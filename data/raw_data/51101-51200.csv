question_id,title,body,tags
528031,Calculation of real values of $x$ in $\sqrt{4^x-6^x+9^x}+\sqrt{9^x-3^x+1}+\sqrt{4^x-2^x+1} = 2^x+3^x+1$,"Calculate the real solutions $x\in\mathbb{R}$ to $$
\tag1\sqrt{4^x-6^x+9^x}+\sqrt{9^x-3^x+1}+\sqrt{4^x-2^x+1} = 2^x+3^x+1
$$ My Attempt: Let $2^x = a$ and $3^x = b$ . Then $(1)$ becomes $$
\sqrt{a^2-a\cdot b+b^2}+\sqrt{b^2-b+1}+\sqrt{a^2-a+1} = a+b+1
$$ How can I complete the solution from this point?",['algebra-precalculus']
528043,Monodromy Groups of Differential Equations,"I have heard that monodromy groups and analytic continuation can be used to construct new solutions to a differential equation from a particular solution. What references (textbook, or papers) could I read to learn more about this topic, and if you happen to know a good example, I would love to hear it. I have made some progress on finding references for this, but the most helpful in terms of explicit computation and a derivation of monodromy strictly from a differential equation is 
""Black Hole Scattering from Monodromy"" by Castro, Lapan, Maloney, and Rodriguez from Harvard and McGill. In particular, I find the derivation in Section 2.1 very helpful and would be looking for a more detailed explanation of computing monodromy matrix representations using analytic continuations, Wilson loops, etc.","['ordinary-differential-equations', 'reference-request', 'complex-analysis']"
528066,What do you see when you drive past an orchard?,"If you've ever driven past an orchard where the trees are planted in a perfect grid, you may have noticed that if you align your line of sight with the grid, you can see down the successive rows and it looks kind of cool. If the trees are sufficiently thin, you may notice that other directions - such as $45^\circ$ to the axes of the grid - have the same effect, although the gap you're able to view is smaller.  If you drive past a grid of thin poles, there are many ""resonant directions"" that you can see and it looks pretty neat.  I can't help but think there's some underlying math here. Here's the model: you start at $(0, 0)$ and drive down the positive x-axis.  At every point with positive integer coordinates, we place a pole.  You then turn your head $\theta$ radians to the left of the x-axis.  I want to find the function $w(\theta)$ that tells you the width of the gap you see. Here's an example, that shows that $w(\frac{\pi}{4}) = \frac{1}{\sqrt{2}}$. The only observation I can make is this: Let $\tan(\theta) = \frac{a}{b}$ for $a, b \in \mathbb{N}$.  Let $T$ be the triangle with endpoints at $\{(0,0),(0,a),(b,0)\}$.  Then $w(\theta)$ is equal to the shortest distance from the hypotenuse of $T$ to some point $(c, d)$ in $T$ with $c, d \in \mathbb{Z}$.  But I am hoping there is a more elegant expression of $w(\theta)$ than that. Thanks!",['geometry']
528089,"Show that if $A\subseteq B$, then inf $B\leq$ inf $A\leq$ sup $A \leq$ sup $B$","Is my logic correct or am I missing something? Show that if $A\subseteq B$, then inf $B\leq$ inf $A\leq$ sup $A \leq$ sup $B$ Case 1. If $A \subset B$ then there exists $b_1,b_2\in B$ such that $b_1,b_2 \notin  A$. Let $a_1,a_2 \in A$ such that $a_1=$ inf A and $a_2$ = sup A. Suppose $b_1$=inf B and $b_2$=sup B than $b_1<a_1<a_2<b_2$ which implies inf $B<$ inf $A < $ sup $A<$ sup $B$ Case 2. If $A = B$ than every element in $A$ is in $B$. This implies that if $A$ is bounded above or below so is $B$ and vice versa. If the sup $B$ is defined to be the least upper bound and the inf $B$ is defined to be the greatest lowest bound. Than sup $B$ = sup $A$ and inf $B$ = inf $A$. Since $A \subseteq B$ the following equality can be written as inf $B\leq$ inf $A\leq$ sup $A \leq$ sup $B$","['inequality', 'real-analysis', 'supremum-and-infimum']"
528100,are all dynamical systems described by differential equations?,"we defined in lecture a dynamical System as a one-parameter family of maps $\phi^t:M\rightarrow M$ such that $\phi^{t+s}=\phi^t\circ\phi^s$ and $\phi^0=Id$, where $M$ is some (smooth) manifold and $s,t\in (a,b)\subset\mathbb{R}$. Of course, if we consider some vector field $V:M\rightarrow TM$, then the flow of that vector field around some point $x_0\in M$ is a (local) dynamical system. Now I'm wondering if all dynamical systems can be described that way. Can we find for all dynamical systems $\phi^t$ a vector field $V$, s.t. $\phi^t$ is the flow of $V$? Maybe you know some argument. Regards","['dynamical-systems', 'ordinary-differential-equations']"
528136,Minimization of Sum of Squares Error Function,"Given that $y(x,{\bf w}) = w_0 + w_1x + w_2x^2 + \ldots + w_mx^m = 	\sum_{j=0}^{m} w_jx^j$ and there exists an error function defined as $E({\bf w})=\frac{1}{2} \sum_{n=1}^{N} \{y(x_n, w)-t_n\}^2$ (where $t_n$ represents the target value). I'm having trouble making sense of a passage in my textbook. (Note: ${\bf w}$ represents a vector of the polynomial's coefficients.) I've listed the passage below: We can solve the curve fitting problem by choosing the value of ${\bf w}$ for which $E({\bf w})$ is as small as possible. Because the error function is a quadratic function of the coefficients ${\bf w}$,   its derivatives with respect to the coefficients will be linear in the elements of ${\bf w}$, and so the minimization of the error function has a unique solution, denoted by ${\bf w^*}$, which can be found in closed form. How do we know that the minimal solution exists and is unique? What guarantees this? Any help understanding this would be appreciated.","['statistics', 'optimization', 'polynomials']"
528144,how do I solve this seperable equation with so many terms?,"Solve given differential equation by separation of variables $$\frac{dy}{dx}=\frac{xy+3x-y-3}{xy-2x+4y-8}$$ I started by multiplying each side by the denominator to get $$(xy-2x+4y-8) dy = (xy+3x-y-3) dx$$
Now that there is $xy$ on each side of the equation do they cancel off or no because they are being multiplied by $dy$ or $dx$. How do I proceed? I'm getting a little discourage because this is the third separable differential equation I have come across and they all have taken a long time and involved lots of writing and are error prone. Is that right, in general differential equations are long and tedious (e.g. involve two integratoins and more)?",['ordinary-differential-equations']
528213,Translating English into First Order Logic,"Translate the following into a formula of first-order logic. ""A language L that is regular will have
the following property: there will be some number N (that depends on L) such that if s is a string
in L (a string is a sequence of characters) whose length is at least N then s can be written as $xyz$
where y is not the empty string and $xy^i
z$ is in the language L for every nonnegative integer i."" can anyone help me with this? This is what I came up with so far and it's definitely not right... My Guess: Universe of Discourse: Language
N(x)= x is some number depending on L
I(x)= x is non negative integer
S(x)= x is string in L for existential quantifier ill use ""bE"" and for universal quantifier ill use ""bA"" Guess starts here: bEx(N(x) ^ (S(x) > N(x)) --> bEx bEy bEz((S(x)=xyz)^y does not equal S element empty set)) ^ bAx(I(x) This is probably completely wrong; I don't really get it. Thanks for any input/help.","['logic-translation', 'discrete-mathematics', 'first-order-logic']"
528220,"Metric is continuous, on the right track?","Let $X$ be a metric space with metric $d$. Show that $d:X\times X\rightarrow \mathbb{R}$ is continuous. The problem is taken from Munkres Topology second edition, Section 20. I know that if $d$ is a metric on $X$ then $d:X\times X\rightarrow \mathbb{R}$. My thinking is that the topology that is on $X$ is the topology induced by the metric $d$, and that the topology on $X\times X$ is the product topology on that space where we take the basis to be
$$\mathcal{B}=\{ U \times V \mid \text{ $U,V$ both open in $X$}\}.$$
Am I on the right track to say that we define some new metric on $X\times X$ and show that this metric induces the same topology as the product topology and then work with the function $d$ as a function between metric spaces to show continuity?
The question doesn't mention anything about defining some new metric and I've tried to solve the problem by looking at $X\times X$ as having the product topology, but in picking some point $(x,y) \in X\times X$ and some neighborhood around $d(x,y)$ in $\mathbb{R}$, I haven't yet found the way to make a neighborhood around $(x,y)$ which maps into the neighborhood around $d(x,y)$.","['general-topology', 'metric-spaces']"
528225,Conditions on Hartshorne exercise II.7.1,"Hartshorne, ""Algebraic Geometry,"" Exercise II.7.1, reads: Let $(X, \mathcal{O}_X)$ be a locally ringed space, and let $f : \mathscr{L} \to \mathscr{M}$ be a surjective map of invertible sheaves on $X$.  Show that $f$ is an isomorphism. To prove this, I note that a morphism of sheaves is injective (resp. surjective) iff it is injective (resp. surjective) on stalks.  Thus $f_P$ is surjective for each $P \in X$.  Since $\mathscr{L}$ and $\mathscr{M}$ are invertible, $\mathscr{L}_P \cong \mathscr{M}_P \cong \mathcal{O}_{X, P}$ as $\mathcal{O}_{X, P}$-modules.  From commutative algebra, a surjective endomorphism of finitely-generated modules over any ring is in fact an automorphism, so $f$ is an isomorphism on stalks and thus an isomorphism of sheaves. This argument sounds fine to me, but now I'm worried because I didn't use many of the conditions in the problem -- I could weaken it to an arbitrary (rather than locally-) ringed space, to any locally free sheaves of the same rank or even to something a bit weaker (namely that $\mathscr{L}$ and $\mathscr{M}$ are locally isomorphic), etc. Have I missed something here?  Or does the result hold in much wider generality without any modification?",['algebraic-geometry']
528230,"Restrict a metric, gives same topology as subspace topology from larger space $X$","Let $A\subseteq X$. If $d$ is a metric for the topology of $X$, show that $d\restriction_{A\times A}$ is a metric for the subspace topology on $A$. I've shown that $d'=d\restriction_{A\times A}$ is a metric on $A$. I am letting $\tau_B$ denote the subspace topology on $A$ that is induced by the metric topology on $X$ and $\tau_{B'}$ denote the topology on $A$ induced by the metric $d'$. My goal is to show $\tau_B=\tau_{B'}$. Let $B=\{A \cap B_\varepsilon^d(x) \mid x \in X, \varepsilon>0\}$, a basis for $\tau_B$ and $B'=\{B_\varepsilon^{d'}(a) \mid a \in A\}$, a basis for $\tau_{B'}$. I've shown $B' \subseteq B$ and so $\tau_{B'} \subseteq \tau_B$. For showing $\tau_B \subseteq \tau_{B'}$ I've picked some $a \in A$ and $A\cap B_\varepsilon^d(x)$, a basis element of $\tau_B$ such that $a \in A\cap B_\varepsilon^d(x)$. My goal is to find some basis element $C$ of $\tau_{B'}$ such that $a \in C \subseteq A\cap B_\varepsilon^d(x).$ If $x \in A$, then
$$A\cap B_\varepsilon^d(x)=B_\varepsilon^{d'}(x)$$
and so I have my needed basis element $C$. The part where I have been having trouble is if $x \notin A$. In this case, what I have tried so far is to see if I can find some $\delta >0$ such that
$$a \in B_\delta^{d'}(a) \subseteq A\cap B_\varepsilon^d(x)$$
but in searching for a delta and trying to show via set containment that the $\delta$-ball is contained in the $\varepsilon$-ball intersected with $A$ has been difficult. I've tried using triangle inequality but I am running into a problem of not knowing how to show that if $y \in B_\delta^{d'}(a)$, meaning $d'(a,y)$ that $y \in A\cap B_\varepsilon^d(x)$, mainly that $d(x,y) < \varepsilon$. It seems with the different $\delta$'s I have tried, I can use the triangle inequality to show something like $d(x,y) < \frac{3}{2}\varepsilon$ but not quite $\varepsilon$.","['general-topology', 'metric-spaces']"
528242,"Hartshorne's proof that $\mathcal{O}_{\operatorname{Spec} A}(D(f)) \cong A_f$, Prop II.2.2(b)","Hartshorne, ""Algebraic Geometry,"" Proposition II.2.2(b) on page 71 reads (roughly): $\mathcal{O}_{\operatorname{Spec} A}(D(f)) \cong A_f$ The relevant section of the proof reads (after some simplification): We define $\psi : A_f \to \mathcal{O}_{\operatorname{Spec} A}(D(f))$ by sending $a/f^n$ to the section which assigns to each $\mathfrak{p}$ the image of $a/f^n$ in $A_\mathfrak{p}$.   First we show that $\psi$ is injective.  If $\psi(a/f^n) = 0$, then for every $\mathfrak{p} \in D(f)$ we have $a/f^n = 0$ in $A_\mathfrak{p}$, so by definition there is some $h \not \in \mathfrak{p}$ such that $h a = 0$ in $A$.  Let $\mathfrak{a}$ be the annihilator of $a$ in $A$.  Then $h \in \mathfrak{a}$ and $h \not \in \mathfrak{p}$, so $\mathfrak{a} \not \subseteq \mathfrak{p}$.  We conclude that $V(\mathfrak{a}) \cap D(f) = \emptyset$.  Therefore $f \in \sqrt{\mathfrak{a}}$, so $f^\ell \in \mathfrak{a}$ for some $\ell$, so $f^\ell a = 0$.  Since $f$ is a unit in $A_f$, this says that $a = 0$ in $A_f$.  The hard part is to show that $\psi$ is surjective... I follow the argument fine, but it strikes me as particularly ingenious, despite Hartshorne's implicit assertion that it's the ""easy part"" of the argument.  (To be fair, the proof of surjectivity takes a whole page.)  In particular, the fact that we're checking a commutative algebra result to apply to a problem in algebraic geometry by applying algebraic geometry to the commutative algebra problem kind of blows my mind at the moment. Is this really just a very clever argument, or is there some perspective from which it's straightforward?  Alternatively, is there some other way of seeing this result?","['commutative-algebra', 'algebraic-geometry']"
528250,do two random variables defined on different probability spaces have the same disribution?,"Given two probability spaces $\textstyle (\Omega_1,\mathcal{F}_1,P_1) , \textstyle (\Omega_2,\mathcal{F}_2,P_2)$ , X is a random variable defined on $(\Omega_1,\mathcal{F}_1,P_1)$, Y is a random variable defined on $(\Omega_2,\mathcal{F}_2,P_2)$. Is it possible X and Y have the same distribution? if have, how to prove?","['probability-theory', 'probability']"
528297,Determine the ideal of an affine variety,"Let $X=\{(r^2,r^3,r^4) : r\in\Bbb R\}\subset \Bbb R^3$. Show that 1)  $X$ is an affine variety. 2)  Determine the ideal of $X$. Every $f\in\Bbb R[x,y,z]$, can we write $f$ in the form $f=p(xz-y^2)+q(z-x^2) +r$ , where $p,q\in\Bbb R[x,y,z]$? i) Affine variety is defined as the solution set to some polynomials in the affine space $k^n$. ii) The ideal of $X$ is defined as $$I(X)=\{f\in \Bbb R[x,y,z]:f(x,y,z)=0, \forall (x,y,z)\in X\}$$",['algebraic-geometry']
528309,Do monotone operators have positive Frechet derivatives?,"If a scalar function $f\colon \mathbb R \to \mathbb R$ is monotone and differentiable, then $f'\geq 0$. Monotonicity is generalized for an operator $A\colon V \to V^*$, where $V$ is a Banach spaces with its dual space $V^*$, via: The operator $A\colon V \to V^*$ is called monotone if $$   \langle A(u) - A(v), u-v \rangle \geq 0,$$ for all $u$, $v \in V$. So my question is: Does monotonicity of $A$ imply, that the Frechet derivative of $A$ is positive, i.e. $\langle A'(w)v,v\rangle \geq 0$ for any $w \in V$ and for all $v\in V$. Any idea or reference is appreciated.","['banach-spaces', 'monotone-operator-theory', 'reference-request', 'functional-analysis', 'derivatives']"
528329,Differential equation: autonomous system,"This isn't homework. I have no idea what theorems I should be looking at to solve this. Guidance, partial and total solutions are all welcomed. Let $f$ be a locally lipschitz function in an open set $G\subseteq \Bbb R^n$. Consider the autonomous system $y'=f(y)$. Let $y(x,\xi)$ be the value at point $x$ of the maximal solution that satisfies the initial condition $y(0)=\xi$. Prove that the domain of $y(\cdot, y(s, \xi))$ is $I-s$, where $I$ is the domain of $y(\cdot ,\xi)$. Prove that for all $s, t$ such that $y(s, \xi)$ and $y(t+s, \xi)$ exist, then $y(t,y(s,\xi))$ also exists and $y(t,y(s,\xi))=y(t+s, \xi)$. If $y$ is a maximal solution and there exists $T>0$ such that $y(0)=y(T)$ and $f(y(0))\neq 0$, then $y$ is a periodic solution and not constant. If $y$ is a solution whose domain is $(a,+\infty)$, if $\eta:=\lim _{x\to +\infty}y(x)$ and $\eta \in G$, then $f(\eta)=0$. EDIT I found an alternative solution for 3. Please check my proof and give feedback in comments: let $u$ be the restriction of $y$ to $[0,T]$, now let $\overline u$ be the periodic extension of $u$ to $\mathbb R$. It is easy to see that $\overline u$ is a solution to the given differential equation. But since $f$ is locally lipschitz, $\overline u$ must coincide with $y$ wherever they are both defined. Since $y$ is a maximal solution, it must be $\overline u$, so $y$ is defined on $\mathbb R$.","['ordinary-differential-equations', 'solution-verification']"
528388,"Cardinality: $\left|\Bbb N^{\Bbb N}\right| = \left|\{0,1\}^{\Bbb N}\right|$","Let $F$ be the set of functions from $\Bbb N$ to $\Bbb N$ and $G$ be the set of functions from $\Bbb N$ to $\{0,1\}$. Prove that $|F| = |G|$. What I tried doing is saying that every number in $\mathbb{N}$ maps to a bitstring, but I don't know how to construct from there?","['discrete-mathematics', 'elementary-set-theory']"
528397,$\mathcal{O}_X(D) \cong \mathcal{O}_X$: Map doesn't agree on intersection,"Let $D$ be the Weil divisor $D = -2[(x)] + [(x-1)] + [(x-2)]$ on $\Bbb{A}^1_k = \operatorname{Spec} k[x]$. I want to show that $\mathcal{O}_X(D) \cong \mathcal{O}_X$. To do this, it is enough to specify isomorphisms $$\mathcal{O}_X(D)(D(f_i)) \to k[x]_{f_i}$$ that agree on $D(f_i) \cap D(f_j) = D(f_if_j)$. Now to do this I calculate the following:
\begin{eqnarray*} \mathcal{O}_X(D)(D(x^2)) &=& k[x]\cdot \frac{1}{(x-1)(x-2)} \\
\mathcal{O}_X(D)(D(x-2)) &=& k[x] \cdot \frac{x^2}{(x-1)} \\
\mathcal{O}_X(D)(D(x-1)) &=& k[x]\cdot \frac{x^2}{(x-2)} \\
\mathcal{O}_X(D)(D(f(x))) &=& k[x]\cdot \frac{x^2}{(x-1)(x-2)f(x)}\end{eqnarray*} where $f$ is not one of the earlier three polynomials. Now I want to say that the map out of $\mathcal{O}_X(D)D(x^2)$ is multiplication by $(x-1)(x-2)/x^2$ and the map out of $\mathcal{O}_X(D)D(x-2)$ is mutiplication by $(x-1)/(x^2(x-2))$. However on the intersection which is $D((x-2)x^2)$, the maps don't seem to agree. What's the problem here?",['algebraic-geometry']
528417,Minimum of set $\{\frac{m}{n} + \frac{4n}{m}\}$,"We have the following set: $\mathcal{A} = \{ \frac{m}{n} + \frac{4n}{m};\ \ m, n \in \mathbb{N} \} $ Attempting to prove that the set's minimum is 4 yields:
$$\frac{m}{n}+\frac{4n}{m} = \frac{m^2 + 4 n ^2}{mn} \geq 4$$
$$m^2 + 4n^2 \geq 4mn$$
$$m^2 + 4n^2 - 4mn \geq 0$$
$$(2n-m)^2 \geq 0$$ I do not know how to proceed beyond this point, although I suspect induction may be required.
Thank you for your time. Edit: how can it be shown that the set has no upper-bound?",['analysis']
528444,How to calculate Frenet-Serret equations,"How to calculate Frenet-Serret equations of the helix $$\gamma : \Bbb R \to \ \Bbb R^3$$ $$\gamma (s) =\left(\cos \left(\frac{s}{\sqrt 2}\right), \sin \left(\frac{s}{\sqrt 2}\right), \left(\frac{s}{\sqrt 2}\right)\right)$$ I know the following info about Frenet-Serret equations:
$$\frac{\mathrm{d}}{\mathrm{d}s} \begin{bmatrix} t \\ n \\ b \end{bmatrix} = \begin{bmatrix} 0 & \kappa & 0 \\ - \kappa & 0 & \tau \\ 0 & -\tau & 0 \end{bmatrix}\begin{bmatrix} t \\ n \\ b \end{bmatrix}$$","['ordinary-differential-equations', 'calculus', 'differential-geometry', 'manifolds', 'self-learning']"
528456,Clarification of L'hospital's rule,I have a question regarding L'hospital's rule. Why can I apply L'hospital's rule to $$\lim_{x\to 0}\frac{\sin 2x}{ x}$$ and not to $$\lim_{x\to 0} \frac{\sin x}{x}~~?$$,"['calculus', 'limits']"
528467,Prove that $\lfloor0.999\dots\rfloor= ?$ $0$ or $1$?,"I think $\lfloor0.999\dots\rfloor= 1$, as $0.999\dots=1$,but I have doubt, as $\lfloor0.9\rfloor=0$,$\lfloor0.99\rfloor=0$,$\lfloor0.9999999\rfloor=0$, etc.","['decimal-expansion', 'limits']"
528477,How to find the $f^{-1}(x)$ of $f(x)=x^{3}-12x+\frac{48}{x}-\frac{64}{x^{3}}$,"It is a question from a quiz. The following is the whole question. Let
  \begin{eqnarray}
\\f(x)=x^{3}-12x+\frac{48}{x}-\frac{64}{x^{3}} , \space x\in (-\infty ,0),
\end{eqnarray}
  find $f^{-1}(x)$. Hint : $f(x)$ can be written in the form, like$(A+B)^{3}$. The first thing I think is $(A+B)^{3}=A^3+3A^2B+3AB^2+B^3$, then try to make it become the the form of $A^3+3A^3B+3AB^3+B^3$. However, it it so difficult to obtain this form. I need help. Update :
Now I have $\left(x - \frac 4x\right)^3$ but how to find the $f^{-1}(x)$ of $f(x)=\left(x - \frac 4x\right)^3$? Thank you for your attention","['rational-functions', 'inverse', 'algebra-precalculus', 'inverse-function']"
528517,Hints for a complex limit: Prove if $\lim_{z \to \infty} f(z)/z = 0$ then $f(z)$ is constant.,"(To clarify, I would just like a hint . Please do not give me the answer to this problem. )
The solution to the following problem has really evaded me here: Problem: Assume that $f$ is entire and that $\lim_{z \to \infty} f(z)/z  = 0.$ Prove that $f(z)$ is constant. My Thoughts and Work So Far: We know that proving that $f'(z) =  0$ or that for some fixed $c \in \mathbb{C}$, $f(z) = c$ for all $z\in \mathbb{C}$. My first approach was to use Liouville's Theorem; If I could could show that $f$ is bounded then I am done. Since $\lim_{z \to \infty} f(z)/z  = 0$, for all $\varepsilon > 0$ there exists a $N \in \mathbb{C}$ so large that if $z \geq N$ then $|f(z)/z| \leq \varepsilon$. Thus, if $C_R$ is the circle of radius $R$ centered at the point $z$, then, as long as z is large enough by Cauchy's Inequality $$
|f'(z)| \leq \frac{1}{2\pi i} \oint_{C_R} \frac{f(\zeta)}{(\zeta - z)^2}\ d\zeta \leq \bigg | \frac{1}{2\pi i} \bigg | \oint_{C_R} \bigg | \frac{f(\zeta)}{(\zeta - z)^2} \bigg | d \zeta \leq \frac{1}{2\pi}  \frac{|\zeta|\varepsilon 2\pi R}{R^2} = \frac{|\zeta|\varepsilon}{R}. 
$$ Now taking the limit as $R \to \infty$ (which to me says, ""let our circle around our point z dilate to an infinite radius so that it covers all of $\mathbb{C}$) 
$$|f'(z)| \leq \lim_{R \to \infty} \frac{|\zeta|\varepsilon}{R} = 0.$$ Thus $f'(z) = 0$ and $z$ was arbitrary, so $f$ must be constant. Why I Think Im Wrong : I say $z$ was arbitrary, but really it is ""any $z \geq N$"" which really isn't all that arbitrary. This is where I am stuck. Am I right, wrong, close, or totally lost? Any hints would be great. Edit: I am very sorry but I accidentally posted this before I was done typing the problem.",['complex-analysis']
528524,Triangles within square,"Points E and F lie on the sides BC and CD of rectangle ABCD, the AEF is an equilateral triangle. point M is the midpoint of the AF. Prove that the triangle BCM is equilateral.","['geometry', 'triangles', 'circles']"
528538,Prove that if p is an odd prime then $x^2=2 \pmod p$ has solutions if and only if $p\equiv \pm 1 \pmod 8$,"I was going to break up $p$ into $8k+1$ and $8k+7$. Using this, I can plug that in for p and then solve using this.",['number-theory']
528546,Is every variety (defined as separated prevariety) a locally closed subset of some projective space?,"In Hartshorne Ch1, variety is defined to be a affine, quasi-affine, projective or quasi-projective variety. In Mumford's Red book, it was defined to be separated prevariety(gluing of a finite number of irreducible varieties). Is every separated prevariety isomorphic to some variety defined as affine, quasi-affine, projective or quasi-projective variety?",['algebraic-geometry']
528556,Convergence of integral under a limit,"Background: Let $X$ and $Y$ be two lognormal random variables, and $Z = X|Y = y$ a lognormal random variable obtained by conditioning on $Y$. Denote by $g_{\rho}(z)$ the probability density function of $Z$ for a fixed $\rho \in [0,1]$, where $\rho$ is the correlation coefficient between $X$ and $Y$. Let $f(z)$ be an extended-real valued and Lipschitz continuous function with $z \in [-\infty,\infty]$. Define $$I (\rho) = \int_{-\infty}^{\infty}f(z)g_{\rho}(z) dz.$$ At $\rho = 1$,  we have $g_{\rho}(z) = 1(z = \mathbb{E}[Z])$, where $1(\cdot)$ denotes the indicator function. As a result, $I(1) = f(\mathbb{E}[Z])$. Desired result: $$\lim_{\rho \to 1}I(\rho) = I(1) = f(\mathbb{E}[Z])$$. Issue: The limit affects the distribution in the integral. The theorems that I am aware of in this situation, such as Portmanteau's Theorem, require boundedness and continuity of $f$. In my case the function $f$ is Lipschitz continuous but unbounded. I wonder if there are alternate results that could be leveraged here or if the fact that $f$ is Lipschitz is useful. Any help on proving this result is much appreciated.","['probability-theory', 'measure-theory', 'real-analysis']"
528588,A common eigenvector of $A^2$ and $A^{-1}$,"Show that the eigenvector of $A^2$ is the same as the one of $A^{-1}$, where $$A = \begin{bmatrix} 2 & 1 \\ 0 & 2 \end{bmatrix}.$$ All that I can find is that $$A^2 = \begin{bmatrix} 4 & 4 \\ 0 & 4 \end{bmatrix}, \quad A^{-1} = \begin{bmatrix} 1/2 & -1/4 \\ 0 & 1/2 \end{bmatrix}.$$ The eigenvalue of $A^2$ is $4$, and of $A^{-1}$ is $1/2$. I don't know how to do the rest. *Edit According to my lecturer's note, $$(A-\lambda I)X = 0 \rightarrow \begin{bmatrix} a-\lambda & b \\ c & d-\lambda \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$$ If I use $A^2$ 's eigenvalue which is $\lambda = 4$. By using the note provided, $$\begin{bmatrix} 4-\lambda & 4 \\ 0 & 4-\lambda \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$$
$$\begin{bmatrix} 4-4 & 4 \\ 0 & 4-4 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$$
$$\begin{bmatrix} 0 & 4 \\ 0 & 0 \end{bmatrix} \begin{bmatrix} x \\ y \end{bmatrix} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}$$
Then I'm stuck here given what I know and what I've done is correct...","['matrices', 'eigenvalues-eigenvectors']"
528590,Existence of $2^{1/2}$,"I'm trying to prove, that the square root of 2 exists in $\mathbb{R}$. I'm looking at the set $A:=\{y\in\mathbb{R}: y\geq 0, y^2\geq 2\}$. I have already proven that the greatest lower bound $b$ of $A$ exists. However, now I don't know how to proceed. I know that I should consider the cases $b^2 > 2$ and $b^2 < 2$, and bring them to a contradiction, so only the possibility $b^2=2$ is left. I have been given the tip to use the quantities $a:=\frac{1}{2}(1 - \frac{2}{b^2}),\; a^\prime := \frac{1}{2}(1-\frac{b^2}{2}),\; b(1-a),\; \frac{b}{1-a^\prime}$.
I believe I should get to the contradiction that $b$ can't be the greatest lower bound in both cases, but I don't see how to get there. Any ideas?",['real-analysis']
528612,Is there a way to calculate $\int \limits_0^1\frac{x^3}{\sqrt{x^2-1}}\frac{1}{1-a^2x^2}\frac{1}{1-b^2x^2}\frac{1}{c-x}\mathrm dx$,"I want to calculate
$\displaystyle \int \limits_0^1\dfrac{x^3}{\sqrt{x^2-1}}\dfrac{1}{1-a^2x^2}\dfrac{1}{1-b^2x^2}\dfrac{1}{c-x}\mathrm dx$ $a$ and $b$ are real parameters, c could be complex and is the solution of a cubic equation. I tried to find an appropriate contour in the complex plane but failed because it seems impossible to go around the cut (integration from $-1$ to $1$ would be easier). Have anyone an idea? 
Or is any other integration technique better suited?",['complex-analysis']
528616,A linear connection induces a covariant derivative of tensor fields.,"Let $M$ be a smooth manifold. notation: $\mathcal T(M)^{(k,l)}$ is the $C^{\infty}(M)$-module of all tensor fields of type $(k,l)$ on $M$ ($k$ indicates the covariant part). $\mathcal T(M):=\mathcal T(M)^{(1,0)}$ is the $C^{\infty}(M)$-module of all vector fields on $M$. All tensor fields are smooth. Now let $\nabla:\mathcal T(M)\times\mathcal T(M)\to \mathcal T(M)$ be a linear connection on $M$; $\nabla$ should be extended in a unique way to a (Koszul) connection, indicated with the same name,
$$\nabla:\mathcal T(M)\times\mathcal T(M)^{(k,l)}\to\mathcal T(M)^{(k,l)}$$
$$(X,Y)\mapsto\nabla_XY$$
respecting some properties. I don't understand in which way the tensor field $\nabla_XY$ is defined. By the characterization lemma of tensor fields it is enough to give a multilinear function:
$$\varphi:\underbrace{\mathcal T(M)^{(0,1)}\times \mathcal T(M)^{(0,1)}}_{k}\times\underbrace{\mathcal T(M)^{(1,0)}\times\ldots\times \mathcal T(M)^{(1,0)}}_{l}\to C^{\infty}(M)$$ but how can I define such $\varphi$?","['tensors', 'riemannian-geometry', 'differential-geometry']"
528630,Is the null set a subset of every set? [duplicate],"This question already has answers here : Is ""The empty set is a subset of any set"" a convention? (7 answers) Prove that the null set is a subset of a set $A$. (5 answers) Closed 4 years ago . Ever since day one of of my Mathematical Logic course, this fact has really bothered me. I cannot wrap my head around how an empty set is a subset of every possible set. Could someone kindly explain how this is true? Any help is appreciated!","['logic', 'elementary-set-theory']"
528647,Trigonometry - How do I simplify this expression?,"We have the expression $$ 13 \sin [ \tan ^{-1} (\dfrac{12}{5}) ] $$ Apparently the answer is 12, and I have to simplify it, and I'm assuming it means I have to show it's 12, without using a calculator. Normally I show my own work in the questions, but in this case I have absolutely no clue how to. The only thing I know that might help is that $\tan(x) = \dfrac{\sin(x)}{\cos(x)}$.",['trigonometry']
528650,Automorphisms of Surfaces and Quotients,"Let $X$ be a surface (algebraic projective smooth complex) and suppose $\sigma$ is an automorphism of finite order $d$. Let $Y=X/\sigma$. I wonder under which simple conditions on $\sigma$ is $Y$ a smooth surface. For example it seems reasonable that this is the case when $\sigma$ has no fixed points, is that true? What about more general conditions (i.e. allowing a fixed locus for $\sigma$)? Also, what about the canonical bundle of $Y$ in relation to that of $X$? Basically I would like to get a general basic picture of this situation for the particular case of complex surfaces.",['algebraic-geometry']
528656,Why can't you count real numbers this way?,"Sorry but this is probably a naive question. Why can't you generate real numbers by a*10^b, the same way as rational numbers by a/b? a and b could be integers so that you would start counting real numbers like: a\b   0     1    -1     2    -2
 0     0     0     0     0     0
 1     1    10   0.1   100  0.01
-1    -1   -10  -0.1  -100 -0.01
 2     2    20   0.2   200  0.02
-2    -2   -20  -0.2  -200 -0.02 That would just take all of the integers and also apply a decimal point anywhere on those integers, thus making the real numbers no? Which ones would be missing? Plus I don't understand the diagonal argument because the real number set is infinite, so surely the diagonal would just go on forever so you can never check them all since there will be more and more, never ending.","['infinity', 'elementary-set-theory', 'real-analysis']"
528661,Finding the limit of $\frac{\sqrt{x}}{\sqrt{x}+\sin\sqrt{x}}$,How would one find the limit of $\displaystyle\lim_{x\to 0}\frac{\sqrt{x}}{\sqrt{x}+\sin\sqrt{x}}$ I know I have to use the L'Hospital rule. $\displaystyle\lim_{x\to 0}\frac{\frac{1}{2}x^{-1/2}}{\frac{1}{2}\frac{1}{\sqrt{x}}+\frac{1}{2}\frac{1}{\sqrt{x}}\cos\sqrt{x}}$ But I find myself stuck,"['calculus', 'limits']"
528670,A question about convex set,"I need to prove the closed set $C\subseteq \mathbb{R}_{+}$ is a convex. And let $x$, $y$ be arbitrary given in $C$, I have proved that $1/2(x+y)\in C$. Then does this means $C$ is convex ?","['general-topology', 'elementary-set-theory', 'functional-analysis', 'operator-algebras']"
528688,Function Surjectivity Proof,"I have this question: Prove that a function $f:X\rightarrow Y$ is surjective iff for any
  finite set $Z$ and any function $g:Z\rightarrow Y$ there exists a
  function $h:Z\rightarrow X$ such that $g$ is their composition: $f
 \circ h = g$. Assume $X,Y$ are also finite. Can someone please show me how to complete this proof? I'm struggling with proving the forward direction, and think my work on the backwards direction (below) may not be rigorous enough. If $f:X \rightarrow Y$ is surjective, then for any $g:Z \rightarrow Y$ there exists $h:Z \rightarrow X$ s.t. $f \circ h = g$. We can show that this holds: we know there is some $y' \in Y$ s.t. $g(z') = y'$, where $z' \in Z$. We also know that for the same $z'$, there is some $x' \in X$ s.t. $h(z') = x'$, as we may define $h$ as such. So we can define $f:X\rightarrow Y$ as mapping each $x'$ to $y'$, i.e. $f(x')=y'$,so $\forall y \in Y, \exists z \in Z s.t. f(h(z)) = y$.","['proof-verification', 'proof-writing', 'elementary-set-theory', 'functions']"
528708,"Two polynomials $r_1, r_2 \in R[X]$ are equal if and only if the cofficients $a_i, b_i$ are equal for all $i, 0 \leq i \leq n$ - Purely a definition?","I've read that two polynomials $r_1, r_2 \in R[X]$ on the form $r = a_nX^n + ... + a_1X + a_0$ are equal if and only if the cofficients of $r_1, r_2$: $a_i, b_i$ are equal for all $i, 0 \leq i \leq n$. Here $R[X]$ denote the polynomial ring on $R$, where $R$ is a ring. Is this purely a definition or can I proof this ? Can two polynomials with different cofficients achieve the same values for all $x \in R$ ? I can write $a_nX^n + ... a_1X + a_0 = b_nX^n + ... b_1X + b_0$ set $X = 0$ and deduce $a_0 = b_0$. Then $a_nX^n + ... a_1X = b_nX^n + ... b_1X$ implies $X(a_nX^{n-1} + ... a_1) = X(b_nX^{n-1} + ... b_1)$ but now I can't conclude $a_1 = b_1$ ? Thanks","['elementary-number-theory', 'abstract-algebra']"
528715,"For $x>0$, $x + \frac1x \ge 2$ and equality holds if and only if $x=1$ [duplicate]","This question already has answers here : How to prove this inequality $ x + \frac{1}{x} \geq 2 $ (20 answers) Closed 10 years ago . Prove that for $x>0$, $x + \frac1x \ge 2$ and equality holds if and only if $x=1$. I have proven that $x+ \frac1x \ge 2$ by re-writing it as $x^2 -2x +1 \ge0$ and factoring to $(x-1)^2\ge0$ which is true because you cannot square something and it be negative. Now I am stuck on the part where I have to prove equality to hold if and only if $x=1$. Any suggestions?","['inequality', 'algebra-precalculus']"
528718,A man is known to speak truth 3 out of 4 times. He throws a die and reports that it is a six. Find the probability that it is actually a six.,"I have this question as an example in my maths school book. The solution given there is:- E = the man reports six P(S1)= Probability that six actually occurs = $\frac{1}{6}$ P(S2)= Probability that six doesn't occur= $\frac{5}{6}$ P(E|S1)= Probability that the man reports six when six has actually occurred = $\frac{3}{4}$ P(E|S2)= Probability that the man reports six when six has not occurred = $1-\frac 3 4=\frac 1 4$ Therefore, by Bayes' Theorem, $P(S1|E)=\frac{(\frac{1}{6}\cdot\frac{3}{4})}{(\frac{1}{6}\cdot \frac{3}{4})+(\frac{5}{6}\cdot \frac{1}{4})} =\frac{3}{8}  $ I have its solution but my teacher said that the solution given is incorrect and told that the actual solution would be something else:- $P(S1|E)=\frac{\frac 1 6\cdot\frac3 4}{(\frac 1 6\cdot \frac 3 4)+(\frac 5 6\cdot \frac1 4\cdot\frac1 5)} = \frac 3 4$ So, I want to ask which one is correct.
Thank you.","['bayes-theorem', 'probability']"
528749,How prove this$\frac{1}{P_{0}P_{1}}+\frac{1}{P_{0}P_{2}}+\cdots+\frac{1}{P_{0}P_{n}}<\sqrt{15n}$,"Let $P_{0},P_{1},P_{2},\cdots,P_{n}$  be $n+1$  points in the plane. Let $ d=1$ denote the minimal value of all the distances between any two points. Prove that $$\dfrac{1}{P_{0}P_{1}}+\dfrac{1}{P_{0}P_{2}}+\cdots+\dfrac{1}{P_{0}P_{n}}<\sqrt{15n}$$ This problem background is  from   China high school math competition (Oct 14, 2012) problem 15,can see http://www.artofproblemsolving.com/Forum/viewtopic.php?p=2822547&sid=bbbc81f99da00d657f61b4835931c87e#p2822547 also can see this two solution: http://wenku.baidu.com/view/82fb84d4240c844769eaeea3.html But for my problem,I can't prove it.and I think this is nice problem,and Thank you for your help.","['geometry', 'inequality', 'combinatorics']"
528760,If 4 people have 5 different cars to choose from and two people cannot pick the same. How many different ways could people pick the cars?,"If 4 people have 5 different cars to choose from and two of those people cannot pick the same(the remaining two people could have the same car). How many different ways could people pick the cars? At first I was thinking First Person: 5 choices
Second Person: 4 choices, because they cannot have the same car as person 1.
Third Person 5 choices
Fourth Person 5 choices
Overall 5*4*5*5 = 500 ways, but I'm just not sure if this would assure people 1 and 2 don't get the same car. To help with confusion lets just give the people names to make this more clear. Abby, Bob, Chris, and Dan. They have 5 different types of cars to choose from but Abby and Bob cannot have the same type of car. Meaning Abby, Chris, and Dan could have the same type of car or Bob Chris and Dan could have the same car. The only restriction is that Abby and Bob do not have the same type of car",['combinatorics']
528764,Finding the limit of $x \sin\frac{\pi}{x}$,How can I find the limit of the following $x\rightarrow\infty$ $x \sin\frac{\pi}{x}$ I did $\dfrac{\sin\frac{\pi}{x}}{\frac{1}{x}}$ I took the derivative using l hospital and got. $\dfrac{-1x^{-2} \cos \dfrac{\pi}{x}}{-1x^{-2}}$ Simplying I get $\cos \frac{\pi}{x}$ but I am stuck. another problem I have is $\dfrac{\ln(x)}{\cot x}$ as $x\rightarrow0$ I did $\dfrac{\dfrac{1}{x}}{-\csc^2(x)}$ But I am unsure how to go on.,"['calculus', 'limits']"
528769,Absolutely irreducible representations of the absolute Galois group of $\mathbb{Q}_p$,"Let $p$ be a prime number. Denote by $G$ the absolute Galois group of (a finite extension of) $\mathbb{Q}_p$. Let $\ell$ be a prime number. For $\ell= p$, I guess it is well known that the  irreducible continuous and finite dimensional representations of $G$ with coefficients in $\bar{\mathbb{F}}_p$ are induced from a character. More precisely, let $d$ be the dimension of the representation which we denote by $\rho$ and let $\mathbb{Q}_{p^d}$ be the unramified extension of $\mathbb{Q}_p$ of degree $d$, with absolute Galois group $G_d$. Then there exist a character $\omega : G_d \to \bar{\mathbb{F}}_p^{\times}$ such that $\rho$ is isomorphic to $Ind_{G_d}^{G} (\omega)$ (and I think $\omega$ is a power of a fundamental character of ""niveau"" $d$ as defined by Serre). Now can we describe the irreducible representations of $G$ with coeffients in $\bar{\mathbb{F}}_{\ell}$ when $\ell \neq p$ ?","['representation-theory', 'galois-representations', 'number-theory']"
528770,function field of an integral scheme,"Suppose $X$ is an integral scheme, and let $\eta \in X$ be its generic point. Then the local ring $\mathcal{O}_{X,\eta}$ is a field, called the function field of $X$ and denoted $K(X)$. Why is $K(X)$ called a function field? In what sense (if any) are its elements functions? Is there some conceptual connection between regular functions (on a variety) and $K(X)$? I'm asking because the name is quite suggestive, but it doesn't seem to follow directly from the definition that $K(X)$ is a field of ""functions"".","['algebraic-geometry', 'schemes']"
528797,Negating $(\forall a \in A)(\exists b \in B)(a \in C \leftrightarrow b\in C)$?,I'm not quite sure how to go about doing this. When negating I know the quantifiers themselves will be negated meaning that $\forall$ would become $\exists$ and vice-versa. Also I know that $\leftrightarrow$ can be written for example as $(\lnot a\in C \lor b \in C)\land(\not b \in C \lor a \in C)$. And this can be negated using De Morgan's laws. However what about the $\in$ would I have to negate those too? Can you please show me how that's done.,"['logic', 'quantifiers', 'discrete-mathematics']"
528811,How would I go about writing this proof in a formal way?,"Let c ∈ Z: Write a detailed structured proof to prove the statement: If c^5 + 7 is even, then c is odd . I started out like this: Assume c ∈ Z
    Assume c^5 + 7 == 2n
        Then c == 2n + 1 Also, is this claim true? I plugged in odd numbers for c, and haven't encountered a counter-example. Is there a way to determine the veracity of the claim before doing the proof?","['logic', 'proof-writing', 'elementary-set-theory']"
528831,Solutions to the Anticommutator Matrix Equation,"I'm investigating matrices with regards to antisymmetric properties, and I'm curious if there is a general solution to
$$[A,X]=B$$
in terms of a (constant) matrix $X$, where $[A,X]$ denotes for shorthand the anticommutator $AX+XA$ (note: not $AX-XA$) and $A$ and $B$ are given matrices. For simplicity, let $A$ and $B$ be real symmetric pos. def. matrices. Is there a reference for this if it's true, or is it possibly a deep result requiring much theory and/or more conditions?","['matrices', 'linear-algebra']"
528840,Explicit description of discrete valuations corresponding to prime divisors,"I'm reading Hartshorne p. 130 on Weil divisors. Let $X$ be a noetherian integral separated scheme regular in codimension 1, $Y$ a prime divisor on $X$, and $\eta \in Y$ its generic point. $\mathcal{O}_{\eta,X}$ is then a discrete valuation ring with quotient field $K = $ the function field of $X$. Consider the corresponding discrete valuation $v_Y$. My question is: is it possible to describe this valuation more explicitly? Or alternatively do you know any illuminating examples for specific schemes and divisors?","['algebraic-geometry', 'schemes']"
528852,Simple upper bound for $\binom{n}{k}$,"I remember seeing an upper bound for the binomial $\binom{n}{k}$ with an exponential function, something like $\binom{n}{k}\leq \left(ne/k\right)^k$. What exactly is it, and are there other similar good upper bounds for $\binom{n}{k}$? Edit : As the link in Macavity's comment shows, the bound is indeed $\binom{n}{k}\leq \left(ne/k\right)^k$. How can we prove this?","['inequality', 'algebra-precalculus']"
528856,Explanation and proof of the 4th order Runge-Kutta method,"The 4th order Runge-Kutta (RK4) method is a numerical technique used to solve ordinary differential equations (ODEs) of the following form $$\frac{dy}{dx} = f(x,y), \qquad y(0)=y_0$$ It gives $y_{i+1}$ in the form $$y_{i+1} = y_i+(a_1k_1+a_2k_2+a_3k_3+a_4k_4)h$$ where the constants are found to be : $$y_{i+1} = y_i+\frac{1}{6}(k_1+2k_2+2k_3+k_4)h$$ and: $$\begin{aligned} k_1 &= f(x_i, y_i)\\ k_2 &= f \left(x_i+\frac{1}{2}, y_i+\frac{1}{2}k_1h \right)\\ k_3 &= f \left(x_i+\frac{1}{2}, y_i+\frac{1}{2}k_2h \right)\\ k_4 &= f(x_i+h, y_i+k_3h) \end{aligned}$$ I also learnt that these are derived from the first four terms Taylor series: $$y_{i+1}=y_i+f(x_i,y_i)h+\frac{1}{2!}f'(x_i,y_i)h^2+\frac{1}{3!}f''(x_i,y_i)h^3+\frac{1}{4!}f'''(x_i,y_i)h^4$$ These are the things that I understood. However, here are what I cannot: I cannot see why this method ""works""? How are the $a_ik_i$ terms derived and computed from the Taylor series? What justifies or proves this result? Please note that I have seen many articles on these things things, but none of them contained a full proof whatsoever... I would also much like to get some examples where the f function is actually a function of both x, y not only x. Could you please send me some links with further advanced and concise links of this question?","['approximation', 'ordinary-differential-equations', 'runge-kutta-methods', 'numerical-methods']"
528868,Symmetric function theorem and Galois Theory -- How deep is the connection?,"By symmetric function theorem in the title, the fundamental theorem of symmetric polynomials is meant: Any symmetric polynomial has a unique representation as a polynomial in the elementary symmetric polynomials. Certainly, symmetric function theorem can be proved using Galois theory. But one is led to suspect that the connection is a little deeper than this simple one-way implication. The line of thought arose after perusing Hecke's lectures in the theory of algebraic numbers. Usually early books on algebraic numbers look at all embeddings in the complex numbers to avoid mentioning the word ``automorphisms of fields'', in addition to the advantage of it being useful for proving various finiteness theorems. But this particular book bases the whole constructions on the symmetric function theorem and this baffles me to no end. As the simplest example, the proof that algebraic integers form a ring is done in this way. Certainly, I could grasp the proofs line-by-line; but the grasp of the big picture is still not there. Could somebody help? There is the unshakeable feeling that there is some deeper connections between the symmetric polynomial theorem and Galois theory or other studies of automorphims involving polynomials.","['galois-theory', 'symmetric-polynomials', 'algebraic-number-theory', 'abstract-algebra']"
528888,Sum of derangements and binomial coefficients,"I'm trying to find the closed form for the following formula $$\sum_{i=0}^n {n \choose i} D(i)$$ where $D(i)$ is the number of derangement for $i$ elements. A derangement is a permutation in which none of the objects appear in their ""natural"" (i.e., ordered) place. For example, the only derangements of $\{1,2,3\}$ are $\{2,3,1\}$ and $\{3,1,2\}$, so $!3=2$.","['summation', 'algebra-precalculus', 'combinatorics']"
528889,Why do we call it a $\sigma$-algebra?,"In simple terms, a $\sigma$-algebra is the collection of all of the things we know how to measure. Why don't we call it something that more directly suggests this, for example a 'measure space?'","['measure-theory', 'soft-question']"
528903,Submanifold of a regular value of a manifold with boundary,"Question: Suppose $M$ is a smooth manifold with boundary, $N$ is a smooth manifold, and $F:M\rightarrow N$ is a smooth map. Let $S=F^{-1}(c)$, where $c\in N$ is a regular value of both $F$ and $F\left|_{\partial M}\right. $. Prove that $S$ is a smooth submanifold with boundary in $M$, with $\partial S=S\cap \partial M$. Work: OK so let $n=\dim(N)$ and $m=\dim(M)$ and let $c$ be a   regular value of both $F$ and $F\left|_{\partial M}\right.$. Then there are charts $(U,\phi)$ and $(V,\psi)$ centered at $c$ and $F(c)$ such that $c\in U$ and $F(U)\subset V$. Note that $(U,\phi)$ is a boundary chart for $M$. We have that the function $\widetilde{F}=\psi\circ F\circ\phi^{-1} $ is smooth so there is an open neighborhood $U'$ of $\phi(c)$ such that there is an smooth extension of $G$ of $\widetilde{F}$ on $U'$. Notice that we have that $G^{-1}(c)\cap H^{m}=\widetilde{F}^{-1}(c)\cap U'$. Now this is where I'm stuck, not sure where to go from here any tips?","['manifolds', 'differential-geometry']"
528927,Help finding a combinatorial proof of $k {n \choose k } = n {n - 1 \choose k -1}$,Help finding a combinatorial proof of $k {n \choose k } = n {n - 1 \choose k -1}$ I have expanded it this far: $$\frac{k \cdot n!}{k!(n-k)!} = \frac{n \cdot (n-1)!}{(k-1)!(n-k)!} $$ but then I am stuck from where to go from there.,"['combinatorial-proofs', 'binomial-coefficients', 'combinatorics']"
528937,$\frac{dx}{dt} = |x|^{1/2}$,"Im looking to find 4 solutions to the ODE : $\frac{dx}{dt} = |x|^{1/2} , x(0)=0$. Clearly, $x=0$ is one solution.
Using seperation of variables for $x>0$ yields $x= t^2/4$ as another solution, and if we consider $x<0$, I find that $x = -t^2/4$. Could someone give a hint as to where I am missing the last solution? Thanks!",['ordinary-differential-equations']
528983,What is meant by 'the completion of Z'?,"In the first chapter of Algebraic Number Theory (lecture notes collected by Cassels-Fröhlich), page 28 has the following paragraph: ""We suppose now that $k$ is a finite field of characteristic $p$ with $q=p^m$ elements. Denote by $\bar{\mathbb{Z}}$ the completion of $\mathbb{Z}$ with respect to the topology defined by the subgroups $n\mathbb{Z}$ ($n>0$). Then $\Gamma(\bar{k}^s/k)$ is an isomorphic copy of $\bar{\mathbb{Z}}$ under the map $$v \mapsto w_q^v$$ where $$\alpha w_q = \alpha^q.""$$ $\Gamma(\bar{k}^s/k)$ refers to the Galois group of the maximal seperable extension of $k$ over $k$, and given an element $\sigma$ of the Galois group Fröhlich writes $x\sigma := \sigma(x)$. Firstly, I'm not positive what it means when it says the topology defined by those subgroups; is it saying the topology generated by taking those sets as a basis? Even if so, I don't see what the completion here would be (i.e. how it could be described), and if the elements aren't integers, I don't see how one 'exponentiates' the automorphism $w_q$.","['galois-theory', 'finite-fields', 'algebraic-number-theory', 'abstract-algebra']"
529007,"if $f(k/N)\rightarrow0$ as $N\rightarrow\infty$ for any $k$, must $f(h)\rightarrow0$ as $h\rightarrow0$?","If $f$ is a function defined on [$\mathbb{R}$ or $\mathbb{C}$] such that for any [real or complex] $k$, $f(\frac{k}{N})\rightarrow0$ as $N\rightarrow\infty$ in $\mathbb{N}$, must it be true that $f(h)\rightarrow0$ as $h$ tends to $0$? (This is essentially 2 questions, but I'd be grateful for an answer to either! I put them together because they're probably both answerable in the same way, since no derivatives are involved.) I've tried to prove the answer is yes using a delta-epsilon argument, but keep stalling because although $f(\frac{k}{N})$ must tend to zero for any particular $k$, there's no uniform rate of convergence for all $k$ in a small interval. On the other hand, I can't find a crazy counterexample either, since once $f$ has been defined at a point, that point can be part of infinitely many sequences $\frac{k}{N}$, along all of which $f$ tends to zero. Many thanks for any help with this!","['sequences-and-series', 'functions', 'limits']"
529010,What is the proof that SVM can be used to solve the least squares problem with norm equality constraint?,"I've seen it claimed that the solution to the minimization problem: $$\begin{align*}
\arg \min_{b} \quad & {\left\| A b \right\|}_{2}^{2} \\
\text{subject to} \quad & {\left\| b \right\|}_{2} = 1
\end{align*}$$ is given by first finding the singular value decomposition of A, $$\textbf{A} = \bf{U \Sigma V}$$ And then taking the column of $\bf{V}$ corresponding to the smallest singular value. Can someone present a proof that this is so?","['optimization', 'linear-algebra', 'svd', 'least-squares']"
529023,Is any subgroup of a direct product isomorphic to a direct product of subgroups?,"This question arose in the context of this problem : Let $G$ and $G'$ be groups and $V$ a subgroup of $G\times G'$.
  Do there exist subgroups $H \leq G$ and $H'\leq G'$ such that $V \cong H\times H'$? In the case that the answer is ""no"": Are there any reasonable constraints to $G$ and $G'$ such that the answer is ""yes""? For finite abelian groups, the answer appears to be yes. Clarification My question is about the subgroup $V$ being isomorphic to a direct product of subgroups. This condition is strictly weaker than being equal to a direct product of subgroups:
For the ""equal"" version, the classical counterexample is the diagonal subgroup $V = \langle (1,1)\rangle \leq G\times G$ where $G$ may be any group but the trivial one. However, this doesn't provide a counterexample to my question, since $V\cong G\times\{1\}$.","['group-isomorphism', 'group-theory', 'abstract-algebra', 'direct-product']"
529025,Prove the Number of Additions of Fibonacci Number Algorithm,"I am studying for a final exam and I'm having trouble with this question: The following recursive algorithm FIB takes as input an integer $n \ge 0$ and returns the $n$-th Fibonacci number $F_n$: Algorithm FIB(n):

    if n = 0 or n = 1 then
        f = n
    else
        f = FIB(n-1) + FIB(n-2)
    endif
    return f Let $a_n$ be the amount of additions made by the algorithm FIB(n) , the total number of times that the $+$-function in the else-case is called. Prove that for all $n \ge 0$ $$a_n = F_{n+1} - 1.$$ I am thinking I should use recurrence to solve it but I'm completely lost. Thanks in advance!","['recurrence-relations', 'discrete-mathematics', 'fibonacci-numbers', 'induction', 'proof-writing']"
529028,To what extent can I square both sides of an absolute equation?,"I am working on some absolute equation problems like the following: $$\begin{align}
& {|x-4|} \lt 1 \\
& 1 \le |x| \le 4 \\
& |x+3| = |2x+1|
\end{align}$$ Now, for both of these equations, I simply squared both sides to get rid of the absolute and then continued solving from there. Now my question is: when can I not do this and what is the alternative if I can't? Thanks a bunch!","['absolute-value', 'algebra-precalculus']"
529048,Straight-line embedding planar graph,"I want to prove that every normal planar graph has a straight-line embedding. First, I assume that the planar graph $G$ is maximal planar, i.e the number of edges is $3n-6$ for $|G|=|V(G)|\ge3$. If the graph is not maximal planar I simply add some edges until it is maximal. I also know that all faces form triangles. Now I want to prove the result with induction with respect to $n$. $n=3:$ This case is trivial, it is just a triangle. $n-1\rightarrow n$. I assume I know that the embedding works for a graph with $n-1$ vertices. I do not know hot to conclude. Intuitively it is clear to me because it is nothing more than some triangles which I clue together. Maybe you can help me.","['graph-theory', 'discrete-mathematics', 'planar-graphs']"
529049,necklace of numbers with bounded distance,"Starting from the numbers 1-2-3-4-5-6-7-8-9-10-11-12 arrange them in a circle so the difference |x-y| between  neighbors is 1 or 2 . If we are working mod 12 so that 12 = 0 , how many possible arrangements are there?",['combinatorics']
529050,Differentiating both sides of a non-differential equation,"I'm working on solving for $t$ in the expression $$\ln t=3\left(1-\frac{1}{t}\right)$$ and although I can easily tell by inspection and by graphing that $t=1$, I'd like to prove it more rigorously. I got stuck trying to solve this algebraically, so I tried to take the derivative of each side with respect to $t$ to get $$\frac{1}{t}=3\left(\frac{1}{t^{2}}\right).$$ However, this implies that $t=3$, which is incorrect. Why can't I take the derivative of each side like this? What am I doing wrong or misunderstanding?","['calculus', 'derivatives', 'transcendental-equations']"
529057,Joint distribution by independent distributions,"We have $N$ independent discrete finite random variables (RVs) $X_1,\dots,X_i,\dots,X_N$ where RV $X_i$ has $M_i$ finite number of elements. We are free to choose any distribution $f_i$ for RV $X_i$ $\forall i=\{1,\dots,N\}$. Then consider the product set $Y = X_1\times\dots\times X_i\times\dots\times X_N$ and say we are interested in a particular distribution $f_Y$, which is in the set of all possible distributions on $Y$. Note $f_Y$ is not the product of $f_i$s. How close can we come to $f_Y$ by manipulating the independent distributions $f_i$ $\forall i=\{1,\dots,N\}$ ? Which I believe (not sure) is same as asking how close is $\prod_i^Nf_i$ to $f_Y$? There is a set of real numbers $\boldsymbol{a}=\{a(y)\}_{y\in Y}$. The objective is to make the expectation of the set $\boldsymbol{a}$ over $f_i$s as close as possible to the expectation of  $\boldsymbol{a}$ over $f_Y$. I tried writing an optimization problem to minimize $\mid \sum_{y\in Y}[\prod_i^Nf_i(y)-f_Y(y)]a(y)\mid$, but it is non convex. And I am not sure if this is the optimization problem I should solve. What does it mean to be ""close"" when we have two distributions? Note that just expectations being close is not sufficient, the probability $\prod_i^Nf_i(y)$ has to be close to the true probability $f_Y(y)$ $\forall y \in Y$. The question Distance between the product of marginal distributions and the joint distribution is bit similar but in there marginals come from the joint but in my question no marginals are compared. Would be very grateful for any clue. Thanks. PS. Not homework. Part of research work.","['probability-theory', 'measure-theory', 'probability-distributions', 'probability']"
529059,derivative of a summation with variable upper limit,"Is the following statement correct and if yes does it need to satisfy specific requirement to be correct:
$${ d \over dt} \sum_{j=1}^{N(t)} f(t,j) = \sum_{j=1}^{N(t)} {df(t,j) \over dt} + f(t,N(t)) {dN(t) \over dt}$$","['summation', 'derivatives']"
529111,"Why if $n \mid m$, then $(a^n-1) \mid (a^m-1)$?","My Number Theory book says that for $n, m$ be positive integers and $a>1$, then $(a^n -1)\mid(a^m -1)$ if and only if $n\mid m$. I understand the proof for only if part, but in if part the autor says ""it is clear"". However a tried to prove that but a get stuck. Can you give a hint?","['divisibility', 'number-theory']"
529141,Conditional Probability: Sheldon Ross Example 2h,"The following question comes from Example 2h, in Sheldon Ross's textbook A First Course in Probability on page 64. I got the same answer as the author through a different line of reasoning (given at the end of the solution). However, I would really like to understand the reasoning given in this solution, if someone could elaborate that would be great! The question: An ordinary deck of 52 playing cards is randomly divided in 4 piles 13 cards in each pile. Compute the probability that each pile has an ace. The solution: We want to define four events for this problem :
\begin{align*}
E_{1}	&=	\{\text{The ace of spades in any one of the piles}\}\\
E_{2}	&=	\{\text{The ace of spades and the ace of hearts are in different piles}\}\\
E_{3}	&=	\{\text{The aces of spades, hearts, and diamonds are all in different piles}\}\\
E_{4}	&=	\{\text{All four of the aces are in different piles}\}
\end{align*} The desired probability is $P(E_{1}E_{2}E_{3}E_{4})$ and by applying the multiplication rule,
$$P(E_{1}E_{2}E_{3}E_{4})=P(E_{1})P(E_{2}|E_{1})\cdots P(E_{4}|E_{1}E_{2}E_{3})$$ Now, $$P(E_{1})=1$$ Since $E_1$ is in the sample space $S$. Also, 
$$P(E_{2}|E_{1})=\frac{39}{51}$$
Since the pile containing the pile contain the ace of spades will contain 12 of the remaining 51 card, and 
$$P(E_3 | E_1 E_2)=\frac{26}{50}$$ Since the piles containing the aces of spades and hearts will receive 24 of the remaining
50 cards. Finally, and finally, 
$$P(E_4 | E_1 E_2 E_3)=\frac{13}{49}$$ Multiplying them all together we get 
$$P( E_1 E_2 E_3 E_4) \approx 0.105$$ My Confusion: I don't quite understand the reasoning; it is clear that $P(E_1)$ is 1, because the ace of spades has to end up some where. But the the conditional probability has me confused; given the the ace of spades is in one pile I have 51 cards to choose from to put in any of the piles. There are $\binom{51}{39}$  ways that I can choose the 39 cards for the piles that don't contain the ace of spades. If I want to assure that I get the ace of hearts in one of the 3 piles that doesn't contain the ace of spades, I can set it aside. Then I am left to choose 38 from 50, there are  $\binom{50}{38}$ ways to do this. Then I have 
$$\frac{\binom{50}{38}}{\binom{51}{39}}=\frac{39}{51}$$ And this same reasoning will lead to the same answer. I see benefit from not having to use the binomial coefficient, but I don't understand the soundness of the authors reasoning could someone elaborate on why his method works?","['probability', 'combinatorics']"
529171,Is the abelianization of a subgroup $H$ a subgroup of the abelianization of a group $G$?,"Let $G$ be a finite group and $H<G$. Then, is it true that $H^{ab} < G^{ab}$, that is, the abelianization of $H$ is a subgroup of the abelianization of $G$? To me, it would make sense if is was indeed true. However, I do not know exactly how to prove it. For any group $G$, we know that $G^{ab} = G/G' < G$, where $G'$ is the commutator subgroup of $G$. Thus, $H^{ab} < H < G$ and so by transitivity, $H^{ab} < G$ and so we obtain $H^{ab} < G$ and $G^{ab} < G$. I am stuck here... Thanks for your help.","['group-theory', 'abstract-algebra', 'abelian-groups']"
529190,How to prove $\frac{\ln x}{\sqrt x}$ is decreasing.,"I need to prove this before I can use the Integral Test to determine if the series is is converging or diverging. My series is from [1,infinity).
I tried plugging in number and the function seems to increase, so I tried the derivative and now I'm stuck. Thank you, everyone!
I've got it now.  The original problem was to determine if the series converges or diverges and why.
Series was from n=1 to infinity: (ln n)/(sqrt n)","['sequences-and-series', 'calculus', 'derivatives']"
529205,"Evaluating the log gamma integral $\int_{0}^{z} \log \Gamma (x) \, \mathrm dx$ in terms of the Hurwitz zeta function","One way to evaluate $ \displaystyle\int_{0}^{z} \log \Gamma(x)  \,  \mathrm  dx $ is in terms of the Barnes G-function . $$ \int_{0}^{z} \log \Gamma(x)  \,  \mathrm  dx = \frac{z}{2}  \log (2 \pi) + \frac{z(1-z)}{2} +  z \log \Gamma(z) - \log G(z+1)$$ Another way is in terms of the Hurwitz zeta function . $$ \int_{0}^{z} \log \Gamma(x)  \,  \mathrm dx = \frac{z}{2} \log(2 \pi) + \frac{z(1-z)}{2} - \zeta^{'}(-1) + \zeta^{'}(-1,z)$$ I've been trying to prove the latter so that I can prove $$\log G(z+1) - z \log \Gamma(z) = \zeta'(-1) - \zeta'(-1,z) .$$ My starting point is the generating function $$ \sum_{k=2}^{\infty} \zeta(k,a) x^{k-1} = \psi(a) - \psi(a-x) .$$ Integrating both sides, I get $$ \sum_{k=2}^{\infty} \frac{\zeta(k,a)}{k} x^{k} = \psi(a) x + \log \Gamma(a-x) - \log \Gamma(a),$$ which implies $$ \sum_{k=2}^{\infty} (-1)^{k} \frac{\zeta(k,1)}{k} x^{k} = \gamma x + \log \Gamma(x+1) . $$ Then rearranging and integrating both sides from $0$ to $z$, I get $$ \int_{0}^{z} \log \Gamma(x+1) \,  \mathrm dx = \int_{0}^{z} \log x \  \mathrm dx + \int_{0}^{z} \log \Gamma(x) \,  \mathrm dx   = - \frac{\gamma z^{2}}{2} + \sum_{k=2}^{\infty} (-1)^{k} \frac{\zeta(k,1)}{k(k+1)} z^{k+1} .$$ And then using the integral representation $$ \zeta(s,a) = \frac{1}{\Gamma(s)} \int_{0}^{\infty} \frac{t^{s-1} e^{-at}}{1-e^{-t}} \, \mathrm dt, $$ I get $$ \int_{0}^{z} \log \Gamma(x) \,  \mathrm dx = z- z \log z  - \frac{\gamma z^{2}}{2} + \sum_{k=2}^{\infty} (-1)^{k} \frac{z^{k+1}}{k(k+1)} \frac{1}{\Gamma(k)} \int_{0}^{\infty} \frac{t^{k-1} e^{-t}}{1-e^{-t}} \, \mathrm dt $$ $$ = z - \log z - \frac{\gamma z^{2}}{2} + z \int_{0}^{\infty} \frac{e^{-t}}{1-e^{-t}} \frac{1}{t} \sum_{k=2}^{\infty} \frac{(-1)^{k}}{k+1} \frac{(zt)^{k}}{k!} \, \mathrm dt $$ $$ = z - z \log z - \frac{\gamma z^{2}}{2}  + z \int_{0}^{\infty} \frac{e^{-t}}{1-e^{-t}}\frac{1}{t} \left( -\frac{e^{-zt}}{zt} - 1 + \frac{zt}{2} + \frac{1}{zt} \right) \, \mathrm dt$$ $$ = z - z \log z - \frac{\gamma z^{2}}{2} + \lim_{s \to 0^{+}} \Big[ - \int_{0}^{\infty} \frac{t^{s -2} e^{-(z+1)t}}{1-e^{-t}} \, \mathrm dt - z \int_{0}^{\infty} \frac{t^{s-1} e^{-t}}{1-e^{-t}} \, \mathrm dt $$ $$ + \frac{z^{2}}{2} \int_{0}^{\infty} \frac{t^{s} e^{-t}}{1-e^{-t}} \, \mathrm dt  + \int_{0}^{\infty} \frac{t^{s -2} e^{-t}}{1-e^{-t}} \, \mathrm dt \Big]$$ $$ = z - z \log z - \frac{\gamma z^{2}}{2} + \lim_{s \to 0^{+}} \Big[ - \Gamma(s-1) \zeta(s-1,z+1) -z \Gamma(s) \zeta(s) + \frac{z^{2}}{2} \Gamma(s+1) \zeta(s+1)$$
$$ + \Gamma(s-1) \zeta(s-1) \Big] .$$ Assuming I haven't made any mistakes up to this point, how do I evaluate that limit?","['riemann-zeta', 'special-functions', 'integration', 'zeta-functions', 'gamma-function']"
529209,Suppose $g$ is even and let $h=f \circ g$. Is $h$ always an even function?,"I came across one of the following problems in my homework set: $$ \text{Suppose} \, g \, \text{is even and let} \, h=f \circ g. \text{Is} \, h \, \text{always an even function?}$$ I came to the conclusion through examples that ""yes"" the answer was true. Rather than just random examples, I also tried thinking about in different way. If we have a function $f$ and we compose it with $g$ and perform the even function test then the even function, $g$ will always evaluate to itself and which makes entire function equivalent. For example, let $g$ be $x^2$ and let $f$ be $\sin x$ then $f \circ g$ is $\sin (x^2)$ and $f(x) = f(-x)$ because $\sin (x^2) = \sin ((-x)^2)$. Is my second approach better than my first? Is there a different and more concrete way to do this? Thanks!","['algebra-precalculus', 'functions']"
529211,$\frac{dy}{d \theta} = {e^y\sin^2(\theta)\over {y\sec(\theta)}}$,Please help me solve the above differential equation. I'm confused as to the steps required to obtain the answer,"['ordinary-differential-equations', 'integration']"
529219,Holonomy and Differential Characters,"This question is going to be rather vague, but I'm just trying to see if there are obvious connections between these two concepts. So the holonomy of a vector bundle with Lie group $G$ is
$$h(A)=\mathcal{P}\exp\left(\int_\gamma A\right)$$
where $\mathcal{P}$ is the path-ordering symbol and the integral over the connection $A$ is taken over a curve $\gamma$. These elements form the holonomy group, which relates to the curvature of the connection via Ambrose-Singer. A differential character is an element
$$h\in Hom(C_{k-1}(M;\mathbb{Z}),U(1)),\quad h\circ \partial \in\Omega^k(M)$$
defined on a chain $c\in C_{k}(M;\mathbb{Z})$ to be
$$h(\partial c)=\exp \left(\int_c \omega(h)\right)$$
where $\omega(h)$ is an element in $\Omega^k(M)$ (Called the curvature of $h$). Differential characters form a group $\hat{H}^*(M,\mathbb{Q}/\mathbb{Z})$, which are related to homology groups and are key objects in topological quantum field theory. So my question is essentially how these two things are related to each other. For instance, one might think that the differential characters evaluated on points would be equal to the holonomies of a $U(1)$ bundle. Thus, can we think of differential characters as something like ""higher-order holonomies""? At least of $U(1)$ bundles? What if we generalize in the other direction, change the image of the exponentials to be a general Lie group $G$? Would this be a generalization of holonomies to a higher $k$-skeleton? Does anyone know if what I propose is natural, totally wrong, or very complicated?","['holonomy', 'gauge-theory', 'differential-geometry', 'characters']"
529230,Does my proof make sense?,"Theorem: For groups $(\Bbb R,+)$ and $(\Bbb R,*)$ (both only dealing with positive integers) there is a function $\phi$ that turns $(\Bbb R,+)\to(\Bbb R,*)$ and vice versa. Proof: Assume $(\Bbb R,+)\to(\Bbb R,*)$. So there is a function where elements $x_1,x_2$ going from additive operation to multiplicative operation where $x_1+x_2 \mapsto x_1 *x_2$.
So there is some $\phi$ where $\phi(X_1*X_2)= \phi(x_1)*\phi(x_2)$ (here * is an operation)
Take $\phi=e$, so $e^{x_1+x_2}=e^{x_1}*e^{x_2}$. Now the inverse of $e$ is $\ln$, so $\ln(x_1 *x_2) = \ln(x_1+x_2)$ I know there is a lot missing from the proof or at least it's not concrete by looking at it. I just need a little help in cleaning up the theorm and proof.",['abstract-algebra']
529242,Help find the derivative of $e^{2^x}$ using the definition of the derivative,"Let $f(x) = e^{2^x}$, where $e$ is the exponential function. So the $f'(x)$ is: $\begin{align}f'(x) &=& \lim_{h \to 0} \frac{e^{2^{x+h}}-e^{2^x}}{h}\\
                      &=& \lim_{h \to 0} \frac{e^{2^{x}2^h}-e^{2^x}}{h}
\end{align}$ I don't know how to finish from here. I believe the next step is to remove the $h$ in the denominator which means I need to factor out the $h$ in the numerator but I am not sure how to do it as that $h$ is an exponent of an exponent. I know I can use the chain rule to arrive at $e^{2^x}2^x\ln 2$ but I would like to try it this way for practice.","['exponential-function', 'algebra-precalculus', 'derivatives']"
529253,Finding the associated matrix of a linear transformation to calculate the characteristic polynomial,"Let $T : M_{n \times n}(\Bbb R) \to M_{n \times n}(\Bbb R)$ be the function given by $T(A)=A^t$ (the transpose of $A$). I need to find the minimal polynomial and the characteristic polynomial of $T$. So, to find the characteristic polynomial, I'm trying to find the associated matrix of $T$. I did it for the case $n=2$. The coordinates of a matrix $\left( \begin{array}{ccc}
a & b \\
c & d \end{array} \right)$ in the canonical basis $\beta$ is $[X]_\beta=\left( \begin{array}{c}
a \\
b \\
c \\
d \end{array} \right)$. Let $$A = \left( \begin{array}{ccc}
1 & 0 & 0 & 0 \\
0 & 0 & 1 &0 \\
0 & 1 & 0 & 0 \\
0 & 0 &0 & 1 \end{array} \right)$$ Then $$A[X]_\beta=[A^t]_\beta==\left( \begin{array}{c}
a \\
c \\
b \\
d \end{array} \right).$$ So, $A$ is the associated matrix of $T$. I know I can do the same for any $n$, but I don't know how to generalize it, and I need it to find the characteristic polynomial, solving $\det (\lambda I-A)=0$. Maybe there's an easier way to find the characteristic polynomial, if you know it, please let me know. If not, how can I generaize this matrix $A$ for any $n$ to find $\det (\lambda I-A)=0$? Thanks so much for your help,","['linear-transformations', 'matrices', 'linear-algebra', 'characteristic-polynomial']"
529270,"Is $\{0,1\}^{\omega_1}$ sequentially compact?","It is claimed that an uncountable product of $[0,1]$ is not sequentially compact, e.g. in Wikipedia (I think replacing $[0,1]$ by $\{0,1\}$ doesn't make much difference).
However, the constructions I saw always take an uncountable set of the same cardinality as the reals.
So I wonder whether $\{0,1\}^{\omega_1}$ is also non-sequentially compact, and if yes, whether one can construct explicitly a sequence without convergent subsequence.
Constructing such a sequence in $\{0,1\}^\mathfrak{c}$ requires no choice; does one need some form of choice to say something about $\{0,1\}^{\omega_1}$?","['general-topology', 'set-theory', 'compactness']"
529280,Partial Fractions over complex variables.,"We proved the following theorem in my Complex Variables class the other day. Let $R(z)=\frac{P(z)}{Q(z)}$ be a rational function with $deg(P)<deg(Q)$ and let the roots of $Q(z)$ be $z_{i}$. Then $$R(z)=\sum_{i=1}^{n}P_{z_{i}}(z)$$ where $P_{z_{i}}(z)$ is the principal part of $R(z)$ at $z_{i}$. This is a nice theorem, making partial fraction expansion very intuitive in many cases, including for real numbers. Recall that $f(z)=\frac{h(z)}{z-z_{0}}$ and $h(z)$ is analytic at $z_{0}$ then the principal part of $f(z)$ at $z_{0}$ is $\frac{h(z_{0})}{z-z_{0}}$. So for example, $$\frac{1}{z^{4}-1}=\frac{1}{z-1}\frac{1}{z+1}\frac{1}{z-i}\frac{1}{z+i}$$ is now easily expandable into: $$\frac{1}{4}\left(\frac{1}{z-1}-\frac{1}{z+1}+\frac{1}{z-i}-\frac{1}{z+i}\right)$$
Which does save time when compared to the traditional way of using undetermined coefficients. However for homework I had to find the partial fraction decomposition of $$\frac{1}{(z-1)^{2}(z^{4}-1)}$$ which has a third order pole at $z=1$. I am finding it very hard to find the principal part here in a nice way. I can figure out the contributions from the other poles like above, as they are all simple. I can find the other principal part with traditional methods, or by using a computer. But I can't figure out a nice way to compute it using the theorem above. Help?","['partial-fractions', 'complex-analysis']"
529302,Notation for Permuting Sets,"If I have some arbitrary sets $A_i : i \in I$ and I want to permute their intersections pairwise, how would I write such a permutation? Would I use some permutation tensor? Essentially I want to permute $A_i \cap A_k \, \, \forall i,k \in I$. How would I notate this formally?","['notation', 'elementary-set-theory']"
529362,$L^1$ bounded martingale,"If $(M_t)_{0\leq t<\infty}$ is continuous martingale and it is $L^1$ bounded, does it imply that quadratic variation $\langle M\rangle_\infty$ is finite a.s. ?","['stochastic-processes', 'martingales', 'probability-theory', 'quadratic-variation', 'stochastic-calculus']"
529377,Optimization Homework,"I need help with this math question: A farmer with 720 ft of fencing wants to enclose a rectangular area and then divide it into four pens with fencing parallel to one side of the rectangle. What is the largest possible total area of the four pens. This is what I have attempted so far. Perimeter = 2*L + 5*W = 720 Solve for W 
W = 144 - 2/5*L Area of each pen = L/4*W 
Plug in W 
Area = L/4*144 - L/4*2/5*L  or is it [Length/4*144 -Lenght/4*2/5lenght) I have a feeling I am attempting this question incorrectly..","['optimization', 'calculus', 'derivatives']"
529406,Verifying the inequality $\sum_{i=1}^n \frac{\cos y_i}{\sin x_i}≤ \sum_{i=1}^n\cot x_i $,"Let $\sum_{i=1}^n x_i=\sum_{i=1}^ny_i= \pi$ , where $n>1$ and $x_i >0 , y_i>0 , \forall i=1,2,..,n$. How can we prove that $$\sum_{i=1}^n \frac{\cos y_i}{\sin x_i}≤ \sum_{i=1}^n\cot x_i $$ ?","['trigonometry', 'inequality']"
529416,Calculus of variations: Lagrange multipliers,"Given a functional 
$$J(y)=\int_a^b F(x,y,y')dx,   \tag{1}$$ where $y$ is a function of $x$, and a constraint 
$$\int_a^b K(x,y,y')dx=l,  \tag{2}$$
if $y=y(x)$ is an extreme of (1) under the constraint (2), then there exists a constant $\lambda$ such that $y=y(x)$ is also an extreme of the functional
$$\int_a^b [F(x,y,y')+\lambda K(x,y,y')]dx. \tag{3}$$
Similarly, if the constraint is 
$$g(x,y,y')=0, \tag{4}$$
then there exists a function $\lambda(x)$ such that the extreme also holds for the functional 
$$\int_a^b [F(x,y,y')+\lambda(x)g(x,y,y')]dx. \tag{5}$$ This is known as the Lagrange multiplier rule for calculus of variations. However, I have two questions about this statement. If the functional (1) has two constraints (2) and (4), does the extreme also hold for the functional
$$\int_a^b [F(x,y,y')+\lambda K(x,y,y') +\lambda(x) g(x,y,y')]dx ? \tag{6}$$ Is this statement also valid for multiple variable case? For example, if $J=\iint F(x_1,x_2,y(x_1,x_2))dx_1 dx_2$, and $\iint K(x_1,x_2,y(x_1,x_2))dx_1 dx_2=l$, is this equivalent to $J=\iint F(x_1,x_2,y(x_1,x_2))+\lambda K(x_1,x_2,y(x_1,x_2))dx_1 dx_2$? Thanks in advance and any suggestion will be appreciated. It is better if you have any reference.","['calculus', 'calculus-of-variations', 'lagrange-multiplier']"
529419,convergence of total variation measure,"Let $X = [0,1]$. Let $\mu_n$ be a sequence of regular Borel measures on $X$, which converges to a measure $\mu$ on $X$ in weak-star, i.e. for any $f\in C_0(X)$, we have $\int_X f \mu_n(dx) \to \int_X f \mu(dx)$. Is it possible to show that $|\mu_n|$ converges to $|\mu|$ in weak-star, or any other modes?","['weak-convergence', 'functional-analysis', 'real-analysis']"
529451,Solution to a tricky inequality (math analysis),"Let $p>1$ and put $q=\frac{p}{p-1}$, so $1/p+1/q=1$. Show that for any $x>0$ and $y>0$, we have 
$$ xy \le \frac{x^p}{p}+\frac{y^q}{q}$$
And find where the equality holds. So far, I have simply tried to multiply through the RHS of the above expression and see what would happen, plugged in for $q$ and I got this: $$ pxy \le  x^p+(p-1)y^\frac{p}{p-1} $$
We also know that $q>1$ by its definition and using $p>1$, but I am not quite sure how to proceed. Any suggestions? 
Thank you for the help",['analysis']
529463,Prove Sine integral exists as improper Riemann integral but is not Lebesgue-integrable.,"I got to prove that $$\int_0^1 \frac{1}{t}\sin\left(\frac{1}{t}\right)dt,$$ exists as an improper Riemann integral, yet that $$f(t)=\frac{1}{t}\sin\left(\frac{1}{t}\right)\notin \mathcal{L}_1((0,1),\mathbb{B},\lambda),$$
i.e. that $$\int_{[0,1]}\left|\frac{1}{t}\sin\left(\frac{1}{t}\right)\right|d\lambda=\infty.$$ Attempt: We know that $\forall \epsilon, 0<\epsilon \le 1$, $f(t)$ is continuous in $[\epsilon,1]$, so $\int_{\epsilon}^1 f(t)dt$ exists. Now, with the change of variable $z=1/t$ the integral becomes
$$\int_1^{\frac{1}{\epsilon}}
\frac{\sin(z)}{z}dz.$$ 
I have to prove the limit of the above expression converges as $\epsilon \rightarrow 0$. For the second part I was told I should approximate $|f(t)|$ by simple functions and show that their integrals go to $\infty$, but I can't quite grasp the procedure. Any ideas or insight would be greatly appreciated.","['lebesgue-integral', 'measure-theory', 'integration']"
529472,inequality of some integrals of continuously differential function.,"Let $f:[a,b]$→$\mathbb{R}$ be a continuously differential fuction satisfying f(a)=0.
My goal is to show that $$\int_{a}^{b} |f(x)|^2 dx \le  \frac{(b-a)^2}{2} \int_{a}^{b} |f'(x)|^2 dx $$ My attempt is following: By FTC, $f(x)=f(a)+\int_{a}^{x} f'(t) dt$ = $\int_{a}^{x} f'(t) dt$ However, by M.V.T for integral $\int_{a}^{x} f'(t) dt=(x-a)f'(\zeta_x)$ for some $\zeta_x \in [a, x]$ So, $\int_{a}^{b} |f(x)|^2 dx$=$\int_{a}^{b} |\int_{a}^{x} f'(t) dt|^2 dx$ = $\int_{a}^{b} |(x-a)f'(\zeta_x) dt|^2 dx$ $\le$ $(b-a)^2\int_{a}^{b} |f'(\zeta_x) dt|^2 dx$ $…(*)$ For a convenience, we define a map $g:[a,b]→[a,b]$ by  $g(x)=\zeta_x$. Then the right integral in the inequality $(*)$ becomes $(b-a)^2\int_{a}^{b} |f'(g(x)) dt|^2 dx$. Consequently, $\int_{a}^{b} |f(x)|^2 dx \le (b-a)^2\int_{a}^{b} |f'(g(x)) dt|^2 dx$. Hereby, I tried. But I don't know next step..  please inform me how to proceed the problem.",['analysis']
529483,convergence in $L^1$ for product of functions,If $f_n$ converges to $f$ in $L^1$ and $g_n$ converges to $g$ in $L^1$. Does it necessarily mean that $f_ng_n$ converges to $fg$ in $L^1$ for finite measure spaces.,"['integration', 'measure-theory', 'real-analysis', 'analysis', 'lp-spaces']"
529499,Gaussian curvature of a surface of revolution,"Let $\alpha(s)=(f(s), g(s))$ be a plane curve parametrized by arc length on the $yz$-plane and assume that $f(s)>0.$ The surface revolution attained by rotating the curve parameterized by $\alpha$ about the z-axis which is given by $f(u,v) = (f(u)\cos v, f(u)\sin v, g(u)).$ How do I show that it has Gaussian curvature $K(u,v) = -\frac{f''(u)}{f(u)}.$ I am wondering how it is derived? I computed the normal vector, the first and second fundamental forms but I still can't derive it.","['curvature', 'differential-geometry']"
529517,"Additive group contains exactly three elements of the set $\{p,p+q,pq,p^q,q^p\}$","Let $p$ and $q$ be distinct primes. There is a proper subgroup $J$ of the additive group of integers which contains exactly three elements of the set $\{p,p+q,pq,p^q,q^p\}$. Which three elements are in $J$? I know the solution is $\{p,pq,p^q\}$. However I do not understand why. I thought $J$ can not even be a finite group. Maybe there is serious misunderstanding of the problem. Can anyone give me a hand? Thanks.","['prime-numbers', 'group-theory']"
529530,Invariance of Integration on Homotopic Curves,"All: I'm trying to show that if curves $\gamma, \gamma'$ are homotopic to each other in some region $R$ (open, connected subset) of the plane, and f is differentiable in $R$ , then: $\int_{\gamma}f=\int_{\gamma'}f$ . Please critique this argument and help me finish: first, we construct a homotopy $H(x,t)$ between the two curves  ${\gamma},{\gamma'}$, with $H(x,0)=\gamma, H(x,1)=\gamma'$ then, define $M$ to be the set $H(x,t)$for $t$ in $(0,1)$, so that $M$ is the region bounded by the two curves. Now, we apply Stokes' thm. to get: $\int \int_M df=\int_{\partial M} f=\int_{\gamma}f-\int_{\gamma'}f$ Now, I need to have the integral be equal to zero, to get the equality $\int_{\gamma}f-\int_{\gamma'}f=0$ How can I do so? Is the rest correct? Thanks.","['general-topology', 'multivariable-calculus', 'differential-geometry']"
529534,How many methods to this limit $\lim_{n\to\infty}\left(\frac{1}{2}+\frac{3}{2^2}+\cdots+\frac{2n-1}{2^n}\right)$,"find the limit
$$\lim_{n\to\infty}\left(\dfrac{1}{2}+\dfrac{3}{2^2}+\cdots+\dfrac{2n-1}{2^n}\right)$$ My try:
let $$S=\dfrac{1}{2}+\dfrac{3}{2^2}+\cdots+\dfrac{2n-1}{2^n}$$
  $$\dfrac{1}{2}S=0+\dfrac{1}{2^2}+\cdots+\dfrac{2n-3}{2^n}+\dfrac{2n-1}{2^{n+1}}$$
  so
  $$\dfrac{1}{2}S=\dfrac{1}{2}+\dfrac{2}{2^2}+\dfrac{2}{2^3}+\cdots+\dfrac{2}{2^n}-\dfrac{2n-1}{2^{n+1}}$$
  so
  $$S=3-\dfrac{4}{2^n}-2\cdot\dfrac{n}{2^n}+\dfrac{1}{2^n}\longrightarrow 3,n\longrightarrow 3$$ solution 2: let $$S=\sum_{n=1}^{\infty}nx^n,|x|<1|$$
  $$S=x\sum_{n=1}^{\infty}nx^{n-1}=x\left(\sum_{n=1}^{\infty}x^n\right)'=x\left(\dfrac{x}{1-x}\right)'$$ Have other nice methods?Thank you","['summation', 'limits']"
529547,Power rule derivative in complex,"Problem:
Prove that if $f(z)= z^n$, then $f' (z)$ = $n z^{n-1} $ using the definition of the derivative.","['calculus', 'complex-analysis']"
529561,How find this $f(k)=\sum_{n=1}^{\infty}\frac{n^k}{2^n}$ is positive integers?,"Question: let $$f(k)=\sum_{n=1}^{\infty}\dfrac{n^k}{2^n},k\in N^{+}$$ show that:
  $f(k)$is always postive integer numbers. this is problem is my creat it,maybe is old problem,because when I deal following $$f(1)=\sum_{n=1}^{\infty}\dfrac{n}{2^n}$$
and this solution:
$$\sum_{n=1}^{\infty}nx^n=x\sum_{n=1}^{\infty}nx^{n-1}=\dfrac{x}{(1-x)^2}$$
so $$f(1)=2$$ and use same methods
$$f(2)=\sum_{n=1}^{\infty}\dfrac{n^2}{2^n}=6$$
$$f(3)=\sum_{n=1}^{\infty}\dfrac{n^3}{2^n}=26$$
$$f(4)=\sum_{n=1}^{\infty}\dfrac{n^4}{2^n}=150$$
$$\cdots\cdots\cdots$$ and How prove $f(k)$ is postive integers,and maybe find the $f(k)=?$","['summation', 'limits']"
529568,"Is it possible that $(ab)^{-1}$ is defined although $a^{-1},b^{-1}$ are not?","I wish to enquire about the properties of units in abstract algebra. In a ring $R$, a unit $u$ is an invertible element. Let $u=ab$. Is it possible that $a$ and $b$ are not units? Is it possible that they're prime? Motivation: If $u=ab$, then $(ab)^{-1}$ exists. We know that if the inverses of $a$ and $b$ exist, then $(ab)^{-1}=b^{-1}a^{-1}$. However, if the inverses of $a$ and $b$ don't exist, I feel $ab$ can still be a unit. However, I'm not sure of this. Thanks in advance!","['noncommutative-algebra', 'ring-theory', 'abstract-algebra', 'monoid']"
