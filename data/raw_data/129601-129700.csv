question_id,title,body,tags
2004878,Product of Infinite series cubes [duplicate],"This question already has answers here : Limit of $\prod\limits_{k=2}^n\frac{k^3-1}{k^3+1}$ (2 answers) Closed 7 years ago . If 
$$X=\left({342\over 344}\right)\left({511\over 513}\right)\left({728\over 730}\right)\dots$$
Up to infinite terms.. The value of $x$ approaches?
What's the approach to the above problem?
They can be expressed as cubes-1/cubes +1.how to simplify further?",['sequences-and-series']
2004895,Does $f\colon x\mapsto 2x+3$ mean the same thing as $f(x)=2x+3$?,"In my textbook there is a question like below: If $$f:x \mapsto 2x-3,$$ then $$f^{-1}(7) = $$ As a multiple choice question, it allows for the answers: A. $11$ B. $5$ C. $\frac{1}{11}$ D. $9$ If what I think is correct and I read the equation as: $$f(x)=2x-3$$
then, $$y=2x-3$$
$$x=2y-3$$
$$x+3=2y$$
$$\frac {x+3} {2} = y$$ therefore: $$f^{-1}(7)=\frac {7+3}{2}$$
$$=5$$","['inverse-function', 'notation', 'functions']"
2004912,Checking validity of Green's Function,"I have the following ODE: $$\left[\frac{d^2}{dt^2}+2\gamma\frac{d}{dt}+\gamma^2\right]x(t) = f(t),$$ where $f(t)$ is an arbitrary driving force. I have already obtained the causal Green's function, $G(t,t')$, which is: $$G(t,t') = \begin{cases}
0 &\text{, if }t\leq t'\\
(t-t')e^{-\gamma\,(t-t')} &\text{, if } t>t'
\end{cases}$$ Is there any way for me to check if the Green's function I calculated is correct? I know that the Green's function should satisfy the ODE for which $f(t)$ is a delta function (an impulse centred at $t=t'$. I have tried substituting back my Green's function into the relevant ODE (modifying the RHS), but I'm not sure what to expect? I think I got $0$, but I'm not entirely confident of that answer, nor what to make of it. EDIT: Fixed a small typo for the solution for $G(t,t')$. Okay, here's what I got: Let $\displaystyle G=H(t-t')e^{-\gamma(t-t')}$. I need to compute the derivatives for $t-t'>0$: $$\begin{align}
\frac{dG}{dt} &= \frac{dH}{dt}e^{-\gamma(t-t')}-H(t-t')\gamma e^{-\gamma(t-t')} \\
&= \delta(t-t')e^{-\gamma(t-t')}-\gamma G(t-t') \\
\frac{d^2G}{dt^2}&= \frac{d\delta}{dt}e^{-\gamma(t-t')}-\gamma\delta(t-t')e^{-\gamma(t-t')}-\gamma\frac{dG}{dt} \\
&= \frac{d\delta}{dt}e^{-\gamma(t-t')}-2\gamma\delta(t-t')e^{-\gamma(t-t')}+\gamma^2G
\end{align}$$
Putting them altogether, I get:
$$\text{L.H.S.}=\frac{d\delta}{dt}e^{-\gamma(t-t')}$$
I don't see how this is equal to $\delta(t-t')$..","['greens-function', 'ordinary-differential-equations']"
2004999,"$\int_{0}^{2\pi} \frac{\cos{3\theta}}{5-4\cos{\theta}}\,d{\theta}$ by using complex/real integration","How to evaluate $\int_{0}^{2\pi} \frac{\cos{3\theta}}{5-4\cos{\theta}}\,d{\theta}$ 
by using complex integration? I assume $z=e^{i{\theta}}$, $\frac{1}{iz}dz=d{\theta}$,
$$\cos{\theta}=\frac{z+z^{-1}}{2}
\quad\mbox{and}\quad \cos3{\theta}=\frac{(z+z^{-1})(z^2+z^{-2}-1)}{2}.$$
Hence 
$$\frac{1}{2i}\oint_{|z|=1} \frac{{(z+z^{-1})(z^2+z^{-2}-1)}}{(5-4\frac{z+z^{-1}}{2})z}\,dz$$
and I'm stuck in this. Could you give me a hints or solution?","['complex-integration', 'complex-analysis', 'integration', 'definite-integrals', 'contour-integration']"
2005021,Sum of binomial coefficients with index divisible by 4,I am trying to obtain a closed form expression for $\sum {n \choose 4k}$ I am trying to use the binomial expansion of $(1 + i)^n$ and $(1 - i)^n$ . $$(1 + i)^n + (1 - i)^n = 2\left(\sum {n \choose 4k} -\sum {n \choose 4k + 2}\right)$$ Stuck at this now. I can't come up with a way to simplify the second term on RHS. Any help would be appreciated.,"['binomial-coefficients', 'sequences-and-series', 'complex-numbers']"
2005035,Rewriting the time-independent Schrödinger equation for a simple harmonic oscillating potential in terms of new variables,"Show that the time-independent Schrödinger equation for a simple harmonic oscillating potential 
$$-\frac{\hbar^2}{2m}\frac{d^2 u}{dx^2}+\frac12 m\,\omega_0^2 x^2u=E\,u$$ can be written as 
$$\frac{d^2u}{dy^2}+(\alpha - y^2)u=0\tag{1}$$ where $$y=\sqrt{\frac{m\,\omega_0}{\hbar}}x$$
and $$\alpha=\frac{2E}{\hbar\,\omega_0}$$ So by my logic $$\frac{dy}{dx}=\sqrt{\frac{m\,\omega_0}{\hbar}}$$ and 
$$\frac{d^2y}{dx^2}=0$$
clearly something has gone wrong or I am going about this the wrong way. My lecturer mentioned in the lecture that: From $$y=\sqrt{\frac{m\,\omega_0}{\hbar}}x\tag{2}$$ it follows that $$\fbox{$\frac{d}{dx}=\sqrt{\frac{m\,\omega_0}{\hbar}}\frac{d}{dy}$}\tag{3}$$ But how does $(3)$ follow from $(2)$? I know that the boxed equation $(3)$ is correct as I have checked the printed notes for that lecture (for which the relevant parts are shown below): But that's just the first problem; even if I understood how obtain $(3)$, I still don't understand how to proceed to derive $(1)$. The only thing I could think to do is take the second derivative of $(3)$ with respect to $x$ such that $$\frac{d}{dx}\frac{d}{dx}=\frac{d^2}{dx^2}=\frac{d}{dx}\sqrt{\frac{m\,\omega_0}{\hbar}}\frac{d}{dy}$$ and once again I am left confused as this approach doesn't appear to be getting me any closer to deriving $(1)$. I don't doubt that I am likely missing something very simple here, but at the moment I have no idea what that is. Could someone please provide me with some hints or advice on how to derive $(1)$ and what operations where carried out to obtain $(3)$? Kindest regards.","['derivatives', 'harmonic-functions', 'chain-rule', 'proof-explanation']"
2005065,Create a function based on data set [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I have a data set: x        y
70 ... -0.05
60 ... -0.0225
50 ... -0.01
45 ... +0.008
40 ... +0.015
30 ... +0.018
20 ... +0.038
15 ... +0.02
10 ... +0.01
5  ...  0
1  ... -0.02 How would I go about creating a function which for any $ x > 0 $ generates $y$ based on this data? (using spline interpolation, y values don't have to be exact match)","['data-analysis', 'functions']"
2005109,Problem in solving this book and pages question,"I was solving some old olympiad problems and I got that one. I m stuck at it. ""In a book with page numbers 1 to 100,some pages are torn off. The sum of the numbers on the remaining pages is 4949. How many pages are torn off??"" I tried to the summation formula(sum of all the pages is sum of all the natural numbers from 1 to 100,since the pages goes from 1 to 100)  and then try to eliminate some numbers (by hit and trial) to see whether the sum comes out to be 4949 or not but I wasn't so lucky. Hoping for help. Any suggestion is heartily welcome","['number-theory', 'combinatorics']"
2005125,Uniqueness proof of the left-inverse of a function,"I attempted to prove directly that a function cannot have more than one left inverse, by showing that two left inverses of a function $f$, must be the same function. My Proof Let $f: A \to B, g: B \to A, h: B \to A$. Suppose $g$ and $h$ are left-inverses of $f$. Thus $ g \circ f = i_A = h \circ f$. Where $i_A(x) =x$ for all $x \in A$. Therefore we have $g(f(a)) = h(f(a))$ for $a\in A$. Now since $f$ must be injective for $f$ to have a left-inverse, we have $f(a) = f(a) \implies a = a$ for all $a \in A$ and for all $f(a) \in B$ Put $b = f(a)$. Then $g(b) = h(b) \
 \ \ \forall b \in B$, and thus $g = h$. $\square$ However based on the answers I saw here: Can a function have more than one left inverse? , it seems that my proof may be incorrect. But which part of my proof is incorrect, I can't seem to find anything wrong with my proof.","['functions', 'proof-verification', 'proof-writing', 'elementary-set-theory', 'proof-explanation']"
2005144,What is a trivial and a non-trivial solution in terms of linear algebra?,"The homogeneous unique solution always gives a trivial solution but trivial solution consists of zeros e.g $\{0,0,0\}$ but what if the solution is still homogeneous unique solution but not in the form of zeros e.g $\{1,2,3\}$. Is this solution also trivial? How?",['linear-algebra']
2005264,Relations which are both equivalence and partial-order.,"Given a set of values suppose $ R = \{1,2,3,4\}$ we need to find the number of relations on the set which are both partial-order and equivalence relations. I constructed the set $R^2$ and its matrix representation. For the relation to equivalence and partial-order we need it to be reflexive , transitive , symmetric and anti-symmetric therefore we can only include the diagonal elements. So the number of elements in the power set of $\{(1,1),(2,2)(3,3)(4,4)\}$
has to be the number of relations? This also contains the empty relation.
Is the empty relation a part of the solution?","['equivalence-relations', 'relations', 'discrete-mathematics']"
2005272,When doesn't this algorithm for solving for multiple variables using only $3$ linear equations work?,"Say we've got the following $3$ linear equations:
$$2a+3b+5c+7d+11e=106$$
$$13a+17b+19c+23d+29e=341$$
$$31a+37b+41c+43d+47e=635$$
Now, we've got three definitions of $a$:
$$a=\dfrac{3b+5c+7d+11e-106}{2}=\dfrac{17b+19c+23d+29e-341}{13}=\dfrac{37b+41c+43d+47e-635}{31}$$
We can now combine these in $3$ different ways:
$$\dfrac{3b+5c+7d+11e-106}{2}=\dfrac{17b+19c+23d+29e-341}{13}$$
$$\dfrac{17b+19c+23d+29e-341}{13}=\dfrac{37b+41c+43d+47e-635}{31}$$
$$\dfrac{3b+5c+7d+11e-106}{2}=\dfrac{37b+41c+43d+47e-635}{31}$$
Which turns into:
$$5b+27c+45d+85e=696$$
$$46b+56c+154d+288e=2316$$
$$19b+73c+131d+247e=2016$$
And... the $a$ has disappeared. We can keep on going, until we can determine the value of $e$, after which we can work our way up. The solution will be:
$$a=1,b=2,c=3,d=4,e=5$$
In many cases this algorithm works, I've even written a Python program for it. But in some cases it doesn't. A result will come up that doesn't satisfy all equations (I've also verified a few of those by hand, so it's not the program) Questions: 1) Why do I get incorrect results? 2) Is there an easy way to see whether a system will give me incorrect results? 3) Clearly, if I only have $3$ equations, but more than $3$ variable, there is an infinite amount of solutions I miss. At what step do I 'lose' information?","['algebra-precalculus', 'systems-of-equations']"
2005297,"Find all numbers such that ""Product of all divisors=cube of number"".","While solving some old olympiad problems I came across this one. As I m stuck at it, so I m here. The problem is: Find all positive integers $N$ such that the product of all the positive divisors of N is equal to $N^3$ . Since I was not able to solve this one mathematically hence I tried Hit and trial method to find the pattern and then work upon it. I got that: 12 has divisors 1,2,3,4,6,12 product of all of which give 1728($12^3$).Similarly 18,20,28 also follow the same case. I noticed that all of them have 4 factors, but I don't think it can take me any further (I also think that a perfect power(such as $2^3$ )will not follow the case). After all of  my efforts I m on U guys. Need help. Any Mathematical formulation or suggestion is heartily welcome. Thanks.","['number-theory', 'elementary-number-theory']"
2005314,Link between the largest eigenvalue and the largest entry of a symmetric matrix,"Let $A$ be a symmetric (or Hermitian) matrix with size $n\times n$. If it helps, one can consider $A$ tridiagonal (and symmetric). By spectral theorem, there exists $\lambda_1\geq ... \geq \lambda_n$ real eigenvalues. Are there known connection (such as inequalities etc) between its largest eigenvalue $\lambda_1$ and its largest entry $\max_{i,j}|a_{i,j}|$ ?","['matrices', 'eigenvalues-eigenvectors']"
2005349,addition theorem for product of THREE Bessel functions: $\sum_n I_{n+m}(a) I_{n-m}(b) I_{p-n}(c)$,"Working on a problem of lattice Green functions (LGF) I encountered a summation shown in the title question:
$$
\sum_{n=-\infty}^\infty  I_{n+m}(a) I_{n-m}(b) I_{p-n}(c) .
$$
 It is part of wider summation: 
$$
\sum_{n=-\infty}^\infty \sum_{m=-\infty}^\infty  I_{n+m}(a) I_{n-m}(b) I_{p-n}(c) I_{q+m}(c)
$$
where all the indices n, m, p, q are integers. 
The above formula is part of still wider integrals:
$$
\int_0^\infty dt \exp(-E t)\sum_n \sum_m  I_{n+m}(a t) I_{n-m}(b t) I_{p-n}(c t) I_{q+m}(c t)
$$
or
$$
\int_0^\infty dt \exp(-E t) I_w(f t) \sum_n \sum_m   I_{n+m}(a t) I_{n-m}(b t) I_{p-n}(c t) I_{q+m}(c t)
$$
the former is LGF in 2 dimensions (2d) the latter - in 3d. Does any one know, how to simplify any of these formulas getting rid of summations? Or how (IF) it could be done? There is Neumann/Graf addition formula which does that for the product of TWO Bessel functions but has any of you seen an analogue for three? How to intersperse the third index into summation? Any simplified versions for $a=b$ or $p=0$ or $q=0$ or $p=0=q$ or with $J_n$ instead of $I_n$ would be also of use. I tried various formulas from Gradshtein-Ryzhik and Abramovitz-Stegun but to no avail. Any hint how to attack the problem?","['bessel-functions', 'calculus', 'multivariable-calculus', 'hypergeometric-function', 'special-functions']"
2005411,Clever way to find cosets,"$H = \{ (1), (12)(34), (13)(24),(14)(23)\}$ an $H$ is a subgroup of $A_4$.  I know that $H$ has 3 cosets in $A_4$ by Lagrange's Theorem, but is there a clever way to compute them without going through every element in $A_4$?","['abstract-algebra', 'group-theory']"
2005413,"Measurability from knowledge of ""slices""","Suppose $(X,\mathcal{B},\mu)$ and $(Y,\mathcal{C},\nu)$ are standard measure spaces, so $X$ and $Y$ are Polish spaces and $\mathcal{B}$ and $\mathcal{C}$ are the Borel $\sigma$-algebras. Consider the product $X\times Y$. From the Fubini-Tonelli theorem it follows that if $E\subseteq X\times Y$ is measurable, then almost all slices $E_x$ and $E^y$ are measurable (in $Y$, resp. $X$). The converse is not always true, see for instance Converse for Fubini-Tonelli's theorem . I was wondering, if you assume that all slices $E_x$ and $E^y$ are open, is that enough to imply that $E$ is measurable? I would already be happy to just see if this is true or not for say the unit interval $[0,1]$ (in fact every standard measure space with non-atomic measure is isomorphic to $[0,1]$, so that's already fairly general). Also if there are other conditions that make it true, I would certainly be interested in knowing about them. Thanks!","['functional-analysis', 'real-analysis', 'measure-theory']"
2005438,How well does probability work in the real world?,"When I was first introduced to probability at the age of about 13, me and my classmates always used to ridicule the subject in a most immature manner. We used to take a deck of well shuffled cards and 'test' the results of probability. For instance the probability of picking a spade was 25%. That is a 1 in 4 chance. We tested this by picking four cards. We got 3 hearts and a dice. We didn't get the expected 1 spade card neither did we get the expected 2 black cards. Hence we decided the science was a silly one. Looking back at those days when I'm currently majoring in math sure does make me laugh. Though I know that probability has more to it, I have not dealt with it at a theoretical level and neither do I know how to argue with children such as the ones we were once upon a time. If a child comes and claims that he tested the outcomes expected by probability and every test failed against probability's favour, I do not know how to argue with him. All I have are trust in Mathematics and the economics, sociology and quantum theory to which probability has proved to be an asset. But that is my opinion and not a proper answer. But I want to answer the child some day....how is probability justified? What is the difference between a 50-50 chance and an indeterminable probability? Well, the 50-50 chance doesn't mean that the outcomes are going to vary alternatively (head, tail, head, tail....); the outcome is more likely (head, head, tail, tail, tail, head, tail....) doesn't my that mean it's indeterminate? If probability claims that the 50-50 chance works only in ideal situations does that mean that in such a hypothetical ideal world, the toss outcome will alternate uniformly? I'm tempted to tell the child that the answer is that probability deals with idealised situations and that's why the results vary. But I shall be a criminal if the child assumes (because of me) that probability is simply a theoretical study of idealised situations that finds no use in real world situations. I cannot mislead the child and I cannot simply live on opinion and trust. What is the answer to the child's question?","['probability', 'soft-question']"
2005465,Von Bertalanffy model of tumor growth and Gompertz model - equilibria and stability,"I'm having trouble reviewing for a calc test and I'm stumbling on this particular question. If I could get a step by step or solution to study then that would be more than helpful! Studying a growth rate for a cucumber using the following the equation: a) Von Bertalanffy model of tumor growth b) $y'=\alpha (1-\frac{ln(y)}{ln(C)})y$,$y(0)=y_0$ - this is a Gompertz model 1) Find the equilibria of the equation 2) Find whether each equilibrium is stable or unstable.
And my question also is how to write this two model with parameters.","['biology', 'ordinary-differential-equations', 'mathematical-modeling', 'calculus']"
2005541,A linear map $\varphi$ such that $\varphi (GL_n(\mathbb C) )\subseteq GL_n(\mathbb C)$ preserves the rank,"Suppose that $\varphi$ is a linear map from $M_n(\mathbb C)$ into $M_n(\mathbb C)$  such that $\varphi (GL_n(\mathbb C) )\subseteq GL_n(\mathbb C)$, where $M_n(\mathbb C)$ is the vector space of $n \times n$ complex matrices and $GL_n(\mathbb C)$ the general linear group of $M_n(\mathbb C)$. How to prove that $\varphi$ preserves the rank? I.e. that for all $A \in M_n(\mathbb C)$ you have $\text{rank } \varphi(A) = \text{rank } A$. Note: I have a proof based on several questions from a French selective exam (see below), and I was looking for a more straight forward proof... if possible.","['matrices', 'matrix-rank', 'linear-algebra']"
2005632,"$L^2$ is the only Hilbert space , Parallelogram Law and particular $f(t),g(t)$","Let the space $C([0,1])$ and consider the norm $\forall p \in \mathbb{N}$ $$\forall f \in  C([0,1]),
   ||f ||_{L^P}= \left (  \int^1_0 |f(t)|^P dt \right )^{\frac{1}{p}} $$ knowing that when $p=2$ , this norm is the norm induced by the innder product $$\forall f,g \in C([0,1]), <f,g>=\int^1_0 f(t)\overline{g(t)} dx $$ The goal of this excersice is to prove that if $p \neq 2$ $||.||_p$ is not a norm induced by an inner product (i.e $L^2$ is the only hilbert space among all $L^p$ spaces. ) To do so, study when the parallelogram law holds. Hint: consider the functions $$f(t)=\frac{1}{2}-t; 
 g(t)= 
  \begin{matrix} 
     \frac{1}{2} -t & \text{ if } 0 \leq t \leq \frac{1}{2} 
     \\ t-\frac{1}{2} & \text{ if  } \frac{1}{2} <t \leq 1 \end{matrix} $$ Parallelogram Law $M=C([0,1])$ Let $(M,<.,.>)$ is an inner product space, where induced norm $$|| .|| =\sqrt{<.,.>} $$ then $$\forall x,y \in M ; || f+g||^2+||f-g ||^2= 2(||f ||^2+||g||^2) $$ Using u-sub $u=(1/2 -t)$ and $\frac{du}{dt}=-1 $ so $dt=-du$ $$ \begin{aligned} 
||f|| &= \int^1_0 (|f(t)|^p dt)^{1/p}= \int^1_0 (|1/2 -t|^p dt)^{1/p}
   \\ &=\int^{u(1)}_{u(0)} (u^p -du)^{1/p}
        \\& =(\int^{-1/2}_{1/2} u^p du)^{1/p}
         \\ &= \left [ \left (\frac{u^{p+1}}{p+1}  \right )^{1/p} \right]^{-1/2}_{1/2}
        \\&= \left [\frac{u^{1+1/p}}{(p+1)^{1/p}} \right]^{-1/2}_{1/2}
        \\&=\frac{(-1/2)^{1+1/p} -(1/2)^{1+1/p}}{(p+1)^{1/p}}
\end{aligned}$$ working on $||f-g ||,||f+g||,||g||$ Guessing big picture that the parallelogram law only works when $p=2$ so it is only induced norm when $p=2$","['functional-analysis', 'real-analysis']"
2005636,Combinatorics Password Selection,"The Problem We want to know the amount of 8 digit passwords we can make using digits, uppercase, lowercase, and special characters. For this problem there are only 16 special characters. The rules are that the passwords must contain at least 1 uppercase, 1 digit, and 1 special character. My Approach After drawing a diagram Venn Diagram of 4 sets and assigning Uppercase to 'A', Digits to 'B', Special Characters to 'C', and Lowercase to 'D' I noticed that the total number we are interested in are the intersects of: |A $\cap$ B $\cap$ C $\cap$ D| + |A $\cap$ B $\cap$ C|. Based on the inclusion/exclusion principle the total number of combinations for 4 sets are:
          $|A∪B∪C∪D|=$ $|A|+|B|+|C|+|D|$ all singletons $-(|A∩B|+|A∩C|+|A∩D|+|B∩C|+|B∩D|+|C∩D|)$ all pairs $+(|A∩B∩C|+|A∩B∩D|+|A∩C∩D|+|B∩C∩D|)$ all triples $-|A∩B∩C∩D|$ all quadruples. $(26+10+16+26)^8$(singles) $-[42^8+36^8+52^8+26^8+42^8+36^8]$(pairs) $+[52^8+68^8+62^8+52^8]$(tripled pairs) $-[26^8+16^8+10^8+26^8]$(quadrupled pairs) =20734390444484096 . This is where I began getting confuzzled. My intuition tells me to start subtracting amounts that we don't need from the total, which is everything but |A $\cap$ B $\cap$ C $\cap$ D| + |A $\cap$ B $\cap$ C| which feels the same as just substituting values $(26^8+16^8+10^8+26^8) + (52^8) =$ 53881777627904 . Is this the correct answer?
Is there a better way of going about this problem?","['combinatorics', 'discrete-mathematics']"
2005653,"One problem in theorem $2$ from ""Some further results in Ideal Convergence in Topological Spaces"" by P. Das","It is Theorem $2$ in this paper by P.Das . I will quote the entire proof here to help discussion by not having to go to the paper repeatedly.: Theorem $2$ . Let $X$ be a first countable space. For any sequence $(x_n)_{n∈N}$ in $X$ the set $I(L_x)$ is an $F_σ$-set provided $I$ is an analytic  $P$-ideal. Proof :  Since $I$ is an analytic $P$-ideal, there exists a lower semicontinuous submeasure $ϕ$ satisfying (∗). For any $r ∈ \mathbb N$ let
  $$F_r =\left\{p ∈ X: ∃A = \{n_1 < n_2 < n_3 < ···\} ⊂ \mathbb N, \lim_k x_{n_k}=p \text{ and} \lim_{n→∞} ϕ(A\backslash[1,n])\ge {1\over r}\right\}$$ We shall now show that each $F_r$ is a closed subset of $X$. Let $α ∈ \bar F_r$ and let $U$ be a neighborhood of $α$. Since $X$ is first countable, there is a sequence $(α_j)_{j∈\mathbb N}$ in $F_r$ converging to $α$. For each $α_j$, we can find $A_j ⊂ \mathbb N$ with ${\lim_{n→∞}}_{n∈ {A_j}} x_n=α_j$
  and $\lim_{n→∞}ϕ(A_j\backslash [1,n])\ge {1\over r}$. Let $(\epsilon_j)_{j∈\mathbb N}$ be a monotonically decreasing sequence of positive real numbers converging to $0$.
  We now proceed as follows: 
    First choose $n_1 ∈ \mathbb N$ such that $ϕ(A_1\backslash [1,n_1])\ge {1\over r}−{{\epsilon_1}\over 2}$. Now lower semicontinuity of $ϕ$ implies
  that $ϕ(A_1\backslash [1,n_1]) = \lim_{n→∞} ϕ[(A_1\backslash [1,n_1]) ∩ [1,n]]$. Choose $m ∈ \mathbb N$ such that $ϕ[(A_1\backslash [1,n_1]) ∩ [1,n]]\ge ϕ(A_1\backslash [1,n_1]) −{\epsilon_1\over 2}∀n\ge m$. Again there exists $m_1 ∈ \mathbb N$ such that $ϕ(A_2\backslash [1,n]) \ge {1\over r} −{\epsilon_2 \over 2}
∀n\ge m_1$. Now choose $n_2 > n_1,m,m_1$. Then clearly
  we have simultaneously $ϕ(A_1 ∩ (n_1,n_2])\ge {1\over r}−\epsilon_1$ and also $ϕ(A_2\backslash [1,n_2])\ge {1\over r}−{\epsilon_2\over 2}$.  Proceeding as above we now choose
  $n_3 > n_2$ such that $ϕ(A_2 ∩ (n_2,n_3])\ge {1\over r}−\epsilon_2$ and $ϕ(A_3\backslash [1,n_3])\ge {1\over r}-{\epsilon_3 \over 2}$ and so on. Thus we can construct a sequence
  $n_1 < n_2 < n_3 < ···$ of positive integers such that
  $$ϕ(A_j∩(n_j,n_{j+1}])\ge {1\over r}−\epsilon_j, j ∈ \mathbb N.$$
  Let us define $$A=\bigcup_j\{A_j∩(n_j,n_{j+1}]\}$$. Then clearly ${\lim_{n→∞} ϕ(A\backslash [1,n])\ge {1\over r}}$ and so ${A \not∈ I}$. Let $A=\{l_1<l_2<l_3< ···\}$. Since
  $\lim_j α_j = α$ and $α ∈ U$ so $α_j ∈ U ∀ j\ge j_0$ for some $j_0∈\mathbb N$. $\color{blue}{\text{ This implies that }x_n∈U\text{ for all but a finite number of indices }n\text{ of the set }A}$. Therefore $α∈F_r$. Hence $F_r$ is a closed subset of $X$. The assertion now immediately follows from the fact that $I(L_x)=\bigcup _{r=1}^∞Fr$. I have difficulty understanding the $\color{blue}{blue}$ part. Since $\alpha\in U$ is the limit of the sequence $\alpha_j$ so from above we have $\alpha_s\in U$ for some $s>j_0.$ Now,$\lim_{n\rightarrow \infty;n\in A_s}x_n=\alpha_s.$ So again there is a $p\in \mathbb N$ such that $x_n\in U\forall n\ge p.$ Let $p=l_t\in A$ and $x_p\in U.$ Now how can I show that $x_{l_{t+1}}\in U$ too? Is not that $x_n$ necessary to show thatall but finite indices go inside $U$? or how else? Please advice. Thank you. EDIT: This question is cross posted in both MSE and MathOverFlow.This one has an answer that I accepted although the one in OverFlow doesn't have any answers or comments. the link to the same question in MathOverFlow .","['general-topology', 'convergence-divergence', 'proof-explanation']"
2005675,What is $E(X^2)$ mean in literal terms?,"In my probability and statistics class we learned about expected value, or $E(X)$. We also did some work about finding expected values of functions and such, like $E(g(x))$. And in the case of finding the variance, one of the steps involve finding $E(X^2)$. Does this mean anything in real-life terms? Using a geometric distribution as an example, is $E(X^2)$ the expected number of times a trial needs to happen until the event $X$ happens twice in a row?","['means', 'expectation', 'probability']"
2005680,What is the inverse of the covariance matrix generated by the exponential covariance function?,"I'm trying to analytically find the inverse of the covariance matrix generated by the exponential covariance function (also known as Ornstein-Uhlenbeck kernel) in $\mathbb{R}$, that is $K_{ij} = k(x_i, x_j) = \exp(-\frac{|x_i - x_j|}{\theta})$ Where $x_i \in \mathbb{R}$ and that $K$ is an $n\times n$ matrix. Here is what I've thought about doing: Since $K$ is a covariance matrix, I know it is positive semidefinite and so is $K^{-1}$. We can do a singular value decomposition on $K = UDU^*$ and $K^{-1} = VCV^*$ where $U, V$ are unitary matrices and $D, C$ are diagonal matrices.
But that I haven't been able to develop the idea further. What would be right approach to get an analytical expression for $K^{-1}$?","['machine-learning', 'covariance', 'linear-algebra']"
2005683,Showing that the zeros of a sequence of functions converge in probability as the functions converge in probability,"Let $S_n$ be a sequence of random real-valued continuous functions defined on $\Theta\subset \mathbb{R}$, such that as $n\rightarrow\infty$, $S_n(\theta)\overset{p}\rightarrow S(\theta)$ for every $\theta\in\Theta$, where $S$ is non-random. Suppose that for some $\theta_0$ in the interior of $\Theta$ and every $\epsilon>0$ small enough we have $$S(\theta_0 - \epsilon)<0<S(\theta_0 + \epsilon)$$ and that $S_n$ has exactly one zero $\hat{\theta}_n$ for every $n\in\mathbb{N}$. Deduce that $\hat{\theta}_n\overset{p}\rightarrow \theta_0$ as $n\rightarrow\infty$. I have literally no idea where to start with this - I know the definition of convergence in probability, but I don't know what trick to employ to convert knowledge knowledge about the range of $S$ to knowledge about its domain.","['real-analysis', 'convergence-divergence', 'statistics']"
2005685,Find the exponential value of a number.,"I'm wondering if there is a way to add two numbers with the same base but different exponents without converting the base of the numbers. For example lets say your adding 2^2 and 2^4 the value of 2^2 is 4 and the value of 2^4 is 16 so the total of the two numbers is 20. The closest I could get my calculator to finding a base of 2 with a value of 20 was 2^4.3219281 which equaled 20.000000071. So I have a few questions. Can 2 be raised to a power that's exactly equal to 20? I know that with division and multiplication you can just add or subtract the exponents. Are there any similar tricks for adding or subtracting values with exponents? Is there anyway to arrive at the result, or a similar result of 2^4.3219281 without changing the base in the process?","['algebra-precalculus', 'arithmetic']"
2005708,"Let $M$ be a free $R$-module, and let it have an infinite basis. Then all bases of $M$ have the same cardinality","I need to prove the following: Let $R$ be an arbitrary ring (according to Lang, Bourbaki etc., so, with $1$). Let $M$ be a free $R$-module, and let $A$ be one of it's bases. If $|\mathbb{N}| \leq |A|$, then all bases of $M$ have the same cardinality. Any ideas on how to prove it? 
Obviously, every element of $A$ is a unique finite sum of elements of $B$, and vice versa.","['abstract-algebra', 'modules', 'free-modules']"
2005748,Product of $L^2$ functions,"If $ \Omega$ is any open subset of $\mathbb{R}^n$, is it true that the product of two $L^2$ functions over $\Omega$ is also $L^2$ ? What about $L^p $ ?",['functional-analysis']
2005755,Martingale and composition of function,"Let $(Z_i)_{i\in \mathbb{N}}$ be a sequence of independent and bounded r.v. with $\mathbb{E}(Z_i)=m_i$ and $\operatorname{Var}(Z_i)=\sigma_i$. Let $\mathcal{F}_n=\sigma({Z_1,\dots,Z_n})$. Find a $(b_n)$ such that for a $t\in\mathbb{R}$
  $$b_n\exp\left(\sum\limits_{i=1}^ntZ_i\right)$$
  becomes a martingale. I get stucked in this exercise because of the exponential function. What shall I do:
$$b_{n+1}\exp\left(\sum\limits_{i=1}^ntZ_i\right)\mathbb{E}\left(\exp\left(tZ_{n+1}\right)\mid\mathcal{F}_{n}\right)$$
I can't compute $$\mathbb{E}\left(\exp\left(tZ_{n+1}\right)\mid\mathcal{F}_{n}\right)=\mathbb{E}\left(\exp\left(tZ_{n+1}\right)\right)$$
Because it's a composition and I only know the expectation of $Z_i$, not of the composition. Do I have to make somehow a substitution?","['stochastic-processes', 'probability-theory', 'martingales']"
2005758,Why is the Skyscraper Sheaf defined as it is?,"In Vakil's Foundations of Algebraic Geometry he defines the skyscraper sheaf as follows. Let $X$ be a topological space with $p\in X$.  Let $S$ be a set and $\{e\}$ any singleton set.  Let $i_p:p\to X$ be the inclusion then define:
$$
i_{p,_{*}S}(U) =
\begin{cases}
S,& p\in U\\
\{e\},& p\not\in U
\end{cases}
$$ My question is, is there any reason why we use a single-element set $\{e\}$?
As far as I can tell, we still get a sheaf if we use an arbitrary set  in place of $\{e\}$.  Why don't we use, say, the empty set instead?","['abstract-algebra', 'sheaf-theory']"
2005775,Average minimum distance between $n$ points generate i.i.d. uniformly in the ball,"Let $U \in \mathbb{R}^3$ be distributed uniformly in the Ball in $\mathbb{R}^3$ centered at zero.   That is $U \sim  f_U(u)= \frac{1}{ \frac{4}{3} \pi R^3}$  for all $\|u\|\le R$  where $R$ is the radius of the ball. Now suppose we generate $n$ points i.i.d. according distribution of   $U$. My questions is: Can we compute the expected minimum distance between the generated points,
that is
\begin{align}
E\left[ \min_{i,j\in \{1,2,,,n\}} \| U_i-U_j\| \right],
\end{align} 
where  $\| U_i-U_j\|$ is Euclidean distance. This question is related to a number of other questions. 
For example, Average distance between two random points in a square Average minimum distance between $n$ points generate i.i.d. with uniform dist. I feel that this question should have been addressed before but not sure where to look. There is a conjecture that the minimum distance behaves as $\frac{1}{n^{\frac{2}{3}}}$ but I am not sure how to show this? Update See a recently add proof of this statement for the case when 'border' effects are negligible. That is the answer is asymptotic.  The question know is how to take into account the border effects? Thank you very much.","['probability-theory', 'probability', 'expectation', 'geometry']"
2005800,Second derivative test inconclusive,"I have the function $f(x,y) = x^2y(4-x-y)$ and $T = \{(x,y) | x\ge 0, y \ge 0, x+y \le 6\}$. With the second derivative test I have found that $(2, 1)$ is a relative maximum. By calculating the first derivatives you will see that $x=0$ and $y \in [0, 6]$ are critical points (correct me if I am wrong). So by using those numbers, the second derivative test is inconclusive. My questions are: What can I do if the second derivative test is inconclusive? Does this function have a relative minimum?","['multivariable-calculus', 'ordinary-differential-equations']"
2005830,Hermite Polynomials (different forms of writing them),"I was seeing this question in which 2 definitions of the Hermite polynomials are given: $$H_n(x) = (-1)^ne^{x^2}\frac{d^n}{dx^n}e^{-x^2}$$ and
$$
H_n(x) = \left( 2x - \frac{d}{dx} \right)^n(1)
$$ Now, I found another definition: $$
H_n(x) = e^{x^2/2}\left(x-\frac{d}{dx}\right)^n e^{-x^2/2}
$$ There is plenty of literature on the first two definitions, but I have found none on the third one. I would like to know if there is a way of deducing the first or second definitions from the third one. I tried expanding in a binomial expansion but got nowhere. I appreciate your help. Or is there any way of showing that the last expression matches the coefficients of the generating function expansion?","['polynomials', 'ordinary-differential-equations', 'hermite-polynomials']"
2005832,"Finding $\lim \limits_{(x, y)\rightarrow (1, -1)}\frac{(x-y)^2-4}{x^2+y^2-2}$","I want to calculate $\lim\limits_{(x, y)\rightarrow (1, -1)}\dfrac{(x-y)^2-4}{x^2+y^2-2}$. I already know that $\lim \limits_{x\rightarrow 1}\lim\limits_{y\rightarrow -1}\dfrac{(x-y)^2-4}{x^2+y^2-2} = \lim\limits_{y\rightarrow -1}\lim\limits_{x\rightarrow 1}\dfrac{(x-y)^2-4}{x^2+y^2-2} = 2$, so if the limit exists, it equals $2$. But how do I prove that? I can't use polar coordinates since $(x, y) \not\to (0,0)$, I've also failed to find a counterexample of a sequence with different limit than $2$.","['multivariable-calculus', 'real-analysis', 'calculus', 'limits']"
2005872,Deriving Taylor series without applying Taylor's theorem.,"First, a neat little 'proof' of the Taylor series of $e^x$. Start by proving with L'Hospital's rule or similar that $$e^x=\lim_{n\to\infty}\left(1+\frac xn\right)^n$$ and then binomial expand into $$e^x=\lim_{n\to\infty}1+x+\frac{n-1}n\frac{x^2}2+\dots+\frac{(n-1)(n-2)(n-3)\dots(n-k+1))}{n^{k-1}}\frac{x^k}{k!}+\dots$$ Evaluating the limit, we are left with $$e^x=1+x+\frac{x^2}2+\dots+\frac{x^k}{k!}+\dots$$ which is our well known Taylor series of $e^x$. As dxiv mentions, we can exploit the geometric series: $$\frac1{1-x}=1+x+x^2+\dots$$ $$\ln(1+x)=x-\frac12x^2+\frac13x^3-\dots$$ $$\arctan(x)=x-\frac13x^3+\frac15x^5-\dots$$ which are found by integrating the geometric series and variants of it. I was wondering if other known Taylor series can be created without applying Taylor's theorem.  Specifically, can we derive the expansions of $\sin$ or $\cos$?","['real-analysis', 'taylor-expansion', 'calculus', 'recreational-mathematics']"
2005893,Nonsingular + Homogeneous polynomial implies Irreducible,"Let $f \in \mathbb{C}[x,y,z]$ be a non-singular homogeneous polynomial. Then $f$ is irreducible. This is a passage in Miranda ""Algebraic Curves and Riemann Surfaces"" book. He claims that it is a basic theorem, but I couldn't prove it. Any help? Thanks!","['irreducible-polynomials', 'polynomials', 'algebraic-geometry']"
2005930,Why is a transversal intersection of submanifolds a manifold?,"Let $N, M \subseteq R^n$be transversal submonifolds of $R^n$ We say that $N$ and $M$ are transversal if $T_pN + T_pM =T_pR^n$ for all $p \in N\cap M$. Why is $N \cap M$ a manifold?","['general-topology', 'smooth-manifolds', 'differential-geometry', 'transversality']"
2005956,Reference request: Existence of a Borel probability measure on a metric space with no support.,"I am looking for a reference for the existence of a Borel probability measure on a metric space with no support? I have seen examples of Borel probability measures with no support but they contain concepts way beyond my comprehension. Specifically i have found the two constructions: Example 7.1.3. in Bogachev's Measure theory Vol. 2 and Example 12.15 in Aliprantis & Border's Infinite Dimensional Analysis, where they construct probability measures with no support. My prerequisites are insufficient to understand these examples, so I have no idea if the topological spaces considered are metrizable. I have also read this MO question and the answer of Joel David Hamkins seems to be what I am looking for, but I don't feel comfortable referencing a MO answer.","['reference-request', 'general-topology', 'measure-theory']"
2005966,Reference Request: ADE Resolution and McKay Correspondence,"I was wondering if there's sort of a canonical introduction to the McKay Correspondence in relation to this ADE singularity story?  I've seen some incomprehensible physics sources, but I was hoping for something very geometric, perhaps also with physics component from a purely mathematical perspective.  Thanks!","['reference-request', 'group-theory', 'algebraic-geometry']"
2005979,Proving that Cauchy condensation test is true for $a_n$ any monotone sequence.,"I'm trying to show that then $\Sigma a_n$ converges iff $\Sigma 2^n a_{2^n}$ converges if $a_n$ is any monotone sequence. I am assuming I have to prove the cases: $a_n$ is positive and increasing $a_n$ is negative and increasing $a_n$ is positive and decreasing $a_n$ is negative and decreasing Here is what I have worked out from some of the comments below: Assume $a_n$ is an increasing sequence. If $a_n$ is positive, then $\lim a_n \neq 0$ and we have divergence. I don't really understand why this is. Is it because $a_n$ is unbounded and so it diverges to $\infty$? I don't know a rigorous way to prove this. I'm assuming I have to make use of the theorem that monotonic $s_n$ converges iff it is bounded. If $a_n$ is negative, then we have that $\lim a_n = 0$ Again, I don't know how to rigorously prove this. How do I find a bound for $a_n$? Let $s_n = a_1 + a_2 + ... + a_n$ and $t_n = a_1 + 2 a_2 + ... + 2^k a_{2^k}$.
  For $n<2^k$, we have $s_n \geq a_1 + (a_2 + a_3) + ... _ (a_{2^k}+...+a_{2^{k+1}-1}
\geq a_1 + a_2 + ... + 2^{k}a_{2k} = t_k
$ And so $s_n \geq t_k$. Similar proof for $2s_{n} \leq t_k$ Someone below has already proved nonnegative decreasing case. I'm assuming that: If $a_n$ was decreasing and negative, then $\lim a_n \neq 0$ and we have divergence. Again, I'm not sure how to prove this.","['real-analysis', 'limits', 'sequences-and-series', 'proof-verification', 'convergence-divergence']"
2005999,"Prove that if P(x) is a quartic polynomial, then there can only be at most one line that is tangent to it at two points.","Prove that if P(x) is a quartic polynomial, then there can only be at most one line that is tangent to it at two points. From what I have seen, the only case in which I have found a tangent line at 2 points is when the tangent line is horizontal. Is there any other way to approach it?","['derivatives', 'calculus']"
2006012,3 person bet based on the perceived likelihoods of an outcome,"Suppose 3 friends want to bet \$100 on whether candidate John Doe will win the next election. They state their perceived likelihood that the event will occur: Alice believes John Doe will win with probability $35\%$ Bob believes John Doe will win with probability $50\%$ Charlie believes John Doe will win with probability $40\%$ How would you go about setting up this bet? In other words, what amount should each friend put down (all three amounts totalling \$100) and what should the payoffs be if John Doe is elected, and what should the payoffs be if John Doe loses? (Asking for a friend)","['probability', 'gambling']"
2006015,Divide a googolplex into two numbers with no prime factor under 100,"Very likely, a googolplex won't be Goldbached into 2 provably prime numbers in my lifetime.  But it seems possible to do a split that can avoid small primes.  The first 24 odd primes have a product of $k=1152783981972759212376551073665878035$, and it's easy to calculate that a googolplex mod $k$ is $x =929084311939231970567712621104570410$, which is prime when 509 is subtracted. I'm not sure what the next steps would be. Can you divide a googolplex into two odd numbers where neither is divisible by any odd prime 97 or under?  If so, how high up can you push that before it starts being computationally challenging?","['number-theory', 'recreational-mathematics', 'prime-numbers']"
2006031,Prove that $a^2 + 1$ cannot have prime factor of the form $4k + 3$,"What I have done: (not sure if it's right) $a^2 + 1\equiv 1\pmod 4$ or $2\pmod 4$ But if it has two prime factors in the form $4k + 3$, it will be $1\pmod4$, and I don't know where to go from here","['number-theory', 'discrete-mathematics', 'elementary-number-theory']"
2006066,What is the broadest definition of conditional probability?,"The usual definition of conditional probability on a probability space $(\Omega, \sigma, P)$ is~:
$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$
which obviously implies that $B$ must not be a negligible set. However this definition appears too restrictive as we sometimes need to compute probabilities conditioned by negligible sets (a usual case is for example an event of the form $B = \{X = x\}$ where $X$ is a continuous random variable and $x$ a real number). Informally speaking we would like to define~:
$$P(A|B) = \underset{P(B') > 0}{\lim_{B'\rightarrow B}} \frac{P(A \cap B')}{P(B')}$$
Now the meaning of the limit should be made precise. I'm neither aware of a topology defined on $\sigma$ itself nor convinced it is the way to go. It might also be possible to work with sequences of decreasing events which in some sense ""convergence"" toward $B$:
$$B_1 \supset B_2 \supset \cdots \supset B$$
such that:
$$\forall x \in \Omega \setminus B, \exists n \in \mathbb N,  x \not\in B_n$$
But I'd like to know if some formal definition already exist.","['probability', 'measure-theory']"
2006117,An Interesting Two Players' Game Involving Cumulative Sum of Uniform Distribution,"$A$ and $B$ are two players, each have exactly one turn. $A$ goes first. $A$ keeps on choosing a random number uniformly distributed over $(0,1)$ and add the values. If at one point it exceeds $1$, $A$ loses. If $A$ thinks his cumulative sum is very close to $1$, hence there is a risk of losing, he stops. Then $B$ starts the same process and add the values separately. If at one point $B$ exceeds $A$'s sum and still below $1$, he wins. What is the optimal strategy for $A$ to stop adding and what is the probability of winning in that case ($B$ knows the value $A$ stopped at)? From simulation It appears that the optimal threshold of $A$'s cumulative sum is approximately $0.5772$, which is very close to the Euler-Mascheroni constant $\gamma$.","['uniform-distribution', 'probability']"
2006191,Product of $\limsup_{x\to\infty} x_n $,"Given $x_n > 0$ and
$$\limsup_{n\to\infty} x_n \cdot \limsup_{n\to\infty} \frac{1}{x_n} = 1$$
Does this mean that $x_n$ converges?","['limsup-and-liminf', 'sequences-and-series', 'convergence-divergence', 'limits']"
2006215,Whispering wall function,"After visiting the Whispering wall where a whisper can be clearly transmitted between two locations on the surface of a dam wall over more than 100 metres, I was puzzled as to how this occurs. I decided to try to solve the following problem: What must be the shape of a curved wall such that any sound emitted towards the wall from one corner will be reflected directly to the opposite corner as in the following diagram (co-ordinates are $x$ and $y$)? From this I derived the following differential equation (derivation below) but myriad substitutions and changes of variable have still left me puzzled as how to put it into a form which can be solved: $$(y’)^2++y’\left(\frac{a^2+y^2-x^2}{ay}\right)+\frac{x}{a}=0$$ for $-a<x<0$ with $y(\pm a)=0$ and $y’(0)=0$, but I’m not sure that this is right. Can solve this equation or else find a mistake in it and find the correct equation to solve my geometrical problem? Derivation (note that from the answers it would appear that this is slightly incorrect) : Taking the following horrible paint diagram where $D$ is the point at which the sound wave is reflected and $AB$ is the tangent to the curve at that point, where we must have that the angles $BDC$ and $ADF$ marked $\theta$ are equal since a specular reflection is assumed to occur: (Note that this is for negative $x$ only so $-x>0$; the vertical line is through the maximum of the curve). I then take the triangle $DBC$ and divide the lengths of the sides by $a-x$ to find that (using the relation between the tangent and the derivative): $$\theta=\arctan{y’}+\arctan{\frac{y}{a-x}}$$ I then take the triangle $ADE$ and divide the lengths by $y$ to obtain: $$\theta=\arctan{\frac{1}{y'}}-\arctan{\frac{a+x}{y}}$$ Setting these equal and taking $\tan$ of both sides and using the law for the tangent of a sum of angles to obtain two fractions which I cross-multiply and then collecting terms I get the differential equation shown above. (Note that interesting facts about similar walls which might better explain the Whispering wall I originally mentioned can be found here , here and here , but I am now specifically looking for a solution to my problem. Also not that the Wikipedia page in my very first link mentioned a ‘parabolic effect’, but I could not see how that would be relevant to my problem)","['ordinary-differential-equations', 'calculus', 'geometry']"
2006235,"If $|f(z)| < \sqrt{\left| z\right|}$, then $\lim_{z\to\infty} f(z)$ exists?","Let $f(z)$ be a holomorphic function defined on $D=\{ z\in\mathbb{C} | \left| z \right| > 1\}$. For all $z\in D$, we have $\left| f(z) \right| \le \sqrt{\left| z \right|}$. Show that $\lim_{z\to\infty} f(z)$ exists. How should I show this? I was thinking could I show that $f(z)$ is actually constant, but that doesn't seem to be the case. I think I can find $f(z)$ that is not constant but has limit at infinity. What is the right ""picture"" to think about here? Hint is greatly appreciated. Update : So I considered $g(z) = f(\frac{1}{z})$. Take $C_R$ be circle of radius $R$. Then I got something like $$\int_{C_R} \left| g(z) \right| dz=\int_{C_R} \left| f(\frac{1}{z})\right| dz\le \int_{C_R} \frac{1}{\sqrt{R}} dz = 2\pi \sqrt{R}$$ Then by Residue Theorem, $$2\pi i \text{Res}_{z= 0} g(z) = 2\pi \sqrt{R}$$ Since this is true for all $R$, $\text{Res}_{z=0} f(z) = 0$ Update 2 : I actually considered $\lim_{z\to 0} zg(z)$. Since
$$ \left| z f\left(\frac{1}{z}\right)\right|<\left| \frac{z}{\sqrt{\left| z\right|}}\right| \to 0 \text{ as } z \to 0$$ $g(z)$ should have a removable singularity at $z=0$. So $f(z)$ should have a removable singularity at infinity?",['complex-analysis']
2006239,Number of roots of $z^6-5z^2+8z+2$ in closed unit disk,"This problem, of course, screams Rouche's Theorem. Unfortunately, the coefficients were chosen in such a way that getting the strict inequality necessary for application of the theorem is not easy. Since we have a disk of radius less than or equal to 1, I know the general thing to do is to compare the polynomial with term with highest coefficient. So we'd look at $f(z) = z^6-5z^2+8z+2$ and $g(z) = 8z$. (Indeed, wolframalpha tells us there is 1 root in the unit disk so this seems like the right way to go about it). 
Then for all $|z|=1$, $$ |f(z)-g(z)| \le 1+5+2 = 8 = |g(z)|,$$
which is not enough. I've also considered looking at disks of radius $1-\epsilon$, but that doesn't seem to work either. Any suggestions? (Hopefully I'm not missing something super obvious)",['complex-analysis']
2006243,Minimum of $\sin \alpha+\sin \beta+\sin \gamma$ with $\alpha+\beta+\gamma = \pi$,"The bounty expires in 5 days . Answers to this question are eligible for a +50 reputation bounty. Darshit Sharma wants to draw more attention to this question: Is there a way using the Jensen's inequality? I can prove that this summation <= 3 root 3/2 using the inequality. But I can't make it to >= -3 root 3/2. For the upper bound what I did was consider the three angles as angles of a triangle and used the function as sin x from 0 to pi( Concave down) for the Jensen's Inequality. Find the minimum of $\sin \alpha+\sin \beta+\sin \gamma,$ where $\alpha,\beta,\gamma\in \mathbb{R}$ satisfying $\alpha+\beta+\gamma = \pi$ . Options: (a) $2$ ; (b) $-2$ ; (c) $0$ ; (d) $-3$ . My try: Putting $\alpha = -\dfrac{\pi}{2}$ , $\beta = -\dfrac{\pi}{2}$ , $\gamma = 2\pi$ , then we get $\sin\alpha+\sin \beta+\sin \gamma = -2$ . Added: Trying using analytical way: Given $\alpha+\beta+\gamma = \pi$ , \begin{align*}
\sin \alpha+\sin \beta+\sin \gamma &= 2\sin \left(\frac{\alpha+\beta}{2}\right)\cos \left(\frac{\alpha-\beta}{2}\right)+2\sin \frac{\gamma}{2}\cdot \cos \frac{\gamma}{2}\\
&= 2\cos \frac{\gamma}{2}\left[\cos \left(\frac{\alpha-\beta}{2}\right)+\cos \left(\frac{\alpha+\beta}{2}\right)\right] = 4\cos \frac{\alpha}{2}\cos \frac{\beta}{2}\cos \frac{\gamma}{2}
\end{align*} Now using $-1 \leq \cos \dfrac{\alpha}{2}, \cos \dfrac{\beta}{2}, \cos \dfrac{\gamma}{2}\leq 1$ , we get $$\sin \alpha+\sin \beta+\sin \gamma = 4\cos \frac{\alpha}{2}\cos \frac{\beta}{2}\cos \frac{\gamma}{2}\geq -4.$$ But this is not possible because $\cos \dfrac{\alpha}{2}, \cos \dfrac{\beta}{2}, \cos \dfrac{\gamma}{2}\neq -1$ simultaneously. I did not understand how can I solve it. Help me, thanks.","['algebra-precalculus', 'inequality', 'trigonometry']"
2006269,Clarification on the Wronskian,"I am getting a few ""contradicting"" conclusions from the Wronskian and I just wanted to clarify, but assume $y_1, y_2$ are two solutions to a second order differential equation that is homogeneous. According to my textbook: If the Wronskian, $W\neq 0$ at some point $t_0$ on the interval $I$ , then $y_1, y_2$ are linearly independent and form the fundamental set of solutions But the solution to the question ""Show that if $y_1, y_2$ are solutions for some second order differential equation, but they have a maxima/minima at the same point in $I$ , then they cannot form the fundamental set of solutions"" seems to contradict this. Their explanation is that: Pick $t_0$ , then the $W(y_1, y_2)(t_0) = 0$ at $t_0$ , so they cannot be linearly independent, so they don't form the set of fundamental solutions But this doesn't prove that $W=0$ across the entire interval $I$ , so I'm confused. Could someone please enlighten me?","['wronskian', 'ordinary-differential-equations']"
2006273,Help with Apostol's Calculus regarding method of exhaustion.,In page 5 Apostol explains to us in modern terms Archimedes's method of exhaustion applied to a parabola. He uses a method of 'approximating from below' and ' approximating from above'using rectangles. I thought I understood what they meant but I got confused when he says that the the area of the outer rectangles $S(outer) = b^3/n^3(1^2 + 2^2 + 3^2+....+n^2)$ while S(inner) = $ b^3/n^3(1^2 + 2^2 +...+ (n - 1)^2)$. Now why is it that the outer rectangles add up to $n^2$ while the inner rectangles stop 1 n less? So it would be very nice if someone can explain to me the meaning of approximating from above and below and how to acquire the area of each separately.,"['algebra-precalculus', 'integration', 'calculus', 'area']"
2006294,binomial congruence $\sum_{i=1}^{\frac{p-1}{2}}\binom{2i}{i}\equiv 0~or (-2)\pmod p$,"Let $p\ge 5$ be a prime number. Show that $$\sum_{i=1}^{\frac{p-1}{2}}\binom{2i}{i}\equiv 0 \text{ or } -2\pmod p .$$ Examples: If $p=5$, then
$$f=\sum_{i=1}^{\frac{p-1}{2}}\binom{2i}{i}=\binom{2}{1}+\binom{4}{2}=8\equiv -2\pmod 5 .$$ If $p=7$, then
$$f=\sum_{i=1}^{\frac{p-1}{2}}\binom{2i}{i}=\binom{2}{1}+\binom{4}{2}+\binom{6}{3}=28\equiv 0\pmod 7 .$$ If $p=11$, then
$$f=\sum_{i=1}^{\frac{p-1}{2}}\binom{2i}{i}=\binom{2}{1}+\binom{4}{2}+\binom{6}{3}+\binom{8}{4}+\binom{10}{5}=350\equiv -2 \pmod{11} .$$","['number-theory', 'binomial-coefficients']"
2006327,What goes wrong in the theory of algebraic groups in characteristic $p$?,"I wonder about the basic facts in the theory of algebraic groups and Lie algebras that are wrong in characteristic $p$. For example, The trace of $1$, that is the dimension of a representation, may be zero, therefore there is no Cartan criterions . The derivative of non-constant polynomial may be zero, therefore there are non-smooth algebraic group schemes . There is no exponential map. Of course, even in characteristic $0$, there is an exponential map only for unipotent algebraic groups, and it is boring, but there is one for both usual and $p$-adic Lie groups (see Schneider, p-Adic Lie Groups , p. 153). What are the other basic problems? For example, what is a fundamental reason why $\operatorname{GL}(\mathbb F_p)$ is not linearly reductive , that is there is no direct complements in finite-dimensional representations?","['algebraic-geometry', 'positive-characteristic', 'soft-question', 'algebraic-groups', 'lie-groups']"
2006355,Katz-Mazur chapter 1 AG questions,"I was reading through Katz-Mazur ""Arithmetic Moduli of Elliptic Curves"", Chapter 1, and ran into some small issues (which might have a lot to do actually with notation). I think most of them are due to not being comfortable enough with the algebraic geometry notions involved. I managed to read on ignoring them but they are still bugging me. I apologize if the questions seems somewhat contentless . Here is a link to the book. Below are my questions. $C/S$ is a smooth curve over $S$ and $D$ is an effective Cartier divisor. (1) Does $\mathcal O_D$ mean the structure sheaf of $D$ as a scheme, or is it $\mathcal O_C/I(D)$ as a sheaf on $\mathcal O_C$ ? I know they are roughly the same, but I am not comfortable enough in my algebraic geometry yet to treat them as the same (if I am wrong, please point out). In the latter case, (1') would the structure sheaf of $D$ be $i^*(\mathcal O_D)$ , where $i$ is the inclusion $D\hookrightarrow X$ , is that correct? (1'') Otherwise, if $\mathcal O_D$ meant the structure sheaf on $D$ , would $\mathscr L\otimes_{\mathcal O_C}\mathcal O_D$ mean then $\mathscr L\otimes_{\mathcal O_C}i_*(\mathcal O_D)$ ? (2) On page 9, we have $\mathscr L/\mathcal O\cong I^{-1}(D)/\mathcal O\cong I^{-1}(D)\otimes_{\mathcal O_C}\mathcal O_D\cong\mathscr L\otimes_{\mathcal O_C}\mathcal O_D=$ an invertible $\mathcal O_D$ -Module. Therefore $D$ is proper over $S$ if and only if the sheaf $\mathscr L/\mathcal O$ has its support proper over $S$ . Why is this so? (3) Here $X$ is any scheme over $S$ and $D,D'$ effective Cartier divisors. On page 13, Globally, in terms of representatives $(\mathscr L,\ell)$ for $D$ and $(\mathscr L,\ell')$ for $D'$ , the condition $D'\le D$ is precisely that the global section $\ell$ of $\mathscr L$ vanish identically in $\mathscr L|D'=\mathscr L\otimes_{\mathcal O_X}\mathcal O_{D'}$ . Ok, so firstly here $\mathscr L|D'=\mathscr L\otimes_{\mathcal O_X}\mathcal O_{D'}$ really bugs me. From what I know, restriction of a sheaf to a subscheme is via pullback of the inclusion map and it gives a sheaf on the subscheme . So then the LHS would be a sheaf on $D'$ while the right hand side is a sheaf on $X$ . There is an exact sequence below involving such terms and it is definitely meant as an exact sequence of sheaves on $X$ , so... what exactly does $\mathscr L|D'$ denote here? Secondly (3') What does it mean that $\ell$ vanishes in $\mathscr L\otimes_{\mathcal O_X}\mathcal O_{D'}$ and why is this implies by $D'\le D$ ? I would be grateful if someone could spell this out in some detail. I don't have any issue understanding the discussion of $D'\le D$ above in terms of their ideal sheaves but somehow I can't translate this into $(\mathscr L,\ell)$ language. Thank you for any illuminating answers/comments.","['algebraic-curves', 'sheaf-theory', 'divisors-algebraic-geometry', 'algebraic-geometry']"
2006369,Convergence of sum of random Poisson variables with divergent parameter,"I'm studying almost-surely convergence and convergence in probability of $S_{n}=X_{1}+\cdots+X_{n},$ where $X_{n}$ is distributed $\mathrm{ Poisson}\left(1/n\right)$ with $n\in\mathbb{N}$ and the sequence of $X_{n}$ are independent. I'm stuck with this because I cannot applied Chebyshev inequality because of divergence of $\displaystyle\sum_{i=1}^{\infty}\frac{1}{n}$, neither Borel-Cantelli Lemma because I don't find a useful bound to use it. I tried use the convergence of $\displaystyle\sum_{n=1}^{\infty}E\left(X_n\right)<\infty$ implies $\displaystyle\sum_{n=1}^{\infty}X_n$ convergence a.s., but I don't get it. Any kind of help is very thanked.","['probability-theory', 'measure-theory']"
2006387,Representing a nonnegative integer as the ordered sum of odd numbers,"Numbers of ways of representing a nonnegative integer as the ordered sum of odd numbers. For the first numbers we find that: $0 \to 0\quad \text{ways}$ $1 \to 1\quad \text{way}$ $2: (1,1) \to 1\quad \text{ways}$ $3: (1,1,1), (3) \to 2\quad \text{ways}$ $4: (1,1,1,1), (3,1), (1,3)\to 3\quad \text{ways}$ $5: (1,1,1,1,1), (3,1,1), (1,3,1), (1,1,3), (5)\to 5\quad \text{ways}$ So, if $A_n$ is the numbers of ways to represent the nonnegative integer n as the ordered sum of $n$ (nonnegative) odd numbers, then $A_n = F_n$ where $F_n$ is the Fibonacci number. How could this be proved? I was trying to prove this by induction, but I'm having problems with the induction step. I really don't know what to do there.","['combinatorics', 'fibonacci-numbers']"
2006406,"Minimum of the value $\sum_{1\le k,i,j\le n}\frac{\sigma{(A_{k}\bigcap A_{i}\bigcap A_{j})}}{\sigma{(A_{k})}\cdot\sigma{(A_{i})}\cdot\sigma{(A_{j})}}$","Let $m,n$ are given positive integers, and  positive real numbers $x_{1}<x_{2}<\cdots<x_{m}$ are given.
  Define $A=\{x_{1},x_{2},\cdots,x_{m}\}$.
  Find the following minimum of the value
  $$\sum_{k=1}^{n}\sum_{i=1}^{n}\sum_{j=1}^{n}\dfrac{\sigma{(A_{k}\bigcap A_{i}\bigcap A_{j})}}{\sigma{(A_{k})}\cdot\sigma{(A_{i})}\cdot\sigma{(A_{j})}}$$ where $A_{1},A_{2},\cdots,A_{n}\subset A$, and $\sigma{(A)}$ denote the sum of the elements of the set $A$. I conjecture this answer is $$\color{red}{\dfrac{n^3}{(x_{1}+x_{2}+x_{3}+\cdots+x_{m})^2}}$$
because when $A_{1}=A_{2}=\cdots=A_{n}=A$,we have
\begin{align*}\sum_{k=1}^{n}\sum_{i=1}^{n}\sum_{j=1}^{n}\dfrac{\sigma{(A_{k}\bigcap A_{i}\bigcap A_{j})}}{\sigma{(A_{k})}\cdot\sigma{(A_{i})}\cdot\sigma{(A_{j})}}&=\sum_{k=1}^{n}\sum_{i=1}^{n}\sum_{j=1}^{n}\dfrac{(x_{1}+x_{2}+\cdots+x_{m})}{(x_{1}+x_{2}+\cdots+x_{m})^3}\\
&=\color{red}{\dfrac{n^3}{(x_{1}+x_{2}+x_{3}+\cdots+x_{m})^2}}.\end{align*} But I can't prove it. I conjecture： The following for $p\geq 2$,
$$\min{\left(\sum_{x_{1}=1}^{n}\sum_{x_{2}=1}^{n}\cdots\sum_{x_{p}=1}^{n}
\dfrac{\sigma{(A_{x_{1}}\bigcap A_{x_{2}}\bigcap A_{x_{3}}}\cdots A_{x_{p}})}{\sigma{(A_{x_{1}})}\cdot \sigma{(A_{x_{2}})}\cdots \sigma{(A_{x_{p}})}}\right)}=\dfrac{n^p}{(x_{1}+x_{2}+\cdots+x_{m})^{p-1}}.$$",['elementary-set-theory']
2006420,Motivation behind stochastic PDEs,"I am starting to study stochastic partial differential equations, and would like to understand when and why they are used. It is well known that in many mathematical models for physics PDEs play a central rôle. E.g. the Navier-Stokes equations in continuum mechanics. Stochastic PDEs often are introduced by considering a physical phenomena with a ""random forcing"", which then might translate into adding a noise term on the RHS of a given PDE. For example the stochastic Navier-Stokes equations. In general one can say that the forces acting on a fluid in motion are chaotic since they might be too difficult to describe in a deterministic setting without considering every molecule independently. Nonetheless I suppose that in most applications most of these chaotic forces can be omitted since, for example, they don't seriously interfere with the movement of the fluid. So a first question is: where and why do we have to consider random forces? And why are these examples important? A second question arises from a very naive thought. If the forces in question are random, I would at first expect that the solution to the SPDE does not differ in mean from the solution is the relative PDE. Are there essential differences between the behaviour of a solution to an SPDE and a PDE? One answer to the latter question could be that the energy of the system explodes in the stochastic setting, because random forces pump energy into the system.","['stochastic-pde', 'reference-request', 'probability-theory', 'soft-question', 'stochastic-analysis']"
2006437,Is it possible to get an example of two matrices,"Is it possible to get an example of two matrices $A,B\in M_4(\mathbb{R})$ both having $rank<2$ but $\det(A-\lambda B)\ne 0$ i.e it is not identically a zero polynomial. where $\lambda$ is indeterminate, I mean a variable. I want to say $(A-\lambda B)$ is of full rank matrix, assuming entries of $A-\lambda B$ is a polynomial matrix with linear polynomial.","['matrices', 'linear-algebra']"
2006468,Find all functions $f: \mathbb Z \to \mathbb Z$ such that $f(x+y)=f(x)+f(y)$,"Let $x=0\,\, f(x+y)=f(0+y)$ every $y \in \mathbb{Z}$ So we get $f(0)+f(y)=f(y)$ then $f(0)=0$ $0=f(0)=f(x(-x))=f(x)+f(-x)=0$ Let $f(1)=k$ for some $k \in \mathbb{Z}$ $f(n)=f(1+1+1+...+1) (n \text{ many } 1)$ $=f(1)+f(1)+...+f(1) (n \text{ many } f(1))$ $=n\cdot k$ Thus $f: \mathbb{Z} \to \mathbb{Z}$ a function such that $f(n)=nk$ I found this but I must also show that there is no other function which satisfies $f(x+y)=f(x)+f(y)$ and I am stuck can somebody help me.","['alternative-proof', 'functional-equations', 'functions', 'proof-verification', 'proof-writing']"
2006538,Prove that $\mathcal T$ is a topology,"Let a function $h:\mathcal P(X)\to\mathcal P(X)$ be defined by $h(\emptyset)=\emptyset$ $h(A\cup B)=h(A)\cup h(B),\;\forall A,B\in\mathcal P(X)$ $h(A)\supseteq A,\;\forall A\in\mathcal P(X)$ $h\circ h=h$ Now setup $\mathcal T:=\{A^\complement\in\mathcal P(X): h(A)=A\}$ . Prove that $\mathcal T$ is a topology on $X$ . Im stuck with this problem. I can show that $\emptyset,X\in\mathcal T$ and that the finite intersection of elements of $\mathcal T$ belong to $\mathcal T$ . But Im unable to prove that arbitrary union of elements of $\mathcal T$ belong to $\mathcal T$ . I was playing around with the properties of $h$ but I cant conclude something about this last axiom to define a topology. Some hint or solution will be appreciated. Thank you.",['general-topology']
2006554,Hurewicz's reformulation of Menger property,"Many papers on selection principles and also the Wikipedia article mention the reformulation of Menger's property given by Hurewicz. Menger's formulation for metric spaces was: Every basis $\mathcal B$ of the topology of $(X,d)$ contains a sequence $(B_n)$ such that $\operatorname{diam}B_n\to 0$ and $\{B_n; n=1,2,\dots\}$ covers $X$. Hurewicz has shown that this is equivalent to: For every sequence $\mathcal U_n$ of open covers of $X$ there exists a sequence of finite subsets $\mathcal F_n\subseteq \mathcal U_n$ such that $\bigcup_{n=1}^\infty \mathcal F_n$ covers $X$. As the reference for the proof that these two formulations are equivalent (in metric spaces) I only found the original Hurewicz's paper: 
Hurewicz, Witold (1926). ""Über eine verallgemeinerung des Borelschen Theorems"". Mathematische Zeitschrift. 24.1: 401–421. DOI: 10.1007/BF01216792 , eudml , GDZ . Are you aware of some English text which contains proof of this result? (Or, if the proof is simple enough, can you outline it here? But this does not seem very likely - I guess after briefly looking through Hurewicz's paper.)","['reference-request', 'general-topology', 'metric-spaces']"
2006629,Is the Risch-algorithm more powerful than the usual integration methods?,"Suppose, a function $f(x)$ has an elementary antiderivate. Is it always possible to find the antiderivate with the usual integration mehods (integration by parts, substitution, and so on) or can the Risch algorithm be necessary to find it ? If I understand it right, the Risch-algorithm is nearly always successful, but I have no idea how the algorithm actually works. Many integrals (assuming that an elementary antiderivate exists) are solveable with the usual methods as well, but I think there are cases which are too hard, so that we actually need the Risch-algorithm. Additional question : How efficient is the Risch-algorithm in practice ? Are there cases prcatically infeasible becuase the Risch-agorithm would take too long (Of course, the length of the antiderivate should not be too large) ?","['elementary-functions', 'integration', 'calculus', 'closed-form']"
2006632,Sum involving the product of binomial coefficients,"I wonder whether it is possible to calculate the folowing sum that involves the Binomial coefficients
$$\sum_{k=0}^n \binom{n}{k}^2 \binom{2k}{k} .$$","['number-theory', 'combinatorics', 'binomial-coefficients']"
2006675,Integrals of a smooth function,"Does there exist a smooth ($\mathcal C^\infty$) function $f \colon \mathbb R \to \mathbb R$ such that $$\int_{-\infty}^\infty t^n f(t) \,\mathrm{d}t = \begin{cases} 1 & n = 0 \\ 0 & n \ge 1\end{cases}?$$ It certainly looks like an application of the Fourier transform and the following formula: if 
$$\hat f (\xi) = \int_{\mathbb R} f(x) \exp(-2\pi i x \xi) \,\mathrm{d}x,$$
then the Fourier transform of $x^n f(x)$ equals
$$\frac{i^n}{2^n \pi^n} \frac{\mathrm{d}^n \hat f(\xi)}{\mathrm{d} \xi^n}.$$ How to proceed?","['integration', 'fourier-transform']"
2006696,Separable Differential Equation -- Last step,"I have separable ODE that is: $$\frac{dy}{dt}=\frac{5y(100-y)}{100}$$ I get stuck towards the end and maybe my answer is even correct,but can't see that it looks like Wolfram's answer (which I know is sometimes strange), but wanted to ask a few questions. I separate this into: $$dy \frac{100}{y (100-y)}=5dt$$ instead of solving the left-hand side by partial fractions, I re-write it as $$dy \frac{100}{y^2\left(\frac{100}{y} -1\right)}$$ so that I can use the u substitution of $$u=\frac{100}{y}-1$$
$$du = -100y^{-2} dy$$ so my left hand integral becomes $$- \int\frac1u du$$ thus my $2$ integrals are: $$-\int \frac1u du  = \int 5 dt$$
Solving these integrals $$-\ln\left|\frac{100}{y} -1\right| = 5t +C.$$ Multiply by $-1$: $$\ln \left|\frac{100}{y} -1\right| = -5t +C.$$ Here is where I'm not sure of best next step (assuming my math is correct so far) Should I put the $\ln$ stuff into: $$\ln\left|\frac{100-y}{y}\right|?$$ Then I would have $$\ln (100-y) - \ln y = -5t +C$$",['ordinary-differential-equations']
2006714,A formula for the infimum of two measures,"In this question the OP claims that given measures $\mu_1,\mu_2$ on a measurable space $(E,\mathcal E)$ we can define their infimum w.r.t. to the ordering of measures by: $$(\mu_1 \wedge \mu_2)(A) := \inf\{\mu_1(A\cap B)+\mu_2(A \cap B^c) : B\in \mathcal E\}$$ Unfornately I'm kind of weak in Analysis and I'm asking for a proof that this 
defines a measure. (Not the actual question: Does this have anything to do with the concept of outer measure / Caratheodory's extension theorem? Because it looks somewhat similar).",['measure-theory']
2006731,Linear regression using mean absolute error,"Is the regression using the mean squared error any different if the absolute error is used? Assuming the formula is $Y = ax + b$ and both a and b are found using the mean squared error, would they be different than with the other method? Should I take the formula of the mean abs error and minimize it?","['regression', 'statistics']"
2006741,How Many Acute Angles,"Knowing that the big angle is 90, how many acute angles we have in this shape? I know acute angle is less than 90, so we have 4 acute angles between the inner lines. Also we have 3 more acute angles combining the above angles. So the total will be 7 acute angles. But the answer says its 9 acute angles, what am I missing?",['geometry']
2006744,"Solvability of group presentations with 2 ""almost disjoint"" relations","I am interested in a certain type of $2$ -relator group presentations arising in algebraic topology which have two relators that only contain a single generator in common.  Specifically, suppose I have group presentation of the form $$
G \cong \langle\{S_1\} \cup \{S_2\} \cup \{b\} \mid P_1 = b^{n_1}, P_2 = b^{n_2}\rangle
$$ Where $S_1 = \{x_1, \dots , x_n\}$ , $S_2 = \{y_1, \dots, y_m\}$ are sets of generators (one or both possibly empty).  In the first relation, $P_1$ is a word which is either a product of commutators of the form $P_1 = [x_1,x_2][x_3,x_4]\dots [x_{n-1},x_n]$ , OR is of the form $P_1 = x_1^2 x_2^2 \dots x_n^2$ .  Similarly, $P_2$ takes on one of those two forms but in the $y_i$ generators. Finally, the $n_{1,2}$ may be any non-zero integers (in particular, they may be positive or negative). We therefore have that $P_1$ is a word only in the generators of $S_1$ and $P_2$ is a word only in the generators of $S_2$ . My Question: I am aware that in general, two relator group presentation word/conjugacy/isomorphism problems are not tractable.  However, given the restricted form that the group relations have (they are formed from disjoint sets of generators, except for $b$ ), are there any theorems or methods which provide additional power to work with these groups? Observations: If $d = gcd(n_1, n_2) = 1$ , then the $b$ generator can be eliminated. If both of $S_{1,2}$ are empty, then the group is cyclic (and trivial if $d=1$ ). If one of $S_{1,2}$ is empty, there are certain simplifications that can be made, but everything seems to be case by case depending on d and the form of $P_1$ , $P_2$ . Are there any results which would allow me to exactly classify when this group presentation can be reduced to a one relatiion group and when two relations is the minimum number possible? Playing around with different special cases, it intuitively seems obvious that this should be the case (but intuition may be incorrect), but I am constantly getting stuck trying to prove that there could not possibly exist any other isomorphic presentations which have a single relation. Any strategies, tactics, useful lemmas/theorems would be greatly appreciated!","['algebraic-topology', 'algebraic-groups', 'group-theory', 'group-presentation']"
2006756,Equivalence between norms in $H_0^1(\Omega)\cap H^2(\Omega)$.,"Based in many questions and answers like [1 , 2 , 3 ] and a comment a good comment here [4] . 
I would like to know that the space $H=H_0^1(\Omega)\cap H^2(\Omega)$ can be equiped with this norm 
$$\tag{1}\|\cdot\|_H=||\Delta\cdot||_{L^2}+||\nabla\cdot||_{L^2}+||\cdot||_{L^2},$$
this is the $H^2$-norm. Or, is it equipped with this one
$$\tag{2}\|\cdot\|_H=||\Delta\cdot||_{L^2}+||\cdot||_{L^2}.$$
Can I say that if $H$ is equipped with (1) then, normes (1), (2) and $||\Delta\cdot||_{L^2}$ are equivalent in $H$.","['partial-differential-equations', 'reference-request', 'regularity-theory-of-pdes', 'sobolev-spaces', 'analysis']"
2006758,Show that in $\lim_{x\to 0}\frac{x^3\sin(1/x)}{\sin^2 x}$ can't be applied L'Hopital's Rule,"I was trying to demonstrate this by showing that one or some of the conditions for the application of L'Hopital's Rule are not met, but it seems to me that the conditions work just fine. According to my textbook. One of the condition of applicability of L'Hopital's Rule is that: If: $1)$ $f$ anf $g$ are differentiable on $(a,b)$; $b-a <\infty$; $2)$ $\lim_{x\to a+0}f(x) = \lim_{x\to a+0}g(x) = 0$; $3)$ $g' \neq 0$ on $(a,b)$; $4)$ $\exists \lim_{x\to a+0}\frac{f'(x)}{g'(x)} \in \mathbb{\overline{R}}$ Then $$\lim_{x\to a+0}\frac{f(x)}{g(x)} = \lim_{x\to a+0}\frac{f'(x)}{g'(x)}$$ My thoughts: Here $a = 0$, so $(0,b)$ is our open interval. $1)$ Both the numerator and the denominator are differentiable on this open interval. $2)$ as $x \to +0 f(x) = g(x)$ (considering the boundeness of $\sin (\frac{1}{x}$) $3)$ we can choose a $b$ small enough so $g'(x) = \sin (2x) \neq 0$ on this interval (any $b<\pi$ works). $4)$ on $(0, b)$, $\lim_{x\to a+0}\frac{f'(x)}{g'(x)}$ is indeterminate but I can apply again L'Hopital's Rule. What am I missing?","['real-analysis', 'limits-without-lhopital', 'calculus', 'limits']"
2006798,Prove that $ \lim_{n \to \infty} \int_{-\infty}^{\infty} \sin(nt) f(t) d t = 0 $.,I am trying to prove that $ \lim_{n \to \infty} \int_{-\infty}^{\infty} \sin(nt) f(t) d t = 0 $ for every Lebesgue integrable function $ f $ on $ \mathbb{R} $. My first thoughts were to use Dominated Convergence Theorem but I realised that there is no pointwise limit of the sequence of functions $ f_n = \sin(nt) f(t) $. I do not know how to proceed. Any help would be appreciated. Thanks!,"['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
2006825,Do we really need a partition of unity to define integration on manifolds,"On wikipedia , there is the following : A partition of unity can be used to define the integral (with respect
  to a volume form) of a function defined over a manifold: One first
  defines the integral of a function whose support is contained in a
  single coordinate patch of the manifold; then one uses a partition of
  unity to define the integral of an arbitrary function; finally one
  shows that the definition is independent of the chosen partition of
  unity. My question is the following : do we really need to use a partition of unity to define the integral of a function defined over a manifold ? Couldn't we just use a sequence $(U_n)$ of chart domains that cover the manifold, and then define the sequence of Borel sets 
$B_{n+1}:=U_{n+1}\backslash U_n$, and $B_0=U_0$, and then just define the integral of a function $f$ with respect to a volume form to be the sum of all integrals of $f$ over $B_n$ (since $B_n$ is in a chart domain, the integral can be computed through a chart).","['manifolds', 'integration', 'differential-geometry']"
2006848,Smooth domain and compact sets,"suppose $M$ is a smooth manifold, $O\subset M$ is an open domain and $K\subset O$ is some compact set. I am wondering if there always exists an open domain $D$ in $M$ with smooth boundary and such that $K\subset D\subset O$? Unfortunately I do not know how to approach this problem. Does anyone have an idea? Best wishes","['riemannian-geometry', 'differential-geometry']"
2006856,Line integral of a conservative vector field,"I was trying to integrate the function $$f(x,y)=\left(\frac{-y}{x^2+y^2},\frac{x}{x^2+y^2}\right)$$ from $(1,1)$ to $(1,-1)$ along any curve that does not intersect the line $L=\{(x,y)\in\mathbb{R}^2\:|\:\: y=0, x\geq 0\}$. My approach was to note that
$$\frac{\partial f_x}{\partial y}=\frac{\partial f_y}{\partial x}$$
and that $\mathbb{R}^2-L$ is an simply connected subset of $\mathbb{R}^2$. This implies that $$\int f\cdot \mathrm{d}s$$ independs of the path and then integrated it along the circle of radius $\sqrt{2}$ that connects the points $(1,1)$ and $(1,-1)$. I arrived at the value $3\pi/2$ for the integral. However, I could define another simply connected subset of $\mathbb{R}^2$ such that I could integrate $f$ along the line that connects $(1,1)$ to $(1,-1)$. Then I would arrive at the result $-\pi/2$ for the integral. What is wrong here?
Thanks!","['multivariable-calculus', 'calculus', 'vector-analysis']"
2006865,"Is there a random-seeming language that is a proper subset of $\{s \in \{0,1\}^n: s \text{ has } k \; 1\text{'s}\}$?","I call a language $L$ a random-seeming language of length $n$ and weight $k$ if $L\subset\{0,1\}^n$, $s\in L \rightarrow (s \text{ has } k \;1\text{'s})$, and $$\forall _{I\subset[n]}\forall_{m\le \min\left(k,|I|\right)} \left(S=\{s \in L: \sum_{i\in I}b_i(s)=m\}\rightarrow\forall_{i\in I}\left[|\{s\in S:b_i(s)=1\}|=\frac {m|S|} {|I|}\right]\right)$$where $b_i(s)$ is the $i^\text{th}$ bit of $s$. Obviously the language $L_\max=\left\{s\in\{0,1\}^n:\sum_{i\in \left[n\right]}b_i(s)=k\right\}$ is random-seeming, but are there any random-seeming languages of length $n$ and weight $k$ smaller than $L_\max$?  More generally, given an integer $l \le |L_\max|$, what is the smallest $\epsilon\ge 0$ such that $$\exists _{L\subset L_\max}\forall _{I\subset[n]}\forall_{m\le \min\left(k,|I|\right)} \left(\left|L\right|\le l \wedge S=\{s \in L: \sum_{i\in I}b_i(s)=m\}\rightarrow\forall_{i\in I}\left[\left|\left|\left\{s\in S:b_i(s)=1\right\}\right|-\frac {m|S|} {|I|}\right|\le\epsilon\right]\right)$$ Note : I included the probability tag because this is essentially a probability question in my mind: a language $L$ is ""random-seeming"" iff for every set of set of digits $I$ and integer $m\le k$, the probability that a random string $s\in \{0,1\}^n$ with $m$ $1$'s in $I$ will be in $L$ is independent of the distribution of the $1$'s in $I$, and in the general problem, $\epsilon$ represents the maximum deviation such a probability can have from the mean probability for any given distribution of $1$'s in any given $I$.  At least, that is what I intended it to mean.  It's possible that I messed up the formal statement above (though I'm pretty sure I got it right), but the point of being random-seeming, is that the number of $1$'s among some of the digits tells you nothing (or in the general case, little) about the distribution of $1$'s in the rest of the digits, only their total number.","['formal-languages', 'probability']"
2006899,Why isn't every eigenvalue of a stochastic matrix equal to 1?,"In this question, we see a proof that the largest eigenvalue of a stochastic matrix is equal to 1: Proof that the largest eigenvalue of a stochastic matrix is 1 However, I think I've found a proof that every eigenvalue of a stochastic matrix is equal to 1.  Can you tell me where my proof is wrong? Proof: Suppose ${\bf r}$ is an eigenvector of the column stochastic matrix $M$ (i.e. $M{\bf r} = \lambda {\bf r}$ for some $\lambda$), and assume without loss of generality that the entries of ${\bf r}$ sum to $1$.  Then $$M{\bf r} =
\begin{bmatrix}
M_{11}\\
M_{21}\\
\vdots\\
M_{n1}
\end{bmatrix} r_1 +
\begin{bmatrix}
M_{12}\\
M_{22}\\
\vdots\\
M_{n2}
\end{bmatrix} r_2
+ \dots +
\begin{bmatrix}
M_{1n}\\
M_{2n}\\
\vdots\\
M_{nn}
\end{bmatrix} r_n$$ Since $M$ is column stochastic, each column must sum to $1$, so the sum of the entries in $M {\bf r}$ is just $1 \cdot r_1 + 1 \cdot r_2 + \dots + 1 \cdot r_n = 1$.  Therefore, $\lambda$ must be $1$, and $M$ can only have one eigenvalue. Thanks!","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2006979,Finding Polynomial Equations for $1^4 + 2^4 + 3^4 + \ldots n^4$ [duplicate],"This question already has answers here : A formula for the power sums: $1^n+2^n+\dotsc +k^n=\,$? (6 answers) Closed 7 years ago . Find a polynomial expression for $$ 1^4 + 2^4 + 3^4 + ... + n^4 $$ I know you have to use the big theorem but I can't figure out how you would start to compute the differences. Suggestions?","['summation', 'discrete-mathematics']"
2007009,How to find equations of the graph of a rational map?,"Assume that $f:{\mathbb P}^n\dashrightarrow {\mathbb P}^n$ is a rational map. Then, how one can write down explicitly the equations of its graph?",['algebraic-geometry']
2007020,Show that the square matrix A is invertible,"The question is: The square matrix $A$ satisfies $p(A) = 0$, where $p(x)$ is a polynomial such that $p(0) \ne 0$. Show that $A$ is invertible. I'm lost, I don't know if there's something more I have to learn to do this. I've gotten this far (I'm most likely not on the right track): $$ p(A) = a_0I+a_1A+a_2A^2+ ...+a_nA^n $$
$$ p(0) = a_0I+(a_1\cdot 0)+(a_2\cdot 0^2)+\ldots +(a_n\cdot 0^n) $$
$$ p(0) = a_oI$$
$$ p(A) = p(0)+a_1A+a_2A^2 +\ldots +a_nA^n $$ I don't quite know what to do further. I know that if $AX=B$, where $A$ is the square matrix, $B$ is a matrix vector, if there's only one solution $X$ for all $B$, then $A$ is invertible.","['matrices', 'linear-algebra']"
2007078,Isometry of Torus,What is the  isometry group of a torus given a flat metric? I know $ O(1) \times O(1) $ should be a subgroup of it. Is there any other possible isometries? What if the metric is not flat?,"['isometry', 'riemannian-geometry', 'differential-geometry', 'differential-topology']"
2007099,Why is the spectrum of an operator with compact resolvent countable and consists only of eigenvalues?,"I'm trying to prove the following statement. Let $\mathcal H$ be a Hilbert space and $T: D \rightarrow \mathcal H$, $D \subset \mathcal H$, a linear operator. Let $\lambda_0 \in \rho(T)$ such that $(T - \lambda_0)^{-1}$ is a compact operator.
Then $(T-\lambda)^{-1}$ is compact for each $\lambda \in \rho(T)$, $\sigma(T)$ consists only of a countable number of eigenvalues and doesn't have a limit point in $\mathbb C$. It was said that this follows from well known facts about the spectral theory of compact operators. Now, the notable facts that I recall are: (let $K$ be a compact operator) each non-zero spectral value of $K$ is also an eigenvalue, for non-zero eigenvalues of $K$, the dimension of their eigenspace is finite, $\sigma(K)$ is countable and its only limit point is 0. Unfortunately, I'm unable to cook up the desired conclusion from those properties alone. So I guess there is some missing link here. Can someone point me into the right direction?","['functional-analysis', 'compact-operators', 'spectral-theory', 'hilbert-spaces']"
2007116,Quadrilateral Interpolation,"The simplest finite element shape in two dimensions is a triangle .
In a finite element context, any geometrical shape is endowed with an interpolation ,
which is linear for triangles (most of the time), as has been explained in this answer :
$$
T(x,y) = A.x + B.y + C
$$
Here $A$ and $B$ can be expressed in coordinate and function values
at the vertices (nodal points) of the triangle:
$$
\begin{cases}
 A = [ (y_3 - y_1).(T_2 - T_1) - (y_2 - y_1).(T_3 - T_1) ] / \Delta  \\
 B = [ (x_2 - x_1).(T_3 - T_1) - (x_3 - x_1).(T_2 - T_1) ] / \Delta
\end{cases} \\ \Delta = (x_2 - x_1).(y_3 - y_1) - (x_3 - x_1).(y_2 - y_1)
$$
Consider the simplest finite element shape in two dimensions except one:
the quadrilateral . Function behavior inside a quadrilateral is approximated
by a bilinear interpolation between the function values at the vertices
or nodal points (most of the time. Wikipedia is rather terse about it) Let $T$ be such a function, and $x,y$ coordinates. Then try:
$$
       T = A + B.x + C.y + D.x.y
$$
Giving:
$$
\begin{cases}
T_1 = A + B.x_1 + C.y_1 + D.x_1.y_1 \\
T_2 = A + B.x_2 + C.y_2 + D.x_2.y_2 \\
T_3 = A + B.x_3 + C.y_3 + D.x_3.y_3 \\ 
T_4 = A + B.x_4 + C.y_4 + D.x_4.y_4
\end{cases} \quad \Longleftrightarrow \quad 
\begin{bmatrix} T_1 \\ T_2 \\ T_3 \\ T_4 \end{bmatrix}
\begin{bmatrix} 1 & x_1 & y_1 & x_1 y_1 \\ 1 & x_2 & y_2 & x_2 y_2 \\
1 & x_3 & y_3 & x_3 y_3 \\ 1 & x_4 & y_4 & x_4 y_4 \end{bmatrix}
\begin{bmatrix} A \\ B \\ C \\ D \end{bmatrix} \\ \Longleftrightarrow \quad
\begin{bmatrix} A \\ B \\ C \\ D \end{bmatrix}
\begin{bmatrix} 1 & x_1 & y_1 & x_1 y_1 \\ 1 & x_2 & y_2 & x_2 y_2 \\
1 & x_3 & y_3 & x_3 y_3 \\ 1 & x_4 & y_4 & x_4 y_4 \end{bmatrix}^{-1}
\begin{bmatrix} T_1 \\ T_2 \\ T_3 \\ T_4 \end{bmatrix}
$$
Provided that we have a non-singular matrix in the middle. But now we have a little problem.
Consider the quadrilateral as depicted in the above picture on the right.
The vertex-coordinates of this quadrilateral are defined by the second and the
third column of the matrix below. This matrix is formed by specifying $T$
vertically for the nodal points and horizontally for the basic functions
$ 1,x,y,xy $ :
$$
 \begin{bmatrix} T_1 \\ T_2 \\ T_3 \\ T_4   \end{bmatrix} =
 \begin{bmatrix}  1  &  -\frac{1}{2}  &   0  &  0  \\
                  1  &   0  &  -\frac{1}{2}  &  0  \\
                  1  &  +\frac{1}{2}  &   0  &  0  \\
                  1  &   0  &  +\frac{1}{2}  &  0  \end{bmatrix}
 \begin{bmatrix} A \\ B \\ C \\ D \end{bmatrix}
$$
The last column of the matrix is zero. Hence it is singular , meaning that
$A,B,C$ and $D$ cannot be found in this manner. Though with a unstructured grid
there may seem to be not a great chance that a quadrilateral is exactly positioned
like this, experience reveals that it cannot be excluded that Murphy comes by.
That alone is enough reason to declare the method for triangles not done for quadrilaterals. Two questions: Why in the first place would a bilinear interpolation be associated
with a quadrilateral ? Why not some other finite element shape?
And why not some other interpolation? How can a bilinear interpolation be defined for an arbitrary quadrilateral (assumed convex ), i.e. without running into singularities? My problem is not so much how the quadrilateral and the bilinear are related but rather why they are related
in this way. I shall be satisfied with a response when it has become more clear that there are no other possibilities i.e. people haven't
overlooked anything. EDIT. The comment by Rahul sheds some light. Let the finite element shape be ""modified"" by an affine
transformation (with $a,b,c,d,p,q$ arbitrary real constants) and work out for the term that is interesting:
$$\begin{cases}
x' = ax+by+p \\
y' = cx+dy+q
\end{cases} \quad \Longrightarrow \\
x'y'=acx^2+bdy^2 + (ad+bc)xy+(cp+aq)x+(dp+bq)y+pq
$$
So the interpolation remains bilinear only when the following conditions are fulfilled:
$$
ac=0 \; \wedge \; bd=0 \; \wedge \; ad+bc\ne 0 \quad \Longleftrightarrow \\ \begin{cases}
a\ne 0  \; \wedge \; d\ne 0 \; \wedge \; b=0 \; \wedge \; c=0 \\
a=0  \; \wedge \; d=0 \; \wedge \; b\ne 0 \; \wedge \; c\ne 0 \end{cases}\quad \Longleftrightarrow \\
\begin{cases}x'=ax+p\\y'=dy+q\end{cases} \quad \vee \quad \begin{cases}x'=by+p\\y'=cx+q\end{cases}
$$
This means that a (parent) quadrilateral element, once it has been chosen, can only be translated, scaled (in $x$- and/or $y$- direction),
mirrored in $\,y=\pm x$ , rotated over $90^o$. Did I forget something? Update. Why a quadrilateral with bilinear interpolation? Little else is possible with polynomial terms like $\;1,\xi,\eta,\xi\eta\,$ , if
four nodal points are needed (one degree of freedom each) for obtaining four
equations with four unknowns. Then stil there remain some issues, such as not
self-intersecting and being convex. The former issue has been covered in the
answer by Nominal Animal. The latter may be stuff for a separate question. Other issues covered in the answer by Nominal Animal are the following. Perhaps the simplest heuristics is to take the direct product of one-dimensional case: the line segment as well as the linear interpolation. With the notations by Rahul and Nominal Animal that is: $[0,1]\times[0,1]$ and $\{1,u\}\times\{1,v\}$ . In the end, we have a square as the standard parent bilinear quadrilateral. For a non-degenerate paralellogram the bilinear interpolation is reduced to a linear one, which makes it simple to express the local coordinates $(u,v)$ into the global coordinates $(x,y)$. LATE EDIT. Continuing story at: Quadrilateral Finite Elements must be convex and not self-intersecting. But why? Jacobian determinant for bi-linear Quadrilaterals","['quadrilateral', 'interpolation', 'finite-element-method', 'geometry']"
2007231,Least or Highest Element in a non-empty set,"I have to prove or disprove that every non-empty set on non-negative rational numbers has a least element. I thought this may be pretty straight forward but I thought what if the non-empty set contains only one element. For example; A = {2}. Does this mean that the least element is 2? Or the highest element is 2? Or both or neither? Would love to hear from everybody.
PS: I'm second year math major so I'm still new to this.",['discrete-mathematics']
2007238,What is the probability of getting an even number from a Poisson random draw?,"Below is a graph showing the probability of drawing an odd number (y-axis) from a Poisson distribution with a given expected value (x-axis) x = seq(0,1e4,1)         // range of values to explore 
lambdas = seq(0,4,0.01)  // expected value of the Poison distribution

FracOdd = numeric(n+1)       // response variable
for (i in 1:length(lambdas)) 
{
   FracOdd[i] = sum(dpois(x,lambdas[i])[seq(2,length(x),2)])  // calculate probability of drawing an odd number
}

plot(y=FracOdd,x=lambdas, type=""l"", lwd=3, xlab=""Expected value"", ylab=""Probability of drawing an odd number"")   // plot the data It seems that the probability of drawing an odd number from a Poisson distribution with non-infinite mean is always lower than the probability of drawing an even number. What is the intuition for why the probability of drawing an odd number from a Poisson distribution always below 0.5? Is the function I drew numerically, easy to derive analytically?","['poisson-process', 'poisson-distribution', 'probability', 'probability-distributions']"
2007255,Probability that a 5-card poker hand contains a flush or a three of a kind,"Please excuse me if I don't type this right, this is my first posted question. I hope I do this right.... I'm having problems with a question from my Intro to Math Analysis course. It is not from any book, but a worksheet that the professor made himself. I need to find the probability of getting a flush or a three of a kind in a 5-card poker hand. It is a standard deck, and I need to exclude ""better hands"", like straight flushes and full houses. I know the denominator is ${52\choose {5}}$. For the numerator I have calculated the following: Number of ways to get a flush but not a straight flush: $4\cdot {13\choose {5}} -4 \cdot 10
$ Number of ways to get a three of a kind but not a full house: $13 \cdot {4\choose {3}} \cdot 4 \cdot{12\choose {1}}  \cdot4 \cdot{11\choose {1}} $ I know I need to add these together, and I know I don't have to worry about subtracting the number of hands that have been counted in both because you can't have a three of a kind of the same suit anyway. So I have a numerator of $114,932$. But this is far from the answer, which has a numerator of $60,020$. Please help. Thank you.",['probability']
2007258,Proof using smallest counter example,"Prove that any integer $n > 1$ is divisible by a prime using smallest counterexample I got about halfway through this proof. I assumed that there was a smallest number $x$ (with $2$ being the base case) which cannot be divided by any prime number. Then I considered $x-1$, which is true. Then I broke this question into two cases: Case 1: $x-1$ is odd. Then, $x-1+1=2k+1+1$, which means that $x=2(k+1)$. This goes against my assumption as this expression is divisible by $2$, which is prime. Case 2: $x-1$ is even. Then, $x-1+1=2k+1$, $x=2k+1$ – I am currently stuck here. I'm currently stuck on the 2nd case. Any advice? Thanks!","['proof-explanation', 'discrete-mathematics']"
2007293,Definition of $e$,"Definition of $e$ $\ln (e)= \int_\limits{1}^e\frac{1}{t}dt=1$ I found this in my calculus textbook, and I was wondering what does this exactly ""mean"".  This is more of a research question which I could do, but where would I start.   I understand that its an integral, and what it states; however, how was this derived in calculus?  Where would be a good book to research to understand an ideal proof of the equation?","['derivatives', 'reference-request', 'soft-question', 'calculus']"
2007302,Is the norm of a singular matrix necessarily zero?,"If not, can you give example of when it's not?","['matrices', 'normed-spaces', 'linear-algebra']"
2007309,how to do this ODE transformation?,"Could someone please show me how the book did the following transformation? I am not able to reproduce the result shown. I show one attempt, but I tried few others. Here is screen shot of the part of the book page showing the transformation used The book link at google books is this and the page is page number 3 in the introduction: \begin{equation}
\frac{d^{2}y}{dx^{2}}\left(  y+x\right)  +\frac{dy}{dx}\left(  \frac{dy}
{dx}-1\right)  =0 \tag{1}
\end{equation} Since $y=u-v\left(  u\right)  $ then, \begin{equation}
\frac{dy}{dx}=\frac{du}{dx}-\frac{dv}{du}\frac{du}{dx} \tag{2}
\end{equation} And% \begin{align}
\frac{d^{2}y}{dx^{2}} &  =\frac{d^{2}u}{dx^{2}}-\frac{d}{dx}\left(  \frac
{dv}{du}\frac{du}{dx}\right)  \nonumber\\
&  =\frac{d^{2}u}{dx^{2}}-\left(  \frac{d^{2}v}{du^{2}}\left(  \frac{du}
{dx}\right)  ^{2}+\frac{dv}{du}\frac{d^{2}u}{dx^{2}}\right)  \tag{3}
\end{align} Now Let $\frac{dv}{du}=v^{\prime},\frac{d^{2}v}{du^{2}}=v^{\prime\prime}$,
then (2) and (3) becomes \begin{align*}
\frac{dy}{dx} &  =\frac{du}{dx}-v^{\prime}\frac{du}{dx}\\
\frac{d^{2}y}{dx^{2}} &  =\frac{d^{2}u}{dx^{2}}-\left(  v^{\prime\prime
}\left(  \frac{du}{dx}\right)  ^{2}+v^{\prime}\frac{d^{2}u}{dx^{2}}\right)
\end{align*} Substituting the above two equations back into (1), and using the given
$x=u+v,y=u-v$ results in \begin{align*}
\left[  \frac{d^{2}u}{dx^{2}}-\left(  v^{\prime\prime}\left(  \frac{du}
{dx}\right)  ^{2}+v^{\prime}\frac{d^{2}u}{dx^{2}}\right)  \right]  \left(
u-v+u+v\right)  +\left(  \frac{du}{dx}-v^{\prime}\frac{du}{dx}\right)  \left(
\frac{du}{dx}-v^{\prime}\frac{du}{dx}-1\right)   &  =0\\
\left[  \frac{d^{2}u}{dx^{2}}-\left(  v^{\prime\prime}\left(  \frac{du}
{dx}\right)  ^{2}+v^{\prime}\frac{d^{2}u}{dx^{2}}\right)  \right]  2u+\left(
\frac{du}{dx}\right)  ^{2}-v^{\prime}\left(  \frac{du}{dx}\right)  ^{2}
-\frac{du}{dx}-v^{\prime}\left(  \frac{du}{dx}\right)  ^{2}+v^{\prime2}\left(
\frac{du}{dx}\right)  ^{2}+v^{\prime}\frac{du}{dx} &  =0\\
2u\frac{d^{2}u}{dx^{2}}-2uv^{\prime\prime}\left(  \frac{du}{dx}\right)
^{2}-2uv^{\prime}\frac{d^{2}u}{dx^{2}}+\left(  \frac{du}{dx}\right)
^{2}-v^{\prime}\left(  \frac{du}{dx}\right)  ^{2}-\frac{du}{dx}-v^{\prime
}\left(  \frac{du}{dx}\right)  ^{2}+v^{\prime2}\left(  \frac{du}{dx}\right)
^{2}+v^{\prime}\frac{du}{dx} &  =0
\end{align*} I do not know how to make the above same as book result.","['substitution', 'ordinary-differential-equations']"
2007373,"Basic Geometric intuition, context is undergraduate mathematics","At some point in your life you were explained how to understand the dimensions of a line, a point, a plane, and a n-dimensional object. For me the first instance that comes to memory was in 7th grade in a inner city USA school district. Getting to the point, my geometry teacher taught, ""a point has no length width or depth in any dimensions, if you take a string of points and line them up for ""x"" distance you have a line, the line has ""x"" length and zero height, when you stack the lines on top of each other for ""y"" distance you get a plane"" Meanwhile I'm experiencing cognitive dissonance, how can anything with zero length or width be stacked on top of itself and build itself into something with width of length? I quit math. Cut to a few years after high school, I'm deep in the math's. I rationalized geometry with my own theory which didn't conflict with any of geometry or trigonometry. I theorized that a point in space was infinitely small space in every dimension such that you can add them together to get a line, or add the lines to get a plane. Now you can say that the line has infinitely small height approaching zero but not zero. What really triggered me is a Linear Algebra professor at my school said that lines have zero height and didn't listen to my argument. . . I don't know if my intuition is any better than hers . . . if I'm wrong, if she's wrong . . . I would very much appreciate some advice on how to deal with these sorts of things.","['synthetic-differential-geometry', 'nonstandard-analysis', 'advice', 'measure-theory', 'geometry']"
2007419,If $|f|$ is differentiable then is $f$ differentiable,If $|f|$ is differentiable then is $f$ differentiable? I know that if $f$ is differentiable then $|f|$ may not be Example $f(x)=x$ But how to do the converse?,"['derivatives', 'real-analysis']"
2007433,Function recommendation? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I want the general form of a function $f(x)$ containing two other variables $a, b$ such that the graph of the function resembles the image below: The function should satisfy the following conditions:
$$f(0)=1$$
$$f(\frac{4}{5}b)=c$$
$$f(b)=0$$ Piece-wise defined functions are acceptable.","['functions', 'graphing-functions']"
2007485,"How do you evaluate the integral $\int\frac{x^2-1}{(x^4+3 x^2+1) \tan^{-1}\left(\frac{x^2+1}{x}\right)}\,dx$?","i'm required to evaluate this integral. I've tried factorizing but it doesn't lead me to anywhere. $$\int\frac{x^2-1}{(x^4+3 x^2+1) \tan^{-1}\left(\frac{x^2+1}{x}\right)}\,dx$$ I've also tried letting $u = \frac{x^2+1}{x}$, $du/dx$ gets me $1-\frac{1}{x^2}$ but it doesn't seem to be working either. Hope to receive some advise/ solutions on how to start tackling the question",['integration']
2007526,"For $f,f_1 \ldots f_n \in L^1(X,M,\mu,\mathbb{R})$ suppose that $\sum_{n}\int |f_n-f| d\mu \lt \infty$ . Show that $f_n \to f ,\mu-$a.e","Suppose that $(X,M,\mu)$ is a measure space. For $f,f_1 \ldots f_n \in L^1(X,M,\mu,\mathbb{R})$ suppose that $\sum_{n}\int |f_n-f| d\mu \lt \infty$ . Show that $f_n \to f, \mu-$a.e This is a problem from Cohn's Measure Theory (Section 3.1, Q4). My try: Let $\epsilon \gt 0$ be fixed. Suppose that $E_n^{\epsilon}=\{x \in X: |f_n(x)-f(x)| \ge \epsilon\}$. Then $$\infty \gt \sum \int|f_n-f|d\mu \ge \sum_{n}\int_{E_n}|f_n-f| \ge \epsilon\sum_{n}\mu(E_n^{\epsilon})$$
Thus $$\sum_{n} \mu(E_n^{\epsilon}) \lt \infty$$
Then for any $\delta \gt 0$, then there exists a $n_0(\delta)$ such that $\forall k \ge n_0(\delta)$ we have $$\sum_{j \ge n_0(\delta)}\mu(E_j^{\epsilon}) \lt \delta$$ Suppose that $$E_{\delta}^{\epsilon}=\cup_{j \ge n_0(\delta)}E_j^{\epsilon}, E^{\epsilon}=\cap_{k=1}^{\infty}E_{\frac{1}{k}}^{\epsilon} (\text{I am taking $\delta=\frac{1}{k}$)}$$ Then  $\mu(E^{\epsilon})=0$. As suggested in the answer, I am getting rid of the dependence on $\epsilon$. Let $$E=\cup_{j \in \mathbb{N}}E^{\frac{1}{j}}$$ It is clear that $\mu(E)=0$. Now let $\eta \gt 0$ be fixed. Then there is $i \in \mathbb{N}$ such that $\dfrac{1}{i} \lt \eta$. Then for $x \not \in E, x \not\in E^{\dfrac{1}{i}}$ which means that $x \not \in E_\dfrac{1}{k_1}^{\dfrac{1}{i}}, \forall j \ge n_0\left(\dfrac{1}{k_1}\right)$ .Thus $|f_n(x)-f(x)| \lt \dfrac{1}{i} \lt \eta, \forall n \ge n_0\left(\frac{1}{k_1}\right)$. I am sorry. The notation is a mess. I will edit it afterwards. Thanks for the help!!","['real-analysis', 'measure-theory', 'analysis']"
2007533,Does the converse of Abel's theorem follow from Monotone Convergence Theorem?,"$\newcommand{\seq}[1]{\left(#1\right)}\newcommand{\oival}[1]{{]#1[}}\newcommand{\dif}{\mathrm d}$ Consider the measure space $(\mathbb{W},\mathcal{P}(\mathbb{W}),\mu)$, where $\mu$ is the counting measure on $\mathbb{W}$. Weaker form of the converse of Abel's Theorem: If $\seq{a_j}_{j=0}^\infty$ is a sequence of non-negative (Opposed to any real for Abel's Theorem) real numbers, and $\sum_{j=0}^\infty a_j x^j$ converges for every $x \in \oival{0, 1}$ with $\lim_{x \nearrow 1} \sum_{j=0}^\infty a_j x^j = a$, then $\sum_{j=0}^\infty a_j$ converges with sum $a$. Proof: Let $\seq{x_k}_{k=0}^\infty$ be any monotonically increasing sequence in $\oival{0,1}$ converging to $1$. Define $f(j) = a_j,f_k(j) = a_j x_k^j$. Then $f_k \to f$ pointwisely with $f_k \leq f_{k+1}$ everywhere. By Monotone Convergence Theorem,
$$ \lim_{k \to \infty} \sum_{j=0}^\infty f_k(j) = \lim_{k \to \infty} \int f_k\,\dif\mu = \int f\,\dif\mu = \sum_{j=0}^\infty f(j)
$$ Does this proof hold?","['real-analysis', 'sequences-and-series', 'proof-verification', 'measure-theory', 'convergence-divergence']"
