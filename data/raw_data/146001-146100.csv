question_id,title,body,tags
2388918,Does $\lim_{x \to +\infty} 2g(2x) - g(x) = 0$ imply $\lim_{x \to +\infty} g(x) = 0$?,"Suppose I have a function $g : [0, \infty) \to [0, \infty)$ such that 
$$
\lim_{x \to +\infty} 2g(2x) - g(x) = 0,
$$
and for every $M>0$, the restriction $g\vert_{[0,M]}$ is bounded (for instance, this is the case if $g$ is continuous).
Does it follow that $ \lim_{x \to +\infty} g(x) = 0$ ? I know that $$4g(4x)-g(x) = 2(2g(4x) - g(2x)) + (2g(2x)-g(x)) \to 0, \quad
x \to \infty$$ so $2^n g(2^n x) - g(x) \to 0$ for any $n \geq 1$.
If $g$ is bounded from above by $B>0$, then $|g(2^n x)| \leq \left| \dfrac{2^n g(2^n x) - g(x)}{2^n} \right| + \dfrac{B}{2^n}$, so I guess by taking $x$ and $n$ large enough, we can get $g(x) \to 0$. What about the general case?","['real-analysis', 'limits']"
2388933,What's the first digit from left of $(2016)!$,"What's the  first digit from left of $(2016)!$ I tried to use the Stirling formula $$n!\approx \dfrac{n^n}{e^n}\sqrt{2n\pi},$$ but I only could find the number of the digits, I didn't get  the first digit. So how to calculate by  hand that the first digit is $2?$ use WA: 2325849581803\cdots","['number-theory', 'approximation']"
2388938,Is there any surface (or general manifold) on which the value of $\pi$ is rational?,"Let $X(u,v)=(x(u,v),y(u,v),z(u,v))$ be some map $X:U\to S$ Let $\pi(u,v,d):=C(u,v,d)/d$, with the following definitions: A ""circle""  is the set of all points $p\in S$ of distance $d/2$ to some fixed point $q=X(u,v)$ (where distance is measured using the metric $G=dX^TdX$), And $C(u,v,d)$ is the arclength of the curve (parameterized in local coordinates by $\gamma(u,v,d)$) defined by this set. (Feel free to suggest other more general definitions if you think they might be helpful) First off: Is there any surface other than the plane for which $\pi(u,v,d)=const$? Is there any other surface on which $\pi(u,v,d)=\pi(u,v)$ (i.e. its constant per point) I'm essentially asking if the fact that $\pi$ is irrational is somehow ""built-in"" to reality, or are there some more ""rational"" realities where, say, $\pi==22/7$. ~ Appendix: I'm reminded vaguely of the mean value theorem for harmonic functions (and solutions of the heat equation), which states that the mean value of any harmonic function $f$ over any set of concentric circles is constant. Assuming this even applies in the case of a harmonic function over some general metric space (does it?), can we somehow interpret $C/d$ as the (reciprocal?) mean value over circles of a harmonic function, and thereby at least prove (2)? The mean around some point $(u,v)$ would be calculated as: $\mu(u,v,d)=\frac{\int_\gamma f(\gamma(u,v,d)) ds}{C(u,v,d)}$ Perhaps the above question can then be rephrased as follows: Is there any surface on which we can define some harmonic function for which $\mu(u,v,d)=d/C(u,v,d)$, in which case we get by the mean value theorem that $\pi$ is constant per point, and further is there any such surface+harmonic function combination for which $\mu(u,v,d)=d/C=const.$ ?","['harmonic-functions', 'metric-spaces', 'differential-geometry', 'pi']"
2388978,$Y=${$(x_j/j):(x_j)\in l_\infty$}. Is Y closed in $l_\infty$?,Let $Y=${$(x_j/j):(x_j)\in l_\infty$}. Is Y closed in $l_\infty$? (I could not find any sequence in Y tending to some point outside Y. Please give some hint for such kind of sequence or any other hints/ways.),"['functional-analysis', 'normed-spaces', 'lp-spaces']"
2388980,Limit of product of sequences is the product of the limits of the sequences,"I want to prove that if: $$\lim_{n \to \infty}s_n = L_1, \lim_{n \to \infty}t_n = L_2$$ then $$\lim_{n \to \infty}(s_n t_n) = L_1L_2$$ where $s_n, t_n$ are complex sequences (I'm working through Rudin's baby rudin, and I did this proof slightly different than him, so I would like it if someone took the time to look through my proof and verify whether it's correct) My attempt (scratch proof: finding the appropriate epsilons etc): By definition of limit, there are positive integers $N_1,N_2$ such that: $$n >N_1 \Rightarrow |s_n - L_1| <\epsilon'$$
$$n >N_2 \Rightarrow |t_n - L_2| <\epsilon''$$ where we can freely choose $\epsilon', \epsilon'' >0$ Let $\epsilon > 0$ Now, if $n > \max\{N_1,N_2\}$, then: $$|s_nt_n - L_1L_2| = |s_n(t_n - L_2) + s_nL_2 - L_1L_2|$$
$$\leq |s_n||t_n - L_2| + |L_2||s_n - L_1|$$
$$\leq |s_n|\epsilon'' + |L_2|\epsilon'$$ We want this expression to be smaller than $\epsilon$, but we can't make our $\epsilon$ depend on $n$, therefore we have to find an upper bound for $|s_n|$ There is a positive integer $N_3$ such that: $$n > N_3 \Rightarrow |s_n - L_1| < 1$$
$$\Rightarrow |s_n| < 1 + |L_1|$$ so for $n > \max\{N_1,N_2,N_3\}$, we have: $$ |s_n|\epsilon'' + |L_2|\epsilon' < (1 + |L_1|)\epsilon'' + |L_2|\epsilon'$$ and by chosing $\epsilon'' = \epsilon' = \frac{\epsilon}{1+|L_1|+|L_2|}$, the expression becomes smaller than $\epsilon$ Rigorous proof Let $\epsilon > 0$ By definition of limit, there are positive integers $N_1,N_2, N_3$ such that: $$n >N_1 \Rightarrow |s_n - L_1| <\frac{\epsilon}{1+|L_1|+|L_2|}$$
$$n >N_2 \Rightarrow |t_n - L_2| <\frac{\epsilon}{1+|L_1|+|L_2|}$$
$$n > N_3 \Rightarrow |s_n - L_1| < 1 \Rightarrow |s_n| < 1 + |L_1|$$ and for $n > \max\{N_1,N_2,N_3\}$, we have: $$|s_nt_n - L_1L_2| = |s_n(t_n - L_2) + s_nL_2 - L_1L_2|$$
$$\leq |s_n||t_n - L_2| + |L_2||s_n - L_1|$$
$$< (1 + |L_1|)\frac{\epsilon}{1+|L_1|+|L_2|} + |L_2|\frac{\epsilon}{1+|L_1|+|L_2|} = \frac{\epsilon}{1+|L_1|+|L_2|}(1+ |L_1| + |L_2|) = \epsilon$$ Alternative proof: Let $\epsilon > 0$ $(s_n)$ converges, so $(|s_n|)$ converges and it is bounded, meaning that there is a positive real number $S$ such that $|s_n| \leq S$ for every positive $n$. By definition of limit, there are positive integers $N_1,N_2$ such that: $$n >N_1 \Rightarrow |s_n - L_1| <\frac{\epsilon}{S + |L_2|}$$
$$n >N_2 \Rightarrow |t_n - L_2| <\frac{\epsilon}{S + |L_2|}$$ Now, for $n > \max\{N_1,N_2\}$, we have: $$|s_nt_n - L_1L_2| = |s_n(t_n - L_2) + s_nL_2 - L_1L_2|$$
$$\leq |s_n||t_n - L_2| + |L_2||s_n - L_1|$$
$$< (S+|L_2|)\frac{\epsilon}{S + |L_2|} = \epsilon $$ Note that this wouldn't work whenever $S + |L_2| = 0$. However, if $S=0$, then $s_n$ is the null-sequence and the theorem is trivial, so we can safely assume $S \neq 0$ such that the denominator never becomes $0$. QED Is this correct?","['real-analysis', 'proof-verification', 'limits']"
2388981,Locating zeros of polynomial,"Given polynomial with real coefficients 
$$p(x) = x^n + a_1x^{n-1}+...+a_{n-1}x+a_n,$$
is there some method for deciding if it has zeros in some interval, for example $(0,1)$? There exist methods for either positive or negative zeros but I am interested for zeros in a specific interval.","['numerical-methods', 'real-analysis', 'polynomials', 'roots']"
2389057,Fast/smart way to write polar curve in cartesian,"Is there a fast way to write the curve:
$$r=\frac{a}{1-\frac{1}{\sqrt{2}}\cos(\theta)}$$
as a cartesian curve $f(x,y)=0$? It seems I can take 
$$r(1-\frac{1}{\sqrt{2}}\cos(\theta)) = a$$
$$r-\frac{x}{\sqrt{2}}=a$$
$$\sqrt{x^2+y^2}-\frac{x}{\sqrt{2}}=a$$
$$x^2+y^2=(a+\frac{x}{\sqrt{2}})^2$$
and then expand out, and complete the square. But I seem to get an error. Perhaps there is a smart way to do this?","['algebra-precalculus', 'calculus']"
2389074,Multivariable derivative: Limit definition,"Consider a path through a domain in $\mathbb{R}^2$ given by $\mathbf{c}(t) = (x(t), y(t))$. We wish to find the rate of change of a function $f(x,y)$ along this path. Therefore, we wish to compute $\frac{d}{dt}f(\mathbf{c}(t))$. My question is about the limit definition. My book gives the limit definition of the derivative as $$
\frac{d}{dt}f(\mathbf{c}(t)) = \lim_{h\to\ 0}\frac{f(x(t+h),y(t+h)) - f(x(t),y(t))}{h}\tag{1}$$ Question Why isn't the derivative written as:
$$\frac{d}{d\mathbf{c}'(t)}f(\mathbf{c}(t)) = \lim_{h\to\ 0}\frac{f(x(t+h),y(t+h)) - f(x(t),y(t))}{\sqrt{(x(t+h)-x(t))^2 + (y(t+h) - y(t))^2}}\tag{2}$$
$$\frac{d}{d\mathbf{c}'(t)}f(\mathbf{c}(t)) = \lim_{\Delta x,\Delta y\to\ 0}\frac{f(x(t) + \Delta x,y(t) + \Delta y) - f(x(t),y(t))}{\sqrt{\Delta x^2 + \Delta y^2}}$$
$$\Delta x = x(t+h) - x(t) \\
\Delta y = y(t+h) - y(t)$$ where $d/d\mathbf{c}'(t)$ indicates the derivative in the direction of the tangent vector of the path. After reading the comments and responses under this question, my answer to my own question (with their help) is that these two limits speak to different derivatives. The first limit indicates the rate of change of $f$ as the parameter $t$ is changed. It indicates change in $f$ per unit $t$ ($t$ usually stands for time, but as we'll see below, it's just an arbitrary parameter. $t$ doesn't have to be 'time'). This derivative will depend on how you parameterize your path. A path can be parameterized in infinitely many ways ($\mathbf{c}_2(t)$ might move along your path twice as fast as $\mathbf{c}_1(t)$ for instance). On the other hand, the second limit is simply the derivative of $f(x,y) = f(\mathbf{c}(t))$. It's just the derivative of the outside function with respect to the inside variables (instead of the derivative of the outside function with respect to the inside-inside variable - remember that if $f(x) = f(g(t))$, $f$ can either change directly through $x$, or indirectly through $t$. Because each case changes the function either by changing the $x$ or $t$ knob, we can ask for either $d/dx$ or $d/dt$). But back to equation $\textbf{(2)}$, since the inside variables $(x,y)$ form a path $\mathbf{c}(t)$, I don't write $\partial/\partial x$ or $\partial /\partial y$, but $d/d\mathbf{c}'(t)$ since $x,y$ are confined to change along a path. As you take the limit, you see that the derivative is in a direction tangent to your path, which is why I use $d/d\mathbf{c}'(t)$ since $\mathbf{c}'(t)$ is the tangent vector to the path. Again, the derivative represents the rate of change with respect to tangent lines to this path (you can see the direction that this derivative is taken in at a given $t$ by looking at the right hand side of equation $\textbf{(2)}$). This derivative indicates change in $f$ per unit change in tangent direction. This derivative will depend on your parameterization. Comparisons to the 1-variable case: The first limit (1) Let's discuss the first limit (the derivative of $f$ with respect to the 'inside-inside' variable. How does $f$ change indirectly through $t$). Is there a 1D analog? Yes. Consider the composite function $f(x) = f(x(t))$. What's the derivative of $f$ with respect to $t$? We can write the limit definition: $$\frac{df(x(t))}{dt} = \lim_{h\to\ 0}\frac{f(x(t+h))-f(x(t))}{h}\tag{3}$$
This is indeed the 1D version of the first limit above $\textbf{(1)}$. To further drive the comparison, we know that $\frac{df}{dt} = f'(x(t))x'(t) = (df/dx)(dx/dt)$ = derivative of the outside times derivative of the inside. And in the multivariate case, that first limit can be shown to equal $\nabla f \cdot \mathbf{c}'(t)$ = derivative of the outside times derivative of the inside and do a sum for each variable. Indeed, the multivariate chain rule is in fact the generalization of the 1D chain rule. $f(x(t))$ is a composite function. But so to is $f(x(t),y(t)) = f(\mathbf{c}(t))$, just in a multivariate way. $\mathbf{c}(t)$ parameterizes how you move along the $x$ and $y$ axes. In the single variable case $f(x(t))$, we are parameterizing how we move along the only axis that $f$ has access to, which is the $x$ axis ($x = x(t)$). We usually see composite functions as $f(g(x)) = f(u)$, in which case we are parameterizing how $f$ moves along the $u$ axis with parameterization $g(x)$ (I'm just using different variables to show that a parameter is a parameter - It doesn't have to be time). Again this derivative of the 'inside-inside' variable will depend on your parameterization, which we can clearly see by looking at the 1D case (just take simple examples and see how $x'(t)$ changes). For instance, in 1D the only path you have to parameterize is the real line. That's the only path (let the path be the whole real line). Therefore different parameterizations will have different $x'(t)$. That is, different parameterizations will have different 'speeds' (again note that if $x$ is parameterized by $x(t)$, $x' = x'(t)$ is only a 'speed' if $x$ has units of meters and $t$ units of time. By 'speed' of the parameterization, I just mean derivative. To make this clearer, let $f(u) = f(g(k))$. The speed of the parameterization is $du/dk = g'(k)$). The change in $f$ per unit parameter will depend on how your path is parameterized. If $f$ is in temperature units Kelvin, $df(x(t))/dt$ could be 2 Kelvin per second for one parameterization and 3 Kelvin per second for another. Comparisons to the 1-variable case: The second limit (2) Let's look at the 1-variable case $f(u) = f(g(t))$. What is $df/du$? This is just the derivative of the outside function with respect to the inside function (it's how $f$ changes directly through it's domain variables as opposed to indirectly through the parameter). It's limit definition is given by $$\frac{df(u)}{du} = \lim_{k\to\ 0}\frac{f(g(t) + k) - f(g(t))}{k}$$ 
which setting $k = g(t+h) - g(t)$ gives $$\frac{df(u)}{du} = \lim_{h\to\ 0}\frac{f(g(t+h)) - f(g(t))}{g(t+h) - g(t)}\tag{4}$$ 
Either way hopefully you can get to this line without going through the first. All you're doing is taking the function at two different values and dividing by the difference. This is the 1D analog of the second limit $\textbf{(2)}$. The main difference is that in 1D, I can only move along my parameterization, which here is the $u$ axis. Therefore I write $d/du$. In the multivariate case, again I can only move along my parameterization. However, as we take a small step size $\Delta x$ and $\Delta y$ allowed by my parameterization that we let go to zero (by looking at $\textbf{(2)}$ hopefully you can see that $h \to 0$ is equivalent to $\Delta x \to 0$ or $\Delta y \to 0$), we are finding the rate of change of the function $f$ in the tangent direction to the path (think of two points on your path $\mathbf{c}(t)$. Fix one and allow the other to approach it. The two points form a tangent line in the limit). Therefore, I use $d/d\mathbf{c}'(t)$ to denote direction of the derivative. It's always a direction tangent to the path and that tangent direction changes over the path. In 1D, the direction tangent to the path was just the path itself (the axis), for the whole path. This derivative $\textbf{(2)}$ and $\textbf{(4)}$) will depend on your parameterization, which we can see by taking simple examples and looking at the 1D case $\textbf{(4)}$. Equations $\textbf{(2)}$ and $\textbf{(4)}$ give the rate of change of $f$ along the tangent direction to the path (which depends on your parameterization). Equations $\textbf{(1)}$ and $\textbf{(3)}$ give the rate of change of $f$ with respect to the parameter (which also depends on your parameterization). Comments/Complaints on the Directional Derivative A pure directional derivative is given by equation $\textbf{(2)}$ where $\mathbf{c}(t)$ is a line. That's it, end of story. For a vector $\vec{v} = (v_x, v_y)$, a parameterization along this direction is $x(t) = x + v_xt$ and $y(t) = y + v_yt$. Therefore, the directional derivative, given by equation $\textbf{(2)}$ is: $$\frac{df(x(t),y(t))}{d\vec{v}} = \lim_{h\to 0} = \frac{f(x(t) + v_xh, y(t) + v_yh) - f(x(t), y(t))}{h}$$ 
$\textbf{IF}$ $\vec{v}$ is a unit vector so that $\sqrt{v_x^2 + v_y^2}$ = 1. However, textbooks will sometimes define this as the directional derivative even if the vector $\vec{v}$ is not a unit vector. I'm not a fan of this because that's not what equation $\textbf{(2)}$ says to do (and I find that $\textbf{(2)}$ makes sense). Essentially what they've done is $\textbf{redefine}$ what it means to be a unit vector. This is fine, but now we take $\vec{v}$ whatever it is, to be the unit vector standard. Therefore, their derivative which is still a rate of change of $f$ per unit distance, has a different meaning of 'per unit distance' then my definition of per unit distance based on my idea of a unit vector. The reason why they do this is because they understand what they are doing (redefining what a unit vector means - which is fine - but for 1st time learners, I think it can be confusing if you don't show that the directional derivative is essentially equation $\textbf{(2)}$.)","['multivariable-calculus', 'calculus']"
2389097,How to derive the Taylor's theorem logically?,"I can't understand how derive the Talyor's theorem logically: Well, the first two terms are quite easy to think of as $f(a)$ + correction term (i.e. slope times change in x-coordinate: $(x-a)$. But how to derive the other correction terms just by logic?","['derivatives', 'taylor-expansion', 'calculus']"
2389099,If the polynomial $f_1(x^3)+xf_2(x^3)$ is divisible by $x^2+x+1$ then $f_1$ and $f_2$ are divisible by $x-1$,"I've tried doing some kind of brute force here, but I'm pretty sure that there has to be a trick which solves this in a couple of lines. I wrote $$
f_1(x^3)=\sum_{i=0}^n a_i x^{3i}, \ f_2(x^3)=\sum_{j=0}^m b_j x^{3j},
$$ and then used the fact that the sum of the two is divisible by $x^2+x+1$ to obtain $$
f_1(x^3)+xf_2(x^3)=\sum_{i=0}^n a_i x^{3i} + \sum_{j=0}^m b_j x^{3j+1} = (x^2+x+1)q(x),
$$ where $q(x)$ is the quotient. However, I have no idea where to go from here. How do I incorporate the $x-1$ part? And how do I switch to the fact that $f_1(x)$ and $f_2(x)$ are divisible by $x-1$? I thought of maybe using the fact that $x^3-1=(x-1)(x^2+x+1)$, but again I'm stuck on where to use it. EDIT: Sorry, there was one $x$ missing in my formulation. The place where I found it also had the $x$ missing, but the original exercise says $f_1(x^3)+xf_2(x^3)$.","['algebra-precalculus', 'polynomials', 'divisibility']"
2389100,composition of the derivative of Dirac delta with a function,"I found this question where a nice formula is given for the composition $\delta(f(x))$. Is there a similar general formula for $\delta'(f(x))$? In other words, is there a nice way to express the integral $$ \displaystyle\int_{\mathbb{R}^n} \delta'(f(x))g(x) dx,$$ where $f,g:\mathbb{R}^n\to \mathbb{R}$?","['dirac-delta', 'distribution-theory', 'analysis']"
2389154,general form of functions whose derivatives can be written in terms of the function itself?,"A classic example for this would be the exponential function, or sigmoid function, or even tanh function. But is there a general form for all these functions, in such a way that the general form follows the same property? (ie the general form function's derivative can be written in terms of the function itself...)","['derivatives', 'hyperbolic-functions', 'exponential-function', 'calculus']"
2389204,$f(g(x))=g(f(x))$ implies $f(c)=g(c)$ for some $c$,"Let $f$ and $g$ be continuous functions and map from $[0,1]$ to $[0,1]$. Also let $f(g(x)) = g(f(x))$ . Prove that there exists $c$ from $[0,1]$ such that $f(c)=g(c)$. I will try with contradiction. Let $h(x) = f(x) - g(x) > 0$ for all $x$ from $[0,1]$. Since $f(x)$ maps from $[0,1]$ to $[0,1]$ and is greater then $g$ for all $x$ from $[0,1]$ then this implies that $g(x)$ is not an element of $[0,1]$ for all $x$ from $[0,1]$. This is a contradiction, so there exists $c$ from $[0,1]$ such that $f(c)=g(c)$. Problem here is that I never used fact that 
$f(g(x)) = g(f(x))$ which bothers me. Is proof correct or there is hole somewhere?","['real-analysis', 'proof-verification']"
2389222,Arguments for valid degree sequences or not,"The following are degree sequences for a simple graph on 6 vertices that may or may not exist. I've started wondering about my methods of proof and if improvements could be made to these arguments. $(a)\quad\quad5, 3, 2, 2, 2$ Only five of the vertices have a degree. Not possible for one vertex to connect to four other vertices with a degree of 5 in a simple graph on 6 vertices. $(b)\quad\quad 3, 3, 3, 3, 2$ Possible. I've drawn it. $(c)\quad\quad 3, 3, 3, 2, 2$ By the handshake theorem; 13 = 2|E| |E| = 6.5. Graph isn't possible. $(d)\quad\quad 5, 5, 3, 2, 2, 1$ If two vertices have a degree of five amongst a total of six vertices; it's not possible for one of the vertices have a degree of one. Graph isn't possible. $(e) \quad\quad5, 1, 1, 1, 1, 1$ Possible. I've drawn it. $(f)\quad\quad 3, 3, 3, 3, 0, 0$ Possible. I've drawn it as $K_4$ with two additional isolated vertices.","['graph-theory', 'alternative-proof', 'proof-verification', 'discrete-mathematics']"
2389275,Prove that $|A|=|\mathbb R |$,"Consider a set $A=\{f \in \mathbb N^\mathbb N : (\forall n)\; f(n)\mid f(n+1)\}$, where 
$\mid$ stands for a relation of divisibility. Prove that $|A|=|\mathbb R |$ My attempts: 
It was easy to show that $|A|\leqslant|\mathbb R |$ since $f \in \mathbb N^\mathbb N$, and $\mathbb N^\mathbb N = \mathbb R$. 
Unfortunately I have no idea how to show that $|A|\geqslant|\mathbb R |$. Could you help me, please?",['elementary-set-theory']
2389303,What is strictly well-ordered under $\in$,"I am studying from a set of notes (otherwise quite excellent) which does not explicitly specify some definitions of ""ordering."" I have tried to accumulate the various pieces from various discussions and proofs in the text, but am having a hard time putting them together. In one place it says strictly well-orderered by $\in$ is $n\lt m$ iff $n\in m$. In another it says a well-ordered set is totally ordered in which every non-empty set has a minimal element. And one aspect of the definition of total ordering is that inequality satisfied by "" minimal "" is ""weak"" ($\leq$) rather than ""strict"" ($\lt$). Lastly, one of the two features of the definition of an ordinal is that it is strictly well-orderered by $\in$ . M confusion comes in a proof showing that an $\alpha$ is an ordinal because ""it has a minimal element and thus is well-ordered under $\in$ ."" Whereas, the definition of an ordinal says nothing about a minimal element. Are they the same thing? And why does it not say: strictly well-ordered by $\in$? I know this is probably torturous reading this and I've tried to be as clear as possible. Perhaps it would be easier to suggest a reference where these aspects are delineated. I've tried wikipedia and several well-known texts. Thanks","['elementary-set-theory', 'definition']"
2389312,Does there exist some strictly positive function such that both the derivative and second derivative are strictly negative?,If $f(x) > 0$ over the reals is it possible to have $f'(x) < 0$ and $f''(x)< 0 $ over the reals? Assuming $f$ can be differentiated twice.,"['derivatives', 'real-analysis', 'calculus']"
2389322,Graph on $2017$ edges with chromatic number $3$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Graph $G$ is simple, has chromatic number $3$ and $2017$ edges. How can I figure out if this graph is possible or not?","['graph-theory', 'discrete-mathematics']"
2389324,Limit of Integral with variable limits of integration,"For a continuous Function $f$, prove that: $$\lim_{x\to0^+}\int_{x}^{2x} \frac{1}{t} f(t) dt = ln(2)f(0)$$ I have already concluded that since f is continuous, it's therefore integrable.Moreover I assumed there is a function $F$ 
$$F(x)=\int_{x}^{2x} f(s)ds$$ 
in order to simplify the limit expression by partial integration. Unfortunately that gave me no solution and I am stuck.","['continuity', 'integration', 'functions', 'limits']"
2389349,Dual Norm: $\|fx\|\leq \|f\|\|x\|$ ???,I'm studying Functional analysis and at this Wikipedia link: https://en.wikipedia.org/wiki/Dual_norm In the proof of Theorem 1 there is one passage where apparently it's used the fact that: $$\|fx\|\leq \|f\|\|x\|$$ I can't understand why this is true.,"['functional-analysis', 'normed-spaces', 'dual-spaces']"
2389376,Is there a non-trivial group $C$ such that $A*C \cong B*C$ implies $A \cong B$?,"I recently learnt that finite groups are cancellable from direct products, i.e. if $F$ is a finite group and $A\times F \cong B\times F$, then $A \cong B$. A proof can be found in this note by Hirshon. In the same note, it is shown that $\mathbb{Z}$ is not cancellable, but if we only allow $A$ and $B$ to be abelian, it is (see here ). I would like to know if there are any groups that can be cancelled from free products rather than direct products. That is: Is there a non-trivial group $C$ such that $A*C \cong B*C$ implies $A \cong B$? If it helps, I would also be interested in the case where the groups are finitely generated. It is certainly not true that every group is cancellable in free products. For example, if $A$, $B$, $C$ are the free groups on one, two, and infinitely many generators respectively, then $A*C \cong C \cong B*C$ but $A\not\cong B$. Many non-examples can be constructed this way, but they are all infinitely generated. This leads to the question: Are there finitely generated groups $A, B, C$ with $A \not\cong B$ but $A*C \cong B*C$?","['free-product', 'group-theory']"
2389407,Error in the book? Or wrong logic?,"In the book ""Elementary linear algebra with supplemental applications"", 11th edition, page 81,task 127, the following task appears: Show that if $A$ is a square matrix such that $A^K=0$ for some positive integer $K$, then the matrix $A$ is invertible and the inverse of the matrix $(I-A)$ is equal to $I + A + A^2 + ... + A^{K-1}$. I have no difficulty in arriving at the identity given that $A^K = 0$, however I think there is something wrong here... Consider the following: Let $A$ be a square matrix not equal to 0 , such that $A^K=0$ for some nonnegative integer $K \ge 2$, and assume for contradiction that $A^{-1}$ exists. Then we can deduce the following: $$A^K=0 \implies A^K A^{-1}=0 \implies A^{K-1} A A^{-1} = 0 \implies A^{K-1} I = 0$$ and we are left with $A^{K-1} = 0$. Thus, $A^K=0 \implies A^{K-1} = 0$, and using the same logic (multiplying by $A^{-1}$), we deduce $A^K=0 \implies A^{K-1} = 0 \implies \cdots \implies A^2 = 0 \implies A = 0$, a contradiction. Thus, the three statements ""$A$ does not equal $0$"", ""$A^{-1}$ exists"" and ""$A^K=0$ for some nonnegative integer $K$ greater than or equal to $2$"" cannot all be true at the same time. And thus the task in the book is inncorrect since it states that $A^{-1}$ exists. Is the book wrong, or is there something wrong with my use of logic here? :)","['matrices', 'linear-algebra']"
2389446,Convergence Proof: Difference within Function of Epsilon,"Here's the problem, and then my proposed proof: Suppose that $\phi : (0, \infty) \mapsto (0, \infty)$ is a function such that $\lim_{\epsilon \to 0}\phi(\epsilon) = 0.$ Let $a_1,a_2,\dots$ be a sequence in $\mathbb{R}^n$. Show that this sequence converges to $a$ if and only if for any $\epsilon > 0$, there exists $N$ such that for $n > N$, we have $|a_n-a|\leq \phi(\epsilon).$ (from Vector Calculus, Linear Algebra, and Differential Forms (Hubbard and Hubbard)) My proof is for the first statement (the if, not the only if). First, to avoid confusion, the argument of the function $\phi$ will be renamed to $\epsilon'$.By the definition of the limit, the statement that $\lim_{\epsilon \to 0}\phi(\epsilon) = 0$ is the same as saying that $$\forall\epsilon >0, \exists \delta > 0 \text{ such that } |\epsilon'| \leq \delta \implies |\phi(\epsilon')| \leq \epsilon $$ By assumption, $|a_n - a| \leq \phi(\epsilon')$, and from the statement above, we get $$|a_n - a| \leq \phi(\epsilon') \leq \epsilon$$
We want $\phi(\epsilon') \leq \epsilon'$. However, since it must be true for all $\epsilon$ and all $\epsilon'$ greater than 0, the two can be taken to be equal. Therefore,
$$|a_n-a| \leq \epsilon'$$ I'm unsure about the final step, where I say that the unprimed and primed epsilon can be taken to be equal. Is this correct?","['epsilon-delta', 'convergence-divergence', 'proof-verification', 'limits']"
2389458,Is this ideal two-sided?,"Suppose R is a ring with identity and J is the left ideal of R generated by $\{ab - ba: a, b \in R\}$. Does J always have to be a two-sided ideal? I failed to construct the counterexample, but I do not know how to prove this statement either. Any help will be appreciated.","['abstract-algebra', 'ring-theory', 'ideals']"
2389527,"If $\operatorname{Deg} D=0$ and $\dim L(D)=1$, then $D$ is principal","Let $X$ a compact Riemann surface and $D$ a divisor with $\operatorname{Deg} D=0$ and $\dim L(D)=1$. Why is then $D$ principal? I already have seen the comments to this answer , but somehow I don't get it. My attempt so far: If $\dim L(D)=1$, then there is some meromorphic function $f$ such that $\operatorname{div} f \ge -D$, and every other element of $L(D)$ is a multiple of it. Probably, $D=\operatorname{div} \frac 1 f$, which would follow if $\operatorname{div} f = -D$, but why is that?","['riemann-surfaces', 'complex-geometry', 'algebraic-geometry']"
2389537,Is there a geometric method to show $\sin x \sim x- \frac{x^3}{6}$,"I found a geometric method to show $$\text{when}\; x\to 0 \space , \space \cos x\sim 1-\frac{x^2}{2}$$ like below : Suppose $R_{circle}=1 \to \overline{AB} =2$ in $\Delta AMB$ we have $$\overline{AM}^2=\overline{AB}\cdot\overline{AH} \tag{*}$$and 
$$\overline{AH}=\overline{OA}-\overline{OH}=1-\cos x$$ when $x$ is very small w.r.t. * we can conclude $$x^2 \approx 2(1-\cos x) \\\to \cos x \sim 1- \frac{x^2}{2}$$
Now I have two question : $\bf{1}:$ Is there other idea(s) to prove (except Taylor series) $x\to 0  , \space \cos x\sim 1-\frac{x^2}{2}\\$ $\bf{2}:$ How can show $\sin x \sim x- \frac{x^3}{6}$ with a geometric concept ? Thanks in advance.","['algebra-precalculus', 'limits', 'trigonometry', 'geometry']"
2389605,"If $a_n = \sum\limits_{r=0}^n \binom{n}{r} b_r$, prove $(-1)^n b_n = \sum\limits_{s=0}^n \binom{n}{s} (-1)^s a_s$","Suppose that sequences of real numbers satisfy: \begin{align*}
  a_n &= \sum\limits_{r=0}^n \binom{n}{r} b_r \\
\end{align*} Prove that: \begin{align*}
  (-1)^n b_n &= \sum\limits_{s=0}^n \binom{n}{s} (-1)^s a_s \\
\end{align*} My work: The $n=0$ case: \begin{align*}
  a_0 &= b_0 \\
  b_0 &= a_0 \\
\end{align*} Then $n=1$ case: \begin{align*}
  a_1 &= \binom{1}{0} b_0 + \binom{1}{1} b_1 = b_0 + b_1 \\
  -b_1 &= \binom{1}{0} a_0 - \binom{1}{1} a_1 = a_0 - a_1 \\
  b_1 &= a_1 - a_0 = b_0 + b_1 - a_0 = b_1 \\
\end{align*} The inductive step: \begin{align*}
  (-1)^{n+1} b_{n+1} &= \sum\limits_{s=0}^{n+1} \binom{n+1}{s} (-1)^s a_s \\
\end{align*} I'm not sure where to go from here. I tried substituting $a_s$ into that last equation and it didn't help. Any ideas?","['combinatorics', 'summation', 'binomial-coefficients']"
2389622,When is the hyperspace of compact subsets a $k$-space?,"Let $X$ be a topological space and let $\mathcal{K}(X)$ denote the hyperspace of all its compact subspaces endowed with the Vietoris topology. When is $\mathcal{K}(X)$ a $k$-space? We know that if $X$ is metrizable, then $\mathcal{K}(X)$ is also metrizable, and hence it is a $k$-space. Also, if $X$ is locally compact, then every compact $K ⊆ X$ has a compact neighborhood, and so $\mathcal{K}(X)$ is a $k$-space. On the other hand, if $\mathcal{K}(X)$ is a $k$-space and $X$ is Hausdorff, then $X$ is closed in $\mathcal{K}(X)$, and so is itself a $k$-space. Is $X$ being a $k$-space a sufficient condition for $\mathcal{K}(X)$ being a $k$-space? Or are there other sufficient conditions weaker than metrizability and local compactness? Is there any reference for results like this?","['reference-request', 'general-topology']"
2389623,Path-Independence and the Residue Theorem,"My question concerns the path-independence integrals calculated using the residue theorem. Consider the integral $$I=\int_{-\infty}^\infty\! \frac{1}{(z+i)(z+2i)(z+3i)}\ \mathrm{d}z. $$ It seems that by integrating over different contours, one could arrive at different values of $I$.  For example, if one chose a semi-circle in the upper half-plane as a contour, applying Cauchy's Residue Theorem would show $I=0$.  On the other hand if, if one chose a contour in the lower half-plane, one would arrive at $I=-2\pi i\sum_{j=1}^3\mathrm{Res}(f;z_j)$, where $z_j=-i,\ -2i, -3i$.  However, it seems like the value of $I$ should be unique and not depend upon the chosen contour. Is this logic correct?  This question is driving me mad, and I would very much appreciate any help!! Edit: Forgot a minus sign in application of Residue Theorem.","['complex-analysis', 'contour-integration', 'residue-calculus']"
2389630,First to 1000 rolls wins,"You and your friend each have a standard $6$-sided die with sides numbered $1, 2, \ldots 6$, every side has an equal probability of arising in a random roll. You throw the cube first* the number that land, is the amount of times your friend need to throw his cube. The sum of all the numbers that landed from the amount of times your friend threw, is the amount of times you need to throw your dice. The sum of all the numbers that landed from the amount of times your friend threw, is the amount of times you need to throw your dice. And then it goes and goes. What is the probability that you will be the first one who need to throw more than $1000$ throws. 
For example: You threw 3 Your friend threw 3 times and got: 2,5,6. The sum is 13. You threw $13$ times and got: $5,2,3,4,6,1,2,5,3,4,1,3,6$. The sum is $45$. Your friend threw $45$ times and got: ..... The sum is $X$ You threw $X$ times and got: .... The sum is $Y$
....
What is the probability that you threw before your friend more than $1000$ throws. *I think it would be interesting the same question but you throw second.",['probability']
2389635,Finite symmetries for embeddings of genus $\geq 2$ surfaces in $\mathbb{R}^3$,"Let $f : \Sigma \to \mathbb{R}^3$ be a genus $g \geq 2$ surface smoothly embedded in $\mathbb{R}^3$.  Let 
$$
G(f) = \{ \phi \in \text{Isom}(\mathbb{R}^3) : \phi(f(\Sigma)) = f(\Sigma)\}
$$ 
be the group of isometries of $\mathbb{R}^3$ that preserve $\Sigma$.  Is the order of $G(f)$ always finite?  If so is there a bound on the order of $G(f)$ (presumably in terms of $g$)?","['euclidean-geometry', 'riemannian-geometry', 'differential-geometry', 'geometry']"
2389644,Zeroes of function with real exponents,"Let real $x \geq 0 $ and real $p > 2$. Let $ f(x) = (x - 1)(x + 1)^{p - 1} - x^p + 1$. Show that, for the given range of $x$ and $p$,  $f(x)=0$ only for $x=0$ and $x=1$. Since $f(x)$ is not convex, I find it difficult to show that $f(x) < 0$ for $0<x<1$ and  $f(x) > 0$ for $x>1$. EDIT (generalization): the same zeroes hold for all  $p>0$ ; $p \neq 1$ , $p \neq 2$.","['algebra-precalculus', 'real-analysis', 'functions']"
2389678,Showing Two Operators Share an Eigenvector,"Question 1 - Let $A$ and $B$ be complex $n \times n$ matrices such that $AB = BA^2$, and assume $A$ has no eigenvalues of absolute value 1. Prove that $A$ and $B$ have a common (nonzero) eigenvector. Question 2 - Let $A$ and $B$ denote real $n \times n$ symmetric matrices such that $AB = BA$. Prove that $A$ and $B$ have a common eigenvector in $\mathbb{R}^n$. For the second question. Suppose $v$ is an eigenvector of $A$ with eigenvalue $\lambda$ so $Av=\lambda v$. Then $$A(Bv) = B(Av) = B(\lambda v) = \lambda Bv$$ which shows that the eigenspace corresponding to $\lambda$ is invariant under B. Now what....","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
2389689,Expected value of adjacent pairs in a deck of 52?,"I am having trouble wrapping this around my head. I believe that using an indicator random variable would be the best approach. Let N be the number of adjacent pairs. The probability of an adjacent pair would be 3/51. Given that the first card is a set value, the probability of the card to its right being the same value would be 3/51. So then E[I]=3/51. I would like to believe that E[N] would equal=(3/51)*26. My thinking is that the deck of cards is set in a format of ABABABAB. The value of A is the key card. The value of B is the card that must match A. So if A were to be the King of Spades, but B were the Queen of diamonds, that pair would not be counted along with the other lonesome King card that should've been with the King of Spades. That is why if one King card indicates that it is not a pair, the other king is automatically discarded as a potential pair. This is done with all cards so that is why you multiply it by 26. This is just my thinking, but can someone give me some guidance? Edit: Typo","['probability', 'random-variables', 'discrete-mathematics']"
2389735,Unbiased estimator of the variance with known population size,"The variance is defined as $$\sigma^2 = \frac{\sum_{i=1}^n (x_i - \bar x)^2}{n}$$ where, $\bar x = \frac{\sum_{i=1}^n x_i}{n}$ If someone wants to estimate this parameter from a sample (s)he must do $$s^2 = \frac{\sum_{i=1}^n (x_i - \bar x)^2}{n-1}$$ as the variance (as would be calculated by $\sigma^2$) of a sample decreases with the size of the sample. $s^2$ is an unbiased estimator of $\sigma^2$ only if sampling is with replacement (which is not the case in the model of interest here) or if the population is infinite. Let's call $N$ the size of the population ($n$ being the size of the sample). To the extreme, if $n=N$ (so that every individual is sampled), then $s^2$ will definitely be a biased estimator of the variance in the population. What is an unbiased estimator of the variance of the population from a sample knowing the population size $N$?","['probability-theory', 'variance', 'statistics', 'probability', 'parameter-estimation']"
2389736,Does Stone-Weierstrass hold for sets of functions that only separate points on a dense subspace?,Supose $X$ is a compact Hausdorff topological space and $Y \subseteq X$ a dense subset. If $S$ is a set of functions in $C(X)$ such that separates points in $Y$ then the Stone-Weierstrass theorem still hold?,"['functional-analysis', 'general-topology']"
2389756,Finding the smallest partition of a set S which satisfies a given property.,"Here is a problem I've encountered while working on graph colouring, and I haven't been able to find the solution (both online and with my own efforts). A problem like this may have been studied previously, perhaps in another guise. Any insights are appreciated. Let $S$ be a set whose elements are the $\binom{n}{k}$ $k$-subsets of some $n$-set. Let $S_1, S_2, \ldots, S_t$ denote a partition of $S$. What is the smallest size of a partition (the smallest value of $t$) such that for each $i \in \{1,2,\ldots, t\}$ and each element $x$ of the $n$-set, $x$ is an element of at most $\ell$ of the $k$-subsets in $S_i$? Let $f(n,k,\ell)$ denote the smallest size of such a partition. An example for $n = 4$, $k = 2$, and $\ell = 2$: Here, $S = \{ \{1,2\}, \{1,3\}, \{1,4\}, \{2,3\}, \{2,4\}, \{3,4\} \}$. We can easily see that $f(4,2,2) = 2$, as $S_1 = \{ \{1,2\}, \{1,3\}, \{3,4\}\}, S_2 = \{ \{1,4\}, \{2,3\}, \{2,4\}\}$ is a valid partition, and no valid partition of size $1$ exists because each element appears in $3 > \ell$ sets. So far, I've just been able to determine a simple upper bound for $f(n,k,\ell)$. Let $1,2\ldots, n$ be the elements of the $n$-set. Let $X_i$, for $1 \leq i \leq n - k + 1$, be the set of subsets which contain the element $i$, and do not contain any element $j$ such that $j < i$. Then, $X_1,X_2,\ldots, X_{n - k + 1}$ is a partition of $S$. Each $X_i$ can itself be partitioned into $\alpha_i = \left \lceil \frac{|X_i|}{\ell} \right \rceil$ sets $S^i_1, S^i_2, \ldots, S^i_{\alpha_i}$ each which contain at most  $\ell$ $k$-subsets. Then the partition $S^1_1, S^1_2, \ldots, S^1_{\alpha_i}, S^2_1, S^2_2, \ldots, S^{n-k+1}_{\alpha_{n-k+1}}$ of $S$ is a partition of size $\alpha_1 + \alpha_2 + \ldots + \alpha_{n-k+1}$ which satisfies our condition, and so $f(n,k,\ell) \leq \sum\limits^{n-k+1}_{i=1} \alpha_i$, where $\alpha_i = \left \lceil \frac{|X_i|}{\ell} \right \rceil = \left \lceil \binom{n-i}{k-1}/\ell \right \rceil$. Unfortunately I expect this upper bound is far from tight (It gives $f(4,2,2) \leq 4$).","['combinatorics', 'graph-theory', 'set-partition', 'discrete-mathematics']"
2389859,"Solve a system of non-linear equations: $2(a-b)=29+4ab$, $2(c-b)= 11+4bc$, $2(c+a) = 9-4ac$","So I've solved this system of equations: $$\begin{array}{lcl}2(a-b) & =& 29+4ab \\2(c-b)& = & 11+4bc \\2(c+a) & = & 9-4ac\end{array}$$ by simply solving for each variable in terms of the others, separately and plugging them into the other equations. It does get tedious and I don't want to sit with this for $40$ min in an exam. Is there any efficient way to solve a system like this?","['algebra-precalculus', 'calculus', 'systems-of-equations']"
2389871,"To write $\int_{\Omega} f d\mu,$ do we require $f$ to be defined *everywhere* in $\Omega?$","When we write the following expression :
$$\int_{\Omega} f d\mu$$
Do we require $f$ to be defined everywhere in $\Omega,$ or is it enough to require $f$ to be defined $\mu$-almost everywhere in $\Omega?$ $($i.e. $\mu\left(\left\{\omega \in \Omega : f(\omega) \text{ is not defined}\right\}\right)=0)$ I ask this question with reference to the following passage from Terence Tao's Introduction to Measure Theory. Here the term $\int_{\Omega} \left(\lim_{n \to \infty} f_n\right) d\mu$ is used even when $\lim_{n \to \infty} f_n$ is defined $\mu$-almost everywhere in $\Omega$. Any clarification would be appreciated. Thank you.","['real-analysis', 'notation', 'integration', 'measure-theory', 'convergence-divergence']"
2389992,When are there $n$ elements in $\mathbb{Z}_n^2$ with all differences distinct?,"For which natural number $n$ are there elements $\{x_i\}_{i=1}^n \subset \mathbb{Z}_n^2$ such that $x_i - x_j = x_k - x_l$ if and only if $i = k$ and $j=l$ (i.e. such that all differences between the elements are distinct)? Such elements do not exist for $n=2$ and $n=3$. But they exist for example for $n=4,5,6$. E.g. for $n=4$ take the elements $\{(\bar{0}, \bar{0}), (\bar{1},\bar{0}), (\bar{2}, \bar{1}), (\bar{1}, \bar{3})\}$. The problem of finding $n$ points with distinct differences in a given rectangular subset of $\mathbb{Z}^2$ has been investigated a lot. Unfortunately, this is not the case for the modular formulation presented above.
The best reference I could find is this paper , section V. There, they construct similar subsets of $\mathbb{Z}_n^2$ using e.g. Golomb Rulers (also known as Sidon sets). The closest result to the question posed above is Theorem 20, but it is not strong enough. Does anyone know where I could find answers to the question above? Thank you! Antropath","['discrete-geometry', 'combinatorial-geometry', 'geometry', 'combinatorics', 'group-theory']"
2390019,When $\|T(b)\|\le M\|b\|$ for each vector from a basis implies that $T$ is bounded?,"A linear operator $T\colon X\to Y$ between linear normed spaces is bounded if there exists a constant $M$ such that $$\|Tx\| \le M\|x\|\tag{*}$$ holds for every $x\in X$. Are there some situations when it is sufficient to verify that this condition is true for elements from some Hamel basis $B$? Is there characterization of normed spaces here validity of $(*)$ for some Hamel basis implies boundedness? Are there at least some sufficient conditions? Is situation easier in Banach spaces? Can we say something at least for $Y=\mathbb R, \mathbb C$? Or are there perhaps no pairs $(X,B)$ such that boundedness on $B$ implies boundedness on $X$? My feeling about this question is that this might be somehow related to the ""shape"" of the unit ball. But I guess that convexity of unit ball is probably not enough. This basically arose from a rather elementary discussion about a linear operator defined on $X=c_{00}$. (The space of sequences which have only finitely many non-zero terms with the sup norm. In this can write down an explicit basis $e^{(i)}=(0,0,\dots,0,1,0,\dots)$ and in the conversation I got an impression that the other person thinks that it suffices to verify $(*)$ for these vectors. I corrected them and said that we need to check this for each $x\in X$ - or at least for all elements of the unit ball - if we follow the definition they've learned. But I realized that the question whether this work at least sometimes might be quite complicated.) I searched a bit to see whether similar question has been posted here in the past. I only found this question, which deals with orthonormal basis rather than Hamel basis: Linear Operator bounded on a basis .",['functional-analysis']
2390038,Find the splitting field of $x^4+1$ over $\mathbb Q$.,"Solution:Let $\mathbb E$ be the splitting field of $x^4+1$ over $\mathbb Q$ .Then $x^4+1$ splits into linear factors in $\mathbb E$ . $$x^4+1=(x^2-i)(x^2+i)=(x-\sqrt i)(x+\sqrt i)(x-\sqrt {-i})(x+\sqrt {-i})$$ $$=(x-e^{i\pi/4})(x+e^{i\pi/4})(x-e^{i3\pi/4})(x+\ e^{i3\pi/4}).$$ Since $\mathbb E$ is the splitting field of $x^4+1$ over $\mathbb Q$ then $\mathbb E$ is the smallest field containing $\mathbb Q$ and the roots of $x^4+1$ .
Thus, $$\mathbb E=\mathbb Q(e^{i3\pi/4},-e^{i3\pi/4},e^{i\pi/4},-e^{i3\pi/4}).$$ Since $e^{i3\pi/4}$ can be obtained by taking the cube of $e^{i\pi/4}$ we have $$\mathbb E=\mathbb Q(e^{i\pi/4})=\mathbb Q\left(\frac{1+i}{\sqrt 2}\right).$$ Thus, $$\mathbb E=\mathbb Q\left(\frac{1+i}{\sqrt 2}\right)=\mathbb Q(i,\sqrt 2)=\mathbb Q(\sqrt {-2}).$$ Please check my solution. Any suggestions are heartly welcome!! Thank you!!","['abstract-algebra', 'splitting-field', 'field-theory']"
2390040,Limit of $f(x)\cdot g(x)$ given that $\lim_{x\to 0}{\frac{f(x)}{\sin(2x)}}=2$ and $\lim_{x\to 0}{(\sqrt{x+4}-2)\cdot{g(x)}}=5$,"Question: If $$\lim_{x\to 0}{\left[\frac{f(x)}{\sin(2x)}\right]}=2$$ and $$\lim_{x\to 0}{\left[(\sqrt{x+4}-2)\cdot{g(x)}\right]}=5$$ then find $$\lim_{x\to 0}{[f(x)\cdot{g(x)}]}$$ But, from what I found, $\lim_{x\to 0}{[g(x)]}$ does not exist. So how can I find $\lim_{x\to 0}{[f(x)\cdot{g(x)}]}$?","['limits-without-lhopital', 'limits']"
2390058,Prove property of integral of continuous functions,"Going over some old notes, I came across the following problem: Let $f,g$ denote continuous real functions on $[a,b]\subset\mathbb{R}$. Prove 
    that 
    $$f(x)\int_{a}^{x}g(t)\,dt \;=\; g(x)\int_{x}^{b}f(t)\,dt$$ 
    has at least one solution on $(a,b)$. Unfortunately, I have a note (in the margin no less!) that just says ""proof follows from Rolle's theorem"". Fortunately, this proof is easier than Fermat's Last Theorem, but I wouldn't mind someone checking my logic since it's a few months since doing the course. Proof : We introduce the function:
$$\begin{aligned}
F:[a,b] &\;\longrightarrow\; \mathbb{R} \\
x &\;\longmapsto\; F(x) \;\equiv\; \left(\int_{a}^{x}g(t)\,dt\right)\left(\int_{x}^{b}f(t)\,dt\right).
\end{aligned}$$
From the Fundamental Theorem of Calculus, the integral of a function continuous on $[a,b]$ is continuous on $[a,b]$ and differentiable on $(a,b)$. It follows from the product of continuous and differentiable functions that $F$ is continuous on $[a,b]$ and differentiable on $(a,b)$. Furthermore, $F(a)=F(b)=0$ since the limits of one of the integrals in $F$ will be the same, and hence vanish, at $x=a$ and $x=b$. Thus, $F$ satisfies the requirements of Rolle's theorem and
$$\exists\, x_{0}\in(a,b) \quad\text{s.t.}\quad F'(x_{0})\,=\, 0.$$
From the Product Rule and the Leibniz Integral Rule, we have
$$\begin{aligned}F'(x) &\;=\; \frac{d}{dx}\left(\int_{a}^{x}g(t)\,dt\right)\cdot\left(\int_{x}^{b}f(t)\,dt\right) + \left(\int_{a}^{x}g(t)\,dt\right)\cdot\frac{d}{dx}\left(\int_{x}^{b}f(t)\,dt\right) \\[0.3cm]
&\;=\;  g(x)\int_{x}^{b}f(t)\,dt - f(x)\int_{a}^{x}g(t)\,dt
\end{aligned}$$
and hence there exists at least one $x_{0}\in(a,b)$ such that
$$\begin{aligned}
F'(x_{0})\,=\, 0 \quad&\Longrightarrow\quad  g(x_{0})\int_{x_{0}}^{b}f(t)\,dt - f(x_{0})\int_{a}^{x_{0}}g(t)\,dt \;=\; 0 \\[0.3cm]
&\Longrightarrow\quad  g(x_{0})\int_{x_{0}}^{b}f(t)\,dt \;=\; f(x_{0})\int_{a}^{x_{0}}g(t)\,dt
\end{aligned}$$
and the result follows. $\;\blacksquare$ I get the feeling that I probably put too much into a proof - but it's good for my own sanity so that I know precisely what's going on and I don't run into the problem (like now!) of remembering precisely the logic. Thoughts welcome!","['real-analysis', 'proof-verification']"
2390137,The (Hausdorff) moment problem for signed measures.,"Moment problems consider the problem of inverting the map which takes a measure $\mu$ to its moments. What type of results are known for the analogous problem with signed measures? Namely, given $K\subset \mathbb R^d$ compact and a collection of real numbers $(M_\alpha)$ indexed by multi-indices $\alpha\in\mathbb N^d$, what conditions does one need on the $(M_\alpha)$ so as to have existence/uniqueness of a signed measure $\mu$ supported on $K$ such that $$\int_K x^\alpha\mu(dx)=M_\alpha?$$ Partial results/comments in this direction would also be appreciated! The following seems to address this problem, but unfortunately I don't speak a word of German and was hoping for other references!","['real-analysis', 'probability-theory']"
2390149,Find the number of times $5$ will be written while listing integers from $1$ to $1000$,"Just a question and then, I'll come up with my doubt. It will be easier to explain then. Question: Find the number of times $5$ will be written while listing integers from $1$ to $1000$. Now, it can be solved in this fashion. The numbers will be of the form: $5xy, x5y, xy5$ where $x,y$ denote the two other digits such that $0\leq x,y \leq 9$. So, $x,y$ can take $10$ choice each. So, answer is $10^2$ multiplied by $3$ for the $3$ sets of numbers mentioned. Answer becomes $300$ and it's correct. But the thing is: When we are considering $x5y$, we include $557$ in this. Again, we include $557$ while considering $5xy$, right? 
So that's a double count, yet the answer is right? This way I think there'll be a lot of more-than 1 counts , I'm not sure. Please explain me. Regards",['combinatorics']
2390166,"Lemma 10.8 Rudin functional analysis, proof.","There's the following theorem I'm trying to understand (Lemma 10.8 Rudin, Functional Analysis). Let $f$ be an entire function on $\mathbb{C}$ such that $f(0) = 1, f'(0) = 0, 0 < \lvert f(\lambda) \rvert \leq e^{\lvert \lambda
\rvert}$ for all $\lambda \in \mathbb{C}$. Then $f(\lambda) = 1$ for
  all $\lambda \in \mathbb{C}$. The maximum modulus theorem is used (Theorem 10.24 Rudin, Real and Complex analysis). Suppose $\Omega$ is a region, $f \in H(\Omega)$, and $\overline{D}(a;r) \subset \Omega$. Then $$ \lvert f(a) \rvert \leq \max_{\theta} \lvert f(a + re^{i\theta}) \rvert $$ For the lemma 10.8 the proof goes as follows. Because $f$ doesn't have zeroes then there's a function $g$ such that $f = \exp\left\{ g \right\}$, $g$ entire in $\mathbb{C}$ and $Re[g(\lambda)] \leq |\lambda|$ with $\lambda \in \mathbb{C}$, $g(0) = g'(0) = 0$. Let $r \geq |\lambda|$, we can verify that $$
\lvert g(\lambda) \rvert \leq \lvert 2r - g(\lambda) \rvert
$$ $$
h_{r}(\lambda) = \frac{r^2g(\lambda)}{\lambda^2(2r - g(\lambda))}
$$ such a function is holomorphic in $\left\{\lambda : |\lambda| < 2r \right\}$. Clearly $\lvert h_r(\lambda) \rvert \leq 1$ if $\vert \lambda \rvert = r$. By the maximum modulus theorem we have for $\lvert \lambda \rvert \leq r$
$$
\lvert h_r(\lambda) \rvert \leq 1.
$$ If we fix $\lambda$ and let $r \to \infty$, we have $g(\lambda) = 0$. My main question is how the maximum modulus theorem is actually used in this context? My function $h_r$ is holomorphic in $\Omega = D(0;2r)$ and also I have $\overline{D}(0,r) \subset D(0;2r)$, this should imply $$
\lvert h_r(0) \rvert \leq \max_{\lambda \in \partial \overline{D}(0,r)}\lvert h_r(\lambda) \rvert \leq 1
$$ where with $\partial A$ I denote the boundary set of a set $A$. Why does this imply $\lvert h_r(\lambda) \rvert \leq 1$ if $| \lambda | \leq r$?. Also why if fix $\lambda$ and let $r$ diverging implies $g(\lambda) = 0$?","['functional-analysis', 'complex-analysis', 'banach-algebras']"
2390172,Infinitely many accumulation points in a bounded sequence?,"Any bounded sequence of real numbers contains at least one accumulation point. If it doesn't converge it has more than one. In fact, $$a_n \equiv n (mod m)$$ has exactly m limit points.
Question: Can a bounded sequence of real numbers have infinitely many limit points?","['real-analysis', 'sequences-and-series']"
2390185,Is Dictionary order on $\mathbb{N} \times \mathbb{N}$ a well order?,"Taking $\mathbb{N}$ with usual order. Then is the dictionary order on $\mathbb{N}^2$  a well order. I tried to make hasse diagram for it. $(2,1)$ is clearly greater then $(1,x)$ but where do I put it if $(1,x)$ would go forever?","['well-orders', 'discrete-mathematics']"
2390192,Evaluate $\lim_{x \to 0}\frac{x}{\sqrt{1-\sqrt{1-x^2}}}$,Evaluate $$L=\lim_{x \to 0}\frac{x}{\sqrt{1-\sqrt{1-x^2}}} \tag{1}$$ I have used L Hopital's  Rule we get $$L=\lim_{x \to 0} 2\frac{ \sqrt{1-\sqrt{1-x^2}} \sqrt{1-x^2}}{x}$$ $\implies$ $$L=2 \lim_{x \to 0}\frac{ \sqrt{1-\sqrt{1-x^2}}}{x}$$  and from $(1)$ we get $$L=\frac{2}{L}$$ $$L=\sqrt{2}$$ is this correct appraoach?,"['algebra-precalculus', 'real-analysis', 'derivatives', 'limits']"
2390215,Is $\mathbb Q$ well ordered?,"There exist a bijection from $\mathbb N$ to $\mathbb Q$, so $\mathbb Q$ is countable. And by well ordering principle $\mathbb N$ has a least member say $n_1$ which is mapped to something in $\mathbb Q$, In this way $\mathbb Q$ can be well arranged? Is my argument good?","['order-theory', 'well-orders', 'elementary-set-theory', 'discrete-mathematics']"
2390227,What is the result of $\lim_{x\to0_+} \frac{e^x - x e^x - 1}{\left(e^x - 1 \right)^2}$ without L'Hôpital's rule. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I have the limit
$$
\lim_{x\to0_+} \frac{e^x - x e^x - 1}{\left(e^x - 1 \right)^2}
$$
which I need to compute without L'Hôpital's rule. (The result is $-\frac{1}{2}$ with L'Hôpital's rule). Thanks.","['limits-without-lhopital', 'calculus', 'limits']"
2390233,When is the limit of a sequence over $n$ the limit of the differences? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Under what conditions on the sequence $a_n$ does
$$
\lim_{n→∞} \frac{a_n}n = \lim_{n→∞} (a_{n+1} − a_n )
$$
hold?","['sequences-and-series', 'limits']"
2390282,"Concepts involved in ""Family of Lines"".","My textbook states: Any line through the point of intersection of the lines $a_1x
 +b_1y+c_1=0$ and $a_2x+b_2y+c_2=0 $  can be represented by the equation: $a_1x +b_1y+c_1+ \lambda(a_2x+b_2y+c_2)=0$ //where $\lambda$ is a
  parameter. Now, this theroem (including the $\lambda$ ) is difficult to understand. I am unable to grasp it's concept. I searched for video lectures on Family of Lines but there were no good ones. Googling, too was of no avail. Can someone please provide a simple explanation of this theorem (what exactly does it intend to convey) along with it's explanatory proof?","['algebra-precalculus', 'coordinate-systems', 'geometry']"
2390325,"If $T^2 = I$, how one can proof that $V = W \oplus U$?","Let $K$ be a field with cardinality different of $2$ and let $V$ be a $K-$vector space. Let $T: V \to V$ be a linear operator such that $T^2 = I$.
Let $W = \{ v \in V: \, Tv = v \}$
 and $U = \{ v \in V : Tv = -v \}$. I'm trying to proof that $V = W \oplus U$. My attempt: If $x \in W \cap U$, $Tx = x$ e $Tx = -x$, i.e $x = -x$, hence $x = 0$. Then, $W \cap U = \{0\}$. If $x \in V$, we have that $x = x - Tx + Tx$ and $x - Tx \in U$, since
$$ T(x - Tx) = Tx - T^2 x = Tx -x = - (x-Tx). $$
However, $Tx$ which is not necessarily in $W$. Help?",['linear-algebra']
2390340,The volume of sphere using integrals,"In spherical coordinate system I have the volume element $$dV=r^{2}\sin(\theta)\ d\theta\ d\varphi\ dr$$
I want to calculate the volume for the radius equal to $R$. I calculate the integral:
$$\int_{0}^{R} \int_{0}^{2\pi} \int_{0}^{\pi}  r^{2}\sin(\theta)\ d\theta\ d\varphi\ dr = \left [-\frac{1}{3}r^{3}\cos(\theta)  \right ]_{0,0,0}^{r=R,\varphi=2\pi,\theta=\pi}=\frac{2}{3}\pi R^{3}$$ What did I do wrong?",['integration']
2390373,Difference between Gâteaux and Frêchet derivatives,"I can't seem to grasp the difference between the definitions of gâteaux and Frêchet derivatives I am wokring with: A function $f: U \rightarrow \mathbb{R}^{n}$ ($U$ open) is said to be Gâteaux diff. in $x_0$ if every directional derivative $D_vf(x_0)$ exists ($\forall v$) and the map $v \mapsto D_vf(x_0)$ is linear. A function is said to be Frêchet diff. in $x_0$ if a linear map $L:\mathbb{R}^n \rightarrow \mathbb{R}$ such that $$\lim_{x \to x_0} \frac{f(x)-f(x_0)-L(x-x_0)}{|x-x_0|} = 0$$ Now by my understanding, as we work over $\mathbb{R}^{n}$, $L$ is equal to the total derivative $df(x_0)$. If a function is frêchet diff., we have $df(x_0) = \langle\nabla f(x_0), \cdot\rangle$, I understand that if a function is frêchet diff in $x_{0}$, it is also gâteaux diff in $x_0$ as exist (whereas $v\mapsto \langle \nabla f(x_0), v\rangle$) But how does the map $v \mapsto D_vf(x_0)$ from the gâteaux definition differ from the total derivative $df(x_0)$ ? I mean the map in the gâteaux definition is also linear so what is difference between both? I know there are similar questions out there, but I could not find one that used the same definitions.","['real-analysis', 'differential-geometry', 'definition']"
2390378,Exercise on equivalence of weak convergence in Sobolev and $L^p$ spaces,"I have to solve the Exercise $10.43$ of page $302$ of the book "" A First Course in Sobolev Space "" by Leoni. The problem is the following. Let $\Omega\subset\mathbb{R}^n$ be an open set, $1\leq p<+\infty$ and $\{u_n\}\subset W^{1, p}(\Omega)$. Prove that $u_n\rightharpoonup u$ in $W^{1, p}(\Omega)$ if and only if $u_n\rightharpoonup u$ in $L^p(\Omega)$ and $\nabla u_n\rightharpoonup\nabla u$ in $L^p(\Omega; \mathbb{R}^n)$. Some ideas/hints? Thank You","['functional-analysis', 'weak-convergence', 'lp-spaces', 'measure-theory', 'sobolev-spaces']"
2390390,Symmetry of point about a line in 3d,"How would I go about finding the symmetrical image of a 3d point $t = (t_x,t_y,t_z)$, about a 3d line given with the equation $\frac{x+1}{4}=\frac{y+1}{-3}=\frac{z-15}{16}$? Edit: To clarify: The above illustration should show what I'm looking for. The coordinates of the point $t'$ on the graph. The purple line on the graph corresponds to the equation given above. It is a freshman linear algebra & analytic geometry exam question and a simple solution (without unneccesary differential equations or other complications) doable with pen and paper in a reasonable amount of time (of up to twenty minutes say) would be appreciated.","['analytic-geometry', 'symmetry', 'reflection', 'geometry']"
2390417,If $ab+1$ is perfect square there is a $k$ such that $ak+1$ and $bk+1$ are perfect squares,"Show that if $ab+1$ is a perfect square for positive integers $a$ and $b$, then there is a positive integer $k$ such that $ak+1$ and $bk+1$ are both perfect squares. I tried to prove that there is a $k$ such that $\gcd(ak+1, bk+1)=1$ and $(ak+1)(bk+1)$ is a perfect square. But it gave me nothing. Any ideas?","['number-theory', 'elementary-number-theory']"
2390419,Maximum of sum of fractions with tans,"Let $ABC$ be an acute triangle. What is the maximum value of
$$\frac{\tan^2A+\tan^2B}{\tan^4A+\tan^4B}+\frac{\tan^2B+\tan^2C}{\tan^4B+\tan^4C}+\frac{\tan^2C+\tan^2A}{\tan^4C+\tan^4A}?$$ For the equilateral triangle, $\tan A=\tan B=\tan C=\sqrt{3}$, and the sum is $1$. For the isosceles triangle with $\angle A=\angle B\rightarrow\pi/2$ and $\angle C\rightarrow 0$, the sum approaches zero.","['algebra-precalculus', 'inequality', 'trigonometry']"
2390420,Complete graph $K_{19}$ in 3-space with all distances at powers of $d$,"For 2D, I asked the question Points with power distances .  For 3D, I asked about Points at Integer Distances in 3-space . Combining these, I was able to construct $K_{19}$ so that all distance between points are powers of $d=1.15096...$ from $d^6 -d^2-1=0$, the same as in Zak's triangle . For smaller cliques, see Powered Clique Polyhedra . Here's the grid of power distances between points.  For example, the 16-17 distance is $d^0$. Values are 0 to 17 sans 1 and 16. Points 1-3 can be placed at the following, with the root value about 4.54932. {{d^6 /2, Root[-19+72 #1^2 -1328 #1^4 +64 #1^6 &,2], 0}, {0,0,0}, {d^6,0,0}} That leads to the first question -- is there a natural way of representing this pyramid, so that all coordinates are expressed in terms of $d$, or so that it is placed symmetrically on the $(x,y,z)$ axis?  Is it possible to get larger cliques? Are there any other $d$ values that can even get close to power-distance clique this large?","['graph-theory', 'algebraic-geometry', 'combinatorial-geometry', 'extremal-combinatorics', 'geometry']"
2390426,Convergence of a series depending on a parameter.,"I was studying the convergence of a series with a parameter and I want to ask you if my conclusion is correct and if there is a better method to do it. $$\sum_{n=1}^{\infty}\left(\frac{\pi}{2}-\arcsin\frac{n}{n+4} \right)^{\alpha}$$ I'm asked to say for which $\alpha$ the series is convergent. I tried to do this: $$\sum_{n=1}^{\infty}\left(\frac{\pi}{2}-\arcsin\frac{n}{n+4} \right)^{\alpha}=
\sum_{n=1}^{\infty}\left(\arccos\frac{n}{n+4} \right)^{\alpha}=\sum_{n=1}^{\infty}\left(\arccos\left(1-\frac{4}{n+4}\right)\right)^{\alpha}$$ Now I tried to see the Taylor Series of $\arccos(1-y)$ as $y\rightarrow 0$, $y=\frac{4}{n+4}$. By deriving $g(y)=\arccos(1-y)$ I obtain: $$g'(y)=\frac{1}{\sqrt{1-(1-y)^2}}=(-x^2+2x)^{\frac{1}{2}}=(2x)^{\frac{1}{2}}(1-\frac{x}{2})^{\frac{1}{2}}=\sqrt{2y}+o(\sqrt{2y})$$ So I see that: $$g(y)=\int\frac{1}{\sqrt{2y}}+o\left(\frac{1}{\sqrt{2x}}\right)dx=\sqrt{2x}+o(\sqrt{2x})$$ From this, I can conclude that my series is: $$\sum_{n=1}^{\infty}\left(\arccos\left(1-\frac{4}{n+4}\right)\right)^{\alpha} \sim \left(\sqrt{\frac{8}{n+4}}\right)^{\alpha}$$ So, for asymptotic comparison to $\left(\frac{1}{n}\right)^{\frac{\alpha}{2}}$ the series converges if and only if $\alpha > 2$. Am I right? If yes, may I ask you if there is a better method to do this computation? And, expecially, if there is a better method (if possible without involving integrals) to compute the Taylor series of inverse trigonometric functions! Thanks in advance.","['real-analysis', 'sequences-and-series', 'calculus', 'convergence-divergence', 'analysis']"
2390446,Lindstedt-Poincare method to find a valid first approximation,"I want to use Lindstedt-Poincare method or multiple scale method to find a uniformly valid first approximation to the equation $\frac{d^2u}{dt^2}-\epsilon (1-u^2)\frac{du}{dt}+u=0$, and show that for a large class of initial conditions, the solution approaches a limit cycle as $t\rightarrow \infty$. I would appreciate any assistance.","['ordinary-differential-equations', 'perturbation-theory']"
2390466,"Partitions of $0$ and $1$ by integers in the interval $[-N,\ldots,N]$","Background Often one comes across the problem of trying to find the number of ways to partition a positive integer into a sum of nonnegative integers. There are three ways to partition the number 3, for example:
\begin{align}
3 &= 3+0,\\
3 &= 1+2,\\
3 &= 1+1+1.\\
\end{align}
The first two are a partitioning of $3$ into $2$ nonnegative integers. The last is a partitioning into $3$ nonnegative integers. The problem statement On the other hand one could consider the number of ways to partition a number over a different set. I am interested in the case where the numbers ""doing the partitioning"" are drawn from the set
$$
S_N = [-N,\ldots,N]
$$
(with repeats allowed) and the numbers to be partitioned are $0$ and $1$. In the general case, $m$ numbers are allowed to be chosen from $S_N$ to do the partitioning. Example Suppose $N = 1$, so that $S_1 = \{-1,0,1\}$. Suppose first we look for partitions into two integers -- in other words, take $m =2$. Then $0$ can be partitioned into two integers from $S_1$ in the two distinct ways as shown below:
\begin{align}
0 &= 0 + 0 \\
0 &= 1 + (-1),
\end{align}
$1$ may be partitioned in only one way:
\begin{align}
1 &= 1 + 0. \\
\end{align}
For $m=3$, $0$ may be partitioned in two distinct ways again,
\begin{align}
0 &= 0 + 0 + 0\\
0 &= 1 + (-1) + 0,
\end{align}
whereas $1$ can now also be partitioned into two distinct ways,
\begin{align}
1 &= 1 + 0 + 0\\
0 &= 1 + 1 + (-1).
\end{align} Is there a solution for the general case? I am wondering if this problem can be solved in the general case (for all $N$ and $m$) in closed form. Literature references are welcome. Thanks! Edit: to address the comments, in the case of $0$ ($1$), what I am looking for is indeed the coefficient of $x^m y^0$ ($x^m y^1$) in the formal series defined by 
$$
g(x,y) = \frac{1}{\prod_{k=-N}^{k=+N}(1-x y^k)}.
$$","['combinatorics', 'integer-partitions']"
2390471,Number of ways to arrange 5 monkeys in a row?,"We have 5 monkeys $a,b,c,d,e$ and we are interested in the number of ways to have them stand in a row without $a$ and $b$ being next to each other. The part that I struggle with most is that I don't fully understand how to solve this when the 5 are different. It's not the same as for example coloring 5 segments either blue or red without any two neighboring segments being red. This is how I tried to solve this but I'm certain that there's something wrong. I would really appreciate it if you could also critique my approach. Idea: Let $f_{k}$ be the number of ways we can have the $5$ monkeys in a row without $a$ and $b$ being next to each other. We try to do this recursively: case 1 : the last monkey is not $a$ or $b$: then we have $f_{k-1}$ possibilities for the rest of the k-1 monkeys. case 2 : the last monkey is either $a$ or $b$: Here the second to last has to be one of $\{c,d,e\}$. So we have $3$ possibilities for the second to last spot and $2$ possibilities for the last. A total of $2*3 = 6$ and $f_{k-2}$ for the remaining spots. The recursive equation I get is: $f_{k} = 6 + f_{k-1} + f_{k-2}$ $f_{1} = 5$ $f_{2} = 10$ $f_{3} = 21$ $f_{4} = 37$ $f_{5} = 64$ I'm not sure about my solution. Thanks in advance","['combinatorics', 'discrete-mathematics']"
2390489,Expansion of $\tan(nx)$ in powers of $\tan(x)$,"If $\tan(nx)$ is expanded in powers of $\tan(x)$ then what are the constant term and coefficient of $\tan(x)$ in the expansion? My try I tried solving by comparing with the general formula for $\tan(nx)$ which is given in terms of $\tan(x)$ , $\tan^n(x)$ but did not get the correct answer. Could someone please help me with this?","['algebra-precalculus', 'trigonometry']"
2390499,Characterization of the sphere,"Hello I wanted to prove the following statement. Let $M$ be a compact connected surface in $\mathbb{R}^3$ such that for all $d\in S^2$ there exists a plane called $\pi_d$, such that is orthogonal to $d$ and it's a plane of symmetry of $M$, then $M=S^2$. So far, I could prove that if the origin is contained in every normal line to $M$, then $M$ is a sphere centered at the origin. So now I tried to see that if I have the symmetry plane given by the statement, every such plane contains the origin, and this way I think I could conclude, but I am not able to prove this last assertion.",['differential-geometry']
2390511,Find the derivative of $y=x^{\sin x}$,"Could someone please explain step 3 for the following: Why do they multiply $1/y$ with $y'$? I understand that the derivative of $\ln y$ is $1/y$, but I don't understand why it is multiplied with $y'$ in step 3. Find the derivative for    $y=x^{\sin x}$ Step 1: $\ln y=\ln x^{\sin x}$ Step 2: $\ln y=\sin x\ln x$ Step 3: $\frac{y'}y=\cos x\ln x+\frac{\sin x}x$ Step 4: $y'=y\left[\cos x\ln x+\frac{\sin x}x\right]=x^{\sin x} \left[\cos x\ln x+\frac{\sin x}x\right]$","['derivatives', 'logarithms', 'exponential-function', 'trigonometry', 'calculus']"
2390542,A conjecture about an unlimited path,"Conjecture: For all primes of the form $a^2+b^2$, there are natural numbers $s,t,u,v$ such that $\quad s^2+t^2,u^2+v^2$ are primes $\quad a+b=s+t$ $\quad u+v=s+t+2$ $\quad |s-u|+|t-v|=2$ This conjecture implies Any odd number is of form $a+b$ where $a^2+b^2$ is prime and seems to be much stronger. I have tested it for $a+b<50.000$ without founding a counterexample, but I guess there may exist counterexamples. In the diagram the vertices correspond to points $(x,y)$ where $x^2+y^2$ is prime, the red edges correspond to pairs of vertices with taxi cab distance equal to $2$ and the gray diagonal lines is the (taxi cab) equidistance lines to origin. The conjecture says there are paths following red edges and gray diagonal lines up to any distance from origin. Addendum : Further tests show that there exists red vertical edges that together with the gray diagonal lines make such paths for all odd $n=a+b=3,\dots,49,999$ except for $n\in\{9,19,49,75,149\}$. In this case I want help with finding counterexamples.","['conjectures', 'graph-theory', 'sums-of-squares', 'number-theory', 'prime-numbers']"
2390557,Could a version of probability theory be made rigorous with only calculus?,"I am wondering if one could, or if there has been built a version of probability theory that could exist rigorous on its own without real analysis and measure theory? The motivation for this quesiton is that in almost every introductory text in mathematical statistics I've seen, they only rely on calculus as a prerequisite. Could one only rely on calculus and multivariate calculus to do this rigorous?
In introductory texts random variables are described as random functions, but their characteristics is their pmf or pdf, would this be enough? So if we only restrict ourselves to what is called discrete or continuous random variables(or vectors) in introductory statistics text, is calculus and multivariate calculus enough to get the theory to stand on its own? or will we need measure theory? If it is the case that this is impossible to do without measure theory, does this mean that most introductory texts in statistics are wrong? Since they base everything on Riemann-integrals, but the theory is wrong? UPDATE: From the discussion in the comments we see that by the definition of a probability space we need it to be a measure, and we also need the events to be a sigma-algebra. Hence we need these two concepts from measure theory. So I should have asked the question like this instead: Will the theory of continuous random variables in introductory texts work out if we only allow Riemann-integration and not Lebesgue-integration? Is the integration-theory in introductory texts in calculus which only deals with Riemann-integration enough to make sure that the theory is rigorous?","['probability-theory', 'calculus']"
2390628,Find an unbiased estimate of $\hat{\theta}$ which is a function of $T$.,"$(X,Y)$ is uniform over the triangular region with vertices at $(0,0)$,$(\theta, 0)$, and $(0,\theta)$, $\theta$ is unknown. Let $(X_i,Y_i)$ be iid as $(X,Y)$. Find a one dimensional sufficient statistic $T$ for $\theta$, and prove it's sufficient. Find an unbiased estimate of $\hat{\theta}$ which is a function of $T$. Attempt $f_{X,Y}(x,y) = \frac{2}{\theta^2}$ $L(\theta| \mathbf{X},\mathbf{Y}) = (\frac{\theta^2}{2})^{-n} \prod I_{x_i+y_i < \theta}$ Sufficient statistic: $T = max_i (X_i+Y_i)$ $\hat{\theta} = ?$","['uniform-distribution', 'statistics', 'random-variables']"
2390638,"Show $\int_Af(x)\,dx=0$ for every measurable subset $A$ of $[0,1]$.","Let $f$ be Lebesgue-integrable on $[0,1]$. Suppose $\int_a^bf(x)\,dx=0$ for all $0\leq a\leq b\leq 1$. Show $\int_Af(x)\,dx=0$ for every measurable subset $A$ of $[0,1]$. *Let $A$ be a measurable subset of $[0,1]$. Then $A$ can be written as the union of disjoint, countable? intervals. Since $\int_a^bf(x)\,dx=0$ for all $0\leq a\leq b\leq 1$, each integral of $f$ over each interval is $0$ so $\int_Af(x)\,dx=0$. I'm not sure if I did it right...","['real-analysis', 'lebesgue-integral', 'measure-theory']"
2390653,Closed and bounded subsets of $\ell_1$,"I am investigating closed and bounded subsets of $\ell_1$ endowed with the $\|\cdot\|_1$ norm. For concreteness, $$\ell_1 = \left\{x = (x_1,x_2,\dots)\ |\ \|x\|_1 = \sum_{i=1}^{\infty} |x_i| < \infty\right\}.$$ I am considering the following example. For all $n \in \mathbb{N}$, define the sequence $$\tilde{e}_n = (0,\dots,0,1 + 1/n,0,\dots).$$ That is, the $i$-th entry of $\tilde{e}_n$ is $0$ if $i \neq n$ and $1+1/n$ if $i = n$. Then set $A = \{\tilde{e}_1,\tilde{e}_2,\dots\} \subset \ell_1.$ Clearly $A$ is bounded, but is it closed? I believe it is vacuously closed since $A$ does not have any limit points. My end goal here is to exhibit a closed and bounded subset $A$ of $\ell_1$ such that the continuous function $f: \ell_1 \rightarrow \mathbb{R}$ defined by $f(x) = \sum_i x_i$ does not achieve its infimum on $A$.","['functional-analysis', 'real-analysis', 'vector-spaces']"
2390664,Algorithm for calculating the mutual information between continuous variables,I'm trying to use the notion of mutual information between continuous variables in a software. https://en.wikipedia.org/wiki/Mutual_information The inputs of the algorithm would be two lists l1 and l2 of n real numbers and the output would be a real number m that represents the mutual information between the values in l1 and l2. But I don't know how can I translate that formula in an algorithm. Can you help me? Best regards.,"['information-theory', 'computational-mathematics', 'probability', 'computer-science']"
2390686,Can't solve Improper Integral $\int_{0}^{\infty} \frac{\sqrt{x}\sin(x)}{1+x^2} dx$,"Whilst checking for the existence of improper integrals, I came across this one:
$$\int_{0}^{\infty} \frac{\sqrt{x}\sin(x)}{1+x^2} dx$$
So in order to check its existence I simply have to see if the limit:
$$\lim_{a\to\infty} \int_{0}^{a} \frac{\sqrt{x}\sin(x)}{1+x^2} dx $$
Is a number or not. However I seem unable to find a way to solve this particular Integral, and neither any online calculator can. I have tried all substitutions that I could think of, as well as partial integration and using any helpful trigonometric identities but they were all in vain.","['improper-integrals', 'integration', 'limits']"
2390728,Boundedness of solution to a second order differential equation,"Suppose $f$ is a convex function with the property that level sets of $f$ are compact. I know that any solution of the differential equation $$\dot{x}=-\nabla f(x)$$ is bounded because $(d/dt) f(x) = - ||\nabla f(x)||^2$ so that $x_t$ always stays within the level set $\{ u ~| f(u) \leq f(x_0)\}$. My question is: suppose I have instead $$m \ddot{x} + c \dot{x} = - \nabla f(x),$$ where $m > 0$ and $c \geq 0$. It seems natural to guess that this will stay bounded as well. Is that true?",['ordinary-differential-equations']
2390730,Multiplication of Ordinals-Antilexicographic order,"I am trying to get my head around the two different definitions of multiplication of ordinals. The first definition is with transfinite induction, which I found pretty easy to understand, as well as all the properties that derive from it. The other definition is with antilexicographic order, it states that $a \cdot b=ord(A\times B,<_{alex})$ . More precisely, we take the cartesian product $A \times B$ and it says that: $$(x_1,y_1)<(x_2,y_2) \iff (y_1<_By_2) \lor (y_1=y_2 \land x_1<_Ax_2)$$ Does that mean $(\omega,  2) <(2,3)$ as $2<3$ ? If so, is there any way to make this clearer than just using the definition? cause so far the $2$ different definitions for multiplication seem very distant to me.... I'm sure I have misunderstood something about the connection of the multiplication and the antilexicographic order, but there were no further examples on my notes on this topic and every book I searched just mentioned the properties and moved on.","['elementary-set-theory', 'ordinals']"
2390769,"Trend in equivalence classes of $ (x,y) \in R \iff x-y \in \mathbb{Z}$","Question: Define the following equivalence relation on the real numbers: $ (x,y) \in R \iff x-y \in \mathbb{Z}$ Compute $ \ [-2], [-1], [0], [1], [2] $. Do you see a trend? My attempt: $ [-2] = \{ { y \in \mathbb{R} : -2-y \in \mathbb{Z} }\}$ $ [-1] = \{ { y \in \mathbb{R} : -1-y \in \mathbb{Z} }\}$ $ [0] = \{ { y \in \mathbb{R} : 0-y \in \mathbb{Z} }\}$ $ [1] = \{ { y \in \mathbb{R} : 1-y \in \mathbb{Z} }\}$ $ [2] = \{ { y \in \mathbb{R} : 2-y \in \mathbb{Z} }\}$ Will all of the above equivalence classes be equal to $ \mathbb{Z}$? Is that the trend?","['relations', 'equivalence-relations', 'elementary-set-theory']"
2390792,Entire function that is a polynomial.,"I came across the following exercise while studying for a qual:  Suppose that $f$ is an entire function such that $|f (z)| \geq 1$ whenever $|z|\geq 1$. Show that $f$ is a polynomial. I'm not sure how to begin this exercise. I had thought maybe using the fact that f is a not identically zero, it must have a finite number of zeros on the unit disk. From there I was hoping to invert f and divide by it's zeros so I had a bounded entire function g. Then I had wanted to invoke liouville. But I not so sure these final steps are good ones.","['complex-analysis', 'analysis']"
2390804,Compute $\int_{0}^{\infty} \frac{\sqrt{x}\sin(x)}{1+x^2} dx$,"How does one compute the following integral?
$$\int_{0}^{\infty} \frac{\sqrt{x}\sin(x)}{1+x^2} dx$$ I have tried extending $x$ to the complex plane then evaluating the following contour integral 
$$\oint_C \frac{\sqrt{x}e^{ix}}{1+x^2} dx$$
with the contour $C$ running along the whole real axis and then upper semicircle. I obtain
$$\int_{0}^{\infty} \frac{\sqrt{x}\big(\cos(x)+\sin(x)\big)}{1+x^2}\,\mathrm dx=\frac\pi{e\sqrt2}$$
but not the original integral.","['improper-integrals', 'integration', 'definite-integrals', 'contour-integration']"
2390807,Major confusion about sheaves of rings and sheaves of modules on schemes,"So this question has largely grown out of two previous questions I asked: Question about notation/conventions for localizations of R-algebras Help understanding closed subschemes and closed immersions I have identified and consolidated some of my major points of confusion. Take exercise (2.18a) from Hartshorne as an example. There I am asked to show that if I have a morphism of rings $\phi: A \longrightarrow B$ with corresponding morphism of schemes $f: \text{Spec} B \longrightarrow \text{Spec}A$, then the corresponding morphism of sheaves $f^{\#}: \mathcal{O}_{Y} \longrightarrow f_{*}\mathcal{O}_{X}$ is injective if and only if $\phi$ is injective. Let me first lay out what I understand before getting to what is confusing me. After doing section 2.1 of Hartshorne, I felt comfortable with sheaves taking values in an abelian category. Once I got to section 2.2, however, I got a little lost. The issue that everything is done in terms of sheaves of $\textit{rings}$, which certainly do not form an abelian category (indeed we don't even have kernels!). When we take stalks of these sheaves, we find that at some point $p$ (say a prime ideal of $B$), the stalk of the sheaf $\mathcal{O}_{X}$ at $p$ is the local $\textit{ring}$ $A_{p}$. This was all well and good until I came to trying to apply exactness results for localization. Returning to the exercise I mentioned above, I went about showing that the sheaf is injective on sections. I started with $\phi: A \longrightarrow B$ and localized at a basic open set $D(h)$ to consider the morphism 
$$
A_{h} \longrightarrow B_{\phi(h)}
$$
I then thought I could just say that since localization is exact, this preserves exactness. However, I realized that this exactness result only holds for modules. That is, if I treated $B$ as a module over $A$, then it would be perfectly fine for me to claim that the map of $\textit{modules}$
$$
A_{h} \longrightarrow B_{h} \simeq A_{h} \otimes _{A} B
$$
is injective. Speaking more generally than just the exericse, what exactly can I say about morphisms of sections, and induced morphisms of stalks since they are rings, not modules. It seems like all of section 2.1 was useless. I have also been looking at the notion of base change where I hit a similar problem. Say the morphism $\phi: A \longrightarrow B$ makes $B$ into a finite-type $A$-algebra. We would like to claim that finite-type morphisms of schemes are preserved under base change. That is, we would like to be able to say that via base change, the morphism
$$
A_{h} \longrightarrow B_{\phi(h)}
$$
makes $B_{\phi(h)}$ into a finite-type $A_{h}$-algebra. I can do this the hands-on way by showing how finitely many generators of $B$ over $A$ map under localization, but I wanted to try to see this more abstractly. I wanted to see the localization $B_{\phi(h)}$ as the pushout of the diagram which would be the tensor product $A_{h} \otimes_{A} B$. Then I realized again that this would only be the case in the category of modules, which brought me back to my original confusion. Is it true that as rings, there holds $B_{\phi(h)} \simeq A_{h} \otimes_{A} B$? Or is it only true when we treat $A$ and $B$ as $\textit{modules}$ that $B_{h} \simeq A_{h} \otimes_{A} B$, in which case we could apply exactness results? I'm sorry for the long post, but this is really bugging me and I wanted to lay out as much detail as I could. I'm still not entirely sure I have asked the question exactly the right way, but I am hoping people can still clear up any confusion.","['modules', 'sheaf-theory', 'algebraic-geometry', 'commutative-algebra']"
2390812,Solving $c A + I = (\det A) S$,"I have a simple matrix equation $$c A + I = (\det A) S$$ which seems linear (or perhaps quadratic) and involves the determinant of the matrix being solved for. Here, $c$ is a constant, and $S$ is a matrix. How could I solve for $A$, a symmetric matrix in $\mathbb{R}^{k\times k}$? An extremely efficient way of computing $A$ would also be fine. If it helps solve the problem, then know that $S$ corresponds to a (full-rank) covariance matrix $\frac{2}{n}X X^{\intercal}$, and $c$ corresponds to the norm of a mean-vector $\left\Vert \frac{1}{n}\overline{x}\right\Vert_2 = \frac{1}{n^2}\overline{x}^{\intercal}\overline{x}$. If there is no simple solution, a solution for the $k=2$ case is all I really need.","['matrix-equations', 'matrices', 'matrix-calculus', 'statistics', 'linear-algebra']"
2390818,Curvature of the earth from Theorema Egregium,"I recently learned Gauss's Theorema Egregium for surfaces embedded in $\mathbb{R}^3$. A TA for my class suggestively said that from this, i.e. that Gaussian curvature depends only on the first fundamental form of a surface, we may calculate the curvature of the earth without leaving its surface. I understand that with knowledge of the first fundamental form, we may calculate the curvature, but for this question I'm not sure how to proceed, since we don't have a priori the first fundamental form of the earth given. It seems to me like we need to find that. I saw some answers using the Gauss-Bonnet theorem, but I think that deals with total curvature, and I'm speaking of Gaussian curvature (I may be wrong here, I don't really know that theorem well). Does it have something to do with measure triangles and angles? And if so, can someone help me relate this back to Gauss's theorem and the first fundamental form? Another point of confusion: How do I even know what a triangle is on an arbitrary surface? A triangle is made by connecting three points with the curve that attains the shortest possible distance between those points, right? So on a plain, that's the normal line segment, but what about for arbitrary surfaces?","['differential-geometry', 'curvature']"
2390819,Combinatorial proof that two ways of counting are equal: $\sum_{r=2}^{n+1} \binom r2 = \binom{n+2}3$,"Prove: $$\sum_{r=2}^{n+1} {r \choose 2} = {n+2 \choose 3}$$ I know that ${n+2 \choose 3}$ is ${n \choose 3}$ with repetition (${n + 3 - 1 \choose 3}$), but apart from that I don't even know what to do. Any help would be appreciated.","['binomial-coefficients', 'combinatorial-proofs', 'combinatorics', 'summation', 'discrete-mathematics']"
2390831,Short exact sequence of vector bundles vs locally free sheaves,"If I have a short exact sequence of vector bundles 
\begin{equation}
0\rightarrow E' \rightarrow E \rightarrow E'' \rightarrow 0
\end{equation}
then it splits, which mean that $E = E'\oplus E''$? 
So if I have a short exact sequence of locally free sheaves 
\begin{equation}
0\rightarrow \mathcal{F}' \rightarrow \mathcal{F}\rightarrow \mathcal{F}'' \rightarrow 0
\end{equation}
then is it also true that the sequence splits and I have $\mathcal{F} = \mathcal{F}'\oplus\mathcal{F}''$?","['algebraic-topology', 'sheaf-theory', 'algebraic-geometry']"
2390875,Confusion about Notation for Twisting Sheaf and Very Ample Invertible Sheaves,"I'm a bit confused by some notation in Hartshorne's chapter II (theorems II.5.17, II.7.6, and some discussion on ample invertible sheaves in section 7). Theorem 5.17 (Serre). Let $X$ be a projective scheme over a noetherian ring $A$ , let $\mathcal{O}(1)$ be a very ample invertible sheaf on $X$ , and let $\mathcal{F}$ be a coherent $\mathcal{O}_X$ -module. Then there is an integer $n_0$ such that for all $n \geq n_0$ , the sheaf $\mathcal{F}(n)$ can be generated by a finite number of global sections. Proof. Let $i: X \rightarrow \mathbb{P}_A^r$ be a closed immersion of $X$ into a projective space $A$ , such that $i^*(\mathcal{O}(1)) = \mathcal{O}_X(1)$ ... [The remainder of the paragraph is devoted to reducing to the case where $X$ is Proj of a polynomial ring.] First, what is meant by the hypothesis "" $\mathcal{O}(1)$ be a very ample invertible sheaf on $X$ "", since, a priori, $X$ is not projective space or Proj of a graded ring? I see that one can appeal to Corollary 5.16 to see that $X$ is $\mathrm{Proj}(S)$ for some graded ring $S$ , finitely generated by $S_1$ as an $S_0 = A$ -algebra. Then one can take $\mathcal{O}(1) = \widetilde{S(1)}$ . Then this is very ample since we can use the description of $S$ to construct a closed immersion $i: X \rightarrow \mathbb{P}_A^r$ with $i^*(\mathcal{O}_{\mathbb{P}_A^r}(1)) = \mathcal{O}_X(1)$ (by Proposition 5.12(c)), which is just $\mathcal{O}(1)$ . Is this the correct interpretation? Second, on p. 153, this result is later quoted as having established: for $\mathcal{L}$ any very ample invertible sheaf on a projective scheme $X$ over $A$ , for any coherent $\mathcal{F}$ , there is an $n_0$ such that $n \geq n_0$ implies $\mathcal{F} \otimes \mathcal{L}^n$ is generated by global sections, which appears slightly different than the above result, since we worked with the particular very ample invertible sheaf $\mathcal{O}_X(1)$ . Based on the above argument, it seems every very ample invertible sheaf over a projective scheme (at least those coming from closed immersions coming from surjective ring maps, by proposition 5.12(c)) will be isomorphic to $\mathcal{O}_X(1)$ . Is this true? If it's not, in what sense was the quoted result proven by theorem 5.17? Also, is this rephrasing merely meant to suggest the definition of ample provided on p. 153? Finally, I am confused about the notation found in the proof of theorem 7.6, in chapter II. The setting is $X$ a scheme of finite type over a noetherian ring $A$ , and $\mathcal{L}$ an invertible sheaf on $X$ . One direction of the theorem is that if $\mathcal{L}^m$ is very ample implies $\mathcal{L}$ is ample. The proof begins with $i: X \rightarrow \mathbb{P}_A^n$ , an immersion with $\mathcal{L}^m \simeq i^*(\mathcal{O}(1))$ . Then given any coherent $\mathcal{F}$ , consider the closure $\overline{X}$ in projective space and $\overline{\mathcal{F}}$ the coherent sheaf which is the extension of $\mathcal{F}$ to $\overline{X}$ . Then it is noted that if $\overline{\mathcal{F}} \otimes \mathcal{O}_{\overline{X}}(l)$ is generated by global sections, hence $\mathcal{F} \otimes \mathcal{O}_X(l)$ is also. My question is, what is the meaning of $\mathcal{O}_X(l)$ ? The map $i$ is just an immersion, so we don't know that $X$ is Proj of some graded ring. Is $\mathcal{O}_X(l)$ just a short-hand for $\mathcal{L}^l$ ?","['sheaf-theory', 'algebraic-geometry']"
2390892,Prove $\frac{1}{\log_2\pi }+\frac{1}{\log_5\pi}>2$,"Knowing that $\pi^2 < 10$. Prove that:
  $$\frac{1}{\log_2\pi}+\frac{1}{\log_5\pi}>2.$$ I have tried to do this the following way: $\log_2\pi+\log_5\pi>\frac{1}{2} \Leftrightarrow \log_2\pi+\frac{\log_2\pi}{\log_25}>\frac{1}{2}\Leftrightarrow 2\log_2\pi-\log_25>\frac{1}{2}$ Is this the right way to proceed?","['inequality', 'number-comparison', 'logarithms', 'algebra-precalculus', 'fractions']"
2390912,Collect 'unusual' examples of real-valued functions,"I am trying to collect research papers, articles and books which contain 'weird' or 'unusual' examples of real-valued function. An example of research paper is A Counterexample and an Exact Versoin of Fatou's Lemma in Infinite Dimension An example of article is Some counterexamples on the behaviour of real-valued
functions and their derivatives Examples of books are Surprises and Counterexamples in Real Function Theory Analysis in examples and counterexamples. An introduction to the theory
of real functions Counterexamples in Analysis Question: Can someone provide me more articles and books which are similar to the above? My aim is to learn as many function construction techniques as possible.","['real-analysis', 'examples-counterexamples', 'reference-request', 'functions', 'soft-question']"
2390919,An inequality on sumsets.,"Given two finite sets $A,B\subset \mathbb{R}$, can we assert the inequality $$|A+B|^2\ge |A+A|\cdot|B+B|?$$ I tried to construct an injective function from $(A+A)\times (B+B)$ to $(A+B)^2$ but failed to make the function injective. It's a problem from my classmates, I'm not 100% sure if it's true.","['combinatorics', 'sumset']"
2390940,Why does the inverse metric of the hypersphere have discontinuities?,"Consider the unit hypersphere in $\mathbb{R}^n$, i.e. with the Euclidean metric, using spherical coordinates. The metric tensor is then :
$$ g_{11}=1 $$ $$ g_{ij}=\delta_{ij}\prod_{k=1}^{i-1}\sin^2(\theta_k) $$
where $\delta_{ij}$ is the Kronecker delta.
The inverse metric is then:
$$ g^{11}=1 $$ $$ g^{ij}=\delta_{ij}\prod_{k=1}^{i-1}\csc^2(\theta_k) $$
Notice that if any of $\theta_k=0$, then there will be a problem with $\csc(\theta_k)$. But $\theta_k=0$ seems to be a perfectly reasonable coordinate to be on. Questions: (1) Why does the inverse metric fail to exist when $\theta_k=0$? (2) How do I fix this so that I can use the inverse metric computationally in cases where $\theta_k$ are allowed to freely vary (and vanish) as they can for $g$? I'm hoping I'm making a silly mistake :) (Note: this is true for $n=3$ too)","['riemannian-geometry', 'tensors', 'spherical-geometry', 'spherical-coordinates', 'differential-geometry']"
2390984,How many ways are there to train the players?,"$210$ players participated the summer course.How many ways are there to choose a trainer out of $20$ trainers for each player so that every trainer have to train different number of people? My attempt :If the trainers had to have at least one player to train then we would have at least $1+2+ \dots +20$ players which is equal to $210$ so the answer would be $\frac{210!}{20!19! \dots 1!}$ but the problem is that a trainer can have no players to train so we will have at least $190$ players and we have to check every case which is really hard.Any hints? This question is in chapter ""combination"" of the book so I am looking for a proof using combination more than others.But others are acceptable too.","['combinations', 'combinatorics']"
2390997,Find integral $\int_{-\infty}^{\infty}\cos{\lambda x}\frac{e^x}{1+e^{3x}}dx$,"I want to find integral
$$ \int_{-\infty}^{\infty}\cos(\lambda x)\frac{e^x}{1+e^{3x}}dx $$
where $\lambda$ is real number. First I replaced $e^x$ with $t$. Then the integral changed to $$ \int_{0}^{\infty}\frac{\cos(\lambda \log t)}{1+t^3}dt$$
There are three poles $\frac{\sqrt{3}+1}{2},-1,\frac{-\sqrt{3}-1}{2}$ and $0$, so I tried to use the residue theorem.The integral route is  the quarter circle of the first quadrant with radius $R$, positive real axis, the qurter circle of the first quadrant with radius $\epsilon$ and positive imaginary axis. But I had a questions. ・How do I evaluate the integral on the imaginary axis? It looks like the integral depends on both $R$ and $\epsilon$. Please give me some advice.","['complex-analysis', 'integration']"
2391003,How many moves are at least needed to find a ball that is from the majority?,"We have $7$ balls that at least $4$ of them are made from iron.In a step we can give two of them to a person that can recognize whether  or not the balls are made from the same materials. How many moves are at least needed to find a ball that is from the majority? My attempt :It is easy to see $4$ moves are enough it is just needed to divide the balls into $3$ sets of two balls and a single ball the check that three sets of balls.Then we have to divide the cases according to the number of ""Yes"" or ""No""'s that we hear.Finally you can get in some cases three is enough and in some $4$ is enough.But I can't prove $3$ steps can't be enough.",['combinatorics']
2391016,"Sanity check on example 6.5 from ""Counterexamples in probability and real analysis"" by Wise and Hall","Citing "" Example 6.5. There exists a real-valued function defined on the plane that is discontinuous and yet such that both partial derivatives exist and are continuous. Proof It is well know that if $f:\mathbb{R} \to \mathbb{R}$ is differentiable, then $f$ is continuous. What if $g:\mathbb{R}^2 \to \mathbb{R}$ is such that both partial derivatives exist and are continuous? Must $g$ be continuous? Consider the function defined via $$g(x,y)= \begin{cases} \frac{xy}{x^2+y^2} & \text{ if } (x,y) \neq (0,0) \\ 0 &\text{ if } (x,y)=(0,0)\end{cases}$$ Then it trivially follows that each partial derivative of g exists and is continuous. However, note that $g$ is not continuous. Note also that this function g is continuous in each variable but is not continuous.
"" However, computing the $x$ partial derivative at $(x,y) \neq (0,0)$ we get, for $x=0,y \neq 0, 1/y$. So the partial derivatives cannot be continuous at $(x,y)=(0,0)$ even though they exist there. Is it, as I think, some elementary mistake by the authors, or is it me who don't understand something obvious?
If it is indeed such an elementary mistake, is this book considered in general to be otherwise trustable?","['real-analysis', 'examples-counterexamples', 'partial-derivative', 'multivariable-calculus', 'book-recommendation']"
2391038,"when are the successive approximations using picard's method for solving an ODE, are the terms of the taylor expansion of the solution of the ODE","The question is as stated in the title, as is ""when are the successive approximations using picard's method for solving an ODE, are the terms of the taylor expansion about $x=0$ of the solution of the ODE"". In this question : Solve $y'=y$, $y(0)=1$ using method of successive approximations, obtaining the power series expansions of the solution , the approximations are indeed the terms of the taylor expansion about $x=0$ of the solution. But, when solving $y' = y^2, y(0)=1$, the second approximation is not the same as the taylor expansion about $x=0$ of the solution of the ODE. first approximation = 1 second approximation = $1+x$ third approximation = $1+x+x^2+x^3/3$ Any help appreciated.",['ordinary-differential-equations']
2391039,Prove $n! +5$ is not a perfect square for $n\in\mathbb{N}$,"I have a proof of this simple problem, but I feel that the last step is rather clunky: For $n=1,2,3,4$ we have $n!+5=6,7,11,29$ respectively, none of which are square. Now assume that $n\geq 5$, then:
$$\begin{aligned}
n! +5 & \;=\; n(n-1)\cdots 6\cdot 5 \cdot 4 \cdot 3 \cdot 2 \cdot 1 + 5 \\[0.2cm]
& \;=\; 5\left[ \frac{}{} n(n-1)\cdots 6\cdot 4 \cdot 3 \cdot 2 \cdot 1 + 1 \right] \\[0.2cm]
&\;=\; 5(3k+1) 
\end{aligned}$$
for some $k\in\mathbb{N}$. Since $5(3k+1)=15k+5\equiv 5\,\text{mod} \, 15$ and all perfect squares are congruent either $0,1,4,6, 9$ or $10\,\text{mod}\,15$, the result follows.  $\;\blacksquare$ It took a pretty tedious exhaustive search of squares modulo 15 in the last step; is there a theorem I am missing that means the last step follows immediately? Your comments are much appreciated!","['number-theory', 'perfect-squares', 'square-numbers', 'elementary-number-theory']"
2391066,An Entire function with growth estimate implies $f(z) = \sin{z}$,"Saw this one from an old exam and have been having trouble trying to crack it. Suppose $f(z)$ is an entire function satisfying $f'(0)=1$, $f(k\pi)=0$ for every integer $k$, and $|f(x+iy)| \leq e^{|y|}$ for $x,\, y \in \mathbb{R}$. Show that $f(z) = \sin{(z)}$. As with similiar problems involving growth estimates and entire functions, my initial idea was to exploit a function like $g(z) = \dfrac{f(z)}{e^{|y|}}$, however I almost feel like its a better idea attacking the coefficients of $f's$ series expansion. Any ideas would be helpful.",['complex-analysis']
2391093,guessing geometric series from a partial sum?,"I had thought the answer would be $b$ since the graph seems to be nearing a specific value and the infinite geometric sum is defined only when $|r| < 1$. However, the answer states it is $c$. Am I wrong (if so how and why), or is the answer wrong?","['algebra-precalculus', 'sequences-and-series', 'graphing-functions']"
2391099,Diagonal dominance preserved by row elimination,"I'm trying complete a proof I've seen in a class, which says that diagonally dominant matrices have an LU decomposition. For this, given a diagonally dominant matrix $A \in \mathbb{R}^{n \times n}$  we know that if sequence $A^{(0)}, \ \dots \ , \   A^{(n-1)} $ defined as $$
A^{(0)} = A \\ 
a_{ij}^{(k)} = a_{ij}^{(k-1)} -  \frac{a_{ik}^{(k-1)} \cdot a_{kj}^{(k-1)}}{a_{kk}^{(k-1)}} 
$$ which consists of each step of gaussian elimination without pivoting is well defined, (i.e $\ a_{kk}^{(k-1)} \neq 0 $ for each $k$), then there is a LU decomposition. Therefore, it is sufficient to show the stronger statement: If $A^{(k)}$ is diagonally dominant, $A^{(k+1)}$ is as well. Now, here is where I've lost track of my notes. I know this has to be true but I've failed to succeed in proving it. We want to show that $$
\sum_{j \neq i}|a_{ij}^{(k)}| < |a_{ii}^{(k)}|
$$ which is equivalent to $$
\sum_{j \neq i}|a_{ij}^{(k-1)} -  \frac{a_{ik}^{(k-1)} \cdot a_{kj}^{(k-1)}}{a_{kk}^{(k-1)}}| < |a_{ii}^{(k-1)} -  \frac{a_{ik}^{(k-1)} \cdot a_{ki}^{(k-1)}}{a_{kk}^{(k-1)}}|
$$ Any thoughts?","['matrices', 'numerical-methods', 'gaussian-elimination']"
