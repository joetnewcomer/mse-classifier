question_id,title,body,tags
1545044,"If every rearrangement of a Schauder basis is also a basis, it is an unconditional one","Let $(e_n)_{n=1}^{\infty}$ be a Schauder basis for the Banach space $X$. Suppose for any bijection $\sigma:\mathbb N \to \mathbb N$, $(e_{\sigma(n)})_{n=1}^{\infty}$ is also a Schauder basis, then is it true that $(e_n)_{n=1}^{\infty}$ is an unconditional Schauder basis?(The question is raised by one of my friends. The converse is part of the definition .) I have tried very hard to prove that 
for any $x \in X$, there exists $(a_n)_{n=1}^{\infty}$ such that
$$\sum _{n=1}^{\infty}a_n e_n=x=\sum _{n=1}^{\infty}a_{\sigma(n)} e_{\sigma(n)}$$ Since there is no conditions about the absolute convergence, we cannot use the proof for ""absolute convergence $\Rightarrow$ unconditional convergence"".
Can anybody show me a proof or an counterexample for this?","['banach-spaces', 'functional-analysis', 'schauder-basis']"
1545051,"$W^{1,p}$ is separable for $1\leq p<\infty$","I've been asked to prove that the Sobolev spaces $W^{1,p}(\Omega)$, $\Omega$ open in $\mathbb R^n$, are separable for $1\leq p <\infty$ using the map $$i\colon W^{1,p}(\Omega)\to L^p(\Omega)\times L^p(\Omega)^n \quad u\mapsto (u,\nabla u).$$ I've done something and I would like to know if it is correct. $W^{1,p}(\Omega)$ is endow with the norm $||u||_{W^{1,p}}:=||u||_{L^p}+||\nabla u||_{{(L^p)}^n}$. Now, I guess that $L^p(\Omega)\times L^p(\Omega)^n$ is endowed with the same norm as $W^{1,p}(\Omega)$ (right?), that makes $L^p(\Omega)\times L^p(\Omega)^n$ a Banach space. With this norm, $i$ is a linear isometry. Moreover $L^p(\Omega)\times L^p(\Omega)^n$, with the norm above, is a separable metric space. In particular $i(W^{1,p}(\Omega))$ is separable, that is, there exists a countable subset $S\subset L^p(\Omega)\times L^p(\Omega)^n$ which is dense in $i(W^{1,p}(\Omega))$. Since $i$ is an isometry, we have that $i^{-1}(S)$ is a countable dense subset of $W^{1,p}(\Omega).$ Is it correct?","['sobolev-spaces', 'metric-spaces', 'solution-verification', 'functional-analysis', 'topological-vector-spaces']"
1545083,What happens to poles lying on branch cuts in contour integration?,"Inverse the Laplace Transform $$\frac{1}{\sqrt{s}}\cdot\frac{1}{1 + s}$$ back to time domain requires evaluation of Bromwich integration: $$\frac{1}{2\pi i}\int_{\gamma-i\infty}^{\gamma+i\infty} \frac{1}{\sqrt{s}}\cdot\frac{1}{1 + s} e^{st} ds$$ The $\sqrt{s}$ term causes a branch cut along the negative half $x$ -axis, including the origin. My question is what happens to the point $(-1, 0)$ : it is both a pole, and lies on the branch cut.
More specifically, when constructing the contour integration path, could I just ignore the pole because the branch cut removes it (figure A), or I should deform the contour as half circles around the pole, once on each side of the branch cut (figure B), as if the pole is duplicated ? Figure A and B: contour integration path","['contour-integration', 'laplace-transform', 'complex-analysis', 'cauchy-principal-value']"
1545095,Closed form of the integral,"$$I=\int_{-1}^1 \frac{\sin\left(\frac{\sinh x}{x}\right)\cdot\log\left(\frac{1+x}{1+x^2}\right)}{x} \space\text{d}x$$ According to Wolfram Alpha, the integral comes out to $$I=2.1607...$$ I don't have a clue on how to solve this because of how the $x$ value is deeply nested here. An answer I am looking for does the following: a) Showing each step. All of your steps also much use only the real plane. I.E. Real Analysis b) You don't have to state theorems in your work, but if what you did is not obvious, just explain. Thanks for any help. EDIT: this integral has a specific application. That application is that I am just beginning to work on nested integral arguments. The further I get in my study, I consistently give myself challenge problems. Strangely, after a while of trying to crack this, I got nowhere! I just wanted to see how to do this and where my mistake lay. (On original trial of the problem, I tried to substitute $x^2$ with $-u^2$ and ignored the fact that $x \not\to -u$)","['closed-form', 'trigonometry', 'real-analysis', 'integration']"
1545116,Surface Integral,"How to find the surface integral of such term $\int \int_{F_+} (y-z)dydz + (z-x)dzdx +(x-y)dxdy$ where $F_+$ is the surface $x^2+y^2 = z^2$ $(0 \leq z \leq h )$ oriented outward. There were other problems, where I could just parametrize the $F_+$ and then compute $\vec{n}$ and simply put in the surface integral formula, but here I'm confused on how to carry on. Hints please. Thanks.",['multivariable-calculus']
1545118,A rank-one matrix is the product of two vectors,Let $A$ be an $n\times m$  matrix. Prove that $\operatorname{rank} (A) = 1$ if and only if there exist column vectors $v \in \mathbb{R}^n$ and $w \in \mathbb{R}^m$ such that $A=vw^t$. Progress: I'm going back and forth between using the definitions of rank: $\operatorname{rank} (A) = \dim(\operatorname{col}(A)) = \dim(\operatorname{row}(A))$ or using the rank theorem that says $ \operatorname{rank}(A)+\operatorname{nullity}(A) = m$. So in the second case I have to prove that $\operatorname{nullity}(A)=m$-1,"['vector-spaces', 'rank-1-matrices', 'matrices', 'matrix-rank', 'linear-algebra']"
1545132,Question about the proof of Rudin's Theorem 2.30,"The theorem states: Suppose $Y \subset X$. A subset $E$ of $Y$ is open relative to $Y$ if and only if $E = Y \cap G$ for some subset $G$ of $X$. I think the proof in the forward direction is relatively clear, however I have some problems relating the backward direction. The proof is relatively quick and goes as (Rudin, pg. 36): If $G$ is open in X and $E = G \cap Y$, every $p \in E$ has a neighborhood $V_p \subset G$ (open ball $B_{r_p}(p) = \{x \in X: d(p, x) < r_p \}$). Then $V_p \cap Y \subset E$, so that $E$ is open relative to Y. In order to prove that $E$ itself is and open set in $Y$, wouldn't we want to prove that for each $p \in E$, there is an open ball contained in $Y$. Thus would it work to remedy the proof by taking a ball for each $p$ with the following radius: $r_p' = \min \{ r_p, \sup_{x \in E} d(p, x) \}$ ? Then we could guarantee that the ball that is guaranteed by the openness of $G$ will let conclude the openness of $E$ relative to $Y$. Thank you very much.",['real-analysis']
1545184,Maximizing the Parameters of a Function,"I am currently in an assistant student research position (I am working directly with a, for sake of privacy, Dr. R, on developmental Toxicity Dose-Response Modeling simulation). I am currently using R trying to maximize and estimate using the 'mle' function (maximum likelihood estimate). Having trouble with this question before I have asked questions on sister sites found here: Trouble With MLE! The function with parameters I want to estimate is, $$L\varpropto \sum_{i=1}^g\sum_{j=1}^{m_i}\{\sum_{k=0}^{x_{ij} -1}log(\mu_i +k*\theta_i )+\sum_{k=0}^{n_{ij}-x_{ij}-1}log(1-\mu_i+k*\theta_i)-\sum_{k=0}^{n_{ij}-1}log(1+k*\theta_i)\}$$ where, $g, m_i, x_{ij},and \space n_{ij}$ are already known. This means the parameters i want to estimate and maximize are $\mu_1...\mu_g$ and $\theta_1...\theta_g$ . I have initial values for both $\mu\space and\space\theta$ . My Question is: What methods can I use to maximize and estimate these parameters? Though I have been using the mle function as shown in the above link, I was curious to see if there were other methods since I could not get the mle function to work. The research i have done online points me to other statistical software or R, which i am obviously having trouble with. Any help would be appreciated!","['optimization', 'statistics', 'parameter-estimation']"
1545200,"Suppose $f: [0,1] \rightarrow \mathbb{R}$ is continuous and $f(0)=f(1)$.","Suppose $f: [0,1] \rightarrow \mathbb{R}$ is continuous and $f(0)=f(1)$. The question asks to give a specific example of $f$ such that: for all $a,b \in [0,1]$ that satisfy $|a-b|=\frac {2}{5}$, $f(a)\ne f(b)$.","['continuity', 'real-analysis', 'functions']"
1545215,How to show this equation equals zero?,"Let $P(z)$ denote a complex polynomial of degree $n$ with simple zeros $a_1, . . . , a_n$. Show that $\sum\limits_{k=1}^{n}\dfrac{a_k^p}{P'(a_k)}=0$, for $p=0,1,...n-2$. I have no idea where to start and the naive way of solving it by brute force is just not working. Any hint would be appreciated.","['polynomials', 'complex-analysis', 'complex-numbers']"
1545219,number theory- sum using Von-Mangoldt functiom,"I am trying to do the following proof: 
""show that there exists an integer c such that $$c*\ln(2)- \frac{1}{2} \, (\ln(2))^2 = \sum_{n=1}^{\infty} \frac{ (-1)^n \ln(n)}{n}$$ I have thought of replacing log(n) by the Von Mangolt function, without success. I'm also thinking that I might need to use the Chebychev approximations theorem.  i.e. $$ \frac{c_{1} \, x}{\ln(x)}  \leq \pi(x) \leq \frac{c_{2} \, x}{\ln(x)}$$ Thoughts, anyone?
J.M.",['number-theory']
1545233,Prove existence a maximal pairwise disjoint subfamily $\mathcal{S} \subseteq \mathcal{R}$,"Can anyone help me with this: Suppose $\mathcal{R}$ is any family of sets. Prove that there exists set $\mathcal{S} \subseteq \mathcal{R}$, which is pairwise disjoint and for each $A \in \mathcal{R}-\mathcal{S}$, there exists $B  \in  \mathcal{S}$ with following property: $A  \cap  B \neq \emptyset$. I have no idea where to start. Thanks in advance for help.",['elementary-set-theory']
1545257,Exponential order in Laplace Transform:constructing a function such that it is of exponential order but its derivative is not.,"I don't understand how to construct such function.I know the definition of a function being of exponential order which states that: $f(t)$ is of exponential order if there exist constants $c,M>0,T_0>0$ such that $|f(t)|e^{-ct} \le M$ for all $t>T_0$. Second Question:Any example which is not of exponential order but its Laplace tranform exists?If I consider $e^{t^2}$,it's not of exponential order.But does its Laplace tranform exist?? Any help is appreciated,as always.Thanks in advance.","['laplace-method', 'real-analysis', 'laplace-transform', 'complex-analysis', 'partial-differential-equations']"
1545258,On the relation of Completeness Axiom of real numbers and Well Ordering Axiom,"In my abstract algebra book one of the first facts stated is the Well Ordering Principle: (*) Every non-empty set of positive integers has a smallest member. In real analysis on the other hand one of the first things introduced are the real numbers and their Completeness Axiom: Every nonempty set of real numbers having an upper bound must have a least upper bound. Which is equivalent to: (**) Every nonempty set of real numbers having a lower bound must have a biggest lower bound (infimum). It has never been mentioned in any book I've read and I don't know if they have anything to do with each other but (*) and (**) seem to me to be such that (**) implies (*). Is the Well Ordering Principle a consequence of the Completeness of
  the real numbers? Or do they have nothing to do with each other? How
  should I think of them in terms of how they relate to each other? Is it okay to see one as a consequence of the other?","['real-numbers', 'axioms', 'real-analysis', 'order-theory']"
1545283,how does $p | (a^2 + b^2)$ force $p | b^2$,"I have a question that reads: if $p | a$ and $p|(a^2+b^2)$, then $p | b$. In the solution menu it reads: since $p|a$, $p|a^2$. Now $p|a^2$ and $p|(a^2+b^2)$ forces $p|b^2$. we can conclude that $p|b$.
I honestly have no idea how $p|(a^2+b^2)$ can give you $p|b^2$.",['discrete-mathematics']
1545310,How do you prove indeterminate form using epsilon and delta?,"The question, for instance, is proving $$\lim_{x\to\infty}\frac{x}{x+1}=1$$ This is my answer, which is likely incorrect. $$\forall\epsilon>0, \exists M \in \mathbb{R}$$  such that $$ x>M \Rightarrow \left|\frac{x}{x+1}-1\right|<\epsilon$$ $$\left|\frac{x}{x+1}-1\right|<\epsilon \iff
\frac{1}{|x+1|}<\epsilon \iff |x+1|>\frac1\epsilon$$ I then get $x>\frac{1-\epsilon}{\epsilon}$ Picking $M=\frac{1-\epsilon}{\epsilon}$,  I get $$x>M=\frac{1-\epsilon}{\epsilon}\Rightarrow x>\frac1\epsilon - 1 \Rightarrow \cdots \Rightarrow \left|\frac{x}{x+1}-1\right|<\epsilon$$ Could anybody please point out which part should I add or fix?","['calculus', 'limits', 'indeterminate-forms', 'epsilon-delta']"
1545322,"Is $C[0,1]$ larger than $\mathbb R$? [duplicate]","This question already has answers here : Cardinality of set of real continuous functions (6 answers) Closed 8 years ago . Let $C[0,1]$ be the set of all continuous function from $[0,1]$ to $\mathbb R$. 
Is the cardinality of $C[0,1]$ larger than or equal to that of $\mathbb R$?",['elementary-set-theory']
1545339,"Proving that an inequality is true, from assuming that second derivatives exist, and first derivatives are zero on the boundary,","EDIT 2: I just posted my revised proof, where I used two Taylor expansions, and subtracting both equations to get something that's pretty close to what I want.  What do you think?  Please see below.  Thanks, EDIT:  I think that, with the help of Joey Zou and Claudeh5's attempts at a solution (please see below), I am pretty close to an answer.  At present there are some things of concern: a) Joey Zou's more technical proof seems to rely on $f''$ being continuous or at least Riemann-integrable.  Unfortunately, I don't think we can assume that. b) Claudeh5's cute one-line proof almost does the job.  It uses Taylor expansion, the Lagrange Remainder, and centering the expansion about  $x=a$, and evaluating the series at $x=b$.  However, the estimate is not quite good enough. Any hints or comments are welcome.  Thanks, The problem statement is: Assume that $f(x)$ has second derivatives on [a,b], and $f′(a)=f′(b)=0$. Prove that there exists a point $c∈[a,b]$ such that $f′′(c)≥\frac{4}{(a−b)^2}|f(b)−f(a)|$. Using Claudeh5's approach, here is my revised proof, which is perhaps closer to the desired upper bound: By Taylor expansion, and the Lagrange remainder, we have that $$f(b) = f(a) + \frac{f''(\psi_1)}{2!} (b-a)^2$$ Now again, but centering the expansion about $x=b$ gives us $$f(a) = f(b) + \frac{f''(\psi_2)}{2!} (a-b)^2$$ Note that the first derivatives vanish at $x=a$ and $x=b$, by assumption. Now subtracting the two Taylor series gives $$2[f(b)-f(a)]= \frac {[f''(\psi_1) - f''(\psi_2)]}{2!}(a-b)^2$$ $$\implies \frac  {4[f(b)-f(a)]}{(a-b)^2}= [f''(\psi_1) - f''(\psi_2)]$$ $$\implies \frac  {4[f(b)-f(a)]}{(a-b)^2} \le max \{f''(\psi_1), f''(\psi_2)\}$$ $$=:f''(c)$$ I am not confident about the last two lines of my proof. Am I on the right track?  I feel a bit closer now to achieving the upper bound ... Thanks,","['calculus', 'real-analysis', 'derivatives']"
1545350,Sheaf of regular functions,"I am trying to show that if $X$ is an (irreducible) affine variety, then $O_X$, which is the set of rings $O_X(U)$ of regular functions on open subsets of $X$, with the obvious restriction maps, is really a sheaf. I am able to verify that $\rho_{U,U}$ is the identity for any inclusion $U\subset V\subset W$, we have $\rho_{V,U}\circ\rho_{W,V}=\rho_{W,U}$. Also, I can show the glueing property. However, I can't show that $\mathcal{F}(\emptyset)=0$. How would the definition work, seeing that
$$\mathcal{F}(\emptyset)=O_X(\emptyset)=\bigcap_{P\in\emptyset}O_{X,P}.$$ So how does one show that $\mathcal{F}(\emptyset)=0$?","['algebraic-geometry', 'sheaf-theory']"
1545355,Determine if H is a normal subgroup of G - faster way than finding cosets?,"$G = S_4$, $H = \{(1),(12)(34),(13)(24),(14)(23)\}$. I just did it the long way, and found H to be normal. Is there a better way than finding left and right cosets?  I don't want to spend this kind of time during a test if it comes up again.","['group-theory', 'normal-subgroups']"
1545363,Decreasing by $\sqrt{n}$ every time,"We start with a number $n>1$. Every time, when we have a number $t$ left, we replace it by $t-\sqrt{t}$. How many times (asymptotically, in terms of $n$) do we need to do this until our number gets below $1$? Clearly we will need more than $\sqrt{n}$ times, because we need exactly $\sqrt{n}$ times if we replace $t$ by $t-\sqrt{n}$ every time. The recurrence is $f(n)=1+f(n-\sqrt{n})$, but I'm not sure how to solve it.","['asymptotics', 'algebra-precalculus']"
1545364,What is the probability that $\triangle ABP$ has a greater area than each of $\triangle ACP$ and $\triangle BCP$?,"A point $P$ is chosen at random in the interior of the equilateral
  triangle $ABC$.What is the probability that $\triangle ABP$ has a
  greater area than each of $\triangle ACP$ and $\triangle BCP$? Since the three triangles $ABP,ACP$ and $BCP$ have equal bases,their areas are proportional to their length of altitudes. But i dont know how to solve further and find the required probability.Please help me.Thanks.","['geometry', 'probability', 'trigonometry']"
1545385,put the following in standard form,"how do I compute the following by putting it in standad form?
\begin{equation}
(2-2\sqrt{3i})^{20}
\end{equation} what I have tried to do is use de Moivre theorem but that requires me to put it in polar form, as in z=... but I don't know how to do that either.","['complex-numbers', 'discrete-mathematics']"
1545399,A name for elements of a group generating the same cyclic subgroup,"Elements with similar properties usually deserve a name in many contexts, say primitive elements in finite fields, integers modulo a number $n$, generators of a free groups etc. Does there exist a similar name for elements of a group generating the same cyclic subgroup?","['group-theory', 'finite-groups', 'terminology']"
1545449,Find a power series representation for the function. (Assume $a > 0$.),I'm down to my last attempt (my teacher allows $5$ tries per question)! Thank you!!,"['power-series', 'convergence-divergence', 'calculus', 'functions']"
1545488,What is the probability that he counts head more that tails when tosses a coin 6 times,"Suppose kitty tosses a coin 6 times. What is the probability that she counts more ""heads"" than tails? This is a question from the test and I got only partial marks so I am wondering what is the solution to this. What I did was I assume the number of coin outcomes,for example: hhhhhh,tttttt,and so on and I use the formula P(E) = n(E)/n(S) 
where n(E) is the number of events n that has heads more than tails.","['probability', 'discrete-mathematics']"
1545495,Problem involving trace and determinant of symmetric matrices,"I've stumbled upon this exercise on a linear algebra book that asks me to determine all the ordered pairs $(a,b)$ of real numbers to which there exists an unique symmetric matrix $A\in R^{2\times 2}$ so that $tr(A)=a$ and $Det(A)=b$.
I don't even know how to tackle this problem, I've tried using Laplace expansion, and other properties of the trace and determinants. Any help will be appreciated.","['determinant', 'linear-algebra', 'trace']"
1545567,Find $\nabla \|x^HAx - b\|_2^2$,"I have to find- $$\nabla\|x^HAx - b\|_2^2,$$ where $x$ is a vector and $A$ is a $4\times 4$ hermitian matrix. I am trying to solve it by using identities given in https://en.wikipedia.org/wiki/Matrix_calculus but I am not able to figure out which identity suits my problem. I would appreciate if anyone tells me how to tackle this problem.","['derivatives', 'matrix-calculus', 'matrices']"
1545612,$f$ bounded but $f'$ isn't,"Is there a bounded function $f$ that holomorphic on the open unit disc but $f'$ isn't bounded? I think first $f$ shouldn't be analytic outside the unit disc then we can't use Cauchy's inequality, because 
$$|f'(z)|\le\frac{\max|f|}{R}$$
When $z$ near the bound of unit disc $R$ should be small so $|f'(z)|$ can be large","['analysis', 'examples-counterexamples', 'complex-analysis']"
1545624,Function defined as a limit,"Q. If $f(x)=\lim\limits_{n\to\infty}\dfrac{\log(2+x)-x^{2n}\sin(x)}{1+x^{2n}}$, then explain why the function does not vanish anywhere in the interval $[0,\pi/2]$, although $f(0)$ and $f(\pi/2)$ differ in sign. My solution: First, we simplify the limit a bit. $$f(x)=\lim_{n\to\infty}\frac{\log(2+x)-x^{2n}\sin(x)}{1+x^{2n}}=\lim_{n\to\infty}\frac{\log(2+x)-(x^{2n}+1-1)\sin(x)}{1+x^{2n}}\\ \implies f(x)=\lim_{n\to\infty}\frac{\log(2+x)+\sin(x)}{1+x^{2n}}-\sin(x)$$ Now, we divide the interval $[0,\pi/2]$ into three parts, viz ., $x\in [0,1)$, $x=1$ and $x\in (1,\pi/2]$. For the first part, i.e., when $x\in [0,1)$, we have $|x|\lt 1$ and hence $1+x^{2n}\to 1+0=1$ as $n\to\infty$, hence, by the quotient rule of limits, it reduces to, $$f(x)=\log(2+x)+\sin(x)-\sin(x)=\log(2+x)~\forall~x\in [0,1)$$ At $x=1$, we have $f(x)=\lim\limits_{n\to\infty}\frac{\log3+\sin(1)}{1+1^{2n}}-\sin(1)=\frac 12(\log3-\sin1)$ For $x\in (1,\pi/2]$, we have $|x|\gt 1$, hence $1+x^{2n}\to\infty$ as $n\to\infty$. But $\log(2+x)$ and $\sin(x)$ are finite constants for a particular $x$. Hence, the limit goes to $0$ as $n\to\infty$ and we get $f(x)=0-\sin(x)=-\sin(x)~\forall~x\in (1,\pi/2]$. So, we write our results collectively as, $$f(x)=\begin{cases}\begin{align}\log(2+x)&&\forall~x\in [0,1)\\ \frac 12(\log3-\sin1)&&\textrm{at }x=1\\ -\sin(x)&&\forall~x\in (1,\pi/2]\end{align}\end{cases}$$ It's easy to verify now that $f(x)$ doesn't vanish in $[0,\pi/2]$ since, for $x\in [0,1)$, we have $f(x)=\log(2+x)\gt \log1=0$ since logarithm is strictly increasing. At $x=1$, the function value is obviously not $0$ since $\log3\neq\sin1$ and for $x\in (1,\pi/2]$, we have $f(x)=-\sin(x)\in [-1,-\sin 1)$ since sine is strictly increasing in $[0,\pi/2]$. Now, the explanation behind why $f(x)$ doesn't vanish even when $f(0)$ and $f(\pi/2)$ differ in sign would be that $f(x)$ isn't continuous on $[0,\pi/2]$, more specifically it's discontinuous at $x=1$ with left hand limit being $\log3$ and right hand limit being $-\sin1$ and hence Bolzano's theorem isn't applicable for $f(x)$ on $[0,\pi/2]$. Comments about my solution and improvements are welcome. Thanks! :)","['limits', 'real-analysis', 'proof-verification']"
1545627,"Is the axiom schema of specification sufficient for solving Russell's paradox? If so, why?","This is basically a two part question, as the title indicates. I understand why unrestricted comprehension will produce paradoxes like the Russell set, but I'm less clear on the question how the axiom of separation (or specification) solves this issue (and even whether it is able to solve it). Is the point that any set B defined in terms of having exactly those sets as members that are not members of themselves can never itself be a member of some arbitrary set A? In that case does this simply show that the Russell set is necessarily excluded from the things that one can meaningfully say about sets? Any help on any aspect of this question would be appreciated!","['paradoxes', 'elementary-set-theory', 'axioms']"
1545633,How to identify lattice in given hasse diagrams?,"Consider the following Hasse diagrams. and given here , Counter example on wiki : Says "" Non-lattice poset: b and c have common upper bounds d, e, and f, but none of them are the least upper bound."" But my question is : f is least upper bound, right? Similarly, Says""Non-lattice poset: a and b have common lower bounds 0, d, g, h, and i, but none of them are the greatest lower bound."" But my question is : 0 is greatest lower bound, right? Can you explain lattice such that I can identify above lattices in hasse diagrams?","['lattice-orders', 'group-theory', 'relations', 'discrete-mathematics']"
1545656,"Evaluating $\int_0^{\infty} \frac {e^{-x}}{a^2 + \log^2 x}\, \mathrm d x$","I am trying to evaluate this integral $$I=\int_0^{\infty} \frac {e^{-x}}{a^2 + \log^2 x}\, \mathrm d x$$ for $a \in \mathbb R_{>0}$. Any ideas? In the case $a=\pi$ we have $I= F - e$ where $F$ is the Fransén–Robinson constant.","['improper-integrals', 'definite-integrals', 'integration']"
1545660,Limit with fractional part,Find $$\lim_{x\to 0}\frac{\sin\{x\}}{\{x\}}$$ where $\{x\}=$ fractional part $=x-[x] $. Please help me to solve. I know the defn of $[x] $ and $\lim_{x\to 0-}[x]=-1$ and $\lim_{x\to 0+}[x]=0$.,"['calculus', 'limits']"
1545691,Limit with fractional part and greatest integer part,"Find $$\lim_{x\rightarrow 2-} \{x+(x-[x]^2)\}$$ For $x\to 2-$, $[x]=1$, i.e $[x]^2=1$, so $\lim_{x\rightarrow 2-} \{x+(x-1)\}=\lim_{x\rightarrow 2-} \{2x-1\}=3.$ I don't know whether $\{\}$ symbolizes fractional part=$x-[x]$ or not for this particular question. I have assumed  $\{\}$ not as fractional part and solved. Please check my solution is correct or not. In case $\{\}$ symbolizes fractional part=$x-[x]$, then what will be the answer?","['calculus', 'limits']"
1545709,Equality of integrals and Almost sure equality of random variables,"Given two random variables X,Y with $E |X|<\infty$, $E |Y|<\infty$ and the equality $$\int_{D}X dP=\int_{D}Y dP, D\in\mathcal{D}$$ where $\mathcal{D}$ is some sigma algebra on the background space. What are the sufficient conditions so that we can conclude that $X$ and $Y$ are almost surely equal? Likewise, if we have two random variables that are almost surely equal, do we have the equality in the integrals above in general?","['probability-theory', 'measure-theory']"
1545813,Proof that the range of a map is determined by its behaviour on the boundary.,"Let f be a mapping from an open neighbourhood of the 3-dimensional unit ball to the 2-dimensional plane. Suppose that f is smooth (infinitely continuously differentiable on its domain) and regular (it's derivative, as a 2x3 matrix, has rank 2 everywhere). I would like a proof, or informed hint, or counterexample, for the claim that the f restricted to the closed unit ball has the same range as f restricted to the unit sphere. It is not difficult to construct a counterexample when f is allowed to be nonregular. I have stated the problem for a mapping from 3 to 2 dimensions but there may be a similar problem going from n to n-1 dimensions. For n=2 the proof is trivial: a regular differentiable mapping from the closed unit disk to the line reaches its maximum on the boundary circle.","['derivatives', 'differential-geometry', 'differential-topology', 'matrices']"
1545832,"(dis)prove:$\sup_{F \in 2^{(L^1(S,\mathbb{R}))}}\limsup\sup_{f\in F}|\int f dP_n-\int fdP|=\limsup\sup_{f\in L^1(S,\mathbb{R})}|\int fdP_n-\int fdP|$","Let $(S,d)$ be a complete separable metric space and consider the set $L^1(S,\mathbb{R})$ of functions $f:S \rightarrow \mathbb{R}$ which are 1-Lipschitz, i.e. $\forall x,y \in S: |f(x) - f(y)| \leq d(x,y)$. Further let:
$$
\mathcal{P}^1(S) := \{P: \mathcal{B}_S \rightarrow [0,1] \mid P \mbox{ probability measure:} \forall a\in S: \int d(a,x) P(dx) < \infty \},
$$
where $\mathcal{B}_S$ is the set of Borel sets induced by the topology which corresponds to $d$. Suppose further we have some $P \in \mathcal{P}^1(S)$ and a sequence $(P_n)_n$ in $\mathcal{P}^1(S)$. Now we consider the claim:
$$\sup_{F \in 2^{(L^1(S,\mathbb{R}))}} \limsup_{n\rightarrow \infty} \sup_{f\in F} \left| \int f dP_n - \int f dP \right| = \limsup_{n\rightarrow \infty} \sup_{f\in L^1(S,\mathbb{R})} \left| \int f dP_n - \int f dP\right|.$$
Here we write $2^{(X)}$ for the collection of finite subsets of $X$.
I've already shown (with the help of the people on stackexhange: Convergence of $\int f dP_n$ to $\int f dP$ for all Lipschitz functions $f$ implies uniform integrability ) that the left hand side is zero if and only if the right hand side is zero. I would however not expect these values to be equal, but I can't seem te find any counterexample. EDIT:
In the case where $(S,d) = (\mathbb{R},d_{\mathbb{E}})$ we have:
$$
\limsup_{n\rightarrow \infty} \sup_{f\in L^1(S,\mathbb{R})} \left| \int f dP_n - \int f dP\right| = \limsup_{n\rightarrow \infty} \sup_{f \in L^1(S,\mathbb{R})} \int_{-\infty}^{\infty} |F(x) - G(x)|dx,
$$
I'm not sure yet if this helps but it gives a new perspective for this case.","['probability-theory', 'measure-theory', 'lipschitz-functions', 'uniform-convergence', 'limsup-and-liminf']"
1545922,Checking Continuity in General.,"Suppose you have a given  Function on $\mathbb R^n$.And you want to check the continuity on a Point.How can you be sure that you checked all possible ways to approach that point$?$That method is useful for proving it does not exist but to prove it does exist you need a more general method.But all methods for continuity have ""for all ..."" in them so how can you check ""for all..."" (sequences ,Open sets,approaches..) whatever definition you wanna use.","['limits', 'continuity', 'real-analysis', 'analysis', 'multivariable-calculus']"
1545956,Proofs in Linear Algebra via Topology,"I'm watching the lecture series by Tadashi Tokieda on Topology and Geometry on YouTube.  In the second lecture he shows how one can prove, using a topological argument, that given two $n\times n$ matrices $P$ and $Q$, the matrix products $PQ$ and $QP$ share the same eigenvalues.  Then he claims that one can also prove that $\det(e^L)=e^{\operatorname{tr} L}$ and the Cayley-Hamilton theorem topologically as well. This has me interested.  Is there some book/ reference work that discusses linear algebra in the context of topology?  Ideally I'd like a book (at maybe the 1st year grad level) on linear algebra that uses topological arguments to prove linear algebraic statements.  Does anyone know of such of work?","['book-recommendation', 'reference-request', 'linear-algebra', 'general-topology']"
1545966,How to calculate if taking a toll road is worth it,"I'm trying to figure out if there's a way to calculate if it's worth taking a toll road if it will save me time. For example, if the toll only costs 50 cents and my trip will save me 30 minutes, I will take the toll.  On the other hand, if the toll is $5 but it will only save me 5 minutes, I will not take the toll. If feel as if there's a mathematical way to calculate this decision, based on: p = price of the toll t = time saved (estimated) v = value of my time Sample inputs: p = 2 dollars t = 15 minutes v = $30/hr Based on this example, is it worth it to take the toll?  And how to make this decision for any inputs?  Perhaps different inputs are needed?  I'm not sure how to set up an equation for this.",['statistics']
1545969,is my answer correct? derivative of logarithmic functions,"I want to check my answer, pleas tell me if it's correct or not first problem $y=\left(\log _{\frac{1}{x}}\left(e\right)\right)$ my answer $y=\frac{lne}{ln_{\frac{1}{x}}}$ $y^|=lne\frac{d\left(\frac{1}{ln_{\frac{1}{x}}}\right)}{dx}=-\left(ln_{\frac{1}{x}}\right)^{-2}\frac{-x^{-2}}{\frac{1}{x}}=\left(lne\right)\left(\frac{-1}{\left(ln_{\frac{1}{x}}\right)^2}\right)\cdot \left(\frac{-1}{x}\right)$ $y^|=\frac{1}{x\left(ln_{\frac{1}{x}}\right)^2}$ second problem $y=\log _{lnx}\left(e\right)$ my answer $y=\frac{lne}{ln\left(lnx\right)}$
$y^|=y=lne\frac{d}{dx}\left(\frac{1}{ln\left(lnx\right)}\right)=\frac{\frac{-\frac{1}{xlnx}}{\left(ln\left(lnx\right)\right)^2}}{\left(ln\left(lnx\right)\right)^{-1}}=\frac{-\frac{1}{xlnx}}{ln\left(lnx\right)}$ $y^|==\frac{-1}{\left(xlnx\right)ln\left(lnx\right)}$","['logarithms', 'derivatives']"
1546006,Study $ h(x)= \sqrt{x^2-1}-x-3$,"Let $g$ be the function defined by
    $$\begin{array}{lrcl}
 h : & [1;+\infty[  & \longrightarrow & \mathbb{R} \\
     & x & \longmapsto & h(x)= \sqrt{x^2-1}-x-3 \end{array}$$ Study the Variations on $[1;+\infty [$, of function $g$ Deduce the sign of $g$ according to $x$ My proof: we have $h'(x)=\dfrac{x}{\sqrt{x^{2}-1} }-1$, always positive on the interval$[1; +\infty[$ , then $h$ is strictly increasing ($ h'$ isn't vanishes for any number $\forall x \in[1;+\infty[,\quad  h'(x)\neq 0$) on the same interval, since it is continuous, it has $h( [1;+\infty[)=[h(1) ;\lim_{x\to +\infty}h(x)[=[-4;-3[$ and then  $h$ is negative on the interval $[1 ;+\infty[$ Is My proof correct ? is there any other way to prove it. Thanks. Update:
here how i calculate the $\lim_{x\to +\infty}h(x)=-3$ \begin{align}
\lim_{x\to+\infty}h(x)&=\lim_{x\to+\infty}\sqrt{x^2-1}-x-3\\
&=\lim_{x\to+\infty}\dfrac{(\sqrt{x^2-1}-(x+3))(\sqrt{x^2-1}+x+3)}{\sqrt{x^2-1}+(x+3)}\\
&=\lim_{x\to+\infty}\dfrac{((x^2-1)-(x+3)^2)}{x\sqrt{1-\frac{1}{x^2}}+(x+3)}\\
&=\lim_{x\to+\infty}\dfrac{-6-\frac{10}{x}}{\sqrt{1-\frac{1}{x^2}}+1+\frac{3}{x}}=\frac{-6}{2}=-3
\end{align}","['continuity', 'calculus', 'real-analysis', 'derivatives']"
1546023,why there are no parabolic (on a paraboloid) non-euclidean geometry?,"I have seen in many contexts that Euclidean geometry is called also ""parabolic geometry"". As in many things in mathematics (conics, differential equations, algebraic equations) the terms: elliptical, parabolic, and hyperbolic refer to the conics with their corresponding names. You could say that a plane is deformed paraboloid (can you?), but why is it that it is not important to consider geometry over a paraboloid? I know Riemannian geometry considers geometry over general surfaces (manifolds) but there might be something uninteresting about parabolids that mathematicians do not like. What is it? Thanks.","['noneuclidean-geometry', 'geometry', 'conic-sections', 'terminology']"
1546037,Beginner's book for Riemannian geometry,"Could you recommend some beginner books for Riemannian geometry to me? I am completely new to Riemannian geometry, but have some basic knowledge of differential geometry. I am looking for a book in Riemannian which is similarly as light as Tu's ""Introduction to Manifolds"" for differential geometry. I know that the classical reference is the book of do Carmo, but I have heard some students complaining that its not a book for the absolute beginner. For the moment, I am just looking for a source to introduce me Riemannian metrics, Riemannian manifolds, curvature, geodesics in a way as clear as possible. Thank you","['book-recommendation', 'differential-geometry', 'riemannian-geometry', 'reference-request']"
1546045,Projection of $F$ onto any line nonparallel to coordinate axes has measure zero.,"Given a square $K=[a,b] \times [c,d]$, we define a union of four squares $K^*\subset K$ as follows: $I_i=[a_i, a_{i+1}]$, $J_i=[c_i, c_{i+1}]$, where $a_i=a+i\frac{b-a}{4}$, $c_i=c+i\frac{d-c}{4}$, for $i=0,1,2,3$ and we let $$K^*=(I_0\times J_1)\cup(I_1 \times J_0) \cup (I_2\times J_3)\cup(I_3 \times J_2).$$ We define a decreasing sequence of compact sets $F_0, F_1, \ldots$ inductively: $F_0=[0,1]^2$, $F_n$ is a finite union of squares $K$, each two having at most one point in common, and $F_{n+1}$ is obtained from $F_n$ by replacing each square $K$ by $K^*$. Let $F=\bigcap_{n=0}^\infty F_n$. Let $\mathcal H^1$ be the Hausdorff measure. Let $\ell$ be a line through $(0,0)$ different from the coordinate axes. Let $\pi:\mathbb R^2\to\ell$ be the orthogonal projection onto $\ell$. Show that $\pi(F)$ is of $\mathcal H^1$-measure null. I have trouble with this exercise. I tried to calculate $\mathcal H^1(\pi(F_n))$ but I failed. Any hints? EDIT: Theorem 3.32 in Falconer's ""The geometry of fractal sets"" states that the projection of $F$ onto almost every line has measure zero. This is weaker than the thesis of this exercise and the proof uses some non-trivial results. I am looking for an elementary argument.",['measure-theory']
1546051,"A set contains $0$, $1$, and all averages of any subset of its element, prove it contains all rational number between 0 and 1","Assume we have a set $S$ $\subseteq \mathbb{R}$, we know $0,1 \in S$. Also, $S$ has the property that if $A \subseteq S$ is finite, the average of elements in $A$ is in $S$. We want to prove that any rational number between 0 and 1 is contained in $S$. Can someone please give me a hint?  I tried to use induction but it seems hopeless to me...","['discrete-mathematics', 'combinatorics']"
1546059,"Does $\sum \frac{\sin^2(nx)}{n^2x}$ converges uniformly on $(0,\delta]$?","I'm already aware, by Parsevsal's theorem, that 
$$\sum_{n=1}^{\infty} \frac{\sin^2(nx)}{n^2x}=\frac{\pi-x }{2}$$ 
is a pointwise convergence on $(0,\delta]$ for all $\delta\in(0,\pi)$. Now I'm wondering, is this convergence also uniform? The first idea that popped into my mind was using Dini's theorem . However, since Dini's theorem requires all the functions to be defined on a compact set, it is not immediately available. But is it possible to extend the definition of $\sin^2(nx)/n^2x$ to $x=0$ so as to make the redefined series fulfill all the conditions that Dini's theorem required? That's to say, can we define a series $\sum f_n(x)$ such that $f_n$ is defined on $[0,\delta]$ and that: 1). $f_n$ is continuous. 2). $f_n(x)=\sin^2(nx)/n^2x$ except at $x=0$. 3). $\sum_{1}^{\infty}f_n(0)=\pi/2$ 4). $f_n\le f_{n+1}$ on $[0,\delta]$. After doing some work I found that the answer is unfortunately no. Because by requiring (1) and (2), we must let $f_n(0)=0$ for all $n$, which contradicts (3). So now I begin to doubt, is it the case that  the convergence just can't be uniform?","['sequences-and-series', 'calculus', 'real-analysis', 'uniform-convergence']"
1546085,Mean of a portion of a normal distribution?,"How do I calculate the mean of a portion of a normal distribution.  In other words, say I have a normal distribution of the heights of adult males.  The mean is 70"" and the standard deviation is 4"".  What is the average height of males above the 95th percentile?  What is the average height of all males below the 95th percentile?  How do I calculate this? Someone asked a similar question here which was never answered clearly: Mean value from part of normal distribution This question has a practical application for my work where I am running a power plant at 10.3 MW mean operating point with a standard deviation of 0.2 MW.  I would like to know the average power when I am above 10 MW.  Or the mean of all points above 10 MW.","['normal-distribution', 'statistics', 'probability-distributions']"
1546103,Solve $\lim \:_{x\to \:1}\frac{1+x+x^2+...\:+x^n-\left(n+1\right)}{x-1}$ [duplicate],"This question already has answers here : How to show $\lim_{x \to 1} \frac{x + x^2 + \dots + x^n - n}{x - 1} = \frac{n(n + 1)}{2}$? (8 answers) Closed 8 years ago . How do I solve limits such as these? The $...$ always make it seem hard to me. From what I can understand from them, they both are $0/0$ limits, and I should be looking to write the numerator in such a way that the denominator should simplify it somehow. For the first I tried writing each element from the numerator as $(a-1)$ where $a = 1, x, x^2 ... x^n$ so that I can simplify the denominator eventually, but I didn't get much out of that. I'm guessing these two are solved in similar ways, hence why I posted them both. Any clues/hints I can get would be appreciated. $$\lim \:_{x\to \:1}\frac{1+x+x^2+...\:+x^n-\left(n+1\right)}{x-1}$$
$$\lim _{x\to 1}\frac{x+x^2+...\:x^n-n}{x+x^2+...\:+x^m-m}$$ $n,\:m\:\in \mathbb{R}$",['limits']
1546148,Determinant of an anti-diagonal block matrix,"Is it true in general that if $A$ and $B$ are two $n \times n$ matrices, then the determinant of the anti-diagonal block matrix $$
J = \left[\begin{array}{cc} 0 & A  \\ B& 0  \end{array}\right]
$$ is $\det(J)=\det(B)\det(A)$?
It is simple to prove this if $n=2$, but I have no idea on how to generalize it.","['determinant', 'block-matrices', 'matrices']"
1546174,values of $a$ for which function $f(x)$ is periodic function.,"The number of real values of $a$ for which $f(x) = x^a+\sin x-ax$ is a periodic function. $\bf{My\; Try::}$ If function $f(x)$ is Periodic function , Then it must satisfy the condition $f(x+T) = f(x)\;,$ Where $T$ is period of that function (Smallest positive value) So Here $(x+T)^a+\sin (x+T)-a(x+T) = x^{a}+\sin x-ax$ So we get $(x+T)^a+\sin (x+T)-aT = \sin x$ From here we can see for $a=0$ and $a=1.$ We get $\sin(x+T)=\sin x.$ So it is a periodic function for $T=2\pi.$ But I did not understand how can we prove that there are only two values of $a$",['algebra-precalculus']
1546217,How to eliminate $\theta$?,While doing a sum I was stuck in a particular step: $$r_1= \frac{4a \cos \theta }{\sin^2 \theta}$$ and $$r_2=\frac{4a \sin \theta }{\cos^2 \theta}$$ How to eliminate $\theta$ ?,"['algebra-precalculus', 'trigonometry']"
1546237,Solve $\lim\limits _{n\to \infty }\lim\limits_{x\to \:0}\left(1+\sin^2x+\sin^22x+\ldots+\sin^2nx\right)^{1/(n^3x^2)}$,"I've no clue how to solve this limit. I tried to solve the inner limit first, but the fact that I have another variable there(n) really makes things difficult(never had to solve such a limit before). How do you go about solving these types of limits?$$\lim_{n\to \infty }\left[\lim_{x\to \:0}\left(1+\sin^2x+\sin^22x+\ldots+\sin^2nx\right)^{1/(n^3x^2)}\right]$$",['limits']
1546240,Galois group of a polynomial of degree seven,"Let $K$ be the splitting field over $\mathbb{Q}$ w.r.t. the polynomial 
$x^7 - 10x ^5+15x+5$.
I think its Galois group is the symmetric group $S_7$. I tried to prove it using a theorem which says:
""If the degree of the polynomial is a prime $p$, the polynomial is irreducible and it has exactly two non real roots, then its Galois group is $S_p$.""
In this case, I know that 
$x^7 - 10x ^5+15x+5$
is irreducible (by the Eisenstein criterion). However, I could not study its roots... I tried to study its derivative... My methods were effective in the remaining questions... Someone, please, know how to solve this problem? Thank you.","['abstract-algebra', 'polynomials', 'galois-theory', 'roots']"
1546247,"$X$,$Y$,$Z$ mutually independent implies $X+Y$ independent of $Z$","Supposing $X$, $Y$ and $Z$ and mutually independent real random variables, how can we prove that $X+Y$ and $Z$ are independent from the definition? If not from the definition, using $\sigma$-algebras? I know that if $X$ and $Y$ are not independent this doesn't work so I know I have to make use of their independence in my proof but I can't figure out how. And it means that if I write the following, I'm making a mistake, and I can't find it: $$\mathbb{P}(X+Y \leq k,Z \leq l)=\int_{\mathbb{R}} \mathbb{P}(X=x,Y \leq k-x, Z \leq l) dx=\int_{\mathbb{R}} \mathbb{P}(X=x,Y \leq k-x) \mathbb{P}(Z \leq l) dx = \mathbb{P}(Z \leq l)\int_{\mathbb{R}} \mathbb{P}(X=x,Y \leq k-x)dx= \mathbb{P}(Z \leq l) \mathbb{P}(X+Y \leq k) $$ PS: I have seen the proof here but it much more advanced stuff, kind of a sledgehammer... X,Y,Z are mutually independent random variables. Is X and Y+Z independent?","['probability-theory', 'alternative-proof', 'proof-verification', 'independence', 'probability']"
1546271,"Prove that there exists $\delta>0$ such that for all $(x,y)\in S$, if $\|(x,y)\|<\delta$, then $f(x,y)\le f(0,0)$.","I need help with this question: Let $f,g:\mathbb{R}^2\rightarrow\mathbb{R}$ be two $C^2$ functions, and let $S=$ { $(x,y)\in\mathbb{R}^2:g(x,y)=0$ }. Suppose that $g(0,0)=\frac{\partial g}{\partial x}(0,0)=0$ and $\frac{\partial g}{\partial y}(0,0)\neq0$ . Also assume that there exists $\lambda \in \mathbb{R}$ such that $\nabla f(0,0)=\lambda\nabla g(0,0)$ and $\frac{\partial^2f}{\partial x^2}(0,0)<\lambda\frac{\partial^2g}{\partial x^2}(0,0)$ . Prove that there exists $\delta>0$ such that for all $(x,y)\in S$ , if $\|(x,y)\|<\delta$ , then $f(x,y)\le f(0,0)$ . Please, I can't do it.","['partial-derivative', 'calculus', 'real-analysis', 'derivatives']"
1546281,Homeomorphism from $U\subset \mathbb{R}^2 \rightarrow U$ which permutes points.,"I'm trying to solve the following problem: Let U be a connected open set, $U \subset \mathbb{R^2}$, and consider $p_1,p_2,...,p_n \in U$ and $q_1,q_2,...,q_n \in U$. Show that exists an homeomorphism $\varphi: U \rightarrow U$ such that  $\varphi(p_i)=q_i$. This comes from a basic algebraic topology book.I tried to find a contradiction using the fact that the fundamental group of $U\setminus \{p_i\}$ is the free group on $n$ generators but I'm not concluding. I know that an open connected subset in $\mathbb{R}^2$ is also path connecting but the fundamental group approach is not working. Any hints would be greatly appreciated.","['fundamental-groups', 'algebraic-topology', 'general-topology']"
1546285,"What's an ""injective"" function $f(i, j)$ such that $i \lt j, k \lt l \implies f(i,k) \lt f(j,l)$?","For example $f(i,j) = i^2 + j^2$ won't work because there are numbers that can be written as the sum of squares in two ways.  It only has to work on the natural numbers.  It only has to be injective across differing pair sets $\{i,j\} \neq \{k,l\}$ and it should be commutative: $f(i,j) = f(j,i)$.","['elementary-number-theory', 'functions']"
1546333,Vertical arrow meaning in math?,"What does the symbol $\uparrow$ in this context means: Consider a function $f$ of $x$, $f: \mathbb{R}\rightarrow \mathbb{R}$ and a set $G\subseteq \mathbb{R}$. Let $1_G:=
\begin{cases}
1 & \text{if } x\in G\\
0 & \text{otherwise}
\end{cases}$ What is the function $f \uparrow 1_G$?","['calculus', 'functions']"
1546334,Cesaro identity for Fibonacci numbers: $ F_{2n} = \sum_{k=1}^n \binom{n}{k} F_k$,"I am stuck with the identity $$
F_{2n} = \sum_{k=1}^n \binom{n}{k} F_k,
$$ which happens to be formula 80 . I am using induction, but so far without too much result. $$
\sum_{k=1}^{n+1} \binom{n+1}{k} F_k = \\
F_{n+1} + \sum_{k=1}^n \binom{n+1}{k} F_k = \\
F_{n+1} + \sum_{k=1}^n \binom{n}{k} F_k + \sum_{k=1}^n \binom{n}{k-1}F_k =\\ F_{n+1} + F_{2n} + \sum_{k=1}^n \binom{n}{k-1}F_k,
$$ I am stuck with the sum $ \sum_{k=1}^n \binom{n}{k-1}F_k$, because, on the other hand $$
F_{n+1}+ \sum_{k=1}^n \binom{n}{k-1}F_k = F_{2n+1}
$$ Which would conclude the proof. What am I missing?","['proof-verification', 'fibonacci-numbers']"
1546366,Distribution of weighted sum of Bernoulli RVs,"Let $x_1,...,x_m$ be drawn from independent Bernoulli distributions with parameters $p_1,...,p_m$. I'm interested in distribution of $t=\sum_i a_ix_i,~a_i\in \mathbb{R}$ $m$ is not large so I can not use central limit theorems. I have the following questions: 1- What is the distribution of $s=\sum_i x_i$? 2- What is the distribution of $t=\sum_i a_ix_i$ or $t=\sum_i a_ix_i-\sum_i a_i$ (to ensure non-negative support) for known $a_i$'s? can I approximate its distribution with a Gamma distribution? If yes, what would be the parameters (as a function of $p_i$'s and $a_i$'s)? 3- Is there a truncated Gamma distribution (or any other distribution (except normal)) that can approximately fits my problem? However, $m$ is not very large, but it is still very large such that I can not calculate the distribution by convolution. Thanks a bunch!","['probability-distributions', 'statistics', 'gamma-distribution', 'probability', 'binomial-distribution']"
1546379,Where did it come from? (derivative of exponential),"We all know this rule: $\text{If } y = a^{f(x)} \text{ then } y' = a^{f(x)} \: f'(x)\ln a$ In my book there is the example: Find $\frac{d}{dx}\left((x^{2} + 1)^{\sin x}\right)$ According to the rule, my answer is: $(x^{2} + 1)^{\sin x} \cdot \cos x \cdot \ln(x^{2} + 1)$ But the answer of the book was: $$(x^{2} + 1)^{\sin x}\left(\frac{2x \sin x}{x^{2} + 1} + \cos x \cdot \ln(x^{2} + 1)\right)$$ So, where did $\frac{2x \sin x}{x^{2} + 1}$ come from?","['exponential-function', 'derivatives']"
1546389,Higher math and statistics/probability,"So I've heard that certain areas of statistics and probability use manifolds and results from analysis and topology. Given that I lack the background to see where manifolds would become useful in these fields, I was wondering if someone could provide me with an example illustrating their application. Thanks in advance","['probability-theory', 'information-geometry', 'stochastic-calculus', 'manifolds', 'statistics']"
1546406,"Estimate the probability $P(X > C\frac{(n-1)^p}{\sqrt{n}})$ for $X\sim N(0,1), C>0, p>1/2$","Let $(B_t)_{t\geq 0}$ be brownian motion, let $p>1/2$. I want to show that 
$$\lim_{t\to\infty} \frac{B_t}{t^p} \to 0 \quad a.s.$$ Atm I'm trying to show that 
$$\limsup_{t\to \infty} \frac{B_t}{t^p} \to 0 \quad a.s.$$ by applying Borel-Cantelli on the event $A = \limsup_{n \to \infty}A_n, A_n = \{\sup_{n-1\leq t \leq n} B_t > C(n-1)^p \}, C > 0.$
This means I want to show that $\sum_{n=1}^\infty P(A_n) < \infty$, which implies $P(A) = 0 \quad a.s. \Rightarrow \limsup_{t\to \infty} \frac{B_t}{t^p} \to 0 \quad a.s.$. By the reflection principle
$$P(\sup_{n-1\leq t \leq n} B_t > C(n-1)^p) \leq P(\sup_{0\leq t \leq n} B_t > C(n-1)^p)$$
$$=2P(B_n > C(n-1)^p) = 2P(B_1 > C\frac{(n-1)^p}{\sqrt{n}}).$$
So my question is: How can I show that 
$$\sum_{n=1}^\infty P(B_1 > C\frac{(n-1)^p}{\sqrt{n}}) < \infty$$
for $C>0,p>1/2, B_1 \sim N(0,1)$? Btw: i'm not even sure whether the sum converges, maybe i have to pick other intervals and not $[n-1,n]$.","['probability-theory', 'borel-cantelli-lemmas', 'normal-distribution', 'stochastic-processes', 'brownian-motion']"
1546409,How many throws of a die until every possible result is obtained? [duplicate],"This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 8 years ago . A die is thrown until every possible result (i.e., every integer from 1 to 6) is obtained. Find the expected value of the number of throws. How do I do that? I understand that probability for the single result is $\{1, 5/6, \ldots , 1/6\}$, but what about the expected value?","['expectation', 'probability', 'combinatorics']"
1546453,Integral in terms of hypergeometric,"I am considering the following integral $$\int_{-t}^{\infty} \frac{dy}{y-s} \frac{1}{y^2} \frac{1}{y^{\epsilon}} {}_2F_1(1,1,2+\epsilon, -t/y)$$ Rewriting the hypergeometric using its integral representation and making a change of variables $y=-t/u$ I obtain the integral, up to some numerical factors, $$\int_0^1 \int_0^1 dz\, du (1-uz)^{-1}u^{1+\epsilon} (1-z)^{\epsilon} (1+\frac{us}{t})^{-1}$$ My question is how to make progress with this? I have attempted partial fractions on the term $$\frac{1}{(1-uz)} \frac{1}{(1+\frac{us}{t})} = \frac{z}{\frac{s}{t}+z} \frac{1}{(1-uz)} + \frac{\frac{s}{t}}{\frac{s}{t}+z}\frac{1}{(1+\frac{us}{t})}$$ but I am not sure if this has helped me at all. Thanks for any comments!","['substitution', 'definite-integrals', 'multivariable-calculus', 'integration', 'hypergeometric-function']"
1546465,How to evaluate $\int\sin ^3 x\cos^3 x\:dx$ without a reduction formula?,"We have the integral $$\displaystyle\int \sin ^3 x \cos^3 x \:dx.$$ You can do this using the reduction formula, but I wonder if there's another (perhaps simpler) way to do this, like for example with a substitution?","['closed-form', 'calculus', 'indefinite-integrals', 'integration']"
1546522,"If $(f \circ g)(x) = x$, and $(g \circ f)(x) = x$, then $g$ is the inverse of $f$.","If $f: A\to B$ is bijective, then it has an inverse $g: B \to A$ defined as \begin{equation} 
g = \left \{ \big( f(a), a \big) : a \in A \right \}
\end{equation}
If $g: B \to A$ is any function for which, \begin{equation}
\begin{aligned}
(f \circ g)(x) & = x, & \forall x \in B, \\  
(g \circ f)(x) & = x, & \forall x \in A.  
\end{aligned}
\end{equation}
then $g \equiv f^{-1}$ (inverse) I basically need to show that if any two functions are composed with $x$ ( I don't if that's the proper way to say it) and you get back $x$, then those two functions are inverses of one another. In other words  $g \equiv f^{-1}$ (inverse) Any help with this would be really appreciated. I've been trying to get this down for a couple of days now.",['functions']
1546541,"""Extension"" of orthogonal group","I'm looking for a Lie group $G$, subgroup of $GL(n,\Bbb{R})$, and which contains $O(n,\Bbb{R})$ as a subgroup:
$$
O(n,\Bbb{R}) \subseteq G \subseteq GL(n,\Bbb{R}).
$$
Obvious examples: the conformal group, and the special linear group. Now, I would like $G$ to have exactly one dimension more than $O(n,\Bbb{R})$. Is the conformal group the only possibility, or are there any others? Thanks. (Feel free to edit tags appropriately.)","['group-extensions', 'lie-groups', 'matrices']"
1546542,Show group can't have 12 elements of order 7,Let $G$ be a group show that $G$ can't have 12 elements of order 7. my try: If there is $a \in G$ such that $o(a)=7$ then $<a>$ has 6 distinct elements of order 7 then suppose $<a>$ is not normal in $G$ then there is element $g \in G$ such that $gag^{-1} \not\in <a>$ so $o(gag^{-1})=7$ and it posses $6$ elements of order 7 then $<a> \cap <gag^{-1}> = \{e \}$ so it gives us $12$ elements so far and I don't know how to contradict this,['group-theory']
1546547,"Find two subgroups of $GL(2,\mathbb{C})$ and an isomorphism between them that is not a homeomorphism.","Find two subgroups $G_1$ and $G_2$ of $GL(2,\mathbb{C})$, and an isomorphism $f:G_1\rightarrow G_2$ which fails to be a homeomorphism. The metric on $GL(2,\mathbb{C})$ is the induced metric from $\mathbb{C}^4$. This is an exercise in The Geometry of Discrete Groups . A hint would be appreciated.","['abstract-algebra', 'group-theory', 'topological-groups', 'general-topology']"
1546554,"If $\frac{1}{8} \left(5^m-2\cdot 3^m+1\right)$ is prime, then $m=2p$ where $p$ is prime?","The following statements are easy to prove with elementary arguments: $X_m=\frac{1}{8} \left(5^m-2\cdot3^m+1\right)$ is an integer for all
integers $m\ge 0$ ($m \equiv 0  \mod 4$  or $m \equiv 1  \mod 4$ )$\Longrightarrow$ 
($X_m \equiv 0  \mod 2$) ($m \equiv 3  \mod 4$  )$\Longrightarrow$($X_m \equiv 0  \mod 3$) ($m \equiv 6  \mod 12$  )$\Longrightarrow$($X_m \equiv 0  \mod 7$) ($m \equiv 10  \mod 20$  )$\Longrightarrow$($X_m \equiv 0  \mod 11$) ($m \equiv 6  \mod 20$  )$\Longrightarrow$($X_m \equiv 0  \mod 11$) ($X_m \equiv0  \mod 5$)$\Longrightarrow$($m\equiv0   \mod 2$ ) $X_m$ is prime $\Longrightarrow$  $m=2k$ where $k$ is odd Moreover, it seems that $X_{158}$ is prime. $ \frac{1}{8} \left(5^m-2\cdot 3^m+1\right)$ is prime $\Longrightarrow$
  $m=2p$ where $p$ is prime Is this true? This would be analogous to $2^n-1$ is prime $\Longrightarrow$ $n$ is prime. But here, I have doubts because sometimes when $7$ is the smallest odd prime factor of $\frac{m}{2}$, my numerical computations show me that the prime divisors of  $ \frac{1}{8} \left(5^m-2 \cdot 3^m+1\right)$ can be quite large. EDIT 1.  Actually $7$ is the first prime which is not a Sophie Germain prime. If $m=2(2k+1)$ and $2k+1$ has a prime divisor $p$ such that $2p+1$ is also prime then it is easy to see that $2p+1$ divides $X_m$, so that $X_m$ cannot be prime.
The above conjecture then becomes : $ \frac{1}{8} \left(5^m-2\cdot 3^m+1\right)$ is prime $\Longrightarrow$
  $m=2p$ where $p$ is prime but not a Sophie Germain prime EDIT 2.  The same can be shown for the Stirling Number of 2nd kind $
{m+1\brace 3}=\frac{1}{2} \left(3^m-2\cdot2^m+1\right)$ and the corresponding conjecture would be $ {m+1\brace 3}$ is prime $\Longrightarrow$
  $m=2p$ where $p$ is prime but not a Sophie Germain prime But It seems that no $m$ is known yet for which $ {m+1\brace 3}$ is prime. EDIT 3.
These numbers have a general form $$q_{m,k}=\frac{\underset{j=0}{\overset{k}{\Sigma }}(-1)^{k-j} (2 j+1)^m \left(
\begin{array}{c}
 k \\
 j \\
\end{array}
\right) }{2^k k!}$$
 From https://oeis.org/A028491 there are at least 18 known values of $m$ for which $q_{m,1}=\frac{3^m -1}{2}$ is prime. So far we have 2 prime values for $X_m=q_{m,2}$ $q_{159,3}$ is prime and it remains to be checked whether other prime $q_{m,3}$ can be found for reasonnably small $m$
$$q_{m,3}=\frac{1}{48} \left(7^m-3.5^m+3.3^m-1\right)$$ In the same line 
$$ {m\brace k}=\frac{\underset{j=0}{\overset{k}{\Sigma }}(-1)^{k-j} j^m \left(
\begin{array}{c}
 k \\
 j \\
\end{array}
\right) }{k!}$$
For $k=2$, 44 of them are known to be prime (Mersenne primes) For $k=3$, apparently none is known to be prime For $k=4$, only 4 of them are known to be prime ( https://oeis.org/A100958 ) For $k\gt 4$, apparently none is known to be prime either. These numbers grow with $m$ like $(2k+1)^m$ or $k^m$ : this is probably why they cannot be prime as often for large $k$ as for small $k$. But it seems that being prime is more likely for $q_{m,k}$ than for $ {m\brace 2k+1}$, I wonder why...","['congruences', 'prime-numbers', 'number-theory', 'modular-arithmetic', 'elementary-number-theory']"
1546559,$E[\varphi(X_t)|\mathcal{F}_t] = \varphi(E[X_t| \mathcal{F}_t]) $ implies adaptedness?,"I am stuck on the following problem: 
Let $X_t$ be a stochastic process. We have that for all $\varphi$ that are continuous and bounded it holds: $$E[\varphi(X_t)|\mathcal{F}_t] = \varphi(E[X_t| \mathcal{F}_t])   $$ where $\mathcal{F}_t$ it is some filtration. Then it follows that $X_t$ is $\mathcal{F}_t$ adapted. 
I am pretty sure that I've already seen this result somewhere but at the moment I cannot figure out where. May be someone here can give me a hint or a reference.","['probability-theory', 'conditional-expectation', 'measure-theory']"
1546573,Every element outside the maximal ideal of a local ring is a unit,"A homework question from my algebra class asks: Show that in a local ring $R$ with maximal ideal $M$, every element outside $M$ is a unit. My argument is that since $M$ is maximal $R /M $ is a field and so for any $ x \in R \backslash M $, $ x + M $ has a multiplicative inverse, which implies $ x $ is a unit. I don't see where we need the fact that $R$ is a local ring.","['abstract-algebra', 'maximal-and-prime-ideals', 'ideals', 'commutative-algebra']"
1546577,Classification of groups of order 12,"I have a lot of difficulty understanding this proof we went over in class about classification of groups of order 12. Let $G$ be a finite group of order $n=p^rm$ where $m \nshortmid p$. Denote $Syl_p(G)$ as the set of all sylow p-subgroups, and $n_p(G)$ as the cardinality of $Syl_p(G)$. (1) G has subgroups of order $p^r$. (How do we know this??) (2) We know all sylow p-groups are conjugate and their number $n_p(G) | m$, by the 2nd and 3rd Sylow Theorems. (3) We have that $n_p(G) \equiv 1(p). $ Then $n=12=2^2*3^1$ so $n_2(G)|3$ gives $n_2(G) \in \{1,3\}$ and $n_3(G)|4$ so $n_3(G) \in \{1,4\}$ since $2 \not\equiv 1(3)$. Case 1: $n_3(G) = 4.$
Then the action of G by conjugation on $Syl_3(G)$ gives a homomorphism $f: G \rightarrow S_{Syl_3(G)} \simeq S_4$.
$Ker(f)$ consists of $g \in G$ that normalizes all 3-Sylow subgroups. (Why?). Let $P_3$ be a 3-Sylow subgroup. Then the order of $P_3$ is 3. (I don't get that either), and $[G:N_G(P_3)] = 4.$ Thus $P_3 \subset N_G(P_3)$ gives $P_3 = N_G(P_3)$. (I'm lost here...)
So $Ker(f) = \cap Syl_3(G) = \{e\}$ (the intersection of the sylow 3-subgroups is trivial. (How did we arrive here...)
Thus we conclude that $G$ is isomorphic to a subgroup of $S_4$ of order 12. To show $G$ is isomorphic to $A_4$, we have that $G$ has 8 elements of order 3: 4 3-sylow subgroups each has 3-1=2 elements of order 3. And $S_4$ has 8 3-cycles meaning f(G) contains all 3-cycles and hence the group they generate, which is $A_4$, so $A_4 \subset f(G)$. But since $|A_4| = 12 = |f(G)$ then $f(G) = A_4$ and $G \simeq A_4$.
(Not understanding the first half of the proof, I do not get this part either). Case 2: $n_3(G) = 1.$ The scope of the question is too large, I will need to post separately to understand the second half, unless the organizational rules of math.stackexchange would require that I post here. In that case, I'll edit the question. I basically cannot follow the proof because it seems to skip too many steps; it would be helpful if anyone could elaborate case 1 with more reasoning so that I can follow it. Any help would be appreciated; I've spent hours trying to look up and decipher the proof but without any success.","['group-theory', 'finite-groups', 'groups-enumeration']"
1546624,Finitely-presented torsionfree group whose abelianization has torsion,In chat someone asked Does anyone know of a torsion-free group (finitely presentable) whose abelianisation has torsion?,"['abstract-algebra', 'group-theory']"
1546636,"Transitive subgroup of $S_n$, with $n$ prime, containing a transposition is always the entire $S_n$","This is a question from a worksheet I'm working at for several days, I'm having huge problems figuring out a nice solution, because I'm always stuck at the solution and don't know where to use that $n$ is prime. The question is as follows: Let $G \leq S_n$ , with $n$ prime, be a transitive subgroup ( $\forall k, l \in \{ 1,...,n\}\ \exists \ \sigma \in G:\sigma (k) = l$ ).
If $G$ contains a transposition $(k,l)$ , then $G = S_n$ . I have tried constructing several generators for $S_n$ , but I couldn't construct an n-cycle (which would be the easiest way of proving it). The second attempt was to construct all possible transpositions, but I also fail here and I have no intuition on where to use that n is prime. The last thing we learned in the lecture were group operations, and the operation of $G$ on $\{ 1,...,n\} $ should also be transitive, but I got nothing out of this approach. Any help appreciated!","['abstract-algebra', 'group-theory', 'finite-groups', 'symmetric-groups']"
1546656,"Finding the $n^{\text{th}}$ term of $-1,-1,-1,-1,1,1,1,1,...$ as a repeating 8-block","In my work I came across that sequence $-1,-1,-1,-1,1,1,1,1,\dots$ and repeating this 8-block so on forever Now I cant find an ( e.g. trigonometric/complex ) expression
$f(n)$ ( e.g. $f(n) =(-1)^g(n)$ ) which gives me the sequence starting with 
$n=2,3,4,5,6,7,8,9,…$
and so on forever.",['sequences-and-series']
1546667,Derivative vanishes $\implies$ Locally Constant,"This is a little lenghty, and there's probably an shorter way to see this, but I want to prove the following: Let $f:N^n\to M^m$ be a smooth map from between smooth manifold and $\{U,x\}$, $\{V,y\}$ be charts on $M$ and $N$ respectively with $f(U)\subseteq V$. I want to show that if the derivative (push-forward) $Df=f_*$ vanish identically on $U$, then $f$ is locally constant on $U$. My thought is to use the following theorem from Browder: Let $A$ be a convex subset of $\mathbb{R}^n$ and $f:A\to\mathbb{R}^m$. If $f$ is differentiable at each point of $A$ and if $||Df_p||\leq M$ for every $p\in A$, then $||f(b)-f(a)||\leq M||b-a||$ for all $a,b\in A$. So if figured since $y\circ f\circ x^{-1}$ is smooth map between the open sets $x(U)\subseteq\mathbb{R}^n$  and $y(U)\subseteq\mathbb{R}^m$ and $(y\circ f\circ x^{-1})_*=y_*\circ f_*\circ x^{-1}_*$, we see $f_*$ vanishes at $p\iff y_*\circ f_*\circ x^{-1}_*$ vanishes at $x(p)$. Suppose $f_*$ vanishes on $U\implies y_*\circ f_*\circ x^{-1}_*$ vanishes on $x(U)$ and $q\in x(U)$. Since $x(U)$ is open, take a small open ball $q\in B_q\subset x(U)$. Then for any points $a,b\in x(U)$, we can connect them with a straight segment $[a,b]$ (since $B_q$ is convex). Then since $y_*\circ f_*\circ x^{-1}_*=0<M$ for all positive $M$, by the theorem above we have $||y\circ f\circ x^{-1}(a)-y\circ f\circ x^{-1}(b)||=0\implies y\circ f\circ x^{-1}$ is constant on $B_q\implies f$ is constant on $x^{-1}(B_q)\subseteq U$. That is, $f$ is locally constant on $U$. Does this look right?","['differential-topology', 'differential-geometry', 'proof-verification', 'real-analysis']"
1546691,Help integrating the transition probability of the Brownian Motion density function.,"1. Problem : Given the Brownian Motion with Drift:
$$ dx = \mu \, dt+\sigma \, dW $$
It can be shown that the transition density function is the following:
$$ p(x, t) = \frac{e^{-\frac{(x-\mu t)^2}{2t\sigma^2}}}{\sqrt{2\pi} \sqrt{t\sigma^2}}$$ Therefore, If I want to find the cumulative probability for some range: Example:
$$ \mu=0.05, \sigma=0.5$$
$$ Pr(T \leq 10, \ -\infty \leq X \leq 5) = 
\int_0^{10}\int_{-\infty}^5 \frac{e^{-\frac{(x-\mu t)^2}{2t\sigma^2}}}{\sqrt{2\pi} \sqrt{t\sigma^2}}\,dx\,dt = 9.997 $$ I get values that are greater than 1; therefore, I am definitely wrong. This is not a probability. So, I have some questions: What is the value that I am getting? How do I read $ Pr(T \leq t, \ X \leq x) $? Simulated Paths for the Diffusion (Equation 1, above): Contour Plot of the Transition Probability Function: What basic probability questions can be answered by inferring from the transition probability density? 2. Follow up question : What if there was a threshold where the paths of the diffusion are being killed - doesn't the time become a random variable? i.e. A book I am reading provides the following  formula for the probability of trajectories that are killed : $$
Pr(T < t \mid y) = \int_{0}^{\infty }\int_{\Omega }k(x)p(t, x\mid y)\,dx\,dt \\
$$ Example: $$ k(x)=\lambda x^2, \ where \ \lambda=0.001 \\$$ Diffusion paths crossing the killing function $ k(x) $ (Red line) This is where my confusion about having a random variable $ T $ comes from. So how can I relate this conclusion with the information below about the transition probability density and the double integral on time? 3. Lessons Learned (Needs Verification) Given the Brownian Motion with Drift: $$ dx = \mu dt+\sigma dW \\ $$ i. Diffusion without Killing : The Transition Probability Function defined as:
$$ p(x,t)dx=P(x(t)\in(x,x+dx)) \\ $$ 
... is obtained by solving the Forward Kolmogorov PDE:
$$ \frac{\partial p(t, x)}{\partial t} = -\frac{\partial\mu p(x, t)}{\partial x}+\frac{1}{2}\frac{\partial^{2}\sigma p(x, t)}{\partial x^{2}} \\
p(x, 0) = \delta (x-x_{0}) \\ $$ ... Inference:
$$ Pr(X \leq x) = \int_{-\infty }^{x}p(x, t)\,dx \\ $$ ii. Diffusion with Killing : The Transition Probability Function defined as:
$$ p(x,t)dx=P(x(t)\in(x,x+dx),T>t) $$ ... is obtained by solving the Backward Kolmogorov PDE:
$$ \frac{\partial p(x, t)}{\partial t} = -k(x)p(x, t) + \frac{\partial\mu p(x, t)}{\partial x}
+\frac{1}{2}\frac{\partial^{2}\sigma p(x, t)}{\partial x^{2}} \\
p(x, 0) = \delta (x-x_{0}) $$
$$and \ BCs $$
... Inference:
$$ Pr(T \leq t, X \leq x) =
\int_{0}^{t}\int_{-\infty }^{x}k(x)p(t, x)\,dx\,dt $$","['probability-theory', 'probability-distributions', 'stochastic-calculus', 'brownian-motion', 'integration']"
1546696,Finding the limit of $\frac {\sin(2x)} {8x}$,"I am taking an online course in Calculus from Ohio State and am just being introduced to the concept of limits. One of the exercises given to me is to find the limit of the following $$\lim_{x \rightarrow 0}\frac {\sin({2x})}{8x} $$
Using what I have so far been taught, I determined that this is equivalent to the following $$\frac {\lim_{x \rightarrow 0}\sin(2x)} {(\lim_{x \rightarrow 0}8) (\lim_{x \rightarrow 0}x)} $$
As far as I am aware, this should become $$\frac 0 {(8)(0)}$$
which is undefined, so I have a feeling this is incorrect. I'm sure that this is an easy problem to solve, I'm just not sure how to do it without getting $\frac 0 0$ as an answer.","['limits', 'trigonometry']"
1546738,Segment in Banach space,"Let $X$ be a Banach space and let $x,y \in X$. We define segment between $x$ and $y$ by $$\left [ x,y \right ] = \left \{ z \in X : \left \| x - z\right \| + \left \| z - y\right \|=\left \| x - y\right \|\right \}.$$ Show that this segment has the following representation $$\left [ x,y \right ] = \left \{ \lambda x + \left ( 1- \lambda \right ) y | \lambda \in \left [ 0,1 \right ] \right \}$$ I proved $\left [ x,y \right ] \supset \left \{ \lambda x + \left ( 1- \lambda \right ) y | \lambda \in \left [ 0,1 \right ] \right \}$ but cannot do in converse case. For $z \in \left [ x,y \right ]$ we have $\left \| x - z\right \| = \lambda \left \| x - y\right \|$ and $\left \| z - y\right \| = \left ( 1 -\lambda \right ) \left \| x - y\right \|$. I don't know how to keep on.","['analysis', 'real-analysis', 'functional-analysis']"
1546751,Finding an explicit isomorphism from $\mathbb{Z}^{4}/H$ to $\mathbb{Z} \oplus \mathbb{Z}/18\mathbb{Z}$,"There was a past qualifying exam problem, I was having trouble with, it is stated below as follows: In the group $G= \mathbb{Z} \times \mathbb{Z}\times \mathbb{Z}\times \mathbb{Z}=\mathbb{Z}^{4}$ , let $H$ be the subgroup generated by $[0,0,3,1], [0,6,0,0], [0,1,0,1]$ . Find an explicit isomorphism between $G/H$ and a product of cyclic groups. I truly do not fully understand how to define such a map on $G/H$ . I have given some thought to this. We have that $H$ consists of integer combinations of the generators above, that is, if $\xi \in H$ , then $\xi=a[0,0,3,1]+b[0,6,0,0]+c[0,1,0,1]$ . In particular, we have that $\xi$ is in the image of a module homomorphism $\mathbb{Z}^{3} \rightarrow \mathbb{Z}^{4}$ whose matrix with respect to a standard basis $(e_{1},e_{2}, e_{3})$ and $(f_{1}, f_{2}, f_{3}, f_{4})$ for $\mathbb{Z}^{3}$ and $\mathbb{Z}^{4}$ respectively, will be $$A=\begin{bmatrix}
0&0&0\\
0&6&1\\
3&0&0\\
1&0&1\\
\end{bmatrix}.$$ We can perform row operations by multiplying on the left by the matrix $P$ and column operations by multiplying  on the right by the matrix $Q$ $$P=
\begin{bmatrix}
0&0&0&1\\
0&1&0&0\\
0&3&1&-3\\
1&0&0&0\\
\end{bmatrix},$$ $$Q=\begin{bmatrix}
1&6&-1\\
0&1&0\\
0&-6&1\\
\end{bmatrix}$$ to obtain the matrix $$PAQ=\begin{bmatrix}
1&0&0\\
0&0&1\\
0&18&0\\
0&0&0\\
\end{bmatrix}.$$ I believe this tells us if $\xi \in H$ , then $\xi=[a,6b,18c,0]$ for $[a,b,c] \in \mathbb{Z}^{3}$ . From here, I think we can conclude that $$\mathbb{Z}^{4}/H \cong \mathbb{Z} \times  \mathbb{Z}/18\mathbb{Z}.$$ I do not see how to explicitly write a function between these two objects. Do I think of $\mathbb{Z}^{4}/H$ as cosets? The matrices $P$ and $Q$ above, tell us exactly the change of basis in the domain and codomain, I was wondering if I could use that. Thanks","['abstract-algebra', 'abelian-groups', 'modules']"
1546777,Fourier transform of the critical line of zeta?,"Is there a known expression for the (distributional) Fourier transform of the Riemann zeta function, taken along the critical line? I'd love to say that it's a weighted sum  of delta distributions, logarithmically spaced and decreasing in amplitude, as in $\sum_n \frac{\delta(\omega-\log(n))}{n^{1/2}}$ but this fails to be a tempered distribution, and fails in general when the exponent in the denominator is less than 1.","['fourier-analysis', 'number-theory', 'complex-analysis', 'analytic-number-theory']"
1546791,Related rates: Two planes converging towards a point,"An air traffic controller spots two planes at the same altitude converging on a point as they fly at right angles to each other. One plane is 225 miles from the point and is moving at 450 miles per hour. The other plane is 300 miles from the point and has a speed of 600 miles per hour."" ""a. At what rate is the distance between the planes decreasing? b. If the controller does not intervene, how close will the planes come to each other?"" I understand that we can use implicit differentiation to solve part a, which shows that the difference is decreasing at 750 mph. However, I wonder why in part b, the answer is 30 minutes. In other words, the difference between the two planes (the hypotenuse of their right angle) is decreasing at a constant rate. Why is that so?",['derivatives']
1546819,What does tilde mean?,"In statistics books, I have seen expressions like: $\frac{(n-1)S^2}{\sigma^2} \sim \chi{( n-1 )}$ In this context, what does the $\sim$ mean?","['probability', 'statistics', 'probability-distributions']"
1546848,Limits of complicated sum.,"I'm faced with something like:
$$ \lim_{r \to \infty} \left[ \sum_{n=0}^r \frac{\hbar^n (-1)^n}{n!} \sum_{k=0}^n \binom{n}{k} \frac{d^k}{dx^k} \left(\sum_{i=0}^{r-n} \frac{x^i}{i!} \right)  \frac{d^{n-k}}{dx^{n-k}} \right] \psi = 0 $$ A huge mess, I know.  I'm not sure exactly how to simplify, and get something in terms of exponentials. Now, obviously it'd be easiest to write this as something like:
$$ \lim_{r \to \infty} \left[ \sum_{n=0}^r \frac{\hbar^n (-1)^n}{n!} \sum_{k=0}^{min\{n,r-n\}} \binom{n}{k} \sum_{i=k}^{r-n} \frac{x^{i-k}}{(i-k)!} \frac{d^{n-k}}{dx^{n-k}} \right] \psi = 0 $$ If you apply the limit then obviously $min\{n,r-n\}=n$ and so you would simply get:
$$ [e^{-\hbar} e^x e^{-\hbar \partial_x}] \psi = 0 $$ But, I feel like there's something missing with this.  If we do this, we're neglecting the part inside the limit where $r-n<n$. For example, if you break up the expression as:
$$ \lim_{r \to \infty} \left[ \sum_{n=0}^{r/2} \frac{\hbar^n (-1)^n}{n!} \sum_{k=0}^n \binom{n}{k} \sum_{i=k}^{r-n} \frac{x^{i-k}}{(i-k)!} \frac{d^{n-k}}{dx^{n-k}} + \sum_{n=r/2+1}^{r} \frac{\hbar^n (-1)^n}{n!} \sum_{k=0}^{r-n} \binom{n}{k} \sum_{i=k}^{r-n} \frac{x^{i-k}}{(i-k)!} \frac{d^{n-k}}{dx^{n-k}} \right] \psi = 0 $$
But, how do you evaluate the limit of this?","['summation', 'limits', 'ordinary-differential-equations']"
1546852,Calculate infinite sum with residues,"I'm trying to use the residue theorem to calculate 
$$\sum_{k=1}^{\infty} \dfrac{1}{(2k-1)^2}.
$$
I came up with $\operatorname{Res}\left(\dfrac{\pi \cot(\pi z)}{(2z-1)^2},\frac12\right)=-\pi^2$ and $\operatorname{Res}\left(\dfrac{\pi \cot(\pi z)}{(2z-1)^2},0\right)=1$.  This leaves me with $\pi^2-1=2\sum_{k=0}^{\infty}=2(\sum_{k=1}^{\infty}+1)$.  Doing the algebra gives $\sum_{k=1}^{\infty}=\dfrac{\pi^2-2}{2}$, while the answer is $\dfrac{\pi^2}{8}$.  I would appreciate it if anyone could help me identify where I am going wrong.","['complex-analysis', 'residue-calculus']"
1546901,"Prove that $\frac{f(x)}{x}$ is uniformly continuous in $[1, +∞)$ if $f$ is Lipschitz","Let $f(x)$ be a Lipschitz function on $[1, +∞)$, i.e. there exists a
  positive constant $C$ such that $$|f(x) − f(y)| ≤ C|x − y|, ∀x, y ∈ [1, +∞).$$ Prove that $\frac{f(x)}{x}$ is uniformly continuous in $[1,+\infty)$. I know that a  Lipschitz function is uniformly continuous. What I did so far is: let $g(x)  = \frac{f(x)}{x}$. Then I assumed $g(x)$ is Lipschitz. (Is the assumption wrong?) 
Then  $|g(x)-g(y)| \le K|x-y|$ satisfies the Lipschitz condition. Therefore $|\frac{yf(x)-xf(y)}{xy}| \le K|x-y|$. How to continue from here?","['lipschitz-functions', 'uniform-continuity', 'real-analysis']"
1546904,Matrix Equations,I have worked it out and determined that both equations hold. I am wondering why this is the case. Is there a reason why the equation holds for these two types of matrices?,"['linear-algebra', 'matrices']"
1547026,Why is rotation about the y axis in $\mathbb{R^3}$ different from rotation about the x and y axis.,"In my textbook for a counterclockwise rotation about the x-axis we have $\begin{pmatrix} 
1 & 0 & 0\\
0 & \cos\theta & -\sin\theta \\
0 & \sin\theta & \cos\theta 
\end{pmatrix}$ For rotation about the z-axis we have $\begin{pmatrix}
\cos\theta & -\sin\theta & 0 \\
\sin\theta & \cos\theta & 0 \\
0 & 0 & 1 
\end{pmatrix}
$ . Now for rotation about the y-axis it's listed as $\begin{pmatrix}
\cos\theta & 0 & \sin\theta \\
0 & 1 & 0 \\
-\sin\theta & 0 & \cos\theta
\end{pmatrix} $ . I can see that they changed it to the rotational matrix for a clockwise matrix but it says right infront of these 3 matrices that they are all for counterclockwise rotations so I'm not entirely sure what's going on.",['linear-algebra']
1547031,Projective limit involving p-adic numbers,"Let $p$ and $q$ be distinct primes. What is the projective limit
  $$\varprojlim \mathbb R^2 / (p^n \mathbb Z \times q^n \mathbb Z)?$$ That's an exercise from Robert's book A Course in p-adic Analysis . Is it true that this limit is isomorphic to $\varprojlim (\mathbb R / p^n \mathbb Z) \times (\mathbb R / q^n \mathbb Z)$ which is just a product of projective limits of $\mathbb R / p^n \mathbb Z$ (and respective expression involving $q$), e.g. $\mathbb S_p \times \mathbb S_q$ where $\mathbb S$ denotes a solenoid?","['p-adic-number-theory', 'general-topology', 'category-theory']"
1547080,Evaluate the limit $\mathop {\lim }\limits_{n \to \infty } \frac{{(n + 1){{\log }^2}(n + 1) - n{{\log }^2}n}}{{{{\log }^2}n}}$,"Evaluate:
$$\mathop {\lim }\limits_{n \to \infty } \frac{{(n + 1){{\log }^2}(n + 1) - n{{\log }^2}n}}{{{{\log }^2}n}}$$ Intuitively, I feel that for large $n$, ${\log}(n+1) \approx \ {\log}(n) 
$. So, the above limit should reduce to: $$=\mathop {\lim }\limits_{n \to \infty } \frac{{\{ (n + 1) - n\} {{\log }^2}n}}{{{{\log }^2}n}} \ = 1$$ However, can someone please suggest how can one mathematically show this. Thanks!",['limits']
1547098,Artin's Algebra exercise special case of some theorem/problem?,"The following exercise is from Artin's Algebra Text: Show that there is a one to one correspondence between maximal ideals of $ \bf R$$[x]$ and complex upper half plane. Solution: Follows from the fact that $ \bf R$$[x]$ is a PID,and any irreducible polynomial of  $ \bf R$$[x]$ is either of degree $1$ or of degree $2$. Is the above problem a special case of some theorem/Problem? In the case of algebraically closed field $k$ It's well known that maximal ideals of polynomial ring in $n$ variable over $k$ corresponds to points of affine space $ \bf A_k^n$.","['ring-theory', 'ideals', 'irreducible-polynomials', 'abstract-algebra', 'maximal-and-prime-ideals']"
1547141,Aggregating standard deviation to a summary point,"I have a range of data (server performance statistics) is formatted as follows, for each server: Time            | Average |  Min  |  Max  | StdDev  | SampleCount |
-------------------------------------------------------------------
Monday 1st      |    125  |   15  |  220  | 12.56   |     5       |
Tuesday 2nd     |    118  |   11  |  221  | 13.21   |     4       |
Wednesday 3rd   |    118  |   11  |  221  | 13.21   |     3       |
....            |    ...  |   ..  |  ...  | .....   |     .       |
and so on... These data points are calculated from data that has a finer resolution (e.g. hourly data). I need to aggregate this data into a single summary point so the end result is a list of servers and an aggregate average, min, max, standard deviation. For average, I take the average of all the averages.
For min, we take the minimum min.
For max, we take the maximum max. However, I'm not sure what method I should be using to aggregate standard deviation? I've seen various answers including square roots and variance but I really need a concrete answer on this - can anyone help?","['average', 'statistics', 'standard-deviation']"
1547154,Clarification on the intended meaning of a probability problem [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I am just wondering if anyone can help with this question: A radio station held a competition where contestants were invited to pick a number from $1$ to $50$. If a contestant picked the ‘winning’ number they won a trip to Vegas. The station picked a new ‘winning’ number at random each time a new contestant played the game. The radio station allowed ﬁve contestants to play every day over the course of one week. Compute the probability that the station will have to pay out for exactly 
      one Vegas trip. I know that there will be 35 people in total who will guess the number but can the 'winning' number be reused or is it without replacement?","['probability', 'statistics', 'problem-solving']"
1547156,Showing that a subset of $\ell^1$ is totally bounded,"Let $A=\{ f \in \ell^1\, :\,\text{ for each natural number}\, n\,\text{we have}\, |f(n)|<1/2^n \}$. Show that it is totally bounded in $\ell^1$ and find the interior of $A$ in $\ell^1$ the closure of $A$ in $\ell^1$ To prove that $A$ is totally bounded it suffices to show A is compact in $\ell^1$, right? But I do not know how to prove it. And also I would like to know how to find interior and closure of $A$.","['compactness', 'metric-spaces', 'real-analysis', 'functional-analysis', 'analysis']"
1547218,Dominated convergence theorem and uniformly convergence [duplicate],"This question already has an answer here : Prove a assertion concerning Lebesgue space (1 answer) Closed 8 years ago . I try to solve the following task: Let $(\Omega,\mathfrak{A},\mu)$ be a measurable space and $\mu(\Omega)<\infty$. Let $(f_n)_{n\geq1}$ be a sequence of integrable measurable functions $f_n:\Omega \rightarrow [-\infty,\infty]$ converging uniformly on $\Omega$ to a function $f$. Prove that $$\int f d\mu = \lim\limits_{n\rightarrow \infty} \int f_n d\mu$$. What I thought: uniformly convergence of $f_n \rightarrow f$ means that $f$ is continuous and therefore measurable. Now I thought that I could use the dominated convergence theorem to show the equality. uniformly convergence means $\lim\limits_{n\rightarrow \infty} \sup \{|f_n-f(x)|:x\in \Omega\}=0$ so I think I can define a function $s(x):=\sup \{|f_n-f(x)|:x\in \Omega\}=0$ which dominates all the $f_n$ and apply the theorem. But I'm not sure, if this is the correct way.","['lebesgue-measure', 'convergence-divergence', 'real-analysis', 'measure-theory']"
1547281,Pre measure for an infinite product of measure spaces,"Let $\{(\Omega_k, \Sigma_k, P_k)\}_{k\geq 1}$ be a sequence of probability spaces. I am trying to prove the statement below in order to use it and get a pre measure and then use the Hahn kolomogrov theorem to get a probability measure on $\prod_{k=1}^{\infty} \Omega_k$. The statement I want to show is: For every $k\geq 1$, let $\{E^{(k)}_j\}_{j\geq 1}$ be a sequence in $\Sigma_k$. It is given that: 1)  $\forall j\geq 1[ \,\,\,|\{k\geq 1:E^{(k)}_j\not= \Omega_k\}|<\infty \,\,\,\,]$ 2) $\prod _{k=1}^{\infty} \Omega_k=\cup_{j=1}^{\infty}(\prod _{k=1}^{\infty} E^{(k)}_j)  $ and the sets in the collection $\{\prod _{k=1}^{\infty} E^{(k)}_j\}_{j\geq 1}$ are pairwise disjoint. then $\sum_{j=1}^{\infty}(\prod _{k=1}^{\infty} P_k(E^{(k)}_j))=1  $. I tried to prove it but only succeeded in proving special cases. If anyone can give me hints, that would be great. Thank you a lot.","['probability-theory', 'infinite-product', 'measure-theory']"
