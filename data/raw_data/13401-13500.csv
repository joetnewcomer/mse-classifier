question_id,title,body,tags
105671,Why can you determine the stability of a system by taking the eigenvalues of the Jacobian?,Why can you determine the stability of a system by taking the eigenvalues of the Jacobian?  I know it's an elementary question but it's been a while. Thank you!,"['dynamical-systems', 'ordinary-differential-equations']"
105694,Can an expected value (mean) be higher than the values used to create it?,"I have this distribution, where ' $x_i$ ' is shorthand for $X=i$ , where $i=0,1,2,3,4$ and where $X$ is a random variable with possible values $0,1,2,3,4$ $$
P(x_0) = 0.2 \\
P(x_1) = 0.25 \\
P(x_2) = 0.3 \\
P(x_3) = 0.15 \\
P(x_4) = 0.1
$$ Using the Expected Value formula: $$
\mu = (0)0.2 + (1)0.25 + (2)0.3 + (3)0.15 + (4)0.1 \\
\mu = 1.7
$$ How does this make sense? How can the expected value be LARGER than any probability in my distribution? Am I using the wrong formula?","['probability-distributions', 'probability']"
105713,Question on proof of Hoeffding identity,"In this paper , there is a proof of Hoeffding identity for covariance (see page 541 or page 5 in pdf file, Theorem 1.11). A part of the proof is the following equality: $$ 2\text{cov}(X,Y) = 2(E(XY)-E(X)E(Y))=E((X_1-X_2)(Y_1 - Y_2))$$ As far as I understand this transition is done by taking into account that$\ (X_1,Y_1)$ is iid copy of$\ (X_2,Y_2)$. It should be pretty simple, but I'm having hard time writing this explicitly. Can you please give me a hint?",['probability']
105716,"Doubts on showing that $g=0$ a.e. on $[0,1]$ given that $\int_p^q g(x)~d\mu =0$ for rationals $p,q\in[0,1]$","Could someone please explain to me why the this answer solves this problem I'd comment on the original question and answer, but I don't have enough rep to do that. thanks.",['measure-theory']
105731,Most and least likely outcomes of a Bernoulli distribution experiment,"Let's say I have some experiment that I repeat $n$ times. Each time I repeat it, there is a $p$ chance that the outcome will be successful. If I set $X$ to be the amount of successful trials, how can I find the most probable and least probable $X$? I figured that the most probable would be $np$, but I'm not quite sure.","['probability-distributions', 'probability']"
105732,References on the History of Linear Algebra,"I have an aggregated understanding of the history of linear algebra compiled from friends, teachers, and coworkers. It may have several errors. It goes something like this: Even ancient cultures like the Chinese used the idea of row reduction to solve systems of linear equations, even if the format looked somewhat different. In medieval times, Arabic cultures kept this idea alive. In the 18th century, European mathematicians developed matrix notation to represent a linear system. There was even now the idea of inverting that matrix. By the mid 19th century, matrices were fully understood as derivatives of multivariable functions, and hence understood as transformations between finite dimensional vector spaces. Still at this point there was limited applicability for practical problem solving. If a matrix was even moderately large, it was a nice theoretical tool, but practically impossible to compute with. So the most recent chapter is In the 1940s and 1950s, with the advent of modern computing technology these limitations were overcome, and for example, Leontiff could solve a system of 500 equations. I suppose my first question is: is any part of this significantly inaccurate? But my main question is: is anyone aware of a good historical reference emphasizing the last chapter, where computers sparked renewed interest in linear algebra? I can't seem to find any good histories that focus on this era. Most of what I find focuses on the theory developed up to the mid 19th century.","['linear-algebra', 'math-history', 'reference-request']"
105741,"How to prove $\gcd(a,\gcd(b, c)) = \gcd(\gcd(a, b), c)$?","I am trying to prove that $\gcd(a, \gcd(b, c)) = \gcd(\gcd(a, b), c)$. The definition of GCD available to me is as follows: Given integers a and b, there is one and only one number d with the following properties. $d \geqslant 0$ $d|a$ and $d|b$ $e|a$ and $e|b$ implies $e|d$. In the book that I am studying, prime factorization of numbers hasn't been taught yet. Only, the definition of GCD, I've given above has been taught and proven. So, I want to use only this to prove that $\gcd(a, \gcd(b, c)) = \gcd(\gcd(a, b), c)$. Could you please help me?","['divisibility', 'number-theory']"
105742,"Interchanging consecutive subsequences to reverse $1,2,3,\ldots,n$","Here is a problem I found on Google Plus. Given a sequence $1,2,....,n$ you are allowed to interchange any two consecutive subsequences in it. Find the least number of steps in which you can reach $n,n-1,.....,1$ using this transformation. Consecutive subsequences means the last element of the first subsequence is less than  the first element of the second subsequence. Examples: $$12345 \to 34125 \to 32541 \to 54321$$
So, $T(5)=3$. Some other example are: $T(15)=11, T(13)=9, T(10)=7$ It has been found that, the transformation can always be done in at most $n-1$ ways by starting with $1,2,\ldots,n-1,n\to n,1,2...,n-1$ and then using induction. 
Is there a simple formula or method for finding the smallest number of ways instead of brute force?","['number-theory', 'combinatorics']"
105760,Prove that $(a^{-1})^{-1}=a$,"How does one prove that if $a \ne 0$, then $(a^{-1})^{-1}=a$? My friend (I'm trying to help her) has in her class notes: $a+(-a)=0$ and $(-a)+a=0$ implies that $a=-(-a)$ by the uniqueness
  theorem. Why does $a+(-a)=0$ and $(-a)+a=0$ imply $a=-(-a)$? How do I use that to prove $(a^{-1})^{-1}=a$? I started out by writing $ab=1$ implies that $b=a^{-1}$. Then, mimicking the teacher's notes I write $a a^{-1}=1$ and $a^{-1} a=1$. I guess next I could just write the conclusion, but I don't understand the reason why it's so. Thanks.",['calculus']
105770,Find the slope of a line given a point and an angle,"I'm trying to figure out this problem and feel like it's something that must be so simple that I could've done in high school no problem, but for some reason my brain is frozen this morning.  I would really appreciate any help, and want to say thanks in advance. I tried to draw a picture below; I want to find the slope of a line given a point $(x,y)$ and $\theta$.","['geometry', 'trigonometry']"
105775,"How to pronounce ""tableaux""? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 8 years ago . Improve this question How do you pronounce Young tableaux ? Does it sound just like its singular form?","['young-tableaux', 'pronunciation', 'terminology', 'combinatorics']"
105789,Separation theorem,"Is it true that given a real vector space $X$ and two disjoint convex sets $A,B\subseteq X$, there is always a linear functional that (weakly) separates them? I.e., is there a non-zero linear functional $\phi\colon X\to \mathbb R$ and a $\gamma\in\mathbb R$, such that $\phi(a)\le \gamma \le \phi (b)$ for all $a\in A$ and $b\in B$? If not, can you give a counterexample? I know the statement is true if you add the aditional hypothesis that at least one of the sets has an internal point. This follows from the Hahn-Banach theorem using the Minkowski functional, but I was wandering whether this hypothesis is necessary.","['convex-analysis', 'functional-analysis']"
105800,Discrete Laplace transform,"Yesterday ago I was reading how the Laplace Transform can be interpreted as the continuous analog of the discrete functional dependance of the power series $$f(x) = \sum a(n) x^n$$
This is to say, $$L\{a(n)\} = f(x)$$ Since I find it more natural I will use a the ""nucleus"" so to call it, $$\frac{x^n}{n!}$$ Thus we can think about the following. Being $L$ the ""discrete Laplace operator"". $L\{1\}(x) = e^x$ $L\{n\}(x) = xe^x$ $L\{n!\}(x) = \frac{1}{1-x}$ $L\left\{\frac{1-(-1)^n}{2}\right\}(x) = \sinh x$ $L\left\{\frac{1+(-1)^n}{2}\right\}(x) = \cosh x$ Similary we can define a ""derivative"" theorem as follows: $$L\left\{\frac{n}{x}a(n)\right\}(x) = \frac{d}{dx}L\{a(n)\}(x) $$ where I leave the $x$ inside to recall we're operating inside the sum, although it'd be the same if we left the $x$ oustide. This is to say, $$f(x) = \sum a(n) \frac{x^n}{n!}$$ $$f'(x) =\frac{1}{x} \sum na(n) \frac{x^n}{n!} =  \sum  a(n) \frac{x^{n-1}}{(n-1)!}$$ It is clear that $$L\{(\alpha+\beta)(n)\}(x) = L\{\alpha(n)\}(x)+L\{\beta(n)\}(x)$$ and that $$L\{k\alpha(n)\}(x) = kL\{\alpha(n)\}(x)$$ so this $L$ transform is linear. Is there any theory on this discrete transform? Is there a motivation to use it, or is just not important in discrete mathematics?","['laplace-transform', 'sequences-and-series', 'discrete-mathematics']"
105809,Curious about Hilbert-Zariski theorem involving homogeneous variety and set of zeroes.,"I got myself in a confusing situation the other week while trying to read a bit of algebraic geometry. I'm hoping someone can pull me out. Suppose $k$ is a field, and $V$ a homogeneous variety with generic point $(x)$ over $k$. Denote by $Z$ the algebraic set of zeroes in $k^a$ of a homogeneous ideal in $k[X]$ generated by forms $f_1,\dots,f_r\in k[X]$. It is a theorem of Hilbert and Zariski that $V\cap Z$ has only the trivial zero if and only if each $x_i$ is integral over $k[f_1(x),\dots,f_r(x)]$. I searched for a proof of this fact and played with it over the course of last week, and came up with nothing. I would like to know, why does $V\cap Z$ have only the trivial zero if and only if each $x_i$ is integral over $k[f_1(x),\dots,f_r(x)]$? Thank you for your expertise.","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
105810,Continuous functions are differentiable on a measurable set?,"I came across the following challenging problem in my self-study: Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be continuous. Then the set of points where $f$ is differentiable is a measurable set. I am having trouble thinking of where to begin in proving this result, and wanted to see if anyone visiting had some suggestions on how to proceed.","['measure-theory', 'descriptive-set-theory']"
105824,"Can $x$ be written as a $\mathbb{Q}[x,y]$-algebraic combination of $x+xy$, $y+xy$, $x^2$, and $y^2$?","I was wondering how to write $x$ as an algebraic combination of $\{x+xy,y+xy,x^2,y^2\}$, with the coefficients $\in \mathbb Q[x,y]$.","['linear-algebra', 'algebra-precalculus']"
105834,Definitions of Baire first and second category sets,"From Planetmath A meager or Baire first category set in a topological space is one which is a countable union of nowhere dense sets. A Baire second category set is one which contains a countable union of open and dense sets. From Wikipedia : A subset of a topological space X is called nowhere dense in X if the interior of its closure is empty of first category or meagre in X if it is a union of countably many    nowhere dense subsets of second category or nonmeagre in X if it is not of first category    in X I was wondering according to Wikipedia's definition, is any subset of a
topological space either of first category or of second category? are the definitions for second category set in Planetmath and
Wikipedia consistent with each other? Wikipedia says these definitions are used for ""historical definition"" of Baire space. I was
wondering if they are archaic i.e. no longer in use? Thanks and regards!","['general-topology', 'baire-category']"
105859,Any linear fractional transformation transforming the real axis to itself can be written in terms of reals?,"I'm trying to teach myself complex analysis, and was reading about linear transformations. I would like to understand why any linear fractional transformation which transforms the real axis into itself can be written with real coefficients. I assume I have some linear fractional transformation $z\mapsto \frac{az+b}{cz+d}$, where $z\in\mathbb{C}$ and $a,b,c,d\in\mathbb{C}$ are the coefficients, and I think I would like to conclude $a,b,c,d\in\mathbb{R}$ actually. Choosing various reals, I get
$$
0\mapsto\frac{b}{d},\quad 1\mapsto\frac{a+b}{c+d},\quad -1\mapsto\frac{-a+b}{-c+d}
$$
so I know all those images are again real. Is there someway to conclude that $a,b,c,d$ are individually real? Thank you.","['transformation', 'complex-analysis']"
105873,Integration with complex numbers,"I know that you can integrate $$\int e^{-x}\cos(x)dx$$ by parts, but I would like to know how you can use complex variables instead.",['integration']
105884,Evaluate fraction of sum,"So i have to evaluate this sum:
$\displaystyle \frac{1-2^{-2}+4^{-2}-5^{-2}+7^{-2}-8^{-2}+10^{-2}-11^{-2}+\cdots}{1+2^{-2}-4^{-2}-5^{-2}+7^{-2}+8^{-2}-10^{-2}-11^{-2}+\cdots}$ it has the form :
$\displaystyle \frac{\sum^{\infty}_0 [(3n+1)^{-2}-(3n+2)^{-2}]}{\sum^{\infty}_0 (-1)^n[(3n+1)^{-2}+(3n+2)^{-2}]}$ My current attempt : Trying to convert this into power series 
$\displaystyle a(n) = (3n+1)^{-2}-(3n+2)^{-2} ~~~~~~ b(n) = (3n+1)^{-2}+(3n+2)^{-2}$ Can a(n) and b(n) be the definite integral of certain polynomial function f(x) ? Maybe there is a better direction. Can someone give me a hint ?","['sequences-and-series', 'fractions', 'calculus']"
105893,How much proof knowledge is necessary to begin Spivak's Calculus? [duplicate],"This question already has answers here : What books are prerequisites for Spivak's Calculus? (5 answers) Closed 2 years ago . I bought Spivak's Calculus a month or so ago, and after doing a few problems from the first chapter, it's apparent that I need some type of foundational knowledge in formal maths and proofs. What did you study prior to Spivak? What books did you use? I've purchased Velleman's How To Prove It , but I'm not  sure if this book will help me tackle an introductory elementary analysis book.","['self-learning', 'calculus', 'real-analysis']"
105896,"Evaluate $\sum \limits_{n=1}^\infty \frac1{L_n}$ where $L_n$ is least common multiple of $1, 2, 3,\ldots,n$","How to evaluate the sum
$\displaystyle\sum \limits_{n=1}^\infty \frac1{L_n}$? Where $L_n$ is the least common multiple of $1, 2, 3,\ldots, n$, e.g. least common multiple of $(6,3,4)$ is $12$.","['sequences-and-series', 'real-analysis']"
105898,Three-dimensional vectors and force systems,"Full disclosure: this is a homework problem. However, I find myself stuck in the middle. The problem is below As shown, a system of cables suspends a crate weighing W = 350 . 
  (Part C 1 figure)  The dimensions in the figure are as follows:  h=
  22.2 , l = 4.20 , x = 9.50 , theta = 40.0, and phi = 16.0. Determine TA, TD, and TE, the tensions in cable segments CA, CD, and CE,
  respectively. I already found that TA = 406, i still need to find TD and TE. I know that CE = CF and that I need to find TD and TE through the Z forces and that the Y forces in these two should equate but I'm not sure about that either. A push in the right direction would be a huge help.","['vector-spaces', 'multivariable-calculus', '3d', 'vector-analysis']"
105903,"Evaluating $\sum\limits_{n=1}^{\infty} \frac{1}{n\operatorname{ GPF}(n)}$, where $\operatorname{ GPF}(n)$ is the greatest prime factor","$\operatorname{ GPF}(n)=$Greatest prime factor of $n$, eg. $\operatorname{ GPF}(17)=17$, $\operatorname{ GPF}(18)=3$. How to evaluate convergence/divergence/value of the sum $$\sum_{n=1}^{\infty} \frac{1}{n\operatorname{ GPF}(n)}\,?$$","['analytic-number-theory', 'sequences-and-series', 'real-analysis']"
105911,Sturm-Liouville systems and the Wronskian,"I'm currently reading through Gohberg and Goldberg's treatment of Sturm-Liouville systems in Basic Operator Theory. Define a Sturm-Liouville system to be a differential equation of the form
$$\frac{d}{dx}(p(x) \frac{dy}{dx}) + q(x) y = f(x)$$
with boundary conditions
$$a_1 y(a) + a_2 y'(a) = 0$$
$$b_1 y(b) + b_2 y'(b) = 0$$
where $a_i, b_i$ are real numbers with $a_1^2 + a_2^2 \neq 0$, $b_1^2 + b_2^2 \neq 0$. Suppose the only solution where $f = 0$ is $y=0$. Then there exist real valued nonzero functions $y_1, y_2$ that are solutions, such that $y_1$ satisfies the first boundary condition and $y_2$ the second. Then they claim that a ""straightforward computation"" verifies that $(pW)' = 0$, where $W$ denotes the Wronskian. I do not see this computation. What I end up with is
$$(pW)' = p'y_1 y_2' - p' y_2 y_1' + py_1' y_2' + py_1 y_2'' - py_2' y_1' - py_2 y_1''$$
and I don't see why it's zero.",['ordinary-differential-equations']
105923,"Find the number of pairs of positive integers $(a, b)$ such that $a!+b! = a^b$","How many pairs of positive integers $(a, b)$ such that $a!+b! = a^b$? A straight forward brute-force reveals that $(2,2)$ and $(2,3)$ are solutions and this seems to be the only possible solutions, I was just wondering how could we prove this.","['number-theory', 'contest-math', 'combinatorics']"
105929,puzzle about array of numbers,"Consider an array of numbers $$
\color{#C00000}{1}\ \hphantom{7\ 6\ 5\ 4\ 7\ 3\ 5\ 7\ 2\ 7\ 5\ 3\ 7\ 4\ 5\ 6\ 7\ }\color{#C00000}{1}\\
1\ \hphantom{7\ 6\ 5\ 4\ 7\ 3\ 5\ 7\ }\color{#C00000}{2}\ \hphantom{7\ 5\ 3\ 7\ 4\ 5\ 6\ 7\ }1\\
1\ \hphantom{7\ 6\ 5\ 4\ 7\ }\color{#C00000}{3}\ \hphantom{5\ 7\ }2\ \hphantom{7\ 5\ }\color{#C00000}{3}\ \hphantom{7\ 4\ 5\ 6\ 7\ }1\\
1\ \hphantom{7\ 6\ 5\ }\color{#C00000}{4}\ \hphantom{7\ }3\ \hphantom{5\ 7\ }2\ \hphantom{7\ 5\ }3\ \hphantom{7\ }\color{#C00000}{4}\ \hphantom{5\ 6\ 7\ }1\\
1\ \hphantom{7\ 6\ }\color{#C00000}{5}\ 4\ \hphantom{7\ }3\ \color{#C00000}{5}\ \hphantom{7\ }2\ \hphantom{7\ }\color{#C00000}{5}\ 3\ \hphantom{7\ }4\ \color{#C00000}{5}\ \hphantom{6\ 7\ }1\\
1\ \hphantom{7\ }\color{#C00000}{6}\ 5\ 4\ \hphantom{7\ }3\ 5\ \hphantom{7\ }2\ \hphantom{7\ }5\ 3\ \hphantom{7\ }4\ 5\ \color{#C00000}{6}\ \hphantom{7\ }1\\
1\ \color{#C00000}{7}\ 6\ 5\ 4\ \color{#C00000}{7}\ 3\ 5\ \color{#C00000}{7}\ 2\ \color{#C00000}{7}\ 5\ 3\ \color{#C00000}{7}\ 4\ 5\ 6\ \color{#C00000}{7}\ 1\\
$$
The pattern: starting from 1 1, every consecutive natural number n will be inserted between two numbers beside each other whose sum equals n (2 between 1 1, 3 between 1 2, 4 between 1 3, etc ) You can see this pattern displayed above. My question is: what is a(n) - the number of times we will have to write n in the nth row ? My attempt:  trying to find recursive formula between a(n) and a(n+1), but this seems hard.","['elementary-number-theory', 'puzzle', 'sequences-and-series']"
105937,What does integration do?,"I know that integrals are used to compute the area under a curve. Let's say I have $y = x^2$. It creates smaller rectangles and then add up the sum (assuming that rectangles are going infinitely in number and is like going to a limit). But I recently encountered a problem in my mind. Suppose we have a function, $y = x^2$. If we integrated it, we simply get the anti derivative of it which is $x^3/3$, assuming that the area is not of concern. What is the correlation of $x^3/3$ to $x^2$? I mean, it simply likes transforms a function into another function, but I can't get a clearer picture. When we graph $x^2$ and $x^3/3$, there is no connection visually. They are simply different graphs. Thanks and I hope your comments can clear up my mind.",['integration']
105944,Probability over a given $\sigma$-algebra,"My question is very basic in a sens : Given a set $\Omega$ and a $\sigma$-algebra $\mathscr T$ over $\Omega$, is it always possible to define a probability over $(\Omega, \mathscr T)$ ? I assume my question is a little bit vague. Any piece of advise to precise it will be welcomed. Thanks in advance !","['probability-theory', 'probability']"
105952,Problem involving a hyperplane and affine subspace II,"I am trying to solve this little problem. Suppose you have a normed vector space $E$. Let $H$ be a hyperplane ( $H=\{x\in E: f(x)= \alpha\}$ for some linear functional $f$ and some real number $\alpha$) and let $V$ be an affine subspace (i.e. $V=U+a$ where $a \in E$ and $U$ is a vector subspace of $E$) that contains $H$. In my previous post I proved the following: either $H=V$ or $V=E$. Check it out here: A problem involving a hyperplane and an affine subspace Now, I want to deduce from this that H is either closed or dense in $E$. Any thoughts?","['normed-spaces', 'functional-analysis', 'analysis']"
105956,Preimage of Intersection of Two Sets = Intersection of Preimage of Each Set : $f^{-1}(A \cap B) = f^{-1}(A) \cap f^{-1}(B)$ [duplicate],"This question already has answers here : how to prove $f^{-1}(B_1 \cap B_2) = f^{-1}(B_1) \cap f^{-1}(B_2)$ (2 answers) Closed 10 years ago . Prove If $f$ is a function , $f^{-1}(A \cap B) = f^{-1}(A) \cap f^{-1}(B)$. Proof attempt
I am guessing here $A$ and $B$ are sets in the range of $f$. Let's assume $x$ belongs to both $A$ and $B$ and $f^{-1}$ exists for both $A$ and $B$. Then there must exist a $y$ such that $y = f^{-1}(x)$. Now by our assumptions $x$ is in intersection of $A$ and $B$ and since $f^{-1}(A)$ and $f^{-1}(B)$ exist then $f^{-1}(A) \cap f^{-1}(B)$ must also exist. Also since $A$ and $B$ exist and are not equal to null set so $A \cap B$ exists and $f^{-1}(A\cap B)$ also must exist and contain our $y$?? Not sure about the ending in this attempt. Any help would be much appreciated. Sources : ♦ 2nd Ed $\;$  P219 9.60(e) $\;$ Mathematical Proofs by Gary Chartrand, ♦ P214 $\;$ Theorem 12.4.#3 $\;$ Book of Proof by Richard Hammack, ♦ P257-258 $\;$  Theorem 5.4.2.#2(a) $\;$ How to Prove It by D Velleman.","['proof-writing', 'elementary-set-theory', 'functions']"
105977,Definition of uniform structure,"From Wikipedia : A uniform space $(X, Φ) $is a set $X$ equipped with a nonempty family
  $Φ$ of subsets of the Cartesian product $X × X$ ($Φ$ is called the
  uniform structure or uniformity of $X$ and its elements entourages)
  that satisfies the following axioms: if $U$ is in $Φ$, then $U$ contains the diagonal $Δ = \{ (x, x) : x
    ∈ X \}$. if $U$ is in $Φ$ and $V$ is a subset of $X × X$ which contains $U$,
  then$V$ is in $Φ$ if $U$ and $V$ are in $Φ$, then $U ∩ V$ is in $Φ$ if $U$ is in $Φ$, then there exists $V$ in $Φ$ such that, whenever
  $(x, y)$ and $(y, z)$ are in $V$, then $(x, z)$ is in $U$. if $U$ is in $Φ$, then $U^{-1} = \{ (y, x) : (x, y) \in U \}$ is also
  in $Φ$. I was wondering A. Are 2 and 3 equivalent to that $Φ$ is a filter on $X \times X$? B. Is $Δ = \{ (x, x) : x ∈ X \}$ also in $Φ$? C. How shall I understand 4? It reminds me of the triangle inequality in the definition of a
    metric. Are they really related? Is 4 equivalent to ""For any $V$ is in $Φ$, and for any $(x, y)$ and $(y, z)$ in $V$, there exists $U$ in $Φ$ such that $(x, z)$ is in $U$?"" D. in 5, What does it mean that it doesn't require $U \equiv U^{-1}$? To distinguish  distances with different ""directions""/""orientations""? Thanks and regards!",['general-topology']
105980,On infinite abelian $p$-group of bounded order,"Definition. If $p$ is a prime, then a $p$ -group is a group in which every element has order a power of $p$ .
Remark: An additively writen group is called bounded if its elements have boundedly finite orders. Of course multiplicative groups with this property are said to have finite exponent but this term is inappropriate in the context of additive groups. Let $G$ be an infinite abelian $p$ -group of bounded order, then prove that $G\cong
\mathbb{Z}_{p^{n}}\oplus\mathbb{Z}_{p^{n}}\oplus H$ , for some natural number $n$ and for some abelian group $H$ .","['p-groups', 'infinite-groups', 'group-theory', 'abelian-groups']"
105990,Showing that $\mathbb{R}$ and $\mathbb{R}\backslash\mathbb{Q}$ are equinumerous using Cantor-Bernstein,"I need to prove that $\mathbb{R}\backslash\mathbb{Q} \sim \mathbb{R} $ Using Cantor-Bernstein, need to show an injection from $\mathbb{R}\backslash\mathbb{Q}$ to $\mathbb{R}$ and from $\mathbb{R}$ to $\mathbb{R}\backslash\mathbb{Q}$. $\mathbb{R}\backslash\mathbb{Q}$ is a subset of $\mathbb{R}$ so only need to show injection from $\mathbb{R}$ to $\mathbb{R}\backslash\mathbb{Q}$ to complete the proof. Possible injection: $f:\mathbb{R}\to \mathbb{R}\backslash\mathbb{Q}$ defined as $f(x) = \pi x$ if $x$ is not a multiple of $\pi$; otherwise $f(x) = \sqrt{2} x$. Not sure if $f$ actually is an injection...",['elementary-set-theory']
106028,Semi-direct v.s. Direct products,"What is the difference between a direct product and a semi-direct product in group theory? Based on what I can find, difference seems only to be the nature of the groups involved, where a direct product can involve any two groups and the semi-direct product only allows a normal subgroup $N$ of some group $G$ and another subgroup of $G$ that intersects trivially with $N$ . Is this all? What are the significance? Thank you.","['semidirect-product', 'group-theory', 'abstract-algebra', 'direct-product']"
106043,Rings whose spectrum is Hausdorff,"Let $A$ be a commutative ring with $1$ and consider the Zariski topology on $\operatorname{Spec}(A)$. When will $\operatorname{Spec}(A)$ be a Hausdorff space? If $A$ has positive or infinite Krull dimension, this can never happen because there are points which will be a proper subset of their closure. In dimension $0$, any Noetherian ring is also Artinian and thus has a discrete spectrum, which is therefore Hausdorff. What about the non-Noetherian, zero-dimensional case? I suspect that there are such rings with a non-Hausdorff spec, but I failed to find an example.","['commutative-algebra', 'algebraic-geometry']"
106045,Gaussian change of probability measure,"In Shreve's book on pp. 37-39 I read that given a standard normal random variable $X \sim N(0, 1)$ and another random variable $Y = X+ \theta$, we can define a measure change $$\frac{d \widetilde{\mathbb{P}}}{d \mathbb{P}} = Z = \exp\left(-\theta X - \tfrac12\theta^2\right)$$ so that under $\widetilde{\mathbb{P}}$ the random variable $Y$ has the same distribution as $X$ under the original probability measure. I am trying to extend it to the case when $X \sim N(\mu, \sigma^2)$. I guessed that in this case: 
$$Z = \exp\left(\frac{-\theta (X - \mu) - \tfrac12\theta^2}{\sigma^2}\right)$$ and the integration seem to confirm (if I haven't made a mistake that is) that it indeed works as expected. However, when I used it in a simulation then for small $\sigma$ the average of the simulated $Z_i$ was much lower than 1 (whereas for the measure change we should have $\mathbb{E}[Z] = 1$). For $\sigma=1$ the simulation works perfectly, which makes me think that I made a mistake somewhere. What I am doing wrong? What is the correct measure change?","['measure-theory', 'probability-distributions', 'probability']"
106049,Another way to go about proving the limit of Fibonacci's sequence quotient.,"It is not difficult to inductively prove that $$\eqalign{
  & \phi  = \phi  + 0  \cr 
  & {\phi ^2} = \phi  + 1  \cr 
  & {\phi ^3} = 2\phi  + 1  \cr 
  & {\phi ^4} = 3\phi  + 2  \cr 
  & {\phi ^5} = 5\phi  + 3  \cr 
  &  \cdots  =  \cdots   \cr 
  & {\phi ^n} = {F_n}\phi  + {F_{n - 1}} \cr} $$ Thus one would have $$\frac{{{\phi ^{n + 1}} - {F_n}}}{{{\phi ^n} - {F_{n - 1}}}} = \frac{{{F_{n + 1}}}}{{{F_n}}}$$ $$\frac{{\phi  - \displaystyle\frac{{{F_n}}}{{{\phi ^n}}}}}{{1 - \displaystyle\frac{{{F_{n - 1}}}}{{{\phi ^n}}}}} = \frac{{{F_{n + 1}}}}{{{F_n}}}$$ Now I remember that in Apostol's Calculus he asked to prove for $F_1 = 1$, $F_2 = 2$ $$F_n < \phi^n$$
Using this, (which I would like to prove too) you have $$\phi  - \frac{{{F_n}}}{{{\phi ^n}}} > \phi  - 1$$ $$1 - \frac{1}{\phi }\frac{{{F_{n - 1}}}}{{{\phi ^{n - 1}}}} < \frac{{\phi  - 1}}{\phi } < 1$$ But this would mean (I'm not 100% sure on this. EDIT : This is wrong) $$\frac{{\phi  - 1}}{{  \frac{{\phi  - 1}}{\phi }}} > \frac{{\displaystyle \phi  - \frac{{{F_n}}}{{{\phi ^n}}}}}{{1 - \displaystyle \frac{1}{\phi }\frac{{{F_{n - 1}}}}{{{\phi ^{n - 1}}}}}} = \frac{{{F_{n + 1}}}}{{{F_n}}}$$ $$\phi  > \frac{{{F_{n + 1}}}}{{{F_n}}}$$ ADD: I guess it then can be proved that $$\left| {\phi  - \frac{{{F_{n + 1}}}}{{{F_n}}}} \right| = \left| {\phi  - \frac{{\phi  - \frac{{{F_n}}}{{{\phi ^n}}}}}{{1 - \frac{{{F_{n - 1}}}}{{{\phi ^n}}}}}} \right|$$ Then if you can prove $$\frac{{{F_n}}}{{{\phi ^n}}} \to L$$ $$\frac{{{F_n}}}{{{F_n}\phi  + {F_{n - 1}}}} \to L$$ (It can be proved that the limit is $\frac{\phi+2}{\phi}$, but using the quotient limit, which cant be used.) $$\left| {\phi  - \frac{{{F_{n + 1}}}}{{{F_n}}}} \right| = \left| {\phi  - \frac{{\phi  - \frac{{{F_n}}}{{{\phi ^n}}}}}{{1 - \frac{{{F_{n - 1}}}}{{{\phi ^n}}}}}} \right| < \epsilon $$ Could someone help?","['inequality', 'fibonacci-numbers', 'sequences-and-series', 'golden-ratio']"
106070,If $A^2 = I$ (Identity Matrix) then $A = \pm I$,"So I'm studying linear algebra and one of the self-study exercises has a set of true or false questions. One of the questions is this: If $A^2 = I$ (Identity Matrix), then $A = \pm I$ ? I'm pretty sure it is true but the answer says it's false. How can this be false (maybe it's a typography error in the book)?","['matrices', 'linear-algebra', 'examples-counterexamples']"
106072,"If $H$ is a cyclic subgroup of $G$ and $H$ is normal in $G$, then every subgoup of $H$ is normal in $G$.","Exercise 11, page 45 from Hungerford's book Algebra . If $H$ is a cyclic subgroup of $G$ and $H$ is normal in $G$, then every
  subgroup of $H$ is normal in $G$. I am trying to show that $a^{-1}Ka\subset K$, but I got stuck. What I am supposed to do now? Thanks for your kindly help.","['cyclic-groups', 'group-theory', 'abstract-algebra', 'normal-subgroups']"
106077,Does the triangle inequality for the absolute value hold for matrix trace?,"It is well-known that, $\left|m-n\right|\ge\left|\left|m\right|-\left|n\right|\right|$
for real numbers. But if one defines $\left|M\right|=\sqrt{M^2}$
for a symmetric matrix $M$, does one have $$\operatorname{trace}\left(\left|M-N\right|\right)\ge\operatorname{trace}\left(\left|\left|M\right|-\left|N\right|\right|\right)$$
if $M\ne\left|M\right|$?","['trace', 'absolute-value', 'inequality', 'matrices', 'linear-algebra']"
106084,"How to find a solution to a differential equation based on another, given solution","Let's say I have the DE: $$
(x^2 - 2x)y'' - (x^2 - 2)y' + (2x - 2)y = 0
$$ And I have one possible solution to the DE: $$
y_1(x) = e^x
$$ How would I go about solving this? I could solve the actual DE, but then what is the point of supplying a possible solution? Where does the solution $y_1$ come into play?",['ordinary-differential-equations']
106085,Order of cyclic groups and the Euler phi function,"According to Wikipedia, a cyclic number (in group theory) is one which is coprime to its Euler phi function and is the necessary and sufficient condition for any group of that order to be cyclic. Why is that true? I can see that if $n$ is prime, that guarantees any group of order $n$ is cyclic, but I don't seem to see how to extend it to $(n,\phi(n))=1$ It would be nice if someone could explain it to me. Thanks.","['reference-request', 'group-theory', 'number-theory']"
106086,What does it mean for an action to be an $F$-linear transformation?,"I'm working on a problem from Dummit & Foote's Abstract Algebra and I can't figure out what exactly I'm being asked to prove. I hate to ask this here, because it seems that I should've been able to find an answer on my own. The problem is from Section 13.2 #19 and it reads: Let $K$ be an extension of $F$ of degree $n$. (a) For any $\alpha\in K$ prove that $\alpha$ acting by left multiplication on $K$     is an $F$-linear transformation of $K$. I have searched and searched through the text and around on the internet and I cannot find an explicit definition of an ""$F$-linear transformation"".  What does this mean? If there is a definition for this in the book (or on the net) could anyone direct me to it?","['linear-algebra', 'abstract-algebra']"
106090,On the generalisation of the Fubini theorem,"Consider a smooth function $g(x) \colon \mathbb{R}^n \to \mathbb{R}$ such that $\nabla g > 0$ entrywise. Let $M_t = \{ x \mid g(x) = t \}$. Assume that $\{M_t\}$ don't intersect pairwise and their union gives $\mathbb{R}^n$. Let $dg \wedge \omega = dx_1 \wedge ... \wedge dx_n \equiv dx.$ How to show than that
$$
  \int\limits_{\mathbb{R}^n} f(g(x),x) dx = \int\limits_{\mathbb{R}} dt \int\limits_{M_t}f(t,x)\omega
$$","['integration', 'differential-geometry']"
106099,Find angles using the Law of Cosines,"if you must find the Angle C based on the sides of  a = 2, 3 b = 4,6 og c = 5, 9 I have used the formula: $$\cos (C) =\frac{a^2 + b^2-c^2}{2ab}$$ use, but I think i'm doing something wrong: $$\cos(C) = \frac{(2,3^2) + (4,6^2) - (5,9^2)}{2 \cdot 2,3 \cdot 4,6} = -0,395085066$$ $$C = \cos^{-1} ( -0,395085066 ) = \cdots$$","['trigonometry', 'triangles', 'algebra-precalculus']"
106101,Correlation between variables,"I asked this question on stats SE but did not find a suitable answer so far. Maybe someone can help. Given n random variables x1,...,xn (one-dimensional). 
The following is known (corr() = Pearson correlation): corr(x1,x2) = a
corr(x2,x3) = a The actual values of the random variables and their covariances are unkown though. Only some of their correlations are known. From this, is it possible to calculate corr(x3,x1) = ? or give an estimate of the lowest possible correlation coefficient corr(x3,x1) > a More generally: Given set of correlations corr(x_i, x_i+1) with i=[1..c], c<n is it possible to either directly calculate corr(x_1, x_c+1) or give a lower bound a of the coefficient with corr(x_1, x_c+1) > a","['statistics', 'regression', 'correlation', 'probability']"
106102,use of $\sum $ for uncountable indexing set,"I was wondering whether it makes sense to use the $\sum $ notation for uncountable indexing sets. For example it seems to me it would not make sense to say $$
\sum_{a \in A} a \quad \text{where A is some uncountable indexing set e.g. some $A \subset \mathbb{R}$ }
$$ Would it be better to avoid the above notation in general for uncountable indexing sets ? Any help in making better sense of this would be very appreciated.","['convention', 'notation', 'real-analysis', 'analysis', 'summation']"
106105,Summation over arbitrary Index Sets,"Suppose $\mathcal{I}$ is an arbitrary indexing set, and suppose we look at a family $A_i$ of subsets of some set $E$. Let's say we fix an element $x \in E$ and we define the function $f: \mathcal{I} \to \{0,1\}$ by
\begin{equation}
f_x(i) = 
\begin{cases}
1 &\text{if } x \in A_i\\
0 &\text{otherwise}
\end{cases}
\end{equation} Now, does the function $F: E \to \mathbb{R} \cup \{\infty\}$ given by
\begin{equation}
F(x) = \sum_{i \in I} f_x(i)
\end{equation}
make sense? I am asking this because I came upon a comment that says the summation symbol $\sum$ cannot be used in cases where the indexing set $\mathcal{I}$ is uncountable, instead, on has to use integration theory for this (and therefore, the symbol $\int$). Yet to me it doesn't look as if the above function $F$ is ill - defined. What am I missing? Thanks for your feedback!","['notation', 'integration']"
106115,What does this notation mean? $\frac{\partial f}{\partial x}(x+y)=\frac{\partial }{\partial x}f(x+y)$,"$$\frac{\partial f}{\partial x}(x+y)=\frac{\partial }{\partial x}f(x+y)$$ I was just wondering what the left-hand side mean. (or how to do the operation based on the notation of the LHS, given a specific function $f$) In addition, when is such commutation true? Under what conditions?","['notation', 'multivariable-calculus']"
106122,Subring of a finitely generated Noetherian ring need not be Noetherian? [duplicate],"This question already has an answer here : Are intermediate rings of finitely generated ring extensions also finitely generated? (1 answer) Closed 5 years ago . A common example showing that a subring of a Noetherian ring is not necessarily Noetherian is to take a polynomial ring over a field $k$ in infinitely many indeterminates, $k[x_1,x_2,\dots]$. The quotient field is then obviously Noetherian, but the subring $k[x_1,x_2,\dots]$ is not since there is an infinite ascending chain of ideals which never stabilizes. Is there an instance of a finitely generated Noetherian ring over some ground ring $R$, that has an intermediate ring which is not finitely generated over $R$, and hence not Noetherian either?","['ring-theory', 'abstract-algebra', 'noetherian']"
106130,Counting Functions or Asymptotic Densities for Subsets of k-almost Primes,"This question is an extension of this question . There the asymptotic density of k-almost primes was asked. By subsets I mean the following: Let $\lambda$ be a partition of $k$ and $P_{\lambda}=\{ \prod p_m^{\lambda_m} \; |\; p_m\neq p_k \}$.
So $P_{(1,1)}$ would be all semiprimes, despite squares. What I got are results on $k$-almost primes, being the union of all subsets $P_{\lambda}$. Here are some explicite formulas, like
$$
\pi_2(n)=\sum_{i=1}^{\pi(n^{1/2})}\left[\pi\left(\frac{n}{p_i}\right)-i+1\right].
$$
A general asymptotic is given by
$$
\begin{eqnarray*}
\pi_k(n) &\sim& \left( \frac{n}{\log n} \right) \frac{(\log\log n)^{k-1}}{(k - 1)!}\\
\end{eqnarray*}
$$
For the case of $P_{(1,1)}$ we just subtract the number of squares from $\pi_2(n)$ and get
$$
\pi_{P_{(1,1)}}=\pi_2(n)-\pi(n^{1/2}),
$$
but I don't see how to extend this. So again: How do the counting function $\pi_{P_{\lambda}}(n)$ or their asymptotics look like?","['prime-numbers', 'number-theory', 'combinatorics']"
106138,"Are Arzelà–Ascoli theorems results of similar theorems on normed spaces, metric spaces or other spaces?","From Wikipedia , two generalizations of the Arzelà–Ascoli theorem are Let $X$ be a compact Hausdorff space. Then a subset $F$ of $C(X)$,
  the set of real-valued continuous functions on X, is relatively
  compact in the topology induced by the uniform norm if and only if
  it is equicontinuous and pointwise bounded. Let $X$ be a compact Hausdorff space and $Y$ a metric space. Then a
  subset $F$ of $C(X,Y)$ is compact in the compact-open topology if and
  only if it is equicontinuous, pointwise relatively compact and
  closed. $C(X)$ is a normed space with the uniform norm, and also a metric space under the metric induced by the uniform norm. I was wondering if the Arzelà–Ascoli theorem generalizations are direct results of applying  to $C(X)$ some similar theorem(s) on normed spaces, metric spaces or other spaces (which $C(X)$ belongs to) ? For example, are the Arzelà–Ascoli theorem generalizations results of the following theorem: A subset in a metric space is compact iff it is complete and totally
  bounded? Or the Arzelà–Ascoli theorem generalizations are not direct results of any similar theorems on normed spaces, metric spaces or other spaces (which $C(X)$ belongs to) ? Thanks and regards!","['general-topology', 'normed-spaces', 'functional-analysis']"
106146,Monty Hall Three-Door Puzzle,"I have a doubt concerning a question about the Monty Hall Three-Door Puzzle, in probability. I found this problem in Rosen's ""Discrete Mathematics and Its Applications"". The Monty Hall Three-Door Puzzle: Suppose you are a game show contestant. You have a chance to win a large prize. You are asked to select one of three doors to open; the large prize is behind one of the three doors and the other two doors are losers. Once you select a door, the game show host, who knows what is behind each door, does the following. First, whether or not you selected the winning door, he opens one of the other two doors that he knows is a losing door (selecting at random if both are losing doors). Then he asks you whether you would like to switch doors. Which strategy should you use? Should you change doors or keep your original selection, or does it not matter? First of all, before I ask my specific doubt: I understand that the best strategy is switching doors, because the probability that the initially chosen door is incorrect is high (2/3); therefore, it is most probably not the winning door. So, after the host opens a door (which he knows is a losing door), the probability that the prize is in the other closed door (and not in the initially chosen one) is higher (2/3). Now, the specific question which I want to ask (found in Rosen's book): Explain what is wrong with the statement that in the Monty Hall Three-Door Puzzle the probability that the prize is behind the first door you select and the probability that the prize is behind the other of the two doors that Monty does not open are both 1/2, because there are two doors left. When the contestant chooses one door (before the host opens a door), the probability that it has the prize is 1/3. But, when the host opens one door (that he knows is a loosing door), the possibilities of where the prize can be are reduced by one, because now the contestant knows that the prize can only be either on the chosen door, or on the closed door. So, it seems reasonable to think that the probability that the prize is in any one of the two remaining doors is 1/2. But this reasoning is apparently wrong. Can any one help me understand why? Thank you in advance.","['monty-hall', 'discrete-mathematics', 'probability']"
106154,Taking logarithm of a generating function identity.,"A week or so ago I asked why
$$
\prod_{n\geq 1}\frac{1}{(1-x^n)^{m_n(q)}}=\frac{1}{1-qx}
$$
where $m_n(q)$ the number of irreducible monic polynomials with degree $n$ over the finite field of order $q$. Why does taking logarithms then imply 
$$
\sum_{n\mid r}nm_n(q)=q^r
$$
for any $r$? I know taking logarithms will change it to an additive identity, but don't see how this particular equality falls out. Thank you.","['generating-functions', 'combinatorics']"
106158,Every Transitive Permutation Group Has a Fixed Point Free Element,"If $G$ acts transitively by permutations on a finite set $A$ with more than one element (i.e. $G$ is a transitive permutation subgroup of the symmetric group $S_A$). Why does $G$ necessarily contain an element which has no fixed points (i.e. $g$ such that $g \cdot a \neq a$ for any $a \in A$)? The hint I have is to think about, given $a \in A$, what fraction of elements of $G$ fixes $a$. I'm not sure how to go about this hint...","['finite-groups', 'group-theory', 'abstract-algebra']"
106163,Show that every group of prime order is cyclic,"Show that every group of prime order is cyclic. I was given this problem for homework and I am not sure where to start. I know a solution using Lagrange's theorem, but we have not proven Lagrange's theorem yet, actually our teacher hasn't even mentioned it, so I am guessing there must be another solution. The only thing I could think of was showing that a group of prime order $p$ is isomorphic to $\mathbb{Z}/p\mathbb{Z}$. Would this work? Any guidance would be appreciated.","['cyclic-groups', 'group-theory', 'abstract-algebra']"
106208,Computing determinant of a matrix with non-zero values on three diagonals,"let $A$ be an $n\times n$ matrix with entries $a_{ij}$ such that $a_{ij}=2$ if $i=j$. $a_{ij}=1$ if $|i-j|=2$ and $a_{ij}=0$ otherwise. compute the determinant of $A$. using the famous formula $\det A=\sum_{i=1}^{n}(-1)^{i+j}a_{ij}\det A^{(ij)}$ where $A{(ij)}$ is the submatrix obtaining from $A$ by omiting it's $i$th row and $j$th colomn, I reached to the formula $\det A=\frac{1}{4}n^2+n+\frac{7}{8}+\frac{1}{8}(-1)^n$. is it correct?","['matrices', 'linear-algebra', 'determinant']"
106226,Automorphism of $\mathbb{Q}^*$,"Show there are infinitely many automorphisms of the group $\mathbb{Q}^*$. I am not sure how show this.  If we were dealing with ring automorphisms $\varphi:\mathbb{Q} \to \mathbb{Q}$, then the fact that $\varphi(1)=1$  makes such a ring automorphism unique.  However, how can we show that with groups that there are inifinitely many such automorphisms.",['abstract-algebra']
106227,Symmetries of a colored cube,"Is there a systematic way to find out what all the symmetries of the following cube are? Naturally, rotations and reflections along a diagonal or a plane are taken into account. Of course, by inspection one may be able to find all the symmetries, but what I really mean is; Given an $n\times n \times n$ cube. If we know that $k$ unit cubes are black and the rest are white. Is it possible to answer the same question in the general case? There might be no symmetry at all, but what is the best criterion that can handle the general case? What is the upper bound of symmetries? and what arrangements of black
and white unit cubes give us the upper bound? P.S. Sorry for asking too many questions in one post.","['reference-request', 'discrete-mathematics', 'group-theory', 'combinatorics']"
106239,Showing family is NOT complete,"How would I show that $$f(x;\theta) = \frac1{2\theta}$$ where $x$ is between positive and negative $\theta$ and $\theta$ is between $0$ and $\infty$ is NOT a complete family? I know that I need to find a non-zero function $u(x)$ whose expectation will be $0$, but I am struggling with finding this function. Thanks",['statistics']
106260,Interpolating the primorial $p_{n}\#$,"The primorial $p_{n}\#$ is given by the product $p_n\# = \prod_{k=1}^n p_k$ (where $p_{k}$ is the $k$th prime) -- is there a natural (a la the gamma function $\Gamma(z)$) way of interpolating it for arguments not necessarily a natural number? (or in $\mathbb{C}$?) I tried starting with the following definition of the gamma function: $$\Gamma(z) = \lim_{n \to \infty} \frac{n! \; n^z}{z \; (z+1)\cdots(z+n)}
= \frac{1}{z} \prod_{n=1}^\infty \frac{\left(1+\frac{1}{n}\right)^z}{1+\frac{z}{n}}$$ My first thought was to modify the Pochhammer symbol in the denominator: $$\Gamma_{?}(z) = \lim_{n \to \infty} \frac{p_{n}\# \; p_{n}^z}{z \; (z+p_{1})\cdots(z+p_{n})}$$ But this clearly doesn't work, because the primes aren't regularly spaced.","['prime-numbers', 'interpolation', 'analytic-number-theory', 'complex-analysis']"
106263,Implicit Function Theorem computation problem,"Problem 1, page 78 of Munkres ( Analysis on Manifolds ): Let $f: \mathbb{R}^3 \to \mathbb{R}^2$ be of class $C^1$; write $f$ in the form $f(x,y_1,y_2)$. Assume that $f(3,-1,2) = \mathbf{0}$ and
  $$ Df(3,-1,2) = \begin{pmatrix} 1 & 2 & 1 \\ 1 & -1 & 1 \end{pmatrix}.$$ (a) Show that there is a function $g: B \to \mathbb{R}^2$ of class $C^1$ defined on an open set $B$ in $\mathbb{R}$ such that $f(x,g_1(x),g_2(x)) = \mathbf{0}$ for $x \in B$ and $g(3) = (-1,2)$. (b) Find $Dg(3)$. (c) Discuss the problem of solving the equation $f(x,y_1,y_2) = \mathbf{0}$ for an arbitrary pair of unknowns in terms of the third, near the point $(3,-1,2)$. Here's what I have so far: Let $b=(-1,2)$ so that $a = (3,-1,2)$. Write $f(x,y_1,y_2)$ with $y = (y_1,y_2)$ then, a =3, and b = (-1,2) and determinant partial of $f$ w.r.t partial of $y (3,-1,2) =$ ? $$
\det \begin{pmatrix} \frac{\partial f_1}{\partial y_1}(a,b) & \frac{\partial f_1}{\partial y_2}(a,b) \\ \frac{\partial f_2}{\partial y_1}(a,b) & \frac{\partial f_2}{\partial y_2}(a,b) \end{pmatrix} 
$$ Derivative of partial of f = [partial of f w.r.t x   partial of f w.r.t. y]
implies Df(3,b) = (Stuck on evaluating this), but I know it is the expression above which I have wrote and what is partial of f1 w.r.t. y1 (a,b), partial of f2 w.r.t. y2 (a,b),  partial of f1 w.r.t. y2 (a,b), and partial of f2 w.r.t. y2(a,b)? For part b: Dg(3) = -{partial of f w.r.t y(3,b)]^-1 [partial of f w.r.t. x1]  at (3,b) =? for part c, I thought of taking 2 variables u and v s.t. partial of f w.r.t partial of (u,v) is not equal to zero. Since $f(a)$ is zero then by the implicit function theorem, there is a neighborhood $B$ of $(-1,2)$ in $\mathbb{R}^2$ and a unique function $g: B \to \mathbb{R}^3$ so that $g(a) = b$.",['analysis']
106264,Sequences containing infinitely many primes,"What are some interesting sequences that contain infinitely many primes? If it takes form of a polynomial, Dirichlet's theorem answer the question completely for linear polynomial. What about polynomials of degree more than 1? Is there a known polynomial of degree more than 1 that contains infinitely many primes? What about more complicated sequences like $2^n+3^n$, $n!+1$, etc? Please provide examples that are as interesting as possible, accompanied with proofs (or reference to proofs) if not too difficult. Thanks in advanced.",['number-theory']
106274,What is the expected root mean square determinant of an $n\times n$ matrix?,"The expected mean determinant of random $n\times n$ matrices of $0$'s and $1$'s is $0$.
What is the expected root mean square determinant? e.g. $\frac{\sqrt{3}}{2\sqrt{2}}$ for a $2\times 2$",['matrices']
106276,$a^m+k=b^n$ Finite or infinite solutions?,"Given positive integers k,a,b, is there a finite or infinite number of solutions in positive integers $m,n>1$, to $a^m+k=b^n$? Pillai's conjecture states that each positive integer occurs only finitely many times as a difference of perfect powers (Only k given, a,m,n,b are variables) . It is an open problem. What are known lower bounds on f(d) defined as how many times d, for d=1,2,3... occurs as a difference of perfect powers? Catalan's conjecture is the theorem that f(1)=1","['elementary-number-theory', 'diophantine-equations', 'number-theory']"
106283,Let $n$ be the positive integer such that $5^n$ and $2^n$ begin with same digit. Which digit is that?,"This is my first time posting here so sorry if I done something wrong, and also my first time encountering a problem like this. Besides trivial $0$, the only solution I found by simply writing down the powers of $2$ and $5$ parallely, is $5$ ($5^5=3125$, $2^5=32$). I couldn't find any kind of period. I've done problems which are about last digit, but not about the first one. Hopefully I could get a hint. Thanks.",['number-theory']
106293,$A$ an absolutely flat ring $\Rightarrow$ $S^{-1}A$ is absolutely flat,"I was doing some exercises in the book of Atiyah / MacDonald on Commutative Algebra, and I'm a little ""stuck"" with number 3.10 (i): If $A$ is an absolutely flat ring and $S\subseteq A$ a multiplicatively closed subset, then the localization $S^{-1}A$ is absolutely flat. I wanted to use a criterion shown earlier: $A$ absolutely flat $\Leftrightarrow$ every principal ideal of $A$ is idempotent. So if $\frac{a}{s}\in S^{-1}A$, my plan was to show that there exists a $\frac{b}{t}\in S^{-1}A$ with $\frac{b}{t}\cdot(\frac{a}{s})^2=\frac{a}{s}$. From the absolute flatness of $A$, we know that there are $x,y\in A$ with $xa^2=a$ and $ys^2=s$. So choosing $b:=x$, $t:=y$ one would be done, but I don't see why $y$ should be in $S$? I guess this has to be ""obvious"" in some way, and I'm just being stupid!? Then I tried to google it, but all I found was a different solution ( here ), and I'd like to ask one question regarding this solution, too, but I don't know if this is the appropriate place to do so? Since it's the same topic, I hope so, but if not, please correct me and I'll edit this post. Let $P$ be an arbitrary $S^{-1}A$-module. The author says there is an obvious isomorphism $S^{-1}P\cong S^{-1}A\otimes_A P\to P$ of $S^{-1}A$-modules. The first isomorphy is clear to me (and proven in the book), but I don't get the second one. I believe the maps should look like this: $\varphi:S^{-1}A\otimes_A P\to P, \varphi(\frac{1}{s}\otimes p)=\frac{1}{s}p$, and $\psi:P\to S^{-1}A\otimes_A P, \psi(p)=1\otimes p$. Then $\varphi\circ\psi=1$. As for $\psi\circ\varphi$, let $\frac{1}{s}\otimes p\in S^{-1}A\otimes_A P$, then $\psi(\varphi(\frac{1}{s}\otimes p))=\psi(\frac{1}{s}p)=1\otimes\frac{1}{s}p$, and then I don't know why I can switch over the $\frac{1}{s}$. I know that there is an $S^{-1}A$-module structure on the tensor product, but I thought it was of the form $\frac{a}{s}\cdot(\frac{1}{t}\otimes p)=\frac{a}{st}\otimes p$. It has to have something to do with the $S^{-1}A$-module structure on $P$. I guess it should be easier to show $S^{-1}M\cong M$ directly, I just had the idea to do it this way, but didn't try it out yet. I am going to do this now, but the question above still remains. It has to be a simple thing I overlook again, something I did not fully understand yet, and I hope you can help me understand it! Thanks for your help in advance!","['commutative-algebra', 'abstract-algebra']"
106295,Solving a triangle given two side lengths and the measure of a non-included angle,"Let's say given an angle A = 46 °, side a = 2.29 and b = 2.71 I figured that the angle B = 58.4 by saying: $$B = \sin^{-1} \left(\frac{ 2.71  \sin{46^{\circ}}}{2.29}\right)=58.4^{\circ}$$ But I think that angle C is incorrect: $$C = \sin^{-1} \left(\frac{2.29 \sin{58.4^{\circ}}}{2.71}\right)=46.03^{\circ}$$ Someone who can help me? what do I do wrong and how should it be done?","['geometry', 'triangles', 'trigonometry', 'algebra-precalculus']"
106305,On matrix norm equivalence: estimates on $A \|\mathbf M\|_2 \leq \|\mathbf M \|_F \leq B\|\mathbf M\|_2$,"For finite dimensional spaces, all norms are equivalent, i.e. there exist constants say $A,B$ such that for all matrices from the $\mathbf M \in R^{d\times d}$ (let $d$ be a fixed positive integer), $$A \|\mathbf M\|_2 \leq \|\mathbf M \|_F \leq B\|\mathbf M\|_2\text{,} $$ where $\|\cdot\|_2$ denotes the spectral norm and $\|\cdot\|_F$ denotes the Frobenius norm. My question is now, whether you know anything specific about $A$ and $B$ , for example whether there exists an analytical expression for let's say $B$ .","['matrices', 'normed-spaces', 'matrix-norms']"
106312,Intersection between orthogonal complement of a subspace and a set,"Consider the normed vector space $E=\mathbb{R}^n$. Define $ P=\{x \in \mathbb{R}^n: x_i \geq 0, \forall i \}$. Let $M$ be a subspace such that $M \cap P = \{0\}$. I want to see that $M^\perp \cap {\rm Int}(P) \neq \emptyset $. This seems obvious geometrically, any idea how a short proof would look like?","['normed-spaces', 'hilbert-spaces', 'analysis']"
106317,For what coinage systems does a greedy algorithm not work in providing change?,"For the United States coinage system, a greedy algorithm nicely allows for an algorithm that provides change in the least amount of coins. However, for a coinage system with 12 cent coins, a greedy algorithm would not work. For instance, change for 15 cents would be a 12 cent coin and 3 pennies (4 coins total) whereas a dime and a nickel (2 coins) would be optimal. In what types of coinage systems does the greedy algorithm not work?","['integer-partitions', 'algorithms', 'combinatorics']"
106330,Field extension obtained by adjoining a cubic root to the rationals.,"I hope it's not too long winded, but I prefer to give a short intro hoping for a last chance to go over this in my head and catch any error. Here's a primitive example of a field extension: $\mathbb{Q}(\sqrt 2) = \{a + b\sqrt 2 \;|\; a,b \in \mathbb{Q}\}$.  It's easy to show that it is a commutative additive group with identity $0$.  It's a little more involved to show that once $0$ is taken out (which rules out $a = b = 0$), what's left is a multiplicative group with identity $1$ and multiplicative inverse
$$\dfrac{1}{a + b\sqrt 2} = \dfrac{1}{a + b\sqrt 2}\dfrac{a - b\sqrt 2}{a - b\sqrt 2} = \dfrac{a - b\sqrt 2}{a^2 - 2b^2} = \dfrac{a}{a^2 - 2b^2} + \dfrac{- b}{a^2 - 2b^2}\sqrt 2$$
which always exists because $a,b\in\mathbb{Q}$ ensures that the denominator in the above equation can never equal zero and since $a$ and $b$ cannot both be $0$ neither can the inverse, giving us closure.  So $\mathbb{Q}(\sqrt 2)$ is a field. Now we seek to replicate this with $\sqrt[3] 5$. A little bit of algebra will quickly show that if we define $\mathbb{Q}(\sqrt[3]5)$ with elements $a + b\sqrt[3]5$ as before, we'll run into problems with closure when multiplying two such elements.  Instead we define $$\mathbb{Q}(\sqrt[3]5) = \{a + b\sqrt[3]5 + c\sqrt[3]{25} \;|\; a,b,c \in \mathbb{Q}\}$$ Once again, checking that the above set is an additive abelian group is easy. To show that the set minus $0$ is a multiplicative group we need to do some linear algebra: We want to show that given $a,b$ and $c$ (not all three $0$) there exists a unique $x,y$ and $z$ such that $$(a + b\sqrt[3]5 + c\sqrt[3]{25})(x + y\sqrt[3]5 + z\sqrt[3]{25}) = (1 + 0\sqrt[3]5 + 0\sqrt[3]{25})$$ where the right-hand side of the above equation is just $1$, namely the multiplicative identity.  Some tedious algebra allows us to rewrite the left-hand side as 
$$(ax + 5cy + 5bz) + (bx + ay + 5cz)\sqrt[3]{5} + (cx + by + az)\sqrt[3]{25} = 1$$
So we can rewrite the above as a system of equations ${\bf A x = b}$ given by
$$\begin{pmatrix}a & 5c & 5b \\ b & a & 5c \\ c & b & a\end{pmatrix}\begin{pmatrix}x \\ y \\ z\end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}$$
This reduces the problem of showing that there always exists a unique multiplicative inverse to one of showing that the above square matrix is invertible (which would guarantee us a unique solution.)  So let's find its determinant: $$\det({\bf A}) = a(a^2 - 5bc) + b(5b^2 - 5ac) + c(25c^2 - 5ab) = a^3 + 5b^3 + 25c^3 - 15abc.$$ Finally, we get to where I'm stuck.  How can we guarantee that the above is always non-zero as long as $a,b$ and $c$ are not all zero?  The notes I'm going over skipped this part and just said that $\mathbb{Q}(\sqrt[3]{5})$ is a field.","['ring-theory', 'abstract-algebra']"
106332,Time Series and statistics,"Consider the time series: $X(t) = 2 + 3t + Z(t) $ where $Z(t)$ are Gaussian white noises from $\mathcal{N}(0,1)$ . Is $X(t)$ stationary - why or why not? Is $Y(t) = X(t) - X(t-1)$ stationary, why or why not? Let $V(t)= \frac{1}{2q+1}\sum_{j=-q}^q X(t-j)$ . What is the mean and auto-covariance function of $V(t)$ . My approach is that: I know a stationary process is one in which the statistical properties of a given series are constant, such as constant mean, auto-covariance etc. I know that the expected value or mean of the noise component is zero. How do I compute the expectation of $X(t)$ ? How do I show the statistical properties are constant or not constant?","['statistics', 'time-series']"
106343,Beginner's algebra (real world application),"This may be too basic a question for this site, in which case I'm sure you'll all let me know. Here is my problem: I have a job worth $\$$40,000 composed of 6 units of x and 3 units of y. I'm trying to determine how much to charge for x and y, where y is worth 30% of x. I'd really like to be able to solve these sorts of questions myself in the future, but my recollection of algebra is far too hazy. Could you work it out longhand for me so I can see how to do it? Preemptive edit: this is not a school question. I'm putting together a SOW for a video job and the 30%(y) is the cost of a French translated version of the video, which is about 30% of the effort since only the audio track changes.",['algebra-precalculus']
106374,Minimize distance between 2 functions,"Just so you know, this is a homework question, and I basically need help with the steps to solve this problem. I understand what it's asking; however, my attempts haven't worked out, and I'm probably over-complicating it. Anyway, here it is: I have a space $C([-\pi/2,\pi/2])$ with the supremum norm: $||f||_\infty = \sup\{|f(x)| : x \in [-\pi/2,\pi/2]\}$ and I need to find the closest linear function $g(x) = cx$ closest to the function $f(x) = \sin(x)$ w.r.t. this norm. In other words, it appears that I need to find $c$ that minimizes the distance between these two curves, or that generates the smallest least upper bound for the function $h(c) = |\sin(x)-cx|$ for $x \in [-\pi/2,\pi/2]$. I thought this would be the same as minimizing the area between these two curves as a function of $c$, but it's not optimal to find the points of intersection of these functions as it would be dependent on $c$. Any ideas?","['optimization', 'normed-spaces', 'real-analysis', 'analysis']"
106381,Use the definition of a limit to show that $\lim_{z \to z_0} (az + b) = az_0 + b.$,"Let $a,b, z_0$ denote complex constants. Use the definition of a limit to show that 
  $$\lim_{z \to z_0} (az + b) = az_0 + b.$$ Here is what I have done: \begin{align*}
|az + b - (az_0 + b)| &= |az - az_0 + b - b|\\
&= |a(z - z_0)|\\
&= |a||z - z_0|.
\end{align*} So for a positive number $\epsilon$, $$|az + b - (az_0 + b)| < \epsilon \text{ whenever } |a||z - z_0| < \epsilon$$ or in other words $|az + b - (az_0 + b)| < \epsilon$ whenever $|z - z_0| < \delta$ where $\delta = \epsilon/|a|$. Have I proved the statement correctly?","['proof-verification', 'complex-analysis', 'limits']"
106389,Recursive solutions to linear ODE.,"When finding the solutions to the simple ODE $$ y'- mxy= x^n \text{ ; } y(0) = 0$$ I found the following: Let $P_n$ be the particular solution for each integer exponent $n$. Then if we define $$P_0(x) = \exp\left(\displaystyle \frac{mx^2}{2}\right)\int_0^x \exp\left(-\displaystyle \frac{mt^2}{2}\right)dt$$ $$P_1(x) =\frac{1}{m}\left\{ \exp\left(\displaystyle \frac{mx^2}{2}\right)-1 \right\}$$ All other solutions are given by the following recursion $$P(x)_{n+1} = \frac{n}{m}\left\{ P_{n-1}(x)-\frac{x^{n}}{n} \right\} $$ $$P'(x)_{n+1} = nxP(x)_{n-1}$$ Is there any theory on such functions? (I'm mostly interested in the last one, which is very similar to Bernoulli's: $$B'_{n+1}(x) = (n+1)B_{n}(x)$$ ADD: The particular solutions are $${P_{2n + 1}} = \frac{{\left( {2n} \right)!!}}{{{m^n}}}{P_1} - \sum\limits_{k = 1}^n {\frac{{\left( {2n} \right)!!}}{{\left( {2k} \right)!!}}} \frac{{{x^{2k}}}}{{{m^{n - k + 1}}}}$$ $${P_{2n}} = \frac{{\left( {2n - 1} \right)!!}}{{{m^n}}}{P_0} - \sum\limits_{k = 1}^n {\frac{{\left( {2n - 1} \right)!!}}{{\left( {2k - 1} \right)!!}}} \frac{{{x^{2k - 1}}}}{{{m^{n - k + 1}}}}$$ So maybe the importance will be in the polynomials (the sums).","['ordinary-differential-equations', 'special-functions']"
106396,Sine Approximation of Bhaskara,"An Indian mathematician, Bhaskara I, gave the following amazing approximation of the sine (I checked the graph and some values, and the approximation is truly impressive.) $$\sin x \approx \frac{{16x\left( {\pi  - x} \right)}}{{5{\pi ^2} - 4x\left( {\pi  - x} \right)}}$$ for $(0,\pi)$ Here's an image. Cyan for the sine and blue for the approximation. ¿Is there any way of proving such rational approximation? ¿Is there any theory similar to Taylor's or Power Series for rational approximations?","['trigonometry', 'approximation']"
106409,Using Durfee squares to prove partition identities?,"I was surprised to learn of Durfee squares , which can be visually explained as the largest square contained within a partition's Ferrers diagram. Moreover, partition identities have always amused me by how complicated they appear at first to prove. Out of curiosity, can Durfee squares be used to prove either of the following partition identities? $$
\prod_{i\geq 1}(1-qx^i)^{-1}=\sum_{j\geq 0}\frac{x^{j^2}q^j}{(1-x)\cdots(1-x^j)(1-qx)\cdots(1-qx^j)}
$$
or
$$
\prod_{i\geq 1}(1+qx^{2i-1})=\sum_{j\geq 0}\frac{x^{j^2}q^j}{(1-x^2)(1-x^4)\cdots(1-x^{2j})}?
$$ In fact, in Andrews and Eriksson's Integer Partitions , Exercise 101 on page 77 suggests that Durfee squares can be used to determine these formulas. How can this method be employed? Thanks.","['integer-partitions', 'number-theory', 'combinatorics']"
106412,About the smallest sigma field under certain conditions.,"Let $ (\Omega, \mathcal{F}) $ be a measurable space. Let $ A, B \in \mathcal {F} $ with $ A \cap B = \emptyset $.
 Let $ \mathcal{A} \subset \mathcal{F} $ the smallest $ \sigma $-field containing $ A $ and not containing $ B $ and $ \mathcal {B} \subset \mathcal{F} $ the smallest $ \sigma $-field containing $ B $ and not containing $ A $. Is it true that $ \mathcal{F} $ is the smallest sigma algebra containing $ \mathcal {A} \cup \mathcal {B}$? And if $|\Omega|=\infty$ ? There is a counter example? Thank´s.",['measure-theory']
106417,what is Prime Gaps relationship with number 6?,Out of the 78499 prime number under 1 million. There are 32821 prime gaps (difference between two consecutive prime numbers) of a multiple 6. A bar chart of differences and frequency of occurrence shows a local maximum at each multiple of 6. Why is 6 so special?,"['prime-numbers', 'number-theory']"
106418,"How to integrate $ \int_{-\infty}^{+\infty} \frac{\sin(x)}{x} \,dx $? [duplicate]","This question already has answers here : Closed 12 years ago . Possible Duplicate: Solving the integral $\int_{0}^{\infty} \frac{\sin{x}}{x} \ dx = \frac{\pi}{2}$ ? How can I do this integration using only calculus? 
(not Laplace transforms or complex analysis) $$
\int_{-\infty}^{+\infty} \frac{\sin(x)}{x} \,dx
$$ I searched for solutions not involving Laplace transforms or complex analysis but I could not find.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'trigonometry']"
106427,Probability of difference of random variables,"How can I compute this probability? I do not know what to do since it involves two random variables. Let $X$ and $Y$ be uniform random variables on $(0,1)$. How can I compute this? $$
P(|X-Y| < 0.25).
$$ I tried to do it using an integral
$$
\int_0^1 P(|X-y| < 0.25) \,dy
$$ but I do not know what to do next. edit: I forgot to mention the independence of the random variables. Thanks for warning.","['uniform-distribution', 'probability']"
106442,Prove that integer $n$ exists such that $n^2$ begins with $201120122013$.,"I've found a few different formulations of the problem where the given digits are different, so my guess is that it actually works for any array of integers. But I don't know how to solve it, nor where to start. I'm not that good in number theory.",['number-theory']
106457,"$L^1$-bounded quadratic variation of a continuous local martingale $\implies$ it is a true martingale, $L^2$-bounded","Let M be a continuous local martingale starting from $0$. Show that M is an $L^2$-bounded ($\displaystyle \sup_t\|M_t\|_2<\infty$) martingale if $\mathbb{E}([M]_{\infty})<\infty$, where $[M]_{\infty}=\displaystyle \lim_{t \to \infty} [M]_t$ and $[M]$ is the unique continuous adapted non-decreasing process such that $M^2-[M]$  is a continuous local martingale. Could do with some hints. My thoughts: I know that any local martingale bounded by an integrable random variable is a true martingale and that $\displaystyle \sup_n\mathbb{E}[M^2_{T_n}] < \infty$, where $T_n$ are the stopping times reducing $M^2-[M]$. What I am finding hard is to make any conclusions about $M_t$, given that I have information about $M_{T_n}$ only. Edit: Managed to show that $M_t \to M_{\infty}$ in $L^2$ for some $M_{\infty}$","['probability-theory', 'stochastic-processes']"
106459,How to prove a surface is smooth,"I am given the function $F:\mathbb{R}^3\to\mathbb{R}$ where $F(x,y,z)=(x^2+y^2+z^2-5)^2+16z^2-16$ and then asked to prove that $M:=F^{-1}(0)$ is a smooth surface. Problem is, I wasn't given a definition of a smooth surface in my lecture and can't seem to find a good one via Googling. I am told that a smooth curve is one for which all higher derivatives exist for each point on the curve, so is this the same for surfaces? Either way could someone let me know how to do this question? Thanks",['differential-geometry']
106462,On the group of signed permutations?,"Let $B_n$ be the group of signed permutations, which is a Coxeter group acting on $\mathbb{R}^n$ with Coxeter generators $\sigma_i=(i\; i+1)\in S_n$ and the change of sign $\tau(x_1,x_2,\dots,x_n)=(-x_1,x_2,\dots,x_n)$. So the elements can be represented by the action on the vector $(1,2,\dots,n)$ as words $w$ in the signed alphabet $\{\pm 1,\dots,\pm n\}$ where the $|w_i|$ form a permutation. Moreover, 
$$
\operatorname{inv}(w)=|\{i<j:w(i)>w(j)\}|+|\{i<j: w(i)+w(j)<0\}|+|\{i: w(i)<0\}|.
$$
Supposedly $\operatorname{inv}(w)$ is just the minimum length of an expression for $w$ written as a product of the Coxeter generators. How does that characterization follow from this definition? Thank you.","['group-theory', 'abstract-algebra', 'combinatorics']"
106464,Proving the Nullstellensatz for homogeneous ideals,"I'd like to prove the following: If $\mathfrak{a} \subseteq k[x_0, \ldots, x_n]$ is a homogeneous ideal, and if $f \in k[x_0,\ldots,x_n]$ is a homogeneous polynomial with $\mathrm{deg} \ f > 0$, such that $f(P) = 0 $ for all $P \in Z(\mathfrak{a})$ in $\mathbb P^n$, then $f^q \in \mathfrak{a}$ for some $ q > 0$. I've been given the hint: interpret the problem in terms of the affine ($n+1$)-space whose affine coordinate ring is $k[x_0,\ldots,x_n]$ and use the usual Nullstellensatz. I'm not really sure what the hint means. We have the isomorphism $k[x_0,...,x_n] \cong k[x_0,...,x_n] / I(\mathbb A_k^{n+1})$ (since $I(\mathbb A^{n+1}) = I(Z(0)) = 0$). But I don't see how this is helpful at all, nor am I sure this is what the hint means. Any help would be greatly appreciated. Thanks",['algebraic-geometry']
106465,Ring of rational numbers with odd denominator,"Consider the ring $R$ of rational numbers which, when written in simplest form, have an odd denominator. This is a subring of $\mathbb{Q}$ with the usual multiplication and addition. I wonder if you could check my understanding of the units, irreducible elements, and prime elements in this ring. Assume all fractions are in simplest form. Units: For any element $\frac{a}{b} \in R$ either $a$ is odd or $a$ is even. If $a$ is odd, then $\frac{b}{a} \in R$ and $\frac{a}{b}\frac{b}{a}=1$. Hence, $\frac{a}{b}$ is a unit. If $a$ is even, then $\frac{b}{a}$ is not in $R$. There's no other possibility for an inverse, so $\frac{a}{b}$ is not a unit. Irreducible elements: We can write an element $\frac{a}{b}$ uniquely in the form $\frac{2^ne}{b}$ where $n \in \mathbb{N}$ and $e$ is odd. I claim that that the irreducible elements are precisely those for which $n=1$. Proof: If $n=0$, then $a$ is odd and our element $\frac{a}{b}$ is a unit, not irreducible. If $n>1$, then $\frac{a}{b}=\frac{2e}{1}\frac{2^{n-1}}{b}$ and neither of the elements of this product are units because their respective numerators are even. However, if $n=1$, we have $$
\frac{a}{b}=\frac{2e}{b}=\frac{w}{v}\frac{y}{z}.
$$ Then one of $w,y$ must be even and the other must be odd. Suppose WLOG that $w$ is even. Then $y$ is odd and $\frac{y}{z}$ is a unit. Hence, $\frac{a}{b}$ is irreducible. Primes: All primes must be irreducible, so we may look among the irreducible elements for our primes. That is, among the elements of the form $\frac{2e}{b}$ with $e$ odd. I'm having trouble getting any further, though. Any suggestions?","['ring-theory', 'abstract-algebra']"
106469,Traditional Marriage GS female pessimality,"In the context of stable matchings I am currently trying to understand the Gale-Shapely Algorithm (traditional marriage algorithm). I have proved it s correctness and I have shown that its male optimal in the sense that each boy  will end up in the best stable match. (i.e. any matching where he would be with a girl he prefers would not be stable), however I am struggling a little to come up with a good strategy to show the algorithm will return a female pessimal matching. (i.e. among all stable matchings  each female will be matched to the least preferred boy) A hint to get me started would be very appreciated.","['graph-theory', 'discrete-mathematics', 'algorithms']"
106479,Prove that the order of convergence must be $\geq 1$,"Given a sequence $\{x_n\}_n$ and real numbers $c > 0$ and $L$, such that $\displaystyle\lim_{n \to \infty}x_n - L = 0$ and $\displaystyle\lim_{n \to \infty} \frac{| x_{n+1} - L |}{|x_n - L|^p} = c$, prove that $p \geq 1$. This is assumed without proof in my textbook and I'd like a rigorous one, but I can't come up with it.","['calculus', 'limits']"
106480,Find roots of sum of sinusoids,"Given this function and an initial point, find the next root : $$
\begin{align}
f(t) & = -L\\ & {} + A \sin(\Theta_1 + \omega_1 t) \\ & {} +B \cos(\Theta_1 + \omega_1 t)\\ & {} - (P_x + V_x t )\sin(\Theta_2 + \omega_2 t)\\ & {} + (P_y + V_y t) \cos(\Theta_2 + \omega_2 t)

\end{align}
$$ (where everything is known except for $t$), starting at $t_0$, I'm trying to find the ""next"" root $t_1$.  That is, in the interval $(t_0, t_1]$ there is only one root and it's $t_1$.  $t_0$ can be the previous root, but it doesn't necessarily need to be. This is for an automated system (for collision detection.  The above equation is related to the motion of a point and a line) so I can't eyeball the function or manually give hints, and not finding an answer would be very bad.  And I don't want to miss any roots so I don't want to set up random seed guesses and build brackets from those if they happen to straddle an odd root (it couldn't catch even roots anyway).  But I can make the simplifying assumption that if two roots are within some epsilon of each other they're the same root as far as I'm concerned. Here's the algorithm I have right now: I'm defining a ""window of interest"", which is a min and max 't' value I'm interested in finding roots within.  There might be many or no roots inside this window of interest; it's just a way of slicing up the function to something more managable.  Within that window of interest I find a maximum value for the second derivative.  Then I use that, an evaluation of the first derivative, and an evaluation of the function itself at the current $t$ value to construct a quadratic interpolation to underestimate the distance to the next root (a ""safe"" step foward, where we're guaranteed we won't miss a root).  Then I can scoot forward my iteration by this amount, and rinse and repeat (this is called ""conservative advancement"" in the literature I have).  If I get into a spot where I get stuck because the function and the first derivative are 0, I choose a step size of an epsilon and scoot forward and try again.  Once I get ""close enough"" to a new 0 (again, to some epsilon), I switch to Newton's Method to refine the root. My Question: The whole algorithm above works okay, but it's neither very performant or very clever.  The ""conservative advancement"", especially when I have to resort to just walking forward by an epsilon, is really really slow (can takes hundreds of function evaluations to get to a point where I can switch over to Newton's method).  And I have no real way of checking if Newton's method is going to refine itself to the root I'm interested in or not when I do switch over. Are there any more clever techniques I could use instead of what I'm doing?  The function itself is a sum of sinusoids, so I thought I could do something clever with the frequencies of each sinusoid to bracket at least the local min/max, and from that maybe the basins of attraction for Newton's method, but in the end I couldn't figure out anything that was actually useful.  Any ideas or literature people could point me to that would be useful would be great. Update: ... Thinking about it a bit more.  I feel like it should be possible to split the function up in to intervals using the angular velocities (the $\omega$ terms), such that each interval contains no more than one local extrema (some sort of pigeonhole principal-esque idea).  If the interval has an even root, it has only one such root in the interval and we know it's the local extrema.  Odd roots might be more easily bracketed in this context, too (I think; haven't worked it out yet, really). Update 2: Wolfram alpha seems to be able to find analytic roots for A*sin(B*t) + C*sin(D*t) .  Anyone have any idea how they do that?  That's not a result I've been able to derive on my own.","['trigonometry', 'calculus', 'roots', 'numerical-methods']"
106490,How the free group on two generators $F_2$ is isomorphic to a particular quotient group,"Suppose we denote the free group on two generators as $F_2$, which is the standard one used in proving the Banach-Tarski Paradox. Now let $\Gamma(2)$ be the group of integer matrices $\left( \begin{smallmatrix} a & b \\ c & d \end{smallmatrix} \right)$ that satisfy the condition $\left( \begin{smallmatrix} a & b \\ c & d \end{smallmatrix} \right) \equiv \left( \begin{smallmatrix} 1 & 0 \\ 0 & 1 \end{smallmatrix} \right) \pmod{2}$. Finally, let $\Gamma(2)/T$ denote the quotient group of $\Gamma(2)$ by the central order $2$ subgroup generated by the matrix $\left( \begin{smallmatrix} -1 & 0 \\ 0 & -1 \end{smallmatrix} \right)$ which I will denote by $T$. How can we show that $F_2 \cong \Gamma(2)/T$, i.e. these two groups are isomorphic? Apparently it's known, but I haven't found a proof for this in any text. Any suggestions?",['group-theory']
106509,Is $\int_a^b f(x) dx = \int_{f(a)}^{f(b)} f^{-1}(x) dx$?,"Is it true that $$\int_a^b f(x) dx = \int_{f(a)}^{f(b)} f^{-1}(x) dx$$ Just making sure. If not, how about: $$\int_a^b f(x) dx = (f(b)-f(a))b - \int_{f(a)}^{f(b)}f^{-1}(x)dx$$ I'm having a hard time concentrating right now, and I'm trying to figure out how to get the area under a curve when the function is inverted.","['calculus', 'integration']"
106520,A nicer recurrence for the Eulerian polynomials.,"I was perusing the subject of Eulerian polynomials. I'm assuming the definition that the Eulerian polynomial is defined by $C_n(t)=\sum_{\pi\in S_n}t^{1+d(\pi)}$, where $d(\pi)$ is the number of descents. The Eulerian polynomials satisfy a standard recurrence $C_n(t)=t(1-t)C'_{n-1}(t)+ntC_{n-1}(t)$. Apparently they also satisfy the more aesthetically pleasing relation
$$
C_n(t)=tC'_{n-1}(t)+t^nC'_{n-1}(t^{-1}).
$$ The generating function in $t^{-1}$ is troublesome to me. How can one derive this other recurrence relation? Thank you,","['recurrence-relations', 'polynomials', 'generating-functions', 'eulerian-numbers', 'combinatorics']"
106530,"System $a+b+c=4$, $a^2+b^2+c^2=8$. find all possible values for $c$.","$$a+b+c=4$$$$a^2+b^2+c^2=8$$ I'm not sure if my solution is good, since I don't have answers for this problem. Any directions, comments and/or corrections would be appreciated. It's obvious that $\{a,b,c\}\in[-\sqrt8,\sqrt8]$. Since two irrational numbers always give irrational number when added, if we assume that one of $a,b $ or $c$ is irrational, for example $a$, then one more has to be irrational, for example $b$, such that $a=-b$. That leaves $c=4$ in order to satisfy the first equation, but that makes the second one incorrect. That's why all of $a,b,c$ have to be rational numbers. $(*)$ I squared the first equation and got $ab+bc+ca=4$. Then, since $a=4-(b+c)$, I got quadratic equation $b^2+(c4)b+(c-2)^2=0$. Its' discriminant has to be positive and perfect square to satisfy $(*)$. 
$$ D= -c(3c-8) $$
From this, we see that $c$ has to be between $0$ and $8/3$ in order to satisfy definition of square root. Specially, for $c=0$ we get $D=0$ and solution for equation $b=\frac{-c+4}{2}=2$. Since the system is symmetric, we also get $c=2$. Similar, for $c=8/3$ we get $b=2$. In order for $D$ to be perfect square, one of the following has to be true:
$$ -c=3c-8 $$
$$ c=n^2 \land 3c-8=1 $$
$$ 3c-8=n^2 \land c=1 $$ However, only the first one is possible, so $c=2$, and for that we get $b=\frac{(-2+4\pm2)}{2} \Rightarrow b=2 \lor b=0$. So, all possible values for $c$ are $c\in\{0, 2, \frac{8}3\}$. EDIT: For $a=b$, there is one more solution: $c=2/3$. Why couldn't I find it with method described above?","['optimization', 'symmetric-polynomials', 'algebra-precalculus', 'systems-of-equations']"
106536,Prerequisite of Projective Geometry for Algebraic Geometry,"I studied Euclidean Geometry in high-school, and I have not studied anything relates to geometry since I started studying in university. I am now intending to study Algebraic Geometry, however, I lacked in geometric intuition, especially in projective aspect. Could you please suggest me some text book about Projective Geometry(or Geometry in general) with a view toward Algebraic Geometry, or have promising intuition to Algebraic Geometry? I am sorry if my poor English lead to any misunderstanding. Thank for reading.","['algebraic-geometry', 'advice', 'projective-geometry']"
106539,Solving Triangles (finding missing sides/angles given 3 sides/angles),"What is a general procedure for ""solving"" a triangle—that is, for finding the unknown side lengths and angle measures given three side lengths and/or angle measures?","['geometry', 'algebra-precalculus', 'triangles', 'trigonometry', 'euclidean-geometry']"
106544,intermediate step in proving old Ramsey lower bound,"Let $r(n,n)=r(n)$ be the usual Ramsey number of a graph. It is known that $$\frac{1}{e\sqrt{2}}n2^{n/2}<r(n)$$ as a lower bound for $r(n).$ Now, in the proof given in the book Erdős on Graphs by Graham and Chung, as an intermediate step this is given: $$2^{\binom{m}{2}}>\binom{m}{n}2^{\binom{m}{2}-\binom{n}{2}+1}\;,\tag{*}$$ and that this implies that $$m\ge\frac{1}{e\sqrt{2}}n2^{n/2}\;.\tag{**}$$ I cannot figure out how $(*)$ implies $(**)$. Can someone please explain this?","['ramsey-theory', 'combinatorics']"
