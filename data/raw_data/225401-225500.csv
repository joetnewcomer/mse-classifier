question_id,title,body,tags
4647003,Computing the limit of $ \frac{1^3+2^3+\cdots+n^3}{\sqrt{4n^8 +1}} $,"I had this exercise: Compute the limit $$ \lim_{n\to\infty} \frac{1^3+2^3+\cdots+n^3}{\sqrt{4n^8 +1}} $$ I tried two different approaches and got different answers. Approach 1: $$\begin{split}
\lim_{n\to\infty} \frac{1^3+2^3+\cdots+n^3}{n^4\sqrt{4 +1/n^8}}&=\lim_{n\to\infty} \frac{\frac{1^3}{n^4}+\frac{2^3}{n^4}+\cdots+\frac{n^3}{n^4}}{\sqrt{4 +1/n^8}}\\
&=\lim_{n\to\infty} \frac{\frac{1^3}{n^4}+\frac{2^3}{n^4}+\cdots+\frac{1}{n}}{\sqrt{4 +1/n^8}}\\
&= \frac{0}{\sqrt{4+0}}\\
&= 0\\
\end{split}$$ Approach 2: We substitute sum of cubes of $n$ natural numbers in the numerator and get $$\begin{split}
\lim_{n\to\infty} \frac{n^2(n+1)^2}{4n^4\sqrt{4 +1/n^8}}&= \lim_{n\to\infty} \frac{n^2(n+1)^2}{4n^4\sqrt{4 +1/n^8}}\\
&= \lim_{n\to\infty} \frac{n^4(1+\frac{1}{n})^2}{4n^4\sqrt{4 +1/n^8}}\\
&= \lim_{n\to\infty} \frac{(1+\frac{1}{n})^2}{4\sqrt{4 +1/n^8}}\\ 
&= \lim_{n\to\infty} \frac{1}{4\sqrt{4}}\\
&= \frac{1}{8}\\
\end{split}$$ I'm not sure why the two methods are giving me different answers and which one is correct?","['limits', 'calculus', 'limits-without-lhopital', 'real-analysis']"
4647032,Looking for prototype for ease-in function,"I'm looking for some kind of ease-in function. Within the range of $0 < x < 1$ , $0 < y < 1$ and depending on a parameter $0 < g < 1$ it should have the following properties: $$ f(0) = 0, f(1) = 1, f'(0) = 0, f'(1) = \infty $$ $$ f(x, g = 0) = x, f(x, g = 1) = 0$$ $$ f\left(\frac{1}{2} + g\right) = \frac12 - g, f'\left(\frac{1}{2} + g\right) = 1$$ So basically it is symmetric about y = 1 - x and crosses that line perpendicularly. I tried to stitch it together from two 3rd degree polynomials, which almos does the job, but not exactly. Graph Biggest issue is that it becomes negative as the parameter gets larger. I'm not quite sure what to look for, so any help would be appreciated!","['functions', 'graphing-functions']"
4647055,Union-closed family with a certain property,"Originally posted on mathoverflow , now crossposted since there is no answer there. Consider a union-closed family $\mathcal{F} = \{A_1, \dotsc ,A_n\}$ of $n$ finite sets, $n$ odd, $n \ge 3$ , $A_i \neq \emptyset$ , $i=1,\dotsc,n$ . Let $r=\frac{n+1}{2}$ . We have that: $$\bigcup_{1 \le i_1 \lt \ldots \lt i_r
 \le n} A_{i_1} \cap \ldots \cap A_{i_r
} = \bigcap_{1 \le i_1 \lt \ldots \lt i_r \le n} A_{i_1} \cup \ldots \cup A_{i_r} \tag{1}\label{1}$$ This is because the LHS contains all elements that are in at least $r$ of the $A_i$ and the RHS contains all elements that are in at least $n-r+1$ of the $A_i$ (because for each element that does not belong to the RHS we can find $r$ $A_i$ that do not contain it and thus it is in maximum $n-r$ of the $A_i$ ) and note that in our case $r=n-r+1$ . The RHS is the intersection of $\binom{n}{\frac{n+1}{2}}$ union expressions. However, we can simplify it removing all terms equal to $U(\mathcal{F})$ or which are supersets of another term, keeping only one union expression for each possible resulting set, to get: $$\bigcap_{1 \le i_1 \lt \ldots \lt i_r \le n} A_{i_1} \cup \ldots \cup A_{i_r} = \bigcap_{k=1}^{h} A_{i_{k,1}} \cup \dotsb \cup A_{i_{k,r}} = \bigcap_{k=1}^{h} B_k \tag{2}\label{2}$$ Where $h \le n-1$ and $B_k = A_{i_{k,1}} \cup \dotsb \cup A_{i_{k,r}}$ . After that, if there is no set $A_{i_{k,1}},\ldots,A_{i_{k,r}}$ in the expression equal to $B_k$ , we replace one set with it, otherwise we leave the expression like it is. In any case we can rewrite it as: $$B_k = A_{j_{k,1}} \cup \dotsb \cup A_{j_{k,r-1}} \cup B_k \tag{3}\label{3}$$ Now suppose that there is some $B_t = A_{j_{u,v}}$ with $t \not= u$ . That would imply $B_t \subseteq B_u$ and then $\eqref{2}$ not minimal. Therefore $B_t \not= A_{j_{u,v}}$ and for what said before also $B_t \not= A_{j_{t,z}}$ . This means that $A_{i_{k,1}},\ldots,A_{i_{k,r-1}}$ are chosen among $n-h-1$ sets ( $-h$ is to remove the $B_k$ and $-1$ for $U(\mathcal{F})$ ). Now suppose that $\bigcap_{k=1}^{h} B_k = \emptyset$ . Suppose also that there is one $A_l$ appearing in $h-1$ of the $\eqref{3}$ expressions, WLOG in $B_1, \ldots ,B_{h-1}$ . Then $A_l \cap A_{i_{h,m}} = \emptyset$ , $m=1,\ldots,r-1$ and $A_l \cap B_h = \emptyset$ , therefore it is easy to see that the unions $A_l \cup A_{i_{h,m}}$ , $m=1,\ldots,r-1$ and $A_l \cup B_h$ must be all different and different also from $A_l$ , $A_{i_{h,m}}, m=1,\ldots,r-1$ , and $B_h$ . We would then have a total of $1 \times r+1+r=n+2 \gt n$ sets, absurd. Therefore all $A_l$ must appear in maximum $h-2$ of the $\eqref{3}$ expressions. As said above $A_{i_{k,1}},\ldots,A_{i_{k,r-1}}$ are $r-1=\frac{n-1}{2}$ sets chosen among $n-h-1$ sets, with $1 \le k \le h$ . None of those sets can appear in more than $h-2$ union expressions. Therefore, thinking to a matrix where each column represents the same set and each row one of the union expressions, we can say that if $\bigcap_{k=1}^{h} B_k = \emptyset$ then: $$h(n-h-1) \ge \frac{n-1}{2}h + 2(n-1-h) \label{4}\tag{4}$$ Inequality $\eqref{4}$ has no solution for $n$ odd, $n \lt 25$ . It implies also that $h \le \frac{n-1}{2}$ . I am curious to see how looks a union-closed family such that all $A_l$ appear in maximum $h-2$ of the $\eqref{3}$ expressions, but I wasn't able to find an example. Someone can help? I precise that in the example that I search it shouldn't be possible to replace some $B_k$ with a different expression, in a way that there is a set appearing $h-1$ or $h$ times. A possible idea is starting from this example where $h=4$ but there is no set appearing in all the $4$ expressions, but there are sets appearing in $h-1=3$ expressions. However I can't see how to build an example as required by the question.","['combinatorics', 'extremal-combinatorics']"
4647138,Bertini's Theorem in Harris' Algebraic Geometry,"I have a question about the proof of Bertini' Theorem found in Harris' book Algebraic Geometry , on page 216/217: Theorem 17.16. Bertini's Theorem. If $X$ is any quasi-projective variety over $\mathbb{C}$ , $f: X \to \mathbb{P}^n$ a regular map, $H \subset \mathbb{P}^n$ a general hyperplane, and $Y = f^{-1}(H)$ , then $$Y_{\text{sing}}= X_{\text{sing}} \cap Y. $$ where $X_{\text{sing}}=X- X_{\text{sm}}$ is the singular locus. The essence of the proof is to analyze the incidence correspondence $$ \Gamma = \{(p,H) \ \vert f(p) \in H \} \subset X \times (\mathbb{P}^n)^*  $$ If $X$ is $k$ -dimensional, $\Gamma$ will have dimension $k + n - 1$ . Now, let $p \in X$ be any smooth point and $H \subset \mathbb{P}^n$ a hyperplane containing $f(p)$ ; then it's easy to see that $$  \dim(T_{(p,H)}(\Gamma))= \dim(T_{(p,H)}(X \times (\mathbb{P}^n)^*))-1  $$ in particular, the singular locus of $\Gamma$ is exactly the inverse image $\pi_1(X_{\text{sing}}$ of the singular locus of $X$ under $\pi_1: X \times (\mathbb{P}^n)^* \to X$ . Now look at the restricted map $\tilde{\pi}_2 : \Gamma_{\text{sm}} \to (\mathbb{P}^n)^*$ . Bertini's theorem follows from
applying Proposition 14.4 to $\tilde{\pi}_2$ ; or, more directly, by Exercise 14.6 the locus $U \subset (\mathbb{P}^n)^*$ of hyperplanes $H$ such that the fiber $\tilde{\pi}^{-1}_2(H) = X_{\text{sm}} \cap H$ is smooth is either contained in a proper subvariety of $(\mathbb{P}^n)^*$ or contains an open subset of $(\mathbb{P}^n)^*$ ,
and we can simply apply Sard's theorem to $\tilde{\pi}_2$ deduce that the former must be the case. Question: I would like to understand better the last part of the proof. Harris offers in the last sentence alongside to the crystal clear argument applying Proposition 14.4 another ""more directly"" argument by means of Exercise 14.6 which I not understand. This exercise asserts: Exercise 14.6. Let $f: X \to Y$ be any regular map of affine varieties. Then the dimension of the kernel of the differential $df_p: T_pX \to T_{f(p)}Y$ is an upper-semicontinuous
function of $p$ . In other words $$X_{\ge k} :=\{p \in X \ \vert \ \dim \text{ Ker} (df_p)) \ge k\} \subset X$$ is closed for every $k \ge 0$ . This implies also that every subset $X_k:= \{p \in X \ \vert \ \dim \text{ Ker} (df_p) = k\}$ is locally closed or constructible and therefore $f(X_k)$ is constructible too, since images of constructible sets are constructible. Note that this statement does not imply that the locus of smooth points of fibers
of $f$ - that is, the locus of $p \in X$ such that the fiber $X_{f(p)} = f^{-1} (f(p))$ is smooth at $p$ - is open or constructible
in $X$ , or that the dimension of $T_p(X_{f(p)})$ is an upper-semicontinuous function of $p$ ,
since the Zariski tangent space to $X_{f(p)}$ may be smaller than $\text{Ker}(df_p)$ . And that's exactly the central problem. We know that the subsets $(\Gamma_{\text{sm}})_k$ and therefore their images under $\tilde{\pi}_2$ are locally closed / constructible. This implies that these have this mentioned property that they are either contained in a proper subvariety of $(\mathbb{P}^n)^*$ or contain an open subset . But we know by means of this exercise 14.6 not enough about the set $U \subset (\mathbb{P}^n)^*$ of those hyperplanes $H$ whose fibers $\tilde{\pi}^{-1}_2(H) \cong X_{\text{sm}} \cap H$ are smooth, ie those $H$ such that for every $(p, H) \in \Gamma_{\text{sm}}$ (equivalently $p \in H \cap X_{\text{sm}}$ ) the dimension of the tangent space of $\tilde{\pi}^{-1}_2(H)$ at $(p,H)$ equals $\dim H \cap X_{\text{sm}} =k-1$ . We only know that on the domain side there is an inclusion $$  \{(p,H) \in \Gamma_{\text{sm}} \ \vert \ \dim \text{Ker} (T_{(p,H)} \tilde{\pi}_2)= k-1\} \subset \{(p,H) \ \vert \ \tilde{\pi}^{-1}_2(H) \text{ smooth at } (p,H) \}$$ because obviously $T_{(p,H)}\tilde{\pi}^{-1}_2(H) \subset \text{Ker} (T_{(p,H)} \tilde{\pi}_2)$ . Therefore we conclude that the set on the right hand side is dense in $\Gamma_{\text{sm}}$ , because $(\Gamma_{\text{sm}})_{k-1}$ is open in $\Gamma_{\text{sm}}$ . But clearly it could happen that $\tilde{\pi}_2((\Gamma_{\text{sm}})_{\ge k})= (\mathbb{P}^n)^*$ , and so we would lose any control at the codomain side. Therefore I not see why $U$ should have the claimed
property to be either contained in a proper subvariety of $(\mathbb{P}^n)^*$ or to contain an open subset of $(\mathbb{P}^n)^*$ .","['algebraic-geometry', 'projective-varieties']"
4647140,Formula for the tangent to an ellipse at a given point (splitting formula),"Consider the ellipse with canonical equation referring to the axes and origin of coordinates in the center of the ellipse, i.e., with equation $$\dfrac{x^2}{a^2}+\dfrac{y^2}{b^2}=1\qquad \text{$(a,\,b>0)$ semiaxes.}$$ With partial derivatives, if we have in the plane a curve $C$ of implicit equation $f(x,y)=0$ , where $f$ is continuous with prime partial derivatives $\partial_x f$ and $\partial_y f$ also continuous, given a point $(x_0, y_0)\in C$ on the noncritical curve for $f$ (i.e., such that $\nabla f(x_0,y_0)\ne(0,0)$ ), it is known that the equation of the tangent line to the curve at the point $(x_0,y_0)$ in question is given by $$\partial f_x(x_0,y_0)(x-x_0)+\partial f_y(x_0,y_0)(y-y_0)=0.$$ In our case, therefore, we have that the equation of the tangent is $$\dfrac{2x_0}{a^2}\,(x-x_0)+\dfrac{2y_0}{b^2}\,(y-y_0)=0,$$ from which with obvious steps $$\dfrac{x_0\,x}{a^2}+\dfrac{y_0\,y}{b^2}-\dfrac{x_0^2}{a^2}-\dfrac{y_0^2}{b^2}=0,$$ That is, since $(x_0,y_0)$ lies on the ellipse $$\boxed{\dfrac{x_0\,x}{a^2}+\dfrac{y_0\,y}{b^2}=1.} \tag 1$$ In this website there is also a long tedious proof where the Italian language is just barely perceptible. Is there a proof of the $(1)$ , using homoteties (dilations) for example, that is simpler and more immediate ? Partial derivatives are not studied in high school.","['alternative-proof', 'algebra-precalculus', 'conic-sections', 'education']"
4647173,I don't understand the hint given when proving the limit of a log function,"The question is to prove the following limit, $n \to \infty $ $$
\frac{n}{t} \ln({1 + \frac{t}{n}}) \to 1
$$ I could do this using something like L'Hôpital's rule but the hint is ""Use the differentiability of log at 1 to show that for each t"" I don't know how to prove it using the hint. Any help would be appreciated?","['limits', 'logarithms']"
4647178,Math proof vs Logic Proof.,"I am trying to learn math ""from scratch"" and started by reading an introductory logic textbook ( A Concise introduction to logic ) that did a great job explaining predicate logic. Among other things, proofs, that is, syntactic string manipulation where from a set of premises P, via a number of inference rules, a new statement, aka conclusion C, can be derived. I am now profoundly stuck trying to make the leap to mathematical proofs. And here is where. The first introductory proof I saw looks like the following: Slide 42 from here But how does this connect to predicate logic?
The predicate logic proofs begin with premises and here the theorem to be proven looks like the conclusion but no premises are given. Which I can understand: in propositional logic, a theorem is ""a sentence that can be derived without premises"" (ctrl + f for ""theorem"" here ). But where do I go from here? I can rewrite the theorem in predicate logic like the following But how can I go about proving it? The techniques in the textbook call for a sequence of conditional derivations and I would guess some universal instantiation or generalizations. What am I missing to connect these 2 proofs?
What is the link between a predicate logic proof and a math proof written in English? I see that there is a square function involved that can be thought of as a relation (a form of predicate) and Even(x) is also a predicate, but aside from that i see no clues. The math proof almost feels like a different underlying language and the predicate logic is like its skeleton that can not really be used here. Is that a valid notion? Proving in math almost feels like using rules of arithmetic to get a matching definition while proving in predicate logic is more about producing a new string from the existing ones. I see how this is a lot of thoughts pointing in potentially different directions  but I am hoping that someone more experienced could notice/relate to the struggle and point me in the right direction. Thank you everyone! I believe my question is similar to the mathematical proof vs. first-order logic deductions but I did not find anything to answer my particular example.","['proof-explanation', 'proof-writing', 'predicate-logic', 'discrete-mathematics']"
4647180,Math Competition Question for IMC 2016 (University level),"I am practicing for the IMC math competition for university students, and I was wondering if someone could help me with this question: Today, Ivan the Confessor prefers continuous functions $f:[0,1]\to\mathbb R$ satisfying $f(x)+f(y)\geq |x-y|$ for all $x,y\in [0,1]?$ Find the minimum of $\int_0^1 f$ over all preferred functions. This is from the 2016 IMC, question 7. My idea was to integrate on both sides from 1 to 0 twice, the first integral in x and the second in y, but this gave a solution of 1/6, but the solution says the true answer is 1/4. I was wondering if someone could explain why my answer was incorrect, and if anyone has a solution to this problem?","['contest-math', 'optimization', 'functions', 'continuity']"
4647210,Reflections of a point about n lines returns point to its original position,"Here's a very interesting problem that I made up with a friend this morning: For which even $n$ does there exist a permutation $\pi$ of $\{1,2,\cdots,n\}$ such that when we reflect any point $P$ in the $xy$ plane about the lines $y=\pi(1)x, y=\pi(2)x, \cdots, y=\pi(n)x$ in that order, $P$ is returned to it's original position? For these $n$ , how many such permutations are there? So far, we've noted the fact that when we reflect a point about two lines, it's equivalent to a rotation about the intersection of the lines of angle twice the angle between the two lines. Thus, if we let $\{a_1,a_2,\cdots,a_{n/2}\}=\{\pi(1),\pi(3),\cdots,\pi(n-1)\}$ and $\{b_1,b_2,\cdots,b_{n/2}\}=\{\pi(2),\pi(4),\cdots,\pi(n)\}$ , the image of $P$ is a rotation of angle $2\left(\sum \arctan(a_k)-\sum \arctan(b_k)\right)$ . This needs to be divisible by $2\pi$ . With $\arctan(t)=-\arctan(-t)$ and some basic facts about complex numbers, this is equivalent to requiring $\prod (1+a_ki)\prod (1-b_ki)\in\mathbb{R}$ . From here, there are two main paths that I tried. The first is using that $z\in\mathbb{R}\iff z=\overline{z}$ . This doesn't get far. The second is trying to find the imaginary part and setting equal to $0$ . I couldn't finish this approach off either. I wrote a C++ program and found that this is impossible for $n=4,6,8,10,12,14$ . Any ideas?","['contest-math', 'reflection', 'linear-algebra', 'rotations']"
4647307,"Among the curves whose all tangents pass through the origin, find the one that passes through point $(a,b)$.","Among the curves whose all tangents pass through the origin, find the one that passes through point $(a,b)$ . Here is my solution but my answer seems incorrect. Let $f(x)$ be the function of the curve.
At $(t, f(t))$ , the function $y=f(x)$ has a tangent line $y=f'(t)(x-t)+f(t)$ . Since the tangent line passes through the origin, we get $0=f'(t)(-t)+f(t)$ $tf'(t)=f(t)$ , which can be written as the differential equation $xy'=y$ . After solving the differential equation, I got the family of curve $y = Cx$ , which is are composed of straight lines passing through the origin. I am stuck here and don't know what the next step should be.
Please feel free to share your thoughts. Thank you in advance.","['differential', 'calculus', 'ordinary-differential-equations']"
4647346,How many methods are there to evaluate $\int_0^{\infty} \frac{1}{\left(x+\frac{1}{x}\right)^{2n}}$?,"Background As I had found the integral $$I=\int_0^{\infty} \frac{1}{\left(x+\frac{1}{x}\right)^2} d x =\frac{\pi}{4}, $$ by using $x\mapsto \frac{1}{x}$ yields $\displaystyle I=\int_0^{\infty} \frac{\frac{1}{x^2}}{\left(\frac{1}{x}+x\right)^2} d x\tag*{} $ Averaging them gives the exact value of the integral $\displaystyle \begin{aligned}I & =\frac{1}{2} \int_0^{\infty} \frac{1+\frac{1}{x^2}}{\left(x+\frac{1}{x}\right)^2} d x \\& =\frac{1}{2} \int_0^{\infty} \frac{d\left(x-\frac{1}{x}\right)}{\left(x-\frac{1}{x}\right)^2+4} d x \\& =\frac{1}{4}\left[\tan ^{-1}\left(\frac{x-\frac{1}{x}}{2}\right)\right]_0^{\infty} \\& =\frac{1}{4}\left[\frac{\pi}{2}-\left(-\frac{\pi}{2}\right)\right] \\& =\frac{\pi}{4}\end{aligned}\tag*{} $ I guess that we can similarly evaluate the general integral $$
I_n=\int_0^{\infty} \frac{d x}{\left(x+\frac{1}{x}\right)^{2 n}}
$$ by mapping $x\mapsto \frac{1}{x}$ and then averaging. $$
I_n=\frac{1}{2} \int_0^{\infty} \frac{1+\frac{1}{x^2}}{\left(x+\frac{1}{x}\right)^{2 n}} d x=\frac{1}{2} \int_0^{\infty} \frac{d\left(x-\frac{1}{x}\right)}{\left[\left(x-\frac{1}{x}\right)^2+4\right]^n}
$$ Letting $x-\frac{1}{x}=\tan \theta$ yields $$
\begin{aligned}
I_n & =\frac{1}{2} \int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \frac{2 \sec ^2 \theta d \theta}{4^n \sec ^{2 n} \theta} =\frac{1}{4^n} \int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \cos ^{2 n-2} \theta d \theta= \boxed{\frac{\pi(2 n-3) ! !}{4^n(2 n-2) ! !}}
\end{aligned}
$$ where the last answer comes from the Wallis cosine formula . My question: How many methods are there to evaluate $\int_0^{\infty} \frac{1}{\left(x+\frac{1}{x}\right)^{2n}}$ ?","['integration', 'improper-integrals', 'calculus', 'definite-integrals']"
4647436,Relation between factorial and number of combinations,"Suppose you have a list of distinct natural or integer numbers $$\mathcal{L}=\{1,3,2,5,\dots\},$$ with length $N$ . Is there a formal proof of following relation? $$ N = \biggl\lceil \sqrt{\frac{N!}{(N-2)!}}\biggr\rceil = \bigl\lceil \sqrt{2\cdot\#}\bigr\rceil $$ Here $\#$ is the number of unique pairwise (different) combinations of the list $\mathcal{L}$ (= length of list $\mathcal{P}$ ), $\mathcal{P}$ is the list of unique pairwise (different) combinations of list $\mathcal{L}$ , $\lceil \bullet \rceil$ is the ceil function (Gauss bracket). Example 1 : $$\mathcal{L}=\{2,5,7\},$$ $$\mathcal{P}=\left\{ \begin{matrix}
     \{2  ,   5\}\\
     \{2  ,   7\}\\
     \{5  ,   7\}\\
\end{matrix} \right\},$$ $$ N=3, \quad \# = 3, $$ $$ 3 = \biggl\lceil \sqrt{\frac{3!}{(3-2)!}}\biggr\rceil = \bigl\lceil \sqrt{2\cdot3}\bigr\rceil $$ Example 2 : $$\mathcal{L}=\{1,2,3,4,5\},$$ $$\mathcal{P}=\left\{ \begin{matrix}
     \{1  ,   2\}\\
     \{1  ,   3\}\\
     \{1  ,   4\}\\
     \{1  ,   5\}\\
     \{2  ,   3\}\\
     \{2  ,   4\}\\
     \{2  ,   5\}\\
     \{3  ,   4\}\\
     \{3  ,   5\}\\
     \{4  ,   5\}\end{matrix} \right\},$$ $$ N=5, \quad \# = 10, $$ $$ 5 = \biggl\lceil \sqrt{\frac{5!}{(5-2)!}}\biggr\rceil = \bigl\lceil \sqrt{2\cdot10}\bigr\rceil $$ Thanks in advance.","['factorial', 'discrete-mathematics']"
4647444,Equivalent statements not giving equivalent negations,"Consider the statement $\forall \epsilon >0 \exists y\ldots.$ Negating it gives $\exists \epsilon>0 \forall y\ldots.$ I understand this. $\forall \epsilon:\epsilon>0 \exists y\ldots.$ is equivalent to the first statement, but negating it gives $\exists\epsilon:\epsilon\leq 0 \forall y\ldots.$ What is my error? It makes sense why first one is right, so the first statement has to be different from last statement, but why is it different isn't $\epsilon>0=\epsilon:\epsilon>0 ?$ Any answer or reference to a website is appreciated.","['quantifiers', 'predicate-logic', 'logic', 'analysis']"
4647482,Combinatorics: Amount of options for majority,"Say we have $2n$ people. Then the amount of options to form a majority (e.g. in a commission) are $ \binom{2n}{n+1} + \binom{2n}{n+2} + \cdots + \binom{2n}{2n}$ I want to prove, that this is equal to $\frac{1}{2} \left[ 2^{2n} - \binom{2n}{n} \right]$ But I'm stuck. I have the this formula: $ \binom{n}{0} + \binom{n}{1} + \cdots + \binom{n}{n} = 2^n $ So I can say $ \binom{2n}{n+1} + \binom{2n}{n+2} + \cdots + \binom{2n}{n} = 2^{2n} - \left[ \binom{2n}{n} + \binom{2n}{n-1} + \cdots + \binom{2n}{n-n} \right] = 2^{2n} - \left[ \binom{2n}{0} + \binom{2n}{1} + \cdots + \binom{2n}{n} \right] $ But I can't see where to go from there, even when writing the binomial coefficients as $ \frac{n!}{k!(n-k)!} $ Can anyone help me with it?",['combinatorics']
4647499,Simple harmonic oscillator position function,"We know from Hooke's law $$F=-kx $$ and $$ md^2x/dt^2 = -kx$$ therefore $$x''+w^2x=0$$ we must get $$x(t) =A\cos(wt)$$ but I don't know how I  know how to derive the position function from graph, but i don't know how to solve it as linear differential equation. May someone do that?","['oscillatory-integral', 'harmonic-functions', 'ordinary-differential-equations']"
4647527,Are $x_1=t\cos(t)$ and $x_2=t\sin(t)$ are solutions to the ODE $x''=q(t)x$?,"I have an ODE of the form $x''=q(t)x$ and need to determine if there exists any continuous $q(t)$ so that $x_1=t\cos(t)$ and $x_2=t\sin(t)$ are linear independednt solutions of this ODE in $(-\pi,\pi)$ . My attempt : I calculated $x_1''(t) = -2\sin(t) - t\cos(t)$ and $x_2''(t) = 2\cos(t) - t\sin(t)$ , so once $q(t) = \frac{-2\sin(t) - t\cos(t)}{t\cos(t)}$ and in the second case $q(t) = \frac{2\cos(t) - t\sin(t)}{t\sin(t)}$ . I don't see how this two can be the same, so my answer would be no. I wanted to check with you if that's correct. Also what got me confused is that i read that linear combinations of solutions of ODE-s are also solutions, and I have proved that $x_1=\cos(t)$ and $x_2=\sin(t)$ are actually solutions of our ODE, so I don't know if that implies anything for our new possible solutions now. Would be glad for some help.","['trigonometry', 'solution-verification', 'ordinary-differential-equations']"
4647564,Statistics and distributions,"How do you know if a distribution fits the data you are analyzing?
For example, if I had data that based on my assumption can be distributed geometrically, how can I check that this distribution fits my data and how can I be sure that any model of this type will fit my data?","['statistics', 'probability-distributions']"
4647567,algebraic structure of modular multiplication,"Consider the set ${\mathbb Z}_N = \{0, \ldots, N-1\}$ under multiplication modulo $N$ . When $N=pq$ with $p, q$ relatively prime, ${\mathbb Z}_N$ and ${\mathbb Z}_p \times {\mathbb Z}_q$ are isomorphic as monoids. Is there some similarly ''nice'' characterization of the monoid ${\mathbb Z}_{p^k}$ ? (I am aware of such a characterization for the group of invertible elements modulo $p^k$ , but I specifically looking for the monoid including the non-invertible elements.)","['monoid', 'abstract-algebra', 'modular-arithmetic']"
4647569,Does the mean ratio of the bases of the largest prime factor exponents converge?,"Let $n = p_1^{a_1} p_2^{a_2} \cdots p_k^{a_k}$ and $H_n = \max(a_1, a_2, \ldots, a_k)$ be the largest exponent in the prime factorization of $n$ . It is possible that two or more prime factors can both be the bases of the largest exponent $H_n$ . Let $b_n$ and $B_n$ be the smallest and the largest prime factor of $n$ respectively for which the exponent is $H_n$ . Clearly, if there is only one distinct prime which have the largest exponent then $b_n = B_n$ otherwise $b_n < B_n$ . Example : If $n = 2^3 5^2$ then $b_n = B_n = 2$ and if $n = 2^2 3^2 5$ then $b_n = 2$ while $B_n = 3$ . Experimental data shows that the mean value of the ratios $\frac{b_n}{B_n}$ converges to some value close to $0.36$ . Conjecture : There is a constant $c \approx 0.36$ such that, $$ \lim_{n \to \infty} \frac{1}{n}\sum_{k = 1}^n \frac{b_k}{B_k} = c $$ Can this be proved or disproved?","['divisibility', 'elementary-number-theory', 'number-theory', 'limits', 'prime-numbers']"
4647570,Using Integration by Parts to find leading order approximation of exponential integral,"I'm trying to understand how finding leading order approximation of exponential integrals. Here is my integral: $$\int^{+\infty}_0 e^{-xt}\ln(1+t^2)dt$$ I need to use Integration by parts to then find the leading order asymptotic approximation and using the remainder in integral form, showing that the approximation is in fact asymptotic. (EDIT) This is what I have tried: Integration by Parts gives: $$[\frac{e^{-xt}\ln(1+t^2)}{-x}]^{+\infty}_0 + x^{-1}\int^{+\infty}_0e^{-xt}\frac{2t}{1+t^2}dt$$ The boundary term vanishes and the Remainder is the second term. Then I show that the Remainder is Asymptotic: $$|R(x)| \leq x^{-1}\int^{+\infty}_0|e^{-xt}||\frac{2t}{1+t^2}|dt \leq x^{-1}[\ln(1+t^2)]^{+\infty}_0$$ But I find a divergence. Any ideas? Many thanks!","['integration', 'laplace-method', 'approximation', 'asymptotics']"
4647595,"Rewriting $||x-y|-z|$, for non-negative $x$, $y$, $z$, in a way that does not involve nested absolutes","Is there an idea that resolves nested value expressions into several separate expressions each using a single absolute value? Something similar like resolving the max function using the absolute value. More concretely, I am looking for a way to rewrite the expression $$||x-y|-z|$$ in a way that does not use expressions of nested absolutes. I already did a case study, and this is what I've got so far For $x<y$ and $(y-x) < z$ , we have: $||x-y|-z| = x - y + z$ For $x<y$ and $(y-x) > z$ , we have: $||x-y|-z| = -x + y - z$ For $x>y$ and $(x-y) < z$ , we have: $||x-y|-z| = -x + y + z$ For $x>y$ and $(x-y) > z$ , we have: $||x-y|-z| = x - y - z$ But I can't seem to find a pattern to rewrite it. If it helps, we can assume that all variables $x$ , $y$ and $z$ are non-negative.","['absolute-value', 'nonnegative-matrices', 'functions', 'algebraic-equations', 'algebra-precalculus']"
4647621,How do group symmetries work exactly?,"Currently in my discrete mathematics course at the university I study at, we are on the topic of permutations and groups. We have learned that a group $G$ can be expressed in terms of a set of generators $S$ like this $G=\langle S\rangle$ such that all elements can be expressed using elements of $S$ and the operation under which $G$ is closed. However, in some examples in our lecture notes and in certain assignments, geometric groups containing a square with vertices $1,2,3,4$ are defined using $\langle (2\text{ }4),(1\text{ }2 \text{ }3 \text{ }4)\rangle$ . I understand that $(2\text{ }4)$ is used to signify reflections, but why the identity permutation is used for signifying rotations is a mystery to me. According to the book, every $90^\circ$ rotation could then be written as $(1\text{ }2\text{ }3\text{ }4)^n$ which seems wrong considering how the identity permutation works. I have looked on the internet for answers but for some reason wikipedia has the exact same definition of a square by its symmetries and I couldn't find anything remotely relevant elsewhere (aside from some article to which I had no access). Is there something I am missing? Wouldn't it make more sense to use the permutation $(4 \text{ }1\text{ }2\text{ }3)$ instead as that alludes to an actual rotation? Edit: first of all, thanks for all the answers so quickly! Secondly, for this course we learned that the single-line notation of permutations was always the same as the double-lined matrix notation except for the first line just being absent such that $$\left(\begin{matrix} 1 & 2 & 3 & 4 \\ \sigma(1) & \sigma(2) & \sigma(3) & \sigma(4)\end{matrix}\right)= (\sigma(1)\text{ }\sigma(2)\text{ }\sigma(3)\text{ }\sigma(4))$$ which probably led to all the confusion as all other examples in lecture notes either used the above added identity, the disjoint cycle notation or the transposition notation. Second edit: after the question brought up by @LeeMosher about the non-standard notation, I took another look into the notation section in our lecture notes and apparently I confused normal brackets with square brackets in the one-lined notation (where one-lined notation is $[\sigma(1)...\sigma(n)]$ ). My apologies for this brain fart.","['permutation-cycles', 'discrete-mathematics', 'geometric-group-theory', 'group-theory', 'symmetry']"
4647623,Is it possible to express $\int\frac{dx}{e^x-x}$ in terms of special functions?,"In a differential equation I am solving, the final result had an integral of $$\int\frac{dx}{e^x-x}.$$ This is non-elementary, and I was wondering if I could get rid of the integral by using some special functions. Is there any hope in doing this? It seems that Wolfram Alpha isn't able to do it.","['integration', 'indefinite-integrals', 'special-functions']"
4647658,Proving $\sin\frac{\pi}{13}+\sin\frac{3\pi}{13}+\sin\frac{4\pi}{13}=\frac12\sqrt{\frac{13+3\sqrt{13}}2}$,"Prove that $$\sin\left(\frac{\pi}{13}\right)+\sin\left(\frac{3\pi}{13}\right)+\sin\left(\frac{4\pi}{13}\right)=\frac{1}{2}\sqrt{\frac{13+3\sqrt{13}}{2}}$$ My Attempt Let $$x = \frac{1}{2}\sqrt{\frac{13+3\sqrt{13}}{2}} \implies 16x^4-52x^2+13=0$$ And through some donkey work we can calculate the chebyshev polynomial for $\sin\left(\frac{\pi}{13}\right),\sin\left(\frac{3\pi}{13}\right),\sin\left(\frac{4\pi}{13}\right)$ which will all be the same as $\sin(n\pi)=0,\text{ for all } n \in \mathbb{I}  $ , so $$P(x) = 4096x^{12}-13312x^{10}+16640x^8-9984x^6+2912x^4-364x^2+13$$ where $x = \sin\left(\frac{2i\pi}{13}\right), \text{ from } 1 \le i \le 12 \text{ where } i \in \mathbb{I}$ , are the roots of $P(x)$ . Now I am not getting how to connect these two into a possible solution and even it is possible (probably is), its still a pretty donkey method as you need to find the $13^{th}$ chebyshev polynomial, so if possible maybe give some another method of approach to this question.","['geometry', 'calculus', 'trigonometry', 'algebra-precalculus', 'complex-numbers']"
4647664,Transitive relation of non function,"I have a doubt trying to determine wether a relation is transitive or not. Given this sets A={1,2,3,4} and B={1,2,3,4} and relation AxB = {(1,1),(3,4),(2,2),(3,3)} we can determine that is transitive given the next definition: if (a,b) in R, and (b,c) in R there must be (a,c) to be transitive. We take (3,3) as (a,b), then we take (3,4) as (b,c) so (3,4) is (a,c), which is already in the set, therefore this is a transitive relation.","['relations', 'discrete-mathematics']"
4647688,Prove that the following set is uncountable,"Good evening to everybody. Today I was trying to find a solution to the following exercise:
Let $$  A_\epsilon= \bigcup_{n=1}^{\infty} ( q_n-\frac{\epsilon}{2^n} , q_n + \frac{\epsilon}{2^n} ) $$ where $ q_n$ are the rational numbers of $ [0,1]$ . Let $$A=\bigcap_{j=1}^{\infty} A_{1/j} $$ The question was to prove that : i) $   \lambda(A_{\epsilon}) \leq 2\epsilon $ ii)  For all $\epsilon < \frac{1}{2}$ , it holds that $[0,1]\backslash A_\epsilon $ is non-empty and $A $ is a subset of $ [0,1]$ iii) it holds $ \lambda(A)=0$ iv) $ \mathbb{Q}\cap[0,1] \subset A $ and that the set $ A $ is uncountable. Ok, I have already proved quite easily the first 3 parts and the first relation of part iv) but I am stuck on the proof of the  uncountability of this set. From what I have already thought, we can identify the rational number $q_1$ with the sequence $ 1, 1 , ... $ (meaning that $q_1$ belongs to the first set of the union in $A_1$ , to the first set of the union in $A_\frac{1}{2}$ etc..) and the rational number $q_2$ with the sequence $ 2, 2 , ... $ (meaning that $q_2$ belongs to the second set of the union in $A_1$ , to the second set of the union in $A_\frac{1}{2}$ etc..),so we can exclude all the rationals in the set $ A $ and, if we show that the set $ A $ contains also some irrational , let say it $ X $ , then we can pick the first integer $N_1 $ to be the natural number ( here $N_1\geq 0 $ )  such that $ X $ belongs to the first set of the union of $A_1 , A_\frac{1}{2} , A_\frac{1}{3},..., A_\frac{1}{N_1-1}$ but NOT in $A_\frac{1}{N_1}$ , then the integer $N_2$ to be the natural number (here we need also $N_2\geq0$ ) such that $ X $ belongs to the second set of the union of $A_1 , A_\frac{1}{2} , A_\frac{1}{3},..., A_\frac{1}{N_2-1}$ but NOT in $A_\frac{1}{N_2}$ , etc..., and thus identify each non rational number of $ A $ by the sequence $ N_1 , N_2 , ...$ . Then assuming that $A$ is countable , say $ \phi_1 , \phi_2 , ...$ we can use the diagonal argument and take the element $ ( \phi_1(1)+1, \phi_2(2)+1 , \phi_3(3)+1 , ... ) $ . . This element is in $ A $ but it is not any of the sequences $ \phi_1 , \phi_2 , ... $ So I only need to prove that $ A $ does not contain ONLY the rationals $q_1 , q_2 ... $ Any ideas would be really helpful.","['measure-theory', 'lebesgue-measure']"
4647705,Logarithm and absolute value,"$$y' - y \tan x = 2x \sec x,\quad y(0)=0\tag1$$ integrating factor $= e^{-\int \tan x\ dx} = e^{\ln|\cos x|} = \cos x$ Can we write $|\cos x|$ as $\cos x$ above? $$I.F. y = \int I.F.\ 2x\ \sec x\ dx\\(\cos x) y = \int \cos x \ 2x\ \sec x\ dx = \int 2x\ dx$$ If we had taken the integrating factor to be $ |\cos x|$ , then in the above line $|\cos x|$ and $\sec x$ wouldn't have cancelled.","['calculus', 'absolute-value', 'ordinary-differential-equations']"
4647745,Is $\csc x = a+bi$ defined? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question A question in my assignment asks to find which equation can have its roots $\sec^2 x, \csc^2 x$ (no restrictions in $x$ were given). The equations were quadratic ( $x^2+bx+c$ ) and the one which satisfies $-b=c$ can be the required equations. There were two which satisfies this, $x^2-3x+3=0, x^2-9x+9=0$ The second one is absolutely correct but the first in the first one $\csc^2x$ is in the form of $a+bi$ . And so first one wasn't the correct answer. But I am having doubt in the answer, as by Euler's formula , $$\sin x=\frac{e^{ix}-e^{-ix}}{2i}$$ And here putting a suitable complex value of $x$ , $\sin x$ can have a value in form of $a+bi$ and so $\csc^2 x$ . So, am I correct? Can we put a complex value in trigonometric functions or can they have a complex value? And also tell what if $\sin x=2$ ?","['trigonometry', 'systems-of-equations', 'complex-numbers']"
4647765,$\lim_{\kappa \to \infty} \frac{R(\kappa)}{\kappa^2}=\frac{12}{\pi^2}$,"[ Rational Points on Elliptic Curves - Joseph H. Silverman, ex 3.1] Given a rational number $x=\frac mn$ in its lowest terms, define $$H(x):=\max\left\{|m|,|n|\right\}.$$ Let $R(\kappa)$ be the number of rational numbers $x$ with $H(x)$ less than $\kappa$ . First prove that $R(\kappa)\le 2\kappa^2+\kappa$ and then show that $$\lim_{\kappa \to \infty} \frac{R(\kappa)}{\kappa^2}=\frac{12}{\pi^2}$$ The first part is quite easy since the number of choices for the numerator is clearly bounded by $2\kappa+1$ and the denominator is bounded by $\kappa$ . But, I have no idea how to proceed with the second part.","['limits', 'pi', 'rational-numbers']"
4647767,Help in solving the differential equation $\frac{dy}{dx} = \frac{y(a-x)}{x(x^2y^2 - b)}$,"I am trying to find the solutions to the following differential equation $$\frac{dy}{dx} = \frac{y(a-x)}{x(x^2y^2 - b)}\quad\quad(1)$$ where $a,b\in\mathbb{R}$ . To be honest I haven't made any progress. I will, however, mention what I have tried. First of all I tried partial fraction decomposition (after supposing that $b\geq0$ ) to see if I can convert $(1)$ to a known form but didn't end up anywhere (besides, I don't really have much experience with differential equations and don't know a lot of techiques/theorems so it might be the case I missed something). I also tried to play around with $(1)$ like I demonstrate \begin{align}
(1) \implies \frac{y'}{y}=\frac{a-x}{x^3y^2-xb}&\implies x^3yy'-bx\frac{y'}{y} = a -x \\
&\iff \frac{1}{2}x^3\left(y^2\right)' - \frac{b}{2}x\left(\ln y^2\right)' = a - x \\
&\iff \frac{1}{2}x^3\left(e^w\right)' - \frac{b}{2}x\left(w\right)' = a - x,\quad w=\ln y^2
\end{align} The last expression seems more solvable, but perhaps it doesn't really help that much.
I had a few other ideas as well but they are all based around writing $(1)$ differently in hopes something comes up. Any solutions/hints would be appreciated. Keep in mind that I am not sure if $(1)$ actually has solutions, but I would obviously want to know if that's th case.",['ordinary-differential-equations']
4647802,How to convert angles to a common orientation,"I'm comparing the orientation of straight lines. I need to handle the case where the lines have the same orientation but one is drawn in the opposite direction of the other, so for example the first line's orientation is 0 and the second line's orientation is 180. Is there an elegant way to convert angles to a common orientation in this fashion? if angle >= 180:
    then angle - 180
else:
    angle seems like it should be sufficient I'm concerned I'm not thinking it through all the way and missing a case where it won't work though.",['trigonometry']
4647811,How can I approach this number theory logic puzzle more formally?,"I have a number theory question that I think I'm supposed to apply the pigeonhole principle to. I've figured out the correct answer just with logic, but I feel like there is a more formal way to do it that I can actually show my work for. Ten inhabitants of an island populated by knights, who never lie, and knaves, who always lie, were given ten different numbers between 1 and 10. When asked ""Is your number divisible by 2?"" 3 people said yes When asked ""Is your number divisible by 4?"" 6 people replied yes When asked ""Is your number divisible by 5?"" 2 people replied yes How many of the ten are knaves and which numbers were given to them? EDIT: My solution: The incorrect numbers of people with the numbers in statements 1 and 2 imply that there are some amount of knaves. Looking at statement 3, the only way 2 people replied yes is if there are no knaves, 2 knaves, or 4 knaves. Statment 2 implies that there must be, at fewest, 4 knaves (as if the knights had both 4 and 8). Therefore, there are 4 knaves total. Statement 2 shows us that, because there are 4 knaves, they must not have 4 and 8 and we know two knaves have 5 and 10 from statement 3. This means that, for statement 1 to be true, the other two knaves must have even numbers, 2 and 6 in this case. Therefore, we know that there are 4 knaves with 2, 5, 6, and 10 and 6 knights with 1, 3, 4, 7, 8, and 9.","['elementary-number-theory', 'recreational-mathematics', 'logic', 'discrete-mathematics']"
4647844,Topology of the product of projective varieties,"I can't prove that the closed sets of a product of projective varieties is a zero locus of multihomogeneous polynomials. I'm taking the abstract point of view to the construction of product of varieties, i.e., if $X$ , $Y$ are algebraic varieties (ringed spaces locally isomorphic to affine varieties) then we have affine open covers $\{U_i\}, \{V_i\}$ of $X$ and $Y$ respectively, and then we define the topology over $X\times Y$ saying that a subset $C\subset X\times Y$ is closed iff $C\cap(U_i\times V_j)$ is closed in $U_i\times V_j$ for all $i,j$ .
Then, my question is: if I have the product $\mathbb{P} ^n\times\mathbb{P}^m$ with the topology induced in the previous form, how I can prove that closed sets of this product are given by zeroes of bihomogeneous polynomials?
Similarly, how I can prove that closed sets of $\mathbb{P} ^n\times\mathbb{A}^m$ are the zeroes of homogeneous polynomials in the first n variables?","['affine-varieties', 'algebraic-geometry', 'projective-geometry', 'projective-varieties']"
4647892,"Integral from MIT Integration Bee 2023 Finals - $\int_{-1/2}^{1/2} \sqrt{x^2+1+\sqrt{x^4+x^2+1}}\,\textrm{d}x$","This question is from the MIT Integration Bee 2023 Finals, and this is Question 3. This integral was to be solved within four minutes, and the goal is to show that $$\int_{-1/2}^{1/2} \sqrt{x^2+1+\sqrt{x^4+x^2+1}}\ \textrm{d}x = \frac{\sqrt{7}}{2\sqrt{2}} + \frac{3}{4\sqrt{2}} \log\left(\frac{\sqrt{7}+2}{\sqrt{3}}\right)$$ My first attempt was to rewrite the inside of the nested square root as $(x^2+1)^2 - x^2$ , after which I performed the trigonometric substitution $x = \tan(\theta)$ . That made the integral above transform to $$\int_{-\alpha}^{\alpha} \sqrt{\sec^2(\theta)+\sqrt{\sec^4(\theta)-\tan^2(\theta)}}\sec^2(\theta)\ \textrm{d}\theta$$ Here, $\alpha = \tan^{-1}(\frac{1}{2})$ . From here, I attempted to force the inside of the nested square root into some $(a\pm b)^2$ form, but doing so required me to be in $\operatorname{GF}(2)$ . In my assumption, that meant $\sec^4(\theta) - \tan^2(\theta) =(\sec^2(\theta) + \sec(\theta) + 1)^2$ , and the integral would transform to $$\int_{-\alpha}^{\alpha} \sqrt{2\sec^2(\theta) + \sec(\theta) + 1}\sec^2(\theta)\ \textrm{d}\theta $$ I'm pretty sure I made a mistake somewhere, but I don't know where. In the event I haven't, how could I simplify the inside of the nested square root? Or, what are other methods on attacking this question? I don't know complex analysis.","['contest-math', 'calculus', 'definite-integrals']"
4647897,Explicit formula for tournament sequence,"I am looking for an explicit formula for a sequence. The sequence is generated as follows: There is a tournament with $10$ teams. In the beginning, all teams have a 0-0 win-loss record. The teams are paired up, and when the first round concludes, $5$ of the teams have a 0-1 record and $5$ of the teams have a 1-0 record. The second round is arranged so that only teams with the same win-loss record are allowed to face each other, and when there are an odd number of teams having a certain win-loss record, the extra team from one win-loss record plays the extra team from the nearby win-loss record. This means that for the second round, four of the 0-1 teams are paired up with each other, $4$ of the 1-0 teams are paired up with each other, and there is one pairing between a 0-1 team and a 1-0 team. We also assume that when there is a pairing across different win-loss records, the team with the better record always wins. This means that at the end of round 2, there will be $3$ teams with a 0-2 record, there will be $4$ teams with a 1-1 record, and $3$ teams with a 2-0 record. I am looking for an explicit formula giving the win-loss record distribution at round $r$ . I am also looking for a general formula for $T$ teams (I used ""10"" earlier just for illustration purposes). I have python code which explicitly calculates this sequence for $T$ teams and round $r$ , but I would like a mathematical expression for this. I have an explicit formula for the first $4$ rows using ceiling/floor functions, but the formula does not work beyond $4$ rows. I also have an explicit formula giving the win-loss record in the long term, but it only works after about $T^2$ rows. In terms of problem solving techniques that I've tried, I've tried various generating series approaches. For example, for the case of $10$ teams, I wrote round $0$ as $$f_0(x,y) = y^0 + y^1 + y^2 + ... + y^9$$ and round $1$ as $$f_1(x,y) = y^0 + y^1 + y^2 + y^3 + y^ 4 + (y^5 + y^6 + y^7 + y^8 + y^9)x$$ and round $2$ as $$f_2(x,y) = y^0 + y^1 + y^2 + (y^3 + y^4 + y^5 + y^6)x + (y^7 + y^8 + y^9)x^2$$ and so on. I don't have a method for moving from $f_k$ to $f_{k+1}$ , but I have lots of near misses. I have also tried using a probabilistic approach. I have started from several invariants, and I have a function that when minimized gives a (sometimes) close approximation. The invariants are as follows: The number of teams $T$ does not change from round to round. The number of total wins at each round is always $T r / 2$ . The win-loss record is symmetric around $r/2$ . These invariants restrict the number of possible choices for round $r$ . I then took the choice that most nearly matches a binomial distribution (using the euclidean distance as a metric, although any similarity metric could work). This metric isn't best, since I believe the win-loss records become ""less binomial"" over time. Another thing I tried was various kinds of graphing. I can post some graphs if requested. I am open to any approach, I look forward to seeing your ideas. Updates and extra information Here are the first few terms of the sequence for $T=10$ : $$10$$ $$5, 5$$ $$3, 4, 3$$ $$2, 3, 3, 2$$ $$1, 3, 2, 3, 1$$ $$1, 1, 3, 3, 1, 1$$ $$1, 0, 3, 2, 3, 0, 1$$ $$1, 0, 1, 3, 3, 1, 0, 1$$ $$1, 0, 0, 3, 2, 3, 0, 0, 1$$ $$1, 0, 0, 1, 3, 3, 1, 0, 0, 1$$ $$...$$ Another clarification is that the number of teams $T$ must be even. Also, I would like to add the formula for the long-term behavior of the sequences. The long-term behavior shows a 2-term repetition, and this repetition depends on the value of $T \pmod 8$ . Here are the four cases: Case 1. ( $T \equiv 0 \pmod 8$ ): $1444...444...441$ , $3444...4444....443$ Case 2. ( $T \equiv 2 \pmod 8$ ): $3444...424...443$ , $1444...4334....441$ Case 3. ( $T \equiv 4 \pmod 8$ ): $3444...444...443$ , $1444...4444....441$ Case 4. ( $T \equiv 6 \pmod{8}$ ): $1444...424...441$ , $3444...4334....443$ Note that I have left off the preceding $1000...$ and the trailing $...0001$ , since the number of zeros can be easily calculated. Not also that the number of $4$ s can be calculated easily from the original number of teams $T$ . Regarding the generating series idea previously, one thing I found is that if we have for example $$f_2(x,y) = y^0 + y^1 + y^2 + (y^3 + y^4 + y^5 + y^6)x + (y^7 + y^8 + y^9)x^2$$ then we can calculate something very close to $f_3(x,y)$ by performing the following steps: $$\frac{f_2(x,y) + f_2(x,-y)}{2} = y^0 + y^2 + (y^4 + y^6)x + (y^8)x^2$$ $$\frac{f_2(x,y) - f_2(x,-y)}{2} \cdot x = y^1 x + (y^3 + y^5) x^2 + (y^7 + y^9) x^3$$ $$\widetilde{f}_3(x,y) = \frac{f_2(x,y) + f_2(x,-y)}{2} + \frac{f_2(x,y) - f_2(x,-y)}{2} \cdot x = y^0 + y^2 + (y^1 + y^4 + y^6)x + (y^3 + y^5 + y^8)x^2 + (y^7 + y^9)x^3$$ which when evaluated at $y = 1$ gives the correct sequence $2,3,3,2$ . It is not exactly correct, since the $y$ terms are no longer ordered in terms of exponents, so this process is not repeatable unless we improve on it somehow. Another Update Let's add a variant to the original rules. The variant will be called ""underdog"", whereas the original rules will be called ""overdog"". The ""overdog"" rules stipulate that the team with the higher win-loss record will always win when it crosses over and faces a team with a lower win-loss ratio; in contrast, the ""underdog"" rules stipulate that the team with the lower win-loss ratio will win. Let's call the overdog sequence with $T$ teams the sequence $O(T)$ , and each term in the sequence will be identified as $O_{r,w}(T)$ where $r$ denotes the round and $w$ denotes the number of wins at that round. For the underdog variant, we define $U(T)$ and $U_{r,w}(T)$ in the same way. I just discovered the following properties: $$O(2^k + 2) = U(2^k) + O(2)$$ $$O(2^k + 4) = U(2^k) + U(2) + O(2)$$ This is helpful since $U(2^k)$ and $O(2^k)$ are easy to calculate for $k$ rows, and $O(2)$ and $U(2)$ are easily calculated for all rows. I'm wondering if we can use the binary representation of $T$ and some kind of summing procedure to improve the number of rows that we can directly calculate. It would be fascinating to try to reduce $O(T)$ and $U(T)$ to the sum of terms of the form $U(2^K)$ or $O(2^K)$ for any arbitrarily large $K >> 0$ . This would give us a way to calculate arbitrarily many rows for any $T$ . Correction to Previous Update I should edit my previous update to be more precise. The powers of two were a bit of a red herring — all that matters is $T \pmod{4}$ . Here are the updated relations: $O(4k + 2) = U(4k) + O(2)$ . $U(4k + 2) = U(4k) + U(2)$ . $O(4k + 4) = U(4k) + U(2) + O(2)$ . This means that the problem is essentially reduced to finding $U(4k)$ instead of finding $U(2k)$ . Not much of a reduction, but it's progress!","['number-theory', 'combinatorics', 'generating-functions', 'probability', 'integer-sequences']"
4647909,The graph of a continuous function defined on a general open/closed set has measure zero (without Fubini),"I was trying to prove the truth (avoiding Fubini) or falsehood of Q: Let $f:A\to\mathbb{R}^m$ be a continuous function where the domain $A\subseteq\mathbb{R}^k$ is open or closed. Then, is it necessarily the case that the graph $\Gamma(f,A)=\{(x,f(x)):x\in A\}$ has Lebesgue measure $0$ (and, thus, is Lebesgue measurable)? But I failed. The thing is: I know that, on this site, the case where $A$ is a rectangle has been asked many times. But what about this more general case? I know how to prove it when $A$ is a rectangle (i.e. of the form $A=\prod_{j=1}^k [a_j,b_j]$ ) but I am unable to generalize this particular case to the more general case (if it is true). I know that every open/closed set in $\mathbb{R}^n$ is the countable union of compact spaces so it would suffice to prove it on compact spaces which seem helpful since continuity on compact sets implies uniform continuity. However, the rectangle case can't be extended to the compact case since there exist compact sets that aren't the union of countably many rectangles such as the Cantor set . Is there a possible counterexample? I don't think so, but there might be one (?). Also: sorry if this question has already been asked here. I've searched as best as I could and, sadly, found nothing... Note: I don’t think that it’s valid to prove the case where $A=\mathbb{R}^k$ and $f$ is a continuous function (which is pretty trivial) and consider every other case of this problem as a simple restriction that follows directly. That is because not every continuous function $f\in C(A,\mathbb{R}^m)$ is the restriction of a continuous function with $\mathbb{R}^k$ as a domain. For example, $f:\mathbb{R}\setminus\{0\}\to\mathbb{R}$ defined $f(x)=\frac{1}{x}$ is continuous but its domain can’t be extended so that it’s still continuous. Or, even worse, $f:\mathbb{R}\setminus\left(\frac{\pi}{2}+\pi\mathbb{Z}\right)\to\mathbb{R}$ defined as $f(x)=\tan(x)$ can’t be continuously extended either. Any help would be highly appreciated! :)","['measure-theory', 'cantor-set', 'real-analysis', 'continuity', 'multivariable-calculus']"
4647946,"Infinite group has infinitely many subgroups, namely cyclic subgroups.","If $G$ is an infinite group then $G$ has infinitely many subgroups. Proof: Let's consider the following set: $C=\{\left \langle g \right \rangle: g\in G \}$ - collection of all cyclic subgroups in $G$ generated by elements of $G$. Two cases are possible: Exists infinitely many distinct cyclic subgroups $\Rightarrow$ We are done. Exists finitely many distinct cyclic subgroups for example $C=\{H_1, H_2,\dots, H_n\}$. Then $G=\bigcup \limits_{i=1}^{n}H_i$. Since $G$ is infinite then WLOG suppose that $H_1$ is also infinite, where $H_1=\left \langle g_1 \right \rangle$. Let's consider the following set $\{\left \langle g_1^n \right \rangle: n\in \mathbb{N}\}$ - the collection of all cyclic sugroups of $H_1\subset G.$  Let $K_1=\left \langle g_1 \right \rangle$, $K_2=\left \langle g_1^2 \right \rangle$, $K_3=\left \langle g_1^3 \right \rangle$, $\dots$. It's easy to show that $K_n$ and $K_m$ are distinct for $n\neq m$. Indeed, WLOG take $n<m$ and taking $g_1^n\in K_n$ but $g_1^n\notin K_m$ otherwise $g_1^n=g_1^{ml}$ where $l\in \mathbb{Z}$ $\Rightarrow$ $g_1^{n-ml}=e$ and since $H_1$ is infinite $\Rightarrow$ $n=ml$ which is contradiciton since $m>n$. Thus, the subgroups $K_n$ for any $n\in \mathbb{N}$ are cyclic subgroups of $H_1$ $\Rightarrow$ cyclic subgroups of $G$. Is this reasoning correct?","['group-theory', 'abstract-algebra', 'solution-verification', 'infinite-groups']"
4647956,Limit of quotient of integrals,"I was working with the next problem: Let $f:[1,\infty)\to\mathbb{R}$ be an increasing function. Consider $F(x)=\displaystyle\int_{1}^{x}\dfrac{f(t)}{t}\, dt$ . Calculate the limit $$\lim\limits_{x\to 1^{+}} \dfrac{F(x)}{\ln(x)}=\lim\limits_{x\to 1^{+}} \dfrac{\displaystyle\int_{1}^{x}\dfrac{f(t)}{t}\, dt}{\displaystyle\int_{1}^{x}\dfrac{1}{t}\, dt}$$ Clearly, if we evaluate in the limit, we obtain a quotient of the from $\frac{0}{0}$ but L'Hopital's rule can't be used because we don't know if $F(x)$ is derivable. If we take $f(x)=x$ then the limit is equal to $$\lim\limits_{x\to 1^{+}}\dfrac{\displaystyle\int_{1}^{x}\dfrac{1}{t}\, dt}{\ln(x)}=\lim\limits_{x\to 1^{+}}\dfrac{\ln(x)}{\ln(x)}=1$$ If $f(x)=nx$ with $n>0$ , then $$\lim\limits_{x\to 1^{+}} \dfrac{\displaystyle\int_{1}^{x}\dfrac{nt}{t}\, dt}{\ln(x)}=\lim\limits_{x\to 1^{+}}\dfrac{n(x-1)}{\ln(x)}=\lim\limits_{x\to 1^{+}}\dfrac{n}{\frac{1}{x}}=\lim\limits_{x\to 1^{+}}nx=n$$ The last step is by L'Hopital's rule. But $n=f(1)$ . Therefore, we claim that $$\lim\limits_{x\to 1^{+}}\dfrac{F(x)}{\ln(x)}=f(1)$$ How can I prove it? Any hint? Thanks!","['integration', 'limits', 'calculus']"
4648022,Help with integrating $\int \frac{dx}{1+\sqrt{\tan(x)}}$,"Starting off with subbing $u^2 = \tan(x)$ to remove the square root, I got: $$\int \frac{2u}{(1+u)(1+u^4)} du$$ (Deriving that $\sec^2(x) = 1+u^4$ ) Then by applying the partial fractions method, I get: $$\int \frac{-1}{1+u} du + \int \frac{u^3-u^2+u+1}{1+u^4} du$$ The first integral is manageable but for the second one I had to split the individual terms in the numerator into their own fractions to further obtain: $$\int \frac{u^3}{1+u^4}du +\int \frac{u}{1+u^4}du + \int \frac{1-u^2}{1+u^4}du $$ Now, the first two I could solve however it is the last one that I am unable to move forward with; $$ \int \frac{1-u^2}{1+u^4}du $$","['integration', 'calculus']"
4648024,"Prove $\cup_{i=1}^\infty A_i = \mathbb{N}$ where $A_i = 2^{i-1}\{1,3,5,7,...\}$","To show the equality we need to show that i) $\cup_{i=1}^\infty A_i \subseteq \mathbb{N}$ and ii) $\mathbb{N} \subseteq \cup_{i=1}^\infty A_i$ . i) $\cup_{i=1}^\infty A_i \subseteq \mathbb{N}$ :    This is straight forward to prove. ii) $\mathbb{N} \subseteq \cup_{i=1}^\infty A_i$ :
    if $x\in \mathbb{N}$ then $x$ is either odd or even: ii_1) if $x$ is odd then $x \in A_1$ $\rightarrow$ $x \in \cup_{i=1}^\infty A_i$ ii_2) if $x$ is even then $x$ is either a power of 2 or not.: ii_2_1) if x is power of 2 then $\exists j \in \mathbb{N}$ s.t $x =2^j$ and hence $x \in A_{j+1}$ $\rightarrow$ $x \in \cup_{i=1}^\infty A_i$ ii_2_2) if x is not a power of 2 then $\exists l \in \mathbb{N}, k \in A_1$ s.t $x =2^lk$ and hence $x \in A_{l+1}$ $\rightarrow$ $x \in \cup_{i=1}^\infty A_i$ Hence, given ii_1, ii_2_1, and ii_2_2, $\mathbb{N} \subseteq \cup_{i=1}^\infty A_i$ . I have the following questions: This proof looks like a nested if statements in programming. Is this a correct proof technique? and if it is does it have a name? Is there an alternative proof for this problem?","['proof-writing', 'logic', 'alternative-proof', 'solution-verification', 'elementary-set-theory']"
4648026,Is there a method for determining if a graph (undirected) is connected?,"The textbook used in our class defines a connected (undirected) graph if for any two vertices $v,w\in G$ there is a path from $v$ to $w$ . The examples used in the textbook show a visualization of a graph and say ""observe that G is connected"" or ""notice that G is connected"". Is there a method to determine if a graph is connected solely by looking at the set of edges and vertices (without relying on inspection of a visualization)?","['graph-theory', 'discrete-mathematics', 'eulerian-path']"
4648030,Conditional probability with unequal probabilities,"My question is based the scenario in Non-Uniform Probability Without Replacement . Suppose we have probabilities of four letters $$P(A) = 0.1 \quad P(B) = 0.2 \quad P(C) = 0.3 \quad P(D) = 0.4$$ If I were to draw two letters without replacement, and the first letter is A, what is the probability that I will get B on the second draw? That is, what is $P(B | A)$ ? I guess that $P(B | A) = P(B)/(1 - P(A)) = 0.2/0.9$ . But why is that so? Where does the formula come from? Can it be derived from simple conditional probability formula? note: I also tried to simulate this problem, and the relative frequency does approach $0.2/0.9.$ But I still confused where the formula comes from.","['conditional-probability', 'statistics', 'combinatorics', 'probability']"
4648043,Draw a triangle in the region bounded by a polynomial curve and a straight line. What is the supremum of the ratio of their areas?,"Draw a triangle in the region bounded by a polynomial curve and a straight line. What is the supremum of the ratio of the triangle's area to the region's area? Context I was thinking about the quadrature of the parabola . If we draw a triangle in the region bounded by a parabola and straight line, the maximum ratio of the area of the triangle to the area of the region, is $3/4$ . Then I wondered, if we can replace the parabola with any polynomial curve, what is the maximum or supremum of the ratio? My attempt I assume that one side of the triangle of largest area, is coincident with the straight line that bounds the region. We can assume that the supremum of the ratio can be attained when the straight line is $y=0$ , because if the supremum is attained with polynomial $y=f(x)$ and line $y=mx+c$ , then we can draw a new polynomial $y=f(x)-(mx+c)$ and line $y=0$ , and the ratio will be the same as before. I conjecture that when the supremum is attained or approached, in the region of interest bounded by the curve and line, the leftmost (or rightmost) point is a stationary point of the curve. If this were not true, then it seems like the ratio of areas could be increased by vertically translating the  horizontal line (such that the area of the region increases), which would be a contradiction. I experimented with various polynomials, and so far, the maximum ratio that I've found is approximately $0.8405$ , using the region bounded by $y=-x^2\left(x+\frac23\right)^2(x-1)$ and $y=0$ from $x=0$ to $x=1$ . Increasing the degree of the polynomial does not seem to allow for a larger ratio, but I could be wrong. (If the polynomial is a cubic, I believe the maximum ratio is exactly $\frac{200}{243}\approx 0.8230$ .)","['area', 'geometry', 'triangles', 'polynomials', 'supremum-and-infimum']"
4648044,Explain the expectation of white balls when randomly pick 5 balls in a box with 3 white balls and 6 red balls.,"Let $X$ denote the number of white balls, and $X=0,1,2,3$ , so we can calculate $E(X)$ : By definition, we can find that $E(X)= \frac53$ But it also equal to $5 \cdot \frac39$ . I wonder how to explain the $5 \cdot \frac39$ , because it looks like that 3 red balls dissolve in 9 balls uniformly, and every time we choose ""one"" ball, we will get $\frac39$ white ball, after 5 times we will get $5 \cdot \frac39$ white balls. Is it an accidient or it make sense?","['balls-in-bins', 'probability-theory', 'probability']"
4648077,Blowup of points in the plane and linear systems,"Let $p_1,\dots,p_r\in \mathbb P^2$ be points in general position, $r\leq 6$ . Let $S$ be the blowup of these $r$ points, then the anticanonical divisor $K_S$ is very ample and it gives an embedding, in particular since $K_{\mathbb P^2}=\mathcal O(-3)$ and each point has an exceptional divisor $E_i$ , we have that this embedding can be interpreted as the embedding in $\mathbb P^{9-r}$ by the linear system of cubics passing through $p_1,\dots,p_r$ . This case is well explained in Beauville or Hartshorne books. This is a del Pezzo variety in the classical sense (very ample anticanonical divisor). However, in modern texts, people started to allow the anticanonical divisor to be only ample, meaning a multiple of it gives the embedding. This includes $r=7,8$ as del Pezzo varieties. My question is, in such cases can we still understand the embedding as a linear system of cubics? I am sure for $r=8$ this cannot happen because of dimension counting. Is this embedding then a linear system of quartics or some other power?","['divisors-algebraic-geometry', 'algebraic-geometry']"
4648079,"Determining whether $\sigma(q^k)/2$ is squarefree, where $q^k n^2$ is an odd perfect number with special prime $q$","Preamble: The present inquiry is an offshoot of What are the remaining cases to consider for this problem, specifically all the possible premises for $i(q)$? . MOTIVATION Denote the classical sum of divisors of the positive integer $x$ by $\sigma(x)=\sigma_1(x)$ . (Note that the divisor sum $\sigma$ is a multiplicative function .) A number $P$ is said to be perfect if $\sigma(P)=2P$ .  If a perfect number $N$ is odd , then $N$ is called an odd perfect number .  Euler proved that a hypothetical odd perfect number $N$ must have the form $$N = q^k n^2$$ where $q$ is the special prime satisfying $q \equiv k \equiv 1 \pmod 4$ and $\gcd(q,n)=1$ . It is known that $$i(q)=\gcd(n^2,\sigma(n^2))=\frac{n^2}{\sigma(q^k)/2}=\frac{\sigma(n^2)}{q^k},$$ where $i(q)=\sigma(N/{q^k})/{q^k}$ is the index of $N$ at the (special) prime $q$ , as initially defined by Broughan, Delbourgo, and Zhou , and whose results were eventually improved upon by Chen and Chen . In a recent preprint , Dris proves that the following implication holds: $$i(q) \text{ is squarefree } \implies \frac{\sigma(q^k)}{2} \text{ is not squarefree.} \tag{1}$$ We likewise obtain the biconditional $$i(q) \text{ is a square } \iff \frac{\sigma(q^k)}{2} \text{ is a square.}$$ This implies that we have the chain of implications $$i(q) \text{ is a square } \implies \frac{\sigma(q^k)}{2} \text{ is a square } \implies \frac{\sigma(q^k)}{2} \text{ is not squarefree.} \tag{2}$$ This MSE answer proves the following Conjecture: If $q^k n^2$ is an odd perfect number with special prime $q$ and $q = k$ , then $\sigma(q^k)/2$ is not squarefree . These findings highly suggest that $\sigma(q^k)/2$ is not squarefree . My question is as follows: Do you see a way of proving that $\sigma(q^k)/2$ is not squarefree ? MY ATTEMPT Suppose to the contrary that $\sigma(q^k)/2$ is squarefree.  Since $$i(q) = \frac{n^2}{\sigma(q^k)/2}$$ and $i(q)$ is an (odd) integer, then $\sigma(q^k)/2 \mid n^2$ .  Now, the assumption that $\sigma(q^k)/2$ is squarefree would imply that $\sigma(q^k)/2 \mid n$ . But we can rewrite $$\frac{n^2}{\sigma(q^k)/2}=\frac{\sigma(n^2)}{q^k}$$ as $$\frac{\sigma(n^2)}{n}=\frac{q^k n}{\sigma(q^k)/2}$$ which means that $\sigma(q^k)/2 \mid n$ is equivalent to $n \mid \sigma(n^2)$ , since $q^k$ and $\sigma(q^k)/2$ are coprime. Now, let $$G = \gcd(\sigma(q^k),\sigma(n^2)) = \sigma(q^k)/2$$ $$H = i(q) = \gcd(n^2,\sigma(n^2)) = \frac{n^2}{\sigma(q^k)/2}$$ $$I = \gcd(n,\sigma(n^2)) = n$$ $$J = \frac{n}{\gcd(\sigma(q^k)/2,n)} = \frac{n}{\sigma(q^k)/2}$$ Since $$H = G \times J^2$$ and because of the following (which hold under the assumption that $G=\sigma(q^k)/2$ is squarefree): (1) $J = 1$ if and only if $H$ is squarefree.  (Note that, under the assumption that $\sigma(q^k)/2$ is squarefree, we get that $H$ is not squarefree.  Therefore, $\sigma(q^k)/2$ is squarefree implies that $J > 1$ .) (2) $G = 1$ if and only if $H$ is a square.  (Note that $G = \sigma(q^k)/2 \geq \frac{q^k + 1}{2} \geq 3$ , so that $H$ is not a square , if $G = \sigma(q^k)/2$ is squarefree.  This confirms the findings in this MO answer to a closely related question.) (3) The remaining case is when $G>1$ and $J>1$ . But $G$ is squarefree, together with the following identity $$G \times H = I^2$$ implies that $$G \mid I.$$ Throughout this paper , we implicitly rely on the simple equality $$\sigma(n^2) = \frac{2q^k n^2}{\sigma(q^k)}. \tag{3}$$ Unfortunately, this seems to introduce fractions.  To avoid that, we can use prime factorizations, as follows.  Write the prime factorization of $n$ as $$n = {p_1}^{a_1} \cdots {p_m}^{a_m},$$ for some unique odd primes $3 \leq p_1 < \ldots < p_m$ , and for some positive integer exponents $a_1, \ldots, a_m$ .  Since both sides of $(3)$ are integers, and since $q \equiv k \equiv 1 \pmod 4$ with $q$ prime, we know that $$\sigma(q^k) = 2 {p_1}^{b_1} \cdots {p_m}^{b_m}$$ for some nonnegative integers $0 \leq b_i \leq 2a_i$ .  Thus, we have $$\sigma(n^2) = q^k {p_1}^{2a_1 - b_1} \cdots {p_m}^{2a_m - b_m}.$$ With this information, we immediately see that $$G := \gcd\left(\sigma(q^k),\sigma(n^2)\right) = \gcd\left(2 {p_1}^{b_1} \cdots {p_m}^{b_m},q^k {p_1}^{2a_1 - b_1} \cdots {p_m}^{2a_m - b_m}\right)$$ $$= {p_1}^{\min(b_1,2a_1 - b_1)} \cdots {p_m}^{\min(b_m,2a_m - b_m)},$$ $$H := \gcd\left(n^2,\sigma(n^2)\right) = \gcd\left({p_1}^{2a_1} \cdots {p_m}^{2a_m}, q^k {p_1}^{2a_1 - b_1} \cdots {p_m}^{2a_m - b_m}\right)$$ $$= {p_1}^{2a_1 - b_1} \cdots {p_m}^{2a_m - b_m},$$ and $$I := \gcd\left(n,\sigma(n^2)\right) = \gcd\left({p_1}^{a_1} \cdots {p_m}^{a_m}, q^k {p_1}^{2a_1 - b_1} \cdots {p_m}^{2a_m - b_m}\right)$$ $$= {p_1}^{\min(a_1,2a_1 - b_1)} \cdots {p_m}^{\min(a_m,2a_m - b_m)}.$$ Lastly, I know that $$\gcd(G,J)={p_1}^{\min\left(\min(b_1,2a_1 - b_1),2a_1 - b_1 - \min(a_1,2a_1 - b_1)\right)} \cdots {p_m}^{\min\left(\min(b_m,2a_m - b_m),2a_m - b_m - \min(a_m,2a_m - b_m)\right)}$$ $$={p_1}^{\min\left(2a_1 - b_1,b_1,2a_1 - b_1 - \min(a_1,2a_1 - b_1)\right)} \cdots {p_m}^{\min\left(2a_m - b_m,b_m,2a_m - b_m - \min(a_m,2a_m - b_m)\right)}$$ $$={p_1}^{\min\left(b_1,\min(2a_1 - b_1,2a_1 - b_1 - \min(a_1,2a_1 - b_1))\right)} \cdots {p_m}^{\min\left(b_m,\min(2a_m - b_m,2a_m - b_m - \min(a_m,2a_m - b_m))\right)}$$ $$={p_1}^{\min\left(b_1,2a_1 - b_1 - \min(a_1,2a_1 - b_1)\right)} \cdots {p_m}^{\min\left(b_m,2a_m - b_m - \min(a_m,2a_m - b_m)\right)}.$$ Alas, this is where I get stuck!  (I currently do not see a way of arriving at a contradiction from assuming that $\sigma(q^k)/2$ is squarefree.) Added from a comment on 02/28/2023 - 8:03 PM - Manila time I noticed that, even without assuming at the outset that $G=\sigma(q^k)/2$ is squarefree, we obtain $$J = \frac{H}{I} = \frac{I}{G},$$ and $$G \times H = I^2 \implies G \mid I^2$$ so that $$\gcd(\sigma(q^k),\sigma(n^2)) = G \mid I = \gcd(n,\sigma(n^2))$$ and $$G \mid I^2$$ both hold.  Does this finding mean that, in fact, $\sigma(q^k)/2$ must be squarefree?","['conjectures', 'perfect-numbers', 'number-theory', 'elementary-number-theory', 'divisor-sum']"
4648133,Best rank-$1$ approximation of matrix with condition.,"Let $A\in\mathbb R^{m\times n}$ be a real matrix. For any $x,y\in\mathbb R^m$ , we write $x\leq y$ if $x_i\leq y_i$ for $i=1,\dots,m$ . For any matrix $B$ , $\| B \|_F$ is the Frobenius norm and is defined by $\| B \|_F^2 := \operatorname{Tr}\left(B^T B\right)$ , recall that the trace has the cyclic property $\operatorname{Tr}(AB) = \operatorname{Tr}(BA)$ and that the trace of a $1 \times 1$ matrix is the only value in that matrix. I am trying to find a numerical method to solve the following optimization problem \begin{align*}
\min_{\substack{u\in\mathbb R^m,v\in\mathbb R^n\\ 0\leq Av}} \left\| A - u v^T \right\|_F^2
\end{align*} For practical purpose, we have $m\ll n$ , for instance $m$ would be of the order of hundreds and $n$ would typically be more than millions. I am expecting that, similarly to the PCA iterative computation procedure , we could get a runtime of order $O(m^2n)$ . To a lesser extent I am also interested in anything related to the case $n<m$ . This is trying to find the best rank- $1$ approximation of $A$ with some constraint on the rank- $1$ approximation. This problem is not convex but is biconvex on a convex subset of $\mathbb R^m\times \mathbb R^n$ , therefore my first idea was to alternate between optimization of $u$ and $v$ . Observe that we can write \begin{align*}
\| A - uv^T \|_F^2 &= \|A\|_F^2 + \mathrm{Tr} (vu^Tuv^T) - 2 \mathrm{Tr}(v u^T A)\\
&= \|A\|_F^2 + v^Tvu^Tu - 2 u^T A v\\
&= \| A \|_F^2+\|u\|^2\cdot \|v\|^2 - 2 u^T A v
\end{align*} Differentiating w.r.t. $u$ gives $2\|v\|^2u-2Av$ and w.r.t. $v$ gives $2\|u\|^2 v - 2 A^T u$ . For $v$ we need to compute the Lagragian and the KKT conditions (which are sufficient for a fixed $u$ but not in general), they are (with $\mu\in\mathbb R^m$ being the vector of Lagrange multipliers : \begin{cases}
2\|u\|^2 v - 2 A^T u-A^T\mu=0\\
0\leq Av\\
0\leq \mu\\
\mu^TAv = 0
\end{cases} So it is necessary that we have $\| v \|^2u=Av$ and the previous conditions. I am not able to solve the system of KKT conditions for $v$ , but solving it's Wolfe dual problem might be easier, it is given by \begin{align*}
\max_{v,\mu} \| u \|^2\cdot \| v\|^2-2 u^TAv-\mu^TAv
\end{align*} under the constraint $2\| u\|^2\cdot v-2A^Tu-A^T\mu=0$ and $\mu\geq 0$ , solving for $v$ and then replacing in the optimization expression gives after some simplifications \begin{align*}
\max_{\mu\geq 0} -(2u+\mu)^TM(2u+\mu)
\end{align*} Therefore solving for $\mu$ is equivalent to solving $\min_{\mu\geq 0} (2u+\mu)M(2u+\mu)$ . I made a second post about this here because it is much simpler and this post is begining to be dirty, I will clean up everything when a solution is found. Let $A^\dagger\in\mathbb R^{n\times m}$ be the Moore-Penrose pseudoinverse of $A$ , in particular $A^\dagger A$ and $A A^\dagger$ are the respective projections onto the span of $A^T$ and $A$ . Here are some facts I could obtain : Fact 1: In the solution $u,v$ to the original problem, $uv^T = 0$ if and only if $$\operatorname{span}(A) \cap [0,\infty[^m = \{ 0\}$$ Proof : If $uv^T\neq0$ , then by the KKT conditions $0\leq u=\frac{Av}{\|\ v\|^2}\in\mathrm{span}(A)\cap [0,\infty[^m$ , but $u\neq 0$ . If $0\neq a\in \mathrm{span}(A)\cap[0,\infty[^m$ , then $b=A^\dagger a \neq 0$ and \begin{align*}
\left\| A-\frac{ab^T}{\|b\|^2} \right\|_F^2 &= \| A \|_F^2+\frac{\|a\|^2\cdot \|b\|^2}{\| b\|^4} - 2 \frac{a^T A A^\dagger a}{\| b\|^2} \\
&=\| A \|_F^2+\frac{\|a\|^2}{\| b\|^2} - 2 \frac{\| a\|^2}{\| b\|^2} \\
&=\| A \|_F^2 - \frac{\| a\|^2}{\| b\|^2} \\
&<\| A \|_F^2
\end{align*} Therefore $uv^T\neq 0$ . Fact 2: If $uv^T\neq 0$ then $u\in \mathrm{span}(A)$ and $v\in\mathrm{span}(A^T)$ , furthermore $u=A\frac{v}{\| v\|^2}$ and $v = A^T\frac{2u+\mu}{2\|u\|^2}$ . Proof : Trivial from KKT conditions. Fact 3: If $a$ , $\sigma$ , $b$ is a singular triple of $A$ with $0\leq a$ , then $u=a$ and $v=\sigma b$ satisfies all KKT conditions. Proof : $2\| v\|^2u-2Av = 2\sigma^2 a- 2 \sigma^2a=0$ , select $\mu=0$ to get $2\|u\|^2 v - 2A^Tu=2\sigma b-2\sigma b=0$ , $0\leq \sigma^2 u = Av$ .","['karush-kuhn-tucker', 'matrix-rank', 'convex-optimization', 'linear-algebra', 'optimization']"
4648138,Evaluate $\int_{0}^{\pi/2} \ln\left[ \tan\left ( \frac{\theta}{2}\right) \right ]^2 K\left ( \sin\theta \right )\text{d}\theta$,"Let us define $K(x)$ as complete elliptic integral of the first kind, where $x$ is elliptic modulus. A possible closed-form is ( $G$ denotes Catalan's constant.) $$
\int_{0}^{\pi/2}
\ln\left[ \tan\left (  \frac{\theta}{2}\right)  \right ]^2
K\left ( \sin\theta \right )\text{d}\theta
=\frac{\Gamma\left ( \frac14 \right )^4G }{8\pi}.
$$ It looks like a ""product"" of two solvable integrals (both are elementary): $$\int_{0}^{\pi/2}
\ln\left[ \tan\left (  \frac{\theta}{2}\right)  \right ]^2\text{d}\theta
=\frac{\pi^3 }{8}$$ and $$
\int_{0}^{\pi/2}
K\left ( \sin\theta \right )\text{d}\theta
=\frac{\Gamma\left ( \frac14 \right )^4 }{16\pi}.
$$ Question :
How can we evaluate the integral? I try to utilize the Fourier series $K(\sin\theta)
=\pi\sum_{n\ge0} \frac{\left ( \frac12 \right )_n^2 }{(n!)^2} 
\sin\left ( \left ( 4n+1 \right )\theta  \right )$ to prove, but seems not to go well. I appreciate for your help. An Interesting Observation :
We find $$
\int_{0}^{\pi/2}
\ln\left[ \tan\left (  \frac{\theta}{2}\right)  \right ]^4
K\left ( \sin\theta \right )\text{d}\theta
=\frac{3\,\Gamma\left ( \frac14 \right )^4}{4\pi}(G^2+\beta(4))
$$ where $\beta(.)$ is Dirichlet's $\beta$ function.","['integration', 'calculus', 'closed-form', 'fourier-series', 'elliptic-integrals']"
4648167,Advection reaction equation is solved by projection of solution of continuity equation,"Suppose an absolutely continuous curve $\mu \colon (0, \infty) \to P_2(\Omega)$ , where $P_2$ is the Wasserstein-2-space , fulfils the continuity equation $$ \label{eq:CE} \tag{CE}
\partial_t \mu_t = \text{div}(\mu_t g_{\mathfrak h \mu_t})
$$ for almost all $t > 0$ in the weak sense , where $\Omega := \Theta \times \mathbb R_{\ge 0}$ , $\Theta$ is a compact connected Riemannian manifold without boundary and $$
g_{v} \colon \Omega \to T \Omega, \qquad (r, \theta)
\mapsto \begin{pmatrix}
            2 \alpha r \cdot J_{v}'(\theta) \\
            \beta \cdot \nabla J_{v}'(\theta)
        \end{pmatrix} \in \mathbb R \times T_{\theta} \Theta
$$ for some fixed $\alpha, \beta > 0$ and $v \in M_+(\Theta)$ is a finite non-negative Radon measure on $\Theta$ and $J_v' \colon \Theta \to \mathbb R$ is differentiable .
Show that (this is Proposition 2.1 in Lenaic Chizat 's Sparse optimization on measures with overparametrized gradient descent ) $v_t := \mathfrak h \mu_t$ fufills $$ \label{eq:advec} \tag{$\ddagger$}
\partial_t v_t = -4 \alpha v_t J_{v_t}' + \beta \cdot \text{div}(v_t \nabla J_{v_t}')
$$ in the weak sense for almost every $t > 0$ , where $\mathfrak h \colon P_2(\Omega) \to M_+(\Theta)$ is defined via $$ \label{eq:h} \tag{$\dagger$}
\int_{\Theta} \psi(\theta) \, \text{d}(\mathfrak h \mu)(\theta)
= \int_{\Omega} \psi(\theta) r^2 \, \text{d}\mu(\theta, r)
\qquad \forall \psi \in \mathcal C(\Theta; \mathbb R).
$$ The metric on $\Omega$ is $$ \label{eq:omega} \tag{$\star$}
\langle (r_1, \partial \theta_1), (r_2, \partial \theta_2) \rangle_{(r, \theta)} := \frac{1}{\alpha} r_1 r_2 + \frac{r^2}{\beta} \langle \partial \theta_1, \partial \theta_2 \rangle_{\theta}
$$ for $x = (r, \theta) \in \Omega$ and $(r_1, \partial \theta_1), (r_2, \partial \theta_2) \in T_x \Omega \cong \mathbb R \times T_{\theta} \Theta$ . My attempts. Let $\xi \colon \Theta \to \mathbb R$ be differentiable .
Then for almost all $t > 0$ \begin{align}
\frac{\text{d}}{\text{d} t} \int_{\Theta} \xi(\theta) \, \text{d}v_t(\theta)
& \overset{\eqref{eq:h}}{\underset{v_t=\mathfrak h \mu_t}{=}} \frac{\text{d}}{\text{d} t} \int_{\Omega} \xi(\theta) r^2 \, \text{d}\mu_t(\theta, r) \\
& \overset{\eqref{eq:CE}}{=} - \int_{\Omega} \left\langle \begin{pmatrix} \nabla \xi(\theta) \\ 2 r \end{pmatrix}, \begin{pmatrix} \beta \cdot \nabla J_{v_t}'(\theta) \\ 2 \alpha r \cdot J_{v_t}'(\theta) \end{pmatrix} \right\rangle_{(\theta, r)} \, \text{d}\mu_t(\theta, r) \\
&\overset{\eqref{eq:omega}}{=} - \int_{\Omega} \frac{1}{\alpha} (2 r) \cdot 2 \alpha r \cdot J_{v_t}'(\theta) + \frac{r^2}{\beta} \beta \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta} \, \text{d}\mu_t(\theta, r) \\
& = - \int_{\Omega}  r^2 \cdot \left( 4 J_{v_t}'(\theta) + \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta}\right) \, \text{d}\mu_t(\theta, r) \\
& \overset{\eqref{eq:h}}{\underset{v_t=\mathfrak h \mu_t}{=}} - \int_{\Theta} 4 J_{v_t}'(\theta) + \langle \nabla J_{v_t}'(\theta), \nabla \xi(\theta) \rangle_{\theta} \, \text{d}v_t(\theta),
\end{align} because the weak formulation of \eqref{eq:CE} is $$
\frac{\text{d}}{\text{d} t} \int_{\Omega} \psi(x) \, \text{d}\mu_t(x)
= - \int_{\Omega} \langle \nabla \psi(x), g_{\mathfrak{h} \mu_t}(x) \rangle_{x} \, \text{d}\mu_t(x)
$$ for all differentiable maps $\psi \colon \Omega \to \mathbb R$ . But this doesn't look like the weak formulation of \eqref{eq:advec}, which should be something like $$
\frac{\text{d}}{\text{d} t} \int_{\Theta} \xi(\theta) \, \text{d}v_t(\theta)
= - \int_{\Theta} 4 \alpha \xi(\theta) J_{v_t}'(\theta) + \beta \langle \nabla \xi(\theta), \nabla J_{v_t}'(\theta) \rangle_{\theta} \, \text{d}v_t(\theta),
$$ because the $\alpha$ and $\beta$ are missing.
Is my calculation wrong (I am particularly sure about the computation of the gradient of $\xi(\theta) \cdot r^2$ ) or did I compute the weak formulation of \eqref{eq:advec} wrong?","['transport-equation', 'gradient-flows', 'measure-theory', 'partial-differential-equations', 'wasserstein']"
4648187,Homogeneous of degree one functions that are a monotonic transformation of an additively separable function,"Let $n>1$ , and let $f:\mathbb{R}^n_{\ge 0}\rightarrow\mathbb{R}_{\ge 0}$ be continuously differentiable, concave, and homogeneous of degree one. Here, homogeneity of degree one means that for all $s\in\mathbb{R}_{\ge 0}$ , and $x\in\mathbb{R}^n_{\ge 0}$ , $f(sx)=sf(x)$ . And suppose that there exist continuously differentiable monotonic increasing functions $g:\mathbb{R}\rightarrow\mathbb{R}_{\ge 0}$ and $h_1,\dots,h_n:\mathbb{R}_{\ge 0}\rightarrow\mathbb{R}$ such that for all $x\in\mathbb{R}^n_{\ge 0}$ : $$f(x)=g(h_1(x_1)+\cdots+h_n(x_n)).$$ Must it be the case that there exists $a_1,\dots,a_n\in\mathbb{R}$ and $\rho,b_1,\dots,b_n\in\mathbb{R}_{\ge 0}$ such that for all $i\in\{1,\dots,n\}$ , $h_i(x)=a_i+b_i \frac{x^{1-\rho}-1}{1-\rho}$ ? (Where, when $\rho=1$ , we understand this as stating $h_i(x)=a_i+b_i\log(x)$ .) Note that by Euler's homogeneous function theorem: $$g(h_1(x_1)+\cdots+h_n(x_n))=(h_1'(x_1)x_1+\cdots+h_n'(x_n)x_n)g'(h_1(x_1)+\cdots+h_n(x_n)).$$ Does this (differential equation) help?","['homothety', 'economics', 'functions', 'partial-differential-equations', 'convex-analysis']"
4648191,$N$-fixed vectors in smooth representations are also fixed by ${\rm SL}_2(\mathbf{Q}_p)$.,"Let $N = \left(\begin{matrix} 1 & * \\ 0 & 1 \end{matrix}\right)$ be the upper triangular unipotent subgroup in ${\rm GL}_2(\mathbf{Q}_p)$ and $K_n = 1 + p^n M_2(\mathbf{Z}_p)$ the usual compact opens in ${\rm GL}_2(\mathbf{Q}_p)$ . I am trying to show that the subgroup generated by $N$ and $K_r$ would contain ${\rm SL}_2(\mathbf{Q}_p)$ for every $r \gg 0$ . This would prove the claim in the title. I believe that, I could make this work if I showed that the group $\langle N, K_r \rangle$ contains $K_{r-1} \cap N^t$ where $N^t$ is the lower triangular unipotent subgroup. I can't quite think of the right matrices from $N$ and $K_r$ to multiply to get the power of $p$ in the lower right hand corner to decrease... Any thoughts would be appreciated.","['automorphic-forms', 'p-adic-number-theory', 'representation-theory', 'matrices', 'group-theory']"
4648264,Solve zero of a trigonometric equation,"This is the equation I have: $$\sin \left(\frac{\pi t+\frac{\pi }{2}}{2}\right)-\sin \left(\frac{\pi t}{2}\right)=0$$ Also the variable t has a requirement $0\le t\le \frac{3}{2}$ . I have tried $\frac{\pi t+\frac{\pi }{2}}{2}=\frac{\pi t}{2}$ but when trying to solve for t, it t gets removed. I'm not sure what to do.","['trigonometry', 'roots']"
4648325,Kernel of Spherically Symmetric Diffusion Equation,"I'm trying to find the Kernel of the 3D Diffusion Equation but my lecture notes are unclear on the procedure. $$\frac{\partial u}{\partial t} = D \nabla ^2u$$ $$u(\vec{x}, 0) = R(|\vec{x}|)$$ I need to show that the solutions might be written as: $$u(|\vec{x}|, t) = \int ^{+\infty}_0 dr r^2 R(r)K(r, |\vec{x}|; t)$$ where $K$ is the kernel which I also need to find explicitly. THIS IS WHAT I HAVE TRIED: I started by transforming the equation: $\frac{\partial \tilde{u}}{\partial t} = -Dk^2\tilde{u} \Leftrightarrow \tilde{u}(k,t) = \tilde{u}(k,0)\exp(-Dk^2t)$ Then using Radial / Spherical Polar Fourier Transform: $$u(x,t) = \sqrt{\frac{2}{\pi}}\int^{+\infty}_0k^2\frac{\sin(kr)}{kr}\tilde{u}(k,t)dk = \sqrt{\frac{2}{\pi}}\int^{+\infty}_0k^2\frac{\sin(kr)}{kr}\tilde{u}(k,0)\exp{(-Dk^2t)}dk$$ $$u(x,t) = \frac{2}{\pi}\int^{+\infty}_0k^2\frac{\sin(kr)}{kr}\exp{(-Dk^2t)}dk\int^{+\infty}_0r^2\frac{\sin(kr)}{kr}R(r)dr$$ $$u(x,t) = \int^{+\infty}_0r^2R(r)K(r, |\vec{x}|;t)dr$$ where here the kernel is: $\frac{2}{\pi}\int^{+\infty}_{0}k^2\frac{\sin(kr)}{k^2r^2}\exp{(-Dk^2t)}dk$ I don't know how to handle the integral and I don't even know if what I am doing is good. Any ideas? Many thanks!","['integration', 'fourier-transform', 'ordinary-differential-equations', 'partial-differential-equations']"
4648334,"Interchanging summations with complicated, nested indices","I have a question regarding interchanging the order of three nested summations. My expression looks like \begin{align}
\sum_{n=0}^\infty \sum_{k=0}^n \sum_{\nu=0}^{4n-2k}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu},
\end{align} where $C_{nk\nu}$ is a term depending on the three indices which, for the purposes of this question is irrelevant. What I want to do (assuming convergence) is to put the $\nu$ sum to the far most left, however I am not sure about the proper summation indices after interchanging the sums. For instance, I know that due to the binomial coefficient $\binom{4n-2k}{\nu}$ and the $(n-k)!$ factor we have the following summation constraints \begin{align}
n-k\geq 0 \hspace{5mm} \Longrightarrow k \leq n,
\end{align} \begin{align}
4n-2k-\nu\geq 0 \hspace{5mm} \Longrightarrow k \leq \dfrac{4n-\nu}{2}.
\end{align} From which I can ""guess"" the new summation indices after interchanging the $k  \leftrightarrow \nu$ sums: \begin{align}
\sum_{n=0}^\infty \sum_{k=0}^n \sum_{\nu=0}^{4n-2k}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu}=\sum_{n=0}^\infty \sum_{\nu=0}^\infty \sum_{k=0}^{\max\left(\lfloor \frac{4n-\nu}{2}\rfloor,n\right)}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu},
\end{align} However this is only true for the cases when $n=0$ and $\forall \ \nu$ but for instance when $n=1$ and $\nu=0$ , $\lfloor \dfrac{4(1)-0}{2} \rfloor=\lfloor 2 \rfloor = 2$ so the $k$ sum will run up to $2$ but then the term $(n-k)!=(1-(2))!=(-1)!$ is undefined so the upper limit that I put is correct for some values but incorrect for others, I have been trying to do some modifications to my upper limit but so far I have failed. Do you have any suggestions to properly flip the summations? Thanks in advance :)","['power-series', 'summation', 'index-notation', 'sequences-and-series']"
4648360,Solving general multivariable quadratic equations,"Consider the variables $\mathbf{x}\in\mathbb{R}^n$ and the known coefficients $\mathbf{A}_i \in \mathbb{R}^{n\times n}, \mathbf{b}_i \in \mathbb{R}^n,$ and $c_i \in \mathbb{R}$ for $i=1,2,\cdots, n$ . They satisfy an $n$ -equation system given by: $$
\mathbf{x}^T\mathbf{A}_i \mathbf{x} + \mathbf{b}_i^T \mathbf{x} + c_i = 0, \quad i=1, 2,\cdots,n.
$$ Can anyone suggest a general solver that can be used for this type of system? I'm not well-versed in algebra and would appreciate it if you could provide me with some method names that I can use.","['systems-of-equations', 'vectors', 'matrices', 'matrix-calculus', 'matrix-equations']"
4648364,Closed form of an averaging series,"Consider the expression $$
f(\mathbf{x},n)=\sum_{k=0}^{n}  \frac{e^{-k^2\overline{x_k}}-e^{-(k+1)^2\overline{x_k}}}{(2k+1)\overline{x_k}}
$$ where $\mathbf{x}=[x_{-n},\cdots,x_{-2},x_{-1},x_0,x_1,x_2,\cdots,x_{n}]^T$ and $$
\overline{x_k}=\frac{1}{2k+1}\sum_{|i|\leq k} x_i
$$ with $0<x_i<\infty$ , for all $i\in\{-n,...,-1,0,1,...,n\}$ . What is $\lim_{n\to\infty}f(\mathbf{x},n)$ ? If not a closed formula, is it possible to find an upper bound? My attempt: Following @metamorphy's answer presented here , for the case where $x_i\equiv x,\forall i$ , and given that $\{x_i\}$ is bounded, one would hope there exists $k^*$ such that $$
f(\mathbf{x},\infty)=\sum_{k=0}^{\infty}  \frac{e^{-k^2\overline{x_k}}-e^{-(k+1)^2\overline{x_k}}}{(2k+1)\overline{x_k}}\simeq \frac{1}{\overline{x_{k^*}}} \sum_{k=0}^{\infty}  \frac{e^{-k^2\overline{x_{k^*}}}-e^{-(k+1)^2\overline{x_{k^*}}}}{2k+1}
$$ which, following the answer to the linked question, leads to the local approximation $$
f(\mathbf{x},\infty)\simeq \frac12\sqrt{\frac{\pi}{\overline{x_{k^*}}}}
$$ However, in simulations, this does not seem to work for numerical attempts on various values of $k^*$ . Nonetheless, I expect an approximation like this to be possible. Just to better visualize the problem, here is the plot of $f(\mathbf{x},n)$ , where the ""data"" vector $\mathbf{x}$ was generated via a random walk with very small increments ( $10^{-5}$ ) and $x_i\in(0,0.1)$ The goal is to approximate the blue curve. Any ideas? Comment on $\mathbf{x}$ : The randomness of $\mathbf{x}$ might difficult finding a potential solution and make this problem way too broad. Therefore, we may take it to behave ""continuously"" enough. For example, it can be taken to be a fine discretisation of a continuous function, as sketched here Naturally the answer should be $\mathbf{x}$ -dependent, but I wonder if it is possible to still make an assertion on an approximation to $f$ , given, for example, a local mean approximation, as seen, for some $k^*$ , Where $\overline{x_n}$ is the overall mean. Note that, for each $k$ , the mean changes little, and we may also assume $$
|\overline{x_k}-\overline{x_{k-1}}|<\epsilon
$$ for some small $\epsilon$ .","['logarithms', 'upper-lower-bounds', 'sequences-and-series', 'limits', 'exponential-function']"
4648365,Why are infinite series seemingly allowed to ignore the Commutative Property? [duplicate],"This question already has answers here : Why does the commutative property of addition not hold for conditionally convergent series? (4 answers) Closed last year . We just learned about conditionally convergent series vs absolutely convergent series in my hs calculus class and I'm really confused about why conditionally convergent series are seemingly allowed to ignore the Commutative Property. We were given this example in class. $$1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}... = \ln(2)$$ We weren't shown why this is $\ln(2)$ but just that it was given. Then he rearranged into $$(1-\frac{1}{2})-\frac{1}{4}+(\frac{1}{3}-\frac{1}{6})-\frac{1}{8}+(\frac{1}{5}-\frac{1}{10})...$$ which equals $$\frac{1}{2}-\frac{1}{4}+\frac{1}{6}-\frac{1}{8}+\frac{1}{10}... $$ he then factors out 1/2 which gives $$\frac{1}{2}(1-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}...)$$ Which includes the original series so the final conclusion is that the new series is $$\frac{\ln(2)}{2}$$ Now here is my question : WHY??? This makes sense (sort of) but I learned in second grade that 1+2=2+1 , which is the Commutative Property, I don't understand why we can ignore that just because it's an infinite series. Are there any more clear examples or better ways of thinking about it so that it actually makes sense, or is it just one of those things that you have to take as given. Why is it considered ""Conditionally Convergent"" instead of ""Divergent"" ? Thank you for the help","['limits', 'calculus', 'sequences-and-series']"
4648391,Properties of Weierstrass's elliptic function.,"In section 6.2 of An introduction to Riemann Surfaces, Algebraic Curves and Moduli Spaces by M. Schlichenmaier, the author wants to embed the torus $T = \mathbb{C}/L$ (for a conventional integer lattice $L = \{m + n z: m,n\in\mathbb{N},z\in\mathbb{C}\}$ ) in the complex projective space $\mathbb{P}^2$ . To do so he introduces the map $$\Psi:T\to\mathbb{P}^2:z\mapsto\begin{cases} (\wp(z):\wp'(z): 1),
& z \neq 0 \\ (0:1:0), & z = 0\end{cases}$$ where $\wp$ stands for Weierstrass elliptic function. Most of the reasoning seems to me quite straight forward, but I fail catastrophically too understand two notions employed to prove the injectivity of $\Psi$ . I cite the problematic passages. $\wp$ is a [meromorphic] function on the torus, thus it takes every value of $\mathbb{P}^1$ equally often (calculated with multiplicity). Why? The image of a non-constant meromorphic function over $\mathbb{C}$ is dense in $\mathbb{C}$ , but how can we get from here to the conclusion that $\wp:T\to\mathbb{P}^1$ is surjective? And not only that, but moreover he says it takes every such value equally often! Does this really mean that $\exists n\in \mathbb{N}\; \forall z\in\mathbb{P}^1\;\exists \{z_1,...,z_n\}\subseteq\mathbb{N}:\;\;\wp(z_i) = z\; \forall i\in [\![1,n]\!]$ ? This is something I am completely unable to understand or prove. Then he continues: It has a pole of order $2$ at $0\in T$ and nowhere else. Hence every value occurs  two times. I presume the reasoning behind this assertion (which follows right after the one cited before it) is very closely related to the preceding one, and I am equally unable to prove it myself. I would really appreciate any help. Thank you in advance. (Solution candidate promoted to answer, see below).","['algebraic-geometry', 'elliptic-curves']"
4648399,Triple integral over the body $Q$ between two spheres,"This is an exercise in using spherical coordinates. Calculate the triple integral $$J = \iiint_{Q}\ \frac{1}{x^2+y^2+z^2} \,dx \,dy \,dz$$ where $Q$ is the body between the two spheres $$x^2+y^2+z^2 = 1 $$ and $$x^2+y^2+z^2 = 9 $$ The calculation is quite easy. I am getting answer $8\pi$ but the answer given is $4\pi$ . Which one is correct?","['real-analysis', 'multivariable-calculus', 'calculus', 'solution-verification', 'multiple-integral']"
4648417,Maximizing volume of a cylinder with $2$ cones given surface area $A$,"A cylinder with a cone on either side of it. The cones have the same radius as the cylinder.
Cylinder area without the sides: $$A_{cyl}=2\pi r h_1$$ Cone area without the base: $$A_{cone}=\pi r \sqrt{h_2^2+r^2}$$ Total area of body: $$A_{tot}=2\pi r h_1 + 2\pi r \sqrt{h_2^2+r^2}$$ Volume: $$V_{tot}=\pi r^2 h_1 +\frac{2\pi r^2 h_2}{3}=\pi r^2 (h_1 + \frac{2}{3}h_2)$$ I have managed to calculate the maximum volume given surface area for the cone and the cylinder separately but together there are three variables. How would I go about calculating $r,h_1,h_2$ to maximize the volume?","['optimization', 'multivariable-calculus']"
4648426,Proving that a square inscribed in a circle has a strictly smaller area,"I'm trying to (for self-study) follow a proof that $\pi \neq 4$ . The exercise allows me to use basic geometric facts and constructions, but I can't use any specific facts about $\pi$ . The first step of the instructor's solution considers a circle of radius $1$ inscribed in a square of side length $2$ . He says that ""we will admit that the area of the circle is less than or equal to the area of the square,"" but I don't know how to prove this without appealing to the properties of $\pi$ . The standard way I would convince myself of this is as follows: The circle has radius $1$ and therefore area $\pi \cdot 1^2 = \pi$ . The square has area $2^2 = 4$ . The ratio of the area of the circle to the area of the square is then $\frac{\pi}{4}$ . As $\pi < 4$ , $\frac{\pi}{4} < 1$ , hence the area of the circle is strictly smaller than the area of the square. I can't use this argument in this specific proof because I'm using a specific fact about $\pi$ . My question, therefore, is: is there a way to notice that the area of the inscribed circle is less than or equal to the square without knowing anything specific about $\pi$ ? The other argument is to just look at the picture and say, ""well, clearly it's smaller because the square takes up every bit of area of the circle, plus some more,"" but that seems very un-rigorous to me.","['proof-explanation', 'geometry']"
4648456,proof that $ \lim_{x \to \infty} \frac{f(x)}{g(x)} = 1 $ is an equivalence relation,"Define the following relation on $ \{f \in \mathbb{R}^\mathbb{R} \mid 0 \notin Image(f) \} $ : $ f \ $ is equivalent to $ \ g \ $ if and only if $ \displaystyle \lim_{x \to \infty} \frac{f(x)}{g(x)} = 1 $ . I want to prove that this is an equivalence relation, is the following proof valid? $ \underline{\text{Reflexivity:}} $ $ \forall x \in \mathbb{R}, \ \frac{f(x)}{f(x)} = 1 \Rightarrow \displaystyle \lim_{x \to \infty} \frac{f(x)}{f(x)} = \lim_{x \to \infty} 1 = 1 \Rightarrow f \ $ is equivalent to $ f $ . $ \underline{\text{Symmetry:}} $ Assume $ \displaystyle \lim_{x \to \infty} \frac{f(x)}{g(x)} = 1 $ . Therefore, $ \displaystyle \lim_{x \to \infty} \frac{g(x)}{f(x)} = \lim_{x \to \infty} \frac{1}{\frac{f(x)}{g(x)}} = \frac{\displaystyle \lim_{x \to \infty} 1}{\displaystyle \lim_{x \to \infty} \frac{f(x)}{g(x)}} = \frac{1}{1} = 1$ and therefore $ \ g \ $ is equivalent to $ \ f $ . $ \underline{\text{Transitivity:}} $ Assume $ \displaystyle \lim_{x \to \infty} \frac{f(x)}{g(x)} = 1 \land \lim_{x \to \infty} \frac{g(x)}{h(x)} = 1 $ . Therefore, $ \displaystyle \lim_{x \to \infty} \frac{f(x)}{h(x)} = \lim_{x \to \infty} \frac{f(x)}{g(x)} \frac{g(x)}{h(x)} = \lim_{x \to \infty} \frac{f(x)}{g(x)} \cdot \lim_{x \to \infty} \frac{g(x)}{h(x)} = 1 \cdot 1 = 1 $ . $$\tag*{$\blacksquare$}$$ I feel that in in ""Transitivity"", I am assuming the limit exists. Is that true?","['limits', 'equivalence-relations', 'solution-verification', 'real-analysis']"
4648515,"Functions without complex roots, but with quaternion roots","Many introductions to complex numbers begin with the question ""What are the roots of $x^2 + 1 = 0$ ?"" This function does not have real roots, but does have complex roots. Are there functions which, in a similar vein, do not have complex roots but do have roots in the quaternions?","['quaternions', 'functions', 'complex-numbers']"
4648547,What are the eigenvalues of this arrowhead matrix?,"Suppose $p_0,\ p_1,\ \dots,\ p_q$ are positive such that $p_0+p_1+\dots+p_q=1$ . I am wondering how to find the eigenvalues of the following arrowhead matrix $$A=\begin{bmatrix}
1 & p_1 & \dots & p_q\\
p_1 & p_1 & & \\
\vdots & & \ddots & \\
p_q & & & p_q
\end{bmatrix} \in \mathbb{R}^{(q+1)\times (q+1)}.$$ where the empty parts in $A$ are all zeros and $p_0$ does not show up in $A$ . Since $p_0>0$ , we have $0<p_1+\dots+p_q<1$ and $A$ is a positive definite matrix. I used the method $|\lambda I - A|$ to find the eigenvalues: $$\lambda I - A=\begin{bmatrix}
\lambda-1 & -p_1 & \dots & -p_q\\
-p_1 & \lambda-p_1 & & \\
\vdots & & \ddots & \\
-p_q & & & \lambda-p_q
\end{bmatrix}.$$ We can multiply the second column of $\lambda I - A$ by $p_1/(\lambda-p_1)$ which could be added to the first column. Then we can eliminate the second entry in the first column. However, this method moves $\lambda-p_1$ in the denominator. It is still hard to find those eigenvalues of $A$ .","['matrices', 'linear-algebra', 'characteristic-polynomial', 'eigenvalues-eigenvectors']"
4648618,Stronger result than bertrand's postulate,"It is well known that there is a prime number between $n$ and $2n$ for all $n$ . I decided to go deeper: is there a lower bound on the number of primes between $n$ and $2n$ for ""large enough"" $n$ ? For instance, I found empirically that $\pi(n)-\pi(n/2)\ge \sqrt n$ at around $n\ge 100$ (In particular, I also used a program to show $\pi(n^2)-\pi(n^2/2)\ge n$ for $n\ge 10$ ). Does there exist a nice elementary proof of this? Obviously, we can show this result asymptotically for very great $n$ . I ask to consider an elementary proof of the above bound.","['distribution-of-primes', 'number-theory', 'elementary-number-theory', 'analytic-number-theory', 'prime-numbers']"
4648635,How do I integrate $\int_0^{\infty} \frac{\log(t+1)}{t^2+a^2} \mathrm{d}t$?,"How do I integrate the following integral: $$\int_0^{\infty} \frac{\log(t+1)}{t^2+a^2} \mathrm{d}t$$ Where $a$ is some parameter? I know that the solution includes Lerch Transcendents and logs (which is what I'm trying to arrive at); however, I've tried integrating this function, but failed. I've already tried using simplifying it using series, which yielded a bunch of integrals as follows: $$-\sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{t^k} {t^2+a^2} \mathrm{d}t - \frac{1}{a^2} \sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{t^k} {t^2+\frac{1}{a^2}} \mathrm{d}t + \frac{1}{a^2} \sum_{k \geq 1} \frac{(-1)^k}{k} \int_0^1 \frac{\log(t)} {t^2+\frac{1}{a^2}} \mathrm{d}t$$ However, I don't know how I'd proceed forwards from here.","['integration', 'calculus', 'logarithms']"
4648638,Approximation used in Hutton's computation in the Schiehallion experiment,"I have been trying to understand the numerical integration approach employed by Charles Hutton in calculating the gravitational attraction of the Schiehallion mountain on a plumb line. The paper is available here: https://royalsocietypublishing.org/doi/10.1098/rstl.1778.0034 . In the paper, he provides a geometric argument and I'm trying to formulate it in terms of calculus. The relevant pages (if you are interested) are 750-755. The basic approach can be seen in the following diagram: The plumb line is at A in the figure. He is using cylindrical coordinates to do the integration. He takes the meridian going toward north to be the positive X-axis and computes the X-component of the gravitational attraction of each mass element on the plumb line. If you have a mass element enclosed in the ring between $r = r_1$ and $r = r_2$ , and the sector between $\theta = \theta_1$ and $\theta = \theta_2$ and planes $z = 0$ and $z = h$ , the X-component of its gravitational attraction would be: $$\int_{\theta_1}^{\theta_2}\int_{0}^{h}\int_{r_1}^{r_2} Gm\rho\;\frac{r^2}{(r^2 + z^2)^\frac{3}{2}}\;\cos{\theta}\;dr\;d\theta\;dz$$ Here, $G$ is the gravitational constant, $m$ is the mass of the plumb bob and $\rho$ is the density of the mountain. The integral (if you factor out $Gm\rho$ ) evaluates to: $$h\;(\sin{\theta_2} - \sin{\theta_1})\;\Biggl\{\log\Biggl(\sqrt{\frac{r_2^2}{h^2} + 1} + \frac{r_2}{h}\Biggr) - \log\Biggl(\sqrt{\frac{r_1^2}{h^2} + 1} + \frac{r_1}{h}\Biggr)\Biggr\}$$ (I hope I have calculated the integral correctly.) He seems to be assuming that $r_2$ is close to $r_1$ and $h \ll \frac{r_1 + r_2}{2}$ . With these assumptions, it seems to me that the following approximation should hold: $$\Biggl\{\log\Biggl(\sqrt{\frac{r_2^2}{h^2} + 1} + \frac{r_2}{h}\Biggr) - \log\Biggl(\sqrt{\frac{r_1^2}{h^2} + 1} + \frac{r_1}{h}\Biggr)\Biggr\} \approx \frac{r_2 - r_1}{\sqrt{(\frac{r_1 + r_2}{2})^2 + h^2}}$$ But I'm unable to see how to derive this approximation. I would greatly appreciate any help you can provide in helping me understand this. Thanks!!","['multivariable-calculus', 'approximation', 'approximation-theory', 'numerical-methods']"
4648645,"Do we have a simpler method for computing $\int_{-\infty}^{\infty} \frac{\ln \left(x^2+ax+b\right)}{1+x^2} d x$, where $b> \frac{a^2}{4} $?","Background After finding the exact value of the integral in my post , I start to investigate a similar integral $$I(a):
 =\int_{-\infty}^{\infty} \frac{\ln \left(x^2+ax+b\right)}{1+x^2} d x=\int_{-\infty}^{\infty} \frac{\ln \left[\left(x+\frac{a}{2}\right)^2+\left(b-\frac{a^2}{4}\right)\right] d x}{1+x^2}$$ where $b> \frac{a^2}{4}.$ By Contour integration along the upper semi-circle Using the fact that $\ln \left(x^2+y^2\right)=2 \operatorname{Re}(\ln (x+y i))$ to reduce the $x^2$ to $x$ and making the branch point of $\ln$ below the real axis, we change the integral into $$
$$ \begin{aligned}
I(a) & =2 \operatorname{Re} \int_{-\infty}^{\infty} \frac{\ln \left(x+\frac{a}{2}+i \sqrt{b-\frac{a^2}{4}}\right)}{1+x^2} d x \\
& =2 \operatorname{Re}\left[2 \pi i \lim _{z \rightarrow i} \frac{\ln \left(z+\frac{a}{2}+i \sqrt{b-\frac{a^2}{4}}\right)}{z+i}\right] \\
& =2 \operatorname{Re}\left[2 \pi i \frac{\ln \left(i+\frac{a}{2}+i \sqrt{b-\frac{a^2}{4}}\right)}{2 i}\right] \\
& = \pi \ln \left(1+b+\sqrt{4 b^2-a^2}\right)
\end{aligned} For example, $$
\begin{aligned}& \int_{-\infty}^{\infty} \frac{\ln \left(x^2+x+\frac{1}{2}   \right)}{1+x^2} d x =\pi \ln \left(\frac{5}{2}\right) \\
& \int_{-\infty}^{\infty} \frac{\ln \left(x^2+x+1\right)}{1+x^2} d x =\pi \ln (2+\sqrt{3})
\end{aligned}
$$ Do we have a simpler method for computing $$\int_{-\infty}^{\infty} \frac{\ln \left(x^2+ax+b\right)}{1+x^2} d x,$$ where $b> \frac{a^2}{4}  $ ?","['integration', 'improper-integrals', 'calculus', 'definite-integrals']"
4648662,Minimizing $\frac{\operatorname{Tr}(H^2)^2}{\operatorname{Tr}(H^3)\operatorname{Tr}H}$,Suppose $H$ is a diagonal positive definite $d\times d$ matrix with $\operatorname{Tr}(H)=1$ . I'm interested in $H$ which minimizes the following: $$J=\frac{\operatorname{Tr}(H^2)^2}{\operatorname{Tr}(H^3)\operatorname{Tr}H}$$ I can use numerical optimizer to solve it and get something like this on diagonal for $d=40$ . Largest value is $0.239376$ and remaining mass is split equally among remaining dimensions. What is the solution in the limit of $d\to \infty$ ? Motivation: minimizing $J$ gives shape of quadratic which is hardest to minimize with a single step of gradient descent.,"['optimization', 'linear-algebra']"
4648706,Is there a closed-form solution to the equation included in this post?,"EQUATION 1: $\text{Constant} = \frac{\ln(y-x)}{\ln(y)}$ GIVEN: $0 <$ Constant $< 1$ The $x$ and $y$ values are always positive. The closed form solution may ignore zero and negative $x$ and $y$ values. SIMPLIFIED EQUATION 1: Equation 1 may be simplified using log rules to $y-y^\text{Constant} = x $ The simplified equation is $x$ as a function of $y$ . I would like to solve $y$ as a function of $x$ . I am stuck at this point. BACKGROUND: I upload a table of $x$ and $y$ values to legacy software. I am commonly told to change the constant. I am able to solve $y$ computationally using Excel. Using Excel introduces manual steps in my workflow when I am told to change the constant. For example, my current workflow is: change the constant, use Excel solver to solve Equation 1 using the updated constant for y as a function of $x$ (e.g., $x$ values $.01$ to $9,999.99$ at a step size of $.01$ ) , upload table with $x$ and $y$ values from excel into legacy software. The legacy software is able to handle closed form solutions. Thus my desire to automate the process of generating the table in the legacy software using the closed-form solution (i.e., without Excel). QUESTION: Is there a closed-form solution to the equation $1$ ? If so, what is the closed-form solution?",['functions']
4648721,Lie algebra sheaf of an abelian variety and the derived pushforward of its structure sheaf,"Let $A$ be an abelian variety over a base scheme $S$ , write $\pi: A \rightarrow S$ , equipped with the zero section $e: S \rightarrow A$ . Let $A^{\vee}$ be the dual variety of $A$ . I am hoping to obtain some kind of result like $$
\underline{\mathrm{Lie}}(A^{\vee}/S) \cong \mathrm{R}^1 \pi_{\ast} \mathcal{O}_A. \quad (\dagger)
$$ Here $\underline{\mathrm{Lie}}(A/S)$ is the Lie algebra sheaf of $A_{/S}$ . My questions are : I am currently having no idea of a precise definition of the Lie algebra sheaf. I found in Mumford's book Abelian Varieties but only saw the definition of the Lie algebra (page 94) associated to the group scheme $G_{/k}$ as a $k$ -vector space. Where can I find a sheaf-version definition of the Lie algebra of abelian varieties that fits in the setup above? How to (find appropriate assumptions on $A/S$ and) show $(\dagger)$ ? Any proof, hint or references are welcome! My attempt : I was told (though not knowing the precise defn of $\underline{\mathrm{Lie}}$ ) that there is an isomorphism for any group schemes $G$ over $S$ : $$
\phi: \underline{\mathrm{Lie}}(G/S) \xrightarrow{\sim} \mathcal{Hom}_{\mathcal{O}_S}(\omega_{G/S}, \mathcal{O}_S)
$$ as $\mathcal{O}_S$ -modules, where $\omega_{G/S}$ is defined as the sheaf $e^{\ast} \mathcal{I}_{G/S}$ , with $\mathcal{I}_{G/S}$ the sheaf of ideals of the closed immersion $e: S \rightarrow A$ . Then I get stuck and have no idea how to carry on. :( My motivation : I know for elliptic curves $E$ over a base scheme $S$ (at least in the world of char zero), we have a short exact sequence deduced from the Hodge-to-de Rham spectral sequence $$
0 \rightarrow \pi_{\ast} \Omega^1_{E/S} \rightarrow \mathcal{H}^1_{\mathrm{dR}}(E/S) \rightarrow \mathrm{R}^1 \pi_{\ast} \mathcal{O}_E \rightarrow 0.
$$ Meanwhile, I saw that people often write short exact sequences like $$
0 \rightarrow \pi_{\ast} \Omega^1_{A/k} \rightarrow \mathcal{H}^1_{\mathrm{dR}}(A/k) \rightarrow \underline{\mathrm{Lie}}(A^{\vee}/k) \rightarrow 0. \quad (\star)
$$ But I cannot find a proof of $(\star)$ . Comparing the two, I am guessing some kind of result like $(\dagger)$ , so that I can deduce $(\star)$ from ""Hodge-to-de Rham"". Thank you so much for commenting and answering!","['algebraic-number-theory', 'abelian-varieties', 'reference-request', 'algebraic-geometry', 'modular-forms']"
4648724,Prove that the system of differential equation satisfies the given inequality.,"Given $x= (x_1, x_2)$ , and the following state equation: $$\dot{x_1} = -x_1+\frac{2x_2}{1+{x_2}^2}$$ $$\dot{x_2} = -x_2+\frac{2x_1}{1+{x_1}^2}$$ Show that the solution satisfies the inequality $$||x(t)||_2 \leq e^{-t}||x(0)||_2+\sqrt{2}(1-e^{-t})$$ I could only notice one thing which is that $(1+{x_i}^2)$ has derivative $2x_i$ . Not sure if it is helpful. The question has a hint that asks to use the comparison lemma, but I'm not sure how to solve this. Any help is appreciated.","['derivatives', 'ordinary-differential-equations', 'control-theory']"
4648729,Centered Hardy-Littlewood maximal functions for measures without full support,"I've seen the (centered) Hardy-Littlewood maximal function defined as follows: Let $X$ be a metric space, and $\mu$ a Borel measure on $X$ . For $f \in L^1(\mu)$ , define $$M^* f(x) : = \sup_{r > 0} \mu(B(x, r))^{-1} \int_{B(x, r)} f \mathrm{d} \mu .$$ Now my understanding is that the prototype for this is Euclidean space with the Lebesgue measure, which is of course fully supported (i.e. every nonempty open ball around any point will have positive measure). So I can see that this function is measurable as a function from $\operatorname{supp}(\mu)$ to $\mathbb{C}$ , and even continuous under some mild additional assumptions. But my question is how the maximal function is defined for $x \not \in \operatorname{supp}(\mu)$ . I assume the answer is supposed to be that $\mu(X \setminus \operatorname{supp}(\mu)) = 0$ , so we just follow the custom of throwing up our hands and shrugging off a null set because this is measure theory and we ignore null sets in measure theory, but it's not clear to me what conditions are needed to ensure that $\mu(X \setminus \operatorname{supp}(\mu)) = 0$ . The Wikipedia page on support says there are examples of nonzero Borel measures on compact Hausdorff spaces for which the support has measure $0$ . So how is the Hardy-Littlewood maximal function defined for measures without full support? Thanks!","['measure-theory', 'geometric-measure-theory']"
4648741,Can conditional expectation be used to prove the following result? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Let $X$ and $Y$ be two random variables. Is it possible to use the law of total expectation to say $$
\mathbb{E}[X - \mathbb{E}[X \mid Y]] 
= \mathbb{E}[\mathbb{E}[X - \mathbb{E}[X \mid Y] \mid Y]
= 0.
$$ It seems right but I believe I might be committing some crime. Thanks","['conditional-probability', 'conditional-expectation', 'probability-theory', 'probability']"
4648769,An explicit form for this differential equation.,"So I came across this differential equation: $$xyy'-y^2=(x+y)^2 e^{-y/x}$$ And I managed to simplify it this way: First I multiplied by $\frac1{xy}$ : $$y'-\frac{y}{x}=\left(\frac{x}{y}+2+\frac{y}{x}\right) e^{-y/x}$$ Then substituted $v = \frac{y}{x}$ sub to get: $$\begin{split}
v+xv'-v&=\left(\frac1v+2+v\right) e^{-v}\\
xvv'&=(1+2v+v^2) e^{-v}\\
xvv'&=(v+1)^2 e^{-v}
\end{split}$$ Which is separable. I then proceeded to separate and integrate both sides to get $$\frac{-e^v}{v+1}\ + e^v=\ln⁡(x)+c$$ or $$\frac{e^v}{v+1}\
=\ln⁡(x)+c$$ Is there a way to get a more explicit equation? Is there something wrong that I did?",['ordinary-differential-equations']
4648790,Distance between the point of touching in three touching circles,"$\textbf{Question : }$ Say you have three touching circles $\Gamma_1,\Gamma_2,\Gamma_3$ with radii $x,y,z$ and centers $A,B,C$ as per the diagram, then prove the following $$|DE|=\frac{2}{\sqrt{\left(\dfrac{1}{x}+\dfrac{1}{y}\right)\left(\dfrac{1}{x}+\dfrac{1}{z}\right)}}$$ $\textbf{My Attempt}$ Let $\angle{DAE} = \alpha, \angle{FBE}=\beta , \angle{FCD}=\pi-\alpha-\beta$ then through sine rule in the $\Delta ABC$ we can say $$\frac{\sin{\alpha}}{y+z}=\frac{\sin{\beta}}{z+x}=\frac{\sin{(\alpha+\beta)}}{x+y} $$ As we know $$|DE|=2x\sin\frac{\alpha}{2}$$ We just need to prove $$\sin\frac{\alpha}{2} = \dfrac{1}{x}\dfrac{1}{\sqrt{\left(\dfrac{1}{x}+\dfrac{1}{y}\right)\left(\dfrac{1}{x}+\dfrac{1}{z}\right)}}$$ So using the sine rule relation $$\sin\beta = \frac{z+x}{y+z} \sin \alpha$$ And again from the sine rule relation $$\sin \alpha = \frac{y+z}{x+y} \sin (\alpha+\beta)$$ Now substituting $\sin \beta$ in terms of $\sin \alpha$ $$\sin \alpha = \sin \alpha \cdot \sqrt{1-\left( \frac{z+x}{y+z}\sin \alpha \right)^2}+\sqrt{1-\sin^2 \alpha}\cdot \frac{z+x}{y+z}\sin \alpha  $$ $$1 =  \sqrt{1-\left( \frac{z+x}{y+z}\sin \alpha \right)^2}+\sqrt{1-\sin^2 \alpha}\cdot \frac{z+x}{y+z}$$ Now this is the step where I get stuck, it is simply too complicated to solve by hand for me at least. Maybe someone can suggest a way to solve this in reasonable time or even better a different approach...","['trigonometry', 'algebra-precalculus', 'circles', 'geometry']"
4648796,Doubt regarding cyclic group of prime power order,"Let $G=\langle x,y\rangle$ be a cyclic group of prime power order. Then is it true that $G$ is generated by either $x$ or $y$ ? What we tried: Let $G=\langle z\rangle.$ Then $x=z^m, y=z^n$ for some integer $m,n.$ So $G=\langle x,y\rangle=\langle z^{gcd(m,n)}\rangle=\langle z\rangle.$ This gives $gcd(m,n)=1.$ By given condition, the order of $z$ is $p^r,$ for some prime $p$ and integer $r.$ Need to show either $m$ or $n$ is 1.","['group-theory', 'cyclic-groups']"
4648839,Find the number of ways to arrange so that at least two are followed,"Suppose there is a sentence containing only sequences of three characters and nothing more. The three characters are $X,Y,Z$ and it is given that $X$ has occurred $a$ times, $Y$ has occurred $b$ times and $Z$ has occurred $c$ times in the sentence. What is the probability that a $X$ will  be followed by a $Y$ at least $2$ times $?$ This problem looks a bit complicated to me, so I decided to break it into some parts. At least $2$ times means, all cases $-$$($ exactly $0$ time $+$ exactly $1$ time $)$ The number of all cases are simply $$\binom{a+b+c}{a}\binom{b+c}{b}\binom{c}{c}$$ For the exactly $0$ times I'm able to think of a logic but it is hard to explain. I think that we should first select a $Z$ and fix it. Then we arrange $b$ $Y's$ and $(c-1)$ $Z's$ on one side of the fixed $Z$ and on other side put all the $X$ . One more is to put all the $X's$ between two $Z's$ and then do the rest of the arrangement. So you see I'm not been able to think of all such cases. One more is put all $Y's$ and then arrange rest such that no $X$ goes behind any $Y$ . For exactly $1$ I have similar incomplete cases. How to find all possible cases in each sub problem $?$ Any help is greatly appreciated.","['combinatorics', 'probability']"
4648880,Example of a martingale with non-independent increments and fixed variance,"I'm trying to come up with a martingale whose increments $\Delta_n = M_n - M_{n-1}$ are non-independent, and have fixed variance, $Var(\Delta_n) = k$ . Attempt 1 Initially I was thinking that $M_N = \sum_{i=1}^n Z_i$ where $Z_i \sim N(0,1)$ .  This results in increments with fixed variance $Var(\Delta_i)=Var(Z_n)=1$ .  However, I think that the increments in this case are independent. Attempt 2 In order to produce dependent increments it feels like something multiplicative might work.  For example $M_n = \prod_{i=1}^n Z_i$ where $Z_i \sim N(0,1)$ .  This approach results in dependent increments, but the variance of the increments seems pretty intractable, and certainly not fixed.","['stochastic-processes', 'probability-theory', 'martingales']"
4648900,"Is $\{(\mathbb R,\phi)\}$ a smooth atlas for $\mathbb R$, where $\phi(x)=\left\{ \begin{array}{ll} x & x<0, \\ 2x& x\geq0~? \end{array} \right.$","Is $\{(\mathbb R,\phi)\}$ a smooth atlas for $\mathbb R$ , where $\phi(x)=\left\{ \begin{array}{ll} x & x<0,  \\ 2x& x\geq0~? \end{array} \right.$ Let $M$ be a topological $ n $ -manifold. A coordinate chart (or just a chart ) on $ M $ is a pair $ (U, \varphi) $ , where $ U $ is an open subset of $ M $ and $ \varphi: U \rightarrow \widehat{U} $ is a homeomorphism from $ U $ to an open subset $ \widehat{U}=\varphi(U) \subseteq \mathbb{R}^{n} $ . If $ U $ and $ V $ are open subsets of Euclidean spaces $ \mathbb{R}^{n} $ and $ \mathbb{R}^{m} $ , respectively, a function $ F: U \rightarrow V $ is said to be smooth if each of its component functions has continuous partial derivatives of all orders. If in addition $ F $ is bijective and has a smooth inverse map, it is called a diffeomorphism . Two charts $ (U, \varphi) $ and $ (V, \psi) $ are said to be smoothly compatible if either $ U \cap V=\varnothing $ or the transition map $ \psi \circ \varphi^{-1} $ is a diffeomorphism. An atlas for $ M $ is a collection of charts whose domains cover $ M $ . An atlas $ \mathcal{A} $ is called a smooth atlas if any two charts in $ \mathcal{A} $ are smoothly compatible with each other. I have carefully checked the definition of each concept related to this question, but I have not found anything contrary to a certain definition. Although it is obvious that $\phi$ itself is not smooth, my understanding is that the atlas $\{(\mathbb R,\phi)\}$ has only a single coordinate chart $(\mathbb R,\phi)$ , and no other coordinate chart to determine whether it is smoothly compatible with $(\mathbb R,\phi)$ . So, is it a smooth atlas? This is a question out of curiosity. Any help would be appreciated.","['manifolds', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
4648938,"Evaluate $\int_{0}^{\pi/2}x\sin^a (x) dx$, $a>0$","I want to evaluate $$\int_{0}^{\pi/2}x\sin^a (x)\, dx$$ where $a>0$ is a real number. I tried: $$I(a)= \int_{0}^{\pi/2}x\sin^a(x)\,dx = \int_{0}^{1}\frac{\arcsin x}{\sqrt{1-x^2}}x^a\,dx$$ $$ I(a)=\sum_{m\geq 1}\frac{4^m}{2m\left(2m+a\right)\binom{2m}{m}}$$ $$I(a)=\frac{1}{a+2}\cdot\phantom{}_3 F_2\left(1,1,1+\tfrac{a}{2};\tfrac{3}{2},2+\tfrac{a}{2};1\right)$$ Any other method please. Any help will be appreciated. Thank you. edit The series expansion of $ \arcsin(x)^2$ is $$2\;\arcsin(x)^2=\sum_{n=1}^\infty \frac{(2x)^{2n}}{n^2\binom{2n}{n}}$$ Differentiating the above series we get the formula used in the question.","['integration', 'definite-integrals', 'real-analysis', 'calculus', 'hypergeometric-function']"
4648962,When will the moons and the planet all be on one straight line again?,"Suppose we have a planet $P$ (which we will assume to be stationary) and $n \in \mathbb N_{> 1}$ moons $M_1, \ldots, M_n$ orbiting $P$ in a circular fashion, all in the clockwise direction, but at different distances, so that it takes them $t_1, \ldots, t_n \in \mathbb N_{> 0}$ (say $t_1 < \ldots < t_n$ ) time units to circumnavigate $P$ , respectively.
Suppose that at time $t = 0$ , there is a straight line segment on which all moons and the planet lies.
What is the first time $t > 0$ that this will happen again? (We assume that $P, M_1, \ldots, M_n$ are points without any width, so they can't obstruct each other or influence each others positions in any other way.) The motivation for this question came from an easy question we conceived for 7-th graders: if we instead ask what the earliest time is that the moons will all be again at the same position, the answer is $\hat{t} := \text{lcm}(t_1, \ldots, t_n)$ , the least common multiple of all orbiting times. Unfortunately, it can happen that the planets lie on one line segment with the planet much earlier, even for $n = 2$ .
We couldn't figure out any line of attack for the difficult version of this question state above.
Maybe an a priori assumption that will simplify this problem is that all moons start off at the same side of the planet, i.e., the line segment $M_1, \ldots, M_n, P$ lie on does not intersect $P$ , it only touches it. I'd be also grateful for any improvements on the statement of the question, thanks to @Albert for the first suggestion in that direction.","['dynamical-systems', 'recreational-mathematics', 'real-analysis']"
4648987,Prove that $|f^{'''}|\le 48$ for an analytic function $f$,"Let $\Omega$ be an open connected subset of $\Bbb C$ containing $U=\{z\in \Bbb C : |z|\le 1/2\}$ and let, $$\mathscr F:=\{f:\Omega \to \Bbb C: f \text{ is analytic and } \sup_{z,w\in U}|f(z)-f(w)|=1\}$$ Then prove that, $|f^{'''}(0)|\le 48$ for all $f\in \mathscr F$ . We have by Cauchy's integral formula, \begin{align}
|f^{'''}(0)|&=\left|\frac{3!}{2\pi i}\int_U \frac{f(z)}{z^4}\,dz\right|\\
&\le \frac{6}{2\pi}\sup_{z\in U}|f(z)|\cdot 2^4\cdot 2\pi\cdot\frac 12\\
&=48 \sup_{z\in U}|f(z)|
\end{align} So, I have to prove $\sup_{z\in U}|f(z)|\le 1$ . How to prove this? Any help, please?","['complex-analysis', 'complex-integration', 'complex-numbers']"
4649000,Reference request: relationship between c-convexity and geodesic convexity on manifolds,"I am interested in a characterization of c-convex/c-concave functions (as in Definition 5.2 and Definition 5.7 in Cédric Villani's book, 'Optimal transport, old and new' ) on manifolds in the case when the cost function is the half squared distance, $c(x, y) = \frac{1}{2} \text{dist}^2(x, y)$ . In particular, in this comment it is mentioned that on a manifold of nonnegative sectional curvature, a c-convex function $f$ is 1-convex, i.e. $ g(t) = f(\gamma(t)) + \frac{t^2}{2} $ is convex, where $ \gamma $ is a unit speed geodesic. Does anyone know of a reference where this property is explored? Thank you!","['optimal-transport', 'convex-analysis', 'riemannian-geometry', 'differential-geometry']"
4649020,$L^1_{\operatorname{loc}}$ and weak $L^1$,"I think in general we cannot say whether $L^1_{loc}$ and $weak$ $L^1$ include each other or not, e.g. $f(x)=\frac{1}{x}$ and $f(x)=1$ are in $weak$ $L^1(\lambda)$ and $L^1_{loc}(\lambda)$ respectively, but not in the other space (for $\lambda$ the Lebesgue measure). My curiosity/question is if there are some sophisticated measure spaces where an inclusion can be made? E.g. I would say that in a finite measure space, $f(x)=1$ would be in weak $L^1$ as well, but a finite measure space is a rather trivial example since we are just making $L^1_{loc}$ be the same as $L^1$ , so we end up with $L^1_{loc}\subset weak\ L^1$ and nothing else since $f(x)=\frac{1}{x}$ would not necessarily be in $L^1$ . At least these are my current thoughts. Let me know if anything I said is wrong.",['measure-theory']
4649063,Why does the number of solutions for the $n$-Queen problem drop at $n = 6$ specifically?,"I was looking into determining the number of solutions to the $n$ -Queens problem, admittedly to study DFS for a course. During this study, I naturally found OEIS A000170 , which lists the number of solutions. The solution count for $n = 6$ stood out, as it seems to be the only value of $n$ for which the value drops from its previous iteration. Why does this specific board size seems to be so specific in its queen layout? Is there a nice mathematical explanation for this or is it just a neat coincidence? When $n=7,$ I think the latin squares provide $28$ of the examples, and there are $12$ others.","['soft-question', 'combinatorics', 'puzzle']"
4649064,The mathematical problem with beer,"A problem is given: $322$ mathematicians walk into a bar, numbered from $1$ to $322$ , each picks someone other than himself at random and writes down his number on a piece of paper. The barman names the first mathematician, he orders a beer for the one he has written on the slip, then the next mathematician in line comes to the barman who has not yet been ordered a beer, orders the one he has written on the slip and so on. How many mathematicians will be left without beer in the expectation? My attempt at a solution: Let's denote by $X_i$ a random variable that equals 1 if the $i$ th mathematician did not get a beer, and equals 0 if the $i$ th mathematician got a beer. We want to find the mathematical expectation of the number of mathematicians who will remain without beer $$\mathbb{E}\left [ \sum_{i=1}^{322}X_i \right ]=\sum_{i=1}^{322}\mathbb{E}[X_i]$$ Now we need to find the mathematical expectation of $X_i$ . Consider the $i$ th mathematician. The chance that he won't get a beer is equal to the probability that his name won't be written on a piece of paper by someone else. The probability that $i$ th mathematician will not be chosen by $j$ th mathematician is $\frac{321}{321}$ (since $j$ cannot choose himself). The probability that $i$ -th mathematician will not be chosen by any of the other $321$ -mathematicians is equal to: $$\left ( 1-\frac{1}{321} \right )^{321}$$ We can now find the mathematical expectation of $X_i$ : $$\mathbb{E}[X_i]=1\cdot \left ( 1-\frac{1}{321} \right )^{321}+0\cdot \left ( 1-\left ( 1-\frac{1}{321} \right )^{321} \right )\approx 0,368$$ On average about $0,368 \cdot 322 \approx 118,6$ of maths will be left without beer. The answer is $\boxed{119}$ I'm not at all sure about the decision. Could you tell me if I have solved it correctly ?","['expected-value', 'probability-theory', 'probability']"
4649072,Dividing by Trig Functions [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question I'm sorry if this is very simple, but I am a little confused. I have an equation which is $-2\times \cos(2x) \times f(x)=0$ . Am I able to simple divide both sides by $-2\times \cos(2x)$ ? I'm not sure if this is helpful, but $f(x) = y - a_0 - a_2\cos(2x) - b_2\sin(2x) - a_4\cos(4x) - b_4\sin(4x)$",['trigonometry']
4649102,Integral with cosine in the denominator and undefined boundaries,I am trying to solve the integral $$ \int_0^{\frac{3}{2}\pi}\frac{1}{\frac{5}{2}+\cos(2x)}dx $$ And I get the primitive function to be $$     \frac{2\arctan\left(\sqrt{\frac{7}{3}}\tan{x}\right)}{\sqrt{21}} $$ But $\tan(\frac{3}{2}\pi)$ is not defined. Mathematica gets the same primitive function and can solve it when using the given boundaries. How do I handle the boundaries?,"['integration', 'definite-integrals', 'calculus', 'trigonometric-integrals', 'trigonometry']"
4649119,"Can the function $\max(x,y,z)$ be expressed in terms of absolute values (not nested)?","Q1: Are there some linear forms $a_ix+b_iy+c_iz$ and signs $\sigma_i\in\{1,-1\}$ such that $$\max(x,y,z)=(a_0x+b_0y+c_0z)+\sum_{i\geq1}\sigma_i|a_ix+b_iy+c_iz|$$ for all $x,y,z\in\mathbb R$ ? Q2: Same question for $\max(|x|,|y|,|z|)$ . For the analogous questions with only two variables, the answers are $$\max(x,y)=\frac{x+y}{2}+\left|\frac{x-y}{2}\right|$$ and $$\max(|x|,|y|)=\left|\frac{x+y}{2}\right|+\left|\frac{x-y}{2}\right|$$ Show that the $\max{ \{ x,y \} }= \frac{x+y+|x-y|}{2}$. And the two-variable case can be applied to the three-variable case: $$\max(x,y,z)=\max(\max(x,y),z)$$ $$=\frac{\frac{x+y+|x-y|}{2}+z+\left|\frac{x+y+|x-y|}{2}-z\right|}{2}$$ $$=\frac{x+y+2z}{4}+\left|\frac{x-y}{4}\right|+\left|\frac{x+y-2z}{4}+\left|\frac{x-y}{4}\right|\right|$$ But this has nested absolute values, which I don't want. I did find an approximate formula, which is exact when one of the variables is $0$ or when all are equal: $$\max(|x|,|y|,|z|)\approx$$ $$-\tfrac13\Big(|x|+|y|+|z|\Big)\\+\tfrac16\Big(|x+y|+|x-y|+|x+z|+|x-z|+|y+z|+|y-z|\Big)\\+\tfrac16\Big(|x+y+z|+|x+y-z|+|x-y+z|+|x-y-z|\Big)$$","['maxima-minima', 'inequality', 'functions', 'absolute-value']"
4649148,Are there an infinity of consecutive primes that have no common digit?,"Examples: $2$ & $3$ , $3$ & $5$ , $5$ & $7$ , $59$ & $61$ , $99999989$ & $100000007$ . I was inspired by the fact that, in English, all consecutive numbers share a common letter, such as seven & eight that share 'e'. See Alex Bellos's Math Puzzle section https://www.theguardian.com/science/2023/feb/20/did-you-solve-it-thats-mathematics . Instead I consider consecutive primes and their base representation. Except for $2$ & $3$ , $3$ & $5$ and $5$ & $7$ all such base- $10$ consecutive primes are of the form: $a \times 10^n - b$ and $a \times 10^n + c$ with $1 \le a\le 8$ . It is easy to show that $a$ cannot be $9$ .
I found $701$ cases below $10^{500}$ . A large example is $1 \times 10^{101}-203\ \ $ & $\ \ 1 \times 10^{101}+3$ and a larger example (with probable primes) is $8 \times 10^{5002}-6243\ \ $ & $\ \ 8 \times 10^{5002}+14481$ . I am pessimistic that the conjecture can be easily proved.
Landau's conjecture that there are infinitely many primes $p$ of the form $p=n^2+1$ remains open. For other bases: in base $2$ there are no such consecutive primes.
In base $3$ it is easy to show that there are none, except $2$ & $3$ .
Base $4$ is the first interesting base.
All cases must be of the form $4^n - b$ and $4^n + c$ (except for $2$ & $3$ ).
I found only $5$ cases with $n$ = $1$ , $4$ , $28$ , $83$ and $1816$ . EDIT : Replaced ""disjoint"" with the more standard ""have no common digits"". See the result for squares in oeis.org/A156981","['number-theory', 'recreational-mathematics', 'conjectures', 'prime-numbers']"
4649180,"Rudin's RCA, Theorem $4.15$","There is   the  definition which we need for $4.15$ There is the theorem : There is $4.15$ : We want to drop the finiteness condition that appears in Theorem $4.14$ without even restricting ourselves to sets that are necessarily countable. For this reason it seems advisable to clarify the meaning of the symbol $\sum_{\alpha \in A} \varphi(\alpha)$ when $\alpha$ ranges over an arbitrary set $A$ . Assume $0$ $\leq$ $\varphi(\alpha)$ $\in$ $\infty$ for each $\alpha$ $\in$ $A$ . Then $\sum_{\alpha \in A} \varphi(\alpha)$ denotes the supremum of the set of all finite sums $\varphi(\alpha_1)$ $+$ ... $+$ $\varphi(\alpha_n)$ , where $\alpha_1$ ,... $\alpha_n$ are distinct members of $A$ . A moment's consideration will show that the sum $\sum_{\alpha \in A} \varphi(\alpha)$ is thus precisely the Lebesgue integral of $\varphi$ relative to the counting measure $\mu$ on $A$ . I don't understand why is the sum $\sum_{\alpha \in A} \varphi(\alpha)$ the Lebesgue integral of $\varphi$ relative to the counting measure $\mu$ on $A$ . Any help would be appreciated.","['measure-theory', 'orthonormal', 'lebesgue-integral', 'vector-spaces', 'hilbert-spaces']"
4649300,Strong law of large numbers and triangular array,"I have a problem from probability theory that I have encountered and I am not getting anywhere in terms of ideas that may help me solve it. Suppose $\{X_{n, i}\}_{1 \leq i \leq n, n \geq 1}$ are mutually independent
with a common marginal distribution, given by $P\left(X_{1,1}=n\right)=R n^{-3}$ for every $n \geq 1$ , where $R$ is the normalizing constant. Let $S_{n}=\sum_{i=1}^{n} X_{n, i}$ . Show that $E\left|X_{1,1}\right|<\infty$ , but $\limsup \frac{S_{n}}{n}=\infty$ almost surely The expectation is found with simple algebra, however, when I am trying to determine that $\limsup \frac{S_{n}}{n}=\infty$ I go blank. I originally thought of considering as $A_n$ the set where $\frac{S_n}{n}$ is greater than $n$ , that is $P(A_n)=P(\frac{S_n}{n}>n)$ . Then I was thinking that if we could consider the infinite sum $\sum_{n=1}^{\infty}P(A_n)$ and show that this diverges, we can apply the Borel-Cantelli lemma. I don't really know how to obtain a convenient lower bound for $P(A_n)$ for this problem since what I have used before is Markov's inequality, but when using it here we would be with an upper bound. I am only looking for a hint as to what may be useful to approach this question.","['statistics', 'analysis', 'real-analysis', 'law-of-large-numbers', 'probability-theory']"
4649301,Is Hahn-Banach equivalent to the ultrafilter lemma in ZF,"I know that the ultrafilter lemma is weaker than the axiom of choice (in ZF)
And that in order to prove Choice in ZF from the ultrafilter lemma we need the Krein-Milman theorem
so $UF+KM=AC$ Furthermore, I know the Hahn-Banach theorem is weaker than choice but in order to get choice from the Hahn-Banach theorem we need (again) Krein-Milman (in ZF). so $HB+KM=AC$ . (And I please complete ignorance of mathematical logic but...)
Doesn't that imply that the Hahn-Banach theorem is logically equivalent to the ultrafilter lemma in ZF? Or if not, does it then imply that we can use a statement that is weaker than Krein-Milman (call such a statement $S$ ) such that $UF+S=AC$ ? So the question is either is $HB=UF$ or if not, what is $S$ ?","['logic', 'filters', 'functional-analysis', 'axiom-of-choice', 'hahn-banach-theorem']"
4649302,Conducting a Proof Sequence - Discrete Mathematics,"I am having trouble conducting this proof sequence. Here are the premises: p -> (q v r) ~q ~r ~p ^ ~ r So far, I have this: p -> (q v r) - Premise ~q - Premise ~r - Premise ~(q v r) - implication, 1 ~q ^ ~r - De Morgan's Law, 4 ~r ^ ~q - commutativity, 5 ~r - simplification, 6 p -> (~r) - ??? ~p - Modus Tollens, 8, 3 ~p ^ ~r - conjunction, 9, 3 Is this sequence correct? I have a hard time understanding the use of implication and when/when not to apply it. My thoughts are using it whenever the disjunction is seen. Any help is greatly appreciated. Thank you!","['logic', 'discrete-mathematics']"
4649308,(When) does $\text{body force}=\text{pressure gradient}=0\neq\text{fluid velocity}\implies0<\text{drag}$?,"I'm working on an unassessed course problem, A cylinder with radius $a_1$ moves parallel to its axis with constant positive velocity $U$ inside a stationary coaxial cylinder with radius $a_2(> a_1)$ . The region between the cylinders is filled with incompressible fluid. Assume that body forces can be ignored and that the pressure gradient in the direction parallel to the axis is zero. If the velocity in the fluid is in the direction of the axis, determine how it varies in the radial direction. I'm used to solving problems where (in)viscidity and/or steadiness are given, but here neither is. It would be convenient if I could reason as follows. Does this make sense? \begin{align}
& \begin{aligned}
\text{Let}&\\
& \vec{F}\text{ be body force per unit mass,} \\
& \vec{F}_D\text{ be drag per unit area,} \\
& \vec{u}\text{ be fluid velocity,} \\
& p\text{ be pressure,} \\
& \mu\text{ be viscosity;}
\end{aligned} \\[1em]
& \text{we have }\vec{F}=\vec{0},\;\frac{\partial p}{\partial z}=0\text{, but }0<u_z \\
\therefore\;&\text{we must have }\vec{F}_D\neq\vec{0}\text{ on the cylinder wall(s)} \tag{$\ast$} \\
\therefore\;&\text{we must have }0<\mu \\
\therefore\;&\text{by the no-slip condition, we must have } (u_z)_{r=a_1}=U\text{, a constant} \\
\therefore\;&\text{we must have }\frac{\partial u_z}{\partial t}=0 \\
\therefore\;&\text{by Navier-Stokes, (etc.)}
\end{align} It's mainly $(\ast)$ I'm wondering about.","['physics', 'multivariable-calculus', 'classical-mechanics', 'fluid-dynamics']"
4650321,Question on Hartshorne exercise II 5.17(e),"I'm trying to solve exercise II 5.17(e) of Hartshorne: Let $f:X\to Y$ be an affine morphism between schemes (i.e. preimage of every open affine subscheme of $Y$ is still affine), and let $\mathcal{A}=f_* \mathcal{O}_X$ .  Show that $f_*$ induces an equivalence of categories from the category of quasi-coherent $\mathcal{O}_X$ -modules to the category of quasi-coherent $\mathcal{A}$ -modules (i.e. quasi-coherent $\mathcal{O}_Y$ -modules having a structure of $\mathcal{A}$ -module). In order to prove this question, it suffices to construct a quasi-coherent $\mathcal{O}_X$ -module $\widetilde{\mathcal{M}}$ for any quasi-coherent $\mathcal{A}$ -module $\mathcal{M}$ , and show the functors $f_*$ and $\tilde{}$ are inverse to each other. I am trying to construct $\widetilde{\mathcal{M}}$ by gluing sheaves: Since $\mathcal{M}$ is a quasi-coherent $\mathcal{A}$ -module, $\mathcal{M}(U)$ has an $\mathcal{A}(U)=\mathcal{O}_X(f^{-1}(U))$ - module structure. Then we have a sheaf $\widetilde{\mathcal{M}(U)}$ on affine open subset $f^{-1}(U)$ .  To glue up all these $\widetilde{\mathcal{M}(U)}$ , we only need to check that, when $U'\subset U$ are open affine subsets, $\widetilde{\mathcal{M}(U)}|_{f^{-1}(U')}\simeq \widetilde{\mathcal{M}(U')}$ .  I am stuck here, and my attempt is as follows : Let $U=\operatorname{Spec}B,U'=\operatorname{Spec}B',f^{-1}(U)=\operatorname{Spec}A,f^{-1}(U')=\operatorname{Spec}A'$ . $$\require{AMScd}
\begin{CD}
f^{-1}(U)=\operatorname{Spec}A @>{f_U}>> \operatorname{Spec}B=U\\
@AAA @AAA \\
f^{-1}(U')=\operatorname{Spec}A' @>{f_{U'}}>> \operatorname{Spec}B'=U'
\end{CD}$$ $$\require{AMScd}
\begin{CD}
B=\mathcal{O}_Y(U) @>>> \mathcal{O}_X(f^{-1}(U))=A\\
@VVV @VVV \\
B'=\mathcal{O}_Y(U') @>>> \mathcal{O}_X(f^{-1}(U'))=A'
\end{CD}$$ Since $\mathcal{M}$ is a quasi-coherent $\mathcal{A}$ -module, $\mathcal{M}(U)$ has a $\mathcal{O}_Y(U)=B$ -module structure via ring homomorphism $B=\mathcal{O}_Y(U)\to \mathcal{O}_X(f^{-1}(U))=A$ . Then $\mathcal{M}$ is a quasi-coherent $\mathcal{O}_Y$ -module implies that $\mathcal{M}|_U\simeq {f_U}_*(\widetilde{\mathcal{M}(U)})\simeq \widetilde{_B\mathcal{M}(U)}$ , where $f_U:f^{-1}(U)=\operatorname{Spec}A\to\operatorname{Spec}B=U$ .  Similarly, we have $\mathcal{M}|_{U'}\simeq \widetilde{_{B'}\mathcal{M}(U')}$ .  Since $\mathcal{M}$ is quasi-coherent $\mathcal{O}_Y$ -module, $(\mathcal{M}|_U)|_{U'}\simeq \widetilde{B'{\otimes{_B}_B}{\mathcal{M}(U)}}\simeq \mathcal{M}|_{U'} \simeq \widetilde{_{B'}\mathcal{M}(U')}$ , which implies that $B'\otimes{_B} _B{\mathcal{M}(U)}\simeq {_{B'}\mathcal{M}(U')}$ . Similarly, $\widetilde{\mathcal{M}(U)}|_{f^{-1}(U')}\simeq \widetilde{\mathcal{M}(U')}$ is equivalent to $A'\otimes_A \mathcal{M}(U)\simeq \mathcal{M}(U')$ , but how can we get this from $B'\otimes{_B} _B{\mathcal{M}(U)}\simeq {_{B'}\mathcal{M}(U')}$ ? Edit It seems that the most important fact in my proof is that, ${f_{U'}}_*(\widetilde{\mathcal{M}(U')})\simeq {f_U}_*(\widetilde{\mathcal{M}(U)})|_{U'}\simeq {f_{U'}}_*(\widetilde{\mathcal{M}(U)}|_{f^{-1}(U')})$ .  But how can we get $\widetilde{\mathcal{M}(U)}|_{f^{-1}(U')}\simeq \widetilde{\mathcal{M}(U')}$ ?","['algebraic-geometry', 'schemes']"
4650371,Negative Log inside Negative Log,"Is there a name for a function which is like $f(x)=-\log(-\log(x))$ where $0<x<1$ ? Or, is there any name for this function $g(x)=x+\log(\frac{1}{x})$ where $0<x$ ? Exchanging $x=-\log k$ in $g(x)$ gives $f(k)$ and I would like to know about those functions any deeper, but I am having trouble searching about them. If there are any specific name or related function that I can search for, I will be very glad to know.","['functions', 'logarithms']"
4650378,Drawing from a uniform distribution,"Suppose I have an unlimited number of draws from a uniform distribution [0,1]. I want to keep on drawing until the sum of all my a values >=x (where 0<x<1). I want to find the probability that my score ends between x and 1 when trying to do this and when it does, the expected value of my score. Obviously the percentage chance of 'busting' is just 1 - the chance that my score is between x and 1. Intuitively, I'm tempted to say that when my score is between x and 1, on average it is halfway between x and 1, but I'm not 100% positive on that. I looked at some other forums and found some things that seemed like they were kind of similar, but I wasn't quite sure where to take it from there. I looked at this: Irwin Hall distribution with varying n right now this is where I'm at, I sum up from n=1 to n=inf $$\frac{(n-z) z^{n-1}}{n!}$$ but for each n here I need to subtract the probability that the sum made it to over 1 for that n and I need to figure out how to find out that out... for n draws out of a uniform distribution, I believe the probability that the sum is less than 1 is 1/n! but I can't just multiply what I have by 1/n! for each sum in the series because that would be 'overcounting' some of the area.","['uniform-distribution', 'probability']"
4650409,How can I show that this set has measure 0?,"The Problem Suppose I have the measurable set $$E = \bigcup_{n = 1}^\infty\bigcap_{k = n}^\infty E_k$$ where $E_k \subseteq \mathbb{R}^d$ is measurable for all $k$ . I want to prove that if $\sum_{k = 1}^\infty m(E_k) < \infty$ then $m(E) = 0$ . What I tried I think it can be shown that $$E = \bigcup_{n = 1}^\infty\bigcap_{k = n}^\infty E_k \subseteq \bigcap_{n = 1}^\infty\bigcup_{k = n}^\infty E_k$$ Next let $B_N = \bigcup_{k = N}^\infty E_k$ . Clearly since the sets may not be disjoint, $$m(B_N) \leq \sum_{k = N}^\infty m(E_k)$$ and since $\sum_{k = 1}^\infty m(E_k) < \infty$ then for all $\epsilon > 0$ there exists $N$ such that $$m(B_N) \leq \sum_{k = N}^\infty m(E_k) < \epsilon$$ Furthermore, it's not hard to see that $\bigcap_{n = 1}^\infty B_n \subseteq B_N$ , so $$m(E) \leq m\left(\bigcap_{n = 1}^\infty\bigcup_{k = n}^\infty E_k\right) \leq m(B_N) < \epsilon$$ Since $\epsilon > 0$ , then $m(E) = 0$ . Have I missed anything? If so, how can I correct it? Thanks in advance!","['measure-theory', 'lebesgue-measure', 'analysis']"
