question_id,title,body,tags
1668804,"Show that for any positive integer $n$ there is $x \in [0,1-\frac{1}{n}]$ for which $f(x) = f(x+\frac{1}{n})$","Suppose $f$ is a continuous function over $[0,1]$ such that $f(0) = f(1).$ Show that for any positive integer $n$ there is $x \in [0,1-\frac{1}{n}]$ for which $f(x) = f(x+\frac{1}{n})$. We seem to be saying that $f(x+\frac{1}{n})$ is periodic with respect to any positive integer $n$. Also this seems to make sense since we start and end at the same spot there have to be values of $x$ with the same $f(x)$ as other $x$'s. But I am struggling to see how to prove this specific statement.",['calculus']
1668835,$C^{\infty}_{loc}$-convergence,"Let $\Omega \subset \mathbb{R}^{n}$ be some open set. Let $f_{n},f\in C^{\infty}(\Omega)$. My question is: What does the following phrase mean? $f_{n}$ converges to $f$ in $C^{\infty}_{loc}(\Omega)$. What is the exact definition of such a convergence.","['functional-analysis', 'real-analysis', 'analysis', 'functions']"
1668836,"Convex combination of independent random variables, that minimizes the $p$th moment","Suppose  $V$ and $W$ are independent. Let \begin{align} f(x)=E[
 ((1-x)V+xW )^p] \end{align} for $x \in [0,1]$ and some even $p \ge 2$.
  Find  \begin{align} \min_{0 \le x \le 1} f(x) \end{align} Also, suppose that $E[W^{2n+1}]=0$ for $2n+1 <p$, that is all odd
  moments of $W$ are zero. (I think this should simplify this a little
  bit) Solution, to some of the cases can be done by expanding and taking the derivative. Case of $p=2$
\begin{align}
E[ ((1-x)V+xW )^2]= (1-x)^2 E[V^2]+x^2 E[W^2]
\end{align} 
it is not difficult to check that the minimizing $x= \frac{E[V^2]}{E[V^2]+E[W^2]}$  and the minimum value is given by
\begin{align}
\min_{x\in [0,1]} f(x) =\frac{E[V^2]E[W^2]}{E[V^2]+E[W^2]}
\end{align} Case of $p=4$ \begin{align}
E[ ((1-x)V+xW )^2]= (1-x)^4 E[V^4]+6x^2(1-x)^2E[V^2]E[W^2]+x^4 E[W^4]
\end{align} and one must solve
\begin{align}
-4(1-x)^3 E[V^4]+6E[V^2]E[W^2] (2x-5x+x^3)+4x^3E[W^4]=0
\end{align}
which I guess can be done. But this procedure becomes increasingly complicated. Are there any other techniques on how to approach this problem?
I also feel that this should have come up in some applications? Here is also an example when the problem can be solve in general The problem can be solved if $V \sim \mathcal{N}(0,\sigma_v^2)$ and $V \sim \mathcal{N}(0,\sigma_w^2)$. Since,
\begin{align} E[
 ((1-x)V+xW )^p] =E \left[(  \sqrt{(1-x)^2\sigma^2_V+x^2\sigma^2_W} Z )^p \right] = ((1-x)^2\sigma^2_V+x^2\sigma^2_W)^{p/2} E[Z^p]
\end{align} 
where $Z$ is standard norma. It is not difficult to check that the expression is minimized by  $x=\frac{\sigma_V^2}{\sigma_V^2+\sigma_W^2}$ (same as for $p=2$) and we get that
\begin{align}
\min_{x \in [0,1]} f(x)= \frac{(\sigma_V^2\sigma_W^2)^{p/2}}{(\sigma_V^2+\sigma_W^2)^{p/2}} E[Z^p]
\end{align} Upper Bound We can derive the following upper bound on the problem by using value inspired optimal value for $p=2$ and triangle (Minkowski) inequality. We use $x=\frac{E^{2/p}[V^p]}{(E^{2/p}[V^p]+E^{2/p}[W^p])}$
\begin{align}
 \min_{x\in [0,1]} E[ ((1-x)*V+x W )^p ] &\le  \frac{ E \left[ (E^{2/p}[W^p] V +E^{2/p}[V^p] W )^p \right])}{ (E^{2/p}[W^p]+E^{2/p}[V^p])^p}  \\
&\le   \frac{ \left(E^{2/p}[W^p] E^{1/p}[V^p] +E^{2/p}[V^p] E^{1/p}[W^p] \right)^p }{ (E^{2/p}[W^p]+E^{2/p}[V^p])^p}\\
&= \frac{E[W^p]E[V^p] ( E^{1/p}[W^p]+E^{1/p}[W^p])^p}{(E^{2/p}[W^p]+E^{2/p} [V^p])^p}\\
& \le 2^p  \frac{E[W^p]E[V^p]}{(E^{2/p}[W^p]+E^{2/p} [V^p])^{p/2}}
\end{align}","['expectation', 'probability-theory', 'probability', 'optimization']"
1668838,"If $f(3x)=f(x)+f(3)$, prove that","If $$f(3x)=f(x)+f(3),$$prove that : $$f(1)=0\\f(3)=0\\f(9)=0\\f(27)=0$$ My attempt:
Here:
$$f(3x)=f(x)+f(3)$$
If $$x=1$$ $$f(3\times 1)=f(1)+f(3)$$
$$f(1)=0$$.
I got the first one but how should I prove the rest?",['functions']
1668856,Flat non-trivial $U(1)$-bundle? Is it possible?,"maybe this is a very stupid question and I'm missing something very trivial. It's well known that $U(1)$-bundles are classified by the Euler class or the first Chern class. More precisely, the isomorphism $$c: \check{H}^1 (X, \mathscr{C}^{\infty} (-, U(1))) \xrightarrow{\sim} H^2 (X, \mathbb{Z})$$, induced by the exact sequence $0 \rightarrow \mathbb{Z} \rightarrow \mathbb{R} \xrightarrow{exp} U(1) \rightarrow 0$, the sheaf isomorphism $\mathscr{C}^{\infty} (-, \mathbb{Z}) \cong \mathbb{Z}_X$ and the isomorphism from \v{C}ech to singular cohomology (or de Rham cohomology with integral periods), is the first Chern class or the Euler class. It's well known too that the first Chern class is given by $$[\frac{1}{2\pi i}F_{\nabla}]$$. This equality can be accomplished by using that the first Chern class is equal to the Euler class, the global angular form $\psi$ restricts to the Maurer-Cartan form on each fiber and every connection is of the form $\psi + \pi^{*} \alpha$ for some $\alpha \in \Omega^1 (X, \mathfrak{u}(1))$, where $\pi: P \twoheadrightarrow X$ is the $U(1)$-bundle 1) From these two remarks, one can conclude that if $F_{\nabla} = 0$ on some circle bundle $P$, then $c_1 (P) = 0$ and, therefore, $P$ is trivial. However it's well known too that in the theory of Cheeger-Simons  differential characters $$H^1 (X, U(1))$$ classifies flat $U(1)$-bundles with connection by assigning the holonomy $$\text{Hol}_{\nabla} (z) = \langle c, z \rangle$$ for every $z \in Z^1 (X, \mathbb{Z})$ to each $[c] \in H^1 (X, U(1))$ and using the canonical pairing coming from the fact that $U (1)$ is divisible and, hence, $H^1 (X, U(1)) = \text{Hom} (H_1 (X, \mathbb{Z}), U(1))$. 2) Therefore it may exist non-trivial bundles with flat connection whenever the first cohomology does not vanish. Having this in mind, why there's a non-trivial flat $U(1)$-bundle? In other words, what's wrong in my conclusions in 1 and 2? Thanks in advance.","['algebraic-topology', 'principal-bundles', 'holonomy', 'differential-geometry']"
1668906,Determinant of a block matrix including non-square matrices,"I am trying to find a nice way of computing the determinant of the matrix \begin{equation}
M=
\begin{bmatrix}
A & B \\ C & D
\end{bmatrix} \in \mathbb{R}^{T\times T}
\end{equation} where $A \in \mathbb{R}^{M\times N}$, $B \in \mathbb{R}^{M\times (T-N)}$, $C \in \mathbb{R}^{(T-M)\times N}$ and $D \in \mathbb{R}^{(T-M)\times (T-N)}$. Furthermore, $(A)_{i,j} = f_i(x_j)$, $(C)_{i,j} = g_i(x_j)$ where $f$ and $g$ are differentiable functions. I know there are nice ways to compute it when either $A$ or $D$ are invertible but is there a way to do it in the more general case above? When $A$ is invertible, 
$$|M|=|A||D-CA^{-1}B|$$
 A similar formula holds when $D$ is invertible. The question is specifically if such formulas can be extended to give $|M|$ in the case where neither $A$ nor $D$ is invertible (indeed, both could be non-square).","['matrices', 'linear-algebra', 'determinant']"
1668919,Why is the Haar measure of a Lie group with finite abelianization both left and right translation invariant? (Moved from math.SE),"I'm reading Foundations of Hyperbolic Manifolds by Ratcliffe. On the way to proving Gromov's theorem on the proportionality of hyperbolic volume and simplicial volume, he states that ""it is a basic fact of the theory of Haar measure that the Haar measure on a group is both left- and right-invariant if the abelianization of the group is finite."" Why should this be?","['measure-theory', 'lie-groups']"
1668992,"Is a bounded, linear, nonnegative and symmetric operator with finite trace on a Hilbert space Hilbert-Schmidt?","Let $U=(U,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a separable Hilbert space and $\left\|\;\cdot\;\right\|$ be the norm induced by $\langle\;\cdot\;,\;\cdot\;\rangle$ $Q$ be a bounded, linear, nonnegative and symmetric operator on $U$ with finite trace I've read that we can conclude that $Q$ is Hilbert-Schmidt, but I'm quite sure that this is wrong. By the Hilbert-Schmidt theorem , there is an orthonormal basis $(e_n)_{n\in\mathbb N}$ of $U$ with $$Qe_n=\lambda_ne_n\;\;\;\text{for all }n\in\mathbb N\tag 1$$ for some $(\lambda_n)_{n\in\mathbb N}\subseteq[0,\infty)$. Since $Q$ has finite trace, $$\sum_{n\in\mathbb N}\lambda_n\stackrel{(1)}=\sum_{n\in\mathbb N}\langle Qe_n,e_n\rangle<\infty\tag 2\;,$$ but the square of the Hilbert-Schmidt norm of $Q$ is equal to $$\sum_{n\in\mathbb N}\left\|Qe_n\right\|^2\stackrel{(1)}=\sum_{n\in\mathbb N}\lambda_n^2\tag 3\;.$$ Maybe we can show that $\sum_{n\in\mathbb N}\lambda_n^2<\infty$, but I don't think so. Am I missing something or does someone know a counter-example?","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
1669007,How many ways in which distinct people can get off a train,"I've been learning probability recently but I'm having trouble solving this question: Suppose you have 50 people on a train and you have 4 stations you can get off at (call them Stations 1,2,3,4). If no one boards the train at any of these stations, in how many ways can the 50 people get off the train, assuming the people are distinguishable (I care who gets off where)? If I didn't care who gets off where, then using stars and bars it would simply be 54 choose 3. But the problem for me arises in thinking when they're distinguishable. Right now my logic was for each of the 54 choose 3 ways, you can permute the groups among themselves in 4! ways. I'm pretty sure that's not right, but I don't know where to go.","['combinations', 'combinatorics', 'probability']"
1669064,Show that $f'(0)= \lim_{\Delta x \to 0}\frac{f(\Delta x)-1}{\Delta x} = 1$,"This question is related to another question I asked here . Specifically, using the definition of $e$ I gave in that question: There exists a unique complex function $f$ such that $f(z)$ is a single valued function $f(z) \in \mathbb{R}$ whenever $z \in \mathbb{R}$ and $f(1) = e$ $\forall z_{1}, z_{2} \in \mathbb{C}$ , $f$ satisfies $f(z_{1} + z_{2}) = f(z_{1})f(z_{2})$ $f$ is complex differentiable for all $z \in \mathbb{C}$ . Essentially, what I'm doing in the problem linked here is trying to prove that for $f$ such a function as meets those three criteria, $f^{\prime}(0) = 1$ . The $f$ I am hoping to get eventually is $f(z) = e^{z}$ , but that is what I am trying to prove; I cannot use anything specifically about $e^{z}$ here, only what is provided here in our definition of the function $f$ . Eventually, I was able to show that $f^{\prime}(0) = \lim_{\Delta z \to 0} \frac{f(\Delta z)-f(0)}{\Delta z} = f(0) \lim_{\Delta x \to 0} \frac{f(\Delta x) - 1}{\Delta x}$ . But, I don't know how to go any further! I need to show that $f'(0) = \lim_{\Delta x \to 0} \frac{f(\Delta x)-1}{\Delta x} = 1$ . Other people have posted similar questions to this on here, but they haven't been answered particularly well. I can't assume anything about $e^z$ , nor can I use anything like L'Hopital's rule, or logarithms, or series expansions. This is probably very very simple. Even an $\epsilon$ - $\delta$ proof would be good, if you could write the whole thing out. I tried that route and I wasn't able to make any progress. Please help!!","['derivatives', 'complex-numbers', 'exponential-function', 'complex-analysis', 'epsilon-delta']"
1669065,Translation of logic terms into set unions and intersections (e.g. uniform and pointwise convergence),"By logic formula of pointwise convergence:
$$(\forall \varepsilon>0) (\forall x\in S) (\exists n_0) (\forall n>n_0) (|f_n(x)-f(x)|<\varepsilon)$$ It can be interpreted by set theroy, for example:
$$\cup_{m}\cap_{n} \cap_{n_0(m,n)}E_{n,m}$$ where $E_{n,m}={\{x~|~~|f_n(x)-f(x)|<1/m}\}$ However, by the logic formula of uniform convergence:
$$(\forall \varepsilon>0) (\exists n_0) (\forall x\in S) (\forall n>n_0) (|f_n(x)-f(x)|<\varepsilon)$$ the set is (if I am not wrong):
$$\cup_{m}\cap_{n_0(m)}E_{n,m}$$ I know the order of $(\forall n_0)(\exists x), $
$(\exists x)(\forall n_0)$ makes the uniform and pointwise convergence differently. 
However, as in the example of pointwise convergence, the formula can be translated one by one literally when taken the term ($\forall x)$ and translate the formula mechanically, however, it is not in the uniform case and need a second thought. So my question is why the insetsection of $\cap_{n_0}$ missing from the formula.
I am confused that how to translate the (proper that can be translated) logic formula into exact set unions and intersections mechanically and correctly, especially in the occasions of the real  in analysis / measure theory.","['real-analysis', 'uniform-convergence', 'logic', 'measure-theory', 'elementary-set-theory']"
1669121,Show that $lim_{n \rightarrow \infty}m(O_n)=m(E)$ when $E$ is compact.,"Below is an attempt at a proof of the following problem. Any feedback would be greatly appreciated. Thx! Let $E$ be a set and $O_n = \{x: d(x, E) < \frac{1}{n}\}$ . Show If $E$ is compact then $m(E) = lim_{n \rightarrow \infty} m(O_n)$ . This is false for $E$ closed and unbounded or $E$ open and bounded. Note that all sets are real and measurable refers to Lebesgue measurable. Suppose $E$ is compact. Then $m(E) < \infty$ . Also, since each $O_n$ is an open set of $\mathbb{R}^d$ , $m(O_n) < \infty$ . If either of the following is true, we have that $lim_{n \rightarrow \infty}m(O_n)=m(E)$ : $O_n \nearrow E$ $O_n \searrow E$ Now $\bigcap_{n=1}^{\infty} O_n = \{ x:d(x,E) = 0\}$ . That is, $x \in \bigcap_{n=1}^{\infty}O_n \iff \exists n> \frac{1}{\epsilon},\ n \in \mathbb{N} \iff x\in \{x \mid d(x,E) =0\}$ . Then we have that $\bigcap_{n=1}^{\infty}O_n = E$ and $O_n \searrow E$ . Thus $ \ m(E) = lim_{n \rightarrow \infty} m(O_n)$ . Suppose $E$ is closed and unbounded. Let $E = \{(x,y): y = 2 \}$ and $O_n = \{(x,y): d(x,E) < \frac{1}{n}\}$ . Since $E$ is a line in $\mathbb{R}^2$ , $m(E) = 0$ . Also, since the measure of a rectangle in $\mathbb{R}^d$ is its volume, $m(O_n) = \left| O_n \right| = \infty$ , since the rectangle $O_n$ is unbounded. It is therefore apparent that $m(E) \not = lim_{n \rightarrow \infty} m(O_n)$ . Suppose $E$ is open and bounded. Let $E=(0,1)$ and $O_n = \{x \mid d(x,E) < \frac{1}{n}\}$ . $\mathbb{R}-E$ is closed and $O_n \in \mathbb{R}-E$ . Since $\mathbb{R}-E$ contains all its limit points $lim_{n \rightarrow \infty}O_n = O \in \mathbb{R}-E$ . Thus $lim_{n \rightarrow \infty} m(O_n) \neq m(E)$ .","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1669136,open map from a topological space whose connected components aren't open to a connected space,"Let $X$ be a connected topological space, and $Y$ a space which is not the disjoint union (as topological spaces) of its connected components (ie, the connected components of $Y$ are not all open). Can there exist an open continuous surjective map $Y\rightarrow X$ with finite fibers? Motivation: I want to argue that any surjective etale map of schemes $Y\rightarrow X$ where $X$ is a connected scheme must have $Y$ be the disjoint union of its connected components. EDIT: By disjoint union (as topological spaces), I mean the coproduct in the category of topological spaces, sometimes denoted as the ""topological sum"".","['general-topology', 'algebraic-geometry']"
1669147,Partition of number's squares,"The problem is to divide $\{k^2\}_{k=1}^{1000}$ into two groups of 500 numbers each, such that they have equal sum. I know that
$$
\sum_{k=1}^n k^2 = \frac{n(n+1)(2n+1)}{6},
$$
but it isn't enough for me to solve this. Please help me, if you can.","['combinatorics', 'integer-partitions']"
1669153,"Derivative of $\ln (z), z\in\mathbb{C}$",Let $f(z) = \ln z := \ln |z| + \arg (z)i$ . Then the derivative is (if it exists) by definition: $$\lim_{h\to 0}\frac{\ln (z+h)-\ln (z)}{h}=\lim_{h\to 0}\frac{\ln |z+h| +\arg(z+h)i-\ln |z| -\arg(z)i }{h}$$,"['derivatives', 'complex-analysis']"
1669178,Prove $\frac {1 + a + a^2 + \ldots +a^{n - 1} }{n} < \frac {1 + a + a^2 + \ldots +a^{n - 1} + a^n}{n + 1}$ if $1 < a$,"Prove $\frac {1 + a + a^2 + \ldots +a^{n - 1} }{n} < \frac {1 + a + a^2 + \ldots +a^{n - 1} + a^n}{n + 1}$ if $1 < a$ Tried induction. Not sure where my mistake is, but what I did doesn't seem to make sense: Let $n = 1.$ Then $1 + a + a^2 + \ldots +1 < \frac {1 + a + a^2 + \ldots +1 + a}{2} = \frac{2 + 2a + a^2+ \ldots}{2} = 1 + a + \frac{a^2}{2} + \ldots$ Then I did this below, but it's unclear if the difference is positive: $\frac {1 + a + a^2 + \ldots +a^{n - 1} + a^n}{n + 1} - \frac {1 + a + a^2 + \ldots +a^{n - 1} }{n} = \frac {n + na +na^2+ \ldots + na^{n - 1} + na^n - n - 1 - an - a- na^2 - a^2 - \ldots -na^{n - 1} - a^{n - 1}}{n(n + 1)} = \frac{n(1 + a + a^2+ \ldots + a^{n - 1} + a^n - 1 -a - a^2 -a^{n - 1}) - 1 - a - a^2 - \ldots - a^{n - 1}}{n(n+1)} $ $ = \frac{- 1 + a(n(a^{n - 1}) - 1 - a - \ldots - a^{n - 2})}{n(n+1)}$ What can I try now?",['algebra-precalculus']
1669184,Does the logistic function have a relation with $\arctan(x)$?,"The logistic function is: $$f(x)=\frac{L}{1+e^{-k(x-x_0)}}+B.$$ It's plot looks similar to the plot of $\arctan(x)$. Therefore, I was wondering whether there is a relationship between these two functions. Can one transform the logistic function in such a way that it equals $\arctan(x)$? For example by giving the constants certain values?","['exponential-function', 'trigonometry', 'calculus']"
1669194,Derivative at Endpoint,"In Rudin's ""Principles of Mathematical Analysis"" he defines the limit of a function as follows. Let $X$ and $Y$ be metric spaces; suppose $E \subset X$, $f$ maps $E$ into $Y$, and $p$ is a limit point of $E$.  Then
  $$
\lim_{x \to p} f(x) = q
$$
  if there is a point $q \in Y$ with the following property: For every $\epsilon > 0$ there exists a $\delta > 0$ such that
  $$
d_Y(f(x),q) < \epsilon
$$
  for all points $x \in E$ for which
  $$
0 < d_X(x,p) < \delta.
$$ The functions $d_X$ and $d_Y$ are the metrics on $X$ and $Y$, respectively.  He then defines the derivative of a real function as follows. Let $f$ be defined on $[a,b]$.  For any $x \in [a,b]$ form the quotient
  $$
\phi(t) = \frac{f(t) - f(x)}{t - x} \qquad a < t < b,\, t \neq x,
$$
  and define
  $$
f^\prime(x) = \lim_{t \to x}\, \phi(t), \qquad (1)
$$
  provided this limit exists in accordance with [the above definition].  We thus associate with the function $f$ a function $f^\prime$ whose domain is the set of points $x$ at which the limit (1) exists. I can't reconcile what's wrong with derivatives at endpoints .  As a concrete example, let $f: [0,1] \to \mathbb{R}$ be defined by $f(x) = x^2$.  I claim that $f^\prime(0) = 0$.  Indeed, the difference quotient is
$$
\phi(t) = \frac{t^2 - 0^2}{t - 0} = t
$$
and so we need to show
$$
\lim_{t \to 0}\, t = 0.
$$
Let $\epsilon > 0$ and choose $\delta = \epsilon$.  Then for all $t \in [0,1]$ such that $0 < |t| < \delta$ we have $|t| < \epsilon$.  Hence $f^\prime(0) = 0$, even though it is at an endpoint of the domain of $f$. In particular, there's no use to introduce one-sided derivatives.  Am I missing something?","['derivatives', 'real-analysis', 'calculus']"
1669217,limit of sum defined sequence,"Let $x_n=\displaystyle \sum_{k=1}^n \sqrt{1+\frac{k}{n^2}}, n\ge1$. Prove that $\displaystyle \lim_{n \rightarrow \infty} n (x_n-n-\frac{1}{4})=\frac{5}{24}$. What I've done:it's easy to show that $\displaystyle \lim_{n \rightarrow \infty} \frac{x_n}{n}=1$ and $\displaystyle \lim_{n \rightarrow \infty} (x_n-n)=\frac{1}{4}$","['sequences-and-series', 'limits']"
1669228,"Solve system of simultaneous equations in $3$ variables: $x+y+xy=19$, $y+z+yz=11$, $z+x+zx=14$","Solve the following equation system: $$x+y+xy=19$$
$$y+z+yz=11$$
$$z+x+zx=14$$ I've tried substituting, adding, subtracting, multiplying... Nothing works. Could anyone drop me a few hints without actually solving it? Thanks!","['algebra-precalculus', 'linear-algebra', 'systems-of-equations']"
1669253,"Is there a ""one-line"" proof of $x<y\Rightarrow x^n<y^n$ (for $n$ an odd natural number)?","Given the usual field and ordering axioms for the real numbers, it isn't difficult to prove that $x<y$, without any further restrictions on the signs of $x$ and $y$, implies $x^n<y^n$, with $n$ an odd natural number. However, all the proofs I've seen and come up with myself seem to rely on distinguishing between the different possible combinations of signs of $x$ and $y$. I find such ""case-by-case"" proofs, especially of elementary facts, rather unappealing. Now, my question is: does there exist an elegant one-line proof of the fact that   $x<y\Rightarrow x^n<y^n$ (for $n$ an odd natural number) which doesn't take into account the signs of $x$ and $y$? Thanks for reading and for any comments!","['real-analysis', 'inequality', 'real-numbers']"
1669329,Is polar coordinates enough to prove that a limit exists,"Somewhat of a basic question but I failed to find an answer or come up with a formal one myself. Suppose I want to find the limit $\lim_{{(x,y)} \to {(0,0)}}f(x,y)$ using spherical coordinates $x:=r\cos \theta$, $y:= r\sin\theta$. Suppose I found that $\lim_{r \to 0} f(r,\theta)$ exists and is equal to $\alpha$ regardless of $\theta$. Did I really cover every possible path? Can we say for sure that the limit is $\alpha$? maybe some other limit exists in another path that we didn't cover. For example, take $\lim_{(x,y) \to (0,0)}\frac{x^2y}{x^2+y^2} = \lim_{r\to 0}\frac{r^3\cos^2\theta \sin \theta}{r^2} = \lim_{r \to 0}r\cos^2 \theta \sin \theta = 0$. I agree that IF the limit exists, it has to be zero. But maybe there is some path we didn't cover and from that path the limit is something else?","['multivariable-calculus', 'calculus', 'limits']"
1669365,Let $f(z) = z^4 - 2z^3 + z^2$. Evaluate $\frac{1}{2\pi i} \int \frac{f'}{f} dz$ and $\int \frac{zf'}{f} dz$,"Let $f(z) = z^4 - 2z^3 + z^2$. Evaluate $\frac{1}{2\pi i} \int_C \frac{f'}{f} dz$ and $\int_C \frac{zf'}{f} dz$ where $C: |z| = R$ for $R >> 1$. Attempt For the first integral, I think we can simply use Rouche's Theorem with $h(z)=z^4$ and $g(z)=- 2z^3 + z^2$. Since $|h(z)| > |g(z)|$ everywhere on $C$, we have by the argument principle that
$$\frac{1}{2\pi i} \int_C \frac{f'}{f} dz = 4.$$ The second integral evaluates to $2 \pi i$ times the sum of the values of the zeros. Since the zeros are located at $0$ and $1$, each with multiplicity $2$, we have
$$\int_C \frac{zf'}{f} dz = 4 \pi i.$$ I'm not sure how to validate my work. Is this the right way to approach these integrals?",['complex-analysis']
1669379,"All possible combinations of the black and white knight on 8x8 chess board, which are not mutually attack?","All possible combinations of the 2 knights on 8x8 chess board, which
  are not mutually attack? I figured that when they DO attack each other the result will be, i think, 64-9 but still puzzled when they do not attack each other. Thank you for your response.","['combinatorics', 'discrete-mathematics']"
1669407,Is $X^2$ independent from $XY$ where $X$ and $Y$ are standard normals?,"I'm thinking they can somehow be expressed as functions of $X-Y$ and $X+Y$, but I haven't quite found out how. Bonus questions: Is it correct that they are both Chi square distributed? And so, would $X^2 + XY$ also be Chi square distributed? What would be the distribution of $a(X_0^2+Y_0^2) + b(X_0X_1+Y_0Y_1)$?","['statistics', 'probability', 'normal-distribution', 'probability-distributions']"
1669417,Finding Divisibility of Sequence of Numbers Generated Recursively,"I have the following generating function:
$$E(x)=\frac{2e^x}{e^{2x}+1+2x}=\sum_{n=0}^\infty {E_n}\frac{x^n}{n!}$$
which generates a sequence of integers below $$\{1, -1, 3, -15, 93, -725, 6815, -74627, 933849,-13148361,205690779,...\}$$ Thus, accordingly, $E_0=1, E_1=-1, E_2=3, E_3=-15, ...$.  So I was playing around and decided to look at these numbers prime factorization.  Below is the breakdown of the first 15 numbers...
$$
\begin{array}{l|l}
n & |E_n| & \text{prime decomposition}  \\
\hline
0 & 1 & 1 \\
1 & 1 & 1  \\
2 & 3 & 3 \\
3 & 15 & 3\cdot 5  \\
4 & 93 & 3\cdot 31 \\
5 & 725 & 5^2\cdot 29 \\
6 & 6815 & 5\cdot 29\cdot 47 \\
7 & 74627 & 7^2\cdot 1523 \\
8 & 933849 & 3^7\cdot 7\cdot 61 \\
9 & 13148361 & 3^2\cdot 17\cdot 19\cdot 4523 \\
10 & 205690779 & 3^3\cdot 7^2\cdot 155473 \\
11 & 3539545559 & 11\cdot 31\cdot 43\cdot 241393 \\
12 & 66466203637 & 11\cdot 283\cdot 701\cdot 30449 \\
13 & 1351309774685 & 5\cdot 13\cdot 97\cdot 5003\cdot 42839 \\
14 & 29595401433975 & 3\cdot 5^2\cdot 13\cdot 8539\cdot 3554779 \\
\end{array}
$$ I noticed that for odd indexed numbers, the number was divisible by the index; in other words, $n|E_n$.  Also, for even indexed numbers, the number was divisible by the index minus one, so $(n-1)|E_n$.  Below is the chart color coded with odds in red and evens in blue. $$
\begin{array}{l|l}
n & |E_n| & \text{prime decomposition}  \\
\hline
0 & 1 & 1 \\
\color{red}{1} & 1 & \color{red}{1}  \\
\color{blue}{2} & 3 & \color{blue}{1}\cdot 3 \\
\color{red}{3} & 15 & \color{red}{3}\cdot 5  \\
\color{blue}{4} & 93 & \color{blue}{3}\cdot 31 \\
\color{red}{5} & 725 & \color{red}{5}^2\cdot 29 \\
\color{blue}{6} & 6815 & \color{blue}{5}\cdot 29\cdot 47 \\
\color{red}{7} & 74627 & \color{red}{7}^2\cdot 1523 \\
\color{blue}{8} & 933849 & 3^7\cdot \color{blue}{7}\cdot 61 \\
\color{red}{9} & 13148361 & \color{red}{3^2}\cdot 17\cdot 19\cdot 4523 \\
\color{blue}{10} & 205690779 & 3\cdot \color{blue}{3^2}\cdot 7^2\cdot 155473 \\
\color{red}{11} & 3539545559 & \color{red}{11}\cdot 31\cdot 43\cdot 241393 \\
\color{blue}{12} & 66466203637 & \color{blue}{11}\cdot 283\cdot 701\cdot 30449 \\
\color{red}{13} & 1351309774685 & 5\cdot \color{red}{13}\cdot 97\cdot 5003\cdot 42839 \\
\color{blue}{14} & 29595401433975 & 3\cdot 5^2\cdot \color{blue}{13}\cdot 8539\cdot 3554779 \\
\end{array}
$$ I thought this was interesting and think the conjecture would hold.  My problem is this: I don't know how to begin even testing this idea.  How do you test for divisibility of large numbers when the numbers are generated recursively?  It would be easy to test for the small; $E_0, E_3, $ etc.  But this is an infinite sequence, so how could i test the 100th term?  What are some methods that would be used to prove such a conjecture? EDIT:  I do have the recursive definition, in fact I have two for the numbers, which may help readers... $$E_n=1-2nE_{n-1}-\sum_{k=0}^{n-2}{\binom{n}{k}2^{n-k-1}E_k}$$
and
$$E_n=-\frac{1}{2}\sum_{k=0}^{n-1}\binom{n}{k}\left(1+(-1)^{n-k}+2(n-k)(-1)^{n-k-1}\right)E_k$$","['divisibility', 'number-theory', 'generating-functions', 'combinatorics', 'sequences-and-series']"
1669457,"Pullback metric, coordinate vector fields..","I'm doing this computation on $\mathbb{R}^3$ with cylindrical coordinates $(r, \theta, z)$, (which aren't defined on the whole of $\mathbb{R}^3$, but I don't care about that) and I seem to get a contradiction. The problem is as follows. Make the following change of coordinates: $$\xi = r,~~\eta = \theta - z,~~\zeta = z.~~~(1)$$ My problem is simple: express the new coordinate vector fields $(\partial_{\xi}, \partial_{\eta}, \partial_{\zeta})$ in terms of the old ones $(\partial_{r}, \partial_{\theta}, \partial_{z})$. I'm getting confused because I actually have two ways of doing this, both seem right, but they disagree; so let me explain what I've tried. 1. From $(1)$, basically using the Chain Rule: $$\partial_{\xi} = \frac{\partial{\xi}}{\partial{r}}\partial_r + \frac{\partial{\xi}}{\partial{\theta}}\partial_{\theta} + \frac{\partial{\xi}}{\partial{z}}\partial_z = \partial_r,~~~~(2)\\ \partial_{\eta} = \partial_{\theta} - \partial_z, \\ \partial_{\zeta} = \partial_z. $$ 2. From $(1)$, compute the differentials first: $$d\xi = dr,~~d\eta = d\theta - dz,~~d\zeta = dz.~~~(3)$$ Now from $(3)$ and the general fact that $dx^i(\partial_j) = \delta_{ij}$, where $i, j = 1, 2, 3$ and $\delta_{ij}$ is the Kronecker delta, we must have $$\partial_{\xi} = \partial_r,~~\partial_{\eta} = \partial_{\theta},~~\partial_{\zeta} = \partial_z + \partial_{\theta}.~~~~(4)$$ But $(2)$ and $(4)$ disagree about who is $\partial_{\zeta}$, for instance. What is going on??","['coordinate-systems', 'differential-geometry', 'polar-coordinates']"
1669513,"Show that the multinomial distribution has covariances ${\rm Cov}(X_i,X_j)=-r p_i p_j$","If $(X_1,\cdots, X_n)$ is a vector with multinomial distribution, proof that $\text{Cov}(X_i,X_j)=-rp_ip_j$, $i\neq j$ where $r$ is the number of trials of the experiment, $p_i$ is the probability of success for the variable $X_i$.
$$fdp=f(x_1,...x_n)={r!\over{x_1!x_2!\cdots x_n!}}p_1^{x_1}\cdots p_n^{x_n} $$ if $ x_1+x_2+\cdots +x_n=r$ I'm trying to use the property: $\text{Cov}(X_i,X_j)=E[X_iX_j]-E[X_i]E[X_j]$ and find that $E[X_i]=rp_i$, but I don´t know the efficient way to calculate $E[X_iX_j].$","['multinomial-distribution', 'covariance', 'statistics', 'probability', 'combinatorics']"
1669515,Equivalent norms without Cauchy-Schwarz inequality,"Let $X$ be a finite-dimensional vector space over $\mathbb{F}$. ($\mathbb{R}$ or $\mathbb{C}$) Theorem: All norms on $X$ are equivalent. Proof: $a_k$s and $c_k$s will refer to elements of $\mathbb{F}$. Let $(e_k)_{k=0}^{n-1}$ be a basis of $X$. Define
$\lVert \sum_{k=0}^{n-1} c_k e_k \rVert_1 = \sum_{k=0}^{n-1} |c_k|$. Evidently $\lVert \cdot \rVert_1$ is a norm. Let $\lVert \cdot \rVert$ be another norm on $X$. Then if we define $c_0 = 1/\max(\lVert e_k \rVert)_{k=0}^{n-1}$, for $x = \sum_{k=0}^{n-1} a_k e_k$,
$$ c_0\lVert x \rVert = c_0\left\lVert \sum_{k=0}^{n-1} a_k e_k \right\rVert
\leq c_0 \sum_{k=0}^{n-1} |a_k| \lVert e_k \rVert \leq \sum_{k=0}^{n-1} |a_k| = \lVert x \rVert_1
$$
Conversely, observe that if $c_1 > 0$ so that $\lVert x \rVert_1 \leq c_1 \lVert x \rVert$, (We may assume that $\lVert x \rVert_1 \neq 0$ by the identity of indiscernibles)
$$ 1 = \frac{\lVert x \rVert_1}{\lVert x \rVert_1} \leq \frac{c}{\lVert x \rVert_1} \lVert x \rVert = c_1\left\lVert \frac{x}{\lVert x \rVert_1} \right\rVert
$$
so it suffices to show that $\lVert\cdot\rVert$ is bounded below on the unit sphere $S =\{x \in X\mid \lVert x \rVert_1 = 1\}$. However, this is the part I'm having trouble with. Obviously if $\mathbb{F} = \mathbb{R}$, I can use the fact that every bounded set in $\mathbb{R}^n$ is totally bounded, and thus show the compactness of $S$.(which implies every sequence of norms on $S$ has a convergent subsequence) But what if $\mathbb{F} = \mathbb{C}$? How does the argument work here? Also, the sequence of norms mentioned earlier converges iff $\lVert\cdot\rVert$ is continuous, which is what I'm trying to show.","['functional-analysis', 'normed-spaces', 'general-topology', 'equivalent-metrics']"
1669543,Are there powerful ways to use the topological definition of continuity in real analysis?,"In the lectures for introductory real analysis, my professor repeatedly told the class that the topological definition of continuity (preimage of open is open) is the most powerful version of continuity, most useful... Then the only example he came up with was .... Example: Prove $S = \{x| ``{\text{weird, impractical and obviously ad hoc inequality 
 here}}""\}$ is open Then the LHS of this weird inequality is a continuous function and inequality is an open set and the preimage $f^{-1}$ on that open set is open, hence $S$ is open. Then we never discussed this again and it never came up in any other context as far I can remember. Question, are there more practical examples/ways to use the topological version of continuity in real analysis?","['self-learning', 'real-analysis', 'examples-counterexamples', 'continuity', 'general-topology']"
1669544,How to solve Schrödinger equation numerically with time dependent potential,"How to solve the Schrödinger equation with time dependent potential in 1D or 3D (if it is easier): $$i\hbar\dfrac{\partial \Psi}{\partial t}(x,t)=\left(-\dfrac{\hbar}{2m}\nabla^2-\frac{e^2}{x+\alpha}-exE(t)\right)\Psi(x,t)$$ where $E(t) = E_0 \exp(-t/\tau^2)sin(\omega_0 t)$ is a Gaussian pulse in time, $\alpha$ is a constant and $e$ is a constant (the electron charge). $\Psi(x,0)$ is hydrogen ground state. What would it mean to find the solution in a self consistent manner?","['partial-differential-equations', 'physics', 'runge-kutta-methods', 'numerical-methods', 'ordinary-differential-equations']"
1669559,Tetrahedron packing in Cube,"I'm thinking about following solid geometry problem. Q: Suppose you have a box of ""cube"" shape with edge length 1. Then, How many regular tetrahedrons(with edge length 1) can be in the box? So, this is kind of packing problem inside cube.
I guess the answer is 3. but I don't know how to prove 3 is the maximum number.
Is there any rigorous way to show this? Thanks for any help in advance.","['packing-problem', 'platonic-solids', 'solid-geometry', 'geometry', 'contest-math']"
1669575,What function does this Taylor Series represent?,"What is the function $f$ who's Taylor series is $1 - \frac{x}{4} + \frac{x^2}{7} - \frac{x^3}{10} + \cdots$ ? I need to find the value of the series $ \sum^{\infty}_{n = 0}a_n = 1 - \frac{1}{4} + \frac{1}{7} - \frac{1}{10} +  \cdots$ by finding $\lim_{x\rightarrow1^-} \sum^{\infty}_{n = 0}a_n x^n$. (Abel Summability) I already did this for another problem.  I was given the series $\sum^{\infty}_{n = 0}b_n = \frac{1}{2\cdot 1} - \frac{1}{3\cdot 2} + \frac{1}{4\cdot 3} - \frac{1}{5\cdot 4} + \cdots$ I showed that $\sum^{\infty}_{n = 0}b_n x^n = \frac{\ln(1+x)}{x^2}+\frac{\ln(1+x)}{x}-\frac{1}{x}\rightarrow 2\ln(2)-1$ as $x\rightarrow1^- \Rightarrow \sum^{\infty}_{n = 0}b_n = 2\ln(2)-1$.  (This checks out numerically, as well) However, I'm having trouble finding the functional representation of $ \sum^{\infty}_{n = 0}a_n x^n$","['real-analysis', 'taylor-expansion', 'sequences-and-series', 'calculus']"
1669615,"Prove: if $a ∈ [x]$ and $b ∈ [y]$, then $a + b = x + y$ (mod $n$).","I am stuck with connecting the integer congruence with the first part of this proof. I've got the outline. Let $n ∈ Z$, and let $[x]$ denote the equivalence class of $x$ under integer congruence modulo $n$. Let $a, b, x, y$ be integers. Proof. Suppose $a ∈ [x]$ and $b ∈ [y]$. Then $aRx$ and $bRy$. So $n|(a-x)$ and $n|(b-y)$, by definition of integer congruence modulo $n$. So there is an integer $g$ such that $a - x = ng$ and there is an integer $f$ such that $b - y = nf.$ So $(a + b) - (x + y) = a - x + b - y = ng + nf = n(g + f).$ Then there is an integer $k$ such that $(a + b) - (x + y) = nk$; namely, $k = g + f$. Then $n|((a+b) - (x + y))$, by definition of integer congruence modulo $n$. Therefore $a + b = x + y$ (mod $n$). Am I on the right path? Can someone help me fill in the '...'? What exactly is contained in [x]? I know what it means to be an equivalence class, but how does it tie to the integer congruence modulo n?","['congruence-relations', 'proof-verification', 'discrete-mathematics']"
1669637,The kernel of a representation is a normal subgroup,"Let $X$ be a matrix representation.
Let the kernel of $X$ be defined as $N = {\{g \in G: X(g) = I}\}$ . A representation is faithful if it's one to one. Show that $N$ is a normal subgroup of $G$ and find a condition on $N$ equivalent to the representation being faithful. Proof: Let $X : G → GL(V)$ be a group representation. Let $g_1 \in N$ and $g \in G$ . Then $$X(g^{-1}g_1g) = X(g^{-1})X(g_1)X(g) = X(g)^{-1}(I)X(g) = X(g)^{-1}X(g) = I.$$ Thus $g^{-1}g_1g \in N$ , so $N$ is a  normal subgroup of $G$ . Further, $X$ is faithful if and only if $N$ is the identity subgroup of $G$ . Can someone please verify, or give feedback on, this proof.","['abstract-algebra', 'normal-subgroups', 'representation-theory', 'solution-verification']"
1669675,Looking to calculate the diameter of a graph of $2^{2016}$ binary strings.,"Compute the diameter of the graph G with $V (G) = \{0, 1\}^{2016}$ in which
two binary strings are connected if and only if they coincide in at most
one coordinate. What I know right now: each vertex is connected to 2017 others and there are $2^{2016}$ total vertices.","['graph-theory', 'discrete-mathematics']"
1669683,"Finding $\lim_{(x,y)\to (0,1)} \frac {xy - x } {x^2 + y^2 - 2y + 1} $","I'm trying to approach it using polar coordinates, but am not sure how to handle it because $r = 1$ instead of $r = 0$. Any help would be appreciated.","['multivariable-calculus', 'limits']"
1669702,Poles with different behaviours,"Is there a difference between the names of the poles at $x=0$ between: 1) $f(x)=\dfrac1x$ 2) $f(x)=\dfrac1{|x|}$ in that (1) tends to $+\infty$ as $x\to0^+$, and to $-\infty$ as $x\to0^-$, whereas (2) tends to $+\infty$ from either side.","['real-analysis', 'asymptotics', 'functions']"
1669735,Expectation of a Standard Normal Random Variable,"Calculate E(X^3) and E(X^4) for X~N(0,1). I am having difficulty understanding how to calculate the expectation of those two. I intially would think you just calculate the $\int x^3e^\frac{-x^2}{2} dx $  and 
$\int x^4e^\frac{-x^2}{2} dx $ for $E(X^3)$ and $E(X^4)$, respectively. However for lecture for $E(X^2)$ this appears appears.","['expectation', 'integration', 'normal-distribution', 'random-variables']"
1669773,Calculating $\int_0^{\pi/2} \sqrt{\cot x} + \sqrt{\cos x} dx$,"How should I solve the following integral: $$\int_0^{\pi/2} (\sqrt{\cot x} + \sqrt{\cos x} )\,\mathrm dx$$","['integration', 'definite-integrals', 'calculus']"
1669816,How To Tell If A Graph is A Hamiltonian?,"So, I can look at this graph and tell that it is not a Hamiltonian, but I do not know the actual mathematical reason why. I can see that if you start on one vertex, then it would be impossible to touch every other vertex just once because you would not be able to make it back. So I know that it is not, but I am having trouble explaining why in a way that makes sense.","['graph-theory', 'hamiltonian-path', 'discrete-mathematics']"
1669827,"Functional analysis, weak* convergence","in lecture notes in the Internet i found the following example for weak and weak* convergence. The unit vectors $\{e_n\}_{n\in \mathbb{N}} $ converges in $l_1$ weak* towards $0 $ but not weak to $0$. $e_n \not\stackrel{w}{\rightarrow} 0$: For the dual of $l_1$ we know, that $l_1^* \cong l_\infty$ holds. For example the sequence $y=(1,1,1,1,1,....) $ is in $l_\infty$ and we geht $y(e_n)=\sum_{i=1}^\infty e_ny_i=y_i \stackrel{n\rightarrow \infty}{\not\rightarrow} 0$, hence not weak convergent. I think this is correct, but I do not understand the following explanation for the weak* convergence:\ 
For a sequence $(f_j)_{j\in \mathbb{N}}\in c_0$ we get $f_j(e_n)=\sum_{j=1}^\infty f_je_n=f_n\stackrel{n\rightarrow \infty}{\rightarrow}0 $ If the sequence is really taken out of $c_0$ I understand the explanation, but for weak* convergence the sequence is normally taken out of the dual, in our case the $l_1^*$ which is not conjugated to $c_0$. In addition it holds $c_0 \subset l_\infty$ so we can´t consider $l_1^*\cong l_\infty$ as a subset of $c_0$ and use the property of $c_0$, as for example in the cases of $l_p$ for $p\in (1,\infty)$. Now I ask myself, is this example correct? It would be great, if somebody can explain it.
Thanks in advance. 
Hias","['functional-analysis', 'weak-convergence']"
1669832,$\displaystyle\lim_{x\to 0} {(\frac{f(x)}{x})} = 2$. Prove that the series $a_n=f(1)+f(\frac{1}{2})+...+(\frac{1}{n})$ is diverging to infinity,I have a feeling this has something to do with the harmonic series. I feel like I need to find a step that does something like $f(x)=2x$ but I think this is not allowed.,"['sequences-and-series', 'calculus', 'limits']"
1669873,Reduce a Riccati Equation to a Bernoulli Equation,"I've seen plenty of proofs and exercises where people reduce a Riccati equation to a linear equation, but not the intermediate step of a Bernoulli equation. I'm trying to reduce the Riccati equation $y' = p(t) + q(t)y + r(t)y^2$ to a Bernoulli equation, which has the form $y' + p(t)y = f(t)y^n$, with the substitution $y = y_1 + u$. I'm having some trouble understanding this particular substitution since the variables $y_1$ and $u$ are not defined. If I just follow the direction of ""substitute the equation,"" I immediately get confused when I attempt to find $y'$ since I can't tell if we get $y' = y_1' + u'$ or $y' = 0$. EDIT: I completely forgot to include the fact that $y_1$ is a particular solution of the equation.",['ordinary-differential-equations']
1669919,Useful bounds on stopping time for a positive drift random walk,"I was studying SPRT (Sequential Probability Ratio Tests) and there was a section (in an online article I was reading) which proved optimality of SPRT using some approximations. Unfortunately, this made the proof weak and I wanted to know if I could come up with an improved proof. Without going into many details, the following is my question: Let $\{Z_i\}$ be iid random variables ($\sim P_Z$) with finite moments and positive mean. Let $S_n = \sum_{i=1}^nZ_i$. Assume $S_0 = 0 ~ a.s$. Given $-\infty < a<0 <b<\infty$, define $N$ as
$$N = \inf\{n\geq 1:S_n \notin (a,b)\}$$
I need to find useful bounds on $E[N]$ in terms of $P_Z$ (and some moments), $a$, $b$ and perhaps other parameters. From Wald's Lemma, we have $E[S_N] = E[N]E[Z_1]$, so bounds on $E[S_N]$ would work as well. I have seen analysis of simple random walks, Gambler Ruins etc. but could not particularize the results to this case. If someone could provide good references to results or proofs, that would be appreciated. Let me know if more information is required. Update: I tried this problem for a while and I got the following. In order to compute $E[N]$, it helps to characterize $P(N\leq n)$. To this end, we have
$$P(N\leq n) = P\left(\bigcup_{k=1}^n\{S_k \geq b\}\cup \{S_k \leq a\}\right) $$
$$= P\left(\bigcup_{k=1}^n\{S_k \geq b\}\right)+ P\left(\bigcup_{k=1}^n\{S_k \leq a\}\right)$$
$$\geq P\left(S_n \geq b\right)+ P\left(S_n \leq a\right)$$
From this, $P(N \geq n+1) \leq P\left(S_{n} \in (a,b)\right)$. This will imply
$$E[N] \leq 1 + \sum_{n=1}^\infty P\left(S_{n} \in (a,b)\right) $$
Now the form in RHS can be simplified depending on moment constraints. I wonder if there are other methods...","['random-walk', 'probability-theory']"
1669926,Defining weak* convergence of measures using compactly supported continuous functions,"I'm reading some lecture notes and the author defines the following:
Let $\mu_{n},\mu$
  be probability measures on $\left(\mathbb{R}^{k},\mathcal{B}\left(\mathbb{R}^{k}\right)\right)$
 , we say $\mu_{n}$
  converge weakly to $\mu$
  if $\int fd\mu_{n}\longrightarrow\int fd\mu$
  for all continuous compactly supported functions $f:\mathbb{R}^{k}\to\mathbb{R}$
 . An almost identical definition appears in many text books with the change of requiring the same thing for any continuous bounded function. I couldn't find any reference which showed that it actually does suffice to look only at compactly supported functions. Is this actually true?","['real-analysis', 'measure-theory', 'probability-theory']"
1669935,What is a set mapping?,"Short question, what is a set mapping? I find it difficult using a set as an argument. I am struggling with measure theory at the moment and the example is a function $f: S \to T$ ,
s.t. $f^{-1}(B) = \{s \in S; f(s) \in B \}$ with $B \subset T$ If someone could explain this. Thanks.",['elementary-set-theory']
1669987,Confusion with arithmetically Cohen-Macaulay varieties,"I'm a bit struck about this fact; I think it's really a silly question, but I'm not completely sure about it. Let $X\subseteq \mathbf{P}^m$ be a projective variety; choose the best hypotheses possible, that is a noetherian separated scheme over an algebraically closed field $k$. Assume also $X$ is smooth. Then I have the following definitions: $X$ is arithmetically Cohen-Macaulay if the coordinate ring is Cohen-Macaulay; $X$ is (geometrically) Cohen-Macaulay if every local ring $\mathscr{O}_{X,p}$ is Cohen-Macaulay. I know that these two definition must be different, but I can't figure out how to prove it. I know that Cohen-Macaulay is a strongly local property (i.e. a ring is Cohen-Macaulay iff every localization is) and this seems to contradict the thesis. Could someone help with an example?","['schemes', 'cohen-macaulay', 'algebraic-geometry', 'commutative-algebra']"
1669992,How to evaluate this integral $\int_{0}^{\infty }\frac{\ln\left ( 1+x^{3} \right )}{1+x^{2}}\mathrm{d}x$,"How to evaluate this integral
$$\mathcal{I}=\int_{0}^{\infty }\frac{\ln\left ( 1+x^{3} \right )}{1+x^{2}}\mathrm{d}x$$
Mathematica gave me the answer below
$$\mathcal{I}=\frac{\pi }{4}\ln 2+\frac{2}{3}\pi \ln\left ( 2+\sqrt{3} \right )-\frac{\mathbf{G}}{3}$$
where $\mathbf{G}$ is Catalan's constant.","['catalans-constant', 'calculus', 'integration', 'contour-integration', 'analysis']"
1670000,Eigenvalues of the principal submatrix of a Hermitian matrix,"This question aims at creating an "" abstract duplicate "" of various questions that can be reduced to the following: Let $A$ be an $n\times n$ Hermitian matrix and $B$ be an $r\times r$ principal submatrix of $A$. How are the eigenvalues of $A$ and $B$ related? Here are some questions on this site that can be viewed as duplicates of this question: Eigenvalues of $MA$ versus eigenvalues of $A$ for orthogonal projection $M$ Relationship of eigenvalues of a diagonal matrix D and $\mathbf{VDV}^{T}$, where V is a semi-orthogonal matrix","['matrices', 'eigenvalues-eigenvectors', 'faq', 'linear-algebra']"
1670014,Find $\sum r\binom{n-r}{2}$,"Let $A=\{1,2,3,\cdots,n\}$. If $a_i$ is the minimum element of set $A_i$ where $A_i\subset A$ such that $n(A_i)=3$, find the sum of all $a_i$ for all possible $A_i$ Number of subsets with least element $1$ is $\binom{n-1}{2}$ Number of subsets with least element $r$ is $\binom{n-r}{2}$ Sum of all $a_r$ is $r\binom{n-r}{2}$ How do I find $$\sum_{r=1}^{n-2}r\binom{n-r}{2}$$","['elementary-set-theory', 'binomial-coefficients', 'functions']"
1670030,Convergence in law implies uniform convergence of cdf's,"Let $F_n, \ F$ be distribution functions with respect to some variables $X_n,\ X$ (in a not necessarily common probability space). Suppose that $F$ is continuous and $F_n \overset{d}{\rightarrow}F$ (i.e in law). Prove that $(F_n)$ converges uniformly to $F$, i.e. $$\displaystyle \lim_{n\rightarrow +\infty}\sup_{x\in \mathbb{R}}|F_n(x)-F(x)|=0$$ Comments . On a proof by contadiction, I 'd suppose that for some $\varepsilon>0$ for all $n$ there is $x_n$ such that $|F_n(x_n)-F(x_n)|\geq \varepsilon.$ But a classic analytic approach throught Bolzano - Weierstrass theorem can not be applied here since there is no information on the boundness of $(x_n).$ Thanks a lot in advance for the help!","['probability-theory', 'uniform-convergence', 'probability-distributions']"
1670033,Differential equation with reciprocal and constant,"I have the following differential equation with a reciprocal and a constant: $$ dx/dt =-\frac{a}{x}-b, $$ where $a$ is a positive constant and $b$ a nonnegative constant. I can solve this for $b=0$. Then (if this is allowed...)
$$x dx = -adt.$$
Integrating both sides and summing up the constants of integration gives
$$\frac{1}{2} x^2 = -at+C,$$
hence
$$x = \sqrt{2(-at+C)}. $$
Perhaps this is a rather elementary question, but how can this be solved for $b>0$? Since $1/x$ is not a well-behaved function, does this differential equation have an analytical solution? Thanks in advance.",['ordinary-differential-equations']
1670065,Finding joint CDF of two random variables,"I can't seem to solve this exercise. I have that 
  $$f_{XY}(x,y) = \begin{cases} 
1, & 0 \leq x \leq 2,\space \max{\{0,x-1\}} \leq y \leq \min{\{1,x\}}\\[0.2cm]
0,     & \text{otherwise} 
\end{cases}$$
  I want to find the joint CDF. I think I solved it for the case where $x \gt 2$ and $y \gt 1$, so that $$F_{XY}(x,y) = 1,$$ for $x \gt 2$ and $y \gt 1$, which I did through reasoning rather than by actually computing anything. After that I'm stuck. I believe these are the rest of the cases: when $x-1 \gt y$ when $x-1 \lt y \lt 1,\space 1 \lt x \lt 2$ when $0 \lt y \lt x,\space 0 \lt x \lt 1$ when $x \lt y,\space 0 \lt x \lt 1$ when $y \gt 1,\space 1 \lt x \lt 2$ I've failed in solving this for all those cases, which makes me think I probably have no idea how to find joint CDF's. For case $2.$, for example, I tried $$F_{XY}(x,y) = \int_1^2 \left(\int_{x-1}^1 f_{XY}(x,y) dy \right)dx,$$ which doesn't give me the right answer. I have tried several other things, but nothing works for me, so any hints or advice would be helpful.","['probability-theory', 'probability', 'probability-distributions']"
1670073,Showing that the exponential expression $e^x (x-1) + 1$ is positive,"I'm looking at $$ f(x) = e^x (x-1) + 1$$ I'm having the feeling (based on the application where I am using it), that $f(x)$ should be strictly positive for $x > 0$. Indeed, Wolfram Alpha plots it as such, with a global minimum of ($f(0)x=0$). However, I fail to show this. It is trivial for $x \geq 1$, but what for $x < 1$?","['real-analysis', 'inequality', 'exponential-function', 'calculus']"
1670081,Block matrix and spectral radius,"I have a problem about a positive definite matrix. I cannot prove this. Let $B= [b_{ij}]$ be a $m \times m$ matrix. Let $\overline{B}^t$ be the conjugate transpose of $B$. If we have a strict inequality on the spectral radius $$\rho(\overline{B}^tB) < 1$$ show that the block matrix $$\begin{bmatrix}
I_n & B \\ 
\overline{B}^t & I_n 
\end{bmatrix}$$ is positive definite. If you don't mind, help me to solve this problem. Remake $\rho(A) = \max_i \lvert \lambda_i \rvert $ where $\lambda_i$ is eigenvalue of $A$.
A matrix $A$ is positive definite if $\overline{x}^t A x >0$ for all $x\in \mathbb{C}^n$ and $ A = \overline{A}^t $.","['eigenvalues-eigenvectors', 'block-matrices', 'matrices', 'spectral-radius', 'linear-algebra']"
1670092,The center of a group is an abelian subgroup,"Let $(G,\circ)$ be a group and let $Z(G):=\{x \in G : ax=xa \ \forall \ a \in G\}$ be the center of $G$ . How can I show that $Z(G)$ is an abelian subgroup of $G$ ? What I did so far: $Z(G)$ is a subgroup if $$a,b \ \in Z(G) \implies a\circ b^{-1} \in Z(G)$$ But I don't know/understand how I can show this. And still there is missing the commutativity.
Maybe someone can help me out with this!","['abelian-groups', 'abstract-algebra', 'group-theory']"
1670093,Around De Moivre–Laplace theorem/Poisson law,"The task is:
Typist printed 1000 pages of text, and made 140
errors. What is the probability that a randomly chosen page contains zero
errors? one? two? The error distribution is described with Poisson law. Using Poisson's law, I got that $P(m=0)=0.86,$ while the correct answer is 0.79. I tried to use ML-theorem, because $pnq=140*0.86 >> 20$ and $n >> 50.$ So under my $\exp$ function I get an argument like $-70$ and $e^{-70} \approx 4E-30,$ and so on. But its highly illogical, that the random page would contain mistake about for sure and its far enough from answer. Where am i wrong; What's the real way?",['statistics']
1670122,Switching limits: $n \rightarrow \infty$ for $n\rightarrow 0$,"I feel like this question may have already been asked, but despite my searches, I could not find it. I am looking to prove that $\lim\limits_{\epsilon \rightarrow 0} \int_{[b, b+\epsilon]} g=0$  for an integrable function $g$.  To do so, I would like to use the Dominated Convergence Theorem, as $g$ is my integrable dominating function.  However, I realize that the DCT is defined for the limit as $n$ goes to infinity.  I am looking to somehow switch this $\epsilon$ for $\frac{1}{k}$ and then take $k$ to infinity and use DCT.  However, I feel that it cannot be so simple.  How do I go about applying DCT to limits which are not going to infinity? Any hints would be appreciated.","['real-analysis', 'limits']"
1670139,Does $f(x) = 1 = \frac{x-1}{x-1}$ have a hole at $x=1$? [duplicate],"This question already has answers here : Why does factoring eliminate a hole in the limit? (16 answers) Closed 7 years ago . While learning about asymptotes and holes in rational functions in Precalculus, I came across a problem that shouldn't happen, but I don't understand. Something just doesn't add up in my head... Here we go: Let f(x)=1.
Since $\frac aa=1$ and $a*1=a$, obviously $a={a*b \over b}$.
Let $b=(x-1)$.
We can multiply f(x) by 1, technically, by saying that: $$f(x)=1={x-1 \over x-1}$$
However, a bit of precalc knowledge shows us that ${x-1 \over x-1}$ has a vertical asymptote at x=1, and an x-intercept at x=1 as well. This means that the graph has a hole, or is undefined at, x=1. (Because plugging in 1 for x yields a denominator of 0, which is undefined.)
However, this is absurd because the graph of $f(x)=1$ obviously has no holes, anywhere.
Somehow, multiplying this extremely simple function by something equivalent to 1 makes it undefined at a particular point... Whaaaaa...? EDIT: I realize that the above function does not have a vertical asymptote. However, my statement was referring to the fact that it appears to have both a vertical asymptote and an x-intercept at the same x-value, which means that it has neither of those things, just a hole.","['calculus', 'rational-functions']"
1670143,Derivation of $\tanh$ solution to $\frac{1}{2}f''=f^3 - f$,"I am a mechanical engineering student, and I am trying to solve the following ODE: $$\frac{1}{2}f''=f^3 - f$$ where $f=f(x)$ and the boundary conditions are $f(0)=0$ and $f'(\infty)=0$. On the Wolfram Mathworld page for the hyperbolic tangent, it is remarked that the solution to this ODE is given by $f=\tanh(x)$. This can easily be verified by substitution, but I am looking for a step-by-step procedure to get to the solution. I have tried using the substitution $g=f'$, which yields
$$ g' = \frac{dg}{dx}=\frac{dg}{df} \frac{df}{dx}=\frac{dg}{df}f'=\frac{dg}{df}g$$ Using $f''=g'$, the substitution of the expresion above in the ODE leads to
$$\frac{1}{2} g dg = (f^3-f) df$$ which can be integrated to yield
$$\frac{1}{4} (f')^2 = \frac{1}{4}f^4-\frac{1}{2}f^2 + C$$ At this point, I am stuck and I do not know how to proceed. Any help would be greatly appreciated! Best regards,
Nick Update 1: Thanks to Mattos' answer, I realised that I can write the final expression as (I already use here $C=0$, although I am not completely sure if that is allowed already): $$\frac{df}{f\sqrt{f^2-2}} = dx$$ Using the following expression I found on sosmath (using different symbols to avoid confusion): $$\int \frac{dh}{h \sqrt{h^2-a^2}}=\frac{1}{a}\sec^{-1}\left|\frac{h}{a}\right|$$ we can integrate to find:
$$\frac{1}{\sqrt{2}} \sec^{-1}\left|\frac{f}{\sqrt{2}}\right|=x$$ which is definitely a lot closer to the answer I am looking for. Any help to go from here to $\tanh$ is appreciated. I will make sure to post the answer if I figure it out. Thanks! Update 2: I am not sure if the above approach will lead to the correct answer. However, an extensive derivation is given in the answers by LutzL. Thanks for the help!","['hyperbolic-functions', 'ordinary-differential-equations', 'calculus']"
1670145,What is the negation to almost everywhere?,"We have some statement $P$ which holds almost everywhere in some complete measure space 
$(\Omega, \mathcal{F}, \mu)$. Formally
$$ \exists N \in \mathcal{F} : \mu(N) = 0 : \forall x \in \Omega \setminus N : P(x) \ \text{holds}$$
so intuitively the statement $P$ holds in $\Omega$ except possible for some points in a null set $N$. Now I think that the negation is
$$\forall N \in \mathcal{F} : \mu(N) \not = 0 : \exists x \in \Omega \setminus N : P(x) \text{ does not hold}$$
I can't quite put my finger on it, but this contradiction does not feel right. I have note taken any courses in formal mathematical logic so I am not sure if I have even constructed the negation correctly. The contradiction above does not feel like a ""working mathematicians"" negation. In the past I have blindly assumed that the negation implies that
$$\exists N \in \mathcal{F} : \mu \left( \left\{ x \in \Omega : P(x) \ \text{does not hold} \right\} \right) > 0$$
but I was unable to prove a strict equivalence between these statements.","['logic', 'measure-theory']"
1670160,"$C(S^1)$, as a Banach algebra, does not have a single generator","Let $S^1$ be the unit circle in the complex plain and $C(S^1)$ be the continuous function space on $S^1$.$f\in C(S^1)$ is a generator means that 
$\{p(f) |\text{ p is a polynomial in z}\}$
is dense in $C(S^1)$. I need to prove $C(S^1)$ does NOT have a generator. $\forall f \in C(S^1)$, let $f=\sum_{n\in \mathbb{Z}}a_nz^n$ be the Fourier expansion of $f$. If $\{f_k\}_{k=1}^{\infty}$ is convergent in $C(S^1)$,then $\{f_k\}_{k=1}^{\infty}$ is also convergent in $L^2(S^1)$.Hence $\{a_n^{(k)}\}_{k=1}^{\infty}$ is convergent,$\forall n \in \mathbb{Z}$.$a_n^{(k)}$ is the fourier coefficient at the n_th position of $f_k$. It follows easily that functions like $f=\sum_{n\geq0}a_nz^n$ or $f=\sum_{n\lt0}a_nz^n$ can not be generators. But I do not know how to prove functions which are not those kinds above can not be generator. Any help would be appreciated.","['functional-analysis', 'real-analysis', 'operator-algebras', 'functions']"
1670178,Complex polynomials on unit circle not closed under conjugation,"Let $T = \{z\in \mathbb{C}: |z| = 1\}$, the unit circle on complex plane, $P(T)$ be the set of polynomials in $T$ with complex coefficients, $C(T)$ the set of continuous functions from $T$ to $\mathbb{C}$. It can be shown that $P(T)$ is not dense in $C(T)$, and all conditions of the complex version of the Stone-Weierstrass theorem are satisfied except that $P(T)$ is not closed under complex conjugation. But if $p(z) = \sum_{j=0}^n a_j z^j$, then $\bar p(z) = \sum_{j=0}^n \bar a_j \bar z^j$, where $|z| = |\bar z| = 1$, so $\bar p \in P(T)$. What's the problem here?","['functional-analysis', 'complex-analysis', 'complex-numbers']"
1670209,Looking for a nonrecursive formula for the general derivatives of the quotient of functions,"I want to prove that the $k$-th derivative $h^{(k)}(x)$ of the function $h(x)=\frac{1}{1+x^2}$ is zero at $x=0$ for all integer values $k>0$. My only idea was to go the stubborn way applying iteratively the elementary formula for the derivative of a quotient of functions. Alas I didnt find a general formula similar to the Leibniz formula for the derivatives of a product of functions neither in Wikipedia nor else in the web so far. This puzzles me. It wouldnt surprise me if a non-recursive closed expression (using iterated binomial coefficient sums) would be existing. I tackled the problem so far in using first the Leibniz formula on $h(x)=f(x)\frac{1}{g(x)}$ in the way $$h^{(k)}(x)=\sum_{r=0}^k f^{(k)}(x)\left( \frac{1}{g(x)}\right)^{(k-r)}$$ So I am in front of the problem calculating $\left( \frac{1}{g(x)}\right)^{(s)}$ which in the first step tackled by decreasing iteratively by $1$ $$\left( \frac{1}{g(x)}\right)^{(s)}=\left( -\frac{g^{(1)}(x)}{g^2(x)}\right)^{(s-1)}$$ If one applies to that quotient iteratively the Leibniz product rule
the next calculation problem comes up for $$\left( \frac{1}{g^2(x)}\right)^{(t)}=\left( -\frac{(g^2)^{(1)}(x)}{g^4(x)}\right)^{(t-1)}$$ So I arrive at the problem calculating $$\left( -\frac {g^{{2^{m-1}}^{(1)}}(x)} {g^{2^m}(x)} \right)^{(1)}$$ Then I tried to go on by de-exponentiating and getting the square $$(g^{2^{m-1}})^{(1)}(x)=\left((g^{2^{m-2}}(x))^2\right)^{(1)}(x)=2g^{2^{m-2}}(x)g^{2^{m-2}})^{(1)}(x)$$ This leads me iteratively to the ( surprising/erroneous(?) ) result $$\left( -\frac {g^{{2^{m-1}}^{(1)}}(x)} {g^{2^m}(x)} \right)^{(1)}=2^{m-1}\frac{g^{\prime}}{g}$$ where the exponent at the $2$ is in doubt. Now I am overwhelmed at putting this all together and especially simplifying the nested iterative Leibniz sums with the binomials.","['derivatives', 'binomial-coefficients', 'calculus']"
1670213,"Choosing 26 of 52 cards, reciprocal probability.","Here we have a deck of $52$ cards numbered $1$ thru $52$ (integers only).  We randomly select $26$ of those $52$ cards (without replacement).  Each card is equiprobable. The task is to find out how many hands have the sum of the reciprocals of the chosen ranks exactly equal to $2$. $52 \choose 26$ is quite large (about $496$ trillion) so a straightforward count might not be possible on some computers in a reasonable amount of time.  $26$ happens to be very convenient though since there are $26$ letters in the alphabet, thus allowing me to run nested loops with single letter names of a,b,c.. .z. I am interested to see what ""pruning"" and rank exclusions can be done to this problem cuz this is a much larger state space than $16$ billion (if choosing only $10$ cards from a deck of $52$).  About $31,000$ times larger. A slight hint/head start:  The maximum possible sum is about $3.85442$ and the minimum possible sum is about $0.6836$.  This is one reason why I chose $2$ as it appears it is possible.  I don't even know yet if there is a single solution but I would suspect there are many, although a very small percentage.",['probability']
1670241,Problem on integration: $\int\frac{\log_{\ e}[\sec x]}{\sqrt{1-x^2}}dx$,"Well, Today I am very confused over a integral problem and I tried 
wolfram and many websites they did not help me.
Compute:
$$\int\frac{\log_{\ e}[\sec x]}{\sqrt{1-x^2}}dx$$ 
this I have to solve to find integral of arcsinx and tanx The Whole Equation:
$$ \int \sin^{-1}x \tan x=\sin^{-1}x\log_{\ e}|\sec x|-\int\frac{\log_{\ e}[\sec x]}{\sqrt{1-x^2}}dx$$ Can Any one give solution fully yo Me and Thanks","['derivatives', 'integration', 'calculus']"
1670269,Prove this fact about holomorphic functions.,"Suppose $f \colon \mathbb{D} → \mathbb{C}$ is holomorphic. Then I want to show that the diameter 
$$d=\sup _{z, w∈\mathbb{D}} |f (z) − f (w)|$$ of the image of $f$ satisfies $2|f′(0)| ≤ d$ and that equality holds precisely when $f$ is linear, this is $f(z) = a_0 +a_1z$. Then I did the following: Using Cauchy's integral formula we get that, $$2|f′(0)|=\left|\frac{1}{2πi}∫_{|z|=r}\frac{f(z)−f(−z)}{z^2}\,dz\right|.$$ Then I parametrize the circle, so arrive at: $$\frac{1}{2πi}∫_{0}^{2 \pi}\frac{f(Re^{i \theta})−f(−Re^{i \theta})}{R^2e^{2i \theta}}iRe^{i \theta}\,d\theta.$$ So given that $R=1$ and that the length of the curve is $2 \pi$ we arrive to this inequality $$\left|\frac{1}{2πi}\int_{0}^{2 \pi}\frac{f(Re^{i \theta})−f(−Re^{i \theta})}{R^2e^{2i \theta}}iRe^{i \theta}\,d\theta\right|< \sup \left|f(e^{i \theta})−f(−e^{i \theta})\right|$$ and for the equality we see that if $f$ is linear then $2f'(0)=2a_0$ and $d=\sup|a_1(z-w)|=a_1$, but the thing there is no reason to have that $a_0=a_1.$ So Am I right in the first approach (or how can I fix it)? Also, how Can I get the equality? Thanks a lot in advance.",['complex-analysis']
1670274,How do I calculate regression line using a data set with repeated values indicated as frequencies?,"I have a data set that comprises of Independent Variable $(X)$ and Dependent Variable $(Y)$ values with a certain frequency $(F)$.
I know that I have to find $x^2$ and $xy$ but how do I factor in the frequency? I am calculating regression using the least squares method ($Y = a + bX$). For clarity, this is the data set that I am working with. Frequency (F) Independent Variable (X) Dependent Variable (Y)
      3                  4                       60
      4                  4                       65
      2                  5                       65
      4                  5                       70
      3                  6                       75
      2                  6                       80
      4                  7                       85
      3                  8                       90","['regression', 'statistics']"
1670275,Definition of a esssential singularity - equivalence?,"I previously held the conception that an essential singularity could be defined as a point $z_0$ of the function $f(z)$ for which:
$$\lim_{z\rightarrow z_0}(z-z_0)^nf(z)$$
is not finite for any finite $n$. Although I don't think this definition is wrong (please correct me if it is), I am under the impression it is not the most useful. I think another definition of an essential singularity is: The point $z_0$ is an essential singularity of the function $f(z)$ if and only if: $$\lim_{z\rightarrow z_0}f(z)$$ can be made to take at least two different values (taking the point at infinity to be only one value) when approaching from two different directions. Would this definition/statement be correct? And if so can an equivalence be shown between these two definitions.",['complex-analysis']
1670299,Prime numbers of the form $2357111317...$,"Let $m_{n}$ be the number we get from putting first $n$ primes together. $$m_{1}=2$$
$$m_{2}=23$$
$$m_{3}=235$$
$$m_{4}=2357$$
$$m_{5}=235711$$
$$m_{6}=23571113$$
$$m_{7}=2357111317$$ and so on. Only primes i found on this sequence with Mathematica are $m_{1}=2, m_{2}=23, m_{4}=2357.$ For $5\leq n\leq 40$ is composite. Are there any more primes of the form $m_{n}$?","['number-theory', 'prime-numbers']"
1670306,Integral of a multivariate Gaussian distribution over quadratically separated partions,"Imagine in the space of $\Re^n$, the quadratic curve $c: f(\mathbf{x}) = \frac{1}{2}\mathbf{x}^TW\mathbf{x} + \mathbf{w}^T\mathbf{x} + w_0$ (with $W$ being a symmetric positive definite matrix, $\mathbf{w}$ a vector and $w_0$ a constant) partitions the space into two regions $c_1 = \lbrace \mathbf{x} \in \Re^n : f(\mathbf{x}) \geq 0 \rbrace$ and $c_2 = \bar{c_1}$. In this space, the random vector $\mathbf{Y}$ is distributed with a white (spherical) multivariate normal distribution ($\mathbf{Y} \sim \mathcal{N}(\mathbf{y};\mathbf{y}_0,\sigma^2 I_n)$). What is the probability that $\mathbf{y}$ is in $c_1$ or $c_2$? In other words, is there any easy trick to calculate the following integral?
\begin{equation}
Pr[\mathbf{Y} \in c_i] = \int_{\mathbf{y} \in c_i} \frac{1}{(2\pi \sigma^2)^{n/2}} exp{[-\frac{1}{2\sigma}(\mathbf{y} - \mathbf{y}_0)^T (\mathbf{y} - \mathbf{y}_0)]} d\mathbf{y}
\\i = 1,2
\end{equation}","['multivariable-calculus', 'quadratic-forms', 'gaussian-integral', 'probability-distributions']"
1670313,$\vert f(x)\vert$ is differentiable at $x=a$ then $f(x)$ is also differentiable at $x=a$,"$\vert f(x)\vert$ is differentiable at $x=a$ then $f(x)$ is also differentiable at $x=a$ Is the above statement always true? If not, can you give an example? $|x|$ and $x$ are both differentiable at $x=2$. The reverse is not always true. The example is $|x|$ itself. $y=x$ is differntiable at $x=0$ but $|x|$ is not.","['algebra-precalculus', 'functions']"
1670333,One-variable continuity of one partial derivative implies differentiability?,"I am interested in a particular instacne of the phenomena ""Partial derivatives + (A certain degree of) continuity"" implies differentiablilty. My case assumes less regularity than usual: Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}, (x_0,y_0) \in \mathbb{R}^2$. Assume that the partial derivatives of $f$ with respect to $x$ and $y$ exist at the point $(x_0,y_0)$ and one of them exists and continuous w.r.t to the other variable (for instance the function $y \mapsto\frac{\partial{f}}{\partial x}(x_0,y)$ is continuous at the point $y_0$). Is it true that $f$ is differentiable at $(x_0,y_0)$? Note: It is known that if both partial derivatives exists, and one of them is continuous (as a functions of two variables) then $f$ is differentiable. (For a proof see here ). However, the proof uses: 1) The existence of $\frac{\partial{f}}{\partial x}$ on some ball around $(x_0,y_0)$ (I assume only $\frac{\partial{f}}{\partial x}$ exists on $\{x_0\} \times (y_0-\epsilon,y_0+\epsilon)$). 2) The continuity of $(x,y) \mapsto \frac{\partial{f}}{\partial x}(x,y)$ at $(0,0)$. (I assume only continuity of $\frac{\partial{f}}{\partial x}(x_0,y)$).","['multivariable-calculus', 'partial-derivative', 'calculus']"
1670337,Find the value of $\sum_{n=2}^{\infty}\log\left(1-\frac{1}{n^2}\right)$ [duplicate],"This question already has answers here : Computig the series $\sum\limits_{n=2}^\infty \ln\left(1-\frac{1}{n^2}\right)$ (4 answers) Closed 6 years ago . Find the value of $$\sum_{n=2}^{\infty}\log\left(1-\frac{1}{n^2}\right)$$ I tried expressing the sum like $\sum a_r-a_{r-1}$.
$$\sum_{n=2}^{\infty}\log\left(1-\frac{1}{n^2}\right)=\sum_{n=2}^{\infty}\log\left[\left(1-\frac{1}{n}\right)\left(1+\frac{1}{n}\right)\right]=\sum_{n=2}^{\infty}\log\left(\frac{n-1}{n}\right)-\log\left(\frac{n}{n+1}\right)$$ I got stuck here. Is there any other simpler method?","['algebra-precalculus', 'summation']"
1670380,To find whether $f:\mathbb{N}\to\mathbb{N}$ defined with $f(x)=\left\lfloor\frac{x+1}{2}\right\rfloor$ is one-one and onto,"$f$ is a function from $\mathbb{N}$ to $\mathbb{N}$ . $$
f(x)=
\begin{cases}
x+1 & \text{ if } x \text{ is odd} \\
x-1 & \text{ if } x \text{ is even}
\end{cases}
$$ I have proved it one-one by taking $x_1$ and $x_2$ either even or odd and putting $f(x_1)=f(x_2)$ , which gives $x_1=x_2$ . And for onto, I took $f(x)=y$ , for both cases, and then found its inverse, which is defined for all $x$ belonging to $\mathbb{N}$ . There is another function from $\mathbb{N}$ to $\mathbb{N}$ $$
f(x)=
\begin{cases}
\frac{x+1}{2} & \text{ if } x \text{ is odd} \\
\frac{x}{2} & \text{ if } x \text{ is even}
\end{cases}
$$ To find: whether it is bijective or not.
I followed the same procedure as above but it gives that it is bijective.
But the answer is that it's not one-one but it's onto.
Someone suggested to take one more case as $x_1$ is odd and $x_2$ as even while finding the proof for one-one, and here I got totally stuck.","['functions', 'functional-equations']"
1670382,$\lim_{x \to 2} \frac{x^{2n}-4^n}{x^2-3x+2}$,"Calculate the limit $$\lim_{x \to 2} \frac{x^{2n}-4^n}{x^2-3x+2}$$ I tried to use 
$$\lim_{x \to 2} \frac{(x^2)^n-4^n}{x^2-3x+2}$$ but i can't find anything special",['limits']
1670449,Does strictly convex imply invertible gradient?,"If $f:\mathbb R^n \to \mathbb R$ is strictly convex and continuously differentiable, does this imply that $\nabla f$ is a one-to-one mapping? To be precise, can we say that $x, y \in \mathbb R^n$ and $\nabla f(x) = \nabla f(y)$ implies $x = y$ ?","['scalar-fields', 'inverse-function', 'convex-analysis', 'multivariable-calculus', 'inverse']"
1670457,"Construct a continuous function $f$ over $[0,1]$ satisfying $f(0) = f(1)$ but $f(x) \neq f(x+a)$","Suppose $0 < a < 1$ is not of the form $\dfrac{1}{n}$ for positive integer $n$. Construct a continuous function $f$ over $[0,1]$ satisfying $f(0) = f(1)$ but $f(x) \neq f(x+a)$ for all $x \in [0,1-a]$. This is a follow up question to this . I am wondering how it is possible to construct such a function. I would start by saying $g(x) = f(x)-f(x+a) \neq 0$ for all $x$ in the domain and then doing casework on the values of $g(x)$. But this unlike the last question doesn't have a nice casework for the values of $g(x)$ so I am stuck.",['calculus']
1670464,Difficulty in understanding a part in a proof from Stein and Shakarchi Fourier Analysis book.,"Theorem 2.1 : Suppose that $f$ is an integrable function on the circle with $\hat f(n)=0$ for all $n \in \Bbb Z$. Then $f(\theta_0)=0$ whenever $f$ is continuous at the point $\theta_0$. Proof : We suppose first that $f$ is real-valued, and argue by contradiction. Assume, without loss of generality, that $f$ is defined on $[-\pi,\pi]$, that $\theta_0=0$, and $f(0) \gt 0$. Since $f$ is continuous at $0$, we can choose $ 0\lt \delta \le \frac \pi2$, so that $f(\theta) \gt \frac {f(0)}2$ whenever $|\theta| \lt \delta$. Let $$p(\theta)=\epsilon + \cos\theta,$$
  Where $\epsilon \gt 0$ is chosen so small that $|p(\theta)| \lt 1 - \frac \epsilon2$, whenever $\delta \le |\theta| \le \pi$. Then, choose a positive $\eta$ with $\eta \lt \delta$, so that $p(\theta) \ge 1 + \frac \epsilon2$, for $|\theta| \lt \eta$. Finally, let $p_k(\theta)=|p(\theta)|^k$, and select $B$ so that $|f(\theta)| \le B$ for all $\theta$. This is possible since $f$ is integrable, hence bounded. By construction, each $p_k$ is a trigonometric polynomial, and since $\hat f(n)=$ for all $n$, we must have $\int_{-\pi}^{\pi} f(\theta)p_k(\theta)\,d\theta=0$ for all $k$. I understood the first paragraph clearly. But the rest is not making it's way into my head. In the beginning of second paragraph, how does the given range works for choosing $\delta$? If the continuity is used to get the range, then how? How can we choose $\epsilon$ so small such that, $|p(\theta)| \lt 1 - \frac \epsilon2$, whenever $\delta \le |\theta| \le \pi$? How can we choose positive $\eta$ with $\eta \lt \delta$, so that $p(\theta) \ge 1+ \frac \epsilon2$, for $|\theta| \lt \eta$. Why do we must have $\int_{-\pi}^{\pi}f(\theta)p_k(\theta)\,d\theta=0$ for all $k$?","['fourier-series', 'polynomials', 'fourier-analysis', 'continuity', 'integration']"
1670508,Solve $\lim_{n\to \infty}\left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{n+n}\right)$ without using Riemann sums. [duplicate],"This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 3 years ago . The natural way (and I think, the easier) to solve
$$\lim_{n\to \infty}\left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{n+n}\right)$$ involves Riemann sums. Multiplying and dividing by $n$, we get $$\lim_{n\to \infty}\left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{n+n}\right)=\frac{1}{n}\sum_{i=1}^{n}\frac{n}{n+i}=\frac{1}{n}\sum_{i=1}^nf\left(\frac{i}{n}\right)$$ where $f(x)=\frac{1}{1+x}$. The last expression is a Riemann sum associated to the partition $P_n=\{0, \frac{1}{n},\dots,\frac{n}{n}\}$ of $[0,1]$, so by Darboux Theorem $$\lim_{n\to \infty}\frac{1}{n}\sum_{i=1}^nf\left(\frac{i}{n}\right)=\int_0^1\frac{1}{1+x}dx=\ln2$$ However, I'm curious if there are other techniques that can be used to find that limit, so my question is Is it possible to find $$\lim_{n\to \infty}\left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{n+n}\right)$$ without using Riemann sums? If so, how?","['integration', 'calculus', 'riemann-sum']"
1670611,$\sigma$-algebra containing all singletons,"Let $\mathcal{A}$ be the minimal $\sigma$–algebra on $\mathbb{R}$ which contains all singletons,i.e. one-element sets.
How can we describe the sets in $\mathcal{A}$ ?",['measure-theory']
1670628,Sine of an angle of an Acute Triangle.,"My book shows an acute triangle $ABC$ with a circle of radius $r$ circumscribed. $ABC$ is placed inside the circle such that $\overline {AB}=2r$. And then there is a statement, $$\sin{\angle A}=\frac{BC}{BA}$$ However Sine of $\angle A$ should be the ratio, $$\frac{h}{AC}$$ where $h$ is the height of triangle.","['trigonometry', 'geometry']"
1670640,Proving the lines $AB$ and $PQ$ are perpendicular,"The points A, B, C and D, in this particular order, lie on a circle. The chords AC and BD intersect in the point P, the line through $C$ perpendicular to AC and the line through $D$ perpendicular to BD intersect in the point Q. How do you prove that the line AB and PQ are perpendicular to one another? NOTE: the chords do not have to be perpendicular to one another! Note The following image makes both lines evidently nontangent to the circle. OP's last drawing makes the line perpendicular to BD seem tangent. Thanks GeoGebra :).",['geometry']
1670675,Interpretation of SVD for non-square matrices.,"I was reading the Wikipedia article on Singular Value Decomposition . It shows a nice visualisation where the SVD of a matrix $M = U\Sigma V^*$ allows us interpret M as a rotation $V^*$, followed by a scaling $\Sigma$, and a second and final rotation $U$. That makes perfect sense when $M$ is a square. Now, how can I interpret the decomposition of a non-square matrix? If I take as a simple example a real row matrix $M$, then $U$ always seems to be a scalar equal to 1 or -1 (which also makes total sense), and $\Sigma$ has a single non-zero entry, namely the first SV. And what does the matrix $V^*$ represent?","['svd', 'linear-algebra']"
1670687,A question about complete metric spaces.,"Is there a theorem which states: ""Every infinite metric space that is complete, connected and locally connected, is arc-wise connected""?",['general-topology']
1670753,"Given $S \in B(Y^{*}, X^{*})$, does there exist $T\in B(X,Y)$ such that $S=T^{*}$?","Let $X, Y$ be Banach spaces, $S \in B(Y^{*}, X^{*})$. Does such operator $T \in B(X, Y)$ exist so that $T^{*}=S$? I suppose that the answer should be - no. Are there any hints that might help in constructing a counterexample? Any help would be much appreciated.","['functional-analysis', 'banach-spaces', 'operator-theory']"
1670761,"If $X $ is distributed as $ U(0,1)$ what is the distribution of $Y = X^3$?","If $X $ is distributed as $ U(0,1)$ what is the distribution of $Y = X^3$?. I have managed to find that, since for $ x \in [0,1]$ we ahve that $g(x) = x^3$ is strictly monotone, then the distribution function is $f_Y(y) = 1/3 y^{-2/3}$ but I can't recognise this as any standard distribution?","['calculus', 'probability-distributions', 'algebra-precalculus', 'statistics', 'probability']"
1670816,Eigenvalues of large tridiagonal matrix,"Given $a, b \in \Bbb R$ , consider the following large tridiagonal matrix $$M := \begin{pmatrix}
        a^2 & b & 0 & 0 & \cdots \\
        b & (a+1)^2 & b & 0 & \cdots & \\
        0 & b & (a+2)^2 & b & \cdots  \\
        \vdots  & \vdots  & \vdots & \vdots & \ddots
        \end{pmatrix}$$ What can be said about its eigenvalues? Are analytic expressions known? Or, at least, properties of the eigenvalues?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'tridiagonal-matrices']"
1670818,What is the third quartile when there are no data above the median?,"I'm a programmer, so apologies if this is a bad question.  I'm writing some code that needs to detect outliers.  I am currently calculating first and third quartiles.  In a sample set of data, I have the following numbers: 179,179,179,178,177 The median comes out to 179 and the first quartile 178, but since there is no number above the median what should I do?  Or what if all the numbers were the same?  Is the quartile the median? This is my reference.","['statistics', 'median']"
1670828,Peano's Existence Theorem - Constructing Maximum and Minimum Solutions,"Suppose that $D=[a, b] \times \mathbb{R}$ is a strip in $\mathbb{R}^2$, and that $f(x, y)$ is continuous and bounded on $D$. Let $(x_0, y_0)$ be an interior point of $D$ (i.e. $a< x_0 <b$). Prove that there are two integral curves $y=\phi_1 (x)$ and $y=\phi_2 (x)$, i.e. the maximum and the minimum solutions to the equation $\frac{dy}{dx}=f(x, y)$, such that (1). $\phi_1 (x_0)=\phi_2 (x_0)=y_0$ and $\phi_1 (x)\geq \phi_2 (x), \forall x\in [a, b]$; (2). the region $\{(x, y)\in \mathbb{R}^2 | a\leq x \leq b, \phi_2 (x)\leq y\leq \phi_1 (x)\}$ can be completely filled by integral curves passing through $(x_0, y_0)$; (3). There are no solutions (integral curves) to $\frac{dy}{dx}=f(x, y)$ passing through $(x_0, y_0)$ that lies outside the region in (2). Below is a sketch of solution given by my TA. By Peano's existence theorem, since $f$ is continuous and bounded on $D$, there exists, in a neighborhood of $x_0$, some function $y=y(x)$ such that $\frac{dy}{dx}=f(x, y)$ and that $y(x_0)=y_0$. By fundamental theorem of calculus, we have that $$y'=f, y(x_0)=y_0 \iff y(x)=y_0+\int_{x_0}^{x} f(t, y(t))dt$$ Let $y_{max}$ be the largest integral curve and $y_{min}$ the smallest. Then $$y_{max}-y_{min}=\int_{x_0}^{x} \Big[f(t, y_{max}(t))-f(t, y_{min}(t))\Big] dt\geq 0$$ These may be constructed using an Euler approximation on the integral to recursively build the max and the min . Any integral curve in-between may also be created since we may take any value between the max and the min in the recursion. The idea he presented is very natural, but what is confusing me is the bolded part. I really have no idea how to build the max and the min recursively. Can anyone explain how to proceed? Any help is appreciated!","['real-analysis', 'ordinary-differential-equations', 'proof-explanation']"
1670844,Show that $||f||_{\infty} = \lim\limits_{p \to \infty} ||f||_p$,"Let $(F,\Omega, \mu)$ be a measure space with $\mu(F) < \infty$. Suppose $f: F \to \mathbb R$ is measurable. Define: $||f||_p = \displaystyle\bigg(\int_F|f|^pd\mu\bigg)^{1/p}$ and $||f||_\infty = \inf \{C \in [0,\infty]: |f| \leq C, \mu-\text{a.e.}\}$. Show that: $||f||_{\infty} = \lim\limits_{p \to \infty} ||f||_p$. We have: $0 \leq |f| \leq ||f||_\infty \Rightarrow \displaystyle\bigg(\int_F|f|^pd\mu\bigg)^{1/p} \leq \bigg(\int_F||f||_\infty^pd\mu\bigg)^{1/p} \Leftrightarrow ||f||_p \leq \mu(F)^{1/p}||f||_\infty$.
When $p \to \infty$, we obtain: $\lim\limits_{p \to \infty} ||f||_p \leq ||f||_\infty$. How to prove the reverse?",['measure-theory']
1670849,When is 2 a quadratic residue in a finite field?,"If $F$ is a finite field of order $q$, where $q$ is an odd prime power, then when is $2$ a quadratic residue in $F$? I know the result for when $q$ is prime. I also know a theorem which says that: If $p$ is an odd prime and $gcd(a,p)=1$, then for any $k\geq 1$, $a$ is a quadratic residue modulo $p^{k}$ if and only if $a$ is a quadratic residue modulo $p$. So this tells me that if $q=p^{k}$ then $2$ is a quadratic residue modulo in $F$ iff $p\equiv 1,7 \mod 8$. But is there no equivalent result which only involves congruences of $q$? Many thanks for any help!","['number-theory', 'finite-fields', 'quadratic-residues', 'elementary-number-theory']"
1670851,How to find $\angle$ b?,"How to find  $\angle$ b ? The vertices of the triangle are on the foci of the ellipse and on the ellipse. $\angle$ a, the major axis and eccentricity are known.",['trigonometry']
1670858,Pointwise convergence of a Legendre polynomial expansion,"$\langle\cdot,\cdot\rangle$ is the dot product on the real vector space $\mathcal C ([0,1],\mathbb R)$ defined by $\langle f,g\rangle = \int_{-1}^1 fg$, and $(L_n)$ is the family of normalised Legendre polynomials $((X^2-1)^n)^{(n)}$ divided by their $\langle\cdot,\cdot\rangle$-norm.
Given a function $f$ such that the series
$$
\sum \langle f,L_n \rangle
$$
converges absolutely, I have to show that the series of functions
$$
\sum \langle f,L_n \rangle L_n
$$
converges pointwise to $f$. Now, I know that it converges to $f$ in the $\mathcal L^2$ sense: $\sum_{k=0}^n\langle f,L_n\rangle L_n \xrightarrow{\|\cdot\|_2}f$ since the $(L_n)$ form a complete orthonormal set of vectors, and I would only need to show the aforementioned series converges pointwise to some function $g$ to conclude, as then $f-g$ would be of ${\|\cdot\|}_2$-norm zero and thus zero. How do I show this ?","['real-analysis', 'fourier-series', 'legendre-polynomials', 'sequences-and-series', 'linear-algebra']"
1670861,Let $A\in M_n(\mathbb R)$ is a non-zero symmetric zero-diagonal matrix and its elements are $0$ ore $1$. What we can say about eigenvalue of $A$?,"Let $A\in M_n(\mathbb R)$ is a non-zero symmetric zero-diagonal matrix and its elements are $0$ ore $1$. We know that the eigenvalue of $A$ are real. I'm interesting to know the number of distinct eigenvlue of the matrix $A$. How many of them are greater than $1$ and how many of them are lower than $1$? Since $\mathrm{trac}(A)=0$, we get that some eigenvalue of $A$ is negative and some of them are positive. In the case that $A=[a_{ij}]$ and $\Pi_{i\ne j}a_{ij}=1$ (i.e. $a_{ij}=1$ for $i\ne j$ and $a_{ii}=0$) the answer is easy and the eigenvalues are $\lambda_1=n-1$ by repeated order $1$ and $\lambda_2=-1$ by repeated order $n-1$. My question is about the case that: $\Pi_{i\ne j}a_{ij}=0$ (i.e. there is $i\ne j$ which $a_{ij}=a_{ji}=0$).","['eigenvalues-eigenvectors', 'matrices', 'minimal-polynomials', 'spectral-graph-theory', 'linear-algebra']"
1670867,Are the additive group of rationals and the multiplicative group of positive rationals isomorphic? [duplicate],"This question already has answers here : Group of positive rationals under multiplication not isomorphic to group of rationals (4 answers) Closed 8 years ago . This question is a little bit different from Group of positive rationals under multiplication not isomorphic to group of rationals since I was wondering if logarithmic function could solve this or not, thank you. Consider two groups $(\mathbb Q^+,\cdot)$ and $(\mathbb Q,+)$, does an isomorphism exist between them? My attempt: Let $\varphi:\mathbb Q^+\rightarrow\mathbb Q$ be the isomorphic function, then the below statement must hold true for all $a,b\in\mathbb Q^+$:
$$\varphi(a\cdot b)=\varphi(a)+\varphi(b)$$
So I guess maybe a logarithmic function would be fine here, since it's bijective, too. But the problem is I can not show for a specific base like $10$ for example, $\log(\mathbb Q^+)=\mathbb Q$.","['logarithms', 'group-theory', 'group-isomorphism']"
1670898,Definition of $\operatorname{arcsec}(x)$,"My calculus book gives for the derivative of $\operatorname{arcsec}(x)$ : $$\frac{d}{dx} \sec^{-1}x=\frac{1}{|x|\sqrt{x^2-1}}$$ Then it continues to state that: ""Some authors prefer to define $\sec^{-1}$ as the inverse of the restriction of $\sec(x)$ to the separated intervals $[0,\pi/2)$ and $[\pi,3\pi/2)$ because this prevents the absolute value from appearing in the formula for the derivative"" Question: what does this mean? What is: ""the inverse of the restriction of $\sec(x)$ to the separated intervals $[0,\pi/2)$ and $[\pi,3\pi/2)$ ""?","['trigonometry', 'calculus']"
1670900,Primes of the form $x^3+y^3+z^3 - 3xyz$,"Do quadruplets $(x,y,z,p)$ of positive integers exist for which $p$ is a prime number and $$x^3+y^3+z^3 = 3xyz + p?$$ 
I've tried looking for solutions in mathematica for $x,y,z<1000$, without finding any. Unfortunately, looking at the equation $\mod 3$ or $\mod 9$ has yielded no result. Is there anyone who can help? Thanks. EDIT: I just discovered a fatal flaw in my mathematica code. vrugtehagel rightfully pointed out that $8^3+8^3+7^3 - 3\cdot8\cdot8\cdot7 = 23$ is a valid solution to this problem.","['number-theory', 'prime-numbers', 'diophantine-equations', 'elementary-number-theory']"
1670903,How many different functions we have by only use of $\min$ and $\max$?,"We can making many functions of three variable by only use and combining of $\min$ and $\max$ functions. But many of them are not different , like : $$\min(x,y,z)=\min(x,\min(y,z)),\quad\min(x,\max(x,y))  = \min(x,x) = \max(x,x)$$ How many different functions $\mathbb R ^3 \rightarrow \mathbb R$ of this form we have? The upper bound of numbers of this functions is $3^{3!}$ . Because there are only $3!$ states for $x , y , z$ like: $ x < y < z$ and $ x < z < y$ and ... and each state gives one of the values of $\{x,y,z\}$ . And my second question is : How many different functions $\mathbb R ^n \rightarrow \mathbb R$ of this form we have ?","['lattice-orders', 'functions', 'combinatorics', 'oeis', 'discrete-mathematics']"
