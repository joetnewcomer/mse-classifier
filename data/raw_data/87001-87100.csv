question_id,title,body,tags
1158413,Tangents in Harmonic Progression,"Here is a problem I am working on: In triangle ABC, $\tan(A)$, $\tan(B)$, and $\tan(C)$ form a harmonic progression. Also, $BC=189$ and $AB=459$. Find AC. My progress so far:
Because tanA, tanB, and tanC are in harmonic progression, $\tan(B)=\frac{(2\tan(A)\cdot\tan(C))}{(\tan(A)+\tan(C))}$. Also, we can compute AC using law of Cosines if we can find $\cos(B)$.
However, I am stuck from here. Any tips?","['geometry', 'trigonometry']"
1158427,"Dual Space Annihilator in C[0,1]","Let $V = C[0,1]$ and let U be the subspace of functions of the form 
$y(x) = ax+b$ for some a, b depending on the function.  Give an explicit family of functionals $F\subset U^\perp$ such that for any $y \in V$ satisfying f(y) = 0$\ \  \forall f \in F$, we have$\  y\in U$. In other words, in $V^{**}$, we have$$span F^\perp\cap\phi(V) = \phi(U).$$ Help Please","['linear-algebra', 'real-analysis']"
1158430,Is there a null-set whose translations generate the set of all null-sets?,"Under the Lebesgue measure, is there a null-set $N$ whose translations generate the set of all null-sets when closed under countable unions and countable intersections? I know that such an $N$ cannot be countable, since the set of all countable sets produce nothing new under countable unions and countable intersections.","['measure-theory', 'lebesgue-measure']"
1158473,What's the difference between a Banach Algebra and a C*-algebra?,I'm currently looking at going into a PhD program in mathematics and need to decide on a specialization. In meeting with my advisor he pushed me into looking at C*-algebras based on my interests. However specialists in the field seem to be rather rare and in expanding my search it seems that Banach Algebra's are closely related but I'm not entirely sure on the distinction (other than C*-algebras seem to be a specific form of Banach's). Can someone tell me the difference?,"['operator-algebras', 'banach-algebras', 'functional-analysis', 'analysis']"
1158510,Left Hand Derivative Definition,What is the actual definition of Left Hand Derivative? I bumped into this site and the second white box on their site gives the definition. Is that wrong? What is the correct one then?,"['derivatives', 'definition']"
1158518,what does the set containing only the zero vector actually span?,"I apologize if this sounds stupid but I am struggling to grasp the following concept. I understand that the span of the empty set is the zero vector. However, what does the set only containing the zero vector span? The zero vector as well? Also, are the following two phrases logically equivalent, ""The span of the empty set is the zero vector"" and ""The empty set spans the zero vector"". I believe they do but I don't want to make any assumptions since I'm not entirely sure myself. Thank you.","['span', 'linear-algebra']"
1158521,"A sequence for which the set of limits points is the interval $[0,1]$.","My professor challenged me to find a sequence with limit points the whole interval $[0,1]$ .","['sequences-and-series', 'examples-counterexamples', 'real-analysis', 'limits']"
1158558,Proof of a limit of a sequence,"I want to prove that $$\lim_{n\to\infty} \frac{2n^2+1}{n^2+3n} = 2.$$ Is the following proof valid? Proof $\left|\frac{2n^2+1}{n^2+3n} - 2\right|=\left|\frac{1-6n}{n^2+3n}\right| =\frac{6n-1}{n(n+3)} $ (because $n \in \mathbb N^+)$. $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (*)$ We have $n \ge 1 \implies 6n -1 > n + 3 \implies \frac{n+3}{n(n+3)} < \frac{6n-1}{n^2+3n}.$ Let $\epsilon > 0$ be given. Note that $ \frac{6n-1}{n^2+3n}< \epsilon \iff \frac{n+3}{n(n+3)} < \epsilon \iff n > \frac{1}{\epsilon}.$  $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (**)$ By the Archimedean Property of $\mathbb R$, $\exists N \in \mathbb N^+$ such that $N > \frac{1}{\epsilon}.$ If $n \ge N$, then $n > \frac{1}{\epsilon}$, and from $(*)$ and $(**)$ it follows that $\left|\frac{2n^2+1}{n^2+3n} - 2\right| < \epsilon$. Therefore $\lim_{n\to\infty} \frac{2n^2+1}{n^2+3n} = 2.$","['proof-verification', 'real-analysis', 'limits']"
1158579,Expressing in terms of symmetric polynomials.,"How to express $$a^7+b^7+c^7$$  in terms of symmetric polynomials ${\sigma}_{1}=a+b+c$, ${\sigma}_{2}=ab+bc+ca$ and ${\sigma}_{3}=abc$ ?","['algebra-precalculus', 'functions', 'polynomials']"
1158585,Number of Words with two letters $a$ and $b$.,"Given $N$ and $M$, find the number of $N$ letter words consisting of only $a$ or $b$, where $b$ must not be consecutive for more than or equal to $M$ times. Example: if $N=3$ and $M=2$, then all the possible words are: $\{aaa , aab , aba , baa , bab\}$.","['permutations', 'combinatorics']"
1158598,How to compute these Riemann-Stieltjes-Integrals?,"I have some doubt on this exercise which I have to solve: Compute The Integral $\displaystyle \int_0^4 F(x) \ \mathrm{d}G(x)$ for 1.) $F(x) = x$ for $x<2$, $1$ otherwise; $G(x)=x^2$ 2.) $F(x) = e^{-x}$ ; $G(x) = 0$ for $x<2$, $4$ for $2≤x<3$ and $-2$ otherwise. 3.) $F(x)=(1+i)^{\lfloor -x\rfloor}$ with $i$ in $(0,1)$; $G(x) = 0$ for $x<0$, $1$ for $0≤x<1$, $2$ for $1≤x<2$ and $\sin(\pi \cdot x)$ otherwise. On 2.) I think the integral will be $0$ because $F$ is continuous, $G(x)$ is constant and there are no common discontinuity points between $F$ and $G$. On 3.) There are common discontinuity points like $0,1,2$. So there doesn't exist an Integral. Now my question is, how to find the integral in 1.)? Because $F$ is not continuous but $G$ is continuously differentiable. So $\mathrm{d}G(x)=G'(x)\mathrm{d}x$.
I tried to calculate the integral in two parts. One from $0$ to $2$ and the other one from $2$ to $4$. But There does not exist a value $F(x)=x$ for $2$. So I don't how to compute the first integral.
How can I solve this problem?
Am I right in 2.) and 3.)?","['integration', 'analysis']"
1158601,A geometry problem (how to find angle x),The solution is $x=50^{\circ}$. How to prove $x=50^{\circ}$ without trigonometry?,['geometry']
1158619,Do there exist functions $f$ such that $f(f(x))=x^2-x+1$ for every $x$?,"My question is on the existence (or not) of a function $f:\mathbb{R}\to\mathbb{R}$ which satisfy the equation: $$f(f(x))=x^2-x+1 \text{ for every }x\in\mathbb{R}$$ Supposing that such a map do exist I was able to prove until now that: $f(x)=1$ iff $x=0$ or $x=1$ $f(x)\ne 0$ for every $x$ $f(x^2-x+1)=f^2(x)-f(x)+1$ for every $x$ $f(x)\ge\frac{3}{4}$ if $x\ge\frac{3}{4}$ For each $x$ it holds that $f(x)=f(1-x)$ or $f(x)+f(1-x)=1$ $f(x)<f(x^2-x+1)$ for all $x\in\mathbb{R}\setminus\{0,1\}$","['algebra-precalculus', 'functional-equations']"
1158623,Sum of all solutions of $(x^2+5x+5)^{(x-3)(x-7)}=1$,"Find the sum of all solutions of $(x^2+5x+5)^{(x-3)(x-7)}=1$ An obvious approach is to consider the case where the exponent is $0$ which yields the solutions $3,7$ and then the case where the base is $1$ which yields the solutions $-1,-4$ and then finally to consider the case where base is $-1$ and the exponent is even,which yields the solution $-3$. But the thing is,how do we know these are the only solutions.I don't see any reason these should be the only solutions.Why can't there be complex solutions,or perhaps even more real solutions.Graphing might give us insight,but I don't have any good graphing software at the moment. I have also thought about using Vieta's formulas,but that seems to complicate things. Any help,hint or prod in the right direction will be appreciated.Also,is there any way we can know about how the graph of the function will behave without actually graphing the function?",['algebra-precalculus']
1158640,Book suggestions: Introduction to Measure Theory for non-mathematicians,"I am taking some courses about stochastic processes, Markov chains, ... and there we need basic measure-theoretic probability theory. My background is computer science, where I had an introductory course about probability and statistics from a quite applied point of view. Moreover, almost all I had up to now was discrete probability theory. Additionally, we had almost nothing in analysis, so my knowledge there is also quite modest. Now I am confronted with expressions like ""almost surely"", ""$\sigma$-algebra"", ""measurable space"", ""measurable function"", and so on. I've read some definitions about $\sigma$-algebras and so on, so together with my background of discrete probability theory I know a little bit what they are talking about but I am missing the essentials. So I plan to learn all the basics for probability theory and measure theory at some point, but now my goal is to learn all the important things I need to know to follow the courses in Stochastic Processes in a more or less short time. Do you know a ""friendly"" book covering these topics at a somehow ""superficial"" level such that a non-mathematician can follow it and at the same time provides all the essential things to understand stochastic processes (from an applied point of view)? Thank you very much. EDIT: I know that there are other questions asking for measure theory books. But I am searching for a somehow easier book for non-mathematicians.","['probability-theory', 'measure-theory', 'book-recommendation', 'reference-request']"
1158694,Definition of a bounded sequence,"My professor gave the following definition: A sequence $\{x_n \}$ is said to be bounded if $\exists M > 0$ such that $|x_n| \le M$ for all $n \in \mathbb N^+.$ But then what about the sequence $(0, 0, ...)$? In that case, can't $M$ be $0$? Wikipedia provides the following definition, which seems more reasonable to me: A sequence $\{x_n \}$ is said to be bounded if $\exists M \in \mathbb R$ such that $|x_n| \le M$ for all $n \in \mathbb N^+.$ Is my professor's definition inaccurate or imprecise in any way?","['sequences-and-series', 'real-analysis', 'definition']"
1158779,Is this restatement of Gauss's lemma correct?,"This seems extremely trivial but I want to make really sure so I'm posting it. This is a yes or no question.. (Sorry for posting this kind of question but I really wonder if I think wrong) Here is a Gauss's lemma (Dummit&Foote version) Let $R$ be a UFD and $F$ be the field of quotients of $R$ . Let $A,B\in F[X]$ be nonconstant polynomials such that $AB\in R[X]$ .
Then, there are nonzero elements $r,s\in F$ such that $rA, sB$ both lie in $R[X]$ and $AB=(rA)(sB)$ . Is this statement equivalent to the below statement? Let $f,g\in F[X]$ be nonzero polynomials such that $fg\in R[X]$ . Then, there exists $r\in F\setminus\{0\}$ such that $rf$ and $\frac{1}{r} g$ both lie in $R[X]$ . (I'm asking this since I don't get why Dummit&Foote wrote two symbols $r,s$ rather than $r,\frac{1}{r}$ )",['abstract-algebra']
1158783,Limits in category of cones.,"I'm trying to do exercise 2.17.2 in Borceux's ""Handbook of Categorical Algebra"": Consider a functor $F: \mathfrak{D} \to \mathfrak{C}$ and the category of cones on $F$. Show that $F$ has a limit if and only if the functor $U$ from the category of cones on $F$ to $\mathfrak{C}$ mapping a cone to its vertex has a colimit. Here is what I thought, however I'm not sure if I should take a different approach or just fill the gaps in the proof.  I hope you can help me: $\Rightarrow$ If $F$ has a limit $L$ we know that  limit is a terminal object in the category of cones on $F$ .So the inclusion functor is a final functor. And we get the result. $\Leftarrow$ Now suppose $U$ has a colimit $L$, now we fix some $D \in \mathfrak{D}$ and there exists morphisms from each cone vertex to $FD$.
This makes $FD$ the vertex of a cocone $\implies \exists ! ~ \alpha_D: L \to FD$. So $(L, \alpha_D)$ is a cone such that for every other cone $C_i, ~ \exists ~ h_i: C_i \to L$.  How do I prove uniqueness of the factorization? PS: I edited the first implication because I found a proposition that helped me. So i just need to finish the last one.","['category-theory', 'abstract-algebra']"
1158798,Show that the dual norm of the spectral norm is the nuclear norm,"Could someone help me understand why the dual norm of the spectral norm is the nuclear norm? We can focus on the real field. Given a matrix $X \in \mathbb{R}^{m \times n},$  then the spectral norm is defined by $$\left \| X\right\| = \max\limits_{i \in \{1, \dots, \min\{m,n\}\} }\sigma_i (X)$$ whereas the nuclear norm is defined by $$\left \| X \right \|_* = \sum\limits_{i=1}^ {\min\{m,n\}} \sigma_i (X)$$ Can someone show me the reasoning process? Thank you in advance.","['matrix-norms', 'matrices', 'linear-algebra', 'nuclear-norm', 'spectral-norm']"
1158879,Finding $ \lbrace a_{n}\rbrace $ s.t. $\mathop {\lim }\limits_{n \to \infty }a_{n}=1$ and $\mathop {\lim }\limits_{n \to \infty }a_{n}^{n}=2015$,The following problem appears in our analysis assignment. Find a sequence $ \lbrace a_{n}\rbrace $ of real numbers such that $$\mathop {\lim }\limits_{n \to \infty }a_{n}=1\text{ and }\mathop {\lim }\limits_{n \to \infty }a_{n}^{n}=2015.$$ Could anyone give me some help to find such a sequence ? Any hints/ideas are much appreciated. Thanks in advance for any replies.,"['sequences-and-series', 'real-analysis', 'analysis']"
1158891,"If the rank of $A$ is equal to the number of non-zero eigenvalues, do $A$ and $A^2$ have the same rank?","Let $A$ be an $n$-by-$n$ matrix over some field. If it happens that $\operatorname{rank}(A)=$ number of non-zero eigenvalues of $A$, can we say that $\operatorname{rank}(A^2)=\operatorname{rank}(A)$? I believe we can say this (thinking about idempotent matrices) but I am not sure about the proof.  Please give some hints to get started and the main idea.","['vector-spaces', 'matrix-rank', 'linear-algebra', 'eigenvalues-eigenvectors']"
1158912,Why is quadratic form defined via a symmetric bilinear form?,"A typical definition of quadratic form goes like this: Let $B:V\times V \to F$ be a symmetric bilinear form. A
  function $Q : V → F$ defined by $Q(v) = B(v, v)$ is called a quadratic form. Why do we need $B$ to be symmetric if the way $Q$ is defined doesn't use it? Edit: And is that related to the reason why we ask for a symmetric bilinear form in the definition of a positive definite bilinear form even though the definition itself $(B(v,v)>0)$ again doesn't directly use it?","['vector-spaces', 'quadratic-forms', 'linear-algebra', 'multilinear-algebra']"
1158929,Character theory - Exercise 5.14,"I am trying to solve the exercise 5.14 from the Isaac Martins Character Theory of Finite Groups. Let $G$ be a nonabelian group and let $ f={\rm min}\{\chi(1) \,\,|\,\, \chi \in {\rm Irr}(G), \chi(1)>1 \}. $ Show that: (a) If $ |G'| \leq f,$ then $G'\subset Z(G)$ (b) If $[G:G'] \leq f,$ then $G'$ is abelian (c) If $H\subset G$ , and $[G:H]\leq f$ , then $G' \subset H$ For (a), the indication given is: if $x\in G$ , then $|Cl(x)|\leq |G'|$ What I have tried for (a) is the second orthogonality relation $$|G|=\sum_{\chi_i}|\chi_i^2(g)|=[G:G']+\sum_{\chi_i {\rm nonlinear}}|\chi_i^2(g)| .$$ For $g=1$ , it gives $$ |G|=[G:G']+\sum_{\chi_i {\rm nonlinear}}|\chi_i^2(1)|\geq [G:G'] +\sum_{\chi_i {\rm  nonlinear}}|f|^2=[G:G']+(k-[G:G'])|f|^2$$ where $k$ is the number of conjugacy classes. Nothing much from that. What I know as well is $|G|\geq |Z(G)|\chi(1)^2$ for any $\chi \in {\rm Irr}(G)$ (derived from the first orthogonality relation with $g \in Z(G) \Rightarrow |\chi(g)|=\chi(1)$ ).  Also $\chi(1) | [G:Z(G)]. $ I tried to show $G/Z(G)$ abelian but no success either. Can someone please help me ?","['representation-theory', 'group-theory', 'characters']"
1158936,The value of $ \int _{0}^{1}x^{99}(1-x)^{100}dx $ is,The value of $\int _{0}^{1}x^{99}(1-x)^{100}dx $ is Not able to do. I'm trying substituton. But clear failure. Please help.,"['definite-integrals', 'integration', 'factorial']"
1158950,Does $\lim_{x \to 0} \frac{\sin (\left \lfloor x \right \rfloor)}{\left \lfloor x \right \rfloor}$ exist?,"The function is defined $\mathbb{R}-[ 0,1)\to \mathbb{R}$. As $x$ approaches $0$ from the left, $\left \lfloor x \right \rfloor=-1$ hence the left hand limit is $\sin \left ( 1 \right )$. Quite clearly , the right hand limit does not exist. Now does the limit exist? On one hand , since LHL is not equal to RHL , it should not exist. On the other , the definition of limit says for all  $\varepsilon > 0$ , there exists a  $\delta > 0 $ such that for all  $x $ in  $D $ that satisfy $ 0 < | x - c | < \delta $, the inequality  $|f(x) - L| < \varepsilon$  holds. Now since we only consider all $x$ in the domain , I don't see how $x$ not being able to approach from the right creates a problem. I think the definition  is still verified if the limit is $\sin \left ( 1 \right )$. This is what we were told in class (no explanation was given , the definition thing is my idea) but I'm not very sure . Wolfram alpha says the limit does not exist.  This question - Find $\lim_{x\to 0}\frac{\lfloor \sin x\rfloor}{\lfloor x\rfloor}$ implies the same. So please help me. Thank you.","['calculus', 'functions', 'limits']"
1158956,To show that orthogonal complement of a set A is closed.,"To show that orthogonal complement of a set A is closed. My try: I first show that the inner product is a continuous map. Let $X$ be an inner product space. For all $x_1,x_2,y_1,y_2 \in X$, by Cauchy-Schwarz inequality we get,
$$|\langle x_1,y_1\rangle - \langle x_2,y_2\rangle| = |\langle x_1- x_2,y_1\rangle + \langle x_2, y_1-y_2\rangle| $$
$$\leq \|x_1- x_2\|\cdot\|y_1\| +\|x_2\|\cdot\| y_1-y_2\|$$ This implies continuity of inner products. Let $A \subset X$ and $y \in A^\perp$. To show that $ A^\perp$ is closed, we have to show that if $(y_n)$ is convergent sequence in $ A^\perp$, then the limit $y$ also belong to $ A^\perp$. Let $x \in A$, then using that inner product is a continuous map,
$$\langle x,y\rangle = \langle x, \lim_{n\to \infty} (y_n)\rangle = \lim_{n\to \infty} \langle x, y_n\rangle = 0.$$ Since $\langle x, y_n\rangle = 0$ for all $x \in A$ and $y_n \in A^\perp$. Hence $y \in A^\perp$. Is the approach\the proof correct?? Thank You!!","['vector-spaces', 'linear-algebra', 'inner-products']"
1158972,"Describe the image of the set $\{z:|z|<1, Im(z)>0\}$ under the mapping $w =\frac{2z-i}{2+iz}$","Describe the image of the set $\{z:|z|<1, Im(z)>0\}$  under the
mapping $w =\frac{2z-i}{2+iz}$ First I need to find the inverse which is $z=\frac{2w+i}{2-iw}$. Now let $w=u+iv$, we have $$z=\frac{2w+i}{2-iw}=\frac{2u+2iv+i}{2+v-iu}$$ From this I get $x= \frac{3u}{(2+v)^2 +u^2}$ and $y=\frac{5v+2u^2 +2v^2+2}{(2+v)^2 +u^2 }$ Since $Im(z)>0$, $5v+2u^2 +2v^2+2>0$ and $|z|<1$ so $ \sqrt{x^2+y^2} <1$. $$x^2 +y^2<1$$
$$(\frac{3u}{(2+v)^2 +u^2})^2 +(\frac{5v+2u^2 +2v^2+2}{(2+v)^2 +u^2 })^2 <1$$ $$3u^4+3v^4+20u^3+8v^3+6u^2v^2+8u^2v+4v^2-3v-12<0$$ Now I'm stuck, so I tried Mr. Blatter method and got$T(-1)=\frac{-2-i}{2+i}$, $T(0)=1$, $T(1)=\frac{2-i}{2+i}$, $T(i)=i$. So is this telling me that the image is the left side?",['complex-analysis']
1158986,Example of an analytic continuation for a function in integral form,"Given $f(z) = \int_{-\infty}^\infty \frac{exp(-t^2)}{z-t}\,dt$, where $Im(z)>0$. Find an analytic continuation to the region $Im(z)<0$. Firstly the solution said that there is a branch cut on the real axis but I fail to see how. I do not see why $f(z)$ is not analytic everywhere. I considered 3 cases: $Im(z)>0$ $z$ on real axis $Im(z)<0$ Using the semicircle contour in case 1 and 3 we would find, by the residue theorem, the principal value of the integral equaling $2\pi i $ times(residue at the pole t=z). Similarly we can find for case 2, $-\pi i$ (residue at the pole t=z). Secondly, the solution suggests that to continue $f(z)$ into the lower half plane, one should deform the contour on the real axis such that it includes the pole in lower half plane with a very sharp ""spike"" circulating the pole. I do not understnad this, since this way are we not just continuing to the region including only this pole?","['residue-calculus', 'analyticity', 'complex-analysis']"
1159006,How to define a compactly generated space?,"I engaged two definitions for a compactly generated space: http://en.wikipedia.org/wiki/Compactly_generated_space 1) In topology, a compactly generated space (or k-space) is a topological space whose topology is coherent with the family of all compact subspaces. Specifically, a topological space $X$ is compactly generated if it satisfies the following condition: A subspace $A$ is closed in $X$ if and only if $A\cap K$ is closed in $K$ for all compact subspaces $K\subseteq X$. http://neil-strickland.staff.shef.ac.uk/courses/homotopy/cgwh.pdf 2) A subset $Y\subseteq X$ is $k$-closed if $u^{-1}\left(Y\right)$
is closed in $K$ for every compact Hausdorff space $K$ and every
continuous map $u:K\rightarrow X$. These sets can be recognized as
the closed sets of a topology (finer than the original topology) and we say that $X$ is compactly generated
if this topology is not properly finer than the original topology. Question: are these definitions equivalent? And if not then wich is the most usual and or convenient to practicize?","['general-topology', 'compactness']"
1159017,How do I calculate: $\int \frac{dx}{3\sin^2 x+5\cos^2x}?$,How can I calculate this integral ? $$\int \frac{dx}{3\sin^2 x+5\cos^2x}=\text{?}$$ Thank you! I've tried using universal substitution but the result was too complicated to be somehow integrated. Can you please give me a useful hint ?,['integration']
1159063,How many ways to reach a given tennis-score?,"Let's say a tennis player wins a set with a game score of 6-3. In how many different ways can we reach this score? Assuming H means the home-player won the game and A means the away-player won the game, one permutation would be HHHHHAAAH. Note that the winner of the set will always have to win the last game (so maybe I could reduce this to how many permutations are there of the set of HHHHH AAA?) I realize I have almost solved the problem but I'm still having problems grasping it, any ideas or if you could point me in the correct directions would be helpful. For those unfamiliar with the tennis scoring system , a set is a sequence of games.  The set score is simply a count of how many games each player won.  For purposes of this question, all you need to know is that the first person to win a total of 6 games wins the set.","['permutations', 'combinatorics']"
1159085,How to calculate combinations of multiple variables which can assume multiple values,"I have 3 variables (A,B,C); each variable can assume 3 different values (1,2,3) .
I want to calculate ho many combinations there are which follow this rule: let's fix A1 , then cycle on all the others variables which can assume 3 values each; then let's move on to A2 and calculate again all the combinations by cycling over the 2 remaining variables (which can assume 3 values each); same thing for A3 . Once I am done with A I repeat the same process with B and so on. The constrain is that the combinations must repeat only once over all:
in fact if I fix A1 and the combination I get is ( A1 B3 C2 ), then when I fix for example B3 I must not count (A1 B 3 C2) because it has been already found before. So what I need is the mathematical formula that allows me to do this calculation with a generic number of variables which can assume a generic number of values","['permutations', 'combinations', 'combinatorics']"
1159097,Can $\prod_{i=1}^{\pi(n)} p_i^{\frac{1}{p_i-1}}$ be calculated?,"Is there a way to calculate this Product as a function of $n$? $$\prod_{i=1}^{\pi(n)} p_i^{\frac{1}{p_i-1}}$$ where $p_i$ is the $i^{\text{th}}$ prime number, and $\pi(n)$ is the Prime-counting function; Thanks.","['prime-numbers', 'products', 'number-theory']"
1159099,A question on proving the uniqueness of a mathematical object,"When proving that there is a unique mathematical object that satisfies a particular condition, e.g., the inverse of an element of a group, is the intuition behind it the following? You assume that the solution set (i.e., the set of objects that satisfy this condition) contains an arbitrary number of elements and then you choose two elements arbitrarily from this set.  Then,  if after a set of logical steps you are able to show that these two elements are actually equal, then (by the transitive property of equality) all elements of the solution set are equal to one another and hence there is actually only one unique solution.",['elementary-set-theory']
1159118,Integral inequality $\int_{0}^{1}h(x)^2dx\int_{0}^{1}x^2h(x)^2dx\ge c\left(\int_{0}^{1}h(x)dx\right)^4$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Does there exist a number $c>0$ such that for every measurable function $h:[0,1]\to\mathbb{R}$, $h(x)\ge 0~\forall x$, we have $$\int_{0}^{1}h(x)^2dx\int_{0}^{1}x^2h(x)^2dx\ge c\left(\int_{0}^{1}h(x)dx\right)^4~~~~?$$","['inequality', 'integration']"
1159148,is $f\left(x\right)\:=\:\left|x\right|^3$ twice differentiable?,"Consider the function $f\left(x\right)\:=\:\left|x\right|^3$ , $f:\mathbb{R}\rightarrow \mathbb{R}$. 1) Is it twice differentiable? And if so, how can I prove this and calculate it? 2) If it does, can I conclude it has third differentiable for every $x$? So far, for 1, I believe is true but I really stuck in the proof: $$\lim _{h\to 0}\left(\frac{f\left(x+h\right)-f\left(x\right)}{h}\right)\:=\:\lim _{h\to 0}\left(\frac{\left|x+h\right|^3-\left|x\right|^3}{h}\right)\:=\:\lim_{h\to 0}\left(\frac{\left(\left|x+h\right|^{\:}-\left|x\right|\right)\left(\left|x+h\right|^2\cdot \left|x+h\right|\left|x\right|+\left|x\right|^2\right)}{h}\right)\:$$ But how to continue from here? I also tried this approach:  $$\lim _{x\to x_0}\left(\frac{f\left(x\right)-f\left(x_0\right)}{x-x_0}\right)\:=\:\lim_{x\to x_0}\left(\frac{\left|x\right|^3-\left|x_0\right|^3}{x-x_0}\right)\:=\:\lim_{x\to x_0}\left(\frac{\left(\left|x\right|^{\:}-\left|x_0\right|\right)\left(\left|x\right|^2+\left|x\right|\left|x_0\right|+\left|x_0\right|^2\right)}{x-x_0}\right)\:\:$$
I have serious problem with the next step. Can someone guide me what tricks I need to do? Thanks in advance!","['calculus', 'derivatives']"
1159185,sup of integrals of simple functions = inf of integrals of simple functions implies f is measurable?,"Let $E \subseteq \mathbb{R}$ be measurable with $|E| < \infty$, and f a nonnegative, bounded function on E. Prove that $sup \lbrace \int_E \phi : 0 \leq \phi \leq f, \phi$ simple$ \rbrace = inf \lbrace \int_E \psi : f \leq \psi, \psi$ simple$ \rbrace$ implies f is measurable. In this case ""f is measurable"" means that $\lbrace x: f(x) > a \rbrace$ is measurable for every real number a. The whole problem is an ""if and only if"", and I was able to show the converse of this, but it isn't clear to me how this direction follows. It makes sense, as these two being equal seems like a reasonable condition for the integral existing, which can only happen if f is measurable, but I don't understand how exactly this condition implies f being measurable. There are very few statements that reliably apply to non-measurable sets in a way that I would know how to use to prove this by contradiction or contrapositive, but doing it directly doesn't seem possible either. I can't appeal to any notion of what the integral of f is or should be since I'm trying to prove that f is measurable. Any help to get started would be appreciated. (Also, I tried to make the relevant equation to the problem the title, but it didn't fit; if anyone knows a better way to express the exact problem that does fit in the space allotted for titles, please edit it in)","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'real-analysis']"
1159190,"Question from Munkres Topology Regarding the Product Topology (Section 16, Exercise 5)","Let $X$ and $X'$ denote a single set in the topologies $\mathscr T$ and $\mathscr T'$ respectively; let $Y$ and $Y'$ denote a single set in the topologies $\mathscr U$ and $\mathscr U'$ respectively.  Assume these sets are non-empty. a) Show that if $\mathscr T'\supseteq\mathscr T$ and $\mathscr U'\supseteq\mathscr U$, then the product toplogy on $X'\times Y'$ is finer than the topology on $X\times Y$. Having trouble making sense of this problem.  How can I compare the topologies if they are on different sets.?",['general-topology']
1159217,Show that $\sqrt{2}\notin \mathbb{Q}(\sqrt[4]{3})$,"I want to show that $\sqrt{2}\notin \mathbb{Q}(\sqrt[4]{3})$. I think it would be easier to prove it using the following:
$\mathbb{Q}\subset\mathbb{Q}(\sqrt{3})\subset\mathbb{Q}(\sqrt[4]{3})$. Then $\sqrt{2}\notin\mathbb{Q}(\sqrt{3})$ so $\sqrt{2}\in \mathbb{Q}(\sqrt[4]{3})\Longleftrightarrow \sqrt{2}=a+b\sqrt[4]{3}$, with $a,b\in\mathbb{Q}(\sqrt{3})$. I tried simplifying the above equation, but I did not get anything.","['galois-theory', 'extension-field', 'abstract-algebra', 'field-theory']"
1159228,General solution of partial differential equations.,"Find the general solution of the given differential equation $$ \frac{y^2}{2}-2ye^t+(y-e^t)\frac{dy}{dt}=0$$ So here is my process: Let: $$\frac{\partial \phi}{\partial t}=\frac{y^2}{2}-2ye^t$$ where: $$ \phi(y,t)=\frac{y^2}{2}t-2ye^t+h(y)$$
and let : $$\frac{\partial \phi}{\partial y}=y-e^t$$ where: 
$$ \phi(y,t)=\frac{y^2}{2}-ye^t+k(t)$$ Now I need to find k(t) and h(y) to make the two $\phi(y,t)$ equal. so this is where i'm stuck, if anyone can help, it be most appreciated.","['ordinary-differential-equations', 'calculus', 'integration']"
1159239,Let $A$ and $R$ be rings and $f : A → R$ a ring homomorphism.,"Let $A$ and $R$ be rings and $f : A → R$ a ring homomorphism. Give a concrete example of $A, R$ and a ring homomorphism $f : A → R$ such that $A$ is commutative and $R$ is not commutative. Prove that if $A$ is commutative and $f$ is surjective, then $R$ is commutative. Here is my random thought: Not sure(even though matrices count) Rough sketch: Since, $A$ is commutative, $ab = ba$, for some $a,b \in A$. And, since $f$ is a ring homomorphism, $f(ab) = f(a)f(b)$ and $f(a) = x$ and $f(b) = y$, for some $x,y \in R$, since $f$ is surjective. Then, $f(ab) = f(a)f(b) = f(b)f(a) = f(ba)$...Since A is commutative. Hence, $f(a)f(b)= xy = f(b)f(a) = yx.$ In particular, $xy = yx$ for some $x,y \in R$ Does this make sense? Please correct me if I am wrong.","['ring-theory', 'ring-homomorphism', 'examples-counterexamples', 'abstract-algebra']"
1159252,How to find equilibrium of a differential equation,"How to find equilibrium of following differential equations$$\frac{dU}{dt}=aV+bV-c\frac{UV}{U+V}$$$$\frac{dV}{dt}=-aV-bV+c\frac{UV}{U+V}$$ If we let these two equation equal to $0$, we get $(a+b)V=c\frac{UV}{U+V}$, I have no idea how to find the equilibrium, anyone could help me with this problem? Thanks very much!",['ordinary-differential-equations']
1159267,Suppose $f$ has derivatives of all orders. Prove that $F(x):=exp(f(x))$ also has derivatives of all orders.,"Suppose $f: \mathbb{R} \rightarrow \mathbb{R}$ has derivatives of all orders. Prove that $F(x):=exp(f(x))$ also has derivatives of all orders. Genuinely very confused by this question. I used an induction, but it looks really sloppy and I want some criticism. First, define the $nth$ derivative by $f^{(n)}$ I note that $exp^1(f(x))=exp(f(x))$. Thus, for $n=1$, $exp(f(x))$ is differentiable. To prove infinite differentiability, we need to show that $exp(f(x))$ is differentiable for all $n$. Suppose $exp^n(f(x))=exp(f(x))$ and is differentiable. Then, consider $exp^{(n+1)}(f(x))$. $exp^{(n+1)}(f(x))=exp^n(f(x))=exp(f(x))$ Thus, $exp(f(x))$ is differentiable for all $n$, i.e. is infinitely differentiable. This seems so naive. I know that its wrong. Please help me with a different method.","['functions', 'calculus', 'derivatives', 'real-analysis']"
1159295,Proof of the spectral theorem,"I am currently going to through my proof of the spectral theorem that we had in class, but I feel that I have copied some nonsense from the board. So we defined the Cayley transform $U= (T-i)(T+i)^{-1} = (T+i-2i)(T+i)^{-1}=id-2i(T+i)^{-1}$ and therefore $(T+i)^{-1}= \frac{1}{2i}(id-U)$. Then we showed earlier that any unitary operator can be written as $e^{iA}$ for some self-adjoint bounded $A$ such that $\sigma(A) \subset [-\pi,\pi]$. Now $-U$ is definitely unitary, as the Cayley transform is unitary, so we have $$\langle -U_t x,x \rangle =  \int e^{it}d\mu_x,$$ where $\mu_x$ is the Borel measure from the functional calculus of $A$. Thus by using  $(T+i)^{-1}= \frac{1}{2i}(id-U)$ we can write $$\langle (T+i)^{-1}x,x\rangle  = \frac{1}{2i} \int(1+e^{it}) d\mu_x$$ and now comes the problem, somehow at the end we made a $arctan$ substitution and I wrote $$\langle (T+i)^{-1}x,x\rangle  = \frac{1}{2i} \int_{\mathbb{R}} (1+e^{i \arctan(s)}) ds$$ and then we rewrote the integrand by Euler's identity so that we ende up with (this I undestand again) $$\langle (T+i)^{-1}x,x\rangle  = \frac{1}{2i} \int_{\mathbb{R}} \frac{1}{s+i} ds$$ The problem is that I don't get this substitution, is there anybody who could make this substitution of the arctan function rigorous, i.e. I don't get what this $ds$ now means, what kind of measure is this? If anything is unclear, please let me know.","['measure-theory', 'operator-theory', 'spectral-theory', 'real-analysis', 'functional-analysis']"
1159311,Stochastic Processes Solution manuals.,"Does anyone have a link or a pdf stash of solution manuals for stochastic processes ebooks? 
I am doing a self-study on this course and I can't seem to find any solution manual online to cross-check my solutions with. Any author or volume or version is ok with me. Thanks.","['stochastic-processes', 'book-recommendation', 'soft-question', 'online-resources', 'probability']"
1159386,Prove Kolmogorov's zero one law using martingales,"I am supposed to provide a martingale proof of Kolmogorov's zero-one law. Hint Let $X_n$ be independent random variables and let $\mathcal C_\infty$ be the corresponding tail $\sigma$-algebra. Let $C \in
 \mathcal C_\infty$ and $\mathcal F_n = \sigma(X_j; 0 \le j \le n)$. Show that $E[1_C\mid \mathcal F_n] = P(C)$. Then show that $\lim_{n
 \to \infty} E[1_c \mid \mathcal F_n] = 1_C$ almost surely and deduce
  that $P(C) = 0$ or $1$ I have no idea how to approach this. I would like an answer but I would love an answer that provides insights about all this. I don't have any intuition about what $C_\infty$ is, and why should I follow the outlined proof, and what's the role of martingales. EDIT 1 Let me try to provide a proof. Please point out any mistake, inaccuracy or redundancy that you can spot! I'll be most grateful. Let us note that for every finite $N$, $\mathcal C_\infty$ is independent with $\mathcal F_N$. In fact $$\mathcal C_\infty = \bigcap_{n=1}^\infty \sigma\left(\bigcup_{m \ge n} F_m\right) = \bigcap_{n=N+1}^\infty \sigma\left(\bigcup_{m \ge n} F_m\right)$$
So $\mathcal C_\infty$ is the result of operations applied only on sigma algebras independent with $\mathcal F_N$ This implies $E[1_c \mid \mathcal F_n] = E[1_C] = P(C)$. Let $\mathcal B_n = \sigma\left(\bigcup_{i \le n} \mathcal F_i\right)$. By the exact same reasoning, we find $E[1_c \mid \mathcal B_n] = P(C) \implies E[1_c \mid \mathcal B_n] = E[1_c \mid \mathcal F_n]$ This was necessary because now $\mathcal B_n$ is an increasing sequence of sigma algebra and I can apply Levy's zero one law:
$$\lim_{n \to \infty} E[1_C \mid \mathcal F_n] = \lim_{n\to \infty} E[1_C \mid \mathcal B_n] =  E[1_C \mid \mathcal B_\infty]\text{    a.s.}$$ Where $\mathcal B_\infty = \sigma\left(\bigcup_{n \ge 0} \mathcal B_n\right)$
Since $\mathcal C_\infty = \inf \mathcal B_\infty \implies \mathcal C_\infty \subset \mathcal B_\infty$ (is this correct?) the fact that $1_C$ is measurable with respect to $\mathcal C_\infty$ implies that $1_C$ is measurable with respect to $\mathcal B_\infty$, so $$\lim_{n \to \infty} E[1_C \mid \mathcal F_n] = E[1_C \mid \mathcal B_\infty] = 1_C$$ Now $\lim_{n \to \infty} E[1_C \mid \mathcal F_n] = P(C) = 1_C$, hence $P(C) = 0$ or $1$. Remarks The proof seems somewhat convoluted and it is probably better done in another way. Also, I am not really sure is it correct.
Moreover, I did not use directly martingale properties; I know Levy's zero one law is a consequence of the Martingale Convergence theorem, though. EDIT 2 I deleted my answer and decided to put my attempt in the question, so I can award points to anyone who is kind enough to help me. I didn't do so previously because the wall of text may be a deterrent to read the whole question.","['probability-theory', 'martingales', 'random-variables']"
1159388,Bijective functions,"If $A$ has $n$ elements, how many functions are there from $A$ to $A$? How
  many bijective functions are there from $A$ to $A$. So for the first part of the question since A isn't bijective, doesn't that mean there are $n^n$ possibilities? So for the second part of the question, since it is bijective means for injectivity it must be one-to-one. therefore wouldn't there be $n!$ functions. Can anyone confirm?",['functions']
1159396,Determine whether F is injective and surjective,"Let $f:\mathbb{R} \to \mathbb{R}$ be a function. Determine whether or not f is injective and surjective where $f(x)=|x|$ So if i'm right, it is not injective and it is not surjective. For a proof, i'll do a counter example: injective counter example: let $x=-1$ and $x=1,$ you will get $y=1$ meaning two x is mapped to one in the codomain. surjective counter example: there is no $x$ which lets you obtain $y=-1$ anyone can verify?",['functions']
1159406,"Proving a metric space $\mathbb N^{\mathbb N}$ with $d(x,y)=1/\min\{j:x_j\neq y_j\}$ is complete","Let $X$ be the collection of all sequences of positive integers. If $x=(n_j)_{j=1}^\infty$ and $y=(m_j)_{j=1}^\infty$ are two elements of $X$, set $$k(x,y)=\inf\{j:n_j\neq m_j\}$$ and $$d(x,y)= \begin{cases} 0 & \text{if $x=y$} \\ \frac{1}{k(x,y)} & \text{if $x \neq y$} \end{cases}$$ We know that $d$ is a metric on $X$. Now, I must prove that the metric space $(X,d)$ is complete. By definition, a metric space $(X,d)$ is complete if every Cauchy sequence in $X$ is convergent. On the real line, this is trivial, but I have trouble applying the concept to metric spaces. We know that a sequence is Cauchy if: $$(\forall \epsilon>0)(\exists N>0)(\forall m,n \geq N)(d(x_m,x_n)<\epsilon)$$ A Cauchy sequence also has the following properties: If a sequence $(x_n)$ converges, then it is Cauchy. Every Cauchy sequence is bounded: for all $a \in X$, there exists $C_a>0$ such that $d(a,x_n)<C_a$ for all $n$. If a Cauchy sequence $(x_n)$ has a converging subsequence $(x_{n_k})$ such that $\lim_{k \to \infty}x_{n_k}=x$, then $(x_n)$ converges to $x$. Here is my attempt thus far, although my reasoning feels wrong. Let $(x_n)_{n=1}^\infty$ be any Cauchy sequence in $X$. Take $\epsilon=\frac12$. Let $N$ be such that for $n,m \geq N$, we have $d(x_n,x_m)<\frac12$. So, $x_n=x_m$ for all $n,m \geq N$ and $x_n=x_N$ for $n \geq N$. Thus, $x_n$ is eventually constant and hence convergent, which proves that the metric space is complete. Any corrections or help on how to prove this would be appreciated. Thank you!","['general-topology', 'the-baire-space', 'real-analysis', 'metric-spaces', 'functional-analysis']"
1159416,Convergence of the series for the Dedekind zeta function,"The Dedekind zeta function of an algebraic number field $K$ is defined as
$\zeta_K(s)\mathrel{\stackrel{\rm def}=} \sum\limits_{I \subset\mathcal O_K} \frac{1}{(N_{K/\mathbb Q}(I))^s}$, where $N_{K/\mathbb Q} (I)$ is the norm of the ideal $I$, i.e., the cardinality of $\mathcal O_K/I$. The first question I have about this function is why the series converges for $s \in \mathbb C$ such that ${\rm Re}(s)>1$ and diverges otherwise. To answer this question should I somehow describe ideals in algebraic number fields? Is there a general way to do this?","['zeta-functions', 'number-theory']"
1159434,"(Unsolved) In this infinite sequence, no term is a prime: prove/disprove.","$ 343,~ 34343, ~3434343, ~343434343,\ldots$ $\begin{array}\\
\color{Red}{343} &\color{Red}{: 7^3}\\
34343  &: 61\times 563\\
\color{green}{3434343} &\color{green}{: 3\times 11^2\times 9461}\\
\color{red}{343434343} &\color{Red}{: 7\times 521\times 94169}\\
34343434343 &: 47\times 79\times 9249511\\
\color{green}{3434343434343} &\color{green}{: 3^2\times 19\times 29\times  67\times10336531}\\
\color{red}{343434343434343} &\color{Red}{: 7\times 151\times 324914232199}\\
34343434343434343 &: 5638147\times 6091262669
\end{array}$ Update: The numbers in black are, $$F_n = \frac{34\times10^{6n-1}-43}{99}$$ and $F_n$ is composite for $n<1667$ (user Uncountable ) and $n<3101$ (user A.P. ).","['prime-numbers', 'number-theory']"
1159438,What is the smallest positive integer of the form $30x+6y+10z$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I am trying to find the smallest positive integer of the form $30x+6y+10z$, where $(x,y,z)\in\mathbb{Z}$ However, I do not know where to start. Hints or answers are welcome.
Thanks!","['modular-arithmetic', 'elementary-number-theory', 'integers', 'number-theory']"
1159461,The meaning of Sprague-Grundy ordinal,"I have an unusual request to you. I speak English badly (I'm from Russia). Май инглиш из вери бед (sorry, Russian stupid joke).
I'm writing a term paper. I faced with the problem of translation of mathematical terms with the English. Could you please help me?
My course work related to the theory of combinatorial games.
Please explain what ""Sprague-Grundy ordinal"" from the text: 
"" The value of 'g' cannot increase as moves are added, and at most finitely many legal moves preserve the value of 'g'. Thus every position has a well-defined Sprague-Grundy ordinal, which may be transfinite. ""","['terminology', 'combinatorics']"
1159475,Simplest proof that the edge of an inscribed equilateral triangle bisects the radius,"Context: I am giving a short talk on the Bertrand Paradox to a mixed group, many of whom have studied mathematics at a higher level some years ago.    The point of the talk is the philosophical ramifications on the Principle of Indifference, but I would very much like to be able to prove all of the results I'm relying on from first principles as my audience are a pedantic bunch. Question: Given a circle with an inscribed equilateral triangle and a radius that is perpendicular to one of the triangle's sides, I need to be able to show that the radius is bisected by the triangle ( not that a perpendicular radius bisects a chord!). This is fairly simple by route of the Central Angle Theorem and then the 30-60-90 triangle, but that gets rather involved if I have to prove even a limited version of the Central Angle Theorem.  Is there a more direct route I'm not seeing?","['geometry', 'triangles', 'circles']"
1159500,"Confusion regarding limiting variances (Casella, Statistical Inference, 2nd edition, example 10.1.8)","In the book Statistical Inference (George Casella 2nd ed.), page 470, there is an example: $\bar{X}_n$ is the mean of $n$ iid observations, and E$X=\mu$, $\operatorname{Var}X=\sigma^2$. ""If we take $T_n=1/\bar{X}_n$, we find that the variance is $\operatorname{Var}T_n=\infty$, so the limit of the variances is infinity."" Why is the limit of the variance infinity? I can go as far as $$\operatorname{Var}\frac 1{\bar{X}_n}=\operatorname{E}_{\bar{X}_n}\left[\left(\frac1{\bar{X}_n}-\operatorname{E} \frac 1{\bar X_n} \right)^2 \mid \mu\right] $$ what's next? I know that $\lim_{n\to\infty}\operatorname{Var}{\bar X_n}=0$. However, $\lim_{n\to\infty}1/\operatorname{Var}{\bar X_n}\not=\lim_{n\to\infty}\operatorname{Var}1/\bar X_n$. How can we show the variance approaches to infinity for sufficiently large $n$? Thanks!","['statistics', 'asymptotics', 'statistical-inference', 'limits']"
1159525,Derivative of angle between two vectors singularity!,"I have been battling a problem of needing to know the derivative of the angle between two vectors, the vectors possibly being parallel at some points in time. I started off with: $$\bf A \dot \bf B = \|A\|\|B\|\cos\theta \Rightarrow \theta=\arccos \left( \frac{\bf A \dot \bf B}{\|A\|\|B\|} \right)$$ Let's say that $\bf A$ and $\bf B$ are unit vectors for simplicity so: $$
\theta=\arccos \left( \bf \hat A \dot \bf \hat B \right)
$$ To find the derivative of the angle $\theta$: $$
\dot \theta = \frac{-1}{\sqrt{1-\left(\bf \hat A \dot \bf \hat B\right)^2}} \left[\bf \dot{\hat A}\dot \bf \hat B+\bf {\hat A}\dot \bf \dot{\hat B}\right]
$$ But, $\bf{\hat A} \dot \bf{\hat B}=$$1$ when $\bf \hat A \,\,\|\,\, \bf \hat B$ and the denominator of the expression for $\dot \theta$ becomes $0$. We hence get a division by $0$. Now I have tried other ways - by projecting $\bf{\hat B}$ onto $\bf{\hat A}$ and taking $\arctan$, by projecting $\bf{\hat B}$ onto a plane and forming a right-angle triangle and again taking $\arctan$. Every method I tried leads to the same singularity when $\bf \hat A \,\,\|\,\, \bf \hat B$. Question : what method can I use such that I don't get a singularity for $\dot\theta$ when $\bf{\hat A}$ becomes parallel to $\bf{\hat B}$? Thank you!","['trigonometry', 'linear-algebra', 'vector-analysis']"
1159621,Showing that order of $SL_2(Z_3)$ is 24,"I am having some trouble proving that order of $SL_2(Z_3)$ is 24, First I know that the number of elements in $M_2(Z_3)$ is 81 because we have four entries and for each entry we have 3 different possibility and so $3^4 = 81$. Now I already showed that $SL_2(Z_3)$ is a subgroup of $GL_2(Z_3)$ And for $GL_2(Z_3)$ we obviously don't have the zero matrix (81 -1  = 80) and then any of the matrices in the form of $\begin{bmatrix}
       0 & 0        \\[0.3em]
       a & b          \\[0.3em]   
     \end{bmatrix}$
do not belong to $GL_2(Z_3)$ and so we have (80 - 3x3) but we exclude the zero matrix so we have (80 - 8 = 72) , also same for $\begin{bmatrix}
       0 & a        \\[0.3em]
       0 & b          \\[0.3em]   
     \end{bmatrix}$ 
and so 72 - 8 = 64 , same for $\begin{bmatrix}
       a & b        \\[0.3em]
       0 & 0          \\[0.3em]   
     \end{bmatrix}$ so we have 64 - 8 = 56 and same for $\begin{bmatrix}
       a & 0        \\[0.3em]
       b & 0          \\[0.3em]   
     \end{bmatrix}$ 
so we have 56 - 8 = 48 So we have 48 different matrices in $GL_2(Z_3)$ Now I from those 48 Matrices , I need to find those matrices that have determinant  = 1 in $Z_3$ (i.e $ad-bc = 1$ in $Z_3$ but I don't know how to do it. Any suggestions ?","['lie-groups', 'group-theory', 'abstract-algebra']"
1159632,simplifying and factoring a fraction,"how i get $\frac{(a+b)^2+(a+c)^2+(b+c)^2}{2}$ from $\frac{a^4}{(a-b)(a-c)}+\frac{b^4}{(b-a)(b-c)}+\frac{c^4}{(c-a)(c-b)}$ assuming that $a\ne b\ne c\ne a$ i tried to make
$$\begin{align}
&\frac{a^4}{(a-b)(a-c)}+\frac{b^4}{(b-a)(b-c)}+\frac{c^4}{(c-a)(c-b)}\\
&=\frac{a^4}{(a-b)(a-c)}-\frac{b^4}{(a-b)(b-c)}+\frac{c^4}{(a-c)(b-c)}\\
&=\frac{a^4(b-c)}{(a-b)(a-c)(b-c)}-\frac{b^4(a-c)}{(a-b)(a-c)(b-c)}+\frac{c^4(a-b)}{(a-b)(a-c)(b-c)}\\
&=\frac{a^4(b-c)-b^4(a-c)+c^4(a-b)}{(a-b)(a-c)(b-c)}\\
&=\frac{a^4b-a^4c-ab^4+b^4c+ac^4-bc^4}{(a-b)(a-c)(b-c)}\\
&=\frac{ab(a^3-b^3)+ac(c^3-a^3)+bc(b^3-c^3)}{(a-b)(a-c)(b-c)}\\
&=\frac{(a-b)(a-c)(b-c)(a^2+ab+ac+b^2+bc+c^2)}{(a-b)(a-c)(b-c)}\\
&=a^2+ab+ac+b^2+bc+c^2\\
&=\frac{2a^2+2ab+2ac+2b^2+2bc+2c^2}{2}\\
&=\frac{a^2+2ab+b^2+a^2+2ac+c^2+b^2+2bc+c^2}{2}\\
&=\frac{(a+b)^2+(a+c)^2+(b+c)^2}{2}
\end{align}$$ $$\begin{align}
\small bc(b^3-c^3)+ac(c^3-a^3)+ab(a^3-b^3)&\small =bc(b^3-a^3+a^3-c^3)+ac(c^3-a^3)+ab(a^3-b^3)\\
&\small =bc(b^3-a^3)+bc(a^3-c^3)+ac(c^3-a^3)+ab(a^3-b^3)\\
&\small =-bc(a^3-b^3)+bc(a^3-c^3)-ac(a^3-c^3)+ab(a^3-b^3)\\
&\small =b(a-c)(a^3-b^3)+c(b-a)(a^3-c^3)\\
&\small =b(a-c)(a^3-b^3)-c(a-b)(a^3-c^3)\\
&\small =b(a-b)(a-c)(a^2+ab+b^2)-c(a-b)(a-c)(a^2+ac+c^2)\\
&\small =(a-b)(a-c)[b(a^2+ab+b^2)-c(a^2+ac+c^2)]\\
&\small =(a-b)(a-c)(a^2b+ab^2+b^3-a^2c-ac^2-c^3)\\
&\small =(a-b)(a-c)[a^2(b-c)+(b^3-c^3)+a(b^2-c^2)]\\
&\small =(a-b)(a-c)[a^2(b-c)+(b-c)(b^2+bc+c^2)+a(b-c)(b+c)]\\
&\small =(a-b)(a-c)(b-c)(a^2+ab+ac+b^2+bc+c^2)
\end{align}$$","['fractions', 'algebra-precalculus']"
1159678,"If $f$ is measurable and $\int f < \infty$, then $f(x) < \infty$ a.e.","I am looking for a hint for what should be a simple proof, but once again I am missing the key connection. Please don't provide a complete solution, nudge me to discover what I am missing. If $f$ is a measurable non-negative function and $\int f < \infty$, then $\{x : f(x) = \infty \}$ is a null set. What I am attempting: Define a function $g(x)$ as follows:
$$g(x) = \left\{\begin{array}{ll} a, & \textrm{if} f(x) = \infty, \\ f(x), & \textrm{otherwise}.\end{array}\right.$$ Then, we have a proposition that states that for measurable $h$, $\int h = 0 \iff h = 0$ a.e. So what I'm trying to do is set $h = f-g$ and show that $\int h = \int f-g = 0$. This would complete the proof. If $A = \{x : f(x) = \infty\}$, then I have $\int g = \int_{A^C} g + \int_A g = \int_{A^C} f+ a\mu(A)$. I want to use this in some way to conclude that $\mu(A) = 0$ necessarily. The only hypothesis I have to work with is $\int f < \infty$. I'm not sure if this is the right approach. Intuitively, I know exactly what the statement means. I just can't identify the machinery needed to get to the conclusion.","['measure-theory', 'integration']"
1159709,Elegant Proof of a simple inequality,"I'm looking for an elegant proof of the following identity: for $w_1,w_2,z_1,z_2\ge 0$, $w_1w_2+z_1z_2\le \max\{z_1,w_1\}\max\{z_2,w_2\}+\min\{z_1,w_1\}\min\{z_2,w_2\}$ The proof I currently have involves checking by cases, which is what I'd like to avoid. If there's some linear algebraic, combinatorial, or geometric way to explain this inequality intuitively, I'd love to hear it. Thanks in advance for your time.","['inequality', 'algebra-precalculus', 'combinatorics']"
1159738,Showing that $\det(AB)=\det A \det B$ with the following identity.,"Given the following formulation of the determinant with Levi-Civita permutation symbols, show that $\det(AB)=\det A \det B$. $$\det A = \sum\limits_{ij\cdots l}\epsilon_{ij\cdots l} A_{i1}A_{j2}\cdots A_{ln}\,,\,\,\,\,\,\textrm{where A is an }n\times n \textrm{ matrix}$$ I have been trying to show this for so long, but I can't seem to get past a certain point. Here is my work so far. $$\begin{align*}
\det (AB)&=\sum\limits_{ij\cdots l}\epsilon_{ij\cdots l}(AB)_{i1}(AB)_{j2}\cdots(AB)_{ln}\\
&=\sum\limits_{ij\cdots l}\epsilon_{ij\cdots l}\left(\sum\limits_{k_1}A_{ik_1}B_{k_11}\right)\left(\sum\limits_{k_2}A_{jk_2}B_{k_22}\right)\cdots \left(\sum\limits_{k_n}A_{lk_n}B_{k_nn}\right)\\
&=\sum\limits_{ij\cdots l}\epsilon_{ij\cdots l}\left(\sum\limits_{k_1,k_2,\cdots k_n} A_{ik_1}A_{jk_2}\cdots A_{lk_n}B_{k_11}B_{k_22}\cdots B_{k_nn}\right)\\
&=???
\end{align*}
$$ Any tips on how to proceed? Have I made a mistake anywhere?","['matrices', 'linear-algebra', 'determinant']"
1159746,Linear Algebra - Suppose $CA=I_n$. Show that the equation $Ax = 0$ has only the trivial solution.,Suppose $CA=I_n$.  Show that the equation $Ax = 0$ has only the trivial solution.  Explain why $A$ cannot have more columns than rows. I really don't even know where to begin with this one.,['linear-algebra']
1159772,Ascoli-Arzela theorem: Hausdorff assumption needed? [duplicate],"This question already has answers here : Theorem of Arzelà-Ascoli (1 answer) Is Hausdorffness necessary for the classical ascoli theorem? [duplicate] (1 answer) Closed 9 years ago . Theorem 4.43 is Folland's Real Analysis is Arzelà-Ascoli Theorem I . Let $X$ be a compact Hausdorff space. If $\mathscr{F}$ is an equicontinuous, pointwise bounded subset of
  $C(X)$, then $\mathscr{F}$ is totally bounded in the uniform metric,
  and the closure of $\mathscr{F}$ in $C(X)$ is compact. I could not understand where the assumption that $X$ is Hausdorff is used in the proof. Is this assumption necessary?","['general-topology', 'real-analysis']"
1159791,"Is there any regular, balanced, connected bipartite graph that does not contain any Hamiltonian cycle? [duplicate]","This question already has an answer here : Does every connected $r$-regular bipartite graph contain a Hamiltonian cycle? (1 answer) Closed 9 years ago . In a set of balanced, connected bipartite graphs, all with regularity $r \ge 2$, is it possible that there exists a bipartite graph that does not contain a Hamiltonian cycle ? My argument : The bipartite graph is balanced, so both of the partition has the same number of vertices. It's regularity $r \ge 2$ and the graph is connected, that means we can switch between the partitions, so there is a Hamiltonian path. Lets say that we have followed the Hamiltonian path from vertex $u$ and reached to a vertex $v$ and exhausted all the vertices, now how do I prove that there must be an edge that will take me back to $u$ from $v$? I am getting lost with this construction of the ""Hamiltonian cycle"". So does this mean that there can be such bipartite graph (connected, balanced, $r \ge 2$ regular) that does not contain a Hamiltonian cycle? If yes, can someone give me a concrete example? N.B.: $r$-regular: every edge is $r$-degree.","['hamiltonian-path', 'graph-theory', 'discrete-mathematics', 'bipartite-graphs']"
1159850,Number of integer solutions with hard restrictions,"In the jungle of posts on math.stackexachange related to this subject I have been searching quite a while now. I read some very useful posts however I can't solve my own problem. My version of the number of integer solutions sounds like this: Question :
Let $x + y + z \leq 13$ with the following restrictions: $x \leq y \leq x+2$ and $x \leq z$. Find the number of possibilities using a generating function. Related to this problem I found this post . I tried so for the equation $x + y + z =13$: Say $z=x+z'$, $x+2=y+x'$ and $y=x+y'$. However replacing those expressions into the equation, I got stuck  with replacing $x'$ and $y'$ for $x$ and $y$. The only thing I see is that: $x' + y'=2$. How can I use this technique properly? And what about the inequality? How to deal with $x + y + z \leq 13$? Thanx in advance!","['generating-functions', 'discrete-mathematics', 'combinatorics']"
1159899,Hard combinatorics and probability question.,"A large white cube is painted red, and then cut into $27$ identical smaller cubes. These smaller cubes are shuffled randomly. A blind man (who also cannot feel the paint) reassembles the small cubes into a large one. What is the probability that the outside of this large cube is completely red?","['combinations', 'probability', 'combinatorics']"
1159949,Why is homeomorphism understood as stretching and bending?,"There are homeomorphisms that cannot be considered as stretching and bending (don't know what the proof of this should look like, as we haven't defined stretching and bending formally, this is my major concern here) - see the bottom of page 22 in A guide of topology by Krantz. Even if we accept that some homeomorphisms cannot be understood as stretching and bending (whatever stretching and bending means), we assume that all stretching and bending that can be represented by homeomorphism - why is that? Has anyone proved it?","['geometric-topology', 'general-topology', 'math-history', 'algebraic-topology', 'differential-topology']"
1159973,checking if a function is differentiable,"How can i prove that the following function is differentiable?
$$f(x_1,x_2)=\int_0^{|x_1|}g(s)ds+x_2^2$$
where $g(x)$ is an increasing function with $g(0)=0$. Its partial derivative is equal to $\frac{\partial f(x_1,x_2)}{x_1}=g(|x_1|)\frac{\partial |x_1|}{\partial x_1}$, isn't there a problem at $x_1=0$?","['multivariable-calculus', 'derivatives']"
1159974,Hyperbolic geometry when the curvature is constant and negative but not -1,"Hyperbolic geometry is the geometry of surfaces of a constant negative Gaussian curvature, in most formula's it is almost assumed this constant negative curvature is $ -1$ . But what when the  constant negative curvature is $-2$ or $ - \frac{1}{3}$ ? For example is the area of a triangle the defect divided or multiplied by the (absolute value of the) Gaussian curvature. Wikipedia says you have to divide the defect by the curvature. $(\pi-A-B-C) R^2$ , where $R = \frac{1}{\sqrt{-K}}$ . Sommerville ""The elements of non euclidean geometry"" page 81 gives $k^2  (\pi - A - B - C)$ and I fear that when I reach for another book I will even get another formula. Who is right and can you give a canonical proof?","['hyperbolic-geometry', 'curvature', 'differential-geometry']"
1159995,Do the last digits of exponential towers really converge to a fixed sequence?,"While fooling around with exponential towers I noticed something odd: $$ 3^{3} \equiv 2\underline{7} \mod 100000  $$
$$ 3^{3^{3}} \equiv 849\underline{87} \mod 100000  $$
$$ 3^{3^{3^{3}}} \equiv 39\underline{387} \mod 100000  $$
$$ 3^{3^{3^{3^{3}}}} \equiv 5\underline{5387} \mod 100000  $$
$$ 3^{3^{3^{3^{3^{3}}}}} \equiv \underline{95387} \mod 100000  $$
$$ \dots$$ It seems that the last digits always converge to a fixed sequence! Is this really true and if yes - can someone think of a proof for this statement? Any kind of help will be appreciated","['modular-arithmetic', 'tetration', 'power-towers', 'number-theory']"
1159999,Concentric Equilateral Triangles,"I'm currently researching a particular dynamical system that is very geometric in nature. As part of this, I need to prove the following results (the second obviously implies the first). They are ""obviously"" true - but the proof doesn't seem so obvious. Equilateral triangles $ABC$ and $DEF$ are concentric. Points $A,G$ and $H$ are collinear. Points $B,H$ and $I$ are collinear. Let $DG=FI=x$ and $EH=y$. Prove that $x=y$. Now suppose the internal triangle $DEF$ is rotated about its centre by some small angle so that points  $A$ and $G$ are still on opposite sides of line $DF$. Prove that the result is still true. I have an algebraic solution to the first problem above. But I'm trying to find a clean geometric proof. I've made no progress on the second generalisation of the first result. I've tried all the usual tricks (congruence, rule of sines and cosines etc.) but to no avail. Does anyone have any approach to such problems that might work?","['dynamical-systems', 'geometry', 'triangles', 'solid-geometry', 'euclidean-geometry']"
1160005,Let $f$ be a function such that every point of discontinuity is a removable discontinuity. Prove that $g(x)= \lim_{y\to x}f(y)$ is continuous.,"Let $f$ be a function with the property that every point of discontinuity is a removable discontinuity, i.e., $\lim_{y \to x}f(y)$ exists for all $x$, but $f$ may be discontinuous at some (even infinitely many) numbers $x$. Define $g(x)= \lim_{y\to x}f(y)$. Prove that $g$ is continuous. Since $g(a)= \lim_{y\to a}f(y)$, by definition, it follows that for any $\epsilon \gt 0$ there is a $\delta \gt 0$ such that $|f(y)-g(a)|\lt \epsilon$ for $0\lt |y-a| \lt \delta$. This means that $$g(a)-\epsilon \lt f(y) \lt g(a)+\epsilon$$.
for $0\lt |y-a| \lt \delta$. What I need to show is that if $|x-a| \lt \delta$, we have $$g(a)-\epsilon \lt \lim_{y\to x}f(y) \lt g(a)+\epsilon$$. I'm having trouble reaching this conclusion with the information I have. I'd appreciate any solutions or suggestions.","['calculus', 'continuity', 'real-analysis', 'analysis']"
1160053,How can you rigorously define trigonometric functions without series or integrals?,"In middle school, cos and sin were defined with angles, and in high school, with the length of an arc of the unit circle. But angles, are defined with cos and you need integrals to define the length of an arc! And the definition with series is a bit abstract. Is there a simple way to define cos and sin without either using advanced tools or ""lying"" to students?",['trigonometry']
1160054,How to quickly recognize closed sets and open sets in $\mathbb{R}^2$,"Let $S$ be any set in $\mathbb{R}^2$. Given a definition $S$, are there tell-tale signs that can be used to conclude that $S$ is closed? For example, in $\mathbb{R}$, I know that any set defined in terms of weak inequalities will be a closed set. Is there a similar rule in $\mathbb{R}^2$. I am wondering about this because a lot of the solutions to a lot of the exercises that asked to determine whether $S$ is closed seem to imply that it is obvious to see. For example: Determine if $$S=\left\{ \left( x,y \right): 1\le x^2y\le 2 \right\}$$
  is closed. The solution simply says: The set $S$ is closed and this will be clear from sketching it. So, here's the sketch: But it is not obvious to me based on the definition and sketch of $S$, why $S$ must be closed. What am I missing? For reference, I know the following about closed sets: A set,$S$, is closed if its complement is open. A set, $S$,  is closed if for any convergent sequence in $S$, the limit of that sequence is also in $S$. I also have a similar query in the case of open sets in $\mathbb{R}^2$ i.e. is there a way to quickly recognize that a subset of $\mathbb{R}^2$ is open given its definition and or sketch?",['general-topology']
1160065,"Let $d$ be any positive integer not equal to $2, 5,$ or $ 13$ , then $\exists a, b \in \{2, 5, 13, d\}$ such that $ab − 1$ is not a perfect square?","Let $d$ be any positive integer not equal to $2, 5,$ or $ 13$. Then can we always find
distinct $a, b \in \{2, 5, 13, d\}$ such that $ab − 1$ is not a perfect square ?",['number-theory']
1160095,Convexity and equality in Jensen inequality,"Theorem 3.3 from W. Rudin, Real and complex analysis, says: Let $\mu$ be a probabilistic measure on a $\sigma$ -algebra of subsets of a given set $\Omega$ . If a function $f:X \rightarrow \mathbb R$ is in $L^1(\mu)$ , $a<f(x)<b$ for $x\in \Omega$ and if a function $\phi:(a,b)\rightarrow \mathbb R$ is a convex  then $$
\phi\left(\int_a^b fd \mu\right) \leq \int_a^b (\phi \circ f) d \mu.
$$ Is it known when in  this inequality holds equality?
Maybe, it is iff $\phi$ is affine a.e. ?","['convex-analysis', 'real-analysis']"
1160121,"Show that assumptions of theorem hold, determine the solution","Consider the initial value problem $$\left\{\begin{matrix}
y'(t)=\sqrt{|y|}, 0 \leq t \leq 2\\ 
y(0)=1
\end{matrix}\right. \tag 1$$ Show that for this problem the assumptions of the following theorem hold: ""Let $c>0$ and $f \in C([a,b] \times [y_0-c, y_0+c])$. If $f$ satisfies at $[a,b] \times [y_0-c, y_0+c])$ the Lipschitz condition in respect to $y$, uniformly in respect of $t$, that means that: $$\exists L \geq 0: \forall t \in [a,b] \ \forall y_1, y_2 \in [y_0-c,y_0+c]: \\ |f(t,y_1)-f(t,y_2)| \leq L |y_1-y_2|$$ then the initial value problem $\left\{\begin{matrix}
y'(t)=f(t,y(t)) &, a \leq t \leq b \\ 
y(a)=y_0 & 
\end{matrix}\right.$ is solved uniquely at least at the interval $[a,b']$ where with $A=\max_{a \leq t \leq b, y_0-c \leq y \leq y_0+c} |f(t,y)|$ we have that $b'=\min \{ b, a+ \frac{c}{A}\}$. "" for appropriate $c$ and $L$.
Determine the solution $y$ with the method of seperation of variables. I tried the following: $$f(t)=\sqrt{|y|}$$ $$\frac{\partial{f}}{\partial{y}}(t, y(t))=\frac{1}{2 \sqrt{|y|}} \leq M \Rightarrow \frac{1}{2M} \leq \sqrt{|y|} \Rightarrow y \geq \frac{1}{4M}$$ $$y(0)-c=1-c=\frac{1}{4M} \Rightarrow c=1-\frac{1}{4M}$$ Then $(1)$ is solved uniquely, at least at the interval $[0,b']$ where $A=\max_{0 \leq t \leq 2, \frac{1}{4M} \leq y \leq 2-\frac{1}{4M}} |\sqrt{|y|}|=\sqrt{2-\frac{1}{4M}}$ $$b'=\min \{ 2, \frac{1-\frac{1}{4M}}{\sqrt{2-\frac{1}{4M}}}\}=\frac{1-\frac{1}{4M}}{\sqrt{2-\frac{1}{4M}}}$$ $$L=M$$ $$\frac{dy}{dt}=\sqrt{|y|} \Rightarrow \frac{dy}{2\sqrt{y}}=\frac{dt}{2} \Rightarrow \sqrt{y}=\frac{1}{2}t+c$$ $$y(0)=1 \Rightarrow c=1$$ So: $$\sqrt{y}=\frac{1}{2}t+1 \Rightarrow y=\left(  \frac{1}{2}t+1\right)^2=\frac{1}{4}t^2+t+1$$ Is it right or have I done something wrong?","['ordinary-differential-equations', 'numerical-methods']"
1160147,Find the Least Integer $k$ such that $B^k=I$,"9>If $A$ and $B$ are two non-singular matrices such that $B\ne I$ , $A^6=I$ and $$AB^2=BA,$$ then what is the  least positive integer $k$ such that $B^k=I$ ? My Try: Given $$AB^2=BA$$ which we can write as $$ABB=BA$$ Post Multiply with $A$ we get $$ABBA=BA^2$$ i.e., $$ABAB^2=BA^2$$ i.e., $$A^2B^4=BA^2$$ Continuing we get $$A^3B^8=BA^3$$ $$A^4B^{16}=BA^4$$ $$A^5B^{32}=BA^5$$ and finally $$A^6B^{64}=BA^6$$ and since $A^6=I$ we have $$B^{64}=B$$ i.e, $$B^{63}=I$$ so $k$ is 63. Can i have any better approach?","['matrices', 'linear-algebra']"
1160179,Right shift operator is not compact but is a limit of finite rank operator?,"I'm doing a preparation for an exam, and I have a doubt concerning the right shift operator, for example in $\ell^2$, $S_d : \ell^2 \to \ell^2$ such that $(x_1,x_2,\ldots) \mapsto (0,x_1,\ldots)$ is standard to show tha $S_d$ is not compact (using the spectral values for example). But if we define $S_{dn} : \ell^2 \to \ell^2$ such that $(x_1,x_2,\ldots,x_n,\ldots) \mapsto (0,x_1,\ldots,x_n,0,0,\ldots)$ then $S_{dn} \to S_d$ and $S_{dn}$ is of finite rank, then $S_d$ should be a compact operator. I know that this affirmation is false, but I can't find why. Thank you for any help.","['operator-theory', 'functional-analysis']"
1160196,Box-Muller Independence Proof by Change of Variables (Help finding the Inverses),"Let $X_1=\cos(2 \pi U_1)\sqrt{-2 \log(U_2)}$ and $X_2=\sin(2 \pi U_1)\sqrt{-2 \log(U_2)}$ wher $U_1$ and $U_2$ are iid uniform (0,1). Prove that $X_1$ and $X_2$ are independent N(0,1) random variables. So my approach (and one of the proofs I was shown) did this though change of variables where
$g_1(u_1,u_2)=\cos(2 \pi U_1)\sqrt{-2 \log(U_2)}$ and $g_2(u_1,u_2)=\cos(2 \pi U_1)\sqrt{-2 \log(U_2)}$ and essentially found their inverses $g_1^{-1}(x_1,x_2)$ and $g_2^{-1}(x_1,x_2)$, and used those to find the Jacobian (essentially here Box-Muller Transform Normality ) I'm wondering how they found those inverses? The rest of the proof I get, but I am not as familiar with a multi-variable inverse.","['statistics', 'self-learning', 'inverse', 'random-variables']"
1160209,"Set Theory proof from ""How to Prove It"" [duplicate]","This question already has answers here : Stuck with proof for $\forall A\forall B(\mathcal{P}(A)\cup\mathcal{P}(B)=\mathcal{P}(A\cup B)\rightarrow A\subseteq B \vee B\subseteq A)$ (3 answers) Closed 9 years ago . I am having difficulties with this proof--Hints will be appreciated. Prove that for any sets $A$ and $B$, if $\mathcal{P}(A) \cup \mathcal{P}(B) =  \mathcal{P}(A\cup B)$ then either $A$ is a subset of $B$ or $B$ is a subset of $A$.",['elementary-set-theory']
1160235,$ Aut(G) \text{ is cyclic} \Rightarrow G \text{ is cyclic}$?,"Let $G$ be a group. Is true that, if $Aut(G)$ be a cyclic group then, $G$ is cyclic?! I know that $ Aut(G) \text{ is cyclic} \Rightarrow G \text{ is Abelian}$, but above question asks something stronger!","['group-theory', 'abstract-algebra']"
1160283,Differentiable function question about pair of points,Let $f \ :\ \mathbb{R} \rightarrow \mathbb{R}$ be a differentiable function. Is it true that for all $x_0 \in \mathbb{R}$ there exists pair of points $a<x_0<b $ such that $f^\prime(x_0)=\frac{f(b)-f(a)}{b-a}$. How to check this?,"['calculus', 'derivatives', 'functions']"
1160289,prove the set of all functions such that $f:\mathbb{Z} \to \mathbb{Z}$ where $|f(x)-f(y)|=|x-y|$ form a group under composition,"Let f be a function $f:\mathbb{Z} \to \mathbb{Z}$ where $|f(x)-f(y)|=|x-y|$ prove that the set of all such functions forms a group under composition. I think this is the set of all linear functions, yes? since $f(x)=x+z$, $z\in \mathbb{Z}$, satisfies this property. It just 'shifts' this 'gap' in some direction along the number line. I assume this works: Let $a,b \in \mathbb{Z}$ then $|f(x)-f(y)|=|a+z-(b+z)|=|a-b+(z-z)|=|a-b|$ I think this has closure since the composition $f(g(x))=f(x+z)=x+2z$ where $2z \in \mathbb{Z}$ since $(Z,+)$ is itself a group. I am not really sure how to identify and prove the existence of the identity here since this is dealing with a set of functions. Any guidance/hints? And as a note - If you've noticed me posting abstract alg. questions over the past day or two it is because I am doing ever problem/exercise/proof given by our prof. over the course of the last month to prepare myself for an exam! None of these are assigned for grading.",['abstract-algebra']
1160296,"How to evaluate $\int \sin^{-1}(x)\cos^{-1}(x) \, dx$?","I need to evaluate $$\int \sin^{-1}(x)\cos^{-1}(x) \, dx.$$ Can anyone please give me an idea or a hint ? Thanks.","['calculus', 'integration', 'real-analysis']"
1160322,Closed Sets are Measurable Proof in Stein/Shakarchi Text,"Had a question about the proof laid out in Stein/Shakarchi's text that closed sets are measurable. Im hoping someone can explain the part in bold below, which is the only thing that's bugging me. They first assume F to be compact and show this is equivalent to it being closed, so take F to be compact: Suppose $F$ is compact, which implies we can find a $O$ such that $F_*\subset O$ and $m_*(O)\leq m_*(F)+\epsilon$. Since $F$ is closed, then $O\backslash F$ is open and we write it as a countable union of almost disjoint cubes $\implies O\backslash F = \bigcup_i Q_i$ Fix an $N$. The finite union $K=\bigcup_i^{N}Qi$ is compact, which means that $d(K,F)>0$ This implies that $m_*(O)\geq m_*(F)+m_*(K)= m_*(F)+\sum_i^{N}m_*(Q_i)$ Which works out to be equivalent to $\sum_i^{N}m_*(Q_i)\leq m_*(O)-m_*(F)\leq \epsilon$ Here's where i get lost:
The authors then claim that ""this holds as N goes to infinity""...Why? Which gives us $m_*(O\backslash F)\leq \sum_i^{\infty}m_*(Q_i)\leq m_*(O)-m_*(F)\leq \epsilon$","['measure-theory', 'real-analysis', 'analysis', 'lebesgue-integral', 'lebesgue-measure']"
1160378,Composite $n$ such that $3^{n-1}-2^{n-1}$ is divisible by $n$,I'm stuck with the following olympiad problem (the solution to which I unfortunately do not possess): Show that there are infinitely many composite (i. e. nonprime) numbers $n$ such that  $3^{n-1}-2^{n-1}$ is divisible by $n$. Could anyone provide a hint how to tackle this exercise?,"['elementary-number-theory', 'contest-math', 'number-theory']"
1160453,A group whose automorphism group is cyclic,Is there an Abelian group $A$ which is not locally cyclic whose automorphism group is cyclic ?,"['group-theory', 'abstract-algebra', 'abelian-groups']"
1160467,Generators of $\mathbb{Z} \times \mathbb{Z}$,"Why is $\mathbb{Z} \times \mathbb{Z}$ generated by $(1,0)$ and $(0,1)$? I thought it should be $(1,1)$, but going through the solution of a certain exercise I am working on, it seems I am wrong. Can anyone explain this?","['group-theory', 'abstract-algebra']"
1160491,Compositions of $n$ with $r$ odd parts and $s$ even parts,"The problem I have been trying to figure out is as follows: Let $n-r=2k$. Show that the number $f(n,r,s)$ of compositions of $n$ with $r$ odd parts and $s$ even parts is given by $\binom{r+s}{r}\binom{r+k-1}{r+s-1}$. Give a generating function proof. The following hint is given: It is clear that $\displaystyle \sum_{n,r,s} f(n,r,s)x^ny^rz^s=\sum_{j\geq 0} \left( \frac{yx}{1-x^2}+\frac{zx^2}{1-x^2} \right)^j$. I can't figure out why the hint is obvious! I have been trying to figure out how to work with the following recursion I came up with: $f(n,r,s)=f(n-1,r-1,s)+f(n-1,r,s)$, which comes from partitioning the set of compositions of $n$ by considering the cases when $1$ is the smallest part and when some number greater than or equal to $2$ is the smallest part. However, my calculations come out insane! Anyone have a better suggestion for how to approach this problem or could you at least give some insight about the hint? Thank you in advance!","['generating-functions', 'discrete-mathematics', 'number-theory', 'combinatorics']"
1160527,The series $\sum_{n=1}^\infty\frac1n$ diverges!,"We all know that the following harmonic series $$\sum_{n=1}^\infty\frac1n=\frac 1 1 + \frac 12 + \frac 13 + \cdots $$ diverges and grows very slowly!! I have seen many proofs of the result but recently found the following: $$S =\frac 1 1 + \frac 12 + \frac 13 +\frac 14+ \frac 15+ \frac 16+ \cdots$$ $$> \frac 12+\frac 12+ \frac 14+ \frac 14+ \frac 16+ \frac 16+ \cdots =\frac 1 1 + \frac 12 + \frac 13 +\cdots = S.$$
In this way we see that $S > S$. Can we conclude from this that $S$ is divergent??","['sequences-and-series', 'divergent-series', 'calculus', 'proof-verification']"
1160563,Proving $\zeta(2) - \beta(1) + \zeta(4) - \beta(3) + \zeta(6)- \beta(5) + \ldots=1$,"Trying to prove $$\zeta(2) - \beta(1) + \zeta(4) - \beta(3) + \zeta(6)- \beta(5) + \ldots=1$$
I found by numerical calculation that (when $k$ goes to infinity) $$\sum_{n=1}^{k}\zeta (2n)=k+3/4+o(1),$$ $$\sum_{n=1}^{k}\beta  (2n-1)=(k-1)+3/4+o(1).$$ in order to prove the above formula. Now how can I prove it analytically?","['special-functions', 'zeta-functions', 'sequences-and-series', 'riemann-zeta']"
1160565,why integrating only alternating forms?,Hello I was reviewing some concepts of differential forms. I cannot recall why only multilinear alternating forms can be integrated on manyfolds and not general multilinear forms... Why is the hypothesis of being alternating so important? In an intuitive way I'd like to understand it... Is it for having a covariant concept? Or for making some riemann sums convergent?,"['multilinear-algebra', 'integration', 'differential-geometry']"
1160575,The regular functions on an open subset $U$ of an affine variety $X$ are the polynomials on $A(X)$.,"This is an exercise of Gathmann's Algebraic Geometry. Show that the regular functions on an open subset $U$ of an affine variety $X$ are the polynomials on $A(X)$, if $A(X)$ is a UFD and $U$ is the complement of an irreducible subvariety of codimension at least 2 in $X$. There was an example showing that regular functions on $U=A^2\backslash\{0\}$ are polynomials. I am trying to use the same idea in that example. Let $V\subsetneq V_0 \subsetneq V_1 \subset X$ be a chain of irreducible varieties. Let $\phi$ be a regular function on $U$. My idea is: if we can find two irreducible functions $f_1, f_2$ such that $V\subsetneq V(f_1), V\subsetneq V(f_2)$, then $\phi=\frac{g_1}{f_1^n}$ on $D(f_1)$ and $\phi=\frac{g_2}{f_2^m}$ for some $g_1,g_2\in A(X)$ and $m,n\in N$. ($D(f)$ here means the distinguished open subset of $f$ in $X$, i.e., the set where $f$ is not equal to $0$ in $X$.) Suppose $f_1$ does not divide $g_1$, $f_2$ does not divide $g_2$. Then on $D(f_1)\cap D(f_2)$, we have $g_1f_2^m=g_2f_1^n$. Since $V(g_1f_2^m-g_2f_1^n)$ is closed, we also have $g_1f_2^m=g_2f_1^n$ on the closure of ${D(f_1)\cap D(f_2)}$ which is $X$. Then because of the irreducibility of $f_1,f_2$ and $A(X)$ is a UFD, we can prove that $m=n=0$. That proves that $\phi$ is a polynomial. Sorry for the long post. I'm not sure whether this is on the right track. Also I don't know how to show that I can find the irreducible $f_1, f_2$. Or they are probably not really irreducible, but product of linear factors. But how to state that in the proof? Any help would be appreciated!",['algebraic-geometry']
1160578,"There aren't non-holomorphic polynomials, right?","Full disclosure: I'm taking my first complex analysis course as a graduate student and the title of my question looks like a dumb question to me. In any case, there's a problem in my book that deals with a sequence of ""holomorphic polynomials"" converging to a ""holomorphic polynomial"". Is this just a redundancy or is there some weird world where certain polynomials aren't (complex) differentiable?",['complex-analysis']
1160596,Prove that $13$ divides the number ${}^910 + 23$. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Prove that the number $13$ divides the number $\large \left( 10^{10^{10^{10^{10^{10^{10^{10^{10}}}}}}}} + 23\right)$.","['modular-arithmetic', 'number-theory']"
1160606,Is it true that all the roots of the minimal polynomial of $\alpha$ are Galois Conjugates of $\alpha$?,"To be more precise, Suppose [K:F] is Galois, $\forall \alpha \in K$ $\alpha \not\in F$, let $m_\alpha$ be the minimal polynomial of $\alpha$ in $F[x]$. I know that $\phi \in Gal(K:F)$, $\phi(\alpha)$ is a root of $m_a$. However, is the converse true? Can we say that if $\beta$ is a root of $m_a$, then $\beta=\phi(\alpha)$ for some $\phi \in Gal(K:F)$? Which means- all the roots of $m_a$ are Galois Conjugates of $\alpha$?","['galois-theory', 'abstract-algebra', 'field-theory']"
1160609,"Is $\mathbb{Z}= \{\dots -3, -2, -1, 0 ,1 ,2 , 3, \dots \}$ countable?","Question: Is $\mathbb{Z}= \{\dots, -3, -2, -1, 0 ,1 ,2 , 3, \dots \}$ countable? My attemp so far: Let us create the following one-to-one correspondence between $\mathbb{Z}$ and $\mathbb{N}$ . $$\begin{matrix}1 & 2 & 3 & 4 & 5 & 6 & 7 & \dots \\ \updownarrow & \updownarrow & \updownarrow & \updownarrow & \updownarrow & \updownarrow & \updownarrow & \dots\\0 & 1 & -1 & 2 & -2 & 3 & -3 & \dots\end{matrix}$$ In order for $\mathbb{Z}$ to be countable we must define a function $f:\mathbb{N} \to \mathbb{Z}$ so that $\mathbb{Z} \sim \mathbb{N}$ . $$\displaystyle f(n) = \begin{cases} \frac{n}{2} & n \text{ is even} \\ -\frac{n-1}{2} & n\text{ is odd} \end{cases}$$ To show that $\mathbb{Z} \sim \mathbb{N}$ we require $f$ to be bijective. From the picture above, we can clearly see that $f$ is surjective since $\forall z \in \mathbb{Z}\  \exists n \in \mathbb{N}$ such that $f(n) = z$ . Hence we must now show that $f$ is injective. We need to consider three cases: $n_1, n_2$ are odd $n_1, n_2$ are even $n_1$ is odd and $n_2$ is even Case 1: \begin{align}f(n_1) &= f(n_2) \\ \implies -\frac{n_1 -1}{2} &= -\frac{n_2 -1}{2} \\ \implies n_1 -1 & = n_2 -1 \\ \implies n_1 &= n_2\end{align} Case 2: \begin{align}f(n_1) &= f(n_2) \\ \implies \frac{n_1}{2} &= \frac{n_2}{2} \\ \implies n_1 &= n_2\end{align} I am, however, experiencing some difficulty showing the injective property for the $3^{rd}$ case. Can anyone please give me some assistance with that specific case?","['elementary-set-theory', 'real-analysis']"
1160625,On a decreasing sequence of compact subsets of a Hausdorff topological space,"I have the following exercise to solve: Exercise. Let $ (E,\tau) $ be a Hausdorff topological space and
    $ (K_{n})_{n \in \mathbb{N}} $ a decreasing sequence of non-empty
    $ \tau $-compact subsets of $ E $. Prove that
    $ \displaystyle K \stackrel{\text{df}}{=} \bigcap_{n \in \mathbb{N}} K_{n} $ is
    $ \tau $-compact. Suppose that there exists a $ \tau $-open subset $ U $ of $ E $ such that
    $ K \subset U $. Then prove that there exists an $ n_{0} \in \mathbb{N} $ such
    that $ K_{n} \subseteq U $ for all $ n \in \mathbb{N}_{\geq n_{0}} $. To prove that $ K $ is $ \tau $-compact, I mentioned that as the $ K_{n} $’s are $ \tau $-compact, they are $ \tau $-closed, so $ K $ is a $ \tau $-closed subset of $ E $ contained within a $ \tau $-compact subset of $ E $. Therefore, $ K $ is $ \tau $-compact. However, I don’t know how to solve the second question or how to see that $ K \neq \varnothing $. Could someone please suggest another method to prove that $ K $ is $ \tau $-compact? Thank you!","['general-topology', 'compactness']"
1160630,Where did I go wrong in solving this differential equation by substitution?,"I have $\frac{dy}{dx}=\frac{x+3y}{x-y}$ and am trying to solve by substituting $y=xv(x)$.  This results in $xv'+v=\frac{1+3v}{1-v}$.  By seperating the variables and integrating I get $\frac{v-1}{v+1}-\ln\left|{v+1}\right|=\ln\left|{x}\right|+C$.  Finally, substituting $v=\frac yx$ back in and rearranging yields $\frac{y-x}{y+x}-\ln\left|y+x\right|=C$. However, the answer key shows $\frac{2x}{x+y}+\ln\left|x+y\right|=C$ and I am having trouble seeing where I went wrong.",['ordinary-differential-equations']
