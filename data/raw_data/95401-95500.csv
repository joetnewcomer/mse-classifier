question_id,title,body,tags
1309051,cardinality of the set of real functions that approaches $0$ when $x\longrightarrow \infty$,I know that this set is a subset of the set of all real functions. Hence its cardinality is less than or equal to $\aleph ^\aleph=2^\aleph$. The question is how do I prove the second direction? (actually I'm not sure that $2^\aleph $ is the cardinality of the above set),"['elementary-set-theory', 'cardinals']"
1309069,Question on proof that $\operatorname{PowerSet}(X)\subset X $ is false for any $X$.,"I am looking at some beginner set theory proofs in this online  text . One question I have is on exercise 6 (1.3.6) on page 2): Prove that   $\mathcal P(X) \subset  X$ is false for any $X$. The given answer is basically as follows: Proof. Let $X$ be an arbitrary set; then there exists a set $$Y = \{ u \in X :    u \notin u \}.$$ Obviously, $Y\subset  X$, so  $Y\in\mathcal P(X)$, by Axiom of Power Set. If $Y\in X$, then we have $Y\in Y \iff Y \notin Y$ (a contradiction).  This
  proves that  $\mathcal P(X) \not\subset X$. I understand how one arrives at a contradiction if one assumes 
that $Y\in X$.  But does $Y$ necessarily have to be an element of $X$?
What about the case in which $$Y \notin X?$$ Don't we have to show a contradiction for that too?",['elementary-set-theory']
1309071,Continuity of the maximum of finite continuous functions,"Let $(X,\tau)$ be a topological space and let $f_1,\ldots,f_n:X\to\mathbb{R}$ be continuous functions (the topology of $\mathbb{R}$ is the usual one). Define $g:X\to\mathbb{R}$ by $g(x)=\text{max}\{f_1(x),\ldots,f_n(x)\}$. How to show that $g$ is continuous? I showed that, if $I\subset \mathbb{R}$ is open, and $V_i$ is the pre-image of $I$ by $f_i$ (which is open in $X$), then $g^{-1}(\{I\})\subset \bigcup_{i=1}^n V_i$. But this does not say much.","['continuity', 'general-topology', 'functions']"
1309111,Defining the $L^2$ norm of a vector valued function,"I am considering a collection of function of the type, $ f:[0,2\pi]\rightarrow \mathbb{R^2}$. I want to define the $L^2$ norm of the function in that space. I am defining the a norm of $f(=(f_1,f_2)')$ as $\rho(f)=\int_0^{2\pi}(f^2_1(x)+f^2_2(x))^{\frac{1}{2}}dx$. Could anyone please suggest me how to show whether the above norm is an $L^2$-norm or not? Or any suggestion about any $L^2$ norm in such a space. Thanks in advance.","['vector-spaces', 'functional-analysis', 'problem-solving']"
1309115,"The relationship of $\hom(M\otimes_RN,M'\otimes_RN')$ and $\hom_R(M,M')\otimes\hom_R(N,N')$.","Let $R$ be a ring with identity, $M$ and $M'$ two right $R$-module, $N$ and $N'$ two left $R$-module. There is a natural way to define a homomorphism $$f:\hom_R(M,M')  \otimes \hom_R(N,N')\to
    \hom(M\otimes_R N, M'\otimes_RN').$$ My question is that, is $f$ always monic, epic, or isomorphic? And if any answer is no, then is there any characterization of the case when $f$ is so?","['homological-algebra', 'abstract-algebra', 'tensor-products', 'additive-categories', 'modules']"
1309116,How can one check if a Cauchy-sequence converges in the rationals?,Let $(x_k)$ be a sequence in $\mathbb Q$ such that $x_k=\sum\limits_{n=1}^{k}\frac{1}{10^{n^2}}$ for all $k\geq 1$. It can be easily seen that this sequence is bounded and Cauchy. But does it converge in $\mathbb Q$? I could not find any way to verify that. Please help!,"['sequences-and-series', 'cauchy-sequences', 'real-analysis']"
1309122,Taylor expansion of Riemannian exponential map and Jacobi fields?,"1) Let $(M,g)$ be a Riemannian manifold, and at $p\in M,$ let $exp_p:U\subset T_pM\to M$ denote the Riemannian exponential map defined on $U\subset T_pM.$ I'd like to know how I could expand $t\mapsto exp_p(tv)$, possibly with the first term $exp_p(0)=p$. Now, I know that addition would NOT make sense unless you assume that $M\subset \mathbb{R}^n$, so assume whatever you need to assume topologically or as differential manifolds, however, $M$ is NOT isometrically embedded in $\mathbb{R}^n$. 2) Secondly, with OR without any such assumption above, how can I expand the Jacobi field $J(t)$along a geodesic $c(t)\subset M$ so that $J(0)=0$ around $t=0$  ?. We know $J(t)=\frac{\partial}{\partial\epsilon}|_{\epsilon=0}exp_p(v+\epsilon w)=(Dexp_p)_{tv}(tw)$. Can I use the Taylor expansion of the exponential map to obtain that of its derivative? I'm hoping for an expression involving first term zero, second term involving $J'(0)=W,$, third term zero (as the second derivative $J''(0)=0$), the fourth term involving the curvature term $K(v,w)$, possible some parallel translates $P_{0,t}$ of certain vectors, and then higher order terms. I've seen a concrete such expansion for $||J(t)||$in Do Carmo's book, chapter on Jacobi fields. But I've never seen one for $J(t)$ itself. A detailed answer would be highly appreciated!","['analysis', 'geometry', 'riemannian-geometry', 'differential-geometry']"
1309137,How to prove that $\aleph_0+\aleph_0=\aleph_0$,"How to prove that $\aleph_0+\aleph_0=\aleph_0$ In my exercise book I have that proof: Let $B=2\mathbb{N}+1$ and $A=2\mathbb{N}$ $A,B $ disjoint and $A+B=\aleph_0$ But to me it looks like example and not a proof.",['elementary-set-theory']
1309149,Why more than 3 dimensions in linear algebra?,"This might seem a silly question, but I was wondering why mathematicians came out with more than 3 dimensions when studying vector spaces, matrices, etc. I cannot visualise more than 3 dimensions, so I am not seeing the goal of having more than 3 dimensions. Except from the fact that the general rules of linear algebra can be applied mathematically to vectors spaces of higher dimensions, what is the practical purpose of having more than 3 dimensions? Linear algebra is also the study of system of linear equations that can have more than 3 unknowns, is this maybe related?","['applications', 'linear-algebra', 'soft-question']"
1309151,Integral and its limit,Evaluate: $$ \int_{0}^{\pi/2}n \left(1-\sqrt[n]{\cos x}\right) \mathrm{d}x$$ Rewriting this as $$I(n)= \int_{0}^{\pi/2}n \left(1-\sqrt[n]{\cos x}\right) \mathrm{d}x$$ and then Differentiating under the Integral Sign with respect to $n$ . I was unable to go much further with this. $$$$ Original problem: $$ \large\lim_{n \to \infty} \int_{0}^{\pi/2}n \left(1-\sqrt[n]{\cos x}\right) \mathrm{d}x$$,['integration']
1309155,"for each $x>1 , \frac{x-1}{x}\ < \ln x < x-1$","I tried to prove this with differentiation:
when $x >$ 1, all 3 functions are positive and when $x = 1$, all 3 reaches zero. And the derivatives are varying like $$\frac{\mathrm{d}(\frac{x-1}{x})}{\mathrm{d}x}\ < \frac{\mathrm{d}(\ln x)}{\mathrm{d}x}\ < \frac{\mathrm{d}(x-1)}{\mathrm{d}x}$$ Are they enough to say that above inequality is true?","['implicit-differentiation', 'derivatives']"
1309161,Compact subsets of the plane with connected complement,"Let $\mathscr{C}$ be the class of compact subsets of the (euclidean) plane $\mathbb R^2$ with connected complement. If $K\in\mathscr C$ and $M \subseteq \mathbb R^2$ is homeomorphic to $K$, does it follow that $M$ belongs to $\mathscr C$? (The corresponding question for open subsets (and the complement in the extended plane) has a positive answer because simple connectedness is a topological property.) The question is related to complex analysis (e.g. Megelyan's theorem).","['complex-analysis', 'general-topology']"
1309169,Show that if $P(0 \leq X \leq c)=1$ then $Var(X) \leq \frac{c^2}{4}$,"I need to show that if $$P(0 \leq X \leq c)=1$$ then $$Var(X) \leq \frac{c^2}{4}$$ I can show that using 2 things:
First, that $E[X^2] \leq cE[X]$
and secondly that $Var(X) \leq c^2[\alpha(1-\alpha)]$ for $\alpha=\frac{E[X]}{c}$. Could anyone help me prove these 2 steps? Last step is quite immediate.",['probability']
1309170,Extension of $|\cdot|_\infty$ on $\mathbb R$ to $\mathbb C$,"Let $|\cdot|$ be the usual absolute value on $\mathbb C$. My question is: Is the only extension of $|\cdot|$ on $\mathbb R$ to $\mathbb C$ $|\cdot|$ itself? I'm not sure about the uniqueness. I want to show any two extensions of $|\cdot|$ to $\mathbb C$ induce same topologies, which means that one is a positive power of the other (and so are equal). Is it true any two absolute values on $\mathbb C$ induce the same topology (as $\mathbb C$ is a finite dimensional vector space over $\mathbb R$)? Thank you!","['number-theory', 'valuation-theory']"
1309187,Why do we assume the complex plane is curvey at infinity?,"In at least a few areas (i.e., those that I have happened across) when we have a need to capture a half-plane we do so by taking a semi-circle of radius $r$ in that half, and taking the limit as $r\rightarrow\infty$. For example, the positive-imaginary half-plane for Jordan's Lemma, or the positive-real half-plane to construct the Nyquist Contour. What motivates this model? It would seem to me that in a 'Cartesian-like' grid, we should have to take a semi-square of side length $s$ (that is, an $s, 2s$ sided rectangle) in the limit $s\rightarrow\infty$. How do we know the semi-circle construction is equivalent? (Or, why am I wrong, and the rectangular construction doesn't work?) I have a sort of sketchy idea from discussion in comments of @texasfloods' answer that I can't think how to formalise - that given the unit circle $x^2+y^2=r^2$ it seems intuitive that taking $\lim_{r\rightarrow\infty}$ is identical to $\lim_{\sqrt{x^2+y^2}\rightarrow\infty}$, the hypotenuse of the right triangle, and by a bit of hand-waving, ""done"". Also from @pbs' comment below, it seems reasonable to say that for any open set $A$ of points enclosed by any 'contour shape' $\Gamma, \forall z\in A$ there exists a 'large-enough' construction of $\Gamma$ to enclose $z$. I'm fairly convinced, but I'd still be interested in a more 'proper'/rigorous proof or explanation if anyone cares to offer one.","['coordinate-systems', 'limits', 'complex-analysis']"
1309234,"Given a vector space with two inner products, there is a linear transformation taking one to another","I am looking for some hint to the following question: Let $V$ be an $n$-dimensional real inner product space and let $\langle x,y\rangle$ and $[x,y] $ both be two different inner products on V. Prove that there exists a linear mapping $L : V → V $such that $$[L(x), L(y)] =
 \langle x,y\rangle$$ for all $x,y \in V$. Thank you.","['vector-spaces', 'linear-algebra', 'inner-products', 'linear-transformations']"
1309235,Complement of a foliation,"I have an $n$-manifold $M$ which is foliated by leaves $F_\alpha$ of dimension $p$ and a path $\gamma:[0,1]\to M$. You can take without problems $\gamma$ to be injective. Is the following statement true? Claim: There exists a neighborhood $U$ of the image of $\gamma$ and a foliation $L_\beta$ of $U$ of dimension $n-p$ such that $F_\alpha\pitchfork L_\beta$ for all $\alpha,\beta$. Basically what I would like to do is to have an extension of a complement of the tangent space to the leaves $F_\alpha$ in $TM$ to the tangent of local submanifolds of complementary dimension. I feel that this should be true, but I'm not sure about how to proceed. Would go to local coordinates (respecting the foliation) in charts around $\gamma$ solve the problem? How could I make the obtained complements patch together correctly? An easy partial result: We can always find such a complement to the foliation in an appropriate chart. Indeed, by definition of foliation we know that for any point $m\in M$ we have a neighborhood $U$ of $m$ and a chart $\phi:U\to\mathbb{R}^n$ such that the leaves correspond to the $p$-planes of constant $x$, where we decompose $(x,y)\in\mathbb{R}^{n-p}\times\mathbb{R}^p=\mathbb{R}^n$. Then the preimages of the planes of constant $y$ are our complement (they are regular by the inverse function theorem and the usual arguments).","['differential-geometry', 'foliations']"
1309245,Local ring at generic point,"Let $X$ be a smooth projective variety, and $Y$ a subvariety of codimension one (both are irreducible).
I want to show that the local ring $\mathcal{O}_{Y,X}$ at the subvariety $Y$ (which is nothing but the local ring $\mathcal{O}_{\eta,X}$ at the generic point $\eta$ of $Y$) is a discrete valuation ring. I know the following: The local ring $\mathcal{O}_{P,X}$ at any point $P \in X$ (closed or not) is regular. (If $P$ is closed, this is the definition of ""smooth"", and any local ring at a non-closed point is a localisation of a local ring at a closed point, whence regular). Any Noetherian regular local ring of (Krull) dimension one is a discrete valuation ring. It seems I need to prove that $\dim \mathcal{O}_{Y,X} = 1$, and since $Y$ is of codimension one in $X$, this would follow from the more general fact that for any subvariety $Z \subset X$, $\dim \mathcal{O}_{Z,X} = \text{codim}_{X} Z$. My question is: Is this reasoning correct, and if yes, how do I prove it. Thanks for your help.","['ring-theory', 'algebraic-geometry', 'localization']"
1309272,Product of reduced row-echelon matrices is also reduced row-echelon,"Show that the product of two reduced row-echelon matrices is also
  reduced row-echelon. That's what I think: A reduced row-echelon matrix has columns like $e_1 =(1, 0, \cdots , 0)^T$ and $e_2 =(0, 1, 0, \cdots , 0)^T$. For columns in between $e_n$ and $e_{n+1}$, only the first $n$ entries will be non-zero. By noticing these two, I can 'imagine' that the product should be reduced row-echelon. But I cannot write down a clear proof for that. Or say, I don't even know how to start my proof. Can someone give me a helping hand?",['linear-algebra']
1309296,Factors in a cubic equation,I have no idea how to go about this. Any Hint? Suppose that $(x-3)$ is a factor of $$kx^3 - 6x^2 + 2kx - 12.$$ Solve for $k$.,"['polynomials', 'factoring', 'algebra-precalculus', 'roots']"
1309303,Show that Laplacian is zero,"Let $u: \mathbb{R}^n \rightarrow \mathbb{R}$ be harmonic, i.e. $\Delta u =0.$ Now, I want to show that $\Delta (u(Ox+b))=0$ for an orthogonal matrix $O$ and a constant vector $b$. Does anybody know how this can be shown? Regarding the answer, I received. mhmm. $D(u(Ox+b)) = Du (Ox+b)D(Ox+b)= Du(Ox+b)O.$ I don't quite see how the divergence of this could look like?","['analysis', 'calculus', 'real-analysis', 'multivariable-calculus']"
1309306,"Accumulation points of $ \{x_n \in \mathbb{R}, n \in \mathbb{N} \ \ | \ x_n = n\sin(n) \}$? [duplicate]","This question already has answers here : Is $n \sin n$ dense on the real line? (3 answers) Closed 9 years ago . A younger student asked me: What are accumulation points of the following set? $$ \{x_n \in \mathbb{R}, n \in \mathbb{N} \ \ | \ x_n = n\sin(n) \}$$ I really can't answer this question, could anyone help me?","['diophantine-approximation', 'real-analysis']"
1309316,"Proof of Number of: *permutations of ‘n’ things, taken ‘r’ at a time, when ‘m’ specified things always come together*","I read below at many sources Number of permutations of ‘n’ things, taken ‘r’ at a time, when ‘m’ specified things always come together =$ m!  * (n-m+1) !$ However no one gave the proof.
I reached till this: First we have choose r out of n: $^nC_r=\frac{n!}{(n-r)!r!}$ Then choose m out of r: $^rC_m=\frac{r!}{(r-m)!m!}$ Next arrange m elements : $m! (r-m+1)!$ Next I have to multiply all above and do cancelation. So I reached to: $\frac{n!(r-m+1)!}{(n-r)!(r-m)!}$ But I don't to get how to proceed to get the given $ m!  * (n-m+1) !$",['combinatorics']
1309348,"Show $\forall\varepsilon>0\,\lim_{n\to\infty}\frac{\#\{\text{positive divisors of n}\}}{n^\varepsilon}=0$","Show that $\forall\varepsilon>0,$ $$\lim_{n\to\infty}\frac{\#\{\text{positive divisors of  n}\}}{n^\varepsilon}=0$$ I'm trying to solve this problem for a long time, but I'm really stuck I have totally no idea where to start.
I tried replacing $\varepsilon$ by $\frac{1}{k}$ where $k$ is a natural number, and show the statement is true for all $k$ by induction, but I haven't succeeded and it doesn't seem promising. If you give me any advice or comment, I would greatly appreciate. Thank you.","['analysis', 'real-analysis', 'elementary-number-theory', 'divisor-counting-function']"
1309350,How should I go about doing this proof?,"I am new to mathematical proofs and would like some help understanding how to prove 
$$
\left(A^c \cup B^c\right) - A = A^c
$$ I would like to see a proof if possible. I understand that we need to prove equality of the two sides which is done by making sure both sides are subsets of each other.",['elementary-set-theory']
1309393,What is the moment generating function of Dirichlet distribution?,"I want to find the moment generating function (or the Laplace transform) of the Dirichlet distribution. I know the moments can be found using the gamma functions as follows 
:$$E\left[\prod_{i=1}^K x_i^{\beta_i}\right]=\frac{B\left(\boldsymbol{\alpha}+\boldsymbol{\beta}\right)}{B\left(\boldsymbol{\alpha}\right)}=\frac{\Gamma\left(\sum_{i=1}^{n}\alpha_{i}\right)}{\Gamma\left(\sum_{i=1}^{n}\alpha_{i}+\beta_{i}\right)}\times\prod_{i=1}^{n}\frac{\Gamma\left(\alpha_{i}+\beta_{i}\right)}{\Gamma\left(\alpha_{i}\right)},$$ but what I am really interested in is the functional form of the MGF (or the Laplace transform) so that it can be used to find other sampling distributions thereof or any other transformation of the Dirichlet also.","['probability', 'statistics']"
1309402,Why $F(z) = |z|^2$ is holomorphic nowhere?,"I am self-studying basic complex analysis, and am slightly confused as to how to show that $F(z) = |z|^2$ is holomorphic nowhere. A necessary and sufficient condition for the holomorphism of $F(z)$ is that $F(z)$ is independent of $\overline{z}$. That is, we require: $$\frac{\partial F}{\partial \overline{z}}=0$$ We note that we have $F(z) = |z|^{2} = z\overline{z}$, and so we have: $$\frac{\partial F}{\partial \overline{z}}=z$$ And so we clearly have that $F(z)$ is holomorphic everywhere, except $z = 0$, however, I don't understand why we cannot say $F(z)$ is holomorphic at $z=0$, is it because in the neighborhood of $z = 0$ we have that $F(z)$ is nowhere holomorphic?","['complex-analysis', 'complex-numbers', 'derivatives']"
1309411,"Proof that $f(x)=0 \forall x \in [a,b]$","Lemma : If $f \in C([a,b])$ and $\int_a^b f(x) h(x) dx=0 \  \forall h \in C^2([a,b])$ with $h(a)=h(b)=0$ then $f(x)=0 \ \forall x \in [a,b]$. Proof of lemma : Suppose that there is a $x_0 \in (a,b)$ such that $f(x_0) \neq 0$, for example without loss of generality we suppose that $f(x_0)>0$.
Because of continuity there is an interval $[x_1, x_2] \subset (a,b)$ such that $x_0 \in (x_1, x_2)$ and $f(x)>0 \ \forall x \in (x_1, x_2)$. We define the function $g(x)=\left\{\begin{matrix}
(x_2-x)^3 (x-x_1)^3 & , x \in (x_1, x_2)\\ \\
0 & ,  x \in [a,b] \setminus{(x_1,x_2)} 
\end{matrix}\right.$. Then $g \in C^2([a,b])$ and $g(a)=g(b)=0$. From the hypothesis we have: $$\int_a^b f(x)g(x) dx=0$$ But $\int_a^b f(x)g(x) dx= \int_{x_1}^{x_2} f(x)g(x) dx>0$, contradiction. First of all, why do we say that there is an interval $[x_1, x_2] \subset (a,b)$ such that $x_0 \in (x_1, x_2)$ and $f(x)>0 \forall x \in (x_1, x_2)$? Why don't we pick the closed interval $[x_1, x_2]$ ? Also why does it hold that $\int_a^b f(x) g(x) dx= \int_{x_1}^{x_2} f(x) g(x) dx$? Furthermore, the prof told us that we couldn't take the function $g(x)=\left\{\begin{matrix}
(x_2-x)^2 (x-x_1)^2 & , x \in (x_1, x_2)\\ \\
0 & ,  x \in [a,b] \setminus{(x_1,x_2)} 
\end{matrix}\right.$ but the powers both of $(x_2-x), (x-x_1)$ have to be greater or equal to $3$. Why is it like that?","['analysis', 'functions']"
1309426,How many solutions for equation $x_1+x_2+x_3+x_4+x_5 = 15$ have two variables equal to 1?,"How many solutions for equation $x_1+x_2+x_3+x_4+x_5=15$ have exactly two variables equal to 1? ($x_i \ge 1 $) Hint : think about splitting 15 beans among 5 children, considering the restrictions.","['discrete-mathematics', 'combinatorics']"
1309427,Can a number be equal to the sum of the squares of its prime divisors?,"If $$n=p_1^{a_1}\cdots p_k^{a_k},$$ then define $$f(n):=p_1^2+\cdots+p_k^2$$ So, $f(n)$ is the sum of the squares of  the prime divisors of $n$. For which natural numbers $n\ge 2$ do we have $f(n)=n$ ? It is clear that $f(n)=n$ is true for the square of any prime, but false for
the other prime powers. If $p$ and $q$ are the only prime divisors of $n$, we would get $p^2+q^2\equiv
0\pmod p$, which implies $p=q$, so for numbers with exact two prime
divisors, $f(n)=n$ cannot hold. If $p,q,r$ are primes with $p<q<r$, then we have two possibilities. If $p,q,r\ne 3$, we have $p^2+q^2+r^2\equiv 0\pmod3$, so $f(n)=n$
cannot hold. If $p=3$ or $q=3$, then $p^2+q^2+r^2 \equiv 2\pmod3$,
so $p^2+q^2+r^2$ is not divisible by $3$, so $f(n)=n$ cannot hold. Finally, if $p<q<r<s$, then if $p>2$, then $p^2+q^2+r^2+s^2\equiv 0\pmod4$, so $f(n)=n$ cannot hold. And if $p=2$, then $p^2+q^2+r^2+s^2\equiv 3\pmod4$, so $p^2+q^2+r^2+s^2$ is odd and $f(n)=n$ again cannot hold. So, apart from the squares of the primes, the number must have at least $5$
prime factors. I searched to about $6\times 10^7$ and did not find a ""non-trivial"" example. Is there a number $n$ with at least two prime factors and $f(n)=n$ ?","['sums-of-squares', 'prime-factorization', 'square-numbers', 'prime-numbers', 'number-theory']"
1309473,Distance between a Poisson and Normal distribution.,"Let $X_a$ be a random variable Poisson distributed with intensity  $a$.
That is 
$$\mathbb{P}(X_a=k)= e^{-a} a^k / (k!)$$
for any $k\in \mathbb{N}$.
Let 
$$Y_a=(X-a)/\sqrt{a}$$
the normalization of $X_a$ such that it has mean $0$ and variance $1$.
Let $F_{Y_a}$ its cumulative distribution function. That is
$$F_{Y_a}(t)=\mathbb{P}(Y_a\leq t).$$
Let $N$ be the standard normal distribution and $F_N$ its cumulative distribution function. That is
$$F_N(t)=\mathbb{P}(N\leq t) = \int_{-\infty}^t \frac{1}{\sqrt{2\pi}} e^{-\frac12 t^2} \mathrm{d}t.$$
Wikipedia says For sufficiently large values of $a$, (say $a$>1000), the normal distribution with mean $a$ and variance $a$ (standard deviation $\sqrt{a}$) is an excellent approximation to the Poisson distribution. My question is: How strong is the convergence of $Y_a$ against $N$ when $a\to\infty$? Do we only have convergence in distribution : $F_{Y_a}(t) \to N(t)$ when $a\to\infty$ for any $t\in\mathbb{R}$. Or can we say more?
In particular I would like to have an upper bound (depending on $a$) for
$$ \int_{-\infty}^{\infty} |F_{Y_a}(t)-F_N(t)| \mathrm{d}t.$$
I would be even more happy if someone comes up with an upper bound for
$$ \int_{-\infty}^{\infty} |F_{Y_a}(t)-F_N(t)|^p \mathrm{d}t \quad \text{with }p>1.$$
What is a good reference for this kind of results?","['probability-theory', 'probability-limit-theorems', 'probability-distributions']"
1309486,"Find $\lim_{x\to\infty}\frac{f^{-1}(x)}{\ln(x)}$, where $f(x)=e^x+x^3-x^2+x$, without L'Hospital","We have $f:\mathbb{R}\to\mathbb{R},f(x)=e^x+x^3-x^2+x$ and we need to evaluate $$\lim_{x\to\infty}\frac{f^{-1}(x)}{\ln(x)}$$ There is an elegant way to solve this problem ? Here is all my steps: My first ideea was to use squeeze theorem such that: $$\alpha\leq f^{-1}(x)\leq\beta$$ $f(\ln(x))=x+\ln^3(x)-\ln^2(x)+ln(x)\ge x\Rightarrow\beta=\ln(x),\forall x>1$ How can I find $\alpha$ such that $f( ? )\leq x,\forall x\in V$ where $V\subset\mathbb{R}$ such that $(\exists)$ an open interval I such that $x\in I\subset V$ ? P.S. : I know the method with L'Hospital's rule and absolutely is the easiest way to solve my problem, but I don't consider an ""elegant way"". I forgot to say that. What I want to prove in my demonstration is that $\frac{\alpha}{\ln(x)}\leq\frac{f^{-1}(x)}{\ln(x)}\leq\frac{\beta}{\ln(x)}$ and if we see the upper bound $\frac{\beta}{\ln(x)}\to 1$ as $x\to\infty$ So what I have to do is to find $\alpha$ such that $\frac{\alpha}{\ln(x)}\to 1$","['analysis', 'calculus', 'real-analysis']"
1309496,Inverse of the Toeplitz matrix,"I am working on the inverse of the sum of an identity matrix and a Toepltz matrix, and trying to find the formula for the (1,1) element of the inverse. For example, Assume $c$ is a nonzero constant, and let $$A_{t}=cI_{t}+\Omega_{t},$$ where, for $t=4$, $$
\Omega _{t}=\left(
\begin{array}{cccc}
1 & \rho  & \rho ^{2} & \rho ^{3} \\
\rho  & 1 & \rho  & \rho ^{2} \\
\rho ^{2} & \rho  & 1 & \rho  \\
\rho ^{3} & \rho ^{2} & \rho  & 1%
\end{array}%
\right), \quad
\text{with} \quad \left\vert \rho \right\vert <1.
$$ In general, the $(i,j)$-th element of $\Omega _{t}$ is given by $\rho ^{|i-j|}$. Is there any way to find a general formula for the $(1,1)$-th element of $A_{t}^{-1}$ for different $t,$ say, $t=2,3,4,\ldots ?$ Many thanks!","['inverse', 'matrices']"
1309498,"Why did Euclid name his book as ""Elements""? What does ""element"" mean in this context?",Does it relate to the nature of the book in some way?,"['geometry', 'terminology']"
1309515,Inverting the Radial Distortion,"Overview The problem is perhaps a very easy one for a trained mathematician. As I am not a mathematician, but instead a researcher in general problem solving, I am reaching out to those who know more than I in an effort to solve a problem. The mathematics are known to me in a simpler form of the solution and it all relates to a set of operations used in optics: radial lens distortion. I have a function: $y=f(x)$. I need the inverse function such that: $x=f'(y)$ . The Data A few websites give a good review of the equations in a simpler form: paulbourke.net/miscellaneous/lenscorrection/ en.wikipedia.org/wiki/Distortion_%28optics%29 www.imagemagick.org/Usage/lens/correcting_lens_distortions.pdf See Page 3 This post asks the same question , but with less contextual data Definition of Terms $ \vec\alpha$ non-normalized vector from $\displaystyle Pixel\_current_{x,y}$ to $\displaystyle Pixel\_center_{x,y}$ $ \beta$ length of $\vec\alpha$ $k_i$ The $i$-th coefficient of the distortion parameter series $P_{(x,y)}$ Undistorted Pixel Location $Q_{(x,y)}$ Distorted Pixel Location List of Known Functions The radial distortion function is in the form of: FUNCTION 1 :: $ P_{(x,y)} = Q_{(x,y)} \times ( \displaystyle 1 + \displaystyle\sum_{i=1}^\infty(k_i  × \beta^{2i} )) $ Most implementations contain only the first two distortion terms, and thus looks like: FUNCTION 2 :: $ P_{(x,y)} = Q_{(x,y)} \times (1 + k_1\beta^2)$ I've found a working inverse function for FUNCTION 2 : FUNCTION 3 :: $ Q_{(x,y)} = \displaystyle \frac {P_{(x,y)}} {1 - k_1 \times \displaystyle \left\| \frac{\vec\alpha}{1 - k_1 \times \left\|\vec\alpha\right\|^2} \right\|^2}$ FUNCTION 3 works beautifully as long as I don't need a second distortion coefficient, or the second term of the original Taylor series. The Request 1. What I’m looking for is a reciprocal function that accounts for the first two terms of the Taylor series, the inverse of: FUNCTION 4 :: $P_{(x,y)} = Q_{(x,y)} \times \left( 1 + k_1 \times \left\|\vec\alpha\right\|^2  + k_2 \times \left\|\vec\alpha\right\|^4 \right) $ 2. I need a version of the formula that I can write into computer code using a list of operators defined on this page ; in addition to standard operators like: $+ - \times \div \left( \right)$, etc. So, every step needs to be broken down into single instructions. Again, my math-fu is limited.","['sequences-and-series', 'inverse', 'functions']"
1309522,Would the Riemann Hypothesis being false affect how frequently primes occur in the number system?,"I want to know that if Riemann hypothesis is false (big assumption) would that lead to any effect in how frequently primes occur . Well I got this half cooked information from here: http://chat.stackexchange.com/transcript/message/21561457#21561457 And I want to get a bit more information on what was said over there. By the way primes occur I mean that will the primes start occurring more frequently. If they start occurring more frequently, can we find out by how much? Then we might be able to relate this to the new bound which has been found between primes. That might give us a connection between the twin prime conjecture and the Riemann hypothesis.","['riemann-hypothesis', 'number-theory', 'riemann-zeta']"
1309541,Relatives of Heegner numbers?,"It is well known that Euler's lucky numbers are related to the Heegner numbers , where \begin{align}
&n^2+n+p\\
\end{align} gives primes for $n=0,\dots,p-2$ if and only if its discriminant $1-4p$  equals minus a Heegner number. This is then true for $p=2, 3, 5, 11, 17, 41.$ There seems to be another group of numbers, namely $p=2, 3, 5, 7, 13,$ that gives primes for \begin{align}
&n^2+n-p^2\\
\end{align} for $n=1,\dots,2p-2.$ eg, $n^2+n-13^2$ for $1\leq n\leq 24$ produces $$-167, -163, -157, -149, -139, -127, -113, -97, -79, -59, -37, \
-13,$$$$ 13, 41, 71, 103, 137, 173, 211, 251, 293, 337, 383, 431.$$ The class numbers for the discriminants are not all the same however, and I could find no reference for this finite group, though there are many sequences that begin with these primes (Mersenne exponents, Pierpont primes, etc.). It could, of course be coincidental, simply an example of the law of small numbers. If not though, what links these numbers if not the class numbers of the discriminants?","['class-field-theory', 'prime-numbers', 'number-theory']"
1309546,An inner product on the dual space of a non-complete inner product space?,"As is well known, for any Hilbert space $V$, there is a natural inner product on the continuous dual. (the space of all continuous linear functionals). Is there a way to endow an inner product on the algebraic dual of an infinite dimensional inner product space? (which should be connected somehow to the inner product of the original space) what about the continuous dual (of non-complete spaces)?","['hilbert-spaces', 'inner-products', 'linear-algebra', 'functional-analysis']"
1309576,Hypothesis Testing Confusion - Laboratory Mice,"I've slowly been building up some confidence on these types of problems but after the easy plug-n-chug I get very confused on what to do. There is a solution I found online for this question (number 1, solution 1) but I get confused on the very last step, where they say .046 > .05. The question is: A colony of laboratory mice consists of several thousand mice. The average
weight of all the mice is 32 grams with a standard deviation of 4 grams. A laboratory assistant
was asked by a scientist to select 25 mice for an experiment. However, before performing the
experiment, the scientist decided to weigh the mice as an indicator of whether the assistants
selection constituted a random sample or whether it was made with some unconscious bias
(perhaps the mice selected were the ones that were slowest in avoiding the assistant, which
might indicate some inferiority about this group). If the sample mean of the 25 mice was
30.4, would this be significant evidence, at the 5 percent level of significance, against the
hypothesis that the selection constituted a random sample? My steps were: Ho = mu-not is 32 grams (selection is random) H1 = mu is not 32 grams (selection is not random) standard deviation is 4 grams n = 25 mice x-bar (sample mean) = 30.4 Confidence Interval is 95% (level of significance is .05) All I really did was find the p-value using: (x-bar - mu) / (std dev / sqrt(n)) p-value: |30.4 - 32| / (4/5) = 2 The probability of rejecting Ho = (Z > 2) Value based on the confidence interval would be the level of significance divided by 2 since this is a two-sided confidence interval. Looking this up in a z-table I got 1.96. However, I don't know where to go from here especially since the solutions page has .046 < .05, which I'm not sure how to get. Can someone please explain this?","['hypothesis-testing', 'statistics']"
1309606,Finding $\lim\limits_{n\to\infty }\frac{1+\frac12+\frac13+\cdots+\frac1n}{1+\frac13+\frac15+\cdots+\frac1{2n+1}}$,I need to compute:  $\displaystyle\lim_{n\rightarrow \infty  }\frac{1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\cdots+\frac{1}{n}}{1+\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\cdots+\frac{1}{2n+1}}$. My Attempt : $\displaystyle\lim_{n\rightarrow \infty  }\frac{1+\frac{1}{2}+\frac{1}{3}+\frac{1}{4}+\cdots+\frac{1}{n}}{1+\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\cdots+\frac{1}{2n+1}}=\lim_{n\rightarrow \infty  }\frac{2s}{s}=2$. Is that ok? Thanks.,"['sequences-and-series', 'harmonic-numbers', 'calculus', 'limits']"
1309628,Easier ways to prove $\int_0^1 \frac{\log^2 x-2}{x^x}dx<0$,"Prove that $$\int_0^1 \frac{\log^2 x-2}{x^x}dx<0$$ One way to do this is use the idea in the proof of Sophomore's dream. We have
$$x^{-x}=\exp(-x\log x)=\sum_{n=0}^\infty\frac{(-1)^nx^n\log^n x}{n!}$$
Therefore, using the change of variable $x=\exp(-t/(n+1))$ we have $$\begin{aligned}\int_0^1 \frac{\log^2 x}{x^x}dx=&\sum_{n=0}^\infty\frac{(-1)^n}{n!}\int_0^1x^n\log^{n+2}xdx\\
=&\sum_{n=0}^\infty\frac{(n+1)^{-(n+3)}}{n!}\int_0^\infty t^{n+2}e^{-t}dt\\
=&\sum_{n=0}^\infty\frac{(n+1)^{-(n+3)}(n+2)!}{n!}\\
=&\sum_{n=0}^\infty(n+1)^{-(n+2)}(n+2)\\
=&\sum_{n=1}^\infty n^{-(n+1)}(n+1)\\
=&\sum_{n=1}^\infty n^{-n}+n^{-(n+1)}\\
<&2\sum_{n=1}^\infty n^{-n}\\
=&\int_0^1\frac{2}{x^x}dx
\end{aligned}$$ Hence the result follows. I am curious if there are any other methods to prove this, especially I am interested in easier approaches. P.S. This was a bonus problem in an assignment from a multivariable calculus class.","['sequences-and-series', 'real-analysis', 'improper-integrals', 'integral-inequality']"
1309701,"Does $\int_{-1}^1\frac{\arctan x}{\text{arctanh}\,x}\,\mathrm{d}x$ have a closed form?","$$\newcommand{\arctanh}{~\mathrm{arctanh}~}\newcommand{\sech}{~\mathrm{sech}~}$$ $$I=\int_{-1}^1\frac{\arctan x}{\arctanh x}\,\mathrm{d}x$$
Mathematica gives an approximate result of $I=1.581949621806183890451628...$, but no exact form. I predict it's a function of $e$ and $\pi$, and perhaps even the Golden Ratio $\phi$ ( It certainly wouldn't be the first time ) The motivation behind this question is pure curiosity. I thought the shape looked nice :) 1st edit: Substitutions of $x=\tan u$ and $x=\tanh u$ respectively yield
$$I= 2\int_{-\pi/4}^{\pi/4}\dfrac{u\sec^2u}{\ln|\frac{1+\tan u}{1-\tan u}|}\,\mathrm{d}u$$
$$I= \int_{-\infty}^{\infty}\dfrac{\arctan(\tanh u)}{u}\sech^2u\,\mathrm{d}u$$ 2nd edit: I've considered another approach starting with parameterizing the desired integral by
$$I_a=\int_{-1}^1\frac{\arctan ax}{\arctanh x}\,\mathrm{d}x$$
so that
$$\frac{\partial I_a}{\partial a}=\int_{-1}^1\frac{x}{(1+(ax)^2)\arctanh x}\,\mathrm{d}x$$
Integrating by parts with
$$\begin{matrix}u=\dfrac{1}{\arctanh x}&&\mathrm{d}v=\dfrac{x}{1+(ax)^2}\,\mathrm{d}x\\[1ex]
\mathrm{d}u=\dfrac{\mathrm{d}x}{(x^2-1)\arctanh^2x}&&v=\dfrac{1}{2a^2}\log(1+(ax)^2)\end{matrix}$$
yields the following integral:
$$\frac{\partial I_a}{\partial a}=\frac{1}{2a^2}\int_{-1}^1\frac{\log(1+(ax)^2)}{(1-x^2)\arctanh^2x}\,\mathrm{d}x$$
which can be modified by a substitution of $y=\arctanh x$ to obtain
$$\frac{\partial I_a}{\partial a}=\frac{1}{2a^2}\int_{-\infty}^\infty \frac{\log(1+(a\tanh y)^2)}{y^2}\,\mathrm{d}y$$ I have an idea of approaching the remaining integral using the series expansion of $\log(1+x)$; namely, the integral would become
$$\frac{\partial I_a}{\partial a}=\frac{1}{2a^2}\int_{-\infty}^\infty \frac{\mathrm{d}y}{y^2}\sum_{k=1}^\infty\frac{(-1)^{k+1}}{k}(a\tanh y)^{2k}=-\frac{1}{2a^2}\sum_{k=1}^\infty \frac{a^{2k}(-1)^k}{k}\underbrace{\int_{-\infty}^\infty \frac{\tanh^{2k}y}{y^2}\,\mathrm{d}y}_{J_k}$$
According to this question , we have a closed from $J_k$ in the case of $k=1$ and potentially all $k>1$ in terms of the Riemann zeta function, but I have yet to do any more investigation. Another method that occurred to me was to consider a keyhole contour to tackle $\dfrac{\partial I_a}{\partial a}$ but I'm afraid I'm not familiar enough with complex analysis to make that jump just yet.","['closed-form', 'special-functions', 'definite-integrals', 'integration']"
1309729,Need help with Mean Value Theorem Please! [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Have a question from a Calculus past paper and don't really know where to go with this question, any help would be appreciated. The question from the paper is: Suppose that $0<a<b.$
Show that $\frac{\sinh b-\sinh a}{\cosh b- \cosh a}=\coth (c)$ for some $c\in(a,b)$. (Hint: Apply the mean value theorem with $f(x)=\sinh x-\lambda \cosh x$ for a suitable choice of $\lambda \in \mathbb{R}$. Just looking for any input to help solve this question, Many Thanks.","['analysis', 'calculus']"
1309742,question from do carmo diff. geometry,"I am studying differential geometry myself from Do carmo and i didn't understand the question : show that if a surface is tangent to a plane along a curve , then the points of this curve are either parabolic or planar . At the question i didn't understand the sentence ' surface is tangent to a plane along a curve ' 
Please firstly help  me about it and later maybe hints for solution",['differential-geometry']
1309780,Why cannot $(2x^2 + x)^2$ be simplified to $2x^4 + x^2$?,"So, I want to simplify an equation : $(2x^2 + x)^2$. I thought this would simplify to $2x^4 + x^2$ But, if you input a value for $x$, the answers do not equal. For example, if you input $x = 3$, then: 
$$(2x^2+x)^2
= 21^2
= 441$$ AND:
$$2x^4 + x^2
= 2(82) + 9
= 173$$
Can anyone explain why this is the case?",['algebra-precalculus']
1309794,"Prove that $M(t)^2 - t$ is a martingale, $M(t)$ is a symmetric random walk","Prove that $M(t)^2 - t$ is a martingale, $M(t)$ is a symmetric random walk. My question here mainly has to do with the $F_{t}$ measurability of $M(t)^2 - t$, where $F_{t} = \sigma (X_1 , X_2, ... , X_t)$. If a function $M(t)$ is a measurable wrt $F_{t} = \sigma (X_1 , X_2, ... , X_t)$, is it always true that its square is also $F_{t}$- measurable?","['stochastic-calculus', 'stochastic-analysis', 'stochastic-processes', 'measure-theory']"
1309827,Completeness of the Hausdorff distance.,"THEOREM Let us define $$F(X) := \{ A \subseteq X | A \neq \emptyset, A - \text{closed and bounded} \} $$
Then if $(X, \rho ) $ is complete, then $(F(X), d_h )$ is complete. Are there any interesting proofs of this theorem other than the ones with long computations with $\epsilon$? I have been searching the internet for a while, but could not find anything.","['metric-spaces', 'complete-spaces', 'general-topology']"
1309839,How can affine coordinate rings be canonically identified as $k$-algebras?,"Exercise 1.5 of Hartshorne asks us to show (in one direction) that any affine coordinate ring $k[x_1,\dots,x_n]/I(Y)$ is a finitely-generated $k$-algebra with no nilpotents. The second part is quite simple - we know $I(Y)$ is radical by Nullstellensatz so the quotient is reduced. However, the second part is trickier for me - we're looking for $k\to k[x_1,\dots,x_n]/I(Y)$ that is finitely generated. Presumably this is somehow canonical, but I'm not sure how to find it. In short, how do I construct this map?","['algebraic-geometry', 'affine-geometry', 'commutative-algebra']"
1309841,find extreme values of $\cos(x)+\cos(y)+\cos(z)$ when $x+y+z=\pi$,"How can I find the maximum and minimum of $\cos(x)+\cos(y)+\cos(z)$ if $x,y,z\geq0$ such that they are vertices of a triangle with $x+y+z=\pi$. I don't know how to start, but I feel like the Lagrange multipliers are a good place to start.","['lagrange-multiplier', 'multivariable-calculus']"
1309847,Is $\sum_{k\leqslant n} f'(k)f'(n-k) \asymp f'(n)f(n)$ when $f'$ is positive decreasing?,"In this answer of a question of mine, the user Homegrown Tomato
  gave a nice argument that somewhat shows that $$\int_{\substack{t+s\leqslant x \\ t,s \geqslant 0}} f'(t)f'(s)dtds \asymp f(x)^2.$$ I actually improved this statement (under the hypotheses of my
  question) and concluded that in fact it's asymptotic to $C\cdot f(x)^2$ for some positive real constant $C$, but I'm not sure whether
  that's beside the point of my actual question here or not. I'm trying to estimate $\sum_{k\leqslant n} f'(k)f'(n-k)$ for $C^0$ decreasing $f'$, like $f'(x) = 1/\log{x}$, or $x^{-1},x^{-1/2},x^{-1/2}\log{x}$, etc. Unlike the case of $\sum_{k\leqslant n} f'(k)$, where to use the integral as an estimate is almost direct, I think something like $$ \sum_{k\leqslant n} f'(k)f'(n-k) \overset{?}\sim \int_{0\leqslant t\leqslant n} f'(t)f'(n-t)dt \tag{1}$$ must be true, but I was not able to prove. Well, still on that thought, the integration here is occuring on part of the boundary of a triangle, the same triangle of the integration on my previous question that I quoted above! So I thought in to try to relate the two questions, using something like Stokes or Reynolds' transport theorem , in order to get $$\int_{0\leqslant t\leqslant x} f'(t)f'(x-t)dt \overset{?}\approx \frac{d}{dx}\int_{\substack{t+s\leqslant x \\ t,s \geqslant 0}} f'(t)f'(s)dtds \overset{?}\approx f'(x)f(x) \tag{2}.$$ So what I'm asking is: Is there a way to formalize (1) and (2) , or at least one of them? And if no (or even if yes), there is another way (an easier, preferably haha) to show the statement of the question? In the worst-case scenario, a counterexample will be welcome hahaha","['real-analysis', 'sequences-and-series', 'integration', 'asymptotics', 'multivariable-calculus']"
1309853,Proving Galmarino's Test,"Galmarino's Test gives a condition equivalent to being a stopping time. It says: Let $X$ be a continuous stochastic process with index set $\mathbb{R}_+$ (i.e. each sample path is a continuous function of time). Let $\mathscr{F}$ be the filtration generated by $X$. Then a random time $T$ is a stopping time iff for every pair of outcomes $\omega$ and $\omega'$, $T(\omega) = t$, $X_s(\omega) = X_s(\omega')$ for $s \leq t \implies T(\omega') = t$ The condition essentially says that the map $T$ restricted to $\{T \leq t\}$ factors through $(X_s)_{s \leq t}$, and I can prove that it is necessary by using a monotone class argument. I don't know how to prove the converse though.","['probability-theory', 'stopping-times', 'martingales', 'stochastic-processes']"
1309857,What's the relation between different antiderivatives?,"If a function $f(x)$ has different forms of antiderivatives: $\frac { d }{ dx } { F }_{ 1 }(x)=f(x)$ $\frac { d }{ dx } { F }_{ 2 }(x)=f(x)$ What's the relationship between $F_1$ and $F_2$, is that ${F}_{1}(x)-{F}_{2}(x)=constant$ correct? For example, question find $\int { \frac { dx }{ { x }^{ 4 }-1 } = } $ ? Method 1: $\int { \frac { dx }{ { x }^{ 4 }-1 } =\int { \frac { dx }{ \left( { x }^{ 2 }-1 \right) \left( { x }^{ 2 }+1 \right)  } =\frac { 1 }{ 2 } \int { \frac { dx }{ { x }^{ 2 }-1 } -\frac { 1 }{ 2 } \int { \frac { dx }{ { x }^{ 2 }+1 }  } =\frac { 1 }{ 4 } ln\left| \frac { x-1 }{ x+1 }  \right| -\frac { 1 }{ 2 } arctan(x) } +c }  } $ Method 2:$\int { \frac { dx }{ { x }^{ 4 }-1 } =\frac { 1 }{ 2 } \int { \frac { d{ x }^{ 2 } }{ { \left( { x }^{ 2 } \right)  }^{ 2 }-1 } =\frac { 1 }{ 2 } ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| +c }  } $ Ok, now the question is: what's the relation between $ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| $ and $\frac { 1 }{ 2 } ln\left| \frac { { x }-1 }{ { x }+1 }  \right| -arctan(x)$ ? Does the equation below is correct and how to prove it? $ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| =\frac { 1 }{ 2 } ln\left| \frac { { x }-1 }{ { x }+1 }  \right| -arctan(x) +constant$",['calculus']
1309864,Why does $e^{-(x^2/2)} \approx \cos[\frac{x}{\sqrt{n}}]^n$ hold for large $n$?,"Why does this hold:
$$
e^{-x^2/2} = \lim_{n \to \infty} \cos^n \left( \frac{x}{\sqrt{n}} \right)
$$ I am not sure how to solve this using the limit theorem.","['central-limit-theorem', 'probability', 'limits', 'exponential-function']"
1309866,Topology on $\mathbb{R}$ strictly coarser (resp. finer) than the usual one which is still Hausdorff (resp. connected),"The following are simple observations. Suppose $\mathcal{T}_1,\mathcal{T}_2$ are two topologies on a set $X$ such that $\mathcal{T}_1$ is finer than $\mathcal{T}_2$ . If $( X ,\mathcal{T}_2 )$ is Hausdorff, then so is $( X ,\mathcal{T}_1 )$ . If $( X ,\mathcal{T}_1 )$ is connected,  then so is $( X ,\mathcal{T}_2 )$ . The real numbers with the usual topology is both Hausdorff and connected, which leads to the following two questions. Is there a topology on the real numbers strictly coarser than the usual one, which makes it still Hausdorff? Is there a topology on the real numbers strictly finer than the usual one, which makes it still a connected space?","['separation-axioms', 'examples-counterexamples', 'connectedness', 'general-topology']"
1309901,Cardinality of all subsets of cardinality $\aleph_0$ or $\aleph$ in $\mathbb{R}$,"What is the cardinality of all subsets of cardinality $\aleph_0$ in $\mathbb{R}$?
And of all subsets of cardinality $\aleph$ in $\mathbb{R}$? Since both are subsets of $P(\mathbb{R})$ , I conclude both have cardinality less or equal to $2^{\aleph}$.
How to proceed from here?","['elementary-set-theory', 'cardinals']"
1309925,Bergman space. What is area measure?,"I have read that the Bergman space $A^p(\Omega)$ consist of all the analytic functions $f$ in $\Omega$, such that 
$$
\left( \int_{\Omega} |f(z)|^p dA \right)^{1/p} < \infty
$$
where $dA$ is the area measure. I am very confuse with what area measure means, I haven't took measure theory yet, my intuition says that 
$$
\int_{\Omega} |f(z)|^p dA = \iint_{\Omega}|f(x+iy)|^p dxdy 
$$
Is this right ?? If not how can I compute an integral with $dA$? How about now if $dA_w$ is the weighted area measure?","['bergman-spaces', 'area', 'functional-analysis', 'measure-theory']"
1309948,Total number of divisors of factorial of a number,"I came across a problem of how to calculate total number of divisors of factorial of a number. I know that total number of divisor of a number  $n= p_1^a p_2^b p_3^c $ is $(a+1)*(b+1)*(c+1)$ where $a,b,c$ are the powers of a number $n$ and $1<n<100000$. But how to calculate total number of divisiors for $n!$","['prime-factorization', 'number-theory', 'algebra-precalculus', 'elementary-number-theory', 'factorial']"
1309966,Work of Ted Kaczynski,"I hope this question is not too crazy sounding, but I was wondering if anyone is familiar with the work of Ted Kaczynski (or even has cited/used it before).
After reading in Lars Ahlfors' Complex Analysis and Serge Lang's book by the same name, I became interested in some of the historic results in complex analysis. I know that Kaczynski did work in the field of complex analysis and specifically geometric function theory. From what I have gathered, he was actually rather brilliant as a research mathematician. What in specific did he research and how are his results used today? (If at all). Again, I do not want to know about his political views or his history as the Unabomber. I am only interested in the utility of his mathematics.","['math-history', 'complex-analysis', 'soft-question']"
1309976,"If $Z=\frac{1}{\partial_{x}^{2}+\partial_{x}\partial_{y}-12\partial_{y}^{2}}.y e^{3x+y}$, what is $Z$?","If: $$Z=\frac{1}{\partial_{x}^{2}+\partial_{x}\partial_{y}-12\partial_{y}^{2}}y e^{3x+y}$$ Then what is $Z$? I know that: $$\frac{1}{\partial_{x}^{2}+\partial_{x}\partial_{y}-12\partial_{y}^{2}}y e^{3x+y}=e^{3x+y}\frac{1}{(\partial_{x}+3)^{2}+(\partial_{x}+3)(\partial_{y}+1)-12(\partial_{y}+1)^{2}}y $$ but I don't know the value of:
$$\frac{1}{(\partial_{x}+3)^{2}+(\partial_{x}+3)(\partial_{y}+1)-12(\partial_{y}+1)^{2}}y$$ Is there a general way to find the value of equations of the form: $$\frac{1}{\phi(\partial_{x},\partial_{y})}f(x,y)?$$ The answer is actually $Z=e^{3x+y}{\frac{1}{98 }(21 x^3 - 8 x + 14 x y)}$","['partial-derivative', 'ordinary-differential-equations', 'partial-differential-equations']"
1310009,Subsheaf generated by one section is coherent,"I'm working on exercise II.5.15 in Hartshorne's book. I need to prove the following bit. Let $ X $ be a noetherian scheme. Let $\mathscr {F }$ be a quasi coherent sheaf on $ X$. Then the subsheaf $ \mathscr{G}\subset\mathscr{F}$ generated by $s\in \mathscr{F}(X)$ is coherent. One idea I have is to show that $ \mathscr{G}(V)=\mathcal{O}_{X}(V)s$. I'm unable to prove that the gluing axiom of sheaves in this case. This answer explains the idea of a subsheaf generated by sections. However, the definition is nonconstructive and I don't see a way to use it: Some question of sheaf generated by sections As a bonus, can we generalise this question to finitely many sections?","['algebraic-geometry', 'sheaf-theory']"
1310054,"For which values of $p,q$ does the integral $\int_0^1 x^p (\ln\frac{1}{x})^qdx$ converge?","For which values of $p,q$ does the integral $\int_0^1 x^p (\ln\frac{1}{x})^qdx$ converge? I use the substitution $t=1/x$ to obtain this better looking integral: $\int_1^\infty \frac{(\ln t)^q}{t^{p+2}}$ . Integration by parts gives me a recurence formula for the integral, but $p,q$ are not necessarily integers so I don't think that's the right approach.","['calculus', 'improper-integrals']"
1310060,Interesting Array of Integers with Strange Pattern,"I was experimenting and I found this pattern: Start with an (infinite) array with top row with all ones, and leftmost two columns also all ones. $$
        \begin{matrix}
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$ Then, to find the columns, starting from the top row, add numbers on the diagonal to the left: $$
        \begin{matrix}
        1 & \color{blue}{1} & \color{blue}{1} & 1 & 1 & 1 & 1 & 1 & \cdots \\
        \color{blue}{1} & 1 & \color{blue}{1+1} & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & ? & ? & ? & ? & ? & ? & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$
After this step, replace the numbers below the last one like this:
$$
        \begin{matrix}
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$ Repeat: $$
        \begin{matrix}
        1 & 1 & \color{red}{1} & \color{red}{1} & 1 & 1 & 1 & 1 & \cdots \\
        1 & \color{red}{1} & 2 & \color{red}{1+1} & ? & ? & ? & ? & \cdots \\
        \color{red}{1} & 1 & 2 & \color{red}{1+1+1} & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & ? & ? & ? & ? & ? & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$ Replace: $$
        \begin{matrix}
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & \cdots \\
        1 & 1 & 2 & 2 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$ Repeat: $$
        \begin{matrix}
        1 & 1 & 1 & \color{blue}{1} & \color{blue}{1} & 1 & 1 & 1 & \cdots \\
        1 & 1 & \color{blue}{2} & 2 & \color{blue}{1+2} & ? & ? & ? & \cdots \\
        1 & \color{blue}{1} & 2 & 3 & \color{blue}{1+2+1} & ? & ? & ? & \cdots \\
        \color{blue}{1} & 1 & 2 & 3 & \color{blue}{1+2+1+1} & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & ? & ? & ? & ? & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$ Replace: $$
        \begin{matrix}
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & \cdots \\
        1 & 1 & 2 & 2 & 3 & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & 4 & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & 5 & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & 5 & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & 5 & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & 5 & ? & ? & ? & \cdots \\
        1 & 1 & 2 & 3 & 5 & ? & ? & ? & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$ I guess you get the idea now. So after filling in the array, I got: $$
        \begin{matrix}
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & \cdots \\
        1 & 1 & 2 & 2 & 3 & 3 & 4 & ? & \cdots \\
        1 & 1 & \color{red}{2} & 3 & 4 & 5 & 7 & ? & \cdots \\
        1 & 1 & 2 & \color{red}{3} & 5 & 6 & 9 & ? & \cdots \\
        1 & 1 & 2 & 3 & \color{red}{5} & 7 & 10 & ? & \cdots \\
        1 & 1 & 2 & 3 & 5 & \color{red}{7} & 11 & ? & \cdots \\
        1 & 1 & 2 & 3 & 5 & 7 & \color{red}{11} & ? & \cdots \\
        1 & 1 & 2 & 3 & 5 & 7 & 11 & \color{red}{?} & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$ So it looks like the numbers on the diagonal might be the prime numbers. But computing the next column destroys this hope: $$
        \begin{matrix}
        1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & \cdots \\
        1 & 1 & 2 & 2 & 3 & 3 & 4 & 4 & \cdots \\
        1 & 1 & \color{red}{2} & 3 & 4 & 5 & 7 & 8 & \cdots \\
        1 & 1 & 2 & \color{red}{3} & 5 & 6 & 9 & 11 & \cdots \\
        1 & 1 & 2 & 3 & \color{red}{5} & 7 & 10 & 13 & \cdots \\
        1 & 1 & 2 & 3 & 5 & \color{red}{7} & 11 & 14 & \cdots \\
        1 & 1 & 2 & 3 & 5 & 7 & \color{red}{11} & 15 & \cdots \\
        1 & 1 & 2 & 3 & 5 & 7 & 11 & \color{red}{15} & \cdots \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
        \end{matrix}
$$ Writing out this sequence: $$2, 3, 5, 7, 11, 15, \cdots $$ So my question is, what is this sequence, that mirrored the primes but then suddenly diverged?","['arithmetic', 'matrices']"
1310061,Cardinality of equivalence relations in $\mathbb{N}$,"I came across this long proof on this site: Cardinality of relations set But I would like to know whether my direction can work. Say we want to find the cardinality of all equivalence relations in $\mathbb{N}$. Since it is a subset of all relations in $\mathbb{N}$, I conclude it has a cardinality smaller or equal to $\aleph$. Now, define an injective function from $P(\mathbb{N})$ to the set of equivalence relations by matching each subset of $\mathbb{N}$ with the identity relation (which is an equivalence relation in $\mathbb{N}$. Therefore the cardinality of all equivalence relations in $\mathbb{N}$ is greater or equal to $\aleph$ and using CSB we get the desired result. Seems legit?","['elementary-set-theory', 'equivalence-relations', 'cardinals']"
1310079,Using linear algebra (e.g. matrix) methods to solve a system of linear inequalities,"Say we have the equation $Ax>b$, where $A$ is an M -by- N matrix, $b$ is a known vector of length N , x is an unknown vector of length N , and the inequality sign means that each element of $Ax$ is greater than the corresponding element of $b$. Is there some linear-algebra-based method, such as e.g. some modification of LU decomposition or something similar, that would be amenable to programming on a computer and which would allow me to generically solve this system for $x$, given numerical values for $A$ and $b$? I will also accept any method of determining merely whether a solution exists, if not any solutions themselves. EDIT: I should clarify that I'm mainly working with matrices with N and M both less than 10, so an exact method that works analogously to e.g. LU decomposition will probably be faster than an iterative method.","['systems-of-equations', 'linear-programming', 'numerical-linear-algebra', 'linear-algebra', 'inequality']"
1310087,${n \choose m}$ on periodic lattice (Bravais),How can I generate all symmetry-inequivalent selections of m sites on a periodic 2d (Bravais) lattice with n sites? Are there some general results or theorems which may be useful in this type of problem?,"['algorithms', 'abstract-algebra', 'group-theory', 'discrete-mathematics']"
1310105,Proving $|\mathbb{R}-\mathbb{S}|=2^{\aleph_0}$ when $\mathbb{S}\subset R$ is countable [duplicate],"This question already has answers here : Does $k+\aleph_0=\mathfrak{c}$ imply $k=\mathfrak{c}$ without the Axiom of Choice? (3 answers) Closed 9 years ago . I wish to prove that $|\mathbb{R}-\mathbb{S}|=2^{\aleph_0}$ when $\mathbb{S}\subset \mathbb{R}$ is countable. I want to say that $|\mathbb{R}-\mathbb{S}|= |\mathbb{R}|-|\mathbb{S}|$ but we haven't studied yet what subtraction of cardinals means (I can guess, though). How could I prove this using only basic cardinal properties?","['elementary-set-theory', 'cardinals']"
1310128,Lower bounding the eigenvalue of a matrix,"Suppose I have the following symmetric matrix 
$$
A'=\begin{bmatrix}
A + b b^T & b \\
b^T & 1
\end{bmatrix}
$$
where $A$ is positive definite $n \times n$ symmetric matrix and $b$ is a $n \times 1$ vector. Suppose $\|b\|_2 \leq B_1$, and all eigenvalues of $A$ are between $[B_2, B_3]$. What is a bound in terms of $B_1$, $B_2$, and $B_3$ for the smallest eigenvalue of $A'$? (It is straight forward to show that $A'$ is positive definite.)","['eigenvalues-eigenvectors', 'matrices']"
1310179,"General form of ""Variation of Parameters""","Recently I found out about the method to solve differential equations called ""variation of parameters"". However, I have only seen the form of this method for 2$^{nd}$ order DEs, namely $$u_1'y_1+u_2'y_2=0$$
$$u_1'y_1'+u_2'y_2'=\frac {Q(x)}{a_2}$$ My question is: Is there a general form for variation of parameters for the general n$^{th}$ order differential equation?",['ordinary-differential-equations']
1310216,$a^2=b^3+bc^4$ has no solutions in non-zero integers [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question this problem is from number theory book , $$a^2=b^3+bc^4$$
has no  solutions in non-zero integers This book hint ：First show that $b$ must be a perfect square.and how to do?",['number-theory']
1310230,Does $IJ=IK\implies J=K$ always hold for integral domain and finitely generated nonzero ideal $I$?,"Let $R$ be a commutative integral domain, $I,J,K$ three ideals of $R$ with $I\neq (0)$ being finitely generated. Then does $IJ=IK$ imply $J=K$? With Nakayama lemma, I can prove it if one of $J$ and $K$ equals to $R$. And I also know it holds when $R$ is a Prüfer domain or $I$ is singly generated.","['abstract-algebra', 'commutative-algebra', 'integral-domain', 'ring-theory']"
1310233,Motivation of Lebesgue differentiation theorem,"Fundamental theorem of calculus states that the derivative of the
integral is the original function, meaning that
$$
f(x)=\frac{d}{dx}\int_{a}^{x}f(y)dy.\tag{*}
$$
To motivate the statement of the Lebesgue differentiation theorem, observe
that (*) may be written in terms of symmetric differences as
$$
f(x)=\lim_{r\to 0^+}\frac{1}{2r}\int_{x-r}^{x+r}f(y)dy.\tag{**}
$$
An $n$-dimensional version of (**) is
$$
f(x)=\lim_{r\to 0^+}\frac{1}{|B(x,r)|}\int_{B(x,r)}f(y)dy.\tag{***}
$$ where the integral is with respect $n$-dimensional Lebesgue measure. The Lebesgue differentiation theorem states that (***) holds pointwise $\mu$-a.e. for any locally integrable function $f$. My question is how could we write (**) by using (*) ? If we define $F(x)=\int_{a}^{x}f(y)dy$. The quotient 
$$
\frac{F(x+r)-F(x)}{r}=\frac{\int_{a}^{x+r}f(y)dy-\int_{a}^{x}f(y)dy}{r}=\frac{1}{r}\int_{x}^{x+r}f(y)dy
$$
How could we say that 
$$\frac{1}{r}\int_{x}^{x+r}f(y)dy\overset{?}{=}\frac{1}{2r}\int_{x-r}^{x+r}f(y)dy$$","['analysis', 'calculus', 'real-analysis']"
1310245,Help in finding the Jordan canonical form of a matrix,"Determine the Jordan Canonical Form of the following matrix: 
$$A=\begin{bmatrix}
 1 & 2 & 3\\
 0 & 4 & 5\\
 0 & 0 & 4\\ \end{bmatrix}$$ I am trying to determine the Jordan Basis first. For that purpose I am trying to find out the generalized Eigenvectors of this matrix. Corresponding to $1$, Let $U_1$ be the generalized eigenspace. My calculations show that $$U_1=span\{(1,0,0)^t\}$$ and $U_2$ be the corresponding generalized eigenspace for $4$. I found out $$U_2=span\{(1,0,-9)^t,(0,1,6)^t\}$$All I need to do now is find the Jordan basis. Since $(A-\lambda_i I)|_{U_i  }$ is nilpotent, all I need to do is find the basis for each such $i$. I am confused from here on what to take as the jordan basis. I am sure that $(1,0,0)^t$ will feature as the first column. I am not sure about the other two. Thanks for the help!!","['jordan-normal-form', 'linear-algebra', 'matrices']"
1310266,"What does ""for all but finitely many $n$"" in the definition of limit inferior mean?","I am recently studying limit superior & limit inferior of sequence of subsets. Then I came across this phrase. What does this actually mean? I have understood ""for infinitely many $n$"" but am not understanding the above phrase. Can anyone help me explain what the phrase wants to convey?",['elementary-set-theory']
1310279,Is it true that this function $f(n)=n^{13}$?,"Assume strictly monotone increasing function;
   such that $f:N^{+}\to N^{+}$ , $h$ for all $n\in N^{+}$ , $$f(f(f(n)))=f(f(n))\cdot f(n)\cdot n^{2015}$$ Prove or disprove: $f(n)=n^{13}$ Put $n=1,f(1)=m$ $$f(f(m))=mf(m)$$ Put $n=m$ , $$f(f(f(m)))=f(f(m))f(m)m^{2015}\Longrightarrow f(mf(m))=m^{2016}(f(m))^2$$ What about following?","['contest-math', 'functional-equations', 'functions']"
1310398,Abstract Algebra: Every group has a cyclic subgroup,"I have to show that every group has a cyclic subgroup. I know what this means, and to me it is obvious, yet I am not sure how to formally write it. I proved it directly, as follows: Let $G$ be a group. Let $g$ be an element in $G$ . Let $o(g) = k$ , i.e., $g^k = e$ , for some integer $k$ , so by definition, $\langle g\rangle = \{e, g, g^2, \dots, g^{k-1}\}$ , therefore, for some $g\in G$ , the cyclic subgroup generated by $g$ is in fact a subgroup of $G$ . Would that be sufficient to prove the statement? Did I leave anything out, or should I mention anything else? New version of the proof: Let $G$ be a finite group. If $G = \{e\}$ , then $G = \langle e\rangle$ , i.e., cyclic. If $G\neq\{e\}$ , then there exists $g\neq e$ , for $g\in G$ . Let $m$ be minimum positive integer s.t. $g^m = e$ . Then $g, g^2, \dots, g^m = e$ are distinct elements in $G$ generated by $g$ So $e, g, g^2, \dots, g^{m-1}$ form a cyclic subgroup $\langle g\rangle$ in $G$ .","['abstract-algebra', 'solution-verification', 'group-theory', 'cyclic-groups']"
1310401,"Associative, but non-commutative binary operation with a identity and inverse [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Can there really be an associative, but non-commutative binary operation with a identity and inverse?",['discrete-mathematics']
1310414,Stone Representation Theorem and Gelfand-Naimark-Segal Theorem?,"I just would like to know whethere Stone Representation Theorem http://en.wikipedia.org/wiki/Stone%27s_representation_theorem_for_Boolean_algebras has a direct connection (and if so, of what kind) with the Gelfand-Naimark-Segal Construction http://en.wikipedia.org/wiki/Gelfand%E2%80%93Naimark%E2%80%93Segal_construction They seem to me to share the same spirit, but I would be happy to hear more fro you about technicalities. Are they objects of the same family, so to speak? Thanks in advance.","['abstract-algebra', 'functional-analysis']"
1310423,Free group in GAP,"I know that in the free group $F$ with two generators $x$ and $y$, there is some word $w \in [F,F]$ such that $xy^2=x^{-2} y^{-3} x^{-2}(xy)^5 w$.
Is it possible to find $w$ using GAP?","['group-theory', 'gap', 'free-groups']"
1310429,How do you solve $f'(x) = f(f(x))$?,A friend told me to solve the following differential equation: $$f'(x)=f(f(x))$$ I have no idea how to solve this! This doesn't seem to be an ordinary differential equation and I can't even solve this numerically! I think my friend is trolling me.,"['ordinary-differential-equations', 'functional-equations']"
1310469,Finite function with infinite Lebesgue integral over any positive measure set,"Is there a measurable function $f:\mathbb{R}\rightarrow [0,\infty)$ such that 
$$\int_A f\, \mathrm{d}\lambda=\infty$$ for any (measurable) set $A\subseteq\mathbb{R}$ with $\lambda(A)>0$. ($\lambda$ is the Lebesgue measure)","['lebesgue-integral', 'lebesgue-measure', 'measure-theory', 'integration']"
1310490,Finding the Jordan Canonical form of a $6 \times 6$ matrix,"Find the Jordan Canonical Form of the following matrix $$\begin{bmatrix} 
1 & 0 & 0 & 0 & 0 & 0\\
1 & 1 & 0 & 0 & 0 & 0\\
1 & 0 & 1 & 0 & 0 & 0\\
1 & 0 & 0 & 1 & 0 & 0\\
1 & 0 & 0 & 0 & 1 & 0\\
1 & 1 & 1 & 1 & 1 & 1\\ \end{bmatrix}$$ My try: I go about finding the Jordan Basis for this matrix. It is clear that $1$ is the only eigenvalue of this matrix. So $$A-I=\begin{bmatrix}0 & 0 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 0 & 0 & 0\\
1 & 1 & 1 & 1 & 1 & 0\\ \end{bmatrix}$$ Moreover Rank$(A-I)^2=1$. Moreover Rank$(A-I)^3=0$ . So We don't need to go further on evaluating the powers of matrices in our search for generalized eigenvectors. 
$$(A-I)^2=\begin{bmatrix}0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & 0 & 0\\
4 & 0 & 0 & 0 & 0 & 0\\ \end{bmatrix}$$ Also $(A-I)^3=0$. It is seen that the generalized eigenspace (say $U$) consists of $U$=span$\{v_1=(0,1,0,0,0,0)^t,v_2=(0,0,1,0,0,0)^t,v_3=(0,0,0,1,0,0)^t,v_4=(0,0,0,0,1,0)^t,v_5=(0,0,0,0,0,1)^t\}$ Here I run into a little problem. Since $(A-I)v_i=v_5$ for each $i=1,2,3,4$, I have only five vectors with me for the Jordan Canonical Basis. Moreover I can't choose any other arbitrary vector linearly independent to these four simply because if $v$ were such a vector , then there is no $i \gt 0$ (and integer) such that $(A-I)v^{i}=0$ I have also another question here. Since $(A-I)^3=0$, why should I not choose general eigen vectors corresponding to $(A-I)^3$?? I am a little stuck here. Thanks for the help!!!","['jordan-normal-form', 'linear-algebra', 'matrix-decomposition', 'matrices']"
1310494,When we can change the sign of denominator,"Suppose $z=\frac{-x_1}{x_2-x_3}$, find $-z$. Which one is correct 
$$-z=\frac{x_1}{x_2-x_3}\ \ \ \text{or}\ \ \ -z=\frac{x_1}{-x_2+x_3}$$","['fractions', 'algebra-precalculus']"
1310511,Looking For a Neat Proof of the Fact that the Grassmannian Manifold is Hausdorff,"$\newcommand{\R}{\mathbf R}$
Let $V$ be an $n$-dimensional vector space and $k$ be an integer less than $n$. A $k$- frame in $V$ is an injective linear map $T:\R^k\to V$. Let the set of all the $k$-frames in $V$ be denoted by $F_k(V)$. It is clear that $F_k(V)$ is an open subset of $L(\R^k, V)$. Define a relation $\sim$ on $F_k(V)$ as follows: We write $S\sim T$ for two members $S$ and $T$ in $F_k(V)$ if and only if $\text{span }T=\text{span }S$. It can be easily seen that $S\sim T$ if and only if there is a $\tau\in GL_k(\R)$ such that $T=S\circ \tau$. The Grassmannian manifold $GR_k(V)$ is defined as the quotient space $F_k(V)/\sim$. I know that the projection map $\pi:F_k(V)\to GR_k(\R)$ is an open map. I am trying to prove that $GR_k(V)$ is a Hausdorff space. I proved the above by noting that the above statement is just this: Given linearly independent lists $(u_1, \ldots, u_k)$ and $(v_1, \ldots, v_k)$ in $V$ which do not span the same subspace, there are neighborhoods $U_i$'s of $u_i$'s and $V_j$'s of $v_j$'s such that whenever $(u_1',\ldots, u_k')\in U_1\times \cdots\times U_k$ and $(v_1',\ldots, v_k')\in V_1\times \cdots\times V_k$, the lists $(u_1', \ldots, u_k')$ and $(v_1', \ldots, v_k')$ are linearly independent and do not span the same subspace. I had a rather long proof of this. Basically I established that given hyperplanes $H$ and $K$ in $V$, there is a hyperplane $P$ in $V$ such that $P$ is ""between"" $H$ and $K$. I am looking for a more direct approach than recasting the problem in the aformentioned way. edit: Also, I am trying to avoid the use of matrices and coordinates as much as possible. Thanks. EDIT. I finally was able to put down the kind of proof I was looking for. Here it is.","['separation-axioms', 'general-topology', 'grassmannian', 'differential-geometry', 'quotient-spaces']"
1310518,Sampling distribution of sample trimmed (truncated) mean,"It is elementary probability theory that the sample mean of an i.i.d. sample follows normal distribution, if the background distribution is normal. But what about the trimmed mean? Is there any result on its distribution for an i.i.d. sample of size $n$ ? (For normal or general population distribution.) My only idea is to use the results for the distribution of order statistics (summing them, taking their non-independence into account), but it seems exceedingly complicated, perhaps there is an easier way... EDIT (2021-08-12): See the answer here .","['order-statistics', 'probability-distributions', 'statistical-inference', 'statistics', 'probability']"
1310540,What is the difference between the probability law of X and the distribution of X?,"I am a bit confused. The probability law regarding a random variable is defined as mapping $\mathcal{P} : \mathbb{B} \to [0,1]$, where $\mathbb{B}$ is the regular Borel set; that is, a probability law is an image measure. On the other hand, the probability distribution is $\mathbb{D} : \mathbb{R} \to [0,1]$, where $\mathbb{D}$ is defined as $\mathbb{D}(x) = P(\omega | X (\omega) < x)$. Although they are very similar, they are not equivalent, since the latter has a very specific structure, but, in the former, one can find the measure of any Borel set. Why, then, do a lot of texts informally claim that they are the, in fact, equivalent? It is clear that, for any measurable function, for example, a random variable, one can write its distribution using the probability law mapping, but, conversely, for example, assigning a probability measure to an arbitrary Borel set using the distribution function is not very clear to me. I have never taken a formal course on probability theory, so forgive me if this question seems too stupid, or does not make much sense.",['probability-theory']
1310541,integer as sum of three binomials,"Prove that for any nonnegative integer $n$ $\exists x,y,z \in \mathbb{N}$ and $0\leq x<y<z$ so
$$n=\binom{x}{1}+\binom{y}{2}+\binom{z}{3}$$ Please give me a hint, I don't have any idea.","['elementary-number-theory', 'combinatorics']"
1310544,I have a simple idea that I would like to make into a formula,"If I wanted to write one plus one, recurring, equals infinity.... Does this make sense? If so, how would it be written as a formula?","['sequences-and-series', 'notation']"
1310555,Showing that $\sqrt[105]{105}>\sqrt[106]{106}$,"How can one prove that $$\sqrt[105]{105}>\sqrt[106]{106}\text{ ?}$$
Induction on the statement $$\sqrt[n]{n}>\sqrt[n+1]{n+1} \text{ for } n \in \mathbb{N}| n>2$$ would yield $\sqrt[3]{3}>\sqrt[4]{4}$ at the base step $n=3$, which we cannot assume. So, based on the properties of powers and square roots alone, can we prove the first statement? EDIT: No calculus, no functions, not even logs. It's more of a riddle that anything else.","['number-comparison', 'algebra-precalculus', 'inequality']"
1310562,Bootstrap method failing where blocking works,"I'm computing an average of individual samples that are not entirely independent and need an estimate for the true standard deviation. According to Newman and Barkema's book the most reliable method will be Bootstrap sampling (see section 3.4.3), where you don't have to worry about the samples being independent and which should give an estimate of the standard deviation of the mean $\sigma_m\approx\sigma\ /\sqrt{n}$ where $n$ is the number of samples. However I proceed to compute the average a number of times so that I get a brute force estimate of the actual $\sigma_m$, and it turns out that the bootstrap is consistently underestimating this. In itself that is maybe not so strange; the bootstrap being an estimate. But the weird thing is that if I use the blocking (or binning) method (see 3.4.2) I get a much better estimate - while according to Newman and Barkema this should be a much more primitive method. In fact the bootstrap consistently gives an estimate very close to the naive $\sigma_m\approx\sqrt{\big(\ \overline{x^2}-\overline{x}^2\ \big)\ /\ n}$. Any idea what's going on?","['means', 'monte-carlo', 'statistics', 'standard-deviation']"
1310589,Volume integral in $R^3$,"Compute the volume of the body defined by the inequalities $$x^2+y^2 \leq 4x, \, |z| \leq x^2+y^2 \\$$ I write the first inequality as $(x-2)^2+y^2 \leq 4$ so it is a disk with radius $2$ and centrum in $(2,0)$. The second inequality is a paraboloid but I don't see how the absolute value of $z$ affects the figure. If $z^+ \leq x^2+y^2$ then $z^- \leq z^2+y^2$ so I don't see the difference it makes. Also, what method is preferable when computing this type of body? As a difference between two double integrals?",['multivariable-calculus']
1310609,Avoiding the Cayley–Hamilton theorem [duplicate],"This question already has answers here : Degree of minimum polynomial at most $n$ without Cayley-Hamilton? (4 answers) Closed 8 years ago . Every $n\times n$ matrix satisfies a polynomial equation of degree at most $n^2$, simply because the space of $n\times n$ matrices has dimension $n^2$. By the Cayley–Hamilton theorem, every matrix satisfies a polynomial equation of degree $n$. Is there a simple proof that every matrix satisfies a polynomial equation of degree at most $n$ without using the Cayley–Hamilton theorem?","['linear-algebra', 'matrices']"
1310657,"Clarify: ""$S^0$, $S^1$ and $S^3$ are the only spheres which are also groups""","The zero, one, and three dimensional spheres $S^0$, $S^1$ and $S^3$ are in bijection with the sets $\{a\in \mathbb{K}:|a|=1\}$ for $\mathbb{K} = \mathbb{R}, \mathbb{C}, \mathbb{H}$ respectively.
The real, complex and quaternionic multiplication therefore provide a group operation on these spheres. This is mentioned in the book: Kristopher Tapp (2011), Matrix Groups for Undergraduates, Indian Edition, pp. 40. Following this there is a statement: It turns out that $S^0$, $S^1$ and $S^3$ are the only spheres which are also groups. Can someone please clarify this statement?
How are these three the only spheres which are also groups? For example, I could take any sphere $S^k$ ($k\ge 1$) and get a bijection $f:S^k \to S^1$ and define a binary operation on $S^k$ by $$a*b = f^{-1}(f(a)\cdot f(b))$$
and $S^k$ would be a group under this operation. So what exactly is meant by the above statement? In what sense are these the only three spheres which are also groups?","['real-numbers', 'quaternions', 'complex-numbers', 'group-theory', 'spheres']"
1310688,Is it possible to have an $n\times n$ real matrix $A$ such that $A^TA$ has an eigenvalue of $-1$?,"Question: Is it possible to have an $n\times n$ real matrix $A$ such that $A^TA$ has an eigenvalue of $-1$? I can prove that it is not possible for $n=1,2$, but I am not sure for the general case. Case $n=1$: $a^2v=-v$ $\implies$ $(a^2+1)v=0$ $\implies$ $v=0$. Case $n=2$: Write $A=\begin{pmatrix}a&b \\ c&d\end{pmatrix}$. Then, $A^T A=\begin{pmatrix}a^2+c^2&ab+cd\\ ab+cd&b^2+d^2\end{pmatrix}$, so
$$
\begin{align}
\det(A^TA+1) 
&= \begin{vmatrix}a^2+c^2+1&ab+cd\\ ab+cd&b^2+d^2+1\end{vmatrix}\\
&= 1+a^2+b^2+c^2+d^2+(ad-bc)^2\\
&\neq 0.
\end{align}
$$
Now, can we generalize to all $n$?","['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1310694,Joint distribution of degrees of Erdös Renyi random graph,"The marginal degree distribution of any particular vertex is $$Bin(n-1,p)$$ in an Erdös Renyi random graph G(n,p) . Denoting the degrees of the n vertices as d1 , d2 ,..., dn , can you please let me know what the joint distribution of d1 , d2 ,..., dn would be?","['discrete-mathematics', 'random-graphs', 'probability-distributions', 'combinatorics']"
1310735,"In the space of probability distributions, is the set of discrete distributions dense?","Is the following true: In the space of probability distributions, the set of discrete  distributions is dense with regard to the Lévy metric. Can someone point me to any reference on this subject?","['probability-theory', 'probability-distributions', 'metric-spaces', 'functional-analysis', 'general-topology']"
1310760,"Is this correct $(\cot x)(\sin x)=2(\cot x)^2$ $0≤x≤2\pi$ $x= \pi/2 , 3\pi/2$ $1.4371774 , 5.139467567$","Steps I took: $$\cot x \sin x=2\cot^2 x$$
$$\cot x \sin x-2\cot^2 x=0$$
$$\cot x (\sin x-2\cot x)=0$$
$$\cot x \left(\frac{\sin^2 x}{\sin x} -2\frac{\cos x}{\sin x} \right)=0$$
$$\cot x \left(\frac{\sin^2 x-2\cos x}{\sin x} \right)=0$$
$$\cot x \left(\frac{1-\cos^2 x-2\cos x}{\sin x} \right)=0$$
$$\cot x \csc x (\cos x+2.414213562)(\cos -0.4142135624)=0$$
$$\cot x =0 \rightarrow x=\frac{\pi}{2},\frac{3\pi}{2}$$
$\csc x$ cannot be $0$
$\cos x$ cannot be $-2.414213562$
$$\cos x = 0.4142135624$$
$$x=1.4371774 , 5.139467567$$",['trigonometry']
1310767,Solve $A = (B+C)\cdot \sin(2\cdot \tan^{-1}(C/D))$ for $C$ algebraically,"I came across this equation while working out how to hang a rising gate by offsetting one hinge. $$A = (B + C) \cdot \sin(2 \cdot \tan^{-1}(C / D))$$ I know A, B and D and have to find C. Having no idea how to approach an algebraic solution, I implemented a successive approximation numerical solution, which converges very well. However, I'd like to know if there is any way to start solving this algebraically, where C is used both inside and outside the trig functions. How could I begin? For the curious, the working to reach this point, and the finished rising gate calculator, are here .",['trigonometry']
1310808,How to write R program to solve the confidence interval?,"The problem: let $X_1,\ldots,X_n$ be random variable from $\mathrm{Poisson}(\theta)$. Under $H_0: \theta=\theta_0$, we want to find the $(1-\alpha)100\%$ confidence interval for $\theta$ by using the likelihood ratio interval, $-2\ln\lambda(x)$.  Now, I have $$1-\alpha = P\{2n[(\theta-\bar{X})-\bar{X} \ln(\theta/\bar{X})] \leq \chi^2_{0.05,df.=1}\}$$ where $2n[(\theta-\bar{X})-\bar{X}\ln(\theta/\bar{X})]$ has chi-square distribution with df. one for large sample size. This is not a formula for the upper limit of $\theta$. Thus I must use the R program to solve it but I have no idea. Please suggest me how to do and for improve my work. Thanks.","['statistics', 'statistical-inference']"
1310818,Non-compact complex manifolds which are not Stein,"I am studying Stein manifolds, and it is clear for me that compact complex manifolds can not be Stein for obviously reasons. On the other hand, there exists some non-compact complex manifolds which are not Stein, otherwise every non-compact complex manifolds is Kähler. Does anyone know of some explicit examples of non-compact complex surfaces which are not Stein? In general non-compact non-Kähler manifolds are not Stein; but I do not know any explicit examples.","['complex-geometry', 'differential-geometry', 'complex-manifolds', 'kahler-manifolds']"
1310821,"Two more questions on Kontsevich's ""Noncommutative Identities"" (Derivations on $\mathbb{C}\langle X,Y \rangle$) [Solved]","The following two questions regard once more the following article: arXiv:1109.2469 . In the second chapter we are dealing with the Lie Algebra $\mathfrak{g}$ of derivations $\delta$ of $\mathcal{A}:=\mathbb{C}\langle X,Y \rangle$ satisfying the properties $(1)$ $\delta(X)=[D,X]$ for some $D\in \mathcal{A}$ $(2)$ $\delta(Y)=0$ $(3)$ For all $t\in\mathbb{C},\  \exists D_t\in\mathcal{A}[t]$ s.t. $\delta(X+tY) \bigg(=\delta(X)\bigg)=[D_t,X+tY]$. He then claims that: $(i)$ a linear basis for $\mathfrak{g}$ is given by:
$$\delta_{n,m}=[c_{n,m},X], \ \delta_{n,m}(Y)=0 \quad n\ge0, m\ge1$$
where for any $n,m\ge0$ we define:
$$c_{n,m}:=\sum_{{n+m \choose n} \text{ shuffles } w}w$$
i.e. the sum of all words in $X,Y$ containing $n$ letters $X$ and $m$ letters $Y$.
Elements $D_t\in\mathcal{A}$ corresponding to the derivation $\delta_{n,m}$ are given by
$$D_t=\sum_{0\le k\le n}c_{n-k,m+k}t^k$$ EDIT [09.06] Solved, see below $(ii)$ $\mathfrak{g}$ is commutative EDIT [13.06] Solved, see answer. My ""progress"": (i) So far I've only been able to prove that the above tuples $(\delta_{n,m},D_{n,m})$ are indeed elements of $\mathfrak{g}$, and in the argumentation I've shown that $$[c_{l-1,r+1},X]= [Y,c_{l,r}].$$ Then my try goes on like: Let now $\sigma\in \mathfrak{g}$ be any (non trivial) element. We decompose the associated $D$ in its homogeneous components $D_{n,m}$ where $n$ indicates the number of $X$'s and ditto $m$ for $Y$. We do this because no cancellation can take place between terms in which these do not match, when evaluating the lie Bracket $[D,X]$, so we can work with each of these components separately. So let $D_{n,m}$ be a non zero homogeneous component of $D$. We claim that:
$$D_{n,m}=\lambda \cdot c_{n,m} \quad \lambda \in \mathbb{C}.$$
Assume not, then, up to removing the homogeneous components, we have that there must be at least one missing homogeneous polynomial. We will show that this will lead to a contradiction to the existance of a $D_t$ of the desired form. Let $D_t:=\sum_{k\ge0}^N w_kt^k$, where $w_k$ is just some sum of words in $X$ and $Y$ as always, be a generic candidate. Do to the definition of the lie algebra, we ask ourselves which property must $D_t$ have to be able to satisfy the given equation: \begin{align*} [D_{n,m},X] & = [D_t,X+tY] = \left[\sum_{k=0}^N w_kt^k,X+tY\right]\\
& = [w_0,X]+\sum_{k=0}^{N-1}([w_{k+1},X]+[w_k,Y])t^{k+1}+[w_N,Y]t^{N+1}\end{align*}
Since the field we are working on is infinite, and since the term on the left hand side is of degree 0 and has trivial centralizer, we see that two straightforward conditions which must be satisfied are:
$$w_0-D_{n,m}=\sum_{k=0}^M \alpha_k X^k \ \text{and} \ w_N=\sum_{k=0}^M \beta_k Y^k \quad \alpha_k,\beta_l \in \mathbb{C} $$ $$[\dots]$$ EDIT [09.06] I've solved this part. One just needed to start from the $w_N=\sum_{k=0}^M \beta_k Y^k$ term, reduce to the case $\beta_k=\delta_{ik}$ and then using the previous result we get the claim. $(ii)$ My try: Since we have found a basis and because of the Leibniz property our task reduces to show the following:
$$\forall k,m\ge 0; n,l\ge 1 : \quad [\delta_{n,m},\delta_{k,l}]\equiv 0 \iff [\delta_{n,m},\delta_{k,l}](X)=0 \text{ and } [\delta_{n,m},\delta_{k,l}](Y)=0$$
Clearly the second equality is a direct consequence of the definition of the $\delta$'s.
For the first equality one needs to work a little bit more: $$[\delta_{n,m},\delta_{k,l}](X) = [\text{ some manipulations... }]= [X,\delta_{k,l}(c_{n,m})-\delta_{n,m}(c_{k,l})-[c_{n,m},c_{k,l}]]$$ I've now checked computationally that the the expression in the right hand side of the Bracket is zero for a few values of $(k,l),(n,m)$; but how to prove this in general? EDIT [13.06] Solved, see answer. Any help is greatly appreciated! Many thanks in advance","['noncommutative-algebra', 'lie-algebras', 'combinatorics']"
