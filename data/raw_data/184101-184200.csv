question_id,title,body,tags
3378844,Applications of Jordan-Holder theorem in an abelian category,"The Jordan-Holder theorem says that any chain of subobjects of a finite lenght object can be refined to a composition series, and that any composition series has the same lenght. This theorem holds for any abelian category, and a notable example is the case of modules over some ring. While I do not need an example of the usefulness of J-H theorem in the context of modules, I would like to ask: What are applications of the J-H theorem in a general abelian category,
  which is not (or not easily proven to be) a category of modules?","['homological-algebra', 'category-theory', 'modules', 'abstract-algebra', 'abelian-categories']"
3378883,"Given sequence of 7-digit positive numbers: $a_{1},...,a_{2017}$ with $a_{1}<a_{2}<...<a_{2017}$. Determine $a_{2017}$.","Given a sequence of 7-digit positive numbers: $a_{1},a_{2},...,a_{2017}$ with $a_{1}<a_{2}<...<a_{2017}$ . The digit is ordered such that it is nonincreasing. It is known that $a_{1}=1000000$ and $a_{n+1}$ is the smallest possible number that is greater than $a_{n}$ . 
This means $a_{2}=1100000$ and $a_{3}=1110000$ . Determine $a_{2017}$ . Attempt: Let us define $a_{0}=0000000$ and present the terms for $n=1,2,...,20$ , $$ a_{1} = 1000000, a_{2} = 1100000, a_{3} = 1110000, a_{4} = 1111000, a_{5} = 1111100$$ $$ a_{6} = 1111110, a_{7} = 1111111, a_{8} = 2000000, a_{9} = 2100000, a_{10} = 2110000$$ $$ a_{11} = 2111110, a_{12} = 2111111, a_{13} = 2200000, a_{14} = 2210000, a_{15} = 2211000$$ $$ a_{16} = 2211100, a_{17} = 2211110, a_{18} = 2211111, a_{19} = 2220000, a_{20} = 2221000$$ We can analyse that the number of sequence that has $1$ as leading digit is $\binom{7}{1} = \binom{6+1}{1}$ . 
Also the number of sequence that has 2 as leading digit is $\binom{6+2}{2}$ . 
In general, the number of sequence that has $j >= 1$ as leading digit is $\binom{6+j}{j}$ . The number of sequence that has leading digit $1,2,..,m$ is therefore: $$ \alpha_{m} = \sum_{j=1}^{m} \binom{6+j}{j}$$ Which means that $a_{\alpha_{m}}$ is the last sequence that has $m$ as leading digit. We can find the simplified form for each $\alpha_{m}$ . We will prove that $$ \alpha_{m} = \sum_{j=1}^{m} \binom{6+j}{j} = \sum_{j=1}^{m} \binom{6+j}{6} $$ $$ = \binom{7}{6} + \binom{8}{6} + \binom{9}{6} + ... + \binom{6+m}{6} = \binom{7+m}{7} - 1$$ We can see $\binom{7+m}{7}$ as the number of ways to pick 7 numbers from the set $\{1,2,...,7+m\}$ . 
But the list can be grouped as, the choice(s) that has $1$ as minimum number, $2$ as minimum number, and so on. These means that $$ \binom{7+m}{7} = \binom{7+m-1}{6} + \binom{7+m-2}{6} + ... + \binom{7+m-m}{6} + \binom{7+m-(m+1)}{6} $$ $$ \binom{7+m}{7} = 1  + \sum_{j=1}^{m} \binom{6 + j}{6} $$ Thus $\alpha_{m}= \sum_{j=1}^{m} \binom{6 + j}{6} = \binom{7+m}{7} - 1$ . Let us check what value of $m$ such that $\alpha_{m-1} \le 2017 \le \alpha_{m}$ . $m$ is $7$ , $$ \alpha_{m-1} = 1715 \le 2017 \le \alpha_{m}=3431 $$ So the leading digit of $a_{2017}$ must be $7$ . The first sequence with leading 7 is $a_{1716}$ . How about the 2nd digit? The number of 6 digits sequence leading 1,2,..,5 is $\binom{6+5}{6} - 1 = 461$ , with leading 1,2,..,4 is $209$ . 
Now because $1715 + 209 < 2017 < 1715 + 461$ , then we can conclude that the 2nd digit must be a 5. We can continue doing this until we find that $a_{2017}=75$ *****. Are there better or quicker approaches?","['contest-math', 'combinatorics', 'problem-solving']"
3378887,Prove $\lim_{n \to \infty} |\cos (nx)|^{\frac{1}{n} }= 1$ for almost every $x \in \mathbb{R}$,"don't know how to proceed with this. 
my thought: if there exist some $n_0, k_0 \in \mathbb{Z}, x_0 \in \mathbb{R}$ such that $n_0 x_0= \frac{\pi}{2}+k_0\pi $ , then there exist countable sequence $\{(n_i,k_i)\}$ such that $n_i x_0= \frac{\pi}{2}+k_i\pi $ , so the limit doesn't exist at $x_0$","['limits', 'measure-theory', 'real-analysis']"
3378906,"How to find a $c \in \mathbb [a, b]$ such that $f(c) = [f(x_1) + f(x_2) + ... + f(x_n)] / n$?","So suppose I have a continuous function on, say, $[a,b]$ with $x_1, x_2, ..., x_n \in [a, b]$ . I want to prove that there exists a $c \in [a, b]$ such that $f(c) = [f(x_1) + f(x_2) + ... + f(x_n)] / n$ . I thought about using mathematical induction at first for n. In this case, $n = 1$ is trivial since $f(x_1) = f(x_1)$ . But then I need to begin with $n = 2$ , as in finding a $c \in [a, b]$ such that $f(c) = [f(x_1) + f(x_2)]/n$ . However, all the theorems I've tried so far don't seem to work. For instance, the Bolzano Intermediate Value Theorem doesn't work since there is a possibility that $f(b) \lt [f(x_1) + f(x_2)]/n$ or $[f(x_1) + f(x_2)]/n \lt f(a)$ . I'm very stuck on this and I'm not sure where to begin. Any help would be much appreciated.","['continuity', 'functions', 'real-analysis']"
3378911,"How to cure ""I don't appreciate Lebesgue integration because I was taught Riemannian integration throughout university""","I was a physics major with applied computation EM background and throughout university I was only taught Riemannian integration. Every textbook I have read used Riemannian integrals (almost by default assumption). No measure theory were ever introduced. Only in grad school did I finally learn Lebesgue integration. But I cannot really appreciate all these beautiful theorems, etc. that can be done using Lebesgue integration because I have to teach other people using textbook written by authors who relies on Riemannian integral by default Many computation software packages seem to have built upon Riemannian integration by default. Too much overhead with Lebesgue integration. I feel like I always have to introduce measure theory (and getting all the miscellaneous technical things) to someone before I can talk about it. At the end of the day, if I were to calculate something, like flux through a plane, or anything involving complex contour integrals, I feel like I have to resort back to Riemannian integration (and the textbooks that base off of it) Is there anything that can be done in this situation for me to appreciate Lebesgue integration theory?","['integration', 'lebesgue-integral', 'math-software', 'physics', 'soft-question']"
3378943,Ways of choosing $n$ objects out of $3n$ objects,"Prove that the number of combinations of $n$ objects out of $3n$ objects in which $n$ are of one kind, $n$ of the other kind and rest $n$ are distinct is $(n+2)2^{n-1}$ My generatingfunctionological approach was as follows:
I take three gen. funcs. for each of the three types of objects and multiply them, which gives: $$(1+x^2+\ldots+x^n)^3 \Rightarrow ( \frac {1-x^{n+1}} {1-x})^3 \Rightarrow (1-x^{3n+3}-3x^{n+1}+3x^{2n+2}) {{r+3-1} \choose r}x^r$$ Now, removing $x's$ with powers greater than $n$ , I get a solution as the coefficient of $x^n$ : $${n+2} \choose 2$$ But this is certainly incorrect. Please help me in rectifying my error.","['combinatorics', 'generating-functions']"
3378947,"If $T_1,T_2$ are two unbiased estimators, prove that $\rho(T_1,T_2) \geq \frac{2-\alpha}{\alpha}$.","Consider the following statement: Let $T_1,T_2$ be two unbiased estimators with common variance $\alpha \sigma^2$ , where $\sigma^2$ is the variance of the UMVUE. Show that that $\rho(T_1,T_2) \geq \frac{2-\alpha}{\alpha}$ , where $\rho$ is the correlation function. Now, clearly $\alpha >1,$ since $\operatorname{Var} (T_1) = \alpha \sigma^2$ must be larger than the UMVUE's variance, $\sigma^2.$ Now, I'm kind of lost on how to show that the statement is true. We can write \begin{align*}
\rho(T_1,T_2) &= \frac{\operatorname{Cov}(T_1,T_2)}{\sqrt{\operatorname{Var(T_1)}} \sqrt{\operatorname{Var(T_2)}}}\\[0.3em]
&= \frac{\operatorname{Cov}(T_1,T_2)}{\alpha \sigma^2}\\
\end{align*} Here we could write $\operatorname{Cov}(T_1,T_2) =\mathbb{E}(T_1 T_2) - \mathbb{E}(T_1) \mathbb{E}(T_2) $ where we know that $\mathbb{E}(T_1) =\mathbb{E}(T_2)= \theta$ , if $T_1$ and $T_2$ are estimators for the parameter $\theta$ (since they are unbiased estimators). However I don't see how that helps. I've tried to reduce algebraically to something simpler, but don't really get anywhere. If anyone could provide some guidance one how to proceed I would appreciate it very much.",['statistics']
3378972,Why am I getting the wrong result when applying the extra strong Lucas pseudoprime test?,"I'm trying to do the Lucas extra strong pseudoprime test but get the wrong result. For example $13$ is prime but the test gives composite. Here is what I tried: $n=13$ then $n+1=14=7 \cdot 2^1$ gives $d=7$ and $s=1$ . set $P=3,Q=1,D=3^2-4=5$ $U_1=1$ and $V_1=P=3$ $U_2=3$ and $V_2=7$ $U_3=8$ and $V_3=5$ $U_6=1$ and $V_6=10$ $U_7=0$ and $V_7=11$ $U_{14}=0$ and $V_{14}=2$ There's two ways the number can be a pseudoprime 1) $U_d \equiv 0 \pmod{n}$ and $V_d \equiv 2 \pmod{n}$ ; or 2) $V_{d2^r} \equiv 0$ for $0 \leq r < s$ We have $14=2\cdot7$ so $d=7$ For 1) $U_7$ is congruent to 0 but the second necessary condition, $V_7$ isn't congruent to 2. For 2) $V_7$ is considered again but still $11$ isn't congruent to $0 \bmod 13$ . Since neither of these congruence hold, the test gives composite. What is wrong with what I have done? I have heard that the extra strong test is faster than the strong test. Is this true? I find it unlikely since it has an additional condition that must be checked, but maybe something to do with the parameters makes it end earlier.","['number-theory', 'pseudoprimes', 'primality-test', 'discrete-mathematics', 'algorithms']"
3378988,How does one prove L'Hôpital's rule?,"L'Hôpital's rule  can be stated as follows: Let $f, g$ be differentiable real functions defined on a deleted one-sided neighbourhood $^{(1)}$ of $a$ , where $a$ can be any real number or $\pm \infty$ . Suppose that both $f,g$ converge to $0$ or that both $f,g$ converge to $+\infty$ as $x \to a^{\pm}$ ( $\pm$ depending on the side of the deleted neighbourhood). If $$\frac{f'(x)}{g'(x)} \to L,$$ then $$\frac{f(x)}{g(x)} \to L,$$ where $L$ can be any real number or $\pm \infty$ . This is an ubiquitous tool for computations of limits, and some books avoid proving it or just prove it in some special cases. Since we don't seem to have a consistent reference for its statement and proof in MathSE and it is a theorem which is often misapplied (see here for an example), it seems valuable to have a question which could serve as such a reference. This is an attempt at that. $^{(1)}$ E.g., if $a=1$ , then $(1,3)$ is such a neighbourhood.","['calculus', 'derivatives', 'real-analysis']"
3379049,Finding the structure of an automorphism group,"Question: Let $G=\operatorname{Aut}(\mathbb Z_4\times\mathbb Z_4)$ , $c$ be an element in $G$ such that $c:(a,b)\mapsto(3a,3b)$ . Prove that $\langle c\rangle\triangleleft G$ , and that $$G/\langle c\rangle\cong S_4\times\mathbb Z_2.$$ My Attempt Rephrasing the question to matrix form, $G=\rm{GL}(2,\mathbb Z_4)$ , the $c$ turns into $\left(\begin{matrix}3&0\\0&3\end{matrix}\right)$ . As $c$ is a diagonal matrix, $M\langle c\rangle M^{-1}=\langle c\rangle$ for all $M$ . Hence $\langle c\rangle\triangleleft G$ . Note that the RHS of the desired isomorphism is a direct product, there must be an element $d$ having order $2$ in $G/\langle c\rangle$ such that it commutes with all elements in the quotient group. One problem I need to overcome is to express the elements in the quotient group. I tried to express them as cosets, but it is hard to tackle. One possible pathway is to find this $d$ and view the quotient group $G/\langle c\rangle/\langle d\rangle$ as a permutation of $4$ elements.","['automorphism-group', 'group-theory', 'abstract-algebra']"
3379066,Calculate the value of $\frac{1}{2}+\frac{1}{4}+\frac{2}{8}+\frac{3}{16}+....+\frac{F_n}{2^n}+....$ [duplicate],"This question already has answers here : How to prove the Fibonacci sum $\sum \limits_{n=0}^{\infty}\frac{F_n}{p^n} = \frac{p}{p^2-p-1}$ (3 answers) Closed 4 years ago . The Fibonacci sequence starts with 1, 1, 2, 3, 5, 8, 13, ... .(Start from the 3rd term,
each term is the sum of the two previous terms). Let $F_n$ be the $n$ th term of this sequence. $S$ is defined as $S=\frac{1}{2}+\frac{1}{4}+\frac{2}{8}+\frac{3}{16}+....+\frac{F_n}{2^n}+....$ Calculate the value of $S$ I have no idea how to solve this, hints aswell as solutions would be appreciated Taken from the 2013 AITMO","['contest-math', 'number-theory', 'fibonacci-numbers', 'sequences-and-series']"
3379071,On the embedding in Hartshorne I 6.8,"I am a little bit confused regarding the statement in the first paragraph of the proof. Since $Y$ is a closed subset of $\mathbb{P}^n$ , we can consider the extended morphism from $X$ to $\mathbb{P}^n$ . But why it is necessary for the image of the ""missing point"" $P$ under the extended morphism lies in $Y$ in case we have that unique extension? I can smell it could be something related to the regular function property, but I could not see explicitly how. Thank you very much for answering in advance.","['algebraic-geometry', 'projective-geometry']"
3379095,Use the relation $x^3=y$ to get $\alpha^3 + \beta^3+\gamma^3$,I have this equation $$x^3-x^2-x+0.5=0$$ Now i have to use the relation $x^3=y$ to get $\alpha^3 + \beta^3+\gamma^3$ which will be the roots of the new equation obatained. I know that i can use many other ways but how to solve by this method I end up with this $$y-y^{\frac {2}{3}}-y^{\frac {1}{3}}+0.5=0$$ I can't factor out $y^{\frac{1}{3}}$ Any help is appriciated,"['cubics', 'algebra-precalculus', 'polynomials']"
3379150,Probability each table leg was in each spot.,"I have a fold up table at home with six legs and three areas. Each area takes 2 legs to keep the table up, but when stored three legs are positioned on the left and three on the right. Everytime I setup the table I randomly take the three legs on the left, put two on the left side and one in the middle. Then I take the three legs from the right and put two on the right and also one in the middle. When folding it up I randomly pick one leg in the middle to go left and one to go right. So basically a leg that started on the left when folded, could end up in the middle when setup and end on the right when folded again. I've setup this table maybe a hundred times and everytime I wonder ""Has each leg been in every spot (six spots when setup) at least once?"" I guess there is a 1/3 change that a leg ends up in the middle and then a 1/2 change it ends up on the other side, which by my uneducated mind results in a 16.6% probability it changes sides, but I have no idea how to go from there. If you perfectly rotate the legs around, you could get them in each spot in 6 times. But I don't know that is even relevant at all. So, what is the probability each leg has been in every spot?",['probability']
3379173,What actually is a differential?,"I am a bit confused about differentials, and this is probably partly due to what I find to be a rather confusing teaching approach. (I know there are a bunch of similar questions around, but none of them clarified my confusion). When first meeting derivatives in calculus, the magic $d$ symbol first appeared in the Leibniz notation for derivatives as $\frac{df}{dx}$ , and got told that it's a symbol for differentiation, not a fraction. The chain rule, saying that $\frac{df}{dx} = \frac{df}{du}\frac{du}{dx}$ was taught along the lines ""looks like fraction simplification, but be careful"". Then integrals came around, with not much being said about the $dx$ at the end, until the substitution rule. Then, I made contact with differentials, but merely saying that when changing the variable, one needs also to change the differential $dx$ to $du=f'dx$ . Now, it seems to me that $du=f'dx$ comes a bit from $f'=\frac{df}{dx}$ . When getting a bit into higher maths, there is more and more operations with functions/differentials. When doing surface areas, we talk about area differential, with $ds^2 = dx^2 + dy^2$ , or differential of a multivariable function as $df = \sum\frac{\partial f}{\partial xi}dx_i$ . It seems like, in some cases, we do operate with the differential as its a simple real value, where the idea of an infinitesimal (basically $\Delta x = x - x_1$ as $x_1 \rightarrow x$ . Possibly the most important thing for me now, it seems like I can see the differential $df$ as a local, linear approximation of $f$ and $ \sum\frac{\partial f}{\partial xi}dx_i$ as a decomposition of the tangent along the basis directions. But, at the same time, I remain stuck with the lack of an exact definition of the differential and a bit of fear of using it due to warnings such as ""chain rule is not really a fraction simplification"".","['differential', 'derivatives']"
3379181,Using spectral theorem for integral Hilbert-Schmidt (maybe) operator,"Let $T: L^2(\mathbb R^d) \to L^2(\mathbb R^d)$ be defined by $\displaystyle (Tf)(x) = \int_{\mathbb R^d}f(y)K(|x-y|)dy$ where $K(|z|) = \frac{1}{1+|z|^\alpha}$ where $z \in \mathbb R^d$ and $\alpha > \frac{d}{2}$ . Show that the spectrum of $T$ (the set of eigenvectors) spans $L^2(\mathbb R^d)$ What I tried (false proof): If we can show $T$ is a Hilbert-Schmidt integral operator, we can use the spectral theorem. Notice that $\displaystyle \int \frac{1}{(1+|z|^\alpha)^2}dz = \int_{|z| \leq 1} \frac{1}{(1+|z|^\alpha)^2}dz + \int_{|z| > 1} \frac{1}{(1+|z|^\alpha)^2}dz \leq \\ \displaystyle \int_{|z| \leq 1} \frac{1}{(1+|z|^\alpha)^2}dz + \int_{|z| > 1} \frac{1}{(|z|^\alpha)^2}dz$ . $\displaystyle \int_{|z| \leq 1} \frac{1}{(1+|z|^\alpha)^2}dz \leq \int_{|z| \leq 1}1dz = \pi < \infty$ so this part is not problematic. Let's analyze the other part of the integral. Define $A_k = \{z: 2^k < |z| \leq 2^{k+1}\}$ . Then we have $\displaystyle \{z: |z| > 1\} = \bigcup_{k=0}^{\infty}A_k$ , and because $A_k$ is simply every element of $A_0$ but multiplied by $2^k$ , from dilation property of measures $m(A_k) = (2^k)^d m(A_0) = 3\cdot \pi \cdot 2^{kd}$ Finally then, \begin{align*} \int_{|z| > 1} \frac{1}{(|z|^\alpha)^2}dz &= \sum_{k=0}^{\infty}\int_{A_k}\frac{1}{(|z|^\alpha)^2}dz \leq \sum_{k=0}^{\infty}\int_{A_k}\frac{1}{(2^k)^{2\alpha}}dz \\
&= \sum_{k=0}^{\infty}2^{-2k\alpha}m(A_k) = 3\pi \sum_{k=0}^{\infty}2^{kd-2k\alpha} \\
&< \infty\end{align*} This sum converges because $2\alpha > d$ . Hence, $K(|z|) \in L^2(\mathbb R^d)$ . Now the false part Because $K(|z|) \in L^2(\mathbb R^d)$ , we can say that $K(|x-y|) \in L^2(\mathbb R^d \times \mathbb R^d)$ . [Not really. This is actually false. Infact, $\iint |K(|x-y|)|^2dxdy = \infty]$ So we can say that $T$ is hilbert schmidt, the fact that it's self adjoint is trivial, and by the spectral theorem we are done. As I said, there's a problem with this proof. Is there a way to make it correct? Is the problem statement even correct?","['hilbert-spaces', 'proof-verification', 'functional-analysis']"
3379216,Does these arithmetic means of Pythagorean triangles converge?,"Primitive Pythagorean triplets $a^2 = b^2 + c^2, \gcd(b,c) = 1$ are given by $a = r^2 + s^2$ , $b = r^2 - s^2$ and $c = 2rs$ where $r > s$ are natural numbers.
Let the $n$ -th primitive triplet be the one formed by the $n$ -th smallest pair in increasing order of $(r,s)$ . Claim 1 : Let $\mu_n$ be the arithmetic mean of the ratio of the
perimeter to the hypotenuse of first $n$ primitive Pythagorean triplets; then, $$ \lim_{n \to \infty}\mu_n = \frac{\pi}{2} + \log 2$$ Claim 2 : Let $\mu_x$ be the arithmetic mean of the ratio of the
perimeter to the hypotenuse of all primitive Pythagorean triplets in
which no side exceeds $x$ ; then, $$ \lim_{x \to \infty}\mu_x = 1 + \frac{4}{\pi}$$ Update 8-Oct-2019 : Claim 2 has been proved in Mathoverflow . Data for claim 1 : From the plot of $\mu_n$ vs. $n$ for $n \le 5 \times 10^8$ we observe that $\mu_n$ is approaching a limiting value which is somwhere between $2.263942$ and $2.263944$ . The midpoint of the distribution of $\mu_n$ agrees with the above closed form to $6$ decimal places. Claim 2 has similar data. Question : Are these limits known if not, can it be proved or disproved? Sage code for claim 1 r   = 2
s   = 1
n   = sum = 0
max = 10^20
while(r <= max):
    s = 1
    while(s < r):
        a = r^2 + s^2
        b = r^2 - s^2
        if(gcd(a,b) == 1):
            c = 2*r*s
            if(gcd(b,c) == 1):
                n = n + 1
                sum = sum + ((a+b+c)/a).n()
                if(n%10^5 == 0):
                    print(n,sum/n)
        s = s + 1
    r = r + 1","['number-theory', 'limits', 'geometry', 'real-analysis']"
3379244,Applications of this integral equation in Banach space,"I’m writing a paper on fixed point theorem, as an application of my main results, I will study this equation: \begin{equation}
 \left\{\begin{matrix}
u(t) &=&\int_{0}^{t} f(s,u(s),v(s))ds\,,\: t\in [0,a] 
\\ 
v(t) &=&\int_{0}^{t} f(s,v(s),u(s))ds\,,\: t\in [0,a] \end{matrix}\right.
\end{equation} where $a$ is a real number such that $a>0$ , $E$ a Banach space and $f :[0,a]\times E\times E\rightarrow  E$ a continuous map. Since I am new to doing research, I want to know if there is an application in physics, biology, population dynamics.. of this system - or this kind of system-. Are there any existing textbooks/articles/papers about this kind of equation? Any help would be very much appreciated. Edit: As it t mentionned by @Robert in his answer, the system is equivalent to the system of differential equations $$ \eqalign{u'(t) &= f(t,u(t),v(t))\cr
            v'(t) &= f(t, v(t),u(t))\cr}$$ with initial conditions $u(0)=v(0)=0$ .","['integration', 'mathematical-physics', 'systems-of-equations', 'analysis']"
3379345,A curious identity from repeated differences of integer powers,"It is a well known fact that the repeated differences between $n$ -powers of consecutive integers produce eventually $n!$ . For example, for $n=3$ we have \begin{eqnarray}
1, 8 , 27, 64\\ 
7, 19, 37\\
12 , 18\\
6
\end{eqnarray} These repeated differences can be summarized in the identity $$
n!=\sum_{k=0}^n {{n}\choose{k}} (-1)^{n-k}(k+1)^n.
$$ What is intriguing me is that the identity seems to be valid even when written as $$
n!=\sum_{k=0}^n {{n}\choose{k}} (-1)^{n-k}(k+c)^n,
$$ where $c$ is any complex number ! I stumble upon this identity by pure chance and I verified it in many numerical experiments, but I could not prove it up to now. Probably I am missing some very basic fact and I would like if someone can tell me what it is.","['number-theory', 'summation', 'discrete-mathematics', 'elementary-number-theory']"
3379361,Is every probability measure in the line induced by a random variable?,"It is a basic fact in probability theory that, for every random variable $$
X: (\Omega, \mathcal{F}, \mathbb{P}) \to (\mathbb{R}, \mathcal{B}),
$$ we have an associated measure $\mathbb{P}_X$ on the borelians of $\mathbb{R}$ given by $$
\mathbb{P}_X(B) := \mathbb{P}(X \in B) = \mathbb{P}(X^{-1}(B)), \forall B \in \mathbb{B}.   
$$ $\mathbb{P}_X$ is called the measure induced by $X$ . My question: is the opposite also true? That is, given a probability measure on the borelians of $\mathbb{R}$ , is it induced by a random variable? More precisely: Is there a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ such that, given a probability measure $\mu$ in $(\mathbb{R}, \mathcal{B})$ , one can find a random variable $X: (\Omega, \mathcal{F}, \mathbb{P}) \to (\mathbb{R}, \mathcal{B})$ such that $\mu$ is induced by $X$ ? I aprreciate your concern! [Edit] What I really want is a probability space that can be used for global representation of probability measures as measures induced by random variables. I have a guess that the space $\Omega = \{f: \mathbb{R} \to \mathbb{R} | f \:\text{is Borel measurable}\}$ with the $\sigma$ -algebra of cilinders and some appropriate measure is the space desired, but I'm not pretty sure on how to prove it.","['probability-theory', 'functional-analysis', 'measure-theory']"
3379374,Why is a skew symmetric matrix called thus?,The symmetric matrix is a lot like the symmetric curve having skewness 0 in a statistical distribution. Can we somehow relate a skew symmetric matrix with this definition to see why it is called thus?,"['matrices', 'statistics']"
3379448,Inequality for Weak $L^p$ spaces,"For each measurable function $f: X \to \mathbf{R}$ , define it's distribution function $F: [0,\infty] \to [0,\infty]$ by $F(t) = |{x : |f(x)| > t}|$ . Then, for each $p \geq 1$ , define the weak $L^p$ norm $\| f \|_{p,\infty}$ as the smallest value $A$ such that for each $t \in [0,\infty]$ , $$ F(t) \leq A^p / t^p. $$ It is easy to see that $\| f \|_{p,\infty}$ is a quasinorm, i.e. that $$ \| f_1 + \dots + f_N \|_{p,\infty} \leq N( \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty}). $$ However, for $p > 1$ , $\| \cdot \|_{p,\infty}$ is comparable to a norm. In particular, this implies that we should be able to obtain an inequality of the form $$ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty}, $$ independantly of $N$ . Is there an elementary proof of the fact that $$ \| f_1 + \dots + f_N \|_{p,\infty} \lesssim_p \| f_1 \|_{p,\infty} + \dots + \| f_N \|_{p,\infty}? $$","['harmonic-analysis', 'inequality', 'functional-analysis']"
3379454,"$(JML)$ and $(JNL)$ respectively cuts $CK$ and $BK$ at $P$ and $Q$. Prove that $\overline{J, N, P}$ and $\overline{J, M, Q}$.","$E$ and $F$ are points respectively lying on $AB$ and $CA$ such that $B, C, E, F$ are concyclic. $BF \cap CE = K$ . $KM \perp CA$ and $KN \perp AB$ $(M \in CA$ and $N \in AB)$ and $L$ is the midpoint of $AK$ . $I$ and $J$ are points lying respectively on $EF$ and $BC$ such that $\angle AKI = \angle KJI$ . $(JML)$ and $(JNL)$ respectively cuts $CK$ and $BK$ at $P$ and $Q$ . Prove that $\overline{J, N, P}$ and $\overline{J, M, Q}$ . Note that $I$ is the midpoint of $EF$ . It can be seen, but not proven, that $J$ is the midpoint of $BC$ . We might be able to establish that $MNPQ$ is a parallelogram, perhaps even an isosceles parallelogram. But I am one of ""us"".","['geometry', 'plane-geometry']"
3379466,"How many ways can you arrange all letters in the word ""management"" so that at least one ""m"" is adjacent to one ""a""?","This permutation question appears harder than it seems. I first to combine a set of ""m"" and ""a"" together. Then subtract all cases where ""ma"" and the other ""ma"", or ""am"" and the other ""am"" as they can switch places. Then subtract the ""ama"", ""mam"" cases. Eventually, get lost in the numerous duplicate cases, can someone please help me with this. Thanks in advance.","['permutations', 'combinations', 'combinatorics']"
3379471,Expected number of regions with $n$ random lines in a circle,"There are $n$ random lines drawn in a circle, defined by endpoints being uniform on circle. I am trying to figure out the expected number of regions separated by $n$ lines. I know $f(0)=1$ , $f(1)=2$ and $f(2)=\frac{10}{3}$ . Though naive, I can work it out through enumeration. But when $n$ is large, is there a formula to do this?","['statistics', 'uniform-distribution', 'probability']"
3379483,Proof that SN (or Jordan-Chevalley) Decomposition is unique?,"Let $M$ be a matrix with entries in $\mathbb C$ . The SN (or Jordan-Chevalley) decomposition theorem states that we can find unique matrices $S$ and $N$ such that: $M=S+N$ $S$ is diagonalizable $N$ is nilpotent $SN=NS$ . I would like to prove the uniqueness part of this theorem, since everything else is immediate from the fact that all complex matrices can be put into Jordan normal form for some choice of basis. (If $M=AJA^{-1}$ , where $J$ is in Jordan normal form, write $J=J_S+J_N$ , where $J_S$ consists of the diagonal part of $J$ with zeroes elsewhere, and $J_N$ consists of the line above the diagonal with zeroes elsewhere. Then let $S=AJ_SA^{-1}$ and $N=AJ_NA^{-1}$ and direct calculation verifies that these meet the criteria above.) This post attempted to answer the same question, but unfortunately the proof is invalid because it assumes that the difference of two nilpotent matrices is another nilpotent matrix, which is not true (a counterexample is given in this post ).","['matrices', 'jordan-normal-form', 'linear-algebra', 'matrix-decomposition']"
3379517,"Criterion for $PSL(2,q)$","I am looking for a criterion for a group to be isomorphic to $PSL(2,p^k)$ in terms of its Sylow $p$ -subgroups. For example, let $G$ be finite group of order $p^km$ where $p$ is an odd prime not dividing $m$ .
Suppose that $G$ is simple. Sylow $p$ -subgroups of $G$ are elementary abelian. Any two distinct Sylow $p$ -subgroups of $G$ intersect trivially. $G$ has exactly $p^k+1$ Sylow $p$ -subgroups. Do these conditions imply that $G\cong PSL(2,p^k)$ ? (Presumably, such an isomorphism would be proved by treating the $p^k+1$ Sylow $p$ -subgroups as the $p^k+1$ points of projective space). Is there similar set of conditions that implies that $G\cong PSL(2,p^k)$ ?","['linear-groups', 'finite-groups', 'reference-request', 'simple-groups', 'group-theory']"
3379519,"Interesting function : $f(x)=\frac{\ln (\frac{x+2}{x+1})}{\ln (1+\frac{1}{x})}$ , $x>1$","Question : Prove this function : $$f(x)=\dfrac{\ln \left(\dfrac{x+2}{x+1}\right)}{\ln \left(1+\dfrac{1}{x}\right)},\quad x>1$$ is increasing. I don't know how I solve by my effort is : Derivative of $f$ is : $$f'(x)=\dfrac{(x+2)\ln \left(\frac{x+2}{x+1}\right)-x\ln \left(\frac{x+1}{x}\right)}{x(x+2)(x+1)\ln^{2} \left(1+\dfrac{1}{x}\right)}$$ Then we will prove that $f'(x)≥0$ for any $x>1$ mean that But I don't know how to prove : $$(x+2)\ln \left(\frac{x+2}{x+1}\right)-x\ln \left(\frac{x+1}{x}\right)\ge0$$ I need some ideas here if any one have. Thanks!","['calculus', 'functions', 'logarithms']"
3379578,Limit of $\frac{n!}{2^{(n^{2})}}$,"Find the following limit: $$\lim_{n\to\infty} \frac{n!}{2^{n^2}}$$ I get the feeling that this limit equals to zero. Intuitively, the function $f(n)=2^{n^2}$ grows much more faster than the factorial, however, I wish to prove this limit using only the squeeze theorem or some algebra. I noticed that: $$0\leq \frac{n!}{2^{n^2}}=\frac{n}{2^n} \cdot\frac{n-1}{2^n}\cdots \frac{2}{2^n}\cdot\frac{1}{2^n}$$ I tried to think about cases about wether $n$ is even or odd, hoping that would lead me to a way to simplify the latter expression, but it didn't work. Also, is there a way to generalize the problem? That is, does the limit $$\lim_{n\to\infty} \frac{n!}{a^{n^a}}$$ is always equal to zero, for $a\in\Bbb{N}$ ? Thanks in advance!","['limits', 'exponential-function', 'factorial']"
3379597,Formula for the sum of words in a 3 letter algebra,"I have two alphabets with 3 letters, $\{V,U,U^\dagger\}$ and $\{X_1,X_2,X_3\}$ where $$ V = X_1 + X_2 + X_3, \, U = X_1 + \omega X_2 + \omega^2 X_3, \, U^\dagger = X_1 + \omega^2 X_2 + \omega X_3 $$ and $\omega = e^{2\pi i /3}$ . The words I can construct in the former alphabet are restricted, such that any letter $U$ can only immediately be followed by a $V$ or a $U^\dagger$ , and ultimately in the string, there must be a corresponding $U^\dagger$ . Any insertion of $U^\dagger$ must be preceded by either the letter $V$ or $U^\dagger$ , with an accompanying $U$ for every $U^\dagger$ . Therefore $U$ and $U^\dagger$ come in a pair, and the letter $U$ will always precede the letter $U^\dagger$ in the word they are present in, and there may be multiple letters of $V$ in between them. Furthermore there can be as many pairs of $UU^\dagger$ as the length of the word permits. Hence, the only possible 2 letter words that can be constructed are $VV$ and $UU^\dagger$ . The 3-letter words that can be constructed are $V V V, V U U^\dagger, U V U^\dagger, U U^\dagger V$ . The 4-letter words that can be constructed are $VVVV, VVUU^\dagger, VUVU^\dagger, UVVU^\dagger, VUU^\dagger V, UVU^\dagger V, UU^\dagger VV$ and $UU^\dagger UU^\dagger$ . The 5-letter words that can be constructed are $VVVVV, VVVUU^\dagger, VVUVU^\dagger, VUVVU^\dagger, UVVVU^\dagger, VVUU^\dagger V, VUVU^\dagger V, UVVU^\dagger V, VUU^\dagger VV, UVU^\dagger VV, UU^\dagger VVV, VUU^\dagger UU^\dagger, UVU^\dagger U U^\dagger, UU^\dagger V UU^\dagger, UU^\dagger UVU^\dagger$ and $UU^\dagger U U^\dagger V$ . In general there $2^{n-1}$ length $n$ words. I would like to write down the real part of the sum of these words when mapped to the alphabet ${X_1,X_2,X_3}$ . I have explicitly shown that up to $n=6$ this gives $$ 2^{n-1} \sum_{\sigma_1,\cdots,\sigma_n=1}^{3} \bigg(- \frac{1}{2}\bigg)^{\sum_{r=1}^n (1-\delta(\sigma_r,\sigma_{r+1}))} X_{\sigma_1}\cdots X_{\sigma_n}, \qquad \sigma_{n+1}=\sigma_1, $$ where $\delta(\sigma_r, \sigma_{r+1})$ is the Kronecker delta. So for example, taking the sum of 2-letter words, listed above, and the expressions for $\{V,U,U^\dagger\}$ in terms of $\{X_1,X_2,X_3\}$ , expanding and collecting terms. Then when we take the real part of the final result we find $$ \text{Re}(VV + UU^\dagger) = 2\bigg(X_1 X_1 + X_2 X_2 + X_3 X_3 + \bigg(-\frac{1}{2}\bigg)^2 X_1 X_2 + \bigg(-\frac{1}{2}\bigg)^2 X_1 X_3+ \bigg(-\frac{1}{2}\bigg)^2 X_2 X_3+ \bigg(-\frac{1}{2}\bigg)^2 X_2 X_1 + \bigg(-\frac{1}{2}\bigg)^2 X_3 X_1 + \bigg(-\frac{1}{2}\bigg)^2 X_3 X_2\bigg) $$ I would like to prove (or disprove) this result for arbitrary $n$ . To do this I am basically using induction, but I have a problem in working out how to express the real part of words of the form $U^\dagger \{\text{length} \, n \, \text{words} \}$ . My question is whether there is a demonstrable way of writing down a closed sum, as above, for the words $U^\dagger \{\text{length} \, n \, \text{words} \}$ . If anyone has any insight into how this might work, I would be extremely grateful.","['combinatorics-on-words', 'induction', 'combinatorics', 'complex-numbers']"
3379623,How can the row rank of a matrix with complex elements be calculated over $\mathbb{Q}$?,"I have a matrix whose elements are complex or real numbers or expressions of complex-valued or real-valued functions. How can the row rank of that matrix be calculated over $\mathbb{Q}$ ? The row rank over $\mathbb{Q}$ is the number of rows that are linearly independent over $\mathbb{Q}$ . for example: $$\left( \begin{array}{c}
1\\\sqrt2\\\sqrt3\\\sqrt6
\end{array}\right)$$ or $$\left(\begin{array}{ccc}
1+x & \sqrt{2}x & e^x \\
1 & \sqrt{2} & e^x \\
0 & 0 & e^x \\
\end{array}\right)$$ Usually, Gaussian elimination is used. But what is the algorithm for Gaussian elimination over $\mathbb{Q}$ ? How must the usual Gaussian elimination algorithm (see e.g. this short and easy program from the MathWorks Matlab forum ) be changed for calculating the rank over $\mathbb{Q}$ ? I also could calculate the Wronskian matrix or the Gramian matrix and calculate their determinant over $\mathbb{Q}$ . Example 2 is the Wronskian matrix of the first row of that matrix. MAPLE has a procedure for calculating determinants over $\mathbb{Q}(i)$ . See e.g. MAPLE: LinearAlgebra[Determinant] - method=rational . Is this only for choosing the fastest algorithm by the user? What is the algorithm for determinant calculation over $\mathbb{Q}$ for matrices with complex elements? I could build all combinations of up to three rows of the matrix and check if they are linearly dependent over $\mathbb{Q}$ because for up to 3 rows, I need to calculate only one coefficient of the linear combination and check if it is rational. But what is with larger matrices? The answer to this questions help to solve the problem in Algebraic independence of the values of algebraic functions? .","['matrices', 'linear-algebra']"
3379636,How to make a correct proof?,"We have ${p_1, p_2,..., p_k}$ which is a set of prime integers. Show that if p prime divide $p^{e_{1}}_{1} \times p^{e_{2}}_{2} \times ... \times p^{e_{k}}_{k}$ for $e_i \in N^*$ for each $1 \leq i \leq k$ there exists $1 \leq i \leq k$ such that $p = p_i$ Proof. Let $m \in N^*$ and m = $p^{e_{1}}_{1} \times p^{e_{2}}_{2} \times ... \times p^{e_{k}}_{k}$ by the fundamental theorem of arithmetic. We know that p divide $p^{e_{1}}_{1} \times p^{e_{2}}_{2} \times ... \times p^{e_{k}}_{k}$ therefore $p$ divides $m$ . Because of the added fact p is prime that means tha p is included in the sequence that forms m by the Euclid's theorem. So we can see that p divide $p^{e_{1}}_{1}$ or $p^{e_{2}}_{2}$ or... so one. Because $m$ is formed of prime numbers multiplied together it is necessary that it will contain $p$ in it if $p$ divide $m$ . So we can conclude that here exists $1 \leq i \leq k$ such that $p = p_i$ is true. $\blacksquare$ Is my proof well constructed? If no I would like to be explained what is wrong exactly. If my proof is false I would like to be given a correct one.","['proof-verification', 'discrete-mathematics']"
3379658,Set theory notation.,"I came across this notation $$\bigcap _{i\in\mathbb{N} }(A_i \cup B_i)$$ while reading a paper on elementary set theory, but I'm not sure of what it means. (Perhaps the intersection of all sets $A_i \cup B_i$ ?) Could anybody tell me?",['elementary-set-theory']
3379661,does a random variable always have a cumulative distribution function?,"I haven't taken a measure class so maybe my question is obvious. I was wondering whether every random variable has a cdf, because for
  pdf it isn't always the case. Moreover, do you know necessary condition for the existence of the pdf ?","['probability-theory', 'probability']"
3379682,Construct an A4 paper.,The A4 European paper format is designed such that if you cut in halve the longest side you would obtain two papers where the ratio of the longest side of each is the same as the original paper. Is it possible to build an A4 paper that satisfies this objective with a ruler and  a pair of scissors? I don't understand what is meant by ratio of the longest side of each. Can someone also give me a hint on what to do to prove this mathematically?,"['proof-writing', 'discrete-mathematics']"
3379690,Using AM-GM to prove $\lim_{p\to 0}$ of the $p$-mean is equal to the GM.,"The problem in question is. Let $a_1,a_2,...,a_n>0$ . Prove that $${\lim_{p\to 0} \left(\frac{{a_1}^p+{a_2}^p+\cdots+{a_n}^p}{n}\right)^{1/p}}=(a_1a_2\cdots a_n)^{1/n}$$ i.e. show that as $p$ approches $0$ , the $p$ -mean approaches the geometric mean. The direct proof of this is simple and can be done using logorithms. However when I started this problem I had the following idea: 
Notice first that by the $AM-GM$ inequality, $$\frac{a_1^p+\cdots+a_n^p}{n}\geq(a_1a_2\cdots a_n)^{p/n}$$ Thus, $$\left(\frac{a_1^p+\cdots+a_n^p}{n}\right)^{1/p}\geq(a_1a_2...a_n)^{1/n}$$ Equality is achieved in the above iff $a_1^p=a_2^p=\cdots=a_n^p$ . But when $p$ approaches $0$ , $a_1^p=a_2^p=\cdots=a_n^p=1$ . Of course this does not prove the problem in question but I am trying to use this idea to construct a proof but it is much trickier that expected. Any ideas? The most promising idea I had so far was to create a subsequence of the p-mean and prove that it is decreasing and the geometric mean is the infinimum of this subsequence. But that is very hard to do. So I guess my main question is:
Could we find some special case where if the terms $a_1,a_2,\cdots,a_n$ approached some $x$ in some limit $L$ then, $L(AM)$ = $L(GM)$ ?","['limits', 'inequality', 'analysis']"
3379715,"Let $A,B\in M_2(\mathbb{C})$ such that $A^2+B^2=3AB$. Prove or disprove that $ \det(AB+BA)=\det(2AB). $","Let $A,B\in M_2(\mathbb{C})$ such that $A^2+B^2=3AB$ . Prove or disprove that $$
\det(AB+BA)=\det(2AB).
$$ I try to start with $\det(2AB)$ and write $$
 \det(2AB)=4\det(AB)=\frac{4}{9}\det(3AB)=\frac{4}{9}\det(A^2+B^2).
$$ After that it seems to me that something is missing. How can I continue from here? Thank you.","['matrices', 'linear-algebra']"
3379720,Order of growth for algorithms: $\log(n)^{4}$or $\log(n)^{4}$ vs $5\sqrt(n)$,I am not sure how to compare behaviour of $\log^4n$ or $\log^2n$ to $5\sqrt n $ for growth. Can someone help me compare it with an explanation?,"['asymptotics', 'discrete-mathematics']"
3379759,"Proof of Taylor series for $\cos x$ is greater than $\cos x$ in $[-1,1]$","I would like to prove that Taylor series of $\cos x$ is greater or equal than $\cos x$ when $|x| \le 1$ : $$1-\frac12x^2+\frac1{24}x^4 \ge \cos x$$ I tried to think taking the as a function $g(x) = \cos x - \left(1-\frac12x^2+\frac1{24}x^4\right)$ and showing that is $> 0$ , but I don't know how. Some help? I also though at the Lagrange remainder. It should be: $$-\frac{\cos(c)}{6!}x^6$$ and it should be always negative for $x \in [-1,1]$ . therefore this would prove that $\cos x$ is $\le$ than the Taylor expansion. is it right?
And returning to the previous approach, how could I prove it?","['functions', 'taylor-expansion']"
3379797,Does the series of the reciprocals of Sophie Germain primes converge?,"Yesterday when reading Landau's Elementary Number Theory, I came across Brun's theorem which states that the reciprocals of twin primes add up to a finite sum (the series converges), and this made me wonder if the same is true for Sophie Germain primes (the reciprocals add up to a finite sum). But I cannot Google out anything. Can anyone give an answer or point me to some references? Thanks!","['number-theory', 'analysis']"
3379903,Algebraic Functors and Left Adjoints,"I'm currently taking a class on Categorical Logic, and we're just finishing our section on Lawvere Duality for algebraic theories. As a quick remark, our profesor mentioned that every algebraic functor admits a left adjoint, and gave an example which feels wrong to me. Definitions and the example are below: Recall a Lawvere Algebraic Theory $\mathbb{A}$ is a finite product category with objects $A^n$ for $n \in \omega$ . $A = A^1$ is called the generator or universal model of $\mathbb{A}$ . The category of (set-valued) $\mathbb{A}$ -models is $\mathsf{Mod}(\mathbb{A}) = 
\mathsf{FP}(\mathbb{A}, \mathsf{Set})$ , the finite product preserving functors into Set. Then a (finite product) functor $F : \mathbb{A} \to \mathbb{B}$ induces a functor $F^* : \mathsf{Mod}(\mathbb{B}) \to \mathsf{Mod}(\mathbb{A})$ . That is, an $\mathbb{A}$ -model in the (syntax) category $\mathbb{B}$ induces a (semantic) map from $\mathbb{B}$ -models to $\mathbb{A}$ -models. Such a functor $F^*$ is called Algebraic . One can prove (though I have not seen the proof) that algebraic functors have left adjoints. As an example of this phenomenon, my professor said the following: If $\mathbb{G}$ and $\mathbb{R}$ are the syntactic categories of groups and rings, respectively, then we have the map $F : \mathbb{G} \to \mathbb{R}$ which sends the generator to the generator. This map induces $F^* : \mathsf{Ring} \to \mathsf{Group}$ , the functor taking a ring to its underlying abelian group. He then remarked the guaranteed left adjoint $G : \mathsf{Group} \to \mathsf{Ring}$ is the group ring functor (I assume over $\mathbb{Z}$ ), however this doesn't sit well with me. The ""group ring"" functor is left adjoint to the ""group of units"" functor, but adjoints are unique and so something must be wrong. Perhaps there is some alternative notion of group ring that makes this go through? The questions, then, are: Am I correct in thinking that the group ring functor cannot be left adjoint to the underlying group functor? If so, then what is the guaranteed left adjoint? I cannot come up with a good candidate, and Google seems to be of little help in the matter. Are there references which will discuss these results? I am aware of Borceux's 3 volumes on the subject, but I am curious if there are other good sources. Thanks in advance!","['adjoint-functors', 'abstract-algebra', 'logic', 'category-theory']"
3379966,Expanding a product of linear combinations with coefficients $1$ and $-1$,"For any odd natural number $n$ , denote $t \equiv \frac{n-1}{2}$ . Let $K$ be a field such that $\operatorname{char} K \neq 2$ . Working over the polynomial ring $K\left[x_1,x_2,...,x_{n} \right]$ , denote by $\Pi_n$ the product of all possible linear combinations of the indeterminants $x_1,x_2,...,x_{n}$ , where each linear combination has $i$ coefficients which are $-1$ and its remaining $n-i$ coefficients are $1$ , and $0 \le i \le t$ . Problem Find an expression for the coefficient of the monomial $\prod_{j=1}^{n}x_{j}^{p_j}$ in the expansion of the aforementioned product $\Pi_n$ . Examples of $\Pi_n$ For $n=1$ obtain that $t=0$ and that $i \in \{0\}$ ; then $\Pi_1$ is $$x_1$$ For $n=3$ obtain that $t=1$ and that $i \in \{0,1\}$ ; then $\Pi_3$ is $$\left(x_1+x_2+x_3 \right)\left(-x_1+x_2+x_3 \right)\left(x_1-x_2+x_3 \right)\left(x_1+x_2-x_3 \right)$$ For $n=5$ obtain that $t=2$ and that $i \in \{0,1,2\}$ ; then $\Pi_5$ is $$
\begin{align}
& \left(x_1+x_2+x_3+x_4+x_5 \right)\\ 
& \left(-x_1+x_2+x_3+x_4+x_5 \right)\left(x_1-x_2+x_3+x_4+x_5 \right)\left(x_1+x_2-x_3+x_4+x_5 \right)\\& \left(x_1+x_2+x_3-x_4+x_5 \right)\left(x_1+x_2+x_3+x_4-x_5 \right)\\ 
&\left(-x_1-x_2+x_3+x_4+x_5 \right)\left(-x_1+x_2-x_3+x_4+x_5 \right)\left(-x_1+x_2+x_3-x_4+x_5 \right)\\&  \left(-x_1+x_2+x_3+x_4-x_5 \right)\left(x_1-x_2-x_3+x_4+x_5 \right)\left(x_1-x_2+x_3-x_4+x_5 \right)\\& \left(x_1-x_2+x_3+x_4-x_5 \right)\left(x_1+x_2-x_3-x_4+x_5 \right)\left(x_1+x_2-x_3+x_4-x_5 \right)\\& \left(x_1+x_2+x_3-x_4-x_5 \right)\\
\end{align}
$$ Quick observations In general, $\Pi_n$ has $\binom{n}{i}=\binom{2t+1}{i}$ factors which correspond to each $0 \le i \le t$ ; hence the total number of factors is $\sum_{i=0}^{\frac{n-1}{2}} \binom{n}{i}=\sum_{i=0}^{t} \binom{2t+1}{i}=2^{2t+1-1}=2^{2t}=4^{t}$ . Any one of the indeterminants $x_1,x_2,...,x_{n}$ has coeffient $-1$ in the linear combinations appearing in exactly $\sum_{j=0}^{\frac{n-1}{2}-1} \binom{n-1}{j}=\sum_{j=0}^{t-1} \binom{2t}{j}=2^{2t-1}-\frac{1}{2}\binom{2t}{t}$ of the factors of $\Pi_n$ . Any $k$ of the indeterminants $x_1,x_2,...,x_{n}$ all have coeffient $-1$ in the linear combinations appearing in exactly $\sum_{j=0}^{\frac{n-1}{2}-k} \binom{n-k}{j}=\sum_{j=0}^{t-k} \binom{2t+1-k}{j}$ of the factors of $\Pi_n$ . It seems that Inclusion-Exclusion is in order to solve this problem, as there is a matter of choice of ""how many minus signs"" each of the indeterminants $x_1,x_2,...,x_{n}$ ""gets"".","['binomial-coefficients', 'combinatorics', 'polynomials', 'symmetric-polynomials', 'multinomial-coefficients']"
3380014,Why are parallelizable manifolds called parallelizable?,"Let $M$ be a smooth manifold of dimension $n$ . Then $M$ is called parallelizable if there exists a global frame, i.e., $n$ linearly independent smooth vector fields $X_1,X_2, \dots, X_n$ . Why is a paralleizable manifold called ""parallelizable""? I guess it's related to the parallel transport on $M$ . We can always choose a Riemannian metric $g$ on $M$ with the corresponding Levi-Civita connection $\nabla$ on the tangent bundle $TM$ . Then we can define the parallel transport of a vector $v \in T_pM$ at any point $p \in M$ along any path $C$ starting from $p$ . Suppose $M$ is connected. Is it true that if $M$ is parallelizable, then we can always obtain a global frame via the parallel transport of a local frame $v_1, \dots, v_n $ of $T_pM$ at any point $p \in M$ ?","['smooth-manifolds', 'riemannian-geometry', 'differential-geometry']"
3380042,Uniquely extended fractional iterations of $\exp$,"Let us define the following basic conditions for an iterated exponential function: $$\exp^1(x)=e^x\tag{$\forall x$}$$ $$\exp^{a+b}(x)=\exp^a(\exp^b(x))\tag{$\forall a,b,x$}$$ I then pondered what sort of additional conditions could be applied. Using the useful inequality $e^x-1\ge x$ , I considered adding the additional constraint: $$\exp^a(x)-a\ge\exp^b(x)-b\tag{$a\ge b$}$$ which can be seen as a reasonable result of inductively applying the inequality. From this, I noticed that: $$0=\exp^0(0)-0\le\exp^a(0)-a\le\exp^1(0)-1=0\tag{$\forall a\in[0,1]$}$$ $$\exp^a(0)=a\tag{$\forall a\in[0,1]$}$$ From this, one can define $\exp^a(0)$ for any $a$ by repeatedly using $$\exp^{a+1}(0)=e^{\exp^a(0)}$$ One can also easily see that this implies $\exp^a(0)$ attains every real value exactly once, meaning it has a well-defined inverse. Now define the super-logarithm: $$x=\operatorname{slog}(\exp^x(0))=\exp^{\operatorname{slog}(x)}(0)$$ and note that we can then write: $$\exp^a(x)=\exp^{a+\operatorname{slog}(x)}(0)$$ which uniquely defines $\exp^a(x)$ . That is to say, we have: $$\exp^a(x)=\begin{cases}a,&x=0\land a\in[0,1]\\\ln(\exp^{a+1}(0)),&x=0\land a<0\\e^{\exp^{a-1}(0)},&x=0\land a>1\\\exp^{a+\operatorname{slog}(x)}(0),&x\ne0\end{cases}$$ One can then check that this satisfies the imposed inequality restriction as well as the functional equation. For the functional equation: $$\exp^a(\exp^b(x))=\exp^{a+\operatorname{slog}(\exp^{b+\operatorname{slog}(x)}(0))}(0)=\exp^{a+b+\operatorname{slog}(x)}(0)=\exp^{a+b}(x)\tag{$x\ne0\land\exp^b(x)\ne0$}$$ The other cases are even simpler to prove. For the inequality: $$\exp^a(0)-a=0\ge0=\exp^b(0)-b\tag{$\forall a,b\in[0,1]$}$$ For $a,b\notin[0,1]$ , the result follows inductively. We can then see that $$\exp^a(x)-a=\exp^{a+\operatorname{slog}(x)}(0)-(a+\operatorname{slog}(x))+\operatorname{slog}(x)$$ and so it follows for all $x$ . What interests me are conditions that do not seem unreasonable or meaningless that lead to similar uniqueness. And so here are my questions: Is there a nice way to extend this to other bases? It seems the inequality for $e$ gets kind of messy if you try to extend it to other bases. And of course I'm not looking for something as trivial as ""just linearly interpolate $\exp_b^a(0)$ for $a\in[0,1]$ with $\exp_b^1(x)=b^x$ ."" What other conditions can be imposed to produce a uniquely defined iterated exponential function (base $e$ or otherwise)? And hopefully I didn't make any mistakes in the above definitions and proofs. $\ddot\smile$","['analysis', 'power-towers', 'tetration', 'exponential-function', 'fractional-iteration']"
3380046,Family indexed by $\mathbb{N}$ vs sequence,"Possibly a trivial question, but no harm in asking: I am reading around and some notes mention a ""family of random variables $\{X_n\}$ where $n\in \mathbb{N}$ "". Is this the same as the sequence of random variables $(X_n)_{n\ge 1}$ ? The curly brackets and use of the word family seem to indicate that there is no specific order (since in other sections he talks about sequences of random variables), but this seems to not make much sense because in the end the author ends up proving limiting results like the central limit theorem etc. Thanks!","['notation', 'sequences-and-series', 'nets', 'probability-theory', 'random-variables']"
3380061,"Can you accurately check if a supposedly ""circular"" object is, in fact, circular only by measuring distances between points on its circumference?","This question was inspired by this thread I just saw on Space Exploration Stack Exchange: https://space.stackexchange.com/questions/39163/did-feynman-cite-a-fallacy-about-only-circles-having-the-same-width-in-all-direc where an anecdote is mentioned regarding how that the famous physicist Richard Feynman realized that part of the fault for the 1986 Space Shuttle Challenger disaster lie in not realizing that ""a circle is not the only figure which has the same width in all directions"". Basically, it seems, the inspectors had tried to verify that the fuel tank sections, which are tubes and need to have cross-sections which are almost exactly perfect circles at the points at which they join together, in order to ensure a good fitting-together thereof with no leaks, by naively measuring the diameter over and over in different places and seeing that all the diameter results seemed to agree, and hence concluded the tanks were ""circular"". And the problem with this is that there are non -circular shapes which have the same ""diameter"" at all points - a famous example being the so-called Reuleaux triangle which, if used to form the cross-section of a drill bit and then such suitably mounted, can be used to quickly and usefully make squarish holes with rounded corners. And this, to me, raises a question: is there any way to, using only the ability to measure between points on the object's circumference, and no other points, determine if that object is or is not circular? In more formal mathematical terms, if we have a closed plane curve $C$ , then what are the conditions on the distances $$d(a, b)$$ between points $a, b \in C$ , that are necessary and sufficient for circularity of the curve?",['geometry']
3380101,Cardinality of power set and binary sequence,"Let $A$ be a set and $P(A)$ be the power set of $A$ . Define $B(A)$ as
  the set of all functions $F:A\rightarrow\{0,1\}$ . For example, $B(\mathbb{N})$ is the set of all binary sequences. Prove that $P(A)$ has the same cardinality as $B(A)$ . When $A$ is finite, this is easy to prove. I am interested in other cases; for instance when $A$ is countably infinite or uncountable. I am also a bit confused with the definition of $B(A)$ . Could anyone help me with this one please?","['elementary-set-theory', 'cardinals', 'functions']"
3380145,Cardinality of sets and the empty set,"A math logic book gives a puzzling solution to this problem. Let set $A = \{a, b\}$ . Determine the power set P(A). Determine $|A|$ and $|P(A)|$ . Solution: $P(A) = \{\emptyset, {a}, {b}, \{a, b\}\}$ . So $|A| = 2, |P(A)| = 4$ . The empty set is a subset of every set. But here it's true only for $P(A)$ , but not for $A$ . Why? If I explicitly include the empty set as one of the element of $A$ will it increase the cardinality of $A$ ?",['elementary-set-theory']
3380195,Why is this limit integrable?,"In the book Real Analysis by Bass, it asks to evaluate the Lebesgue integral $$ \lim_{n\to\infty} \int_{0}^{n} \bigg(1 - \frac{x}{n} \bigg)^{n} \log(2+\cos(x/n)) \ \mathrm{d}x $$ I assume I should use one of the convergence theorems. Define the integrand as $f_n(x)$ . Is it possible to evaluate this even if $f_n(x)$ is not defined for all $x \in \mathbb{R}$ for some values of $n \in \mathbb{R}$ ? To be specific, $f_n(x)$ is defined for all $x\in\mathbb{R}$ , and the integral as well, if $n \in \mathbb{N}$ . Is this enough for the limit to be integrable? Another thing that confuses me is that the upper limit of the integral is $n$ , should I define the sequence of functions $g_n = \int_{0}^{n} \left(1 - \frac{x}{n} \right)^{n} \log(2+\cos(x/n)) \, \mathrm{d}x$ for each positive integer $n$ ? My edit: What I mean is that the integrand is real-valued on $(0,n)$ but I don't know how to tackle cases where the integration interval varies with the limit.","['integration', 'measure-theory', 'lebesgue-integral', 'real-analysis', 'limits']"
3380233,How many solutions $x_1+\dots+x_8=30$ has?,"Enumerate the solutions of $$x_1+\dots+x_8=30$$ where $2\leq x_i\leq 5$ for $i=1,\dots,6$ ,
  and $x_7$ and $x_8$ must be or 5 or 10. I am not sure with my process. 
and I would like to ask you if you have a better way to solve this?
and if I am right. $S_0 - S_1 + S_2 - S_3\dots$ etc. is the solution. 
but i think im doing something wrong: my solution","['combinatorics', 'discrete-mathematics']"
3380290,Finding a recurrence for the number of $n$-digit passwords having the same digit at least twice in a row [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Passwords consist of digits. A password is valid if it contains the same digit at least twice in a row. For example 4558, 000637 and 33972240 are valid passwords but 8385878 is not a valid password. Let $a_n$ denote the number of different valid passwords of length $n$ . I have been having trouble to figure out how to find a recurrence relation for this problem. I figured the password has to have at least two digits, so $a_2$ would be 10 possibilities(00,11,22,...,99) Does anyone know if I am on the right track, and how to find the recurrence relation?","['combinatorics-on-words', 'combinatorics', 'recurrence-relations', 'discrete-mathematics']"
3380320,Vector bundle with Euclidean metric isomorphic to dual,"I am trying to proof, that if a vector bundle $\xi$ posses an Euclidean metric, then it is isomorphic to its dual $Hom( \xi, \epsilon^1 )$ , where $\epsilon^1 = B( \xi ) \times \mathbb{R}$ denotes the trivial line bundle. This statement suprises me, as locally the statement should always hold. Does someone have a counterexample of a vector bundle, where this is not true? My ""proof"" so far is the following: Consider the map $\Phi: E(\xi) \to Hom(\xi, \epsilon^1)$ , that maps $y=(x,b) \in \mathbb{R}^n \times F$ after the choice of a neighborhood to $g_b(x, -)$ , where $g_b(-,-)$ is the metric at the basepoint $b$ .
It is an isomorphism as $g_b$ is positive definite, so its describing matrix (after the choice of a basis) is invertible, so any linear form $\varphi \in (E(\xi)_b)^*$ is of the form $g_b(z,-)$ of the form $g_b(z,-)$ . I feel uncomfortable with it, as for me it is not clear, if everything glues to a global map, as I only consider everything locally, by using the isomorphism $(x,b) \in U \cong \mathbb{R}^n \times F$ . Is it true, that these map glue to a global map, and how can one show this?","['geometric-topology', 'vector-bundles', 'differential-geometry']"
3380351,Symbol of a pseudo-differential operator. Hormander property and principal symbol,"Suppose I have a pseudo-differential operator on $\mathbb R$ whose symbol is $a(x,\xi) = e^{-\xi^2/2}$ (notice, no dependence on $x$ ) Question 1 : 
Are the following statements correct? $a$ is an Hörmander symbol in the class $\mathcal S^{m}_{1,0},\; \forall\, m\in \mathbb R$ . Since $\mathcal S^{m}_{1,0} \subset \mathcal S^{n}_{1,0}$ for $m\leq n$ holds, then we might say $a\in \mathcal S^{-\infty}_{1,0}$ where we define $\mathcal S^{-\infty}_{1,0}=\cap_{m\in \mathbb R}\mathcal S^{m}_{1,0}$ . Question 2 : Does $a$ have a principal symbol? If it does, what is it? N.B. For the notation one might refer to the Wikipedia page on pseudo-differential operators.","['microlocal-analysis', 'pseudo-differential-operators', 'functional-analysis', 'analysis']"
3380353,Is the following relation a well-order?,"Suppose, $A$ is a well-ordered set with strict well-order $<_A$ . Suppose $B$ is the set of all bijections from $A$ to $A$ . Let’s define a relation $<_B$ on $B$ in the following way: $b <_B a$ iff $\exists c \in A$ , such that $b(c) <_A a(c)$ and $\forall d <_A c$ $b(d) = a(d)$ . Is $<_B$ always a strict well-order? I know that it is always a strict total order, because it is both transitive and trichotomous. If $A$ is finite, then it is also a well-order. But what is about the general case?","['elementary-set-theory', 'order-theory', 'well-orders']"
3380366,Name for region between two parallel planes,"Is there an established name for the region between two parallel planes? I can use sheet, layer, lamina... but I'd like to know whether there is an established name for it.","['geometry', 'terminology']"
3380375,"If I stretch a convex polygon, does the original fit into the streched version?","Suppose you have a convex polygon $P=\mathrm{conv}(\{(x_1,y_1),\dots, (x_k,y_k)\})$ and you stretch it in one dimension, that is, we choose $\alpha>1$ and get a new polygon $P^\alpha=\mathrm{conv}(\{(\alpha x_1,y_1),\dots, (\alpha x_k,y_k)\})$ . Is it true that you can translate and rotate $P$ to make it fit into $P^\alpha$ ? This seems true to me, as you are somehow making it bigger and ""keeping the shape"", but I have no additional insight in how one could prove such a thing.","['geometry', 'polygons', 'convex-hulls']"
3380386,relation set theory,"I was reading about relation and function https://www.purplemath.com/modules/fcns.htm And I was not able to understand this phrase in it where it says ""So then this is not a function. Heck, it ain't even a relation! "" I could definitely understand why it isn't a function but couldn't understand why it isn't a relation either. I believe there is no rule for a relation to be a relation. Please explain. Thanks.","['elementary-set-theory', 'relations', 'functions', 'examples-counterexamples']"
3380411,What is the ring of invariants under the action of an arbitrary subgroup of the symmetric group?,"Let $A$ be a commutative unitary ring and $A[t_1, t_2, ..., t_n]$ the polynomial ring over $A$ in $n$ variables. The symmetric group of degree $n$ acts on $A[t_1, t_2, ..., t_n]$ in a natural way and the ring of invariants under this action is well understood. If we restrict the action to an arbitrary subgroup $G$ of the symmetric group of degree $n$ , what are known results for the ring of invariants under this action? Can we classify them in some sense?","['group-theory', 'abstract-algebra', 'combinatorics']"
3380436,How to Differentiate two equations to find Maximum Values,"I am stuck on this Differentiation problem, any help would be great! If $A=xy$ and $x+5y=20$ find the maximum value of $A$ and the values of $x$ and $y$ for which this maximum value occurs","['calculus', 'derivatives']"
3380446,Is this type of matrix always positive semidefinite?,"Let $b\in[0,1]^n$ , with $n\in\mathcal{N}^*$ . Consider the symmetric matrix $A=(a_{i,j})$ , defined by $$
a_{i,j}=\begin{cases}\min\lbrace b_i,...,b_j\rbrace &\mbox{if } i<j\\
\min \lbrace b_j,...,b_i\rbrace &\mbox{if } j\leq i\end{cases}
$$ Is $A$ always positive semidefinite? For instance, the matrix generated by the vector $[0. 1, 0.2, 0.3]$ is $$
    \left(\begin{matrix}
    0.1 & 0.1 & 0.1 \\
    0.1 & 0.2 & 0.2 \\
    0.1 & 0.2 & 0.3 \\
    \end{matrix}\right)
$$ while the one generated by the vector $[0. 2, 0.1, 0.3]$ is $$
    \left(\begin{matrix}
    0.2 & 0.1 & 0.1 \\
    0.1 & 0.1 & 0.1 \\
    0.1 & 0.1 & 0.3 \\
    \end{matrix}\right)\text{.}$$ So far, I have only managed to show that $A$ is positive semidefinite when $b$ is sorted (either in  increasing or decreasing order). The proof is by induction: The statement clearly holds if $n=1$ . Induction step:
Let's denote $A(b)$ the matrix generated when following the procedure described above with a vector $b$ . Let $n\in\mathcal{N}^*$ .  Assume that all the matrices $M\in\lbrace A(b), b\in [0,1]^{i}, i\in\lbrace 1,...n\rbrace, b \mbox{ sorted}\rbrace$ are positive semidefinite. Consider then a sorted vector $b$ with $n+1$ elements and apply Sylvester's criterion: all the sub-matrices of $A(b)$ corresponding to principal minors belong to $\lbrace A(b), b\in [0,1]^{i}, i\in\lbrace 1,...n\rbrace, b \mbox{ sorted}\rbrace$ , so the result holds. I have also tried to generate counter-examples in the case where $b$ is not sorted, but unsuccessfully.","['matrices', 'linear-algebra', 'positive-semidefinite']"
3380470,Implications of weak convergence in Lp e change of measure spaces,"In the paper ""A uniform algebra of analytic functions"" of Carne-Cole-and-Gamelin. The Theorem 6.4 says: Theorem 6.4: Let $\mu$ be a positive measure on some measure space, let $2\leq p<\infty$ , and let $N$ be a integer satisfying $N\geq p$ . Let $\{f_j\}$ be a sequence in $L_p(\mu)$ such that $f_j\longrightarrow 0$ weakly, and $F(f_j)\longrightarrow 0$ for every $F\in\mathcal{P}_N(L_p(\mu))$ . Then $\|f_j\|_p\longrightarrow 0$ . Here, $\mathcal{P}_N(L_p(\mu))$ is the space of N-homogeneous polynomials. Proof: Since the $f_j$ 's are all carried by some $\sigma$ -finite set, we can assume that the measure $\mu$ is $\sigma$ -finite. Replacing $\mu$ by a mutually absolutely continuous measure, we can assume that $\mu$ is a probability measure. $\cdots$ My questions. Someone can help me understand this change of a arbitrary measure space to a probability measure space? Why the functions are carried by a $\sigma$ -finite set? Thanks for any hint.","['measure-theory', 'weak-convergence', 'lp-spaces', 'functional-analysis', 'probability-theory']"
3380515,Example of differentiating through Lebesgue integral,"I am having trouble showing that I can differentiate this specific example through the integral $$\frac{d}{dt} \int_\mathbb{R} e^{-tx^2} dx = - \int_\mathbb{R} x^2 e^{-tx^2} dx$$ The way I tried was using the Dominated convergence theorem, but I am stuck. I was able to prove that the sequence defined by $$f_n = \left(\frac{x^2}{n} +1\right)^{-tn}$$ converges to $e^{-tx^2}$ and counts with all the required properties for the theorem. That is, measurability, and that it is absolutely bounded (e.g. by the constant function $1$ in this case). This also applies to the sequence defined by the derivatives $\frac{d f_n}{dt}$ . My problem is that, at the end I have the same problem, the limit is still outside the integral. At this point, I have shown that $$\int_\mathbb{R} \frac{df_n}{dt} dx \to - \int_\mathbb{R} x^2 e^{-tx^2} dx$$ $$\int_\mathbb{R} f_n dx \to \int_\mathbb{R} e^{-tx^2} dx$$ But still not the crucial fact that $$\frac{d}{dt} \int_\mathbb{R} f_n dx = \int_\mathbb{R} \frac{d f_n}{dt} dx$$","['measure-theory', 'lebesgue-integral', 'real-analysis', 'convergence-divergence', 'derivatives']"
3380613,Rounding Up to Next Odd Number,"I want a function $f(x)$ that rounds any $x$ to the next odd integer. For example $f(5.5)=7,f(4)=5,f(7)=7$ . It does not have to be continuous nor differentiable. When I say ""function"", I mean an explicit definition so I can graph it on graphing software (like Desmos). For example, something like $\mathbb{ceil}(\frac{x}{2})-1$ would be accepted, if it were right.","['functions', 'integers']"
3380645,Prove $P(A) = \sum_{i=1}^{n}P(A_i) - 2\sum_{i<j \leq n}P(A_i \cap A_j) + \ldots)$,"Let $A$ be the collection of outcomes which belong to only one event among events $A_1, \ldots, A_n$ . Prove \begin{align*}
P(A)
&= \sum_{i=1}^{n}P(A_i) - 2\sum_{i<j \leq n}P(A_i \cap A_j) + 3\sum_{i<j<k \leq n}P(A_i \cap A_j \cap A_k) - \ldots \\
&\qquad \ldots + (-1)^{n-1} n P(\bigcap_{i=1}^n A_i)
\end{align*} The question is from my course's exercise problem, the expression looks pretty similar to inclusion-exclusion formula, I tried induction but didn't work.","['probability-theory', 'probability']"
3380646,Standard error of variance estimation,We know that a mean estimation is the following $\bar{x}=\frac{1}{n}\sum_{n=1}^{N}x_{n}$ and the standard error of the mean estimation is $Var(\bar{x})=\sigma^{2}/n$ . Also the estimation of variance is $s^{2}=\frac{1}{n-1}\sum_{n=1}^{N}(x_{n}-\bar{x})^{2}$ Is there a way to calculate the standard error of variance ?? $Var(s^{2})=\frac{1}{n-1}nVar((x_{n}-\bar{x})^{2})\frac{n}{n-1}Var(x_{n}^{2}+\bar{x}^{2}-2x_{n}\bar{x})$ How we are supposed to handle the term $Var((x_{n}-\bar{x})^{2})$ ? Lastly $Var(x_{n})=\sigma^{2}$ and $\mathbb{E}(x_{n})=\mu$ .,"['statistics', 'variance', 'standard-deviation', 'estimation']"
3380703,"Where is a ""fat Cantor staircase"" differentiable?","The Cantor staircase is an example of a continuous function $f$ such that $f'=0$ almost everywhere, and yet $f$ is nonconstant. It is differentiable precisely at the points that aren't in the Cantor set. Now, repeat the construction with a fat Cantor set (such as the Smith–Volterra–Cantor set, shown here). Where is this fat Cantor staircase differentiable? Naively, I would've expected it to be differentiable on the complement of the Cantor set again, just like the original staircase. But this contradicts the theorem that says monotone functions are differentiable almost everywhere. So the fat Cantor staircase must be differentiable on some points in the Cantor set! Where, precisely, in the Cantor set does this happen? What is the derivative there? And what does the integral of this function's derivative look like? (Conjecture: it is differentiable on the ""pseudo-interior"" - the set of points in the fat Cantor set without successor or predecessor, not counting 0 and 1.)","['measure-theory', 'cantor-set', 'real-analysis']"
3380735,What are the non-negative integers of this form?,"What are $( \frac{x^2-1-my}{x}, \frac{y^2-1-nx}{y} ) \in  \mathbb{Z}^2_{\ge 0}$ for $(m,n) \in \mathbb{Z}^2_{\ge 0}$ , $(x,y) \in \mathbb{R}^2_{\ge 1}$ and $mx+ny=xy$ ? Some investigations : According to this answer of Ivan Neretin , assuming $x,y$ integers, the only possibility is $(0,1)$ with $(m,n) = (0,1)$ and $(x,y) = (1,2)$ , up to permutation. If $x=y$ , then $(m+n)x = x^2$ , so $x=m+n$ positive integer. In general $y=mx/(x-n)$ with $x>n$ . Thus we need to consider $$ ( \frac{x^2-1-m\frac{mx}{x-n}}{x}, \frac{(mx/(x-n))^2-1-nx}{mx/(x-n)}  ) $$ $$ = (\frac{(x^2-1)(x-n)-m^2x}{x(x-n)},\frac{m^2x^2-(x-n)^2(1+nx)}{mx(x-n)}) \in  \mathbb{Z}^2_{\ge 0} $$ Let $\alpha=\alpha_{n,m}$ be the root of $$P_{n,m}(x):=(x^2-1)(x-n)-m^2x$$ when $x>n$ (show unicity). Then $$m^2\alpha^2-(\alpha-n)^2(1+n\alpha) = (\alpha^2-1)(\alpha-n)\alpha -(\alpha-n)^2(1+n\alpha) $$ $$ = (\alpha-n)((\alpha^2-1)(\alpha-n)-\alpha+n^2\alpha) = (m^2+n^2-1)\alpha(\alpha-n)$$ Let $\beta = \beta_{n,m}$ be the root of $$Q_{n,m}(x):=m^2x^2-(x-n)^2(1+nx)$$ when $x>n$ (show unicity). Note that if $n=m$ then $\beta = n \alpha/(\alpha-n)$ . We can assume (by symmetry) that $\alpha \le \beta$ . Let $(a,b) = ( \frac{x^2-1-my}{x}, \frac{y^2-1-nx}{y} )$ . Then for $x=\alpha$ we get $$(a,b) = (0,\frac{m^2+n^2-1}{m}),$$ and by symmetry, for $x=\beta$ , we get $$(a,b) = (\frac{m^2+n^2-1}{n},0).$$ The problem reduces to find all the $x \in [\alpha, \beta]$ such that $P_{n,m}(x)$ an $Q_{n,m}(x)$ are integers. Remark : If $n |(m^2-1)$ or $m |(n^2-1)$ , then above is at least one solution. Example: $m=n=1$ , then $\alpha=1.80193773580484...$ and $\beta=2.24697960371747...$ . Let us plot $P_{1,1}$ and $Q_{1,1}$ : It follows that $(0,1)$ and $(1,0)$ are the only solutions if $m=n=1$ . What are all the others solutions in general? An other approach Take $(p,q) = ( \frac{x^2-1-my}{x}, \frac{y^2-1-nx}{y} )$ . Then: $$\left\{
\begin{array}{ll}
x^2 - px-1-my = 0 \\
y^2 -qy-1-nx = 0
\end{array}
\right.$$ Because $(x,y) \in \mathbb{R}^2_{>1}$ , it follows that: $$\left\{
\begin{array}{ll}
2x = p + (p^2+4(1+my))^{1/2}\\
2y = q + (q^2+4(1+nx))^{1/2}
\end{array}
\right.$$ So $$ 2x = p + [p^2+4+2m(q + [q^2+4(1+nx)]^{1/2})]^{1/2} $$ Then $$ [(2x-p)^2-p^2-4-2mq]^2 = q^2+4(1+nx) $$ Thus $$ (4x^2-4xp-4-2mq)^2 = q^2+4(1+nx) $$ We got a polynomial of degree $4$ , allowing us to get at most $4$ roots $x_i(m,n,p,q)$ with $i \le 4$ . Then $$2y_i(m,n,p,q) = q + (q^2+4(1+nx_i(m,n,p,q)))^{1/2}$$ It remains to solve the Diophantine equation $$mx_i(m,n,p,q)+ny_i(m,n,p,q)=x_i(m,n,p,q)y_i(m,n,p,q).$$","['number-theory', 'elementary-number-theory']"
3380759,When is $L^2(\mu)$ separable?,"Let $(E,\mathcal E,\mu)$ be a probability space. Under which further assumption are we able to show that $L^2(\mu)$ is separable? Most lecture books on measure theory only show separability of $L^2(\mu)$ for $(E,\mathcal E,\mu)=\left(\mathbb R^d,\mathcal B(\mathbb R)^{\otimes d},\lambda^{\otimes d}\right)$ , where $\lambda$ is the Lebesgue measure on $\mathcal B(\mathbb R)$ . I guess (but I'm not sure) that we need something like separability of $\mathcal E$ equipped with the metric $$d_\mu(A,B):=\mu(A\Delta B)\;\;\;\text{for }A,B\in\mathcal E,$$ where $\Delta$ denotes the symmetric difference. Remark : I know there are several questions regarding the separability of $L^p$ -spaces on the board, but almost all of them are concered with $E=\mathbb R^d$ .","['measure-theory', 'lp-spaces', 'probability-theory', 'separable-spaces']"
3380770,In how many ways can $2n+1$ seats in a party are divided among three parties so that the coalition of any two parties will ensure them of a majority?,"In how many ways can $2n+1$ seats in a party are divided among three parties so that the coalition of any two parties will ensure them of a majority? If $x$ , $y$ and $2n+1-x-y$ are the numbers of seats belonging to the first, second and third party respectively, then the situation in question will be described by the following system of equations: $$2(x+y)>2n+1$$ $$2n+1>2x$$ $$2n+1>2y$$ Thus the question can be reduced to counting integer solutions of this system. However, I have no idea how to do it.",['combinatorics']
3380841,There are 10 men and 10 women. Alice (woman) and Brad (man) never stand next to each other.,"There are 10 men and 10 women. Alice (woman) and Brad (man) never stand next to each other. Assume that the men and women alternate in a line, how many possible ways are there for the arrangement? Without the condition of Alice and Bob not standing next to eachother, it would be 10! * 10! * 2. Now I need to subtract all the ways in which they could be stuck together, or 9! * 9! * 10 * 2. (I can elaborate on how I got this part if it is wrong) So would the final answer just be 10!10!2 - 9!9!10*2 ??","['statistics', 'combinatorics', 'probability']"
3380843,Is $ 5 $ the only number that cannot be expressed as $ p + x ^ y$?,"Let $n,x,y \in \mathbb{N}$ where $n\ge3,y\ge2$ and $p$ is prime number. For some $n$ , $n$ can be expressed as $n=p+x^y$ Example $3=2+1^y$ $15=7+2^3$ We can check, $5$ can't be expressed. Question Is $ n=5 $ the only number that cannot be expressed as $ p + x ^ y$ ? I checked, there are always pair for n=3 up to n = 50. Except $5$ .","['number-theory', 'elementary-number-theory']"
3380846,Find the number of magical grids.,"Question- Consider an N ×N grid in which very cell has either +1 or −1. We call such a grid
  a Binary grid.
  The Row-Product of any row is defined to be the product of all elements in that
  single row. Similarly, the Column Product of a column is defined to be the product of all elements in that single
  column. 
  An N ×N Binary grid is called a Magical Grid if exactly one of the N Row-Products
  is −1, and exactly one of the N Column-Products is −1. That is, the other N−1
  Row-Products should all be +1, and the other N−1 Column-Products should all
  be +1.
  Find the number of Magical Grids of size N × N.(I am only interested in the case N=3,4,5). My attempt- I really haven't figured out a way of attacking the problem but here are a few deductions that I have made: The number of $-1$ s in only one row will be odd. Same goes for columns. I could potentially break down the problem into sub-cases, finding the number of magical grids for only one $-1$ , then two $-1$ s but that will take a very long time, and very inelegant. Could anyone give any leads?","['recreational-mathematics', 'combinatorics']"
3380974,"How many ways can you divide $9$ students into three unlabeled teams of $4$, $3$, and $2$ people?","How many ways can you divide $9$ students into three unlabeled teams where one team contains $4$ people, one contains $3$ people and the last contains $2$ people? Unlabeled, meaning that groups with abc = bca = cba, etc I understand how to do this if the teams are labeled: $$\frac{9!}{4!3!2!}$$ But there is a term missing in the denominator when the teams are unlabeled and I'm having difficulty understanding how to calculate how many ways the teams can be organized. There are $3!$ ways to organize the same first group of $3$ , $4!$ ways to organize the same second group of $4$ and $2!$ ways to organize the last group of $2$ . Why wouldn't you multiply $3!4!2!$ in the denominator? For instance: (ABC, DEFG) = (ABC, DEGF)  = (ABC, DFEG) = (ACB, DFGE), etc",['combinatorics']
3381008,Show that $P(\lim\limits_{n\to \infty} X_{n}=0 \operatorname{or} 1)=1$ and if $X_{0}=\theta$ then $P(\lim\limits_{n\to \infty} X_{n}=1)=\theta$,"Let $X_{n} \in [0,1]$ be adapted to $\mathcal{F}_{n}$ and $\alpha, \beta > 0$ where $\alpha + \beta =1$ . Further: $P(X_{n+1}=\alpha + \beta X_{n} \vert \mathcal{F}_{n})=X_{n}$ or $P(X_{n+1}= \beta X_{n} \vert \mathcal{F}_{n})=1-X_{n}$ Show that $P(\lim\limits_{n\to \infty} X_{n}=0 \operatorname{or} 1)=1$ and if $X_{0}=\theta$ then $P(\lim\limits_{n\to \infty} X_{n}=1)=\theta$ I honestly do not know where to begin: $E[1_{\{X_{n+1}=\alpha + \beta X_{n}\}} \vert \mathcal{F}_{n}]=X_{n}$ $E[1_{\{X_{n+1}=\beta X_{n}\}} \vert \mathcal{F}_{n}]=1-X_{n}$ Maybe the tower property could help: $E[E[1_{\{X_{n+1}=\alpha + \beta X_{n}\}}\vert \mathcal{F}_{n+1}] \vert \mathcal{F}_{n}]=X_{n}$ But it leads to nothing.","['measure-theory', 'real-analysis', 'martingales', 'probability-theory', 'probability']"
3381016,What is that $t$ in $E[e^{itX}]$?,"I'm looking at the Characteristic Function Of A Random Variable. I don't understand why it's less than or equals to 1, since I see Mean Function on Random Variable ( $E[e^{iX}]$ ), which might be bigger than 1. And t, which I don't understand in the first place is my 1st suspect.
Could someone explain me the role of that $t$ ? Referring to my latest comment after research on my own question, on How do the complex functions get built (here: How from Fourier Transform with imaginary numbers we get the one with real numbers? ).","['statistics', 'characteristic-functions']"
3381053,"For polyhedron $P$, vector $a$, scalar $b$, prove that $Q:=\{x\in P:a^tx\leq b\}$ is a polyhedron. Also, can $Q=P$?","Let $P$ be a polyhedron in $\mathbb{R}^n, a\in\mathbb{R}^n$ a vector, and $b\in\mathbb{R}$ a scalar. Consider the set $Q=\{x\in P:a^tx\le b\}$ $a)$ Prove that $Q$ is a polyhedron $b)$ Is it always possible to choose $b$ in such way so that $Q=P$ ? Explain your answer Definition of polyhedron A polyhedron is the intersection of finitely many halfspaces: $$P=\{x∈\mathbb{R}^n,a^tx≤b\}$$ $a)$ Proof Let $Q:=\{x\in P:a_0^tx\le b\}$ Show that $Q$ is the intersection of finitely many half-spaces Since $P$ is a polyhedron we have $$\exists a_1^t\dots a_n^t\in\mathbb{R}^n,c_1\dots c_n\in\mathbb{R},s.t.$$ $$P=\{x\in\mathbb{R}^n:a_1^tx\le c_1\}\cap\dots\cap\{x\in\mathbb{R}^n:a_n^tx\le c_n\}$$ $$=\{x∈\mathbb{R}^n:a_1^tx≤c_1\wedge\dots\wedge a_n^tx\le c_n\}$$ Then $$Q=\{x\in P:a_0^tx\le b\}=\{x\in \mathbb{R}^n:x\in P\wedge a_0^tx\le b\}$$ $$=\{x\in \mathbb{R}^n:a_0^tx\le b\wedge a_1^tx≤c_1\wedge\dots\wedge a_n^tx\le c_n\}$$ $$=\{x\in \mathbb{R}^n:a_0^tx\le b\}\cap\{x\in\mathbb{R}^n:a_1^tx\le c_1\}\cap\dots\cap\{x\in\mathbb{R}^n:a_n^tx\le c_n\}$$ Which is the intersection of finite many half-spaces. $\tag*{$\square$}$ $b)$ No, consider case $n=1$ in $\mathbb{R}^2$ , if $P=\{x∈\mathbb{R}^2:x_1+x_2≤0\},Q=\{x\in P:x_1-x_2\le b\}$ Where $b\in\mathbb{R}$ Then $$Q=\{x∈\mathbb{R}^2:x_1-x_2\le b\wedge x_1+x_2≤0\}$$ For example $\left(\frac{b}{2},-\frac{b}{2}-1\right)$ is in $P$ but not in $Q$ . Since $\frac{b}{2}-\frac{b}{2}-1≤0$ that $\left(\frac{b}{2},-\frac{b}{2}-1\right)\in P$ But $\frac{b}{2}-\frac{b}{2}-1≤0\wedge\frac{b}{2}-(-\frac{b}{2}-1)\le b$ is false that $\left(\frac{b}{2},-\frac{b}{2}-1\right)\not\in Q$ for any real $b$ . That proves sometimes $$\forall b\in\mathbb{R},Q\neq P$$ $\tag*{$\square$}$ $\dots$ Is my proof correct ? Any suggestions would be appreciated. Also please tell me if there is a better method to prove it. Thanks for your help.","['polytopes', 'discrete-geometry', 'polyhedra', 'proof-verification', 'elementary-set-theory']"
3381071,"Given $W=ULV^T$ and a vector $\mathbf{x}$, can we compute $UL^kV^T\mathbf{x}$ without doing the SVD, for any integer k?","Consider a matrix $W \in \mathbb{R}^{n\times m}$ with corresponding singular value decomposition, $W = ULV^T$ ,  and a vector $\mathbf{x} \in \mathbb{R}^{m}$ . Is it possible to compute matrix-vector-products of the form $U L^k V^T \mathbf{x}$ without explicitly computing the SVD? If $k$ is odd, this is easy. For example, $W W^{T} W\mathbf{x} = UL^3V^T\mathbf{x}$ . But I can't see an obvious way to solve this for even powers. For context, I want to avoid the SVD as computing the matrix vector products will typically be much cheaper (e.g. for $k \ll n)$ . Ideally, a working algorithm would have complexity $O(kmn)$ instead of $O(mn^2 + nm^2)$ .","['numerical-linear-algebra', 'linear-algebra', 'svd']"
3381099,Is $\sum_{n=1}^{\infty} 1 = -\frac{3}{12}$ true? [duplicate],"This question already has answers here : How to derive $\sum_{n=0}^\infty 1 = -\frac{1}{2}$ without zeta regularization (7 answers) Closed 4 years ago . Here is how I derived this... $$1+2+3+4+...=-\frac{1}{12}$$ $$2+4+6+8+...=2(1+2+3+4+...)=2(-\frac{1}{12})=-\frac{1}{6}$$ Thus $1+3+5+7+...=-\frac{1}{6}-(1+1+1+...) $ because $S_{odd}=S_{even}-(1+1+1+...)$ Also $S_{odd}=(1+2+3+4+...)-(2+4+6+8+...)=-\frac{1}{12}+\frac{1}{6}=\frac{1}{12}$ Thus $\frac{1}{12}=-\frac{1}{6}-(1+1+1+...)$ $$1+1+1+...=-\frac{3}{12}$$ What I think my mistake was (if I have one) is where I assume the sum of all numbers is half the sum of all even numbers; although, it should work since there is nothing two times infinity. Please leave  simple solution (im only 15 years old) to why this is false: Wikipedia says that $\sum_{n=1}^{\infty} 1 = \infty$ . Edit : I know now that the above notion is false. I recently watched a Numberphile video proving $\sum_{n=1}^{\infty} n = -\frac{1}{12}$ . I followed the same line of reasoning to derive the untrue $\sum_{n=1}^{\infty} 1 = -\frac{3}{12}$ I'll admit; I was ignorant in believing so and I apologize for wasting your time. Thanks for the answer kindly explaining why I was wrong. I guess I should watch this video to un-brainwash me. Sorry again.","['divergent-series', 'summation', 'sequences-and-series']"
3381219,$\mathbb{N} ⊇ A_1 \supset A_2 \supset A_3 \supset \cdots$ but $\bigcap_{n=1}^∞ A_n$ is infinite?,"What is an example of an infinite intersection of infinite sets is infinite? I know that the intersection of infinite sets does not need to be infinite. However, I am seeking for an explicit example where it is infinite I was thinking A n = { [n,infinity) }","['elementary-set-theory', 'natural-numbers', 'infinity']"
3381263,Some basic doubts about partial differentiation - PART I,"EDIT : I had earlier asked four doubts together and I thought that maybe I should ask some of them in a separate question. I have some very basics doubts about partial differentials .... Doubt #1 : What is the correct mathematical interpretation of the statement "" $x$ and $y$ are independent variables"" ? Does it mean $\large \frac {\partial x}{\partial y}=\frac{\partial y}{\partial x}=0$ ? According to my understanding of independent variables, if $x$ and $y$ are given to be independent, then any change in $y$ and $y$ only should not cause any change in $x$ . So $ \large \frac{\partial x}{\partial y}$ must be zero. Similar logic for $\large \frac {\partial y}{\partial x} =0$ . Is it okay to use this logic ? Doubt #2 : : Under what circumstances is $\large\frac{\partial x }{\partial y} = \Large \frac{1}{\frac{\partial y}{\partial x}}$ valid? These doubts have become a real hinderance to my understanding of partial derivatives. I need some insightful examples so that I can understand the subtleties that I am currently overlooking. Rest of the doubts can be found here : Some basic doubts about partial differentiation - PART II","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
3381271,How does well-ordering theorem apply to real numbers if real numbers are not countable?,"From what I understand, the well-ordering theorem assumes ANY set can be made well-ordered depending on how you define the ordering. For example, $\mathbb{Z}$ is not well-ordered according to the conventional ordering of (<). But, if we define a new ordering, say ( $\prec$ ), s.t. for any $a,b \in \mathbb{Z}$ , we have $a \prec b$ whenever $|a| \le |b|$ , then we can order the set of integers as $\{0, 1 ,-1, 2,-2,3, -3,...\}$ and thus make the set well-ordered. Under this new ordering the least element is $0$ , and every nonempty subset will also have a least element. If the well-ordering axiom is true, then there exists an ordering s.t. the $\mathbb{R}$ are also well-ordered, but how is this possible given the $\mathbb{R}$ is uncountable? In other words, if there was such an ordering, say ordering $(@)$ , then that ordering would effectively be a function makes the reals listable, would it not? Under $@$ , there would be some number, say $n_1$ , that would be the least element of $\mathbb{R}$ ... and another number, $n_2$ , that would be the least element of $\mathbb{R}-\{n_1\}$ ... and another number, $n_3$ , that would be the least element of $\mathbb{R}-\{n_1,n_2\}$ , and so on and so forth... but we know the reals cannot be placed into a one-to-one correspondence with $\mathbb{N}$ as $n_1,n_2,n_3$ ,... This seems like a contradiction to me. Can anyone resolve this for me without getting too steeped in jargon and notation? Thanks.","['elementary-set-theory', 'well-orders']"
3381283,Find the value of $\sum\limits_{n=1}^{\infty} \frac{2^{n}}{x^{2^n}+1}$,Find the value of $$\sum\limits_{n=1}^{\infty} \frac{2^{n}}{x^{2^n}+1}$$ I recently came across a question in which we had to find the value of the above question. The question seemed simple at first glance but the term $2^n$ in the numerator is posing me with a problem. I could neither reduce it to a telescopic series nor could I compare it with any standard expansion. I've run out of ideas. Would someone please help me to solve this problem? Thanks for help.,['sequences-and-series']
3381333,Can elliptic curve over non-perfect field be reduced to Weierstrass form? [duplicate],"This question already has answers here : Elliptic curves classification, including the case of non-perfect fields. (3 answers) Closed 1 year ago . I have been reading 'The Arithmetic of Elliptic Curves' by Silverman. It proves that any elliptic curve defined over a perfect field can be reduced to Weierstrass form, [III.3.1,page 59]. The convention $k$ is perfect is mentioned at the begining of the book. The proof uses the fact that $\bar{k}/k$ is Galois when $k$ is perfect. Hence I don't know how to move the proof to the case $k$ is non-perfect.","['algebraic-curves', 'algebraic-geometry', 'elliptic-curves']"
3381355,Unique existence of horizontal lifts in Principal $G$-bundles,"I wanted to show that for any smooth principal $G$ -bundle $E\xrightarrow\pi B$ any smooth curve $\gamma\colon I\to B$ has a unique horizontal lift from a fixed starting point $u_0\in\pi^{-1}\left(\left\{\gamma\left(0\right)\right\}\right)$ . There are two proofs I could think of/I could find. (Convention: $I=\left[0,1\right]$ ) This is a long question, so even if you have an answer to any subpart, please do comment/answer. Proof 1 Suppose we have an Ehresmann connection $u\mapsto H_u$ on the bundle. Then as we have the map $\mathrm d\pi\vert_u\colon T_uE\to T_{\pi\left(u\right)}B$ we have $T_uE/\mathrm{ker}\,\mathrm d\pi\vert_u\simeq\mathrm{im}\,\mathrm d\pi\vert_u$ . But $\mathrm{ker}\,\mathrm d\pi\vert_u=V_u$ (the vertical subspace) and $T_uE=V_u\oplus H_u$ and $\mathrm{im}\,\mathrm d\pi\vert_u=T_{\pi\left(u\right)}B$ ( $\mathrm d\pi\vert_u$ is surjective as the bundle is locally trivialisable). So we have $H_u\simeq T_{\pi\left(u\right)}B$ . Now for smooth $\gamma\colon I\to B$ , we have the vector field $X_t=\dot\gamma\left(t\right)\equiv_\text{def}\mathrm d\gamma\vert_t\left(1\right)$ . Using the above isomorphism, we have a horizontal vector at every point u such that $\pi\left(u\right)\in\mathrm{im}\,\gamma$ . Choosing a $u_0\in\pi^{-1}\left(\left\{\gamma\left(0\right)\right\}\right)$ We can then find the integral curve of this vector field starting at $u_0$ and this will give a horizontal lift. Questions about this proof How do we guarantee that the integral curve is lift (is it because it has to stay on the submanifold $\pi^{-1}\left(\mathrm{im}\,\gamma\right)$ , is this even a submanifold?)? Do we have an existence theorem for integral curves of vector fields along submanifolds? Or an existence theorem for integral curves of vector fields defined on closed subsets? Any special case relevant here is fine too. Even if we have such an existence theorem, then won't it only give us a solution in some $\left[0,\epsilon\right]$ and not on all of $I$ ? Is there a theorem that will give me the existence of the curve on all of $I$ ? Now suppose what we constructed gives us a horizontal lift $\gamma^\mathrm{h}\colon I\to E$ , then how do we get uniqueness. What I thought is, now that we have a lift, we can apply the next proof to show uniqueness. But this uses the principal $G$ -bundle structure. Can we get uniqueness of horizontal lifts on general bundles with connection? Proof 2 We have a connection form $\omega\colon TE\to\mathrm{Lie}\, G$ ( $\mathrm{Lie}\,G$ is the lie algebra corresponding to the Lie group $G$ ). Let us assume that we have a lift $\tilde\gamma\colon I\to E$ starting at $u_0$ of $\gamma$ . Then any lift can be written as $\tilde\gamma_1\left(t\right)=\tilde\gamma\left(t\right)\cdot g\left(t\right)$ fpr some $g\colon I\to G$ (this follows from freeness and transitivity of the $G$ -action on each fibre). So in particular if a horizontal lift $\gamma^\mathrm{h}$ exists, then it too can we written as $\gamma^\mathrm{h}\left(t\right)=\tilde\gamma\left(t\right)\cdot g\left(t\right)$ . We have \begin{equation}
\omega_{\gamma^\mathrm{h}\left(t\right)}\left(\dot\gamma^\mathrm{h}\left(t\right)\right)=0\Longleftrightarrow\omega_{\gamma^{h}\left(t\right)}\circ\mathrm d\gamma^\mathrm{h}\vert_t=0\Longleftrightarrow\left(\gamma^\mathrm{h}\right)^*\omega=0
\end{equation} Let $a\colon E\times G\to E,a_g\colon E\to E,a_u\colon G\to E$ be defined by $a\left(u,g\right)=a_g\left(u\right)=a_u\left(g\right)=u\cdot g$ . Then \begin{equation}
\mathrm d\gamma^\mathrm{h}\vert_t=\mathrm da_{\tilde\gamma\left(t\right)}\vert_{g\left(t\right)}\circ\mathrm dg\vert_t+\mathrm da_{g\left(t\right)}\vert_{\tilde\gamma\left(t\right)}\circ\mathrm d\tilde\gamma\vert_t
\end{equation} Now, $a_{\tilde\gamma\left(t\right)}=a_{\gamma^\mathrm{h}\left(t\right)\cdot g\left(t\right)^{-1}}=a_{\gamma^\mathrm{h}\left(t\right)}\circ L_{g\left(t\right)^{-1}}$ .
So, $$\omega_{\gamma^\mathrm{h}\left(t\right)}\circ\mathrm d\gamma^\mathrm{h}\vert_t$$ $$=\omega_{\gamma^\mathrm{h}\left(t\right)}\circ\mathrm da_{\gamma^\mathrm{h}\left(t\right)}\vert_e\circ\mathrm dL_{g\left(t\right)^{-1}}\vert_{g\left(t\right)}\circ\mathrm dg\vert_t+\omega_{\gamma^\mathrm{h}\left(t\right)}\circ\mathrm da_{g\left(t\right)}\vert_{\tilde\gamma\left(t\right)}\circ\mathrm d\tilde\gamma\vert_t$$ $$=\mathrm dL_{g\left(t\right)^{-1}}\vert_{g\left(t\right)}\circ\mathrm dg\vert_t+\mathrm{Ad}_{g\left(t\right)^{-1}}\circ\omega_{\tilde\gamma\left(t\right)}\circ\mathrm d\tilde\gamma\vert_t$$ $$=\mathrm dL_{g\left(t\right)^{-1}}\vert_{g\left(t\right)}\circ\left(\mathrm dg\vert_t+\mathrm dR_{g\left(t\right)}\vert_e\circ\left(\tilde\gamma^*\omega\right)_t\right)=0$$ Since $L_g$ is an isomorphism, its derivative is invertible, so we have \begin{equation}
\mathrm dg\vert_t=-\mathrm dR_{g\left(t\right)}\vert_e\circ\left(\tilde\gamma^*\omega\right)_t\Longleftrightarrow \dot g\left(t\right)=-\mathrm dR_{g\left(t\right)}\vert_e\left(\omega_{\tilde\gamma\left(t\right)}\left(\dot{\tilde\gamma}\left(t\right)\right)\right)
\end{equation} Since $\tilde\gamma\left(0\right)=\gamma^\mathrm{h}\left(0\right)=u_0$ , we have $g\left(0\right)=e$ . So we have an ODE for $g$ , and we have a unique solution for $t\in\left[0,\epsilon\right]$ for some $\epsilon$ . We have uniqueness of lift as any lift could have written as $\tilde\gamma\left(t\right)\cdot g\left(t\right)$ . Questions about this proof We have the same extendibility problem as above. Given the final ODE for $g\left(t\right)$ , how do we know it can be found on all of $I$ and not just till some $\epsilon$ . (I know that for matrix groups we can do it using the path-ordered exponential.) How do we know that there is some lift? I tried to prove this as follows. First assume that the image of the curve lies in some open $U$ for which we have a trivialisation $\psi_U\colon \pi^{-1}\left(U\right)\xrightarrow\sim U\times G$ . Then we have the obvious lift starting at $u_0$ given by $\tilde\gamma\left(t\right)=\psi^{-1}\left(\gamma\left(t\right),g_0\right)$ where $\psi\left(u_0\right)=\left(\gamma\left(0\right),g_0\right)$ . Now suppose that the there $\mathrm{im}\,\gamma$ does not lie in a single trivialisation. Let $\left(U_p,\psi_p\colon\pi^{-1}\left(U_p\right)\xrightarrow\sim U_p\times G\right)$ be the local trivialisation of the bundle around $p\in E$ . Then we have a cover for $\mathrm{im}\,\gamma$ given by $\left\{U_p\right\}_{p\in\mathrm{im}\,\gamma}$ . Since $I$ is compact, and $\gamma$ is continuous, $\mathrm{im}\,\gamma$ is compact. So we have a finite subcover $\left\{U_{p_k}\right\}_{k=1}^n$ . Now I tried to inductively create a lift. First take the open set which contains $\gamma\left(0\right)$ , let is be $U_{p_{k_1}}$ . Take the connected component containing $0$ in $\gamma^{-1}\left(U_{p_{k_1}}\right)$ . Let the supremum of this $t_1$ . We can lift $\gamma\vert_{\left[0,t_1\right)}$ , call it $\tilde\gamma$ . Now because $\mathrm{im}\,\gamma$ is connencted, $\gamma\left(t_1\right)$ It will belong to some other open set, let that be $U_{p_{k_2}}$ . Repeat the process and lift this new strand with initial point at $\lim\limits_{t\rightarrow t_1}\tilde\gamma\left(t\right)$ (exists by compactness). repeat this process untill the enitre curve is lifted. Without loss of generality, I can assume that $U_{p_i}$ are simply connected pre-compact. I need to show that $\mathrm{im}\,\gamma\cap U$ has finitely many connected components if $U$ is simply connected and precompact. So this reduces to the following problem: Given a $\gamma\colon I\to\mathbb R^n$ , does $\mathrm{im}\,\gamma\cap B^n_1\left(0\right)$ (where $B$ is the unit ball) have finitely many connected components? I seem to be stuck here.","['connections', 'fiber-bundles', 'ordinary-differential-equations', 'differential-geometry']"
3381382,Function such that $f(f(f(x))) = f(f(x)) \neq f(x)$ [duplicate],"This question already has an answer here : Calculus function create [closed] (1 answer) Closed 4 years ago . Give an example of a function $f\colon\Bbb R\rightarrow \Bbb R$ such that $f\circ f\circ f=f\circ f\neq f$ , that is, $f(f(f(x))) = f(f(x))$ on $\Bbb R$ but $f(f(x))\ne f(x)$ for some $x\in\mathbb R$ .","['functional-equations', 'functions']"
3381414,$(n^2 - 1)!$ is a multiple of $(n!)^n$,"Question: Find all positive integers $n$ such that $(n^2 - 1)!$ is a
  multiple of $(n!)^n$ . I can show that the required condition fails if $n$ is a prime, and by direct computation, it also fails for $n=4$ . After doing a few small examples by hand, I believe that the required answer is 1 and all composites greater than 4. However, I cannot seem to prove this. For each prime $p<n$ , I tried to count the number of appearances of $p$ on both sides, but I get that I am supposed to compare $n(\lfloor{\frac{n}{p}} \rfloor + \lfloor{\frac{n}{p^2}} \rfloor +\dots)$ against $\lfloor{\frac{n^2-1}{p}} \rfloor + \lfloor{\frac{n^2-1}{p^2}} \rfloor + \dots$ , which is not obvious to compare. Any help will be gretaly appreciated.",['number-theory']
3381439,Seeking an explicit solution (using Lambert W?) for $\lambda$ in $2\lambda = \sinh(\lambda)+(1+2\beta)(\cosh(\lambda)-1)$,"Let $\beta\in \mathbb{R}$ , I'm looking for an explicit solution in terms of $\lambda$ to the following equation: $$2\lambda = \sinh(\lambda)+(1+2\beta)(\cosh(\lambda)-1)$$ It seems, numerically, that for $\beta\in [-1,0]$ the equation has three real solutions $(0,\lambda^*_1,\lambda^*_2)$ and for $\beta>0$ or $\beta<-1$ there are two solutions $(0,\lambda^*_3).$ Could there exist expressions of these solutions in terms of Lambert functions by any chance? See my answer below for a conjecture about the general form.","['hyperbolic-functions', 'trigonometry', 'lambert-w', 'random-variables']"
3381445,What does it mean with real manifold with complex structure?,"For example on wikipedia I found that one can also define a Hermitian manifold as a real manifold with a Riemannian metric that preserves a complex structure. For real manifold it should be understood a manifold with real charts, i.e., diffeomorphisms from an open subsets of M and open subsets of $\mathbb{R}^n$ , then what does it mean with complex structure? is only the complexification of its tangent space?","['manifolds', 'complex-geometry', 'differential-geometry']"
3381453,Find all five digit number $\overline{abcde}$ such that $\overline{abcde} = \overline{(ace})^2$,"Find all five digit number $\overline{abcde}$ such that $$\overline{abcde} = \overline{(ace})^2$$ This question popped in my mind while solving other elementary numbers and I have been trying to solve it ever since but without any luck. My Take : Since the digit place of $e^2$ should be equal to digit's place of $e$ , So the only possible values of $e$ are $0,1,5$ and $6$ Also since the First digit of the numbers are equal , We can conclude that the the only possible values of $a=1$ . Hence our number can take the following form : $$(1bcd0),(1bcd1),(1bcd5),(1bcd6)$$ But how do we further solve this? Also Another interesting part of this question would be to solve for $\overline{abcd}$ such that $$\overline{abcd} = \overline{(bd)}^2$$","['number-theory', 'algebra-precalculus', 'modular-arithmetic', 'elementary-number-theory']"
3381465,"For continuous, monotonically-increasing $f$ with $f(0)=0$ and $f(1)=1$, prove $\sum_{k=1}^{10}f(k/10)+f^{-1}(k/10)\leq 99/10$","A question from Leningrad Mathematical Olympiad 1991: Let $f$ be continuous and monotonically increasing, with $f(0)=0$ and $f(1)=1$ .
  Prove that: $$
\text{f}\left( \frac{1}{10} \right) +\text{f}\left( \frac{2}{10} \right) +...+\text{f}\left( \frac{9}{10} \right) +\text{f}^{-1}\left( \frac{1}{10} \right) +\text{f}^{-1}\left( \frac{2}{10} \right) +...+\text{f}^{-1}\left( \frac{9}{10} \right) \leqslant \frac{99}{10}
$$ I tried to express them in areas to find inequalities but failed.","['contest-math', 'inequality', 'functions', 'analysis']"
3381493,How to evaluate the limit for this sequence?,"I need to evaluate the following limit : Suppose that $\displaystyle\lim_{n \to \infty} a_n = a$ then find the Limit : $\displaystyle\lim_{n \to \infty} \left(\dfrac{a_n}{1} + \dfrac{a_{n-1}}{2} + \dfrac{a_{n-2}}{2^2} + \ldots + \dfrac{a_1}{2^{n-1}}\right)$ Since term in denominators forms a Geometric sequence,I am trying to solve this by using Sandwich Theorem to get some insights but I haven't achieved any success . Any idea how should I proceed towards the solution ?","['limits', 'real-analysis']"
3381501,Random walk on infinite group - Entropy Speed and Growth,"Let $\Gamma$ be an infinite, finitely generated group, and $X_n$ a random walk over $\Gamma$ with step distribution $\mu$ . recall the definitions of : Entropy of $X_n$ : $\frac{-\log \mu^{*n}(X_n)}{n} \to h$ , a.s. Speed of $X_n$ : $\frac{\vert X_n \vert}{n} \to \ell$ , a.s. Exponential growth rate of $\Gamma$ : $\beta = \lim_{n\to\infty}\frac{\log \vert B_n\vert}{n}$ , where $B_n$ is the ball of radius $n$ for $\Gamma$ I would like to prove that $h \leq \beta\ell$ Using that $h = \lim\frac{H(X_n)}{n}$ with $H(X_n)$ Shannon entropy of $X_n$ , and that $H(X_n) \leq  \log\vert B_n\vert$ , we have the immediate result that $h\leq \beta$ . I need to introduce the random walk's speed. I've seen this paper , page 8, but the ""proof"" includes at least one big mistake (switching a $\geq$ into a $\leq$ ), and it goes way to fast through Egorov's theorem. Any input on how to prove the inequality? Edit I'm trying to fix the proof in the aforementioned paper. With $H(X_n)\leq \log\vert B_n\vert$ , we know that for any $\gamma>0$ , for $n$ large enough, $$ H(X_n) \leq (\beta +\gamma) n$$ For any $\varepsilon>0$ , we can still split the calculation of $H(X_n)$ as $$H(X_n) = \sum_{x\in B_{n(\ell+\varepsilon)}}p_n(x)(-\log p_n(x))+\sum_{x\not\in B_{n(\ell+\varepsilon)}}p_n(x)(-\log p_n(x))$$ And we can now upper bound the first term using the max entropy $$\sum_{x\in B_{n(\ell+\varepsilon)}}p_n(x)(-\log p_n(x)) \leq (\beta+\gamma)(\ell+\varepsilon)n$$ In order to conclude I only need to understand the section about Egorov's Theorem, and the fact that $$\vert X_n(\omega)\vert\leq n(\ell+\varepsilon)$$ uniformly for $\omega\in E$ , where $E$ is an event with $\mathbb{P}(E)\geq 1-\varepsilon$ , leading to $$  \mathbb{P}\left(X_n \not\in B_{n(\ell+\varepsilon)}\right) \leq \varepsilon$$ I don't even understand the notation $X_n(\omega)$ , any idea? Edit 2 I think we could use the argument : Because $\vert X_n\vert / n$ tends to $\ell$ almost surely, then it also converge in probability, and for any $\varepsilon>0$ , for $n$ large enough $$ \mathbb{P}\left[ \vert X_n\vert\leq n(\ell+\varepsilon)\right] = 1$$ And then $$\mathbb{P}[X_n\in B_{n(\ell+\varepsilon)}]=1 $$ Then we should be able to conclude : $$ h \leq (\beta+\gamma)(\ell+\varepsilon)$$ True for any $\gamma>0$ and any $\varepsilon>0$ hence $$ h \leq \beta+\ell$$ I will write the full argument in a neat answer, and I will post it tomorrow if noone contradicts me before.","['group-theory', 'infinite-groups', 'random-walk']"
3381530,Are gradient flows the quickest way to minimize a function for a short time?,"Let $F:\mathbb{R}^n \to \mathbb{R}$ be a smooth function, and let $p \in \mathbb{R}^n$ . Let $\alpha(t)$ be the solution to the negative gradient flow of $F$ , i.e. $$ \alpha(0)=p, \, \, \dot \alpha(t)=-\nabla F(\alpha(t)).$$ Let $\beta(t)$ be a smooth path starting at $p$ (i.e. $\beta(0)=p$ ) and suppose that $\|\dot \beta(t)\|=\|\dot \alpha(t)\|$ . Is it true that $F(\alpha(t)) \le F(\beta(t))$ for sufficiently small $t$ ? We can assume that $\nabla F(p) \neq 0$ , since otherwise $\alpha$ is constant, and then $\|\dot \beta \|=\|\dot  \alpha\|=0$ implies $\beta$ is also constant. It is easy to see that the answer is positive if $\dot \beta(0) \neq -\nabla F(p)$ (see details below). I am not sure what happens when $\dot \beta(0) = -\nabla F(p)$ . Details: Write $G(t)=F(\beta(t))-F(\alpha(t)) $ . Then, $G(0)=0$ , and $$G'(0)=\langle \nabla F(p),\dot \beta(0) \rangle-\langle \nabla F(p),\dot \alpha(0) \rangle=\langle \nabla F(p),\dot \beta(0) \rangle+\|\nabla F(p)\|^2 \ge 0,$$ Since by the C-S inequality, we have $\langle \nabla F(p),\dot \beta(0) \rangle \ge - \|\nabla F(p)\| \cdot \|\dot \beta(0)\|=-\|\nabla F(p)\| \cdot \|\dot \alpha(0)\|=-\|\nabla F(p)\|^2$ , with equality if and only if $\dot \beta(0)=-\lambda  \nabla F(p)$ for some positive scalar $\lambda$ . So, we showed that if $\dot \beta(0) \neq -\nabla F(p)$ , then $G(0)=0,G'(0) >0$ , hence $G(t)>G(0)$ . Analysis of the case $\dot \beta(0) = -\nabla F(p)$ : Writing $$G'(t)=\langle \nabla F(\beta(t)),\dot \beta(t) \rangle-\langle \nabla F(\alpha(t)),\dot \alpha(t) \rangle$$ we get $$G''(t)= d^2F_{\beta(t)}(\dot \beta(t),\dot \beta(t))+\langle \nabla F(\beta(t)),\ddot \beta(t) \rangle -d^2F_{\alpha(t)}(\dot \alpha(t),\dot \alpha(t))-\langle \nabla F(\alpha(t)),\ddot \alpha(t) \rangle,$$ so $$ G''(0)= d^2F_{p}(-\nabla F(p),-\nabla F(p))+\langle \nabla F(p),\ddot \beta(0) \rangle -d^2F_{p}(-\nabla F(p),-\nabla F(p))-\langle \nabla F(p),\ddot \alpha(0) \rangle=\langle \nabla F(p),\ddot \beta(0) -\ddot \alpha(0) \rangle. \tag{1}$$ Now, we use our assumption that $\langle \dot \beta(t),\dot \beta(t) \rangle=\langle \dot \alpha(t),\dot \alpha(t) \rangle$ . Differentiating this, we obtain $$ \langle \dot \beta(0),\ddot \beta(0) \rangle=\langle \dot \alpha(0),\ddot \alpha(0) \rangle \tag{2},$$ which really means $$ \langle \nabla F(p),\ddot \beta(0) \rangle=\langle \nabla F(p),\ddot \alpha(0) \rangle. \tag{3}$$ Combining $(1)$ and $(3)$ implies that $G''(0)=0$ , so this does not seem to help us. Do we need to proceed to third derivatives? It seems interesting to see if using $\|\dot \beta \|=\|\dot  \alpha\|$ we can express neatly $G'''(0)$ . Edit: As commented by Anthony Carapetis, this ""differential analysis"" approach is doomed to fail: Indeed, if we want to show $G(t)\ge 0$ by examining derivatives of $G$ at zero, we will have to show that the first non-zero derivative is strictly positive. However, $\alpha$ and $\beta$ may have arbitrarily many derivatives agreeing at zero. (they can even agree on the derivatives of all orders).","['gradient-flows', 'multivariable-calculus', 'optimization', 'gradient-descent', 'differential-geometry']"
3381551,Multiplicities following Weil (Mumford's & Oda's AG II),"I'm reading the proof of 7.5 from Mumford's & Oda's Algebraic Geometry II on page 198 and I'm a little confused about an argument. Let $X$ be a noetherian integral scheme, $x \in X$ a formally unibranch point. Let $f : Y \to X$ be a morphism of finite type and let $y$ be an isolated point of $f^{−1}(x)$ . Then we define $mult_y(f)$ as follows: Let $R = \hat{\mathcal{O}}_{x,X}/ \sqrt{(0)}$ : By assumption this is an
  integral domain. Let $K$ be quotient field of $R$ . Form the fibre product $Y':= Y \times_X Spec \text{ } R$ . Let $y′ \in Y′$ be the unique point over $y$ . define $mult_y(f):= \dim_K(\mathcal{O}_{y',Y'} \otimes_R K)$ . let $Y_1':=Spec \text{ } \mathcal{O}_{y',Y'}$ . because $y$ is a isolated point we can decompose disjointly $Y'=Y'_1 \cup Y' _2$ . Two futher quantities are introduced in the preparation and play in 7.5 & my question essential role: ${\text{mult}_y}^{\circ}(f)$ satisfying $mult_y(f) = [\mathbb{k}(y):\mathbb{k}(x)]_s{\text{mult}_y}^{\circ}(f)$ and let $\widetilde{\mathcal{O}}$ be the finite étale extension of $\hat{\mathcal{O}}_{x,X}$ with residue field $L$ , as in Corollary IV.6.3. recall that $\mathbb{k}(x)$ is the residue field of $\mathcal{O}_{x,X}$ . these all quantities occuring in 7.5. Assume $X$ is formally normal at $x$ and that all associated points of $Y$ lie over $η_X$ . Then ${\text{mult}_y}^{\circ}(f)=1$ if and only if $f$ is étale at $y$ . the interesting part is ${\text{mult}_y}^{\circ}(f)=1$ implies $f$ is étale at $y$ . beginning with this assumtion the proof shows that $\mathcal{O}_{y',Y'} \cong \widetilde{\mathcal{O}}$ . this implies that that the expression $R \to \widetilde{\mathcal{O}}$ make sense. after that the author gives following chain of isomorphisms: $$(\Omega_{Y/X})_y \otimes_{\mathcal{O}_{y,Y}} \mathbb{k}(y) \cong (\Omega_{Y_1 '/Spec \text{ } R}) \otimes_{\mathcal{O}_{y',Y'}} \mathbb{k}(y) \cong $$ $$(\Omega_{Spec \text{ } \widetilde{\mathcal{O}}/Spec \text{ } R})\otimes_{\widetilde{\mathcal{O}}} L = (0)$$ Q: the last two equalities I not understand. the first one is simply base change rule for differential: Suppose that we have ring maps $R\to R′$ and $R\to S$ . Set $S′=S \otimes R′$ , then $\Omega_{S/R} \otimes_RR′=\Omega_{S′/R′}$ .  the last one seems to use as essential ingredient that by construction $\widetilde{\mathcal{O}}$ is finite étale over $\hat{\mathcal{O}}_{x,X}$ , is $\widetilde{\mathcal{O}}$ also étale over $R$ ? is that true?","['algebraic-geometry', 'schemes']"
3381620,Showing that two combinatorial expressions are equal,"Is there an algebraic way of showing that $$\sum_{m=\lceil p / b\rceil}^{c} \left(-1\right)^m \frac{\binom{b\cdot m}{p}}{\binom{b\cdot c}{p}} \sum_{k=m}^{c}k\cdot(-1)^{k} \binom{c}{k} \binom{k}{m} = c\cdot\left[1 - \frac{\binom{b\cdot[c - 1]}{p}}{\binom{b\cdot c}{p}}\right], $$ for all positive integers $b$ , $c$ , $p$ ? Background: A friend sent me a puzzle, which I've solved in two different ways, and I'd like to convince myself that they're algebraically the same. Specifically, I was asked to consider the following problem: Suppose we have 80 balls in a bowl of 8 different colours, with 10 of each colour. If we draw 15 of them without replacement, how many colours would we expect to see? Method 1: We can find the expected number of colours as the weighted average of the possible number of colours, with the weights being the probabilities: $\bar{k} = \sum_{k} k \cdot P_k$ . To do this we need to calculate the probabilities of seeing exactly $k$ colours for all possible values of $k$ . The probability of using just one colour is 0, as $15 > 10$ . The probability of using exactly two colours is $\binom{8}{2} \cdot \frac{\binom{20}{15}}{\binom{80}{15}}$ . The probability of using exactly at most three colours is $\binom{8}{3} \cdot \frac{\binom{30}{15}}{\binom{80}{15}}$ .This probability however includes some cases where we've picked only two colours. To get the probability of picking exactly three colours, we need to subtract these cases, giving: $\binom{8}{3} \cdot \left[\frac{\binom{30}{15}}{\binom{80}{15}} - \binom{3}{2}\frac{\binom{20}{15}}{\binom{80}{15}}\right]$ . Using the inclusion-exclusion principle, the general probability of getting exactly $k$ colours is $$ 
  P_k = (-1)^{k} \frac{\binom{8}{k}}{\binom{80}{15}} \sum_{m=2}^{k}\left(-1\right)^m \binom{k}{m}\binom{10m}{15}
$$ The expected number of colours can then be written as $$ \begin{align}
    \bar{k}  &= \sum_{k=2}^8k\cdot(-1)^{k} \frac{\binom{8}{k}}{\binom{80}{15}} \sum_{m=2}^{k}\left(-1\right)^m \binom{k}{m}\binom{10m}{15}\\
    &= \sum_{m=2}^{8} \left(-1\right)^m \frac{\binom{10m}{15}}{\binom{80}{15}} \sum_{k=m}^8k\cdot(-1)^{k} \binom{8}{k} \binom{k}{m}.
\end{align}  $$ Method 2 Alternatively, I reasoned that for any given colour, the probability of having that colour in the draw is $P_{\mathrm{c}} = 1 - \frac{\binom{70}{15}}{\binom{80}{15}}$ . If the colour is included, it contributes 1 to the total number of colours, and if not, it contributes 0. The expected value of the number of colours is then $$
    \bar{k} = \sum_{\mathrm{colours}} P_{\mathrm{c}} = 8 - 8 \frac{\binom{70}{15}}{\binom{80}{15}}
$$ I can calculate both of these numbers, and for this particular case, they are the same. What I'd like is to understand why they should be equal in general -- there's nothing in the derivations which limits us to 8 colours, 10 balls of each colour and 15 picks. It's been a while since I had any combinatorics, so I'm a bit stuck","['inclusion-exclusion', 'puzzle', 'combinatorics']"
3381646,Integral $\int_0^1 \frac{2x-1}{1+x-x^2}\left(4\ln x\ln(1+x)-\ln^2(1+x)\right)dx$,"The following problem was posted earlier this year by Cornel Ioan Valean: Prove that $$I=\int_0^1 \frac{2x-1}{1+x-x^2}\left(4\ln x\ln(1+x)-\ln^2(1+x)\right)dx=\frac{127}{20}\zeta(3)-\frac{8\pi^2}{5}\ln(\varphi)$$ My idea was to consider the following integral: $$\mathcal J(a)=\int_0^1 \frac{2x-1}{1+x-x^2}\ln(a+x)\ln(1+x)dx$$ So $I=4\mathcal J(0)-\mathcal J(1)$ . In order to evaluate $\mathcal J(a)$ I tried to apply Feynman's trick: $$\mathcal J'(a)=\int_0^1 \frac{\ln(1+x)}{a+x}\frac{dx}{\varphi-x}-\int_0^1 \frac{\ln(1+x)}{a+x}\frac{dx}{\frac{1}{\varphi}+x},\quad \varphi=\frac{1+\sqrt 5}{2}$$ $$\small =\frac{1}{a+\varphi}\int_0^1 \frac{\ln(1+x)}{a+x}dx+\frac{1}{a+\varphi}\int_0^1 \frac{\ln(1+x)}{\varphi-x}dx+\frac{1}{a-\frac{1}{\varphi}}\int_0^1 \frac{\ln(1+x)}{a+x}dx-\frac{1}{a-\frac{1}{\varphi}}\int_0^1 \frac{\ln(1+x)}{\frac{1}{\varphi}+x}dx$$ But I gave up on this idea after I realised that: $$\int_0^1 \frac{\ln(1+x)}{t+x}dx=\ln 2\ln \left(\frac{t+1}{t-1}\right)+\operatorname{Li}_2\left(\frac{2}{1-t}\right)-\operatorname{Li}_2\left(\frac{1}{1-t}\right)$$ Where $\operatorname{Li}_2(x)$ is the Dilogarithm.
Other methods weren't promising either, such as the substitution $x=\frac{1-t}{1+t}$ , to combine the integral with it's sister one that has the denominator $1-x+x^2$ , or to integrate by parts which gives: $$\small 2I=2\int_0^1 \frac{\ln(1+x-x^2)\ln x}{1+x}dx+2\int_0^1 \frac{\ln(1+x-x^2)\ln(1+x)}{x}dx-\int_0^1 \frac{\ln(1+x-x^2)\ln (1+x)}{1+x}dx$$ I believe that the factor of $4$ plays a big role into obtain nicely this result and one shouldn't split the integral into two parts, but I had no success and I would appreciate some help.","['integration', 'definite-integrals', 'closed-form', 'logarithms']"
3381677,Is possible to show that the linear operator $T(\varphi)(x) = \int_{V_x\cap M} \varphi(y)\text{d}y$ has spectral radius $>0$.,"Fix some $σ>2/(3\sqrt{3})$ , let $M$ be the interval $[x_-,x_+]$ , where $$x_- = \text{unique real root of 
 $x^3 + \sigma = x$}$$ and $$x_+ = \text{unique real root of 
 $x^3 - \sigma = x$}.$$ Moreover, define the set $$V_x=\{z\in \mathbb{R};\ z = x^3+\omega \sigma,\ \mbox{for some $\omega\in[-1,1]$}\}.$$ Consider the Banach Space $\left(\mathcal C^0(M),\|\cdot\|_\infty\right)$ . Where $$\mathcal C^0(M):=\{f:M\to\mathbb{R};f\ \text{is continuous}\}\ \mbox{and }\|\phi\|_\infty=\sup_{x\in M}|\phi|.$$ Now, define the continuous linear map \begin{align*}
T: \mathcal C^0(M)&\to \mathcal{C}^0 (M)\\
\varphi&\mapsto \left(x\mapsto\int_{V_x\cap M}\varphi(y)\text{d} y\right).
\end{align*} My Question: Is it possible to guarantee that the continuous linear operator $T$ has a positive spectral radius? Remark: It is possible to show that $T$ is a compact operator.","['banach-spaces', 'function-spaces', 'spectral-radius', 'linear-algebra', 'functional-analysis']"
3381705,A conical tent is made by using a semi-circular piece of canvas of radius 8 feet.,"A conical tent is made by using a semi-circular piece of canvas of radius 8 feet. Find the height of the tent and the number of cubic feet of air inside. By manipulating I have found a way to get to the solutions provided by the textbook (that is $h = 4\sqrt{3}$ and $V = \frac{64}{3}\sqrt{3}\pi$ )  but I do not understand them. Here is what I have done so far Let A be the area of the semi-circular piece of canvas of radius 8 so that $ A = \frac{1}{2}\pi r^2 = \frac{1}{2}\pi 8^2 = 32\pi$ Using the formula for the lateral area of a cone we have $\pi rs = A = 32\pi\implies s = \frac{32\pi}{8\pi} = 4$ This is where I am stuck because I have a slant height smaller than the radius. However if I keep pushing forward I get $s^2 = h^2 + r^2 \implies h^2 = s^2 - r^2 = 4^2 - 8^2 \implies h = \sqrt{|-48|} = 4\sqrt{3}$ I am quite close to the solution, but I cannot find a way to set up the problem correctly.","['algebra-precalculus', 'geometry', 'volume']"
3381719,How many ways can you choose 12 items from 8 items types if you choose at least one of each type?,"For example, how many ways can you choose $12$ items from $8$ item types? One possibility is that you choose every item from just one of the types. But what if we have the restriction that we must have at least $1$ of each type? The way I think of this is that $8$ out of our $12$ choices are locked in, so we only have freedom in choosing the remaining $4$ items, and so the answer is $8$ multichoose $4$ , and the calculation is carried out as $$\frac{11!}{4!7!}= 330$$ Does this make sense? Any help is appreciated!","['multisets', 'combinatorics', 'discrete-mathematics']"
3381728,Find closest power of 2 to a specific number,"This question is weird and it's not a homework question. I couldn't come up with anything substantial, so sorry if you think that I should have posted my tried methods (I have tried but most of them were fails). So, suppose I have a number $n$ . Its parity doesn't matter(whether it is even or odd is to no interest to us). Just by having $n$ is there a way to find $2^m$ where when $2$ raised to the power of $m$ , it is the value that is closest to $n$ ? Like for example, if $n = 7$ then the closest power of $2$ is $2^3$ which is $8$ . But my question is: Is there a function with which I can calculate this? If there was something that I failed to represent and as a result, you didn't understand, please comment. Also, I don't know the tag to put this in, somebody please help me.",['algebra-precalculus']
