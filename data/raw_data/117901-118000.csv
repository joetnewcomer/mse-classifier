question_id,title,body,tags
1746712,"isomorphism between $C[0,1]$ and $C^1[0,1]$","Is space $C[0,1]$ with norm $\parallel f \parallel=\max|f(x)|$ (space of continuous functions on $[0,1]$) isomorphic to space $C^1[0,1]$ with norm $\parallel f \parallel=\max|f(x)|+\max|f'(x)|$ (space of continuously differentiable functions on $[0,1]$) ? Under isomorphism I mean continuous linear bijective operator between these two spaces (and also the inverse is continuous). If yes, is there any explicit example of such isomorphism ? Thank you very much for Your answers.","['functional-analysis', 'banach-spaces']"
1746743,Prove that trees have at least two vertices of degree one,"Prove that every tree with $n\geq 2$ vertices has at least two vertices of degree one. What I tried: Suppose that there are fewer than two vertices of degree one. So we can split into two cases. Case one: there is no vertex of degree one. Since we know that every tree has $n-1$ edges then the total degree of any tree have to be $2(n-1)$ . But for this case since no vertex have degree $1$ then every vertex have at least a degree of $2$ and since there are $n$ vertices, the total degree is $\geq 2n$ which is a contradiction. Case two: there is only one vertex of degree one. Similarly  the total degree of any tree have to be $2(n-1)$ . Then there are $(n-1)$ vertices with which have degree of $\geq 2$ while only one vertex with degree of one. Thus summing up to find the total of the vertices, we have that the total degree of vertices is $\geq 2(n-1)+1=2n-1$ which is also a contradiction. This thus proves the statement for both cases. Is my proof correct? Could anyone explain better?","['graph-theory', 'proof-verification', 'discrete-mathematics']"
1746748,Which is easier to integrate?,"My calculus teacher gave us this problem in class: Which is easier to integrate? $$\int \sin^{100}x\cos x dx$$ or $$\int \sin^{50}xdx$$ By easier, I assume the teacher means which integral would take less work. I'm unsure of how to approach this problem because of the relatively large exponents. I would guess the second because it has smaller exponents but I'm not sure.","['integration', 'calculus']"
1746763,Is the notion of a proper map useful between non-locally-compact spaces?,"Recall that a map $f: X \to Y$ between topological spaces is called proper if, for every compact $K \subseteq Y$, $f^{-1}(K)$ is compact. It strikes me that this definition is unlikely to be useful if $Y$ doesn't have ""enough"" compact subsets. And it's likely to be ""too restrictive"" if $X$ doesn't have ""enough"" compact subsets. This is born out in the intuitive picture (cf. wikipedia ) which says that if $f: X \to Y$ is proper, and $\{x_i\}$ is a sequence which ""escapes to infinity"" in the sense that any compact $K \subseteq X$ contains at most finitely many of the $x_i$'s, then the sequence $\{f(x_i)\}$ escapes to infinity in the same sense. This notion could be modified to use nets instead of sequences, but it would still be the wrong notion of ""escape to infinity"" in a non-locally-compact space -- for example, in this sense an orthonormal basis of $\ell_2(\mathbb{N})$ ""escapes to infinity"". So this intuitive picture really only works for locally compact spaces, where it essentially says that $f$ extends to a map between 1-point compactifications sending $\infty$ to $\infty$. Hence the question: is the notion of a proper map useful when one is working with non-locally-compact spaces? For example, are there any interesting theorems whose hypotheses ask that a map be proper without asking that the spaces involved be locally compact? If not, is there some sort of ""substitute"" notion which does work well for spaces that are not locally compact? (It would be nice, but not necessary, for such a substitute notion to agree with properness on locally compact spaces.)",['general-topology']
1746772,Continuous strictly increasing function with derivative infinity at a measure 0 set,"Let $E\subset [0,1]$ with $\mu(E)=0$. Does there exist a continuous, strictly increasing function $f$ on $[0,1]$ so that $f'(x)=\infty$ for all $x\in E$ (in Lebesgue sense)? I think there exist such a function, but I don't know how to construct.","['derivatives', 'real-analysis', 'lebesgue-measure', 'measure-theory', 'analysis']"
1746794,Finding the number of ordered pairs of integers (Discrete Maths),"Let $k$ and $n$ be positive integers such that $k\le n$ (i) How many ordered sequences of integers ($a_{1}$,$a_{2}$,...$a_{k}$) are there such that $a_{1}$,$a_{2}$,...$a_{k}$$\in $(1,2...n) (ii) How many ordered sequences of integers ($a_{1}$,$a_{2}$,...$a_{k}$) are there such that $a_{1}$,$a_{2}$,...$a_{k}$$\in $(1,2...n) and $a_{1}$,$a_{2}$,...$a_{k}$ are pairwise distinct? (iii)How many ordered sequences of integers ($a_{1}$,$a_{2}$,...$a_{k}$) are there such that $a_{1}$,$a_{2}$,...$a_{k}$$\in $(1,2...n) and $a_{1}$,$a_{2}$,...$a_{k}$ contain only one ordered pair? (iv))How many ordered sequences of integers ($a_{1}$,$a_{2}$,...$a_{k}$) are there such that $a_{1}$,$a_{2}$,...$a_{k}$$\in $(1,2...n) and $a_{1}\lt a_{2}...\lt a_{k} $ ? (v))How many ordered sequences of integers ($a_{1}$,$a_{2}$,...$a_{k}$) are there such that $a_{1}$,$a_{2}$,...$a_{k}$$\in $(1,2...n) and $a_{1}\le a_{2}...\le a_{k} $ ? What i tried (ii) pairwise distinct means that the integers can be group onto a pair with each pair being different from one another, thus we are group indistinguishable integers into distinguishable pair. Thus there are $k^{n}$ ways. (iii) Ordered pair have got something to do with permutations so i think it is $k$ permutate $n$ (iv) While this part means that the integers must be arranged in order form the smallest to the biggest Im unsure of how to do these questions. Could anyone explain. Thanks","['combinatorics', 'discrete-mathematics']"
1746795,How can I get f(x) from its Maclaurin series?,"I know how to get a Maclaurin series when $f(x)$ is given. I have to find $\sum_{n=0}^{\infty}\frac{f^{(k)}(0)}{k!}x^k$. But how can I get $f(x)$ from its Taylor series? The problem is $$f(x) = \sum_{n=0}^{\infty} C_n x^n,$$ where $C_n$ is a Catalan number defined by $C_n = \frac{1}{n+1}\binom{2n}{n}$. How can I get $f(x)$?","['combinatorics', 'taylor-expansion', 'combinatorial-proofs']"
1746926,$\int_0^\infty {x^a\over (x^2+1)^2} dx$ where $0<a<1$. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question $\int_0^\infty {x^a\over (x^2+1)^2} dx$ where $0<a<1$. I know I can use partial fraction decomposition to obtain two different integrals, but I'm not sure how to integrate them. Any solutions or hints are greatly appreciated.","['real-analysis', 'calculus', 'complex-analysis', 'integration', 'analysis']"
1746931,Differentiating $h(x) = x f(x) + g(x)$,"If i have a definition like this: $h(x) := x f(x) + g(x)$ What would $h'(x)$ be? Without the $x$ preceeding $f(x)$, it would just be 
$h'(x) := f'(x) + g'(x)$, right? How does it work with the preceeding $x$, which i believe spells ""$x$ times $f(x)$""?",['ordinary-differential-equations']
1746976,why is the geometric mean less than the logarithmic mean? [duplicate],"This question already has answers here : Proof of the following inequality $ \frac{x - y}{\log x - \log y} > \sqrt{xy} $, $x>y$. (6 answers) Closed 4 years ago . Can someone explain why the geometric mean is less than the logarithmic mean?
$$\sqrt{ab} \leq  \frac{b-a}{\log b-\log a}
$$","['statistics', 'calculus']"
1747010,"Computing (the ring structure of) $\mathrm{Ext}^\bullet_R(k,k)$ for $R=k[x]/(x^2)$","Let $k$ be some field (say of characteristic zero, if it matters) and define $$R=k[x]/(x^2).$$
I want to compute $$\mathrm{Ext}^\bullet_R(k,k)$$ and, in particular, the ring structure on it (though I think I can do this part if I can compute the Ext modules) . I know that we can think of elements of $\mathrm{Ext}^m_R(k,k)$ as length $m+2$ exact sequences of the form $$0\to k\to X_m\to\ldots\to X_1\to k\to0$$
modulo some sensible equivalence relation, and that we can also think of it as $$\mathrm{Ext}^m_R(k,k) = H^m(\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(P_\bullet,k)) = H^m(\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(k,I^\bullet))$$
for some projective (or injective) resolution $P_\bullet$ (or $I^\bullet$, respectively) of $k$. However, when it comes to the hands-on part of actually computing this, I hit a mental block. Since $R$ is a local ring (with maximal ideal $(x)$) we know that projective modules are exactly the free modules, and so computing a projective resolution will probably be easiest...? I would appreciate hints and partial answers over explicit answers (though it's likely I might have to ask for more hints if I still struggle...). At this stage I'll take whatever I can get. Edit: Here is a partial answer, all that remains is the question of the ring structure. Note that $k\cong R/(x)$ and so we have an epimorphism $\pi\colon R\twoheadrightarrow k$ given by $x\mapsto0$ (the quotient map).
If we write $R=k[\varepsilon]$ where $\varepsilon$ is such that $\varepsilon^2=0$ then we obtain the following free resolution of $k$:
$$\ldots\xrightarrow{\cdot\varepsilon}k[\varepsilon]\xrightarrow{\cdot\varepsilon}k[\varepsilon]\twoheadrightarrow k\to0.$$ Now any morphism $k[\varepsilon]\to k$ must send $\varepsilon$ to some element $\eta\in k$ such that $\eta^2=0$.
But $k$ is a field, and so we are forced to choose $\eta=0$.
This means that any such morphism is determined entirely by where it send $1\in k$, and it can send it to any $x\in k$.
Thus $$\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(k[\varepsilon],k)\cong k.$$
So taking $\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(-,k)$ of the free resolution gives us the sequence
$$0\to k\xrightarrow{\cdot0}k\xrightarrow{\cdot0}\ldots$$
which has homology $H_n=\ker d_n/\mathrm{im}\,d_{n+1}=k/0\cong k$ for all $n\geqslant0$.
Thus $$\mathrm{Ext}^\bullet_R(k,k)\cong\bigoplus_{n\geqslant0}k$$ So my question now is about the ring structure of $\mathrm{Ext}^\bullet_R(k,k)$, and also about thinking of $\mathrm{Ext}$ as being extensions of $k$ by $k$.
Unless I'm wrong, this means that we should be able to construct, taking $n=1$, short exact sequences $$0\to k\hookrightarrow X\twoheadrightarrow k\to0$$
and the collection of all such sequences should be isomorphic to $k$.
The first thing that sprang to mind was to take $X=R$ and the epimorphism multiplication by $x\varepsilon$ for $x\in k$, but then I struggle to find a monomorphism into $R$ with the right kernel, and also taking $x=0$ means that the map fails to be an epimorphism. What is the correct choice of $\,\,\to X\to\,\,$? How can we compute explicitly the ring structure on $\mathrm{Ext}^\bullet_R(k,k)$ ? Edit 2: Following the ideas in the comments, I'm trying to explicitly spell out the following isomorphism, but I'm struggling to understand how the quotients are realised on both sides (i.e. the equivalence relations): I feel like the right-hand side should just be chain maps modulo homotopy equivalence, even though the $\mathrm{Hom}$ complex is just of maps of chains. I'm pretty certain that the lifts $\hat{f}_\bullet$ that we construct are in fact chain maps.","['derived-functors', 'modules', 'abstract-algebra', 'projective-module', 'homological-algebra']"
1747012,Does $\sum^{\infty}_{n=1}\frac{\ln{n}}{n^{1.1}}$ converge or diverge?,Does $$\sum^{\infty}_{n=1}\frac{\ln{n}}{n^{1.1}}$$ converge or diverge? I think the basic comparison works but I have a hard time finding a comparer. Could someone suggest one?,"['convergence-divergence', 'sequences-and-series', 'calculus', 'limits']"
1747043,Differential equation and exact solutions,"Given a differential equation $y'(t)=f(t,y(t))$, where f satisfies the condition $(u-v)(f(t,u)-f(t,v))\le0$ for all $u$ and $v$. If $U(t)$ and $V(t)$ are exact solutions, I want to show that $|U(t)-V(t)|\le|U(0)-V(0)|$. Can I prove it in this way: if $U(0)$ and $V(0)$ are exact solutions, then they are equal. If $U(0)$ and $V(0)$ are not exact solutions, then they are larger than $|U(t)-V(t)|$. And also how can I use this result, to prove that two numerical solutions $u_n$ and $v_n$ generated by implicit Euler satisfy $|u_n-v_n|\le|u_0-v_0|$ for all $n\ge0$.","['numerical-methods', 'ordinary-differential-equations']"
1747065,Obtaining the Rodrigues formula,"On $So(3)$ the algebra of a $3 \times 3$ skew symmetric matrices define Lie bracket $[A,B]=AB-BA$ Consider the exponential map $$EXP: So(3) \to So(3)$$. We have the $So(3)$ matrix $$A=\begin{bmatrix} 0 & -c & b \\c &  0 & -a\\
-b & a & 0\end{bmatrix}$$ Upon letting $\theta=\sqrt{a^2 + b^2 +c^2}$ , show that we obtain the identity (which is the Rodrigues formula) $$EXP (A)=I_3 + \frac{sin \theta}{\theta} A+ \frac{I-cos \theta}{\theta^2} A^2$$ I am not sure how we get the expressions $$A^{2n}=(-1)^{n+1} \theta^{2(n+1)}\begin{bmatrix} -(b^2+c^2) & ab & ac \\ab &  -(a^2+c^2) & bc\\
ac & bc & -(a^2+b^2)\end{bmatrix}$$ and $$A^{2n+1}=(-1)^n \theta^{2n}\begin{bmatrix} 0 & -c & b \\c &  0 & -a\\
-b & a & 0\end{bmatrix}$$ I understand that you look at the powers of $A$, $A^2$, $A^3$ and so on. I also understand that you get $A^{2n}$ for even powers of n and $A^{2n+1}$ for odd powers of n. I work out $$A^2= \begin{bmatrix} -b^2-c^2 & ab & ac \\ab &  -a^2-c^2 & bc\\
ac & bc & -a^2-b^2\end{bmatrix}$$ $$A^3= \begin{bmatrix} 0 & a^2c-c(-b^2-c^2) & -a^2b+b(-b^2-c^2) 
\\-b^2 c+c(-a^2-c^2) &  0 & ab^2-a(-a^2-c^2)\\
bc^2-b(-a^2-b^2) & -ac^2+a(-a^2-b^2) &  0\end{bmatrix}$$ From $A^2$ how do you get the expression for $A^{2n}$? From $A^3$ how do you get the expression for $A^{2n+1}$? For example how is $\theta$ incorporated?",['differential-geometry']
1747129,What is the most general way to think about Integrals?,"Given a single-variable scalar function, $f : \mathbb{R} \to \mathbb{R}$ The ""area under the curve"" (of the graph of the function $f$ in $\mathbb{R^2}$) is given by $$\int_{a}^{b} f(x) \ dx = Area$$ Given a multi-variable scalar function, $g: \mathbb{R^2} \to \mathbb{R}$ The ""volume under the curve"" (of the graph of the function $g$ in $\mathbb{R^3}$) is given by $$\int\int_{a}^{b} g(x, y) \ dx \ dy = Volume$$ But when thinking about integrals in this sense as translating from $\ Lines \to Areas \to Volumes$, (i.e. taking the Riemann Sum of an infinite number of infinitesimal line segments to get an area, or taking the Riemann Sum of an infinite number of infinitesimal areas to get a volume) it's a pretty ""applied"" approach. I mean you need a to plot the function $f$ as a graph for explanations such as ""area under the curve"" or ""volume under the curve"" to make any sort of sense. I'm sure that this way of thinking about Integrals breaks down at some point. For example, what would the double integral of the single-variable function I gave in the first example ""represent"" . $$\int\int_{a}^{b} f(x) \ dx^2 = \ ???$$ The graph of $f$ can be plotted in $\mathbb{R^2}$, by means of a vector-function (correct me if I'm wrong here), however the graph of $f$ only exists in $\mathbb{R^2}$, and ""Volumes"" only have any meaning in $\mathbb{R^3}$ so there can be no way that the double integral of a single-variable scalar function could represent a ""volume under the curve"" My Question Is there a more ""Pure"" Mathematical approach to thinking about integrals? Because I'm sure that this more ""applied"" way of thinking about Integrals cannot be the most general. What would be the most general, and pure mathematical way to think about Integrals, and specifically Multiple Integrals? If you have spotted any gaps in my understanding, please feel free to comment below, as an undergraduate student, majoring in Pure Mathematics, I'm always looking to improve.","['real-analysis', 'calculus', 'multivariable-calculus', 'integration', 'soft-question']"
1747158,"30 ball bearings, five are defective. Choose 10 probability.","Could someone confirm my solutions for a combinatorics question? Question: In a group of 30 ball bearings, 5 are defective.  If 10 of the ball
  bearings are chosen, what is the probability that: a) None of them are defective? b) Exactly two are defective? Part (a) Solution: There are 30 ball bearings and only 10 need to be chosen, so the sample space is $\dbinom{30}{10}$. Since only the non-defective ball bearings are chosen, 10 of the 25 non-defective ball bearings are chosen to make up the set, $\dbinom{25}{10}$. Part (a) Answer: $P = \frac{\dbinom{25}{10}}{\dbinom{30}{10}}$ Part (b) Solution: There are 30 ball bearings and only 10 need to be chosen, so the sample space is $\dbinom{30}{10}$. There are exactly two defective ball bearings in the set of 10 chosen ones; thus, two of the defective ball bearings must be chosen from the set of five, $\dbinom{5}{2}$. Afterwards, additional eight ball bearings must be chosen and they must be non-defective, so they must be chosen from the 25 available non-defective ball bearings, $\dbinom{25}{8}$. Part (b) Answer: $P = \frac{\dbinom{5}{2}\dbinom{25}{8}}{\dbinom{30}{10}}$","['combinatorics', 'probability']"
1747191,determining if a tail event,"I am to determine if $$\{\sup X_n < \infty \}$$ is a tail event, the solutions are as follows: I don't understand how they got the line of equalities, specifically the last one, and why it holds for all $M$ and $n$.","['real-analysis', 'probability', 'measure-theory', 'probability-theory']"
1747209,"Multiple Angle formulas, alternate forms","Relatively simple question, that might not be simple to answer:
I have noticed that there are ways of expressing every double angle formula of a given trigonometric function using only that function except for $\sin$ and $\csc$. That is, $\sin2\theta=2\sin\theta\cos\theta=?$ $\cos2\theta=2\cos^2\theta-1$ $\tan2\theta=\dfrac{2\tan\theta}{1-\tan^2\theta}$ $\csc2\theta=\dfrac{1}{2}\csc\theta\sec\theta=?$ $\sec2\theta=\dfrac{\sec^2\theta}{2-\sec^2\theta}$ $\cot2\theta=\dfrac{\cot^2\theta-1}{2\cot\theta}$ For triple angle formulas, all 6 trig functions have expressions using only the given trig function. They are $\sin3\theta=3\sin\theta-4\sin^3\theta$ $\cos3\theta=4\cos^{3}\theta-3\cos\theta$ $\tan3\theta=\dfrac{3\tan\theta-\tan^3\theta}{1-3\tan^2\theta}$ $\csc3\theta=\dfrac{\csc^3\theta}{3\csc^2\theta-4}$ $\sec3\theta=\dfrac{\sec^3\theta}{4-3\sec^2\theta}$ $\cot3\theta=\dfrac{3\cot\theta-\cot^3\theta}{1-3\cot^2\theta}$ My question is: What are the the formulas, provided they exist, for $\sin2\theta$ and $\csc2\theta$ in terms of $\sin\theta$ and $\csc\theta$ respectively. If they do not exist, then some explanation as to why it is not possible would be most insightful. Edit: I appreciate the answers so far, but what I really wanting to know is: Is there a known closed form (no piecewise-defined function) expression for the given expressions. Or if not, how to show that there is no such expression?",['trigonometry']
1747215,Help solving $\int_{0}^{\frac{\pi}{6}} \frac{1}{\cos(u)^9}du$,"My calculus final is coming up. My teacher was nice enough to give old exams as study material, which I have been doing. One questions asks:
$$\int_{0}^{\frac{1}{2}} \frac{1}{(1-x^2)^5}dx$$
Using trigonometric substitution, I have found:
$$\int_{0}^{\frac{\pi}{6}} \frac{1}{\cos(u)^9}du$$
However, I am not able to move forward. None of the integration techniques we have learnt seem to apply here. I have tried some online integral calculators which all show very complex approaches which we have not learnt. Assuming that was just how the algorithm solved it and that a human would have a more elegant solution, I came here for help. Edit: Turns out there is a typo in the question. It should read:
$$\int_{0}^{\frac{1}{2}} \frac{1}{(1-x^2)^\frac{5}{2}}dx$$
That is much easier to solve. I am going to leave this here just in case someone can answer it because that answer might be useful to someone at some point.","['substitution', 'integration', 'trigonometry']"
1747221,Comparing Two Statements of the Rank Theorem,"I don't think this a duplicate, even though a similar question appears here . Let $m\geq n$ and let $F:\mathbb R^n\to \mathbb R^m$ be a $\mathcal C'$ mapping s.t. rank $F'(x)=r\leq n$ for all $x\in E\subseteq \mathbb R^n.\ $Fix $a\in E$ and set $A=F'(a)$ and let $P$ be a projection in $\mathbb R^m$ onto the $Y_1=$range of $A$. Set $Y_2=kerP.$ Then the claim is that there are open sets $U\subseteq E$ and $V$ in $\mathbb R^n$ s.t $a\in U$; and there is a  bijective $\mathcal C'$ map $H:V\to U$ s.t $\tag1 F(Hx)=Ax+\varphi (Ax)$ where $\varphi$ is a $\mathcal C'$ function mapping $A(V)$ into $U$. This is,of course, a somewhat abbreviated version of the statement that appears in blue Rudin. The proof is not hard, but it seems rather abstruse and uniformative, compared to the version I first learned, which follows my comments, and question here. $H$ seems to be simply a change of coordinates (diffeomorphism),but I can't find an easy geometric interpretation of $\varphi$. It is easy to show that $P$ restricted to $F(U)$ is a bijection onto $A(V)$ but this is immediate from the other version below. In fact, it seems a lot easier to understand the idea in the following, different (?) version of the Rank Theorem: Suppose $U, V$ are open in $\mathbb R^n,\mathbb R^m$,resp. and let $F:U\to V$ be a $\mathcal C'$ map s.t. $F'(x)$ has rank $r$ for all $x\in U$. Then, there exist open sets $U_1,V_1\in \mathbb R^n,\mathbb R^m$, resp. and  diffeomorphsims $\varphi:U_1\to U_0$ and $\psi:V_1\to V_0$ s.t. for fixed $a\in U$, $\varphi (a)=0;\ \psi (f(p))=0$ and $\tag2 \psi\circ f\circ \varphi ^{-1} (x_1,x_2,\cdots ,x_r,x_{r+1},\cdots x_n)=(x_1,\cdots ,x_r,0,0,\cdots ,0)$. This formulation is simpler and more intuitive. Are the two versions equivalent? If not, how is Rudin's ""better"" than the other?","['general-topology', 'real-analysis', 'differential-geometry']"
1747317,What does a triple integral represent?,"From my understanding if the integrand is 1, then it gives you the volume of the region defined by the bounds. But what does the value of a triple integral represent if the integrand is a function for a surface in space?",['multivariable-calculus']
1747323,How to prove $\lim\limits_{x\to \infty}3x=\infty$?,"How to prove $\lim\limits_{x\to \infty}3x=\infty$? First I am not sure about formal definition of $\lim\limits_{x\to \infty}f(x)=\infty$, I guess $\forall K\in \Bbb{R},\exists N\in \Bbb{R}:x\gt N\implies f(x)\gt K$ If that's the case, Let $K\in \Bbb{R}$, let $N=\frac{K}{3}$, then $x\gt \frac{K}{3}\implies 3x\gt K$. I am sure it's not this simple. Could someone givea valid one?","['epsilon-delta', 'calculus', 'limits']"
1747359,Frobenius Norm and Relation to Eigenvalues,"I've been working on this problem, and I think that I almost have the solution, but I'm not quite there. Suppose that $A \in M_n(\mathbb C)$ has $n$ distinct eigenvalues $\lambda_1... \lambda_n$ . Show that $$\sqrt{\sum _{j=1}^{n} \left | {\lambda_j} \right |^2 } \leq \left \| A \right \|_F\,.$$ I tried using the Schur decomposition of $A$ and got that $\left \| A \right \|_F = \sqrt{TT^*}$ , where $A=QTQ^*$ with $Q$ unitary and $T$ triangular, but I'm not sure how to relate this back to eigenvalues and where the inequality comes from.","['eigenvalues-eigenvectors', 'inequality', 'matrices', 'normed-spaces', 'linear-algebra']"
1747373,Minimize $\mbox{trace}(AX)$ over $X$ with a positive semidefinite $X$,"I want to minimize $\mbox{trace}(AX)$ over $X$, under the constraint that $X$ is positive semidefinite. I guess the solution should be bounded only for a positive semidefinite $A$, and it's zero, or the solution should be minus infinity. If this is correct, can anyone tell me why? or if it is wrong, please tell me the correct solution. Thank you very much!!","['optimization', 'matrices', 'semidefinite-programming', 'positive-semidefinite', 'linear-algebra']"
1747421,Prove $\frac{a_n}{S_n^2} \leq \frac{1}{S_{n-1}}-\frac{1}{S_n}$ for partials sums of a divergent series,"Let $(a_n)$ be a sequence of non-negative numbers such that $a_1 > 0$ and $\sum a_n$ diverges. Let $S_n = \sum_{k=1}^n a_k$.  Prove that, for all $n \geq 2$,
$$\frac{a_n}{S_n^2} \leq \frac{1}{S_{n-1}}-\frac{1}{S_n}$$ How would I start this proof? I've just been staring at it and am very stuck. All i know so far is that $S_n-S_{n-1}=a_n$. Where does the inequality come from?","['real-analysis', 'sequences-and-series']"
1747471,H-space multiplication question (homotopy),"Let $(X,x_0)$ be a $H$-space with multiplication $\mu:X\times X\to X$. Let $e$ denote the constant map $I^n\to x_0$. Is it true (and why) that
$\begin{cases}
\mu(f(2x_1,x_2,\dots,x_n),e),&x_1\in[0,1/2]\\
\mu(e,g(2x_1-1,x_2,\dots,x_n)),&x_1\in[1/2,1]
\end{cases}$ is homotopic to $\mu(f(x_1,x_2,\dots,x_n),g(x_1,x_2,\dots,x_n))$? I am not sure how the multiplication $\mu$ in $H$-spaces work, other than that it is continuous. Thanks.","['algebraic-topology', 'general-topology']"
1747549,About the nature of continuity of trigonometric functions and equality,"I was recently somewhat confused by the result of an exercise from a textbook that read: Question How many solutions are there to the equation $(\tan x)\sin^2(2x)=\cos x$ , $-2\pi \leq x \leq 2\pi$ ? Correct choice [[ from a multiple choice question ]]
8 Explanation: Using your GDC to graph the two functions $y=(\tan x)\sin^2(2x)$ and $y=\cos x$ and counting the intersection points over the interval $[-2\pi , 2\pi]$ This is however contrary to what my original answer was, which is $4$ . After some research, asking a teacher, and briefly consulting a tutor from the textbook's company, I am still in doubt concerning where my approach is flawed. It is thence that I approach this community in hopes that someone can lead me to a realization or comment on my procedure. My best guess is that maybe I have conceptualized something wrong, maybe to do with limits, or the nature of equality(?). At any rate, I am humbly lost and it would be very gracious from any of you to help, I would really appreciate it.
So here we go: Relevant ideas and concepts considered under my approach Equality of functions To my knowledge, in order for two functions to be defined as equal (and thus be mathematically the same, even if represented differently) their domains must be formally equal to each other. Equality of sets To my knowledge, the following is accurate and varitable: Two sets are equal if and only if they have the same elements. [...] for any sets A and B, $A=B\iff[x\in A\iff x\in B]\forall x$ My argument Let $f(x)=\tan[x]\sin^2[2x]$ and $g(x)=\cos[x]$ both restricted by definition to $-2\pi \leq x \leq 2\pi$ To find: solutions to the equation $f(x)=g(x)$ The solutions to the equation can be found graphically, by discerning the amount of intersections between their graphs, naturally noting the boundaries of the restricted general domain of the equation.
Alternatively, but in a similar fashion, one can build the set $f \cap g$ and determine its cardinality. Relevant, however, is that $f(x)$ has its domain restricted further by the nature of the function $\tan(x)$ , which is undefined for any value where $x=\frac{(2n-1)\pi}{2}$ for any integer $n$ . Graphically, $\tan(x)$ presents asymptotic behaviour at $x=\frac{(2n-1)\pi}{2}$ .
Let $\mathbb S=\lbrace\frac{-3\pi}{2},\frac{-\pi}{2},\frac{\pi}{2},\frac{3\pi}{2}\rbrace$ , the set of x-coordinates where $tan(x)$ presents asymptotes under the restricted domain $[-2\pi,2\pi]$ . Since $\tan(x)$ is a component of the function $f$ , then the domain of $f$ $\mathbb D_f= [-2\pi,2\pi]\setminus \mathbb S$ , for if $tan(x)$ is undefined for a specific $x$ so is $\tan[x]\sin^2[2x]$ (for that same $x$ ). The function $f$ is thusly discontinuous. It then follows that the set of ordered pairs in the form $(x,y)$ representing the relation function of $f$ does not contain any element for which the x value is contained in the set $\mathbb S$ . Plotting $f$ and $g$ on a graph results in the following image: //apparently I can't post images 'yet' jpg image https://pbs.twimg.com/media/CeBRIMMUEAEWBc5.jpg online graph https://www.desmos.com/calculator/8ypryliymf Both functions appear to intersect at 8 distinct points. However, if we also plot $x \in \mathbb S$ we can cognise that 4 of these intersections are ' invalid ', for $f$ is undefined for those $x$ values. $f \cap g \neq 8$ , rather $f \cap g = 4$ So, being explicit on my conclusion, I would state that I believe that:
The domain of $\tan(x)$ does not include any element of $\mathbb S=\lbrace\frac{-3\pi}{2},\frac{-\pi}{2},\frac{\pi}{2},\frac{3\pi}{2}\rbrace$ Then (for the set of ordered pairs $f$ ) $f \not \ni (x,0) \forall x \in \mathbb S$ i.e. $f \not \supset \lbrace(\frac{-3\pi}{2},0), (\frac{-\pi}{2},0), (\frac{\pi}{2},0), (\frac{3\pi}{2},0)\rbrace$ Then $\mathbb D_f = [-2\pi,2\pi] \setminus \mathbb S \neq [-2\pi,2\pi] = \mathbb D_g = \mathbb D_{\cos x}$ To which ultimately follows that $f(x) \neq g(x) \forall x \in \mathbb S$ Then $ \lvert f \cap g \rvert = 4 \neq 8$ . -end of my argument- I presented this idea to a [presumed] mathematician, to which they replied as follows: I understand why you have said what you have done. Allow me to suggest another way of thinking. If we replace $\tan$ with $\frac{\sin}{\cos}$ , then multiply both sides by $cos$ , we end up with $\sin(x)\sin^2(2x)=\cos^2(x)$ , which is fully defined at all values of $x$ , and has $8$ possible solutions. The $tan$ function is undefined at certain values of $x$ , in that the value of $\tan$ tends to infinity. However, when we multiply anything (including infinity) by zero, we do always obtain zero. While I am not entirely comfortable with algebra including 'infinities' ( cfr. ""multiply infinity by zero""), I think I understand where they wanted to go.
I however would insist that even though mathematically and by definition (if I recall correctly) I agree that $\tan(x)\sin^2(2x) = \frac{\sin(x)}{\cos(x)}\sin^2(2x)$ I cannot find myself able to agree to the underlying implied proposition that $f(x)=\frac{\sin(x)}{\cos(x)}\sin^2(2x) \forall x \in [-2\pi,2\pi]$ . Which is, to my mind, strictly important to the nature of the problem at hand. In my mind, that manipulation of the function is a form of removing the discontinuity of $f$ , but it (in my mind) is a process whereby the nature of the function is altered and does not remain strictly 'equal' under the proper definition of 'equality' in terms of functions. It is then that my question about the nature of discontinuities and equalities is: If $$\tan(x)=\frac{\sin(x)}{\cos(x)}$$ does it logically follow that $$f(\frac{(2n-1)\pi}{2})=0$$ (which, I want to emphasize, is not the same statement as $\sin^2(2[\frac{(2n-1)\pi}{2}])=0$ ) ??? // I am a high-school student, so I proffer my sincere apologies if any of the \above notation is inappropriate or if the terminology is not on point.","['limits', 'trigonometry', 'functions', 'continuity', 'elementary-set-theory']"
1747559,image of adjoint equals orthogonal complement of kernel [duplicate],"This question already has answers here : The range of $T^*$ is the orthogonal complement of $\ker(T)$ (2 answers) Closed 5 years ago . Let $T:V\to W$ be a linear map of finite-dimensional spaces.  Then
$${\rm im}(T^{\textstyle*})=({\rm ker}\,T)^\perp\ .\tag{$*$}$$
I can prove this as follows:
$${\rm ker}(T^{\textstyle*})=({\rm im}\,T)^\perp\tag{$**$}$$
is quite easy, and we know $T^{\textstyle*}{}^{\textstyle*}=T$ and $W^{\perp\perp}=W$, so
$${\rm im}(T^{\textstyle*})=({\rm im}\,T^{\textstyle*})^{\perp\perp}=({\rm ker}\,T^{\textstyle*}{}^{\textstyle*})^\perp=({\rm ker}\,T)^\perp\ .$$
However, I would be interested in a ""direct"" proof of $(*)$.  It's fairly easy to show ${\rm LHS}\subseteq{\rm RHS}$.  For the converse I have tried obvious things but seem to be going round in circles. Also, any insights as to why $(**)$ is harder than $(*)$ - if in fact it is :) Edit .  To clarify, I am considering the adjoint defined in terms of an inner product,
$$\langle\,T({\bf v})\mid{\bf w}\,\rangle
  =\langle\,{\bf v}\mid T^{\textstyle*}({\bf w})\,\rangle\ .$$","['linear-algebra', 'adjoint-operators']"
1747600,"Where does the term ""marginal"" in ""marginal probability"" or ""marginal distribution"" come from?","Where does the term ""marginal"" in ""marginal probability"" or ""marginal distribution"" come from?","['marginal-probability', 'probability-theory', 'probability-distributions', 'terminology', 'marginal-distribution']"
1747624,How to evaluate this series using fourier series?,"With the help of Hermite's Integral ,I got
$$\sum_{n=1}^{\infty }\frac{1}{n}\int_{2\pi n}^{\infty }\frac{\sin x}{x}\mathrm{d}x=\pi-\frac{\pi}{2}\ln(2\pi)$$
I'd like to know can we solve this one using fourier series?","['integration', 'fourier-series', 'sequences-and-series', 'calculus']"
1747681,What is the norm of the dual space $H^1(\Omega)'$?,"I am working on the Bidomain-Model which, during a time interval [0,T], describes the electrical behaviour of the myocardial muscle considered as $\Omega \subset \mathbb{R}^3$. This model has partial differential equations which involve the intra- and extracellular voltages, $u$ and $v$, which are functions of this type: 
$$ u=u(t,x):[0,T]\times\Omega\rightarrow\mathbb{R}$$
$$ v=v(t,x):[0,T]\times\Omega\rightarrow\mathbb{R}$$ 
Now, as functions of time,
$$ u,v \in X=L^2\left(0,T,H^1(\Omega)\right)$$
with norm $\| u \|_{_{X}} = \left(\int_{_{[0,T]}}\| u(t) \|^{^2}_{_{H^1(\Omega)}} dt \right)^{1/2}$. Their time derivatives
$$ \dot u,\dot v \in Y=L^2\left(0,T,H^1(\Omega)' \right)$$
with norm $\| u \|_{_{Y}} = \left(\int_{_{[0,T]}}\| u(t) \|^{^2}_{_{H^1(\Omega)'}} dt \right)^{1/2}$. Further, for any fixed $t_0 \in [0,T]$, 
$$\| u(t_0) \|_{_{H^1(\Omega)}}^{^2} = \| \dot u(t_0,x) \|_{_{L^2(\Omega)}}^{^2} + \| u(t_0,x) \|_{_{L^2(\Omega)}}^{^2} = \langle u(t_0,x), u(t_0,x) \rangle_{_{H^1(\Omega)}}$$
but Which is $\| u(t_0,x) \|_{_{H^1(\Omega)'}}$? Is it $$\|u(t_0)\|_{_{H^1(\Omega)'}}^{^2} = \sup_{\xi \in H^1(\Omega)} \left\{ \langle  u(t_0,x), \xi(t_0,x) \rangle_{_{H^1(\Omega)}} \, | \, \| \xi(t_0,x)\|_{_{H^1(\Omega)}}^{^2} \le 1 \right\}$$
  as this post suggests?","['functional-analysis', 'normed-spaces', 'hilbert-spaces']"
1747696,Consecutive integers sum with different steps,"First of all: beginner here, sorry if this is trivial. We know that $ 1+2+3+4+\ldots+n = \dfrac{n\times(n+1)}2 $ . My question is: what if instead of moving by 1, we moved by an arbitrary number, say 3 or 11? $ 11+22+33+44+\ldots+11n = $ ?
The way I've understood the usual formula is that the first number plus the last equals the second number plus second to last, and so on.
In this case, this is also true but I can't seem to find a way to generalize it.","['arithmetic-progressions', 'summation', 'sequences-and-series']"
1747720,Is $\sqrt{z}$ an analytic function?,"I know hat $\sqrt{z}$ is a multivalued function with a branch point at $z=0$, but it can be expanded (I think) as a Taylor series that will converge, meaning is should in theory be called analytic. Is it common practice to call such a function analytic or not?",['complex-analysis']
1747722,Why is the functor of tensor coalgebra right adjoint to the forgetful functor?,"Let $\mathbf{NCoalg}$ be the category of non-unital coassociative conilpotent coalgebras (where ""conilpotent"" means that for any element there exists a power of comultiplication that vanishes on this element). We have a forgetful functor $\mathbf{NCoalg} \to \mathbf{Vect}$. Its seems that the right adjoint has to be the functor of non-unital tensor coalgebra: 
$$T(V)=V\oplus V^{\otimes 2}\oplus V^{\otimes3}\oplus \cdots ,$$
$$ \Delta(v_1\otimes v_2\otimes \cdots \otimes v_n) = (v_1)\otimes(v_2\otimes\cdots\otimes v_n)+\cdots+(v_1 \otimes\cdots\otimes v_{n-1})\otimes(v_n).$$ Indeed, let $C$ be a coalgebra and $V$ a vector space. Consider a linear map $f: C \to V$. We would like to define a coalgebra map $\tilde{f}:C\to T(V)$ as follows: 
$$ c \mapsto f(c)+f^{\otimes2}\Delta(c)+f^{\otimes3}\Delta^2(c)+\cdots. $$ The sum is in fact finite because $C$ is conilpotent. However, how can I show that $\tilde{f}^{\otimes2}\Delta(c)=\Delta(\tilde{f}(c))$? I guess it can be done with some abominable coordinates but they appeared too abominable and I couldn't break through. Is there a better way (more categorical perhaps)?","['category-theory', 'abstract-algebra', 'adjoint-functors', 'coalgebras']"
1747752,Every $\mathcal{C}^1$ manifold can be made smooth?,"I heard of a theorem saying that each $\mathcal{C}^k$-manifold with $k\geq 1$ can be made into a smooth manifold, i.e. $\mathcal{C}^{\infty}$ (by restriction of the atlas). However, I cannot find this theorem anywhere. Can anyone point me in the write direction (book, paper, webpage, ...) and/or give me the proof?","['manifolds', 'reference-request', 'smooth-manifolds', 'differential-geometry']"
1747784,Groups which can not occur as automorphism group of a group,"Consider the following natural question: Given a finite group $H$, does there exists a finite group $G$ such that $\mathrm{Aut}(G)\cong H$? In short, does any finite group occurs as the automorphism group (of some group)? The answer is NO. For example, $H=\mathbb{Z}_3$. Another counter-example is $H=Q_8$, the quaternion group of order $8$ (I leave their verification to interested reader). Note that $\mathbb{Z}_4$ occurs as automorphism group of $\mathbb{Z}_5$. This raises following two questions to me: Among finite abelian groups, which groups can occur as automorphism groups? Is there any other non-abelian finite group which can not occur as automorphism group? Perhaps first question is easy to answer since structure of automorphism group of finite abelian groups is well known; I don't know its complete answer. For second question, I would be happy to see if there is an infinite family of counterexamples.","['finite-groups', 'group-theory', 'automorphism-group']"
1747789,Product of two random polynomials,"Let $\alpha,\beta$ be two polynomials of the form
$$\alpha(X)=\sum_{i=0}^{n}\alpha_iX^i,\quad \quad \beta(X)=\sum_{j=0}^n\beta_jX^j$$
where each coefficient is $1$ with a probability of $p$ and $0$ with probability $1-p$. The coefficients of $\alpha,\beta$ are all independent. Note that $\alpha,\beta$ are of degree at most $n$. What can I say about the distribution of the polynomial $H(X)=\alpha(X)\cdot \beta (X)$? Note that the $k$-th coefficient of $H$ is $$h_k=\sum_{i=0}^k\alpha_i\beta_{k-i},$$ therefore it is distributed in $[0,k+1]$, but how ? Note also that the variables $c_i^{(k)}:=\alpha_i\beta_{k-i}$ are $1$ with probability $p^2$ and $0$ with probability $1-p^2$, and are independent for fixed $k$ so I can treat $h_k$ as the sum of independent random discrete variables, which is fairly easy. However, for different values of $k$ there is correlation between these variables, in other words $H$'s coefficients are not independent. It looks complicated to characterize such correlation, is there any way to measure it ? Thank you all EDIT : As an easy example to see the correlation, note that the probability of $h_1=2$ knowing that $h_0=0$ is $0$.","['polynomials', 'probability']"
1747812,Inverse of the sum of a invertible matrix with known Cholesky-decomposion and diagonal matrix,"I want to  ask a question about invertible matrix. Suppose there is a $n\times n$ symmetric and invertible matrix $M$, and we know its Cholesky decomposion as $M=LL'$. Then do we have an efficient way to calculate $(M+D)^{-1}$, where $D=diag(d_1,...,d_n)$ with positive diagonal entries, by taking the information of $M=LL'$ rather than calculating from scratch with $M+D$ directly? Or what if for the sepcial case $D=dI_n$? Thanks a lot!","['cholesky-decomposition', 'matrices', 'matrix-decomposition', 'inverse', 'linear-algebra']"
1747813,How to find a formula for a periodic sequence?,"I would like to find the formula for a periodic sequence such as 4, 1, 1/4, 1/4, 1, 4... with a period of 6","['periodic-functions', 'sequences-and-series']"
1747858,On a proof that the metric volume form is parallel wrt to the Levi-Civita connection,"In the context of (semi-)Riemannian geometry, the following fact is well-known: if a (semi-)Riemannian manifold $(M,g)$ is oriented, then the unique volume form $\epsilon = \mathrm{vol}_g$, induced by the metric together with the orientation, is parallel with respect to the Levi-Civita connection $\nabla$. That is,
$$ \nabla \epsilon = 0$$
or, using indices, $\nabla_b \epsilon _{a_1 \cdots a_n}=0$ where $n = \mathrm{dim}(M)$. I am aware of a few different ways of proving this result and most make good sense to me. My problem is that I can't seem to completely follow the logic in one particular proof which I found in Robert M. Wald's ""General Relativity"" (Appendix B, page 432). The argument there goes as follows: $\epsilon$ is uniquely specified by the choice of orientation together with the condition
$$ \epsilon^{a_1 \cdots a_n}  \epsilon_{a_1 \cdots a_n} = (-1)^s n! $$
where $s$ is the number of negative eigenvalues of $g$ (so $s=0$ for a Riemannian metric) and indices are raised and lowered using $g$. Taking covariant derivatives, since the RHS is constant, one has
$$ 0 = \nabla_b (\epsilon^{a_1 \cdots a_n}  \epsilon_{a_1 \cdots a_n}) = (\nabla_b \epsilon^{a_1 \cdots a_n})  \epsilon_{a_1 \cdots a_n} + \epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n} = 2\epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n}$$
using the fact that the metric is parallel with respect to $g$ in the last step. So far so good, we have obtained that $\epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n} = 0$. Question. But then it is argued that this, ""in turn, implies that $\nabla_b \epsilon_{a_1 \cdots a_n}=0$ since $\epsilon_{a_1 \cdots a_n}$ is totally antisymmetric in its last $n$ indices and $\epsilon^{a_1 \cdots a_n}$ is non-vanishing"". Can anyone expand on the logic of how this implication works? I have tried to interpret this by thinking of $\epsilon^{a_1 \cdots a_n}$ and of $\nabla_j \epsilon_{a_1 \cdots a_n}$, for each fixed $j$, as analogous to two antisymmetric matrices $A$ and $B$ respectively, and the desired statement is then something like
$$ \mathrm{Tr}(A^TB) = 0 \ \Longrightarrow \ B = 0,$$
but I can't seem to get very far with this reasoning. Thanks in advance for your help!","['semi-riemannian-geometry', 'riemannian-geometry', 'general-relativity', 'tensors', 'differential-geometry']"
1747862,"How many ordered pairs $(x,y)$ are there such that ${1\over\sqrt x}+{1\over\sqrt y}={1\over\sqrt {20}}$, where both $x$ and $y$ are positive integers","$${1\over \sqrt x}+{1\over \sqrt y}={1\over \sqrt {20}}$$ I could find one ordered pair that satisfies above equation, that is $(80,80)$. But the answer says that there are $3$ ordered pairs satisfying above equation.",['algebra-precalculus']
1747886,A question on ordinal arithmetic.,"I have to order these two ordinals and I was just wondering if I have done it correctly. $\omega^\omega + \omega^3$ and $\omega + \omega^3 +\omega^\omega$ I have worked out that $\omega + \omega^3 + \omega^\omega = \omega^\omega$
and that $\omega^\omega + \omega^3 = \omega^{\omega + 3}$ so $\omega^\omega + \omega^3 > \omega + \omega^3 +\omega^\omega$ Is this correct?","['ordinals', 'elementary-set-theory', 'arithmetic']"
1747897,Evaluation of $\int \frac{1-\sin x}{(1+\sin x)\cos x}dx$,Evaluate $$I=\int \frac{(1-\sin x) dx}{(1+\sin x)\cos x}$$ I tried in the following way: $$1-\sin x=1-\cos\left(\frac{\pi}{2}-x\right)=2 \sin^2\left(\frac{\pi}{4}-\frac{x}{2}\right)$$ Similarly $$1+\sin x=2 \cos^2\left(\frac{\pi}{4}-\frac{x}{2}\right)$$ So $$I=\int \tan^2\left(\frac{\pi}{4}-\frac{x}{2}\right) \sec x \: dx=\int \sec^2\left(\frac{\pi}{4}-\frac{x}{2}\right) \sec x \: dx-\int \sec x \:dx$$ If $$J=\int \sec^2\left(\frac{\pi}{4}-\frac{x}{2}\right) \sec x \: dx$$ Applying parts for $J$ we get $$J=-2\sec x \tan\left(\frac{\pi}{4}-\frac{x}{2}\right)+2\int \sec x \tan x \tan\left(\frac{\pi}{4}-\frac{x}{2}\right)dx  $$ But i am clueless from here,"['algebra-precalculus', 'integration']"
1747925,Rank of upper triangular matrix,"Show that the rank of an upper triangular matrix is at least as large as the number of non-zero main diagonal entries. What I do not understand with this statement is how can one have a triangular matrix with more linearly independent vectors than non-zero main diagonal entries. If $T = [t_1 \quad t_2 \quad \dots t_n]$ is upper triangular ($t_i$ being the column vectors), cannot $t_j$ always be expressed as linear combination of the set $\{t_1, \dots, t_{j-1} \}$ if the diagonal element $t_{jj} = 0$? In that case the rank should be equal to the number of non-zero diagonal entries. Is there any counter example? Is it even meaningful to consider non-square matrices?",['matrices']
1747950,How are image and pre-image different from range and domain respectively?,"How are image and pre-image different from range and domain respectively, in Layman's terms (as simple as possible)? Are they basically just keywords that often indicate more nuanced subsets of the domain and range respectively when studying esoteric properties? Is that basically what image and pre-image are? Words that just often help mathematicians drill down definitions to more specific subsets of the domain and range?","['type-theory', 'terminology', 'foundations', 'elementary-set-theory', 'category-theory']"
1747951,Is there a way to solve an arbitrary ODE of first order?,"$$\frac{\text{d}y}{\text{d}x}=f(x,y)$$ I know there are some tricks to solve like separations of variables and change of variables. Especially, change of variables, how can I see what I shall substitute. But they seem to be ""coincident""! Is there any algorithms to apply?",['ordinary-differential-equations']
1747998,"A formal name for ""smallest"" and ""largest"" partition","Consider a set $A=\{1,2,3,4,5\}$,
is there any terminology for the following partitions of $A$ ? (1) $A=\{ \{1\},\{2\},\{3\},\{4\},\{5\} \}$ (2) $A=\{\{1,2,3,4,5\}\}$.","['terminology', 'set-partition', 'elementary-set-theory']"
1748012,Localization Preserves Euclidean Domains,"I'm wanting to prove that given a ring $A$ (by ""ring"" I mean a commutative ring with identity ) and a multiplicative subset $S \subset A$: if $A$ is an Euclidean Domain, and $0 \notin S$ then $S^{-1}A$ (localization of A at S) is also an Euclidean Domain. I'm trying to produce an Euclidean Function in $S^{-1}A$ using the Euclidean Function $N:A \rightarrow \mathbb{N}$, that I already have from $A$ but I'm having trouble trying to define it in a way that works and verifies the properties an Euclidean Function must verify. Does any one mind giving me hints? I don't really want a solution.. I would like to work it myself. Thanks in advance. :)","['localization', 'abstract-algebra', 'ring-theory', 'euclidean-algorithm']"
1748025,How to calculate $\lim\limits_{x\to 0}\frac{\int^{2x}_{x}g(t)dt}{x^2}$ assuming $g(0)=0$?,"Assume $g(x)$ is differentiable everywhere .So $\lim\limits_{x\to 0}\frac{\int^{2x}_{x}g(t)dt}{x^2}=\lim\limits_{x\to 0}\frac{\int^{2x}_{0}g(t)dt-\int^{x}_{0}g(t)dt}{x^2}$. But the problem here is how do you know $\lim\limits_{x\to 0} \int^{2x}_{0}g(t)dt-\int^{x}_{0}g(t)dt=0$ (so we can apply lhopital later)? suppose we know $\int^{2x}_{0}g(t)dt-\int^{x}_{0}g(t)dt=0$, then $\lim\limits_{x\to 0}\frac{\int^{2x}_{0}g(t)dt-\int^{x}_{0}g(t)dt}{x^2}=\lim\limits_{x\to 0}\frac{2g(x)-g(x)}{2x}$ (not sure if the variable is correct) $=\frac{g'(0)}{2}$. Could someone clear my confusion?","['derivatives', 'limits', 'functions', 'calculus', 'integration']"
1748028,CW construction of Lens spaces Hatcher,"I am working through Hatcher's book and I am having trouble while understanding the CW-complex structure of Lens spaces. It is on page 145. He proves it constructing it in an inductive process. I upload two pictures: I think I understand all the previous ideas but I struggle with the text in yellow. I just don't see that. Why we have that? Are the $B_j^{2n-1}$ with $j \in \{1, \cdots ,m\}$ a cover of $S^{2n-3}$? I think there is something I have missed somewhere. Maybe I am not thinking about it adequately? Some of my pictures so far are these (for the case $n=2$): Maybe just explaining it with different words could help me to understand it. I am afraid I can not explain better. Thanks in advance and any help would be appreciated. Also note there are two related questions: CW structure of lens space CW construction of a generalized lens space from Hatcher","['algebraic-topology', 'general-topology', 'cw-complexes']"
1748043,Necessity of being rigorous,"Disclamer I am no serious mathematician, just curious Context I recently discovered some set theories, ZFC and IZF in particular. It made me realize that I've studied math a whole year without even knowing what a set really is (it was nothing more than a collection of objects with neither order nor repetition, as in the Naive set theory ). On the one hand I can't blame my teacher because his only goal was for us to pass the entrance exam of some engineer school, and not to turn us into mathematicians, But on the other hand, it doesn't make any sense to study groups and vector spaces, without a proper definition of what a set is. Or does it ? Questions Is mathematical consistency really necessary to study mathematics ? (Like having decided if yes or no the LEM holds) Can any axiomatic system really be independant ? (As an axiomatic system is defined to be a set of axioms along with the derived theorems)","['axioms', 'elementary-set-theory']"
1748048,How to prove $\lim\limits_{n\to \infty}(a_n+2b_n)=L+2M$ using the formal definition of limit of sequence?,"Let $\{a_n\}^{\infty}_{n=1},\{b_n\}^{\infty}_{n=1}$ be sequence. Assume $\lim\limits_{n\to \infty}a_n=L,\ \ \lim\limits_{n\to \infty}b_n=M$, how to prove $\lim\limits_{n\to \infty}(a_n+2b_n)=L+2M$ using the formal definition of limit of sequence? I remember the formal definition goes as following(not sure for sequence though): $\forall \epsilon\gt 0,\exists N\in\Bbb{R}:x\gt N\implies |a_n-L|\lt \epsilon$ Then we can set $\forall \epsilon\gt 0,\exists N\in\Bbb{R}:x\gt N\implies |a_n-L|\lt \frac12\epsilon$ $\forall \epsilon\gt 0,\exists N\in\Bbb{R}:x\gt N\implies |b_n-M|\lt \frac14\epsilon$ Then $\forall \epsilon\gt 0,\exists N\in\Bbb{R}:x\gt N\implies |2b_n-2M|\lt \frac12\epsilon$ Then $|a_n-L|+|2b_n-2M|\lt \epsilon$. But I am not sure write a proof, could someone help?","['limits', 'proof-verification', 'calculus', 'epsilon-delta', 'sequences-and-series']"
1748070,"$f_1,...,f_n$ be linear functionals on a real vector space $V$, then is there a norm on $V$ which makes every $f_i$ continuous?","Let $V$ be a real vector space, $f_1,...,f_n$ be linear functionals on $V$; then does there exist a norm on $V$ with respect to which each of $f_i$ is continuous? And what if we have infinitely many, linearly independent, such functionals?","['functional-analysis', 'normed-spaces', 'linear-transformations']"
1748082,Intuitive explanation of double expectation,This has been bugging me for some time. The famous result in probability is like $E[Y] = E[E[Y|X]]$ Can someone write an intuitive explanation of the above?,['probability-theory']
1748096,Integration by guessing the form of the numerator,"I sometimes see integrands in textbooks with a square in the denominator, like this one:
$$\int\frac{x^2}{\left(x\sin\left(x\right)+\cos\left(x\right)\right)^2} dx$$
Often, these integrands are actually the derivative of a quotient $P(x)/Q(x)$. Since we have the square in the denominator, we already know $Q(x)$. In the example, $Q(x)=x\sin\left(x\right)+\cos\left(x\right)$. Now we have to find a suitable $P(x)$ such that the integrand's numerator ($x^2$) equals $P'(x)\cdot Q(x)-P(x)\cdot Q'(x)$, since that's the numerator of the derivative of $P(x)/Q(x)$. This is basically like Ostrogradsky's method for integrating rational functions, but using polynomials not just in one variable $x$, but in many, e.g. $\{x,\sin(x),\cos(x)\}$. The fact that one might have to apply trigonometric identities to cancel terms (e.g. $\sin^2(x)+\cos^2(x)=1$) makes it more complicated. So we try different forms that $P(x)$ might have and use the method of undetermined coefficients. We might for example try $P(x)=A\sin(x)+Bx$ and find that there are no $A$ and $B$ that will work. In the example, the correct form is $P(x)=A\sin(x)+Bx\cos(x)$. The coefficients are $A=1$ and $B=-1$, i.e. we find that $P(x)=\sin(x)-x\cos(x)$ and the antiderivative is: $$\frac{\sin\left(x\right)-x\cos\left(x\right)}{x\sin\left(x\right)+\cos\left(x\right)}+C$$ Now to the actual question: While a computer can easily try hundreds of different forms for $P(x)$ within a short amount of time, doing this manually is painful. Is there any method to narrow down the possible forms of $P(x)$ that one has to try? E.g. can one make reasonable assumptions on: the number of terms that $P(x)$ must have, what kind of terms must appear, or their powers? Or is there maybe a more ""traditional"" approach to solving such integrals?","['indefinite-integrals', 'integration']"
1748103,Counting Squares In a Range,"I've been working on a series of programming challenges to work on my math skills, and I came across a solution that I don't know how to explain. The problem: ""For 1 <= A <= B <= 10^9 , find the number of perfect squares between
  $A$ and $B$ (inclusive). My initial solution was to loop through all the numbers in a range and count the perfect squares that way. However, this was obviously a very slow solution (~ 14 seconds for range 1 -> 10^9). Then, I came across the following: ""The number of squares between $A$ and $B$ = sqrt(B) - sqrt(A - 1) rounded
  down"". NOTE: From an answer to this question, rounded down is incorrect in this case, but this formula holds for finding the perfect squares in a given range. The code for this question actually converts the value to an int , which performs rounding to the nearest integer, not necessarily down. This is cool and offered a vastly quicker solution, but I don't understand why. Can anyone help me understand why this simple equation actually works?","['algebra-precalculus', 'square-numbers']"
1748106,Find the latus rectum of the Parabola,"Let $y=3x-8$ be the equation of tangent at the point $(7,13)$ lying on a parabola, whose focus is at $(-1,-1)$. Evaluate the length of the latus rectum of the parabola. I got this question in my weekly test. I tried to assume the general equation of the parabola and solve the system of equations to calculate the coefficients with the help of these given conditions. But this way it becomes very lengthy and tedious. Can anyone provide an elegant solution? Thanks.","['algebraic-geometry', 'calculus', 'algebra-precalculus', 'geometry', 'conic-sections']"
1748130,Prove $x^5+10x^3+ax^2+bx+c=0$ has no more than four real roots,"I'm trying to prove that $$f(x) = x^5+10x^3+ax^2+bx+c=0$$ can not have more than four real roots, no matter the values of $a,b,c$ real Numbers . My attempt: $f'(x) = 5x^4+30x^2+2ax+b =0$ and $ f''(x) = 20x^3+60x+2a$, now $f(x)$ is differentiable and continuous in all real line but from here I want to use the intermediate value theorem, however I don't know how to apply it for $f$.","['algebra-precalculus', 'calculus']"
1748139,Rational sum of the $p$-adic series,"Koblitz states (as one of the excercises to chapter 2) that whenever we are given an integer $k > 0$ and prime $p$, the series
$$
f(p, k) = \sum_{n=0}^\infty n^kp^n
$$
converges in $\mathbb Q_p$ and its limit is even rational (that is, in its $p$-adic expansion we can find a place from which the same finite sequence of digits repeats over and over). Can we find a explicit formula for $f(p, k)$ or maybe fix some $p_0$ and then efficiently compute the value of $f(p_0, k)$? Here are some initial terms: $\begin{array}{c|ccccccc}
p/k &1&2&3&4 & 5 & 6 & 7 & 8 & 9 & 10 \\\hline
2 &2& -6& 26& -150& 1082& -9366& 94586& -1091670&14174522& -204495126 \\
3 &\frac{3}{4}&-\frac{3}{2}&\frac{33}{8}&-15&\frac{273}{4}&-\frac{1491}{4}&\frac{38001}{16}&-17295&\frac{566733}{4}&-\frac{2579313}{2} \\
5 &\frac{5}{16}&-\frac{15}{32}&\frac{115}{128}&-\frac{285}{128}&\frac{3535}{512}&-\frac{26355}{1024}&?&-\frac{1139685}{2048}&?&? \\
7 &\frac{7}{36}&-\frac{7}{27}&\frac{91}{216}&-\frac{70}{81}&\frac{2149}{972}&-\frac{3311}{486}&\frac{285929}{11664}&-\frac{220430}{2187}&?&?
  \end{array}$","['sequences-and-series', 'p-adic-number-theory']"
1748147,Interesting integral: $I=\int_0^1 \int_0^1 \log\left( \cos(\pi x)^2 + \cos(\pi y)^2 \right)dxdy$,"I've stumbles across the following integral when doing some combinatorial work: $$ I=\int_0^1 \int_0^1 \log\left( \cos(\pi x)^2 + \cos(\pi y)^2 \right)dxdy$$ After plugging this into Mathematica, it outputs:
$$ I=\frac{4C}{\pi}-\log(4)$$ where $C$ is Catalan's constant $\left( C= \frac{1}{1^2}-\frac{1}{3^2}+\frac{1}{5^2}-\ldots \right)$. I have messed around with this integral yet I cannot figure out how it got that result. Anyone have any ideas?","['multivariable-calculus', 'integration', 'definite-integrals', 'sequences-and-series']"
1748162,Problem with basic definition of a tangent line.,"I have just started studying calculus for the first time, and here I see something called a tangent. They say, a tangent is a line that cuts a curve at exactly one point. But there are a lot of lines that can cut the same point just like shown in the picture- WHY arent we saying that lines M and C are also tangents? What is the real definition of a tangent line?  A tangent line is a line which passes through two infinitesimally close points Is this definition correct? 
Thanks!","['tangent-line', 'infinitesimals', 'calculus', 'definition']"
1748189,For every group $G$ there is a $2$-dimensional cell complex $X_G$ with $\pi_1(X_G)\cong G$.,"I am reading Allen Hatcher's Algebraic Topology, and am trying to understand the proof to corollary 1.28: For every group $G$ there is a $2$-dimensional cell complex $X_G$ with $\pi_1(X_G)\cong G$. Since his book is available on his homepage , I will copy his proof below: Choose a presentation $G=\langle g_\alpha\;|\;r_\beta\rangle$. This exists since every group is a quotient of a free group, so the $g_\alpha$s can be taken to be the generators of this free group with the $r_\beta$s generators of the kernel of the map from the free group to $G$. Now construct $X_G$ from $\bigvee_\alpha S_\alpha^1$ by attaching $2$-cells $e_\beta^2$ by the loops specified by the words $r_\beta$. Which loops are specified here, and where do we attach the $2$-cells? Edit: An example I thought of was a simple case where $G=\langle a, b\;|\;ab\rangle$, then we'd have $S_a^1\vee S_b^1$, and one $2$-cell which should ""wrap around"" both $S^1$? But then $\pi_1(X_G)$ would be trivial (contractible), unlike $G$? Additionally, would there be an algorithm to work backwards, i.e. given a $2$-dimensional cell complex $X_G$ with some conditions (cells are disjoint except for the middle of the wedge), we can obtain $G=\langle g_\alpha\;|\;r_\beta\rangle$?","['algebraic-topology', 'general-topology', 'group-presentation']"
1748192,"$f\in L^{1}[0,1]$ Show $\lim_{n\to\infty}\int_{0}^{1}|f(x)|^{\frac{1}{n}}dx = m(\left\{ {x:f(x)\neq 0}\right\} )$","The following is from a Sample Exam question I am studying from, and the question  has stumped me. $$f\in L^{1}[0,1]$$ $$\lim_{n\to\infty}\int_{0}^{1}|f(x)|^{\frac{1}{n}}dx = m(\left\{ {x:f(x)\neq 0}\right\} )$$ What I think:from below:
I set $A=\{x:f(x)\neq 0\} )  $
Then
$\lim_{n\to\infty}\int_{A}|f(x)|^{\frac{1}{n}}dx \leq \lim_{n\to\infty}\int_{0}^{1}|f(x)|^{\frac{1}{n}}dx$ When I take the limit both sides I get that required lower bound. from above I get 
$$\lim_{n\to\infty}\int_{0}^{1}|f(x)|^{\frac{1}{n}}dx \leq 1$$ any insight would be appreciated.
My Texing skills are not great, but the above sums up the best of my attempts so far.
Thank you","['real-analysis', 'limits', 'lp-spaces', 'integration', 'measure-theory']"
1748204,Can every partially ordered set (POSET) take the form of a directed acyclic graph (DAG)?,"A POSET (Partially ordered set) is a set on the elements of which we have established a partial order relation ($\leq$) , i.e. a relation which is: reflexive : $x\leq x,$ for every x in S anti-symmetric : $x \leq y \wedge y \leq x \Rightarrow x=y $ transitive : $x\leq y, y\leq x \Rightarrow x\leq z$ My question is if every POSET can take the form of a DAG (Directed Acyclic Graph) if we view its elements as the nodes and the relation itself as the edge set.","['abstract-algebra', 'graph-theory']"
1748216,Complex manifold with subvarieties but no submanifolds,"Note, I have now asked this question on MathOverflow . There are examples of compact complex manifolds with no positive-dimensional compact complex submanifolds. For example, generic tori of dimension greater than one have no compact complex submanifolds. The proof of this fact, see this answer for example, shows that these tori also have no positive-dimensional analytic subvarieties either (because analytic subvarieties also have a fundamental class). My question is whether the non-existence of compact submanifolds always implies the non-existence of subvarieties. Does there exist a compact complex manifold which has positive-dimensional analytic subvarieties, but no positive-dimensional compact complex submanifolds? Note, any such example is necessarily non-projective.","['complex-manifolds', 'complex-geometry', 'algebraic-geometry']"
1748259,Function analytic in each variable does not imply jointly analytic,"I have heard that a function $f: \mathbb R^2 \to \mathbb R$ can be analytic in each variable (i.e. $f(x,y_0) = \sum_{n=0}^{\infty} a_n x^n, \forall x \in \mathbb R$, and the same for $y$) without being jointly analytic (i.e. $f(x,y) = \sum_{i,j=0}^{\infty} a_i b_j x^i y^j, \forall x,y \in \mathbb R$).
Is there some standard example of such a function?","['analyticity', 'real-analysis']"
1748269,Integrate $\sqrt{x^2 + x}$,"I'm stuck with trying to integrate the following expression:
$$ \int (\sqrt{x^2 + x}) dx $$ I have tried u-substitution where $u = \sqrt{x}$, but it didn't get far. How should I approach this? Thanks ahead!",['integration']
1748286,Regularizing the sum of all factorials,"Consider the series $$\sum_{n=0}^\infty n! = 0! + 1! + 2! + 3! + 4! + \ldots = 1 + 1 + 2 + 6 + 24 + \ldots$$ This series clearly diverges. Now, given that the Gamma function is defined by $$n! = \Gamma(n+1) = \int_0^\infty t^n \mathrm{e}^{-t} \mathrm{d}t$$ we obtain $$\sum_{n=0}^\infty n! = \sum_{n=0}^\infty \int_0^\infty t^n \mathrm{e}^{-t} \mathrm{d}t$$ Interchanging limits for the sake of regularization yields \begin{align}
\sum_{n=0}^\infty n! &= \int_0^\infty \sum_{n=0}^\infty t^n \mathrm{e}^{-t} \mathrm{d}t \\
&= \int_0^\infty \frac{\mathrm{e}^{-t}}{1 - t} \mathrm{d}t \\
&= \left[ -\mathrm{e}^{-1} \mathrm{Ei}(1-t) \right]_0^\infty \\
&= \mathrm{e}^{-1} \mathrm{Ei}(1) \\
&\approx 0.697175
\end{align} where $\mathrm{Ei}$ is the exponential integral. Notice that we used the Cauchy principal value since the function has a pole at $t = 1$ . Is this a valid regularization of the series? Entering the command N@Sum[n!, {n, 0, Infinity}, Regularization -> ""Borel""] into Mathematica yields 0.697175 + 1.15573 I which is a complex value. Why is the answer different? I know this is a divergent series, but I would like to find its regularized value. EDIT: 0.697175 + 1.15573 I is just $\mathrm{e}^{-1} (\mathrm{Ei}(1) + i\pi)$ .","['regularization', 'improper-integrals', 'divergent-series', 'sequences-and-series', 'gamma-function']"
1748337,sphere-filling curve,"Let $S^2$ denote the $2$-dim sphere in $\mathbb R^3$. I am interested in finding a space-filling curve, i.e. a map $\varphi: [0,1]\to S^2$ that is continuous and onto. We know that there is such a space-filling curve onto $[0,1]^2$ from Peano's and Hilbert's results. Know my idea was to consider a unit cube in $\mathbb R^3$. Then I want to take a path that traverses enough edges of the cube (or just take a Hamiltonian path). From an edge I want to fill its face with Peano's curve and then go back to the edge after filling. This construction yields a cube-filling curve. Then I blow the cube up to the sphere and I am done. However, this seems to simple to me. Does that work or do I miss something?","['general-topology', 'geometry']"
1748341,Is there an explicit irrational number which is not known to be either algebraic or transcendental?,"There are many numbers which are not able to be classified as being rational, algebraic irrational, or transcendental. Is there an explicit number which is known to be irrational but not known to be either algebraic or transcendental?","['analytic-number-theory', 'transcendental-numbers', 'transcendence-theory', 'irrational-numbers', 'number-theory']"
1748379,Is there a diagonalizable matrix $A \neq B$ such that $e^A = e^B$?,"Is there a diagonalizable matrix $A \neq B$ such that $e^A = e^B$? My initial thought was that if this is possible, then
$$
e^A e^{-A} = e^B e^{-A}
$$
so
$$
I = e^B e^{-A}.
$$
This means the statement is true if there exists a nonzero matrix $C$ such that $e^C = I$. But is this possible? My intuition tells me no, but how can it be proved?","['matrices', 'matrix-exponential', 'linear-algebra']"
1748404,A String Tied Around The Earth,"Say you're standing on the equator and you have a string below you tied around the equator (40,075 km) that is the length of the equator + 1 meter (40,075.001 km). What is the maximum height you can you lift the string off the ground? Can you create a function of both circumference of the circle (earth) and string to output the distance between the two if pulled tight? Assumptions: For illustration, the result would be pulled from a single point, making a triangle until it met with the earth, in which it would follow the curvature of the earth. Similar to a snow-cone or O> The string does not stretch The earth can be assumed to be a perfect sphere","['trigonometry', 'transcendental-equations', 'geometry']"
1748407,Confusion on Differential Operators and Notation,"My teacher wrote the following on the board: $\frac{d}{dx}: C^1(a,b)\rightarrow C^0(a,b)$ I thought that a 1st order differential operator takes a function which is continuous and maps it to some function space where we don't know the properties (i.e. I don't know that the derivative is continuous). To me, what he wrote looks like it takes a function with a continuous derivative and maps it to a continuous function. Would someone explain this to me more clearly?","['derivatives', 'calculus', 'functional-analysis', 'linear-algebra', 'vector-spaces']"
1748452,Find all the parameters and such that the line $y = ax + \frac{1}{2}a - 2$ intersects the hyperbola $xy = 1$ at right angles in at least one point .,"Problem:
Find all the parameters and such that the line
$y = ax + \frac{1}{2}a - 2$ intersects the hyperbola $xy = 1$ at right angles
in at least one point. My work: We try to find tangent to hyperbola such that tangent line intersects given line at rigth angle. We know that two line $y_1=ax+b$ and $y_2=cx+d$ intersects at right angle iff $a=-\frac{1}{c}$. So we need to find tangent to hyperbola. Let $t...y=kx+l$ be our tangent line. To find that first we will need $y'$ and we will find it by implicit differentiation.
$$xy=1$$
$$y+xy'=0 \iff y'=\frac{-y}{x}$$
$$k=-\frac{y}{x}$$
But I haven't idea how to finish my work.","['derivatives', 'real-analysis', 'calculus', 'tangent-line', 'implicit-differentiation']"
1748489,Setting double integral,"Integrate $f(x,y,z)=y$ over the region $x=0,y=0,z=0, 2x+2y+z=4$ Will the double integral be of the form $\int_0 ^4 \int_y^{4-2y}ydydz$? Any help would be much appreciated! Thanks!","['multivariable-calculus', 'definite-integrals', 'calculus']"
1748502,The tower of ramification indices,"Let $K\subset L\subset M$ be an extension of number fields. Let $R\subset S\subset T$, be their algebraic integers rings, respectively. Suppose that $P\subset R$, $Q\subset S$, $U\subset T$ be a prime ideals such that $U\cap S=Q,Q\cap R=P$. I need to show that $e(U|P)=e(U|Q)e(Q|P)$. ($e$ is the ramification index) I am trying to prove it using the unique factorisation. I know $R,S,$ & $T$ are Dedekind domains. So. $PT=U^{e(U|P)}{U_2}^{t_2}...{U_r}^{t_r}$ $PS=Q^{e(Q|P)}{N_2}^{s_2}...{N_k}^{s_i}$ $QT=U^{e(U|Q)}{F_2}^{x_2}...{F_b}^{x_j}$ All the ideals in the factorisation are prime ideals. how to write $PT=U^{({{e(U|Q)}})^{e(Q|P)}}.....$ and we deduce the result for the unique factorisation.","['number-theory', 'abstract-algebra', 'algebraic-number-theory', 'field-theory']"
1748511,Principal Minors of $B(AB)^{-1}A$ and Cauchy-Binet Terms,"I am looking for a proof for the following conjecture. I think the result follows from applying a generalization of the Cauchy-Binet formula to the matrix $\mathbf{M}$ defined bellow. I've tested it as much as I could using Mathematica and am convinced it is true, but I haven't been able to prove it. Any help will be much appreciated. Setup Suppose $\mathbf{A}$ and $\mathbf{B}$ are $(n \times m)$ and $(m \times n)$ matrices respectively, with $n<m$ and $\operatorname{rank}(\mathbf{A})=\operatorname{rank}(\mathbf{B})=n$. Let $K \equiv \{1,\dots,m\}$, $\mathbf{X}_{k}$ denote the matrix $\mathbf{X}$ keeping only columns and rows in $k$, $\mathbf{X}_{rk}$ denote the matrix $\mathbf{X}$ keeping only rows in $k$, and $\mathbf{X}_{ck}$ denote the matrix $\mathbf{X}$ keeping only columns in $k$. Also, for any $k \subset K$, let $K_n$ be the set of subsets of $K$ with $n$ elements. Then, using the Cauchy-Binet formula, the determinant of the matrix $\mathbf{A}\mathbf{B}$, denoted by $\Delta$, can be written as $$\Delta \equiv \det(\mathbf{A}\mathbf{B}) = \sum_{k\in K_n}{\det(\mathbf{A}_{ck})\det(\mathbf{B}_{rk})}. $$ Denote each element of this sum by $$ d_k \equiv \det(\mathbf{A}_{ck})\det(\mathbf{B}_{rk}), \;\;\;\;\text{for all }k \in K_n.$$ Consider the matrix $\mathbf{M}$ given by $$ \mathbf{M} = \mathbf{B}(\mathbf{A}\mathbf{B})^{-1}\mathbf{A}, $$ with principal minors given by $\det(\mathbf{M}_{k})$ for any $k \in P(K)$, where $P(K)$ is the power set of $K$ (the set of all subsets of $K$). Conjecture I want to show that
  $$ \det(\mathbf{M}_{k}) = \frac{1}{\Delta}\sum_{j\in \{ i \in K_n : k \subset i \}}d_j, \;\;\;\;\text{for all }k \in P(K) $$ Example to clarify notation Suppose that $m=3$ and $n=2$. Then, from the definitions we have that \begin{align}
P(K) =& \{\{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\}\} \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \\[3ex]
K_n =& \{\{1,2\},\{1,3\},\{2,3\}\} \\[3ex]
\mathbf{A} =& \left[\begin{matrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \end{matrix}\right],  \;\;\; \mathbf{B} = \left[\begin{matrix} b_{11} & b_{12}  \\ b_{21} & b_{22}  \\ b_{31} & b_{32} \end{matrix}\right] \\[3ex]
\mathbf{A}\mathbf{B} =& \left[\begin{matrix} a_{11}b_{11}+a_{12}b_{21}+a_{13}b_{31}	& a_{11}b_{12}+a_{12}b_{22}+a_{13}b_{32} \\
a_{21}b_{11}+a_{22}b_{21}+a_{23}b_{31} &	a_{21}b_{12}+a_{22}b_{22}+a_{23}b_{32}\end{matrix}\right]
\end{align} and the Cauchy-Binet formula implies \begin{align}
\det(\mathbf{A}\mathbf{B}) =& \det(\mathbf{A}_{c\{1,2\}})\det(\mathbf{B}_{r\{1,2\}}) + \det(\mathbf{A}_{c\{1,3\}})\det(\mathbf{B}_{r\{1,3\}}) + \det(\mathbf{A}_{c\{2,3\}})\det(\mathbf{B}_{r\{2,3\}}) \\[2ex]
=& \det\left[\begin{matrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{matrix}\right]\det\left[\begin{matrix} b_{11} & b_{12}  \\ b_{21} & b_{22}  \end{matrix}\right] + \det\left[\begin{matrix} a_{11} & a_{13} \\ a_{21} & a_{23} \end{matrix}\right]\det\left[\begin{matrix} b_{11} & b_{12}  \\ b_{31} & b_{32} \end{matrix}\right] + \\[1ex]
 & \det\left[\begin{matrix}  a_{12} & a_{13} \\ a_{22} & a_{23} \end{matrix}\right]\det\left[\begin{matrix} b_{21} & b_{22}  \\ b_{31} & b_{32} \end{matrix}\right].
\end{align} Again, using the definitions above we have that \begin{align}
d_{\{1,2\}} \equiv & \; \det(\mathbf{A}_{c\{1,2\}})\det(\mathbf{B}_{r\{1,2\}}) \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\\[1ex]
d_{\{1,3\}} \equiv & \; \det(\mathbf{A}_{c\{1,3\}})\det(\mathbf{B}_{r\{1,3\}}) \\[1ex]
d_{\{2,3\}} \equiv & \; \det(\mathbf{A}_{c\{2,3\}})\det(\mathbf{B}_{r\{2,3\}}) \\[3ex]
\Delta \equiv & \; d_{\{1,2\}}+d_{\{1,3\}}+d_{\{2,3\}}
\end{align} and, with some algebra, it is easy to verify that the principal minors of $\mathbf{M}$ can be written as \begin{align}
\det(\mathbf{M}_{\{1,2\}}) =& \; \frac{1}{\Delta}\sum_{j\in \{1,2\}}d_j =\; \frac{1}{\Delta}d_{\{1,2\}} \\[2ex]
\det(\mathbf{M}_{\{1,3\}}) =& \; \frac{1}{\Delta}\sum_{j\in \{1,3\}}d_j =\; \frac{1}{\Delta}d_{\{1,3\}} \\[2ex]
\det(\mathbf{M}_{\{2,3\}}) =& \; \frac{1}{\Delta}\sum_{j\in \{2,3\}}d_j =\; \frac{1}{\Delta}d_{\{2,3\}} \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \\[2ex]
\det(\mathbf{M}_{\{3\}}) =& \; \frac{1}{\Delta}\sum_{j\in \{\{1,3\},\{2,3\}\}}d_j =\; \frac{1}{\Delta}(d_{\{1,3\}}+d_{\{2,3\}}) \\[2ex]
\det(\mathbf{M}_{\{2\}}) =& \; \frac{1}{\Delta}\sum_{j\in \{\{1,2\},\{2,3\}\}}d_j =\; \frac{1}{\Delta}(d_{\{1,2\}}+d_{\{2,3\}}) \\[2ex]
\det(\mathbf{M}_{\{1\}}) =& \; \frac{1}{\Delta}\sum_{j\in \{\{1,2\},\{1,3\}\}}d_j =\; \frac{1}{\Delta}(d_{\{1,2\}}+d_{\{1,3\}})
\end{align} Moreover, $\det(\mathbf{M}_{\{1,2,3\}}) =0$ follows from the fact that $\det(\mathbf{M}_{\{1,2,3\}})$ is a principal minor of order $3>2=n$. All principal minors of $\mathbf{M}$ of order greater than $n$, are equal to zero, since $\operatorname{rank}(\mathbf{M})=n$. Attempts at the proof using the suggestions by @darijgrinberg Fix $k \in P(K)$ and let $v\equiv |k|$, i.e. the number of elements in $k$. First suppose that $v \gt n$, so that $\det(\mathbf{M}_k)=0$, since $\operatorname{rank}(\mathbf{M}_k)=0$, and $\{ i \in K_n : k \subset i \} = \emptyset$, so that the conjecture holds trivially. Next, suppose that $v \le n$. What follows is tentative. Working with the definition of $\mathbf{M}_{k}$: By definition, $$ \mathbf{M}_{k}=\mathbf{B}_{rk}(\mathbf{A}\mathbf{B})^{-1}\mathbf{A}_{ck} $$ where $\mathbf{B}_{rk}$ and $(\mathbf{A}\mathbf{B})^{-1}\mathbf{A}_{ck}$ are $(v \times n)$ and $(n \times v)$ matrices respectively. Let $L\equiv \{1,\dots,n\}$ and $L_v$ be the set of subsets of $L$ with $v$ elements, and from the Cauchy-Binet formula we have that $$ \det(\mathbf{M}_{k})=\sum_{j \in L_v}\det\left(\mathbf{B}_{rk,cj}\right)\det\left((\mathbf{A}\mathbf{B})_{rj}^{-1}\mathbf{A}_{ck}\right), \tag1$$ and $$	\det\left((\mathbf{A}\mathbf{B})_{rj}^{-1}\mathbf{A}_{ck}\right)=\sum_{i \in L_v}\det\left((\mathbf{A}\mathbf{B})_{rj,ci}^{-1}\right)\det\left(\mathbf{A}_{ri,ck}\right).$$ So that $$ \det(\mathbf{M}_{k})=\sum_{i,j \in L_v}\det\left((\mathbf{A}\mathbf{B})_{rj,ci}^{-1}\right)\det\left(\mathbf{A}_{ri,ck}\right)\det\left(\mathbf{B}_{rk,cj}\right),$$ and since $$ (\mathbf{A}\mathbf{B})^{-1}=\frac{1}{\Delta}\operatorname{adj}(\mathbf{A}\mathbf{B}) \implies (\mathbf{A}\mathbf{B})_{rj,ci}^{-1}=\frac{1}{\Delta}\operatorname{adj}(\mathbf{A}\mathbf{B})_{rj,ci} $$ it follows that $$ \det(\mathbf{M}_{k})=\frac{1}{\Delta^v} \sum_{i,j \in L_v}\det\left(\operatorname{adj}(\mathbf{A}\mathbf{B})_{rj,ci}\right)\det\left(\mathbf{A}_{ri,ck}\right)\det\left(\mathbf{B}_{rk,cj}\right).$$ Next, for each $i,j \in L_{v}$ define $i'\equiv \{1,\dots,n\}\setminus i$ and $j'\equiv \{1,\dots,n\}\setminus j$, then it follows from Jacobi's theorem that $$ \det(\operatorname{adj}(\mathbf{A}\mathbf{B})_{rj,ci})=(-1)^{\sigma_{ij}}\det(((\mathbf{A}\mathbf{B})^{\top})_{rj',ci'})\Delta^{v-1}=(-1)^{\sigma_{ij}}\det(\mathbf{A}_{rj'}\mathbf{B}_{ci'}) $$ where $$ \sigma_{ij} \equiv i_{v+1}'+\cdots+i_{n}'+j_{v+1}'+\cdots+j_{n}' $$ and, therefore, $$ \det(\mathbf{M}_{k})=\frac{1}{\Delta}\sum_{i,j \in L_{v}}(-1)^{\sigma_{ij}}\det(\mathbf{A}_{rj'}\mathbf{B}_{ci'})\det(\mathbf{A}_{ri,ck})\det(\mathbf{B}_{rk,cj}) $$ So far I haven't been able to proceed from here. Working with the conjecture equation: Notice that for any $j \in K_{n}$, $$ \det((\mathbf{A}\mathbf{B})^{-1}\mathbf{A}_{cj})=\frac{1}{\Delta}\det(\mathbf{A}_{cj}), $$ so that the conjecture can be rewritten as $$ \det(\mathbf{M}_{k}) = \sum_{j\in \{ i \in K_n : k \subset i \}}\det(\mathbf{B}_{rj})\det((\mathbf{A}\mathbf{B})^{-1}\mathbf{A}_{cj}), \tag2$$ which looks similar equation $(1)$, rewritten here for convenience $$ \det(\mathbf{M}_{k})=\sum_{j \in L_v}\det\left(\mathbf{B}_{rk,cj}\right)\det\left((\mathbf{A}\mathbf{B})_{rj}^{-1}\mathbf{A}_{ck}\right). $$ I am not sure how to deal with the difference in the indexes between the two equations. My guess is that I will need to use a Laplace expansion to equation $(2)$.","['matrices', 'linear-algebra', 'determinant']"
1748524,When exactly is a compact complex manifold algebraic?,"It is well known that a necessary and sufficient condition for a compact Khler manifold $\mathcal{X}$ to be a projective algebraic variety is that it admit a positive holomorphic line bundle $L \rightarrow \mathcal{X}$ . The positivity of $L$ yields a proper holomorphic embedding in projective space and Chow's theorem tells us that the image is cut out by homogeneous polynomials. Here I regard the existence of a positive holomorphic line bundle (meaning a line bundle whose Chern connection has positive curvature) as a differential-geometric condition. Now suppose that $X$ is a smooth, complete variety over $\mathbb{C}$ in the algebraic category, where $X$ is not necessarily projective. We have an analytification functor ( la Serre's GAGA) which when applied to $X$ yields a compact complex manifold $X^{an}$ . In this way, we can think of $X^{an}$ as algebraic in the complex category. Note of course that $X^{an}$ need not be projective, nor even Khler. Hironaka's example yields non-Khler examples. My question is: Is there some differential-geometric condition that tests when a
compact complex manifold $\mathcal{X}$ is algebraic (i.e. $\mathcal{X} = X^{an}$ is the analytification of a smooth complete variety $X$ over $\mathbb{C}$ )? We know in particular that such an $\mathcal{X}$ will be a Moishezon manifold (its algebraic dimension $a(\mathcal{X})$ equals $\mbox{dim}_{\mathbb{C}}$ ( $\mathcal{X}$ )) but it is known that there are Moishezon manifolds that are not algebraic (i.e. not the analytification of a variety), so the condition of being Moishezon is not sufficient. That said, it is known (due to Artin) that every Moishezon manifold is the analytification of a proper algebraic space , which is defined here by Wikipedia and is a generalization of a scheme. So my question asks for a differential-geometric condition which is almost 'parallel' to asking when an algebraic space is in fact a scheme.","['complex-manifolds', 'complex-geometry', 'algebraic-geometry']"
1748547,Prove $b-a \le \sum^n_{i=1}(b_i-a_i)$ by induction,"Show that if the closed interval $[a,b]$ is covered by finitely many open intervals $(a_1,b_1), ...,(a_n,b_n)$, then $$b-a \le \sum^n_{i=1}(b_i-a_i)$$. I know that $(a_1,b_1), ...,(a_n,b_n)$ form an open covering of $[a,b]$, and my thought is to show the inequality by mathematical induction, but not sure how to prove this. Could someone provide a complete proof please? Thanks a lot.","['induction', 'real-analysis', 'measure-theory']"
1748549,Rolling a die until two rolls sum to seven,"Here's the question: You have a standard six-sided die and you roll it repeatedly, writing
  down the numbers that come up, and you win when two of your rolled
  numbers add up to $7$. (You will almost surely win.) Necessarily, one of the
  winning summands is the number rolled on the winning turn. A typical
  game could go like this: $1, 1, 4, 5, 3$; you win on the 5 th turn
  because $3 + 4 = 7$. How many turns do you expect to play? Here's what I've tried: 
We seek $E(N)$ where $N$ is a random variable counting the number of turns it takes to win. Then $N \ge 2$, and $$E(N) = \sum_{n=2}^\infty n P(N=n) = \sum_{n=1}^\infty P(N > n).$$
I want to find either $P(N=n)$, the probability that I win on the $n$ th turn, or $P(N > n)$, the probability that after $n$ turns I still haven't won. Note that $P(N = 1) = 0$. Let $X_k$ be the number rolled on the $k$ th turn. Then $$P(N = 2) = P(X_1 + X_2 = 7) = \sum_{x=1}^6 P(X_1 = x)P(X_2 = 7-x) = 6\cdot \frac{1}{6}\cdot\frac{1}{6} = \frac{1}{6}.$$
So far so good. To compute $P(N > 3)$ I let $A_{i, j} = \{\omega \in \{1, \dotsc, 6\}^3 : w_i + w_j = 7\}$ and used the inclusion-exclusion principle and symmetry to find $$|A_{1,2} \cup A_{2,3} \cup A_{1,3}| = 3|A_{1,2}| - 3|A_{1,2}\cap A_{1,3}| = 90$$
so $P(N > 3) = \frac{126}{216} = \frac{7}{12}$. This is the probability that no two of three dice sum to seven. Similarly, I found $P(N > 4)$ to be $\frac{77}{216}$. I don't see how to generalize the above. I also thought that $$P(N > n) = P(X_i + X_j \ne 7 \text{ for all }1 \le i\ne j \le n) = (1 - P(X_i + X_j = 7))^{\binom{n}{2}} = \left(\frac{5}{6}\right)^{n(n-1)/2}$$ 
but that's false because the events are not independent. I also tried $$P(N = n) = P(X_n = 7 - X_k \text{ for some } 1 \le k < n \text{ and }N \ne n - 1)$$
where that last clause is shorthand for ""and the previous rolls did not secure your victory"". 
This yields the recursion $p_n = (1-(5/6)^{n-1})(1-p_{n-1})$, $p_1 = 0$, which didn't agree with my previously computed probabilities. (Perhaps I made an error.)","['expectation', 'probability', 'dice']"
1748554,Oscillating integral converges to zero?,"An integral like, say, 
$$\int_0^1 \cos[ nf(x)]~dx$$
with some function $f$ which is well behaved, and maybe almost everywhere non-zero, should be very small for large $n$ since the positive and negative contributions should about cancel each other whenever the oscillation frequency is high enough. Is there a way to formalise this? For $f(x)=x$, one could compute $$\int_0^1 \cos nx ~dx=\int_0^1 \frac{d}{dx}\left(\frac{\sin nx}{n}\right) dx=\frac{\sin n}{n}$$ but how could one argue when there is no expression for the antiderivative available? For certain cases a substitution $y=f(x)$ and some integration by parts might help, but it seems that the restrictions on $f$ imposed by that are stronger than necessary.","['real-analysis', 'integration', 'calculus', 'limits']"
1748605,"Show that continuous functions on $[0,1]$ satisfy this property: $\lim_{n \to \infty} n\int_0^1e^{-nx}f(x)dx$","If $f \in C[0,1]$ prove that 
$$
\lim_{n \to \infty} n\int_0^1e^{-nx}f(x)dx
$$
exists and find the limit. I can show that $|g_n|$ are bounded by $M=\max(f)$. After some test functions I suspect that $g_n \to f(0)$ but I'm stuck!","['continuity', 'integration', 'lebesgue-integral', 'measure-theory']"
1748712,A pill bottle with large and small pills,"Alright here's the exact question: A bottle initially contains $48$ large pills and $76$ small pills. Each day a patient randomly chooses one of the pills. If a small pill is chosen, it is eaten. If a large pill is chosen, the pill is broken in two; one part is eaten and the other part is returned to the bottle, and is now considered to be a small pill. Let $X$ be the number of small pills in the bottle after the last large pill has been chosen and its smaller half is returned. Find $\operatorname{E}(X)$. Now here is my thought process so far: $X_i$ = the time at which the $i$th large pill is chosen and then broken. Then
$X = \sum_{i = 1}^{48}X_i$, so $\operatorname{E}(X) = \sum_{i = 1}^{48}\operatorname{E}(X_i)$. From this I gather that $X\sim \operatorname{Geo}(\frac{48-i+1}{76+i-1})$, but I have no idea how I would actually go about computing such a ridiculous amount of geometric random variables.","['probability', 'random-variables']"
1748751,How was the Runge-Kutta method derived?,"By K values, I mean the values described here: https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods#Explicit_Runge.E2.80.93Kutta_methods I know how the K values in the Runge-Kutta method can be proven to be correct, by comparing their taylor expansion with the taylor expansion of the function to be approximated, but how were they originally figured out? I think I understand the Runge-Kutta method derivation when you have the derivative in terms of one variable f'(t). It seems to be a direct consequence of Simpson's rule and its higher order equivalents. But when it is some form of first order differential equation (i.e. f'(t, y(t))), I am still lost. Is there an equivalent of Simpson's rule for multivariable functions?","['numerical-methods', 'ordinary-differential-equations', 'runge-kutta-methods']"
1748768,What is the advantage of Borel sigma algebras in defining probability spaces?,"I'm trying to get the central concepts correct, so I'm going to express them without embellishment. A Borel $\sigma$ algebra is defined as a sigma algebra generated by a topological space
    $(M,\mathcal{T})$. If $M$ is $\mathbb{R}$, it will typically
    be the ""standard topology"" defined as the set of all open intervals. Because a $\sigma$ algebra is closed under intersection of infinitely-countably many sub-sets, we can prove that $\displaystyle\bigcap_{n\geq1}(a -\frac{1}{n},\,b)= [a,b)$. This step would not be possible within the topological space where only finite intersections are allowed. So we ""recover"" closed and half-closed intervals, thanks to the Borel $\sigma$-algebra. Now, the half-open intervals are in the sigma algebra (and so are closed intervals), and can be assigned a measure. So we went through quite a bit of maneuvering (assuming all this is correct) for what purpose? In particular, if we focus on probability spaces, the probability of a close interval is the same as an open interval, since the probability of any point in the real line is zero. Here is a tentative, unsophisticated, and crass way of looking at it (I'm posting it here to get further feedback): We can't assign a probability measure to $[0,1]$ because of Cantor's different types of infinites, and $2^$ of $[0,1]$ being far too big, etc. But we want a smooth domain, so that we can get a nice $pdf$ to integrate over... Solution: start with the standard topology over the real line, and then ""fill"" the gaps by turning it into a sigma algebra. Reference: On minute:sec 57:39 of this video the speaker ends up the segment with the words: ""That very often is very useful."" This prompted my question. Where is it needed in probability?","['probability', 'measure-theory']"
1748789,"Primes of the form $(2p)^{2}+1$, $p$ prime, have $h^{2}+1$ as a prime divisor?","I'm an undergraduate student and I usually ask questions here about things I'm struggling with in my academical mathematical studies, but this particular question is actually more like a curiosity. More specifically, I'm playing around with that ""famous"" problem of creating a sequence that only generates prime numbers. I know that many people have tried this and it is a very hard problem, but this is part of mathematics, right? I mean, attacking hard problems as a (yet) naive student at the very least to make you realize how difficult they actually are and hopefully motivates for further study on the issue. Feel free to say that I'm wasting my time, though. So, to the question: I realized that the numbers $N$ of the form $N=(2p)^{2}+1$, where $p$ is prime, are often prime numbers (at least for small $p)$. This is sort of justified by the fact that it will never by divisible by a prime $q\equiv 3\pmod 4$, since it would imply that $-1$ is a quadratic residue mod $q$. Hence, all its prime divisors are $\equiv 1\pmod 4$, and in particular, all of its divisors are of this form, since $1\cdot 1\equiv 1\pmod 4$. Now, I thought of that famous result that says that any prime $\equiv 1\pmod 4$ can be written as a sum of two squares of integers, and hence such a number $N$ would be of the form (in prime factorization)
\begin{equation}
N=(a^{2}+b^{2})(c^{2}+d^{2})\dots(x^{2}+y^{2}).
\end{equation} My question (for now, since I've just started these investigations), is: Is it true that, when $N$ is not prime, one of these prime factors will always be the form $h^{2}+1$? This is happening in my particular examples. I guess this is a hard question, and I'd appreciate any efforts, or references. Thanks.","['number-theory', 'elementary-number-theory']"
1748796,"Let $\nu$ be a signed measure, then E is $\nu$-null iff $|\nu|(E)=0$","I am having trouble with understanding the proof of the forward direction. In all the proofs I have seen it's always the case that the following fact is implied. Taking a Hahn Decomposition $X=P\cup N$. $\nu(E)=0 \Rightarrow \nu(E\cap P)=0$ since $E\cap P\subset E$. However why is this true? An example, proving $E$ is $\nu$-null iff $|\nu| (E)=0$ . I can only deduce $0=\nu(E)=\nu(E\cap P)+\nu (E\cap N)$ and $\nu(E\cap P)\geq 0$ since it is a subset of P, but $\nu (E\cap N)$ could still be negative. Alternatively, are there any other proofs?",['measure-theory']
1748834,An automorphism that has no fixed points except for the identity and is its own inverse implies commutativity,"Let $G$ be a finite group and suppose there exists $f\in\text{Aut}(G)$ such that $f^2=\text{id}_G$, i.e., $f$ is its own inverse, and such that $f$ has no fixed points other than the identity $e$ of $G$, i.e., $f(x)=x\Rightarrow x=e$. Show that $G$ is necessarily abelian. While trying to do this exercise I noticed two facts. First, $g$ and $f(g)$ have the same order because $o(f(g))|o(g)$ and, applying $f$ again and using $f^2=\text{id}_G$, $o(f(f(g)))=o(g)|o(f(g))$ and, once the order of any element is $\geq 1$, it follows that $o(g)=o(f(g))$. Also, it's easy to see that $g$ and $f(g)$ commute. Second, there cannot exist such an automorphism if the order of $G$ is even, because $f(e)=e$ and we can form pairs like $\{g,f(g)\}$ with $f(g)\neq g$ that are invariant under $f$, i.e., $f(\{g,f(g)\})=\{g,f(g)\}$. But once the order of $G$ is even, proceeding with the construction of the pairs, we'll end up with just one element $\neq e$, so we must have some $\gamma\in G\setminus{e}$ with $f(\gamma)=\gamma$, contradicting the hypothesis. Let $n$ be the order of $G$ and let's fix an enumeration of the elements of $G$, say $G=\{g_1,\ldots,g_n\}$. My approach was the following. For each $\sigma\in S_n$, let $x_{\sigma}=\prod_{i=1}^ng_{\sigma(i)}$. Then we have that $f(x_{\sigma})=x_{\sigma^{\prime}}$. If it's shown that $f(x_{\sigma})=e\;\forall\;\sigma\in S_n$, then we'd have $x_{\sigma}=e\;\forall\;\sigma\in S_n$, which implies that $G$ is abelian. The problem is that $S_n$ has $n!$ elements while $G$ has $n$ elements, so there repetitions among the $x_{\sigma}$, and we cannot apply directly the reasoning of the last paragraph. Is this the right way, or is there an easier manner to solve this?","['finite-groups', 'group-homomorphism', 'permutations', 'group-theory']"
1748861,Does every non-Archimedean absolute value satisfy the ultrametric inequality?,"The Archimedean property occurs in various areas of mathematics; for instance it is defined for ordered groups, ordered fields, partially ordered vector spaces and normed fields. In each of these contexts it is roughly the following property: Archimedean property. For any two (strictly) positive elements $x$ and $y$ there is some $n\in\mathbb{N}$ such that $n \cdot x$ exceeds $y$. This definition might not be adequate in each of the mentioned contexts, but at least it conveys the general idea. Indeed, in the context of normed fields we have the following definition (paraphrasing the definition given on Wikipedia): Definition. Let $F$ be a field with an absolute value $\left|\:\cdot\:\right|$, that is, a function $\left|\:\cdot\:\right| : F \to \mathbb{R}_{\geq 0}$ satisfying the following properties: $|x| = 0$ if and only if $x = 0$; For all $x,y\in F$ we have $|xy| = |x|\cdot |y|$; For all $x,y\in F$ we have $|x + y| \leq |x| + |y|$. Then $F$ is said to be Archimedean if for any non-zero $x\in F$ there exists some $n\in\mathbb{N}$ such that
  $$ \big|\:\underbrace{x + \cdots + x}_{n\ \text{times}}\:\big| > 1. $$
  An absolute value that does not satisfy this property is called non-Archimedean . However, in the literature the term non-Archimedean absolute value is usually used as a synonym for an absolute value which satisfies the ultrametric inequality: For any $x,y\in F$ we have $|x + y| \leq \max(|x|,|y|)$. It is not so hard to see that an ultrametric absolute value can never be Archimedean: one easily proves that $|1| = 1$ holds, and then we find $|1 + 1| \leq 1$, followed by $|1 + 1 + 1| \leq 1$ and so on (repeatedly using the ultrametric inequality). It is however not so clear to me that any non-Archimedean absolute value must necessarily satisfy the ultrametric inequaltiy. Is this always true? Or is it only true for certain fields, say $\mathbb{Q}$, that happen to be the most common fields in the study of absolute values on fields?","['valuation-theory', 'abstract-algebra', 'field-theory', 'absolute-value']"
1748885,Difference in Notation for Vectors in Linear Algebra & Multivariable Calculus,"Often in Linear Algebra we see vectors depicted either in Column or Row Form as : Linear Algebra : Vector in Row Form $$ \vec{V}^{\,} = \left[x_1,\ldots,x_n\right]$$ OR Linear Algebra : Vector in Column Form $$ \vec{V}^{\,} = \left[\begin{array}{c}x_1\\\vdots\\x_n\end{array}\right]$$ But in Multivariable Calculus, often, angle brackets/chevrons are used to represent vectors like so : Representation of a Vector in Multivariable Calculus: $$ \vec{V}^{\,} = \left<x_1,\ldots,x_n\right>$$ Is there any fundamental difference between these three representations of Vectors or is it purely a difference in notation and convention?","['notation', 'multivariable-calculus', 'soft-question', 'linear-algebra', 'vectors']"
1748894,Is $(2x+ y) dx - xdy = 0$ a separable differential equation?,"I was given the following differential equation in an assignment the other day: $(2x+ y) dx - xdy = 0$ The problem specified to solve the equation using the method of separation of variables. My problem was setting the integral, I tried multiple manipulations with but nothing seemed to work. So, I have to ask can this equation be solved using separation of variables?","['ordinary-differential-equations', 'calculus']"
1748904,"For every nonzero vector $v$ there exists a linear functional $f$, sucht that $f(v) \neq 0$.","I want to prove that for all $v \in V$ with $v \neq 0 \implies \exists f \in V^{*} : f(v) \neq 0$. I know that if $V$ is finite-dimensional we can choose a basis $\{e_i\}$ of $V$ and construct the corresponding dual basis $\{e^{*}_i\}$. If $v \neq 0$ then necessarily at least one component of $v$ with respect to $\{e_i\}$ must be nonzero. WLOG let $v^{j} \neq 0$ then $e^{*}_j(v) = v^{j} \neq 0$ proving the theorem. However, I think this theorem should be true even in the infinite-dimensional case and I would like to see a basis-free proof (i.e. a proof that doesn't require a choice of basis). Apparently there's a proof in this question , but I'm pretty sure that the constructed functional $f$ is not linear. For the sake of argument let me reproduce the answer here: Let $v \neq 0$ and let $H$ be a subspace of $V$, such that $V = \operatorname{span}(v)\oplus H$. Define $f: V^{*} \to \mathbb{F}$ by $f(v) = 1$ and $f(h) = 0$ for all $h \in H$. Now, let's check whether $f$ is homogenous. Let $w \in \operatorname{span}(v)$, such that $w = \alpha v$ for some nonzero $\alpha \in \mathbb{F}$. We need to show that $f(w) = f(\alpha v)$ equals $\alpha f(v) = \alpha$. However, by definition $f$ is nonzero only for the vector $v$ and we get $f(w) = 0 \neq \alpha = \alpha f(v)$. Even if we interpret the definition of $f$ to mean that $f(s) = 1$ for all $s \in \operatorname{span}(v)$ it doesn't work out. How is this supposed to work out?",['linear-algebra']
1748905,Can you define linear maps between vector spaces over different fields? [duplicate],This question already has an answer here : ''Linear'' transformations between vector spaces over different fields (1 answer) Closed 3 years ago . My book defines linear maps between vector spaces with a chosen fixed field but can you define linear maps between vector spaces over different fields? Is there any reason to restrict attention to fixed fields?,"['abstract-algebra', 'vector-spaces']"
1748914,Galois group of splitting field over $\mathbb{Q}$,"Describe the structure of the Galois group of the splitting field $L$ of the polynomial $X^4-7$ over $\mathbb{Q}$ I believe that $L=\mathbb{Q}(\sqrt[4]{7}, i)$ is the splitting field of the polynomial Now I need to describe the structure of $Gal(L, \mathbb{Q})$ $H=Gal(L, \mathbb{Q}(i))$ is a cyclic group of order $2$ generated by $\tau_1$ such that: $\tau_1(\sqrt[4]{7})=i\sqrt[4]{7}$ $Gal(L, \mathbb{Q}(\sqrt[4]{7}))$ is a cyclic group generated by $\tau_2$ such that: $\tau_2(\sqrt[4]{7})=\sqrt[4]{7}$ and $\tau_2(i)=-i$ I believe that $Gal(L, \mathbb{Q})$ consists of the identity element $e$ and some multiplied combinations of $\tau_1$ and $\tau_2$ but could do with some help filling in the gaps and improving my understanding","['galois-theory', 'splitting-field', 'abstract-algebra', 'group-theory', 'field-theory']"
1748947,Why does the power series of $ x + x^2 + x^3 ...$ not equal to $x/(1-x) $ when x is larger than 1?,"Why does the power series of $x + x^2 + x^3\ldots$ not equal to $x/(1-x)$ when $x$ is larger than $1$? It is never specified what range of values $x$ takes on, so the algebra should work out in all cases. Why does it not work out when $x \gt 1$?",['algebra-precalculus']
1748958,A Property of Martingale of Sum of i.i.d. Random Variables,"I am trying to solve the following problem: Let $\{Y_n\}_{n=1}^{\infty}$ be a sequence of i.i.d. random variables with finite mean. Let $F_n =\sigma(Y_1,...,Y_n)$. Let $\tau$ be a stopping time adapted to the filtration $\{\mathcal{F}_n\}_{n=1}^{\infty}$ with finite mean. Define $X_n = \sum_{i=1}^n Y_i$. Show that $E(X_\tau) = E(Y_1)E(\tau )$. The following is also given as a hint: Write $X_\tau$ as
$\sum_{k} Y_kg_k(\tau )$, where $g_k(\tau)$ is $\mathcal{F_{k-1}}$-measurable. I tried to take 
$$g_k(n)=\begin{cases}1\ \ {\rm if }\ \  k\leq n \\ 0\ \ \ {\rm otherwise}\end{cases}$$
But this turns out to be not $\mathcal{F_{k-1}}$-measurable, since $\tau^{-1}(g_k^{-1}(1))$ is the union of $\{\tau=m\}$'s for all $m$'s larger than or equal to $k$. Am I doing something wrong? Is there a better set of functions to take?","['martingales', 'probability-theory', 'measure-theory', 'statistics']"
1748973,Why is chi-square distribution with 2 degrees of freedom an exponential distribution?,"Is there any explanation on why these two distributions are equivalent? How can the sum of two square of Gaussians represents the limit of a geometric distribution? I found an answer here, which says it is just coincidence. But I have a hard time believing it.","['probability-theory', 'probability-distributions']"
1748982,Proving that $-1$ has no square root in $\mathbb Z_3$ (3-adic integers),"I want to prove that $-1$ has no square root in $\mathbb Z_3$ (3-adic integers). By the definition of inverse limit, we know that there is a ring homomorphism $\phi$ from $\mathbb Z_3$ to $\mathbb Z/3 \mathbb Z$. So, if $\alpha$ is the square root of $-1$ in  $\mathbb Z_3$ then $\phi(\alpha)$ must be the square root of $-1$ in $\mathbb Z/3 \mathbb Z$. Since, there is no square root of $-1$ in $\mathbb Z/3 \mathbb Z$ this should imply $-1$ has no square root in $\mathbb Z_3$ (3-adic integers). Is the above argument correct? or am I missing something?","['number-theory', 'abstract-algebra', 'p-adic-number-theory']"
1748991,Convergence of $\int_0^{\infty} \frac{x^n}{(1+x^2)^m}dx$,"Suppose we have an integral of the form $$I(n,m):= \int_0^{\infty} \frac{x^n}{(1+x^2)^m}dx$$ Most of my test cases computed seem to indicate if $n\geq 2m-1$, then this integral diverges. I have a non-rigorous justification for this: just expand the bottom and look at leading terms. If we ignore lower order terms as we move towards $\infty$, the integrand will be of order $x^{n-2m}$. If $n= 2m-1$, then this will be $x^{-1}$, whose integral diverges here, and similarly for $n>2m-1$, whereas for $n<2m-1$, the integrand behave like $x^{-2}$ or greater negative powers, which will converge. This is all very nice intuitively, but I'm wondering if anyone has a more rigorous, formal approach to this? Here's a related question, of which this is a generalization.","['improper-integrals', 'integration', 'calculus']"
1749007,How to compute $\int \frac{1}{(x^2+1)^2}dx$?,Suppose we know $\int \frac{1-x^2}{(x^2+1)^2}=\frac{x}{x^2+1}+C$ How to compute $\int \frac{1}{(x^2+1)^2}dx$? I tried writing it as $\frac{1+x^2-x^2}{(x^2+1)^2}=\frac{1-x^2}{(x^2+1)^2}+\frac{x^2}{(x^2+1)^2}$. But then how do you deal with $\frac{x^2}{(x^2+1)^2}$? Some ideas?,"['partial-fractions', 'integration', 'calculus']"
