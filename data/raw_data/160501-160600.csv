question_id,title,body,tags
2774077,(NOT a physics question) Is electric field always asymptopic to $x^{\alpha}$ for some rational $\alpha$?,"In three dimensional space with origin $O$, you pick a finite number of points $P_1, P_2, \cdots, P_n$. To each point $P_i$ you assign a nonzero integer (positive or negative) $q_i$. For all other points $R$ in the plane, define the vector valued function $$\displaystyle \vec{F(R)} = \sum_{i = 1}^{n} \frac{q_i}{D(P_i, R)^2} \vec{r_i}, $$ where $D(P_i, R)$ is the Euclidean distance between $P_i, R$, and $r_i$ is a vector of unit magnitude directed from $P_i$ to $R$. Now you pick a ray $\vec{\ell}$ originating from $O$ in any direction. Is it true that for any such configuration of such points, there always exist an rational number $\alpha$ such that $\displaystyle \lim_{x \rightarrow \infty} \| F(R_x) \| x^{\alpha}$ converges to some nonzero constant, where $R_x \in \ell$  with $D(O, R_x) = x$ and $\| F(R_x) \|$ is the magnitude of the function at $R_x?$","['multivariable-calculus', 'physics', 'asymptotics', 'vector-analysis']"
2774093,Combinatorics problem-Centipede,"A centipede wants to put on its 100 legs 100 socks and 100 shoes. In how many different sequences can it put on all shoes and socks if it has to put on each sock on a leg before the shoe, but it can put on a sock on another leg before putting on a shoe on the former leg? 
I tried it by recursion, but it seems complicated.",['combinatorics']
2774106,why is the least square cost function for linear regression convex,"I was looking at Andrew Ng's machine learning course and for linear regression he defined a hypothesis function to be $h(x) = \theta_0 + \theta_1x_1 + \dots + \theta_nx_n$ , where $x$ is a vector of values,
so the goal of linear regression is to find $\theta$ that most closely estimates the real result in order to estimate how wrong the hypothesis is compared to how the data is actually distributed. He uses the least square $$
\mathrm{error} = (h(x) - y)^2, 
$$ where $y$ is the real result. Since there are a total of $m$ training examples he needs to aggregate them such that all the errors get accounted for. So he defined a cost function $$
J(\theta) = \frac{1}{2m}\sum_{i=0}^{m}(h(x_i) - y_i)^2, 
$$ where $x_i$ is a single training set. He states that $J(\theta)$ is convex with only $1$ local optimum. I want to know why is this function convex?","['machine-learning', 'real-analysis', 'linear-regression', 'least-squares']"
2774110,A Proposition on the Banach space,"I want to prove the following proposition. It comes from the exercise of Conway, Functional Analysis. Prop. Let $X$ be compact and suppose that $\mathfrak{X}$ is a Banach subspace of C(X). If $E$ is a closed subset of $X$ such that for every $g$ in $C(E)$ there is an $f\in \mathfrak{X}$ such that $f|_E=g$, then there is a constant $c>0$ such that for each $g\in C(E)$, there is $f\in \mathfrak{X}$ with $f|_E=g$ such that
$$
\sup_{x\in X}|f(x)|\leq c\sup_{x\in E}|g(x)|
$$ By the open mapping theorem, I observed that $f\mapsto f|_E$ is an open map. Maybe it needs Baire Category Theorem, but I have no idea how to use it. Please give me any hints. Thanks in advance.","['functional-analysis', 'banach-spaces']"
2774148,Open and Connectedness on the Topological Vector Space over $\mathbb{R}$ Implies Path-Connectedness,"I want to prove the following proposition (which is also the title). Open and connectedness of a subset G of the topological vector space X over $\mathbb{R}$ implies path-connectedness. I haven't proved this kind of proposition earlier, and I don't even know where to start. If $G$ is convex, then the proposition is trivial. But if $G$ is not convex, I have no idea how I can find the path between two arbitrary points. I suppose being a vector space over $\mathbb{R}$ is important, but I don't know how to use this fact. Should I instead prove that this is a locally path-connected space? Please give me any hints. Thanks in advance. Edit. Here is my another try. Fix $x\in G$ and let $U, V$ be 
$$
U:=\{y\in G|y,x\textrm{ are path-connected.}\}\\
V:=\{y\in G|y,x\textrm{ are not path-connected.}\}
$$ 
I claim that $U$ is open. If $G$ has a open convex neighborhood $W$ of $0$ (I am not sure about the existence of $W$ here), $y+\epsilon W \subset U$ when $y\in U$(again here I am not sure about the existence of $\epsilon$). Hence $U$ is open. Similarly, if $y\in U$, $y+\epsilon W\subset V$. $y\in U$ and $U\cap V=\emptyset$, but $U\cup V=G$ and since $G$ is connected, $U=G$. Thus $G$ is path-connected. There are some missing parts in the proof, and I don't know how I can complete it.","['functional-analysis', 'topological-vector-spaces', 'path-connected', 'connectedness']"
2774156,"Why do integrals ""start"" at 0? [duplicate]","This question already has answers here : Why is $f(4)$ the area under $f'(x)$ specifically from $0$ to $4$ and not for ex from $1$ to $4$ or $2$ to $4$? (3 answers) Closed 6 years ago . This is a dumb question and I don't really know how to word it. When you take an antiderivative and plug in number you are given the area under the curve starting at 0 (assuming C is 0). I can easily see how the derivative of an integral is given by the function value, but why does the integral start at 0 and not any other number? When I try to imagine the area of some curve starting at negative 1 for example the area under the curve would intuitively to me still be given by the antiderivative. 0 makes sense as a starting point but for some reason I can't visualize it. I'm not sure if that made any sense but if anyone could help me wrap my head around it I'd appreciate it.",['integration']
2774202,Sheaf cohomology of $\mathbb{A}^\infty_k$ without the origin,"Let $k$ be a field, $A = k[x_1, x_2, \dots]$ and $\mathfrak{m} \subset A$ be the maximal ideal $(x_1, x_2, \dots)$. Defining $U = \text{Spec}\, A \setminus \mathfrak{m}$, how may one compute the groups $H^i(U, \mathcal{O}_U)$? I was able to compute the Cech cohomology group for $i=1$ to be zero using the standard cover $D(x_i)$. This is then equal to the sheaf cohomology group because the sheaf is quasi-coherent and finite intersections of this cover is affine, the result applying for any higher cohomology groups as well (look at the Cech-to-derived functor spectral sequence). Is there an easy way to see what the groups should look like for $i > 1$?","['sheaf-cohomology', 'algebraic-geometry']"
2774256,Some interesting integrals with dilogarithm,"Calculating without techniques involving the contour integration $$a) \ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^2-(\operatorname{Li}_2(e^{i x}))^2}{e^{-i x}-e^{i x}}\textrm{d}x;$$ $$b) \ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^3-(\operatorname{Li}_2(e^{i x}))^3}{e^{-i x}-e^{i x}}\textrm{d}x.$$ I'm working now on such a method. What would your real method inspiration be here? Supplementary question : Calculate $$ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^4-(\operatorname{Li}_2(e^{i x}))^4}{e^{-i x}-e^{i x}}\textrm{d}x.$$ Moreover, may we hope for a generalization of the type below? $$ I(n)=\int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^n-(\operatorname{Li}_2(e^{i x}))^n}{e^{-i x}-e^{i x}}\textrm{d}x.$$ Preparing another two generalizations: $$ i) \ J(n,m)=\int_0^{2\pi} \frac{(\operatorname{Li}_m(e^{-i x}))^n-(\operatorname{Li}_m(e^{i x}))^n}{e^{-i x}-e^{i x}}\textrm{d}x;$$ $$ ii) \ K(n)=\int_0^{2\pi} \frac{\operatorname{Li}_2(e^{-i x})\operatorname{Li}_3(e^{-i x})\cdots \operatorname{Li}_n(e^{-i x})-\operatorname{Li}_2(e^{i x})\operatorname{Li}_3(e^{i x})\cdots \operatorname{Li}_n(e^{i x})}{e^{-i x}-e^{i x}}\textrm{d}x.$$","['calculus', 'complex-analysis', 'integration', 'definite-integrals', 'special-functions']"
2774268,Show that short exact sequence of abelian groups $0\to A\to B\to\mathbb{Z}\to 0$ is split. [duplicate],"This question already has an answer here : Exact sequence of abelian groups, special case [duplicate] (1 answer) Closed last month . My question is similar to the following two questions: Exact sequence of abelian groups, special case and Show $0 \to A\mathop \to B\mathop \to C \to 0$ is split when $C$ is a free Abelian group , but neither have been answered. I have an idea of how to do this proof: Let $0\to A\to B\to\mathbb{Z}\to 0$ be a short exact sequence of abelian groups with $f:A\to B$ and $g:B\to\mathbb{Z}$. I want to use the splitting lemma, which states that if there exists a map $j:\mathbb{Z}\to B$ with $gj=1_{\mathbb{Z}}$, then the sequence is split. Because this is a short exact sequence, we have that $B/A\cong\mathbb{Z}$. Then because $\mathbb{Z}$ is cyclic, so is $B/A$, and in particular $b+A$ for some $b\in B$ generates all of $B/A$. I then want to use this fact somehow to construct a map from $\mathbb{Z}\to B$ which composes with $g$ to give the identity in $\mathbb{Z}$, but I can't quite figure out the construction.","['abstract-algebra', 'exact-sequence', 'group-theory']"
2774305,"Is f(x,y) continuous at (0,0) $ f(x,y) = (x+y)^2\cos\left(\frac{1}{\sqrt{x^2+y^2}}\right)$","Show if the following function of two variables has a limit in (0,0).
$$ f(x,y) = (x+y)^2\cos\left(\frac{1}{\sqrt{x^2+y^2}}\right);(x,y)\ne(0,0);f(0,0)=0 $$
I tried to find a limit of the function by substituting y = x:
$$ f(x,x) = 4x^2\cos(\frac{1}{x\sqrt{2}}) $$
Then easily by squeeze theorem:
$$ \lim_{(x,y)\to(0,0)}f(x,x) = 0 $$
On the other hand, after a little fiddling with it, I've come to this:
$$ f(x,y) = \frac{\cos\left(\frac{1}{\sqrt{x^2+y^2}}\right)}{(\frac{1}{\sqrt{x^2+y^2}})^2} + \cos\left(\frac{1}{x^2+y^2}\right)2xy $$
EDIT: Here I thought the left side should go to $\infty$, which is obviously wrong. When f(x,y) approaches (0,0), $\frac{1}{f(x,y)}$ approaches infinity. Thus everything is in order.
$$ \lim_{(x,y)\to(0,0)} f(x,y) = 0 $$
EDIT: Also, a very useful and stunningly easy solution (from answer below) is using squeeze theorem with cos.
$$ -(x+y)^2 \le (x+y)^2\cos(g(x)) \le (x+y)^2 $$
From that it's easily seen that function is continuous.","['multivariable-calculus', 'continuity', 'limits']"
2774323,Check the continuity of a function of two variables,"I've been trying to check the continuity of the following function: $$ f(x,y) = 
\begin{cases}
    \frac {(x-1)(y-4)^2}{(x-1)^2+\sin(y-4)}      & \quad \text{(x,y) } \ne \text{ (1,4)}\\
    0  & \quad \text{(x,y) } = \text{ (1,4)}
  \end{cases} $$ I've tried calculating the following $lim$ , as $t = x-1$ , and $ z = y-4 $ : $$ \lim_{{(t,z)\to(0,0)}}{ \frac {tz^2}{t^2+\sin(z)}} $$ I've tried choosing different paths: $ t=z$ and $t=z^2$
but both gave me the same result - $0$ . I'm not sure how to prove or disprove that the limit is $0$ . I'd appreciate your help, thanks!","['multivariable-calculus', 'continuity', 'functions', 'limits']"
2774375,"Does $\exists n : 6 + \sum_{i=2}^n p_i = x^6+y^6$ for $p_i$ the $i^{\text{th}}$ prime and $x,y\in\mathbb{Z}$?","I noticed something about the prime numbers: Pick the number $2$ . Then, add the first odd prime, namely $3$ . The result is $5 = 1^2+2^2$ . Notice that the exponents are also the number we picked. Pick the number $4$ . Add the first odd prime, then the second, and the third, all the way up to $71$ . It follows that $$4+3+5+\cdots + 67+71=5^4 + 2^4.$$ I cannot find a number $n$ such that when you add all the $n$ odd primes together, and then add $6$ (the next even number from $4$ ) then the result is $x^6+y^6$ for $x,y\in\mathbb{Z}$ . Does there exist a number $n$ for this specific case? Is there a more mathematical way of finding out as opposed to brute-force? Thank you in advance.","['square-numbers', 'sums-of-squares', 'number-theory', 'summation', 'prime-numbers']"
2774410,Proper use of various derivative and partial derivative notations,"I think I have seen all of these notations and more used for derivatives: $\dot f(x)$, $f'(x)$, $f_x(x)$, $df(x)/dx$, $D f(x)$ and for partial derivatives: $\partial f(x,y)/\partial x$, $\partial_x f(x,y)$, $f_x(x,y)$, $D_x f(x,y)$ and the corresponding notations used for higher order derivatives for derivatives: $f''(x)$, $f_{xx}(x)$, $d^2f(x)/dx^2$, $D^2_x f(x)$ and for partial derivatives: $\partial^2 f(x,y)/\partial x^2$, $\partial_{xx} f(x,y)$, $f_{xx}(x,y)$, $D_{xx} f(x,y)$ I also think I have seen many of these used without the function argument, e.g $f'$ or $f_x$. My question is: Is there an accepted proper usage for these derivative notations. Any links or references would be appreciated. See also Why are there so many notations for differentiation?","['derivatives', 'partial-derivative', 'notation']"
2774413,How many different 'knot shadows' can a circle embedded in high dimension have?,"Suppose I take a map $\gamma : S^1 \to \mathbb{R}^n$, where $n > 3$. Then, I can project $\gamma$ onto a 3-dimensional subspace of $\mathbb{R}^n$, and (for generic choice of subspace), I will end up with a knot in $\mathbb{R}^3$. Can we say anything about the number of inequivalent knots that we can get from projecting a single $\gamma$ onto different subspaces? For instance, for $n = 6$, we can have at least two inequivalent 'knot shadows', by the following construction. Take $\gamma_1, \gamma_2 : S^1 \to \mathbb{R}^3$ to be two different knots, and let
$$\vec{\gamma}(t) = (\vec{\gamma_1}(t), \vec{\gamma_2}(t))$$
so that the projection onto the first three coordinates gives the knot $\gamma_1$ and the projection onto the second three coordinates gives the knot $\gamma_2$. I've not been able to find a similar construction (for multiple knot shadows) for $n=4$ or $n = 5$, though I believe that it should exist. Also, I have not been able to find a construction that gives three different knot shadows, though I believe that should exist.","['knot-theory', 'general-topology']"
2774463,How can I understand the fundamental theorem of line integrals in terms of differential forms on manifolds?,"Let $f$ be a differentiable function $\mathbb{R}^3\rightarrow\mathbb{R}$. Let $x,y,z$ be the standard coordinates on $\mathbb{R}^3$. Let $r : [0,1]\rightarrow\mathbb{R}^3$ be a smooth parametrized curve, with image $C$. In the fundamental theorem of line integrals, it is often said that:
$$\int_C df = \int_C\nabla f\cdot dr = f(r(1)) - f(r(0))$$ Now, on the far left, I understand ""$df$"" to be the differential form
$$df = \frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy + \frac{\partial f}{\partial z}dz\in \Omega^1(\mathbb{R}^3)$$
restricted to $C$. Thus, the left hand side makes sense, as the integral of a differential form. But what about $\int_C\nabla f\cdot dr$? In what sense is $\nabla f\cdot dr$ a differential form on $C$? To me, $\nabla f$ is defined to be a vector field on $\mathbb{R}^3$, which via the standard Riemannian metric on $\mathbb{R}^3$ can be identified with a differential 1-form (if it helps) In this case, we probably really want to think of $\nabla f$ as its restriction $\nabla f|_C$ to $C\subset \mathbb{R}^3$. How should I think of ""$dr$""? One thought is to view $dr$ as a vector field on the image $C$ of $r$, namely $dr|_{r(t_0)}$ is the tangent vector at $r(t_0)\in \mathbb{R}^3$ represented by the germ of the parametrized curve $r$ at $t_0$. Ie, it is the tangent vector defined by the derivation:
$$dr|_{r(t_0)} = \frac{\partial (x\circ r)}{\partial t}(t_0)\frac{\partial}{\partial x} + \frac{\partial (y\circ r)}{\partial t}(t_0)\frac{\partial}{\partial y} + \frac{\partial (z\circ r)}{\partial t}(t_0)\frac{\partial}{\partial z}$$
on the ring of germs of smooth functions at $r(t_0)$. If we view $dr$ this way, then the dot product $\nabla f\cdot dr$ makes sense, but unfortunately it's value is a scalar field (ie a function) on $\mathbb{R}^3$, not a differential form. How do we view it as a differential form? In particular, I would like to understand how exactly is it true that
$$""\frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial y}dy + \frac{\partial f}{\partial z}dz = \nabla f \cdot dr""$$","['differential-geometry', 'differential-topology']"
2774464,Statement on prime factors of Fibonacci numbers with prime index,"Consider the set of Fibonacci numbers $F_{i}$ with a prime index $p$, $\mathcal{F}_{\mathbb{P}}$. The first few numbers in this set are: $\mathcal{F}_{\mathbb{P}} = \{F_2,\; F_3,\; F_5,\; F_7,\; F_{11},\; F_{13},\; ...\} = \{1,\; 2,\; 5,\; 13,\; 89,\; 233,\; ...\}$ Is every prime factor of these Fibonacci numbers necessarily larger or equal to its index for $p \geq 5$? Some comments: Because $\mbox{gcd}(F_{m},F_{n})=F_{\text{gcd}(m,n)}$ for $m,n\ge 1$, a Fibonacci number with a prime index $p$ must necessarily be coprime with every Fibonacci number possessing an index not equal to $1$ or integer multiples of $p$. Consequently, there are quite a few numbers that cannot be prime factors for each member of $\mathcal{F}_{\mathbb{P}}$, but prime numbers that are not Fibonacci numbers ($7$, for example) can always be potential prime factors based on the above criteria. A rudimentary search through $p < 50$ shows that no prime factors of $F_p$ are smaller than $p$. Can this be proven/disproven for all $p$?","['number-theory', 'fibonacci-numbers', 'prime-numbers', 'prime-factorization']"
2774472,"Minimum length of a nontrivial word in $[[F_n,F_n],F_n]$","Let $F_n$ be the free group on $n$ generators.  I would like to know what the minimum length of a nontrivial word in the third term in the lower central series of $F_n$ is - (i.e. $[[F_n,F_n],F_n]$). I know that since the exponent sum must be even, and length has the same parity as exponent sum, the length must be even.  I know that it can not be less than 4 and with some simple guessing I can get elements of length 8.  Could I ever find elements of length 6 or 4?","['combinatorial-group-theory', 'group-theory', 'free-groups']"
2774501,Prove that $g^m=1$ for any element $g$ in a finite group of order $m$,"Let $\mathbb{G}$ be a finite group with $m = |\mathbb{G}|$, the order of the group. Prove that $g^m = 1$ for any element $g \in \mathbb{G}$. I can prove it if $\mathbb{G}$ is abelian.
If $\mathbb{G}$ is abelian, for an arbitrary $g \in \mathbb{G}$ and $g_1, \cdots g_m \in \mathbb{G}$, 
$$g_1 \circ g_2 \circ \cdots \circ g_m = (g \circ g_1)\circ(g \circ g_2) \cdots (g \circ g_m) = g^m \circ (g_1 \circ g_2 \cdots g_m)$$
Since the right-hand side is equal to the left-hand side, $g^m = 1$. However, I really don't know how to prove it when $\mathbb{G}$ is not abelian.","['finite-groups', 'group-theory']"
2774514,Questions concerning the canonical construction of a Brownian motion.,"I have some questions concerning the canonical construction of a Brownian motion and would be very happy if someone can help me. In my probability lecture I have seen the following definitions: Let $W = \{W_t : t \geq 0\}$ be a Brownian motion starting from $0$ defined on some probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and let $C = C(\mathbb{R}_+, \mathbb{R})$ be the space of real-valued continuous functions $$x: \mathbb{R}_+ \rightarrow \mathbb{R}, t \mapsto x(t).$$ $C$ is endowed with the topology induced by uniform convergence on compact sets. We denote by $\mathcal{C}$ the associated Borel $\sigma$ -field. $\mathcal{C}$ is generated by cylindrical sets $$B = \{x \in C : x(t_1) \in A_1, \ldots, x(t_m) \in A_m\}$$ , where $t_1, \ldots, t_m \in [0, \infty)$ and $A_1, \ldots, A_m \in \mathcal{B}(\mathbb{R})$ . My questions are: Why is the event $\{\omega \in \Omega : \{W_t(\omega) : t \geq 0\} \in B\}$ necessarily an element of $\sigma(W)$ for all $B \in \mathcal{C}$ and why does this imply that $\mathbb{W}(B) = \mathbb{P}(W \in B)$ on $(C, \mathcal{C})$ is a probability measure (called the Wiener measure) ? Does the definition of the Wiener measure depend on the initial choice of the Brownian motion $W$ ? I would like to prove that the canonical process $$X : C \rightarrow C : x = \{x(t) : t \geq 0\} \mapsto \{X_t(x) : t \geq 0\}$$ , defined by $$X_t(x) = x(t)\ \forall\ x \in \mathbb{C}, \forall\ t \geq 0$$ is a Brownian motion. For this, I  have to check the conditions of the definition of a Brownian motion. It is clear that for every fixed $\omega \in \Omega$ , $t \mapsto X_t(\omega)$ is continuous. However, how do I show $X$ is Gaussian with zero mean and $$cov(X_t(x), X_s(x)) = \mathbb{E}[x(t)x(s)] = min(s, t) ?$$ Any hint or comment will be much appreciated. Thanks for your help.","['stochastic-processes', 'probability-theory', 'probability', 'measure-theory', 'brownian-motion']"
2774547,A question about the shape operator of a minimal hypersurface.,"I was reading a paper about minimal hypersurfaces. The author said that the Codazzi equation for a hypersurface $M$ in a manifold with constant sectional curvature is given by $(\nabla A)(X,Y)=(\nabla A)(Y,X)$ where $A$ is the shape operator of $M$ and $(\nabla A)(X,Y)=\nabla_X(AY)-A(\nabla_XY)$. Then the author said that if $M$ is a $minimal$ hypersurface then in a local orthonormal frame $\{e_1,e_2,...,e_n\}$, we have \begin{equation}
(\nabla A)(e_i,e_i)=0
\end{equation} I couldn't figure out why this should be true. If $M$ is minimal then all I know is that in the orthonormal frame $\sum_{i=1}^n g(Ae_i,e_i)=0$. I tried to differentiate it and get the expression but I was unable to do so. Can you please help me with this ? Thanks","['minimal-surfaces', 'riemannian-geometry', 'differential-geometry', 'proof-explanation']"
2774575,Does there exist a formula to calculate $2.357137939171\ldots$?,"So I was messing with polynomials and I encountered the following equation: $$26214x^3 - 27761x^2 - 71019x - 21667 = 0.$$ Solving for $x$ using the cubic formula, I got three solutions (as expected, pursuant to the FTOA, namely, the Fundamental Theorem of Algebra). Let's call the equation $p(x)$ and I will denote by $p(x)_n$ the $n^{\text{th}}$ root of $p(x)$ . $p(x)_{1,2}<0$ but $p(x)_3>0$ . In fact, $$p(x)_3 = 2.3571379391713739171440\ldots$$ Notice that we begin with the first four primes $2,3,5,7$ and then we go to $1,3,7,9$ . Also notice that the next four primes after $7$ are $11,13,17,19$ . That's when I realised that $p(x)_3$ has its decimal places being the last digit of primes, apart from $4,4,0$ . Question: Let $d_n$ be the last digit of the $n^{\text{th}}$ prime, then is the decimal $2.d_2d_3d_4\ldots$ transcendental ? Does it have a formula? Can a formula be constructed? Thank you in advance.","['transcendence-theory', 'polynomials', 'sequences-and-series', 'prime-numbers']"
2774583,Is there a continuous and surjective mapping from a simple connected space to the topologist's sine curve?,"The topologists sine curve is the set: $$ T =\left\{\left(x, \sin\left(\frac{1}{x}\right)\right): x \in (0,1) \right\} \cup\{(0,y):y\in \mathbb{R}\}$$ A common (and fun!) exercise is to prove that the set is connected. The usual answer goes like this: (1) the graph of the function $f(x) = \sin\left(\frac{1}{x}\right)$ is the graph of a continuous function over a connected domain, so there is an homeomorphism between its domain and the graph, thus the graph is connected (2) $(0,0)$ is a limit point of the graph, so if we add it to the set connectedness is preserved (3) $T$ is then the union of the set constructed in the last step and the $y$ axis, being the union of two non disjoint connected sets, $T$ is also connected. I am interested in solving the problem directly at step 1 by finding a continuous map from some simple connected set to $T$. My (wrong) candidate would be: Let $M = \{(0,y) \in \mathbb{R}^2 : y \in \mathbb{R} \}\cup\{(x,0) \in \mathbb{R}^2 : x \in (0,1) \}$. Let $g:M\to T$ defined as: $$g(x,y) = \begin{cases}
(x,\sin\left(\frac{1}{x}\right)) & \mbox{if $0\lt x \lt 1$,}\\\
(x,y) & \mbox{otherwise}\end{cases}
$$ The function would ""transform"" a connected subset of the $x-y$ axis into $T$, but now I see that my construction is not continuous*. Could we change $g$ in any way to make it continuous? Or maybe there is another connected (and simple!) set for which there is a continuous map into $T$? *we could get a sequence $(X_k,0)$ in $M$ going to $(0,0)$ but for which $g(X_k,0)$ is not going to $g(0,0)$ ** I have no definition for ""simple"", I hope it makes sense","['general-topology', 'connectedness']"
2774599,"Can $f, g \in L^{1}(\mathbb{R})$ imply $ \lim_{x \to \infty} (f * g)(x) = 0 $","Can $f, g \in L^{1}(\mathbb{R})$ imply 
$$
\lim_{x \to \infty} (f * g)(x) = 0
$$
or not? $*$ denotes convolution here: 
$$
(f*g)(x) = \int_{\mathbb{R}} f(t)g(x-t)\ dt
$$ I read that when $f \in L^{p}$ and $g \in L^q$, we can prove $f * g(x)$ vanishes at infinity, using Holder's inequality to estimate $\int_{B(0,R)^C}| f(t)g(x-t) | dt$. But in the case of $L^1(\mathbb{R})$ I have difficulty in the estimation. I guess it is true but not so sure. Any help is appreciated!","['functional-analysis', 'lp-spaces', 'integration', 'convolution']"
2774682,Inhomogeneous Wave Equation Energy Method,"Let $u$ be a solution to the following equation: $$
u_{tt}=u_{xx}−u^3
$$
Assume that $u(x,0) =u_t(x,0) = 0$ for all $x\in[a, b]$.  Prove that $u(x, t) = 0$ if $a+t < x < b−t$. I initially thought of using Duhamel's principle on this but realized that the cube in the integrand would make things a little tricky. I was also thinking of using an energy functional and showing that it was $0$ everywhere and nonincreasing. What would the functional be, and what would/should the domain of integration be?","['multivariable-calculus', 'wave-equation', 'calculus-of-variations', 'partial-differential-equations']"
2774685,Find the range of $a$,"If the function $$f(x)=[4.8+a\sin x]$$ where $[.]$ denotes the greatest integer function, is an even function then find the range of $a$. So, if the function of even then $f(-x)= f(x)$. Therefore,$$[4.8+a\sin x]=[4.8-a\sin x]$$ $$\implies [0.8+a\sin x]=[0.8-a\sin x]$$
But I don't have any idea what to do next, please help.
Cheers","['even-and-odd-functions', 'functions', 'ceiling-and-floor-functions']"
2774710,Angle of Intersection Between two Planes as Viewed from an Oblique Third Intersecting Plane,"Two planes, $P_1$ and $P_2$ intersect in a line. I am interested in the angle $\alpha$ between them as measured from a third mutually intersecting plane $P_{int}$. The intersections of $P_{int}$ with $P_1$ and $P_2$ can be visualized on $P_{int}$ as two lines meeting at a common point $v$. The angle these two lines make at this vertex $v$ is what I call $\alpha$. I presume that $\alpha$ equals the dihedral angle of $P_1$ and $P_2$ only when $P_{int}$ is orthogonal to the two planes. Now suppose $v$ is fixed and I rotate $P_{int}$ by an angle $\beta$ (with the vertical) to make it oblique. Then the angle measured between two intersecting lines on $P_{int}$ will be different from the actual dihedral angle. My question is how can I relate the two angles $\alpha$ and $\beta$? Thanks.","['euclidean-geometry', 'geometry']"
2774712,How can one trust geometric proofs if humans are susceptible to optical illusions?,"How can one make a proof that doesn't consist of a bunch of symbolic manipulations ""formal""?","['fake-proofs', 'geometry']"
2774891,"How to show that when $F_n$ is divided by $F_m$($n>m$),then the remainder r is Fibonacci number or $F_m -r$ is a Fibonacci number?","How to show that  when $F_n$ is divided by $F_m$($n>m$),then the remainder r is Fibonacci number or $F_m -r$ is a Fibonacci number? On applying Division algorithm,we get $F_n=kF_m+r;0\le r<F_m$ How to proceed further? EDIT If we prove  that both $F_m-r$ and $r$ both are not Fibonacci number then $F_m $  is not Fibonacci number then we are done?","['number-theory', 'fibonacci-numbers', 'elementary-number-theory']"
2774904,Examples of integral $k$-algebra,"Definition : We say that a ring $R$ is an integral $k$-algebra if it is a $k$-algebra that is an integral domain. We say that a ring $R$ is an geometrically integral $k$-algebra if it is a $k$-algebra such that for every field extension $k'\supset k$, the ring $R\otimes_{k}k'$ is an integral $k'$-algebra. The first example I want to find is an integral $k$-algebra $R$ such that $k$ is a perfect field and $R$ is not a geometrically integral . Secondly, when $k$ is an imperfect field , I want to find an integral $k$-algebra $R$ such that for a field extension $k'\supset k$, the tensor product $k'\otimes_{k}R$ has nonzero nilpotent element . How can I find such examples? Thanks in advance.","['abstract-algebra', 'algebraic-geometry']"
2774912,4-Torsion on an elliptic curve embedded in $\mathbb{P}^{3}$ as the intersection of two quadrics,"I'm having trouble with exercise 3.10 from Silverman's Arithmetic of Elliptic Curves . I include part (a) for context and part (d) because that's the part I'm stuck on. All fields in this section are algebraically closed. Let $E/K$ be an elliptic curve with Weierstrass coordinate functions $x$ and $y$. (a) Show that the map 
  $$
\phi: E \to \mathbb{P}^{3} 
$$
  defined by
  $$
\phi = [1 : x : y : x^{2}]
$$
  maps $E$ isomorphically onto the image of two quadrics in $\mathbb{P}^{3}$. (d) Let $P \in E$. Prove that $[4]P = \mathcal{O}$ if and only if there exists a hyperplane $H \subset \mathbb{P}^{3}$ such that $\phi(E) \cap H = \{ P \}$. If char($K$) $\neq 2$, prove that there are exactly $16$ such hyperplanes, and hence that $\#E[4] = 16$. I assume char$K$ $\neq 2, 3$ for notational convenience. Thus $E/K$ is isomorphic to a plane curve given by equation 
$$
y^{2} = x^{3} + ax + b
$$
where $4a^{3} - 27b^{2} \neq 0$. The quadrics described in part (a) should then be given by
$$
Q_{1}: z_{1} = z_{3}z_{0}
$$
$$
Q_{2}: z_{2}^{2} = z_{3}z_{1} + az_{1}z_{0} + bz_{0}^{2}
$$
where the $z_{i}$ are homogeneous coordinates on $\mathbb{P}^{3}$.
The first part of (d) follows immediately from part (c). I'm having trouble with the hyperplanes, here is my latest attempt:
We first note that there are $4$ immediate $4$-torsion points of $E$ given by $\mathcal{O}$ and the $3$ points of order $2$ corresponding to the roots of the equation $x^{3} + ax + b$. This gives us $4$ hyperplanes with the required intersection property. It can be checked that $[0 : 0 : 0 : 1] = \phi(\mathcal{O})$  and that this is the only point on both quadrics where $z_{0} = 0$, so we can assume $z_{0} \neq 0$. We can also assume $z_{2} \neq 0$ since these points are the images of the points of order $2$. Now consider a general hyperplane:
$$
H: c_{0}z_{0} + c_{1}z_{1} + c_{2}z_{2} + c_{3}z_{3}.
$$
If $c_{3} = 0$ then $H$ passes through $\phi(\mathcal{O})$ and so if it intersects $\phi(E)$ once could only be one of the hyperplanes we have already counted, so we can assume $c_{3} \neq 0$ and since the hyperlanes are parameterised by $\mathbb{P}^{3}$, we can assume $c_{3} = 1$ . Thus setting $u = \frac{z_{1}}{z_{0}}$, $v = \frac{z_{2}}{z_{0}}$, $w = \frac{z_{3}}{z_{0}}$, we reduce to
$$
Q_{1}: u^{2} = w
$$
$$
Q_{2}: v^{2} = wu + au + b
$$
$$
H: c_{0} + c_{1}u + c_{2}v + w = 0.
$$
The first equation clearly makes $w$ redundant so we can reduce to two equations:
$$
Q: v^{2} = u^{3} + au + b
$$
$$
H: c_{0} + c_{1}u + c_{2}v + u^{2} = 0
$$
so finally I've reduced to the intersection of an elliptic curve and a quadratic. When we do the necessary substitutions we get a quartic in $u$, which we would need to have a repeated root. I've attempted various ways using the coefficients to obtain equations in the $c_{i}$  ( formally differentiating multiple times to obtain the root and then comparing coefficients with binomial expansion etc) but each has left me with a confusing mess, so I can't help thinking I've gone wrong somewhere above. Also I never used the $z_{2} \neq 2$ condition. Any help would be greatly appreciated! Edit: The purpose of this question is to prove in the special case $m = 4$ that deg$[m] = m^{2}$, so ideally I'd like answers that don't quote this result.","['arithmetic-geometry', 'elliptic-curves', 'algebraic-geometry']"
2774937,Is eight is the most common number of divisors of integers?,"If the prime factorisation of a number is $n = p_1^{a_1}p_2^{a_2}\ldots p_k^{a_k}$ then the number of divisors of $n$ is $\tau_n = (a_1+1)(a_2+1)\ldots(a_k+1)$. Thus number of divisors of a number is 2 if an only if the number is a prime. In other words, the number of integers $\le x$ that have exactly two divisors is equal to $\pi(x)$ the number of primes $\le x$. Let $N_k(x)$ be the number of integers $\le x$ which have $k$ divisors. Thus for $x = 2000000$, $N_8(x) = 448777$ and $N_4(x) = 407091$. Is there an asymptotic formula for the number integers $\le x$ which have exactly $k$ divisors? I observed that 8 is the most common number of divisors. More specifically, we have: Conjecture : $N_8(x) > N_k(x)$ for all $x > 248770$ and $k \ne 8$. or more elegantly: Eight is the most common number of divisors of integers. I have verified this conjecture for $x = 2*10^{10}$. Question: Can this conjecture be proved/disproved or is there any heuristic arguments against or in support of it?","['analytic-number-theory', 'asymptotics', 'number-theory', 'prime-numbers', 'elementary-number-theory']"
2774960,Is the map $A \to \bigwedge^{k}A $ an immersion?,"$\newcommand{\Cof}{\operatorname{cof}}
\newcommand{\id}{\operatorname{Id}}$
Let $V$ be a real oriented $d$-dimensional vector space ($d>2$). Let $2 \le k \le d-1$ be fixed. Consider the following map:
$$\psi:\text{GL}^+(V) \to \text{GL}(\bigwedge^{k}V,\bigwedge^{k}V) \, \,, \, \, \psi(A)=\bigwedge^{k}A,$$ where $\bigwedge^{k} V$ is the $k$-th exterior power of $V$. Is $\psi$ an immersion? Note that $\psi$ is injective and smooth. My motivation is connected to this question . Edit: Here are some observations: First, using the multiplicative nature of $\psi$, we can reduce everything to the identity. (Since $d\psi_A(B)=\psi(A) \circ d\psi_{\id}(A^{-1}B)$). Let's consider for a moment the case $k=2$: In that case
$$ \big(d\psi_{\id}(B)\big)(e_i \wedge e_j)=e_i \wedge Be_j+Be_i \wedge e_j. \tag{1}$$ So, we have reduced the question into showing that if equation $(1)$ holds for every two vectors $e_i,e_j$, then $B=0$. (Of course, it suffices to take $e_i,e_j$ to be part of a given basis for $V$). I have also proved that $\text{trace} B=0$ (In general $d\psi_A(B)=0 \Rightarrow \langle \Cof A,B \rangle=0$ and $\Cof A=\id$). Since the answer is positive for $k=d-1$ (see explanation below), we see that the first non-obvious case is $k=2,d=4$. A proof the answer is positive for $k=d-1$: In that case $\bigwedge^{d-1}A$ is essentially the cofactor matrix of $A$, $\Cof A$. Then we have the following formula for its derivative : $$d(\Cof)_A(B)   = (A^{T})^{-1}\big(\langle \Cof A , B\rangle \cdot \id - B^T \circ \Cof A  \big),$$ so $d(\Cof)_A(B)=0$ implies $\langle \Cof A , B\rangle \cdot \id = B^T \circ \Cof A$. Taking traces we get
$$d \langle \Cof A , B\rangle = \langle \Cof A , B\rangle \Rightarrow \langle \Cof A , B\rangle =0,$$ which in turn implies
$$ B^T \circ \Cof A  =0 \Rightarrow  B=0.$$","['differential-geometry', 'smooth-manifolds', 'linear-algebra', 'exterior-algebra']"
2774985,Evaluate the limit $\lim_{t\to0+}{(\frac{1}{t}+\frac{1}{\sqrt{t}})(\sqrt{t+1}-1)}$,Problem: $\lim_{t\to0+}{(\frac{1}{t}+\frac{1}{\sqrt{t}})(\sqrt{t+1}-1)}$ I have difficulties to solve this problem. Here are my steps: $\lim_{t\to0+}{(\frac{1}{t}+\frac{1}{\sqrt{t}})(\sqrt{t+1}-1)}$ =$\lim_{t\to0+}{\frac{(\sqrt{t}+t)(\sqrt{t+1}-1)}{t\sqrt{t}}}$ (To satisfy the condition of l'hôpital Rules) This is in a $\frac{0}{0}$ form. $\frac{d}{dy}(\sqrt{t}+t)(\sqrt{t+1}-1)$ =$(\frac{1}{2\sqrt{t}}+1)(\sqrt{t+1}-1)+(\sqrt{t}+t)(\frac{1}{2\sqrt{t+1}})$ $\frac{d}{dy}t\sqrt{t}=\frac{t}{2\sqrt{t}}+\sqrt{t}=\frac{3}{2}\sqrt{t}$ =$\lim_{t\to0+}{\frac{\frac{d}{dy}(\sqrt{t}+t)(\sqrt{t+1}-1)}{\frac{d}{dy}t\sqrt{t}}}=\frac{0}{0}=0$ While the solution gives $\frac{1}{2}$ rather than 0. I've did the computation again and again but still feel hard to figure out where I made mistakes. Anyone there to help me? Thanks in advance!!,"['calculus', 'limits']"
2775046,Grouping Hexagonal Coordinates into Larger Hexagons,"When using a data structure to partition space, a convenient approach is to form a sort of self similar hierarchical grid (I'm not sure of the proper terminology here). For example, a quadtree recursively subdivides each node into four children of equal size. While trying to accomplish something similar with hexagons, I've hit a bit of a dead end. I happen to be using an axial coordinate system, with the positive portion of the y-axis arranged to be symmetric about the x-axis. I'm using an analogous coordinate system to label the groups, but rotated slightly to match their layout. Everything works as expected with the coordinate system itself; the issue arises when I try to translate between child (hexagon) and parent (group) coordinates. Specifically, I'm having trouble with the following points. Given the coordinate for any arbitrary hexagon, I'd like to determine the coordinate of its group. Given the coordinate for any arbitrary group, I'd like to determine the coordinate of the hexagon at its origin (ie its equivalent of the (0, 0) position in the (0, 0) group). Some examples to hopefully clarify things (same axes and grouping as images): Hex(0, 2) -> Group(0, 0) Hex(0, 3) -> Group(0, 1) Hex(5, 2) -> Group(1, 0) Hex(4, 6) -> Group(1, 1) Group(1, 0) -> Hex(3, 2) Group(0, -1) -> Hex(2, -3) So far the math doesn't seem like it will be very simple, but I'm hoping I've missed something.","['tiling', 'geometry']"
2775061,When does $\frac{a+b}{2}$ and $\sqrt{ab}$ have inversed tens digits and ones digits?,"Let $a$ and $b$ be natural numbers, and $$A = \frac{a+b}{2}$$
$$B = \sqrt{ab}$$ It's given that $A$ and $B$ are two-digit numbers such that the tens digit of $A$ is the same as the ones digit of $B$, and the tens digit of $B$ is the same as the ones digit of $A$. So $A = 10x + y\;\,$and$\;B = 10y + x$. Also given is $A\ne B$. What is $a$ and $b$? My teacher gave us the answer without explaining it as: $a = 98$ and $b = 32$, which makes $A = 65$ and $B=56$. My question is: How do you prove this? I know $98 = 2\cdot 7^2$ and $32 = 2^5$, but I don't understand how to find this specific answer.","['algebra-precalculus', 'elementary-number-theory']"
2775081,Is there an analytically continued function of $z^p$ at zero?,For a rational number $p > 1$. We know that the function $z^p$ is holomorphic on $\mathbb{C} \setminus \mathbb{R}^-$ (excluding $z = 0$). Is there an analytic continuation of the function $z^p$ at zero ? Thank you.,"['analyticity', 'complex-analysis', 'holomorphic-functions', 'analytic-continuation']"
2775120,How to prove that $(1 + \frac{1}{n})^{\sqrt{n(n+1)}} < e$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . The community reviewed whether to reopen this question 8 months ago and left it closed: Original close reason(s) were not resolved Improve this question I've been trying to solve the following problem: Show that $\ln{(k+1)} - \ln{k} = \ln{(1 + \frac{1}{k})} \leq \frac{1}{\sqrt{k(k+1)}}$ EDIT: the title was inaccurate, my bad. 
So what we have to prove is that the upper limit of $(1 + \frac{1}{n})^{\sqrt{n(n+1)}}$ equals $e$.","['inequality', 'exponential-function', 'limits']"
2775129,"Given that $3a^2 < 8b$, prove that the equation $x^4 + ax^3 + bx^2 + 2018x = 207$ has exactly two real roots.","$${x^4 + ax^3 + bx^2 + 2018x = 207} $$
$$3a^2 < 8b$$ While trying to prove that this equation has exactly two solutions, I defined the function $$f(x) = {x^4 + ax^3 + bx^2 + 2018x - 207}$$ and then evaluated it at $f(0)$ to show that it is less than zero. I was going to use the Intermediate Value Theorem to prove that at some large positive and negative value result in values greater than $0.$ But then I don't know how to prove that the function doesn't cross more than twice.","['algebra-precalculus', 'polynomials', 'calculus']"
2775143,Linearity of indefinite integrals,"I am trying to make sense of 'linearity' of indefinite integrals. Let us restrict to the 1-dimensional case. My point is that $\int 0\, dx = C \in \mathbb{R}$, so I cannot really say that $\int$ is a linear operator. Indeed, linearity of $f \colon V \rightarrow W$ ($V,W$ vector spaces) implies $f(0) = 0$. In order to define $\int \colon V \rightarrow W$ in a good way, I should introduce an equivalence relation $\sim$ on $W$ saying that two elements are in the same equivalence class if they coincide up to a constant. So $\int$ becomes linear as operator $\int \colon V \rightarrow W_{/\sim}$. Assume a primitive of $f$ is $F$. Then
$$\int f(x)\,dx = [F(x)] \in W_{/\sim}$$
or, as usual, $F(x)+C, C \in \mathbb{R}$. So I would say that the result of an indefinite integral is actually a coset in some quotient vector space. This even solves the problem that $\int \colon V \rightarrow W $ is not a well defined function. My question is: is this a good way to think, or is there a better one? I have never seen such a thing, neither in a course of Analysis, nor in the books I have read. I am wondering why. It seems a very natural thing to do when introducing indefinite integrals.","['real-analysis', 'linear-algebra', 'linear-transformations']"
2775180,Dini Derivatives,"Define $f:\mathbb R\rightarrow \mathbb R $ by $$ f(x)= \begin{cases} 0&,x\in \mathbb R \setminus \mathbb Q\\1&,x\in \mathbb Q \end{cases} $$ Let $x\in \mathbb R \setminus \mathbb Q$. I was asked to calculate Dini derivatives of $f$ at $x$, i.e. $(D^+f)(x), (D_+f)(x), (D^-f)(x),$ and $(D_-f)(x)$.
 I obtained $(D_+f)(x)=0$ (which I'm not entirely sure is right) so far, and I can't seem to proceed further. I can kind of guess that $(D^+f)(x)=∞ $ but I don't know how to show my working to obtain this.  I think if I know how to compute the first two derivatives, the rest would be very much similar.  Can someone please help?  Thank you.","['derivatives', 'limsup-and-liminf']"
2775198,Can you completely permute the elements of a matrix by applying permutation matrices?,"Suppose I have a $n\times n$ matrix $A$. Can I, by using only pre- and post-multiplication by permutation matrices, permute all the elements of $A$? That is, there should be no binding conditions, like $a_{11}$ will always be to the left of $a_{n1}$, etc. This seems to be intuitively obvious. What I think is that I can write the matrix as an $n^2$-dimensional vector, then I can permute all entries by multiplying by a suitable permutation matrix, and then re-form a matrix with the permuted vector.","['matrices', 'permutations', 'permutation-matrices', 'linear-algebra']"
2775205,Integral $\int^{\frac{\pi}{6}}_{0}\ln^2(2\sin \theta)d\theta$,"Greetings I am trying to find a close form for: $\int^{\frac{\pi}{6}}_{0}\ln^2(2\sin \theta)d\theta$ My first thought was to let $$I(k)=\int_0^{\frac{\pi}{6}} (2sin(\theta))^k d\theta$$ So I would get the answer to the original integral if I evaluate this in terms of k, derivate two times the result and plug $k=0$.  I am struggling with the last one.  $$I(k)=2^k\int_0^{\frac{\pi}{6}} sin^k (\theta) d\theta=2^k \,\Im\int_0^{\frac{\pi}{6}} e^{ik\theta} d\theta= 2^k \,\Im\int_0^{\frac{\pi}{6}}\frac{d}{d\theta}\left(\frac{e^{ik\theta}}{ik}\right)d\theta=\Im2^k\left(\frac{\cos k\frac{\pi}{6}+i\sin\frac{k\pi}{6}-1}{ik} \right)=2^k\frac{{1-\cos\frac{k\pi}{6}}}{k}$$ Is this correct? If not I would appreciate some help with the integral.","['integration', 'closed-form']"
2775224,Area of a parametric surface,"Given the parametric surface $\Phi(\rho,\theta)=(\rho\cos\theta,\rho\sin\theta,\theta)$, $\rho\in]0,1]$, $\theta\in[0,4\pi]$ find its area. This is a kind of exercise i might find in my multivariable calculus exam. I'm struggling to find a way to solve it because there's no resolution method mentioned in the study material my prof gave me for this kind of exercise . I guess i need to do some sort of integration to solve this, but i don't know which one to look up for. I think an example could help me understand.","['multivariable-calculus', 'integration', 'area']"
2775268,Basic spectral geometry question for surfaces in $\mathbb{R}^3$,"Assume that $S \subset \mathbb{R}^3$ is a smooth, compact, properly embedded surface with boundary $\partial S = \gamma_1 \cup \gamma_2$, where $\gamma_i$ are smooth closed curves. Moreover assume that $S$ is diffeomorphic to an annulus. If I know the value of the first Dirichlet eigenvalue of $S$, what kind of geometric information do I get? Can I have an estimate on the area, for example? Any help would be very much appreciated!","['spectral-theory', 'differential-geometry', 'surfaces']"
2775293,Integro-Differential Equations,I was attempting to solve the following integro-differential equation using convolutions. My answer also had a convolution which did not seem right and was wondering if someone would check my process. Problem with initial work My final solution,"['integro-differential-equations', 'ordinary-differential-equations', 'convolution']"
2775319,Second derivative of a third degree polynomial function,"Let $f(x) = ax^3 + bx^2 + cx +d $ be a third degree polynomial function. $$f'' = 6ax + 2b = 0 \Longrightarrow x = \frac{-b}{3a} $$
This is equal to $\frac{1}{3}$ of the sum of the roots of $f(x)$. So my question is: can we say that the root of the second derivative is equal to $\frac{1}{3}$ of the sum (of roots) for all third degree polynomial functions? If not, why?","['algebra-precalculus', 'polynomials', 'calculus', 'derivatives']"
2775338,"For $d\mid m$, $\mathbb{Z}/d\mathbb{Z}$ is not an injective $\mathbb{Z}/m\mathbb{Z}$-module when some prime divides $d$ and $\frac{m}{d}$","Suppose $d\mid m$. Show that $\mathbb{Z}/d\mathbb{Z}$ is not an injective $\mathbb{Z}/m\mathbb{Z}$-module when $\exists p$ prime with $p\mid d$ and $p\mid \frac{m}{d}$. $\textbf{My attempt:}$ We have that $(a+m\mathbb{Z})(b+d\mathbb{Z}) \mapsto ab + d\mathbb{Z}$ defines $\mathbb{Z}/d\mathbb{Z}$ as a $\mathbb{Z}/m\mathbb{Z}$-module as usual. Using Baer's criterion I want to show that there exists an ideal of $\mathbb{Z}/m\mathbb{Z},$ say $J$, and an $R$-module map $f:J \to \mathbb{Z}/d\mathbb{Z}$ which $\textbf{cannot}$ be extended to a map $f_*:\mathbb{Z}/m\mathbb{Z} \to \mathbb{Z}/d\mathbb{Z}$. Take the ideal $\langle \frac{m}{d} \rangle$ in $\mathbb{Z}/m\mathbb{Z}$ and map $$f:\left\langle \frac{m}{d} \right\rangle \xrightarrow{\simeq} \mathbb{Z}/d\mathbb{Z}$$
$$ a\frac{m}{d} + m\mathbb{Z} \mapsto a + d\mathbb{Z}$$ Then this is a module isomorphism. If we could extend this to a map $f_*$ then as $f$ is surjective we'd get the following short exact sequence:
$$ 0 \rightarrow ker(f_*) \xrightarrow{i} \mathbb{Z}/m\mathbb{Z} \xrightarrow{f_*} \mathbb{Z}/d\mathbb{Z} \rightarrow 0$$ This sequence splits because $f$ was an isomorphism (so $f_*\circ f^{-1} = f\circ f^{-1} = id$ witnesses the splitting) [$\textbf{is this logic valid?}$]. So $\mathbb{Z}/m\mathbb{Z}=ker(f_*)\oplus\mathbb{Z}/d\mathbb{Z}$ and $ker(f_*)$ as a submodule of $\mathbb{Z}/m\mathbb{Z}$ is of the form $\mathbb{Z}/e\mathbb{Z}$ for some $e.$ [$\textbf{Is this true?}$] So that $\mathbb{Z}/m\mathbb{Z}=\mathbb{Z}/e\mathbb{Z}\oplus\mathbb{Z}/d\mathbb{Z}$. I want to show that this is the desired contradiction. Now I want to use the condition $p\mid d$ and $p\mid\frac{m}{d}$ to show that $\mathbb{Z}/m\mathbb{Z} \ne \mathbb{Z}/e\mathbb{Z}\oplus\mathbb{Z}/d\mathbb{Z}$  but I'm not sure how. Tried using orders of elements but got a little muddled... If I can do this (and I think it can be done), is this approach all ok, or have I made a mistake?","['injective-module', 'modules', 'abstract-algebra', 'homological-algebra', 'ring-theory']"
2775343,Determine the arc length of the following parametric curve,"Determine the arc length of the parametric curve given by the following parametric equation:
   $φ(t)= (\sqrt{t}, t+1, t)$ $t\in[10,20]$ In order to do this I simply tried it to solve it by the formula of arc lenght. Given the formula, $
L=\int_{a}^{b} \sqrt{\left(\frac{dx}{dt}\right)^2 +\left(\frac{dy}{dt}\right)^2 +\left(\frac{dz}{dt}\right)^2 } \;dt$ I get that $L=\int_{10}^{20} \sqrt {2+\frac{1}{4t}}; dt=\int_{10}^{20}\sqrt {\frac{8t+1}{4t}} \; dt$ Then, I tried to get prettier the integral function by multiplying in the argument of the square root by $4t/4t$ (I eliminated square root in the denominator) getting this  not very satisfying result: $L=\int_{10}^{20}\sqrt {\frac{(4t)^2+t}{2t}} \; dt$ I really don't know how to solve that integral, so I wonder if someone comes out with some idea about how to do it. In the other hand, I tought that maybe there is a nicer parametrization of that particular parametrization, e.g. a reparametrization, where we could solve the integral more easily, but in that case I'm not sure about how to find it. Any ideas?","['real-analysis', 'arc-length', 'integration', 'parametrization', 'analysis']"
2775363,Solution to Vector Lambert W function type Equation,"I was wondering if anyone has any ideas for a closed-form solution to the equation $$Ax + \exp(x) +b =0$$ where $x,b \in \mathbb{R}^n$, $A$ is a symmetric positive definite matrix and $\exp$ denotes elementwise exponentiation (i.e., $\exp(x) =(\exp(x_1),\exp(x_2), \dots, \exp(x_n) $). The case where $n=1$, $$ ax+\exp(x)+b =0$$ has the solution $$ x= -W_{n}\left(e^{\frac{-b}{a}}\right)+\dfrac{b}{a}, $$ where $a\neq 0$, $n \in \mathbb{Z}$, and $W_{n}$ is the $n$th branch of the Lambert W function. I'm looking for unique solutions of the vector version.","['lambert-w', 'functional-analysis', 'complex-analysis', 'special-functions', 'linear-algebra']"
2775400,Does $2^A\to 2^B$ produce a function $B\to A$? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Let $A, B$ be two sets such that there is a function $2^A\to2^B$ preserving unions and $\emptyset\mapsto\emptyset$ and $A\mapsto B$ and no singleton maps to $\emptyset$. Does there exist a ""canonical"" function $B\to A$? If not, what are the conditions that guarantee the existence of a such function? I have no idea to attempt to this problem. First I tried to work with some explicit examples, but that does not help me to understand what is actually happening here. Can anybody help me to solve this problem? I do not need a complete solution, but enough explanation to understand the problem statement and some hint (if necessary). Thank you in advance.","['elementary-set-theory', 'functions']"
2775421,Number of solutions of the function,"Let $'f'$ be an even periodic function with period 4 such that $f(x) = 2^x -1$, $0\le x \le2$. The number of solutions of the equation $f(x) = 1$ in $[-10,20]$ are? Since the given function is even, $f(x) = f(-x)$ since the given function is periodic, $f(x+4) = f(x)$ So, $f(x+4) = f(-x)$ Well, according to the function defined for $x \in [0,2]$ we get one solution for $f(x) = 1$ at $x=1$ I don't know how do I proceed from here. Any help would be appreciated.","['calculus', 'functions']"
2775459,Validity of constant functions,"Is a constant function, like $y = 3$, defined for all inputs? A function is defined at some arbitrary point if it has a value at that point, yes? And constant functions have values for all inputs, namely the constant. So they should be defined for all inputs, right? I'm learning about Maclaurin's series, and it states that the function and its nth derivatives must be defined at $x = 0$. Would it work with a constant function? Thank you.","['algebra-precalculus', 'functions', 'definition']"
2775480,Solution of the second order differential equation,"Consider the differential equation $$\frac{d^2y}{dx^2}-2\tan x \frac{dy}{dx}-y=0$$
defined on $\big(-\frac{\pi}{2}, \frac{\pi}{2}\big)$. Which among the following are true? there is exactly one solution $y=y(x)$ with $y(0) = y'(0) = 0$ and $y\big(\frac{\pi}{3}\big) = 2\big(1+\frac{\pi}{3}\big)$ there is exactly one solution $y=y(x)$ with $y(0) =1, \  y'(0) = -1$ and $y\big(-\frac{\pi}{3}\big) = 2\big(1+\frac{\pi}{3}\big)$ any solution $y=y(x)$ satisfies $y''(0) = y(0)$. if $y_1$ and $y_2$ are any two solutions then $(ax+b)y_1 = (cx+d)y_2$ for some $a, b, c, d \in \mathbb{R}$. How to solve the above problem?",['ordinary-differential-equations']
2775534,OLS: Omitted variable bias when $\mathbb{E}$(omitted variable) $\neq 0$,"The proof for omitted variable bias is pretty simple, via here : Assume the true model is $$Y = X\beta + Z\delta + U$$ and we estimate naively $$Y = X\beta + W$$ The OLS estimate of the incorrectly specified model is then $$\beta = [X^TX]^{-1}X^TY = [X^TX]^{-1}X^T[X\beta + Z\delta + U] = \beta + [X^TX]^{-1}X^T[Z\delta + U]$$ And taking the expectation conditional on $X$ (assuming $U$ is mean zero and independent of $X$): $$\mathbb{E}[\beta\vert X] = \beta + [X^TX]^{-1}\mathbb{E}[X^TZ\vert X]\delta$$ The standard proof then shows that our estimate of $\beta$ will be biased if $X$ and $Z$ are correlated. But what if the mean of $X$ and $Z$ are both nonzero? For example, assume $Z$ is independent of $X$ and that $\mathbb{E}X\neq 0 \neq \mathbb{E}Z$. Then we have 
$$\mathbb{E}[\beta\vert X] = \beta + [X^TX]^{-1}\mathbb{E}[X^TZ\vert X]\delta = \beta + [X^TX]^{-1}X^T\mathbb{E}[Z]\delta \neq \beta $$ Doesn't that mean, then, that our estimate of $\beta$ can be biased even if the omitted variable is independent of the other regressors if $\mathbb{E}Z>0$","['least-squares', 'probability-theory', 'statistics']"
2775536,Proof that $g(x) = xf(x)$ is differentiable at 0 given that f is continuous at 0,"Let $f : \mathbb{R} \rightarrow \mathbb{R}$ be continous at $0$ and let $g : \mathbb{R} \rightarrow \mathbb{R}$ be $g(x)=xf(x)$ for all $x\in \mathbb{R}$. How do I proof $g$ is differentiable at $0$? I know that the product of two differentiable functions is differentiable, and that $x$ is differentiable. So I guess I need to proof that $f(x)$ is differentiable at $0$? Continuity does however not imply differentiability, so I wouldn't know how.","['derivatives', 'real-analysis', 'continuity']"
2775582,Infinite dimensional Hilbert space is isomorphic to $L^{2}$,"In ""The Free Markoff Field"" by E. Nelson, it is claimed that if $H$ is an infinite-dimensional real Hilbert space, then there is a non-atomic measure space $(K,m)$ such that $L^{2}(K,m)$ is isomorphic to $H$.  How does this work?  I know that if $\{u_{\alpha}\}_{\alpha \in \mathcal{A}}$ is a complete orthonormal set, then the Plancherel formula $\langle x, y \rangle = \sum_{\alpha \in \mathcal{A}} \langle x, u_{\alpha}\rangle \langle u_{\alpha},y\rangle$ exhibits a unitary isomorphism between $H$ and $L^{2}(\mathcal{A},c)$, where $c$ is the counting measure.  However, $(\mathcal{A},c)$ is certainly atomic.  Apparently this is untrue if $H$ is finite-dimensional, but it's not obvious to me how to get something better than $(\mathcal{A},c)$ when $\mathcal{A}$ is infinite.","['functional-analysis', 'measure-theory', 'hilbert-spaces']"
2775594,Calculating coupon collector problems without replacement. What is the probability of discovering all types for a given number of samples?,"Suppose I buy a big box of assorted sweets. There are 10 distinct types of sweets, all evenly distributed in their assortment. I am separating them out into party bags for a party. I make up 100 party bags, each containing four distinct sweets. As such there are 400 sweets in total, with 40 of each variety distributed amongst the bags. The question is, if I look inside $n$ bags (without replacement), what is the probability that I will have seen every variety of sweet? I appreciate that if I knew the exact tally of sweet varieties I wanted to find I could use a multivariate hypergeometric distribution. This is a version of the coupon collecting problem but without replacement. It may be that this problem isn't easily analytically solvable? Am I doomed to be unable to do this for such a large dimension of variables? Any advice or input would be greatly appreciated. Perhaps calculating a Chao index is required?","['combinations', 'probability-theory', 'probability-distributions', 'probability', 'combinatorics']"
2775597,Find the altitude of a tetrahedron whose faces are congruent triangles,"Any set of four identical triangles can be arranged to form a four-surface solid. If these four triangles are not equilateral, e.g. 3,4,5, how do I find the altitude of from the one used for the bottom to the apex formed by the other three.","['euclidean-geometry', 'trigonometry', 'solid-geometry']"
2775673,Random matrices: stochastic dominance of trace and determinant,"For this question, if $X$ and $Y$ are 2 real random scalars, then $X$ has first-order stochastic dominance over $Y$ if for any $x$, $\Pr[X\leq x]\leq\Pr[Y\leq x]$. Let's write $X\succeq Y$. Suppose $A$ and $B$ are $n\times n$ random positive semidefinite real matrices and I'm interested in sufficient conditions that allow me to say $\operatorname{tr}(A)\succeq\operatorname{tr}(B)$ or $\det(A)\succeq\det(B)$. In particular, can I say something if I know $c'Ac\succeq c'Bc$ for all $n\times 1$ nonstochastic $c$?","['reference-request', 'statistics', 'random-matrices', 'linear-algebra']"
2775676,"Determinant of a matrix of ones, whose anti diagonal elements are zero","I'm trying to prove a formula I have constructed for the determinant of a general $n\times n $ real matrix $A$, given here in the case $n=5$:
$$ A = \begin{bmatrix}
1 & 1 & 1 & 1 & 0 \\
1 & 1 & 1 & 0 & 1 \\
1 & 1 & 0 & 1 & 1 \\
1 & 0 & 1 & 1 & 1 \\
0 & 1 & 1 & 1 & 1
\end{bmatrix}.
$$
That is, the matrix containing all 1's apart from the anti-diagonal which consists of zeros. Using a simple matlab code I've computed the determinants for the first few values of $n$, and have come to the formula
$$ \det A =
\begin{cases}
-(n-1) \hspace{1em}\mbox{ if }\,\,\, n \equiv -1,0\mod 4, \\
n-1 \hspace{2.2em}\mbox{ otherwise,}
\end{cases}
$$
but I'm unsure where to start to prove this.","['matrices', 'linear-algebra', 'determinant']"
2775745,"If $\frac{\sin^2 A + \sin^2 B + \sin^2 C}{\cos^2 A + \cos^2 B + \cos^2 C}=2$ , then $\triangle ABC$ is a right triangle","Show that the triangle whose angles satisfy the equality
  $$\frac{\sin^2 A + \sin^2 B + \sin^2 C}{\cos^2 A + \cos^2 B + \cos^2 C}=2$$
  is right-angled. I've tried many times, but was unsuccessful.","['trigonometry', 'proof-explanation']"
2775748,About Groups and Isomorphic Quotients,"So I was studying some group theory and I came up with this question: Say you have a group $G$ and two isomorphic normal subgroups $A,B$ , is it true then that $$\dfrac{G}{A}\cong\dfrac{G}{B}$$ Turn out, it is not, take $G=\mathbb{Z}_4\times\mathbb{Z}_2$ and $A=\mathbb{Z}_2\times1$ and $B=1\times\mathbb{Z}_2$ , so $G/A\cong\mathbb{Z}_2\times\mathbb{Z}_2$ and $G/B\cong\mathbb{Z}_4$ which are not isomorphic to each other. Now, my question is, is there any desirable property that relates isomorphic subgroups and their respective quotients? Perhaps if the groups are not finite, or different than direct product of groups (?). Thanks a lot!","['abstract-algebra', 'group-theory', 'group-isomorphism']"
2775765,Proving completeness of space of converging sequences,"Assume $c_{0, \lambda}$ is a metric space of converging to zero sequences, where $c_{0, \lambda} =\{ x = (x_i):\lim_{i \rightarrow \infty} i^{\lambda} x_i = 0 \}$, here $\lambda > 0$ imposes a certain restriction on the convergence speed for the sequences; with the following metric $d(x,y) = \sup_{i}i^{\lambda}|x_i - y_i|$, I'm trying to prove that such space is complete. My approach: Assume that $(x_n)$ is a Cauchy sequence from $c_{0, \lambda}$. It is clear that $(x_n)$ is also from $c_{0}$ (with $\lambda = 0$, which is known to be complete). If we construct a sequence $z_n = (z_{n,i}) = ( i^{\lambda} x_{n, i} )$, by definition it should hold that $z_n \in c_0$ for some fixed $\lambda > 0$, and it's also a Cauchy sequence in $c_0$. Hence, there exists a limit $z_0 \in c_0$, which implies that $\lim_{i \rightarrow \infty} z_{0, i}= 0$. Therefore, it should hold that $\lim_{i \rightarrow \infty} z_{0,i}/{i^{\lambda}} = 0$ for the same fixed $\lambda > 0$, suggesting that $x_0 := (x_i) = (z_{0,i}/i^{\lambda}) \in c_{0, \lambda}$. Since $d(x_n, x_0) = \sup_{i}i^{\lambda}|x_{n,i} - x_{0,i}| = sup_i | i^\lambda x_{n,i} - i^{\lambda} x_{0, i}| = sup_{i} | z_{n, i} - z_{0, i} | \rightarrow 0$, $i \rightarrow \infty$, it seems that $x_n \rightarrow x_0, n \rightarrow \infty$, suggesting that $c_{0, \lambda}$ is complete. Here the last result holds due to convergence in $c_0$ under supremum metric. My question: Is such approach suitable for proving completeness? If not, what would be the right way to proceed in this case (and in more general ones, where the restriction $i^{\lambda}$ may have various other expressions (and hence the metric would be constructed accordingly))? The goal I'm trying to achieve here is not only to just prove the completeness for this particular example, but to better understand proving completeness for various spaces, where it is clear that it is a some sort of a restricted version of a larger, well known space the properties of which is known. Would be grateful for any hints or corrections!","['functional-analysis', 'complete-spaces', 'metric-spaces', 'convergence-divergence']"
2775795,Short-time existence of Ricci flow,"Hamilton and DeTurck's short time existence theorem of the Ricci flow states that if $M^n$ is a smooth closed manifold with a $C^{\infty}$ Riemannian metric $g_0$ on $M$, then the Ricci flow on $M$ starting at $g_0$ exists for a short time. Question : Are there any short time existence results for an initial metric $g_0$ with less regularity (e.g. $C^{k,\alpha}$, Lipschitz, etc)?","['ricci-flow', 'differential-geometry', 'partial-differential-equations']"
2775807,How does one compute the reciprocal of $\cos(z)=\sum_{n=0}^{\infty}(-1)^n\frac{z^{2n}}{2n!}$,"I've been going through some past exam papers and came across  a question which asks you to compute the Taylor expansion of $\sec(z)$ given that $$\sec(z)=\frac{1}{\cos(z)},$$ and $$\cos(z)=\sum_{n=0}^{\infty}(-1)^n\frac{z^{2n}}{(2n)!}.$$ The problem is I dont know how to compute the reciprocal, and I have found it difficult to find how to do so online. Could someone point me in the direction of some webpage that goes through such problems( I can't afford a book), or perhaps explain a general method for computing the reciprocal in such cases ?","['complex-analysis', 'taylor-expansion', 'trigonometry', 'power-series']"
2775823,An isometry between linear subspaces that is not very far from orthogonal projection,"Let $\mathcal M$ and $\mathcal N$ be two linear subspaces of $\mathbb{R}^n$ such that $\dim \mathcal M = \dim \mathcal{N}$. Such subspaces are known to be isometric: that is, there exists a bijective linear operator $T:\mathcal M\to\mathcal N$ such that $\|Tx\|=\|x\|$ for all $x\in\mathcal M$. But I want to choose such $T$ so it's not too far from the orthogonal projection onto $\mathcal N$, denoted $P_{\mathcal{N}}$. Is there an isometry $T:\mathcal M\to\mathcal N$ such that $$
\|Tx-P_\mathcal Nx\|\le \|x-P_\mathcal Nx\|\quad \forall x\in\mathcal M \tag{?}
$$ Progress so far If $\mathcal M \perp \mathcal N$, the answer is trivially yes: any isometry works because $P_\mathcal Nx=0$ for all $x\in \mathcal M$. If $\dim \mathcal M = 1 =\dim \mathcal N$, the answer is also yes. Indeed, we can arrange for $\mathcal N$ to be the horizontal axis in $\mathbb{R}^2$, and for $\mathcal N$ to be the line $\{(t\cos \theta, t\sin\theta) : t\in\mathbb{R}\}$ where $\theta\in [0, \pi/2]$ is fixed. The isometry $(t \cos\theta, t\sin\theta)\mapsto (t, 0)$ satisfies (?) because 
$1-\cos \theta \le \sin\theta $. It suffices to consider the case $\mathcal M\cap \mathcal N = \{0\}$. Otherwise, let $\widetilde{\mathcal M}$ be the orthogonal complement of $\mathcal M\cap \mathcal N$ in $\mathcal M$, and similarly for $\widetilde{\mathcal N}$. Pick an isometry $\widetilde{T} : \widetilde{\mathcal M} \to \widetilde{\mathcal N}$ for which (?) holds, and extend it to $T:\mathcal M\to\mathcal N$ by letting $Tx=x$ on $\mathcal M\cap \mathcal N$. Then $T$ is equivariant with respect to shifts along  $\mathcal M\cap \mathcal N$, and so is $P_{\mathcal N}$, so the property (?) holds for $T$ as well.","['isometry', 'projection', 'linear-algebra']"
2775888,For which primes $p$ is $(p-6)! \equiv 1 \mod p$ defined?,"For which primes $p$ is $(p-6)! \equiv 1 \mod p$ defined? I brute forced it by repeatedly trying lots of primes and ended up with $p=7, p=17$. Does anyone have a better method to do this?","['number-theory', 'prime-numbers', 'elementary-number-theory']"
2775916,Find a left-inverse for the function $f:\Bbb Z \to \Bbb Z$ given by $f(n)=2n+1$.,"Find a left-inverse for the function $f:\Bbb Z \to \Bbb Z$ given by $f(n)=2n+1$. Verify that your answer is correct. Does f have a right-inverse? Explain. Hi all, I need to asses whether this function is left and/or right invertible, and then prove it using proper proof language. I'm trying to follow the way my professor taught me, but I'm not really sure I understand what I'm doing. This is what I have: Theorem. $f$ is left-invertible. Proof. $f$ is left-invertible if there is some function $g:\Bbb Z \to \Bbb Z$ such that $g \circ f = id_{\Bbb Z}$. Consider $g(n)=\frac{n-1}{2}$. Then, $g \circ f(n) =\frac{2n+1-1}{2}=n=id_{\Bbb Z}$. Therefore, $f$ is left-invertible. Does that make any sense so far? Honestly, it doesn't  make any sense to me. The other problem is that using a similar strategy, I find that $f$ is also right-invertible. However, I know that not to be true, because $f(1)=3$ and $f(2)=5$, and thus there is no $n\in\Bbb Z$ such that $f(n)=4$ (aka, the function only spits out odd numbers if we restrict the domain to integer inputs). Therefore, it is not survective. If anyone can help me understand, perhaps from the beginning, how to properly do this problem and write it out, that would be amazing. Cheers","['inverse-function', 'functions', 'proof-verification']"
2775981,Prove $\sin(\alpha -\beta)+\sin(\alpha-\gamma)+\sin(\beta-\gamma)=4\cos\frac{\alpha-\beta}{2}\sin\frac{\alpha-\gamma}{2}\cos\frac{\beta-\gamma}{2}$,"Here is a problem from Gelfand's Trigonometry : Let $\alpha, \beta, \gamma$ be any angle, show that $$\sin(\alpha -\beta)+\sin(\alpha-\gamma)+\sin(\beta-\gamma)=4\cos\left(\frac{\alpha-\beta}{2}\right)\sin\left(\frac{\alpha-\gamma}{2}\right)\cos\left(\frac{\beta-\gamma}{2}\right).$$ I have tried to worked through this problem but cannot complete it. If I let $A= \alpha -\beta$, $B=\beta-\gamma$ and $C= \beta-\gamma$, and $A+B+C=\pi$ (now $A$, $B$ and $C$ are angles of a triangle), then I could prove the equality. But without this condition, I am stuck. Could you show me how to complete this exercise?","['algebra-precalculus', 'trigonometry']"
2776010,$f\left( \bigcap_{n=1}^{\infty}A_{n}\right) = \bigcap_{n=1}^{\infty}f(A_{n})$ for a continuous function on a compact space,"I have the following statement. Let $X$ a compact metric space. Let $f: X \rightarrow X$ a continuous function. If $\lbrace A_{n} \rbrace$ is a decreasing sequence of nonempty closed sets on $X$, then $$f\left( \bigcap_{n=1}^{\infty}A_{n}\right) = \bigcap_{n=1}^{\infty}f(A_{n}) $$ Now, it is easy to see that $$f\left( \bigcap_{n=1}^{\infty}A_{n}\right) \subseteq \bigcap_{n=1}^{\infty}f(A_{n}) $$ Could someone give a suggestion to get the other part?","['functional-analysis', 'general-topology', 'metric-spaces', 'analysis']"
2776020,The canonical projection $\pi: \nu M \rightarrow M$ is a submersion,"Let $M$ be a subvariety of  $\mathbb{R}^n$. Show that the canonical projection $\pi: \nu M \rightarrow M$ is a submersion. Where $\nu M=\{(x,v)\in \mathbb{R}^n \times\mathbb{R}^n;x\in M \text{ and } v\perp T_{x}M\}$. My initial idea was to show that restriction of differentiable is differentiable, but I can not write.
It's been some time since I studied geometry.","['submanifold', 'fiber-bundles', 'differential-geometry']"
2776037,Deriving the posterior distribution given arbitrary measures,"I am given the following facts: $$
\forall A \in \mathcal{B}:  \; \mu(A) = \int_{A} f(x) \alpha(\text{d} x), \quad \text{  and } \quad
\nu_x(A) = \int_{A} g_x(y) \beta(\text{d} y), \; \forall x \in \mathbb{R}
$$
where $\alpha, \beta$ are $\sigma$-finite measures on $(\mathbb{R}, \mathcal{B})$. Let
$$
p_y(x) = \frac{f(x) g_x(y)}{
\int_{\mathbb{R}} f(z)g_z(y)\alpha(\text{d}z)}
$$
and asked to prove that $p_y$ is the density of a version of the conditinal distribution of $X$ given $Y$, with respect to $\alpha$. Previously, I have
proven that $$
\pi(S) = \int_{\mathbb{R}} \nu_x(S_x) \mu(\text{d} x) = \int_S f(x) g_x(y) \text{d}(\alpha \times \beta), \; S \in \mathcal{B}
\times \mathcal{B}
$$
is a probability measure on $(\mathbb{R}^2, \mathcal{B} \times \mathcal{B})$, where $S_x$ is defined as $$
S_x = \left\{y \in \mathbb{R} \ \middle|\ (x, y) \in S\right\}
$$ My attempt :
By the definition of the Radon-Nikodym derivative, we have
$f = \frac{\text{d} \mu}{\text{d} \alpha}, g_x = \frac{\text{d} \nu}{\text{d} \beta}$. If we replace the former in $p_y$, we obtain
$$
p_y(x) = \frac{f(x) g_x(y)}{
\int_{\mathbb{R}} g_z(y)\mu(\text{d}z)}
$$ In order for $p_y(x)$ to be the density of the conditional distribution $\mathbb{P}(X \ |\ Y)$, we need to show that $$
\int_A p_y(x) \alpha(\text{d} x) =
\frac{\int_{A} g_z(y) \mu(\text{d} z)}{\int_{\mathbb{R}} g_z(y) \mu(\text{d} z)}
$$ is a version of the conditional probability $\mathbb{P}(X \in A \ |\ Y)$, which in turn should satisfy the integral criterion: $$
\int_{B} \left[ \frac{\int_{A} g_z(y) \mu(\text{d} z)}{\int_{\mathbb{R}} g_z(y) \mu(\text{d} z)} \right] \beta(\text{d} y) = \mathbb{P}([X \in A] \cap
[Y \in B]) = \pi(A \times B)
$$ However, I'm having trouble simplifying the double integral. My only approach has been to try and substitute $g_x = \frac{\text{d} \nu_x}{\text{d} \beta}$ which doesn't give me any useful form to work with, and I'm stuck at this point. Any hints? Edit : I was also able to show that, since $$
\int_{B} \int_{\mathbb{R}} f(z) g_z(y) \alpha(\text{d} z) \beta(\text{d} y)
= \pi(\mathbb{R} \times B)
$$ we can write $$
\int_{\mathbb{R}} f(z) g_z(y) \alpha(\text{d} z) = \frac{\text{d} \pi(\mathbb{R} \times \cdot)}{\text{d} \beta}
$$ but still can't figure out if I can use that somehow.","['real-analysis', 'probability-theory', 'radon-nikodym', 'probability', 'measure-theory']"
2776038,Use the well-ordering principle to prove that every integer $n\ge2$ has a prime factor.,"EDIT: I am updating this to illustrate my proof thus far. I would appreciate any critique. Question details: ""Use the well ordering principle to prove that every integer $n\ge2$ has a prime factor. One way to prove this for a given integer $n\ge2$ is to apply the well-ordering principle to the set $X=\{d\in{\Bbb Z}:d\ge2 \land d\ |\ n\}$, the set of all factors $d$ of $n$ such that $d\ge2$. (a) Prove that $X$ is not empty. (b) Prove that if $p$ is the minimal element of $X$, then $p$ must be a prime number. (c) Finish the proof of the theorem."" (a)  Trivial. By definition of $X$, $n\in X$ if $n\ge2$. Thus, $X$ is nonempty given any integer $n\ge2$. (b) Suppose $p$ is the minimal element of $X$. Then, it is a divisor of $n$, and it is also $\ge2$. Consider some integer $q\ge2$ that is a divisor of $p$. Then, $q\in X$ by definition of $X$, since any divisor of $p$ is also a divisor of $n$  (and $q\ge2$).  Since $p$ is the minimal element of $X$, then any other element of $X$ $\le p$. Therefore, $q\le p$. Furthermore, $q$ is a divisor of $p$, so $q\ge p$. Then, $q=p$. Thus, $p$ only has two positive integer factors - itself, and 1. Therefore, $p$ is prime. (c) Suppose, for the sake of contradiction, that there exists a set $C$, of integers $\ge2$ that cannot be factored into a product of two prime numbers. By the well-ordering principle, there is some $m\in C$ such that $m$ is the minimal element of $C$. Because $m\in C$ and therefore cannot be prime, it must be the product of two integers $s,t$ such that $2\le s,t \lt m$. Therefore, $s,t\notin C$ because they are smaller than $m$, which is the minimal element of $C$. Since $s,t\notin C$, they can be factored into the products of primes, $a_1,a_2,b_1$ and $b_2$ such that $s=a_1*a_2$ and $t=b_1*b_2$. Since $s,t$ are divisors of $m$, $m=s*t=(a_1*a_2)(b_1*b_2)$, the product of primes. This is a contradiction, because $m\in C$. Thus, set $C$ cannot exist. As a consequence, we have proved that every integer $n\ge2$ has a prime factor. [The End] Have I got it right? If not, please point out any flaws. If I do have it correct, what I would especially appreciate is any input on the proof-writing itself - is it nonsensical or inefficient? Thanks!","['well-orders', 'proof-verification', 'proof-writing', 'logic', 'elementary-set-theory']"
2776054,Closed-form expression of a tricky integral,"Let $a$, $b$ and $c$ be positive real scalars such that $a>b,c$ and consider the following integral
$$
\int_{t_0}^{t_1} \log\left(\frac{a-c}{a-b\sin(\tau)}\right)\,\mathrm{d}\tau.
$$ My question. Does there exist some sort of nice closed-form expression of the above integral? If so, does there also exist a ""nice"" closed-form expression of the following multiple integral
  $$
\int_{t_0}^{t_1} \int_{\tau_{1,0}}^{\tau_1} \cdots \int_{\tau_{k-1,0}}^{\tau_{k-1}} \log\left(\frac{a-c}{a-b\sin(\tau_k)}\right)\,\mathrm{d}\tau_k \cdots\,\mathrm{d}\tau_2\,\mathrm{d}\tau_1 \ \ \ ?
$$","['integration', 'analysis', 'closed-form']"
2776085,What is the difference between sample space and event space?,"I am a little confused about the difference between sample space and event space. After reading some information, I want to take an example. If I am wrong, please correct me. Sample space: all possible outcomes Event: a subset of the sample space Event space: all events For a fair die: Sample space: ${(1, 2, 3, 4, 5, 6)}$ Event: $(1)$ or $(2)$ or $(3)$ or $(4)$ or $(5)$ or $(6)$ or $(1,2)$ or $(1,3)$ or $(1,4)$ or $(1,5)$ or $(1,6)$ or $(2,3)$ or $(2,4)$ or $(2,5)$ or $(2,6)$ or $(3,4)$ or $(3,5)$ or $(3,6)$ or $(4,5)$ or $(4,6)$ or $(5,6)$ or $(1,2,3)$ or $(1,2,4)$ or $(1,2,5)$ or $(1,2,6)$ ,etc. Event space: all events Although the event is the subset of sample space, and event space is the all events. The sample space is actually not the same as event space, right?","['probability-theory', 'probability']"
2776110,Find all integers $m$ and $n$ such that $n\cos\frac{\pi}{m}= \sqrt{8+\sqrt{32+\sqrt{768}}}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Find all integers $m$ and $n$ such that: 
  $$n\cos\frac{\pi}{m}= \sqrt{8+\sqrt{32+\sqrt{768}}}$$ I tried to find the relation of $m$ and $n$, but it's difficult for me. I need help! Thanks!",['trigonometry']
2776133,Deriving a recurrence equation,I've really been stuck on this problem for a while. We have the equation: $s_t = (s_{t-1}/2)+3$. I need to show the steps it would take to show this can be written as: $s_t = 2^{-t}(s_0-6) +6$. I figure it has something to do with telescoping but I'm not sure how this would be done.,"['recurrence-relations', 'discrete-mathematics']"
2776152,Vector Spaces: Understanding the basics,"I'm studying for the Math GRE subject test and I'm currently going over Linear Algebra. I'm carefully re-reading my course book ""Linear Algebra Done Right"" By Sheldon Axler (Third Edition). I have a few questions in regards to the fundamental concepts: Going over the definition of a Vector Space , it doesn't seem obvious to me why we need the scalars , adjoined to the vector set , to be members of a Field . If we loosen this definition of a Vector Space a little bit I think we can get algebraic structures that are analogous to that of a Vector Space and thus meaningful. Hence my first question: Is the Real Number Line a Vector Space? . If so, then this would imply that numbers themselves can be interpreted as vectors. Then, in trying to consider ""small"" Vector Spaces (other than the trivial case of the singleton zero vector set $\{0\}$) I wonder, in this sense, my second question: can there be Vector Spaces contained inside the Real Number Line? It is here where loosening the definition of a vector space can be of merit. If we allow our scalars to be Integers and our vector set to be all the multiples (positive and negative) of a Natural Number then that vector set adjoined with the operation of vector addition and scalar multiplication would manifest all the characteristics that define a Vector Space. Try using the set that contains all the multiples of three - $\{x | x = 3\alpha \text{ where } \alpha \in \mathbb{Z}\}$. Thus why would such a structure not be a vector space. Is it missing something? Or why do we demand that we use scalars from a field? I'm interested in knowing what you think.","['modules', 'abstract-algebra', 'ring-theory', 'linear-algebra', 'vector-spaces']"
2776158,Is the blue area greater than the red area?,"Problem: A vertex of one square is pegged to the centre of an identical square, and the overlapping area is blue. One of the squares is then rotated about the vertex and the resulting overlap is red. Which area is greater? Let the area of each large square be exactly $1$ unit squared. Then, the area of the blue square is exactly $1/4$ units squared. The same would apply to the red area if you were to rotate the square $k\cdot 45$ degrees for a natural number $k$ . Thus, I am assuming that no area is greater, and that it is a trick question $-$ although the red area might appear to be greater than the blue area, they are still the same: $1/4$ . But how can it be proven ? I know the area of a triangle with a base $b$ and a height $h\perp b$ is $bh\div 2$ . Since  the area of each square is exactly $1$ unit squared, then each side would also have a length of $1$ . Therefore, the height of the red triangle area is $1/2$ , and so $$\text{Red Area} = \frac{b\left(\frac 12\right)}{2} = \frac{b}{4}.$$ According to the diagram, the square has not rotated a complete $45$ degrees, so $b < 1$ . It follows, then, that $$\begin{align} \text{Red Area} &< \frac 14 \\ \Leftrightarrow \text{Red Area} &< \text{Blue Area}.\end{align}$$ Assertion: To conclude, the $\color{blue}{\text{blue}}$ area is greater than the $\color{red}{\text{red}}$ area. Is this true? If so, is there another way of proving the assertion? Thanks to users who commented below, I did not take account of the fact that the red area is not a triangle $-$ it does not have three sides! This now leads back to my original question on whether my hypothesis was correct. This question is very similar to this post . Source: The Golden Ratio (why it is so irrational) $-$ Numberphile from $14$ : $02$ .","['inequality', 'area', 'triangles', 'geometry']"
2776256,A functional equation problem: $ \frac { f \left( f ( y ) ^ 2 + x y \right) } { f ( y ) } = f ( x ) + y $,"Let $ \mathbb R ^ + $ denote the set of the positive real numbers. Find all functions $ f : \mathbb R ^ + \to \mathbb R ^ + $ satisfying $$ \frac { f \left( f ( y ) ^ 2 + x y \right) } { f ( y ) } = f ( x ) + y $$ for all $ x , y \in \mathbb R ^ + $ . I am very thankful for any solution, please help! I tried to set $ x = y = 1 $ , $ x = y = 2 $ , $ x = 1 $ , $ y = 2 $ , so on, but this problem is more difficult.","['contest-math', 'functions', 'functional-equations']"
2776274,"A Paul Erdős problem: If a triangle has circumradius $R$ and largest exradius $r_a$, then $2r_a\geq 3R$","Let $r_a$ be the radius of the largest escribed circle of a triangle, and let $R$ denote the radius of the circumscribed circle. Prove that $2r_a \geq 3R$. How to prove it? I am not keen on inequalities, but I think (since it is from Paul Erdős) it is a beautiful problem. Please help! Thank you!","['geometric-inequalities', 'geometry']"
2776291,A geometry problem with the reflection of the incenter,"Consider $\triangle ABC$ and its incenter $I$. Let $M$ be the midpoint of arc $BC$ (not containing $A$) and $P$ be the second intersection point of the circumcircle of $\triangle ABC$ and the circle with center $I$ and radius $IA$. Prove that if $I'$ is the reflection of $I$ with respect to $BC$, then $I', P, M$ are collinear (lie on the same line). Please help, I am lost, I don't have any idea! Thanks a lot in advance! Anyway, this problem is based on a problem connected to the reflection of the incenter, which appeared in Mathematical Excalibur. For help, here is a figure:","['geometric-transformation', 'reflection', 'euclidean-geometry', 'geometry', 'contest-math']"
2776307,"Find $P(B(s)>0, B(t)>0)$, where $B(s)$ is Brownian motion, $s<t$.","Exercise 7.1.1 in Textbook by Durret. I try to find $P(B(s)>0, B(t)>0)$, where $B(s)$ is Brownian motion, $s<t$. But how to write the probability in terms of $B(s)$ and $B(t)-B(s)$? If it works, I have got $$P(B(s)>0, B(t)-B(s)>0)=P(B(s)>0)P(B(t)-B(s)>0)$$
$$=\int_{0}^{\infty}\frac{1}{\sqrt{2\pi s}}\exp\Big(-\frac{x^2}{2s}\Big)\int_{0}^{\infty}\frac{1}{\sqrt{2\pi (t-s)}}\exp\Big(-\frac{x^2}{2(t-s)}\Big).$$","['stochastic-processes', 'probability-theory', 'brownian-motion', 'stochastic-analysis']"
2776335,Converting $\frac{(3+3i)^5 (-2+2i)^3}{(\sqrt 3 +i)^{10}}$ to trigonometric form,"Convert complex to trig. $$\frac{(3+3i)^5 (-2+2i)^3}{(\sqrt 3 +i)^{10}}$$ Let us consider 
$$(3+3i)^5$$
Here $a = 3$ ,$b=3$ $$\sqrt{a^2+b^2}=\sqrt{3^2+3^2} = \sqrt{18}=3\sqrt{2}$$ $$\theta =\arctan\biggr(\frac{b}{a}\biggr) =\arctan\biggr(\frac{3}{3}\biggr) = \arctan (1)$$ $$\theta = \frac{\pi}{4}$$ Thus in trigonometric form we get $$Z_1 = \biggr [3\sqrt2 \bigg(\cos \frac{\pi}{4}+i\sin \frac{\pi}{4}\bigg)\bigg]^5$$ $$Z_1 =(3\sqrt 2)^5 \biggr [\bigg(\cos \frac{5\pi}{4}+i\sin \frac{5\pi}{4}\bigg)\bigg]$$ Let us consider $$(-2+2i)^3$$ $a = -2$, $b=2$ $$\sqrt{a^2+b^2}=\sqrt{(-2)^2+2^2} =2\sqrt{2}$$ $$\theta =\arctan\biggr(\frac{b}{a}\biggr) =\arctan\biggr(\frac{2}{-2}\biggr) = \arctan (1)$$ $$\theta = \frac{3\pi}{4}$$ $$Z_2 =(2\sqrt 2)^3 \biggr [\bigg(\cos \frac{9\pi}{4}+i\sin \frac{9\pi}{4}\bigg)\bigg]$$ Multiplying $Z_1 \cdot Z_2$ we get $$Z_1 \cdot Z_2 = (3\sqrt 2)^5 \cdot (2\sqrt2)^3  \biggr [\bigg(\cos \frac{5\pi}{4}+\cos \frac{9\pi}{4}\bigg)+i\sin \bigg(\frac{5\pi}{4}+i\sin\frac{9\pi}{4}\bigg)\bigg]$$ $$Z_1 \cdot Z_2 = 31104\biggr [\bigg(\cos \frac{7\pi}{2}+i\sin \frac{7\pi}{2}\bigg)\bigg]$$ Let us consider $$(\sqrt 3+i)^{10}$$ Here $a = \sqrt 3$, $b =1$
$$\sqrt{a^2+b^2}=\sqrt{(\sqrt3)^2+1^2} = \sqrt{4}=2$$ $$\theta = \arctan \biggr(\frac{1}{\sqrt 3}\biggr) = \frac{\pi}{6}$$ $$Z_3 = 2^{10} \biggr [ \cos \biggr(\frac{5\pi}{3}\biggr)+i\sin \biggr(\frac{5\pi}{3}\biggr)\biggr]$$ Now we have $$\frac{Z_1 \cdot Z_2}{Z_3} = \frac{31104\biggr [\bigg(cos \biggr(\frac{7\pi}{2}\biggr) +i\sin \biggr(\frac{7\pi}{2}\biggr) \bigg]}{2^{10} \biggr [ \cos \biggr(\frac{5\pi}{3}\biggr)+i\sin \biggr(\frac{5\pi}{3}\biggr)\biggr]} = \boxed {30.375 \biggr [ \cos \biggr(\frac{11\pi}{6}\biggr)+i\sin \biggr(\frac{11\pi}{6}\biggr)\biggr]}$$ Is my assumption correct?","['trigonometry', 'complex-numbers']"
2776351,"Does $\mathbb{N} = \lim_{n \to \infty} \{0, 1, 2, ..., n\}$?","I thought that ($\mathcal{P}$ is the powerset) $$\mathcal{P}(\mathbb{N}) = \lim_{n \to \infty} \mathcal{P}(\{0, 1, 2, ..., n\}) = \bigcup_{n = 1}^{\infty} \mathcal{P}(\{0, 1, 2, ..., n\})$$ But recently found out this is wrong. So I wonder, does $$\lim_{n \to \infty} \{0, 1, 2, ..., n\} =^{?} \bigcup_{n = 1}^{\infty} \{0, 1, 2, ..., n\} =^{?} \mathbb{N}$$ And if yes , how come the first equation does not hold?",['elementary-set-theory']
2776356,Proof any five points determine a conic,"Theorem There is a conic through any five $\color{red}{\textit{pairwise distinct }}$ points in a real plane.
$(1)$  It is unique if and only if no four of the points are colinear; 
$(2)$  It is  nondegenerate if and only if no three of the points are collinear . How to prove this theorem , only applying some theories of linear algebra(including matrix)？ Let $\textbf{p}_{i}=(x_{i},y_{i}),i=1,2,3,4,5.$ be the five points in the plane . Consider a homogeneous system $\textbf{Ax}=\textbf{0}$ whose coefficient matrix is $\textbf{A}= \begin{pmatrix}
 x_{1}^{2}&  x_{1}y_{1}&  y_{1}^{2}&  x_{1}&  y_{1}&  1\\ 
 x_{2}^{2}&  x_{2}y_{2}&  y_{2}^{2}&  x_{2}&  y_{2}&  1 \\ 
 x_{3}^{2}&  x_{3}y_{3}&  y_{3}^{2}&  x_{3}&  y_{3}&  1 \\ 
 x_{4}^{2}&  x_{4}y_{4}&  y_{4}^{2}&  x_{4}&  y_{4}&  1\\ 
 x_{5}^{2}&  x_{5}y_{5}&  y_{5}^{2}&  x_{5}&  y_{5}&  1 
\end{pmatrix}; $ $\qquad\qquad\textbf{x}$ = $\begin{pmatrix}
A\\ 
B\\ 
C\\ 
D\\ 
E\\
F 
\end{pmatrix};$ $\qquad\qquad\textbf{0}$=$\begin{pmatrix}
0\\ 
0\\ 
0\\ 
0\\ 
0
\end{pmatrix}.$ $\textbf{A}_{i}(i\in\{1,2,3,4,5,6\})$ is the $5\times 5$  square matrix obtained by deleting the $i^{th}$ column of $\textbf{A}.$
$\\$ Then the above theorem  is equalvlity of the following statement from the algebraic point of view. $(1){'} $ $rank(A)=5$ and at least one of $\textbf{A}_{1},\textbf{A}_{2},\textbf{A}_{3}$ is nonsingular. $\Longleftrightarrow $ $\forall\quad k_{1},k_{2},k_{3},k_{4}\in \{1,2,3,4,5\} $and $k_{1}<k_{2}<k_{3}<k_{4}$,$ rank(\begin{pmatrix}
 x_{k_{1}}&  y_{k_{1}}& 1\\ 
 x_{k_{2}}&  y_{k_{2}}& 1 \\ 
 x_{k_{3}}&  y_{k_{3}}& 1\\ 
 x_{k_{4}}&  y_{k_{4}}& 1 
\end{pmatrix})=3.$ $(2){'}$ A conic through $\textbf{p}_{i}=(x_{i},y_{i}),i=1,2,3,4,5$ is nondegenerate.$\Longleftrightarrow $ $ \forall \quad k_{1},k_{2},k_{3}\in \{1,2,3,4,5\} $and $k_{1}<k_{2}<k_{3}$,$ rank(\begin{pmatrix}
 x_{k_{1}}&  y_{k_{1}}& 1\\ 
 x_{k_{2}}&  y_{k_{2}}& 1 \\ 
 x_{k_{3}}&  y_{k_{3}}& 1
 \end{pmatrix})=3.$ Until now, how to prove $(1){'}$,$(2){'}$ hold, only using some theories of linear algebra(including matrix)？","['algebraic-geometry', 'matrices', 'projective-geometry', 'matrix-rank', 'linear-algebra']"
2776381,Proof Verification: All subsets of the natural numbers are at most countable.,"Proof:
Suppose $X\subset\Bbb{N}$ and $X\neq\emptyset$; By the well-ordering principle $X$ has a minimum element. $\forall X'=X\setminus\{x_0\}\subset\Bbb{N}$ such that $x_0\leq m,\forall m\in X$, we know that that $X'$ still has a minimum element $x_1$, by the well-ordering principle. Clearly, $x_1$ is the next least element in $X$. By defining a function $f:\Bbb{N}\rightarrow X$ such that if $x_n$ is the least element of $X_n\subset\Bbb{N}$ and $x_{n+k}$ is the least element of $X_n=X\setminus\{x_n,x_{n+1},...,x_{n+k-1}\}\subset\Bbb{N}$, then \begin{align}f(0)=x_n\quad and\quad f(n+k)=x_{n+k}\end{align} for all $n,k\in\Bbb{N}$. Thus, $f$ is surjective. Furthermore, if $f(j)=f(i)$ then $x_{n+j}=x_{n+i}$. Since $x_{n+i}$ is the least element of $X_{n+i}=X_n\setminus\{x_n,...,x_{n+i-1}\}$ and $x_{n+j}$ is the least element of $X_{n+j}$. We know by the well-ordering principle that the least element is unique. Suppose $X_{n+i}\neq X_{n+j}$ such that $X_{n+i}\subset X_{n+j}$ where $X_{n+j}=X_n\setminus\{x_n,...,x_{n+i},...,x_{n+j-1}\}$. Since $x_{n+i}\notin X_{n+j}$, then it cannot be the least element of $X_{n+j}$ and $x_{n+i}\neq x_{n+j}$, a contradiction. Therefore, it must be that $X_{n+i}=X_{n+j}$ which means $\vert X_{n+j}\vert =\vert X_{n+i}\vert$ and $i=j$. Hence, $f$ is also injective.","['elementary-set-theory', 'proof-verification']"
2776386,How to solve the differential equation $xx'' = (x')^2$?,"There is an differential given:
$$xx'' = (x')^2,$$
where $x' \neq 0.$ I tried to solve this problem but I cannot see the proper substitution.",['ordinary-differential-equations']
2776451,Solve an equation which contains binomial coefficient,"I have the following equation: 
$${{x}\choose{3}}=10$$
I want to solve it for $x$ so I wrote: 
$${{x}\choose{3}}=\frac{x!}{3!(x-3)!}=10$$
which follows: 
$$\frac{x!}{(x-3)!}=60$$
I wonder how to proceed from here and solve for $x$? As $(x-3)!\neq x!-3!$.","['combinatorics', 'binomial-coefficients']"
2776479,Finding equal partial sum given two $N$-tuples of natural numbers,"This is an interesting question which I haven't found anyone addressing it. Let $N$ be a fixed natural number, $(a_1, \cdots, a_N), (b_1, \cdots, b_N)$ two $N$-tuples of natural numbers with $a_i, b_j \in \{1, 2. \cdots, N\}$. Does there exist a subcollection $(a_{i_1}, \cdots, a_{i_k})$, $(b_{j_1}, \cdots, b_{j_l})$ so that 
  $$a_{i_1} + \cdots + a_{i_k} = b_{j_1} + \cdots + b_{j_l}?$$ Example : say $N=3$. Consider $(1,1,2)$ and $(1,3,3)$. Obviously there are equal partial sums.  Take $1, 2$ from the first triples and $3$ from the second, we got $1+2 =3$. Or , you can find another equal sum: Take $1 =1$ for example. For example for $N=4$. Similarly we can always find an equal sum. Let's check this with a few trials. Say we have $$(4, 4,4,4), (3,3,3,2).$$
We can find at least one equal sum as follows: $4+4 =3+3+2$. Another trial : $(1,1,1,1)$, $(2,3,2,3)$. We can find easily even more than one equal sum: $1+1=2$, $1+1+1 =3$ etc... I always found equal partial sums. I couldn't find a counter example. I am asking either for a counter example or a proof. Remark : 
I know that the statement is true for two $2N$-tuples with numbers ranged from $1$ to $N$. In this case the proof is easy with the pigeonhole principle. You must get two subgroups which are equal. Moreover you would get sequences which are equal. But would that hold true for sets of length $N$? The simple proof that works for $2N$ wouldn't hold here. On the other hand I couldn't find any counter example for $N$. Is it true or not?  Is it possible to prove one way or the other?","['pigeonhole-principle', 'combinatorics', 'contest-math']"
2776482,In Geometric distribution what does it mean to include first success,"I was watching the harvard stat110 course on Geometric distribution and the PMF is $P(X = k) = pq^k$ where $p$ is the probability of success and $q = 1-p$. later he mentions another r.v $Y$ which he defined as the 1st success distribution and he mentions that this distribution, unlike the Geometric Distribution, includes the first success. I got a bit confused as to the meaning of including the first success, in the PMF of $Geo(p)$ there is a $p$, isn't this including the first success already?","['statistics', 'probability-distributions']"
2776524,Constructing $2n$ points with no three collinear points,"For any integer $n \ (n \geq 2)$, is there a way to construct $2n$ points $(x_1, y_1), (x_2, y_2), \cdots, (x_{2n}, y_{2n})$ with following conditions? For every integer $i \ (1 \leq i \leq 2n)$, $x_i$ and $y_i$ are integers between $1$ and $n$ Every points are different, i.e. for every integers $1 \leq i < j \leq 2n$, it satisfies $x_i \neq x_j$ or $y_i \neq y_j$ For every integers $i, j, k \ (1 \leq i < j < k \leq 2n)$, $(x_i, y_i), (x_j, y_j), (x_k, y_k)$ are not collinear Small-case examples: If $n=2$, if points are $(1, 1), (1, 2), (2, 1), (2, 2)$, it satisfies all conditions. If $n=3$, if points are $(1, 1), (1, 2), (2, 1), (2, 3), (3, 2), (3, 3)$, it satisfies all conditions. If $n=4$, if points are $(1, 1), (1, 2), (2, 3), (2, 4), (3, 1), (3, 2), (4, 3), (4, 4)$, it satisfies all conditions. Is there some construction for all $n$, including $n \geq 5$? If there are, how to construct?","['combinatorics', 'geometry']"
2776529,Draw a perpendicular to diameter with only a straight edge,"Given a circle $C_1$, its diameter $AB$ and a Point anywhere on the plane $X$ form a method to draw perpendicular to line $AB$ passing through $X$ using only a straight edge. I solved cases where $X$ is NOT on the circle or the line $AB$ itself with relative ease. So my question is how to do it if $X$ lies on the circle or $AB$ How I did the first part (if $X$ not on circle or $AB$): 1. Draw $AX$ intersecting circle at $C$ 2. Draw $BX$ intersecting circle at $D$ 3. Draw $AD$ and $BC$ intersecting at $F$ 4. $XF$ is the required perpendicular This works because altitudes always pass through orthocenter. But this fails if $X=C,D,A,B$. How to do in those cases?",['geometry']
2776536,Finding Probability of on arrangement,"In a box, there are $100$ tickets numbered $1,\cdots, 100$. Let five tickets are taken out randomly one by one and kept in same order. Let $x_1, x_2, x_3, x_4,x_5$  be the numbers on the tickets $1,2,3,4,5$ respectively. Find the probability 
$$ a) P(x_1<x_2<x_3<x_4<x_5)?$$ 
$$ b) P(x_1<x_2<x_3>x_4>x_5)? $$
I am facing hard time solving this problem. If anyone helps that is well appreciated.","['probability-theory', 'probability', 'statistics']"
2776544,Existence of a special set in $\mathbb{R}^2$,"Let $X$ be a non–empty subset of $\mathbb{R}^2$ satisfying the following properties: Each point of $X$ is a limit point of $X$. ( Under the distance topology in $ \mathbb{R}^2$) No rational point belongs to $X$. (We call a rational point to be a point whose two coordinates in $\mathbb{R}^2$ are both rational numbers) $X$ is closed. Does such a set $X$ exist? If such a set $X$ exists, then any rational point in $\mathbb{R}^2$ is not a limit point of $X$. But I don't know how to go on. Any hint would be of great welcome! Edit: Thanks for everybody's help! Consider another question: What if we change $\mathbb{R}^2$ in the problem into $\mathbb{R}$?","['general-topology', 'real-analysis']"
2776620,Solving differential equations of the form $\theta''(t)+\theta'(t)+\theta(t-\delta)=0$,"TLDR: Hi, is there an exam friendly* method to solve (without using numerical methods)  differential equations of the form $$\theta''(t)+\theta'(t)+\theta(t-\delta)=0$$ I have been searching for 'delay differential equations' and only first order DDEs solutions seem to show up. *possible with bare hands, a graphing calculator, (and a reasonable level of mathematical intelligence for a pretty smart high school student) Basically, I am working on making a mock paper for my friends (still in high school) and ended up setting a question on 2nd order ODE that I can't solve. So I'm curious on whether there is a (hopefully not too advanced) way to solve such ODEs. The full question and the solution I have worked on so far is below: Consider an elliptical track at the standard position such that its major and minor axes lie on the $x$-axis and $y$-axis respectively. A point $P\left(a\cos \theta,b\sin \theta\right)$ on the ellipse, where $a>b>0$, is moving with an angular acceleration $\alpha$ rad s -2 , an angular velocity $\omega$ rad s -1 , and an angular displacement $\theta$ rad measured in an anticlockwise manner from the starting point $P_0\left(a,0\right)$. As $P$ is moving, a laser ray is continuously shot with the speed of light $c$ m s -1 from $P$ through the left focus of the elliptical track and reflects off a point $Q$ on the ellipse towards the right focus. The right focus then directs the laser ray back towards the point where it was shot from. The time taken in the process is denoted by $\delta$ s. The angular displacement of the current position of $P$ with respect to the point where the laser eventually hits is $\phi$ rad. Given that
$$\alpha+\omega+\theta=\phi$$
for time $t\ge\delta$, and 
$$\theta=\frac{2\sqrt3}3e^{-\frac t2}\sin\frac{\sqrt3}2t$$
for $0\le t <\delta$, find the parametric equations describing the motion of $P$ with respect to time $t$. By the geometric definition of an ellipse,
$PF_1+PF_2=2a$.
Hence, the distance traveled by the laser is 
\begin{align*}
PF_1+F_1Q+QF_2+F_2P
&=\left(PF_1+PF_2\right)+\left(QF_1+QF_2\right)\\
&=4a
\end{align*} The time $\delta$ s taken for the laser to travel back is $$\delta=\frac{4a}{c}$$ Hence the angular distance is such that
$$\phi=\theta\left(t\right)-\theta\left(t-\delta\right)=\theta\left(t\right)-\theta\left(t-\frac{4a}{c}\right)$$ Rewriting the given differential equation,
\begin{align*}
\alpha+\omega+\theta&=\phi\\
\alpha\left(t\right)+\omega\left(t\right)
+\theta\left(t\right)&=\theta\left(t\right)-\theta\left(t-\delta\right)\\
\alpha\left(t\right)+\omega\left(t\right)
+\theta\left(t-\delta\right)&=0\\
\alpha\left(t-\delta\right)+\omega\left(t-\delta\right)
+\theta\left(t-2\delta\right)&=0\\
\end{align*}","['conic-sections', 'ordinary-differential-equations', 'delay-differential-equations', 'calculus']"
2776638,Extreme points of a subset of density functions,"Let us consider the set of real density functions with fixed mean and variance: $$S(\mu, \sigma^2)=\{f: \Bbb R\to \Bbb R: f\geq 0, f \textrm{ continuous, }\\ \int_{\Bbb R}f(x)=1, \int_{\Bbb R}xf(x)=\mu,\; \int_{\Bbb R}(x-\mu)^2f(x)=\sigma^2\}.$$ I am curious about the following questions: What is the set of extreme points of S? Is the normal distribution with corresponding mean and variance an extreme point? Any pointer to the literature for either this or similar problems is also appreciated.","['density-function', 'convex-geometry', 'probability-theory', 'convex-analysis', 'stochastic-analysis']"
2776642,Expression for $\mathcal{O}_{\mathbb{P}(N_{Y/X})}(-k)$ in blowup,Let $X$ be a smooth toric variety and $Y \subset X$ be a complete intersection with the normal bundle $N_{Y/X}$ and $E \subset \mathrm{Bl_Y X}$ be exceptional divisor. Than it is well known that $E \simeq \mathbb{P}(N_{Y/X})$ and $\mathcal{O}_{\mathbb{P}(N_{Y/X})}(-k) \simeq \mathcal{O}_{E}(E)$. My question is: How to express $\mathcal{O}_{\mathbb{P}(N_{Y/X})}(-k)$ with $k > 1$ in similar terms? Actually i want to construct a resolution of $\mathcal{O}_{\mathbb{P}(N_{Y/X})}(-k)$ like $0\to\mathcal{O} \to \mathcal{O}(E)\to \mathcal{O}_{\mathbb{P}(N_{Y/X})}(-1)\to 0$,"['algebraic-geometry', 'blowup']"
2776685,Small oscillation of spherical pendulum,"I'm using Arnol'd's book on ordinary differetial equations. I'm having difficulty with problems after the example of small oscillations of a spherical pendulum. We have the system of differential equations $\dot{x}_1=x_2$, $\dot{x}_2=-x_1$, $\dot{x}_3=x_4$, $\dot{x}_4=-x_3$. Problem 1. Prove that the phase curves of this field lie on the three-dimensional spheres $x_1^2+\cdots+x_4^2=const$. I know how to do this one because the phase curves are defined by $x_1^2+x^2=c_1$ and $x_3^2+x_4^2=c_2$. Problem 2. Prove that the phase curves are great circle of these spheres. What is the definition of a great circle of $S^3$? I only know the definition of great circles of $S^2$. Problem 3. Prove that the set of all phase curves on each three-dimensional sphere itself form a two-dimensional sphere. First I need to figure out what the author means here. Does he mean that on each three-dimensional sphere, the union of all phase curves form a two-dimensional sphere? This is not true as the union is the whole three-dimensional sphere. Or does he mean that on each three-dimensional sphere, the set itself is a two-dimensional sphere when equipped with a topology in a natural way? This does not seem true because this set can be indexed by one single parameter $c_1$. Thanks in advance for your help!","['analytic-geometry', 'euclidean-geometry', 'geometry', 'general-topology', 'ordinary-differential-equations']"
2776696,Calculus: substitution for multiple variables,"Problem I have a question about variable substitution for a multivariate integral. Let me first pose the question and then provide some context, since I think the context is not necessarily very important. Say we have ( for example ) the following integral 
$$\int_0^1 \int_0^{1-\varepsilon_1} \int_0^{1-\varepsilon_1 -\varepsilon_2} 24 (1- \varepsilon_1 - \varepsilon_2 - \varepsilon_3) d\varepsilon_3 d\varepsilon_2 d\varepsilon_1= 1$$ Furthermore, let $z = \varepsilon_1 + \varepsilon_2 + \varepsilon_3$. I'm trying to find $f(z)$ satisfying
$$\int_0^1 f(z) dz = 1$$
corresponding to the integral above. At first glance, this seems like an easy problem, but whatever I do, I cannot seem to eliminate all the epsilon! I suppose there are three cases: $$\text{substituting } \varepsilon_1 = z - \varepsilon_2 - \varepsilon_3: \qquad \int_{\varepsilon_2 + \varepsilon_3}^{1+\varepsilon_2 + \varepsilon_3} \int_0^{1-\varepsilon_1} \int_{0}^{1- \varepsilon_1 - \varepsilon_2} 24 (1- z) d\varepsilon_3 d\varepsilon_2 dz$$ $$\text{substituting } \varepsilon_2 = z - \varepsilon_1 - \varepsilon_3: \qquad \int_0^1 \int_{\varepsilon_1 + \varepsilon_3}^{1+\varepsilon_3} \int_{0}^{1- \varepsilon_1 - \varepsilon_2} 24 (1- z) d\varepsilon_3 dz d\varepsilon_1$$ $$\text{substituting } \varepsilon_3 = z - \varepsilon_1 - \varepsilon_2: \qquad \int_0^1 \int_0^{1-\varepsilon_1} \int_{\varepsilon_1 + \varepsilon_2}^{1} 24 (1- z) dz d\varepsilon_2 d\varepsilon_1$$ The first two integrals will actually not evaluate to a numerical value. Only the last one will, but $z$ is eliminated in the first step (which is not what I want of course). So my question is: can I partially solve this integral in a way that leaves me with a function $f(z)$? Context I am trying to compute the convolution of a linear combination of three dependent variables $\varepsilon_1$, $\varepsilon_2$ and $\varepsilon_3$. So I am trying to determine the distribution of $\alpha_1 \varepsilon_1 + \alpha_2 \varepsilon_2 + \alpha_3 \varepsilon_3 + \cdots + \alpha_n \varepsilon_n$. I was able to determine the joint distribution $f(\alpha_1 \varepsilon_1, \ldots, \alpha_n \varepsilon_n)$, so I really only have the integration problem left to solve.","['multivariable-calculus', 'substitution', 'integration', 'convolution']"
