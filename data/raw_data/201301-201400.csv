question_id,title,body,tags
3955689,$\operatorname{rank}(AB-BA)=1$ implies $AB-BA$ is nilpotent,"Let $A$ and $B$ be $n \times n$ complex matrices. Then $\operatorname{rank}(AB-BA)=1$ implies $AB-BA$ is nilpotent. I have seen proof here that $\operatorname{rank}(AB-BA)=1$ implies $A$ and $B$ are simultaneously triangularisable, which implies that $AB-BA$ is nilpotent. I was wondering if there is an easier way to show the result. (I could show $A$ and $B$ share a common eigenvector but that does not imply $AB-BA$ is nilpotent.)","['matrices', 'matrix-rank', 'linear-algebra', 'eigenvalues-eigenvectors']"
3955731,"What do we mean when we say ""Let $x$ be an element of the set $\mathbb{R}$""?","What do we mean when we say ""Let $x$ be an element of the set $\mathbb{R}$ ""? Does $x$ represents only a single  element of set $\mathbb{R}$ ? or does $x$ represent all the element of set $\mathbb{R}$ simultaneously at the same time? People say that if $x\in\mathbb{R}$ then $x$ is any real number; that means $x$ represents all real numbers. But if $x$ is any real number then let's say $x=1$ ; so $x$ is one, then how it can represent all real numbers? Please help me I am very confused.","['elementary-set-theory', 'terminology']"
3955735,"The intersection of any $r+1$ sets in a set $F$ is nonempty, then the intersection of all sets in $F$ is nonempty.","Let $F = \{E_{1}, E_{2}, \ldots, E_{s}\}$ be a family of subsets with $r$ elements of some set $X$ . Show that if the intersection of any $r+1$ (not necessarily distinct) sets in $F$ is nonempty, then the intersection of all sets in $F$ is nonempty. Note that this has a solution but this statement seems untrue to me. But here is the given proof. Given Proof We assume the contrary that the intserction of all sets in $F$ is empty. Now consider the set $E_{1} = \{x_{1}, x_{1}, \ldots, x_{r}\}$ . Because none of the $x_{i}, i = 1,2, \ldots, r,$ lies in the intersection of all the $E_{j}$ (this intersection being empty), it follows that for each $i$ we can find some $E_{{j}_{i}}$ such that $x_{i} \notin E_{{j}_{i}}$ . Then \begin{align}
E_{1} \cap E_{{i}_{1}} \cap E_{{i}_{2}} \cap \ldots \cap E_{{i}_{r}} = \emptyset
\end{align} Since, at the sametime, this intersection is included in $E_{1}$ and does not contain any element of $E_{1}$ . But this contradicts the hypothesis. It follows that our initial assumption was false, and hence the sets from the family $F$ have a nonempty intersection. My Argument This becomes a problem given that the intersection of any $r+1$ sets in $F$ are not necessarily distinct. Thus if we take $E_{1}$ and intersect with itself $r+1$ times, the intersection is not empty. However, we note that it would be possible to come up with a set $F$ where $E_{1}, \ldots, E_{s}$ do not intersect for a given $X$ . And thus provides a counter example to the problem. Comments I don't think their proof is correct either given that we are picking $E_{{i}_{r}}$ to make sure the set intersection is empty. This is an invalid choice because it does not fit the narrative of the original question of being not necessarily distinct intersection. Any insight or help into understanding this proof would be helpful. Note this problem comes from Putnam and Beyond as an example in the first section.","['elementary-set-theory', 'combinatorics']"
3955743,Function resulting from taking a function from histogram data input.,"I was working with histograms and I have a histogram which has a shape that is well approximated by $a(\cos(x)+1)$ . I was wondering if I took a function on the data, say $\cos(x)$ and plotted the resulting data in a histogram, what function would well approximate that histogram? I have written a little code in python to make my question more clear: import numpy as np
import matplotlib.pyplot as plt

list_of_x = []
list_of_cosx = []

for i in range(100000):
    v = 2*np.arccos(2*np.random.random()-1)-np.pi
    list_of_x.append(v)
    list_of_cosx.append(np.cos(v))


plt.hist(list_of_x, bins=100)
plt.show()
# Well approximated by cos

plt.hist(list_of_cosx, bins=100)
plt.show()
# Well approximated by ??? ```",['functions']
3955760,"How to find coordinates of tangent point on circle, given center coordinates, radius, and end point of tangent line","I'm working on a hobby programming project and my mathematic thinking is feeling a bit slow at the moment. Basically, in situations similar to the image I made, given the information I mentioned in the title, I need to be able to calculate the coordinates of the tangent point. (Dimensions are from the origin.) Could you all help me out with finding a straightforward way of doing so? Thanks in advance. (P.S. In the program, this will actually be in 3D, but once I have the 2D solution I should be able to figure it out in 3D.)","['tangent-line', 'geometry']"
3955762,Find the area under curve using the given data,"Consider the curve $y=f(x)$ which satisfies the DE $(1+x^2)\frac{dy}{dx} +2xy=4x^2$ and passes through the origin. Find area enclosed by $f^{-1}x$ , x axis, and $x=2/3$ After some calculation which I don’t think is necessary to show here, I got $$y=\frac{4x^3}{3(1+x^2)}$$ Now the inverse for this function can’t be found directly, and I don’t know how else to do it. Can I get a hint?","['integration', 'definite-integrals', 'ordinary-differential-equations', 'inverse-function', 'calculus']"
3955780,When/why is a point on a curve an effective Cartier divisor?,"The definition of effective Cartier divisor that I'm using is: a closed immersion whose corresponding quasicoherent sheaf of ideals is an invertible sheaf. Let $X$ be a scheme that is dimension 1 and locally of finite type over a field $k$ (but can be singular or have multiple components). Let $p$ be a closed point on $X$ . Then why is the canonical morphism $f : Spec(k(p)) \rightarrow X$ is an effective Cartier divisor? This is my attempt so far: Since $p$ is a closed point, $f : Spec(k(p)) \rightarrow X$ is a homeomorphism onto its range and the range is closed. Also, the pullback morphism $f^\# : O_X \rightarrow f_* O_{Spec(k(x))}$ is surjective (as on an affine open neighbourhood $U = Spec(A)$ of $p$ , we have $A \rightarrow Quot(A/p) = A/p$ since $p$ is a closed point so it's a maximal ideal, so pullback is surjective). Therefore it's a closed immersion. Let $\mathcal{I}$ be the corresponding quasicoherent sheaf of ideals. For open sets U that don't contain $p$ , $\mathcal{I} \sim O_X|_{U}$ so is an invertible sheaf on there. But now I'm stuck on the part where open sets $U$ that contain $p$ . Is the statement even true? If so, how do I prove $\mathcal{I}$ is invertible on some open set $U$ that contains $p$ ?","['divisors-algebraic-geometry', 'algebraic-geometry', 'schemes']"
3955830,Unique question about packing problem,"I added the related pages from part 3 of the book: combinatorial geometry by János Pach,Pankaj K.Agarwal (1995) (which is not available on net so I added them as pictures). A. Prove that one can always find a packing $Ç$ of the plane with congruent copies of a convex disc $C$ whose density $d(Ç,R^2)$ exists and is equal to $\delta(C)$ .
Similarly show that there is a Lattice packing $Ç$ with $d(Ç,R^2)=\delta_L(C)$ . B.construct a packing $Ç$ of unit discs and two convex discs $P,P'$ such that $lim_{r\to \infty} d(Ç,P(r)) \neq lim_{r\to \infty} d(Ç,P'(r))$ . Hints:
Part A:To prove the first statement, construct a packing $C_n$ of congruent copies of $C$ in the disc $D(n)$ with density $d(C_n,D(n))\geq \delta(C)-O(1)/n$ For every n choose a subsequence $n_1,n_2,...$ such that $C_{n_i}$ converges when restricted to $D(1)$ as $i\to \infty$ .
From this choose a subsequence for which $C_n$ converges when restricted to $D(2)$ and so on.
Show that the limit packing meets the requirements. For part B: Let $Ç$ be the densest packing of unit discs in a cone.
Choose $P$ and $P'$ to be circular disc and a regular triangle respectively. Can you kindly help me to understand this (I'm a beginner in this field). 1.( https://i.sstatic.net/2k1mz.jpg ) 2.( https://i.sstatic.net/ZEdCp.jpg ) 3.( https://i.sstatic.net/fhhvM.jpg ) 4.( https://i.sstatic.net/WIVsz.jpg ) 5.( https://i.sstatic.net/B2O4m.jpg ) 6.( https://i.sstatic.net/ZuXvX.jpg ) Many thanks.","['geometry', 'packing-problem', 'combinatorial-geometry', 'combinatorics', 'density-function']"
3955877,"If a strictly convex function attains a minimum on the unit ball, does it attain a minimum on every weak*-compact set?","Let $X'$ be the topological dual of a normed TVS $X$ , and let $f$ be a real, strictly convex function on $X'$ If $f$ attains a minimum on the closed unit ball of $X'$ , does it attain a minimum on every weak*-compact subset of $X'$ ? Attempt. My guess is that it's not true. Let $X = X' = \mathbb R$ , so that the closed unit ball in $X'$ is $[1,-1]$ . The idea now is to define $f$ so that it's continuous on $[-1,1]$ , and therefore achieves a minimum, but introduce a discontinuity elsewhere so that it doesn't achieve a minimum on some other closed interval. For example, I was thinking something like $f(x) = (x-2)^2$ if $x \in (-\infty,2)$ and $f(x)$ is a linear on $[2,\infty)$ with, say, $f(2)=1$ . Then $f$ doesn't attain a minimum on $[1,2]$ . I'm not sure I can define $f$ in a way that makes it strictly convex, however. (Turns out I can't. See diracdeltafunk's comment below.)","['convex-optimization', 'topological-vector-spaces', 'convex-analysis', 'functional-analysis']"
3955907,How to read and execute $\sum_{1 \leq \ell <m<n} \frac{1}{5^{\ell}3^{m}2^{n}}$,"How to read and execute this sum? $$\sum_{1 \leq \ell <m<n} \frac{1}{5^{\ell}3^{m}2^{n}}$$ I am having trouble to understand where is my error. The question does not say, but I am assuming that $\ell$ starts at $1$ , $m$ at $2$ , and so $n$ at $3$ . This is essential a product of pg: $$\sum_{1 \leq \ell<m<n} \frac{1}{5^{\ell}3^{m}2^{n}} = \sum_{\ell=1}\frac{1}{5^{\ell}}\sum_{m=2}\frac{1}{3^{m}}\sum_{n=3}\frac{1}{2^{n}} = \frac{1/5}{1-1/5}\frac{1/9}{1-1/3}\frac{1/8}{1-1/2}$$ But this does not agree with the answer :/","['summation', 'notation', 'calculus', 'sequences-and-series', 'algebra-precalculus']"
3955974,"Stability of equilibrium points in Gradient Systems , Lyapunov functions and Hartman-Grobman Theorem","So I have learned about Lyapunov theory to study the stability of equilibrium points are now we want to apply it to the study of gradient systems. So suppose we have $x'=-\nabla V(x)$ and we have that $a$ is an equilibrium point for this equation that is $\nabla V(a)=0$ .  Now if we have that $a$ is an isolated local minimum we can use the Lyapunov function $H(x):=V(x)-V(a)$ to see that this is an asymptotically stable point. If $a$ is an isolated local maximum we can use $-H(x)$ to see that it is unstable, but what happens if $a$ is an isolated saddle point ? How can we study the stability in this case? One way I thought about it would be to use the Hartman-Grobman theorem and we know that the linearization of this dynamical system will be unstable and so since they have homeomorphic flows I guess this would also be unstable, but I am not completely sure this works, or if there is another way to see this.
I guess my biggest doubt is that if we can use the Hartman-Grobman theorem to study the stability of the sistem from the linearized equation. Any help is appreciated, thanks in advance.","['ordinary-differential-equations', 'dynamical-systems']"
3955985,Cannot Solve Tangent Plane Equation to Parametric Surface,"I have a problem while finding the equation of a tangent plane to a parametric surface. The surface is given by $$\pmb r = \begin{bmatrix} s^2 + t^2 \cr 2s+2t \cr 2 \end{bmatrix}$$ The point at which plane is tangent $$ \pmb r_o = \begin{bmatrix} 2 \cr 4 \cr 2 \end{bmatrix} (s=1, t=1)$$ I know that for tangent-plane equation, I need to find a normal vector $\pmb n$ by doing a cross-product of $\frac{\partial \pmb r}{\partial t}$ at $r_o$ and $\frac{\partial \pmb r}{\partial s}$ at $r_o$ . My problem is that both $\frac{\partial \pmb r}{\partial t}$ and $\frac{\partial \pmb r}{\partial s}$ are being computed as the same vector $\begin{bmatrix} 2 \cr 2 \cr 0 \end{bmatrix}$ . So my normal vector will always be zero, and I can't use it to find the equation of the tangent. How to get around this problem? Also, in general, how do we solve tangent-plane equations to parametric surfaces in such cases?","['vectors', 'geometry', 'multivariable-calculus', 'calculus', 'parametric']"
3955989,Simulating Brownian motion in R. Is this correct?,"I have a Weiner process $\{W(t)\}_{t\ge0}$ with $\sigma^2=\text{Var}(W(1))=1$ . For a real constant $\epsilon>0$ consider the differential ratio process $\Delta_\epsilon=\{\Delta_\epsilon(t)\}_{r>0}$ given by \begin{equation}
\Delta_\epsilon(t) = \frac{W(t+\epsilon)-W(t)}{\epsilon}, \quad \text{for} \ t>0.
\end{equation} I want to simulate a sample path of $\{\Delta_\epsilon(t)\}_{t\in(0,1]}$ for small $\epsilon>0$ in Rstudio. Simulating a basic Weinerprocess/Brownian motion is easy in R, one can do it by the function rweiner() or by plotting the cumulative sum of standard normally distributed variables. The part that confuses me is how to simulate the $W(t+\epsilon)$ . What I've done is used rwiener() and simply passed the end parameter to $1+\epsilon$ . epsilon = 10e-1
weinerEps = rwiener(end = 1+epsilon, frequency = 1000)
weiner = rwiener(end = 1, frequency = 1000)

Delta = (wienerEps - wiener)/epsilon

plot(Delta , type=""l"") I'm not sure this is correct though.","['stochastic-processes', 'statistics', 'brownian-motion']"
3956016,Completing a proof for a pigeonhole principle question,Seventeen people correspond by mail with one another - each one with all the rest. In their letters only three different topics are discussed. Each pair of correspondents deals with only one of these topics. Prove that there are at least three different people who write to each other about the same topic. Work I have done so far Each person can talk to maximum $16$ people on $3$ topics $\implies$ at least one topic will be spoken about $6$ times by Pigeonhole principle. This part is clear to me. I do not understand how to complete the proof by showing that there are at least three different people who write to each other about the same topic.,"['pigeonhole-principle', 'combinatorics', 'discrete-mathematics']"
3956025,Geometric interpretation of differentiability,"I know that the geometric interpretation of differentiability for a function $f:\mathbb{R}^2\to \mathbb{R}$ in a point $(x_0,y_0)$ is that it admits a tangent plane in the point $P=(x_0,y_0,f(x_0,y_0))$ . Thinking about the concept geometrically, I came up with the following """"conjecture"""". Let for simplicity $\ell_{v}$ the tangent line in the point $P$ to the graphic of $f$ in the direction of the versor $v$ , and let's suppose the function $f$ admits directional derivatives in every direction. $f \text{ differentiable in } (x_0,y_0)$ $\iff$ $\forall v,u \ \ \text{versors}$ , $\ell_{v}$ $\text{and}$ $\ell_{u}\ \text{are coplanar}$ I tried proving this using affine geometry but calculations get pretty messy. I would like if it's true or not(in the former case I would like a proof, in the latter a counterexample)","['geometric-interpretation', 'multivariable-calculus', 'derivatives', 'affine-geometry']"
3956067,Find the Expectation and Variance of 4 Independent Dice,"We were given this seatwork: With four independent dice: a) the expected value of the sum of the rolls, b) the expected value of the product of the rolls, and c) the variance of the sum of the rolls . I was able to answer a and b, but I don't know how to get the variance. Here's my attempt: \begin{align*}
S = \dfrac{1 + 2 + 3 + 4 + 5 + 6}{6} = 3.5
\end{align*} This is the expectation of one die. For the expectation of four dice, we could assume the expectation of the sum four dice is equal to the sum of the expectations of a die: \begin{align*}
&= S + S + S + S\\
&= 4S\\
&= 4(3.5)\\
&= 14
\end{align*} Similarly, we could also do this for the products. The expected product of four dice rolls is: \begin{align*}
&= S \cdot S \cdot S \cdot S\\
&= S^4\\
&= 3.5^4\\
&= 150.06
\end{align*} Are these assumptions correct?","['solution-verification', 'discrete-mathematics', 'probability']"
3956112,"Why do I get a math error for this when trying to compute $\int_{-1}^1(x^2-\frac{1}{x^2}+3) \, dx$?","I tried to evaluate $$
\int_{-1}^1(x^2-\frac{1}{x^2}+3) \, dx
$$ in the following way: $$
\left[\frac{x^3}{3}+\frac{1}{x}+3x\right]_{-1}^1=\frac{26}{3} \, .
$$ But when I typed the integral into a calculator I got a math error. Why did this happen?","['integration', 'calculus', 'improper-integrals']"
3956130,(Tao's Ex 1.1.3) Uniqueness of elementary measures; confused how to proceed.,"This is an exercise from Tao's Introduction to Measure Theory. Exercise 1.1.3:( $\textit{uniqueness of elementary measure}$ ) Let $d \ge 1$ . Let $m':\mathcal{E}(\mathbb{R}^d)\to \mathbb{R}_{\ge 0}$ be a map from the collection $\mathcal{E}(\mathbb{R}^d)$ of elementary subsets of $\mathbb{R}^d$ to the non negative reals that obeys the non-negativity, finite additivity and translation invariance. Show that there exists a constant $c \in \mathbb{R}_{\ge 0}$ such that $m'(E)=c\,m(E)$ for all elementary sets $E$ . In prticular, if we impose the additional normalisation $m'\left([0,1)^d\right)=1$ then $m' \equiv m$ . Attempt: Given hint: set $c:=m'([0,1]^d)$ and then compute $m'\left([0,\tfrac{1}{n})^d\right)$ . For simplicity I've tried for $d=1$ . Partitioning we get $E:=[0,1)=[0,\tfrac{1}{n})\cup [\tfrac{1}{n},\tfrac{2}{n})\cup \cdots \cup [\tfrac{n-1}{n},1)$ for some $n\in \mathbb{N}$ . Now translating $[0,1)$ by $\tfrac{k}{n}$ we get $[\tfrac{k}{n},\tfrac{k+1}{n})$ where $k=1,\ldots,n-1$ . Now given that $m'$ obeys translation invariance, then we write $$m'\left([0,\tfrac{1}{n})\right)=m'\left([\tfrac{k}{n},\tfrac{k+1}{n})\right)$$ Now using the finite additivity property we get \begin{align}
    m'([0,1))&=m' \left(\bigcup_{k=0}^{n-1}[\tfrac{k}{n},\tfrac{k+1}{n})\right)=\sum_{k=0}^{n-1}m' \left([\tfrac{k}{n},\tfrac{k+1}{n})\right)\nonumber \\&=\sum_{k=0}^{n-1}m'([0,\tfrac{1}{n})]=n\cdot m'([0,\tfrac{1}{n}))\nonumber
\end{align} This gives us $m'([0,\tfrac{1}{n}))=\tfrac{1}{n}m'([0,1))=c\cdot m([0,\tfrac{1}{n})).$ I can do this for any $d$ , also setting $m'([0,1)^d)=1$ , i will have $m'\equiv m.$ But does intervals of type $[0,\tfrac{1}{n})$ exhaust all possibilities? Don't i need to consider also intervals of the form $[0,a)^d$ where $a\in \mathbb{R}_{\ge 0}$ ? I'm confused at this stage. Appreciate any help.","['measure-theory', 'real-analysis']"
3956176,Suppose $A\subseteq{C}\And{B}\subseteq{D}$ Prove that: $A\times{B} = \left(A\times{D}\right)\cap\left(C\times{B}\right) $,"I'm not sure how to approach it. So far I've come to this: \begin{array}{|c|}
            \hline
            a\in{A}\rightarrow{}a\in{C} \\
            b\in{B}\rightarrow{}b\in{D} \\
            \hline
\end{array} $$\left(x,y\right)\in \left(A\times{D}\right)\cap\left(C\times{B}\right)$$ $$\Downarrow$$ $$\left(x,y\right)\in\left(A\times{D}\right)\land\left(x,y\right)\in\left(C\times{B}\right)$$ $$\Downarrow $$ \begin{array}{c|c}
x\in{A} & x\in{C} \\
y\in{D} & y\in{B}
\end{array} True $$\Downarrow$$ $$A\times{B} = \left(A\times{D}\right)\cap\left(C\times{B}\right)$$ But I don't think it's correct at all.","['elementary-set-theory', 'discrete-mathematics']"
3956179,"Are there non-homogeneous topological spaces which are ""almost homogeneous"" in Rudin's sense?","Let $X$ be a nonempty topological space and $G$ the group of all homeomorphisms $g:X\to X$ . Recall that $X$ is homogeneous if $G$ acts transitively on $X$ . In ""Homogeneity Problems in the Theory of Čech Compactifications"", The Mathematical Legacy of Eduard Čech (1993), pages 81-92, Walter Rudin considers the following condition on $X$ : for all point $x\in X$ and all nonempty open subset $U\subset X$ there is a $g\in G$ such that $g(x)\in U$ . He calls such a space almost homogeneous . I suspect that there are simple examples of almost homogeneous non-homogeneous spaces, but I haven't been able to find any. Let me ask the implicit question formally, together with an obvious follow-up question: Question 1. Are there almost homogeneous non-homogeneous spaces? Question 2. Assuming the answer to Question 1 is Yes, what is the least possible cardinality of an almost homogeneous non-homogeneous space? [I added the quotient-spaces tag because, in the above notation, $X$ is almost homogeneous if and only if the quotient topology of $G\backslash X$ is coarse.]","['general-topology', 'group-actions', 'quotient-spaces']"
3956195,Difficulty in proving that closure of an open ball of radius $r$ is a closed ball.,"Let $X$ be a metric space and $A$ be a subset of $X$ such that for some $p\in X$ and $\delta \gt 0$ , we have $A=\{a\in X: d(a,p)\lt \delta\}$ . Let's define $B=\{b\in X: d(b,p)\le\delta\}$ . Let $\bar A=$ Closure of $A=A\cup A'$ , where $A'$ is the set of limit points of $A$ . I am trying to prove that $\bar A= B$ . For any $x\in B$ , we have $d(p,x)\le \delta$ so either $d(p,x)\lt \delta $ or $d(p,x)=\delta$ . If $d(p,x)\lt \delta $ , then $x\in A\subseteq A\cup A'$ However, if $d(p,x)=\delta$ , then I am having difficulty in showing $x\in \bar A$ . I tried as follows: Let $0\lt\epsilon \lt \delta$ , choose $z\in A$ such that $\delta \gt d(p,z)\gt \delta -\epsilon$ , then we must have $d(x,p)+d(p,z)\ge d(x,z)\implies d(x,z)\le 2\delta$ . I am stuck here. I want to show that $d(x,z)\lt \epsilon$ which would prove that $x$ is a limit point of $A$ i.e., $x\in A'\subseteq A\cup A'$ Please help. Thanks.","['calculus', 'general-topology', 'real-analysis']"
3956253,Proof of Inclusion Exclusion Principle,"Show that $|A \cup B| + |A \cap B|= |A| + |B|$ for two finite sets $A$ and $B$ . Can you please check the proof below, and let me know if it's right? It makes me a bit uneasy for some reason, and I can't tell why. My givens are: $|A|$ is defined as $n$ if there is a bijection $f: A \to \{1,2,\dots,n\}$ . The cardinality of an empty set is 0. If there is some bijective $f: A \to B$ and a bijective $g: B \to C$ , then there exists some $h: A \to C$ such that $h$ is also bijective. Rudimentary results about sets from Chapter 1 of the text I'm using.","['elementary-set-theory', 'inclusion-exclusion', 'discrete-mathematics']"
3956271,Question about isometric isomorphism between normed spaces.,"Let $(\Omega, \mathcal F)$ be a measurable space. Let $\mu$ and $\nu$ be two $\sigma$ -finite measures on $(\Omega,\mathcal F).$ Define two norms $\|\cdot\|_{\mu}$ and $\|\cdot\|_{\nu}$ on $L^1(\mu)$ and $L^1(\nu)$ respectively defined by $\|f\|_{\mu} : = \int_{\Omega} |f|\ d\mu,\ f \in L^1(\mu)$ and $\|f\|_{\nu} : = \int_{\Omega} |f|\ d\nu,\ f \in L^1 (\nu).$ Is there any necessary and sufficient condition for the normed linear spaces $(L^1(\mu),\|\cdot\|_{\mu})$ and $(L^1(\nu),\|\cdot\|_{\nu})$ to be isometrically isomorphic? What I have found is as follows $:$ If $\nu \lt \lt \mu$ (or $\mu \lt \lt \nu$ ) and if the corresponding Radon-Nikodym derivative $\frac {d\nu} {d\mu} = \alpha$ (say) be such that $\alpha \gt 0$ and $\alpha \in [c,C]$ for some $0 \lt c \lt C$ a.e. $\mu$ (and hence a.e. $\nu$ ) then $L^1(\mu) = L^1 (\nu)$ and the map $f \mapsto \frac {f} {\alpha}$ gives the required isometric isomorphism from $(L^1(\mu),\|\cdot\|_{\mu})$ to $(L^1(\nu),\|\cdot\|_{\nu}).$ So the above gives a sufficient condition for the two normed linear spaces to be isometrically isomorphic. I have also found a weaker converse of the above result which is as follows $:$ If $L^1(\mu) = L^1(\nu)$ and the normed linear spaces $(L^1(\mu),\|\cdot\|_{\mu})$ and $(L^1(\nu),\|\cdot\|_{\nu})$ are isometrically isomorphic then $\nu$ is absolutely continuous with respect to $\mu$ and vice-versa and the corresponding Radon-Nikodym derivative is bounded by $[c,C]$ a.e. $\mu$ (resp. $\nu$ ) for some $0 \lt c \lt C.$ How do I proceed if $L^1(\mu) \neq L^1(\nu)\ $ ? Any help in this regard will be appreciated. Thanks for your time.","['measure-theory', 'normed-spaces', 'vector-space-isomorphism', 'functional-analysis', 'isometry']"
3956309,sine vs Sine: understanding the differences,"I was using the textbook A History in Mathematics by Victor J. Katz. I saw a theorem from Nasir al-Din al-Tusi. The way the theorem is written in the book is like this: In any plane triangle, the ratio of the sides is equal to the ratio of the sines of the angles opposite to those sides. That is, in triangle ABC, we have AB:AC=sin(angle ACB):sin (angle ABC). [Note that since we are considering a ratio it is irrelevant whether we use Sines or sines.) This theorem is about the law of sines. My question is about the last sentence in parenthesis. What is the difference between Sine and sine?","['geometry', 'reference-request', 'notation', 'trigonometry', 'terminology']"
3956327,Specific expectation of non-negative random variable,"Let $T$ a random variable of non-negative integers. Suppose that there is $n \in \mathbb{N}$ and there is $\alpha>0$ such that for all $k \in \mathbb{N}$ we have $$\mathbb{P}(T >kn) \le (1-\alpha)^k.$$ Prove that $\mathbb{E}[T] \le \frac{n}{\alpha}$ . I tried to use the sum formula for expectation of nonnegative integer random variables $$\mathbb{E}[T] = \sum_{i \ge 0}{\mathbb{P}(T > i)},$$ but I can't get a ' $\le$ ' innequalty.","['markov-chains', 'expected-value', 'probability-theory', 'probability', 'random-variables']"
3956362,Find all entire functions $f$ such that $|f|$ is harmonic.,"I'm trying to find all entire functions $f$ such that $|f|$ is harmonic. My attempt is as follows. Because $f$ is entire, we may write $f(z) = f(x + iy) = u(x,y) + iv(x,y)$ where $u$ and $v$ have continuous first-order partial derivatives and satisfy the Cauchy-Riemann equations. Furthermore, $u$ and $v$ are harmonic. Now $|f| = \sqrt{u^2 + v^2}$ so I thought maybe to look at $|f|^2$ first. Then, $$(|f|^2)_{xx} = 2(u_x)^2 + 2(v_x)^2 + 2(u\cdot u_{xx} + v \cdot v_{xx})$$ and $$(|f|^2)_{yy} = 2(u_y)^2 + 2(v_y)^2 + 2(u\cdot u_{yy} + v \cdot v_{yy}).$$ I need $(|f|^2)_{xx} + (|f|^2)_{yy} = 0$ in order for $|f|^2$ to be harmonic. So adding these equations and using that $u$ and $v$ are harmonic, I obtain $$(u_x)^2 + (u_y)^2 + (v_x)^2 + (v_y)^2 = 0.$$ By the Cauchy-Riemann equations, I can simplify this to $$(u_x)^2 + (v_x)^2 = 0.$$ I'm a little stuck on how to proceed from here. I want to somehow conclude $|f|^2$ is constant but I'm not sure how.","['complex-analysis', 'harmonic-functions']"
3956366,"$C^1[0,1]$ is not banach using the closed graph theory","Show that $C^1[0,1]$ is not a banach space using the closed graph theory with the maximum norm.
First, look at the derivative operator: $D:C^1[0,1]\to C[0,1]$ , $D(f)=f'$ . We can check that $D$ is linear and not bounded (by taking an example such as a polynomial $x^{n+1}$ ).
Thus $D$ is not continuos.
I'm not sure, if it is possible to show that $D$ has a closed graph (a linear map $T:X\to Y$ has a closed graph if $x_n\subset X$ such that $x_n\to x$ and $T_{x_n}\to y$ then $Tx=y$ ).So if by contradiction, we assume that $C^1[0,1]$ is banach with the sup norm, then get by the closed graph theory  that $D$ is continuos, which is not true according to what we've said.","['banach-spaces', 'functional-analysis', 'closed-graph']"
3956392,Struggling with intuition about this probability question. Symmetry argument of two balls drawn from an urn.,"So the question is as follows: An urn contains m red balls and n blue balls. Two balls are drawn uniformly at random
from the urn, without replacement. (a) What is the probability that the first ball drawn is red? (b) What is the probability that the second ball drawn is red?* The answer to a) quite clearly works out to be $\frac{m}{(m+n)}$ , but the answer to b turns out to be the same, and my tutor said this is intuitive by a symmetry argument. i.e. that $P(A_1)$ = $P(A_2)$ where $A_i$ is the event that a red ball is drawn on the ith turn. However I am struggling to see how this is evident, can anyone explain this?","['polya-urn-model', 'intuition', 'probability']"
3956396,Need help to check alternating series criterion,"I know this is simple calculation based question but I got stuck: I want to check convergence of the following series: $$1-\frac{1}{2}(1+\frac{1}{3})+\frac{1}{3}(1+\frac{1}{3}+\frac{1}{5})-\cdots$$ Clearly this is alternating series. So I need satisfy alternating series criterion. That means I need to show that its terms are decreasing monotonically. Let $a_n=\frac{1}{n}(1+ \frac{1}{3}+\frac{1}{5}+\cdots+\frac{1}{2n-1})$ and $a_{n+1}=\frac{1}{n+1}(1+ \frac{1}{3}+\frac{1}{5}+\cdots+\frac{1}{2n+1})$ . I just have to show $a_n-a_{n+1}>0$ but right here I got stuck because of the presence of the first factor. I think i am missing a simple trick here. Anyway, I got $$a_n-a_{n+1}=(\frac{1}{n}-\frac{1}{n+1})+\frac{1}{3}(\frac{1}{n}-\frac{1}{n+1})+\cdots+\frac{1}{2n-1}(\frac{1}{n}-\frac{1}{n+1}) {-\color{red}{\frac{1}{(2n+1)(n+1)}}}.$$ The last red color term making problem. May be ratio test help as well ? Any help please","['convergence-divergence', 'sequences-and-series']"
3956485,"Is this a relation of equivalence? $R := \{(x,y) \in \mathbb{R} \times \mathbb{R} ; \sin(x)=\sin(y)\}$","We have to prove reflexivity, symmetry, and transitivity. $1.)$ Reflexivity: If our relation is reflexive we know that if $(x,y)\in R$ then $(x,x)\in R$ $(x,x)\in R \to \sin(x)=\sin(x)$ which is true. Out relation is reflexive. $2.)$ Symmetry: If our relation is symmetric we know that if $(x,y)\in R$ then $(y,x)\in R$ $(y,x)\in R \to \sin(y)=\sin(x)$ which is the same as our original relation: $\sin(x)=\sin(y)$ $3.)$ Transitivity: If our relation is symmetric we know that if $(x,y) \in R \land (y,z) \in R$ then $(x,z) \in R$ $(x,y) \in R \to \sin(x)=\sin(y)$ $(y,z) \in R \to \sin(y)=\sin(z)$ $\sin(x)=\sin(y) \land \sin(y)=\sin(z) \to \sin(x)=\sin(z)$ Which ios what we wanted to prove. So $R$ is an equivalent relation on $\mathbb{R} \times \mathbb{R}$","['equivalence-relations', 'trigonometry', 'solution-verification']"
3956526,Average number of strings with edit distance at most 3 (larger alphabet),"Consider a string of length $n \geq 3$ over an alphabet $\{1,\dots, \sigma\}$ .   An edit operation is a single symbol insert, deletion or substitution.  The edit distance between two strings is the minimum number of edit operations needed to transform one string into the other one.  Given a string $S$ of length $n$ with $S_i \in \{1,\dots, \sigma\}$ , my question relates to the number of distinct strings which are edit distance at most $3$ from $S$ . Let us write $g_{k, \sigma}(S)$ for the number of distinct strings over the alphabet $\{1,\dots, \sigma\}$ which are edit distance at most $k$ from $S$ , i.e. $g_{k,\sigma}(S) = |\{S' : d(S', S) \leq k\}|$ where $d(-,-)$ is the edit distance. Let $X_n$ be a random variable representing a random string over the alphabet $\{1,\dots, \sigma\}$ of length $n$ , with the symbols chosen uniformly and independently. This leads directly to my question: Let $X_n$ be a random variable representing a random string of
length $n$ , with the symbols chosen uniformly and independently.  What is: $$\mathbb{E}(g_{3, \sigma}(X_n))\;?$$ For $\sigma=2$ we can get an explicit formula $(40+6n-4n^2)/2^n-83/2+(331/12)n-6n^2+(2/3)n^3$ . So my question is, what does the dependency on the alphabet size $\sigma$ look like?","['combinatorics-on-words', 'combinatorics']"
3956531,"Proof by induction, $2^{n} > n^{2} - 2$","So I have to proof that $2^{n} > n^{2} - 2$ for $n > 2$ , using mathematical induction. I start of with the ""basecase"" for n = 3: RHS: $2^{3} = 8$ , LHS: $3^{2} - 2 = 7$ Clearly, the inequality is correct in this case. I assume that the inequality is true for $\forall n = k$ where $k \in \mathbb{Z}^{+}$ .
To prove this inequality, we have to proof that it holds for n = k + 1. $2^{k} > k^{2} - 2$ We multiply both sides with 2: $2^{k+1} > 2(k^{2} - 2)$ $2^{k+1} > 2k^{2} - 4$ $2^{k+1} > k^{2} + k^{2} - 2 - 2$ According to our assumption, $2^{k} > k^{2} - 2 $ , hence $2^{k+1} > k^{2} - 2 $ Because $k^{2} - 2 \geq 2k + 1 $ for $k > 2 $ , we get: $2^{k+1} > k^{2} + 2k + 1 - 2$ Thus: $2^{k+1} > (k+1)^{2} - 2$ QED. How does my proof look, does it have any deficits, and how would you prove it? Thank you!","['induction', 'discrete-mathematics']"
3956534,"If $\mu$ is a finite measure on a metric space, then for all $\varepsilon$, there is a $\delta<\delta$ with $\mu(\partial B_\delta(x))=0$","The following should be rather elementary, but since I never found a result of this kind in the literature and I never thought about this before, I wonder whether I'm missing something or not. First of all, I claim the following: Claim 1 : Let $(E,\mathcal E,\mu)$ be a measure space; $\mathcal A\subseteq\mathcal E$ be disjoint; $B\in\mathcal E$ with $\biguplus\mathcal A\subseteq B$ and > $\mu(B)<\infty$ . Then $(\mu(A))_{A\in\mathcal A}$ is summable and $$\sum_{A\in\mathcal A}\mu(A)\le\mu(B)\tag1.$$ Proof : Since $\mathcal A$ is disjoint, $$\sum_{A\in\mathcal F}\mu(A)=\mu\left(\biguplus\mathcal F\right)\le\mu(B)<\infty\tag2$$ for all countable $\mathcal F\subseteq\mathcal A$ and hence, since $\mu$ is nonnegative, $(\mu(A))_{A\in\mathcal A}$ is summable with $$\sum_{A\in\mathcal A}\mu(A)=\sup_{\substack{\mathcal F\subseteq\mathcal A\\\mathcal F\text{ is finite}}}\sum_{A\in\mathcal F}\mu(A)\le\mu(B)\tag3.$$ Now I would like to use Claim 1 to conclude the following: Claim 2 : Let $E$ be a metric space, $\mu$ be a finite signed measure on $\mathcal B(E)$ and $x\in E$ . Then, $$\forall\varepsilon>0:\exists\delta\in(0,\varepsilon]:|\mu|(\partial B_\delta(x))=0\tag4.$$ Proof : Let $\varepsilon>0$ . Then, $$\biguplus_{\delta\in(0,\:\varepsilon)}\partial B_\delta(x)=B_\varepsilon(x)\setminus\{x\}\tag5$$ and hence, since $|\mu|$ is finite, $(\mu(\partial B_\delta(x)))_{\delta\in(0,\:\varepsilon)}$ is summable by Claim 1. Thus, $$\left\{\delta\in(0,\varepsilon):\mu(\partial B_\delta(x))\ne0\right\}\tag6$$ is countable. This immediately yields the claim.","['measure-theory', 'probability-theory', 'summability-theory']"
3956661,Integer Linear Programming Conditional Constraints,"How can I create a constraint that reflects the following: if $x_{ij} = 1$ AND $x_{jk} = 1$ THEN $x_{ik} = 1$ ? All my variables $x_{ij}$ are binary. To provide some context: I'm trying to create a linear equation system to be solved via the simplex algorithm that provides a solution to the problems schools face when creating class groups. Each student chooses 5 other students that he would like to be with in the following year. The school promises that each student will be in a class with at least one of the students they chose. To create the equation system I decided that my variables will be boolean and represent the following: $x_{ij} = 1$ if student $i$ is with student $j$ and $x_{ij} = 0$ otherwise. Thus, $x_{ij}= x_{ji}$ and $x_{ii} = 1$ . However, I'm having trouble with the following constraint: if student $i$ is together with student $j$ and student $j$ is together with student $k$ , then inevitably student $i$ will be together with student $k$ . This is represented by the constraint I mentioned at the beginning of the question. I tried using the big M approach as mentioned in other questions but to no avail. In these questions there was only one condition but I have two. Even if I solve this problem, how can this be scalable? For example: if $x_{12} = x_{23} = x_{14} = 1$ then $x_{13} = x_{34} = x_{24} = 1$ . Maybe the variables I chose are not correct and I'm overcomplicating things. If this is the case, any guidance in the right direction would be more than welcomed. Thanks for the help in advance!","['linear-algebra', 'integer-programming', 'linear-programming']"
3956698,Looking for a proof of two combinatorial summation identities,"While working on a problem I came across the following similar combinatorial identities valid by numerical evidence $(n\ge m)$ : $$\begin{align}
A(n,m)&\equiv\sum_{k\ge1}\binom km\binom{n-1}{k-1}=2^{n-m-1}\binom nm\frac{n+m}{n},\\
B(n,m)&\equiv\sum_{k\ge1}\left[\binom{\left\lfloor\frac k2\right\rfloor}m
+\binom{\left\lceil\frac k2\right\rceil}m\right]\binom{n-1}{k-1}=2^{n-2m}\binom {n-m}{m-1}\frac{n+1}{m}.
\end{align}$$ I am looking for an algebraic proof of these identities. Is there a smart way to prove: $$
B(n,m)=A(n-m+1,m)
$$ without explicit evaluation of the sums?","['summation', 'binomial-coefficients', 'combinatorics']"
3956738,"Cannot understand why cosine similarity is calculated as $\cos(u,v) = 1 - \frac{u\cdot v}{\|u\|_2 \cdot \|v\|_2}$","I am reading this article (PDF via arXiv.org) . At page 3 of the PDF, right column, under section 3.2 ""Quantifying Bias Removal"", there is a formula to calculate the cosine distance between two vectors: $$\cos(\mathbf{u},\mathbf{v}) = 1 - \dfrac{\mathbf{u} \cdot \mathbf{v}}{\|u\|_2 \cdot \|v\|_2} \tag1$$ But I thought that in an Euclidean space: $$\mathbf{u} \cdot \mathbf{v} = \|u\|_2 \cdot \|v\|_2 \cdot \cos(\theta) \tag2$$ So the right hand side of $(1)$ would be $ 1-\cos(\theta) $ and not $\cos(\theta)$ .","['euclidean-geometry', 'inner-products', 'normed-spaces', 'vector-spaces', 'trigonometry']"
3956798,Determinants of matrices defined by the minimum/maximum indices of their entries,"$
\newcommand{\m}[1]{\left( \begin{matrix} #1 \end{matrix} \right)}
$ The Problem: Consider the matrices $A_n := \left(a^{(n)}_{i,j}\right)_{1 \le i,j \le n},B_n := \left(b^{(n)}_{i,j}\right)_{1 \le i,j \le n} \in M_{n \times n}(\Bbb R)$ with entries defined as follows: $$a^{(n)}_{i,j} := \min \{i,j\} \qquad b^{(n)}_{i,j} := \max \{i,j\}$$ (Examples of these matrices follow momentarily, to show how the structure of each ""evolves"" and emerges as $n$ increases.) What are $\det(A_n)$ and $\det(B_n)$ in the general $n \times n$ case, for each $n \in \Bbb Z^+$ ? Background/Context: I happened to have a question similar to this on my linear algebra final a few weeks ago. (In full disclosure: final grades have already been determined and all that, so this isn't any longer an ""active"" test question.) However, that problem used a matrix similar to $A_n$ , without specific numbers, and only the $4 \times 4$ case. I then recently found a video by Dr. Peyam which considered the $5 \times 5$ cases for both $A_n$ and $B_n$ , and hinted that these possibly came from a Putnam exam. I'm not sure if it was, though. I looked back through all of the Putnam problems back to $1985$ and didn't see this exact one, though one was similar: $A2$ from $2014$ , where $A_n$ is instead defined by $a^{(n)}_{i,j} = 1/\min\{i,j\}$ . (Maybe I'll look at that some other time.) I imagine the definition for $B_n$ is just considered a natural generalization of this problem. In any event, I couldn't find this problem handled in its generality on MSE, so I figured I'd try to figure it out, and post my own solution. Of course, if you have your own solutions, they're greatly welcomed! Each can provide their own insights. Small Cases for the Matrices: To help show the structure of the matrices, $A_n$ and $B_n$ look like, in the cases for $n=1,2,\cdots,6$ , as follows. Determinants are included, but calculated by Wolfram. \begin{alignat*}{3}
&\boxed{n=1} &&\qquad A_1 = \m{
1  }  &&\qquad \det(A_1) = 1\\
& &&\qquad B_1 = \m{
1 }
&&\qquad \det(B_1) = 1\\
&\boxed{n=2} &&\qquad A_2 = \m{
1 & 1 \\
1 & 2  } 
&&\qquad \det(A_2) = 1\\
& &&\qquad B_2 = \m{
1 & 2    \\
2 & 2   }
&&\qquad \det(B_2) = -2\\
&\boxed{n=3} &&\qquad A_3 = \m{
1 & 1 & 1 \\
1 & 2 & 2 \\
1 & 2 & 3 } 
&&\qquad \det(A_3) = 1\\
& &&\qquad B_3 = \m{
1 & 2 & 3   \\
2 & 2 & 3  \\
3 & 3 & 3  }
&&\qquad \det(B_3) = 3\\
&\boxed{n=4} &&\qquad A_4 = \m{
1 & 1 & 1 & 1 \\
1 & 2 & 2 & 2 \\
1 & 2 & 3 & 3 \\
1 & 2 & 3 & 4 } 
&&\qquad \det(A_4) = 1\\
& &&\qquad B_4 = \m{
1 & 2 & 3 & 4  \\
2 & 2 & 3 & 4 \\
3 & 3 & 3 & 4   \\
4 & 4 & 4 & 4  }
&&\qquad \det(B_4) = -4\\
&\boxed{n=5} &&\qquad A_5 = \m{
1 & 1 & 1 & 1 & 1 \\
1 & 2 & 2 & 2 & 2 \\
1 & 2 & 3 & 3 & 3 \\
1 & 2 & 3 & 4 & 4 \\
1 & 2 & 3 & 4 & 5 } 
&&\qquad \det(A_5) = 1\\
& &&\qquad B_5 = \m{
1 & 2 & 3 & 4 & 5  \\
2 & 2 & 3 & 4 & 5 \\
3 & 3 & 3 & 4 & 5  \\
4 & 4 & 4 & 4 & 5 \\
5 & 5 & 5 & 5 & 5 }
&&\qquad \det(B_5) = 5\\
&\boxed{n=6} &&\qquad A_6 = \m{
1 & 1 & 1 & 1 & 1 & 1\\
1 & 2 & 2 & 2 & 2 & 2\\
1 & 2 & 3 & 3 & 3 & 3\\
1 & 2 & 3 & 4 & 4 & 4\\
1 & 2 & 3 & 4 & 5 & 5\\
1 & 2 & 3 & 4 & 5 & 6} 
&&\qquad \det(A_6) = 1\\
& &&\qquad B_6 = \m{
1 & 2 & 3 & 4 & 5 & 6 \\
2 & 2 & 3 & 4 & 5 & 6\\
3 & 3 & 3 & 4 & 5 & 6 \\
4 & 4 & 4 & 4 & 5 & 6 \\
5 & 5 & 5 & 5 & 5 & 6 \\
6 & 6 & 6 & 6 & 6 & 6}
&&\qquad \det(B_6) = -6
\end{alignat*} One reasonably conjectures that $\det(A_n) = 1$ for all $n$ and $\det(B_n) = (-1)^{n-1} n$ for all $n$ .","['matrices', 'determinant', 'linear-algebra', 'alternative-proof']"
3956810,Prove by induction floor and ceiling,I couldn't solve below question ... I was able to start the solution .. but I couldn't turn left side to be same as write side in the inductive step:,"['induction', 'discrete-mathematics', 'ceiling-and-floor-functions']"
3956821,Integrating Dirac Delta Gives Two Different Answers,"I am trying to solve the following differential equation $$\frac{dx}{dt} = x \delta(t-\tfrac{1}{2})$$ from $t=0$ to $t=1$ where $\delta$ denotes the typical Dirac function. If I separate variables and integrate, I get $$ \int_{x_0}^{x_t} \frac{1}{x} dx = \int_0^t \delta (\tau-\tfrac{1}{2}) d\tau$$ leading to $$ \ln (x_t) - \ln(x_0) = \begin{cases} 0, & t \leq 1/2 \\ 1, & t > 1/2 \end{cases} $$ On the other hand, if I rewrite the original equation as $$ \int_{x_0}^{x_t} dx = \int_0^t x(\tau) \delta (\tau-\tfrac{1}{2}) d \tau$$ and simply apply the definition of the Dirac function, I get $$ x_t - x_0 = \begin{cases} 0, & t \leq 1/2 \\ x\left(\tfrac{1}{2}\right), &t > 1/2 \end{cases} $$ Why do I get two different answers? Is either of these right or is the original equation ill-defined in some sense ... perhaps the Radon-Nikodym derivative does not exist since the LHS is wrt to Lebesgue and the RHS is wrt Dirac? Thanks in advance!","['integration', 'measure-theory', 'dirac-delta', 'radon-nikodym']"
3956827,Does $x^{x} = \sum\limits_{n=0}^{\infty}\frac{x^n \ln(x)^n}{n!}$ converges uniformly for $x = 0$?,"For this exercise we can use that $e^x = \sum\limits_{n=0}^{\infty}\frac{x^n}{n!}$ converges uniformly in all limited subset of $\mathbb{R}$ and have to show that $x^{x} = \sum\limits_{n=0}^{\infty}\frac{x^n \ln(x)^n}{n!}$ converges uniformly for all $x \in [0,1]$ . I can show that it converges uniformly for all $x \in (0,1)$ by Dirichlet Test and $x=1$ by particular case, but I don't know if it is really true for $x = 0$ . Is it possible to converge uniformly even having $ln(0)$ not existing? (As for $0^0$ , we have a note saying to consider that as $1$ ). Also, the next question is to show that $\int _0^1 \! x^x \, \mathrm{d}x = \sum\limits_{n=0}^{\infty} \frac{1}{n!}\int _0^1\! {x^n\ln(x)^n} \, \mathrm{d}x$ . This would be easy if I had uniform convergence for $x = 0$ , because I could use a Theorem that says that I can interchange sum and integral when convergence is uniform for all $x$ in integral limits.","['analysis', 'real-analysis', 'calculus', 'uniform-convergence', 'sequences-and-series']"
3956874,Do people agree on what dx is in Riemann integration?,"I've been rather curious about what the official rigorous understanding of the dx term in a Riemann integral is. Of course, we could use the formal definition of a Riemann integral but I have seen on Wikipedia other proposed ways of defining the differential of some function (we'll call x), dx. The classic high school teacher approach is to say it's a ""very small change in x"", or rather a small change in a linear approximation of x. However, as someone who studies differential geometry, I am wondering how this can be interpreted as the exterior derivative of a function x, in which dx is a 1-form. Do we then reinterpret $\int{f(x)}\,dx$ as being the integral of a 1-form? And how then can we consider a 1-form to be a ""small change in x""?","['integration', 'riemann-integration', 'differential', 'differential-geometry']"
3957022,Random Walk Probability in a Circle,"Consider a circular arrangement of 8 people as shown below: Let's say person 1 has a candy which is passed around with equal probability either to the left or right. All the other people do the same. a) Find the probability that the person 3 gets the candy before person 6. b) Find the expected number of times the candy will be passed before the person 5 gets it for the first time. For a) I could just break the circle between 3 and 4 and consider them siting in a straight line as, $3\hspace{10pt}2\hspace{10pt}1\hspace{10pt}8\hspace{10pt}7\hspace{10pt}6$ Now how do I go about calculating the probability? Do I take different cases? I think using conditional probability I could get some recurrence relation. Not sure how to go about b).
Any help is appreciated. Thanks!","['random-walk', 'probability']"
3957023,Convergence of the recursive sequence $x_{n+1} = \frac{1}{4-x_n}$,"I'm doing exercise 2.4.1 in the book Understanding Analysis by Stephen Abbott. I'd like to ask, if my proof is rigorous and technically correct. (a) Prove that the sequence defined by $x_1 = 3$ and \begin{align*}
    x_{n+1} = \frac{1}{4 - x_n}
\end{align*} converges. (b) Now that we know $\lim x_n$ exists, explain why $\lim x_{n+1}$ must also exist and equal the same value. (c) Take the limit of each side of the recursive equation in part (a) to explicitly compute the $\lim x_n$ . Proof. (a) By direct computation, we find that $x_1 = 3$ , $x_2 = 1$ . Let us prove that $(x_n)$ is a decreasing sequence, that is $x_{n+1} < x_{n}$ for all $n \in \mathbf{N}$ . This is true for $n=1$ . By induction, let's assume that $x_{k+1} < x_k$ . Therefore, \begin{align*}
	x_{k+1} &< x_{k} \implies \frac{1}{4 - x_{k+1}} < \frac{1}{4 - x_k} \implies x_{k+2} < x_{k+1}
\end{align*} So, $(x_{n})$ is a monotonically decreasing sequence. Moreover, we can show that $(x_n)$ is bounded. We are interested to show that $x_n > 0$ for all $n \in \mathbf{N}$ . This holds for $n=1$ . Assume that $x_k > 0$ , then \begin{align*}
	x_{k+1} = \frac{1}{4 - x_k} > \frac{1}{4} > 0
\end{align*} Thus, the sequence $(x_n)$ has a lower bound $0$ . By the Monotone Convergence Theorem, the sequence $(x_n)$ converges. (b) The sequence $(x_{n+1})=x_2,x_3,x_4,\ldots$ also converges and has the same limiting value because the $1$ -tail of $(x_n)$ is a (i) monotonically decreasing sequence (ii) has the same lower bound $0$ . It is the infinite tail of the sequence, that ultimately determines the convergence of a sequence. (c) We have: \begin{align*}
	\lim (x_n) &= \frac{1}{4 - \lim x_{n+1}}\\
	L &= \frac{1}{4 - L} \\
	4L - L^2 &= 1\\
	L^2 - 4L + 1 &= 0\\
	(L - 2)^2 - 3 &= 0\\
	L&= 2 \pm \sqrt{3}
\end{align*} As $0 < L < 1$ , we have $L = 2 - \sqrt{3}$ .","['solution-verification', 'sequences-and-series', 'real-analysis']"
3957030,Solutions of $2^{1978}(1+2^{4a-2030})=y(y+1)$,"I am given that $a,y$ positive integers and $$2^{1978}(1+2^{4a-2030})=y(y+1).$$ I want to maximize $a$ . I guessed that $a$ is maximized when $2^{1978}=y$ and hence $4a-2030=1978\implies a =1002$ . However, there is the other case of when a factor of $1+2^{4a-2030}$ is ""contained"" in $2^{1978}$ , that is: $(2^{1978}x, \frac{1+2^{4a-2030}}{x}) = (y,y+1) \text{ or }=(y+1,y)$ . I have proven for the $(y,y+1)$ case that $2^{4a-30} \ge 2^{1978}x^2$ which imply that there may be infinite solutions and so there is no maximum.","['contest-math', 'number-theory', 'majorization', 'elementary-number-theory']"
3957054,Prove relation about area of triangle,"In the below picture, angle A is obtuse, AD is a median.
We are also given the relation $AB^2 = AF*AC$ .
We want to prove that area of triangle $(ABC) = AB*AD$ . What I have tried: Area of triangle is $A = \frac {1}{2}*AC*BF$ . Replacing AC from the given relation $AB^2 = AF*AC$ , we get $A = \frac {1}{2}*\frac{AB^2*BF}{AF}$ . Also from Pythagoras, we replace $AB^2$ with $BF^2+AF^2$ . But I can't see how to involve AD and prove the required relation! Any help please?",['geometry']
3957100,$\lim_{y \to 0^{+}} \int_{0}^{\infty} e^{-yx} \frac{\sin x}{x} dx = \frac{\pi}{2}$,"I have shown using the application of Dominated Convergence Theorem (i.e., interchange of differentiation and integral) that $$
\int_{0}^{\infty} e^{-yx} \frac{\sin x}{x} dx = \frac{\pi}{2}-\tan^{-1}y
$$ for $(x,y) \in [0,\infty) \times (0,\infty)$ . Now I want to conclude that $$
\int_{0}^{\infty} \frac{\sin x}{x} dx =\int_{0}^{\infty} \lim_{y \to 0+}e^{-yx} \frac{\sin x}{x} dx =\lim_{y \to 0+}\int_{0}^{\infty} e^{-yx} \frac{\sin x}{x} dx = \lim_{y \to 0+} \frac{\pi}{2}-\tan^{-1}y =  \frac{\pi}{2}
$$ (The hint which is given with this part is to use DCT.) To interchange the limit and the integral sign, using DCT, I need to find a non-negative function $g$ which dominates $ |(e^{-yx}\sin x) /x|$ and is integrable, i.e., $g \in L^{1}([0,\infty))$ . The only function I could think of is (obviously) $|\sin x/x|$ . But I don't know whether $|\sin x/x|$ is integrable.","['limits', 'measure-theory', 'lebesgue-measure', 'lebesgue-integral']"
3957126,partial fractions when the fraction cannot be decomposed,"I am trying to find partial fractions of $\frac {1}{(x^2+1)^2}$ . All the coefficients I get are zeros except the coefficient for the constant term which is 1, leaving me with the fraction I started with, so it seems like the fraction cannot be decomposed. How can I then go about writing this fraction as the sum $\frac {1}{2}\left [\frac {1}{x^2+1}-\frac{x^2-1}{(x^2+1)^2}\right]$ ? Is it just manipulation and trial and error?","['calculus', 'algebra-precalculus']"
3957127,"If p, q, r are the roots of $x^3-6x^2+3x+1=0$ determine the possible values of $p^2q+q^2r+pr^2$. [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question If p, q, r are the roots of $x^3-6x^2+3x+1=0$ determine the possible values of $p^2q+q^2r+pr^2$ . I tried to solve this problem through Vieta's relations but I did not find a way that allows not to use the cubic formula.
I found this question on Pathfinder of Olympiad Mathematics and I have been struggling for a week without getting anywhere.","['cubics', 'algebra-precalculus', 'roots', 'polynomials']"
3957179,Analyzing the Coefficient of a generating function and its asymptotic,"The generating function $\sum_{n\geq 0} D(n) x^n = \frac{1}{\sqrt{1-6x+x^2}}$ is the gf of the Delannoy number. See last paragraph in https://en.wikipedia.org/wiki/Delannoy_number In this link, they mentioned that the coefficient of this gf  is $D(n) = \sum_{k=0}^{n} {n \choose k} { n+k \choose k}$ . My question is how can this coefficient be calculated/extracted from its gf.And how they conclude that it behaves asymptotically as ${\displaystyle D(n)={\frac {c\,\alpha ^{n}}{\sqrt {n}}}\,(1+O(n^{-1}))}$ where $\alpha =3+2{\sqrt {2}}\approx 5.828$ and $c=(4\pi (3{\sqrt {2}}-4))^{-1/2}\approx 0.5727$ . How to calculate/extract $D(n)$ from its gf and how to analyze it asymptotically then?
Is that possible to do that with a direct calculations? Edit I tried to find the asymptotic of the codfficidnt in the above gf this way: The gf has two poles: $r_1=3+\sqrt{8}$ , $r_2=3-\sqrt{8}$ . So the smallest/dominant pole is $r_2=3-\sqrt{8}$ .
We can write the gf as: $A(x)=1/ \sqrt{r_2-x} * 1/ \sqrt{r_1-x}$ Then A(x) behaves as: $1/ \sqrt {r_1-r_2} * 1/ \sqrt{r_2-x}=
1/ \sqrt {2 * 8^{1/4}} * \sum_{n\geq 0} {-1/2 \choose n} (-1)^n (r_1)^{n+1}x^n$ Here I used the expansion's formula  of $(1+x)^a$ for $a=-1/2$ and $x=-x/r_2$ .
So the coefficient behaves asymptotically as: $1/ \sqrt 2 * 1/ 8^{1/4} * (3+\sqrt 8)^{n+1/2} {-1/2 \choose n} (-1)^n$ . We can simplify it more, by using the asymptotic of ${-1/2 \choose n}$ . Is that approach fine?","['combinatorics', 'asymptotics', 'generating-functions']"
3957181,Evaluate $\lim\limits_{n \to \infty} nx_n.$,"Suppose $$x_2 \in \left(0,\frac{\pi}{2}\right), x_{n+1}=\left(1-\frac{1}{n}\right)\sin x_n(n \ge 2).$$ Evaluate $\lim\limits_{n \to \infty} nx_n.$ Note that $$x_{n+1}=\left(1-\frac{1}{n}\right)\sin x_n\le \sin x_n\le x_n,$$ and $$|x_{n+1}|=\left|\left(1-\frac{1}{n}\right)\sin x_n\right|\le 1,$$ it follows that $\{x_n\}$ converges. Therefore, we can readily obtain $x_n \to 0$ . As for the limit wanted, we can consider apply Stolz theorem . But it's too complicated.","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3957197,"Confusion about limits, specifically the definition of a limit","$$\lim_{x\to0}f(x)$$ The most common way to read this is ""limit of f(x) as x approaches 0"" . But the thing is, I find that there is a difference between these two limits for example $$\lim_{x\to\infty}\frac{x^2-1}{x^2+1} = 1$$ $$\lim_{x\to0}\frac{x}{5} = 0$$ Looking at the first one, technically speaking, the value won't actually ever hit 1. But it's converging to it. But with the second one, it does become 0, even though it's correct to say ""as x approaches 0, $\frac{x}{5}$ approaches 0"" , it's also correct to say ""as x approaches 0, $\frac{x}{5}$ will eventually equal 0"" . The latter statement doesn't sound so correct when you try to apply it with the first limit. This kind of confused me, and I was unable to find answers online, so for a while I made a deduction myself and kept in mind that ""yes, $\frac{x^2-1}{x^2+1}$ won't actually ever equal 1, but it will be infinitesmally close to it, to the point that this infinitesmally small distance doesn't matter, thus concluding that from a larger scale it's equal to 1"" . My question: is this interpretation correct? Graphing the function of the first limit shows this even better Edit: Sorry I edited the example because I realized the infinity limit is a bad a example!",['limits']
3957198,Compactness of a subset of $\ell^2$,"Let $K \subset \ell^2(\mathbb{N})$ be a set defined as follows: $$ K := \left\{x = (x_1, x_2, \dots) \in \ell^2(\mathbb{N}) \,|\, |x_n| \le \frac{1}{n}\right\}.$$ Since $\ell^2(\mathbb{N})$ is a reflexive space, we know that any sequence of $K$ , being bounded, admits a converging subsequence by the Eberlein-Smulian theorem. Moreover, since $K$ is closed, the weakly converging subsequence has a limit in $K$ , and thus $K$ is weakly sequentially compact. Since $(\ell^2(\mathbb{N}))^*$ is separable, we know that $\overline{B(0,1)}$ is metrizable for the weak topology and hence $K$ is not only weakly sequentially compact but compact for the weak topology. Is it compact for the strong topology as well?","['weak-topology', 'functional-analysis', 'compactness']"
3957218,Solving $\left(\sin\left(\sqrt{x}+5\right)-\cos\left(\sqrt{x}+5\right)\right)e^\sqrt{x}=0$,"I tried to solve the following problem; but I couldn't. $$\left(\;\sin\left(\sqrt{x}+5\right)-\cos\left(\sqrt{x}+5\right)\;\right)e^\sqrt{x}=0$$ I placed it into Microsoft Math Solver and the following was the answer: $$x=\frac{(-4\pi n_1+20-9\pi)^2}{16}, n_1\in Z$$ How do I solve it to reach the correct answer? My solution : $$\sin(\sqrt{x}+5)=\cos(\sqrt{x}+5)$$ $$\sqrt{x}+5=\pi n_1+\frac{\pi}{4}$$ And after solving it I obtained: $$x=\frac{(4\pi n_1-20+\pi)^2}{16}$$ My solution lacks the $9$ that there's in the correct answer. Am I doing something wrong?","['algebra-precalculus', 'trigonometry']"
3957302,"Assumption in prooving the Inverse Function Theorem (in Spivak's ""Calculus on manifolds"")","My question follows up with an additional remark from Spivak's proof of Inverse Function Theorem . The problem I have is the statement which immediately follows the If the theorem is true for $λ^{−1}∘f$ , it is clearly true for f... statement (from the link I've posted), in which Spivak assumes ""at the outset"" that $λ$ is the identity function, i.e. $λ=I$ , while $λ$ was clearly defined as $λ=Df(a)$ . How can he even assume this without loss of generality? He's basically limiting himself to functions $f$ such that $Df(a)=I$ . Did I get this wrong?","['multivariable-calculus', 'inverse-function-theorem']"
3957348,$a + bp^\frac{1}{3} + cp^\frac{2}{3} = 0$,"Q. If $a + bp^\frac{1}{3} + cp^\frac{2}{3} = 0$ , prove that $a = b = c = 0$ ( $a$ , $b$ , $c$ and $p$ are rational and $p$ is not a perfect cube.) My approach: Solving the quadratic, I get: $p^\frac{1}{3} = \dfrac{-b ± \sqrt{b^2 - 4ac}}{2c}$ Case 1: If the $b^2 - 4ac$ is a perfect square, I get the LHS as irrational and the RHS as rational, which is a contradiction. Case 2: If $b^2 - 4ac$ is not a perfect square, $b =  \pm \sqrt{b^2 - 4ac} - 2cp^\frac{1}{3}$ Here, the LHS is rational and the RHS is irrational, contradiction again. (Edit: The answer of @GNUSupporter has the proper proof.) So the equation is not quadratic and $c = 0$ . $a + bp^\frac{1}{3} = 0$ $-\dfrac{a}{b} = p^\frac{1}{3}$ This is a contradiction and hence $b = 0$ and $a = 0$ Is there any other way to solve this?","['real-numbers', 'number-theory', 'irrational-numbers']"
3957444,Is my solution correct in terms of proof? I can't prove directly that $f(x)=4$.,"Given $f:\mathbb{R}\rightarrow \mathbb{R}^+$ and the following conditions: $f(x+2)\cdot f(x+3)=16$ , $f(x)+f(-x)=8$ , we have to find integral $\int_{-8}^8 f(x-2019)dx$ . So, if we plug in $0$ , then $f(0)+f(0)=8$ . Therefore, $f(0)=4$ . Then plug in $-2$ in first equation,  we get $f(0)\cdot f(1)=16$ , therefore $f(1)=4$ , analogically plug $x=-1$ and I think that $f(x)=4$ , so answer will be $64$ (value after integrating). Is this correct? How can i prove it in a better manner?","['functional-equations', 'calculus', 'solution-verification']"
3957451,"Is $\mathbb{Z}[2x, 2x^2 , 2x^3 , \cdots ]$ noetherian","I am currently studying for my University's preliminary exam in Algebra. I have come across a problem that is practice. I hope I can get some feedback on my proof. Question: Consider the ring $\mathbb{Z}$ . Let $\mathbb{Z}[x]$ be the polynomial ring in one variable over $\mathbb{Z}$ . Define $T \subset \mathbb{Z}[x]$ by $T = \mathbb{Z}[2x, 2x^2 , 2x^3 , \cdots ]$ . Determine  whether  or  not $T$ is noetherian. Proof:
Consider $$\pi: \mathbb{Z}[x] \rightarrow \frac{\mathbb{Z}[x]}{2\mathbb{Z}[x]} \cong \mathbb{F}_2[x].$$ Note that $\pi(T) \subset \mathbb{F}_2$ . Suppose that, for some $n \geq 1$ : $$2x^{n + 1} = t_1 2x + t_2 2x^2 + \cdots + t_n 2x^n \quad \text{ for } t_i \in T.$$ Then in $\mathbb{Z}[x]$ we have that $x^{n + 1} = t_1 x + t_2 x^2 + \cdots + t_n x^n$ . By applying $\pi$ we get that $x^{n + 1} = c_1 x + c_2 x^2 + \cdots + c_n x^n$ for $c_i \in \mathbb{F}_2$ . This however is a contradiction, since the monomials $x^i$ are linearly independent over the field $\mathbb{F}_2$ .  Therefore, the ascending chain of ideals in $T$ defined by $$(2x) \subset (2x,2x^2) \subset (2x,2x^2,2x^3) \subset \cdots $$ does not stabilize and thus $T$ is not noetherian. Am I on the right track? If I am not, can I please have some hint's in the correct direction or let me know where in my proof I have failed.","['ring-theory', 'abstract-algebra', 'noetherian']"
3957454,Prove a symmetric complex matrix is non-singular,"As a compromise to this question , can we claim that the following symmetric complex matrix \begin{align*}
S = \begin{pmatrix}
0 & 1 + 2i & 1 + 3i & \cdots & 1 + ni \\
1 + 2i & 0 & 2 + 3i & \cdots & 2 + ni \\
1 + 3i & 2 + 3i & 0 & \cdots & 3 + n i \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 + ni & 2 + ni & 3 + ni & \cdots & 0
\end{pmatrix}
\end{align*} is non-singular? To clarify, the $(k, l)$ entry of $S$ is \begin{align*}
s_{kl} = \begin{cases}
k + il & l > k, \\
0      & l = k, \\
s_{lk} & k > l.
\end{cases}
\end{align*} Through some row/column reduction, I have shown that \begin{align*}
\det(S) = 
\begin{vmatrix}
0 & 1 + 2i & i & \cdots & i & i \\
1 + 2i & -2(1 + 2i) & 2 + 2i & & \\
i & 2 + 2i & -2(2 + 3i) & \ddots & \\
\vdots &   & \ddots & \ddots & \ddots & \\
i      &   &        & (n - 2) + (n - 2)i & -2[(n - 2) + (n - 1)i] & (n - 1)  + (n - 1)i \\
i      &   &        &                    & (n - 1) + (n - 1)i     & -2[(n - 1) + ni]
\end{vmatrix}. \tag{$*$}
\end{align*} Then I got stuck here. Is there any clever way to get around this? Or demonstrating the invertibility through other angles (say, linear independence or eigenvalues)? Result updates: Following @user8675309's tip, we can show by Levy-Desplanques theorem that the lower $(n - 1) \times (n - 1)$ submatrix of $(*)$ is non-singular, as it is row diagonally dominant. Thus $\mathrm{rank}(S) \geq n - 1$ . But the passage from $n - 1$ to $n$ seems quite difficult.","['determinant', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'symmetric-matrices']"
3957520,"Prove for some $n\in\mathbb{N}$ there are infinitely many primes $p$ , S.T the numbers $p-1,p+1,p+2$ have $n$ different prime factors .","Prove for some $n\in\mathbb{N}$ there are infinitely many primes $p$ , S.T the numbers $p-1,p+1,p+2$ have $n$ different prime factors . Attempt : by the fundamental theorem of arithmetic's we know that $$p-1=p_1^{a_1}...p_k^{a_n}$$ also $$p+1=q_1^{a_1}...q_k^{a_n}$$ $$p+2=w_1^{a_1}...w_k^{a_n}$$ Noticing that all the factorizations consists of $n$ different prime factors. I tried proving a stronger case with adding $p$ and its factorization to achieve 4 consecutive numbers. However that led me no where. I tried to solve it with the Chinese remainder theorem using the abstract idea that there is only one unique $x_0$ solution. Not sure how to continue with this idea.","['number-theory', 'prime-factorization', 'elementary-number-theory', 'prime-numbers']"
3957533,Are $\mathbb{N} $ $\times$ $\mathbb{Z}$ and $\mathbb{Z} $ $\times$ $\mathbb{Z}$ similar?,"In other words, my question is: Is there any order preserving bijection between $\mathbb{N} $ $\times$ $\mathbb{Z}$ and $\mathbb{Z} $ $\times$ $\mathbb{Z}$ , with antilexicographic order: $$ (a,b)<(c,d)⟺(b<d) \lor (b=d \land a<c) $$ (Two sets are similar if there exists a bijection between them which keeps the order in sets.) I know that $\mathbb{N} $ and $\mathbb{Z} $ are not similar, but still, I don't know what to do with this task...","['elementary-set-theory', 'order-theory']"
3957590,Is convergence itself necessary for Riemann´s rearrangement theorem?,"I have been studying series recently and I´ve gone through the proof of Riemann´s rearrangement theorem among other things. I was given the following related but different statement to prove as an exercise: A divergent series $\sum{a_k}$ has a convergent rearrangement if and only if the sum of the positive and negative terms diverge to $+\infty$ and $-\infty$ respectively and $\lim_{k\to \infty}{a_k}=0$ While trying to prove that the condition was sufficient I wondered: ""Can I not just appeal to Riemann´s rearrangement theorem?"" However it states that any conditionally convergent series can be rearranaged to converge to any real number or diverge. The statement I´m trying to prove assumes $\sum{a_k}$ diverges. From what I can tell however, in the proof of Riemann´s rearrangement theorem, the convergence itself of the series doesnt seem to be used to prove the theorem, but rather the fact that the sum of the positive and negative terms diverge to $+\infty/-\infty$ and that $\lim_{k\to \infty}{a_k}=0$ . So my question is: Is the convergence itself necessary to prove Riemann´s theorem?","['sequences-and-series', 'real-analysis']"
3957668,"Prove $A, B, C, D$ are $N(0,1)$ random variables","$A$ and $B$ are i.i.d RVs, assume $\mathbb{E}[A^2]$ exists, $\mathrm{var}{A}=1$ , and that MGF of $A$ exists near zero. $C=(A+B)/\sqrt{2}$ and $D=(A-B)/\sqrt{2}$ . Now prove that if. $C$ and $D$ are i.i.d., $A, B, C, D$ are $N(0,1)$ random variables. Basic computation got me to figure out that the expectation and variance of all four RVs are 0 and 1 respectively, and I also know that RVs that have an MGF such that $M(2s)=(M(s))^4$ have a normal distribution, but I am not sure how to proceed from there.","['moment-generating-functions', 'probability-distributions', 'normal-distribution', 'probability']"
3957701,"Showing that the maximum value of $\sin x+\sin y\sin z$, where $x+y+z=\pi$, is the golden ratio","Find the maximum of $$\sin x+\sin y\sin z$$ if $x+y+z=\pi$ . By using Lagrange multipliers, concluded that $y=z$ , further plug $x=\pi-2y$ , I've reduced the problem to single-variable expression. $$\sin^2 y+\sin(2y)$$ Then by taking first derivative and using formulas for $\sin(\arctan x)$ and $\cos(\arctan x)$ , finally we can obtain the maximum $$\frac{\sqrt5+1}{2}$$ As one can see this is precisely the golden ratio $\phi$ ! But this solution takes some time, so I'm interested in different no calculus solution of this problem, especially considering that it is related to the golden ratio.","['golden-ratio', 'lagrange-multiplier', 'multivariable-calculus', 'trigonometry']"
3957762,"Quaternion's multiplicative group as a subgroup of $\mathrm{GL}(4,\mathbb{R})$","Thinking about $\mathbb{C}$ : One can view the multiplicative group of complex numbers to be the matrices in $\mathrm{GL}(2,\mathbb{R})$ such that commutes with the matrix $I=\begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}$ a quick calculation shows that those are the matrix of the form $\begin{pmatrix} a & b \\ -b & a \end{pmatrix}$ . One can also view the quaternion's multiplicative group as the matrices in $\mathrm{GL}(2,\mathbb{C})$ that satisfies $IX=\bar{X}I$ the same calculation as above shows that those are the matrices of the form $\begin{pmatrix} a & b \\ -\bar{b} & \bar{a} \end{pmatrix}$ . How can i find a matrix that indentifies by a law of the form above the multiplicative group of $\mathbb{H}$ in $\mathrm{GL}(4;\mathbb{R})$ ? My attempts: I've tryed to use the fact that in the matrix representation of complex numbers the conjugation is the transpose operation together with the properties of block matrix under transposition and substituing in the complex matrices the 2x2 blocks that corresponds to the complexes entries, but i didn't succeded. If someone wants i can give more datails of my attempt. The candidate matrix was a the real-blocks matrix \begin{pmatrix} 0 & -I \\ I & 0 \end{pmatrix} but i am not sure it is enought. Any hint or suggestion please?","['matrices', 'abstract-algebra', 'linear-algebra', 'complex-numbers', 'quaternions']"
3957771,Ideal sheaf of a birational morphism arising from successive blowups,"Let $L\subset \mathbb C^3$ be the line defined by $x=y=0$ , and $p\in L$ the point defined by $x=y=z=0$ . Let's consider the blowup of $\mathbb C^3$ at $p$ and then blow up the strict transform of $L$ and denote the new space as $X$ . We can also consider blowup of $\mathbb C^3$ along $L$ and then blow up the preimage of $p$ and denote the new space as $Y$ . The two spaces are not the same because the fibers over $p$ are not Edited: The fibers of $X$ and $Y$ over $p$ are the same: On one side, it is the blowup a point on $\mathbb P^2$ , while on the other side, it can be viewed as a $\mathbb P^1$ -bundle over $\mathbb P^1$ . Question 1: Are $X$ and $Y$ isomorphic? According to Hartshorne II. Theorem 7.17, $$X\to \mathbb C^3$$ is a blowup of some ideal $I$ on $\mathbb C^3$ , and the same for $Y$ and we denote the corresponding ideal as $J$ . Question 2: How to determine the ideals $I$ and $J$ explicitly? It is elementary to check that both $I$ and $J$ are contained in the ideal $(x,y)$ of $L$ , reduced on $L\setminus \{p\}$ and non-reduced at $p$ (otherwise, they would be isomorphic to $Bl_{L}\mathbb C^3$ ), but they have different non-reduced structure at $p$ . $(x^2,y^2,xy,xz,yz)$ as Youngsu suggested is probably the first ideal to consider that is supported on $L$ and non-reduced only at $p$ , but currently, I can't determine it is $I$ or $J$ , or perhaps neither of them. How to find such $I$ and $J$ explicitly? Thanks in advance for any help.","['algebraic-geometry', 'blowup', 'commutative-algebra', 'birational-geometry']"
3957772,"Find multivariable limit: as $(x,y) \to (0,0)$ of $ \frac {x\sin y-y\sin x} {x^2+y^2}$","How do I evaluate the following limit? $$ \lim_{(x,y) \to (0,0)} \frac {x\sin y-y\sin x} {x^2+y^2}$$ So far I tested the limit along the paths in which $y=mx$ and I got zero. However I have no clue how I can prove the limit exists or find the limit's value.","['multivariable-calculus', 'limits', 'calculus', 'limits-without-lhopital']"
3957886,How to Understand the Domain of a Function,"Typically, a function $f: D \mapsto R$ is described as $$\forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right),$$ where $P$ is a predicate that specifies the relation between an input and the output, for instance, $y = 3x$ if $D \subseteq \mathbb{R}$ and $R \subseteq \mathbb{R}$ . However, this definition does not specify what happens outside $D$ . Should we explicitly specify that no element outside $D$ corresponds to an output under $f$ ? That is, should we use the following proposition $$\left(\forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right) \right) \wedge \left(\forall x \not\in {D}, \lnot \exists y, \left(x,y\right)\in f\right)$$ to describe $f$ ? My own understanding is as follows. In mathematical proofs, people are more concerned with the existence of such a function. That is, what happens outside $D$ does not matter. What matters is, such a function $f$ exists, so that the proof can move on. Specifically, when people talk about a function, they are saying: $$\exists f, \forall x \in D, \exists ! y \in R, \left(x,y\right) \in f \wedge P\left(x,y\right).$$ And they can proceed with a particular example of such a function. In such a circumstance, the information of existing $f$ s outside $D$ is not of interest.",['elementary-set-theory']
3957999,Need help understanding proof for probability of union for two events.,My book says that for any two events A and B $P(A \cup B) = P(A)+P(B)-P(A\cap B)$ The proof it provides is this: $$\def\P{\mathop{\rm P}}\begin{align}\P(A \cup B) &= \P(A \setminus B) + \P(A \cap B) + \P(B \setminus A) \\[1ex]&= \P(A \setminus B) + \P(A \cap B) + \P(B \setminus A) + \P(A\cap B) - \P(A\cap B) \\[1ex]&= \P(A)\hspace{16.5ex}+\P(B)\hspace{16.5ex}-\P(A\cap B)  \end{align}$$ My question is what happened to the $P(A\setminus B)$ and $P(B\setminus A)$ in the second line?,['probability']
3958074,What is the meaning of ⊊?,"I have encountered this when referencing subsets and vector subspaces. For example, T ⊊ span(S) should mean that T is smaller than span(S)--at least from what I've gathered. Is ⊊ a sort of ≤ or < but for subsets? What would that little crossing line mean? I have tried looking it up on the net but could not find an answer. Thank you.","['elementary-set-theory', 'notation', 'linear-algebra']"
3958085,Use Green's Theorem to Prove Change of Variable for Double Integral,"Question: Use Green's Theorem to prove: $$\iint_{R}dxdy=\iint_{S}\begin{vmatrix}\frac{\partial(x,y)}{\partial(u,v)}\end{vmatrix}dudv$$ $\Big(\frac{\partial(x,y)}{\partial(u,v)} $ is the Jacobian of the transformation $\Big)$ I found this question from the Stewart's Calculus Book. The question only states that $x=g(u,v)$ and $y=h(u,v)$ are the transformation (I suppose it is one-to-one, because in order to apply this, the transformation has to be one-to-one). Here comes the problem. Let C be a positively-oriented boundary curve of R (simple closed), and $Q=x ,P=0$ so that $\frac{\partial{Q}}{\partial{x}}-\frac{\partial{P}}{\partial{y}}=1$ and $S$ be the region of transformed R, then: \begin{align}
\iint_{R}dxdy&=\oint_CP \hspace{0.1cm}dx+Q\hspace{0.1cm}dy\\
&=\oint_Cx\hspace{0.1cm}dy\\
&=\oint_Cg(u,v)\,(h_udu+h_vdv)\\
&=\iint_Sg_uh_v+gh_{vu}-g_vh_u-gh_{uv}\;dA
\end{align} The result can be obtained if $h_{vu}=h_{uv}$ . However, it is not obvious to me that these are equal. Also, doing this way provides no information for the 'absolute' of the Jacobian. Can someone please point out my problems? Thank you. ADD ON: There has been no answer for three days..., I can't really think out of a solution on my own, I will appreciate a lot if someone answer me, thanks.","['greens-theorem', 'calculus', 'change-of-variable']"
3958187,Solving $2\log_2 (\log_2 x) + \log_{1/2} (\log_2 x) = 1$,"just looking for some help with the following: $$2\log_2 (\log_2 x) + \log_{1/2} (\log_2 x) = 1$$ I know how to solve a log equation with a single nested log that's $= 1$ or $0$ or some number, but I'm unsure of what to do when summing/ subtracting nested logs like these. If possible, a hint would be much more appreciated than the flat out answer. Thanks in advance to anyone who stops to help.","['algebra-precalculus', 'logarithms']"
3958299,reachability of the norm by the operator,"$A: \ell^1 \to \mathbb{R}$ , where $$Ax= \sum\limits_{k=0}^\infty((2+\cos(\pi(1/3)^{k+1})\xi_{k+1}).$$ \begin{aligned}
||Ax||_{\mathbb{R}} &= |Ax| = |(2+\cos(\pi(1/3))\xi_1) + (2+\cos(\pi(1/9))\xi_2)+(2+\cos(\pi(1/27))\xi_3) + \dots| \\
&\leq |(2+\cos(\pi(1/3))\xi_1)|+|(2+\cos(\pi(1/9))\xi_2)|+|(2+\cos(\pi(1/27))\xi_3)|+\dots \\
&\leq 3|\xi_1|+3|\xi_2|+3|\xi_3|+\dots \\
&=3||x||_{\ell^1}
\end{aligned} I have already shown the limit, but I can't prove that the norm is not reached.","['normed-spaces', 'functional-analysis']"
3958305,Algebra problem with isomorphism,"Let $G=(-1,1)$ and the binary operation  such that $x*y=\frac{x\sqrt{1-y^2}+y\sqrt{1-x^2}}{\sqrt{1-(xy)^2+2xy\sqrt{(1-x^2)(1-y^2)}}}$ .
Prove that (G,*) it is a isomorph group with the group (R,+).
I tried to find the bijective function $f:G\to R$ such that $f(x*y)=f(x)+f(y)$ but I could not.","['group-theory', 'functions', 'group-isomorphism']"
3958321,Identifying isomorphic graphs,"I'm having trouble solving this exercise I found about isomorphic graphs. It reads Among the following graphs, which pairs are isomorphic? For each pair that are isomorphic, describe an isomorphism (bijection of vertices preserving adjacency) between them. For each pair that are not isomorphic, give a property preserved under isomorphism that one graph has but the other graph does not. I've been referencing the vertices and counting the cycles but I don't know if that's all there is to it. I know that a, b and d have vertices that line up well, but c's don't. On the other hand a, b and c have cycles for 1 of 5 but d's is 4. Any help is appreciated.","['graph-theory', 'graph-isomorphism', 'discrete-mathematics']"
3958335,Is there a formula for $\int_0^\pi\frac{\sin(nx)}{\cos(\theta)-cos(x)}dx$?,"I'm working on a school project about the aerodynamics of an helicopter blade. I'm trying to adapt my aerodynamics class ( centered around planes wings mostly ) to this case. In our class, we used what we called the integrals of Glauert and more specifically, this integral : $$
\int_{0}^{\pi}\frac{\cos\left(nx\right)}
{\cos\left(\theta\right) - \cos\left(x\right)}\,{\rm d}x = -\pi\,\frac{\sin\left(n\theta\right)}{\sin\left(\theta\right)}
$$ In the helicopter case, I need to evaluate a similar integral but with $\sin\left(nx\right)$ instead of $\cos\left(nx\right)$ . I found a beautiful proof of the first result in the book Inside Interesting Integrals by Paul Nahin ( page $60$ ) which uses recursivity. I tried to adapt it to the other integral using the formula $$\sin\left(\left(n + 1\right)x\right) +
\sin\left(\left(n - 1\right)x\right)
= 2\sin\left(nx\right)\cos\left(x\right)$$ $$
\mbox{Calling}\quad
I_{n} =
\int_0^\pi\frac{\sin\left(nx\right)}{\cos\left(\theta\right) - \cos\left(x\right)}\,{\rm d}x,
$$ I find that $$
I_{n+1} - 2\cos\left(\theta\right)I_{n} +
I_{n - 1} = \int_{0}^{\pi}2\sin\left(nx\right)\,{\rm d}x
$$ but I then have a problem to solve the recursive equation be the result is $0$ or $\frac{4}{n}$ depending on the parity of n. I decoupled the system to get two recursive equations for the different parities : For $a_n=I_{2n}$ , I get $a_{n+1}-2\cos(2\theta)a_n+a_{n-1}=8\cos\theta(\frac{1}{2n+1}+\frac{1}{2n-1}$ ) And for $b_n=I_{2n+1}$ , I get $b_n-2\cos(2\theta)b_{n-1}+b_{n-2}=\frac{8}{2n-1}\cos(\theta)$ I entered these formula on Wolfram Alpha and got some really ugly results. I was thus wondering if a more simple formula could exist for my integral. I also quickly looked at the wikipedia proof which uses residual theorems but I got lost quite fast... Do you know some other way to evaluate this integral or maybe if it's possible to solve the recursive equations to get to a simpler result than the one from Wolfram ? Thank you very much !","['integration', 'physics', 'cauchy-principal-value', 'recurrence-relations']"
3958349,"If $m$ and $n$ are reversed numbers (like $123$ and $321$) and $m * n = 1446921630$ , find $(m+n)$.","If $m$ and $n$ are reversed numbers (like $123$ and $321$ ) and $m * n = 1446921630$ , find $(m+n)$ . What I Tried : I found $1446921630 = 2 * 3^5 * 5 * 7 * 11^2 * 19 * 37$ , but that did not really give me useful information. A little information I got is that $m$ and $n$ each will have a factor of $11$ , and at-least $1$ factor of $3$ , as both will be divisible by $3$ and $11$ . I could have assumed the numbers to be of the form $10x + y$ or something, but I can't as I don't know how many digits both $m$ and $n$ will have, and that will more like Trial and Error. Another thing is that among $m$ and $n$ , one will be even and one will be odd. The odd number will start with an even digit which is not $0$ , and the even number cannot end with $0$ . Also $5$ should divide the odd number and it will end with $5$ . That is all I could conclude. Can anyone help me?","['contest-math', 'number-theory', 'problem-solving']"
3958364,Interesting convex function inequality,"Let $f:(0,+\infty)\to \mathbb R$ a convex function. Prove that: $$20\int^3_0 f(x)\,dx + 10\int^6_0 f(x)\,dx \ge 12 \int^5_0 f(x)\,dx + 15 \int^4_0 f(x)\,dx$$ I tried to use the Newton-Leibniz formula but I did not get to any relevant point.","['integration', 'inequality', 'convex-analysis', 'integral-inequality']"
3958398,How many meetings would it take for 12 people to meet in 4 groups of 3 until they met everyone?,I have a group of 12 people that I would like to meet in four groups of three each month.  How many minimum months would it take such that each person has been in at least one group with every other person? Below is the brute force method I used to get it to seven months:,"['combinatorial-designs', 'combinatorics']"
3958410,Inverting Triangular Matrices,"A $d × d$ triangular matrix $L$ with non-zero diagonal entries can be expressed in the form $(\Delta + A)$ , where $Δ$ is an invertible diagonal matrix and $A$ is a strictly triangular matrix. Show how to compute the inverse of $L$ using only diagonal matrix inversions and matrix multiplicatons/additions. Note that strictly triangular matrices of size $d × d$ are always nilpotent and satisfy $A^d = 0$ . It is mentioned a page before that $(I+A)^{-1}=I-A+A^2-A^3+A^4+\dots$ which I see is obtained via Taylor Expansions, using this hint, my attempt: $(\Delta+A)^{-1}=\\\Delta^{-1}\Delta(A+\Delta)^{-1}=\\\Delta^{-1}[(A+\Delta)\Delta^{-1}]^{-1}=\\\Delta^{-1}(I+A\Delta^{-1})^{-1}$ Expanding: $\Delta^{-1}[I-A\Delta^{-1}+(A\Delta^{-1})^2-(A\Delta^{-1})^3+\cdots]$ And since $A$ is a nilpotent matrix, any $A^d=0$ , therefore: $(\Delta+A)^{-1}=\Delta^{-1}(I-A\Delta^{-1})$ Although something in my mathematical gut tells me this is ridiculous. SOURCE : Linear Algebra and Optimization for Machine Learning: A Textbook (Charu C. Aggarwal); page 18 problem 1.2.11","['matrices', 'inverse']"
3958430,Finding eigenvalues and eigenfunctions of differential equation,"I need to write the following d.e. in Sturm-Liouville form and find the eigenvalues and eigenfunctions. $$\frac {\mathrm d ^2 y}{\mathrm d x^2} + 7 \frac {\mathrm d y} {\mathrm d x} + (e^{3x} + \lambda)y = 0$$ where $y(0)=y(1)=0$ . I have written it as $-(p(x)y')' + q(x)y = \lambda r(x) y$ with $p(x) = e^{7x}$ , $q(x) = -e^{10x}$ and $r(x) = e^{7x}$ . I am not sure how to find the eigenvalues though. I know that the boundary conditions are relevant but I'm not sure where to start in terms of finding the eigenfunctions. How do I know by looking at the d.e. when it is possible to find them?","['sturm-liouville', 'ordinary-differential-equations', 'eigenfunctions']"
3958478,In how many ways can I select 13 cards from a standard deck of 52 cards so that 5 of those cards are of the same suit?,"My professor says the solution is $47 \choose 8$ , but I don't understand how and why. Could you please explain the solution or say whether it is correct or not?
Thanks in advance!","['combinatorics', 'card-games', 'discrete-mathematics']"
3958490,Checking if a set is algebraic [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 years ago . Improve this question Given a subset of $\mathbb C^n,$ is there some way to check if it is the zero set of a collection of polynomials of degree $\le d?$ Certainly when $d=1$ this is easy, and for larger $d$ there are many necessary conditions - but is any of them sufficient?","['complex-analysis', 'algebraic-geometry', 'abstract-algebra']"
3958496,Expectation of submartingale always increasing?,"In a proof (upcrossing inequality) our professor used something, which i'm not sure i understand. So let's say we have a $(\mathcal F_n)$ -submartingale $(X_n)_{n\geq0}$ with $X_0 = 0$ . He then said that $E[X_n] \geq 0$ $\forall n \geq 1$ , but how can you see this? I know that $E[X_{n+1} | \mathcal F_n] \geq X_n $ , but how can i go from the conditional expectation to the ""usual"" expected value?","['martingales', 'probability-theory', 'probability']"
3958519,Elements of the same order in the same conjugacy class that commute are contained in the same cyclic subgroup,"I have a conjecture, that I would like to prove. EDIT: My first idea was not true, as pointed out by Derek Holt. Statement: Let $G$ be a (finite) group and $m$ the maximal order of an element of $G$ , such that all elements of maximal order are conjugated. If two commuting elements $x,y \in G$ have order $m$ , then $x^n=y$ for some $n \in \mathbb{N}$ , i.e. $y$ is contained in the cyclic subgroup generated by $x$ I looked for some examples: $(1,2,3)=(1,3,2)^2\in S_3$ $(1,2,3,4)=(1,4,3,2)^3 \in S_4$ , but for non-commuting elements of this conjugacy-class it is not true, see: $(1,2,3,4)\not=(1,3,2,4)^n \forall n \in \mathbb{N}$ . Is this true in general? Does anyone know a proof? Thanks in advance.","['symmetric-groups', 'abelian-groups', 'group-theory', 'finite-groups']"
3958557,Does $\int \tan^3x\sec^2x \space dx$ have 2 solutions?,"So normally, you evaluate $\int\tan^3x\sec^2x \space dx$ by substituting $u = \tan x$ and $du = \sec^2x\space dx$ right? So, $$\begin{equation}\begin{aligned}
\int\tan^3x\sec^2x \space dx &= \int u^3 \space du \\
  &= \frac{u^4}{4} + C\\
  &= \frac{tan^4x}{4} + C \\
\end{aligned}\end{equation}$$ But, I tried to solve it this way instead, $$\begin{equation}\begin{aligned}
\int\tan^3x\sec^2x \space dx &= \int\tan^2x\tan x\sec x\sec x\space dx \\
  &= \int(\sec^2x-1)\tan x\sec x\sec x\space dx \\
  &= \int\sec^3x\tan x\sec x-\sec x\tan x\sec x\space dx \\
  &= \int\sec^3x\tan x\sec x-\sec x\tan x\sec x\space dx \\
  &= \int\sec^3x\tan x\sec x\space dx - \int\sec x\tan x\sec x\space dx \\
\end{aligned}\end{equation}$$ and then substituting $u = \sec x$ , thus $du = \tan x\sec x\space dx$ . So, $$\begin{equation}\begin{aligned}
\int\sec^3x\tan x\sec x\space dx - \int\sec x\tan x\sec x\space dx &= \int u^3 du - \int u\space du\\
&= \frac{u^4}{4} - \frac{u^2}{2} + C \\
&= \frac{\sec^4x}{4} - \frac{\sec^2x}{2} + C \\
\end{aligned}\end{equation}$$ What?! Can someone explain to me where I made the mistake?","['integration', 'calculus', 'trigonometric-integrals', 'indefinite-integrals', 'trigonometry']"
3958578,"Finite straight line question, will this formula create a straight line between two end points","I created a formula that I hope creates a finite straight line between any two points, I wanted to know if my math logic is correct or if I have an error in my formula. The idea is to create a straight line at y=1 between two points and then use that intersection to multiply by any other formula to get the part of the formula that fits within the bounds of my defined limit. Here is the formula that I created: $$\ln\left(\sqrt{9-x^2}*2\right)-\ln\left(\exp\left(\frac{\ln\left(\left(9-x^2\right)^2\right)}{4}\right)*2\right)+1$$ please note that the 9 can be any number and the square root of that number will be the endpoints of the line, so in the example above I am hoping to get a line between -3 and 3 exclusive. Can you please tell me if my logic is correct and if this will always return just a positive line at y=1 between two defined endpoints. if not can you please tell me where the issue is. Thank you for your help! Thank you all for your feedback. just to clarify why I am doing this, I would like to, using a standard math formula get any section of another formula without the need to to use absolute value, or other math functions like MOD. I would like to be able to create a standard math function that I can insert into any other formula and get a subsection of the formula using standard math. Thank you and sorry if it is confusing or if I am making things more complicated than they have to be. My idea is only the first part will be invalid if $9-x^2$ is negative, and the rest of the logic will always be the exact same value without the value returning square root of a negative number so that it does not cancel out. and finally add a one so that if x is within the limit then the value is always 1 to later be able to multiply by any other formula. My apologies again if I am making things way too complicated for my self. I now understand what the feedback meant about it being too complicated. her is what I think the formula should be; $$\ln\left(\sqrt{9-x^2}\right)-\frac{\ln\left(\left(9-x^2\right)^2\right)}{4}+1$$ I believe this will be simpler and since $\ln\left(\sqrt{9-x^2}\right)$ does not allow x  > 3 but $\frac{\ln\left(\left(9-x^2\right)^2\right)}{4}$ does allow x > 3 then this simpler function can be used to get any slice of a graph. Please let me know if this is not correct. Thank you, all again.",['geometry']
3958590,"If $X$ and $Y$ are independent random variables, are $X^2$ and $Y^2$ also independent?","If $X$ and $Y$ are independent random variables, are $X^2$ and $Y^2$ also independent? Can this be proven?",['statistics']
3958632,Contraction on 3x3 matrices?,"I would like to prove that the following linear map is a contraction on the $3 \times 3$ complex matrices endowed with the usual operator norm (i.e. the largest singular value norm): $$
\begin{pmatrix}
           a_{11} & a_{12} & a_{13} \\
  a_{21} & a_{22} & a_{23} \\
    a_{31} & a_{32} & a_{33} 
\end{pmatrix}
 \mapsto {2\over 3}\begin{pmatrix}
           a_{11} & a_{12} & a_{13} \\
  a_{21} & a_{22} & a_{23} \\
    a_{31} & a_{32} & {a_{11} + a_{22} \over 2}
\end{pmatrix}. $$ Numerical simulation shows this is likely to be true, but it is absolutely not clear to me how to prove it. Any idea is welcomed.","['operator-theory', 'matrices', 'linear-algebra', 'matrix-norms', 'numerical-linear-algebra']"
3958651,Solution to an inexact differential equation with the difference between partial derivatives not single variable,"How can I find the general solution to the equation $$\left(x^2+xy+\frac{y^2}{x}\right)dx+(x^2+xy-y)dy=0$$ Note that, by using exact differentials, I could reduce it to $(x+y)d(x+y)=yd\left(\frac{y}{x}\right)$ , but could not solve it. The difference between $M_y-N_x=\frac{2y}{x}-x-y$ , where $M=x^2+xy+\frac{y^2}{x}$ , $N=x^2+xy-y$ . Any hints? Thanks beforehand.","['calculus', 'ordinary-differential-equations', 'real-analysis']"
3958660,Can continuity be characterized by nets?,"Let $X$ and $Y$ be topological spaces  (not necessarily assumed to be  Hausdorff or to have any additional property) and let $f:X\to Y$ be a given function.  Is it true that $f$ is continuous iff
for every $x\in  X$ , and every net $\{x_i\}_i$ converging to $x$ , one has that $f(x_i)\to f(x)$ . PS: I have searched for this specific question in MSE and, although I found several posts discussing it ( this , this , and this ) with varying degress of objectivity, and using various additional hypothesis (Hausdorff,
completely regular, first countable) I do not believe it can be found in the exact terms above. I therefore thought it would be nice to register it here. I am also providing an answer which I hope  is similar to the one in The Book $\ddot \smile$","['continuity', 'general-topology', 'nets']"
3958673,"Given first fundamental form, provide an example of its surface","How to find surface of this first fundamental form (not a plane)? I know it may sound stupid, but my few attempts got me $(u,v,0)$ , but it is plane. Is there any algorithm, I could not find any.","['surfaces', 'differential-geometry']"
3958684,About the correct definition of a binomial random variable,"I'm having trouble with how to exactly define a binomial random variable. Let's fix a discrete probability space $(\Omega,P)$ , where $|\Omega| \le \aleph_0$ . Then, if $X\colon \Omega \to \mathbb{R}$ is a real random variable, when exactly can we say that it is binomial ( $X \sim Bi(n,p)$ )? I found two possible (non equivalent) definitions: $X$ is the sum of $n$ independent Bernoulli random variables $X_1\colon \Omega \to \{0,1\},\dots,X_n\colon \Omega \to \{0,1\}$ , where $X_1 \sim Be(p),\dots,X_n \sim Be(p)$ ; The probability distribution of $X$ is given by $p_X(k)=P(X=k)=\binom{n}{k}p^k(1-p)^{n-k}$ when $k \in \{0,\dots,n\}$ , while $p_X(x)=0$ if $x \in \mathbb{R} \setminus \{0,\dots,n\}$ . I know that 1) implies 2), but in general it is not true the converse, so that 1) is not equivalent to 2). So maybe I should use 1) as a definition. Right? I apologize for the low level of my question. Thank you!","['binomial-distribution', 'definition', 'soft-question', 'probability-theory', 'probability']"
3958695,Show $ g(s):=\int_{0}^{\infty}f(t)t^{s-1} dt$ is well defined and analytic.,"Let f be a real-valued function as following : for fixed $z \in \mathbb{C}$ $$f(t) = \sum_{a,b \in \mathbb{N} }e^{-\lvert az +b \rvert^2 t}$$ Let's define $$ g(s):=\int_{0}^{\infty}f(t)t^{s-1} dt$$ Then, show that $g(s)$ is a well-defined and analytic for all $s \in \mathbb{C}$ except $s=0, 1$ [ My attempt ] First, I showed that $\int_{t_0}^{\infty}f(t)t^{s-1} dt$ is well-defined for $t_0 >0$ . We know that for each $a>0$ , $b>0$ $$ a^2+b^2 \geq 2ab $$ Therefore, $$ \lvert az+b \rvert^2 = a^2\lvert z \rvert^2+b^2+2\text{Re}(z)ab \geq 2\lvert z \rvert ab+2\text{Re}(z)ab = (2\lvert z \rvert + 2\text{Re}(z)) ab =:k_1ab$$ so $$f(t) = \sum_{a,b \in \mathbb{N}}e^{-\lvert az +b \rvert^2 t} \leq \sum_{a,b \in \mathbb{N} }e^{-k_1ab t}$$ Therefore, we can check that $f(t)t^{s-1}$ has rapidly decaying at $\infty$ However i'm stuck here. I can't prove the integral of $g$ is well defined at $0$ and analytic part. How to prove this? Thank you for your attention.","['complex-analysis', 'calculus', 'real-analysis']"
3958773,Prove that $\int_0^b x^3 dx = \frac{b^4}{4}$,"The problem is as below: $\textbf{Problem 1}$ Prove that $\int_0^b x^3 dx = \dfrac{b^4}{4}$ by
considering partitions into $n$ equal subintervals, using the  formula
for $\sum_{i=1}^n i^3$ which was found in problem 2-6.    This problem
requries only a straightforwad imitation of calculations in the text,
but you should write it as a formal proof to make certain that all the
fine points of the argument are clear. I'm using the 4th Ed. of Calculus by Michael Spivak. I'm looking for some criticism on my proof-writing. Here is my solution: We consider the interval $[0,b]$ of the function $f(x) = x^3$ .
We use lower and upper sums in our proof. First, let $P = \{t_0, \dots, t_n\}$ be a partition of $[0,b]$ . Suppose that these partitions divide $[0,b]$ into $n$ equal
subintervals. Then, the length of each subinterval is $\dfrac{b}{n}$ . Specifically, we have that $t_0 = 0, t_1 = \dfrac{b}{n}, t_2 = \dfrac{2b}{n}$ . So, each partition $t_i = \dfrac{ib}{n}$ . So, we define $$
	m_i = t_{i-1}^3 \quad M_i = t_i^3
$$ so we have that $$
	L(f, P) = \sum_{i=1}^n t_{i-1}^3 \dfrac{b}{n}
$$ and specifically, $$
	L(f, P) = \sum_{i=1}^n \dfrac{(i-1)^3b^3}{n^3} \cdot \dfrac{b}{n}
$$ Moreover, $$
	L(f, P) = \sum_{j=0}^{n-1} j^3 \cdot \dfrac{b^4}{n^4}
$$ Which simplifies to: $$
	L(f, P) = (\dfrac{n(n-1)}{2})^2 \cdot \dfrac{b^4}{n^4}
$$ The last steps: \begin{align*}
	L(f, P) &= (\dfrac{n^2(n-1)^2}{4}) \cdot \dfrac{b^4}{n^4}
	\\&= \dfrac{(n-1)^2}{4} \cdot \dfrac{b^4}{n^2}
	\\&= \dfrac{(n-1)^2}{n^2} \cdot \dfrac{b^4}{4}
\end{align*} The process for the upper sum is similar, we take the same partition: \begin{align*}
	U(f, P) &= \sum_{i=1}^n (\dfrac{ib}{n})^3 \cdot \dfrac{b}{n}
		\\&= \sum_i^n i^3 \cdot \dfrac{b^4}{n^4}
		\\&= \dfrac{n^2(n+1)^2}{4} \cdot \dfrac{b^4}{n^4}
		\\&= \dfrac{(n+1)^2}{n^2} \cdot \dfrac{b^4}{4}
\end{align*} Now, it is clear that $L(f, P) \leq \dfrac{b^4}{4} \leq U(f, P)$ for all $P$ of equal partition width.
By choosing $n$ sufficiently large, we can make $U(f, P_n) - L(f, P_n)$ as
small as desired where $n$ is the number of sub-intervals. Taking the limits of both sides to infinity, by squeeze
theorem, we see that $\lim_{n \to \infty} L(f, P_n) = \lim_{n \to \infty} U(f, P_n)$ and so the integral is $\dfrac{b^4}{4}$ for the function $f(x) = x^3$ .","['calculus', 'solution-verification']"
3958813,Generalizing the Binary Reflected Gray Code,"Let $Q_n$ denote the $n$ -dimensional hypercube. It has a vertex for each binary string $x = x_n x_{n-1} \ldots x_1 \in \{0, 1\}^n$ , and there is an edge between two vertices $v_x$ and $v_y$ if their corresponding binary strings $x$ and $y$ have Hamming distance one. For convenience, we will use $x$ to denote $v_x$ when the context is clear. An $n$ -bit gray code is a cyclic ordering of all $n$ -bit binary strings such that consecutive strings in the code have Hamming distance one. Therefore, an $n$ -bit gray code corresponds to a Hamiltonian cycle in $Q_n$ . The Binary Reflected Gray Code (BRGC) is an example of such a code defined as follows, which we denote by $G_n$ . For $n = 1$ , $G_1$ is simply $[0; 1]$ . For $n > 1$ is can be defined recursively by $G_n = 0 \cdot [G_{n - 1}]; 1 \cdot [G_{n-1}]^R$ . In other words, $0 \cdot [G_{n - 1}]$ denotes the elements of $G_{n-1}$ prefixed by a $0$ and $1 \cdot [G_{n-1}]^R$ denotes the elements in $G_{n-1}$ , in reversed order, prefixed by a $1$ . The BRGC has two useful properties. Let $G_n = [g_0; g_1; \ldots; g_{2^n - 1};]$ denote the elements of $G_n$ . Bit $x_1$ is flipped every other time. For odd $i$ , $0 \leq i \leq 2^n - 1$ , define the pairs $P_{\lfloor \frac{i}{2} \rfloor} = (g_i, g_{i + 1 \mod 2^n})$ . The elements of $Q_n$ can be partitioned into $2^{n-2}$ pairwise disjoint copies of $Q_2$ (isomorphic to $Q_2$ ), where each copy of $Q_2$ corresponds to two of the above pairs, which we denote by $S = (s_1, s_2)$ and $T = (t_1, t_2)$ , such that $s_1 \oplus s_2 = t_1 \oplus t_2$ (the exclusive-or operator). Note that since $s_1$ occurs immediately before $s_2$ and $t_1$ occurs immediately before $t_2$ in $G_n$ , then $s_1$ and $t_1$ have Hamming distance two. We can obtain such a partitioning as follows. The pairs $P_{2^{n-2} - 1}$ and $P_{2^{n-1} - 1}$ form one copy of $Q_2$ , as well as the pairs $P_j$ and $P_{2^{n-1} - 2 - j}$ , for $0 \leq j < 2^{n-2}-1$ . Is it possible to find a gray code (possibly by generalizing the BRGC), that admits a similar partitioning, except into $2^{n-3}$ disjoint copies of $Q_3$ ? I worry that the first property might prevent the generalization, but haven't been able to prove so. If true, can something be said regarding a similar partitioning into $2^{n-d}$ disjoint copies of $Q_d$ ? Example for $n=4$ : The vertices are labelled from $g_0$ to $g_{15}$ , starting from the string of all zeros, denoting the order in the BRGC. The pairs $P_3$ and $P_7$ form one copy of $Q_2$ , pairs $P_1$ and $P_5$ form another copy of $Q_2$ , while the pairs $P_0$ and $P_6$ , as well as $P_2$ and $P_4$ , make the other two copies of $Q_2$ .","['graph-theory', 'gray-code', 'combinatorics']"
3958814,Almost Everywhere Conservative Vector Field,"$$F(x,y) = \left \langle\frac{-y}{\sqrt{x^2 + y^2}}, \frac{x}{\sqrt{x^2 + y^2}},0 \right \rangle $$ Is a famous example of a vector field whose curl is zero away from the origin but does not have potential function associated with it. However, can a potential function be defined almost everywhere that works? I think this function can be increasing as it goes - say starting at zero on the x-axis. When it comes back, it will be at a higher value. But since I have specified that it be defined a.e., the value along the x-axis won't matter. I don't know how to explicitly write this function though.","['multivariable-calculus', 'differential-geometry']"
3958821,$30$ Sided Dice Problem. Interview Preparation. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . The community reviewed whether to reopen this question 11 months ago and left it closed: Original close reason(s) were not resolved Improve this question I came through this problem three years ago when I prepared for interview. Today when reviewing it, I still couldn't think out a mathematical way to solve it. Any help would be appreciated. $4$ players roll a fair $30$ -sided dice. Each of them rolls once and the $4$ numbers rolled are different. The $2$ individuals that rolled the biggest and small value will be in a team while the $2$ individuals who rolled the $2^{\text{nd}}$ and $3^{\text{rd}}$ smallest value will be on the opposite team. The team with the largest average wins and the loser has to pay the winners' average number ( for example, if the dice outcome is $27, 20, 15,$ and $11,$ then the people who get $27$ and $11$ get paid $19$ ). Q) If you are the first to roll, what number would you prefer to maximize your payout?","['expected-value', 'expectation-maximization', 'dice', 'probability']"
3958842,"How good can a ""near-miss"" polyomino packing be?","Given a polyomino $P$ with $n$ cells, we can ask about its maximal packing density $\delta_P$ in the plane (perhaps the limsup if we are concerned about convergence issues, though I don't think this actually comes up). If $\delta_P=1$ , then $P$ tiles the plane: having arbitrarily good packings implies that $P$ can cover arbitrarily large $N\times N$ squares, and from there the result follows via a compactness argument. We can then ask: among polyominoes on $n\ge 7$ cells that do not tile the plane, which one achieves the highest density? Call this maximal value $\Delta_n$ . For each $n$ , $\Delta_n<1$ , though of course in the limit for large $n$ it approaches $1$ . As a simple lower bound, we always have $\Delta_n\ge n/(n+1)$ , as exhibited by the polyomino given by taking all but the first square in a spiral of length $n+1$ around the origin; once we plug the hole, it tiles the plane without gaps, but the hole cannot be filled. For instance, with $n=7$ : In contrast, putting remotely nontrivial upper bounds on $\Delta_n$ in general should be exceedingly difficult or impossible, since any computable upper bound less than 1 would yield an algorithm to decide the tiling problem for polyominoes, which is suspected not to exist. (Non-computable upper bounds on the order of $1-1/\text{BB}(k\cdot n)$ can be done, of course, but these are rather silly.) However, improved lower bounds and exact values for small $n$ seem pretty tractable, and I'm curious what is known in this direction. Some questions: Is the sequence $\Delta_7,\Delta_8,\ldots$ monotonically increasing? I suspect not. When does $\Delta_n$ first exceed $n/(n+1)$ ? I don't actually know that it does, but I strongly suspect so for reasons described above. When $n=7$ I have not found any packings of density greater than $7/8$ , although only for one of the four non-tiling heptominoes (the one pictured above) have I proven this is optimal. (All four obtain $7/8$ by adding one square to yield a tiling octomino.) Can $\Delta_7$ be proven to equal $7/8$ , if indeed it does so? Exhausting all tilings of an $N\times N$ square by each of the four non-tiling polyominoes and counting the max density therein would at least yield an upper bound; if $\Delta_7$ exceeds $7/8$ , I would guess it does so via finding a tiling $15$ -omino which is the union of two copies of a non-tiling heptomino and an additional cell. [Subjective] What are some examples of interesting ""near-miss"" tilings?","['polyomino', 'geometry', 'packing-problem']"
3958865,Second order homogeneous differential equations: why do repeated roots modify the solution set?,"Consider the following differential equation with constant coefficients: $$
y'' + 2ky' + k^2y = 0 \, .
$$ The auxiliary equation is \begin{align}
m^2 + 2km + k^2 &= 0 \\[4pt]
(m+k)^2 &= 0 \\[4pt]
m &= -k \, .
\end{align} This means that the solutions of the differential equation are $Ae^{-kx}+B\color{red}{x}e^{-kx}$ , where $A$ and $B$ are arbitrary constants. The $x$ -term highlighted in red is what confuses me. Generally speaking, if the roots of the auxiliary equation are $\alpha$ and $\beta$ , then the solutions to the differential equation are $Ae^{\alpha x} + Be^{\beta x}$ . However, if $\alpha=\beta$ , then the solutions are not $Ae^{\alpha x} + Be^{\alpha x}$ —or at least, this solution is incomplete. I can verify that $y=xe^{-kx}$ is a solution of the differential equation by plugging it back in to the equation, but I'm looking for a deeper reason for why this occurs.","['calculus', 'ordinary-differential-equations']"
3958870,Bracing a polygon without triangles,"The following Laman graph braces a square without triangles. Stated another way, this is a unit-distance rigid graph without 3-cycles. It seems to be the smallest example of a triangle-free braced polygon .  This happens to be a subgraph of the unit sticks cube graph. What other regular polygons have triangle-free rigid constructions?","['graph-theory', 'rigid-transformation', 'coloring', 'geometry']"
