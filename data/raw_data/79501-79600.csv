question_id,title,body,tags
1022448,Does this sequence of sets eventually contain all primes?,"I was on Reddit earlier and answered a question about the usual proof that there are infinitely many primes: multiply any finite set of them, add 1, factor, and you get factors that are not in the set. But a question occurred to me that I've never seen discussed, and I'm curious if any work has been done or if a conclusive answer has been reached. The question relates to the following sequence. Define: $S_0 = \{2\}$ $S_n = S_{n-1}\cup T_{n-1}$ where $T_{n-1}$ is defined as the set of prime factors of $\Pi S_{n-1}+1$ (is there a standard notation for ""the set of prime factors of n?""). The question is, do all primes eventually appear in one of the $S_n$?","['prime-numbers', 'number-theory']"
1022485,"Proof by Induction: for all integers n $\ge$ 0, $12\mid8^{2n+1}+2^{4n+2}$","I'm working on a homework problem for my discrete math class, and I'm stuck. (Note: I made a post about this earlier, but I read the problem incorrectly, thus the work was wrong, so I deleted the post.) Prove by mathematical induction that for every integer n $\ge$ 0,  $12\mid8^{2n+1}+2^{4n+2}$ I start out by proving the base case, $F(0)$, to be true: $$
F(0)=8^1+2^2=12\quad \text{Obviously, 12 is divisible by 12}
$$ I then move on to the induction step to prove the $F(n+1)$ is true: I assume that $8^{2n+1}+2^{4n+2}$ is divisible by 12, and then plug in $(n+1)$: $$
F(n+1)=8^{2(n+1)+1}+2^{4(n+1)+2}=8^{2n+3}+2^{4n+6}
$$ I then do $F(n+1)-F(n)$: $$
F(n+1)-F(n)=(8^{2n+3}+2^{4n+6})-(8^{2n+1}+2^{4n+2})
$$ $$
=8^{2n+3}-8^{2n+1}+2^{4n+6}-2^{4n+2}
$$ I then factor out the terms used in $F(n)$: $$
8^{2n+1}(8^2-1)+2^{4n+2}(2^4-1)=8^{2n+1}(63)+2^{4n+2}(15)
$$ I can re-write the result as: $$
8^{2n+1}(63)+2^{4n+2}(12+3)
$$ This is where I'm stuck. I broke up the $15$ into $12+3$ since I need to prove that there is a multiple of 12, but I don't know what to do with the 63, since (I think) you're supposed to have the terms in $F(n)$ multiplied by 3 after you distribute so that you can factor out the 3 and have $F(n)$ in the equation, which is proven to be divisible by 12. I tried splitting the $63$ into $(21*3)$ $$
8^{2n+1}(21*3)+2^{4n+2}(12+3)
$$ But I'm not sure what to do next. Any ideas?","['induction', 'discrete-mathematics', 'proof-verification', 'divisibility']"
1022489,Lagrange Multiplier Question and my attempt,"Question is ""Find the extrema of $xyz$ when $x+y+z=a$ , $a>0$ "". Starting with usual Lagrange Multiplier method, I get $f_x = yz + \lambda = 0$ $f_y = xz + \lambda = 0$ $f_z = yz + \lambda = 0$ Now from three equations above, I multiply first by $x$ and second by $y$ and third by $z$ , I get $f_x = xyz + \lambda x = 0$ $f_y = xyz + \lambda y = 0$ $f_z = xyz + \lambda z = 0$ Clearly from these equating values of $xyz$ . I get $x=y=z$ . And thus I have solved the question and is consistent with my answer with textbook. BUT, if I manipulate equations in a way as if I equate values of $\lambda$ I get $yz=xz=xy$ Now I take $yz=xz$ . This implies either $z=0$ or $x=y$ . If I take $z=0$ and put in other two equations I get $xy=0$ which means either $x=0$ or $y=0$ . Say I take $x=0$ and now putting in constraint equation I get $y=a$ so i get $(0,a,0)$ . Not only this but by solving other equations like this I get $(0,a,0)$ , $(a,0,0)$ , $(0,0,a)$ , $((a-1)/2,(a-1)/2,1)$ .
But this is not consistent with textbook. Can anybody help me out from here? Thanks","['multivariable-calculus', 'lagrange-multiplier']"
1022512,What is the most influential work of Grothendieck in mathematics?,"Recently Alexander Grothendieck has passed away but his mathematical wave is still alive and passes its growth ages. It is hard to describe the influence of such a great man in mathematics just in few words and even more hard to determine a particular idea of him as the most influential but maybe some descriptive papers of some historians and expert researchers who work on his theories can help us to reach a better insight about it. Question: What are examples of nice descriptive papers or books which are concentrated on impacts and connections of Grothendick's theorems and theories in mathematics, specially those which describe the influence of his works on those parts of mathematics which were developed before him and are under development now? In particular, as a logician I am interested in papers related to possible impacts of Grothendick's mathematical ideas on some fields of mathematicial logic like set theory and model theory.","['logic', 'algebraic-geometry', 'reference-request', 'soft-question', 'mathematicians']"
1022551,Discrete Mathematics for someone who has already done Analysis/Algebra?,"I graduated with an undergraduate mathematics degree this past May, but I had never taken a Discrete Mathematics course. I took the usual years' worth of Algebra and Analysis. I am interested in a discrete mathematics text (with challenging problems) that covers all of the topics on the Math GRE Subject Test, i.e., Discrete mathematics : logic, set theory, combinatorics, graph theory and algorithms and won't be boring for me to read, given my math background. (I have heard that I would be bored in such a class, as I once spoke to a Discrete Math professor about taking her class, and she told me it would be a waste of time.)","['discrete-mathematics', 'reference-request']"
1022579,What is the coefficient of $x^{25}$ in $(x^3 + x + 1)^{10}$?,"Here's what I have so far on the off chance that my thinking is correct...
So using Vieta's the coefficient of the $x^{25}$ should be $-(r_1r_2r_3r_4r_5+r_1r_3r_4r_5r_6+...+r_6r_7r_8r_9r_{10})$
Since each root is equal it is $-(r^5+r^5...+r^5)$
And there are 10 roots and you want to group them in 5's, so there are $10 \choose 5$ = 252 number of $r^5$s. Have I gotten it right so far or are there errors in my work and/or line of reasoning?
I have $-252*(r^5)$ as the coefficient, with r being the solution to the cubic $x^3+x+1=0$.
How do I solve for r? Would appreciate any help with this problem. Thanks in advance!","['contest-math', 'polynomials', 'recreational-mathematics', 'binomial-coefficients', 'combinatorics']"
1022636,How many password combination?,"How many password combinations if you can have up to 8 letters, uppercase or lowercase, with only letters and no numbers or special characters? My attempt: $$52+52^2+52^3+52^4+52^5+52^6+52^7+52^8$$ because there are 52 possible at each place and you can have up to 8 letters which means you can have either 1 2 3 4 5 6 7 or 8 letters. Is this correct? My reasoning could be off. Thank you!",['discrete-mathematics']
1022664,Open set of Polish space is again a Polish space?,"A Polish space ​is a separable completely metrizable topological space. On the wikipidia article and in the book measure theory from Bauer (§26, Example 4) is stated that any open set of a polish space is again a polish space. In the book from Bauer one can find a proof that shows that any open set of a Polish space is homeomorphic to another Polish space. But how is it possible that a open set is again completely metrizable? For instance, the set $[0,1]$ is Polish and $(0,1)$ is an open subset which is not completely metrizable, right?","['general-topology', 'descriptive-set-theory']"
1022682,How do I prove that a matrix is a rotation-matrix?,"I have to prove that this matrix is a rotation-matrix
$$\begin{pmatrix} \frac12 & 0 & \frac{\sqrt{3}}{2} \\
0 & 1 & 0 \\
\frac{\sqrt{3}}{2} & 0 & \frac12
\end{pmatrix}$$
How do I do this? 
My idea is to multiplicate it with $\begin{pmatrix} x \\ y \\ z\end{pmatrix}$ and show that one component will remain unchanged . Is this enough? Do non-rotational transformations exist, which leave one component unchanged ?",['linear-algebra']
1022698,"Does existence of non-trivial solution of $S(x,y,z) = 0, \; S(y,z,x) = 0, \; S(z,x,y) = 0$ implies existence of trivial solution at $x=y=z$ axis?","My question is following. Suppose that you have an implicit surface given by equation $S(x,y,z) = 0$ (if it matters, now $S(x,y,z)$ is a polynomial function). I'm interested only in $\mathbb{R}^3_{+}$ part of $\mathbb{R}^3$ (you may think that $S(x,y,z)$ is symmetric under $(x,y,z) \mapsto (\pm x, \pm y, \pm z)$ ). 
In my case the intersection of $S(x,y,z)$ with coordinate planes will look like on the picture: Let the cyclic group of 3rd order act on $\mathbb{R}^3$ via cyclic shift $(x,y,z) \mapsto (y,z,x)$. It's easy to see that if $\lbrace S(x,y,z) = 0 \rbrace \cap \mathbb{R}^3_+$ is fully contained in some fundamental domain of group action then system of equations $S(x,y,z) = 0, \; S(y,z,x) = 0 \; S(z,x,y) = 0 $ has no solution. If $S(x,y,z)$ intersects with only one face of fundamental domain, then the same result holds. Now suppose that we have a non-trivial solution of system $S(x,y,z) = 0, \; S(y,z,x) = 0 \; S(z,x,y) = 0 $. By non-trivial I mean solution that is inner point of group action's fundamental domain. Now the question goes here: My hypothesis is that such surface $S(x,y,z)$ necessarily will have intersection with line $x=y=z$. Are there any counterexamples that immediately jump to your mind or is there any proof sketch? UPDATE So, the most important feature of $S(x,y,z)$ is that $S(x,y,0) = 0$ has solution. Solution set consists of two compact connectivity components (see the picture 1 for example). The same for $S(x,0,z)$ and $S(0,y,z)$","['algebraic-geometry', 'examples-counterexamples', 'soft-question']"
1022745,"On the evaluation of the integral $\int_{0}^{1}\sqrt{x^2+1}\,dx$","The integral $\displaystyle \int_{0}^{1}\sqrt{x^2+1}\,dx$ can be evaluated with the standard technic of sub $u=\tan \theta$. However, in the book says evaluate the integral without trigonometric substitution. I can't find a way. I applied the sub $u=1-x$ and it got a little messie.
I also tried to approach it geometrically, but again I had a problem because the graph is not a common shape thus saying that the integral is equal to the area of that shape. For example if I had the integral $\displaystyle \int_0^1 \sqrt{1-x^2}\,dx$ then this equal to aread of the quadrateral etc. In the case of the other integral I don't see something like this. If someone could give me a hint,that would be nice!!","['definite-integrals', 'integration', 'real-analysis']"
1022775,How does one show sin(x) is bounded using the power series?,"Define the real valued function 
$$ \sin:\mathbb{R} \rightarrow \mathbb{R}, \qquad given ~~by \qquad \sin(x) := x-\frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \ldots $$ How does one show $\sin(x)$ is bounded using this definition? Note that you are not allowed to 
use the power series of $\cos(x)$ and try to show $\sin^2(x) + \cos^2(x) =1$ and 
then prove they are bounded. I want a direct proof using the power series of $\sin(x)$. Remark: I am looking for a proof that will allow me to modify/mimic the arguments if I am given some DIFFERENT power series that also happens to be bounded (but which doesn't have all the nice properties of sin(x) and cos(x) ). That is the motivation for the question. Take the power series of $\exp(-x^2)$ for example. Why is that bounded?","['power-series', 'ordinary-differential-equations', 'inequality', 'real-analysis']"
1022783,"How to show that $f(x)=2x$ is not onto, as a function from $\mathbb{Z}$ to itself?",$f\colon\Bbb Z\to\Bbb Z$ is given by $f(x) = 2x$. Show that $f$ is one-to-one and not onto. I know this is a very simple question but I can't figure out why this is NOT onto. I've done many other questions but this is the one I'm stuck with! Thanks for any help,"['elementary-set-theory', 'functions']"
1022803,Umbilical points of Ellipsoid alternate method,"I'm having serious trouble finding the umbilical points of the ellipsoid represented by $$\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1,    \;\;\;a,b,c\neq 0.$$ My first thought was to use the parametrization $$\mathbf{x}(u,v)=(a\sin(u)\cos(v),b\sin(u)\sin(v),c\cos(u)),$$ for $0<u<\pi$ and $0<v<2\pi$, compute the first and second fundamental forms, etc., but this is a nightmare. After doing some researching (and on the back solutions of Do Carmo) I came across I suppose what would be an alternate method which doesn't dig directly into a parametrization. It is explained slightly at the end of the pdf: http://www.math.umn.edu/~voronov/5378/sample1.pdf which essentially states to notice that $N_1=(\frac{x^2}{a^2},\frac{y^2}{b^2},\frac{z^2}{b^2})$ (the gradient) is such that $N_1=fN$, for some $f$ such that $|f|=|N_1|$, where $N$ is the unit normal vector to surface, as well as notice a point on a curve $\alpha(t)=(x(t),y(t),z(t))$ lying on the ellipsoid is an umbilical point iff the vector triple product
\begin{equation}
\left(\frac{dN_1}{dt}\wedge \alpha '\right)\cdot N_1=0\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;(1)
\end{equation}
which I mostly understand. Then it says use some trickery by multiplying a $\frac{z}{c^2}$ to the equation and put it in terms of $x,x',y',$ and $y$ like this... The way I understand it you should start with equation (1) in this form
$$
\left(\left(\frac{x'}{a^2},\frac{y'}{b^2},\frac{z'}{c^2}\right)\wedge\left(x',y',z'\right)\right)\cdot\left(\frac{x}{a^2},\frac{y}{b^2},\frac{z}{c^2}\right)=0.
$$
Then, making things more complicated, (plugging everything in and doing the computation) we have
$$
\frac{xy'z}{a^2b^2}-\frac{xy'z'}{a^2c^2}+\frac{x'yz'}{b^2c^2}-\frac{x'yz'}{a^2b^2}+\frac{x'y'z}{a^2c^2}-\frac{x'y'z}{b^2c^2}=0.
$$
Multiplying $\frac{z}{c^2}$ to both sides gives
$$
\frac{xy'z'z}{a^2b^2c^2}-\frac{xy'z'z}{a^2c^4}+\frac{x'yz'z}{b^2c^4}-\frac{x'yz'z}{a^2b^2c^2}+\frac{x'y'z^2}{a^2c^4}-\frac{x'y'z^2}{b^2c^4}=0
$$
From here I suppose one would use the original equation for the ellipsoid as well as implicit derivative, $\frac{2zz'}{c^2}=-\frac{2yy'}{b^2}-\frac{2xx'}{a^2}$ to get rid of $z$ and $z'$. However, when I do that it starts getting pretty messy and I'm starting to believe I'm not quite understanding the method correctly. I also believe $y=0$ should satisfy this equation, but that's not quite working out, which also leads me to believe that I'm wrong in my thought. Any opinions/suggestions would be greatly appreciated. Thank you",['differential-geometry']
1022849,Total variation distance of two centered normal distributions,"I need to prove that the total variation distance between two normal random variables $X_t \sim \mathcal{N}(0,t)$ and $X_s \sim \mathcal{N}(0,s)$ converges to $0$ when $s \nearrow t$. We know that $$||X_t - X_s||_{\text{TV}}= \sup_{||f||_\infty \leq 1} \mathbb{E} (f(X_t)-f(X_s))$$ or that $$||X_t - X_s|| = \int_{-\infty}^\infty \bigg\vert\frac{e^{-\frac{x^2}{2t}}}{\sqrt{2\pi t}} - \frac{e^{-\frac{x^2}{2s}}}{\sqrt{2\pi s}} \bigg\vert dx$$
I try two work with the second identity but I didn't get something useful.
For example we can use that $s < t$ and define $$x(s,t) = \sqrt{\frac{st}{t-s}\log\left(\frac{t}{s}\right)} $$ and then 
$$||X_t - X_s|| = \int_{-\infty}^{-x(s,t)} \left(\frac{e^{\frac{-x^2}{2t}}}{\sqrt{2\pi t}} - \frac{e^{\frac{-x^2}{2s}}}{\sqrt{2\pi s}} \right)dx + \int_{-x(s,t)}^{x(s,t)}\left(\frac{e^{\frac{-x^2}{2s}}}{\sqrt{2\pi s}} - \frac{e^{-\frac{x^2}{2t}}}{\sqrt{2\pi t}} \right)dx + \int_{x(s,t)}^{\infty} \left(\frac{e^{\frac{-x^2}{2t}}}{\sqrt{2\pi t}} - \frac{e^{\frac{-x^2}{2s}}}{\sqrt{2\pi s}} \right)dx$$.
Then by symmetry we get
$$||X_t -X_s||= 2\left( \int_{x(s,t)}^{\infty} \left(\frac{e^{\frac{-x^2}{2t}}}{\sqrt{2\pi t}} - \frac{e^{\frac{-x^2}{2s}}}{\sqrt{2\pi s}} \right)dx + \int_0^{x(s,t)}\left(\frac{e^{\frac{-x^2}{2s}}}{\sqrt{2\pi s}} - \frac{e^{-\frac{x^2}{2t}}}{\sqrt{2\pi t}} \right)dx \right).$$
I want to use this and some kind of convergence property of the integral to conclude but I don't know how to do it.","['probability-theory', 'normal-distribution']"
1022851,This result holds in general or just for vector bundles?,"If $(P,\pi, M)$ is a principal $G$-bundle, then given a left $G$-space $F$, using the $G$-product we can create a new bundle $(P_F, \pi_F, M)$ that is said to be associated to the first. Also, if we have a certain vector bundle, if we pick the principal bundle of bases we can see that this vector bundle is associated to the latter. So in the case of vector bundles we have the converse: every vector bundle is associated to some principal bundle. Now, I wonder if this holds for more general bundles. Indeed, the book I'm reading makes it seems that it does: A crucial idea is that of a 'principal fibre bundle', which is a bundle whose fibre is a Lie group in a certain special way. These have the important property that all non-principal bundles are associated with an underlying principal bundle . Furthermore, the twists in a bundle associated with a particular principal bundle are uniquely determined by the twists in the latter, and hence the topological implications of fibre-bundle theory are essentially coded into the theory of principal fibre bundles. This sounds like every non-principal bundle is associated with some principal bundle. Is this true? If it is, how can we show it? I don't have yet an idea of a proof, but if it is true I imagine it has something to do with the transition functions between overlapping local trivializations. Is that right?","['general-topology', 'fiber-bundles', 'principal-bundles', 'differential-geometry']"
1022878,Fill chart using final data,"so all I know is that:
n=100.
i have 5 departments within the numbers: 0-1000. md = 500.
avg =490.
lower decile=200.
upper quarter=600. I really don't know how to use the formulas of each if I don't have any data.(fx,Fx etc) notice: this chart is filled by the correct answers(2. 15 = box 2, the answer is 15), how to i get to them?",['statistics']
1022879,Geometric Interpretation of the Cross-Ratio,"The cross ratio of 4 points $A,B,C,D$ in the plane is defined by $$(A,B,C,D) = \frac{AC}{AD} \frac{BD}{BC}$$ And it's a ratio which is preserved under projections, inversions and in general, by Möbius-Transformations. Although I can see it's utility and power, I cannot see a geometric definition or intuition for the cross ratio. Can someone give me any insights about this? EDIT : To be more specific, I'd like to express the cross-ratio as the length of some segment constructible with straightedge-and-compass.","['geometry', 'projective-geometry']"
1022890,"if $k$ is a positive integer and $G$ a finite group such that $G=\{x^k:x\in G\}$ , then is it true that g.c.d.$(|G|,k)=1$ ?","If $G$ is a finite group of order $n$ and $k$ is a positive integer such that g.c.d.$(n,k)=1$ , then I know that $G=\{x^k:x\in G\}$ ; is the converse true ? that is if $k$ is a positive integer and $G$ is a finite group such that $G=\{x^k:x\in G\}$  , then is it true that g.c.d.$(|G|,k)=1$ ? I have a feeling that the converse is true . Say g.c..d$(|G|,k)=d>1$ , then there is a prime $p|d$ , then there is an element $g$ of $G$ of order $p$ , but I don't know what else to do . Please help.","['finite-groups', 'group-theory', 'number-theory']"
1022899,Can one apply a WKB method to an inhomogeneous first order differential equation in order to find the asymptotic expansion of the solution?,"Consider
\begin{equation}
\varepsilon \frac{dy}{dx} = Q(x)y + R(x)
\end{equation}
where $\varepsilon$ is a small parameter.  Can one apply a WKB method to find an asymptotic expansion for the solution? I expect to obtain
\begin{equation}
y(x) \sim - \sum_{n = 0}^\infty \left(\frac{\varepsilon}{Q(x)} \frac{d}{dx}\right)^n \frac{R(x)}{Q(x)}
\end{equation}
(I am aware that this is a divergent sum), but I have been unsuccessful in recovering this form by using WKB methods.","['asymptotics', 'approximation', 'ordinary-differential-equations']"
1022907,Why don't we need to check for associativity for a subgroup?,"The textbooks I read say that it's obvious that associativity follows in a subgroup, but it doesn't explain why (since it's not obvious to me). We still have to check for closure under the operation, the identity element, and the inverse, but why does associativity immediately follow for a subgroup just because the group itself has it?","['group-theory', 'abstract-algebra']"
1022937,Spectrum of a nilpotent operator,"Let $X$ be a Banach space and $A:X\to X$ be a bounded operator such that $A^n=0$ for some $n\in \mathbb{N}$. Is the spectrum of $A$ finite, countable ?","['operator-theory', 'spectral-theory', 'functional-analysis', 'banach-spaces']"
1022966,"Rigorous proof of marginalization in probability, i.e. $P_{X}(x) = \sum_{\hat{y} \in \mathcal{Y}} P_{X,Y}(x,\hat{y})$","How do you proof the marginalization rule of probability? i.e. what is the proof for: $$P_{X}(x) = \sum_{\hat{y} \in \mathcal{Y}} P_{X,Y}(x,\hat{y})$$ I managed to get a ""picture proof"" by drawing a venn diagram and then looking at the following equation: $$ P_{X}(x) = \sum_{\hat{y} \in \mathcal{Y}} P_{X,Y}(x,\hat{y}) = P_{X,Y}(x,y) + P_{X,Y}(x,\bar{y}) $$ Which by inspecting the venn diagram: One can notice that translating $P_{X,Y}(x,y) + P_{X,Y}(x,\bar{y})$ into sets gives: $$X \cap Y$$ and $$X \cap \bar{Y}$$ Which covers the whole ""area"" of X. I guess this makes sense in this case, but I feel that there are some issues with the ""proof"". Its a proof by picture (not a real proof) Does not generalize very well for an alphabet size of more values or more random variables. Not sure how to generalize this for continuous random variables Does not feel rigorous enough (probably because of the previous reasons). I was wondering, is this just an axiom of probability or can it be derived from more basic axioms? I am having a hard time generalizing this. Also, I thought this would have been a basic result in probability and should be in the web bus was unable to find any good rigorous reference. If possible I'd like an official reference too e.g. a textbook.","['probability-theory', 'probability']"
1023022,Sum of Harmonic numbers $\sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{2^nn^2}$,"Finding the closed form of: $$\sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{2^nn^2}$$ where, $\displaystyle H_n^{(2)} = \sum\limits_{k=1}^{n}\frac{1}{k^2}$ It appears when we try to determine the summation $\displaystyle \sum_{n=1}^\infty\frac{H_n}{n^3\,2^n}$, using the generating function: \begin{align}
\sum_{n=1}^{\infty} \frac{H_n}{n^3} \, x^{n} &= - \frac{1}{2} \, \sum_{n=1}^{\infty}\frac{1}{n^2} \, \sum_{k=1}^{n} \frac{(1-x)^k}{k^2} - \frac{\zeta(2)}{2} \, \operatorname{Li}_2(x) + \frac{7 \, \zeta(4)}{8} - \frac{1}{4} \, \operatorname{Li}_2^2(1-x) + \frac{\zeta^2(2)}{4} + \operatorname{Li}_4(x) \\
& \hspace{5mm} + \frac{1}{4} \, \log^2 x \, \log^2(1-x) + \frac{1}{2}\log x \, \log (1-x) \, \operatorname{Li}_2(1-x) + \zeta(3) \, \log x - \log x \, 
\operatorname{Li}_2(1-x)
\end{align}
when we write, $\displaystyle \sum\limits_{n=1}^{\infty}\frac{1}{n^2}\sum\limits_{k=1}^{n}\frac{(1-x)^k}{k^2} = \zeta(2)\operatorname{Li}_2(1-x) + \operatorname{Li}_4(1-x) - \sum\limits_{n=1}^{\infty} \frac{H_n^{(2)}}{n^2}(1-x)^n$ Combined with Cleo's closed form here , I know what the closed form should be, but how do I derive the result ?","['closed-form', 'sequences-and-series', 'harmonic-numbers']"
1023032,Simple Trigonometric Problem,"Here is a Trig problem, and I am missing some understanding of some basic algebraic rule: $if \sin\theta= \frac{m^2 +2mn}{m^2+2mn+2n^2}$
then prove that $\tan\theta = \frac {m^2 +2mn}{2mn+2n^2},$ In the picture below can anyone explain me how did they achieve the step from 1 to 2 highlighted in red.","['trigonometry', 'algebra-precalculus']"
1023039,"If $|f(x)-f(y)|\geq \frac12|x-y|$, must $f$ be bijective? [duplicate]","This question already has an answer here : $|f(x)-f(y)|\geq k|x-y|$.Then $f$ is bijective and its inverse is continuous. (1 answer) Closed 9 years ago . Let $f:\mathbb R\rightarrow \mathbb R$ be a continuous function such that $$|f(x)-f(y)|\geq \frac12|x-y|$$ for all$x,y\in \mathbb R$. Then is $f$ one-one and onto? Let $f(x)=f(y)$ i.e. $0=|f(x)-f(y)|\geq (1/2)|x-y|$ i.e $x=y$ Hence $f$ is injective. But I am unable to conclude whether $f$ is onto.Any help","['continuity', 'real-analysis']"
1023044,Is it possible to build a tensor with the following properties?,"I am searching for a tensor in 4-dimensional space-time with two indices that satisfy: \begin{eqnarray}
M_{;\mu }^{\mu \nu } &=&0, \\
M^{\mu \nu } + M^{\nu\mu}&=&0,  \nonumber \\
M_{;\varepsilon }^{\mu \nu }+M_{;\nu }^{\varepsilon \mu }+M_{;\mu }^{\nu
\varepsilon } &=&0.  \nonumber
\end{eqnarray} An obvious choice would be the electromagnetic field strength, but I am investigating if it is possible to build a tensor with such properties that only depends on geometrical properties of the space-time manifold (metric tensor, connection). For instance, the Riemann tensor satisfies two of these properties for fixed α, β: \begin{eqnarray}
R_{;\varepsilon }^{\alpha \beta \mu \nu }+R_{;\nu }^{\alpha \beta
\varepsilon \mu }+R_{;\mu }^{\alpha \beta \nu \varepsilon } &=&0\text{ } \\
R^{\alpha \beta \mu \nu } &=&-R^{\alpha \beta \mu \nu }  \nonumber
\end{eqnarray} But I found its divergence is zero only in very special cases, such as for maximally symmetric spaces. Is there anyway to build a tensor with these properties always, or at least in not so special cases?","['general-relativity', 'tensors', 'differential-geometry']"
1023059,The inequality $x^{6}-x^{5}+x^{4}-x^{3}+x^{2}-x+3/4 >0$ holds for all $x\in\mathbb R$,"Show $\forall \ x \in \mathbb{R}:\quad  x^{6}-x^{5}+x^{4}-x^{3}+x^{2}-x+\dfrac{3}{4}>0$ My attemps: Case $x=-1$ That is true for this case Then for $x \neq - 1$: $$\dfrac 3 4 - x + x^2 - x^3 + x^4 - x^5 + x^6 = \dfrac{1 + x^7}{1 + x} - \dfrac 1 4$$ let  $g(x)=\dfrac{1 + x^{7}}{1 + x}-\dfrac{1}{4} \quad \forall x\in \mathbb{R} \backslash  \{-1\}$
then
$
\begin{align*}
g'(x)&=\dfrac {(1+x^7)'(1+x)-(1+x)'(1+x^7)}{(1 + x)^2}  \quad \forall x\in \mathbb{R} \backslash  \{-1\}\\
g'(x)&=\dfrac {(7 x^6)(1+x)-(1+x^7)}{(1 + x)^2}  \quad \forall x\in \mathbb{R} \backslash  \{-1\}\\
g'(x)&=\dfrac {7 x^6+7 x^7-1-x^7)}{(1 + x)^2}  \quad \forall x\in \mathbb{R} \backslash  \{-1\}\\
g'(x)&=\dfrac{7 x^6+6 x^7-1}{(1 + x)^2}  \quad \forall x\in \mathbb{R} \backslash  \{-1\}
\end{align*}
$ To determine the sign of the numerator $(7 x^6+6 x^7-1)$
once time let  :$ h(x)=7 x^6+6 x^7-1$
then $$h'(x)=42x^5+42x^6=42(1+x)x^5$$
$$h'(x)=0  \Longleftrightarrow x=-1 \text{or} x=0$$ thus $h$ admits a minimum on the point $x=0$
and a maximum on the point $x=-1$ or $h(-1)=0$ and $h(0)=-1$ $\lim_{x\to -\infty}h(x)=-\infty$ and $\lim_{x\to +\infty}h(x)=+\infty$
as $h(-1)=0$ and $h(0)=-1$ by Intermediate value theorem  there is $u \in(-1, 0)$ such that h(u) = 0.
i'm stuck here am i on my way ? is there any other ways to solve it","['inequality', 'calculus', 'real-analysis', 'polynomials']"
1023061,An inner product space and its proper closed subspace with trivial orthogonal complement,"I am looking to do the following: Construct an inner product space $X$ (with inner product $\langle \cdot, \cdot \rangle$ and a proper, closed subspace $Y$ of $X$ such that $Y^\perp = \{0\}$, ie $\langle x, y \rangle = 0 \ \forall y \in Y \iff x = 0$. I see that we need $X$ to be infinite dimensional, hence isomorphic to $\Bbb R^n$ with the standard dot product, and then clearly not possible, as a proper (closed) subspace has a smaller dimension. If someone could give me a hint as to how to start this construction, then I'd be most grateful, as I'm fairly stuck beyond this! As always, please make sure that the hint is reasonably minor, ie doesn't give away too much - I still want to learn from this question, not just be told the answer! The question is on a course in linear analysis.","['orthogonality', 'inner-products', 'functional-analysis']"
1023064,Coordinate-free definition of integration of differential forms?,"Let $\omega$ be an $n$-form on an oriented $n$-manifold $M$. To integrate $\omega$, we choose an atlas $(O_\alpha, (x^1_\alpha,\dots, x^n_\alpha))_\alpha$ for $M$ and a partition of unity $\phi_\alpha$ subordinate to the atlas. Then we write $\omega|_{O_\alpha} = f_\alpha \mathrm{d}x^1 \wedge \dots \wedge \mathrm{d}x^n$ and define $\int_M \omega = \sum_\alpha \int_{O_\alpha} \phi_\alpha f_\alpha dx^1\cdots dx^n$, where now the ""d""'s represent the Lebesgue measure rather than the exterior derivative of differential forms. Then we show that the result doesn't depend on the choice of atlas or partition of unity. Is there an alternate definition that avoids the coordinates? It seems to me that one should be able to define integration of a differential form in a coordinate-independent way and then derive the above formula as a consequence. It's not actually the partition of unity that bugs me the most. What really puzzles me is the way we use coordinates to ""magically"" transform our differential form into a measure. This transformation doesn't depend on a choice of coordinates, so why should we have to use coordinates to describe it?","['differential-topology', 'differential-forms', 'integration', 'differential-geometry']"
1023069,Does ultralimit of sequence change after shift?,"Let $(a_n)$ be a bounded sequence of numbers, $\omega$ be an non-principal ultrafilter on $\mathbb N$, then one can assign a limit along ultrafilter $(\omega-)\lim a_n$ to it as is said here . This limit remains the same, if one changes a finite number of the elements of sequence. But will it be shift-invariant, i.e. equal for sequences $(a_n)$ and $(a_{n+1})$? If not, can one choose an ultrafilter with this property at least for sequences with $a_{n+1}-a_n \to 0$?","['general-topology', 'logic', 'filters', 'limits']"
1023071,Calculate limit without L'Hopital,I need a some help with this. Calculate: $$\lim_{x\to\infty}\frac{\ln(x-1)}x$$ I know the answer is zero. But dont know how to handle the $\ln(x-1)$,"['limits-without-lhopital', 'calculus', 'limits']"
1023113,Finding a closed form of $\cos^n(x)$ in terms of $\cos$,"By definition we have $$\cos(x):= \frac{1}{2}\left(e^{ix}+e^{-ix} \right) $$ Using this definition and applying the binomial expansion to the right hand side I would get $$\cos^n(x)= \left(\frac{1}{2}\right)^n\sum_{k=0}^n\left(\begin{matrix} n \\ k\end{matrix}\right) e^{ixk} e^{(-ix)(n-k)} = \left(\frac{1}{2} \right)^n \sum_{k=0}^n\left(\begin{matrix} n \\ k\end{matrix}\right) e^{(2k-n)ix}$$
which looks promising, but I can't continue from there, apparently to this Wikipedia entry here there is a much more elegant form. I do of course with the above already obtain the $\cos(2k-n)$ part but there is still the $i\sin(2k-n)$ part present. Namely: $$\cos^n(x) = \frac{1}{2^n}\sum_{k=0}^n \left(\begin{matrix} n \\ k\end{matrix}\right)\left(\cos((2k-n)x)+i \sin((2k-n)x)\right) $$ It feels like an invalid argument to say that $\cos^n(x)$ is real and therefore the $i \sin(2k-n)$ part will vanish.","['trigonometry', 'binomial-theorem']"
1023130,Singular Value Decomposition in Axler's book,"In Axler's ""Linear Algebra Done Right"", he gave the singular-value decomposition as: $Tv = s_1\langle v,e_1\rangle f_1 + \cdots + s_n\langle v,e_n\rangle f_n$, where 
T is an operator; $s_1,\ldots,s_n$ are the singular values of $T$; $(e_1,\ldots,e_n)$ and $(f_1,\ldots,f_n)$ are orthonormal bases of $V$. Singular values of $T$ are defined as eigenvalues of $\sqrt{T^*T}$. $\langle ,\rangle $ is inner product. I am having trouble connecting this to the more generally used matrix representation $A=UΣV^T$. 
Matrices in Axler's book are considered as linear maps, ""with respect to some bases"". How do I understand Axler's exposition using matrices? Thank you. Update: To clarify, I was thinking from the perspective where an operator is a matrix with respect to some basis (in his book...). So an operator can be written as $M(T,(b1,...bn),(b1,...bn))$. If I apply change of basis, I get $M(I,(f1,...fn),(b1,...bn))*M(T,(e1,...en),(f1,...fn))*M(I,b1,...bn),(e1,...en))$ 
where (e1,...en) is an orthonormal basis; (f1,...fn) is another orthonormal basis given by $fi=Sei$ given by isometry $S$ from polar decomposition. $M(T,(e1,...en),(f1,...fn))$ gives me the diagonol matrix $Σ$. But how about the rest? Thanks. Update 2 :
Thanks for the answers below and I understand those. But my question is a bit specific to Axler's definition. In Axler's book, he thinks of matrix a bit differently: m*n matrix is defined as $M(T,(v_1...v_n),(w_1..w_m))$ where $T$ is a linear map from space $V$ to W, and $(v_1...v_n)$ and $(w_1...w_m)$ are bases for 2 spaces. For the $k$th column in the matrix, each entry $a_{ik}$ is defined as $Tv_k=a_{1k}w_1+...a_{mk}w_m$, so the matrix represents the linear map between the bases. So it's like ""you don't talk about a matrix without talking about $T$ and the bases"". Whether this is a good way to think about matrix is probably also a topic for debate... Anyway, now with that, I am trying to decompose: $M(T,(b_1,...b_n),(b_1,...b_n))$. I already know that the diagonol $Σ$ in SVD can be thought of as: A. $M(T,(e_1,...e_n),(f_1,...f_n))$, (where $f_i=Se_i$ given by isometry $S$ from polar decomposition $T=S\sqrt{T^*T}$), OR , B. $M(\sqrt{T^*T},(e_1,...e_n),(e_1,...e_n))$. So I would also like to know: 1. the operator 2. the bases, for the other 2 unitary matrices, no matter which one you choose for $Σ$. Thanks again.","['matrices', 'linear-algebra', 'svd']"
1023141,Remainder in the multivariate Taylor expansion,"For the function $f:\mathbb{R}\to\mathbb{R}$, I can write the Taylor expansion 
$$f(x+h) = f(x) + f'(x)h + \frac{1}{2!}f''(x)h^2 + O(h^3)$$ where the remainder is $o(h^2)$ as well. I'm confused with what is the remainder written with Big oh for the second-order expansion in the multivariate case $f:\mathbb{R}^n\to\mathbb{R}$, i.e.
$$f(\mathbf{x} + \mathbf{h}) = f(\mathbf{x}) + Df(\mathbf{x})\mathbf{h} + \frac{1}{2!}\mathbf{h}'D^2f(\mathbf{x})\mathbf{h} + O(?)$$ Should it be something like $O\left(\sum_{k,l,m}h_kh_lh_m\right)$? I know that with little oh it is simply $o(\|\mathbf{h}\|^2)$.","['multivariable-calculus', 'taylor-expansion']"
1023143,Clarifying and sketching the differences between proper and improper nodes in phase space for first-order differential equations?,"So I recently read this question: Difference between improper node and proper node for phase portrait and I find myself still needing some more concrete clarification about the differences between the two and how to draw or identify them based solely on their eigenvalues and eigenvectors (if that is even possible). Here's what I've learnt so far for first-order differentials in the phase plane - please correct me if I'm wrong: Any critical point classified as a ""node"" must either be proper or
improper. An improper node (with two eigenvectors) has trajectories which are parallel to the eigenvector near the fixed point and parallel to the second eigenvector far away from the fixed point. An improper node (with one eigenvector) has trajectories which are parallel to the eigenvector near the fixed point and then loop backwards and are parallel to the same eigenvector far away from the fixed point. A proper node (with two eigenvectors) has only straight-line trajectories which intersect the fixed point. A proper node with one eigenvector does not exist, right? Here are some examples - all pictures taken from this source (1) Proper node (stable), also known as a ""star node"" or ""nodal sink"" : λ are real, repeated and negative. Two linearly independent eigenvectors. (2) Proper node (unstable), also known as a ""star node"" or ""nodal source"" : λ are real, repeated and positive. Two linearly independent eigenvectors. (3) Improper node (stable), also known as a ""degenerate node"" : λ are real, repeated and negative. One independent eigenvector. (4) Improper node (unstable), also known as a ""degenerate node"" : λ are real, repeated and positive. One independent eigenvector. (5) Improper node (stable), also known as a ""degenerate node"" : λ are real, distinct and negative. Two linearly independent eigenvectors. (6) Improper node (unstable), also known as a ""degenerate node"" : λ are real, distinct and positive. Two linearly independent eigenvectors. So here is my flood of questions: For (1) and (2), if you were given their system of equations ($\vec{x}'=A\vec{x}$), how the hell can you get TWO eigenvectors given that $A$ would only have repeated eigenvalues?
Another way to ask this is: if $A$ has a repeated real eigenvalue, whats the difference between a matrix that gives you one or two eigenvectors? For (1) and (2), what would the trajectories look like? Just an infinite number of straight lines intersecting the center? For examples (3) and (4), is it possible to tell from the (eigenvalues and eigenvectors) in what direction (either left or right) the trajectories trail off far away and become parallel to the eigenvector? For examples (5) and (6), is it possible to tell (from the eigenvalues and eigenvectors) which eigenvector will have the trajectories become parallel to it near the fixed point (will hug it at close range so to speak)? For centers and spirals, you could take a point on one of the axis and substitute it into the system of equations to get a vector pointing in the direction the trajectories move but this method doesn't seem as viable for improper nodes - e.g. if you picked a point on (3) or (4) and got a vector, how would you know if this vector's direction represented the direction of the trajectories that had already ""looped back"" instead of the trajectories that were hugging the eigenvector near the fixed point? 
You might say ""Then don't pick a point so close to the eigenvector you silly goose!"" but how do you tell what is and isn't ""close"" enough for any example of (3) or (4)? EDIT: Figured out the answers to my own questions (I think).","['ordinary-differential-equations', 'calculus']"
1023153,Max. and Min. value of $f(\phi) = \frac{1+\cos \phi}{2+\sin \phi}.$,"Calculation of Max. and Min. value of $\displaystyle f(\phi) = \frac{1+\cos \phi}{2+\sin \phi}.$ $\bf{My\; Solution::}$ Let $\displaystyle y = \frac{1+\cos \phi}{2+\sin \phi}\Rightarrow 2y+y\sin \phi = 1+\cos \phi$ So $y\cdot \sin \phi - 1\cdot \cos \phi=1-2y\;,$ Now Using cauchy-Schwatrz Inequality, We get $\displaystyle \left((y)^2+(-1)^2\right)\cdot \left(\sin^2 \phi+\cos^2 \phi\right)\geq \left(2y\sin \phi-\cos \phi\right)^2\Rightarrow \left(y^2+1\right)\geq \left(1-2y\right)^2$ So $\displaystyle y^2+1\geq 1+4y^2-4y\Rightarrow 3y^2-4y\leq 0\Rightarrow 3y\left(y-\frac{4}{3}\right)\leq 0 $ So We get $\displaystyle 0\leq y \leq \frac{4}{3}\Rightarrow y\in \left[0,\frac{4}{3}\right]$ My Question is can we solve it Using Geometrically or using Derivative Test, If Yes Then plz explain me, Thanks",['algebra-precalculus']
1023170,Limit of a sum by integral: $\lim_{n\rightarrow\infty} \sum\limits_{i=1}^{n-1}\frac{i}{n^2}$,"I have to find the following limit by using an integral, but I have no idea what to do. $\lim_{n\rightarrow\infty}(\sum\limits_{i=1}^{n-1}\frac{i}{n^2})$ I know that $\sum\limits_{i=1}^n\int_a^bf_i(x)dx = \int_a^b \sum\limits_{i=1}^\infty f(x)dx$ if $S_n\rightarrow f$ uniformly, but I don't know if that can help me here. Thanks","['riemann-sum', 'real-analysis', 'limits']"
1023171,maximize function with two variables,"I would like to maximize the function: $f(x,y) = c[x\log(2y) + (1-x)\log(2(1-y))]$ subject to constraint that $x,y \in (0,1)$ to find a relationship between $x$ and $y$ that maximizes $f(x,y)$. My solution is: take partial derivative with respect to $y$ and set to 0: $\partial f/\partial y = c\times\partial/\partial y[x\log(2y) + (1-x)\log(2(1-y))] = 0$ I treat $x$ as constant and I believe this yields that: $x = y$, for the derivative to be zero. Questions: Is this the correct way to solve this, and how can we show $x = y$ is a maximum? I think the $2$ constant inside the $\log$ doesn't change the solution. If we had substituted any constant $z$ for $2$ in the equation, ie: $f(x,y) = c[x\log(zy) + (1-x)\log(z(1-y))]$ The result would be the same. Is that right?","['optimization', 'multivariable-calculus', 'calculus', 'functions']"
1023193,How can I prove $\pi ^2=\sum_{n=0}^{\infty }\frac{1}{(2n+1+\frac{a}{3})^2}+\frac{1}{(2n+1-\frac{a}{3})^2}$,"Proving this formula 
$$
\pi^{2}
=\sum_{n\ =\ 0}^{\infty}\left[\,{1 \over \left(\,2n + 1 + a/3\,\right)^{2}}
+{1 \over \left(\, 2n + 1 - a/3\,\right)^{2}}\,\right]
$$
if $a$ an even integer number so that
$$
a \geq 4\quad\mbox{and}\quad{\rm gcd}\left(\,a,3\,\right) = 1
$$","['sequences-and-series', 'calculus', 'number-theory']"
1023195,Infinite Series with Pi,"I have this homework problem, that I'm stuck on. We know that:$$\sum_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$$ I have to find the sum of: $$\frac{1}{1^2}+\frac{1}{3^2}+\frac{1}{5^2}+\frac{1}{7^2}+\cdots$$ I came up with this equation:
$$\sum_{n=1}^{\infty}\frac{1}{(2n-1)^2}=\sum_{n=1}^{\infty}\left(\frac{1}{2n-1}\right)^2$$ I know that the answer is $\frac{\pi^2}{8}$ I found $a=1$, but can't seem to figure it out...","['riemann-sum', 'sequences-and-series', 'calculus']"
1023210,Find the exact value of $\frac{1-2\sin\left(α\right)\cos\left(α\right)}{1-2\sin^2\left(α\right)}$.,"The task is: Given that
$0\leq \alpha \leq \pi$ is an angle with $\tan\left(\,\alpha\,\right)=3/4$, find the exact value of
$$
{1 - 2\sin\left(\,\alpha\,\right)\cos\left(\,\alpha\,\right)\over
 1 - 2\sin^{2}\left(\,\alpha\,\right)}.
$$
I have stuck with this task. Can anybody help me with this ?
( I need detailed answer ).",['trigonometry']
1023213,Find the limit of a function using the definition,"I want to prove the limit of the function sqrt(x) equals 2 using the definition of the limit of a function. The definition of the limit of a function is: Let I be an open interval that contains the point c and suppose f is a function defined on I, except possibly at the point c. Then f has limit L at c if for each e>0, there exists a number q>0 such that |f(x)-L| So far, I have the following completed: Let e>0 be given. We must find q>0 such that |sqrt(x)-2| I have completed these proofs when the function is a polynomial, but I am a little confused of where to go with this problem next. If anyone is willing to assist me, it would be much appreciated. Thank you!","['functions', 'limits']"
1023275,Showing that the dual of Banach space $l^1$ is $l^{\infty}$,"I'm trying to show that the dual of Banach space $l^1$ is isometrically isomorphic $l^{\infty}$. I've defined a linear map  $F: (l^1)^* \to l^{\infty}$ by $F(y)(x) = \sum x_n y_n$. So far I've shown that this map is well-defined and linear in x and y. Now I'm trying to show that it is norm-preserving. I can easily show that $|F(y)| \le \|y\|_{\infty} \|x\|_1$ as this is immediate from the definition. I'm now trying to show the other direction of the inequality. So far I have: Suppose $M$ is such that $|F(y) (x)| \le M\|x\|_1$. I want to try and choose a particular sequence $x$ so that $M$ must necessarily be greater than $\|y\|_{\infty}$ and then the inf over all $M$ must then be greater than $\|y\|_{\infty}$ and I will have the result. The only thing I have tried so far is the sequence $X = (1,1,...1,0,...)$ with 1's up to the nth place but unfortunately I cannot get this to work. Thanks","['lp-spaces', 'functional-analysis', 'banach-spaces']"
1023325,Surjectivity of the pullback,"I've tried to prove the naturality of the pullback of a connection. I've reduced it to the following question: Is the pullback a surjective mapping on the space of sections of a vector bundle? i.e., suppose I have a smooth vector bundle $~E\to M$, and a smooth map $~f:N\to M$. Then is
$$f^*:\Gamma(E)\to \Gamma(f^*E)$$
surjective, where $f^*E$ is the pullback bundle over $N$? It seems intuitive, but I'm struggling to prove it.",['differential-geometry']
1023336,Proof that uniform topology is finer than compact convergence topology.,"I've tried a few approaches for the last few hours but nothing really works. I already proved that the compact convergence topology is finer than the pointwise convergence topology, if this helps. To be clear, $X$ is any topological space and $Y$ a metric space. We define the uniform topology on $Y^X = \{$functions from $X$ to $Y\}$ as the topology with subbasis $\{B(f,\epsilon): f \in Y^X, \epsilon > 0\}$, where 
$$B(f,\epsilon) = \{g \in Y^X: \sup_{x\in X} d(f(x),g(x)) < \epsilon\}$$
and the compact convergence topology is generated by the collection of sets
$$B_K(f,\epsilon) = \{g \in Y^X: \sup_{x\in K} d(f(x),g(x)) < \epsilon\},$$
with compact $K \subset X$.","['general-topology', 'metric-spaces']"
1023338,can have solution of $x^4-3x^3+2x^2-3x+1=0$ using only high school methods,"can have solution of $x^4-3x^3+2x^2-3x+1=0$ using only high school methods??? i only know quadratic formula $$x =  \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}$$ i tried many algebraic manipulations and i get $(x^2+1)^2=3(x^3+x)$, so can we have solution using only high school methods? i guess i have to do an algebraic substitution to reduce $x^3+x$ to polynomial of degree 2?? i also know $$(r_1 - r_2)^2 = (r_1 + r_2)^2 - 4r_1r_2$$ where $r_1,r_2$ are roots of polynomial of degree 2","['algebra-precalculus', 'contest-math', 'polynomials']"
1023341,"Presentation $\langle x,y,z\mid xyx^{-1}y^{-2},yzy^{-1}z^{-2},zxz^{-1}x^{-2}\rangle$ of group equal to trivial group","Problem: Show that the group given by the presentation $$\langle x,y,z  \mid xyx^{-1}y^{-2}\, , \, yzy^{-1}z^{-2}\, , \, zxz^{-1}x^{-2} \rangle $$ is equivalent to the trivial group. I have tried all sorts of manners to try to show that the relations given by the presentation above imply that $x=y=z=e$. However, I am stuck and would appreciate any hints as to how I should move forward.","['algebraic-topology', 'group-presentation', 'group-theory', 'abstract-algebra']"
1023402,Surfaces on which not every pair of points is connected by a geodesic,"Let $S$ be a surface in $\mathbb{R}^3$.
I believe that, if $S$ is smooth, bounded, and closed, then,
for every pair of points $x,y \in S$, there is at least one geodesic $\gamma$
connecting $x$ to $y$.
This is because there is certainly a path between $x$ and $y$, and then one
could shorten it until it is locally shortest and is then a geodesic. Q1 . Is this correct? If so: Q2 . What are examples of
  surfaces $S$—perhaps not smooth, not bounded, and/or not closed— for which
  not every pair of points is connected by a geodesic?","['geometry', 'differential-geometry', 'riemannian-geometry', 'geodesic', 'surfaces']"
1023404,Question about the Ascoli-Arzelá Theorem proof,"Ascoli-Arzelá Thoerem : Let $K$ be a compact space and $M$ be a metric space and $C(K,M)$ be the set of continuous functions from $K$ to $M$. $H \subset C(K,M) $ is relatively compact if and only if $H$ is equicontinuous and $H(x) : = \{ f(x): f\in H\}$ is relatively compact. I want to understand the step in the implication ($\Leftarrow$). In order to show that $H$ is relatively compact I'd like to know how to prove that $\overline{H}$ is complete. $\underline{Ideas:} $ First one. Let $\overline{f}_n $ be a Cauchy sequence in $ \overline{H}$. Then for any $n$, let $f_n \in H$  such that 
\begin{equation}
d(f_n,\overline{f}_n) < 1/n
\end{equation}
As by hypothesis $\overline{H(x)}$ is compact and therefore complete, $(f_n(x))_n$ is a Cauchy sequence and we can define $f(x):= \lim_{n} f_n(x)$. There is a result that if $\overline{f}_n$ is equicontinuous  and converges punctually to $f$, then $f$ is continuous and converges uniformly. I can see that  $\overline{f}_n$ and converges punctually to $f$ but I can't see that $ \overline{f}_n $ is equicontinuous. The place where I saw this Idea says that this is by construction. I can see by construction the party that I alredy said. How to  see this? Second one. It suffices to show that $f_n \rightarrow f$ uniformly since $f$  will be continuous as uniform limit  of continuous functions. As $\overline{f}_n$ is a Cauchy sequence for all $\varepsilon >0 $ there is $n_0$ such that $n>n_0$ impllies
\begin{equation}
d(\overline{f}_n,\overline{f}_m) : = \sup_{x \in K} d(f_n(x),f_m(x)) < \varepsilon.
\end{equation}
Then, by triangle inequality and taking the limit as $m \rightarrow \infty$ in
\begin{equation}
d(\overline{f}_n,f) \le d(\overline{f}_n,\overline{f}_m) + d(\overline{f}_m, f)
\end{equation}
to obtain 
\begin{equation}
d(\overline{f}_n,f) \le \varepsilon + \lim_{m} d(\overline{f}_m, f).
\end{equation}
Then we only need to prove that
\begin{equation}
\lim_{m\rightarrow \infty} \sup_{x \in K} d(\overline{ f}_n(x),f(x)).
\end{equation}
Note that we can use the same idea to  show that $C(K,M)$ is  complete (I do not know if this is true, for example is true if $M = \mathbb{R}$). Because  if this is true $\overline{H}$ is complete because is the closure of a set contained in a in a complete space is compact. Any help will be good. I will be very grateful.","['metric-spaces', 'reference-request', 'analysis']"
1023405,Find the closed form of $\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} \frac{H_n}{kn (k+n)^3}$,"Here is a challenging double series question I wanna share with you $$\sum_{k=1}^{\infty} \sum_{n=1}^{\infty} \frac{H_n}{kn (k+n)^3}$$ together with the question: what tools would you like  employ for computing it? EDIT: thank you, no need for further work. I know how to do it now, but it's a long way.","['sequences-and-series', 'calculus', 'real-analysis', 'harmonic-numbers']"
1023408,"A sequence $a_i$ such that $|a_1-a_2|,|a_2-a_3|,\ldots$ is also permutation of the positive integers","Let $a_1,a_2,\ldots,$ be a permutation of the positive integers. Is it possible that $|a_1-a_2|,|a_2-a_3|,\ldots$ is also a permutation of the positive integer? My idea is to construct the sequence in such a way that every $a_i$ and $|a_i-a_{i+1}|$ occurs, and never repeats. So I start with $a_1=1$. At any stage, if the lowest unused $a_i$ is $m$ and the lowest unused difference $|a_i-a_{i+1}|$ is $n$, we will attempt to use them. Suppose we've constructed the sequence up to $a_i$. Then set $a_{i+1}$ to be something sufficiently high, set $a_{i+2}=a_{i+1}+n$, and $a_{i+3}=m$. Then we've used $m$ and $n$. Does this work?","['permutations', 'combinatorics']"
1023409,Why is the pole generally outside the contour loop when its outside the contour loop in 2D?,"The following contour integral is path dependent with the following results
\begin{align}
\oint_C\dfrac{dz}{z} = 
\begin{Bmatrix}
2\pi i && \text{when $z=0$ is inside C}
\\
0 && \text{when $z=0$ is outside C}
\end{Bmatrix}
\end{align} however when I think of how the complex plane can be embedded to the surface of the Riemann sphere, I realize a contradiction. A loop which does not locally enclose a pole on a closed surface, such as the Riemann sphere, encloses it globally by going the other way around the closed surface. We are taught in complex analysis that all complex infinities converge at the same point, probably in reference to the Riemann sphere? This creates a contradiction on what it means to take a contour integral around a pole and not around a pole. I am curious to know if this is a topology issue, because the difference between integrating on the complex plane versues the Riemann sphere, is there metrics are different \begin{align}
\text{plane metric} && |dz|^2  &=& dx^2+dy^2
\\
\text{sphere metric} && |dz|^2  &=& \dfrac{4}{1+x^2+y^2}(dx^2+dy^2)
\end{align} which would imply a different definition of the contour integral. Why is the pole generally outside the contour loop when its outside the contour loop in 2D?","['differential-topology', 'complex-analysis', 'contour-integration']"
1023469,Trying to understand polar coordinate vectors,"I'm trying to understand what the unit polar coordinate vectors (I'll denote them $\hat r$ and $\hat \phi$ ) are and if they form a basis for $\Bbb R^2$ . So from what I understand, $\hat r$ points radially from the center and $\hat {\theta}$ points orthogonally to $\hat r$ , as in the picture below: Then a vector $\vec v$ could be represented by a linear combination of $\vec v$ , i.e. $\vec v=a \hat r + b \hat \phi$ .  My question is, if $\{\hat r,\hat \phi\}$ is a basis of $\Bbb R^2$ , then knowing $(a,b)$ should completely specify any point, right?  But I don't understand how either $\hat r$ or $\hat \phi$ specify the angle that the vector makes with the positive $x$ -axis (or whatever that reference line is called in polar coordinates).  I can see how, if you know the Cartesian representation of $\hat r$ or $\hat \phi$ , you can then determine the other and thus specify any point, but can you specify any point in the plane without a conversion to Cartesian first?  If not, why are $\hat r$ and $\hat \phi$ even useful? Edit : Muphrid does a good job of explaining why trying to think of $\hat r$ and $\hat \phi$ as basis vectors of $\Bbb R^2$ isn't the best way to use them.  But in case anyone who reads this is interested in where they come from, how to use them, and how to derive the relations for the grad, div, and curl, I found this pretty good set of lecture notes .","['coordinate-systems', 'linear-algebra']"
1023483,Graph theory - inequality,"I'm having troubles solving the following problem which is about proving an inequality in the field of graph theory. We consider G = (V,E) a graph with n a natural number (n is the number of vertices), that doesn't contain any triangles. (so the vertices don't form any triangle inside the graph) the problem is about solving :   |E|≤ (n^2) / 4 all I know is that {u,v}∈E : deg(u)+deg(v) ≤ n (I don't know if it is relevant to the problem though...)","['graph-theory', 'discrete-mathematics', 'combinatorics']"
1023505,Showing a set of limit points of a sequence of measurable functions is measurable.,"I have been wrestling with this question and I am not sure how to solve it. Question: Let $(X, s)$ be a measure space and $\{f_n\}$ a sequence of measurable functions such that $f_n:X\to R$ with the normal Borel sigma algebra on $R$. Let $$A = \{x\in X | \lim_{n\to\infty} f_n(x)\text{ exists}\}$$ Show $A$ is measurable. .. I know we need to show $A$ is in s but I don't know how, we don't have integrals yet so this needs to be proved only using facts about measurable functions. Help would be greatly appreciated.( I saw another post on this but it did not help)","['measure-theory', 'real-analysis']"
1023509,Explicit traveling wave solution for the diffusion equation,"Find explicit formulas for $v$ and $\sigma$ so that $u(x,t)=v(x-\sigma t)$ is a traveling wave solution of the nonlinear diffusion equation $$u_t-u_{xx}=f(u)$$ where $$f(z)=-2z^3+3z^2-z$$ and assume that $\lim_{s\to+\infty}v(s)=1$, $\lim_{s\to-\infty}v(s)=0$ and $\lim_{s\to\pm\infty}v'(s)=0$. Here's what I got so far: we have $u_t=-\sigma v'(x-\sigma t)$ and $u_{xx}=v''(x-\sigma t)$, so rewrite the equation we have $$v''+\sigma v'+f(v)=0$$ This means $$v''v'+\sigma(v')^2+v'f(v)=0$$ Hence $$\sigma(v')^2=-v''v'-v'f(v)$$ Integrating both sides we have $$\sigma\int_{-\infty}^{\infty}(v'(s))^2ds=-\int_{-\infty}^{\infty}v''(s)v'(s)ds-\int_{-\infty}^{\infty}v'(s)f(v(s))ds.$$ By using the assumptions $\lim_{s\to+\infty}v(s)=1$, $\lim_{s\to-\infty}v(s)=0$ and use the change of variable $y=v(s)$ we have $$\int_{-\infty}^{\infty}v'(s)f(v(s))ds=\int_0^1f(y)dy=0$$ From $\lim_{s\to\pm\infty}v'(s)=0$ we have $$\int_{-\infty}^{\infty}v''(s)v'(s)ds=0$$ Thus $$\sigma\int_{-\infty}^{\infty}(v'(s))^2ds=0$$ At this point I cannot further proceed. Any further hints are welcomed. Thanks.","['ordinary-differential-equations', 'partial-differential-equations']"
1023517,"Is this study plan sufficiently general, or overly specialized? [closed]","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question My current study plan is in order below. I will be completing these textbooks in this order one at a time. I have been told that I don't have textbooks in my plan that approach topology in a general matter, but instead my focus is very narrow, meaning I may miss many important ideas. Question: Is this a valid concern? Is the same true for either Algebra, or Analysis? Cohn - Classic Algebra Rudin - Principles of Mathematical Analysis Lee - Topological Manifolds Cohn - Basic Algebra Rudin - Complex Analysis Lee - Smooth Manifolds Cohn - Further Algebra Rudin - Functional Analysis Lee - Riemannian Manifolds Note: My calculus is sufficiently built. For meta discussion on the close votes, please go here. List constructed with advice from comments and the one answer(added are bold). It seems to be potentially excessively long(added bold): Cohn – Classic Algebra Axler – Linear Algebra Done Right Zorich – Mathematical Analysis I Rudin – Principles of Mathematical analysis Dugundji - Topology Lee – Topological Manifolds Zorich – Mathematical Analysis II Rudin – Real & Complex Analysis Cohn – Basic Algebra J.P May – A Concise Course in Algebraic Topology Ddo Carmo - Differential Geometry of Curves and Surfaces Lee – Smooth Manifolds Cohn – Further Algebra Rudin – Functional Analysis Lee – Riemannian Manifolds","['general-topology', 'self-learning', 'abstract-algebra', 'analysis', 'learning']"
1023520,Prove that $\frac{d^n}{dx^n} (\sin^4 x + \cos^4 x) = 4^{n-1}\cos (4x + \frac{n\pi}{2})$,"Question Prove that $\frac{d^n}{dx^n} (\sin^4 x + \cos^4 x) = 4^{n-1}\cos (4x + \frac{n\pi}{2})$ My attempt First calculate $\frac{d}{dx} (\sin^4 x + \cos^4 x)$, that is, 
$$\frac{d}{dx} (\sin^4 x + \cos^4 x) =4\sin^3 x \cos x - 4\cos^3 x \sin x $$
$$= 4\sin x \cos x(\sin^2 x - \cos^2 x)$$
$$\tag {n=1} = -2\sin 2x \cos 2x = - \sin 4x$$ Now, using the value of $n=1$, I calculate the derivatives for a few more values of $n$: $$\tag {n=2} -4\cos 4x$$
$$\tag {n=3} 4^2\sin 4x$$
$$\tag {n=4} 4^3\cos 4x$$
$$\tag {n=2} -4^4\sin 4x$$ From this I observe the consistency of the $4^{n-1}$ factor. Now I will expand $\cos (4x + \frac{n\pi}{2})$, which results in $$\cos 4x \cos \frac{n\pi}{2} - \sin 4x \sin \frac{n\pi}{2}$$ From what I know of of $\sin$ and $\cos$ functions, this fits the pattern I observe in calculating the derivatives of $\sin^4 x + \cos^4 x$ My concerns I feel uncomfortable putting so much weight on observing a pattern, instead I feel I should be able to put it down in terms of mathematics . One more thing, I don't feel comfortable with From what I know of of $\sin$ and $\cos$ functions, this fits the pattern I observe in calculating the derivatives of $\sin^4 x + \cos^4 x$. , there must be a better way to relate $$\frac{d^{n-1}}{dx^{n-1}} (-\sin 4x) $$ with $$\cos (4x + \frac{n\pi}{2})$$ I would appreciate any hints, suggestions, and alternative approaches. Keep in mind that this should be approached with the tools of elementary introductory derivatives and trigonometry.","['trigonometry', 'calculus', 'derivatives']"
1023540,Can this summation be expressed differently?,"Lets say I have a sum that states the following
$$
\sum_{j=0}^{k-c} {k-c \choose j}\ln(a)^{k-c-j} \frac{d^j}{dx^j}[(x)_c]
$$
where $(x)_c$ is the falling factorial such that $$
(x)_c = x(x-1)(x-2)\cdots(x-c+1)
$$ How can I evaluate this summation? Viewing the summations partially, I know that $$
\sum_{j=0}^{k-c}{k-c \choose j}\ln(a)^{k-c-j} = \left(\frac{1}{\ln(a)}+1\right)^{k-c} \ln(a)^{k-c}
$$
But it is possible that $k-c > c$ and therefore having the summation above be incomplete due to differentiating a constant, resulting in an incomplete gamma function result seen here: http://www.wolframalpha.com/input/?i=sum+%28%28k-c%29%21%2F%28%28k-c-r%29%21%29%29ln%28y%29%5E%28k-c-r%29%2C+r%3D0..k-c%2Bn An interesting thing to note is that taking multiple derivatives of the falling factorial x results in the sum of the permutations that the falling factorial can be presented in, multiplied by the factorial of the amount of times differentiated. an example would be:
$$
\frac{d}{dx} [x(x-1)(x-2)(x-3)] = 1![x(x-1)(x-2)+x(x-1)(x-3)+x(x-2)(x-3)+(x-1)(x-2)(x-3)]
$$ $$
\frac{d^2}{dx^2} [x(x-1)(x-2)(x-3)] = 2![x(x-1)+x(x-2)+x(x-3)+(x-1)(x-2)+(x-1)(x-3)+(x-2)(x-3)]
$$
Note that the number of terms produced by taking $n$ derivatives of $(x)_c$ is directly proportional to ${n \choose c}$ Is there no defined way to express this summation? Thank you for any information in advance.","['calculus', 'analysis', 'summation', 'derivatives', 'combinatorics']"
1023571,What's wrong with this argument? (Limits),"In order to compute $\displaystyle \lim_{x \to \infty} \sqrt{9x^2 + x} - 3x$ we can multiply by the conjugate and eventually arrive at a limit value $1/6$. But what about the line of reasoning below, what is wrong with the argument and why? I can't think of a simple explanation, I had one involving the limit definition but I believe there should be a less complicated one. Here's the argument:
Clearly for large $x$ we can say $\sqrt{9x^2 + x} \approx \sqrt{9x^2} = 3x$. Hence $$ \lim_{x \to \infty} \sqrt{9x^2 + x} - 3x = \lim_{x \to \infty} 3x - 3x = 0 \ . $$ So the limit ought to be zero, easy! What goes wrong and why?","['calculus', 'limits']"
1023575,Factoring in $\mathbb{Z}[\sqrt{2}]$,"How would one factor a number, say $9+4\sqrt{2}$ in $\mathbb{Z}[\sqrt{2}]$? This is what I've attemped to do:
$$(a_1+b_1\sqrt{2})(a_2+b_2\sqrt{2}) $$
$$a_1a_2+a_1b_2\sqrt{2}+a_2b_1\sqrt{2}+2b_1b_2$$
Thus,
\begin{eqnarray}
a_1a_2+2b_1b_2&=&9 \\
a_1b_2+a_2b_1 &=& 4.
\end{eqnarray} But this results in 4 variables and only 2 equations.","['factoring', 'ring-theory', 'abstract-algebra']"
1023585,Finding the zeroes in a function,I have come across a problem on my trigonometry homework where we need to find the zeros of a function without the use of a calculator. The Equation: Given one of the zeros is $x=5$ $f(x) = x^3+2x^2-23x-60$ Is there a more efficient way to go about this problem than simply factor it out?,"['roots', 'functions', 'polynomials']"
1023630,What is the Domain of $f(x)=x^{\frac{1}{x}}$,"Find the Domain of $$f(x)=x^{\frac{1}{x}}$$ I have Confusion on Negative Real numbers. if $x=-2$  then $f(x)$ is not Real, but if $x=-3$ ,$f(x)$ is Real. I am unable to figure out which set of negative real numbers come into the Domain.Books give the Domain as $\mathbb{R^+}$","['calculus', 'analysis']"
1023663,My attempt regarding finding critical ponts of $(\cos x)(\cos y)(\cos(x+y))$,"Given this problem Restrictions on $x$ any are that $x\in[0,\pi]$ , $y\in[0,\pi]$ I have $f_x=-(\cos y)({\sin(2x+y))}--------*$ $f_y=-(\cos x)(\sin x+2y)-----------**$ So from $*$ I get either $\cos y=0$ or $\sin(2x+y)=0$ From $\sin(2x+y)=0$ , I get $2x+y=0,\pi,2\pi,3\pi$ as $2x+y\in[0,3\pi]$ And from second case I get $\cos y=0\implies y=\dfrac{\pi}{2}$ Also from $**$ , I get $x+2y=0,\pi,2\pi,3\pi$ and from $\cos x=0\implies x=\dfrac{\pi}{2}$ Now I have made $16$ cases because of following equations: $2x+y=0,\pi,2\pi,3\pi$ $x+2y=0,\pi,2\pi,3\pi$ example as like $2x+y=0$ , $x+2y=3\pi$ ....similarly $16$ cases from above equations and I point $\left(\dfrac{\pi}{2},\dfrac{\pi}{2}\right)$ After examining all cases I have got valid critical points only for cases of type $2x+y=R$ $x+2y=R$ Where $R$ is $0,\pi,2\pi,3\pi$ , taken one by one. So out of $16$ cases I have made above , I got my valid points out of $4$ cases as shown above.. MY QUESTION - Why I am getting points from these cases only ($R$ cases) ...Points from other $12$ cases are either same as that of the ($R$ cases), or they are not in domain Also am I right in making $16$ cases like this. Is this correct way of solving these equations? Is there any alternative way?? Thanks for your kind help!!","['optimization', 'trigonometry', 'systems-of-equations']"
1023681,"Is $Y$ is a Banach space if $B(X,Y)$ is a Banach space? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Improve this question Let $X$ and $Y$ be normed linear spaces, $X\ne\{0\}$. Let $B(X,Y)$ be the collection of all bounded linear operators from $X$ into $Y$ with the operator norm. Suppose that $B(X,Y)$ is a Banach space. Show that $Y$ is a Banach space.","['complete-spaces', 'functional-analysis', 'banach-spaces']"
1023691,A sufficient condition to ensure a function to be linear,"Suppose that $f$ is continuously differentiable on $\Bbb R$, and $$\lim_{x\to +\infty}f'(x)$$
exists and is finite. Furthermore, $$f(x+1)-f(x)=f'(x),\ \forall\ x\in\Bbb R.$$
Show that $f$ is linear, that is, there exists constants $a,b$ such that 
$$f(x)=ax+b,\ x\in \Bbb R.$$","['continuity', 'functions']"
1023750,"Find the volume of the region bounded by the planes $ z=8-y^2, y = 8-x^2, x=0, y=0, z=0$","I figured out the bounds for z: $z=0$ to $z=8-y^2$ The bounds for y: 
$y=0$  to  $y=8-x^2$ The bounds for x:
$x=0$ to $x=\sqrt{8}$ (Since $8-x^2 = 0$) So, the volume by using triple integral: $\int_{0}^{2\sqrt{2}}\int_{0}^{8-x^2}\int_{0}^{8-y^2}dzdydx $ Am I right?","['multivariable-calculus', 'volume', 'integration']"
1023753,"What are the irreducible components of $V(xy-z^3,xz-y^3)$ in $\mathbb{A}^3_K$?","What are the irreducible components of the algebraic set $V(xy-z^3,xz-y^3)$ in $\mathbb{A}^3_K$ ? (Here I'm letting $K$ be an algebraically closed field.) Normally, what I do is take the equations determining an algebraic set $V(I)$ , and usually one of them factors so that $V(I)$ decomposes as $V(J_1)\cup V(J_2)\cup\cdots$ or something. After breaking things down enough, I can eventually find that $K[x,y,z]/J_i$ is an intergral domain, so $J_i$ is prime, and $V(J_i)$ is irreducible. However, I don't see any obvious way to break $V(xy-z^3,xz-y^3)$ down as a union of smaller sets since neither of the polynomials factor. I think $K[x,y,z]/(xy-z^3,xz-y^3)\cong K[x]\oplus \langle y,z\rangle$ because any occurrence of $xy$ or $xz$ be be replaced with a power of $z^3$ or $y^3$ , but I'm not sure if that helps.","['commutative-algebra', 'algebraic-geometry']"
1023776,Sets of measure zero and the Lebesgue differentiation theorem.,"This is an exercise from Stein-Sharachi Chap. 3 Exx. 25 $\textbf{Problem Statement}$ Let $E$ be a set of measure zero in $\mathbb{R}^d$. Show that there exists a non-negative integrable $f$ in $\mathbb{R}^d$, so that $$\liminf_{m(B) \to 0} \frac{1}{m(B)} \int_{B} f(y) dy = \infty$$ for each $x \in E$ and $B$ is any ball containing $x$. $\textbf{My Attempt:}$. From the hint, let $f(x) = \sum_{n=1}^{\infty} \chi_{\mathcal{O}_n} (x)$, where $\mathcal{O}_n \supset E$ and $m ( \mathcal{O}_n) < \frac{1}{2^n}$. We can do this since $E$ has measure zero. Then $$\int_{\mathbb{R}^d} f(x) dx = \sum_{n=1}^{\infty} \int \chi_{\mathcal{O}_n}(x) = 1$$ and so $f$ is integrable. I know  have left out some details but the above is not where I am having difficulties. Let $B$ be any ball. From above we have that $E \subset \mathcal{O}_n$. Thus for any $x \in E$, there exists a ball $B_n \subset \mathcal{O}_n$ such that $x \in B_n$. $$ \int_B f(y) dy = \sum_{n=1}^{\infty} m ( \mathcal{O}_n \cap B) \ge \sum_{n=1}^{\infty} m ( B_n \cap B)$$ Then $$\frac{1}{m(B)} \int_B f(y) dy \ge \sum_{n=1}^{\infty} \frac{m(B_n \cap B)}{m(B)}$$ Since $x \in B_n$ is a point of Lebesgue density I have that $$\lim_{m(B) \to 0} \frac{m(B_n \cap B)}{m(B)} =1$$ This seems useful since then, $$ \sum_{n=1}^{\infty} \lim_{m(B) \to 0} \frac{m(B_n \cap B)}{m(B)} = \infty$$ and I would have my result. However, how does $\liminf$ ever come in to play? I really do not understand the significance. And how do I back up moving the limit inside of the summation?","['measure-theory', 'lebesgue-measure', 'real-analysis']"
1023796,2nd derivative test fail,"I trying to solve this problem in Advanced Calc by Buck, sec 3.6 problem 9: Let $f(x,y)=(y-x^{2})(y-2x^{2})$.
Show that the origin is a critical point for $f$ which is a saddle
point, although on any line through the origin, $f$ has a local minimum
at $(0,0)$. Solution: We have
\begin{align*}
f(x,y) & =(y-x^{2})(y-2x^{2})\\
 & =y^{2}-3x^{2}y+2x^{4}
\end{align*} so that
\begin{align*}
f_{1}(x,y) & =-6xy+8x^{3} &  & (1)\\
f_{2}(x,y) & =2y-3x^{2} &  & (2)
\end{align*}
set (1) and (2) equal to zero and solve: from (2) 
$2y-3x^{2}=0\,\Longrightarrow y=\frac{3}{2}x^{2}$ in (1) 
$-6xy+8x^{3}=0\,\Longrightarrow-9x^{3}+8x^{3}=0\,\Longrightarrow x=0,\Longrightarrow y=0$
hence (0,0) is a critical point of $f$. (0,0) is a saddle point:
By Theorem 19 page 157: If the determinant of the hessian (2nd order
partial derivatives matrix) is negative at $p_{0}$, then $p_{0}$is
a saddle point. hence
$H=\left[\begin{array}{cc}
f_{11} & f_{12}\\
f_{21} & f_{22}
\end{array}\right]=\left[\begin{array}{cc}
-6y+24x^{2} & -6x\\
-6x & 2
\end{array}\right]$ $\Delta=-12y+48x^{2}-36x^{2}=12(x^{2}-y)$ at (0,0) $\Delta=0$, therefore the second derivative test is inconclusive. However since $f(x,y)=(y-x^{2})(y-2x^{2})$, then if $x^{2}<y<2x^{2}$
we have $f(x,y)<0$, also if ($y<x^{2}$ or $y>2x^{2}$) we have $f(x,y)>0$,
and we have $f(x,y)=0$ if $x=y=0$. Therefore the critical point
(0,0) is a saddle point. I don't feel confident about the proof of (0,0) is a saddle point. Also I am not sure how to do the last part (any line through the origin, $f$ has a local minimum
at $(0,0)$) any help appreciated.","['multivariable-calculus', 'calculus']"
1023816,Why is $\arg(i\cosh x)=\frac{\pi}{2}$?,I was told $\arg(i\cosh (x))=\frac{\pi}{2}$ and $\arg(\cosh (x))=0$ but I can't figure out why. Could someone explain it to me?,"['hyperbolic-functions', 'complex-analysis']"
1023817,$\frac{\partial^2 u}{\partial t^2}-c^2\frac{\partial^2u}{\partial x^2}=0\text{ implies } \frac{\partial^2 u}{\partial z \partial y}=0$,"I have the following question: Show that if $z=x+ct$ and $y=x-ct$ then: $$\frac{\partial^2 u}{\partial t^2}-c^2\frac{\partial^2u}{\partial x^2}=0\text{ implies } \frac{\partial^2 u}{\partial z \partial y}=0$$ If I had $u$ it would follow trivially I imagine, but I don't have $u$. It would seem that $u$ is linear in $t,x$ and since $t,x$ are linear in $y,z$ it seems logically consistent, but I am not sure what to do. Perhaps this is related to harmonic functions. What should I first do to get this started? Perhaps I notice that $c=\frac{z-x}{t} \text{ and } c=\frac{x-y}{t}$ and thus $\frac{z-x}{t} =\frac{x-y}{t}\implies x-y=z-x\implies 2x=y+z$","['partial-derivative', 'wave-equation', 'partial-differential-equations', 'analysis']"
1023826,On definition of tangent vectors of a manifold,I saw the definition of tangent vector on a manifold given as: A tangent vector $v$ at a point $m$ of a smooth $n$-manifold $M$ is a linear derivation of the algebra of germs of functions at $m$. My question is: How can I see (say in a concrete example) that every linear derivation on this algebra corresponds to a tangent vector? I know it is a definition but it is clear that every tangent vector say to $S^2$ in $\mathbb R^3$ defines a linear derivation. What is less clear to me is why the other direction also holds.,['differential-geometry']
1023885,"A Partition of $[0, 1)$","Consider a sequence of disjoint nonempty intervals $[\ell_{n}, r_{n}) \subseteq [0, 1)$, $n \in \mathbb{N}$, such that $$\sum_{n = 1}^{\infty} (r_{n} - \ell_{n}) = 1,\qquad 0 < r_{n + 1} - \ell_{n + 1} \leq r_{n} - \ell_{n} < 1.
$$
My question is, need the set $$A=[0, 1) \setminus \bigcup_{n \in \mathbb{N}} [\ell_{n}, r_{n})$$ be countable? All constructions I've been able to come up with are such that $A$ is countable. Obviously, $A$ has Lebesgue measure $0$, but that does not imply that $A$ is countable.","['lebesgue-measure', 'analysis']"
1023898,Show that $A\cap B\subseteq A$ and $A\subseteq A\cup B$,$$A \cap B \subseteq A$$ My first step would be to write it as $(x \in  A \land  x \in B) \subseteq A$. Then I know  by the following implication that is always true $P \land Q \implies  P$. But I am not sure how to write it down mathematically correct. $$A \subseteq A \cup B $$ I would write it as $A \subseteq (x \in A \lor x \in B)$ . Then I know  by following implication that is always true $P \implies P \lor Q$. But again I do not know how to write in down mathematically correct. May you could help a beginner?,"['proof-writing', 'elementary-set-theory']"
1023911,Inequivalent norms (given by different inner products) on infinite dimensional Hilbert space.,"I have this question in reviewing for my exam. Let $H$ be an infinite dimensional Hilbert space. Write down an inner product on $H$ that gives a norm inequivalent with the original norm. Is $H$ complete under the norm determined by the new inner product? In my understanding, as the norm of a Hilbert space is induced by the inner product it equipped, there are different inner products , all satisfy linearity, conjugate symmetry, positive-definiteness, hence different norms. My confusion is, why the question is asking ""original norm""?  Is a Hilbert space uniquely determined by the inner product it uses? For example, the collection of square integrable functions on $R^d$ is a Hilbert space and equipped with a inner product of integral form. Finite-dimensional complex Euclidean space with dot product. Or, there is a space can be equipped with different inner product (to define its norm) to form the same Hilbert space? For example, the Euclidean space? BTW, how is this question related to the fact that. All infinite-dimensional (separable) Hilbert spaces are $l^2$$(Z)$ in
  disguise Due to my poor understanding of functional analysis, I am not sure how is this question trying to motivate my thinking. Any help would be appreciated! 
Thanks in advance!","['normed-spaces', 'inner-products', 'hilbert-spaces', 'functional-analysis']"
1023913,Commuting matrices implies upper triangular simultaneously,"Let $A_\alpha$ be a family of commuting matrices, that is, $A_\alpha A_\beta=A_\beta A_\alpha$. Show that there exists an unitary matrix $U$ such that $U^*A_\alpha U$ is upper triangular for each $\alpha$. I know that there should be something related to invariant subspaces. However, I could not proceed...",['linear-algebra']
1023917,Does a continuous point-wise limit imply uniform convergence?,"Question Given a sequence of continuous functions $(f_n)_{n \in \mathbb N}$ and define
$$
f : X \rightarrow Y, \quad f(x) = \lim_{n \rightarrow \infty} f_n(x)
$$
where $X$ and $Y$ are metric spaces. If $f$ is continuous, is it true that $(f_n)$ converges uniformly to $f$? Are there any restrictions on $(f_n)$, $f$, $X$ and/or $Y$ for this to be true? Thoughts This seems like a very useful result, yet it does not seem to be mentioned anywhere which leads me to think it is either completely obvious, or false.  This site usually has a question or two pertaining to 'obvious' results, and my attempts to find them have been unsuccessful, though I have found Dini's theorem which relaxes the condition of continuity but requires the sequence to be monotonic and $X$ to be compact. I know this statement is false if $(f_n)$ are discontinuous functions.  Take as counter-example
$$
f_n : \mathbb R \rightarrow \mathbb R, \quad f_n(x) = \begin{cases} x^n & x \in [0, 1) \\ 0 & \text{Else} \end{cases}
$$
then $f \equiv 0$ is continuous, but $(f_n)$ does not converge uniformly to it. I have attempted a proof below, and if nothing is wrong, then we require that $X$ is compact. Attempted Proof We wish to show that given $\varepsilon > 0$, there exists an $N$ such that for $n > N$, then 
$$
\forall x \in X, \quad d(f_n(x), f(x)) < \varepsilon.
$$ Since $f_n$ are continuous, then for $x \in X$, there exists a neighbourhood $N_x \subseteq X$ such that
$$
\forall y \in N_x, \quad d(f_n(x), f_n(y)) < \varepsilon
$$
and similarly with $f$. Additionally, we know that for $x \in X$, there exists $N(x) \in \mathbb N$ such that
$$
\forall n > N(x), \quad d(f_n(x), f(x)) < \varepsilon
$$ We now set $\varepsilon > 0$, and suppose there does not exist an $N$ such that for $n > N$, then $\sup_{x \in X} \{d(f_n(x), f(x))\} < \varepsilon$.  This means we can always pick some $x_0 \in X$ such that $d(f_n(x_0), f(x_0)) \geq \varepsilon$. By the triangle inequality, we have that $\forall x \in X$
$$
d(f_n(x_0), f(x_0)) \leq d(f_n(x_0), f_n(x)) + d(f_n(x), f(x)) + d(f(x), f(x_0))
$$
As $f_n$ and $f$ are continuous, then we can pick $x$ in a neighbourhood such that the first and third term are less than any $\varepsilon > 0$.  In other words, we have that
$$
d(f_n(x_0), f(x_0)) < d(f_n(x), f(x))
$$
Thus in the neighbourhood of any 'badly behaving' point, there exists another badly behaving point. If we require $X$ to be compact, then there exists a point $y \in X$ such that $d(f_n(y), f(y)) = \sup_{x \in X}\{ d(f_n(x), f(x)) \}$ (since $f_n$, $f$ and $d$ are all continuous, thus the image of the distance function must be compact too), in which case the above result would lead to a contradiction. -- Some of the answer have shown the proof to be false.  Why?","['general-topology', 'metric-spaces', 'examples-counterexamples', 'uniform-convergence']"
1023928,Richardson Extrapolation - problems understanding how it works,"I'm doing homework, and I am stumped on the first problem. I'm given this: Apply the extrapolation process described in Example 1 to determine $N_3(h)$, an approximation to $f(x_0)$, for the following functions and stepsizes. Where $f(x) = ln(x), x_0 = 1, h = 0.4$ So I go to build the table. In the reference example they use forward difference, so I will use that here. $$
N_1(0.4) = \frac{f(1.4)-f(1)}{0.4}=0.841181
\\
N_1(0.2) = \frac{f(1.2)-f(1)}{0.2}=0.911608
\\
N_1(0.1) = \frac{f(1.1)-f(1)}{0.1}=0.953102
\\
N_2(0.4) = N_1(0.2)+(N_1(0.2) - N_1(0.4)) = .982035
\\
N_2(0.2) = N_1(0.1)+(N_1(0.1) - N_1(0.2)) = .994596
\\
N_3(0.4) = N_2(0.2) + (N_2(0.2) - N_2(0.4)) = 1.077584
$$ This is wrong, according to the book this approximation should be around 1.0000109. Can anyone give me a in-depth explanation of where I'm going wrong here? I'm trying to understand this, but it doesn't help when your professor just does book examples and doesn't explain much even when asked. Thanks!","['extrapolation', 'derivatives', 'numerical-methods']"
1023933,"Two Urns contain white and black balls, drawn using a set of rules. Probability that nth ball drawn is white.","Two urns contain respectively 'a white and b black' and 'b
white and a black' balls. A series of drawings is made according to the
following rules: (i) Each time only ball is drawn and immediately returned to the same
urn it came from. (ii) If the ball drawn is white, the next drawing is made from the first urn. (iii) If it is black, the next drawing is made from the second urn. (iv)The first ball drawn comes from the first urn. What is the probability that nth ball drawn will be white ? My Attempt Probability of White ball from urn 1: $\frac{a}{a+b}$ Probability of Black ball from urn 1: $\frac{b}{a+b}$ Probability of White ball from urn2: $\frac{b}{a+b}$ Probability of Black ball from urn 2: $\frac{a}{a+b}$ I don't know how to proceed mathematically from here, but from trial and error:
$$ \sum_{i=0}^n \binom {n}{i} (\frac{a}{a+b})^{n-i} (\frac{b}{a+b})^i $$ I couldn't find this question anywhere online. Sorry if repost.. Thanks in advance!","['probability', 'combinatorics']"
1023955,Changes in the unit ball,"Given the open unit ball in $\mathbb{R}^2$ (or for any other $\mathbb{R}^n$ as well), if I use the function $f:B^2 \rightarrow \mathbb{R}^2$ that does the following: $f(x,y)= (\frac{x}{2}, \frac{y}{2} )$, will the result on the entire ball, i.e. $f(B^2)$, be the ball with a radius of $\frac{1}{2}$ (with same center)? Or perhaps with a radius of $\frac{1}{4}$? Edit: And another question is how can I move the ball to another ball with a different center point? should I add to just one ( $x$ or $y$ ) coordinate or to both? What I mean is, if I have a ball with radius $r$ and center point $x_0$ and I want to transfer this ball with to a ball with same radius $r$, just with a center $x_1$, what type of function should I need? (the same questions applies in general to $\mathbb{R}^n$, just thought $\mathbb{R}^2$ would be easier to see)",['analysis']
1023958,math question angle of elevation,"A tree is $x$ meters high. The angle of elevation of its top from a point $P$ on the ground is 23 degrees. From another point $Q$, 10 meters from $P$ and in line with $P$ and the foot of the tree, the angle of elevation is 32 degrees. Find $x$. [OP points out in the comments: if $QR=y$, then $\tan32=x/y$, so $y=x/\tan32$, and $\tan23=x/(10+y)$.]",['trigonometry']
1023963,What does constant terms for complex roots represent when drawing a phase portrait?,"For example if I have ODE where $x$ is a matrix of $x_1$ and $x_2$ 
$$x_1 ' = x_1 - 5 x_2$$
$$x_2 ' = x_1 - 3 x_2$$ and I found the solutions which are 
$$x_1  =  c_1  e^{-t}  (2  \cos(t)-\sin(t)) - c_2   e^{-t} (2 \sin(t)+\cos(t))$$
$$x_2  =  c_1  e^{-t}  \cos(t ) - c_2  e^{-t} \sin(t)$$
$c_1,c_2$ are constants Now I know that due to $e^{-t}$, it will have decaying solution as t goes to infinity
and will be unstable spiral that is moving in clockwise direction. 
However, my question is about $c_1$, $c_2$, what do these $c_1$, $c_2$ represent in the phase portrait?","['dynamical-systems', 'ordinary-differential-equations']"
1023973,Catch 22 situation involving inverting a function and finding the range of the function.,"Let $f(x) = \sqrt{x+5} - \sqrt{x-5}$ Calculating the inverse: $y = \sqrt{x+5} - \sqrt{x-5}$ $y + \sqrt{x-5} = \sqrt{x+5}$ $y^2 + x - 5 + 2y\sqrt{x-5} = x + 5$ $\frac{(10 - y^2)^2}{4y^2} + 5 = x$ Thus, $f^{-1}(x) = 5 + \frac{(10-x^2)^2}{4x^2}$ Now let's use the inverse function to calculate $f^{-1}(10)$. We get $f^{-1}(10) = 25.25$ Going back to the original function. $f(f^{-1}(10)) = f(25.25)$ should be equal to $10$. However, if we calculate, $f(25.25)$ comes out to be $1$. I had originally wanted to find the range of $f(x)$. To do that, I wanted to take the inverse and calculate the inverse function's domain (which would be the original function's range). Looking at the original function, I observed the following: 1) Taking the first derivative, it can be seen that the function is a monotonically decreasing function. 2) Domain of function is $[5, \infty)$ 3) $f(5) = \sqrt{10}$ 4) as $x \to \infty, f(x) \to 0$ Combining all $4$ points, we get the range of the function to be $(0, \sqrt{10}]$ and so, the domain of the inverse function is $(0, \sqrt{10}]$. That means that when we put $x = 10$ in $f^{-1}(x), we were outside the domain of the function. This seems to be a catch 22 situation. I wanted to take the inverse of the function $f(x)$ to calculate the range, however to be able to use the inverse function properly, I needed to know the range of the function $f(x)$ in the first place. How does one solve for the range of the function in such cases?","['algebra-precalculus', 'functions', 'inverse', 'real-analysis', 'analysis']"
1023974,Is $0^\omega=1$?,"According to a definition of ordinal exponentiation defined in Kunen's Set Theory: An Introduction to Independence Proofs (pp. 26), we define $$\begin{align}
\alpha^0&=1\\
\alpha^{(\beta+1)}&=\alpha^\beta\cdot\alpha\\
\alpha^\beta&=\bigcup\{\alpha^\gamma:\gamma<\beta\}&\text{if }\beta\text{ is a limit}.
\end{align}$$ So, it is correct to conclude that $0^\omega=1$, right? (In fact, we have $0^\beta=1$ for all limit $\beta$). This is quite surprising for me since I never think that other exponentiations of $0$, except $0^0$, can be $1$. Furthermore, there is another definition of ordinal exponentiation defined in Kunen's (pp. 43). It can be defined as follows. Let $$F(\alpha,\beta)=\{f\in{^\beta\alpha}:|\{\xi:f(\xi)\ne0\}|<\omega\}.$$ For any $f,g\in F(\alpha,\beta)$ such that $f\ne g$, say $f\lhd g$ iff $f(\xi)<g(\xi)$, where $\xi$ is the largest ordinal such that $f(\xi)\ne g(\xi)$. Then $\alpha^\beta=\operatorname{type}(\langle F(\alpha,\beta),\lhd\rangle)$. The book claims that this definition is equivalent to the above definition. But, as we can see, for $0^\omega$, we consider $F(0,\omega)$, which is $\emptyset$. So $\operatorname{type}(\langle F(0,\omega),\lhd\rangle)=0$. Which one is a correct one, or if you think none of them is wrong, which one is much more make sense to you?","['exponentiation', 'ordinals', 'elementary-set-theory']"
1023979,$p^3 + 2$ is prime if $p$ and $p^2 + 2$ are prime?,"I'm self-learning number theory. I want to prove the following statement: $$p \text{ is prime } \land \text{ }p^2 + 2 \text{ is prime } \implies p^3 + 2 \text{ is prime }$$ I failed to do so, and I failed to find any proofs online. My initial attempts involved using Fermat's Little Theorem: $$\begin{align*}
a^{p} &\equiv a \mod p \\
a^{p^2 + 2} &\equiv a \mod {p^2 + 2} \\
\end{align*}$$ But that form didn't really help me that much. Any hints?","['prime-numbers', 'number-theory']"
1023984,Combining two convolution kernels,"Is it possible to combine two convolution kernels (convolution in terms of image processing, so it's actually a correlation) into one, so that covnolving the image with the new kernel gives the same output as convolving it with the first, and then the second kernel? For example, if I want to convolve an image with 1st 3x3 kernel and then 2nd 3x3 kernel, apparently I should be able to combine those two kernels and convolve my image with this new kernel. What is the size of my new kernel? Is it 3x3? If so, there's something worrying me about that. Let me explain. Let's say I'm convolving Input image with Kernel 1, then convolving the result with Kernel 2. Pixel marked X depends on value of pixel P2 (convolving the image with kernel 2). Pixel P2 lies on the new image that was produced by convolving input image with Kernel 1. So the value of P2 was calculated with taking P1 into account. Now, X relies on values of P1 and P2.
That's what stops me from believing I could achieve the same result with convolving my original image with a 3x3 kernel combining kernel 1 and kernel 2. Pixel X cannot ""know"" anything about pixel at location P1.","['convolution', 'linear-algebra', 'image-processing']"
1024058,"If a,b,c are three distinct real numbers","If $a,b,c$ are three distinct real numbers and $$a+\frac1b=b+\frac1c=c+\frac1a=t$$ for some real number $t$ prove that $abc+t=0$",['algebra-precalculus']
1024061,"Is $x = 2$ is the only real solution for $a^x + b^x = c^x$ when $(a,b,c)$ is a pythagorean triplet?","Take any pythagorean triplet $(a,b,c)$,
we know, by the definition that:
$$a^2 + b^2 = c^2$$ But take $$a^x + b^x = c^x$$ Is $x=2$ the only possible solution $\in \Bbb R$ in this case? How can this be concluded? I conjecture that $2$ is the only solution but I am not sure how to conclusively state this fact.","['algebra-precalculus', 'proof-writing', 'pythagorean-triples']"
1024067,The Theorem on Formal Funtions - Harthshorne Theorem 11.1,"Let $f:X \rightarrow Y$ a projective morphism of noetherian schemes, let $\mathcal{F}$ be a coherent sheaf on $X$, and let $y\in Y$ be a point. For each $n\geq 1$ we define $X_n=X \times_Y Spec (\mathcal O_y/{m_y}^n) $ $\require{AMScd}$
\begin{CD}
    X_n @>v>> X\\
    @V f' V V\Box @VV f V\\
    Spec \mathcal O_y/{m_y}^n @>>v'> Y
    \end{CD} 1.For n=1, we get $X_n=X_y$ 2.For $n\geq 2$, we get a scheme with nilpotent elements having the same underlying space as $X_y$. It is kind of ""thickened fibre"" of $X$ over the point $y$. Let $\mathcal{F_n}=v^{*}\mathcal {F}$, Then we have natural maps, for each $n$ $R^{i}f_{*}\mathcal{F}\otimes \mathcal{O_y}/m_y^n\rightarrow R^{i}f'_{*}(\mathcal{F_n})$ Question - How does we get this natural map? My Attempt: We have a map 
$v'^{*}({R^if_{*}(\mathcal F)})\rightarrow R^i f'_{*}{v^*{\mathcal{F}}}=R^i f'_{*}{\mathcal {F_n}}$.  ---(1) I don't understand why is $v'^{*}({R^if_{*}(\mathcal F)})=R^if_{*}(\mathcal F)\otimes\mathcal O_y/{m_y}^n $. Since $Spec(\mathcal O_y/{m_y}^n)$ is an affine scheme concentrated at a point the right hand side of the equation is $H^i(X_n, \mathcal{F_n})^\sim =H^i(X_n, \mathcal{F_n})$ (Since the scheme is one-pointed) As n varies, both sides form inverse systems. Question: How does it forms an inverse system? What are the maps  $H^i(X_n, \mathcal{F_n})\rightarrow H^i(X_m, \mathcal{F_m})$ and $R^{i}f_{*}\mathcal F\otimes \mathcal{O_y}/m_y^n \rightarrow R^{i}f_{*}\mathcal F\otimes \mathcal{O_y}/m_y^m$ which makes them an inverse system?","['sheaf-theory', 'sheaf-cohomology', 'algebraic-geometry', 'schemes']"
1024071,Show this function has infinitely many critical points and classify;,"Show that $$f(x,y)=x^2-x+\cos(xy)$$has inifinitely many critical points and classify; Partial Derivative w.r.t. $x$ $$f_{x}=2x-1-y\sin(xy)=0$$ Partial Derivative w.r.t. $y$ $$f_{y}=-x\sin(xy)=0$$ Now trying to simultaneously solve; you get that $$\sin(xy)=\dfrac{1-2x}{x-y}$$ is that enough to show infinite solutions? And how would I classify these?, use the hessian method?","['optimization', 'multivariable-calculus']"
1024075,If N and every subgroup of N is normal in G then G/N is abelian .,"Let $N$ be a normal subgroup of a group $G$ such that every subgroup of $N$ is normal in $G$ and $C_G(N)\subseteq N $ . Prove that $G/N$ is abelian. Here, as usual, $C_G\left(N\right)$ means the centralizer of $N$ in $G$ (i.e., those elements of $G$ that commute with everything in $N$ ). I think we need to use that every subgroup of $N$ is normal in $G$ but i can't use .Please help me with Hints.","['group-theory', 'abstract-algebra', 'abelian-groups']"
1024099,Evaluating $\int e^{x\sin x+\cos x}\left(\frac{x^4\cos^3 x-x\sin x+\cos x}{x^2\cos^2 x}\right)dx$,"Evaluate $$\displaystyle \int e^{x\sin x+\cos x}\left(\frac{x^4\cos^3 x-x\sin x+\cos x}{x^2\cos^2 x}\right)dx$$ $\bf{My\; Try::}$ Let $$\begin{align}I &= \int e^{x\sin x+\cos x}\left(\frac{x^4\cos^3 x-x\sin x+\cos x}{x^2\cos^2 x}\right)dx\\
&=\int e^{x\sin x+\cos x}\left(x^2\cos x+\frac{\cos x-x\sin x}{x^2\cos^2 x}\right)dx\\
&= \int x\cdot e^{x\sin x+\cos x}\left(x\cos x\right)dx+\int e^{x\sin x+\cos x}\left(\frac{\cos x-x\sin x}{x^2\cos^2 x}\right)dx\\
\end{align}$$ Now Let $x\sin x+\cos x = t\;,$ Then $x\cos x\,dx = dt$ and Integration by parts for $\bf{1^{st}}$ Integral So $$\displaystyle I = x\cdot e^{x\sin x+\cos x}-\int e^{x\sin x+\cos x}dx+\int e^{x\sin x+\cos x}\left(\frac{\cos x-x\sin x}{x^2\cos^2 x}\right)dx$$ Now I do not understand how to solve after that.","['calculus', 'integration', 'indefinite-integrals']"
1024141,Uniqueness of the universal covering space (up to an isomorphism),"Let $Y_1$, $Y_2$ be universal covering spaces of some topological space $X$. I want to show that $Y_1$ are $Y_2$ are isomorphic. Denote $p_1 \colon Y_1 \to X$, $p_2 \colon Y_2 \to X$ the projections. Then there exist maps $f_1 \colon Y_1 \to Y_2$ and $f_2 \colon Y_2 \to Y_1$ such that $p_2 f_1 = p_1$, $p_1 f_2 = p_2$. Taking compositions we obtain 
$$
   p_1 f_2 f_1 = p_1, \\
   p_2 f_1 f_2 = p_2.
$$
We have to show that $f_2 f_1 = \mathrm{id}_{Y_1}$ and $f_1 f_2 = \mathrm{id}_{Y_2}$. Suppose that this doesn't hold, i.e. there exists $y_1 \in Y_1$ such that $f_2 f_1 (y_1) = \widetilde y_1 \neq y_1$. This implies $p_1(\widetilde y_1) = p_1(y_1)$. But I don't see a contradiction. Please help me to finish the proof.","['general-topology', 'covering-spaces']"
1024158,How to find a general sum formula for the series: 5+55+555+5555+.....?,"I have a question about finding the sum formula of n-th terms. Here's the series: $5+55+555+5555$+...... What is the general formula to find the sum of n-th terms? My attempts: I think I need to separate 5 from this series such that: $5(1+11+111+1111+....)$ Then, I think I need to make the statement in the parentheses into a easier sum: $5(1+(10+1)+(100+10+1)+(1000+100+10+1)+.....)$ = $5(1*n+10*(n-1)+100*(n-2)+1000*(n-3)+....)$ Until the last statement, I don't know how to go further. Is there any ideas to find the general solution from this series? Thanks","['geometric-progressions', 'arithmetic-progressions', 'summation', 'sequences-and-series']"
1024178,"Evaluating $\lim_{(x,y)\rightarrow (0,0)} \frac{(xy)^3}{x^2+y^6}$","$$\lim_{(x,y)\rightarrow (0,0)} \frac{(xy)^3}{x^2+y^6}$$
I don't really know how to do, but I was trying to do like that:
$a=x$, 
$b=y^2$
then I was trying to do this
$$\lim_{(x,y)\rightarrow (0,0)} \frac{ab}{a^2+b^2}$$
then I don't know no more how to do...","['multivariable-calculus', 'limits']"
1024186,Hermitian manifold counterexample,"I'm trying to come to come to grips with the notion of a hermitian manifold. Although I know some examples of hermitian manifolds, I am more interested in counterexamples: naturally occurring Riemannian manifolds which are not hermitian. Could anyone check that my (counter)example below is indeed correct? I fear that I am misunderstanding something. Relevant definitions: A linear map $J: V \to V,$ for $V$ a vector space, is said to be an almost complex structure if $J^2 =-Id.$ A Riemannian manifold $M$ is said to be hermitian if the metric $g$ is compatible with an almost complex structure $J$ on the manifold's tangent space. This means that $\langle X, Y \rangle = \langle JX, JY \rangle,$ for all $X,Y \in TM.$ On a complex manifold, there is a natural almost complex structure on $TM$ induced by the holomorphic charts. This is simply the map $\partial_x \mapsto \partial_y$ and $\partial_y \mapsto -\partial_x.$ Main Question: Let us now consider a simple 2D real surface embedded in $\mathbb{R}^3:$ the (upper half) cylinder parametrized by $(x,y) \mapsto (x, y, \sqrt{1-y^2}).$ The induced Riemannian metric can be written in the basis $(\partial_x, \partial_y)$ as \begin{pmatrix}
  1 & 0  \\
  0 & 1/(1-y^2) 
 \end{pmatrix} Now, the above parametrization can also be thought of as providing maps from $\mathbb{C}\cap \{|\text{Re}(z)|<1\}$ to the upper half cylinder, with the transition maps simply the identity and hence trivially holomorphic. The induced complex structure, in matrix form, is 
\begin{pmatrix}
  0 & 1  \\
  -1 & 0 
 \end{pmatrix} We easily compute that $J^*GJ \neq G$ (where $G$ is the matrix of the metric $g$). Hence the Riemannian metric is NOT compatible with the induced almost complex structure. Hence, the cylinder described is not a hermitian manifold. Supplemental note (feel free to ignore): Following the above arguments, I get that a necessary and sufficient condition for a real surface in $\mathbb{R}^3$ which has holomorphic transition functions to be a hermitian manifold is for the metric to be of the form \begin{pmatrix}
  a & b  \\
  -b & a 
 \end{pmatrix} Is this right?","['differential-geometry', 'complex-geometry', 'riemannian-geometry', 'complex-analysis']"
1024258,Probability: $n$ balls into $n$ holes with exactly one hole remaining empty [duplicate],"This question already has answers here : What is the correct way to think about this yet another balls/boxes problem? (4 answers) Closed 9 years ago . The question is: n balls are distributed into n holes at random. What is the probability that exactly one hole remains empty.
I came up with $$P\left(A\right)=\frac{\:\dbinom{n\:}{1}\:\dbinom{n\:-1}{1}\:\left(n-2\right)!}{n^n}$$ but was told I’m way way off. Yes, I do realize I’m awful at probability.
Thanks for the help.",['probability']
1024259,How to calculate $\int_0^{\infty}\frac{\ln(x)}{1+x^2}\ \mathrm dx$ [duplicate],"This question already has answers here : Evaluate $\int_0^\infty\frac{\ln x}{1+x^2}dx$ (7 answers) Closed 9 years ago . How does one go about calculating : $$\int_0^{\infty}\frac{\ln x}{1+x^2}dx$$ I've tried Integration by parts, and failed over and over again",['integration']
