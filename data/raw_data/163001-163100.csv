question_id,title,body,tags
2832901,Equivalence between two definitions of sheaves,"I am reading ""Notes on Grothendieck topologies, fibered categories and descent theory"", version of october 2, 2008, from Angelo Vistoli, he introduces the definition of sheaf on page $31$ , definition $2.37$ , item $ii$ : Definition $2.37$ . Let $\mathcal{C}$ be a site, $F:\mathcal{C}^{op}\rightarrow (Set)$ a functor. $(i)$ $F$ is separated if, given a covering ${\mathcal{U}_i\rightarrow\mathcal{U}}$ and two sections $a$ and $b$ in $F\mathcal{U}$ whose pullbacks to each $F\mathcal{U}_i$ coincide, it follows that $a=b$ . $(ii)$ $F$ is a sheaf if the following condition is satisfied:suppose that we are given a covering ${\mathcal{U}_i\rightarrow\mathcal{U}}$ in $\mathcal{C}$ , and a set of elements $a_i\in F\mathcal{U}_i$ . Denote by $pr_1:\mathcal{U}_i\times_{\mathcal{U}}\mathcal{U}_j\rightarrow \mathcal{U}_i$ and $pr_2:\mathcal{U}_i\times_{\mathcal{U}}\mathcal{U}_j\rightarrow \mathcal{U}_j$ the first and the second projection respectively, and assume that $pr_{1}^{*}a_i=pr_{2}^{*}a_j\in F(\mathcal{U}_i\times_{\mathcal{U}}\mathcal{U}_j)$ for all $i$ and $j$ . Then there is a unique section $a\in F\mathcal{U}$ whose pullback to $F\mathcal{U}_i$ is $a_i$ for all $i$ . If $F$ and $G$ are sheaves on a site $\mathcal{C}$ , a morphism of sheaves $F\rightarrow G$ is simply a natural transformation. A sheaf on a site is separated. I want to prove the equivalence of that definition with the one given on category theory, using equalizers: Let $\mathcal{C}$ be a Grothendieck site. A pre-sheaf of Abelian groups is a functor $F:\mathcal{C}^0\rightarrow Ab$ . A sheaf is a pre-sheaf such that for every object $\mathcal{U}$ of $\mathcal{C}$ and every covering ${\mathcal{U}_i\rightarrow \mathcal{U}}$ , the following diagram $F(\mathcal{U})\xrightarrow{Equalizer} \prod_iF(\mathcal{U}_i)\xrightarrow[g]{f}\prod_{i,j} F(\mathcal{U}_i\times_{\mathcal{U}}\mathcal{U}_j)$ is an equalizer."" Where the definition of equalizer is the following: Definition of equalizer: Let $X,Y\in\mathcal{C}$ and $f,g\in Mor(E,X)$ . An equalizer is a pair $(E,Eq)$ such that $E\in\mathcal{C}$ and $f\circ Eq=g\circ Eq$ and if there is another pair $(A,h)$ such that $A\in \mathcal{C}$ and $h\in Mor(A,X)$ such that $f\circ h= g\circ h$ , then $\exists!\Phi:A\longrightarrow E$ with $Eq\circ \Phi=h$ . Suggestions and answers will be tremendously appreciated. Thanks in advance.","['category-theory', 'sheaf-theory', 'algebraic-geometry']"
2832909,"Is the ideal $I:=\langle xy-z,x^5-z^3 \rangle $ prime in $\Bbb{C}[x,y,z]$?","Let us take the ideal $I:= \langle xy-z,x^5-z^3 \rangle $ of the ring
  $\Bbb{C}[x,y,z].$ We want to find if this ideal is prime. My thoughts: We define $f:=xy-z,\ g:=x^5-z^3 \in \Bbb{C}[x,y,z].$ The first thought is to prove that  the quotient ring $\Bbb{C}[x,y,z]/\langle xy-z,x^5-z^3\rangle$ is an integral domain. We observe that $f:=-z+xy\in \Bbb{C}[x,y][z]$ is irreducible in $\Bbb{C}[x,y][z]=\Bbb{C}[x,y,z]$ since $f$ has degree $1$ and $-1\in U(\Bbb{C}[x,y])=\Bbb{C^*}$ . And, from the general Eisenstein Criterion, we can take that $g$  is irreducible too. 1) Is it true that (since $f,g$ are irreducible ) $\gcd (f,g)=1\implies 1\in I \iff I=\Bbb{C}[x,y,z]?$ And if the answer is no, why? 2) I found in this post that although in $K[x]$  an irreducible polynomial generates a prime (maximal) ideal, now this is not always true, so we can not claim from irreducibility of $f,g$, that $I$ is prime. Could you please give me a help? Thank you in advance.","['irreducible-polynomials', 'abstract-algebra', 'ring-theory', 'maximal-and-prime-ideals']"
2832912,$\sum_{-\infty}^{+\infty}\frac{\exp(-n^2)}{1-4n^2}$ in closed form?,"I have accrossed this sum which is defined as :$\sum_{-\infty}^{+\infty}\frac{\exp(-n^2)}{1-4n^2}$ , Wolfram alpha assume that series is converges and gives $\approx 0.75229789\cdots$ , really I have tried to present that value in closed form using Inverse symbolic calculator but i didn't succeeded , Now my  question is :  to give the value of the titled series in the closed form ?","['sequences-and-series', 'convergence-divergence', 'closed-form']"
2832930,The gauss map $ N$ is surjective if the surface is compact,"I'm having trouble in solving this (classical - I think) exercise.
I have to adjust some detail. Let M be a compact and orientable surface in $\mathbb{R}^3$ with genus $g \gt 0$ and Gaussian curvature K. 1) Let $M_{+} = \{p \in M | K(p) \geq 0\}$. Show that the Gauss map $N: M_{+} \to \mathbb{S}^2$ is surjective. 2) Show that $\int_{M} |K|dA \geq 8\pi$ My attempt is: 1) Pick $\vec{v} \in \mathbb{S}^2$. Define the function $F: M \to \mathbb{R}$ with $F(p) = \vec{p} \cdot \vec{v}$. Since S is compact, F has a max $p_{0}$.
Now take $\vec{v_{0}} \in T_{p_{0}}M$. So it exists a curve $\sigma: (-\epsilon, \epsilon) \to M$ with $\sigma(0) = p_{0}$ and $\sigma'(0) = \vec{v_{0}}$. Define the function $f: (-\epsilon, \epsilon) \to \mathbb{R}$ with $f(t) = \sigma(t) \cdot \vec{v}$. It has a max in 0, fo $f'(0) = 0$ and $f''(0) \leq 0$, Now, $f'(0) = \sigma'(0)\cdot\vec{v} = \vec{v_{0}}\cdot\vec{v} = 0$. So $\vec{v} \in (T_{p_{0}}M)^{\bot} = N_{p_{0}}$. So, $N_{p_{0}} = \pm\vec{v}$. (*) Then $f''(0) = \sigma''(0)\cdot\vec{v} = II_{p_{0}}(\vec{v_{0}})\cdot\pm N_{p_{0}}$, that is always negative or positive, so Gaussian curvature is positive. My problem is (*). If I use Jordan-Brouwer theorem, I can choose a priori the normal vector pointing outside and I'm done, it will be positive. But I suppose I can conclude even without this strong theorem. My idea, but probably I'm wrong, is that if $N_{p_{0}} = -\vec{v}$ then $N_{p_{1}} = \vec{v}$ where $p_{1}$ is the minimum of F, but I don't know how to prove it. 2) Here I have simply to prove that $\int_{M_{+}} |K|dA \geq 4\pi$, then it will follow from Gauss-Bonnet.
The idea is clear: use the change of variable theorem. $\int_{M_{+}} |K|dA = \int_{N^{-1}(\mathbb{S}^2)}|\det dN|dA \geq \int_{\mathbb{S}^2}dA = 4\pi$ My problem is: can I do that? N will not be in general injective nor a diffeomorphism, so I cannot use the ""real"" change of variable theorem. I put ""$\geq$"" because intuitively I restrict the integral on a domain that makes N bijective, but I don't know if this is correct. Thanks in advance","['integration', 'differential-geometry', 'surfaces', 'curvature']"
2832934,"How to prove that $\lim_{h\to 0} \, \frac{e^h-1}{h}$","when I try to show that the derivative of exp function is 
$$\frac{\partial e^t}{\partial t}=e^t$$
I need to prove firstly that this limit is equal to 1. $$\lim_{h\to 0} \, \frac{e^h-1}{h}=1$$ If you try to use L'Hospital's rule then you need firstly to know what is the derivative of exp function that we want to prove it. If you want to use approximation of $e^\epsilon \simeq1+\epsilon$ you well found the answer '$1$' but I don't want to use this approximation because it based on the Taylor series that required also to know the derivative of exp function that we don't have it yet The only way that I can prove it, is with the definition of $e$ number  $$ \lim_{x\to\infty}\left(1+\frac{1}{x}\right)^x=e $$
so I ask if there are another way to show this limit.","['derivatives', 'exponential-function', 'calculus', 'limits']"
2832958,"Help with a limit, function to the power of a function","I have the following limit: $$y=\lim_{x\to\infty}
      \left(x\ln\left(1+\frac{1}{x}\right)\right)^{x^2\sin(1/x)}$$ From here I do the following: $$\ln(y)=\lim_{x\to\infty}x^2\sin(\frac{1}{x})ln(x\ln(1+\frac{1}{x}))=\lim_{x\to\infty}\frac{\sin(\frac{1}{x})}{\frac{1}{x^2}}\ln(\frac{\ln(1+\frac{1}{x})}{\frac{1}{x}})$$ And from here on I'm stuck with no obvious way to apply L'hopital's rule. Any tips? According to limit calculators $\ln(y)$ should have a value of $-\frac{1}{2}$ and then $y=\frac{1}{\sqrt{e}}$","['calculus', 'limits']"
2832966,Reciprocal solutions of a differential equation,"I need to show that if $a$ is a constant and $b(x)$ is a function, then $$y''+\frac{b'(x)}{b(x)}y'-\frac{a^2}{[b(x)]^2}y=0$$ has a pair of linearly independent solutions which are reciprocal and then find them. I would have thought I could just substitute in $y=u(x)+\dfrac{1}{u(x)}$ but I seem to get nowhere. Anyway, we have $y'=u'-\dfrac{u'}{u^2}$ and $y''=u''-\dfrac{u''}{u^2}+\dfrac{2(u')^2}{u^3}$ .  Therefore, we get $$u''-\frac{u''}{u^2}+\frac{2(u')^2}{u^3}+(\frac{b'(x)}{b(x)})(u'-\frac{u'}{u^2})-(\frac{a^2}{[b(x)]^2})(u(x)+\frac{1}{u(x)})=0\,.$$ tidying gives $$-\frac{u''}{u^2}+\frac{2(u')^2}{u^3}+(\frac{b'(x)}{b(x)})(-\frac{u'}{u^2})-(\frac{a^2}{[b(x)]^2})(\frac{1}{u(x)})=0\,.$$ multiply by $-u^2$ to get $$u''-\frac{2(u')^2}{u}+(\frac{b'(x)}{b(x)})(u')+(\frac{a^2}{[b(x)]^2})(u(x))=0\,.$$","['ordinary-differential-equations', 'calculus']"
2832986,"Proving the product of four consecutive integers, plus one, is a square [duplicate]","This question already has answers here : Prove that the product of four consecutive positive integers plus one is a perfect square (16 answers) Closed 2 years ago . I need some help with a Proof: Let $m\in\mathbb{Z}$. Prove that if $m$ is the product of four consecutive integers, then $m+1$ is a perfect square. I tried a direct proof where I said: Assume $m$ is the product of four consecutive integers. If $m$ is the product of four consecutive integers, then write $m=x(x+1)(x+2)(x+3)$ where $x$ is an integer. Then $m=x(x+1)(x+2)(x+3)=x^4+6x^3+11x^2 +6x$. Adding $1$ to both sides gives us: $m+1=x^4+6x^3+11x^2+6x+1$. I'm unsure how to proceed. I know I'm supposed to show $m$ is a perfect square, so I should somehow show that $m+1=a^2$ for some $a\in\mathbb{Z}$, but at this point, I can't alter the right hand side of the equation to get anything viable.",['algebra-precalculus']
2833024,Prove: $ \operatorname{Ker}(T)^\perp= \operatorname{Im}(T^*)$,Let $T:V\to V$ Prove: $ \operatorname{Ker}(T)^\perp= \operatorname{Im}(T^*)$ If $v\in  \operatorname{Im}(T^*)$ so  $\exists w\in V:T^*w=v$ but how can I continue from here? If $v\in  \operatorname{Ker}(T)^\perp$ what does it say?,['linear-algebra']
2833034,Series $\sum_{n=1}^{\infty}(-1)^n\frac{n}{(2n-1)^2}$,"I how do I evaluate this integral $$I=\int_{0}^{\pi/2}\cos^2(x/2)\ln\cot(x/2)dx?$$ I would start out by making a sub of $u=\frac{x}{2}$, $dx=2du$ $$I=2\int_{0}^{\pi/4}\cos^2(u)\ln(\cot u)du$$ We shall use the trig: $\sec^2(u)=\tan^2(u)+1$, we sneakily can write as, $\cos^2(u)=\frac{\sec^2(u)}{[\tan^2(u)+1]^2}$ $$I=-\int_{0}^{\pi/4}\sec^2(u)\frac{\ln(\tan u)}{[1+\tan^2(u)]^2}du$$ We are going to make another sub: $v=\tan(u)$, $du=\frac{1}{\sec^2(u)}dv$ $$I=-\int_{0}^{1}\frac{\ln(v)}{(1+v^2)^2}dv$$ The denominator $(1+v^2)^{-2}=1-2v^2+3v^4-4v^6+5v^8-\cdots$, I am sure it is permissible to this series $$I=-\int_{0}^{1}(1-2v^2+3v^4-4v^6+5v^8-\cdots)\ln(v)dv$$ $$I=\sum_{n=1}^{\infty}(-1)^n{n}\int_{0}^{1}v^{2n-2}\ln(v)dv$$ This can easily evalute by using integration by parts
$$J=\int_{0}^{1}v^{2n-2}\ln(v)dv=-\frac{1}{(2n-1)^2}$$ Finally we got to:
$$I=\sum_{n=1}^{\infty}(-1)^n\frac{n}{(2n-1)^2}$$ I only know that $$\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{(2n-1)^2}=G$$ Where $G$ represent the Catalan's Constant, approx to $0.91596...$","['catalans-constant', 'integration', 'sequences-and-series']"
2833062,A measure similar to variance that's always between 0 and 1?,"Consider the following histogram, obtained from around 1000 measures of distance. As you can observe, most of the data appears near the mean arond the value 5-10. I also have some isolated samples far away at values 100, 160. 1) Is there any statistical measure I can use to detect when this happens? Sometimes there are no outliers and I'm trying to detect such cases. I was thinking of thresholding variance, but I'm looking for a measure with a value in a fixed interval (e.g. always 0 to 1). 2) I'm trying to get an interval like the one in red that only includes the measures around the mean. I'm looking for a method that works for different histograms with a similar shape (number of readings and values can vary, but shape is always similar). Could you suggest me a method?","['statistics', 'standard-deviation', 'variance']"
2833066,The determinant of $T: \mathbb C^2\to \mathbb C^2$ as an $\mathbb R$-linear operator,"Suppose the determinant of a $\mathbb C$-linear transformation $T:\mathbb C^2\to \mathbb C^2$ is $a+bi$. I'm trying to prove that when $\mathbb C^2$ is identified with $\mathbb R^4$, the determinant of the $\mathbb R$-linear transformation $T:\mathbb R^4\to \mathbb R^4$ is $a^2+b^2$. I started off with a lower dimensional case: a complex-linear operator $T': \mathbb C\to \mathbb C$ must be multiplication by a complex number $a+bi$, and if I write the matrix of $T'$ w.r.t. the basis $(1,i)$ of $\mathbb C$ over $\mathbb R$, then the determinant of the matrix is $a^2+b^2$. In higher dimensional case, the complex-linear $T$ is multiplication by a $2\times 2$ matrix $$A=\begin{bmatrix}x_1+ix_2&z_1+iz_2\\y_1+iy_2&w_1+iw_2\end{bmatrix}.$$ The set $((1,0)^T,(i,0)^T,(0,1)^T,(0,i)^T)$ would be an $\mathbb R$-basis of $\mathbb C^2$. W.r.t. this basis, the matrix of $T$ is $$A'=\begin{bmatrix}x_1&-x_2&z_1&-z_2\\x_2&x_1&z_2&z_1\\y_1&-y_2&w_1&-w_2\\y_2&y_1&w_2&w_1\end{bmatrix}.$$ Am I supposed to compute the determinant of this last matrix and make sure it equals $a^2+b^2$ provided $\det A=a+bi$? It seems like a lot of calculations.","['complex-numbers', 'matrices', 'determinant', 'linear-transformations', 'linear-algebra']"
2833072,Isotopy classes of essential simple closed curves in a 4-punctured sphere,"This textbook says that it is well known that the  Isotopy classes of essential simple closed curves in a 4-punctured sphere can be identified to $\mathbb{Q}\cup\{\infty \}$. I tried to find some textbooks/pdf on google that I can find explanations to that, but I couldn't. Can anyone explain that to me? From here , I understand the case of the Torus but the case of the 4-punctured sphere looks mysterious to me.","['algebraic-topology', 'general-topology']"
2833102,Finding maximum using elementary calculus. (Using Derivatives),"I'm reading these set of online notes and it reads as following: $f(x)- P(x)$=$\frac{(x-x_0)(x-x_1)(x-x_2)}{3!}$$f'''c(x)$
where $c(x)$ is some point between the minimum and maximum
of the points in ${x, x_0, x_1, x_2}$. Then they say: Let $x_1=x_0+h$, $x_2=x_1+h$. Denote $\phi_2(x)=(x-x_0)(x-x_1)(x-x_2)$ We must compute:If we want a uniform bound for $x_0 ≤ x ≤ x_2$, we must
compute $\max\limits_{x_0\leq x\leq x_2}$ $|\phi_2(x)|$ = $\max\limits_{x_0\leq x\leq x_2}$ $|(x − x_0) (x − x_1) (x − x_2)| $. Using Calculus: $\max\limits_{x_0\leq x\leq x_2}$ $|\phi_2(x)|$=$\frac{(2h^3)}{3\sqrt3}$ at $x=x_1 \pm$$\frac{(h)}{\sqrt3}$ . I'm confused by Step 5. How did they determine that the maximum was at $x=x_1 \pm$$\frac{(h)}{\sqrt3}$ . 
I tried setting the derivative equal to $0$ but I can't seem to get the same result.  The confusing thing is that you can write $x_0$,$x_1$, $x_2$ in terms of h.  So I'm not sure if they converted $\phi_2(x)$ in terms of $x_1$'s and $h$'s.  Any help would be much appreciated. Sorry for the basic problem, I just really need to know how they derived step 5.  Thank you very much.","['derivatives', 'taylor-expansion', 'optimization', 'calculus', 'sequences-and-series']"
2833117,Why is $\sin(155^\circ)$ same as $\sin(25^\circ)$?,"I am practicing for a test and i've come across this question which asks "" What is the value of $\sin(25^\circ)$ if $\sin(155^\circ) = 0.423$? "" and I've checked on the calculator, both give same result; $0.423.$
why do they have the same value?
how would you know this without using a calculator?",['trigonometry']
2833128,Why would you take the logarithmic derivative of a generating function?,"Today, my climbing expedition scaled Mt. Sloane to request the Oracle's Extensive Insight into Sequences . The monks there had never heard of our plight, so they inscribed our query in mystical runes on a scrip of paper and took it into a room we were not permitted to enter. The Superseeker, as they called it, eventually responded with a fresh scroll, bearing (among other, more familiar, symbols) six imposing letters: LGDEGF. ""Logarithmic Derivative Exponential Generating Function,"" the monks muttered in unison as I unravelled the scroll, nodding and tittering amongst themselves. But what is such a thing? They were quick to recite that it is a function $f$ such that $$\exp\biggl(\int f(x) \,dx\biggr) = \sum_n a_n \frac{x^n}{n!}$$ for my sequence $a_n$, and that the information in the scroll pertained to this $f$, but they refused to answer any further questions. My expedition crew was well-versed in the basic science of generating functions, ordinary power series and exponential. But why might taking the logarithmic derivative of either generating function give interesting or exciting information? Where do they occur in the wild? Most importantly, where in the literature can we learn about them?","['generating-functions', 'combinatorics', 'oeis']"
2833164,"Is the ideal $J:=\langle -y^2+xz,x^5-z^3 \rangle$ prime in $\Bbb{C}[x,y,z]?$","We want to prove that the ideal $J:=\langle -y^2+xz,x^5-z^3 \rangle$
  is prime in $\Bbb{C}[x,y,z].$ My attempt. An informal thought is to take the equations $y^2-xz=0,\ x^5-z^3=0 \iff y^2=xz,\ x^5=z^3.$ From this we set $x=t^3,y=t^4,z=t^5.$ So, now we define the mapping 
$$\phi: \Bbb{C}[x,y,z]\longrightarrow \Bbb{C}[t^3,t^4,t^5],\\
f(x,y,z)\mapsto \phi(f(x,y,z)):=f(t^3,t^4,t^5).$$ It's not difficult to see that $\phi$ is an epimorphism with image $\mathrm{Im}\phi=\Bbb C[t^3,t^4,t^5].$ And $J\subseteq \ker\phi$. Questions. 1) What about $\ker \phi \subseteq J$? 
An idea is to take the division algorithm, and from this to claim that if $f\in \ker \phi\implies f=(-y^2+xz)\cdot q_1+r_1$ with $r_1\in \ker\phi,\ f= (x^5-z^3)\cdot q_2+r_2$ with $r_2\in \ker\phi$. But could this help? 2) If $J=\ker\phi,$ then (from 1st Isomorphism Theorem) $$\Bbb C[x,y,z]/\langle -y^2+xz,x^5-z^3 \rangle \cong \Bbb C[t^3,t^4,t^5] \subset \Bbb C [t],$$ so,
 $$\begin{equation} \begin{split}\Bbb C [t] \text{ is an integral domain }& \implies \Bbb C[t^3,t^4,t^5] \text{ is an integral domain } \\
& \iff \Bbb C[x,y,z]/\langle -y^2+xz,x^5-z^3\rangle \text{ is an integral domain} \\
& \iff J \text{ is prime ideal }. \end{split}\end{equation}$$
Is this claim right? 3) Are there any alternative proofs for 1) and 2) ? Thank you in advance.","['algebraic-geometry', 'abstract-algebra', 'maximal-and-prime-ideals', 'ring-theory', 'multivariate-polynomial']"
2833177,Why is a derivative defined using limits? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question From our childhood, we learn mathematics along with a gradual progression where topics are sequentially related to each other. The discussion of calculus, almost, always starts with the concept of limits . This is where most beginners start to gasp for air. The concept of limit is a disconnected concept which superficially connects algebra and calculus. Why is a derivative defined using the concept of limit?","['derivatives', 'calculus']"
2833184,Let $X$ be the connected sum of the torus with the Klein Bottle. Compute the fundamental group of $X$,"This summer I am in charge of hosting a prep course for my university's graduate qualifying examination in differential geometry/topology. I've done this before, so I'm fairly confident in my understanding of differential geometry and point-set topology. However I'm currently going through the most recent qualifying exam in the area, and, to my horror, there is an algebraic topology question on it. It is stated as follows: Let $X$ be the connected sum of the torus with the Klein Bottle. Compute the fundamental group of $X$ Now I'm reasonably familiar with fundamental groups, and to my understanding the ""connected sum"" is created by deleting a ball from each space and gluing together the resulting boundary spheres. The problem does not specify precisely where we are gluing the two spaces together, so I can only assume this doesn't change the resulting fundamental group (as is intuitively true). After doing some reading, I've come across the following version of the Seifert-van Kampen Theorem: [Corollary 70.3 in Munkres] Let $X=U\cup V$, where $U$ and $V$ are open in $X$; assume $U$, $V$, and $U\cap V$ are path-connected. Fix $x_0\in U\cap V$. If $U\cap V$ is simply connected, then there is an isomorphism
  $$
k:\pi_1(U,x_0)*\pi_1(V,x_0)\to\pi_1(X,x_0).
$$
  [Here $*$ denotes the free product.] Since the fundamental groups of the torus and Klein bottle are $\mathbb{Z}\times\mathbb{Z}$ and $<a,b:aba^{-1}b=1>$, respectively, it seems that I may apply the above theorem to say that
$$
\pi_1(X,x_0)=(\mathbb{Z}\times\mathbb{Z})*<a,b:aba^{-1}b=1>.
$$
Is this true? If so, can this representation be simplified more? I'm out of my element here, so I figure I should at least run my thoughts by more capable people than I before the prep course begins. Any comments or references to similar material is greatly appreciated. Thank you.","['algebraic-topology', 'abstract-algebra', 'general-topology']"
2833202,Homeomorphism of Borel set is Borel,"While self-studying Rudin's Real and Complex Analysis , I have come across a line saying that if $T$ is a linear transformation from $R^n$ to $R^n$ that is onto and 1-1, and is thus a homeomorphism, and $m$ is the Lebesgue measure, then $T(E)$ is a Borel set for every Borel set $E$, and thus we can define a positive Borel measure $\mu$ by defining $\mu(E) = m(T(E))$. I have a couple questions on this: How do we know that $T(E)$ is Borel for every Borel set $E$? Since $T$ is a homeomorphism it pulls back open sets to open sets, and intuitively we can write $E$ as a countable union, intersection, and complement of open sets so that $T(E)$ must pull back Borel sets to Borel sets; however, I have no idea how to best formalize this. How do we define $T(\emptyset)$? The empty set isn't a member of $R^n$, but it seems we need to have $T(\emptyset) = 0$ for $\mu(\emptyset) = 0$ to hold.","['lebesgue-measure', 'measure-theory']"
2833216,Maximizing by setting Derivative equal to 0. Stuck (struggling),"I'm having immense difficulty doing this question. Want to maximize (respect to x):
$f(x)$=$(x-x_0)(x-x_1)(x-x_2)(x-x_3)$ where $x_1-x_0=h$ $x_2-x_1=h$ $x_3-x_2=h$. Want to get the value of x in terms of $x_1$ and $h$. First I take the derivative and get: $(x-x_0)(x-x_1)(x-x_2)$ +$(x-x_0)(x-x_1)(x-x_3)+(x-x_0)(x-x_2)(x-x_3)+ (x-x_1)(x-x_2)(x-x_3)=0$ Now using the facts 1,2, and 3, I substitute for $x_0, x_2$, and $x_3 $:(Need to write everything in terms of x1 and h) $x_0$=$x_1-h$, $x_1=x_1$, $x_2=x_1+h$, $x3=h+x2=h+(x_1)+h=2h+x_1$ Then we have for the derivative: $(x-x_1+h)(x-x_1)(x-(x_1+h))$ + $(x-x_1+h)(x-x1)(x-(2h+x_1))$+ $(x-x_1+h)(x-x_1-h)(x-(2h+x_1))$+$(x-x_1)(x-x_1-h)(x-(2h+x_1))$=0. Then we have: $[(x-x_1)^2+h(x-x_1)]((x-(x_1+h))$+$[(x-x_1)^2+h(x-x_1)]((x-(2h+x_1))$+ $[(x-x_1)^2-h^2](x-(2h+x_1))$+$[(x-x_1)^2-h(x-x_1)]((x-(2h+x_1))$=0 This is all I have but I can't solve for x still.  Wolfram Alpha won't give me answer.  Any help would be much appreciated thank you.  I believe the max value of f(x) should be (like max y value): $f(x)=9/16$. or $(f(x)=72/128)$
Thank you.  I have been working on this problem for over three hours so any help would really be appreciated. Here is the actual question I'm working on for reference: 5 Part c.  Where Theorem 1 is given to be:","['derivatives', 'taylor-expansion', 'optimization', 'calculus', 'sequences-and-series']"
2833245,On The Parametric Equation Of A Parabola,"Let's look at a parabola with an equation $(y-k)^2=4a(x-h)$. I'm struggling to understand why its parametric equation would be $x=h+at^2$ and $y=k+2at$. Since it is being subtracted by $h$ and $k$ respectively, why would its $x$ and $y$ values increase/have $h$ and $k$ added to them instead? I understand that since each $x$-value is being subtracted by $h$, each $x$-value needs to be $h$ bigger to ""achieve"" the same y-value. But that also means that for each $y$-value, each $x$-value will be h smaller right? So how does subtracting by $h$ increase the value of $x$ by $h$, as shown in the parametric equation $x=h+at^2$? I ask the same question for $y=k+2at$. Anyways, I have no idea what the ""x"" output the parametric equation gives out even means? Does the parametric equation give out the x-value which will be inputted into the equation? But then no matter where the graph is, that doesn't change what x-value would be inputted into the equation, right? So why would subtracting x by h change the parametric equation of x either, if x will remain unchanged? Or does the parametric equation give out the x-value as in the x-value to be plotted on the graph? But then if so, I still don't get why the sign would be +h, instead of -h. Yes, in the graph, for every y-value, the x-value of a graph y^2=4a(xx-h) would be left of the original graph. But how do we know the parametric equation refers to the x-value for every given y-value. And if that is not what is referred to by the parametric equation, why are we subtracting? Can someone explain this to me as simply as possible, since I'm still a beginner. I'm just putting this as a precaution, and try not to use Calculus in the response, since I haven't learnt it yet.","['algebra-precalculus', 'parametric', 'intuition', 'functions']"
2833248,Find $x$ if $\frac1{\sin1°\sin2°}+\frac1{\sin2°\sin3°}+\cdots+\frac1{\sin89°\sin90°} = \cot x\cdot\csc x$ [duplicate],"This question already has an answer here : Finite Series - reciprocals of sines (1 answer) Closed 6 years ago . If $$\dfrac1{\sin1°\sin2°}+\dfrac1{\sin2°\sin3°}+\cdots+\dfrac1{\sin89°\sin90°} = \cot x\cdot\csc x$$ and $x\in(0°,90°)$, find $x$. I tried writing in $\sec$ form but nothing clicked. Any ideas?","['algebra-precalculus', 'telescopic-series', 'summation', 'trigonometry']"
2833254,Wrong proof for the variance of a sum of normally-distributed variables?,"I'm reading the book ""Introduction to Error Analysis"" by John R. Taylor. The author is discussing the probability distribution of a sum of two normally-distributed random variables, and wants to show that if $x \sim N(0,\sigma_x^2)$ and $y\sim N(0,\sigma_y^2)$, then $x+y \sim N(0, \sigma_x^2 + \sigma_y^2)$. He proceeds to prove this, but either there's something I'm seriously missing, or the proof is extremely hand-wavey (or just plain wrong). In particular, I don't see how you can take a term involving $x$ and $y$, call it $z$, and then conveniently integrate w.r.t. $z$ as if it were independent of $x$ and $y$. I'm quoting the proof below, with some slight formatting modifications to make typing it out easier. Thank you for your help. $\Pr(x,y) \propto \exp\left[-\frac{1}{2}\left(\frac{x^2}{\sigma_x^2} +
 \frac{y^2}{\sigma_y^2}\right)\right]\quad\quad\quad$ (5.53) Knowing the probability of obtaining any $x$ and $y$, we can now
  calculate the probability for any given value of $x+y$. The first step
  is to rewrite the exponent in (5.53) in terms of the variable of
  interest, $x+y$. This step can be done using the identity (which you
  can easily verify) $ \frac{x^2}{A} + \frac{y^2}{B} = \frac{(x+y)^2}{A+B} + \frac{(Bx-Ay)^2}{AB(A+B)}  \quad\quad\quad$ (5.54) $= \frac{(x+y)^2}{A+B} + z^2 \quad\quad\quad (5.55) $ In the second line I have introduced the abbreviation $z^2$ for the
  second term on the right of (5.54) because its value does not interest
  us anyway. If we substitute (5.55) into (5.53), replacing $A$ with $\sigma_x^2$
  and $B$ with $\sigma_y^2$, we obtain: $ \Pr(x,y) \propto
 \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 +
 \sigma_y^2)}\right) - \frac{z^2}{2} \right]\quad\quad\quad$ (5.56) This probability for obtaining given values of $x$ and $y$ can just as
  well be viewed as the probability of obtaining given values of $x+y$
  and $z$. Thus, we can rewrite (5.56) as $ \Pr(x+y,z) \propto
 \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 +
 \sigma_y^2)}\right)\right] \exp\left[- \frac{z^2}{2}\right]
 \quad\quad\quad$ (5.57) Finally, what we want is the probability of obtaining a given value of
  $x+y$ irrespective of the value of $z$. This probability is obtained
  by summing, or rather integrating, (5.57) over all possible values of
  $z$, that is, $ \Pr(x+y) = \int \limits_{-\infty}^{\infty} \Pr(x+y,z)\,dz
 \quad\quad\quad (5.58) $ When we integrate (5.57) with respect to $z$, the factor
  $\exp(-z^2/2)$ integrates to $\sqrt(2\pi)$, and we find $ \Pr(x+y) \propto \exp\left[-\frac{1}{2}\left(\frac{(x+y)^2}{(\sigma_x^2 +
\sigma_y^2)}\right)\right] \quad\quad\quad $ (5.59)","['normal-distribution', 'fake-proofs', 'proof-verification', 'statistics', 'probability']"
2833284,Find orbit of element in Banach space,"Let $\mathcal{B}_1,\mathcal{B}_2$ be some Banach spaces, then
$$S=\left\{A:\mathcal{B}_1\to\mathcal{B}_2\big|\left\lVert A\right\rVert\leqslant1\right\}\subset\mathcal{L}\left(\mathcal{B}_1,\mathcal{B}_2\right)$$
is a closed uniball in a linear continuous operator space. Let $x\in\mathcal{B}_1$ be some fixed element. I have a task to find an orbit of such point, which is denoted as:
$$\text{Orb}\left(x\right)=Sx=\left\{Ax\big|A\in S\right\}$$ I think, such orbit would be a closed ball of radius $\left\lVert x\right\rVert$ in $\mathcal{B}_2$, but I don't know how to prove it. The furthers I got is that $\text{Orb}\left(x\right)\in\left\{y\in\mathcal{B}_2\big|\left\lVert y\right\rVert\leqslant\left\lVert x\right\rVert\right\}$. What should I do next?","['functional-analysis', 'banach-spaces', 'operator-theory']"
2833321,Infinite Product Expansion of Hyperbolic Functions,"the following equation is from ""[1970] Goodson - Distributed system simulation using infinite product expansions"": \begin{align*}
	\cosh z + \left( c z+ \frac{d}{z} \right) \sinh z & = (1 + d)  \displaystyle\prod_{n=1}^{\infty} \left( 1 + \frac{z^2}{p_n^2} \right)\\
\tan p_n & = \frac{p_n}{c p_n^2 - d}, \quad p_n \ge 0, \text{real}
\end{align*} I am not sure if $p_n \ge 0$ is correct, I guess it is $p_n >0$ instead. Maybe someone can give a reference (e.g. a book) where to find the derivation of this equation (or just the equation itself)? This would help me a lot! Best","['hyperbolic-functions', 'infinite-product', 'weierstrass-factorization', 'analysis']"
2833345,"Evaluating $\int_{\frac{-1}{2}}^{\frac{1}{2}} \int_{\frac{-1}{2}}^{\frac{1}{2}} \frac{x^2}{(x^2+y^2)^2 \log^2(\frac{2}{\sqrt{x^2+y^2}})} \,dx\,dy.$","$$\int_{\frac{-1}{2}}^{\frac{1}{2}} \int_{\frac{-1}{2}}^{\frac{1}{2}} \frac{x^2}{(x^2+y^2)^2 \log^2(\frac{2}{\sqrt{x^2+y^2}})} \,dx\,dy.$$ I encountered this integral while evaluating norm of a function. The first attempt was to change it into polar coordinates, which didn't work well, since the region of integration is rectangular. I found a similar integral here , but even WolframAlpha couldn't calculate this. Does anybody know how to evaluate this?","['multivariable-calculus', 'multiple-integral', 'integration', 'calculus']"
2833367,The Abel-and-Cain Urn Problem,"An urn contains three distinguishable kinds of balls, say $A,B,C$. Abel bets to get, in $t$ trials with replacement, at least one ball of kind $A$ and at least one ball of kind $B$. Cain bets to get, in $t$ trials with replacement, exactly $t$ balls of kind $C$. We want Abel and Cain to have the same chance to win. My solution is : No matter the number of balls of each kind in the urn, if Abel and Cain have the same chance to win at the end of the game, then it must be $t=2$. My reasoning is : Abel can win at any trial between $2$ and $t$, whereas Cain can possibly win only at the end of the game. Since we asked that at the end of the game Abel and Cain must have the same chance to win, then the last trial must represent the only possible success also for Abel , and this implies $t=2$. Is this reasoning correct? A further question, which might be a bit naive (or even silly), so please apologize me in that case: How do we take into account (e.g. in terms of conditional probability) the fact that Cain already knows that Abel cannot win at the first trial and that Abel already knows that Cain cannot win at any trial a part the last one? EDIT : I attach this scheme to explain the reasoning (see also the comments for further details). Here we interpret each trial as a shot. And the probability to get a success for Abel in each trial $k$ as a target of a certain area (green targets, top scheme). The area of the $Ab_k$ targets increases as $k$ increases, and the area of the target in correspondence of $t$ is $Ab_t=p$. For Cain, there is only one target (blue target, bottom scheme), the last one, since he cannot win in the middle of the game. The area of his last target is $Ca_t=q$. The request is that $p=q$, in correspondence of the last trial. Now, Abel can hit a target (and therefore win the game) at any trial (a part the first one). So if the last one has the same area for Abel and Cain, there must be only one target, otherwise Abel has more chance to win.","['gambling', 'game-theory', 'fair-division', 'probability', 'combinatorics']"
2833413,"What is a ""closed subvariety""?","I'm studying algebraic geometry from the classical viewpoint in which the Zariski topology takes center stage and schemes have yet to be invented. I sometimes see the term ""closed subvariety"" thrown around, but I can't find a proper definition for this. For example on p.43 of J.S. Milne's notes we find: PROPOSITION 2.27. Let $V$ be an irreducible variety such that $k[V]$ is a unique factorization domain. If $W\subseteq V$ is a closed subvariety of dimension $\mathrm{dim}(V)-1$, then $I(W)$ is a principal ideal. (In this context $I(W)$ means the set of all polynomials that vanish on $W$.) I'm not quite sure what a closed subvariety is. Isn't every variety automatically closed?",['algebraic-geometry']
2833443,How to confirm the $k$-th power of this matrix?,"For any $k \in \mathbb N$, $$\begin{bmatrix}2&-2\\0.5&0\end{bmatrix}^k = \begin{bmatrix}k+1&-2k\\k/2&-(k-1)\end{bmatrix}$$ I found this empirically using numerical computation, but I cannot prove it. I have tried computing the eigendecomposition, but this matrix is not diagonalizable.","['matrices', 'linear-algebra']"
2833475,"Proof verification : $X_n \to X$ in distribution, $Y_n \to 0$ in probability $\implies$ $X_nY_n \to 0$ in probability","I have to show : $X_n \to X$ in distribution, $Y_n \to 0$ in probability $\implies$ $X_nY_n \to 0$ in probability. Let $\alpha>0, \epsilon>0$. Then $\exists \delta>0$ such that $-\epsilon/\delta$, $\epsilon/\delta$ are continuity points of distribution of $X$ and $$P(|X|>\epsilon/\delta) \leq \alpha$$ Since $X_n \to X$ in distribution, $P(X_n \leq x) \to P(X \leq x)$ for all continuity points $($and in particular $-\epsilon/\delta$ and $\epsilon/\delta)$. There exists $N_1, N_2 \in \mathbb{N}$ such that
$$n \geq N_1 \implies |P(X_n \leq -\epsilon/\delta) - P(X \leq -\epsilon/\delta)|<\alpha$$
$$n \geq N_2 \implies |P(X_n \leq \epsilon/\delta) - P(X \leq \epsilon/\delta)|<\alpha$$
Let $N=\max\{N_1,N_2\}$. Then for $n \geq N$, $$P(|X_n|>\epsilon/\delta)=1-P(|X_n| \leq \epsilon/\delta)=1-P(-\epsilon/\delta \leq X_n \leq \epsilon/\delta) = 1-P(X_n \leq \epsilon/\delta)+P(X_n < -\epsilon/\delta) = 1-P(X_n \leq \epsilon/\delta)+P(X_n \leq -\epsilon/\delta 
\,\,[\text{by continuity}] \leq 1-P(X \leq \epsilon/\delta)+P(X \leq -\epsilon/\delta)+2\alpha = P(|X|>\epsilon/\delta)+2\alpha \leq 3\alpha$$ Since $Y_n \to 0$ in probability, $\exists$ $N_3 \in \mathbb{N}$ such that
$$n \geq N_3 \implies P(|Y_n|>\delta) \leq \alpha$$ Choose $N^{*}=\max\{N,N_3\}$. Note that
$$|X_nY_n|>\epsilon \implies |X_n|>\epsilon/\delta \,\,\text{or}\,\, |Y_n|>\delta$$
Hence,
$$P(|X_nY_n|>\epsilon) \leq P(|X_n|>\epsilon/\delta \,\,\text{or}\,\, |Y_n|>\delta) \leq P(|X_n|>\epsilon/\delta)+P(|Y_n|>\delta)$$
Thus,
$$n \geq N^{*} \implies P(|X_nY_n|>\epsilon) \leq 4\alpha$$
Since, $\alpha>0$ is arbitrary, $X_nY_n \to 0$ in probability. Is the proof okay? I have a feeling that I have sort of over-killed it. Is it possible to write a shorter proof of the result? Thank you.","['alternative-proof', 'probability-theory', 'proof-verification', 'convergence-divergence', 'random-variables']"
2833504,Friends pairing problem,"I came across this question: Given $n$ friends, each one can remain single or can be paired up with some other friend. Each friend can be paired only once. Find out the total number of ways in which friends can remain single or can be paired up. The recursive solution for this problem is: Let $f(n)$ be the number of ways $n$ people can remain single or pair up. Then,
  $$f(n) = f(n - 1) + (n - 1) * f(n - 2)$$ For the $n$-th person there are two choices: the $n$-th person remains single, we recur for $f(n - 1)$ the $n$-th person pairs up with any of the remaining $n - 1$ persons. We get $(n - 1) * f(n - 2)$ Can anyone please elaborate this solution.
Thanks!","['combinatorics', 'recursion']"
2833580,Sum of 2 raised to the power of every element in a line of Pascal’s triangle,"I know that the elements of a line in Pascal’s triangle add up to $2^n$ . What about: $$\sum_{k=0}^n 2^{\binom{n}{k}}$$ For example, line $n = 2$ adds up to $8$. $n = 3$ adds up to $20$. Is there any formula?","['summation', 'binomial-coefficients', 'sequences-and-series']"
2833589,About a sum that looks like a determinant,"I want to prove the following equality. $$\sum_{\sigma\in S_n}\frac{\text{sgn}(\sigma)}{|\text{Fix}(\sigma)|+1}=(-1)^{n+1}\frac{n}{n+1},$$
  where $\sigma$ is a permutation on $n$ elements and $\text{sgn}, \text{Fix}$ stand for the sign of the permutation and the fixed points of the permutation. The sum reminds me of a determinant since, but I can't see how would
$$\prod_{i=1}^na_{i,\sigma(i)}=\frac{1}{|\text{Fix}(\sigma)|+1}.$$ I tried also looking at the element on the right hand side. The $\frac{1}{n+1}$ reminds me of two things, one could be an alternating geometric series and the other one is the integral of $x^n$. My instinct tells me that matrix whose determinant is this must not be very complicated, I feel there must be some symmetries as well. If you can provide any insight or hints it would be very much appreciated.","['matrices', 'permutations', 'determinant']"
2833614,If all the $k$-minors of a matrix are non-zero then its rank is greater than $k$?,"Let $A$ be a $d \times d$ real matrix, and let $1<k<d$. Suppose that all the $k$-minors of $A$ are non-zero. Is it necessarily true that $\text{rank}(A)>k$? I am looking for a counter-example. When $k=1$, this is obviously false; take $A=\begin{pmatrix} 1 & 2 \\\ 1 & 2 \end{pmatrix}$. All the entries of $A$ (the $1$-minors) are non-zero, but $\text{rank}(A)=1$. Is there an easy way to generalize this example to $k>1$? Comment: In the converse direction, we do know that $\text{rank}(A)>k$ implies there are many non-zero $k$-minors; There exist a non-zero $k+1$-minor; omitting any row and column participating in this minor, we obtain a non-zero $k$-minor. Thus we have at least $(k+1)^2$ non-zero $k$-minors. This lower bound is sharp; there exist matrices of rank $k+1$ with exactly $(k+1)^2$ non-zero $k$-minors- e.g. take $\text{Id}_{k+1 \times k+1} \otimes O_{d-k-1  \times d-k-1}$.","['matrices', 'matrix-rank', 'linear-algebra', 'determinant']"
2833624,Horizontal and vertical bundles,"Consider the smooth fiber bundle $$F\to E \xrightarrow{\pi}B.$$ The vertical bundle $\mathcal{V}\subset TE$ is uniquely defined to be the kernel of $d\pi$. By choosing some Riemannian metric $g$ on $E$, we can also define a horizontal bundle $\mathcal{H}\subset TE$ as the $g$-orthogonal complement of $\mathcal{V}$, i.e. $$\mathcal{H}=\mathcal{V}^{\perp}=(\ker d\pi)^{\perp}.$$ Then the tangent bundle of $E$ decomposes as $TE=\mathcal{V}\oplus \mathcal{H}$. Is it true that $\mathcal{H}$ and $TB$ are isomorphic vector bundles? Here is my idea for trying to prove it: Pointwise, $d\pi_p:\mathcal{H}_p\to T_{\pi(p)}B$ is an isomorphism of vector spaces since $\pi$ is a submersion (i.e. $d\pi$ is a surjective linear map) and the restriction of $d\pi_p$ to $\mathcal{H}_p$ is injective by construction: $\mathcal{H}_p\cong T_pE/\ker(d\pi_p)$. Thus, in one direction, we have the vector bundle morphism $(\pi:E\to B,\;d\pi:\mathcal{H}\to TB)$ induced by $\pi$. For the inverse morphism, let $\varphi:B\to E$ be a global section of $\pi$ and define the vector bundle morphism $(\varphi:B\to E,\;(d\pi)^{-1}:TB\to\mathcal{H})$. Does this work? My concern is that there may not exist a global section $\varphi$ of $\pi$. Thanks for your help.","['vector-bundles', 'differential-geometry']"
2833683,Proving that the Cantor Set is perfect,"In his book ""The elements of Cantor Sets - With Applications"" the author Robert Vallin defines on page 102 that a set $A$ is called perfect if $A$ is equal to the set of it's limit points. Immediately after that he cites the Cantor Set as an example for a perfect set. I do not find this conclusion trivial, do I overlook something
? 
I already know that the Cantor set is compact. Could you explain this to me please?","['general-topology', 'cantor-set']"
2833697,"Is there an ""easy"" way to prove the general version Hall's Marriage Theorem?","Hall's theorem: Suppose that $\mathcal{R}$ is a relation, $A=\mathrm{dom}(\mathcal{R})$ and $B=\mathrm{ran}(\mathcal{R})$ are finite, $h(A')=\{b\in B\mid \exists a\in A'\text{ such that } a\mathcal{R}b\}$ for $A'\subseteq A$ , and that $|A'|\leq|h(A')|$ for all $A'\subseteq A$ . Then there exists an injection $f:A\to B$ such that $f\subseteq\mathcal{R}$ . I have two questions regarding this theorem. I have spent a week to give a shot, but I'm not sure if it contains error. Please check my below proof. We will prove this theorem by induction on $|A|$ . It's clear that the theorem is true for $|A|=1$ . Assume it is true for $|A|=n$ . For $|A|=n+1$ . Consider two cases. a. $|A'|<|h(A')|$ for all $A'\subseteq A$ Let $A_1=A-\{a\}$ for some $a\in A$ , and $b\in h(\{a\})$ . Then $|A_1|=n$ . For all $A'\subseteq A_1$ , $|A'|<|h(A')|\leq|h(A')-\{b\}|+1$ . So $|A'|\leq |h(A')-\{b\}|$ . Since the theorem is true for $|A|=n$ , there is an injection $f':A_1\to B-\{b\}$ such that $f'\subseteq\mathcal{R}$ . Since $(a,b)\notin f'$ and $(a,b)\in\mathcal{R}$ , $f=f'\cup\{(a,b)\}$ is the required function. b. There exists $\varnothing\neq A^{*}\subseteq A$ such that $|A^{*}|=|h(A^{*})|$ Let $A_1=A-A^{*}$ . We will prove that for all $A'\subseteq A_1,|A'|\leq |h(A')-h(A^{*})|$ . Assume the contrary, there exists $A'\subseteq A_1$ such that $|A'|>|h(A')-h(A^{*})|$ . Therefore, $|A'\cup A^{*}|=|A'|+|A^{*}|>|h(A')-h(A^{*})|+|h(A^{*})|=|(h(A')-h(A^{*}))\cup h(A^{*})|$ $=|h(A')\cup h(A^{*})|=|h(A'\cup A^{*})|.$ To sum up, $|A'\cup A^{*}|>|h(A'\cup A^{*})|$ . This contradicts the fact that $|A'\cup A^{*}|\leq|h(A'\cup A^{*})|$ [Since $A'\cup A^{*}\subseteq A$ ]. Thus for all $A'\subseteq A_1,|A'|\leq |h(A')-h(A^{*})|$ . So there is an injection $f_1:A_1\to B-h(A^{*})$ such that $f_1\subseteq\mathcal{R}$ . We also have an injection $f_2:A^{*}\to h(A^{*})$ such that $f_2\subseteq\mathcal{R}$ . Since $f_1\cap f_2=\varnothing$ , $f=f_1\cup f_2$ is the required function. Is there any ""easy"" way to prove the more general version of this theorem in which $A$ is NOT necessarily finite, i.e. $A$ can be infinite. I read one proof from https://proofwiki.org/wiki/Hall%27s_Marriage_Theorem/General_Set and figured out one possible mistake ( I posted a thread to confirm this mistake at Is this a mistake in the proof of Hall's Marriage Theorem from https://proofwiki.org? , but have not received any answer). Besides containing a possible error, the proof in that link appeals to Cowen-Engeler Lemma which appeals to Ultrafilter Lemma. I'm not exposed to any of these knowledge. I would like to ask if there is any way to prove the more general version without using Cowen-Engeler Lemma or Ultrafilter Lemma.","['elementary-set-theory', 'proof-verification']"
2833750,Compute $\prod_{j=1}^{n-1}\sin\left(\frac{\pi j}{2 n}\right)$,"How can I evaluate $\prod_{j=1}^{n-1}\sin\left(\frac{\pi j}{2 n}\right)$ ? 
I know that without the factor $2$ one can take advantage of the roots of the unity, but in this case only the roots with positive imaginary parts are to be considered. Thanks in advance.","['complex-analysis', 'trigonometry']"
2833774,What Makes a Ruled Surface Rational,"I am new to the study of algebraic geometry and have decided to study it for a personal project of mine. As such I have been trying to understand what differentiates a rational and an irrational ruled surface. What I know: A ruled surface takes the parametric form of $x(u,v)=b(u)+vd(u)$ $b(u)$ is the directrix curve and $d(u)$ is the director curve. What I think I know: A ruled surface is rational if the genus of the directrix is 0 The genus of the directrix (base curve) can be calculated from its degree as such $g=0.5(d-1)(d-2)$ If the ruled surface can be parameterized such that $b(u)$ takes the form of a line then $b(u)$ is the line of striction My question: is a ruled surface with the directrix defined by the parametric equation of a line a rational ruled surface even if the parameterization of the director is irrational? For example. Let: $b(u)=<X_0+x*u, Y_0+y*u, Z_0+z*u,>$ $d(u)=<\sqrt{ X_0+x*u }, \sqrt{ Y_0+y*u }, \sqrt{ Z_0+z*u },>$ Given b(u) is a line of degree 1 its genus is 0 thus the surface is a rational ruled surface.
Is my logic correct or am I misunderstanding?","['surfaces', 'algebraic-geometry']"
2833782,Are there always matrices $X$ and $Y$ such that $XY=A$ and $YX=B$?,"Fix a natural number $n$ and let $A,B\in\mathbb{C}^{n\times n}$. Are there matrices $X,Y\in\mathbb{C}^{n\times n}$ such that $XY=A$ and that $YX=B$? A necessary condition for that to happen is that $A$ and $B$ have the same characteristic polynomials . But this condition is not sufficient: if $A=\operatorname{Id}_n$, then $XY=A\implies YX=A$. So, my question is: are there necessary and sufficient conditions about $A$ and $B$ so that the problem has a solution?","['matrices', 'matrix-equations', 'linear-algebra']"
2833821,Coupling continuous random variables,"Let $X,Y$ be random variables with densities $f_X(x)=x^{-2}1_{[1,\infty)}$ and $f_Y(x)=3x^{-4}1_{[1,\infty)}$. How do I couple these such that $X\leq Y$ with probability 1? Attempt: I know that they intersect at $x=\sqrt{3}$. Then $f_Y(x)>f_X(x)$ for $x<\sqrt{3}$ and $f_Y(x)<f_X(x)$ for $x>\sqrt{3}$. Now we want to find random variables $X'$ and $Y'$ with joint probability function $P'$ such that its marginals return $X$ and $Y$ and $X'\leq Y'$. How do I do this?","['probability-theory', 'probability']"
2833828,Is the integral less than $\frac{n!}2?$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Knowing that $$\int_0^\infty x^n\exp(-x)\,dx=n!,$$
can we prove the following inequality: $$\int_0^n x^n\exp(-x) \,dx< \frac{n!}2 \;\;?$$",['integration']
2833888,"Prove that if $ \operatorname{Gal}(K/F) \simeq \Bbb{Z}/2\Bbb{Z}\times\Bbb{Z}/2\mathbb{Z}$, then $K = F(\sqrt{a},\sqrt{b})$ for some $a,b \in F$","Let $F$ be a field of characteristic not $2$, and let $K$ be a Galois extension with $[K:F] = 4$. Prove that if $\operatorname{Gal}(K/F) \simeq \mathbb{Z}/2\mathbb{Z}\times\mathbb{Z}/2\mathbb{Z}$, then $K = F(\sqrt{a},\sqrt{b})$ for some $a,b \in F$ I showed that If $F$ is a field of characteristic not $2$, and $K$ is an extension
  of $F$ with $[K: F] = 2$, then $K = F (\sqrt{a})$ for some $a
\in F$. Using an idea like this . But I couldn't use that same idea to prove this case. Can someone help me? EDIT. Since $\operatorname{Gal}(K/F)$ is Klein group, there is subgroup $H$ of order $2$ and by the Fundamental Theorem of Galois Theory, there is a subfield $L$ of $K/F$ with $L \leftrightarrow H$ such that $[L:F] = [G:H] = 2$ and so, $[K:F] = [K:L][L:F] = [K:F(\sqrt{b})][F(\sqrt{b}):F]$. Can I to apply this result to $[K:F(\sqrt{b})]$ too?","['abstract-algebra', 'galois-theory', 'extension-field']"
2833941,Prove that $f(x) = x - {\lfloor}x{\rfloor}$ is periodic.,"How do I prove that $f(x) = x - {\lfloor}x{\rfloor}$ is periodic and find its minimal period? I've taken the following steps: Let $x = x_0 + \Delta{x}$ where $x_0 \in \mathbb Z$ and $\Delta{x} \in [0;1)$. I need to prove that for given $x$ and $T$: $f(x) = f(x+T)$ where $T$ is some period to be defined.
Let $T = n + \Delta{T}$ where $n \in \mathbb N$ and $\Delta{T} \in [0, 1)$ $$
f(x) = f(x+T) \\
x- {\lfloor}x{\rfloor} = x+T - {\lfloor}x+T{\rfloor} \\
x_0+\Delta{x} - {\lfloor}x_0+\Delta{x}{\rfloor} = x_0 + \Delta{x} + n +\Delta{T} - {\lfloor}x_0 + \Delta{x} + n + \Delta{T}{\rfloor}
$$ So since $\Delta{x} \in [0;1)$ and $x_0 \in \mathbb Z$ then ${\lfloor}x_0+\Delta{x}{\rfloor} = x_0 +{\lfloor}\Delta{x}{\rfloor}$. Based on that LHS may be rewritten as: $$
x_0+\Delta{x} - {\lfloor}x_0+\Delta{x}{\rfloor} = \Delta{x} - {\lfloor}\Delta{x}{\rfloor} = \Delta{x}
$$ At the same time: $$
x_0 + \Delta{x} + n +\Delta{T} - {\lfloor}x_0 + \Delta{x} + n + \Delta{T}{\rfloor} = \\
= (x_0 + n) + \Delta{x} + \Delta{T} - (x_0 + n) - {\lfloor}\Delta{x} + \Delta{T}{\rfloor} = \\
= \Delta{x} + \Delta{T} - {\lfloor}\Delta{x} + \Delta{T}{\rfloor}
$$
That means that for LHS and RHS to be equal $\Delta{T}$ must be equal to $0$, hence $T=n+\Delta{T} \in \mathbb N$. And the smallest natural number is $1$, which gives that the function is indeed periodic and its minimal period is $1$. Is the proof above valid?","['algebra-precalculus', 'ceiling-and-floor-functions', 'functions', 'proof-verification']"
2833942,Sum of infinite series $ {1+ \frac{2}{6} + \frac{2\cdot5}{6\cdot12} + \frac{2\cdot5\cdot8}{6\cdot12\cdot18} + \cdots}$.,"Prove that $1+ \frac{2}{6} + \frac{2\cdot5}{6\cdot12} + \frac{2\cdot5\cdot8}{6\cdot12\cdot18} +\cdots=4^{\frac13}$ I tried it in the backward method... I rewrote $4^{\frac13}$ in this way... 
$(1+3)^{\frac13}$ and expanded it in the binomial expansion method, but it doesn't help in any way.",['sequences-and-series']
2833959,Why do we need a finite measure to have this theorem?,"Here is the theoerem 6.2.4 given in “Ross Leadbetter -A basic course of measure and probability” Let $(X,\mathfrak{M},\mu)$ be a finite measure space. Let $f_n,f$ be measurable (real) functions on $X$ . Then, $f_n\to f$ $\mu$ -a.e. iff $\mu(\limsup_n \{x:|f_n(x)-f(x)|\geq \epsilon\})=0$ for each $\epsilon>0$ . This seems obviously true for arbitrary measure space. However, the author emphasize that this thereom holds for a finite measure space.. Why do we need a finiteness condition here? Am I missing something?","['real-analysis', 'examples-counterexamples', 'measure-theory']"
2833989,Is this :$\int_{-\infty}^{+\infty} \frac{\exp(1-ix)}{x^2+1}=\pi$?,"I have tried to evaluate this integral:$$\int_{-\infty}^{+\infty} \frac{\exp(1-ix)}{x^2+1}$$  playing by denominator $x^n+1$ , I have accrossed for $n=2$  a value is close to $\pi$ as shwon here in wolfram alpha , Now my question is to know what is the exact value of that integral ? is it $\pi$ ? Note : $i$ is the unit imaginary part","['integration', 'convergence-divergence']"
2833997,Representations and classes of square group (D4),"The Group of symmetries of the square (D4) has an order of 8.
There are 2 classes in the group (correct me if Im wrong). These classes are: One class made of rotations in the plane of the square, of $0$ (identity), $\pi/2$, $\pi$ and $3 \pi /2$. Also 4 rotations with axis inside the plane: two across the diagonals of the square and two perpendicular to the sides by the middle. Using the ""dimensionality theorem"", which says that the order is equal to the sum of the square of the dimensionalities of the possible representations, I get $2^2+2^2=8$, meaning that there are 2 representations of order 2. One of this representations has the first class represented with these matrices: $\begin{bmatrix} 
    1 & 0 \\0 & 1
\end{bmatrix}$,
$\begin{bmatrix} 
    0 & -1 \\1 & 0
\end{bmatrix}$, 
$\begin{bmatrix} 
    -1 & 0 \\0 & -1
\end{bmatrix}$,
$\begin{bmatrix} 
    0 & -1 \\1 & 0
\end{bmatrix}$ And the second class represented as: $\begin{bmatrix} 
    -1 & 0 \\0 & 1
\end{bmatrix}$,
$\begin{bmatrix} 
    1 & 0 \\0 & -1
\end{bmatrix}$,
$\begin{bmatrix} 
    0 & 1 \\1 & 0
\end{bmatrix}$,
$\begin{bmatrix} 
    0 & -1 \\-1 & 0
\end{bmatrix}$ But my problem is that the traces of a same class should be the same (correct me again if im wrong), and the first class has 1 matrix of $Tr=2$, 1 of $Tr=-2$ and two of $Tr=0$. The second class has every matrix with $Tr=0$. I immediately thought that the classes I choose were wrong, and that I have 3 classes. But it doesn't have sense for me because, if I have 3 classes I cant fulfill the dimensionality theorem, as there isn't any sum of square integers which is equal to 8. What I am missing? There are 2 or 3 classes? Im choosing wrong the members of the classes?","['finite-groups', 'representation-theory', 'group-theory']"
2834034,A plague spreading on a graph,"This is a problem I heard from a friend. I didn't figure it out, so I want to post it here because it's quite an interesting problem. The island pictured below is made up of nine towns. One day, a plague arrives at $G$. Though the citizens do their best to contain the plague, each road between an infected and uninfected village has a $10\%$ chance every day to spread it to the uninfected one. How long do we expect it to take until the whole population is infected?"" My attempt: Probability is not my strong suit, so I couldn't get very far with this problem. The naive way to go about it is to build a probability tree, but I feel like there has to be a simpler way to do with the degrees of the vertices. The problem I keep running into, though, is that you can easily calculate probabilities for the first day - 10% to each neighboring town, 20% overall, but past that you have too many possible infection maps to do any meaningful calculations. I also just noticed that the last node to be infected (in terms of probability) will be the farthest from $G$, which is $A$ - 4 edges away. Because each day there is a 10% chance of one of those edges being infected, we have an average time of $10*4$=40 days to get to $A$. Is this a correct solution? If not, what is the solution to this problem? EDIT: The answers posted thus far have been amazing, but this problem was given to mathematically talented high school students so there has to be a simple solution (in terms of math used, not the argument itself). I'll be offering a bounty for such an answer when it's available.","['graph-theory', 'probability']"
2834037,Perturbation of injective map.,"I've got stuck on a result I am not able to prove. I will extrapolate it from its context: Let$\space$ $f$  be a linear injective map between $\mathbb{R}^n $ and $\mathbb{R}^m $ with $n \leq m$ and $g$ be a linear isomorphism in  $\mathbb{R}^n $. Let $ || \space ||$ be some consistent $m \times n$ matrix norm. Then exists $\epsilon >0$ such that for every $A$, $||A|| < \epsilon$ we have that: $f+Ag$ is still injective. Can someone help? Thanks :)","['real-analysis', 'functional-analysis', 'linear-transformations', 'linear-algebra', 'analysis']"
2834056,Calculating volume using cylindrical coordinates.,"A solid $D$ is defined by the following inequalities: $$\begin{align}x^2+y^2+(z-1)^2 &\le 1\\ z^2 &\le x^2+y^2\end{align}$$ Calculate the volume of $D$. Attempt to solve: $$\begin{align}x&=r\cos\theta \\ y&=r\sin\theta\end{align}$$ Plugging in these values into the first equation we get : $$\begin{align}
r^2+(z-1)^2&=1 \\
(z-1)^2&=1-r^2 \\
z&=1\pm\sqrt{1-r^2}
\end{align}$$ Since $z^2=r^2$ from the 2nd inequality, we'll have $z=\pm r$. Solving for $r$: $$r=1+\sqrt{1-r^2} \implies r=1$$ and $0<\theta<2\pi$. However, I'm confused about how to define the limits of $z$ since it could be equal to $1+\sqrt{1-r^2}$ or $1+\sqrt{1-r^2}$. Thanks in advance.","['multivariable-calculus', 'integration', 'calculus', 'cylindrical-coordinates']"
2834063,Why are 'finite morphisms' important in algebraic geometry? And what does a module of finite type mean?,"Linear transformations, Group, ring, $k$-algebra morphisms and many other types of morphisms that appear throughout mathematics are more or less obvious in the sense that we can clearly see why they are defined the way they are. Then we have continuous maps as morphisms in the category $\mathrm{Top}$ that look tricky in the way they're defined, but we don't mind them a lot because we have seen them long before we learned about morphisms and they are familiar to us. However, I have been struggling to understand why we need to define 'finite morphisms' in algebraic geometry. What do they help us achieve? What properties do they preserve? Why are they interesting? We already have a notion of morphism between algebraic varieties seen as 'spaces with functions' which seems quite natural and reasonable to me as it is. Why do we need another type of morphism between algebraic varieties? And more importantly, what does it mean for a $B$-module $A$ to be of finite type? Is it related to the concept of a finite morphism?","['morphism', 'algebraic-geometry', 'abstract-algebra', 'commutative-algebra', 'category-theory']"
2834064,Which group of order 24 is this group?,"I have a group $G$ which is presented as $$\langle g, m \mid m^{12} = 1, g^2 = 1, gm = m^5g\rangle$$ That is, $G$ is a semidirect product $C_2 \rtimes C_{12}$, but it is not the usual semi-direct product. The action $C_2 \to Aut(C_{12})$ sends $$g \mapsto (m \mapsto gmg^{-1} = m^5)$$ I am vexed! It is not obviously the usual dihedral or dicyclic group. If we try to put it in the form of the dicyclic group, with $\langle a, x \mid a^{12} = 1, x^2 = a^6, x^{-1}ax = a^{-1}  \rangle$ we find that setting $a = g$, and $x = gm$ does not satisfy the last relation. Which of the familiar groups of order 24 is this beastie?","['finite-groups', 'abstract-algebra', 'group-theory']"
2834075,Continuous antipodal map $f: S^2 \to S^1$,"I want to show that there is no continuous map $f: S^2 \to S^1$ with property $f(-x) = -f(x)$ for all $ x \in S^2$. My ideas: By asuming that there exist such map $f$ and the fact that the fundamental group $\pi(S^2) =0$ vanishes, $f$ must factorise through universal covering $\mathbb{R}$ of $S^1$. 
I suppose that the key might be considering paths $\gamma:[0,1] \to S^2$ with some properties like $\gamma(0)= -\gamma(1)$ or something similar, mapping it via $f$ to $S^1$ and lifting them. But I don't see how to derive here a contradiction to the assumption. Intuitively I guess that one maybe can break here the uniqueness lifting therorem, but I don't find the concrete examples.","['general-topology', 'homotopy-theory']"
2834081,Finding limit of multivariable function.,"I have a question that might be silly but I need to understand these kind of problems. So i have this limit:$$\lim_{(x,y)\to(0,0)} \frac{x^3 + y^3}{x^2 + y^2}$$
To solve it I am going to use poolar coordinates, so the limit would be like this: $$\lim_{r\to0} \frac{r^3\cos^3\theta + r^3\sin^3\theta}{r^2}=$$
$$\lim_{r\to0} {r(\cos^3\theta + \sin^3\theta)}$$ Now it is clear to me that r tends to $r\to0$ but, can I actually say something about $\cos^3\theta + \sin^3\theta?$
In case I could, then I would say that it is bounded, thus the limit would be 0. But it is not clear to me, could anyone help me with this?","['multivariable-calculus', 'polar-coordinates', 'limits']"
2834091,"$ \int^1_0 \max\{f_1(x), . . . , f_n(x)\} \, dx \leq C $, $f_n \geq 0$ and $f_n \to 0$, then $f_n \to 0$ in $L^1(0,1)$","Let $f_n \in L^1(0, 1)$ and $C > 0$ be such that $f_n \geq 0$, $f_n \to 0$ a.e. in $(0, 1)$, and
$$ \int^1_0 \max\{f_1(x), . . . , f_n(x)\} \, dx \leq C $$
for every $n$. Prove that $f_n \to 0$ in $L^1(0,1)$. My solution. I define $g_n(x)=\max\{f_1(x), . . . , f_n(x)\}$. First of all I observe that $0\leq f_n \leq g_n$ a.e. The sequence $g_n$ is increasing and positive, then there exists a function $g\geq 0$ (eventually $g\equiv +\infty$) such that $g_n\to g$ a.e. By monotone convergence theorem we get
$$ \int^1_0  g\, dx = \lim_{n\to\infty}\, \int^1_0  g_n \, dx\leq C  ,$$
then $g\in L^1(0,1)$ (and in particular a.e. finite). Now we are in position to use the ""generalized"" dominated convergence theorem (e.g. Variant of dominated convergence theorem, does it follow that $\int f_n \to \int f$? ). Do you agree with my proof ? I am also interested in different kind of solution. Thanks in advance. Update: it is not necessary to use the generalized DCT. If fact, since $g_n$ is increasing, we have $0\leq f_n \leq g_n \leq g$. So we can use the classical DCT using $g$ as dominant function for the sequence $f_n$. My mistake.","['alternative-proof', 'proof-verification', 'lebesgue-integral', 'measure-theory', 'convergence-divergence']"
2834100,World Cup: what group stage result (vector) is most likely?,"In the World Cup 2018 group stage, a group consists of 4 teams, and every team plays every other team once, for a total of 6 games.  A team gets 3 points per win, 1 point per draw, 0 point per loss.  After all 6 games, the teams are ranked by total number of points. Let $v$ be the sorted 4-vector of total points.  E.g. $v=(9,6,3,0)$ represents a group where there are no draws, the top team beats all others, the 2nd top team beats the other two, and the 3rd top team only beats the worst team.  Similarly, $v=(3,3,3,3)$ represents a group where all 6 games are drawn. (Note: only a small number of different vectors are possible.  This was asked in World Cup Standings but has no posted answer.) My question is: which $v$ is most likely?  Obviously this depends on the probability model.  For the purpose of this question, assume (unrealistically) that each game is i.i.d., has probability $p$ of being drawn, and each team wins with equal probability ${1-p \over 2}$. What I seek: as a function of $p$, which $v$ is most likely? Further comments: Obviously, for any given value of $p$, the solution can be found numerically (exactly and/or Monte Carlo with high precision).  However, I'm hoping for a more intuitive answer using e.g. symmetry arguments, graph theory, entropy(?!) etc. I'm also interested in transitions as $p$ changes from $0$ to $1$. (E.g. as $p$ goes from $0$ to $1$, the $Prob(v=(3,3,3,3))$ also goes from $0$ to $1$, but at what point does $(3,3,3,3)$ become the most likely?) If you can't solve the general problem, it might still be interesting to know the answer for ""typical"" values of $d$.  E.g. as of this writing - the last games of Groups E & F just finished - there are 9 draws out of 44 games, so $p=9/44 \approx 0.2$. Lastly, one possible approach which I thought about for a bit but didnt make much progress: the problem might be easier if, instead of varying $p$, we vary the number of draws $D \in [0,6]$.  I.e. conditioned on $D$ draws out of 6 games, which $v$ is most likely?  This may provide an intermediate step to answering my original question (because $D$ is distributed $Binomial(6,p)$). [Off topic] Good luck to all remaining teams... and may all future VAR decisions be non-controversial!  :)","['combinatorics', 'recreational-mathematics', 'probability']"
2834163,A finite group is isomorphic to a subgroup of $GL_n(\mathbb Z)$,"I'm trying to prove that any finite group $G$ of order $n\ge 2$ is isomorphic to a subgroup of $GL_n(\mathbb Z)$. My thoughts: By Cayley, $G$ is isomorphic to a subgroup of $S_n$. Now I need to establish somehow a connection between $S_n$ and $GL_n(\mathbb Z)$. In the case of $n$ small, say $n=2$, $S_3$ acts on $\{e_1,e_2,e_1+e_2\}$, and this action is faithful, which gives an injective homomorphism $GL_2(\mathbb Z)\to S_3$. But a) I guess I need a homomorphism to the other direction (in this case this is an isomorphism, but for larger $n$ it is not I believe) and b) I don't know how to generalize this for larger $n$.","['abstract-algebra', 'group-theory', 'linear-algebra']"
2834195,Solve parametric differential equation using Mathematica,"Using the method of characteristics on a PDE system, I have gotten a parametric differential equation
$$
\frac{dy}{dx} = \frac{y - xy}{1 + xy - x}.
$$
where $x$ and $y$ are both functions of a third variable $t$. How could I use Mathematica to solve for the solution curve that $(x(t), y(t))$ follows? There is a similar approach done here: Does this simple 2D dynamical system have a conserved quantity? . EDIT: The system where this came from is
\begin{align*}
\frac{dx}{dt} &= x - xy \\
\frac{dy}{dt} &= 1 + xy - y
\end{align*} EDIT2: Just to be clear, I know how to draw solution curves with Mathematica. What I am wondering if there is a way to solve the equation analytically and get a closed form curve as the solution.","['mathematica', 'parametric', 'ordinary-differential-equations', 'partial-differential-equations']"
2834230,I am using neighborhood balls to define continuity. Are these definitions of pointwise continuous and uniform continuous correct?,"I seem to understand topology more than analysis and was wondering if these definitions of continuity, which to me have more a topological flavor, are correct. Suppose $X$ and $Y$ are metric spaces and let $f: X \to Y$. $f$ is pointwise continuous on $X$ if: for all $x \in X$ and for all $\epsilon>0$, there exists $\delta>0$ such that $B_\delta (x) \subset f^{-1}(B_\epsilon(f(x)))$. $f$ is uniformly continuous on $X$ if: for all $\epsilon>0$, there exists $\delta>0$ such that for all $x \in X$, $B_\delta (x) \subset f^{-1}(B_\epsilon(f(x)))$.","['continuity', 'uniform-continuity', 'general-topology', 'metric-spaces', 'analysis']"
2834231,What's the Fourier transform of the p-Laplacian operator $\Delta_{p}$?,"Consider the p-Laplacian operator $\Delta_{p}u:= div(|\nabla u|^{p-2}\nabla u)$, where $1<p<\infty$. We know when $p=2$, it's the standard laplacian operator. So my question is what is the fourier transform of this operator.
For general Laplacian, I know $\widehat {\Delta u}(\xi)=|\xi|^2 \hat u(\xi)$. What is $\widehat {\Delta_{p} u}(\xi)$? I couldn't find relevant notes and only find this link: https://mathoverflow.net/questions/228009/backgrounds-of-the-p-laplacian-operator","['real-analysis', 'fourier-analysis', 'partial-differential-equations', 'harmonic-analysis', 'analysis']"
2834270,Prove that an $n \times n$ matrix ${\bf A}$ is orthogonally similar to a lower triangular matrix,"Prove that if ${\bf A}$ is an $n \times n$ matrix with real eigenvalues, then ${\bf A}$ is orthogonally similar to a lower triangular matrix ${\bf T}$. I can prove that ${\bf A}$ is similar to an upper triangular matrix (using induction), but I can't find a way to prove it similar to a lower triangular matrix.","['matrices', 'linear-algebra']"
2834288,Calculating the Hilbert class field group of $\mathbb{Q}(\sqrt[3]{19})$,"In Marcus book “Number Fields” there is an exercise which asks to calculate the Hilbert class field group of $\mathbb{Q}(\sqrt[3]{19})$ I know that the ring of integers is $R=\mathcal{O}_K=\mathbb{Z}[\alpha,\beta]$ , where $\alpha=\sqrt[3]{19}$ and $\beta=\frac{\alpha^2+\alpha+1}{3}.$ After some calculations I have that $disc{K}=-3\cdot19^2$ and that the indexes of $\alpha$ and $\beta$ are, respectively $3,2.$ The Minkowski bound say that I only have to consider the following ideals that I have factored using Kummer: $$2R=(2,\alpha-1)(2,3\beta)$$ $$3R=(3,\beta)^2(3,\beta-1)$$ $$5R=(5,\alpha+1)(5,\alpha^2-\alpha+1)$$ $$7R=(7).$$ Using a preceding exercise, I know that $$N(a+b\alpha+c\alpha^2)=a^3+19b^3+19^2c^3-57abc.$$ I observe that the congruence $x^3\equiv m\mod19$ can be satisfied only if $m\equiv0,1,7,8,11,12,18.$ I can deduce that there aren’t elements of norm 2,5, and a similar arguments holds for the primes over $3.$ However, there exist elements of norm $18,45$ respectively $\alpha-1$ and $\alpha-4$ . With direct computation, I have found that $$\alpha-4\in(3\beta)(3,\beta-1)(5,\alpha+1)$$ I would like to calculate the norm of the prime ideal $(5,\alpha+1)$ I know it is a power of $5,$ more precisely $5$ or $25.$ How can I calculate this norm? For example, if I would like to calculate it computing $$|(5,\alpha+1)/(5,\alpha+1)^2|,$$ how can I proceed? If it is $5$ , in this way I should conclude that the class field group is cyclic with the class of $(3,\beta)$ as generator. 
Finally, how can I prove that the order of the group is divisible by $3$ ? I think I have to match the powers of the ideal class $(3,\beta)$ in the right way, but I’m not completely sure.","['algebraic-number-theory', 'class-field-theory', 'group-theory']"
2834303,Find the stationary points of w = $ −3x^2 − 4xy − y^2− 12y + 16x $ which reside at 1st quadrant,"Find the stationary points of 
w = $ −3x^2 − 4xy − y^2− 12y + 16x $ which reside at 1st quadrant. I did this problem with traditional method : like find $f_x$ = 0 $f_y$ = 0  and checking $f_{xx} f_{yy} - f_{xy}^2 $ which I got negative. I got the critical point as  = <-20,34>. Now how can I get a critical point on first quadrant? They've given the answer as <8/3,0>.",['multivariable-calculus']
2834331,UMVUE for a function of parameter [duplicate],"This question already has an answer here : Finding UMVUE of $\theta$ when the underlying distribution is exponential distribution (1 answer) Closed 4 years ago . Let's say in the exponential distribution, the cdf if
$$f(x|\lambda)=\frac{1}{\lambda}\exp\left\{-\frac{x}{\lambda}\right\}$$
If we have $n$ observations: $X_1, X_2, \cdots, X_n$. Then we know since it belongs to the exponential family we have the UMVUE for $\lambda$ is
$$T({\bf X})=\sum^n_{i=1}X_i$$
And
$$E(T)=E\left(\sum^n_{i=1}X_i\right)=\sum^n_{i=1}E(X_i)=n\lambda$$
Then 
$$\hat{\lambda}_{UMVUE}=\frac{T}{n}=\bar{X}$$
Then, what if we want to find the UMVUE of $\frac{1}{\lambda}$?","['statistics', 'statistical-inference']"
2834335,Help with axler's definition of a polynomial (linear algebra done right),"I'm having trouble following Axler's polynomial definition. I don't understand the meaning of $$p\colon {\bf F}\to {\bf F}$$ on page 10 of Axler Further, how would I go about rigorously verifying that ${\cal P}({\bf F})$ is a vector space?","['notation', 'linear-algebra']"
2834338,Can we remove the absolute value when doing Diophantine Approximation?,"This is a very general question. For Diophantine Approximation propositions, the statements always include the absolute value sign, but I think if we can remove the absolute value sign, the approximation will become more useful. For example, we have Hurwitz's theorem: For any irrational $\zeta$ there are infinitely many pairs of integers $p,q$ such that $|\zeta - p/q|<\frac{1}{\sqrt{5}q^2}$ However, when we remove the absolute value, is the following statement true or not? For any irrational $\zeta$ there are infinitely many pairs of integers $p,q$ such that $0<\zeta - p/q<\frac{1}{\sqrt{5}q^2}$ This is just example. My main question is: Is there any theory about it? Where can I get the reference on this topic?","['number-theory', 'diophantine-approximation', 'analysis']"
2834341,Existence of a solution for a ODE defined on an open set in $\mathbb{R}^n$.,"Let $U \subset \mathbb{R}^n$ be an open set, and $B$ a smooth matrix valuated function $B:U \to M_n(\mathbb{R})$ . Let $\frac{\partial}{\partial x^1}$ be the constant vector field defined on $U$.  I am trying (with no success)  to prove that given $x_0 \in U$, and $A_0 \in M_n(\mathbb{R})$ there exist a smooth matrix valuated function  $A:U \to M_n(\mathbb{R})$ , such that: $\frac{\partial A}{ \partial x^1}= B \cdot A $, with $A(x_0)=A_0$. And that the dependence on $(x_0 , A_0)$ is smooth. Well i arrived to this problem trying to show the smoothness of a distribution defined on a manifold, and using a chart (reading Spivak introduction to differentiable geometry vol 2, pp 338 2nd edition), and i have been trying with the classical existence theorems, my idea is: Take $x_0=(x_0^1 , \dots , x_0^n) \in U$ and define the first ODE: $A'(t)= B(c(t))\cdot A(c(t))$. Where $c$ is an integral curve for $\frac{\partial}{\partial x^1}$ such that $c(0)= x_0$, this equation is very well know to have a solution, with initial condition $A_0$, and seems natural to try to define $A(c(t)) = A(t)$. If I take curves by $(x_0^1 \pm \epsilon, x_0^2, \dots x_0^n)$ I can define  ODE with the same initial condition. The problem is i can't see why all these solutions, glue together! I would appreciate any help or advise. in fact, i don't know if it is true! (one friend told me to use a more general existence of solution theorem which lets $B$ be a smooth function of $\mathbb{R}^n$, but i can't find this theorem anywhere) ... Any help or advise is welcome. Thank you all!","['ordinary-differential-equations', 'differential-geometry']"
2834347,Kunneth formula,"I am trying to understand the proof of the Kunneth formula, as described by Ravi Vakil's notes in 18.2.8 here: http://math.stanford.edu/~vakil/216blog/FOAGnov1817public.pdf#page=475 I will follow Ravi's notation. Why is that the the tensor product of the Cech complexes of $X$ and $Y$ the same as the Cech complex of $X \times Y$ with respect to the product cover? More specifically, let $\mathcal U =  \{U_i \}_{i \in I}$ and $\mathcal V = \{ V_j \}_{j \in J}$ be open affine covers of $X$ and $Y$. Then $\mathcal U \times_k \mathcal V = \{ U_i \times_k V_j \}$ is an open affine cover of $X \times Y$. The $n$-cochains in Cech complex of $X \times Y$ are: $$
C^n(\mathcal U \times_k \mathcal V, \mathcal F \boxtimes \mathcal G)
=
\prod_{ (i_0,j_0), \dots, (i_n, j_n) \in (I \times J)^{n+1} }
(\mathcal F \boxtimes \mathcal G) ( (U_{i_0} \times V_{j_0}) \cap \dots \cap (U_{i_n} \times V_{j_n}) )\\
=
\prod_{ (i_0,j_0), \dots, (i_n, j_n) \in (I \times J)^{n+1} }
(\mathcal F \boxtimes \mathcal G) ( U_{i_0 \dots i_n} \times V_{j_0 \dots i_n} )\\
=
\prod_{ (i_0,j_0), \dots, (i_n, j_n) \in (I \times J)^{n+1} }
\mathcal F(U_{i_0 \dots i_n}) \otimes_k \mathcal G(V_{j_0 \dots j_n})
$$
This looks to me like $ C^n(\mathcal U, \mathcal F) \otimes_k C^n(\mathcal V, \mathcal G)$. I don't see how this is supposed to be the degree $n$ part of $C^\bullet(\mathcal U, \mathcal F) \otimes C^\bullet(\mathcal V, \mathcal G)$, which is
$$
\bigoplus_{p+q=n} C^p(\mathcal U, \mathcal F) \otimes C^q(\mathcal V, \mathcal G).
$$ Thanks for you help.",['algebraic-geometry']
2834366,Application of implicit function theorem?,"Let $f: U \subset \mathbb{R}^2 \to \mathbb{R}$ be a continuous function in the open subset $U$ of $\mathbb{R}^2$ such that
$$(x^2+y^4)f(x,y)+f(x,y)^3 = 1, \forall (x,y) \in U$$
Show that $f$ is of class $C^1$ in $U$. I think that is an application of implicit function theorem, but I don't know how to solve it, because I only saw examples about system of linear equations.","['derivatives', 'manifolds', 'analysis']"
2834396,Sine of a finite sum of angles,"There is a formula for evaluating the function
$$
\sin\left(\sum_{i = 1}^\infty \theta_i\right),
$$
where $\theta_i$ form an absolutely convergent series. See Wikipedia . How to write this down for
$$
\sin\left(\sum_{i = 1}^N \theta_i\right),
$$
and how to prove it? Any reference to an existing proof is highly appreciated.","['proof-writing', 'trigonometry', 'proof-verification']"
2834401,The value of x satisfying the equation $x=\sqrt{2+\sqrt{2-\sqrt{2+x}}}$,The value of x satisfying the equation $x=\sqrt{2+\sqrt{2-\sqrt{2+x}}}$ (A) $2 \cos 10$ (B) $2 \cos 20$ (C) $2 \cos 40$ (D) $2 \cos 80$ I was dumb enough to square the expression to reach $x^8-4x^6+4x^4+2-x=0$ which is clearly a dead end ;-;,"['nested-radicals', 'trigonometry', 'quadratics']"
2834405,In parabola why the angle at focus is $90$,"The green line below is tangent drawn at point $P$. This construction uses the fact that the angle $PFT$ is $90$ degrees. But it doesn't give any explanation of why it must be $90$. Is there any simple way to see this with or without calculus? Intuitively, when $P$ are right above $F$, it is clear that the angle is 90 because $PF$ is vertical and $FT$ is horizontal. As $P$ moves to the right, it seems $T$ also moves upkeep the angle at focus $90$. I'm not that sure how to approach proving things like these... Help appreciated.","['conic-sections', 'calculus', 'geometry']"
2834442,"Is $F=\left\lbrace f: f\in C_{\left[0, 1\right]}, f\left(0\right)=f\left(1\right)\right\rbrace$ complete metric space?","Is $F=\left\lbrace f: f\in C_{\left[0, 1\right]}, f\left(0\right)=f\left(1\right)\right\rbrace$ complete metric space? I know how to prove that $C_{\left[0, 1\right]}$ is complete. But I don't know how to use condition that $f\left(0\right)=f\left(1\right)$.","['functional-analysis', 'complete-spaces', 'metric-spaces']"
2834469,Finite dimensional distrubutions of Brownian motion,"I am having some trouble with interpreting the following standard expression for the finite distributions for the brownian motion $P(B_{t_{1}}\in A_{1}, \ldots B_{t_{n}}\in A_{n})=\int_{A_{1}} f({t_{1}},x_{1}-{x_{0}})dx_{1}\cdots \int_{A_{n}}f({t_{n}-t_{n-1}},x_{n}-{x_{n-1}})dx_{n}$ where $f$ is the centered gaussain density. Given that we know the defining properties of the brownian motion, how do we end up here?","['stochastic-processes', 'probability-theory', 'brownian-motion']"
2834495,Proving $x^2+x+1\gt0$,"I was doing a question recently, and it came down to proving that $x^2+x+1\gt0$. There are of course many different methods for proving it, and I want to ask the people here for as many ways as you can think of. My methods: $x^2+x+1=(x+\frac12)^2+\frac34$, which is always greater than $0$. Let it be $0$ for some $x=k$. Then $x^2+x+1=0$ has a real solution. But since $1^2\not\gt4$, this has no real solution. Therefore it is more than $0$.","['algebra-precalculus', 'inequality', 'big-list', 'alternative-proof']"
2834520,Prove there are no 3 collinear points on a non-degenerate conic,"Obviously, I know it is not possible, but I don't know how to prove it. I tried choosing 3 points, using that the slopes between them are equal, then trying to somehow show that the general form of conics $Ax^{2}+Cy^{2}+Dx+Ey+F=0$ has no root. That didn't help. Maybe a geometrical proof would be easier.","['conic-sections', 'linear-algebra', 'geometry']"
2834533,Finding $\lim\limits_{n \to \infty} \sqrt[n^2]{a_n}$ given that $\lim\limits_{n \to \infty} \frac{a_n a_{n+2}}{(a_{n+1})^2}=L^2$,"This is the problem I saw in another question - which was later closed and deleted (the close reason was missing context). Still, the problem seemed interesting to me - at least in the sense that the solution is not immediately obvious. The problem: Suppose that $(a_n)$ is a real sequence such that $a_n>0$ for $n>0$ and
  $$\lim\limits_{n\to\infty} \frac{a_na_{n+2}}{a_{n+1}^2}=L^2.$$
  Suppose further that $L\ge0$
  Find $\lim\limits_{n\to\infty} \sqrt[n^2]{a_n}$. (In terms of $L$.) The original problem in the linked question was given with $L=2$. However, I do not think that the problem should change that much for any value of $L$. (Maybe one could be suspicious about $L=0$?) It is also clear - at least for $L>0$ - that if it is possible to express the second limit using $L$, then the limit should be equal to $L$. It suffices to notice that for $a_n = L^{n^2}$ we have
$$\frac{a_na_{n+2}}{a_{n+1}^2}=
\frac{L^{n^2+(n+2)^2}}{L^{2(n+1)^2}} =
L^{(2n^2+4n+4)-2(n^2+2n+2)} = L^2.
$$ So we know what is the candidate for the result, we still need to prove whether this is actually true. I have posted my attempt as answer. But I will be glad to learn about other solutions. (And of course, also corrections to my approach, if I made some mistakes.)","['sequences-and-series', 'limits']"
2834540,Facing difficulty in working $\int_{0}^{1}\frac{\arctan\left(\frac{ax}{1-x}\right)}{\sqrt{1-x}}\frac{dx}{x^{3/2}}$,"I would like to evaluate this integral,$$\int_{0}^{1}\frac{\arctan\left(\frac{ax}{1-x}\right)}{\sqrt{1-x}}\frac{dx}{x^{3/2}}\tag1$$ This is the approach I will take: We can begin with a sub: $y=\sqrt{x}$, $dx=2\sqrt{x}dy$ $$-2\int_{0}^{1}\frac{\arctan\left(\frac{ay^2}{y^2-1}\right)}{\sqrt{1-y^2}}\frac{dy}{y^2}\tag2$$ Not sure, but we can try integration by parts: $u=\arctan\left(\frac{ay^2}{y^2-1}\right)$, $$du=\frac{2ay}{y^2-1}-\frac{2ay^3}{(y^2-1)^2}\times \frac{1}{\frac{a^2y^4}{(y^2-1)^2}+1}dy$$ $dv=\frac{1}{y^2\sqrt{1-y^2}}dy$, $$v=-\frac{\sqrt{1-y^2}}{y}$$ $$2a\int_{0}^{1}\frac{(1-y^2)^{3/2}}{(y^2-1)+a^2y^4}+2a\int_{0}^{1}\frac{y^2(1-y^2)^{1/2}}{(y^2-1)^2+a^2y^4}dy=2a\left(I+J\right)\tag3$$ Integral I: Making another sub: $y=\sin(u)$, $u=\arcsin(y)$, $dy=\cos(u) du$ It is too much to write everything down, finally got to:
$$I=\int_{0}^{\pi/2}\frac{cos^4(u)}{a^2\sin^4(u)+\cos^4(u)}du$$ Using trig identities we can rewrite $$I=\int_{0}^{\pi/2}\sec^2(u)\frac{du}{(1+\tan^2(u))(1+a^2\tan^4(u))}$$ Make another sub: $s=\tan(u)$, $du=\frac{1}{\sec^2(s)}ds$ $$I=\int_{0}^{\infty}\frac{ds}{(1+s^2)(1+a^2s^4)}$$ Using partial fraction decomp: $$I=\frac{\pi}{2(a^2+1)}-\frac{a^2}{a^2+1}\int_{0}^{\infty}\frac{s^2-1}{a^2s^4+1}ds$$ Integral J: Making another sub: $y=\sin(v)$, $v=\arcsin(y)$, $dy=\cos(v) dv$ $$J=\int_{0}^{\pi/2}\frac{\cos^2(v)\sin^2(v)}{(a^2+1)\sin^4(v)-2\sin^2(v)+1}$$ Using trig identities to rewrite $$J=\int_{0}^{\pi/2}\sec^2(v)\cdot \frac{\tan^2(v)}{(1+\tan^2(v))(a^2\tan^4(v)+1)}$$ Make another sub: $t=\tan(v)$, $dv=\frac{1}{\sec^2(v)}dt$ $$J=\int_{0}^{\infty}\frac{t^2}{(1+t^2)(1+a^2t^4)}dt$$ Using partial fraction decomp: $$J=\frac{1}{1+a^2}\color{red}{\int_{0}^{\infty}\frac{a^2t^2+1}{a^2t^4+1}dt}-\frac{\pi}{2(1+a^2)}$$ The red integral it is definitely way out of my reach! $$\int_{0}^{\infty}\frac{a^2t^2+1}{a^2t^4+1}dt=\int_{0}^{\infty}\frac{t^2}{t^4+a^{-2}}dt+\int_{0}^{\infty}\frac{dt}{a^2t^4+1}$$ The above approach seem to be not helping in evaluating the question. After simplification I got to: $$2a(I+J)=\int_{0}^{1}\frac{\arctan\left(\frac{ax}{1-x}\right)}{\sqrt{1-x}}\frac{dx}{x^{3/2}}
=\frac{1}{1+a^2}\int_{0}^{\infty}\frac{a^2+1}{a^2t^4+1}dt$$ If my work so far it is correct, then I am shruggle in solving this integral $$\int_{0}^{\infty}\frac{1}{a^2t^4+1}dt=\int_{0}^{\infty}\frac{dt}{(at^2-i)(at^2+i)}dt$$","['integration', 'trigonometric-integrals', 'calculus']"
2834554,Newman's proof of the Asymptotic Formula for the Partition Function,"I'm working on Donald J. Newman's proof that $p(n) \sim \frac{1}{4\sqrt{3}n}e^{\pi\sqrt{\frac{2n}{3}}}$, as found in Chapter II of his book Analytic Number Theory . Here's what we have so far: the generating function for general partitions is $F(z) = \sum_{n=1}^{\infty}p(n)z^n$, which is a Taylor series of some kind. We can therefore conclude that for any $n\in\mathbb{N}$, $$p(n) = \frac{1}{2\pi i}\int_C \frac{F(z)}{z^{n+1}}dz$$ for some closed curve $C$ around the origin. That's fine and looks promising. So we need $F$ in a form that lets us perform the integration. A long-known fact is that the generating function $F$ can be written as $F(z) = \prod_{k=1}^{\infty}\frac{1}{1-z^k}$. Next, we take logs and find after some algebra that $$\ln (F(z)) = \sum_{j=1}^{\infty} \frac{1}{j}\frac{1}{z^{-j}-1}.$$ Then letting $z=e^{-w}$ for some $w\in\mathbb{C}$ with Re$(w)$ approaching $0$ from the positive side, we get $$\ln (F(e^{-w})) = \sum_{k=1}^{\infty}\frac{1}{k}\frac{1}{e^{kw}-1}.$$ Using a Taylor expansion for $\frac{1}{e^{kw}-1}$ that converges for $w$ near $0$, we find that near $0$, $$\ln (F(e^{-w})) = \frac{\pi^2}{6w} + \frac{1}{2}\ln (1-e^{-w}) + \sum_{k=1}^{\infty}\frac{1}{k}\Bigg(\frac{1}{e^{kw}-1} - \frac{1}{kw} + \frac{e^{-kw}}{2}\Bigg) .$$ This sum, according to Newman, is essentially a Riemann sum, so taking some $h>0$, he indicates the general result that if $f$ is any real function with an integral that converges from $0$ to $\infty$, then $$\sum_{k=1}^{\infty}f(kh)h - \int_{0}^{\infty}f(x)dx < hV(f),$$ where $V(f)$ is the total variation of $f$ from $0$ to $\infty$. I'm assuming this means the supremum of $f$ minus its infimum on that interval. Then things get messier. Newman takes $w=he^{i\theta}$ for some $\theta \in \big(-\frac{\pi}{2}, \frac{\pi}{2}\big)$, which keeps its real part positive, while $h$ keeps it small. That's fine, but then he says that we can use our Riemann sum estimate to conclude that $$\sum_{k=1}^{\infty}F(khe^{i\theta})h - \int_{0}^{\infty}F(xe^{i\theta})dx < hV_{\theta}(F),$$ where $V_{\theta}(F)$ is the variation of the argument of $F$ 'along the ray'. I don't know what that means. Is the ray the real line? Is that the argument of $F$'s image, or the argument of the variable we plug into $F$, or what? How does this inequality follow from the first? Also, isn't $F$ a complex function with a complex image, and if so how do we make sense of integrating it along the real line? Newman goes on to say that this means $$\sum_{k=1}^{\infty}F(kw)w - \int_{0}^{\infty}F(xe^{i\theta})d(xe^{i\theta}) < w V_{\theta}(F).$$ That integral looks like it can't be right, because $xe^{i\theta}$ can't vary between $0$ and $\infty$ unless $\theta = 0$. So that's puzzling too. There are two other things Newman mentions soon afterward that I don't fully understand: first, he says that $F$ drops off like $\frac{1}{x^2}$ as it approaches $\infty$. Is he talking about the real part of $F$ for $F$ with a real variable plugged in? If so, how does he get that asymptote? And second, he mentions the formula $V_{\theta}(F) = \int_{0}^{\infty}|F'(xe^{i\theta})|$ which, because I'm not sure about this whole ray thing, it's difficult to see how to derive. If anyone is familiar with this work of Newman's, I'd appreciate help with these questions. (I might also add a few more as I get further in the chapter -- I hope that's not bad form.)","['complex-analysis', 'analytic-number-theory', 'integer-partitions', 'riemann-sum']"
2834573,"Determine conditions on $X$ and $Y$ that make span$(X,Y)$ an involutive distribution. How does this affect the maximal integral submanifolds?","I've been thinking about the following problem: Equip $\mathbb{R}^3$ with coordinates $(x,y,z)$ and define two vector fields $X$ and $Y$ by
      $$
X=\frac{\partial}{\partial x}+f(x,y)\frac{\partial}{\partial z},\hspace{.5 in}\text{and}\hspace{.5 in}Y=\frac{\partial}{\partial y}+g(x,y)\frac{\partial}{\partial z}.
$$
      Define the distribution $\Delta\subset T\mathbb{R}^3$ by
      $$
\Delta =\text{span}(X,Y).
$$
      Determine conditions on the functions $f(x,y)$ and $g(x,y)$ that imply $\Delta$ is involutive. What do your conditions imply about the maximal connected integral submanifolds of $\Delta$? I've mostly worked out this question, however I'm stuck on the last question: to find how my conditions affect the maximal connected integral submanifolds of $\Delta$. Here's my solution so far. ""Solution"" Note that
    \begin{align*}
    [X,Y]&=X(1)\frac{\partial}{\partial y}+X(g)\frac{\partial}{\partial z}-Y(1)\frac{\partial}{\partial x}-Y(f)\frac{\partial}{\partial z}\\
    &=\left(\frac{\partial g}{\partial x}+f \frac{\partial g}{\partial z}\right)\frac{\partial}{\partial z}-\left(\frac{\partial f}{\partial y}+g\frac{\partial f}{\partial z}\right)\frac{\partial}{\partial z}\\
    &=\left(\frac{\partial g}{\partial x}-\frac{\partial f}{\partial y}\right)\frac{\partial}{\partial z},
\end{align*}
    where we have used that $f$ and $g$ are independent of $z$. Now $\Delta$ is involutive if and only if $[X,Y]\in\text{span}(X,Y)$, so we require the determinant of
    $$
\begin{pmatrix}
1 & 0 & f\\
0 & 1 & g\\
 0 & 0 & \frac{\partial g}{\partial x}-\frac{\partial f}{\partial y}
\end{pmatrix}
$$
    to vanish identically, i.e. we require
    $$
\frac{\partial g}{\partial x}=\frac{\partial f}{\partial y}.
$$ My problem is that any curve following $X$ would be of the form $\alpha(t)=(t+x_0,y_0,F(t))$, where $F$ is some antiderivative of $f(t+x_0,y_0)$, and similiarly for $Y$. Since in this form $f$ is constant in the $y$-direction I don't see how the condition above will come into play. Is my thinking incorrect? Is one of my calculations wrong? Any help would be greatly appreciated. Thanks.","['general-topology', 'differential-geometry', 'differential-topology']"
2834619,Pedal form to polar form of an ellipse,"How do I convert the equation $$\frac{a^2b^2}{p^2}=a^2+b^2-\frac{1}{u^2}$$ into the following equivalent form? $$u^2=\frac{\sin^2 \theta}{b^2}+\frac{\cos^2 \theta}{a^2}$$ where $$\frac{1}{p^2}=u^2+\left( \frac{du}{d\theta} \right)^2$$ EDIT: I have tried and found out $$\frac{uab}{\sqrt{u^2(a^2+b^2)-1-u^4a^2b^2}}\, du = d\theta$$ How do I integrate and express the result in terms of $\sin \theta$ and $\cos \theta$? $p$ is the perpendicular distance from $O$ to the tangent line to $C$ at the point in case of pedal equation of a curve.  It is converted to $u$ as stated above.","['multivariable-calculus', 'integration', 'ordinary-differential-equations']"
2834648,Is a pointwise decomposable differential form smoothly decomposable?,"Let $\omega$ be a smooth differential form on a smooth manifold $M$. Suppose $\omega$ is pointwise decomposable, that is for every $p \in M$, $\omega_p=e^1_p \wedge e^2_p \wedge \dots \wedge e^k_p$  for some $e^i_p \in T_p^*M$. Is it true that $\omega$ is smoothly decomposable? at least locally? That is, does there exist (locally) smooth one-forms $\omega_i$ such that $\omega=\omega_1 \wedge \omega_2 \dots \wedge \omega_k$?","['exterior-algebra', 'tensor-decomposition', 'smooth-manifolds', 'differential-forms', 'differential-geometry']"
2834720,Laurent series around z=-i for $\frac{1}{z(z-1)}$ and $1<|z+i|<\sqrt2$,"I'm given the function : $$f(z)=\frac{1}{z(z-1)}$$ I'm interesting in finding the Laurent series around $z=-i$ for the one finite circular ring corresponding to this function given its singularities ( I hope I'm using the right words here). I have some ideas but having seen very few problems, I'm not sure about them. So this question is mostly here to check if the way I do things is correct. I think the area we are interested in is the following : $1<|z+i|<\sqrt2$ $f(z)$ can be written as $f(z)=\frac{1}{z-1}-\frac{1}{z}$ We can write the first term as $$\frac{1}{z-1}=\frac{-1}{(1+i)(1-\frac{z+i}{1+i})}$$
$$\frac{-1}{(1+i)}\frac{1}{(1-\frac{z+i}{1+i})}=\frac{-1}{(1+i)}\sum_{n=0}^\infty\left(\frac{z+i}{1+i}\right)^n$$ I tried to turn this in the form of the geometric series. This is valid for $$\frac{|z+i|}{|1+i|}<1=>|z+i|<\sqrt2$$ For the other part of the inequality I will try to do the same for the second term of $f(z)$ : $$\frac{1}{z}=\frac{1}{(z+i)(1-\frac{i}{z+i})}=\frac{1}{z+i}\sum_{n=0}^\infty\left(\frac{i}{z+i}\right)^n$$ which gives the inequality we are looking for : $$\frac{|i|}{|z+i|}<1=>|z+i|>1$$ Finally, this leads to the Laurent Series: $$f(z)=\sum_{n=0}^\infty\left(\frac{z+i}{1+i}\right)^n-\sum_{n=0}^\infty\left(\frac{i}{z+i}\right)^n$$ The left part is the analytic part , and the right one is the principal part except for the n=0 term. Is everything alright with my solution? Should I provide more details if I'm asked in a test?","['laurent-series', 'complex-analysis']"
2834733,Domain of sum of self-adjoint operators $A \otimes 1 + 1 \otimes B$?,"Thinking about some quantum mechanics issues, I stumbled across the following functional analysis problem which confuses me a lot. Let $A$, $B$ be self-adjoint, unbounded and positive operators with domains $\rm{dom}(A) \subset H_1$ and $\rm{dom}(B) \subset H_2$, where $H_1, H_2$ are some separable Hilbert spaces ($L^2$ of something, in fact). What is the domain of $A + B$, which denotes the closure of the operator $A \otimes 1 + 1 \otimes B$ definable on $\rm{dom}(A) \otimes \rm{dom}(B) \subset H_1 \otimes H_2$? I know that the closure can in principle lead to complications here. But I thought that the answer should be something like $\rm{dom}(A) \otimes H_2 \cap H_1 \otimes \rm{dom}(B)$ because both operators are positive and there cannot be any strange cancellations that would further enlarge the domain.","['functional-analysis', 'tensor-products', 'unbounded-operators']"
2834735,Median is twice the mean,"I am stuck at solving the following problem (at what I believe is the last step): Determine which distributions on the non-negative reals, if any, with mean $\mu$ are such that $2\mu$ is a median. My thoughts so far: Let's call the distribution in question $X$. Given that $X$ takes values in the non-negative reals, we can apply the Markov inequality $\left(P(X\geq t)\leq\frac{E[X]}{t}, \mbox{ for } t\geq 0\right)$. Taking $t = \mu$ in this inequality we get that 
$$
P(X\geq 2\mu)\leq \frac{\mu}{2\mu} = \frac{1}{2}
$$ However, given that $2\mu$ is the median, we have that $P(X\geq 2\mu)\geq \frac{1}{2}$. Hence we get that $P(X\geq 2\mu) = \frac{1}{2}$. Therefore we have equality in the Markov inequality . Hence $X\in\left\{ 0,2\mu\right\}$. How do I determine where $X$ takes the value $0$ and where $X$ takes the value $2\mu$ (if there is any such way)? From 1, how do I get the pdf of $X$?","['means', 'probability', 'median', 'probability-distributions']"
2834816,Then general values of $\theta$ in inverse Trigo sum,If $\displaystyle \theta = \tan^{-1}\bigg(2\tan^2 \theta\bigg)-\frac{1}{2}\sin^{-1}\bigg(\frac{3\sin 2 \theta}{5+4\cos 2 \theta}\bigg).$ Then general values of $\theta$ is Try: Let $\alpha =\tan^{-1}\bigg(2\tan^2 \theta\bigg)\Rightarrow \tan \alpha =2 \tan^2 \theta$ and $\displaystyle \beta = \frac{1}{2}\sin^{-1}\bigg(\frac{3\sin 2 \theta}{5+4\cos 2 \theta}\bigg)\Rightarrow \sin (2\beta) = \frac{3\sin 2 \theta}{5+4\cos 2 \theta} = 3\frac{2\tan \theta}{1+\tan^2 \theta}\cdot \frac{1}{5+4\bigg(\frac{1-\tan^2 \theta}{1+\tan^2 \theta}\bigg)}$ So $\displaystyle \sin (2\beta) = \frac{6\tan \theta}{9+\tan^2 \theta}.$ could some help me how to find range of $\theta$. Thanks,['trigonometry']
2834854,"If $f_m \rightarrow f$ in $L^p$, does $|f_m|^r \rightarrow |f|^r$ in $L^{\frac{p}{r}}$?","Suppose that $(f_m)_m, f \subset L^p(\Omega)$ are nonnegative, such that $f_m \rightarrow f$ in $L^p$; that is: $$
\|f_m - f\|_p \rightarrow 0
$$ It is clear that $({f_m}^r)_m, f^r \subset L^{\frac{p}{r}}(\Omega)$, since $\int |f|^p = \int|f^r|^{\frac{p}{r}}$. Can we conclude that ${f_m}^r \rightarrow f^r$ in $L^{\frac{p}{r}}$? That is: $$
\left\|
{f_m}^r - f^r
\right\|_{\frac{p}{r}} \rightarrow 0
$$ Note: we assume $1<r<p<\infty$, and $\Omega \subset \mathbb{R}^n$ is measurable.","['real-analysis', 'uniform-convergence', 'functional-analysis', 'lp-spaces', 'convergence-divergence']"
2834870,Prove that the Kolmogorov Quotient is $T_0$,"I am trying to prove the following (more on the background below) Let $(X, \tau)$ be a space, $KQ(X) := X / \sim$ be the quotient set and $\pi : X \rightarrow X / \sim$ the projection which maps every element to its equivalence class. If $KQ(X)$ is given the final topology of $\pi$, it is a $T_0$ space. Proof idea I need to show that every two distinct equivalence classes $[a], [b] \in KQ(X)$ are distinguishable. Instead, I try to prove the contraposition
$$
[a] \sim [b] ~\Longrightarrow~ [a] = [b] ~\Longleftrightarrow~ a \sim b
$$
If $U \subset KQ(X)$ is open, then I have
$$
a \in \overset{-1}{\pi}(U)
~\Longleftrightarrow~
\pi(a) \in U 
~\overset{[a] \sim [b]}{\Longleftrightarrow}~ 
\pi(b) \in U
~\Longleftrightarrow~
b \in \overset{-1}{\pi}(U)
$$
Which is almost what I want, since if I could replace $\overset{-1}{\pi}(U)$ (which is open since $\pi$ is continuous) by any open set $\mathcal{O} \subseteq X$ I would have shown $a\sim b$ by the above. But thus far, I have failed at finding a way to do this. On any topological space $(X,\tau)$ , you can define an equivalence relation $\sim$ $\subseteq X \times X$ by
$$
a \sim b  ~: \Longleftrightarrow ~ 
\big( ~\forall U \in \tau : ~ a \in U ~\Leftrightarrow~ b \in U \big)
$$
If two points are equivalent, they are called (topologically) indistinguishable . A space is called $T_0$ iff all distinct points are distinguishable ( i.e. $a \neq b \Rightarrow \neg (a \sim b)$ ). For any space $(X,\tau)$ you can look at the quotient set $X / \sim$ and give it the final topology of the projection to obtain the so called Kolmogorov Quotient $KQ(X)$, which is $T_0$.","['general-topology', 'quotient-spaces']"
2834876,Convergence of geometric series with |r|>1,"The geometric series $\sum_{n=0}^\infty ar^n$ with $a, r \in \mathbb{R}$ converges to $\frac{a}{1-r}$ iff $|r| < 1$. Given this proof: $\sum_{n=0}^\infty ar^n = a + \sum_{n=1}^\infty ar^n = a + r\sum_{n=0}^\infty ar^n$ [1], where we can clear $\sum_{n=0}^\infty ar^n$ as $(1-r) \sum_{n=0}^\infty ar^n = a$, leading to $\sum_{n=0}^\infty ar^n = \frac{a}{1-r} \blacksquare$, my question is: where have been used the fact that $r$ must be $|r|<1$? To me, all the steps done in [1] are true no matter how $r$ is.","['sequences-and-series', 'convergence-divergence']"
2834906,"How is the ""surface measure"" on a manifold defined?","Let $k,n\in\mathbb N$ with $k\le n$ $M$ be a $k$-dimensional $C^1$-submanifold of $\mathbb R^n$ $\Omega\subseteq\mathbb R^k$ be open, $\phi:\Omega\to M$ be a global chart of $M$ and $$g_\phi(x):=\det\left(\left({\rm D}\phi(x)\right)^\ast {\rm D}\phi(x)\right)\;\;\;\text{for }x\in U$$ Now, let $\lambda^k$ denote the Lebesgue measure on $\mathcal B(\mathbb R^k)$,  $\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U$ denote the measure with density $\sqrt{g_\phi}$ with respect to $\left.\lambda^k\right|_U$ and $$S_M:=\phi_\ast\left(\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U\right)$$ the pushforward measure of $\sqrt{g_\phi}{\rm d}\left.\lambda^k\right|_U$ with respect to $\phi$. $S_M$ is a measure on $\mathcal B(M)$ and we're able to verify that $S_M(A)$ is the surface area of $A\in\mathcal B(M)$. I'm searching for a generalization of the concept described above for more general $M$. In particular, the $M$ I've got in mind is the finite union of triangles in $\mathbb R^3$. Two different triangles can be assumed to intersect only along one common side or at one common vertex and two different sides can intersect only at one common vertex. I've searched the internet for a couple of hours, but couldn't find anything (Actually, I wasn't even able to find the construction of $S_M$ above anywhere). So, is there any good textbook on that topic?","['real-analysis', 'measure-theory', 'manifolds', 'submanifold', 'manifolds-with-boundary']"
2834911,Solve Green function of an annulus to calculate the shape of a clamped elastic sheet,"I am trying to solve the shape of an elastic sheet clamped at $r=1$ and $r=b<1$. 
$$\left\{
\begin{array}{c l}	
     \Delta u = \rho(r,\phi)  \quad (a<r<1)\\
     u(a)=0\\
     u(1)=1
\end{array}\right.$$ I have solved the solution for a case that has the rotational symmetry ($\partial u /\partial \phi = 0$):
$$\left\{
\begin{array}{c l}	
     \Delta u = g  \quad (a<r<1)\\
     u(a)=0\\
     u(1)=1
\end{array}\right.$$
where $g$ is a constant. With the polar form of the Laplacian $\Delta = \frac{1}{r} \frac{\partial}{\partial r}\left(r \frac{\partial u}{\partial r}\right)+\frac{1}{r^2}\frac{\partial^2 u}{\partial \phi ^2}=\frac{1}{r} \frac{\partial}{\partial r}\left(r \frac{\partial u}{\partial r}\right)$, the solution is
$$u(r,\phi)=\frac{g}{4} r^2 + C_1 \log{r} + C_2$$
where $C_1, C_2$ are determined by the two boundary conditions. My question is how can I find the Green function $G(\mathbf{r,r'})$ of this problem to reproduce this result ($\rho (r,\phi)= g$) so that I can apply it to the original problem with general $\rho(r,\phi)$? I am particularly interested in $\rho(r,\phi)=\delta(r-b)\delta(\phi)$ where $a<b<1$, which represents a point charge at $r=b$. I really appreciate your attention! Following Dylan's solution and choosing $\phi_0=0$, $A_n(r)$ can be calculated as
\begin{equation}
\begin{aligned}
A_n(r)&=\frac{1}{n} \left[\Theta(r-r_0)\cdot \sinh{(n\log{(\frac{r}{r_0})})}+\frac{\sinh{(n\log{(\frac{a}{r})})}\sinh{(n\log{r_0})}}{\sinh{(n\log{a})}}\right]\\
&=\frac{1}{n} \left[\Theta (r-r_0) \cdot \left((\frac{r}{r_0})^n-(\frac{r}{r_0})^{-n}\right)+\frac{\left((\frac{a}{r})^n-(\frac{a}{r})^{-n}\right)\left(r_0^n-r_0^{-n}\right)}{a^n-a^{-n}}\right]
\end{aligned}
\end{equation}
Since the source is even in the $\phi$ component, $B_n(r)=0$. Here is a plot of the numerical result (cross section) for a problem with actual numbers. $u_c(r)$ uses the first 30 terms of the series. $u_h(r)$ is the homogeneous solution. $u_m(r)$ is the part corresponding to the uniform loading in the in-homogeneous solution and $u_c(r)$ is the part corresponding to the point load.","['poissons-equation', 'partial-differential-equations', 'physics', 'greens-function', 'ordinary-differential-equations']"
2834992,How to find one-sided confidence interval for exponential law,"Question: Let $X_1,\ldots,X_n \sim \operatorname{Exp}(\lambda)$ iid for some $\lambda>0$. Find an expression for the ""left"" one-sided confidence uniformly most powerful interval for a threshold $1-\alpha$ for the parameter $\lambda>0$ My attempt: We're looking for an interval of the form $[\delta_\alpha,\infty)$ such that $\Bbb P[\lambda\in [\delta_\alpha,\infty)]\geq1-\alpha\ (\iff\Bbb P[\lambda<\delta_\alpha]\leq1-\alpha)$ first we find the $1-\alpha$-quantile: $$\lambda e^{-\lambda x}=1-\alpha\iff -\lambda x=\log \left( \frac{1-\alpha}{\lambda} \right)\iff x=q_{1-\alpha}=-\frac{\log(\frac{1-\alpha}{\lambda})}{\lambda}$$ Then the statistic test we're looking for is $\delta=\Bbb 1\{\tau>q_{1-\alpha}\}$ where $\tau=\sum\limits_{i=1}^n T(X_i)$ where $T$ is from the exponential family form of $\lambda e^{-\lambda x}=\exp\{\eta(\lambda)T(x)-d(\lambda)+S(x)\}=\exp\{\log(\lambda)-\lambda x\}$ But in order to apply the theorem that tells us what the wirght test function is $\eta$ must be strictly increasing and in $C^1$ so we have to choose $\eta(\lambda)=\lambda$ and $T(x)=-x\implies \tau=-\sum\limits_{i=1}^nX_i$ and at this point I feel like I am doing something wrong... Any help is welcome!","['statistics', 'confidence-interval', 'statistical-inference']"
2835006,Does $f'(x)$ always remain close to $f(x)/x$ as $x \rightarrow 0$?,"Consider a function $f: (0,1): \to  (0,1)$ such that $\lim_{x \rightarrow 0+} f(x) = 0$, $\lim_{x \rightarrow 1-} f(x) = 1$; $f$ has a power series expansion around $x=1$ that converges in $(0,1)$:
$$
f(x) = 1 - \sum_{k=1}^\infty c_k(1-x)^k.
$$
with $c_k \geq 0$ for all $k$. Note that the condition $\lim_{x \rightarrow 0+} f(x) = 0$ implies $\sum_{k=1}^\infty c_k = 1$. A typical example may be $f(x) = x^{2/3}$. Note that the derivative of $f$ may tend to $\infty$ as $x$ approaches $0$ from the right, as in this example. I would like to prove (or find a counter-example) that the derivative $f'(x)$ remains asymptotically close to $f(x)/x$ as $x \rightarrow 0$. By that I mean any of the following: the limit
$$
\lim_{x \rightarrow 0} f'(x)x/f(x)
$$
exists and is finite and nonzero; or more generally that $f'(x) = \Theta(f(x)/x)$ as $p \rightarrow 0$, where $\Theta$ means ""bounded below and above asymptically"" (see definition here ); or any similar result that asserts that $f'(x)$ does not ""deviate too much"" from $f(x)/x$ as $x \rightarrow 0$. For the example function this is true. In fact the limit exists and equals $2/3$. This seems to be the case (with other values) for all functions I am testing, but how to prove it/disprove it?","['real-analysis', 'asymptotics', 'calculus', 'functions']"
2835021,Does the Tietze extension theorem hold for maps into R if on R we put the semi open interval topology?,"I guess the above is false, so I'm trying to find a counter example. The only thing I found is the whole space should not be compact. If not, the statement is true directly from the Tietze extension. Any help will be appreciated.",['general-topology']
2835038,Sum of conditional probabilities equals 1?,"Assuming that sum of probabilities for all possible events that can occur should sum to 1, how does one denote this for a conditional probability? Is it $P(A|E_1) + P(A|E_2) + ... = 1$, where $E_i$ is a specific event to be conditioned on? Or is the answer something else entirely?","['probability-theory', 'probability', 'conditional-probability']"
2835043,From sheaf torsors to geometric bundles on schemes,"$\DeclareMathOperator{\Spec}{Spec}$
$\DeclareMathOperator{\Sym}{Sym}$
$\newcommand{\func}{\mathcal{O}}$
$\newcommand{\M}{\mathcal{M}}$
It is well known that the notions of locally free $\func_X$-modules on a scheme $X$ and vector bundles on $X$ ($X$-schemes $E$ that are locally $\mathbb{A}_X^n$) are equivalent : given vector bundle, one takes the sheaf of sections, and given a locally free $\func_X$-module $\M$, the total space of the bundle is $\Spec_X(\Sym^\bullet\M^\vee)$. Given a group sheme $G$ and a $G$-torsor over $X$, is there a simple procedure that gives the total space of the torsor ? A few clarifications about the question : the general answer seems to be ""no"", according to this answer the same link refers to Milne's Etale cohomology , section III.4, where a partial answer is given. However it is not what I would call a ""simple procedure"" : I am looking for something more similar to taking the relative spectrum of the symmetric algebra for a vector bundle. however I have no hope that directly taking the relative spectrum of a clever $\func_X$-algebra will work : this is a procedure that ""takes closed subschemes"", while often a torsor will look like an ""open subscheme"" (see the following example). My question is in fact motivated by this particular case : given a locally free $\func_X$-module $\M$, we have the $GL$-torsor of trivializations of $\M$, that is the sheaf whose sections over $U\subset X$ is the set of bases of $\M(U)$ as $\func_X(U)$-module. The question becomes : Is there a simple description of the total space of the torsor of trivializations of a vector bundle $\M$ ? (The point of this, ultimately, is that it will be a final object in the category of couples $(Y,f,\phi)$, where $f\colon Y\to Y$ is a morphism and $\phi$ is an $\func_Y$-isomorphism $f^*\M\simeq\func_Y^n$) I think this procedure works : Call $E\to X$ the total space of the bundle $\M$, and form the product $F=E\times_X\ldots\times_XE$ with $n$ terms. By construction, locally over a sufficiently small open $U\subset X$, it is isomorphic to $\mathbb{A}^{n^2}\times U$ (with compatibility between the $U$). We can then take the open subset of points corresponding to an invertible matrix, and this gives the desired space. What I am interested in is to find a ""simpler"" way, i.e. using existing general constructions, without needing to manipulating the details like I just did. Admittedly the construction above is not hard in anyway, it just doesn't generalize well. Last, I feel that this all carries verbatim to rigid analytic geometry (in the sense of Tate), eg the relative spectrum is done by Brian Conrad in Relative ampleness in rigid geometry §2.2. But since I am not overly familiar with this setting (especially Grothendieck topologies), I still ask : What about the setting of rigid analytic geometry ?","['principal-bundles', 'vector-bundles', 'algebraic-geometry', 'rigid-analytic-spaces']"
2835072,Integration of $f^2(x)F(x)^n$,"Is there any general closed form to the following?
$$\int^1_0 f^2(x)F^{n-1}(x)dx$$
when F is a CDF with support $[0,1]$ and $f$ is its corresponding pdf. It's easy when it is $\int^1_0 f(x)F^{n-1}(x)dx$, but what happens when the pdf is powered by some number?","['integration', 'probability']"
2835101,Same convex combinations in Komlós Lemma for two random variables $X$ and $Y$,"Denote by $conv(X_n,X_{n+1},...)$ the set of convex combinations of the random variables $(X_n)_{n \in \mathbb{N}}$, i.e. it contains the elements $\sum_{i=n}^\infty \lambda_i X_i$ for $\lambda_k \geq 0$, $\sum_{i=n}^\infty \lambda_i$ and all but finitely many $\lambda_i$ are not zero. Komlós Lemma states the follwing Lemma : Let $(X_n)_{n \in \mathbb{N}}$ be a sequence of random variables. Then there exist convex combinations $X'_n \in conv(X_n,X_{n+1},...)$ and a random variable $X$, such that $$X'_n \rightarrow X \text{, $P$-a.s.}$$ My question is now: If I have two sequences $(X_n)_{n \in \mathbb{N}}$ and $(Y_n)_{n \in \mathbb{N}}$ is it possible to choose the same convex combinations such that $X'_n \rightarrow X'$ and $Y'_n \rightarrow Y'$ for some random variables $X'$ and $Y'$? By same convex combinations I mean that the $\lambda's$ in the convex combinations are the same for every $X'_n$ and $Y'_n$. Thanks a lot in advance!","['stochastic-processes', 'real-analysis', 'measure-theory', 'probability-theory']"
