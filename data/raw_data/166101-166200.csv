question_id,title,body,tags
2893149,Set with Lebesgue measure 0 or 1.,"Set $f:[0,1]\rightarrow \mathbb{R}$ for which each set $X_{c}=\{x\in [0,1] \mid f(x)\leq c \}$ has Lebesgue measure 0 or 1. Prove that there is $c_{0}$ such that $f(x)=c_{0}$ q.t.p $x\in[0,1]$. I take $c_{0}:=\inf \{c , m(X_{c})=1 \}$, where $m$ is the Lebesgue measure. Any help would be appreciated. Thanks!",['measure-theory']
2893222,Expressing Green's relations in regular semigroups,"Let $S$ be a semigroup and $a \in S$. An element $a' \in S$ is called an inverse of $a$ if
$$
 aa'a = a \qquad 
 a'aa' = a'.
$$
Denote the set of all inverses by $V(a)$. A semigroup where every element has an inverse is called a regular semigroup . We use Green's relations , in particular the definition of $\mathcal L-, \mathcal R-, \mathcal D-$ and $\mathcal H$-classes. The following is taken from J. M. Howie Fundamental of semigroup theory (page 49): Let $a,b$ be elements of a regular semigroup. Then $(a,b) \in\mathcal L$ if and only if there exists $a' \in V(a), b' \in V(b)$ such that $a'a = b'b$. I tried to prove it on my own, but failed. And I do not understand the proof in the book. So can anyone give me proof of it or clarify the one given in the book? By the way, I was unable to find this proposition for regular semigroups in other books. The proof from the book uses two previously shown Propositions, namely In a regular semigroup (or in a regular $\mathcal D$-class, i.e. every element is regular) each $\mathcal L$-class and each $\mathcal R$-class contains an idempotent. If $D$ is a regular $\mathcal D$-class and $a,b \in D$ are such that $R_a \cap L_b$ and $L_a \cap R_b$ contain idempotents $e,f$ respectively, then the $\mathcal H$-class of $b$ contains an inverse $a^*$ of $a$ such that $aa^* = e, a^*a = f$. Now the proof goes like this: Suppose that $(a,b) \in \mathcal L$. If $a' \in V(a)$ then $a'a$ is an idempotent in $L_a = L_b$. The $\mathcal R$-class $R_b$ contains at least one  idempotent by Proposition 1 above, and then, by Proposition 2 above, the $\mathcal H$-class $R_{a'a} \cap R_e$ contain an inverse $b'$ of $b$ with the property that $b'b = a'a$ (and $bb' = e$). Notice that we have shown the stronger implication that
  $$
 (a,b) \in \mathcal L \Rightarrow (\forall a' \in V(a))(\exists b' \in V(b)) a'a = b'b.
$$ That's it. I found that in an older book by the same author, named Introduction to semigroup theory (which seems to be a precursor of the present book) the same Proposition appears, but the referred $\mathcal H$-class is $R_{a'a} \cap L_e$ and not $R_{a'a} \cap R_e$ (which seems to make more sense as $\mathcal H$-classes are intersection of $\mathcal R$-classes and $\mathcal L$-classes by definition, but note that the $\mathcal H$-class of $b$ is $L_b \cap R_b = L_{a'a} \cap R_e$). But what I do not understand is that to apply Proposition 2 above, we need something like $L_a \cap R_b$ and $R_a \cap L_a$ should contain idempoents, but I do not see that $a'a$ is in $R_a$ (or $R_b$) neither do I see that $e$ is in $L_a = L_b$, and even if I write $e \in R_b \cap L_e$ then I need $a'a \in R_e \cap L_a$, but this I neither see? EDIT: I found the following related question here.","['group-theory', 'abstract-algebra', 'greens-relations', 'semigroups']"
2893235,Clarifying definition of maximum/minimum point,"Can a point be considered maximum/minimum if the graph ends at that point? Consider the following image. Point A is a typical maximum point. At that point, $\frac{dy}{dx}= 0$ and $\frac{d^2y}{dx^2} < 0$. Now consider this image. What about Point B? At Point B, both the conditions $\frac{dy}{dx}= 0$ and $\frac{d^2y}{dx^2} < 0$ are also fulfilled. Yet, we don't usually think of it as a ""maximum"" point. Is it actually one? Am I missing something?","['calculus', 'derivatives']"
2893242,Looking for a bound on a contour integral,"I'm looking for an estimate of this contour integral $$\left|\,\int_{\gamma}\,\left(\,1+\log^2(u)\,\right)^a\,du\,\right|$$ where parammeter $a\in\mathbb{C}$ and the path $\gamma$ is the circle with center $b$ and radius $b$, that is, $\gamma=\{\,u \,;\,|u-b|=b\,\}$ with $ 0.5\leq b<0.8.$ Since its calculation is difficult, it would be enough to find a bound. With the classical parameterization $$\left|\,\int_{\gamma}\,\left(\,1+\log^2(u)\,\right)^a\,du\,\right|\leq\,b\,\int_0^{2\pi}\left|\,\left(\,1+\log^2(b+be^{i\,x})\,\right)^{\,a}\,\right|\,dx$$ Any help will be wellcome. Edit_1 :
We can split
$$\int_0^{2\pi}\left|\,\left(\,1+\log^2(b+be^{i\,x})\,\right)^{\,a}\,\right|\,dx=\int_0^{\pi}\left|\,\left(\,1+\log^2(b+be^{i\,x})\,\right)^{\,a}\,\right|\,dx+\int_{\pi}^{2\pi}\left|\,\left(\,1+\log^2(b+be^{i\,x})\,\right)^{\,a}\,\right|\,dx$$ and after a chenge of variable $x-\pi\to y $ we obtain two similar integrals $$\int_0^{\pi}\left|\,\left(\,1+\log^2(b+be^{i\,x})\,\right)^{\,a}\,\right|\,dx+\int_0^{\pi}\left|\,\left(\,1+\log^2(b-be^{i\,x})\,\right)^{\,a}\,\right|\,dx$$ The question was solved by Szeto below. Edit_2 : Now, it's possible to find $\int_0^{2\pi}\left|\,\left(\,1+\log^2(b+be^{i\,x})\,\right)^{\,a}\,\right|\,dx$ ? May be with a change of variable like $b+be^{i\,x}\to e^y$ ?","['complex-analysis', 'contour-integration']"
2893246,Minimum value of the expectation $\mathbb{E}[ X_1 X_2 / (X_1^2 + X_2^2) ]$,"Let $X_1$ and $X_2$ be i.i.d. random variables from a distribution $D$ on the real numbers with finite variance (and therefore finite mean). Assume that the probability of $X_i = 0$ is $0$. Must it be true that
$$
\mathbb{E}\left[ \frac{X_1 X_2}{X_1^2 + X_2^2} \right] \ge 0?
$$
If not, what is the infimum over all such distributions of this expectation? Comments The expectation is always finite. It is possible for the expectation to be $0$, when $D$ is symmetric about $0$. My conjecture is that this expectation is necessarily nonnegative. Of course without the denominator, $\mathbb{E}[X_1 X_2] = \mathbb{E}[X_1] \cdot \mathbb{E}[X_2] = \mu^2 \ge 0$. But with the denominator, it is not so clear. I imagine this may be very elementary: I am not an expert in most inequalities used in probability theory. I tried expanding the fraction with partial fractions over the complex numbers, getting
$$
\frac{X_1 X_2}{X_1^2 + X_2^2} = \frac{\tfrac12 X_2}{X_1 + i X_2} + \frac{\tfrac12 X_2}{X_1 - i X_2},
$$
but I don't have an idea for how to evaluate these expectations, either. This question is a result of my previous question . Specifically we can write
$$
\mathbb{E}\left[ \frac{(X_1 + X_2)^2}{X_1^2 + X_2^2}\right] = 1 + 2 \cdot \mathbb{E}\left[ \frac{X_1 X_2}{X_1^2 + X_2^2} \right],
$$
and in the answer to my previous question it seemed to be the case that the former expectation never goes below $1$. This is equivalent to the present question about the latter expectation.","['inequality', 'probability-theory', 'expectation']"
2893264,Combinatorial problems that were solved using the representation theory of finite groups?,"Question: What are some examples of problems in combinatorics that were solved using the representation theory of finite groups ? I am aware the representation theory of finite groups plays a role in solving problems in number theory, for example automorphic forms . But what are some (important) examples from combinatorics. We have the following paper from Diaconis: Group Representations in Probability and Statistics . In particular are the results related to card shuffling.","['finite-groups', 'big-list', 'combinatorics', 'group-theory', 'soft-question']"
2893357,Counting Conjugacy Classes: $A^6 = I$,"This question is inspired by this earlier post .  The question that I'm interested in is as follows: Let $S= \{A \in \mathbb{Q}^{k \times k} : A^6 = I \text{ and }A^n \ne I \text{ for any }0 < n < 6\}$. How many orbits under conjugation by $GL_k(\mathbb{Q})$ does $S$ contain? Per the argument that I've given in the linked post, it suffices to list representatives in rational canonical form .  Thus, it is equivalent to enumerate the multisets of irreducible polynomials $\{p_1,\dots,p_n\}$ (which are the polynomials corresponding to companion matrix blocks) each of which divides $x^6-1$, whose degrees sum to $k$, and whose lcm divides $x^6 - 1$ but no polynomial of the form $x^n - 1$ for $n < 6$. Of course, there is only one such multiset in the case of $k=2$, hence the answer to the linked question.  As $k$ grows things get trickier. For $k=5$, we have
$$
\{x^2 - x + 1, x \pm 1, x \pm 1, x\pm 1\}\\
\{x^2 + x + 1, x+1, x\pm 1, x\pm 1\}\\
\{x^2 - x + 1,  x^2 \pm x + 1 ,x \pm 1\}\\
\{x^2 + x + 1, x^2 + x + 1, x+1\}\\
$$
For a total of $14$ conjugacy classes. How might one approach this problem in general?","['matrices', 'abstract-algebra', 'linear-algebra', 'combinatorics']"
2893412,Zero-dimensional and non-archimedean spaces,"A zero-dimensional (Hausdorff) space is a space such that the set of all ""open-and-closed"" sets is a basis for the topology. A non-archimedean space is a space with a basis for the topology such that any two basic sets either are disjoint or one contains the other. In the P. Nyikos' paper ""A Survey of zero-dimensional spaces"" ( Topology (Proc. 9th Annual Spring Conf. Memphis, 1975) , M. Dekker (1976) pp. 87â€“114) is stated that every compact zero-dimensional space is non-archimedean, but he doesn't prove it (moreover, he doesn't cite any explicit reference for this fact). Do you know a reference for this fact? I'm interested in the proof.","['general-topology', 'reference-request']"
2893433,Analyticity of the convolution of two functions,"This question came about when trying to answer this one . Does there exist a function $f\in C^\infty(\Bbb R)$ not identically zero such that: $f$ is supported on $[-1,1]$ , $f$ is analytic on $(-1,1)$ , The convolution $f*f$ is analytic at $0$ ? Typical example of an $f$ satisfying 1. and 2. is $e^{-1/(1-t^2)}\chi_{[-1,1]}$ , where $\chi_A$ is the characteristic function of the set $A$ .","['fourier-analysis', 'real-analysis']"
2893478,"Show that $ \max\big\{ (1-x)(1-y) , xy , x(1-y) + y(1-x)\big \} \geq \dfrac49$ for $x,y \in [0,1]$.","For $x$ and $y$ in the interval $[0,1]$, show that
$$\max\big\{ (1-x)(1-y) , xy  , x(1-y) + y(1-x) \big\}\geq \frac49$$
 I have been thinking on this for some time but couldn't get to prove it, any inputs are welcome.","['optimization', 'algebra-precalculus', 'analysis', 'real-analysis']"
2893495,Why the weak topology is never metrizable?,"Let $X$ be an infinite-dimensional normed space.  Why the weak topology on $X$ is never metrizable ? I saw a proof here but I don't really understand the argument. Here is his argument Assume that there is a metric $d$ on $X$ inducing the weak topology, and consider $U_n:=\{x\in X: d(x,0)<\frac{1}{n}\}$.  We know each $U_n$ is weakly open and so will be unbounded, and thus $$\forall (n)\exists (x_n\in U_n) \:\text{s.t.}\: \|x_n\|\geq n$$ But $x_n\to 0$ in $(X, d)$, so that $x_n \stackrel{w}{\to}0$, and hence $(x_n)$ is bounded. Contradiction. Q1) Why $U_n$ is weakly open ? Is it because a basis of the weak topology is of the form $$\{B_d(x,\varepsilon)\mid x\in X, \varepsilon>0 \}$$
where $$B_d(x,\varepsilon)=\{y\in X\mid d(x,y)<\varepsilon\} \ ?$$ Q2) Why are $U_n$ unbounded ? Since $U_n\subset B(0,1)$ for all $n\geq 1$, then $U_n$ is bounded (for me, in a metric space $(X,d)$, a set $A$ is bounded, if it's included in a ball $B_d(a,\varepsilon)$... since here $U_n\subset B_d(0,1)$ for all $n\geq 1$, it should be bounded). I really don't understand the argument here.","['general-topology', 'functional-analysis', 'metric-spaces']"
2893509,When does the continuous dual of the weak operator topology consist only of finite linear combinations of evaluations?,"Let $V$ and $W$ be topological vector spaces, say, over $\mathbb C$. Let $L(V, W)$ be the vector space of continuous linear maps equipped with the weak operator topology , which is the initial topology for the maps
$$\begin{align*}
\phi_{v, \mu} : L(V, W) &\to \mathbb C \\
T & \mapsto \mu(Tv)
\end{align*}$$
for $v \in V$ and $\mu \in W^*$ (the continuous dual of $W$). Equivalently, it is the topology induced by the seminorms $p_{v, \mu} = |\phi_{v, \mu}|$. In particular, $L(V, W)$ is locally convex, and Hausdorff iff $W^*$ separates points of $W$. By construction, the $\phi_{v, \mu} : L(V, W) \to \mathbb C$ are continuous linear maps, and so are finite linear combinations of the $\phi_{v, \mu}$. Under which conditions do the $\phi_{v, \mu}$ span the continuous dual $L(V, W)^*$? I know that this is the case when $V = W$ is a Hilbert space. (Takesaki, Theory of Operator Algebras I , Chapter II Theorem 2.6.) In these notes , Paul Garrett suggests that this is more generally true for certain topological vector spaces: the proof of the second corollary on page 3 uses that this is true when $V$ is an LF-space and $W$ quasi-complete and locally convex.) It does not give a precise statement, which makes we wonder if this is true for general topological vector spaces: Is there any good reference which addresses the case of topological vector spaces (not just normed spaces)?","['operator-algebras', 'operator-theory', 'topological-vector-spaces', 'weak-topology', 'functional-analysis']"
2893539,Boundedness of a subset using boundedness of linear functionals,"Let $S\subset X$ be a subset of a normed linear space such that $\sup_{x\in S} |f(x)|<\infty$ for all $f\in X^*$, the continuous dual of $X$. Prove that the set $S$ is bounded. By definition $S$ is bounded if $d(S)<M$ for some $0<M\in\mathbb{R}$, where $d(S)$ denotes the diameter. I already proved that this is equivalent to $\sup_{x\in S}\|x\|<\infty$ in the previuos exercise, so probably I should use that here, but I don't know how. I also thought about using Hahn-Banach: I know that for every $a\in S$ there is $f_a\in X^*$ such that $f_a(a)=\|a\|$ and $\|f_a\|=1$, but I don't get to use the second condition. What I can show is $$\|a\|=f_a(a)\leq\sup_{x\in S}|f_a(x)|<\infty.$$ But know I don't know what happen if I take the supremum on both sides. How do I see that the right side stays bounded?","['analysis', 'functional-analysis', 'upper-lower-bounds', 'dual-spaces', 'supremum-and-infimum']"
2893560,"Why does Spivak say ""$dx$ (in $\int f(x) dx$) has no meaning in isolation"" in his Calculus textbook?","I was under the impression that the $dx$ in $\int f(x) dx$ is called the differential and represents an infinitesimal change in $x$ . However, at the bottom of p. 264 in Spivak's Calculus (4th ed.) , the author writes ""The symbol $dx$ has no meaning in isolation, any more than the symbol $x \rightarrow$ has any meaning; except in the context $\lim\limits_{x
\rightarrow a} f(x)$ ."" He also states on the next page that for $\int x^2 dx$ , ""The entire symbol $x^2 dx$ may be regarded as an abbreviation for:
the function $f$ such that $f(x) = x^2$ for all $x$ ."" Upon looking at the appendix, there are no mentions of the word ""differential"" in the book. However, he makes use of them later in the book while describing the integral substitution formula using the equations \begin{equation}
\begin{split}
u &= g(x),\\
du &= g'(x)dx
\end{split}
\end{equation} and \begin{equation}
\begin{split}
x &= g^{-1}(u)\\
dx &= (g^{-1})'(u)du.
\end{split}
\end{equation} Is anyone familiar with the reasoning behind this seemingly deliberate omission?","['limits', 'calculus', 'definition', 'infinitesimals']"
2893574,How to show the morphisms $f_i$ glue to a morphism $f:X\to Y$.,"$\textbf{Liu Qing, Proposition 5.1.31.}$ Let $Y=\operatorname{Proj}A[T_0,\cdots,T_d]$ be a projective space over a ring $A$, and let $X$ be a scheme over $A$. (b) Conversely, for any invertible sheaf $\mathscr L$ on $X$ generated by $d+1$ global sections $s_0,\cdots,s_d$, there exists a morphism $f:X\to Y$ such that $\mathscr L\simeq f^*\mathscr O_Y(1)$ and $f^*T_i=s_i$ via this isomorphism. $\textbf{Proof}$ (b) The open subsets $X_{s_i}$ cover $X$. For every $i\le d$, let us consider the morphism $f_i:X_{s_i}\to D_+(T_i)$ corresponding to the ring homomorphism 
$\mathscr O_Y(D_+(T_i))\to \mathscr O_X(X_{s_i}),$ $T_j/T_i\mapsto s_j/s_i\in \mathscr O_X(X_{s_i})$. It is clear that the morphisms $f_i$ glue to a morphism $f:X\to Y$, and that $\mathscr L\simeq f^*\mathscr O_Y(1)$ by Proposition 1.14(b) and the description in Example 1.19. Now I'll explain the above proof. For every $i\le d$, let us consider the morphism $f_{ij}:X_{s_i}\cap X_{s_j}\to X_{s_i}\to D_+(T_i)$ corresponding to the ring homomorphism 
$\mathscr O_Y(D_+(T_i))\to \mathscr O_X(X_{s_i})\to\mathscr O_X(X_{s_i}\cap X_{s_j}),$ $T_k/T_i\mapsto s_k/s_i\mapsto s_k/s_i\in \mathscr O_X(X_{s_i}\cap X_{s_j})$. It can be factored as follows:
$\mathscr O_Y(D_+(T_i))\to \mathscr O_Y(D_+(T_iT_j))\to \mathscr O_X(X_{s_i}\cap X_{s_j})$ $T_k/T_i\mapsto (T_kT_j)/(T_iT_j)\mapsto s_k/s_i\in \mathscr O_X(X_{s_i}\cap X_{s_j})$. The second ring homomorphism $\mathscr O_Y(D_+(T_iT_j))\to \mathscr O_X(X_{s_i}\cap X_{s_j})$ is defined as follows:
$(T_mT_n)/(T_iT_j)\mapsto (s_m/s_i)(s_n/s_j)\in \mathscr O_X(X_{s_i}\cap X_{s_j})$. Let $s_j/s_i=a, s_i/s_j=b$. $\because s_j=as_i=(ab)s_j$, $\therefore ab=1$, $\therefore (s_m/s_i)(s_n/s_j)=(s_n/s_i)(s_m/s_j)$. $\therefore$The ring homomorphism is defined well. $\therefore f_{ij}(X_{s_i}\cap X_{s_j})\subset D_+(T_iT_j)$ and $f_{ij}=f_{ji}.$ It is clear that the morphisms $f_i$ glue to a morphism $f:X\to Y$. Is my argument correct?","['algebraic-geometry', 'schemes', 'sheaf-theory']"
2893586,Probabilities regarding casino slot machine,"Exercise : A casino slot machine has been programmed so as to offer total winnings $X$ euros per hour, regardless of other hours, with $Î¼_x = E[X] = 180$ and $Ïƒ_x = V[X] = 10.125$ . From long term data we know that the value $Y$ in euros that players bet per hour (independent of the values that are played at other hours and the winnings values) follows the uniform distribution over the interval $[100,300]$ . (a) Calculate approximately the probability that in the duration of one month the slot machine has yielded total winnings of over $135.000$ euros. (b) Calculate approximatel the probability that in the duration of one month the clear profit of the casino is over $10.000$ euros. (c) Let it be that we want to change the parameter $\sigma$ in the program of the slot machine. What is the biggest value of $\sigma$ for which the clear profit that the slot machine yields for the casino is over $10.000$ with probability at least $95%$ ? (Suppose that the casino operates the 24hrs per day and that every month has 30 days). Attempt - Question : (a) Since we are asked to calculate the probability of winnings over the course of one month, we should multiply the variable $X$ by $24 \cdot 30 = 720$ . Thus, what we need to find, is : $$P[720X > 135.000] = 1 - P[720X \leq 135.000] = 1 - P[X \leq 187.5] = 1 - P[X-180 \leq 7.5] = 1 - P\bigg[\frac{X-180}{45\sqrt{5}} \leq \frac{7.5}{45\sqrt{5}}\bigg] = 1 - P\bigg[Z \leq \frac{7.5}{45\sqrt{5}}\bigg]$$ which can be calculated approximately via the $\Phi$ probability function boards. (b) The clear profit of the casino in the duration of one month is the total value of the bets by the players minus the total winnings, thus $720(Y-X)$ . Now, the probability of the clear profit of the casino being over $10.000$ per month is : $$P[720(Y-X) > 10.000] = 1 - P[720(Y-X) \leq 10.000] = 1 - P[Y-X \leq 125/9$$ Since $Y \sim U(100,300)$ , it will be $E[Y] = 200$ and $V[Y] = 10000/3$ . How should I proceed now to calculate the probability above ? How would I form a normal distribution simulation for $2$ variables this time, which follow different distributions ? (c) For the probability of the casino earnings (total profit) being more than $10.000$ with at least $95%$ probability, I assume that something like this is needed : $$P[720(Y-X) > 10.000] = 0.95$$ but proceeding in this case I have the same issue as before, thus leading to the initial question. How would I proceed with implementing the parameters of the distributions both the variables $X$ and $Y$ into a normal distribution simulation fraction in order to produce an approximate probability ? Also, is my approach for part (a) correct ?","['statistics', 'probability-limit-theorems', 'probability-distributions', 'probability-theory', 'probability']"
2893621,Avoiding exactly one permutation pattern,"Let $n \geq k$.  We say that a permutation $\sigma \in S_n$ contains a permutation (or ""pattern"") $\tau \in S_k$ if there is a substring of $k$ (not necessarily consecutive) elements of $\sigma$ ordered like $\tau$.  For example, the permutation $\sigma=24513$ contains $132$, since the string $243$ in $\sigma$ has the same relative order as $132$. Similarly, it contains $123$ (the string $245$), $213$ (the string $213$), $231$ (the string $451$) and $312$ (the string $513$).  The only length-$3$ pattern it does not contain is $321$. Question: Given a permutation $\tau \in S_k$, is it possible to find a value of $n$ and a permutation $\sigma \in S_n$ such that $\sigma$ contains every pattern of length $k$ except $\tau$? Overly Ambitious Generalization: Given a permutation $\sigma \in S_n$ and a $k \leq n$, let $T_k(\sigma)$ be the set of patterns of length $k$ contained in $\sigma$.  For a fixed integer $k$, what sets of patterns can possibly appear as $T_k(\sigma)$ for some $\sigma$? For large $k$, almost all subsets do not ever occur as a $T_k(\sigma)$.  One way to see this: By ErdÅ‘sâ€“Szekeres every permutation with $n>(k-1)^2$ contains either $123\dots k$ or $k\dots 321$.  There's less than $(k^2)!$ other choices for $\sigma$, each of which contains at most $\binom{k^2}{k}$ patterns.   So at most $\binom{k^2}{k} (k^2)!$ subsets containing neither $123\dots k$ nor $k \dots 321$ ever appear as a $T_k$, which is much smaller than the total number of subsets not containing those two patterns. The first question arose out of a discussion I had with a computer science graduate student about the complexity of testing for pattern containment.  Most of the work I've seen on pattern-avoiding permutations has focused more on enumerating them, and I'd appreciate any references to other work done on relationships between various pattern containments.","['permutations', 'pattern-matching', 'combinatorics', 'reference-request']"
2893710,Enquiry about the number of irreducible representations of a finite group,"In the representation theory of groups, it is a common assertion that the number of irreducible representations of a finite group G over the complex numbers is equal to the number of conjugacy classes of G. I have two quires: 1- Do we still have such a result if the field we are working on is of characteristic zero? 2- Till now the books I read, the authors stated such a fact with either the field of complex numbers $\mathbb{C}$ or the algebraically closed field F; what is significant of requiring algebraically closed field?","['representation-theory', 'group-theory', 'finite-groups']"
2893717,Zeta function generalized to quaternions?,"Has the $\zeta(s)$ function, $\sum_n 1/n^s$, been generalized
  to quaternions, so $\zeta(q)$ for $q$ a quaternion? Euler defined it for $s$ integers, Chebyshev for $s$ real,
Riemann for $s$ complex. So it is natural to explore $s$ a quaternion. But perhaps this does not lead to an interesting Quaternion Hypothesis?","['complex-analysis', 'number-theory', 'riemann-zeta', 'quaternions']"
2893725,Making a matrix as sparse as possible,"Consider a matrix $A \in \mathbb{R}^{m \times n}$ where $n >> m$. In other words, $A$ has much more columns than rows. Also, consider we are given a fixed number (integer) $m \leq r < n$. I'm trying to find a matrix $B \in \mathbb{R}^{r \times m}$ such that $B' B = I_m$ (i.e., $B'$ is the left inverse of $B$) and $BA$ is very sparse, as much as possible. My first idea was to consider the case $r = m$ and take the $QR$ factorization of $A$. Then set $B = Q^T$ to get 
$$BA = Q^TA = Q^TQR = I_mR = R,$$ 
a triangular (and rectangular) matrix. This matrix has a few zeros in the first $m$ columns, but since $m$ is much smaller than $n$, there are a lot of non zero terms left. Also, in my context usually $r$ will be bigger than $m$ and smaller than $n$, so I don't want to choose specif values for $r$. I really want a general approach that maximizes the number of zero entries in $BA$ for a generic $r$ between $m$ and $n$. I wonder if there is a better matrix to do the job. Hope you can help me. Thank you.","['matrices', 'sparse-matrices', 'linear-algebra', 'linear-transformations']"
2893726,"Is Paolo Aluffi's ""Algebra: Chapter 0"" enough algebra preparation for a standard graduate course in algebraic geometry (using Hartshorne's text)?",Does Aluffi's book have enough commutative algebra for algebraic geometry? I understand that traditional graduate algebra course using Hungerford's book or Lang's book provides enough background for such a course.,"['algebraic-geometry', 'abstract-algebra']"
2893733,Prove $A\cap(A'\cap B')'=A$ using set equivalence laws,I am having trouble using set equivalence laws to prove the following. $$A\cap(A'\cap B')'=A$$ Any help would be greatly appreciated.,['elementary-set-theory']
2893748,"Given a $3\times3$ real matrix $A$ with eigenvalues $0,1,2$, find real constants $a,b,c$ such that $aI+bA+cA^2$ has eigenvalues 0,1,3","Suppose $A$ is a $3\times 3$ real matrix with three distinct eigenvalues $0,1,2$. Find real constants $a,b,c$ such that the matrix $aI+bA+cA^2$ has eigenvalues $0,1,3$. My only initial thought on how to approach this problem is to use the Cayley-Hamilton theorem. i.e. 
$$A^3+3A^2+2A=0=(cA^2+bA+aI)^3-4(cA^2+bA+aI)^2+3(cA^2+bA+aI)$$
but this is a pretty ugly system (I didn't bother to show the algebraic steps of expanding the characteristic polynomials, but they are $C_p(A)=x(x-1)(x-2)$ and $C_p(aI+bA+cA^2)=x(x-1)(x-3)$). Thanks in advance for any assistance.","['eigenvalues-eigenvectors', 'cayley-hamilton', 'matrices', 'linear-algebra', 'matrix-equations']"
2893852,The degree of the sum is the larger of the two starting degrees.,"I am doing a course in algebra, in the course professor is teaching "" The degree of the sum is the larger of the two starting degrees"" which means if we add two polynomial having the same degree then after doing the sum the total degree will add up. I am finding the flaw in the above quoted statement. How come the degree of the sum will be larger it has to be same. If we add $x^2 + x^2$ the sum will be $2x^2$, degree remains same.",['algebra-precalculus']
2893897,Is weak operator topology (WOT) limit of unitary operators isometry?,"Let $(U_{\alpha})$ be net of unitary operator in $B\mathcal{(H)}$ s.t. $U_{\alpha} \xrightarrow {\text{WOT}}V$.Can we conclude that V is an isometry? If it be not true give a counter example. Comments : I observe that if $U_{\alpha} \xrightarrow {\text{SOT}}V$ then V is necessarily isometry. But I could not able to justify the statement for weak operator topology case neither by proving nor by giving counter example. Notations : $U_{\alpha} \xrightarrow {\text{WOT}}V$ means $\langle U_{\alpha}x,y\rangle\rightarrow\langle Vx,y\rangle$ for all x,y $\in\mathcal{H}$, $U_{\alpha} \xrightarrow {\text{SOT}}V$ means $\Vert 
U_{\alpha}x\Vert\rightarrow\Vert Vx\Vert$ for all x$\in \mathcal{H}$ and $\mathcal{H}$ is a Hilbert Space. Any comment regarding proving the statement or giving counter example is highly appreciated.Thanks in advance.","['operator-theory', 'functional-analysis']"
2893908,Proving the required condition for $f(x)$ from given information,"Let $f:[0,1]\to\mathbb{R}$ be twice differentiable function such that $f(0)=f(1)=0$ and $f''(x)-2f'(x)+f(x)\geq  e^x$ then prove that $fâ€™(x)\cdot f(x)$ has at least one root in $(0,1)$. My thought : $$f''(1)-2f'(1)\geq e$$
and
$$f''(0)-2f'(0)\geq 1$$
If we assume $g(x)=f(x)-x$ and the function $g'(x)$ is $0$ at least once in the domain of $f$ such that $x\in(0,1)$. Also if we use the given equation we get $e>f''(a)-f(a)>1$ for any $a$ in $(0,1)$ where $g'(x)$ may be zero at least once in $(0,1)$. After this I am not able to think how to proceed further. Please explain in simpler terms as I as newbie in this zone of mathematics. :-)","['functions', 'derivatives']"
2893939,"Proof verification: Let $f:O\subset \Bbb{R}^n\to\Bbb{R}$ be a $C^3$ function. If $A$ is positive, then $x_0$ is a local minimum.","Let $f:O\subset \Bbb{R}^n\to\Bbb{R}$ be a $C^3$ function. Let $x_0\in O$ be a critical point of $f$. Let \begin{align}A=\left(\frac{\partial ^2f}{\partial x_i\partial x_j}\right)_{1\leq i,j\leq n}\end{align}
If $A$ is positive, then $x_0$ is a local minimum. Proof By Taylor's formula
\begin{align}f(x)=f(x_0)+f'(x_0)(x-x_0)+\frac{f''(x_0)}{2!}(x-x_0)^2+\Vert x-x_0 \Vert^2\epsilon(x-x_0)\end{align}
But \begin{align}f'(x_0)=0\end{align}This implies
\begin{align}f(x)-f(x_0)=\frac{f''(x_0)}{2!}(x-x_0)^2+\Vert x-x_0 \Vert^2\epsilon(x-x_0)\end{align}
Now,
\begin{align}
f''(x_0)(x-x_0)^2=\langle A(x-x_0),(x-x_0)\rangle\end{align}
\begin{align}
=\sum^{n}_{i=1}\sum^{n}_{j=1}\frac{\partial ^2f(x_0)}{\partial x_i\partial x_j}(x_j-x_{0_j})^2\end{align}
\begin{align}
=\sum^{n}_{i=1}\sum^{n}_{j=1}(x_j-x_{0_j})\frac{\partial ^2f(x_0)}{\partial x_i\partial x_j}(x_j-x_{0_j})\end{align}
\begin{align}
=\langle (x-x_0),A(x-x_0)\rangle\end{align}
Thus, 
\begin{align}f(x)-f(x_0)=\frac{\langle (x-x_0),A(x-x_0)\rangle}{2!}(x-x_0)^2+\Vert x-x_0 \Vert^2\epsilon(x-x_0)\end{align}
\begin{align}f(x)-f(x_0)\geq\Vert x-x_0\Vert^2\left[\alpha+\epsilon(x-x_0)\right],\;\;\text{for some}\;\alpha>0\end{align}
Hence, $\exists\;\delta>0$ such that $\Vert x-x_0\Vert<\delta$ implies $\left[\alpha+\epsilon(x-x_0)\right]>0$. So, for $x\in(x_0-\delta,x_0+\delta)$
\begin{align}f(x)\geq f(x_0)\end{align}
Therefore, $x_0$ is a local minimum. Can someone check if this proof is correct? Corrections will be highly welcome! Thanks","['multivariable-calculus', 'calculus', 'proof-verification', 'derivatives']"
2893991,Evaluate $\int \frac{\sqrt{1+x^8} dx}{x^{13}}$,Evaluate: $\displaystyle\int \frac{\sqrt{1+x^8}}{x^{13}}dx$ My attempt : I have tried substituting $1+x^8=z^2$ but that did not work. I also tried writing $x^{13}$ in the denominator as $x^{16}.x^{-3}$ hoping that it would bring the integrand into some form but that too did not work.,"['integration', 'indefinite-integrals']"
2893993,Commutator of Lie derivative and Hodge star operator,"I want to derive and expression for the commutator $[\mathcal{L}_Z,\star]\omega$. I found this post of mathoverflw that answers this question, but I have a few questions about Willie Wong's proof. How is the inverse metric $g^{-1}$ defined? I would guess that $g^{-1}$ is the metric defined on pairs of $1$-forms $g^{-1}(\alpha,\beta)=g(\alpha^\sharp,\beta^\sharp)$ where $\sharp$ denotes the musical isomorphism. He then states that $\star\omega = \text{Vol}_g\cdot(g^{-1})\cdot\omega$. I don't understand where this expression comes from, or what the $\cdot$ operator represents. Most likely it represents tensor contraction. I also don't understand where the expression $\mathcal{L}_Zg^{-1} = g^{-1}(\mathcal{L}_Zg)g^{-1}$ comes from. I would be very appreciative if someone could explain what exactly is going on here.","['differential-geometry', 'lie-derivative', 'differential-topology', 'differential-forms', 'exterior-algebra']"
2894036,Writing numbers with fewer symbols using expressions with powers,"For example, it takes 7 symbols to write the natural number $n=9999999$ but we can also write it with 5 symbols as $n=10^7-1$. (Of course, with even larger exponents we can save even more symbols.) Another example: $13841304697 = 7^{12}+8*3^7$. Here we have 11 symbols vs. 8 symbols. Let's denote by $r(n)$ the minimal number of symbols needed to represent the natural number $n$ with this sort of expressions using exponentiation (to a natural number), $+, -, *$ and $/$. There are all sorts of interesting questions that arise: How to find the minimal representation? Does some sort of greedy algorithm that takes  $a^b$ away from $n$ so that $r(n-a^b)$ is minimal work? What type of numbers $n$ have large values for $r(n)$ relative to the number of digits of $n$? How much writing numbers minimally like this, saves space. To put it formally, what can we say about $$\frac{\sum_{n=0}^N r(n)}{ \sum_{n=0}^N (\lfloor \log_{10}(n)\rfloor + 1) }?$$","['number-theory', 'natural-numbers']"
2894042,Do even degree polynomials have even degree factors (no conjugates)?,"An even degree polynomial is a polynomial which has terms of only even degree, for example $3x^6 + x^4 + 2x^2 + 5$. Let $p$ and $q$ be two non-zero polynomials such that both don't have a term with the same degree (for example, $p = x^3 + x + 1$, $q = x^4 + 3x^2 + 5$ is not allowed since both have a term of degree 0). A conjugate factor pair is a pair of form $p + q$ and $p - q$. Assume all factorisation is over integers. Now suppose there is a even polynomial which doesn't have a conjugate factor pair in it's list of factors. Will all factors be even degree polynomials too? I really have no idea how to even approach this problem. Only thing I tried was taking examples. But I wasn't successful in finding a counter example. My inspiration behind asking this was that, if you remove the conjugate pair restriction, there there are examples like $(x-1)(x+1) = x^2 - 1$ or $(x^2 + 1 + x)(x^2 + 1 - x) = x^4 + x^2 + 1$.","['number-theory', 'abstract-algebra', 'factoring', 'polynomials']"
2894045,Action of a projection on a pairwise orthogonal projections.,Let us consider two projections $e_1$ and $e_2$ on the Hilbert space $H$ with $e_1e_2=0$. Does there exists any projection $p$ with $$\overline{pe_1(H)}=\overline{pe_2(H)}=\overline{p(e_1+e_2)(H)}\neq0$$,"['operator-theory', 'functional-analysis', 'operator-algebras']"
2894058,A group with finitely generated normal subgroup and finitely generated quotient is finitely generated itself,"Let $G$ be a group with $G \trianglerighteq N$ normal subgroup. Assume that $N$ is finitely generated, and $G /N$ (the quotient group) is finitely generated as well.
  Is $G$ finitely generated? I think that the answer is no, and I wanted to use the following example: $G = \mathbb{Q}$, $N=\mathbb{Z}$. My only remaining question is, how to show that $\mathbb{Q} /\mathbb{Z}$ is finitely generated?(if at all). And if it isn't, any other ideas?","['finitely-generated', 'group-theory', 'normal-subgroups']"
2894071,A holomorphic function with infinitely many zeros in the unit disc,"Prove that if $f$ is holomorphic in the unit disc, bounded and not identically zero, and $z_1, z_2, z_3, \dotsc, z_n, \dotsc$ are its zeros ($\vert z_k \vert$ $\lt1$ ),then
  $$\sum_{k=1}^\infty (1-\vert z_k \vert) \lt \infty$$
  [Hint:Use Jensen's formula.] Since Jensen's formula can be used when $f$ vanishes nowhere on the circle $C_R$. I notice that there exist an increasing sequence $r_n$ for   $\lim_{n\to \infty} r_n = 1$, and $f$ vanishes nowhere on each $C_{r_n}$. Suppose $f(0) \neq 0$, then use Jensen's formula on each circle $C_r$ and get
$$
    \sum_{k=1}^{n_r} \log \vert z_k \vert
  =   \log \vert f(0) \vert
    + n_r \cdot \log r
    - \frac{1}{2\pi}
      \int_{0}^{2\pi}
      \log \vert f(re^{i\theta}) \vert
      \,\mathrm{d}\theta,
$$ where $n_r$ denotes the numbers of zeros inside the disc $C_r$.
But I don't know how to estimate the limit of $n_r \log r$ as $r$ tends to $1$.",['complex-analysis']
2894084,If $A+B = AB$ then proving that $AB = BA$?,"Even though this has been asked before in main site If $A+B=AB$ then $AB=BA$ , still I had a query? If $A,B$ are both $n \times n$ matrix and the entries are from $\Bbb{R}$. If it satisfies $A+B = AB$, then can we say that $A$ and $B$ commute? that is $AB = BA$ ? I thought of this that as we are given the rule $A+B = AB$, so that also implies that $B+A =BA$ just interchanging the roles of $A$ and $B$? from which we get $AB = BA$ hence $A$ and $B$ commute. Any flaw in this? How do we approach this problem?",['linear-algebra']
2894085,An endofunction on natural numbers defined by induction on $n$.,"A function $f \colon \mathbb{N} \to \mathbb{N}$ fulfils the following conditions, for all $n \in \mathbb{N}$ : $f(4n) = f(2n) + f(n)$ ; $f(4n + 2) = f(4n) + 1$ ; $f(2n + 1) = f(2n) + 1$ . Question 1: Show that the cardinality of the set $S_m := \{n \in \mathbb{N} \mid n <  2^m \text{ and } f(4n) = f(3n)\}$ is $f(2^{m+1})$ . Question 2: Is it true that $\lim_{n \to +\infty} f(n) = +\infty$ ? In my opinion, the two questions, especially the first one, are really intriguing and challenging. I have no answer for either, just some preliminary remarks. Remarks: The conditions above define $f$ by induction on $n$ , since $f(0) = 0$ according to condition 1. For all $n > 0$ , we have that: $f(n) = f(n-1) + 1$ if $n$ is odd (according to condition 3); $f(n) = f(n-1)$ if $n$ is even and not divisible by $4$ (according to conditions 2 and 3); $f(n)$ decreases with respect to $f(n-1)$ if $n$ divisible by $4$ , but I'm not able to find a general law. I conjecture that $f(2^n) = F(n)$ where $F(n)$ is the $n$ th number of the Fibonacci sequence, but I don't have a proof of that","['elementary-number-theory', 'induction', 'functions', 'natural-numbers', 'algebra-precalculus']"
2894089,Expressing every natural number as a sum of elements of two disjoint subsets in a unique way,"I thought of the variation of the following question on AOPS:
""Find two infinite subsets $A$ and $B$ in $\mathbb{N}_{0}$ such that every positive integer can be written uniquely as the sum of an element in  $A$ and an element in $B$.""
The variation added by me was that the sets must intersect only at $\{0\}$.
Few trivial construction were to write the base $b$ representation of every positive integer (here $b$ is a prime number), and then consider the vector space $\mathcal{P}(b)$ of polynomials of $b$ with coefficients in $\mathbb{Z}_b$ and then find subspaces $U$ and $V$ such that $\mathcal{P}(b)=U\oplus V$.
I am looking forward for other constructions which also satisfy this variation of the problem.","['number-theory', 'linear-algebra']"
2894118,Is there any easy proof of Brouwer's fixed point theorem? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I am taking a course in game theory. For proving the Nash equilibrium we require  Brouwer's fixed point theorem. But I have not taken a topology course so I am finding the proof difficult to understand. You may explain the same Brouwer's in little easy way.","['game-theory', 'general-topology', 'nash-equilibrium']"
2894168,Confidence intervals for proportions - why isn't the Bessel correction used in estimating the standard deviation?,"When calculating confidence intervals for a population with standard deviation Ïƒ unknown, Ïƒ is estimated using the sample standard deviation S, which uses the Bessel correction to more closely approximate the real Ïƒ. But suppose the population X is a Bernoulli variable. X being now a binary variable, $
 \sum_{i=1}^n (x_i - \bar x)^2 = n\bar x (1 - \bar x)
$ (as we can see in an answer to this question). So the formula of the sample standard deviation would be $ S = \sqrt {\frac {n} {n-1} \bar x (1 - \bar x)}$. But in all resources I've read about confidence intervals for proportions , when the population proportion p is unknown, the standard deviation of the population is estimated by $ \sqrt{\bar p (1-\bar p)} $ . This approximation, however, does not use the Bessel correction. If it were, Ïƒ would be approximated by $ \sqrt{\frac {n} {n-1} \bar p (1-\bar p)} $. I understand that $ \bar p (1-\bar p)$ is a consistent estimator for $p(1-p)$, but wouldn't $\frac {n} {n-1} \bar p (1-\bar p)$ be consistend and unbiased, and thus a better estimator?","['statistical-inference', 'statistics', 'confidence-interval', 'standard-deviation', 'binomial-distribution']"
2894183,Learning Real Analysis outside a classroom setting,"I am studying Real Analysis -- using Baby Rudin -- on my own in a community that does not have a university near (if the ""why"" is important, see below).  I recently worked through standard texts for Calculus, (basic) Differential Equations, Linear Algebra, Vector Calculus and [Eccles] ""Introduction to Mathematical Reasoning"" in preparation.  Most of those were fairly easy to do in a self-study environment, because it was reasonably easy to tell, when doing the problem-sets, whether I'd gotten it right or not.  (Student & Instructor answer books and Chegg helped a good bit when I got stuck; which was not often, but more often than I'd like .) However: while I have the answer-book for Rudin, I'm finding it much harder to tell -- where most problems are of the form ""Prove X"" -- whether my proofs are valid unless they match precisely those in the answers.  Sometimes they do.  Usually there are subtle (or greater) differences.  And I cannot reliably tell whether those 'subtle differences' are inconsequential or horrifyingly stupid (plus WRONG).   Anyone with thoughts or experience on how this subject can best be learned in a self-study environment?  Or is it likely I'm going to have to develop a resource -- one way or the other -- to 'grade' my efforts and help keep me on track?  Thanks for considering. [Possibly unnecessary framing information: Mostly I just want to spiff up my mathematical understanding.  But there exists a research project that I'd like to join, in my field (Medicine), which really needs at least some ability to think topologically about the problems, and which often involve (somewhat) the math of Chaos.  Thus I think I need to bring myself up to at least that level to participate.]","['self-learning', 'proof-verification', 'real-analysis']"
2894218,Functor of points of the affine line with double origin,"If $X$ is a scheme then the functor of points is the map $\hom(-, X)$ from the category of schemes to the category of sets.  If we restrict this to affine schemes and apply Yoneda then the functor of points becomes a functor from commutative rings into sets. In this context the functor of points of the affine line is very simple, it's just the forgetful functor which sends a ring $R$ to $R$ considered as a set with no structure. Is there a similarly nice description of the functor of points of the affine line with a double point at the origin? (Example 2.6.3 in Hartshorn)","['affine-schemes', 'algebraic-geometry', 'functors', 'schemes']"
2894224,Simplify $\sum_{k = 1}^n \tan(k) \tan(k - 1)$ by first proving $\tan(k)\tan(k - 1) = \frac{\tan(k) - \tan(k - 1)}{\tan(1)} - 1$,"I have the following problem: Use the formula $$\tan(A - B) = \dfrac{\tan(A) - \tan(B)}{1 + \tan(A) \tan(B)}$$ to prove that $$\tan(k)\tan(k - 1) = \dfrac{\tan(k) - \tan(k - 1)}{\tan(1)} - 1$$ Hence simplify $$\sum_{k = 1}^n \tan(k)\tan(k - 1)$$ Since we have that $$\tan(A - B) = \dfrac{\tan(A) - \tan(B)}{1 + \tan(A) \tan(B)},$$ I then deduced that $$\tan(k)\tan(k - 1) = \dfrac{\tan(k)[\tan(k) - \tan(-1)]}{1 + \tan(k)\tan(-1)}$$ But I'm not sure how to proceed from here. And I don't have any solutions to refer to. I would greatly appreciate it if people could please take the time to clarify this.","['trigonometric-series', 'trigonometry', 'summation', 'sequences-and-series']"
2894233,An uncountable set of reals in which any finite sum of elements is irrational - without choice,"I tried to prove the following: There exists a set $A\subseteq \mathbb{R}$ such that $|A|>\aleph_0$, and, for every $x_1,\ldots,x_n\in A$, $$x_1+\ldots+x_n \notin \mathbb{Q}$$ I found a solution using Zorn's lemma. I'm interested to know whether there exists a solution which doesn't apply the axiom of choice. My solution: Apply Zorn's lemma to find a maximal element among subsets $A\subseteq \mathbb{R}$ such that any finite sum of elements from $A$ doesn't belong to $\mathbb{Q}$. Now, if the maximal $A$ was countable, then we could extend it to $A\cup \{r\}$, where $r\in \mathbb{R}$ is picked as follows: take $r\in \mathbb{R}$ which doesn't belong to the countable set of elements of the form $q-S$, where $q\in \mathbb{Q}$ and $S$ is a sum of finitely many elements of $A$.","['elementary-set-theory', 'elementary-number-theory']"
2894236,Finding a chain map from an $F$-acyclic resolution to an injective resolution which is a monomorphism in each degree,"Let $\mathcal{A}$ be an abelian category with enough injectives. Let $F:\mathcal{A}\to\mathcal{B}$ be a left-exact additive functor to $\mathcal{B}$ another abelian category If $M$ has an $F$-acyclic resolution:
  $$0\longrightarrow M\longrightarrow X^0 \longrightarrow X^1 \longrightarrow X^2\longrightarrow\cdots$$ It is claimed ( In Lang (2002) on page 797 line 11 ) that I can find an injective resolution:
  $$0\longrightarrow M\longrightarrow I^0 \longrightarrow I^1 \longrightarrow I^2\longrightarrow\cdots$$ and a cochain map from the first resolution to the second, such that each $i\geq 0$ the morphism $X^i\to I^i$ is a monomorphism. Question: How do I find such an injective resolution, with such a chain map? My attempts are below! 1) Using that we have enough injectives, I can find a monomorphism $X^0\to I^0$ for some $I^0$ injective. Then by composition I can find a morphism $M\to X^0\to I^0$. This gives me the monomorphism $M\hookrightarrow I^0$. Similarly using enough injectives, we can find a monomorphism $X^1\hookrightarrow I^1$ for $I^1$ injective. Then using the composite $X^0\to X^1\to I^1$ and that $I^1$ is injective, we induce a morphism from $I^0\to I^1$. We can do this inductively to obtain a cochain map between $0\to M\to X^\bullet$ and $0\to M\to I^\bullet$, with these monomorphisms for all $k\geq 0$ $X^k\hookrightarrow I^k$ for $I^k$ injective. But I can't show that the bottom row is exact, and hence I cannot show that this $I^\bullet$ an injective resolution. In fact part of me doubts that it even is (even trying to chase elements fails, since I have no epimorphisms appearing). 1b) I tried taking cokernels in each degree so that I could try to do something with the epimorphisms it gives me. Mainly I want to apply $F$ and use the long exact cohomology sequence, to make use of the $F$-acyclicity. But unless I can show exactness on the second row, I can't ensure $F$ will preserve the short exact sequence of complexes. 2) I tried using that we have enough injectives to induces a monomorphism from $M\to I_M^0$ and a monomorphism $X^0\to I_{X^0}^0$ and taking the direct sum, which I can show is also an injective object, and then repeating this for $I_{X^0}^0\oplus I_M^0$ and $X^1$, so on. But this seems highly non-exact (in fact all the morphisms in this bottom row are probably injective...) 3) I think the category of chain complexes has enough injectives, but I don't think an injective object in the chain category looks like what I want. 4) I couldn't think of any way to take the injective resolution first, and then choose compatible morphisms such that the result follows.","['homological-algebra', 'abstract-algebra', 'homology-cohomology']"
2894246,Question: Compare the cardinality between the sets $\Bbb R$ and $\Bbb N^{\Bbb N}$,I was comparing the sets $\mathbb{N}^{\mathbb{N}}$ and $\mathbb{R}$ for a fun practice because I didn't know at first that $\mathbb{N}^{\mathbb{N}}$ was uncountable. But how can I compare two uncountable sets and see which has the larger cardinality?,"['elementary-set-theory', 'real-analysis']"
2894270,Adjunction space is homeomorphic to quotient: an easier proof?,"All spaces are in $Top.$ It is trivially obvious geometrically that if $A\subseteq X$, and $f:A\to *$, where $*$ is a singleton, then $X/A\cong X\cup_f *.$ I have never seen a proof of this, however, and since I know some category theory, I did it using pushouts. My work follows. But it seems like a lot of work to show something so trivial so my question is, how could we show this without using category theory? Consider the following commutative square. I show it is a pushout, from which we may conclude immediately that $X/A\cong X\cup_f *.$ $\require{AMScd} \begin{CD} A @>{f}>> *\\ @V{i}VV @VV{g}V\\ X @>>{\pi}> X/A\end{CD}$ Suppose there are $Z\in Top$ and 
 $\alpha: X\to Z;\ \beta:*\to Z$ such that $\beta f=\alpha i\ .$ Then, of course, $\beta f=z_p\in Z.$ Now, if we define $\phi:X/A\to Z$ by: $\phi([x])=\alpha (x)$ if $x\notin A$ and $\phi([A])=z_p,$ then, $\phi \pi=\alpha:$ $x\notin A\Rightarrow \phi ([x])=\alpha (x)\ $ and $x\in A\Rightarrow \phi \pi(x)=\phi([A])=z_p\ =\beta f(x)=\alpha i(x)=\alpha (x).$ $\phi g=\beta:$ $\phi g(*)=\phi([A])=z_p=\beta (*)$ The definition of the quotient topology implies that $\phi $ is continuous because $\alpha$ is and $\phi \pi=\alpha\Rightarrow \alpha^{-1}=\pi^{-1}\phi^{-1}.$ $\phi$ is unique by construction. Therefore, $X/A\cong X\cup_f *.$","['general-topology', 'geometry', 'category-theory', 'quotient-spaces']"
2894279,Deligne's theorem on the Leray spectral sequence and weights,"Motivation : If $f : X \to Y$ is a smooth projective map between algebraic varieties, then there is a theorem by Deligne which says that the Leray spectral sequence degenerates at $E_2$. The proof I know uses derived categories and Hard Lefschetz on the fibers. However I understood there was a simpler proof using weights, as suggested in the answer a previous question of mine here . In the article by Durfee, ""A naive guide to mixed Hodge structures"", the axioms state that a morphism preserves weights if the morphism is geometric i.e induced by a map of algebraic varieties. However it doesn't seems that the differentials in the Leray spectral sequence are geometric. Question : Why do the differentials in the Leray spectral sequence preserve the weights ?","['hodge-theory', 'complex-geometry', 'spectral-sequences', 'algebraic-geometry']"
2894297,Definition of a self homeomorphism,"In this article https://en.wikipedia.org/wiki/Homeomorphism The definition of a homeomorphism is stated as follows: A function $f : X \rightarrow Y$ between two topological spaces $(X,T_X)$  and $(Y, T_Y)$ is called a ''homeomorphism'' if it has the following properties: $f$ is a bijection, $f$ is continuous, the inverse function $f^{-1}$ is continuous. Now what if we have the same space $X$ but with two given topologies $T_X$ and $T^{'}_X$
can we say from the definition that $(X,T_X)$ and  $(X,T^{'}_X)$ are homeomorphic if and only if $T_X=T^{'}_X$ ?","['elementary-set-theory', 'general-topology']"
2894298,"Show that $\frac1n\max\limits_{1\le i \le n } X_i\to0$ almost surely, with no independence assumption","This is self-study, I encountered this problem in one of the previous examination papers. Let $X_1,X_2,\dots $ be a sequence of identically distributed random variables with $E|X_1| < \infty $ and let $Y_n = \frac1n\max_{1 \le i \le n } X_i$. Show that $Y_n \overset{a.s.}{\to} 0$ This problem is fairly straightforward if it was i.i.d case - one can easily find the distribution of sample maximum and use Borel Cantelli lemma 1 to show that this almost surely happens. Because this is an examination question, I think, one clue is to use Markov's inequality because of the $E[|X|]$ term. Any clues are greatly appreciated.","['self-learning', 'convergence-divergence', 'probability-theory']"
2894305,How to prove that there is no differentiable function with given partial derivatives,"Let $U=\{(x,y)\in\mathbb{R}^2:(x,y)\neq(0,0)\}$. Show that there is no differentiable function $f:U\rightarrow\mathbb{R}$ satisfying
  $$\frac{\partial f}{\partial x}=\frac{y}{x^2+y^2}, \frac{\partial f}{\partial y}=-\frac{x}{x^2+y^2}.$$ My initial thought was to show that these partials are not continuous at some point $(x,y)\neq(0,0)$, but since it is possible to have a differentiable function that is not $C^1$, this is not enough. Any suggestions are greatly appreciated.","['multivariable-calculus', 'derivatives', 'real-analysis']"
2894328,Entire function problem: translation,"Let $f$ be an entire function such that $f\circ f$ has no fixed points. Prove that $f$ is a translation
  $$z\mapsto f(z)=z+b \qquad (b\neq 0)$$ Firstly, we prove that there exists a constant $c\in \mathbb{C}\backslash \{0,1\}$ such that 
$$f(f(z))-z=c(f(z)-z) $$
applying Picard's little theorem. If $c=0$, then $f(f(z))=z$, so $f\circ f$ has a fixed point (absurd). If $c=1$, then $f(f(z))=f(z)$, so $f$ is the identity $f(z)=z$ and of course it has fixed point (absurd). Then, 
$$F(z)=\frac{f(f(z))-z}{(f(z)-z)}$$
is an entire function which does not take the values 0 and 1 so, by Picard's little theorem, it must be constant. Also, I've proved that $f'\circ f$ is a constant function. Let's see this. Differentiating 
$$f(f(z))-z=c(f(z)-z) $$
we have
$$f'(z)f'(f(z))-1=cf'(z)-c$$
$$f'(z)[f'(f(z))-c]=1-c$$
Again, the entire function 
$$G(z)=f'(z)[f'(f(z))-c]$$
does not take the values $0$ and $1$ so, by Picard's Little Theorem, then is constant. However, I don't know how to prove this problem. Any help would be appreciate.","['complex-analysis', 'entire-functions', 'problem-solving']"
2894332,Can the solution of $(a+x^2)=0\bmod(b-x)$ such that $x<b-1$ be found without brute force?,"For the last couple of days I have been trying to find a non brute-force method of solving the following equation where $a$ and $b$ are known integers.
$$
  (a+x^2) \bmod (b-x) = 0 \quad \text{such that $0\le x < b-1$}
$$ Example:
$$
  (603+x^2) \bmod (622-x) =0 \quad \text{such that $0\le x < 621$}
$$
The solution is $x=173$ My attempts to find an answer or even a similar solved question have not been successful. My knowledge of discrete mathematics is rusty at best, so I am not sure if non brute force method is even possible. I am new here so if I have formatted wrong or done something incorrectly please let me know and I will fix it as soon as possible.","['elementary-number-theory', 'modular-arithmetic', 'discrete-mathematics']"
2894360,How does $\frac{x + \frac{1}{2}}{\frac{1}{x} + 2} = \frac{x}2$?,"How does simplifying $\dfrac{x+\frac12}{\frac1x+2}=\dfrac{x}2$ Plugging and chugging seems to prove this, but I donâ€™t understand the algebra behind it. How would you simplify $\dfrac{x+\frac12}{\frac1x+2}$ to get $\dfrac{x}2$? I tried multiplying the expression by $x/x$, but that left me with $\frac{x^2+\frac{x}2}{1+2x}$ Is the fact that $\frac1x$ and $2$ are the reciprocals of $x$ and $\frac12$ respectively of any significance? Thanks!",['algebra-precalculus']
2894376,Ways to arrange books,"$2$ different History books, $3$ different Geography books and $2$ different Science books are placed on a book shelf. How many different ways can they be arranged? How many ways can they be arranged if books of the same subject must be placed together? For the first part of the question I think the answer is $$(2+3+2)! = 5040 \text{ different ways}$$ For the second part of the question I think that I will need to multiply the different factorials of each subject. There are $2!$ arrangements for science, $3!$ for geography and $2!$ for history. Am I correct in saying that the number of different ways to place the books on the shelf together by subject would be 
$$2! \times 3! \times 2! = 24 \text{ different ways}$$","['permutations', 'combinatorics']"
2894379,Reversing the digits of $2^n$ to yield a prime power,"This question asks about the existence of an $n\in\Bbb N$ such the number obtained reversing de digits of $2^n$ is a power of $7$. The same question with $5$ instead of $7$ was asked by Freeman Dyson, according to this post . So I asked myself: for which $n\in\Bbb N$ is the number obtained reversing de digits of $2^n$ a prime power? Clearly $n=1,2,3$ work, as do $n=4,5$, since $61$ and $23$ are prime. A computer search up to $n\le 10\,000$ found
$$
1,2,3,4,5,17, 24, 37, 45, 55, 70, 77, 107, 137, 150, 271, 364, 1157, 1656,\\ 2004, 2126, 3033, 3489, 3645, 4336, 6597, 7279
$$
Except for $n=2,3$, the number obtained reversing de digits of $2^n$ is prime (sequence A057708 ). So, my question is: Is there an an $n\in\Bbb N$, $n\ne2,3$, such that the number obtained reversing de
  digits of $2^n$ is a prime power with exponent at least $2$?","['number-theory', 'recreational-mathematics']"
2894389,Number of permutations of six numbers with certain restrictions,"There are $6!$ permutations of the numbers $1...6$, like $156234$.
in this permutation, $1$ is in the first location, $5$ is in the second, etc. The problem is: how many permutations with the numbers $1...6$ are there that follow this rule: each number is either in the location that is equal to its value, or in a location that differs from its value by $1$ ($+1$ or $-1$), or in a location that differs from its value by $2$ ($+2$ or $-2$). For example: the permutation $245163$ doesn't follow the rule only because $1$ is in the 4th place, and because $3$ is in the 6th place. I solved a weaker version of this problem, in which there are only $4$ numbers with the same rule, by taking the overall number of permutations with the $4$ numbers, subtracting those who had $4$ in the first place and those who had $1$ in their 4th place, and adding those who had $4$ in their first place and $1$ in their 4th place, to avoid subtracting them twice: $4!-3!-3!+2 = 
14$. This strategy worked, but once you get to just $5$ numbers, there are just too many cases to add and subtract...",['combinatorics']
2894403,What is this 2D division algebra?,"Consider the set $A$ of 2-tuples of real values $(a,b)$, equipped with an addition defined as
$$ (a,b) + (c,d) = (a+c,b+d)$$
and multiplication defined as
$$ (a,b) \times (c,d) = (ac+bd,ad-bc).$$ What is this weird little thing? This algebra has some nice properties. For instance: on both sides multiplication distributes across addition, because the multiplication is bilinear it is a division algebra, as there are no zero divisors a subset is isomorphic to the reals,  $(a,0) \leftrightarrow a$ has a positive definite quadratic form
$$ (a,b)\times(a,b) = (a^2+b^2,0) $$ identity on left, $(1,0)\times(a,b) = (a,b)$ But it has some weird properties: there is no identity for multiplication on the right $z=(0,1)$ anti-commutes with the subset noted above as being isomorphic to the reals
$$ (a,0)\times z + z \times (a,0) = (0,0)$$ the multiplication is not associative the multiplication is not even power associative, as seen with $z=(0,1)$, $$ z\times(z\times z) = -(z\times z)\times z$$ the center is trivial, as only $(0,0)$ commutes with all elements. So I'm not sure on the terminology, but this can also be viewed as ""extending"" the Reals with an exotic sqrt of 1, 
$$ z^2 = 1,$$
which anti-commutes with multiplication of reals,
$$\forall a \in \mathbb{R} : az+za=0.$$
Then the set $A = \{a+bz : a,b \in \mathbb{R}\}$. After playing with it a bit I realized it can also be viewed as taking the complex numbers and defining the operation: 
$$x \times y = x^*\ y$$ Which means this is also like taking a 1D complex Hilbert space, and treating the inner product as if it is a multiplication because in this case the scalar and vector are the same dimension. This bizarre little thing is simple enough that I assume it has been studied before. Does it have a name? Also, regardless if it has a name, I'd like to know the proper terminology for describing this. Because of the relation to complex numbers, would mathematicians consider it ""just the complex numbers"" since the operations can be represented with complex numbers? It at least isn't isomorphic to the complex numbers, correct? Would you consider this a 2D real division algebra distinct from the complex numbers? Since the structure was defined in terms of operations on the reals, and the elements are a tuple of reals, it feels like this would be some-object ""over the Reals"". Maybe a left semimodule over the Reals. Or does the phrase ""over the reals"" require that the Reals commute with everything? Similarly, if you object to my use of terminology in the discussion of the properties, I'd appreciate if you could point that out and suggest more reasonable terminology with explanation.","['abstract-algebra', 'division-algebras']"
2894411,How is possible that those shapes are equivalent in topology?,"I recently started to study topology, I have no idea about the subject so my question could be very simple but I need a clear explanation.  It is about the page number 19 of Introducton to Topology by Colin Adams and Robert Franzosa; it said that the shapes: are equivalent in topology, but one has just one hole and the other has two. is possible to add holes or stick holes?",['general-topology']
2894416,Suppose $b \in \mathbb{R}$ and $|b| < \frac{1}{n}$ for every positive integer n. Prove that $b = 0$.,"This comes from an exercise in Appendix C from Axler's Measure, Integration & Real Analysis . The following is my approach. Suppose $b \neq 0$. Let $|b| = \epsilon$. Then 
        by Archimedean Property (2) 
        $$\exists n^* \in \mathbb{Z}^+ \text{ such that} \frac{1}{n^*} < \epsilon$$
        but $b < \frac{1}{n}$, $\forall n \in \mathbb{Z}^+$. Hence a contradiction. Am I approaching this correctly, if I am are there any other approaches?",['real-analysis']
2894434,Evaluate $\int_{-5}^{+5}\frac{dx}{1+f(x)}$ from the given information,"$f(-x)f'(x)-f(x)f'(-x)=0$ and $f(0)=1$. Then what is the value of $$\int\limits_{-5}^{+5}\frac{dx}{1+f(x)}$$ My attempt: From the first piece of information,
$f(x)f(-x)=k$ (some constant). Differentiating both sides, $f(-x)f'(x)-f(x)f'(-x)=0$. Putting $x=0$, we get $k=1$ (from second info given). Now,I can't proceed further.","['calculus', 'definite-integrals']"
2894457,Absolute complement of a set,"For a universal set $U$, I have two questions. 1) Is it guaranteed that any set $A$ is going to be a subset of $U$, because $U$ is the universal set? 2) In the context that $A$ is a subset of $U$, would it be valid to think of the absolute complement of $A$, as the logical negation of every element of $A$?",['elementary-set-theory']
2894466,"If $X$ is exponentially distributed with parameter $1$, prove that $\exp(-X)$ is uniformly distributed on $[0,1]$.","This is what I have so far: The PDF of $X$ is  $$f_X(x)=e^{-x}$$ when $x\geq0$ and $0$ otherwise. The CDF of $X$ is $$P(X\leq x)=F_X(x)=1-e^{-x}$$ when $x\geq 0$ and $0$ otherwise. I know that I want to end up with the pdf of $Y=e^{-X}$ being $$f_Y=1$$ on $[0,1]$ and $0$ otherwise, hence a uniform distribution. So, \begin{align}F_Y(y)&=P(Y\leq y)\\
&=P(e^{-X}\leq y)\\
&=P(-\ln(y)\leq X)
\end{align}
 I don't know how to proceed from here. Also, I know that $X=-\ln(Y)$, but I am not sure how to use it/ if I need to.",['statistics']
2894488,Proof of the recursion theorem,"The present statement of the theorem is as follows: Let $A$ be a set with an element $a \in A$ , and let $\psi\colon A \to A$ be a map. There exists a unique map $f\colon \mathbb{N} \to A$ with $f(1) = a$ such that $$ f(n+1) = \psi(f(n)) $$ for all $n \in \mathbb{N}$ . My definition of the natural numbers takes $1$ to be the initial element. The proof in my textbook considers the set $\Gamma$ of all subsets $U \subseteq \mathbb{N} \times A$ that satisfy $(1, a) \in U$ , $(n, b) \in U \Rightarrow (n+1, \psi(b)) \in U$ . Letting $F := \bigcap_{U \in \Gamma} U$ , we show that $F$ is the graph of a function. It is easy to show by induction that for all $n \in \mathbb{N}$ there exists at least one $b \in A$ such that $(n, b) \in F$ . However, proving that this $b$ is unique is left to the reader, and I haven't been successful in finding a proof for it.","['elementary-set-theory', 'recursion']"
2894490,"Show that $E_{t}=\left( \mathbf{x}_{t},\mathbf{E}_{1},\mathbf{E}_{2},\mathbf{E}_{3}\right)$ is a first order frame field along $\mathbf{x}_{t}$","Show that about any $m_{0}\in U$, there exist a neighborhood $V\subset U$
  and a positive number $\delta \leq \epsilon $ for which there exist smooth
  vector fields
  $$
\mathbf{E}_{a}:V\times \left( -\delta ,\delta \right) \rightarrow 
\mathbb{R}^3,
$$
  for $a=1,2,3$, such that $E_{t}=\left( \mathbf{x}_{t},\mathbf{E}_{1},\mathbf{%
E}_{2},\mathbf{E}_{3}\right) :V\rightarrow E\left( 3\right) $ is a first
  order frame field along $x_{t}$ for each $t\in \left( -\delta ,\delta
\right) $, with the property that
  $$
\mathbf{E}_{1}\left( m,0\right) =\mathbf{e}_{1}\left( m\right) \text{, }%
\mathbf{E}_{2}\left( m,0\right) =\mathbf{e}_{21}\left( m\right) \text{, }%
\mathbf{E}_{3}\left( m,0\right) =\mathbf{e}_{3}\left( m\right) 
$$
  for every $m\in V$. Consequently,
  $$
\frac{\partial \mathbf{E}_{j}}{\partial t}\left( m,0\right) \cdot \mathbf{e}%
_{j}\left( m\right)
= \left. \frac{1}{2}\frac{\partial }{\partial t} \right|_{t=0}\left( \mathbf{E}_{j}\cdot \mathbf{E}_{j}\right)
=0
$$
  for every $m\in V$ for $j=1,2$. I only managed to show the existence of the fields, but I could not show the rest, that is, first order frame field and the others ... We are using the definition below Definition 8.1. An admissible variation of $\mathbf{x}$ is any smooth map
  $$
         X
  \colon M \times (-\epsilon, \epsilon)
  \to    \mathbb{R}^3,
$$
  with compact support , such that for each $t \in (-\epsilon, \epsilon)$, the map
  $$
         \mathbf{x}_t
  \colon M
  \to    \mathbb{R}^3,
  \quad  \mathbf{x}_t(m)
  =      X(m,t),
$$
  is an immersion.
  The support of $X$ is the closure in $M$ of the set of points of $M$ where $\mathbf{x}_t(m) \neq \mathbf{x}(m)$, for some $t$. and Definition 3.5 A first order frame field along $\mathbf{x}$ is a frame field $e \colon U \to G$ along $\mathbf{x}$ for which
  $$
    e^* \omega^{m+1}
  = \dotsb
  = e^* \omega^n
  = 0,
  \quad
  e^* \omega^1 \wedge \dotsb \wedge e^* \omega^m \neq 0.
$$
  at every point of $U$. (Original scanned image here .)","['vector-fields', 'riemannian-geometry', 'lie-groups', 'differential-geometry']"
2894498,Showing that $G/G_m$ and $G/G_n$ are isomorphic groups.,"Let $G$ be the multiplicative group of complex numbers of modulus $1$ and let $G_n$ (with $n$ a positive integer) be the subgroup consisting of the $n$-th roots of unity. For positive integers $m$ and $n$, I want to show that $G/G_m$ and $G/G_n$ are isomorphic groups. I can't even prove that the natural map is well defined. Please help me. Thanks.","['group-theory', 'abstract-algebra', 'complex-numbers']"
2894525,Quadratic inequality puzzle: Prove$ |cx^2 + bx + a| â‰¤ 2$ given $|ax^2+bx+c| â‰¤ 1$,"I came across this problem as part of a recreational mathematics challenge on university: Suppose $a, b, c$ are real numbers where for all $ -1 \le x \le 1 $ we have $|ax^2 + bx + c| \le 1$. Prove that for all $-1 \le x \le 1 ,$ $$    |cx^2 + bx + a| \le 2$$ Was interested to know how you can approach this as I have not so far been successful, especially frustrating as it does not appear to be that hard of a problem? The inequality to prove is presented accurately by professors and I am sure it holds. edit: I have tried with a graph, as I only have to worry about $x=1, -1$ and at the maxima/minima of where the quadratic will be at most 2 but I don't know if a graph can constitute a 'prove' and in any case it hasn't worked. I have tried a lot of algebraic manipulation like completing the square but again, nothing. I have noticed the symettrey in the inequalities, specifically, if we add them then we get $$|(a+c)x^2 + 2bx + (a+c)| = |dx^2 + 2b + d|$$","['inequality', 'absolute-value', 'recreational-mathematics', 'substitution', 'algebra-precalculus']"
2894530,Expectation of a random variable as a random variable,"I am doing an exercise in inference theory which involves finding a confidence interval for a difference in expectations. I have two groups $A$ and $B$, of let's say patients, and we measure each groups blood sugar levels. We assume these groups each correspond to a random variable $X_A$ and $X_B$, distributed as $N(\mu_A, \sigma_A^2)$ and $N(\mu_B, \sigma_B^2)$ respectively. What we want is to find a confidence interval $I_{\mu}$ on significance level $\alpha$ for $\mu = \mu_A - \mu_B$, such that $$1-\alpha = P(h(\mu, \hat{\mu}) \in I) = P\left(h^{-1}_{\hat{\mu}}(h(\mu, \hat{\mu})) \in h^{-1}_{\hat{\mu}}(I)\right) = P(\mu \in I{\mu}).$$ I start by estimating $\mu$ by $\hat{\mu} = \hat{\mu_A} - \hat{\mu_B}$ and $\sigma^2$ by the pooled variance, $$\hat{\sigma}^2 = \frac{\hat{\sigma}^2_A(n_A-1)+\hat{\sigma}^2_B(n_B-1)}{(n_A-1)+(n_B-1)}=\frac{\sum_{i=1}^{n_A}(x_i-\bar{x})^2 \ +\sum_{j=1}^{n_B}(y_i-\bar{y})^2}{n_A + n_B - 2}$$ where there are $n_A$ and $n_B$ measurements from each group. Regarding the pivot random variable, I reasoned that $\hat{\mu}$ must have a normal distribution because a linear combination of normally distributed random variables is also normally distributed and the expectation, $E(\cdot)$, as an operator is linear. How do I formalize this? I read somewhere that this is $t$-distributed but don't know (yet) what a $t$-distribution. When I google on the $t$-distribution it looks like a normal distribution but with less variance. What is the connection? All the help is much appreciated, thank you in advance, Isak","['statistical-inference', 'statistics', 'confidence-interval', 'normal-distribution', 'expected-value']"
2894543,"Find smallest $c \leq 1$ such that $\operatorname{var} \left(\max(\mathbb{E}[X], X) \right) \leq c \,\operatorname{var}(X)$","Consider random variable $X \geq 0$. Find smallest $c \leq 1$ such that $\operatorname{var} \left(\max(\mathbb{E}[X], X) \right) \leq c \operatorname{var}(X)$. Intuitively, it seems to be true for some $c < 1$, but I could only prove it for $c = 1$. Any idea?","['statistics', 'probability-theory', 'probability']"
2894561,"In a Cayley table, which Group axioms fail when an entry appears twice in a row or a column?","In a Cayley table, which Group axioms fail when an entry appears twice in a row or a column? It's obviously not the Closure axiom, and after some inspection, I believe the Inverses axiom does fail. However, I'm not so sure how to show whether or not the two other axioms fail (Identity and Associativity).","['axioms', 'monoid', 'cayley-table', 'semigroups', 'group-theory']"
2894580,"Describe $\mathbb{R}[x]/(x^{2}+ax+b)$ where $a,b \in \mathbb{R}$","So obviously using quadractic formula, we have three cases for the roots which depends on the discriminant. I am not sure if I am right on this but, Case 1: $a^{2}-4b>0$. Then we have two distinct real roots so this factors as
$$\mathbb{R}[x]/(x-\alpha) \oplus \mathbb{R}[x]/(x-\beta).$$
(My guess here is since $\alpha$ and $\beta$ are different, these two ideals are comaximal so I can apply the Chinese Remainder Theorem). But this is isomorphic to
$$\mathbb{R} \oplus \mathbb{R}.$$ Case 2: $a^{2}-4b < 0$. In this case, we have a complex root so we have an extension of degree $2$. But obviously whatever root we have, this is contained in $\mathbb{R}[i]\cong \mathbb{C}$ so we must have this is $\mathbb{C}$ by the tower law since $\mathbb{R}[i]$ is also a degree $2$ extension of $\mathbb{R}$. Case 3: $a^{2}-4b=0$. Then we have a real root with multiplicity $2$. I am not sure what this is as if we have the root is $\alpha$, we get
$$\mathbb{R}[x]/(x-\alpha)^{2}$$
Since these roots are the same, $(x-\alpha)$ and $(x-\alpha)$ are not comaximal I believe so I don't know what this ring is.","['irreducible-polynomials', 'field-theory', 'abstract-algebra', 'polynomials', 'extension-field']"
2894626,Show $\int_{-\infty}^\infty dx \sin(ax) \log\Big(\Big| \frac{x+1}{x-1} \Big|\Big) = \frac{2 \pi \sin(a)}{a}$,"I'm interested in integrals of the form $\int_{-\infty}^\infty dx f(x) \log(\big| \frac{x+1}{x-1} \big|)$. It's particularly nice when f(x) has definite parity, since $\log(\big| \frac{x+1}{x-1} \big|)$ is odd. My question is how to show $$I \equiv \int_{-\infty}^\infty dx \sin(ax) \log\Big(\Big| \frac{x+1}{x-1} \Big|\Big) = \frac{2 \pi \sin(a)}{a}$$ for $a>0$. I'm trying to use complex methods to solve the integral, but I keep finding an answer of 0 owing to the lack of residues. I suspect that I'm not being careful enough about divergences and phase, and please point out if you see a mistake in the comments. Here's my work so far: $$I = \Re \Big(\int_{-\infty}^\infty dx \sin(ax) \log\Big(\frac{x+1}{x-1} \Big) \Big)$$ I justify this line since removing the absolute value bars merely adds a finite imaginary component from the integral between $-1 < x < 1$. Next, $$I = -\frac{1}{2}\Re \Big(i\int_{-\infty}^\infty dx\, e^{iax} \log\Big(\frac{x+1}{x-1} \Big) -i\int_{-\infty}^\infty dx\, e^{-iax} \log\Big(\frac{x+1}{x-1} \Big) \Big).$$ I believe it's kosher to split the integral into two, because each split integral converges on its own by Dirichlet's test for $|x|>1$ . Next, I substitute $x \rightarrow -x$ in the second integral, and I find $$I = -\frac{1}{2}\Re \Big(i\int_{-\infty}^\infty dx\, e^{iax}\, \Big(\log\Big(\frac{x+1}{x-1}\Big)-\log\Big(\frac{-x+1}{-x-1} \Big) \Big).$$ Combining the logarithms yields $$I = -\Re \Big(i\int_{-\infty}^\infty dx\, e^{iax} \log\Big(\frac{x+1}{x-1}\Big) \Big).$$
The line above is where I wonder if some subtlety of the phase of the arguments of the logarithm was lost on me. In particular, I find that if I should have an extra '$\pi i $' added onto the logarithm, I would have the anticipated result. 
Continuing nonetheless, to evaluate the integral $J \equiv \int_{-\infty}^\infty dx\, e^{iax} \log\Big(\frac{x+1}{x-1}\Big)$, I choose to evaluate $$K \equiv \oint dz\, e^{iaz} \log\Big(\frac{z+1}{z-1}\Big) $$ on the semicircle contour in the UHP, pictured below. I do not believe the branch cut I chose matters too much, since I chose the cut along the x-axis, but it could be that this choice of branch was somehow inconsistent with how I handled merging the logarithms above. The shrinking semi-circles about -1 and 1 contribute nothing. There aren't any residues inside, so $K=0$. Thus my integral $J$ must be equal to the upper arc as $R$ goes to infinity. Along the upper arc, note that taking the radius $R$ of the arc outward sends $\log\Big(\frac{z+1}{z-1}\Big) \rightarrow 0 $ as $\frac{1}{R}$. This, coupled with Jordan's lemma, kills the upper arc as the radius goes to infinity. Thus we find that $J=0$ and hence $I=0$, in contradiction to what we wished to show. I'll be looking over my steps to find a mistake.","['integration', 'complex-analysis', 'contour-integration', 'logarithms']"
2894631,What mathematical prerequisites do I need to properly learn stochastic DEs?,"I'm a PhD student in biology, and I'm trying to teach myself the necessary math to get into mathematical modeling of the phenomenon we study, because this is an area of inquiry that 1) I'd like to get into and 2) the lab I work for may like to get into, and it'd be on my shoulders to do it. The phenomenon we study, among other things, has been modeled using delay differential equations and stochastic differential equations. I have courses under my belt in differential/integral calculus and am teaching myself differential equations, and possess the requisite computational background.  Multivariable calculus is next on my list.  What else do I need to know to get to a level where I can adequately make use of DDEs and SDEs?","['stochastic-calculus', 'ordinary-differential-equations']"
2894632,"If $\text{ad}(A)$ is nilpotent and $\text{tr}(A) = 0$, then $A$ is a nilpotent matrix.","Let $\mathfrak{gl}\left(\mathbb{R}^n\right)$ be the vector space of all linear transformations $T:\mathbb{R}^n \to \mathbb{R}^n$ . If $A$ $\in$ $\mathfrak{gl}\left(\mathbb{R}^n\right)$ , we can define the linear map \begin{align*}
\text{ad}(A):\mathfrak{gl}\left(\mathbb{R}^n\right)&\to \mathfrak{gl}\left(\mathbb{R}^n\right)\\
B &\mapsto AB-BA. \\
\end{align*} I would like to know how to prove the following theorem: Theorem : Let $A$ $\in$ $\mathfrak{gl}\left(\mathbb{R}^n\right)$ , such that $\text{ad}(A)$ is nilpotent and $\text{tr}(A) = 0$ , then $A$ is nilpotent. I was trying to prove the theorem above by induction in the dimension of $\mathbb{R}^n$ , but I did not make much progress. Does anyone have a nice idea?","['matrices', 'linear-algebra', 'lie-algebras']"
2894653,"Number of $n$-element subsets of $\{1, 2, \dotsc, 3n\}$ with sum divisible by $n$","Is there any recurrence relations/formula/algorithm to count the number of $n$ -element subsets of the set $\{1, 2, \dotsc, 3n\}$ with sum divisible by $n$ ? How about replacing $3n$ with $kn$ ? I currently only know that if $k=2$ , then the number of $n$ -element subsets divisible by $n$ is $$     
  \frac{(-1)^n}{n}\sum_{d \mid n} (-1)^d\phi({n\over d})\binom{2d}{d}
$$ from http://oeis.org/A169888 , but a similar search for $k=3$ doesn't return any results. 
Is there any similar formula for $k \geq 3$ ? Thanks. Some bruteforced values for $k=3$ : $$
  \begin{array}{c|ccccccccc}
      n
    & 1
    & 2
    & 3
    & 4
    & 5
    & 6
    & 7
    & 8
    & 9
    \\
    \hline
      \text{$n$-element subsets}
    & 3
    & 6
    & 30
    & 126
    & 603
    & 3084
    & 16614
    & 91998
    & 520779
    \\
  \end{array}
$$","['elementary-set-theory', 'polya-counting-theory', 'divisibility', 'algorithms']"
2894663,Limit of $\frac{2^{\frac{\ln n}{2}}}{n}$,I would like to know the limit of $\lim_{n\to\infty}\frac{2^{\frac{\ln n}{2}}}{n}$. I notice repeatedly taking L'opital Rule does not help. Is there any other approach where I can use to derive the limit?,"['calculus', 'derivatives']"
2894666,Replacing $b$ with $bi$ in $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$ turns the ellipse equation into a hyperbola equation; is there a deep meaning to this?,"I've a kind of strange doubt.
I was doing some exercises about conic sections and then I realized that a hyperbola and an ellipse have some strange relation. If we have the ellipse equation $$\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$$ and we make the transformation
$b\to bi$ (where $i^2=-1$), then we have now a hyperbola. I've done some problems and derived some formulas using that fact. Therefore, I've a conceptual doubt now. Is there a deep meaning in this transformation, or is it just a coincidence?","['analytic-geometry', 'geometry', 'complex-numbers']"
2894674,Does there exist irreducible polynomials of each degree over arbitrary field?,"Let $F$ be an arbitrary field such that $[\overline{F}: F]=\infty$. Here $\overline{F}$ denotes the algebraic closure. The question in the title of this post can be rephrased as: Question 1 . For each $n\in\mathbb{N}$, can we find a field extension $L$ of $F$ such that $[L:F]=n$? Let me remark that the condition $[\overline{F}: F]=\infty$ is necessary. Indeed, by the Artin-Schreier theorem , the condition $[\overline{F}:F]<\infty$ in fact forces $[\overline{F}:F]=2$, in which case $F$ can only have extensions of degree at most $2$. I suspect that Question 1 may have a negative answer for small values of $n$, so I am happy to consider the weaker problem: Question 2 .  Does there exist a number $n_0$ (that only depends on $F$) such that for each $n\geq n_0$, there exists a field extension $L$ of $F$ such that $[L:F]=n$? In case there are any separability issues, feel free to assume that $F$ is perfect. Added later: Looks like this question has already been asked. See this MSE thread . Before we close my question as a duplicate (which is the right thing to do), I was wondering if anyone has any additional details or more in the case when $F$ is a perfect field. Having the details of the construction is especially appreciated!","['irreducible-polynomials', 'field-theory', 'galois-theory', 'abstract-algebra', 'extension-field']"
2894675,Non-constant entire functions,"Question: If $g$ is a non-constant entire function does it follow that $G_1(z)=g(z)-g\left(z+e^{g(z)}\right)$ is non-constant? The reason I care is it would imply Prop 3 below, which in turn implies Prop 1, giving a proof that might seem better motivated than the proof here . It seems at least plausible. The only thought I've had is a little vague: $-G_1(z)$ is something somewhat like $g'(z)e^{g(z)}$. And $g'e^g$ cannot  be constant:  If $g'e^g=c$ then $e^g=cz+d$. So $cz+d$ has no zero, hence $c=0$, and it follows that $g$ is constant. The problem is that the size of $g'(z)e^{g(z)}+G_1(z)$ depends on the size of $e^g$ and also on the size of $g''$... Context: The other day at the link above I learned something totally new to me: Prop 1. Suppose $f$ is entire. Then $f\circ f$ has no fixed point if and only if $f$ is a nontrivial translation ($f(z)=z+b$, $b\ne0$.) The obvious question is when $f$ has a fixed point - this is trivial: Prop 2. The entire function $f$ has no fixed point if and only if $f(z)=z+e^{g(z)}$ for some entire function $g$. (Proof: $f$ has no fixed point if and only if $f(z)-z$ has no zero...) It occurred to me to try to use Prop 2 to prove Prop 1: Suppose $f\circ f$ has no fixed point. Then $f$ has no  fixed point, so $f(z)=z+e^{g(z)}$, and now we have something to work with in investigating when $f\circ f$ has a fixed point... It  turns out that to get to Prop 1 from Prop 2 we need this: Prop  3 If $g$ is a non-constant entire function then $G_2(z)=e^{g(z)}+e^{g\left(z+e^{g(z)}\right)}$ has a zero. Proving two assertions above: If the answer to the question is yes then Prop 3 follows: If $G_1$ is non-constant then little  Picard shows that there exist $k\in\Bbb Z$ and $z\in\Bbb C$ with $G_1(z)=(2k+1)\pi i$: this shows that $G_2(z)=0$. Prop  3 implies Prop 1: Suppose $f\circ f$ has no FP Then $f$ has no FP, so $f(z)=z+e^{g(z)}$. But now $f(f(z))=z+G_2(z)$,  so saying $f\circ f$ has no FP is saying exactly that $G_2$ has no zero. So Prop 3 implies that $g$ is constant, hence $f$ is a non-trivial translation. In fact the two are equivalent (and hence Prop 3 is in fact true): Prop 1 implies  Prop 3: Say $g$ is non-constant and let $f(z)=z+e^{g(z)}$. Then $f$ is not a translation, so $f\circ f$ has a FP, hence as before $G_2$ has a zero. My ""might seem better motivated"" might be worth justifying, given the bizarre appearance of Prop 3. It's  really perfectly natural: If we're investigating when $f\circ f$ has a FP it's natural to first wonder when $f$ has a FP. Then Prop 2 is trivial, and given Prop 2 the question of when $f\circ f$ has a FP leads naturally to Prop 3, since $f(f(z))=z+G_2(z)$. (And now saying $G_2$ has a zero is clearly equivalent to saying $G_1(z)=(2k+1)\pi i$ for some $z$, and to prove that we only need to show that $G_1$ is non-constant, hence the question ...) Perfectly clear, qed.","['complex-analysis', 'entire-functions']"
2894680,Intuition of error in Taylor appoximation and finding error in approximation of a function by a constant function,"I am reading up on Taylor approximation of a function and I'm trying to develop the intuition for the remainder, when approximating a function with $n^{th}$ degree polynomial which has a continuous $(n+1)^{th}$ derivate, given by
     $\frac{1}{n!}\int_{a}^{x} (x - t)^nf^{(n+1)}(t)dt$ My intuition of linear approximation is this: We used a constant first derivate to evaluate at x (since we approximate f at a). Hence, we have to use the information about rate of rate of change from the any point $ t \in (a,x)$ to compensate for this error. Specifically, the second derivative gives the difference between the first derivatives at two successive points and scales it over unit interval. Therefore, f''(t) corrects for error at t but introduces new error from (t, x) which is corrected with the same logic at the next point. Thus, the integral given above. Is this correct? My reasoning is because if I begin the approximation using a constant function and reason that by using the rate of change at every point, a function can be reconstructed starting from any point. But if I try to use the above integral to compute the error in estimates for the constant function, it doesn't work because of the $(-t)$. Is there a formula to estimate the error including the constant case? I understand the proof of the integral using integration by parts (and requirement of the continuity of $f^{(n+1)}(x)$ is to be able to use the first fundamental theorem). Can you please help me fix my intuition of the integral?","['approximation', 'calculus', 'linear-approximation', 'taylor-expansion', 'sequences-and-series']"
2894681,How to transform/shift the mean and standard deviation of a normal distribution?,"Given some Gaussian distribution with mean x and deviation s, how do I transform the distribution to have a new specific mean and specific deviation. Say the distribution has a mean, $\bar x = 4$ and deviation, $s = 10$, and needs to be transformed so that the new mean and deviation are $\bar x = 0.50$ and $s = 2$. My approach is to scale each element in the data set by $c = 0.20$, which will also scale the deviation to the desired $s = 2$, and will make the mean $\bar x = 0.80$. Finally I subtract 0.30 from each element to shift the mean to the desired $\bar x = 0.50$.","['descriptive-statistics', 'statistics', 'normal-distribution']"
2894700,Textbooks on differential geometry,I want the best textbook on differential geometry and I want it to be comprehensive..I mean I want it to start from scratch til it reaches the most advanced topics..if possible I want it to have a mathematically rigorous and theoretical approach but still not ignore the subject's various applications in physics...I don't care if it's 10000 pages. If that's not possible then I want a list of textbooks to read in succession with the same properties above. I looked on the web a lot but quickly got lost because there are so many suggestions and most people simply want introductions and I'm not prepared to buy a huge textbook based on someone's review of it only to discover that it wasn't what I hoped for. So..if someone recommends a certain textbook..Kindly say what's good or not good about it..of course I'm not expecting to find a perfect one I only want to find one that's not very different from what I have in mind. Thanks in advance.,"['riemannian-geometry', 'differential-geometry']"
2894722,the kernel of the evaluation map,"Assume that $R$ is a commutative ring with a multiplicative identity element. Fix $a\in{R}$, and consider the evaluation map $e_{a} : R[x]\rightarrow{R}$ defined to be ${e_{a}}(f(x))=f(a)$. If $(x-a)$ is the principal ideal generated by $x-a$ in $R[x]$, it is clear that $(x-a)\subset \ker{e_{a}}$. Is the reverse inclusion always true? One can see immediately that it holds by the factor theorem if $R$ is a field. This is Exercise 47 in J.J. Rotman's book Galois Theory (Second Edition), but I am not sure if $\ker{e_{a}}=(x-a)$ is true in an arbitrary ring. Thanks!",['abstract-algebra']
2894748,"$\Bbb R[X,Y]/(F) \cong \Bbb R[Z]$ and $F_X G_Y - G_X F_Y \in \Bbb R^*$","Hope this isn't a duplicate. I was trying to solve the following problem : Let $F,G \in \Bbb R[X,Y]$ satisfy $\Bbb R[F,G]= \Bbb R[X,Y]$. Prove that : (i) $\Bbb R[X,Y]/(F) \cong \Bbb R[Z]$ , for some $Z$ and (ii) $F_X G_Y - G_X F_Y \in \Bbb R^*$ (where $F_X$ etc. denote partial derivatives) I don't have any idea regarding the problem.","['ring-theory', 'abstract-algebra', 'polynomial-rings']"
2894765,Find out when $(x + y)^5 = x^5 + y^5$ (Spivak's Calculus Book),"I know that I can see that this match with $y = 0$, $x = 0$ and $y = -x$. But, the author of the book says: ""Hint: From the assumption $(x + y)^5 = x^5 + y^5$ you should be able to derive the equation $x^3 + 2x^2y + 2xy^2 + y^3 = 0$ if $xy \neq 0$. This implies that $(x + y)^3 = x^2y + y^2x = xy(x + y)$"" Then, I realize that $(x + y)^3 - xy(x + y) = x^3 + 2x^2y + 2xy^2 + y^3$. That's why if $(x + y)^3 - xy(x + y) = 0$ then  $(x + y)^3 = xy(x + y)$. Then, I did the same with $(x + y)^5$ $x^5 + 5x^4y +9x^3y^2 + 9x^2y^3 + 5xy^4 + y^5 = 0$  if  $xy \neq 0$ Then $(x + y)^5 - x^2y^2(x + y) = 0$ $(x + y)^5 = x^2y^2(x + y)$ Then I can prove that its true when $y = -x$ But I still don't get it why I have to did this and what the author want to tell me doing this.",['algebra-precalculus']
2894766,"Proving that the sequence $1, \frac12, \frac{1/2}{3/4}, \cdots$ converges to $\frac{\sqrt 2}2$ [duplicate]","This question already has answers here : Tall fraction puzzle (3 answers) What is $\cdots ((((1/2)/(3/4))/((5/6)/(7/8)))/(((9/10)/(11/12))/((13/14)/(15/16))))/\cdots$? [duplicate] (6 answers) Closed 5 years ago . I saw this on a Facebook page:
\begin{align*}
1, \qquad \frac12,\qquad\frac{\frac12}{\frac34}, \qquad\frac{\frac{\frac12}{\frac34}}{\frac{\frac56}{\frac78}},\qquad \dots\to \frac{\sqrt{2}}2.
\end{align*}
The $n$-th term is the combination of $2^n$ consecutive integers from $1$ to $2^n$. Question: How to prove this in a both rigorous and easy way? 1st attempt Let $\{a_n\}$ be the sequence. We try to ""simplify"" $a_n$ as the form $\dfrac{1\cdot4\cdot6\cdot7\cdots}{2\cdot3\cdot5\cdot8\cdots}$, as simple fraction, to find the pattern in which some integers are numerators and others are denominators. Let $f: \Bbb N \mapsto \Bbb Z$ such that 
\begin{align*}
a_n=\prod_{k=1}^{2^{n-1}}k^{(-1)^{f(k)}}.\tag{*}
\end{align*}
However, it seems hard to find the expression / recurrence formula for $f$ and show it converges to $\dfrac{\sqrt2}2$. 2nd attempt Again we let $\{a_n\}$ be the sequence. Consider the continued fraction:
\begin{align*}
\sqrt2=1+\underset{i=1}{\overset{\infty}{\mathrm K}} ~ \frac{1}{2}=1+\cfrac1{2+\cfrac1{2+\cfrac1{2+\cfrac1{\ddots}}}}.
\end{align*}
Then, we define
\begin{align*}
b_m=\frac12\left(1+\underset{i=1}{\overset{m}{\mathrm K}} ~ \frac{1}{2}\right)=\frac12+\frac12\cdot\cfrac1{2+\cfrac1{\ddots+\cfrac1{2}}}.
\end{align*}
Obviously $b_m$ converges to $\dfrac{\sqrt2}2$. Then we just need to show that $a_n$ is between $b_m$ and $b_{m+1}$ for big $m$ and $n$ ( $m$ depends on $n$), which seems complicated.","['infinite-product', 'limits', 'continued-fractions', 'sequences-and-series']"
2894784,"Given any commutative ring $R$ with unity, $R[X]$ has infinitely many maximal ideals.","Hope this isn't a duplicate. I was trying to answer the following questions: (i) Let $k$ be any field. Then prove that $k[X]$ has infinitely many maximal ideals. (ii) Using (i) prove that, given any commutative ring $R$ with unity, $R[X]$ has infinitely many maximal ideals. My attempt: (i) If $k$ is  infinite, then the collection of ideals of the form $(x-a) \forall a \in k$ will suffice. For finite fields I argue by contradiction. Begin by assuming that there are only finitely many prime polynomials, a listing of them in $k[X]$ say, $p_1,\ldots,p_n$ . Next we define $p_{n+1} := p_{1} \cdots p_{n} +1$ then $p_{n+1} > p_{j} \forall 1\leq j\leq n $ and none of them divide it i. e. proceed like Euclid's argument for proving infinitely many primes. (ii) By Krull's theorem, any non-zero commutative ring with unity has a maximal ideal. Let $\mathscr{M}$ be a maximal ideal of $R$. Then $\frac{R}{\mathscr{M}}$ is a field, we consider $\frac{R}{\mathscr{M}} [X]$ , then by part (i), $\frac{R}{\mathscr{M}} [X]$ has infinitely many maximal ideals. Since,$\frac{R}{\mathscr{M}} [X] \cong \frac{R[X]}{\mathscr{M}[X]}$ , thus $\frac{R[X]}{\mathscr{M}[X]}$ must have maximal ideals. Now any ideal of $\frac{R[X]}{\mathscr{M}[X]}$ is of the form $\frac{I}{\mathscr{M}[X]}$ where $I$ is an ideal of $R[X]$ containing $\mathscr{M}[X]$. So any maximal ideal of $\frac{R[X]}{\mathscr{M}[X]}$ is an ideal of $R[X]$ containing ${\mathscr{M}[X]}$, say $J$. But I don't know whether $J$ is maximal in $R[X]$ or not. How to cross the hurdle? Also if there are mistakes in my arguments please point them out.","['ring-theory', 'abstract-algebra', 'polynomial-rings']"
2894808,Characterize Abelian Factor Group to Direct Product,"What group is isomorphic to $(\mathbb{Z}_4\times\mathbb{Z}_4\times\mathbb{Z}_8)/\langle(1,2,4)\rangle$? I can only see that $\mathbb{Z}_4\times\mathbb{Z}_4\times\mathbb{Z}_8$ has $128$ elements and $\langle(1,2,4)\rangle$ has $4$ elements, so this factor group will have $128/4=32$ elements, and will therefore be isomorphic to exactly one of the following groups:
$$
\mathbb{Z}_{32},
\quad
\mathbb{Z}_{16}\times\mathbb{Z}_2,
\quad
\mathbb{Z}_8\times\mathbb{Z}_4, 
\quad
\mathbb{Z}_8\times\mathbb{Z}_2\times\mathbb{Z}_2,
\quad
\mathbb{Z}_4\times \mathbb{Z}_4\times\mathbb{Z}_2
$$ However, determining which one it is actually isomorphic to seems like a messy work, I can only do it by writing all the cosets and see which abelian group it is isomorphic to. Is there any faster and reliable method?","['direct-product', 'finitely-generated', 'abstract-algebra', 'group-theory', 'abelian-groups']"
2894812,Solving a non-homogeneous second-order differential equation with constant coefficients,"I am given this equation:
$$
y''(x) y(x) - 4 y(x) = -4e^{4x}
$$
And I am asked to start off by finding the solution to the homogeneous equation. First, I am confused as to why the above equation is said to be constant coefficient. Wouldn't the $y''(x)$ being multiplied to $y(x)$ mean that it is not a constant coefficient equation? But, our teacher did not teach us how to solve for equation that are not constant coefficient, and strictly said that we will not look at those equations now. I went on to solve for the homogeneous solution by equating the right hand side of the equation to zero.
I got the characteristic equation: $q^2 -4=0$, $\longrightarrow$ $q=+2$ or $-2$. So, i then got that the general homog. solution is: $Ae^{2t} + Be^{-2t}$, for $A,B$ constants. But, this is wrong.","['calculus', 'homogeneous-equation', 'ordinary-differential-equations']"
2894817,The 'Locally Ringed' condition in the definition of a scheme.,"Is the 'Locally Ringed' condition in the definition of a Scheme redundant? My question is, if it admits a cover by Affine Schemes, does it follow that the Ringed space is Locally Ringed? More generally, if a Ringed Space $(X,\mathscr{O}_X)$ admits a cover $\{U_i\}$ such that each $(U_i,{\mathscr{O}_{X}}_{|U_i})$ is Locally Ringed, is $(X,\mathscr{O}_X)$ itself Locally Ringed?","['ringed-spaces', 'algebraic-geometry', 'schemes']"
2894824,Hartshorne Exercise II.3.17 Noetherian Induction,"I'm confused by the Noetherian Induction exercise in Hartshorne. Let $X$ be a Noetherian topological space, and let $\mathscr{P}$ be a property of closed subsets of $X$. Assume that for any closed subset $Y$ of $X$, if $\mathscr{P}$ holds for every proper closed subset of $Y$, then $\mathscr{P}$ holds for $Y$. (In particular, $\mathscr{P}$ must hold for the empty set.) Then $\mathscr{P}$ holds for $X$. Using Zorn's Lemma, we can say that the set $\Sigma$ of closed subsets of $Y$ where $\mathscr{P}$ holds has a maximal element, but how do we know that the maximal element is $X$? I want to say that we can take the union of all closed subsets in $\Sigma$ and that should be $X$ but why is the union of all closed subsets in $\Sigma$ equal to $X$? Thanks!",['algebraic-geometry']
2894833,Multiplicity of the zero eigenvalue when a symmetric matrix has $m$ identical rows,"Let $A$ be a real symmetric matrix of order $n$.
  Show that if $A$ has $m$ identical rows then $A$ has a zero eigenvalue of multiplicity at least $m-1$. My try : Since $A$ has $m$ identical rows by elementary row operations we have $m-1$ rows of $A$  equal to $0$. Hence $A$ has geometric multiplicity of $0$ to be equal to atleast $m-1$.
Since $A$ is symmetric so the algebraic multiplicity of $0$ equals its geometric multiplicity and so it is atleast $m-1$. But how to show that it is equal to exactly $m-1$? Will you please help?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
2894841,Reference Request: Mature introduction to differential geometry,"I didn't want to call it an advanced introduction, at the risk of sounding absurd. What I'm looking for is a mature and/or modern introduction to differential geometry. Let me clarify three things: what I mean by mature is that the book should assume (or at least be targeted towards) someone who has experience reading math, and say a solid background in analysis, topology, and algebra (and maybe a very basic intro to differential geometry). What I mean by modern is that it does not shy away from using modern algebraic and analytic machinery. What I mean by ""and/or"" is that of course, I would be interested in either modern introductions or mature introductions, due to fear that maybe both is a tall order. I know do Carmo has ""Differential Geometry of Curves and Surfaces."" Is that the best choice?","['reference-request', 'differential-geometry']"
2894849,"How do I eliminate $x$ and $y$ from the system $x^2 y= a$, $x(x+y)= b$, $2x+y=c$ to get a single equation in $a$, $b$, $c$?","Alright, a homework problem. I'm stuck at this question, Eliminate $x$ and $y$ from the given equations to get a single
  equation in terms of $a$ , $b$ and $c$ $$\begin{align}
x^2 y &= a \\
x(x+y) &= b \\
2x+y &=c
\end{align}$$ Let me tell you what I tried, I tried to get $y$ from one equation and substitute in the other two. Turns out that I'm not able to fully get rid of both $x$ and $y$. Help please.",['algebra-precalculus']
2894850,Does the gradient theorem generalize to vector-valued potentials?,"The gradient theorem states that if $F$ is a differentiable scalar-valued function of an $n$-dimensional vector space, then the gradient of $F$ is a conservative vector field. Line integrals through this field are path-independent, meaning that any line integral through $F'$ that starts at point $a$ and ends at point $b$ will evaluate to the scalar $F(b) - F(a)$. Does this result generalize to cases where we start with a vector field? So say $G$ is a vector field and $G'$ is its Jacobian matrix: is the tensor field defined by $G'$ conservative in roughly the same way? Does any line integral through that field starting at $a$ and ending at $b$ now evaluate to the vector $G(b) - G(a)$? I feel this must be true because you can just argue component-wise, treating each dimension of the output of $G$ as a scalar and considering the vector field defined by each of the corresponding dimensions of $G'$. But I'm not certain that actually works out, or whether there are additional conditions that must hold. For example, must $G$ itself be a conservative vector field? Or, to put it differently, must $G'$ be a Hessian matrix?","['multivariable-calculus', 'line-integrals', 'linear-algebra', 'vector-analysis']"
2894879,Function is partial differentiable but has no total derivative,"I have to give an example of a function $f \colon \mathbb{R}^2 \to \mathbb{R}$ that has partial derivatives $(\partial_1f)(0,0) = 1 = (\partial_2f)(0,0)$ but no total derivative in $(0,0)$. I think that the function 
$$
  f \colon \mathbb{R}^2 \to \mathbb{R},
  \quad 
  f(x,y) =
  \begin{cases}
  \frac{xy}{x^2 + y^2} + x + y & \text{if $(x,y) \neq (0,0)$} \\
  0 & \text{if $(x,y) = (0,0)$} 
  \end{cases}
$$
is an example, I'm just not sure if my proof is correct. We know that $f$ is total differentiable if $(x,y) \neq (0,0)$ because the partial derivatives exist and are continuous. $f$ is also partial differentiable if $(x,y) = (0,0)$ because $f(x,0) = x$ and $f(0,y) = y$ and they are given by $(\partial_1 f)(x,0) = 1 = (\partial_2f)(0,y) = 1$. To proof that $f$ is total differentiable in $(0,0)$ we now only have to proof that 
$$
    f(x,y)
  = (1,1)
    \begin{pmatrix}
      x \\
      y \\
    \end{pmatrix}
    + o(\| (x,y) \|)
  \qquad
  \text{when $(x,y) \to (0,0)$}
$$
but this doesn't hold when $x=y=t$ and $t \to 0$ and so $f$ is not total differentiable when $(x,y) = (0,0)$. Can someone confirm if this is correct?","['partial-derivative', 'derivatives', 'real-analysis']"
2894908,How to find the value of the $20^\text{th}$ derivative of the function in concrete point?,"We have function $\arcsin(x)$. How to find it's  $20^\text{th}$ derivative in $x = 0$? Actually i don't have any idea except to get that derivatives manually one by one. Also, i've tried to get it with computer help, the function i get is something terrible. Also it can be solved with Leibniz formula, but it is too hard (to my mind).",['derivatives']
2894944,Find the range of values of $k$ such that $f(x)$ is onto,"I am trying to solve the below problem in pre-calculus, I give below the steps I followed , I am stuck as it gets very complicated , need help in solution. A function $f : \mathbb R \to \mathbb R$ is defined by $$f(x) = \frac{kx^2+6x-8}{k+6x-8x^2}.$$ Find the intervals of values of $k$ such that $f$ is onto. The answer given in the book is $2 \leq k \leq14$. I started by trying to find the range of the function and find the values of k such that the range is = $\mathbb R$ ( that is range = co domain , in this case co domain is $\mathbb R$ and hence has to prove that range = $\mathbb R$) Let $$y = \frac{kx^2+6x-8}{k+6x-8x^2}$$ 
Rearranging and grouping gives
$$(k+8y)x^2 + 6(1-y)x - (8+ky) = 0.$$ 
This is quadratic in $x$ and for $x$ to be real $det(x) \geq 0$, which requires $$36(1-y)^2+4(k+8y)(8+ky) \geq 0.$$ Rearranging and grouping this equation gives 
$$(36+32k)y^2+(4k^2+184)y+(36+32k) \geq 0.$$
Now I have to find the range of values of $k$ such that the above expression is $\geq 0$. Totally stuck here. Please help. Also, is there any other easier way of arriving at the range of $k$ ?","['algebra-precalculus', 'functions', 'rational-functions']"
2894957,Interesting limit: $I(n)=\lim_{x \to 0} (e^x-1)^{-n} - \left(\frac{x}{1!}+\frac {x^2}{2!}+\dotsb+\frac{x^n}{n!}\right)^{-n}$,"I recently came up with a problem which I think is quite interesting and here it is. Let $$I(n)=\lim_{x\to 0} \left(\frac {1}{(e^x-1)^n} -\frac {1}{\left(\frac {x}{1!}+\frac {x^2}{2!}+\frac {x^3}{3!}+\cdots +\frac {x^n}{n!}\right)^n}\right) $$ Evaluate $I(n)$ in terms of $n$ . Now I tried a lot of messing ups with this monster.  Tried L'Hospital,  Squeeze theorem, Stolz-Cesaro,  Binomial theorem and Multinomial theorem,  etc.  But couldn't reach the general form. On writing out few terms using Wolfy I get $I(1)=\frac {-1}{2}$ , $I(2)=\frac {-1}{3}$ , $I(3)=\frac {-1}{8}$ , $I(4)=\frac {-1}{30}$ and so on On spending some time on these observations I could conjecture that $$I(n)=\frac {-n}{(n+1)!}$$ and tried this formula to check whether it was consistent with other values of $n$ and it indeed was.  So Now I have the general form but no proof to it. And something which is quite interesting in this question is that the first fraction has a denominator with a function raised to power $n$ while the denominator of second fraction is nothing but the Maclaurin expansion of that function with finite terms (here $n$ terms)  raised to power of $n$ . So I tried to test it with some other functions and the results impressed me a lot. 1) $$J(n)=\lim_{x\to 0} \left(\frac {1}{(\ln (1+x))^n} -\frac {1}{\left(x-\frac {x^2}{2}+\frac {x^3}{3}-\cdots +\frac {(-1)^{n+1} x^n}{n}\right)^n}\right) =\frac {(-1)^{n+1}n}{n+1}$$ 2) $$G(n)=\lim_{x\to 0} \left(\frac {1}{(\arccos x-\frac {\pi}{2})^n} -\frac {1}{\left(\underbrace{\frac {x}{1}+\frac {x^3}{6}+\frac {3x^5}{40}+\frac {5x^7}{112}+\cdots}_{\text {n terms}}\right)^n}\right) $$ Now this limit is more interesting because it equals $0$ for all even natural $n$ and it doesn't exist for any odd natural $n$ Now what I actually want is a proper method to solve such problems. You can take any of top 2 limits ( i.e of $(e^x-1)$ or $\ln (1+x)$ ) to demonstrate your method. Thanks in advance for your attention.","['limits', 'calculus', 'taylor-expansion']"
2894959,Determining the limit of $x_{n+1} = x_n + 1/(3 x_n^2)$,"Let $\{x_n\}_{n \in \mathbb{N}}$ be a sequence such that 
  $$
  x_1 > 0,
  \qquad
  x_{n+1} = x_n + \frac{1}{3 x_n^2}
$$
  Check whether the sequence converges, and if so find its limit. So I know that a sequence converges if it is bounded and monotone. So I proved those two (hopefully correct): Proving that $x_n > 0$ for all $n$: Base: $x_1 > 0$ Hypothesis: $x_n > 0$ Step:
  $$
           \text{$x_n > 0$ and $\frac{1}{3 x_n^2} > 0$}
  \implies x_n + \frac{1}{3 x_n^2} > 0
  \implies x_{n+1} > 0
$$ Proving that the sequence is monotone increasing:
  $$
    x_{n+1} - x_n
  = x_n + \frac{1}{3 x_n^2} - x_n
  = \frac{1}{3 x_n^2}
  > 0
  \qquad
  \text{for all $n$}
$$ Now, I've tried finding the limit, like this:
$$
           \exists \alpha = \lim_{x \to \infty} x_{n+1}
  \implies \alpha = \alpha + \frac{1}{3 \alpha^2}
  \implies \frac{1}{3 \alpha^2} = 0
$$ Where I end up with a conclusion that the limit is equal to infinity, meaning that the sequence diverges. So what am I doing wrong here? Is one of my proofs incorrect or is my limit calculation wrong? Thanks","['sequences-and-series', 'recurrence-relations', 'real-analysis']"
2894975,"Why is the ""greater than"" or ""less than"" symbol referred to as operators?","My understanding of operators is it works on elements of a set and produces another element of the same set. I don't see how or why the ""$>,â‰¥,<,â‰¤$"" would be referred to as ""operators"" on some pages as it doesn't map to another element. (I think I've also seen it on Wikipedia as well) I've always thought of it as a ""relation"" though. Can anyone shed some light?",['functions']
