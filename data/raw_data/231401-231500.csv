question_id,title,body,tags
4809514,Sheaves of modules isomorphic after pullback - when isomorphic in general?,"Let $f: X \to Y$ be a morphism of schemes and $\mathcal{M}, \mathcal{N}$ be $\mathcal{O}_Y$ -modules. Suppose $f^*\mathcal{M} \cong f^* \mathcal{N}$ . Under which assumptions can I conclude that already $\mathcal{M} \cong \mathcal{N}$ ? This is clearly wrong in the general as one can see by $f$ being the inclusion of a point, so surjectivity/dominance of $f$ will be one of these conditions, but is this condition already enough? I was playing around with the adjunction of pushforward and pullback but currently I am stuck. I am mainly interested in the case of $\mathcal{M}, \mathcal{N}$ being line bundles on a nodal curve $C$ over an algebraically closed field and $f$ being the normalisation of $C$ , so I would be happy about a positive result in this case, but I think the general question is also educational.","['algebraic-geometry', 'coherent-sheaves']"
4809521,"Divergence, interior products and Lie derivative coincide?","The divergence on a Riemannian manifold is defined as $$\operatorname{div}X=\operatorname{tr}(Y\mapsto \nabla_YX)$$ for $X,Y\in \mathfrak{X}(M)$ . I found online that this can be apparently defined also as $$d(\iota_XdV_g)= (\operatorname{div}X)dV_g.$$ Here $dV_g$ is the volume form with the metric $g$ . I have a hard time understanding why these two definitions are equivalent. It is also furthermore said that $\mathcal{L}_X(dV_g)=(\operatorname{div}X)dV_g$ which only adds to my confusion. Could anyone elaborate on why these are all equivalent definitions?","['riemannian-geometry', 'differential-geometry']"
4809530,"combinatorics olympiad problem infinite board, two parts","Grid the plane forming an infinite board. In each cell of this board, there is a lamp, initially turned off. A permitted operation consists of selecting a square of $3\times 3, 4\times 4$ or $5\times 5$ cells and changing the state of all lamps in that square (those that are off become on, and those that are on become off). (a) Prove that for any finite set of lamps, it is possible to achieve, through a finite sequence of permitted operations, that those are the only lamps turned on on the board. (b) Prove that if in a sequence of permitted operations only two out of the three square sizes are used, then it is impossible to achieve that at the end the only lamps turned on on the board are those in a $2 \times 2$ square. I couldn't solve part b). In a) you can change the state of a $9\times 9$ board using the $3\times 3$ , then you change the same $9\times 9$ board using 2 $4\times 4$ boards and 2 $5\times 5$ boards such that the $5 \times 5$ boards share a square. Therefore we changed the state of only one lamp, and this is enough to prove part a). (If this solution to part a) is not well understood, you can answer it in the comments and I will clarify it better). Moons are the $5\times 5$ and elephants the $4\times 4$ I tried part b for a long time but I have no ideas how I can get it.",['combinatorics']
4809599,How to integrate $\int \frac{1}{1+\sqrt{\frac{1}{1+x}}}dx$?,"How to integrate $\int \frac{1}{1+{\sqrt{\frac{1}{1+x}}}}dx$ ? I am trying this integral by substituting $x=\tan^{2}\theta$ . Therefore $dx=2(\tan\theta)(\sec^{2}\theta)d\theta$ . Now $\sqrt{\frac{1}{1+x}}=|\cos\theta|$ . Now  if I take $|\cos\theta|=\cos\theta$ , then  the result of the above integral will be $\int{(\sec^{2}\frac{\theta}{2})}(\tan\theta)(\sec^{2}\theta)d\theta$ . And for $|\cos\theta|=-\cos\theta$ , the result of the above integral will be $\int (\csc^{2}\frac{\theta}{2})(\tan\theta)(\sec^{2}\theta)d\theta$ . Thus two different integrals are occurring. Therefore I thought of taking $|\cos\theta|=(\cos\theta)\text{sgn}(\cos\theta)$ . Therefore the above integral will be $\int \frac{1}{1+(\cos\theta)(\text{sgn}(\cos\theta))}d\theta$ . But I can't simplify further. Also I can't understand the case when $|\cos\theta|=0$ . Because, when $\cos\theta=0$ , then $\tan\theta=\infty$ . Therefore, I am in very much doubt with this integral. Please help me out with this integral.","['integration', 'indefinite-integrals', 'calculus']"
4809600,$\alpha$-mixing properties and convergence in distribution,"I have a stochastic process $\{W_t\}_{t\geq 1}$ , of uncorrelated but not indipendent random variables, with $\mathbb{E}(W_t) = 0$ and $Var(W_t)=\frac{t-1}{2}$ $\forall, t\geq 1$ (The $\{W_t\}_{t\geq 1}$ are not identically distributed). In particular I have some evidence (by Monte Carlo simulation) that: $$
D_n = 1+\frac{2}{n}\sum_{t = 1}^{n}W_t\to Z\sim Exp(1) \mbox{ as $n\to\infty$}
$$ where $""\to""$ represents the convergence in distribution of the new process $D_n$ . By simply calculations $\mathbb{E}(D_n) = 1$ and $Var(D_n) = 1-\frac{1}{n}$ . Classic limit theorems do not apply in this case, because $W_t$ are not indipendent random variables (although uncorrelated). I have just read about the $\alpha$ -mixing condition of a stochastic process, and in general the  concept of ""measure of indipendence"" and ""asymptotic indipendence"". You can find the main definitions for example here: https://encyclopediaofmath.org/wiki/Strong_mixing_conditions I have seen that there are many limit theorems which use this property to prove that some kind of sequence converge in distribution and I really think that one of them will be the key to my case. For example in the following book: https://books.google.it/books/about/Limit_Theory_for_Mixing_Dependent_Random.html?id=GeRT0---hhcC&redir_esc=y there are some of them. If needed I will add the definition of $W_t$ , although I would prefer a general theorem which also covers my particular case (with the assumption that $W_t$ or $D_n$ satisfy the $\alpha$ -mixing condition). Question Do you know a limit theorem which use (or doesn't use) the $\alpha$ -mixing condition and such that my case satisfies its hypothesis? Thank you in advance for your help!","['probability-limit-theorems', 'weak-convergence', 'stochastic-processes', 'probability', 'random-variables']"
4809608,Extending function on semialgebra to measure on algebra requires non-negativity? Durrett Probability,"In the 1st section of the appendix of Durrett's probability theory and examples, he said the following: Theorem A.1.1 Let $\mathcal{S}$ be a semialgebra and let $\mu$ defined on $\mathcal{S}$ have $\mu(\emptyset)=0$ . Suppose (i) if $S \in \mathcal{S}$ is a finite disjoint union of sets $S_i \in \mathcal{S}$ , then $\mu(S)=\sum_i \mu\left(S_i\right)$ , and (ii) if $S_i, S \in \mathcal{S}$ with $S=+_{i \geq 1} S_i$ then $\mu(S) \leq \sum_i \mu\left(S_i\right)$ . Then $\mu$ has a unique extension $\bar{\mu}$ that is a measure on $\overline{\mathcal{S}}$ the algebra generated by $\mathcal{S}$ . If the extension is $\sigma$ -finite, then there is a unique extension $v$ that is a measure on $\sigma(\mathcal{S})$ . Proof Lemma 1.1.7 shows that $\overline{\mathcal{S}}$ is the collection of finite disjoint unions of sets in $S$ . We define $\bar{\mu}$ on $\overline{\mathcal{S}}$ by $\bar{\mu}(A)=\sum_i \mu\left(S_i\right)$ whenever $A=+_i S_i$ . To check that $\bar{\mu}$ is well defined, suppose that $A=+_j T_j$ and observe $S_i=+_j\left(S_i \cap T_j\right)$ and $T_j=+_i\left(S_i \cap T_j\right)$ , so (i) implies $$
\sum_i \mu\left(S_i\right)=\sum_{i, j} \mu\left(S_i \cap T_j\right)=\sum_j \mu\left(T_j\right)
$$ In Section 1.1 we proved:... He did require measure on algebra to be non-negative, but he never said so for $\mu$ . So I wonder if that's a typo? In fact, I don't understand why he would require $\mu(\emptyset) = 0$ , but not the nonnegative requirement. Durrett never defined measure for semi-algebra, so I assume $\mu$ is just some function.","['measure-theory', 'probability-theory', 'real-analysis']"
4809697,"$G_p=\{\{x_n\}_{n\inℕ} \in l^p(R) :\displaystyle \sum_{k=1}^\infty x_k=0 \}$ is not closed for $p\in (1,\infty)$","I have to show that $G_p=\left\{\{x_n\}_{n\inℕ} \in l^p(R) :\displaystyle \sum_{k=1}^\infty x_k=0 \right\}$ is not closed for $p\in (1,\infty)$ . My idea was to take a sequence: $x_n(k)=-1 \text{    for } k=1$ $x_n(k)=\frac{1}{n} \text{    for } 2\le k<n+1$ $x_n(k)=0 \text{    for } k>n+1$ which is element of $G_p$ for all $n $ but the pointwise limit: $x(k)=-1 \text{    for } k=1$ $x(k)=0 \text{    for rest}$ is not element of $G_p$ ... Let's try to show that $x_n \to x$ in $l^p$ $$||x_n-x||_p^p={\sum_{k=2}^{n+1} \frac{1}{n^p}}= n \frac{1}{n^p} \to_{n\to\infty}  0$$ am I missing something here?","['lp-spaces', 'functional-analysis']"
4809699,Can you completely determine a finitely presented finite group?,"Let $G = \langle S \mid R \rangle$ be a finitely presented group. Suppose you know $G$ is finite. Can you completely construct the group multiplication table? I feel like the answer is yes. My first thought is to construct homomorphisms into symmetric groups, but I am not quite sure how to go about it.","['group-presentation', 'finite-groups', 'combinatorial-group-theory', 'abstract-algebra', 'group-theory']"
4809945,Does zero-probability imply impossible event in discrete cases?,"I'm still confused about impossible events and events with zero probability. When the sample space is discrete and finite, does $P(A)=0$ ⇒ $A=∅$ ? Also, if B is an event which doesn't contain any elements from the sample space, is it therefore an impossible event $B=∅$ ? Like, rolling a $7$ on a $6$ -sided die. Thanks.","['statistics', 'probability-theory', 'probability']"
4810112,Challenging integration,"I have just seen a question regarding an integration, which is quite hard. Though, I guess the word “hard” here means it is not an integration that needs a specific complicated technique, but I do not know nor see the trick to simplify the integrand. Find the definite integral $$\int_0^1 (x+1)(2x+1)(3x+1)\ldots (2566x+1)\left(\frac{1}{x+1} + \frac{2}{2x+1} + \ldots + \frac{2566}{2566x+1}\right) \,\Bbb dx$$","['integration', 'calculus', 'definite-integrals']"
4810147,Solving $\frac{1}{\sqrt x}-\frac{1}{\sqrt {x-5}}=-\frac 16$,"I got stuck on below equation $$\frac{1}{\sqrt x}-\frac{1}{\sqrt {x-5}}=-\frac 16$$ I tried to power both sides, use substitution and ... like these $$\frac{1}{\sqrt {x-5}}=u \to x= \frac{5u^2+1}{u^2}\\\frac{u}{\sqrt{5u^2+1}}-u=-\frac16\\ \frac{u^2}{5u^2+1}=u^2+\frac 1{36}-\frac 13 u$$ then I tried to multiplying by $$\sqrt{x(x-5)}$$ to both sdies but bcome a 4th degree equation. then I tried grphical calculator  for $$f(x)=\frac{1}{\sqrt x}-\frac{1}{\sqrt {x-5}}-\frac 16$$ and see the solution is $x=9$ I take $f'(X)$ and see $f'>0 $ and $f(x)$ is increasing function, so must have one root.    but I want to know  if there is a tricky way or simple Idea to solve the equation without dealing with 4th degree equation ? any help will be appreciated.","['calculus', 'functions', 'algebra-precalculus']"
4810238,"If $f''(x) +f(x) \geq 0$, show that $f(x) + f(x+\pi) \geq 0$ for all $x$ [duplicate]","This question already has an answer here : $f''+f \ge 0$ implies $f(x)+f(x+\pi) \ge 0$ (1 answer) Closed 7 months ago . I've been trying to solve the following exercise and simply have no idea how to solve it whatsoever. Let $f:\mathbb{R}\to\mathbb{R}$ be a function of class $\mathcal{C}^2$ , such that for all $x\in\mathbb{R}$ one has: $$f''(x)+f(x)\geq0$$ Show that for all $x\in\mathbb{R}$ one has: $$f(x)+f(x+\pi)\geq0$$ How can I even begin to tackle a question like this? I'm used to differential equations and solve them without a problem most of the time, but I can't find any information on differential inequalities , which is why I'm desperately resorting to this forum (which I know normally doesn't receive problems without much of an attempt behind them very well). What's the general approach one must adopt in order to tackle a problem like this?","['calculus', 'ordinary-differential-equations']"
4810249,For which $n$ in $2048 < n < 4096$ is the exact number of groups of order $n$ up to isomorphism currently unknown?,"The number of groups of order $2^{11} = 2048$ up to isomorphism is currently unknown, that is at least, as of 2023. The same can be said of $2^{12}=2 \cdot 2048 = 4096$ . What about the number of groups of order $n$ for $2048 < n < 4096$ ? Perhaps for example $3072 = 1024 \cdot 3 = 2^{10} \cdot 3$ , as it has the same number of prime factors (with multiplicity) as $2048$ ? Or is this one known?","['group-theory', 'finite-groups', 'groups-enumeration', 'reference-request']"
4810258,Intuition behind a zero derivative,"I came across a following statement in my analysis book: A function being strictly increasing doesn't imply that its derivative is always greater than zero. For example, $(x-2)^5$ is strictly increasing, while its derivative $5(x-2)^4$ is equal to $0$ at $x=2$ . I'm really having trouble making sense of this. I always thought that a zero derivative at a point $c$ means that for points $x$ really close to $c$ , $f(x) = f(c)$ . Could someone please explain how this statement makes sense intuitively?","['functions', 'derivatives', 'monotone-functions', 'intuition']"
4810280,Prove the formula $(\forall x Px \wedge \forall x Qx) \leftrightarrow \forall x [Px \wedge Qx]$,"I'm sure this implication is correct. However, are there rules on how one can manipulate with quantifiers? It might somehow be related to whether no free variables are becoming bounded after the operation.","['elementary-set-theory', 'quantifiers', 'logic']"
4810284,Functional equation f(x+1)=f(x)+2x+1,"I took the function $f(x)=x^2$ and noted that $f$ satisfies the following functional equation (from well-known equality $(x+1)^2=x^2+2x+1$ ): $$f(x+1)=f(x)+2x+1.$$ Here's the question: is there another solution $f: \mathbb{R} \to \mathbb{R}$ for this equation? I tried to prove it myself, but didn't succeed. Could you help, please? Also I wonder: there is another functional equation for $f(x)=x^2$ : $$f(x+y)=f(x)+2xy+f(y).$$ Is it related to the previous one? Can we deduce the second from the first? UPD1: the fist question was answered in the comments. What about the second one? UPD2: the second eqution has others solutions too. For instance, take $f(x)=x^2+ax$ , where $a$ is an arbitrary real number. See Functional equation $f(x+y)=f(x)+2xy+f(y)$ .","['functional-equations', 'functions', 'real-analysis']"
4810303,Convergence in distribution of a trig sequence of random variables,"Let $\theta_i\sim\mathcal{U}(0,2\pi)$ , $i = 1,\dots,n$ be $n$ i.i.d. uniformly distributed random variables. Let: $$
\frac{D_n^2}{n} = 1 + \frac{2}{n}\sum_{i<j}^{n}\cos(\theta_i-\theta_j)
$$ I have the evidence (by Monte Carlo simulation) that $\frac{D_n^2}{n}\to Z\sim Exp(1)$ in distribution as $n\to\infty$ . I really have tried all the strategies I know, but none of them seem to work in this case. Note that the random variables $\cos(\theta_i-\theta_j)$ in general are not indipendent (although uncorrelated). Note how $\frac{D_n^2}{n}$ has mean 1 and variance equal to $1-\frac{1}{n}$ (so at least asymptotically they certainly have the first two moments equal to each other). I have proved that $\frac{D_n^2}{n}$ has all the moment bounded, in particular: $$
\mathbb{E}\Bigl(\Bigl(\frac{D_n^2}{n}\Bigr)^k\Bigr)\leq\frac{(2k)!}{2^k k!} \mbox{ $\forall k\in\mathbb{N}$}
$$ although I really think, since I have evidence of the convergence in distribution of $\frac{D_n^2}{n}$ to an exponential distribution, that: $$
\lim_{n\to\infty}\mathbb{E}\Bigl(\Bigl(\frac{D_n^2}{n}\Bigr)^k\Bigr) = k!
$$ which is indeed the $k$ -th moment of an exponential of parameter 1. I was also trying to understand if $\frac{D_n^2}{n}$ was sub-exponential or sub-gaussian $\forall n\in\mathbb{N}$ , and I think the answer is yes, although again I don't know how to use this information to prove this convergence. I have also tried to use the Portmanteau theorem, without success (probably I didn't find the right trick to prove it). To simulate this process using the software $R$ , here is a code I made for computing $\frac{D_n^2}{n}$ : it = 10000
n = 1000
thetamat = matrix(rep(0,n*it),n,it)
  D1 = rep(0,it)
  for(i in 1:n) {
    thetamat[i,] = runif(it,0,2*pi)
  }
  for(k in 1:it) {
    for(i in 1:(n-1)) {
      for(j in (i+1):n) {
        D1[k] = D1[k] + cos(thetamat[i,k]-thetamat[j,k])
      }
    } 
  }
  D = 1 + 2/n*D1 Any help will be so much appreciated. Thank you in advance.","['weak-convergence', 'probability-limit-theorems', 'probability-theory', 'probability']"
4810309,I can't find the minimum point using Lagrange multipliers in that function,"I need to find the maximum and minimum points of the function $f(x,y,z) = x^2 + y^2 + z^2$ restricted to $x^4 + y^4 + z^4 = 1$ . I manage to find the maximum point, $\sqrt{3}$ . However, the template is also pointing to a minimum point equal to 1. I know that I can make $x = 0$ and $y = 0$ in the constraint, and thus conclude that $z= \pm 1$ , or just change the combinations. However, solving the system \begin{align*}
2x &= \lambda 4x^3 \\
2y &= \lambda 4y^3 \\
2z &= \lambda 4z^3 \\
x^4 + y^4 + z^4 &= 1
\end{align*} I can't find $z= \pm 1$ . Could anyone help me?","['multivariable-calculus', 'lagrange-multiplier']"
4810325,A conjugacy class of an element in a profinite group is either finite or uncountably infinite?,"Let $g$ be an element of a profinite group $G$ . Is it true that the conjugacy class $g^G=\{hgh^{-1}~|~h\in G\}$ of $g$ in $G$ is finite or uncountably infinite? I know that profinite groups are always finite or uncountable, and we can consider the coset space $G/C_G(g)$ where $C_G(g)$ is the centralizer of $g$ in $G$ . Thus, we are done if $C_G(g)$ is a normal subgroup of $G$ . What if $C_G(g)$ is not normal? Any comments and references would be appreciated.","['group-theory', 'profinite-groups']"
4810329,What does exactly $ ∀ε>0$ means?,"I was proving a problem from textbook which states : Let $a < b$ be real numbers and consider the set $T= ℚ ∩ [a,b]$ . Then $supT=b$ . My attempt : Since $a < b$ , so by density of $ ℚ $ there exists atleast one rational number between $a$ and $b.$ Thus $T ≠ ∅$ . Moreover $b$ is an upper bound for $T$ , therefore by axiom of completeness supT exists.
Suppose $ε > 0$ be arbitrary. Then $b − ε < b.$ By density of rational numbers there exists $q ∈ℚ $ s.t $b − ε < q < b$ . Here I have to show that $q \in ℚ $ and i got stuck. Later I found a solution (online) : I saw my solution is exactly similar. But after looking the next step I still didn't understand How $r\in ℚ$ and $b- ε < r < b$ implies $r \in T$ ? So my online friend told me ""this is because of arbitrary small $ ε $ . Moreover in real analysis we suppose $ ∀ ε > 0$ as arbitrary small $ ε > 0$ . Even in your proof, we have $ 0 < ε 
< b -a $ ."" (Notice this is exact his wording I am using all conclusion which I understood). My questions : what does $ ∀ ε > 0$ shows? Some people say this is arbitrary small number, that is $0 < ε <$ (some positive number, whatever your needed). But if so, then why we write "" $ ∀ ε > 0$ ? Because this shows actually $ ∀x ∈ ℝ (x > 0)$ , any positive real number not necessarily small. How does "" $ \cdots$ implies $r ∈ T$ "" in above solution (pic)? I have spend almost whole day to understand the concept but I didn't. I have found many posts on MSE about epsilon but none of them was answering my question. Thank you.","['epsilon-delta', 'proof-writing', 'analysis', 'real-analysis', 'solution-verification']"
4810332,Inverse for the canonical isomorphism of inner product space with its dual.,"Let $V$ be a finite-dimensional vector space equipped with an inner product $\langle\cdot,\cdot\rangle$ . We know that in this case $V$ is isomorphic to $V^*$ via the map $$f:V \to V^\ast, f(v)=\langle v,\cdot\rangle.$$ I can prove that this is injective and surjective, but what I wanted to know is that what is the inverse of this map explicitly? I couldn't find an answer online. Much of the stuff  I found were proving the bijectivity, but not giving an explicit inverse.","['abstract-algebra', 'linear-algebra', 'vector-spaces']"
4810334,Seeking more alternate proofs of a combinatorial generating function identity $G(x)=\overline{G}(-x)^{-1}$ related to counting strings.,"Let $\mathcal{S}=[m]^*$ be the set of all strings on the alphabet $[m]=\{1, 2,\cdots, m\}$ . Let $\Sigma\subset[m]^2$ be a set of strings of length $2$ , and let $\overline{\Sigma}=[m]^2\backslash\Sigma$ be the complementary set. Let $\mathcal{G}$ (respectively $\overline{\mathcal{G}}$ ) be the set of all strings in $\mathcal{S}$ with the property that every substring of length $2$ belongs to $\Sigma$ (respectively $\overline{\Sigma}$ ). (Note that $\mathcal{G}$ and $\overline{\mathcal{G}}$ both include all strings of length $0$ or $1$ .) Letting $\pi(\sigma)$ be the length of a string $\sigma\in\mathcal{S}$ , define the two generating functions \begin{equation}
G(x)=\sum_{\sigma\in\mathcal{G}}x^{\pi(\sigma)}\qquad\qquad \overline{G}(x)=\sum_{\sigma\in\overline{\mathcal{G}}}x^{\pi(\sigma)}
\end{equation} The following identity holds: $G(x)=\overline{G}(-x)^{-1}$ A few years ago during my undergrad, I was asked to prove the above generating function identity in an assignment for a class on combinatorial enumeration. I have written out a proof of this identity below as an answer (I think that makes the most sense here, to keep this question concise). However, after I submitted this proof, I was informed that my proof was unexpected, and that there were other more intended methods to arrive at the identity. Therefore I ask out of curiosity: What are some alternate methods of proving the above identity? (perhaps using more standard string counting generating function arguments, generalized inclusion exclusion, a combinatorial approach, or some more exotic method) I would also be interested in seeing if/how different approaches to this problem allow for generalization of this identity. (perhaps a higher order identity of this sort exists, or perhaps one involving substrings of length greater than $2$ , or one involving more general objects) I give mention one such small generalization in my answer.","['generating-functions', 'alternative-proof', 'combinatorics', 'formal-power-series', 'power-series']"
4810405,What is a localized borel space?,"This question is based on the presentation in Kallenberg's Foundations of Modern Probability 3e. Call the measurable spaces $(S,\mathcal S)$ and $(T,\mathcal T)$ Borel isomorphic if there is a bijection $f:T\to S$ with $f$ and $f^{-1}$ measurable. Call $(S,\mathcal S)$ a Borel space if it is Borel isomorphic to a borel subset of $[0,1]$ . (In particular, any polish space is Borel.) Next, given a Borel space $(S,\mathcal S)$ , we choose a ""localizing sequence"" $E_n \uparrow S$ with $E_n\in \mathcal S$ . Let $B\subset S$ . If $B\subset E_n$ for some $n$ , then we say $B$ is bounded and we by denote $\hat{\mathcal S}$ the ring of bounded (measurable) sets. In particular, if $\mathcal S$ is generated by a metric $\rho$ , then we may take $\hat{\mathcal S}$ to be all $\rho$ bounded sets. The notion of signed measure is then introduced. Let $(S,\mathcal S)$ be a localized Borel space and let $\nu: \hat{\mathcal S}\to \mathbb R$ . Say that $\nu$ is a signed measure if $\nu \cup_n B_n = \sum \nu B_n$ for any $B_i$ disjoint with the series converging absolutely. What is going on here? On the other hand, in the second edition of the book, there is no discussion of the notion of a ""localized Borel space.""  Indeed, a signed measure is presented in the usual way. Namely, let $(\Omega,\mathcal A)$ be a measurable space. $\nu:\mathcal A\to\mathbb R$ is a bounded signed measure if $\nu \cup B_n = \sum \nu B_n$ for any disjoint $B_i$ with the series converging absolutely. Why do we need to introduce localized Borel spaces? As another example, in the second edition, one has the usual definition of locally finite measure. Namely, $\mathcal X$ is a topological space and $\mathcal B$ its Borel $\sigma$ -field. Call $\mu$ locally finite if every point $x\in \mathcal X$ has a neighborhood with finite measure. In the third edition, it is instead defined as let $(S,\mathcal S)$ be a localized Borel space and $\mu$ a measure. Say $\mu$ is locally finite if $\mu<\infty$ on $\hat{\mathcal S}$ .","['measure-theory', 'probability-theory', 'intuition']"
4810483,"When can we ""switch"" isomorphic things","I'm finishing a course on basic abstract algebra, which covers groups, rings, modules, and finite group representations. However, up to this point, I am not very sure about the concept of isomorphism. I know there are examples where given a group $G$ and two normal subgroups, $H$ and $K$ , where $H \cong K$ , but $\frac{G}{H} \not \cong \frac{G}{K}$ . For instance, see here . However, for (external) direct sum, this does not seem to be a problem, for groups $A,B,C,D$ , if $A \cong B$ , $C \cong D$ , $A \oplus B \cong C \oplus D$ . I only know a little (if not nothing) about category theory. When learning general topology, we constructed product topology and quotient topology with universal product, and that's the most I know about these constructions. So my question is, when we create a new object based on two or more objects in the same category, does the isomorphism carry over? For instance if we make object $(AB)$ from $A$ and $B$ , and $(CD)$ from $C$ and $D$ , when can we conclude that $A \cong C$ , $B \cong D$ implies that $(AB) \cong (CD)$ , or vice versa?","['category-theory', 'quotient-group', 'abstract-algebra', 'quotient-spaces', 'general-topology']"
4810555,Proving that $\int f^2\log \left(\frac{|f|}{\|f\|_2}\right)dx \leq \int f^2\left(\log \frac{|f|}{\|f\|_2}\right)^2 dx$.,"I want to prove the following inequality: $$\int_{-\infty}^{\infty} f^2\log \left(\frac{|f|}{\|f\|_2}\right) dx \leq \int_{-\infty}^{\infty} f^2\left(\log \frac{|f|}{\|f\|_2}\right)^2 dx$$ Note that this inequality remains the same if we multiply $f$ by a scalar $c$ . Hence, without loss of generality, we may assume that $\|f\|_2=1$ . Partial solution: By Holder's inequality, and by recalling that $\|f\|_2=1$ , we have that $$\int_{-\infty}^{\infty} f^2\log \left(\frac{|f|}{\|f\|_2}\right) dx \leq \left[\int_{-\infty}^{\infty} f^2\left(\log \frac{|f|}{\|f\|_2}\right)^2 dx\right]^{1/2}$$ Hence, if $\int_{-\infty}^{\infty} f^2\left(\log \frac{|f|}{\|f\|_2}\right)^2 dx\geq 1$ , then this implies the inequality that we want. However, I'm unable to prove this inequality if $0\leq \int_{-\infty}^{\infty} f^2\left(\log \frac{|f|}{\|f\|_2}\right)^2 dx<1$ . I am probably missing something quite elementary.","['inequality', 'analysis']"
4810674,Confusion on integration by parts on a Riemannian manifold,"For two vector fields $X$ and $Y$ on a Riemannian manifold $M$ with metric $g$ , we define $$\langle X, Y \rangle_{L^2} = \int_M g_{ij}X^iY^j dV.$$ I have been unable to find a similar expression for two functions $f,g \in C_0(M)$ . I am guessing that this will just be $$\langle f, g \rangle = \int_M fgdV \tag{1}$$ Why do we not have to take the complex conjugate as in Euclidean space? But if this definition is correct, consider the heat equation: $$\partial_t u - \Delta u = 0$$ so that $u: M \rightarrow \mathbb{R}$ . In these set of notes they state $$\langle \Delta u, u\rangle_{L^2} = \int_M (\Delta u)u d\mu = -\int_M |\nabla u|^2 d\mu \leq 0 \tag{2}$$ where they take $d\mu$ to be the Riemannian measure. Using (1), (2) is obtained from integrating by parts as one usually does on Euclidean space with $\mu$ the Lebesgue measure. Does this just mean we can always treat $dV$ (or $d\mu$ in the notation of the notes) to be some multiple of the Lebesgue measure? If so, what justifies this? If not, what justifies the integration by parts formula as in (2)? Lastly, I have seen the integration by parts formula on a Riemannian manifold (for example, here ) given as $$\int_M \langle \nabla f, X \rangle = -\int_M f div X + \int_{\partial M} f \langle X, \nu \rangle.$$ But what is the relationship between this formula and the integration by parts of scalar functions as in (2)?","['integration', 'measure-theory', 'riemannian-geometry', 'geometric-measure-theory', 'differential-geometry']"
4810688,$\infty-\infty$ indeterminate case,"The methods yield two different answers. Could you explain the reason clearly and in detailed? Question: $$\lim_{{x \to \infty}} \left( \sqrt{x^2 + 6x + 14} - (x+1) \right) = ?$$ Solution: Method 1: By employing the conjugate of the original problem, the solution is as follows: \begin{aligned}
& =\operatorname{lim}_{x \rightarrow \infty}\left[\sqrt{(x+3)^2+5}-(x+1)\right] \\
& =\lim _{x \rightarrow \infty}\left[\sqrt{(x+3)^2 \cdot\left(1+\frac{5}{(x+3)^2}\right)}-(x+1)\right] \\
& =\lim _{x \rightarrow \infty}\left[|x+3| \cdot \sqrt{1+\frac{5}{(x + 3)^2}}-(x+1)\right] \\
& =\lim _{x \rightarrow \infty}[(x+3)-(x+1)]=2
\end{aligned} Method 2: Alternatively, \begin{aligned}
& =\lim_{x \rightarrow \infty}\left[\sqrt{x^2 \cdot\left(1+\frac{6}{x}+\frac{14}{x^2}\right)}-(x+1)\right] \\
& =\lim_{x \rightarrow \infty} \left[|x| \cdot \sqrt{1+\frac{6}{x}+\frac{14 }{x^2}}-(x+1)\right] . \\
& =\lim_{x \rightarrow \infty}[(x)-(x+1)]=-1
\end{aligned} In some books, the authors solve the examples with $\infty-\infty$ indeterminate case by multiplying and dividing the expression by its conjugate in the $\infty-\infty$ indeterminate case. But is it not $\frac{\infty}{\infty}$ ? How can we do it? Please see my other question in this site.","['indeterminate-forms', 'limits']"
4810694,Finding CDF for simulation [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 7 months ago . Improve this question I have the following pdf: $f(x) = 2\alpha e^{-\alpha x} (1 - e^{-\alpha x})$ , $x>0, \alpha>0$ fixed. I need to find the cdf to simulate X. $$F(x)=  \int_{-\infty}^{x}(2\alpha\cdot e^{-\alpha\cdot t})dt= \left ( 1-e^{-\alpha\cdot t} \right )^{2}-\displaystyle \lim_{t \to -\infty} ( 1-e^{-\alpha\cdot t})^{2} = (1-e^{-\alpha\cdot t})^{2}\cdot (1-e^{\infty})^{2} = -\infty$$ Why isn't it finite?","['statistics', 'probability']"
4810712,Growth of distance function near singularity of riemannian metric,"Let $\overline{M}$ be a projective manifold, $D$ is smooth divisor in $\overline{M}$ . Suppose $S$ is the defining section of $D$ , that is $S$ is a nontrivial meromorphic section of the line bundle $[D]$ such that $D=\{S=0\}$ . If we further suppose that $[D]$ is an ample line bundle, then it's direct to compute that $\omega_g=\frac{\sqrt{-1}}{2\pi}\partial\overline{\partial}(-\log\vert|S\vert|^2)^{\frac{n+1}{n}}$ is a Kahler metric on $M=\overline{M}\backslash D$ . The problem is that if we fix a point $x_0\in M$ , then when $x$ is sufficiently close to $D$ , the distance function $r(x)=d(x,x_0)$ is of order $O((-\log\vert|S\vert|^2)^{\frac{n+1}{2n}})$ , where $\vert|\cdot\vert|$ is some Hermitian metric on line bundle $[D]$ . This claim comes from the paper ""Complete Kahler Manifolds with Zero Ricci Curvature"", and I'm confused with this. Although the setting is complex, the problem is essentially Riemannian geometry. As far as I'm concerned, a standard process of caculating the distance function involves finding a geodesic $\gamma(t)$ connecting $x$ and $x_0$ , then use $d(x,x_0)=\int_0^1\vert|\gamma'(t)\vert|dt$ . However, in our setting, it's too complicated to carry out this process since finding a geodesic explicitly is already horrifying. Still the claim does not require a precise formula of distance function, so this may rather be a simple question where I got stuck at some stupid point. Any solution or hint is highly appreciated!","['kahler-manifolds', 'complex-geometry', 'riemannian-geometry', 'differential-geometry']"
4810732,Verify the identity: $\frac{\cos(x)+1}{\sin^3(x)} = \frac{\csc(x)}{1-\cos(x)}$,"How can I prove $$\frac{\cos(x)+1}{\sin^3(x)} = \frac{\csc(x)}{1-\cos(x)}$$ I got up to multiplying the LHS by the conjugate of the denominator and so far have: \begin{align*}
&= \left(\frac{\cos(x)+1}{\sin^3(x)}\right)\left(\frac{1-\cos(x)}{1-\cos(x)}\right)\\  
&= \frac{\cos(x)-\cos^2(x)+1-\cos(x)}{\sin^3(x)(1-\cos(x))}\\ 
&= \frac{\sin^2(x)}{\sin^3(x)(1-\cos(x))}\\
&= \frac{1}{\sin(x)(1-\cos(x))} 
\end{align*} I don't know where to go from here","['trigonometry', 'calculus', 'algebra-precalculus']"
4810755,Geometry problem where rectangle ABCD provides area of small rectangles,"On the rectangle $ABCD$ , two points $M$ and $N$ have been marked on the sides $AB$ and $BC$ respectively. The rectangle has lines drawn between $AN$ , $ND$ , $MC$ , $MD$ . It forms many different areas, many of which are triangles. A triangle is formed in the lower left corner that has points $A$ , $M$ and the point where the line $AN$ intersects $MD$ (call that point $E$ ). That triangle has area $3$ . Another triangle is formed in the upper left corner. It has points $C$ , $N$ and the point where the line $ND$ intersects $CM$ (call that point $F$ ). That triangle has area $2$ . A quadrilateral is formed in the lower right corner. It has points $M$ , $B$ , $N$ and the point where the line $MC$ intersects $AN$ (call that point $G$ ). That quadrilateral has an area of ​​ $20$ . The goal of the assignment is to find the area of the quadrilateral $DEGF$ . You best understand the assignment when looking at it on paper, so I attached a image down below. This question is from a high school entrance exam in Sweden. I have tried to match triangles to each other with no success. I can guess that you would need a giant expression with a bunch of variables which eventually cancel out to get an answer, but I have gotten no success from that path. I also assume that you would need to figure out the length of AB and BC to solve the question. I have also looked at geometric identities but have gotten no success, and found none that seems relevant to the question.","['problem-solving', 'geometry']"
4810756,Can nonisomorphic groups have near-identical Cayley tables?,"Nonisomorphic groups can have very similar multiplication (Cayley) tables. For example, the two groups \begin{align*}
\mathbb{Z}/9\mathbb{Z}&=\{\overset{a}{0},\overset{b}{1},\overset{c}{2},\overset{d}{3},\overset{e}{4},\overset{f}{5},\overset{g}{6},\overset{h}{7},\overset{i}{8}\}\\
\mathbb{Z}/3\mathbb{Z}\times\mathbb{Z}/3\mathbb{Z}&=\{\underset{a}{(0,0)},\underset{b}{(0,1)},\underset{i}{(0,2)},\underset{d}{(1,0)},\underset{e}{(1,1)},\underset{c}{(1,2)},\underset{g}{(2,0)},\underset{h}{(2,1)},\underset{f}{(2,2)}\}
\end{align*} have multiplication (Cayley) tables \begin{array}{r|ccccccccc}
\mathbb{Z}/9\mathbb{Z}&a&b&c&d&e&f&g&h&i\\\hline
a&a&b&c&d&e&f&g&h&i\\
b&b&c&d&e&f&g&h&i&a\\
c&c&d&e&f&g&h&i&a&b\\
d&d&e&f&g&h&i&a&b&c\\
e&e&f&g&h&i&a&b&c&d\\
f&f&g&h&i&a&b&c&d&e\\
g&g&h&i&a&b&c&d&e&f\\
h&h&i&a&b&c&d&e&f&g\\
i&i&a&b&c&d&e&f&g&h\\
\end{array} and \begin{array}{r|ccccccccc}
\mathbb{Z}/3\mathbb{Z}\times\mathbb{Z}/3\mathbb{Z}&a&b&c&d&e&f&g&h&i\\\hline
a&a&b&c&d&e&f&g&h&i\\
b&b&\boxed{i}&d&e&\boxed{c}&g&h&\boxed{f}&a\\
c&c&d&\boxed{h}&f&g&\boxed{b}&i&a&\boxed{e}\\
d&d&e&f&g&h&i&a&b&c\\
e&e&\boxed{c}&g&h&\boxed{f}&a&b&\boxed{i}&d\\
f&f&g&\boxed{b}&i&a&\boxed{e}&c&d&\boxed{h}\\
g&g&h&i&a&b&c&d&e&f\\
h&h&\boxed{f}&a&b&\boxed{i}&d&e&\boxed{c}&g\\
i&i&a&\boxed{e}&c&d&\boxed{h}&f&g&\boxed{b}\\
\end{array} respectively (note the boxed elements are different). The proportion of different elements between these two tables is $\frac{18}{9\times 9}=\frac{2}{9}\approx 22.2\%$ . Given a finite group $G=\{g_1\ldots g_n\}$ with a fixed enumeration of its elements, we define its multiplication table to be the unique matrix $M_G\in\{1\ldots n\}^{n\times n}$ such that for all $i,j\le n$ , if $k=(M_G)_{ij}$ then $g_i\cdot g_j=g_k$ . Question. Given $\varepsilon=\frac{1}{1000}$ , does there exist two finite groups $G=\{g_1\ldots g_n\},H=\{h_1\ldots h_n\}$ with multiplication tables $M_G,M_H$ , such that for all but at most $\varepsilon n^2$ many pairs $(i,j)\in\{1\ldots n\}^2$ , it holds that $(M_G)_{ij}=(M_H)_{ij}$ , and $G\not\cong H$ ? Thanks for your help.","['finite-groups', 'cayley-table', 'abstract-algebra', 'combinatorics', 'group-theory']"
4810768,How to calculate probabilities in a Poisson process with exponential lifetime of arrivals?,"I have a Poisson process where people arrive at the rate of $λ$ --  so when an event occurs, a new person arrives.  This means that the times between successive arrivals are $T_i$ ~ Exponential $(\lambda)$ . And the lifetime of each person is independent Exponential $(μ)$ .  That is, $L$ ~ Exponential $(\mu)$ . Further, let $M(t)$ be the number of people at time $t$ . Suppose at time $t$ , we just have $1$ person. I am trying to calculate the probability that there will be no people remaining when this $1$ person dies. My attempt until now is as follows: $P($ there will be no people remaining when this $1$ person dies $)$ $=$ $P($ no new person arrives during the lifetime of this $1$ person $)$ $+$ $P($ someone or more than one person arrives after time $t$ and dies within the lifetime of this $1$ person $)$ $=$ $P(L < T)$ $+$ $P($ one or more than one person arrives after time $t$ and dies before this $1$ person dies $)$ I calculated that $P($$L < T$$)$ $=$ $\frac{\mu}{\mu  +  \lambda}$ , because $L$ ~ Exponential $(\mu)$ , and $T$ ~ Exponential $(\lambda)$ . Now, I am trying to calculate: $P($ one or more than one person arrives after time $t$ and dies before this $1$ person dies $)$ Could someone please point me to how I can find this probability?  Thank you very much!","['poisson-distribution', 'stochastic-processes', 'probability-theory', 'probability', 'random-variables']"
4810776,What is the probability that $X+Y$ and $X$ are both greater than $0$? $X$ and $Y$ are both normal standard gaussian.,"The question gives me: $X,Y\sim N(0,1)$ iid. I also know that $X+Y\sim N(0,2)$ because it is a sum of normal random variables.
From my understanding, the sum and $X$ are not indepedent therefore the way to solve would be to rephrase it like this: $$P(X>0\text{ and }X+Y>0) = P(X+Y>0|X>0)*P(X>0).$$ I know that $P(X>0) = 0.5$ and that I can rewrite the first probability as: $P(Y>-x|X=x,x>0) = 1-P(Y<-x)$ .
But all this still depends on x, which I suppose should be removed somehow. I thought of integrating over all possible values of $X$ the cdf of the normal, but it seemed too many calculations for a simple question. How can I solve this in a simpler way?","['normal-distribution', 'probability', 'random-variables']"
4810780,"Is an Archimedean topological group of the reals isomorphic to $(\mathbb R,+)$?","A group $H:=(\mathbb R,\boxplus)$ , is given to be Ordered as per the canonical order of $\mathbb R$ . Archimedean as per order in 1. Topological as per canonical topology of $\mathbb R$ . Can it be deduced that $H$ is group isomorphic to $(\mathbb R,+)$ ? If not, what additional properties would be sufficient? I have found that, by a theorem of Hölder, any Archimedean group is group isomorphic to a subgroup of $(\mathbb R, +)$ . Hence the question above reduces to whether, as a result of the fact that the set itself is $\mathbb R$ and $H$ topological, the case of $H$ being isomorphic to a proper subgroup of $(\mathbb R,+)$ can be excluded.","['ordered-groups', 'group-theory', 'topological-groups']"
4810807,Blow up and hyperelliptic curves.,"Let $C'$ be a non singular affine curve $y^2=x^5+3$ over $\mathbb{C}$ . $C'^\#$ be its projective closure : $Y^2Z^3=X^5+3Z^5$ . It has singular point at $\mathcal{O}'=(0:1:0)$ . On the other hand, let $C$ be a hyperelliptic curve whose affine part is $C’$ i.e. $C=C'\cup_{\phi} \tilde{C'}$ (gluing curve) where $\tilde{C'}$ is an affine curve defined by $y^2=x(1+3x^5)$ and $\phi:C'\dashrightarrow \tilde{C'}$ is a rational map such that $(x,y)\mapsto (1/x,y/x^3)$ . Question: Now, let $C’’$ be a affine part of $C'^\#$ defined by $Y=1$ (i.e. $C’’:z_{2/1}^3=x_{0/1}^5+3z_{2/1}^5$ where $x_{0/1}:=X/Y, z_{2/1}:=Z/Y$ ), I want to check the blow up of $C’’$ at $\mathcal{O}=(0,0)$ will be $C$ . How do I do? My computation: Take a blow up of the affine plane $\mathbb{A}_{(x_{0/1},z_{2/1})}$ of its coordinate is $(x_{0/1},z_{2/1})$ : $\pi:Bl_{\mathcal{O}}(\mathbb{A}_{(x_{0/1},z_{2/1})})\to\mathbb{A}_{(x_{0/1},z_{2/1})}$ Now let the coordinates of affine parts of $Bl_{\mathcal{O}}(\mathbb{A}_{(x_{0/1},z_{2/1})})$ are $\mathbb{A}_{(x_{0/1},u)}$ and $\mathbb{A}_{(v,z_{2/1})}$ (then $z _{2/1} =ux _{0/1}, v=1/u$ ). Then the strict transforms of $C’’$ in $\mathbb{A}_{(x_{0/1},u)}$ , $\mathbb{A}_{(v,z_{2/1})}$ are $\pi^{-1}[C’’]_0: u^3=x_{0/1}^2+3u^5x_{0/1}^2$ , $\pi^{-1}[C’’]_1: 1=v^5z_{2/1}^2+3z_{2/1}^2$ . There exists a rational map $\psi:\pi^{-1}[C’’]_0\dashrightarrow \pi^{-1}[C’’]_1; (x_{0/1},u)\mapsto (ux_{0/1},1/u)$ and we have the blow up $Bl_{\mathcal{O}}(C’’)=\pi^{-1}[C’’]_0\cup_{\psi} \pi^{-1}[C’’]_1$ .","['algebraic-curves', 'algebraic-geometry', 'blowup', 'elliptic-curves']"
4810860,Why does the cartesian product of two two-dimensional figures lie in the three-dimensional space?,"So, here is the question. Assume we have two circles. They lie in the two-dimensional space. The cartesian product of the sets representing two circles consists of 4-tuples, and thus, one may expect a geometric representation of that set in the fourth-dimensional space. Indeed, one may consider the cartesian product of a line (one-dimensional space) and a circle (two-dimensional space) as a cylindrical surface (one plus two, thus three-dimensional space). However, for two circles, one may come up with the torus representation, which seems intuitively reasonable. So, what makes two circles special in this case, and is there a general rule which allows us to determine whether there is a representation in a space of a lower dimension than the sum dimension? P.S. I'm not sure about the tags. Sorry if they're misleading.","['general-topology', 'geometry']"
4810918,Can't use Stolz - Cesaro theorem because the condition that the limit exists can't be proven,"So I found this question: If $\lim_{n \to \infty} \frac{c_{n+1}}{n \cdot c_n} = a$ then prove that $\lim_{n \to \infty} \sqrt[n+1]{c_{n+1}} - \sqrt[n]{c_n} = \frac{a}{e}$ Now I used the Stolz - Cesaro theorem to prove this by the following method: Let $a_{n+1} = \sqrt[n+1]{c_{n+1}}$ and $b_{n+1} = n+1$ Thus $\lim_{n \to \infty} \sqrt[n+1]{c_{n+1}} - \sqrt[n]{c_n} = \frac{a_{n+1}-a_n}{b_{n+1}-b_n} = \frac{a_n}{b_n} = \frac{\sqrt[n]{c_n}}{n} = \sqrt[n]{\frac{c_n}{n^n}}$ Let $x_n = \frac{c_n}{n^n}$ then using the converse of the geometric mean case of Stolz - Cesaro theorem $(\lim_{n \to \infty} \sqrt[n]y_n = L \implies \lim_{n \to \infty}\frac{y_{n+1}}{y_n} = L$ ) we get $\sqrt[n]{\frac{c_n}{n^n}} = \frac {c_{n+1} \cdot n^n}{c_n \cdot (n+1)^{n+1}} = \frac {c_{n+1}}{n \cdot c_n} \cdot \frac{1}{(1 + \frac{1}{n})^{n+1}}$ I don't know if the converse of the multiplicative identity of the Stolz - Cesaro theorem can be used or not but I could not find another way to solve this question. Can you also tell me if the converse of the multiplicative identity of the Stolz - Cesaro theorem exists here ? we know $(1 + \frac{1}{n})^n = (1 + \frac{1}{n})^{n+1} = e\;\&\;(\lim_{n \to \infty} (1+\frac{1}{n}) → 1)$ and it is given that $\frac {c_{n+1}}{n \cdot c_n} = a$ So we get that $\lim_{n \to \infty} \sqrt[n+1]{c_{n+1}} - \sqrt[n]{c_n} = \frac{a}{e}$ Obviously the problem (ignoring the usage of the converse of the multiplicative identity of the Stolz - Cesaro theorem) is we have to prove that $\frac{a_{n+1}-a_n}{b_{n+1}-b_n}$ exists to use Stolz - Cesaro theorem but I cannot find a way to prove how to do it, I just can't get where to start to prove that it exists. It intuitively looks like it should exist. So my question is : can we prove that it exists and if not, then how would we legitimately solve this question? P.S. : I saw this question but that solution has a different approach and also my doubt is a little different because I want to use the method stated above. To prove that, we had to prove that $\lim_{n \to \infty} \sqrt[n+1]{c_{n+1}} - \sqrt[n]{c_n}$ exists first which I am not able to do.","['limits', 'calculus', 'linear-algebra', 'real-analysis']"
4810957,Simple but nontrivial trichotomous relation that isn’t a strict total order?,"A binary relation $R$ over a set $A$ is a strict order if it’s irreflexive, asymmetric, and transitive. It’s trichotomous if for every $a, b \in A$ exactly one of $xRy$ , $yRx$ , and $x = y$ is true. It’s a strict total order if it’s both trichotomous and a strict order. I’ve been teaching a discrete math class for years and have been looking without success for a simple example of a binary relation that is trichotomous but not a strict total order. None of the “nice” trichotomous binary relations I’ve tried fit the bill, and the best I’m able to do is draw a picture of an example of such a relation and say “this works, but there isn’t a simple explanation for the rule defining $R$ other than this picture.” Is there a simple way to define a trichotomous relation $R$ over a set $A$ such that the definition of $R$ is “simple” (e.g. accessible to a first-quarter college freshman with no prior experience with proof-based mathematics), the definition is given symbolically (e.g. not a picture), the relation $R$ isn’t a strict total order, and (ideally) $A$ is a large set, or there’s a family or such relations over arbitrarily large sets? Thanks!","['order-theory', 'discrete-mathematics']"
4810960,How can I calculate this integral? $ \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^c \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x$,"I know how to calculate this: $
\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^\infty \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x=\Phi\left(\frac{b}{\sqrt{1+a^2}}\right)$ but i am struggling with this: $
\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^c \Phi(a x+b) \exp \left(-\frac{x^2}{2}\right) d x=\Phi_2\left(\frac{b}{\sqrt{1+a^2}}, c ;-\frac{a}{\sqrt{1+a^2}}\right)$ . where $\Phi_2\left(\cdot, \cdot ;\rho \right)$ is the bivariate cummulative Gaussian distribution with correlation $\rho$ . Can anyone help me?","['integration', 'normal-distribution', 'probability']"
4810976,Diagonal in the power of a group,"Let $L$ be a simple group and $G=L^t$ . The diagonal $D=\lbrace(x,x,\ldots,x), x\in L\rbrace$ is a subgroup of $L^t$ . I can prove that if $D$ is maximal then $t$ is a prime. If $t=mn$ then the subgroup $\lbrace (x_1,\ldots,x_1,x_2,\ldots,x_2,\ldots,x_n,\ldots,x_n), x_i\in L\rbrace$ properly contains the diagonal. Hence if $D$ is maximal then $t$ is a prime. I can not prove the converse, namely if $D$ is a maximal subgroup of $L^p$ provided $p$ prime. For $p=2$ the statement holds. EDIT The problem that generated the previous question is the following: let $L$ be a simple group and $p$ be prime. The cyclic group with $p$ elements $\mathbb{Z}_p$ acts on $L^p$ by cycling the components, i.e. $$a\cdot (x_1,x_2,\ldots, x_p)=(x_p,x_1,x_2,\ldots,x_{p-1})$$ where $a$ is a generator of the cyclic group. We can then build the semidirect product $G=L^p\rtimes \mathbb{Z}_p$ defined by the action above. The centralizer of $(1,1,\ldots,1,a)$ in $G$ is $$C=\lbrace(x,\ldots,x,a^n), x\in L, n\in \mathbb{N}\rbrace.$$ The question is: when is $C$ a maximal subgroup of $G$ ? In particular, if the diagonal $D$ is maximal in $L^t$ then $C$ is maximal in $G$ , but I am not sure that the converse hold (so the two questions are not equivalent).","['group-theory', 'simple-groups']"
4811003,Can one compute the location of the unseen point?,"My question is quite simple. I have two images, on the first one I know the location of points $P1, P2, P3$ , and $P4$ . In the second image, I know the location of $P2'$ , $P3'$ , $P4'$ , and point $Q'$ . Is there any way I could find the exact location of point $Q$ on the first image? Edit I have prepared a gist to replicate this problem in Python: gist . I think this is a mathematical challenge, and I'm seeking a solution for my project in which I'm creating a CV application to correlate points between two sheets of paper. Indeed, a perspective transform would solve the issue but unfortunately, in image 2, I don't know the location of $P1'$ . Also, I don't have access to the camera calibration parameters such as the focal length. What I know is that it's a DIN A4 in 3D world and I know its dimensions in millimeters. I also know that is a rectangle that, due to the perspective, the angles are not $90\deg$ on the projected image (on the screen). I have tried to work with affine transformations but it's not leading me closer to the solution, as the weak perspective is not working accurately enough. As an example, let's say that the location of the points, measured on the first image, are: $P1 (2498, 3169)$ $P2 (521, 3199)$ $P3 (681, 762)$ $P4 (2290, 776)$ . On the second image are: $P2' (2209, 1009)$ $P3' (2634, 2908)$ $P4' (271, 2870)$ $Q' (1368, 2096)$ For reference, both of the images are $4032x3024$ pixels. So the center would be at $C=(2016,1512)$ . I grabbed all the points myself manually and the solution I got for $Q$ is $(1581,1405)$ .","['triangulation', 'projection', 'geometry', '3d']"
4811006,Simulate a random variable from given PDF,"Let $f(x) = \begin{cases} 
\frac{1}{a}\log(\frac{a}{x}), & \text{if } 0 < x < a \\
0,& x \notin(0,a)
\end{cases}$ , $a \text{ fixed}$ I want to generate a random variable $X \sim f(x)$ , where $f(x)$ is the PDF. I tried with inverse method but no result (transcedental equation). I want to try rejection method now, but suppose that I let $Y \sim \operatorname{Uniform}(0,a) \implies g(x) = \frac{1}{a}, x\in(0,a)$ is the density of $Y$ . Now when I want to find the constant $c \ge \frac{f(x)}{g(x)} \forall x\in(0,1)$ I can't because $\frac{f(x)}{g(x)}$ is unbounded close to $0$ . So ... how I can simulate a random variable $X \sim f(x)$ ? Thanks!","['statistics', 'probability']"
4811017,"How to find the ""sum"" of two parametric curves?","Given two parametric 2D curves: $c_1=[x_1(a),y_1(a)], \text{ for } a\in[0,1]$ $c_2=[x_2(b),y_2(b)], \text{ for } b\in[0,1]$ I want to find the ""sum"" of these curves, which I define as the points $[x,y]$ for which there exists $a,b$ such that $x=x_1(a)+x_2(b)$ $y = y_1(a) = y_2(b)$ . I suspect the result should also be a curve, since there is only one degree of freedom given the constraint $2$ ). I approached this by brute-forcing it, checking all points $[a,b]$ in a grid and keeping those that satisfy constraint $2$ ) (with a given margin), and indeed the result $[x,y]$ looks like a curve (see example below, where the right curve shows the ""sum"" of the two curves on the left). However, extending this to more input curves becomes computationally expensive, since each new curve would add a new dimension to the grid. Notice that it is impossible to add curves sequentially in this way, since the result is a list of sparse points, instead of a parametric curve. This question has a physical origin: if two physical systems with a non-linear relationship between parameters (e.g., pressure and temperature) are connected in such a way that one of the parameters must be the same in both, what would be the resulting curve for the total system? Would you know of any more efficient way to get the resulting curve? Or any other way this could be extended to more input curves in an efficient way?","['curves', 'multivariable-calculus', 'geometry', 'computational-geometry']"
4811036,Existence of a weak-star limit of a family of operators in $B(\mathcal{H})$,"Thank you in advance for reading this question, and your thoughts. I am working with a family of operators $(A_{s,\alpha})_{s\geq 0,\alpha>0}$ in the space $B(\mathcal{H})$ (the space of bounded linear operators on a complex separable Hilbert space $\mathcal{H}$ ) depending on two parameters $s\geq 0$ and $\alpha>0$ . This family is such that for fixed $\alpha>0$ , the mapping $[0,\infty)\ni s\mapsto A_{s,\alpha}\in B(\mathcal{H})$ is a strongly continuous semigroup , and $$(\star)\quad \forall\, s>0,\,\forall\, \alpha>0:\quad \big|\big|A_{s,\alpha}\big|\big|_{B(\mathcal{H}}\leq 1\,, $$ i.e. the family of operators $(A_{s,\alpha})_{s\geq 0,\alpha>0}$ lives in the norm-closed unit ball of $B(\mathcal{H})$ .
Next, the pre-dual of $B(\mathcal{H})$ (up to isometric isomorphism)  is $B_1(\mathcal{H})$ , the trace-class operators on $\mathcal{H}$ . This defines a weak-star topology on $B(\mathcal{H})$ , and by the  Banach-Alaoglu theorem, the norm-closed unit ball of $B(\mathcal{H})$ is weak-star compact. Question 1: I think that since $\mathcal{H}$ is separable, it follows that $B_1(\mathcal{H})$ is separable, and hence the norm-closed unit ball of $B(\mathcal{H})$ is weak-star sequentially compact? Next, assuming an affirmative answer to Question 1 , let us fix an arbitrary sequence $\alpha_n\to 0^+$ .  Then for any fixed $s\geq 0$ , $(\star)$ above implies   the sequence of operators $(A_{s,\alpha_n})_{n\in \mathbb{N}}$ has a weak-star convergent subsequence $(A_{s,\alpha_{n_k}})_{k\in \mathbb{N}}$ . Unfortunately , however, this subsequence may depend on the particular $s\geq 0$ . Question 2: Is it possible to show that there exists a subsequence $(\alpha_{n_j})_{j\in \mathbb{N}}$ of the above $\alpha_n\to 0^+$ so that for all $s\geq 0$ the sequence of operators $(A_{s,\alpha_{n_j}})_{j\in \mathbb{N}}$ converges in the weak-star topology in $B(\mathcal{H})$ ? If not, are there some ""natural"" assumptions one can make on the $\alpha$ -dependence of the operators such that this works?","['operator-algebras', 'operator-theory', 'weak-topology', 'functional-analysis', 'semigroup-of-operators']"
4811057,Smoothening a continuous piecewiese smooth function on $\mathbb R$ around one point only?,"Let $f:\mathbb R \to \mathbb R$ be a continuous function and smooth on $(-\infty,0)$ and $(0,+\infty)$ respectively. For any $\epsilon>0, a>0$ , can we always find a smooth function $g:\mathbb R \to \mathbb R$ such that $g|_{\mathbb R\backslash (-a,a)}=f$ and the uniform norm $\|g-f\|_{\mathbb R}<\epsilon$ ? Is there an explicit construction (I am okay with abtract non-constructive proof, though)? I am aware of https://en.wikipedia.org/wiki/Mollifier , but the convolution there changes $f$ globally not locally.","['calculus', 'functions', 'real-analysis']"
4811062,Tangent Bundle of a smooth manifold with boundary,"This is exercise 3.19 from John Lee's Introduction to Smooth Manifolds that I can't quite prove. Suppose $M$ is a smooth manifold with boundary. Show that $TM$ has a natural topology and smooth structure making it into a smooth manifold with boundary, such that if $(U,(x^i))$ is any choundary chart for $M$ , then rearranging the coordinates in the natural chart $(\pi^{-1}(U),(x^i,v^i))$ for $TM$ yields a boundary chart $(\pi^{-1}(U),(v^i,x^i))$ . For interior charts we define the chart as given an interior chart $(U,\phi)$ for $M$ , since $\pi^{-1}(U) \subset TM$ is the set of all tangent vectors to $M$ at all points of $U$ , and letting $(x^1, \dots, x^n)$ denote the coordinate functions of $\phi$ , we can define a map $\tilde{\phi}:\pi^{-1}(U)\to \mathbb{R}^{2n}$ by $$\tilde{\phi}(v^i\frac{\partial}{\partial x^i}|_p)=(x^1(p),\dots, x^n(p), v^1, \dots, v^n).$$ Its image set is $\phi(U)\times \mathbb{R}^n$ which is an open subset of $\mathbb{R}^{2n}$ , and is a bijection onto its image where its inverse is $$\tilde{\phi}^{-1}(x^1,\dots, x^n, v^1, \dots, v^n)=v^i \frac{\partial}{\partial x^i}|_{\phi^{-1}(x)}.$$ Then smooth compatibility given two smooth charts $(U,\varphi)$ and $(V,\psi)$ for $M$ , we have the transition map $\tilde{\psi}\circ \tilde{\varphi}^{-1}:\varphi(U \cap V)\times \mathbb{R}^n \to \psi(U\cap V) \times \mathbb{R}^n$ written as $$\tilde{\psi} \circ \tilde{\varphi}^{-1}(x^1, \dots, x^n, v^1, \dots, v^n)=(\tilde{x}^1(x),\dots \tilde{x}^n(x), \frac{\partial \tilde{x}^1}{\partial x^j}(x)v^j,\frac{\partial \tilde{x}^n}{\partial x^j}(x)v^j)$$ which is clearly smooth. The problem I have is establishing smooth compatibility between interior charts and boundary charts. By the Smooth Manifold Chart Lemma (Lemma 1.35), we need to show that whenever $\pi^{-1}(U)$ and $\pi^{-1}(V)$ intersect, the map $\tilde{\psi} \circ \tilde{\varphi}^{-1}$ is smooth. If we take the transition of two boundary charts as suggested by rearranging the order of $v^i$ and $x^i$ , we would get the same kind of equation as above with just a rearrangement and the final component will be in the half plane $\mathbb{H}^n=\{x: (x)_n \ge 0\}$ . However, how do we ensure smooth compatibility for interior and boundary charts, i.e. the case where $\psi$ is a boundary chart and $\varphi$ is an interior chart and vice versa? I think this can be resolved by the invariance theorem of boundary. So $U\cap V$ can only be interior or boundary domain but not both. So in the case where $(U,\phi)$ is an interior chart and $(V,\psi)$ is a boundary chart, $U\cap V$ cannot contain boundary points, so the transition map $\tilde{\psi} \circ \tilde{\phi}^{-1}(x^1, \dots, x^n, v^1, \dots , v^n)=(\frac{\partial \tilde{x}^1}{\partial x^j}(x)v^j,\dots, \frac{\partial \tilde{x}^n}{\partial x^j}(x)v^j, \tilde{x}^1(x),\dots, \tilde{x}^n(x))$ , and $\tilde{\phi} \circ \tilde{\psi}^{-1}(v^1, \dots , v^n, \tilde{x}^1, \dots, \tilde{x}^n,)=(x^1(\tilde{x}),\dots, x^n(\tilde{x}), \frac{\partial x^1}{\partial \tilde{x}^j}(\tilde{x})v^j,\dots, \frac{\partial x^n}{\partial \tilde{x}^j}(\tilde{x})v^j)$ which are smooth as maps with domain and codomain contained in $\mathbb{R}^{2n}$ and the first transition is just a rearrangement of the case with two interior charts.","['manifolds', 'multivariable-calculus', 'smooth-manifolds', 'differential-geometry']"
4811064,Is $\mathbb{A}^{n+1}_\mathbb{C}\setminus \{0\} \to \mathbb{P}^n_\mathbb{C}$ a closed morphism?,"I have already proved that the projection map $p \colon \mathbb{A}^{n+1}_\mathbb{C}\setminus \{0\} \to \mathbb{P}^n_\mathbb{C}$ given by $(x_0,x_1,..x_n) \rightarrow [x_0,x_1,..,x_n]$ is a morphism. But a further question arises that whether this morphism is closed, i.e. it maps closed sets to closed sets (assuming equipped with Zariski topology). The answer is negative, as Daniel Schepler has pointed out. Moreover, this exercise is followed by another one, asking whether $\mathbb{C}^{n+1} \setminus \left\{ 0 \right\}$ is isomorphic to $\mathbb{P}^n \times \left( \mathbb{C} \setminus \left\{ 0 \right\} \right)$ . Is there any correlation between these two problems? Any advice is welcomed and appreciated.","['projective-varieties', 'algebraic-geometry', 'projective-space']"
4811146,If $\mathbb{E}(|X_1|)=\infty$ then a.s. $X_n/n$ does not tend to 0.,"Let $(X_n)_{n \geq 1}$ be i.i.d. real random variables. Then my prof. wrote: „If $\mathbb{E}(|X_1|)=\infty$ then a.s. $X_n/n$ does not tend to 0“ I’m not so comfortable with probability notation so far so I‘m using the notation from measure theory. I interpret the statement as: $$
\mathbb{E}(|X_1|)= \infty \Rightarrow  \mathbb{P}(\lim_{n \rightarrow \infty} X_n/n = 0) = 0
$$ Is this correct so far? Then I tried to prove it: \begin{equation}
        \infty = \mathbb{E}(|X_n|)= \int_{0}^{\infty} \mathbb{P}(|X_1| \geq t) \ dt = \sum_{n=0}^{\infty} \int_{n}^{n+1} \mathbb{P}(|X_n|/ \geq t) \ dt \leq \sum_{n=0}^{\infty}  \mathbb{P}(|X_n| \geq n)
    \end{equation} Since the $|X_n|$ are still i.i.d. by the second Borel-Cantelli Lemma we get: \begin{equation}
    \lim_{n \rightarrow \infty } \mathbb{P}\left( \{\omega \ : \ |X_n|\geq n\}\right)=\lim_{n \rightarrow \infty } \mathbb{P}\left( \bigcup_{m=n}^{\infty} \{\omega \ : \ |X_m|\geq m\}\right) =\mathbb{P}\left(\bigcap_{n=1}^{\infty} \bigcup_{m=n}^{\infty} \{\omega \ : \ |X_m|\geq m\}\right) = 1
\end{equation} Thus: \begin{equation}
    \lim_{n \rightarrow \infty } \mathbb{P}\left( \{\omega \ : \ |X_n|/n\geq 1\}\right) = 1
\end{equation} Hence for all $\varepsilon > 0$ there is a $N$ s.t. for all $n > N$ we have: $|\mathbb{P}\left( \{\omega \ : \ |X_n|/n\geq 1\}\right) - 1|< \varepsilon$ i.e. $|\mathbb{P}\left( \{\omega \ : \ |X_n|/n = 0\} \right) | \leq |\mathbb{P}\left( \{\omega \ : \ |X_n|/n < 1\} \right) |< \varepsilon$ , i.e. \begin{equation}
      \lim_{n \rightarrow \infty } \mathbb{P}\left( \{\omega \ : \ |X_n|/n = 0\}\right) = 0
\end{equation} But I‘m still not at: $$
\mathbb{P}(\lim_{n \rightarrow \infty} X_n/n = 0) = 0
$$ Could someone show me how to get there, or show me a faster way? Thank you!:)","['measure-theory', 'probability-theory', 'probability', 'random-variables']"
4811175,Expected amount of items with weight probabilities,"Suppose, you have a box $B$ with $n$ items and you pull $k<n$ items out of it. Items have different sizes $s_i$ , with larger items being more probable to get pulled out: $$p(i) = \frac{s_i}{\sum_{\forall j\in B}{s_j}}$$ What's the expected chance an item $i$ will be among the $k$ items you will have pulled out of the box? Is there some way to do it more easily than by bruteforcing the tree of probabilities?","['combinatorics', 'probability-theory', 'probability']"
4811204,Is the cardinality of an infinite set correlated with the amount of information needed to specify any one element?,"I was thinking about the fact that some infinities are 'bigger' than others. For example, the cardinality of the reals is literally bigger than the cardinality of the rationals. One cannot match them one-to-one. Georg Cantor proved this several times. But if I look at the infinities and the items they contain, I noticed a pattern. Aleph-0 is the infinity of the rational numbers. Any rational number is either terminating or repeating. To store any given rational finite number, one would need a finite amount of information. No matter how precise, the precision would be finite, and thus could be representable in a finite amount of information (bits, digits, etc). But then if I look at the power set of Aleph-0 which is has the cardinality of the reals, to specify any given element from any other requires infinite information. An infinite number of bits is required to name any given irrational number. However, the amount of information needed to name any one element of an uncountable set is infinite, but countable . Each digit of pi corresponds to a natural number. So if I extend this, to, say, the power set of the set of the real numbers, would that mean, to specify any given element, I would need an uncountable amount of information? There would be no digits in order that could possibly name any given element in the set, even given an infinite number of them? In summary, is my assumption correct that for any one of the infinity infinite sets of differing sizes, to single out any one element, would require an amount of information equal to the previous smaller infinity?","['elementary-set-theory', 'infinity']"
4811207,"Does there exists a quadratic extension $L$ of $K$, in which $p_1,p_2,\ldots,p_n$ ramifies in $L/K$?","Let $K$ be a number field. For arbitrarily fixed positive integer $n$ , fix $p_1,p_2,\ldots,p_n$ be a  prime elements of ring of integers of $K$ . Does there exists a quadratic extension $L$ of $K$ , in which $p_1,p_2,\ldots,p_n$ ramifies in $L/K$ ? My try: From Dedekind's Discriminant theorem , we need to find $L/K$ : quadratic such that all $p_i$ divides relative discriminant $\Delta_{L/K}$ . In the case $K=\Bbb{Q}$ , Let $D=p_1p_2\cdots p_n$ , then, $\Delta_{L/K}$ is $D$ or $4D$ , thus $L=K(D)$ is enough in this case. But in the case $K$ is not $\Bbb{Q}$ , I'm stucking with how to find $L/K$ : quadratic such that all $p_i$ divides $\Delta(L/K)$ because in this case, $\Delta{L/K}$ is not just $p_1・・・p_n$ . I'm stucking with calculating $\Delta(L/K)$ . If there are any book or pdf dealing with this proposition, I would also welcome any references. Thank you in advance.","['algebraic-number-theory', 'ramification', 'number-theory', 'galois-theory', 'abstract-algebra']"
4811224,Does this pattern for the order of $2$ modulo a power of a prime always hold?,"I know that the order of $2$ modulo $7$ is $3$ , the order of $2$ modulo $7^2$ is $3 \cdot 7$ , and the order of $2$ modulo $7^3$ is $3 \cdot 7^2$ . In general, is it valid to say that if $p$ is a prime and the order of $2$ modulo $p$ is $q$ , then the order of $2$ modulo $p^n$ is $q \cdot p^{n-1}$ ?","['group-theory', 'modular-arithmetic']"
4811228,Prove that $nS_{tt}(\sum_{i=1}^nc_i^2)\geq \sum_{i=1}^nt_i^2$,"Let $c_1,\cdots, c_n,t_1,\cdots,t_n\in\mathbb{R}$ such that $\sum_{i=1}^nc_it_i=0$ and $\sum_{i=1}^nc_i=1$ . Suppose that there're $i,j$ such that $t_i\neq t_j$ . Prove that $nS_{tt}(\sum_{i=1}^nc_i^2)\geq \sum_{i=1}^nt_i^2$ with $S_{tt}:=\sum_{i=1}^n(t_i-\overline t)^2$ and $\overline t:=(\sum_{i=1}^nt_i)/n$ . I know that $\sum_{i=1}^nt_i^2=S_{tt}+n(\overline t)^2$ and I tried to use Cauchy-Schwartz to prove that inequality, however I failed. Please help me to prove that inequality EDIT: That inequality is related to the fact that among the unbiased linear estimators of $\alpha$ in simple regression analysis the least square estimator $\hat\alpha$ is the one of minimum variance.So that inequality is expected to attain its minimum when $c_i=\frac{S_{tt}-n\overline t(t_i-\overline t)}{nS_{tt}}$ for all $i=1,\cdots,n$","['statistics', 'inequality']"
4811267,Showing Sum of Normal Random Variables More than Additive,"Hopefully this is a quick question. I am not a statistician, so I would like to just make sure that I am approaching this problem correctly. I have some data that I am working with which is meant to monitor cell death and I am trying to compare the effects of different treatments on the cells. Since the research is proprietary, I cannot give the full details here, but I will give an example. I am monitoring cell death in response to stimuli. My control group contains 39 samples and is normally distributed with a mean death percentage of 0.05 and a variance $\sigma^2$ of 0.001. My first sample of size 37 is given treatment X has an approximately normal distribution with a mean death percentage of 0.1 and a variance $\sigma^2$ of 0.04. Likewise, the 43 cells given treatment Y have a death percentage of 0.18 and variance of 0.09. Lastly, the sample containing treatments X and Y with size 34 has a mean death percentage of 0.54 with a variance of 0.16. My question is then how do I show that the effect of treatments X and Y together is more than what would be expected from adding the random variables? Since I do not know that the variables are guaranteed to be independent (in fact, their effects seem to be very much not independent), my idea was to use the formulas $$E[X + Y] = E[X] + E[Y]$$ and $$Var[X + Y] = Var[X] + Var[Y] + 2Cov[X,Y]$$ to obtain the normal distribution for the sum of the random variables where I believe that the covariance of samples would be computed via $$Cov[X,Y] = \frac{\left(\sum\limits_{i = 1}^{N_x}(x_i - \mu_x)\right) \left(\sum\limits_{j=1}^{N_y}(y_j - \mu_y)\right)}{(N_x - 1)(N_y - 1)}$$ where the loss of 1 in each of the terms in the denominator comes from the loss of 1 d.o.f. from using each of the means (I am not sure if this is the correct formula as I could not find a reference for two different random variables, but it would make sense to me given the situation). Then, my idea was to construct two 95% confidence intervals -- one for my sample and one for the computed $X + Y$ random variable, and, provided that the confidence intervals did not overlap, I believe that I can reject the assumption that the effect of the two random variables is additive. Is this the correct approach, or have I lost my mind here? Thank you in advance for any help that you can give!","['statistics', 'probability-distributions', 'normal-distribution']"
4811309,Two seemingly contradictory series in a calc 2 exam,"On a calculus exam I took recently, there were two problems. Find the sum of the series defined by $\sum_{n=1}^{\infty}\frac{1}{(n(n+1))}$ A series $\sum_{n=1}^{\infty}a_n$ has partial sums $s_n = \frac{n-1}{n+1}$ . Find $a_n$ and $\sum_{n=1}^{\infty}a_n$ I got both problems correct, but my answers seem to conflict with each other. For 1, I got 1. For 2, I also got 1 for the sum, and $\frac{2}{n(n+1)}$ for the value of $a_n$ My question is, how can this be possible? The value of $a_n$ in question 2 should be twice that of question 1, so shouldn't the value of the series in question 2 be 2? But when you look at the definition of the series in question 2, the sum as n approaches infinity is obviously 1. Did I make a mistake in finding $a_n$ ? I got it from $s_n - s_{n-1}$ , which should just give me $a_n$ . I brought it up with my TA and professor, and they didn't know, either. What am I missing here?","['calculus', 'sequences-and-series']"
4811371,Is the sample mean absolute deviation unbiased for a normally distributed population?,"Let $X_1,\ldots,X_n$ be a random sample from a normally distributed population.
Is the sample mean average deviation $$\frac{\sum_{i=1}^n|X_i-\bar{X}|}{n}$$ an unbiased estimator of the population mean average deviation?","['statistical-inference', 'statistics', 'descriptive-statistics']"
4811425,Does the interior of Pascal's triangle contain three consecutive integers?,"Consider the interior of Pascal's triangle: the triangle without numbers of the form $\binom{n}{0},\binom{n}{1},\binom{n}{n-1},\binom{n}{n}$ . A006987 (which is described here ) is a list of the smallest $10000$ numbers in the interior of Pascal's triangle, without repeats. It contains $15$ instances of two consecutive integers. It contains only one instance of integers separated by $2$ . But it does not contain three consecutive integers. So I wonder: Does the interior of Pascal's triangle contain three consecutive integers? Looking at the formula for the binomial coefficients, $\binom{n}{r}=\dfrac{n!}{r!(n-r)!}$ , I see no reason why there could not be three consecutive integers, but I cannot find any examples either. This question seems open questiony, but I cannot find any references. EDIT: In the comments, @Sil notes that it is conjectured that a certain list is a complete list of binomial coefficients that differ by $1$ , which if true would imply that the answer to the OP is no. But regardless of the outcome of that conjecture, perhaps there is a way to show that there can be no three consecutive binomial coefficients. Maybe proof by contradiction, or a combinatorial argument? EDIT 2: Posted at MO .","['conjectures', 'number-theory', 'reference-request', 'binomial-coefficients', 'discrete-mathematics']"
4811456,A question of random points in a square and probability of intersection of their line segments,"The following is a problem from PUMaC 2007: Take the square with vertices $(0,0)$ , $(1,0)$ , $(0,1)$ , and $(1,1)$ . Choose a random point in this square
and draw the line segment from it to $(0,0)$ . Choose a second random point in this square and draw
the line segment from it to $(1,0)$ . What is the probability that the two line segments intersect? I tried to find the probability by taking the general point $(x,y)$ and finding the region in which the second point should lie so that the line segments intersect, however, I am stuck in this step. My idea was to find the area of the region, divide by area of the square to get probability and then double integrate wrt y and x to get probability.  I have failed at this after multiple attempts, If the region is a triangle (which is erroneous) I got the answer as $3/8$ , and if I try to do the general case, I find that the integral does not converge. (Do note, over here vertices are adjacent, not opposite)","['geometric-probability', 'probability-theory', 'probability']"
4811467,Injection from A to B given injection from A^2 to B^2,"I wonder if given an injection $A^2 \rightarrow B^2$ , there necesarrily exists an injection $A \rightarrow B$ . And if there is, can you construct it canonically?
If we assume the axiom of choice, then non-existence of an injection implies existence of a surjection. So then this can be rephrased as given a surjection $A \rightarrow B$ , construct a surjection $A^2 \rightarrow B^2$ , which off course is possible canononically.
So my question is if we can find a canonical injection $A \rightarrow B$ given an injection $A^2 \rightarrow B^2$ without invoking the axiom of choice.",['functions']
4811609,Probability that an item from a group is not in a random sample (sampling without replacement),"I have a dataset of $3600$ items. There are $120$ item groups, each containing $30$ items. I create a test set by randomly sampling $720$ items without replacement from the dataset. What is the probability that there is at least one item of every item group in the sampled set? And what is the probability that at least $x$ item groups are not in the sampled set? (any combination of item groups, not specific item groups) Thanks a lot to the efforts of Gabriel Romon and RyRy The Fly Guy . Extra info : Brute forcing leads to a result of about $0.865$ Initially, I started with a easy approach that said: Every item group has the same probability of being sampled, so let's dumb it down to sampling from 120 item groups with equal probability. But obviously that does not work, as it would sample $\frac{720}{30} = 24$ item groups and ignores that every item group can be sampled.","['combinatorics', 'probability-theory', 'probability']"
4811620,Exercise on a fixed end Lagrange's MVT,"Given a function f with derivative on all $[a;b]$ with $f'(a) = f'(b)$, show that there exists $c \in (a;b)$ such that $f'(c) = \frac{f(c)-f(a)}{c-a}$. This is some kind of MVT with constraint. I have a proof but it uses Darboux's theorem. Can you prove it without using it? Sketch of the proof I have using Darboux I suppose first that $f'(a) = 0$ (it's easy to get back to this case with an affine transform) and I set $g(x) = \frac{f(x)-f(a)}{x-a}$. $g'(b) = - \frac{g(b)-g(a)}{b-a} = - g'(d)$ for some $d \in (a;b)$ by Lagrange's MVT. Then $g'(b)$ and $g'(d)$ are either null or have different signs in which case we can find $e \in (d;b)$ such that $g'(e) = 0$. In all cases $g'$ has a zero which is the $c$ we need to find.",['derivatives']
4811625,Three real roots of a cubic,"Question: If the equation $z^3-mz^2+lz-k=0$ has three real roots, then necessary condition must be _______ $l=1$ $ l \neq 1$ $ m = 1$ $ m \neq 1$ I know there is a question here on stack about discriminant and all for these three distinct real roots but I do not feel myself competent to use that. However I tried differentiating the function and for real roots I ended up with $m^2 \geq 3l$","['cubics', 'roots-of-cubics', 'calculus', 'algebra-precalculus', 'derivatives']"
4811708,Deducing an incorrect statement when the mean and median are given,"$~a,~b,~c,~d$ are positive integers such that $a~<~b~<~c~<~d$ If mean and median of $~a, ~b, ~c,~d$ are $35$ and $39$ respectively, then which one of the following statements cannot be true? a = 21 a+c =71 a+c=60 d = 61 I after some attempts made it up to $b+c = 78$ and $a+d = 62$ but can't proceed further. Moreover, please suggest a good title for this post.","['algebra-precalculus', 'median', 'means', 'statistics']"
4811762,What is a labeled group?,"Clicking through the OEIS I found this sequence that seems curious - the number of ""labeled"" groups. It cross references the usual sequence of the number of groups up to isomorphism (the very first sequence in the OEIS) as well as saying it is ""a sequence related to groups"". So I've tried to look up this concept, but Google with ""labeled group"", ""labeled group maths"", ""labeled group theory"", and so on, to no avail at finding anything. Groupprops (essentially a wiki for group theory) doesn't seem to have anything either. I've clicked through the links on that OEIS entry and cannot find anything of help. So as a last resort I'm asking here (I know this isn't necessarily the kind of place for definition questions though, sorry). So, what is a labeled group?","['group-theory', 'definition', 'reference-request']"
4811774,Trouble defining hypothesis-testing problem,"Consider a person who claims to have favorable chances in a game in the sense that if you randomly draw one card from a set with as many red as black cards, said person has probability 0.6 of naming the correct color of the card instead of probability 0.5. To test this person's claim we have him guess 25 consecutive times, where the drawn card is put back in the set every time. We choose to believe him if he guesses correctly at least 17 times; otherwise we choose not to believe him. I've made an attempt at defining suitable null and alternative hypotheses for this test along with a suitable critical region where $T = X$ is the test statistic. I've considered $p \leq 0.5$ and $p > 0.5$ as the null and alternative hypothesis respectively, which corresponds to the critical region $\{17, 18, \dots, 25\}$ . But I'm not sure whether this is correct, as I'm still confused on what the hypotheses should look like given the context. Perhaps we would want to disprove the person's claim? Would someone be so kind as to provide me with a hint to what the null and alternative hypothesis should look like, or whether what I've proposed is correct. Thanks in advance.","['statistics', 'hypothesis-testing']"
4811800,Interesting property about triangles I don't know about.,"Trying to solve a problem with a colleague of mine, we prove a theorem that I'm sure someone else must have had to come across but couldn't find anything about it. We needed a way to tell how far away from equilateral was any triangle. A measure for any triangle of its non-equilateral-ness. One idea (that later turned out not to be the best) was this: Let ABC be any triangle (the one we want to know how far away from equilateralness is). Let's take any of its sides, say AB. Let's take the point C' in which ABC' is equilateral, and which lies to the same side of AB as C. Let's measure the distance CC'. Let's take points B' and A' the same way we took C'. What we found is that the distances CC', BB', and AA', are equal. No matter which side of the triangle we start with, the result is the same. Is it known to be found earlier? Edit For the record, the proof goes this way: We have the original triangle ABC and three new points A', B', C' such that ABC' is equilateral and so on. Let's see triangles ABC' and AB'C. Both are equilateral and share the same point A. Let's see the geometric transformation that brings C' into C, B into B' and A into itself. Given that the distances C'A and BA are the same, the distance traveled by C' to go into C must be the same as the distance traveled by B to go into B'. Ergo, distances C'C and BB' are the same. By the same way we prove that the distance A'A is also the same.","['euclidean-geometry', 'triangles', 'geometry']"
4811807,"Why can we produce a composition of two functions, if we know that the codomain of the inner function is equal to the domain of the outer function?","I'm having some trouble understanding this. For example if we have functions $f:X \to Y$ and $g:Y\to Z$ it seems to me that the only possible way for $g \circ f$ to be defined is if $f(X)$ =Y so the range of f must equal it's codomain. For example if we construct $g(f(x))$ then that $f(x)$ is always some element in the range of f, but not necessarily in it's codomain, for example if $f$ isn't surjective. So lets say $f(x)$ is some $y\in Y$ (not random) then we have $g(y)$ , and since $g$ maps from $Y$ to $Z$ then by definition of a function all elements of Y must be mapped to it's codomain. But lets assume that f isn't surjective so then $g(y)$ can't map all of the elements in it's domain, and the function $g \circ f$ can't be defined. So then when we have this information of where these sets f and g map to and we try to make a composition of f and g, we always have to implicitly assume that f(X)=Y.","['calculus', 'functions']"
4811822,"Understanding the Geometry Spawned from Quotient Spaces $GL^+(4,R)/SO(3,1)$, $GL^+(4,R)/Spin(3,1)$, and $GL^+(4,R)/Spin^c(3,1)$","I'm working on a theoretical framework where I explore different quotient spaces formed with GL $^+$ (4,R) and various groups. Specifically, I'm interested in the types of geometry that arise from the following quotient spaces: GL $^+$ (4,R)/SO(3,1) GL $^+$ (4,R)/Spin(3,1) GL $^+$ (4,R)/Spin $^c$ (3,1) For GL $^+$ (4,R)/SO(3,1), the situation is relatively clear as it leads to the usual symmetric, non-degenerate metric tensors commonly used in theories of gravity. However, I encounter difficulties when trying trying to understand the GL $^+$ (4,R)/Spin(3,1) and GL $^+$ (4,R)/Spin $^c$ (3,1) cases. In these scenarios, what geometry is described by these? To provide some context, I am using the Majorana representation of the Dirac matrices to construct a representation of 4x4 matrices. Furthermore in this representation Spin $^c$ (3,1) can be represented by exp (f+b), where f is a bivector and b a pseudo-scalar which is in GL $+$ (4,R). My question is: For instances GL+(4,R)/SO(3,1)xR spawns Weyl conformal geometry. But what do GL $^+$ (4,R)/Spin(3,1) and GL $^+$ (4,R)/Spin $^c$ (3,1) spawn? Any insights, references, or suggestions on how to approach these constructions would be greatly appreciated.","['quantum-field-theory', 'gauge-theory', 'general-relativity', 'lie-groups', 'differential-geometry']"
4811831,Inequality $\sum_{k=1}^{n} \frac{\log(a_k)}{1+a_{k}^{2}} \leqslant 0$,"Let $a_1,a_2,...,a_n$ be positive real numbers such that $a_1 \cdot a_2 \cdot ... \cdot a_n=1$ . Prove that $\sum_{k=1}^{n} \frac{\log(a_k)}{1+a_{k}^{2}} \leqslant 0$ . I tried using Jensen inequality, but function is not concave for all positive real number and I'm stuck. Any help will be greatly appreciated.","['multivariable-calculus', 'tangent-line-method', 'inequality', 'real-analysis']"
4811887,"Prove that $f'(x)$ is constant from $2(f'(x))^2 + f(x)f''(x)=c$, c constant?","I was fiddling around with derivatives of functions and messed up a question so badly that I was left with the above expression and the knowledge that $f(0)=0$ . To proceed, I assumed $f'(x)=\text{constant}$ for all $x$ and that gave me the answer to the problem. I also know from solving it with another method that there really exists only 1 function $f(x)$ . The problem is, if a non-constant $f'(x)$ could be found, there would exist another solution to the problem, which I know to not be the case, so $f'(x)$ should be constant, and provable from the above equation and knowing $f(x)=0$ . If so, how do we go about proving it? For the curious, the original question stated that, for a continuous and differentiable $g(x)$ , define $f(x)$ to be $f(x)=g''(x)$ and $g(x)=kf^3(x)$ for a constant $k$ , and $g(0)=g'(0)=0$ . You arrive at my equation by taking the derivative of both sides of the equation twice and simplifying it by $f(x)$ (we are given that $f(x)$ is not $0$ for all $x$ ).","['derivatives', 'ordinary-differential-equations']"
4811888,Derivation of inverse matrix [duplicate],This question already has answers here : Derivative of the inverse of a matrix (5 answers) Closed 7 months ago . My question is about how can reach to the formula $$\frac{dA^{-1}}{dt}=-A^{-1}\frac{dA}{dt}A^{-1}$$ when $A$ is a matrix. It is very similar to $$\frac{dx^{-1}}{dt}=-x^{-2}\frac{dx}{dt}$$ And I know we can write $$A^{-1}=A^{-1}I\\A^{-1}=A^{-1}AA^{-1}$$ then it seems to be $$\frac{dA^{-1}}{dt}=\frac{dA^{-1}}{dt}AA^{-1} +A^{-1}\frac{dA}{dt}A^{-1}+A^{-1}A\frac{dA^{-1}}{dt}$$ in this part: how can I simplify right hand side? to obtain $\frac{dA^{-1}}{dt}=-A^{-1}\frac{dA}{dt}A^{-1}$ Any hint will be appreciated.,"['matrices', 'linear-algebra', 'inverse', 'derivatives', 'matrix-decomposition']"
4811896,"Let $p$ and $q$ be twin primes, both greater than or equal to $5$ , is every group of order $p^2q^2$ abelian?","I don't know if I made a mistake, but it seems that something is missing here. Let $p$ and $q$ be twin primes, i.e., $q = p + 2$ . We want to prove that every group with order $p^2q^2$ is abelian, where $p$ and $q$ are greater than or equal to 5. Call our group $G$ with $|G| = p^2q^2$ . Let $n_p$ be the number of subgroups of $G$ with order $p^2$ , and let $n_q$ be the number of subgroups of $G$ with order $q^2$ . We have that $n_p$ divides $q^2$ and $n_p$ is congruent to 1 mod $p$ . This gives us initially $n_p = (1, q, q^2)$ . We have that $n_q$ divides $p^2$ and $n_q$ is congruent to 1 mod $q$ . This gives us initially $n_q = (1, p, p^2)$ . But since $q = p + 2$ : If $n_p = q = p + 2$ , then $p + 2 - 1$ is not congruent to 0 mod $p$ . If $n_p = q^2 = (p + 2)^2 = p^2 + 4p + 4$ , then $p^2 + 4p + 4 - 1$ is not congruent to 0 mod $p$ because $p > 3$ . So, $n_p = 1$ . Let's call $A$ the subgroup of $G$ with order $p^2$ . Also, if $q = p + 2$ , then $p = q - 2$ : If $n_q = p = q - 2$ , then $q - 2 - 1$ is not congruent to 0 mod $q$ , because $q > 3$ . If $n_q = p^2 = q^2 - 4q + 4$ , then $q^2 - 4q + 4 - 1$ is not congruent to 0 mod $q$ because $q > 3$ . So, $n_q = 1$ . Let's call $B$ the subgroup of $G$ with order $q^2$ . A $p$ -Sylow subgroup is normal in $G$ if and only if $n_p = 1$ . Thus, $A$ and $B$ are normal in $G$ . Furthermore, $\text{gcd}(p^2, q^2) = 1$ , which implies that $A \cap B = \{1\}$ . This gives us $|AB| = |A \cdot B| = p^2q^2 = |G|$ . Since $\text{gcd}(p^2, q^2) = 1$ , by the Chinese remainder theorem, $Z_{p^2} \times Z_{q^2}$ is isomorphic to $Z_{p^2q^2}$ . Groups of order $p^2$ with $p$ prime are abelian, so $Z_{p^2}$ and $Z_{q^2}$ are abelian. The direct product of abelian groups is abelian. Thus, $Z_{p^2q^2}$ is abelian. Am I missing something?","['group-theory', 'normal-subgroups', 'abelian-groups', 'sylow-theory']"
4811983,Game Theory / Probability Interview question,"Got this for an interview and didn't get it. How to solve? You and your opponent have a uniform random sampler from 0 to 1. We both sample from our own machines. Whoever has the higher number wins. The catch is when you see your number, you can resample. The opponent can re sample once but you can resample twice. What’s the probability I win? My not-confident-at-all approach: For each player you come up with a strategy that revolves around the idea of “if this number is too low, resample.” you know that for myself, I have three samples, and the EV of the third sample is 1/2. So for the second sample, if it’s below 1/2, you should resample; if above 1/2, do not resample. And you do this for the first sample with a slightly higher threshold. And then assuming our player is opponent they will follow the same approach, but they only have two rolls. No matter what, we know the game can end with six outcomes: it can end with me ending on the first, second, or third sample, and them ending on the first or second outcome. We just condition on each of those six cases and find the probability that my roll is bigger than their roll on that conditional uniform distribution.","['game-theory', 'probability']"
4812016,Product of 2 dice game,"You are playing a game where you a paid the product of 2 dice a) How much would you pay to have the opportunity to reroll any 1 of the dice? b) How much would you pay to roll 3 dice and discard the lowest? I know the EV of product of 2 dice is 12.25 I calculated the Probability of the Product of 2 dice to be <= 12 as $ \frac {23} {36} $ Similarly the probability of the Product of 2 dice to be > 12 as $ \frac {13} {36} $ Now for Part a) New E.V. = $ \frac {23} {36} $ * (Increase in EV in this case) + $ \frac {13} {36} $ * (0 Increase) However, I'm confused how to approach the Increase in EV in the case where we choose to reroll 1 of the dice with Probability of 23/36. One approach I can think of for the above case is that we would only reroll a 1,2 or 3 and never a 4,5,6 as (4 * 4 = 16), (5 * 5 = 25), (6*6 = 36) is > than 12.25. Then - $$  \frac {1} {3}  * (3.5-1) +  \frac {1} {3}  * (3.5 -2) +  \frac {1} {3}  * (3.5-3) = 1.5 $$ Now, I'm not sure if it should be $ \frac {1} {3}  or   \frac {1}{6} $ for the probabilities above considering that it is conditioned on rerolling only if we get a 1,2 or 3 Now the 2nd die E[x] = 3.5 so we can say $$ 1.5 * 3.5 = 5.25 $$ which would be the increase in EV in the case where we choose to reroll 1 of the die Hence increase in EV = $$  \frac {23} {36} * 5.25 = \frac {161} {48} $$ Not sure if this approach is correct Part b) I'm not sure how to approach it","['expected-value', 'probability-theory', 'probability']"
4812062,Relationship between dispersion point and biconnected property,"I am looking at the relationship between the existence of a dispersion point and the biconnected property.  Some definitions: A space $X$ is biconnected if it is connected and is not the union of two disjoint connected subsets, each with at least two points. The point $p\in X$ is a dispersion point for $X$ if $X$ is connected and the subspace $X\setminus \{p\}$ is totally disconnected (where totally disconnected = all connected components are singletons). When the space $X$ has a very small number of elements, the definitions degenerate into trivial cases: To witness that a connected space is not biconnected, one needs at least four elements (two elements in each subset).  So any connected space with at most three elements is biconnected. Also, a space with less than two elements is trivially totally disconnected.  So if $X$ has a single point, that point is trivially a dispersion point.  And if $X$ is connected with exactly 2 points, each of its points is a dispersion point. For size 3, there are examples of $X$ connected (hence biconnected) and without dispersion point.  For example, if the corresponding specialization preorder is a chain, there is no dispersion point ( $X\setminus\{p\}$ is connected for every $p$ ).  Explicitly, take $X=\{a,b,c\}$ with topology $\{\emptyset,\{a\},\{a,b\},X\}$ . Now some results.  First a standard one, which does not depend on the cardinality of $X$ . Proposition 1: If $X$ has a dispersion point, then it is biconnected. Proof: If $X=A\cup B$ with $A$ and $B$ disjoint and connected of size at least $2$ and if the dispersion point $p\in A$ for example, then $B$ would be a connected subset of $X\setminus\{p\}$ of size at least $2$ .  That is not possible since $X\setminus\{p\}$ is totally disconnected. The converse implication is not true.  The classic example of biconnected space without dispersion point is ""Miller's biconnected set"" from Counterexamples in topology , example #131 (taken from E. Miller, Concerning biconnected sets Fundamenta Mathematicae 29 (1937), 123-135).  Another (trivial) such example with three elements was given above. But I think there could be a valid converse for most finite spaces. Proposition 2: If $X$ is biconnected and finite with at least four points, then it has a dispersion point. Can this be proved?","['general-topology', 'connectedness']"
4812069,Is Leibniz rule fundamental?,"Disclaimer, I am a physicist and mess up with math and really think that derivatives are just fractions (roughly). I am starting to study maths itself as the discipline it is and not as a tool for my science. Concretely, I am delving into differential forms and manifolds because there are some facts about physics that I do not really understand. For example, why is there a Lie algebra underlying Poisson Brackets, why the phase space is a 2-form and its role in geometric quantization. In this journey, an intuition is growing (that I do not know if is correct) on what is a derivative, let me explain. I have seen that every operator that somehow follows a Leibniz rule can be understood as a derivative. The derivation applied to functions, the external derivative and the Poisson Bracket follows a Leibniz rule-like. Regarding the last one, as I have seen, in the free coordinate formulation of differential forms and manifolds the Poisson Brackets are very familiar to Lie Derivatives. This motivated my question: is the Leibniz rule fundamental in the descriptions of derivatives? I mean, some operator that do not follow this kind of rule implies that is not a derivative? Thanks in advance for your response. T.","['physics', 'derivatives', 'differential-geometry']"
4812085,Integral over a small set is small and dimension independent,"Let $\mu_n$ be the standard normal distribution over $\mathbb{R}^n$ . Is the following true? For all $\epsilon > 0$ and $d \in \mathbb{N}$ , there exists $\eta > 0$ such that for all $n \geq 1$ and $T \in \mathcal{B}_{\mathbb{R}^n}$ with $\mu_n(T) \leq \eta$ , the following holds. For all polynomials $f:\mathbb{R}^n \to \mathbb{R}$ of degree at most $d$ , $\int_{T} |f|d\mu_n \leq \epsilon \int |f| d\mu_n$ If so, what is a sufficient condition on the class of distributions $\{\mu_n\}_{n \geq 1}$ for this statement to hold? In this similar question, $\eta$ is allowed to depend on $f$ .","['measure-theory', 'reference-request', 'real-analysis', 'gaussian-integral', 'probability-theory']"
4812123,Transport equation and entropy conditon,"Consider the transport equation with smooth coefficient $a \in C^1(\mathbb{R}\times \mathbb{R}^+)$ given by \begin{align}
u_t+(a(x,t)u)_x=0.
\end{align} A weak solusolution $u \in C(\mathbb{R}^+;L^{1}(\mathbb{R}))$ satifies the PDE in the sense of distribution. Since it is transport equation, one would expect any weak solution should automatically satisfy the Kruzkov entropy condition. How to prove this rigorously for any $u \in C(\mathbb{R}^+;L^{1}(\mathbb{R}))$ ?. P.S. If $u \in C^1(\mathbb{R}\times \mathbb{R}^+)$ is a weak solution, then a standard computaion shows that $u$ satisfies enropy condition for any $\eta \in C^1(\mathbb{R})$ convex and then by a density argument we can choose $\eta(u)=|u-k|$ by a limiting argument.","['fluid-dynamics', 'transport-equation', 'analysis', 'partial-differential-equations']"
4812171,$\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta=(0.9999999913...)(\pi/2)$? Seriously?,"In the diagram, $\alpha$ and $\beta$ are independent uniformly random real numbers in $\left(0,\frac{\pi}{2}\right)$ . What is $\mathbb{E}(h)$ ? Superimposing a cartesian coordinate system, the equations of the lines are $y=(\tan\alpha)x$ and $y=(-\tan\beta)(x-1)$ , so the $y$ -coordinate of their intersection is $\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta}$ . So we have $$\mathbb{E}(h)=\frac{4}{\pi^2}\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta$$ Desmos says $I=\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan\alpha)(\tan\beta)}{\tan\alpha+\tan\beta} d\alpha d\beta$ is $(0.9999999913...)(\frac{\pi}{2})$ . Is that a computer error, and the result is exactly $\frac{\pi}{2}$ ? I don't know how to evaluate the integral. Wolfram evaluates the inside integral but doesn't evaluate both integrals . If Desmos is not very reliable, then maybe my earlier weird conjecture is actually true. (This question was inspired by a question about random points in a square.) Edit : In the comments, @G.Gare notes that Mathematica says the integral $I$ is exactly $\pi/2$ . Can we prove it? Maybe an intuitive geometrical argument? Edit2: I seek to generalize this result here .","['integration', 'conjectures', 'definite-integrals', 'geometry', 'expected-value']"
4812183,if $\lim\limits_{n \to \infty} b_n =0 $ then how to prove that $\lim\limits_{n \to \infty} \sum\limits_{k =1} ^n \frac{b_k}{n+1-k}=0$,"in Problems in Mathematical Analysis I problem 2.3.16 a), if $\lim\limits_{n \to \infty}a_n =a$ , then find $\lim\limits_{n \to \infty} \sum\limits_{k=1 }^n \frac{a_k}{(n+1-k)(n+2-k)}$ The proof that was on the answers:- by Toeplitz theorem let $c_{n,k} =\frac{1}{(n+1-k)(n+2-k)}$ and the answer is $a$ , here I didn't understand how this is possible because one condition for Toeplitz theorem is $ \lim\limits_{n \to \infty} c_{n,k} =0 \ \forall k \in \mathbb{N}$ doesn't hold if $k=n $ for example $\textbf{Toeplitz theorem :}$ let $\{ c_{n,k}: 1\leq k \leq n \}$ be an array of real numbers such that: 1- $ \lim\limits_{n \to \infty} c_{n,k} =0 \ \forall k \in \mathbb{N}$ 2- $\sum\limits_{k=1} ^{n} c_{n,k} \to 1$ as $n\to \infty$ 3- There is exist $C \in \mathbb{R}$ such that for all positive integer $n$ $\sum\limits_{k=1} ^{n} |c_{n,k}| \leq C$ then for any converging sequence $ \{a_n \}$ the sequence $\{ b_n \}$ given by $b_n:=\sum\limits_{k=1} ^{n} c_{n,k} a_k $ is convergent and $\lim\limits_{n \to \infty}b_n= \lim\limits_{n \to \infty}a_n$ $\textbf{ My Proof:-}$ First I have to prove  that the sequence $\{ b_n\}$ is convergent this can be shown by considering the sum $s_n =\sum\limits_{k=1} ^{n} |c_{n,k} a_k| $ since the terms of the sum consist only positive number and since $a_n$ is convergent sequence then there exist some $M \in  \mathbb{R} $ such that $a_k\leq M \ \forall k $ then the sequence $s_n <M ,  \sum\limits_{k=1} ^{n} |c_{n,k}| \leq C M $ then the sequence $s_n $ converge then $b_n$ converge
Now lets proof that $\lim\limits_{n \to \infty}b_n= \lim\limits_{n \to \infty}a_n$ first let $a:=\lim\limits_{n \to \infty}a_n$ since $\sum\limits_{k=1} ^{n} c_{n,k} \to 1$ as $n\to \infty $ then I need to prove that $ \sum\limits_{k=1} ^{n} c_{n,k} a_k-a \sum\limits_{k=1} ^{n}  c_{n,k} \to 0 \text{ as } n \to \infty  $ $$S_n:=\sum\limits_{k=1} ^{n} c_{n,k} (a_k-a)$$ $$\text{since } a_k \to a \text{ then }  \forall \varepsilon_1 >0 \  \exists N \in \mathbb{N} \text{ such that } \forall n \geq N \ |a_k-a|<\varepsilon_1 $$ $$ \text{Choose $\varepsilon =\inf \{ \varepsilon_1 , \frac{\varepsilon_1}{ C M}\}$  } \text{Choose $n$ such that } \sup\{ |c_{n,k}| \} < \frac{\varepsilon_1}{NM}$$ $$-\varepsilon - \sum\limits_{k=N+1} ^{n} |c_{n,k} a_k| \leq S_n \leq \varepsilon + \sum\limits_{k=N+1} ^{n} |c_{n,k} a_k|$$ since $\sum\limits_{k=N+1} ^{n} |c_{n,k} a_k| <\varepsilon$ then $$-2\varepsilon<S_n< 2\varepsilon$$ I tried to prove it myself and this what I got let $b_{n-1}= a_n - a_{n-1}$ it is easy to see that $\lim\limits_{n \to \infty }b_n =0 $ (because any converging sequence in $\mathbb{R}$ is a Cauchy sequence) so $$ \lim\limits_{n \to \infty} \sum\limits_{k=1 }^n \frac{a_k}{(n+1-k)(n+2-k)}=\lim\limits_{n \to \infty} \left( a_n - \frac{a_1}{n+1} +b_n -\sum\limits_{k =1} ^n \frac{b_k}{n+1-k} \right)=a -\lim\limits_{n \to \infty} \sum\limits_{k =1} ^n \frac{b_k}{n+1-k} $$ and here I couldn't prove that $\lim\limits_{n \to \infty} \sum\limits_{k =1} ^n \frac{b_k}{n+1-k} =0$ I also want to ask why is the answers that the book provide is correct ? because one of the necessary condition of Toeplitz theorem doesn't hold EDIT @TheSilverDoe has an excellent answer but now I don't know where my mistake was since $\lim\limits_{n \to \infty} \sum\limits_{k =1} ^n \frac{b_k}{n+1-k} \neq 0$ and $$ \lim\limits_{n \to \infty} \sum\limits_{k=1 }^n \frac{a_k}{(n+1-k)(n+2-k)}= \lim\limits_{n \to \infty} \sum\limits_{k=1 }^n \frac{a_k}{(n+1-k)}- \frac{a_k}{(n+2-k)}$$ $$ =\lim\limits_{n \to \infty}+a_n -\frac{a_1}{n+1}- \sum\limits_{k=1 }^{n-1} \frac{a_{n+1-k}- a_{n-k}}{k+1} $$ $$= a-\lim\limits_{n \to \infty} \sum_{k=1}^{n-1}\frac{a_{k+1}- a_{k}}{n+1-k}=a-\lim\limits_{n \to \infty} \sum_{k=1}^{n-1}\frac{b_{k}}{n+1-k}=a-\lim\limits_{n \to \infty} \sum_{k=1}^{n}\frac{b_{k}}{n+1-k}- b_{n}=$$ $$a- \lim\limits_{n \to \infty} \sum\limits_{k =1} ^n \frac{b_k}{n+1-k}$$ I still can't figure out where is the mistake in my logic. Is the mistake related to conditional convergent series and Riemann rearrangement theorem ?","['summation', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
4812227,Alternative q-Analog,"Wikipedia gives the following definition of a q-analog: ""In mathematics, a q-analog of a theorem, identity or expression is a generalization involving a new parameter $q$ that returns the original theorem, identity or expression in the limit as $q \rightarrow 1$ . Typically, mathematicians are interested in q-analogs that arise naturally, rather than in arbitrarily contriving q-analogs of known results."" There seem to exists, for basic mathematical objects like; the numbers, factorial, binomial coefficient,... a well-known q-analog established as convention, however for other lesser known objects like specific types of numbers, or derivatives, there seem to be a few different types of q-analogs all with their own unique properties. These q-analogs are all still based off of the 'basic building block' of all q-analogs, which is the q-number $${[n]}_q = \sum_{k=0}^{n-1}q^k$$ Which has the arithemtic properties $${[n m]}_q = {[n]}_q{[m]}_{q^n}$$ and $${[n+m]}_q = {[n]}_q+q^n{[m]}_q$$ My question is just if there are other known q-analogs of, for example the number. Perhaps even known q-analogs that return the original theorem when $q \rightarrow x$ for some $x \neq 1$ ? Of course anyone could arbitrarily create a q-analog like $n^q$ so when $q \rightarrow 1$ returns $n$ but that doesn't seem that useful. Any contribution is appreciated Edit: Just to add this here in case anyone is interested. I found something called a d-analog from this paper here. Regardless of the notation, this is relevant to the post, and since it doesn't seem very popular I thought I could share it here and maybe someone finds it interesting. Bounty A +100 bounty is set for anyone who can create/showcase a well-defined and interesting alternative analog for some basic 'building-block' mathematical object like a number $n \in \mathbb{Z}$ . You can go into as much detail, perhaps even formulating $n!$ , analog derivatives, $n \in \mathbb{Q}$ , showcasing how it is useful, etc.
Bounty goes to the best one! Good luck!","['combinatorics', 'q-analogs']"
4812236,"For all positive integers $a, b, c > 4$ if $(a - 2) (b - 2)(c - 2) = 4(a + b + c) + 4$ then what can be the value of $(a + b + c)$?","For all positive integers $a, b, c > 4$ if $(a - 2) (b - 2)(c - 2) = 4(a + b + c) + 4$ then what can be the value of $(a + b + c)$ ? 13 15 20 None of these Here is my try at the question: $(a - 2) (b - 2)(c - 2) = 4(a + b + c) + 4$ $ abc -2bc-2ac+4c-2ab+4b+4a-8 = 4a + 4b + 4c +4$ $abc - 2(bc+ac+ab) = 12$ However, I don't know how to proceed further. Any clues?","['elementary-number-theory', 'algebra-precalculus']"
4812238,Infinite sum of Gamma random variables with same shape parameter but different rate parameter,"Question Let $Z_i\sim\chi_{(1)}^2\sim\Gamma(\frac{1}{2},\frac{1}{2})$ be i.i.d. chi-square random variables. We define: $$
W_n =\Bigl[\sum_{i = 1}^{n-1}\frac{Z_i}{2^{i}}\Bigr] + \frac{Z_n}{2^{n-1}} \mbox{ $\forall n\geq 2$}
$$ For example: $W_2 = \frac{1}{2}Z_1+\frac{1}{2}Z_2$ , $W_3 = \frac{1}{2}Z_1+\frac{1}{4}Z_2+\frac{1}{4}Z_3$ and so on. I would like to determine the distribution of $W_{\infty}$ defined as: $$
W_{\infty} = \lim_{n\to\infty}W_n = \sum_{k = 1}^{\infty} \frac{Z_k}{2^{k}} \mbox{ where $Z_k\sim \Gamma\Bigl(\frac{1}{2},\frac{1}{2}\Bigr)$ are i.i.d.}
$$ More specifically I have interest in computing the probability $P(W_{\infty} > 1$ ). References Note that this problem has references, in particular in this paper by Mathai: https://www.ism.ac.jp/editsec/aism/pdf/034_3_0591.pdf Reference [4]: In my case, following its notations $\alpha = \frac{1}{2}$ , $X_i\sim\Gamma(\frac{1}{2},\frac{1}{2})$ are i.i.d. and $n\to\infty$ . The main problem is that I didn't manage to find Prabhu's work about this fact, and in general I didn't manage to find any other references to this problem. My attempt I was trying to approach this problem using the Levy-criteria for the convergence in distribution.. in particular I was trying to calculate (since they are indipendent random variables) the infinite product of their characteristic functions, which is the characteristic function of $W_{\infty}$ .. but I wasn't able to determine a closed form for it. In particular if $H_k \sim \Gamma(1/2,2^k)$ then $\phi_{H_k}(t) = \Bigl(1-\frac{t}{2^k}\Bigr)^{-\frac{1}{2}}$ and so: $$
\phi_{W_{\infty}}(t) = \prod_{k = 0}^{\infty}\frac{1}{\sqrt{1-\frac{it}{2^k}}}
$$ Code and simulation I'm sure that $W_n$ converges in distribution by simulating it using R, in particular the following code: it = 10000
n = 300
mat = matrix(rep(0,n*it),n,it)
w = vector()
for(i in 1:n) {
  mat[i,] = rchisq(it,1)
}
for(i in 1:n) {
  mat[i,] = mat[i,]/2^i
}
for(j in 1:it) {
  w[j] = sum(mat[,j])
}
hist(w,freq = F,breaks = seq(0,10,0.1)) produces the following output: $W_{300}$ "" /> which is the distribution of $W_{300}$ . I don't really know if this is a well known distribution, and I don't really know if its density function has a closed form. I don't know how to proceed. Thank you in advance for your help! New approximation of $P(W_{\infty} > 1)$ Using the software R and the library ""CompQuadForm"": https://cran.r-project.org/web/packages/CompQuadForm/CompQuadForm.pdf I manage to approximate the value of $P(W_{\infty} > 1)$ with the code: library(CompQuadForm)
n = 10000
q = 1
lambda = vector()
for(i in 1:n) {
  lambda[i] = 2^(-i)
}
acc1 = 10^(-15)
approx = davies(q, lambda, h = rep(1, length(lambda)), delta = rep(0,length(lambda)), sigma = 0, lim = 500000, acc = acc1)$Qq
sprintf(""%.30f"",approx) which gives: $$
P(W_{\infty} > 1) \approx 0.371741079532780016592141691945
$$ which I think are the real first 30 digits. (I'm sure for the first 15 since I set an accuracy of $10^{-15}$ ). Of course I would prefer an ""analytic"" form of this number..","['probability-limit-theorems', 'probability-distributions', 'infinite-product', 'probability-theory', 'probability']"
4812245,A non-local equation on Laplace transforms.,"I wish to find all probability distributions $\mu$ on $\mathbb R^+$ whose Laplace transform: $\varphi(z) = \int_{0}^{\infty} e^{-zx} \mu(dx), z \geqslant 0,$ solves the equation: $\varphi(z) = \beta \varphi(z) g(z) +  (1-\beta) \frac{\varphi(z+1)}{\varphi(1)},$ where $g$ again is the Laplace transform of some given distribution on $\mathbb R^+$ This equation characterizes the fixed point in distribution of some probabilistic model for the balance between selection and mutation. The difficulty comes from the non-local term (the fact that the equation mixes $z$ and $z+1$ ) All comments are welcome !","['functional-equations', 'laplace-transform', 'probability']"
4812292,Is $\cos$ a polynomial function of $\sin$?,We know that $\cos^2$ is a polynomial function of $\sin$ because $$\cos^2 x=1-\sin^2 x.$$ But this left me wondering: Does there exist a polynomial function $P$ such that $$\cos x=P(\sin x)?$$ Can we prove it?,"['trigonometry', 'polynomials', 'real-analysis']"
4812330,$2\csc^2(1-2x) = 2\cot(1-2x)\csc(1-2x)$ when using two different methods on same derivative.,"I was playing around with the following derivative: $$ \frac{d}{dx} \left(\frac{1}{\sin(1-2x)}\right) $$ The way our teacher approached it was to transform the sine into a cosecant: $$ \begin{align} 
\frac{d}{dx}( \csc(1-2x)) 
 &= -\csc^2(1-2x)\frac{d}{dx} (1-2x) \\\\
 &= 2\csc^2(1-2x) 
\end{align} $$ However, I also tried combining the chain and power rules: $$ \begin{align}
\frac{d}{dx} \left(\frac{1}{\sin(1-2x)}\right) 
 &= \frac{-1}{\sin^2(1-2x)}\frac{d}{dx}(\sin(1-2x)) \\\\
 &= \frac{-1}{\sin^2(1-2x)}(\cos(1-2x))\frac{d}{dx}(1-2x) \\\\
 &= \frac{2\cos(1-2x)}{\sin^2(1-2x)} \\\\
 &= 2\cot(1-2x)\csc(1-2x) 
\end{align}$$ I also tried graphing them using desmos (blue, green and purple overlap): I want to know if both methods were correct, and if so, why are the graphs different and is there another way to demonstrate that these two terms are equivalent.","['trigonometry', 'derivatives']"
4812377,Game with 4 coins,"Consider the following game. We have 4 fair coins, they are tossed and you have 2 options, either take the amount of money equal to the number of heads that fell, or toss 4 coins again, after you toss 4 coins again you must take the money and the game ends. Obviously, the optimal strategy is: If on the first throw there are 2, 3 or 4 heads, then we take the money, but if the number of heads is 0 or 1, then we throw the coins again. How to calculate the expected value of this strategy? I don't understand how to calculate expectations in such games, if anybody could explain on this example, I would appreciate that!","['game-theory', 'probability-theory', 'probability']"
4812508,What is the solution of the differential equation,I'm trying to solve the differential equation: $$ y'=\frac{1}{2} \frac{2x + 3y^2+1}{3x+4y^2+1} $$ I thought it was a homogeneous differential equation and I tried to find the integrating factor and then substitute: $$ u= \frac{y}{x} $$ However I don't think that is possible. I also tried to substitute: $$ u = y^2$$ But I didn't get any results. I have just started learning differential equations so I would appreciate any suggestions!,['ordinary-differential-equations']
4812596,How to get derivatives from Taylor series [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 7 months ago . Improve this question I recently started learning about Taylor series and getting the derivative is confusing from the sum provided. So for example if I had the Taylor series $$f(x) = \sum_{k=0}^\infty (-1)^{k+1}\frac{k!}{(2k)!}(x-4)^k$$ how would I get derivatives from this for example $f ''(4)$ ?","['calculus', 'derivatives', 'taylor-expansion']"
4812602,"In nonstandard probability theory, does an event hold nearly everywhere iff it holds on an event whose complement has infinitesimal probability?","In Nelson's ""Internal Set Theory: A New Approach to Nonstandard Analysis"", he defines a predicate holding nearly everywhere if for all standard $\epsilon > 0$ , there exists an event $N$ on which the predicate holds whose complement has probability less than $\epsilon$ . Is it the case that we can upgrade this to a single event $N$ whose complement has infinitesimal probability? If not, are there any concrete counterexamples?","['nonstandard-analysis', 'probability-theory']"
4812664,The smallest cardinality of a set such that it is transitive,"I am currently stuck on a set theory problem. Suppose we have set S = $ \{1, 2, 3, 4, 5 \}$ and set A $\subseteq S * S$ given by $A = \{ (1, 1), (1, 4), (2, 1), (2, 2), (2, 4), (3, 5), (4, 3), (4, 4), (5, 2) \} $ . Now, suppose $B \subseteq S * S$ and is a transitive relation such that $A \subseteq B$ . What is the smallest cardinality of $B$ ? My working was as follows:
For $B$ to be transitive, for every $(a, b) \in B$ and $(b, c) \in B$ there must be $(a, c) \in B$ . As $A \subseteq B$ , we can get the smallest set if we consider the elements in $A$ which already hold a transitive relation and simply add any 'missing' elements to fulfil the remaining elements that lack this relation. There's an issue though. Once we add those 'missing' elements, they become part of the set and so need to hold the transitive relation for themselves. For example, we have from $A$ , $(1,4)$ and $(4,3)$ . Therefore we need to add $(1, 3)$ to complete the transitive relation between those two. However, this creates another issue - $(1, 3)$ (the added 'missing' element) and $(3, 5)$ (from set $A$ ) do not satisfy the transitive relation (i.e. there is a missing $(1, 5)$ ). Once I got this impression, it made me believe that manually determining all the pairs to add to $B$ in order to satisfy the transitive requirement for the set may take a while. The given solution says the answer is '25' (i.e. the entirety of the elements of $S * S$ ). Is this verifiable without manually crunching all the pairs required to satisfy the requirement? If so, it would be funny that the 'smallest' possible cardinality is the entire set.","['elementary-set-theory', 'relations', 'discrete-mathematics']"
4812685,Card game Puzzle,"You have a special deck with 11 cards, with 10 red cards and 1 joker. starting with $1 we play a game: shuffle the deck we can choose to draw the top card. if it's red, we double our money, but if it's the joker, our money is multiplied by 1/2048. the card we drew is then discarded. repeat step 2 until you want to walk away: at any time, you can choose to stop drawing cards and take home however much you have. a) how would you play this game? what's the minimum amount of money you are guaranteed to take home? b) let's say you employ a strategy where you always draw n cards then stop. What value of n should you pick? how much money would you on average then have? c) what strategy maximizes the expected value, and what is this value? We now modify the game so that before drawing a card, you can bet any number between 0 and how much money you currently have. then, the bet is either doubled or multiplied by 1/2048 depending on whether you draw a red card or the joker. d) does your strategy change? how should you now play, and what are the associated expectations? e) what is the most amount of money you are guaranteed to win? My approach: Part a) If you ever draw a Joker, you continue to draw all the other cards. Hence minimum amount of money guaranteed is \$ 1/2 or 50 cents. b) We will stop drawing after n cards when $ E[n+1] <= E[n]:$ $$ \frac {10-n} {11-n} * 2^{n+1} <= \frac {10-n + 1} {11-n +1} * 2^{n} $$ This gives us $ n^2 -22n + 119 = 0 $ as our equation giving $ n <= 9.59 $ Hence we should stop after drawing 9 Red cards. However, if we get a Joker we obviously draw all cards then. c) Assuming same strategy as above $$ E[x] = \frac {2}{11} * 2^9 + \frac {9} {11} * \frac {1} {2} = 93.5 $$ Not sure if this strategy is correct/optimal that maximizes EV. Also no idea on the next part where we can bet any amount of the money we currently have","['expected-value', 'puzzle', 'probability-theory', 'probability']"
4812703,Is this Monoid Finitely Generated?,"Let $G$ be a finitely generated  abelian group, $H\leq G$ , and $S = \{g_1, \dots, g_n\}$ be some finite generating set for $G$ . Let $G’$ be the set of negative-free linear combinations of elements of $S$ . i.e. $G’ = \{a_1g_1 + \dots + a_ng_n | a_1,\dots, a_n \in \mathbb{N}\}$ , and let $H’= G’ \cap H$ . Is $H’$ finitely generated as a monoid i.e. is there some finite subset of $H’$ , $S’$ such that every element of $H’$ is a nonnegative linear combination of $S’$ ?","['monoid', 'finitely-generated', 'abstract-algebra', 'group-theory', 'abelian-groups']"
4812708,Show one solution of ODE system is bounded above and below,"Defined on $\mathbb{R}$ , there're three $C^1$ functions $u_{1}(x),u_{2}(x),u_{3}(x)$ . Given the ODE system \begin{cases}
u_{1}'(x)&=u_{2}(x)u_{3}(x) \\
u_{2}'(x)&=-u_{1}(x)u_{3}(x) \\
u_{3}'(x)&=-k^2u_{1}(x)u_{2}(x) \\
\end{cases} Here $0<k<1$ . The initial condition is $u_{1}(0)=0,u_{2}(0)=u_{3}(0)=1$ .
Show that $\sqrt{1-k^2}\leq u_{3}(x)\leq1$ . I have known $u_{1}^2(x)+u_{2}^2(x)=1$ by combining the first two equations. However, I haven't found how to continue the boundeness of $u_{3}$ . By differentiating $u_{3}$ I got $u_{3}''=k^2(u_{1}^2-u_{2}^2)u_{3}$ but it seems no use. By $u_{1}^2+u_{2}^2=1$ we may know $1\geq 2u_{1}u_{2}$ .",['ordinary-differential-equations']
4812742,Finite covers of $X$ and continuous profinite group actions,"I have a question that is related to the one here , but I found the answer there unsatisfactory and kind of confusing. For context, we are considering the action of the fundamental group $\pi_1(X,x)$ on the fiber $p^{-1}(x)$ of some finite connected cover $p:Y\rightarrow X$ . The proof is from Corollary 2.3.9 of Szamuely's book, showing an equivalence of categories of finite covers of $X$ with the category of finite continuous left $\hat{\pi}_1(X,x)$ -sets, where $\hat{\pi}_1(X,x)$ is the profinite completion of $\pi_1(X,x)$ . Here's the result from the text: For a finite connected cover $p\colon Y\rightarrow X$ the action of $\pi_1 (X,x)$ on $p^{-1}(x)$ factors through a finite quotient, so we obtain an action of $\hat{\pi}_1 (X,x)$ as well. The stabilizer of each point $y\in Y$ [ $y\in p^{-1}(x)$ ] is a subgroup of finite index, and hence contains a normal subgroup of finite index by the lemma. Therefore the stabilizer of $y$ under the action of $\hat{\pi}_1 (X,x)$ is an open subgroup in the profinite topology (being a union of cosets of an open normal subgroup), which means that the action is continuous. Conversely, a continuous action of $\hat{\pi}_1(X,x)$ on a finite set factors through a finite quotient which is also a quotient of $\pi_1(X,x)$ , and as such gives rise to a finite cover $Y\rightarrow X$ . I guess I'm mainly confused on two points here: Why is the normal subgroup open? I tried drawing some diagrams and couldn't come up with a satisfactory answer. The answer I linked above says that we can see that the projection $\hat{\pi}_1(X,x)\rightarrow \hat{\pi}_1(X,x)/N$ is continuous where the image has the discrete topology, but it seems to me that the argument then implies that any normal $N$ with finite index in a profinite group would be open, which I don't think is true. It also is not clear to me why a finite quotient of $\hat{\pi}_1(X,x)$ is also a finite quotient of $\pi_1(X,x)$ . I tried messing around with the natural map $\pi_1(X,x)\rightarrow \hat{\pi}_1(X,x)$ but didn't get anywhere.","['profinite-groups', 'topological-groups', 'fundamental-groups', 'algebraic-geometry', 'algebraic-topology']"
4812776,"Conjecture: If $x_k$ are random in $(0,\pi/2)$ then expectation of $\frac{\prod_{k=1}^n\tan x_k}{\sum_{k=1}^n\tan x_k}$ is $(\pi/2)^{2n-6}$ for $n>2$.","Let $E(n)=\text{expectation of }\dfrac{\prod_{k=1}^n\tan x_k}{\sum_{k=1}^n\tan x_k}$ where $x_k$ are independent uniformly random real numbers in $\left(0,\frac{\pi}{2}\right)$ . Is the following conjecture true: $E(n)=\left(\frac{\pi}{2}\right)^{2n-6}$ for $n>2$ . Context Earlier I found that $E(2)=\left(\frac{2}{\pi}\right)^2\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan x_1)(\tan x_2)}{\tan x_1+\tan x_2}dx_1dx_2=\frac{2}{\pi}$ . Naturally, I wondered if $E(n)$ has closed forms for other $n$ values. Basis of my conjecture $E(3)=\left(\frac{2}{\pi}\right)^3\int_0^{\pi/2}\int_0^{\pi/2}\int_0^{\pi/2}\frac{(\tan x_1) (\tan x_2)(\tan x_3)}{\tan x_1+\tan x_2+\tan x_3}dx_1dx_2dx_3=0.9999996\dots$ , according to Desmos . I guess it's actually $1$ . For $n>3$ , Desmos and Wolfram Cloud don't work, so I used Excel with about a million trials. I got: $E(4)\approx2.480$ , whereas $\left(\frac{\pi}{2}\right)^{2(4)-6}\approx2.467$ $E(5)\approx6.047$ , whereas $\left(\frac{\pi}{2}\right)^{2(5)-6}\approx6.088$ $E(6)\approx16.794$ , whereas $\left(\frac{\pi}{2}\right)^{2(6)-6}\approx15.022$ $E(7)\approx37.495$ , whereas $\left(\frac{\pi}{2}\right)^{2(7)-6}\approx37.065$ As $n$ increases, the values of $\dfrac{\prod_{k=1}^n\tan x_k}{\sum_{k=1}^n\tan x_k}$ fluctuate more and more, so this numerical approach becomes less reliable. If my conjecture is true, I can't imagine what a proof would look like.","['integration', 'conjectures', 'definite-integrals', 'expected-value', 'trigonometry']"
4812807,Smooth map between oriented manifolds.,Let $f: M\rightarrow N$ be a smooth map between smooth closed oriented connected manifolds of same dimension. Question: is it true that $f$ is smoothly homotopic to some smooth map $g: M\rightarrow  N$ such that The determinant of the differential $\det (dg(m))\geq 0$ for all $m\in M$ or $\det(dg(m))\leq 0$ for all $m\in M$ .,"['differential-topology', 'reference-request', 'differential-geometry']"
4812810,A generalized criteria of being projective spaces?,"Here is an exercise V.1.11.12.1 in J. Kollar's book Rational curves on algebraic varieties : Let $X$ be a smooth projective variety of dimension $n$ over an algebraically closed field $k$ . Let $\mathscr{L}$ be a line bundle on $X$ such that $\mathscr{L}^{n+1}\cong \omega_X^{-1}$ and $h^0(X,\mathscr{L})\geq n+1$ . Then $X\cong\mathbb{P}^n_k$ and $\mathscr{L}\cong\mathscr{O}(1)$ . (Hint: induction on $n$ ) Actually before this exercise he proved a classical result: if $X$ is a smooth Fano variety with index $n+1$ , then $X\cong\mathbb{P}^n$ . So this exercise is some kind of generalization of it. It seems right but I don't know why or why not? If it is not right, are there some counter-examples? Here is what I thought (has been edited follows Cranium Clamp's remark ): We can prove it under three assumptions. We know this is right for $n=1$ . We assume that this is right for $n-1$ . Now consider $n\geq 2$ . Pick $D\in|\mathscr{L}|$ (I don't know why this is smooth. But I will assume ( $\star$ ) it is), then by adjunction formula we have $$\omega_D\cong\omega_X|_D\otimes\mathscr{L}|_D\cong \mathscr{L}^n|_D.$$ Moreover, by $0\to\mathscr{O}_X\to\mathscr{L}\to\mathscr{L}|_D\to0$ , we have $h^0(D,\mathscr{L}|_D)\geq n$ . Hence by induction $(D,\mathscr{L}|_D)\cong(\mathbb{P}^{n-1},\mathscr{O}(1))$ . Hence we have $\int_Xc_1(\mathscr{L})^n=1$ .
As $0\to\mathscr{O}_X\to\mathscr{L}\to\mathscr{L}|_D\to0$ , we find that $\mathscr{L}$ is base-point free if $H^1(X,\mathscr{O}_X)=0$ ( $\star$$\star$ ). Hence this induce $\phi:X\to\mathbb{P}^n$ . Hence $1=\int_Xc_1(\mathscr{L})^n=\deg\phi\deg\mathrm{Im}\phi$ . Hence $\phi$ is of degree $1$ which is also surjective. Hence if we assume ( $\star$$\star$$\star$ ) $\mathscr{L}$ is ample, then $f$ is also finite. Hence $f$ is an isomorphism. Hence $X\cong\mathbb{P}^n_k$ and $\mathscr{L}\cong\mathscr{O}(1)$ . So I solved this problem with some assumptions: Assumption ( $\star$ ): $\mathscr{L}$ has smooth divisor. It seems a hard condition... We can not use Bertini's theorem here. Is there some Bertini-type theorem can slove this? Assumption ( $\star$$\star$ ): $H^1(X,\mathscr{O}_X)=0$ . If $\mathrm{char}k=0$ and $\mathscr{L}$ is ample, then this follows from Kodaira vanishing theorem. Assumption ( $\star$$\star$$\star$ ): $\mathscr{L}$ is ample in this case. As here we already proved (using the first assumption) that $\mathscr{L}$ is base-point free, then by Nakai-Moishizon theorem, to show $\mathscr{L}$ is ample we just need to show $\mathscr{L}\cdot C>0$ for any integral curves $C\subset X$ . But how? So if we let $\mathscr{L}$ is very ample at beginning, these two assumptions will hold automatically. But unfortunately we have no this beautiful assumption. Thank you for your help!!!",['algebraic-geometry']
4812823,$a*b=a \iff a=0$ or $b=1$,"$a$ and $b$ are integers. $$a*b=a \iff a=0 \ \text{or} \ b=1$$ First, i tried using the right side to prove the left, so $$b=1 \Longrightarrow a*1=a \Longrightarrow a=a$$ $$ a=0 \Longrightarrow 0*b=0$$ whereas b can have any value. The way around would be: Supose b is invertible, then $$ab=a \Longrightarrow a * (b*b^{-1})= a*b^{-1}$$ $$ \Longrightarrow a*1=a*b^{-1} \Longrightarrow a=ab^{-1}  $$ Therefore $$ab=a=ab^{-1}$$ Supose $a≠0$ then $b = b^{-1}$ iff $b=1$ or $b=-1$ If $a=0$ b can be any integer. Any other ideas? Is that correct?","['algebra-precalculus', 'solution-verification', 'integers', 'discrete-mathematics']"
