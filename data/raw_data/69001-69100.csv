question_id,title,body,tags
834392,Equations of lines tangent to an ellipse,"Determine the equations of the lines that are tangent to the ellipse $\displaystyle{\frac{1}{16}x^2 + \frac{1}{4}y^2 = 1}$
and pass through $(4,6)$. I know one tangent should be $x = 4$ because it goes through $(4,6)$ and is tangent to the ellipse but I don't know how to find the other tangents. Any help is appreciated.",['calculus']
834394,"sections of an invertible sheaf, and their support","Suppose I have a section $s$ of an invertible sheaf $L$, vanishing along a divisor $D$. Then there is an isomorphism $(L, s) \simeq (O(D), 1)$. In the next paragraph I'll pick $D=K_X$, but that is just how I stumbled upon my question/confusion, it works for any divisor $D$. Let $X$ be a smooth variety of dimension $n$, let $\omega$ be an $n$-form, and let $K_X=div(\omega)$. To help me explain my confusion, assume $K_X$ is an effective Weil divisor (although it's not really crucial).
The sections of $O(K_X)$ are rational functions $f$ such that $div(f) + K_X \geq 0$, in other words, sections of $O(K_X)$ consist of rational functions that (assuming for convenience $K_X$ is effective) can have \emph{poles} along $K_X$, which is confusing me because $K_X$ is the divisor of zeroes (minus poles) of a rational $n$-form of the canonical bundle $\omega_X \simeq O(K_X)$! Can someone help sort out my confusion ... I'm having trouble formulating my precise question. How should I think of the sections of $O(K_X)$? As n-forms or as rational functions with poles along $K_X$? I think what may be happening is that if I think about a section of $O(K_X)$ as rational function $f$, and then if I want to switch to thinking about the divisor of the corresponding section of $\omega_X$, I have to take not $div(f)$ but $div(f) + K_X$. That is basically how the isomorphism $\omega_X \simeq O(K_X)$ goes. In the definition of terminal singularities, the condition is, for a resolution $f:X \to Y$, we require $f_*O(mK_X -E) = O(mK_Y)$
How should I think of an element of $f_*O(mK_X -E)$, particularly to figure out the following statement, which I found on p. 8 here : ""Assume $Y$ is smooth and let $s \in H^0(Y,mK_Y)$. Then $f^\ast s$ as a section of $mK_X$ will vanish along the exceptional divisor of $f$."" So does that mean $s \in f_*O(mK_X-E)$, or is it $s \in f_*O(mK_X+E)$? Why? I can see reasons for both options even though only one is correct.",['algebraic-geometry']
834403,The product of two divergent series is divergent?,"This is an TRUE/FALSE queston: The product of two divergent series is divergent. The correct answer is FALSE. I know that the product of two convergent series may not be convergent (i.e. $\frac{(-1)^n}{\sqrt{n}}$) according to Cauchy Product. My question is why ""The product of two divergent series may not be divergent""?? Is there any counter example? Thanks!","['sequences-and-series', 'calculus', 'real-analysis']"
834420,Prove that $A^{t}A$ is positive definite,"$A$ is an invertible matrix over $\mathbb{R}$ (nxn).
Show that $A^{T}A$ is positive definite. I looked up for it and found this two relevent posts but still need help. positive definite and transpose help me understand a line in an “$A^TA$ is positive, semi-definite” proof Any suggestions? thanks (The whole excercise is about bilinear forms)","['matrices', 'linear-algebra', 'bilinear-form']"
834425,What does $\vee$ mean in set theory?,"The following proof is from Probability by Davar Khoshnevisan. There is a symbol $\vee$ in the third sentence of the proof. What does this symbol mean, please? There seems no definition about it in the book and I certainly do not recall seeing this symbol in previous studies. Thank you! Kolmogorov's Zero-One Law. If $\{ X_i\}^\infty_{i=1}$ are independent
random variables, then their tail $\sigma$-algebra $\mathscr{T}$ is
trivial in the sense that for all $E\in\mathscr{T}$, $P(E)=0$ or $1$.
Consequently, any $\mathscr{T}$-measurable random variable is a constant
almost surely. Proof. Our strategy is to prove that every $E\in\mathscr{T}$ is
independent of itself, so that $P(E)=P(E\cap E)=P(E)P(E)$. Since
$E\in\mathscr{T}$, it follows that $E$ is independent of $\sigma(\{
X_i\}^{n-1}_{i=1})$. Because this is true for each $n$, Lemma 6.15 (iii)
ensures that $E$ is independent of $\vee^\infty_{n=1}\sigma(\{
X_i\}^{n-1}_{i=1})$, which is defined to be the smallest
$\sigma$-algebra that contains $\cup^\infty_{n=1}\sigma(\{
X_i\}^{n-1}_{i=1})$. In other words, $E$ is independent of all the
$X_i$'s, and hence of itself.","['notation', 'measure-theory', 'elementary-set-theory', 'probability-theory', 'probability']"
834431,Quotient group $\mathbb Z^n/\ \text{im}(A)$ [duplicate],This question already has an answer here : Question on determinants of matrices changing between integer matrices [duplicate] (1 answer) Closed 6 years ago . Let $A$ be an $n \times n$ matrix with integer coefficients and nonzero determinant. Can we say something about $ \mathbb{Z}^n /\ \text{im}( \phi )$ (here $\phi : v \mapsto Av$ )? This problem has arised as I was solving some problem in homology theory.,"['matrices', 'group-theory', 'abstract-algebra', 'abelian-groups']"
834451,"Geometrically, what is the span of vectors?","Simple question from a calc 3 beginner. Visually I cannot imagine the span of two vectors, what does this necessarily mean? For example my text mentions if two vectors are parallel their span is a line, otherwise a plane. Can anyone elaborate?","['vector-spaces', 'linear-algebra', 'vectors']"
834471,Help Evaluating $\lim_{x \to \infty} \sqrt{x + \sqrt{x + \sqrt{x}}} - \sqrt{x}$,"Does anyone know how to evaluate the following limit?
$$
\lim_{x \to \infty} \sqrt{x + \sqrt{x + \sqrt{x}}} - \sqrt{x}
$$
The answer is $\frac{1}{2}$, but I want to see a step by step solution if possible.","['radicals', 'nested-radicals', 'calculus', 'limits']"
834579,pullback of canonical divisor,"Let $Y$ be a smooth variety of dimension $n$. Then I can get (a representative for) the canonical divisor class $K_Y$ on $Y$ by taking any rational $n$-form $\omega$ on $Y$ and taking its divisor of zeroes and poles, so $K_Y\equiv div(\omega)$. Now let $f:X \to Y$ be a birational morphism between smooth varieties of dimension $n$, and $\omega$ an $n$-form on $Y$. Then $f^\ast\omega$ is an n-form on $X$, so by the above recipe (take the divisor of any n-form to get a representative for the canonical divisor class) we get $K_X\equiv div(f^*\omega)$. Also $div(f^*\omega)= f^*div(\omega)$  by definition of pullback of a Cartier divisor. So $K_X\equiv f^*K_Y$ which is not true .. I am missing the exceptional divisor. Where is the flaw in my argument? This question proves $K_X \equiv f^* K_Y + R$ where $R$ is supported on the exceptional divisor, and it might help to spot where I'm going wrong.",['algebraic-geometry']
834599,Acquiring $Df(\mathbf{x})$,"Sorry for the probably easy and silly question, but I try to teach myself linear algebra and I am stucked at ""the derivative as a matrix"" part. 
I know how to differentiate partially and I know how $Df(\mathbf{x})$ should look like. I just don't know how to calculate it with vectors/matrices. In the excercise I need to find $Df(\mathbf{x})$ at $a=\begin{pmatrix} 
1\\ 
2\\ 
\end{pmatrix}$ with $f(\mathbf{x})=\begin{pmatrix}
(x+y)^3\\ 
x^2y^3\\ 
y/x\\
\end{pmatrix}$.
I don't understand the process... So could you please explain to me how it works? I am using these lecture notes (this part starts on p. 53). Thank you in advance.","['matrices', 'linear-algebra', 'derivatives', 'multivariable-calculus']"
834601,Which functions have a list for all periodic points of them?,"I was searching for a method that finds all periodic points of a given function e.g. $f(x)=x-x^2$ on its domain. As @Did explained in comment it's too hard even though for polynomials of degree 2. So I change the question to list and categorize functions with all their periodic points. Definition : The point $x$ is a periodic point of period $n$ if $f^n(x) = x$.
(I will add functions which I know them as soon as I can.)
Please add new functions if you know.","['dynamical-systems', 'functions']"
834607,Is it possible to reverse a gradient ($\vec{\nabla}$) operation?,"In calculus, the antiderivative (indefinite integral) can be considered as the reverse operation of a derivative. A gradient yields a vector. Is there a similar way of reversing gradient, as you do with derivatives?","['calculus', 'vector-analysis']"
834629,Group theoretical characterization of $\mathbb Q$ and $\mathbb Q^\star$,"$\mathbb Z$ can be characterized in group-theoretic language as the infinite cyclic group. But what kind of a group is $\mathbb Q$ under addition? What about $\mathbb Q^\star$? What kind of subgroup structure do they have, and is there a canonical way to single them out as groups?","['group-theory', 'abstract-algebra']"
834674,Solve $y^{2/3}+(y')^{2/3}=1$ other than the direct method?,Is there any way to solve $$y^{2/3}+(y')^{2/3}=1$$ other than just solving for $y'$ and then integrate?,['ordinary-differential-equations']
834681,When residual standard error is equal to standard deviation of dependent variable in linear regression?,I wonder when residual standard error is equal to standard deviation of dependent variable in linear regression? Could someone provide some information on this topic and explanation?,"['statistics', 'regression']"
834683,Analysis or (abstract) algebra first?,Which one would you recommend? I only know calculus and linear algebra when it comes to university-level mathematics. Is one required to understand the other?,"['self-learning', 'abstract-algebra', 'real-analysis', 'learning', 'advice']"
834698,"Solve $ 3 e^x \tan{y} \, dx + \dfrac{2-e^x}{\cos^2{y}} \, dy = 0 $ Stupid error somewhere","I am trying to solve the following ODE $$ 3 e^x \tan{y} \, dx + \dfrac{2-e^x}{\cos^2{y}} \, dy = 0 $$ This is my attempt: Its form looks like,
$$P(x,y) \, dx + Q(x,y) \, dy = 0$$
so I may be exact or it may accept an integration factor. I have computed: $$\dfrac{\partial}{\partial y}P(x,y) = \dfrac{3 e^x}{\cos^2{y}} \qquad \qquad \dfrac{\partial}{\partial x}Q(x,y) = \dfrac{-e^x}{\cos^2{y}}$$ Unfortunately, these last two terms are not equal, so the equation is not homogeneous. Nevertheless we can find an integration factor because the following expression depends only on $x$ $$\dfrac{1}{Q(x,y)} \left(\dfrac{\partial}{\partial y}P(x,y)-\dfrac{\partial}{\partial x}Q(x,y) \right) = \dfrac{4 e^x}{2-e^x} $$ Thus the integration factor is $$ u(x) = \int \dfrac{4 e^x}{2-e^x}  \, dx = -4 \log{(2-e^x)} $$ Now, we multiply our ODE with $u(x)$ to get an equivalent but exact ODE $$ u(x) P(x,y) \, dx + u(x) Q(x,y) \, dy = 0$$ My problem is that this last ODE, which should be exact, is not. I have verify my computing with mathematica: Where did I mess up?",['ordinary-differential-equations']
834700,Can conditional expectation always be realized in a standard probability space?,"Given any integrable random variable $X : (\Omega, \mathcal F, \mathbb P) \to \mathbb R$ (where $(\Omega, \mathcal F, \mathbb P)$ is not necessarily a standard probability space) and a sub-sigma-algebra $\mathcal D \subset \mathcal F$, is it always possible to build another random variable $X'$ living on a standard probability space $(\Omega', \mathcal F', \mathbb P')$ and a sub-sigma-algebra $\mathcal D' \subset \mathcal F'$ such that $(X, E(X | \mathcal D))$ is equal in distribution to $(X', E(X'| \mathcal D'))$ (i.e., same joint distribution)? Also, is the same true for any countable collection of random variables $(X_i)_{i \in \mathbb N}$? That is, given $(X_i)_{i \in \mathbb N}$ and $\mathcal D \subset \mathcal F$, is it always possible to build $(X'_i)_{i \in \mathbb N}$ and $\mathcal D'$ living on a standard probability space such that the probability distribution of $((X_i, E(X_i | \mathcal D)))_{i \in \mathbb N}$ and that of $((X'_i, E(X'_i | \mathcal D')))_{i \in \mathbb N}$ is the same probability measure on $(\mathbb R^2)^{\mathbb N}$? Some cases If $\mathcal D$ is equal to $\sigma(Y)$ (up to null sets) for some random variable $Y$, then we can build $Y'$ and $(X'_i)_i$ living on a standard probability space such that $(Y, X_1, X_2, \cdots)$ is equal in distribution to $(Y', X'_1, X'_2, \cdots)$ (for example, we can build them on $\mathbb R \times \mathbb R^{\mathbb N}$ with the obvious push forward measure on it.) Then $((X_i, E(X_i | \mathcal D)))_{i \in \mathbb N}$ is equal in distribution to $((X'_i, E(X'_i | \mathcal D')))_{i \in \mathbb N}$ (where $\mathcal D' := \sigma(Y')$) because $E(X_i | \mathcal D) = g_i(Y)$ while $E(X'_i | \mathcal D') = g'_i(Y') = g_i(Y')$. I guess in the end it boils down to the issue of whether there is a pathological $\mathcal D$ on which conditional expectations behave irreparably bad. At first, I thought the perforated interval would give me a counter example, but the sigma algebra associated with the perforated interval, which is pathological in some sense, is generated by a random variable so it's not irreparably pathological. Motivation If the answer is no, the counter example would be an interesting example.","['probability-theory', 'measure-theory', 'conditional-probability']"
834723,Every finite group has a composition series,"Every finite group has a composition series. The proof of this statement is as follows Proof. If $|G| = 1$ or $G$ is simple, then the result is trivial. Suppose $G$ is not simple, and the result holds for all groups of order $< |G|$. Let $H$ be a maximal normal subgroup of $G$. By the induction hypothesis $H$ has a composition series ${e} \subset H_1 \subset \cdots \subset H$. Therefore, $G$ has a composition series  ${e} \subset H_1 \subset \cdots \subset H \subset G$. My question is, how can it be guaranteed that there exists a maximal normal subgroup of $G$ of order $< G$?","['finite-groups', 'group-theory', 'abstract-algebra']"
834733,Is the set of continuous function with Lebesgue zero set a Borel set in continuous space?,"Let $D$ be a domain in $\mathbb{R^d}$ and denote the continuous function space on $D$ as $X := C(\overline{D})$ where we can define the $\sigma$-algebra $\mathscr{B}(X)$ of $X$, that is sets in $X$ containing all open sets of $X$ and closed under countable unions and taking complements. We define the zero set of $u$ as $Z_u = \{x\in \overline{D}: u(x) = 0\}$ and denote $m(A)$ as the Lebesgue measure of $A\subset \overline{D}$. If $F: = \{u\in C(\overline{D}): m(Z_u) = 0\}$, can we prove that $F\in \mathscr{B}(X)$? It is easy to see that $F$ is not a closed set in $X$. But can we write $F$ as countable union of closed set or other form of Borel set? Otherwise, is there any counterexample to make that false?","['measure-theory', 'roots', 'real-analysis', 'descriptive-set-theory']"
834735,Show that $\left|X\right|=\left|Y\right|$,"Let $A, B$, two sets. $X$ is the set of all relations from $A$ to $B$, and $Y$ is the set of all functions from $A$ to $P(B)$ (power-set of $B$). Prove that $\left|X\right|=\left|Y\right|$. My Solution: $\left|A \right| = a$,
$\left|B \right| = b$ $\left|Y\right| = \left| A\rightarrow P(B) \right| = \left| P(B) \right|^{\left|A \right|} = (2^b)^a = 2^{ab}$ $\left|X \right| = \left|P(A\times B \right)|$ $(*)$ Now, since every $\left<a,b\right>$ can be in the relation or not. We have $2^{ab}$ relations. I've been told I didn't treat the infinite case (Maybe the meaning is I cannot use $(*)$ for the infinite case). What should I do instead (or in addition to the finite case)? Update: I was guided not use functions. Instead, I should show it using cardinals arithmetics.","['cardinals', 'elementary-set-theory']"
834762,How does Wolfram get from the first form to the second alternate form?,"So, I was trying to compute an integral but I couldn't actually manage getting anywhere with it in its initial form. So, I inserted the function in Wolfram Alpha and I really got a nicer form (second alternate form). But I want to understand how that was done, I really need some help here. Input: $\dfrac{1}{(e^t + 1)(e^t + 2)(e^t + 3)}$ Alternate forms: $\dfrac{1}{11e^t + 6e^{2t} + e^{3t} + 6}\\
-\dfrac{1}{e^t + 2} + \dfrac{1}{2(e^t + 3)} + \dfrac{1}{2(e^t + 1)}
$","['algebra-precalculus', 'functions', 'partial-fractions']"
834773,Elements of subfield $F_{8}$ of $F_{2}[x]/(x^{6}+x+1)$,I need to find the elements of the subfield $F_{8}$ of $F_{2}[x]/(x^{6}+x+1)$ in their standard representation. I know that $F_{2}[x]/(x^{6}+x+1)$ represents the residu classes of polynomials modulo $(x^{6}+x+1)$ with coefficients either 0 or 1. There are $2^{6}$ of those residu classes because we work with the finite field of 2 elements and the degree of the polynomial is 6. $F_{8}$ is the finite field with 8 elements and I can perfectly construct this finite field. However I have difficulty seeing that $F_{8}$ is a subfield of $F_{2}[x]/(x^{6}+x+1)$. Can someone guide me in the right direction?,"['finite-fields', 'discrete-mathematics', 'abstract-algebra']"
834780,Probabilities of this blackjack hybrid,"I am currently trying to study a hybrid / simplified version of Black Jack but as i am not as good with probabilities i am hoping that i could receive some advice about the probabilities behind the game. The rules of the game: The three face cards are all worth 10 points, just like the real BlackJack. The Ace card has a behavior where it gets the value of 11/1. To understand the logic in this hybrid, simply assume that Ace has a value of 11 however if the total goes over 21, minus 10 from the total. All cards are chosen randomly by a computer and hence the same cards can be repeated and the probability of selection of a particular card is independent of the probability of the cards that came before it. All other cards have values 1-9, same as their real number. However the gameplay is modified and simplified The player starts the game and gets two random cards. If the total of these cards adds up to 21 (I.e one ace and one face card) the player immediately wins. If the total is not 21, the player is free to draw as many cards as possible but if the total goes over 21, he loses. Once he's satisfied with the total, he 'stands'. Then the dealer tries to draw cards and beat the player's total without going over 21. What i am wondering is what is the probability that the player wins the game? Also what would be the best number to stop drawing further cards as the player?","['statistics', 'probability']"
834784,"If the integral of a non-negative function is $0$, then the function is $0$","Suppose that $f$ is a continuous function on $[a,b]$ and that $f(x)\geq0$ for all $x\in [a,b]$. Show that if $\int_a^bf(x)=0$, then $f(x)=0$ for all $x\in[a,b]$. Let $F(x)=\int_a^xf(x)$. Since $\int_a^xf(x)+\int_x^bf(x)=\int_a^bf(x)=0$ for every $x\in[a,b]$, we have $\int_a^xf(x)=-\int_x^bf(x)$. But since $f(x)\geq0$ for all $x\in[a,b]$, both $\int_a^xf(x)$ and $\int_x^bf(x)$ are positive. So $F(x)=0$ for all $x\in[a,b]$ and by the fundamental theorem of calculus, $f(x)=F'(x)=0$ for all $x\in[a,b]$. Is this a valid proof?","['definite-integrals', 'proof-verification', 'real-analysis', 'solution-verification']"
834786,Log concavity of binomial coefficients: $ \binom{n}{k}^2 \geq \binom{n}{k-1}\binom{n}{k+1} $,"How do we prove that Binomial coefficients are log-concave ? A sequence $a_0, \dots, a_n$ is log-concave if $a_k^2 \geq a_{k-1}a_{k+1}$. $$ \binom{n}{k}^2 \geq \binom{n}{k-1}\binom{n}{k+1} $$ If $ n >> k$  I suppose we get some estimates related to Poisson distribution : $\binom{n}{k} \approx \frac{n^k}{k!} $ $$ \left(\frac{n^k}{k!}\right)^2 \geq \frac{n^{k-1}}{(k-1)!} \frac{n^{k+1}}{(k+1)!} \hspace{0.25in}\text{ or }\hspace{0.25in} k!^2 \leq (k-1)!(k+1)!$$ In my homework, I have a product of 3 binomial coefficients and I want to know if I can replace them with the average: $$ \binom{n}{\frac{a+b+c}{3}}^3 \geq \binom{n}{a}\binom{n}{b}\binom{n}{c} $$","['inequality', 'combinatorics']"
834787,Concentration set of a weak star limit of a sequence of measures.,"Let $I=[0,1]$, $\lambda$ the Lebesgue measure and $\mu$ a non negative Borel measure. Assume that $g_n$ is a sequence of non neagative continuous functions satisfying: $$g_n(x)\to 0\ a.e.\ \mbox{and}\ \int_Ig_n(x)dm=1.$$ Note that $g_ndm$ are Borel measures. If $g_n dm$ converge in the weak star topology to $\mu$, i.e. $$\lim_n\int_I fg_ndm=\int_I f
d\mu
,\ \forall f\in C(I),$$ can we conclude that $\mu\perp \lambda$? The result seems true to me and I was betting that the support of $\mu$ is contained in the set $$\{x\in I:\ \lim_n g_n(x)\neq 0\},$$ which I think, is equal to the sets $$\{x\in I:\ f(x)=\int_I fd\mu,\ \forall f\in C(I)\}=\{x\in I:\ \lim_n g_n(x)=\infty\}.$$ Any help is appreciated.",['measure-theory']
834788,Difference between Topological Data Analysis and Graph Technology,"I'm trying to understand the difference between Oracle's graph technology, which apparently has an inherent understanding of topology, and Ayasdi's Topological Data Analysis technology. Are these two completely different and where does one draw the line when distinguishing them? Is Oracle's graph technology operating on a completely different domain (in terms of topology) than Ayasdi's algebraic topological data analysis approach? Thanks in advance!","['topological-data-analysis', 'general-topology', 'abstract-algebra', 'graph-theory', 'data-analysis']"
834789,Image of a proper class under one-one function is a proper class,Working under Zermelo-Franenkel set theory. how I can prove following: Let $V$ be proper class. Let $F : V \rightarrow U$ be a one-one function. Then $U$ has to be a proper class.,['elementary-set-theory']
834816,Show that a connected graph on $n$ vertices is a tree if and only if it has $n-1$ edges.,"Can someone please verify this? Show that a connected graph on $n$ vertices is a tree if and only if it has $n-1$ edges. $(\Rightarrow)$ If a tree $G$ has only $1$ vertex, it has $0$ edges. Now, assume that any tree with $k-1$ vertices has $k-2$ edges. Let $T$ be a tree with $k$ vertices. Remove a leaf $l$ to obtain a tree $T'$ with $k-1$ vertices. Then, $T'$ has $k-2$ edges, by the inductive hypothesis. The addition of $l$ to $T'$ produces a graph with $k-1$ edges, since $l$ has degree $1$. $(\Leftarrow)$ Let $G$ be a connected graph on $n$ vertices, with $n-1$ edges. Suppose $G$ is not a tree. Then, there exists at least one cycle in $G$. Successively remove edges from cycles in $G$ to obtain a graph $G'$ with no cycles. Then, $G'$ is connected and has no cycles. Therefore, $G'$ is a tree, with $n$ vertices and $n-1-x$ edges, for some $x > 0$. However, this contradicts the previous derivation. Therefore, it must be the case that $G$ is a tree.","['graph-theory', 'proof-verification', 'combinatorics']"
834824,Multiple antiderivatives?,"The way I have seen the fundamental theorem of calculus stated is: $$\int_a^bf(x)\ dx=F(b)-F(a)$$ Where $F(x)$ is any antiderivative of $f(x)$. Does the ""any antiderivative"" refer to the constant $C$ that is always added to the integral, or are there functions that have several completely different antiderivatives?","['calculus', 'integration']"
834841,Hint for solving $ y (y')^2 + (x-y) y' - x = 0$,Need to solve the following ODE: $$ y (y')^2 + (x-y) y' - x = 0$$ I don't really know how to start. Any hints?,['ordinary-differential-equations']
834858,The abelian group of homeomorphism,"Let $G$ be a subgroup of the group of homeomorphisms on the circle, and we suppose $G$ is abelian, if every element of $G$ has a fixed point on the circle, does it imply that $G$ has a common fixed point?","['general-topology', 'dynamical-systems', 'group-theory']"
834862,Is $\sqrt{x}$ concave?,"I have function $f(x)= \sqrt(x)$. To check is it concave or convex i am checkin $f''(x). $
Which is $ -\frac{1}{4x^{\frac{3}{2}}} < 0$ So the $f(x)$ is concave.  Is it correct ? And is is the same with $f(x)=arctan(x)$,  $f''(x)= -\frac{2x}{(x^{2}+1)^{2}}<0$. It is concave ?","['convex-analysis', 'locally-convex-spaces', 'functions']"
834867,Real solution of the equation $(x^2-2x+2)^2-2(x^2-2x+2)+2 = x$,"Calculate all real solutions $x\in\mathbb{R}$ of the equation
  $$
\tag1(x^2-2x+2)^2-2(x^2-2x+2)+2 = x
$$ My Attempt: I used the concept of a composite function. Let $f(x) = x^2-2x+2$. Then equation $(1)$ converts into $f(f(x)) = x$. Both $f(x) = x$ and $f(x) = -x$ satisfy the given composite function. Case 1: If $f(x) = x$, then $$
x^2-2x+2=x\\
x^2-3x+2=0\\
x\in\{1,2\}
$$ Note that $1,2\in\mathbb{R}$. Case 2: If $f(x)=-x$, then $$
x^2-2x+2=-x\\
x^2-x+2=0\\
x=\frac{1\pm \sqrt{1-8}}{2}\notin \mathbb{R}
$$ So only $x\in\{1,2\}$ are the real solutions of above equation. Is my process correct? Is there is any other method by which we can solve the above question?",['algebra-precalculus']
834874,Determine if a particular matrix is diagonalizable,"my teacher gave me this exercise: Determine if this matrix is diagonalizable
$
\begin{pmatrix}
1 & 1&1&1\\ 
1&2&3&4\\ 
1&-1&2&-2\\ 
0&0&1&-2 
\end{pmatrix}
$ I have tried to calculate the characteristic polynomial, that is $-13 + 10 x + x^2 - 3 x^3 + x^4$, but I don't know how to go on. 
I tried to look at the roots of the characteristic polynomial with Wolfram Alpha and they are horrible! So I think that must exist an alternative way to do it!
Have you got any ideas? Thank you!","['matrices', 'linear-algebra', 'diagonalization']"
834924,Elements with order 3 in group $F_{16}/\{0\}$,"If you have the finite field $GF(16)$ and you define the group $GF(16)/\{0\},*$ this group is cyclic. I need to determine how many elements in this group have order 3. Of course you could just try out all elements but I wonder if there isn't a more efficient technique. I don't need to know which elements have order 3, just how many.","['finite-fields', 'discrete-mathematics', 'abstract-algebra']"
834962,How to find the value of $4\cos(\frac{\pi}{26})+\tan(\frac{2\pi}{13})$,I have found in wolfram alpha that $\displaystyle 4\cos\left(\frac{\pi}{26}\right)+\tan\left(\frac{2\pi}{13}\right)=\sqrt{13+2\sqrt{13}}$. How to prove this identity ? Thank you.,['trigonometry']
834966,Is the dihedral group $D_n$ nilpotent? solvable?,Is the dihedral group $D_n$ nilpotent? solvable? I'm trying to solve this problem but I've been trying to apply a couple of theorems but have been unsuccessful so far. Can anyone help me?,"['dihedral-groups', 'solvable-groups', 'abstract-algebra', 'nilpotent-groups', 'group-theory']"
834981,Let $G$ be a graph of girth $5$ for which all vertices have degree $\geq d$. Show that $G$ has at least $d^2+1$ vertices.,"Could someone verify this? Pick a vertex $v$ of $G$. Pick distinct vertices $u_1, u_2, \ldots, u_d$ incident with $v$. Note that this can be done since $v$ has no loops and degree $\geq d$. For each $u_i$, pick distinct vertices $w_i^{(1)}, w_i^{(2)}, \ldots,  w_i^{(d-1)}$ incident with $u_i$ other than $v$. Then, $$w_i^{(k)} \neq w_j^{(l)}$$
To see this, note that $v, u_i, w_i^{(k)}, u_j, v$ would form a cycle of length $4$. Also,
$$w_i^{(j)} \neq u_k$$
To see this, note that $v, u_k, u_i, v$ would form a cycle of length 3. Also, $$v \neq w_i^{(j)}$$ Otherwise, $v, u_i, v$ would form a cycle of length $2$. So, all of the edges $v, u_1, \ldots, u_d, w_1^{(1)}, \ldots, w_d^{(d-1)}$ are distinct. So, the graph contains at least $1+d+d(d-1) = 1+d^2$ vertices.$~~~~~~~~~$","['graph-theory', 'proof-verification', 'combinatorics']"
834985,In how many ways can 4 girls and 3 boys sit in a row such that just the girls are to sit next to each other? Answer: 288,"In how many ways can 4 girls and 3 boys sit in a row such that just the girls are to sit next to each other? Answer: 288 Please explain how to get this. I understand that we have GGGG => 4 girls next to each other
B B B => 3 boys but how do you put them together and work out the number of possible ways. They are different so not identical","['statistics', 'order-statistics', 'combinatorics']"
834987,Are there finite-dimentional unital associative algebras over $\Bbb{C}$ that are not isomorphic to a group algebra $\Bbb{C}[G]$ for finite group G?,"I've seen somewhere in my lecture notes that the answer is yes, but I can't think of an explicit example of such an algebra. Is there a standard way of constructing these algebras for particular groups G?","['finite-groups', 'group-theory']"
834991,What level of rigour is expected in Real Analysis?,"I fail to find a duplicate. I am wondering what level of rigour is needed in a typical undergraduate course in Real Analysis. To clarify my question, I provide an exercise from Rudin and my proposed solution: (Exercise 5, Chapter 1) Let $A$ be a nonempty set of real numbers which is bounded below. Let $-A$ be the set of all numbers $-x$, where $x \in A$. Prove that $$\inf A = -\sup(-A)$$ My answer: $A$ is bounded below. As such, $-A$ must be bounded above. Suppose $\alpha$ is the greatest lower bound of $A$.  It follows that $-\alpha$ is the least upper bound of $-A$. As such, we arrive at the desired expression $$\inf A = -\sup(-A)$$ This, for instance, feels very short, but I also feel that there is not much more to be said here. While this task might possibly be a bad example, I dare to guess that the most common pitfall for young students entering higher mathematics is that they underestimate the rigour needed to solve seemingly trivial problems. As such, I ask for an elaboration on this. The provided example does not necessarily have to be used in your answer.","['soft-question', 'real-analysis']"
835008,In how many ways can $7$ girls and $3$ boys sit on a bench in such a way that every boy sits next to at least one girl,"In how many ways can $7$ girls and $3$ boys sit on a bench in such a way that every boy sits next to at least one girl The answer is supposedly $1,693,440 + 423,360 = 2,116,800$",['combinatorics']
835010,Skew-symmetric matrix and exp function $e^A$,"Let $A_{nXn}(\mathbb{R})$ Skew-symmetric matrix $A=-A^t$ prove that $e^A(e^A)^t=I$ while:
$e^A=\sum_{i=0}^{\infty} \frac{A^n}{n!}$ I tried this:
$A=-A^t \Rightarrow A$ is Diagonalizable with orthogonal basis over
  $\mathbb{C}$ $\Rightarrow A=PDP^*$and $P^*=P^{-1}$ 
and D is:
 \begin{pmatrix}
  \lambda_1 &0 & \cdots & 0 \\
  0 & \lambda_2 & \cdots & 0 \\
  \vdots  & \vdots  & \ddots & \vdots  \\
 0 & 0 & \cdots & \lambda_n
 \end{pmatrix}
we know that :$\lambda_i=0$ or $\lambda_i=ib$ for $b \in R$  because A is Skew-symmetric matrix.
so: $e^A=Pe^DP^t$
so if I will prove that $\lambda_i=0$ we will get $e^A=PP^t=I$. Is it possible?","['matrices', 'linear-algebra', 'exponential-function']"
835016,Show that a group of order $p^2q^2$ is solvable,"I am trying to prove that a group of order $p^2q^2$ where $p$ and $q$ are primes is solvable, without using Burnside's theorem. Here's what I have for the moment: If $p = q$, then $G$ is a $p$-group and therefore it is solvable. If $p \neq q$, we shall look at the Sylow $p$-subgroups of $G$. We know from Sylow's theorems that $n_p \equiv 1 \pmod p$ and $n_p \mid q^2$, therefore $n_p \in \{1, q, q^2\}$. If $n_p = 1$, it is over, because the Sylow $p$-Subgroup $P$ is normal in $G$ of order $p^2$, and $G/P$ has order $q^2$. Thus both are solvable and $G$ is solvable. If $n_p = q^2$, we have $q^2(p^2-1)$ elements of order $p$ or $p^2$ in $G$, and we have $q^2$ elements left to form a unique Sylow $q$-subgroup. By the same argument as before, $G$ is solvable. That's where I'm in trouble. I don't know what to do with $n_p = q$. It seems to lead nowhere. Thanks in advance for any help! Laurent","['solvable-groups', 'group-theory', 'abstract-algebra']"
835017,Using binary entropy function to approximate log(N choose K),"I am not a mathematician and struggling with the exercises while reading this book Information Theory, Inference and Learning Algorithms . The author introduced the binary entropy function at the start of the book as $$
H \equiv x \log \frac{1}{x} + (1-x) \log \frac{1}{(1-x)}
$$ He shows it can be used to approximate $$
\log \binom{N}{r} \simeq NH(\frac{r}{N})
$$ I am puzzled how he got to this approximation. Please could someone explain why?","['probability-theory', 'information-theory']"
835022,Convergence of random harmonic series,"The problem is to show that the random harmonic series $X_n:=\sum_{n=1}^{\infty}\frac{\nu_n}{n}$ with $P[\nu_n = 1] = P[\nu_n = -1] = \frac{1}{2}$ converges. It is obvious that the harmonic series diverges and the alternating harmonic series converges. Also I am positive that the random harmonic series converges almost surely. Say I want to prove this with Kolmogorov's 3 series theorem where I need to show convergence of the three following series. $\sum_{n=1}^{\infty}P[X_n \neq Y_n]$ $\sum_{n=1}^{\infty} E[Y_n]$ $\sum_{n=1}^{\infty}var[Y_n]$ where $Y_n:= X_n 1_{\{|X_n|\leq c\}}$ I already have $E[\nu_n] = 0$ $E[X_n] = 0$ $var[\frac{\nu_n}{n}] = \frac{1}{n^2}$ and $var[\sum_{n=1}^{\infty}\frac{\nu_n}{n}] = \sum_{n=1}^{\infty}\frac{1}{n^2} = \frac{\pi^2}{6}$ I need help with 1. and I am not really sure what the difference between $X_n$ and $Y_n$ is. Is it just enough to say that since $X_n \geq Y_n$ and $\sum_{n=1}^{\infty} E[X_n]$ converges, 2. converges and $\sum_{n=1}^{\infty}var[X_n]$ converges, so 3. converges? I don't really understand this. Any help would be great.","['convergence-divergence', 'probability']"
835042,$f(0)=f'(0)=f'(1)=0$ and $f(1)=1$ implies $\max|f''|\geq 4$,"Let $f\in C^2(\mathbb [0,1],\mathbb [0,1])$ such that $f(0)=f'(0)=f'(1)=0$ and $f(1)=1$ Prove that $\max_{[0,1]}|f''|\geq 4$ Progress Applying Cauchy mean value theorem three times proves the existence of $\xi\in (0,1)$ such that $f'(\xi)=1$ $\eta\in(\xi,1)$ such that $\displaystyle f''(\eta)=\frac{1}{\xi-1} <0$ $\beta\in(0,\xi)$ such that $\displaystyle f''(\beta)=\frac{1}{\xi}>0$ If $\displaystyle \xi\leq \frac{1}{4}$ or $\displaystyle \xi\geq \frac{3}{4}$ , we're done. What about other cases ? I haven't used the continuity of $f''$ yet...","['calculus', 'real-analysis']"
835046,Show that $0=x^x$ has no solution in $\mathbb{R}$.,"I want to show that $0=x^x$ has no solution for $x > 0$ in $x \in \mathbb{R}$. I know that there isn't a solution, but I don't know how to show it mathematically. EDIT: What I have finally written in my exercise as proof: $x^x = 0$ $\Leftrightarrow x = \dfrac{ln(0)}{ln(x)}$ $\Rightarrow ln(0)$ is not defined, therefore no solution exists.",['calculus']
835047,Time derivative of flux,"We have a time and even ""position"" invariant vector field and a surface. If the surface is moving with constant velocity, is the flux through the surface should constant in time?
Also, is there an easy to follow proof for the formula
$$\frac{d}{dt} \iint_{S(t)}\overline{V}(\overline{r},t) \cdot d\overline{A}  $$",['multivariable-calculus']
835050,Alternating second power Euler sum $\sum_{k\geq 1} \frac{(H'_k)^2}{k^2}$,"Question: Evaluate $$\sum_{k\geq 1} \frac{(H'_k)^2}{k^2}$$ Where we define the alternating harmonic number $$H'_k=\sum_{n=1}^k\frac{(-1)^n}{n}$$ I remember seeing a closed form involving a quadrilogarithm. I am interested in knowing the full solution, if possible.","['special-functions', 'polylogarithm', 'sequences-and-series']"
835054,Discrete math: Sum of Geometric series on a problem - Notes make little sense.,"I've been reading a PDF of slides from my Discrete Math I professor. The title is Sums, Products and Asymptotic Estimations. He gives us a problem to fire off the lecture, which is the following: In a TV game show, the host is willing to give you 50,000€ every year for 20
years, or 750,000€ right in your hands. 

What would be the most profitable choice, if you knew that the interest rate
in the bank is 3% every year? He then goes on, in the notes, and says that the total value of per-year reward is $\sum\limits_{i=0}^{19}\frac{50000}{(i+p)^i}$ Right after that, to calculate the sum, he's got a slide titled ""Summation of geometrical series"", in which he writes: 
$\begin{split}
S(k) & = x^0 + x^1 + ... + x^k \\
-xS(k) & = -x^1 - x^2 - ... - x^{k+1} \\
S(k) - xS(k) & = 1 - x^{k+1} \Rightarrow S(k) = \frac{1-x^{k+1}}{1-x}
\end{split}$ Finally, he finishes by referencing the problem again, this time saying As we calculated, it is more profitable to get 50,000€ for 20 years
as it has a value of 766,190. Could anyone point me in the right direction or assist me in finding out how he came to that conclusion? I cannot, for the life of me, understand how he ended up with that result. Isn't $x$ here supposed to be $\frac{1}{1.03^i}$ ?","['summation', 'sequences-and-series', 'discrete-mathematics']"
835088,To sample or not to sample?,"I have the following issue (I want to predict sports results). Let $X$ be a discrete RV with $m$ possible outcomes, each having probability $p_i$, for $i=1,\ldots,m$. Assume that I have a large iid sample $X_1,\ldots,X_n$, where each variable has the same distribution as $X$. Now, to make a prediction for each $X_k$ (before its actual value is drawn) I could just always predict outcome $i^*$ with largest probability $p^*_i$. Then, in expectation, I would be right on $n\cdot p^*_i$ samples. Alternatively, I could sample from the distribution of $X$, that is, for each $X_k$ predict value $i$ according to $p_i$. Then, the probability that my prediction for $X_k$ equals the actual draw of $X_k$ is $$q=P[\hat{X}_k=X_k]=\sum_{i=1}^m P[\hat{X}_k=i]P[X_k=i]=\sum_{i=1}^m p_i^2.$$ Thus, according to this approach, the probability that I am correct on $r$ predictions is $B(r;n,q)=\binom{n}{r}q^r(1-q)^{n-r}$. Now, what is the probability that this approach gives me at least $n\cdot p_i^*$ correct results (i.e., $B(n\cdot p_i^*;n,q)+\cdots+B(n;n,q)$)? Are there any known general results on this? How does the answer depend on the distribution of $X$ (e.g. uniform, skewed, ...)? In other words, should I sample (approach 2) or just predict the most probable outcome (approach 1)? (Did I make any mistakes somewhere?)","['statistics', 'sampling', 'probability']"
835108,"How can I find the roots of a quartic equation, knowing one of its roots?","I need to decompose (in $\Bbb{C}[x]$) the function $$
f(x) = x^4 + 4x^3 - 4x^2 + 24x + 15
$$ in its simplest form, knowing that $1 - 2i$ is one of its roots. Any ideas?","['algebra-precalculus', 'abstract-algebra', 'polynomials']"
835111,Integer solutions to $a^{2014} +2015\cdot b! = 2014^{2015}$,"How many  solutions are there for $a^{2014} +2015\cdot b! = 2014^{2015}$, with $a,b$ positive integers? This is another contest problem that I got from my friend. Can anybody  help me  find the answer? Or  give me a hint to solve this problem? Thanks","['contest-math', 'number-theory']"
835145,Under what conditions can a function $ y: \mathbb{R} \to \mathbb{R} $ be expressed as $ \dfrac{z'}{z} $?,"Can an arbitrary function $ y: \mathbb{R} \to \mathbb{R} $ always be expressed as $ \dfrac{z'}{z} $ for some differentiable function $ z: \mathbb{R} \to \mathbb{R} $, or are additional conditions on $ y $ needed for this to be true? This question was inspired by reading a writeup about differential equations, where the change of variables $ y = \dfrac{z'}{z} $ is made.","['ordinary-differential-equations', 'calculus', 'derivatives', 'real-analysis']"
835158,Find the principle value and all other values of $i^{2/\pi}$,"I'm a little confused about how to go about this? Any help would be appreciated, thanks.","['complex-numbers', 'complex-analysis']"
835178,Elliptic functions surjective,Is it true that every nonconstant elliptic function $f:\mathbf{C}/\Lambda\rightarrow\mathbf{P}^1$ is surjective? (I take elliptic functions to be defined on the torus $\mathbf{C}/\Lambda$) For how is it otherwise true that $\# f^{-1}(c)$ is independent of $c\in\mathbf{P}^1$?,"['elliptic-functions', 'complex-analysis']"
835221,Using paraboloidal coordinates,"I have the 3-dimensional paraboloidal coordinates $$s_{\pm}=\sqrt{x^2+y^2+z^2}\pm z$$
$$\phi=ArcTan(y/x)$$
with the inverse transformation
$$x=\sqrt{s_+ \cdot s_-}\cdot cos(\phi)$$
$$y=\sqrt{s_+ \cdot s_-}\cdot sin(\phi)$$
$$z=\frac{s_+ - s_-}{2}$$ Questions: Properties in integration: Suppose I have $ I= \int_{0}^{\infty} ds_+ \int_{0}^{\infty} ds_- f(s_+,s_-) \cdot \delta(s_+ - t)$, can I naively apply the Dirac-Delta and get $I=\int_{0}^{\infty} ds_- f(t,s_-)$ ? Properties in differentiation: Suppose I have $D=\frac{\partial}{\partial s_-} e^{2\cdot s_-} \cdot s_+$, can I naively ignore the $s_+$ Term and get $D=2\cdot e^{2\cdot s_-} \cdot s_+$ ? Every hint will be much appreciated!","['coordinate-systems', 'analysis']"
835222,How to express $z'(t)$ and $w'(t)$ in terms of $z(t)$ and $w(t)$?,"I have these functions: $x' (t) = −5x(t) + 2 y(t)$ $y' (t) = 2x(t) − 2y(t)$ where $x(0)=10$ and $y(0)=0$ I am also given these 2 functions: $z(t) = x(t) + 2y(t)$ $w(t) = −2x(t) + y(t)$ First question is to express $z'(t)$ and $w'(t)$ in terms of $x'(t)$ and $y'(t)$ so: $z'(t) = x'(t) + 2y'(t)$ $w'(t) = -2x'(t) + y'(t)$ Easy enough. I am then asked to express $z'(t)$ and $w'(t)$ in terms of $z(t)$ and $w(t)$, but I don't know how to do that! Can I get some pointers? Thanks!","['ordinary-differential-equations', 'systems-of-equations', 'derivatives']"
835225,"Find all positive integer solutions $(x,y,z)$ that satisfy $5^x \cdot 7^y +4= 3^z$?",This is another contest math-problem. The only problem that I cannot find the way to tackle this problem. Can anybody try to provide the solution to solve this problem? Thanks,"['contest-math', 'number-theory']"
835233,Why this function defines a bijection?,"Show that if $B\subset A$ and there is an injective function $f:A\to B$, then $\operatorname{card}(A)=\operatorname{card}(B)$. This exercise suggest a way to solve the problem: define $A_1=A, B_1=B$ and $A_n=f(A_{n-1}),B_n=f(B_{n-1})$. Since $A \subset B$ we have $A_{n+1}\subset B_n\subset A_{n-1}$ for $n\geq2$. Then define $$h(x) =  \left\lbrace
  \begin{array}{l}
     f(x) &\text{ if } x \in A_n-B_n \text{ for some n}\\
     x &\text{ otherwise } \\
  \end{array}
  \right.$$ And the above function is supposed to define a bijection, but I cannot see why the function is injective, I mean, why isn't this possible: I imagine the problem about injectivity as in the picture I draw, $x\in A_1 - B_1$ then $h(x)=f(x)=y$, but since $y\notin A_n-B_n$ for any $n$ and $y\in A$ must be $h(y)=y$ as well.","['cardinals', 'elementary-set-theory']"
835258,"In a compact space, every net has a convergent subnet","I'm just learning how to work with nets. I'm attempting the proof that $X$ compact $\implies$ every net in $X$ has a convergent subnet, and I wonder if I'm overcomplicating it. Suppose $\langle x_i \rangle _{i \in I}$ is a net in $X$. Define $F_i\subset X$ as $F_i := \operatorname{Cl} \left(\{ x_j: j \succeq i \}  \right)$. Observe that $\{ F_i \}$ has the finite intersection property, because given $\cap_{k=1}^n F_{i_k}$, take $i^*:= \operatorname{Join}(i_1, \dotsc, i_n)$ and then $x_{i^*} \in \cap_{k=1}^n F_{i_k}$. Now by compactness, there exists $x\in \cap_{i \in I}F_i$. It seems clear that the net should ""return frequently"" to each neighborhood of $x$, and so we can define a convergent subnet. But my construction of the subnet became somewhat involved, and I wondered if there was a simpler way. I have to find a directed set $J$ and a function $g: J \to I$ such that $j_1 \succeq j_2 \implies g(j_1) \succeq g(j_2)$ and $g(J)$ is cofinal in $I$. What I chose for $J$ were tagged neighborhoods $\mathcal{O}$ of $x$, ""tagged"" with an element $i \in I$ such that $x_i \in \mathcal{O}_i$. Now we can order $J$ by $\mathcal{O}_{i_1} \succeq \mathcal{O}_{i_2}$ iff $\mathcal{O}_{i_1} \subseteq \mathcal{O}_{i_2}$ and $i_1 \succeq i_2$. Now define the function $g:J \to I: \mathcal{O}_i \mapsto i$. (The tags have allowed the same neighborhood be considered as different elements in $J$ based on their various tags.) I claim $J$ is a directed set with well-defined join, that $g(J)$ is cofinal in $I$, and that it defines a subnet that converges to $x$. Does anyone have a less complicated way to construct the convergent subnet?","['general-topology', 'compactness', 'nets']"
835267,Show that $V = U^\perp \bigoplus U$,"If $(V,\langle , \rangle)$ is a Euclidean vector space, $U \subseteq V$ is a subspace of V and $U^\perp := \{v \in V | \langle v,u \rangle = 0, \forall u \in U\}$. Show $V = U^\perp  \bigoplus U$ In the first part I proved that $U^\perp$ is a linear subspace of V already. I need to prove that $V = U^\perp + U$ and $U^\perp \cap U = \{0\}$. For $U^\perp \cap U = \{0\}$ I have: $0 \in U^\perp \cap U$ since $U,U^\perp$ are subspaces of V. Also if $u \in U^\perp \cap U \Rightarrow \langle u,u \rangle = 0$, but by the definition of the inner product it follows that $u=0$. But how can I prove that $V = U^\perp + U$?","['linear-algebra', 'inner-products']"
835273,probability distribution of X+Y,"Let a fair die be rolled 2 times. The 2 rolls are independent. Let X and Y be the outcomes of the first and second rolls, respectively. a. What is the probability distribution of X+Y? What is each unique possible value of X+Y and each possibility’s corresponding probability. b. What is the probability that X+Y is greater or equal to 10? Answer:
I previously posted this without making an attempt. Here is my attempt to this: a) 2 happens 1 time, 3 - 2 times, 4 - 3 times, 5 - 4 times, 6 - 5 times, 7 - 6 times, 8 - 5 times, 9 - 4 times, 10 - 3 times, 11 - 2 times, 12 - 1 time. so the probability distribution is: 1/36, 2/36, 3/36, 4/36, 5/36, 6/36, 5/36, 4/36, 3/36, 2/36 and 1/36, respectively. b) since 10 happens 3 times, 11 - 2 times, and 12 - 1 time, answer is 6/36.",['probability']
835276,Mean of random sum of random variable,"Suppose that we have $X_1, X_2, \ldots$ is a sequence of i.i.d random variables with $E(X_i)<+\infty$ and $N$ is a random variable taking values in $\{1,2,\ldots\}$, $N$ is independent with $X_1, X_2, \ldots$. I know that
$$E\left(\sum_{i=1}^N X_i \right) = E(N)E(X_1)$$ If I divide the sum by $N$, 
$$M = \frac 1N \sum_{i=1}^N X_i  $$
I have sample mean of $X_1, X_2,\ldots, X_N$ but $N$ is random.
In this case, what is the distribution of $M$ and how to calculate $E(M)$ and $Var(M)$. Thanks.","['statistics', 'probability-distributions', 'probability', 'probability-theory']"
835278,Simple proof that product of the diagonals of a polygon = N,"There is a beautiful fact: If you take a regular N-sided polygon, which is inscribed in the unit circle and find the product of all its diagonals (including two sides) carried out from one corner you will get N exactly: $A_1A_2\cdot A_1A_3\cdot ...\cdot A_1A_N = N$ For example, for a square we have $\sqrt{2}\cdot 2\cdot \sqrt{2} = 4$ . I know there is some prove, which is based on complex numbers. But the result is so simple that I wonder is there much more simple prove, which you can explain to a school boy easily? P.S. Please, use spoiler tag >! in your answers.","['geometry', 'polygons']"
835283,Is a function $f$ with $f(X)\perp (I-f)(X)$ necessarily linear?,"Let $X$ be a real or complex inner-product space, and let $f : X\rightarrow X$ be a function such that every element of $f(X)$ is orthogonal to every element of $(I-f)(X)$. Prove or give a counterexample to the claim that $f=P$ where $P$ is a linear, orthogonal projection, i.e.,
$$
           P^{2}=P,\;\; (Px,y)=(x,Py),\;\; x,y \in X.
$$","['inner-products', 'functional-analysis']"
835308,Limit of $f_n(x) = n\log(\frac{nx+1}{nx-1})$ and its uniform covergence,"Let $f_n(x) = n\log(\frac{nx+1}{nx-1})$. What is the pointwise limit of $f_n$ for $x \in[1,\infty]$? Is it uniformly convergent? $$\lim_{n\longrightarrow \infty}n\log(\frac{nx+1}{nx-1})=\lim_{n\longrightarrow \infty}\frac{\log\left(\frac{x+\frac{1}{n}}{x-\frac{1}{n}}\right)}{\frac{1}{n}}\stackrel{H}{=}\lim_{n\longrightarrow \infty}\frac{\frac{-2x}{n^2}\frac{1}{(x-\frac{1}{n})(x+\frac{1}{n})}}{\frac{-1}{n^2}}=\lim_{n\longrightarrow \infty}\frac{2x}{(x-\frac{1}{n})(x+\frac{1}{n})}=\frac{2}{x}$$
Is that correct? And how to check uniform covergence? I would really like not to search for $\sup$ of $|n\log(\frac{nx+1}{nx-1}) - \frac{2}{x}|$...","['sequences-and-series', 'calculus', 'uniform-convergence', 'limits']"
835318,About globally generated Sheaves,"On Vakil's Lecture Notes, he puts an important  exercise that says: ''Suppose $\cal{F}$ is a finite type quasicoherent sheaf on a scheme $X$. Show that$\cal{F}$ is globally generated at $p$ if and only if “the fiber of $\cal{F}$ is generated
by global sections at $p$”, i.e., the map from global sections to the fiber $\cal{F}_p/\cal{m}_p\cal{F}_p$ is surjective, where $\cal{m}_p$ is the maximal ideal of $\cal{O}_{X,p}$''. Though he said that this is an easy exercise I can not do this,  I'm a little confuse with the term ''the map from global sections to the fiber $\cal{F}_p/\cal{m}_p\cal{F}_p$ is surjective'' what this in fact means, that I have to find a surjective map of modules $\cal{F}(X) \to \cal{F}_p/\cal{m}_p\cal{F}_p$? If yes, he says that we have to use the Geometric Nakayma Lemma, but I don't see how to use this here. Has anyone have a clue? Thank you so much!","['quasicoherent-sheaves', 'algebraic-geometry']"
835321,"Let $a_1=1$, $a_2=3$ , and for $n \ge 2$ let $a_n=a_{n-1}+a_{n-2}$. Show that $a_n < \left(\frac{7}{4}\right)^n$ for all natural numbers.","Let $a_1=1$, $a_2=3$ , and for $n \ge 2$ let $a_n=a_{n-1}+a_{n-2}$. Show that $a_n <
\left(\frac{7}{4}\right)^n$ for all natural numbers. I assume I'm supposed to use induction. base step is easy. I'm stuck on how to form the inductive step. Any tips are greatly appreciated.",['discrete-mathematics']
835333,Evaluate the limit $\lim_{x \to 0}{\frac{\sqrt{1+x\sin{x}}-\sqrt{\cos{2x}}}{\tan^{2}{\frac{x}{2}}}}$,I need to evaluate the limit without using l'Hopital's rule. $$\lim_{x \to 0}{\frac{\sqrt{1+x\sin{x}}-\sqrt{\cos{2x}}}{\tan^{2}{\frac{x}{2}}}}$$,"['calculus', 'limits']"
835339,Show that $\|e^{tA}\| \le e^{t\|\Re (A)\|}$,"Let $X$ be a complex Hilbert space, and let $A$ be a bounded linear operator on $X$. Define the real part of $A$ to be $\Re(A)=\frac{1}{2}(A^{\star}+A)$, and define $e^{tA}=\sum_{n=0}^{\infty}\frac{1}{n!}(tA)^{n}$, which converges in $\mathcal{L}(X)$ for all $t$. Show that
$$
                    \|e^{tA}\| \le e^{t\|\Re(A)\|},\;\;\; t \ge 0.
$$
Note: $A$ is not assumed to be normal.","['operator-theory', 'exponential-function', 'hilbert-spaces', 'functional-analysis']"
835346,finding the explicit function of a recursive sequence,"So I have the recursive sequence $f(0) = 0, f(n+1) = 2f(n)+ (n+1)^2$, and I'm not quite sure how to make it explicit. Substituting $n$ for $n+1$ cleans it up a little, yielding $f(n) = 2f(n-1) + n^2$, but I'm not quite sure what to do after that. It seems to be a lot harder than it looks. Any help would be appreciated.","['sequences-and-series', 'functions']"
835383,Path to Differential Geometry,"What do I need to learn to start on the rigorous study of differential geometry?  I'm about to start my 3rd undergrad year at school, and have taken Cal 1-3, Linear Algebra, Elementary Number Theory, and ODEs. If I want to take the most direct path to studying differential geometry, what should I start learning now?  Should I start on Real Analysis or Topology?  Should I just pick up Spivak's Intro to Differential Geometry ?  My multivariable calculus class did not cover differential forms, so should I read his Calculus on Manifolds or Munkres' Analysis on Manifolds first? I'm pretty sure that I want to study differential geometry in grad school and I'd like to start on it before then (ideally, I'd like to be able to publish something -- not necessarily extremely deep -- in diff geo before applying to grad schools). So what path should I take to self-study it? NOTE: My school has 1 undergrad course in Differential Geometry available in the Spring, so I'll probably do that next year, but I'd rather start now and go well beyond whatever I'm going to learn in that class.","['advice', 'soft-question', 'differential-geometry']"
835407,What does $\iint_S (\hat{\mathbf{n}} \times \nabla \psi) \; dS$ mean?,"In the Wikipedia article on vector calculus identities ,
we have the following $$\oint_{\partial S} \psi \; d\mathbf{\ell} = \iint_S (\hat{\mathbf{n}} \times \nabla \psi) \; dS$$ The right hand side is an integral of a vector field over a surface integral against $dS$, and not $\cdot dS$ or $\cdot \mathbf{\hat{n}} \; dS$. So if it's not a flux integral, I don't know what this means. I don't think the right hand side is the flux integral of $\mathbf{\hat{n}} \times \nabla \psi$. Otherwise, by Stokes' theorem, this would equal
$$-\int_{\partial S} \psi \mathbf{\hat{n}} \; \cdot d\ell = 0$$
since the normal vector is normal to the tangent vector on the boundary. Then the identity is false. So what is this called? The only way I know how to integrate a vector field along a surface it by its flux, but this clearly is not what this is. I haven't seen this notation anywhere else, does anyone know where I can find a precise, rigorous definition of what it's supposed to mean? EDIT: Here is my guess. These are vector valued integrals. The left hand side is
$$\oint_{\partial S} \psi \; \mathbf{d\ell}$$
What this means is the vector
$$\left(\int_{\partial S} (\psi, 0, 0) \cdot d\ell,
\int_{\partial S} (0, \psi, 0) \cdot d\ell,
\int_{\partial S} (0, 0, \psi) \cdot d\ell \right)$$
where the integrals are the usual line integrals of vector fields along $\partial S$. The right hand side is
$$\iint_S (\hat{\mathbf{n}} \times \nabla \psi) \; dS$$
Observe that $\hat{\mathbf{n}} \times \nabla \psi$ gives a vector that can be
written as
$$(\mathbf{G}_1 \cdot \mathbf{\hat{n}}, \mathbf{G}_2 \cdot \mathbf{\hat{n}},
\mathbf{G}_3 \cdot \mathbf{\hat{n}})$$
for some vector fields $\mathbf{G}_i$, $1 \leq i \leq 3$. The right hand side
is thus the vector
$$\left(\int_S \mathbf{G}_1 \cdot \mathbf{\hat{n}} \; dS,
\int_S \mathbf{G}_2 \cdot \mathbf{\hat{n}} \; dS,
\int_S \mathbf{G}_3 \cdot \mathbf{\hat{n}} \; dS\right)$$
where the components are the flux integrals of the $\mathbf{G}_i$. Still not sure what the $dS$ is supposed to be, since it seems a bit useless? EDIT 2: I think I understand now, the integral of a vector valued function is just the integral of the component functions with respect to the volume form of what we are integrating over ($dS$ or $d\ell$). So there are two ways to integrate a vector field over a surface. One, is to take the usual flux integral, which yields a scalar. The second, which is presented here, is the integrals of the component functions over the surface, which yields a vector.
Funnily enough, I've never seen this in any of my math books...perhaps it's more common in physics?",['multivariable-calculus']
835419,"Real sequences which sum to 0, multiply to 1.","Does there exist two sequences $(x_n)_n$, $(y_n)_n$ of real numbers such that
$\lim_n x_n-y_n\neq 0$ (may not exist), but $\lim_n x_n+y_n=0$ and $\lim_n x_ny_n=1$? Notice that it cannot be the case that both sequences are convergent, or even bounded, since by taking convergent subsequences, say with limits $x$ and $y$, we would have that $x+y=0$ and $xy=1$, which has no real solutions.",['real-analysis']
835434,Simple Branched covering over sphere.,"A simple branched covering is a branched covering with branching points of degree at most 2, in some context, it is also required to have at most one branching point in each fiber. My question is one of the exercises from Donaldson's Riemann Surface : every Riemann surface can be realized as a simple branched covering over sphere. Donaldson mentioned this result once again in chapter 14 when he talked about Hurwitz moves. And Donaldson said it was by Riemann-Roch theorem. There is one proof in section 8 of http://www.jstor.org/stable/pdfplus/1970748.pdf?acceptTC=true&jpdConfirm=true , but it used more than Riemann-Roch.","['riemann-surfaces', 'algebraic-curves', 'complex-analysis']"
835442,Why must polynomial division be done prior to taking the limit?,"Suppose I wish to evaluate the following,
$$\mathop {\lim }\limits_{x \to 2} \left( {{{{x^2} - 4} \over {x - 2}}} \right)$$
If I just substitute two into $x$, it can't be done because the answer would be undefined (division by zero). But, if I complete the polynomial division, that I hate to do because I'm all thumbs at it,
$$\mathop {\lim }\limits_{x \to 2} \left( {{{{x^2} - 4} \over {x - 2}}} \right) = \mathop {\lim }\limits_{x \to 2} \left( {x + 2} \right) = 4$$ Please tell me what's going on here?","['calculus', 'limits']"
835454,$f: SL_2(\mathbb{R}) \to GL_4(\mathbb{R})$ show that $Im(f)=SL_4(\mathbb{R})$,"I was struggling with the following problem (from linear algebra): Let $V$ be the vector space of the $2 \times 2$ matrices with real coefficients. Consider the action of the group $SL_2(\mathbb{R})$ on $V$, namely for any matrix $T \in SL_2(\mathbb{R})$ and for every matrx $A \in V$ we define $\Phi_T(A)=T\cdot A\cdot T^{-1}$. Prove that for every $T\in SL_2(\mathbb{R})$, $\Phi_T$ is an endomorphism of $V$. Then starting from a basis of $V$, write the corresponding homomorphism $SL_2(\mathbb{R}) \to GL_4(\mathbb{R})$, then show that the image lies inside $SL_4(\mathbb{R})$ First of all. Does anybody know the origin of this problem? Is there a book with standard solutions to this kind of problem? And is my solution any good? Apparently it is generalizable to many more dimensions, giving a nontrivial result on the determinant of such matrices.
And what does it happen when the trace is $0$? Can we show an homomorphism $SL_2(\mathbb{R}) \to SL_3(\mathbb{R})$ in the same way?","['linear-algebra', 'abstract-algebra']"
835458,Expected value of two successive heads or tails (stuck on computation),"Problem: This is problem 33 of section 2.6 (conditioning) in Bertsekas, Tsitsiklis intro to probability text. We are given that a coin has probability of heads equal to p and tails equal to q and it is tossed successively and independently until a head comes twice in a row or a tail comes twice in a row. What isthe expected value of the number of tosses? Solution: Let $X$ be a random value that tracks the number of tosses. In addition, let $H_k, T_k$ be the event that a head or tail comes up on the kth flip respectively. The solution I am looking at involves using total expectation theorem. I outline the following steps in the solution. We can partition the sample space into $H_1$ and $T_1$, allowing us to invoke the total expectation theorem. Hence, $E[X] = pE[X|H_1] + qE[X|T_1]$ Again by total expectation theorem, we can utilize another partition to obtain $E[X|H_1] = pE[X|H_1,H_2] + qE[X|H_1,T_2] = 2p + q(1 + E[X|T_1])$ $E[X|T_1] = qE[X|T_1,T_2] + pE[X|T_1,H_2] = 2q + p(1+E[X|H_1])$ Stuck: The solution follows up by saying that we can combine the above two relations and use the fact that p+q = 1 to obtain $E[X|T_1] = \frac{2+p^2}{1-pq} , E[X|H_1] = \frac{2+q^2}{1-pq}$ I have been staring at this for a while now, but I cannot seem to see the steps of the computation. I'd be very grateful if someone could fill in the details regarding the computation. Thank you.","['probability', 'conditional-probability']"
835460,Prove $\sin(-x) = -\sin(x)$,I'm looking for a really basic proof of $\sin(-x) = -\sin(x)$. The proof should pretty much only employ basic trigonometry. Thanks,['trigonometry']
835472,About the order of integration for double integrals,"I have to compute $\int\int (2x-y) \,dx \, dy $ on the domain $\{ (x,y) \in R^2 : 1\leq x\leq 4, 0\leq y\leq \sqrt{x} \}$ So mi first try is to do: $\int_0^{\sqrt{x}}\int_{1}^{4} (2x-y)\, dx \, dy = 15 \sqrt{x}-\frac{3}{2}x$ But if i do this like: $\int_1^4 \int_0^{\sqrt{x}} (2x-y) \,dy\, dx = \frac{421}{20}$ In the first case the result still depends on $x$, but in the second case i get a value. I know i did not changed the order of integration, but i just intepreted in diferent ways what my homework ask. Im a bit confused here, my question is: what is the correct order of integration?","['multivariable-calculus', 'integration']"
835478,"The first, fifth, and eighth terms of an arithmetic progression are the first, second, the third terms of a geometric progression ...","The first term is $8$ and the common difference is $d\neq0$ . The first, fifth, and eighth terms of the progression are the first, second, and third terms, respectively, of a geometric progression whose common ratio is $r$ . What are two equations connecting $d$ and $r,$ and how can we use this to show that $r=3/4$ and find the value of $d?$ What is the sum to infinity of the geometric progression? How can we find the sum of the first eight terms of the arithmetic progression?","['arithmetic', 'algebra-precalculus']"
835496,Prove that $x^2+1$ is reducible in $\mathbb{Z}_p[x]$.,"Prove that $x^2+1$ is reducible in $\mathbb{Z}_p[x]$ if and only if there exists integers $a$ and $b$ such that $a+b=p$ and $ab \equiv 1 \pmod{p}$. (Here $\mathbb{Z}_p$ means the integers modulo a prime $p$). I'm having trouble with the 'only if' direction of this proof, the 'if' direction is pretty trivial. After assuming $f$ is reducible, I've been able to use the Factor Theorem to show that $f$ is of the form $f(x)=c(x-a)(x-b)$ for $a,b,c \in \mathbb{Z}_p$, so $x^2+1=cx^2-c(a+b)x+c(ab)$. Comparing coefficients, we see that $c=1$, so we must have $ab=1$ and $a+b=0$, hence, $a+b \equiv 0 \pmod{p}$ and $ab \equiv 1 \pmod {p}$. Id like to show that $a+b=p$. This seems to be the case, but I'm having difficulty proving it. Is it okay here to assume that $a<p$ and $b<p$ (since they are elements of $\mathbb{Z}_p$), and assume without loss of generality that $a\leq b$, so that $a\leq b < p$, and use this to deduce that if $a+b=\alpha p$ for some $\alpha \in \mathbb{Z}$ with $\alpha \geq 0$, then we must have $\alpha =1$? I want to say something like, if either $a=0$ or $b=0$, then $ab \equiv 0 \pmod{p}$, a contradiction, so we must have $a+b\geq 2$, so we cannot have $\alpha=0$. If $2\leq \alpha$, then since $a\leq b < p$, we have $a+b<p+b<2p\leq \alpha p$, contradicting that fact that $a+b=\alpha p$, so we must have $\alpha =1$. I have a strong feeling I'm over-thinking this problem, thanks in advance for any help!","['abstract-algebra', 'polynomials']"
835502,Liouville number + rational number,The set of Liouville numbers is defined as all irrational $x$ such that for each natural $n$ there exists integers $p$ and $q > 1$ such that $|x - p/q| < 1 / (q^n)$. QUESTION: Is a Liouville number plus a rational number again a Liouville number? How do you prove this?,['number-theory']
835517,"Inverse Laplace Transform,","I have been stuck on this problem for quite a bit, have tried to look at similar answers on website but no help... The original questions is, Solve the IVP $\ y''+y=\sin(t);y(0)=1;y'(0)=0$ I applied Laplace to both sides and ended up with this $\ Y(s) = \frac {s}{s^2+1} - \frac {1}{s^2+1} + \frac {1}{(s^2+1)^2}$ where $\ L(y(t)) = Y(s) $ so $\ y(t) = \cos(t) - \sin(t) +L(\frac {1}{(s^2+1)^2}) $ the first to fractions on the RHS of the equation are simple to solve, what I am having trouble with is the last fraction. I have tried partial fractions, but got nothing out of it. I am not sure where to go with this? I tried using this solution, but wasn't sure how to apply it to my problem; Finding the inverse Laplace transform of $\frac{s^2-4s-4}{s^4+8s^2+16}$","['ordinary-differential-equations', 'laplace-transform']"
835522,Principal G bundles v.s. Flat G connection,"What is the difference between Principal G bundles v.s. Flat G connection ? I heard that for a discrete group $G$ (in physics, or a finite group $G$ in math), the principal G bundles is the same as the flat G connection. I know the definitions, but I wish to know explicit cases where I can see their differences. Like this MO post .","['principal-bundles', 'differential-geometry', 'fiber-bundles', 'differential-topology', 'gauge-theory']"
835526,"$\oint_{C}(A-\lambda I)^{-1}\,d\lambda=0$ implies interior of $C$ is in the resolvent.","Suppose that $A$ is a bounded linear operator on a complex Banach space $X$ with resolvent set $\rho(A)$. If $C$ is a simple closed smooth curve in $\rho(A)$ such that
$$
                  \oint_{C}(\lambda I -A)^{-1}\,d\lambda =0,
$$
then show that the the interior $\mbox{Int}(C)$ of $C$ is contained in the resolvent set $\rho(A)$. No assumptions are made about the spectrum of $A$ or about $A$. NOTE: I discovered a proof, but it's very contorted, and it seems to me that there should be a short proof. I feel that it should be almost obvious from the analytic functional calculus. This is not something I found in a book or that was part of homework.","['operator-theory', 'functional-analysis', 'complex-analysis', 'functional-calculus']"
835536,Find $\lim_{n\to\infty}n\left(\sum_{i=1}^{n}\dfrac{1}{(n+i)^2}\right)$,Can you help me with this limit? What do I have to do? I'm lost. $$\lim_{n\to\infty}n\left(\sum_{i=1}^{n}\dfrac{1}{(n+i)^2}\right)$$ The solution given is $\dfrac{1}{2}$.,"['limits', 'calculus', 'analysis']"
835554,Consider convergence of series: $\sum_{n=1}^{\infty}\sin\left[\pi\left(2+\sqrt{3}\right)^n\right]$,"Consider convergence of series: $$\sum_{n=1}^{\infty}\sin\left[\pi\left(2+\sqrt{3}\right)^n\right]$$ My tried: We have $$\sum_{n=1}^{\infty }\sin(\pi (2+\sqrt{3})^{n})=\sum_{n=1}^{\infty}\sin\left(\pi[(2+\sqrt{3})^{n}+(2-\sqrt{3})^{n}]-\pi(2-\sqrt{3})^{n}\right)\, (*)$$
Because $$(2+\sqrt{3})^{n}=\sum_{k=0}^{n}C_{n}^{k}2^{n-k}3^{\frac{k}{2}}$$
                $$(2-\sqrt{3})^{n}=\sum_{k=0}^{n}(-1)^{k}C_{n}^{k}2^{n-k}3^{\frac{k}{2}}$$
Hence $$(2+\sqrt{3})^{n}+(2-\sqrt{3})^{n}=\left\{\begin{matrix} 0&,k=2l+1 \\ m\in N&,k=2l \end{matrix}\right.$$
       $$\Rightarrow (1)=\sum_{n=1}^{\infty}\sin\left(m\pi-\pi(2-\sqrt{3})^{n}\right)=\sum_{n=1}^{\infty}(-1)^{m+1}\sin\frac{\pi}{(2+\sqrt{3})^{n}}<\sum_{n=1}^{\infty}\sin\frac{\pi}{(2+\sqrt{3})^n}$$ $\sum_{n=1}^{\infty}\sin\frac{\pi}{(2+\sqrt{3})^n}$ converge Hence series is converge. True or False?",['sequences-and-series']
835557,"I can't quite figure out this ""separable equation""","My prof assigned this question for exam studying and I can't figure it out. It's supposed to be a separable equations question and I'd be able to do something, but for that pesky '$+ y$'. All we've learned so far is separable equations and I feel like this is something more. $x\ln(x) \dfrac{dy}{dx} + y = xe^x$","['ordinary-differential-equations', 'calculus']"
835564,"Determine whether A is invertible, and if so, ﬁnd the inverse. (3x3)","In Exercises 37-38, determine whether $A$ is invertible, and if so, find the inverse. [ Hint: Solve $AX = I$ for $X$ by equating corresponding entries on the two sides. 37. $A = \begin{bmatrix} 1&0&1 \\ 1&1&0 \\ 0&1&1 \end{bmatrix}$ How the heck am I supposed to find an inverse of a 3x3? If I'm supposed to solve for $X$ I'd normally multiply both sides by $A^{-1}$ but this book gave no mention of a formula for more than 4 elements in a matrix... so if I equate $AX$ to $I$ , how do I solve for $X$ ?",['linear-algebra']
835627,'Fixed Point' Irrationals,"I found this interesting problem which turns out to be more difficult than it first appears: Suppose $f: \mathbb{R} \rightarrow \mathbb{R}$ is a function such that $f(f(x))=x$ for all $x \in \mathbb{R}$. Prove that there exists an irrational number $t$ such that $f(t)$ is irrational. The $f(f(x))=x$ condition reminds me of fixed point problems but as nothing else about $f$ is known I'm not sure how to apply this. Instead, I thought about the standard 'irrational to irrational power being rational' problem. So I thought about trying something along the lines of taking $x \in \mathbb{R}$ irrational then looking at $f(x)=y$. If $y$ is irrational we are done. If not, then I feel like trying something like $\sqrt{2}y$ as an input would work but nothing really panned out. Then I observed if $g(x)=(f\circ f)(x)$, we have
$$
g(xy)=xy=g(x)g(y)
$$
and
$$
g(x+y)=x+y=g(x)+g(y)
$$
but am unsure what this gets me. Any clues as to how I might proceed or perhaps an alternative route?","['real-analysis', 'problem-solving']"
835668,Show that the limit of $ f(x)$ as $x\rightarrow 0$ is $0$,"Show directly from the definition of a limit of a function that lim x->0 (x^(1/3) * sin(1/x)) = 0. The definition is The limit of f as x goes to p is q if for every e>0 there exists a d>0 s.t. dx(x,p)<d for x belongs to E -> dy(f(x), q)< e with the notation limi x->p f(x) = q My approach We want to show that dx(x,0)<d, x belongs to E -> dy( (x^(1/3) * sin(1/x)),0) < e which is | x-0| < d - > | x |<d and |(x^(1/3) * sin(1/x))|< e Now the solution I have takes e^3=d and shows that |(x^(1/3) * sin(1/x))|< d^(1/3)=e which makes no sense... I suppose the steps start from |x^(1/3)|<= d^(1/3)

|x^(1/3)| * | sin(1/x)|<= d^(1/3) * | 1| (Does he multiply by one because the max value of sin is 1 and hence it will always be smaller? ) Then takes e^3=d and somehow it is proven. It makes much more sense that I explained it now but I am looking to see what people think.... Please edit the notation if you know how. Thanks a lot.","['real-analysis', 'analysis']"
835693,Solving a system of recurrence relations,What is the methodology to solve for a system of recurrence relations? For example: $X_{n+1} = 4X_n + Y_n$ $Y_{n+1} = 3Y_n + X_n$,"['recurrence-relations', 'discrete-mathematics']"
835729,Proof Check: Every Cauchy Sequence is Bounded,"Sorry if I keep asking for proof checks. I'll try to keep it to a minimum after this. I know this has a well-known proof. I understand that proof as well but I thought I'd do a proof that made sense to me and seemed, in some ways, simpler. Trouble is I'm not sure if it's totally correct. It's quite short though. I was just hoping someone could look it over and see if it is a valid proof. Thank you! Lemma : Every Cauchy sequence is bounded. Proof : Let $(a_{n})$ be Cauchy. We choose $ 0<\epsilon_{0}$. So $ \forall \; n>m\geq N_{0}$ we have that $\vert a_{n}-a_{m} \vert < \epsilon_{0}$. Therefore $(a_{n})$ is bounded for all $ m \geq N_{0} $ by $ \epsilon_{0} $. Since $ \mathbb{N}_{N_{0}}$ is finite, it is bounded. So, for all $ m<N_{0} $, $ (a_{n})$ is bounded. Therefore $(a_{n})$ is bounded. I realize I haven't said what the bounds are but I think that's sort of irrelevant. So long as we know it's bounded. Any help is much appreciated!","['sequences-and-series', 'proof-verification', 'real-analysis']"
835731,"$G \times H \cong G \times K$ , then $ K \cong H$","I already know that if groups $G,H,K$ are finitely generated abelian groups, following is true. If $G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$.
I prove this by uniquness of factorization of finitely generated abelian groups. My questions are If group $G$ is finite,$G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$? Can you give me a easiest proof and it can be proved by projection function on external direct product? If $G,H,K$ are groups.  If $G\times K$ is isomorphic to $H\times K$, then $G$ is isomorphic to $H$. This statement is false. What is a counterexample? *$\times$ is external direct product","['group-theory', 'abstract-algebra']"
835745,A constant function,"$f:\mathbb{Z}\to \mathbb{R}$ is bounded above and satisfies 
$$f(n)\le \frac{f(n+1)+f(n-1)}{2}$$
Does it follow $f$ is constant ?
There was a dreadful typo in the previous question (in the previous question, the domain of $f$ was $\mathbb N$, here, it is $\mathbb Z$), I am posting a new one. Thanks for helping.",['functions']
