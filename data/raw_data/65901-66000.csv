question_id,title,body,tags
776855,Fibonacci numbers from $998999$,"Is there a nice explanation of $$\frac{1}{998999}=0.000\,\underbrace{001}_{F_1}\,\underbrace{001}_{F_2}\,\underbrace{002}_{F_3}\,\underbrace{003}_{F_4}\,\underbrace{005}_{F_5}\,\underbrace{008}_{\ldots}\,013\,021\,034\,055\,089\,144\,233\,377\,...$$
or is this a mere coincidence? The pattern breaks at $16$th Fibonacci number producing $988$ instead of $987$.","['fibonacci-numbers', 'puzzle', 'sequences-and-series']"
776875,The proof of ONE$\uparrow G_{po}^s(X) \Rightarrow$ ONE$\uparrow G_{po}(X) $.,"Let $X$ be a topological space. The point-open game $G_{po}(X)$ is defined as folows. It is played by two players ONE and TWO. In the n'th step $(n \in \omega)$, ONE choose a finite subset $F$ of $X$, and TWO selects an open $G_n$ in $X$, $F_n \subset G_n$. ONE wins if $\bigcup \{ G_n : n \in \omega \} = X$, otherwise TWO wins. Also: Let $X$ be a topological space. The strict point-open game $G_{po}^s(X)$ is defined as folows. It is played by two players ONE and TWO. In the n'th step $(n \in \omega)$, ONE choose a finite subset $F$ of $X$, and TWO selects an open $G_n$ in $X$, $F_n \subset G_n$. ONE wins if $\underline {Lim} G_n  = X$, otherwise TWO wins. Theorem 1 here (page 154) states that ONE$\uparrow G_{po}^s(X)$ iff ONE$\uparrow G_{po}(X)$. There is a notation in the proof which I am not familiar with and is not clear to me.
In order to prove the non-trivial direction, the autors assume that S is a winning strategy for ONE in ONE$\uparrow G_{po}(X)$. They state then, that ""a sequence 
$\langle \langle F_i,G_i \rangle : i < \omega \rangle$ is compatible with S, if $F_i$ is finite, $G_i$ is open, $F_i \subset G_i$ for $i < \omega$, and, for any $k < \omega$, $S(\langle G_i : i<k \rangle) \subset F_k$"". I don't understand the meaning of the notation $S(\langle G_i : i<k \rangle)$. It is, also, not explained previously in the article. Any help? Thank you! p.s. ONE$\uparrow G_{po}(X)$ means: ONE has a winning strategy in $G_{po}(X)$","['general-topology', 'combinatorial-game-theory']"
776880,A subsequence of a convergent sequence converges to the same limit. Questions on proof. (Abbott p 57 2.5.1),"Solutions to Homework 3 doesn`t duplicate . We have to prove that if $(a_{n})$ is a sequence in $\mathbb{R}$ with $\displaystyle \lim_{n\rightarrow\infty} a_n =a$, and if $(a_{n_{k}})_{k\in \mathbb{N}+}$ is a subsequence of $(a_{n})$ , then $\displaystyle \lim_{k\rightarrow\infty}a_{n_{k}}=a$. We first need to know that $n_{k}\geq k$ for all $k\in Z_{>0}$. This is proved by induction on $k$. I omit this. Let $e >0$. $\displaystyle \lim_{n\rightarrow\infty}a_{n}=a$ is posited, so there's $\color{violet}{N}\in \mathbb{N}$ such that for all $n\in\mathbb{N}$, $n \ge N \implies |a_n-a| < e$. Let $k\in \mathbb{N}$ with $k\geq N.$ Then ${n_k}\geq k\geq N$. Therefore $|a_{n_{k}}-a|<e$. I know we must find $ N\in\mathbb{N}$ such that  $\color{red}{n_k} \ge N\implies |a_\color{red}{n_k}-a| < e \quad (♫)$. As the proof overhead shows, this $N$ is the same as the posited $\color{violet}{N}$. But what engenders $(♫)$ ? Is proof saying $n \ge N \implies |a_n-a| < e$ implies $\color{red}{k} \ge N \implies |a_\color{red}{k}-a| < e$ implies $(♫)$, because $n_k \ge k \ge N$? If yes, then I don't understand how $k$ can be replaced by $n_k$?","['proof-verification', 'real-analysis']"
776896,A basis for the column space of a real matrix,"Let $A$ be a real square matrix, and let its column space be $$\mathrm{col}(A)=\{y\in\mathbb{C}^n:y=Ax\text{ for some } x\in\mathbb{C}^n\}.$$ Under what conditions is $\mathrm{col}(A)$ spanned by eigenvectors of $A$ associated to nonzero eigenvalues? Do we get the same answer if we take $\mathbb{R}$ rather than $\mathbb{C}$ as the field (so $\mathrm{col}(A)=\{y\in\mathbb{R}^n:y=Ax\text{ for some } x\in\mathbb{R}^n\}$ and we look for conditions for the real and imaginary parts of the eigenvectors of $A$ associated to nonzero eigenvalues to be in $\mathrm{col}(A)$? My attempt to answer 1 so far: Any eigenvector $v\in\mathbb{C}^n$ is in $\mathrm{col}(A)$, so $\mathrm{col}(A)$ is spanned by eigenvectors of $A$ associated to nonzero eigenvalues if there are $\mathrm{rank}(A)$ linearly independent eigenvectors eigenvectors of $A$ associated to nonzero eigenvalues. Can we say more? As for 2, I'm confused.","['vector-spaces', 'matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
776899,"If every convergent subsequence converges to $a$, then so does the original bounded sequence (Abbott p 58 q2.5.4 and q2.5.3b)","Assume $(a_{n})$ is a bounded sequence such that every convergent subsequence of $(a_{n})$ converges to the same limit $a\in \mathbb{R}$. Show $(a_{n})$ must converge to $a$. Prove by contradiction . Prove the contrapositive: If $(a_{n})$ is a bounded sequence that doesn't converge to the number $a\in \mathbb{R}$, then there is some subsequence that converges to $b \neq a$ (videlicet, not every convergent subsequence converges to a). 1. How to presage proof by contrapositive? Why not a direct proof? Suppose $(a_{n})$ is a bounded sequence that does not converge to $a$. In other words, negate [ for every $\epsilon >0$, there is an $N\in \mathbb{N}$ such that, for all $n\geq N,\ |a_{n}-a|<\epsilon$ ]. Pass the negation through the various quantifiers. Then this means that there is some $\epsilon_{0}>0$ such that, for all $N\in \mathbb{N}$, there is an $n \geq N$ such that $|a_{n}-a|\geq\epsilon_{0}$. Stated in plainer language, we're assuming that there is some $\epsilon_{0}>0$ such that infinitely many of the $a_{n}$'s are at a distance at least $\epsilon_{0}$ away from $a$. Now, these infinitely many $a_{n}$'s form a subsequence; call it $(a_{n_{k}})$ . Since $(a_{n})$ is bounded, the subsequence $(a_{n_{k}})$ is also bounded. Thus, by the Bolzano-Weierstrass Theorem, $(a_{n_{k}})$ contains a convergent subsequence $(a_{n_{k_{\ell}}})\rightarrow b$. Since each of the $a_{n_{k_{\ell}}}$ is at a distance at least $\epsilon_{0}$ from $a$, so $b\neq a$. Ergo, not every convergent subsequence of $(a_{n})$ converges to $a. \square $ 2. I understand the steps of the proof, but not the modus operandi of the proof.
  Question posits a convergent subsequence, so we work with $\{a_{n_k}\}.$ How to presage we need a convergent sub sub sequence $\{a_{\Large{{n_{k_l}}}}\} $? 3. Intuition please? Figure please? I forgot I asked about this earlier, but this question betters the old one .","['proof-verification', 'real-analysis']"
776908,Using Trigonometry vs. Geometry,"I have a friend who is trying to build a wooden retaining wall around a trampoline.  He wants the wall to be in the shape of a regular polygon with sides between $24""-30""$.  He asked me to figure out how many sides he should make it, and then calculate the angles so that he knows how to cut the wood.  The trampoline has a diameter of $16'$. So I attacked the problem at first using Geometry.  I found that the area of the trampoline is approximately $201.1$ $ft^2$.  Then I used the regular polygon formula $A=\frac{a\cdot p}{2}$, where $a$ is the apothem and $p$ is the perimeter for all sides from $24""-30""$.  To make a long story short.  I found that a polygon of $24$ sides with $26""$ sides would best do the trick, and another mathematics friend of mine concurred.  Since we have 24 sides, using the internal angle formula, I know that the sum of the interir angles is $A(24)=180(24-2)=3960$ which means each of the $24$ angles should be $165$ degrees.  Halving this gives me cuts of $82.5$ degrees. However, using Trig, if the long side of the triangle is $96""$ and the short side is $13""$, then $\tan{\theta}=\frac{96}{13}$ which implies that $\theta=82.288$, not $82.5$ Why the discrepancy?  I know these numbers are close, but shouldn't the math agree?  I don't see where my error lies if there is an error in my math.","['geometry', 'trigonometry']"
776960,"How to solve this limit, hint only",$$\lim_{n\to\infty}\bigg(\frac{1}{\sqrt{9n^2-1^2}}+\frac{1}{\sqrt{9n^2-2^2}}+ \dots +\frac{1}{\sqrt{9n^2-n^2}}\bigg)$$ I need a hint. I see that maybe compute with integral. But what the integrable function?,['limits']
776973,Number of subgroups of order $4$ and $8$ in a group of order $72$,Let $G$ be a group of order $72$. I want to calculate the number of subgroups of order $4$ and $8$ with GAP. How can I do? thanks in advance.,"['computational-algebra', 'finite-groups', 'math-software', 'gap', 'group-theory']"
776997,Formula for prime counting function,I saw this formula on this paper page 2 $$\pi (n)=\sum_{j=2}^{n}\frac{\sin^{2}\left(\pi \frac{(j-1)!^{2}}{j}\right)}{\sin^{2}(\frac{\pi }{j})}$$ Where $\pi(n)$ is the prime counting function. Is this true? How to prove it?,"['prime-numbers', 'number-theory']"
777005,Rank of $(G/H)/(G/H)_t$ where $G$ is finitely generated abelian and $H$ is a subgroup.,"Let $G$ be a finitely generated abelian group and $H$ be a subgroup. Let subscript $t$ denote the torsion subgroup. If $G/G_t$ is free of rank $n$ and $H/H_t$ is free of rank $m$, it is easy to embed $H/H_t\hookrightarrow G/G_t$ and deduce that $m\le n$. Now the question is that I want to show that $(G/H)/(G/H)_t$ is free of rank $n-m$. This is harder than it looks and I have not succeeded in finding a proof after many hours. [EDIT] I'm looking for a group theory proof.","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
777016,Equations of the image of a curve with elimination theory,"I've been trying to solve the next problem but I can't complete the last step. The problem is: Considering the image of the circle $$V=\{  (x_1,x_2): x_1^2+x_2^2=1  \}$$ given by the map $$\rho: V \rightarrow \mathbb{A}^2(\mathbb{R})$$ $$(x_1,x_2) \longmapsto (\frac{x_1}{1+x_2^2}, \frac{x_1x_2}{1+x_2^2})$$ Compute the equations of the image. My attemp: The map $\rho$ is well defined over the open set $$U=\{(x_1,x_2)\in V: g=(1+x_2^2)(1+x_2^2) \neq 0\}=V$$ so we can take the affine variety $ Y:=\mathbb{A}^2(\mathbb{R})_g \subset  \mathbb{A}^3(\mathbb{R})$ given by $$Y:=\{(x_1,x_2,z):zg(x_1,x_2)-1=0\}=\{(x_1,x_2,z):z(1+x_2^2)^2-1=0\}$$ and a morphism $\phi: Y \rightarrow W $ such that $\phi(Y)= \rho(V)$.
$$ $$ Calling $ \Gamma_\phi$ to the graph of $\phi$ in $ \mathbb{A}^3(\mathbb{R}) \times  \mathbb{A}^2(\mathbb{R})$, we have that: $$I(\Gamma_\phi)=\langle  z(1+x_2^2)^2-1, y_1-x_1 (1+x_2^2), y_2-x_1x_2(1+x_2^2)  \rangle$$ Now we have to compute a Gröbner basis of that ideal and, after that, use elimination theory to quit all the expresions in that basis that depend on $x_1,x_2,z$. The remaining equations will be those asked in our problem.
I've tried this last part many times but I always get all the equations depending on $x_1,x_2,z$. I'd really appreciate if someone could help me in this last part. 
Thanks in advance.","['commutative-algebra', 'algebraic-geometry', 'proof-verification', 'abstract-algebra']"
777031,How can infinity be an accumulation point?,"Let $(a_n)_{n∈\mathbb N}$ be a set in $\mathbb R$ . For every $r ∈ \mathbb R$ exits an accumulation point $b ∈ R \cup \{{−\infty} \}$ of $(a_n)_{n∈\mathbb N}$ with $ b < r$ .  ( $\pm \infty$ are allowed as accumulation points) Show, that $-\infty$ is an accumulation point of $(a_n)_{n∈\mathbb N}$ . I can't wrap my head around this: An accumulation point is a point of a set, which in every yet so small neighborhood (of itself) contains infinitely many points of the set, right? If (in my case) $-\infty$ is an accumulation point, then we could find a point of the set, that is finitely distant from infintity?!","['infinity', 'analysis']"
777051,"A linear operator between $C[0,1]$ and $C[0,1]$ defined as $Tf = f + \int f$; Show $T$ is an isomorphism","Define a linear operator $T:C[0,1] \to C[0,1]$ as follows:
$$Tf(x) = f(x) + \int_0^x f(u)du$$
It is easy to show that $T$ is a bounded linear operator. The statement also (1) claims that $T$ is one-to-one and onto, and (2) asks to compute $T^{-1}$. (Hence $T$ is an isomorphism due to a corollary of Open Mapping Theorem) I need help to prove $T$ is onto: given any $g \in C[0,1]$, how to decompose it into a sum between a continuous $f$ and its antiderivative. I have trouble decomposing $g(x)=|x|$, not to mention bizarre functions like Weierstrass function. It seems impossible. Thanks in advance for help!","['continuity', 'functional-analysis', 'real-analysis']"
777114,Application of Picard-Lindelöf to determine uniqueness of a solution to an IVP,"I am still struggling quite a lot with the Picard-Lindelöf-Theorem (also known as the Cauchy-Lipschitz-Theorem ). Problem : Consider the following IVP with $\alpha \neq 1$  $$\begin{cases} y'&= t|y|^\alpha \\ y(0)&=1 \end{cases} $$
  And show that there exists a unique solution $f_\alpha$ on an Interval $I_\alpha$ with $0 \in I_\alpha$, also show that $f_\alpha (t) > 0$ for small $t$ So to use Picard-Lindelöf I want to show that $f(t,y)=t|y|^\alpha$ is Lipschitz-continuous with respect to its second variable. I could do this by computing the partial derivative with respect to $y$ and find an interval on which this expression is bound, then on said hypothetical interval the solution would exist and be unique. My approach : $$\frac{\partial f}{\partial y}= t\alpha|y|^{\alpha-1} \cdot \frac{y}{\sqrt{y^2}} $$
At which point I already run into trouble. I have made use of the fact that $|x|'= x/\sqrt{x^2}$ because it gives correct results in regard of the direction (when approaching from the left and the right). But the above expression is not defined at $y=0$. So I thought if I could come up with an argument that shows why $y \neq 0$, then at least this problem would be out of the way. Assume that $y=0$ then $y'=0=f(t,y) \implies \frac{\partial f}{\partial y}=0$ which is bound on $\mathbb{R} \implies f$ is Lipschitz continuous with respect to $y$ but we have $y(0)=1$ and thus $$y'=0 \implies y=c $$
So $y$ is a constant function and $y(0)=1$ means that $c=1 \implies y=1 \neq 0$ which shows that $y$ can not be the 'zero' function (if that exists). Questions : Is the above argumentation correct? How can I find the desired interval $I_\alpha$ with $0 \in I_\alpha$? Update : I tried to continue a bit on my own and ignore the Picard-Lindelöf part and just focus on solving the IVP, apparently the step I have taken above was necessary so I can divide by $|y|^\alpha$, however I will land at $$\frac{dy}{|y|^\alpha}=tdx $$
So it seems like I have to come up with a condition that guarantees me that $y$ is positive in some Intervall.","['ordinary-differential-equations', 'calculus', 'definition', 'self-learning', 'real-analysis']"
777132,Proving a function is surjective given the composition is surjective [duplicate],"This question already has answers here : Show that if $g \circ f$ is injective, then so is $f$. (5 answers) Closed 8 years ago . Here is the question $f:X \rightarrow Y$ and $g: Y \rightarrow Z$ are functions and $g \circ f$ is surjective, is $g$ surjective? My proof: If $g \circ f$ is surjective than $\forall z \in Z \; \exists x \in X \; \mid (g \circ f)(x)=z  $ Suppose $f$ is surjective, than $\forall y \in Y \; \exists x \in X\; \mid f(x)=y$. By def. of $(g\circ f)(x)=z$ we have $g(f(x))=z$ and since $f(x)=y$ than we have $g(y)=z$ which implies surjectivity therefore $g$ is surjecive. Is this the correct way to prove that $g$ is surjective? Or can I not assume surjectivity on $f$","['discrete-mathematics', 'elementary-set-theory', 'functions', 'function-and-relation-composition', 'proof-verification']"
777142,"Simplifying a u-substitution for $\int \frac{x} { \sqrt {4-3 x^4 } } \, dx$","this is a calculus one problem I cannot figure out.  I may be making a simple assumption in my substitutions, please help.  (I hope I typed this correctly, this is my first time using the MathJaX formatting.)  Thanks! $\int \frac{x} { \sqrt {4-3 x^4 } } \, dx$ I let $u = 3 x^4$, then $du = 12 x^3$.  I then used $\sqrt{u} = \sqrt{3} x^2$.  When I substituted in I got the the following integral which I can't figure out how to simplify: $\frac{1}{12}  {\int \frac{\sqrt{3}} {\sqrt{u} \sqrt{4-u}}} \, du$ Thanks for any help at all!","['calculus', 'integration', 'indefinite-integrals']"
777174,Question about particular solutions of $y''+4xy'+Q(x)y=0$.,"If we know that $$y''+4xy'+Q(x)y=0$$ 
have two solutions of the form: $y_1=u(x)$ and $y_2=xu(x)$, where $u(0)=1$. How can we determine $u(x)$ and $Q(x)$ explicitly? (This problem is extracted from: Tom Apostol Calculus II.) If $x$ does not appear in the above equation, (i.e. just y'', y and constants) i can solve similar problems. Because in that case, i can say that if the ODE have a solution of the form $y=e^{kx}$ then the general solution is of the form $y=Ae^{k_1x}+Be^{k_2x}$, etc. Can i do something similar for the above equation? Any help or suggestion is welcome. Thanks.",['ordinary-differential-equations']
777178,Inverse matrix for a matrix with sinus and cosinus functions,"I have this matrix A:
$$\left(\begin{array}{cc} \cos x & -\sin x \\ \sin x & \cos x \end{array}\right)$$ and I need to create an inverse matrix for this matrix A. The sinus and cosinus functions in there makes me confused, I don't know how to start and proceed.
To count a determinant from this matrix is kinda easy, but how to count an inverse matrix to this? Thank you","['matrix-equations', 'matrices', 'matrix-calculus']"
777191,Finding formula using tangentline information,"I'm new on SE, but I hope that you guys will help me with this question I have.
I'm currently not capable of using $\LaTeX$ or anything nice to set up my formulas, but I hope you will bear over with that - at least for now. I have the following information: A function $f$ solves the differential equation $\frac{dy}{dx} = 2x+5-y$ And the line with the equation $y=1$ (I notice the two $y$'s as well...) is a tangent line to $f$. And my question is then: How do I find the formula for $f$ using only this information? What I have done so far (basically only using separation of variables): $\frac{dy}{dx} = 2x+5-y$ $\frac{dy}{y} = (2x+5)dx$ $\int(1/y)dy = \int(2x+5)dx$ $\ln(y) = x^2 + 5x + k$ $y=e^{x^2 + 5x + k}$ Also I would be pleased if you would check if what I have done is correct, as I have not actually learned separation of variables yet... Thanks in advance",['ordinary-differential-equations']
777205,The closed form of $\sum_{n=0}^{\infty} \arcsin\bigl(\frac{1}{e^n}\bigr)$,"In my study on some type of integrals I met the series below that I don't how to approach it. Of course, one of the obvious questions is: does it have a closed form? Before answering that, I need to learn how to tackle them, the proper tools to employ. Any help  on this series is very welcome. The use of $\arcsin(x)$ series expansion wasn't fruitful. $$\sum_{n=0}^{\infty} \arcsin\left(\frac{1}{e^n}\right)$$ that more generally can be considered as $$\sum_{n=0}^{\infty} \arcsin\left(x^n\right)$$","['sequences-and-series', 'calculus', 'elliptic-integrals', 'real-analysis', 'complex-analysis']"
777250,Mean curvature flow - implementation fails for some meshes,"I am working on piece of software to deal with 3D meshes and I need to smooth some meshes. I have implemented MCF by using this formula $\vec{H} = {{t}\over{2}} \sum_{q \in\ link\ p} \vec{Ne} |e| \sin({\theta\over{2}})$ where $\vec{Ne}$ = ${\vec{N1} \vec{N2}}\over{2 \cos{{\theta}\over{2}}}$, $\vec{e} = q - p$ and $N1$ and $N2$ are normals to faces to whom edge belongs. $\theta$ is calculated by cosine similarity between $N1$ and $N2$ And I have tested my implementation with meshes like cube, cone, torus and it works well. But the problem is with more complex meshes, e.g. I tried to smooth Stanford bunny and I got smaller but bumper result instead of smoother! Below you can find examples which present bunny before and after smoothing. My question is if I forgot about something important or this is normal behavior of MFC for some meshes and I should forget about MFC and implement another flow(I will be grateful for any recommendations). I have to add that, for another problematic mesh I calculated some MFC vectors on paper and I got same results(up to floating point errors). At the and I want to add that, as probably some of you know Stanford bunny is not 2-manifold so I removed faces from problematic edges by using MeshLab's filters. Thanks and happy math!","['polygons', 'curvature', 'differential-geometry', 'mean-curvature-flows']"
777263,Computing the primitive $\int\frac{1}{1+x^n} dx$,"Well, this might be a really simple one. But still... What will be the soln. to ---
\begin{aligned}
\int\frac{1}{1+x^n} dx \end{aligned} Is substituting \begin{aligned} 1+x^n \end{aligned} by tan z the correct step? Thanks for the Help.","['calculus', 'integration', 'indefinite-integrals']"
777301,Explanation of a proof without words of Ptolemy theorem,What is the explanation of Ptolemy Theorem - Proof Without Words ?,['geometry']
777308,How to combine Unitary Matrices in a clever way?,"I am trying to implement genetic-type algorithms on unitary matrices. Hopefully I should be able to use this question for the mutation part. But I am having an issue with the cross-over step. So here is my question: Given two unitary matrices $A$ and $B$(both square matrices with the same size, and their elements belong to $\mathbb C$), what is a clever way of combining them so the result would still be unitary.
Where, by clever I mean if the parents $A$ and $B$ are close to each other, the child would also be close to them. I can give a precise notion of what I mean by being close(if necessary), but I think most of the reasonable notions would satisfy me. Besides the trivial choice of $A^iB^j$, I actually haven't been able to construct any unitary operators from $A$ and $B$ yet; and $A^iB^j$ is not necessarily close to $A$ or $B$. I don't know if this is asking too much, but since the unitary matrices I'm dealing with would scale like $2^n\times2^n$(where $n>10$), I guess another aspect of being clever, should be the efficiency of the algorithm. Edit: So I thought about a way of generating off-springs. I think it satisfies the first requirement of being clever, however I'm not sure how efficient it could be implemented. It is built upon the fact that if $H$ is Hermitian, then $e^{iH}$ would be unitary. So this is how it works:
$$A'=e^{i\alpha(B-A+B^\dagger-A^\dagger)}A \\ B'=e^{i\alpha(A-B+A^\dagger-B^\dagger)}B$$
where $\alpha$ is a real number. I don't think this method is unique or perfect, and I would appreciate any improvements to it.","['optimization', 'matrices', 'algorithms']"
777318,Taylor Expansions in Spherical Coordinates (Generator of Rotations),"We can expand a smooth function $f:\mathbb{R}^3\to \mathbb{R}$ in a Taylor series:
$$f((x^1,x^2,x^3)+(h^1,h^2,h^3))=f(x^1,x^2,x^3)+h_i\frac{\partial f}{\partial x^i}+h_ih_j\frac{\partial^2 f}{\partial x^i\,\partial x^j}+\cdots$$
Now suppose we write the same function in spherical coordinates: $\hat f\equiv f\circ g$, where $g:R_\theta^3\to \mathbb{R}^3$ is the spherical coordinate mapping. Why can't we then write
$$\hat f((\theta^1,\theta^2,\theta^3)+(\phi^1,\phi^2,\phi^3))=\hat f(\theta^1,\theta^2,\theta^3)+\phi_i\frac{\partial \hat f}{\partial \theta^i}+\phi_i\phi_j\frac{\partial^2 \hat f}{\partial \theta^i\,\partial \theta^j}+\cdots\tag{1}$$
What's going on here? Perhaps it's the periodicity, but then shouldn't the formula be valid if $(\phi^1,\phi^2,\phi^3)$ is sufficiently small? What I'm really after is for a valid version of (1).","['derivatives', 'real-analysis']"
777356,How to prove divergence of the integral $\int_{0}^{\infty}\frac{\sin(x)}{x^{2}}dx$,"I want to show that the following integral diverges: $$\int_{0}^{\infty}\frac{\sin(x)}{x^{2}}dx$$ I used the substitution $ t = \frac{1}{x} $ to transform this integral into $$\int_{0}^{\infty}\sin \frac{1}{t}dt$$ It seems intuitive that for large $t$, $\sin \frac{1}{t} = O(\frac{1}{t})$ and so the last integral diverges and so does the original. Is this correct?","['improper-integrals', 'integration', 'real-analysis', 'analysis']"
777373,Is a limit ordinal necessarily a cardinal?,"Maybe this is a trivial question. I see that every infinite cardinal is necessarily a limit ordinal, but is the converse true ?","['cardinals', 'elementary-set-theory', 'ordinals']"
777375,A particle moves along a path described by $y = 4 − x^2$ . At what point along the curve are $x$ and $y$ changing at the same rate?,"Why is the answer $\left(-\frac 1 2 , \frac{15}{4} \right)$? I have no idea how to approach this problem. Can someone guide me/explain it to me step by step? I have a final on this in less than 2 hours and I'm freaking out!","['calculus', 'derivatives']"
777397,Cantor's proof on uncountability of irrationals,"I have a question regarding Cantor's proof that the set of irrational numbers is uncountable.
As far as I know, to prove this, Cantor proves that there exists a mapping between irrationals and naturals so that at least one irrational is left out. However, the existence of such a mapping does not imply the nonexistence of a one-to-one mapping. Did I understand the proof wrong? If yes, an explanation would be much appreciated! Thank you for taking the time to read my question!","['elementary-set-theory', 'irrational-numbers']"
777423,submodular-like functions on $\mathbb{R}$,"The definition of submodularity led me to define a type of function on numbers (I suppose ordered rings, but consider the reals for now) as $f(x) + f(y) \ge f(x+y) + f(xy)$. Such functions exist: for example, the constant functions. I can infer some basic properties of these functions: plugging in $x = 1$ and $y = c-1$ yields $f(1) \ge f(c)$ so 1 is a global maximum; similarly, $x = 2$ and $y = 2$ yields $f(2) \ge f(4)$. Another property of interest is that if $f$ is differentiable at $x$ and 0, $y = \epsilon$ gives $f(x+\epsilon) - f(x) \le f(\epsilon) - f(x\epsilon)$ and letting $\epsilon \rightarrow 0$ yields $f'(x) \le (1-x)f'(0)$. (edit: thanks kingW3) Can anyone characterize such functions more completely? Are there any such functions beside the constant ones? I am having difficulty coming up with one.","['functions', 'functional-inequalities', 'real-analysis', 'functional-equations']"
777449,Conditions under which a bijective morphism of quasi-projective varieties is an isomorphism?,"I'm reading a paper by Nakajima ( Quiver Varieties and Tensor Products ), and I'm having a hard time understanding his proof of Lemma 3.2. Essentially, we have two (quasi-projective) varieties, say $X$ and $Y$, that we would like to show are isomorphic. The proof uses the following argument: (1) Construct a bijective morphism $f:X \to Y$. (2) Show that $\mathrm{d}f: T_x(X) \to T_{f(x)}(Y)$ is an isomorphism for all $x \in X$ (where $T_x(X)$ is the tangent space of $X$ at $x$). From (1) and (2), he concludes that $f$ is an isomorphism. My question is, how can one conclude that $f$ is an isomorphism from (1) and (2)? According to Joe Harris's Algebraic Geometry (specifically Theorem 14.9 and Corollary 14.10), a bijection $f:X \to Y$ that induces an isomorphism on the tangent spaces is an isomorphism if $f$ is finite or if $X$ and $Y$ are projective (this is in general false otherwise). In our setting, $X$ and $Y$ are not projective and it is not obvious (to me, at least) that the map constructed by the author is finite. Does anyone know what conditions the author is using to conclude that (1) and (2) $\implies$ $f$ is an isomorphism?",['algebraic-geometry']
777470,Divisibility of a sum in terms of the divisibility of summands,"Let $d(x) =_{df} \{y ~~|~~ \exists z: (y\cdot z) = x\}$, where $x,y,z \in \mathbb Z^+$. Informally, $d(x)$ is the set of integral factors of $x$. My question is rather elementary: is it true that $(\forall x,y)$: $d(x + y) = d(x) \cap d(y)$? If it is, how might we go about proving it? I unpacked the definitions, but can't seem to transform the right hand side in such a way as to obtain the $d(x+y)$ set.","['elementary-number-theory', 'elementary-set-theory']"
777479,"Solving IVP $y'=t|y|^\alpha, \ y(0)=1$","Intro : This is a follow up to my post Application of Picard-Lindelöf to determine uniqueness of a solution to an IVP , where I am trying to verify that the below IVP has a unique solution in some interval that includes $0$. This is a nightmare and doesn't work out for me. So I try to go the opposite direction and see whether or not I can come up with something. I hope it's okay to make this kind of a follow up post, if not please feel free to close it. I also hope someone finds the time to quickly look through this post and tell me whether or not my reasoning is correct. Problem : Solve the following IVP $$ \begin{cases} y' &= t|y|^\alpha \\ y(0)&=1 \end{cases} $$ where $ \alpha \neq 1$ My approach : This is the first time I am dealing with an absolute value function, so I guess it is reasonable to look into the two cases where $y$ is positive and $y$ is (strictly) negative. I first want to show that I can divide through the expression $y^\alpha$. Let $y=0$ then $y'=0 \implies y=c$ but $y(0)=1$ and therefore $c=1 \implies y=1$ which is a contradiction, thus $y \neq 0$. Then I start solving the differential equation. $$ \frac{dy}{dt}=ty^\alpha \iff \frac{dy}{y^\alpha}=tdt \implies \frac{y^{1- \alpha}}{1-\alpha}=\frac{t^2}{2}+C \\ \implies y = \left( \frac{(1-\alpha)t^2}{2}+K \right)^\frac{1}{1-\alpha} $$
Applying initial conditions would lead to $K=1$. Is that correct? Now the same for $y$ negative of course which I will save for now, just substituting $|y|=-y$ into the original IVP. How could these results resemble uniqueness? Update : A sudden idea striking me, it seems very tedious but do I need to do a check analysis for $\alpha$? Meaning do the above calculations for $\alpha < 0$, likewise $\alpha > 1$ and $\alpha \in ]0,1[$ ?","['ordinary-differential-equations', 'calculus', 'real-analysis']"
777489,image of intersections of sets and equality with intersection of images.,"It can be shown that if $f$ is a map of sets, $f:X\rightarrow Y$ say, that for $A_\lambda \subseteq X, \lambda \in \Lambda$, an indexing set, then: $$f\left(\bigcup\limits_{\lambda}A_\lambda\right)=\bigcup\limits_{\lambda}f\left(A_\lambda\right)$$ and $$f\left(\bigcap\limits_{\lambda}A_\lambda\right)\subseteq\bigcap\limits_{\lambda}f\left(A_\lambda\right).$$ I was just wondering are there functions such that equality holds for the second statement for all collections of subsets $\{A_\lambda\}_{\lambda \in \Lambda}$ of $X$ where $\bigcap\limits_{\lambda}A_\lambda \neq \emptyset$? I would suppose constant maps to be an example. Any others? I'm just wondering if there might be a condition for it. This seemed relevant but it relies on the sets having topologies on them, with ""nice"" properties. Continuous image of the intersection of decreasing sets in a compact space I was thinking about this in relation to a mapping of closed sets in a basis for a topology, and I suppose using topology would also be relevant then.","['elementary-set-theory', 'functions']"
777493,Do the Kolmogorov's axioms permit speaking of frequencies of occurence in any meaningful sense?,"It is frequently stated (in textbooks, on Wikipedia) that the ""Law of large numbers"" in mathematical probability theory is a statement about relative frequencies of occurrence of an event in a finite number of trials or that it ""relates the axiomatic concept of probability to the statistical concept of frequency"". Isn't this is a methodological mistake of ascribing an interpretation to a mathematical term, perhaps relying too much on the colorful language, that does not at all follow from how this term is mathematically defined? Recall the typical derivation of the WLLN: Let $X_1, X_2, ..., X_n$ be a sequence of n independent and identically distributed random variables with the same finite mean $\mu$, and with variance $\sigma^2$ and let: $\overline{X}=\tfrac1n(X_1+\cdots+X_n)$ We have: $E[\overline{X}] = \frac{E[X_1+...+X_n]}{n} = \frac{E[X_1]+...+E[X_n]}{n} =
 \frac{n\mu}{n} = \mu$ $Var[\overline{X}] = \frac{Var[X_1+...+X_n]}{n^2} = \frac{Var[X_1]+...+Var[X_n]}{n^2} = \frac{n\sigma^2}{n^2} =
\frac{\sigma^2}{n}$ And from Chebyshev's inequality: $P(|\overline{X}-\mu|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ And so X is said to converge in probability to $\mu$. Now consider what is strictly speaking the meaning of this expression in the axiomatic framework it is derived in: $P(|\overline{X}-\mu|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ $P()$, everywhere it occurs in the derivation, is known only to be a number satisfying Kolmogorov's axioms, so a number between 0 and 1, and so forth, but none of the axioms introduce any theoretical equivalent of the intuitive notion of frequency. If additional assumptions about $P()$ are not made, the sentence can obviously not be interpreted at all, but what is also important the theoretical mean $\mu$ is not necessarily the mean value in an infinite number of trials, $\overline{X}$ is not necessarily the mean value from n trials, and so forth. Consider an experiment of tossing a fair coin repeatedly - quite obviously, nothing in Kolmogorov's axioms enforces using 1/2 for the probability of heads, you could just as well use $1/\sqrt{\pi}$, yet the derivation continues to ""work"", except the meaning of the various variables is not in agreement with their intuitive interpretations. The $P()$ might still mean something, it might be a quantification of an absurd belief of mine, the mathematical derivation continues be true regardless, in the sense that as long as the initial $P()'s$ satisfy axioms, theorems about other $P()'s$ follow, and with Kolmogorov's axioms providing only weak constraints on and not a definition of $P()$, it's basically only symbol manipulation. This ""relative frequency"" interpretation frequently given seems to rest on an additional assumption, and this assumption seems to be a form of the law of large numbers itself. Consider this fragment from Kolmogorov's Grundbegriffe on applying the results of probability theory to the real world: We apply the theory of probability to the actual world of experiment
  in the following manner: ... 4) Under certain conditions, which we shall not discuss here, we may
  assume that the event A which may or may not occur under conditions S,
  is assigned a real number P(A) which has the following
  characteristics: a) One can be practically certain that if the complex of conditions S
  is repeated a large number of times, n, then if m be the number of
  occurrences of event A, the ratio m/n will differ very slightly from
  P(A). Which seems equivalent to introducing the weak law of large numbers in a particular, slightly different form, as an additional axiom. Meanwhile, many reputable sources contain statements that seem completely in opposition to the above reasoning, for example Wikipedia: It follows from the law of large numbers that the empirical
  probability of success in a series of Bernoulli trials will converge
  to the theoretical probability. For a Bernoulli random variable, the
  expected value is the theoretical probability of success, and the
  average of n such variables (assuming they are independent and
  identically distributed (i.i.d.)) is precisely the relative frequency. This seem to be mistaken already in claiming that from a mathematical theorem anything can follow about empirical probability (the page on which defines it as the relative frequency in actual experiment), but there are many more subtle claims that technically also seem erroneous from the above considerations: The LLN is important because it ""guarantees"" stable long-term results for the averages of random events. Note that the Wikipedia article about LLN claims to be about the mathematical theorem, not about the empirical observation, which was also historically sometimes been called the LLN. It seems to me that LLN does nothing to ""guarantee stable long-term results"", for as stated above those stable long-term results have to be assumed in the first place for the terms occuring in the derivation to have the intuitive meaning we typically ascribe to them, not to mention something has to be done to at all interpret $P()$ in the first place. Another instance from Wikipedia: According to the law of large numbers, if a large number of six-sided die are rolled, the average of their values (sometimes called the sample mean) is likely to be close to 3.5, with the precision increasing as more dice are rolled. Does this really follow from the mathematical theorem? In my opinion, the interpretation of the theorem that is used here, rests on assuming this fact. There is a particularly vivid example in the ""Treatise on probability"" by Keynes of what happens when one follows the WLLN with even a slight deviation from this initial assumptions of p's being the relative frequencies in the limit of an infinite number of trials: The following example from Czuber will be
  sufficient for the purpose of illustration. Czuber’s argument is as
  follows: In the period 1866–1877 there were registered in Austria m = 4,311,076 male births n = 4,052,193 female births s = 8,363,269 for the succeeding period, 1877–1899, we are given only m' = 6,533,961 male births; what conclusion can we draw as to the number n of female births? We
  can conclude, according to Czuber, that the most probable value n' = nm'/m = 6,141,587 and that there is a probability P = .9999779 that n will lie between
  the limits 6,118,361 and 6,164,813. It seems in plain opposition to
  good sense that on such evidence we should be able with practical
  certainty P = .9999779 = 1 − 1/45250 to estimate the number of female
  births within such narrow limits. And we see that the conditions laid
  down in § 11 have been flagrantly neglected. The number of cases, over
  which the prediction based on Bernoulli’s Theorem is to extend,
  actually exceeds the number of cases upon which the à priori
  probability has been based. It may be added that for the period,
  1877–1894, the actual value of n did lie between the estimated limits,
  but that for the period, 1895–1905, it lay outside limits to which the
  same method had attributed practical certainty. Am I mistaken in my reasoning above, or are all those really mistakes in the Wikipedia? I have seen similar statements all over the place in textbooks, and I am honestly wondering what I am missing.","['foundations', 'logic', 'probability-theory', 'philosophy', 'probability']"
777500,Prime number Stone-Weierstrass-looking problem,"Can you show that if $f \in C[0,1]$, and $\int_{0}^{1} f x^p dx =0$ for all primes $p$, that $f \equiv 0$?","['measure-theory', 'integration', 'real-analysis']"
777524,Showing that $\sum_{n=1}^{\infty} \frac{z^n}{1+z^{2n}}$ converges,Studying for an exit exam and it's been years since I work with any series expansions. Here's a past problem: Show that $$\sum_{n=1}^{\infty} \frac{z^n}{1+z^{2n}}$$ converges to an analytic function on the set $A=\{z \in \mathbb{C}: |z|<1 \}$. I'm looking to use Taylor's theorem for this problem but how would I compute the radius of convergence? Do I have to do a comparison test?,['complex-analysis']
777563,Codomain of a function,"At high school we were told that a function has a domain and a range, the function maps from the domain to the range. Such that the domain contains all and only the possible inputs and the range contains all and only the possible outputs. Now at University I'm told a function has a domain and a codomain, and that the codomain contains all the possible outputs but may also include other numbers. What is the point of having values in the codomain that can not be output by the function, how does that aid in describing the function? Does this also mean that the domain can include numbers that the are not inputs to the function? Surely this means you could say the codomain of any function (that outputs numbers) is the complex set (so all numbers)? EDIT: Wikipedia says the function $f : x \rightarrow x^2$ has codomain $\mathbb{R}$ but it's image (what I guess I knew as range in high school) is $\mathbb{R}^+_0$, so why not just say the codomain is $\mathbb{R}^+_0$. EDIT2: And is it also then true that is a function is ""onto"" the codomain is the same as the image? So surely any function can be ""onto"" if you just change the what the codomain is? What I'm really trying to ask I guess is the range/image of a function is defined by the function, what defines the codomain?","['functions', 'definition']"
777571,"$f(x) = \frac {ax+b}{cx+d}$ , bijection $f: \Bbb R \to\Bbb R$?","For which $a,b,c,d \in \Bbb R$ does $f(x) = \frac {ax+b}{cx+d}$ define a bijection $f: \Bbb R \to \Bbb R$? I'm guessing I need a system of equations and I know that $cx + d \ne 0$. Thanks!",['functions']
777592,TaylorSeries of complete elliptic integral of the first kind,"I want compute $K(k)$ as a Taylor Series; $k\in\mathbb{R}$ and $\vert k \vert < 1$ .
Can someone help me? $$
K(k):= \int^{\frac{\pi}{2}}_0 \dfrac{dt}{\sqrt{1-k^2 \sin^2t}}
$$ Results so far: $$
K(k):= \int^{\frac{\pi}{2}}_0 \dfrac{dt}{\sqrt{1-k^2 \sin^2t}} = \int^{\frac{\pi}{2}}_0 (1-k^2 \sin^2t)^{-\frac{1}{2}}dt
$$ With using binomial Series we get $$
\int^{\frac{\pi}{2}}_{0} \sum^\infty_{\Phi=0} {-\frac{1}{2} \choose \Phi}(-k^{2\Phi}){\sin^{2\Phi}{t}} \ dt = \sum^\infty_{\Phi=0} {-\frac{1}{2} \choose \Phi}(-k^{2\Phi})\int^{\frac{\pi}{2}}_{0}\sin^{2\Phi}t \ dt
$$ For $\Phi$ even: $$
\int^{\frac{\pi}{2}}_{0}\sin^{2\Phi}t \ dt = \frac{\pi}{2}\frac{1}{2}\frac{3}{4}\frac{5}{6}...\frac{n-1}{n} = S
$$ thus we get: $$
 1. \sum^\infty_{\Phi=0} {-\frac{1}{2} \choose \Phi}(-k^{2\Phi})\cdot S
$$ now i need some help to compute 1. as taylor series, can someone help? Thanks! Landau.","['elliptic-integrals', 'integration', 'functions', 'taylor-expansion']"
777593,Laplace Transform Piecewise Function,"I've never seen these types of bounds on a piecewise function of a Laplace transform before, can someone help explain how to solve this problem, particularly the Laplace transform of g(t)? Thanks in advance.","['ordinary-differential-equations', 'laplace-transform']"
777602,Use Cantor-Schroder-Bernstein to prove |X1|=|X2|,"If  $X_1 = \left\{\text{all functions }f: \mathbb{ R}\rightarrow \mathbb{ R}\right\}$ and $X_2=\left\{\text{all functions }g:\mathbb{R}\rightarrow\mathbb{R}\text{ such that }g(0)=0\right\}$, $a)$ Use Cantor-Schroder-Bernstein to prove |$X_1$|=|$X_2$| $b)$ Find a concrete bijection between both sets For part $a)$ I said that because $X_2 \subseteq X_1$, then $|X_2|\leq|X_1|$. So now I just need to find an injection between $X_1$ and $X_2$. I have tried a couple of functions but I always get that two functions in $X_1$ that differ only on their value for $x=0$ map to the same function in $X_2$, so it's not injective. So I don't know how to procede from here. Any help would be greatly appreciated.","['elementary-set-theory', 'functions']"
777624,proving a theorem of alternative,"I've read the following exercise in my book: Let $A\in\mathbb R^{m\times n},b\in\mathbb R^m,c\in\mathbb R^n$. Then exactly one holds: $Ax=0,c^t\cdot x=1$ with $x\geq0$ has a solution $A^ty\geq c$ has a solution I've tried to prove it but having some troubles with the solution. My attempt: Suppose 1. and 2. are right. Then 
$$y^t\cdot x\leq(A^ty)^t\cdot x=y^t\cdot Ax=0$$This is a contradiction. So both aren't solvable together. So suppose 1. hasn't got any solution. How can you show 2. has a solution? Thanks for helping! Edit: I want to use Farkas' Lemma .","['optimization', 'numerical-linear-algebra', 'linear-algebra']"
777633,Generality of rings' abelian group,"Let G be an abelian (finite) group. Is there a ring $R$ with $G$ isomorphic to the group $(R,+)$?","['ring-theory', 'finite-groups', 'group-theory']"
777636,"continuous, two-dimensional function","I have a question to this two dimensional function. $f_1(x,y):=\begin{cases} \frac{2xy}{x^2+y^2},&\text{if }(x,y)\neq(0,0)\\0,&\text{else}\end{cases}$ I want to analyse if this function is continous for $(x,y)=0$
I think i can show this with an $\epsilon-\delta$ proof $$|f(x,y)-f(0,0)|=\left|\frac{2xy}{x^2+y^2}\right|\leq 1$$ Would this be correct for the start? I dont know how to finish the proof. Thanks.","['epsilon-delta', 'multivariable-calculus', 'continuity']"
777643,Integral $\int_0^\infty \log(1+x^2)\frac{\cosh \pi x +\pi x\sinh \pi x}{\cosh^2 \pi x}\frac{dx}{x^2}=4-\pi$?,"Hello am looking for a solution to proving this.
$$
I:=\int_0^\infty \log(1+x^2)\frac{\cosh \pi x +\pi x\sinh \pi x}{\cosh^2 \pi x}\frac{dx}{x^2}=4-\pi.
$$
This one is related to Integral $\int_0^\infty \log(1+x^2)\frac{\cosh{\frac{\pi x}{2}}}{\sinh^2{\frac{\pi x}{2}}}\mathrm dx=2-\frac{4}{\pi}$ that the community together seemed to solve! I tried writing
$$
I=\int_0^\infty \log(1+x^2)\frac{dx}{x^2\cosh \pi x}+\int_0^\infty \log(1+x^2)\frac{\pi x\tanh \pi x}{\cosh \pi x }\frac{dx}{x^2}
$$
but is not so clear now that I have two integrals to solve.  I wasn't sure how integrating by parts would give me a clearer integral as the terms do not clean up here like the last one.  I am not sure how else Introducing something like $I(\alpha), I'(\alpha)$ in this situation did help but not much after this: $$
I(\alpha)=\int_0^\infty \log(1+\alpha x^2) \frac{\cosh \pi x +\pi x\sinh \pi x}{\cosh^2 \pi x}\frac{dx}{x^2}, \frac{dI}{d\alpha}=
$$ 
$$
\int_0^\infty \frac{dx}{1+\alpha x^2}\frac{\cosh \pi x +\pi x\sinh \pi x}{\cosh^2 \pi x}=\int_0^\infty \frac{dx}{(1+\alpha x^2)\cosh \pi x}+\pi\int_0^\infty \frac{dx}{1+\alpha x^2}\frac{x\tanh \pi x}{\cosh \pi x}
$$
  Thank you","['calculus', 'integration', 'definite-integrals', 'real-analysis', 'complex-analysis']"
777672,probability that something will occur given infinite time,"thanks in advance for the help.  Let r be a round.  Also let N be a set of coins.  Suppose that every round I flip all of the coins.  Is it correct to say given infinite rounds the probability that there will be at least one round where all N coins are heads or tails is 1?  If so how would I express this conclusion mathematically?  I believe that I could express this conclusion (as true) using a limit, but I'm not completely convinced that using a limit approach is logically correct.","['probability', 'limits']"
777690,"Is there an embedding of projective varieties $\mathrm{Grass}(r,n)\hookrightarrow(\mathbb{P}^{n-1})^{\times r}$?","Let $k$ be an algebraically closed field, and let $r\le n$ be positive integers.  Let $\mathrm{Grass}(r,n)$ be the projective variety of all $r$-dimensional planes in $k^n$.  Notice that $\mathrm{Grass}(1,n)\cong\mathbb{P}^{n-1}(k)$. For $r>1$, we have $\dim(\mathrm{Grass}(r,n))=r(n-r)<r(n-1)=\dim(\mathbb{P}^{n-1}(k))^{\times r}$ from which it follows that $\mathrm{Grass}(r,n)\not\cong(\mathbb{P}^{n-1}(k))^{\times r}$.  However, can we see $\mathrm{Grass}(r,n)$ as a subvariety of $(\mathbb{P}^{n-1}(k))^{\times r}$? Invoking the axiom of choice, if for each $r$-dimensional plane $W$ we choose a basis $\{w_1,\ldots,w_r\}$, then the map $W\mapsto ([w_1],\ldots,[w_r])$ is an injective mapping of sets, but unless there is some coherence to how the bases are chosen as $W$ ranges over all $r$-dimensional planes, this map will not identify $\mathrm{Grass}(r,n)$ with a subvariety of $(\mathbb{P}^{n-1}(k))^{\times r}$.  Is there some natural way to choose a basis for an $r$-dimensional plane $W$, or is there another way to view $\mathrm{Grass}(r,n)$ as a subvariety of $(\mathbb{P}^{n-1}(k))^{\times r}$?","['projective-space', 'algebraic-geometry', 'grassmannian']"
777724,Calculate $\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt$,"Calculate the following integral for $n \in \mathbb{Z}$ with the
  residue theorem $$\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt$$ So far I have tried two approaches. Firsty, for $n\geq 0$:
$$\begin{align*}\int_{0}^{2\pi} \frac{\cos((2n+1)t)}{\cos(t)}dt &= \int_{C(0,1)^{+}} \frac{z^{2n+1}+z^{-(2n+1)}}{z+z^{-1}}\cdot \frac{1}{iz}dz \\
& = -i \int_{C(0,1)^{+}} \frac{z^{2n+1}+z^{-(2n+1)}}{z^2+1}dz \\
& = -i \int_{C(0,1)^{+}} \frac{z^{2(2n+1)}+1}{z^{2n+1}(z^2+1)}dz \\
& = -i \cdot 2\pi i \cdot Res_{z=0}\left(\frac{z^{2(2n+1)}+1}{z^{2n+1}(z^2+1)}\right) \\
& = \left.\frac{2\pi}{(2n)!} \left[ \frac{z^{2(2n+1)}+1}{z^2+1} \right]^{(2n)} \right\rvert_{z=0}
\end{align*}$$ For the first equality I used the reversed parametrization  $z(t) = e^{it}$, with $0 \leq t \leq 2\pi$. The last equality follows from $Res_{z=a} \left( \frac{f(z)}{(z-a)^{n+1}}\right) = \frac{f^{(n)}(a)}{n!}$. However, I'm not sure how to calculate that derivative. Seconldy, I tried to integrate the function $f(z) = \frac{e^{i(2n+1)t}}{cos(t)}$. Using a similar technique this yields: $$\begin{align*}
\int_{0}^{2\pi} \frac{e^{i(2n+1)t)}}{\cos(t)}dt &= \int_{C(0,1)^{+}} \frac{z^{2n+1}}{(z+z^{-1})/2}\cdot \frac{1}{iz}dz \\
& = -2i\int_{C(0,1)^+}\frac{z^{2n+1}}{z^2+1}dz
\end{align*}$$ However, for $n \geq 1$, the singularities lie on my contour over which I integrate. How do I fix this? Can I just ignore that? Is this the right approach, or should I try differently? Thanks in advance.",['complex-analysis']
777740,Can a product of symmetric matrices give a non-zero skew symmetric matrix?,"I've been trying to find symmetric $\mathbf{A},\mathbf{B}$ such that $\mathbf{AB}$ is skew-symmetric, but it seems that no matter what I try, I end up forcing $\mathbf{AB}=\mathbf{0}$. Is it possible for this product to be non-zero? I've also tried proving that $\mathbf{AB}$ must be $\mathbf{0}$ but haven't got much further than $\mathbf{AB}=-\mathbf{BA}$.","['matrices', 'linear-algebra']"
777749,Convergence equivalence,"If $G_k(\mathbb{R}^m)=\{ W: W$ is subspace of $\mathbb{R}^m, \dim W=k \}$ and consider in $G_k(\mathbb{R}^m)$ one topology $\tau$ where $U\in \tau$ is open iff  the set $\widehat{U}=\lbrace v: v\in W\backslash \lbrace 0\rbrace, \mbox{for some}  \ W\in U \rbrace$ is open in $\mathbb{R}^m$ I'm testing the following: If for every $k\in \mathbb{N}$ there is a basis $\lbrace u^k_1,\ldots,u^k_n\rbrace$ of $S_k$ such that $\Lambda=\lbrace \displaystyle{\lim_{ k \rightarrow +\infty}}u^k_1,\ldots,\displaystyle{\lim_{ k \rightarrow +\infty}}u^k_n\rbrace$ is a basis of $S$ then $\lbrace S_k\rbrace \subset G_n(\mathbb{R}^m)$ converges to $S\in G_n(\mathbb{R}^m)$ . My progress: Let $U$ open of $S$ in $G_n(\mathbb{R}^m)$ . Given that $\widehat{U}$ is open in $\mathbb{R}^m$ such that $\Lambda \subset \widehat{U}$ , there $k_0 \in \mathbb{N}$ such that $u^k_j \in \widehat{U}$ for all $k\geq k_0$ and all $1\leq j\leq n$ . There $W_j\in U$ such that $u^k_j\in W_j$ . But as showing $W_j=S_k$ for all $1\leq j\leq n$ ? Note: The other direction of the statement is also true but I only need the above. This is an example of open","['general-topology', 'grassmannian', 'real-analysis']"
777753,Prove this identity: $\frac{2\sin^4x+\cos^2x-2\cos^4x}{3\sin^2x-1} =1$,"I am stuck on this identity
$$\frac{2\sin^4x+\cos^2x-2\cos^4x}{3\sin^2x-1} =1$$ I began working on the left side trying to get things to cancel out or equal one by the Pythagorean identities. I am stuck and can't get it to reduce anymore.","['trigonometry', 'algebra-precalculus']"
777773,Asymptotic evaluation of integral method of steepest descent,"The question asks to show that the leading term of the integral $$
\int_{-\infty}^\infty (1+t^2)^{-1}\exp\left(ik(t^5/5+t)\right) dt
$$ for large $k$ using the method of steepest descent is equal to $$
\sqrt{\frac{\pi}{k}} e^{\frac{-4k}{5\sqrt2}} \cos\left(\frac{4k}{5\sqrt2} - \frac{3\pi}{8}\right)
$$ ...I don't even know how to pick my contour for this problem.  Thanks for the help!","['asymptotics', 'complex-analysis']"
777775,Combinatorics - Counting in two ways? [duplicate],"This question already has answers here : Counting two ways, $\sum \binom{n}{k} \binom{m}{n-k} = \binom{n+m}{n}$ [duplicate] (2 answers) Closed 10 years ago . What is the idea of proving a binomial identity by counting in two ways ? Could you please illustrate this with this example? Thank you very much. $$\binom{2n}{n}= \sum_{k=0}^n {\binom nk}^2$$ (original screenshot)",['combinatorics']
777806,Finite Trigonometric Sum,"I have a dynamical system model whose equilibria depend on the solution of the following finite sum: \begin{align}
\sum_{j\neq i}^n\frac{\sin(\theta_j-\theta_i)}{\left(1-\cos(\theta_j-\theta_i)\right)^{3/2}}=0
\end{align} I think I'm ok to suppose $\theta_i=0$ and run the sum from $j=1$ to $j=n-1$. Is this alright? Also, can I jettison the denominator altogether and focus on the sine terms? The solutions should be confined to the domain $(\theta_j-\theta_i)\in[0,2\pi]\:\forall\: j$. Im sure they are related to the roots of unity but haven't worked that out. Maybe there is some clever way to solve this equation once and for all? \begin{align}
\sum_{j=1}^{n-1}\sin\left(\frac{2\pi j}{n}\right) = 0
\end{align} Does this exhaust the solutions? Assume that it does for a moment. This constraint on the angles in the system then leads finally to an additional trig sum that has some interesting properties. It appears that if the $l|k$ then the $k^{th}$ term contains the $l^{th}$ term with an additional factor. viz: \begin{align}
\frac{1}{2\sqrt{2}}\sum_{j=1}^{n-1}\frac{1}{\sqrt{1-\cos(\frac{2\pi j}{n})}} = \frac{1}{4}\sum_{j=1}^{n-1}\csc\left(\frac{\pi j}{n}\right)
\end{align} The first 12 terms: \begin{align}
&0,\:\frac{1}{4}\:,\frac{1}{\sqrt{3}}\:,\frac{1}{4}+\frac{1}{\sqrt{2}}\:,\sqrt{1+\frac{2}{\sqrt{5}}}\:,\frac{5}{4}+\frac{1}{\sqrt{3}},\\[2mm]
&\frac{1}{\sqrt{2 \left(1+\sin \left(\frac{\pi}{14}\right)\right)}}+\frac{1}{\sqrt{2-2 \sin \left(\frac{3 \pi }{14}\right)}}+\frac{1}{\sqrt{2\left(1+\cos \left(\frac{\pi}{7}\right)\right)}},\\[2mm]
&\frac{1}{4}+\frac{1}{\sqrt{2}}+\sqrt{2+\sqrt{2}},\\[2mm]
&\frac{1}{\sqrt{3}}+\frac{1}{\sqrt{2-2 \sin \left(\frac{\pi }{18}\right)}}+\frac{1}{\sqrt{2 \left(1+\cos \left(\frac{\pi}{9}\right)\right)}}+\frac{1}{2} \csc \left(\frac{\pi}{9}\right),\frac{1}{4}+\sqrt{5}+\sqrt{1+\frac{2}{\sqrt{5}}},\\[2mm]
&\frac{1}{\sqrt{2 \left(1+\sin\left(\frac{\pi }{22}\right)\right)}}+\frac{1}{\sqrt{2-2 \sin \left(\frac{3 \pi}{22}\right)}}+\frac{1}{\sqrt{2 \left(1+\sin \left(\frac{5 \pi}{22}\right)\right)}}+\frac{1}{\sqrt{2 \left(1+\cos \left(\frac{\pi}{11}\right)\right)}}+\frac{1}{2} \csc \left(\frac{\pi}{11}\right),\\[2mm]
&\frac{5}{4}+\sqrt{6}+\sqrt{\frac{5}{6}+\sqrt{\frac{2}{3}}}
\end{align} You see for example 6 is divisible by 2 and 3 and the 6th term is equal to the 2nd term plus the 3rd term  plus 1. This sequence must be related the the symmetry point group $C_{nh}$ and its subgroups but how?","['roots-of-unity', 'finite-groups', 'analysis', 'summation', 'trigonometric-series']"
777834,Maximum/Minimum of Curvature - Ellipse,"Find the sum of the maximum and minimum of the curvature of the ellipse: $9(x-1)^2 + y^2 = 9$. Hint (Use the parametrization $x(t) = 1 + \cos(t)$) Tried to use parametrization like that, but then get stuck trying to find the curvature function and max/minimizing it.","['multivariable-calculus', 'curvature', 'conic-sections']"
777876,Inequality problem about sides of a triangle and the semiperimeter,"Let $a,b,c$ the sides of a triangle and $s$ be the semi perimeter. Then show that 
$$
              a^2+b^2+c^2 > \frac{36}{35}(a^2+\frac{abc}{s})
$$
I tried it doing in many ways using some changes but cannot help my cause.","['geometry', 'triangles', 'trigonometry', 'inequality']"
777886,Proving $\phi$ is well-defined,"Let $H$ and $K$ be normal subgroups of a group $G$, with $H \subseteq K$. Define $\phi: G/H \rightarrow G/K$ by $\phi(Ha)=Ka.$ Prove that $\phi$ is a well-defined function (i.e., if $Ha=Hb$, then $\phi(Ha)= \phi(Hb)$. Honestly I have never understood well-defined and how to prove it.","['group-theory', 'abstract-algebra']"
777891,Why is calculating the area under a curve required or rather what usage it would provide,I understand Integration and Differentiation and see a lot of Physics / Electrical Theory using them. Take for example a sine wave. So area for me means the space any object would occupy. So what's usage it comes to find the area of a sine curve? There are so a many formulas that calculates the area by Integration - but why calculation is required - I mean what information we can get (isn't it just space occupied) or rather what data we can find by calculating area of a curve via Integration?,"['calculus', 'integration']"
777912,Invertibility of uncertain matrix,"Given that we start with some $n\times n$ square matrix $A_0$ that is non-singular. We add some perturbation to it, $\Delta A$, so that our new matrix is $A = A_0 + \Delta A$. The question is whether we can guarantee invertibility of our new $A$ matrix if $|\Delta A_{ij}|<\rho$. We can refer to this $\rho$ as the radius of invertibility or radius of non-singularity. There seems to be a paper that talks about this exact problem, the additive case: http://www.eecs.berkeley.edu/~elghaoui/Pubs/InvErr_LAA02 . It says that $\rho$ is the smallest singular value of $A$. My question is, if we generate some random $A$ matrix that invertible, can we experimentally converge on $\rho$ through numerous trials? I suppose this is more of a question about possible algorithms than linear algebra.",['linear-algebra']
777925,Prove that the maximum volume of a triangular-base prism is $\sqrt{\frac{K^3}{54}}$ where $K$ is the area of three triangles containing a vertex $A$,"Consider a prism with triangular base. The total area of the three faces containing a particular vertex $A$ is $K$. Show that the maximum possible volume of the prism is $\sqrt{\frac{K^3}{54}}$ and find the height of this largest prism. I have no idea how to approach the problem. Please help. I know we need to use the properties of triangles and also the AM-GM inequality somewhere, but cannot put it together to solve the problem.","['geometry', 'triangles', 'area']"
777946,Prove that $Z(G)$ which is the center of $G$ is a subgroup of $G$,"Question: Let $G$ be a group. Prove that $Z(G)$ is a subgroup of $G$ . If I want to show that $Z(G)$ is a subgroup of $G$ that means I have to show that it is closed under group operation? Here is my attempt. Let $a,b$ be elements in $Z(G)$ and $x$ be an element in $G$ . Then $ax=xa$ which is under group multiplication commutative and under inverse $(a^{-1}) x=x(a^{-1})$ . And hence $(a^{-1})bx= (a^{-1})xb=x (a^{-1})b$ which is under group operation so $(a^{-1}),b$ are elements in $Z(G)$ thus a subgroup of $G$ . Really appreciate if anyone can help me by directing me if my attempt is not good.
Thanks in advance.",['group-theory']
777966,Simplifying $\frac1{1+x}+\frac2{1+x^2}+\frac4{1+x^4}+\frac8{1+x^8}+\frac{16}{x^{16}-1}$,"We need to simplify $$\dfrac{1}{1+x}+\dfrac{2}{1+x^2}+\dfrac{4}{1+x^4}+\dfrac{8}{1+x^8}+\dfrac{16}{x^{16}-1}$$ The last denominator can be factored and we can get all the other denominators as factors of $x^{16}-1$. I tried handling the expressions in pairs,starting from the right.I also tried to take a common factor of two out of the numerators to help simplify,but that has yielded nothing.I then tried multiplying all the fractions to get $x^{16}-1$ in the denominator but that worsens things(I think so anyway). So after doing the above things(and much more),I feel like I am running out of ideas.A really small hint will be appreciated.",['algebra-precalculus']
778010,Reference request: a differential equation arising in geometry,"$$
\frac{d\beta}{d\alpha} = \frac {\sin\beta}{\sin\alpha}
$$
In what contexts (if any) is this equation known to occur?","['ordinary-differential-equations', 'reference-request']"
778036,How do I tell whether axiom of choice is used or not?,"I am having a hard time understanding the Axiom of Choice(AC). Say I have an index set $A$ , and a collection of indexed sets {${V_\alpha}$}, where $\alpha$ is a member of $A$. Then, does the difficulty of defining a ""choice function"" come from the fact that (a) elements of each set $V_\alpha$ in the collection might not be ""ordered"" (in some sense) so that whoever is constructing a choice function is not sure which element to choose from each set? OR (b) the collection might be uncountably infinite so that there seems to be no systematic way to go through each set (without missing one) in the collection? Or (c) Is it both? As an illustration of my confusion with AC, please consider the following examples. (1) If I want to prove that the square of a real number is always non-negative, then I would begin my proof by saying that ""Pick any real number $x$."" Here, am I using AC?
I am ""choosing"" an element from the set of real numbers $R$, but I am not specifying ""how"" so I feel that I am using AC. On the other hand, however, since I only have one set $R$, it seems intuitively obvious that I can just ""grab"" any element from the set without a problem. (2)  Here is the proof by Rudin of the theorem that monotonic functions have at most countable discontinuities. When Rudin writes that ""with every point x of E, we associate a rational number $r(x)$"", is he using AC here? If I can somehow associate a natural number n(x) with every point x of E, would I still be using AC? I am sorry if my questions are a bit all over the place, but I would appreciate it very much if you could help me understand AC!","['set-theory', 'axiom-of-choice', 'analysis']"
778058,How to evaluate $\lim_{n \to \infty} \int_0^1 \arcsin (\sin(nx)) dx$?,"I would like to evaluate $\lim_{n \to \infty} \int_0^1 \arcsin (\sin(nx)) dx$ . I think the answer is 0, but can't prove it. The problem is difficult because of rapid oscillations.","['calculus', 'integration', 'limits']"
778068,$\ln|x|$ vs.$\ln(x)$? When is the $\ln$ antiderivative marked as an absolute value?,"One of the answers to the problems I'm doing had straight lines:
    $$ \ln|y^2-25|$$ versus another problem's just now:
    $$ \ln(1+e^r) $$ I know this is probably to do with the absolute value.  Is the absolute value marking necessary because #1 was the antiderivative of a squared variable expression that could be either positive or negative (and had to be positive because, well, natural log) and the second was positive by default? Sorry if this is me asking and answering my own question; I'd just love to get confirmation in case I'm wrong.","['calculus', 'integration']"
778130,"$[D,D']$ where $D$ is a derivation and $D'$ is skew","This is a proposition in 33 page of Foundation in Differential Geometry - KN 
   I need some detail. Let $D^r(M)$ be a set of $r$-form. Then derivation (resp. skew-derivation) of degree $k$ is a linear mapping from $D^r(M)$ to $D^{r+k}(M)$
 s.t. $$ D(\omega \wedge \tau ) = D\omega \wedge \tau + \omega \wedge D\tau $$ (resp. $ D(\omega \wedge \tau ) = D\omega \wedge \tau + (-1)^r \omega \wedge D\tau $) where $\omega \in D^r(M)$ Note that ${\bf exterior\ differentiation}$ is skew of degree $1$. ${\bf Question}$ : I wanto prove that $[D,D']$ is skew of degree $k+k'$ where $D$ is derivation of degree $k$ and $D'$ is skew of degree $k'$ ${\bf Try}$ : $$ DD' (\omega \wedge \tau ) = D\{ D'\omega \wedge \tau + (-1)^r\omega \wedge D'\tau \} $$ $$ = DD'\omega \wedge \tau + D'\omega \wedge D\tau +(-1)^rD\omega \wedge D'\tau + (-1)^r\omega \wedge D D'\tau$$ $$D'D(\omega \wedge \tau ) = D'\{ D\omega \wedge \tau + \omega \wedge D\tau \} $$ $$ = D'D\omega\wedge \tau +  (-1)^{k+r}D\omega \wedge D'\tau +D'\omega \wedge  D\tau + (-1)^r\omega \wedge D'D\tau
$$ So $$ [D,D'] (\omega \wedge \tau )=[D,D']\omega \wedge \tau + (-1)^r \omega \wedge [D,D']\tau + [(-1)^r - (-1)^{k+r}]D\omega \wedge D'\tau $$ Am I miss something ? Why do not the last term disappear ?",['differential-geometry']
778171,Intersection of Ellipsoid with Ray,"Let $E$ be an ellipsoid centered at $p = (x,y,z) \in \mathbb{R}^3$ and
  let $T:\mathbb{R}^3 \to \mathbb{R}^3 $ be a linear transformation
  which transforms $E$ to a unit sphere. Let $R$ be the ray $p_0 + tv$ ($v$ is normalized). Assume we want to find the minimal $t \ge 0 $ if any such that $R$
  intersects $E$. I tried to define the ray $R_T$ to be $T(p_0) + tT(v)$ (where $T(v)$ is normalized) and find the minimal $t'\ge0$ if any such that $R_T$ intersects the unit sphere centered at $T(p)$. If there was no intersection with $t\ge0$ then there is no intersection with $E$. Otherwise the new $t$ is the dot product of $v$ and $T^{-1}(t' \cdot T(v))$. Is this correct? if $T(v)$ wasn't normalized in $R_T$ and we found the intersection with a sphere then the found $t$ would be the same for $E$ ?","['geometry', 'linear-algebra', '3d', 'multivariable-calculus']"
778173,"Tridual-""Reflexive""","Let $X$ be an Banach space, and $X^*$ the space of linear functionals on $X$. The dual of $X^*$ is called the bidual, and if the bidual $X^{**}=X$, we say that $X$ is a reflexive space. It is well known that the $L^p$-spaces ($1<p<\infty$) are reflexive. Now, let us define the tridual to be the dual of the bidual, $X^{***}$. Are there spaces $X$ such that $X^{***}=X$? What about ""reflexivity"" with respect to n-duals? Does this have any application?","['functional-analysis', 'banach-spaces']"
778175,Diagonal morphism,"Hello I'm starting to study algebraic geometry on my own with a book and I've been thinking on this problem a few days. I'd appreciate if someone could help me. Let $V$ be an affine variety. We define diagonal map as $$\Delta:V\rightarrow \Delta (V)\subset V \times V $$   $$ v\longmapsto(v,v)$$
(a) Prove that $\Delta$ is a morphism. (b) Let $V=\mathbb{A}^n(k)$ and fixed coordinates $x_1,...,x_n,y_1,...,y_n$ en $\mathbb{A}^n(k)\times \mathbb{A}^n(k)$. Show that $I(\Delta _V)= \langle x_1-y_1,...,x_n-y_n \rangle$. (c) For general affine variety $V$, prove that $\Delta _V$ is closed in $V \times V$. (d) Show that $\Delta:V \rightarrow  \Delta _V$ is an isomorphism. My attemp: (a) I've proved that statement and I'm sure it's correct. (b) I can't prove that, I tried many things but  I don't get the solution. (c) I don't know if this solution it's right. A topological space $V$ is Hausdorff iff the diagonal set $\Delta _V$ is closed. So if $V$ is an affine variety, and $x,y \in V, x \neq y$. If I consider the lineal polinomial $f $ so that $f(x)=0$, and the paralel lineal polinomial $g$ that anihilates $y$ (It's possible since $x \neq y$), then $U,W$  (subset of points of $V$ such that anihilates f or g, respct.) are disjoint neigbourhoods of $x,y $ and hence, $V$ is Hausdorff. (d) I've thinked about using projections $\pi_1,\pi_2: V \times V \rightarrow V$, but I didn't get the solution. Thanks in advance","['commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
778202,Convergence of infinite product $\prod_{n=2}^\infty (1- \frac 1n) $,"I am revising Complex Analysis and I am a bit confused. I have a couple of results from lectures which say that  $\prod_{n=1}^\infty (1+a_n)$ converges if and only if the sum $\sum_{n=1}^\infty \log(1+a_n) $ converges absolutely. And also, the infinite product converges absolutely if and only if the $|a_n|$ are summable. Consider the example:
$$\prod_{n=2}^\infty \left(1- \frac 1n\right) $$
It can easily be shown that the partial product $\prod_{n=2}^{N} (1- \frac 1n) = \frac 1N $ which tends to zero as $N\to \infty$ Maybe I'm interpreting the theorems wrong, but the sums: $\sum_{n=2}^\infty |\log(1-\frac 1n)| $ and $\sum_{n=1}^\infty |-\frac 1n| $ both diverge, so from the results I listed at the start, the product cannot converge, but it does - to zero. I'm getting quite confused here so I would appreciate some help!","['convergence-divergence', 'sequences-and-series', 'infinite-product', 'complex-analysis']"
778215,Permutation of matrix elements,"Let each row and each column of a $n\times n$ matrix $A$ be a permutation of $\{1,2,\ldots,n\}$ and
let $A$ be symmetric. (a) If $n$ is odd, prove that each of $1,2,\ldots,n$ occurs on the principle diagonal of $A$. (b) For every even number $n$, show that there exists an $A$ in which not all of $1,2,\ldots,n$
appear on the diagonal. My knowledge of matrices is pretty basic. I have noticed similar types of questions before. What topics do I need to learn to solve these types of problems?","['matrices', 'linear-algebra']"
778233,Is there any perfect squares that are also binomial coefficients?,"Examining the Tartaglia's triangle, I have observed that all the squares were the trivial cases, that is, $\binom{n^2}1$ or $\binom{n^2}{n^2-1}$. More formally: Conjecture : If $\binom nm=k^2$ then $n=k^2$. Is it known to be true? I have tried to use the formula $$\nu_p\left(m!\right)=\sum_{k=1}^\infty\left\lfloor \frac m{p^\alpha}\right\rfloor$$ to prove that the exponents of the factorization of the binomial coefficients are odd, but I realized that this cannot be proved, because the binomial coefficients needn't be square-free: $\binom 63=20$, for example. Any ideas?","['number-theory', 'combinatorics']"
778249,Differential equations books using lots of algebraic topology?,"The wikipedia page on 'Algebraic Topology' contains the following sentence: One can use the differential structure of smooth manifolds via de Rham cohomology, or Čech or sheaf cohomology to investigate the solvability of differential equations defined on the manifold in question. Unfortunately, no concrete references are added. Are there good textbooks or other sources on applications of algebraic topology to solvability (and perhaps other qualitative aspects) of differential equations?","['algebraic-topology', 'ordinary-differential-equations', 'reference-request']"
778252,Find basis such that bilinear forms attain normal form,"Let $g :=$ symmetric bilinear form : $g(v,w) := \omega(v,Jw)$ with $J \in \textrm{O}(V,g)$ and $\omega := $ skew-symmetric bilinear form : $\omega(v,w) := g(v,Jw)$ with $J \in \textrm{Sp}(v,\omega)$. $J$ is defined as an almost complex structure such that $J \in \textrm{O}(V,g) : J^2 = -\textrm{id}$. The normal form of bilinear forms is defined as either
$$J_{2r} = \begin{pmatrix} 0 & I_r \\ -I_r & 0 \end{pmatrix} \qquad \textrm{or} \qquad J_{2r} = \textrm{diag} \left( \begin{pmatrix} 0 & 1 \\ -1 & 0\end{pmatrix},...,\begin{pmatrix} 0 & 1 \\ -1 & 0\end{pmatrix} \right) $$ We also know the equality $B = A \cdot C$ for $A$ the gramian matrix associated to the basis $(v_i)$ of $g$, $B$ the matrix associated to $\omega$ and $C$ the matrix associated to $J$. Show that there exists a basis $(v_i)$ of the $n$-dimensional $\mathbb R$ vector space $V$ such that the gramian matrices for the non degenerate symmetric bilinear form $g$ and the symplectic form $\omega(,) := g( ,J())$ have normal form and show that $g(J(), )$ defines a symplectic structure as well. What is the relationship of $g(J(), )$ to $\omega$ ? So $g$ and $\omega$ are inverse to each other and since $g$ is non degenerate, $\omega$ is also non degenerate (follows from small lemma). To show that $g(J(), )$ also defines a symplectic structure, I tried to show that $g(Jv,w) = -g(Jw,v)$: $$g(Jv,w) \overset{\text{J orthogonal}}{=} g(J^2v, Jw) = g(-v, Jw) = -g(v, Jw) \overset{\text{g symmetric}}{=} -g(Jw, v).$$ So $g$ is alternating and since it is non degenerate by assumption it is symplectic, but how about showing the existence of the basis? Can anybody help???","['almost-complex', 'linear-algebra', 'bilinear-form']"
778265,Double Think about Numerosity,"According to standard mathematics, the Natural Numbers are given.
Moreover, they are given as a (completed) Infinite Set. This set is commonly
denoted as:
$$
  \mathbb{N} = \left\{ 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,\,
        \dots \right\}
$$ Theorem. The set of all natural numbers is a completed infinity. Proof. A set is infinite (i.e. a completed infinity) if there
exists a bijection between that set and a proper subset of itself. Now consider
the even naturals. They are a proper subset of the naturals and a bijection can
be defined between the former and the latter. The ""numerosity"" of the evens is equal to the ""numerosity"" of the naturals. There are ""as many"" evens as there are naturals. As follows: 2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 ...
  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 ... Galileo's Paradox . The cardinality of the squares equals the cardinality of the naturals. There are ""as many"" squares as there are naturals. Proof. There exists a bijection between the naturals and the squares. The numerosity of the squares equals the numerosity of the naturals: 1 2 3  4  5  6  7  8  9  10  11  12  13  ..
| | |  |  |  |  |  |  |   |   |   |   |
1 4 9 16 25 36 49 64 81 100 121 144 169  .. The cardinality of the powers of $7$ equals the cardinality of the
naturals. There are ""as many"" powers of $7$ as there are naturals. Proof. There exists a bijection between the naturals and these powers: 1  2   3    4     5      6      7       8        9        10  ..
|  |   |    |     |      |      |       |        |         | 
7 49 343 2401 16807 117649 823543 5764801 40353607 282475249  .. In general. Let there be defined a function $\;A(n) : \mathbb{N} \rightarrow \mathbb{N}$ .
Assume that $\,A(n)\,$ is a sequence which is monotonically increasing with $\;n\;$ . Then we have the following bijection: 1     2     3     4     5     6    7     8     9   .. 
   |     |     |     |     |     |    |     |     |
 A(1)  A(2)  A(3)  A(4)  A(5)  A(6) A(7)  A(8)  A(9)  .. It can be concluded that the cardinality of the set 
$\;\left\{n\in\mathbb{N}:A(n)\right\}\;$ is $\;\aleph_0\;$, which is the cardinality of the naturals. Examples are: $A(n) = 2\cdot n\;$ (the even numbers) $A(n) = n^2\;$ (Galileo's paradox) $A(n) = 7^n\;$ (powers of seven) But let's have a second thought about all this [ e.g with $A(n) = 7^n$ ]: 1   2 3 4 5 6   7  8 9 10 .. 48  49  50 .. 343 .. 2401 ..
  0   0 0 0 0 0   1  1 1  1     1   2   2      3       4   : D(n)
A(0)            A(1)              A(2)       A(3)    A(4) Let $D(n)$ be the number of $A(m)$ values (count) less than or equal to $n$,
where $(m,n)$ are natural numbers. Then we have the following theorem , tentatively
called the Inverse Function Rule :
$$
 \lim_{n\rightarrow \infty} \frac{D(n)}{ A^{-1}(n) } = 1
$$ Proof. $A(n)$ is monotonically increasing with $n$ , therefore the inverse
sequence $A^{-1}(n)$ exists in the first place.
And it is monotonically increasing as well. Furthermore,
we see that $\,D(n)\,$ is $\,m\,$ for $\,A(m) \le n < A(m+1)$ . Consequently: $\;A(D(n)) \le n < A(D(n)+1)\;$ , hence $\;D(n) \le A^{-1}(n) < D(n) + 1\;$
, therefore $\;A^{-1}(n) - 1 < D(n) \le A^{-1}(n)\;$ . Divide by $\;A^{-1}(n)\;$ to get: $\;1 - 1/A^{-1}(n) < D(n) / A^{-1}(n) \le 1\;$ .
For $\,n\rightarrow \infty\,$ now the theorem follows, because
$\;A^{-1}(n) \rightarrow \infty\;$ . Written as an asymptotic equality: $\,D(n) \approx A^{-1}(n) $ . Examples. Revealing the Double Think. $A(n) = 2.n \;\Longrightarrow\;\lim_{n\rightarrow\infty} D(n)/[\,n/2\,] = 1 \;\Longrightarrow\; D(n) \approx n/2$ The numerosity of the evens is not equal but half the numerosity of the naturals $A(n) = n^2 \;\Longrightarrow\;\lim_{n\rightarrow\infty} D(n)/\sqrt{n} = 1\;\Longrightarrow\; D(n) \approx \sqrt{n}$ The numerosity of the squares is the square root of the numerosity of the naturals $A(n) = 7^n \;\Longrightarrow\;\lim_{n\rightarrow\infty} D(n)/[\,\ln(n)/\ln(7)\,] = 1\;\Longrightarrow\; D(n) \approx \log_7(n)$ The numerosity of the powers of 7 is the 7-logarithm of the numerosity of the naturals Still another example at the Wikipedia page about Fibonacci number s :
For large $\,n$ , the Fibonacci numbers are approximately $F_n \approx \phi^n/\sqrt{5}$ .
Giving a limit similar to the one for the powers of seven:
$$
 A(n) = F_n \quad\Longrightarrow\quad \lim_{n\rightarrow\infty}
        \frac{D(n)}{\ln(n.\sqrt{5}) / \ln( \phi )} = 1 
        \qquad \mbox{where} \quad \phi = \frac{1}{2}(1+\sqrt{5})
$$ Question . My problem is nomenclature in the first place.
The term Inverse Function Rule seems to have been coined up somewhere
on the internet but I could't find any application resemblant to the above -
there also is a rumour that it goes all the way back to Carl Friedrich Gauss,
but I coun't find any sensible reference confirming this. Wouldn't even dare to ask about the more important thing, namely what is the ""correct"" way to no double think about numerosities: cardinalities or via the ""inverse function rule"" ?","['inverse', 'sequences-and-series', 'limits']"
778278,"Hints on calculating the integral $\int_0^1\frac{x^{19}-1}{\ln x}\,dx$","I would be happy to get some hints on the following integral:
$$
\int_0^1\frac{x^{19}-1}{\ln x}\,dx
$$","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'logarithms']"
778287,number of lattice points in an n-ball,"I have faced a problem in my work and I will appreciate any hint/reference as I am not much into the lattice problems. Assume an n-dimensional lattice $\Lambda_n$ with generator matrix $G$. Note that lattice points are not necessarily integer, i.e., $x\in \mathbb{R}$ where $x$ is a lattice point. Is there a way to count/estimate/bound the number of lattice points inside and on an n-ball? any hint or reference to appropriate literature is appreciated","['geometry', 'geometry-of-numbers', 'integer-lattices', 'combinatorics']"
778373,"If this relation holds, then is the triangle equilateral?","Let $ABC$ be a triangle. If $$\sum_{cyc}\frac{BC}{4AC\cos^2({\frac{\angle BAC}{2})}+BC}=\frac{3}{4}$$ then the triangle is equilateral? We can check if we set $\widehat{BAC}=\pi/3$ and $AB=BC=CA$ that the relation holds. If yes, how to prove this?
Thank you!","['geometry', 'triangles', 'trigonometry']"
778386,Span of union of subspaces,"I was reading a proof in my linear algebra notes, and it says: Let $U, W$ be subspaces of $\mathbb{R}^3$ , $U = \text{span}\{(1,0,1), (0,1,1)\}$ , $W = \text{span}\{(1,1,0), (0,1,1)\}$ Then it goes on to say $\text{span}(U \cup W) = \text{span} \{ (1,0,1), (0,1,1), (1,1,0) \}$ Why does the span of the union of $U$ and $W$ equal the span of the union of the sets that span $U$ and $W$ ?","['vector-spaces', 'linear-algebra']"
778390,Continuous complex function without antiderivative,"It's a well-known result that every real continuos function has an antiderivative. Is this theorem still true for a complex function? If not, can someone point out a counter-example (and proof that it is indeed a counter-example)?",['complex-analysis']
778426,continuous function using the monotone convergence theorem,"Let $f:\mathbb{R} \longrightarrow \mathbb{R}^+$ an integrable function. Defines $g(x)=\int_{-\infty}^{x}f(t) dt$. Show that $g$ is continuous using the monotone convergence theorem. I cannot find out the way of apply the monotone convergence theorem there, how can I define an increasing sequence related to $g$? I'll appreciate any suggestions, thanks.",['measure-theory']
778440,Spectrum of a product of rings isomorphic to the product of the spectra,I've found in an exercise this statement: If $A$ is a commutative ring with unit and $A = A_{1} \times \dots \times A_{n}$ then $$\def\Spec{\operatorname{Spec}} \Spec(A) \cong  \Spec(A_{1})\times \dotsb \times \Spec(A_{n})$$ Why is this true ?,"['commutative-algebra', 'ring-theory', 'ideals', 'abstract-algebra']"
778454,Does every prime > 2 have a primitive root that is a prime?,"Every prime number has a primitive root. Actually, for every prime number p a considerable percentage of the numbers from 2 to p-1 are primitive roots (with the exception p = 2 which is the only prime that has 1 as a primitive root). Following a discussion how to find primitive roots, I thought it would be a good idea to start checking whether the small primes (2, 3, 5, 7, 11, ... ) are primitive roots because they seem to be more than average likely to be primitive roots. That obviously raises the question whether every prime p other than 2 actually has a primitive root in the range from 2 to p-1 that is prime. Googling didn't find any answer. There doesn't seem to be an obvious answer, for example p = 41 has the primitive root 6 but neither 2 nor 3 are primitive roots (2^20 = 3^8 = 1 modulo 41). There should always be a prime primitive root because of the sheer numbers of primitive roots (p = 271 with smallest prime primitive root 43 seems quite exceptional), but a proof would be nice.",['number-theory']
778455,Invert a matrix.,"$$A=\begin{pmatrix}1 & -a_1 & -a_1 &\cdots & -a_1\\
-a_2 & 1 &-a_2 & \cdots &-a_2\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
-a_{N-1} & -a_{N-1} & \cdots& 1 & -a_{N-1}\\
-a_N & -a_N & \cdots & -a_N & 1
\end{pmatrix}.$$ Where $a_i\geq0\;\forall\; i\in\{1, \cdots, N\}$ and $$\sum\limits_{i=1}^{N}\dfrac{a_i}{a_i+1}<1.\quad (1)$$ EDIT 1 : The condition $(1)$ must guarantee that the inverse exists. EDIT 2 In fact, there is no formula given for $A^{-1}$. The problem is to find $P_i$ in the following equation: $$P_i-a_i\sum\limits_{j\neq i}^{N}P_j=\alpha a_i\;\forall\;i\in\{1, \cdots, N\}.$$
This is equivalent to $AP=b$ and hence $P=A^{-1}b$.
They said that $P_i$ is given by: $$P_i=\dfrac{\alpha}{1-\sum\limits_{j=1}^{N}\dfrac{a_j}{1+a_j}}\dfrac{a_i}{1+a_i}.$$
Where $b=[\alpha a_1, \alpha a_2, \cdots, \alpha a_N]^{\mathrm{T}}$ and $P=[P_1, P_2, \cdots, P_N]^{\mathrm{T}}.$ This matrix is given in a paper: the authors said that its inverse is given by $A^{-1}$ when $(1)$ is satisfied. I do not know how to proceed to invert it. How did they get $P$ without getting $A^{-1}$ ? Thank you very much.",['matrices']
778479,"Evaluate $\int\frac{1}{\sin(x-a)\sin(x-b)}\,dx$","I'm stuck in solving the integral of $\dfrac{1}{\sin(x-a)\sin(x-b)}$. I ""developed"" the sin at denominator and then I divided it by $\cos^2x$ obtaining $$\int\frac{1}{\cos(a)\cos(b)\operatorname{tan}^2x-\cos(a)\sin(b)\operatorname{tan}x-\sin(a)\cos(b)\operatorname{tan}x+\sin(a)\sin(b)}\frac{1}{\cos^2x}dx$$ 
Then I made a substitution by $t=\operatorname{tan}x$ arriving to this $$\int\frac{1}{\cos(a)\cos(b)t^2-(\cos(a)\sin(b)+\sin(a)\cos(b))t+\sin(a)\sin(b)}dt$$ How can I solve it now? (probably I forgot something, it easy to make mistakes here) Thank you in advance!","['closed-form', 'calculus', 'integration', 'indefinite-integrals', 'trigonometry']"
778495,"I have the pattern: 1 + 2 + 3 + 4 + 5 + 6, but I need the formula for it","I'm writing some software that takes a group of users and compares each user with every other user in the group. I need to display the amount of comparisons needed for a countdown type feature. For example, this group [1,2,3,4,5] would be analysed like this: 1-2, 1-3, 1-4, 1-5
2-3, 2-4, 2-5
3-4, 3-5
4-5 By creating little diagrams like this I've figured out the pattern which is as follows: Users - Comparisons
2     -   1
3     -   3 (+2)
4     -   6 (+3)
5     -   10 (+4)
6     -   15 (+5)
7     -   21 (+6)
8     -   28 (+7)
9     -   36 (+8) I need to be able to take any number of users, and calculate how many comparisons it will take to compare every user with every other user. Can someone please tell me what the formula for this is?","['summation', 'combinatorics']"
778501,Using a Moment Generating Function to find a probability function,"I'm struggling hugely with breaking down my M.G.F. into something that I can use to give me a probability function of $X$, the problem reads: Find the probability function, $f$, of $X$ including domain given the moment generating function of $X$ is $$M_X(t) = (0.4e^{-t} + 0.6e^{t})^2$$ I know the $0.4$ and $0.6$ values are significant, but I feel powerless as to where to start. Anybody out there with the know how to lend a hand?","['probability-theory', 'moment-generating-functions', 'probability', 'functions']"
778504,"Let $H,K \trianglelefteq G$. Show that if $H$ and $K$ are solvable then the subgroup $HK$ is solvable.","Let $H,K \trianglelefteq G$. Show that if $H$ and $K$ are solvable then the subgroup $HK$ is solvable. I did the following :
Since H is solvable, there is a subnormal series $\{e\} = H_0 \trianglelefteq H_1 \trianglelefteq ... \trianglelefteq H_n = H$, with $\frac{H_{i+1}}{H_i}$ abelian.
By $H,K \trianglelefteq G$ then $HK \trianglelefteq G$.
Thus, considering the chain $\{e\} = H_0 \trianglelefteq H_1 \trianglelefteq ... \trianglelefteq H_n = H \trianglelefteq HK$. 
It remains to show that $\frac{HK}{H}$ is abelian. But I'm not getting. I do not know if there is any error in proof.","['group-theory', 'abstract-algebra']"
778586,Gauss-Newton method -- is this matrix product invertible?,"In the Gauss-Newton method for solving overdetermined systems of equations,  the iteration matrix is of the form $(J^t   J)^{-1}   J^t$, for a $m \times n$ Jacobian matrix $J$ with $m > n$.   I was under the impression that if J had full column rank, then the product $J^t   J$ would always be invertible.   Is this incorrect?","['matrices', 'numerical-methods']"
778606,Show that a smooth plane quartic is never hyperelliptic,I have been asked to show that a smooth plane quartic is never hyperelliptic. I know that The genus of any such curve is 3 The statements of Riemann-Roch and Riemann-Hurwitz A curve is hyperelliptic if there's a degree 2 map from it to $\Bbb P^1$ . Can I have a hint about what to do please? Cheers.,['algebraic-geometry']
778637,How to evaluate this integral? $\int \frac {x e^{\arctan(x)}}{{(1+x^2)}^{3/2}} \ dx$,I am working on a integral and I run out of ideas how to solve it. Does anyone has good some good idea? I tried various substitutions but it seems that I did not find the correct one. $$\int \frac {x e^{\displaystyle\arctan(x)}}{{(1+x^2)}^{3/2}} \ dx$$,"['calculus', 'integration']"
778639,Average number of distinct values,Let $q$ such that $q < n$. I pick at random $n$ values in $\mathbb{F}_q$. What is the average number of distinct values ? Thank you,"['statistics', 'finite-groups', 'probability']"
778661,Is number rational?,"How can we check if number $a=\frac{ \sqrt[4]{2}+\sqrt[3]{3}}{\sqrt[4]{2}+\sqrt[3]{3} +1}$ is rational? Is there any smart solution? Another assignment is to find $\left( \mathbb{Q}(\sqrt[4]{2},\sqrt[3]{3}):\mathbb{Q} \right)$ which is twelve, maybe we can somehow use it for checking whether $a$ is rational or not?","['abstract-algebra', 'field-theory']"
778679,General birth and death process,"hi i need some help to understand the following (from the general birth and death process).I'll give some context first , then i ask questions. Consider general birth and death process with birth rates $\{\lambda_n \}$ and death rates,where $\mu_o = 0$, and let $T_i$ denote the time,starting from state $i$, it takes the process to enter $i+1$, $i\geq 0$. We will recursively compute $E[T_i]$,$i\geq 1$,by starting with $i = 0$. Since $T_0$ is exponential with rate  $\lambda_0$ we have: $E[T_0]= \frac{1}{\lambda_0}$ For $i> 0$, we condition wheater the first transition takes the process into state $i-1$ or $i+1$, that is let: $I_i = \begin{cases} 1, &\mbox{if the first tranistion from $i$ is to $i+1$ }  \\ 
0 & \mbox{if the first transition from $i$ is to $i-1$}  \end{cases}$ and note that $E[T_i\vert I_i = 1] = \frac{1}{\lambda_i +\mu_i}$ $E[T_i\vert I_i = 0] = \frac{1}{\lambda_i +\mu_i} + E[T_{i-1}]+ E[T_{i}] $ $\textbf{questions}$ $E[T_i\vert I_i = 1] = \frac{1}{\lambda_i +\mu_i}$ how do i interpret this? it is clear from the text above that $E[T_i\vert I_i = 1]$ is the expected time for the process to enter state $i+1$,given that the first transition is from $i $ to $i+1$. but how is this equal to $\frac{1}{\lambda_i +\mu_i}$. Is this the mean for the minimum of two random variables with rates $\lambda_i$ and $\mu_i$?","['statistics', 'markov-chains', 'markov-process', 'probability']"
778691,Writing answers to trigonometric equation,I wonder how to write answers to trigonometric equations in more elegant form. For instance if we have $ \displaystyle \sin x = \frac{\sqrt{2}}{2} \vee \sin x=-\frac{\sqrt{2}}{2}$ then I write four cases instead of just one where $\displaystyle x=\frac{\pi}{4}+\frac{k\pi}{2}$ Can anyone explain how to obtain such forms ?,['trigonometry']
778753,Axiom of unrestricted comprehension,"I'm doing some research on naive set theory and was a little confused over the statement of the axiom of unrestricted comprehension,  $\exists$B$\forall$x(x$\in$B$\iff$$\phi$(x)). I am curious as to why this is an iff statement. I was under the assumption that, in naive set theory, a set only exists if it is determined by some property, but this seems to say that a property exists for each set as well. Why doesn't the implication $\exists$B$\forall$x(x$\in$B$\implies$$\phi$(x)) suffice?","['logic', 'axioms', 'elementary-set-theory']"
778811,Function application (word problem),The problem: My work so far: $3=log(\frac{A}{A_0})$ ---> $10^3=\frac{A}{A_0}$ $\frac{A}{A_0}=1000$ (Am I done there?) Plugging it in: $M=log(\frac{1900000}{1000})$ $10^M = \frac{1900000}{1000}$ $M=3.278753601$ I know this is wrong because for it to be 10 times as strong it would have to be a 4.0 EDIT: I realize that $A_0$ can't  1000 because $A_0$ Is supposed to be the smallest measurable quake.,"['applications', 'logarithms', 'algebra-precalculus', 'functions']"
778855,Odd $\sin/\cos$ integral,"How to evaluate
$$\int \frac{\sin^3 x}{\cos^5x}dx\ ?$$ I've tried various substitutions with $\sin x = u$ or $\cos x = u$, I've tried using Euler's formula which result in too heavy calculations and I've tried using $\sin^2x + \cos^2x = 1$ in various forms without success.","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
