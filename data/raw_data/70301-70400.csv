question_id,title,body,tags
856654,Why absolute values of Jacobians in change of variables for multiple integrals but not single integrals?,"If $g:[a,b]\to\mathbf R$ is a change of 1D coordinates, then the formula is:
$$ \int_{g(a)}^{g(b)}\,f(x)\,dx = \int_a^b\,f(g(t))\frac{dx}{dt}\,dt. 
\qquad\text{(1)}$$ If  $T=\{x=f(u,v); y=g(u,v)\}$ is a change of 2D coordinates, then the formula is:
$$\iint_{T(R)}\,\phi(x,y)\,dx\,dy = \iint_R\,\phi(f(u,v),g(u,v)) \left| 
\frac{\partial(x,y)}{\partial(u,v)} \right|\,du\,dv \qquad\text{(2a)}$$ It seems that the formula for 2D (and higher dimensions) are extensions of the 1D version.   If so, then the 1D version 'should' also require absolute value.  Can anyone explain why, except for 1D, do all higher versions require the absolute value of Jacobians? Does it have something to do with the way we specify the lower and upper limits of the 1D integral? If so, can anyone elaborate it further? ===== Below were added after this question was flagged as a duplicated ====== This question was flagged as duplicated. But it seems to me that this question has a very clear objective: absolute value for higher dimension, but why not 1D?  This question is not about any particular example, it is more about the way the theorem is stated in 1D and higher dimension.  Specifically, it is more about the challenge of a  practical and clerk-like notation of specifying an orientation of a 2D region in double integral. As elaborated by StrangerLoop and Hurkyl, 1D region such as an interval can be flipped naively just by noting the magnitudes of the endpoints. We can indicate the 'orientation' in a practical and clerk-like manner (as the limits). For double integrals we need to know which side of the region is the 'right' side.  As a follow up,  I have the following comment: There is no universal practical and clerk-like way to specify a 2D region. How to specify an oriented region $T(R)$ in a generic manner so that one always mechanically compute a stand-alone double integral correctly, including the sign. I assume that if we can do that, then it is possible to generalize the 1D version to 2D without the 'artificial' need of absolute value.  Because each double integral, as a stand-alone integral, on either side of (2b) will be correctly signed. $$\iint_{T(R)}\,\phi(x,y)\,dx\,dy = \iint_R\,\phi(f(u,v),g(u,v))  
\frac{\partial(x,y)}{\partial(u,v)} \,du\,dv \qquad\text{(2b)} $$ Thanks for the two answers. They are helpful in helping me understand the ""why"" part.  Any further comment on my observation is appreciated.","['multivariable-calculus', 'calculus', 'integration']"
856663,Important applications of the Uniform Boundedness Principle,"There's like three applications of the uniform boundedness principle in wikipedia: 1) If a sequence of bounded operators converges pointwise to an operator, then the limit operator is also bounded, and the convergence is uniform on compact sets. 2) Any weakly bounded subset of a normed space is bounded. 3) A result in pointwise convergence of Fourier series. I am just asking if there's more interesting applications of the uniform boundedness principle.","['general-topology', 'functional-analysis', 'banach-spaces', 'big-list']"
856675,Find the power series of $x\ln(1-x)$.,"So the exercise I had to do was: Find the power representation of $x\ln(1-x)$. The way to go was finding the power series representation of $\ln(1-x)$ and then multiply it with $x$. But why can't you first find the derative of $x\ln(1-x)$ which is $x/(1-x) + \ln(1-x)$ and then make power series of them both. And then find the antiderative of that. Because when they ask to find power series representation of $\ln(1-x)$ you have to first find derivative of this then convert it into series and then find antiderivative of this series. So why can't i do the same with $x\ln(1-x)$..?
So why can't I apply the same method? Why can't I solve this exercise in same way, by first finding the derivative then turning it into a power series and then integrating it? I did $f(x)= x\ln (1-x)$ $f^\prime(x) = -x/(1-x) + \ln(1-x)$ I already knew $\ln(1-x)= Î£-(1/n) x^{n+1}$ (with n=0) This in power series gives
$-x\sum x^n + \sum -1/n x^{n+1}$ (both n=0) This gives $\sum-x^{n+1} + \sum-(1/n) x^{n+1}$
Now I integrate both and get
$\sum-(1/(n+2)) \cdot x^{n+2} + \sum-1/n \cdot 1/(n+2) x^{n+2} $","['power-series', 'calculus']"
856682,Proof Verification for Discrete Math Class,Prove that $n^2$ is even iff $n$ is even. I proved it like this: Case I: $n$ is even 1) $n = 2a$  $(a\in Z)$ 2) $n^2 = 4a^2 = 2(2a^2)$ 3) $2a^2 = K$ $(K \in Z)$ 4) $n^2 = 2K$ Case II: $n$ is odd 1) $n = 2a + 1$ $(a\in Z)$ 2)$n^2 = 4a^2 + 4a +1 = 2(2a^2 + 2a) + 1$ 3) $2a^2 + 2a = K$ $K\in Z$ 4) $n^2 = 2K+1$ My book does it slightly differently: Is my proof still correct?,"['discrete-mathematics', 'proof-writing', 'proof-verification']"
856688,The limit of a sequence $\lim_{n\rightarrow \infty}\prod_{k=0}^{n-1}( 2+\cos \frac{k\pi }{n})^{\pi/n}$.,"$$
\lim_{n \to \infty}\prod_{k = 0}^{n - 1}
\left[\,2 + \cos\left(k\pi \over n\right)\right]^{\pi/n}\ =\ ?
$$ Please give some hints.","['sequences-and-series', 'calculus', 'limits']"
856702,"If $w$ is in weak $A_{\infty}(d\mu)$ where $d\mu$ is a doubling measure, then is $w\,d\mu$ doubling?","Let $\mu$ be a positive Borel measure on $\mathbb{R}^n$ and let it be doubling i.e. there exists a a constant $C>1$ such that $\mu(B(x_0, 2r)) \leq C \mu(B(x_0,r))$ for all balls $B(x_0,r)$. Let $w$ be a weight with respect to $\mu$ i.e. $w\in L^1_\text{loc}(\mathbb{R^n}, d\mu)$ and $w>0$ $\mu$ a.e. Consider the measure $w\,d\mu$ and let $$w(A) = \int_A w\,d\mu $$ for any measurable set $A$. Suppose there exists constants $\alpha$ and $\beta$ with $0<\alpha, \beta <1$ such that whenever $E\subset B$ is a measurable subset of the ball $B$ and satisfies $$ \frac{\mu(E)}{\mu(B)} >\alpha  \quad \text{ then} \quad \frac{w(E)}{w(B)} > \beta$$ Question: Is the measure $wd\mu$ doubling? i.e. does there a constant $C>1$ such that $w(B(x_0,2r))\leq Cw(B(x_0,r))$ for all balls $B(x_0,r)$? $$ $$ Background: This is the characterization of weak $A_\infty$ weights of $d\mu$. The thing is that if $\mu$ is the lebesgue measure then there is no problem. However for general doubling measures $\mu$, this looks tricky to me as we have no control over the value of $\alpha$ (Note in particular that $\mu(B)/\mu(2B)$ can be quite small as compared to $\alpha$, which makes the given property difficult to use). Stein in his Harmonic analysis only has $\mu$ as the lebesgue measure and Journe in book on Calderon Zygmund Operators, says this is obvious but I am skeptical. The best that I could do was that $w$ has to satisfy a reverse holder inequality (just adapting the proof in Stein), but still with this I don't know how to prove doubling.","['measure-theory', 'harmonic-analysis']"
856703,Newly Developed With Details - Describing orthographic projection using simple 2D transformations,"Thanks to Pedro for helping me further develop my question into something tangible. His (most recent) answer below clearly and formally outlines what I am asking. This is similar to this question, except in 3D and involving surfaces. I am doing some graphics work involving rotation matrices. The problem is that I am not just transforming points, I'm also transforming arbitrary surfaces (images, colors, etc.) These surfaces are represented by rectangles and only really support two main transformations, rotation and scaling (along the horizontal and vertical axes). If I have a rotation matrix:
$$
    M = \left(\begin{matrix}
        m_0 & m_1 & m_2 \\
        m_3 & m_4 & m_5 \\
        m_6 & m_7 & m_8 \\
        \end{matrix}\right)
$$ That might produce some rotation like this: (just for illustration purposes) It could be said that in order to achieve this shape, a rectangle would go through a certain counter-clockwise rotation and then a certain scaling along the horizontal axis and the vertical axis. Is there any way to figure out what that counter-clockwise angle is and what the scale factors are? Keep in mind that I said that the rotation occurs first, though this is arbitrary and the rotation and scale transformations could happen in any order. EDIT: Hopefully these details grant more clarity. Here's exactly what's happening. There is a set of points (a, b, 0) that represent 3D coordinates. Each of these points have a related surface represented by a width and height. That surface could be an image, a color or any other shape potentially. These surfaces support two main transformations: rotation and scale transformations. The scale transformations occur in the horizontal and vertical axis and the rotations occur around an axis perpendicular to the screen. Assume the plane of the screen is the reference point from which all rotations occur. Also assume that there is a matrix M as defined above that represents the orientation of the 3D coordinate plane on which (a, b, 0) resides. What I am trying to do is project the point (a, b, 0) AND its related surface onto the screen using the aforementioned matrix. Taking that point (a, b, 0), as well as an orientation matrix in as input, I would like to figure out how I should transform the surface so that it appears as it would in 3D on the 2D screen (i.e. how I can transform it so that it looks projected on the screen). The image above is a good example of a surface that while looking 3D, is actually somehow represented by a set of 2D points. I would like to know how to come up with that projection given that I do not have the full point array. My assumption, which I now see may be incorrect, was that you could do that with a rotation and a scale alone. An answer below demonstrated that in fact you need at least another angle called the shear angle. Another piece of information that may be useful: As I mentioned, this is graphics work, so the coordinate axis are actually flipped. The x-axis is the same, but the y-axis is flipped so it becomes more positive as you go down. Hopefully making my question a bit more broad will lead to an answer: What transformations do I need to project a flat 3D surface onto a 2D plane (the screen)?",['matrices']
856717,Existence of a sequence of continuous functions converging pointwise to a characteristic function.,"I'm reading Rudin's Real and Complex Analysis and in section 5.11 he makes the next assertion: Put $g_n(t)=1$ if $D_n(t)\geq 0$, $g(t)=-1$ if $D_n(t)<0$. There exist $f_j\in C(T)$ such that $-1\leq f_j\leq 1$ and $f_j(t)\to g(t)$ for every $t$, as $j\to \infty$. Here, $C(T)$ denotes the set of continuous functions on  the unit circle $T=\{z\in\mathbb{C}:|z|=1\}$ and for $t\in T$, $D_n(t)=\sum_{k=-n}^n e^{ikt}$. I know that by Lusin's theorem, we can find a sequence of continuous functions converging a.e. to $g$ with $|f_j|\leq 1$ for every function $f_j$ in the sequence, but I don't why he claims that we can find a sequence converging for every point. Could you help me to clarify this? I think it suffices to show this for a characteristic function of a closed set since $g=\chi_F-\chi_{T\setminus F}$ where $F=D_n^{-1}([0,\infty))$ but I don't know how to prove this.
Thanks.","['measure-theory', 'real-analysis']"
856719,How to prove that $R\cup S$ and $R\cap S$ are symmetric if R and S are symmetric?,"The question is as follows- R and S are two symmetric relations on the same set A. Prove that $R\cup S$ and $R\cap S$ are symmetric. I tried it like this but I can't continue it. Any help is appreciated. Let a,b $ \in$ A s.t (a,b)$\in$R and (a,b) $\in$ S. Since R and S are reflexive, (b,a)$\in$R and (b,a) $\in$ S",['elementary-set-theory']
856727,Finding a rare case where an incorrect rule works?,"""A not uncommon error in calculus is to believe that the product rule for derivatives states that $(fg)' = f'g'$. If $f(x) = e^{3x}$, find a nonzero function g for which $(fg)' = f'g'$."" I believe you can find the function(s) using algebra, I got ${dy \above 1pt dx}ge^{3x} = g'*3e^{3x}$ but I don't know what to do with $g$. What would I sub in for $g$ and $g'$, or am I going about this all wrong?",['calculus']
856745,Measure which does not grow faster than Lebesgue,"Is there an example of a measure $\mu$ on $\mathbb{R}$ which is not absolutely continuous with respect to Lebesgue measure such that $\mu[\mathbb{R}]=+\infty$ but
$$\limsup_{a\to +\infty}\frac{a}{\mu[-a,a]}<+\infty.$$","['measure-theory', 'lebesgue-measure', 'real-analysis']"
856756,Taking the means of numbers repeatedly,"Let $A_1 = \{x_1,x_2,x_3,x_4\}$ be a set of four positive real numbers.
The sets $A_i, i\geq 2$ are made up of four real numbers defined from the arithmetic mean, geometric mean, harmonic mean and root mean square, as shown below. Let $A_2 = \{ \text{AM} (A_1),\text{GM}(A_1),\text{HM}(A_1),\text{RMS}(A_1) \}$ Let $A_3 = \{ \text{AM} (A_2),\text{GM}(A_2),\text{HM}(A_2),\text{RMS}(A_2) \}$ $ \vdots$ Let $A_{i+1} = \{ \text{AM} (A_i),\text{GM}(A_i),\text{HM}(A_i),\text{RMS}(A_i) \}$ I was wondering if there was anything special as this process is repeated. Do the elements of the set converge towards a specific number? I was thinking it would converge to SOME number between the AM and GM since $RMS \geq AM \geq GM  \geq HM$, but this is as far as I could go.","['means', 'algebra-precalculus']"
856757,Why is $\cos(2x)=\cos^2(x)-\sin^2(x)$ and $\sin(2x)=2\sin(x)\cos(x)$?,"I was studying math.. and I just realized that I only just memorized these trigonometric equations, but I don't really know the reason behind them. So um... Why is $\cos(2x)=\cos^2(x)-\sin^2(x)$ and $\sin(2x)=2\sin(x)\cos(x)$? What happens if $x=3\theta$? 
Would the equations change to something like $\cos(6\theta)=\cos^2(3\theta)-\sin^2(3\theta)$ and $\sin(6\theta)=2\sin(3\theta)\cos(3\theta)$?","['trigonometry', 'calculus']"
856764,Show that a specific $w$ cannot be the root of an quadratic with integer coefficients.,"Let $w$ be the only real root of $x^3-x-1=0$. Show that
 $w$  cannot satisfy the quadratic $ax^2 + bx + c$ ,where $a,b,c\in \Bbb Z$. I have written 
$$w^3=w+1$$
but I can't go any further than this. Thank you.","['calculus', 'number-theory']"
856784,How to show that $\lim\limits_{n\to\infty}n^{2/3}a_{n}=\sqrt[3]{2}/\Gamma{(1/3})$,"Let $$\left(\dfrac{1+x}{1-x}\right)^{1/3}=\sum_{n=0}^{\infty}a_{n}x^n,|x|<1$$ Show that $$\lim_{n\to\infty}n^{2/3}a_{n}=\dfrac{\sqrt[3]{2}}{\Gamma{\left(\dfrac{1}{3}\right)}}$$","['power-series', 'limits']"
856791,Infinite limit terms under root,"Suggest me a hint to solve:$$\psi=\lim_{x\to0}{\frac{\sqrt{1-\cos x+\sqrt{1-\cos x+\sqrt{1-\cos x+\cdots}}}-1}{x^2}}$$ My try,",['limits']
856808,how many ways can 1001 people win 500 identical items?,"the question is stating that $1001$ people are in a race and there are $500$ objects that are identical (say the same shirts). We need to find the number of ways that the 500 shirts can be given out IF only the first $500$ people to finish the race get the shirts. I know that since the shirts are identical, order shouldn't matter. What I propose is that since there are $n=1001$ people and $k=500$ shirts, it would be $\dbinom{n}{k}$. Pretty sure this isnt right because the number is huuge... Thanks for your help!","['discrete-mathematics', 'combinatorics']"
856810,What is the probability when i attempt twice?,"// I have never got probabilities' lessons , I only know some basics Let's say the probability of me hitting the target ( let's consider hitting a bottle with a soccer ball ) in ONE ATTEMPT is calculated and it equals 0.3 . Logically , when i try more than once i'm having a bigger chance of hitting it . Then what will the probability of me hitting the target - at least once - if i try 15 times be ?","['probability-theory', 'probability', 'conditional-probability']"
856848,Closed form of $\sum_{k=0}^nk\binom{k}{3}\binom{2n}{k}$,"Recently, I came across the following exercise on the course of discrete math Find a closed form for $\sum_{k=0}^nk\binom{k}{3}\binom{2n}{k}$ So I tried some of the usual techniques: Let $f(x)=\sum_{k=0}^n\binom{2n}{k}x^k$. If we denote $F(x)=\frac16x^3\left(xf'(x)\right)'''$ then $F(x)=\sum_{k=0}^nk\binom{k}{3}\binom{2n}{k}x^k$, so the desired sum is $F(1)$. Problem here is that I can't find a closed expression for $f(x)$. Clearly, $(1+x)^{2n}=\sum_{k=0}^{2n}\binom{2n}{k}x^k$, but how can I take out only the first 'half' of the terms? Second thing I tried was to take $g(x)=(1+x)^{2n}$ and then denote $G(x)=\frac16x^3\left(xg'(x)\right)'''$. Then $G(x)=\sum_{k=0}^{2n}k\binom{k}{3}\binom{2n}{k}x^k$. So, if we look at 
$$h(x)=G(x)\frac1{1-x}=\sum_{j=0}^\infty\left(\sum_{k=0}^jk\binom{k}{3}\binom{2n}{k}\right)x^j$$
So the desired sum will be the coefficient of $x^n$. But here it doesn't work either, as $$h(x)=\binom{2n}{3}(2nx+3)\frac{(1+x)^{2n-4}}{1-x}$$
But I can't find a closed form for the coefficient of $x^n$. Any help will be much appreciated.","['closed-form', 'generating-functions', 'discrete-mathematics']"
856902,Proof when the circle map is ergodic,"Let $E=[0,1)$ with Lebesgue measure. For $a \in E$ consider the mapping $\theta_a:E \rightarrow E, \ \ \theta_a(x) = (x+a) \mod  \ 1$. a) Show that $\theta_a$ is not ergodic when $a$ is rational. b) Show that $\theta_a$ is ergodic when a is irrational. I think that $\theta_a$ is isomorphic to the map $\theta_a=e^{2\pi i(x+a)}$ but not sure how this would help solve the problem. For part b) the hint, consider $a_n=\int_E f(x)e^{2 \pi i nx}dx$ to show that every invariant function is constant , is given. Strong hints would be greatly appreciated.","['measure-theory', 'lebesgue-measure', 'ergodic-theory']"
856932,Can there be more than one power series expansion for a function.,"I guess the answer is NO, for polynomials. I know that there are more than one series expansion for every function. But I am talking about power series here. All Ideas are appreciated","['power-series', 'sequences-and-series', 'algebra-precalculus', 'calculus', 'integration']"
856960,How to solve: $\cos^2x + \sin x = 1$,$\cos^2x + \sin x = 1$ How to solve for $x$?,"['trigonometry', 'algebra-precalculus']"
857035,Every martingale is also a martingale with respect to its own filtration,"I want to prove the following: Let $A_0, A_1, ..$ be a martingale with respect to the sequence $B_0, B_1, ..$. then $(A_i)_{i\geq0}$ is also a martingale with respect to itself. I have no idea how to approach this, but it seems like a pretty standard problem.","['probability-theory', 'martingales']"
857038,Proving there's a set with the cardinality $\mathfrak c$ on the $x$ axis of points that do not belong to the set of disks,"Prove/disprove: On the $x$ axis there's a set with the cardinality $\mathfrak c$ of points that do not belong to any disk of a set $O$ of disjoint disks of positive radius $\{(x,y)\in \mathbb R|(x-a)^2+(y-b)^2\le r^2 \}:a,b,r\in \mathbb R: r \gt 0$ . Note: the disks can't overlap. I think it's true, by sketching the disks I always get a gap between them, and even by filing these gaps to infinity they can't cover all the points on an interval because they can't overlap. It's impossible for any shape to not have gaps if they can't overlap. In a previous part of the exercise I already found the cardinality of $O$ to be (at most) $\aleph_0$ by finding a rational point $(q_1,q_2)$ in each disk of $O: q_1,q_2\in \mathbb Q\times\mathbb Q$ . So if we'll take all the numbers that do not belong to any disk, they would be a subset of the transcendental numbers and on the other hand, every disk would have two gaps from both sides of its perimeter, so we'll get $2^{\aleph_0}$ .","['cardinals', 'elementary-set-theory']"
857066,injective curve inside curve,"I am struggling to prove the following intuitive result: Take $\phi:[a,b]\rightarrow \mathbb{R}^{n}$ a continuous mapping with $\phi(a)\neq\phi(b)$ . Then there is a continuous injective mapping $\phi_{0}$ with image contained in $\phi([a,b])$ such as $\phi_{0}(a)=\phi(a)$ and $\phi_{0}(b)=\phi(b)$ . I found this statement in Falconer, The geometry of fractal sets , with a sadly incorrect proof, which went as follows. ""Take the collection $\mathcal{C}$ of proper intervals $I_{x}$ of the form $[t_{1},t_{2}]$ with $\phi(t_{1})=\phi(t_{2})=x$ who are contained in no other intervals of the same form. Since it is a collection of countably many proper disjoint closed intervals, we can find a continuous surjective increasing function $f:[a,b]\rightarrow [a,b]$ such as $f(t_{1})=f(t_{2})$ if and only if $t_{1}=t_{2}$ or if $t_{1},t_{2}$ are in a same interval of $\mathcal{C}$ . Then it is easy to check that $\phi_{0}$ , defined by $\phi_{0}(u)=x$ if $f^{-1}(u)=I_{x}$ and $\phi_{0}(u)=\phi(f^{-1}(u))$ otherwise, satisfies our requirements."" The problem with that proof is that though the intervals of $\mathcal{C}$ are indeed proper and closed, they are not necesarily disjoint. I can't reproduce the drawing here but it is not too difficult to show a curve in $\mathbb{R}^{2}$ with two double points $x,y$ such as $\phi(a_{1})=\phi(a_{2})=x$ , $\phi(b_{1})=\phi(b_{2})=y$ , and $a_{1} < b_{1} < a_{2} < b_{2}$ . I don't know how to complete the proof (I even tried with Zorn's lemma), if you have any ideas they are welcome. Here's a diagram ... Since the intervals are not necessarily disjoint they aren't necessarily countable either.","['general-topology', 'plane-curves', 'curves']"
857073,Formula for adjusting font height,"INTRODUCTION AND RELEVANT INFORMATION: I am a software developer that needs to implement printing in my application. In my application user can choose different paper sizes ( A3, A4, A5 ...) which requires from my application to scale drawing accordingly. I have managed to solve most of the tasks except adjusting the font height. This is the place where I got stuck. I have asked for help in StackOveflow but got no satisfying answer. Since all I need is formula for scaling font height, I have decided to ask for help here. Since this is mathematical site, I will phrase my question in a way that does not require any programming knowledge ( all I ask for is to carefully read the question, since this will be hard for me ). If I need to clarify something or add more info please leave a comment and I will update my post. PROBLEM: I have coordinates of the rectangle in which text should be drawn. Unfortunately, I must pick random value for font before drawing the text inside ( there is no way around it ), instead of calculating proper font size. All I can do now is to calculate the rectangle this text ( with this font height ) will fit in. Below image shows what I mean: I have font height of the text in proposed rectangle; I have (x,y) coordinates of both rectangles ( since my English is unable to precisely describe what I mean please see image below ): IMPORTANT NOTE: In my programming framework, y-axis is reversed -> positive values are below x-axis and negative ones above. Please see below picture: QUESTION: Can you give me the formula for properly changing  current font height so the text can fit into target rectangle? EDIT: I have tried to apply formula recommended by member Nikos M. and got very decent results. The earlier problem why his formula malfunctioned was related to the way my programming language performed conversion between integer and real numbers. After correcting this, the output is nearly perfect ( the last letter barely exceeds the limit ). I will keep trying with this approach since it looks very promising, but would welcome other solutions if there are any. END OF EDIT EDIT #2: I have altered the formula from member MvG 's answer to this: $$\text{optimal font size}=\text{guessed font size}\times\sqrt{\frac
{\text{desired width}}{\text{computed width}}}$$ There was only one case where text exceeded the limit, in all other cases the behavior was perfect. END OF EDIT #2 Again, this is my fisrt post so if edit is required/adding of proper tags/anything leave me a comment and I will react accordingly as soon as possible. Thank you for your patience and understanding. FINAL REMARKS: I have tried everything but the accepted solution always failed in one or two cases. No matter how much answerer tried, each time failure would happen. I believe that the problem doesn't lie in mathematical part, but is rather related to a faulty API I use. I have consulted experienced engineers and they agreed. Therefore I have officially accepted the answer, since from the mathematical standpoint it does solve the problem. This section is written to warn programers to become misguided that the formula actually solves programming part of the problem too. Thank you everyone for trying to help and for your support. Best regards 'till next time.",['geometry']
857098,Complex measures vs. Positive Measures,"In his real and complex analysis, Rudin writes that the right hand side of the expression $\mu(E) = \Sigma \mu(E_i)$ must necessarily converge for any countable partition $\{E_i\}$ of a measurable E, with respect to any complex measure. He points out that this convergence requirement would not apply to a positive measure. (The first paragraphs of chapter 6.) This confuses me - 1) I don't see why the definition implies that $\Sigma \mu(E_i)$ must converge unless $\mu(E)$ is given to be finite, 
2) and if $\mu(E)$ is finite, then positive additivity would imply that $\Sigma \mu(E_i)$ converges even if $\mu$ is only a positive measure. Thank you.","['complex-analysis', 'measure-theory', 'real-analysis']"
857109,Integral of factorial function,"$$
\mbox{What can we say about the integral}\quad
\int_{0}^{a} x!\,{\rm d}x\ ?.
$$ Or something like $\displaystyle\int_{0}^{3} x!\ {\rm d}x\ ?$ .","['factorial', 'integration']"
857139,Derivative of continuous function exists if limit of derivative exists,"I'm stuck on this old qualifier problem.  I suppose one could do it using the basic definitions of continuity and differentiability, but is there a simpler way? (For example, using DCT, FTC, Lebesgue differentiation theorem, etc.) Let $f:\mathbb{R} \mapsto \mathbb{R}$ be continuous.  Suppose $f$ is differentiable away from $0$ and lim$_{x \to 0} f^\prime(x)$ exists.  Show $f^\prime(0)$ exists.","['calculus', 'real-analysis', 'analysis']"
857145,How to prove Godunova's inequality?,"Let $\phi$ be a positive and convex function on $(0,\infty)$. Then
  $$\int_0^\infty \phi\left(\frac{1}{x}\int_0^x g(t)\,dt\right)\frac{dx}{x} \leq \int_0^\infty \phi(g(x))\frac{dx}{x}$$ The application of this inequality is this : $(1)$ Hardy's inequality. With $\phi(u)=u^p$, we obtain that
$$\int_0^\infty \left(\frac{1}{x} \int_0^x g(t) \, dt\right)^p\frac{dx}{x} \leq \int_0^\infty g^p(x)\frac{dx}{x}$$
(2) Polya-Knopp's inequality By using it with $\phi(u)=u^p$, replacing $g(x)$ by $\log g(x)$ and making the substitution $h(x)=\frac{g(x)}{x}$ we obtain that $$\int_0^\infty \exp\left(\frac{1}{x} \int_0^x \log h(t)\right) \, dt \leq e\int_0^\infty h(x) \, dx$$ How to prove Godunova's inequality? Is there any reference?","['convex-analysis', 'inequality', 'integral-inequality', 'real-analysis', 'analysis']"
857148,Find maximum of $P$,"Let $$P = \frac{{{x^2}}}{{{x^2} + yz + x + 1}} + \frac{{y + z}}{{x + y + z + 1}} - \frac{{1 + yz}}{9}.$$ 
Find maximum of $P$  where $x, y,z$ are nonnegative real numbers such that ${x^2} + {y^2} + {z^2} = 2$. I guess $\max P=\dfrac{5}{9}$ when $x=y=1, z=0$. But I can not prove.","['optimization', 'multivariable-calculus', 'inequality']"
857175,When does $x^TAx + c^Tx$ have a global minimum?,"This question is closely related to my last question about extended quadratic forms. I figured out a nice criterion, when $$f : \mathbb R^n \rightarrow \mathbb R$$
$$f(x) = x^TAx + c^Tx$$ has a global minimum , where $A \in Mat(n,n,\mathbb R)$ is symmetric, $c \in Vec(n,\mathbb R )$ I want to know, when f(x) has a global minimum. It is clear, that A must be
positive semi-definite. In this case, I figured out that f(x) has a global
minimum, if and only if $c^T$ is orthogonal to the kernel of A. In other words,
for any $x$ with $Ax=0$ , the equation $c^Tx=0$ must hold. Is there an easy proof for this criterion ? Can this result be understood geometrically ?","['matrices', 'quadratic-forms', 'linear-algebra']"
857187,Arranging the word 'MISSISSIPPI',"""How many ways are there to arrange the letters in the word 'MISSISSIPPI' in such     a way that there are no three consonants in a row?"" I am thinking like this. The following are 'slots' for the letters of our word: _ _ _ _ _ _ _ _ _ _ _.  There are 21 consonants in total (English). The first slot as 21 possibilities, the second also has 21, but the third has only 5 possibilities. So how many ways can I place vowels within this word... I don't know. I can try to enumerate all of the place the I's can go, but there has to be a better way than doing that.",['combinatorics']
857196,Derivative and integral of the abs function,"I would like to ask about how to find the derivative of the absolute value function for example : $\dfrac{d}{dx}|x-3|$ My try:$$
f(x)=|x-3|\\
f(x) =
\begin{cases}
x-3, & \text{if }x \geq3 \\
3-x, & \text{if }x \leq3
\end{cases}
$$ So:
$$f'(x) =
\begin{cases}
1, & \text{if }x \geq3 \\
-1, & \text{if }x \leq3
\end{cases}
$$ What is wrong with this approcah?.Please clarify.
Also I want also like to find out how to integrate the absolute value function. Thanks","['absolute-value', 'calculus', 'derivatives', 'analysis']"
857219,Are random selections from i.i.d. random variables independent?,"Let us have identically independently distributed random variables $x_1, x_2, \dots, x_{10}$. Now let us pick indices $\alpha, \beta$ uniformly independently from $1,2,\dots,10$. Are variables $x_{\alpha}$ and $x_{\beta}$ independent? My intuition says that they are not , since there is a chance $\frac{1}{10}$ that they are the same. But how can I formally prove this? (or prove that they are independent in case I am wrong)","['probability-theory', 'random-variables']"
857229,"How do I find $f(0)$, $f'(0)$, and $f'(x)$ given $f(x+y)=f(x)+f(y)+x^2y+xy^2$ and $\lim_{x\to0}\frac{f(x)}{x}=1$?","How can I find $f(0)$, $f'(0)$, and $f'(x)$ given that $f(x+y)=f(x)+f(y)+x^2y+xy^2$ and $\lim_{x\to0}\frac{f(x)}{x}=1$.","['calculus', 'derivatives', 'limits']"
857247,"If matrix $A$ is invertible, then there is a permutation of its rows leaving no-zeros on the diagonal","I need to prove this statement: "" If $A$ invertible, then exist a permutation of its rows leaving no-zeros on the diagonal "" and I tried using the definitos of invertible matrices and $LU$ factorization, but without results. Can you help me, please?","['matrices', 'permutations', 'linear-algebra']"
857273,Finding all $f:\mathbb R^3\to\mathbb R^*$ satisfying $f(O)=f(A)f(B)f(C)f(D)$ for any non-degenerate tetrahedron $ABCD$ with incenter $O$,"$f:\mathbb{R}^3\to \mathbb{R}^{\ast}$ is such that for any non-degenerate tetrahedron $ABCD$ with $O$ the center of the inscribed sphere, we have : $$f(O)=f(A)f(B)f(C)f(D) $$ Prove that $f(X)=1$ for all points $X$ . Here $\mathbb{R}^{\ast}=\mathbb{R}\setminus \{0\}$ . How would someone go on proving this? I have seen the problem If a function $f:\mathbb{R}^2\to \mathbb{R}$ satisfies $$\sum_{A\in \mathcal{P}}f(A)=0$$ where $\mathcal{P}$ is a regular $n$ -gon then $f(X)=0$ for all $X$ . But I have no idea about it. I have been told it is from a olympiad but I don't know which. Could someone help me? I tried to mimic the solution to the second problem but that didn't really help. Thanks.","['geometry', '3d', 'contest-math']"
857291,"$ T $ is normal if and only if for every $ T $-invariant subspace, its orthogonal complement is also $ T $-invariant.","Proposition: Suppose that $ V $ is a complex vector space and $ \dim(V) < \infty $. Then $ T \in \mathcal{L}(V) $ is normal if and only if the orthogonal complement of every $ T $-invariant subspace is $ T $-invariant. I hope that you can help me with a solution or a hint. Thanks. My idea: The forward implication: If $ T $ is normal, then $ T^{*} = p(T) $ for any polynomial $ p \in \Bbb{C}[X] $. Then given a $ T $-invariant subspace $ U $, we know that $ U $ is $ p(T) $-invariant. In other words, $ U $ is $ T^{*} $-invariant. As $ U $ is $ T^{*} $-invariant, it follows that $ W \stackrel{\text{df}}{=} U^{\perp} $ is $ (T^{*})^{*} $-invariant. Hence, $ W $ is $ T $-invariant. I was unable to work out the backward implication.","['vector-spaces', 'linear-transformations', 'linear-algebra']"
857301,Evaluation of $\int_0^1 \frac{\log(1+x)}{1+x}\log\left(\log\left(\frac{1}{x}\right)\right) \ dx$,"I need some hints, clues for getting the closed form of $$\int_0^1 \frac{\log(1+x)}{1+x}\log\left(\log\left(\frac{1}{x}\right)\right) \ dx$$","['improper-integrals', 'sequences-and-series', 'integration', 'definite-integrals', 'real-analysis']"
857322,When does connectedness imply path-connectedness [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed last year . Improve this question In a locally path-connected space connectedness and path connectedness are equivalent. What is the minimal condition we would impose on a topological space to get the same result? EDIT: This question is closed for clarity. The question is very clear. I will restate it, ""What is the most relaxed topological condition that implies equivalence of connectedness and path connectedness?"". Obviously, it's an open question, since it has no asnwer.","['general-topology', 'connectedness']"
857393,Complex Integration: theorem of Residues,"I am trying to prove a theorem that is doing my head in a bit. I have tried to simplify the problem as much as possible and leave out the details, even though it might look a bit too big. The simplified problem comes down to solving the following integral:
$$
-\frac{Ke^{-rT}}{2\pi}\int_{ai-\infty}^{ai+\infty}e^{-iz(\ln\frac{S}{K}+rT)}\varphi(-z)\left(\frac{i}{z}-\frac{i}{z-i} \right)dz
$$
where $a>1$, $K,T,r,S$ are constants and $\varphi$ is some function, where $\varphi(0) = \varphi(-i) = 1$. If my calculations are correct, the residue at $z=0$ is $\left(\frac{-Ke^{-rT}i}{2\pi}\right)$. Similarly, the residue at $z=i$ is $\left(\frac{iS}{2\pi}\right)$. Now is when I cannot move forward: I am not sure which contour I should define in order to solve the problem. I would be very grateful if you could help me out. If it helps you, I show below the answer to this problem (I don't know how to get there): $$
-\frac{Ke^{-rT}}{2\pi}\int_{ai-\infty}^{ai+\infty}e^{-iz(\ln\frac{S}{K}+rT)}\varphi(-z)\left(\frac{i}{z}-\frac{i}{z-i} \right)dz = I_1 + I_2
$$
where
$$
I_1 = \frac{1}{2}(2\pi i)\frac{Ke^{-rT}i}{2\pi}+\frac{Ke^{-rT}}{2\pi}Pr.Value\left(\int_{-\infty}^{\infty}e^{iu(\ln\frac{S}{K}+rT)}\varphi(u)\frac{i}{u}du \right)
$$
and
$$
I_2 = -\frac{1}{2}(2\pi i)\frac{iS}{2\pi}+\frac{Ke^{-rT}}{2\pi}Pr.Value\left(\int_{i-\infty}^{i+\infty}e^{iu(\ln\frac{S}{K}+rT)}\varphi(-z)\frac{i}{z-i}dz \right)
$$
where in $I_1$ we have used the change of variable $u = -z$. PS: I am especially confused about that $\frac{1}{2}$ at the beginning of the definition of $I_1$ and $I_2$. Why would we only take the half of the residuals ?. Thanks in advance.","['residue-calculus', 'complex-integration', 'fourier-analysis', 'complex-analysis']"
857395,Simplifying a Vector Integral,"While reading the book - Theory and Applications of Boltzmann Transport Equation by Cercignani (I am not a math student), I found this integral which I am unable to understand. Note that $\xi_i , \xi_l$ and $x_i , x_l$ are vectors. The first term in the simplification comes from the fact that $x_i$ is not equal to $x_l$, and we are differentiating $P_N$ wrt $x_i$ (over which we do not integrate) ; so the differentiation can be taken out of the integral. However the domain of integration has boundaries $|x_i-x_l|= \sigma $ which depend upon $x_i$, so there is some second term. This is the image: My question is: where does the second term come from? This book is mathematically very involved (for e.g. it uses at some places, volume and surface area of $n>3$ dimensional spheres) and its seems that I need to have some background/prerequisite for reading this book. I'll be very grateful if someone can suggest a maths book as prerequisite based on what I told you and which will help me to understand the integration.","['multivariable-calculus', 'calculus', 'integration', 'reference-request', 'statistical-mechanics']"
857408,Prove that there is no polynomial $P(z)$ such that for all $1 < |z| < 2$ we have that $ |P(z) - 1/z| < 1/2$.,Prove that there is no polynomial $P(z)$ such that for all $1 < |z| < 2$ we have that $ |P(z) - 1/z| < 1/2$. I tried using the maximum modulus principle and I noted that $ P(z)$ can't equal 0 on the specified domain but I am having no luck.  Some help would be awesome.  Thanks.,['complex-analysis']
857413,Transforming equations of the form $ax''+b(x^2-1)x'+cx=0$ into van der Pol equations,"Show that every equation of the form $$ax'' + b(x^2 - 1) x' + cx = 0$$ where $a, b, c > 0$ can be transformed into a van der Pol equation by a change in the independent variable. I am unable to find this replacement. If anyone could help me or give a hint I would be grateful.","['dynamical-systems', 'ordinary-differential-equations']"
857481,About how to understand the third isomorphism theorem,What is a good way to understand the intuition behind the third isomorphism theorem? Is it something looking like zooming out of the group structure?(i.e. discard the detailed info by modding out a normal subgroup).,"['quotient-spaces', 'intuition', 'abstract-algebra', 'quotient-group']"
857507,Evaluating a limit involving trigonometry,"I really thank you for your answers to my first question--I could easily solve first problem and a few more ones without another question. But a while later I got another one while studying, then I attempted to solve it on my own. Despite my efforts to solve I have spent scores of minutes with neither finding one correct solution nor making any process. Here is the problem: $$
\lim_{x \rightarrow 0} \frac{e^{1-\sin x}-e^{1-\tan x}}{\tan x-\sin x}
$$ The happiness would be mine, if you could let me know how to solve or even a few hints. Cheers.","['trigonometry', 'calculus', 'limits']"
857532,Limits of $\frac{\sin^2x}{x^2}$ as $x$ approaches infinity,"I just want to make sure I'm on the right path with the problem. The problem is as follows: $$\lim_{x\to\infty}\frac{\sin^2x}{x^2}$$ I rewrote it as follows: $$\lim_{x\to\infty}\frac{(\sin x)^2}{x^2}$$ Now $\sin(x)^2$ does oscillate as $x$ approaches infinity and therefore a limit does not exist. However it oscillates between the numbers $-1$ and $1$. Since the denominator would increase without bound and the numerator would only move between $-1$ and $1$, part of me wants to say that the limit is zero. However a smarter part of me wants to say that the limit does not exist due to the numerator. Could someone shed some light on this problem?","['trigonometry', 'calculus', 'algebra-precalculus', 'limits']"
857537,What is the intutive explanation of why the notation of matrices is as it is?,"If I want to solve a system of linear equations, like
2x-y=1
x+2y=4 Then the matrix notation for the same would be: $$ \begin{bmatrix} 2 & -1 \\ 1 & 2  \\ \end{bmatrix} \begin{bmatrix} X\\ Y\\ \end{bmatrix} =  \begin{bmatrix} 1\\ 2\\ \end{bmatrix}$$ I'd like to know how did this notation come into existence? Is this notation intutive for everyone? Or is there any significance of this notation? Or was this just proposed by someone (or a set of people) and then set as the standard?","['notation', 'matrices', 'matrix-equations', 'math-history']"
857539,"Who named ""Quotient groups""?","Who decided to call quotient groups quotient groups, and why did they choose that name? A lot of identities such as $$\frac{G/A}{B/A}\cong \frac{G}{B}$$ suggest that whoever invented the notation understood these things a lot better than I do... Edit : I'm also interested in the notation; I was assuming that the notation and terminology went together, but perhaps that is not the case.","['notation', 'math-history', 'abstract-algebra', 'group-theory', 'terminology']"
857540,Linear dual of vector fields,"Suppose that $M$ is a smooth manifold and $\mathfrak{X}(M)$ is the set
of smooth vector fields on $M$. There are basically two different linear
structures on $\mathfrak{X}(M)$: 1.) $\mathfrak{X}(M)$ is a (infinite dimensional) $\mathbb{R}$-vector space. 2.) $\mathfrak{X}(M)$ is an $C^\infty(M)$-module, where $C^\infty(M)$ means the algebra of smooth real valued functions on $M$. (These structures are related by a so called Lie-Rinehart pair, but that's irrelevant for the question) Now, the $C^\infty(M)$-dual of $\mathfrak{X}(M)$ is well known and precisely 
the $C^\infty(M)$-module of differential one-forms , that is $$\Omega^1(M)=Hom_{C^\infty}(\mathfrak{X}(M),C^\infty(M))$$ The question is: Is there moreover a common description of the $\mathbb{R}$-dual of $\mathfrak{X}(M)$? I
mean, how can we think about the elements of $$
Hom_\mathbb{R}(\mathfrak{X}(M),\mathbb{R})
$$ and are there places in mathematics where they appear? I know this is pretty vague, but I'm just trying to 'get a hand' on this kind of
dual. Edit: From some of the comments/answers, it became clear to me, that there are better understood restrictions of $Hom_\mathbb{R}(\mathfrak{X}(M),\mathbb{R})$,
so the question is generalized to Is there a common description of (some meaningful vector subspace of)  the $\mathbb{R}$-dual of $\mathfrak{X}(M)$?","['modules', 'linear-algebra', 'differential-geometry']"
857557,Finding a formula for specific limits,Hey guys I have a math problem I'm not sure how to go about solving. If someone could give me a systematic method for solving these kinds of problems that would be great. The problem is as follows: Find a formula for a function $f$ that satisfies the following conditions: $$\lim_{x\to\pm\infty}f(x) = 0$$ $$\lim_{x\to0}f(x) = -\infty$$ $$f(2) = 0$$ $$\lim_{x\to3^-}f(x) = \infty$$ $$\lim_{x\to3^+}f(x) = -\infty$$,"['calculus', 'algebra-precalculus', 'limits']"
857566,How to get the standard deviation of a given histogram (image),"I have a doubt:
How to get the standard deviation of a given histogram?
I'm looking for it on the internet. But I got Nothing. 
For example the case of this image below Thanks in advance!",['statistics']
857577,Analytical Expression for Hysteresis Loop Area,"EDIT:  I've updated the title and restatement of my question. Is there a known analytical solution for the area of a hysteresis loop?  I've found that a hysteresis loop can be described analytically using parametric equations, however performing contour integration has not bee successful. Iâve been working with a system that exhibits hysteresis and Iâve found that the more common models do not work for me.  I am wondering if anyone is aware of other models that might be out there for hysteresis.  Thus far, Iâve tried the Preisach model and Jiles-Atherton model, neither of which allow me to simulate the types of loops that I work with. Iâve gone the the Physics, Mathematics, Electrical Engineering, Mathematica, and some other StackExchange communities, but havenât found anything beyond Preisach or Jiles-Atherton being mentioned as potential approaches to modeling/simulating hysteresis.  I found some information on the VINCH model, the BoucâWen model, and the BoucâWenâBaberâNoori model, but none of them fit what I am trying to model.  This model really needs to be analytical rather than computational.  Some of the models use functions like sign[x] , and so forth, that aren't going to work for my system. Iâve been messing with the idea of using a parametric approach, that is to say, having both quantities that are shown in the hysteresis plot (for instance, M and H for ferromagnetism, or D and E for ferroelectricity, etc.), both being dependent on some other variable. Iâve found one paper that analytically handles this type of model by Lapshin, R.V., Analytical Model for the Approximation of Hysteresis Loop and Its Application to the Scanning Tunneling Microscope. Review of Scientific Instruments , 1995. 66(9): p. 4718-4730 (DOI: 10.1063/1.1145314 ). The model shows some interesting results, however the hysteresis loops that I am trying to model are more complex than those in the publication. Actually, I am considering trying to use a superposition of solutions to try and construct a solution appropriate for my system.  However, my attempts have yet to work. What I am trying to model is the following: a system in hysteresis that allows for both linear and non-linear ""slopes"", as well as linear and non-linear phase lags. Here are the pieces that you see in the graph above: (1)  A linear (reversible), in-phase component, same slope over the entire range (BLUE) (2)  A linear (irreversible), out-of-phase component (RED) (3)  A non-linear (reversible), in-phase component, one slope near origin, saturates far from origin (MAGENTA) (4)  A non-linear (irreversible), out-of-phase component (GREEN) If this was a circuit model, and were plotting charge vs. voltage (q vs V), while driving the circuit sinusoidally, (1) would be simple linear resistor, (2) would be a linear capacitor, (3) would be a non-linear resistor (perhaps one that saturates above a certain voltage, but not a memristor), and (4) would be a non-linear capacitive element that is bistable with very constant remanence and coercivity, not sure what it would be called though, perhaps an ""ideal hysteron"". If you add these four components together, you can get something resembling a proper hysteresis loop: Notice that the hysteresis loop can also be rotated in phase space. Has anyone seen a model that would allow this?  Also, is there some way to correlate these components to real physical properties for a hysteresis loop? Thanks!","['nonlinear-system', 'mathematical-physics', 'trigonometry', 'parametric', 'mathematical-modeling']"
857601,Counterexamples for lcm-gcd identity and modular law for rings,"In Miles Reid's Undergraduate Commutative Algebra , Exercise 1.3, we need to find counterexamples of lcm-gcd identity and modular law in the ring $A=k[X,Y]/(XY)$: $(I+J)(I\cap J)=IJ$; $I\cap(J+K)=(I\cap J)+(I\cap K)$. for ideals $I,J\subseteq A$. In general, if $A$ isn't restricted to $k[X,Y]/(XY)$, we can consider $I=(X)$ and $J=(Y)$ in $A=k[X,Y]$. The left side of 1 should be $(X^2Y,XY^2)$ and the right side should be $(XY)$, so they're different. However, I want to understand the geometric meaning for the fallacy of the identity. When $A$ is a coordinate ring for an affine algebraic set, we cannot find the different zero sets of $(I+J)(I\cap J)$ and $IJ$ in general by Hilbert's Nullstellensatz. It seems that there's some infinitesimal information to distinguish. I need some geometric interpretations for these, and then lead to an intuitive counterexample for 1,2. Any idea? Thanks! EDIT: There's a counterexample: $I=(x),J=(x+y),K=(y)$, gratefully thanks to user26857.","['ideals', 'commutative-algebra', 'ring-theory', 'algebraic-geometry']"
857604,Does anyone have a good reference on calculating contour integrals around the unit circle (numerically or otherwise)?,"I am looking for a reference that will help me calculate contour integrals around the unit circle or other curve. I have a particularly ugly function which isn't likely to have a nice closed form so I can't find any references which solve similar problems. In my case, I need to integrate a contour around the unit circle where the denominator contains the fourth root of a polynomial of degree $12$. It happens that $6$ of the $12$ roots are inside the unit circle and have a known value. I also know the value of the other $6$ roots outside of the unit circle but I do not think they are as important. Does anyone have a source that will help me deal with this problem? Can anyone sketch a method of calculating this? I have tried integrating from one root to it's conjugate assuming the other sections of the contour would have no contribution but I have not received correct results. Can I assume that there is no contribution from the circles that go around the zeros of the polynomial?","['reference-request', 'complex-analysis', 'contour-integration']"
857616,The Intersection of Ordered Pairs,"I've seen that the ordered pair $(a,b)$ is defined as a set that is
$(a,b)=\{\{a\},\{a,b\}\}$. 
Can you explain what do we mean when $(a,b) \cap (b,a) = \{\{a,b\}\}$? I feel that there should be no intersection whenever a is not equal to b.",['elementary-set-theory']
857624,second degree differential equation,"Find all functions $f(x)$ such that $$f''(x)+f(x)=\frac{1}{1+x^2}.$$ I would like to know if it's solvable and the solution/hints. What I got : $$2f(x)f(x)'+2f(x)'f(x)''=2\frac{1}{1+x^2}f'(x)$$
  $$(f(x)^2)'+((f(x)')^2)'=2\frac{1}{1+x^2}f'(x)$$
  $$f(x)^2+(f(x)')^2=\int 2\frac{1}{1+x^2}f'(x)dx .$$",['ordinary-differential-equations']
857627,Jordan decomposition of linear functionals,"Let $X$ be a locally compact Hausdorff space. Also, let $C_0(X,\mathbb R)$ denote the vector space of such continuous functions $f:X\to\mathbb R$ that the set $\{x\in X\,|\,|f(x)|\geq\varepsilon\}$ is compact for all $\varepsilon>0$. Suppose that $I:C_0(X,\mathbb R)\to\mathbb R$ is a bounded, linear functional. Define, for any $f\in C_0(X,[0,\infty))$, $$I^+(f)\equiv\sup\{I(g)\,|\,g\in C_0(X,[0,\infty)),\,0\leq g\leq f\text{ pointwise}\}.$$
The following properties of $I^+$ are known. $I^+(f)$ is well-defined (finite) and non-negative for any $f\in C_0(X,[0,\infty))$; $I^+(cf)=cI^+(f)$ for any $f\in C_0(X,[0,\infty))$ and $c\geq0$; $I^+(f_1+f_2)=I^+(f_1)+I^+(f_2)$ for all $f_1,f_2\in C_0(X,[0,\infty))$. I am trying to prove the following Claim: If $f\in C_0(X,[0,\infty))$, then it is impossible to have both $I^+(f)>0$ and $I^+(f)>I(f)$. In other words, $I^+(f)\leq\max\{0,I(f)\}$ must hold. I tried to derive a contradiction using the supremum property, but to no avail so far. Any hint would be appreciated. UPDATE: The claim is false , as @ChristianRemling cogently pointed out. FYI, what I ultimately wanted to show is this: If the functionals $I^+$ and $I^-\equiv I^+-I$, which can be meaningfully extended to $C_0(X,\mathbb R)$ from $C_0(X,[0,\infty))$, are given by $I^+(f)=\int f\mathrm d\mu^+$ and $I^-(f)=\int f\mathrm d\mu^-$ $\forall f\in C_0(X,\mathbb R)$ for some finite Radon measures $\mu^+,\mu^-$ on $X$, then $\mu=\mu^+-\mu^-$Â is precisely the Jordan decomposition of the signed measure $\mu$. While this claim happens to be true, I wanted to prove it using the false claim above in this question. The proof of the claim about the Jordan decomposition of $\mu$ is surprisingly and annoyingly elusiveâfor those interested, it is proved here (Proposition 13.42, pp. 279â280) .","['measure-theory', 'functional-analysis', 'real-analysis']"
857647,Calculating a triple integral with spherical coordinates?,"I need to calculate $$\iint_D \sqrt{x^2+y^2+z^2} dx dy dz$$  where $D=\{ (x,y,z):x^2+y^2+z^2\leq z\}$ . After substituting $x=r\cos\theta\sin\phi , y=r\sin\theta\sin\phi , z=r\cos\phi $ into the inequality $x^2+y^2+z^2\leq z$, I received that $0\leq r \leq\cos \phi$ so as far as I understand this $\phi$ should be in $[-\frac{\pi}{2} , \frac{\pi}{2}] $ . The problem is that when I calculate it with these boundaries I get the integral is zero, and when I calculate it for $\phi \in [0 , \frac{\pi}{2}] $ and multiply by $2$, I get $\frac{\pi}{10}$. So: Why is it not correct to take $\phi \in [-\frac{\pi}{2} , \frac{\pi}{2}] $? Thanks in advance.",['multivariable-calculus']
857667,A year having more than one Friday the 13th?,"We know that every year has at least one Friday the 13th . What about two Friday the 13ths, in a year? What is the probability of a year having two Friday the 13ths? (interesting subquestion here is if this probability is the same for leap and non-leap years) Is it possible that a year has three Friday the 13ths? (after posting the question I discovered that it is, as said in comments) This web page on wolfram MathWorld claims that a year has 1.72 Friday the 13ths on average. It also gives this table:","['probability', 'calendar-computations']"
857686,How is this subgroup abelian?,"Let $G$ be a finite group of order $2n$ such that half of the elements of $G$ are of order $2$ and the other half form a subgroup $H$ of order $n$. Then I know that $H$ is of odd order because for each $x \ne e$ in H, we have $x \ne x^{-1}$; thus after pairing all such elements we are left with the identity. Also, the subgroup $H$, being of index two, is a normal subgroup of $G$. How to determine if $H$ is abelian or not?","['finite-groups', 'group-theory', 'abstract-algebra', 'normal-subgroups']"
857693,What is the sum of this series: $\displaystyle\sum_{n=0}^{\infty} \dfrac{a^n}{(3n)!}$ [duplicate],This question already has answers here : Infinite Series $\sum\limits_{n=1}^\infty\frac{x^{3n}}{(3n-1)!}$ (4 answers) Closed 9 years ago . I tried getting it into a closed form but failed. Could someone help me out? $$\sum_{n=0}^{\infty} \dfrac{a^n}{(3n)!}$$,"['sequences-and-series', 'calculus']"
857712,Show that $\displaystyle u=\frac{1}{2}\log(x^2+y^2)$ is harmonic and find its harmonic conjugate function,"Show that $\displaystyle u=\frac{1}{2}\log(x^2+y^2)$ is harmonic and find its harmonic conjugate function. I did the first part to show that $\displaystyle \frac{\partial^2 u}{\partial x^2}+\frac{\partial^2 u}{\partial y^2}=0$ Now, to find v: $\displaystyle\frac{\partial u}{\partial x}=\frac{x}{x^2+y^2}=\frac{\partial v}{\partial y}$ I get $\displaystyle v=\tan^{-1}(\frac{y}{x})$ $\displaystyle\frac{\partial u}{\partial y}=\frac{y}{x^2+y^2}=-\frac{\partial v}{\partial x}$ Here I get $\displaystyle v=-\tan^{-1}(\frac{x}{y})$ What did I do wrong here ?","['partial-derivative', 'complex-analysis']"
857723,"finding $ \int_{C(0,2)^+} \frac{z^3}{z^3+z^2-z-1} $","I want to find
$$
I \ = \ \int_{C(0,2)^+} \frac{z^3}{z^3+z^2-z-1}
$$
First of all, I know that $z^3+z^2-z-1 = (z+1)^2(z-1)$. I split up the integral as a sum of residues:
$$
I \ = \ 
2\pi i \cdot Res_{z=-1}\frac{z^3}{(z+1)^2\cdot(z-1)}
\ + 2 \pi i \cdot Res_{z=1}\frac{z^3}{(z+1)^2\cdot(z-1)}
$$
The rightmost part becomes $2 \pi \cdot 1^3/(1+1)^2 \ = \ \pi i /2$. The same trick can't be applied for the the other part. There was another lemma that was useful though:
$$
Res_{z=1}f(x) \ = \  \frac{1}{(2-1)!} \cdot 
\lim_{z \rightarrow -1}\left( (z+1)^2 \cdot \frac{z^3}{(z+1)^2(z-1)}\right)
\ = \ \frac{1}{(1+1)^2} \ = \ \frac{1}{4}
$$
Now I should multiply this by $2 \pi i$, which gives me $\pi \cdot i /2$.
Adding gives us $\pi i $.
Could you please check what I did and tell me if I this is the right way to solve this?",['complex-analysis']
857750,prove that $a^b\ge{b}^a$ where $a\le{b}$.,"prove that $a^b\ge{b}^a$ for all $a,b\ge3$. given that $a\le{b}$. I was trying to solve the question by graph. Can anyone help me please?","['inequality', 'calculus', 'real-analysis', 'analysis']"
857762,First Order Logic Consistency Big Problem,"as i read some tutorial material on First Order Logic, i deduce that the following formula was consistent in FOL except the third one. am i right? i have doubt about the first one. any idea? thanks to all experts. $\bigl\{\exists y\exists x\forall z\,\bigl(C(x,y,z) \to \neg C(x,x,x)\bigr)\bigr\}$ $\bigl\{Â \forall x \bigl(A(x) \to B(x)\bigr), \forall x \bigl(A(x) \to \neg B(x)\bigr)\bigr\}$ $\{\forall x\,A(x)\} \cup \{\neg A(t) \mid t \text{ is a term}\}$ $\{\forall x\exists y\, B(x,y) \to \neg \exists y \forall x \,B(x,y), \exists x\,B(x,x)\}$","['calculus', 'discrete-mathematics', 'logic', 'linear-algebra', 'first-order-logic']"
857768,Another formula for number of onto function.,"Let A and B be two sets. $A=\{1,2,\dots m\}$ $B=\{1,2,\dots n\}$ We have to find the number of onto functions from A to B In the following link , the approach of the answer was applying Inclusion Exclusion to count the complement. Can't we use it directly? Number of onto functions My Approach Let $J_i$ denote the number of mappings in which there exists a pre-image of $i$. We need to find $|J_1\cup J_2\cup \dots J_n|$. From inclusion exclusion we conclude $$|J_1\cup J_2\cup \dots J_n|=\sum_{i=0}^n|J_i|- \sum_{1\leq i <j\leq n}|J_i\cap J_j| \dots$$ Now, $|J_i| = m * n^{m-1}$ $|J_i\cap J_j|$= $m*(m-1)*n^{m-2}$ and so on. Then we just put in the values. Is it correct?","['permutations', 'combinations', 'combinatorics']"
857771,Does the limit of a sequence with floor function exist?,"Question : Let $a_n=n\alpha-\lfloor n\alpha\rfloor\ (n=1,2,\cdots)$ where $\alpha$ is an irrational number. Then, does the limit $n\to\infty$ of $(a_n)^n$ exist? I know that $\lim_{n\to\infty}(a_n)^n=0$ for a rational number $\alpha$. However, I don't have any good idea to solve the question. Can anyone help? $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $","['limits', 'irrational-numbers', 'number-theory']"
857778,Do these definitions make sense?,"Letting $G$ be a group and $S(G)$ be all permutations of $G$, define $$L(G)=\{\phi\in S(G)|\forall n\in \mathbb Z , \phi(g^n)=\phi(g)^n\ \ \forall g\in G \}.$$ It is easy to check that $L(G)$ is a group. My intuition to define $L(G)$ is to define ""local isomorphisms "" of a group as it sends cyclic groups to its correspondonce. We have $L(G)\geq Aut(G)$, and if $G$ is cyclic then $L(G)=Aut(G)$. With similiar intuition, we can define $$A(G)=\{\phi\in S(G)|\phi(xy)=\phi(x)\phi(y)\ \ if \ xy=yx \}$$ and can see that $L(G)\geq A(G)\geq Aut(G)$, and if $G$  is abelian then $A(G)=Aut(G)$. The group $Aut(G)$ may give a lot of information about $G$. Is that also true about $L(G)$ or $A(G)$? Any further observations would be appreciated.","['finite-groups', 'group-theory', 'abstract-algebra']"
857784,Product neighborhood theorem with boundary,"The Product Neighborhood Theorem states that if $N\subseteq M$ is a smooth compact submanifold without boundary of codimension $n$ and there is a trivialization of the normal bundle (wrt. some smooth metric) of $N$ in $M$, then some neighborhood of $N$ is diffeomorphic to $N\times \mathbb{R}^n$ s.t. the diffeomorphism takes the framing vectors to the canonical basis of $\mathbb{R}^n$. Is the same true if $N,M$ are smooth manifolds with boundary and $N$ is a neat submanifold of $M$? For the proof, in most texts I found the idea to map $(n,x)\in N\times\mathbb{R}^n$ to $\varphi(1)$ for a geodesics $\varphi$ starting in $n$ with tangent vector $\epsilon x$ for $\epsilon$ small enough. This probably doesn't work on the boundary: for example, if $M$ is the closed unit 2-disc and $N:=\{0\}\times [-1,1]$ with the horizontal framing $(1,0)$ then I don't see how to generalize the above construction. I can hardly have a geodesics in $M$ starting in $(0,1)$ in the $(1,0)$ direction. Remark: What confuses me is that the boundary-version of PNT is used in the proof of the Thom-Pontryiagin construction -- namely, that $[M,S^n]$ is isomorphic to the framed cobordism group $\Omega^{fr}_{n;M}$ (a framed cobordism has boundary) -- but in all books, I have only seen the statement of PNT for the boundaryless case.","['differential-topology', 'riemannian-geometry', 'differential-geometry']"
857800,What kind of transformation an upper triangular matrix represents,"Every matrix represents a linear transformation, but depending on characteristics of the matrix, the linear transformation it represents can be limited to a specific type. For example, an orthogonal matrix represents a rotation (and possibly a reflection ). Is it something similar about triangular matrices ? Do they represent any specific type of transformation? (Actually a reference describing different geometric transformations and their corresponding transformation matrices would be great)","['linear-transformations', 'linear-algebra', 'transformation', 'rotations']"
857802,Solving the equation $n\log n = 10^9$,"This seems very basic (I guess my calculus needs brushing up). Is there a way to find n without a calculator in this one? $10^{9} = n\log(n)$ My Attempt (log is base 2 base on the book convention.) $10^9 = n\log n(n)\\
2^{10^9} = 2^{\log(n^n)}\\
2^{10^9} = n^n$ Currently I'm tempted to use Newton's method on 
$n^n-2^{10^9}=0$
but that seems to be an overkill.","['computational-complexity', 'calculus', 'discrete-mathematics']"
857846,Finding UMVUE for Poisson distribution using Rao Blackwell,"Let $X_1,X_2,\ldots,X_n$ be a random sample from a Poisson distribution with parameter $\lambda$. Let $\gamma(\lambda)=P(X\le 1)$.
Find UMVUE for  $\gamma(\lambda)$. This is my attempt: First I defined a indicator function as $T'=I_{(X_1\le 1)}=\begin{cases}
1,  & \text{if $X_1\le1$ } \\
0, & \text{otherwise}  \\
\end{cases}$ which is unbiased estimator for  $\gamma(\lambda)$. Also since this belongs to one parameter exponential family $T=\sum X_i$ is a sufficient statistic for  $\gamma(\lambda)$. Then by Rao Blackwell Theorem,
$E[T'|T=t]$ is a UMVUE for  $\gamma(\lambda).$ \begin{align}
& \operatorname E[T'\mid T=t]=1\cdot P[T'=1\mid T=t]+0\cdot P[T'=0\mid T=t] \\[10pt]
= {} & {P[X_1\le 1 \text{ and } X_1+ X_2+ X_3+\cdots+ X_n=t] }\over P[\sum X_i=t] 
\end{align} Since at this moment$ X_1\le 1$ it becomes that $X_2+ X_3+\cdots X_n\ge t-1$.Then since $ X_1\le 1$ and $X_2+ X_3+\cdots+X_n\ge t-1$ are independent from one another \begin{align}
& P[X_1\le 1 \text{ and } X_1+ X_2+ X_3+\cdots+X_n=t] \\[10pt]
= {} & P[X_1\le 1] \cdots P\left[\sum_{i=2}^n X_i\ge t-1\right]
\end{align} Now I am stuck in computing $P[\sum_{i=2}^n X_i\ge t-1]$. $\sum_{i=2}^n X_i$ follows a poisson with parameter $(n-1) \lambda$.  In finding $P[\sum_{i=2}^n X_i\ge t-1]$ I came up to cumulative of Poisson $e^{-(n-1)\lambda}\sum_{i=0}^{y-1}(({n-1)\lambda)}^i / i!$.Is there a way I can simplify this.Please help me to find a UMVUE for this problem.","['statistics', 'statistical-inference']"
857866,"Is $\cup_{k=1}^\infty (r_k-\frac{1}{k}, r_k+\frac{1}{k}) = \mathbb{R}$?","Let $r_k$ be the rational numbers in $\mathbb{R}$. (1).Is $\cup_{k=1}^\infty (r_k-\frac{1}{k^2}, r_k+\frac{1}{k^2}) = \mathbb{R}$? (2).Is $\cup_{k=1}^\infty (r_k-\frac{1}{k}, r_k+\frac{1}{k}) = \mathbb{R}$? (1).Because $m(\mathbb{R})=+\infty, \sum_{k=1}^\infty \frac{1}{k^2}<+\infty$, so $\mathbb{R} \setminus\cup_{k=1}^\infty (r_k-\frac{1}{k^2}, r_k+\frac{1}{k^2})\neq \Phi  $
(2) What about (2)?",['real-analysis']
857875,Are indefinite integrals unique up to the constant of integration?,"We often write e.g. $$\int x^2 dx=\tfrac{1}{3}x^3+c$$ for any $c \in \mathbb{R}$, where $c$ is the constant of integration . We can show (via limits) that, if $g(x)=\frac{1}{3}x^3+c$, then $\frac{dg}{dx}=x^2$ for any $c \in \mathbb{R}$.  But this doesn't exclude the possibility that some function $f=f(x)$ that doesn't have the form $\tfrac{1}{3}x^3+c$ also has the derivative $\frac{df}{dx}=x^2$.  So... Q : Are indefinite integrals unique up to the constant of integration?  If so, how do we know?","['calculus', 'integration', 'indefinite-integrals']"
857882,Differential equation $2xy \frac{dy}{dx}-y^2+x=0$,"I've been doing some exam tasks and I've come along this equation $$2xy \frac {dy}{dx}-y^2+x=0$$ 
that I dont know how to solve. I probably need some substitution in here but I just can't see it.",['ordinary-differential-equations']
857899,Elliptic partial differential equations and elliptic operators,"I'm starting to study elliptic partial differential equations and I just want to know if there are any connections between the following  concepts: An elliptic partial differential equation is given as being a second-order partial differential equation of the form $$Au_{xx} + 2Bu_{xy} + Cu_{yy}+Du_{x} + Eu_{y} + F = 0$$ that satisfies the condition $B^{2}-AC < 0$. The classification seems to be connected with conic sections. And then there's the definition of an elliptic operator which is defined as a linear differential operator $L$ of order $m$ on a domain $\Omega$ in $\mathbb{R}^{d}$ given by $$Lu = \sum_{|\alpha| \leq m}a_{\alpha}(x)\partial^{\alpha}u$$ (where $\alpha$ is a multi-index) is called elliptic if for every $x$ in $\Omega$ and every non-zero $\zeta$ in $\mathbb{R}^{d}$ $$\sum_{|\alpha|=m}a_{\alpha}(x)\zeta^{\alpha} \neq 0$$ I just have a couple of questions about these concepts? Firstly, why are PDE's classified in this way where it relates to conic sections?(elliptic, parabolic,hyperbolic) Secondly, what is the connection between elliptic partial differential equations and elliptic operators? I thought that an elliptic operator would be an elliptic PDE in operator form, in the sense that say $x-y=0$ was an elliptic PDE then $f(x,y) = x-y$ would be an elliptic operator. But it seems that there is no connection between elliptic operators and elliptic PDE's? Thanks for any help.","['operator-theory', 'functional-analysis', 'partial-differential-equations']"
857903,Is there a name for those commutative monoids in which the divisibility order is antisymmetric?,"Every commutative monoid $M$ is naturally equipped with its divisibility preorder, defined as follows. $$x \mid y \leftrightarrow \exists a(ax=y)$$ Is there a name for those commutative monoids such that the above preorder is antisymmetric? In other words, I'm interested in those commutative monoids satisfying the following quasi-identity : $$\frac{ax=y\quad by=x}{x=y}$$ Motivation. The category of all such structures is probably a reflective subcategory of the category of all commutative monoids, with the left-adjoint to the inclusion functor being the functor $F$ such that $F(M)$ is the commutative monoid obtained by identifying elements $x,y \in M$ satisfying $x \mid y$ and $y \mid x$. Now given a commutative monoid $M$, we are often interested in meets and joins with respect to the divisibility order, but uniqueness issues rear their annoying heads. They can be remedied by working not in $M$, but in $F(M).$","['category-theory', 'terminology', 'abstract-algebra', 'monoid']"
857924,$2^{1/4} \times 4^{1/8} \times 8^{1/16} \times 16^{1/32} \times \ldots\to2$,$2^{1/4} \times 4^{1/8} \times 8^{1/16} \times 16^{1/32} \times \ldots\to2$ How can I explain this to a school student who doesn't know what a  limit is?,"['education', 'algebra-precalculus', 'intuition']"
857929,Affine connection on a Lie group.,"Let $G$ be a Lie group. For $g \in G$, we can define a diffeomorphism $l_g: G \to G$ by $l_g(x)=gx$, and a bundle map ${l_g}_*:TG \to TG$. Then, I guess that we can obtain the affine connection on $G$ by reverse thinking that we could make a parallel transportation from a connection. Now, ${l_g}_*$ is the 'parallel transportation', and we would like to make the 'affine connection' from this. Is it true? If so, what is the name of this affine connection on $G$? Thanks for your help!!","['lie-algebras', 'differential-geometry', 'lie-groups', 'differential-topology', 'connections']"
857934,How prove $f(x)$ is a monotonic function if $f(x+y)=f(x)f(y)$,"Let $f(x)$ be a real valued, differentiable function such that for any $x,y \in \mathbb{R}$ , $f(x+y)=f(x)f(y)$ . Suppose there exist $a,b$ such that $f(a)\neq 0, f'(b)>0$ . Show that $f(x)$ is a monotonic function I tried to use the Cauchy equation result to get: $f(x)=p^x$ for some $p>1$ . I would like to know if there are simpler methods.",['functions']
857942,How to find orthogonal projection of vector on a subspace?,"Well, I have this subspace: $V = \operatorname{span}\left\{ \begin{pmatrix}\frac{1}{3} \\\frac{2}{3} \\\frac{2}{3}\end{pmatrix},\begin{pmatrix}1 \\3 \\4\end{pmatrix}\right\}$
and the vector $v = \begin{pmatrix}9 \\0 \\0\end{pmatrix}$ How can I find the orthogonal projection of $v$ on $V$? This is what I did so far: \begin{align}&P_v(v)=\langle v,v_1\rangle v_1+\langle v,v_2\rangle v_2 =\\=& \left\langle\begin{pmatrix}9 \\0 \\0\end{pmatrix},\begin{pmatrix}\frac{1}{3} \\\frac{2}{3} \\\frac{2}{3}\end{pmatrix}\right\rangle\begin{pmatrix}\frac{1}{3} \\\frac{2}{3} \\\frac{2}{3}\end{pmatrix}+\left<\begin{pmatrix}9 \\0 \\0\end{pmatrix},\begin{pmatrix}1 \\3 \\4\end{pmatrix}\right>\begin{pmatrix}1 \\3 \\4\end{pmatrix} = \begin{pmatrix}10 \\29 \\38\end{pmatrix}\end{align} Is this the right method to compute this?","['orthogonality', 'linear-algebra', 'inner-products']"
857961,Changing one point does not change the Riemann integral,"I tried to prove the following. Please could somebody tell me if my proof is correct? Let $f: [a,b]\to \mathbb R$ be Riemann integrable. Then changing one
  value of $f$ then $f$ is still integrable and it integrates to the
  same value. My proof. Let $x \in [a,b]$ denote the point where $f$ is changed. Let $\widetilde{f}$ denote the new function with $\widetilde{f}(x) = z$ and the old function is $f(x) = y$. Let $M = |y-z|$. Let $\varepsilon > 0$. Let $U(f,P)$ denote the upper sum and $L(f,P)$ the lower sum for partition $P$. Since $f$ is integrable there exists a partition $P$ such that the upper sums minus the lower sums are less than epsilon: $$ U(f,P) - L(f,P) < \varepsilon $$ Let $Q$ be the refinement of $P$ consisting of $P$ and $\{x-{\varepsilon \over 2M}, x + {\varepsilon \over 2M}\}$. Then $U(f,P) \ge U(f,Q)$ and $L(f,P) \le L(f,Q)$. Furthermore, $|U(f,Q)-U(\widetilde{f},Q)| \le {\varepsilon \over M}\cdot M = \varepsilon$. This is true because $f$ and $\widetilde{f}$ only differ at $x$ and at $x$ they can maximally differ by $M$. Since the partition $Q$ contains the interval $(x- {\varepsilon \over 2M}, x + {\varepsilon \over 2M})$ and this interval has lenght ${\varepsilon \over M}$ the maximal difference of these sums can be only $\varepsilon$. Similarly, $|L(f,Q)-L(\widetilde{f},Q)| \le \varepsilon$. Hence $$ |U(\widetilde{f},Q) - L(\widetilde{f},Q)| \le |U(\widetilde{f},Q) - U(f,Q)| + |U(f,Q) - L(f,Q)| +  |L(f,Q) - L(\widetilde{f},Q)| \le \varepsilon $$","['proof-verification', 'real-analysis']"
857971,Ring of integers is a PID but not a Euclidean domain,"I have noticed that to prove fields like $\mathbb{Q}(i)$ and $\mathbb{Q}(e^{\frac{2\pi i}{3}})$ have class number one, we show they are Euclidean domains by tessellating the complex plane with the points $a+bv : a, b \in \mathbb{Z}$ , where $1, v$ is an integral basis.  Then any $c +dv$ in the field has distance $\leq 1$ from some lattice point.  On the other hand a similar geometric argument fails with the field $\mathbb{Q}(\sqrt{-5})$ , which does not have class number one. Any ring of integers of a finite extension of $\mathbb{Q}$ is a Dedekind domain, hence a PID if and only if a UFD.  But can such a ring be a PID but fail to be a Euclidean domain?","['principal-ideal-domains', 'unique-factorization-domains', 'algebraic-number-theory', 'abstract-algebra']"
857979,Basic Question about notation in the space of continuous functions,"I am reading the book ""Introduction to Calculus of Variations"" by Bernard Dacorogna (Could not find a link in google books) where he defines
$C(\bar{\Omega})$ to be the space of continuous functions $u : \Omega \to \mathbb{R}$ which can be continuously extended to $\bar{\Omega}$ (here $\Omega$
is an open set in $\mathbb{R}^n$). After this, he defines the norm over $C(\bar{\Omega})$ by 
$\|u\|_0 = \sup_{x \in \bar{\Omega}} |u(x)|$ and then $C(\bar{\Omega})$ with this norm is a Banach Space. I am confused about two things:- 1) Does $C(\bar{\Omega})$ consist of functions $u : \Omega \to \mathbb{R}$ which can be continuously extended or functions $u : \bar{\Omega} \to \mathbb{R}$ 2)The ""norm"" $\|.\|_0$ is not a norm as $\bar{\Omega}$ need not be bounded and
hence it can take an infinite value Can someone please let me know if I am right and if so, this notation is OK in some texts.",['functional-analysis']
857986,"If $\cos 25^\circ + \sin 25^\circ = k,$ then what is $\cos 20^\circ$?","Question: If $$\cos 25^\circ + \sin 25^\circ = k,$$ then what is $\cos 20^\circ$? What I did: I tried to square both sides, and obtained that $\sin 50 = k^2 -1$, however, this didn't get me anywhere. Then I tried splitting 25 into 20 + 5 but that didn't get me anywhere either. Can someone just point me in the right direction?","['trigonometry', 'algebra-precalculus']"
857992,References for mathematical theory of summability of divergent series,"Once in a while, I can't help it to ask very broad questions. I have read (a portion of) Hardy's Divergent Series. Back then, I think besides in mathematics, divergent series and the need to assign values to them hadn't arisen. But nowadays, for example, almost all explanations of the 26 dimensions of Bosonic string theory deals with such an assignment. Also, the internet literally exploded on Youtube explaining these kinds of issues (they conveniently left out all the proofs). Questions: Are there (more modern) references for the mathematical theory of the summability of divergent series, and its philosophy (I.e. usage of such things in physics) ? I have seen divergent series of real numbers sum to a complex number with non-zero imaginary part. Is there something more to it (for example, are there known divergent series that lead to a quaternion) ? I am tagging this with meta, biglist and analysis, for obvious reasons.","['big-list', 'divergent-series', 'reference-request', 'analysis']"
857995,Second degree partial differential equation with variable-change,"Edit: @Etienne mentioned that I did a typo, writing $u_y' = -xye^{-y}$ instead of $u_y' = -xe^{-y}$. I've corrected that in the calculations and now it's closer to being correct! Though I still miss $e^{-y}$ multiplicated with $f_{uv}''$ to get the correct answer. Problem: Transform the differential equation: $$
x\frac{\partial ^2f}{\partial x^2} + \frac{\partial ^2f}{\partial x \,\partial y} + \frac{\partial f}{\partial x} =  xe^{-2y}
$$ by introducing:
$$ 
\begin{cases}
u = &xe^{-y} \\
v = &y
\end{cases}
$$ How I am solving it. Rewrite to:
$$
xf_{xy}'' + f_{yx}'' + f_{x} = xe^{-2y}
$$ solve $x$ and $y$ in $u$ and $v$:
$$
\begin{cases}
x = &\frac{u}{e^{-v}} \\
y = &v
\end{cases}
$$ And calculate:
$$
\begin{cases}
u_x' = & e^{-y} \\
u_y' = & -xe^{-y}
\end{cases} 
$$
$$
\begin{cases}
v_x' = & 0 \\
v_y' = & 1
\end{cases} 
$$ Find $f_x'$ by using the chainrule:
$$
f_x' = f_u' \cdot u_x' + f_v' \cdot v_x' = f_u' \cdot e^{-y}+f_v'\cdot0=f_u'e^{-y}
$$ set $g=f_u'$ and $h=f_v'$ and calculate $f_{xx}''$ $$
f_x' = f_u'e^{-y} \underbrace{= }_{g=f_u'} ge^{-y}
$$
$$
f_{xx}'' = g_x' \cdot e^{-y}
$$ Find $g_x'$ (using chainrule):
$$
g_x' = g_u' \cdot u_x' + g_v' \cdot v_x' = g_u' \cdot e^{-y} + g_v' \cdot 0 =  g_u' \cdot e^{-y} \underbrace{= }_{g=f_u'} (f_u')_u' \cdot e^{-y} = f_{uu}'' \cdot e^{-y}
$$ insert $g_x'$ in $f_{xx}''$ gives:
$$
f_{xx}'' \underbrace{=}_{g_x' = f_{uu}'' \cdot e^{-y}} (f_{uu}'' \cdot e^{-y}) \cdot e^{-y} = f_{uu}'' \cdot e^{-2y} \underbrace{=}_{y=v} f_{uu}'' \cdot e^{-2v}
$$ Now I have $f_x'$ and  $f_{xx}''$ and I only need $f_{yx}''$ to insert the differentials ito the original equation. But $f_{yx}''$ can be found using $(f_x')_y'$ since $f_{xy}'' = f_{yx}''$. $$
f_{xy}'' = -ge^{-y} + g_y'e^{-y}
$$ Find $g_y'$ (using chainrule):
$$
g_y' = g_u' \cdot u_y' + g_v' \cdot v_y' = g_u' \cdot (-xe^{-y}) + g_v' \cdot 1 \underbrace{=}_{g=f_u'} (f_u')_u' \cdot (-xe^{-y}) + (f_u')_v' \cdot 1 =
$$
$$ - f_{uu}'' \cdot xe^{-y} + f_{uv}'' = - f_{uu}'' \cdot \frac{u}{e^{-v}}e^{-v} + f_{uv}'' = - f_{uu}'' \cdot u + f_{uv}''
$$ replace $g$ and $g_y'$ and translate to $u$ and $v$ instead of $x$ and $y$ $$
f_{xy}'' = -f_u' e^{-v} + (- f_{uu}''u + f_{uv}'')e^{-v} = -f_u' e^{-v} - f_{uu}''ue^{-v} + f_{uv}''e^{-v}
$$ Insert $f_{xx}''$, $f_{yx}''$ and $f_v'$ in the original equation: $$
\frac{u}{e^{-v}} (f_{uu}'' e^{-2v}) + -f_u' e^{-v} - f_{uu}''ue^{-v} + f_{uv}''e^{-v} + f_u'e^{-v} = xe^{-2y}
$$
$f_u' e^{-v}$ and $uf_{uu}''e^{-v}$ cancels and I get
$$
f_{uv}'' = ue^{-v} = \frac{\partial ^2f}{\partial u \,\partial v}
$$ Obviously I've missed something. The terms with $f_{uu}''$ is gonna cancel out each other, but I can't figure out whats wrong. I've recalculated this assignment 3 times and it must be something Im not doing correctly, since I probably wouldnt do the same error three times in a row.. The answer is supposed to be:
$$
\frac{\partial ^2f}{\partial u \,\partial v} = u
$$ So I'm missing a $v$ in the first term and $e^{-v}$ multiplied with $f_{uv}''$","['multivariable-calculus', 'partial-differential-equations']"
858000,"prove $ab\in A$, if $A=\{x^3+y^3+z^3-3xyz\mid x,y,z\in \mathbb Z\}$, $a,b\in A$","let $A=\{x^3+y^3+z^3-3xyz\mid x,y,z\in \mathbb {Z}\}$ , prove that: if $a,b\in A$ , then $ab\in A$ , I think we must find $A,B,C$ such $$A^3+B^3+C^3-3ABC=(a^3+b^3+c^3-3abc)(x^3+y^3+z^3-3xyz)$$ where $A,B,C,a,b,c,x,y,z\in \mathbb Z$ , but I can't find it. I think this result is interesting, I hope someone can solve it. Thank you",['number-theory']
858018,"Prove that the symmetric group on $n$ letters, $S_n$, has order $n!$.","Here's my proof in which I've used another theorem to prove this one. I want you suggest me another proof without using this theorem, please. Proof : By the theorem Cardinality of set of injections , we have: Let $S$ and $T$ be sets. The number of injections from $S$ to $T$ where $|S|=m, |T|=n$ is often denoted $P_{nm}$, and is $P_{nm}=\left\{ \begin{array}{rl} \frac{n!}{(n-m)!} & m\leq n \\ 0 & m>n \end{array}\right.$ Since the symmetric group on $n$ letters is a bijection (and therefore and injection), and that by the operation $f\circ g:S\rightarrow S$ we have $m=n$, then $|S_n|=n!/0!=n!$  $\square$","['group-theory', 'abstract-algebra']"
858036,Proving Induction $(1\cdot2\cdot3)+(2\cdot3\cdot4)+...+k(k+1)(k+2)=k(k+1)(k+2)(k+3)/4$,"I need a little help with the algebra portion of the proof by induction. 
Here's what I have: Basis Step: $P(1)=1(1+1)(1+2)=6=1(1+1)(1+2)(1+3)/4=6$ - Proven Induction Step: $$(1\cdot2\cdot3)+(2\cdot3\cdot4)+...+k(k+1)(k+2)+(k+1)(k+2)(k+3)=(k+1)(k+2)(k+3)(k+4)/4$$
 $$=k(k+1)(k+2)(k+3)/4+(k+1)(k+2)(k+3)=(k+1)(k+2)(k+3)(k+4)/4$$ I'm stuck with the algebra here and not sure how to simply LHS. Any suggestions, or another set of eyes to to see another solution would be great!","['induction', 'discrete-mathematics']"
858064,Proof of the inequality $\sqrt{\det X} \leq \frac{\operatorname{tr}X}{2}$,"Let $A, B \in M_2(\mathbb{R})$ be symmetric and positive definite. Put $X:=AB$. 
then, we have the following inequality: $$\sqrt{\det X}\leq \dfrac{1}{2}\operatorname{trace}X.$$ and the equality holds iff $\exists \lambda>0\ s.t.\ X=\lambda E$. I cannot prove this though I have put 
$A=\left(\begin{array}{ccc}
a &s\\
s &b\\
\end{array} 
\right), $
$B=\left(\begin{array}{ccc}
x &t\\
t &y\\
\end{array} 
\right), $
 and have extended each part of the inequality by $a,s,b,x,t,y$. Please help me. (I encountered this problem when I tried to solve [3.10] of Nishikawa ""Variational Problems in Geometry"". )","['matrices', 'linear-algebra']"
858078,The only fixed-point free automorphism of order $2$ is $\phi(a)=a^{-1}$(in a finite group),"I got the problem in  Dummit and Foote's Algebra book to prove if $G$ is a finite group that has an automorphism $\phi$  in which if $a=\phi(a)$ then $a=1$. And which satisfies $\phi(\phi(a))=a$ for all $a$ then $G$ is abelian. Here is what I did: I first prove the map $\omega(a)=a^{-1}\phi(a)$ is injective(and since the group is finite and the domain is the same as the co-domain this proves it is also bijective): $a^{-1}\phi(a)=b^{-1}\phi(b)\implies ba^{-1}\phi(a)=\phi(b)\implies ba^{-1}=\phi(b)\phi(a)^{-1}=\phi(ba^{-1})\implies ba^{-1}=1\implies b=a$. So every element in $G$ is of the form $a^{-1}\phi(a)$. Notice $\phi(a^{-1}\phi(a))=\phi(a^{-1})a$. Which is the inverse of $a^{-1}\phi(a)$ which tells us $\phi(g)=g^{-1}$. From here we get $\phi(ab)=b^{-1}a^{-1}=a^{-1}b^{-1}=\phi(a) \phi(b)$ multiplying by $a$ and $b$ on both sides gives $ab=ba$ as desired. My question is: is what I did correct (especially everything up to the point where I conclude $\phi(a)=a^{-1}$)? Normally I wouldn't ask this, but the fact that it asked me to prove something much weaker instead of characterizing the automorphism uniquely makes me doubt it is OK.","['proof-verification', 'abstract-algebra']"
858117,"There exist $x_1, x_2, x_3$ such that $\frac{1}{f'(x_1)} + \frac{1}{f'(x_2)} + \frac{1}{f'(x_3)} = 3$","Let $f$ be a real-valued function defined in $[a, b] \subset \mathbb{R}$, with
$f(a) = a, f(b) = b$. Suppose that $f$ is continuous on $[a, b]$ and differentiable on $(a, b)$. Show that there exist three distinct points $x_1, x_2, x_3$ such that $$\frac{1}{f'(x_1)} + \frac{1}{f'(x_2)} + \frac{1}{f'(x_3)} = 3$$ My hunch is to use the mean-value theorem or Rolle's theorem somehow. But these theorems only guarantee the existence of a certain point, and not a triple of points, so I am stuck.",['real-analysis']
858134,Prove that $\lim_{n\rightarrow\infty}\frac{x_1^2+x_2^2+\cdots+x_n^2}{n^2}=0$,"Let's $x_n\ge0$ and $$\overline{\lim}_{n\rightarrow\infty}\frac{x_1+x_2+\cdots+x_n}{n}\lt+\infty,~~\lim_{n\rightarrow\infty}\frac{x_n}{n}=0.$$Prove that $$\lim_{n\rightarrow\infty}\frac{x_1^2+x_2^2+\cdots+x_n^2}{n^2}=0.$$
I have no idea how I can start the proof. Thanks!","['sequences-and-series', 'limits']"
858167,Conditioning on information about the moments of a random variable is trivial,"Say we have some random variable, $X$. Is it always trivial to condition
on information about the moments of $X$? For example, suppose we know that $\mathbb{E}(X)$ is positive. But
$\mathbb{E}\left(X|\mathbb{E}(X)>0\right)=\mathbb{E}(X)$ since the
thing in the conditioning set is just some generic fact about a constant. Same is true for $X,Y$ have some joint distribution. $\mathbb{E}(X|\mathbb{E}(X)>\mathbb{E}(Y))=\mathbb{E}(X)$.","['statistics', 'probability', 'expectation']"
858190,Solving $|z-3| \leq|z-1-i|$,"I was trying to solve graphicly: $$|z-3| \leq |z-1-i|$$ I plugged x and y in proper places as real componenets of the comlex number yielding in the end $-4x+2y+7 \leq0$ this might be tackled if
first eqauted to $0$ hence: $y=2x-3.5$ I need to sketch it also and I suppose that it should be all values which are under the graph of $y=2x-3.5$  on the gauss plane?","['complex-numbers', 'algebra-precalculus', 'complex-analysis']"
858209,How to compute $\int_C {e^{3z}-z\over (z+1)^2z^2}$?,"I am asked to compute the integral
$$
\int_C {e^{3z}-z\over (z+1)^2z^2}
$$
where $C$ is a circle with the center at the origin and radius ${1 \over 2}$. My approach was to separate the integral as a differentiation of 2 contour integrals: $$
\int_C {e^{3z}-z\over (z+1)^2z^2} = \int_C {e^{3z}\over (z+1)^2z^2} - \int_C {1\over (z+1)^2z}
$$ Then I calculated the residue of each contour integral with a Laurent series around $z_0 = 0$: $$
{e^{3z}\over (z+1)^2z^2} = {1\over (z+1^2)}\ .\ e^{3z}\ .\ {1\over z}
$$ $$
{e^{3z}\over (z+1)^2z^2} = \sum_{n=0}^\infty {3^nz^{n-2}\over n!}\ .\ (1-2z+3z^2+...)
$$ $$
{e^{3z}\over (z+1)^2z^2} = {a_{-2}\over z^2}+{-2+3\over z}+a_0+...
$$ So the residue for this contour integral is $1$ and the final result is $2\pi i$ I did the same with the other countour integral: $$
{1\over (z+1)^2z} = {1\over z}\ .\ (1-2z+3z^2+...)
$$ $$
{1\over (z+1)^2z} = {1\over z}-2+3z^2+...
$$ So the residue for this contour integral is also $1$ and the final result is $2\pi i$ Then I substitute my results in the original contour integral: $$
\int_C {e^{3z}-z\over (z+1)^2z^2} = 2\pi i - 2\pi i
$$ And this is where my problem is (I get zero), can someone point to me what I did wrong?","['laurent-series', 'complex-analysis', 'contour-integration']"
858224,Non-examples for the Kato-Rellich Theorem,"The Kato-Rellich Theorem is a classical result stating that if $A,B$ are unbounded operators on a Hilbert space with $A$ self-adjoint, $B$ symmetric, $\mathcal D (A)\subset \mathcal D(B)$ and
$$
\|Bx\|\leq a\|A x\|+b\|x\|,\;\;x\in\mathcal D(A)
$$
for positive constants $a,b$, with $a<1$, then $A+B$ is self-adjoint on the domain of $A$. The infimum of those $a$ for which the above inequality holds is called the relative bound of $B$. Thus, $A+B$ is self-adjoint if $B$ is relatively bounded with bound $a<1$. I'm interested in non-examples where $A+B$ is not essentially self-adjoint even though $A$ is self-adjoint, $B$ is symmetric and $\mathcal D(A)\subset\mathcal D(B)$. I have tried considering multiplication operators to no avail. Let $M_\phi$ denote the multiplication operator
$$
M_\phi h=\phi h,\;\;\mathcal D(M_{\phi})=\{ h|\phi h\in L_2\},
$$
and let $A=M_f$, $B=M_g$ with $f,g$ real functions, finite almost everywhere. Since $A$ and $B$ are closed, the assumption $\mathcal D(A)\subset\mathcal D(B)$ implies the bound
$$
\|B h\|\leq C(\|A h\| +\|h\|)
$$
for some $C>0$. But then, for $h$ non-zero only on the set $\{x||f(x)|\leq M\}$, one obtains
$$
\|B  h\|\leq C(1+M)\|h\|,
$$
which implies that $|g(x)|\leq C(1+M)$ almost everywhere on $\{x||f(x)|\leq M\}$. This in turn implies $|f(x)+g(x)|\leq (M+ CM + C)$ on that same set. But then $\mathcal D(A)$ is a core for $\mathcal D(M_{f+g})$, which implies that $A+B$ is essentially self-adjoint. Next up were SchrÃ¶dinger operators. 'Unfortunately', Theorem XIII.96 in Methods of Modern Mathematical Physics vol 4 by Reed and Simon implies that (on $\mathbb R^d$, with $d\leq 3$) the inclusion $\mathcal D(-\Delta)\subset\mathcal D(V)$ is sufficient in order to conclude that $V$ is relatively $(-\Delta)$-bounded with bound $0$.","['examples-counterexamples', 'partial-differential-equations', 'linear-algebra', 'hilbert-spaces', 'functional-analysis']"
