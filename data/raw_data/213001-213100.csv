question_id,title,body,tags
4302136,Does every continuous function have an order of vanishing?,"I am trying to understand in what ways we can characterise growth of continuous functions around a point. One particular way to do so is by comparing a functions growth to a power of $x$ as follows. For a continuous function $f:[0,\infty) \to \mathbb{R}$ define its order of vanishing (at $x=0$ ) to be the number $0\leq \alpha \leq \infty$ such that $$\lim_{x \to 0} \left(\frac{f(x)}{x^\alpha}\right) =\gamma \neq \cases{0 \\ \pm \infty} $$ i.e. the $\alpha$ so the above limit is defined, finite and non-zero. In the case for a function $f(x)$ where $\frac{f(x)}{x^n} \to 0 \quad \forall n \in[0,\infty)$ define the order of vanishing of $f(x)$ , namely $\alpha$ , to be $\infty$ . For example with these definitions $\alpha=\infty$ when $f(x)=\exp \left(-\frac{1}{x}\right)$ as then $f(x)$ would grow slower than any power of $x$ around $x=0$ . My question is : Does the order of vanishing always exist for each continuous function $f$ on $[0,\infty)$ ? i.e. is this quantity well defined? If not then are there extra conditions should I stipulate on $f$ to guarantee existence? My thoughts on the matter as are follows, If such an $\alpha$ exists it is necessarily unique, for if $\beta<\alpha$ then $$\frac{f(x)}{x^\beta}=\frac{f(x)}{x^\alpha}\cdot x^{\alpha-\beta} \to 0$$ since by assumption the limit of $\frac{f(x)}{x^\alpha}$ is finite and non-zero. Hence $\beta$ cannot be an order of vanishing for $f$ . Similarly if $\beta>\alpha$ then $$\frac{f(x)}{x^\beta}=\frac{f(x)}{x^\alpha}\cdot \frac{1}{x^{\beta-\alpha}} \to \pm \infty$$ again, $\beta$ cannot be an order of vanishing of $f$ . Therefore if $\alpha$ exists it is unique. We cannot have $\frac{f(x)}{x^n}\to \pm \infty \quad \forall n \in [0,\infty)$ Since for $n=0$ this would imply $f(0)$ non finite. I suspect the existence of such an $\alpha$ may have a topological proof, maybe we can partition the domain of $\alpha \in [0,\infty)$ up into parts $S$ and $L$ , i.e. $[0,\infty)=S \cup L$ where $$S:=\bigg\{ \alpha \in [0,\infty) \bigg | \frac{f(x)}{x^\alpha} \to \pm \infty \text{ as } x \to 0 \bigg \}$$ $$L:=\bigg\{ \alpha \in [0,\infty) \bigg | \frac{f(x)}{x^\alpha} \to 0 \text{ as } x \to 0 \bigg \}$$ Maybe this violates the connectivity of $[0,\infty)$ ?","['asymptotics', 'real-analysis', 'continuity', 'limits', 'general-topology']"
4302146,Plotting graphs of Modular Forms,"After watching all the 8 parts of ""“Introduction to Modular Forms,” by Keith Conrad"" on YouTube, I got ""extremely intrigued"" by plotting graphs of Modular Forms ( on SL(2,Z) ). So after watching all those videos, I tried the following approach by dipping my hands into SageMath fundamentally by obtaining the q-expansion and using the Fourier series to reconstruct it. I used the following ""procedure"" ( this has been done using SageMath ) : obtain the modular form M4 = ModularForms(SL2Z,4) obtain 40 coefficients of the q-expansion print (M4.q_expansion_basis(40)) define FM(q) = 1 + 240 q + 2160 q^2 + 6720 q^3 + 17520 q^4 + 30240 q^5 + 60480 q^6 + 82560 q^7 + 140400 q^8 + 181680 q^9 + 272160 q^10 + 319680 q^11 + 490560 q^12 + 527520 q^13 + ..etc. etc. .. up to  .. +14770560 q^39 define FQ(z) = e^(2 I pi*z) finally plot the modulus of FM(FQ(z)) with a colormap ( i.e. complex_plot(FM4(FQ()), (-1,1),(0,1.5))) I get results like this picture : But as you can see ""the image definition is not the best"" , I was looking around for papers/things about ""plotting modular forms"" could not find much, except one paper mentioning something like ""using 5000 terms of the Fourier Serie"". Now the question is ""in any better way to get more detailed pictures of Modular forms ?"", I suspect mine is a bit of a ""brute force approach"" also probably prone to much numerical instability ? If you ask me ""why all that ?"" .. ""because I wanted to see how they look like"" :) Many thanks in advance for any reply. Cheers.","['modular-function', 'sagemath', 'number-theory', 'graphing-functions', 'modular-forms']"
4302185,When does there exist a subsequence which converges to the Cesaro mean,"I have a sequence of continuous (even analytic) functions on $[0,1]$ . I know that the Cesaro mean of the sequence of functions converges uniformly on $[0,1]$ : $$\frac{1}{N}\sum_{n=1}^Nf_n\rightarrow f$$ I was also able to show that this sequence is uniformly Lipschitz and bounded, so I know that there exists a subsequence of functions which converges uniformly on $[0,1]$ (using Arzela-Ascoli). I'd like to determine if there possibly exists a subsequence of functions which converges uniformly to the Cesaro mean itself ( $f$ ). So basically I'd be happy to hear some ideas about possible criterions I could use. I am obviously not saying that there should always be a subsequence which converges to the Cesaro mean, but maybe there are some useful special cases which I can use. At first I tried to possibly think in the direction of the Banach-Saks theorem and weak- $*$ topology. I know that the unit ball in $C([0,1])$ is weak- $*$ compact. I am actually not sure if it is weak- $*$ sequentially compact, but let's say it is. Then my bounded sequence contains a subsequence which converges in the weak- $*$ topology. Then I could maybe apply some version of Banach-Saks to show that this subsequence has a smaller subsequence which actually converges to the mean value in norm (so uniformly). But as I said, I am not sure if there is a version of Banach-Saks which applies in this case, and I am overall not sure about the details and if this should work, this was just a hunch. Anyway, I'd be happy to hear some ideas as to what tools might come in handy and under what assumptions I can actually show something like this. Thanks in advance.","['banach-spaces', 'weak-convergence', 'functional-analysis', 'uniform-convergence', 'sequences-and-series']"
4302187,"Can I exchange these operations: Absolute square, limit and time derivative in my specific example involving a Dirac sequence. If yes: why?","I am rederiving some physics stuff (related to Fermi's Golden rule) so I know what the result should be. ( I am a physicist, so I lack some math training.) However to get this result I have to exchange several operations at some point and I am really unsure why I should be able to do this. The term I have is: $$
\frac{d}{dt}
\left|\lim_{\epsilon \rightarrow 0} \frac{e^{\epsilon t} e^{\mathrm{i} (x -y) t}}{\epsilon + \mathrm{i}( x - y)} \right|^2
$$ If I could just reorder all the operations as much as I want, I would choose: First absolute square, then time derivative, then the limit. This would give me: $$
\lim_{\epsilon \rightarrow 0} \frac{2 \epsilon e^{2 \epsilon t}}{\epsilon^2 + (x - y)^2} = 2 \pi \delta(x-y)
$$ which is what I expected to find at some point in my derivation.
But why should this be allowed? Is it allowed in this case? I tried to read up on when I can exchange two limits when expressing $\frac{d}{dt}$ as a limit. However I think the problem is more special because of the Dirac distribution (?). I would be happy if someone can give advise here. Thank you very much in advance.","['limits', 'derivatives', 'dirac-delta']"
4302200,Distribution of the first hitting time for a Poisson point process,"Consider a $\mathbb{R}_+^2$ -valued Poisson point process $(e_s,\, s \geq 0)$ with intensity measure $\mu(\mathrm{d}x)\mathrm{d}y$ where $\mu$ is a finite measure on $\mathbb{R}_+$ . Let $f \colon \mathbb{R}_+ \to \mathbb{R}_+$ . Writing $e_s = (x_s,y_s)$ , define $T = \inf\{s\geq 0\colon\, y_s\leq f(s)\}$ . It is not hard to see that $$\mathbb{P}(T= \infty) = \mathbb{P}\left(\mathrm{Card}\{s\colon \, y_s \leq f(s)\}=0\right)=\exp\left(-\mu(\mathbb{R}_+)f(s)\right).$$ Now I would like to determine the joint distribution of $(T,x_T)$ on the event $\{T<\infty\}$ . I know that if $f\equiv c$ is constant then a classical result on Poisson point processes gives that $T$ is exponentially distributed, $x_T$ has distribution $\mu(\mathrm{d}x)/\mu(\mathbb{R}_+)$ and they are independent. What can be said about the general case when $f$ is not constant? Does a result of this type exist in the literature?","['stochastic-processes', 'probability-theory', 'poisson-process']"
4302224,"How to define function with range [0,1] from values ranging [0,∞)?","I have two entities A and B ; each is defined by two characters: density (D) and grade (G) . Density has the range [0, ∞); grade has range [μ, ν]. The two entities are related together as follows. If the density of B (Db) goes to 0, the grade of A (Da) goes to μ; viceversa: lim Db → ∞, Ga → ν. I could define a function relating the two entities as follows: f(A|B) = μ + (ν-μ)ε(B) where ε is a function that goes to 0 when lim Db → 1, and goes to 1 when lim Db → ∞.
The problem is that I don't know how to implement ε . I can't simply do ε=D, because G is a number well above 1. I could put ε=Db/Da, but Db might be larger than Da, thus ε>1. Neither I can do Db/max(Db) because max(Db) is ∞. Is there some mathematical trick I could apply to define ε?","['algebra-precalculus', 'functions']"
4302233,Injective functions and composition,"I'm trying to prove that a function $f \in A \to B $ is injective if and only if for all $C$ , for all $g,h \in C \to A$ : $f \circ g = f \circ h \to g = h$ . The $\to$ direction is proved as follows: [ $\to$ ] Let $f$ be injective and suppose that $f \circ g = f \circ h$ . It follows that $f(g(a)) = f(h(a))$ for any $a \in A$ , whence, for all $a \in A: h(a) = g(a)$ , by injectivity. I cannot however derive the $\leftarrow$ , by Suppose for all $g,h \in C \to A$ : $f \circ g = f \circ h \to g = h$ and that $f(a) = f(b)$ and, for contradiction, that $a \neq b$ . It is not clear to me how to get the information that $a = b$ from these assumptions. Can anyone help here?",['elementary-set-theory']
4302235,"Can two circles intersect each other at right angles, such that one circle passes through the center of the other circle?","More precisely, do there exist two intersecting circles such that the tangent lines at the intersection points make an angle of 90 degrees, and one of the circles passes through the center of the other? I think the answer is no, and that this can only be the case if the circle passing through the center of the other circle is actually a line. I'm not sure how to show this though. Can someone give a proof or a counterexample?","['conjectures', 'circles', 'geometry']"
4302272,Why would $\mathbb P( S > x \lvert \mathcal{F}_{0})= \frac{X_{0}}{x}\land 1$ imply that $S$ is distributed under $\mathcal F_{0}$ as $X_{0}/U$,"Let $X_{0}> 0$ a.s. and $\mathbb P( S > x \lvert \mathcal{F}_{0})= \frac{X_{0}}{x}\land 1$ . Why would this imply that $S$ is distributed under $\mathcal F_{0}$ as $\frac{X_{0}}{U}$ where $U$ is the uniform distribution on $[0,1]$ ,i.e. $\;\mathcal{U}[0,1]$ ? ( $U$ is independent of $\mathcal{F}_{0}$ and $X_{0}$ .) My problem: If $X_{0} < x \;,\; \; \text{then we have }\mathbb P( S > x \lvert \mathcal{F}_{0})= \frac{X_{0}}{x}$ If $X_{0} \geq x \;,\; \; \text{then we have }\mathbb P( S > x \lvert \mathcal{F}_{0})= 1$ I would have thought that $U$ would have to be $\mathcal{U}([X_{0},\infty))$ , i.e. uniformly distributed on $[X_{0},\infty)$ . Why is $[0,1]$ used?","['uniform-distribution', 'conditional-probability', 'martingales', 'probability-theory', 'probability']"
4302342,An exercise from Stein's complex analysis - Phragmen-Lindelof principle,"I am considering exercise 9 from chapter 4 of Stein and Sharkarchi's complex analysis: (a). Let $F$ be a holomorphic function in the right half-plane that extends continuously to the boundary, that is, the imaginary axis. Suppose that $|F(iy)|\leq 1$ for all $y \in \mathbb{R}$ , and $|F(z)| \leq Ce^{c|z|^\gamma}$ for some $c,C >0$ and $0 <\gamma <1$ . Prove that $|F(z) |\leq 1$ for all $z $ in the right half plane. (b). More generally, let $S$ be a sector whose vertex is the origin, and forming an angle of $\pi/\beta$ . Let $F$ be a holomorphic function in $S$ that is continuous on the closure of $S$ , so that $|F(z)| \leq 1$ on the boundary of $S$ and $|F(z)|\leq Ce^{c|z|^\alpha}$ for some $c,C>0$ and $0<\alpha < \beta$ . Prove that $|F(z)| \leq 1$ for all $z \in S$ . I was able to prove part (a) by considering the function $F_{\epsilon}(z) = F(z) e^{-\epsilon z^D}$ , where $\gamma<D<1$ and showing that $F_{\epsilon}(z)\leq 1$ for all $z$ in the right half plane. This is the idea behind the Phragmen-Lindelof principle. I assume that a similar approach is needed for part (b), but I can't seem to find a good candidate for $F_\epsilon$ in this case. For reference, Chapter 4 of Stein's complex analysis gives a nice demonstration of this proof tactic.","['complex-analysis', 'fourier-analysis', 'maximum-principle']"
4302358,Probability / Combinatoric of fair roulette question,"In a fair roulette there are $4$ sections, numbered $1$ to $4$ . A player spins the roulette's pointer $10$ times independently. What is the chance that the pointer stops at each one of the $4$ sections at least one? My attempt: We have symmetric distribution here, so $|\Omega|=4^{10}$ . Define: $A_i$ = the pointer stops at each one of the sections exactly $i$ times, for $i=1,2$ . We want $P(A)$ , and note that $A=\cup_{i=1}^2 A_i$ Then:
For $P(A_1)$ we choose 4 places for each section out of the 10 places, then we choose 3 sections out of the 4 and arrange them with the 6 places left, so: $$P(A_1)=\frac{\binom{10}{4}\binom{4}{3}6!}{10^4}$$ I do not know how to calculate $P(A_2)$ however, and I am not sure that what I did is correct, if not please explain me why. Thanks a lot!","['discrete-mathematics', 'combinatorics', 'probability', 'real-analysis']"
4302403,Is there a quadratically closed field strictly between the quadratic closures of $\mathbb{Q}$ and $\mathbb{Q}(\sqrt[3]{2})$?,"Let $K$ be the quadratic closure of $\mathbb{Q}$ , and $K'$ the quadratic closure of $\mathbb{Q}(\sqrt[3]{2})$ . Is there a quadratically closed field $L$ strictly between $K$ and $K'$ , i.e. such that $K \subsetneq L \subsetneq K'$ ? It is a particular case of my previous question , so this is inspired by questions about ruler and compass constructions. If we could find some element $r \in K' \setminus K$ such that $\sqrt[3]{2}$ is of degree $3$ in $\mathbb{Q}(r)$ , then the quadratic closure of $\mathbb{Q}(r)$ would not contain $\sqrt[3]{2}$ , because the quadratic closure only adds elements whose degrees are powers of $2$ , and therefore we could define $L$ as this quadratic closure. The degree of $r$ over $\mathbb{Q}$ , if there is such a $r$ , is a power of $2$ , because we have $$ [\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}] = [\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}(\sqrt[3]{2})] \cdot [\mathbb{Q}(\sqrt[3]{2}) : \mathbb{Q}] = 2^n \cdot 3$$ so $$ [\mathbb{Q}(r) : \mathbb{Q}] = \frac{[\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}]}{[\mathbb{Q}(\sqrt[3]{2},r) : \mathbb{Q}(r)]} = \frac{2^n \cdot 3}{3} = 2^n.$$ We also have the reverse implication: if there is a quadratically closed field $L$ strictly between $K$ and $K'$ , then $\sqrt[3]{2}$ must be of degree $3$ over $L$ , otherwise it would be of degree smaller than $3$ , and there is no element of degree $2$ over $L$ , so it would be contained in $L$ , and for any element $r \in L \setminus K$ , $\sqrt[3]{2}$ would be of degree $3$ over $\mathbb{Q}(r)$ . To sum up, the question reduces to: is there an $r$ which is of degree a power of $2$ over $\mathbb{Q}$ and which is not polyquadratic over $\mathbb{Q}$ , but which is polyquadratic over $\mathbb{Q}(\sqrt[3]{2})$ ? You can find the formulas for the roots of a quartic polynomial here . We see that the solutions are contained in the quadratic closure of $\mathbb{Q}(\sqrt[3]{2})$ if the intermediate parameter $f$ is an integer or if it is equal to $\sqrt[3]{2}$ . So if we could find such an irreducible quartic over $\mathbb{Q}$ and such that its roots are not polyquadratic, we would conclude. But that becomes quite far fetched. Edit: Now cross-posted (not by me) on Mathoverflow .","['field-theory', 'abstract-algebra', 'extension-field']"
4302454,Need help with Pearson criterion (chi-square) to check if the distribution is uniform,"Let's assume we have X - a random variable, and its values are 1, 2, and 3. We also have frequencies for each of the values, which equal to 51, 40, and 65 respectively.
So, this will look like this: X 1 2 3 n 51 40 65 And the question is whether the variable X has uniform distribution. I am to use Pearson criterion to check it.
I actually do know how to solve it, but I have stumbled across one problem: the number of degrees of freedom is equal to zero, hence, I cannot use tables with critical values for chi-squared, since there is no zero degrees of freedom. What do I do? Is it even possible at all to solve this task using this criterion?",['statistics']
4302525,A detailed and self-contained proof of Fubini's theorem for Banach spaces,"After so much preparation (in proving auxiliary lemmas), I finally complete the proof of Fubini's theorem for Banach spaces. This is what I have desired after proving Tonelli's theorem :) The journey to the proof is very enriching. It solidifies my understanding in some aspects. Why are the $\sigma$ -finiteness and completeness of measure important and where do we use them? Why does $E$ need to be complete, i.e. $E$ is a Banach space? Where is Tonelli's theorem used? The relation between $\mathcal L_1$ convergence and a.e. convergence. Why is the quotient space $L_1$ of $\mathcal L_1$ useful? Could you please have a check on my proof? It is detailed and thus easy to read. I would be grateful if any mistake is spotted. Related definitions of Bochner integrals can be found here . Let $(X, \mathcal A, \mu)$ and $(Y, \mathcal B, \nu)$ be complete $\sigma$ -finite measure spaces, and $(E, | \cdot |)$ a Banach space. $\mathcal C :=\mathcal A \otimes \mathcal B$ the product $\sigma$ -algebra of $\mathcal A$ and $\mathcal B$ . $\lambda := \mu \otimes \nu$ the product measure of $\mu$ and $\nu$ . $\mathcal S (X \times Y, \lambda, E)$ the space of $\lambda$ -simple functions from $X \times Y$ to $E$ . $\mathcal  L_0 (Y, \nu, E)$ the space of $\nu$ -measurable functions from $Y$ to $E$ . $\mathcal  L_1 (Y, \nu, E)$ the space of $\nu$ -integrable functions from $Y$ to $E$ . Fubini's theorem: Let $f: X \times Y \to E$ $\lambda$ -integrable. $f_x: Y \to E, \, y \mapsto f(x, y)$ for all $x \in X$ . $f_y: X \to E, \, x \mapsto f(x, y)$ for all $y \in Y$ . Then The map $f_x$ is $\nu$ -integrable for $\mu$ -a.e. $x \in X$ . The map $f_y$ is $\mu$ -integrable for $\nu$ -a.e. $y \in Y$ . The map $\Phi: X \ni x \mapsto \int_Y f_x  \mathrm d \nu$ is $\mu$ -a.e. defined and $\mu$ -integrable. The map $\Psi: Y \ni y \mapsto \int_X f_y \mathrm d \mu$ is $\nu$ -a.e. defined and $\nu$ -integrable. The following identity holds: $$\int_X \Phi \mathrm d \mu = \int_{X \times Y} f \mathrm d \lambda = \int_Y \Psi \mathrm d \nu.$$ My proof: By symmetry, it's enough to prove for the case of $\Phi$ . Lemma 1: Let $(f_n)$ be a Cauchy sequence in $\mathcal S (X \times Y, \lambda, E)$ that converges $\lambda$ -a.e. to $f$ . We define $f_x,f_{n,x}: Y \to E$ by $f_x(y) := f (x, y)$ and $f_{n,x} (y) := f_n (x, y)$ . Then there is a subsequence $\varphi$ of $(0, 1, 2, \ldots, )$ such that for $\mu$ -a.e. $x \in X$ , $(f_{\varphi (n), x})_n$ is a Cauchy sequence in $\mathcal S (Y, \nu, E)$ and converges to $f_x$ both in $\mathcal  L_1 (Y, \nu, E)$ and $\nu$ -a.e. [A proof can be found here ] Lemma 2: Let $(h_n)$ be a sequence in $\mathcal  L_1 (Y, \nu, E)$ that converges to $h$ in $\mathcal  L_1 (Y, \nu, E)$ . Then there exists a subsequence $\varphi$ of $(0, 1, 2, \ldots, )$ such that $(h_{\varphi(n)})$ converges $\nu$ -a.e. to $h$ . [A proof can be found here ] (i) Let $f= 1_G$ where $G \in \mathcal C$ and $\lambda(G) < \infty$ . Notice that $f$ is a characteristic function in $\mathcal S(X \times Y, \lambda, \mathbb R)$ . By Tonelli's theorem, $\Phi$ is measurable and $\int_{X \times Y} f \mathrm d \lambda = \int_X \Phi \mathrm d \mu$ . On the other hand, $\int_{X \times Y} f \mathrm d \lambda = \lambda(G) < \infty$ . Hence $\Phi$ is also integrable and thus Fubini's theorem holds in this case. (ii) Let $f= e1_G$ where $0 \neq e \in E$ , $G \in \mathcal C$ , and $\lambda(G) < \infty$ . Notice that $f$ is the atomic function in $\mathcal S(X \times Y, \lambda, E)$ . Let $1_{G, x} := (1_G)_x$ . Then $\Phi (x) = \int_Y e 1_{G, x} \mathrm d \nu = e \int_Y 1_{G, x} \mathrm d \nu$ . By (i), $x \to \int_Y 1_{G, x} \mathrm d \nu$ is integrable, so is $\Phi:x \to e \int_Y 1_{G, x} \mathrm d \nu$ . Also, \begin{align}
\int_X \Phi \mathrm d \mu &= \int_X \left [ e \int_Y 1_{G, x} \mathrm d \nu \right ] \mathrm d \mu (x)
&&= e \int_X \int_Y 1_{G, x} \mathrm d \nu \mathrm d \mu (x) \\
&\overset{(\star)}{=} e \int_{X \times Y} 1_G \mathrm d \lambda \quad \text{by (i)}
&&= \int_{X \times Y} e1_G \mathrm d \lambda \\
&= \int_{X \times Y} f \mathrm d \lambda.
\end{align} Here $(\star)$ is due to Tonelli's theorem. Hence Fubini's theorem also holds in this case. By linearity of integrals, Fubini's theorem also holds for all simple functions $f \in \mathcal S(X \times Y, \lambda, E)$ . (iii) Let $f \in \mathcal L_1 (X \times Y, \lambda, E)$ . This means $f$ is $\lambda$ -a.e. limit of a Cauchy sequence $(f_n)$ in $\mathcal S (X \times Y, \lambda, E)$ . Let $$f_{n,x} (y) := f_n (x, y) \quad \text{and} \quad\Phi_n (x) := \int_Y f_{n, x} \mathrm d \nu.$$ By (ii), $$\Phi_n \in \mathcal L_1(X, \mu, E) \quad \text{and} \quad \int_X \Phi_n \mathrm d \mu = \int_{X \times Y} f_n \mathrm d \lambda, \quad n \in \mathbb N.$$ By Lemma 1 , there is a subsequence $\varphi$ of $(0, 1, 2, \ldots, )$ such that for $\mu$ -a.e. $x \in X$ , $(f_{\varphi (n), x})_n$ is a Cauchy sequence in $\mathcal S (Y, \nu, E)$ and converges to $f_x$ both in $\mathcal  L_1 (Y, \nu, E)$ and $\nu$ -a.e. It follows that for $\mu$ -a.e. $x \in X$ , $$\int_Y f_{\varphi (n), x} \mathrm d \nu \xrightarrow{n \to \infty} \int_Y f_x\mathrm d \nu.$$ This means $\Phi_{\varphi (n)} \to \Phi$ $\mu$ -a.e. Let's prove that $(\Phi_{\varphi (n)})$ is indeed a Cauchy sequence in $\mathcal L_1(X, \mu, E)$ . In fact, \begin{align}
\| \Phi_{\varphi (n)} - \Phi_{\varphi (m)}\|_1 &= \int_X \left  |\int_Y \big ( f_{\varphi (n), x}- f_{\varphi (m), x} \big ) \mathrm d \nu \right | \mathrm d \mu(x) \\
&\le  \int_X \int_Y \left  | f_{\varphi (n), x} - f_{\varphi (m), x} \right | \mathrm d \nu  \mathrm d \mu(x) \\
&=  \int_{X \times Y} | f_{\varphi (n)} - f_{\varphi (m)} |  \mathrm d \lambda \quad \text{by Tonelli's theorem} \\
&= \| f_{\varphi (n)} - f_{\varphi (m)} \|_1.
\end{align} It follows that there is $\Phi' \in \mathcal L_1(X, \mu, E)$ such that $\Phi_{\varphi (n)} \to \Phi'$ in $\mathcal L_1(X, \mu, E)$ . By Lemma 2 , there is a subsequence $\tau$ of $\varphi$ such that $\Phi_{\tau (n)} \to \Phi'$ $\mu$ -a.e. We have already proved that $\Phi_{\varphi (n)} \to \Phi$ $\mu$ -a.e., so $\Phi = \Phi' \in \mathcal L_1(X, \mu, E)$ $\mu$ -a.e. As such, $$\int_X \Phi_{\varphi (n)} \mathrm d \mu \xrightarrow{n \to \infty} \int_X \Phi \mathrm d \mu.$$ By definition of integrals, $$\int_{X \times Y} f_n \mathrm d \lambda \xrightarrow{n \to \infty} \int_{X \times Y} f \mathrm d \lambda.$$ Recall that $$\int_X \Phi_n \mathrm d \mu = \int_{X \times Y} f_n \mathrm d \lambda, \quad n \in \mathbb N.$$ Hence $$\int_X \Phi \mathrm d \mu = \int_{X \times Y} f \mathrm d \lambda.$$ This completes the proof.","['banach-spaces', 'measure-theory', 'solution-verification', 'functional-analysis', 'fubini-tonelli-theorems']"
4302547,Taylor series of $f(x) = \cos x$ centered at $\frac{\pi}{4}$,"I am asked to find the Taylor Series that represent the function $f(x) = \cos x$ centered at $\frac{\pi}{4}$ . My process Finding the first few derivatives and establishing a pattern. Given that sine and cosine functions go back and forth, there needs to be two formulas (sums) to produce all the terms. The even and odd ones are: $$f^{(2k)}(x) = (-1)^k \cdot \cos(x)$$ $$f^{(2k+1)}(x) = (-1)^{k+1} \cdot \sin(x)$$ Therefore, $$f^{(2k)} \left( \frac{\pi}{4} \right) = (-1)^k \cdot \frac{1}{\sqrt{2}}$$ $$f^{(2k+1)} \left( \frac{\pi}{4} \right) = (-1)^{k+1} \cdot \frac{1}{\sqrt{2}}$$ The sums will be $$\sum_{k = 0}^{\infty} (-1)^k \cdot \frac{1}{\sqrt{2}} \frac{\left( x - \frac{\pi}{4}\right)^k}{k!}$$ $$\sum_{k = 0}^{\infty} (-1)^{k+1} \cdot \frac{1}{\sqrt{2}} \frac{\left( x - \frac{\pi}{4}\right)^k}{k!}$$ Now, my question is the following: how do I combine these? Do I need to look at both and try to establish a pattern, which would lead me to the sum shown on the mark scheme? Or is there some algebraic manipulation that I can do in order to get the answer? Markscheme's answer $$\frac{\sqrt{2}}{2} \sum_{k = 0}^{\infty} \left( -1 \right)^{\frac{k(k+1)}{2}} \cdot \left( x - \frac{\pi}{4}\right)^k \cdot \frac{1}{k!}$$ Thank you. Edit I believe I've found a solution. Interesting to see that, when you combine two sums, the terms show up two by two.","['trigonometry', 'sequences-and-series', 'taylor-expansion', 'real-analysis']"
4302557,$\lim_{x \to a} x^2 = a^2$.,"As per the definition of limits if $\lim_{x \to a} f(x)= L$ , then $$\forall \varepsilon \gt 0 \ \exists \delta \gt 0 \ s.t 0\lt\lvert x-a \rvert \lt \delta \ \implies \ 0\lt \lvert f(x)- L\rvert \lt \varepsilon $$ I want to prove that $\lim_{x \to a} x^2 = a^2$ .
As per the definition $$\lvert f(x)- L\rvert = \lvert x^2- a^2\rvert = \lvert (x-a)(x+a)\rvert =\lvert x-a\rvert \lvert x+a \rvert$$ As per definition $$\lvert x-a \rvert \lt \delta \implies -\delta \lt x-a \lt \delta \implies a-\delta \lt x <a+\delta \implies 2a-\delta \lt x+a <2a+\delta $$ I'm stuck beyond this. I cannot find a suitable $\varepsilon$ to satisfy my condition here.","['limits', 'calculus']"
4302594,Density of bounded continuous functions in $L^1$,"Let $X$ be a metric space, $\mathbb P$ a Borelian probability measure on $X$ and $L^1 = L^1(X,\mathcal B(X) , \mathbb P)$ the associated Lebesgue space. Also let $C_b = C_b(X,\mathbb R)$ be the set of continuous bounded functions from $X$ to $\mathbb R$ . Under what hypothesis on $X$ and $\mathbb P$ the set $C_b$ is dense in $L^1$ ? If $X$ is a topological space that is Hausdorff locally compact and $\mu$ is locally finite regular then I know that $C_c$ the set of continuous functions from $X$ to $\mathbb R$ with compact support is dense in $L^p(X,\mathcal B(X),\mu)$ , $p \in [1,\infty)$ . The counter example I know of $C_c$ not being dense in $L^1$ does not work because of the compacity. Take $X$ infinite dimensional normed vector space, then $C_c = \{ 0 \}$ . Then if we ask in addition $X$ Polish and $\mu$ probability measure we get a counter example. The space $C_b$ being bigger and without any notion of compacity I expect less hypothesis on $X$ and $\mu$ than the one I gave for $C_c$ . To allow $C_b$ to be a subset of $L^1$ we should take finite measure, thus without loss of generality I choosed a probability measure.","['measure-theory', 'lebesgue-integral', 'metric-spaces', 'continuity', 'functional-analysis']"
4302624,"Distributing $10$ indistinguishable cars, $12$ indistinguishable balls, $14$ indistinguishable teddy bears to $3$ children, each have exactly $7$ toys","I have $10$ indistinguishable cars , $12$ indistinguishable balls, $14$ indistinguishable teddy bears.I want to distribute them to $3$ different children in a kindergarten such that each child will take exactly $7$ toys.How many distributions are there? $\mathbf{\text{My attempt:}}$ First of all, I thought that it can be solved by generating functions easily. However, the process became suddenly cumbersome. If each child will take exactly $7$ toys , then we need $21$ toys in total.  For example , $10$ cars, $6$ balls and $5$ teddy bears can be a sample. By using this information, I decided to use generating functions such that if a child take exactly $7$ toys, then his generating function form is $$(x^7+y^7+z^7+x^6y+x^6z+x^5y^2+x^5yz+...+yz^6)$$ where $x,y,z$ represents cars, balls and teddy bears, respectively.  As you count by combination with repetition, there are $\binom{7+3-1}{7}=36$ terms in the tuple. Because of there are $3$ children , we will deal with $$(x^7+y^7+z^7+x^6y+x^6z+x^5y^2+x^5yz+...+yz^6)^3$$ However, there is a problem for me. Calculating the coefficients for each possible selection is very cumbersome. For example, we said that one of the possible toy selections of $21$ of $36$ is $10$ cars, $6$ balls and $5$ teddy bears. In that sample, we should find $$[x^{10}y^6z^5](x^7+y^7+z^7+x^6y+x^6z+x^5y^2+x^5yz+...+yz^6)^3$$ As you realize there are many other toy selections out of $36$ , for example $5$ cars, $8$ balls and $8$ teddy bears is an another sample. I want you guys to handle this cumbersome selection process.  How can I find the all coefficients of this generating function for all possibilities? Please do not suggest using a computer algorithm. I am here to see a mathematical approach I could apply to my problem. What's more, if you have another approach, feel free and share it with me. I am open to another methods.","['combinatorics', 'balls-in-bins', 'discrete-mathematics', 'generating-functions', 'problem-solving']"
4302628,L-stable discretization method with optimal stability region,"I am looking for discretization methods of continuous linear time invariant systems with the properties: It is L-stable (meaning it is A-stable and its stability function approaches zero in the limit) It maps the open left half of the complex s-plane to the interior of the unit circle of the z-plane. Some background: Consider the system $$
\begin{align}
\dot{x}(t) &= f(t,x(t))  \\
 x(0) &= x_0
\end{align}\tag{1}
$$ where $f:R^m\to R^m$ is smooth and $x\in R^m$ . A numerical solution to the initial value problem $(1)$ can be computed by the general (potentially implicit) Runge-Kutta method of order $s$ and step-witdth $h$ : $$
\begin{align}
x_{n+1} &= x_n + h \sum_{i = 1}^s b_i k_{ni} \\
k_{ni} &= f\Big(t_n + c_i h, x_n + h \sum_{j = 1}^s a_{ij}k_{nj}\Big)
\end{align} \tag{2}
$$ The coefficients $a_{ij},b_i,c_i$ in $(2)$ are defined by the Butcher tableau: $$
\begin{array}
{c|c}
c & A  \\
\hline
& b^T
\end{array}=
\begin{array}
{c|cccc}
c_1 & a_{11} & a_{12} & \dots & a_{1s} \\
c_2 & a_{21} & a_{22} & \dots & a_{2s} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
c_s & a_{s1} & a_{s2} & \dots & a_{ss} \\
\hline
& b_1 & b_2 & \dots & b_s
\end{array}
$$ Different methods have different Butcher tableaus. For example: $$
\begin{array}{|c|c|c|}
\hline
\text{Method} & \text{Butcher tableau} \\ \hline
\text{Explicit Euler} & A = 0, b = 1, c = 0 \\ \hline
\text{Implicit Euler} & A = 1, b = 1, c = 1 \\ \hline
\text{Heun} & A = \begin{pmatrix}0&0\\1&0\end{pmatrix}, b = \begin{pmatrix}\frac{1}{2}\\ \frac{1}{2}\end{pmatrix}, c = \begin{pmatrix}0\\ 1\end{pmatrix}  \\ \hline
\text{Runge Kutta 4} & A = \begin{pmatrix}0&0&0&0\\\frac{1}{2}&0&0&0\\ 0&\frac{1}{2}&0&0\\0&0&1&0 \end{pmatrix}, b = \begin{pmatrix}\frac{1}{6}\\\frac{1}{3}\\ \frac{1}{3}\\ \frac{1}{6}\\ \end{pmatrix}, c = \begin{pmatrix}0\\ \frac{1}{2}\\ \frac{1}{2} \\ 1\end{pmatrix} \\ \hline
\text{Trapezoidal} & A = \begin{pmatrix}0&0\\ \frac{1}{2} & \frac{1}{2}\end{pmatrix}, b = \begin{pmatrix}\frac{1}{2}\\ \frac{1}{2}\end{pmatrix}, c = \begin{pmatrix}0\\ 1\end{pmatrix} \\ \hline
\end{array}
$$ Each method has a stability region $S$ which is given by $$
S = \{ z \in \mathbb{C} : |\phi(z)| \leq 1 \} \tag{3}
$$ In Eq. $(3)$ the function $\phi$ is the stability function of the considered method which is constructed from its Butcher tableau: $$
\phi(z) = \frac{\det(I - z A + z \mathbf{1} b^T)}{\det(I - z A)} \tag{4}
$$ Here $I$ is $s \times s$ identity matrix and $\mathbf{1}$ a $s \times 1$ vector of ones. The stability regions (in yellow) for the five methods look like this: Now define A-stability : A method is A-stable if its stability region contains the left half-plane of $\mathbb{C}$ , meaning that $\{ z \in \mathbb{C} : Re(z) \leq 0 \} \subset S$ . Here $Re(z)$ is the real part of $z$ . As can be seen in the plots above, out of the the five example methods, only the implicit Euler and the trapezoidal method are A-stable. Now define L-stability : A method is L-stable if it is A-stable and if $$
\lim_{Re(z) \rightarrow -\infty} |\phi(z)| = 0
$$ Note : A-stability and L-stability are different concepts than asymptotic stability and Lyapunov stability (the naming is a bit unfortunate in my opinion). To come back to my question, I am looking for a method that is L-stable (1. condition) and whose stability region is exactly the left half of the complex plane (2. condition). In other words, I am looking for a L-stable method with stability region $S = \{ z \in \mathbb{C} : Re(z) \leq 0 \}$ . For example the billinear transform (trapezoidal method) satisfies the second condition. However its stability function $\phi$ satisfies $$
\lim_{Re(z) \rightarrow -\infty} |\phi(z)| = \lim_{Re(z) \rightarrow -\infty} \Big|\frac{1 + 0.5 z}{1 - 0.5z}\Big| = 1 \neq 0
$$ So it is not L-stable. On the other hand, the implicit Euler method is L-stable because $$
\lim_{Re(z) \rightarrow -\infty} |\phi(z)| = \lim_{Re(z) \rightarrow -\infty} \Big|\frac{1}{1 - z}\Big| = 0
$$ However it doesn't satisfy the second condition because its stability region is ""larger"" than the left half of the complex plane. Question : Is there a method that has both properties?","['integration', 'ordinary-differential-equations', 'control-theory', 'numerical-methods', 'dynamical-systems']"
4302669,15 Puzzle question - trying to understand the proof,"I have been struggling to understand the proof proposed here to the 15 puzzle question ( exercise 6 ) from the MIT Mathematics for computer science course. The proof argues: If a column move happens, the parity of the number of inversions is flipped (+3 or -3). Also, the parity of the row number of the blank square is flipped (+1 or -1). Given the start state with odd number of inversions and even row number for the blank square, the parity of those two variables will continue to differ after flipping them both to the opposite side. But I have found a column movement that increases the amount of inversions by 2 and not 3. Initial state => 1 inversions
A   B   C   D
E   F   G   H
I   J   K   L
M   O   N   

Second state => 1 + 3 = 4 inversions
A   B   C   D
E   F   G   H
I   J   K   
M   O   N   L

Third state (K moves left, N moves up) => 1 + 3 - 1 + 2 = 5 inversions
A   B   C   D
E   F   G   H
I   J   N   K
M   O       L Can anybody explain why my counter example does not work or whether that proof is incorrect/incomplete? I am sorry for posting a new question, but I am totally new to Stack Exchange and they won't let me comment in the original question until I have 50 reputation.","['alternative-proof', 'proof-explanation', 'discrete-mathematics']"
4302678,Proof Reference For Doob's First Stopping Time Theorem,"I am reading through a proof of Doob's First (Bounded) Stopping Time Theorem, and I am not really following. Can somebody either provide a good reference, or be able to prove it? For a martingale $X$ , and for stopping times $S, T$ , with $S \le T \le c$ , where $c > 0$ is a uniform bound, we have that $\mathbb{E}[X_T | \mathcal{F}_S] = X_S$ .","['martingales', 'probability']"
4302682,"I know that $\exp(\lambda B_{t} -\frac{\lambda^{2}}{2}t)$ is a martingale, how can I use it to prove that the following are martingales","Let $B$ be a standard Brownian motion and further let I know that for $\lambda \in \mathbb R$ , we have that $(\exp(\lambda B_{t} -\frac{\lambda^{2}}{2}t))_{t\geq 0}$ is a martingale, but how can I use it to prove that the following are martingales: $B_{t}^{2}-t,\; \; B_{t}^{3}-3tB_{t}, \; \; B_{t}^{4}-6tB_{t}^2+3t^{2}\; \; (*)$ . By differentiating wrt $\lambda $ and then setting $\lambda = 0$ , we use that for $s < t$ : $\mathbb E [\exp(\lambda B_{t} -\frac{\lambda^{2}}{2}t)\lvert \mathcal{F}_{s}]=\exp(\lambda B_{s} -\frac{\lambda^{2}}{2}s)$ Now differentiating both sides wrt $\lambda$ , and setting $\lambda = 0$ we get: $\mathbb E[B_{t}\lvert \mathcal{F}_{s}]=B_{s}$ [Side question: What can of justification do I need to bring the differentiation operator of $\lambda$ into the conditional expectation?] Ok, so now we have the idea to show that $(B_{t})$ is a martingale, but how can we use it to show that $(*)$ are all martingales?","['martingales', 'brownian-motion', 'probability-theory', 'probability']"
4302812,Contour integral around the unit circle: $∮_{|z|}z^2 e^{-1/z}dz $,"Compute the following contour integral around the unit circle $$∮_{|z|}z^2 e^{-1/z}dz
$$ What I have tried $$
z(t)=cos(t)+isin(t)=e^{it}
$$ then by taking derivative of $z(t)$ we arrive at $$\dot{z(t)}=ie^{it}$$ After substituting these values into the given problem, integration becomes really difficult to solve $$∮_0^{2\pi}e^{2it} e^{-1/{e^{it}}}ie^{it}dt
$$ Could you assist me with this problem?","['integration', 'complex-analysis', 'contour-integration']"
4302877,Percentage and Set theory related question,"So I have come across a question Where it says that among 500 students from a school, 35% play football, 25% play cricket and 20% play neither. So how many students play both the sports? The answer given in the text book is 200 students. But according to my simple logic if 200 students play both football and cricket then how come 175 (35% of 500) play Football in total? I have also used the concept of Venn diagram and came up with the below mention diagram. Plus I am not considering that the 35% football players only play football. And the 25% cricket players only play cricket.","['elementary-set-theory', 'percentages', 'ratio']"
4302991,Surjectivity of induced map on cohomology for projective scheme,"Note: Below, cohomology means Čech cohomology. (Liu, exercise 5.3.13) Let $X,S$ be locally Noetherian schemes, $f:X\to S$ a projective morphism and $\mathcal{F,G}$ quasicoherent sheaves on $X$ with a surjective morphism $\mathcal{F}\to\mathcal{G}$ . Suppose that the fibers of $f$ are of dimension $\leq d$ . I would like to show that $$H^d(X,\mathcal{F})\to H^d(X,\mathcal{G})$$ is surjective, and here's what I've managed to prove so far. First off, let $\mathcal{K}$ be the kernel of the morphism $\mathcal{F}\to\mathcal{G}$ . Then $\mathcal{K}$ is quasicoherent. Proposition 5.2.34 tells us that our assumptions ( $f$ projective, $Y$ locally Noetherian, $\dim X_s\leq d$ ) imply the vanishing of the $p$ :th higher direct images of any quasicoherent sheaf on $X$ for $p\geq d+1$ . In particular, $$R^pf_*\mathcal{K}=0,\ p\geq d+1.$$ In other words, for every open affine $V\subseteq S$ , we have $$(R^pf_*\mathcal{K})(V)=H^p(f^{-1}(V),\mathcal{K}|_{f^{-1}(V)})=0,\ p\geq d+1\tag{$\star$}.$$ Now, from the short exact sequence $$0\to \mathcal{K} \to \mathcal{F} \to \mathcal{G} \to 0$$ and quasicoherence of $\mathcal{G}$ , we obtain a long exact sequence in cohomology containing the following piece: $$H^d(X,\mathcal{F})\to H^d(X,\mathcal{G})\to H^{d+1}(X,\mathcal{K})$$ The surjectivity of the first arrow is equivalent to the vanishing of the last group, but is it possible to conclude that from $(\star)$ ? If $[k]\in H^{d+1}(X,\mathcal{K})$ , so $k=(k_\alpha)\in C^{d+1}(\mathcal{U},\mathcal{K})$ for some cover $\mathcal{U}$ , I don't see how I can find a refinement of $\mathcal{U}$ for which $(\star)$ would be applicable. Edit: It seems like the exercise is false as stated. Let $X=S=\mathbb{P}^1_k$ , $\mathcal{F}=\mathcal{O}_X$ and $\mathcal{G}=k(x) \oplus k(y)$ the direct sum of scyscraper sheafs supported at $x\neq y$ . There is a natural surjective morphism of sheaves $\mathcal{F}\to\mathcal{G}$ . Now, if $f:X\to X$ is the identity morphism (which is projective) then every fiber has dimension $0$ and the claim would imply that we have a surjection $$k=H^0(X,\mathcal{O}_X)\to H^0(X, k(x) \oplus k(y))=k(x) \oplus k(y),$$ which is impossible.","['algebraic-geometry', 'sheaf-cohomology']"
4303019,"Show that $\lim_{(x,y) \to (0,0)} {\frac{x\sin y - y\sin x}{x^2 +y^2}}$ does not exist","Show that $\lim_{(x,y) \to (0,0)} {\frac{x\sin y - y\sin x}{x^2 +y^2}}$ does not exist I did use Wolfram Alpha and it says this limit does not exist. I'm trying to prove this with sequential definition of multivariable function. So basically, I have to find two sequences $(u_k)$ and $(v_k)$ such that they approach $(0,0)$ but the two sequences $f(u_k)$ and $f(v_k)$ approach two different limits. I tried various things but nothing works out. Could you give me some hint about this problem? Thank you in advance!",['multivariable-calculus']
4303062,Let $G$ be a group and $H$ a subgroup of $G$. Show that $aH=Ha$ if and only if $aha^{-1} \in H$ for every $h \in H$.,"Let $G$ be a group and $H$ a subgroup of $G$ . Show that $aH=Ha$ if and only if $aha^{-1} \in H$ for every $h \in H$ . Suppose that $aH= Ha$ . Then for $h' \in aH$ we have that $h'=ah$ for some $h \in H$ . Right multiplying by $a^{-1}$ we have that $h'a^{-1}=aha^{-1}$ . As $aH= Ha$ we have that $h'=ah=ha$ so $h'a^{-1} = \underbrace{haa^{-1}}_{h} = aha^{-1} \implies aha^{-1} \in H$ . Conversely suppose that $aha^{-1} \in H$ . The claim is that $aH=Ha$ so we will do both inclusions. Let $h' \in aH$ . Then $h'=ah$ for some $h \in H$ . Now right multiplying by $a^{-1}$ we have that $h'a^{-1}=aha^{-1} \in H$ . So multiplying again from right I have that $h'a^{-1}a=aha^{-1}a \implies h'=ah \in Ha$ . For the other direction let $h'' \in Ha$ . Then $h''=ha$ for some $h \in H$ . Right multiplying by $a^{-1}$ then left multiplying by $a$ and again right multiplying by $a^{-1}$ I get that $ah''a^{-1}a^{-1} = aha^{-1} \in H$ . Now left multiplying by $a$ I have that $aah''a^{-1}a^{-1} = aaha^{-1} \in aH$ Is it necessarily true that $aah''a^{-1}a^{-1} = h''$ and that $aaha^{-1} = ah$ ? This would seem to conclude the result, but I'm not sure if it's allowed. Also is should I do these kind of ""multiplying"" here? It seems that I am going in circles multiplying everywhere.","['group-theory', 'abstract-algebra', 'solution-verification']"
4303148,High dimensional generalizations of $\int_{\sqrt{2} }^{\sqrt{3} } \frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } dy =\frac{5\pi^2}{96}$,"Let $Q=n_1+n_2+n_3+1$ , $\mathbf{s}=(n_1,n_2,n_3)$ .
Define $$
A(\mathbf{s})
=\int_{D}\prod_{n=1}^{Q-1}\frac{1}{1+x_n^2}\int_{1}^{\infty}\left(Q+\sum_{n=1}^{Q-1}x_n^2 +y^2\right)^{-1}\mathrm{d}y
\text{d}x_i.
$$ Where $D=[0,\infty]^{n_1}\times[0,1]^{n_2}
\times[1,\infty]^{n_3}\subset\mathbb{R}^{Q-1}$ , $\mathrm{d}x_i
=\prod_{n=1}^{Q-1} \text{d}x_n$ . Special case. For $\mathbf{s}=(0,0,n_3)$ , we have $$
A(\mathbf{s})
=\frac{1}{Q}\left ( \frac{\pi}{4}  \right )^Q.
$$ Question 1 Prove $$
\pi^{-Q}A(\mathbf{s})\in\mathbb{Q}.
$$ My ultimate goal is to evaluate $A(\mathbf{s})$ . Numerical calculations suggest that $$A(1,0,0)=\frac{\pi^2}{12} \quad A(0,1,0)=\frac{5\pi^2}{96}\quad A(0,0,1)=\frac{\pi^2}{32}$$ $$A(2,0,0)=\frac{\pi^3}{32} \quad A(1,1,0)=\frac{\pi^3}{80}$$ $$A(0,3,0)=\frac{93\pi^4}{35840} \qquad A(0,4,0)=\frac{193\pi^5}{322560}$$ Actually, if we explicit calculate the multiple integrals, it yields $$
\begin{aligned}
&\int_{\sqrt{2} }^{\sqrt{3} } 
\frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } \text{d}y
=\frac{5\pi^2}{96},\\
&\frac{\pi}{6} \int_{\sqrt{3} }^{\sqrt{5} } 
\frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } \text{d}y
-\int_{2}^{\sqrt{5} } 
\frac{\displaystyle{\arctan (y)\arctan \sqrt{\frac{y^2-4}{y^2-2} } } }{(y^2-1)\sqrt{y^2-2} }
\text{d}y=\frac{11\pi^3}{5760},\\
&\frac{\pi}{6} \int_{\sqrt{3} }^{\sqrt{5} } 
\frac{\arctan\left(y\sqrt{2+y^2} \right)}{(y^2-1)\sqrt{y^2-2} } \text{d}y
-\int_{2}^{\sqrt{5} } 
\frac{\displaystyle{\arctan\left(y\sqrt{2+y^2}\right)\arctan \sqrt{\frac{y^2-4}{y^2-2} } } }{(y^2-1)\sqrt{y^2-2} }
\text{d}y=\frac{\pi^3}{420}.
\end{aligned}
$$ Are there any other simple results? For $Q=4$ , we may meet some 'troubles', such as this one: $$
\int_{0}^{1} \int_{1}^{\sqrt{2} } 
\frac{u\left(\pi-2\arctan\sqrt{u^4-1}-2\arctan \sqrt{\frac{u^2-1}{u^2+1} }
\right) \arctan \sqrt{4+u^2+v^2}  }
{(1+v^2)\sqrt{1+u^2}(2+u^2) \sqrt{4+u^2+v^2}  } \text{d}u\text{d}v.
$$ I can hardly convert into a 'simple' form. Question 2. Can we evaluate a more general family of this kind of integrals? $$A(\alpha,\mathbf{s})
=\int_{D}\prod_{n=1}^{Q-1}\frac{1}{\alpha^2+x_n^2}\int_{1}^{\infty}\left(\alpha^2 Q+\sum_{n=1}^{Q-1}x_n^2 +y^2\right)^{-1}\mathrm{d}y
\text{d}x_i.$$","['integration', 'improper-integrals', 'definite-integrals', 'real-analysis', 'multiple-integral']"
4303199,Law of Iterated Expectation for RVs with Stieltjes Integral.,"I want to show that the law of iterated expectations $E[E[X|Y]] = E[X]$ holds for RVs that are not discretely or continuously distributed. In specific in our class we have defined the expectation of X in terms of the Riemann-Stieltjes integral: $E[X] =  \int_{\mathbb{R}} x d F_X$ What I got so far: E[E[X|Y]] = $\int_{\mathbb{R}} \int_{\mathbb{R}} x dF_{X|Y} dF_Y$ In the discrete and continuous case we use the definition of the conditional expectation $P(X|Y) P(Y) = P(X\cap Y)$ . My idea was to use the above definition to to define a product measure $F_{X|Y} F_Y = F_{X,Y} = F_{Y|X} F_X$ and apply Fubini's Theorem twice. \begin{align}
\int_{\mathbb{R}} \int_{\mathbb{R}} x dF_{X|Y} dF_Y &= \int_{\mathbb{R}^2} x dF_{X,Y} = \int_{\mathbb{R}} \int_{\mathbb{R}} x dF_{Y|X} dF_X\\
 &= \int_{\mathbb{R}} x  dF_X \int_{\mathbb{R}} 1 dF_{Y|X} = \int_{\mathbb{R}} x  dF_X = E[X]
\end{align} Using the fact that any probability measure integrates to one. Is this a valid application of Fubini's Theorem? I know that we use the Riemann-Stieltjes Integral to integrate over function with non-continuous CDFs. Can I generally think about the measure $dF(t)$ being equivalent to $dP(X\leq t)$ ? Any help or suggestions for introductory readings is appreciated.","['measure-theory', 'stieltjes-integral', 'conditional-expectation', 'expected-value', 'probability']"
4303216,What is the Cayley graph for alternating group A6?,"According to ATLAS of Group Representations , the alternating group $A_6$ is a group of order 360 which has presentation $$
\langle a,b \mid a^2 = b^4 = (ab)^5 = (ab^2)^5 = 1 \rangle.
$$ If we draw its Cayley graph using these two generators, the 4-order element $b$ will induce regular quadrilaterals in the graph. Further if we shrink each quadrilaterals to a vertex, it is not hard to see from the relations that the resulting graph consists of regular pentagons with 6 meeting at each vertex. I've found the graph very similar to 120-cell . However they are different because this graph is expected to have 90 = 360/4 vertices while the 120-cell has 600 ones. So my questions are: Does this graph have a name? Is there any picture on the internet that visualizes it? Edit: it should be 6, instead of 4, pentagons meeting at a vertex","['visualization', 'geometry', 'group-theory', 'cayley-graphs', 'terminology']"
4303227,Convexifying a Concave Polygon by Reflections,"Let $P$ be a given concave polygon and consider the following procedure. Take the convex hull $Q$ of $P$ and consider a side $AB$ of $Q$ which is not a side of $P$ . Then, let $P'$ be the polygon obtained by $P$ by replacing the polygonal path of $P$ from $A$ to $B$ which has no vertex in common with those of $Q$ other than $A$ and $B$ with its image in the reflection with respect to $AB$ . If $P'$ is a convex polygon, then the procedure stops, otherwise replace $P$ by $P'$ and repeat the process. Does this procedure end after finitely many steps, for every initial concave polygon $P$ and every (or at least some) possible choice of the sides with respect to which to take the reflections? My intuition, shaped by the many concrete examples which I have carefully examined, strongly suggests that the answer is positive, but when I haved tried to sketch a proof, I got completely stuck. $\mathbf{Remark}$ . Just note that the polygons $P$ and $P'$ have the same perimeter, while $P'$ has a larger area than $P$ . Actually, this procedure was described by David in his answer to the post Proving that the regular n-gon maximizes area for fixed perimeter , in which the isoperimetric problem for n-gons is discussed. Even though the eventual finiteness of the procedure is irrelevant to the solution there given, I think this issue has its own interest.","['euclidean-geometry', 'convex-hulls', 'convex-geometry', 'geometry', 'convex-analysis']"
4303237,Prove that $2017$ is a divisor of $2016!(x-\frac{x^2}{2}+\frac{x^3}{3}-....-\frac{x^{2016}}{2016})$.,"Let $x$ be an integer such that $2017$ is a divisor of $x^2+x+1$ . Prove that $2017$ is a divisor of $2016!(x-\frac{x^2}{2}+\frac{x^3}{3}-....-\frac{x^{2016}}{2016})$ . We define ""segment congruence"" : $\frac{a}{b}\equiv  \frac{c}{d} (\mod 2017)$ if and only if $ad \equiv bc (\mod 2017)$ So to prove that $2017$ is a divisor of $2016!(x-\frac{x^2}{2}+\frac{x^3}{3}-....-\frac{x^{2016}}{2016})$ , we only need to prove $(x-\frac{x^2}{2}+\frac{x^3}{3}-....-\frac{x^{2016}}{2016}) \equiv 0 ( \mod 2017)$ $2017$ is a divisor of $x^2+x+1 \Rightarrow x^3 \equiv 1 \mod 2017$ $\Rightarrow -\frac{x^2}{2} + \frac{x^5}{5} -...+ \frac{x^{2015}}{2015} \equiv x^2 (-\frac{1}{2} +\frac{1}{5}-...+\frac{1}{2015} )\mod 2017$ $x-\frac{x^4}{4}+\frac{x^7}{7}-\frac{x^{10}}{10}+....-\frac{x^{2014}}{2014} \equiv x( 1 -\frac{1}{4} + \frac{1}{7}-\frac{1}{10}+...-\frac{1}{2014}) \mod 2017$ $\frac{x^3}{3}- \frac{x^6}{6} -....-\frac{x^{2016}}{2016} \equiv \frac{1}{3}-\frac{1}{6} +\frac{1}{9}-...-\frac{1}{2016} \mod 2017$ We have $( 1 -\frac{1}{4} + \frac{1}{7}-\frac{1}{10}+...-\frac{1}{2014})-(\frac{1}{3}-\frac{1}{6} +\frac{1}{9}-...-\frac{1}{2016}) = (\frac{1}{1}+\frac{1}{2016} -\frac{1}{4}-\frac{1}{2013}-...-\frac{1}{2014}-\frac{1}{3}) \equiv 2017 \frac{c}{d} \equiv 0 \mod 2017$ $\Rightarrow ( 1 -\frac{1}{4} + \frac{1}{7}-\frac{1}{10}+...-\frac{1}{2014}) \equiv (\frac{1}{3}-\frac{1}{6} +\frac{1}{9}-...-\frac{1}{2016}) \mod 2017 $ So to prove $(x-\frac{x^2}{2}+\frac{x^3}{3}-....-\frac{x^{2016}}{2016}) \equiv 0 ( \mod 2017)$ , we only need to prove $-\frac{1}{2} +\frac{1}{5}-...+\frac{1}{2015} \equiv  1 -\frac{1}{4} + \frac{1}{7}-\frac{1}{10}+...-\frac{1}{2014} \equiv \frac{1}{3}-\frac{1}{6} +\frac{1}{9}-...-\frac{1}{2016} \mod 2017 $ But I don't have any idea yet, hope to get your help. Thank you very much !","['number-theory', 'algebra-precalculus', 'elementary-number-theory', 'prime-numbers']"
4303238,Set of points A that are differentiable using the complex function $f(z) = |z|^{2}+e^{-5z}$,"I have to check if this function is differentiable one of the following conditions: $ A=\{(0,0)\} $ or $ A=\{\text{z } \in \text{ C: }|z|=1 \} $ . To the first condition, I have verified it's differentiable using Cauchy-Riemann theorem to $f(z) = x^{2} + y^{2} + e^{-5x}(\cos(5y)-i*\sin(5y))$ , following: $\qquad \frac{\partial u}{\partial x}= 2x - 5 e^{-5x}\cos(5y) \qquad \frac{\partial v}{\partial y}= - 5 e^{-5x}\cos(5y)$ $\qquad \frac{\partial u}{\partial y}= 2y - 5 e^{-5x}\sin(5y) \qquad -\frac{\partial v}{\partial x}= - 5 e^{-5x}\sin(5y)$ Throught this I can conclude that $x=0$ and $y=0$ satisfy the theorem. However, to the second condition, I supposed that $x^{2}$ and $y^{2}$ are any constants that respect $|z|^{2} = 1$ . Thus, I have analyzed the Cauchy-Riemann to $f(z) = 1+e^{-5z}$ and it also respected the differentiability to $f(z) = 1 + e^{-5x}(\cos(5y)-i*\sin(5y))$ : $\qquad \frac{\partial u}{\partial x}= - 5 e^{-5x}\cos(5y) \qquad \frac{\partial v}{\partial y}= - 5 e^{-5x}\cos(5y)$ $\qquad \frac{\partial u}{\partial y}= - 5 e^{-5x}\sin(5y) \qquad -\frac{\partial v}{\partial x}= - 5 e^{-5x}\sin(5y)$ It looks like is not correct to me that this second conditions is differentiable because by the first condition we confirmed that it's only differentiable at $\{0,0\}$ . However, I can't understand why my assumption to the second condition is wrong and how I can show that is not differentiable at $|z|$ equal to any constant. I appreciate very much any help since I couldn't find errors or explanations myself.","['complex-analysis', 'multivariable-calculus']"
4303326,Generating Function of Riordan numbers,"I would like to find generating function of $f(n)$ , where $f(n)$ is defined as following: $$f(n)=\sum_k^n \binom{n}{k}(-1)^{n-k}C_k\text{.}$$ With $C_k=\frac{1}{k+1}\binom{2k}{k}$ ( $C_k$ is the $k^{th}$ Catalan's number).","['generating-functions', 'combinatorics', 'discrete-mathematics', 'sequences-and-series']"
4303348,No simple group of order $2025$,"There is no simple group of order $2025$ . If $G$ is simple then by the Sylow theorem, there must be $81$ Sylow $5$ -subgroups and $25$ Sylow $3$ -subgroups. Also, I can see that if Sylow $5$ subgroups intersect only on the identity element then $1944$ elements have order $5$ or $25,$ from here, Sylow $3$ subgroup must be unique hence normal and the assumption that $G$ is simple must be false. But I couldn't find a contradiction for distinct Sylow $5$ -subgroups $P$ and $Q$ where $|P \cap Q|=5. $ My question is: How can I prove the rest of this argument? And could we solve the same problem if we work on Sylow 3-subgroups using the same argument?","['simple-groups', 'group-theory', 'sylow-theory']"
4303371,"Algebraic, Projective, and Riemannian Geometry: How do they interact?","The aim of this question is to understand the interaction between projective algebraic varieties (over the complex or real numbers), Riemannian manifolds, and projective space, through shared concepts - that is, to understand which concepts can be defined intrinsically in more than one of these structures, and whether these concepts agree when a space admits more than one of these structures. I'll start with motivation: In the usual Euclidean geometry of the plane, one has the concept of straight lines. It is well known that these arise from the Riemannian structure of the Euclidean plane as geodesics - that is, if one looks at the Euclidean plane only as a Riemannian manifold (without the vector space structure, etc.) one can still recover the straight lines as locally distance-minimizing curves. Interestingly, however, one can also forget the metrical\Riemannian structure and look at the projective plane, and somehow still talk about straight lines - straight lines still make sense in projective geometry, even though there is no metric structure and thus no geodesics. Projective varieties are in some sense a generalization of projective geometry to spaces that are not necessarily 'linear'. In projective varieties, is there a concept generalizing straight lines or geodesics? Another generalization of projective geometry to curved spaces is manifolds with projective connections ; in these spaces, there is indeed an appropriate notion of geodesics. So, do smooth projective varieties (at least over the real numbers) have a natural projective connection that somehow agrees with the variety structure? If there was such a natural connection, this would provide a natural extensions of the concept of straight lines to projective varieties. The two questions that I'd like to ask are: Which concepts from projective geometry and from Riemannian geometry have natural analogs in the intrinsic geometry of projective varieties? Is there a relationship between the structure of a (smooth) projective variety and the structure of a manifold with a projective connection? Are there spaces which have both of these structures and they somehow agree with each other? Some concepts I already know that generalize from projective geometry to general algebraic varieties are dimension, the automorphism group of the variety (which for projective space is the projective general linear group), subvarieties, polynomial functions, and for one-dimensional varieties, the cross-ratio (this has a generalization to any Riemann surface). As raised above, what about straight lines? Do these have a generalization to projective surfaces/varieties? What about the degree of an embedded subvariety (for projective space this is defined using straight lines/hypersurfaces)? And are there Riemannian concepts which have natural analogs on algebraic varieties, such as curvature? connection? geodesics? holonomy? This question is rather broad, but I'll appreciate any partial answers, perspectives on this, or even references or names that can point me to relevant material.","['geodesic', 'projective-geometry', 'projective-varieties', 'algebraic-geometry', 'differential-geometry']"
4303450,"Hartshorne's Caution 6.5.2: $\mathcal{Ext}^*(-,\mathcal{G})$ as a derived functor in the first variable","In his Algebraic Geometry Robin Hartshorne shows in Proposition III.6.5 that if the category of $\mathcal{O}_X$ -modules of a scheme $X$ has enough locally frees, then a locally free resolution may be used to compute the $\mathcal{Ext}^* (-,\mathcal{G})$ functors. However, in Caution III.6.5.2 he then writes: The results (6.4) and (6.5) do not imply that $\mathcal{Ext}$ can be construed as a derived functor in its first variable. In fact, we cannot even define the right derived functors of $\text{Hom}$ or $\mathcal{Hom}$ in the first variable because the category $\mathfrak{Mod}(X)$ does not have enough projectives. But I thought that what Hartshorne proves is exactly that the class of locally free sheaves is adapted to the $\mathcal{Hom}(-,\mathcal{G})$ functor for any $\mathcal{O}_X$ -module $\mathcal{G}$ , and hence its right derived functor exists and may be computed using a locally free resolution. Am I missing something, or is this just a consequence of Hartshorne only defining derived functors in the situation of enough projectives/injectives?","['algebraic-geometry', 'derived-functors', 'sheaf-theory']"
4303460,Equivalence of Definitions of Hirsch and Wall of Strong $C^r$-topologies,"I've been reading about strong (and weak) $C^r$ -topologies on the space of $C^r$ -maps between $C^s$ -manifolds $M$ and $N$ ( $s \ge r$ ) from the textbooks of Hirsch and Wall (both called Differential Topology), and I noticed that they use different definitions for the strong and weak $C^r$ -topology. Hirsch's definition: take a $C^r$ -function $f: M \to N$ , locally finite set of charts $\Phi = \{(U_i, \varphi_i)\}_i$ on $M$ , a set of charts $\Psi = \{(V_i,\psi_i)\}_i$ on $N$ , a family of compact sets $K = \{K_i\}_i$ with $K_i \subseteq U_i$ , and a family of positive real numbers $\varepsilon = \{\varepsilon_i\}_i.$ Then a basic neighborhood of Hirsch's strong topology is \begin{multline}
\mathcal{N}^r(f; \Phi, \Psi, K, \varepsilon) = \{g \in C^r(M,N) \textrm{ }| \textrm{ } (\forall i) \textrm{ }g(K_i) \subset V_i, \textrm{ } (\forall i, x \in \varphi_i(K_i), k = 0,\dots,r) \textrm{ } \\
||D^k(\psi_i f \varphi_i^{-1})(x) - D^k(\psi_i g \varphi_i^{-1}(x)|| < \varepsilon_i\}.
\end{multline} Wall's definition: Wall's definition is simpler - for an open set $W \subseteq M \times J^r(M,N)$ , a basis set is given by $$B(W) := \{f \in C^r(M,N) \textrm{ } | \textrm{ } \Gamma(j^rf) \subseteq W\}.$$ $\Gamma$ denotes the graph of a function. It is the minimal topology such that the injective map $j^r: C^r(M,N) \to C^0_F(M, J^r(M,N))$ is a topological embedding, where $C^0_F(M,J^r(M,N))$ denotes the fine topology . In general, given topological spaces $X$ and $Y$ , the fine topology is the one generated by the basis $B(W) = \{f \in C(X,Y) \textrm{ } | \textrm{ } \Gamma(f) \subseteq W\}$ , where $W \subset X \times Y$ is an open set. QUESTION: How would one prove that these two definitions are equivalent, i.e. generate the same topology? I was able to prove equivalence for their definitions of weak topology, as well as one direction for the strong one - namely, that Hirsch's topology is no finer than Wall's. However, I'm having a hard time with the other direction - it just seems too complicated to construct all of the necessary data - the $\Phi$ , $\Psi$ , $K$ and $\varepsilon$ ... I provide what I've done below. Hirsch $\subseteq$ Wall: By Lemma A.4.1 of Wall's book, if $X,Y$ are metric spaces, then the sets $$I(\{K_\alpha, U_\alpha\}) = \{f \in C(X,Y) \textrm{ } | \textrm{ } (\forall \alpha) \textrm{ } f(K_\alpha) \subseteq U_\alpha\},$$ where $K_\alpha$ are compact and $U_\alpha$ open, and $\{K_\alpha\}$ is a locally finite collection, form a subbase for the fine topology on $C^0(X,Y).$ Now if I'm given a set $\mathcal{N}^r(f; \Phi, \Psi, K, \varepsilon)$ , then it's equal to $(j^r)^{-1}(I(\{K_i,W_i\})$ where $W_i \subseteq J^r(U_i,V_i)$ is the inverse image by the jet chart of the set \begin{multline}
W_i' := \{(\varphi_i(x),\psi_i g (x), D(\psi_i g \varphi_i^{-1})(x),\dots,D^r(\psi_i g \varphi_i^{-1})(x)) | x \in U_i, \forall k = 0, \dots, r : ||D^k(\psi_i g \varphi_i^{-1})(x) - D^k(\psi_i f \varphi_i^{-1})(x)|| < \varepsilon_i\}
\end{multline} and therefore it's open in ""Wall's strong topology."" As for the other direction , I look at some $f \in (j^r)^{-1}(I(\{K_\alpha, W_\alpha\}_{\alpha \in A}))$ - for every individual pair $(K_\alpha, W_\alpha)$ , I can find a set $\mathcal{N}^r(f; \Phi_\alpha, \Psi_\alpha, K'_\alpha, \varepsilon_\alpha)$ where the collections $\Phi_\alpha, \Psi_\alpha, K'_\alpha, \varepsilon_\alpha$ are finite such that $$f \in \mathcal{N}^r(f; \Phi_\alpha, \Psi_\alpha, K'_\alpha, \varepsilon_\alpha) \subseteq (j^r)^{-1}(I(\{K_\alpha,W_\alpha\})).$$ Therefore, a possible solution would be to take the intersection for all $\alpha \in A$ to get $$\mathcal{N}^r(f; \cup_{\alpha \in A} \Phi_\alpha, \cup_{\alpha \in A} \Psi_\alpha, \cup_{\alpha \in A} K'_\alpha, \cup_{\alpha \in A} \varepsilon_\alpha).$$ However, I don't know if $\cup_{\alpha \in A} U_\alpha$ will be locally finite . Of course, I can take a locally finite refinement, but I don't know what I'd do with the other data - $\Psi$ , $K'$ , $\epsilon$ . PS: I am willing to provide more details in an edit or in private - also, it's possible that most of what I wrote is useless, so feel free to write a solution that doesn't rely on my ramblings. However, I'd like it to be as self-contained as possible, because many general-topological facts in Hirsch and Wall go unproven.","['general-topology', 'differential-topology']"
4303464,"Find all positive integers $x,y,z$ for which the expression is true.","So I wish to find all the positive integers $x,y,z$ such that the following expression is true. $$\frac{-1 + x + y + x y}{-1 - x - y + x y} = z$$ The problem is that the expression does not simplify any further as far as I can tell. The only constraint that I can think of is the denominator has to be greater than zero and so we get that $y > \frac{x+1}{x-1}$ . We can also write the left-hand side as: $$\frac{(x+1)(y+1)-2}{(x-1)(y-1)-2} = z$$ But I still can't see the algorithm that would let me find the integer solutions. Any ideas? PS. Wolfram can easily find the solutions but I wish to know how it approaches the problem.","['elementary-number-theory', 'algebra-precalculus', 'factoring', 'diophantine-equations']"
4303488,Countability of the set of distinct sequences that all consist of the same elements,"Let us consider an infinite binary sequence $s$ (i.e., an infinite sequence of 0s and 1s). Let us then consider set $S(s)$ , which consists of all the different sequences that can be obtained by swapping the positions of the elements of $s$ . For example, if $s_1 = (1, 0, 0, 0, 0, 0,  \dots)$ , then $S(s_1) = \{ (1, 0, 0, 0, 0, 0, \dots), (0, 1, 0, 0, 0, 0, \dots), (0, 0, 1, 0, 0, 0, \dots), \dots \}$ . Clearly, in my example case, $S(s_1)$ is a countably infinite set. However, I'm interested in whether such an infinite binary sequence $s$ exists that $S(s)$ is an uncountable set. My intuition says that the set of all infinite binary sequences can be expressed as a countable union of sets $S(s_1), S(s_2), S(s_3), \dots$ for some sequences $s_1, s_2, s_3 \dots$ , which would mean that $S(s_i)$ must indeed be an uncountable set for some $s_i$ , since the set of all infinite binary sequences is uncountable. However, I cannot figure out any $s$ such that $S(s)$ would be an uncountable set.","['elementary-set-theory', 'binary', 'combinatorics', 'sequences-and-series']"
4303490,Looking for a way to compute the discrete version of a continuous random distribution,"I just learn the way to compute the cumulative probability distribution (CDF) of a distribution in terms of some known results. For example, a random variable $Y$ is written in terms of a uniform random variable $U(0,1)$ as $$
  Y \sim \frac{5}{U + 1}
$$ the CDF of $Y$ could be found in the following way $$
  \begin{align*}
  \text{CDF}(y) & = F(y) = \mathbb{P}(Y\leq y) = \mathbb{P}\left(\frac{5}{U+1}\leq y\right)\\
  & = \mathbb{P}\left(U\geq \frac{5}{y}-1\right) = 1- \mathbb{P}(U<\frac{5}{y}-1)\\
  & = 2 - \frac{5}{y}
  \end{align*}
$$ so the probability distribution function (PDF) for $Y$ will be $$
  P(y) = \dfrac{dF(y)}{dy} = \frac{5}{y^2}
$$ Compute the expectation value for $y$ $$
  \text{E}[y] = \int y\frac{5}{y^2}dy = 3.46574
$$ In the text, it is said that the uniform distribution is continuous so I apply the integral to compute the expectation. I read something online about discrete distribution. If I change the random variable as $$
  Y \sim \left\lfloor \frac{5}{U+1} \right\rfloor
$$ how do we derive the PDF and CDF for the discrete version of $Y$ ? I am trying a simulation to run 1M random numbers for u as follows: s = 0
  for i=1 to 1000000
    s += floor(5/(rand(0, 1) + 1)
  end
  print s/1000000 this gives me an average of 2.9172 instead of 3.46574 I think the difference is originated from a great number of states that are suppressed by the floor operation. I wonder if there is any analytical way instead of a simulation to compute the result. I try to replace y in PDF with the floor(5/(u+1)) and replace the integral with a summation $$
  \sum \left\lfloor\frac{5}{y+1}\right\rfloor \times \frac{5}{\left\lfloor\frac{5}{y+1}\right\rfloor^2} = \sum \frac{5}{\left\lfloor\frac{5}{y+1}\right\rfloor}
$$ but this gives me 1.8418, very far from 2.9172.","['probability-distributions', 'discrete-mathematics']"
4303528,ten-digit codes combinatorics,"How many ten-digit codes can be made in which each digit occurs exactly once, but in which the following patterns do not occur: (a) 123 (e.g., 1203987654 may, but 9876501234 may not) (b) 123 and 98765 (e.g. 3210567489 is allowed, but the two examples given earlier are not. may not). (c) 123, 98765, and 04 (e.g., you may use 8412765930, but all of the previously given examples may not). I have: (a) 10! -8! (b) 10! -8! -6! +4! (c) 10! - (8! +6! +9! -4! -7! -5! +3!) Can someone please confirm these solutions/explain why a solution is incorrect?","['permutations', 'combinatorics', 'discrete-mathematics']"
4303577,what actually is a manifold?,"I am struggling with the term manifold. It's the first time, I am studying this. I have tried some sites and videos on youtube but I didn't really get the idea. Roughly speaking, Manifold is something that looks flat when we zoom it a lot or that is locally flat. It seems very easy but I am still confused. Why actually do we need to define the manifolds while every shape can be seen as flat except the corners part? Is there any easy way to understand the concept of the manifold? Or in any case, how to check practically if any space is manifold or not. here is a problem that I found somewhere. For $\lambda \in \mathbb R$ Let $M_{\lambda}=\{ (x,y,x)\in\mathbb R^3 : x^2+y^2-z^2=\lambda\}$ . Determine the paremters $\lambda$ for which $M_{\lambda}$ is a sub-manifold of $\mathbb R^3$ . for $\lambda = 0$ , we get something like the cone shape, and I feel like there is a problem at the origin because no matter how much we zoom at the origin, it will not homeomorphic to a flat thing. So Is that true $M_{\lambda}$ is not a manifold for $ \lambda = 0$ ? How to find all such $\lambda$ ? (Is it possibly Only by looking at the shapes in $\mathbb R^3$ or there is some other way. Like some particular mathematical conditions that the set does not satisfy) I am sorry if it seems a very easy question for you guys. Looking forward to hearing from you people.
Many Thanks.","['manifolds', 'submanifold', 'differential-geometry']"
4303639,Find the 0.95 quantile such that $P(Y \le \phi_{.95})=0.95$,"Suppose I have the density function $f(y) = 6y(1-y), 0 \le y \le 1$ , find the 0.95 quantile such that $P(Y \le \phi_{.95})=0.95.$ What I have tried: $$6\int_0^{\phi_{.95}}y(1-y)dy=6\left[\frac{y^2}{2}-\frac{y^3}{3} \right]_0^{\phi_{.95}}=0.95$$ $$\implies6\left[\frac{(\phi_{.95})^2}{2}-\frac{(\phi_{.95})^3}{3} \right]=0.95$$ Now I'm not sure on how to proceed from here, the booklet answer shows $\phi_{0.95} = 0.865$ , I had thought that I would have to re-arrange the integral result to find for $\phi$ though I cannot seem to isolate it. Using the Newton approximation method as suggested $$f(x_0)=f(x_0)-\frac{f(x_0)}{f'(x_0)}$$ When picking $f(x_0) = 0.95$ After I re-arranged the equation above into a cubic I get $$\implies f(x_0) = 0.95-\frac{2(0.95)^3-3(0.95)^2+0.95}{6(0.95)^3-6(0.95)^2}\approx 0.8$$ $$\implies f(x_1) = 0.8-\frac{2(0.8)^3-3(0.8)^2+0.95}{6(0.8)^3-6(0.8)^2}\approx 0.865$$","['integration', 'statistics']"
4303673,Difference of two stopping times,"Let $(X_{n})_{n \geq 0}$ be a sequence of random variables and $\tau,t$ stopping times with respect to the sequence $(X_{n})_{n \geq 0}$ $$\begin{align*}\{\tau+t =n\} = \{\tau+t = n\} \cap \{t \leq n\} &= \bigcup_{k=0}^n \{\tau+t = n\} \cap \{t = k\} \\ &= \bigcup_{k=0}^n \{\tau=n-k\} \cap \{t=k\}. \end{align*}$$ As $\{\tau =n-k\} \in \mathcal{F}_{n-k} \subseteq \mathcal{F}_n$ and $\{t = k\} \in \mathcal{F}_k \subseteq \mathcal{F}_n$ for any $k \leq n$ , this implies that $\{\tau+t=n\} \in \mathcal{F}_n$ , and so $\tau+t$ is a stopping time. Now, my question is , let assume that I am considering $\tau-t$ . I know that in general, $\tau-t$ is not a stopping time. However, if I were to consider my birthday this year (a stopping time), which is a deterministic stopping time. At any time, I know exactly when my birthday occurs. Also, I know two days before my birthday i.e, $\tau-2$ . What kind of a formulated counterexample will show that $\tau-2$ is indeed a stopping time in this setting.","['measure-theory', 'stopping-times', 'probability-theory', 'stochastic-calculus']"
4303685,Hypergraph variant of handshake problem.,"I came across this well known problem that goes something like this. If $n$ people shake hands with each other. How many handshakes will be there in total? The question can be interpreted as asking about the number of edges in a complete graph of with $n$ vertices, which will be $n \choose 2 $ . What if the question was changed to something more tricky? If $n$ people take turns playing board games with each other. Each game needs exactly $k$ players to play. How many games are needed for everyone to have played a game with everyone else? As you can see, for the case of $k=2$ this would be equivalent to the previous handshake problem. I initially thought the answer would be $ n \choose k$ , but in the case of $n = 6$ and $ k= 4$ , I can make everyone play everyone with just 3 games. If the players are labeled $[1 .. n]$ $$ \text{Game 1: } {1,2,3,4} \\\text{Game 2: } {3,4,5,6} \\\text{Game 3: } {1,2,5,6} $$ Since $ {6 \choose 4} \neq 3 $ , this cannot be the answer. The binomial is counting all possible games even when getting everyone to play each is possible with less games. I suspect that considering the games as hyperedges of k-uniform hypergraph is the best way to approach this problem, but I lack any formal math training beyond high-school math, so I don't know where to start. I've tried doing some googling (which is how I know what a hypergraph is), but I've haven't gotten anywhere.","['elementary-set-theory', 'graph-theory', 'combinatorics', 'hypergraphs']"
4303705,Why is the spectrum of a commutative ring only concerned with fields?,"Let $R$ be a commutative ring.
The (prime) spectrum of $R$ can be constructed as $$
  \operatorname{Spec}(R)
  =
  \left\{
    (k, φ)
  \;\middle|\;
    \begin{array}{l}
      \text{$k$ is a field,} \\
      \text{$φ \colon R \to k$ is a homomorphism of rings}
    \end{array}
  \middle\}
  \right/
  {\sim}
$$ where $\sim$ is the equivalence relation generated by $(k, φ) \sim (k', ι ∘ φ)$ whenever $ι \colon k \to k'$ is a field extension.
(This construction of the spectrum is equivalent to the usual one via prime ideals by assigning to the equivalence class of $(k, φ)$ the kernel of $φ$ .)
In other words, the spectrum of $R$ classifies the different ways in which the ring $R$ maps into fields.
I think this can also be understood as a kind of “geometrification” of the functor $$
  \operatorname{Hom}(R, -)
  \colon
  \mathbf{Field} \to \mathbf{Set} \,.
$$ I’ve been wondering why the spectrum is constructed in such a way that it is only concerned with fields instead of arbitrary commutative rings. Indeed, it seems more natural to me to try to “geometrify” the functor $$
  \operatorname{Hom}(R, -)
  \colon
  \mathbf{CRing} \to \mathbf{Set} \,,
$$ instead since this functor contains all information about the ring $R$ by Yoneda’s lemma. I suspect that it makes no difference if the ring $R$ is reduced since then any two distinct elements of $R$ can be distinguished by a homomorphism into a suitable field. So I guess that my question has something to do with the role of nilpotents.","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
4303736,"$F: B(0,1)\to R$ is differentiable, $|F|\leq 1$. show $\exists\ \xi\in B(0,1)$, $|\nabla F(\xi)|\leq 2$","$F: B(0,1)\to R$ is differentiable, $|F|\leq 1$ . show $\exists\ \xi\in B(0,1)$ , $|\nabla F(\xi)|\leq 2$ . Here $B(0,1)$ is the unit ball in $\Bbb R^d$ . If I just use Lagrange intermediate value theorem on two points of the boundary, I could just deduce some $\xi$ exists, such that one directional deriative has absolute value $\leq 1$ ...What idea for the problem?",['multivariable-calculus']
4303750,"Why is there no UMVUE for $\mu$ with two samples from $N(\mu, \sigma^2)$, $N(\mu, \tau^2)$?","Question: I have an attempted answer below; I don't think it's quite correct. I also have another sketch of a proof at the bottom. My attempt: (d) The family of independent samples $X_1, \dots, X_m$ from $N(\mu, \sigma^2)$ and $Y_1, \dots, Y_n$ from $N(\mu, \tau^2)$ have distributions having densities of the form \begin{align*}
f_{X_1, \dots, X_m, Y_1, \dots, Y_n}(x_1, \dots, x_m, y_1, \dots, y_n; \mu, \sigma^2, \tau^2) =\\
\frac{1}{(\sqrt{2\pi})^m (\sqrt{2\pi})^n}\exp\Bigg[\frac{\mu}{\sigma^2}\sum_{i = 1}^m x_i - \frac{1}{2\sigma^2}\sum_{i = 1}^m x_i^2 - m\frac{\mu^2}{2\sigma^2} - m\log \sigma\\
+ \frac{\mu}{\tau^2}\sum_{i = 1}^n y_i - \frac{1}{2\tau^2}\sum_{i = 1}^n y_i^2 - n\frac{\mu^2}{2\tau^2} - n\log \tau\Bigg].
\end{align*} According to the theory of exponential families, this is a four-dimensional exponential family. We have parameter space $\Theta = \mathbb R \times (0, \infty) \times (0, \infty)$ . Let $\theta = (\mu, \sigma^2, \tau^2) \in \Theta$ . Define the function \begin{align*}
\eta'' \colon \Theta &\to \mathbb R^4 \text{ by}\\
\theta &\mapsto \Big(\frac{\mu}{\sigma^2}, -\frac{1}{2\sigma^2}, \frac{\mu}{\tau^2}, -\frac{1}{2\tau^2}\Big).
\end{align*} We can write \begin{align*}
\eta''(\theta) &=
\begin{pmatrix}
\frac{1}{\sigma^2} & 0 & 0\\ \\
0 & -\frac{1}{2\sigma^4} & 0\\ \\
0 & 0 &\frac{\mu}{\tau^4} \\ \\
0 & 0 & -\frac{1}{2\tau^4}
\end{pmatrix}
\begin{pmatrix}
\mu\\ \\
\sigma^2\\ \\
\tau^2
\end{pmatrix}\\ \\
&=
\begin{pmatrix}
\frac{\mu}{\sigma^2}\\ \\
-\frac{1}{2\sigma^2}\\ \\
\frac{\mu}{\tau^2}\\ \\
-\frac{1}{2\tau^2}
\end{pmatrix}.
\end{align*} If I can argue that three vectors (the column vectors in the matrix) can't have an image in $\mathbb R^4$ containing an open ball, then I am done, right? This would prove that the conditions for Lehmann-Scheffé can't be satisified. (e) The exponential family isn't full rank, so Lehmann-Scheffé doesn't apply. Another outline of a proof: Can anybody develop the argument below into a full proof? I don't get it. Why $\bar X - \bar Y$ ?","['statistics', 'normal-distribution']"
4303765,Is the set of all underdetermined matrices A that solve Ax = b (for a given x and b) dense?,"Let's say I have two fixed vectors $x \in \mathbb{R}^{n}$ and $b \in \mathbb{R}^{m}$ , where $m < n$ . There are an infinite number of matrices $A \in \mathbb{R}^{m \times n}$ that can solve this underdetermined system. My question is: are these solutions dense over the set of all matrices in $\mathbb{R}^{m \times n}$ ? Please be gentle, I am not very mathematical.","['matrices', 'general-topology', 'linear-algebra']"
4303824,Is this a basis for the bounded operators on $ L^2(\mathbb{R}) $?,"Let $ L^2=L^2(\mathbb{R}) $ . For every pair $ a,b $ of real numbers define the operator $ U_{a,b} $ on $ L^2 $ sending $ \psi \in L^2 $ to $ U_{a,b}\psi $ defined by the equation $$
[U_{a,b}\psi](x)=e^{ibx}\psi(x+a)
$$ Consider the set of operators $$
\mathcal{B}:=\{ U_{a,b}:a,b \in \mathbb{R} \}
$$ Is $ \mathcal{B} $ a basis for the space of bounded operators on $ L^2 $ ? They seem linearly independent and it also seems like the span should be a subalgebra at least.
But is the closure of the span of $ \mathcal{B} $ all of the bounded operators on $ L^2 $ ?","['operator-algebras', 'operator-theory', 'representation-theory', 'hilbert-spaces', 'functional-analysis']"
4303894,Proof for a nice conjecture related to circles,"I have made a conjecture but am unable to prove it. If $P$ and $Q$ are any points such that they are both at an equal given distance from a given point $C$ , subtending a fixed angle at another given point $O$ (wherein $ OC<PC=QC $ ). Then the maximum and minimum distance $PQ$ occurs when $P$ and $Q$ lie on equally inclined rays to the line perpendicular to $OC$ through $O$ . Clearly, the minimum case would be in the smaller segment and maximum in the larger segment. Also note  that if $P$ and $Q$ subtend an angle $2x$ at $O$ , then each of the rays will be inclined at $90°-x$ to the line perpendicular to $OC$ .","['trigonometry', 'circles', 'geometry']"
4303924,Find all $c\in \mathbb{R}$ such that $f^{-1}(c)$ is a submanifold(Solution verification),"Consider the following problem from my course notes on manifolds: Question:Define $f: \mathbb{R}^2 \to \mathbb{R}$ by $f(x,y)= x^3 -6xy+y^2$ . Find all values $c\in \mathbb{R}$ such that $f^{-1}(c)\in M$ is an embedded submanifold of $\mathbb{R}^2$ . So, $f$ is an onto map (just take $y=0$ , $x^3 $ is onto) and $f^{-1}(c) = $ { $(x,y): f(x,y)=c$ }. $\mathbb{R}^3$ is a manifold and there always exists a chart $(U,\phi)$ , $\phi$ is homeo. So, I think that using onto property of $f$ I think for all $c\in \mathbb{R}$ , $f^{-1}(c)$ is a submanifold as $\phi( U \cap f^{-1} (c)) $ will always be in $\mathbb{R}^3$ and hence satisfying definition of submanifold. Am I right?","['smooth-manifolds', 'analysis', 'manifolds', 'differential-topology', 'differential-geometry']"
4304026,Linear Taylor expansion of Dieterici equation,"once again I am dealing with the Dieterici equation. As I am conducting a peer review with my fellow students, it would really be nice to know the exact result of the question. It is asked to find the linear Taylor expansion of following expression, assuming a<<RT: I just assumed it would be correct to Taylor-expand the exponential function at the origin point, that means using the MacLaurin expansion of e^z: My result is the equation at the bottom. But I am unsure if this is correct. My thoughts were: Linear Taylor expansion would mean terminating the sequence after the first n which is not zero. Furthermore, I thought that expanding the e-function is the way to go. But I am unsure where a<<RT would play into this to be honest (maybe it is the reason why we could expand in the first place). Any tips and/or advice or real solutions would really be appreciated, thanks!","['multivariable-calculus', 'taylor-expansion']"
4304029,About the Fibonacci's numbers identity ${n \choose k}_F = F_{n-k+1}{n-1 \choose k-1}_F+F_{k-1} {n-1 \choose k}_F$,"I am trying to prove, in a combinatorial way, this identity for fibonomial coefficients, when $0\lt k \lt n $ : $${n \choose k}_F = F_{n-k+1}{n-1 \choose k-1}_F+F_{k-1} {n-1 \choose k}_F$$ where $F_n$ is defined by $F_n=F_{n-1}+F_{n-2}$ , $\,\,\,F_0=0, \,\,\,\,F_1 =1$ and $${n \choose k}_F = \frac{n!_F}{k!_F(n-k)!_F}, \,\,\,\,\,\,\,\,\,\,n!_F=F_1F_2\dots F_n$$ It's well known that the $F_n$ counts the number of coverings of a board $(n-1)\times1$ with squares and dominoes and I have already proved that $F_n = F_{n-k+1}F_{k-2}+F_{k-1}F_{n-k}$ by considering when the $(k-1)$ th slot of the board is covered either with one or the other kind of tile. It's clear that the fibotorial $n!_F$ enumerates the number of tilings, with squares and dominoes, of a upper-triangular board $(n-1)\times(n-1)$ and, it has been quite harder, but I showed that the fibonomial is an integer number by ""cutting away"" the number of coverings of a $(k-1)\times(k-1)$ upper triangular board from $n!_F$ . Now I want to conclude  that ${n-1 \choose k-1}_F = F_{k-2}$ and ${n-1 \choose k}_F =F_{n-k}$ by assembling the two results, I can do that algebraically, but how to see it in a combinatorial way?","['fibonacci-numbers', 'binomial-coefficients', 'combinatorics', 'combinatorial-proofs']"
4304082,A combinatorics problem with applications for optimizing Huffman Compression Algorithms,"I am currently working on a Huffman data compression algorithm and struck a problem when trying to optimize space-efficiency by changing the set of symbols the algorithm uses. I will give more context, but if you only care about the mathematical problem itself, skip this next section. Context I found that given a file and a complete set of symbols, it seems that making an algorithm that takes the set of symbols and the file and spits out what the exact compressed file size would be when pushed through the Huffman Compression algorithm cannot be done without actually putting the file through the Huffman Compression algorithm itself or by just giving a rough estimation that is closer to a guess than anything else. This would not be a problem if for a complete sets of symbols, running the program did not take hours for a 100Mb file. The problem comes down to that to have a time-efficient algorithm, you cannot guarantee be sure that it is very space-efficient. However, it is certain that the most space-efficient algorithm will be very time-inefficient relative to the time-efficient algorithm. One solution to this trade-off is to make this algorithm pick a complete set of symbols such that it produces the most space-efficient algorithm for a file its size on average . Since this calculation of probability is relatively short, this gives a relatively time-efficient algorithm that produces a more optimized Huffman compression on average. I have found a way to describe this calculation step in a mathematical way, but I am struggling with finding its solution. Here is the problem: Let S be a set of y unique symbols. Let b be a random sequence of symbols from S that is x symbols long such that x $\ge$ y. (symbols can repeat in b) Finally, let T be the set of unique symbols used in b. Given x and y, what is the probability that the number of elements in T is less than some z $\in \mathbb{Z}$ , y $\ge$ z $\ge$ 2. Simple Example It could be that S has 3 unique symbols and b is 3 characters long. For argument sake, lets say that S = {A, B, C}. If we were to ask what is the probability that the number of unique symbols used in b is 1 then either b = AAA, BBB, or CCC. Of course, there are 27 different 3-symbol long words we can made with S. Therefore, the probability that b consists of only 1 symbol from S is $\frac{1}{9}$ . In this case, z = 2 Final Remarks I have tried more complicated examples, but the difficulty of the combinatorics logic seems to grow very complicated very quick. Is there a general solution to this problem given x, y, z?","['combinatorics', 'combinatorial-proofs', 'probability']"
4304157,Existence of Abelian group extension relative to group homomorphism,"Let $f: A \to B\ $ be an Abelian group homomorphism. Are there Abelian groups $G,\ H,\  K$ such that $K \subseteq H \subseteq G$ and the map $$\pi \circ i: H \to G/K$$ which is the composition of projection and inclusion is isomorphic to $f$ ? By isomorphic to $f\ $ I mean there exist isomorphisms $\tau: H \to A\ $ and $\sigma: G/K \to B$ such that $f = \sigma \circ \pi \circ i \circ \tau^{-1}$ . I think it is a quite natural question, since the case where $f$ is epimorphism is a consequence of the fundamental homomorphism theorem. However, I can't prove the existence nor the uniqueness of the group extension. I'm not familiar at all with the general theory of group extension, but maybe the case where $A,\ B\ $ are Abelian could be easier. If such an extension really exists, it would be much more intuitive when dealing with chain complexes and exact sequences, imaging there is a ""huge"" group such that elements of all other groups are just its cosets. The question has been answered in MO ( link ).","['group-homomorphism', 'group-extensions', 'abstract-algebra', 'group-theory', 'abelian-groups']"
4304160,How to prove the existence of such a map and such a function,"This question was in my manifolds notes which I borrowed from a senior and I was unable to  prove the result. Let S be an k-dimensional submanifold of an n-manifold M with k<n. Show that , for every point $p\in S$ , there exists an open set $U\subset M$ containing p, and a smooth function $f: U \to \mathbb{R}^{n-k}$ such that $f^{-1}(0) =U \cap S$ . For every $p\in S$ there will always exists an open set $U \in M$ containing p but I have to find a specific U that also satisfies the condition on the smooth function. A subset S of M is called a k-dimensional submanifold of M if the following holds: If $p\in S$ there exists a chart $(U,\phi)$ containing P st $\phi(U\cap S)$ is an open subset of $\mathbb{R}^k$ . But How to use it to find such a function. I am really sorry but I am unable any way to prove it. I couldn't add much to my attempt and thoughts because I am struck. Kindly don't close this question. Please shed some light on this!","['submanifold', 'analysis', 'smooth-manifolds']"
4304162,Tarski's elementary Euclidean geometry,"It is a well-known theorem of Tarski that (what is now called) Tarski's elementary Euclidean geometry is a decidable theory. This is a first-order theory, as opposed to Hilbert's second-order axiomatization of Euclidean geometry. My (somewhat vague) question is whether Tarski's axiomatization encompasses (i.e., proves) ""most"" geometry statements of interest, at least, say, at the college level geometry courses, so that one could arguably state that ""Tarski's result mechanizes questions in Euclidean geometry"" in such a context. In other words, I would like to have a better idea of the scope of ""elementary geometry"" within general Euclidean geometry. I would also be happy if you could give me examples (or categories) of geometric statements that lie outside of the scope of Tarski's axiomatization (i.e., they essentially need something like Hilbert's second-order system).","['euclidean-geometry', 'axiomatic-geometry', 'geometry', 'axioms']"
4304187,Is this function nowhere differentiable?,"I was looking at the following function, $$\displaystyle f(x) := \sum_{n=0}^\infty {\sin(2^nx) \over 2^n}.$$ It is pretty obvious that $f$ is continous everywhere in $\mathbb{R}$ . But I can't figure out where it is differentiable. Differentiating term by term would lead me to believe it is differentiable nowhere but I'm not sure if I can do that.","['derivatives', 'sequences-and-series', 'real-analysis']"
4304244,Upper and lower bound on the N-th Pythagorean triplet,"Let $H_n$ be the hypotenuse of the $n$ -th primitive Pythagorean Triplet when arranged in ascending order of the length of the hypotenuse. What is known about the asymptotic expansion of or bounds on $H_n$ ? My experimental data suggests that $$
2\pi n - 4n^{\frac{1}{3}} - 4 < H_n < 2\pi n + 4n^{\frac{1}{3}} + 4
$$ There are no violations of this inequality for $n \le 1.4 \times 10^8$ .","['number-theory', 'pythagorean-triples', 'asymptotics', 'analytic-number-theory', 'inequality']"
4304254,Is each graph a subdivision of itself? On proving reflexivity of the topological minor relation.,"Diestel writes in his Graph Theory book (Proposition 1.7.1) that The minor relation and the topological-minor relation are partial orderings on the class of finite graphs, i.e. they are reflexive, antisymmetric and transitive I proved the three properties for the minor relation but am confused when it comes to the topological-minor relation and proving that it is reflexive. Diestel does not really define if a graph $G$ is counted as a subdividing itself, i.e. having an empty set of subdividing vertices and reading the definition on Proof Wiki sounds like one has to at least subdivide one edge resulting in a non-isomorphic graph $G'$ such that $G'$ is the smallest subdivision of $G$ . However, to prove reflexivity, i.e. $G$ being a topological minor of $G$ , $G$ must be in the set of subdividing graphs $TX$ . This is due to the fact that the topolocical minor relation is defined as follows: $X$ is a topological minor of $Y$ if there exists a subdivision of X, which is a subgraph of $Y$ . Therefore, if $G\notin TX$ because $G'$ is the smallest subdivision of $G$ . Then, no graph in $TX$ can be a subgraph of $G$ and hence, $G$ can't be its own topological minor. Am I misunderstanding how to prove the reflexivity of a topological minor or something in its definition? PS: This post asked a similar but different question.","['graph-theory', 'graph-minors', 'combinatorics', 'discrete-mathematics']"
4304329,Find maximum of $\sin{x}+\sin{y}-\sin{(x+y)}+\sqrt{3}\left(\cos{x}+\cos{y}+\cos{(x+y)}\right)$,"The trick is that we can't use derivatives. If we look at $\cos{x}+\cos{y}+\cos{(x+y)}$ , the function cos attains its maximum of $1$ at $0$ radians, so $x=y=0$ and $x+y=0$ and the maximum of $\cos{x}+\cos{y}+\cos{(x+y)}=1+1+1=3$ . What about part of the function with $\sin$ ? If we use the same logic: $\sin$ attains its maximum of $1$ at $\pi/2$ radians, so $x=y=\pi/2$ , so $x+y=\pi$ , we get the maximum of $\sin{x}+\sin{y}-\sin{(x+y)}=1+1-0=2$ , but I guess it's not true, cause Wolfram says the maximum is $0$ . Any hint would help a lot!! thank you!","['maxima-minima', 'trigonometry', 'extreme-value-analysis']"
4304353,"Is there always a positive $x$ that satisfies $\cos(n_1x)\leq0$, $\cos(n_2x)\leq0$, $\cos(n_3x)\leq0$ for given distinct positive integers $n_i$?","Prove or disprove: Given distinct $n_1$ , $n_2$ , $n_3$ $\in \mathbb{N}$ , \begin{cases} \cos(n_1x)\leq0 \\ \cos(n_2x)\leq0 \\ \cos(n_3x)\leq0\end{cases} has a
positive solution. My first attempt was by writing each cosine in terms of $\cos(x)$ , then by setting $\cos(x) = t$ , it's solved like a normal system of inequalities. This didn't work for me because writing each $\cos(n_jx)$ in terms of $\cos(x)$ gets harder as the $n_j$ increases, and I'm also unable to find a pattern behind their conversion, this doesn't let me find a generalized proof. Second attempt was by using parametric functions: $\\ \sin{(\alpha)}=\frac{2t}{1+t^2}\ \ \ \mbox{where }\ t=\tan{\left(\frac{\alpha}{2}\right)}\mbox{ and }\alpha\neq\pi+2k\pi$ $\\ \cos{(\alpha)}=\frac{1-t^2}{1+t^2}\ \ \ \mbox{where }\ t=\tan{\left(\frac{\alpha}{2}\right)}\mbox{ and }\alpha\neq\pi+2k\pi$ $\\ \tan{(\alpha)}=\frac{2t}{1-t^2}\ \ \ \mbox{where }\ t=\tan\left(\frac{\alpha}{2}\right)\mbox{ and }\alpha\neq\frac{\pi}{2}+k\pi\ \wedge\ \alpha\neq\pi+2k\pi$ Same problem as the first attempt, I'm unable to generalize their conversion in terms of a fixed $α$ , so can't again find a generalized proof. A third attempt was using proof by contradiction: We suppose no such $x$ exists. Then, for every positive $x,$ at least one of the three cosines is always positive. ... Can't get past this point.","['algebra-precalculus', 'trigonometry', 'inequality']"
4304402,"Why is Vakil's definition of ""distinguished affine base"" of a scheme not a base in the usual sense?","From Vakil's Foundations of Algebraic Geometry : The open sets of the distinguished affine base are the affine open subsets of $X$ . We have already observed that this forms a base. But forget that fact. We like distinguished open sets $\operatorname{Spec} A_f \hookrightarrow \operatorname{Spec} A$ , and we don’t really understand open embeddings of one random affine open subset in another. So we just remember the ""nice"" inclusions. 13.3.1.Definition. The distinguished affine base of a scheme $X$ is the data of the affine open sets and the distinguished inclusions. Vakil writes that this a ""not a base in the usual sense."" Is this not a base in the usual sense? If $X$ is a topological space, a collection of open subsets $\mathcal B$ forms a base if every open subset of $X$ is a union of elements of $\mathcal B$ . Let $U$ be an open subset of a scheme $X$ . Let $p \in U$ . Then $p$ is in some affine open subset of $X$ , say $\operatorname{Spec} A$ . Then $p \in U \cap \operatorname{Spec} A$ , which is open in $\operatorname{Spec} A$ , hence $p \in \operatorname{Spec} A_f$ for some $f \in A$ . $\operatorname{Spec} A_f$ is an open subset of an open subset, hence open in $X$ . So, $p  \in \operatorname{Spec} A_f \subset U$ .","['general-topology', 'algebraic-geometry', 'definition', 'schemes']"
4304434,"Can a non-zero smooth $f: [a,b] \rightarrow \mathbb{R}_{\geq 0}$ have infinitely many zeroes? [duplicate]","This question already has answers here : Infinitely differentiable function with given zero set? (3 answers) Closed 2 years ago . Given a non-negative, smooth function $f: [a,b] \rightarrow \mathbb{R}_{\geq 0}$ . If there exists a sequence (of pairwise disjoint points) $x_n \in [a,b]$ such that $f(x_n)=0$ for all $n  \in \mathbb{N}$ , does it mean that $f(x)=0$ for all $x \in [a,b]$ ? Motivation: Consider smooth curves in polar coordinates that is a map $c: [0,2\pi) \rightarrow \mathbb{R}^2 , t \mapsto r(t) \cdot (\cos(t),\sin(t))$ . If we restrict this curve to a compact intervall, is it regular (i.e. $r'(t)^2 +r^2(t) \neq 0$ for all $t \in [0,2\pi)$ ) up to finitely many points or finitely many closed intervalls? This would follow, if the above conclusion holds. Thoughts: By compactness we can find (by abuse of notation) a subsequence $x_n \rightarrow x \in [a,b]$ such that $f(x)=0$ . From the taylor expansion we see that all derivatives in $x$ must vanish, that is $f^{(n)}(x)=0$ for all $n \in \mathbb{N}$ . Remarks: Smooth function on a closed intervall means there is an extension to an open intervall containing it.","['smooth-functions', 'real-analysis']"
4304436,"$(A_K^*f)(x) = \int_0^1 K^*(x,y) f(y)\, dy$ for all $f\in L^2[0,1]$ - Fubini's theorem?","Let $K$ be a square-integrable kernel on $[0,1] \times [0,1]$ , i.e. $$\int_0^1 \int_0^1 |K(x,y)|^2\, dx\, dy < \infty$$ and let $A_K$ be the integral operator induced by it on $L^2[0,1]$ , i.e. $$(A_K f)(x) = \int_0^1 K(x,y) f(y)\, dy$$ for all $f\in L^2[0,1]$ . Define $K^*(x,y) = \overline{K(y,x)}$ . Show that the adjoint operator $A_K^*$ is the integral operator induced by the kernel $K^*$ . Hint: Fubini's theorem. My thoughts: In mathy language, we want to prove that $$(A_K^*f)(x) = \int_0^1 K^*(x,y) f(y)\, dy = \int_0^1 \overline{K(y,x)} f(y)\, dy$$ By definition of the adjoint, we have $\langle A_K f,g\rangle = \langle f, A_K^*g\rangle$ for all $f,g\in L^2[0,1]$ . The usual inner product on $L^2[0,1]$ is defined by $\langle f,g\rangle = \int_0^1 f(x) \overline {g(x)}\, dx$ for all $f,g\in L^2[0,1]$ . Thus, we have $$\langle A_K^* g, f \rangle = \int _0^1 g(x) \overline{\int_0^1 K(x,y) f(y)\, dy}\, dx = \int_0^1 \int_0^1 g(x) \overline{K(x,y)} \overline{f(y)}\, dy \, dx$$ Swapping $x$ and $y$ in the last (definite) integral, i.e. via a change of variables, we have $$\int_0^1 \int_0^1 g(x) \overline{K(x,y)} \overline{f(y)}\, dy \, dx = \int_0^1 \int_0^1 g(y) K^*(x,y) \overline{f(x)}\, dx \, dy$$ Also, $$\langle A_K^* g, f \rangle = \int_0^1 (A_K^*g)(x) \overline{f(x)}\, dx$$ Certainly, the constant function equal to $1$ on $[0,1]$ is in $L^2[0,1]$ , so putting $f = 1$ we get $$\int_0^1 (A_K^*g)(x) \, dx = \int_0^1 \int_0^1 g(y) K^*(x,y)\, dx \, dy$$ for all $g\in L^2[0,1]$ . Thanks!","['operator-theory', 'analysis', 'hilbert-spaces', 'functional-analysis', 'fubini-tonelli-theorems']"
4304485,Can covariance be negative?,"So I always thought that covariance could take any real number. However, in class today my professor gave us a problem where we were supposed to find the covariance, $q$ $$0 = q^2 - 2q - 3 = (q - 3)(q + 1)$$ $$q = 3 \text{ or } q = -1$$ He then said that we should reject the negative case since covariance always needs to be non-negative. In this case, the covariance is a scalar. I know that the covariance matrix needs to be positive, semi-definite and that the elements along the diagonal of that matrix needs to be non-negative(since they're variances). So, since we have a scalar covariance does that mean it necessarily needs to be non-negative? Looking online, people mention that a negative covariance means that a greater value in one variable leads to lesser values in the other, so I'm guessing that covariance is allowed to be negative even in the scalar case?","['covariance', 'variance', 'probability-theory', 'probability']"
4304511,"If a curve $\alpha$ is contained in a submanifold $P$ of $M$, $\alpha'(t)\in T_{\alpha(t)}P$?","Let $P\subset M$ be a smooth regular submanifold of $M$ , and $\alpha:(0,1)\to M$ be a smooth curve such that $\alpha(a,b)\subset P$ . I want to see whether or not $\alpha'(t)\in T_{\alpha(t)}P$ for any $t\in(0,1)$ (as well as for $P$ a  submanifold that doesn't have to be regular). In my notes, I have that, taking $p\in P$ , $T_pP$ is identified with the image in $T_pM$ through $(di)_p:T_pP\to T_pM$ , where $i:P\hookrightarrow M$ is the inclusion. Proposition 3.9 from Lee's Smooth Manifolds tells us that $(di)_p$ is an isomorphism. But I don't really understand this characterization of $T_pP$ well, or if I can do anything at all in this problem. I know that, taking $\left\{\left(\frac{\partial}{\partial x_i}\right)_p\right\}_{i=1}^n$ a base of $T_pM$ associated to the chart $(U,\varphi = (x_1,\ldots,x_n))$ , one can represent the velocity of the curve as \begin{equation}
\alpha'(t_0) = \sum_{i=1}^n(x_i\circ\alpha)'(t_0)\left(\frac{\partial}{\partial x_i}\right)_p.
\end{equation} But I don't know how to represent $T_pP$ out of the information above. And I don't see if anything would change between $P$ being regular or not. Could anyone please help me out?","['curves', 'submanifold', 'smooth-manifolds', 'differential-geometry']"
4304595,Can we prove a trinomial distribution approaches a Gaussian,"Consider a random walk with trinomial distribution where $i^{th}$ step is a random variable $X_i$ takes values $-\frac{1}{i}, 0, \frac{1}{i}$ with probability $0.3, 0.4, 0.3$ respectively. (A simpler problem may deal with $X_i$ taking values $-1, 0, +1$ with probability $\frac{1}{3}$ each). My intuition is that probability distribution for $S_n = \sum_{i \le n} X_i$ is likely a Gaussian. I started by following the template of proof for how the binomial distribution tends to a Gaussian for large n but am having trouble even at the first step when writing equation for $\mathbb{P}(S_n = m)$ . Any ideas for how to prove or disprove of this? Thanks!","['random-walk', 'probability-theory', 'binomial-distribution', 'gaussian', 'multinomial-distribution']"
4304624,"Prove there are at least $100!$ ways to write $100!$ as a summation of numbers in $\{1!,2!,...,99!\}$. (each number can be used multiple times.)","Prove there are at least $100!$ ways to write $100!$ as a summation of numbers in $\{1!,2!,...,99!\}$ . (each number can be used multiple times.) I have no idea how to solve this question. First, I thought of using mathematical induction and seeing the reason for $2!$ and then trying to find out a pattern for the rest, but it did not work. For $3!$ in set $\{1!,2!\}$ I can do the addition like: $1+1++1+1+1$ $1+1+1+1+2$ $1+1+2+2$ $2+2+2$ and so it failed for this one too and I could not use induction.
If someone could help me with this I would really appreciate it.","['number-theory', 'induction', 'combinatorics']"
4304682,Help me prove or disprove $v^T(A+vv^T)^{-1}v=1$ for singular A,"Given arbitrary singular square matrix $A$ deficient in rank by $1$ , and vector $v$ , in numerical experiments with numerous values of the variables, I always get $v^T(A+vv^T)^{-1}v=1$ .  Why does $A$ cancel out like this?  (And when not, aside from obvious zero situations?) EDIT: My $A$ matrices have been symmetric positive semidefinite (so far).  And the relation keeps holding when many or all elements of $v$ are tiny.  (It takes around 6 orders of magnitude smaller than the A elements to break down).","['matrices', 'linear-algebra']"
4304724,Ball drawn with replacement - with a twist. Is there an elegant solution I may be missing?,"Here's the question : Suppose there's a bag filled with balls numbered one through fifty.  You reach in and grab three at random, put them to the side, and then replace the ones you took so that the bag is once again filled with fifty distinctly numbered balls.  Do this five times, so you have 5 groups of 3 numbered balls such that within each group every number is distinct from the other, but across groups, the numbers may not necessarily be distinct. What is the probability that you have some three-of-a-kind in your five groups?  That is to say, what is the probability that some number appears at least three times among the selected balls? Now I'm not very good at probability, but I'm pretty sure I know how I would brute-force calculate the probability of this situation, but it would take a ridiculously long time.  Does anyone know a particularly elegant method for solving something like this?  Also, more generally, are there problems of this sort that are fundamentally messy, which require long case-by-case calculations and there's no tidy and pleasing way to answer them? Hope my question makes sense, let me know if there is any clarification needed.  Cheers friends! Edit :  It appears I need to share more context and more of my own work so far.  Briefly, I came up with this question, it's not for a class, just my own curiosity.  It's actually related to character selection in the video game Heroes of the Storm, where each of five players is given a selection of three characters at random.  I was just trying to calculate some probabilities, like - What is the chance you get a particular character you want to play?  What is the chance the character you want to play appears somewhere among the five players?  What is the chance that some character appears twice or more among the five players?  Etc. For the latter question - What is the chance that some character appears twice or more - I managed a fairly straightforward solution that I hope is correct, here is my process: Characters are represented as the numbers 1-50.  Five groups are selected represented as ${(X_1, Y_1, Z_1), (X_2, Y_2, Z_2), ..., (X_5, Y_5, Z_5)}$ s.t $X_n \neq Y_n \neq Z_n$ Let's also call the character set $C_n = (X_n, Y_n, Z_n)$ The probability that some character appears twice or more is the same as 1 minus the probability that all characters are distinct.  So we want to find $ P(C_1, C_2, ..., C_5 $ are distinct $)  = P(C_1 $ is distinct $) * P(C_2 $ is distinct $ | C_1 $ is distinct $) * ... * P(C_5 $ is distinct $ | C_1, C_2, C_3, C_4 $ are distinct $) $ $X_1 \neq Y_1 \neq Z_1$ therefore $C_1$ is distinct always. $P(C_2$ is distict | $C_1$ is distinct) $= (\frac{47}{50})(\frac{46}{49})(\frac{45}{48}) $ since there are three choices that can no longer be taken if distinction is going to be preserved.  Since $X_2 \neq Y_2 \neq Z_2$ , the denominator must decrease by one each time. Similarly, $P(C_3$ is distinct | $C_1, C_2$ are distinct) $= (\frac{44}{50})(\frac{43}{49})(\frac{42}{48})$ $P(C_4$ is distinct | $C_1, C_2, C_3$ are distinct) $= (\frac{41}{50})(\frac{40}{49})(\frac{39}{48})$ $P(C_5$ is distinct | $C_1, C_2, C_3, C_4$ are distinct) $= (\frac{38}{50})(\frac{37}{49})(\frac{36}{48})$ The probability that every character is distinct is the product of all the above terms, so: $(\frac{50}{50})(\frac{49}{49})(\frac{48}{48})(\frac{47}{50})(\frac{46}{49})(\frac{45}{48})(\frac{44}{50})(\frac{43}{49})(\frac{42}{48})(\frac{41}{50})(\frac{40}{49})(\frac{39}{48})(\frac{38}{50})(\frac{37}{49})(\frac{36}{48})$ Or more succinctly, $\frac{50!}{35!*50^5*49^5*48^5} \approx 13.1\%$ It follows then that the probability of having one character appear at least twice would be approximately 86.9%.  I feel fairly confident in this answer but I'm always prone to think I'm right and then be miles off, so if someone sees a mistake in my reasoning (if it's even readable) let me know! I am having a hard time figuring out a solution to the more specific problem of - what is the probability of having one character appear at least three times?  I would approach it a similar way, but it seems to require ridiculous amounts of calculations that I don't really care to do, I'd just rather code a quick simulation to find the answer, haha.  I am interested in the mathematics of it though, and wonder if anyone has any advice on a more elegant way than brute-forcing every conditional case, I would love to hear it!  Hope this clears things up a bit.",['probability']
4304736,$~A:=\text{matrix} ~\rightarrow~\lim_{n\to\infty}A^{n}=?~;~$How should I approach against it first?,"$$A:=\begin{pmatrix} \alpha&1-\alpha\\1-\beta&\beta\\\end{pmatrix}$$ $$\left(0<\alpha,\beta<1\right)~~\wedge~~\left(\alpha+\beta\neq 1\right)$$ $$\underbrace{\lim_{n\to\infty}A^{n}}_{\text{What can I do?}}$$ The problem didn't specified whether $~n~$ is an natural number. I think this problem is of a quite typical problem. $$\det\left(B-\lambda I\right)$$ $$=\det\left( \begin{matrix} \alpha-\lambda&1-\alpha\\ 1-\beta&\beta-\lambda\\ \end{matrix}\right)$$ $$=\det\left(\left(\alpha-\lambda\right)\left(\beta-\lambda\right)-\left(1-\alpha\right)\left(1-\beta\right)\right)$$ $$=\det\left(\left(\lambda-\alpha\right)\left(\lambda-\beta\right)-\left(\alpha-1\right)\left(\beta-1\right)\right)$$ $$=\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\alpha\beta-\left(\alpha\beta-\alpha-\beta+1\right)\right)$$ $$=\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\alpha\beta-\alpha\beta+\alpha+\beta-1\right)$$ $$=\det\left(\lambda^{2}-\left(\alpha+\beta\right)\lambda+\left(\left(\alpha+\beta\right)-1\right)\right)$$ $$\lambda=\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(\alpha+\beta\right)^{2}-4\left(\left(\alpha+\beta\right)-1\right)}}{2}$$ About inside the square root. $$\left(\alpha+\beta\right)^{2}-4\left(\left(\alpha+\beta\right)-1\right)$$ $$=\left(\alpha+\beta\right)^{2}-4\left(\alpha+\beta\right)+4$$ $$=\left(\left(\alpha+\beta\right)-2\right)^{2}\geq0$$ $$\therefore~~~\lambda=\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(\left(\alpha+\beta\right)-2\right)^{2}}}{2}$$ $$=\frac{\left(\alpha+\beta\right)\pm\sqrt{\left(2-\left(\alpha+\beta\right)\right)^{2}}}{2}$$ $$=\frac{\left(\alpha+\beta\right)\pm\left|2-\left(\alpha+\beta\right)\right|}{2}$$ Since $~\alpha+\beta<2~$ is held, $$\lambda=\frac{\left(\alpha+\beta\right)\pm\left(2-\left(\alpha+\beta\right)\right)}{2}~~\leftarrow~~\text{Removed operator of absolute value}$$ $$\lambda^{+}=\frac{\left(\alpha+\beta\right)+\left(2-\left(\alpha+\beta\right)\right)}{2}$$ $$=1$$ $$\lambda^{-}=\frac{\left(\alpha+\beta\right)-\left(2-\left(\alpha+\beta\right)\right)}{2}$$ $$=\frac{\left(\alpha+\beta\right)-2+\left(\alpha+\beta\right)}{2}$$ $$=\frac{2\left(\alpha+\beta\right)-2}{2}$$ $$=\left(\alpha+\beta\right)-1$$ $$\therefore~~~\lambda=1,\underbrace{\left(\alpha+\beta\right)-1}_{\neq0}$$ $$p_{A}\left(x\right)=x^{2}-sx+s-1$$ $$n\in\mathbb{N}_{\geq2}$$ $$q\left(x\right)=n-2~\text{degree polynomial}$$ $$a_{n},b_{n}\in\mathbb{R}$$ $$\underbrace{x^{n}=q\left(x\right)p_{A}\left(x\right)+a_{n}x+b_{n}}_{\text{I've been struggling to derive it}}$$ $$x^{n}=q\left(x\right)p_{A}\left(x\right)+a_{n}x+b_{n}$$ $$=\left\{\text{const}_{n-2}x^{n-2}+\sum_{i=0}^{n-3?}\text{const}_{i}x^{i}\right\}\left(x^{2}-sx+s-1\right)+a_{n}x+b_{n}$$ About above, at least, I can understand that RHS of the above equation is n degree polynomial but unable to prove that other $~x^{i}~~\leftrightarrow~~i\in\mathbb{N}\setminus\left\{n-2\right\}~$ disappears. I think as $~n~$ is greater than 2, then any const takes zero hence $~a_n, b_n~$ is always zero except as n is 2.","['limits', 'systems-of-equations', 'linear-algebra', 'exponentiation']"
4304740,Defining an interval as a subset of the naturals,"$x \in (a,b) \subset \Bbb N$ as a way to say "" $x$ is any natural number in the interval $a < x < b$ ."" I like this expression better than $x \in \Bbb N, x \in (a,b)$ , but I'm not sure if it's allowed, since by definition, an interval is a subset of the reals. However, a set that only contains positive integers would still be a subset of the reals, but it would also be a subset of the naturals, no?","['elementary-set-theory', 'notation', 'interval-arithmetic']"
4304750,"Find $x ,y$ satisfying : $x,y$ are $2$ positive integers and $(xy+x+2)(xy+1)$ is a perfect square. [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Find $x ,y$ satisfying : $x,y$ are $2$ positive integers and $(xy+x+2)(xy+1)$ is a perfect square. I have solved this problem and will post the solution as soon as possible. Hope everyone can check my solution! Thanks very much !","['elementary-number-theory', 'algebra-precalculus', 'prime-numbers']"
4304782,Continuous functions on the unit simplex,"For some $n\in\mathbb N$ , define the unit simplex as $$S\equiv\left\{\mathbf x\in\mathbb R_+^n\,\middle|\,\sum_{i=1}^nx_i=1\right\}.$$ For each $i\in\{1,\ldots,n\}$ , suppose that $f^i:S\to\mathbb R_+$ is a non-negative continuous function, $\alpha^i\geq0$ is a number, and let $\mathbf e^i\in S$ denote the vector whose $i$ th coordinate is $1$ and all other coordinates are $0$ . Suppose that the functions are such that $f^i(\mathbf e^i)\geq\alpha^i$ for every $i\in\{1,\ldots,n\}$ ; and $\displaystyle \sum_{i=1}^nf^i(\mathbf x)\geq\sum_{i=1}^n\alpha^i$ for every $\mathbf x\in S$ . Question: Does there necessarily exist some $\mathbf x^*\in S$ such that $f^i(\mathbf x^*)\geq\alpha^i$ for every $i\in\{1,\ldots,n\}$ ? The answer is affirmative for $n=2$ and it easily follows from the intermediate-value theorem. For higher dimensions, I am stuck with coming up with a proof—in fact, I feel diffidence as to whether the answer is affirmative in the first place. Any hints or counterexamples would be appreciated.","['continuity', 'convex-analysis', 'real-analysis']"
4304802,Equality of two minimum spanning trees,"Given weighted complete undirected graph $G=(V,E)$ with $n$ vertices and positive weights. Suppose we find minimum spanning tree $MST(G)$ as $T$ .Next we want to decrease weight of $n$ edges in $G$ to $-\infty$ . So we create new graph $G'=(V,E')$ that contains only edges that have $-\infty$ edge weights. Finally we compute Minimum spanning tree $T'$ from $T\cup G'$ . My question is, if at the first, decrease spcific edges in $G$ to $-\infty$ and then compute minimum spanning tree $T''$ , can we conclude that, edges in $T'$ are the same as $T''$ ?","['graph-theory', 'trees', 'discrete-mathematics', 'algorithms']"
4304823,what is the meaning of the notation $f: A\times B \rightarrow C$,"I'm reading the 4th paragraph on page 8, under section 1.2 Fields, in the following book https://drive.google.com/file/d/1KQ7dbLXI4x39VwZovTL0DKRsZwt_i3Vt/edit ""linear algebra done openly"". the summary is: a function $f$ is a relationship between sets, say $A$ and $B$ ...we denote this function relation as $f: A \rightarrow B$ ... $A\times B$ denotes the set of ordered pairs of elements from $A$ and $B$ ... An operation is a function of the form $f: A \times B \rightarrow C$ . One should think of an operation as a process of bringing two objects together and creating a third operation. what does: ""An operation is a function of the form $f: A \times B \rightarrow C$ . One should think of an operation as a process of bringing two objects together and creating a third operation."" exactly mean? what would a good example look like?","['vector-fields', 'functions', 'abstract-algebra', 'linear-algebra', 'function-fields']"
4304864,"If $f'(x)≥0$, $f''(x)≤0$ then prove that $f(x)f^{-1}(x)-x^2≤0$","If $f:[0,1] \rightarrow [0,1]$ such that $f'(x)≥0$ , $f''(x)≤0$ then prove that $$f(x)\cdot f^{-1}(x)-x^2≤0$$ I was able to form a graphical solution but it doesn't feel rigorous enough to me, can someone else come up with some alternate proof? My ad-hoc method: Take $A (t,f(t))$ , $B(t,f^{-1}(t))$ and $B' (f^{-1}(t),t)$ (note $B'$ lies on $f(x)$ ). Now the graph of $f(x)$ will look something like $\sqrt{x}$ and $f^{-1}$ will be it's reflection about $y=x$ so once we make the proper diagram we will see that slope $OB'≥$ slope $OA$ $$\implies \frac{x}{f^{-1}(x)}≥\frac{f(x)}{x}$$ $$\implies f(x)\cdot f^{-1}(x)-x^2≤0$$","['functional-equations', 'functional-inequalities', 'calculus', 'functions', 'derivatives']"
4304881,Closed expression for a continued fraction,"Does anyone know a closed expression for the following continued fraction? $$G(x) = \cfrac{1}{x+1+\cfrac{1}{x+3+\cfrac{4}{x+5+\cfrac{9}{x+7+\cfrac{16}{x+9+\cdots}}}}}$$ All I know is that $G(0) = \frac{\pi}{4}$ and $G(x)$ converges for $x \geq 0$ , while also $G(x) \sim \frac{1}{x} \ (x \to \infty)$ . The equation $G(0) = \frac{\pi}{4}$ follows from a well-known continued fraction expansion for $\arctan$ .  However, the expansion above is different.  It came up in my research, and I can't find it in any continued fraction tables.","['continued-fractions', 'special-functions', 'analysis']"
4304902,Convex n-sided polygons whose exterior angles expressed in degrees are in arithmetic progression,"If the exterior angles of a convex n-sided polygon, are all integers, expressed in degrees, are in arithmetic progression, how many values are possible for $n$ ? The sum of all exterior angles has to be 360°. So, the total number of factors of $360$ ° are $24$ . Subtracting $2$ factors ( $1$ & $2$ ), all the other factors can easily represent the number of sides of polygons. So, on the whole, why can't be there $22$ polygons having all exterior angles in $AP$ , and integer?","['arithmetic-progressions', 'geometry', 'polygons', 'diophantine-equations']"
4304959,Interesting pattern in plot involving prime numbers,"If we plot $f(n) = \dfrac{n+1}{p_{n+1}} - \dfrac{n}{p_n}, n \in \mathbb{N} $ , we get an interesting pattern. Questions: Why it looks like there's different lines on plot? Why they have such shape? How those lines can be approximated? Why there's like peak at $n \approx 500$ ? Why points in lines become sparcer as they are closer to the bottom?","['number-theory', 'prime-numbers']"
4305031,Hartshorne Exercise III.2.7(a): sheaf cohomology of constant sheaf $\Bbb Z$ on $S^1$ in the usual topology,"I am trying to solve this exercise: Let $S^1$ be the circle(with its usual topology), and let $\mathbb Z$ be the constant sheaf $\mathbb Z$ (a) Show that $H^1(S^1,\mathbb Z)\simeq \mathbb Z$ , using our definition of cohomology. I have tried to construct an injective resolution: like Proposition 2.2, Let $I^0=\prod_{x\in S^1}j_*(\mathbb Q)$ . But then I don't know how to  calculate its stalk. So I have difficulties in build the $I^1$ ... If I just use its discontinuous sections to build a flasque resolution, I also can't calculate the stalk... Could you provide some help or give a complete answer? Using Cech cohomology is also accepted. Thanks!",['algebraic-geometry']
4305054,Questions regarding Homogeneous Differential Equation,"I have problem with two differential Equation solutions done in my text book. I am begginer in this field. I know only Uniqueness Existence Theorem and few methods. $\frac{dy}{dx}= \frac{y^2- x^2}{2xy}$ and $\frac{dy}{dx}= \frac{2xy}{x^2-y^2}$ and $y(1)=1$ For the first one , they put $y = vx$ and got the solution $y^2+x^2= 2x$ for all $(x,y) \in \mathbb R^2$ . But my doubt is following. It is clear from the question that the differential equation is defined on the set $\mathbb R - A$ where $A = \{ (x,y) : xy = 0\}$ . so clearly solution of this differential equation should have been defined on that set only.  I can not understand how they are getting solution for the whole $\mathbb R^2$ . For the second one , they  have done in the following way. $\frac{dy}{dx}= \frac{2xy}{x^2-y^2}$ implies $\frac{dx}{dy}= \frac{x^2-y^2}{2xy}$ After that they have put $x$ in the place of y and vice-versa in the previous solution to get the solution of this differential equation. I can not understand how $\frac{dy}{dx}= \frac{2xy}{x^2-y^2}$ implies $\frac{dx}{dy}= \frac{x^2-y^2}{2xy}$ . Why are they not caring about what will happen when $\frac{dy}{dx}= \frac{2xy}{x^2-y^2}=0$ ? Can anyone please help me ? I got stuck on this and I can not go ahead without understanding this. PLease help me.","['calculus', 'derivatives', 'ordinary-differential-equations', 'real-analysis']"
4305071,How to factor $ ab(x^2 +y^2) + xy (a^2 +b^2)$?,"Source : poblem 291 ( image below)  of Lebossé & Hémery, Algèbre et Analyse ( Classe de seconde , 1965) Note : "" classe de seconde "" is $10^{\mathbb th}$ grade , which inspires me the reflection that I wouldn't have be admitted to $11^{\mathbb th}$ grade in $1965$ . Developping I get , $abx^2+ ab y^2 + xy a^2 + xyb^2$ but I cannot see which known identity is hidden below this expression. Symbolab is unable to give any answer regarding this factorization problem.","['algebra-precalculus', 'soft-question', 'polynomials']"
4305082,"$S=\{a,a+d,a+2d,...\}$ where $a,d$ are natural numbers. Show that there are infinitely many composite numbers in S.","It is easy to prove when $a>1$ . Each element in this set is of the form $a+nd$ . Whenever n is a multiple of a, then $n=ak$ , thus $a+nd=a+ak=a(1+k)$ . Thus n is composite. But the difficulty comes when $a=1$ . I cannot find a way. Any hint will be much appreciated.","['elementary-number-theory', 'discrete-mathematics']"
4305088,Show that $x^4-8x^2+(1-m)x+1-c=(x-a)^2(x-b)^2$,"I am stuck on the following question: My thoughts on how to approach it: Find coefficient of $x$ in $(x-a)^2(x-b)^2$ . Equate coefficient to $1-m$ Prove that the values are equal. To prove it I thought of setting up $2$ simultaneous equations and finding $a, b, m$ - one where I write $f^\prime(a) = f^\prime(b) = m$ and other where I use $m = \frac{f(b) - f(a)}{b-a}$ . Use values of $a, b, m$ to find $c$ and prove that $1 - c = \text{coefficient of }x^0$ Problems with this approach: It's a boring algebra bash that is too long and involves $4^{th}$ degree polynomials. It doesn't follow the order of the questions i.e. $a, b, m$ are found before we prove part (c). I am not sure whether it even works. Any help on a simpler approach will be much appreciated.","['tangent-line', 'functions']"
4305095,Why is the Galois conjugate of a modular eigenform another eigenform?,"In this question, $k \geq 2$ and $N \geq 1$ are integers. We consider the space $S = \mathcal{S}_k(\Gamma_1(N))^{new}$ of modular forms of weight $k$ for $\Gamma_1(N)$ (the same question can certainly be asked for $k = 1$ but I think that this MO answer should help). It has an action of Hecke operators $T_p$ (for all primes $p$ ) and diamonds $\langle d\rangle$ (for all integers $d$ coprime to $N$ ). Let $T_{\mathbb{Q}}$ be the (commutative) $\mathbb{Q}$ -algebra generated by these operators (seen as a subalgebra of the ring of endomorphisms of $S$ ), and $T_{\mathbb{C}}$ be the sub- $\mathbb{C}$ -algebra of the ring of endomorphisms of $S$ generated by these operators. My question is the following: let $f \in S$ be a Hecke normalized newform. Let $\sigma$ be an automorphism of $\mathbb{C}$ (or of $\overline{\mathbb{Q}}$ if we accept that the eigenvalues of Hecke operators are algebraic). It is well-known (it appears in, say, Shimura's 1976 paper The special values of zeta functions associated with cusp forms ) that $f^{\sigma}$ (defined as a formal power series by letting $\sigma$ act on all the coefficients of $f$ ) is another Hecke eigenform. But why is that? A possible reformulation involves using the well-known fact that such eigenforms are exactly the $\mathbb{C}$ -morphisms $T_{\mathbb{C}} \rightarrow \mathbb{C}$ . Now, if $f$ corresponds to the morphism $\mu$ , $f^{\sigma}$ corresponds to a $\mathbb{C}$ -morphism mapping $T_n$ to $\sigma \circ \mu(T_n)$ . But this cannot define a $\mathbb{C}$ -morphism $T_{\mathbb{C}}$ unless every $\mathbb{C}$ -linear relation between the $T_n$ (and the diamonds) is in fact rational. In other words, we need that $T_{\mathbb{Q}} \otimes_{\mathbb{Q}} \mathbb{C} \rightarrow T_{\mathbb{C}}$ be injective. But I'm not sure if this is easier to prove than the original statement. In weight $2$ , Hecke operators can be interpreted as endomorphisms of the Jacobian of $X_1(N)$ and cusp forms can be interpreted as global differentials on said Jacobian. So we could be done if, for a complex abelian variety $J$ , $\mathrm{End}(J) \otimes \mathbb{C} \rightarrow \mathcal{L}(H^0(J,\Omega^1))$ is injective. This is, however, false, because of $J=\mathbb{C}/\mathbb{Z}[i]$ (and other instances of complex multiplication). If, however, we have a full basis of $\mathcal{S}_k(\Gamma_1(N))$ by cusp forms with rational Fourier coefficients, this means that the image of the Fourier expansion map $\mathcal{S}_k(\Gamma_1(N)) \rightarrow \mathbb{C}[[q]]$ is of the form $V \otimes \mathbb{C}$ , where $V$ is a subspace of $\mathbb{Q}[[q]]$ and thus that the Galois conjugate of a modular form for $\mathcal{S}_k(\Gamma_1(N))$ is in $\mathcal{S}_k(\Gamma_1(N))$ , and then the result follows easily. But this doesn't look easier than the bolded question. So where does that assertion come from? Why is the Galois conjugate of a newform a newform of same level? (You may use that Hecke eigenvalues are algebraic integers, but I would appreciate a reference for the weights $k > 2$ ).","['galois-theory', 'number-theory', 'modular-forms', 'hecke-algebras']"
4305151,Probability that the first and fourth balls are red when drawing 4 balls.,"Sorry, couldn't fit the entire question into the title. Question: A box contains 15 identical balls except that 10 are red and 5 are
black. Four balls are drawn successively and without replacement. Calculate the probability that the first and fourth balls are red . My attempt: Probability = $$1*2C0 + 1*2C1 + 1*2C2  \over 4C0 + 4C1 + 4C2 + 4C3 + 4C4 $$ My idea is that no. of ways to make first and fourth balls = 1, and we have 2 balls left which
can either have red or black colors. However, my textbook answer was: $$10P2*13P2\over15P4$$ Which I don't get at all; why would you use permutations when you have identical balls ? Wouldn't that mess things up? Thanks in advance.","['combinatorics', 'probability']"
4305301,Star refinement and paracompactness,"If $\mathcal{U}$ is a cover of a space $X$ and $S\subseteq X$ , define the star of $S$ with respect to $\mathcal{U}$ as $\text{st}(S,\mathcal{U})=\bigcup\{U\in\mathcal{U}\mid S\cap U\neq\emptyset\}$ . According to wikipedia , a Hausdorff space is paracompact iff it is fully normal; it is also defined there that a space is fully normal if every open cover has an open star refinement. In the same page it says a cover $\mathcal{U}$ is a star refinement of $\mathcal{V}$ if for any $x\in X$ , $\text{st}(\{x\},\mathcal{U})\subseteq V$ for some $V\in\mathcal{V}$ . However the wikipage for star refinement says it should be for any $U\in\mathcal{U}$ , $\text{st}(U,\mathcal{U})\subseteq V$ for some $V\in\mathcal{V}$ , which is a priori stronger. Do these give the same definition? If not which one is the correct definition of fully normal spaces? Consider the following property: any open cover $\mathcal{V}$ has an open refinement $\mathcal{U}$ such that any $U\in\mathcal{U}$ intersects only finitely many other members of $\mathcal{U}$ . This property easily implies paracompactness. Is the converse true (maybe under mild assumption)? If not does this property has a name?","['general-topology', 'compactness']"
4305322,"If $F(x+y+z, x^2+y^2+z^2)=0$ then find $\frac{\partial^2 z}{\partial x \partial y }$","If $F(x+y+z, x^2+y^2+z^2)=0$ then find $\frac{\partial^2 z}{\partial x \partial y }$ . Attempt I think that here we must apply the implicit differentiation Theorem, but I´dont know how I should do it, first I try use $X=x+y+z$ and $Y=x^2+y^2+z^2$ and then In case of be useful calculate $$\frac{\partial X}{\partial x}=1, \, \frac{\partial X}{\partial y}=1, \, \frac{\partial X}{\partial z}=1$$ and also $$ \frac{\partial Y}{\partial x}=2x, \, \frac{\partial Y}{\partial y}=2y, \, \frac{\partial Y}{\partial z}=2z$$ and hence my Function should looks as $$F(X,Y)=0$$ From here I Try apply the implicit function theorem which states that I should find a function $z(X)$ such that $F(X,Z(X))=0$ and that in fact $z$ is differentiable with differential equal to $$\frac{\partial z}{\partial x}=-\frac{\frac{\partial F}{\partial x}}{\frac{\partial F}{\partial z}}$$ But I´m not sure about if the form of I use actually is valid, and in other case someone can clarify what is the answer(step by step (because i´m learning Analysis by myself)  and more important how I should apply and understand this famous theorem.","['multivariable-calculus', 'calculus', 'implicit-function-theorem', 'real-analysis']"
4305357,"Orthonormal sequence in L$^2(0,1)$","Let $\{\phi_n\}_{n=1}^{\infty}$ be an orthonormal sequence in L $^2(0,1)$ . Prove that $\{\phi_n\}_{n=1}^{\infty}$ is an orthonormal basis iff $\forall a\in [0,1]$ , $a=\sum_{n=1}^{\infty}|\int_0^a\phi_ndx|^2$ . For the first direction, this is just using Parseval's identity with $\chi_{(0,a)}$ , because: $$a=\|\chi_{(0,a)}\|^2=\sum_{n=1}^{\infty}|\int_0^1\phi_n\chi_{(0,a)}dx|^2=\sum_{n=1}^{\infty}|\int_0^a\phi_ndx|^2$$ . For the second direction, I tried using the fact that $\{\phi_n\}$ is orthonormal basis iff $\{\{\phi_n\}_{n=1}^{\infty}\})^{\bot}=\{\vec 0\}$ , but this didn't work. Also tried to show that Parsavel's equality must hold but also got stuck there. Any hint would be appreciated.","['banach-spaces', 'orthogonality', 'analysis', 'real-analysis', 'hilbert-spaces']"
4305364,Turtle geometry in 3D,"I'm undertaking a small project whereby I'm trying to recreate the educational programming language Logo . For those who don't know it, Logo consists of a 'turtle' which starts at the (x, y) location (0, 0) and can then move forwards and backwards to draw lines. In addition, the turtle can turn to the right or left infinitely (I.E. the angle 'wraps' at 360 back to zero when turning clockwise, and has the same property in the counter-clockwise direction.) Students can then use commands like FD to move the turtle forward, or RT to turn to the right. So, for example, the program FD 10 RT 90 FD 10 RT 90 FD 10 RT 90 FD 10 RT 90 would draw a square with sides of 10-units in length. My turtle has x , y and angle properties, and when I supply d to specify the distance to travel, I can easily calculate the new values of x and y with the following: old_x = x old_y = y r = angle * (pi / 180) # convert angle (in degrees) to radians new_x = old_x + (d * cos(r)) new_y = old_y + (d * sin(r)) I then draw a line from (old_x, old_y) to (new_x, new_y) . So far, so good. I'm able to move the turtle perfectly in two dimensions. But, what I'd like to do now, is add UT and DT commands to my program, so that it is possible to move the turtle's nose up and down, so that we can now draw 3D shapes. For example, the program FD 10 UT 90 FD 10 UT 90 FD 10 UT 90 FD 10 UT 90 would still draw a square, only now it would standing vertically. I know my graphics library (OpenGL) supports drawing lines in 3D, infact that's what I'm already doing, only I'm keeping the z dimension zero the whole time, and obviously I'll need to keep track of a second angle variable for up and down, but I've absolutely no idea of how to go about calculating the new x , y and z values given two angles. Can anyone help? Many TIA.","['geometry', '3d']"
4305385,A man invited five friends.,"A man invited five friends. He was born in April as also all the invited friends. What is the probability that none of the friends was born on the same day of the month as the host? The way I approached it was $\frac{(30\times 29^5)}{(30^6)}$ . However, there is yet another equally convincing way i.e. Probability that a friend's birthday is on the same day as the host is $\frac{1}{30}$ . So if this goes for all friends then we have $\big(\frac{1}{30}\big)^5$ . And we want the negation of it so $1-\big(\frac{1}{30}\big)^5$ . Which one is correct?","['combinatorics', 'birthday', 'probability']"
4305433,Prove that $f(x)=x^2$ is integrable using superior and inferior sums,"I need to prove that $f:[-1,2]\rightarrow\mathbb{R}$ given by $f(x)=x^2$ is integrable using this theorem: Let $f:[a,b]\rightarrow\mathbb{R}$ be limited. The following afirmations are equivalent: (1) $f$ is integrable; (2) for all $\varepsilon>0$ , exists partitions $P$ and $Q$ from $[a,b]$ such that $S(f;Q)-s(f;P)<\varepsilon$ ; (3) for all $\varepsilon>0$ , exists a partition $P=\{t_0,\dots,t_n\}$ from $[a,b]$ such that $$S(f;P)-s(f;P)=\sum_{i=1}^{n}\omega_i(t_i-t_{i-1})<\varepsilon.$$ $$s(f;P)=\sum_{i=1}^{n}m_i(t_i-t_{i-1}); S(f;P)=\sum_{i=1}^{n}M_i(t_i-t_{i-1});$$ $$m_i=\inf\{f(x);x\in[t_{i-1},t_i]\};M_i=\sup\{f(x);x\in[t_{i-1},t_i]\};\omega_i=M_i-m_i.$$ I got stuck in a part of the demonstration I tried: Given $\varepsilon>0$ , exists $n\in\mathbb{N}$ such that $$\dfrac{1}{n}<\varepsilon\quad\mbox{ and }\quad\dfrac{2}{n}<2\varepsilon.$$ Let's take partitions $P_1$ and $P_2$ that refine $P_0=\{-1,0,2\}$ such that $$P_1=\left\{t_0=-1,t_1=-1+\dfrac{1}{n},t_2=-1+\dfrac{2}{n},\dots,t_n=-1+\dfrac{n}{n}=0\right\}\mbox{and}$$ $$P_2=\left\{t_0=0,t_1=0+\dfrac{2}{n},t_2=0+\dfrac{2(2)}{n},\dots,t_n=0+\dfrac{n(2)}{n}\right\}.$$ Note that for each interval $[t_{i-1},t_i]$ from $P_1$ we have that $$m_i=f(t_i)=(t_i)^2\quad\mbox{and}\quad M_i=f(t_{i-1})=(t_{i-1})^2;$$ because $f$ strictly decreasing in $[-1,0]$ . Note, also, that for each interval $[t_{i-1},t_i]$ from $P_2$ we have that $$m_i=f(t_{i-1})=(t_{i-1})^2\quad\mbox{and}\quad M_i=f(t_{i})=(t_{i})^2;$$ because $f$ is strictly increasing in $[0,2]$ . In this way, $$S(f;P_2)-s(f;P_1)=$$ $$\left[\left(\dfrac{2}{n}\right)^2\left(\dfrac{2}{n}-0\right)+\left(\dfrac{4}{n}\right)^2\left(\dfrac{4}{n}-\dfrac{2}{n}\right)+\cdots+\left(2\right)^2\left(2-\dfrac{(n-1)(2)}{n}\right)\right]$$ $$-\left[\left(-1\right)^2\left(-1+\dfrac{1}{n}-(-1)\right)+\left(-1+\dfrac{1}{n}\right)^2\left(-1+\dfrac{2}{n}-\left(-1+\dfrac{1}{n}\right)\right)+\cdots+\left(-1+\dfrac{n-1}{n}\right)^2\left(0-\left(-1+\dfrac{n-1}{n}\right)\right)\right]$$ and that's it... I got stuck. What I was trying to do is simplify all of this to get that $$S(f;P_2)-s(f;P_1)=\left(\dfrac{2}{n}\right)-\left(\dfrac{1}{n}\right)<2\varepsilon-\varepsilon=\varepsilon.$$ But I couldn't do it... anyone can help me?","['riemann-sum', 'analysis', 'real-analysis']"
4305450,Orders of Paige Loops over Finite Fields,"A Moufang loop $M$ is a loop that satisfies the Moufang identity: $(zx)(yz) = z((xy)z),\forall x,y,z\in M$ . From here , we get the following statement: For any field $F$ let $M(F)$ denote the Moufang loop of unit norm elements in the (unique) split-octonion algebra over $F$ . Let $Z$ denote the center of $M(F)$ . If the characteristic of $F$ is $2$ then $Z = \{e\}$ , otherwise $Z = \{±e\}$ . The Paige loop over $F$ is the loop $M^*(F) = M(F)/Z$ . Paige loops are nonassociative simple Moufang loops. All finite nonassociative simple Moufang loops are Paige loops over finite fields. So we have (see multiplication table below for $i,\ell, k$ ), $M(\mathbb{F}_{p^n})=\{x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k\}$ , where $x_m\in \mathbb{F}_{p^n}$ and unit norm: $N(x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k)=(x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k)\cdot (x_{0}-x_{1}\,i-x_{2}\,j-x_{3}\,k-x_{4}\,\ell -x_{5}\,\ell i-x_{6}\,\ell j-x_{7}\,\ell k)=1$ Question : What are the orders of these Paige loops? Examples: $|M^*(\mathbb{F}_2)|=120$ $|M^*(\mathbb{F}_3)|=624/2=312$ It gets much harder to manually compute; is there work on this?","['finite-fields', 'octonions', 'reference-request', 'abstract-algebra', 'group-theory']"
4305457,"Prove that a set $S$ cannot be partitioned into two subsets, each having the same products of elements","Let $p\equiv 3\mod 4$ be a prime. Let $S$ be a set of $p-1$ consecutive positive integers. Prove that $S$ cannot be partitioned into two subsets, each having the same product of elements. I think a contradiction should be useful here, and it should not be necessary to use this theorem by Erdos . So suppose $S$ can be partitioned into two subsets $A$ and $B$ , each having the same products of the elements. Let $m$ be the smallest element in $S$ . Then $\prod_{a\in A} a= \prod_{b\in B} b = \frac{1}2\prod_{j=1}^{p} (m+j-1).$ To get a contradiction, it might be possible to show that $B$ and $A$ cannot be disjoint, but I'm not sure how to do this. I know $S$ may or may not contain a multiple of $p$ , but if one added another integer to $S$ , then the new set must contain a multiple of $p$ . Also, every nonmultiple of $p$ in $S$ has a unique inverse in $\mathbb{Z}_p^*,$ the multiplicative group of integers modulo $p$ .","['elementary-set-theory', 'elementary-number-theory', 'group-theory']"
4305471,Do I have the right bounds and function for this integral?,"Find the integral of function $f(x,y,z)=(x^2+y^2+z^2)^{3/2}$ inside the sphere $(z-2)^2+x^2+y^2=4$ My approach: by changing it to spherical coordinates, we have $0\le\rho\le2\cos\varphi$ $(0\le\theta\le2\pi,\ 0\le\varphi\le\frac\pi2)$ , and the function becomes $f(\rho,\theta,\varphi)=ρ^3$ , which, when multplied by the Jacobian, $ρ^2\sin\varphi$ , becomes $ρ^5\sin\varphi$ . In other words, we are integrating this function in the above $\rho,\theta,\varphi$ bounds. Is this correct？Why would Wolfram alpha's calculator give a much larger value when integrated in Cartesian coordinates?","['multivariable-calculus', 'spherical-coordinates', 'multiple-integral']"
4305538,Compute the Fourier transform of $(x_{1}+ix_{2})^{-1}$ in $S'(\mathbb{R}^{2})$ (as a tempered distribution).,"I am trying to compute the Fourier transform of $(x_{1}+ix_{2})^{-1}$ in $S'(\mathbb{R}^{2})$ . i.e. as a tempered distribution. It might be useful to note that for $\mu \in S'(\mathbb{R}^{2})$ and $\psi \in S(\mathbb{R}^{2})$ we define $\langle\hat{\mu},\psi\rangle=\langle\mu,\hat{\psi}\rangle$ . In my attempt, I noted that the definition of the Fourier transform in $S(\mathbb{R}^{2})$ : $$
\hat{f}(\lambda)=\int_{\mathbb{R}^{2}}f(x)e^{-i \lambda \cdot x} dx,
$$ gave us that $\widehat{(-i \partial_{1}+\partial_{2}) \delta}=x_{1}+ix_{2}$ . I'm not sure how to use this fact to help me complete the problem. Any help would be greatly appreciated.","['fourier-analysis', 'fourier-transform', 'distribution-theory', 'real-analysis', 'functional-analysis']"
