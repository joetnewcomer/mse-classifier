question_id,title,body,tags
2620133,"Let $A,B$ be $m \times n$ and $n \times m$ matrices, respectively. Prove that if $m > n$, $AB$ is not invertible","We haven't done anything about rank or dimensions or linear dependence / basis or determinants.  Possible related facts : A matrix is invertible iff it is bijective as a linear transformation. An invertible matrix is row-equivalent to the identity matrix. A matrix has a right inverse iff it has a left inverse. Also, invertability is only defined for square matrices.","['matrices', 'linear-algebra', 'linear-transformations', 'inverse']"
2620151,Find an explicit formula for the recursive formula,"Find an explicit formula for the recursive formula: $$a_{n+1} = 2a_n\left(a_n + 3\right); a_0 = 4$$ The first few terms in the sequence go like this: $4, 56, 6608, \dots$ After $a_2$ the sequence begins increasing at a very strong rate. Normally how we were taught to find an explicit formula, we start by defining the first few terms of the sequence in terms of the initial term, $a_0$, and then look for patterns to generalize a formula for the $n$th term. For this example, we have $a_1 = 2(a_0)^2+6(a_0)$, but it only got worse when trying to find $a_2$. $a_2 = 8(a_0)^4 + 48(a_0)^3+84(a_0)^2 + 36(a_0)$ I feel as if this isn't the most efficient method to find the explicit formula, and I imagine $a_3$ would only be a ""messier"" polynomial and won't help me give me any sort of clue as to what the explicit formula may be. Is there another way to tackle this problem? Note: although I was never taught this method, I hear generating functions may be able to be used for problems such as these.","['recurrence-relations', 'sequences-and-series']"
2620166,"Pre - calc problem turned hard, easier method for this formula?","I am constantly brain storming challenge questions for my pre calculus students. Today I came up with this question, but upon finding the answer I don't think this one will be feasible for my students. Suppose during month zero your credit card balance is $b_0$. Sometime
  during month zero you make the minimum payment, say $p$. The next
  month the bank calculates your new
  balance by $b_0 - p + I(b_0 - p)$ where $I$ represents your interest.
  Assuming you always pay the minimum payment every month, $p$, and your
  interest $I$ stays fixed, a recursive function that gives your balance
  in month $n$ could be given by $f(0) = b_0$ and $f(n) = f(n-1)-p +
 I(f(n-1) - p)$ for $n \geq 1$. Find a closed form for the function
  $n$. As always, I set out to make sure I could even solve the problem before giving it to my students as a challenge problem. My solution took me quite a while. Here is the answer I came up with, that could possibly be further simplified: $$f(n) = \frac{p(1+I)^{n+1} - Ib_0(1+I)^n - P(1+I)}{-I}$$ My method was to start by writing out the first few terms using the recursive definition, then start rearranging and looking for patterns. After a while I was able to spot and prove a binomial expansion, and a geometric sum of binomials was occurring which yields my solution. I will currently not write my full derivation unless requested because it is long and mostly just symbol crunching. My question to the MSE community is, does anyone have a slick easy
  derivation of a solution to this problem? I did not thing it should be
  so tedious when I came up with it? Is there a better method? I don't even know what to tag this, if anyone has any good suggestion for tags let me know.","['algebra-precalculus', 'recurrence-relations', 'recursive-algorithms']"
2620171,"When can one write $f(x,y)$ as $|g(x)-g(y)|_2^2$ for some $g(\cdot)$?","Suppose I have a function $f:\mathbb{R}^n \times \mathbb{R}^n \rightarrow \mathbb{R}$. Fix a natural number $k$. Under what conditions can I write 
$$
f(x,y) = [g(x) - g(y)]^{T}[g(x) - g(y)]
$$
for some appropriate function $g:\mathbb{R}^n \rightarrow \mathbb{R}^k$? Necessary conditions are obviously that $f(x,y) \geq 0$, $f(x,x) = 0$ and that $f(x,y) = f(y,x)$, but are these sufficient?","['functional-equations', 'real-analysis', 'analysis', 'functions']"
2620193,Is function is uniformly continuous on $\mathbb{R}$ then it is uniformly continuous on subset of $\mathbb{R}$?,"We know that, the function $f: \mathbb{R}→ \mathbb{R}$ such that  $f(x) = x$ is uniformly continuous on $\mathbb{R}$. Now, my Question is,  if we define the function $g:\mathbb{Q} →\mathbb{R}$ such that $f(x) = x$ for all $x ∈ Q$ then is function $g$ is uniformly continuous on $\mathbb{Q}$? My attempt :
 as we know, continuity is domain based property. So to check continuity of $g$, we must consider the point of domain first!!. Now let $q ∈\mathbb{Q}$ then as we know, rationals are dense in $\mathbb{R}$ so, $q$ must be limit point of domain and not an isolated point of domain. So $g$ is continuous at $q$ if and only if, $$\lim_{x\to q} g(x) = g(q)$$
But is $$\lim_{x\to q+} g(x)=\lim_{x\to q-} g(x)$$? (I stuck here) As between two rationals there is an irrational number and function is not defined their. So is left hand limit and right hand limit of $g$ as $x$ tends to $q$ are equal? Is $g$ is continuous at $q$ ? and what about uniform continuity? Please help me.","['real-analysis', 'limits', 'continuity', 'uniform-continuity', 'analysis']"
2620204,An Isserlis theorem for Elliptical Distributions?,"For my purposes, I am only interested in rotationally invariant Elliptical Distributions. So suppose $x$ is a $p$-dimensional random variable with zero mean and identity covariance, with density equal to $g(x^{\top}x)$. I am interested in third and fourth moments:
$$
E\left[x_i x_j x_k \right] \quad\mbox{and}\quad
E\left[x_i x_j x_k x_l \right],
$$
where the indices may be duplicated. I have some hints from this paper by Kan, but not enough.","['expectation', 'probability']"
2620206,How fast does the sequence $b_{n+1}=b_n+\frac{1}{b_n}$ grow?,"$b_{n+1}=b_n+\frac{1}{b_n}$, where $b_0=1$. I have proven that this sequence is $O(\ln n)$ and $o(n)$. Can anyone give a more precise estimation of the order of $b_n$? i.e. a $f(n)$ such that $0<\lim_{n \to \infty}\frac{b_n}{f(n)}<\infty$","['recursion', 'sequences-and-series', 'calculus', 'analysis']"
2620213,What does the p-harmonic series converge to when p = 1 + ε?,"In infinitesimal calculus, $\epsilon$ is an infinitesimal number, that is, it is defined to be a number smaller than any real number but greater than $0$. The p-harmonic series is: $\displaystyle \sum_{n=1}^{\infty} \frac{1}{n^p}$ It is well known that this series diverges when $p \leq 1$ and converges when $p > 1$. A lot of teachers like to do examples of this problem with $p$ arbitrarily close to one, but still greater, like $p = 1 + 0.001$. What I want to know is, what happens when $p$ is infinitesimally close to $1$? In other words what does the series converge to when $p = 1 + \epsilon$?: $\displaystyle \sum_{n=1}^{\infty} \frac{1}{n^{1 + \epsilon}}$ Is this any different from just taking the limit as $p$ approaches 1?: $\displaystyle \lim_{p \to 1^+} \sum_{n=1}^{\infty} \frac{1}{n^{p}}$ $1 + \epsilon$ is a number that is greater than $1$, whereas, the limit is getting arbitrarily close to $1$, and presumably that means it gets closer to $1$ than $1 + \epsilon$. However, I don't know what number the series could possible converge to when $p = 1 + \epsilon$.","['power-series', 'infinitesimals', 'sequences-and-series']"
2620222,Find number of solutions of $(x-1)^2+\lceil x \rceil=4$,"Find number of solutions of $$(x-1)^2+\lceil x \rceil=4$$ I could find that there are no integral solutions since , for $x$ an integer we have $$(x-1)^2+x=4$$ $$x^2-x-3=0$$ which has Non integer roots. How about Non integer solutions without graphing?","['algebra-precalculus', 'functions', 'ceiling-and-floor-functions']"
2620229,How to prove $\lim \limits_{x \to 1^-} \sum\limits_{n=0}^\infty (-1)^nx^{n^2} = \frac{1}{2} \ $?,"How to prove $$\lim \limits_{x \to 1^-} \displaystyle \sum_{n=0}^\infty (-1)^nx^{n^2} = \frac{1}{2}\,?$$ The power $n^2$ is problematic. Can we bring this back to the study of usual power series? I do not really have any idea for the moment.","['real-analysis', 'sequences-and-series', 'limits']"
2620248,"Show that the following curve, $\alpha (s)$ is a circle centered at the origin","Let $\alpha (s)$ for $s \in \mathbb{R}$ be a curve in $\mathbb{R}^3$, parametrized by arc length which does not pass through the origin. Suppose for every $s\in \mathbb{R}$, the straight line through $\alpha(s)$ parallel to $\bf{n}$$(s)$ always passes through the origin $(0,0,0)$, Show $\alpha (s)$ is a circle centered at the origin. I dug around and found out that if the curvature is constant and torsion is $0$, then the curve is a circle. But now I have the following questions. It makes sense for a circle to have constant curvature part, but I don't quite understand how torsion works aside from it's definition.","['multivariable-calculus', 'differential-geometry']"
2620257,System of equations involving complex numbers,"I'm getting confused to figure this work out. The only thing that came into my head was using AM-GM inequality, but i just get stuck. Here's the problem: Let $a,b,c,$ be the complex numbers such that $abc=1$. and
\begin{cases}
a^{20}+b^{20} + c^{20} &= \frac{1}{a^{20}} + \frac{1}{b^{20}} + \frac{1}{c^{20}} \\
a^{17}+b^{17}+c^{17} &= \frac{1}{a^{17}} + \frac{1}{b^{17}} + \frac{1}{c^{17}}\\
a^{2017} + b^{2017}+c^{2017} &= \frac{1}{a^{2017}} + \frac{1}{b^{2017}} + \frac{1}{c^{2017}}\\
\end{cases}
show that $1 \in \{a,b,c\}$. Please help me to solve this question, any thought would be helpful.","['algebra-precalculus', 'systems-of-equations']"
2620316,Complex number basic stuff,"The first question is to prove that $\operatorname{Re}(iz)=-\operatorname{Im}(z)$. First $z= x+ iy$; $$\operatorname{Re}(i(x+iy))=\operatorname{Re}(ix+i^2y)=\operatorname{Re}(ix-y)$$ ---> I don't know how to move on to make it equal to $-\operatorname{Im}(z)$. Another similar question is to prove that $\operatorname{Im}(iz)=\operatorname{Re}(z)$. Basically, $$\operatorname{Im}(iz)=\operatorname{Im}(ix-y)$$ ---> same place I got stuck. I know that $\operatorname{Re}(z)=x$, and $\operatorname{Im}(z)=y$.",['complex-analysis']
2620318,Recommendation on probability textbook,"Most posts here asked for a probability textbook which does not assume measure-theoretic background. However, I have a quite concrete background of measure-theory and am looking for a probability textbook which is very measure-theoretic and written for pure mathematicians, not engineers. (I am a third-year graduate student and I have studied at least 4 different real-analysis textbooks including Folland’s, Stein’s, Royden’s, Rudin’s and etc. However, I have never studied probability theory before, and I need to study this theory now.)","['book-recommendation', 'probability-theory', 'probability']"
2620347,Is a conformal transformation also a general coordinate transformation?,"As far as I understand, a general coordinate transformation is induced by a diffeomorphism $f:M\rightarrow M$ where $M$ is a manifold (which can locally be described with coordinates). So if $x:M\rightarrow \mathbb{R}^m$ is a  coordinate map, then $y:=x\circ f$ is a new coordinate map after the coordinate transformation. One could locally express the new coordinates in terms of the old ones, writing $y=y(x)$. Is that right so far? Now if such a diffeomorphism is applied to all points, it should induce an effect on the metric. Let's say $X,Y$ are vector fields (elements of the module of derivatives over the ring of smooth functions $C^\infty(M)$ over $M$) and $g$ is the metric tensor field (an element of the comodule of the module of vector fields which takes two vector fields back to $C^\infty(M)$) and $p$ is a point of $M$. Then, is it right to say that the diffeomorphism induces the change
\begin{equation}
f^*g(X,Y)|_p = g_p(f_* X_p, f_* Y_p)?
\end{equation}
I have also seen in another post an action defined on all objects as in
\begin{equation}
(f^*)^{(-1)}g(f_* X,f_* Y)|_p = g_p(X_p, Y_p),
\end{equation}
which would mean that any diffeo would leave $g(X,Y)$ invariant? If this is correct, then I am confused here because I don't yet understand why the action should include the inverse of the pull-back? A conformal transformation is defined as a diffeomorphism that leaves the metric invariant up to a an overall factor, meaning that the diffeomorphism induces a pull-back of the metric that is conformally equivalent (equivalent up to an overall factor) to the old one. Does this mean
\begin{equation}
f^*g(X,Y)|_p=g_p(f_* X_p, f_* Y_p)=\Omega(p) g_p(X_p,Y_p)?
\end{equation} In that case, a conformal transformation would be  a coordinate transformation that changes the metric only by an overall factor and is thus also a coordinate transformation? But then a conformal invariance of some theory would not be special anymore in a covariant formulation which confuses me. Thus my understanding of the action of a transformation on the metric and the vector fields is probably wrong at some (or multiple) point(s). Would be great if you could help me to clarify that.","['transformation', 'pullback', 'invariance', 'conformal-geometry', 'differential-geometry']"
2620355,Difference between an ODE and dynamical system?,"I don’t really understand the difference between an ODE and a dynamical system.
The ODE just seems like a way to describe it.
Is there more to it? Are there dynamical systems which cannot be represented by any ODE?","['terminology', 'ordinary-differential-equations', 'dynamical-systems']"
2620360,Combinatorics: number of ways to seat 5 children in a line with rules,"Five children need to be seated into $5$ seats, but Mike won't sit in the middle, and Johnny can't be seated at the edges. Since it is rather manageable to count in how many different ways Mike and Johnny can be placed I've done it ""by hand"" and then multiplied by $3!$ for the remaining children. $m$ is for Mike,
$j$ is for Johnny, $x$ is for the rest $$
\begin{array}{c}
n & \text{s1}  & \text{s2} & \text{s3} & \text{s4} & \text{s5} \\
\hline
1 & m & j & x & x & x \\
2 & m & x & j & x & x \\
3 & m & x & x & j & x \\
4 & x & m & j & x & x \\
5 & x & m & x & j & x \\
6 & x & j & x & m & x \\
7 & x & x & j & m & x \\
8 & x & j & x & x & m \\
9 & x & x & j & x & m \\
10 & x & x & x & j & m \\
\end{array}
$$ Totaling 10 different permutations times $3!$ for the remaining children which can sit at any spot: $10 \cdot  6 = 60.$ How is this problem supposed to be dealt with in a proper, mathematical, fashion ?",['combinatorics']
2620377,Does $(\sum_{i=1}^n a_i^{1.5})^2 - \sum_{i=1}^n a_i \; \sum_{i=1}^n a_i a_{i+1} > 0$ hold for $n \leq 8$?,"Let positive reals $\{a_i\}$, where not all $a_i$ are equal. Does
$$
f(\{a_i\}) = (\sum_{i=1}^n a_i^{1.5})^2 - \sum_{i=1}^n a_i \; \sum_{i=1}^n a_i a_{i+1} > 0
$$
hold for $n \le 8$? It is understood that $a_{n+1} = a_1$. The restriction to $n \le 8$ comes from a known counterexample for $n = 9$ given by Martin R. in this post : $a_i = (40, 37, 40, 50, 60, 65, 65, 56, 47)$. In there, he also gave counterexamples for higher $n$. Further, there is a  proof for $n=3$ in here and Michael Rozenberg has added comments in here that for $n=4$ a solution can be found by $AM-GM$ and in here that for $n=5$, Buffalo Way can produce a solution. From the counterexamples and from numerical experiments, it appears that the solution will have to do with oscillations, so a Fourier series approach might be helpful.","['algebra-precalculus', 'inequality', 'fourier-series', 'rearrangement-inequality']"
2620380,(Conway's Functional Analysis) Why can we assume that $\bigcap_{j\neq k}ker(f_j) \neq \bigcap_{j=1}^n ker(f_j).$,"In Conway's A Course in Functional Analysis , the author stated the following Proposition $1.4$ at page $377.$ Let $X$ be a vector space over $\mathbb{R}.$
  Given $f,f_1,f_2,...,f_n$ are linear functionals on $X.$
  If 
  $$\bigcap_{j=1}^n ker(f_j) \subseteq ker(f),$$
  then there exist scalars $a_1,...,a_n$ such that 
  $$f(x) = \sum_{j=1}^n a_j f_j.$$ The proof starts as follows: It may be assumed that without loss of generality that for $1\leq k\leq n,$
$$\bigcap_{j\neq k}ker(f_j) \neq \bigcap_{j=1}^n ker(f_j).$$ Question: Why can we assume above? 
  In general, we have 
  $$\bigcap_{j\neq k} ker(f_j) \supseteq \bigcap_{j=1}^n ker(f_j).$$
  So in the proof, we can safely assume that the inclusion is strict. 
  If the inclusion is not strict, meaning the two intersections are equal, then 
  kernel of $f_j$ is a subset of kernel of $f_i$ for some $i.$","['functional-analysis', 'proof-explanation']"
2620387,"What is a secant line passing through $P, Q $ in $\mathbb{P}^n_k$?","In Chapter $4$ of Hartshorne, the author gives some propositions about a projection $\mathbb{P}^n_k \backslash \{ O \} \to \mathbb{P}^{n-1}_k $ and secant or tangent lines.
He defines the secant line determined by $P,Q$ to be the line passing through $P,Q$, and the tangent line at $P$ (to a geometrically connected smooth projective scheme $X$ in $\mathbb{P}^n_k$) to be the unique line $L$ in $\mathbb{P}^n_k$ passing through $P$ such that the tangent space of $L$ at $P$ is equal to that of $X$ at $P$, as subspaces of the tangent space of $\mathbb{P}^n_k$ at $P$. Intuitively these definitions are clear, however I can't understand these scheme theoretically. Please help me understand the concrete definition of secant lines and tangent lines.",['algebraic-geometry']
2620388,How do I find this angle?,"Okay, I know the angles next to $115^{\circ}$ are supplementary to it, so the angles are $65^{\circ}$. I subtracted $65$ and $30$ from $180$ to get to measure angle of $85^{\circ}$. How can I find $e$ this way? Do I use alternate or supplementary angles?","['angle', 'geometry']"
2620392,"finding a bijective map from $ F(m,n)\times F(k,n)$ to $F(m+k,n)$","Let $E$ be a complex Hilbert space and $\mathcal{L}(E)$ be the algebra of all bounded linear operators on $E$. For $A=(A_1,...,A_n) \in \mathcal{L}(E)^n$ and $m,k\in \mathbb{N}^*$. I want to show that
    $$\sum_{h\in F(m,n)} A_h^*\left(\sum_{g\in F(k,n)} A_g^* A_{g}\right) A_{h}=\sum_{f\in F(m+k,n)} A_f^* A_{f}\; ??$$
  where $F(m,n)$  the set of all functions $f$ from $\{1,2, ... , m\} $ to the set  $\{1.2...,n\}$. For $g\in F(m,n)$, we set $A_g:=A_{g(1)}\cdots A_{g(m)}$. I try as follows: $$
\sum_{h\in F(m,n)} A_h^*\left(\sum_{g\in F(k,n)} A_g^* A_{g}\right) A_{h}=\sum_{h \in F(m,n), g \in F(k,n)} (A_{g\ast h})^* A_{g \ast h},
$$ where $g \ast h$ is a function from $ F(m,n)\times F(k,n)$ to $F(m+k,n)$. I'm facing difficulties to give the expression of $g \ast h$ in order to show that it is a bijection.","['hilbert-spaces', 'abstract-algebra', 'functions', 'functional-analysis', 'inverse']"
2620406,Question about proof of Stein's Lemma by Casella and Berger,"I am looking at the following proof from Casella and Berger's Statistical Inference. However, I don't understand the final statement. The only condition on $g'$ here is that $E|g'(X)|<\infty$. But how does this ensure that $g(x)e^{-(x-\theta)^2/(2\sigma^2)} \to 0$ as $x \to \pm \infty$?","['statistics', 'probability']"
2620409,Counterexamples showing natural density is not a measure,"Natural density $d$ measures how large a subset of natural numbers is, as defined here . There are some examples showing natural density is not countably summable. For instance, 
$$
0=\sum_{k=0}^\infty d(\{k\}) \neq d(\bigcup_{k=0}^\infty\{k\})=d(\mathbb{N})=1.
$$ However, all those examples I have seen considers sets with zero density. Question: Is there a counterexample (showing that natural density is not countably summable) considers only the sets with density strictly between 0 and 1? That is to find $\sum_{k=0}^\infty d(A_k) \neq d(\bigcup_{k=0}^\infty A_k)$, where all $A_k$ are disjoint and $0<d(A_k)<1$ for all $k$ and $d(\bigcup_{k=0}^\infty A_k)<1$. In other words, can $d$ be a measure if we restrict its domain to all the sets that have density strictly between 0 and 1 and $\mathbb{N}$ and $\emptyset$?","['analytic-number-theory', 'examples-counterexamples', 'number-theory', 'measure-theory', 'elementary-number-theory']"
2620465,Inequality regarding norm of a positive definite matrix,"Prove that $$\sqrt{\frac{a^TA^2a}{a^TAa}}\le \sqrt{\|A\|}$$ where $A$ is a $n \times n$ symmetric positive definite matrix and $a \in \mathbb{R}^n \setminus \{0_n\}$ . The norm of a vector here is the Euclidean norm and norm of a matrix $A$ is $$\|A\|=\max\{\|Ax\|:\|x\|=1\}$$ and if $A$ is symmetric then $$\|A\|=\max\{|x^TAx|:\|x\|=1\}$$ and also equal to the largest eigenvalue of $A$ . We have from this min-max theorem that $$\lambda_{\min}\|x\|^2\leq x^THx \le \lambda_{\max}\|x\|^2$$ where $\lambda_{\min},\lambda_{\max}$ are the smallest and largest eigenvalues of the Hermitian matrix $H$ . So we have $$\sqrt{\frac{a^TA^2a}{a^TAa}}\le \sqrt{\frac{\lambda^2_{\max}}{\lambda_{\min}}}$$ In order to prove the inequality in the question, we need to show that $\frac{\lambda^2_{max}}{\lambda_{\min}}\le \lambda_{\max}$ which implies $\frac{\lambda_{\max}}{\lambda_{\min}}\le 1$ . We have $\|A\|=\lambda_{\max}$ and $\|A^{-1}\|=\frac{1}{\lambda_{\min}}$ but on the contrary it is a fact that $\|A\|\|A^{-1}\|\ge 1$ . Where have I gone wrong and how do we prove this inequality?","['optimization', 'matrices', 'positive-definite', 'matrix-norms', 'linear-algebra']"
2620468,Show the equivalence of arc length definitions,"Definition 1: Let $r: [a,b] \to \Bbb R^d$ be a continuous differentiable function. Then the arc length is given by $$L(r) = \int_a^b || r'(t) || \, dt$$ Definition 2: Let $r: [a,b] \to \Bbb R^d$ be a continuous function. Then the arc length is given by $$ V(r) = \sup_P \sum_{k=1}^n || r(x_k)-r(x_{k-1}) ||$$ where the supremum is taken over all partitions $P = \{a=x_0 \lt x_1 \lt \ldots \lt x_n = b \}$ of $[a,b]$. How can I show that for a continuous differentiable $r(t)$ the two definitions are equivalent, i.e. $L(r)=V(r)$? What I've done so far: I found this question , which shows that I can convert the supremum to a limit $$V(r) = \sup_P \sum_{k=1}^n || r(x_k)-r(x_{k-1}) || = \lim_{n \to \infty} \sum_{k=1}^n || r(x_k)-r(x_{k-1}) ||$$ by choosing an appropriate sequence of partitions $P_n$ of which I take the $x_k$'s. This gives $$ \lim_{n \to \infty} \sum_{k=1}^n || r(x_k)-r(x_{k-1}) || = \lim_{n \to \infty} \sum_{k=1}^n || \frac{r(x_k)-r(x_{k-1})}{x_k-x_{k-1}} || (x_k-x_{k-1})$$ Now I somehow need to show that $$\lim_{n \to \infty} \sum_{k=1}^n || \frac{r(x_k)-r(x_{k-1})}{x_k-x_{k-1}} || (x_k-x_{k-1}) = \int_a^b ||r'(t)|| \, dt$$ How can I justify this step of converting the sum to an intergral and taking the limit of the inside simultaneously?","['curves', 'real-analysis', 'arc-length', 'differential-geometry']"
2620473,"$\tan{A} \cdot \tan{B} \cdot \tan{C}=9$, find $\tan^2{A}+\tan^2{B}+ \tan^2{C}$","In  $\triangle{ABC}$, $$\tan{A}\cdot \tan{B}\cdot \tan{C}=9$$ $$\tan^2{A}+\tan^2{B}+ \tan^2{C}=\lambda$$ then, $\lambda$ lies in the interval?","['trigonometry', 'geometry']"
2620518,Number of non-negative integral solutions of $2x+3y+z=19$,"The question is to find the number of solutions of $2x+3y+z=19$. There are posts like this with answers arrived by counting the possibilities. But I decided to approach it in a different way. My Approach: I learnt a theorem stating that The number of integral solutions of $$a_1x_1+a_2x_2+a_3x_3...+a_nx_n=r$$ is the coefficient of $x^r$ in $$(1+{x}^{a_1}+{x}^{2\cdot{a_1}}+...+{x}^{\left \lfloor{\frac{r}{a_1}}\right \rfloor\cdot{a_1}})\cdot(1+{x}^{a_2}+{x}^{2\cdot{a_2}}+...+{x}^{\left \lfloor{\frac{r}{a_2}}\right \rfloor\cdot{a_2}})...(1+{x}^{a_n}+{x}^{2\cdot{a_n}}+...+{x}^{\left \lfloor{\frac{r}{a_n}}\right \rfloor\cdot{a_n}})$$ (I don't know the name of this theorem) Substituting and reducing the equation, I landed up with finding coefficient of $x^{19}$ in $${\frac{1-x^{20}}{1-x^2}}\cdot{\frac{1-x^{21}}{1-x^3}}\cdot{\frac{1-x^{20}}{1-x}}$$ But, I had no clue of finding that. My doubts: Is there any other relatively elegant way of finding it? (Other than counting or stars and bars - as in here ) If no, how to solve further to get the answer? Thanks in advance...","['combinatorics', 'binomial-coefficients', 'linear-algebra']"
2620577,Conditional Distribution of The Sum of Two Standard Normal Random Variables,"I have a question about conditional Distribution. Let $X,Y\sim N(0,1)$ and independently distributed. Then, let $Z=X+Y$. 
Find the p.d.f and c.d.f of $Z\mid(X>0, Y>0)$. The hint here is to use the circular symmetry of joint density of $X$ and $Y$. No integration needed. My attempt: First, we know that $Z\sim N(0,2)$ then the p.d.f of $Z$ is $f_{Z}(z)=\frac{1}{2\sqrt{\pi}}e^{\frac{-z^{2}}{4}},-\infty<z<\infty.$ Next, we have that: $$F_{Z\mid X>0,Y>0}(z\mid x>0,y>0)=P(Z\leq z\mid X>0,Y>0)=\frac{P(Z\leq z, X>0,Y>0)}{P(X>0,Y>0)}.$$ It follows that by independence: \begin{align}
& F_{Z\mid X>0,Y>0}(z\mid x>0,y>0) = \frac{P(0<Z\leq z)}{P(X>0)P(Y>0)} \\[10pt]
= {} & \frac{F_Z(z)-F_Z(0)}{\frac{1}{4}} = 4F_Z(z)-\frac{4}{2}=4F_Z(z)-2.
\end{align} So, the c.d.f is: $F_{Z\mid X>0,Y>0}(z\mid x>0,y>0)=4F_Z(z)-2$. Then, the p.d.f will be $$f_{Z\mid X>0,Y>0}(z\mid x,y)=4f_Z(z)=\frac{2}{\sqrt{\pi}} e^{\frac{-z^{2}}{4}},0<z<\infty.$$ This is what I got; however, I'm pretty sure I did something wrong since when I integrate the p.d.f over the whole region, it does not give me 1. Any suggestion?","['statistics', 'probability', 'normal-distribution', 'probability-distributions']"
2620600,How to prove differentiability and continuity for piecewise function,"Given the following piecewise function: $f(x)$ \begin{cases} 
      x \sin x & x\ \in \mathbb Q \\
      0 & x \in \mathbb {R/Q} 
   \end{cases}
Prove/Disprove:
a) $f(x)$ is continuous
b) $f(x)$ is differentiable I am having trouble using the Epsilon-Delta definition given that there is always an irrational number between rational numbers, so I'm assumung that I need to construct a sequence that converges to an x $\in \mathbb {Q}$ but these sequences  $(x_{n})_n$ could also theoretically be $\in \mathbb {R/Q}$?","['derivatives', 'continuity', 'analysis']"
2620611,Roots of a polynomial inside the unit circle,"Let $k$ be a even positive integer. Now, consider the polynomial 
$$
p(x)=x^k-px^{k-1}-qx^{k-2}-x^{k-3}-\cdots -x-1,
$$
with $p$ and $q$ integers satisfying $q-1>p\geq 1$. How to prove that this polynomial has k-2 roots inside the unit circle (there are two roots outside this circle by using the Descarte sign rule and the intermediate value theorem). Any suggestion? I tried to use Rouché theorem, but without success.","['complex-analysis', 'calculus']"
2620616,What is the difference between $x$ and $\{x\}$ when $x$ itself is a set?,"I've already asked this a part of another question, but thought it'd be easier to elaborate a bit more on my concern. Let $x$ be a set. What is the difference between $x$ and $\{x\}$? I get that the latter is a set consisting of a single element - namely $x$, but what is the difference? For example, we can have $x$ to be the set $\{1\}$, then $\{x\}=\{\{1\}\}$. Aren't those $2$ expressions the same? Another problem are the brackets - when we have a set, do we always have to surround him with brackets, for instance, can we have $x$ to be the set $2$? Thanks a lot","['notation', 'elementary-set-theory']"
2620658,Finding the interval of definition of an ODE solution: $x'(t)=\frac{x^2-1}{2}$.,"This is the first exercise of my ODE notes, so I'd like you to check if my approach is correct or not. Find the maximum interval of definition of the solutions: $\dot{x}=\frac{x^2-1}{2}, \ \ x(t_0)=x_0.$ My approach: I found the solution of this ODE. They're of the form: $$x(t)=\frac{-e^{c_1+t}-1}{e^{c_1+t}-1}.$$ Now we take the denominator and equal it to $0$ to see what points are not in the domain. We see that $${e^{c_1+t}-1}=0 \implies t=-c_1.$$ So we have a vertical asymptote on $x(c_1)$ in every solution considered. Therefore, the interval is $$(c_1,\infty)\ \ if \ \ c_1>0$$ $$(-\infty,c_1)\ \ if \ \ c_1<0$$ $$(c_1,\infty)\ \ or \ \ (-\infty,c_1) \ \ if \ \ c_1=0.$$ Is my approach correct? Thanks for your time.","['derivatives', 'integration', 'ordinary-differential-equations', 'calculus']"
2620661,How to prove that $\sum _{p}\sum_{k = 2}^\infty \frac{1}{kp^k}$ is convergent?,How to prove that $\sum _{p}\sum_{k=2}^\infty \frac{1}{kp^k}$ is convergent? where $p$ is prime. What I have done is $$\sum_{k = 2}^\infty \frac{1}{kp^k}=-\log\left(1-\frac 1p\right)-\frac 1p $$ Then for $\sum _{p}(-\log(1-\frac 1p)-\frac 1p) $ I was trying to use integral test after putting $n\in \Bbb N$ in place of $p$. But I was not getting my desired result. Please help.,"['analytic-number-theory', 'real-analysis', 'number-theory', 'sequences-and-series', 'analysis']"
2620675,Is a compact set with respect to the product topology measurable?,"Let $X_1,...,X_n$ be metrizable spaces. Let $\Sigma_i$ be a $\sigma$-algebra on $X_i$ such that every compact subset of $X_i$ is an element of $\Sigma_i$, for each $i$. Then, is every compact subset of $\prod_{i=1}^n X_i$ an element of $\otimes_{i=1}^n \Sigma_i$?","['real-analysis', 'measure-theory']"
2620676,How Turing instability explains the patterns present on the animal skin?,"Alan Turing in his original paper presents the following system of differential equations: $\frac{\delta X_r}{\delta t} = f(X_r, Y_r) + \mu(X_{r+1} -2X_r + X_{r-1})$ $\frac{\delta Y_r}{\delta t} = g(X_r, Y_r) + v(Y_{r+1} - 2Y_r + Y_{r-1})$ for $r \in \{0, ..., N-1\}$ He talks about N cells forming a ring and each cell having two morphogens X and Y. $X_r(t)$ and $Y_r(t)$ are the concentrations of those morphogens in the r-th cell. Then he reasons that under certain conditions the equilibrium state $f(X_r, Y_r) = g(X_r, Y_r) = 0$ is unstable and thus $X_r(t)$ as well as $Y_r(t)$ quantities will deviate in time. This is called the Turing instability. Finally, because of the Turing instability, the animal skin can have many interesting patterns, such as stripes, spots, etc. My questions: 1) Do I understand this correctly? 2) How to relate those differential equations to the animal skin pattern? 3) Could one assume that the concentration of the chemical $X_r$ is proportional to the ""intensity"" of the cell colour? Thus, those cells for which $X_r$ is high will be black, others white, and that's how the colour pattern is formed? 4) If (3) is assumed, then the pattern of the animal skin is eventually formed, thus each $X_r$ settles down to some fixed value. I.E. eventually $\frac{\delta X}{\delta t} = 0$. So does it mean that the system reaches another fixed state $\frac{\delta X_r}{\delta t} = 0$ and $\frac{\delta Y_r}{\delta t} = 0$ that is stable this time? 5) The example assumes N cells forming a ring. How to relate this to a skin, for which a plane (rather than a ring) looks like a better representation?","['partial-derivative', 'ordinary-differential-equations', 'biology']"
2620731,Is it possible to create a function that's onto but not 1-1 between two sets with the same cardinality?,"Given two sets, $S = \{1, 2, 3\}$ and $T = \{a, b, c\}$ is it possible to create a function $F:S\rightarrow T$ that is onto but not one to one? It seems like the only way to do this would be not to use all the elements in $S$, but then it wouldn't be a function.",['discrete-mathematics']
2620761,Find radical of ideal using algebraic set,"I want to find the radical of the ideal $I=(y-x^2,y^2)$ in $\mathbb{C}[x,y]$. The vanishing points of the first polynomial are $V(y-x^2)$ the parabola $y=x^2$ in $\mathbb{C}$ and $V(y^2)=0\in \mathbb{C}$. But I'm not sure how to connect these two together. Then I can just apply Hilbert's theorem since $\mathbb{C}$ is algebraically closed.",['algebraic-geometry']
2620762,Finite groups with 15 or 16 conjugacy classes [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How can I classify all almost simple groups with 15 or 16 conjugacy classes? A finite group $G$ is almost simple if there is a non-abelian simple group $S$ such that $S\trianglelefteq G\leq \operatorname{Aut}(S)$. We know that groups with at most 12 conjugacy classes are given in the paper ""A. Vera López and J. Vera López, Classification of finite groups according to the number of conjugacy classes I, II, Israel J. Math."". Is there a GAP program to compute groups with 15 or 16 conjugacy classes?","['finite-groups', 'group-theory', 'gap', 'simple-groups']"
2620794,Relating the union of the power set of a set to the set itself,"I'm pretty sure I've asked way too many questions on sets already(still, a big thanks to everyone who helped) and even though I'm starting to see what's going on there are still some issues, for example this question: Prove that $\bigcup P(X)=X$, where $P(X)$ is the power set for the set $X$ So, what I can do is the following: $a \in \bigcup P(X) \implies \exists b \subset X$ s.t. $a\in b \implies a \in X$ and for the other direction I can take $b=X$. However, I'm not sure whether this is correct, and in particular, the bit with $b \subset X, a\in b \implies a \in X$ If I take $X=\{\{1\},\{2\}\}$, then $P(X)=\{\emptyset,\{1\},\{2\},\{\{1\},\{2\}\}\}$, hence $\bigcup P(X)=\{1,2,\{1\},\{2\}\}$ which is not equal to $X$ by ZF$1$ Where's the problem? Thanks",['elementary-set-theory']
2620811,Find the largest term of the sequence $a_n=\sqrt[n]{n}$,Find the largest term of the sequence $a_n=\sqrt[n]{n}$. By simple calculation: $$a_1= 1$$ $$a_2=1.41$$ $$a_3=1.44$$ $$a_4=1.41$$ $$a_5=1.37$$ $$a_6=1.348$$ $$\quad\vdots$$ After that the sequence seems to be pretty much decreasing and $$\lim_{n\to \infty}{\sqrt[n]{n}}=1$$ This way it looks like $a_3$ is the largest term however there is no official proof behind this. What's the usual way to approach such problems?,"['radicals', 'real-analysis', 'optimization', 'logarithms', 'sequences-and-series']"
2620829,Expected value of negative and positive part of a random variable,"We have $M_n=\max\left\{X_1,\ldots,X_n\right\}$ where $X_i\sim \exp(1)$ iid , where the cdf of $M_n$ is $(1-e^{-x})^n$.And I want to prove that $$\lim_{n\rightarrow \infty}\mathbb{E}[(M_n-\ln n)^{+}]=\int_0^\infty 1-e^{-e^{-t}} \, dt$$ $$\lim_{n\rightarrow \infty}\mathbb{E}[(M_n-\ln n)^{-}]=\int_0^\infty e^{-e^{-t}} \, dt$$ So first I try to find the dsitribution of $(M_n-\ln n)^{+}$ $$\mathbb{P}[(M_n- \ln n)^{+}\leq x] = \begin{cases}
0 &  M_n-\ln n<0\\ 
\mathbb{P}[M_n-\ln n] & M_n-\ln n>0
\end{cases}=\begin{cases}
0 &  M_n-\ln n<0\\
\left(1-\frac{e^{-x}}n\right)^n & M_n-\ln n>0
\end{cases}$$ Then $$\lim_{n\rightarrow \infty}\mathbb{E}[(M_n-\ln n)^{+}]=\lim_{n\rightarrow \infty}\int_0^\infty xe^{-x}\left(1-\frac{e^{-x}} n \right)^{n-1}\,dx=-\int_0^\infty e^{-e^{-x}} \, dx$$ Same calculation for the negative part , but I'm not getting the correct result .There has to be a mistake , but I dont know what I did wrong.","['probability-theory', 'probability']"
2620871,An intriguing distance-like invariant,"I recently came across the following property while setting up problems for a discrete mathematics course. It is not too hard to prove it by induction, but I am wondering whether there is more to it - that is, a somewhat deeper reason why this holds. Take the set of integers from $1$ to $2n$ and split it into two disjoint subsets $A$ and $A^c$ of equal size $n$. Then, consider the distance $|M_A-m_{A^c}|$ between $A$'s largest element $M_A$ and ${A^c}$'s smallest element $m_{A^c}$. Remove $M_A$ and $m_{A^c}$ from $A$ and ${A^c}$ respectively and iterate until both sets are empty. Fact: The sum of all distances thus computed is equal to $n^2$, regardless of the choice of $A$. Example: $n=3$, $A=\left\lbrace 1,4,5 \right\rbrace$, $A^c=\left\lbrace 2,3,6 \right\rbrace$ $$|5-2|+|4-3|+|1-6|=9=3^2.$$ Question(s): are there deeper reasons for this to hold than a mere
  induction? Is this related to another combinatorial problem?","['combinatorics', 'recreational-mathematics', 'integers', 'reference-request']"
2620924,prerequisite for reading characteristic classes,"Can some one tell me what are the prerequisites for learning characteristic classes as they are in book Foundations of Differential geometry by Kobayashi and Nomizu. I only read first two chapters of that book which covers details about principal bundles and connections on principal bundles. I started reading this chapters on characteristic classes. It starts section on chern classes saying that We consider the category of differential complex vector bundles over differentiable manifolds. But they have not given so many details about complex vector bundles in any of previous chapters. So, I am not able to understand anything about this characteristic classes. Any suggestion on references for complex vector bundles is welcome. I have seen Kobayashi’s another book On complex vector bundles. He never explains in detail what they are in that book as well. If you think any other prerequisites are necessary for this, do let me know.","['characteristic-classes', 'reference-request', 'differential-geometry']"
2620986,"Proof verification : $n\cdot \int_{0}^{1} x^n \cdot f(x) \, \mathrm{d}x\underset{n\to+\infty}{\longrightarrow}f(1) $","Let $f: [0, 1] \rightarrow \mathbb{R}$ a continuous function. Proove that : 
$$n\cdot \displaystyle \int_{0}^{1} x^n \cdot f(x) \, \mathrm{d}x\underset{n\to+\infty}{\longrightarrow}f(1) $$ I would like to know if what I've done is correct, because my book's solution isn't the same at all and seems more complicated. Using Riemann sum we know that : $\displaystyle \lim_{n \rightarrow \infty}\int_{0}^{1} x^n \cdot f(x) \mathrm{d}x = \lim_{n \rightarrow \infty}\frac{1}{n}\cdot\sum_{i = 0}^{n} g(\frac{i}{n})$ where $g(x) = x^n \cdot f(x)$.
Hence : $\displaystyle \lim_{n \rightarrow \infty} n\cdot\int_{0}^{1} f(x) \cdot x^n \mathrm{d}x = \lim_{n \rightarrow \infty}\sum_{i = 0}^{n}g(\frac{i}{n})$
Yet note that for all $x \in [0, 1[$ $\displaystyle \lim_{n \rightarrow \infty} x^n\cdot f(x) = 0$ and for $x = 1$ we have $g(1) = f(1)$. Thus : $\displaystyle \lim_{n \rightarrow \infty} n\cdot\int_{0}^{1} f(x) \cdot x^n \mathrm{d}x = f(1)$","['real-analysis', 'proof-verification', 'proof-writing', 'integration', 'definite-integrals']"
2621075,Projection from algebraic variety is surjective,"Let $k \subseteq K$ be a field extension and $X$ a $k-$algebraic variety. Is it true that the projection $X_K = X \times_{\mathrm{Spec}k} \mathrm{Spec} K \to X$ is surjective? Since I don't know what the underlying topological space of $X_K$ is, I am finding it difficult to do anything... Another (possibly related) question: is it true that $\mathcal{O}_{X_K}(U_K) = \mathcal{O}_{X}(U) \otimes_k K$ for all open subsets $U \subseteq X$? I think this should hold for affine subsets, but I am not sure whether it is true in general...","['schemes', 'algebraic-geometry']"
2621082,Stuck in Tao’s proof for Kolmogorov extension theorem,"I’m reading Tao’s article: https://terrytao.wordpress.com/tag/kolmogorov-extension-theorem/ I am stuck in the proof for Kolmogorov extension theorem (Theorem 62). Let $\{((X_\alpha,\mathscr{B}_\alpha),\mathscr{F}_\alpha)\}_{\alpha\in A}$ be a family of measurable spaces $(X_\alpha,\mathscr{B}_\alpha)$ equipped with a topology $\mathscr{F}_\alpha$ For each finite $B\subset A$, let $\mu_B$ be an inner regular probability measure on $\mathscr{B}_B:=\prod_{\alpha\in B} \mathscr{B}_\alpha$ with the product topology $\mathscr{F}_B:=\prod_{\alpha\in B} \mathscr{F}_\alpha$. Assume that $(\pi_{C\leftarrow B})_*\mu_B=\mu_C$ whenever $C\subset B\subset A$ are two nested finite susbsets of $A$. Let $\mathscr{B}_0$ be the set of all subsets of $X_A$ that are of the form $\pi_B^{-1}(E_B)$ for some finite $B\subset A$ and some $E_B\in \mathscr{B}_A$. Define $\mu_0(E):=\mu_B(E_B)$ whenever $E$ takes the form $\pi^{-1}_B(E_B)$ for some finite $B\subset A$ and $E_B\in \mathscr{B}_B$. By the compatibility condition, this $\mu_0$ is well-defined. Let $\{F_n\}$ be a decreasing sequence in $\mathscr{B}_0$ such that $\bigcap_n F_n=\emptyset$. Suppose $\lim_{n\to\infty} \mu_0(F_n)>0$. Then, there exists $\epsilon>0$ such that $\mu_0(F_n)>\epsilon$ for all $n$. As each $F_n$ lies in $\mathscr{B}_0$, we have $F_n=\pi^{-1}_{B_n}(G_n)$ for some finite sets $B_n\subset A$ and some $\mathscr{B}_{B_n}$-measurable sets $G_n$. By enlarging each $B_n$ as necessary we may assume that the $B_n$ are increasing in $n$. The decreasing nature of the $F_n$ then gives the inclusion $G_{n+1}\subset \pi^{-1}_{B_n\leftarrow B_{n+1}}(G_n)$. By inner regularity, one can find a compact subset $K_n$ of each $G_n$ such that $\mu_{B_n}(K_n)\geq \mu_{B_n}(G_n)-\epsilon/2^{n+1}$. Define $K_n’:= \bigcap_{m=1}^n \pi_{B_m\leftarrow B_n}^{-1}(K_m)$. Then we see that each $K_n’$ is compact and $\mu_{B_n}(K_n’)\geq \mu_{B_n}(G_n)-\epsilon/2^n\geq \epsilon - \epsilon/2^n$ I do not get where this first inequality comes from. I also checked Tao’s book “An introduction to measure theory” and here he defines $K_n’$ as the union instead of intersection . However, this again does not make sense because $K_n’$ need not be compact in this case..","['real-analysis', 'probability-theory', 'proof-verification', 'measure-theory', 'proof-explanation']"
2621113,Is a system of ODEs solvable if the coefficient matrix has determinant zero?,"Pardon the simple question, but my memory's failing me on this, and I can't seem to find any answers. I have a system of differential equations, with a coefficient matrix that looks like this, where a, b, and c are constants: \begin{bmatrix}
 0& 1& 0& 0& 0& 0\\ 
 0& 0&-a& 0& b& 0\\ 
 0& a& 0& 0& 0& c\\ 
 0& 0& 0& 0& 0& 0\\ 
 0& 0& 0&-1& 0&-a\\ 
 0& 0& 0& 0& a& 0
\end{bmatrix} Now, it's pretty obvious to see that the coefficient matrix has a zero determinant (expand over the first column).  Does this mean that the system is unsolvable?  If so, what can I do to make it solvable?","['matrices', 'ordinary-differential-equations', 'systems-of-equations']"
2621135,The diagonal extraction procedure?,"What do we mean by "" The diagonal extraction procedure "" in the extraction of sequence in the following proof taking from: http://leonard.perso.math.cnrs.fr/papers/Leonard-Orlicz%20spaces.pdf Thank you","['banach-spaces', 'partial-differential-equations', 'functional-analysis', 'orlicz-spaces', 'analysis']"
2621211,Proving a tautology using logical equivalences,Can somebody show me how can I prove that this proposition is a tautology using logical equivalences? $\lnot p \land (p \lor q) \to q$ I already did: $\lnot(\lnot p \land (p \lor q)) \lor q \quad$        definition of the arrow $(\lnot\lnot p \lor \lnot(p \lor q)) \lor q$ But at this point if I continue following this path I'll reach a dead end...,"['propositional-calculus', 'logic', 'discrete-mathematics']"
2621255,Prove that $\frac{1}{\epsilon}\int_{\mathbb{R}}f(t).\exp\left(\frac{-\pi(x-t)^2}{\epsilon^2}\right)dt \xrightarrow{\epsilon \to 0}f(x) $,"Prove that, for any $x \in \mathbb{R}$ and $f \in (L^1\cap C)(\mathbb{R})$,
  $$\frac{1}{\epsilon}\int_{\mathbb{R}}f(t).\exp\left(\frac{-\pi(x-t)^2}{\epsilon^2}\right)dt \xrightarrow{\epsilon \to 0}f(x) $$ By substituting $u=\frac{\sqrt{\pi}}{\epsilon}(t-x)$, we get $du=\frac{\sqrt{\pi}}{\epsilon}dt$ and 
\begin{align*}
\int_{\mathbb{R}}\exp\left(\frac{-\pi(x-t)^2}{\epsilon^2}\right)dt=\frac{\epsilon}{\sqrt{\pi}}\int_{\mathbb{R}}\exp\left(-u^2\right)du=\epsilon\\
\end{align*}
Therefore
\begin{align*}
\frac{1}{\epsilon}\int_{\mathbb{R}}f(t).\exp\left(\frac{-\pi(x-t)^2}{\epsilon^2}\right)dt-f(x)\\
&=\frac{1}{\epsilon}\int_{\mathbb{R}}(f(t)-f(x))\exp\left(\frac{-\pi(x-t)^2}{\epsilon^2}\right)dt\\
&=\frac{1}{\sqrt{\pi}}\int_{\mathbb{R}}\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right)\exp\left(-u^2\right)du\\
\end{align*}
Suppose that $f$ is compactly supported. Let $[-a,a]$ be the compact support for $f$. Since $f$ is continuous, given $\eta > 0$, there exists $\delta > 0$ such that whenever $|h| < \delta$, we have $|f(x+h)-f(x)| < \eta$. For all $\epsilon < \frac{\sqrt{\pi}\delta}{2a}$, we have $\left|\frac{\epsilon}{\sqrt{\pi}}u+x-x\right|=\frac{\epsilon |u|}{\sqrt{\pi}} < \frac{\epsilon 2a}{\sqrt{\pi}} < \delta$ giving us $\left|f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right|< \eta$. Hence, for all $\epsilon < \frac{\sqrt{\pi}\delta}{2a}$
\begin{align*}
\left|\frac{1}{\epsilon}\int_{\mathbb{R}}f(t).\exp\left(\frac{-\pi(x-t)^2}{\epsilon^2}\right)dt-f(x)\right|&\le \frac{1}{\sqrt{\pi}}\int_{\mathbb{R}}\left|\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right)\right|\exp\left(-u^2\right)du\\
&\le\eta\frac{1}{\sqrt{\pi}}\int_{\mathbb{R}}\exp(-u^2)du=\eta\\
\end{align*}
Now, since compactly supported functions are dense in $L^1$, for any function $f \in L^1$, there exists a compactly supported function $h $ such that $\|f-h\|_1 < \frac{\eta\sqrt{\pi}}{3}$. Therefore, $$\left|\frac{1}{\epsilon}\int_{\mathbb{R}}f(t).\exp\left(\frac{-\pi(x-t)^2}{\epsilon^2}\right)dt-f(x)\right|$$
$$\le
 \frac{1}{\sqrt{\pi}}\int_{\mathbb{R}}\left|\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-h\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)\right)\right|\exp\left(-u^2\right)du$$
$$+\frac{1}{\sqrt{\pi}}\int_{\mathbb{R}}\left|\left(h\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-h(x)\right)\right|\exp(-u^2)du+\frac{1}{\sqrt{\pi}}\int_{\mathbb{R}}|h(x)-f(x)|\exp(-u^2)$$ I can make the first two integrals small. I am not able to make the third integral small. I am yet to use that $f$ is continuous. There is a way to do this problem using Dominated Convergence Theorem. I don't want to do that. (Using Hint) Let $g \in L^1(\mathbb{R})$. Let $E_n=[-n,n]$. Then $E_n \subset E_{n+1}$ for all $n$ and $\mathbb{R}=\cup_{n=1}^{\infty}E_n$. Therefore $$\int_{\mathbb{R}}|g|d\mu=\lim_
{n \to \infty}\int_{E_n}|f|d\mu$$ Let $\eta \gt 0$. Then there exists $n_0 \in \mathbb{N}$ such that for all $n \ge n_0$, we have $$\left|\int_{\mathbb{R}}|g|d\mu-\int_{E_n}|g|d\mu\right|\lt \eta \implies \left|\int_{|x| \gt n}|g(x)|d\mu \right| \lt \eta$$ 
Since $f, e^{-u^{2}} \in L^1(\mathbb{R})$, there exists $n_0 \in \mathbb{N}$ such that for all $n \ge n_0$, we have $\int_{|u| \gt n}|f(u)|du \lt \frac{\sqrt{\pi}\eta}{4}$ and $\int_{|u| \gt n}e^{-u^2}du \lt \frac{\sqrt{\pi}\eta}{4|f(x)|}$. ` Now $$\frac{1}{\sqrt{\pi}}\int_{\mathbb{R}}\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right)\exp\left(-u^2\right)du=\frac{1}{\sqrt{\pi}}\int_{|u| \le \frac{1}{\sqrt{\epsilon}}}\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right)\exp\left(-u^2\right)du+\frac{1}{\sqrt{\pi}}\int_{|u| \gt \frac{1}{\sqrt{\epsilon}}}\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right)\exp\left(-u^2\right)du$$
Since $f$ is continuous at $x$, there exists a $\delta \gt 0$ such that whenever $|h| \lt \delta$, we have $|f(x+h)-f(x)| \lt \frac{\eta}{2}$.
Thus, for $\epsilon \lt \pi\delta^2$, whenever $|u| \lt \frac{1}{\sqrt{\epsilon}}, |x+u\frac{\epsilon}{\sqrt{\pi}}-x| \lt \frac{\sqrt{\epsilon}}{\pi} \lt \delta$ and 
\begin{align*}
\frac{1}{\sqrt{\pi}}\left|\int_{|u| \le \frac{1}{\sqrt{\epsilon}}}\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right)\exp\left(-u^2\right)du\right|\\&\le \frac{1}{\sqrt{\pi}}\int_{|u| \le \frac{1}{\sqrt{\epsilon}}}\left|\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right)\right|\exp\left(-u^2\right)du\\
&\le \frac{\eta}{2}\frac{1}{\sqrt{\pi}}\int_{|u| \le \frac{1}{\sqrt{\epsilon}}}e^{-u^2}du&(\text{ using continuity of f})\\
&\lt \frac{\eta}{2}\\
\end{align*}
For $\epsilon \lt \frac{1}{n_0^2}, |u| \gt \frac{1}{\sqrt{\epsilon}} \gt n_0$ and $\left\{|u| \gt \frac{1}{\sqrt{\epsilon}}\right\} \subset \{|u| \gt n_0\}$. Therefore,
\begin{align*}
\frac{1}{\sqrt{\pi}}\left|\int_{|u| \gt \frac{1}{\sqrt{\epsilon}}}\left(f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)-f(x)\right)\exp\left(-u^2\right)\right|du\\ &\le \frac{1}{\sqrt{\pi}}\int_{|u| \gt \frac{1}{\sqrt{\epsilon}}}\left|f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)\right|du
+\frac{1}{\sqrt{\pi}}|f(x)|\int_{|u| \gt \frac{1}{\sqrt{\epsilon}}}e^{-u^2}du\\
&\le\frac{1}{\sqrt{\pi}}\int_{|u| \gt n_0}\left|f\left(\frac{\epsilon}{\sqrt{\pi}}u+x\right)\right|du
+\frac{1}{\sqrt{\pi}}|f(x)|\int_{|u| \gt n_0}e^{-u^2}du\\
&\le \frac{\eta
}{2}\\
\end{align*}
Thus, for $\epsilon \lt \min\{\pi\delta^2,\frac{1}{n_0^2}\}$, we have the claim. Thanks for the help!!","['dirac-delta', 'real-analysis', 'integration', 'measure-theory']"
2621277,"$\int_0^1 \int_0^{1-y} \cos\Big( \frac{x-y}{x+y} \Big) \, dx dy$ [duplicate]","This question already has answers here : How to get the interval after change of variables? (2 answers) Closed 6 years ago . Reviewing old homework sets for a class and I came across this integral: $$\displaystyle \int_0^1 \int_0^{1-y} \cos\Big( \frac{x-y}{x+y} \Big) \; dx dy,$$ which the question suggests to evaluate using a change of coordinates; however, I haven't a clue where to begin to identify a useful change of coordinates. I tried $u = x-y$ and $v = x+y$, but then wasn't sure how I'd convert the domain of integration. After that, I looked to the given limits for inspiration and noticed that $0<x<1-y$ could be rewritten $y < x+y < 1$, so tried $u = x+y$ and $v = y$, which yielded $$\displaystyle \int_0^1 \int_y^{1} \cos\Big( \frac{ u - 2y }{u} \Big) \; du\,dy,$$ but that doesn't seem any simpler than the original, to me. Any advice would be appreciated!","['multivariable-calculus', 'change-of-variable', 'definite-integrals']"
2621302,Bad Luck Protection (Probability question from playing a video game) [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 years ago . Improve this question So this is a probability/statistics problem that I got from playing a video game called World of Warcraft. I only have a basic knowledge of probability and statistics so I was wondering if anyone could help me to a solution. Basically in the video game there are ""legendaries"" that you can acquire based on a hidden probability. Every time you partake in an activity, you get a chance of getting a ""legendary"". There is a set number of legendaries but having more or less does not affect the chances. On top of that you can only acquire one legendary at a time. The makers of World of Warcraft implemented a system called ""Bad Luck Protection"" that basically ""protects"" people from having extremely bad luck and long periods between getting legendaries. Every activity you do without getting a legendary increases your chances until you finally get one and the probability resets back to the original value. Now there are multiple activities you can do to get a chance at these legendaries but each one gives a different amount of bad luck protection. My primary goal is to find out how one can calculate how much each activity gives in terms of bad luck protection. I would be given a lot of data that lists how many of each activity a player took part in before they got a legendary. Again I'd like to reiterate that I am not great at probability and I'm not even sure there exists an algorithm to solve this problem but really wanted to ask somebody. Thank you!","['statistics', 'probability', 'statistical-inference']"
2621369,Circle inversion and the Pappus chain paradox,"As is well-known, lines and circles are converted into lines and circles by circle inversion, or by any Möbius transformation for that matter. What bothers me is what happens in the Pappus's classical construction of a chain of circles inscribed into a region between two tangent circles (so-called Archimedes's arbelos). One can apply a strategic circle inversion that converts this region into a strip between two parallel lines (see the first image on Mathhelp's Pappus Chain and below). Naturally, the inscribed circles are inverted into a vertical stack of circles inscribed into the strip, and their centers lie on its midline. The trouble is that the centers of the original Pappus chain circles lie on an ellipse (this is easy to show using its focal property, see e.g. Wikipedia's Pappus Chain ). Since the inversion is involutive it would seem that it inverted a line into an ellipse?! I am probably missing something very simple but I am not sure what. Is it that circle centers are not inverted into circle centers? Where does this ellipse go then?","['circles', 'transformation', 'mobius-inversion', 'geometry']"
2621372,Does a closed form formula for the series $\sum\limits_{n = 1}^N {\frac{{1 + {x^{2n - 1}}}}{{1 + {x^{2n + 1}}}}}$ exist?,Does a closed form formula exist for the following series? $\sum\limits_{n = 1}^N {\frac{{1 + {x^{2n - 1}}}}{{1 + {x^{2n + 1}}}}}$,"['sequences-and-series', 'closed-form']"
2621389,Is there a neat way to see that $C_3$ is not a quotient of $S_n$?,"Well, we know all normal subgroups of $S_n$, including the interesting case $n=4$. Using this one can conclude that the cyclic group of order 3 is not a quotient of $S_n$. Is there are more direct way to see this? $C_3$ is simple, so if there were a surjective homomorphism from $S_n$ onto $C_3$, its kernel would be a maximal subgroup of index 3. The alternating group is also maximal as it has index 2. Can we combine these two fact together to get a contradiction?","['finite-groups', 'group-theory']"
2621392,Confused by logarithmic properties,"So I've been watching a Khan Academy video that got me confused and I really want to close my gaps so bear with me. I hope that I can understand why I'm failing to understand this.
So here are the steps: 
$$\log_2 \sqrt \frac{32}{\sqrt8}$$
$$log_2(\frac{32}{\sqrt8})^\frac{1}{2}$$
Here comes my question : How can the exponent (from the second step) be put out of the parentheses? Wouldn't this indicate that = $\frac{1}{2}$ to the power of both $32$ and sroot of $8$, which wouldn't be correct because we only un-rooted $32$, not $8$. Continuing: 
$$\frac{1}{2}(log_2(\frac{32}{\sqrt8})$$
$$\frac{1}{2}(log_2{32}-log_2{\sqrt8})$$
Second confusion is at this next step:$$\frac{1}{2} (log_2{32}-\frac{1}{2}log_28)$$
Here I get completely confused because I thought we should either do this instead:$\frac{1}{2} (log_2{32})-\frac{1}{2} (log_28)$ or this:$\frac{1}{2} log_2{32}-\frac{1}{2} log_28$ so any explanation would be a relief. The lasts steps (which I do understand except the $\frac{1}{4}$ but thats because confusion number 2: $$Distributing: \frac{1}{2}log_2{32}-\frac{1}{4}log_2{8}$$
$$=\frac{5}{2}-\frac{3}{4}$$ Video for reference: https://www.youtube.com/watch?v=TMmxKZaCqe0 (Last part of the vid, from around minute 8:00 to around 9:58) Thanks in advance!","['algebra-precalculus', 'logarithms']"
2621396,Why do we care if a set forms a basis?,"I am taking an advanced linear algebra course and am once again confused by a lot of the concepts. I understand that the definition of a basis is a set of vectors that spans the vector space and is linearly independent. Can anyone provide any intuition on why this matters? I can visualize (kind of) what it means for a set to span a vector space, and I understand (from regression analysis) why it is important that vectors are linearly independent, but I don't really understand why it matters if they are both, ie why it matters if they form a basis. For reference I am an undergraduate interested in statistics and data analysis. I have taken courses in mathematical statistics, regression analysis and am currently enrolled in time series analysis. I am somewhat familiar with PCA. Any intuition that can be provided through any of those lenses would be much appreciated.","['regression', 'statistics', 'linear-algebra', 'change-of-basis']"
2621442,Characterization of log-concavity based on the MGF or characteristic function?,"Is there any characterization of log-concavity (of probability distributions) in terms of the moment-generating function or characteristic function? Specifically, I want to prove some random variable (real-valued) has a log-concave distribution. However, finding the pdf is a mess; but the MGF $M_X$ of $X$ is rather nice. Is there some property of $M_X$ which would imply log-concavity of (the distribution of) $X$?","['reference-request', 'probability-theory', 'probability-distributions']"
2621446,"Is the Fourier series always the ""best"" approximation?","In Stein and Sharkachi's Introductory Fourier Analysis book, in Chapter 3, we're given the ""Best Approximation Theorem"". The theorem implies (and almost states) that if $f \in L^2 (0,2\pi)$ , then the ""best"" way to approximate $f$ by a sequence of trigonometric polynomials is precisely by the partial sums of its Fourier series. Rigorously speaking,  if $a_N(\theta) = \sum_{|n| \leq N} b_n e^{in\theta}$ is any other sequence of trigonemtric polynomials, then $$||f-S_N(f)||_{L^2} \leq ||f-a_N||_{L^2} $$ My question is the following, is this true in any other norms? The most natural norms would to start with would be , of course, the $L^p$ norms.  I'm just curious how ""canonical"" are Fourier series in the approximation .","['fourier-series', 'fourier-analysis', 'measure-theory']"
2621521,why such a point exists?,"Given oval $$O: \frac{x^2}6+\frac{y^2}3=1$$ and point $A (2,1)$ on it, draw two lines $l_1$, $l_2$ passing through  $A$ s.t. the slopes satisfy $k_1k_2=2$, let $l_1$ and $l_2$ intersect with $O$ at $B$ and $C$, then line $BC$ always pass point $D(\frac{10}3, -\frac{5}3)$. My question is, why such a point $D$ exists? what's the relationship between $A$ and $D$?","['analytic-geometry', 'conic-sections', 'geometry']"
2621567,How to solve the limit of $\ln(x \sin x)$ as $x$ approaches $0$?,"I have a limit: $$k = \lim_{x\to0+} \ln(x \sin x)$$ How do I find this? Since $\ln(x)$ is continuous I tried: $$k = \ln( \lim_{x\to0+}  (x \sin x))$$ $$k = \ln(0)$$ Which to my understanding is undefined, but the answer is $-\infty$ somehow. Where did I go wrong?","['logarithms', 'calculus', 'limits']"
2621575,"Proof of theorem 7.7.1. in Lars Hormander's ""The Analysis of Linear Partial Differential Operators I""","I have been trying to understand this proof for a while but I just can't follow what the author writes. If anyone can either explain Hormander's proof or has an alternate proof I would highly appreciate it. THEOREM 7.7.1. Let $K\subset\mathbb{R}^n$ be a compact set, $X$ an open neighborhood containing $K$ and $j, k$ non-negative integers. If $u\in C^{k}_c(K), f\in C^{k+1}(X)$ and $\Im[f]\geq 0$ in $X$ then for all $w > 0$,
  $$
w^{j+k}\left\lvert \int u(x)\left(\Im[f(x)]\right)^j e^{iwi(x)} dx \right\rvert
\leq C \sum_{\lvert\alpha\rvert \leq k}\sup\lvert D^\alpha u\rvert \left(\lvert f^\prime\rvert^2 + \Im[f]\right)^{\lvert{\alpha}/2-k}
$$ Proof available here In the statement of the theorem the author also mentions that ""$C$ is bounded when $f$ stays in a bounded set in $C^{k+1}(X)$"". I am not sure what he means by that. What exactly does the constant $C$ depend on? The proof makes sense to me until equation (7.7.3). Note that the supremum is outside of the sum, so how did the author use the induction hypothesis? I also don't see how equation (7.7.4) follows from the lemma. On the top of page 218, how is the inequality
$$
N\lvert{u_\nu}\rvert_\mu \leq C\left(\lvert{N}_1\lvert{u_\nu}\rvert_{\mu-1}\dots \lvert{u_\nu}\rvert_0\right)
$$
obtained? Finally, how does (7.7.6) follow from (7.7.5)?","['real-analysis', 'partial-differential-equations', 'asymptotics', 'proof-explanation', 'analysis']"
2621595,Simplify Trig Expression,"I am looking at a worked out answer to a problem I got wrong. Part of the work shows this simplification: $=2\cdot\csc(x)\cdot\sec(x)+2x\cdot−\csc(x)\cot(x)\cdot\sec(x)+2x\cdot\csc(x)\cdot\sec(x)\tan(x)$
$=2\csc(x)\sec(x)−2x\csc^2(x)+2x\sec^2(x)$ There's no explanation of how they got from the first expression to the second, and I can't figure it out.","['algebra-precalculus', 'trigonometry']"
2621598,How to solve $\ddot{y} = t^2$,"I am having trouble to solve $\ddot{y} = t^2$. Step 1: Find the homogenous solution: (this part is simple) $$y_H = c_1+c_2t$$ Step 2: Find the particular solution:  Since the nonhomogenous part is a polynomial of degree $2$, so $$y_P = At^2+Bt+C$$ Step 3:  $y = y_H+y_P$ and then plug in: We have $$2A = t^2$$ which is not correct. How should I modify this?  please advise, thanks!","['derivatives', 'ordinary-differential-equations']"
2621611,Why do generalized Fourier series seem to converge to functions so far outside of the Hilbert space?,"My understanding is that one of the most important properties of a separable Hilbert space is that we can decompose its elements into generalized Fourier series. For example, consider a set of basis functions $f_n(x)$ that spans the Hilbert space $L^2(\mathbb{R})$. For any function $g(x) \in L^2(\mathbb{R})$, the generalized Fourier series
$$\sum_{n = 0}^\infty \langle g, f_n \rangle\, f_n(x), \qquad \qquad \langle g, f \rangle := \int_{-\infty}^\infty g(x)\, f(x)\, dx$$
converges to $g(x)$ in the $L^2$ norm. (Sometimes we can make even stronger statements; for example, for the Hilbert space $L^2([0, 2\pi])$ with the standard basis functions $e^{i n \theta}$, Carleson's theorem guarantees that the (standard) Fourier series above converges to $g(x)$ almost everywhere. As shown here , this is not true in general.) However, the generalized Fourier series above seems to work much better than we might expect. That is, if we take a function $g(x)$ that does not lie in the Hilbert space and naively consider the above series, it appears to still converge to $g$. For example, the functions $g(x) \equiv 1$ and $g(x) = x^2$ obviously don't lie in $L^2(\mathbb{R})$. Nevertheless, when I try plotting the first few terms of the above generalized Fourier series with the Hermite basis functions , the series does indeed appear (by eye) to approach $g(x)$ more and more closely. The above generalized Fourier series makes formal sense for any function $g(x)$ such that the inner product $\langle g, f \rangle$ is defined. For basis functions (like the Hermite functions) that lie in Schwartz space , this space of functions $g$ is much larger than $L^2(\mathbb{R})$ and even incorporates some functions that diverge exponentially at infinity. We can't apply the $L^2$ norm to functions $g(x)$ that don't lie in $L^2(\mathbb{R})$, but is there some other sense in which the above generalized Fourier series converges to $g$? If so, why?","['fourier-analysis', 'hilbert-spaces', 'functional-analysis', 'convergence-divergence', 'sequences-and-series']"
2621623,Calculate infinite summation of sin(x)/x [duplicate],"This question already has answers here : Why does $\sum_{k=1}^{\infty}\frac{{\sin(k)}}{k}={\frac{\pi-1}{2}}$? (8 answers) Closed 6 years ago . How do you calculate the infinite sum $\sum_{i=1}^{\infty} \frac{\sin(i)}{i}$? According to Wolfram Alpha, the value of the sum is $\frac{\pi - 1}{2}$, but it does not tell me the method by which it gets this result.",['sequences-and-series']
2621637,Prove that any permutation of the given numbers can't be a perfect square,"Prove that a natural number written using one $1$, two $2$'s, three $3$'s, ... , nine  $9$'s cannot be a perfect square. This is the first problem that I have encountered of any such types. So I was not getting even a single idea over how to start. I don't have a proper understanding of the mathematical induction so any other method or a hint will be really appreciable.","['combinatorics', 'integers', 'discrete-mathematics', 'elementary-number-theory']"
2621665,What is the equation for an ellipse given 3 points and the tangent line at those points?,"Does anyone know how to find this? I know I have enough information to uniquely generate an ellipse (you only need five points for a conic, I have three plus the slopes or tangents at those points which count as points), but my problem is trying to solve the system of equations that include the derivatives that blow up to infinity because one of the tangents is vertical. Here are my points and the tangents associated with them. \begin{align}
P_1&=(0,-3);\ \ m_1=+1\\
P_2&=(1,\pm0);\ \ m_2=\infty \; \; \text{i.e. $(x=1)$}\\
P_3&=(0,+3);\ \ m_3=-1\\
\end{align} Thank you for helping to solve this problem!","['tangent-line', 'slope', 'conic-sections', 'geometry']"
2621674,Looking for challenge problems in topology,Right now my friend and I are going through Munkres Topology and we meet up to work on the challenge problems. I am wondering if anyone knows of a good resource or if someone could post some difficult questions. Right now we are mostly focusing on stuff before the quotient topology in Munkres. Any help much appreciated.,"['reference-request', 'general-topology']"
2621701,Partial Orders on finite sets to which Zorn's lemma does not apply,"Zorn's lemma is stated in the text I'm reading as If $(A, \leq)$ is a poset such that every chain of elements in $A$ has an upper bound in $A$ , then $A$ has at least one maximal element. However, I can't think of any partial ordering (defined as a relation which is reflexive, anti-symmetric, and transitive) on which the condition If $(A, \leq)$ is a poset such that every chain of elements in $A$ has an upper bound in $A$ would not hold if $A$ is a finite set. (I understand how an infinite set like $[0, 1)$ would fail to satisfy this requirement). My argument is that if $C$ is a chain in the poset $(A, \leq)$ then there will be an end to the chain which will be an element in the chain, and hence every set will satisfy this. Then can we say that if $A$ is a finite set then any poset $(A, \leq)$ has at least one maximal element by Zorn's lemma? If not, is there a counter-example to help me understand?","['order-theory', 'elementary-set-theory']"
2621750,"Computing the definite integral $\int _0^a \:x \sqrt{x^2+a^2} \,\mathrm d x$","Compute the following definite integral $$\int _0^a \:x \sqrt{x^2+a^2} \,\mathrm d x$$ This is what I did: $u = x^2 + a^2 $ $du/dx = 2x$ $du = 2xdx$ $1/2 du = x dx$ $\int _0^a\:\frac{1}{2}\sqrt{u}du = \frac{1}{2}\cdot \frac{u^{\frac{3}{2}}}{\left(\frac{3}{2}\right)}$  from $0$ to $a$. $\frac{1}{3}\cdot \left(x^2+a^2\right)^{\frac{3}{2}}$ from $0$ to $a$. I eventually got: $\frac{1}{3}\left(81+a^2\right)^{\frac{3}{2}}-\frac{1}{3}\left(a^2\right)^{\frac{3}{2}}$ but this was incorrect. The correct answer was: $\frac{1}{3}\left(2\sqrt{2}-1\right)a^3$ Any help?","['integration', 'definite-integrals', 'calculus']"
2621763,If $A$ is $2\times 2$ skew orthogonal with $A^TA=-I$ and $\det A=1$ then $\operatorname{tr} A=0$,"$A$ is skew orthogonal if $A^TA=-I$ in $\mathbb{Z_p}$ for $p>2$. The general form of $2\times 2$ characteristic polynomial: $x²-(\operatorname{tr} A)x+\det A$. It is given: $\det A=\pm 1$ If $\det A=-1$ then $\operatorname{tr} A= 0,1,-1$. But if $\det A=1$, then $\operatorname{tr} A$ must be $0$ only. What is the reason behind this?","['matrices', 'linear-algebra']"
2621776,"The sequence $\,a_n=\lfloor \mathrm{e}^n\rfloor$ contains infinitely many odd and infinitely many even terms","PROBLEM. Show that the sequence $\,a_n=\lfloor \mathrm{e}^n\rfloor$ contains infinitely many odd and infinitely many even terms. It suffices to show that the terms of the sequence $$\,b_n=\mathrm{e}^n\,\mathrm{mod}\, 2,\,\,\,n\in\mathbb N,$$ are dense in $[0,2]$ . Unfortunately, Weyl's Theorem does not look helpful in this case. EDIT. As Chris Culter said, the claim that the terms of the sequence $$\,b_n=\mathrm{e}^n\,\mathrm{mod}\, 2,\,\,\,n\in\mathbb N,$$ are dense in $[0,2]$ is (or might be) an open problem. Nevertheless, this does not imply that the claim that the sequence $\,a_n=\lfloor \mathrm{e}^n\rfloor$ contains infinitely many odd and infinitely many even terms is necessarily an open problem as well. It is also noteworthy that it is relatively easy to construct an irrational $\alpha$ with the property that the sequence $\,\alpha^n\,\mathrm{mod}\, 2,\,\,n\in\mathbb N,$ is NOT dense in $[0,2]$ .","['uniform-distribution', 'real-analysis', 'sequences-and-series']"
2621795,Counting the number of sets [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Given two positive integers $n$ and $k$ with the same parity, count the number
of sets $$S = \{0 < s_1 < s_2 < \dots < s_k = n\},$$ such that $s_1, s_3, \dots$ are odd numbers, and $s_2, s_4,\dots$ are even numbers.","['combinatorics', 'discrete-mathematics']"
2621797,Simple 2d-graph question,"Say, I have the line in $R^3$ defined by the parametric equations, $x=t$, $y=0$, and $z=t$.  How would I draw this line in 2-d, using the x and z coordinate axis? I'm just brushing up a bit on my calculus 3. Attempt:
To graph it,  I think I should just pick different values of t starting from 0 (or can I pick negative values) and see what values x and z takes on.  Thus, it would look just like the straight line going through the origin, the same as the line y=x in the x-y plane.  Am I correct?","['algebra-precalculus', 'multivariable-calculus', 'calculus', 'graphing-functions']"
2621908,How to find the following limit algebraically?,"I've been trying to answer this for a while and I know it's a simple question relative to most questions that are posted here. $$
\lim_{x\rightarrow -2}\: \frac{x^4+5x^3+6x^2}{x^2(x+1)-4(x+1)}
$$ If we substitute -2 for $ x $ we get $ 0/0 $, an indeterminate form. I figured that the denominator can be rewritten as $ (x^2-4)(x+1) $. And then I tried to factor something in the numerator but couldn't see anything interesting. How do I find the limit algebraically? I know that the answer is supposed to be 1, but I don't know how they got there. Thanks in advance!","['calculus', 'limits']"
2621924,"$\mathrm{Hom}(\mathrm{Hom}(G,H),H) \simeq G$?","Let $G,H$ be abelian groups. Under what conditions would the following holds true $\mathrm{Hom}(\mathrm{Hom}(G,H),H) \simeq G$? For example, if $G$ is any abelian group and $H=\Bbb R/\Bbb Z$ the isomorphism holds true. This is well-known as The Pontryagin duality theorem . Is there any counterexample?","['abelian-groups', 'group-theory', 'group-isomorphism', 'duality-theorems']"
2621925,Values of local maxima are countable for a $C^1$ function,"Prove or disprove: Let $f:[a,b]\rightarrow \mathbb{R}$ be a $C^1$ function, $C:=\{f(x) \mid f'(x)=0\}$. So $|C| \le \aleph_0$. My try: I've shown that the set of the x-values (and the set of the points) of the strict local maxima is countable by selecting rational numbers and using their cardinality. However, I cannot use this fact for the set of the values...What can I do? Thanks in advance.","['derivatives', 'cardinals', 'maxima-minima', 'calculus']"
2621970,Scheme has no Embedded Points,"Let $X$ be scheme and I want to know what are the weakest conditions for $X$ such that $X$ has no embedded points. The embedded points are defined by: $$\operatorname{Emb}(\mathcal{O}_C):= \{x \in X \ | \  m_x \in \operatorname{Ass}_{\mathcal{O}_{X,x}}(\mathcal{O}_{X,x})~\text{and}~x~\text{is not generic}\} $$ I think that it's clear that integral schemes don't have embedded points (because localisations of integral domains are integral domains), right? Do reduced schemes have embedded points? Because the problem is local, equivalent question: Why a reduced ring has no embedded points?","['algebraic-geometry', 'commutative-algebra']"
2621972,Compute $\lim\limits_{n \to \infty} n\sum\limits_{k=1}^n(f(k/n) - f((k-1)/n))\int_{(k-1)/n}^{k/n}f(t)dt$,"Let $f : [0,1] \to \mathbb{R}$ be a continuous function and let $(a_n)_{n>0}$ and $(b_n)_{n>0}$ be two sequences such that $$\displaystyle{ a_n = \sum_{k=1}^n{f \left(\frac{k-1}{n}\right) \cdot \int_\frac{k-1}{n}^\frac{k}{n}}{f(t)dt}},$$ $$\displaystyle  b_n = \sum_{k=1}^n{f \left(\frac{k}{n}\right) \cdot \int_\frac{k-1}{n}^\frac{k}{n}}{f(t)dt}, $$ $\forall n \in \mathbb{N}^*$ . a) Prove that $\displaystyle{\lim_{n \to \infty}{(b_n - a_n)} = 0}$ . b) Compute $\displaystyle{\lim_{n \to \infty}{n(b_n - a_n)}}$ . I have managed to solve a). Proof for a) : From the mean value theorem, we know that $\displaystyle{\exists c_k \in \left(\frac{k-1}{n}, \frac{k}{n}\right)}$ such that $\displaystyle{\int_{\frac{k-1}{n}}^{\frac{k}{n}}{f(t)dt} = \frac{1}{n}f(c_k)}$ So, $b_n = \displaystyle{\frac{1}{n}\sum_{k=1}^n {f(c_k) \cdot f\left(\frac{k}{n}\right)} = \frac{1}{2} \cdot \frac{1}{n}\sum_{k=1}^n{\left(\frac{f(c_k) + f\left(\frac{k}{n}\right)}{2}\right)^2 \cdot 4 - (f(c_k))^2 - \left(f\left(\frac{k}{n}\right)\right)^2}}$ . Since $f$ has the intermediate value property, then $\exists x_k \in \displaystyle{\left(c_k, \frac{k}{n}\right) \subset \left(\frac{k-1}{n}, \frac{k}{n} \right)}$ such that $\displaystyle{\frac{f(c_k) + f\left(\frac{k}{n}\right)}{2} = f(x_k)}$ . Therefore, $\displaystyle{\lim_{n \to \infty}b_n = \int_0^1{(f(t))^2dt}}$ . Using the same method, $\displaystyle{\lim_{n \to \infty}a_n = \int_0^1{(f(t))^2dt}}$ , so $\displaystyle{\lim_{n \to \infty}{(b_n - a_n)} = 0}$ . I have trouble solving b). I tried using the same method but it doesn't work, not unless $f$ is differentiable (so I can use Lagrange's theorem). $\displaystyle{n(b_n - a_n) = \sum_{k=1}^n{f(c_k) \left( f\left(\frac{k}{n}\right) - f\left(\frac{k-1}{n} \right) \right)}}$ and if $f$ is differentiable, then $\displaystyle{f\left(\frac{k}{n}\right) - f\left(\frac{k-1}{n} \right) = \frac{1}{n}f'(c_k)}$ .","['real-analysis', 'integration', 'definite-integrals']"
2622016,Extend an automorphism from a partially ordered set $P$ to the complete Boolean algebra $B(P)$.,"Cf. Jech's Set Theory p.221. A partially ordered set $P$ is separative if for any $p,q$ with $p\nleq q$, there is $r\leq p$ such that $r$ and $q$ are incompatible , i.e., there is no $s\leq r,q$. Let $P$ be a separative partially ordered set. If $\pi$ is an automorphism of $P$, then $\pi$ extends to an automorphism of the complete Boolean algebra $B(P)$ by
  $$
\pi(u)=\sum\{\pi(p)\mid p\in P\wedge p\leq u\}
$$
  where $B(P)$ contains $P$ is given by the following: Corollary 14.12. For every partially ordered set $(P,<)$ there is a complete Boolean algebra $B=B(P)$ and a mapping $e:P\to B^+$ such that: (i) if $q\leq p$ then $e(q)\leq e(p)$; (ii) $p$ and $q$ are compatible if and only if $e(p)\cdot e(q)\neq 0$; (iii) $\{e(p)\mid p\in P\}$ is dense in $B$. $B$ is unique up to isomorphism. I want to check that $\pi$ is an automorphism of $B$. It is easy to see that (i) $\pi(0)=0$ and $\pi(1)=1$; (ii) $\pi(u\cdot v)\leq\pi(u)\cdot\pi(v)$; (iii) $\pi(u+v)\geq\pi(u)+\pi(v)$, but I cannot finish the nontrivial directions in (ii) and (iii); once this has been done, I can prove the bijectivity.","['boolean-algebra', 'elementary-set-theory']"
2622043,"Is $f$ continuous at$(0,0)$?","$f:\Bbb R^2\to \Bbb R$ given by
$$
f(x, y) = \cases{\dfrac{2(x^3+y^3)}{x^2 + y} & if $(x, y)\neq (0,0)$\\
0 & if $(x, y) = (0,0)$
}
$$
It looks continuous, but my friend said it isn't. I tried to show discontinuity by taking various paths, but was only met with failure.  I couldn't prove it is continuous either. Please help.","['multivariable-calculus', 'real-analysis', 'calculus']"
2622047,Ratio of volumes of $n$-dimensional unit balls,"Prove that $$\left( \frac{nS_n}{S_{n-1}}\right)^{1/n} \le 2$$ where $S_i$ is the volume of the $i$th dimensional unit ball and $n\ge 2$. I think we can use the fact that an $n$-dimensional unit ball is contained in a hypercube whose edge measures $2$ units, and the ball contains a hypercube whose edge measures $\sqrt{2}$ units. So we have $\sqrt{2}^n\le S_n \le 2^n$ and thus $$\left( \frac{nS_n}{S_{n-1}}\right)^{1/n} \le \left( \frac{n2^n}{\sqrt{2}^{n-1}} \right)^{1/n} = n^{1/n}2^{\frac{n+1}{2n}} = n^{1/n}\sqrt{2}\sqrt{2}^{1/n}.$$ So if we take $n^{1/n} \le 2$ and $\sqrt{2}^{1/n}\le \sqrt{2}^{1/2}$, then an upper bound to my problem is $2^{1+3/4}$ which isn't good enough. Do we need another approach or do we get better bounds on $n^{1/n}$?","['convex-optimization', 'euclidean-geometry', 'geometry']"
2622118,Cardinality of the irrational numbers vs the rationals,"I am trying to explain why this proof is false. The easy way is to just assert that we have a valid proof that tells us that the cardinality of the irrational numbers is greater than the set of rationals and be done with it, but I want to be able to explain exactly where this proof is wrong. Let $I$ be the set of irrational numbers, where  the elements are $\{i_n: n \in R \land 0 < i_n < 1.0 \} $ Let $T_{i_n}$ be the set of all rational prefixes of $i_n$ For example if $i_{1.3721\dots} = 0.314159\dots$ then set $T_{i_{1.3721\dots}} = \{ 0.3, 0.31, 0.314, 0.3145, 0.314159, \dots\}$ Let $T = \bigcup T_{i_n}: n \in R$ Then $T$ will be a set of rational numbers If $\exists q : q \in T_{i_k} \land  q\notin \bigcup T_{i_n}: n \in (R \setminus k)$ Then $|I| \le |T|$ We are done Else $|I| \not \le |T|\rightarrow  \exists i_x \exists i_y: i_x \ne i_y \land T_{i_x} = T_{i_y}$ Contradiction Two different irrational numbers can't have the same prefix set. The proof is trying to say that every prefix set contributes at least one rational number to the union, and if that one prefix set were removed, then there would be some rational number missing from the union. I would argue that in the prefix set given as an example, there are an infinite number of prefix sets that contribute 0.3 to the union, and there are an infinite number of sets that contributes 0.31, and the same for 0.314, and the same for all the elements in that prefix set. So you can remove any prefix set from the union and the union will not be any less. You can even remove an infinite number of irrationals and still have the same union. The only way to reduce the rational elements in the union, is by removing a segment from the union. For example if you remove an interval, like all the irrational numbers between 0.005 and 0.006 then the rational numbers from 0.005 to 0.006 will not be in the union. Would this be one reason for why the proof fails and are there others?","['elementary-set-theory', 'proof-verification']"
2622119,"If the roots of the cubic equation $ax^3+bx^2+cx+d=0$ are equal, can one then establish a relationship between $a, b, c, d$?","If the roots of the cubic equation $$ax^3+bx^2+cx+d=0$$ are equal, can one then establish a relationship between $a, b, c, d$? Forgive me for any mistake in the wording of the problem. Thanks in advance.","['algebra-precalculus', 'cubics', 'roots', 'polynomials']"
2622123,Birthday Problem Alteration,"The well-known birthday problem asks how many people must be in a room before the probability of two or more people people sharing a (any) birthday is $>0.5$ and the answer is 23; a common alteration to this is how many people must be in a room before the chance of at least one person sharing your birthday (i.e. one specific date) is again greater than half, the answer is 253. I've been through these proofs and understand them however I want to know how many people must be in a room before the chances of at least two people sharing a specific birthday given at the start of the problem (e.g. 'your' birthday) is greater than half. Clearly the probability of this $=1-P($one or fewer people have this specific birthdate$)=1-P($one person shares this birthdate$)-p($no one shares this birthdate$)$. I've gone through the methods used to calculate the original problems but every answer I get becomes unsolvable when made greater than 0.5, how would I do this?","['birthday', 'statistics']"
2622149,Where is this function continuous/differentiable?,"Let $f: \mathbb R \to \mathbb R$ defined by $$f(x):= \begin{cases} x\sin x & x \in \mathbb Q \\ 0 & x\in \mathbb R \setminus \mathbb Q \end{cases}$$
In which $x\in \mathbb R$ is $f$ continuous (differentiable)? Looking at the graph the obvious assumption is that $f$ is continuous at $k\pi, k\in \mathbb Z$ and discontinuous elsewhere. Let $x\in \mathbb R \setminus \{k\pi, k\in \mathbb Z \}$. If $x$ is irrational: Let $a_n$ be a sequence of rational numbers converging to $x$. Then $$\lim_{n\to \infty} f(a_n) = a_n\sin(a_n) \neq 0,$$
but $x$ is irrational so $f(x) = 0$. Analogous proof for $x$ rational.
Now if $x = k\pi$ for some $k\in \mathbb Z$, let $a_n$ be a sequence converging to $x$. We have 
$$\left \lvert f(a_n) \right \rvert \leq \rvert a_n \sin a_n \lvert \to 0 = x\sin(x),$$
hence $f$ is continuous in $x$. But how to proof where $f$ is differentiable? I assume it is only in $0$, any solution?","['derivatives', 'real-analysis', 'real-numbers', 'sequences-and-series', 'analysis']"
2622190,Hausdorff methods of summation,"From the book of Boss ""Classical and modern methods in summability"": ""The class of Hausdorff methods includes the Hölder, Cesaro and Euler methods. A large number of other matrix methods which play an essential role in summability are Hausdorff methods too."" I wonder if there is any well-known example of Hausdorff methods? For example, circle methods such as Meyer-Konig or Taylor is an Hausdorff method?","['summation-method', 'reference-request', 'functional-analysis', 'summation', 'sequences-and-series']"
2622229,How many rounds in a tournament with n players,"I am stuck on the following question... Suppose n people are playing in a tournament where n is a power of two so that it creates an even bracket. In the first round each player is paired with another player, only the winner of each pair go on to the next round. How many rounds will there be in the tournament until it finishes? I have to create an equation in terms of n but I have been messing around with some numbers and can't figure this one out.",['discrete-mathematics']
2622259,Graph Theory: A loop-free connected graph with degree sequence,"- Background Information: I am studying graph theory in discrete mathematics. As I was practicing questions I came across this solution, provided by my professor, which is confusing for me to fully understand it. I need some clarification for the solution to make sense - Question and Solution: Construct a graph with the specified properties. If no such graphs exist, explain why. - My question: Could you please explain... Why can we have a maximum of 2 nodes of degree 1? In the degree sequence, there are 3 nodes of degree 1, so I don't understand where the 2 is coming from. Why does the graph not exist? If we add the degree sequences, we get a sum of 24 which is even and acceptable for drawing the graph. Edit: [definitions] A loop is an edge from a vertex to itself.","['graph-theory', 'discrete-mathematics']"
2622303,Polynomial form of two variable matrix determinant function,"We have the function $$f(x,y)=\det(A^2+B^2-xAB-yBA)$$ where $x, y$ are real numbers and $A, B$ are $2 \times 2$ matrices with real coefficients. What are the coefficients of $f(x,y)$ in polynomial form?","['matrices', 'polynomials', 'linear-algebra', 'determinant']"
2622339,Symmetric difference as a equivalent relation-equivalence classes,"I was wondering if I can get a hint on the following question: Let $R$ be an equivalence relation on  $\mathcal P(\mathbb{N})$, which satisfies:
$\langle A,B\rangle \in R$ iff $A \Delta B $ is finite. Prove that $R$ is an equivalence relation, and that each equivalence class is countable. I managed to prove that it is an equivalence relation,but got stuck on second part of the question. This is from a class of elementary set theory.","['relations', 'equivalence-relations', 'cardinals', 'elementary-set-theory']"
2622393,Variance Derivation of Chi-Squared Distribution,"If we find the MGF of $$Z^2$$ where $$Z \sim N(0,1)$$ we find that $$M_{Z^2}(t) = (1-2t)^{-.5}$$ for $t < .5.$ Consider that a chi squared distributed variable $X$ with $r$ degrees of freedom is the sum of $r$ iid standard normal variables squared. ie: 
$$X \sim \chi^2(r) = \sum_{j=0}^r Z_j^2$$
where $$Z_j \sim N(0,1)$$ are independent therefore the mgf of chi squared is
$$M_X(t) = (1-2t)^{-r/2}$$
Then $$M'_X(t) = -r/2\cdot-2r(1-2t)^{-r/2-1} = r(1-2t)^{-r/2-1}$$
so  $$E(X) = r(1) =r$$ And then $$M''_X(t) = r\cdot-r/2\cdot-2r(1-2t)^{-r/2-2} = r^2 (1-2t)^{-r/2-2}$$
so $$E(X^2) = r^2$$
But this implies that 
$$Var(X) = E(X^2) - (E(X))^2 = r^2 - r^2 = 0$$
Which is obviously false as the variance of chi squared depends on $r.$ Where is the mistake in my derivation?","['moment-generating-functions', 'statistics', 'variance', 'proof-verification']"
2622400,Is the Mandelbrot set path-connected?,The Mandelbrot set is known to be connected but whether it is path-connected is an open question. But what is the general consensus/belief among mathematicians? I am unable to convince myself either way because I am rather new to topology and don't yet have a good intuition about connectedness and path-connectedness.,"['fractals', 'path-connected', 'complex-analysis', 'complex-dynamics', 'general-topology']"
2622509,"Show that $\int_0^1\frac{\ln(x)^n}{x-1}dx=(-1)^{n+1}n!\zeta(n+1)$, for $n\geq 1$","I want to find a closed form of the following integral : $I_n =\int_0^1\frac{\ln(x)^n}{x-1}dx$ , for  $n\geq 1$. My attempt was to evaluate , using series :  $I_1,I_2,I_3,I_4$ 
and noticed a pattern :
$$I_1=\zeta(2)\\I_2=-2\zeta(3)\\I_3=2.3\zeta(4)\\I_4=-2.3.4\zeta(5)\\I_5=2.3.4.5\zeta(6)$$
Can we deduce that $I_n=(-1)^{n+1}n!\zeta(n+1)$ ? How to prove it ?","['integration', 'riemann-zeta']"
2622564,Why do these paths all have the same length?,In a high school book the author said these paths have all the same distance. Is that true? how to convince myself (and my students as well) they all have the same length?,['geometry']
2622640,Theta Method for system of ODEs,"So here is a question about a little Matlab code writing because I've never seen ""theta method""... Consider the $θ$-method
  $$y_{n+1} = y_n + θhf_n + (1 − θ)hf_{n+1}$$
  where $0 ≤ θ ≤ 1$ and $f_n = f(t_n, y_n)$. Write a MATLAB code to implement
  the theta method for systems of ODEs. For $θ = 0$, $0.5$, $1$, use your code for solving
  \begin{aligned}
y_1' &= −y_1 \\
y_2' &= −100 \left(y_2 − \sin(t)\right) + \cos(t)
\end{aligned}
  for $0 ≤ t ≤ 1$, with initial value $y_1 = 1$, $y_2 = 2$. Try this for
  stepsizes $h = .01$ and $h = .05$. Now I know how to do the Euler Code.... h = 0.05; %step size
y1 = 1; %IC Conditions Y1
x1 = 2; %IC Condition Y2
t0 = 0; %Initial time
t1 = 1; %Final time

nsteps = (t1-t0)/h; %number of steps

y(1) = y1; %Array for euler method Y1, -I.C Y1
x(1) = x1; %Array for euler method Y2  -I.C Y2
t(1) = t0 ; %array for euler method t

%% For loop and implementation of Euler Method

for n = 1:nsteps
   t(n+1) = t(n)+h; %time stepping euler method, increment time
   yprime(n+1) = -y(n); %Right hand side of diff eqy y1' = -y1
   xprime(n+1) = -100*(x(n)-sin(t(n)))+cos(t(n)); %RHS of y2'= -100*(y2-sin(t))+cos(t)
   y(n+1) = y(n)+yprime(n+1)*h;   
   x(n+1) = x(n)+xprime(n+1)*h;
end Would I just be changing the last part of the code where I have this? y(n+1) = y(n)+yprime(n+1)*h;   
   x(n+1) = x(n)+xprime(n+1)*h; Essentially I would think I change that part above into the theta method of, $y_{n+1} = y_n + θhf_n + (1 − θ)hf_{n+1}$ If anyone is familiar with this method, please let me know how you would write this code, any feedback is helpful. Thank you","['numerical-methods', 'ordinary-differential-equations', 'matlab']"
2622698,Why is partial ordering by continuation (vs just inclusion) required for Zorn's Lemma $\implies$ Well Ordering Theorem?,"In the proof that Zorn's Lemma implies the Well-Ordering Theorem, it is required that the set $\mathcal{W}$ of all well-ordered subsets of some set $\mathcal{A}$ be partially ordered by continuation . (Then by showing that every chain in $\mathcal{W}$ has an upper bound, it follows from Zorn's Lemma that there exists a maximal element in $\mathcal{W}$, and it is shown that that element is a well-ordering of $\mathcal{A}$). My question is, why is it necessary for $\mathcal{W}$ to be partially ordered by continuation , and not just by inclusion ? Meaning $\left(C,\leq _C\right)\leq _{\mathcal{W}} \left(D,\leq _D\right) \iff C\subseteq D\;$ and $ \leq _C\; \subseteq\; \leq_D$ (without the additional requirement that $C$ be an initial segment of $D$). I don't see why Zorn's Lemma can't apply in a similar way here too, and if it does why it doesn't follow that the maximal element in $\mathcal{W}$ is a well-ordering of $A$. Thanks",['elementary-set-theory']
2622702,"The IVP $\begin{cases}\dot{x}=x^3+e^{-t^2}\\x(0)=1\end{cases}$ possesses a solution in $I=(-1/9,1/9)$","I'm stuck with this problem: Prove that the IVP $$\begin{cases}\dot{x}=x^3+e^{-t^2}\\x(0)=1\end{cases}$$ has an unique solution defined on $I=(-1/9,1/9)$ . Which is the largest interval of definition of the solution? We can extend that solution to $t=1$ ? Okay, so it's obvious that $f(t,x)=x^3+e^{-t^2}$ is locally Lipschitz with respect to $x$ , and it's continuous too. So by Picard we can find a unique solution defined on $\mathbb{R}$ . But then the exercise wouldn't have any sense, so I think that I'm doing something wrong. Thanks for your time.","['derivatives', 'real-analysis', 'calculus', 'ordinary-differential-equations', 'initial-value-problems']"
