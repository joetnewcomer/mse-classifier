question_id,title,body,tags
3448078,Immersed principal subbundles,"In Kobayashi and Nomizu's Foundations of Differential Geometry vol. 1 the authors define immersed principal subbundles (actually, they call them imbeddings ) of a principal $G$ -bundle $\pi: P \to M$ as a principal $G'$ bundle $\pi': P' \to M'$ with an injective immersion $f: P' \hookrightarrow P$ and an injective homomorphism of Lie groups $\phi: G' \hookrightarrow G$ such that $$
f(q \cdot g) = f(q) \phi(g) \quad \text{for all}~q \in P', g \in G'~.
$$ This induces a smooth map $h: M' \to M$ such that $h \circ \pi' = \pi \circ f$ . The authors claim that (in the case of a immersed subbundle) this is also an injective immersion. I don't see why the last statement should hold. Take for example $M' = \mathbb{R}$ , $G' = \{e\}$ , so $P' = \mathbb{R} \times \{e\}$ and $P = \{p\} \times \mathbb{R}^2$ , i.e. $M$ is a single point and $G = (\mathbb{R}^2, +)$ . Then the map \begin{align}
    \mathbb{R} \times \{e\} &\to \{p\} \times \mathbb{R}^2 \\
    (t, e) &\mapsto (p, (t, 0))
\end{align} satisfies the conditions to be an immersed principal subbundle. However the map induced on $\mathbb{R} \to \{p\}$ is not an injective immersion. Am I  missing something (an additional assumption, a different definition)? If not, is there any  assumption that can be added to make the claim in the book true?","['principal-bundles', 'smooth-manifolds', 'manifolds', 'lie-groups', 'differential-geometry']"
3448085,"Karatzas and Shreve Problem 3.2. A generating family for the trace $\sigma$-algebra $\sigma(T_1, \dots, T_n)$ with the set $\{N_s = n\}$.","This is part of the solution to problem 3.2 (i) in Karatzas and Shreve. 
Here, $T_1, T_2, \dots$ is a sequence of independent exponentially distributed random variables with parameter $\lambda>0$ . $S_0 = 0, S_n = \sum_{i=1}^n T_i$ . And $N_t = \max\{n \ge 0: S_n \le t\}$ for $0\le t < \infty$ . I have question about the last sentence of the following excerpt. I know that $\mathscr{H}$ is generated by sets of the form $\{T_1 \le t_1, \dots , T_n \le t_n, N_s = n\}$ since the $\sigma$ -field $\sigma(T_1, \dots, T_n)$ are generated by such sets $\{T_1 \le t_1, \dots , T_n \le t_n\}$ . However, how is it generated by $\{S_1 \le t_1, \dots, S_{n-1}\le t_{n-1}\}$ ?","['stochastic-processes', 'measure-theory', 'probability-theory', 'real-analysis']"
3448087,Integral squared sinus of the Brownian motion is infinite,"I'm looking to prove that, almost surely: $$\int_0^\infty \sin^2(B_s) \, ds = \infty $$ where $B_s$ is a Brownian motion, without using the Ito Formula. I had two initial ideas: We know that the Brownian motion visits zero infinitely many times, but countable, so the Lebesgue measure of these visits is zero. Therefore we can hope that it stays nonzero and positive (cause $\sin^2$ is positive) long enough infinitely many times. Following up on the first idea, if I can prove that $$ P \left( B_s \in \bigcup_{n \in \mathbb{Z}} \left[\frac{\pi}{4} + n\pi,\frac{3\pi}{4} + n\pi \right] \right)$$ is big enough (maybe something like using Borel-Cantelli's theorem?), I could lower bound the integral by infinity. I'm not quite sure of these ideas and their formality, every help is much appreciated. Thank you!","['integration', 'brownian-motion', 'probability-theory', 'stochastic-calculus']"
3448125,Decay of Fourier transform of pushforward measure,"Let $A\subset [0,1]$ be closed and let $\tilde{A}:=\{ x\in \mathbb{R}^n : \|x\|\in A\}$ . Assume $\nu$ is a finite measure supported on $\tilde{A}$ s.t. its Fourier transform decays as $\frac{n-1+\alpha}{2}$ . In symbols $$ \hat{\nu}(\xi) = \int e^{-i\langle \xi, x \rangle}d\nu(x)  $$ $$ | \hat{\nu}(\xi)| \le \|\xi\|^{-\frac{n-1+\alpha}{2}}$$ Let $\mu$ be the pushforward measure of $\nu$ on $[0,1]$ via $\|\cdot\|$ , i.e. $$ \mu([a,b])= \nu(\{x\in \mathbb{R}^n : \|x\| \in [a,b] \} )$$ What can I conclude on the decay of $\mu$ ? I would expect that $ | \hat{\mu}(t)| \le |t|^{-\frac{\alpha}{2}}$ but I'm having a hard time in trying to prove it. If $\nu$ were radial I should be able to get to the conclusion using Bessel functions, but in the general case I don't know how to proceed. I thought I could consider the averages of $\hat{\nu}$ over the spheres, i.e. $$ f(\xi) = \int_{S^{n-1}} \hat{\nu}(\|\xi\| \theta) \, d\sigma^{n-1}(\theta) $$ but then I don't know how to conclude that $f$ is the Fourier transform of  some measure supported in $\tilde{A}$ .","['measure-theory', 'fourier-analysis', 'harmonic-analysis', 'pushforward', 'fourier-transform']"
3448158,Diagonalizing a nearly-diagonal matrix,"Take a (kind of) arrowhead real-symmetric matrix of the general form $$
M = 
\begin{bmatrix}
a_{11} & a_{12} & a_{13} & a_{14} & a_{15} & a_{16} \\
a_{12} & a_{22} & a_{23} & a_{24} & a_{25} & a_{26} \\
a_{13} & a_{23} & a_{33} & 0 & 0 & 0 \\
a_{14} & a_{24} & 0 & a_{44} & 0 & 0 \\
a_{15} & a_{25} & 0 & 0 & a_{55} & 0 \\
a_{16} & a_{26} & 0 & 0 & 0 & a_{66} \\
\end{bmatrix}
$$ where the size of the blocks may vary, however in general, the diagonal submatrix will be of dimension close to that of the entire matrix. Is there a method to diagonalise this matrix which takes advantage of this largely diagonal structure? My desire is computational efficiency, i.e. compared to dgemm . I require all of the eigenvalues and eigenvectors of this matrix, i.e. $V^{-1}MV = W$ where $V$ are the eigenvectors of $M$ , and $W$ a diagonal matrix containing the eigenvalues.","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'numerical-linear-algebra', 'diagonalization']"
3448168,How to prove math discrete expression in right way?,I have such expression $$ \{A\} \subseteq P(B) \to P(A) \subseteq P(B) $$ As far as I understand I have to convert expression left part to make it fit right one. But I don't see any associations with these two parts...,"['elementary-set-theory', 'discrete-mathematics']"
3448181,Phase plane portrait center ellipse equations,"If I have a system of differential equations, with coefficient matrix,
A= $\begin{bmatrix} 1&13\\-2&-1\end{bmatrix}$ . The eigenvalues are $\lambda= \pm 5i$ . The phase portrait is a center with a clockwise direction field. How would I go about determining the equation of one of the rotated ellipse orbits?","['ordinary-differential-equations', 'dynamical-systems']"
3448243,How to modify normal distribution to take into account properties of Mahonian numbers,"According to Richard Stanley's answer from normal approximation to $inv(\pi)$ : $$ \left| P\left( \frac{\mathrm{inv}(\pi)-\frac 12{n\choose 2}}{\sqrt{n(n-1)(2n+5)/72}}\leq x\right)-\Phi(x)\right| \leq \frac{C}{\sqrt{n}}, $$ where $\Phi(x)$ denotes the standard normal distribution we get that Raw maxima $M(n)$ of Mahonian numbers ( $T(n,k)$ is the number of permutations of ${1..n}$ with $k$ inversions): $M(n+1)/M(n)=n-\frac 12+o(1)$ for large $n$ . To be more precise the asymptotic is like $M(n+1)/M(n)=n-\frac {1}{2}+O(\frac {1}{n^{1-\epsilon}})$ I wonder how to modify the normal distribution (for eg. its mean and variance) to take into account the precise information about the $M(n)$ numbers? What will be the new variance, mean? I suppose that we'll have the same mean but a different variance in normal distribution. I understand we cannot improve the inequality without further assumptions about the numbers.
Thank you for explanations and ideas.","['permutations', 'statistics', 'probability-distributions', 'real-analysis', 'inequality']"
3448266,"Let $f: A\rightarrow A$. Prove that if $(f ◦ g)$ is surjective, then $f$ is surjective. [duplicate]","This question already has answers here : If $f \circ g$ is surjective, then f is surjective (2 answers) Closed 4 years ago . Let $f: A\rightarrow A$ . Prove that if $(f ◦ g)$ is surjective, then $f$ is surjective. We know that $(f ◦ g)$ is surjective, so that means that $\forall x\in A, \exists a$ such that $f(g(a)) = x$ Let $y = g(a) \in A$ $\implies f(y) = f(g(a)) = x$ $\implies \forall x\in A, \exists y$ such that $f(y) = x$ $\implies f$ is surjective Is this proof correct?","['elementary-set-theory', 'functions', 'proof-verification']"
3448271,"If generators of $\sigma$-algebra independent, then $\sigma$-algebras are independent","Let $(\Omega, \mathcal{A}, P)$ be a probability space and $\mathcal{E}_i\subset \mathcal{A},\ \forall i\in I$ . If $(\mathcal{E}_i \cup \{\emptyset\})$ is $\cap$ -stable, then $(\mathcal{E}_i)_{i\in I}\text{ independent} \Leftrightarrow\left (\sigma(\mathcal{E}_i)\right )_{i\in I}\text{ independent}$ Every proof I have seen is quite long, so I am not sure if mine is correct. For my proof I use the principle of good sets and the $\pi$ - $\lambda$ theorem. Let $\mathcal{G}:=\{A\in\sigma(\mathcal{E}_1)\colon P\left (\bigcap_{i\in I\setminus{\{1\}}}(E_i)\cap A \right )=\prod_{i\in I\setminus{\{1\}}}P(E_i)\cdot P(A),\ E_i\in \mathcal{E}_i\ \forall i\in I\setminus{\{1\}}\}$ Since $\mathcal{E}_1\subset \mathcal{G}$ , if I can show that $\mathcal{G}$ is a $\lambda$ -system, I have by the $\pi$ - $\lambda$ theorem that $\sigma(E_1),(\mathcal{E}_i)_{i\in I\setminus{\{1\}}}$ are independent. This I want to repeat for every $ \sigma(E_i)$ from which the conclusion follows. Thus, the only thing I need to show now is that $\mathcal{G}$ is a $\lambda$ -system. First axiom ( $\Omega\in\mathcal{G}):$ I will not show this, as it immediately follows. Second axiom ( $A,B\in\mathcal{G}, A\subset B$ then $B\setminus A\in\mathcal{G}$ ): $P\left (\bigcap_{i\in I\setminus\{1\}}E_i\cap(B\setminus A)\right)=P\left (\bigcap_{i\in I\setminus\{1\}}E_i\cap(B\cap A^c)\right)=\prod_{i\in I\setminus\{1\}}P(E_i)P(A^c)P(B)=\prod_{i\in I\setminus\{1\}}P(E_i)P(B\setminus A)$ This follows from the fact (would even follow immediately) that if sets are independent, their complement and every combination of taking complement are independent, too. Third axiom ( $\bigcup_{n\in\mathbb{N}}A_n\in\mathcal{G}$ for any disjoint sets $A_1,...\in\mathcal{G}$ ): $P\left ((\bigcap_{i\in I\setminus\{1\}}E_i)\cap(\dot\bigcup_{n\in\mathbb{N}}A_n)\right) = P\left (\dot\bigcup_{n\in \mathbb{N}}\left (\bigcap_{i\in I\setminus\{1\}}E_i\right) \cap A_n \right) \\
=\sum_{n\in \mathbb{N}}\prod_{i\in I\setminus\{1\}}P(E_i)P(A_n)=\prod_{i\in I\setminus\{1\}}P(E_i)\cdot \left( \sum_{n\in \mathbb{N}}P(A_n)\right)\\
=\prod_{i\in I\setminus\{1\}}P(E_i)P(\dot\bigcup_{n\in\mathbb{N}}A_n)$ where I have only used distributivity between intersection and union and that $\sigma$ -additivity.","['measure-theory', 'probability-theory']"
3448285,"Limit with radicals, $\cos$, $\ln$ and powers","$\underset{x\rightarrow +\infty}\lim{\frac{\sqrt[6]{1-\cos{\frac{1}{x^3}}}\Big(2^{-\frac{1}{x}}\;-\;3^{-\frac{1}{x}}\Big)}{\ln(x-1)^{\frac{1}{x}}-\ln{x^{\frac{1}{x}}}}}=\underset{x\rightarrow +\infty}\lim{\frac{\sqrt[6]{1-\cos{\frac{1}{x^3}}}\Big(2^{-\frac{1}{x}}\;-\;3^{-\frac{1}{x}}\Big)}{\ln(\frac{x-1}{x})^{\frac{1}{x}}}}=\underset{x\rightarrow +\infty}\lim{\frac{\sqrt[6]{1-\cos{\frac{1}{x^3}}}\Big(\frac{\sqrt[x]{3}-\sqrt[x]{2}}{\sqrt[x]{6}}\Big)}{\frac{1}{x}\ln{\Big(1-\frac{1}{x}\Big)}}}=0$ My answer is rather imprecise: $$\underset{x\rightarrow +\infty}\lim{\cos{\frac{1}{x^3}}}=1\implies\underset{x\rightarrow +\infty}\lim{\sqrt[6]{1-\cos{\frac{1}{x^3}}}}=0$$ $$\underset{x\rightarrow +\infty}\lim{\frac{\sqrt[x]{3}-\sqrt[x]{2}}{\sqrt[x]{6}}}=0?$$ I am aware of the mistake I have made by writting $0$ for an undefined term. $$\underset{x\rightarrow +\infty}\lim{\Big(1-\frac{1}{x^3}\Big)}=1\implies \ln{\Big(1-\frac{1}{x}\Big)}<0\implies\underset{x\rightarrow +\infty}\lim{\Bigg(\frac{1}{\frac{1}{x}\ln{\Big(1-\frac{1}{x}\Big)}}\Bigg)=-\infty}$$ The limit of the denumerator is $0$ $\&$ the limit of the whole expression is $0$ .
How can I prove this concisely?","['limits', 'calculus', 'proof-writing', 'real-analysis']"
3448337,Number of partial orders that contain a specific relation?,"Let be $A=\{1,2,3,4\}$ Find the number of partial order relations of A that contain the relation $R=\{(1,2),(3,4)\}$ I figured out that there is no easy way of counting partial orders, so I sketched all the possible Hasse diagrams (no way to check that out as far as I'm concerned) and then tried to count them by hand. (1) We have 2 ways. $(1,2)$ up, $(3,4)$ down and viceversa. (2) We have only 1 way. (3) and (4) are equivalent, so they give me 2 ways. (5) and (6) give me 2 ways too. (7) Gives me 4 ways but 2 of them are mirrored, so 2 ways really. So we have: $2+1+2+2+2 = 9$ partial orders containing $R=\{(1,2),(3,4)\}$ . I don't have any way to check if I'm right, any help?","['order-theory', 'relations', 'discrete-mathematics']"
3448343,"Find all positive integers $x, y, z$ so that $(x+2y)(y+2z)(z+2x)$ is equal to prime power","Find all positive integers $x, y, z$ so that $(x+2y)(y+2z)(z+2x)$ is equal to prime power. My try Since $x, y, z$ are positive integers it follows that $x+2y, y+2z, z+2x \geq 3$ . We have following system of equations: $$\begin{align}
x+2y &= p^r \tag{1}\label{eq1} \\
y+2z &= p^s \tag{2}\label{eq2} \\
z+2x &= p^t \tag{3}\label{eq3}
\end{align}$$ Where $p$ is prime number and $r, s, t$ are positive integers.
Solving this system of equations for $x, y, z$ gives us $x=\frac{4p^t-2p^s+p^r}{9}$ , $y=\frac{4p^r-2p^t+p^s}{9}$ , $z=\frac{4p^s-2p^r+p^t}{9}$ . Since $x, y, z$ are integers following equations must hold: $$\begin{align}
4p^t-2p^s+p^r &\equiv 0 \pmod 9 \\
4p^r-2p^t+p^s &\equiv 0 \pmod 9 \\
4p^s-2p^r+p^t &\equiv 0 \pmod 9
\end{align}$$ I don't know how to continue from there. Can somebody help?","['number-theory', 'prime-numbers', 'diophantine-equations']"
3448430,Solve this First Order Non-Linear Differential Equation,"I need to solve $$y'=x\sqrt{x^2+y^2},\quad y(1)=\alpha \in\mathbb{R}$$ I'm not sure how to proceed . it's nonlinear and The method of Separation of Variables cannot  be   be possible. by Cauchy Lipschitz , the Equation admits a local solution",['ordinary-differential-equations']
3448453,Solving a differential equation by Laplace transform,"I am trying to solve: $$y""+2y'+y = 0, y(0)=1,y'(0)=1$$ My work is shown below: $y''+2y'+y=0$ , $y(0)=1$ , $y'(0)=1$ $\mathcal L[y''+2y'+y]=\mathcal L(0)$ $\mathcal L[y'']+2\mathcal L[y]'+\mathcal L[y]=0$ $[s^2\mathcal L[y(s)]-sy(0)-y'(0)]+2[sx(s)-y(0)]+x(s)=0$ $s^2x(s)-s-1+2sx(s)-2+x(s)=0$ $x(s)(s^2+2s+1)=s+3$ $x(s)=\frac{s+3}{s^2+2s+1}$ I don't see this particular problem online or any other site so it might help people on the same problem. Any advice you might have as to how to proceed would be greatly appreciated. Thanks in advance.","['laplace-transform', 'ordinary-differential-equations']"
3448459,"Rudin Exercise 2.7: union of subsets of a metric space, and closure thereof","I am trying to solve exercise 7 in Chapter 2 of Rudin and was hoping someone could look over my proof. Let $A_1, A_2, A_3, \ldots$ be subsets of a metric space. a) Let $B_n = \bigcup\limits_{i=1}^n A_i$ , prove that $\overline{B}_n = \bigcup\limits_{i=1}^n \overline{A}_i$ , for $n = 1, 2, 3, \ldots$ b) If $B = \bigcup\limits_{i=1}^{\infty} A_i$ , prove that $\overline{B} \supset \bigcup\limits_{i=1}^{\infty} \overline{A}_i$ . Show, by an example, that this inclusion can be proper. Here is my attempt. a) The closure of a set is the smallest closed set containing it. Thus, for all $i$ , $\overline{A}_i$ is closed. Further, the finite union of closed sets is closed. Thus, $\bigcup\limits_{i=1}^n \overline{A}_i$ is closed. Furthermore, $\overline{A}_i = A_i \cup (A_i)'$ , where $(A_i)'$ is the set of limit points of $A$ . Thus, $A_i \subset \overline{A}_i$ for all $i$ , which implies that $\bigcup\limits_{i=1}^n A_i \subset \bigcup\limits_{i=1}^n \overline{A}_i$ , i.e., $B_n \subset \bigcup\limits_{i=1}^n \overline{A}_i$ . By Theorem $2.27$ , for any metric space $X$ where $E, F \subset X$ , if $E \subset F$ where $F$ is closed, then $\overline{E} \subset F$ . Therefore, we deduce that $\overline{B}_n \subset \bigcup\limits_{i=1}^n \overline{A}_i$ . Furthermore, $A_i \subset \bigcup\limits_{i=1}^n A_i$ for any $i$ , meaning that $A_i \subset B_n$ for any $i$ . But $B_n \subset \overline{B}_n$ , meaning that \begin{align*}
A_i \subset B_n \subset \overline{B}_n,
\end{align*} i.e., $A_i \subset \overline{B}_n$ , where $\overline{B}_n$ is closed. Thus, Theorem 2.27 gives that $\overline{A}_i \subset \overline{B}_n$ for any $i$ , and hence that $\bigcup\limits_{i=1}^n \overline{A}_i \subset \overline{B}_n$ . Thus, $\overline{B}_n \subset \bigcup\limits_{i=1}^n \overline{A}_i$ and $\bigcup\limits_{i=1}^n \overline{A}_i \subset \overline{B}_n$ , so $\overline{B}_n = \bigcup\limits_{i=1}^n \overline{A}_i$ . b) Let $B = \bigcup\limits_{i=1}^{\infty} A_i$ . Since $A_i \subset \bigcup\limits_{i=1}^{\infty} A_i$ , $A_i \subset B$ . But $B \subset \overline{B}$ , so \begin{align*}
A_i \subset B \subset \overline{B},
\end{align*} hence, \begin{align*}
A_i \subset \overline{B}.
\end{align*} But $\overline{B}$ is closed, so by Theorem $2.27$ , we have \begin{align*}
\overline{A}_i \subset \overline{B},
\end{align*} for any $i$ , which implies that \begin{align*}
\bigcup\limits_{i=1}^{\infty} \overline{A}_i \subset \overline{B},
\end{align*} which can be written as \begin{align*}
\overline{B} \supset \bigcup\limits_{i=1}^{\infty} \overline{A}_i.
\end{align*} As for an example to show that this inclusion can be proper, let us consider: \begin{align*}
A_i = \left[\frac{1}{i}, 1\right],
\end{align*} in which case each $A_i$ is closed, so $\overline{A}_i = A_i$ , meaning that their infinite unions are the same. That is, \begin{align*}
\bigcup\limits_{i=1}^{\infty} A_i = \bigcup\limits_{i=1}^{\infty} \overline{A}_i. 
\end{align*} However, we have: \begin{align*}
\bigcup\limits_{i=1}^{\infty} A_i = \bigcup\limits_{i=1}^{\infty} \left[\frac{1}{i}, 1\right] = (0,1]. 
\end{align*} However, for the left-hand side, we get: \begin{align*}
B = \bigcup\limits_{i=1}^{\infty} A_i \implies \overline{B} = \overline{\bigcup\limits_{i=1}^{\infty} A_i} = \overline{(0,1]} = [0,1].
\end{align*} Since $(0,1] \subset [0,1]$ , $\bigcup\limits_{i=1}^{\infty} \overline{A_i}$ is properly contained in $B$ . Any feedback would be greatly appreciated.","['proof-verification', 'real-analysis']"
3448486,Kernel of the following Substitution Homomorphism over $\mathbb{C}[x]$,"I'm hoping someone could review my proof for accuracy, thanks! There is another proof of this on stack exchange, but it uses quotient rings, which we haven't learned yet. Problem: Let $\phi: \mathbb{C}[x,y]$ -> $\mathbb{C}[t]$ , a the homomorphism that sends x -> $t + 1$ and $ y$ -> $t^3 - 1 $ . Determine the kernel $K$ of $\phi$ , and prove that every ideal of $\mathbb{C}[x,y]$ that contains $K$ can be generated by two elements. Proof: Note that $f = (x-1)^3 - 1 - y \in K$ . Suppose there is some $g \in K$ such that $f$ does not divide $g$ in $\mathbb{C}[x,y]$ . Then we have that $f$ is monic of degree $1$ when considered as a polynomial in the variable $y$ . Then we have $g = fq + r$ , where deg(r) $\lt$ 1 (with respect to the variable $y$ ). This implies that $r(x)$ is either a polynomial in $\mathbb{C}[x]$ that is non constant or is the $0$ polynomial. If it is nonconstant in $x$ then since r $\in$ K we must have that $x+1$ is a root of r. Part I think is wrong: But this implies that the polynomial $r$ has infinite roots, as $x$ is a variable that can range over all of $\mathbb{C}$ for example. Part I think may work better: Alternatively, plugging in x -> $x + 1$ will not send a non zero polynomial to zero as we are working in an integral domain and the substitution will maintain the degree of the polynomial as distributing $x+1$ will just produce extra terms of lower degree. Hence we have r(x) must be the zero polynomial and so f generates all of K and so K is principle and $K$ = $ ( (x-1)^3 - 1 - y )$ . Then Let $I$ be an ideal that contains K. If I = (1), then I contains K and is generated by 1 element. Suppose $I$ is a proper ideal then. New attempt: Then for any $g$ $\in$ $I$ we have $g = fq + r$ when dividing over $y$ . Then deg(r) $\lt$ $1$ and so it is either a constant or a polynomial over $x$ , call it $r(x)$ . Since $r(x)$ $\in$ $\mathbb{C}[x]$ then the set of all remainders is an ideal and is principle as it is polynomials in one variable over a field. Though I’m not sure if we can claim the set of remainders is an ideal. It is certainly a subset of $I$ , but I’m not sure if it is an ideal itself. ______________below this  is wrong__________ Then let $g$ $\in$ I and suppose $f$ does not divide $g$ . Then we can similarly divide $g$ by $f$ and conclude the remainder, $r(x)$ , must be degree 0 in the variable y which implies it may be of non zero degree of $x$ . Indeed it may be as considering $f$ as a function in the variable $x$ now we have that it is monic of degree 3. Then $g = fq + r$ is valid as an equation in the variable $y$ , and the variable $x$ . So we are dealing with the same $r(x)$ value as previously, and it must satisfy the additional constraint that the degree of $r(x)$ is less than $3$ . Hence any g $\notin$ K for g $\in$ I is of the form $g = fq + r$ , where $r(x)$ $\in$ $\mathbb{C}[x]$ . Then $r(x)$ $\in$ I also, as $I$ is closed under addition. Then the the lowest degree of $r$ is $0$ , $1$ or $2$ . $0$ implies $I$ is the whole ring. $1$ or $2$ implies we can generate $I$ with either $x$ or $x$$^2$ as $\mathbb{C}[x]$ is a ring with only ideals that are principle that are generated by lowest degree monic polynomials, and so $x$ or x $^2$ would suffice in that case. In any case we have I =  or , or <1>. Hence the claim is shown.","['ring-theory', 'abstract-algebra', 'proof-verification']"
3448503,"$f:[a,b]\subseteq \Bbb R \to \Bbb{R}^2$ s. t. $f(a) = f(b)$. Then $f'(t)$ takes any possible direction","I'm asked to prove that for a function $f:[a,b]\subseteq \Bbb R \to \Bbb{R}^2$ such that $f(a)=f(b)$ is derivable for all $t$ on the interval then $f'(t)$ takes all possible directions.
I am not sure my logic is correct, but I Was thinking about a function $f$ where $f(t)=v$ . Then we would still have $f(a)=f(b)$ but we would not have f' taking any possible direction.",['multivariable-calculus']
3448518,"Prove $\int\limits_0^{\frac{\pi}{2}}\sin(2n x)\,\cot x\,\mathrm{d}x- \int\limits_0^{\frac{\pi}{2}}\frac{\sin(2n x)}{x}\,\mathrm{d}x\to 0$","Let $$a_n=\int\limits_0^{\frac{\pi}{2}}\sin(2n x)\,\cot x\,\mathrm{d}x ~~~\textrm{ and} ~~~   b_n=\int\limits_0^{\frac{\pi}{2}}\frac{\sin(2n x)}{x}\,\mathrm{d}x.$$ Prove that $a_n-b_n \to 0.$ Attempt. We have that $$a_n-b_n  = \int\limits_0^{\frac{\pi}{2}}\sin(2n x)\,\left(\cot x-\frac{1}{x}\right)\,\mathrm{d}x.$$ Integration by parts would give: $$a_n-b_n=\left[\log\left(\frac{\sin x}{x}\right)\sin(2nx)\right]_0^{\frac{\pi}{2}}-2n\int\limits_0^{\frac{\pi}{2}}\cos(2n x)\,\log\left(\frac{\sin x}{x}\right)\,\mathrm{d}x$$ $$=-2n\int\limits_0^{\frac{\pi}{2}}\cos(2n x)\,\log\left(\frac{\sin x}{x}\right)\,\mathrm{d}x$$ but this doesn't seem to go any further. On the other hand, from Integral $\int_0^\pi \cot(x/2)\sin(nx)\,dx$ we have $a_n=\frac{\pi}{2}$ , so: $$b_n-a_n=\int\limits_0^{\frac{\pi}{2}}\left(\frac{\sin(2n x)}{x}-1\right)\,\mathrm{d}x,$$ so: $$|b_n-a_n|\leqslant \int\limits_0^{\frac{\pi}{2}}\left|\frac{\sin(2n x)}{x}-1\right|\,\mathrm{d}x,$$ but I also didn't manage to get this any further. Thanks in advance for the help. Edit. Consequence of the above limit is the evaluation of the Dirichlet integral: $$\int\limits_0^{+\infty}\frac{\sin x}{x}\,\mathrm{d}x=
\lim_{n \to +\infty}b_n=\lim_{n \to +\infty}a_n=\frac{\pi}{2}.$$","['integration', 'calculus', 'analysis', 'real-analysis']"
3448560,Looking for a problem and answer book for measure theory,"Looking supplementary self-study texts for measure theory, including a good problem and solutions companion while studying Royden and Stein's Real Analysis .  Instructors solutions for either would work as well .","['measure-theory', 'reference-request', 'real-analysis']"
3448564,Derivation of information entropy using Stirling's approximation,"I'm currently studying the textbook Pattern Recognition and Machine Learning (Bishop, 2006) and am studying the information entropy in chapter 1. In the book, the author derives the definition of information entropy for discrete random variable cases by giving the analogy of ""considering a set of $N$ objects that are to be divided amongst a set of bins, such that there are $n_i$ objects in the $i$ th bin. The total number of ways to allocate the $N$ objects is: $$W = \frac{N!}{\prod_i n_i !}$$ and the entropy is based on the logarithm of this scaled by a constant: $$H = \frac{1}{N} \ln (W) $$ The author then uses Stirling's approximation to make a derivation, but I'm getting stuck midway from how the author derived the final result. Here's my derivation: $$
\begin{align}
H & = \frac{1}{N} \ln (W) \\
& = \frac{1}{N} \ln \left( \frac{N!}{\prod_i n_i !}\right) \\
& = \frac{1}{N} \left( \ln(N!) - \ln \left( \prod_i n_i! \right) \right) \\
& = \frac{1}{N} \left( \ln(N!) - \sum_i \ln (n_i!) \right) \\
& = \frac{1}{N} \left( (N \ln(N) - N) - \left( \sum_i (n_i \ln (n_i) - n_i )\right) \right) \\
& = \left( \ln(N) - 1 \right) - \frac{1}{N} \left( \sum_i n_i\ln(n_i) - \sum_in_i \right) \\
& = (\ln(N) - 1) -\frac{1}{N} \sum_i n_i \ln(n_i)  + 1 \\
& = \ln(N) - \frac{1}{N} \sum_i n_i \ln(n_i)
\end{align}
$$ The author's final result states that: $$
\begin{align}
H & = -\lim_{N \rightarrow \infty} \sum_i \left( \frac{n_i}{N} \right) \ln \left( \frac{n_i}{N} \right) \\
& = -\sum_i p_i \ln(p_i)
\end{align}
$$ I'm a bit confused as to how the author jumped from the derivation to suddenly using a limit, and also how using the limit on those values gives the values of $p_i$ . My initial thought was that $p_i = \frac{n_i}{N}$ and so I'm not sure what purpose the limit serves here. Would anybody be kind enough to give me some tips or pointers as to how this result was derived? Thanks in advance.","['limits', 'information-theory']"
3448569,"How much algebra and how much topology is there in ""algebraic topology?""","I would like to study Hatcher's book, Algebraic Topology - in particular the fundamental group and introductory homotopy theory. I haven't had formal instruction in algebra or topology (my background is primarily in analysis). I've read through the first five chapters of Munkres' Topology and have a fairly good grasp on everything except the proof of Tychonoff's theorem - is that sufficient, or should I continue reading Munkres? As for algebra, my knowledge is considerably less; it is mostly what I have taught myself, but I've never seriously studied it. I'm familiar with basic notions of group theory but not so much with the major theorems. I am assuming this is where I should focus my efforts on in preparing to study Hatcher's book. What are some topics that I should be familiar with, and some texts to study those from? Would Dummit and Foote be a suitable choice, or should I seek something not quite so heavy? I would like to say I am ""mathematically mature,"" just not specifically familiar with algebra. I should stress that I'm not looking to become an expert in algebraic topology, just enough to study the fundamental concepts and theorems. My question is mostly whether I should focus more on algebra or topology in my preparation.","['advice', 'book-recommendation', 'abstract-algebra', 'general-topology', 'algebraic-topology']"
3448580,"Prove the surjectivity of $f(r,m)$ from $\mathbb{Z^{+}} \times \mathbb{N} \rightarrow 2\mathbb{N}+1$","I'm trying to prove the bijectivity of some function and already have the injective proof down, but am having trouble with the surjectivity. I have to prove the following function, $f$ , is surjective to the positive odd integers. For some function $f(r,m) = 2^{r+1}m + \frac{2^{r}(5+(-1)^{\left\lceil\frac{r+2}{2}\right\rceil}+3(-1)^{\left\lfloor\frac{r+2}{2}\right\rfloor})-1}{5}$ , $r \in \mathbb{Z^{+}}$ and $m \in \mathbb{N}$ Prove $f(r,m): \mathbb{Z^{+}} \times \mathbb{N} \rightarrow 2\mathbb{N}+1$ It seems like at each r-value the function produces odds that are a subset of the positive odd integers, but I can't find a way to prove surjectivity to the positive odds. I have a map of some values below so you can see how it jumps back and forth. $f$ to odd integers"">","['elementary-set-theory', 'elementary-number-theory', 'integers']"
3448583,About the eigenvalues of real symmetric matrix,"Let $S$ be an $n×n$ symmetric real matrix, and for some $v≠0$ , $\|Sv-αv\|<ε\|v\|$ ( $α$ is a real number). Then how can we prove that $S$ has at least one eigenvalue $λ$ with $|λ-α|<ε$ ?
I am aware that the eigenvectors associated with different eigenvalues are orthogonal, but how can I apply this? 
Thank you in advance.","['matrices', 'linear-algebra', 'symmetric-matrices', 'eigenvalues-eigenvectors']"
3448590,Is this a compact operator?,"Define $T: L^1 [0,1] \rightarrow C[0,1] $ as $$Tf(x) = \int_0^x f(t)dt$$ In my understanding it's compact since $$sup | \int_0^x f_n(t)dt - \int_0^xf_m(t)dt | \leq  \int_0^x |f_n(t) -f_m(t)|dt \leq \int_0^1 |f_n(t) -f_m(t)|dt = \Vert f_n-f_m\Vert_1$$ So for any convergence sequence $\{f_n\} \in L{[0,1]}$ , $\{Tf_n\} $ is a convergence sequence in $ C{[0,1]}$ . But the answer is that the operator is noncompact. What goes wrong?","['operator-theory', 'compact-operators', 'functional-analysis']"
3448616,A difficult game theory riddle,"Suppose a master hires $n$ servants who work for him. At the end of the day, the service come to him and request a wage for their service. They are able to request a wage up to $\$1$ , but no more. With $1/2$ probability, the master is in a good mood an will give all servants their requested wages. With $1/2$ probability, the master is in a bad mood and only pays the the servant with the lowest request; however, he pays him wage $g(x)$ where $g$ is a continuous, differentiable, monotonically increasing $g(0)=0$ and $x$ is the wage requested by the servant who requested the highest wage. If there is a tie in this state, then nobody is payed any wage. No servant knows if the master is in a good or bad mood and all share the half-half prior belief. Show that there is a symmetric equilibrium (Nash) where each servant makes a wage request according to the same distribution over some interval in $[0,1]$ . This means that anywhere in the support of this interval will give the same expected wage to the servant conditional on the strategy being used by the others and, of course, anywhere outside of the interval gives the same or lower expected wage. Show that this equilibrium is unique among symmetric equilibria. Progress: Let A be the good-mood state and B be the bad-mood state of the world. Note that servants will never want to tie and so a symmetric solution will never contain atoms. Let $F$ be the equilibrium distribution and consider the maximum of the support $\bar{w}$ . Any wage offer close to the maximum of the support becomes arbitrarily unlikely to get paid in state B (this follows from no atoms). In this case, if $\bar{w}< 1$ , the servant will eventually earn more in expectation by giving up on earning anything in state B and will be better of requesting $\$1$ . This implies that the maximum must be one. Because every request in the support must earn the same expected wage, and $\$1$ is in the support, the expected wage is $\$1/2$ . From this we can write an equation for the expected wage for any request in the interval: \begin{align}
1=\frac{1}{2}w+\frac{1}{2} \left(1-F(w) \right)^{n-1}   \int_w^1 g(z) f(z) (n-1)  \frac{(F(z)-F(w))^{n-2}}{(1-F(w))^{n-1}} \;dz\\
1=\frac{1}{2}w+\frac{1}{2} (n-1)   \int_w^1 g(z) \left( F(z)-F(w)\right)^{n-2} \;dF(z)
\end{align} Here, given a proposed wage $w$ and assuming all other $(n-1)$ servants use mixed strategy according to $F$ , $(1-F(w))^{n-1}$ is the probability that all other requested wages were higher than $w$ and that the payment will be made. Given that a request was higher than $w$ , it's distribution is then the truncated distribution $\frac{F(z)-F(w)}{1-F(w)}$ . The distribution of the maximum of this is then $\left(\frac{F(z)-F(w)}{1-F(w)}\right)^{n-1}$ . If a pdf exists, the maximum pdf is then $ f(z) (n-1)  \frac{(F(z)-F(w))^{n-2}}{(1-F(w))^{n-1}}$ which is what shows up in the first integral. The integral term is the expected wage given request $w$ . Seems obvious to me that the $F$ should exist and be unique, just seems difficult to show this for arbitrary $n$ . Maybe there should be some simple way to argue this?","['game-theory', 'nash-equilibrium', 'ordinary-differential-equations', 'integro-differential-equations']"
3448628,Combinatorics and Expected Value,"There are 15 candidates running for a given Senate seat, comprised of 10 men and 5 women. There are 32 polls, in which any of the candidates are equally likely to be ranked first, independently of the other polls (meaning the position of each candidate on any of the polls is purely random). Find the expected value of the number of times that a woman will rank 1st in any of the polls. I understand I need to find the probability of that any given woman will rank 1st in at least 1 of the polls, which I need direction on how exactly to approach.","['statistics', 'combinatorics', 'probability']"
3448681,Know that $\tan\left(\alpha-\frac{\pi}{4}\right)=\frac{1}{3}$ calculate $\sin\alpha$,"Know that $\tan\left(\alpha-\frac{\pi}{4}\right)=\frac{1}{3}$ calculate $\sin\alpha$ My proof: $\tan\left(\alpha-\frac{\pi}{4}\right)=\frac{1}{3}\\
\frac{\sin\left(\alpha-\frac{\pi}{4}\right)}{\cos\left(\alpha-\frac{\pi}{4}\right)}=\frac{1}{3}\\3\sin\left(\alpha-\frac{\pi}{4}\right)=\cos\left(\alpha-\frac{\pi}{4}\right)\\\sin^2\left(\alpha-\frac{\pi}{4}\right)+9\sin^2\left(\alpha-\frac{\pi}{4}\right)=1\\\sin\left(\alpha-\frac{\pi}{4}\right)=\pm\frac{1}{\sqrt{10}}\\
\sin\left(\alpha-\frac{\pi}{4}\right)=\sin\alpha\cos\frac{\pi}{4}-\sin\frac{\pi}{4}\cos\alpha=\frac{\sqrt{2}}{2}\sin\alpha-\frac{\sqrt2}{2}\cos\alpha=\frac{\sqrt2}{2}\left(\sin\alpha-\cos\alpha\right)=\pm\frac{1}{\sqrt{10}}\\\sin\alpha-\cos\alpha=\pm\frac{1}{\sqrt{5}}\\\sin\alpha=\pm\frac{1}{\sqrt{5}}+\cos\alpha$ I have no idea how to determine $\sin\alpha$",['trigonometry']
3448725,"Positiveness of some functions, connection with the central limit theorem and stable distributions","Final update on 11/28/2019: I have worked on this a bit more, and wrote an article summarizing all the main findings. You can read it here . Let us consider the following function: $$f(x) = \frac{1}{2\pi}\int_{-\infty}^{\infty} \cos(xt)\cdot\exp\Big(-a^2(b-|\sin(ct)|^d)\cdot t^2\Big)dt.$$ Here $-\infty < x < \infty, a\geq 1, b=4, c=1$ and $d=1$ or $d=2$ . The function $f(x)$ is a symmetric density centered at zero, it integrates to one, all its odd moments are zero, and all its even moments exist and are positive. Indeed, this is the density of a random variable $X$ with the following characteristic function: $$\psi_X(t) = \exp\Big(-a^2(b-|\sin(ct)|^d)\cdot t^2\Big)\Big.$$ Most importantly, it is NOT the density of a Gaussian distribution (unless $c=0$ or $d=0$ ) and its variance is finite. The big question is this: is it really a density, that is, is the characteristic function a valid one? The one thing that needs to be confirmed is whether $f(x)\geq 0$ everywhere. In the cases that I investigated, the answer seems to be positive, but the minimum value of $f(x)$ on any finite interval is so close to zero that it is impossible to conclude. It certainly looks like $f(x) > -10^{-16}$ everywhere but unfortunately this is too close to zero to be confirmed by numerical computations as the precision in my algorithms is about 15 digits. WolframAlpha is also unable to answer this question. Below is the chart for $f(x)$ , with $a=1, b=4, c=1, d=2$ . My computations tell me that $f(-39.71) \approx -2.94 \times 10^{-17}$ yields the absolute minimum, while $f(39.71) \approx -1.38 \times 10^{-17}$ . This is beyond the precision offered by the programming language, and anyway $f(-39.71) = f(39.71)$ . WoframAlpha returns $f(-39.71) = f(39.71) = 0$ (an absolute $0$ ), see the computation here . By contrast, if $a=1, b=2, c=1, d=2$ , then the minimum is $-0.000003388$ and it is clearly negative and confirmed by WolframAlpha: it is attained at $x\approx \pm 13.56$ . The case $a=1, b=4, c=1, d=1$ is even more challenging, with $f(x)$ looking perfectly strictly positive everywhere. See also my related question posted on CrossValidated, here . Connection with CLT and Stable Distributions If any of these functions is positive (say if $a\geq 1, b=4, c =1, d=2$ ) then we are dealing with a stable family of true densities governed (in this example) by one parameter: $a\geq 1$ . There are two consequences to this, unless something is wrong in my reasoning: It invalidates the classical theory of stable distributions, stating
that the only stable family with a finite variance is the Gaussian
family (see the book Limit Distributions for Sums of Independent Random Variables , by Gnedenko and Kolmogorov, published in 1954; the whole purpose of this book is proving this very fact.) It also potentially invalidates the central limit theorem (CLT): If $X_1, X_2$ are   i.i.d. with a distribution from that family, the same is true for $X_1 + X_2$ , and indeed for $\lim_{n \rightarrow \infty} (X_1+\cdots +X_n)/\sqrt{n}$ . Note that $E(X_i)=0$ . Thus, the convergence in distribution is towards a distribution from that same family, which does NOT include the Gaussian law. The only $X_i$ 's known to violate the CLT have an infinite variance, for instance the Cauchy distribution which also constitutes a stable family. Yet in this case the variance is finite. Question Thus my question is this: is it true that $f(x) \geq 0$ everywhere, at least depending on the parameters, and excluding the Gaussian case. What about the stability of the family of distributions introduced here (it is fully stable under addition / multiplication by a constant?) Update 2 I just computed the density in question in the case $c=0$ . This corresponds to a Gaussian distribution, thus $f(x)$ is definitely strictly positive in this case. Yet my program returns the global minimum as being below zero, about $-4 \times 10^{-17}$ . This suggests that negative values (of similar magnitude) obtained in the case $a=1, b=4, c=1, d=2$ are just an artifact of machine precision. This boosts my confidence in the fact that we are also dealing with a proper density in this latter case. But it is not a proof of course, and I am still a little skeptical. For those interested, I am now looking at some nasty distribution, something defined by a CF like $$\psi_X(t) = \exp\Big(-a^2 |t|^{2+\sin(1/|bt|)}\Big).$$ This density looks very smooth yet is really nasty in some sense. Let's call it $H(a, b)$ as it is governed by two parameters $a, b$ . It integrates to 1, but... it is not a density! The minimum is very slightly below zero, around $-0.02$ . I am somewhat confident that I will find one within the next 10 days, with the same nastiness, that is a proper density. Here is a proposed generalization. The $H(a, b)$ distribution (if it was actually a distribution) is semi-stable in the following sense: stable both under addition and multiplication by a scalar, separately but not jointly stable. What it means is this: If $X,Y$ are independent and are $H(a_1, b), H(a_2,b)$ respectively,
then $X+Y$ and $X-Y$ is $H(\sqrt{a_1^2+a_2^2},b)$ . If $X$ is $H(a,b)$ and $r>0$ , then $rX$ is $H(ar, br)$ . As a result, $Z=(X_1 + \cdots + X_n)/n$ is $H(a, b/\sqrt{n})$ . A general class of 2-parameter semi-stable, symmetric distributions centered at zero (much larger than the class of symmetric stable distributions centered at zero) is defined by the following characteristic function: $$\psi_X(t) =\exp\Big[-a^2\Big(p(b\cdot|t|)+q(b\cdot|t|)\Big) \Big] .$$ Here $p,q$ are two real-valued functions chosen so that $\psi_X$ is a proper characteristic function, and $b>0$ . For instance $p(t) = t$ and $q(t) = t^2$ . If you use the product $p(b\cdot|t|)\times q(b\cdot|t|)$ rather than the sum $p(b\cdot|t|) + q(b\cdot|t|)$ , it also works.","['statistics', 'characteristic-functions', 'probability-distributions', 'real-analysis', 'probability-theory']"
3448759,"How many number of non zero pairs $(a,b)$ such that $a,b$ are both palindrome numbers, and the sum of $a$ and $b$ is $A.$.","Given any number let say $N$ , how many ways this can be written as the sum of the palindrome numbers. 
For example $1443$ there are $20$ pairs of palindrome which have sum $1443$ . $(1441, 2),
(1221, 222),
(999, 444),
(989, 454),
(979, 464),
(969, 474),
(959, 484),
(949, 494),
(898, 545),
(888, 555),
(878, 565),
(868, 575),
(858, 585),
(848, 595),
(797, 646),
(787, 656),
(777, 666),
(767, 676),
(757, 686)
(747, 696)$ I tried this and able to find all possible pairs for small numbers $ N<=10^{14} $ . list all palindromic numbers in $O(\sqrt N * log N)$ . Iterate through the list for all 1.... $\sqrt N$ int id = lowerBound(allPanin, n / 2 + 1);

    for (int i = 0; i < id; i++) {

        int p = Collections.binarySearch(allPanin, n - allPanin.get(i));
        if (p > 0){
            System.out.println(n - allPanin.get(i) + "", "" + allPanin.get(i));
            tp += 1;
        }
    } But how to find all pairs for $N <= 10^{18}$","['number-theory', 'palindrome', 'discrete-mathematics', 'elementary-number-theory']"
3448772,How to find the limit of this function using L'Hospital's rule?,"$$\lim_{x\rightarrow 0} \,\,\left( \sqrt[3]{1+2x+x^3} - \frac{2x}{2x+3}   \right) ^ {\frac1{x^3}} $$ I have already tried several options, but the only answer I have gotten so far is $e^{\infty}$ , which is incorrect. The correct answer is $e^\frac{43}{81}$ , which is easy to get by using Taylor series, but our task was to get the same one by using L'Hospital's rule. Can you help me with it?",['limits']
3448790,How to represent subset using 5-bit binary code?,"For the set $V=\{a, e, i, o, u\}$ , give the $5$ -bit binary string that codes each of the following subsets: $\{a, i,o\}; \{e\}; V; \emptyset$ ; Which subset is represented by the $5$ -bit string $10001$ ? Can I know how do you get the 5-bit binary string from the respective subsets? What are the differences between using 3-bit binary string to represent them and using 5-bit binary string?","['elementary-set-theory', 'data-structure', 'binary-operations', 'computer-arithmetic']"
3448796,Semi-circle inside of a square,"We have a square ABCD , and a semi-circle inside it with AB as its base. We make a tangent line from point C different from CB and mark its point of contact with the semi-circle F . Then we mark the intersection of BD with the semi-circle (different from point B ) point E . What's the area of triangle BEF if AB=10?","['triangles', 'circles', 'geometry']"
3448814,On the notation for the Jacobian using indices,"A contravariant vector is an object that is usually written with a superscript and it is defined by the ""transformation law"": $$V^{'i} = \frac{\partial x^{' i}}{\partial x^j} V^j $$ where $i,j = 0,1,2,3$ . In the definition above the fractional terms is referred to as the Jacobian. Now my confusion is the following: I understand that in the definition above really represent 4 different equations (due to the Einstein summation convention), but why does fractional term represent a matrix (the Jacobian).","['notation', 'derivatives']"
3448846,Method to solve long differential equation,$$(D^3-2D^2-5D+6)y=2e^{x}+4e^{3x}+7e^{-2x}+8e^{2x}+15$$ The complementary solution is : $ae^{x}+be^{3x}+ce^{-2x}$ . For the particular solution I get the form : $d_1+d_2xe^{x}+d_3xe^{-2x}+d_4e^{2x}+d_5xe^{3x}$ Proceeding after this becomes difficult as too many terms are getting involved. Is there a shorter method to solve such questions? I don't have any knowledge except trial solution method.,['ordinary-differential-equations']
3448855,"Some frogs form $2^{n-1}-1$ groups of $n$ frogs. If any frog can belong to multiple groups, prove the following","This is a repost of a question I saw here that was deleted. Suppose that we have some number $m\geq 1$ of frogs. These frogs form $2^{n-1}-1$ groups, each consisting of $n>1$ frogs. Each frog can be part of multiple groups. Suppose that each frog is colored red or blue. I want to show that, no matter how the frogs choose their groups, I can always assign blue or red to each frog such that each group contains at least one blue and one red frog. My attempt: I thought about using induction. Here are my thinking steps for small $n$ : If $n=2$ then there is only one group with two frogs. So I can assign ""blue"" to one frog and ""red"" to the other. If $n=3$ then there are three groups, each with three frogs. Now I already don't know what to do. I could easily brute force every possibility of the frogs to form groups, however that does not help my understanding of a potential induction step. If the statement is true for $n$ then it is true for $n+1$ : I don't know how to prove this.","['recreational-mathematics', 'puzzle', 'combinatorics']"
3448911,"Is a proper map of varieties $f:X\to Y$ an isomorphism if $f_Z: X\times_Y Z\to Z$ is an isomorphism for any closed, one-point subscheme $Z\subset Y$?","Let $f:X\rightarrow Y$ be a proper morphism of schemes of finite type over algebraically closed field $k$ (not necessarily of characteristic 0). Is is it true that $f$ is an isomorphism if $f_Z:X\times_Y Z\rightarrow Z$ is an isomorphism for every closed subscheme $Z\subset Y$ having support at one point of $Y$ ? This question is quoted from the proof of universal property of Poincare bundle in the book Abelian Varieties by D. Mumford. I guess what he means is that if for any $y\in Y$ , and any $m_{y}$ -primary ideal $I\subset \mathcal{O}_{Y,y}$ , the closed subscheme $V(I):=\mathrm{Spec}(\mathcal{O}_{Y,y}/I)$ induces $f_{V(I)}:X\times_Y V(I)\rightarrow V(I)$ which is assumed to be an isomoprhism, then $f$ is an isomorphism. I guess that if we can show that $\mathcal O_{Y,f(x)}\rightarrow \mathcal O_{X,x}$ is an isomorphism for any $y\in Y$ , then this induces an isomorphism $U\rightarrow V$ for some open neighborhoods $U\ni x$ and $V\ni f(x)$ , then we are done. But I think in general for a local morphism of local rings $h:A\rightarrow B$ , the induced morphism $A/h^{-1}(I)\rightarrow B/I$ being isomorphic for each $m_B$ -primary ideal $I$ only shows that $\widehat{h}:\widehat{A}\rightarrow \widehat B$ is an isomorphism. Anyone has some better understanding of above quotation?",['algebraic-geometry']
3448920,Two guys and a horse,"This problem is from my general maths textbook. Two guys will travel to a place $20$ miles away from their house. They both will start at the same time, and will walk at a constant velocity of $4$ miles/hour. However, they own a horse that can carry one person at a time and can run at $10$ miles/hour, regardless of whether someone is riding or not. Find the minimum time required for both of them to reach their destination. This is what I got till now: The horse will travel x miles with person 1, drop him off, and turn back to catch person 2 who had been walking that whole time. We will choose x in such a way that person 1 reaches the destination by the time the horse reaches person 2, and then the horse will carry person 2 the rest of the way, solving it gives $3 \frac{19}{41}$ hours. The answer provided is $3 \frac{1}{11}$ hours. What did I miss? Update 1: Apparently we can improve our choice of x. We'll be choosing it in such a way that both persons reach the destination at the same time. This resulted in overall $3 \frac{1}{3}$ hours.","['algebra-precalculus', 'arithmetic']"
3448963,Prove that $[(A\times B)\cup (B\times A) =(A\cup B)\times (A\cup B)] \iff A=B$,"Prove that $$[(A\times B)\cup (B\times A) =(A\cup B)\times (A\cup B)] \iff A=B$$ $$\Leftarrow$$ Assume $A=B$ $\therefore (A \times B) \cup (B \times A) = (A \times A) \cup (A \times A) =A^2$ and $(A \cup B) \times (A \cup B) = ( A \cup A) \times (A \cup A) = A \times A = A^2  (1)$ i have proved that if $A=B$ is to be true then the other part is also true now i want to prove the opposite $$\Rightarrow$$ Assume $(A\times B)\cup (B\times A) = (A\cup B)\times (A\cup B)$ Let $p$ be an arbitrary element $p \in (A \cup B) \times (A \cup B) \iff \exists x \exists y(x \in (A \cup B) \land y \in (A \cup B) \land p=(x,y))$ $ \iff \exists x\exists y((x\in A\lor x\in B) \land (y \in A \lor y\in B)\land p=(x,y))$ and i'm stuck right here i think that i have to prove that $A \subseteq B$ and $ B \subseteq A$ then $ A=B$ using my assumption
so any ideas that might help me ?","['elementary-set-theory', 'discrete-mathematics']"
3449019,English versions of Géométrie et théorie des groupes and Sur les groupes hyperboliques d’après Mikhael Gromov,"I am reading the paper ""Small cancellation theory and Burnside problem"" by Remi Coulon, and there are some references of it that were written in french. I searched for English translation but did not find anything. The references are: 1) M. Coornaert, T. Delzant, and A. Papadopoulos. Géométrie et théorie des groupes, volume
1441 of Lecture Notes in Mathematics. Springer-Verlag, Berlin, 1990. 2) É. Ghys and P. de la Harpe. Sur les groupes hyperboliques d’après Mikhael Gromov, volume 83
of Progress in Mathematics. Birkhäuser Boston Inc., Boston, MA, 1990. Can somebody help me to find english translations in the web for these? thanks.","['group-theory', 'algebraic-geometry', 'reference-request']"
3449030,Converse of 0/0 Type Stolz Theorem,"One version of Stolz Theorem is that Given two sequences $\{a_n\},\{b_n\}$ , with $\lim_{n\to\infty}a_n=0$ and $\{b_n\}$ is strictly decreasing and its limit is also $0$ . Then $$\lim_{n\to\infty}\dfrac{a_n-a_{n+1}}{b_n-b_{n+1}}=L<\infty$$ implies $$\lim_{n\to\infty}\dfrac{a_n}{b_n}=L.$$ I want to find a counterexample for the converse statement, although I'm not so sure is there any counterexample. I first assume $a_n/b_n$ has a limit and its limit is $L$ , then $$\dfrac{a_n-a_{n+1}}{b_n-b_{n+1}}-\dfrac{a_n}{b_n}=\dfrac{a_n/b_n-a_{n+1}/b_{n+1}}{b_n/b_{n+1}-1}$$ If $\lim b_n/b_{n+1}\neq 1$ , then it is easy to see that the inverse is also true. But if $b_n/b_{n+1}\to 1$ , we have $$\lim_{n\to\infty}\dfrac{a_n}{a_{n+1}}=\lim_{n\to\infty}\dfrac{a_n}{a_{n+1}}\cdot\dfrac{b_{n+1}}{b_n}=\dfrac LL=1$$ so if there is a counterexample, it must satisfy both $b_n/b_{n+1}\to 1$ and $a_n/a_{n+1}\to 1$ . Being stricted the search domain, I'm still not able to work out a counterexample. Hence is there really a counterexample or the converse is indeed true?","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3449092,"The number of sequences of length n from the set of K elements, so that each element occurs in the sequence","Number of combinations to make a sequence of length $N$ using set of $K \leq N$ elements so that each element occurs at least one time. For example with set ${1, 2}$ and $N = 3$ all possibilities are: (1, 1, 2) (1, 2, 1) (1, 2, 2) (2, 1, 1) (2, 1, 2) (2, 2, 1) What equals to: $\binom32\binom11 + \binom11\binom32$ Is there any way to get expression for number of combinations through $N$ and $K$ ?","['permutations', 'combinatorics']"
3449151,Strong deformation retract of a singleton implies locally path connected at that point?,"Strong deformation retract of singleton $\{x\}$ : there exists a continuous $H: X \times I \to X$ s.t. $\forall t \in I: H(x,t) = x$ , $\forall y \in X: H(y,0) = y$ and $\forall y \in X: H(y,1) = x$ . Locally path connected at a point $p$ : there exists an open neighborhood basis of $p$ consisting of path connected sets. So the question is where $\{p\}$ a strong deformation retract implies that $X$ is locally path connected at $p$ . I haven't been able to come up with any counterexamples: all spaces I have consider which are contractible are locally path connected at all points that are strong deformation retracts. I have prove the intermediate lemma, which would likely factor into to any proof of the affirmative: $\{p\}$ is a strong deformation retract implies that for all open neighborhoods $U$ of $p$ , there exists an open neighborhood $V \subseteq U$ of $p$ s.t. $\forall y \in V$ there exists a path from $y$ to $p$ lying entirely in $U$ . This can be proved by considering $H^{-1}(U)$ , where $H$ is the homotopy described above, noting that $\{p\} \times I \subseteq H^{-1}(U)$ , so by the tube lemma, there exists an open $V \subseteq X$ s.t. $V \times I \subseteq H^{-1}(U)$ and $p \in V$ . Then the homotopy induces a path from $y \in V$ to $p$ which lies in $U$ . On the other hand I have exhibited a TS $X$ s.t. there exists a point $p$ s.t. for all open neighborhoods $U$ of $p$ , there exists an open neighborhood $V \subseteq U$ of $p$ s.t. $\forall y \in V$ there exists a path from $y$ to $p$ lying entirely in $U$ , and yet $X$ is not locally path connected at that point. So the lemma alone isn't sufficient. Unfortunately, this space is not a strong deformation retract (I'm fairly certain) to that point $p$ , so it is not a counterexample. I can give a construction of the example if anyone wants it.","['general-topology', 'path-connected', 'homotopy-theory']"
3449207,What does Sánchez intended to mean here?,"In Ordinary Differential Equations: A Brief Eclectic Tour , Sánchez mentions the following. Assume that the three functions $x_1(t)<x_2(t)<x_3(t)$ are $T$ -periodic. Then, $$\int_0^T\Bigr( {\dot x_3(t)-\dot x_2(t)\over x_3(t)-x_2(t)} - {\dot x_3(t)-\dot x_1(t)\over x_3(t)-x_1(t)} \Bigl) dt =0.$$ Can someone explain how is that true?","['integration', 'definite-integrals', 'ordinary-differential-equations']"
3449209,Condition for $f(x)=p[x+1]+q[x-1]$ to be continuous at $x=1$,"The function $f(x)=p[x+1]+q[x-1]$ where $[x]$ is the greatest integer function is continuous at $x=1$ , if ___________________ $f(1)=2p$ $\lim_{x\to 1^+}f(x)=p(2)+q(0)=2p$ $\lim_{x\to 1^-}f(x)=p(1)+q(-1)=p-q$ $p-q=2p\implies p+q=0$ But my reference gives the solution $p=q$ , what is going wrong here ?","['limits', 'functions', 'limits-without-lhopital', 'continuity']"
3449245,Character theory - Exercise5.12 (Martin Isaacs),"This asks: Let $\varphi^{G} = \chi \in {\mathrm{Irr}}(G)$ with $\varphi \in {\mathrm{Irr}}(H)$ . Show that $Z(\chi) \subseteq H$ . Here is my solution: Fix a right coset transversal $T$ of $H$ in $G$ with $1 \in T$ . Let $x \in Z(\chi)$ . Then $$|\varphi^{G}(x)| = \varphi^{G}(1) = |T| \varphi(1)$$ and $\varphi^{G}(x) = \sum_{t \in T} \varphi^{\circ}(txt^{-1})$ . If $T(x) = \{ t \in T ~:~ txt^{-1} \in H \}$ , then by triangle inequality we have $$|T| \varphi(1) = |\varphi^{G}(x)| = |\sum_{t \in T(x)} \varphi(txt^{-1})| \leq |T(x)| \varphi(1)$$ This proves $|T| \leq |T(x)|$ and hence $T(x) = T$ . Therefore $txt^{-1} \in H$ for every $t \in T$ . In particular, we have $x \in H$ . I fail to see where am I using any of the characters are irreducible. Any idea?","['representation-theory', 'group-theory', 'finite-groups', 'characters']"
3449258,"According to limits there is a horizontal asymptote at y = 0, however the equation has a root at x = 1.",So I have the equation $$f(x)=\frac{(x-1)}{x^2}$$ This clearly has a root when $x=1$ however when considering limits we have the following $$\lim_{x\to\infty}f(x)=0$$ And similarly $$\lim_{x\to-\infty}f(x)=0$$ Which implies there is horizontal asymptote when $f(x)=0$ However this is clearly not the case since the function crosses the $y$ -axis. Have I made a mistake somewhere or is this a case where the definition of horizontal asymptotes doesn't work (or do I have the wrong definition!).,"['limits', 'calculus', 'functions']"
3449270,"Determine All Functions $f:[0,1] \to \mathbb{R}$","Determine All Functions $f:[0,1] \to \mathbb{R}$ that have the
  following properties: a) $ f $ is three times differentiable with $ f '' '(x) \geq 0 $ , for
  all $ x \in [0,1] $ b) $ f '$ is increasing and strictly positive: c) $ f '(1) (2f (1) -f (0) -f' (1)) \int ^ 1_0 \frac {dx} {(f '(x)) ^
 2} = 1 $ $$\frac{-\pi}{2}<x < \frac{\pi}{2}$$ $$0 < \frac{\pi}{2}+x < \pi$$ $$0 < \frac{\frac{\pi}{2}+x}{\pi}<1$$ So the function $$f (x) = tan (\frac {x} {\pi}) + \frac {1} {2}$$ This is a possible function. Finding them all is hard I think that can prove that cardinality in $ (0,1) $ is equal to cardinality in reais by proving that there is a bijective function that satisfies, But I could not","['integration', 'calculus', 'functions', 'derivatives']"
3449316,Inverse image of this set?,"Suppose that we have a function $f$ $:$ $X$ $\to$ $Y$ , with $ X $ $=$ {1,2,3,4,5,6} $Y$ $=$ {a,b} define $$
f(x) = \left\{
   \begin{array}{ll}
      a & \mbox{if $x =1$ OR $2 $ OR 3} \\
      b & \mbox{if $ x = 4 $ OR 5 OR 6} \
   \end{array}\right.
$$ my question is, when we take the f inverse of {a,b} will we get {1,2,3,4,5,6} OR {{1,2,3},{4,5,6}} ? Edited : I also have another doubt, do $f^{-1}(a)$ and $f^{-1}$ ({ $a$ }) mean the same?",['functions']
3449350,How can I justify this without determining the determinant?,"I need to justify the following equation is true: $$
    \begin{vmatrix}
    a_1+b_1x & a_1x+b_1 & c_1 \\
    a_2+b_2x & a_2x+b_2 & c_2 \\
    a_3+b_3x & a_3x+b_3 & c_3 \\
    \end{vmatrix} = (1-x^2)\cdot\begin{vmatrix}
    a_1 & b_1 & c_1 \\
    a_2 & b_2 & c_2 \\
    a_3 & b_3 & c_3 \\
    \end{vmatrix}
$$ I tried dividing the determinant of the first matrix in the sum of two, so the first would not have $b's$ and the second wouldn't have $a's$ . Then I'd multiply by $\frac 1x$ in the first column of the second matrix and the first column of the second, so I'd have $x^2$ times the sum of the determinants of the two matrices. I could then subtract column 1 to column 2 in both matrices, and we'd have a column of zeros in both, hence the determinant is zero on both and times $x^2$ would still be zero, so I didn't prove anything. What did I do wrong?","['determinant', 'linear-algebra']"
3449372,Smallest possible sum $\sum_{i=0}^{\infty} \frac{a_i^2}{a_{i+1}}$ over non-increasing infinite sequences starting with 1 [duplicate],"This question already has an answer here : Find the $\lim_{n\to\infty}\text{inf} \left(\frac {x_0^2}{ x_1}+\frac {x_1^2}{ x_2}+\cdots \frac {x_{n-1}^2}{ x_n}\right)$ (1 answer) Closed 2 years ago . Let $a_n$ be a sequence of positive numbers such that $a_0=1$ and $\forall n : a_n \ge a_{n+1}$ . Find the infinum of $\sum_{i=0}^{\infty} \frac{a_i^2}{a_{i+1}}$ over all such sequences. If $\{a_n\}$ is a geometric seriess $1, q, q^2, ...$ , where $0<q<1$ , then the sum equals $\frac{1}{q}+\frac{1}{1-q}$ , which has minimum at $q=\frac{1}{2}$ , so the infinum is no greater than $4$ . I suspect that the answer is indeed $4$ , but I have no idea how to prove that.",['sequences-and-series']
3449433,Selecting cards to form a fair game,"Background In an old card game we draw 2 cards from a pile of 2 red and 2 black cards without replacement. If the two cards have the same color (for instance red and red) you win. However, if the cards have opposite color you lose. This is a rich problem, especially if we instead look at the broader problem of drawing $2$ cards from a pile of $(n,m)$ cards, where we now have $n$ red and $m$ blue cards. After sorting out the information one can show that any solution must satisfy $$(n-m)^2 = n + m$$ from which it is not hard to deduce that every solution must be a pair of consecutive triangular numbers. $$(1,3), \ (3,6), \ (6,10), \ (10,15), \ldots$$ In other words we have $$T_2(n) = T_2(n-1) + n, \qquad T(n)=0, n\leq 1$$ Which of course also can be expressed as $T_2(n) = n(n+1)/2$ . So $\bigl(T_2(n), T_2(n+1)\bigl)$ forms every solution. My question is if similar beautiful patterns appear when we increase the number of cards we draw. Main statement Assume we have a pile of $(n,m)$ cards, where $n$ of the cards are red and $m$ are black and we draw $c$ cards from the pile (where $c \leq n + m$ ). Fix $n$ , how do we have to choose $m$ to obtain a fair game? E.g. a game where the probability of drawing a pile of cards of similar colors (red, red ..., red or black, black, ..., black) equals the probability of drawing cards of opposite color (any combination of red and black cards) For $c = 3$ it seems we have to find integer solutions to $$n(n-1)(n-2) + m(m-1)(m-2) = 3mn(n+m-2)$$ and this seems really hard. However, it seems $(1,5,3)$ is a solution. After an extensive computer search it seems $$(1,5), \ (5,20), \ (20,76), \ (76,285), \ (285,1065), \ (1065,3976), \ \ldots$$ Are the first few solutions when drawing three cards. It seems these satisfy $$
	T_3(u) = 5 T_3(u-1) - 5 T_3(u-2) + T_3(u-3) \ \text{with} \ T_3(1) = 1 \ \text{and} \ T_3(u) = 0 \ \text{if} \ u \leq 0.
$$ EDIT: Seems to boiling down to finding all integer pair such that $$     \binom{m}{c}\binom{n}{0} \Bigl/\binom{m+n}{c}\Bigr. 
    + \binom{m}{0}\binom{n}{c} \Bigl/\binom{m+n}{c}\Bigr. = \frac{1}{2}, $$ Where again $c \in \mathbb{N}_{\geq 2}$ and $c \leq n < m$ . The expression above can be ""simplified"" to $$\prod_{i=0}^{n-1} \frac{m+n-k-i}{m+n-i} + \prod_{i=0}^{m-1} \frac{n+m-k-i}{n+m-i} = \frac{1}{2}$$ and can be quite easily be numerically approximated. However, it does not lead me closer to finding every solution for every $c$ . EDIT 2: While I thought all solutions would be on the form $(a,b)$ , $(b,c)$ , $(c,d), \ldots$ this does not seem to be the case. 
In particular for $c = 6$ we $$T_6(1) = (1,11), \qquad T_6(2) = (2,19)$$ interesting! Problems Let $T_c(n)$ be the $n$ 'th solution when drawing $c$ cards. Is it true that $T_c(1) = 2c - 1$ for every $c\geq 2$ ? Is there a general recurrence relation for $T_c(n)$ ? Is there a closed expression for $T_c(n)?$ Given a particular $c$ how can we find all pairs $(n,m)$ that form a fair game?","['fair-division', 'combinatorics', 'card-games', 'game-theory', 'probability']"
3449443,Inequality in 4 variables Vasc's EV,"Let $a,b,c,d\geq0$ satisfying $a+b+c+d=4$ . Prove $$\sqrt{a^3+b^3+c^3+d^3}+2(\sqrt3
 -1)abcd\geq\sqrt{3(abc+abd+acd+bcd)}$$ Attempt: $a^3+b^3+c^3+d^3=(a+b+c+d)(a^2+b^2+c^2+d^2-ab-bc-cd-da-ac-bd)+3(abc+abd+acd+bcd)$ . Let's try it with Vasc's EV. Who knows?","['multivariable-calculus', 'buffalo-way', 'muirhead-inequality', 'inequality']"
3449459,"Given the sequence $(a_n)_{n \ge 1}$ with $a_1=2$ and $a_{n+1} = \frac{n^2-1}{a_n} + 2$ for $n \ge 1$, find the following limits.","I have the sequence $(a_n)_{n \ge 1}$ , such that: $$a_1 = 2, \hspace{1.5cm} a_{n+1} = \dfrac{n^2-1}{a_n}+2 \hspace{.25cm}, \forall n \ge 1$$ And I have to find $2$ limits: $$\lim\limits_{n \to \infty} \dfrac{a_n}{n} \hspace{3.5cm} \lim\limits_{n \to \infty} \dfrac{\sum\limits_{k=1}^{n}a_k^3}{n^4}$$ The second one completly put me in the dark. I don't see any trick that I could use. For the first one, I tried using Stolz-Cesaro: $$\lim\limits_{n \to \infty} \dfrac{a_{n+1}-a_n}{n+1-n} = \lim\limits_{n \to \infty} (a_{n+1}-a_n) = \lim\limits_{n \to \infty} \bigg ( \dfrac{n^2-1}{a_n} - a_n \bigg )$$ And I got stuck. I don't think I can find a closed form for $a_n$ , so I really don't know what should I do to find these $2$ limits.","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3449467,Is R[x] a ring of functions or a ring of expressions?,"I know that these two notions are isomorphic, but for a ring $R$ , is $R[x]$ a ring of functions (e.g. $f:x\mapsto x^3+1$ ) or a ring of expressions (e.g. $f(x)=x^3+1$ ). If it were the former, the variable $x$ would be meaningless and $R[x]=R[y]$ , but if it were the latter, $x$ would be important and $R[x] \cong R[y]$ (isomorphic), but $R[x]\neq R[y]$ .","['ring-isomorphism', 'ring-theory', 'abstract-algebra', 'polynomial-rings', 'polynomials']"
3449475,Twisted cubic as a plane section of the Segre threefold,"As usual, I have not a clue on how to tackle excercises our instructor assigns from Harris. The fact is that, at least to me, Harris is very concise and do not really builds the ''mindset'' to do solve this problems. It is asked to show that the twisted cubic $C\subset\mathbb{P}^3$ can be realized as the itersection of the Segre threefold $\Sigma_{1,2}\subset\mathbb{P}^5$ with a 3-plane $\mathbb{P}^3\subset\mathbb{P}^5$ I know that $\Sigma_{1,1}=V(x_0x_3-x_1x_2)$ and that I can write $\Sigma_{2,1}=V(x_0x_3-x_1x_2;x_2x_5-x_4x_3;x_0x_5-x_1x_4)$ while the twisted cubic as $C=V(x_0x_3-x_1x_2; x_1x_3-{x_2}^2; x_0x_2-{x_1}^2)$ . So both surfaces are in the zero locus of the quadric $x_0x_3-x_1x_2$ . What I would neeed then is a 3-plane embodying the two constraints $x_1x_3={x_2}^2; x_0x_2={x_1}^2$ do these two equations define a 3-plane in $\mathbb{P}^5$ ?","['algebraic-geometry', 'projective-geometry', 'problem-solving']"
3449476,Reduced scheme and covering with non affines reduced schemes,"For a scheme $X$ to be reduced there is a criterion that says that $X$ is reduced if there is a covering $(U_i)$ by affines open subsets such that for all $i$ , $\mathcal{O}_X(U_i)$ is reduced. I guess that it doesn't works anymore when the $U_i$ are not affines. Does someone has a example. I tried with the classical $\operatorname{Spec}(k[X]/(X^2))$ but all its open sets are affine... something like $\operatorname{Spec}k[x,y]/(x^2)$ maybe? Thanks!","['algebraic-geometry', 'abstract-algebra', 'commutative-algebra']"
3449530,"Bifurcation diagrams,value and classification","I got the following dynamical system in 1-d, $$\dot x = (x+\mu)(\mu+2x-x^2)$$ Im asked to find dependence of the the stationary points of the system and its stability with respect the $\mu$ parameter. Then draw the bifurcation diagram and find at which $\mu$ the bifurcation occurs. Before showing my attempt of solution I have to say sorry, but Im really lost and I havent found any reference to study this properly. Here we go, Attempt of partial solution For the stationary(fixed points), we have that $x=-\mu$ or $x=1\pm 1\sqrt{1+\mu}$ . So, now we have to analyze stability for the cases $\mu >-1$ and $\mu <-1$ . We will check the sign of $\frac{d((x+\mu)(\mu+2x-x^2))}{dx} = 3\mu + 4x - 2 \mu x - 3 x^2$ . Case 0: $\mu = -1$ theres only one stationary point which is x=1. Case 1: $\mu >-1$ , 1.1)For $x=-\mu$ , $\frac{d((x+\mu)(\mu+2x-x^2))}{dx} = 3\mu-4\mu+2\mu^{2}-3\mu^{2}<0$ . So, $x=-\mu$ is stable. 1.2)For $x= 1+1\sqrt{1+\mu}$ , $\frac{d((x+\mu)(\mu+2x-x^2))}{dx}=-2 (\mu + 1)( \sqrt{\mu+ 1} + 1)<0$ 1.3) For $x = 1-1\sqrt{1+\mu}$ , $\frac{d((x+\mu)(\mu+2x-x^2))}{dx}=2 (1 + \mu) (-1 + \sqrt{1 + \mu})>0$ which implies it is unstable. Case 2: $\mu <-1$ The way to work it is analogous to what we did in C.1. Now, I have no idea how to draw the bifurcation diagram. Its only one diagram or its 1 for each case?, what exactly means that 'a bifurcation occurs' and how do I classify these points into pitchfork, saddle node and transcritical? Thanks so much for your help, I really appreciate it. <3","['ordinary-differential-equations', 'bifurcation', 'stability-in-odes', 'stability-theory', 'dynamical-systems']"
3449589,Example 1.4 in Lee's Introduction to Smooth Manifolds,"In Example 1.4 of Lee's Introduction to Smooth Manifolds , which is showing that the $n$ -sphere, $\mathbb{S}^n$ is a topological $n$ -manifold, the following is stated. In the part where the author shows that $\mathbb{S}^n$ is locally Euclidean, he does the following. For $1\leq i \leq n+1$ he let's $$U_i^+ = \{(x^1, \cdots, x^{n+1}) \in \mathbb{R}^{n+1} \ | \ x^i > 0 \}$$ and $$U_i^{-} = \{(x^1, \cdots, x^{n+1}) \in \mathbb{R}^{n+1} \ | \ x^i < 0 \}.$$ Then he defines $f : \mathbb{B}^n \to \mathbb{R}$ by $$f(u) = \sqrt{1-|u|^2}$$ and claims that $U_i^+ \cap \mathbb{S}^n$ is the graph of the function $$x^i = f(x^1, \dots, \widehat{x^i}, \dots, x^{n+1})$$ and $U_i^- \cap \mathbb{S}^n$ is the graph of the function $$x^i = -f(x^1, \dots, \widehat{x^i}, \dots, x^{n+1})$$ and where the hat indicates omission of the $x^i$ . Now here is where my confusion comes about. Let me call the first function that $U_i^+ \cap \mathbb{S}^n$ is supposedly the graph of to be $g_i$ and let me label $h_i$ as the function which $U_i^- \cap \mathbb{S}^n$ is the graph of. So now $$g_i = f(x^1, \dots, \widehat{x^i}, \dots, x^{n+1})$$ and $$h_i = -f(x^1, \dots, \widehat{x^i}, \dots, x^{n+1}).$$ The problem that I'm having is that if I want to write down the domain and codomain of $g_i$ and $h_i$ set-theoretically, they are both going to be maps from $\mathbb{B}^{n+1} \to \mathbb{R}$ , because surely one would need both $g_i$ and $h_i$ to take inputs of the form $(x^1, \dots, x^i, \dots, x^{n+1})$ to even begin talking about removing the $x^i$ , so we must have $g_i, h_i : \mathbb{B}^{n+1} \to \mathbb{R}$ , but the graph of these functions would then be a subset of $\mathbb{R}^{n+2}$ whereas $U_i^- \cap \mathbb{S}^n$ is a subset of $\mathbb{R}^{n+1}$ . So my question is how can we rigorously (in terms of set theory) define these functions $g_i$ and $h_i$ so that $U_i^+ \cap \mathbb{S}^n$ is the graph of $g_i$ and $U_i^- \cap \mathbb{S}^n$ is the graph of $h_i$ ?","['elementary-set-theory', 'differential-geometry']"
3449649,Constructing a Borel set,"I have to make a Borel set $E \subset R $ such that $ 0 < m(E \cap I) < m(E)$ , for all real segment $I$ , where $ m $ is the Lebesgue measure.
I also have to say if it is possible for E to have $m(E)< \infty$ I know that I have to take a dense sequence $(r_j)$ , such as $Q$ , $a_j > 0$ such that $a_k > \sum_{j=k+1} ^{\infty} {a_j}$ , such as $ a_j = 1/3^j$ , and then define $I_j = (r_j-a_j,r_j+a_j)$ , $E_k= I_k \setminus \bigcup _{j=k+1}^{\infty} {I_j} $ , and finaly $E = \bigcup E_k$ . I just don't know how to calculate its measure, nor how to prove that $m(E)$ can or can't be finite.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
3449668,What is the value of $ g (x + f (y)) $?,"Let $ f, g: \mathbb {R} \to \mathbb {R} $ function such that $ f (x + g (y)) = - x + y + 1 $ for each pair of real numbers $ x, y $ . What is the value of $ g (x + f (y) )$ ? Solution: Correct?","['contest-math', 'functions', 'proof-verification']"
3449738,Proof that Singular Solution of Clairaut's Equation is the envelope of the family of General Solutions [duplicate],"This question already has an answer here : Relation between general solutions and singular solution of Clairaut’s equation. (1 answer) Closed 2 years ago . I want to show that the singular solution is the envelope for the general solutions. Proof Outline Both solutions pass from the same point $(a,b)$ Both solutions have the same gradient at that point (are tangent to each other) Proof: The form of Clairauts equation is $$y(x) = xy' + f(y')$$ You differentiate once to get $$y' = y' + xy'' + f'(y')y''$$ You rearrange and get two solutions The general solution $$y = Cx + f(C)$$ The singular solution $$x + f'(y') = 0$$ From the general solution we get $$a = (b - f(C))/C$$ Subbing this in to the singular solution we get $$b - f(C) + Cf'(y') = 0$$ Here, I need to show that this equation holds to show that for $x=a$ , the singular solution also passes $y=b$ , which will cover (1) from my requirements. Also, any help on (2) would be greatly appreciated. I have no idea how to proceed with that.","['envelope', 'singular-solution', 'proof-writing', 'ordinary-differential-equations']"
3449764,Exponential generating function of the falling factorial,"Let $\alpha$ be a real number. Define the sequence $(a_n)_n$ by $a_0=1$ and $a_n=\alpha(\alpha-1)\cdots(\alpha - (n-1))$ for $n\geq 1$ . Find the exponential generating function of this sequence. We have that $a_n=(\alpha-(n-1))a_{n-1}$ for $n\geq1$ , so \begin{align*}
A(x)&=\sum_{n\geq 0}a_n\frac{x^n}{n!}=a_0+\sum_{n\geq 1}a_n\frac{x^n}{n!}\\
&=1+\sum_{n\geq 1}(\alpha+n-1)a_{n-1}\frac{x^n}{n!}\\
&=1+\sum_{n\geq 0}(n+\alpha)a_{n}\frac{x^{n+1}}{(n+1)!}=1+\alpha\int_0^xA(t)dt+\sum_{n\geq 0}n\frac{x^{n+1}}{(n+1)!}\end{align*} I'm stuck here. I tried to write the last sum as an integral and then solve a differential equation for $A(x)$ , but it didn't work. Should I search for another recurrence relation that $a_n$ satisfies?","['combinatorics', 'generating-functions']"
3449862,On the existence a symmetric positive definite matrix,"Let $u,v\in\mathbb{R}^n$ be such that $\langle u,v\rangle>0.$ My question is whether or not there exists a symmetric positive definite matrix $Q$ such that $v=Qu$ . If such a matrix $Q$ exists, how to construct $Q$ from $u,v$ ? Thank you for all solutions.",['linear-algebra']
3449869,How do we define the cotangent space as the quotient of ideals?,"I am interested in the definition of the cotangent space as the quotient space of ideals. The definition goes like this: Let $\mathcal M$ be a smooth manifold. $C^\infty (\mathcal M)$ is the ring of smooth scalar fields on $\mathcal M$ . Let $\mathcal I_p$ be the greatest subring of $C^\infty (\mathcal M)$ where $\phi (p)=0$ for all $\phi \in \mathcal I_p$ . $\mathcal I_p$ is an ideal. The square of this ideal is $\mathcal I_p^2=\{\sum_{i=1}^n \phi_i \psi_i | n\in \Bbb N, \phi_i,\psi_i\in\mathcal I_p \}$ . $\mathcal I_p$ and $\mathcal I_p^2$ are vector spaces. The quotient space of $\mathcal I_p$ and $\mathcal I_p^2$ is $\mathcal I_p/\mathcal I_p^2=\{\phi+\mathcal I_p^2|\phi\in\mathcal I_p\}$ . This quotient space is either equal to the cotangent space on $\mathcal M$ at $p$ or isomorphic to it. An element of $\mathcal I_p/\mathcal I_p^2$ could look like $\Phi=\{\phi + \psi \gamma, \phi + \eta \nu, \phi + \delta \upsilon  + \alpha \beta,... \}$ . How is $\Phi$ interpreted as a covector such as $\text d\phi_p$ ? Is $\Phi$ equal to $\text d \phi_p$ ?","['co-tangent-space', 'abstract-algebra', 'ideals', 'differential-forms', 'differential-geometry']"
3449930,How to compute $\sum_{n=1}^\infty\frac{(-1)^nH_n}{n^4}$ by real integration only?,"How to prove, by real methods that $$\sum_{n=1}^\infty\frac{(-1)^nH_n}{n^4}=\frac12\zeta(2)\zeta(3)-\frac{59}{32}\zeta(5)$$ where $H_n$ is the harmonic number and $\zeta$ is the Riemann zeta function. This alternating Euler sum was already evaluated by M.N.C.E here using complex analysis and also by Cornel using series manipulation. My question here is can we do it by integration only? The integral representation of the sum is $\ \frac16\int_0^1\frac{\ln^3x\ln(1+x)}{x(1+x)}dx$ . Thanks.","['integration', 'real-analysis', 'alternative-proof', 'harmonic-numbers', 'sequences-and-series']"
3449932,Deriving the ideal equation for sluice gate problems,"I'm trying to figure this problem out, i know the correct answer, and i know the method, but for some reason i'm missing something and i'm just not getting there, any help would be greatly appreciated. Consider a Sluice Gate (lock gate) as pictured, A brief Description is. A large reservour if fluid of depth $h_1$ is held stationary in $x < 0$ to the left of a vectical gate at the origin of width W. The gate is raised and fluid streams steadily through the opening between the bottom of the gate and the base of the reservoir. Far upstream (the left of the gate) the fluid moves with constant velocity $u_1$ in the x horizontal direction and uniformly through the depth $h_1$ . far upstream,  (to the right of the gate) the fluid assumes a depth $h_2$ and moves with constant velocity $u_2$ in the horizontal x direction. The job is to Derive a relation expressing conservation of mass. Use Bernoulli's equation along a suitable streamline in order to show two >possible choices of $\frac{h_2}{h_1}$ are $\frac{h_2}{h_1} = 1$ and > $\frac{h_2}{h_1} =\frac{Fr^2+Fr\sqrt{Fr^2+8}}{4}$ where $Fr$ is the Froude number $Fr = \frac{u_1}{\sqrt{gh}}$ Then finally Find the net force on the raised gate So, 
1. Deriving a relationship expressing conservation of mass is just understanding that as the flow empties from one side, it must rush into the other at the same rate,  and so we have $$Q = u_1 A_1 = u_2 A_2 \implies Q = u_1 h_1W = u_2 h_2 W$$ as our relation. this has been bugging me quite a bit, i'll come back to this. with This question, i believe the correct method is to pick a control volume at about the sluice, then combine the above conservation of mass equation with bernoulli's equation for a steady flow. so
here i go... We express Bernoulli's equation as $$\frac{1}{2} \rho u^{2}_1+\rho g h_1 - \frac{1}{2}\rho u^{2}_{2}+\rho g h_2= p_{constant_1} - p_{constant_2} = P_{c}$$ where we have h is the elevation, $\rho$ the density and u is the flow velocity. we have that the pressure also cancels out. and the above equation happens because bernoulli's is a constant along any streamline in the flow. now using this line of logic, i find myself coming up with $$F = \rho g \frac{\left(1-\frac{h_2}{h_1}\right)^3}{2\left(1+\frac{h_2}{h_1}\right)}$$ which means im missing a step as the correct answer is actually $F_{net} = h_1^2 W\rho g \frac{\left(1-\frac{h_2}{h_1}\right)^3}{2\left(1+\frac{h_2}{h_1}\right)}$ This has been really bothering me for the last few, so any help would be greatly appreciated. Thank you for taking the time to read this.","['multivariable-calculus', 'calculus', 'physics', 'fluid-dynamics']"
3449978,What does algebraic multiplicity mean for compact operators,"Im trying to understand Lidskii Theorem which states the following. If $H$ is a separable Hilbert Space, $T:H \rightarrow H$ a (compact) trace class operator and $\{\gamma _n\}_{n\in \Bbb N}$ are the eigenvalues of $T$ , each repeted as many times as its algebraic multiplicity, then $$Trace(T)= \sum_{n=1}^\infty \gamma_n$$ And I couldn't find anywhere the definiton of algebraic multiplicity of an eigenvalue in the infinite dimensional case. I started believing it has something to do with the following statement. Let $T:H \rightarrow H$ be a compact operator, for every eigenvalue $\gamma$ there exist a $m\in \Bbb N_0$ such that $$\{0 \} \subsetneq Ker(T-\gamma.Id)\subsetneq Ker(T-\gamma.Id)^2 \subsetneq \dots\subsetneq Ker(T-\gamma.Id)^m=Ker(T-\gamma.Id)^{m+1}=Ker(T-\gamma.Id)^{m+2}=\dots$$ I thought $m$ was the algebraic multiplicity of $\gamma$ but then realiced this does not match with the definition in the finite dimensional case, for example, taking $T=Id_{\Bbb R^2}$ and $\gamma=1$ . So my question, again, is ""what does algebraic multiplicity means?""","['compact-operators', 'eigenvalues-eigenvectors', 'trace', 'functional-analysis', 'spectral-theory']"
3449995,Long time average of solution to ODE with almost periodic structure,"I encountered the following question in my studies: Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a Bohr almost periodic function such that $\inf_{\mathbb{R}} f = 0$ but $f(x) > 0$ for all $x\in \mathbb{R}$ . An example is $$ f(x) = 2-\sin(2\pi x) - \sin(2\pi \sqrt{2}x).$$ If $\eta(\cdot)$ is the solution to the following ODE $$ \dot{\eta}(s) = f(\eta(s)), \qquad \eta(0) = 0.$$ Is there any tools that allow us to say something about the limit $$ \lim_{s\rightarrow +\infty} \frac{\eta(s)}{s}$$ and if the limit exists (I guess, by numerical implementations) can we say anything about the rate of convergence of $\frac{\eta(s)}{s}$ to that limit?","['ordinary-differential-equations', 'almost-periodic-functions', 'asymptotics', 'real-analysis', 'stability-in-odes']"
3450011,"maximize $\sum_{A\subseteq [q], A\neq \emptyset} \alpha_A \log(|A|)$ with nonlinear constraints","Let $[q]:=\{1,2,3, \ldots,q\}$ , where $q$ is a positive integer. Consider a vector $\underline{\alpha}=(\alpha_A)_{A\subseteq [q], A\neq \emptyset}$ , where each $\alpha_A \in \mathbb{R}$ . Note that such a vector $\underline{\alpha}$ has $2^q-1$ entries. Given such an $\underline{\alpha}$ , we define the following: $$ OBJ(\underline{\alpha}):=\sum_{A\neq \emptyset} \alpha_A \log(|A|), \quad v(\underline{\alpha})=\sum_{A\neq \emptyset} \alpha_A, \quad E(\underline{\alpha})=\sum_{\{ \{A,B\}: A,B \subseteq [q], A\cap B=\emptyset \}} \alpha_A \alpha_B, $$ where the sum in the definition of $E(\underline{\alpha})$ is taken over all unordered pairs of disjoint subsets of $[q]$ . Define $FEAS(1/4)=\{\underline{\alpha}: \alpha_A \geq 0 \text{ for all nonempty A },\,  v(\underline{\alpha})=1, \, E(\underline{\alpha})\geq 1/4 \}$ . I believe that the following is true: $$OPT(1/4):= \max_{\underline{\alpha} \in FEAS(1/4) } OBJ(\underline{\alpha})=\frac{\log(\lfloor q/2 \rfloor \cdot \lceil q/2 \rceil)}{2}.   $$ I know that it is true when $q$ is even (it was proven), but I want to show that it also holds for odd $q$ . I have verified that this is true for $q=3,5,7,9$ using SageMath, but would like to prove it by hand for general odd $q$ . I think that this problem can be solved using the language of probability. It is natural to do so given that the sum $v(\underline{\alpha})=\sum \alpha_A=1$ in the set $FEAS(1/4)$ . Consider a random variable $X$ on $2^{q}\setminus \{\emptyset\}$ (the power set of $[q]$ , excluding the empty set) such that $\mathbb{P}[X=A]=\alpha_A$ , where $A \subseteq [q]$ . Note that $2\cdot E(\underline{\alpha})$ can be interpreted as the probability that from the sets in $2^{[q]}\setminus \{\emptyset\}$ one selects two disjoint sets $A$ and $B$ . Since by definition of $FEAS(1/4)$ , $2\cdot E(\underline{\alpha}) \geq 1/2$ , we see that we are more likely to select two disjoint sets rather than two sets which have a nonempty intersection. One can verify that the set $FEAS(1/4)$ is compact, so there exists some $\underline{\alpha}^*\in FEAS(1/4)$ for which $F(\underline{\alpha}^*)=\max_{\underline{\alpha} \in FEAS(1/4) } F(\underline{\alpha})$ . I conjecture that this vector $\underline{\alpha}^*$ has exactly 2 nonzero entries $\alpha^*_{A_1}=1/2$ and $\alpha^*_{A_2}=1/2$ , where $|A_1|=\lfloor q/2 \rfloor$ , $|A_2|=\lceil q/2 \rceil$ , $A_1\cap A_2 =\emptyset$ , and $A_1\cup A_2=[q]$ . That is, the sets $A_1$ and $A_2$ form a partition of the first $q$ positive integers and their sizes are as equal as possible. If it is difficult to prove this for general odd $q$ , how would I prove it for, say, $q=5$ ? I would like to avoid using Lagrange multipliers with so many variables. Let $\gamma \in \mathbb{R}$ such that $0\leq \gamma \leq \frac{q-1}{2q}$ . Then $$OPT(\gamma)=\{\underline{\alpha}: \alpha_A \geq 0 \text{ for all nonempty A },\,  v(\underline{\alpha})=1, \, E(\underline{\alpha})\geq \gamma \}.$$ In the paper for which I provided the link above, Serguei Norine shows that $OPT(\gamma)\leq \log(q(1-2\gamma))$ , with equality holding if and only if $\gamma=\frac{r-1}{2r}$ for some positive integer $r$ dividing $q$ . When $r=2$ we see that $\frac{r-1}{2r}=1/4$ , so $OPT(1/4)=\log(q/2)$ if and only if $q$ is divisible by two.","['convex-optimization', 'probability-distributions', 'combinatorics', 'discrete-mathematics', 'optimization']"
3450084,Is it true that $\lim (\frac{f(x)}{g(x)} - \frac{f'(x)}{g'(x)}) = 0$ for L'Hopital Rule?,"I'm wondering if for some function whereby the numerator and denominator goes to $0$ and L'Hopital Rule can be applied to find the limit of the function, does it necessarily imply that, $\lim (\frac{f(x)}{g(x)} - \frac{f'(x)}{g'(x)}) = 0$ . I'm asking this question because I came across this question that asked me to find the limit of the following expression: $$\lim_{x \rightarrow 0}(\frac{e^x+e^{-x}-2}{1-\cos2x}-\frac{e^x-e^{-x}}{2\sin2x})$$ This limit goes to zero. It may be possible to combine the fractions and use L'Hopital's on the entire fraction, but that is tedious to do. Upon closer inspection, the second term is just what you'd get if you did L'Hopital on the first expression. Since the limits of both terms should approach the same value, shouldn't they 'cancel out', in a sense? I'm wondering if $\lim (\frac{f(x)}{g(x)} - \frac{f'(x)}{g'(x)}) = 0$ is always true for functions which are of indeterminate form. I've been playing around and I've yet to find a counterexample.","['limits', 'calculus']"
3450093,"$| \int fg|\leq 1$ for any $g\in C_{0}^{\infty}$, $\|g\|_{L^{2}}=1$ then $\|f\|_{L^{2}}\leq1$","I have the following question: Let $f$ be a continuous function in an open, bounded, smooth domain $\Omega$ in $\mathbb{R}^{n}$ such that $|  \int_{\Omega} fg|\leq 1$ for any $g\in C_{0}^{\infty}(\Omega)$ , $\|g\|_{L^{2}(\Omega)}=1$ . Here the measure and the integral are w.r.t. Lebesgue measure.  And $C_{0}^{\infty}(\Omega)$ is the set of smooth functions of compact support in $\Omega$ . Can we conclude that $f\in L^{2}(\Omega)$ ? Thanks for any hint.","['lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3450094,Show continuity of $f:\mathbb R \to \mathbb R^{2 \times 2}$,"$f:\mathbb R \to \mathbb R^{2 \times 2}$ $f(x)=\begin{pmatrix}1&&0\\1-x&&x\end{pmatrix}$ Now, I know that $f$ is continuous because it is continuous entry wise, but I want to show it directly. Let $|x-y|<\delta$ $\|f(x)-f(y)\|=\|\begin{pmatrix}0&&0\\y-x&&x-y\end{pmatrix}\|=\sup\{\|\begin{pmatrix}0&&0\\y-x&&x-y\end{pmatrix}\begin{pmatrix}v_1\\v_2\end{pmatrix}\|:v \in \mathbb R^2, \|v\|\le 1\}=\sup\{\|\begin{pmatrix}0\\(y-x)v_1+(x-y)v_2\end{pmatrix}\|:v \in \mathbb R^2, \|v\|\le 1\}$ How to continue?","['matrices', 'continuity', 'calculus', 'linear-algebra']"
3450113,How to prove −AΔB=AΔC→C=−B?,"Question is : There are A , B , C subset groups of universal set U . Prove that $$ -A \Delta B = A\Delta C \to C = -B $$ As far as I see first part of expression is false as well as second, because for example $ -A \Delta B $ could not be equal to $A\Delta C$ also in second part C could not be equal to -B But it is means that $ false \to fasle $ give us true. I don't understand what is universal group U in this question thus I am not sure if my answer is right...","['elementary-set-theory', 'discrete-mathematics']"
3450174,Uniqueness of the limit on random variable,"Of course convergence in $L^2$ does not imply convergence in $a.s.$ and, equally, convergence in $probability$ does not imply convergence in $a.s.$ or in $L^2$ (without further requirement). However there is  a sort of uniqueness on the limit of the random variables? What I mean is, if a sequence of random variables $X_n$ converge to X a.s., does this imply that IF $X_n$ converge also in $L^2$ then the limit has to be the same (namely X)? Or there is not even this type of relation? Namely $X_n$ could converge to X a.s., and $X_n$ could converge to Y in $L^2$ ?","['convergence-divergence', 'probability-theory', 'random-variables']"
3450215,proof: $A-A(A+B)^{-1}A=B-B(A+B)^{-1}B$ [duplicate],This question already has an answer here : Matrix equation: $A−A(A + B)^{−1}A = B−B(A + B)^{−1}B$ (1 answer) Closed 4 years ago . I have to prove that $$A-A(A+B)^{-1}A=B-B(A+B)^{-1}B$$ and I don't know how to start. The only thing that is known is $A+B$ is nonsingular. Can someone help me to prove this?,"['matrices', 'linear-algebra']"
3450222,A function that verifies the property $f(ab) = f(a) + f(b)$,"Is there a function $f: (0,+\infty) \to \mathbb{R}$ that satisfies the property : $$  f(ab) = f(a) + f(b), \forall (a,b) \in\mathbb{R}^2 $$ Other than the logarithmic functions. If $f$ is differentiable at $1$ , then the answer is no, but if $f$ is not differentiable at $1$ , I can only show that it verifies the basic properties of logarithmic functions, not that it must be one.
Thank you.","['functional-equations', 'functions', 'analysis']"
3450227,Conditional independence for 3-way contingency tables,"In class we went over a proof to show that $$(X_{1}, X_{2}) \perp X_{3} \equiv X_{1} \perp X_{3} | X_{2}$$ for 3-way contingency tables. I understand the rest of the proof, but can't see how these were derived: $$LHS \Longrightarrow P(X_{1} = i, X_{2} = j, X_{3} = k) = P(X_{1} = i, X_{2} = j)P(X_{3} = k)$$ and $$RHS \Longrightarrow \frac{P(X_{1} = i, X_{2} = j, X_{3} = k)}{P(X_{2} = j)} = \frac{P(X_{1} = i, X_{2} = j)}{P(X_{2} = j)} \frac{P(X_{2} = j, X_{3} = k)}{P(X_{2} = j)}$$ I assume Bayes formula has been used, but am unsure where or how. Any help would be awesome!","['conditional-probability', 'proof-explanation', 'statistics', 'independence']"
3450231,Evaluate $6^{433} \pmod {21}$ and a proving question,"Question 1: Denote $a \mod b$ as $a \% b$ , where $a$ and $b$ are some integers Evaluate 12^32475 % 21 The following is what I tried: 12^32475 % 21 = (12^3 % 21)^10825 % 21 = 6^10825 % 21 = ... = 6^433 % 21 But how to continue ? Question 2: I don't understand this: n-1= -1 mod n. Where is this from? And does this line become the next line? Context: my class is discrete math for computer science. So far for related topics, it covers modular inverse, (extended) GCD algorithm, Fermat's Little Theorem and Chinese Remainder Theorem (CRT).","['computer-science', 'modular-arithmetic', 'discrete-mathematics', 'modules']"
3450236,Quartic Diophantine equation in three variables,"Is there a positive integer solution to the quartic Diophantine equation? $$x^4-4x^2y^2+8y^4=z^2$$ Cf. Yiu,""Recreational Mathematics"" Chap. 6.2 pp. 50/360 Sinha, T. N. Two simultaneous diophantine equations. Math. Student 33 (1965), 59-61","['number-theory', 'diophantine-equations']"
3450337,Question regarding eigenvalue for left shift operator,"I am asked whether if $|\lambda|=1$ is an eigenvalue for the left shift operator $T:\ell^{p}\rightarrow\ell^{p}$ for $1\leq p<\infty$ where $T(x_1,x_2,\dots)=(x_2,x_3,\dots)$ . $\textbf{My attempt:}$ My intuition says no, $|\lambda|=1$ cannot be an eigenvalue for $T$ . Because $$Tx-\lambda x=(x_2-\lambda x_1,x_3-\lambda x_2,\dots)=0$$ from which we can see that $x_2=\lambda x_1,\ x_3=\lambda^2 x_1$ etc. From this I would get that an eigenvector would be $(\lambda,\lambda^2,\dots)$ . If $|\lambda|=1$ then this supposed eigenvector does not exist in $\ell^p$ since the norm of the supposed eigenvector is infinite. It's only an eigenvector if $|\lambda|<1$ . Is this correct? And if so, could I argue/show this in a more clever way? Thanks in advance.","['functional-analysis', 'real-analysis']"
3450363,Weak Law Of Large Numbers without assumption of having finite variance,"In the first volume of Feller's book ( see at Archive ), chapter 10  section 2, there is a proof of the weak law of large numbers for the case the second moment does not exist. I am reading about 7 books in English and Russian and none goes further than using Chebyshev's Inequality and assuming existence of the first two moments. Wikipedia and just googling for a proof without variance do not help to find it either. Does anyone know why such a beautiful and, moreover, much general proof is so unpopular? Or, maybe there is some imperfection I do not notice, could you point it out? Thank you!","['law-of-large-numbers', 'probability-theory', 'probability']"
3450365,The number of solutions of the equation $|\cot x|=\cot x +\frac{1}{\sin x}$ where $0<x<2\pi$,"$$|\tan x| = \frac{\sin x}{1+\cos x}$$ $$|\tan x|=\tan (\frac x2)$$ then x can assume only two values $0,2\pi$ (at least that’s what I think). But since it doesn’t fit in the given interval, number of solutions should be zero, but the answer is 2. How should I correct it?","['algebra-precalculus', 'trigonometry']"
3450380,Why can I solve an impossible equation using linear algebra?,"I am currently learning matlab and linear algebra side by side and I stumbled upon this example from mathworks A = [1 2 0; 0 4 3];
b = [8; 18];
x = A\b

x = 3×1

     0
4.0000
0.6667 which in my mind translates to $$
A = \left[
\begin{matrix}
1 & 2 & 0 \\
0 & 4 & 3
\end{matrix}\right]
B = \left[
\begin{matrix}
8 \\ 18
\end{matrix}\right]
x = \left[
\begin{matrix}
a \\ b \\ c
\end{matrix}\right]
$$ $$
Ax = \left[
\begin{matrix}
1 & 2 & 0 \\
0 & 4 & 3
\end{matrix}\right] \times \left[
\begin{matrix}
a \\ b \\ c
\end{matrix}\right] 
= \left[
\begin{matrix}
a + 2b \\ 4b + 3c
\end{matrix}\right]
$$ which boils down to $$
\left[
\begin{matrix}
a + 2b \\ 4b + 3c
\end{matrix}\right] = \left[
\begin{matrix}
8\\ 18
\end{matrix}\right] \Rightarrow \begin{matrix}a + 2b = 8 \\4b + 3c = 18\end{matrix}
$$ which is an equation with 3 unknown (a, b and c) with two equations, which is impossible! Yes there is a solution $$
x = \left[
\begin{matrix}
0 \\ 4 \\ 2/3
\end{matrix}\right]
$$ How can I solve an impossible equation (three unknown and two equations) using linear algebra?",['linear-algebra']
3450386,"Find $\lambda\in \mathbb{C}$ s.t. $\exists$ entire $f$, s.t. $f(z)=f(\lambda z),~\forall z\in\mathbb{C}$ [duplicate]","This question already has answers here : For which $a$ does the equation $f(z) = f(az) $ has a non constant solution $f$ (2 answers) Closed 4 years ago . I want to find all $\lambda \in \mathbb{C}$ such that there exists an entire non-constant function $f$ with $f(z)=f(\lambda z)$ $\forall z \in \mathbb{C}$ . My idea was the following: Since $f$ must be entire on the whole complex plane it can be represented as taylor series around $0$ . So I get then in total \begin{align*}
\sum\limits_{n=0}^\infty \frac{f^{(n)}(0)}{n!}z^n=f(z)=f(\lambda z)=\sum\limits_{n=0}^\infty \frac{f^{(n)}(0)}{n!}\lambda^{n}z^n.
\end{align*} Now I (hope I can) conclude that \begin{align*}
f^{(n)}(0)=f^{(n)}(0)\lambda^{n}.
\end{align*} Therefore, either $f^{(n)}(0)=0$ or $\lambda^{n}=1$ must hold. First I conclude that $|\lambda|=1$ must hold, therefore $\lambda=e^{i\theta}$ for some $\theta \in [0,2\pi].$ If now there exists $n\in \mathbb{N}$ such that $\theta=\frac{2\pi}{n}$ then I have $\lambda=e^{i\frac{2\pi}{n}}$ and therefore $\lambda^n=1$ . For such functions I might be able to define a entire function $f$ , such that all derivates in $0$ vanish except all $kn$ derivatives in $0$ . I just wonder if those are all and my thoughts were correct?
Thanks in advance.","['complex-analysis', 'entire-functions', 'taylor-expansion']"
3450390,Binomial upper bound for the bi-color Ramsey numbers (Erdős-Szekeres),"The question : How did Erdös - Szekeres came up with a close form with a binomial for the upper bound: Where does the idea behind $R(2,2)=\binom{2+2-2}{2-1}$ -  I do see that $R(2,2)=2$ - or $\binom{s+t-3}{s-1}\left(\text{or }\binom{s+t-3}{s-2}\right)$ come from? And how is the induction over $s$ and $t$ work? What I understand: I see that $R(s,t) \leq R(s-1,t)+R(s,t-1)$ I understand that ${\displaystyle  {\binom {r+s-3}{r-2}}+{\binom {r+s-3}{r-1}}={\binom {r+s-2}{r-1}}}$ - Pascal's triangle. I also see that $\forall s, t ∈ \mathbb N,$ the relationship $R(s, t) = R(t, s)$ holds. And I get it that $R(s,2)=R(2,s)=s.$ The problem: There are tons of sites where the proof of the inequality above is readily available, including one of the answers to this post. However, when the inequality is proven, the binomial formula seems to appear out of thin air like it is self-evident, typically with a short justification such as: easily proven by induction on $s$ and $t.$ But how does this work? How did they come up with this binomial to begin with? This binomial coefficient appears before testing the base cases. Background info: For instance, in here : Since $R(r, s) ≤ R(r − 1, s) + R(r, s − 1)$ so this automatically gives an upper bound, although not in the closed form that we expect. The closed form expression is ${\displaystyle R(r,s)\leq {\binom {r+s-2}{r-1}}}.$ To derive this use double induction on $r$ and $s.$ The base case $r = s = 2$ is easily established as $${\displaystyle R(2,2)=2\leq {\binom {2+2-2}{2-1}}=2}.$$ Now assume the expression holds for $R(r − 1, s)$ and $R(r, s − 1).$ Then $${\displaystyle R(r,s)\leq R(r-1,s)+R(r,s-1)\leq {\binom {r+s-3}{r-2}}+{\binom {r+s-3}{r-1}}={\binom {r+s-2}{r-1}}}$$ gives us our upper bound. Note that we have used Pascal's relation in the last equivalence. But why did they start already applying the binomial formula they intend to prove in ${\displaystyle R(2,2)=2\leq {\binom {2+2-2}{2-1}}=2},$ and how does the inductive process proceed from that point? I see there are related questions, and in fact, I have tried to contribute with a possible answer as to the proof of a finite Ramsey number for every combination of two natural numbers here to get feedback. However, I still have problems with the immediately related proof of the inequality ( theorem of Erdős-Szekeres ): $$R(s,t) \leq \binom{s+t-2}{s-1}$$ as in here : I see that this inequality is fulfilled by the base cases, as well as $s+t<5,$ but I presume other inequalities could also be fulfilled by the first Ramsey numbers. In the following two answers that I found online it seems as though the Ramsey number on, say $(r,t),$ i.e. $R(r,t)$ is somewhat just replaced by $r$ and $t$ in the combinatorics solution. So I don't get the analogy to Pascal's triangle... Solution 1: The answer can be found here : $$R(k,l) \leq \binom{k+l-2}{k-1}$$ because the recurrence $$R(k,l) \leq R(k-1,l) + R(k,l-1) $$ can be seen as the paths from a point $R(k,l)$ on the grid below to $(1,1):$ and the number of ways to get to a point on a lattice $(x,y)$ taking off from $(0,0)$ are: $$\binom{x+y}{x}$$ Here we are moving in the opposite direction, and stopping at $(1,1),$ which reduces the count to: $$\binom{(x-1)+(y-1)}{x-1}=\binom{x+y-2}{x-1}$$ ""We’ve placed the value $1$ at each position $(k, 1)$ or $(1, l)$ in this grid, corresponding to the
base case $r(k, 1) = r(1, l) = 1$ of our induction. At the point $(k, l)$ in the grid, we know
that the value $r(k, l)$ at that point is upper-bounded by the sum of the values immediately
below and immediately to the left. Applying this same recurrence to these adjacent nodes,
we see that every left/down path from $(k, l)$ to the boundary will contribute $1$ in the final
sum (corresponding to the value $1$ at the boundary points). Thus, $r(k, l)$ is upper-bounded
by the number of left/down paths to the boundary, which is in turn equal to the number of
left/down paths from $(k, l)$ to $(1, 1),$ which is exactly $\binom{k+l-2}{k-1}.""$ Solution 2: From here :","['graph-theory', 'ramsey-theory', 'combinatorics', 'discrete-mathematics']"
3450405,Closed expression for sum $\sum_{k=1}^{\infty} (-1)^{k+1}\frac{\left\lfloor \sqrt{k}\right\rfloor}{k}$,"Inspired by the recent question if the series $\sum_{k=1}^{\infty} \frac{\sqrt{k}-\left\lfloor \sqrt{k}\right\rfloor}{k}$ diverges (which is the case) I became interested in the alternating series which is convergent by the Leibniz criterion. The core of the problem is then the question if this sum $$s = \sum_{k=1}^{\infty} (-1)^{k+1}\frac{\left\lfloor \sqrt{k}\right\rfloor}{k}\simeq 0.591561$$ has a closed expression. Here $\left\lfloor {x}\right\rfloor$ is the greatest integer less than or equal to $x$ . I have found a nice integral representation for $s$ but I could not find a closed expression. Also, due to the slow convergence of the sum it is not trivial to get a numerical result with high accuracy which might be necessary to identify a possible closed expression. Problems a) find a closed expression for $s$ b) find the numerical result exact to 20 decimal places","['ceiling-and-floor-functions', 'closed-form', 'sequences-and-series']"
3450464,Wording of a statistics question,"Apologies if this is not the correct area to post this but, I have a question about the specific wording of an assignment. We have been given this sentence, basically The occurrence of false positives [in some experiment] is 40% What does this mean? Does it mean that 40% of positives are false? Or 40% of all tested patients are specifically both false and positive? Or say 40% of those that are false are positive? I'm quite confused as to what this means, and none of the people I have asked understand either. Thanks",['statistics']
3450481,Is there a prime of the form $\ (9n)!+n!+1\ $?,"See also MathOverflow: Why am I unable to find primes of the form $(9n)!+n!+1$ ? In a project, I search primes of the form $$(kn)!+n!+1$$ with positive integers $\ k,n\ $ . The smallest $\ k\ $ for which I still know no prime is $\ k=9\ $ . For $$k=1,2,3,4,5,6,7,8$$ the numbers $$n=1,3,605,185,850,7,11,120$$ are respective the smallest $n$ for which we get a prime, except possibly for $n = 605, 850$ , in which case we just know we get a probable prime (the rest is proven to be prime according to FactorDB ) Is there a prime of the form $$(9n)!+n!+1$$ with positive integer $\ n\ $ ? Chances should be good because such a number cannot have a prime factor less than or equal to $\ n\ $ , but upto $\ n=500\ $ , there is none.","['number-theory', 'examples-counterexamples', 'elementary-number-theory', 'prime-numbers']"
3450547,Showing $p dx + q dy$ is locally exact,"I'm working on the following question from Ahlfors' Complex Analysis : Prove without use of Theorem 16 that $p dx + q dy$ is locally exact on $\Omega$ ( $\Omega$ open, simply connected) iff $\int_{\partial R} p dx + q dy =0$ for every rectange $R \subset \Omega$ with sides parallel to the axes. Theorem 16 (the one I'm not supposed to use) states that if $p dx + q dy$ is locally exact in $\Omega$ , then $\int_{\gamma} p dx + q dy =0$ for every cycle $\gamma \sim 0$ in $\Omega$ . I understand the definitions, but I don't really know how to get started, so any help would be appreciated. The following definition is the one I am currently working with: A differential $p dx + q dy$ is said to be locally exact in $\Omega$ is it is exact in some neighborhood of each point in $\Omega$ .",['complex-analysis']
3450645,Average maximum length of a cycle in a permutation,"I'm looking to compute the average maximum length of cycles in a given random permutation of length n. I know that the average cycle length is equal to n/Hn, with Hn being the n-th harmonic number, and I went through the whole proof for this fact. However I suspect that the average maximum length is a whole different problem (but maybe I am mistaken). Is there any existing formuma for it ?","['permutations', 'combinatorics', 'discrete-mathematics', 'permutation-cycles']"
3450652,Inverse function derivative of multivariable functions,"In one dimension, if the inverse of function $x(\zeta)$ exists, $\frac{d\zeta}{dx}=(\frac{dx}{d\zeta})^{-1}$ , and $\frac{d^2\zeta}{dx^2}=(-\frac{d^2x}{d\zeta^2}(\frac{dx}{d\zeta})^{-3})$ . So I can calculate these derivatives with only knowing the $x(\zeta)$ function.
This is all nice in one dimension, but I would like to do something like this in 2 dimensions. The problem is given: $x(\zeta,\eta)$ and $y(\zeta,\eta)$ are known and I need to calculate $\frac{\partial^2 \zeta}{\partial x^2}$ and $\frac{\partial^2 \zeta}{\partial y^2}$ , and calculate $\frac{\partial^2\eta}{\partial x^2}$ and $\frac{\partial^2\eta}{\partial y^2}$ , without knowing $\zeta(x,y)$ and $\eta(x,y)$ . Can you help me in this? The aim of the whole thing is to calculate $\Delta_{xy} N(\zeta(x,y), \eta(x,y))$ . So N is defined in the $(\zeta,\eta)$ coordinate system, and a transformation from $(\zeta,\eta)$ to $(x,y)$ is given by $x(\zeta,\eta)$ and $y(\zeta,\eta)$ Any hint is appreciated. Thank you!","['real-analysis', 'multivariable-calculus', 'calculus', 'inverse', 'partial-derivative']"
3450654,Probability - Brick in box,"From the set {1, 2, 3, ... 999}, 6 distinct numbers are chosen. These are divided into two groups $a_1,a_2,a_3$ and $b_1,b_2,b_3$ . Find the probability that a brick made from the dimensions of group $a$ fits into a box made from the dimensions of $b$ . Assume that the brick can be rotated in a suitable manner to be made to fit inside the box I am able to comprehend this question and what it asks. However, I don't have a strategy in place to solve this question. The solution provided has the following to say: without loss of generality, we can say that out of the 20 possible cases, 5 are suitable. Therefore, the probability is $\frac 1 4$ . What are the twenty possible cases here? How can we set conditions on $a$ and $b$ such that we can obtain these cases? The ability to rotate the brick before placing in the box has confused me. Any help would be appreciated!",['probability']
3450728,Each closed ideal $I\subset C(X)$ is of the form $\{f\in C(X) \ | \ A\subset f^{-1}\{0\}\}$ for some closed subset $A\subset X$.,"I know that this question has been asked before (for example here ), but I am looking for a different answer. Let $X$ be a compact Hausdorff space and consider the commutative Banach algebra $C(X):=\{\text{continuous functions $f\colon X\to\mathbb{C}$}\}$ endowed with the supremum norm. I want to prove that every closed ideal $I\subset C(X)$ is of the form $I_{A}:=\{f\in C(X) \ | \ A\subset f^{-1}\{0\}\}$ for some closed subset $A\subset Y$ . I proved that $I_{A}$ is a closed ideal for any subset $A\subset X$ . The exercise gives a hint that I should prove and use the following: Given $f\in I$ and $\varepsilon\in(0,1)$ , there exists a continuous map $u\colon X\to\mathbb{C}$ such that $u\in I$ , $u(x)\in[0,1]$ for all $x\in X$ , $u(x)=0$ whenever $|f(x)|\leq\varepsilon$ , $u(x)=1$ whenever $|f(x)|\geq1$ . I managed to prove this hint, but still I'm having trouble with the exercise. As the link above suggests, I tried to prove that $I=I_{A}$ where $$A:=\bigcap_{g\in I}g^{-1}\{0\}.$$ Any suggestions on how to prove this using the hint above would be greatly appreciated.","['banach-algebras', 'continuity', 'functional-analysis', 'uniform-convergence', 'ideals']"
3450752,"Triangle sides $a,b,c$ are in arithmetic progression. Show $\sin^2(A/2)\csc2A$, $\sin^2(B/2)\csc2B$, $\sin^2(C/2)\csc2C$ are in harmonic progression","If sides $a,b,c$ of the triangle ABC are in arithmetic progression, prove that $\sin^2\frac{A}{2}\mathrm{cosec}(2A),\sin^2\frac{B}{2}\mathrm{cosec}(2B),\sin^2\frac{C}{2}\mathrm{cosec}(2C)$ are in harmonic progression. My attempt is as follows:- $$T_1=\dfrac{1-\cos A}{2\sin2A}$$ $$T_1=\dfrac{1}{4}\dfrac{\sec A-1}{\sin A}$$ $$T_1=\dfrac{2R}{4}\left(\dfrac{\dfrac{2bc}{b^2+c^2-a^2}-1}{a}\right)$$ $$T_1=\dfrac{R}{2}\left(\dfrac{\dfrac{2bc-b^2-c^2+a^2}{b^2+c^2-a^2}}{a}\right)$$ $$T_1=\dfrac{R}{2}\left(\dfrac{\dfrac{a^2-(b-c)^2}{b^2+c^2-a^2}}{a}\right)$$ $$T_1=\dfrac{R}{2}\left(\dfrac{(a+c-b)(a+b-c)}{(b^2+c^2-a^2)a}\right)$$ By symmetry, we can say $T_2=\dfrac{R}{2}\left(\dfrac{(b+c-a)(b+a-c)}{(a^2+c^2-b^2)b}\right)$ $T_3=\dfrac{R}{2}\left(\dfrac{(c+a-b)(c+b-a)}{(a^2+b^2-c^2)c}\right)$ For $T_1,T_2,T_3$ to be in HP, $\dfrac{1}{T_1},\dfrac{1}{T_2},\dfrac{1}{T_3}$ should be in A.P $$\dfrac{1}{T_1}+\dfrac{1}{T_3}-\dfrac{2}{T_2}=\dfrac{2}{R}\left(\dfrac{(b^2+c^2-a^2)a}{(a+c-b)(a+b-c)}+\dfrac{(a^2+b^2-c^2)c}{(c+a-b)(c+b-a)}-\dfrac{2(a^2+c^2-b^2)b}{(b+c-a)(a+b-c)}\right)$$ $$\dfrac{1}{T_1}+\dfrac{1}{T_3}-\dfrac{2}{T_2}=\dfrac{2}{R}\left(\dfrac{a(b^2+c^2-a^2)(b+c-a)+c(a^2+b^2-c^2)(a+b-c)-2b(a^2+c^2-b^2)(c+a-b)}{(b+c-a)(a+b-c)(c+a-b)}\right)$$ $$\dfrac{1}{T_1}+\dfrac{1}{T_3}-\dfrac{2}{T_2}=\dfrac{2}{R}\left(\dfrac{a(b^3+b^2c-ab^2+bc^2+c^3-ac^2-a^2b-a^2c+a^3)+c(a^3+a^2b-a^2c+b^2a+b^3-b^2c-c^2a-c^2b+c^3)-2b(a^2c+a^3-a^2b+c^3+ac^2-bc^2-b^2c-ab^2+b^3)}{(b+c-a)(a+b-c)(c+a-b)}-\right)$$ $$\dfrac{1}{T_1}+\dfrac{1}{T_3}-\dfrac{2}{T_2}=\dfrac{2}{R}\left(\dfrac{a^4+c^4-2b^4+ab^3-a^3b+ac^3-a^3c+a^3c+b^3c-ac^3-bc^3+ab^2c+abc^2+a^2bc+ab^2c-2a^2bc-2abc^2\cdot\cdot}{(b+c-a)(a+b-c)(c+a-b)}\right)$$ It was getting very difficult to solve from here, is there any other method in which we can solve this question?","['trigonometry', 'triangles']"
3450777,Is Hamel Basis necessarily uncountable?,Let $X$ be a (real or complex) infinite dimensional vector space. (Not Normed or Banach one). Is every Hamel Basis for $X$ necessarily uncountable ?,"['hamel-basis', 'linear-algebra']"
3450787,Covering a domain with disjoint open balls -- up to a set of measure zero,"Is it known if an open set of $\mathbb{R}^n$ can be covered (up to a set of Lebesgue measure zero) with disjoint open balls? It is obviously true for $n=1$ where every open set is a union of intervals which are the same as balls, and it is also valid for the p-adics as in here . It is also known that it can be covered with open-closed boxes of the type $(0,1]^n$ as done in measure theory.","['general-topology', 'lebesgue-measure', 'measure-theory', 'real-analysis']"
3450807,"Does $[\mathfrak{h},[\mathfrak{h},\mathfrak{h}]]=0$ imply $[\mathfrak{h},\mathfrak{h}]=0$?","Let $\mathfrak{g}$ be a Lie algebra. Suppose there exists a subspace $\mathfrak{h}\subset \mathfrak{g}$ such that $$
[X,[Y,Z]] =0
$$ for all $X,Y,Z \in \mathfrak{h}$ . Is it true that $\mathfrak{h}$ is an abelian subalgebra of $\mathfrak{g}$ , i.e., $[X,Y]=0$ for all $X,Y \in \mathfrak{h}$ ?","['lie-algebras', 'abstract-algebra', 'linear-algebra', 'lie-groups', 'differential-geometry']"
3450813,Numerical method for steady-state solution to viscous Burgers' equation,"I am reading a paper in which a specific partial differential equation (PDE) 
on the space-time domain $[-1,1]\times[0,\infty)$ is studied. The authors are 
interested in the steady-state solution. They design a finite difference method (FDM) for the PDE. As usual, there are certain discretizations in time-space, $U_j^n$ , that approximate the solution $u$ at the mesh points, $u(x_j,t_n)$ . The 
authors conduct the FDM method on $[-1,1]\times [0,T]$ , for $T$ sufficiently large 
such that $$ \left|\frac{U_j^N-U_j^{N-1}}{\Delta t}\right|<10^{-12},\quad \forall j, $$ where $t_N=T$ is the last point in the time mesh and $\Delta t$ is the 
distance between the points in the time mesh. The approximations for the steady-state 
solution are given by $\{U_j^N\}_j$ . I wonder why the authors rely on the PDE to study the steady-state solution. As 
far as I know, the steady-state solution comes from equating the derivatives 
with respect to time to $0$ in the PDE. The remaining equation is thus an ordinary 
differential equation (ODE) in space. To approximate the steady-state solution, 
one just needs to design a FDM for this ODE, which is easier than dealing with 
the PDE for sure. Is there anything I am not understanding properly? For completeness, I am referring to the paper Supersensitivity due to 
uncertain boundary conditions . The authors deal with the PDE $u_t+uu_x=\nu u_{xx}$ , $x\in (-1,1)$ , $u(
-1,t)=1+\delta$ , $u(1,t)=-1$ , where $\nu,\delta>0$ . They employ a FDM for this 
PDE for large times until the steady-state is reached. Why not considering the 
ODE $uu'=\nu u''$ , $u(-1)=1+\delta$ , $u(1)=-1$ , instead?","['ordinary-differential-equations', 'finite-difference-methods', 'partial-differential-equations', 'numerical-methods', 'finite-differences']"
3450832,Haar Measure on topological groups,"I'm currently reading an article and the author defines the following objects. Let $\mathbb{Z}_{n}$ be the cyclic group of integers mod $n$ , for some $n \ge 1$ and define $$\mathcal{G} := \bigoplus_{k=0}^{\infty}\mathbb{Z}_{n}$$ Furthermore, define the subgroups: $$\mathcal{G}_{k} :=\{x \in \mathcal{G}, \hspace{0.1cm} \mbox{$x_{i}=0$, for all $i \ge k$}\}$$ if $k\ge 1$ and $\mathcal{G}_{0}:=\{0\}$ . Now, if $L\ge 2$ , we introduce a notion of norm: $$|x| :=\begin{cases}
\displaystyle 0 \quad \mbox{if $x=0$}\\
\displaystyle L^{p} \quad \mbox{where $p=\inf \{k,\hspace{0.1cm} x\in \mathcal{G}_{k}\}$ if $x \neq 0$}
\end{cases} $$ Now, the author defines, in his words "" $dx$ to be a Haar measure which is also the counting measure on $\mathcal{G}$ "". I'm not familiar with the concept of a Haar measure on a group, but I've read that it should be defined on some locally compact Hausdorff topological group. Now, how do I conclude that $\mathcal{G}$ is such a group? Does $|\cdot|$ define a topology on $\mathcal{G}$ ? How can I define a topology on $\mathcal{G}$ with the above informations? I imagine $|\cdot|$ defines a topology in some way, but I don't know how. Besides, does this topology fulfill all properties (Hausdorff, locally compact) to define the Haar measure?","['group-theory', 'abstract-algebra', 'algebraic-topology']"
