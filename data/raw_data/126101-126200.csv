question_id,title,body,tags
1914836,When is first group cohomology isomorphic to conjugacy classes of sections?,"In chapter 1, exercise $\S$2.1 of Neukirch's Cohomology of Number Fields page 24, there is the following situation: $G$ is a profinite group, $A$ is a discrete group (not necessarily abelian) with a continuous $G$-action, $\hat{G} = A \rtimes G$, and $\mathrm{SEC}(\hat{G}\to G)$ is defined as the $A$-conjugacy classes of homomorphic sections of the natural exact sequence $$1 \to A \to \hat{G} \xrightarrow{\pi} G \to 1.$$
The result in question is that if either $G$ or $A$ is finite, then there is a canonical bijection of pointed sets $H^1(G,A) \cong \mathrm{SEC}(\hat{G}\to G)$. My questions are: (1) Why is it necessary for either $G$ or $A$ to be finite? (2) Would the result be true if $A$ were not discrete but profinite? (3) If $A$ were profinite, would the finiteness condition be necessary?","['group-cohomology', 'profinite-groups', 'group-theory']"
1914889,"Revisit ""How can I visualize the nuclear norm ball""","Revisiting How can I visualize the nuclear norm ball? Two eigenvalues are reproduced as following: $$ s_{1,2}=\frac{1}{\sqrt{2}}\sqrt{x^2+2y^2+z^2\pm|x+z|\sqrt{(x-z)^2+4y^2}}. $$ According to the following (from a paper) If a symmetric matrix: $$ A=\left( \begin{array}{cc} x & y\\ y & z\end{array} \right)$$ is rank $1$ , then $y=\sqrt{xz}$ , which comes from the fact that $vv^T$ is rank $1$ and any rank $1$ matrix can be represented in this form. $$\left[\begin{array}{cc} v_1\\ v_2\end{array}\right]\left[\begin{array}{cc} v_1 & v_2\end{array}\right]=\left( \begin{array}{cc} v_1^2 & v_1v_2\\ v_1v_2 & v_2^2\end{array} \right)$$ My question: how to explain the red circle in figure (b) is the $2\times 2$ symmetric unit-Euclidean-norm rank $1$ matrix? This is a circle in $3$ -D, how to get the equation of this circle through the rank $1$ matrix provided above? I believe just replace $y=\pm\sqrt{xz}$ in $s_{1,2}$ and can get the answer. So I choose the larger one of $s_{1,2}$ : $$ s_{\max}=\frac{1}{\sqrt{2}}\sqrt{x^2+2y^2+z^2 + |x+z|\sqrt{(x-z)^2+4y^2}}= \sqrt{2(x+z)^2}=1 (\text{unit norm})$$","['nuclear-norm', 'matrices', 'normed-spaces', 'functional-analysis', 'linear-algebra']"
1914901,False proofs claiming that $\mathbb{Q}$ is uncountable.,"Here are two false proofs of the fact that $\Bbb Q$ is uncountable. From Stephen Abbott's Understanding Analysis . Proof 01 Lemma:(Nested Interval Property - NIP). For each $n ∈ N$, assume we are given a closed interval $I_n = [a_n, b_n]$. Assume also that each I_n contains I_{n+1}. Then, the resulting nested sequence of closed intervals
  $$I_1 ⊇ I_2 ⊇ I_3 ⊇ I_4 ⊇ · · ·$$
  has a nonempty intersection. Assume, for contradiction, that $\Bbb Q$ is countable. Thus we can write $\Bbb Q =\{r_1, r_2, r_3, . . .\}$ and, construct a nested sequence of closed intervals with $r_n \not \in  I_n$. Our construction implies $\bigcap_{n=1}^{\infty} I_n = ∅$ while NIP implies $\bigcap_{n=1}^{\infty} I_n \neq ∅$
  . This contradiction implies $\Bbb Q$ must therefore be uncountable. Proof 02 Theorem : The open interval $(0,1)$ is uncountable. Proof: Lets assume that $(0,1)$ is countable and thus let $f:\Bbb N\to (0,1)$ be a bijective function. Then let $f(m) = 0.a_{m1}a_{m2}a_{m3} . . . .$ (decimal representation). Let $x=0.b_1b_2...$ with $b_i=3$ if $a_{ii}=2$ else $b_i=2$. Its not difficult to see x is a different number from the counted set a contradiction. Now the question is: Every rational number has a decimal expansion, so we could apply this same argument to show that the set of rational numbers between $0$ and $1$ is uncountable. However, because we know that any subset of $\Bbb Q$ must be countable, the proof of Theorem. I can't figure out the flaws in these two arguments.","['real-analysis', 'fake-proofs', 'elementary-set-theory']"
1914905,Can I make any injective function bijective by patching the codomain?,"I have a function $f$ that is injective from $\mathbb R \to \mathbb  R$ but not surjective, i.e., the image $f$ is not all of $\mathbb R$. Can I make $f$ bijective by patching the codomain and removing any parts that are not in the image?",['functions']
1914920,What is meaning of the notation $\lfloor x \rceil$? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I am reading materials about Lenstra–Lenstra–Lovász lattice basis reduction algorithm on Wikipedia. What is the definition of this notation $\lfloor x\rceil$ appearing in the description of the algorithm? From the context, I guess $x=\lfloor x\rfloor$ if $\{x\}<\frac{1}{2}$ , and $x=\lceil x \rceil$ if $\{x\}\ge\frac{1}{2}$ .","['number-theory', 'notation']"
1914923,How to formally prove that the set $x^2 + y^2 -z^2 = a$ is not a manifold for $a=0$.,"I have proved that it is for $a>0$ by constructing six parametrizations that are diffeomorphisms. When $a=0$, these parametrizations lose their diffeomorphic character as the derivative fails to exist at the origin. However, the definition of a manifold is that ${\bf there \ exists}$ a local diffeomorphism from an open neighborhood of the set to $\mathbb{R}^k$ everywhere. So just because the specific parametrizations that I constructed fails doesn't disprove that the set isn't a manifold. Obviously at the vertex of a cone, the object cannot map smoothly to $\mathbb{R}^2$; but how would I formally prove this using the definitions of manifolds, diffeomorphisms, parametrizations, smoothness, etc?","['general-topology', 'differential-geometry', 'differential-topology']"
1914925,Proving that a function composed with its inverse is the identity,"Let $f:X \rightarrow Y$ be a bijection with inverse function $f^{-1}: Y \rightarrow X.$ Show that $f^{-1}(f)$ and $f(f^{-1})$ are the identity functions on X and Y respectively. My approach for the first part of the problem was to try to show that for $x \in X$, we need to show that $f^{-1}(f(x)) = x$ I feel like I can use the fact that f is one to one here somehow, but i'm not sure how to get started.","['elementary-set-theory', 'functions']"
1914931,Is $\sqrt x$ continuous at $0$? Because it is not defined to the left of $0$,"If a function has a limit from the right but not from the left, is it still continuous?",['calculus']
1914948,Intuition for $\lim_{x\to\infty}\sqrt{x^6 - 9x^3}-x^3$,"Trying to get some intuition behind why: $$ \lim_{x\to\infty}\sqrt{x^6-9x^3}-x^3=-\frac{9}{2}. $$ First off, how would one calculate this? I tried maybe factoring out an $x^3$ from the inside of the square root, but the remainder is not factorable to make anything simpler. Also tried expressing $x^3$ as $\sqrt{x^6}$, but that doesn't really help either. One would think that, as $x^6$ grows more quickly than $x^3$ by a factor of $x^3$, the contribution of the $x^3$ term to the term in the square root would be dwarfed by the contribution of the the $x^6$ term, so the overall behavior of the first term in the limit would ""behave"" like $x^3$, as x gets bigger and bigger, so I would think intuitively that the limit would evaluate to 0.",['limits']
1914997,An old question about sumsets and difference sets,"Let $A$ be a finite set. Define the symbols $+$ and $-$ as follows: $$A+A=\{a+b:a,b\in A\};$$ $$A-A=\{a-b:a,b\in A\}.$$ Prove or disprove $|A+A|\leq|A-A|$ , where $|A|$ denotes the cardinality of $A$ . This is an intuitively appealing conjecture.  (Since $a+b=b+a$ but $a-b\ne b-a$ , one might expect there are about twice as many possible differences as sums.)  But surprisingly, the conjecture is false. A counterexample is $A=\{1,2,3,5,8,9,13,15,16\}$ , then $A+A=\{2,3,\ldots,32\}\backslash\{27\}$ , $|A+A|=30$ and $A-A=\{-15,-14,\ldots,15\}\backslash\{\pm9\}$ , $|A-A|=29$ . Now here are my questions: What's special about that counterexample that made it different? And can we gain some insight from this into how to generate more counterexamples? Since $|A+A|\leq|A-A|$ is false, can we find the minimum/infimum of $\frac{|A+A|}{|A-A|}$ ?","['combinatorics', 'difference-sets', 'additive-combinatorics', 'discrete-mathematics']"
1915036,How to formally prove that equilibrium cannot be reached in finite time?,"Let $v:\left[0,1\right]\to\mathbb{R}$ be a Lipschitz continuous velocity, and let $t\mapsto u(t,x)$ be the (unique) solution of the initial problem $$x'(t)=v(x(t)),\;\;\; x(0)=x$$ defined on its maximal interval of existence, say $I_x$. Consider the flow $(\Phi_t)_{t\geq 0}$ given by $$\Phi_t(x)=
\begin{cases} 
u(t,x), &t\in I_x,\\
u(\sup I_x,\,x), &\text{otherwise}.
\end{cases}
$$
Now define the first hitting time
$$\tau_y(x)=\inf\{t\geq 0:\, \Phi_t(x)=y\}\;\;\;(\text{with the convention: }\inf\emptyset:=\infty).$$ I would like to prove that if $y\in\left[0,1\right]$ satisfies $v(y)=0$ then $\tau_y(x)=\infty$ for all $x\in\left[0,1\right]\backslash\{y\}$. I have a problem with a proof of this. Let $y\in\left[0,1\right]$, and think about the case where $x<y$. Roughly speaking, I see that the Lipschitz continuity of $v$ forces that $s\mapsto\frac{d}{ds} \Phi_s(x)$ tends to $0$ as $s\mapsto \Phi_s(x)$ gets closer and closer to $y$. However, I have no idea how to formally show that $\Phi_s(x)=y$ cannot happen for some $s>0$. I would be grateful for any hints.","['ordinary-differential-equations', 'dynamical-systems']"
1915038,block design and group testing,This is a question from course notes: The answer I'm given is something like this: So my questions are: 1.How do we know there should be 9 tests? why not 8 tests or 10 tests? 2.How many items are we testing? is it 9 items or 18 items? It doesn't make sense that we are doing 9 tests on 9 items.,"['combinatorial-designs', 'statistics', 'discrete-mathematics']"
1915045,Raabe's and Schlömilch's tests for limits,"This is problem 2.53 in Sohrab's Basic Real Analysis Problem First the Raabe's test as it has been formulated in the book. Corollary 2.3.31 Let $(x_n)$ be a sequence of positive numbers. Then $\sum x_n$ converges if $x_{n+1}/x_n\leq 1-r/n$ is ultimately true for some $r>1$. Problem 2.53 Show that Raabe's Test (Corollary 2.3.31) implies the following one (which is due to Schlömilch): Let $x_n > 0\;\forall n\in\mathbb{N}$. Then $\sum x_n$ converges if $n\log(x_n/x_{n+1})\geq r$ is ultimately true for some $r > 1$. Hint: Use the inequalities $x/(1+x)\leq \log(1+x)\leq x$ for all $x>-1$. Question The idea is to prove: Schlömilch's premises $\implies$ Raabe's premises $\implies$ convergence. BUT I'm only able to prove: Raabe's premises $\implies$ Schlömilch's premises $\implies$ convergence: $$\frac{r}{n}\leq 1-\frac{x_{n+1}}{x_n}\leq \log\frac{x_n}{x_{n+1}}$$
where, with $y:=\frac{x_{n}}{x_{n+1}}-1$, we have used $y/(1+y)\leq \log(1+y)$. It seems to me that the Raabe's is a more general result, therefore it is not possible to show that Schlömilch's premises $\implies$ Raabe's premises. And this is the question: Is my thought correct or otherwise where is the error in my reasoning?","['sequences-and-series', 'calculus', 'limits']"
1915057,Prove that $\sum\limits_{k=1}^n (k!)^2$ is not a perfect square when $n\ge2$,"Prove that $\displaystyle \forall n\geq 2, \sum_{k=1}^n (k!)^2$ is never a perfect square. I'm far from well-read in number theory and I can't make any significant progress with this problem. I tried to look at the sum $\text{mod}$ some small numbers, to no avail.","['number-theory', 'perfect-powers', 'sequences-and-series']"
1915100,Application of Thoms transversality theorem,"I try to verify example 20.4.10 from Wiggins - Introduction to Applied Nonlinear Dynamical Systems and Chaos and I am quite new to the topic so please be patient. In the book is written that the family of maps
\begin{equation*} f(x,\mu) = \mu + ax^2 \end{equation*} 
is a generic family. If I understand the theory correctly I have to show that the 2-jet of $f(x,\mu)$ is transversal to the submanifold $B := \{(x,f(x), Df(x),D^2f(x)) \in J^2(\mathbb{R},\mathbb{R})~|~ f(x) = Df(x) = 0\}$ and the assertion follows from Thoms transversality theorem. To get the 2-jet of $f$ I apply the 2-jet extension and get:
\begin{equation*} j^2f(x,\mu) = j^2(\mu+ax^2) = (x, \mu+ax^2, 2ax, 2a)\end{equation*} To show that $j^2f \pitchfork B$ I have to show that 
\begin{equation} T_xj^2f(T_xJ^2(\mathbb{R},\mathbb{R})) + T_{j^2f}B = T_{j^2f}J^2(\mathbb{R},\mathbb{R}).\end{equation} 
(Are the spaces in the equation above correct?) Here are the questions I have: What is the property that is meant to be generic for $f(x,\mu)$? To be a versal deformation or to have an non hyperbolic fixed point? At which point should I show that$j^2f \pitchfork B$? Should that be the rest point of $f(x,\mu)$? How do I show that $T_xj^2f(T_xJ^2(\mathbb{R},\mathbb{R})) + T_{j^2f}B = T_{j^2f}J^2(\mathbb{R},\mathbb{R}).$ Thank you for your help!","['transversality', 'ordinary-differential-equations', 'differential-topology']"
1915102,Complex integral constant in real integration,"Can an indefinite integration of a real function with respect to real variable have a complex integral constant? i.e. for $\int f(x) dx = g(x) + c$, can '$c$' be complex, where $f(x)$ is a real function? N.B. I have found a lot of integrations of real function ( example 1 , example 2 ) which use theorems from complex analysis, but finally get real value. N.B. As per as I understand, it can't have complex constant, because integration of a real valued function would only be defined on real plane. Am I right? N.B. I am just checking my understanding. I need to use this result in another problem. Thanks in advance. :)","['complex-analysis', 'integration', 'complex-numbers']"
1915157,Solving $x\log x=1$ without numerical methods,"I tried solving $x\log x=1$ where $x \in (1,e) \subset \mathbb{R} $ but couldn't find a nice way to solve it. Given that $x \in (1,e)$, I tried $x:=e^\alpha$ for $\alpha \in [0,1]$ so that I obtain $\alpha e^\alpha=1$. This resembles the familiar exponential function $f(t)=e^{\alpha t}$. I tried to recover some useful relations and I found the following: a) $\forall t \in [0,1]\quad f^n(t)f^{n+1}(t)=\alpha^{2n}$ b) Using the mean-value theorem, I can show that: $\int_{0}^{1} f^n(t)dt=\alpha^{n-1}(\frac{1}{\alpha}-1)$ which isn't too difficult to show given that $\exists c_n \in (0,1) \quad f^{n+1}(c_n)=f^n(1)-f^n(0)=\alpha^n f'(c_0)$ I found that $c_0 = \frac{1}{\alpha}\log(\frac{1}{\alpha^2}-\frac{1}{\alpha})$ But, after all this work I still couldn't figure out how to find $\alpha$. Perhaps there's an additional relation which I simply failed to discover? Anyway, at this point I tried Newton's method: Using $\large t_{n+1}=t_n-\frac{f(t_n)}{f'(t_{n+1)}}=t_n-\frac{t_n\ln(t_n)+t_n^2}{1+t_n}$ I found that $\alpha \approx 0.567143$. But, I don't consider this a nice solution as I haven't found the exact value of $\alpha$. Might there be a better way that doesn't use numerical methods?","['numerical-methods', 'real-analysis', 'calculus']"
1915172,What is the coproduct in the category of commutative unital C*-Algebras?,"Let $A$ be a commutative unital C*-Algebra and let $X= Spec(A) $ be the corresponding compact Hausdorff space of characters. By Gelfand-Naimark duality we know that
$$ X \times X = Spec(A \coprod A) $$
or in other words
$$ A \coprod A = \mathcal{C}(X \times X).$$ Is there an algebraic way to construct the coproduct, as for example some form of topological tensor product or similar?","['functional-analysis', 'abstract-algebra', 'general-topology', 'category-theory']"
1915181,Integrate $\int \frac{\sin{2x}}{\sin{x}+\cos^2{x}}dx$,"$$\int \frac{\sin{2x}}{\sin{x}+\cos^2{x}}dx=\int \frac{2\sin{x}\cos{x}}{\sin{x}+1-\sin^2{x}}dx=\left| \begin{array}{c} t=\sin x \\  dt=\cos x\,dx \end{array}  \right|=\int \frac{2t}{-t^2+t+1}dt$$ Now I see that $2t$ in numerator and $-t^2$ in denominator, i want to do substitution, but $t$ is the way. I am stuck here.","['indefinite-integrals', 'real-analysis', 'integration', 'trigonometry']"
1915322,Determine if a point lies between two parallel lines,"Let's say I'm given the equations of two parallel lines, and an arbitrary point. What is the method I should use to check if that point lies in between the parallel lines? For example, let's say I have two equations and a point A: $$2x+3y=7$$ $$2x+3y=12$$ $$A (3, -5)$$ How do I check if $A$ lies in between the two lines?","['algebra-precalculus', 'functions', 'analytic-geometry']"
1915324,Find $f(X)$ that minimizes $E[(Y-f(X))^2|X]$,"Let $X$ and $Y$ random variables with $E(Y)=\mu$ and $E(Y^2)<\infty$.
  Deduce that the random variable $f(X)$ that minimizes
  $E[(Y-f(X))^2|X]$ is $f(X)=E[Y|X]$. I just find the minimum with derivatives $$\frac{d}{d f(X)}E[(Y-f(X))^2|X]=-2E[Y-f(X)|X]$$ $$=-2E[Y|X]+2E[f(X)|X]=0$$
$$\Leftrightarrow E[Y|X]=E[f(X)|X]$$
$$\Leftrightarrow f(X)=E[Y|X]$$ Is this right? I founded this solution Is this wrong too?","['derivatives', 'statistics', 'probability', 'expectation']"
1915335,number of distinct rotations of a string,"How do we count the number of distinct rotations of string ? string s=""ABCD"" has four distinct rotations ""ABCD"", ""BCDA"", ""CDAB"" and ""DABC"" but 
ABAB"" has only 2: ""ABAB"" and ""BABA"". More so, a string like ""BBBB"" has only 1 rotation.",['combinatorics']
1915345,Finding an example to disprove a quantified statement,"Find an example of $P(x,y)$ where $\forall x \exists y P(x,y)$ is false ($x \in \mathbb{R})$. My interpretation of this statement is that for all $x$ in $\mathbb{R}$, there must be a $y$ where $P(x,y)$ is true. One example of $P(x,y)$ where the quantified statement would be false is:
$$
P(x,y) \equiv  \frac{y}{x} = 1
$$ This would make the above statement false because if $x$ was $0$, then $\frac{y}{0}$ would be undefined, right? At this point, I don't see a value of $y$ that would make $\frac{y}{x}$ evaluate to $1$.","['logic', 'discrete-mathematics']"
1915347,Proof that convergence almost everywhere is not topological.,"I have written the following proof that convergence almost everywhere is not topological, and I would like it checked if you guys please: Assume that $\tau$ is the topology of almost everywhere convergence. Let $f_n$ be a sequence of measurable functions dominated by an integrable function. Lemma: If $f_n\to f$ in $\tau$ then $f_n\to f$ in $L^1$. Theorem: $f_n\to f$ in $L^1$ implies $f_n\to f$ in $\tau$ Proof: $f_n\to f$ in $L^1$  implies that every subsequence of $f_n$ converges to $f$ in $L^1$. But then for every subsequence of $f_n$, we have a subsequence (of the subsequence) that converges almost everywhere to $f$. Thus, for every subsequence of $\{f_n\}$, there is a subsequence of that subsequence that converges to $f$ in $\tau$. But $\tau$ is a topology and we can thus conclude that $f_n$ converges to $f$ in $\tau$. End Of Proof. Therefore, we have proved that convergence in $L^1$ for a set of measurable dominated functions implies almost everywhere convergence. However, the typewriter sequence satisfies the hypothesis without converging almost everywhere. Thus, we have proved a wrong theorem and thus our assumption that $\tau$ exists was wrong. Thus, convergence almost everywhere is not topological.","['functional-analysis', 'general-topology', 'measure-theory']"
1915353,Irrationality measure of the number is itself,"Does there exist real number $\theta\in \mathbb{R}$\ $\mathbb{Q}$ such that Irrationality Measure of  $\theta$ is itself? $$\forall \epsilon >0, \exists C>0, \forall(p,q)\in \mathbb{Z^2},\bigg|\theta-\frac{p}{q} \bigg|\geq\frac{C}{q^{\theta+\epsilon}}$$","['number-theory', 'diophantine-approximation']"
1915364,"Supposing joint normality, is a pair of asymptotically uncorrelated sequences also asymptotically independent?","Let's say there are two sequences of random variables $(X_n, Y_n)$ and we know that For each $n$, $(X_n, Y_n)$ is normally distributed. $\mathrm{cov}(X_n, Y_n) \rightarrow 0$ as $n \rightarrow \infty$. I am wondering if we can conclude that $X_n$ and $Y_n$ are asymptotically independent (maybe not?), that is, for any Borel sets $A$ and $B$,
$$
\mathbb{P}(X_n \in A, Y_n \in B) - \mathbb{P}(X_n \in A)\mathbb{P}(Y_n \in B) \longrightarrow 0,\text{  as } n \rightarrow \infty
$$ By the two conditions, we know that for any $\theta_1$, $\theta_2$,
$$
\mathbb{E}[e^{i(\theta_1 X_n + \theta_2 Y_n)}]-\mathbb{E}[e^{i\theta_1 X_n}]\mathbb{E}[e^{i\theta_2 Y_n}] \longrightarrow 0
$$ Then it seems we might deduce that for any periodic and bounded functions $\phi$ and $\varphi$, 
$$
\mathbb{E}[\varphi(X_n)\phi(Y_n)]-\mathbb{E}[\varphi(X_n)]\mathbb{E}[\phi(Y_n)] \longrightarrow 0
$$ But I have no idea if we can proceed to further replace $\varphi$ and $\phi$ with indicator functions (or functions in $C_0$ space?).. Any hint will be appreciated :-)","['probability-theory', 'probability', 'measure-theory']"
1915396,Show that the Quotient map is closed.,"Let $X$ and $Y$ be topological spaces. Let $X \cup Y$ be the space with disjoint union topology.Suppose $A \subset X, A $ closed, $f : A \to Y$ be a continuous closed map.Consider the quotient map $\pi: X \cup Y \to X \cup _{f} Y$.Then $\pi$ is closed map. I am trying to prove using the definitions directly but its getting bit messy.Is there any 'smart' way to prove $\pi$ is closed?","['algebraic-topology', 'general-topology', 'quotient-spaces']"
1915418,Geometric Prior Distribution,"What is an appropriate posterior distribution given a geometric prior distribution? I think a Bernoulli posterior would be appropriate, but am unsure if this is correct. Can anyone verify my idea, or give an alternative posterior? Thank you!","['bayesian', 'probability-theory']"
1915452,"Upper bound for the variance of an inner product between two $L^2$ functions, one of them is deterministic","Assume that we have $g,h$ are two $L^2(\mathbb{R}^{+})$ functions, where $g$ is deterministic and $h$ is random. I want to bound $Var[\langle g,h\rangle]$ with $Var[h]$ so I minimize the former by just minimizing the latter ($\langle,\rangle$ is the inner product). One way that I thought about it is to use the delta method which gives me 
$$ Var[ b(h)] \approx \left(b'(\operatorname{E}\left[h\right])\right)^2\operatorname{Var}\left[h\right]$$
Where $b:h \rightarrow \langle g,h\rangle$ Is there any simpler way to do that?? I replied to this question below but I am wondering if we could obtain sharper bound? Thanks.","['functional-analysis', 'probability-theory', 'probability']"
1915471,"If $A$ and $B$ are $n\times n$ complex matrices , then $AB-BA=I$ is impossible. [duplicate]","This question already has answers here : $AB-BA=I$ having no solutions (6 answers) Closed 7 years ago . If $A$ and $B$ are $n\times n$ complex matrices , then $AB-BA=I$ is
  impossible I understand this by any example. But how can one explain it generally?","['matrices', 'linear-algebra', 'linear-transformations']"
1915516,Changing starting point of a sum to another one.,"While doing some homework ive came across problems were the solution involves changing the $\sum$ starting point from lets say $n=1$ to $n=0$ and in this process Ive noticed they will add a constant or so and I dont remember seeing this in class, and Im not quite sure why its done. This is an example 
$$\sum_{n=1}^{\infty}(\sin1)^n$$ 
It then goes and rewrites it in terms of $n=0$ and does the following
$$\sin(1)\sum_{n=0}^{\infty}\sin(1)$$ And they still use the extra value in the geometric series setup
$$\frac{\sin1}{1-\sin1}$$
Im not sure if my question is clear enough but I would like to know how the extra value of the $\sin1$ is added in the second $\sum$ while only changing the starting point from $n=1 \to n=0$","['infinite-product', 'sequences-and-series', 'calculus']"
1915530,Singular values of a matrix after scaling,"Given a complex matrix $A$ and diagonal matrix $D$ with no zero elements on its diagonal, it is well-known that $A$ and $DAD^{-1}$ has the same eigenvalues, however not the same singular values. My question is, how far apart can the singular values be? 
Specifically, consider a stochastic matrix $A$ of dimension $n$ with eigenvalues $|\lambda_1| \ge |\lambda_{2}| \ge \ldots \ge |\lambda_n|$
such that $\lambda_1 = 1$ and $|\lambda_{2}| < 1$. Denote its singular values by $\sigma_{1} \ge \sigma_{2} \ge \ldots \ge \sigma_{n}$, and we know that $\sigma_{1} = 1$ if $A$ is doubly stochastic and $\sigma_{1} > 1$ otherwise. Can one obtain a non-trivial upper bound on $\sigma_{2}(DAD^{-1})$? (I know that a lower bound can be achieved by majorization). In other words, might it be that $\sigma_{2}(DAD^{-1})=\sigma_{1}(DAD^{-1})$?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1915557,Analysing the roots of a ninth degree polynomial,"$$(x-3)^9+(x-3^2)^9+(x-3^3)^9.....+(x-3^9)^9=0$$ $\text{has} A)\text{all real roots} $ B)$3,3^2,..3,^9 C)\text{1 real  8 imaginary roots} D)\text{5 real 4 imaginary roots}$ .$$\text {my approach}$$ If we take it as $f(x)$now with some knowledge of calculus we can see differentiating it we get an expression which is always positive so the $f(x)$ is continuously increasing.But this question was asked in one of the class tests much before we were introduced to calculus. So is there any way where we can use general theory of equations or algebra to get the answer.Thanks!",['algebra-precalculus']
1915646,Existence of a cofinal sequence in a countable directed set,"How does on prove that if $(A, \le)$ is a countable upper-directed set, there exist an increasing cofinal sequence $(a_n)_{n \ge 0} \subseteq A$ (i.e. a sequence such that $a_n \le a_{n+1} \ \forall n$ and for any $a \in A$ there exist $n \in \Bbb N$ with $a \le a_n$)? I am studying Bourbaki's presentation of Kolmogorov's theorem about the existence of the projective limit of a projective system (indexed by $A$) of spaces with measure. The theorem is proven first for $A = \Bbb N$, and for a general countable index set $A$ the proof is reduced to the case $A = \Bbb N$ with the aid of the above statement. No reference or proof suggestion is given therein, and a quick browsing through the set theory volume (the chapter devoted to ordered sets) didn't help me.","['probability-theory', 'limits-colimits', 'measure-theory', 'order-theory']"
1915663,On the complex function $f(s)=\sum\limits_{n=1}^\infty\sigma(n)^{-s}$,"Let $s=x+iy$ the complex variable (if you want a difffernt notation you are welcome), then I know that $\sum_{n=1}^\infty n^{-s}$ converges for $\Re s>1$. On the other hand let $\sigma(n)=\sum_{d\mid n}d$ the sum of divisors function . An important fact is that $\sigma(p)=p+1$ if and only i $p$ is a prime number . We define for some abscissa of convergence $$\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}.$$
Since applying the triangle inequality one has $$\left|\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}\right|\leq\sum_{n=1}^\infty\frac{1}{|\sigma(n)^s|}=\sum_{n=1}^\infty\frac{1}{\sigma(n)^{\Re s}},$$
and one knows that $\sigma(n)\geq n+1>n$ for each $n>1$ (notice that $\sigma(1)=1$) then $(\sigma(n))^{-\Re s}<n^{-\Re s}$ with convergence of the infinite series thus for $\Re s>1$ by the comparison test . And since $\sum_{p \text{ prime}}1/p$ diverges (thus by comparison also $\sum_{p \text{ prime}}1/(p+1)$) I believe that the abscissa of convergence is $1$ (please if there is some mistake or inaccurancie in my claims say me, I want learn and write mathematics rigurously). Thus the information that I can deduce for this function is that has a pole at $s=1$ and converges in the half-plane $\Re s>1$. But I don't know what different claims can be deduced easily. Question. I would like to learn more about complex analysis, what's about this function $$f(s)=\sum_{n=1}^\infty\frac{1}{(\sigma(n))^s}$$
  concerning if  is it meromorphic , (I hope that my words and claims are rights), it is possible /feasible an analytic continuation to different regions of the complex plane, or can you deduce other easy things about non-vanishing for $\Re s>1$...? Has zeros ? Thus I am asking about what's things are easily deduced for a complex function of this kind. I understand that is a question involving a lot of possible computations, but I would like to know how works with this kind of functions from the complex path. You can deduce the more relevant facts and other provide us as hints. Thanks in advance.","['divisor-sum', 'complex-analysis', 'analytic-continuation', 'convergence-divergence']"
1915667,Relation between signs of imaginary parts of $(x+iy)$ and $\sqrt{x+iy}$,"I am looking at the Harvard notes for the complex analysis, and I do not follow how they arrive at the circled: EDIT: Can also someone show me how to get to the last line? I am a bit confused about how the $\text{sgn}(b)$ emerges there.","['algebra-precalculus', 'complex-analysis', 'radicals']"
1915731,Is the space of finite point measures locally compact?,"Let $X$ be a polish locally compact space. If we define the space of finite point measures over $X$,
$$\mathcal{M}_p(X)=\left\{\sum_{i=1}^n\delta_{x_i}\left\vert\vphantom{\frac{1}{N}}\right.n\in\mathbb{N},x_i\in X\right\},$$
is this space locally compact under the topology of weak convergence? I'm having trouble trying to prove if it's true or not and i can't find a reference about this. Any help will be appreciated.",['measure-theory']
1915746,"Evaluate $\int x\frac{\tan{x}}{\cos^{2}{x}}\,dx$",What is $\int x \frac {\tan{x}} {\cos^{2}{x}}dx$? I managed to get to $\frac {x\sec^2x}2+\int \frac {\sec^2x}2-\frac12+c$ but I'm not sure if I can absorb the $-\frac12$ into the constant at this point. Guidance would be appreciated.,"['integration', 'trigonometry', 'integration-by-parts', 'calculus']"
1915776,Continuous function keeps the convergence in distribution,"Let $(X_n)_{n\in \mathbb{N}}$ be a sequence of real random variables and $X_n\to X$ in distribution. If $f$ is a contiuous function, then $f(X_n)\to f(X)$ in distribution. How do I prove this? Is this correct: let $f:\mathbb{R}\to \mathbb{R^+}$ then 
$$\mathbb{E}(f(X_n))=\underbrace{\int f(x_n)P(X_n\geq x)}_{\text{is this correct?}}\xrightarrow{(d)}\int f(x)P(X\geq x)= \mathbb{E}(f(X))$$","['probability-theory', 'probability', 'probability-distributions']"
1915804,Sensitivity equations with discontinuities,"I'm working on solving pharmacometric problems using ordinary differential equations of low dimensionality. For example, a common simple model looks like this: $$\dot{A} = -KA$$ where $A$ is the amount of a drug in blood plasma, and $K$ is the elimination rate, in units of 1/time. It is desired to know how $A$ varies with changes in $K$. Define $G = \partial A/\partial K$. Then we can write a ""sensitivity equation"": $$\dot{G} = -KG - A$$ This is all well known, but what is not well known is how to handle discontinuities at particular time points, such as doses $A = A + D$, or simply setting $A$ to zero $A = 0$. What do we do with $G$ at those time points?
I've tentatively concluded that adding something to $A$ does not affect $G$, but multiplying $A$ by some factor, like $0$, should also be applied to $G$. I would appreciate any insight I may be lacking on this. For what it's worth, here is some documentation on CVODES, by Serban and Hindmarsh:",['ordinary-differential-equations']
1915808,Second fundamental form and Weingarten map,"I know two definitions of the 2nd fundamental form on 2-surfaces in $\mathbb R^3$: 1) For a parametrization $X(u,v)$ of the surface and the normal vector $\nu$, the 2nd fundamental form is given by the matrix $$
\left(
\begin{array}
& X_{uu} \cdot\nu & X_{uv}\cdot\nu \\
X_{vu} \cdot\nu & X_{vv}\cdot\nu
\end{array}
\right)
$$ where $$X_{uv}=\frac{\partial}{\partial u}\frac{\partial}{\partial v}X$$ 2) $\Pi(x,y)=-\langle Dn_p(x),y\rangle$ where $Dn_p$ is the Weingarten map and $\langle,\rangle$ the scalar product in $\mathbb R^3$. How can I show that the two definitions define the same thing?",['differential-geometry']
1915816,Deformations of codimension 2 ACM subschemes,"I have a question about a theorem and example in Hartshorne's ""Deformation Theory"" p. 65. The theorem reads: Theorem 8.9 Let $Y_0$ be an ACM closed subscheme of codimension 2 of $X_0=\mathbb{P}^n_k$ , and assume $\dim Y_0\ge1$ . Using notation (6.1) [note: this means we have an exact sequence $$0\to J\to C'\to C\to0$$ where $C$ and $C'$ are local Artin rings with residue field $k$ and $J$ is an ideal with $\mathfrak{m}_{C'}J=0$ ], suppose we are given a closed subscheme $Y$ of $X=\mathbb{P}^n_C$ , flat over $C$ and with $Y\times_Ck=Y_0$ . Then: (a) There is an $r\times(r+1)$ matrix $\varphi$ of homogeneous elements of $R=C[x_0,\ldots,x_n]$ whose $r\times r$ minors $f_i$ generate the ideal $I$ of $Y$ , and give a resolution $$0\to\bigoplus R(-b_i)\xrightarrow{\varphi}\bigoplus R(-a_i)\xrightarrow{f}R\to R/I\to0.$$ (b) For any lifting $\varphi'$ of $\varphi$ to $R'=C'[x_0,\ldots,x_n]$ , taking $f'$ to be the $r\times r$ minors gives an exact sequence $$0\to\bigoplus R'(-b_i)\xrightarrow{\varphi'}\bigoplus R'(-a_i)\xrightarrow{f'}R'\to R'/I'\to0$$ and defines a closed subscheme $Y'$ of $X'=\mathbb{P}^n_{C'}$ , flat over $C'$ , with $Y'\times_{C'}C=Y$ . (c) Any lifting $Y'$ of $Y$ to $X'$ , flat over $C'$ with $Y'\times_{C'}C=Y$ , arises by lifting $\varphi$ as in (b). This theorem is followed by: Example 8.9.1 The conclusions of (8.9) are false in the case of a scheme $Y_0$ of dimension 0 in $\mathbb{P}^n$ . For example, let $Y_0$ be a set of three collinear points in $\mathbb{P}^2$ . Then there is a linear form in the ideal of $Y_0$ . But as you deform the points in the direction of a set of three noncollinear points of $\mathbb{P}^2$ , the linear form does not lift. So the deformations of $Y_0$ cannot all be obtained by lifting the elements of the corresponding matrix $\varphi$ . I think I understand why this is a counterexample in dimension 0. Now suppose we replace this $Y_0$ with the cone over $Y_0$ in $\mathbb{P}^3$ . Now it has dimension 1, and is still ACM of codimension 2, so (8.9) applies. Yet it seems like the argument in (8.9.1) still works. Instead of three collinear points, we have three coplanar coincident lines, so there is a linear form in the ideal of the lines. Yet if we deform in the direction of three noncoplanar lines, still coincident at the cone point (just take the cone over the deformation from (8.9.1)), the linear form does not lift. But this would be a counterexample to the theorem. What is wrong with this argument?","['deformation-theory', 'algebraic-geometry']"
1915830,"Can two figures (of any kind, bounded by curves or not) have the same area and perimeter, but different shapes?","Can two figures (of any kind, bounded by curves or not) have the same area and perimeter, but different shapes? By ""different shape"", I mean that you cannot rotate one, take it out of the plane, and/or enlarge/reduce it so that it fits the other.","['general-topology', 'geometry']"
1915838,Concept of the slope,"Having difficulties understanding the concept of the slope: Suppose we have $f(x)=x^2$, its derivative $f'(x)=2x$ At $x=10$, $f(x)=100$ and $f'(x)=20$. So the rate of change of the function at $(x,y)=(10,100)$ is $20$, but what does that mean? If we take $x+1=11$, we get: $f(11)=121$ and not $120$. So what was the point of calculating the slope at (10,100)? What information did it provide us?","['derivatives', 'slope', 'soft-question', 'calculus']"
1915848,"Randomly putting things in buckets, computing overflow probability (Basic probability question)","Setting: Assume I have $n$ buckets, where each can hold $w$ balls and initially there is one ball in each bucket. I do the following. I keep taking one ball from a random bucket and I put it into another random bucket. I do this $l$ times. I want to figure out with what probability one of the buckets will overflow, i.e. what the probability is that at some point I try to put more than $w$ balls into some bucket.
Furthermore, I would like to know how large the buckets need to be s.t. the probability of such an overflow is below a threshold. Question: I have trouble deciding what the correct approach to this problem is and it's somehow not clear to me how, generally, to decide what approach to take. There are several methods that seem somewhat unrelated, yet useful for this problem. Approaches: For instance, I could look at an arbitrary, but fixed bucket and try to use the binomial formula to compute the probability that I will put $k$ out of $l$ balls into a specific bucket. However, I'm not sure how to consider the fact that I don't just put balls into buckets, but also remove them randomly. Also, I'm not sure whether looking at one bucket is really the same as looking at all of them. Another, to me seemingly totally independent, approach would be to compute the expected value for the number of balls in a bucket (which should be 1) and then use the Chernoff bound to bound the probability that a specific bucket will overflow. Here, I'm not sure which Chernoff bound to use. There seem to be several very similar formulas, but I don't really understand the differences. Would I get some probability bound that depends on the number of iterations of my experiment, i.e. how often I randomly relocate a ball into some bucket?","['balls-in-bins', 'probability']"
1915876,Find $f^{(100)}(0) $ and $f^{(101)}(0) $ if $f(x)=xe^{\arctan{x}}$,$$f(x)=xe^{\arctan{x}}$$ Part of my solution $$f^{(n)}(x)=\sum_{k=0}^{n}\binom{n}{k}x^{(k)}(e^{\arctan{x}})^{(n-k)}=x(e^{\arctan{x}})^{(n)}+(e^{\arctan{x}})^{(n-1)}$$ First term probably disappears because $x=0$ but i don't know what to do with second term.,"['derivatives', 'real-analysis']"
1915885,Does this sequences convergence? $a_{n} = n \cdot \sin(\frac{2}{n})$ for $n \rightarrow \infty$?,"Does this sequences convergence for $n \rightarrow \infty$? $$a_{n} =
n \cdot \sin(\frac{2}{n}) $$? Very problematic task.. $n$ alone would diverge to $\infty$ and $sin(\frac{2}{n})$ would converge to $0$. So we got $\infty \cdot 0$ which means we need to use Hôpital's rule. For use this rule we need fraction: $$\frac{n}{\frac{1}{sin(\frac{2}{n})}}$$ $$\left ( n\right )' = 1$$ $$\left (\frac{1}{sin(\frac{2}{n})} \right )' = \frac{2 cos(\frac{2}{n})}{n^{2} \cdot sin^{2}(\frac{2}{n})}$$ $$\Rightarrow$$ $$\frac{1}{\frac{2 cos(\frac{2}{n})}{n^{2} \cdot sin^{2}(\frac{2}{n})}} = \frac{n^{2} \cdot sin^{2}(\frac{2}{n})}{2 cos(\frac{2}{n})}$$ Problem still remains, $$\frac{\infty^{2} \cdot 0^{2}}{2 \cdot 1}$$ I would just say that the sequence diverges.. No idea what else I can do. What you think about my solution?","['convergence-divergence', 'sequences-and-series', 'calculus', 'analysis']"
1915986,"Intuition for opposite ring, equivalence of left and right modules, anti-involution.","Here is an excerpt from what I am reading. One can similarly define right $A$ -modules. A convenient way to give a formal definition of right module is as follows. First, given a ring $A$ , one defines $A^{op}$ , the opposite ring, to  be the abelian group $(A, +)$ equipped with an opposite multiplication $a$ , $b \mapsto a \cdot_{op} b := ba$ . Then, a right $A$ -module is, by definition, the same thing as a left $A^{op}$ -module. Remark. An anti-involution on a ring $A$ is a morphism $A \to A$ , $a \mapsto a^*$ of abelian groups such that $$(ab)^* = b^* a^*, \quad (a^*)^* = a, \quad (1_A)^* = 1_A, \quad a, b \in A.$$ An anti-involution on $A$ provides a ring isomorphism $A \overset{\sim}{\to} A^{op}$ . Transposition of matrices gives an example of a non-trivial anti-involution on $\text{M}_n(k)$ , a noncommutative ring. The identity map is an anti-involution on any commutative ring. Thus, we have $A^{op} \cong A$ for any commutative ring $A$ and hence the notions of left and right $A$ -modules coincide in this case. This is quite dense, and so I am wondering if anybody can help me unpack the following. What is the intuition behind the definition of opposite rings, and for working with them? Do they ever come up in practice? Why is a right $A$ -module the same thing as a left $A^{op}$ -module? What is the intuition behind the definition of opposite rings, and for working with them? Do they ever come up in practice? And why do they provide a ring isomorphism $A \overset{\sim}{\to} A^{op}$ ? What is the intuition behind $A^{op} \cong A$ for a commutative ring $A$ and having the notions of left and right $A$ -modules coinciding? Ugh, sorry for the large blocks of text. Thanks!","['modules', 'abstract-algebra', 'ring-theory', 'group-theory', 'linear-algebra']"
1916017,What is the main feature of uncountable sets?,"Sorry if my question is not constructive. This theme is very interesting for me and I really want to understand it. All written below don't claim as serious argument for any fact. It just shows my understanding of the theme (as you can see I don't understand it well). Let's look at $\mathbb{Z}$ and $\mathbb{Q}$. They are both infinite and countable but we can differ them using this fact: $\mathbb{Q}$ is dense (unlike $\mathbb{Z}$). I'm trying to understand the difference between countable and uncountable sets in the same way, by finding any property which is true for one and false for other. Let's look at $\mathbb{Q}$ and $\mathbb{R}$. What property can I get? Dense? There are both dense. Containing irrational numbers? Well, but the set of algebraic numbers also contains some of them, even all roots, but it's countable. Yes, Cantor's diagonal argument gives us a simple example of uncountable set. But there I have same question: what are the properties which are true for the set of infinite sequences of 0 and 1 and false, for example, for $\mathbb{N}$? Or, if we interpret the infinite sequence of 0 and 1 as a binary fraction, we can compare real numbers from [0; 1] with algebraic ones. I can't understand how it can two different infinities exist. What finally confused me is Zermelo's Well-ordering theorem which says that we can rearrange elements in any (even in more than uncountable) set such that it will become well-ordered. Because of this every element will have next to it. It means that even $\mathbb{R}$ will not be dense but will stay still uncountable. How is it possible? (I know that there are used Ordinal numbers)","['infinity', 'elementary-set-theory']"
1916035,Regular curve which normal lines pass through a fixed point [duplicate],"This question already has answers here : Tangent and Normal lines that pass through the origin (2 answers) Closed 4 years ago . I have the following question: Assume that $α$ is a regular curve in $R^2$ and all the normal lines of
  the curve pass though the origin. Prove that $α$ is contained in a
  circle around the origin. (Recall the normal line at $α(t)$ is the line
  through $α(t)$ pointing in the direction of the normal vector $N(t)$.) My attempt: I know that if $α(t)$ is contained in a circle, then the curvature is constant. So I have to prove that the curvature at $α(t)$ is constant. I also know that the equations of the normal lines through the origin that passes through arbitrary points on the curve $α(t)$ denoted as $(t, α(t))$ have the equations: $$α(t) = \frac{t}{α'(t)}$$ I'm confused on how to proceed from here.","['curves', 'parametrization', 'differential-geometry', 'curvature']"
1916069,Khatri-Rao product example,"I am trying to understand the following definition of the Khatri-Rao product taken from Kolda, Tamara G., and Brett W. Bader. ""Tensor decompositions and applications.""(2009): ""The Khatri-Rao product is the ""matching columnwise"" Kronecker product. Given matrices $\mathrm{A} \in \mathbb{R}^{I \times K}$ and $\mathrm{B} \in \mathbb{R}^{J \times K}$, their Khatri-Rao product is denoted by $\mathrm{A} \odot \mathrm{B}$. The result is a matrix of size $(IJ) \times K$ and defined by $$\mathrm{A} \odot \mathrm{B} = [\mathrm{a}_1 \otimes \mathrm{b}_1 \mathrm{a}_2 \otimes \mathrm{b}_2 \ldots \mathrm{a}_k \otimes \mathrm{b}_k] $$."" I do understand the result of a matrix Kronecker product, but not of elementwise Kronecker products and so I'm having a hard time understanding the result of such a multiplication. So far I just can't find good online examples. Can someone give me a simple numerical example of what the result of such a multiplication should be?","['matrix-decomposition', 'tensor-products', 'linear-algebra']"
1916101,Colimits in the category of $k$-topological spaces,"Recall a $k$-space $X$ is a topological space with the property that a subset is open if, and only if its intersection with any compact subspace is open in the subset topology. Let $k$ Top be the full subcategory of Top consisting of the $k$-spaces and continuous maps between them. There is a functor Top $\to$ $k$ Top ($k$-ification) changing the topology slightly. We denote $Y_k$ the image of a topological space $Y$ under this functor. It has the property that if $X$ is a $k$-space, $Y$ is any topological space, and $f:X\to Y$ is any function, then $f$ is continuous if, and only if $f$ seen as a map $X\to Y_k$ is continuous. In light of what we have said above, is it true that a colimit in $k$ Top is the same as that colimit taken in Top ? Namely, denote by $\iota:$ $k$ Top $\to$ Top the inclusion. Let $D$ be a diagram in $k$ Top . Is
$$\operatorname{colim}^{\textbf{Top}}\iota(D) \cong \iota(\operatorname{colim}^{k\textbf{Top}}D)$$
true?","['category-theory', 'general-topology', 'limits-colimits']"
1916156,Ideal generating the Grassmannian,"An exercise in Shafarevich's Basic Algebraic Geometry I is to show that the ideal of the projective embedding of the $(2,n)$-Grassmannian is generated by the Plücker equations (this is true for the $(k,n)$-Grassmannian generally, but I guess it's harder to show). Let us write the Plücker equations as $F_1,...,F_m$, and the ideal of all polynomials vanishing on the Grassmannian let us denote as $\mathfrak{U}_{Gr}$. The suggestion in Shafarevich is to show that the ""affine"" versions of $\mathfrak{U}_{Gr}$ are generated by the ""de-homogenized"" Plücker equations (i.e. $\frac{F_1}{x_i^{\deg F_1}},\dots,\frac{F_m}{x_i^{\deg F_m}}$) on the usual affine patches of projective space given by non-vanishing of $x_i$, and then somehow use this to show that the actual ideal $\mathfrak{U}_{Gr}$ is generated by the homogeneous polynomials $F_1,...,F_m$. I can show the statement for the affine ideals, but I am struggling to show that this implies what is desired for the actual ideal. I think a concise way to state the difficulty I am having is maybe how to show the following, if it is true: (*) Let $\mathbb{P}^n$ be projective space, and $X$ be an irreducible projective variety defined set-theoretically by the vanishing of homogeneous polynomials $F_1=\cdots=F_m=0$. If for $i=0,...,n$ we have that the ideal of all functions vanishing on the affine piece of $X$ given by $X\cap\{x_i\ne 0\}$ is $(\frac{F_1}{x_i^{\deg F_1}},\dots,\frac{F_m}{x_i^{\deg F_m}})$, then the homogeneous ideal given by all homogeneous polynomials vanishing on $X$ is equal to $(F_1,...,F_m)$. If anyone can give me a hint towards seeing why this is true, I would appreciate it.","['grassmannian', 'algebraic-geometry', 'commutative-algebra']"
1916175,Converting two nonlinear DEs into a system of four first order ODEs,"From a from a spring pendulum system, I was able to derive the equations
$$ mr''=m(\theta')^2 +mg\cos(\theta)-k(r-l) $$ and 
$$r^2\theta''= 2rr'\theta'=gr\sin(\theta) $$
where $r$ is a function of time denoting the length of the spring in the picture ,so r(t)=l+x(t) where $x(t)$ measures how much the spring has been stretched from its equilibrium length $l$; $\theta$ is a function of time which measures the angle shown above; $m$ is the mass of the object at the end of the spring; $g$ is the gravitational constant; and $k$ is the spring constant. My question: I've been told that I can turn these two nonlinear equations into  a system of four first order ODEs using the newly defined terms $\rho_{\theta}=mr^2\theta'$ and $\rho_{r}=mr'$. I'm curious to know if there is a general method or systematic approach to convert nonlinear systems into simpler systems like I want to do above or is it more of an ad hoc approach. In the former case, will someone provide a reference? In the latter, will someone provide a hint for this specific example?","['ordinary-differential-equations', 'dynamical-systems']"
1916191,ODE with inverse function. Solve $f^{-1}(x)=f'(x)$.,"Find all functions $f:\mathbb{R}^+\rightarrow\mathbb{R}^+$ such that $$f^{-1}(x)=f'(x)$$ I think one such function would be of the form $f(x)=ax^b$. But then $b$ would be irrational and when $x\lt0$ this causes problems. So I guess letting $f(x)=-a(-x)^b$ for $x<0$ might work. But that's only one possibble solution, what are all the solutions? Edit: With the comment of Joey Zou, the domain and range has been changed to $(0,\infty)$. Edit: I already know the solution of the form $ax^b$. However, what I'm really asking is whether it is the unique solution.",['ordinary-differential-equations']
1916196,Number of r-combination of a multiset of with k different types of objects,"I am having a hard time in understanding the following theorem: Let $S$ be a multiset with objects of $k$ types, each with an infinite repetition number. Then the number of r-combinations of $S$ equals $${r+k-1 \choose r} = {r+k-1 \choose k-1}$$ Proof: Let the $k$ types of objects of $S$ be $a_1,a_2,...,a_k$ so that
$$S = \{\infty.a_1,\infty.a_2,...,\infty.a_k\}$$ Any r-combination of $S$ is of the form $\{x_1.a_1,x_2.a_2,...,x_k.a_k\}$, where $x_1,x_2,...,x_k$ are nonnegative integers with $x_1,x_2,...,x_k = r$ Conversely, every sequence $x_1,x_2,...,x_k$ of nonnegative integers with $x_1,x_2,...,x_k = r$ corresponds to an r-combination of $S$. Thus, the number of r-combinations of $S$ equals the number of solutions of the equation $$x_1+x_2+...+x_k = r$$ We show that the number of these solutions equals the number of permutations of the multiset $$T = \{r.1, (k-1).*\}$$ I don't understand how the equation relates to the number of permutations of the set $T$ and how the $T$ has been constructed.","['combinations', 'combinatorics', 'multisets']"
1916242,What is the smallest and largest possible values for the variance?,"Suppose
$P( X \in \{1,2,3\}) = 1$ and  $E(X) =2.5.$ What is the smallest and largest possible values for the variance? My understand: So what I understand is variance finds the distance between each element and the mean. So the closer 2 is to E(X) the farther 1 and 3 can be from E(X). But I have no clue how to obtain this..",['probability']
1916344,Question about locus in rhombus.,"Suppose we have rhombus $ABCD$ and we have point $X$ inside our rhombus.
Now we should find locus of such points : $AXD$ + $BXC$ = $\pi$.
My attempt : obviously point of diagonals intersection is a good one.
Now suppose there is another point. So let : $d_{1} = AX$ , $d_{2} = DX$ , $d_{3} = BX$ and $d_{4} = CX$.
I figured out that : 
$cos(\alpha)=\frac{d_{1}^2 + d_{2}^2 - d_{3}^2-d_{4}^2}{d_{1}d_{2}+d_{3}d_{4}}$ but that doesn't help me at all","['locus', 'geometry']"
1916358,Why is $x'=\lambda x$ considered stiff for $\lambda<0$?,"Consider the ODE $x'(t)=\lambda x(t)$, $x(0)=1$ for $t\in[0,1]$, with $\lambda\in\mathbb{R}$. Applying the explicit Euler method yields approximations $x_N$ with $x_N(i/N)=(1+\frac{\lambda}{N})^i$, $i\in\{0,\dots,N\}$. The relative error to the exact solution $x(t)=\exp(\lambda t)$ is therefore
$$
\epsilon_N(i/N)=\frac{\exp(\lambda i/N)-(1+\frac{\lambda}{N})^i}{\exp(\lambda i/N)}\\
=1-(1+\frac{\lambda}{N})^i\exp(-\lambda i/N)=1-\exp(i\log(1+\frac{\lambda}{N})-i\lambda/N)=1-\exp(-i\xi^2)
$$
for some $\xi\in[0,|\lambda|/N]$ (as long as $N>-\lambda$). Therefore, $\sup_{i=1}^N|\epsilon_N|\leq \alpha$ requires (with $0<\alpha<1$ fixed and $\lambda\to \infty$) that $N\sim\lambda^2$. In the above derivation, the sign of $\lambda$ only appears once, when we require $N>-\lambda$ (which only is restrictive when $\lambda<0$). However, at the end we get $N\sim\lambda^2$ anyway. Therefore, I don't understand why the problem is considered stiff for $\lambda<0$ but not for $\lambda>0$.","['numerical-methods', 'ordinary-differential-equations']"
1916361,Different R structures on a complex variety,"I was reading Springer's Linear Algebraic Groups and I came across this problem 1.3.9 on page 6. Let $k = \mathbb{C}$ , $\;F = \mathbb{R}$ , $\;k[X] = k[T,U]/(T^2 + U^2 -1)$ , and let $a,b$ be the images of $T,U$ in $k[X]$ . Show that $F[a,b]$ and $F[ia,ib]$ define two different $F$ structures on $X$ . I can show that they are both $F$ -structures. However, I do not see how they are different or what it even means for $F$ -structures to be different.","['algebraic-groups', 'algebraic-geometry']"
1916365,Why the integral of $\frac{1}{z}$ over a closed curve is not $0$.,"Consider the path $\gamma: [0,2\pi]\rightarrow \mathbb{C}$ given by $\gamma(t) = e^{it}$. Let $f(z) = \frac{1}{z}, z\neq 0$. I worked out the integral $$\int_\gamma f = \int_{0}^{2\pi} f(\gamma(t))\gamma'(t) dt = 2\pi i$$ However, $f$ is continuous on $f(\gamma([0,2\pi]))$, so I was wondering why this integral is nonzero, since I thought that the integral over a  closed path that takes $[a,b] \rightarrow G$, where $f$ is continous on $G$ and $f$ has a primitive on $G$ should be $0$. What is going wrong here?",['complex-analysis']
1916384,Suppose $M$ is an $m \times n$ matrix such that all rows and columns of $M$ sum to $1$. Show that $m=n$,"I find this a rather awkward question,  from the book ""Mathematical Circles"" by Fomin, Genkin and Itenberg. The question number is Question number 23 from  Chapter 12 (""Invariants""). I was given a hint: use invariants, which I found even more awkward. There was also a remark : ""strange as it may seem, this is an invariants problem"". Funny , because I don't know what to expect now! Suppose $M$ is an $m \times n$ matrix such that all rows and columns of $M$ sum to $1$ . Show that $m=n$ . I have no clue how this is a problem on invariants, let alone how to solve this problem. I'll need hints on why this is the case.","['matrices', 'invariance', 'linear-algebra']"
1916411,Arrangements of MISSISSIPPI with all S's and P's separated,"If the all S,P are separated in the word MISSISSIPPI then the total possible arrangements are $k\frac {10!}{4!.4!} $ then value of k is? Now all S,P are separated so we can have slash method. Thus they can be placed alternatively in $6! $ ways and rest 5 can be placed in $5! $ ways. Thus we equate to get $$6!.5!=k\frac {10!}{4!.4!} $$  to get $k=13.7$ while $k=4/3$ .Where is my mistake Thanks",['combinatorics']
1916412,Definition of exterior algebra,"I'm studying tensor algebra and exterior algebra and having problems with the definition of $\bigwedge(\mathbb{V})$. Let $\mathbb{V}$ be any vectorial space over a field $K$. Define
$T^k\mathbb{V}:=\underbrace{\mathbb{V}\otimes \mathbb{V}\otimes\cdots\otimes\mathbb{V}}_{k-times}$, where $T^0\mathbb{V}=K$. Define the tensorial algebra $T(\mathbb{V}):=\bigoplus_{k=0}^{\infty}T^k(\mathbb{V})=K\oplus\mathbb{V}\oplus(\mathbb{V}\otimes\mathbb{V})\oplus\cdots$. Multiplication on $T(\mathbb{V})$ is determinated by the canonical isomorphism $T^k(\mathbb{V})\oplus T^j(\mathbb{V})\rightarrow T^{k+j}(\mathbb{V})$, so $T(\mathbb{V})$ is naturally a graded algebra. Define exterior algebra (and here is my doubt) $\bigwedge(\mathbb{V})$ over a $K$-vector space $\mathbb{V}$ as the quotient algebra  of the tensorial algebra $T(\mathbb{V})$ by the two sided ideal $I$ spanned by the elements of the form $x\otimes x$ with $x\in\mathbb{V}$, $\bigwedge(\mathbb{V}):=\dfrac{T(\mathbb{V})}{I}$ My question is, first of all how are specifically the elements of $I$? It is a subspace of $T(\mathbb{V})$.","['abstract-algebra', 'exterior-algebra', 'tensor-products']"
1916422,How can trigonometric ratios of 90° be found?,"The angles in a right triangle can never be 90° (excluding the right angle ofcourse). Then how can T-ratios of 90°  be found? Leaving ""finding them""  aside, how can they even exist? Same goes for T-rations of angles bigger than 90° . I am a 10th class student and have studied trig for thr first time so sorry if this is a dumb question..","['algebra-precalculus', 'trigonometry']"
1916457,direct product commutes with tensor product?,"Let $(A_i)_{i\in I}$ be a family of right $R$-modules and $M$ be a left $R$-module, where $I$ is an index set. The natural homomorphism
$$\varphi:(\prod_{i\in I}A_i)\otimes_RM\to \prod_{i\in I}(A_i\otimes_RM)$$ given by $(a_i)\otimes m\mapsto(a_i\otimes m)$ is not always a bijection. It is  easy to obtain $\varphi$ is a surjection provided $M$ is finitely generated. If we assume that $M$ is finitely presented, can we prove $\varphi$ is a bijection?","['abstract-algebra', 'ring-theory', 'modules', 'tensor-products']"
1916479,Can we use this as definition of the derivative?,Let $D$ be a subset of $\mathbb{K}$ where $\mathbb{K}=\mathbb{R}$ or $\mathbb{C}$. Let $f:D\to \mathbb{K}^N$ be a function. Then $f$ is differentiable at $x$ if $$\lim_{n\to \infty}\frac{f(x+\frac{1}{n})-f(x)}{\frac{1}{n}}$$ exists.,['derivatives']
1916517,Number of ways of distributing $N$ balls into $M$ bins such that at least one bin has at least $n$ balls in it?,"What is the number of ways of distributing $N$ indistinguishable balls into $M$ bins such that at least one bin has at least $n$ balls in it? My attempt: The number of ways of of placing $N$ balls into $M$ bins is $\binom{N+M-1}{N}$. I tried, by stars and bars, to calculate the number of ways of distributing $N$ indistinguishable balls into $M$ bins such that exactly one bin has exactly $n$ balls in it: If the first or last bin contains the $n$ balls, we have used one partition, so there are $M-2$ left. This gives $2\binom{N-n+M-2}{N-n}$ ways. If the second to $(M-1)$th bin contains the $n$ balls, we have used two partitions, which gives $(M-2)\binom{N-n+M-3}{N-n}$ ways. So the total number of ways of distributing $N$ indistinguishable balls into $M$ bins such that exactly one bin has exactly $n$ balls in it is 
$$2\binom{N-n+M-2}{N-n}+(M-2)\binom{N-n+M-3}{N-n}.$$ Is this correct? It seems like a strange result. Then I thought about simply summing this expression for $n$ going from $n$ to $N$, i.e., $$\sum_{k=n}^N 2\binom{N-k+M-2}{N-k}+(M-2)\binom{N-k+M-3}{N-k},$$ in order to obtain the expression for ""at least $n$ balls,"" but I feel like this would be over-counting somehow. And then there is the issue of ""at least one bin,"" which I am rather blunted by. Any help is much appreciated! Note that I'm looking for a closed form solution to the problem in the yellow box. Thanks.","['combinatorics', 'balls-in-bins']"
1916529,"Is $\{n\pmod \pi: n \in \Bbb N\}$ dense in $[0,\pi]$?","Is $\{n\pmod\pi: n\in\Bbb N\}$ dense in $[0,\pi]$ ? Is there a proof or well known theorem for this result? My intuition would say that it is dense.",['real-analysis']
1916532,Number of all of finite monotone sequences,"Let $X = \{1, 2,\ldots ,n\}, n\in\mathbb{N}$. Find the number of $f: X\to X$ such that $f$ is monotone i.e
$$i<j\Longrightarrow f(i)\leq f(j)$$ Put another way, find the number of monotone finite sequences. Counting them is so painful even for $n=5$, lest the beginning is easy... If $f(1)=5$, there's only one way: $f(j)=5$ for every $j$. If $f(1) = 4$, then it starts to depend on subsequent choices.
$f$ doesn't even have to be onto. This will clearly be a headache, so I was hoping to make the reasoning inductive/recursive (somehow). If $1\mapsto 5$, 1 possibility. If $1\mapsto 4$, then we allow $f(2)\in\{4,5\}$ Since we have ($k$) four elements left to map, we get a total of $5$ possibilities of doing so [counted manually from diagram]. ($k+1$?). If $1\mapsto 3$ and $2\mapsto 5$, 1 possibility. If $1\mapsto 3$ and $2\mapsto 4$, then $f(3)\in\{4,5\}$. $4$ possibilities by hypothesis (result, perhaps?). If $1\mapsto 3$ and $2\mapsto 3$, then $f(3)\in\{3,4,5\}$: Lost hope at this point. I can apply the result for set with 2 elements recursively, but would still need to recompute possibilities for set with $3$ elements and then $4$ el etc$\ldots$ Are there any tips/hints on how to, perhaps, simplify the counting?",['combinatorics']
1916543,Connection between ceil and round,"I have two rounding functions. The first is ceil , which always finds the smallest integer that is at least as large as the input. E.g. ceil(0) = 0 , ceil(0.1) = 1 , ceil(0.5) = 1 , ceil(0.9) = 1 . The second is round , which always finds the integer closest to the input. For the middle (.5), it is defined as returning the next larger integer.  E.g. round(0) = 0 , round(0.1) = 0 , round(0.5) = 1 , round(0.9) = 1 . Is there a connection between them that allows to substitute ceil by round ? Like ceil(x) = g(round(f(x))) for some functions f , g that do not contain ceil ? Do such functions exist? I only care about nonnegative numbers as input for ceil and round .","['algebra-precalculus', 'ceiling-and-floor-functions']"
1916560,"If $A+B+C+D=2\pi$, prove that:","If $A+B+C+D=2\pi$, prove that: $$\cos A+\cos B+\cos C+\cos D=4\cos\frac {A+B}{2}\cdot\cos\frac {A+C}{2}\cdot\cos\frac {B+C}{2}$$. My Approach: Here,
$$A+B+C+D=2\pi$$
$$A+B=2\pi - (C+D)$$
$$ \sin(A+B)=\sin(2\pi-(C+D))$$
$$\sin(A+B)=-\sin(C+D)$$ Again, $$\cos(A+B)=\cos(2\pi-(C+D))$$
$$\cos(A+B)=\cos(C+D)$$ Now, $$L.H.S=\cos A+\cos B+\cos C+\cos D$$
$$=2 \cos\frac {A+B}{2}\cdot\cos\frac {A-B}{2} + 2 \cos\frac {C+D}{2}\cdot \cos\frac {C-D}{2}$$. I got stuck at here. Please help me to complete the proof.","['algebra-precalculus', 'trigonometry']"
1916562,Children disliking in a circle,"$n\geq 3$ children are to be placed in a circle. Some pairs of children dislike each other and do not want to be next to each other. (Disliking is mutual.) What is the maximum $k$ such that if each child dislikes no more than $k$ other children, then a placement is always possible? If a child dislikes $n-2$ other children, a placement is obviously not possible because we cannot find two children to be next to this child. If a child dislikes $n-3$ other children, his two neighbors are fixed.","['combinatorics', 'graph-theory']"
1916591,Probability that parents don't name their children with the same first initial as their own,"To test the hypothesis that parents name their children without bias towards their own initials we have data of one parent name and one of their children's names . There are 600 data points and it has been measured that roughly 7% of parents have names that start with the same first initial as their own. If there is no such tendency, what is the expected rate of parent-child first initial matches? Is it as simple as 1 in 26 (letters in the alphabet)? What would be the best way to go about it? Could you use distribution of children's names?",['statistics']
1916644,Does the following condition suffice to imply convergence in distribution?,"We know that convergence in distribution of random variables can be characterized as follows: Suppose $\{X_n\}$ and $X$ are defined on the same probability space. $X_n \stackrel{d}{\longrightarrow} X$ if and only if for any bounded and continuous function $f$, 
$$
\mathbb{E}[f(X_n)] \rightarrow \mathbb{E}[f(X)]
$$ My Question : Suppose that for any bounded continuous function $f$ and any bounded random variable $Y$, we have
$$
\mathbb{E}[f(X_n)Y] \rightarrow \mathbb{E}[f(X)Y]
$$
Then we readily have that for any random variable $Y$, 
$$
\mathbb{E}[f(X_n)g(Y)] \rightarrow \mathbb{E}[f(X)g(Y)]
$$
holds for all bounded continuous functions $f$ and $g$. Following the result, can we conclude that for any random variable $Y$, $(X_n, Y) \stackrel{d}{\longrightarrow} (X,Y)$, that is, for any $\varphi \in C_b(\mathbb{R}^2)$, 
$$
\mathbb{E}[\varphi(X_n, Y)] \rightarrow \mathbb{E}[\varphi(X, Y)]
$$
holds? It seems that if any $\varphi \in C_b(\mathbb{R}^2)$ can be approximated uniformly by product of two functions in $C_b(\mathbb{R})$, we can conclude so. But I am not sure if such topological argument is true.. Any hint will be greatly appreciated!","['probability', 'measure-theory']"
1916672,Showing $\frac{z}{1+z}+\frac{2z^2}{1+z^2}+...+\frac{2^{k}z^{2^k}}{1+z^{2k}}+...=\frac{z}{1-z}$,"Prove that for $\left\lvert z \right\rvert<1$, $\dfrac{z}{1+z}+\dfrac{2z^2}{1+z^2}+...+\dfrac{2^{k}z^{2^k}}{1+z^{2k}}+...=\dfrac{z}{1-z}$. Also, justify any change in the order of summation. This is a exercise from my textbook, but I have no idea. I have shown that: $$\dfrac{z}{1+z}+\dfrac{2z^2}{1+z^2}+...+\dfrac{2^{k}z^{2^k}}{1+z^{2k}}-\dfrac{z}{1-z}= \dfrac{2^{k+1}}{1-\dfrac{1}{z^{2^{k+1}}}}$$ but I do not know how to show $2^{k+1}$
 is growing 'slow enough' in order to make the whole fraction tending zero. The hint from the book is: Use the dyadic expansion of an integer and the fact that $2^{k+1}-1=1+2+2^2+...+2^k$ Could you please give me some more hint? Thank you.","['complex-analysis', 'sequences-and-series']"
1916716,Topology of varieties in a flat family,"I am learning about flat deformations of schemes at the moment. I understand that while it is not immediately clear from the definition why this should be a good definition it turns out that these have many properties that one wants a family of schemes to have. To get the correct picture, I want to ask if my intuition regarding topology is correct: Consider a flat and projective morphism $f: X \to T$ where $T$ is variety over $\mathbb{K}=\mathbb{C}$ or $\mathbb{R}$ and assume that $T(\mathbb{K})$ is connected (in the classical topology). Then my intuition says that things can only change when passing through singular varieties in the family. Here are my concrete questions: Let $X_t$ be smooth for all $t\in T$. Is it true that all $X_t(\mathbb{K})$ are homeomorphic to each other? Let $t_0\in T(\mathbb{K})$ and $Y=X_{t_0}$. Assume that $X_t$ is smooth for every $t\neq t_0$. Let $Y_{sm}$ be the nonsingular locus of $Y$ and assume that the space $Y_{sm}(\mathbb{K})$ is connected. Is it then true that every $X_t(\mathbb{K})$ is connected? (This makes maybe only sense for $\mathbb{K}=\mathbb{R}$.)","['moduli-space', 'algebraic-geometry', 'flatness']"
1916741,Local parameter at infinity on a hyperelliptic curve and poles of differentials,"I'm trying to understand some stuff regarding differentials on a hyperelliptic curveof genus $g$. I'm working with an odd model, $C: \;y^2=f(x)$ over $\mathbb{A}^2_F$, where $F$ is a characteristic $0$ field. I'm looking at the de Rham cohomology $H^1_{DR}(C)$. I get why the basis of this cohomology is given by $$\omega_0 = \dfrac{dx}{y}, \omega_1= x\omega_0,\omega_2= x^2\omega_0,...,\omega_{2g-1}= x^{2g-1}\omega_0 $$ where if projective co-ordiantes are $[X:Y:Z]$ then $x = \dfrac{X}{Z}$, $y= \dfrac{Y}{Z}$. What I am trying to get my head around is the following: At infinity, $x$ has a pole of order $2$ and $y$ has a pole of order $2g+1$. This then means that $\omega_0, \omega_1,...,\omega_{g-1}$ are all holomorphic at infinity, and can be extended to regular differentials on the complete hyperelliptic curve. However, $\omega_g,...,\omega_{2g-1}$ are not holomorphic and have in fact got poles of orders $-2,-4,..,-2g$ at infinity. Therefore, they do not extend to regular differentials at on the complete elliptic curve. I have been trying to understand this, but everywhere I go it seems like it is simply asserted. I've tried to understand the corresponding statement for elliptic curves - i.e. that $\omega=\dfrac{dx}{y}$ and $xw$ are regular and of the second kind respectively, but again it doesn't seem clear to me. If we take, as suggested in other places, the local co-ordainte $t = \dfrac{x^{g}}{y}$ then it would come out pretty quickly, but really this to me is using what we want to show to show exactly that. Needless to say, I'm a bit confused and would appreciate a nudge in the right direction. I guess it has something to do with the fact that we'd want to consider the class of the divisors $(\dfrac{X}{Z}),(\dfrac{Y}{Z})$ coming out of $K(C)$ and then consider the valuation $v_{\infty}$ at these classes, but I'm struggling a bit.","['elliptic-curves', 'differential-forms', 'algebraic-geometry']"
1916751,A mysterious geometric argument regarding mollification in Evans's PDE book,"The following argument is made in Evans's Partial Differential Equations , Chapter 5.3.3: Here are my questions : As I can read from the argument, $\lambda\varepsilon$ would be eventually small enough if $\varepsilon>0$ is small enough. Why on earth would one need $\lambda$ to be sufficiently large? What if we just define 
  $$
x^\varepsilon=x+\varepsilon e_n?
$$ What does ""there is room to mollify within $U$"" mean? How does one know
  $$
v^\varepsilon\in C(\overline{V})?
$$","['multivariable-calculus', 'sobolev-spaces', 'differential-geometry', 'partial-differential-equations']"
1916785,Solution to $y''-\frac{2y'}x+cy=0$ by order reduction,"$$y''-\frac{2y'}x+cy=0$$
I have tried many ways to reduce this form to a first-order equation but they seem to be useless. Can anyone give me a hint? Is there any method that is better than changing to first-order?",['ordinary-differential-equations']
1916791,What's the name of this 2D shape?,"I'm trying to find out the correct name of this shape. Here are a few arranged in a circle: Each of these shapes has four edges: two circular arcs and two straight line radii, making a closed shape. I've been loosely calling this a sector , but I think the consensus is that sectors (also called slice or wedge) have three edges: two full radii as sides and a portion of a circle's circumference as the third edge. It's not a chord, obviously... If there's no obvious name for this, any suggestions for a suitable one? I was thinking track or band , but not sure if these have better names already.","['circles', 'geometry']"
1916793,How do I solve this equation; $x^4+4x-1=0$?,"I know that I can easly solve this with the $4$th degree's equation, but isn't there a smarter way? It is an olympiad's problem so it shouldn't be a formula, but more find a formula... I have remarked that it is equal to $(x^2+1)\cdot(x+1)\cdot(x-1)+4x=0$ It isn't just solving the equation, I want to know if it can be solved otherwise than that... Could someone explain why this is equal to $(x^2+1)^2-(\sqrt{2}(x-1))^2$ please ?","['algebra-precalculus', 'quartics']"
1916803,sequence and $\frac{\phi(n)}{n}$,"Let $f$ be defined by $$f(n) = \frac{\phi(n)}{n}.$$ Then define a sequence $(n_k)$ by $$n_1 = 1, \mbox{and for } k \geq 2,$$
$$n_k = \ \mbox{smallest integer }n\ > n_{k-1} \ \mbox{with}\ f(n) > f(n_k)$$ for any $n < n_k$. Deduce a formula for $n_k$ and $f(n_k)$, with proof. Sol. I try to calaulate some values of the $n_k$ as follows :
$$\begin{array}{c|ccccccccccccccccc}
n & 1 &2&3&4&5&6&7&8&9&10&11&12&13&14&15&16&17 \\ 
\hline
\phi(n) &1&1&2&2&4&2&6&4&6&4&10&4&12&6&8&8&16\\
\hline
f(n)&1&\frac{1}{2}&\frac{2}{3}&\frac{2}{4}&\frac{4}{5}&\frac{2}{6}&\frac{6}{7}&\frac{4}{8}&\frac{6}{9}&\frac{4}{10}&\frac{10}{11}&\frac{4}{12}&\frac{12}{13}&\frac{6}{14}&\frac{8}{15}&\frac{8}{16}&\frac{16}{17}
\end{array}$$ and so $n_1 = 1, n_2 = 2$,and $n_3 = 6$ To see what $n_k$ should be, it requires computations, and I still do not see potential formula. Can anyone please suggest the formula, or a more effective way to analyse this problem ?","['number-theory', 'analytic-number-theory']"
1916819,"Determine the number of towers of the form $\varnothing \subseteq A \subseteq B \subseteq \{1, 2, 3, \ldots, n\}$","Determine the number of towers of the form  $\varnothing \subseteq  A \subseteq B \subseteq \{1, 2, 3, \ldots, n\}$. It is an exercise problem in Richard's Introductory combinatorics. My thought : There are $n$ Choose $k$ (length) subsets of $B$. Then, there are $2^k$ subsets $A$ of $B$. Thus, the total number of subsets is $\sum_k\binom{n}k\cdot 2^k$. Is this correct idea? Note that: there is no meaning to the word ""towers"" other than what is given: subsets empty contained in $A$ contained in $B$ contained in $\{1,2,\ldots,n\}$.","['combinatorics', 'statistics', 'probability']"
1916929,Understanding why $\det(A) = \det(A^T)$ via the 3D Paralleliped,"I am trying to understand why, geometrically, we have that $$
\det(A) = \det(A^T).
$$ To build intuition, I am thinking in 3 dimensions . So let $A$ be a $3 \times 3$ matrix of real numbers. First, I know that if $$
\det(A) = \left|
\begin{array}
xx_1 & y_1 & z_1 \\
x_2 & y_2 & z_2 \\
x_3 & y_3 & z_3
\end{array}
\right|
$$ then $|\det(A)|$ can be thought of as the area of a parallelepiped formed by $(x_1, x_2, x_3)$, $(y_1, y_2, y_3)$, and $(z_1, z_2, z_3)$. Moreover, the fact that $\det(A) = \det(A^T)$ implies that $|\det(A)|$ can also be thought of as the area of the parallelepiped formed by $(x_1, y_1, z_1)$, $(x_2, y_2, z_2)$, and $(x_3, y_3, z_3)$. Question: Does this also mean that the area of a parallelepiped formed by any permutation of the $x_i$, $y_i$, and $z_i$ is equal to $|\det(A)|$? For example, does the area of a parallelepiped formed by the coordinates $(x_1, y_2, z_3)$, $(x_2, y_1, z_2)$, and $(x_3, y_3, z_1)$  equal $|\det(A)$|?","['transpose', 'determinant', 'linear-algebra', 'geometry']"
1916960,Covering a set $A \subset \Bbb R$ by two families of disjoint intervals taken from given intervals,"Let $A \subset \Bbb R$ be a bounded set. Every element $a \in A$ is the center of some given open interval, let's denote it by $I_a=(a-r_a, a+r_a)$. I'm interested in knowing the following: Can we always color some of the given intervals $I_a$ in red and some others in blue such that intervals of the same color are disjoint, and the colored intervals together contain all of $A$? I know that there is some constant number of colors that suffices for all possible $A$ and $I_a$, and this holds even in higher dimensions for different constants; this is Besicovitch's covering theorem . Thus we can rephrase the question as: what is the optimal constant for Besicovitch's covering theorem in $\Bbb R$? Note that $A$ is not necessarily closed, so it seems we cannot choose some ""extremal"" values such as largest intervals to construct a greedy approach to coloring. A now-deleted answer linked to this post containing a proof. However, I don't understand the proof at all. So it suffices if someone would write it in a way that is easier to comprehend.","['general-topology', 'real-analysis']"
1917002,For which degrees is being smooth equivalent to being irreducible?,"To the best of my knowledge, an algebraic curve of degree $2$ is smooth if and only if it is irreducible. In other words, the only smooth conic sections are the non-degenerate ones. Does this hold for any higher degree algebraic curves? I know that being reducible implies that the curve is not smooth, which is the contrapositive of smooth implying irreducible. This should follow from the product/Leibniz rule of differentiation, because if an algebraic curve equals $p(x_1,\dots,x_n)q(x_1,\dots,x_n)$, then all of its partial derivatives are of the form $\frac{\partial}{\partial x_i}p(x)q(x_1,\dots,x_n) +p(x_1,\dots,x_n) \frac{\partial}{\partial x_i}q(x)$, and thus the curve will have a singular point at every point of intersection of the zero sets of $p$ and $q$, which by Bezout's theorem should be non-empty at least in projective space. (Here I am using the definition of smooth as having no singular points at all, singular points being where the gradient vanishes and thus we can not define a tangent line.) So I guess my question reduces to: Does an algebraic curve being irreducible imply that it is smooth?",['algebraic-geometry']
1917044,"Proving the converse of an IMO problem: are there infinitely many pairs of positive integers (m,n) such that m divides n^2 + 1 and n divides m^2 + 1?","This problem is taken from the movie X+Y ( A Brilliant Young Mind in the US). Apparently, it is a real problem from a British IMO qualifying exam: Are there infinitely pairs of positive integers $(m,n)$ such that $m$ divides $n^2 + 1$ and $n$ divides $m^2 + 1$? The answer is yes, with infinitely many solutions coming from alternating Fibonacci numbers: Let $F_0 = 1$. Then $(F_{2n}, F_{2n+2})$ form a solution pair. Besides the trivial solution $(1,1)$, all other solutions appear to be a pair of Fibonacci numbers of the above form. So I have been trying to prove this: The only pairs of positive integers $(m,n)$ that satisfy $m|n^2+1$ and $n|m^2+1$ are $(1,1)$ and $(F_{2n}, F_{2n+2})$ for nonnegative $n$ where $F_{n}$ denotes the $nth$ Fibonacci number beginning with $F_0=1$. Little success so far. Can anyone point me in the right direction? All I have so far is in suspecting that Vieta jumping might come in handy.","['recurrence-relations', 'fibonacci-numbers', 'divisibility', 'number-theory', 'contest-math']"
1917057,Are the real Grassmannians simple spaces?,The real Grassmannians are not simply connected. My question is whether they are simple in the sense that their fundamental group acts trivially on the higher homotopy groups. Thank you.,"['algebraic-topology', 'homotopy-theory', 'geometry']"
1917065,"Function whose image of every open interval is $(-\infty,\infty)$ [duplicate]",This question already has answers here : Is there a function $f\colon\mathbb{R}\to\mathbb{R}$ such that every non-empty open interval is mapped onto $\mathbb{R}$? (5 answers) Closed 7 years ago . How to find a function from reals to reals such that the image of every open interval is the whole of R? Is there one which maps rationals to rationals?,"['real-analysis', 'examples-counterexamples']"
1917120,Are proofs by contradiction and counterexample two different techniques?,"New to proofs. Suppose I want to prove $f: \mathbb Z \to \mathbb Z$ as $f(n) = 2n$ for all $n$ is not onto. Are the two arguments below valid, separate proofs? Are they invalid iterations of a single proof? By contradiction: Suppose $f$ is onto. Then for all $m \in \mathbb Z$, there's some $k \in \mathbb Z$ such that $f(k) = 2k = m$ which implies $k = \frac m2.$ Then $k \not \in \mathbb Z$ for all $m \in \mathbb Z.$ Contradiction. By counter-example: $1$ has no pre-image in $\mathbb Z$.",['discrete-mathematics']
1917179,I - T not isomorphism in non-Banach normed spaces,"So I know that if $T : X \to X$ is a bounded operator with $X$ a Banach space and that $\|T\| < 1$, then $I - T$ is an isomorphism. Is this true in general normed spaces?","['functional-analysis', 'normed-spaces', 'banach-spaces', 'operator-theory']"
1917181,Intricate Markov Bayesian Theorem Probability Problem.,"Their exist a fraudulent gambling den that uses $2$ kinds of dices. A fair dice which has a $\frac16$ probability of rolling any number, their also exist a loaded dice that has $0.5$ possibility to roll a $6$ and $0.1$ possibility to roll any other number. The possibility that the fraudulent gambling den switches from the fair to loaded dice is $0.01$ and the probability of switching back from loaded to fair is $0.2$. Sequentially record dice by $q_{1},q_{2},q_{3}...,$ and numbers rolled by $o_{1},o_{2},o_{3}..$ for example $:q_{1}= F, o_{1}=2$ means the first die is Fair and by rolling the first die the number is observed is $2$, moreover $p(q_{1}=F)=P(q_{1}=L)=0.5.$ Derive the following possibility that : $P(o_{100}=4|q_{99}=F), P(q_{3}=L|o_{1}=1,o_{2}=3),$ $P(o_{100}=4 ,q_{99}=L| q_{98}=F), P(o_{15}=3,o_{16}=6|q_{14}=F), P(o_{1}=4,o_{2}=2,q_{2}=F), $ $P(o_{1}=4,o_{2}=2,o_{3}=4,q_{3}=F)$ One must use the theorem $$P(A_i | B) = \frac{P(B|A_i) * p(A_i)}{P(B)}$$ I must assume that $P(B|A) = 0.016666$ and $p(A_i) = 0.5$ $p(B) = 0.1$ Then $$P(A_i | B) =\frac{0.016666 * 0.5}{0.1} = 0.08$$ My question for this problem is there any steps that I may be missing. I feel that their must be a second step in this problem. Also the Markov chain must play in important part in solving this enigma.","['markov-chains', 'statistics', 'probability']"
1917187,Volume of a vector field embedded in 4D,"Given a surface in 4D, $\bigl(s, t, u(s, t), v(s, t)\bigr)$, if we define vectors between each point $(s, t, 0, 0)$ in some region of the $(s, t)$-plane, and a corresponding point $\bigl(s, t, u(s, t), v(s, t)\bigr)$, it seems that these vectors would define a 3D volume in 4D space, assuming $u(s, t)$ and $v(s, t)$ are continuous and differentiable. Assuming that is in fact true, how would one calculate the volume? I don't have a specific application in mind, just a question that occurred to me musing about higher dimensional functions and space. I appreciate any insight. I'm an engineer, not a mathematician, so the terminology of modern mathematics will lose me quickly, although I have some very minimal exposure to the terminology of fiber bundles. Thanks in advance","['multivariable-calculus', 'integration', 'calculus']"
1917219,About integral involving power factors.,"Maybe this integral is easy...but so far I have not been able to solve it: \begin{equation}
\int_0^\infty y^{-b} (y+a)^{1-b} \, dy
\end{equation} where $b$ is a positive constant. I've tried to use subtitution. Re-writing \begin{equation}
y^{-b} (y+a)^{1-b} = \frac{y+a}{(y^2+ay)^b}
\end{equation}
By doing $y^2+ay = u^{1/b}$...I almost got it...but it failed at the end. Note that: \begin{equation}
2y \, dy + a \, dy = \frac{1}{b}u^{\frac{1-b}{b}} \, du
\end{equation} Any help is appreciated...thanks","['integration', 'calculus']"
1917250,Show that a closed convex ball implies the triangle inequality,"I am given a function $\|\cdot\|: \Bbb R^2 \rightarrow \Bbb R$ that satisfies all the conditions of a norm except the triangle inequality. And let: $$ B = \{\mathbf v \in \Bbb R^2 \mid \|\mathbf v\| \leq 1 \}$$ I am asked to show that if $B$ is convex, namely if $\mathbf{v},\mathbf{w} \in B, \: t\mathbf v + \left(1-t\right)\mathbf w \in B \:\:\: \forall t \in \left[0,1\right]$, then $\|\cdot\| $ satisfies the triangle inequality. I have thought that maybe I can prove this by contradiction, assuming that there exists some pair of vectors that do not satisfy the triangle inequality under this function. However, I need to prove the result that: $$ \|\mathbf v + \mathbf w\| > \|\mathbf v\| + \|\mathbf w\| \Rightarrow \|l\mathbf v + k\mathbf w\| > |l| \|\mathbf v\| + |k|\|\mathbf w \| \:\: \forall l,k \in \Bbb R$$ And I cannot seem to do this. If this result is true than I can consider the unit versions of the vectors and show that convexity forces the triangle inequality and thus, a contradiction. However, I cannot prove this result. Would my approach work? Is there perhaps a shorter, more concise and neater approach that would achieve the desired proof? Any advice and help you may be able to offer would be greatly appreciated!","['general-topology', 'metric-spaces']"
1917262,"What is the domain of a set operation (e.g., union and intersection)?","My understanding: The set operations (such as union and intersection) are operations and so functions with a domain and codomain. A function's domain and codomain are always sets. The input to a set operation is either a set or a tuple of sets. My thoughts: My thoughts about what the domain of a set operation would be (based on the above understanding) has brought me to ""the set of all sets"". This is clearly wrong. My Question: What is in fact the domain of a set operation? Am I to instead understand the domain of such an operation to be a class? This would cause me to revise my current understanding of a function to allow the domain and codomain to be classes. Thanks.","['binary-operations', 'elementary-set-theory']"
1917280,Model Selection property between AIC and Mallow's $C_p$,"Let us consider a set of linear models defined by the function
$Y_i = \beta X_i + \epsilon_i, \epsilon_i \sim N(0,\sigma^2).$
Take a model $S$, and define the training error of a given model as
$\hat{R}_\text{tr}(S) = \sum_{i=1}^n (\hat{Y}_i(S) - Y_i)^2.$
We define Mallow's $C_p$ statistic as
$$\hat{R}(S) = \hat{R}_\text{tr}(S) + 2|S|\hat{\sigma}^2,$$ where $|S|$ denotes the number of terms in the model $S$ and $\hat{\sigma}^2$
is the estimate of $\sigma^2$ obtained for the full model.
Consider the AIC function of a model to be $AIC(S) = l_S - |S|,$
where $l_S$  is the log-likelihood of the model evaluated at the MLE. I would like to show that, given $\sigma$ as known, that
$\arg\max_S AIC(S) = \arg\min_S \hat{R}(S).$
I was having some trouble showing this statement using general unconstrained
optimization, in particular because I am not entirely sure how to handle
the derivative of the function for Mallow's $C_p$ given that we have $|S|$ in
the second term of that function. Is there a better way to show this particular
statement?",['statistics']
1917292,Proving a matrix rank equality,"In my studies of the Schur complement within matrix theory I have come across this problem which seems tough: Let us consider the block matrix $ A = \left( \begin{array}{ccc}
B & C \\
D & E \end{array} \right)  $ where $ E $ is an invertible principal square submatrix of $ A $ and we are asked to prove the following equality of ranks
  $\operatorname{rank}\left( \begin{array}{ccc}
CE^{-1}D & C \\
D & E \end{array} \right) = \operatorname{rank}(E) $ using the Schur complement I have thought about using the identity $\operatorname{rank}(A)=\operatorname{rank}(E)+\operatorname{rank}(A/E) $ and then using the definition of the Schur complement in this case $ A/E = B-CE^{-1}D $ but I have no idea how to show equality of ranks in this case. I appreciate all help.","['block-matrices', 'matrices', 'schur-complement', 'matrix-rank', 'linear-algebra']"
1917296,Are conic sections equivalent in the REAL projective plane?,"To transform between the unit ellipse (circle) $x^2 + y^2 =1$ and the unit hyperbola $x^2 - y^2=1$ , we can use the simple change of coordinates $y_1 = iy_2$ in the complex projective plane. However, this change of coordinates is obviously not available in the real projective plane, so it is no longer obvious to me whether hyperbolas and ellipses are equivalent in the real projective plane. Questions: 1. What is the definition of a projective change of coordinates in $\mathbb{RP}^2$ ? Is it the same as the definition for $\mathbb{CP}^2$ but with all real coefficients? 2. Are all non-degenerate conic sections (i.e. ellipses, hyperbolas, and parabolas), still equivalent in $\mathbb{RP}^2$ , the same way they are equivalent in $\mathbb{CP}^2$ ? My Research So Far: This video on YouTube certainly seems to suggest that ellipses and hyperbolas are equivalent in the real projective plane. https://www.youtube.com/watch?v=lDqmaPEjJpk Likewise, this webpage seems to say that all non-degenerate conics are projectively equivalent in the real projective plane. However, they say that, given an old conic section $Q$ , a new conic section $Q'$ , and an invertible linear transformation, that $Q'=Q\circ M$ or $Q'= -Q \circ M$ . Why can't we just say that $-Q \circ M = Q \circ (-M)$ and note that $-M$ is also an invertible linear transformation? Do we have to use a different definition besides ""invertible linear transformation of the homogeneous coordinates"" for projective changes of coordinates in the real projective plane? The fact that sign issues are relevant seems encouraging at least since it seems connected to the problem of transforming hyperbolas into and from ellipses using real coefficients mentioned at the beginning. http://www.math.poly.edu/courses/projective_geometry/chapter_five/node4.html The answer to this question What shape do we get when we shear an ellipse? And more generally, do affine transformations always map conic sections to conic sections? seems related to my confusion, because it states that ""Since the sign of the discriminant $B^2-4AC = -4\det M$ determines the type of conic section, and the transformation $\det M \to (\det T)^2\det M$ preserves the sign, all linear and affine transformations of the plane map conics to conics of the same type (ellipses to ellipses, parabolas to parabolas, and hyperbolas to hyperbolas)"" where $T$ is the transformation matrix, and $M$ is the matrix of coefficients, which is admittedly confusing given that above $M$ was the transformation matrix (not the coefficient matrix) and $Q$ was the matrix of coefficients of the quadratic form corresponding to the conic section. So it seems like whether or not all conic sections are equivalent in the real projective plane comes down to what definition of ""projective change of coordinates we use"", because using the direct analog of the complex projective definition seems to make the statement fail  to be true.","['projective-geometry', 'algebraic-geometry']"
