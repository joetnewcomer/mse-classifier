question_id,title,body,tags
962471,"Do we have to claim it? If so, at which point?","I have to solve the recurrence relation $$T(n)=\left\{\begin{matrix}
3T\left (\frac{n}{4} \right)+n & , n>1\\ 
1 &, n=1 
\end{matrix}\right.$$ and prove by induction that the solution I found is right. I found that the solution of the recurrence relation is $T(n)=O(n)$. I started proving it like that: $n=1: T(1)=1 \leq c \cdot 1 \checkmark \text{ for } c \geq 1$ We suppose that for any $m$, $2 \leq m <n , n>2$: $T(m) \leq c \cdot m$. We want to show that the claim stands for $n$. But, then I noticed that we do not have a formula for $T \left ( \frac{n}{4} \right)$ when $n<4$ and also when $n \neq 4^k$. So, do we have to suppose that $n \geq 4$ and $n=4^k$ ? If so, at which point of the proof, do I have to claim it?","['induction', 'recurrence-relations', 'discrete-mathematics']"
962480,Tricky integration/functions problem,"For $x>0$, let $f(x) = \displaystyle \int_1^x\frac{\ln t}{1+t}dt$. Find the function $f(x) + f(1/x)$ and show that $f(e) + f(1/e) = 1/2$. Any help would be thoroughly appreciated.",['integration']
962500,how to prove that $k+1 \ge (1+\frac{1}{k})^{k}$?,"How to prove that
$$k+1\ge \bigg(1+\frac{1}{k}\bigg)^{k}
$$    when $k>2$",['analysis']
962501,"Showing that $(1-u)z^2\leq P(uz\leq |X|)$ when $0<u<1, E(X^2)=1, $ and $0<z<E(|X|)$.","I am trying to show that $$(1-u)z^2\leq P(uz\leq |X|)$$ where $0<u<1, E(X^2)=1, $
   and $0<z<E(|X|)$. I've been given a hint to consider Cauchy-Schwarz, however, I don't see where this could apply.  I have been thinking maybe I could combine it with Markov's or Chebyshev's inequalities, to turn the condition on $E(X^2)$ into a condition on the probability $P(uz\leq |X|)$, but I don't see how to do it. Could I get a further hint, please?","['probability-theory', 'inequality', 'probability', 'random-variables']"
962504,Can -9 to 9 be placed in 41 lines of zero?,"The cubic curve $2x^3-4x^2y+2xy^2-8x+y^3-y$ can be used to get lattice points allowing the placement of the numbers $-8$ to $8$ so that all 32 triplets that sum to 0 will be a straight line of three. Some other nice curves are at ""Elliptic Curves on a Small Lattice"" Is there such a diagram for -9 to 9? EDIT -- Lines through 1-8, 2-7, 3-6, 4-5 turn out to be concurrent. So it turns out to be easy to add 9 and -9.  Similarly, -10/10 and -11/11 can be added. -12/12 also seems concurrent, but it's a far off point. Points for -13/13, -14/14, and -15/15 are also on concurrent lines. So I give a solution, that seemingly extends to infinity, but I don't have an explanation. Is there a less crowded diagram for -14 to 14?  Are these easy to make by some method? Can more digits be added to infinity with all triples concurrent? EDIT 2: 
$(x,y)$ positions for 0 to 17 are as follows, with the third item being the denominator: $(0,0,1), (1,-3,1), (0,-1,1), (1,-1,1), (-1,-2,1), (3,1,1), (-4,-3,1),$ $(3,3,1), (-2,0,1), (3,11,7), (-4,7,5), (-1,13,19), (-3,10,1), (1,-9,23),$ $(24,-57,31), (-11,-87,67), (84,-32,59), (-143,-187,73)$ For -1 to -17, take the negative. Is there an easy way to get these values from the original curve?","['cubics', 'recreational-mathematics', 'combinatorics']"
962507,What is the flaw in both of my approaches to this limit?,"I have been solving a 3D limit problem: $$\lim_{(x,y) \to (0,0)} \frac{x^2+y^2}{\sqrt{x^2+y^2+1}-1}$$which apparently, is $2$.  However, I cannot find the flaw in my approach.  Here it goes:
$$\mathrm{Let \space y=mx} \\\lim_{(x,y) \to (0,0)} \frac{x^2+m^2x^2}{\sqrt{x^2+m^2x^2+1}-1}= \lim_{(x,y) \to (0,0)} \frac{x^2(1+m^2)}{\sqrt{2x^2+1}-1}=\frac{0}{0} \\ \mathrm{Apply \space L'HÃ´pital's \space rule}\\ \lim_{(x,y) \to (0,0)}\frac{2x(1+m^2)}{(\frac{2x}{\sqrt{2x^2+1}})}$$
I've solved this two different ways and I keep getting the answer as $(1+m^2)$.  The Student Solutions Manual , alas, says the answer it $2$.  Just in case my mistake lies somewhere after this step, even though I got the same answer solving it two different ways after this point I'll give you one of my methods, the shorter of the two:
$$...\space=\lim_{(x,y) \to (0,0)} \frac{2x(1+m^2)\sqrt{2x^2+1}}{2x}=\lim_{(x,y) \to (0,0)}\frac{(1+m^2)\sqrt{2x^2+1}}{1}=(1+m^2)$$
No idea how to get to $2$ here.  Also, am I abusing notation by leaving the bounds of the limits in terms of $(x,y)$ rather than reducing it to $x$ when I have let $y$ be equal to some terms of $x$?",['limits']
962568,Single $\Delta$-complex structure on $S^3$,Is it possible to identify pairs of faces of $\Delta^3$ to produce a $\Delta$-complex structure on $S^3$ having a single simplex? I'm thinking to identify left with right and behind with bottom. But I cannot visualize what I can obtain and how can I make sure I get $S^3$?,"['general-topology', 'algebraic-topology']"
962579,Derivative of matrix inversion function?,Let's say I have a function $f$ which maps any invertible $n\times n$ matrix to its inverse. How do I calculate the derivative of this function?,['analysis']
962603,Can a double-factorial be a perfect square?,"The title says it, basically. My question is $-$ for $ n \ge 2 $, can  $n!!$ be a perfect square, where $!!$ represents the double-factorial ? My conjecture is no, but I can't seem to be able to find a good proof for this.","['factorial', 'number-theory']"
962625,$2$-element subsets of $n$ elements?,"the question is as follows: Give a recursive definition for the number of $2$-element subsets of $n$ elements. We started working this out in class and here is where we got too: -if  $n = 0$, then we are looking for the $2$-element subsets of $0$ elements. There are none. So $f(0) = 0.$ -If  $ n > 0$, then our set looks like $S $= {$s_1, s_2, ..., s_n$}. Let's look at all of the $2$-element subsets of $S$. Some of them will include $s_n$. These sets look like {$x, s_n$}, where x is one of the elements {$s_1, s_2, ..., s_{n-1}$}. As we have $n-1$ choices for the element $x$, we have $n+1$ 2-element subsets that contain sn. Others will not include sn. But if they don't, then we are looking for the $2$-element subsets of  {$s_1, s_2, ..., s_{n-1}$}, and we know that there are $f(n-1)$ of these. I know the recursive definition is: $f(0) = 0$ $f(n) = f(n-1)+n-1$ But I don't really understand what a 2 element subset is. Can someone give me an example of this/more insight into this problem? What are we really trying to show here? Also why isn't $f(1)$ equal to $0$ as $f(0) = 0$ since both of them are less than $2$?","['recurrence-relations', 'discrete-mathematics', 'elementary-set-theory']"
962636,Prove Existence of a Circle,"There are two circles with radius $1$, $c_{A}$ and ${c}_{B}$. They intersect at two points $U$ and $V$. $A$ and $B$ are two regular $n$-gons such that $n >  3$, which are inscribed into $c_{A}$ and ${c}_{B}$ so that $U$ and $V$ are vertices of $A$ and $B$. Then suppose a third circle, $c$, with a radius of $1$ is to be placed so that it intersects $A$ at two of its vertices $W$ and $X$ and intersects $B$ at two of its vertices $Y$ and $Z$. Details and Assumptions: Assume that $U,V,W,X,Y,Z$ are all distinct points. $U$ lies outside of $c$. $V$ lies inside of $c$. Given all of these details, prove that there exists a regular $2n$-gon which comprises of $W,X,Y,Z$ as its 4 vertices.","['geometry', 'discrete-geometry']"
962657,Show $\int_0^{\infty} \frac{e^{-x}-e^{-xw}}{x} dx = \ln{w}$ for $\operatorname{Re}({w})>0$,"I want to show that for $\operatorname{Re}({w})>0$, $$\int_0^{\infty} \frac{e^{-x}-e^{-xw}}{x} dx = \ln{w}.$$ I've tried setting the problem up as: $$\int_\gamma \frac{e^{-z}}{z} dz = 0,$$ where $\gamma$ is the path around the quadrilateral with vertices $a,b,bw,aw$ for some $a,b \in \mathbb{R}$ where $0<a<b<\infty$, but I'm not sure if I am parametrizing the paths between these points correctly.","['complex-integration', 'complex-analysis']"
962661,Numbers Made From Concatenating Prime Factorizations,"I came across the following curious problem while playing around with my calculator. Take any positive integer $n$; for this example we'll use $216$. Create a sequence as follows: Factor $n$ into its prime factors, listing smaller factors first and expanding exponents; $216=2\times2\times2\times3\times3\times3$ Create the next number by concatenating the first $d$ digits of its prime factors, where $d$ is the number of digits in $n$; $2\times2\times2\times3\times3\times3\to222$ Repeat until...? $222\to2\times3\times37\to233\to233\to\cdots$ The first thing that is easy to show is that you will always be able to create a $d$-digit number at any step. The sequence obviously stops once it hits a prime number. But can it stop for any other reason? It turns out that the first number whose sequence does not end in a prime number is $333$, a composite which miraculously generates itself: $333=3\times3\times37\to333$. A quick computer program found several other numbers that exhibit this property: $2255\to5114\to2255\to\cdots$ a loop! $22222\to24127\to23104\to22222\to\cdots$ a longer loop! $22564\to22564\to\cdots$ $31111\to53587\to41130\to23354\to21167\to61347\to31111\to\cdots$ !!! $210526\to210526\to\cdots$ $252310\to252310\to\cdots$ $1143241\to1143241\to\cdots$ $3331233\to3331233\to\cdots$ $3710027\to3710027\to\cdots$ Update: up to 150 million, I found $219371601\to367109140\to225183554\to219371601\to\cdots$ I'll call these numbers, whose sequence does not end in a prime, self-factoring numbers. As far I've tested, these are all the self-factoring numbers below forty million. This topic may have no depth to explore (it may just be a fun mathematical coincidence), but I would still like to pose the following questions: Are these self-factoring numbers related in any way? Can we prove any property about these numbers at all? Is there any property that might help speed up a computer search past the brute force approach? Are there infinitely many such self-factoring numbers? Could there be a constructive proof?","['prime-factorization', 'soft-question', 'number-theory']"
962663,"Why is $\frac{d^n}{dx^n}(y(x))$ the notation for the $n$th derivative of $y(x)$, instead of $\frac{d^n}{d^nx}(y(x))$?",I've always wondered why the numerator is $d^n$ while the denominator is $dx^n$ instead of $d^nx$ like the numerator. I must be missing something very obvious or fundamental. Is this notation derived from the chain rule in some way?,"['calculus', 'notation', 'partial-derivative', 'differential', 'derivatives']"
962707,"How do I solve the limit $\lim_{(x,y)\to(0,0)} \frac{1-\cos(x^2+y^2)}{x^2y^2(x^2+y^2)}$?","I've just started solving 2-variable limits and I'm stuck at one of the examples: $$\lim_{(x,y)\to(0,0)} \frac{1-\cos(x^2+y^2)}{x^2y^2(x^2+y^2)}$$ How do I approach limits like that? I've been thinking on it for quite a long time and I don't know what could I possibly do. Intuition (which may be wrong) tells me that this limit exists and is equal to $0$ because of the nominator, but as I said - I don't seem to find any way to solve it.","['multivariable-calculus', 'limits']"
962771,Question about $\lim_{x\to \infty}\frac{\cos(3x)}{e^{8x}}$,"$\lim_{x\to \infty}\dfrac{\cos(3x)}{e^{8x}}$ The answer is $0$. Why is the answer $0$? The top oscillates between $-1$  and $1$ and the bottom becomes huge, but since the top is oscillating, shouldn't the answer be DNE (does not exist)?","['calculus', 'infinity', 'limits']"
962830,Book Request: Taylor's Theorem for functions $f: \Bbb R^n \to \Bbb R^m$,"I'm looking for a resource (e.g. a book, website, or arxiv paper) that goes over the general case of Taylor's theorem, with a full proof and examples.  Do you guys know of any material that covers this.","['multivariable-calculus', 'reference-request', 'taylor-expansion']"
962832,What allows us to break up $dy/dx$ in solving a separable differential equation?,"Suppose you had a separable first order differential equation that can be written as
$$
\frac{dy}{dx}=f(x,y)=g(x)h(y)
$$ Rigourously, what allows us to rearrange this as
$$
\frac{1}{h(y)}dy=g(x)dx?
$$ I'm familiar with differential geometry, and differential $k$-forms, but is there a rigourous explanation of why treating the derivative as a fraction ends up working?",['ordinary-differential-equations']
962849,Set of sequences which converge to zero is a closed subspace of $l^\infty$,Prove that: $$c_0 = \{\{a_n\}_1^\infty:lim_{n\to\infty}a_n = 0\}$$ Is a closed subspace of $l^\infty$.,"['functional-analysis', 'lp-spaces']"
962863,cardinality of maximum antichains in power set posets,Let $\mathcal{P}(S)$ be the power set of a non empty set $S$. Consider the poset $\succ$ for the inclusion relation over the elements of $\mathcal{P}(S)$ (which is equivalently represented by a single source single sink DAG). is there a known result for the cardinality of maximal antichain of $\succ$ ?,"['graph-theory', 'lattice-orders', 'discrete-mathematics', 'order-theory']"
962898,On a Proof that the Splitting Field of a Separable Polynomial is Galois,"Prop.: If $f \in F[x]$ is separable, then the splitting field of $f$ over $F$ is a Galois extension of $F$. Proof: By induction over $[E:F]$, where $E$ is the splitting field. By previous results concerning finite extensions, we know it suffices to show that $[E:F] = |\text{Aut}(E/F)|$. If $[E:F]=1$ there is nothing to do. If $[E:F]>1$, then we can write $f=pq$ where $p,q \in F[x]$, $p$ irreducible and $\deg p>1$. Since $f$ is separable, $p$ is separable. Write
$$
p(x) := \prod_{i=1}^n (X-\alpha_i),
$$
where $\alpha_i \in E$ are different. Let $E_i := F(\alpha_i)$. Then $E$ is the splitting field of $f/(x-\alpha_1) \in E_1[x]$. Since $m := [E:E_1]<[E:F]$, the induction hypothesis tells us there are $m$ elements in $\text{Aut}(E/E_1)$, let's say $\text{Aut}(E/E_1) = \{\tau_1, \ldots, \tau_m\}$. There are also $n$ isomorphisms
\begin{align}
\sigma_i : E_1 &\to E_i \\
\alpha_1 &\mapsto \alpha_i.
\end{align}
Each combination $(\tau_j, \sigma_i)$ gives an element in $\text{Aut}(E/F)$. Hence there are $mn$ elements in $\text{Aut}(E/F)$. But $mn=[E:E_1][E_1:F]=[E:F]$. $\blacksquare$ Questions: Does $\alpha_i \in E\backslash F$ for all $i$? In fact, this is used to deduce $[E:E_1]<[E:F]$? I think the answer to both is yes and that $\alpha_i \not\in F$ follows from the irreducibility of $p$ over $F$ and from the fact that $e \in E\backslash F$ & $f\in F$ $\implies$ $ef \in E\backslash F$. To apply the induction hypothesis, we note that $E$ is the splitting field of $f/(x-\alpha_1) \in E_1[x]$. But is it not true that we have more simply that $E$ is the splitting field of $f \in E_1[x]$? When we say that each combination $(\tau_j, \sigma_i)$ gives an element in $\text{Aut}(E/F)$, what are those elements? I think it must be some compositions, but the domains and codomains of $\tau_j$ and $\sigma_i$ don't quite match...? Also why are those $mn$ elements different?","['galois-theory', 'splitting-field', 'abstract-algebra', 'field-theory']"
962914,Negative determinant,"Let
$$
A = \begin{bmatrix}
-a_{12}-a_{13}-a_{14} & a_{12} & a_{13} & 1\\
a_{21} & -a_{21}-a_{23}-a_{24} & a_{23} & 1\\
a_{31} & a_{32} & -a_{31} - a_{32} - a_{34} & 1\\
a_{41} & a_{42} & a_{43} & 1
\end{bmatrix},
$$
where all $a_{ij}$'s are positive reals. If we explicitly calculate the determinant of $A$ and factor whole expression, then we can easily see that $\det(A) < 0$. Is it possible to prove that $\det(A) < 0$ (or that $\det(A) \neq 0$ if it is easier) using some matrix manipulations without calculating it directly?","['matrices', 'determinant']"
962956,Prove that a non-abelian group of order $pq$ ($p<q$) has a nonnormal subgroup of index $q$,"So I've come up with a proof for the following question, and I'd like to know if it's correct (as I couldn't find anything online along the lines of what I did). Question Let $p$ and $q$ be primes with $p<q$.  Prove that a non-abelian group of order $pq$ has a nonnormal subgroup of index $q$, so there there eixists and injective homomorphism into $S_q$ First I prove a Lemma : If $H\triangleleft G$, then for every conjugacy class $\mathcal{K} \subseteq H$ or $\mathcal{K} \cap H = \emptyset$. proof : If $x\in K\cap H$, then $gxg^{-1} \in gHg^{-1}$ for all $g\in G$.  Since $H$ is normal $gHg^{-1}=H$, so that $H$ contains all the conjugates of $x$,i.e., $\mathcal{K} \subseteq H$ (Dummit and Foot, 4ed, pg 127). Here's my attempt on the question: proof : Let $G$ be a group such that $|G|=pq$ and $p<q$. Then $G \cong \mathbb{Z}_{pq}$, and so $G$ has two subgroups, say $H$ and $K$, of orders $p$ and $q$, respectively .  'Suppose that $H$ is a subgroup in $G$ of order $p$; a subgroup $K$ of order $q$ exists in $G$ by Cauchy (Nicky Hekster).'  Also, by Lagrange, $H=\langle x \rangle$ and $K=\langle y \rangle$ for some $y,x \in G$.  Since $p$ is the smallest prime that divides the order of $G$ and $|G:K|=p$, then $K\triangleleft G$ (by some theorem). Suppose, by contradiction, that $H\triangleleft G$.  Then for $x^i \in H$, $gx^ig^{-1}=x^k \in H$ for all $g\in G$.  So $H\subseteq \mathcal{O}_{x^i}$ (the conjugacy class of $x_i$).  Since $|x^i|$ divides $p$, then $x_i\not \in K$.  Thus $\mathcal{O}_{x_i} \not \subseteq K$.  Also, since $e=x^p$ and $gx^pg^{-1}=e$, then $e\in \mathcal{O}_{x_i}$.  Thus $\mathcal{O}_{x_i} \cap K \neq \emptyset$.  Therefore $K$ is not normal in $G$, which is absurd. Now let $\phi: G \rightarrow S_q$ be the permutations representation afforded by the action of $G$ on $A=G/H$ by left multiplication -- say $\pi_g:A\rightarrow A$ defined by $aH\mapsto gaH$ for all $g\in G, \; aH\in A$.  We know that $\ker \pi_g \leq H$ and $\ker \pi_g \triangleleft G$.  Since $|H|=p$, then $|\ker \pi_g|=p$ or $|\ker \pi_g|=1$.  If $|\ker \pi_g|=p$, then $\ker \pi_g$ is not normal in $G$.  Therefore, $|\ker \pi_g|=1$.  Since $\ker \pi_g=\ker \phi$, then $\phi$ must be injective. Sorry for any typos (and a HUGE 'thank you' to anyone who actually reads this).","['abstract-algebra', 'sylow-theory', 'finite-groups', 'proof-verification', 'group-actions']"
962958,100 sequential parking spaces,"In my high school's math club today, we explored but did not solve this interesting problem: 100 autonomous robotic vehicles enter a warehouse in arbitrary order to park. Inside the  warehouse, there are 100 sequential parking spaces enumerated from 1 to 100. Each vehicle has an assigned number where it will attempt to park. However, there is an error in the programming such that if a vehicle finds its path to the assigned parking spot blocked by an already-parked robot, the robot will immediately park in the spot before it. For example, if vehicle 50 parks in spot 50 but vehicle 75 is immediately behind it, vehicle 75 will park in spot 49. Also, if vehicle 1 parks in spot 1, every robot behind it will be blocked from entering the warehouse at all. The vehicles do not have the ability to maneuver around already-parked vehicles. What is the most likely number of robots that will be parked in the warehouse at the end of the routine? So far the group came up with just some underlying intuition that the most likely number should be fewer than 50, as it is likely that some robot will park in position $\leq 50$ early on and leave many spaces unable to be occupied. I tried manually exploring small cases with 2, 3, 4, and 5 parking spaces, but this did not produce much help.","['probability', 'problem-solving']"
962971,Prove that the kernel is of dimension 2,"""Experimentally"", I found that the kernel (null space) of the following matrix is of dimension 2. I'd like to prove it, but haven't managed yet:
\begin{equation}
\text{for almost all } t>0,\quad \text{dim}\,\text{ker}\left(\mathbf{Q}_2\mathbf{Q}_1(t)-\mathbf{Q}_1(t)^{-1}\mathbf{Q}_2\right)\overbrace{=}^?\;2 
\end{equation} where: $\mathbf{Q}_2$ is the identity matrix everywhere except in $(2n,2n)$:
\begin{equation}
\mathbf{Q}_2=\begin{bmatrix} 1 & & \\  & \ddots &   \\ & & 1 & \\ & & & -1  \end{bmatrix}\in\mathbb{R}^{2n\times2n}
\end{equation} $\mathbf{Q}_1(t)$ is defined by: \begin{equation}
\forall t>0,\quad\mathbf{Q}_1(t)=\begin{bmatrix}\textbf{cos}(\boldsymbol \Omega t) & \boldsymbol \Omega^{-1}\,\textbf{sin}(\boldsymbol \Omega t) \\  -\boldsymbol \Omega\,\textbf{sin}(\boldsymbol \Omega t) & \textbf{cos}(\boldsymbol \Omega t)\end{bmatrix}\in\mathbb{R}^{2n\times2n}
\end{equation}
where (... sorry...):
\begin{equation}
\boldsymbol\Omega=\begin{bmatrix} \omega_1 & & \\  & \ddots & \\  & & \omega_n  \end{bmatrix}\in\mathbb{R}^{n\times n},\quad \forall i\in\lbrace 1,\dots, n\rbrace, \omega_i>0
\end{equation} and the four blocks are diagonal, for example:
\begin{equation}
\mathbf{cos}(\boldsymbol\Omega t)=\begin{bmatrix} \cos(\omega_1t) & & \\  & \ddots & \\  & & \cos(\omega_n t)  \end{bmatrix}\in\mathbb{R}^{n\times n}
\end{equation} Interesting properties of $\mathbf{Q}_1$ and $\mathbf{Q}_2$ : Obviously, $\mathbf{Q}_2$ is invertible and $\mathbf{Q}_2=\mathbf{Q}_2^{-1}$. Also, $\det(\mathbf{Q}_1)=1$ ($\omega_i>0$ and for proper $t>0$) and:
\begin{equation}
\mathbf{Q}_1(t)^{-1}=\begin{bmatrix}\textbf{cos}(\boldsymbol \Omega t) & -\boldsymbol \Omega^{-1}\,\textbf{sin}(\boldsymbol \Omega t) \\  \boldsymbol \Omega\,\textbf{sin}(\boldsymbol \Omega t) & \textbf{cos}(\boldsymbol \Omega t)\end{bmatrix}
\end{equation} The initial equation can therefore also be written as:
\begin{equation}
\text{ker}\left(\mathbf{Q}_2\mathbf{Q}_1(t)-\mathbf{Q}_1(t)^{-1}\mathbf{Q}_2\right)=\text{ker}\left(\mathbf{Q}_2\mathbf{Q}_1(t)\mathbf{Q}_2\mathbf{Q}_1(t)-\mathbf{1}_{2n}\right)
\end{equation} So another way of solving the problem is to prove that 1 is an eigenvalue of $\mathbf{Q}_2\mathbf{Q}_1(t)\mathbf{Q}_2\mathbf{Q}_1(t)$ with a multiplicity of 2. But I'm not sure this helps... Any clues would be greatly appreciated.","['matrices', 'linear-algebra']"
963024,"How far can we take ""If $f$ is holomorphic in $D\setminus C$, $f$ is holomorphic in $D$.""?","It is a theorem of Riemann that if a function $f:D\to\Bbb C$ is holomorphic in all but finitely many points where it is continuous, then in fact $\mathcal O(D)\ni f$. An exercise in Remmert's introductory text asks to prove this is true if $f$ is holomorphic in $D$ except for a line in $D$, where it is continuous. Can one characterize the subsets $C$ of a fixed open set $D$ such that the claim  ""If $f$ is holomorphic in $D\setminus C$, $f$ is holomorphic in $D$."" holds true?",['complex-analysis']
963032,How to solve this linear first order differential equation?,$$\frac{1}{N}\frac{dN}{dt} + 1 = te^{t+2}$$ The equation is separable and so is easily solvable. However doing so gives me the following: $$\int \frac{1}{N}dN = \int(te^{t+2} - 1)dt$$ Simplyifing gives: $$|N| = e^{-t + te^{t+2} - e^{t+2} + c}$$ How do I proceed from here?,"['ordinary-differential-equations', 'calculus']"
963039,Indefinite integral with trig components,The following integral has me stumped. Any help on how to go about solving it would be great. $\int\frac{\cos\theta}{\sin2\theta - 1}d\theta$,"['trigonometry', 'integration', 'indefinite-integrals']"
963046,"Is c, the Banach space of convergent sequences with the sup norm, separable?","Is $c$, the Banach space of convergent sequences with the sup norm, separable? Let $X$ be the set of all sequences which are rational numbers, that converge to some rational number $x$. As the rationals are countably infinite, we need to only show that $X$ is dense in $c$. That is what I am a bit unsure how to show... help would be appreciated.",['functional-analysis']
963061,Can the set of computable numbers be used as a theoretical basis for calculus?,"I recall from my Real Analysis course that the rational numbers $\mathbb{Q}$ are not suitable for doing calculus, and I believe the reason was that $\mathbb{Q}$ does not possess the least-upper-bound property, which creates problems when defining continuity and computing limits of Riemann sums.  (This is discussed in more detail here: Importance of Least Upper Bound Property of $\mathbb{R}$ ) So, $\mathbb{R}$ has some desirable properties.  On the other hand, I think it also has some undesirable properties.  For example: $\mathbb{R}$ is uncountably infinite, which means we could never enumerate all real numbers, even given infinite time and space (as demonstrated by Cantor's diagonal argument) In contrast, the set of computable numbers is countably infinite.  This means that the vast majority of real numbers cannot be described in any algorithmic way.   As a consequence, it is impossible to represent the vast majority of real numbers in a computer algebra system, even given an unlimited amount of working memory. This seems like a philosophical problem for calculus, and I'd be interested to know whether anyone has found a viable alternative to use in place of $\mathbb{R}$. In particular, if we use the set of computable numbers instead of $\mathbb{R}$, can we define differential and integral calculus sensibly and avoid the limitations of $\mathbb{R}$ mentioned above? (After all, the ""important"" irrational numbers, including $e$ and $\pi$ and the algebraic irrationals, are all included in the computable numbers, so I doubt we'd miss out on any number we've ever heard of.) Note: The Wikipedia article on computable numbers (cited above) discusses this somewhat, but the details (as of this writing) are a bit sparse.  It mentions ""computable analysis"", a ""constructivist"" branch of mathematics that attempts to use computable numbers instead of $\mathbb{R}$. The article says: The computable numbers form a real closed field and can be used in the place of real numbers for many, but not all, mathematical purposes. but it does not say precisely what the computable numbers can or cannot be used for, especially regarding calculus. Also, I realize that this question is entirely moot in practice, since finite computer memory means that we can only use computers to manipulate a finite set of numbers (ditto regarding our finite brains).  But it still seems interesting from a theoretical perspective.","['philosophy', 'analysis']"
963077,CDF of probability distribution with replacement [duplicate],"This question already has answers here : What is the probability of rolling $n$ dice until each side appears at least once? (2 answers) Closed 8 years ago . I want to get every color of gumball in a gumball machine (where there are 16 types of gumballs, each with a 1/16 chance of obtaining a particular color [assume there are an infinite amount of gumballs]). I'm interested in knowing what the PMF (as a function of # of attempts) of getting every single gumball. ie. what is the probability of getting all 16 colors of gumballs in n trials? I'd rather not have to brute-force the answer and am hoping for a somewhat elegant solution (maybe we can use the negative binomial distribution to find this?).","['coupon-collector', 'probability-distributions', 'probability']"
963083,Why does a sequence in $\ell^2$ always converge to zero?,"I was taking the MOOC on Functional Analysis offered on coursera and in one of the videos in which the professor gives an example of  a sequence which converges in the weak topology but not in the strong topology, he gives an example of an $\ell^2$ sequence $(u_k)=\delta_{kn}$ $u_1=\{1,0,0,...\}$ $u_2=\{0,1,0,...\}$ He then defines the product $\langle u_k,v\rangle$ where $v \in \ell^2$ and claims that $\lim_{k \to \infty}\langle u_k,v\rangle=0$ as $v_k$ is convergent to zero.
I do not understand why all the sequences in $\ell^2$ converge to zero.","['functional-analysis', 'real-analysis']"
963087,How to derive the cigar soliton solution to the Ricci flow equation?,"I am trying to derive the cigar soliton solution to the Ricci flow equation.  Such solution has the form $$ {\frac {{{\it dx}}^{2}+{{\it dy}}^{2}}{{{\rm e}^{4\,t}}+{x}^{2}+{y}^{2
}}}
 $$ I am starting from a metric with he form $${\frac {{{\it dx}}^{2}+{{\it dy}}^{2}}{f \left( t,x,y \right) }}$$ and from the Ricci flow equations $dg_{ij}/dt = -2 R_{ij}$, I am obtaining $$-{\frac {\partial }{\partial t}}f \left( t,x,y \right) = \left( {
\frac {\partial }{\partial y}}f \left( t,x,y \right)  \right) ^{2}-
 \left( {\frac {\partial ^{2}}{\partial {y}^{2}}}f \left( t,x,y
 \right)  \right) f \left( t,x,y \right) + \left( {\frac {\partial }{
\partial x}}f \left( t,x,y \right)  \right) ^{2}- \left( {\frac {
\partial ^{2}}{\partial {x}^{2}}}f \left( t,x,y \right)  \right) f
 \left( t,x,y \right)
$$ I am looking for a solution of the form $f(t,x,y)=F(t)+g(x)+h(y)$.  Then I obtain $$f \left( t,x,y \right) ={\frac {{C_{{2}}}^{2}}{C_{{1}}}}+{{\rm e}^{2\,
C_{{1}}t}}C_{{3}}+{\frac {1}{2}}C_{{1}}{x}^{2}+C_{{2}}x+{\frac {1}{2}}C_{{1}}{y}^{2}+C_{
{2}}y
$$ Please let me know what other conditions it is necessary to apply with the aim to obtain the cigar soliton solution.  Many thanks.","['ricci-flow', 'partial-differential-equations', 'differential-geometry']"
963106,Existence of an open normal subgroup of a neighborhood of 1 in a compact Hausdorff and totally disconnected topological group,Let $G$ a compact Hausdorff and totally disconnected topological group. Then every neighborhood of 1 contains an open normal subgroup of finite index in $G$. I need this lemma to prove that every compact Hausdorff and totally disconnected topological group is a profinite group. I am trying but I can not prove it. Any suggestions?,"['topological-groups', 'profinite-groups', 'group-theory']"
963115,"${\rm Hom}_R(M, R/M) =\{0\} \implies R$ is a field.","Let $R$ be a local ring with maximal ideal $M$. Suppose $M$ is finitely generated. Prove that if ${\rm Hom}_R(M, R/M) =\{0\}$, then $R$ is a field. ${\rm Hom}_R(M, R/M)$ stand for the group of $R$-module homomorphisms from $M$ to the quotient $R/M$.","['modules', 'commutative-algebra', 'ring-theory', 'abstract-algebra']"
963152,Is the continuity of a vector field enough for the existence of the solution of a differential equation?,"I've recently seen the existence-uniqueness theorem for ordinary differential equations from Arnold's book. I understand that the theorem as stated guarantees both existence and uniqueness if the corresponding vector field is continuously differentiable. I've also noticed that in most examples where unique solutions don't exist, the differentiability of the vector field is missing. My question is, will any weaker condition suffice to guarantee only the existence (and not necessarily the uniqueness) of an ODE? Is it for example true that if the vector field is just continuous, a solution exists even if not unique? 
I went through Existence of Solution to Differential Equations. , but this doesn't seem to answer my doubts completely.","['ordinary-differential-equations', 'vector-fields']"
963164,Verify the following combinatorial identity: $\sum_{k=0}^{r} \binom{m}{k}\binom{n}{r-k} = \binom{m+n}{r}$ [duplicate],"This question already has answers here : Combinatorial interpretation for Vandermonde's identity $\sum\limits_i\binom{m}{i}\binom{n}{j-i}=\binom{m+n}{j}$? (2 answers) Closed 9 years ago . $$\sum_{k=0}^{r} \binom{m}{k}\binom{n}{r-k} = \binom{m+n}{r}$$ Nice, so I've proven some combinatorial identities before via induction, other more simple ones by committee selection models.... But this one is weird, induction doesn't even seem feasible here without things getting nasty, and the summation on the left is not making things easier. Can anyone help?","['summation', 'combinatorial-proofs', 'combinatorics']"
963174,Prove that this sequence converges almost surely,Suppose that $(X_n)_{n\ge1}$ is a sequence of independent random variables with $E[|X_n|] < \infty$ for all $n$ and $E(X_n) = \mu$. Prove that $$\sum_{n=1}^{\infty}\frac{1}{2^n}X_n = \mu \; a.s$$ I am stuck with this question and not sure how to go about it. I have proven that the sum converges absolutely almost surely but am not sure if this is useful towards my goal.,"['probability-theory', 'probability-limit-theorems', 'measure-theory', 'lebesgue-measure']"
963209,Finding bump function on a smooth manifold using partitions of unity.,"Let $M$ be a smooth manifold. Let $A$ and $B$ be disjoint closed sets of $M$. Show there exists a smooth function $f$ such that $f^{-1}(0)=A$ and $f^{-1}(1)=B$. This is my idea so far, Since $A$ and $B$ are disjoint closed subsets $\{M-A,M-B\}$ is an open cover for $M$. Therefore there exists a partition of unity $\{\psi_{1},\psi_{2}\}$ with $\psi_{1}$ supported in $M-A$ and $\psi_{2}$ supported in $M-B$. Furthermore $\psi_{1}+\psi_{2}=1$. Then $\psi_{1}(1-\psi_{2})$ is zero on $A$ and $1$ on $B$. I get the inclusions $A\subset f^{-1}(0)$ and $B\subset f^{-1}(1)$. I've tried adding a few more open sets to the cover like $M-(A\cup B)$ and $(M-A)-B$ and $(M-B)-A$ but I still can't ensure that the function only vanishes at $A$. Then I moved on to attempt to find any bump function that is 1 only on $A$ and ran into the same problem. Am I missing something here or do I just need to be clever with how I define a function. Any hints would be much appreciated. Thanks.","['differential-topology', 'differential-geometry']"
963287,Maximise the volume of an open triangular prism,"An open container is to be constructed out of 200 square centimeters of cardboard. The two end pieces are equilateral triangles. The open top is a horizontal rectangle. Find the lengths of the sides of the triangle for maximum volume of the container. So effectively we have an equilateral triangular prism of length $L$. I first found an equation for $L$:  $$L=\frac{200-\sqrt{3}x^2}{2x}$$ I then used $V = \frac{1}{2}x^2Lsin60$ to get the volume, substituting for $L$ to get the volume in terms of $x$. Differentiating with respect to $x$, setting equal to zero, and solving for $x$ gave me value of $x=6.2$ $$\frac{dv}{dx} = 50\sqrt{0.75} - \frac{9x^2}{8} = 0$$
x=6.204 But this answer was marked wrong by my teacher. Where had I gone wrong?","['optimization', 'calculus', 'derivatives']"
963299,True or false? A relative maximum or minimum must occur at a critical point.,"I'm taking calculus one and I have to determine if this statement is true or false. A relative maximum or minimum must occur at a critical point. I believe it is false. The answer key says it is true so I am curious if I am right (low probability) or if I can get this clarified (the answer key has always been right when I thought it was wrong). For example for y = $\frac{1}{x}$ there is a critical point at x=0 (because the derivative at this point does not exist) even though there is no relative maximum or minimum (or is there?). I think if the statement was ""A relative maximum or minimum must occur at a critical point when the derivative at that point exists."" Please help. Thanks.","['calculus', 'derivatives']"
963360,Direct sum and direct product of infinitely many abelian groups are not isomorphic,"Let $I$ be an infinite set, and for each $i$ let $A_i$ be an abelian group with order $o(A_i) \ge 2$.  Prove that the direct product $\prod A_i$ and the direct sum (coproduct) $\bigoplus A_i$ are not isomorphic. Here the product and coproduct are taken in the category of abelian groups.  So an element of the direct product is a ""list"" of one element from each group, and an element of the coproduct is such a list where all but finitely many terms are zero. This problem appeared on an algebra problem set a couple weeks ago and I haven't been able to solve it then or since then.  Any ideas? An initial observation is that the direct sum is of course a subgroup of the direct product.  But the direct product could be a subgroup of the direct sum as well!  For example let $I = \mathbb{N}$, and let $A_1 = B \times B \times B \times \cdots$ where $B = A_2 \times A_3 \times A_4 \times \cdots$.  Then
$$
\prod A_i
= A_1 \times B
= (B \times B \times B \times \cdots) \times B
= A_1
\subset \bigoplus A_i
$$ This causes many of my ideas to fail; for instance I cannot rely on there existing a generating set of a certain cardinality, nor can I argue there are a certainly cardinality of subgroups, nor in general can I make any sort of argument regarding the size of the two groups. It also seems promising to appeal directly to the universal mapping properties satisfied by the product and coproduct.  The problem I ran into in this case was that the projections from the direct product to the individual $A_i$s and the inverse projections from the $A_i$s to the direct sum need not have anything to do with each other.  Also, this approach would somehow have to make use of the fact that $I$ is infinite...","['direct-sum', 'abelian-groups', 'abstract-algebra', 'category-theory', 'direct-product']"
963419,Simplifying a square root fraction,Simplify the following $$\frac{\sqrt{3}}{\sqrt{2}(\sqrt{6} - \sqrt{3})}$$ Apparently the answer is $\frac{1}{2} (2 + \sqrt{2})$ but can't for the life of me see how to get it.  Any help is massively appreciated. Thanks,"['radicals', 'fractions', 'algebra-precalculus']"
963438,Cube root of complex number without trigonometric functions,"Is there a general equation for a cube root of a complex number that does not exploit De Moivre's Theorem or in any way use trigonometric functions? For example, a square root of a complex number $x$ is $$\sqrt{\frac{|x|+\operatorname{Re}(x)}{2}}+i\sqrt{\frac{|x|-\operatorname{Re}(x)}{2}}.$$ Is there a similar equation for a cube root of $x$? By introducing $a$ and $b$ such that $(a+ib)^3=x$, we can then expand and obtain two equations in $a$ and $b$ by equating the real and imaginary parts on each side. However, the resulting equations are cubic and I don't know any method to find the roots of a cubic equation without having to take the cube root of a complex number, which is the problem I want to solve in the first place.","['complex-numbers', 'algebra-precalculus', 'roots']"
963445,Skorokhod's theorem and summary of convergence of sequence of RVs,"This question is about convergence of RVs (when convergence in one sense implies other convergence modes). I would like to have a big picture on convergence modes and various implications between them. My sources are books, older posts here, and Wikipedia, and I hope to obtain a big beautiful picture with your help. I will update this post with your replies and comments (I hope this is in line with MSE guidelines). Start with the big picture (main source: this ). I write $X_n\to X$ for RVs and $F_n\to F$ for distributions (laws). \begin{matrix}
X_n \xrightarrow{L^s} X \implies X_n \xrightarrow{L^{s-1}} X \implies \cdots \implies 
& X_n \xrightarrow{L^1}X & \\
& & \hspace{-25mm}\searrow \nwarrow_{**} \\
& & X_n \xrightarrow{p} X \implies F_n \to F \\
& \Uparrow_{*} & \hspace{-25mm}\nearrow & \\
& X_n \xrightarrow{a.s.} X &
\end{matrix} (The picture is not so typographically beautiful actually! I don't know how to rotate implication symbols in MathJax. So rotated single arrows have to be intended as implications.) A.s. convergence implies convergence in $L^1$ ($\Uparrow_{*}$) under the hypotesis: $\exists Y: |X_n|<Y, \mathbb{E}(Y)<\infty$. Convergence in p. implies convergence in $L^1$ ($\nwarrow_{**}$) under the hypothesis of  uniformly integrable (u.i.) $X_n$, i.e.
$$ \lim_{a\to\infty} \sup_n \mathbb{E}(|X_n| \mathbb{1}_{\{|X_n|>a\}})=0.$$ A sufficient (simpler) condition which implies u.i. is $\exists \epsilon>0: \sup_n \mathbb{E}(|X_n|^{1+\epsilon})<\infty.$ I would like to complete the picture, i.e. know if there exist conditions which ensure  stronger convergence modes from weaker ones (for example, when convergence in p. implies convergence a.s.) or, more in general, conditions under which a convergence mode implies others (for example when convergence in the first mean implies convergence a.s.). ** Big picture (after the answer) ** Implication with one asterisk: valid for a subsequence. Implication with two asterisks: under the uniform integrability condition (see also the characterizations proposed above and in the answer). Implication with three asterisks: under the further condition that $X$ is a.s. constant (i.e. the distribution $F$ is a point mass).",['probability-theory']
963455,intro level set theory question.,"I want to show that $X\cap(Y\cup Z) = (X\cap Y) \cup Z \ \iff Z\subseteq X$ I think I have figured out one direction: Assume $Z\subseteq X$ then $Z\cap X= Z$. We know $X\cap(Y\cup Z)=(X\cap Y)\cup (X\cap Z)$. So $X\cap(Y\cup Z)=(X\cap Y) \cup Z.$ I am having trouble with the other direction. I was to assume $X\cap(Y\cup Z) = (X\cap Y) \cup Z$ and show $Z\subseteq X.$ How do I go about this? I have tried using the ""distributive"" property a bunch, but I get lost... What is the best way to go about something like this?",['elementary-set-theory']
963496,Relationship between the Hausdorff dimension and the Box-counting dimension,"In Fractal Geometry by Falconer the author writes: If $1<\mathcal H^s(F)=\lim_{\delta\to0}\mathcal H_\delta^s(F)$
  then $\log N_\delta(F)+s\log\delta>0$ if $\delta$ is sufficiently small.
  Thus $s\leqslant\underline{\lim}_{\delta\to0}\log N_\delta(F)/-\log\delta$ so
  $$\dim_HF\leqslant\underline\dim_BF\leqslant\overline\dim_BF\tag{3.17}$$
  for every $F\subset\mathbb R^n$.
  We do not in general get equality here.
  Although Hausdorff and box dimensions are equal for many âreasonably regularâ
  sets, there are plenty of examples where this inequality is strict. What happens in the case $\mathcal{H}^s(F) \leq 1$?","['geometry', 'fractals', 'dimension-theory-analysis', 'analysis', 'geometric-measure-theory']"
963505,What are the points of some schemes?,"Let $X=\operatorname{Spec}\mathbb{C}[x,y,t]/(xy-t)$, $Y=\operatorname{Spec}K[x,y]/(xy-t)\rightarrow \operatorname{Spec}K$ and $Z=\operatorname{Spec}R[x,y]/(xy-t)\rightarrow \operatorname{Spec}R$, where $K$ is the rational function field with variable $t$, and $R$ is the Laurent series ring of variable $t$. Question: What are the points in $Y$ and $Z$? I know that points of $X$ are the follows. The generic point $\xi$ is given by the ideal $(0)$, and corresponding to   $V=\{ xy=t\}\subset \mathbb{C}^{3}$. Any point of $V$ is a closed point of $X$. We also some points in the middle, for example one corresponding to curve  $\{ xy=t\}$ with a fixed $t\neq0$, or $\{x=0, t=0\}$ or $\{y=0, t=0\}$ or $\{xa=t, y=a\}$ etc. What's the analog description of $Y$ and $Z$?","['commutative-algebra', 'algebraic-geometry', 'schemes']"
963563,Make x the subject given the formula for y,I am given the following formula: $$y=\frac{x}{a}+\sqrt{\frac{x}{b}}.$$ I want to make x the subject. I rearranged the equation and got to: $$y^{4}=x(\frac{y^{2}}{2}+2y^{2})-x^{2}.$$ and I don't know where to go from here. May be this is the wrong rearrangement. The answer according to wolfram alpha is: $$x=\pm \frac{a^{\frac{3}{2}}\sqrt{a+4by}+a^{2}+2aby}{2b}.$$ How can I get there?,['algebra-precalculus']
963612,Uniqueness of IVP solution with a condition weaker than Lipschitz?,"We know that Lipschitz condition with respect to $x$ in $$x' = f(t,x) , x(t_0)=x_0 $$ implies uniqueness of IVP problem above. Can we have uniqueness with condition less than Lipschitz?","['lipschitz-functions', 'ordinary-differential-equations']"
963661,Proving Identities.,I tried to solve it but I cant get the answer. How to prove this by using a hand? $$ \sec^2x + \csc^2x = \sec^2x \csc^2x $$ $$ \frac{\sec\theta + 1}{\sec\theta - 1} = \frac{1 + \cos\theta}{1 - \cos\theta}$$ $$ \frac{1 - \cot^2\theta}{1 + \cot^2\theta} = \sin^2\theta - \cos^2\theta $$ Anyone can help? Thanks.,['trigonometry']
963700,A simple question about the definition of martingales,"The definition of Martingale denotes that $E(M_{n+1}\mid\mathcal{F}_n)=M_n$. This implies $E(E(M_{n+1}\mid\mathcal{F}_n))=E(M_n)$. Then does it mean that $E(M_{n+1})=E(M_n)$ using the tower property? If so, what gives a significance to the optional stopping theorem that tells us $E(M_T)=E(M_0)$?","['probability-theory', 'martingales']"
963758,Complex numbers on circle of unit radius,"Given three points in the complex plane (i.e. numbers $z_1,z_2,z_3\in\mathbb C$), they define a unique circle (unless they are collinear). When does that circle have radius one? I know how to compute that âthe hard wayâ, i.e. by separating real and imaginary part. From there I could either construct perpendicular bisectors and intersect these, or I could solve $ax_k+by_k+c=x_k^2+y_k^2$ for $k\in\{1,2,3\}$ and then deduce the radius from the $a,b,c$ I found. But I guess there might be some more elegant way to express this condition using vocabulary more suited for complex numbers. Separating numbers into real and imaginary part for all numbers should not be needed, even though conjugation might still be needed at some point. As a motivating example: we know that four points are cocircular iff they satisfy $$\begin{vmatrix}
x_1^2+y_1^2 & x_1 & y_1 & 1 \\
x_2^2+y_2^2 & x_2 & y_2 & 1 \\
x_3^2+y_3^2 & x_3 & y_3 & 1 \\
x_4^2+y_4^2 & x_4 & y_4 & 1
\end{vmatrix}=0$$ but with $z_k=x_k+iy_k$ you can also check the condition $$\frac{(z_1-z_3)(z_2-z_4)}{(z_1-z_4)(z_2-z_3)}\in\mathbb R$$ which is a lot easier to write and compute. I'm looking for some similar simplification for the case of unit radius.","['geometry', 'complex-numbers', 'triangles']"
963817,Variation of Chebsyhev: How to prove that?,"I have the ""job"" to prove that for any random variable with standard deviation $\sigma$ and expectation $\mu$ and for any $t>0$ we have
$$Pr[X-\mu \geq t \sigma] \leq \frac{1}{1+t^2}.$$ I thought that this would be quite easy and tried to apply Chebyshev, but here's my result: $$Pr[X - \mu \geq t \sigma] \leq Pr[|X-\mu| \geq t \sigma] \leq \frac{Var[X]}{t^2\sigma^2}=\frac{1}{t^2},$$
so my result is too bad, either because Chebyshev is not good enough or because (what I think is the main reason) my first inequality is too ""weak"". How should I handle this in order to get $\frac{1}{1+t^2}$?","['distribution-tails', 'random-variables', 'expectation', 'probability-distributions', 'probability']"
963819,Does $f(x)=ax$ intersect $g(x)=\sqrt{x}$,"It maybe a stupid question but I want to be sure how to explain it formally. Does $f(x)=ax$ intersect $g(x)=\sqrt{x}$, when $x>0$ and $a>0$ (however small it is) I think it does. The derivative of $f(x)$ is constant, positive. And the derivative of $g(x)$ tends to $0$. So there will be some point $x_0$, from which the derivative of $f$ will be greater than derivative of $g$. Therefore $g$ will grow slower than $f$ and both functions finally meet. Am I right? This is enough? Can one formally prove it?","['calculus', 'functions']"
963857,The intuition of the rank theorem,"In Rudin's Principle of Math Analysis, I know the proof of the rank theorem. However, I fail to understand its content. 9.32 Theorem: Suppose $m,n,$ are nonnegative integers, $m\geq r,n\geq r$, $F$ is a $C^1$ mapping of an open set $E\subset R^n$ into $R^m$, and $F'(x)$ has rank $r$ for every $x\in E$. Fix $a\in E$, put $A=F'(a)$, Let $Y_1$ be the range of A, and let $P$ be the projection in $R^m$ whose range if $Y_1$. Let $Y_2$ be the null space of $P$. Then there are open sets $U$ and $V$ in $R^n$, with $a\in U,U\subset E$ and there is a 1-1 mapping $H$ of $V$ onto $U$(whose inverse is also of class $C^1$) such that (66) $F(H(x))=Ax+\phi(Ax)$ $(x\in V)$ where $\phi$ is a $C^1$ mapping of open set $A(V)\subset Y_1$ into $Y_2$. It is clear that F is a manifold of dimension r. However, what is the purpose of H? I do not understand the content of H. Or should I treat H as a chart of the manifold described by F?","['multivariable-calculus', 'differential-geometry', 'linear-algebra', 'real-analysis', 'differential-topology']"
963861,A Sine integral: problem I,"Is it possible to demonstrate a solution for the integral
\begin{align}
\int_{0}^{\infty} x^{n} \, \sin\left( a x^{2} + \frac{b}{x^{2}} \right) \, dx 
\end{align}","['definite-integrals', 'gamma-function', 'integration', 'hypergeometric-function']"
963882,Alternating sum of binomial coefficients multiplied by (1/k+1) [duplicate],"This question already has answers here : How to prove $\sum\limits_{r=0}^n \frac{(-1)^r}{r+1}\binom{n}{r} = \frac1{n+1}$? (5 answers) Closed 4 years ago . I'm trying to prove that $$\sum_{k=0}^n {n \choose k} (-1)^k \frac{1}{k+1} = \frac{1}{n+1}$$ So far I've tried induction (which doesn't really work at all), using well known facts such as $$\sum_{k=0}^n {n \choose k} (-1)^k = 0$$ and trying to apply identities like $${n \choose k} = {n-1 \choose k-1} + {n-1 \choose k}$$ Would anyone be able to point me towards the right method? Should I be looking to apply an identity or is there a method I'm missing?","['summation', 'binomial-coefficients', 'combinatorics']"
963922,How can a finite graph be viewed as a discrete analogue of a Riemann surface?,"In the paper ""RiemannâRoch and AbelâJacobi theory on a finite graph"" by Baker and Norine, the first line of the abstract states: ""It is well known that a finite graph can be viewed, in many respects, as a discrete analogue of a Riemann surface"". Perhaps this is indeed well known, but not to me. Nor can I find any material online that explains this concept in detail. If someone could point me in the right direction it would be much appreciated. I am interested how an arbitrary finite graph can be viewed as a discrete Riemann surface, not a graph that simply results from a triangulation.","['algebraic-geometry', 'graph-theory', 'riemann-surfaces', 'reference-request', 'combinatorics']"
963934,Frobenius method differ by integer,"When the roots of the indicial equation differ by an integer the equation is of the form:
$$y_2 (z)=cy_1 (z) \ln(z)+z^{\sigma_2 } \sum_{n=0 }^\infty(b_n z^n )$$
Here is what is bothering me. The last term on the RHS (namely $z^{\sigma_2 } â_{n=0 }^\infty(b_n z^n )$) is the Frobenius series that we would usually (if the roots did not differ by an integer) substitute into the original ODE. But the reason that we did not do this in the first place is because it leads to something going wrong (such as dividing by 0 for one of the terms). Thus when we sub $y_2$ into the ODE since derivatives are like linear operators we will get exactly the same problem as we had before hand i.e. for one of the terms we will need to divide by 0, say. So how do we get around this problem? To demensionstrate my point consider example 7 in this document http://www.most.gov.mm/techuni/media/EM_03011_p2chap34.pdf The ODE is $(x^2-x)y''-xy'+y=0$
  The roots to the indicial equation are $r_1=1$ and $r_2=0$. And it can be easly shown that for a given root $r$ the reccurence relationship is:
  $$a_{s+1}=\frac{a_n(n+r-1)^2}{(n+1+r)(n+r)}$$
  when $r=0$ when have
  $$a_{s+1}=\frac{a_n(n-1)^2}{(n+1)(n)}$$
  Thus when $n=0$ we end up dividing by 0 and we can not use this method.
  When $r=1$ this can be solved to get $y_1=a_0 x$.
  Thus using $$y_2 (x)=cx \ln(x)+x^{r_2 } \sum_{n=0 }^\infty(b_n x^n )$$
  and differentiating it twice and subbing it back into the ODE we get:
  $$-xc+\sum (n(n-1)b_n+(n+1)nb_{n+1}-b_nn+b_n)x^n=0$$
  so when equating coefficients of $x^n$ in an effort to find $b_n$ we will get exactly the same recurrence relationship as before and thus not be able to find $b_1$ since it will involve dividing by 0","['ordinary-differential-equations', 'sequences-and-series']"
963950,Dimension of moduli of lines on quadric,"What is the dimension of the moduli space of lines on a general quadric hypersurface in $\mathbb{P}^n$? Maybe the question is quite trivial, but different intuitive approaches (Ã  la Italian algebraic geometry) yield different answers.","['intersection-theory', 'algebraic-geometry']"
963957,Is the Gamma Function a jointly sufficient statistic?,"A random sample $X_{1},...,X_{n}$ are pulled from a gamma distribution. Are there jointly sufficient statistics based on these observations for the two unknown parameters? The definition of a gamma distribution is f(x;$\alpha$,$\beta$)=$\frac{x^{\alpha-1 }}{\beta ^\alpha \Gamma(x){}}e^{\frac{-x}{\beta }}$ I kind of understand what a Jointly Sufficient Statistic is however I am not sure what to do from here. Possibly taking the product $\prod_{i=1}^{n}$ in front of the distribution. Can anybody help? Thanks!","['statistics', 'self-learning', 'probability-distributions']"
963983,Proving that $\bigcup\mathcal{A}\times\bigcap\mathcal{B}\subseteq\bigcup\{a\times b\mid a\in\mathcal{A}\land b\in\mathcal{B}\}$ is always true,"The problem is to prove that the following expression is true for any families of sets $\mathcal{A}$ and $\mathcal{B}$ that are not empty. $$\bigcup\mathcal{A}\times\bigcap\mathcal{B}\subseteq\bigcup\{a\times b\mid a\in\mathcal{A}\land b\in\mathcal{B}\}$$ Our definition of cartesian product is that $A \times B = \{  (a,b) | a\in A \land b \in B \}$ and and ordered pair $(a,b)=(c,d)$ if and only if $a=c$ and $b=d$. So we haven't seen Kuratowski's definition of ordered pairs yet.
I'm not searching for a complete solution, the problem is I don't know where to start. I know what a family of sets is but I can't see what is a sum of all cartesian products $a \times b$ (right side of the equation). How should I start approaching such a problem? I'm familiar with easier proofs with sets but these cartesian products and operations  with $\bigcup$ and $\bigcap$ are new to me.",['elementary-set-theory']
963986,What is a solution of such equation concerning the arithmetic and integral means?,"Let $f:[a,b] \rightarrow \mathbb R$ be integrable and satisfies 
$$
f\left(\frac{x+y}{2}\right)=\frac{1}{y-x} \int_x^y f(t)dt 
$$
for all $x \neq y$, $x,y \in [a,b]$. What about $f$? Is it affine function? Thanks",['analysis']
963987,Proving that $\sum \overline{PV_i}^2=\frac{nl^2}{4}\left(1+2\cot^2 \frac{\pi}{n}\right)$,"Given that $P$ is any point on the incircle of a regular $n$-sided polygon with edge length $l$ and vertices $V_1,V_2...V_n$, how do we prove that $$\displaystyle\sum_{i=1}^{n} \overline{PV_i}^2=\dfrac{nl^2}{4} \left(1+2\cot^2 \dfrac{\pi}{n}\right)$$
? Here is a figure of what I understand I don't even know where to begin with this one.. We want to prove that $\displaystyle\sum_{i=1}^{n} \overline{PV_i}^2$ is independent of the chosen point $P$.. Hints in the right direction and answers appreciated. Please avoid using vector algebra or complex numbers to solve this problem.",['geometry']
963995,About Integration $ \int \frac{\tanh(\sqrt{1+z^2})}{\sqrt{1+z^2}}dz $,"How to calculate the following integral $$
\int \frac{\tanh(\sqrt{1+z^2})}{\sqrt{1+z^2}}dz
$$ Is there any ways to calculate those integral in analytic? (Is $[0,\infty]$, case the integral is possible?) How about using numerical method? Is there are good numerical scheme to complete this integral? From the answer by @Lucian, 
The integral of
$\displaystyle\int_0^\infty\bigg[1-\tanh(\cosh x)\bigg]~dx$ is converges. How one can evaluate this integral?","['improper-integrals', 'integration', 'indefinite-integrals']"
964001,Non Hausdorff complex manifold?,"Suppose there is a topological space $X$ equipped with an atlas making it into a complex manifold. Is it true that this implies automatically that $X$ is Hausdorff ? I have heard it is the case for Riemann surfaces, although I don't have a reference for it. Is it true in higher dimension ? EDIT as remarked in the comments and answer, I was mistaken. This does not seem true even in dimension one.","['general-topology', 'complex-manifolds']"
964008,Proof of an identity involving binomial coefficients,"I have found numerically that the following identity holds:
\begin{equation}
\sum_{n=0}^{\frac{t-x}{2}} n 2^{t-2n-x}\frac{\binom{t}{n+x}\binom{t-n-x}{t-2n-x}}{\binom{2t}{t+x}} = \frac{x^2+t^2-t}{2t-1},
\end{equation} 
where $n$, $t$, and $x$ are positive integers ($x \leq t$). To make it more visible, values of $n$ range from $0$ to $\frac{t-x}{2}$. Any clue about how to prove it? Thanks, Antonio","['binomial-coefficients', 'combinatorics']"
964019,Symmetrical of a triangle's vertexes,"I have the following problem : Show that the symmetrical (ie reflection) of a triangle's vertexes by the opposite side are aligned iff the distance between the orthocenter and the circumcenter is twice the circumradius. I made a few pictures with GeoGebra to try and find a way to solve that, but it didn't really help. When two of them ($A'$ and $C'$) are in the same place : When they are distinct and aligned :","['geometry', 'triangles', 'linear-algebra', 'circles']"
964049,global solutions for ODEs,"I'm searching for related results for the following problem: Consider the ODE:
  $$
x'=-3x+ x^2\log x,\quad x(0)=3/2. 
$$
  Does a solution $x(t)$ exist on $t\in[0,\infty)$? A quick research on Google returns mainly the local theory such as Picard's existence theorem. Can anybody come up with some references about global existence of solutions to ODEs? In the problem quoted above, the function 
$$
f(x)=-3x+ x^2\log x
$$
is locally Lipschitz. I'm not sure if this can guarantee the existence of solution on $[0,\infty)$.","['ordinary-differential-equations', 'reference-request']"
964068,Integral of Wiener Process and Central Limit Theorem,"I am trying to solve the following exercise: (1) Given $W$ is a Wiener process, find a constant $M$ such that
  $\lim\limits_{t\to\infty} \frac{1}{t}\int_{0}^{t}\sin^2W_s ds=M$ (2) Then show that
  $\frac{1}{\sqrt{t}}\int_{0}^{t}(\sin^2W_s-M) ds$ converges to $N(0,\sigma^2)$ and compute $\sigma^2$. So far I have only started the first part of the question before getting stumped.  I started the following:
I simply integrated by parts with respect to s and evaluated at the bounds 0 and t $$\lim_{t\to\infty} \frac{1}{t}\int_{0}^{t}\sin^2W_s ds= \lim_{t\to\infty} \frac{1}{t}\left(\frac{1}{2}\Big((W_t-\sin(W_t)\cos(W_t)-(W_0-\sin(W_0)\cos(W_0)\Big)-\int_{0}^{t}sd(\sin^2W_s)\right)$$ Given $W_0=0$ We have the following: $$\lim_{t\to\infty} \frac{1}{t}\left(\frac{1}{2}(W_t-\sin(W_t)\cos(W_t))-\int_{0}^{t}sd(\sin^2W_s)\right)$$ I am assuming I have to apply something like Ito's formula to the stochastic integral term on the RHS. However, I am stumped how to show this limit equals a constant M, and how to begin the second part of the problem statement.","['stochastic-processes', 'stochastic-integrals', 'probability-theory', 'stochastic-calculus', 'probability']"
964082,"Derive branch cuts for $\log(\sqrt{1-z^2} + iz)$ as $(-\infty,-1)$ and $(1,\infty)$?","Attempt: First, we examine $\sqrt{1-z^2}$. Note that it can be written $\sqrt{1-z}\sqrt{1+z}$, so the appropriate branch cuts are $(-\infty,-1)$ and $(1,\infty)$ for the inner square root term. Next, we look at $\log(w)$ and note that we can define the cut for $\log(w)$ as $(-\infty,0)$. But now what? I tried setting $w= \sqrt{1-z^2} + iz$, solving for the branch point where $w=0$, but this results in $1=-z^2+z^2=0$, so I think this is the wrong approach. What is the correct way to understand this?","['branch-cuts', 'complex-analysis']"
964092,"The ""Empty Tuple"" or ""0-Tuple"": Its Definition and Properties","(I would like to link to a previous discussion on the subject: What is A Set Raised to the 0 Power? (In Relation to the Definition of a Nullary Operation) ) In axiomatic (ZFC) set theory, we define the ordered pair $(a,b)$ to equal $\{\{a\},\{a,b\}\}$. Then, we define the ordered triple in terms of the ordered pair: $(a,b,c):=((a,b),c)$. Similarly, we define the ordered quadruple as $(a,b,c,d)=((a,b,c),d)=(((a,b),c),d)$. In general, one can define the $n$- tuple using this nesting argument. To define $(x)$, Herbert Enderton's 1977 Elements of Set Theory suggests the convention $(x)=x$. This seems reasonable: note that if $S=\{a,b,c,d\}$, then $(a,b,c) \in S^3$, $(a,b) \in S^2$, you would also expect $(a) \in S$, which would be true if you defined $(a)=a \in S$. Finally, the ""Empty Tuple"" or ""$0$-Tuple"", $()$, is defined as \begin{equation}
()=\{\}=\emptyset
\end{equation} This is confirmed by The Wikipedia Tuple page as the correct choice of definition for $()$. Moreover, this agrees with the conclusion we discovered in the previous discussion , in which we decided that $S^0=\{()\}=\{\emptyset\}=1$. For consistency, then, it is pleasing to know that $()=\emptyset$. My question, however, pertains to the properties of $()$. I have listed some which I believe true: $(())=(\emptyset)=\emptyset$. Thus $(())=()$. The "" dissolution property "": $((),s_1,\ldots,s_n)=(\emptyset,s_1,\ldots,s_n)=(s_1,\ldots,s_n)$ Any others? Although this doesn't have to do specifically with the empty tuple, as a follow-up to the dissolution property, it would be ideal if it were true that $((a,b),c)=(a,(b,c))$ (both suitable definitions for $(a,b,c)$), and possibly also $((a,b,c),d)=(a,(b,c,d))=((a,b),(c,d))$ (which are all suitable definitions for $(a,b,c,d)$), etc. The reason I want (2) to be true is because certain definitions like the nullary operation require that
\begin{equation}
S^0 \times S^n = \{()\} \times S^n = \{\emptyset\} \times S^n = S^n.
\end{equation}
For this to be true, however, would require that  $((),s_1,\ldots,s_n)=(\emptyset,s_1,\ldots,s_n)=(s_1,\ldots,s_n)$, i.e. property (2). However, I can't just ""want"" or ""believe"" these properties to be true; I need to prove them within ZFC set theory, using the set-theoretic definition of $n$-tuples. Any help with this? Thanks for reading my trail of thoughts, and please let me know if you see anything anywhere which is incorrect. Thanks! Edit 1: Looking at the ""Tuples as Nested Ordered Pairs"" section of the Wikipedia Tuple Page , I see they define $(a,b,c)$ not as $((a,b),c)$, but instead as $(a,(b,(c,\emptyset)))$. There are two thing strange about this to me: first why the nesting occurs on the right, and second why they choose to pair $c$ with $\emptyset$ instead of just writing it as $(a,(b,c))$. Any insight on this? I wish I could sort this all out. Thanks again! Edit 2: Chris Culter's answer points out a contradiction which may stem from the definition of $(a)=a$. Perhaps if we define $(x)=(\emptyset,x)=\{\{\emptyset\},\{\emptyset,x\}\}$ then all the desired properties, including the dissolution property, fall into place. So far we haven't been successful in letting $(\emptyset, a) = (a)$, however. But this is the property we need, i.e. we need $((),s_1,\ldots,s_n)=(s_1,\ldots,s_n)$ if we want $S^0 \times S^n = S^n$!","['relations', 'motivation', 'elementary-set-theory', 'definition']"
964163,"Normal distribution problem - ""6 times the standard deviation""","An old textbook says the range of data can be estimated as 6 times the standard deviation. If the data is normally distributed what percentage of the data is within the range? By 'range of data', does the question mean biggest - smallest? In that case, how do I write an expression for it if it's normally distributed?",['statistics']
964194,"Uniform convergence of the series $\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}\sin\frac{1}{nx}$ on $(0,+\infty)$","Does the series $$\sum_{n=1}^\infty \frac{(-1)^{n+1}}{n}\sin\frac{1}{nx}$$
converge uniformly on $(0,+\infty)$? First, I guessed that it does, but Abel's test is not applicable here because $\sin\frac{1}{nx}$ is not monotonic, other tools didn't seem to help either. Now I think that there's no uniform convergence, but I can't prove it as well. Any ideas would be appreciated.","['sequences-and-series', 'uniform-convergence']"
964197,Can you easily simplify large exponents without Fermat's Little Theorem?,"I am asked to check if $x = 19$ is a solution to the following congruence: $$ x^{30034} â¡ 2 \pmod{18}$$ How can I do this? And in general, is there an easy/fast way to solve these types of problems when you can't use Fermat's LT?","['modular-arithmetic', 'discrete-mathematics', 'congruences']"
964199,permutation and f(n) challenge,"Suppose $f(n)$ be the number of permutation from set ${1,2,..,n}$ such
that for each $ 1 \leq i \leq n$ we have: $ | \pi(i)-i| \leq 1 $.
meaning of $ \pi(i)$ is an elements whose in place $i$ of permutation.
for example in permutation $<2,3,1>$, $ \pi(1)=2$. how we reach to $f(10)= 89$","['permutations', 'recurrence-relations', 'calculus', 'discrete-mathematics', 'contest-math']"
964206,Algebraic Structures: Does Order Matter?,"(I want to link to similar question with a very good answer: Question about Algebraic structure? ) An algebraic structure is an ordered tuple of sets. One of these is called the underlying set, and the others are operations of various arity . Since operations are functions, which are sets of ordered pairs, this is why we can interpret the components of an algebraic structure to be sets. For example, a group is a quadruple $(G,0,-,+)$ where $G$ is the underlying set, $0 \subseteq G^0 \times G$ is a nullary operation , $- \subseteq G \times G$ is a unary operation, and $+ \subseteq G^2 \times G$ is a binary operation. My question is why we choose an ordered tuple to describe the algebraic structure. For instance, does it make a difference if I define a group to be $(G,+,-,0)$, where I list the operations in order of descending, rather than ascending, arity? If the order doesn't matter, why don't we just define a group to be $\{G,0,-,+\}$, rather than an ordered tuple? Thanks!","['universal-algebra', 'elementary-set-theory', 'abstract-algebra', 'definition']"
964242,A question on self-dual differential 2-forms,"This question is from Lemma 2 in Derdzinski's paper . Let $$\omega=e_1\wedge e_2+e_3\wedge e_4, \eta=e_1\wedge e_3+e_4\wedge e_2, \theta=e_1\wedge e_4+e_2\wedge e_3$$
be a basis for self-dual two-forms on a four-manifold, where $\{e_1,e_2,e_3,e_4\}$ is an orthonormal basis of the tangent space. Derdzinski said that $$\omega^2=\eta^2=\theta^2=-id,\ \omega\eta=\theta=-\eta\omega.$$ I was wondering what $\omega^2=-id$ and $\omega\eta=\theta$ mean? Is this wedge product or other operation? Thank you very much.","['differential-forms', 'riemannian-geometry', 'differential-geometry']"
964270,Ricci SCALAR curvature,"Are there any manifolds that have NULL SCALAR curvature but not null ricci curvature tensor? For dim>2, obviously. Edit: Are there, also, any manifolds of null scalar curvature but ricci curvature not proportional to the metric tensor?","['geometry', 'differential-geometry', 'riemannian-geometry', 'curvature', 'conformal-geometry']"
964275,Bipartite Graph and Matches of Graph,"We know that one match from $G=(V,E)$ be a subset of edges $M \subset_= E  $ in such a way non two edges of M hasn't a common vertex. Matches M is Maximal if M not a proper subset of any other matches of G. a) if $M_1, M_2$ be an arbitrary matches of $G=(V,E)$, then $G' = (V, M_1 \cup M_2)$ is bipartite. b) if $M_1, M_2$ be two maximal matches, then $|M_1| \leq 3/2 |M_2|$. why a is true and b is false?","['discrete-mathematics', 'bipartite-graphs', 'graph-theory', 'computer-science', 'algebraic-graph-theory']"
964278,Divergence of a radial $1/r^2$ vector field,"How to obtain the divergence of the function $F(r,\varphi,\theta)=\hat{r}/r^2$ where $\hat r$ is the unit vector in radial direction? Is there a solution without computing the surface integral for definition of divergence? The issue is: in this divergence, the delta function will be present. But if you obtain divergence from formula $\nabla\cdot F$, that is equal to zero. At the  point $r=0$,  this formula cannot be used.","['multivariable-calculus', 'vector-analysis']"
964363,Principal $\mathrm{SL}_n$-bundles,"It seems to be well-known that a principal $\mathrm{SL}_n$-bundle on a scheme or manifold $X$ is the same as a vector bundle of rank $n$ whose determinant is a trivial line bundle. One direction is clear to me: A principal $\mathrm{SL}_n$-bundle corresponds to a principal $\mathrm{GL}_n$-bundle whose cocycles can be chosen to live in $\mathrm{SL}_n$, which means that we have a vector bundle of rank $n$ whose determinant has trivial cocycles. Conversely, if we are given a vector bundle of rank $n$ whose determinant is a trivial line bundle, this corresponds to a principal $\mathrm{GL}_n$-bundle whose determinant bundle has cocycles which are just coboundaries (not trivial). So how do we get cocycles in $\mathrm{SL}_n$? Edit. Here is an attempt to spell out the details in MarianoSuÃ¡rez-Alvarez's comment. Consider the short exact sequence of groups $1 \to \mathrm{SL}_n \to \mathrm{GL}_n \to \mathrm{GL}_1 \to 0$. It is split in the sense that $\mathrm{GL}_n \to \mathrm{GL}_1$ has a section, for example $\lambda \mapsto \mathrm{diag}(\lambda,1,\dotsc,1)$. We obtain an exact sequence of pointed sets
$$0 \to H^1(X,\mathrm{SL}_n) \to H^1(X,\mathrm{GL}_n) \to H^1(X,\mathrm{GL}_1) \to 0$$
because $H^i(X,\mathrm{GL}_n) \to H^i(X,\mathrm{GL}_1)$ is surjective for $i=0,1$. But this means that $0 \to \mathrm{Bun}_{\mathrm{SL}_n}(X) \to \mathrm{Vect}_n(X) \to \mathrm{Pic}(X) \to 0$ is exact, proving the claim. Essentially the same argument is given in archipelago's answer without using the language of cohomology.","['principal-bundles', 'algebraic-geometry', 'algebraic-topology']"
964367,Counting the number of different ways in which groups of one or two can be formed...,"I'm having trouble proving that the number of ways n>3 people can be divided into groups of either one or two is equal to: $A_n = A_{n-1} + (n-1)âA_{n-2} $ I'm trying to prove this by counting but am open to suggestions. So far, I've got: The base cases: $A_1 =1$ $A_2 =2$ $A_3 =4$ And I think that the first part $A_{n-1}$ is just counting all the ways if the $n$th term is added to $A_{n-1}$ on a group by itself. I also believe that the second term $(n-1)âA_{n-2} $ is counting the number of groups of 1 in $A_{n-1}$ that the $n$th term can pair up with, although I don't know how to even start proving this since I can't get the logic behind exactly how it's counting these groups of 1. I'd really appreciate any guidance on how to go about this...","['induction', 'recursion', 'combinatorics']"
964373,Proof of the conjecture that the kernel is of dimension 2,"I already asked this question which has been answered. This question may seem very similar but the required matrix manipulations are probably very different here due to the addition of the matrix $\mathbf{P}$, which makes the problem more difficult. ""Experimentally"", I found that the kernel (null space) of the following matrix is of dimension 2. I'd like to prove it, but haven't managed yet:
\begin{equation}
\text{for almost all } t>0,\quad \text{dim}\,\text{ker}\left(\mathbf{Q}_2\mathbf{Q}_1(t)-\mathbf{Q}_1(t)^{-1}\mathbf{Q}_2\right)\overbrace{=}^?\;2 
\end{equation} where: $\mathbf{Q}_2$ is the identity matrix everywhere except in $(2n,2n)$:
\begin{equation}
\mathbf{Q}_2=\begin{bmatrix} \mathbf{I}_n & \mathbf{0}_n \\  \mathbf{0}_n & \mathbf{P}^{-1}\begin{bmatrix}1 & && \\ & \ddots && \\ & & 1& \\ &&& -1 \end{bmatrix}\mathbf{P}  \end{bmatrix}\in\mathbb{R}^{2n\times2n}
\end{equation}
where $\mathbf{P}\in\mathbb{R}^{n\times n}$ is any invertible matrix. $\mathbf{Q}_1(t)$ is defined by: \begin{equation}
\forall t>0,\quad\mathbf{Q}_1(t)=\begin{bmatrix}\textbf{cos}(\boldsymbol \Omega t) & \boldsymbol \Omega^{-1}\,\textbf{sin}(\boldsymbol \Omega t) \\  -\boldsymbol \Omega\,\textbf{sin}(\boldsymbol \Omega t) & \textbf{cos}(\boldsymbol \Omega t)\end{bmatrix}\in\mathbb{R}^{2n\times2n}
\end{equation}
where (... sorry...):
\begin{equation}
\boldsymbol\Omega=\begin{bmatrix} \omega_1 & & \\  & \ddots & \\  & & \omega_n  \end{bmatrix}\in\mathbb{R}^{n\times n},\quad \forall i\in\lbrace 1,\dots, n\rbrace, \omega_i>0
\end{equation} and the four blocks are diagonal, for example:
\begin{equation}
\mathbf{cos}(\boldsymbol\Omega t)=\begin{bmatrix} \cos(\omega_1t) & & \\  & \ddots & \\  & & \cos(\omega_n t)  \end{bmatrix}\in\mathbb{R}^{n\times n}
\end{equation} Interesting properties of $\mathbf{Q}_1$ and $\mathbf{Q}_2$ : Obviously, $\mathbf{Q}_2$ is invertible and $\mathbf{Q}_2=\mathbf{Q}_2^{-1}$. Also, $\det(\mathbf{Q}_1)=1$ ($\omega_i>0$ and for proper $t>0$) and:
\begin{equation}
\mathbf{Q}_1(t)^{-1}=\begin{bmatrix}\textbf{cos}(\boldsymbol \Omega t) & -\boldsymbol \Omega^{-1}\,\textbf{sin}(\boldsymbol \Omega t) \\  \boldsymbol \Omega\,\textbf{sin}(\boldsymbol \Omega t) & \textbf{cos}(\boldsymbol \Omega t)\end{bmatrix}
\end{equation} The initial equation can therefore also be written as:
\begin{equation}
\text{ker}\left(\mathbf{Q}_2\mathbf{Q}_1(t)-\mathbf{Q}_1(t)^{-1}\mathbf{Q}_2\right)=\text{ker}\left(\mathbf{Q}_2\mathbf{Q}_1(t)\mathbf{Q}_2\mathbf{Q}_1(t)-\mathbf{1}_{2n}\right)
\end{equation} So another way of solving the problem is to prove that 1 is an eigenvalue of $\mathbf{Q}_2\mathbf{Q}_1(t)\mathbf{Q}_2\mathbf{Q}_1(t)$ with a multiplicity of 2. But I'm not sure this helps... Any clues would be greatly appreciated.","['matrices', 'linear-algebra', 'determinant']"
964381,The two envelopes problem,"Suppose you're given two envelopes. Both envelopes have money in them, and you're told that one envelope has twice as much money as the other. Suppose you pick one of the envelopes. Should you switch to the other one? Intuitively, you don't know anything about either envelope, so it'd be ridiculous to say that you should switch to the other envelope to maximize your expected money. However, consider this argument. Let $x$ be the amount of money in the envelope you picked. If $y$ is the amount of money in the other envelope, then the expected value equals $$E(y) = \frac{1}{2}\left(\frac{1}{2}x\right) + \frac{1}{2}\left(2x\right) = \frac{5}{4} x$$ But $5x/4 > x$, so you should switch! The Wikipedia article says that $x$ stands for two different things, so this reasoning doesn't work. I say this is not a valid resolution. Consider opening up the envelope that you pick, and finding $\$10$ inside. Then you can run the expected value calculation to get $$E(y) = \frac{1}{2} \cdot \$5+\frac{1}{2} \cdot \$20 = \$12.50$$ This means that if you open one of the envelopes and find $\$10$, you should switch to the other envelope. The $\$10$ doesn't stand for two different things, it literally just means $\$10$. But you don't have to open up the envelope to run this calculation, you can just imagine what's inside, and run the calculation based on that. This is what ""Let $x$ be the amount in the envelope"" means. The problem with the argument is not that $x$ stands for two different things. So what is the problem? Previous questions on stack exchange have given the resolution that I just said I wasn't satisfied by, so please don't mark this as a duplicate . I want a different resolution, or a more satisfying explanation of why $x$ does stand for two different things. Apparently there is still research being published about this problem - maybe it isn't so obvious? I think there's something subtle wrong with the premise. Because there's no uniform probability distribution on $\mathbb{R}$, statements like ""random real number"" are not well-defined. Likewise, I think ""one envelope has twice as much money as the other"" assumes some probability distribution on $\mathbb{R}$, and perhaps our expected value calculation assumes that this distribution is uniform, which it cannot be ...","['probability', 'paradoxes']"
964387,Euclidean topology on $\mathbb{R}^{m+n}$ is equivalent to the product topology on $\mathbb{R}^m \times \mathbb{R}^n$,"I'm attempting to teach myself topology for graduate school this summer, but I'm having a tough time. 
I'm trying to prove that the Euclidean topology on $\mathbb{R}^{m+n}$ is equivalent to the product topology on $\mathbb{R}^m \times \mathbb{R}^n$. I realize to do this that I should make a homeomorphism between them, and the identity function would work for this, but I'm unsure on what to do from there. Here's what I have so far: 
Let $x \in U \subseteq \mathbb{R}^{m+n}$ be some open set in $\mathbb{R}^{m+n}$, then there exists an open ball $B_{\epsilon}(x) \subseteq U$. But I'm not sure where to go from there. I have read this Product topology and standard euclidean topology over $\mathbb{R}^n$ are equivalent but I do not understand why you are allowed to assume that each of the subsets in $B^1_{\epsilon}(x_i)$ are open in $\mathbb{R}$. thank you","['general-topology', 'product-space']"
964433,Does the series $\sum_{n=1}^{\infty}\sin\left(2\pi\sqrt{n^2+\alpha^2\sin n+(-1)^n}\right)$ converge?,"Let $\alpha$ be such that $0\leq \alpha \leq 1$. Since $\sin n$ has no limit as $n$ tends to $\infty$, I'm having trouble with finding if the series $$\sum_{n=1}^{\infty}\sin \left(2\pi\sqrt{n^2+\alpha^2\sin n+(-1)^n}\right)$$ is convergent? Thanks.","['conditional-convergence', 'sequences-and-series', 'convergence-divergence', 'calculus']"
964438,Integral $\int_0^1\frac{x^{42}}{\sqrt{x^4-x^2+1}}\operatorname d \!x$,"Could you please help me with this integral?
$$\int_0^1\frac{x^{42}}{\sqrt{x^4-x^2+1}} \operatorname d \!x$$ Update: user153012 posted a result given by a computer that contains scary Appel function, and Cleo gave much simpler closed forms for powers $n=42,\,43$. I am looking for a way to prove those forms. I also would like to find a more general result that would work for arbitrary integer powers, not just $42$.","['definite-integrals', 'closed-form', 'calculus', 'integration']"
964472,How many players needed for the game to have the highest probability of finishing the fastest?,"Welcome to the fictional game of ""color-tag""; the not-so-fast-paced cousin of paintball Where marking your opponent is all that counts! If $A$ marks $B$ with his/her color, then $B$ will be permanently marked with $A$'s color,
but at the same time all other people marked with $B$'s color
will instantly be permanently marked with $A$'s color as well. The first one to have marked everyone wins, and the game is finished! $m<x$ where $m = 16$, and the number of players, $x$, is put in a room and assigned an unique color. With every hour that progress, all the players have a probability of $1 - \frac{m}{x}$ of successfully marking another player.
There is no limit as to how many times a player marks another player. In the event that $A$ marks another player, the player, that is being marked, $B$, is chosen at random; Although players cannot mark themselves. Now, I would like to know what the optimal number of players for the game having the highest probability of being the fastest. That is, how many players are needed for the game to have the highest probability of finishing the fastest? Sounds simple enough, right? It turns out that it sounds simpler than it is; At least in my ears. I've tried to warp my head around it, but I fail to find a viable approach. I started out by calculating $(1 - \frac{16}{32} * \frac{1}{32})^{32}$, thinking that $(1 - \frac{m}{x} * \frac{1}{x})^x$
was the way to go about calculating the fastest possible game with respect to the number of players.
I soon realized that there was no way that was going to give me anything near correct results, so
I came up with something along the lines of $\sum_{n=0}^{x-1} ((1 - \frac{m}{x}) * \frac{x-n}{x})^n$, which I hoped would get me somewhere;
But all it did was feed me an absurdly small number and make me realize that I've never been faced with a problem like this, and that I have no idea of how to solve it. Right now, I'm not even considering that I must find the cases with the highest probabilities of success, then cross check to see which is he fastest;
Which I do think is paramount in this problem, alas I know of no way to approach this. Any input (especially tag additions) is greatly appreciated! EDIT 1: Just to make sure there is no confusion:
If a player $A$ and another player $B$ both get to mark an opponent (opponents being all the other players) within a hour, then there is a chance, and it is allowed that $A$ marks $B$, and $B$ marks $A$. Marking another player happens instantaneously and simultaneously.",['probability']
964477,Average value of a bilinear map on a Euclidean sphere,"Let $(V, g = \langle \cdot, \cdot \rangle)$ be a Euclidean vector space and let $B \colon V \times V \to \mathbb{R}$ be a symmetric bilinear form. Denote by $S_r = S(0,r)$ the sphere centered at the origin in $V$ with radius $r > 0$, $\sigma_r$ the volume element on $S_r$ induced from the metric $g$ and $\operatorname{vol}(S_r) = \int_{S_r} \sigma_r$ its volume. How can one prove that: \begin{equation}
 \frac{1}{\operatorname{vol}(S_r)}\int_{S_r} B(x, x) \, \sigma_r = \frac{r^2}{\dim V}\operatorname{tr}_g(B)~.
\end{equation} Here we have denoted by $\operatorname{tr}_g(B)$ the $g$-trace of $B$, i.e. the trace of the $g$-self adjoint endomorphism of $V$ associated to $B$. It is also equal to the 
trace of the matrix representing $B$ in a $g$-orthonormal basis.","['eigenvalues-eigenvectors', 'integration', 'bilinear-form', 'linear-algebra', 'harmonic-functions']"
964489,Need Help setting up a unusual related rates problem (Calc AB),"Currently I am doing a project in my calculus class where we create a related rate problem relating to 2 ideas pulled out of a hat and solve it(mine was a student(s) bored in class and souls). Being a kind of weird combination, the problem I came up with is: A student is sitting in one of the most boring classes in history. The class is so boring, that causes the students soul to be sucked out of his body. Every minute, the student loses 4 soul pieces per boredom level. Starting at a level of 0 boredom, the student becomes more and more bored at a rate of 5 boredom levels per minute. If the student's soul is made of 1000 soul pieces, what rate is the student loosing his soul when he has 700 soul pieces remaining? Originally, I thought I could simply solve this problem using a Pythagorean theorem setup where one side would the total souls, one side would be the boredom [the prime being the rate of it increasing], and my hypotenuse being the lost souls [the prime being the rate of it being lost]. When I started doing the work itself, I got stuck because there was no way to find my base value of the boredom side. My teacher told me that I had to change something in my problem and not use a Pythagorean theorem setup (Because there was no way of proving it was a triangle problem in the first place). Any ideas on what I should change in my problem and what type of problem it would be (shadow, volume, expanding area, etc)? I think I would have to treat this problem just like a velocity problem.","['ordinary-differential-equations', 'calculus']"
964494,Probability help! Am I even doing this right?,"I am really bad with probability, so I just want some explanations and help with this problem (and probably many more to come!) and I also want to know if I am on the right track. Thank you! Lyme disease is a disease carried by ticks, which can be transmitted
to humans by tick bites. Suppose the probability of contracting the disease is 1/100
for each tick bite. a. What is the probability that you will not get the disease when bitten once? I know that the probability of NOT getting the disease is 99/100, so if it is one time you get bitten, then the probability that you will not get the disease when bitten once IS 99/100, right? Since it is only one time. b. What is the probability that you will not get the disease from your first tick bite,
and will the it from your second tick bite? I did (probability of NOT getting the disease) x (probability of getting the disease). So I got (99/100) x (1/100) = 99/10000 as the answer. Am I correct? I think the events are independent from each other.","['statistics', 'probability']"
964511,Calculating Moments,"The following problem is from a Schaum book on statistics. While I thought I did it right, I did not come up with the right answer. Therefore, I am thinking I did something wrong. Problem: Find (a) the moment generating function of the random variable $ x = \begin{cases}
    \, \frac{1}{2} &\text{ prob. 1/2} \\
    -\frac{1}{2} &\text{ prob. 1/2} \\
    \end{cases}
$ and (b) the first four moments about the origin. Answer: The moment generating function for $x$ is: $M_x(t) = E(e^{tx})$ Since $x$ can have only two values, this gives us the following function: $
M_x(t) = \frac{1}{2}e^{\frac{t}{2}} + \frac{1}{2}e^{-\frac{t}{2}}
$ Now to find the first four moments about the origin, I compute the first four
derivatives of $M_x(t)$. $ M_x'(t) = \frac{1}{4}e^{\frac{t}{2}} - \frac{1}{4}e^{-\frac{t}{2}} $ $ M_x''(t) = \frac{1}{8}e^{\frac{t}{2}} + \frac{1}{8}e^{-\frac{t}{2}} $ $ M_x'''(t) = \frac{1}{16}e^{\frac{t}{2}} - \frac{1}{16}e^{-\frac{t}{2}} $ $ M_x''''(t) = \frac{1}{32}e^{\frac{t}{2}} + \frac{1}{32}e^{-\frac{t}{2}} $ Now, let $u_1, u_2, u_3, u_4$ be the first four moments of $x$. $ u_1 = M_x'(0) = \frac{1}{4}e^{\frac{0}{2}} - \frac{1}{4}e^{-\frac{0}{2}} $ $ u_1 = \frac{1}{4} - \frac{1}{4} = 0 $ $ u_2 = M_x''(0) = \frac{1}{8}e^{\frac{0}{2}} + \frac{1}{8}e^{-\frac{0}{2}} $ $ u_2 = \frac{1}{8} + \frac{1}{8} = \frac{1}{4} $ $ u_3 = M_x'''(0) =
    \frac{1}{16}e^{\frac{0}{2}} - \frac{1}{16}e^{-\frac{0}{2}} $ $u_3 = \frac{1}{16} - \frac{1}{16} = 0 $ $ u_4 = M_x''''(0) =
    \frac{1}{32}e^{\frac{0}{2}} + \frac{1}{32}e^{-\frac{0}{2}} $ $ u_4 = \frac{1}{32} + \frac{1}{32} = \frac{1}{16} $ However, the books answer is: $ u_1 = 0 $ $ u_2 = 1 $ $ u_3 = 0 $ $u_4 = 1 $ I do not understand what I am doing wrong and I am hoping that somebody here
can tell me. Thanks
Bob","['statistics', 'probability']"
964534,Proving that all entire and injective functions take the form $f = ax + b$?,"Prove that all entire functions that are also injective take the form $f(z)=az+b$ with $a,b\in\Bbb C$ . Solution: We take $g : \Bbb C^* \to \Bbb C$ , $g( z) = f(1/z)$ , which is holomorphic everywhere except the origin. Now, we try to find out what type of singularity is the origin for $g$ . If the origin is a removable singularity for $g$ , then $g$ is bounded on a closed disk centred at the origin, which implies that $f$ is bounded outside a closed circle containing the origin. But $f$ is bounded on this closed circle, because $f$ is continuous, therefore, $f$ is bounded. Since $f$ is entire and bounded, by Liouville's Theorem, $f$ is constant. This contradicts the injectivity of $f$ . So the origin is not a removable singularity for $g$ . Suppose now that $0$ is an essential singularity for $g$ . Then, by Casorati-Weierstrass Theorem, if we chose a punctured disk centred at the origin $D^*$ , then $g ( D^*)$ is dense in $\Bbb C$ . This implies $f (\{ \lvert z\lvert > r\})$ is dense in $\Bbb C$ . But $f (\{ \lvert z\lvert < r\})$ is open because any holomorphic mapping is an open mapping. Then $f (\{ \lvert z\lvert > r\})\cap f (\{ \lvert z\lvert < r\})\ne \emptyset$ , which is again a contradiction with the injectivity of $f$ . Therefore $0$ is a pole for $g$ . Since the Laurent expansion is unique, and the principal part of $g$ is the same as the analytic part of $f$ , it follows that the analytic part of $f$ has finitely many terms, which implies that $f$ is a polynomial. Since $f$ is injective, the polynomial can have at most one root. Because $f$ is not constant, we conclude that the only expression of $f$ can be of the form $f ( z ) = az + b$ , where $a, b \in \Bbb C$ and $a \ne 0$ . Original text image I'm a little confused at both the overall logic in this proof. Are we simply using $g(z)$ to make conclusions about $f(z)$ , because $g(z)$ is the reciprocal of $f$ ? Is the proof assuming that $f$ is injective and entire (all the while knowing that it has some sort of singularity at $z = 0$ ), and then trying to reach contradictions in the essential singularity and removable singularity cases? Then, once it concludes that $z = 0$ is a pole singularity, it reaches the conclusion that $f$ must be of the form $f(z) = az + b$ ? Also, more specific questions about the different cases: Removable singularity case: Why is $f$ bounded on the closed circle if $f$ is continuous? Am I missing something simple? Essential singularity case: Why exactly is $f(\{|z| > r \} \cap f(\{|z|<r\}) \neq \emptyset$ ? $f(\{|z| > r \})$ is dense, but how does $f(\{|z|<r\}$ being open guarantee that their union is non-empty?",['complex-analysis']
964563,Prove Arrow's Theorem is not true when there are two candidates,"I'm trying to prove the Arrow's Theorem is not true when there are two candidates, however I'm having trouble trying to prove that there is no dictator. I have suggested that in a majority rules voting system, unanimity and IIA are satisfied but I have no idea how to prove that it isn't a dictatorship.",['discrete-mathematics']
964606,"$\lim \limits_{h\to \infty} \left(\frac{f(10+\frac{1}{h})}{f(10)}\right)^h $ given that $ f(10) = 5, f'(10)=2$","Trying to find this limit: 
$\lim \limits_{h\to \infty} \left(\frac{f(10+\frac{1}{h})}{f(10)}\right)^h $
given that $ f(10) = 5, f'(10)=2$. Tried: take the log of the limit, then it becomes 
$\lim \limits_{h\to \infty} h\left(\log\left(f(10+\frac{1}{h})\right)-\log f(10)\right) $ I couldn't find a way to make use of  $f'(10)=2$... Any hint?","['calculus', 'limits']"
964661,Why is the derivative of the arccos the negative derivative of arcsin?,$$ \dfrac{d}{dx} \sin^{-1}x = \dfrac{1}{\sqrt{1-x^2}}$$ $$\dfrac{d}{dx} \cos^{-1}x = - \dfrac{d}{dx} \sin^{-1}x$$ What is the reason for this?,"['trigonometry', 'derivatives']"
964663,shape created by parabola,"What would be the name of the shape that is the set of all points such that they are equidistant from the point $(0,1)$ and to the parabola $y=x^2$. Here is a desmos graph that generates the points. It is basically using the same process that creates a parabola with a focus and a directrix but this directrix is a parabola rather than a line","['geometry', 'conic-sections', 'functions']"
964688,length of intersection of parabolic cylinder and a surface,"Let $C$ be the curve of intersection of the parabolic cylinder $x^2 = 2y$ and the surface $3z = xy$. Find the length of the part of $C$ from $(0, 0, 0)$ to $(6, 18, 36)$.
(Hint: It may be useful to note the identity a
$2 + 4a + 4 = (a + 2)^2$
in the middle of computation.) We were given the solution to this problem. I am given the two equations $x^2=xy$ and $3z=xy$ which are then parameterized into $\langle t,.5t^2,(1/6)t^3\rangle$. I was wondering if someone could help me with this parameterization step.","['multivariable-calculus', 'parametric']"
