question_id,title,body,tags
3972250,Structure of a periodic bijection on the set of bitstrings,"Let $S$ be the set of bitstrings of length $n$ i.e. strings of zeroes and ones. Let these bitstrings be ordered according to Hamming weight (i.e. number of ones in a string) and then by lexicographic order. Let $x\in S$ , let $W(x)=w$ be the Hamming weight of $x$ and we now define a $f:S\to S$ to be such that $f(x)=y$ where $y$ is $\delta=\lfloor\frac{2^n}{n}\rfloor \text{ (mod }2^n)$ places to the right of $x$ in the ordering described above. This defines a bijection on $S$ to itself. I am trying to find the structure of this bijection. Given $n$ and $w$ i.e. all those $x\in S$ s.t. $W(x)=w$ , I am trying to find how many of these bitstrings $x$ are mapped to which weight classes under $f$ . Would the analysis be easier if we choose another $\delta$ ? I am allowed to change $\delta$ with the constraint that it needs to grow exponentially and be $o(2^n)$ where $o(\cdot)$ stands for little-O. So we can choose $\delta=\lfloor\frac{2^n}{n^2}\rfloor$ or something like that if it makes analysis easy. My attempt: Let's say I want to look at the weight classes that bitstrings of $w=1$ are mapped to. Take the first $x$ , in the ordering, s.t. $W(x)=1$ . There are $\binom{n}{w}$ bitstrings for each $w$ . To find $y$ s.t. $f(x)=y$ is complicated because I would need to find $k$ s.t. $$\sum_{i=1}^k \binom{n}{i}<\frac{2^n}{n}<\sum_{i=1}^{k+1} \binom{n}{i}$$ because that would mean $W(y)=k+1$ . But as we know there are known upper bounds for $\sum_{i=1}^k \binom{n}{i}$ and not a precise equality which makes finding such $k$ hard. Any ideas? EDIT: Explicit example of $f$ : Let $n=4$ . If we order the strings first according to weight and then by lexicographic order, then we get this order: $$0,1,2,4,8,3,5,6,9,10,12,7,11,13,14,15$$ where the above numbers are decimal values of bitstrings. Now $\lfloor\frac{2^n}{n}\rfloor = 4$ . So $f(0)=8, f(8)=9, f(9)=11, f(11)=0, f(1)=3, f(3)=10, f(10)=13, f(13)=1, f(2)=5, f(5)=12, f(12)=14, f(14)=2, f(4)=6, f(6)=7, f(7)=15, f(15)=4$","['combinatorics', 'discrete-mathematics']"
3972266,Finding the kernel of homomorphism between two cyclic groups,"I have two cyclic group $\langle G,*\rangle $ with order $7$ and a generator $a\in{G}$ , $\langle H=\{\bar2,\bar4,\bar6,\bar8\},\cdot_{10}\rangle $ . I also have a homomorphism $\phi:G\rightarrow H , $ where $ \phi(a)=\bar8$ . I have tried to see where each power of $a$ maps to and saw that : $$\begin{align}
\phi(a)&=\bar8,\\
\phi(a^2)&=\bar4,\\
\phi(a^3)&=\bar2,\\
\phi(a^4)&=\bar6=e_H,\\
\phi(a^5)&=\bar8,\\
\phi(a^6)&=\bar4,\\
\phi(a^7)&=\bar2
\end{align}$$ I am a bit confused becauase I know that if $\phi$ is homomorphism then the identity element $a^7=e_G$ must map to the identity element of $H$ . But I have $\phi(a^7)=\bar2$ .","['group-homomorphism', 'group-theory', 'cyclic-groups']"
3972343,Change of Variable with Jacobian,"Let $\Omega \subset  \mathbb{R}^m$ be some compactly contained domain in $\mathbb{R}^m.$ Let $Q_t(x) = x+t\zeta$ where $\zeta\in C^{\infty}_c(\Omega, \mathbb{R}^m)$ and $t$ is small enough so that $Q_t$ is a diffeomorphism on $\Omega.$ My goal is to compute, $$\frac{d}{dt}\left(\int_{\Omega} |D(u(x+t\zeta))|^2dx\right)_{|t=0} = \int_{\Omega}\left(\frac{|Du|^2}{2}\operatorname{div}(\zeta) - \partial_{\alpha}u^i \partial_{\beta} u^i \partial_{\beta}\zeta^\alpha\right) dx$$ where $u\in H^{1}(\Omega, \mathbb{R}^n),$ and we implicitly sum over indices $1\leq \alpha, \beta \leq m$ and $1\leq i \leq n.$ I am reading a proof where the author considers the map, $u_t(x)=u(Q_t^{-1}(x))$ and argues that, $$\int_{\Omega} |D(u(x+t\zeta))|^2dx =\int_{\Omega} |Du_t(x)|^2dx.$$ I am not sure how to prove this, I tried change of variable, by setting $y=Q_t(x)$ in the first integral, to get $x=Q_t^{-1}(y)\implies dx = |\det DQ_t^{-1}(y)| dy$ and so, $$\int_{\Omega} |D(u(x+t\zeta))|^2dx = \int_{\Omega} |Du(x+t\zeta) DQ_t(x)|^2 dx \\
=\int_{\Omega} |Du(y)|^2 |DQ_t(Q_t^{-1}(y))|^2 |\det DQ_t^{-1}(y)| dy\\
=\int_{\Omega} |Du(y)|^2 |DQ_t(Q_t^{-1}(y))|^2 |\det DQ_t^{-1}(y)| dy.$$ On the other hand, the author claims that, $$\int_{\Omega} |Du_t(x)|^2dx = \int_{\Omega} |Du(x)|^2 DQ_t^{-1}(Q_t(x))|^2 |\det DQ_t(x)| dx.$$ How do I show that the two expressions are the same?","['multivariable-calculus', 'change-of-variable', 'vector-analysis']"
3972352,Why does the Minus-1 trick to get particular and general solutions work?,"Minus-1 trick: A practical trick where the reduced row-echelon form of a system of equations is augmented with -1 rows. It is used to get particular and general solutions. While it is a handy trick, I was wondering why does it work. The following is an example of the minus-1 trick from the book Mathematics for Machine Learning Book","['matrices', 'linear-algebra']"
3972447,A Combinatorial/Algebraic Solution to Combinatorics Identities Exercise,"The exercise: $$\sum_{k=r}^n {n \choose k} {k \choose r} 2^k = {n \choose r} 2^r 3^{n-r}$$ I have tried everything. Combinatorial proof, differentiating a function to reach both sides, finding patterns of combinatorial identities, binomial coefficient identity and mixtures of all the above. Nothing. One idea which I thought was promising is summing both sides with $\sum_{r=0}^n$ so the right-hand side becomes $5^{n}$ by binomial identity but (a) I'm not sure that is even valid and (b) I couldn't make anything of the left-hand side. Thanks.","['derivatives', 'binomial-coefficients', 'combinatorics', 'combinatorial-proofs']"
3972509,How to prove that this graph is non-planar?,"I'm having trouble proving that the above shown graph is non planar, I think that I have to look for a subdivision of the graph $K_{3,3}$ using Kuratowski's theorem, can someone give me any tips to find this?","['graph-theory', 'discrete-mathematics', 'planar-graphs']"
3972520,Definition of Differentiability (equivalent form),"Suppose $E$ is an open set in $\mathbb R^n$ , $f$ maps $E$ into $\mathbb R^m$ , and $x\in E.$ If there exists a linear transformation $A$ of $\mathbb R^n$ into $\mathbb R^m$ such that $$ \lim_{h\to 0} \frac{|f(x+h)-f(x)-Ah|}{|h|}=0$$ then we say that $f$ is differentiable at $x$ , and we write $$f'(x)=A$$ Question: Can we rewrite the above definition to the following form: $$ f(x+h)-f(x)=f'(x)h + r(h)$$ where the remainder $r(h)$ satisfies $$ \lim_{h\to 0} \frac{|r(h)|}{|h|}=0. $$ If so, how to justify this.","['multivariable-calculus', 'real-analysis']"
3972540,How to solve the matrix equations: $\frac{1}{2}(\Omega Q - Q\Omega)=F$ for $\Omega$,"How to solve the following matrix equation: $$\frac{1}{2}(\Omega Q + Q\Omega^T)=F$$ $Q$ is of rank $1$ , $\text{tr}(Q)=1$ , $Q\succeq0$ (positive semidefinite).  So we can werite $Q = qq^T$ for some $q$ with $\|q\|=1$ . $\Omega$ is skew-symmetric, i.e., $\Omega^{T} = -\Omega$ . So diagonal entries are all $0$ . $\Omega$ , $Q$ , $F$ are $4\times 4$ square matrices. $\Omega$ is the variable I want to solve. I cannot find any method to solve it. Can anyone suggest me how to solve $\Omega$ in terms of $Q$ and $F$ ? Even though we cannot obtain the closed form, any approximation or trick can we use? Thanks! Note: $\Omega$ should look like $$\begin{bmatrix}0 & \omega_3 & -\omega_2 & \omega_1 \\
  -\omega_3 & 0 & \omega_1 & \omega_2 \\
   \omega_2 & -\omega_1 & 0 & \omega_3 \\
   -\omega_1 & -\omega_2 & -\omega_3 & 0 \end{bmatrix}$$","['matrices', 'matrix-equations']"
3972556,An Olympiad Geometry problem with incenter configurations.,"Let the inscribed circle of triangle ABC touches side BC at D ,side CA at E and side AB at F. Let G be the foot of the perpendicular from D to EF. Show that $\frac{FG}{EG} = \frac{BF}{CE}$ . So this problem is equivalent to proving similarity between $\Delta BFG$ and $\Delta CEG$ . I was able to prove that $\angle GFB$ = $\angle GEC$ but after that, I hit a dead end. I found the point $G$ pretty annoying as I couldn't apply any circle theorems to it. Any solution is highly appreciated but I am not very good at inversion and complex numbers so please don't use them.","['contest-math', 'geometry']"
3972632,Problem about system of points and segments in space,"Ii am thinking now about this problem: There are $200$ points in space.  Each two of them are connected by a segment, and the segments do not intersect with each other.  Each segment is colored in one of $K$ colors. Peter wants to paint each point in one of these colors so that there are no two points and a segment between them painted in the same color.  Will Peter always succeed if
a) $K = 7$ ;  b) $K = 10$ ? I know, how to prove a) by induction, but i have no idea about b). $\underline{\text{Proof of a).}}$ Let us prove by induction the following statement: if the number of colors is $n$ and the number of points is at least $2^n$ , then the answer is no. The base ( $n = 1$ ) is obvious. Induction step. Divide the points into two sets, each consisting of at least $2^{n-1}$ points. In each of the sets, color the segments with $n - 1$ colors in accordance with the inductive hypothesis. All the segments connecting points from different sets will be colored with the remaining color.  If in any of the two sets there are no points painted in the last color, then the ""bad"" segment exists by the induction hypothesis. If in both sets there are points of the last color, then the segment connecting them is ""bad"". Can you help me with b)? I will appreciate any ideas for proving.","['induction', 'geometry']"
3972740,Finding roots of an equation dealing complex numbers,"For the equation $z^6
 + 6z + 20 = 0,$ z is a complex number Putting z=x+iy is tiresome . Moreover my question demands to find the roots lying in each quadrant . Is there an easy way out? Edit. The actual statement is
The number of roots in 1st,2nd,3rd ,4th quadrant are","['complex-analysis', 'complex-numbers', 'contest-math']"
3972759,"Is $\max\{-X_{(1)},X_{(n)}\}$ a one dimensional or two dimensional statistic?","Is statistic $\max\{-X_{(1)},X_{(n)}\}$ one dimension or two dimension? I was trying to find the minimal sufficient statistic for $U(-\theta,\theta)$ from $n$ $i.i.d$ random variables $X_i$ . The result is that $\theta\ge \max\{-X_{(1)},X_{(n)}\}$ thus the minimal sufficient statistic is $\max\{-X_{(1)},X_{(n)}\}$ . However, the problem actually states that ""Find a two dimensional minimal sufficient statistic for $U(-\theta,\theta)$ "". Is $\max\{-X_{(1)},X_{(n)}\}$ a two dimensional statistic? Here $X_{(i)}$ is the $i^{th}$ smallest value of $X_1,\cdots,X_n$ .","['statistics', 'sufficient-statistics']"
3972790,How to use Leibniz notation properly,"I think that I didn't understant properly how to use Leibniz notation for derivatives and partial derivatives. I know that: $$\frac{df}{dx}=f'$$ And here I don't have any problem. But then if $g,f$ are two functions, how should I intend: $$\frac{df}{dg}$$ Is it $f'\circ g$ ? Things get worse when we have to work in more variables.Let: $\mathbf{f}:\mathbb{R}^n\to\mathbb{R}^m$ $\mathbf{g}:\mathbb{R}^m\to\mathbb{R}^p$ $\mathbf{\Phi}:=\mathbf{g}   \circ  \mathbf{f}$ $\mathbf{\Phi}(\mathbf{x})=(\Phi_1(\mathbf{x}),...,\Phi_p(\mathbf{x}))$ Here's how I would write the $j$ -th  partial derivative of the $i$ -th component function of $\mathbf{\Phi}$ : $$\frac{\partial \Phi_i}{\partial x_j}(\mathbf{x})=\sum_{k=1}^{m} \left[ \frac{\partial g_i}{\partial x_k}(\mathbf{f}(\mathbf{x}))\right ]\left[\frac{\partial f_k}{\partial x_i}(\mathbf{x})\right ] $$ Or if I want to omit the argument $$\frac{\partial \Phi_i}{\partial x_j}=\sum_{k=1}^{m} \left[ \frac{\partial g_i}{\partial x_k}\circ \mathbf{f}\right ]\left[\frac{\partial f_k}{\partial x_i}\right ] $$ But my book writes it in this way: $$\frac{\partial \Phi_i}{\partial x_j}=\sum_{k=1}^{m}  \frac{\partial g_i}{\partial f_k} \frac{\partial f_k}{\partial x_i} $$ So am I supposed to understand by magic that: $$\frac{\partial g_i}{\partial f_k}:=\frac{\partial g_i}{\partial x_k}\circ \mathbf{f}$$ I know that the formula given by the book is more elegant and synthetic, but when I read it the first time I didn't understand anything.
My question is: Is there a standard convention for this kind of notation?
Because I'm seriously hating this notation, not only because of how unreadable is(to me), but also because all of the ""differential cancellation"" that we make in ODE(but this maybe will be part of a future question). Thank you :)","['partial-derivative', 'multivariable-calculus', 'derivatives']"
3972807,Chromatic number of union of graphs,"I have two graphs, $G$ and $G'$ on the same vertex set $V$ . I have already disproven that $\chi (G\cup G')\leq \chi G + \chi G'$ . Now I have to prove or disprove that $\chi (G\cup G')\leq \chi G \cdot \chi G'$ . I think that it is true, but I don't know how to start proving this. Can someone help me? Thanks!","['graph-theory', 'discrete-mathematics']"
3972831,Why is addition and multiplication associative but not exponentiation and beyond?,"The most similar question I found on math.se was concerning commutativity ( Why are addition and multiplication commutative, but not exponentiation? ). If this ostensibly simple (but not obvious to me) question has already been discussed, please post the link and I apologize for duplicate. I am wondering too how other rules of arithmetic in basic and other algebras (distributivity, transitivity, additive and multiplicative inverses, etc) apply or don't apply to operators and any rhyme to their properties' applicability or hierarchy. associativity of addition: (α+β)+γ ≡ (α+β+γ) := α+β+γ ≡ α+(β+γ) associativity of multiplication: ( a × b )× c := ( ab )⋅ c = abc ≡ a ( bc ) non-associativity of exponentiation: A^B^C := (A^B)^C := $(A^B)^C$ = ${A^B}^C$ ≢ $A^{B^C}$ = $A^{(B^C)}$ := A^(B^C)","['algebra-precalculus', 'arithmetic']"
3972832,Lakers and Bucks arrangements,"I know some of them must be trivial but I have pretty poor knowledge of combinatorics:
We have 5 Lakers players and 7 Bucks and we want to (a) have them seated in a row. My answer: $(7+5)! = 12!$ (b) In a row but with all Lakers to be seated together: We consider the Lakers as one block, so we have 8 ""items"": $8!5!$ . (c) Be seated in a circle: It is $(12-1)! = 11!$ (d) In a circle but with at least 2 Lakers players to be seated together: I am not sure about this one: We treat the pair as one, so we have $10!$ ? (e) In a row, with two Lakers in the first and last position and no two Lakers in consecutive places. I don't know how to calculate this one. Clearly we need to find the arrangement of 10, with no Lakers in starting and ending positions, and no Lakers in consecutive places, multiplied by the number of ways to select 2 out of 5 (which is 20?) (f) In a circle but with no two or more Lakers sitting next to each other. I don't know how to calculate this one (g) In how many ways can we make a subgroup of any 3 players: It is $\binom {12}{12-3}$ (h) a subgroup of size 3 but with exactly 1 Laker player: $\binom {7}{2} \binom {5}{1}$ (i) a subgroup of size 3 but with at least 1 Laker player: $\binom {12}{12-3} - \binom {7}{3}$ ?? Can you please help me with the ones I've got wrong or haven't answered? Thank you!",['combinatorics']
3972834,Is there a category-theoretic generalisation of function application?,"(I'll be using functional programming jargon, because my category theory is not too good). Is the notion of function application, i.e. the application f a of a function f :: a -> b to a value a :: a to yield a value b :: b , peculiar to functions, or is there a more general category-theoretic concept to generalise it?","['functions', 'category-theory']"
3972861,Is completeness over a normed space invariant under linear homeomorphisms?,The question is contained in the title. I know that for metric spaces completeness is not invariant under homeomorphisms. What happens if we consider the same problem in the category of normed spaces with continuous linear maps as morphisms?,"['general-topology', 'functional-analysis']"
3972878,Omega Limit sets for a Gradient system,"I am trying to do the following exercise Let $V: \mathbb{R}^2 \rightarrow \mathbb{R}$ be a $C^2$ function such that the set of equilibrium points is finite. Consider the diferential equation $x'=-\nabla V(x)$ . Show that $V$ has no periodic orbits and no homoclinic orbits, and that for every $x\in \mathbb{R}^n$ if we have that $\omega(x)\neq \emptyset$ then it consists of a single equilibrium point. The first two assertions I was able to do. The first by noticing that $V(x(t_0))-V(x(t_N))=\int_{t_0}^{t_N}\frac{d}{ds}V(x(s)) ds =\int_{t_0}^{t_N}-\nabla V(x(s))^2ds<0$ . The second one since we have that $\frac{d}{dt}V(x(t))<0$ for any solution starting in the homoclinic orbit and if we have that $x_0$ is the equilibrium point associated with the homoclinic orbit then $x_0=\lim_{t_n\rightarrow \infty}x(t_n)=\lim_{t_n\rightarrow -\infty}x(t_n)$ but since we have that $V(x(t))$ is decreasing with time we get that $V(x_0)< V(x(t_0))<V(x_0)$ and hence a contradiction . Now the one I am not being able to do is the third assertion . Let's suppose that $\omega(x)\neq \emptyset $ , and now I would like to see that for $y\in \omega(x)$ then $\nabla V(y)=0$ , and with this I would get that $\omega(x)$ is a compact set since there's a finite number of equilibrium points and hence connceted and so it can only be one. But I am not sure how to see that $\nabla V(y)=0$ . We have that $\nabla V(y)=\lim_{t_n\rightarrow \infty}\nabla  V(x(t_n))$ . Also another idea would be to try and use Poincare Bendixson theorem but I am not sure that $\omega(x)\neq \emptyset$ implies that it is bounded, since there are examples of unbounded $\omega$ -limit sets. Also I don't think we know that the solution is defined on the whole line but I guess we are assuming it, I think for this to be true could ask that $V(x)\geq 0$ and that $V(0)=0.$ Any help with this last is appreciated. Thanks in advance.","['ordinary-differential-equations', 'dynamical-systems']"
3972891,Consequences of Axiom of Choice,"In the proof of Zorn's lemma by Jonathan Lewin published in AMM in 1991, the following reasoning appears: Suppose every chain of a set $\mathcal{P}$ has a strict upper bound in $\mathcal{P}$ (an element strictly greater than all the elements ).Then by Axiom of choice, there exists a function $f$ mapping every chain in $\mathcal{P}$ to its strict upper bound. I am not sure how is this derived directly from Axiom of Choice, which only states there exists some function mapping every chain to its element. Nothing is said about choosing a particular element, and let alone the fact the upper bound is not even an element of the set.
It might be a simple consequence of Axiom of Choice, but this is a new field for me so I would appreciate a detailed explanation.","['elementary-set-theory', 'axiom-of-choice']"
3972937,Bounded subsets (supremum and infimum),"The problem is as follows: Let $S$ and $T$ be nonempty, bounded subsets of the real numbers. Prove that if $T$ contains $S$ , then $\inf T\leq\inf S\leq \sup S\leq\sup T.$ My problem is that I don’t understand why the parent set has the greatest lower bound and the least upper bound. Help. Please and thank you.","['supremum-and-infimum', 'analysis', 'real-analysis']"
3973058,Physics and Ela exam question - Probability,"I had to solve the following questions and I've provided all my work in order to get to the solutions. Could someone let me know whether I have done them properly? Question(s): There are 59 students, out of which 50 are writing the ela exam,
22 are writing a physics exam and 20 are writing both. Round answers to the nearest thousandth. a) determine the probability, that a randomly selected student isn't
writing the ela or physics exam. b) determine the probability, that a randomly selected student is
writing either the ela or the physics exam. c) determine the probability, that a randomly selected student is
writing only the physics exam. established facts: 20 students are taking both exams (given) 30 (50 [ela students] - 20 [ela and physics students]) students are taking the ela exam 2 (22 [physics students] - 20 [ela and physics students]) students are taking the physics exam 7 (59 - [20 + 30 + 2]) students aren't taking either of the tests visuals/different ways of viewing the problem? let E represent the set of ela let P represent the set of physics let B represent the set of both ela and physics E = {30} P = {2} B = {20} or it can also be seen as: My work: a) take the # of students who aren't taking the exams (7) and divide it by the total # of students (59). = 7/59 --> 0.119 b) using the non-mutually exclusive probability formula: P(A∪B) = P(A) + P(B) - P(A∩B) where A is E (for ela) and B is P (for physics) P(E∪P) = P(E) + P(P) - P(E∩P) P(E∪P) =  50  +  22  -   20 P(E∪P) = 52 for the probability: it's just taking P(E∪P) / 59 (total # of people) = 0.881 c) we know that there are only 2 students writing just the physics exam. all we have to do here is take the # of students taking just the physics exam and dividing it by the
total # of students. 2/59 = 0.034","['education', 'discrete-mathematics', 'probability']"
3973084,Find the integer solutions to $4^x - 9^y = 55$,"I want to find the integer solutions of: $$ 4^x - 9^y = 55$$ For now, I see that $x = 3, y = 1$ is an integer solution to the equation. How can I rigorously prove there are no other solutions for $x, y$ integers? I tried to solve for $y$ , but to no avail. WolframAlpha tells me that it is the only solution, but it doesn't provide an explanation.","['exponential-diophantine-equations', 'number-theory', 'algebra-precalculus']"
3973114,How many generator blocks can I fit inside a $3\times3\times3$ cube?,"In my Minecraft world I have a $3\times3\times3$ cube of space which I want to fill with $1\times1\times1$ generator and wire blocks. I can install a single outlet as part of the room's wall; it takes up none of the $3\times3\times3$ space. Each generator block must be connected to the outlet through wires, so for each generator there is always a path of adjacent wire blocks that goes from that generator to the outlet. Diagonal neighbors are not adjacent in this case. The outlet can only be touching one block, it can't be installed on the edge between blocks. I can choose where to place the generators, wires, and outlet. I want to fit as many generators as I can. I can see a way to get $18$ powered generators, if the middle layer is $9$ wire blocks and the top and bottom layers are $9$ and $9$ generator blocks. But I can't tell if this is the maximum possible.","['discrete-optimization', 'geometry', 'packing-problem']"
3973125,How to solve the coupled differential equations with 3 variables?,"I have the following set of differential equations, \begin{aligned}
& x' - \alpha(yz' - zy') =  -\beta(yP_z -zP_y) \\
& y' - \alpha(zx' - xz') =  -\beta(zP_x -xP_z) \\
& z' - \alpha(xy' - yx') =  -\beta(xP_y -yP_x)
\end{aligned} I know how to implement runga kutta 4th order or Euler or Heun's method...what I can't figure out is how to update the $x'$ or $y'$ or $z'$ term while I am solving it. Any help or direction towards possible resources would be appreciated.","['numerical-methods', 'systems-of-equations', 'ordinary-differential-equations']"
3973135,Roots of a matrix equation,"Let $X \in \mathbb{C}^{n \times m} $ be a rectangular matrix of full rank, and $X^*$ its hermitian conjugate, let $A \in \mathbb{C}^{m \times m}$ a square matrix, and let $f: \mathbb{C} \to \mathbb{C}$ be defined by $$
f(z) = \det \left( I_n + X \frac{1}{A - z I_m} X^* \right)
$$ where $I_n$ is the $n \times n$ identity matrix. Show that for $n \leq m$ solutions of $f(z)= 0$ are given by $z$ equal to an eigenvalue of $B : = A + X^* X$ . My attempt: for $n = m$ , $f(z)$ can be straightforwardly rearranged to $$
f(z) = \det \left( X \frac{1}{B-A} \big( B - I_m z \big) \frac{1}{A - z I_m} X^* \right) = \frac{\det(X) \det(B - I_m z) \det(X^*)}{\det(A - z I_m) \det(B - A)}
$$ where the desired result follows from the factor $\det(B - I_m z)$ . However I cannot factorise the determinant in this way for $n < m$ , and I am unsure how to proceed.","['matrices', 'matrix-equations', 'eigenvalues-eigenvectors']"
3973137,What is an open set in a topological space?,"I recently started learning topology to help me understand limits and continuity better for calculus, and I am struggling with some of the definitions. What I am getting confused with is why is every set in a topology considered to be open and when talking about sets in the topology we always say the set is open. My intuitive notion of openness from  previous knowledge of mathematics is an interval that does not contain its endpoints, so there is an infinite sequence at the end points, e.g., $(0,1)$ is an open interval. However, in topology, for example, the singleton $\{1\}$ is considered an open set—how is this so? Why are sets in a topology always open? And what is the definition of an open set in a topological space? Thanks in advance.","['general-topology', 'real-analysis']"
3973177,Convergence almost surely question,"Suppose you have a sequence of independent random variables { $X_i, i\geq1$ }, such that $$\Bbb P(X_i=i^2 -1)=i^{-2},$$ $$ \Bbb P(X_i=-1)=1-i^{-2}.$$ Then, $\frac1n \sum_{i=1}^n X_i$ converges almost surely to a constant c. Find the value of c. For this question, I thought of applying the strong law of large numbers which says: $$ \frac1n \sum_{i=1}^n X_i$$ converges almost surely to $\mu$ , where { $X_i, i\geq1$ } is a sequence of IID random variables whose mean $\mu$ exists. However, for the question above, $\mu=0$ . But c is not equal to $0$ . c is, in fact, equal to -1. Any clarification on this would greatly be appreciated, as I'm not sure how $c=-1$ .","['borel-cantelli-lemmas', 'statistics', 'convergence-divergence', 'probability-theory']"
3973205,Does anyone know some theorem to solve this integral?,"Recently I have been studying calculus and I got stuck with this problem: I already know that the functions $f$ and $g$ are both real functions, defined and continuous in $[a,b]$ , such that \begin{equation}
\int_{a}^{b}f(t)dt=2\int_{a}^{b}g(t)dt.
\end{equation} I need to show that exists $c\in[a,b]$ , such that $f(c)=2g(c)$ . To solve that, I've started doing: \begin{equation}
\int_{a}^{b}f(t)dt=F(b)-F(a)=2[G(b)-G(a)]=2\int_{a}^{b}g(t)dt,
\end{equation} considering $F(t)$ and $G(t)$ antiderivatives for $f(t)$ and $g(t)$ . Multiplying all terms by $\frac{1}{(b-a)}$ , we have: \begin{equation}
\frac{F(b)-F(a)}{b-a}=2\frac{[G(b)-G(a)]}{b-a}.
\end{equation} I don't know the theorem, but I surely know that exists $c\in[a,b]$ such that \begin{equation}
F'(c)=\frac{F(b)-F(a)}{b-a}\Leftrightarrow f(c)=\frac{F(b)-F(a)}{b-a}=2\frac{[G(b)-G(a)]}{b-a},
\end{equation} whitch gives me \begin{equation}
f(c)=2\frac{[G(b)-G(a)]}{b-a}.
\end{equation} I'm almost there, but I feel that I'm missing something. Please, help me.","['integration', 'calculus', 'analysis']"
3973227,Density and distributions of those numerically or analytically KNOWN solutions of Riemann $\zeta(1/2 + r i)=0?$,"We know the conjecture about the Riemann hypothesis is about the nontrivial zeros are on $$(1/2 + r i)$$ for some $r \in \mathbb{R}$ of Riemann zeta function. My question is how much is known about the density and the distributions of those numerically or analytically KNOWN solutions of $$\zeta(1/2 + r i)=0?$$ I found a related post but it was about 8 years ago, so maybe we have a better update? Mean density of the nontrivial zeros of the Riemann zeta function","['complex-analysis', 'number-theory', 'riemann-hypothesis']"
3973239,Formulas's deduction from the generating function of Hermite polynomials,"In the book ""Essential Mathematical Methods for Physicists"" comes the following problem that I am trying to solve: at first I could see that the first formula that is given as an answer is wrong since the hermite polynomial $ H_4 (x) $ does not match with the known since: $\begin{align*}
H_{2n}(x)&=(-1)^{n}\sum_{s=0}^{n}(-1)^{2s}(2x)^{2s}\cfrac{(2n)!}{(2s)!(n-s)!}\\
H_{2n}(x)&=(-1)^{n}\sum_{s=0}^{n}\left[(-1)^{2}\right]^s\left[(2x)^{2}\right]^s\cfrac{(2n)!}{(2s)!(n-s)!}\\
H_{2n}(x)&=(-1)^{n}\sum_{s=0}^{n}\left[1\right]^s\left[4x^2\right]^s\cfrac{(2n)!}{(2s)!(n-s)!}\\
H_{2n}(x)&=(-1)^{n}\sum_{s=0}^{n}\left[4x^2\right]^s\cfrac{(2n)!}{(2s)!(n-s)!}\\
H_{2(2)}(x)&=(-1)^{2}\sum_{s=0}^{2}\left(4x^2\right)^s\cfrac{(2\cdot 2)!}{(2s)!(2-s)!}\\
H_{4}(x)&=(1)\sum_{s=0}^{2}\left(4x^2\right)^s\cfrac{(4)!}{(2s)!(2-s)!}\\
H_{4}(x)&=\sum_{s=0}^{2}\left(4x^2\right)^s\cfrac{24}{(2s)!(2-s)!}\\
H_{4}(x)&=(4x^2)^{0}\cfrac{24}{(2\cdot 0)!(2-0)!}+(4x^2)^{1}\cfrac{24}{(2\cdot 1)!(2-1)!}+(4x^2)^{2}\cfrac{24}{(2\cdot 2)!(2-2)!}\\
H_{4}(x)&=(1)\cfrac{24}{(0)!(2)!}+(4x^2)\cfrac{24}{(2)!(1)!}+(16x^4)\cfrac{24}{(4)!(0)!}\\
H_{4}(x)&=(1)\cfrac{24}{(1)(2)}+(4x^2)\cfrac{24}{(2)(1)}+(16x^4)\cfrac{24}{(24)(1)}\\
H_{4}(x)&=12+(4x^2)(12)+(16x^4)\\
H_{4}(x)&=12+48x^2+16x^4\\
H_{4}(x)&=16x^4+48x^2+12 \\
\end{align*}$ But the real $H_4(x)$ is $H_4(x)=16x^4-48x^2+12$ so the $H_{2n}$ formula is wrong.
But trying to find errors in the formula for $ H_ {2n + 1} $ I did not find any for the polynomials 1,3,5 so I think that this formula is correct. If the generating function of the hermite polynomials is $g (x, t) = e^{-t^2 + 2tx} = \sum_{n = 0} ^ {\infty}H_n (x) \cfrac{t ^ n}{n!} $ How can the formula for $H_{2n + 1}$ be derived? I tried using the formula $H_n(x)=\sum_{s=0}^{[n/2]}(-1)^s\cfrac{n!}{(n-2s)!s!}(2x)^{n-2s}$ (
which is just the equation 13.40 that mentions the problem) substituting in the value of 2n + 1 but couldn't deduce anything, as there were terms that I couldn't adjust to look like the one the book asks for an answer. Any help is really appreciated!","['hermite-polynomials', 'ordinary-differential-equations', 'generating-functions']"
3973247,2-dimensional Lebesgue measure of certain sets in $R^3$,"Let $\theta >0$ and $E \subseteq \mathbb{R}^3$ be a closed set (I've added closedness as a new requirement) which satisfies the following condition: For any $x \in E$ , there exist at least two lines $L_1,L_2 \subseteq E$ passing through $x$ with $\angle(L_1,L_2) \in (\theta, \frac{\pi}{2})$ . I am trying to figure out whether $\mathscr{L}^2(E)>0$ (excluding non-measurable sets). In fact, I can't even come up with 2-dimensional (Hausdorff) sets satisfying the above condition other than 2-planes or a union of them. Would appreciate some suggestions.","['measure-theory', 'lebesgue-measure', 'geometric-measure-theory', 'analysis']"
3973262,Determining whether an operator is positive or not,"Let $T=\int_a^bT_w dw$ , where each $T_w$ is a strictly positive, self-adjoint, compact operators acting on a separable Hilbert space $X$ . Then, I wonder whether T is also a strictly positive operator. That is, its eigenvalues are all strictly positive. I am naturally guessing that the answer is yes, but I cannot prove it. Above all, I do not know how rigorously one can define the operator $T$ given by an integral of operators, which I think should be the starting point of the proof. I am thinking that the other steps would be just simply straightforward if only it is defined rightly. Also, any reference related to this kind of material would be appreciated. Thanks.","['eigenvalues-eigenvectors', 'operator-theory', 'real-analysis', 'hilbert-spaces', 'functional-analysis']"
3973269,"Why use the term ""arbitrary""? [duplicate]","This question already has answers here : When do I use ""arbitrary"" and/or ""fixed"" in a proof? (4 answers) Closed last year . At the beginning of proofs, mathematicians will often write something like: Let $x$ be an arbitrary integer I understand that the point of this statement is to get the reader of the proof to think about ""a new symbol $x$ which represents one of the integers, although the specific integer is unspecified"". Because the specific integer is unspecified, nothing will be assumed about the object represented by $x$ throughout the proof, except that it is an  integer. So the proof will apply for all integers. The above is discussed here: Question about how to interpret arbitrary elements My question is ""Why is the term arbitrary used to invoke the above ideas?"". This is my guess. The term ""arbitrary"" generally means ""done without any reasoning or logic"". So when a mathematician says ""Let $x$ be an arbitrary integer"", they are saying ""Let $x$ be an integer, where the integer is chosen without any reasoning or logic"". Because the integer is chosen withou any reasoning, it is unknown / unspecified. So a reader  will then think about ""a new symbol $x$ which represents one of the integers, although the specific integer is unspecified"". Am I correct in understanding why the term ""arbitrary"" is used? Thank you for your time and please feel free to elaborate.","['proof-writing', 'soft-question', 'discrete-mathematics']"
3973278,How to show this particular $4 \times 4$ matrix is positive definite?,"I am preparing for an exam in Numerical Analysis, and I am solving some practice problems. The question is to show that the following matrix $A$ is positive definite. I would only have about 10 minutes to work on this problem, so I am trying to solve this as fast as possible. We are also told that all the eigenvalues of $A$ are distinct (but this information may not be useful here; there is a part b to this question which might make use of this fact) $$A = \begin{bmatrix}
1 & -1 & 2 & 0\\
-1 & 4 & -1 & 1\\
2 & -1 & 6 & -2\\
0 & 1 & -2 & 4
\end{bmatrix}$$ My Attempts: My first tought is to use Greshgorin's Circle Theorem to show that all the eigenvalues are positive. However, this does not work because  the first Greshgorin disk contains negative reals. My second tought is to use Sylvester's Criterion. This is perhaps doable in under 10 minutes, but it is prone to mistakes (especially when going fast). I am also not sure if Sylvester's Criterion was taught in the class that this problem comes from.","['matrices', 'abstract-algebra', 'linear-algebra', 'numerical-linear-algebra', 'numerical-methods']"
3973283,How to solve $(2k+1)(2k^2+1) = y^2$ over the positive integers,"How could I find a solution to $(2k+1)(2k^2+1) = y^2$ over positive integers? WolframAlpha returns some solutions, but I was wondering if there was a way to find all of them, or prove that there are infinitely many. Here is the link to the Wolfram Alpha answer: https://www.wolframalpha.com/input/?i=solve+%282k%2B1%29%282k%5E2%2B1%29+%3D+y%5E2+over+the+integers This is a personal question inspired by the equation $(k+2)(4k+1) = y^2$ which is doable using elementary methods.","['number-theory', 'elliptic-curves', 'diophantine-equations']"
3973308,When do intermediate fields being Galois imply entire extension is Galois?,"Let $k \subset K$ be Galois. The Fundamental Theorem of Galois Theory gives us a criteria for when any intermediate field $k \subset E \subset K$ is Galois over our base field $k$ . Also, it is in general not true that if $k \subset E$ and $E \subset K$ are both Galois, then $k \subset K$ will be Galois. For example, take $k = \mathbb{Q}, E = \mathbb{Q}[\sqrt{2}]$ , and $K = \mathbb{Q}[\sqrt[4]{2}]$ . However, are there any minimal restrictions we can put on on the extensions $k \subset E \subset K$ such that when $E$ is Galois over $k$ and $K$ is Galois over $E$ that guarantees us $K$ being Galois over $k$ ?","['galois-theory', 'abstract-algebra']"
3973338,How to solve $\sqrt3\sin3x -\cos x =\sqrt2$,$\sqrt3\sin3x -\cos x =\sqrt2$ Does $\sin3x = 3\sin x - 4\sin^3x$ work? $=3\sin x\cos^2x - \sin^3x$ ??? I don't see any factor and next step?,['trigonometry']
3973363,Exterior powers of tensor products,"I am trying to understand Cauchy formula for exterior powers of tensor products. Let $k$ be a characteristic 0 field. Let $E$ and $F$ be two vector spaces over $k$ . Then we have $$ \wedge^d(E\otimes F) \cong \bigoplus_{|\lambda|=d} L_\lambda E \otimes L_{\lambda'}F, \ \text{where $\lambda'$ is dual of $\lambda$}.$$ Here $L_{\lambda}$ is the Schur functor and $L_\lambda E$ is the Schur module. I am following the notations of Weyman's book( Cohomology of vector bundles and syzygies). I am curious in the map of this natural isomorphism. There is a proof given in the Weyman's book but I am unable to understand it. If someone can explain the maps even in $d = 2 \ or \ 3$ case that will work for me. Any ideas\hints are welcome.","['homological-algebra', 'algebraic-geometry', 'representation-theory', 'commutative-algebra']"
3973380,"Deductions for the sets $A = \left\{(-1)^n + \frac{2}{n}:n=1,2,3,\ldots\right\}$ and $B = \{x \in \mathbf{Q}:0<x<1\}$","I would like to ask, if my proof and deductions for the below sets with respect to openness, closure checks out and is technically correct. Exercise 3.2.2 from Understanding Analysis by Stephen Abbot. Let \begin{align*}
	A = \left\{(-1)^n + \frac{2}{n}:n=1,2,3,\ldots\right\}
\end{align*} and \begin{align*}
	B = \{x:\mathbf{Q}:0<x<1\}
\end{align*} Answer the following questions for each set.
(a) What are the limit points?
(b) Is the set open? Closed?
(c) Does the set contain any isolated points?
(d) Find the closure of the set. Proof. (a) Writing out a few elements of the set $A$ , we have: \begin{align*}
	A = \left\{1,2,-\frac{1}{3},\frac{5}{4},-\frac{3}{5},\frac{4}{3},\ldots\right\}
\end{align*} The points $-1$ and $1$ are the limit points of $A$ . There exists a subsequence $a_{2n-1} = -1 + \frac{2}{2n-1}$ in $A$ such that $\lim_{n\to\infty} a_{2n-1} = -1$ and $a_{2n-1} \ne 1$ for all $n \in \mathbf{N}$ . Similarly, look at the subsequence $(a_{2n})$ . $\lim_{n\to\infty} a_{2n} = 1$ . Every real number in $[0,1]$ is the limit of a sequence of rational numbers in $B$ . So, the closed interval $[0,1]$ is the set of all limit points of $B$ . (b) The set $A$ is open. For all $a \in A$ , there exists an $\epsilon$ -neighbourhood of $a$ , $V_\epsilon(a)$ that is contained in $A$ , $V_\epsilon(a) \subseteq A$ . The limit points of $A$ are not elements of the set $A$ . $A$ is not closed. The set $B$ is open. $B$ has no largest or smallest element. For every rational number $x \in B$ , there exists an $\epsilon$ -neighbourhood of $B$ , that intersects $B$ and contains points other than $x$ . The set $B$ is not closed, because $B$ does not contain its limit points. (c) Pick any point $a = (-1)^n + 2/n$ . Let $\epsilon = 2(\frac{1}{n} - \frac{1}{n+1})$ . Then, $V_\epsilon(a) \cap A = \{a\}\ \subseteq A$ . So, every point in $A$ is an isolated point. The set $B$ does not contain any isolated points. (d) \begin{align*}
	\bar{A} &= A \cup \{-1,1\}\\
	\bar{B} &= [0,1]
\end{align*}","['general-topology', 'solution-verification', 'real-analysis']"
3973428,"degree of $f : \mathbb{S}^n \longmapsto \mathbb{S}^n$ with $f(-x) = -f(x)$, where $f \in C^{\infty}$","The question I'm about to ask has been asked several times on MSE but none with an answer that involves only degree theory. I'd like to prove the general case of the exercise in the title without using homology theory, maybe using induction since I managed to prove the case $n=1$ through degree theory on covering spaces, proving that called $\tilde{f}$ the ""covering"", $\tilde{f}$ satisfies $\frac{1}{2\pi}(\tilde{f}(2\pi)-\tilde{f}(0)) = 2k+1$ . For example, for the case $n=2$ , I received an hint to find a regular value whose preimage doesn't intersect the equator line and find an homotpy beetween $f$ and a map with same property. I don't understand very well this idea so I don't even know whether this idea could be applied only to the case $n=2$ since I'm don't see where it's going. Any help or direct proof would be appreciated","['spheres', 'smooth-manifolds', 'covering-spaces', 'general-topology', 'differential-topology']"
3973433,Prove $\sqrt{a_{1}a_{n}}\leq\sqrt[n]{a_{1}a_{2}\cdot...\cdot a_{n}}$,"Let { $a_{n}$ } be an arithmetic sequence with positive terms.
Prove that for any $n \in \mathbb{N}$ $$\sqrt{a_{1}a_{n}}\leq\sqrt[n]{a_{1}a_{2}\cdot...\cdot a_{n}}$$ When proving that using induction, induction step would be if it is true for some n,
we show that $$\sqrt{a_{1}a_{n}a_{n+1}}\leq\sqrt[n+1]{a_{1}a_{2}\cdot...\cdot a_{n}a_{n+1}}$$ or $$\sqrt{a_{1}a_{n+1}}\leq\sqrt[n+1]{a_{1}a_{2}\cdot...\cdot a_{n}a_{n+1}}$$ and why?
Also solutions for this problem are appreciated.","['algebra-precalculus', 'inequality', 'real-analysis']"
3973447,Solutions of the equation $x^x=\frac{1}{256}$,"Find the solutions of the equation $$x^x=\frac{1}{256}$$ I know that the function $f(x)=x^x$ is defined for $x>0$ , so the solutions, if they exists, must be $>0$ ; as far as I know, this is because to maintain the formal properties of power, we must impose that $x>0$ or it is easy to get contradictions like $-1=(-1)^{\frac{2}{2}}=[(-1)^2]^{\frac{1}{2}}=1^{\frac{1}{2}}=1$ . So, since the function $x^x$ has an absolute minimum at $x=\frac{1}{e}$ and it is $\left(\frac{1}{e}\right)^{\frac{1}{e}}>\frac{1}{256}$ , it follows that there isn't an $x>0$ such that $x^x=\frac{1}{256}$ and it follows that the equation hasn't real solutions. However, Wolfram|Alpha says that the equation has the integer solution $x=-4$ and it is indeed a solution, as one can check by substitution. However, for what I said before, the function $x^x$ doesn't exist for $x<0$ and so it can't be evaluated for that value. Why is this happening? Has it something to do with complex numbers? Or finding a solution of that equation is different to consider the function $x^x$ involved? Thank you.","['calculus', 'functions', 'analysis']"
3973468,How to solve $\lim_{n \to \infty}\frac{1}{\sqrt[3]{n^3+n+1}-\sqrt{n^2-n+2}}$ without L'Hopital?,"$\lim_{n \to \infty}\frac{1}{\sqrt[3]{n^3+n+1}-\sqrt{n^2-n+2}}$ $\lim_{n \to \infty}\frac{1}{\sqrt[6]{(n^3+n+1)^2}-\sqrt[6]{(n^2-n+2)^3}}$ but because this limit is still the type of $\frac{1}{\infty-\infty}$ I tried to do this: $\lim_{n \to \infty}\frac{\sqrt[6]{(n^3+n+1)^2}+\sqrt[6]{(n^2-n+2)^3}}{(n^3+n+1)^2-(n^2-n+2)^3} = \lim_{n \to \infty}\frac{\sqrt[6]{(n^3+n+1)^2}+\sqrt[6]{(n^2-n+2)^3}}{3n^5-7n^4+15n^3-17n^2+14n-7}$ I'm totally stuck here. I would divide the fraction by $3n^5$ and then the solution is $0$ . Not the correct answer.
Did I miss something?","['limits', 'calculus', 'limits-without-lhopital', 'radicals']"
3973470,Show that $b_nb_k\mid b_{n+k}$,"Let ${a_n}$ be sequence such that $\forall n,k\in\mathbb{N}, a_n\mid a_{n+k}-a_k$ and, let $b_n=\Pi^{n}_{i=1} a_i$ . Then prove that $\forall n, k\in\mathbb{N}, b_nb_k\mid b_{n+k}$ . $a_i=ci, c\in\mathbb{N}$ satisfies the condition:
I'll prove $m!k!\mid (m+k)!$ . $p\in\mathbb{P}$ , let $\upsilon_p(a)=k\iff p^k\mid\mid a$ . $\forall p\in\mathbb{P}$ , $\upsilon_p(\frac{(m+k)!}{m!k!})=\sum_{i=1}^{\infty}([\frac{m+k}{p^i}]-[\frac{m}{p^i}]-[\frac{k}{p^i}])$ and since $[x+y]\ge [x]+[y]$ , $[\frac{m+k}{p^i}]\ge [\frac{m}{p^i}]+[\frac{k}{p^i}]$ for all $i\implies \forall p\in\mathbb{P}, \upsilon_p(m!k!)\le\upsilon_p((m+k)!)\implies m!k!\mid (m+k)!$ . And I want to prove that there is no more solutions. Can anyone help me?","['contest-math', 'divisibility', 'number-theory', 'elementary-number-theory', 'sequences-and-series']"
3973502,Question about Theorem 3.54 Rudin.,"Let $\sum a_n$ be a conditionally convergent series. Suppose : $$
-\infty \leq \alpha\leq \beta \leq +\infty$$ Then there exist a rearrangement $\sum a'_n$ with partial sums $\{s'_n\}$ such that $$
\lim\limits_{n\to\infty} \inf s'_n=\alpha \quad \quad \lim\limits_{n\to\infty}\sup s'_n=\beta$$ Let $$p_n = \frac{|a_n| + a_n}{2}, \ q_n = \frac{|a_n| - a_n}{2} \ (n = 1, 2, 3, \ldots). $$ Then $p_n - q_n = a_n$ , $p_n + q_n = |a_n|$ , $p_n \geq 0$ , $q_n \geq 0$ . The series $\sum p_n$ , $\sum q_n$ must both diverge. For if both were convergent, then $$\sum \left( p_n + q_n \right) = \sum |a_n|$$ would converge, contrary to hypothesis. Since $$ \sum_{n=1}^N a_n = \sum_{n=1}^N \left( p_n - q_n \right) = \sum_{n=1}^N p_n - \sum_{n=1}^N q_n,$$ divergence of $\sum p_n$ and convergence of $\sum q_n$ (or vice versa) implies divergence of $\sum a_n$ , again contrary to hypothesis. Now let $P_1, P_2, P_3, \ldots$ denote the non-negative terms of $\sum a_n$ , in the order in which they occur, and let $Q_1, Q_2, Q_3, \ldots$ be the absolute values of the negative terms of $\sum a_n$ , also in their original order. The series $\sum P_n$ , $\sum Q_n$ differ from $\sum p_n$ , $\sum q_n$ only by zero terms, and are therefore divergent. We shall construct sequences $\{m_n \}$ , $\{k_n\}$ , such that the series $$ P_1 + \cdots + P_{m_1} - Q_1 - \cdots - Q_{k_1} + P_{m_1 + 1} + \cdots + P_{m_2} - Q_{k_1 + 1} - \cdots - Q_{k_2} + \cdots \tag{25}, $$ which clearly is a rearrangement of $\sum a_n$ , satisfies (24). Choose real-valued sequences $\{ \alpha_n \}$ , $\{ \beta_n \}$ such that $\alpha_n \rightarrow \alpha$ , $\beta_n \rightarrow \beta$ , $\alpha_n < \beta_n$ , $\beta_1 > 0$ . Let $m_1$ , $k_1$ be the smallest integers such that $$P_1 + \cdots + P_{m_1} > \beta_1,$$ $$P_1 + \cdots + P_{m_1} - Q_1 - \cdots - Q_{k_1} < \alpha_1;$$ let $m_2$ , $k_2$ be the smallest integers such that $$P_1 + \cdots + P_{m_1} - Q_1 - \cdots - Q_{k_1} + P_{m_1 + 1} + \cdots + P_{m_2} > \beta_2,$$ $$P_1 + \cdots + P_{m_1} - Q_1 - \cdots - Q_{k_1} + P_{m_1 + 1} + \cdots + P_{m_2} - Q_{k_1 + 1} - \cdots - Q_{k_2} < \alpha_2;$$ and continue in this way. This is possible since $\sum P_n$ , $\sum Q_n$ diverge. If $x_n$ , $y_n$ denote the partial sums of (25) whose last terms are $P_{m_n}$ , $-Q_{k_n}$ , then $$ | x_n - \beta_n | \leq P_{m_n}, \ \ \ |y_n - \alpha_n | \leq Q_{k_n}. $$ Since $P_n \rightarrow 0$ , $Q_n \rightarrow 0$ as $n \rightarrow \infty$ , we see that $x_n \rightarrow \beta$ , $y_n \rightarrow \alpha$ . Finally, it is clear that no number less than $\alpha$ or greater than $\beta$ can be a subsequential limit of the partial sums of (25). Why is $| x_n - \beta_n | \leq P_{m_n}$ ? Why $P_n\to 0$ ? What if $\sum a_n$ converges absolutely? I don't know how this inequality is true but makes sense because it says something like ""By definition $m_n$ is the smallest integer such that $x_n > \beta_n$ "" which might be key to it. I think $P_n\to 0$ is because $a_n\to 0$ but it is still not clear since there might be exception. $\sum a_n$ shouldn't converge absolutely for this theorem makes sense but I don't know why.","['sequences-and-series', 'real-analysis']"
3973505,Finding the derivative of $ \cos(\arcsin x)$,"I study maths as a hobby. I am trying to find the derivative of $ \cos(\arcsin x)$ This is how I have been proceeding: Let u = $\arcsin x$ Then $\sin u = x$ Differentiating: \begin{align}
\cos u \frac{du}{dx} &= 1 \implies \frac{du}{dx} = \frac{1}{\cos u} \\[4pt]
\cos^2 u + \sin^2 u &= 1 \\[4pt]
\cos u &= \sqrt {1 - \sin^2 u} = \sqrt {1 - x^2}
\end{align} But that is as far a I get. The text book says the answer is $\frac{x}{\sqrt {1 - x^2}}$ but I cannot see how this is arrived at.","['calculus', 'trigonometry']"
3973592,"How many ways are there of creating an $8$ character password with a digit, a lowercase letter, and $2$ capital letters? [duplicate]","This question already has answers here : How many ways can you create a password of 10 characters long that has at least one lowercase letter (a-z) and at least one number ($0-9$)? (2 answers) Closed last year . A valid password for the bank's website consists of 8 characters
(digits and letters in English) and must contain at least one digit,
at least one small English letter, and at least two capital letters.
How many legal passwords are there? I considered four sets: $|A|$ = number of ways for no digits appearing in the password = $52^8$ , $|B|$ = number of ways of no small letter in the password = $36^8$ , $|C|$ = number of ways of no capital letter in the password = $36^8$ , $|D|$ = number of ways of only 1 capital letter in the password = $26*36^7$ , and $|U|$ = number of ways of forming the bank's password without restriction  = $62^8$ . Using the formula for inclusion and exclusion for 4 sets $|U| - [ |A| \cup |B| \cup |C|\cup |D|]$ such that $$
\begin{align}
&|A\cup B\cup C\cup D|\\[3pt]
&=|A|+|B|+|C|+|D|\Big\}\text{ all singletons}\\
&-(|A\cap B|+|A\cap C|+|A\cap D|+|B\cap C|+|B\cap D|+|C\cap D|)\Big\}\text{ all pairs}\\
&+(|A\cap B\cap C|+|A\cap B\cap D|+|A\cap C\cap D|+|B\cap C\cap D|)\Big\}\text{ all triples}\\
&-|A\cap B\cap C\cap D|\Big\}\text{ all quadruples.}\\
\end{align}
$$ Now what I'm stuck at is when it comes to triples and quadruples. $|A\cap B\cap C\cap D|$ , to find the number of ways of union of this is kinda contradicting because we have to find a password with no digits, no small letters, no big letters, but only 1 small letter.. or when $|A\cap C\cap D|$ is also contradicting because how we can find number of ways of password with no big letters and also 1 big letter..","['inclusion-exclusion', 'combinatorics']"
3973601,hint on a solved old exam question on probabilistic methods calcualation,"In my note I have some previous exam solved question as follows in Probabilistic methods section: Example: We have $k$ classes $C_1, C_2,...,C_k$ where each $C_i$ has uniform distribution over $-(2^{i-2})<x<2^{i-2}$ . by using maximum likelihood ratio test, then $ \lim_{k\rightarrow \infty} $ P $(error)= \frac{1}{2}$ $ \frac{1}{2}$ is Calculated by following idea: ** My challenge is I couldn't understand the logic of this answer. is
there any intuitive idea to better understand here? **","['statistics', 'probabilistic-method', 'probability-distributions', 'machine-learning', 'computer-science']"
3973610,Continuity & Domain: What Is Their Relationship?,"It's hard for me to formulate this into a specific question, so I'll split this into two sub-questions that will hopefully explain my confusion. Say I have the function $\frac{x}{x}$ . As far as my understanding goes, this guy is discontinuous at $x=0$ , but is continuous at any other point on the real line (with both limits & function values being $1$ ); the limit is $1$ at $x=0$ as well, but the function's value is not (nor is it anything, seeing as it is not defined there), which is why it's not continuous at that point. Assuming the above is true, I can look at $\frac{x}{x}$ as the product of, for instance, $f(x)=x$ and $g(x)=x^{-1}$ , and say that it is discontinuous at $x=0$ simply because the domain of $g$ (and therefore, the domain of the product) does not include $0$ . A discussion I was reading seemed to conclude that, for a function $g(x)$ discontinuous at point $a$ and a continuous function $f(x)$ , the product $f(x) \cdot g(x)$ is discontinuous at $a$ if neither $f(x)$ nor $g(x)$ are $0$ , but is continuous $\forall x \in \mathbb{R}$ (incl. a) if, e.g, $f(x)=0$ for all $x \in R$ . Though, to my understanding, this is only true if the discontinuity isn't caused by a point in which either function is undefined. For example, if $f(x)=0$ and $g(x)=\frac{1}{x}$ , then it would still be wrong of me to say that $f(x) \cdot g(x)$ is continuous at $0$ , because $0$ should be out of its domain. Is this right? And for the second part of the question: I initially began this question with ""Say I have the function $\frac{x}{x}$ over $\mathbb{R}$ "", but then felt extremely unsure about whether I could even say that, seeing as it is not defined at $x=0$ and a function needs to be defined over the entirety of its own domain. In the case of the function mentioned above, the domain must therefore not include $0$ , so it could, for example, be $\mathbb{R} \setminus \{0\}$ . But then this raises another question: I saw a mention of the Dirichlet function being continuous over the rationals; but if this is the case then continuity is domain-dependent, and so if I define $\frac{x}{x}$ over $\mathbb{R} \setminus \{0\}$ , then it is continuous. I can tell there's a difference here: the function is continuous over the entirety of its own domain; but it then gets a bit more confusing when I have a product of two different functions with different domains. Please help me understand the relationship between domain & continuity, and/or point out any inconsistencies in my understanding described above.","['continuity', 'functions', 'real-analysis']"
3973654,Chern classes and curvature of total space,"Let $L$ be a holomorphic line bundle on a compact complex manifold $X$ with $\dim_{\mathbb C} X = n$ . The first Chern class $c_1 (L)$ can be directly related to the curvature of a connection on $L$ by $$
c_1 (L) = \left[ \frac{i}{2 \pi} \Theta \right] \in \mathrm H^2_{\mathrm{dR}} (X)
$$ where $\Theta$ is the curvature form of the connection. Can the first Chern class also be interpreted as some suitable notion of curvature of the total space $M = \mathrm{Tot} (L)$ of the line bundle, which would be a (real) manifold of dimension $2n + 2$ ?","['complex-geometry', 'characteristic-classes', 'curvature', 'differential-geometry']"
3973672,derive eulers integration method from taylor series,"I'm having a hard time understanding how to derive eulers integration method from tayler series expansion I have an ODE and an initial value problem $$
\dfrac{dy}{dt}=f(y,t) 
$$ $$
y(0)=y_{0}
$$ How does this taylor series expansion relate to eulers integration method $$
y(t+h)=y(t)+hy'(t)+\frac{h^2}{2!}y''(t)+\frac{h^3}{3!}y'''....
$$ What exactly is h in this formula? is it that if i know y(0) i can find y(t+h)? i was also given that if h is small i can write $$
y(t+h)=y(t)+hy'(t)+\frac{h^2}{2!}y''(t)+\frac{h^3}{3!}y'''+O(h^4)
$$ Why is that? - i do know that it relates to the truncation error And how do i come from this $$
y(t+h)=y(t)+hy'(t)+\frac{h^2}{2!}y''(t)+\frac{h^3}{3!}y'''+O(h^4)
$$ to this $$
y_{k+1}=y_{k}+h\cdot f(y_{k},t_{k})
$$","['numerical-methods', 'taylor-expansion', 'ordinary-differential-equations']"
3973700,How to prove that $\frac{2^{\sqrt{n}}}{n!}\left(\frac{n}{e}\right)^n$ diverges as $n \rightarrow \infty$?,"Consider the limit $$\lim_{n\to +\infty} \frac{2^{\sqrt{n}}}{n!}\left(\frac{n}{e}\right)^n.$$ How to show that this limit is $+\infty$ ? I just tried square criterion but it doesn’t work. Moreover, Stirling’s formula is not allowed (requested in the assignment). Could anyone please help? Thank you in advance!","['limits', 'functional-analysis', 'real-analysis']"
3973707,Finding infinitely many primes of the form $4k+3$ in a specific sequence,"Question: Let $m$ be a natural number. Show that there exists infinitely many primes $p$ of the form $p=4k+3$ such that $p$ divides at least one integer in the sequence $2^nm+1$ ; $n \in \mathbb{N}$ . My attempt: If $ p \mid 2^nm+1$ for some $n$ , then we have $ m \equiv \frac{-1}{2^n} \pmod{p}$ for some $n$ . This is equivalent to $ m \equiv -2^{n'} \pmod{p}$ for some $n'$ .
Hence, if we can show the existence of infinitely many primes of the form $4k+3$ of the sequence $m+2^n$ , then we will be done. But this didn't seem any easier. Also,I realized that if $2$ is a primitive root modulo some $p$ then that $p$ divides some term of the sequence irrespective of $m$ . But overall I couldn't get anything useful.","['contest-math', 'elementary-number-theory', 'prime-numbers', 'sequences-and-series']"
3973729,Evaluate integral $\int \frac{(2-x^2)e^x}{(1-x)(\sqrt{1-x^2})}dx $,"I tried to solve it by the following method: \begin{align*}
    \int \frac{(2-x^2)e^x}{(1-x)(\sqrt{1-x^2})}dx&= \int \frac{(1-x^2)e^x+\frac{e^x}{2}+\frac{e^x}{2}}{(1-x)(\sqrt{1-x^2}) }dx \\ &= \int \frac{(1-x^2)e^x+\frac{(1-x)e^x}{2}+\frac{(1+x)e^x}{2}}{(1-x)(\sqrt{1-x^2}) }dx \\ &=\int \frac{\sqrt{(1-x^2)}e^x+\frac{\sqrt{(1-x)}e^x}{2\sqrt{x+1}}+\frac{\sqrt{(1+x)}e^x}{2\sqrt{1-x}}}{(1-x) }dx \\&=
    \int \frac{\sqrt{1-x}(\sqrt{x+1}\cdot e^x+\frac{e^x}{2\sqrt{x+1}})+\sqrt{x+1}\cdot e^x \cdot \frac{1}{2\sqrt{1-x}}}{1-x}dx \\&= \int\left(\frac{\sqrt{x+1}\cdot e^x}{\sqrt{1-x}}\right)'dx \\ &=\left(\frac{\sqrt{x+1}\cdot e^x}{\sqrt{1-x}}\right)+C
\end{align*} Is this solution right?
if it is right are there other methods to solve it.","['integration', 'indefinite-integrals', 'solution-verification']"
3973758,$g(x) = \frac{f'(x)}{f(x)}$ not bounded,"Let $f : ]0,1[ \rightarrow ]0,+\infty[$ a differentiable function such that $\lim_{x\to0+} f(x) = 0$ Show that the function $g:]0,1[ \rightarrow \mathbb{R}$ defined by $g(x) = \dfrac{f'(x)}{f(x)}$ is not bounded. I tried a lot of things: I tried the extension by continuity on 0, tried to pass by Mean value theorem and tried to proof by absurd by bounding $g(x)$ but it doesn't lead me anywhere... Thanks for help in advance","['limits', 'functions', 'real-analysis']"
3973794,"Given function π, prove that seg(x) is a well ordered set","(ZF) Let $\langle A,\le \rangle$ be a linear ordered set. Let the function $π : \mathscr{P}(A) \to \mathscr{P}(A)$ be defined by: $$π(X) = \{y ∈ A : \mathrm{seg}(y) \subseteq X\}$$ Prove that $π$ is monotonic and if that $A^*$ is the smallest fixed point of $π$ , then for each $x ∈ A$ the following equivalence holds: $$x \in A^* \iff \langle \mathrm{seg}(x), {\le} \cap(\mathrm{seg}(x)×\mathrm{seg}(x))\rangle \text{ is a well ordered set}$$ What I have in mind is the following: To use Tarsky's theorem about fixed points which states that: if π is a monotonic function, defined in P(A),  there exists a point x in P(A) for which π(x)=x. I will name this point A . Then if I consider π to be a linear operator, I think that I will have to prove that π preserves the order, namely: π(x)<π(y) for x<y. So in this way I will get π to be an increasing function with lower bound π(A )=A . Is it correct, can you please help me to solve this problem?
Thank you in advance!",['elementary-set-theory']
3973796,Method of least squares - solution verification,"I'm homelearning statistics and trying to solve the following problem: We have regression model $\tilde{y}=a \cdot \cos(x)+\varepsilon$ . Therefore $\tilde{y}_k =
 a \cdot \cos(x_k) + \varepsilon_k$ , where $\varepsilon_k \approx N(0,
 \sigma^2), k= \overline{1,n} $ . Calculate an estimate of $\widehat{a}$ using the method of least squares. What is the
expected value of $\tilde{y}_k$ ? What is the dispersion of $\tilde{y}_k$ ? Prove that $\widehat{a}$ is an unbiased estimate and show that the dispersion of $\widehat{a}=\frac{\sigma^2}{\sum_k^n(\cos^2(x_k))}$ . $\varepsilon_k$ is just ""noise"", or a deviation. This is my attempt, can you verify it whether it is correct please? $\hat{a}=\frac{\sum \tilde{y}_i \cdot \cos(x_i)}{\sum \cos^2(x_i)}$ $E\tilde{y}_k=E(a\cos(x_i)+\epsilon_i)=a \cdot \cos(x_i)+E(\epsilon_i)=a \cdot \cos(x_i)$ $D\tilde{y}_i=D(a\cos(x_i)+\epsilon_i)=D(\epsilon_i)=\sigma^2$ $E(\hat{a})=\frac{1}{\sum \cos^2(x)x_i} \cdot E(\sum \tilde{y}_i \cdot \cos(x_i))=\frac{1}{\sum \cos^2(x_i)} \cdot \sum E(\tilde{y}_i \cdot \cos(x_i))=\frac{1}{\sum \cos^2(x_i)} \cdot E(\tilde{y}_i) = \frac{1}{\sum \cos^2(x_i)} \cdot \sum {\cos(x_i)} \cdot a \cdot \cos(x_i)=a \cdot \frac{\sum \cos^2(x_i)}{\sum \cos^2(xi)}=a$ $D(\hat{a})=D\frac{\sum \tilde{a}_i \cdot \cos(x_i)}{\sum \cos^2(x_i)}=\frac{1}{\sum \cos^2(x_i)} \cdot D(\sum \tilde{y_i} \cdot \cos(x_i))=(\frac{1}{\sum \cos^2(x_i)})^2 \cdot \sum D(\tilde{y}_i \cdot \cos(x_i))=(\frac{1}{\sum \cos^2(x_i)})^2 \cdot \sum \cos^2(x_i) \cdot D(\tilde{y}_i)=(\frac{1}{\sum \cos^2(x_1)})^2 \cdot \sum \cos^2(x_i) \cdot \sigma^2=\sigma^2 \cdot \frac{\sum \cos^2(x_i)}{(\sum \cos^2(x_i))^2}=\frac{\sigma^2}{\sum \cos^2 (x_i)}$ Is it correct? Thanks","['regression', 'statistics', 'least-squares']"
3973842,Solving $\sin x\cos5x=\sin ax\cos3x$ without many addition formulas,"I am trying to solve this trigonometric equation (with $a$ a constant) $$\sin(x)\cos(5x)=\sin(ax)\cos(3x)$$ I tried expanding all terms using angle addition, but I got a huge Left and Right hand sides, and apart from the obvious $x=0$ solution,  I can't find the rest. Is there an easy way to solve this? Or is it necessary to do the huge procedure?","['algebra-precalculus', 'trigonometry']"
3973854,Specializing group scheme embedding,"Let $R$ be a DVR with algebraically closed residue field $k$ and fraction field $K$ . Let $f:G\longrightarrow H$ be a morphism of commutative $R$ -group schemes. Suppose that $G$ is an abelian scheme over $R$ and that $f_K$ is an embedding. Then, is $f_k$ injective? Is it an embedding?","['group-schemes', 'algebraic-geometry']"
3974075,Newton's Theorem,"For my Measure & Integration course, I've been asked to prove the following: Let $g$ be a function taking values on $\Bbb{R_+}$ , $f: \Bbb{R}^3 \to \Bbb{R}$ such that $f(x) = g(|x|)$ . Suppose that $f \in L^1(\Bbb{R}^3, dx)$ , and let $$ \Phi(x) = \int_{\Bbb{R}^3} \frac{f(y)}{|x-y|}dy. $$ For all $r=|x| > 0$ , a) Show that $$\Phi(x) = \frac{4π}{r}\int_0^r g(s)s^2\ \mathrm ds+ 4\pi\int_r^{\infty}g(s)s\ \mathrm ds.$$ b) Deduce that $$\Phi(x) = \int_{\Bbb{R}^3} \frac{f(y)}{max\{|x|,|y|\}}\mathrm dy.$$ c) Show that $$\mu\{x: \Phi(x) > t\} < \infty\qquad\text{for all }t>0,$$ where $\mu$ denotes the Lebesgue measure d) Conclude that $\Phi(x) = \Phi^*(x)$ , where $\Phi^*(x)$ is the symmetric decreasing rearrangement of the function $\Phi(x)$ . After a lot of torture I managed to prove part a), but I'm completely stuck on the following parts. Any advice would be very very welcome!","['integration', 'decreasing-rearrangements', 'measure-theory', 'lebesgue-measure']"
3974087,What is the meaning of writing the differential inside of a function?,"I am reading through Resnick's ""Extreme Values, Regular Variation and Point Processes"" and have come across some notation that I am not familiar with. In talking about moving a Poisson point process into higher dimensions, we are introduced to the mean measure function: \begin{align*}
\mu^*(dx, dy)=\mu(dx) K(x, dy),
\end{align*} my question here is strictly about notation like: $\mu(dx)$ . I know the following notation \begin{align*}
\int_\Omega f(x)\mu(dx)=\int_\Omega f(x)d\mu(x)=\int_\Omega fd\mu
\end{align*} and I know that when we write something like \begin{align*}
\int_\Omega f(X, y)K(X, dy)
\end{align*} we are freezing $X$ and integrating with respect to $K$ , viewed now as a function only of $y$ . My question here is, what is meant when we write the differential inside a function, like $\mu(dx)$ , outside of the integral?","['self-learning', 'poisson-process', 'probability-theory', 'probability', 'extreme-value-analysis']"
3974094,Interesting cyclic infinite nested square roots of 2 and cosine values,"It is interesting to note that any angle between 45° to 90° satisfying $1\over4$ < $p \over q$ < $1\over2$ where $ p \over q$ is of form $p = 2^n $ and $q$ is an odd number satisfying $2^{n+1} <q <2^{n+2}$ can be represented as cyclic infinite nested square roots of 2 (Hereafter referred as $cin\sqrt2$ ) refer here for an example of interesting cyclic infinite nested radical Let us consider certain cosine angles with odd numbers starting from 5 and its exponents and see the number of $'+'$ and $'-'$ signs in single cycle $2\cos(\frac{2\pi}{5})=\sqrt{2+2\cos(\frac{4\pi}{5}})=\sqrt{2-2\cos(\frac{\pi}{5}})=\sqrt{2-\sqrt{2+2\cos(\frac{2\pi}{5}}})$ . We can observe expansion goes infinite and results in cyclic infinite nested square roots of 2 for $2\cos(\frac{2\pi}{5})$ or $2\cos72^\circ$ $2\cos\frac{2\pi}{5} = cin\sqrt2[1-1+]$ single cycle contains $1 -$ sign and $1 +$ sign and is simple representation of $\sqrt{2-\sqrt{2+...}}$ $2\cos(\frac{8\pi}{25}) = \sqrt{2+2\cos(\frac{16\pi}{25}}) = \sqrt{2-2\cos(\frac{9\pi}{25}}) = \sqrt{2-\sqrt{2+2\cos(\frac{18\pi}{25}}}) = \sqrt{2-\sqrt{2-2\cos(\frac{7\pi}{25}}}) = \sqrt{2-\sqrt{2-\sqrt{2+2\cos(\frac{14\pi}{25}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-2\cos(\frac{11\pi}{25}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+2\cos(\frac{22\pi}{25}}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-2\cos(\frac{3\pi}{25}}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+2\cos(\frac{6\pi}{25}}}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+2\cos(\frac{12\pi}{25}}}}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+2\cos(\frac{24\pi}{25}}}}}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-2\cos(\frac{\pi}{25}}}}}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2+2\cos(\frac{2\pi}{25}}}}}}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2+\sqrt{2+2\cos(\frac{4\pi}{25}}}}}}}}}}) = \sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+2\cos(\frac{8\pi}{25}}}}}}}}}}})$ Above cycle repeats infinitely $2\cos\frac{8\pi}{25} = cin\sqrt2[4-2+1-3+]$ single cycle contains $5 +$ signs and $5 -$ signs and is simple representation of $\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+...}}}}}}}}}}$ Steps can be simplified as follows. When the angle exceeds $\frac{\pi}{2}$ we are applying the basic cosine angle identity $2\cos(\pi-\theta) = -2\cos(\theta)$ Doubling happens infinitely with $\frac{\pi}{4} < \theta < \pi$ As the denominator in the angle is odd number, when the $\frac{numerator}{denominator} > \frac{1}{2}$ the signs changes while doubling the cosine angle expansion as nested radical. Above steps are programmable. I have created a program to calculate the number of $'+'$ and $'-'$ signs in cyclic infinite nested square roots of 2 for cosine values in Python as follows and anyone can verify which will provide the result for any odd number other than 3 (I am not expert in this) import time
n = int(input(""Enter an odd number to get single cycle cinsqrt2 "")) #odd number is denominator
# steps to calculate numerator as $2^n$ so that fraction lies between 0.25 and 0.5
i = 0
for i in range(n):
    if 2 ** i > n and n < 2 ** (i + 1):
        break
numerator = 2 ** (i - 2)
print(""Numerator is"", numerator)
#print(""The Angle generated is"", (numerator*180)/n, (numerator*180)//n,'+', ((numberator*180)%n)/n)
halfway_of_n = (n - 1) // 2 #to decide the sign, we need halfway number
# print(""Half way to n is"", halfway_of_n)
lst = []
r = numerator * 2
begin = time.time()
while r != numerator:
    if r > halfway_of_n:
        r = n - r
        r = r * 2
        lst = lst + ['-']

    else:
        r = r * 2
        lst = lst + ['+']
lst = lst + ['+']
print(len(lst))
count = lst.count('-')
print('No of minus signs is/are ', count)
count = lst.count('+')
print('No of plus signs is/are ', count)
print(lst) #list containing '+' and '-' signs

end = time.time()

print('Program execution time is', end - begin) $2\cos\frac{32\pi}{125} = cin\sqrt2[2-4+1-1+1-2+2-1+2-1+1-1+2-2+3-1+3-3+1-2+1-1+5-1+1-5+]$ single cycle contains $25 +$ signs and $25 -$ signs and (representing this as a infinite nested radical will be big and occupy big space. Therefore I'm representing in the simplified form as shown above) Exciting pattern emerges for cosine values having exponent of 5 in the denominator and number of + and - signs in the $cin\sqrt2$ which also exponentially growing as follows for $5^1$ in denominator $5^0 + 5^0$ signs in total (in single cycle) for $5^2$ in denominator $5^1 + 5^1$ signs in total (in single cycle) for $5^3$ in denominator $5^2 + 5^2$ signs in total (in single cycle) for $5^4$ in denominator $5^3 + 5^3$ signs in total (in single cycle) and so on Question: Any other way to get these signs inside the nested radicals in a better way?","['nested-radicals', 'elementary-number-theory', 'recreational-mathematics', 'combinatorics', 'trigonometry']"
3974110,Sorting an array to get the maximum combined sum of the differences between every two adjacent elements,"This is related to this question: Stack Overflow Problem description We are given a sequence of n positive integers. How to sort the elements to get the maximum combined sum of the differences between every two adjacent elements. For example, for a sequence {8, 4, 1, 2, 3} the starting difference is (8-4) + (4-1) + (2-1) + (3-2) = 9, but 14 can be reached for {4, 8, 1, 3, 2}. The best arrangement is {4, 1, 8, 2, 3}, sum 17. Claim Optimal solution can always be reached by either starting with the smallest or largest element and then alternately putting currently largest/smallest elements on both sides of the sequence. That's not all yet: for the starting sequence {1, 2, 3, 4} we would start with 4 $\longrightarrow$ 1 4 2 $\longrightarrow$ 3 1 4 2 or 1 4 2 3. So this approach is not strict enough yet. However, if we always first put to the left and then to the right (or otherwise), we are guaranteed that the number on the left side will be smaller/bigger than the corresponding number on the right side. I tested the solution above so I am quite sure it works.
I am interested how would you prove it.","['permutations', 'sorting', 'proof-writing', 'combinatorics', 'discrete-optimization']"
3974111,Evaluate $ \sum_{k=1}^\infty ( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6})$,"I need to evaluate the sum given by: $$\displaystyle \sum_{k=1}^\infty \left( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6} \right)$$ I know that: for $k = 1$ I get: $\frac{1}{7}+\frac{1}{9}+\frac{1}{11}-\frac{1}{8}-\frac{1}{10}-\frac{1}{12}\mathbf{-\frac{1}{14}}$ for $k = 2$ I get: $\frac{1}{13}+\frac{1}{15}+\frac{1}{17}-\frac{1}{16}-\frac{1}{18} \mathbf{-\frac{1}{20}-\frac{1}{22}}$ for $k = 3$ I get: $\frac{1}{19}+\frac{1}{21}+\frac{1}{23}-\frac{1}{24} \mathbf{-\frac{1}{26}-\frac{1}{28}-\frac{1}{30}}$ for $k = 4$ I get: $\frac{1}{25}+\frac{1}{27}+\frac{1}{29} \mathbf{ -\frac{1}{32}-\frac{1}{34}-\frac{1}{36}-\frac{1}{38}}$ I can write that sum for $k = 4$ as: $$ \frac{1}{7}-\frac{1}{8}+\frac{1}{9}-\frac{1}{10}+\frac{1}{11}-\frac{1}{12}+\frac{1}{13} -\frac{1}{14}+\frac{1}{15}-\frac{1}{16}+\frac{1}{17}-\frac{1}{18}+\frac{1}{19}-\frac{1}{20}+\frac{1}{21}-\frac{1}{22}+\frac{1}{23}-\frac{1}{24}+\frac{1}{25}-\frac{1}{26}+\frac{1}{27}-\frac{1}{28}+\frac{1}{29} -\frac{1}{30} \mathbf{ -\frac{1}{32}-\frac{1}{34}-\frac{1}{36}-\frac{1}{38}}$$ And I can write that sum for $k = 8$ as: $$ \frac{1}{7}-\frac{1}{8}+\frac{1}{9}-\frac{1}{10}+\frac{1}{11}-\frac{1}{12}+\frac{1}{13} -\frac{1}{14}+\frac{1}{15}-\frac{1}{16}+\frac{1}{17}-\frac{1}{18}+\frac{1}{19}-\frac{1}{20}+\frac{1}{21}-\frac{1}{22}+\frac{1}{23}-\frac{1}{24}+\frac{1}{25}-\frac{1}{26}+\frac{1}{27}-\frac{1}{28}+\frac{1}{29} -\frac{1}{30} + \frac{1}{31}-\frac{1}{32}+\frac{1}{33}-\frac{1}{43}+\frac{1}{35}-\frac{1}{36}+\frac{1}{37} -\frac{1}{38}+\frac{1}{39}-\frac{1}{40}+\frac{1}{41}-\frac{1}{42}+\frac{1}{43}-\frac{1}{44}+\frac{1}{45}-\frac{1}{46}+\frac{1}{47}-\frac{1}{48}+\frac{1}{49}-\frac{1}{50}+\frac{1}{51}-\frac{1}{52}+\frac{1}{53} -\frac{1}{54} \mathbf{ -\frac{1}{56}-\frac{1}{58} -\frac{1}{60}-\frac{1}{62}-\frac{1}{64}-\frac{1}{66}-\frac{1}{68} -\frac{1}{70}}$$ I see that for every k I get $1$ extra negative element at the end of the sum. I had an idea to rewrite it that way: $$\displaystyle \sum_{k=1}^\infty \left( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6} \right) = $$ $$\displaystyle \sum_{k=1}^\infty \left( (-1)^{n+1}\frac{1}{n} \right) -1+\frac{1}{2}-\frac{1}{3}+\frac{1}{4}-\frac{1}{5}+\frac{1}{6} - \displaystyle \sum_{k=1}^\infty X$$ That way I know that the first sum converges (Dirichlet), but still I don't know how to evaluate that expression. I don't know how to evaluate $\displaystyle \sum_{k=1}^\infty ( (-1)^{n+1}\frac{1}{n}$ ) and I don't know how to include those negative elements in my sum (those are marked as X).","['analysis', 'real-analysis']"
3974229,"If $(E[\int_0^T|f_n(s)|^2ds])_n$ converges, does it exists a subsequence $f_{n(j)}$ such that the integral converges for $t<T$?","Suppose $f, f_1, f_2, \dots: [0, T] \times \Omega \to \mathbb R$ , and that $$
\lim_n \mathrm E\left [  \int_0^T \left |f_n(s, \cdot) \right|^2 ds\right ] \to \mathrm E\left [ \int_0^T \left |f(s, \cdot) \right|^2 ds\right ] < \infty.
$$ Does it follow that for any $0 < t < T$ , there exists a subsequence $n(j)$ such that $$
\lim_j \mathrm E\left [ \int_0^t \left |f_{n(j)}(s, \cdot) \right|^2 ds\right ] \to \mathrm E\left [ \int_0^t \left |f(s, \cdot) \right|^2 ds\right ]\quad ?
$$ If so, how would you prove it? Must grateful for any help provided!","['measure-theory', 'probability-theory', 'stochastic-calculus']"
3974238,$\lim_{n \rightarrow \infty} \frac{(-1)^{n}\sqrt{n}\sin(n^{n})}{n+1}$. Am I correct?,"I have to find this limit: \begin{align} \lim_{n \rightarrow \infty}
 \frac{(-1)^{n}\sqrt{n}\sin(n^{n})}{n+1} \end{align} My attempt: Since we know that $-1\leq \sin (x) \leq 1$ for all $x \in \mathbb{R}$ we have: \begin{align}
\lim_{n \rightarrow \infty} \frac{(-1)^{n}\cdot\sqrt{n}\cdot(-1)}{n+1}\underbrace{\leq}_{\text{Is this fine?}}&\lim_{n \rightarrow \infty} \frac{(-1)^{n}\cdot\sqrt{n}\cdot\sin{(n^{n})}}{n+1} \leq \lim_{n \rightarrow \infty} \frac{(1)^{n}\cdot\sqrt{n}\cdot(1)}{n+1}\\ \\ \lim_{n \rightarrow \infty} \frac{(-1)^{n+1}\cdot\sqrt{n}}{n+1}\leq&\lim_{n \rightarrow \infty} \frac{(-1)^{n}\cdot\sqrt{n}\cdot\sin{(n^{n})}}{n+1} \leq \lim_{n \rightarrow \infty} \frac{\sqrt{n}}{n+1}
\end{align} My doubt in the inequeality is because of the $(-1)$ terms. If everything is correct, then we have \begin{align}
\lim_{n \rightarrow \infty} \frac{(-1)^{n+1}\cdot\sqrt{\frac{1}{n}}}{1+\frac{1}{n}}\leq&\lim_{n \rightarrow \infty} \frac{(-1)^{n}\cdot\sqrt{n}\cdot\sin{(n^{n})}}{n+1} \leq \lim_{n \rightarrow \infty} \frac{\sqrt{\frac{1}{n}}}{1+\frac{1}{n}}\\ \\  \Rightarrow \ \ \ 0 \leq &\lim_{n \rightarrow \infty} \frac{(-1)^{n}\cdot\sqrt{n}\cdot\sin{(n^{n})}}{n+1} \leq 0 \\ \\ \therefore& \lim_{n \rightarrow \infty} \frac{(-1)^{n}\cdot\sqrt{n}\cdot\sin{(n^{n})}}{n+1}=0
\end{align} Am I correct? If I am not, how can I solve it? There are other ways to find this limit? I really appreciate your help!","['limits', 'calculus', 'sequences-and-series']"
3974264,Understanding the derivation of the PDF of a two-point mixed distribution from its CDF,"A random variable $X$ has the cumulative distribution function $$\begin{cases}
0 & x<1 \\
\dfrac{x^2-2x+2}{2} & 1 \le x<2 \\
1 & x\ge 2
\end{cases}$$ Calculate $E[X]$ . The answer uses the following pdf to get $E[X]$ : $$\begin{cases}
\dfrac{1}{2} & x=1 \\
x-1 & 1 < x<2 \\
0 & \text{otherwise}
\end{cases}$$ The book I am reading doesn't have much (any!) information on two-point mixed distributions and I want to make sure that I understand how this PDF was derived from the CDF. My understanding so far is that firstly, we need to figure out from the CDF that $X$ follows a mixed distribution. Note that $F(1) = 1/2 \ne 0$ , which indicates that there is a jump in the CDF of $X$ at $x=1$ . Since $X$ is continuous from $1<x<2$ , $X$ must follow a two-point mixed distribution. Now, the magnitude of the jump in the graph is $\frac{1}{2}-0 = \frac{1}{2}$ which gives $f(x) = \frac{1}{2}$ if $x=1$ . The rest of the pdf can be obtained using routine computations. Finally, we need to compute the probabilistic ""weights"" to get to the CDF. Clearly, the ""weight"" for the discrete part is $\frac{1}{2}$ , so the ""weight"" for the continuous part must be $1-\frac{1}{2} = \frac{1}{2}$ , and we have $$E[X] = \int_1^2 (x-1) \cdot x dx + \text{Weight for the discrete part} \cdot 1 = \int_1^2 x(x-1) dx + P[X=1] \cdot 1$$ $$= \int_1^2 x(x-1) dx + \frac{1}{2}$$ which gives the correct answer. However, I am more interested in learning whether my process for obtaining the answer (which was based mostly on deduction and intuition) is correct. Can someone please critique my post? Thanks!","['statistics', 'probability-distributions', 'solution-verification', 'probability']"
3974270,"Convergence of $\overset{\infty}{\underset{n=1}{\sum}}\dfrac{\log(1+e^{\alpha n})}{1+n^{\alpha}}(x-e^{\alpha})^n$ in $(2,3)$","I have to study for which values $\alpha\in\mathbb R$ , the following sum converges $\forall x\in(2,3)$ : $$\overset{\infty}{\underset{n=1}{\sum}}\dfrac{\log(1+e^{\alpha n})}{1+n^{\alpha}}(x-e^{\alpha})^n.$$ I made a substitution $u=x-e^{\alpha }$ and I've studied the succession $a_n:=\dfrac{\log(1+e^{\alpha n})}{1+n^{\alpha}}$ in order to calculate the radius of convergence of the series $\overset{\infty}{\underset{n=1}{\sum}a_nu^n}$ . Omitting the symbol of limit, I found $\bigg(\dfrac{\log(1+e^{\alpha n})}{1+n^{\alpha}}\bigg)^{\frac{1}{n}}=e^{\log\Big({\Big(\frac{\log(1+e^{\alpha n})}{1+n^{\alpha}}\Big)^{\frac{1}{n}}}\Big)}=e^{\frac{\log(\log(1+e^{\alpha n}))-\log(1+n^{\alpha})}{n}}=e^{\frac{\log(\log(1+e^{\alpha n}))}{n}-\frac{\log(1+n^{\alpha})}{n}}$ . Now I think that, if $\alpha$ is positive, the order of infinity of $n$ is greater than the order of infinity of the $\log$ term. I tried to study the case $\alpha <0$ and I wrote the Taylor's polynomial for $\log(1+e^{\alpha n})$ and $\log(1+n^{\alpha})$ , since $n^{\alpha},e^{\alpha n}\underset{n\to\infty}{\longrightarrow}0$ . The problem is that I don't manage to find a useful condition for the parameter. Furthermore, studying $2<u<3$ , I got the condition $\alpha\in[\log 2,\log3]$ but I can't find other conditions (I know there are other conditions because I know the risult)... Thank you in advance.","['power-series', 'uniform-convergence', 'analysis']"
3974283,"How do we apply chain rule to a function of two variables, which are also functions.","Let $f$ and $g$ be differentiable functions. $$
\frac{\partial}{\partial z}(g(f(x+y),f(z))
$$ How do we apply the chain rule here correctly? Do we just treat $f(x+y)$ and $f(z)$ as some variables $u$ and $v$ ?","['multivariable-calculus', 'derivatives']"
3974300,On deformation of linear combination of linearly independent vectors,"Suppose we have a linearly independent set of vectors $\{v_i\}_{i=1}^n \subset H$ where $H$ is a Hilbert space. Let $$
Q_1 = \sum_{i=1}^n v_i
$$ Consider $\{q_i\}_{i=1}^n \subset \mathbb{C}$ with $|q_i| < 1$ for any $i$ and set $$
Q_2 = \sum_{i=1}^n q_i v_i
$$ Is it true, that $\|Q_2\| \le \|Q_1\|$ ? I thought that it could be prooved somehow by Smith orthogonalization method, but I haven't figured out how. Thank you!","['independence', 'linear-algebra', 'functional-analysis']"
3974309,Distribution of sum of inverses with random signs,"Let $(Z_n)_{n\geq 0}$ be a sequence of i.i.d. random variables with $\mathbb{P}(Z_i=1)=\mathbb{P}(Z_i=-1)=1/2$ . Define $S_n=\sum_{k=1}^nZ_k/k$ . Since $(S_n)_{n\geq 0}$ is a martingale that is bounded in $L^p$ for $p>1$ , it converges a.s. and in $L^p$ to some r.v. $S_\infty$ . Can we determine the distribution of $S_\infty$ ?","['probability-limit-theorems', 'martingales', 'probability-theory', 'probability', 'random-variables']"
3974387,"Convergence of $ \int^\infty \int^\infty \cdots \int^\infty \frac{dx_1 dx_2 \cdots dx_n}{(x_1^2+x_2^2+\cdots+x_n^2)^a}$, where $a > \frac{1}{2} n$.","I want to show that $ \int^\infty \int^\infty \cdots \int^\infty \frac{dx_1 dx_2 \cdots dx_n}{(x_1^2+x_2^2+\cdots+x_n^2)^a}$ converges, where $a > \frac{1}{2} n$ . This problem is from Cambridge Math Tripos 1904. I am not sure why there is no lower bound for this integral. Anyone knows what is the default value for the empty lower bound? I can see if $n = 3$ , we can use the spherical triple integrals to solve the problem. But how do we show that the general case for nth repeated integrals?","['integration', 'improper-integrals', 'real-analysis']"
3974407,Matrix derivative is invertible.,"I'm stuck with the next exercise. Let $f,g:U\subseteq\mathbb{R}^{2}\to\mathbb{R}$ a $C^1$ functions over $U$ . Consider $F:U\subseteq\mathbb{R}^{2}\to\mathbb{R}^{2}$ and $H:U\subseteq\mathbb{R}^{2}\to\mathbb{R}$ defined by $F(x,y)=(f(x,y),g(x,y))$ and $H(x,y)=||F(x,y)||^{2}$ . Prove that for all $x\in U$ , one of the next two conditions is not fulfilled. $H$ attains a local maximum at $x$ The derivative of $F$ at $x$ is invertible, i.e., the matrix $DF(x)$ is invertible. My idea was to proceed by contradiction, i.e., suposse that there exist $x_0\in U$ such that (1) and (2) holds. For this, (1) means that there exist $\varepsilon>0$ such that for all $z\in B(x_0,\varepsilon)\subseteq U$ , $H(z)\leq H(x_0)$ . Moreover, $\nabla H(x_0)=\overline{0}$ . Here, $$\nabla H(x_0)=\left(2 f(x_0)\dfrac{\partial f}{\partial x}(x_0)+2g(x_0)\dfrac{\partial g}{\partial x}(x_0), 2 f(x_0)\dfrac{\partial f}{\partial y}(x_0)+2g(x_0)\dfrac{\partial g}{\partial y}(x_0) \right)=(0,0)$$ By (2), $DF(x_0)$ is an invertible matrix. Then $$DF(x_0)=\begin{pmatrix}
  \dfrac{\partial f}{\partial x}(x_0) & \dfrac{\partial f}{\partial y}(x_0)\\ 
  \dfrac{\partial g}{\partial x}(x_0) & \dfrac{\partial g}{\partial y}(x_0)
\end{pmatrix}$$ Beign invertible, then $\dfrac{\partial f}{\partial x}(x_0)\dfrac{\partial g}{\partial y}(x_0)-\dfrac{\partial f}{\partial y}(x_0)\dfrac{\partial g}{\partial x}(x_0)\neq 0$ .
But, from here, I don't know how to continue. Maybe we can join the two conditions to derive a contradiction, but it's not clear to me. Any hint? Thanks for your help.","['multivariable-calculus', 'calculus']"
3974428,Out of the box & WOW effect Probability,"It is a common knowledge, that problems from graph theory/combinatorics can be often solved via short and
astonishing probabilistic reasoning. In contrast to this, it is much harder to find such ""out of the box""/""WOW effect"" solutions for analysis, topology or algebra problems. So, what are your favorite problems like this, how do you prove them? This question was inspired by a very nice analysis problem: evaluate $ \ \lim_{n\to \infty} e^{-n} \cdot \sum_{k=0}^{n}\frac{n^k}{k!}$ . with the following, extremely beautiful solution: This is $P[N_n\leqslant n]$ where $N_n$ is a random variable with Poisson distribution of parameter $n$ . Hence each $N_n$ is distributed like $X_1+\cdots+X_n$ where the random variables $(X_k)$ are independent and identically distributed with Poisson distribution of parameter $1$ . By the central limit theorem, $Y_n=\frac1{\sqrt{n}}(X_1+\cdots+X_n-n)$ converges in distribution to a standard normal random variable $Z$ , in particular, $P[Y_n\leqslant 0]\to P[Z\leqslant0]$ . Finally, $P[Z\leqslant0]=\frac12$ and $[N_n\leqslant n]=[Y_n\leqslant 0]$ hence $P[N_n\leqslant n]\to\frac12$ , QED. Both, question and solution come from Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$ . I think  that such a list might be helpful for educational purposes. Such problems act on the imagination of students/listeners and much more likely raise their interest.","['big-list', 'analysis', 'soft-question', 'probability-theory', 'probability']"
3974452,How to get the maximum perimeter in a set of straight squares?,"The problem is as follows: Rudy has a toy set which consists of $11$ squares. All of them are equal
in size. The lenght of each edge is equal to $\textrm{1 cm.}$ Assuming
he's been given the instruction to make with those, plane figures that
are made up of squares joined by a complete side. If at the end of the
day he succeeds and builds one such figures whose perimeter is
maximum. What is the value of such perimeter? The alternatives given in my book are as follows: $\begin{array}{ll}
1.&\textrm{24 cm}\\
2.&\textrm{26 cm}\\
3.&\textrm{28 cm}\\
4.&\textrm{22 cm}\\
\end{array}$ I'm not very sure on this question. The situation is that the kid has been given the task to make different figures using 11 squares, given that these must share a full side or in other words two squares must be glued together not counting corners then he succeeds into making those figures. But it just happens that he makes one peculiar figure which has the largest possible perimeter . But how to get that?. My first guess is that the only possible way to make a figure given those conditions is to put the squares one next to each other. Given this it would follow that: $1*11*2+2=24\,cm$ But I don't know if this should be the right answer?. Is it possible to make a larger figure with those requirements?. Is there any way to ensure that's the only way to maximize the perimeter?. Can someone help me here?. Please try to include a figure in the answer I don't know but it seems that this may need it to justify the situation.","['recreational-mathematics', 'geometry']"
3974459,"Given functions $h,k:\Bbb R\to \Bbb R$, is it possible to determine whether $f,g:\Bbb R\to\Bbb R$ exist so that $g\circ f=h$ and $f\circ g=k$?","Let's say I have two functions $h,k:\Bbb R\to \Bbb R$ .  I want to find $f,g:\Bbb R\to \Bbb R$ such that $g\circ f=h$ and $f\circ g=k$ .  I know that $f,g$ might not exist (for example, Functional equation involving composition and exponents ).  Do we know at least a condition for $h,k$ such that $f,g$ exist? Which condition guarantees the uniqueness of $f,g$ (provided that they exist)?  Note that there are $h,k$ such that $f,g$ are not unique. For example, $h=k=0$ , where $f=0$ works and $g$ is any function s.t. $g(0)=0$ .  Or when $h=k$ is the identity function, and we take $f$ to be any bijection and $g=f^{-1}$ . At the very least, what do we know about this problem when $h,k$ are polynomial functions?  Is there a simple test that tells us there are polynomials $f,g$ that satisfy the conditions for a given pair of polynomials $h,k$ ?  Again, what about the uniqueness of polynomial solutions? If the general problem is too hard, I am most interested in this specific problem. I want to find $f,g:\Bbb R\to\Bbb R$ such that $$g\circ f(x)=x^3+1$$ and $$f\circ g(x)=x^3+3x^2+3x+2.$$ Clearly $f,g$ are bijective functions if they exist.  So, can we determine the value of $g\circ f^{-1}(-7)$ ? I found $f,g$ that almost work.  When $f(x)=x^3$ and $g(x)=x+1$ , we have $g\circ f(x)=x^3+1$ but $f\circ g(x)=x^3+3x^2+3x+1$ .  Unfortunately they don't quite work.  I know also that there are no polynomial functions $f,g$ that work. Note that $$f(x^3+1)=f(x)^3+3f(x)^2+3f(x)+2$$ and $$g(x^3+3x^2+3x+2)=g(x)^3+1.$$ $\therefore$ if $a,b$ are the unique real numbers such that $a^3+1=a$ and $b^3+3b^2+3b+2=b$ , we see that $f(a)=b$ and $g(b)=a$ .  These are the only values of $f$ and $g$ that I know.  But I can also see that $$ f^{-1}(-7)=g(-3)$$ if that helps. Let $h(x)=x^3+1$ and $k(x)=x^3+3x^2+3x+2$ .  Due to $f\circ g(x)$ and $g\circ f(x)$ are given; find $f$ and $g$ , if $f=f_0$ and $g=g_0$ satisfy the conditions, then $f=f_0\circ \phi$ and $g=\phi^{-1}\circ g_0$ form a solution for any bijection $\phi:\Bbb R\to\Bbb R$ such that $h\circ \phi=\phi\circ h$ .  Because any iteration of $h$ commutes with $h$ , we can see that there are infinitely many $f$ and $g$ , if $f_0,g_0$ exist.  How do I see whether $f_0,g_0$ exist?","['functional-equations', 'functions', 'function-and-relation-composition']"
3974491,Proof that Effros Borel space is standard,"I have difficulty understanding the proof of Theorem 12.6 in Kechris's Classical Descriptive Set Theory that if $X$ is Polish then the Effros Borel space of $F(X)$ is standard. $F(X)$ consists of all closed sets in $X$ , and I am not giving the definition of Effros Borel space since it is probably not so related to my confusion. The proof proceeds as follows: Let $\overline{X}$ be a compactification of $X$ . Identify $F(X)$ with a subset $G$ of $K(\overline{X})$ , the collection of compact sets in $\overline{X}$ . Prove that $G$ is $G_\delta$ in $K(\overline{X})$ , hence Polish. Carry the topology on $G$ back to $F(X)$ . Prove that Effros Borel space coincides with the topology. I guess in 3 the author implicitly assumes that $K(\overline{X})$ is Polish, which seems to depend on the metrizability of $\overline{X}$ . But why is it metrizable? Certainly not any compactification works, for example the Stone–Čech compactification of $\mathbb{N}$ is not even first countable; I think the one-point compactification of $\mathbb{R}^{\mathbb{N}}$ is not first countable either. Can every Polish space be embedded into some compact metric space?","['general-topology', 'descriptive-set-theory']"
3974499,Why is left multiplication on a group bijective?,"I noticed the fact ""left multiplication on a group is always bijective"" is a very common argument (for instance to prove Sylow's theorem) I don't see why left (and right) multiplication is bijective in general.
All I can see is that left multiplication is an action of a group on itself, so let $G$ be a group: $$\cdot: G \times G \longrightarrow G$$ $$(g,g') \longmapsto g \cdot g'=gg'$$ Properties of group actions hold. I tried to prove this by contradiction but I'm not able to find any useful argument.
Could anyone enlighten me?","['group-actions', 'group-theory', 'abstract-algebra']"
3974503,handshaking lemma and Erdos-Gallai theorem,"The conditions for a sequence to be the degree sequence of a simple graph are given by the Erdos-Gallai theorem in addition to the handshaking lemma . Is there an example of a degree sequence where the handshaking lemma is satisfied, but the Erdos-Gallai theorem is not satisfied and thus, the sequence is not graphic (or vice versa). Or, does satisfying one of these conditions ensure the other is always satisfied?","['graph-theory', 'combinatorics', 'examples-counterexamples']"
3974515,Derivatives with rational numbers,"A definite integral written entirely in terms of rational numbers and functions of rational numbers does not always equal a rational number. For example, with the function $1/x$ , $$
\int_1^2 \frac{dx}{x}  = \ln 2$$ I am curious whether or not this is also true for derivatives. Given a function $f$ for which the image of $\mathbb Q$ is a subset of $\mathbb Q$ , is the image of $\mathbb Q$ under $f'$ always a subset of $\mathbb Q$ ? I have verified that this is true for every function written as a combination of arithmetic operations, but I have not verified it for all rational functions.","['analysis', 'rational-numbers']"
3974541,Right-invariance of a volume form on a compact Lie group,"The following is a question from the second edition of John M. Lee's Introduction to Riemannian Manifolds . 3-9. Suppose $G$ is a compact Lie group with a left-invariant metric $g$ and a left-invariant orientation. Show that the Riemannian volume form $dV_g$ is bi-invariant. [Hint: Show that $dV_g$ is equal to the Riemannian volume form for a bi-invariant metric.] Since $G$ is compact, it admits a bi-invariant metric $\tilde g$ , and with this and the given orientation, we have a volume form $dV_{\tilde g}$ . It's easy to see that $dV_g$ and $dV_{\tilde g}$ are both left-invariant, using the fact that the metrics $g, \tilde g$ and the orientation are left-invariant. Since they are both left-invariant and positive with respect to the given orientation, there is a $c > 0$ such that $dV_g = c dV_{\tilde g}$ . Then $dV_g$ is equal to the Riemannian volume form corresponding to the bi-invariant metric $c^{2/n}\tilde g$ , as the hint suggests. I am having trouble showing that $dV_g$ is also right-invariant; here is my work thus far. Since for any $\varphi \in G$ the forms $R_\varphi^*(dV_g)$ and $dV_g$ are left-invariant, there is a function $f \colon G \to \mathbb{R}^\times$ such that $R_\varphi^*(dV_g) = f(\varphi) dV_g$ . Evaluating both sides at $e$ , one obtains $f(\varphi) = \det(\mathrm{Ad}(\varphi^{-1}))$ , a continuous homomorphism. Since $G$ is compact, $f(G)$ is a compact subgroup of $\mathbb{R}^\times$ , i.e. $f(G) = \{1\}$ or $f(G) = \{\pm 1\}$ . I do not see how to exclude the second case, i.e. if $R_\varphi$ is orientation-reversing for some $\varphi \in G$ . Since $f(e) = 1$ , $f$ is identically $1$ on the identity component of $G$ ; this would finish the problem if $G$ were connected, but unfortunately, it might not be. Since I haven't used the fact that $dV_g$ equals the volume form for a bi-invariant metric yet, I feel it must be used here, but I cannot see how. Some searching reveals this may be related to the idea of left/right-invariant Haar measures and unimodular Lie groups, but my measure theory knowledge is insufficient to understand that material. A small part of me believes that the problem is incorrect without the connectedness hypothesis (e.g. consider the diagonal matrix $A$ with $-1$ and $1$ in $O(2)$ , then $f(A) = -1$ ?), but the errata for the book reveals nothing. Any hints or suggestions on how to proceed with this problem would be appreciated.","['riemannian-geometry', 'lie-groups', 'differential-geometry']"
3974576,Integrate lognormal pdf multiplied by an exponential to find the mean and variance of transmission through a lognormally varying medium,"Seeking to find the mean and standard deviation of two-way transmission of light through a slab whose optical depth is a lognormal random variable.
The expression for the mean is $$\overline T  = \int_0^\infty  {\frac{{\exp \left( { - 2x} \right)}}{{\sqrt {2\pi } \sigma x}}} \exp \left[ { - \frac{{{{\left( {\ln x - \mu } \right)}^2}}}{{2{\sigma ^2}}}} \right]dx$$ where $T = \exp ( - 2x)$ is the two-way transmission, $x$ is the one-way optical depth, $\mu  = \overline {\ln x} $ , and ${\sigma ^2} = {\mathop{\rm var}} \left( {\ln x} \right)$ .  An algebraic solution is desired, but my attempts to solve have been in vain.
An alternative formulation by using $y = \ln x$ is $$\overline T  = \int_{ - \infty }^\infty  {\frac{{\exp \left( { - 2{e^y}} \right)}}{{\sqrt {2\pi } \sigma }}} \exp \left[ { - \frac{{{{\left( {y - \mu } \right)}^2}}}{{2{\sigma ^2}}}} \right]dy$$ The expressions for the second moment of $T$ are the same, except in the integral $ - 2x$ becomes $ - 4x$ , and $ - 2{e^y}$ becomes $ - 4{e^y}$ .","['calculus', 'statistics', 'definite-integrals', 'probability']"
3974666,Showing something is an open two cell (Lee page 134),"In Lee's Introduction to Topological Manifold on page 134, it states that the set $\mathbb{B}^2\setminus \{(x,0): x\in[0,1)\}$ is an open 2-cell. However, I'm not quite sure as to how to define a homeomorphism from $\mathbb{B}^2$ onto the set. ( $\mathbb{B}^2$ is defined to be the open disc in $\mathbb{R}^2$ ).",['general-topology']
3974667,Derive the inequality $x<\arcsin \left(x\right)<\frac{x}{\sqrt{1-x^2}}$,I found that I could do this with the Mean Value theorem and also found a similar question here in the stackexchange and Socratic but couldn't solve the right hand side of the inequality. I figured that by specifically choosing the function and the interval (combinations of the given question) we could prove that. But  I am lost tin selecting the appropriate function. Can you guys please suggest some ideas and also some example sums where I could check these kind of sums. Thanks,"['inequality', 'real-analysis', 'calculus', 'trigonometry', 'algebra-precalculus']"
3974815,Why does the diagonal morphism of a map between affine schemes correspond to the following morphism of rings?,"Suppose I have a morphism of affine schemes $(f, f^\sharp) : \operatorname{Spec} A \to \operatorname{Spec} B$ , then my question is - why does the diagonal morphism $(\Delta_f, \Delta_f^\sharp) : \operatorname{Spec} A \to \operatorname{Spec} A \times_{\operatorname{Spec} B} \operatorname{Spec} A = \operatorname{Spec} (A \otimes_B A)$ correspond the following morphism of rings $\phi : A \otimes_B A \to A$ given by $\phi(a \otimes a') = a\cdot a'$ ? This was my attempt to try and asnwer that.
I know that we have the result that $$\operatorname{Hom}_{\textsf{Sch}}\left(\operatorname{Spec} A, \operatorname{Spec} (A \otimes_B A)\right) \cong \operatorname{Hom}_{\textsf{Ring}}(A \otimes_B A, A)$$ with the bijection given by $(g, g^\sharp) \mapsto g^\sharp_{\operatorname{Spec} A}$ so one possible way to show that the diagonal morphism does correspond to the claimed morphism of rings would be to show that ${\Delta_f}_{_{\operatorname{Spec} A}}^\sharp = \phi$ but I was unable to actually verify this. Another thing I was thinking of was the following. If I let $(p_1, p_1^\sharp) : \operatorname{Spec} (A \otimes_B A) \to \operatorname{Spec} A$ denote the projection map that comes with the fibered product, then we know that $p_1 \circ \Delta_f = 1_{\operatorname{Spec} A}$ the identity map on $\operatorname{Spec} A$ . Now I guess , (but I cannot show), that the morphism $(p_1, p_1^\sharp)$ corresponds to the morphism of rings $\iota : A \to A \otimes_B A$ given by $\iota(a) = a \otimes_B 1_A$ , because then we see that $\phi \circ \iota = 1_A$ the identity map on $A$ . If it were the case that the morphism $(p_1, p_1^\sharp)$ corresponds to $\iota$ , then since taking global sections is a contravariant functor (and really what that bijection above is) I would see that ${\Delta_f}_{_{\operatorname{Spec} A}}^\sharp\circ \iota = 1_A$ as well, but this isn't enough to prove that ${\Delta_f}_{_{\operatorname{Spec} A}}^\sharp = \phi$ . So I have in addition two further follow up questions in addition to the original one: How does one prove that the morphism $(p_1, p_1^\sharp)$ corresponds to $\iota$ ? Is there a more efficient way to prove that a morphism of schemes corresponds to a morphism of rings? If it is relevant, you can assume that the construction of the fibered product I am working with is the same one given in Theorem 3.3 in Hartshorne's book.",['algebraic-geometry']
3974836,Calculate this limit without L'Hôpital's rule.,Calculate $$\lim_{x\to0}\frac{(x+32)^{1/5}-2}{x}$$ without L'Hôpital's rule. My attempt: I first rationalized the expression to get $$\left(\frac{(x+32)^{1/5}-2}{x}\right)\left(\frac{(x+32)^{1/5}+2}{(x+32)^{1/5}+2}\right)=\frac{x+28}{x((x+32)^{1/5}+2)}$$ How should I get rid of the singular $x$ in the denominator now? Should I factor something here?,"['limits', 'calculus', 'limits-without-lhopital']"
3974889,Is pushdown transduction of a periodic sequence periodic?,"Let’s define a pushdown transducer as a 9-tuple $V = (A, B, S, Q_A, Q_S, \phi, \psi, \chi, q_0)$ , where $A$ is the finite input alphabet , $B$ is the finite output alphabet , $S$ is the finite stack alphabet , $Q_A$ are the finite set of read-from-input states , $Q_S$ is the finite set of read-from-stack states , $\phi: (Q_A \times A) \cup (Q_S \times (S \cup \{ \epsilon \})) \to (Q_A \cup Q_S)$ (where $\epsilon \not\in S$ ) - is the state transition function , $\psi: (Q_A \times A) \cup (Q_S \times (S \cup \{ \epsilon \})) \to S^*$ (where $\epsilon \not\in S$ ) is stack transition function , $\chi: (Q_A \times A) \cup (Q_S \times (S \cup \{ \epsilon \})) \to B^*$ (where $\epsilon \not\in S$ ) is output function , $q_0 \in Q_A$ is the initial state . Now, let’s define the total transducer function of $V$ of $V$ as $f_V: A^* \to  (Q_A \cup Q_S) \cup S^* \to B^*$ defined by recurrence relation $$f_V(\Lambda, q, \sigma) = \Lambda$$ $$f_V(a\alpha, q, \Lambda) = \begin{cases} \chi(q, a) f_V(\alpha, \phi(q, a), \psi(q, a)) & \quad q \in Q_A  \\ \chi(q, \epsilon) f_V(\alpha, \phi(q, \epsilon), \psi(q, \epsilon)) & \quad q \in Q_S \end{cases}$$ $$f_V(a\alpha, q, \sigma s) = \begin{cases} \chi(q, a) f_V(\alpha, \phi(q, a),  \sigma s \psi(q, a)) & \quad q \in Q_A \\ \chi(q, s) f_V(\alpha, \phi(q, s), \sigma \psi(q, s)) & \quad q \in Q_S \end{cases}$$ and limited transduction function as $t_V(A^*) = f_V(A^*, q_0, \Lambda)$ . We call a deterministic function $A^* \to B^*$ a finitary pushdown transduction iff it is a limited transduction function of some pushdown transducer. We call a deterministic function $f:A^{\infty} \to B^{\infty}$ an infinitary pushdown transduction iff there exists some finitary pushdown transduction $g: A^* \to B^*$ such that $\forall \alpha \in A^*, \beta \in A^\infty$ we have $f(\alpha \beta) = g(\alpha)f(\beta)$ . Pushdown transducers are a more powerful computation model than finite state transducers, but less powerful than Turing machines. Now, let's say that a sequence $\alpha = a_0 a_1 a_2 ... \in A^\infty$ is ultimately periodic iff $\exists t, k \in \mathbb{N}$ such that $\forall n > t$ we have $a_{n + k} = a_n$ . Now, suppose $\alpha \in A^\infty$ is an ultimately periodic sequence and $f: A^\infty \to B^\infty$ is an infinitary pushdown transduction. Is $f(\alpha)$ also periodic? If $f$ is a regular transduction, then periodicity of $f(\alpha)$ is an easy consequence of pigeonhole principle. However, that proof does not work for pushdown transductions due to the fact that the number of possible contents of the stack is infinite.","['periodic-functions', 'automata', 'discrete-mathematics', 'pushdown-automata']"
3974893,How to transform this periodic boundary value problem to an integral equation?,"While reading this paper , I find this passage interesting, but I dont know how to prove it exactly(I know that It uses Green's function..) ""We study the existence of a solution of the following periodic system: \begin{align}
& u^{\prime}+\lambda_{1} u-\lambda_{2} v=f(t, u)+g(t, v)+\lambda_{1} u-\lambda_{2} v \\
& v^{\prime}+\lambda_{1} v-\lambda_{2} u=f(t, v)+g(t, u)+\lambda_{1} v-\lambda_{2} u
\end{align} together with the periodicity conditions, $$
u(0)=u(T) \quad \text { and } \quad v(0)=v(T)
$$ This problem is equivalent to the integral equations: $$
\begin{align}
u(t)=\int_0^T & G_1(t, s)\left[f(s, u)+g(s, v)+\lambda_1 u-\lambda_2 v\right] \\
& {}+G_2(t, s)\left[f(s, v)+g(s, u)+\lambda_1 v-\lambda_2 u\right] \mathrm{d} s \\
v(t)=\int_0^T & G_{1}(t, s)\left[f(s, v)+g(s, u)+\lambda_1 v-\lambda_2 u\right] \\
& {}+G_2(t, s)\left[f(s, u)+g(s, v)+\lambda_1 u-\lambda_2 v\right] \mathrm{d} s
\end{align}
$$ where $$G_{1}(t, s)=\left\{\begin{array}{ll}
\frac{1}{2}\left[\frac{e^{\sigma_{1}(t-s)}}{1-e^{\sigma_{1} T}}+\frac{e^{\sigma_{2}(t-s)}}{1-e^{\sigma_{2} T}}\right] & 0 \leq s<t \leq T \\
\frac{1}{2}\left[\frac{e^{\sigma_{1}(t+T-s)}}{1-e^{\sigma_{1} T}} + \frac{e^{\sigma_{2}(t+T-s)}}{1-e^{\sigma_{2} T}}\right] & 0 \leq t<s \leq T
\end{array}\right.$$ and $$G_{2}(t, s)=\left\{\begin{array}{ll}
\frac{1}{2}\left[\frac{e^{\sigma_{2}(t-s)}}{1-e^{\sigma_{2} T}}-\frac{e^{\sigma_{1}(t-s)}}{1-e^{\sigma_{1} T}}\right] & 0 \leq s<t \leq T \\
\frac{1}{2}\left[\frac{e^{\sigma_{2}(t+T-s)}}{1-e^{\sigma_{2} T}}-\frac{e^{\sigma_{1}(t+T-s)}}{1-e^{\sigma_{1} T}}\right] & 0 \leq t<s \leq T
\end{array}\right.$$ Here, $ \sigma_{1}=-\left(\lambda_{1}+\lambda_{2}\right)$ and $ \sigma_{2}=\left(\lambda_{2}-\lambda_{1}\right) .$ ""","['integration', 'ordinary-differential-equations']"
3974933,Operation defined on a group uniquely determines that group,"This is an exercise (2.2:3) in An Invitation to General Algebra and Universal Constructions by George M. Bergman: If $G$ is a group, let us define an operation $\delta_{G}$ on $|G|$ by $\delta_{G}(x, y) = xy^{-1}x$ . Does the pair $G' = (|G|, \delta_{G})$ determine the group $(|G|, {}\cdot{} , ^{-1}, e)$ ? (I.e., if $G_1$ and $G_2$ yield the same pair, $G'_1 = G'_2$ , must $G_1 = G_2$ ?) ( $|G|$ means underlying set of a group). If $G'_1 = G'_2$ then they are equal as pairs and that means that $|G_1| = |G_2|$ and $\delta_{G_1} = \delta_{G_2}$ . Let $\circ$ , $^{-1}$ , $e_1$ (resp. $\star$ , $^{'}$ , $e_2$ ) be binary operation, operation of taking inverse and identity operation in group $G_1$ (resp. $G_2$ ). By virtue of $\delta_{G_1} = \delta_{G_2}$ we get $$ x \circ y^{-1} \circ x = x \star y^{'} \star x \tag{1}$$ for every $x, y$ of $|G_1|$ .
Plugging various $x$ and $y$ in $(1)$ we can get following relations of identities: $$ e_1 \star e_1 = {e_2}^{-1} \tag{2}$$ $$ e_2 \circ e_2 = {e_1}^{'} \tag{3}$$ $$ {e_2}^{-1} \star e_1 = {e_2}^{-1} \circ {e_2}^{-1} \tag{4}$$ And I'm stuck with that: can't get any reasonable relation which would allow to get equalitity of identities or equality of inverses or just distributivity between two group operations (to prove that groups are equal).
On the other hand, to disprove that one must find a counterexample e.g. in groups of small order (i.e. two different group structures on the same set giving the same derived operations), but it is tedious.","['universal-algebra', 'group-theory', 'abstract-algebra']"
3974947,Permutation problem of trading dolls,"There are $n$ girls, numbered $1,2,...,n$ . In the morning, each girl has a doll: Girl number $k$ has doll number $k$ . Then, each pair of girls (in some order) traded their dolls. My question is: When is it possible that at the end of the day, each girl will have the doll she started with? Of course that because of permutation pairity arguments, since there were $n \choose 2$ trades, we must have $n \choose 2$ even. Is it enough? Whenever we have $n \choose 2$ even, is it always possible to have any pair of girls trading their dolls such that at the end girl $i$ has doll number $i$ ?","['permutations', 'combinatorics']"
3974975,Counting minimum elements needed such that their sum covers the whole finite space.,"In $\mathbb{F}_p$ , how to find a subset with smallest cardinality such that the sum between its pairs cover $\mathbb{F}_p\setminus\{0\}$ .
So for a subset with cardinality $n$ there are ${n\choose 2}$ pairs and correspondingly ${n\choose 2}$ sums. I want $n$ to be smallest such that those ${n\choose 2}$ sums cover $\mathbb{F}_p\setminus\{0\}$ . For example in $\mathbb{F}_7$ , let $A=\{0,1,2,4\}$ ,
The sums between its pairs covers $\mathbb{F}_7\setminus\{0\}$ since \begin{align*} 
0+1=1,0+2=2,1+2=3,0+4=4,1+4=5,2+4=6\;.
\end{align*} I want to know if over large $p$ similar set can be easily constructed and what would be the size of that set (I expect it to be close to $\sqrt{2p}$ ). Any similar literature is also appreciated.","['finite-fields', 'combinatorics', 'extremal-combinatorics']"
3975025,Cat and Mice puzzle!,"I was studying an Iranian olympiad book problems then I faced a very intersting puzzle, I wanted to solve this but faced lots of problems. I'd like to share this with you and know your mind. We have divided the following figure garden into two areas with fences.We have drawn the fences on a simple and closed curve.
Only three parts of the garden are known and the rest of the garden is covered with trees.
Three cats are waiting for the mice.
All three are in the outer area and can not cross the fence. How many mice might be trapped? (Iranan Math Olympiad).","['graph-theory', 'puzzle', 'geometry']"
3975026,Can you give an example of a continuous function with this property?,"Can you give an example of a continuous function $f:[0, \infty)$ $\to$ $\Bbb R$ such as $\lim_{b\to \infty}$ $\int_0^b{f(x)dx}$ exists but $f$$\notin$ $L^{1}$ ([0, $\infty$ )) ? ( $f$$\notin$ $L^{1}$ ([0, $\infty$ )) means that $f$ is not Lebesgue integrable in that interval)","['functions', 'analysis']"
3975031,Proof of $BAC-CAB$ identity missing step,"I'm stuck on one step of the proof for the identity: $$ \vec{A}\times(\vec{B}\times\vec{C}) = \vec{B}(\vec{A}\cdot\vec{C}) - \vec{C}(\vec{A}\cdot\vec{B})$$ So far, the proof follows as: We know that $\vec{B}\times\vec{C}$ gives a vector perpendicular to both $\vec{B}$ & $\vec{C}$ , and that $ \vec{A}\times(\vec{B}\times\vec{C})$ gives a vector perpendicular to both $\vec{A}$ & $(\vec{B}\times\vec{C})$ . Therefore, the vector $\vec{A}\times(\vec{B}\times\vec{C})$ must lie in the plane containing both $\vec{B}$ & $\vec{C}$ . Provided $\vec{B}$ & $\vec{C}$ are not parallel (if they were, $\vec{A}\times(\vec{B}\times\vec{C}) = 0$ regardless), vectors $\vec{B}$ & $\vec{C}$ span the 2D plane containing them both. Therefore, we can  express any vector in the plane as a linear combination of both $\vec{B}$ and $\vec{C}$ and so we can write: $$\vec{A}\times(\vec{B}\times\vec{C}) = \alpha\vec{B} + \beta\vec{C} \tag{1}$$ Taking the scalar product of both sides with $\vec{A}$ : $$\vec{A} \cdot (\vec{A}\times(\vec{B}\times\vec{C})) = \vec{A} \cdot (\alpha\vec{B} + \beta\vec{C}) = 0$$ So, $$\alpha(\vec{A} \cdot \vec{B}) + \beta(\vec{A} \cdot\vec{C}) = 0$$ Now writing, $$\lambda = \frac{\alpha}{\vec{A} \cdot\vec{C}} = -\frac{\beta}{\vec{A} \cdot \vec{B}}$$ and substituting $\alpha$ and $\beta$ back into (1) we get: $$ \vec{A}\times(\vec{B}\times\vec{C}) = \lambda(\vec{B}(\vec{A}\cdot\vec{C}) - \vec{C}(\vec{A}\cdot\vec{B}))$$ I am able to show $\lambda = 1$ with particular choices of unit vectors for $\vec{A}, \vec{B}, \vec{C}$ but I am unable to prove that $\lambda$ is independent of the magnitude of vectors (i.e. $\lambda = 1$ for all choices of $\vec{A}, \vec{B}, \vec{C}$ ). This is the step that I am struggling with. Any suggestions?","['proof-explanation', 'linear-algebra', 'vectors']"
3975085,Uniform convergence and differentiability of $\frac{nx+x^2}{2n}$ and $\frac{nx^2+1}{2n+x}$,"I have solved the following exercise and I would like to know if I have made any mistakes: Let $g_n(x)=\frac{nx+x^2}{2n}$ and set $g(x)=\lim g_n(x)$ . Show that $g$ is differentiable in two ways: (a) Compute $g(x)$ by algebraically taking the limit as $n\to\infty$ and then find $g'(x)$ . (b) Compute $g'_n(x)$ for each $n\in\mathbb{N}$ and show that the sequence of derivatives $(g'_n)$ converges uniformly on the interval $[-M,M]$ . Conclude $g'(x)=\lim g'_n(x)$ . (c) Repeat parts (a) and (b) for the sequence $f_n(x)=\frac{nx^2+1}{2n+x}$ . My solution: (a) For fixed $x\in\mathbb{R}: \frac{nx+x^2}{2n}=\frac{nx}{2n}+\frac{x^2}{2n}=\frac{x}{2}+\frac{x^2}{2n}\xrightarrow[]{n\to\infty}\frac{x}{2}=:g(x)$ so $g'(x)=\frac{1}{2}$ ; (b) $g'_n(x)=\frac{1}{2}+\frac{x}{n}$ and $|g'_n(x)-\frac{1}{2}|=\frac{|x|}{n}\leq\frac{M}{n}<\varepsilon$ for $n>\frac{M}{\varepsilon}$ so $g'_n$ is uniformly convergent to $\frac{1}{2}$ on each interval $[-M,M]$ and since $0\in [-M,M]$ for every $M\in\mathbb{R}$ and $g_n(0)=0\xrightarrow[]{n\to\infty}0$ , so we can conclude that $g_n$ converges uniformly on $[-M,M]$ and $g=\lim_{n\to\infty} g_n$ is differentiable and satisfies $g'=\lim g'_n$ . (c) For fixed $x\in\mathbb{R}: \frac{nx^2+1}{2n+x}=\frac{1}{2}\frac{x^2 +\frac{1}{n}}{1+\frac{x}{2n}}\xrightarrow[]{n\to\infty}\frac{x^2}{2}=:f(x)$ and $f'(x)=x$ ; $f'_n(x)=\frac{4n^2x+nx^2-1}{(2n+x)^2}$ and $|f'_n(x)-x|=|\frac{x^3+3nx^2+1}{(2n+x)^2}|\leq\frac{x^2 |x+3n|+1}{4n^2}\leq\frac{M^2 (M+3n)+1}{4n^2}\xrightarrow[]{n\to\infty}0$ so $f'_n$ converges uniformly to $x$ on $[-M,M]$ and since $0\in [-M,M]$ and $f_n(0)=\frac{1}{2n}\xrightarrow[]{n\to\infty}0$ so we can conclude that $f_n$ converges uniformly on $[-M,M]$ and $f=\lim f_n$ is differentiable and satisfies $f'=\lim f'_n$ .","['solution-verification', 'derivatives', 'uniform-convergence', 'real-analysis']"
3975113,Is there a direct proof for $\int_0^{2\pi}\frac{r^2+r(\cos t-\sin t)}{1+2r\cos t+r^2}dt=2\pi$,"Is there a direct method to prove that, if $r>1$ $$I=\int_0^{2\pi}\frac{r^2+r(\cos(t)-\sin(t))}{1+2r\cos(t)+r^2}dt=2\pi$$ I ask this question because this integral can be thought as an integral of a 1-form along a circle: $\omega=\frac{x-y}{x^2+y^2}dx+\frac{x+y}{x^2+y^2}dy$ and $\gamma=(1+r\cos(t),r\sin(t))$ for $t\in[0,2\pi]$ and if I'm not mistaken this curve is homotopic to the unit circle centered in $(0,0)$ if $r>1$ , then the integral is equal to the integral along this curve that is $2\pi.$ Is my argument correct?","['integration', 'complex-analysis', 'residue-calculus', 'definite-integrals']"
3975195,Projection to positive Fourier coefficients,"$\newcommand{\A}{A({\mathbb D})}\newcommand{\C}{C({\mathbb T})}$ Let $\C$ the Banach space consisting of all complex
valued, continuous functions on the unit circle $\mathbb T$ under the sup norm.  The disk algebra $\A$ is an intensely
studied  subspace of $\C$ which can be defined in three equivalent ways: The closed subspace of $\C$ spanned by the functions $z\mapsto z^n$ , for $n\geq 0$ . The subset of $\C$ formed by all functions $f$ with vanishing negative
Fourier coefficients,  that is, $$
  \hat f(n)=0,\quad\forall n<0.
  $$ The subset of $\C$ formed by all functions $f$ admitting a continuous extension $\tilde f$ to the closed unit disk $\mathbb D$ ,
such that $\tilde f$ is
holomorphic on the interior of $\mathbb D$ . It is a fact that $\A$ is not complemented in $\C$ in the sense that there is no closed subspace $E\subseteq \C$ such that $$
  \C=\A\oplus E.
  $$ This can be shown to be equivalent to the following statement: There exists a doubly infinite sequence of complex numbers $\{a_n\}_{n=-\infty }^\infty $ , such that $$
  \sum_{n=-\infty }^\infty a_n e^{int}
  $$ is the Fourier series of a continuous, $2 \pi $ -periodic function, while the positive part of this series, namely $$
  \sum_{n=0}^\infty a_n e^{int}
  $$ is not. Question .  What is a concete example  of a sequence $\{a_n\}_{n=-\infty }^\infty $ , as above? NOTES See On projection of fourier series for the corresponding result
regarding $L^\infty(\mathbb T)$ . I found two proofs  of the fact that $\A$ is not complemented in $\C$ , which would in theory be enough to provide an
answer to my question, but I was unable to make it work.  These proofs can be found in: Page 137 of Rudin, Walter , Functional analysis, McGraw-Hill Series in Higher Mathematics. New York etc.: McGraw-Hill Book Comp. XIII, 397 p. (1973). ZBL0253.46001 . Page 55 of Hoffman, K. , Banach spaces of analytic functions, Prentice-Hall Series in Modern Analysis. Englewood Cliffs, N.J.: Prentice-Hall, Inc. XIII, 217 p. (1962). ZBL0117.34001 .","['complex-analysis', 'fourier-series', 'functional-analysis']"
3975207,"Given a finite number of stones. We place every stone on an integer. Prove that, given different movements, we can only make finite number of moves","Given a finite number of stones. We place every stone on an integer (a number $x$ where $x\in Z$ ) and maybe multiple stones on an integer. On each move we can make one of the following movements: Remove a stone from numbers $n-1$ and $n$ and place one stone in integer $n+1$ . Remove $2$ stones from $n$ and place them in integers $n+1$ and $n-2$ . Prove that we can only make finite number moves. I attempted to do it as follows: On each stone we give it the weight $x^n$ where $x^2-x-1=0$ , hence $x=\frac{1+\sqrt{5}}{2}$ . Hence we have that $x^{n-1}(x^2-x-1)=0$ and $x^{n+1}+x^{n-2}-2x^n=x^{n-2}(x^3+1-2x^2)=x^{n-2}(x^2+x+1-2x^2)=x^{n-2}(x+1-x^2)=0$ . Which proves that the total weight of the stones is an invariant. This is as far as I got. I do not know how to finish it off although I do believe that this question is logically solved like this. Could you please explain to me how to solve this question?","['invariance', 'linear-algebra', 'combinatorics', 'algebra-precalculus', 'problem-solving']"
3975230,Change of variable formula for a generic measure applied to classical change of variable formula.,"I was reading this interesting post about changing the variables in an integral with a generic measure. I was wondering how this applies to the standard change of variable. In other words, $$\int_{F(\Omega)} f d\lambda = \int_{\Omega} f \circ F |\det DF| d\lambda
$$ where $d\lambda$ is the lebesgue measure. I think I have to show that $F_{*}(|det DF|\lambda)=\lambda$ (where $F_*$ is the pushforward of measures). In other words, for every $B$ measurable I need to show $|det DF|\lambda(F^{-1}(B))=\lambda(B)$ but I am not sure how to continue.","['measure-theory', 'change-of-variable', 'lebesgue-integral']"
