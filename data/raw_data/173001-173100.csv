question_id,title,body,tags
3077344,Prove weighted ball in $l^2$ space is compact,"Let $B \subseteq l^2$ , $B=\left\{x\in l^2:\sum_{n\geq1}n|x_n|^2\leq1\right\}$ , show that $B$ is compact. My thought: $B$ is closed in $l^2$ which is complete. Then $B$ is complete. It suffices to show $B$ is totally bounded. I think we need to first get rid of the infinite tail sum, i.e., bound all sequences with balls centered at sequences that only have finitely many terms. And then find a ball cover for the finite sequences. But I don't know how to bound the tail sum and I'm stuck.","['general-topology', 'lp-spaces', 'compactness', 'real-analysis']"
3077372,"Trying to solve this triple integral: $\iiint (x-1)(y-1) \,dx\,dy\,dz$","Here's the question $$\iiint (x-1)(y-1) \,dx\,dy\,dz.$$ I am asked to evaluate this integral over the region $$D:=\left \{ (x,y,z) \in\mathbb{R}^3 :x^2+y^2 \leq z \leq 2x+2y+2 \right \}.$$ There are the bounds of integration in set D (the variable $z$ is isolated) and well I tried to find the solution of this integral : \begin{align*}
&\iint_{Pr_{(y,x)}(D)}\int_{x^2+y^2}^{2x+2y+2}(x-1)(y-1) \,dx\, dy\, dz \\
=&\iint_{Pr_{(y,x)}(D)}\int_{x^2+y^2}^{2x+2y+2}(xy-x-y+1) \,dx\, dy\, dz,
\end{align*} and integrate only with respect to $z.$ I have that: \begin{align*}
\int_{x^2+y^2}^{2x+2y+2}(xy-x-y+1) \,dz&=(xy-x-y+1)*(2x+2y+2-(x^2+y^2)) \\
&=3x^2y+3xy^2-2x^3y-2xy^3-3x^2+x^3-2xy-3y^2+y^3+2.
\end{align*} It looks like this way is too long. The second thing that came to mind when I saw the set $D$ was to apply cylindrical coordinates, but this doesn't make easier the left member of the set $D.$ What can I do or what have I done wrong up until now? Any support for this question would be appreciated.","['integration', 'multivariable-calculus', 'spherical-coordinates', 'definite-integrals']"
3077416,Maximum number of ufo that can visit any planet,"Consider an infinite alien 2d world consisting of infinite planet, so that distance between any two planets is not same. Now at some point of time, a ufo leaves each planet and goes to planet nearest to it. Only one ufo leaves each planet. Find the maximum number of ufo that can land on any planet. For this question, I found the critical condition of a hexagon inscribed inside a circle with centre as planet P. Now, in this case all distances are equal. So by intuition, it appears that maximum no of ufo that can land on P should be 5 planets $p_i$ , each lying so as to satisfy constraints. Is my reasoning correct?","['optimization', 'algebra-precalculus', 'puzzle', 'recreational-mathematics']"
3077430,Find cardinality of $X = \left\{ A : A \subset \mathbb R \wedge \text{c}(A) \right\} $,"I have some doubts with this task: Find cardinality of a) $X = \left\{ A : A \subset \mathbb R \wedge \text{c}(A)   \right\} $ b) $X = \left\{ A : A \subset \mathbb Q \wedge \text{c}(A)   \right\} $ where $\text{c}(A)$ means that set contains maximum and minimum element I think that the result is $ \mathfrak{c} $ , so I have decided to show two injectives: $$f:\mathbb R \rightarrow X  $$ and $$g:X \rightarrow \mathbb R  $$ If it comes to $f$ it may be $$ f = \lambda x.\left\{x \right\} $$ and that set contains maximum and minimum element so I think that it is good example (both in a) and b) ). But I am trying to show example of function $g$ and I have stuck there. One idea was to take $$ g = \lambda A. \frac{1}{2}(\min+\max) $$ but it is not injective :(
thanks for your time","['elementary-set-theory', 'cardinals']"
3077434,"Is histogram ""function"" linear?","I was ask to prove/disprove if for two given images $f_1(x,y)$ and $f_2(x,y)$ the histogram of $f_1(x,y)-f_2(x,y)$ and $h_1-h_2$ are equal, where $h_i$ is the histogram of image i. Intuitively it seems to be correct, as if we look at the images as matrices, the histogram is a function that take the matrix values and count the number of repetitions (""losing"" the indices of each value) But is there a proper mathematically proof?","['statistics', 'image-processing']"
3077446,Classification of subalgebras of composition algebras,"Let $F$ be an algebraically closed field. It is known that the only composition algebras over $F$ are $F$ itself, the direct sum $F\oplus F$ (also called split-complexes), the algebra of $2\times 2$ matrices (or split-quaternions) $M_2(F)$ , and Zorn's vector-matrix algebra (or split-octonions) $Zo(F)$ . The elements of these four algebras admit a respective description in terms of $2\times 2$ matrices or generalized versions of such, namely: $$\begin{pmatrix} a & 0 \\ 0 & a\end{pmatrix}, \begin{pmatrix} a & 0 \\ 0 & b\end{pmatrix}, \begin{pmatrix} a & b \\ c & d\end{pmatrix}, \begin{pmatrix} a & (b,c,d) \\ (e,f,g) & h\end{pmatrix},$$ where $a,b,\ldots,h$ are arbitrary elements of $F$ , and in the last case we use the modified matrix multiplication described in this article , which is nonassociative. All four algebras are clearly subalgebras of the biggest one $Zo(F)$ , if we identify any $x$ in the upper-right and lower-left corners with the vector $(x,0,0)$ . There exist other subalgebras (necessarily not composition), namely the dual numbers $F[\varepsilon]$ where $\varepsilon^2=0$ , the upper triangular $2\times 2$ matrices $B_2(F)$ (apparently also called ternions ), and the sextonions $Se(F)$ . A matrix representation for these subalgebras is respectively $$\begin{pmatrix} a & b \\ 0 & a\end{pmatrix}, \begin{pmatrix} a & b \\ 0 & c\end{pmatrix}, \begin{pmatrix} a & (b,c,0) \\ (d,0,e) & f\end{pmatrix}$$ (for the last one see here ). There is yet another subalgebra that I found by trial and error, that I guess we could call the ""quintonions"" $Qui(F)$ . A matrix representation is $$\begin{pmatrix} a & (b,0,0) \\ (0,c,d) & e\end{pmatrix}.$$ My question is Is this list exhaustive? Do there exist any other subalgebras of composition algebras (unital, properly containing $F$ as a subalgebra) not isomorphic to the ones already described ( $F$ , $F[\varepsilon]$ , $F\oplus F$ , $B_2(F)$ , $M_2(F)$ , $Qui(F)$ , $Se(F)$ , $Zo(F)$ )? (By the way, have these quintonions been described anywhere in the literature?)","['octonions', 'reference-request', 'abstract-algebra', 'algebras', 'nonassociative-algebras']"
3077532,what is the difference between $\tan^2 (x)$ and $\tan(x^2)$,"I know $\tan^2(x) \neq \tan(x^2)$ but I can't find an intuitive way to understand $\tan^2(x)$ . When I do it in my mind I think: $\tan^2(x) = \left(\frac{\text{opp}}{\text{adj}}\right)^2$ which I think isn't right, that looks more like $\tan(x^2)$ . Thanks for any tips, this has been rolling in my head for a while.","['algebra-precalculus', 'trigonometry']"
3077571,Understanding the defintion of dual operators,"I'm reading a book about Functional Analysis, and now I've reached to the part about dual operators. I'm having some difficulties understanding the following definition - Why $A^*$ is $Y^*\rightarrow X^*$ ?
We know that $\phi \in Y^*$ , i.e., $\phi:Y\rightarrow Y$ and bounded. So the image of $\phi(Ax)$ should be in $Y^*$ , shouldn't it? How come it's in $X^*$ ? ( $X^*$ is reffered here as the space of all bounded linear functionals on $X$ ).","['operator-theory', 'hilbert-spaces', 'linear-algebra', 'functional-analysis', 'adjoint-operators']"
3077587,When do polynomial equations come from complexification?,"If $f(z) \in \mathbb{C}[z]$ is a polynomial of degree $d$ , then it has $d$ complex zeros. Writing the complexification $$f(x+iy)=u(x,y)+iv(x,y)$$ we observe that the real polynomial system $u(x,y)=v(x,y)=0$ has $d$ real solutions (corresponding to the $d$ complex zeros of $f$ ). Motivating question: if you are given $u(x,y),v(x,y)$ how could you recognize whether they came from a complexification $f(x+iy)$ ? The answer is to check the Cauchy Riemann equations. Actual (and more difficult) question: Suppose you are given new generators $g(x,y),h(x,y)$ for the ideal $\langle u(x,y),v(x,y) \rangle$ (where $u$ and $v$ are the real and imaginary parts of the complexification of a univariate polynomial). 
Although the solutions $g=h=0$ are the same as $u=v=0$ , you can check that $g(x,y),h(x,y)$ (generically) do not satisfy the Cauchy-Riemann equations. 
Now how can one tell when $g(x,y),h(x,y)$ came about in this fashion? and thus be able to tell immediately that they have real common solutions?","['complex-analysis', 'polynomials', 'real-algebraic-geometry']"
3077607,Proof verification that $\overline{\mathbb{R}^{\infty}} = \mathbb{R^\omega}$ and $\overline{\mathbb{R}^{\infty}} = \mathbb{R^\infty}$ in prod/box top.,"I want  to rid myself of any misunderstandings I have, so feel free to nitpick my attempt all you want so that in the end it's as clear as possible! Now, this is the exercise: \begin{array} { l } { \text { Let } \mathbb { R } ^ { \infty } \text { be the subset of } \mathbb { R } ^ { \omega } \text { consisting of all sequences that are ""eventually zero,"" } } \\ { \text { that is, all sequences } \left( x _ { 1 } , x _ { 2 } , \ldots \right) \text { such that } x _ { i } \neq 0 \text { for only finitely many values } } \\ { \text { of } i . \text { What is the closure of } \mathbb { R } ^ { \infty } \text { in } \mathbb { R } ^ { \omega } \text { in the box and product topologies? Justify } } \\ { \text { your answer. } } \end{array} I will first show that $\overline{\mathbb{R}^{\infty}} = \mathbb{R^\omega}$ in the product topology. Indeed, take any $x \in \mathbb{R^\omega}$ and let $U$ be an open set of $\mathbb{R^\omega}$ such that $x \in U$ . Then $U$ contains a basis element $B$ of the product topology such that: $$x \in B = \displaystyle{\prod_{n \in \mathbb{N}} U_{n}} \subset U $$ and $U_n = \mathbb{R} \ \forall n \in \mathbb{N}\setminus F$ where $F$ is a finite subset of $\mathbb{N}$ . Now, the sequence $(y_n)_{n \in \mathbb{N}}$ defined by: $$\begin{align*} &y_n = \pi_n(x)  \ \forall n \in F \\ &y_n = 0 \ \forall n \notin F\end{align*}$$ is an element of $B$ , by construction. It follows that $(y_n)_{n \in \mathbb{N}} \in B \subset U$ , and also by construction we have that $(y_n)_{n \in \mathbb{N}} \in \mathbb{R}^{\infty}$ . Then: $$U \bigcap \mathbb{R}^\infty \neq \emptyset$$ and therefore $\overline{\mathbb{R}^{\infty}} = \mathbb{R^\omega}$ . $\\$ Now I will show that $\overline{\mathbb{R}^{\infty}} = \mathbb{R^\infty}$ in the box topology. For this, it suffices to show that any $x \notin \mathbb{R}^{\infty}$ is not in $\overline{\mathbb{R}^{\infty}}$ , and this can be done by showing that there exists an open set $U \ni x$ in the product topology such that $U \bigcap \mathbb{R}^{\infty} = \emptyset$ . Indeed, by definition if $x = (x_n)_{n \in \mathbb{N}} \notin \mathbb{R}^{\infty}$ , then there exists an infinite set $I \subset \mathbb{N}$ such that $x_i \neq 0 \ \forall i \in I$ .  Now, for: $$U = \displaystyle{\prod_{i \in \mathbb{N}} U_{i} }$$ where $U_i = \mathbb{R} \setminus \{0\} \forall i \in I$ and $U_i = \mathbb{R}$ otherwise. As desired, it's clear that $x \in U$ and $U \bigcap \mathbb{R}^{\infty} = \emptyset$ and we're done. Have I made any unnecessary or not entirely correct steps here? Is there anything I should make clearer? EDIT: As I thought, there were some things that could be (and indeed were) improved. Thanks a lot, Brevan and Henno! This kind of thinking is very important and I will always try to bear it in mind so that my proofs are always as clean and clear as possible.","['general-topology', 'solution-verification']"
3077639,How to show the derivative of $f(M)=\text{Tr}(M\log (M) -M)$ is $\log (M)$?,"Let $M$ be a positive definite matrix in $\mathbb{S}_+^n$ . Let $\log$ be natural matrix logarithm which $\log(M)$ is defined as $\log(M)=\sum_{i=1}^{n}\log(\lambda_i)v_iv_i^T$ where $(\lambda_i,v_i)$ are eigenpairs of $M$ . This function is called negative Von Neumann entropy or negative Quantum entropy. How can we show the derivative of $f(M)=\text{Tr}(M\log M -M)$ is $\log M?$","['matrices', 'matrix-calculus', 'derivatives']"
3077641,Finding the tenth derivative of $f(x) = e^x\sin x$ at $x=0$ [duplicate],"This question already has answers here : $n$th derivative of $e^x \sin x$ (3 answers) Closed 5 years ago . I came across this Question where I have to find $$f^{(10)}$$ for the following function at $x = 0$ $$f(x) = e^x\sin x$$ I tried differentiating a few times to get a pattern but didn’t get one, can someone provide the solution.","['calculus', 'derivatives']"
3077642,How to see $x^6-1=(x^2âˆ’1)(x^2+x+1)(x^2âˆ’x+1)$?,"I was reading an example where the purpose was to compute a certain Galois group. Along the way, the writer says : note $x^6-1=(x^2âˆ’1)(x^2+x+1)(x^2âˆ’x+1)$ . But how do I note this? I understand you can factorize by $x^2-1$ , since when I draw on the unit circle I see that $-1$ and $+1$ are roots. But for the rest? Edit : I see you can then factor $(x^2-1)(x^4+x^2+1)$ and than substitute $x^2=y$ and solve quadratic equation but can you actually see the solution visually?","['algebra-precalculus', 'factoring', 'polynomials']"
3077670,"Since $\emptyset \subset A$ where $A$ is any set, does that mean $\emptyset \in A$?","Clearly $\emptyset \subset A$ where $A$ is any set. But does that mean $\emptyset \in A$ ? And if so, would it make sense to try to perform arithmetic operations with it. Like $$\emptyset \cdot 5 \tag{where $5 \in A$}$$ This is inspired by a question that was along the lines of: if a relation is symmetric and transitive, is it reflexive? Where I've seen (and am relatively satisfied by) the answer of: no, consider the empty relation .","['elementary-set-theory', 'relations']"
3077680,"What is $\mathbb P\{W\leq x,Y\leq y\}$ ?Is it $\mathbb P\{\omega \in \Omega : X(\omega )\leq x,Y(\omega )\leq y\}$?","Let $(\Omega ,\mathbb F,\mathbb P)$ . I'm confuse about something : Let $X,Y:\Omega \to \mathbb R$ r.v. What is $$\mathbb P\{X\leq x,Y\leq y\} \ \ ?\tag{1}$$ Is it, $$\mathbb P\{\omega \in \Omega \mid X(\omega )\leq x,Y(\omega )\leq y\}$$ or $$\mathbb P\{(\omega ,\omega ')\in \Omega ^2\mid X(\omega )\leq x,Y(\omega ')\leq y\} \ \ ?\tag{2}$$ I say the notation $$\mathbb P\{X\leq x,Y\leq y\}=\mathbb P\{\{\omega \in \Omega \mid X(\omega )\leq x\}\cap \{\omega \in \Omega \mid Y(\omega )\leq x\}\},$$ but in otherhand, I know that $\mathbb P\{X\in A,Y\in B\}$ is a product measure on $\mathbb R^2$ , so may be we also have a product measure on $\Omega ^2$ ? I'm a bit confuse... Espacially that if $(\Omega ',\mathcal F',\mathbb P')$ , and $X:\Omega \to \mathbb R$ , $Y:\Omega '\to \mathbb R$ , then $$\mathbb P\otimes \mathbb P'\{X\leq x, Y\leq y\}=\mathbb P\otimes\mathbb P'\{(\omega ,\omega ')\in \Omega \times \Omega '\mid X(\omega )\leq x, Y(\omega ' )\leq y\}=\mathbb P\{X\leq x\}\mathbb P'\{Y\leq y\},$$ which is a measure on $\mathbb R^2$ . That's why I would think that $(é)$ is true but not $(1)$ . What do you think ?","['measure-theory', 'probability']"
3077689,Conditions for a given manifold to admit a given metric,"It is well-known that every smooth manifold admits a Riemannian metric and it is commonplace to study when certain manifolds admit metrics of some specific type (eg Kahler, Ricci-Flat...), but I am wondering if it is known (or a well-posed question) to ask when a specific manifold admits a specific metric. In other words, for a given manifold and its tangent bundle, is there a way to assign coordinate labels to points such that some metric, which may be a solution to a system of equations, will manifestly be admited by that manifold. I ask primarily in the context of general relativity when we solve for the metric via Einstein's Equations, but then just seem to arbitrarily set it on some manifold. It is not obvious to me anyway that whichever manifold is selected would admit the metric.","['general-relativity', 'riemannian-geometry', 'differential-geometry']"
3077699,"""bounding"" an unbounded operator","I was wondering if, given a certain unbounded operator on a Hilbert space, it can (naively speaking) be ""cutted"" (or ""bounded"") by certain projections. So, thinking about this in a more sensible way, I have the following question: Let $T$ be a unbounded (densely defined) self-adjoint (positive) operator on $\mathcal{H}$ , and let $\{P_\lambda\}_{\lambda > 0}$ the spectral family of $T$ . Then we can look at the following: $\mathcal{H}_\lambda:= P_{(\lambda^{-1},\lambda)}\mathcal{H}$ , where $P_{(\lambda^{-1},\lambda)}$ correspond to the Borel functional calculus on $T$ of the characteristic function on the interval $(\lambda^{-1},\lambda)$ . Is it true that, on $\mathcal{H}_\lambda$ , $||Tx||\leq \lambda||x||$ ?","['operator-theory', 'spectral-theory', 'functional-analysis', 'unbounded-operators']"
3077708,Existence of the Limit of a Two-Variable Function,"This problem is an example in my calculus textbook. Let: $$
f(x,y)=\frac{y^2\sin^2(x)}{x^4+y^4}
$$ My textbook says that $$
\lim_{(x,y)\to(0,0)}f(x,y) \text{ does not exist.}
$$ Questions: How do we know the limit does not exist? In general, suppose the limit of a function exists but we do not know the value of such limit, how do we find it?","['limits', 'multivariable-calculus']"
3077710,"Representation of negative Quantum entropy in terms of eigenvalues, i.e., $\text{Tr}(M\log M -M)=\sum_{i=1}^{n}(\lambda_i\log(\lambda_i)-\lambda_i)$?","Negative Quantum entropy or Negative Von Nuemann entropy is defined as $f(M)=\text{Tr}(M\log M -M)$ . Where $M$ is a positive definite matrix in $\mathbb{S}_+^n$ , $\log$ is natural matrix logarithm for which $\log(M)$ is defined as $\log(M)=\sum_{i=1}^{n}\log(\lambda_i)v_iv_i^T$ where $(\lambda_i,v_i)$ are eigenpairs of $M$ . Show $f(M)=\text{Tr}(M\log M -M)=\sum_{i=1}^{n}(\lambda_i\log(\lambda_i)-\lambda_i)$ .","['matrices', 'linear-algebra', 'positive-definite', 'symmetric-matrices']"
3077732,Construct homotopy from $(\alpha \cdot \beta) \cdot \gamma$ to $\alpha \cdot (\beta \cdot \gamma)$ explicitly,"I understand the general idea of a homotopy, but I'm a little lost on how to create them myself. For example if I wanted to show $$ \text{Let} \: \alpha, \beta, \text{and} \: \gamma \: \text{be paths} \: I \to X, \: \text{from} \: x_{0} \: \text{to} \: y_{0}, y_{0} \: \text{to} \: z_{0}, \: \text{and}  \: z_{0} \: \text{to} \: u_{0}. \: \text{Then} \: \\
(\alpha \cdot \beta) \cdot \gamma \sim \alpha \cdot (\beta \cdot \gamma) $$ A possible homotopy is $F: I \times I \to X$ , given by $$\\ F(t,s) = 
\begin{cases}
\alpha(\frac{4t}{1+s}) & 0 \leq t \leq \frac{s+1}{4} \\
\beta(4t-1-s) & \frac{s+1}{4} \leq t \leq \frac{s+2}{4} \\
\gamma(\frac{4t - 2 - s}{2-s}) & \frac{s+2}{4} \leq t \leq 1 \\
\end{cases}$$ What I don't understand is where this comes from. What is the intuition here and how can I form explicit homotopies like this?","['general-topology', 'algebraic-topology']"
3077749,Show $ \sum_1^n (x_i-\bar{x})^2 = \sum_1^{n-1} (x_i -\bar{x}^*)^2+\frac n{n-1}(x_n-\bar{x})^2 $,"Let $x_1,...,x_n$ be a random sample from some population with $n\geq3$ and with at most $n-2$ sample points being equal.
How can one show $$ \sum_1^n (x_i-\bar{x})^2 = \sum_1^{n-1} (x_i -\bar{x}^*)^2+\frac n{n-1}(x_n-\bar{x})^2, $$ where $ \bar{x}=\frac1n\sum_1^nx_i$ and $ \bar{x}^* = \frac 1{n-1} \sum_1^{n-1} x_i.$ This is a useful identity since it would allow me to have an upper bound on the deviation of $x_i$ from the mean. That is $$ \max_{1\leq i \leq n} | x_i - \bar{x}| < \frac {n-1} {\sqrt{n}} S, $$ where $ S^2 = \frac 1 {n-1} \sum_1^n (x_i - \bar{x})^2.$ Thank you very much for your help. Source of the question A Matrix Formulation on How Deviant an Observation Can Be Author: Ingram Olkin. Source: The American Statistician, Vol. 46, No. 3 (Aug., 1992), pp. 205-209 https://www.jstor.org/stable/2685215 I will add shortly what I've tried so far.",['statistics']
3077759,Proof that the minimum area rectangle is collinear with an edge of the convex hull?,"If I have a finite set of points S, is there a way to prove that the minimum area rectangle containing all points in S will be collinear with one of the edges of the convex hull of S? As far as I can tell, this is assumed in every convex hull proof I can find, but I can't seem to find a proof of this assumption itself.","['geometry', 'convex-hulls']"
3077766,"Why is the magnitude of the sum of two adjacent nth roots always an 'interesting' number, and what do these numbers have to do with each other?","While doing something completely unrelated, I discovered an interesting function: $$f(x)=2\left\vert\cos{\frac{\pi}{x}}\right\vert$$ Which gives the absolute value of the sum of any two adjacent $x^\text{th}$ -roots of unity for $x\in\mathbb{R}$ . This function seemed interesting to me because, for whatever reason, integer (and certain rational) values of $x$ seem only to yield 'interesting' numbers. For instance: $f(5/2)=\Phi$ (golden ratio conjugate)
, $f(4)=\sqrt{2}$ , $f(5)=\phi$ (golden ratio), $f(7)=\sqrt{\mathcal{S}}$ (squareroot of the silver constant), $f(9/7)=\frac{1}{\mathcal{P}_c(6^3)}$ ( $\mathcal{P}_c\left(6^3\right)$ is the bond percolation threshold for a honeycomb lattice), $f(9)=\frac{1}{\mathcal{P}_c(3^6)}-1$ ( $\mathcal{P}_c\left(3^6\right)$ is the bond percolation threshold for a triangular lattice) ...and so on. I found out shortly before writing this that these are the square roots of Beraha numbers, but I have no idea what that means or what it has to do with roots of unity, so the question hasn't changed. Why are these numbers showing up? And what do Beraha numbers, roots of unity, lattices, and algebraic roots have to do with each other? Note: if $x$ is rational, then $f(x)$ is algebraic. I can neither confirm nor deny that $f(x)$ is algebraic if $x$ is algebraic. In any case, transcendental numbers don't show up here. It is also easy to show that the sum of any two $x^\text{th}$ roots of unity are algebraic if $x$ is rational. Note: two $x^\text{th}$ -roots of unity are 'adjacent' if the distance between them is minimal. i.e. $z_1,z_2=\sqrt[x]{1}$ are adjacent if there is no $z_3=\sqrt[x]{1}$ such that $d(z_1,z_2)>d(z_1,z_3)$ or $d(z_1,z_2)>d(z_2,z_3)$ If you count the roots of unity by 'stepping' clockwise or counterclockwise around the unit circle, then the magnitude of the sum of two roots of unity separated by $n$ steps is given by the function: $$f(x)=2\left\vert\cos{\frac{\pi n}{x}}\right\vert$$","['number-theory', 'soft-question', 'roots-of-unity', 'complex-numbers']"
3077768,Linear Regression's Expectation of Prediction Error on a given point in the test set,"I'm self-learning the book ""The Elements of Statistical Learning"", and I've got a little problem on deriving equation 2.27 in this book. I would appreciate if anyone could help me with this. In order to make this question consistent, I'll list all the information needed for the deriving. Suppose we have two random variables $Y$ and $X$ with the following relation: $Y = X^T\beta + \epsilon$ where $\epsilon \sim N(0, \sigma^2)$ . and we fit data in a training set $\mathcal{T}$ with linear regression by least squares: $\hat{Y} = X^T \hat{\beta}$ , where $\hat{\beta}$ is the parameter and $\hat{Y}$ is our prediction, $X$ is the input. we define the Expected Prediction Error (EPE) of a record ( $x_0, y_0$ ) in test data as $EPE(x_0) = E_{y_0|x_0}E_{\mathcal{T}}(y_0 - \hat{y_0})^2$ where $\hat{y_0}$ is our prediction w.r.t. $x_0$ . According to the book , $EPE(x_0) = Var(y_0|x_0) + Var_{\mathcal{T}}(\hat{y_0}) + Bias^2(\hat{y_0})$ where $Bias^2(\hat{y_0}) = (E_{\mathcal{T}}\hat{y_0} - y_0)^2$ . Here is my derivation: $EPE(x_0) = E_{y_0|x_0}E_{\mathcal{T}}(y_0 - \hat{y_0})^2$ $=E_{y_0|x_0}E_{\mathcal{T}}(y_0^2 - 2y_0\hat{y_0} + \hat{y_0}^2)$ $=E_{y_0|x_0}(y_0^2) -2E_{y_0|x_0}y_0E_{\mathcal{T}}\hat{y_0} + E_{\mathcal{T}}\hat{y_0}^2$ By the lemma $Var(X) = E(X^2) - (E(X))^2$ we have $EPE(x_0) = Var(y_0|x_0) + (E_{y_0|x_0}(y_0))^2 -2E_{y_0|x_0}y_0E_{\mathcal{T}}\hat{y_0} + Var_{\mathcal{T}}(\hat{y_0)} + (E_{\mathcal{T}}(\hat{y_0}))^2$ $= Var(y_0|x_0) + Var_{\mathcal{T}}(\hat{y_0}) + (E_{\mathcal{T}}(\hat{y_0}) - E_{y_0|x_0}(y_0))^2$ which is really close to the conclusion given in the book, as long as we can prove $E_{y_0|x_0}(y_0) = y_0$ the proof is completed. But I've no clue how to prove $E_{y_0|x_0}(y_0) = y_0$ since I've no idea about $p(y_0 | x_0)$ . I'm wondering if anyone could help me on that. My guess is that, since $y_0 = x_0^T\beta + \epsilon$ , $E_{y_0|x_0}(y_0) = E_{y_0|x_0}(x_0^T\beta) + E_{y_0|x_0}(\epsilon) = E_{y_0|x_0}(x_0^T\beta) + \epsilon$ , and $x_0^T\beta$ is deterministic given $x_0$ , so $E_{y_0|x_0}(y_0) = x_0^T\beta + \epsilon = y_0$ , but I'm not sure if this is right. Thank you very much for your reading! Possible relative questions: What is Expected Prediction Error (EPE) a function of? Expected squared prediction error conditioned on training set","['linear-regression', 'statistics']"
3077774,Why can’t you reassign the ‘mystery number’ in Cantor’s diagonal argument to a new number in the natural numbers?,"I don’t want to claim that I have ‘refuted Cantor’ or something here, I just want to understand it adequately. 
I do understand that the proof works something like this:
You assume that you can map the naturals onto the real numbers like so, where each letter represents some arbitrary digit: $$1 — 0.abcd\cdots$$ $$2 — 0.efgh\cdots$$ $$3 — 0.ijkl\cdots$$ And then you constrict the ‘mystery number’ $x$ which differs in at least one digit of each number that is assigned to a natural number. This mystery number, by definition, cannot be mapped onto any of the natural numbers. This is fine, but why can’t you just assign $0.abcd\cdots$ to $2, 0.efgh\cdots$ to $3$ , and so on, then assign $x$ to $1$ , which would now be open? What is the problem with doing this? Update: Sorry for the poor notation and formatting, I’m writing this on my phone.","['elementary-set-theory', 'infinity']"
3077786,Maximality of an ideal for showing that an algebra is in fact a field,"I have an algebra $A$ over the field $F$ , with the finite dimensionality $n$ as a vector space over $F$ . I can also assume that $A$ is an integral domain. Assuming that $v_1,...,v_n$ is a spanning list of vectors and that $v_1=1$ , I believe I can represent $A$ as $F[v_1,v_2,...,v_n]/I$ where $$I=\left(v_1-1,\ v_iv_j\ \forall\ 2\leq i,j\leq n\right).$$ Now, I'd hope to show that $A$ is a field by proving the maximality of $I$ , but I can't figure out how to show that.","['field-theory', 'abstract-algebra', 'maximal-and-prime-ideals', 'ideals']"
3077789,what does it mean by determinant of Jacobian matrix = 0?,I have an example: $$ u={x+y\over 1-xy} $$ $$ v = \tan^{-1}(x)+\tan^{-1}(y) $$ So by calculating the determinant of the Jacobian matrix I get zero. Does it mean there is no functional relationship between u and v? What does $|J|=0$ mean?,"['jacobian', 'calculus', 'linear-algebra']"
3077806,Continuity of Energy Functional,"Let $u : \Omega \times [0,T]$ be a function such that $u \in C^{2,1}(\Omega \times [0,T])\cap C^{1}((0,T);L^{2}(\Omega))\cap C([0,T);H_{0}^{1}(\Omega))$ for $\Omega \subset \mathbb{R}$ an unbounded domain. In order to clarify the meaning of the notation, I will explain some notations mentioned above. 1. $C^{2,1}(\Omega \times [0,T])$ : the function is twice differentiable with respect to spatial domain and once differentiable with respect to time domain. 2. $C^{1}((0,T);L^{2}(\Omega))$ : for any fixed $t \in (0,T)$ , $u(\, .\, ,t)\in L^{2}(\Omega)$ and the mapping is once differentiable 3. $C([0,T);H_{0}^{1}(\Omega))$ : for any fixed $t \in [0,T), u(\, .\, ,t)\in H_{0}^{1}(\Omega)$ and the mapping is continuous. So now I define, a functional $F[\, .\,] = ||\, .\,||_{L^{p}(\Omega)}^{p}$ ( $2<p<\infty$ ) so that I have $F[u(\,.\,)] : [0,T)\to\mathbb{R}$ What I want to show is $F[u(\,.\,)] \in C([0,T);\mathbb{R})$ but I am not sure how to ensure that $||\,.\,||_{L^{p}(\Omega)}$ is finite since $\Omega$ is unbounded and thus I cannot use the embedding of $L^{p}$ to $L^{2}$ for $2<p<\infty$ . Furthermore, the dimension $n=1$ so I cannot use any embedding inequality here. Any help is much appreciated! Thank you!","['continuity', 'functions', 'normed-spaces', 'functional-analysis']"
3077814,Lipschitz constant of a matrix,"I am studying the Lipschitz continuity and trying to solve the following question: If a function $f(x)= Ax$ is defined for $x \in \mathbb{R}^2$ with $A= \begin{bmatrix}
    a       & b \\
    c       & d
\end{bmatrix}$ , then find a constant L such that \begin{eqnarray*}
||Ax - Ay|| \le L||x - y||, x, y \in \mathbb{R}^2.
\end{eqnarray*} I understand how to find the Lipschitz constant in $\mathbb{R}$ , but I have no idea about how to find it in $\mathbb{R}^2$ .","['matrices', 'continuity', 'multivariable-calculus', 'lipschitz-functions']"
3077935,Solving the Euler-Lagrange equation for the brachistochrone problem with friction,"This Wolfram Alpha Page contains a derivation of the parametric form of the brachistochrone curve that result from either assuming friction or its absence. I am asking for help understanding how the solution to the differential equation obtained from applying the Euler-Lagrange equation to the integrand of the the integral representing the total time of descent is obtained. This differential equation can be found on step (30) of the page. I am asking for help in understanding the next step, how setting $$\frac{dy}{dx} = \cot(\theta/2)\tag{31}$$ allows for the equation to be solved, obtaining the parametric equations for $x$ and $y$ , shown in steps (32) and (33).","['parametric', 'euler-lagrange-equation', 'ordinary-differential-equations', 'calculus-of-variations']"
3077965,Is the pull-back of the structure sheaf the structure sheaf?,"Maybe this is a stupid question, but I got irritated by it: Suppose $f: X \rightarrow Y$ is a morphism of schemes. That comes with a map of sheaves $f^\#: \mathcal{O}_Y \rightarrow f_* \mathcal{O}_X$ . Because $f_*$ and $f^*$ are adjoint to each other, this map corresponds to a homomorphism $f^*\mathcal{O}_Y \rightarrow \mathcal{O}_X$ of $\mathcal{O}_X$ -modules. But as far as I understand, $f^*\mathcal{O}_Y = f^{-1}\mathcal{O}_Y \otimes_{f^{-1}\mathcal{O}_Y}\mathcal{O}_X = \mathcal{O}_X$ . So the map $f^\#$ really is the same as an $\mathcal{O}_X$ -module homomorphism $\mathcal{O}_X \rightarrow \mathcal{O}_X$ , which is the same as giving a global section $s \in \Gamma(X, \mathcal{O}_X)$ , because the map is fully determined by the value of the global section $1$ . Is this reasoning correct, or did I make a mistake?","['pullback', 'coherent-sheaves', 'algebraic-geometry', 'schemes']"
3077989,Characteristic and primitive roots of unity,"Let $F$ be a finite field. If the characteristic of $F$ doesn’t divide $n$ , then $F$ contains a primitive $n^{th}$ root of unity. I believe the converse is true, too, but I can’t prove either direction? I know that $F^{*}$ is cyclic and of order $p^n -1$ , where $p$ is the characteristic of $F$ and $n >0$ . So it contains a generator, $\alpha$ with $\alpha^{p^n -1} = 1$ . But how does this relate to the characteristic not dividing $n$ ?","['galois-theory', 'finite-fields', 'abstract-algebra']"
3078032,Can one hear the shape of a DeRham ring ? Is any ring a DeRham ring?,"Sorry for the Clicbait title, but take $A$ a graded $\mathbb R$ commutative (in the graded sense) algebra of finite dimension. Does there exist a smooth manifold $M$ having $A$ as a DeRham cohomology ring : $H^*(M) \simeq A$ ? In the negative case, what would be a natural restriction that I missed on the structure of the DeRham ring ? I was thinking of taking generators for the algebra and taking product of spheres. But i have problems when those generators verfies relations among them.","['ring-theory', 'differential-geometry']"
3078048,"Is there any meaning of this ""Median-mean""","Given a data set $\{a_1,\cdots,a_n\}$ with median M Define the medimean to be the value of $x$ s.t. $$\left(\frac{1}{n}\sum_{n}{}{a_n}^x \right)^{1/x}=M$$ Is this $x$ value useful / used at all in statistics? Some examples $\{\frac{1}{5},\frac{1}{4},\frac{1}{3},\frac{1}{2},\frac{1}{1}\} : x=-1$ $\{2,4,8,16,32\} : x=0$ $\{\sqrt{1},\sqrt{2},\sqrt{3},\sqrt{4},\sqrt{5}\} : x=2$ $\{1,2,3,4,5\} : x=1$ $\{1,4,9,16,25\} : x=\frac{1}{2}$ $\frac{1}{x}$ seems to say something about how the numbers are distributed, apart from when $x=0$ Just an idea I was playing around with yesterday. $\{1,1,1,2,2\} : x=-\infty$ $\{1,1,2,2,2\} : x=\infty$","['statistical-inference', 'statistics', 'descriptive-statistics']"
3078088,"Show that $n ≤ 100$ if $ \{A_1,A_2,... ,A_n\}$ is a set of distinct $3$-element subsets of $\{1, 2,... , 36\}$ such that...","Let $X = \{A_1,A_2,... ,A_n\}$ be a set of distinct $3$ -element subsets of $\{1, 2,... , 36\}$ such that i) $A_i$ and $A_j$ have non-empty intersection for every $i,j$ . ii) The intersection of all the elements of $X$ is the empty set. Show that $n ≤ 100$ . How many such sets $X$ are there when $n = 100$ ? Source: BMO 2005 round 2 question. Please help !! I am not even able to proceed with the question I tried to come up with a recurrence relation but its not working. I have only been able to figure out the number when 36 is replaced by 6, which is an easy thing to do","['contest-math', 'combinatorics']"
3078168,Counting the ways to form 4 different teams,"We have 40 players and we need to form 4 teams. For each team is necessary to indicate explicitly 6 players and 4 reserves. How many ways can teams be formed? My attempt: first we can start to calculate in how many ways we can choose 6 players and 4 reserves. Since a distinction is made between players and reserves, I think we should consider it in the calculation (in the sense that, otherwise, it would have been simply 11 players). I think that we can calculate this number by multiplicate $\binom{40}{6}$ ways to choose the players and $\binom{34}{4}$ ways to choose the reserves. Now, the multiplication produces a very large number and makes me believe that I'm wrong (because then I need to calculate in how many ways we can assign one of the combinations to a team). Am I wrong? Is this a correct reasoning?","['combinatorics', 'discrete-mathematics']"
3078221,"$\Gamma(s)= \lim_{n \to \infty} \frac{n^s n!}{s(s+1)...(s+n)}$ , the product formula of Gamma function .","Prove that $$\Gamma(s)= \lim_{n \to \infty} \frac{n^s n!}{s(s+1)...(s+n)}$$ Whenever $s \neq 0,-1,-2,...$ My attempt : By applying product formula for $\frac{1}{\Gamma}$ , $$\Gamma(s)=\lim_{n\to \infty} \frac{n!}{s(s+1)...(s+n)}e^{s(1+\frac12+...+\frac1n-\gamma)}$$ Notice that $1+\frac12+...+\frac1n-\gamma\to \log n$ , so it seems that we then get the desired conclusion . But whenever $Re(s)\gt0$ , $n^s \to \infty$ , we can not have $$\Gamma(s)=\lim_{n\to \infty} \frac{n!}{s(s+1)...(s+n)}\lim_{n\to \infty} e^{s(1+\frac12+...+\frac1n-\gamma)}$$ Let $A(s)=\lim_{n\to \infty} \frac{n!}{s(s+1)...(s+n)}n^s$ , I want to prove this exercise by showing the following statement. 1) $A(s)$ defines a meromorphic function with simple poles at $0,-1,-2,...$ and nowhere else. 2) $A(s)=\Gamma (s)$ whenever $s \in (\frac14,\frac13)$ . To show 2) , we need some estimate of $\gamma$ , $$\sum_{n=1}^N \frac1n-\log N =\sum_{n=1}^{N-1}\int_n^{n+1} \frac1n-\frac1x \,dx +\frac1N$$ Then we may write $a_n=\int_n^{n+1} \frac1n-\frac1x \,dx $ and $\gamma=\sum_1^{\infty}a_n$ . Moreover , $a_n \le \frac{1}{n(n+1)}$ Notice that whenever $s\in (\frac14,\frac13)$ , $\frac{n!}{s(s+1)...(s+n)}$ is bounded by some fixed $M$ . $$\Gamma(s)-A(s)\le M\lim_{n\to \infty} |e^{s(1+\frac12+...+\frac1n-\gamma)}-e^{s \log n}|$$ apple mean-value theorem we have $$|e^{s(1+\frac12+...+\frac1n-\gamma)}-e^{s \log n}|\le s|1+\frac12+...+\frac1n-\gamma-\log n||e^{s*2 \log n}|$$ $$\le sn^{\frac23} |\sum_{k=n}^{\infty} a_k+\frac1n|\le sn^{\frac23} |\sum_{k=n}^{\infty} \frac{1}{k(k+1)}+\frac1n|\le \frac{2sn^{\frac23}}{n} \to 0$$ And we complete the proof of 2) . To prove 1) , we need to prove that for every compact subset $\Omega$ of $C-\{0,-1,-2,...\}$ , $f_n=\frac{n!}{s(s+1)...(s+n)}n^s$ converges uniformly . I have no idea how to deal with this .","['complex-analysis', 'gamma-function']"
3078231,Finding a closed form for $I_n=\int_0^1 \prod_{l=1}^n\left[x^2-\frac{l^2}{n^2}\right]dx$,"I'm now dealing with this integral and trying to give a closed form to it: $$I_n=\int_0^1 \prod_{l=1}^n\left[x^2-\dfrac{l^2}{n^2}\right]dx$$ Where the first few values are given: $$I_1=\int_0^1 (x^2-1) dx=-\dfrac23$$ $$I_2=\int_0^1 \left(x^2-\dfrac14\right)(x^2-1)dx=\dfrac1{30}$$ $$I_3=\int_0^1 \left(x^2-\frac19\right)\left(x^2-\frac49\right)(x^2-1)dx=-\dfrac{136}{8505}$$ I've tried to expand the polynomial, but I could merely give a general expression for the first few and the last few coefficients, and they become complicated very fast. I have searched the Internet; did I miss something that I couldn't find them because I don't know the Theorem's name?","['integration', 'calculus']"
3078260,Integral $\int_{\sqrt{33}}^\infty\frac{dx}{\sqrt{x^3-11x^2+11x+121}}$,"How can we prove $$I:=\int_{\sqrt{33}}^\infty\frac{dx}{\sqrt{x^3-11x^2+11x+121}}\\=\frac1{6\sqrt2\pi^2}\Gamma(1/11)\Gamma(3/11)\Gamma(4/11)\Gamma(5/11)\Gamma(9/11)?$$ Thoughts of this integral This integral is in the form $$\int\frac{1}{\sqrt{P(x)}}dx,$$ where $\deg P=3$ . Therefore, this integral is an elliptic integral. Also, I believe this integral is strongly related to Weierstrass elliptic function $\wp(u)$ . In order to find $g_2$ and $g_3$ , substitute $x=t+11/3$ to get $$I=2\int_{\sqrt{33}-11/3}^\infty\frac{dt}{\sqrt{4t^3-352/3t+6776/27}}$$ The question boils down to finding $\wp(I;352/3,-6776/27)$ but I seem to be on the wrong track.","['integration', 'elliptic-integrals', 'definite-integrals']"
3078296,"Having a cube, with a point at its center. What are the points that are equidistant from the center point to the cubes vertices?","Having a cube, with a point at its center. What shape do the points wich are equidistant between the center and the cubes vertices make? The source of why I had this question is the following photo What shape is resultant from this composition of equidistant points? Thank you very much.",['geometry']
3078303,"Joint essential range of $\varphi\in L^\infty(X,\mu)^d$.","Definition: Let $(X,\mu)$ be a measure space and $\phi=(\phi_1,\cdots,\phi_d)\in L^{\infty}(X)$ . The joint essential range of $\phi$ is the set $\mathcal{C}(\phi)$ which is consisting of all $z = (z_1,\cdots,z_d)\in \mathbb{C}^d$ such that for every $\varepsilon>0$ $$\mu \left(\left\{t\in X\,;\;\sum_{i=1}^d|\phi_i(t)-z_i|<\varepsilon  \right\}\right)>0 .$$ Assume that $$r=\max\left\{\sum_{i=1}^d|z_i|^2; (z_1,\cdots,z_d)\in \mathcal{C}(\phi)\right\}.$$ i.e. $$ r:=\max\left\{\sum_{i=1}^d|z_i|^2\,;\;\mu \left(\left\{t\in X\,;\;\sum_{i=1}^d|\phi_i(t)-z_i|<\varepsilon  \right\}\right)>0,\;\text{for every}\;\varepsilon>0\right\}.$$ I want to understand why the following two facts hold? $$\mu \left(\left\{t\in X\,;\;\sum_{i=1}^d|\phi_i(t)|^2>r \right\}\right)=0 ,$$ and $$ \int_X\left(\displaystyle\sum_{k=1}^d|\phi_k|^2\right)|f|^2d\mu\leq r  \int_X|f|^2d\mu.$$ Note that the two facts figure in this paper (page 6 and 7).","['general-topology', 'measure-theory']"
3078305,Direct proof that a parallel almost complex structure is integrable,"Let $(M,g,J)$ be an almost Hermitian manifold nad $\nabla$ be the Levi-Civita connection on $M$ . If $\nabla J=0$ , it is straightforward to show that the Nijenhuis tensor of $J$ must vanish which implies that $J$ is integrable. But the condition $\nabla J=0$ is stronger than $N_J=0$ , so my question is: Is there a direct proof of this statement without invoking the Newlander-Nierenberg theorem?","['complex-geometry', 'almost-complex', 'kahler-manifolds', 'differential-geometry']"
3078388,K time differentiable function,Is there any k time differentiable function such that $$f(f'(f''(f'''(......f^{(k)}(x))))=x$$ for all $x$ belongs to $\mathbb R$ ? EDIT:- What will the case be when the order of the functions taken are reversed?,"['calculus', 'functional-analysis', 'real-analysis']"
3078457,"The number $F(n,k)$ of forests on the vertex set $[n]$ having $k$ components and such that $1, . . . , k$ belong to distinct components?","Problem : What is the number $F(n,k)$ of forests on the vertex set $[n]$ having $k$ components and such that $1, . . . , k$ belong to distinct components? Solution given by the professor Janos Pach : Take an arbitrary tree $T$ on the vertices $v _ { 1 } , \ldots , v _ { k }$ . Any forest of $k$ components where $v _ { 1 } , \ldots , v _ { k }$ are in distinct components, together with $T$ is a tree on $n$ vertices, and vica-versa. So, we need to compute how many labeled trees on $n$ vertices contain a given labeled subtree on a given subset of $k$ vertices. Using the previous exercise, we obtain $k n ^ { n - k - 1 }$ . Previous exercice : Let $T _ { 1 } , \ldots , T _ { k }$ be trees on disjoint sets of points and $V = V \left( T _ { 1 } \right) \cup \ldots \cup V \left( T _ { k } \right) .$ What is the number of labeled trees on $V$ containing $T _ { 1 } , \ldots , T _ { k } ?$ Answer : $\left| V \left( T _ { 1 } \right) \right| \ldots \left| V \left( T _ { k } \right) \right| \cdot | V ( T ) | ^ { k - 2 }$ My question : I think I'm having difficulties in the understanding of the exercise. Is $T$ a tree with each vertices being a subtree? Are there $k$ subtrees in the forest? How manies vertices are there in a subtree? How does it relate numerically to the answer of the previous exercise?","['graph-theory', 'trees', 'combinatorics', 'discrete-mathematics']"
3078464,What's the intuition behind the Co-Area formula?,"I mainly work in statistics and I know only basic measure theory. I was trying to understand the Co-Area formula by Federer. If $f:\mathbb{R}^M\to \mathbb{R}^N$ is a Lipschitz function with $M \geq N$ then $$
\int_A J_N f(x) d\mathcal{L}^M x = \int_{R^N} \mathcal{H}^{M-N} (A\cap f^{-1}(y)) d\mathcal{L}^N y
$$ Could anyone please give me an intuition of what the formula implies and what it means practically? In particular, this is a simple example I am trying to wrap my head around: suppose we are in 2 dimensions and there is a curve defined by a function What does the co-area formula tell us in this context? Here are some practical questions: My understanding is that we have some space of dimension $M$ and there a manifold in it of dimension $M-N$ and we would like to compute the area of this manifold using the Hausdorff measure. Is this what is happening? I am completely lost as to why we need $A\cap f^{-1}(y))$ what's the intuition behind this? On the right hand side we have $\mathcal{H}^{M-N}$ . I am familiar with the Lebesgue measure $d\lambda$ however I am lost as to why we seem to have both the Lebesgue and the Hausdorff measure on the right hand side. I thought we should only have the Hausdorff measure on the RHS?","['measure-theory', 'geometric-measure-theory', 'multivariable-calculus', 'differential-topology', 'differential-geometry']"
3078486,Integrate $\int\frac{\cos^2(x)-x^2\sin(x)}{(x+\cos(x))^2}dx$,"I had to integrate the following integral: \begin{equation}
\int\frac{\cos^2(x)-x^2\sin(x)}{(x+\cos(x))^2}dx
\end{equation} but I can't find a suitable substitution to find a solution. Nothing I try works out and only seems to make it more complicated. Does anyone have an idea as to how to solve this? I also tried to get help from WolframAlpha but it just says that there is no step-by-step solution available. The sollution by wolfram alpha is: \begin{equation}
\int\frac{\cos^2(x)-x^2\sin(x)}{(x+\cos(x))^2}dx = \frac{x\cos(x)}{x+\cos(x)} + c
\end{equation}","['integration', 'real-analysis']"
3078540,Find $\lim_{n \to \infty} \left(n - \sum_{k=1} ^{n} \cos \frac{\sqrt{k}}{n} \right)$,"Find $\lim_{n \to \infty} \left(n - \sum_{k=1} ^{n} \cos \frac{\sqrt{k}}{n} \right)$ My Attempt: $\forall x: \ |\cos(x)|\leq 1$ , Therefore: $$\lim_{n \to \infty} \left(n - \sum_{k=1} ^{n} \cos \frac{\sqrt{k}}{n} \right) \leq \lim_{n \to \infty} \left(n - \left| \sum_{k=1} ^{n} \cos \frac{\sqrt{k}}{n}  \right| \right) \leq  \lim_{n \to \infty} \left( \sum_{k=1}^{n} |\cos \frac{\sqrt{k}}{n} | \right) \leq \lim_{n \to \infty} \left(n - \sum_{k=1} ^{n} k \right) = 0$$ but I can't find a way to bound the limit such that I could prove that: $$0 \leq \lim_{n \to \infty} \left(n - \sum_{k=1} ^{n} \cos \frac{\sqrt{k}}{n} \right) \leq 0$$ which would finish the proof.","['limits', 'calculus', 'real-analysis']"
3078556,Completion of a $\sigma$-algebra is a $\sigma$-algebra,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space. Let \begin{align*}
 \mathcal{N}&= \left\{N\subseteq\Omega:\exists F\in\mathcal{F}, N\subseteq F,\mathbb{P}(F)=0\right\}  \\ \mathcal{G}&=\left\{A\cup N:A\in\mathcal{F},N\in\mathcal{N}\right\} \end{align*} Prove that $\mathcal{G}$ is a $\sigma$ -algebra. I've shown that $\Omega\in\mathcal{G}$ and that if $(A_n)_n\subseteq\mathcal{G}$ then $\cup_n A_n\in\mathcal{G}$ . How can I show that if $A\in\mathcal{G}$ then $A^c\in\mathcal{G}$ ? I also noticed $\mathcal{F}\subseteq\mathcal{G}$ if it helps somehow.","['elementary-set-theory', 'measure-theory', 'probability-theory']"
3078569,Solving $(\ln(x)-1)y'' - \frac{1}{x}y' + \frac{1}{x^2}y = \frac{(\ln(x) - 1)^2}{x}$,"On my exam I had to solve the following differential equation. \begin{equation}
(\ln(x)-1)y'' - \frac{1}{x}y' + \frac{1}{x^2}y = \frac{(\ln(x) - 1)^2}{x^2}
\end{equation} Which is a differential equation of the form: \begin{equation}
y'' + a(x)y' + b(x)y = R(x)
\end{equation} The only method we've seen to solve this kind of differential equations is: If the differential equation is of the form: \begin{equation}
y'' + a(x)y' + b(x)y = 0
\end{equation} First find a solution of the characteristic equation, being $\varphi_1$ . Then: \begin{equation}
\varphi_2(x) = \varphi_1(x)\int\frac{dx}{A(x)(\varphi_1(x))^2}
\end{equation} With $A(x) = e^{\int a(x) dx}$ Then the homogenous solution is given by: \begin{equation}
y(x) = c_1\varphi_1(x) + c_2\varphi_2(x)
\end{equation} The first problem is that this doesn't satisfy the requirements for this method since the differential equation is not homogenous, but since this is the only fitting method, I'd still try to use it. My guess would be to start with the characteristic equation which gives: \begin{equation}
(\ln(x)-1)x^2 - 1 + \frac{1}{x^2}y = 0
\end{equation} or \begin{equation}
x^2 - \frac{1}{(\ln(x)-1)} + \frac{1}{x^2(\ln(x)-1)} = 0
\end{equation} but i wouldn't even know how to start solving this equation to find the roots of the equation. Does anyone have an idea as to how to tackle this problem. Note the only other ways of solving linear differential equations that we have seen are ways to solve first order differential equation or ways to solve second order differential equations in the form: \begin{equation}
y'' + py' + qy = R(x)\;\;\;\text{with}\;\; p,q\in\mathbb{R}
\end{equation}","['differential', 'ordinary-differential-equations', 'real-analysis']"
3078576,Fredholm operators on non-Banach spaces.,"Apparently Fredholm operators are usually (at least in Wikipedia and my functional analysis lecture) only defined as operators $T$ between two Banach spaces. As far as I can see, the definition can be extended to operators between arbitrary normed spaces without any problems, although then the condition that $\operatorname{im} T$ is closed is no longer independent of $\ker T < \infty$ and $\operatorname{coker} T < \infty$ . Is there some reason why this is not usually done? Are Fredholm operators between non-Banach spaces so much less interesting/useful than those between Banach spaces? If yes, why?","['banach-spaces', 'operator-theory', 'soft-question', 'functional-analysis']"
3078630,Let $T$ be the number of tosses required until three consecutive heads appear for the first time. Find $\textbf{E}(T)$.,"A fair coin is tossed repeatedly. Let $A_{n}$ be the event that three heads have appeared in consecutive tosses for the first time on the $n$ -th toss. Let $T$ be the number of tosses required until three consecutive heads appear for the first time. Find $\textbf{P}(A_{n})$ and $\textbf{E}(T)$ . Let $U$ be the number of tosses required until the sequence $HTH$ appears for the first time. Can you find $\textbf{E}(U)$ ? EDIT The textbook provides an answer based on recurrence equations, but I seek for an alternative approach if it is possible. Can somebody please help me out? Thanks in advance.","['expected-value', 'probability-distributions', 'probability-theory', 'probability']"
3078632,Topological consequences of negative and zero Einstein condition,"Let $(M,g)$ be a complete Riemannian manifold which is Einstein, i.e. $\mathrm{Ric}=kg$ for some constant $k\in \mathbb{R}$ . 1) If $k<0$ , is $M$ then necessarily noncompact ? If so, does the condition $k<0$ give any other topological restraints? All examples of negative Einstein manifolds that I know are noncompact (e.g. hyperbolic space). Note that when $k>0$ , $M$ must be compact by Myers' theorem . I know that any Riemannian manifold admits a complete metric with $\mathrm{Ric}<0$ , but I suspect that the Einstein condition is much more restrictive. 2) Does the condition $k=0$ give any topological information? For example, can $S^n$ admit a metric with $k=0$ ?","['smooth-manifolds', 'geometry', 'riemannian-geometry', 'differential-geometry']"
3078637,Reference for Grassmann and Schubert varieties for Beginners .,I need some references to understand Grassmann and Schubert Variety as a beginner. I am looking for self-contained notes on these. Thanks.,"['reference-request', 'algebraic-geometry', 'abstract-algebra', 'linear-algebra', 'schubert-calculus']"
3078643,What makes statistical distributions so unique?,"I am going to start this question with a definition. Definition:  If $Z\sim \mathcal{N}(0,1)$ and $U \sim \chi_{n}^2$ , and $Z$ and $U$ are independent, then the distribution of $$\frac{Z}{\sqrt{\frac{U}{n}}}$$ is called the $t$ distribution with $n$ degrees of freedom. My question , which may sound strange, is, why is this so special?  Why can't anyone just come up with a distribution which is some combination of other random variables and name it after themselves?","['statistics', 'random-variables']"
3078704,"Given a chord, how do I find the ellipse?","It will explain my use case at the end, in case I am approaching this wrong, but I will start with the math question. Given: a point $\rm P$ on an ellipse; the slope of the tangent (or normal) to the ellipse at $\rm P$ ; and the horizontal and vertical distances from the ellipse’s center and $\rm P$ , how I can mathematically represent the ellipse? I'm sure that was unintelligible, so pictorally, here is the situation: As you can see, for simplicity, I've taken the liberty of placing the ellipse where the center is on the x-axis, because that works for me.  I've made my fixed point on the horizontal x-axis at the origin, also for simplicity (you'll see why later).  I know the location of the point on the ellipse $(-c, d)$ , and I know the angle/slope of the normal at that point (which I've called $\phi$ , and therefore also the tangent.  Since I have made the ellipse pass through the origin, I know the center of the ellipse is at $(-a, 0)$ .  However, I am struggling to determine the values of $a$ and $b$ that I need to complete the equation for the ellipse. Here's my actual use case: there's a rectangular robot, and a target that I want to drive to.  That target is on a wall, which is likely at an angle to robot.  I want the robot to arrive at the wall with the front of the robot flat against the wall, meaning that direction the robot travels the instant it touches the wall is perpendicular to it.  I thought that I should be able to follow the elliptical arc for a nice, smooth path to achieve that.  But to do that, I need to represent the ellipse mathematically. Basically, here's what I'm looking to do: I know the points $(u, v)$ and $(x, y)$ , relative to the robot, that are on the target wall, equidistant from the target point itself, and can therefore identify the location of the target, and the angle/slope of the target wall.  I could also easily flip that to identify the tangent at that point. I want to identify that magenta path so that I can have the robot follow it.  I want to do this computationally on the fly, which also means I can't plug values into an equation and solve ""interactively"". By looking around this site, I've found that the equation for the normal at $(X, Y)$ is: $\frac{(X-h)(y-Y)}{a^2}-\frac{(x-X)(Y-k)}{b^2}=0$ , which in my case means that: $\frac{(-c+a)(y-d)}{a^2}-\frac{(x+c)d}{b^2}=0$ , but I cannot get much further than that, and could really use some help.","['trigonometry', 'conic-sections', 'geometry']"
3078707,"How to show $\text{Tr}(M\log N)=\sum_{i,j}^n\lambda_i\log(\tilde{\lambda_j})(u_i^{\top}\tilde{u}_j)^2$?","The above question is the equation $(2.4)$ of the following paper: MATRIX EXPONENTIATED GRADIENT UPDATES . Let $M$ and $N$ be two $n \times n$ positive definite matrices where $M=U\Lambda U^{\top}$ , $N=\tilde{U}\tilde{\Lambda} \tilde{U}^{\top} 
$ and $(\lambda_i,v_i)$ are eigenpairs of $M$ , likewise for $N$ . How to show the following $$\text{Tr}(M\log N)=\sum_{i,j}\lambda_i\log(\tilde{\lambda_j})(u_i^{\top}\tilde{u}_j)^2$$ First I do not know what $i,j$ mean in summation, and how we have it using two summations. Second how to get that. My try: \begin{align}
\text{Tr}(M\log N) &=
\text{Tr}(U\Lambda U^{\top}
\tilde{U}\log(\tilde{\Lambda})\tilde{U}^{\top}) \\
& = \text{Tr}(\Lambda U^{\top}
\tilde{U}\log(\tilde{\Lambda})\tilde{U}^{\top}U)
\end{align} How can I proceed using matrix calculus to get the result not by expanding? what is the hidden trick?","['matrices', 'linear-algebra', 'positive-definite', 'symmetric-matrices']"
3078725,How do I find the order of a bijection?,"Question: List all bijections (permutations) from $\{1, 2, 3\}$ onto $\{1, 2, 3\}$ . Find their order and sign. I understand there will be n! permutations, namely: $
\begin{Bmatrix}
    1 & 2 & 3 \\
    1 & 2 & 3 \\
\end{Bmatrix}
$ , $
\begin{Bmatrix}
    1 & 2 & 3 \\
    1 & 3 & 2 \\
\end{Bmatrix}
$ , $
\begin{Bmatrix}
    1 & 2 & 3 \\
    2 & 1 & 3 \\
\end{Bmatrix}
$ , $
\begin{Bmatrix}
    1 & 2 & 3 \\
    2 & 3 & 1 \\
\end{Bmatrix}
$ , $
\begin{Bmatrix}
    1 & 2 & 3 \\
    3 & 1 & 2 \\
\end{Bmatrix}
$ , $
\begin{Bmatrix}
    1 & 2 & 3 \\
    3 & 2 & 1 \\
\end{Bmatrix}
$ I understand that order of a permutation $\sigma$ is the smallest possible integer $k$ such that $\sigma^k = \epsilon$ , where $\epsilon$ is the identity permutation. But I am confused by the definition of ""identity permutation"". If my identity is: $$
\begin{Bmatrix}
    1 & 2 & 3 \\
    1 & 2 & 3 \\
\end{Bmatrix}
$$ then order $= 0$ and sign = $(-1)^k = (-1)^0 = 1$ . And for: $
\begin{Bmatrix}
    1 & 2 & 3 \\
    1 & 3 & 2 \\
\end{Bmatrix}
$ , order $= 1$ , sign $= -1$ . And for $
\begin{Bmatrix}
    1 & 2 & 3 \\
    2 & 3 & 1 \\
\end{Bmatrix}
$ order $= 2$ , sign $= 1$ . But if my first bijection from $\{1, 2, 3\}$ onto $\{1, 2, 3\}$ is: $$
\begin{Bmatrix}
    1 & 2 & 3 \\
    2 & 3 & 1 \\
\end{Bmatrix}
$$ then order $= 0$ and sign $= 1$ . So depending on which projection I chose as an identity, the order differs. Can someone clarify?","['elementary-set-theory', 'group-theory', 'symmetric-groups', 'permutations']"
3078774,Find the attractor of the sequence of orthic triangles (formed by joining the feet of altitudes of the previous triangle).,"Triangle 1 (see the picture) is given. Find the point toward which the vertices of triangle n -> infinity converge, assuming that triangle n is constructed by uniting the feet of the altitudes of triangle n-1. Sequence of triangles formed by the above mentioned rule. For the definition of ""foot of an altitude"" please see: Perpendicular Foot","['triangles', 'geometry']"
3078851,A notion of adjacency-matrix symmetry?,"I have a set of adjacency matrices that have a certain property, and I am trying to figure out what features of the adjacency matrix deliver that property and whether this property has a name. Here is the property: Let $A$ be an adjacency matrix for an undirected graph. Such a matrix has Property $X$ if all the diagonal elements of $A$ are the same (which of course they are trivially), all the diagonal elements of $A^2$ are the same, all the diagonal elements of $A^3$ are the same, and so on for all powers of $A$ . Another way of describing this property is that for each node $i$ , there are the same number of walks of length $k$ from node $i$ to itself for all $k$ . Thanks!","['matrices', 'graph-theory', 'linear-algebra']"
3078862,How do you integrate $\int \frac{\cos(4x)}{\cos(x)}dx$?,"I tried using trigonometric formulas for turning it into 2 $\int \frac{\cos^2(2x)}{\cos(x)}dx - \int \frac{1}{\cos(x)}dx$ and can solve the second one, but still no idea of how to proceed with $\int \frac{\cos^2(2x)}{\cos(x)}dx$ . Any suggestion?","['integration', 'indefinite-integrals', 'trigonometry']"
3078891,Scalar Multiplication of a Set,"I am aware of how one can represent the Cartesian product of two sets, say $A$ and $B$ . However, is there are standard way to represent the scalar product of a value and a set/multiset? As a simple example (with a multiset), let $P = \{1, 2, 3, 4, 2\}$ and $q = 2$ .  Then $$q \cdot P := \{(1 \cdot 2),(2 \cdot 2),(3 \cdot 2), (4 \cdot 2), (2 \cdot 2)\} = \{2, 4, 6, 8, 4 \}. $$ Could this be the appropriate notation for a scalar product? I'm not entirely certain scalar multiplication of a value and a set exists as I haven't been able to find it anywhere in books or online––if this is the case, is it because set are immutable? In case it is asked, I am unfortunately unable in this example to make $P$ a vector and do the same operation.","['elementary-set-theory', 'notation']"
3078918,Differentiability of simple zero of a polynomial curve,"Suppose $f(x, t) = x^n + a_{n-1}(t) x^{n-1} + \dots + a_0(t) \in \mathbb R[x]$ where each $a_j(t) \in C^{\infty}(\mathbb R)$ . If $x_0 \in \mathbb C$ is a simple zero of $f(x, t_0)$ , I want to know if there is a $C^{\infty}$ function $\eta: I \to \mathbb C$ such that $\eta(t_0) = x_0$ and $\eta(t)$ is a zero for $f(x, t)$ for every $t \in I$ and $I$ is some interval with $t_0 \in I$ . Clearly, a zero should be a function over the coefficients and thus a function over $t$ . By chain rule, we can formally differentiate with respect to $t$ and get $f(x(t))' = f'(x(t)) x'(t)$ here $x$ can be equivalently viewed as $\eta$ . At $t_0$ , $f'(x(t_0)) = f'(x_0) \neq 0$ . I want to say by inverse function theorem, $\eta$ is defined for some $I$ . But I got suspicious over the first step. I am not convinced why I can do that?","['complex-analysis', 'abstract-algebra', 'polynomials']"
3078938,Show that the $\text{Tr}(A)^2 = \text{Tr}(A^2)+\text{Sum of Eigenvalues} $,"Let $A$ be a square $ m \times m $ with eigenvalues $\lambda_{i},...,\lambda_{m}$ . Show that: $$
[\text{Tr}(A)]^{2} =\text{Tr}(A^{2}) + \sum_{i \neq j} \lambda_{i}\lambda_{j}
$$ Here is my attempt: LHS $$
[\text{Tr}(A)]^{2} = \sum_{i =1}^{m} \lambda_{i}\sum_{j =1}^{m}\lambda_{j} = \sum_{i =1}^{m}\sum_{j =1}^{m} \lambda_{i}\lambda_{j}
$$ RHS It can be shown that $\lambda_{i}^{2}$ is an eigenvalue of $A^{2}$ so: $$
\text{Tr}(A^{2}) + \sum_{i \neq j} \lambda_{i}\lambda_{j} = \sum_{i =1}^{m} \lambda_{i}^{2} + \sum_{i \neq j} \lambda_{i}\lambda_{j}
$$ $$
= \sum_{i =1}^{m}\sum_{j =1}^{m} \lambda_{i}\lambda_{j}
$$ Does this make sense?","['matrices', 'trace', 'linear-algebra', 'eigenvalues-eigenvectors']"
3078942,What does do Carmo mean here and also what is a curve parametrized by arc length?,"From do Carmo Differential Geometry: In the third paragraph, Do Carmo says: it can happen that the parameter $t$ is already the arc length
  measured from some point. What does he mean by this? Also, what does he mean by curves parametrized by arc length ?","['calculus', 'differential-geometry']"
3078953,What does the value of a PDF mean? [duplicate],"This question already has answers here : What does the value of a probability density function (PDF) at some x indicate? (6 answers) Closed 5 years ago . I understand that the integral of a PDF provides tangible value --i.e., the integral of a PDF allows one to see the probability of a value or less than that value, under a particular distribution, occurring. But, what does the value of just the output of the PDF provide? In other words, what does the PDF of the standard normal distribution at x=0.5 mean?",['probability']
3078955,What's the value of $\sum\limits_{k=1}^{\infty}\frac{k^2}{k!}$?,"For some series, it is easy to say whether it is convergent or not by the ""convergence test"", e.g., ratio test. However, it is nontrivial to calculate the value of the sum when the series converges. The question is motivated from the simple exercise to determining whether the series $\sum\limits_{k=1}^{\infty}\frac{k^2}{k!}$ is convergent. One may immediately get that it is convergent by the ratio test. So here is my question: What's the value of $$\sum_{k=1}^{\infty}\frac{k^2}{k!}?$$","['factorial', 'real-analysis', 'calculus', 'sequences-and-series', 'exponential-function']"
3079002,Double Summation: Help needed with proof,"This question is about Theorem 8.3 of Baby Rudin: what I don't understand is: What is $E$ ? Is it subset of any metric space? Also, I can't see how $f_i$ continuous at $x_0$ , because we are talking about only one sequence of set, converging to $x_0$ . I have been struggling since yesterday to figure out why $$\lim\limits_{n\to\infty}\sum_{i=1}^{\infty}\sum_{j=1}^n a_{ij}=\lim\limits_{n\to\infty}\sum_{j=1}^n\sum_{i=1}^{\infty} a_{ij}$$ is permissible, and why $\lim\limits_{n\to\infty}\sum_{j=1}^n\sum_{i=1}^{\infty} a_{ij}$ indeed converges.","['limits', 'summation', 'sequences-and-series', 'real-analysis']"
3079113,A sequence of $rs + 1$ real numbers has an increasing subsequence of length $r + 1$ or a decreasing subsequence of length $s + 1$.,"Problem : Prove the following: a sequence of $rs + 1$ real numbers has an increasing subsequence of length $r + 1$ or a decreasing subsequence of length $s + 1$ . Solution : Define a partial ordering on the sequence $a _ { 1 } , \ldots , a _ { r s + 1 }$ by $a _ { i } \preceq a _ { j }$ iff, $a _ { i } \leq a _ { j }$ and $i \leq j$ A chain is an increasing subsequence, an antichain is a decreasing subsequence. Now I would like to apply Dilworth theorem. Suppose that the maximum size of a chain is $r+1$ , the poset can be partitioned into $r+1$ antichain. However from there I don't now how to continue, what would be size of those antichains?","['elementary-set-theory', 'combinatorics', 'discrete-mathematics', 'sequences-and-series']"
3079116,"Find a point $X$, in the plane of regular pentagon $ABCDE$, that minimizes $\frac{XA+XB}{XC+XD+XE}$.","Find such a point $X$ , in the plane of the regular pentagon $ABCDE$ , that the value of expression $$\frac{XA+XB}{XC+XD+XE}$$ is the lowest. I tried using Ptolemy's theorem but don't know how to make use of inequalities it gives. I'd be really grateful for any help :)","['euclidean-geometry', 'geometry', 'maxima-minima', 'geometric-inequalities', 'optimization']"
3079148,"In $\triangle ABC$ with $AB=AC$ and $\angle BAC=20^\circ$, $D$ is on $AC$, with $BC=AD$. Find $\angle DBC$. Where's my error?","In $\triangle ABC$ with $AB=AC$ and $\angle BAC=20^\circ$ , point $D$ is on $AC$ , with $BC=AD$ . Find $\angle DBC$ . I know the correct solution, but I'm more interested in where is the problem in my solution. My solution : Now in $\triangle ABD$ , applying the sine rule: $$\frac{AD}{\sin\alpha} = \frac{BD}{\sin 20^\circ} \tag{1}$$ In $\triangle BDC$ : $$\frac{BD}{\sin 80^\circ} = \frac{BC}{\sin(180^\circ-\beta)} \tag{2}$$ We know $AD= BC$ ; put in to $(1)$ : $$\frac{BC}{\sin\alpha} = \frac{BD}{\sin 20^\circ}  \tag{3}$$ Comparing $(2)$ and $(3)$ : $$\frac{BC}{BD} = \frac{\sin\alpha}{\sin 20^\circ} = \frac{\sin(180^\circ-\beta)}{\sin 80^\circ} \tag{4}$$ $$\frac{\sin \alpha}{\sin(180^\circ-\beta)} = \frac{\sin 20^\circ}{\sin 80^\circ} \tag{5}$$ Now, $\alpha = 20^\circ$ and $\beta = 100^\circ$ , but when I plug these values in $\triangle ABC$ , it's not even triangle. oO Where I am wrong? Thanks. PS : sorry for poor editing, I don't have any clue about it.",['geometry']
3079166,"What is the difference between ""equality"" and ""equivalence relation""","I think equality is just an instance of equivalence relation. An equivalence relation can be defined in the set theory, but how can we define ""equality""? I wonder what equality is.","['elementary-set-theory', 'logic']"
3079222,Compact embedding of the domain and compact inverse,"I have several problems in showing this point of a problem:
we consider $X$ Banach space and $T: D(T) \to X$ a closed operator with domain $D(T) \subseteq X$ . Let be $T$ bounded, invertible and suppose the embedding $(D(T),\|\cdot \|_T) \to (X,\|\cdot\|_X)$ is compact.
I have to show that $T^{-1}$ is compact. Firstly I consider $\|\cdot \|_T$ as the graph norm.
Then I started thinking that an unbounded operator $T$ with domain $D(T)$ is bounded, invertible if there is a map $T^{-1}$ with image $D(T)$ and $TT^{-1}x = x$ for every $x \in X$ and $T^{-1}Tu = u$ for every $u \in D(T)$ . But I don't have any idea how to proceed. Could someone help me to show the compactness?","['inverse', 'functional-analysis', 'compact-operators']"
3079229,Collection: Results on stopping times for Brownian motion (with drift),"The aim of this question is to collect results on stopping times of Brownian motion (possibly with drift), with a focus on distributional properties: distributions of stopping times (Laplace transform, moments,..) distributional properties of the stopped process (computation/finiteness of moments, ...) Many of the results, which I have in mind, are typical homework problems. What is the motivation for such a collection? There is a number of ""classical"" stopping times for Brownian motion, but unfortunately these stopping times don't have a specific name (apart from ""exit time"", ""hitting time"", ... - which is also not very specific), and this makes it hard to find results here on StackExchange. Sometimes, when I'm looking for a result, I know that it is somewhere here on MSE but I'm simply not able to find it. For other questions, which are asked very frequently in MSE, it is often difficult to find a good ""old"" answer. In any case, I believe that it would be a benefit to make the knowledge easier to access - both for students (who are trying to solve their homework problems) as for the ""teachers"" (who are answering questions on MSE). To make this list a helpful tool (e.g. for answering questions) please make sure to give a short but concise description of each result which you list in your answer.","['stopping-times', 'big-list', 'brownian-motion', 'probability-theory']"
3079279,Books/Lecture notes about 2-categories.,Are there good books or lecture notes just about 2-categories?(not about higher categories nor $\infty$ -categories) (I'm studying fibered categories for the descent theory of quasi-coherent sheaves. I want to understand fibered categories from 2-categorical view point.),"['book-recommendation', 'category-theory', '2-categories', 'reference-request', 'algebraic-geometry']"
3079312,"What is the definition of ""equality""","I thought we could define ""the equality on set $A$ "" by the relation $\{(a,a):a\in A\}\subseteq A^2$ . However, no book has this definition. Moreover, some books say that this is the ""diagonal relation"". Is it just another name for the equality? Of course I am also interested in the general properties of equality, but now I wonder if the above definition makes sense.","['elementary-set-theory', 'logic']"
3079320,Are all Fibonacci words uniquely represented as concatenation of two palindromes?,"Suppose Fibonacci word sequence is a word sequence defined by the following relations: $$\phi_1 = «0»$$ $$\phi_2 = «01»$$ $$\forall n > 2 \text{ } \phi_n = \phi_{n - 1}\phi_{n - 2}$$ Let’s prove, that for every natural n, there exist two palindromes $\alpha_n$ and $\beta_n$ , such that $\phi_n = \alpha_n\beta_n$ It is well known, that
1. The last two letters of a Fibonacci word are alternately $«01»$ and $«10»$ 2. Suppressing the last two letters of a Fibonacci word, or prefixing the complement of the last two letters, creates a palindrome Suppose $\phi_{2n+1} = \alpha_{2n + 1}^110$ and $\phi_{2n} = \alpha_{2n}^101$ . Then, if we we can take $\beta_{2(n + 1)}^1 = 01\alpha_{2n + 1}^110$ and $\beta_{2n + 1}^1 = 10\alpha_{2n}^101$ . Then, it is easy to see that $\alpha^1_n$ and $\beta_n^1$ satisfy the aforementioned conditions for every natural $n \geq 2$ However I failed to find an answer to the question: «Does there exist a natural number $n$ and two palindromes $\alpha$ and $\beta$ , not equal to $\alpha_n^1$ and $\beta_n^1$ respectively, such that $\phi_n = \alpha\beta$ ?» Any help will be appreciated.","['fibonacci-numbers', 'combinatorics-on-words', 'recurrence-relations', 'palindrome', 'combinatorics']"
3079386,Simple example of invariants,"The combinatorics textbook I'm reading introduces invariants with the following example: There are three piles with $n$ tokens each. In every step we are allowed
  to choose two piles, take one token from each of those two piles and add a token to
  the third pile. Using these moves, is it possible to end up having only one token? Solution: To the tokens in the first pile we can assign the pair $(0, 1)$ , to the tokens
in the second pile the pair $(1, 0)$ and to the tokens in the third pile the pair $(1, 1)$ . Notice that the sum modulo $2$ of any two of these pairs give us the third one. Thus,
in every step the sum modulo $2$ of all the assigned pairs is the same. However, the
sum of all the assigned pairs in the beginning is $(2n, 2n)$ , which is equal to $(0, 0)$ modulo $2$ . Since this pair was not assigned to any pile, it is not possible to end up
with only one token. Although I already knew what invariants are, I do not understand how they're applied in this specific case, what is the meaning of the pairs that are assigned to each pile, and how is a pair affected by a step?","['invariance', 'combinatorics']"
3079406,Problemsolving with weights and their labels,"The problem is stated as follows: With a balance scale and six given weights; 1g, 2g, 3g, 4g, 5g and 6g, is it possible to make sure the labels on the weights are put on correctly only using the scale twice? Assume there is no way to identify weights by apperance, and that only the labels might have gotten in the wrong place (ie there is exactly one of each). I've come as far as realizing a good way to start would be to balance 6g towards 1+2+3g. If balanced, the 6g weight must be correct, and 1g, 2g, 3g can only have switched labels with each other. It gives no direct info on 4g and 5g, but they can only have switched with each other. With that in mind, the next step must include exactly 2 out of 1g, 2g, 3g but not both on the same side of the scale (as we still wouldn't know if they have each other's labels in that case), and atleast one of 4g, 5g. Furthermore, if we choose 1g and 2g we might confuse ourself and not realizing that the switch 1g->2g->3g->1g has been made, and same thing with 2g+3g, therefore the weight labeled 1g on one side and and 3g on the other is the best option. But where do I go from here? I've tried so many things but always end up with some sort of ambiguity. That is not a solid proof that it is not possible, however. Do anyone have a way of succeeding in two uses of the scale, or a way of prooving that it is not possible?","['recreational-mathematics', 'puzzle', 'discrete-mathematics']"
3079408,"How to solve the integral $\int_{B(0,1)} xy(x+z)(y+z)dxdydz$?","How to solve the integral $$\int_{B(0,1)} xy(x+z)(y+z)dxdydz$$ where $B(0,1)=\{ (x,y,z) | x^2 + y^2 + z^2 < 1\}$ ? I tried using spherical coordinates, but it turned out ugly.
I then tried solving without any substitution but it wasn't so pleasant as well. I think to use the substitution $u=xy, v = x+z, w = y+z$ but I can't determine the range. I also am not sure if it is a diffeomorphism. Any suggestions? Help would be appreciated","['integration', 'multivariable-calculus', 'calculus']"
3079433,Is there always exactly one solution to $a \cos\left(\frac{x}{2}\right)- b \sin\left(\frac{x}{2}\right) = 0$ in the interval $0\leq x\leq 2\pi$?,"I have a probably simple question.
If I have an equation like \begin{align}
a \cos \left(\frac{x}{2}\right) - b \sin \left(\frac{x}{2}\right) &= 0\\
\frac ab \cos \left(\frac{x}{2}\right) -  \sin \left(\frac{x}{2}\right) &= 0
\end{align} with $a, b > 0$ . Is it true that there is always precisely one solution in the interval $0 \leq x \leq 2 \pi$ . I think it is obvious, but can I use this in a proof without proving it?",['trigonometry']
3079444,"Find limit of $(a_n)$ if $a_n=\frac{1}{k}\sum\limits_{i=1}^{k}a_{n-i}$, $a_0=1$ and $a_{-n}=0$ for $n>0$","We have a sequence $a_n$ which solves the recurrence relation $$a_n=\frac{1}{k}\sum\limits_{i=1}^{k}a_{n-i}$$ for any $n>0$ with a given $k$ . Let the initial values be $a_0=1$ and $a_{-n}=0$ for any $n>0$ . I wrote a program and found that the sequence should have a limit $\frac{2}{k+1}$ , but I can't figure out how to prove it.","['limits', 'recurrence-relations', 'sequences-and-series']"
3079448,Can we multiply both sides of a limit equation?,"Compute $\lim_{x \to -1} f(x)$ for a function $f: \mathbb R \to \mathbb R$ such that $$4 = \lim_{x \to -1} \frac{f(x)+2}{x+1} - \frac{x}{x^2-1} \tag{1}$$ $$ = \lim_{x \to -1} \frac{f(x)+2}{x+1} - \frac{\frac{x}{x-1}}{x+1}$$ $$ = \lim_{x \to -1} \frac{f(x)+2 - \frac{x}{x-1}}{x+1}$$ Solution 1: My approach is that the numerator $f(x)+2 - \frac{x}{x-1}$ must approach zero as $x \to -1$ because the denominator approaches zero as $x \to -1$ and so $\lim_{x \to -1} f(x) = -\frac{3}{2}$ . Are we allowed to do the following, which seems to be the required solution, instead ? This does not seem very rigorous, and I have a feeling there are obvious counterexamples. Of course, we can use $\varepsilon-\delta$ to check our answer, but I would like to know if and how this can be generalised for any function $f: \mathbb R \to \mathbb R$ . Solution 2: Observe $$0 = \lim_{x \to -1} x+1$$ Then $$4 = \lim_{x \to -1} \frac{f(x)+2 - \frac{x}{x-1}}{x+1}$$ $$\implies 0 = 0 \cdot 4 = (\lim_{x \to -1} x+1) \cdot 4 = \lim_{x \to -1} \frac{f(x)+2 - \frac{x}{x-1}}{x+1} \lim_{x \to -1} x+1$$ $$ = \lim_{x \to -1} \frac{f(x)+2 - \frac{x}{x-1}}{x+1} x+1 = \lim_{x \to -1} (f(x)+2 - \frac{x}{x-1})$$ $$ = \lim_{x \to -1} f(x) + \lim_{x \to -1} 2 - \lim_{x \to -1} \frac{x}{x-1} = \lim_{x \to -1} f(x)+2 - \frac12 = \lim_{x \to -1} f(x)+ \frac32$$ $$\implies - \frac32 = \lim_{x \to -1} f(x) \tag{2}$$ I suspect the preceding solution is not rigorous, and this is a case where we have only a guess and must check our answer by proving $(1)$ , by computation since $\varepsilon-\delta$ is actually not yet allowed, assuming $(2)$ , so if one does then preceding solution, then one must follow up with a computation. I'm not quite sure what the problem is, but it might be that we don't know $\lim_{x \to -1} f(x)$ exists in the first place. Is the fact that the domain and range are both $\mathbb R$ relevant? I think of a counterexample like $f: \{7,8,10\} \to \{1,2\}$ or $f: C \to \mathbb Q^c$ where $C$ is the Cantor set.","['alternative-proof', 'limits', 'calculus', 'real-analysis']"
3079492,"Functions and sets. Show that if A is a subset of X, then $f^{-1}(f(A))\supseteq A$. Find an example where $f^{-1}(f(A))\neq A$.","I have proved that if $A$ is subset of $X$ , then $f^{-1}(f(A))\supseteq A$ for any function $f:X\rightarrow Y$ . However, I can't find an example where $f^{-1}(f(A))\neq A$ .","['discrete-mathematics', 'real-analysis']"
3079493,irreducible representations and character table of $D_6$,"Let $$D_6=\langle a,b| a^6=b^2=1, ab=ba^{-1}\rangle$$ $$D_6=\{1,a,a^2,a^3,a^4,a^5,b,ab,a^2b,a^3b,a^4b,a^5b\}$$ I would like to compute its character table and its irreducible representations. I will explain what I have done so far and I will add some doubts I had while doing this. MY ATTEMPT Compute conjugacy classes. $$C_1=\{e\}, C_2=\{a,a^5\},C_3=\{a^2,a^4\}$$ $$C_4=\{a^3\},C_5=\{b,a^2b,a^4b\},C_6=\{ab,a^3b,a^5b\}$$ Find $1$ -dimensional representations. Since $D_6/\{a,a^5\}\cong \mathbb{Z}_2$ , we have one more representation apart from $\alpha_1=id$ . That is $$\alpha_2: G \longrightarrow \mathbb{C}: a \mapsto 1, b\mapsto -1$$ Again using irreducible representations from quotient group by normal subgroup, I considered $G/\{\overline{1},\overline{a},\overline{b},\overline{ab}\}\cong \mathbb{Z}_2\times\mathbb{Z}_2$ (since it is abelian). Then from here I obtained $$\alpha_3:G\longrightarrow \mathbb{C}: a\mapsto -1, b\mapsto 1$$ $$\alpha_4:G\longrightarrow \mathbb{C}: a\mapsto -1, b\mapsto -1$$ Find $2$ -dimensional representations. I have seen in my notes that for $D_n$ we can define $2$ -dimensional representations: $$\alpha_5: G\longrightarrow GL_2(\mathbb{C}): a\mapsto \begin{bmatrix}cos(\frac{2\pi}{n}) & -sin(\frac{2\pi}{n})\\ sin(\frac{2\pi}{n}) &cos(\frac{2\pi}{n})\end{bmatrix}, b\mapsto \begin{bmatrix}1 & 0\\ 0 &-1\end{bmatrix}$$ Hence my $$\alpha_5: G\longrightarrow GL_2(\mathbb{C}): a\mapsto \begin{bmatrix}\frac{1}{2} & -\frac{\sqrt{3}}{2}\\ \frac{\sqrt{3}}{2} &\frac{1}{2}\end{bmatrix}, b\mapsto \begin{bmatrix}1 & 0\\ 0 &-1\end{bmatrix}$$ Build my character table. \begin{array}{|c|c|c|c|}
\hline
& C_1 & C_2 &C_3 &C_4 &C_5 &C_6 \\ \hline
\chi_1& 1 & 1 &1 &1 &1&1 \\ \hline
\chi_2& 1 & 1 &1 &1 &-1 &-1 \\ \hline
\chi_3& 1 & -1 &1 &-1 &1 &-1 \\ \hline
\chi_4& 1 & -1 &1 &-1 &-1 &1 \\ \hline
\chi_5& 2 & 1 &-1 &-2 &0 &0 \\ \hline
\chi_6& 2 & -1 &-1 &2 &0 &0 \\ \hline
\end{array} where I have computed $\chi_6$ by the orthogonality formula $(\chi_6|\chi_j)=\delta_{6,j}$ . QUESTIONS Is $D_6/\{a^2,a^4\}$ really abelian? I can not see it clearly. My first question comes when I have to find $2$ -dimensional irreducible representations. I have find them because I have seen it in my notes. But how could I get $\alpha_5$ and $\alpha_6$ without knowing the special case of $D_n$ . I know that I also could get it from $S_3$ (one of them). But I have again the same problem, if you are looking for $2$ -dimensional irreducible representations of $S_3$ , how do you find them? (Both). Now consider $X$ to be the set of the vertices of a regular $6$ -gon and consider the action of $D_6$ on the set $X$ by restricting the usual action of $D_6$ on the $6$ -gon to the set of vertices $X$ . Let $\phi$ be the induced permutation representation (over $\mathbb{C}$ ) of $D_6$ . I would like to write it as a sum of irreducible representations by computing the in-product of the irreducible characters with $\chi_{\phi}$ . What should I do? I do not understand this induced permutation representation. Any help?","['group-theory', 'representation-theory', 'characters']"
3079497,Differentiability through paths,"Let $f:\mathbb{R}^{2} \to \mathbb{R}$ defined by $$f(x) = \begin{cases}\displaystyle\frac{x^{3}}{x^{2}+y^{2}},& (x,y)\neq (0,0)\\ 0,& (x,y) = (0,0)\end{cases}.$$ Show that $f$ is not differentiable in $(0,0)$ , however, show that for every differentiable path $\lambda: (0,1) \to \mathbb{R}^{2}$ , passing through origin, $f \circ \lambda$ is differentiable. My problem is in the second part. If $\lambda: \mathbb{R} \to \mathbb{R}^{2}$ is a line pararallel to $e_{i}$ passing through $0$ , $\lambda(t) = (0,0) + te_{i}$ , I can show that $(f\circ \lambda)'(0) = \frac{\partial}{\partial x_{i}}f(0,0)$ . I've tried to generalize this to an arbitrary path with domain $(0,1)$ , but I couldnt. Can someone help me?","['derivatives', 'real-analysis']"
3079513,"Avoiding choice in proving ""Sequential compactness implies Lebesgue Number Lemma""","The standard proof can be found in ProofWiki . From what it is shown on that, it uses the Axiom of Countable Choice when choosing the subsequence $\{x_n\}$ to produce a contradiction. And normally, as I discover, when some instances of AC is used on ProofWiki, it will be remarked at the bottom of the page. So this leads me to question whether AC is indeed necessary here. Please provide some clarification. Thanks in advance. Context: This is a step in proving ""sequential compactness implies compactness for metric spaces"". I know it must use AC at a certain point, but is it here?","['axiom-of-choice', 'general-topology', 'set-theory']"
3079520,Evaluating definite integrals using Fundamental Theorem of Calculus,"Here is a statement of the second part of the Fundamental Theorem of Calculus (FTC2), from a well-known calculus text (James Stewart, Calculus , 4th ed): If $f$ is continuous on $[a,b]$ , then $\int_a^b f(x) \, dx = F(b)-F(a)$ , where $F$ is any [emphasis mine] antiderivative of $f$ , that is, a function such that $F'=f$ . The following, however, seems to give a counterexample.* Can someone resolve this for me?: Let $f(x) = \frac{1}{4 \sin (x)+5}$ . $f$ is continuous on $[0, 2 \pi]$ : Consider two antiderivatives of $f$ , $F_1$ and $F_2$ : $$F_1(x) = \frac{x}{3}+\frac{2}{3} \tan^{-1}\left(\frac{\cos (x)}{\sin (x)+2}\right)$$ $$F_2(x)=\frac{1}{3} \left(\tan ^{-1}\left(2-\frac{3}{\tan \left(\frac{x}{2}\right)+2}\right)-\tan^{-1}\left(2-\frac{3}{\cot \left(\frac{x}{2}\right)+2}\right)\right).$$ Using Mathematica, I've confirmed that both $F_1'= f$ and $F_2'= f$ .  According to my reading of the above statement of FTC(2), $\int_0^{2\pi} f (x) \, dx = F_1(2\pi)-F_1(0)= F_2(2\pi)-F_2(0)$ However, $F_1(2\pi)-F_1(0)=2\pi/3$ $F_2(2\pi)-F_2(0)=0$ Note from the plots below that $F_1$ is continuous on $[a,b]$ , while $F_2$ is not.  Given all of this, it seems the sufficient condition for $\int_a^b f (x) \, dx = F(b)-F(a)$ is that the antiderivative be continuous on $[a,b]$ , not the integrand. $F_1 =$ $F_2=$ *I've taken this example function from a wolfram.com blog.","['calculus', 'definite-integrals']"
3079553,Optimal code for simple game,"Setup : Alice and Bob are playing a cooperative game. Alice chooses a number $y \in \{1, 2, 3, 4\}$ uniformly at random. Bob doesn't observe $y$ ; his goal is to guess $y$ . Alice can send Bob a message $z$ that contains at most 1 bit of information about $y$ (i.e., $I(z;y) = 1$ ). Problem : How should Alice encode information about $y$ into her message $z$ ? Potential Solutions : I have three ideas for what Alice should do, but they all give contradictory answers. If $y \in \{1, 2\}$ , Alice sends $z = 0$ ; otherwise, Alice sends $z = 1$ . The code $z$ contains 1 bit of information. Bob will guess $y$ correctly with probability 0.5. With probability 1/2, Alice sends $z = y$ (2 bits); otherwise, Alice sends some null message (0 bits). Thus, Alice sends 1 bit in expectation. Bob will guess $y$ correctly in the first case; in the second case, he will guess randomly and be correct with probability 0.25. In total, Bob will guess $y$ correctly with probability $0.5 \cdot 1.0 + 0.5 \cdot 0.25 = 0.625$ . Alice samples $z$ from the following 4-dimensional Categorical distribution that places probability 0.811 on $z = y$ and probability 0.063 on the other 3 atoms. The marginal $p(z)$ is uniform, so $H(z) = \log_2(4) = 2$ ; the conditional $p(z \mid y)$ has entropy $$H(z \mid y) = 0.811 \cdot \log_2(\frac{1}{0.811}) + 3 \cdot 0.063 \cdot \log_2(\frac{1}{0.063}) \approx 1 $$ The information content of Alice's message is $I(z;y) = H(z) - H(z \mid y) = 1$ . Bob's guess will be whatever message Alice sends, so he'll guess $y$ correctly with probability 0.811.","['coding-theory', 'probability', 'information-theory']"
3079591,"Suggestions of long and complex formulas/equations, for practicing memorization (It's my hobby.)","First, I'm not a mathematician; my hobby is mainly memorization. I want to  practice math formulas and/or equations memorization. In that way, I'm looking for large and complex formulas or equations for memorization practice, nothing for academically goals. So, what are your suggestions? What formula or equation do you believe is large and complex and represents difficult memorization?","['algebra-precalculus', 'recreational-mathematics']"
3079620,Finding the derivative of $x^2|x|$,"Usually, for a question involving products, my first approach would be to apply the product rule, giving $\frac{d}{dx}(x^2|x|)=x^2(\frac{d}{dx}|x|)+|x|2x$ .
Using methods discussed here ( Finding the Derivative of |x| using the Limit Definition ), I got $\frac{d}{dx}|x|=\frac{x}{|x|}$ , so subsituting this in gives $\frac{d}{dx}(x^2|x|)=\frac{x^3}{|x|}+2x|x|$ . However, the derivative of $x^2|x|$ is in fact equal to $3x|x|$ . Where have I gone wrong? I also tried using $\frac{df(x)}{dx}=\lim_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}$ , which gave $\frac{x^2|x|-x_0^2|x_0|}{x-x_0}\rightarrow\frac{x^2_0|x_0|-x_0^2|x_0|}{x_0-x_0}=0$ as $x\rightarrow x_0$ - I need to get $3x|x|$ , so this can't be right! Any help would be much appreciated.","['limits', 'derivatives', 'real-analysis']"
3079695,Intriguing geometry problem regarding isogonal lines,"A line $r$ contains the points $A,B,C,D$ in this order. Let $P\notin r$ such that $$\angle APB=\angle CPD$$ Denote furthermore by $G$ the intersection of the angle bisector of $\angle APD$ and $r$ . Prove that $$\frac{1}{GA}+\frac{1}{GC}=\frac{1}{GB}+\frac{1}{GD}$$ My attempt so far: Let $\Delta APD$ be a triangle, then $PB$ and $PC$ are isogonal lines. Hence $$\frac{AB}{BD}·\frac{AC}{CD}=\Bigl(\frac{AG}{GD}\Bigr)^2$$ (This fact might be proven with the Sine Law) I don't know how to proceed now...","['contest-math', 'euclidean-geometry', 'projective-geometry', 'trigonometry', 'geometric-transformation']"
3079714,Exercise: first-order linear differential equation,"This is a first-order linear differential equation: $$y' = -ky + p$$ where $k$ and $p$ are constant. Based on my calculations, the solution is $$y(x) = y(0) \cdot \exp^{-kx} + \; \dfrac{p}{k}$$ while my teacher's file says $$y(x) = \dfrac{p}{k} + \left[y(0) - \dfrac{p}{k} \right] \exp^{-kx}$$ Which one is the right one? Thank you in advance",['ordinary-differential-equations']
3079744,Equality concerning the norm of rows of a resolvent matrix.,"This problem showed up on UCLA's basic exam for Fall 2018: Let $X$ be an $n \times n$ symmetric (real) matrix and $z \in \mathbb{C}$ with $\text{Im } z > 0$ .  Define $G = (X - zI)^{-1}.$ Show that $$\sum_{1 \leq j \leq n} |G_{ij}|^2 = \frac{\text{Im } G_{ii}}{\text{Im }z}.$$ I worked on this for a little bit where I applied the real spectral theorem to $X$ which in turn gives you that $G = Q^T D Q$ where $Q$ is real orthogonal ( $Q^T Q = Q Q^T = I$ ) and $D$ is diagonal satisfying $D_{ii} = (\lambda_i - z)^{-1}$ .  Where $\lambda_1, \ldots, \lambda_n$ are the eigenvalues for $X$ .  Couldn't really see any immediate way out from there.  Would be interested in seeing peoples' solutions to this problem and any connections to the study of matrix resolvents: https://en.wikipedia.org/wiki/Resolvent_formalism","['complex-analysis', 'linear-algebra']"
3079776,"For a general ring $R$, if $R$ has a unique right-unity, then it has a unity.","Problem: For a general ring $R$ I want to show that:
if $R$ has a unique right unity, then it has an overall unity. Attempt: Suppose $e$ is the unique right unity of $R$ . Then for any $r \in R$ , we have that $re=r$ and so $er=ere$ and $er-ere=0$ . From here I feel the answer should be obvious but I'm not seeing it right away. Help appreciated.","['ring-theory', 'abstract-algebra']"
3079815,Calculate $\int\limits_{-\infty}^{\infty}\frac{\sin^2(x)\cos(wx)}{x^2}dx$ using complex analysis technique,In a complex analysis test an exercise asks to calculate ( $w \in \Bbb{R}$ ): $$\displaystyle\int_{-\infty}^{\infty}\frac{\sin^2(x)\cos(wx)}{x^2}dx$$ Of course I need to solve it with complex analysis technique. I have used all the tricks I know such as integrate on a semi-circumference of radius $R$ in $\Bbb{C}$ and then let $R \to \infty$ but everything I have tried to do just seemed useless. Thank you for every hint or solution to this problem!,"['integration', 'complex-analysis', 'definite-integrals', 'improper-integrals']"
3079820,is function differentiable iff directional derivative is linear,"Original definition A function $f: A \to \mathbb{R}^n$ , $A \subseteq \mathbb{R}^m$ is differentiable at a point $\mathbf a \in \mathbb R^m,$ if there is a linear transformation $T$ such that $$
\lim_{\lVert \mathbf h\rVert \to 0}
\frac{f(\mathbf a+\mathbf h)-f(\mathbf a)-T_a(\mathbf h)}{\lVert \mathbf h\rVert} = \mathbf 0.
$$ My definition A function $f: A \to \mathbb{R}^n$ , $A \subseteq \mathbb{R}^m$ is differentiable at a point $\mathbf a \in \mathbb R^m,$ if there is a linear transformation $T$ such that for any unit vector $\hat u$ $$
\lim_{t \to 0}
\frac{f(\mathbf a+t \hat u)-f(\mathbf a)}{t} = T_a(\hat u).
$$ Question: is there any difference between original definition and my definition In the original definition, $\mathbf h$ can approach to $\mathbf 0$ by any trajectory; In my definition it can only be approached from certain direction, so my definition is weaker than the original definition. Substitute $\mathbf h = t \hat u$ to the original definition will get my definition. If my definition is not true, can somebody provide a counter example ? One may already noticed that $$
\partial_{\hat u} f (a) = T_a(\hat u)
$$ Since $T$ is linear, we can assume (here $\nabla f$ is just a function, it happens to be equal to the gradient if exist): $$
T_a(\hat u) = \hat u \cdot \nabla f(a)
$$ So my definition can be written as: $$
\partial_{\hat u} f (a) = \hat u \cdot \nabla f(a) \Leftrightarrow f\text{ is differentiable at }a
$$",['multivariable-calculus']
3079837,What is the minimum value of $f_\infty=\frac{x}{\sqrt{x-\sqrt[3]{x-\sqrt[4]{x-\cdots}}}}$?,"In a similar vein to What is the maximum value of this nested radical? , I'd like to share a similar nested radical, but this time with changing fractional powers. What is the minimum value of $$f_\infty=\frac{x}{\sqrt{x-\sqrt[3]{x-\sqrt[4]{x-\cdots}}}}$$ where the radicals go up by one each time? Here is a plot of $f_{19}$ . We can see that as $x\to 1^+$ , $\min f_{19}\to 1.7186$ which is strange as the denominator can only take the binary values $0$ or $1$ at $x=1$ . The curve is monotonically increasing from $1$ onwards, which is expected as the numerator dominates. Actually, a simulation in PARI/GP up to $f_{100}$ yields a minimum value of around $1.718565$ , which is somewhat close to $e-1$ , although I strongly doubt that it will ever reach that value. Note that $f_k$ is defined in $(1,\infty)$ for all positive integers $k$ , but the curve swings wildly for $(-\infty,1)$ . It is, of course, not a good idea to differentiate $f_\infty$ directly, but unfortunately we can't take $x$ and $\sqrt{x-\sqrt[3]{x-\sqrt[4]{x-\cdots}}}$ separately as both are increasing. Another interesting question: Why is the minimum value of $f_k$ for large $k$ not equal to the expected $0,1$ or $\pm\infty$ ? Is it possible to manipulate $f_\infty$ so that L'Hopital can be used to find the value of $1.718\cdots$ ? Related are Evaluating the limit of $\sqrt[2]{2+\sqrt[3]{2+\sqrt[4]{2+\cdots+\sqrt[n]{2}}}}$ when $n\to\infty$ Find $\sqrt{4+\sqrt[3]{4+\sqrt[4]{4+\sqrt[5]{4+\cdots}}}}$ but neither have been solved as of now.","['nested-radicals', 'recursion', 'maxima-minima', 'functions', 'limits']"
3079853,"If $E$ is Banach and $E^*$ is its dual, is every $T:E^*\rightarrow E^*$ an adjoint?","If $E$ is a (complex) Banach and $E^*$ is it's dual, is every bounded $T:E^*\rightarrow E^*$ an adjoint? I am mostly interested in when $T$ is an automorphism. If not, is $\{T: E^*\rightarrow E^* \ | \ \mbox{T is an adjoint}\}$ dense in $B(E^*)$ ? Thanks in advance!","['functional-analysis', 'real-analysis']"
3079995,How to define a function with summation?,"Suppose we have two sets: $A=\{a_1,a_2,a_3\}$ and $B=\{b_1,b_2,b_3\}$ . Is there a way to define a function that simply adds/subtracts the elements of these two sets? For example, $$\mu(\cdot)=\sum_{i\in\mathbb{N}:\;a_i\in A}a_i+\sum_{j\in\mathbb{N}:\;b_j\in B}b_j.$$ I am not sure if I am allowed to say that $\mu(\cdot)$ is a function with domain $A\times B$ . Basically, my question is about rigorously defining a function that simply adds elements from two different sets. Is that possible? If yes, then how?","['summation', 'functions']"
3079997,Does $f(n\theta) \to 0$ for all $\theta>0$ and $f$ Darboux imply $f(x) \to 0$ as $x \to \infty$?,"Recall that a Darboux function $f:\mathbb{R} \to \mathbb{R}$ is one which satisfies the conclusion of the intermediate value theorem (i.e., connected sets are mapped to connected sets). Being Darboux is a weaker condition than continuity. If a theorem about continuous functions only uses the intermediate value theorem, then chances are it also holds for the entire class of Darboux functions. I find it interesting to study which theorems about continuous functions also hold for Darboux functions. We have the following theorem, which is fairly well known and hinges on the Baire Categoery Theorem. If $f:\mathbb{R} \to \mathbb{R}$ is continuous and $f(n\theta) \xrightarrow[n \in \mathbb{N}, \ n\to\infty]{} 0$ for every $\theta \in (0, \infty)$ , then $f(x) \xrightarrow[x \in \mathbb{R}, \ \ x\to\infty]{} 0$ . A counterexample if we drop continuity is $f(x) = \mathbf{1}_{\{ \exp(n) : n \in \mathbb{N}\}}$ . However, this counterexample isn't Darboux, and I haven't been able to come up with any counterexample which is Darboux. Thus, this leads me to my question. Can the continuity condition in the theorem stated above be relaxed to Darboux? In searching for counterexamples of this sort, one approach is playing around with $\sin \frac{1}{x}$ . An alternative approach is considering highly pathological functions with the property that every nonempty open set is mapped to $\mathbb{R}$ (for instance, Conway Base-13 , or Brian's example here ) and modifying these in such a way that they satisfy the hypotheses of the problem.",['real-analysis']
