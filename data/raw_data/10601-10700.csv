question_id,title,body,tags
81099,"$F$ is a free abelian group on a set $X$ , $H \subseteq F$ is a free abelian group on $Y$, then $|Y| \leq |X|$","I am confused by the proof a proposition: $F$ is a free abelian group on a set $X$ and $H$ is a subgroup of $F$, then $H$ is free abelian on a set $Y$, where $|Y| \leq |X|.$ The proof is: Let $X$ be well-ordered in some fashion, say as $\{ x_{\alpha} | \alpha < \beta \}$ where $\beta$ is an ordinal number. Define $F_{\alpha} = \langle x_{\gamma} | \gamma < \alpha \rangle$: then $F_{\alpha+1} = F_{\alpha} \oplus \langle x_{\alpha} \rangle$ and $F_{\beta} = F$. Writing $H_{\alpha}$ for $H \cap F_{\alpha}$, we have from the second isomorphism theorem $$H_{\alpha+1}/H_{\alpha} \cong (H \cap F_{\alpha+1})F_{\alpha}/F_{\alpha} \leq F_{\alpha+1}/F_{\alpha} \cong \langle x_{\alpha} \rangle.$$ Thus, either $H_{\alpha} = H_{\alpha+1}$ or $H_{\alpha+1}/H_{\alpha}$ is infinite cyclic. We may therefore write $H_{\alpha+1} = H_{\alpha} \oplus \langle y_{\alpha} \rangle$ where $y_{\alpha}$ may be $0$. Clearly $H$ is the direct sum of the $\langle y_{\alpha} \rangle$'s and $H$ is free on the set $Y = \{ y_{\alpha} \neq 0| \alpha < \beta \}$. I don't know why can $X$ be well-ordered. Also, in the proof, the author defines $F_{\alpha+1}$. Does this mean considering $X$ as being countable? In fact, $X$ is just a set in the proposition, and we do not know whether or not $X$ is well-ordered/countable. Would you please give me some explanation or hint as to my confusion? Thanks very much. [On Page 100 and 101 of A Course in the Theory of Groups written by Derek J.S. Robinson , GTM80]","['abelian-groups', 'elementary-set-theory', 'axiom-of-choice', 'free-groups', 'group-theory']"
81101,What is the dimension of this algebraic variety?,"Let $\mathbb K$ be a number field of degree $n$ over $\mathbb Q$, and let
$\alpha_1,\alpha_2, \ldots ,\alpha_n$ be a $\mathbb Q$-basis of $\mathbb K$. Then there
are coefficients $(c^{ij}_k)$ (where $i,j,k$ are independent indices between $1$ and $n$)
such that $$
\alpha_i \times \alpha_j = \sum_{k=1}^{n} c^{ij}_k \alpha_k
$$ and we have for any indices $i,j,k,l$, $$
(1) c^{ij}_k=c^{ji}_k \ (\ {\rm commutativity})
$$ $$
(2) \sum_{y=1}^{n}c^{iy}_lc^{jk}_y=\sum_{y=1}^{n}c^{ij}_yc^{yk}_l \ (\ {\rm associativity})
$$ If we take $\alpha_n$ to be $1-\sum_{y=1}^{n-1} \alpha_y$, we also have $$
(3) \sum_{y=1}^{n}c^{yi}_j=\delta_{ij} 
$$ where $\delta_{ij}$ is the Kronecker symbol. Now, let $V$ be the algebraic variety in the variables $( c^{ij}_k)$ 
defined as the subset of ${\mathbb C}^{n^3}$ satisfying equations (1) to (3). Is the dimension of $V$ (in the sense of algebraic geometry) known ?","['algebraic-geometry', 'polynomials']"
81103,Definitions of weak (topological) mixing,"Let $X$ be a compact (metric) space and $T:X\rightarrow X$ be a continuous map.  Let $U_T:C(X)\rightarrow C(X)$ be the linear operator $U_T(f) = f\circ T$ . Then Wikipedia (see http://en.wikipedia.org/wiki/Weak_mixing#Topological_mixing ) (vaguely) says that $T$ is weak topological mixing if, whenever $U_t(f)=\lambda f$ for some $\lambda\in\mathbb C$ and $f\in C(X)$ , then $f$ is a constant function. But Terry Tao (see Definition 3 of http://terrytao.wordpress.com/2008/01/28/254a-lecture-7-structural-theory-of-topological-dynamical-systems/ ) says that $T$ is topologically weakly mixing if $T\times T$ is topologically transitive , that is, if $U,V\subseteq X\times X$ are open then there is $n\in\mathbb Z$ with $(T\times T)^n(U)\cap V\not=\emptyset$ .  I guess this is equivalent to saying that for $A,B,C,D\subseteq X$ open we can find one $n\in\mathbb Z$ with both $T^n(A)\cap B$ and $T^n(C)\cap D$ non-empty. Unfortunately, if I look in e.g. Brin and Stuck's book, then topologically transitive is defined to mean that for some $(x,y)\in X\times X$ , the forward orbit $\{ (T^n(x),T^n(y)) : n\geq 1 \}$ is dense in $X\times X$ . ( Edit: Thinking about this, B&S, Prop 2.2.1 shows that Tao's definition implies the B&S definition; and, at least if $T$ is a homeomorphism, the converse holds.  But it doesn't seem to if $T$ is not surjective). Is the definition of mixing involving $U_T$ equivalent to the usual one?  If so, can anyone supply a reference or a sketch proof?  I am beginning to think that Wikipedia has confused topological and measure-theoretic mixing. If they are equivalent, do I really need $T$ to be a homeomorphism?  (One could either replace $\mathbb Z$ by $\mathbb N$ in Tao's definition, or let $T^{-1}$ be the inverse image, and iterate).  Do I need $X$ to be metric? Edit: The reference Willie found gives the following: Suppose $T$ is a homeomorphism and $T\times T$ is minimal in the B&S sense.  Then if $f\in C(X)$ with $f\circ T = \lambda f$ , necessarily $\lambda\in\mathbb T$ (as $T$ is a homeomorphism).  Consider $g(s,t) = f(s)\overline{f(t)}$ , which defines a continuous function on $X\times X$ .  Then $g(T^ns,T^nt) = f(T^ns)\overline{f(T^nt)} = \lambda^n f(s) \overline{\lambda}^n \overline{f(t)} = f(s)\overline{f(t)} = g(s,t)$ .  There is $(x,y)$ such that $\{ (T^nx,T^ny):n\geq 1\}$ is dense in $X\times X$ , from which it follows that $g$ must be constant (as $g$ is continuous).  So in particular $f(x)\overline{f(y)} = |f(x)|^2$ for all $x,y$ , so $f$ is constant. So that's one implication...","['functional-analysis', 'dynamical-systems', 'reference-request']"
81113,Is $\sum\limits_{n=1}^{\infty}\frac{n!}{n^n}$ convergent?,"I can clearly see that $\dfrac{n!}{n^n}\to 0$ when $n\to\infty$. But how do I know if the sum $$\sum_{n=1}^{\infty}\frac{n!}{n^n}$$ is convergent or not? I know this might be basic, but thank you if anyone can help me.","['factorial', 'sequences-and-series', 'exponentiation', 'calculus']"
81120,A question regarding limits,"I have this limit: $$\lim_{x \to 1} \frac{2x^2-x-6}{x(x-1)^3}$$ This can be written as: $$\lim_{x \to 1^+} \approx \frac{-5}{1\times\mbox{tiny positive}} \to - \infty$$ Why is that? I mean, let's plug in some numbers. 
$-5/1.0000000001$ is almost $-5$ , the greater the denominator becomes the close the number to $-5$ Can anybody tell me why the book says it goes to -infinity? Thanks a lot","['calculus', 'limits']"
81122,inequality with roots of unity,"Do you know proofs or references for the following inequality: There exists a positive constant $C>0$ such that for any complex numbers $a_1,\ldots,a_n$ $$
|a_1|+\cdots+|a_n| \leq C\sup_{z_1^3=1,\ldots,z_n^3=1 } |a_1z_1+\cdots + a_n z_n|
$$
where the supremum is taken over the complex numbers $z_1,\ldots,z_n$ such that $z_1^3=1,\ldots,z_n^3=1$?","['fourier-analysis', 'inequality', 'reference-request', 'analysis', 'complex-numbers']"
81123,"Examples of categories where epimorphism does not have a right inverse, not surjective","An epimorphism is defined as follows: $f \in \operatorname{Hom}_C(A,B)$ is an epimorphism if $\forall Z, \forall h', h'' \in \operatorname{Hom}_C(B, Z)$ then $h' f = h'' f \; \Rightarrow \; h' = h''$. I can't think of examples where epimorphism would not have a right inverse. Also, if I understand correctly, epimorphism is not surjective in the categories where we can't talk about surjection (where objects does not have internal structure?). Thanks in advance.","['category-theory', 'abstract-algebra']"
81127,Reference for Martingale version of Riesz representation theorem / Riemann–Stieltjes integral,"(Please let me know if this is more appropriate as a MathOverflow question.) I can work out most of the following martingale generalization to the Riesz representation theorem and the Riemann–Stieltjes integral.  But I also imagine it is a standard result, and I am looking for a reference. The result: Let $(X,\mathcal{B},P)$ be a Borel probability measure on a compact space $X$.  Let $M_n$ be a (discrete time) $\mathcal{L}^1$-bounded martingale on a filtration $\mathcal{F_n}$ such that $\mathcal{F_n}\uparrow\mathcal{B}$ and $coarseness(\mathcal{F}_n)\rightarrow0$ where $coarseness(\mathcal{F}_n)\leq\delta$ iff there is a countable set $\{A_k\}\subseteq\mathcal{F}_n$ which covers $X$ such that $diameter(A_k)\leq \delta$ for all $k$.  (Update: I didn't originally have this courseness/diameter stuff, but I think I need it. So I am also now assuming there is a metric on $X$. Also, the $\mathcal{F_n}\uparrow\mathcal{B}$ condition is now redundant.) Then for continuous functions $g$ on $X$, define the integral $\int g\ dM = \lim_n \mathbb{E}[g M_n]$.  It is easy to check it is a bounded linear transformation on continuous functions, and hence an integral. (Update: The proof that it converges is at the end.) Let $\nu$ be the corresponding signed measure.  Then the limit of $M_n$ is the Radon–Nikodym derivative $d \nu /dP$.  Also, $\nu$ is absolutely continuous if $M_n$ is uniformly integrable,  $\nu$ is singular if $M_n$ converges to $0$ a.e., and $\nu$ is positive if $M_k$ is nonnegative.  (Update: I originally wrote these as ""if and only if""s but the situation is a bit more subtle, just like with bounded variation functions.) Where can I find a reference for this? I can see how this would not be a standard probability result since I am assuming something topological about the sample space. Update: Proof that $\lim_n \mathbb{E}[g M_n]$ converges. 
Since the space is compact, $g$ is uniformly continuous.  By the coarseness/diameter condition, there is some $n'$ such that $\Vert g - \mathbb{E}[g\mid \mathcal{F}_{n'}] \Vert_\infty \leq \epsilon$ for all $n\geq n'$. We show $\mathbb{E}[g M_n]$ is Cauchy. For $n\geq n'$, $\left| \mathbb{E}[g M_n] - \mathbb{E}[g M_{n'}] \right| \leq \left\Vert (g - \mathbb{E}[g\mid \mathcal{F}_{n'}])(M_n - M_{n'})\right\Vert_1 + \left\Vert \mathbb{E}[g\mid \mathcal{F}_{n'}](M_n - M_{n'})\right\Vert_1$ $\leq \epsilon (\Vert M_n \Vert_1 + \Vert M_{n'} \Vert_1) + \left\Vert \mathbb{E}[g\mid \mathcal{F}_{n'}] \mathbb{E}[M_n - M_{n'}\mid \mathcal{F}_{n'}]\right\Vert_1$ Since $M_n$ is a martingale, $\Vert M_{n} \Vert_1$ is bounded.  Also, $\mathbb{E}[M_n - M_{n'}\mid \mathcal{F}_{n'}]=0$.  Hence the righthand side of the inequality goes to $0$.","['measure-theory', 'probability-theory', 'riesz-representation-theorem', 'reference-request', 'functional-analysis']"
81134,When is the canonical model of a curve nonsingular,"Let $O$ be a Dedekind domain with fraction field $K$. Let $C$ be a smooth projective geometrically connected curve of genus $g>1$ over $K$. Let $p:X \to \mathrm{Spec} \ O $ be the canonical model of $X$. Assuming that $C$ has semi-stable reduction over $O$,  we have that $p$ is a stable curve. When is $X$ regular? One possible answer would be when the minimal regular model and the canonical model coincide . But when does this happen? When there aren't any curves to be contracted on the minimal regular model. But I have a feeling this actually never happens...Why?","['algebraic-geometry', 'algebraic-curves', 'surfaces']"
81158,Converse to the Koebe Distortion?,"Given a univalent function on the disk satisfying $f(0)=0$ and $f'(0)=1$, Koebe Distortion theorem says that \begin{equation}
\frac{1-|z|}{1+|z|}\le \left|z\frac{f'(z)}{f(z)}\right|\le \frac{1+|z|}{1-|z|}.
\end{equation} I'm wondering if there is some kind of a converse statement: Given a holomorphic function on the unit disk with $f(0) = 0$ and $f'(0)=1$ satisfying the inequality above, what are some minimal set of conditions that would make $f$ univalent? I will be very grateful if someone could point me in the right direction in terms of finding appropriate references. Thank you in advance.",['complex-analysis']
81163,Dirac delta function relation,"Is there a way of showing that for a monotonic (not necessarily strictly monotonic) function $f(x)$ defined on $[a,b]$ which has a simple zero at $c\in (a,b)$ that $\int\limits_a^b g(x)\delta(f(x))dx={g(c)\over |f'(c)|}$? I know that I could get there by using the property $\delta(f(x))={\delta(x-c)\over |f'(c)|}$, but how can I not quote this property but instead use the fact that $f$ is monotonic on $[a,b]$ to show the relation?","['special-functions', 'integration']"
81177,Solving $ \frac {27 ^ {(2x+1)} } { 3 ^ {(x+1){5}}} = \frac{1}{3} $,"I am trying to find the value of $x$ in the following problem, I have to solve it without logarithm. Problem : $$
\frac {27 ^ {(2x+1)} } { 3 ^ {(x+1){5}}} = \frac{1}{3}
$$ EDIT:
My work so far: $$
\dfrac {3^{3(2x+1)} } { 3 ^ {(x+1)5}} = 3^{-1}
$$ I know the formula $b^{u} = b^{v} \Longleftrightarrow u = v$ , but I am not able to use it with this problem. Thanks for help !","['exponentiation', 'algebra-precalculus', 'roots']"
81178,Help with Cramer's rule and barycentric coordinates,"I'm trying to learn about barycentric coordinates so after a Google search found this PDF file which didn't look too scary. I'm only on page 3 and getting confused so hope I can get help here... A triangle has vertices $p_1$, $p_2$, $p_3$ and a barycentric combination of the three points takes the form $$p = up_1 + vp_2 + wp_3$$ where $$u + v + w = 1$$ It says p can be rewritten $$p=up_1 + vp_2 + (1 - u - v)p_3$$ Then it asks ""How can we find the barycentric coordinates of a given point p?"" The claim is that there are 3 equations and the following linear system is setup: $$\begin{bmatrix}p_1&p_2&p_3\\1&1&1\end{bmatrix}\begin{bmatrix}u\\v\\w\end{bmatrix} = \begin{bmatrix}p\\1\end{bmatrix}$$ for the unknown $u,v,w$. The system is then solved using Cramer's rule: $$A = \begin{vmatrix}p_1&p_2&p_3\\1&1&1\end{vmatrix}$$
$$A_1 = \begin{vmatrix}p&p_2&p_3\\1&1&1\end{vmatrix}$$
$$A_2 = \begin{vmatrix}p_1&p&p_3\\1&1&1\end{vmatrix}$$
$$A_3 = \begin{vmatrix}p_1&p_2&p\\1&1&1\end{vmatrix}$$ My 2 points of confusion: 1) Is there 3 equations as claimed? I can see $p = \dots$ and $u + v + w = 1$ which is 2 equations. 2) Cramer's rule uses determinants, i.e. a value linked to a square matrix. The coefficient matrix here is 2-by-3, not square. Can someone help me see what the author is doing here please?","['geometry', 'linear-algebra']"
81181,Probability about three independent exponential random variables,"Suppose we have three independent exponential random variables $A$, $B$ and $C$  with respective parameters $1$, $2$ and $3$. Calculate $P(A<B<C)$. The hint says this problem could be solved with calculus and without calculus. I am really curious how to approach it with different methods.",['probability']
81184,Ways to calculate the derivative of the matrix exponential,"Could someone provide me with a rigorous proof as to why the derivative of the function $f:t \ni \mathbb{R} \mapsto e^{tA}\in \textrm{Mat}_n (\mathbb{R})$ is $t \mapsto A\cdot e^{tA}$ ?
I didn't understand the ""elementwise"" arguments, as to why the above should hold and when trying to evaluate $f'$ by hand I got stuck at evaluating
$$ \lim _{h\rightarrow 0} \frac{||e^{xA}\cdot e^{hA} - e^{xA} -A\cdot e^{xA} \cdot h||}{|h|},$$ where $||\cdot ||$ denotes any norm on $\textrm{Mat}_n (\mathbb{R}) $ that is multiplicative (so that $( \textrm{Mat}_n (\mathbb{R}) , || \cdot ||)$ becomes a Banach algebra) - which is what I have do to, I think (please correct me, if I'm wrong, or using an unnecessary abstract level of discourse), because in the setting of matrix-valued functions the derivative of a matrix becomes the derivative between the Banach spaces $\mathbb{R}$ and $\textrm{Mat}_n (\mathbb{R}) $ (using an isomorphism $\phi:\textrm{Mat}_n (\mathbb{R}) \rightarrow \mathbb{R}^{n^2} $ to do the derivative there and then transporting everything back to  $\textrm{Mat}_n (\mathbb{R}) $ seems rather ugly to me - although I tried to do it this way and failed). Could I replace $\mathbb{R}$ with $\mathbb{C}$ ?","['matrices', 'exponentiation']"
81203,Definitions of Hessian in Riemannian Geometry,"I am wondering if there is any quick way to see the following two definitions of Hessian coincide with each other without using local coordinates. $\operatorname{Hess}(f)(X,Y)= \langle \nabla_X \operatorname{grad}f,Y \ \rangle$ ; and $\operatorname{Hess}(f)(X,Y)=X (Yf) - (\nabla_XY) f$ .","['riemannian-geometry', 'differential-geometry']"
81216,Every open cover of the real numbers has a countable subcover (Lindelöf's lemma),"How to prove for every open cover of the real numbers $\mathbb{R}$ there is a countable subcover? Without using more sophisticated results from topology, assuming only a real analysis background. I've found a proof using second-countable space characterization, but since i never studied general topology before, it's hard to associate a countable base on the real line. My intuition says to transform the open cover into disjoint open subsets, but how to achieve that?","['general-topology', 'real-analysis']"
81220,How to show that $x=\ln 3$  solves $x=\ln(10/3 - e^{-x})$,"My homework has tasked me with finding $x$ when $\cosh x=5/3$. I know that the solution is $\ln (3)$, but I can't figure out how to solve it myself. The furthest I can simplify it is the following: $$\frac{e^x+e^{-x}}{2} = 5/3$$
$$ e^x+e^{-x} = 10/3$$
$$e^x = \frac{10}{3}-e^{-x}$$
$$x = \ln \left(\frac{10}{3}-e^{-x} \right)$$ Now, if I put this into Wolfram Alpha it tells me that the answer is $\ln(3)$, but it doesn't tell me how it solved that. Also, I'm guessing there may be another way to solve this by taking a different route than the above.",['algebra-precalculus']
81234,What does the graph of the height function on $\mathbf{Q}$ look like,"This question is a bit vague. I was just wondering what the graph of the height function on $\mathbf{Q}$ would look like. Define the height $h(q)$ of a rational number $q$ as follows. Write $q=a/b$, where $a$ and $b$ are coprime integers. Then $h(q) := \max(\vert a\vert,\vert b\vert)$. The function $h$ has the property that the set of rational numbers $q$ such that $h(q)$ is bounded by a real number $C$ is finite. So I was trying to imagine how this would look like on the interval $[0,1]$ but didn't get really far. It gets arbitrarily large around any number $x \in [0,1]$. Any thoughts? Of course, we could also consider a height function on $\overline{\mathbf{Q}}$ and its graph.","['graphing-functions', 'elementary-number-theory', 'functions']"
81254,number of zeros of a complex polynomial,"I would like to find how many zeros $z^4-5z+1$ have in the annulus $\{z | 1\lt |z| \lt 2\}$. I think I have to apply Rouche's theorem, but I don't know how. I would like some help. Edit: First, consider the circle $|z|=2.$ Let $f(z)=z^4$ and $g(z)=-5z+1$.  On the curve $|z|=2$, $|g(z)|=|-5z+1|\leq |-5z|+|3|\leq 13$, and $|f(z)|=2^4=16.$ Thus, the hypothesis of Rouche's Theorem are satisfied.
Now, since $f(z)=z^4$ has four zeros inside $|z|=2$, by Rouche's Theorem, $f(z)+g(z)= z^4 -5z +1$ also has four zeros inside $|z|=2.$ Now, consider the circle $|z|=1$. Let $f(z)=-5z+1~,g(z)=z^4$. Then on $|z|=1$, $|g(z)|=|z^4|=1.$  But $|f(z)|=|-5z+1|\lt |-5z| +|1|=4.$ So again, the hypothesis is satisfied. But $f(z)$ has only one zero inside $|z|=1$, so, $f(z)+g(z)=z^4-5z+1$ also has only one zero in $|z|=1$.. Hence $z^4-5z+1$ has $(4-1)=3$ zeros in the the annulus $\{z | 1\lt |z| \lt 2\}$. Please, is the above right? thanks.",['complex-analysis']
81264,"An exercise of the book ""Hamilton's Ricci Flow"" by Bennett Chow","This is  remark 1.24 on p. 13 of the book Hamilton's Ricci Flow by Bennett Chow, but how to prove this conclusion? If $\varphi (t): M^n \to M^n$ is the $1$-parameter family of diffeomorphism and $\alpha$ is a tensor, then 
$$ \frac{\partial}{\partial t} (\varphi(t)^\ast \alpha) = L_{X(t)} \varphi(t)^\ast \alpha  ,$$
where 
$$
X(t_0) = \left. \frac{\partial}{\partial t} \right|_{t = t_0} (\varphi (t_0)^{-1} \circ \varphi(t)) .  
$$",['differential-geometry']
81267,Surjective Function from a Cantor Set,"I recently solved an interesting problem on an midterm. Here is one piece of it: Let $K =\prod_{i=1}^\infty \{0,1\}$ in the product topology, and let $s_1,s_2,\ldots$ be a sequence of positive real numbers such that $\sum_{i=1}^\infty s_i = 1$. Define a function 
$f\colon K \to [0,1]$ by $(k_1,k_2,\ldots) \mapsto \sum_{i=1}^\infty k_is_i$. Show that $f$ is continuous. (This part I had no trouble with.) Show that if $s_k \leq \sum_{i=k+1}^\infty s_i$ for all $k$, then $f$ is surjective. I was able to prove this, but I'm not satisfied with my proof of the second part, because it seems like there should be a much easier way to show this. Does anyone see a simple/simpler approach to this problem than mine? Here's a very rough outline of my proof. I've left out a lot of details, so let me know if something really doesn't make sense. Suppose there is some $x \in [0,1] \setminus f(K)$.
Then there is a neighborhood $(x-\epsilon,x+\epsilon)$ which isn't hit by $f$.
Since $K$ is compact, $f(K) \cap [0,x]$ is compact, hence closed, and so it contains its supremum. 
This supremum is the image of an element of the form 
$(k_1,\ldots,k_n,0,1,1,\ldots)$.
By our hypotheses we get $f((k_1,\ldots,k_n,0,0,\ldots)) < x-\epsilon$ and $f((k_1,\ldots,k_n,0,1,1,\ldots)) > x+\epsilon$, so we take the supremum of the images of all elements that start with $(k_1,\ldots,k_n,0)$ and map into $[0,x]$. This element is again the image of an element whose entries are eventually equal to 1.  Repeating this gives a sequence of pairs of elements of $K$ with longer and longer initial parts. These must converge in $K$, but their images have to be at least $2\epsilon$ apart, so we reach a contradiction.",['general-topology']
81280,Arithmetic error in Feller's Introduction to Probability?,"In my copy of An Introduction to Probability by William Feller (3rd ed, v.1), section I.2(b) begins as follows: (b) Random placement of r balls in n cells. The more general case of [counting the number of ways to put] $r$ balls in $n$ cells can be studied in the same manner, except that the number of possible arrangements increases rapidly with $r$ and $n$.  For $r=4$ balls in $n=3$ cells, the sample space contains already 64 points ... This statement seems incorrect to me.  I think there are $3^4 = 81$ ways to put 4 balls in 3 cells; you have to choose one of the three cells for each of the four balls.  Feller's answer of 64 seems to come from $4^3$.  It's clear that one of us has made a very simple mistake. Who's right, me or Feller?  I find it hard to believe the third edition of a universally-respected textbook contains such a simple mistake, on page 10 no less.  Other possible explanations include: (1) My copy, a cheap-o international student edition, is prone to such errors and the domestic printings don't contain this mistake. (2) I'm misunderstanding the problem Feller was examining.","['probability', 'combinatorics']"
81286,why is this $\bar X$ a.s. irrational?,"Suppose that $X_1, X_2,\cdots, X_n$ are iid random variables from $N(\theta,1)$, $\theta$ is rational. Then we know that $\bar X \sim N(\theta,1/n)$. It is said that $\bar X$ is almost surely irrational. I am wondering why is it irrational a.s.? How can I interpret it?","['statistics', 'probability-distributions']"
81314,Number of permutations with no succession,The question is to calculate the number of permutations $\pi\in S_n$ such that $\pi(i+1)\neq\pi(i)+1$ for all $1\leq i\leq n-1$.,"['permutations', 'combinatorics']"
81324,A problem on $C^\ast$-algebras and $W^\ast$-algebras,"Let $I$ is a compact topological space, $m$ is a positive regular Borel measure. Then $L^\infty(m)$ is a standard example of commutative $W^\ast$-algebra (von Neumann algebra), but it is also a commutative $C^\ast$-algebra, so it should be isomorphism with $C(I)$. I can not believe that $L^\infty(m)$ is isomorphic to $C(I)$, who can tell me what happens?","['c-star-algebras', 'operator-algebras', 'von-neumann-algebras', 'functional-analysis']"
81325,Why is $(x+h)^n$ written like this?,"I encountered this in my calculus book: $$f\;'(x)= \lim_{h \to 0} \frac{f(x+h)-f(x)}{h}$$ $$f(x)=x^n$$ $$\begin{align*}
(x + h)^n &= (x + h)(x + h)...(x + h)\\
&=x^n + nhx^{n-1}+ \text{stuff  involving }h^2\text{ as factor}
\end{align*}$$ I don't get where that $nhx^{n-1}$ and stuff involving $h^2$ as factor come from. A little help please?",['calculus']
81343,Quotient of a variety and orbits,"Suppose a group G acts on a variety X and a quotient exists, that is, we have a variety Y and a regular map $\pi : X \rightarrow Y$ so that any regular map $\varphi :X \rightarrow Z$ to another variety Z factors through $\pi$ if and only if $\varphi (p) = \varphi (g(p)) \forall p \in X, g \in G$. I'm trying to prove that the points of Y correspond to orbits of G on X, i.e. $\pi (p) = \pi (q) \iff \exists g \in G: g(p) = g(q) $ However, I am stuck. The only triviality I was able to show is that, assuming $\pi (p) = \pi (q)$, we'd have $\pi (g_1(p)) = \pi (g_2(q)) \forall g_1, g_2 \in G$. I guess it boils down to choosing the right variety Z and then make use of the fact that Y is a quotient, but I don't know how. I'd be grateful for any hints. EDIT: I just realized I have a bad typo in this post. $g(p) = g(q)$ should be $g(p) = q$ , sorry!!",['algebraic-geometry']
81346,Why are Gram points for the Riemann zeta important?,"Given the Riemann-Siegel function, why are the Gram points important? I say if we have $S(T)$, the oscillating part of the zeros, then given a Gram point and the imaginary part of the zeros (under the Riemann Hypothesis), are the Gram points near the imaginary part of the Riemann zeros? I say that if the difference $ |\gamma _{n}- g_{n} | $ is regulated by the imaginary part of the Riemann zeros.","['analytic-number-theory', 'riemann-zeta', 'number-theory']"
81357,On the Lie derivatives along time-dependent vector fields,"I was stimulated by this question . On a smooth manifold $M$, an isotopy $\phi:(t,m)\in \mathbb{R}\times M\mapsto\phi_t(m)\in M$, generates the time dependent vector field $X:(t,m)\in\mathbb{R}\times M\mapsto X_t(M)=\left.\frac{d}{ds}\right|_{s=t}(\phi_s\circ\phi_t^{-1})(m)\in TM$. The flow of $X$ is the map $\psi_{s,t}=\phi_s\circ\phi_t^{-1}:m\in M\mapsto\phi_s(\phi_t^{-1}(m))\in M$. For a tensor field $T$ on $M$ its Lie derivative along the time dependent vector field $X_t$ is given by: $$\frac{d}{dt}(\psi_{t,s}^\ast T)=\psi_{s,t}^\ast(\mathcal{L}(X_t).T).$$ Concerning this expression I suppose that in general, in this context, $\mathcal{L}(X_t).(\psi_{s,t}^\ast T)\neq\psi_{s,t}^\ast(\mathcal{L}(X_t).T)$, but I don't know an example exhibiting such inequality. Probably it is silly but my question is: where I can look for such an example?",['differential-geometry']
81370,The extension of Manifold,"If $M \subset \mathbb R^n$ is a compact smooth manifold with boundary, and ${M_\varepsilon }$ is the closed $\varepsilon$-neighborhood of $M$ in $\mathbb R^n$, then whether for sufficiently small $\varepsilon$, ${M_\varepsilon }$ is a smooth manifold?",['differential-geometry']
81371,"Series around $s=1$ for $F(s)=\int_{1}^{\infty}\text{Li}(x)\,x^{-s-1}\,dx$","Consider the function $$F(s)=\int_{1}^{\infty}\frac{\text{Li}(x)}{x^{s+1}}dx$$ where $\text{Li}(x)=\int_2^x \frac{1}{\log t}dt$ is the logarithmic integral.  What is the series expansion around $s=1$? It has a logarithmic singularity at $s=1$, and I am fairly certain (although I cannot prove it) that it should expand as something of the form $$\log (1-s)+\sum_{n=0}^\infty a_n (s-1)^n.$$  (An expansion of the above form is what I am looking for)  I also have a guess that the constant term is $\pm \gamma$ where $\gamma$ is Euler's constant.  Does anyone know a concrete way to work out such an expansion? Thanks!","['sequences-and-series', 'integration', 'integral-transforms', 'analytic-number-theory', 'taylor-expansion']"
81372,Nonlinear differential equation type,"Which method should I use for solving equation
$\sqrt{1-x^2}dy + \sqrt{1-y^2}dx = 0$ ?",['ordinary-differential-equations']
81384,When is the composition of a function and a harmonic function harmonic?,"I was looking at a comprehensive exam, and I found the this question. Can anyone help me out? If $u$ is a harmonic function, which type of function $f$ is needed so that $f(u)$ is harmonic?",['complex-analysis']
81386,Does the exponential of a matrix commute with the matrix?,"Can someone give me an idea for the proof that for every $t\in \mathbb{C}$ we have $e^{tA}\cdot A = A \cdot e^{tA} =$ ?
I couldn't find a counterexample, so my gues is, that it would be true, but I'm not sure even how to begin the proof.","['matrices', 'matrix-calculus', 'matrix-analysis', 'matrix-exponential']"
81392,Does a dense $G_\delta$ subset of a complete metric space without isolated points contain a perfect set?,"Let $(X,d)$ be a complete metric space without isolated points. Is it true that each dense $G_\delta$ subset of $X$ contains a nonempty perfect set (i.e. closed without isolated points)? Thanks.","['general-topology', 'descriptive-set-theory', 'analysis']"
81394,Dividing colored balls between children,"The following was an exercise I solved: We have 8 numbered balls - two blue, two red, two green, and two yellow. When dividing them between 4 children, 2 balls each, what is the probability at least one child will get two balls of the same color? I solved it using the exclusion-inclusion principle, and got the end result $3/7$. My question is, since this is such a nice fraction, was there any way of solving the problem such that I could've arrived at the fraction directly? (This is the calculation I did: http://www.wolframalpha.com/input/?i=C(4%2c1 )*(4*C(6%2c2)*C(4%2c2) C(2%2c2))%2f2520-C(4%2c2) (4*3*C(4%2c2) C(2%2c2))%2f2520%2bC(4%2c3) (4*3*2*C(2%2c2))%2f2520-C(4%2c4)*(4*3*2*1)%2f2520&incParTime=true)",['probability']
81399,What is the integral of $x(1-x)^8$?,"I want to find the integral of $x (1-x)^8$. How do I go about this? For example, which rule do I use from http://integral-table.com ? Thanks!",['integration']
81405,Anti-curl operator,"It is known that if a vector field $\vec{B}$ is divergence-free, and defined on $\mathbb R^3$ then it can be shown as $\vec{B} = \nabla\times\vec{A}$ for some vector field $A$ . Is there a way to find $A$ that would satisfy this equation? (I know there are many possibilities for $A$ ) Note: I want to find it without using the explicit formula for $B_x(x,y,z), B_y(x,y,z), B_z(x,y,z)$ , but maybe with a formula involving surface/curve integrals. For example, I've found that in the 2D case (if $B_z=0$ and $\vec{B}=\vec{B}(x,y)$ ) then $A$ can be shown as: $$\vec{A}(x,y)=\hat{z}\int_{\vec{R_0}}^{\vec{r}} (\hat{z}\times\vec{B})\cdot\vec{dl}$$ I am looking for something similar in the general case.","['curl', 'multivariable-calculus', 'vector-analysis', 'vector-fields']"
81411,Are sin and cos the only continuous and infinitely differentiable periodic functions we have?,Sin and cos are everywhere continuous and infinitely differentiable.  Those are nice properties to have.  They come from the unit circle. It seems there's no other periodic function that is also smooth and continuous.  The only other even periodic functions (not smooth or continuous) I have seen are: Square wave Triangle wave Sawtooth wave Are there any other well-known periodic functions?,"['trigonometry', 'periodic-functions']"
81417,"Given $X$ is distributed normally, is $Y=aX$ normal? (for some constant a)","I assumed it was true, and then found $f_Y(y) = f_x(\frac{y}{a}).a^{-1} = a^{-1}\frac{1}{\sqrt{2\pi\sigma^2}}.\exp\{-\frac{(\frac{y}{a}-\mu)}{2\sigma^2}\} = \frac{1}{\sqrt{a^2.2\pi\sigma^2}}.\exp\{\frac{(y-\frac{\mu}{a})}{2a\sigma^2}\} $ which is almost of the form of a normal pdf, but there isn't a consistent value for $\sigma^2_Y$, unless $a=\pm1$","['statistics', 'normal-distribution']"
81432,An application of Jensen's Inequality,"Given that $\{\phi_n\}$ is a sequence of non-negative numbers whose sum is $1$ and $\{\psi_n\}$ is a sequence of positive numbers, how can I show that 
$$ \prod_{n=1}^{\infty}~\psi_n^{\phi_n}~\leq~\sum_{n=1}^{\infty}~\phi_n\psi_n~? $$ Thanks. PS: I'm not too sure about the title. Perhaps, someone could give it a better title?","['inequality', 'real-analysis']"
81447,Zero image of an element in the direct limit of modules,"Let $\left(M_i,f_j^i\right)_{i,j \in I, i \le j}$ be a directed family of modules over some ring. Assume there is an index $k \in I$ such that there exists $x_k \in M_k$ whose image is zero in $\varinjlim M_i$. Why there must exist $j \in I$ such that $j \ge k$ and $f_j^k(x_k)=0$? In particular, how do we see this from the interpretation of $\varinjlim M_i$ as $\left(\bigoplus M_i\right) / N$ where $N$ is the submodule of $\bigoplus M_i$ generated by elements of the form $x_{ij}$ with $i \le j$, whose $i^{th}$ component is $x \in M_i$, their $j^{th}$ component is $-f^i_j(x)$ and the rest components are zero? A hint would be appreciated :-)","['commutative-algebra', 'abstract-algebra']"
81458,Category of Field has no initial object,Why the category of Field has no initial object? (see page $47$ of Category Theory by Horst Herrlich and George E. Strecker ),"['category-theory', 'abstract-algebra', 'field-theory']"
81467,When are minimal and characteristic polynomials the same?,"Assume that we are working over a complex space $W$ of dimension $n$. When would an operator on this space have the same characteristic and minimal polynomial? I think the easy case is when the operator has $n$ distinct eigenvalues, but what about if it is diagonalizable? Is that sufficient, or can there be cases (with repeated eigvals) when char poly doesn't equal min poly? What are the general conditions when the equality holds? Is it possible to define them without use of determinant? (I am working by Axler and he doesn't like it.) Thanks.","['linear-algebra', 'characteristic-polynomial', 'minimal-polynomials']"
81479,Why not use the identity matrix instead of the Kronecker delta?,"The Kronecker delta is defined as : 
$$\delta_{mn} = \begin{cases}
1 & \text{if }m=n,\\
0 & \text{if }m\neq n.
\end{cases}$$ This is equal to the matrix $E_n$ which is a matrix with the diagonal filled with ones. Why not use $E_n$ instead of Kronecker delta? Does anybody see why? Please do tell me.",['linear-algebra']
81496,geometric meaning behind line integrals,"What are some geometric meanings behind line integrals? I know if you have a curve on the xy plane and you are given a function $f(x,y)$ then the geometric meaning is a ""curtain drawn"" from the function (surface) to the curve below.  This is a planer curve. However what about when we just have a helix? Similarly what the geometric meaning (or explanation) for the line integral involving a vector field $F$ and a curve. 
$$\int_c{F\cdot ds}$$ Here is an example: Let $c(t)= \sin{t}, \cos{t}, t$ from 0 to $2\pi$. let the vector field $F$ be defined by $$F(x,y,z)=x\hat{i} + y\hat{j} + z\hat{k}$$ 
  Compute $\int_c{F\cdot ds}$ Any links to pdfs and other resources helping me understanding would be very helpful! Thanks!","['multivariable-calculus', 'reference-request']"
81504,$\sigma$-algebra for Lebesgue-Stieltjes Measure,"If $f:\mathbb R \rightarrow \mathbb R$ is increasing and right continuous, one can define a measure $\mu_f$, the Lebesgue-Stieltjes measure induced by $f$, by setting $\mu_f(a,b] = f(b) - f(a)$ for half-open intervals $(a,b]$ then extending to a measure on the Borel $\sigma$-algebra by Caratheodory's theorem. In the special case where $f(x) = x$, one gets Lebesgue measure. In this case, the measure can be extended to the Lebesgue $\sigma$-algebra, which consists of unions of Borel sets and sets of Lebesgue measure zero. The same holds if $f$ is absolutely continuous. I am wondering whether the same holds for the Lebesgue-Stieltjes measure induced by functions $f$ which are not absolutely continuous. Can we always extend a Lebesgue-Stieltjes measure on $\mathbb R$ to the Lebesgue $\sigma$-algebra? To some $\sigma$-algebra which properly contains the Borel $\sigma$-algebra? I am particularly curious about singular continuous functions, like the Cantor-Lebesgue function.",['measure-theory']
81510,Simplifying function notation,"For example, in the process of proving that $$\left({\frac{f}{g}}\right)'\left({a}\right)=
\frac{f'\left({a}\right)g\left({a}\right)-f\left({a}\right)g'\left({a}\right)}{\left[{g\left({a}\right)}\right]^{2}}$$ I'd like to tidy things up a bit by writing $$\left({\frac{f}{g}}\right)'\left({a}\right)=
\left[\frac{f'\cdot g-f\cdot g'}{{g}^{2}}\right]\left({a}\right).$$
I believe that this is true, but I'm not confident why it is true: what assumptions am I making in rewriting this way, and is there a name for this change of notation?","['functions', 'calculus', 'real-analysis', 'notation']"
81516,Convexity and equality in Jensen's inequality,"The problem: Recall that we saw that when $\mu$ is a probability measure on $X$ and $f$ is integrable with respect to $\mu$, then
  $$ \exp\left(\int_X f(x)d\mu(x)\right) \leq \int_X e^{f(x)}d\mu(x).$$
  What can you conclude if we have equality? I know the solution is the functions that are constant on $X$ for all but a set of measure 0, but I'm not too sure how to prove this. So far what I've done is to show that a constant function on a set of measure 1 in $X$ gives equality, but I haven't been able to come up with a way to show a function with at least two distinct values on subsets of $X$ of positive measure cannot give equality. Namely: If we have some integrable function (with respect to $\mu$) that is constant on all but a set of measure 0, say $f(x) = c$ for all $x\in Y\subset X$, with $\mu(Y) = 1$, then the left hand side is
\begin{align*}
 \exp\left(\int_X f(x)d\mu(x)\right) &= \exp\left(c\int_X d\mu(x)\right)\newline
                          &= \exp\left(c\int_Y d\mu(x)\right)\newline
                          &= \exp(c\mu(Y))\newline
                          &= e^c.
\end{align*}
The right hand side is
\begin{align*}
 \int_X e^{f(x)}d\mu(x) &= \int_X e^c d\mu(x)\newline
                        &= e^c \int_X d\mu(x)\newline
                        &= e^c \int_Y d\mu(x)\newline
                        &= e^c \mu(Y)\newline
                        &= e^c,
\end{align*}
and so we have
$$ \exp\left(\int_X f(x)d\mu(x)\right) = \int_X e^{f(x)}d\mu(x).$$
These are the only possible $f$ for equality to occur. To see this, suppose $f$ were not constant (on all but a set of measure 0). Start with the simplest case, namely, suppose $X = N\cup Y\cup Z$ with $N,Y$ and $Z$ pairwise disjoint, $\mu(Y) > 0 < \mu(Z)$, and $\mu(N) = 0$ such that $f(y) = a$ for all $y\in Y$ and $f(z) = b$ for all $z\in Z$, with $a\neq b$. Then the left hand side is
\begin{align*}
 \exp\left(\int_X f(x)d\mu(x)\right) &= \exp\left(\int_Y a d\mu(x) + \int_Z b d\mu(x)\right)\newline
                          &= \exp\left(a\int_Y d\mu(x) + b\int_Z d\mu(x)\right)\newline
                          &= \exp(a\mu(Y) + b\mu(Z)).
\end{align*}
whereas the right hand side is
\begin{align*}
 \int_X e^{f(x)}d\mu(x) &= \int_Y e^a d\mu(x) + \int_Z e^b d\mu(x)\newline
                        &= e^a \int_Y d\mu(x) + e^b \int_Z d\mu(x)\newline
                        &= e^a \mu(Y) + e^b \mu(Z).
\end{align*} So...? I'm not sure how to show $a\neq b$ implies
$$ \exp(a\mu(Y) + b\mu(Z)) < e^a \mu(Y) + e^b \mu(Z).$$ My guess is it's something simple I'm missing, but I don't really see how to proceed. Edit: I suppose I can add some of the fiddling around I've done. We know
$$\mu(Z) = 1 - \mu(Y),$$
so the original equality can be written as
$$ \exp(a\mu(Y) + b(1-\mu(Y))) \leq e^a \mu(Y) + e^b (1-\mu(Y))$$
which means
$$ \exp((a-b)\mu(Y) + b) \leq (e^a - e^b)\mu(Y) + e^b.$$
Hence as
$$ \exp((a-b)\mu(Y) + b) = \exp((a-b)\mu(Y))e^b,$$
we have
$$ \exp((a-b)\mu(Y)) \leq (e^{a-b} - 1)\mu(Y) + 1.$$ Edit some more: I suppose one could look at this last inequality as a function of $a-b$. To make things neater, just a function of $\exp(a-b)$, so let $x = \exp(a-b)$. Then we have
$$ x^{\mu(Y)} \leq (x - 1)\mu(Y) + 1.$$
Now we know if $a = b$ (i.e., $x = 1$) we have equality, so we can compute the derivative of both sides. The derivative of the left hand side is
$$ \mu(Y)x^{\mu(Y) - 1},$$
whereas the derivative of the right hand side is simply $\mu(Y)$. Hence as $x$ increases the functions can never be equal again. I think this works, though I'll sit on it and think a little more about it (and it's generalization to all non-constant functions on $X$)","['convex-analysis', 'real-analysis']"
81525,Difficult integral: $\sin^3\theta / (\sin^3\theta - \cos^3\theta)$,"The question is, find the integral to the function: $\sin^3\theta / (\sin^3\theta - \cos^3\theta)$ The only thing I could think of was to factor the denominator. But then I couldn't make any further progress.","['trigonometry', 'integration']"
81529,Computational complexity of computing the determinant,"The formula for the determinant of an $n$ by $ n$ matrix given by expansion of minors involves $n!$ terms. As such, computing the determinant of a given matrix of with integer entries via expansion by minors takes a number of steps is bounded below by $n!$ . (In practice the number of steps required depends on the size  of the matrix entries). However, the determinant of such a matrix can also be computed by Gaussian Elimination; we know how each elementary row operation affects the determinant of a matrix and if we keep track of the row reduction steps which we perform in the process of performing Gaussian elimination we can almost immediately reconstruct the determinant of the original matrix from this data. The number of steps that it takes to row reduce a matrix with integer entries is $O(n^3)$ and so this method of computing the determinant of a matrix takes $O(n^3)$ steps. Juxtaposing the two methods above, one sees that the computational problem under discussion looks to be very time consuming from one perspective but is much faster from another perspective. In this respect the problem is analogous to that of computing a partial sum of a telescoping series. And yet it's not at all clear to me how see the ""implicit cancellation"" from the formula that comes from expansion by minors. Indeed, the formula bears a strong superficial similarity with that of the formula for the permanent of a matrix, the computation of which is #P-complete . The fact that half of the terms of the determinant have negative signs in front of them makes the formula for the determinant look more like a telescoping sum than the formula for the permanent, but not by very much. Is there a way to see the fact that the determinant of a matrix is
  bounded by a polynomial in the dimension of the matrix and size of the
  entries directly from the formula given by expansion by minors?","['linear-algebra', 'computer-science', 'soft-question']"
81531,Limits of integration for random variable,"Suppose you have two random variables $X$ and $Y$. If $X \sim N(0,1)$,  $Y \sim N(0,1)$ and you want to find k s.t. $\mathbb P(X+Y >k)=0.01$, how would you do this? I am having a hard time finding the limits of integration. How would you generalize $\mathbb P(X+Y+Z+\cdots > k) =0.01$? I always get confused when problems involve multiple integrals.",['statistics']
81536,I calculated the number of permutations with no 2-cycles in two ways but I got 2 different results,"I calculated the number of permutations in $S_n$ with no 2-cycles in two ways but I got 2 different results. The first time I used the principle of inclusion-exclusion and I got $\sum_{k=0}^n \frac{n!}{k!}\frac{1}{2^k}(-1)^k$ and I'm pretty sure that it's right. The second way is using generating functions. Using the exponential formula I calculated that the generating function of this type of permutations is $\frac{e^{-x^2/2}}{1-x}$. So it is $(\sum x^n)(\sum 1/n! (-1/2)^n x^{2n}$. If I make the product of these two series I got the series with coefficient $\sum_{k=0, k\;even}^n 1/(k/2)!(-1/2)^{k/2}$. Could you tell me where is the mistake? This is the computation of inclusion-exclusion: 
we count the permutations with at least one 2-cycle. The number of permutation with at least k 2-cycles is $c_k=(n-2k)!\frac{\binom{n}{2}\binom{n-2}{2}\cdots\binom{n-2k+2}{2}}{k!}$. So the permutations with at least one 2-cycle are $\sum_{k=1}^n(-1)^kc_k$. So what we want is $n!-\sum_{k=1}^n\frac{n!}{k!}\frac{1}{2^k}(-1)^k=\sum_{k=0}^n\frac{n!}{k!}(-1/2)^k$. So it's probable that the mistake is in the computation of $(-1)^kc_k$. Does anyone see an expression for this?","['permutations', 'generating-functions', 'combinatorics']"
81572,How do I find a splitting field $x^8-3$ over $\mathbb{Q}$?,"Here's the situation. I am in this algebra class, and so far we have defined splitting fields and proved their existence and uniqueness. We have not yet decided on any rigorous definition of complex numbers, by the way. For a homework question (and yes, we are allowed to use any internet resources we want), I have to find a splitting field for $x^8-3$ over $\mathbb{Q}$ and find its degree of extension. I don't really know how to go about it. If I can use that the complex numbers are algebraically closed, can't I just adjoin all of the roots, or is there something more explicit that I can do in order to find the degree of extension?","['galois-theory', 'abstract-algebra', 'field-theory']"
81583,How do I prove that $x^p-x+a$ is irreducible in a field with $p$ elements when $a\neq 0$?,"Let $p$ be a prime. How do I prove that $x^p-x+a$ is irreducible in a field with $p$ elements when $a\neq 0$? Right now I'm able to prove that it has no roots and that it is separable, but I have not a clue as to how to prove it is irreducible. Any ideas?","['irreducible-polynomials', 'abstract-algebra', 'positive-characteristic', 'polynomials', 'field-theory']"
81589,Algebra equations - how to solve?,"I have two equations that I want to solve but I can solve the first but not the second, here's an example:
$$\begin{align*}
    100 &= 120 \times x\\
    0.83 &= 123/ x
\end{align*}$$ The first one I know how to solve, basically I am doing on both sides of the equation with the same inverse operation of the 120 which is division, In order to separate the variable. But when I'am try to do the same method on the seconed equation (by multiply both sides of the equation with the same number 120 in this case, it doesn't work as I am expect). I can solve it by dividing the 120 by 0.83, but it isn't the same method as above. The main thing for me here is to acquire some kind of method on how to solve this kind of equation, and I have learned to separate the variable by doing the inverse operation on both sides, so if you can please point me what I am doing wrong here?
I am prefer to stay with the method above.
Thanks.",['algebra-precalculus']
81600,Order Statistic Expectation / Probability,"Let $Y_1<Y_2$ be order statistics from a random sample of size $2$ from a normal distribution, $\mathcal{N}(\mu,\sigma^2)$, where $\sigma^2$ is known. Show that $P(Y_1<\mu<Y_2)=\frac12$ and find $E(Y_1-Y_2)$. I am not exactly sure how to solve the question above. Any help would be appreciated. Thanks.","['statistics', 'probability']"
81607,Finite abelian $p$-group with only one subgroup size $p$ is cyclic,"My goal is to prove this: If $G$ is a finite abelian $p$-group with a unique subgroup of size $p$,
  then $G$ is cyclic. I tried to prove this by induction on $n$, where $|G| = p^n$ but was not able to get very far with it at all (look at the edit history of this post to see the dead ends). Does anyone have any ideas for a reasonably elementary proof of this theorem?","['finite-groups', 'group-theory', 'abelian-groups']"
81613,Convergent series $\sum\limits_{n=1}^{\infty}\ln\left(1+\frac{1}{n^k}\right)$ [duplicate],"This question already has answers here : Convergence of an infinite logarithmic series.$\sum\limits_{n=1}^\infty\ln\left(1+\frac{1}{n^a}\right)$ (3 answers) Closed 1 year ago . Find all possible values of the positive constant k such that the series $$\sum_{n=1}^{\infty}\ln\left(1+\frac{1}{n^k}\right)$$ is convergent. Definitely not root test. Tried ratio test, $L = 1$ which is not conclusive. Tried integral test but the integral looks too hideous to evaluate. Any other suggestions? How do I come up with the series to compare with? Keep practising? For this question, in my mind, I would compare it with another logarithm and not even think about Riemann series.","['convergence-divergence', 'sequences-and-series']"
81615,Lebesgue inner measure formula,"I cannot prove this formula:
$E$ is measurable and $A$ is any subset of $E$
show that $m(E)=m_*(A) +m^*(E-A)$. Define inner measure of $A$ by $m_∗(A)=\sup(m(F))$, where the supremum is taken over all closed subsets $F$ of $E$. $m(E)$ means $E$ is measurable and for outer measure of $E$, cover $E$ by countable collection $S$ of intervals $I_k$. i.e. $m^\ast(E)=\inf \sum \nu(I_k)$ Thanks and regards.","['measure-theory', 'real-analysis']"
81620,Higher Ext groups of skyscraper sheaf,"I would like to understand the calculation of higher Ext groups of a skyscraper sheaf $\mathcal{O}_p$ at $p$. The calculation I have seen does this using a Koszul resolution. It starts out like this ""Assuming $X$ is affine, local coordinates near $p$ define a
section $s$ of $\mathcal{O}^n$  ($n = \dim X$) vanishing transversely at $p$. "" I know that for such a section we get a koszul resolution of $\mathcal{O}_p$ that will lead to the Ext groups. However, I fail to understand the quotation. More specifically: how is this section obtained and why is $p$ the zero locus? Thanks in advance for your answers. Carsten ps: the calculation is from http://math.mit.edu/~auroux/18.969-S09/mirrorsymm-lect16.pdf","['algebraic-geometry', 'coherent-sheaves']"
81636,How to place objects equidistantly on an Archimedean spiral?,"To place objects equidistantly on an Archimedean (arithmetic) spiral, the arc length of the spiral has to increase linearly between the objects. This is what I have so far: The length of a spiral is determined by
$$
l = \frac{a}{2}\left[\varphi\cdot\sqrt{1+\varphi^2}+\ln \left(\varphi+\sqrt{1+\varphi^2} \right)\right]
$$
I presume that solving this equation for $\varphi$ will give me what I need. But trying that with WolframAlpha leads to a timeout. Is solving this equation for $\varphi$ really the right thing to do? If yes, how can I solve it?","['geometry', 'plane-curves']"
81649,First derivative bounded by supremum of difference of values in disc,"Need a little help in the following: Let $f(z)$ analytic function on $D = \{z\in\mathbb C: |z| < 1\}$. Define $\displaystyle d = \sup_{z,w \in D} |f(z) - f(w)|$. Prove that $|f'(0)| \leq \frac{d}{2}$.",['complex-analysis']
81658,"Prove that $Af(x) = \frac 1x \int\limits_0^x f(t) dt$ isn't compact in $L_2[0,1]$","I need to prove that operator $\displaystyle Af(x) = \frac 1x\int\limits_0^x\ f(t) dt$ isn't compact in $L_2[0,1]$. I have tried to calculate spectrum of $A$, but failed.",['functional-analysis']
81664,"$k$ balls into $n$ bins: how to formally account for ""time""","We throw balls into the bins until no bin is empty. What is the expected time until no bin is empty? The solution goes: 
Let $Y$ be the random variable that counts the time until no bin remains empty. We write $Y$ = Sum of $Y_i$. $Y_i$ is the time since we had $(i-1)$ nonempty bins, until we have $i$ nonempty bins. Usually I would think about this as $k$ independent balls into $n$ bins and the sample space is clear here. The $Y$ random variable is very intuitive, but how does one formalize it? What is the sample space? And how can we justify the passage from the $k$ balls into $n$ bins sample space into the one I'm asking about?","['probability-theory', 'problem-solving']"
81668,Killing vector field of the sphere,"Given a tangent vector field $X(x,y,z) = y\frac{\partial}{\partial x} -x\frac{\partial}{\partial y}$ of the sphere $S^2 \subset \mathbb{R}^3$. Compute the Levi-Civita covariant derivative $\nabla_{v_p}X$ of any tangent vector $v_p$. Secondly, show that this is a Killing vector field for the sphere. I am having trouble with the first part, computing the covariant derivative. Is the easiest way to compute it to use the ambient covariant derivative?",['differential-geometry']
81679,Ways to put numbered balls in boxes no box being empty,"I know the formula for putting $n$ identical balls in $r$ different boxes such that each box has at least 1 ball, but what is the formula for putting $n$ different balls in $r$ different boxes, no box being empty? Thanks!","['inclusion-exclusion', 'combinatorics']"
81683,How to convert $\sqrt{\frac{5}{3}}$ to $\frac{\sqrt{15}}{3}$?,"Disclosure : This is homework, but not part of the homework. This is just something that I do not understand. $$ x = \sqrt{\frac{5}{3}} $$ $$ x = \frac{\sqrt{15}}{3} $$ Could anyone please explain this to me? Thanks in advance.",['algebra-precalculus']
81702,Is there some consensus on the dimensions of a Jacobian matrix and of a gradient?,"According to Wikipedia, given a differentiable mapping $F: \mathbb{R}^n \to \mathbb{R}^m$, its Jacobian matrix is a $m \times n$ matrix defined as:
$$
J_F=\begin{bmatrix} \dfrac{\partial y_1}{\partial x_1} & \cdots & \dfrac{\partial y_1}{\partial x_n} \\ \vdots & \ddots & \vdots \\ \dfrac{\partial y_m}{\partial x_1} & \cdots & \dfrac{\partial y_m}{\partial x_n} \end{bmatrix}. 
$$
Specially when $m=1$, the Jacobian matrix is also called the gradient $\nabla F$.
So when trying to compute a differential, it is $J_F \Delta x$ or $\nabla F \Delta x$. In real analysis, optimization, ..., some texts agree with Wikipedia's definitions. However, in some others, a Jacobian matrix or a gradient of a differentiable mapping is defined to be  the transpose of the Wikipedia definitions. Moreover, in baby Rudin, $J_F$ is of $m \times n$ dimension, while when $m=1$, $\nabla F$ is of $n \times 1$ dimension. When it comes to writing my own formulas, I wonder which way is mostly adopted? Thanks and regards!",['real-analysis']
81706,The dual of $C_0^k(X)$,"Let $X$ be a compact ball in $\mathbb{R}^n$. Let $C_0^k(X)$ be the space of a $k$ times continuously differentiable complex, valued smooth functions, which vansih outside of $X$. The norm on $C_0^k(X)$ is given by
$$ ||f|| = \sum_{| \alpha | \leq k} || \partial^\alpha f ||_\infty $$ How does the Banach space dual space of $C_0^k(X)$ look?","['vector-spaces', 'functional-analysis']"
81707,Generated $\sigma$-algebra question,"Reading through my lecture notes, and I'm stuck a bit on this concept. Let $A$ be a set of subsets of $E$. Define $$ \sigma(A) = \{ A \subseteq E \ : \  A \in F \text{ for all } \sigma\text{-algebras } F \text{ containing }A \} .$$ Then $\sigma(A)$ is a $\sigma$-algebra, which is called the $\sigma$-algebra generated by $A$. It is the smallest $\sigma$-algebra containing $A$. So let's say: $E = \{1,2,3\}$. All the possible subsets of $E$ will be $ = \{ \{ \emptyset \}, \{1,2,3\}, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1,3\}, \{2,3\} \}$. So if we choose $A= \{1 \}$, then what would $\sigma(\{1\})$ equals to? $$ \sigma(\{1\}) = \{ \{1 \} \subseteq E \ \colon \ \{1 \} \in F \text{ for all } \sigma\text{-algebras } F \text{ containing } \{1\} \} .$$ How would I find all the $\sigma$-algebras $F$ containing $\{1\}$? Thanks.",['measure-theory']
81708,A local-global problem concerning roots of polynomials,"Let $f(x)$ be a polynomial with integer coefficients, irreducible over the integers. Suppose that for all primes $p$, $f$ has a zero in the field $\mathbb{Q}_p(\sqrt{2})$. Here $\mathbb{Q}_p$ denotes the field of $p$-adic numbers. Must $f$ have a zero in the field $\mathbb{Q}(\sqrt{2})$?",['number-theory']
81709,Confidence interval of a random variable for an ordinary linear regression,"I have a small problem. With my limited stats background I am not sure I am getting this one right.
After fitting an ordinary linear regression model I get
$$\hat{\underline{Y}}=X\hat{\underline{\beta}}$$
Now the problem is to calculate confidence interval of not observed $Y_{\alpha}$. Is this incredible stupid to just calculate confidence interval for each $\beta_j$, say $\hat{\beta_j}\pm\epsilon_j$ and then look at $a:=\sum{\epsilon_j} x_{ij}+\hat{\sigma} z$, (z=1.96 usually) where $\sigma^2$ is the variance of an error term of a model $$\underline{Y}=X\underline{\beta}+\underline{\epsilon}, \underline{\epsilon} \sim N_n(0,\sigma^2I_n)$$
Now It seems intuitive to claim that $(\sum{\hat{\beta_j} x_{ij}}\pm a)$ is the confidence interval for $Y_{\alpha}$.","['statistics', 'regression', 'probability-distributions']"
81715,Gradient in differential geometry,"I am a graduate student in physics trying to learn differential geometry on my own, out of a book written by Fecko. He defines the gradient of a function as: $
\nabla f = \sharp_g df = g^{-1}(df, \cdot )
$ This makes enough sense to me.  However, when I try to calculate the gradient of a function in spherical coordinates: $
g^{-1} (df, \cdot) = g^{ij} \partial_i(df) \otimes \partial_j = g^{ij} \partial_i f  \partial_j
$ So the $j^{th}$ component of the gradient of f is: $
g^{ij} \partial_if
$ The coefficients of the metric tensor are: $
g = 
\begin{pmatrix} 
1 & 0 & 0 \\ 
0 & r^2 & 0 \\ 
0 & 0 & r^2 \sin^2{\theta} 
\end{pmatrix} 
$ So the inverse of a diagonal matrix ($g^{-1}$) is just a diagonal matrix whose entries are the reciprocals of the original matrix: $
g^{-1} = 
\begin{pmatrix} 
1 & 0 & 0 \\
0 & r^{-2} & 0 \\ 
0 & 0 & r^{-2} \csc^2{\theta} 
\end{pmatrix} 
$ So it seems our expression doesn't match the vector calculus definition of the gradient in spherical coordinates.  For instance, differential geometry gives us a  $\hat{\theta}$ component of $ r^{-2} \partial_\theta f$ but vector calculus tells us this is $ r^{-1} \partial_\theta f$. Where is my mistake?",['differential-geometry']
81720,Weaker condition for law of large numbers,"$X_k$'s are i.i.d. Suppose $X_k$ is symmetric and $E[|X_k|^{3/4}]<\infty$. Do we have $S_n/n \rightarrow 0$ either in probability or almost surely, where $S_n$ is the partial sum.",['probability']
81721,Is the supremum of a function squared the square of its supremum,Let $f$  be a holomorphic function on the open unit disc. Is $(\sup \vert f \vert)^2 = \sup (\vert f\vert^2)$?,['analysis']
81738,How to find the limit $\lim \limits_{n\to\infty}\prod \limits_{j=1}^n \left( 1+\frac{1}{j} \left(\cos \left(\frac{tj}{n} \right)-1 \right) \right)$?,"$$ \lim \limits_{n\to\infty}\prod \limits_{j=1}^n \left( 1+\frac{1}{j} \left(\cos \left(\frac{tj}{n} \right)-1 \right) \right)$$ I am unsure how to find this limit. Are there some general techniques that I should be using when looking for the limit? I know that I should get : 
$$ \exp\left({\int_0^1 \frac{\cos(tx)-x}{x} \, dx}\right) .
$$","['sequences-and-series', 'limits']"
81742,"If $m^3 = n^2$ and $n$ is even, then n is divisible by $4$.","Conjecture: If $m^3 = n^2$ and $n$ is even, then n is divisible by $4$. The proof falls apart from the beginning. $n$ is even therefore there is a number $k$ such that $n=2k$ $m^3 = n^2$ $m^3 = (2k)^2$ $m^3 = 4k^2$ $4|4k^2$ therefore $4|n^2$ However, I can't think of an example where a cubic is equal to a square.  I also ask with hesitation because we have been studying prime numbers and the Euclidean Key theorem as well as other proofs using the Fundamental Theorem of Arithmetic.  So, this approach seems out of place for the section of homework that I'm doing.","['elementary-number-theory', 'discrete-mathematics']"
81755,"Calculating $\pi(x)$ , a new idea?","I am asking myself if instead of working with the primes in the calculation of $\pi(x)$ up to $x$, we instead work with the composite numbers and then using a simple subtraction to get $\pi(x)$. After all it must be much easier to deal with the composite numbers. We only need to look at $x/3$ to get $\pi(x)$ since $2/3$ of the numbers are multiples of $2$ and $3$. So we can write $c(x)+\pi(x) = x/3$ ( and add the $2$ coming from primes $2$ and $3$ ) to get the correct result ( $c(x)$ being of course the number of composite up to $x/3$ not included the multiples of $2$ and $3$ of course). We know how to produce the composite numbers, but we don't know if a given number is a prime without testing it. What would be wrong with that?","['prime-numbers', 'algorithms', 'number-theory']"
81759,Existence of irrationals in arbitrary intervals,"I was studying for my analysis mid-term paper and was going over the properties of real numbers. I was wondering how to prove the following statement: (Not a textbook problem, it just popped into my head.) Given rational numbers $p$ and $q$ such that $p < q$, show that there exists an irrational number $r$ such that $p < r < q$. I know some ways of proving it, like picking a known irrational and shifting it into the open interval $(p,q)$. I was wondering whether there is a way to prove it without referencing to any previously known irrationals. Specifically I am trying to construct a sequence of rational numbers which converges to a irrational in the interval $(p,q)$. Is there any way to do that?","['irrational-numbers', 'real-analysis']"
81760,Scheme of finite type over a field $K$ v.s. $K$-scheme,"I'm lost in some definitions about schemes. I have some trouble about two definitions of a scheme of finite type over $K$, for an alg.closed field $K$. Version 1 (Hartshorn) : a scheme of finite type over $K$ is a scheme $X$ together with a morphism $X \to K$, where $X$ is a scheme (a locally ringed space $(X, \mathcal{O})$ with a cover of spectra of rings) and for me $K$ is the (ridiculous ?) scheme $\text{Spec} K = \{ (0) \}$ with the sheaf sending $\{(0)\}$ to $K$. So the morphism is a continuous function $f \colon X \to \{\ast\}$ irrelevant since only one possible, and a finite morphism of sheaves, that is reduced to a single ring hm $f^{\sharp} \colon K \to \mathcal{O}_X(X)$. Version 2 : a scheme of finite type over $K$ is a scheme with a finite cover of spectra of finitely generated $K$-algebras. For example, let's assume $X$ is affine, so $X = \text{Spec} R$ for some ring $R$, so in the first version it is the data of $\text{Spec} R$ with its topology and the sheaf associated, and we add a finite morphism $K \to \mathcal{O}_X(X) = R$. In the second version, it is a scheme of the form $\text{Spec}(A)$ for some finitely generated $K$-algebra $A$. Oh, actually i think this makes the bridge between the two notions... Well... Sorry. I have however another question : 
While studying algebraic groups in the Borel, he considers $K$-schemes, which are almost schemes of finite type over $K$, in the sense that the topological space is not the whole spectrum $\text{Spec} A$ but only $\text{max} A = \text{Spec}_K A$ of maximal ideals of the finitely generated $K$-algebra $A$. So clearly the topological space contains ""less"" points, what does it change ? Why does he do that ? There is a bijection between $\text{max} A$ and $\text{Hom}_K (A,K)$, but what does it bring along ? Because we lose the functoriality (inverse image of maximal ideal is not maximal) and the result is not a scheme anymore... Sorry for this not linear question, I hope it's understandable, or I'll edit or delete..
Thanks for any hint or piece of information !!
Bogdan P.S. Actually,","['algebraic-geometry', 'schemes']"
81768,"Finding $\lim \limits_{x \to 0} \frac{1 - \cos x}{x}$, given $\lim \limits_{x \to 0} \frac{\sin x}{x} = 1$","I am working on a textbook problem. The first step is to prove that $$\lim \limits_{x \to 0} \frac{\sin x}{x} = 1$$ (which I did). The exercise goes on Use this limit [i.e. the one above] to find 
  $$\lim \limits_{x \to 0} \frac{1 - \cos x}{x}$$. How can this be done? I don't really see a connection between the two...","['calculus', 'limits']"
81769,Denjoy's probability argument for the Möbius function,"How or where could I find the proof of Denjoy's probability argument for the Mertens function $$ M(x) = \sum_{n=1}^x \mu(n) = O(x^{1/2}+e) $$ with  $e \to 0$ based on the fact that the Möbius function $ \mu(n)$ behaves as a random variable that takes the values $\{-1,1\}$ with same probability $\frac12$? Is there a similar probabilistic interpretation for problems inside number theory?","['probability-theory', 'number-theory']"
81800,Lebesgue integral question concerning orders of limit and integration,"I've got a hand-in question in a pure analysis course that I was hoping I might get a hint on - having difficulty coming up with a decent approach. The question: Let $(X,\Sigma,\mu)$ be a measure space and let $f:X\rightarrow [0,\infty]$ be a measurable function such that $$\int_X f(x)d\mu(x)=A,$$ for some $0<A<\infty$.
If $\alpha>0,$ show
$$\lim_{n\rightarrow\infty} \int_X n\log\left(1 + \left(\frac{f(x)}{n}\right)^{\alpha} \right)d\mu(x)=\begin{cases}
\infty&\mbox{if }0<\alpha<1\\\
A&\mbox{if } \alpha=1\\\
0&\mbox{if }\alpha>1.
\end{cases}$$ My attempt at a solution only comes as far as the first part: \begin{align*}
g(x,n)&=n\log(1 + [f(x)/n]^{\alpha})\\
&=n\cdot \sum_{m=1}^{\infty}(-1)^{m+1}[f(x)/n]^{\alpha m}/m\\
&=\sum_{m=1}^{\infty}(-1)^{m+1}\cdot \frac{f(x)^{\alpha m}}{m\cdot n^{\alpha*m-1}} \\
&= \frac{f(x)^\alpha}{n^{\alpha-1}}+\sum_{m=2}^{\infty}(-1)^{m+1}\frac{f(x)^{\alpha m}}{m\cdot n^{\alpha m-1}},
\end{align*}
 which is increasing  in $n$ for $\alpha<1$ (this is a bit handwavy, but I can't seem to figure out how to show it in a strict manner). Thus, we can apply the Monotone Convergence Theorem to move the limit inside the integrand, transform $n=1/t$, use a bit of L'hopitals rule, and get that this limit is diverging for any $f(x)$ and $\alpha<1$ (and $f(x)$ for $\alpha=1$, zero for $\alpha>1$). But how do I go about proving that I can switch limit and integrand in these other cases, or is there any other simple way to prove it? Any hints would be much appreciated! Many thanks in advance","['measure-theory', 'limits', 'analysis']"
81803,"Proof that for all distinct primes $p, q$, there exists $n$ so that $p+n$ is prime, but $q+n$ isn't","Imagine two distinct prime numbers $p$ and $q$. Intuitively, I'd say that there is always a natural number n so that $p+n$ is a prime number, but $q+n$ isn't . I was given two hints: for each natural number $n$ there is a prime $p$ so that $n < p \leq 2n$ consider the primorials But I still can't come up with a mathematical proof. My main problem is that I don't understand how I can show that the sum of a prime and another number is a prime. Any help?","['prime-numbers', 'number-theory']"
81805,How to show that this binomial sum satisfies the Fibonacci relation?,"The binomial sum
  $$s_n=\binom{n+1}{0}+\binom{n}{1}+\binom{n-1}{2}+\cdots$$
  satisfies the Fibonacci relation. I failed to prove that $\binom{n-k+1}{k}=\binom{n-k}{k}+\binom{n-k-1}{k}$... Any hints or suggestions?","['fibonacci-numbers', 'summation', 'binomial-coefficients', 'combinatorics']"
81807,Singular random variables,"I've been reading through Grimmett's and Stirzaker's Probability and Random Processes and on page 33 they state: For the moment we are concerned only with discrete variables and continuous variables. There is another sort of random variable, called 'singular', for a discussion of which the reader should look elsewhere. A common example of this phenomenon is based upon the Cantor ternary set (see Grimmett and Welsh 1986, or Billingsley 1995.) Other variables are 'mixtures' of discrete, continuous, and singular variables. I looked on Google Scholar for the two references mentioned in the excerpt, but haven't had any luck locating them. Can someone explain what a singular random variable is and how it differs from the continuous and discrete variants?",['probability-theory']
81821,Double exponential distribution is not an exponential family,"Define a one-parameter exponential family as a family of densities of the form
$$f_\theta(x)=\exp(\eta(\theta)T(x) + \xi(\theta))h(x)$$
where $T(x)$ and $h(x)$ are Borel functions, $\theta\in\Theta\subset\mathbb R$ and $\eta$ and $\xi$ are real-valued functions defined on $\Theta$. Double exponential distribution is a distribution having the density 
$$p_\theta(x)= \frac{1}{2}\exp(-|x - \theta|)$$
for $\theta\in\mathbb R$. I am looking for a simple proof of the theorem in the title. I found a proof in the book of Shao "" Mathematical Statistics. Exercises and Solutions. "" but it uses a more general definition of exponential families and doesn't show why the classes are not compatible. What is the special feature of $p_\theta(x)$ that makes the representation as exponential family impossible?","['probability-theory', 'probability-distributions']"
81836,What is the topological dual of $C_b(\mathbb{R})$,"Consider the Banach space $C_b(\mathbb{R})$ of continuous bounded functions on $\mathbb{R}$ equipped with the sup-norm. 1) Do we know a precise description of its topological dual $C_b(\mathbb{R})^*$ ? 2) I was wondering what kind of relation has $C_b(\mathbb{R})^*$ with $C_c(\mathbb{R})^*$, the topological dual of the space $C_c(\mathbb{R})$ of continuous functions having compact support. If $L\in C_b(\mathbb{R})^*$ then  there exists $C_L$ such that 
$|L(f)|\leq C_L\|f\|_\infty$ for any $f\in C_b(\mathbb{R})$, and thus for all $f\in C_c(\mathbb{R})$, so that $L\in C_c(\mathbb{R})^*$ and $ C_b(\mathbb{R})^*\subset C_c(\mathbb{R})^*$. Is that correct ? 
Then, can we find all the probability measures on $\mathbb{R}$ into $C_b(\mathbb{R})^*$ ? (In other worlds, is the ""weak"" topology for probability measures a weak* one ?)","['functional-analysis', 'duality-theorems', 'reference-request', 'probability-theory']"
81841,How to find the roots of $f(x)= \ln( \frac{x+1 }{x-2})$?,"I can't solve this equation:
$$\ln\left(\frac{x+1}{x-2}\right) = 0.$$ I do:
$$\begin{align*}
 \ln \left( \frac{x+1}{x-2} \right)&=0\\
 \frac{x+1}{x-2} &= 1 \\
x+1&=x-2 \\
 x+1-x+2&=0 \\
x-x+3&=0 \\
 3&=0 
\end{align*}$$ Then $x$ is?","['logarithms', 'algebra-precalculus', 'roots']"
81847,Pumping lemma usage,"I need to know if my solution for a problem related with regular languages and pumping lemma is correct. So, let $L = \{a^ib^jc^k \mid i, j,k \ge 0 \mbox{ and if } i = 1 \mbox{ then } j=k \}$ Now i need to use the pumping lemma to prove that this language is not regular. I wrote my proof like this: Let's assume that $L$ is regular. Let $|w|= p$ be the pumping length and $q = p -1$. Now if we consider $i = 1$ then $j=k$, so now i can pick a string from $L$ such as $w = ab^qc^q=xyz$. Since $q = p - 1$, it implies that $x = a$, $y=b^q$ and $z=c^q$. It satisfies the property $|xy| \le p$ and $|y| \gt 0$. Assuming that $L$ is regular, then $\forall_i\ge_0\ xy^iz \in L$, but if we choose $i=2$ we have $xy^2z$, which means that we have more $b's$ than $c's$, and we reached a contradiction, therefore $L$ is not regular, which completes the proof. Is my proof correct? i'm having some doubts related with my $q = p - 1$, but i think that it makes sense to choose a $q$ like that to ""isolate"" $y=b^q$, that will make the proof trivial after. Thanks in advance.","['computer-science', 'discrete-mathematics']"
81853,"Does Uniform Boundedness in the Sobolev Space $W^{1,2}$ and Convergence in $L^p$ $(1 \leq p < 6)$ Imply Convergence in $L^6$?","Let $B$ denote the open unit ball in $\mathbb{R}^3$.  I want to either prove or disprove that a sequence of functions $u_m$ in the Sobolev space $W^{1,2}(B)$ which is uniformly bounded in the $W^{1,2}(B)$ norm and which is convergent in $L^p(B)$ for all $1 \leq p < 6$ must be convergent in $L^6(B)$. Can someone please point me in the right direction? I know (cf. Chapter 5 of Evans PDE book) that the bound 
$$
\| u \|_{L^q(U)} \leq C(k,p,n,U) \| u \|_{W^{k,p}(U)}
$$
holds when $U$ is a subset of $\mathbb{R}^n$ having smooth boundary, $u \in W^{k,p}$, $k < \frac{n}{p}$, and $\frac{1}{q} = \frac{1}{p} - \frac{k}{n}$.  The constant $C = C(k,p,n,U)$ is independent of $u$. It follows from this bound that the $u_m$ are uniformly bounded in $L^6(B)$. Since $W^{1,2}(B)$ is a Hilbert Space, uniform boundedness of $u_m$ in $W^{1,2}(B)$ also implies existence of a subsequence $u_{m_j}$ that converges weakly in $W^{1,2}(B)$, hence weakly in $L^6(B)$. Thanks!","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations', 'analysis']"
81858,What is an example of $\mathscr O_{Spec R}(U)\neq S^{-1}R$ for some $S$ consisting of the elements of $R$ not vanishing on $U$?,"I've been meditating on the very basics of algebraic geometry, and in particular on how exactly $X=\operatorname{Spec} R$ relates to its structure sheaf $\mathscr O_X$. In these meditations, I've realized that the only $\mathscr O_X(U)$ for open subsets $X\setminus V(I)=U\subset X$ that I've come across have turned out to be $S^{-1}R$ where $S=\{f\in R \ \colon \ V(f)\subset V(I)\}$, i.e. they have always been the localization of $R$ at the set of elements of $R$ which do not vanish on $U$. It is easy to see that $S^{-1}R$ is the direct limit of $\mathscr O_X(X_s)=R_s$ (localizations of $R$ at ${1,s,s^2,\dots}$) for those $s$ that don't vanish on $U$. However, the actual definition of the sheaf requires that $\mathscr O_X(U)$ be the inverse limit of $\mathscr O_X(X_f)=R_f$ for those $f$ that vanish on the every point of the complement of $U$ (i.e. for $f$ such that $X_f\subset U$). Evidently, the former admits a unique morphism into the latter, as the former is an initial object and the latter a terminal object. I strongly suspect that the two constructions are different in general (otherwise why torture us beginners with the counter-intuitive inverse limit definition), but I have been unable to come up with an example where the two diverge.","['commutative-algebra', 'algebraic-geometry']"
81862,One question on 1st-order PDE,"Given a smooth vector field $\mathbf{b}$ on $\mathbb{R}^n$, let
  $\mathbf{x}(s)=\mathbf{x}(s,x,t)$ solve the ODE
  $$\dot{\mathbf{x}}=\mathbf{b}(\mathbf{x}) (s\in\mathbb{R}), x(t)=x.$$ (a) Define the Jacobian
  $$J(s,x,t):=\det D_x\mathbf{x}(s,x,t)$$
  and derive the Euler formula
  $$J_s=\operatorname{div} \mathbf{b}(\mathbf{x})J.$$ (b) Set $$u(x,t):=g(\mathbf{x}(0,x,t))J(0,x,t).$$ Show that $u(x,t)$
  solves the equation
  $$u_t+\operatorname{div}(u\mathbf{b}(x))=0, \mbox{ in } \mathbb{R}^n\times\mathbb{R}_+,$$
  with the initial value $u(x,0)=g(x)$. This is an exercise in L. Evans' classic textbook ""Partial
differential equations (2nd Edition)"", page 162-163. We have solved
(a). Now we are focusing on (b). Evans gave a hint on (b): one
should show $\frac{\partial}{\partial s}(u(\mathbf{x},s)J)=0$
firstly. We have tried the characteristic method and some other methods,
however, we are not able to work it out. Thanks for all of your
help!","['ordinary-differential-equations', 'partial-differential-equations']"
81863,uniform convergence of series of functions,"Prove that $f(x)=\displaystyle{\sum_{n=1}^{\infty}} \dfrac{e^x \sin (n^2x)}{n^2}$ is convergent for every $x \in \mathbb{R}$ and that its sum $f(x)$ is a continuous function on $\mathbb{R}$. This is my tentative to solve the problem:
$f(x)= e^x \sum {\frac{\sin (n^2x)}{n^2}}$. So, to prove that $f(x)$ is convergent, I only need to prove that $\sum {\frac{\sin(n^2x)}{n^2}}$ is convergent. 
since  absolute value of $\frac {\sin (n^2x)}{n^2} \le \frac{1}{n^2}$ because absolute value of $\sin (n^2x)$ is $\le 1$ and the series: $\sum {\frac{1}{n^2}}$ is convergent, then by the $M$-test the series $\sum {\frac{\sin (n^2x)}{n^2}}$ is uniformly convergent and thus $f(x)$ is continuous on $\mathbb{R}$. Please let me know whether my solution is true? Also, do I have to distinguish the two cases where $x=0$ and $x \ne 0$? Do I have to prove that $f$ is continuous at $x=0$ separately?","['calculus', 'real-analysis', 'analysis']"
81876,Question about Pick's Theorem,Is there a Pick's Theorem for a general lattice in $\mathbb{R}^{2}$?,"['geometry', 'integer-lattices']"
81884,"""measurable with respect to completion"" vs ""equals a measurable function almost everywhere""?","Let $X$ and $Y$ be sets and let $\mathscr{M}$ (resp. $\mathscr{N}$) be a $\sigma$-algebra of subsets of $X$ (resp. $Y$). Let $f:X \to Y$ be some function. Even without any measures lying around, we can still make sense of what it means for $f$ to be measurable (ie. elements of $\mathscr{N}$ pull back to elements of $\mathscr{M}$). Now let us specify some not necessarily complete (countably additive) measure $\mu:\mathscr{M} \to [0,\infty]$. I will call a set $N \subset X$ $\mu$-null if there exists $N' \in \mathscr{M}$ such that $N \subset N'$ and $\mu(N') = 0$. Suppose I tell you that $f$ is ""$\mu$-measurable"". It seems to me there are two sensible ways to interpret this. I take the completion of the measure space $(X,\mathscr{M},\mu)$ and require that $f$ be measurable after replacing $\mathscr{M}$ with the resulting, possibly larger, $\sigma$-algebra. This is equivalent to requiring that, for all $B \in \mathscr{N}$, $f^{-1}(B) = A \cup N$ where $A \in \mathscr{M}$ and $N$ is $\mu$-null. I require that there exist some measurable function $g:X \to Y$ such that $f=g$, $\mu$-almost-everywhere (ie $\{x \in X: f(x) \neq g(x)\}$ is $\mu$-null). It isn't too hard to see that 2 implies 1. I sort of suspect the converse fails, but I can't think of a counterexample. Thoughts?",['measure-theory']
81885,A real differentiable function is convex if and only if its derivative is monotonically increasing,"I'm working on a problem in baby Rudin, Chapter 5 Exercise 14 reads: Let $f$ be a differentiable real function defined in $(a,b)$. Prove that $f$ is convex if and only if $f'$ is monotonically increasing. I am trying to prove that $f'$ is monotonically increasing under that assumption that $f$ is convex. I have written a proof, but a friend and I do not agree on the validity of my argument. Here is my argument. First, assume that $f$ is convex. Since $f$ is differentiable and real on $(a,b)$, $f$ is continuous on $(a,b)$. So, for $a<s<u<v<t<b$, by the mean value theorem there exist points $y_1\in[s,u]$ and $y_2\in[v,t]$ such that 
  $$
f'(y_1)=\frac{f(u)-f(s)}{u-s}\quad\text{and}\quad f'(y_2)=\frac{f(t)-f(v)}{t-v}.
$$ Then, by exercise 23 of chapter 4 (proven previously): 
  $$
\frac{f(u)-f(s)}{u-s}\leq\frac{f(t)-f(v)}{t-v}
$$
  or,
  $$
f'(y_1)\leq f'(y_2).
$$
  Hence, $f'$ is monotonically increasing. $\hspace{3.5in}\square$ My friend claims that this merely proves that for any two arbitrary intervals $[s,u]$ and $[v,t]$ there are points that satisfy $f'(y_1) \leq f'(y_2)$. He says that what I need to prove is that for any two arbitrary points $y_1\leq y_2$ we have $f'(y_1)\leq f'(y_2)$. (I should mention that he doesn't know how one would do this.) Is he right? Is my proof insufficient? If so, how can I fix it?","['convex-analysis', 'real-analysis']"
81887,Proving sequence equality using the binomial theorem,"The problem: Prove that for $n \in \mathbb N$: $$ \left(1 + \frac{1}{n} \right)^n = 1 + \sum_{m=1}^{n} \frac{1}{m!} \left(1 - \frac{1}{n} \right) \left(1 - \frac{2}{n} \right) \cdots \left(1 - \frac{m-1}{n} \right). $$ The hint is to use the binomial theorem. So the left side can become: $$ \sum_{m=0}^{n} \frac{n!}{m!(n - m)!} \left(\frac{1}{n} \right)^m $$ I don't really know where to go from here, I've tried manipulating the expressions to make them look similar but I'm not really getting anywhere.",['sequences-and-series']
