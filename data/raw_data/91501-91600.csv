question_id,title,body,tags
1239393,Finding an ODE given some of its solutions,"Find $a, b, f(x)$ such that $$y''+ay'+by = f(x)$$
  Is satisfied by $g_{1}=\sin x + e^x$ and $g_{2}=\sin x - e^{-x}$ What I tried to do: First, I used the fact that if $g_{1}$ and $g_{2}$ are solutions for the nonhomogeneous ODE, than $g_{1}-g_{2}$ is a solution for the homogeneous correspondent ODE.
So, $g = e^x + e^{-x}$ is a solution of $ y''+ay'+b=0$. 
On the other hand, if I had $ y''+ay'+b=0$ and the discriminant $d = a^2-4b>0$, I would have solutions of the form: $$c_{1}e^{r_{1}x} + c_{1}e^{r_{2}x}$$, where $r_{1}$ and $r_{2}$ are solutions of $$r^2+ar+b=0$$
As in my case I have $r_{1} = 1$ and $r_{2} = -1$, the quadratic equation gives  $a=0$ and $b= -1$. I don't know how to find the function (or the functions) $f$ such that $$y''-y = f(x)$$
I was thinking about putting $y = \sin x$, as $\sin x$ appears in both the particular solutions $g_{1}$ and $g_{2}$ (that is, I expected that sine was a particular solution for the nonhomegeneous equation).
I'm I doing this right? Does someone has a suggestion on how I could improve it?","['calculus', 'ordinary-differential-equations']"
1239438,"4 cards are shuffled and placed face down. Hidden faces display 4 elements: earth, wind, fire, water. You turn over cards until win or lose.","Question: $4$ cards are shuffled and placed face down in front of you. Their hidden faces display 4 elements: water, earth, wind, fire. You turn over cards until win or lose. You win if you turn over water and earth. You lose if you turn over fire. What is the probability that you win? I understand that wind is effectively absent from the sample space. Does not affect your chances of winning or losing. I also know that $\frac13$ (because we removed wind), you can pick fire where you lose the game.","['probability-theory', 'probability', 'statistics', 'discrete-mathematics']"
1239485,Solve an initial value problem using the directional derivative,"In my notes there is the following example of solving an initial value problem using the directional derivative. The problem is the following: $$u_t(x,t)=u_x(x,t), x \in \mathbb{R}, t>0 \\ u(x,0)=f(x), x \in \mathbb{R}$$ We do the following: $$u_t(x,t)-u_x(x,t)=0 \\ \left (u_x(x,t), u_t(x, t)\right ) \cdot \frac{(-1,1)}{\sqrt{2}}=0$$ $\overrightarrow{v}=\left (-\frac{\sqrt{2}}{2}, \frac{\sqrt{2}}{2}\right )$ Reminder : Directional Derivative: 
       $v=(a,b)$, unit $|v|=\sqrt{a^2+b^2}=1$ 
       $$\frac{\partial{u}}{\partial{v}}(x_0)=\nabla u(x_0) \cdot   v=\frac{d}{dt}u(x_0+tv)|_{t=0}=(u_x(x_0), u_y(x_0)) \cdot  
 (a,b)=au_x+bu_y$$ $$\frac{\partial}{\partial{\overrightarrow{v}}}u(x,t)=0 \text{ When we are moving at the direction of } \overrightarrow{v}, u \text{ doesn't change. }$$ $$h(s)=u((x,t)+sv) \Rightarrow h'(s)=\nabla u((x,t)+sv) \cdot v \\ \text{ From the Mean Value Theorem we have that } \exists \xi \text{ in the intervall } 0,s : \\ h(s)=h(0)=(s-0)h'(\xi) \\ \text{ So, } u((x,t)+sv-u(x,t)=(s-0) \nabla u((x,t)+\xi v) \cdot v=0$$ So, $\exists \phi : \mathbb{R} \rightarrow \mathbb{R}$ differentiable $u(x,t)=\phi(x+t)$ For $t=0 \Rightarrow u(x,0)=\phi(x) \Rightarrow \phi(x)=f(x), \forall x \in \mathbb{R}$ $u(x,t)=f(x+t), x \in \mathbb{R}, t>0$ $$$$ Could you explain to me this method?? How did we get that $u(x,t)=\phi(x+t)$ ?? $$$$ EDIT: To solve an initial value problem as the above one, we do the following: We are looking for the unit $\overrightarrow{v}$ such that $\frac{\partial{u}}{\partial{v}} \cdot \overrightarrow{v}=0$. That means that $u$ is constant at the direction of $\overrightarrow{v}$. Is it correct so far?? I haven't understood what we do next do find the solution... Could you explain it to me??","['partial-differential-equations', 'ordinary-differential-equations', 'derivatives']"
1239524,Prove $\mathbb{P}(\sup_{t \geq 0} M_t > x \mid \mathcal{F}_0)= 1 \wedge \frac{M_0}{x}$ for a martingale $(M_t)_{t \geq 0}$,"Let $M$ be a positive, continuous martingale that converges a.s. to zero as $t$
tends to infinity. I now want to prove that for every $x>0$
$$ P\left( \sup_{t \geq 0 } M_t > x \mid \mathcal{F}_0 \right) = 1 \wedge \frac{M_0}{x}. $$
My approach:
I thought that rewriting the conditional probability to an expectation would help so we obtain that we must prove:
$$ \mathbb{E} \left[ 1_{\sup_{t \geq 0 } M_t > x}  \mid \mathcal{F}_0 \right] = 1 \wedge \frac{M_0}{x}.$$
A hint to me was given that I should consider stopping the process when it gets above $x$. Thus a stopping time that would do this is $\tau = \inf\{t\geq 0 : M_t>x\}$. But now I'm stuck as I want to apply optional sampling results but we have an indicator which complicates things. How could I proceed from this? Any help is appreciated!","['probability-theory', 'martingales', 'stochastic-processes']"
1239545,About the ramification locus of a morphism with zero dimensional fibers,"This question arises from my somewhat frustrating attempts to understand what etale means (in the world of algebraic varieties for now) and marry the more advanced algebraic geometry references and the ones from differential geometry. The particular example I am studying, is the Lyasko-Looijenga morphism. Say that $f:X\rightarrow Y$ is a finite map of affine varieties with zero-dimensional fibers. Finiteness of the map means that the coordinate ring $A(X)=S$ is a finitely generated $A(Y)=R$ module. Now say the point $y\in Y$ corresponds to the maximal ideal $P\subset R$. I understand how the ideal $PS$ in $S$ cuts the variety $f^{-1}(y)$ but might not be radical, so we define $S/PS$ to be the algebraic fiber but we know it is not exactly the coordinate ring of $f^{-1}(y)$. Evenmore, we know that $S/PS$ is an $R/P$-vector space of dimension $k$ at most as big as the rank of $S$ as an $R$-module (and equal if in particular $S$ is a free $R$-module). This in turn implies that the fiber $f^{-1}(y)$ will contain at most $k$-many points (the coordinate ring of a finite variety is a vector space of dimension as big as its cardinality). I am trying to understand when this number is achieved: The approach in Shafarevich is to consider the extension $f^{*}k(Y)\subset k(X)$ and define $\operatorname{deg}f$ to be its degree; when the cardinality of the fiber equals that degree: $$\#f^{-1}(y)=\operatorname{deg}f$$ we say that $f$ is unramified at $y$. The differential geometry approach is just to check the Jacobian at $y$; $f$ is unramified at $y$ precisely when $$J_f\ (y)\neq 0.$$ Question 1: I am asking for some help to understad the equivalence here. How does the Jacobian of $f$ affect the cardinality of $f^{-1}(y)$ in relation to the degre of the extension $f^{*}k(Y)\subset k(X)$? Question 2: What about the ring $S/PS$? It encodes all the information we need for $f^{-1}(y)$. How can we understand here which points are fatter than others? What is the situation for $\operatorname{Spec}S/PS$? Question 3: Is it apparent that the degree of the extension $f^{*}k(Y)\subset k(X)$ is equal to the rank of $S$ as an $R$-module, when $S$ is free over $R$? What happens when $S$ is not free? Remark: The reason that I am not just satisfied with the Jacobian definition (the fiber has full cardinality when $J_f\ (y)\neq 0$ ) is because it is easier to compute the generic size of the fiber via $S/PS$. In particular, when -as in my case- $S$ can be shown to be a free $R$-module, the rank can be calculated via the Hilbert series of the two rings. On the other hand, it is much easier to actually find the ramification locus using the Jacobian definition. Therein lies my current conundrum...","['affine-geometry', 'affine-schemes', 'commutative-algebra', 'algebraic-geometry', 'schemes']"
1239546,What's wrong in this equation? (Regarding Euler's eqn),"I got an idea, but that doesn't match with Euler's theory.. So What's wrong?! $$e^{jx} = (e^{j 2\pi})^{x/2\pi} = 1^{x/2\pi} = 1$$",['complex-analysis']
1239549,Dense basic open set contained in dense open subset,For an affine variety $X$ with coordinate ring $A$ it is not hard to see that for $g\in A$ the basic open set (or distinguished open set) $$D(g):=\{ P\in X | g(P)\neq 0\}$$ is dense in $X$ if and only if $g$ is not a zero divisor in $A$. Now let $U\subset X$ be a dense open subset. It should be true that $U$ contains one of the dense $D(g)$. Is this easy to see? Is it possible to prove this without using any scheme theory?,"['algebraic-geometry', 'geometry', 'affine-geometry']"
1239569,Is the ring of germs of $C^\infty$ functions at $0$ Noetherian?,"I'm considering the property of the ring $R:=C^\infty(\mathbb R)/I$, where $I$ is the ideal of all smooth functions that vanish at a neighborhood of $0$. I find that $R$ is a local ring of which the maximal ideal is exactly $(x)$. I also want to determine if $R$ is a Noetherian ring, but I have no idea about how to tackle with it. Can anyone help me? Thanks in advance.","['ring-theory', 'abstract-algebra', 'analysis', 'germs', 'noetherian']"
1239591,Extracting Bernoulli polynomials from their generating function,"The generating function for Bernoulli polynomials is $$ \frac{te^{tx}}{e^t-1} = \sum_{n=0}^\infty B_n(x) \frac{t^n}{n!}$$ The only way that I know of to get the coefficients out of this is to use Taylor's theorem. But to use Taylor's theorem, it needs to have derivatives at zero, and this doesn't, because there is always a $e^t-1$ in some denominator, which at zero is undefined. However, if instead of evaluating things at zero, I take the limit as $t \to 0$, then it looks like it works. As an example, for the second ""term"", $$ \lim_{t\to 0} \left(\frac{te^{tx}}{e^t-1} \right)^{(1)}\frac{t^0}{n!}  
= \frac{x-1/2}{n!}
$$ Which works, since $B_1(x) = x - 1/2$. My questions are, 1) Does this actually work, and if so, why? Are there other cases where we have formal power series which sum to something that doesn't have a Taylor series at zero? 2) Is there a better way to extract Bernoulli polynomials from that generating function (not using some other formula)?","['formal-power-series', 'analysis', 'bernoulli-numbers', 'generating-functions']"
1239621,An R-matrix in a quasitriangular Hopf algebra,"I am new to the theory of Hopf algebra. So I am sorry if the following question has really trivial answer. Suppose that we have a quasi triangular Hopf algebra with the universal R-matrix $R$. It satisfies the following equation by definition:
$$(\Delta \otimes \mathrm{id})(R)=R_{13}R_{23}$$
where
$\Delta$ is the comultiplication and $ R_{13}=\phi_{13}(R)$ with $\phi_{13}(a\otimes b)=a\otimes 1 \otimes b$ and $ R_{23}=\phi_{23}(R)$ with $\phi_{23}(a\otimes b)=1\otimes a \otimes b$. Let us write $R=\sum e_i\otimes f_i$. Let $R'=\sum f_i \otimes e_i$. My question is whether we can replace $R$ with $R'$ in the above equation. Namely:
Is
$$(\Delta \otimes \mathrm{id})(R')=R'_{13}R'_{23}$$
hold true?","['abstract-algebra', 'noncommutative-algebra', 'hopf-algebras']"
1239624,Ring Homomorphisms from $\mathbb Z_{20} \to \mathbb Z_{30}$,"We need to find all ring homomorphisms from $\mathbb Z_{20} \to \mathbb Z_{30} $ ;
I read its solution somewhere which states that : 
$R : \mathbb Z_{20} \to \mathbb Z_{30}$ defined by $R(x) = ax$ , $a$ belongs to $\mathbb Z_{30}$ is a ring homomorphism if : $1) \  a^2 = a$ and , $2) |a| \ \Big| \ 20 , \ \ \  |a| \ \Big| \ 30$ $1)$ is acceptable , but i couldn't understand $2)$.. why order of $a$ should divide both $20$ and $30$ ?",['abstract-algebra']
1239629,"$\forall x\in\mathbb{R},,$ if $x^{2}$ is rational, then $x$ is rational.","This is my attempt at this question. Is this correct? $\forall x\in\mathbb{R},,$ if $x^{2}$ is rational, then $x$ is rational. This statement is false.
Using counterexample, let $x=\sqrt{2}$. Since $x^2 = (\sqrt{2})^2 = 2$ is a rational number and $x = \sqrt{2}$ is an irrational number, this statement is false.","['number-theory', 'proof-verification']"
1239636,Difficult exercise on unicity of solutions for an IVP,"Suppose $f$ and $g$ are continuous and $g$ is odd and  strictly increasing function. I have to prove that the IVP $$y'=f(x)g(y)$$ $$y(0)=1$$ has a unique solution if and only if $$\lim \limits_{u \to 0} \left [ \int_{u}^{1} \frac {1}{g(y)} dy \right] = + \infty$$ Does someone have a hint on what I could use? I have absolutely no idea from where the result follows. As $g$ is odd (and so $g(0)=0$), I would expect the limit to be always infinite. I know that any solution of the ODE will satisfy $$\int \frac {1}{g(y)} dy = \int f(x) dx$$ but I don't know how I could use this result...","['calculus', 'real-analysis', 'ordinary-differential-equations']"
1239641,"Derivative of $\int_0^1 e^{\sqrt{x^2+t^2}}\,\mathrm{d}x$ at $t = 0$","Let the real-valued function $\phi:\mathbb{R}\to\mathbb{R}$ be defined by
$$\phi(t)=\int_0^1e^{\sqrt{x^2+t^2}}\,\mathrm{d}x,$$
it can then be shown that $\phi$ is continuous and differentiable. I wish to find its derivative, in particular at $\mathbf{t = 0}$ . I believe, since the integration is independent of $t$, that I can differentiate under the integration sign (correct me if I'm wrong) hence
$$\phi'(t)=\frac{\mathrm{d}}{\mathrm{d}t}\int_0^1e^{\sqrt{x^2+t^2}}\,\mathrm{d}x =  \int_0^1 \frac{\mathrm{d}}{\mathrm{d}t}e^{\sqrt{x^2+t^2}}\,\mathrm{d}x = \int_0^1 \frac{te^{\sqrt{x^2+t^2}}}{\sqrt{x^2+t^2}}\,\mathrm{d}x.$$
Naïvely, it then looks like $\phi'(0) = 0$, since it is $0$ times something. However, as $t\to0$ we actually get the indeterminate form $0\cdot \infty$ since the integrand becomes infinite, so we cannot say that $\phi'(0) = 0$. I tried various substitutions, but I'm not sure if this is the right approach. Perhaps, it is necessary to use dominated convergence theorem or something of that sort? Thanks for any help.","['derivatives', 'measure-theory', 'integration']"
1239645,Localization of a regular local ring is regular,"Quoting Hartshorne's Algebraic Geometry Definition. We say a scheme $X$ is regular in codimension one if every local ring $\mathcal{O}_x$ of $X$ of dimension one is regular. The most important examples of such schemes are nonsingular varieties
over a field (I, §5) and noetherian normal schemes. On a nonsingular variety the local ring of every closed point is regular (I, 5.1), hence all the
local rings are regular, since they are localizations of the local rings of
closed points. I know that there is a general result stating that localizations at prime ideals of regular local rings are regular (Cor. 2.13 here ). I was wondering if all this machinery is really needed to prove something that Hartshorne says so easily; is not there an easier proof for this case? My idea is that the following result would be enough Let $A$ be a (noetherian) regular local ring. If $\mathfrak{p} \subset A$ is a prime ideal such that $\dim(A_{\mathfrak{p}})=1$ then $A_{\mathfrak{p}}$ is regular. How to prove this last statement? What do you think Hartshorne was actually meaning in his assertion?","['algebraic-geometry', 'commutative-algebra']"
1239667,"How to obtain the line element in cylindrical coordinates, using definition of differential forms","In general, a volume element is a k-form on an K-dimensional manifold. a k-form w on $\mathbb{R}^{n}$ is defined as $w(x) = \sum_{i_{1}<i_{2}<...<i_{k}} w_{i_{1}i_{2}...i_{k}}(x) \cdot\mathrm{d} x_{i_{1}}\wedge \mathrm{d} x_{i_{2}}\wedge...\wedge \mathrm{d} x_{i_{k}}$ For cylindrical coordinates, the line element is a 1-form in $\mathbb{R}^{3}$, and $\mathrm{ds}= \mathrm{dr}\hat{\mathrm{r}} + \mathrm{dz}\hat{\mathrm{z}}+\mathrm{r}\mathrm{d}\phi \hat{\phi}$. I can understand how this follows from the definition given above, since the line element is a 1-form. But I don't understand where the factor r in front of the $\mathrm{d}\phi \hat{\phi}$ comes from, using the definition of the differential form?","['differential-forms', 'multivariable-calculus']"
1239669,High-School level probability and logic problem,"So the other day I took a math test, (not for class, its just an optional test, so this isn't and kind of cheating) which included all kinds of logical and problem solving exercises, among others this one: -""Given a deck of cards with N cards in it and each card is numbered (so the cards are 1, 2, 3, 4, ... nth card). Two cards are drawn one after each other. What is the probability that the when a third card is drawn, that this third cards number is in between the first card's and the second card's number."" I had done most of this test without problems but I just couldn't get around the fact that N (the number of cards) is unknown, so I'm not sure if the result should be a function of N or whether its an independent number. Any kind of help is greatly appreciated! 
I can post some more of the questions if anyone is willing to see, the exam is something a teacher does for those students who want to stay after school and test out their logical and problem solving skills","['probability', 'problem-solving']"
1239682,Subgroups of finite index have finitely many conjugates,"is it true the following statement: Let $G$ be a group and let $H$ be a subgroup of $G$. If the index $[G:H]$ of $H$ in $G$ is finite, then $H$ have finitely many conjugates. What I think, is that it's true. I proceed as follows: Suppose $[G:H]=n<\infty$ and let $\{g_{1}H,\dots,g_{n}H\}$ be its left cosets. For every $g\in G$ there exists a unique $1\leq i\leq n$ such that $g=g_{i}h$ for some $h\in H$. This implies that $gHg^{-1}=g_{i}Hg_{i}^{-1}$. So there can be at most $n$ conjugates of $H$. Is this correct? Thanks in advance.","['abstract-algebra', 'group-theory']"
1239687,Projected Area of Circle onto the Side of a Cylinder,"I have encountered a problem that requires me to find the projected area of a beam of light (circular cross-section, with radius $R_1$) vertically onto the side of a cylinder with $R_2$ as its cross-section. The setting is therefore similar to the problem of two-cylinder Steinmetz Solid. However, what if $R_1 \neq R_2$, especially $R_1 \gt R_2$?
Thanks.","['projective-geometry', 'geometry', 'differential-geometry']"
1239714,"Show that if $AA^t = A^tA$, then $A=A^t$","Suppose $A$ is a matrix with non-negative real entries. If $A^tA = AA^t$, show that $A=A^t$. My proof says: $AA^t = A^tA = (AA^t)^t$. I can't seem to get to the point of $A=A^t$ Edit: What if $A$ is a $2x2$ matrix?","['linear-algebra', 'matrices']"
1239735,computing an integration with a floor function,"I am trying to compute 
$$\int_0^1 \left(\frac{1}{x} -  \biggl\lfloor \frac{1}{x}\biggr\rfloor\right) dx$$ 
with no success.
Any hints?","['real-analysis', 'integration']"
1239812,parametric equation of level curve in three dimensional plane,"What is the parametric equation for the tangent plane to the level curve of the function $$w(x,y,z) = xy+yz+xz$$ at the point $(1,-1,2)$? My answer was: $$(x,y,z) = (1,-1,2)+r<1,0,δz/δx>+<0,1,δz/δy>$$ but since $δz/δx$ and $δz/δy$ are not defined at $(1,-1,2)$, is there another way to find the parametric equation to the tangent plane?",['multivariable-calculus']
1239816,Using exclusively the definition of limit proof that $\lim_{x \to 0} \frac{x^3-2x+x}{\sin(x)} = -1$,"Using exclusively the definition of limit proof that 
$$
\lim_{x \to 0} \frac{x^3-x}{\sin(x)} = -1
$$ I have to learn how to prove limits by the delta-epsilon definition, I know how to do basic ones (like linear functions) but not things like this. I'd like to thoroughly understand the process to get the proof working. For example: I've seen people choose an ""auxiliary $\delta_1=1$"" and then declare $\delta=\min(\delta_1,\text{some other thing})$. I have no idea why choosing a delta if allowed, or why we have to take the min when we are done. Every bit of insight is hugely appreciated.","['calculus', 'limits', 'epsilon-delta']"
1239846,Orthonormal frame on hyperbolic plane,"I'm having trouble comprehending a question from Do Carmo's Differential Forms and Applications. The question (in its entirety) is as follows: (Exercise 5-2 in Do Carmo) . Let $H^2$ be the upper half-plane, that is,
  $$
H^2=\{(x,y)\in\mathbb{R}^2;y>0\}.
$$
  Consider in $H^2$ the following inner product: If $(x,y)\in H^2$ and $u,v\in T_pH^2$, then
  \begin{equation}
\langle u,v \rangle_p=\frac{u\cdot v}{y^2}
\end{equation}
  where $u\cdot v$ is the canonical inner product of $\mathbb{R}^2$. Prove that this is a Riemannian metric in $H^2$ whose Gaussian curvature is $K\equiv -1$; with this Riemannian metric $H^2$ is called the hyperbolic plane. [ Hint: Choose the orthonormal frame $e_1=\frac{a_1}{y}$, $e_2=\frac{a_2}{y}$, where $\{a_1,a_2\}$ is the canonical frame of $\mathbb{R}^2$.] I'm not all that troubled with the question, except that I don't understand the hint to the point where I think there's a typo (though there probably isn't). I get how $e_1,e_2$ are orthogonal with respect to the inner product $\langle\cdot\,,\cdot\rangle$, but
$$
\langle e_1,e_1\rangle_p=\frac{e_1\cdot e_1}{y^2}=\frac{(a_1\cdot a_1)/y^2}{y^2}=\frac{1}{y^4}\neq 1.
$$
So $e_1,e_2$ can't be orthonormal with the inner product. It would work perfectly with $e_1=ya_1$ and $e_2=ya_2$, but then why does the hint say something different? Am I misunderstanding what he means by ""orthonormal?"" Any help is appreciated. Thank you in advance.",['differential-geometry']
1239872,Conditions for Deriving $R_0$ for SIR Model Using Survival Function Method,"I'm taking a look at the SIR model given by the system of differential equations \begin{align} \frac{dS}{dt} & = -  \beta S I \\ \frac{dI}{dt} & =  \beta S I - \gamma I \\ \frac{dR}{dt}& = \gamma I \end{align} where $S$, $I$, and $R$ represent the number of susceptible, infectious, and removed individuals in a population, and we have that $S + I + R = 1$. I am trying to justify the derivation of $R_0$, the basic reproductive number, as being equal to $\frac{\beta}{\gamma}$, using its definition as the expected number of secondary infections caused by a single index case in a population where all other individuals are susceptible. To do this, I am trying to apply the survival function method outlined on page two of this article http://mysite.science.uottawa.ca/rsmith43/R0Review.pdf . This method, as far as I understand it, computes the value of $R_0$ as $$R_0 = \displaystyle\int_0^{\infty} F(\tau) b(\tau) d\tau$$ where $F(\tau)$ is the probability that the initially infectious individual is still infectious at time $\tau$, and $b(\tau)$ is the rate at which this infectious individual infects susceptibles at time $\tau$. My first guess for an approach is based on the fact that the initially infectious individual will deterministically remain infectious for $\frac{1}{\gamma}$ time in the SIR model. I would take $$F(\tau)\ = \left\{
     \begin{array}{ll}
       1 & : \tau <= \frac{1}{\gamma}\\
       0 & : \tau > \frac{1}{\gamma}
     \end{array}
   \right.
$$ And then to interpret $b(\tau) = \beta$ for all values of $\tau$, which will give us $$R_0 = \displaystyle\int_0^{\infty} \beta F(\tau) d\tau = \displaystyle\int_0^{\frac{1}{\gamma}} \beta d\tau = \frac{\beta}{\gamma}$$ This produces the desired result, but I feel that one step might be unjustified. When I assume that $b(\tau) = \beta$, I feel like I am implicitly assuming that, for the entire infectious period of the index case, the proportion of individuals infected by that index case have almost no impact on the availability of susceptibles to be infected. I guess I feel that I would like conditions on $\beta$, $\gamma$, and the population size such that the primary index case does not infect a substantial enough fraction of the population to slow down its own infection rate. For example, if $\beta$ was very large, it could be possible for the index case to have already depleted a large portion of the susceptibles before exiting its own infectious period. Do you guys know of any such conditions? Additionally, is it overkill to assume that such an issue could be possible in a somewhat realistic epidemic process on a large population?","['dynamical-systems', 'biology', 'ordinary-differential-equations']"
1239885,Proving $\int_{0}^{1}\sqrt{\frac{1-x}{1+x}}dx=\frac{π}{2}-1$,"Proving $$\int_0^1 \sqrt{\frac{1-x}{1+x}} \, dx= \frac{π}{2}-1$$
My attempt is: I assumed the $1-x=u$
$du =-dx$
$$\int_0^1 \sqrt{\frac{u}{2+u}}\,(-du)$$",['integration']
1239945,Riemann Integral on $\mathbb{R}^2$,"I have the following question. Find a function $f(x,y)$ that is integrable on rectangle $[0,1] \times [0,1]$, such that $g(y) = f(\frac{1}{2}, y)$ is not integrable for $y \in [0,1]$, or prove that it is impossible. I think it is not possible. The reason is that if $f$ is integrable on $[0,1] \times [0,1]$, then $g$ will be a function over the set $\{(\frac{1}{2}, y) : y \in [0,1]\}$. What I have tried is following. Let $R = [0,1] \times [0,1]$. Since $f$ is integrable on $R$, there is a partition $P = \{ 0 = x_0, \ldots , x_n = 1 ; 0 = y_0 , \ldots , y_m = 1 \}$ such that the lower Riemann sum $s_Pf$ and the upper Riemann sum $S_Pf$ so that the lower and upper integrals are equal. I am stuck here and I am not even sure if I am on the right track. I am was thinking that I could prove it if I fix the partition $P$ such that $P = \{ \frac{1}{2} ; 0 = y_0 , \ldots , y_m = 1 \}$ and show that $g$ is integrable using the Cauchy Criterion for integrability. Can anyone help me with this?","['multivariable-calculus', 'integration']"
1239968,Let $1 \leq p <\infty$ and $f \in L^p(\mathbb{R})$. Prove $\lim_{x \to \infty} \int_x^{x+1} f(t) dt = 0$.,"(Jones, p. 246) Let $1 \leq p <\infty$ and $f \in L^p(\mathbb{R})$. Prove $\lim_{x \to \infty} \int_x^{x+1} f(t) dt = 0$. This seems pretty easy to prove in the following way: Let $g_j$ be a continuous function of compact support that approximates so that $\| g_j - f \|_{L^1} < 1/2^j$. Then, since the supp(g) is finite, for all $\epsilon$, there exists an $x$ large enough that $\int_x^{x+1} g(t) dt < \epsilon$. Since $g$ approximates $f$ in the L1-norm, we have that $\int_x^{x+1} f(t) dt < 1/2^j + \epsilon \to 0$ as $r,j \to \infty$. Is this a good approach?","['proof-verification', 'lebesgue-integral', 'integration']"
1240041,"If $|G|=p^n$, then $p^2 \le |G : G^\prime|$. [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Prove that, if $G$ be a p-group of order $p^n$, then $p^2 \le |G : G^\prime|$, where $G^\prime$ is the  commutator subgroup of $G$ and $n \ge 2$.","['abstract-algebra', 'group-theory', 'finite-groups']"
1240047,Borel Sigma Algebra generated by Open Intervals,"So I know that the Borel $\sigma$-algebra of $\mathbb{R}$ is the $\sigma$-algebra generated by open sets. I have been able to prove that this Borel $\sigma$-algebra is also generated by the family of open intervals of the form $(a,b),  a,b \in \mathbb{R}$ Now I want to show that the family of open intervals $(a,\infty)$ also generate the Borel $\sigma$-algebra. So what I have done is first show that $(a,b) = \bigcup_{q \in \mathbb{Q}, q<b}  ((a, \infty)-(q,\infty))$. This shows  that every open interval is a countable union of intervals of the form $(a,\infty)$ and thus $\sigma$-algebra generated by $(a,b)$ is contained in the $\sigma$-algebra generated by $(a, \infty)$ But how would I show the other way around, i.e. that every interval $(a, \infty)$ is in the Borel $\sigma$- algebra? (Can we just say that every interval $(a, \infty)$ is infact an open interval in itself and thus belongs to  the $\sigma$-algebra generated by $(a,b)$?)",['measure-theory']
1240055,Why does the Gaussian-Jordan elimination work when finding the inverse matrix?,"In order to find the inverse matrix $A^{-1}$, one can apply Gaussian-Jordan elimination to the augmented matrix
$$(A \mid I)$$
to obtain
$$(I \mid C),$$
where $C$ is indeed $A^{-1}$. However, I fail to see why this actually works, and reading this answer didn't really clear things up for me.","['inverse', 'gaussian-elimination', 'linear-algebra', 'matrices']"
1240119,"If $A \cap B \cap C = \varnothing$, is one $A \cap B$, $B \cap C$ or $C \cap A$ empty too? [duplicate]","This question already has answers here : Show that $A∩B∩C= ∅$ is only true when $A∩B = ∅, A∩C = ∅$ or $B∩C = ∅$ or show a counterexample. (3 answers) Closed 9 years ago . How do I give counter example to this? Prove or find a counter example to the following claim: For all sets $A$, $B$, $C$ if $A\cap B\cap C=\varnothing$, then either $A\cap B=\varnothing$ or $A\cap C=\varnothing$ or $B\cap C=\varnothing$.",['elementary-set-theory']
1240145,Simple equation re-arrangement,"I have a simple re-arrangement of an equation which I can't seem to solve, help would be much appreciated. I'm trying to re-arrange the equation: $e^{-3t}\frac{dy}{dt} - 3e^{-3t}y = C$ where $C$ represents a constant. Into: $\frac{d}{dt}(e^{-3t}y) = C$ I have already tried multiple ways of doing this with no success, as I'm not too sure of what operations I can perform on C for it still to be classed as a constant (such as differentiating it).","['linear-algebra', 'ordinary-differential-equations']"
1240161,Borel $\sigma$-algebra,"Since the Borel $\sigma$-algebra is generated by the family of open sets, does that mean that every Borel set is essentially some countable union/intersection of open sets or a complement of open sets? The idea is quite similar to the concept of generated field extensions in field theory, where the field $K(\alpha)$ is a field extension  generated by $\alpha$ over $K$. and we see that every element is essentially a quotient of linear combinations of powers of $\alpha$.",['measure-theory']
1240192,How do people find the number of ways you can put together a rubiks cube?,Just curious. How do people actually find the number of ways you can put together a rubiks cube? How do you find the number of choices? Do you use the same permutation formula? Insight would be appreciated. Thank you :),['combinatorics']
1240201,maximum area of semi-circle in square,"I'm struggling the with the following question: Given is a square with length $a$. Now I want to find a semi-circle with the max. area. Looks like this: http://tube.geogebra.org/material/show/id/222093 Now I want to prove, that the semi-circle is the best one (max. area) but have no idea, how to start.","['geometry', 'real-analysis']"
1240242,"What does it mean to write $(y,z)=G(x)$","I understand this is a map from $\mathbb{R} \mapsto \mathbb{R^2}$. Is it the case that $y=y(x)$ and $z=z(x)$? i.e Are $y$ and $z$ individually functions of $x$ as well as being so jointly ($(y,z)=G(x)$)",['functions']
1240264,How many rectangles or triangles.,"I have come across numerous questions where I am given the picture such as the above one been asked ""how many rectangles are there?"". I have even come across some slightly different images that instead of rectangles you are supposed to find the number of triangles. Well, I was thinking whether there is any formula or strategy that is used to solve these problems without having to manually count every shape. Help would be appreciated. Thank you :)","['discrete-mathematics', 'recreational-mathematics', 'combinatorics']"
1240289,"$X_1, \dots, X_n$ are independent random variables. Suppose $M = \min(X_1, X_2, \dots, X_n)$","Given that $X_1,\dots, X_n$ are independent random variables. Suppose $M = \min(X_1, X_2,\dots, X_n)$ and $X_i$ are exponential random variables with parameter $λ_i$, compute $E[M  X_j | M = X_i]$ where $i \ne j$. I have got the pdf and pmf of $M$. But I still don't know how to solve. Anyone can help?",['probability']
1240310,Show the equivalence of two infinite series over Bessel functions,"The following sums pop up in diffraction theory and are related to Lommel's function of two variables. Let $u,v\in\mathbb{R}$. I claim that
$$\sum_{n=0}^\infty i^n \left ( \frac{u}{v} \right )^n J_{n+1}(v)=\text{sign}(u)e^{iu/4}\sqrt{\frac{2\pi}{u}}\sum_{n=0}^\infty i^n (2n+1)J_{n+1/2}\left ( \frac{u}{4} \right )J_{2n+1}(v),$$
where $J_a(b)$ is the Bessel J. Can anyone show this? The left hand side is related to Lommel's original definition and the right hand side was derived by Zernike and Nijboer in 1947 (published 1949). However, Zernike and Nijboer are light on detail. The expansion on the RHS may somehow be related to the Bauer/Rayleigh expansion: $$e^{ikr\cos\theta}=\sum_{n=0}^\infty i^n(2n+1)j_n(kr)P_n(\cos\theta),$$ where $j_n$ is the spherical Bessel j and $P_n$ is the $n$th Legendre polynomial. Also, I added the $\text{sign}(u)$ myself in order to make things fit numerically. The expression published by Boersma (where I got the expressions) is missing the signum and doesn't seem to work out for negative u.","['bessel-functions', 'sequences-and-series', 'special-functions']"
1240353,Cyclic group Zp [duplicate],"This question already has answers here : Is $\mathbb Z _p^*=\{ 1, 2, 3, ... , p-1 \}$ a cyclic group? (6 answers) Closed 9 years ago . How to show if $p$ is prime, then group $Z_{p}^{*}$ is cyclic. Tip Let $g$ and $h$ of a commutative group $G$ have orders $n$ and $m$ respectively. There exists and element $x \in G$ of order $LCM (n,m)$ In any field $\mathbb{K}$ a polynomial $f \in \mathbb{K} [x]$ of degree $n$ has at most $n$ different roots. I have no idea.",['abstract-algebra']
1240382,Any hint about solving this monster determinant?,"I'm asked to solve the following determinant:
$$|A|=
\begin{vmatrix}
1 &2 &3 &\cdots &{n-1} &n\\
2 &3 &4 &\cdots &n &1\\
\vdots &\vdots &\vdots & &\vdots &\vdots\\
{n-1} &n &1 &\cdots &{n-3} &{n-2}\\
n &1 &2 &\cdots &{n-2} &{n-1}
\end{vmatrix}
$$
My attempt is to add all the other columns onto the first one, which gives
$$|A|=\frac{n(n+1)}{2}|B|$$
where $|B|$ is, however, none the easier than $|A|$. I think the result should be very special, since $A$ is a very special symmetric matrix itself. But I simply get stuck. Can you help me? thanks in advance. EDIT It just occurred to me that definition might work out well here. Am I on the right track? I'm now into another question. If $(j_1,j_2,\cdots,j_n)$ is an $n-th$ permutation of ${1,2,\cdots,n}$ and the number of inversion pairs in there is $\tau$, then what's the number of inversion pairs in its inverse permutation $(j_n,j_{n-1},\cdots,j_2,j_1)$ ? This may shed a light on the problem. Some friend of mine has given me a relatively simple solution, which I will add subsequently  as an answer.","['determinant', 'linear-algebra', 'matrices']"
1240388,A torsion-free sheaf of rank 1 on a surface,"Let $X$ be a surface and $E$ be coherent sheaf on $X$. Now there is always a natural map $\mu:E\longrightarrow E^{\vee\vee}$. The kernel of this map is precisely the torsion subsheaf of $E$. Now if $E$ is torsion-free, this map $\mu$ is injective. Let us call $E^{\vee\vee}=F$. Now on a surface, if $E$ is a torsion-free sheaf of rank 1, then we have an injective map $E\longrightarrow E^{\vee\vee}=F$. Now $F$ is a line bundle, therefore, tensoring by $F^{\vee}$, we get an injective map $E\otimes F^{\vee}\longrightarrow F\otimes F^{\vee}=\mathcal{O}_X$. Therefore, $E\otimes F^{\vee}$ is an ideal sheaf of a closed subscheme say $Z$. That is $E$ of the form $I_Z\otimes F$. The claim is that $Z$ is a codimension two subscheme. How do we see this? Any help will be appreciated!","['algebraic-geometry', 'surfaces', 'sheaf-theory']"
1240391,$a$ and $1+a^{-1}$ have same degree over $F$ if $a$ is algebraic over $F$,"Suppose that $a$ is algebraic over a field $F$. Show that $a$ and $1+a^{-1}$ have the same degree over $F$. Not really sure where to start for this one. I know that I have to show that $[F(a):F]=[F(1+a^{-1}):F]$, and I assume that being told that $a$ is algebraic over $F$ gives me some info, but I'm not sure how to use this info. $a$ algebraic over $F$ means that $a$ is a zero of some non-zero polynomial with coefficients in $F$. So there exists some minimal polynomial of the form $p(x)=c_0+c_1 x+\ldots+ c_{n-1} x^{n-1}$ for $c_i\in F$ such that $p(a)=0$. We also know that $F(a)$ is isomorphic to $F[x]/\langle p(x)\rangle$. Guidance how to approach this problem would be appreciated. Thank you.","['extension-field', 'abstract-algebra', 'field-theory']"
1240416,"Why the radius of convergence and not ""areas of convergence"" for power series?","My calculus is quite rusty and I'm trying to rebuild it on an intuitive basis. Currently, I am looking at power series and have trouble understanding the radius of convergence. I am comfortable with the fact that if the limit of the function at a certain point $a$ doesn't exist, the power series won't converge for this value of $x$. But why can't the series converge for $x$ whose absolute value is greater than this point? Why aren't there ""areas of convergence"" instead of a single radius of convergence?","['power-series', 'calculus', 'real-analysis']"
1240426,Why would one care about Fibre Bundles,"As a physics student I can easily understand the motivation for studying manifolds and why the definition looks the way it does, I only have to think of Minkowski space in GR. But for the life of me the notion of a fibre bundle seems highly unmotivated. Why would we want to talk about manifolds in this strange way? Why are we jumping through hoops and ladders to talk about a manifold locally as a product space of two things?","['differential-topology', 'differential-geometry']"
1240438,Terminology for functions such that $f(x)\ge x$ for all $x$,"Is there a common terminology for a real function $f$ such that $$f(x)\ge x$$ for all $x$ ? same question for the conditions $\forall x,f(x)>x$ ; $\forall x,f(x)\le x$ ; $\forall x,f(x)<x$ . (I'm not specific about the domain of definition, I have in mind functions from $\mathbf{R}_+$ to itself but I don't expect this to be important, it could be from any interval to any other, or even from any totally ordered set to itself.) If I had to coin a terminology I would say something like ""dynamically non-decreasing"" but it's a bit ugly.","['order-theory', 'terminology', 'real-analysis', 'dynamical-systems', 'functions']"
1240439,Totally disconnected space that is not $T_2$,The Wikipedia article on totally disconnected spaces seems to imply they are not necessarily Hausdorff (they are all $T_1$ though). What's an example of a totally disconnected non $T_2$ space? (A space is totally disconnected if all connected components are singletons.),"['separation-axioms', 'examples-counterexamples', 'connectedness', 'general-topology']"
1240507,no. of disordered pairs of disjoint subsets,"I found this question in a book. The same question has been asked before, but I want a more generalised and rigorous, so to speak, answer. The question reads- "" Consider the set $S= \{1,2,3,4\}.$ Calculate the no. of unordered pairs of disjoint subsets."" To start with, I have no idea as to what is meant by ""unordered pair of disjoint subsets"". Can someone explain that please?(of course, I do know what disjoint sets are) Secondly (probably the more important one), the book gives the answer as $41,$ with the solution reading- "" no. of unordered pairs of disjoint subsets is $\frac{3^{n} + 1}{2}$. Using $n=4,$ we get $41"".$ Now, I don't know how do they derive the term $\frac{3^{n} + 1}{2}$. Can someone please give a rigorous derivation for it? I want to know how does it give the no. of disordered pairs of disjoint subsets( I don't know what that means).
Also, if the total no. of subsets is $2^m = 16$, how do I get $41(>16)$ sets as the answer? I am in a fix. So, in short, can someone- (1) Explain the meaning of unordered pair of disjoint subsets (2) Explain the DERIVATION of the formula- no. of unordered pairs of disjoint subsets = $\frac{3^n +1}{2}$ Thanks in advance!","['elementary-set-theory', 'combinatorics']"
1240512,Limit of the projection of a matrix when the projection is not continuous,"Consider two real matrices: the $n\times n$ matrix $A$ the $n\times m$ matrix $B$ of rank $m$, with $m<n$. Let, for $a\in\mathbb{R}$, 
$$S_a=A-aI_n,$$ and denote by $P_a$ the orthogonal projection onto the orthogonal complement of $\operatorname{col}(S_a B)$, that is, $P_a=I_n-S_aB(S_aB)^\dagger$, where $(\cdot)^\dagger$ denotes the Moore-Penrose pseudoinverse. I'm interested in whether the following is correct. Conjecture : For an arbitrary real eigenvalue $\lambda$ of $A$, 
$$P_\lambda S_\lambda =0$$ implies $$\lim_{a\to \lambda}P_a S_a =0.$$ My attempts : Note that $\operatorname{rank}(S_a B)=k$ for any $a$ different from an eigenvalue of $A$. The conjecture is correct when $\operatorname{rank}(S_\lambda B)=k$, because in that case $$\lim_{a\to \lambda}P_a=P_\lambda.$$ (since the Moore-Penrose pseudoinverse of a matrix is continuous at some point if the rank of the matrix does not change at that point). From my numerical examples so far it seems to me that the conjecture may be correct even when $\operatorname{rank}(S_\lambda B)=k$, but I cannot see why. I'll also state some facts that might be relevant, or at least might help to clarify my question. I can see that $\operatorname{rank}(S_\lambda B)=k$ iff $\operatorname{null}(S_\lambda)\cap \operatorname{col}(B)=\{0\}$, that is, iff $\operatorname{col}(B)$ does not contain any eigenvectors of $A$ associated to $\lambda$; $P_\lambda S_\lambda =0 \text{ iff }\operatorname{col}(S_\lambda)=\operatorname{col}(S_\lambda B),$ because $\operatorname{col}(S_\lambda B)$ is trivially a subset of $\operatorname{col}(S_\lambda)$ and $P_\lambda S_\lambda =0$ iff $\operatorname{col}(S_\lambda)\subseteq\operatorname{col}(S_\lambda B)$; $P_a S_a \neq0$ for any $a$ different from an eigenvalue $\lambda$ of $A$.","['vector-spaces', 'limits', 'eigenvalues-eigenvectors', 'real-analysis', 'linear-algebra']"
1240519,"""Breaking the symmetry"" in solving a quartic equation","I've heard somewhere a discussion about solving algebraic equations before: When solving a quadratic equation, we are essentially doing the following.  Observe that $\Bbb{C}(x,y)\supset\Bbb{C}(x+y,xy)$ and $x-y\not\in\Bbb{C}(x+y,xy)$. But $(x-y)^2\in \Bbb{C}(x+y,xy)$ and
$$
P_1(x,y)=x-y\in\Bbb{C}(x+y,xy,\sqrt{(x-y)^2})=\Bbb{C}(x,y,z).
$$ When solving a cubic equation, observe that
$$
\Bbb{C}(x,y,z)\supset\Bbb{C}(x+y+z,xy+yz+zx,xyz)
$$
and $P_1(x,y,z)=(x-y)(y-z)(z-x)\not\in \Bbb{C}(x+y+z,xy+yz+zx,xyz).$ Now
$$
[(x-y)(y-z)(z-x)]^2\in \Bbb{C}(x+y+z,xy+yz+zx,xyz)
$$
and
$$
(x-y)(y-z)(z-x)\in \Bbb{C}(x+y+z,xy+yz+zx,xyz,\sqrt{[(x-y)(y-z)(z-x)]^2}).
$$
The next step is to add $P_2(x,y,z)=x+\zeta y+\zeta^2 z$ to the field above to get $\Bbb{C}(x,y,z)$ where $\zeta^2+\zeta+1=0$. Here are my questions : The pattern seems to be adding some special polynomials to the field generated by the elementary symmetric polynomials in symbols to get the filed generated by ""singleton"" of the symbols. How would one come up with a similar argument when solving a quartic equation? In what specific way is this procedure related to the group theory? I learned only a little bit Galois theory in the modern approach by field theory before. One can have the permutation group approach to Galois theory according to the Wikipedia article. But I am not familiar with it.","['abstract-algebra', 'field-theory', 'group-theory', 'galois-theory']"
1240550,Help in finding the sum of the series,$$\sum_{n=1}^\infty \frac{1}{n^4+n^2+1}$$ I tried breaking into factors but it is not telescoping. $$\frac {1}{(n^2+n+1)(n^2-n+1)} = \frac {1}{2n} \left(\frac {1}{n^2-n+1} - \frac {1}{n^2+n+1}\right)$$,"['sequences-and-series', 'calculus', 'limits']"
1240559,Distribution of a transformed Brownian motion,"Let $W$ be a standard Brownian motion. From an earlier proven result I know that $N_t = \exp\left\{a W_t - \frac12 a^2 t \right\}$ defines a martingale on the natural filtration of $W$ for all $a \in \mathbb{R}$. I now want to prove that for every $a>0$ the random variable 
$$ \sup_{t \geq 0} \left(W_t - \frac12 a t\right),$$
has an exponential distribution with parameter $a$. To prove this I want to use another earlier proven result namely that 
$$ P\left( \sup_{t \geq 0 } M_t > x \mid \mathcal{F}_0 \right) = 1 \wedge \frac{M_0}{x} \quad\text{a.s.,} $$
for every $x>0$ and positive, continuous martingale $M_t$ that converges a.s. to zero as $t \rightarrow \infty$. Yet I don't really see how I could combine these results as we are dealing with an exponential martingale $N_t$ which is indeed continuous and positive (does it converge to zero if $t$ tends to infinity?) hence we could use the statement:
$$ P\left( \sup_{t \geq 0 } \exp\left\{a W_t - \frac12 a^2 t \right\} > x \mid \mathcal{F}_0 \right) = 1 \wedge \frac{1}{x} \quad\text{a.s.,}$$
but what does this say about the distribution of  $\sup_{t \geq 0} \left(W_t - \frac12 a t\right)$?","['probability-theory', 'brownian-motion', 'stochastic-processes']"
1240599,How do I prove that $\forall \beta\in F(\alpha)\setminus F$ is transcendental?,"Let $E/F$ be a field extension. Let $\alpha\in E$ be transcendental over $F$. Let $\beta\in F(\alpha)\setminus F$. Then, how do I prove that $\beta$ is transcendental over $F$? Here's how I tried: Since $\beta\in F(\alpha)$, there exist $f(X),g(X)\in F[X]$ such that $\beta=\frac{f(\alpha)}{g(\alpha)}$. Suppos $\beta$ is algebraic over $F$. Then, there exists $h\in F[Y]\setminus\{0\}$ such that $h(\beta)=0$. Set $n=deg(h)$. Then, $\sum_{i=0}^n h_i (\frac{f(\alpha)}{g(\alpha)})^i=0$ Hence, $(\sum_{i=0}^n h_i f^i g^{n-i})(\alpha)=0$. To conclude, it should be proven that $\sum_{i=0}^n h_i f^i g^{n-i}$ is not a zero polynomial. How do I prove this? Or is there another way to prove that $\beta$ is transcendental?","['abstract-algebra', 'field-theory', 'transcendental-numbers']"
1240601,What is the easiest way to determine the accepted language of a deterministic finite automaton (DFA)?,"I'm new to automata theory and I'm currently working on some exercises on determining the accepted language of DFAs. I was wondering whether there exists some clever strategy to determine the accepted language of a DFA. For example, I have the following DFA over the alphabet {0, 1}: What is be the best approach to solve such problems?","['automata', 'discrete-mathematics']"
1240606,Convergence in Fréchet spaces and the topology,"actually i have two questions concerning Fréchet spaces (i am not familiar with these spaces so i need some help). I have a vector space $V$ with a distance $$d(x,y) = \sum_{n\in \mathbb{N}} \frac{|x-y|_k}{2^k(1+|x-y|_k)} $$ where $|.|_k$ is a separating family of semi-norms.
My questions are the following : 1/ I have noticed that a sequence $(x_n)$ converges to a $x$ for $d$ if and only if for all $M\in \mathbb{N}$ $$\lim_{n\to \infty} \max_{k\leq M}|x_n-x|_k =0$$ However i did not find this result in textbook (probably because it is too easy or because it is wrong). Could someone tell me if it really holds of if i made a misstake ? 2/ The topology induced by the familly of semi-norms is the set of subsets of $V$ which are unions of sets of the form  $$\cap_{j\in J}\{ y\in V : | |y|_k - a_j | <\epsilon_j \}$$ where $J\subset \mathbb{N}$ is finite. Is there a very short proof that this topology is the same as the one induced by the metric above ?","['metric-spaces', 'real-analysis', 'functional-analysis', 'general-topology', 'normed-spaces']"
1240613,"On the inequality $ \int_{-\infty}^{+\infty}\frac{(p'(x))^2}{(p'(x))^2+(p(x))^2}\,dx \le n^{3/2}\pi.$","$ p(x)\in\mathbb{R[X]} $ is a polynomial of degree $n$ with no real
  roots. Show that: $$\int\limits_{-\infty}^{+\infty}\dfrac{(p'(x))^2}{(p'(x))^2+(p(x))^2}\,dx \leq n^{3/2}\pi.$$ It's easy to see that the degree of $ p$ has to be even. For $n=2$ this integral is at most $2\pi$. For $n>2$ the maximum value of this integral is obtained when all the imaginary parts of the roots of $p(x)$ tend to $0$, but I couldn't go further. Any help would be appreciated, thanks. Edits by David Speyer: It seems very likely now that the optimum bound is $n \pi$, not $n^{3/2} \pi$. As pointed out in the comments below, and further in 23rd's question , this is the value we get in the limit where $p$ has double roots on the real axis. It seems likely that  moving the roots of $p$ away from the real axis can only make the integral less. Write the roots of $p$ as $a_j \pm i b_j$, so $p(x) = \prod ((x-a_j)^2 + b_j^2)$ and 
$$\frac{p'(x)}{p(x)} = \sum \frac{2 (x-a_j)}{(x-a_j)^2 + b_j^2}.\quad (\ast)$$ 
So making the $b_j$ larger tends to make $p'(x)/p(x)$ smaller, which makes the integral smaller. But this argument is not rigorous, because the terms of $(\ast)$ can have both positive and negative sign, so it could be that making the individual terms closer to $0$ makes the absolute value of $(\ast)$ larger. 
I don't see how to beat this issue easily. Thus, I'm putting up a bounty for proving or disproving $$ \int_{-\infty}^{+\infty}\dfrac{(p'(x))^2}{(p'(x))^2+(p(x))^2}\,dx \leq n\pi.$$","['polynomials', 'integral-inequality', 'improper-integrals', 'integration']"
1240643,"Two numbers are chosen at random over the interval $ [0,1]$","Two real numbers, $x$ and $y$ are chosen at random over the interval $ [0,1]$. What is the probability that the closest integer to $\frac{x}{y}$ will be even? Floor functions don't play nicely with integrals and I'm fairly certain that's the wrong way to be going about this. Looking for some rigor in the answer, if possible.","['probability', 'real-analysis', 'integration']"
1240668,Complex infinity ($1/0$) [duplicate],"This question already has answers here : I have learned that 1/0 is infinity, why isn't it minus infinity? (13 answers) Closed 9 years ago . I've learned that $$1/0$$ is postive and negative infinity, but if I ask wolfram mathematica to calculate $$1/0$$ it gives me: 'complex infinity' but how can we proof that that is true?","['infinity', 'discrete-mathematics']"
1240675,Probability of tail event using Kolmogorov's 0-1 law,"If $X_1,X_2,... $ are independent random variables and $X=\sup_nX_n$ then $P(X<\infty)$ is either 0 or 1. I think that if we prove the event to be a tail event then the result will follow. But I just don't know how to prove it to be a tail event.","['probability-theory', 'random-variables', 'measure-theory']"
1240696,Differentiation Tricks,"Since most derivatives are trivial to take, it's understandable why integrals get most of the mathematical tricksters' attention. However, not all derivatives are trivial to take and I think it's good to have as many tricks up your sleeves as possible. I noticed the other day that $\left(\frac{dy}{dx}\right)^{-1}=\frac{dx}{dy}$ and that we can use this fact to differentiate functions like the inverse trig functions e.g. $y=\arcsin(x)$, $$\frac{d \sin(y)}{dy}=\cos(y)=\cos(\arcsin(x))=\sqrt{1-x^2}=\left(\frac{dy}{dx}\right)^{-1}$$ My question is, does anybody know of any similar tricks to differentiate those rare functions which are non-trivial?","['differential-forms', 'derivatives']"
1240713,Convergence in the weak operator topology implies uniform boundedness in the norm topology?,"If $\{T_n\}$ is a sequence of bounded operators on the Banach space $X$ which converge in the weak operator topology, could someone help me see why it is uniformly bounded in the norm topology? I know how to apply the uniform boundedness principle to reach the conclusion above under the stronger assumption that the $T_n$ converge in the strong operator topology. I'd appreciate any helpful hints.","['banach-spaces', 'real-analysis', 'functional-analysis']"
1240718,Riddle: Assigning Students into Groups,"Suppose you had a classroom with 25 students. You want to assign 6 homework assignments over the course of the term and for each of these assignments students will work in groups of 5. But you want to do it so that no two students work in the same group for two different assignments. Is this possible, and if so how? I worked it out for the case of 25 students into groups of 5 and (I believe) $m^2$ students grouped into groups of $m$ if $m$ is a prime power. But these aren't all the possibilities. The conditions for situations that work are clearly if you have $n$ people put into groups of size $k$ you should have that $k$ divides n. But if you want it to work out so that you can have everyone work with everyone else exactly once with constant group sizes it should be the case $k-1$ divides $n-1$ since each student works with $k-1$ new students each time and they have a total of $n-1$ students they need to eventually work with. It turns out that the numbers n that satisfy this are $k + s k(k-1)$ for any nonnegative integer $s$ . So, $s = 0$ is trivial and $s = 1$ corresponds to the squares. So my question is: is it necessarily possible to solve this when $s > 1$ . That is: Is it possible to take a class with $k+s k(k-1)$ students, group them into groups of size $k$ for a series of assignments so that everyone works with everyone else exactly one time? Also, what about cases where there isn't a prime power number of students?","['graph-theory', 'combinatorics']"
1240798,On the existence of a polynomial in several variables with only one zero,"Given an ordered field $\mathbb{K}$, then for all $n>1$ there exists $f\in\mathbb{K}[X_1,\ldots,X_n]\ s.t.\ \mathcal{V}^{\mathbb{K}^n}(f):=\{p\in\mathbb{K}^n:f(p)=0\}=\{(0,\ldots,0)\}$ For instance, the unforgettable $\sum_{k=1}^nX_n^2$. On the other hand, Hilbert's Nullstellensatz shows that if $\mathbb{K}$ is algebraically closed a polynomial as such doesn't exist. So I started wondering for which fields $\mathbb{K}$ and $n>1$ $\ \exists f\in\mathbb{K}[X_1,\ldots,X_n]\ \mathcal{V}^{\mathbb{K}^n}(f)=\{(0,\ldots,0)\}$ I do not hope for a complete solution (but I wouldn't dislike it either): a little bestiary of examples and/or necessary conditions would be more than appreciated. For instance: what happens in finite fields? Chevalley-Warning theorem , paired with the observation that $\forall \alpha \in \mathbb{F}_q\ \alpha^q=\alpha$ made me think that such polynomials did not exist, but I soon proved myself wrong by realizing that $xy+x+y$ works for $n=2$ in $\mathbb{F}_2$ and $\mathbb{F}_4$. Thanks for any help.","['field-theory', 'number-theory', 'algebraic-number-theory', 'finite-fields']"
1240860,Question about this ODE? $\frac{dy}{dx} = \frac{2x-y}{x+2y}$,"Am I being dumb, or is this question actually hard?  I made the substitution $u=y/x \implies y = ux$, so then I get: $x \cdot \dfrac{du}{dx} + u = \dfrac{2x-ux}{x+2ux} \implies x \cdot \dfrac{du}{dx} + u = \dfrac{2-u}{1+2u} $.  Then I simplified this to $x \cdot \dfrac{du}{dx} + \dfrac{2u^2+2u-2}{1+2u}=0$... Now I have no idea how to solve this, back to where I started.  Was my initial substitution wrong? It's the one my teacher recommended so I thought it would work out a little better... Thanks!",['ordinary-differential-equations']
1240867,How to evaluate $\lim _{n\to \infty }\:\int _{1/(n+1)}^{1/n}\:\frac{\sin\left(x\right)}{x^3}\:dx$?,"We have to evaluate the following limit: $$\lim _{n\to \infty }\:\int _{\frac{1}{n+1}}^{\frac{1}{n}}\:\frac{\sin\left(x\right)}{x^3}\:dx,\:n\in \mathbb{N}$$ First step I wrote that
$\int _{\frac{1}{n+1}}^{\frac{1}{n}}\:\frac{\sin\left(x\right)}{x^3}\:dx\:=\:\frac{1}{n\left(n+1\right)}\cdot f\left(c\right)$ , where $c\in \left(\frac{1}{n+1},\frac{1}{n}\right)$. I have no ideea how can I evaluate: $\lim _{n\to \infty }\frac{\:f\left(c\right)}{n\left(n+1\right)}$ P.S: After, I want to see at you another method of solving.Thanks in advance!","['calculus', 'real-analysis', 'integration']"
1240873,Why do we take the odd extension?,"When we have the initial and boundary value problem $$u_{tt}(x,t)-c^2u_{xx}(x,t)=0, x>0, t>0 \\ u(0,t)=0 \\ u(x,0)=f(x), x \geq 0 \\ u_t(x,0)=g(x), x \geq 0$$ can we apply Green's theorem or does it have to stand that $x \in \mathbb{R}$ to use it?? Because in my notes they take the odd extension and I don't know why... Could you explain it to me?? $$$$ EDIT : In my notes they do it as followed: $$w_{tt}-c^2w_{xx}=0, x \in \mathbb{R}, t>0 \\ w(x,0)=f_{\text{odd}}(x), x \in \mathbb{R} \\ w_t(x,0)=g_{\text{odd}} (x), x \in \mathbb{R}$$ $$w(x,t)=\frac{1}{2}(f_{\text{odd}}(x-ct)+f_{\text{odd}}(x+ct))+\frac{1}{2c}\int_{x-ct}^{x+ct}g_{\text{odd}}(s)ds \\ w(0,t)=\frac{1}{2}(f_{\text{odd}}(-ct)+f_{\text{odd}}(ct))+\frac{1}{2c}\int_{-ct}^{ct}g_{\text{odd}}(s)ds=0$$ So, for $x>0, t>0$ $$u(x,t)=w(x,t)=\frac{1}{2}(f_{\text{odd}}(x-ct)+f_{\text{odd}}(x+ct))+\frac{1}{2c}\int_{x-ct}^{x+ct}g_{\text{odd}}(s)ds$$ $$u(x,t)=\left\{\begin{matrix}
\frac{1}{2}{(f(x-ct)+f(x+ct))+\frac{1}{2c}{\int_{x-ct}^{x+ct}g(s)ds, \ \ x-ct \geq 0}}\\ \\
\frac{1}{2}(-f(ct-x)+f(x+ct))+\frac{1}{2c}\int_{ct-x}^{x+ct}g(s)ds \ \ \ \ \ \ \ \ \ \ \ \ \ 
\end{matrix}\right.$$ Why have we taken the odd extension although we solve $u$ and not $w$ ??","['ordinary-differential-equations', 'partial-differential-equations']"
1240879,$\frac{d^2y}{dt^2}+4y=t\sin(2t)$'s particular solution,"Finding the particular solution of : $\frac{d^2y}{dt^2}+4y=t\sin(2t)$ Hey everyone! My professor recently went over this problem and I can't seem to find where he derived a particular equation. Hopefully, someone can help me out with that equation. I shall indicate when I explain below: We have: $$\frac{d^2y}{dt^2}+4y=t\sin(2t)$$ which can be rewritten as: $$\frac{d^2y}{dt^2}+4y=te^{2it}$$ Next, $$ a=1, b=0, c=4, \alpha=2i$$ Set $y=e^{2it} v$ Now my professor said this: $$ v''+4iv'=t$$ and I have no idea where he obtained that from. I shall show the rest
  of the problem. Guess=polynomial and since there is no v term, the highest power is 2. $$v=a_1t+a_2t^2$$
$$v'=a_1+2a_2t$$
$$v''=2a_2$$ Plugging back into $ v''+4iv'=t$, we have: $$ 2a_2+4ia_1+8ia_2t=t$$ Equating: $$ 8ia_2=1 \rightarrow a_2=\frac{-i}{8}$$ $$ 2_a2+4ia_1=0 \rightarrow a_1=\frac{1}{16}$$ Plugging back into v(t):
$$v(t)=\frac{1}{16}t-\frac{i}{8}t^2$$ Putting it all together: $$y=e^{2it}[\frac{1}{16}t-\frac{i}{8}t^2]$$
$$y=[\cos(2t)+i\sin(2t)][\frac{1}{16}t-\frac{i}{8}t^2]$$ Take note how the original problem says $\sin(2t)$, therefore our answer is the imaginary part which means the particular solution is: $$\psi(t)=\frac{t}{16}\sin(2t)-\frac{t^2}{8}\cos(2t)$$ I hope someone can help me find the part above. My professor mention there is two ways of solving this problem and normally I use another way but when I realize my professor's solution is much shorter, I wanted to learn his way but I'm just stuck with the part above.",['ordinary-differential-equations']
1240905,Sufficient conditions on integration kernel for continuity of the integral operator,"Suppose that we have a measure $d\mu(v)=e^{-|v|^2}dv$ on $\Bbb R^d$. We define a linear operator 
$$T[f](u)=\int_{\Bbb R^d} |u-v|^\beta f(v) d\mu(v).$$
I want to establish conditons on $\beta\in\Bbb R$ so the operator $T$ is continuous on $L^2(d\mu)$. Constant functions belong to $L^2(d\mu)$; for $\beta\le -d $ the operator $T$ is not defined for constant functions, hence, necessarily we need $\beta>-d$. If $\beta>-d/2$, then the integration kernel $k(u,v)=|u-v|^\beta \in L^2(d\mu(u)\,d\mu(v))$, and hence by Hilbert-Schmidt criterion the operator $T$ is compact and continuous. I'm interested in the case $\beta\in(-d,d/2]$. Is there a criterion that allows to show continuity/compactness of the operator $T$? I'll be glad to hear all suggestions.","['functional-analysis', 'hilbert-spaces', 'compact-operators', 'integral-operators', 'operator-theory']"
1240917,Green's Theorem and limits on y for flux,"I'm working through understanding the example provided in the book for the divergence integral.  The theorem (Green's): $$
\oint_C = \mathbf{F}\cdot \mathbf{T}ds = \oint_CMdy-Ndx=\int\int_R(\frac{\partial M}{\partial x}+\frac{\partial N}{\partial y} )dxdy
$$ The example uses the following: $\mathbf{F}(x,y) = (x-y)\mathbf{i} + x\mathbf{j}$ over the region $\mathbf{R}$ bounded by the unit circle $C: \mathbf{r}(t)=cos(t)\mathbf{i} + sin(t)\mathbf{j}, 0 \le t \le 2\pi$. There is then the following relations: $$
\begin{array}{rr}
M = cos(t) - sin(t) & dx = d(cos(t)) = -sin(t)dt \\
N = cos(t) & dy = d(sin(t)) = cos(t)dt
\end{array} \\
\begin{array}{rrrr}
\frac{\partial M}{\partial x}=1 & \frac{\partial M}{\partial y} = -1 & \frac{\partial N}{\partial x}=1 & \frac{\partial N}{\partial y} = 0
\end{array}
$$ Now that the foundation is laid, here's the rightmost part of the first equation given: $$
\begin{array}{rcl}
\int\int_R \frac{\partial M}{\partial x} + \frac{\partial N}{\partial y} dxdy & = & \int\int_R 1 + 0 dxdy \\
 & = & \int\int_R dxdy \\
 & = & \text{area inside unit circle} \\
 & = & \pi
\end{array}
$$ I understand it intuitively because it's the area over that region and the area of a circle is $A = \pi\cdot r^2$.  With $r = 1$ that's obviously $\pi$.  What I'm not sure of is how to express it in an integral.  The question $x^2 + y^2 = 1$ represents the unit circle.  Thus, $x$ as a function of $y$ I get $x = \sqrt{1-y^2}$, thus the final stage I show should be: $$
\int_{?}^{?} \int_{0}^{\sqrt{1-y^2}}dx dy
$$ right?  What should be used for the limits on y?  I know it's simple but I'm just not seeing it and I need some guidance. Thanks","['greens-theorem', 'multivariable-calculus', 'integration']"
1240931,Defining Lebesgue measure on a subspace of $\mathbb{R}^n$,"Let $\bar{w}_1,.., \bar{w}_k$ be linearly independent vectors in $\mathbb{R}^n$. Let $W$ be the subspace spanned by these $\bar{w}_i$'s. I know how the Lebesgue measure is defined on $\mathbb{R}^n$. How does one define Lebesgue measure on $W$ and assign volumes to measurable subsets of $W$? My attempt for clarification by an example: In $\mathbb{R}^3$, take $\bar{e}_1 = [1,0,0]$ and $\bar{e}_2 = [0,1,0]$. Let $V = Span \{\bar{e}_1,\bar{e}_2 \}$. The Lebesgue measure $m$ on $\mathbb{R}^3$ computes the volume of measurable sets in $\mathbb{R}^3$ and it gives $m(V) = 0$. But we can also define Lebesgue measure on $V$, which computes the area of measurable subsets of $V$. My question is about how one can generalize this example from $\mathbb{R}^3$ to $\mathbb{R}^n$ and to subspace $W$. PS This came up when I was reading something related to geometry of numbers where they computed volumes of certain parallelepipeds in the lattice of a subspace of $\mathbb{R}^n$. And I was wondering how it worked. Thank you! PPS I would also appreciate any reference.","['lebesgue-measure', 'reference-request', 'measure-theory']"
1240939,Why is there only one group of order $n$ for some non-primes?,"I would like to understand for which integers $n$ is there only one group of order $n$. (up to isomorphism). I understand that if $n$ is prime there is only one group of order $n$.  In Sloane's OEIS A003277 we see the primes along with: $1, 15, 33, 35, 51, 65, 69, 77, 85, 87, 91, 95, \cdots$.  We are told that there is only one group of order $n$ for integers in this sequence.  There are several characterizations of these numbers: Integers $n$ such that $x^n \equiv1$ (mod $n$) has no solution $2 \leq x \leq n$.  Integers $n$ such that gcd($\varphi(n),n)=1$.  Integers $n = p_1 \cdot p_2 \cdots p_k$ where no $p_i$ divides $p_{j - 1}$. Would any of these characterizations be used in a proof that there is only one group of order $n$ for $n$ in A003277?","['group-theory', 'elementary-number-theory']"
1240944,Finding all possible pairs of positive integer values,"The ratio of the sum of two positive integers to their difference is $7:5$. If the the sum of the two numbers is at most $25$, find all possible values for the pair of numbers. Let $m$ be the first positive integer. Then $\frac{m}{6}$ is the second positive integer. This gives $m = 21.4$, but now I'm stuck?","['arithmetic', 'fractions', 'algebra-precalculus']"
1240956,Relation between successor cardinals and power sets,"What are the known relation between successor cardinals $\kappa^+$ and power sets $2^\kappa$ (when GCH is not assumed)? For example, is it true that $\kappa^+ \le 2^\kappa \le \kappa^{++}$? In general, I am interested in rules and tricks for transforming an inequality involving one into an inequality involving the other. Is there a good (preferably online) reference that covers how the successors and power sets relate to one another?","['elementary-set-theory', 'cardinals']"
1240965,The even-numbered coefficients of the Maclaurin series of $ \frac{1}{\cos(x)} $ are odd integers.,"Let’s consider $ G(z) \stackrel{\text{df}}{=} \dfrac{1}{\cos(z)} $ as the exponential generating function of the sequence of Euler numbers. How can one prove that in the Maclaurin series of $ G $,
$$
G(z) = \sum_{k = 0}^{\infty} a_{2 k} \cdot \frac{z^{2 k}}{(2 k)!},
$$
the coefficients $ a_{2 k} $ are all odd integers? For instance, it’s reasonable to use the fact that
$$
\forall n \in \mathbb{N}_{0}: \quad
a_{2 n} = \frac{{G^{(2 n)}}(0)}{(2 n)!},
$$
but this way of bringing it into life seems too much complicated. Any help would be appreciated.","['power-series', 'taylor-expansion', 'calculus', 'generating-functions', 'combinatorics']"
1240974,What would the expected number of swaps in a merge sort be? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question If I were given a list of random numbers say x1, x2, .........., xn and these numbers are sorted according to the merge sort algorithm. What would be the number of expected swaps/exchanges which would take place?","['discrete-mathematics', 'permutations', 'algorithms', 'sorting', 'probability']"
1241015,Show that the Möbius band has its central circle $C$ as a deformation retract,"I have started this problem by using the planar representation of the Möbius band and noted that a line down the middle is probably what is meant by the central circle, since travelling from top to bottom (where the left and right sides are identified in opposite directions) appears to trace out a circle. The specifics of the deformation retraction are lost on me, I think I need a homotopy $f:M \times I \to S^1$ such that for all $m\in M$ and $x\in S^1$ we have $f(m,0)= m$, $ f(m,1)\in S^1$, $ f(x, 1) = x$. Is there a parameterisation of the Möbius band that makes defining such a function explicitly obvious? Intuitively I can imagine pulling the sides of the Möbius band in continuously to the circle, is the idea of straight line homotopy useful here?","['homotopy-theory', 'geometry', 'algebraic-topology', 'general-topology']"
1241049,$\mathbb Z[1/2]$ is not finitely generated?,"$\mathbb Z[1/2]$ is not finitely generated ? Maybe I misunderstood, what finitely generated means. Here it says, we need finitely many elements and I think $1$ and $1/2$ suffices as generators. But here , at the end of Proposition $5.1.4$, from the fact that $\mathbb Z[1/2]$ is not finitely generated it is concluded that $1/2$ is not integral.","['abstract-algebra', 'modules', 'finitely-generated']"
1241147,Finding lower/upper bounds for $\prod_{i=2}^n \log(i)$,"I have a homework problem where I need to asymptotically order a set of functions, and $\prod_{i=2}^n \log(i)$ is one of them. Is there a tight upper/lower bound for this function? I've tried the obvious upper bound of $\prod_{i=2}^n \log(n)$, and I've tried $2^n$ as a lower bound, but it's not particularly tight..","['calculus', 'functions']"
1241177,$x^p-x-1$ is irreducible over $\mathbb{Q}$[x],"For any prime  p, prove  that  $x^p-x-1$ is irreducible over $\mathbb{Q}$[x]. (In a field of characteristic p this is true). I asummed exist root in $\mathbb{Q}$, let's call $\frac{\alpha}{\beta} \in \mathbb{Q}$. Then following that  $\frac{\alpha ^p}{\beta ^p} - \frac{\alpha}{\beta}-1  = 0$ and then $\alpha ^p - \alpha \beta ^{p-1} - \beta ^p =0$. So $\alpha ^p = -\beta^p (1 + \alpha \beta ^{-1})$. But this only proves that $x^p -x -1$ don't have rational roots.",['abstract-algebra']
1241207,Symbol clarification,"Okay, so I've read a few different meanings for the exclamation point in a statement. For example: $$!\exists x \in O \ni 2x < 5$$ The only question I have is about the Exclamation point in front of the ""there exists"" symbol. I know it's also used in permutations, but that's a slightly different concept (I think) Any clarification would be fantastic, thank you","['elementary-set-theory', 'discrete-mathematics']"
1241245,Need Help Understanding Notation With Functions,"Original picture: LaTeX approximation: $$f\color{blue}{\substack{(x)\\x\to\infty}}=\pm\sqrt{\frac{(x^2+x)^3}{\pi}}.$$
What does the notation highlighted in blue mean? I understand that $x\to\infty$ means that $x$ is approaching infinity, but I do not understand how this could be used in a function. I should probably confess that I first saw this while watching Spongebob... Even though this is a kids show I still don't see why the creators would make up nonsense mathematics. Here is a picture:","['notation', 'functions']"
1241250,One of these two operators is not invertible,"I have a Hilbert space $H$ and a bounded self-adjoint operator $T$ on it with $||T||=1$. I've been trying to show that at least one of $I+T, I-T$ are not invertible, but I haven't been able to make any progress yet. Any suggestions would be appreciated.","['hilbert-spaces', 'real-analysis', 'functional-analysis']"
1241288,Limit $\lim_{x\to 0} x^{x^x}$,"What is:
$$\lim_{x→0} x^{x^x}$$ I'm getting 0 as an answer, but I also got infinity as an answer.
How would one solve this?",['limits']
1241292,expectation calculation problem,"I got the answers for this and i know its 1.05 but the way it explains is very difficult to understand so im seeking for some help here. A system made up of 7 components with independent, identically distributed lifetimes will operate until any of 1 of the system's components fails. If the life time X of each component has density function $f(x) =
\begin{cases}
3/x^4,  & \text{for 1<x}\\
0, & \text{otherwise}
\end{cases}$ what is the expected lifetime until failure of the system? I tried to find the intersect of 7 components by integrating and power it by 7 but it doesnt give me anything useful...","['probability-theory', 'probability', 'statistics']"
1241333,When does a homogeneous morphism have only finite fibers?,"Suppose that we have a map ${\bf f}:=(f_1,f_2,\cdots ,f_n):\mathbb{C}^n\rightarrow \mathbb{C}^n$ given by $$ \mathbb{C}^n\ni {\bf z}:=(z_1,z_1,\cdots,z_n)\rightarrow \big(f_1({\bf z}),f_2({\bf z}),\cdots,f_n({\bf z})\big) \in \mathbb{C}^n$$ such that the $f_i$'s are homogeneous polynomials of degree $d_i$ . I want to understand why the following is true: Theorem: The morphism ${\bf f}$ has finite fibers if and only if ${\bf f}^{-1}({\bf 0})={\bf 0}$. (where I am refering to the cardinality of ${\bf f}^{-1}({\bf y})$ for any ${\bf y}\in \mathbb{C}^n$ and where ${\bf 0}=(0,0,\cdots,0)$ ) Now, I know at least one way to do it: The condition ${\bf f}^{-1}(0)=0$ is equivalent with the fact that $(f_1,f_2,\cdots,f_n)$ is a homogeneous system of parameters for $\mathbb{C}[z_1,z_2,\cdots, z_n]$. This is easy to see, since $${\bf f}^{-1}(0)=0 \iff \sqrt{(f_1,f_2,\cdots,f_n)}=(z_1,z_2,\cdots,z_n)\iff (z_1,z_2,\cdots,z_n)^N\subset (f_1,f_2,\cdots,f_n)  $$ for a suitably big $N$, which is, according to Eisenbud for instance, the definition of a system of parameters. Now being a system of parameters implies $\mathbb{C}[f_1,f_2,\cdots,f_n]$ is a finitely generated $\mathbb{C}[z_1,z_2,\cdots,z_n]$-module and this in turn implies ${\bf f}$ is a finite morphism and hence has finite fibers. However, in the paper I am studying, the theorem is actually used to show the finiteness of ${\bf f}$ (via proper+quasifinite $\Rightarrow$ finite..). I believe there must be another way to show it then, without going through finiteness first. I am not sure if it is going to be a more elementary method or not. In particular, I think Bezout's theorem is involved, but I cannot figure it out. Say for instance that the fiber ${\bf f}^{-1}({\bf y})$ is an infinite set for some ${\bf y}\in\mathbb{C}^n$. We can translate that into the following situation in projective space: Consider $f_i'=f_i({\bf z})-y_i\cdot z_{n+1}^{d_i}$; they are homogeneous in $\mathbb{C}[z_1,z_2,\cdots,z_{n+1}]$) and therefore define $n$ hypersurfaces in $\mathbb{CP}^n$. Now, Bezout's theorem says that if the have finitely many intersection points, those would be at most $d_1d_2\cdots d_n$-many. Evenmore, if an intersection point $[z_1:z_2:\cdots:z_{n+1}]$ has $z_{n+1}\neq 0$ it corresponds (by setting $z_{n+1}=1$ and returning to the affine setting) to a solution of ${\bf f}({\bf x})={\bf y}$. Does an infinitude of intersections imply a common component for the hypersurfaces $f_i'=0$? Would this easily mean that there are nontrivial solutions of ${\bf f}({\bf x})={\bf 0}$? Even worse, I am afraid this isn't true in general (because not everything is a complete intersection...) Remark: Clearly, the direction (has finite fibers) $\Rightarrow\ {\bf f}^{-1}({\bf 0})={\bf 0}$ is obvious, since otherwise, because of homogeneity,  ${\bf 0}$ would have an infinite fiber (a whole line at least). I am looking for the less straight-forward direction.","['homogeneous-equation', 'affine-geometry', 'intersection-theory', 'commutative-algebra', 'algebraic-geometry']"
1241346,"Evaluate $\int_0^{1/\sqrt{3}}\sqrt{x+\sqrt{x^2+1}}\,dx$","I want to find a quick way of evaluating $$\int_0^{1/\sqrt{3}}\sqrt{x+\sqrt{x^2+1}}\,dx$$ This problem appeared on the qualifying round of MIT's 2014 Integration Bee , which leads me to think there should be a shortish way (no more than three minutes by hand) to solve it. Examining the indefinite integral (thanks to WolframAlpha) hasn't particularly helped me: $$\int\sqrt{x+\sqrt{x^2+1}}\,dx=-\frac{2}{3} \left(\sqrt{x^2+1}-2x\right) \sqrt{x+\sqrt{x^2+1}}+C$$ The bounds on the integral hint at trigonometric substitution, but I got nowhere by trying $x=\tan u$. I also noticed that we can transform the integral by multiplying $\dfrac{\sqrt{x^2+1}-x}{\sqrt{x^2+1}-x}$ in the first square root, but there didn't seem to be anything to do after that either.","['calculus', 'definite-integrals', 'integration']"
1241373,Proving a property about modulus,"I seem to be having a lot of trouble finding a place to start in proving that $$(a \cdot b) \mod m = ((a \mod m) \cdot (b \mod m)) \mod m$$
Any ideas on how I should go about doing this? I've been trying for about 30 minutes now with no progress.",['discrete-mathematics']
1241396,Embeddability of connected sum of non-embeddable surfaces,Let $X$ be a surface which can not be embedded into $\Bbb R^n$. Let $X \# X $ denotes the connected sum of two  copies of $X$. Then is it true that the connected sum $ X \# X $ is also not embeddable into $\Bbb R^n$?,"['algebraic-topology', 'general-topology', 'geometric-topology']"
1241400,Finite conjugate subgroup,"In a paper titled ""Trivial units in Group Rings"" by Farkas, what does it mean by Finite conjugate subgroup. Here is the related image attached- What is finite conjugate subgroup of a group? It is not clear to me what is author referring here.","['abstract-algebra', 'group-rings', 'group-theory']"
1241408,Why are the differentiation/integration rules what they are?,"So I understand what rules you use where, and the general forms of the rules like: $$\left(\frac{d}{dx}\right)^nx^k=\frac{k!}{(k-n)!}x^{k-n}$$ My question is why are these the formulas that give us the answers we want?  I learned integrals and derivatives using the limit method as the subdivisions got smaller and smaller, but I don't have a good conceptual understanding of the geometric manipulation taking place that allows the above rule to give us (slopes/areas) of exponential curves. For example, I learned that when you integrate you're finding an bunch of infinitesimal area rectangles under the curve $$dA=h*dx$$ where the height was the distance from the x-axis to the curve $$h=f(x)$$ so we get $$dA=f(x)dx$$ and then to go from an infinitesimal area to the whole area you integrate to get $$A=F(x)$$ Now from here, if $$f(x)=x$$ then $$F(x)=\int{x}dx=\frac{x^2}{2}+C$$ And my question is why does changing the exponent of the curve in this way (add one, divide by new exponent) give us the geometric area under the curve?","['derivatives', 'integration']"
1241469,Equivalence of 2 definitions of Differentiability,"Let $X,Y$ be Banach spaces. I would like to prove the equivalence of the following definitions of differentiability. Let $f:X\to Y$ and $a\in X$ There is a map $\Delta : X \to L(X,Y)$ continuous at $a$, s.t.
$$f(x)=f(a)+\Delta(x)(x-a)$$ There is a map $D_af\in L(X,Y)$ s.t. $$\lim_{x\to a}\frac{f(x)-f(a)-D_af(x-a)}{\|x-a\|_X}=0$$ The implication 1 => 2 is easy by picking $D_af=\Delta(a)$.
Im however stuck on the other direction, do I have to assume that $X,Y$ are finite dimensional? 1 => 2: Assume 1 holds, then $$\begin{align*}\frac{f(x)-f(a)-\Delta(a)(x-a)}{\|x-a\|_X}&=\frac{\Delta(x)(x-a)-\Delta(a)(x-a)}{\|x-a\|_x}\\
&=[\Delta(x)-\Delta(a)]\left(\frac{x-a}{\|x-a\|_X}\right)\to0\end{align*}$$ since  $\Delta$ is continuous at a. For 2=>1 I can do the 1-dimensional case. Then the map $D_af$ is just multiplication with the element $f'(a)$. If I let
$$R(x):= \frac{f(x)-f(a)-D_af(x-a)}{x-a}$$
And define the map $\Delta(x)$ to be multiplication with the element $(f'(a) + R(x))$ (for $x\neq a$ and $D_af$ else) everything works out fine. So I thought the general finite dimensional case should work similar by defining $\Delta(x)$ to be the map given by the Jacobi Matrix of $D_af$ with every entry increased by $R(x):=\frac{\|f(x)-f(a)-D_af(x-a)\|_Y}{\|x-a\|_X}$. This surely gives continuity at $a$ but I don't see how the equality in 1 follows. For the infinite dimensional case I have no idea how to proceed.","['multivariable-calculus', 'real-analysis']"
1241489,Prove that ≿ is transitive iff ≻ and ∼ are transitive,"Let ≿ be a complete preference relation (as in game theory). How to prove that ≿ is transitive if and only if ≻ and ∼ are both transitive? My reasoning is as follows. a ≿ b probably means (a ≻ b) ∨ (a ∼ b) , by analogy with ≥, which means greater OR equal. Transitivity means (a ≿ b) ∧ (b ≿ c) → (a ≿ c) . Therefore we must prove that following expression is valid: $$[(a \succ b) \wedge (b \succ c) \rightarrow (a \succ c)] \wedge [(a \sim b) \wedge (b \sim c) \rightarrow (a \sim c)] \equiv [((a \succ b) \vee (a \sim b)) \wedge ((b \succ c) \vee (b \sim c)) \rightarrow ((a \succ c) \vee (a \sim c))]$$ For brevity, let's substitute the relations with capital letters: a ≻ b: A
a ∼ b: B
b ≻ c: C
b ∼ c: D
a ≻ c: E
a ∼ c: F The expression then becomes: $$(A \wedge C \rightarrow E) \wedge (B \wedge D \rightarrow F) \equiv [(A \vee B) \wedge (C \vee D) \rightarrow (E \vee F)]$$ No amount of logical manipulation allows to prove that LHS is equivalent to RHS. What am I doing wrong? Ideally, your answer would consist of a hint that would allow me to solve the problem myself without giving out the answer.","['elementary-set-theory', 'propositional-calculus', 'relations']"
1241527,Sup and inf of $n \sin(1/n)$,"If $n$ is a natural number then, what is the supremum and infimum of $n\sin(1/n)$? is the question I want to solve. I drew $sin(x)/x$ graph and I think that the supremum is $1$ and infimum is $sin(1)$. Is that right? And how can I solve?","['analysis', 'supremum-and-infimum']"
1241539,Proof By Induction $n^2 > 3n$ where $n\ge 4$,"I am trying to prove the following example, however I seem to be getting a little stuck: For $n\in\mathbb N$, $n\ge 4, n^2>3n$ What I have Done:
Base Case:$ n=4$, LHS: $4^2 = 16$, RHS: $3\cdot 4 = 12$ $16\gt 12$, so True Assume true for $n=k$,
$k^2 > 3k$ Should be true for $n=k+1$ $(k+1)^2 \gt 3(k+1)$ This is where I am stuck! Any help would be appreciated!","['induction', 'discrete-mathematics', 'inequality']"
1241548,Open Unit Ball diffeomorphic to the Open Unit Cube,"How can I show that the open unit cube $(-1,1)^n \subset \mathbb{R}^n$ and the open unit ball $B = \{x \in \mathbb{R}^n  \mid  \|x\| < 1\}$ are diffeomorphic? I know that one can proof this by showing that those two sets are diffeomorphic to the whole space $\mathbb{R}^n$. But is there a direct way (not over the $\mathbb{R}^n$ ) to proof this? Thus, is there a smooth, differentiable bijection between the two sets with a differentiable inverse?","['differential-topology', 'differential-geometry', 'general-topology']"
1241568,ODE) $y'' + 2y' = 1 + t^2 + e^{-2t}$,"I'm stuck with the ODE problem: $y'' + 2y' = 1 + t^2 + e^{-2t}$ This problem is in ""judicious guessing"" chapter of Braun's ""Differential Equations and Their Applications"". The trick he taught in the chapter is to set $\psi$ = $A_0 + A_1 t + ... A_n t^n$ and determine constant terms. Also, he taught the technique to deal with such equations as $(1+t+t^3)e^5t$. But, he is never explicit as to equations with the above form. I tried several tricks, but they don't work. Can anybody help with this? Thanks.",['ordinary-differential-equations']
1241569,Show that the free product of countably many countable groups is countable.,"The question I am struggling with is as follows: Suppose that $\{G_\alpha\}$ is a countable collection of countable
  groups. Show that $\ast_{\alpha}G_\alpha$ is countable. The definition of countable that I am using is that $G$ there is some injective function $G \rightarrow \mathbb{N}$. I am aware that one can show the Cartesian product of countable groups is countable by constructing a matrix, and I have been trying to do something similar for this problem, however I can't seem to get anywhere.","['abstract-algebra', 'group-theory', 'free-groups']"
1241571,Counting sequences using Catalan Numbers,"Count the number of sequences $a_{1},...,a_{2015}$ such that: $a_{i}\in \{-1,1\}$, and $\sum _{i=1} ^ {2015} a_{i}=7$, and $\sum _{i=1} ^{j} a_i >0$ for every $1\leq j\leq 2015$ I assume we have to use Catalan numbers somehow. It's clear that the number of $1$'s = number of $-1$'s $+7$. From the third condition it's also clear that the sequence must start with $1$. Beyond that, I can't see how to proceed from here.","['catalan-numbers', 'combinatorics']"
1241610,Random Variables and Statistic,"I'm studying Statistical Inference by Casella and I'm confused with the definitions of random variable & statistic. So let we have the probability space  $(\Omega, F, P)$ where $\Omega$ is the sample space, $F$ is the $\sigma-algebra$ and $P$ is the probability function. Then we define ""a"" random variable, a function that maps every element in the sample space to a real number in the interval $[0,1]$. After that we define a statistic; Let $X_1, X_2, .., X_n$ be a random sample of size n from a population and let $T(x_1, x_2, .., x_n)$ be a function whose domain includes the sample space of $(X_1, X_2, .., X_n)$. Then the random variable/vector   $T(X_1, X_2, .., X_n)$  is called a statistic. This is the part where I stuck. I think that we can define lots of different random variables on a probability space and then define different distribution functions. But what is the relation between our sample space, random variables and ""a"" statistic?","['probability-theory', 'statistical-inference', 'statistics', 'sampling', 'probability']"
