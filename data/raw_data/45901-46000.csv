question_id,title,body,tags
459522,Density of Diagonalizable matrices,"Suppose that the matrix $A$ is not diagonalizable. Show that for all $\epsilon>0$, there exists a diagonalizable matrix $A_{\epsilon}$ such that $||A-A_{\epsilon}||_{2}<\epsilon$. Can anyone help me prove this or give a hint?","['matrices', 'linear-algebra']"
459553,Compute $\int_{\mathbb {R}}\sin \left(\frac {\pi x}{x^2+1}\right)\frac{1}{x^2+1} dx$,"How do I compute this integral?
$$\int_{\mathbb {R}}\sin \left(\frac {\pi x}{x^2+1}\right)\frac{1}{x^2+1} dx$$","['fourier-analysis', 'real-analysis', 'analysis']"
459554,How can one convert rational matrices into integer ones?,Let $G$ be a finite subgroup of $GL_n(\Bbb{Q})$. I want to show the existence of a matrix $A\in GL_n(\Bbb{Q})$ with the property that $AGA^{-1} \subseteq M_n(\Bbb{Z})$.,['linear-algebra']
459576,Infinite solutions of Pell's equation $x^{2} - dy^{2} = 1$,"Let $d > 1$ be a squarefree integer. Prove that the equation $x^{2} - dy^{2} = 1$ has infinitely many solutions in $\mathbb{Z} \times \mathbb{Z}$. What I have done: let $ \ \mathbb{K} = \mathbb{Q}[\sqrt{d}]$. If $ d \not\equiv 1$ mod $4$, then $O_{\mathbb{K}} = \mathbb{Z}[\sqrt{d}]$ and the statement follows by the Dirichlet Unit Theorem. What about the case $ d \equiv 1 $ mod $4$ ?","['diophantine-equations', 'algebraic-number-theory', 'abstract-algebra', 'number-theory']"
459585,Image of subgroup and Kernel of homomorphism form subgroups,"Is my proof ok? Let $f:G\to G^{\prime}$ be a group homomorphism and let $H\leq G$ . $\text{Im}(H) = \{f(x):x\in H\}$ . To show that $\text{Im}(H)$ is a group, it suffices to show that $f(x)f(y)^{-1}\in \text{Im}(H)$ . $$f(x)f(y)^{-1}=f(xy^{-1})\in \text{Im}(H)\text{ because } xy^{-1}\in H$$ $\text{Ker}(f)=\{x:f(x)=e^{\prime}\}$ ( $e^{\prime}$ is the identity in $G^{\prime}$ ). $$f(xy^{-1})=f(x)f(y)^{-1}=e^{\prime}(e^{\prime})^{-1}=e^{\prime}\in \text{Ker}(f)$$ .",['group-theory']
459611,"$\int f_k\to 0 $ but $f_k $ does not converge to $0 $ ae, where $ f_k $ is defined in $[0, 1] $","Give an exemple, in [0, 1], of a sequence of functions $ f_k $ such that $||f_k||_ 1=\int |f|_k \to 0 $ but $ f_k $ does not converge to $0 $ a.e.","['lp-spaces', 'examples-counterexamples', 'real-analysis', 'analysis']"
459627,Probability in a deck of cards to have two jacks in a row,"In a deck of $36$ cards ($9$ cards per color, $4$ colors) what is the probability to have $2$ jacks (or more) that follow each other?","['card-games', 'probability', 'combinatorics']"
459633,Doubling measure is absolutely continuous with respect to Lebesgue,"Let $\mu$ be a fixed finite measure on $\mathbb R$. We say that $\mu$ is doubling if there exists a constant $C>0$, such that for any two adjacent intervals $I=[x−h,x]$ and $J=[x,x+h]$, $$C^{−1}\mu(I)≤\mu(J)≤C\mu(I).$$ 
Assuming that $\mu$ is doubling, show that there exist positive constants $B$ and $a$, such that for every interval $I$, $$\mu(I)≤B[length(I)]^a$$ By Radon-Nikodim, I solved but I use the fact that $\mu$ is absolutely continous with respect to Lebesgue measure, but I don't know to prove this last part, i.e., that $\mu$ is absolutely continuous with respect to Lebesgue.","['measure-theory', 'real-analysis', 'analysis']"
459640,Example of modules over PID's,"From Advanced Modern Algebra (Rotman): Definition If $M$ is a finitely generated torsion $R$ -module, where $R$ is a PID, and $$M= R/(c_1) \oplus R/(c_2) \oplus ... \oplus R/(c_t),$$ where $t \geq 1$ and $c_1 | c_2 | ... | c_t$ , then the ideals $(c_1), (c_2), ... , (c_t)$ are called the invariant factors of $M$ . Corollary 8.20 If $M$ is a finitely generated torsion module over a PID $R$ , then $$(c_t) = \{r \in R: rM=\{0\}\},$$ where $(c_t)$ is teh last ideal occuring in the decomposition of $M$ [in the definition]. In particular, if $R=k[x]$ , where $k$ is a field, then $c_t$ is the monic polynoial of least degree for which $c_tM=\{0\}$ . I understand how these work for abelain groups. Let $G = J(c_1) \oplus ... \oplus J(c_r),$ where $J(c_i)$ is a cyclic group of order $c_i$ , and $c_1 | c_2 | ... |c_r$ . Then, since $c_iJ(c_i) = 0$ , (if we let $c_r = ac_i$ for some $a$ ) we have $c_rJ(c_i) = a(c_iJ(c_i)) = 0$ . It also makes intuitive sense to me. But when I think about modules, it kind of gets confusing. How can you annhilate a cylic module by multiplying it by a polynomial ? In other words, I thought that it would be clearer in my head if I saw an example, so I tried to search the internet but couldn't really find anything useful. So I was wondering if anybody could give me an example (even if its a simple one), just so I can see how multiplying by a polynomial can annihilate a cyclic module. Thank you in advance","['modules', 'linear-algebra', 'abstract-algebra']"
459650,Continuity on open and closed intervals,"I will be taking Calculus I soon, and I just want to make sure I understand some concepts correctly. So far, reading my book for Calculus I, I've encountered the definition of continuity as being defined on a closed interval $[a,b]$. This means that it exists at every single point in the interval including the endpoints, (meaning, that it can be approached from $a^+$, from $a^-$, from $b^+$, and from $b^-$, i.e., from both sides), correct? A polynomial would be such an example. I looked through my book but there is no definition of continuity on an open interval $(a,b)$. Continuity on an open interval just means that it's approachable from only one side, either $a^-$ or $a^+$, or $b^+$ or $b^-$, but not only one of those, correct? Is such a property the same thing as a one-sided limit? So, for example, ln would be an example of such a continuous property, since it's only defined for the positive numbers and thus can only be approached from one side? So, then, does that mean that only a continuous function on a closed interval $[a,b]$ can attain a maximum/minimum value? A closed-open interval would also attain a maximum or a minimum but not both, such as $[a,b)$, correct? sorry if these are too elementary for this website...","['definition', 'calculus', 'continuity', 'limits']"
459668,Proving formula for $p$-adic ordinal of $n!$,Let $n \geq 1$ and $n = n_0 + ... n_{\ell}p^{\ell}$ be the p-adic expansion of $n$. Define $\alpha_p(n) = n_0 + ... n_\ell$.  Then $\mathrm{ord}_p(n!)= \frac{n - \alpha_p(n)}{p-1}$.  I'm trying to prove this by induction and that doesn't seem to work without insanity.  Any ideas? P-adic Notes by Andrew Baker,['number-theory']
459671,How many zeros does $z^{4}+z^{3}+4z^{2}+2z+3$ have in the first quadrant?,"Let $f(z) = z^{4}+z^{3}+4z^{2}+2z+3$. I know that $f$ has no real roots and no purely imaginary roots. The number of zeros of $f(z)$ in the first quadrant is $\frac{1}{2\pi i}\int_{C}\frac{f'(z)}{f(z)}\, dz$ by the Argument Principle where $C = C_{1} + C_{2} + C_{3}$ with $C_{1}$ the line from origin to the point $(R, 0)$ on the $x$-axis, $C_{2}$ is the line $Re^{i\theta}$ where $0 \leq \theta \leq \pi/2$, and $C_{3}$ is the line segment from the point $(0, R)$ to the origin. We have
$$\frac{1}{2\pi i}\int_{C_{2}}\frac{f'(z)}{f(z)}\, dz = \frac{1}{2\pi}\int_{0}^{\pi/2}4 + O(R^{-1})\, d\theta \rightarrow 1$$ as $R \rightarrow \infty$.
I am having an issue computing the integral for $C_{1}$ and $C_{3}$. For $C_{1}$, I want to compute
$$\lim_{R \rightarrow \infty} \frac{1}{2\pi i}\int_{0}^{R}\frac{4x^{3} + 3x^{2} + 8x + 2}{x^{4} + x^{3} + 4x^{2} + 2x + 3}\, dx$$ but doesn't this evaluate to $\infty$ since the inside is $O(1/x)$?","['roots', 'complex-analysis']"
459675,"Prove that the map $\phi:S^3\times S^3\to{\bf GL}(4,\Bbb R)$ defined via quaternions as$\phi(p,q)(v)=pvq^{-1}$ has image ${\bf SO}(4)$","I am interested in the map $\phi:S^3 \times S^3 \to GL_4(\mathbb{R})$ given as follows: Let $(p,q) \in S^3 \times S^3$. We identify $p$ and $q$ as real quaternions with unit norms and define $\phi(p,q)$ to be the map sending $v \in \mathbb{H}$ to the product $pvq^{-1}$, where $\mathbb{R}^4$ and $\mathbb{H}$ are identified in the obvious way as $\mathbb{R}$-vector spaces. It isn't hard to show that $\phi$ is a group homomorphism. I would like to prove the following in complete detail: 1) The image of $\phi$ is $SO(4)$. 2) The kernel of $\phi$ is $\{(1,1), (-1, -1)\}$ I proceed by noting that the maps $\phi(p,q)$ are clearly $\mathbb{R}$-linear, and since $p$ and $q$ have unit norm, these maps are also easily seen to be orthogonal. Thus, we have $\phi(S^3 \times S^3) \subseteq O(4)$. Now suppose $\phi(p,q)$ is the identity map on $\mathbb{R}^4$. That is, $pvq^{-1}=v\ \ \ \forall v \in \mathbb{H}$. Then for $v=1 \in \mathbb{H}$, we have $pq^{-1}=1$, and so $p=q$. By considering the equations $piq^{-1}=i$, $pjq^{-1}=j$, and $pkq^{-1}=k$, we conclude that $p=q \in \mathbb{R}$. Since $\mathbb{R} \cap S^3 = \{\pm1\}$, an easy compuation shows that the kernel of $\phi$ is $\{(1,1), (-1, -1)\} \cong \mathbb{Z}_2$. I am not very confident about the remainder of this argument. The map $\phi$ is smooth since the entries of the matrices $\phi(p,q)$ are polynomials in the $\{1, i, j, k\}$-coordinates of $p$ and $q$ realized as quaternions. Since $S^3 \times S^3$ is connected, we know that $\phi(S^3 \times S^3)$ is contained in the identity component of $O(4)$. That is, $\phi(S^3 \times S^3) \subseteq SO(4)$ (We could have also checked the determinant explicitly, but this is a bit tedious).
Since the kernel acts freely and properly on $S^3 \times S^3$, we see that the image of $\phi$ is a smooth six-dimensional manifold. We can count the dimension of $SO(4)$ by considering its Lie algebra of skew-symmetric matrices. It is then easy to see that the dimension of $SO(4)$ is six. It follows that the image is an open submanfiold of $SO(4)$. Note also that $S^3 \times S^3$ is compact, and so is its image. Since $SO(4)$ is Hausdorff, it follows that the image of $\phi$ is also closed in $SO(4)$. Since $SO(4)$ is connected, it follows that the image of $\phi$ is all of $SO(4)$. My questions are as follows: 1) Is there anything wrong with this argument? Even picky corrections are much appreciated. 2) Can you identify any arguments that, while correct, you would prefer to do another way? 3) What more can be said about this map? Is there a common sense reason that these left and right quaternion multiplication actions produce all of $SO(4)$? Can we rephrase this argument in another language which might be more natural? This question is a little bit open ended, but only because I am not sure how to phrase it. The best answer would give me some clue about where this map fits into the general picture, if possible. Perhaps some application of the covering map would be appropriate here. Thanks in advance for any responses.","['differential-geometry', 'abstract-algebra', 'quaternions', 'lie-groups', 'group-actions']"
459676,Probability of getting at least one ball of each color,"Given that we have an urn containing $N=\sum{N_i}$ balls, $N_1$ of color $1$, $N_2$ of color $2, \dots, N_k$ of color $k$, we draw $m$ balls from the urn such that $m \geq k$ and $m \leq \max(N - N_i)$ what is the probability that we get at least one ball of each color? 
I just cant find a reasonable way to express this condition in order to get a closed form formula for it.","['probability-theory', 'probability']"
459680,Are quantifiers a primitive notion?,"Are quantifiers a primitive notion? I know that one can be defined in terms the other one, so question can be posed, for example, like this: is universal quantifier a primitive notion?  I know, that $\forall x P (x) $ can be viewed as a logical conjunction of a predicate $ P $ being applied to all possible variables in, for example, $\sf ZFC$. But how can one write such a statement down formally? Also, it seems you can not use the notion of a set to define the domain of discourse, because you are trying to build $\sf ZFC$ from scratch, and sets make sense only inside $\sf ZFC$. Obviously, I'm missing a lot here. Any help is appreciated.","['logic', 'elementary-set-theory']"
459696,Norm of a $2\times 2$ matrix as a Hilbert space operator,"Work in the Hilbert space $\mathbb C^2$. Let $$A = 
        \begin{bmatrix}
        a & b \\
        c & d  \\
        \end{bmatrix}
$$ be a matrix with entries in $\mathbb C$, and let $A$ act in the standard way on $\mathbb C^2$. This gives a linear operator on $\mathbb C^2$. Define $\alpha=[|a|^2+|b|^2+|c|^2+|d|^2]^{1/2}$ and $\delta = \sqrt{\det A^* A}$. I would like to show that $$\|A\|=\frac{\alpha^2+\sqrt{\alpha^4-4\delta^2}}{2},$$ where $\|A\|$ is the norm as a Hilbert space operator. (Note the resemblance to the quadratic formula.) This problem comes from page 30 of Conway's A Course in Functional Analysis , 2nd edition. It is problem 1.11 in chapter 2.","['hilbert-spaces', 'functional-analysis']"
459701,"Arguing that $\lim_{r \to 0}\int_{C_{r}}f(z) \, dz = i \pi \operatorname{Res}[f(z), z_{0}]$, where $C_{r}$ is a semicircle of radius $r$","I recently made the following observation: Assume that the function $f(z)$ can be expressed near $z=z_{0}$ in the form $$ \sum_{k=-n}^{0} a_{2k-1} (z-z_{0})^{2k-1} + g(z) \, ,$$ where the function $g(z)$ is analytic at $z_{0}$. If $C_{r}$ is a counterclockwise-oriented semicircle of radius $r$ centered at $z_{0}$, then $$\lim_{r \to 0} \int_{C_{r}} f(z) \, dz = i \pi  \, \text{Res}[f(z),z_{0}].$$ Is my observation correct? Attempt at a proof : $$ \begin{align} \int_{C_{r}} f(z) \, dz &= \int_{\alpha}^{\alpha + \pi}f(z_{0}+re^{it}) \ i r e^{it} \, dt \\ &= \int_{\alpha}^{\alpha + \pi} \left(\sum_{k=-n}^{0} a_{2k-1} (re^{it})^{2k-1} + g(z_{0}+re^{it}) \right) i r e^{it} \, dt \\ &= i \sum_{k=-n}^{-1}a_{2k-1} r^{2k} \underbrace{\int_{\alpha}^{\alpha + \pi} e^{2ikt} \, dt}_{0} + i a_{-1} \int_{\alpha}^{\alpha + \pi} \, dt + i r \int_{\alpha}^{\alpha + \pi} g(z_{0}+re^{it}) \, e^{it} \, dt \\  &= i \pi a_{-1} + i r \int_{\alpha}^{\alpha + \pi} g(z_{0}+re^{it}) \, e^{it} \, dt \end{align}$$ And since $|g(z)|$ is bounded near $z_{0}$, $$ \lim_{r \to 0} \int_{C_{r}} f(z) \, dz = i \pi a_{-1} + 0 = i \pi \, \text{Res}[f(z),z_{0}]$$","['complex-analysis', 'contour-integration']"
459723,Banach space integral via defining it in $X^{**}$ and then proving it's in $X$,"Vector-valued integration is something I generally try not to think about very much. I have the impression that it can be a sort of ""rabbit hole"" of a subtlety if one allows it to be. So, I tend to treat it as a black box. Eventually, though, adopting this attitude is bound to make a person feel guilty -- and then it's time to firm things up a bit. I know there are various ways of defining the integral of a Banach space-valued function. What I'm asking about here is an approach that I've always had in the back of my mind as something that ""should work"", but, when I tried to write down the details, I became less confident. Can anybody help me put this on rigorous footing? Or gently inform me that this approach is not good? Here is the sort of setting I have in mind. Let $X$ be a Banach space, say over $\mathbb{C}$, and let $f : \mathbb{R} \to X$ be continuous and such that $M : = \int_\mathbb{R} \|f(t)\| \ dt < \infty$. Now, for any $\varphi \in X^*$, we have
$$ | \int \varphi \circ f | \leq \int |\varphi(f(t))| \ dt \leq \int \| \varphi \| \| f(t) \| \ dt = M \|\varphi\| $$
so it is not difficult to see that $\varphi \mapsto \int \varphi \circ f : X^* \to \mathbb{C}$ is a bounded linear functional, that is, an element of $X^{**}$. What I want to do now show is show that this element of the double dual is actually in $X \subset X^{**}$ so that there is an element $I \in X$ satisfying $\varphi(I) = \int \varphi \circ f$ for all $\varphi \in X^*$. One then defines $\int f := I$. The way I always envisioned doing this was by an application of the following fact: An element $\psi \in X^{**}$ is actually in $X \subset X^{**}$ if (and only if) it is continuous $X^* \to \mathbb{C}$ when $X^*$ has the weak-star topology. So, let's try to see if $\varphi \mapsto \int \varphi \circ f$ has this kind of continuity. Suppose that $\varphi_i$ is any net in $X^*$, convergent in the weak-start topology to some $\varphi \in X^*$. That is $\varphi_i(x) \to \varphi(x)$ for all $x \in X$. We want to show that
$$ \int_\mathbb{R} \varphi_i(f(t)) \ dt \to \int_\mathbb{R} \varphi(f(t)) \ dt.$$
In our favour, we have that $\varphi_i \circ f \to \varphi \circ f$ pointwise over $\mathbb{R}$ (from the weak-star continuity). So, one thinks that Lebesgue's dominated convergence function may apply. But the problems with this are two-fold. We need a dominating function for the family of functions $t \mapsto \varphi_i(f(t))$. I think maybe the uniform boundedness principle can help here? The Lebesgue dominated convergence theorem applies to sequences not nets. Unless there is some way to finesse around this issue, I think this may be a more critical error. To reiterate, the slightly flabby question I'm asking is: Can the approach to defining $\int f$ I just outlined be ""rigourized""? Thanks for reading.","['integration', 'banach-spaces', 'vector-analysis', 'lebesgue-integral', 'functional-analysis']"
459724,Is $\lim_{x\rightarrow\infty}\frac{x}{\pi(x)}-\ln(x) =-1$?,"$\pi(x)$ is the number of primes not exceeding $x$. The prime number theorem states that $\lim_{x\rightarrow \infty} \frac{\pi(x)}{x/\ln(x)} = 1.$ So I, naïvely, inferred that $\lim_{x\rightarrow\infty}\frac{x}{\pi(x)}-\ln(x) =0.$ But I did some tests and it would very much seem that the true value of the limit is minus one. But just because $\lim_{x\rightarrow \infty} \frac{\pi(x)}{x/\ln(x)} = 1,$ this doesn't tell anything about the absolute error.... So I ask if $\lim_{x\rightarrow\infty}\frac{x}{\pi(x)}-\ln(x) =-1$?","['prime-numbers', 'logarithms', 'elementary-number-theory', 'limits']"
459727,Continuity on open interval,"A function is said to be continuous on an open interval if and only if it is continuous at every point in this interval. But an open interval $(a,b)$ doesn't contain $a$ and $b$, so we never actually reach $a$ or $b$, and therefore they're not defined, and points that are not defined are not continuous, in other words $f(a)$ and $f(b)$ don't exist which makes the interval $(a,b)$ discontinuous. So what is this definition saying, because I thought that it can't be continuous at $a$ or $b$ since they are not defined (an open circle on the graph), but everywhere in between $a$ and $b$ it can still be continuous... So is it just continuous between these points $a$ and $b$, and a jump discontinuity occurs at these two points? Why then does it say that it's continuous at every point in $(a,b)$, if we are not including $a$ and $b$? Points on an open interval can be approached from both right and left, correct? why is it required to be continuous on open $(a,b)$ in order to be continuous on closed $[a,b]$, I don't understand this because $a$ and $b$ are not defined in $(a,b)$. please help to understand","['calculus', 'definition', 'functions', 'continuity', 'limits']"
459735,Dilogarithm inversion formula: $ \text{Li}_2(z) + \text{Li}_2(1/z) = -\zeta(2) - \log^2(-z)/2$,"I have been chugging through some proofs regarding the dilogarithm, also known as
[Spencer's function][1]. \begin{alignat}{2} 
		&  \operatorname{Li}_2(z) + \operatorname{Li}_2(-z) = \frac{1}{2} \operatorname{Li}_2(z^2)  
		&& \text{(Double Identity)} \tag{1} \\
		&  \operatorname{Li}_2(z) + \operatorname{Li}_2(1-z) = \frac{\pi^2}{6} - \log z \log (1 - z) \
		&& \text{(Eulers reflection formula)} \tag{2} \\
		&  \operatorname{Li}_2(-z) + \operatorname{Li}_2\left( \frac{z}{1+z} \right) = -\frac{1}{2} \log^2(z+1)  
		&& \text{(Landen's Identity)} \tag{3} \\ 
		&  \operatorname{Li}_2(z) + \operatorname{Li}_2\left( \frac{1}{z} \right) = - \frac{\pi^2}{6} - \frac{1}{2}\log^2(-z) \ \ 
		&& \text{(Inversions formula)} \tag{4}
\end{alignat} With the basis of $\text{Abel's Identity}$ (see Proving Abel's identity for the Dilogarithm. ). I have been able to prove
all the the identities except the last. (My proof for $(3)$ , was somewhat convoluted, so hints there would be appreciated..). I have yet to prove $(4)$ , although I have given it two attempts below Attempt 1 In the Abel Identity let $x=y=1-z$ and divide by $2$ to obtain $$
\frac{1}{2}\log(-z)^2 = \operatorname{Li}_2\left( -\frac{1+z}{z}\right) - \frac{1}{2} \operatorname{Li}_2\left( \left[ \frac{1+z}{z} \right]^2 \right) -   \operatorname{Li}_2(1+z)
$$ By now using $(1)$ with $z = [1+1/z]^2$ and inserting it into the equation above I obtain $$
\frac{1}{2}\log(-z)^2 = - \left[ \operatorname{Li}_2\left( \frac{1}{z} + 1\right)- \operatorname{Li}_2(1 + z)\right]
$$ and from here I am stuck. It is close to what I want but I can not find
any way to transform the right hand side. Attempt 2 From chat the suggestion was to instead look at the integral definition, this gives \begin{align*}
\operatorname{Li}_2(z) + \operatorname{Li}_2\left( \frac{1}{z}\right) 
   & = - \int_0^z \frac{\log(1-t)}{t}\,\mathrm{d}t 
       - \int_0^{1/z} \frac{\log(1-t)}{t}\,\mathrm{d}t \\
   &  =  - \int\limits_0^1 {\frac{{\log \left( {z - t} \right) + \log \left( {1 - zt} \right) - \log z}}{t}dt} \\ 
     & = -\zeta(2) + \int_0^1 \frac{\log z - \log(1-zt)}{t}\,\mathrm{d}t
\end{align*} The last step used that $$
\int_0^1 \frac{\log(1-t)}{t}\,\mathrm{d}t 
= \int_0^1 -\frac{1}{t} \sum_{n=1}^\infty \frac{t^n}{n} \,\mathrm{d}t
= \sum_{n=1}^\infty \frac{1}{n^2} 
= \zeta(2)
$$ And this is where I stopped.
I think this argument can be finished by series expansion, but I got lost in the algebra.
If possible I would very much like to prove this identity from Abel's Identity and the three equations stated above. Any hint or solutions is much appreciated as always =)
[1]: http://en.wikipedia.org/wiki/Spence%27s_function","['special-functions', 'integration', 'real-analysis']"
459758,A field of order $32$,"I was working on this problem from an old qual exam and here is the 
question. In particular this is not for homework. True or False: There are no fields of order 32. Justify your answer. Attempt : From general theory I know that any finite field has prime power order
and conversely given any prime power there exists a finite field of that order. So of course such fields exist. But now I need to explicitly construct such a field.
If I could somehow construct $\mathbb{Z}_2[x]/(p(x))$ where $p(x)$ is a polynomial of degree 5 which is irreducible over $Z_2$ I am done. But wait, how do I come up with a degree 5 polynomial that is irreducible over $Z_2$. My normal methods don't work here because $p(x)$ does not have order 2 or 3. In which case it is easy to check for irreducibility. My question is in these kinds of situations, is there a general way to proceed. Note: I have not learnt Galois' theory or anything like that. Does this problem require more machinery to solve? Please help.","['finite-fields', 'abstract-algebra', 'field-theory']"
459776,Difference between coordinate space and vector space,"I am new to linear algebra and was going through this link, and it made me wonder: Is there a technical difference between coordinate space (e.g., $R^n$) and vector space? If not, then why are there 2 terms for the same concept?","['vector-spaces', 'linear-algebra']"
459793,"If $H$ and $K$ are supersolvable, normal subgroups of $G$, does it follow that $HK$ is supersolvable?","Let $H$ and $K$ be supersolvable, normal subgroups of some group $G$. Does it follow that $HK$ is supersolvable? This is true if $H \cap K = 1$ since a direct product of two supersolvable groups is supersolvable. However, I think counterexamples for the statement exist when $H \cap K \neq 1$. What is the smallest (finite) example? Any example that is particularly easy to prove?","['group-theory', 'abstract-algebra', 'normal-subgroups']"
459812,On the original Riemann-Roch theorem,"I think Riemann first stated and proved a part of the Rieman-Roch theorem on a compact Riemann surface.
And later Roch supplemented it.
I wonder what the original statements of the R-R theorem by Riemann and Roch were and how they proved them respectively.","['riemann-surfaces', 'algebraic-geometry', 'math-history']"
459815,The structure of the group $(\mathbb{Z}/2^n\mathbb{Z})^*$,"I really got stuck with this exercise, can you help me? This is the total exercise. Calculate $(1+4)^{2^{n-3}}\in (\mathbb{Z}/2^n\mathbb{Z})^*$, and show that the element $5$ has order $2^{n-2}$ for $n \geq 2$. Prove that $5$ and $-1$ generate the group $(\mathbb{Z}/2^n\mathbb{Z})^*$. Prove that $ -1 \notin \langle 5\rangle$ Prove that $(\mathbb{Z}/2^n\mathbb{Z})^* \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2^{n-2}\mathbb{Z}$. (This is an isomorphism of groups.) Here is what I tried to do. 1) The first thing I thought about is the binomial theorem:
$$(1+4)^{2^{n-3}} \quad = \quad \sum_{i=0}^{2^{n-3}}\left( {\begin{array}{*{20}c} {2^{n-3}} \\ i \\ \end{array}} \right) 4^i \quad = \quad \sum_{i=0}^{2^{n-3}}\frac{2^{n-3}!\cdot 4^i}{i!(2^{n-3}-i)!}$$ And that is pretty much how far I came. 
For the next part we should show that $5^{2^n-2}-1 = k\cdot 2^n$ for some integer $k$. What I knew is that $5^{2^n-2}$ is odd, so $5^{2^n-2}-1$ must be even. For more insight, I tried induction: base case . $5^{2^2 -2}-1= 0\cdot 2^n$ Induction step. Assume that $\exists n \in \mathbb{N},\exists k \in \mathbb{Z},5^{2^n-2}-1 = k\cdot 2^n$. Now we want to proof that for some integer $k'$ the identity $5^{2^{n+1}-2}-1 = k'\cdot 2^{n+1}$ holds. So this is what I did.
$5^{2^{n+1}-2}=(5^{2^n-1})^2=(5^{2^n-2}\cdot 5)^2=(5^{2^n-2})^2\cdot 25$. From the induction hypotesis we obtain $5^{2^n-2}=2^n k+1 \quad \text{so that}\quad \ (5^{2^n-2})^2\cdot 25 = (2^n k+1)^2\cdot 25-1 = 25(2^n k +1)^2-1$.
Let's expand this. $25(2^nk+1)^2-1 = 25\cdot 2^{2n}k^2 +25\cdot 2^{n+1}k+24$. This is another point where I got stuck. 2) Well, let's take an arbitrary element $x \in \mathbb{Z}$. Can we find $a,b \in \mathbb{Z}$ such that $(-1)^a\cdot 5^b = 2^n\cdot k$ for some integer $k$? I calculated $|(\mathbb{Z}/2^n\mathbb{Z})^*|=2^{n-1}$ by using Euler's product formula. By this, using the previous bits of the exercise, it's enough to show that $\langle -\bar{1}\rangle \cap \langle \bar{5}\rangle = \{1\}$ Because in that case
$$|\langle -\bar{1},\bar{5}\rangle| =|\langle -\bar{1} \rangle| \cdot |\langle\bar{5}\rangle|=2 \cdot 2^{n-2} = |(\mathbb{Z}/2^n\mathbb{Z})^*|$$ This brings us to the next part. 3) Clearly $ -1 \notin \langle 5\rangle \iff \langle -\bar{1}\rangle \cap \langle \bar{5}\rangle = \{\bar{1}\}$, since $-\bar{1}$ is the only non-trivial element in $\langle \bar{1}\rangle$. I wanted to show the desired claim by contradiction. If $ -1 \in \langle 5\rangle$, then $\langle \bar{5} \rangle = (\mathbb{Z}/2^n\mathbb{Z})^*$ as remarked. Unfortunately, I don't see how this should contradict our premises. 4) When all the previous stuff will be proved, this is not that hard. We define the mapping $\quad \eta \quad : \quad \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2^{n-2}\mathbb{Z} \rightarrow \quad : \quad (\bar{i},\bar{j}) \mapsto (-1)^i\cdot5^j$. The mapping is well-defined because the order of the elements divides the group's order, surjective because of 2, injective because of 3 and an homomorphism because of the commutativity of $""\cdot""$. Hopefully this long story is legible, so that some of you will take the effort to find my mistakes, and give me some hints.","['group-theory', 'abstract-algebra', 'abelian-groups']"
459827,how to define the composition of two dominant rational maps?,"Let's follow Hartshorne's definition, according to which, a rational map $\phi:X \rightarrow Y$ from variety $X$ to variety $Y$ is an equivalence class $\langle U,\phi_U \rangle$, where $U$ is open in $X$ and $\phi_U: U \rightarrow Y$ is a morphism of varieties. If $\phi_U(U)$ is dense in $Y$, $\phi$ is called dominant. Hartshorne says that we can ""clearly compose dominant rational maps"".
So let $\phi: X \rightarrow Y, \psi:Y \rightarrow Z$ be dominant rational maps given by the pairs $\langle U,\phi_U \rangle, \langle V, \psi_V \rangle$. Question: how exactly do we define $\psi \circ \phi$? To be consistent with the definition, we need to construct a pair $\langle W,\sigma_W \rangle$, where $W$ is open in $X$ and $\sigma_W : W \rightarrow Z$ is a morphism of varieties with dense image and somehow this $\sigma_W$ must arise from the ""composition"" of $\phi_U$ and $\psi_V$. But how can we compose these two? Remark: i am aware that there are at least two other questions on this forum related to this topic, however the answers and comments do not clarify the issue i am raising.",['algebraic-geometry']
459841,"If $f$ is Lebesgue measurable on $[0,1]$ then there exists a Borel measurable function $g$ such that $f=g$ a.e.?","If $f:[0,1]\to\mathbb{R}$ is Lebesgue measurable then there exists a Borel measurable function $g:[0,1]\to\mathbb{R}$ such that $f=g$ a.e.?","['measure-theory', 'examples-counterexamples', 'real-analysis', 'analysis']"
459849,Examples of uncountable sets with zero Lebesgue measure,I would like examples of uncountable subsets of $\mathbb{R}$ that have zero Lebesgue measure and are not obtained by the Cantor set. Thanks.,"['descriptive-set-theory', 'examples-counterexamples', 'measure-theory', 'real-analysis', 'analysis']"
459851,Sum of $1/(x+1) +2x/(x+1)(x+2) +3x^2/(x+1)(x+2)(x+3)+\ldots$ till n terms,Sum of $$\frac{1}{(x+1)}+\frac{2x}{(x+1)(x+2)}+\frac{3x^2}{(x+1)(x+2)(x+3)}+\ldots$$ till n terms ... I have no clue how to solve this ... I tried multiplying quantities ... such as $(x+2)-(x+1)$,['sequences-and-series']
459862,Sides of isosceles triangle,I have an isosceles triangle; the vertex angle and the base length are known (I think the base angles can be figured from this). How do I calculate the leg length?,"['geometry', 'triangles']"
459868,Are most polynomials reducible or irreducible?,"Let $k$ be an algebraically closed field and consider the ring $R = k[X_1, \ldots, X_n]$ of polynomials in $n$ variables over $k$. Is the ""general"" polynomial in $R$ reducible or irreducible? The exact meaning of the set of ""general"" polynomials is left to the pleasure of the reader, but two possibilities that come to mind are ""outside a set of measure zero"" (if $k = \mathbb C$ and w/r/t the Lebesgue measure) or ""in the complement of a countable union of Zariski closed sets"". If $n = 1$ then any polynomial factors as a product of linear ones, so ""most"" polynomials are reducible. If $n > 1$ the opposite might be true, because by mumbling ""Bertini theorem"" the general member in a linear system corresponding to an ample divisor might be irreducible; since homogeneous polynomials in many variables are examples of such things (over projective space), there the general (homogeneous) polynomial could be irreducible.","['algebraic-geometry', 'abstract-algebra', 'polynomials']"
459880,"Average of all 6 digit numbers that contain only digits $1,2,3,4,5$","How do I find the average of all $6$ digit numbers which consist of only digits $1,2,3,4$ and $5$? Do I have to list all the possible numbers and then divide the sum by the count? There has to be a more efficient way, right? Thank you!",['algebra-precalculus']
459898,How many circular permutations are there of the multiset,"How many circular permutations are there of the multiset: $$\{3\cdot{a},4\cdot{b},2\cdot{c},1\cdot{d}\}$$","['inclusion-exclusion', 'combinatorics']"
459912,how to find the roots of a cubic equation?,"Given a formula $$x^3+ax^2+bx+c=0$$ how can I get the value of x without having an $i$ in my roots?  Because Cardano's formula does have imaginary numbers if the discriminant is less than zero.
My task is to generalize it and all the cases about the discriminant is applied without having a restriction in imaginary numbers. I have been using Cardano's formula but if the cases are not suitable there is a root with imaginary numbers.","['algebra-precalculus', 'roots']"
459933,A $2$-form on $S^2$ is exact if it integrates to zero.,"I'm trying to show that a $2$-form on $S^2$ is exact if and only if it integrates to zero, without appealing to de Rham's theorem (basically only using the Poincaré lemma [that every closed form on a contractible manifold is exact]). One direction is easy, since $\partial S^2=0$, Stokes's theorem shows that if $\omega=d\psi$ for some $(n-1)$-form $\psi$ on $S^2$, then $\int_{S^2}\omega=\int_{S^2}d\psi=\int_{\emptyset}\psi=0$. I know the usual way to go, to decompose $S^2$ into it's northern and southern hemispheres, each of which is contractible. So if $\int_{S^2}\omega=0$, this gives two $(n-1)$-forms $\psi^+$ and $\psi^-$ on the northern and southern hemispheres, respectively with $d\psi^{\pm}=\omega$ on their domains. Moreover, Stokes's theorem shows again that $0=\int_{S^2}\omega=\int_{\{x_3\ge 0\}}d\psi^++\int_{\{x_3\le 0\}}d\psi^-=\int_{\{x_3=0\}}\iota_{\{x_3=0\}}^*(\psi^+)-\iota_{\{x_3=0\}}^*(\psi^-)$ But now I have no idea how to proceed. Thanks in advance for your help! Also, I realize that this question has been answered before, but keep in mind I'm looking for a solution that does not use de Rham's theorem.","['differential-forms', 'differential-geometry']"
459944,How to check a set of ring is a subring?,"To check a subset of a given ring is a subring,
is it enough to check that the subset is closed under induced operations(multiplication and addition) or
do I also need to show that it contains 0 and additive inverses of each element?",['abstract-algebra']
459947,Birational between affine and projective,I'm asked to prove that $\mathbb{A}^n$ is birational to $\mathbb{P}^n$. I know I'm suppose to find a rational function whose inverse is also a rational function. But I have no idea where to start. Maybe it's because I'm having trouble believing this is result is even true. This is because I know that $\mathbb{A}^n$ is birational to $\mathbb{P}^{n}$ with one of the coordinates fixed as $1$.,"['algebraic-geometry', 'projective-geometry']"
459953,Find the smallest $n$ such that the digits in $2^n$ have every digit from $1$ to $9$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Find the smallest $n$ such that the digits in $2^n$ have every digit from $1$ to $9$. Like, the smallest power of $2$ that it has every digits from $1$ to $9$, excluding $0$. Is there a way to do this without ""brute force""?",['number-theory']
459959,integrate $\int{\sin(x)\cos(2x)dx}$,I can't find a way to do u-substitution for the following integral: $$\int{\sin(x)\cos(2x)dx}$$ Is it possible to evaluate this integral? What method(s) should I use?,"['calculus', 'integration']"
459973,Generalized Alternating harmonic sum $\sum_{n\geq 1}\frac{\left(1-\frac{1}{2}+\frac{1}{3}-\cdots \pm \frac{1}{n}\right)}{n^p}$,"Is there a general formula for the following $$\sum_{n\geq 1}\frac{\left(1-\frac{1}{2}+\frac{1}{3}-\cdots \pm \frac{1}{n}\right)}{n^p}\,\, p\geq 1$$ What about some restrictions on $p$ , like integers or anything helpful ?",['sequences-and-series']
459991,What does it mean when an integral cannot be solved in terms of elementary functions?,"My calculus teacher told our class that in integral calculus, they teach you how to integrate all kinds of functions by various methods, but in the end tell you that there are infinitely many integrals that we do not know how to integrate (represent in terms of elementary functions). So, does that mean: that there exists elementary functions that are unknown in mathematics that can represent the integral, that the integral can be represented in non-elementary functions (I do not know what those would be...), or it is absolutely impossible to represent the integral in another way, other than another integral?","['calculus', 'integration', 'elementary-functions']"
459997,Is there any function that never gives an answer other than 0/0 when applying L'Hôpital's rule?,"Someone asked this question in my calculus class and the teacher said that he would get back to the student on that one. I never heard back, so was hoping someone here knew the answer? EDIT Sorry guys, I think I worded the question wrong, so I attempted to rewrite it...","['calculus', 'derivatives']"
460011,Showing the 3D Ricci flow ODE preserves the order of the curvature tensor eigenvalues,"The following system of ODEs arises when studying Ricci flow on 3-manifolds:
$$
\frac{dm_1}{dt} = m_1^2+m_2m_3 \\
\frac{dm_2}{dt} = m_2^2+m_1m_3 \\
\frac{dm_3}{dt} = m_3^2+m_1m_2 \\
$$ Going back over Hamilton's 1986 paper I realised I didn't understand the first step of his reasoning: Note that $$\frac{d}{dt}(m_2 - m_1) = (m_2-m_1)(m_2+m_1-m_3)$$ so that if $m_1 \le m_2$ to start it remains so. The only extra context required is that $m_2 \le m_3$ at the initial time. How can we make this conclusion? It's not as simple as $m_2 - m_1$ being non-decreasing; choosing a large value for $m_3$ makes this clear. I initially thought to rewrite as
$$\frac{d}{dt}\log(m_2-m_1) = m_2 + m_1 - m_3$$
but at this stage of the analysis I see no reason why $\int (m_2 + m_1 - m_3) dt$ should not fly off to $-\infty$; indeed we have blowup in finite time for the ""similar"" equation $\frac{df}{dt}=f^2$. I have a feeling that I'm missing something very easy and will shortly be quite embarrassed, but it's been niggling at me.","['ricci-flow', 'ordinary-differential-equations', 'riemannian-geometry']"
460014,Prove that any homeomorphism $f:X\to Y$ establishes a bijection between the components of $X$ to the components of $Y$.,"I'm reading Intro to Topology by Mendelson. The section I'm in is titled ""Components and Local Connectedness"". The entire problem statement is, Let $X$ and $Y$ be homeomorphic topological spaces. Prove that any homeomorphism $f:X\to Y$ establishes a bijection between the components of $X$ to the components of $Y$. My attempt of the proof is, We have that the components of $X$ partition $X$ such that $$X=\bigcup\limits_{\alpha\in I} C_\alpha$$ where for any $\alpha,\beta\in I$, $C_\alpha\cap C_\beta=\varnothing.$ Since $X$ is homeomorphic to $Y$, $$f(X)=Y=f\left(\bigcup\limits_{\alpha\in I} C_\alpha\right)=\bigcup\limits_{\alpha\in I} f(C_\alpha).$$ Since for each $\alpha\in I$, $C_\alpha$ is connected, $f(C_\alpha)$ is connected. Also, for any $\alpha,\beta\in I$, $f(C_\alpha\cap C_\beta)=f(C_\alpha)\cap f(C_\beta)=\varnothing$, since $f$ is a homeomorphism. Thus, $Y$ is partitioned by the images of the components of $X$, where each $f(C_\alpha)$ is a component of $Y$. Therefore, a bijection exists between the components of $X$ and the components of $Y$, since a bijection exists between $C_\alpha$ and $f(C_\alpha)$. Is my general approach correct or should I try to come up with an actual function between the components? Does the end of my proof make sense? Thanks for any help or feedback!","['general-topology', 'connectedness', 'proof-verification']"
460021,Can a vector field always be written as a cross-product of two other vector fields?,"As the title suggests, can any arbitrary conservative vector field, $\bf{F}$ $= \langle P,Q,R \rangle$, where the component functions are functions of $(x,y,z)$, always be written as a cross-product of two other vector fields, namely $\bf{A} \times \bf{B}$? Going further, let $\bf{A}$ $= \nabla a$, where $a = a(x,y,z)$ and has continuous first partial derivatives. Also, let $\bf{B}$ $=\langle b_1,b_2,b_3\rangle$ where the component functions are functions of $(x,y,z)$. What I have so far is the following: $\cases{
P=\frac{\partial a}{\partial y}b_3-\frac{\partial a}{\partial z}b_2\\
\\
Q=\frac{\partial a}{\partial z}b_1-\frac{\partial a}{\partial x}b_3\\
\\
R=\frac{\partial a}{\partial x}b_2-\frac{\partial a}{\partial y}b_1
}$ The reason I am asking is that I recently solved the following question: Let $f$ be a smooth function defined on $\mathbb{R}^3$. Let $S$ be the level surface, $\{(x,y,z):f(x,y,z)=c\}$ for some $c \in \mathbb{R}$. Assume $\nabla f$ is never the zero vector on $S$ and let $\bf{F}$ $=\nabla f$. Show that the surface integral over $S$ of $\bf{F} \times \bf{G}$ is $0$ for any $\bf{G}$. ($\star$) And I thought I could use this property if I can take a complicated surface integral and attempt to break it down to this case to easily see answers that are zero. So I suppose I am asking for the conditions that arbitrary vector fields need to satisfy to use the result of the property in the above problem. Thanks! $\bf{EDIT}$ Summary of questions: Q1. Can a vector field always be written as a cross-product of two other vector fields? $\bf{Answered.}$ Q2. Given that $\bf{F}$ $=\nabla f$ can be written as a cross-product of two vector fields, what other conditions are necessary to use the result of $(\star)$?    $\bf{Answered.}$",['multivariable-calculus']
460057,Factorization of a linear combination of matrices,I'm trying to understand the determinant from Axler Sheldon's paper and there is one point in the very beginning that I don't understand :S (Link below to the paper) http://www.cs.berkeley.edu/~wkahan/MathH110/DownDets.pdf I have attached a picture of the point I don't understand: I have higlighted the area I don't understand with a red rectangle. Could someone clarify why can we do the factorization and the last remark (about the injectivity) made by the author? Thank you for any help :),"['matrices', 'linear-algebra', 'factoring', 'determinant']"
460058,Why must a function have to have even and odd parts,"For a function $f(x)$, it was given here with derivation that it has $E(x)$ as even part and $O(x)$ as odd part, $$f(x)=E(x)+O(x)$$ why does this have to be always true? What is the proof?",['functions']
460068,A Hausdorff $ k$-space is minimal $ KC$ if and only if it is compact.,"Atopological space is called $k$ - space if it has the property that any subset $S$ such that $ S \cap K $ is closed for all closed compact $ K $ is itself closed. The bellow theorem comes from "" THE FDS-PROPERTY AND SPACES IN WHICH COMPACT SETS ARE
  CLOSED."" I have some problem with this theorem. * Theorem: *A Hausdorff $k$-space is minimal $ KC$ if and only if it is compact. Proof: The sufficiency is clear. For the necessity, let $(X, τ)$ be a non-compact space which
  satisfies the hypothesis of the theorem. Define a new topology σ on X as follows:
  $σ = \{U ∈ τ : a \not\in U \} ∪ \{U ∈ τ : a ∈ U , \quad   \text{X - U is   compact} \}$.
  Clearly (X, σ) is a compact and σ ⊂ τ. we claim that
  $(X, σ)$ is a $KC$-space.To this end, suppose that $ S ⊆ X$ is a compact subset
  of $(X, σ)$. It is clear that $cl_{σ}(S) ⊆ cl_{τ} (S) ∪ \{a\}$ . There
  are then two possibilities: If $S$ is a compact subset of $(X, σ)$ and (a) if $a \not\in S$, then then by the preceding remarks, S is compact, and hence closed, in $(X, τ)$
  and so $X - S $ is an open $σ$-neighbourhood of a. Thus $a \not\in cl_{σ}(S)$ and so $cl_{σ}(S) = cl_{τ} (S) = S$. then $cl_{σ}(S) = cl_{τ}
(S) $. (b) : If on the other hand, $a ∈ S$, then $cl_{σ}(S) = cl_{τ}
(S)$ and so if $S$
  is not closed in $(X, σ)$, then it is not closed in $ (X, τ)$ either. Since $(X, τ)$ is a $k$-space,
  there is some compact set $C$ in $ (X, τ) $ such that $ C ∩ S $ is not closed in $ C$. Furthermore,
  if the chosen compact set $ C $ has the property that $a ∈ C$, then since $(X, τ)$ is Hausdorff,
  given $x ∈ cl_{τ} (C ∩ S) - (C ∩ S)$, we can find disjoint open neighbourhoods $ U, V $ of $x$ and $a$
  respectively. Then $ C - V$ is a compact subset of $(X, τ)$ with the property that 
  $S ∩ (C - V ) $ is not closed in $ C - V $. Hence we have shown that it is
  possible to choose$ C$ so that  $a \not\in C $. Then  $cl_{τ} (C ∩ S) ⊆ C $ is a closed, hence compact subset of $ (X, τ) $ which does not contain $ a$
  and hence is also closed in $ (X, σ)$ . Thus $T = S ∩ cl_{τ} (C ∩ S)$ is a $σ$-closed subset of $S$ and
  hence is compact in $(X, σ)$. However, since $a \not\in T$ , it follows that $T_{τ} = T_{σ}$ and hence $T$ is
  compact in $(X, τ)$, a contradiction, since $x ∈ cl_{τ} (T ) - T$ . But: can you explain that : why he said that "" (1) :$ C - V$ is a compact subset of $(X, τ)$ with the property that $S ∩ (C - V )
$ is not closed in $ C - V $ . Hence we have shown that it is possible to choose $ C$ so that  $a \not\in C $. (2) : why $cl_{τ} (C ∩ S) ⊆ C $ is a closed? (3) :$(X, τ)$ is $ T_{1}$, is it right to say that  $(X, σ)$ is $ T_{1}$? Thanks.",['general-topology']
460071,Why is there this contradiction or what is wrong,"In the second paragraph on Page 30 of this published paper , it says that the intersection of the convex
hull of points $(\alpha_{1}+\beta_{P_{1}},\alpha_{2}+\beta_{P_{2}})$
with the convex hull of points $(\beta_{1}+\alpha_{P_{1}},\beta_{2}+\alpha_{P_{2}})$
contains the point $(\gamma_{1},\gamma_{2})$. For example, if
$\alpha_{1}=2$, $\alpha_{2}=0$, $\beta_{1}=3$, and $\beta_{2}=2$,
then the intersection is a line segment between $(3,4)$ and $(4,3)$
. But don't the eigenvalues of the the sum matrix actually lie on
the line segment between $(1,5)$and $(3,4)$? or what is wrong?","['matrices', 'geometry', 'linear-algebra', 'analysis']"
460072,"$a_n$ given, then evaluate $\lim_{n\to \infty}a_n$.","If  $$a_n=\sqrt{4+\sqrt{4+3\sqrt{4+5\sqrt{4+7\sqrt{\cdots\sqrt{4+(2n-1)\sqrt{4+(2n+1)}}}}}}}$$for any natural number $n$,
then evaluate $\lim_{n\to \infty}a_n$. Note that $a_1=\sqrt{4+\sqrt{4+3}}$ and $a_2=\sqrt{4+\sqrt{4+3\sqrt{4+5}}}$. I don't have any good idea. I need your help.","['sequences-and-series', 'limits']"
460074,An open subset of an irreducible set is dense.,"I'm trying to understand this example in Hartshorne's algebraic geometry book In order to prove the irreducible part, suppose $Y$ is an irreducible space and $Y'$ a open subset of $Y$ with $Y'=Y'_1\cup Y'_2$ with $Y'_1,Y'_2$ proper closed subsets. Then $Y=(Y-Y')\cup (Y'_1\cup Y'_2)$ contradiction because $Y$ is irreducible. Am I right? I need help also in the density part, I'm really stuck I don't know even how to begin. Thanks a lot.",['algebraic-geometry']
460084,Convergence in measure is not given by a seminorm,"Let $V$ be the vector space of all real-valued Borel measurable functions on $[0,1]$. Show that convergence in measure (with respect to Lebesgue measure) is not given by a seminorm. That is, show that there no seminorm $\|\cdot\|$ on $V$ such that elements $f,f_1,f_2,\dots$ of $V$ satisfy $\lim_n \|f_n-f\| = 0$ iff $(f_n)$ converges to $f$ in measure. (Hint: show that if such a seminorm exists, then for each positive $\epsilon$ there are functions $g_1, \dots, g_n \in V$ such that $\|g_i\| \leq \epsilon$ for each $i$ and such that $1/n \sum _{i= 1} ^n g_i $ is equal to the constant function 1.) I have problem both showing the existence and then the contradiction.
I'm grateful for hints or solutions.","['measure-theory', 'convergence-divergence']"
460086,Two variable limits via paths - are there pathalogical examples?,"In the first year calculus course at my university, we do not introduce the $\varepsilon$-$\delta$ definition of a limit. When considering the limit of a function of two variables, we resort to paths. That is, for the real-valued function $f$, defined in a deleted open neighbourhood of ${\bf a} \in \mathbb{R}^2$, we write $\displaystyle\lim_{{\bf x} \to {\bf a}}f({\bf x}) = L$ if the limit along every path to ${\bf a}$ is $L$. Though we don't go into this detail, what is meant by the limit along a path is to pick a parameterisation $\gamma : (r, s) \to \mathbb{R}^2$ with $\displaystyle\lim_{t \to s^-}\gamma(t) = {\bf a}$, and then check that $\displaystyle\lim_{t \to s^-}f(\gamma(t)) = L$. Of course, without the $\varepsilon$-$\delta$ definition, this one-dimensional limit can only be deduced from limit laws and given fundamental limits. Without loss of generality, suppose ${\bf a = 0}$. When asked to determine whether or not the limit $\displaystyle\lim_{{\bf x} \to {\bf 0}}f({\bf x})$ exists, there are only a couple of things the students can do: employ continuity if possible (limit laws may be needed), use polar coordinates together with the squeeze theorem, find a path along which the limit does not exist, and find two paths with have different limits. The first two options can be used to show the limit exists, while the last two options can be used to show the limit does not exist. An efficient way to test limits along different paths is to try a whole family of paths simulateously, i.e. we could consider the family of quadratic paths given by $\gamma(t) = (t, kt^2)$ where $k \in \mathbb{R}$. If the limit $\displaystyle\lim_{t \to 0-}f(\gamma(t))$ exists and is independent of $k$, then along all of these paths, the limit is the same. This does not prove that $\displaystyle\lim_{{\bf x} \to {\bf 0}}f({\bf x})$ exists as there are still plenty of paths that have yet to be considered. Questions: Is there a reference which takes this approach to limits in higher dimensions (i.e. greater than one) in a rigorous way without using the $\varepsilon$-$\delta$ definition? I wouldn't be surprised if the answer is no. However, I am somewhat more interested in the following question: How pathological can two-dimensional limits be? That is, along how many paths can the function have the same limit whilst still failing to have the overall limit existing? Is it possible to have all but one? I imagine there would be some sort of density argument that would prevent this.","['calculus', 'examples-counterexamples', 'reference-request', 'real-analysis', 'limits']"
460098,Pushforward/image outer measure,"Let $X$ and $Y$ be two sets, $f:X\to Y$ and $\mu$ be an outer measure on $2^X$. Is that true that the image of $\mu$ under $f$ defined by
$$
  \nu(B):= \mu(f^{-1}(B))
$$
is an outer measure on $Y$? If I am not mistaken, the answer is yes as $f^{-1}$ preserves empty sets, set inclusions and commutes with the unions. At the same time, I have never seen such construction in use, so I would be happy if anybody knows any reference on a topic.",['measure-theory']
460111,Find $f(x)$ from $2f'(x)-3f'(1/x)=x$,"Find $f(x)$ given that $2f'(x)-3f'(1/x)=x$ Also, is it possible to do this without integration?","['ordinary-differential-equations', 'calculus', 'functional-equations']"
460115,Weighted Probability Problem,"Lets say, few independent events are happening. $E_1, E_2,...,E_n$. The probability of each of these events happening is given as $P_1,P_2,...,P_n$. Each of these events carry weightage, say $W_1,W_2,...,W_n$ respectively. I tried building a tree like the one shown here http://www.mathsisfun.com/data/probability-tree-diagrams.html . But its highly inefficient, for even small value of n, eg: $200$, the number of leaf nodes will be $2^{200}$. Now, how can I find the probability of getting at least weight $W$? Example: Probabilities = [0.2, 0.8]
Weights       = [3, 5] It means that, for the first event, there are 20% chances for that to happen. If it happens, the weightage will become 3, 0 otherwise. In the second case, there are 80% chances for that to happen. If it happens, the weightage will become 5, 0 otherwise. Now if I want to find the probability of getting atleast Weight 4 would be like this 0.2 * 0.8 = 0.16 -> Total weight 8 (1)
0.8 * 0.8 = 0.64 -> Total weight 5 (2)
0.2 * 0.2 = 0.04 -> Total weight 3 (3)
0.8 * 0.2 = 0.16 -> Total weight 0 (4) So, the total probability of getting atleast 4 weight is 0.16 (From (1)) + 0.64 (From (2)) = 0.80 EDIT2: The sum of all the probabilities $P_i$ need not be 1 always","['probability-theory', 'probability']"
460155,Terminology for $\phi(xy)=\phi(x)\phi(y)$,"I have a model which contains a function $\phi:{\mathbb R}_+ \rightarrow {\mathbb R}_+$ that satifies: $$\tag{*}\phi(xy)=\phi(x)\phi(y)$$ for all $x,y\in{\mathbb R}_+$. In Number Theory there is a property termed completely multiplicative ( see ), but this is only defined for functions of integers. Although there is a certain overlap of property $(*)$ with this definition, property $(*)$ applies to the whole space ${\mathbb R}_+$. Can I say that $\phi(\cdot)$ is completely multiplicative or is there a more appropriate notation for this sort of functions? Update: Another related property is additivity . $\phi(\cdot)$ can be seen as a log-additive function. This is, $\log\phi(xy)= \log\phi(x)+\log\phi(y)$.","['terminology', 'functions', 'number-theory']"
460165,Does convergence in probability not imply convergence in distribution for Least Squares estimators?,"I have a question relating to convergence in probability and distribution for least squares estimators. Frequently, I see in textbooks that $\hat{\beta} \rightarrow^p b$. Where $b$ is the population parameter, and $\hat{\beta}$ is the Least Squares estimator of that parameter; demonstrating that LS estimators are consistent. I also often see that, $\hat{\beta} \rightarrow^d N(b,\frac{1}{N}(X'X)^{-1})$, showing that $\hat{\beta}$ tends in distribution to a Normal centered around $b$. I just wanted to check that my thinking here is correct. Convergence in probability always implies convergence in distribution as far as I understand it. Hence convergence in probability of LS estimators to a constant $b$ should imply convergence in distribution to the same constant $b$. Hence we should have that $\hat{\beta} \rightarrow^d b$. Is this satisfied above with $N(b,\frac{1}{N}(X'X)^{-1})$ since the variance tends to zero (since $N\rightarrow \infty$), meaning the distribution is itself that of a constant? Or is there some other reason that means that LS estimators converge in distribution to a constant? Many thanks, Ben","['statistics', 'convergence-divergence', 'statistical-inference', 'parameter-estimation']"
460166,Does there exist a non-empty set that is a subset of its power set?,"While working through Velleman, I proved that if $A \subseteq P(A)$, then $P(A) \subseteq P(P(A))$. One example where this may be the case is when $A = \emptyset$. Another may be when $\emptyset \in A$. I cannot think of any other example though. Supposing that $x$ and $y$ are two arbitrary elements of $A$, then $P(A)$ will always enclose those elements in a new set, thus $x,y \notin P(A) $ Thus my question is: Is there an example of a set, $A$, where $A \subseteq P(A)$ wand $A$ is non-empty and does not contain the empty set.",['elementary-set-theory']
460191,$ \frac {dy}{dx} \sin y = (1-x\cos y)\cos y$,"How may we solve the following differential equation, $$ \frac {dy}{dx} \sin y = (1-x\cos y)\cos y$$ ? (my progress concerning it is almost zero)",['ordinary-differential-equations']
460199,Self Study of Fractals,"I am looking for a book to self-study fractals with a certain criteria. I have checked out Getting Aquainted with Fractals . Note that Getting Aquainted with Fractals does not include exercises/problems. I would like to find a book that has exercises/problems, geometrical interpretations and more explanations (I do not like textbooks that are full of fluff, but I also do not think I am ready to fill in every blank either). To clarify about the last criteria, I do like books that are in the definition, theorem, proof format, however I would like a book that presents easier to read proofs that contain more detail. Also, I would like some discussions that prelude definitions which give their motivation and possibly give rise to geometric intuition. I would also like a supplementary text covering the material in Mathematical Analysis as a lot of vocabulary, concepts and ideas come from analysis. I know the basic concepts and properties: Self-Similarity, Recursively defined, and the Box Counting Dimension. I know about the classic fractals: Koch Curve, Sierpinski triangle and their variations. However, I do not know anything about fractals defined in the complex plane such as Mandelbrot set and Julia set. I also do not know much about the link between fractal geometry and chaotic theory. Thanks for all the help!","['self-learning', 'reference-request', 'fractals', 'analysis']"
460237,"X projective variety, connected, constant morphism (counterexample?)","Let $X$ be a projective $k$-variety and $Y$ a quasi-affine $k$-variety. Assume
that $X$ is connected. Show that every morphism of $k$-varieties $X \to Y$ is constant, i.e., its image consists of a single point. I was able to prove this exercice in my course notes (very introductory AG). A natural question, I next asked myself, was: what is the relevance of the condition that $X$ is projective? What if we remove this condition or change it, where would things go wrong? I have not yet acquired an intuitive and flexible to understand what's ""really"" going on in AG. Can somebody, maybe, provide a counterexample and/or explain intuitvely why the condition that $X$ is projective is necessary.","['algebraic-geometry', 'abstract-algebra']"
460250,Mathematical notation for redefined set?,"I have a set of numbers (W), from which I am only keeping those greater than 5. I want to state that the set W has been redefined to only include the subset of values greater than 5, but want to avoid giving the new set a new name, because I already have too many variables, and I want readers to associate W with the new set. Is there a way of referring to the redefined set W? I've been using W ' in my notes, but this could be misleading to others ... W={1,3,5,2,7,9,10,18} W '={7,9,10,18} Apologies if this is a naive question - it has been a while since I had to write my code in proper notation!","['notation', 'elementary-set-theory']"
460261,Simplifying second derivative using trigonometric identities,"Given that $x=1+\sin(t)$ , $y=\sin(t) -\frac{1}{2} \cos(2t)$ show that $\frac{\text{d}^2y}{\text{d}x^2}=2$. I am having trouble proving this. Here is my working so far: \begin{align}\frac{dx}{dt}&= cos(t)\\
\frac{dy}{dt}&= cos(t) + sin(2t)\end{align} \begin{align}\frac{dy}{dx}&=\frac{\cos(t) + sin(2t)}{cos(t)}\\
\frac{d^2y}{dx^2}&=\frac{2cos(2t)cos(t) - sin(2t)sin(t)}{cos^2(t)}\frac{1}{cos(t)}
\end{align} I think its just a matter of simplifying my expression for $\frac{\text{d}^2y}{\text{d}x^2}$ using trigonometric identities but I can't see the right ones to use.","['trigonometry', 'derivatives']"
460281,Reasoning that $ \sin2x=2 \sin x \cos x$,"In mathcounts teacher told us to use the formula $ \sin2x=2 \sin x \cos x$.
What's the math behind this formula that made it true?  Can someone explain?","['trigonometry', 'algebra-precalculus', 'proof-explanation']"
460289,To prove the limit of given function does not exist.,"Ques: I want to show that a limit of a function $$f(x,y)=\frac{x^{3}+y^{3}}{x-y}$$ does not exist at point $(0,0)$. My try: I am just taking path $y=x-x^{3}$ then $$\lim _{(x,y)\rightarrow(0,0)}\frac{x^{3}+y^{3}}{x-y}=\lim_{x\rightarrow 0}\frac{x^{3}+(x-x^{3})^{3}}{x^{3}}=2$$
Then i am taking path $y=2(x-x^{3})$ and i got limit $0$. So, in the both case the limit does not remain same. it means limit of given function does not exist. Am i right? please give your valuable suggestions!","['functions', 'calculus', 'real-analysis', 'limits']"
460307,Evaluate the integral $\int_{0}^{+\infty}\frac{\arctan \pi x-\arctan x}{x}dx$,Compute improper integral : $\displaystyle I=\int\limits_{0}^{+\infty}\dfrac{\arctan \pi x-\arctan x}{x}dx$.,"['improper-integrals', 'integration']"
460329,$a: E\times F\to G$ bilinear separately continuous implies continuous?,"Let $E$, $F$ and $G$ be Banach spaces and let $a$: $E \times F \to G$ be a bilinear map which is separately continuous, that is
$$\forall x \in E \textrm{ the map } y \mapsto a(x,y) \textrm{ is continuous}$$
and
$$\forall y \in F \textrm{ the map } x \mapsto a(x,y) \textrm{ is continuous}$$ Show that $a$ is bounded, i.e., there exists a constant $M\geq 0$ such that
$$\|a(x,y)\|_G \leq M \|x\|_E \|y\|_F,\quad\forall(x,y)\in E \times F.$$",['functional-analysis']
460331,Simplify $\left({\sum_{k=1}^{2499}\sqrt{10+{\sqrt{50+\sqrt{k}}}}}\right)\left({\sum_{k=1}^{2499}\sqrt{10-{\sqrt{50+\sqrt{k}}}}}\right)^{-1}$,Simplify $$\frac{\displaystyle\sum_{k=1}^{2499}\sqrt{10+{\sqrt{50+\sqrt{k}}}}}{\displaystyle\sum_{k=1}^{2499}\sqrt{10-{\sqrt{50+\sqrt{k}}}}}$$ I don't have any good idea. I need your help.,"['radicals', 'fractions', 'summation', 'sequences-and-series']"
460333,Finding Weak Solutions to ODEs,"I'm wondering if anyone has a reference to a good set of notes on finding weak (distributional) solutions to ODEs, or has any tips or tricks.  For example, $$
xy^\prime=0
$$ has a classical solution $y(x)=C$, but it also has a distributional solution $y(x)=H(x)$, the Heaviside step function, since (symbolically) $H^\prime(x)=\delta(x)$ and so $xH^\prime=x\delta(x)=0$.  We can prove that this is a weak solution by acting on test functions, i.e. show that $\langle xH^\prime,\varphi\rangle=0$ for all suitable $\varphi$. For the above ODE, it was fairly simple to guess that $H(x)$ is a solution.  The set of lecture notes I have only goes this far - they ""guess"" the solution then prove it works.   My question is: how do we go about finding weak solutions for a general homogeneous ODE of the form $Ly=0$?  Is ""guess and check"" the best we can do?  Am I guaranteed a certain number of weak solutions (i.e. for a second order equation, there are 2 weak solutions and 2 strong solutions...?) Thanks!","['ordinary-differential-equations', 'weak-derivatives', 'reference-request']"
460334,Dedekind's cut and axioms,"What is the importance of 3rd axiom of dedekind's cut? a Dedekind cut is a partition of a totally ordered set into two non-empty parts (A and B), such that A is closed downwards (meaning that for all a in A, x ≤ a implies that x is in A as well) and B is closed upwards, and A contains no greatest element.(From Wikipedia) what is importance of statement ""A contains no greatest element""??
Please explain in intuitive way. Also my reasoning is that if you don't know what is greatest number in A how can you calculate Least Upper Bound for A which is required for completeness of R.","['calculus', 'real-analysis']"
460343,"Finding best player,second best and third using least games possible.","Note:assume if arm wrestler a beasts b and b beats c then a beats c. Suppose you have an arm wrestling championship and 32 arm-wrestlers. What is the minimum matches you need to organizeto find the best second best and third best arm-wrestlers. The answer is supposed to be 39 but I can only manage to get it down to 42. This is how I did it: Make a round robin to find champ(31 uses)
the second place was beaten by champ, so find the best out of the 5 players champ beat (4 uses) the champ was beaten by second or third.(second beat at most 4 other people) find best of the people the champ defeated except the second(3). Find the best the second defeated(3). Put the best of those to find third place (1)",['combinatorics']
460345,Calculate the integer part,"I have to calculate the  integer part of this: $$[(\sqrt{2}+\sqrt{5})^2]$$
 I tried to write it like this: $$[2+5+2\sqrt{10}]=[7+2\sqrt{10}]=7+[2\sqrt{10}]$$ Any ideas?",['algebra-precalculus']
460354,Nth roots of square matrices,Is there a general method (which can be implemented by hand) to finding the $n$-th roots of $2 \times 2$ matrices? Is there a similar method for a general $m \times m$ matrix? (for $n > 1$ and $n\in\mathbb{Z}$),"['matrices', 'linear-algebra']"
460363,$P(X \ge 450)$ in Possion distribution,"The number of pedestrians that cross the street in one minute has Poisson distribution $\def\Pois{\operatorname{Pois}}\Pois(8)$. Find the probability that at least $450$ pedestrians will cross the street in $1$ hour. The number of pedestrians that cross the street in one hour has $\Pois(480)$ distribution. So, $$\begin{align}
P(X \ge 450) & = 1 - P(X < 450) \\
& = 1 - \sum_{i = 0}^{449}\frac{450^i}{i!}e^{-450} \\
& = 1 - e^{-450}\sum_{i = 0}^{449}\frac{450^i}{i!},\end{align}$$ and I am stuck here.","['probability-distributions', 'probability']"
460376,Is maximizing the Shannon differential entropy equivalent to minimizing the predictability and/or minimizing the maximum density?,"For a real-valued, 1-dimensional, continuous random variable $X$ with density $f(x)$ , I am trying to determine if maximizing the Shannon differential entropy of $f(x)$ is mathematically equivalent to finding the $f(x)$ with the least predictive density (as defined below) for a given set of constraints: Least predictive density: The density that minimizes the maximum probabiliy associated with each value of the Lebesgue measure on the domain of $f(x).$ For example, let $X$ be an RV with domain ( $-\infty $ , $+\infty $ ) and specified mean $M$ and variance $V$ and $I$ be a set of intervals on the real line with total Lebesgue measure $\mathcal{L}$ (i.e., sum of the measure of each interval in the set. The actual intervals not specified, only their total Lebesgue measure is given). The least predictive distribution would minimize the maximum probability that can be contained in I , for each value of L , while also having mean M and variance V. I don't know if this problem can be formulated generally as a functional so that calculus of variations can be applied. At this point, I have formulated it as a functional for the specific case of a fixed interval for unimodal symmetric unbounded densities, but generalizing this has been problematic. Related to the above, this problem appears to boil down to minimizing the maximum value of the density subject to any constraints (such as specified mean and variance). Given the above ""preamble"", the two issues I am hoping to get guidance on are: 1) Is maximum Shannon entropy equivalent to minimal predictability (as defined above for a particular set of constraints)? 2) Is minimal predictability equivalent to minimizing the maximum density (subject to a set of constraints)? I hope I have specified this precisely enough and given enough background on my current thinking and work on this. Any pointers, references, or research results related to the above would be much appreciated. Thanks :)","['probability-theory', 'information-theory', 'entropy']"
460377,Is exponential function analytic over all complex numbers,"In my textbook, I find a text where it says $e^z$ is analytic everywhere (in complex plane). Is it true? If so, what is the proof? I approached using maclaurin series, which gives $e^z= \sum_{n=0}^{\infty} \frac{z^n}{n!}$. But given the Mac-laurin series, how can we find the points where it is analytic, i.e the points of convegrnece of its Taylor series? I am just a beginner here, so it my seem silly to some. However, any help will be appreciated. Thanks in advance! :D","['convergence-divergence', 'calculus', 'taylor-expansion']"
460388,$1-2+3-4+\dots = \frac{1}{4}$,"Recently I came across this paradoxical equation: $$1-2+3-4+\dots = \frac{1}{4}$$ More rigorously, this infinite sum can be write as $$\sum_{n=1}^{\infty} n(-1)^{n-1}$$ and it is well known to diverge since, for instance $$1=1$$ $$1-2=-1$$ $$1-2+3=2$$ $$1-2+3-4=-2$$ $$1-2+3-4+5=3$$ $$1-2+3-4+5-6=-3$$ Now, the thing I cannot explain to myself is why the sum equals $\frac{1}{4}$, although it doesn't tend towards any limit. Here's because, I think, the equality above is called "" paradoxical "". I (tried to) read the Wikipedia article , but it is full of material I've never encountered in my studies, full of examples and analogies that made me even more confused. The only thing I believe to have understood concerning this equality, written for the first time by Leonhard Euler , is that the latter came to the rusult by reducing the polynomial $$1-2x+3x^2-4x^3+\dots$$ in $$\frac{1}{(1+x)^2}$$ Thus, if we take $x=1$, we obtain the equality above. But how is this reduction done? I'm afraid if I couldn't realise the answers to this question on Wikipedia, but I just need an explanation that would make me understand, even intuitively, the paradoxical nature of the equality and its mathematical derivation by means of even one clear reasoning.",['sequences-and-series']
460392,Clarifying a step in proving uniqueness of Jordan Decomp of signed measures,"This should be real simple but I have been struggling to see this in an easily intuitive manner. Basically, my confusion comes down to showing that if $A,B$ and $A',B'$ are two arbitrary Hahn decompositions and that if $v = v^+ - v^-$ is a signed measure that: $v^+(E\cap A) = v^+(E\cap A')$ where E is an arbitrary set in the $\sigma$-algebra. I keep only being able to think about it by saying $E \cap A = (E \cap A')\cup N$ where $N$ is some null set since Hahn-Decompositions are unique except for null sets. Then I want to say that $v^+(E\cap A) = v^+(E\cap A') + v^+(N)$. But it isn't clear to me why $v^+(N) = 0$ for any null set $N$. ie $N$ would satisfy the criteria of a null set if $v^+(n) = v^-(n) \forall $ measurable $n \subset N$. What am I missing? What is the simplest way to show $v^+(E\cap A) = v^+(E\cap A')$?","['measure-theory', 'analysis']"
460397,Is $\sqrt[3]{2}$ contained in $\mathbb{Q}(\zeta_n)$?,"Is $\sqrt[3]{2}$ contained in $\mathbb{Q}(\zeta_n)$ for some $n$, where $\zeta_n=e^{2\pi i/n}$? I think the answer is no, but I can't give a full proof. Assume the contrary, we then have $\mathbb{Q}(\sqrt[3]{2}) \subset \mathbb{Q}(\zeta_n)$, can I say $\mathbb{Q}(\zeta_n)/ \mathbb{Q}$ is a cyclic extension but $\mathbb{Q}(\sqrt[3]{2}) / \mathbb{Q}$ is not, so this is a contradiction?","['galois-theory', 'abstract-algebra', 'field-theory']"
460430,Computing invariant factors from Smith normal form,"The goal is to find the Jordan Canonical Form of the matrix $$A=\begin{bmatrix}2&1&1&2\\0&2&0&1\\0&0&2&-1\\0&0&0&1\end{bmatrix}$$ Since the matrix is already upper-triangular, it's obvious that the eigenvalues are 2 and 1, where 1 has geometric and algebraic multiplicity 1, so that I could easily find the JCF by computing $\operatorname{rank}{(A-2I)^{i}}$ for each $i$. However, I thought I would instead try to do it by computing the invariant factors by finding the Smith normal form of the characteristic matrix $xI-A$. The problem is that using elementary row and column operations, I only seem able to obtain the matrix $$\begin{bmatrix}1&0&0&0\\0&1&0&0\\0&0&(x-2)^2&0\\0&0&0&(x-1)(x-2)\end{bmatrix}$$ My questions are: Even though this matrix is not in Smith normal form, is it valid to conclude that the elementary divisors are the powers of the irreducible factors that appear in each diagonal entry, i.e. $(x-1)$, $(x-2)^2$, and $(x-2)$? It happens to be true for this $A$, but would it always be true? How do I coax the above matrix into Smith normal form?","['matrices', 'smith-normal-form', 'linear-algebra']"
460445,"Is $\large \frac {\pi}{e}$ rational, irrational, or trandescendal?","Is there an argument for why $\large \frac {\pi}{e}$ is rational, irrational, or trandescendal? Can the quotient of any two transcendental numbers (which are not rational multiples of each other) be rational, or at least irrational? Thanks.","['pi', 'algebra-precalculus', 'transcendental-numbers', 'number-theory']"
460469,Similarity in shapes,"I have been thinking which countries in the world are similar in shape, then I had this problem. For example we have country maps as seen in the figure and we need to determine which country is similar in shape to the country A. Intiutively we can say that the 5.th country is more and less similar, but it is difficult to determine the second most similar country. The sizes of the maps do not matter, we have option to scale. I have been thinking to solve the problem like least squares method but we have to determine the functions of the maps. Is there any branch of mathematics study these things?","['geometry', 'numerical-methods']"
460474,Question regarding Lebesgue Dominated Convergence Theorem,"Below is problem where, in one direction of the proof, I use the Lebesgue Dominated Convergence Theorem. I have, of course, included my attempt at the solution. Any help concerning the ""correctness"" of my attempt would be very helpful. Thank you! $\textbf{Problem:}$ Let $X$ be the set of natural numbers, $\textbf{X}$ be the $\sigma$-algebra consisting of all the subsets of $X$, and let $\mu$ be the counting measure on $\textbf{X}$. Show that $f \in L(X,\textbf{X}, \mu)$ if and only if the series $\sum f(n)$ is absolutely convergent, in which case $$\int f d\mu = \sum f(n).$$
$\textbf{Attempt at Solution:}$
$\Rightarrow$ Assume $f \in L(X,\textbf{X}, \mu)$. We need to show $\sum |f(n)|$ converges. Define a sequence of functions $(\phi_{m})$ by the following equation: $$\phi_{m}=\sum^{m}_{n=1} |f(n)|\chi_{\{n\}}.$$ Note that $(\phi_{m})$ is a monotone increasing sequence of functions which converges to $|f|$, which is integrable by our assumption. Hence, the Monotone Convergence Theorem imples that $$\int |f| d\mu = \lim \int \phi_m d\mu.$$ Using our definition of the integral of a simple function, we see that $$\lim \int \phi_m d\mu = \lim \sum^{m}_{n=1} |f(n)|\mu(\{n\})=\lim \sum^{m}_{n=1} |f(n)|=\sum |f(n)|$$ Indeed, $\sum |f(n)|=\int |f| d\mu$, from which it follows that $\sum f(n)$ is absolutely convergent. (Remember, $|f| \in L(X,\textbf{X}, \mu)$ means its integral is a finite real number.) $\Leftarrow$ Assume $\sum f(n)$ is absolutely convergent; specifically, let $\sum f(n)=k$. Put $g(x)=k$. Then, $g$ is a constant function and integrable. Define a sequence of functions $(\psi_{m})$ by the following equation: $$\psi_m = \sum^{m}_{n=1} f(n)\chi_{\{n\}}$$ This sequence converges to $f$. For each $m$ (and $x \in X)$, $$|\psi_m|\leq \sum^{m}_{n=1} |f(n)\chi_{\{n\}}| \leq  k.$$ Finally, by the Lebesgue Dominated Convergence Theorem, we conclude that $f$ is indeed integrable and $$\int f d\mu = \lim \int \psi_{m} d\mu = \lim \sum^{m}_{n=1} f(n) \mu(\{n\}) = \sum f(n). \blacksquare$$",['measure-theory']
460477,$\frac{1}{N} | \int_1^N e^{2 \pi i b \log x }dx |\rightarrow \frac{1}{ \sqrt{1 + 4\pi ^2 b^2} } $ as $N \rightarrow \infty$,"I want to show that 
$$\frac{1}{N} \left| \int_1^N e^{2 \pi i b \log x }dx \right| \rightarrow \frac{1}{ \sqrt{1 + 4\pi ^2 b^2} } $$
as $N \rightarrow \infty$. This what I have done: First do a substitution $u = \log x$ to obtain
$$ \int_1^N e^{2 \pi i b \log x }dx = \int_0^{ \log N} e^{(1+ 2 \pi i b ) u }du .$$
Then
$$\int_0^{ \log N} e^{(1+ 2 \pi i b ) u }du = \frac{  e^{(1+ 2 \pi i b ) \log N } -1 }{ 1+ 2 \pi i b} = \frac{ N e^{2 \pi i b  \log N } -1 }{ 1+ 2 \pi i b}. $$ So
$$\frac{1}{N} \int_1^N e^{2 \pi i b \log x }dx = \frac{  e^{2 \pi i b  \log N }  }{ 1+ 2 \pi i b}-  \frac{ 1   }{ N(1+ 2 \pi i b)}. $$ The second term goes to zero but I'm not sure how to proceed with the first term. EDIT:
So my question is how does one evaluate the limit
$$ \lim_{N \rightarrow \infty} N^{2 \pi i b } $$","['definite-integrals', 'calculus', 'limits']"
460497,Singular values: smallest perturbation to make a matrix singular,"A problem from Gilbert Strang's Linear text, after the section on the singular value decomposition: Suppose $A$ is $2\times 2$ and  invertible (with $\sigma_1 > \sigma_2 > 0$). Change $A$ by as small a matrix as possible to produce a singular matrix $A_0$. Hint: $U$ and $V$ don't change. Use $$A = \left [ \begin {matrix} u_1 & u_2\end {matrix}\right ] \left [ \begin {matrix} \sigma_1 &  \\ & \sigma_2 \end {matrix}\right ] \left [ \begin {matrix} v_1 & v_2\end {matrix}\right ]^T.$$ I think we can change $A$ by $$\left [ \begin {matrix} u_1 & u_2\end {matrix}\right ] \left [ \begin {matrix} 0 &  \\ & -\sigma_2 \end {matrix}\right ] \left [ \begin {matrix} v_1 & v_2\end {matrix}\right ]^T.$$ But how can we show this is the smallest possible alteration of $A$ to get a singular matrix? I think Strang is expecting a somewhat loose answer here, since he's not yet introduced the matrix norm, so it's not clear what he means by ""as small as possible.""  If we were to attempt it in a more rigorous way, I think we'd like two results: A result relating singular values to addition and subtraction, something like $\sigma_n(A) + \sigma_n(B) \geq \sigma_n(A \pm  B)\geq \sigma_n(A) - \sigma_1(B)$, where $\sigma_1, \dotsc , \sigma_n$ are arranged in descending order. A result relating singular values to matrix norm. I believe the largest singular value is the value of the 2-norm, but how can we relate this to the operator norm?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
460502,"If $\langle Tv,v\rangle\in\mathbb{R}$, prove that $T$ is self-adjoint [duplicate]","This question already has answers here : If $\langle Ta, a\rangle \in \mathbb{R}$ for all $a$ then $T$ is self-adjoint (3 answers) Closed 5 years ago . Let $V$ be a finite-dimensional vector space over $\mathbb{C}$, together with a Hermitian inner product $\langle\cdot\,,\cdot\rangle$. Let $T:V\to V$ be a linear function. Prove that $T$ is self-adjoint if $\langle Tv,v\rangle\in\mathbb{R}$. I know that since $\langle Tv, v\rangle \in\mathbb{R}$, $\langle Tv,v\rangle=\langle v, Tv\rangle $ ... I'm not sure where to go from here.","['linear-algebra', 'inner-products']"
460516,Probability to draw a white ball from the third box.,There are $2$ boxes full of black and white balls. The first one has $a$ white and $b$ black balls ($a\geq2$ && $b\geq2$). The second one has $c$ white and $d$ black balls ($c\geq1$ && $d\geq1$). You draw $2$ balls from the first box and $1$ ball from the second box and put them into a third box. What is the probability to draw a white ball from the third box. I tried to solve it this way: $A_1$ - draw 2 white balls from first box and 1 white from second box and put them in third box. $A_2$ - draw 2 white balls from first box and 1 black from second box and put them in third box. $A_3$ - draw 1 white ball and 1 black ball from first box and 1 white from second box and put them in third box. $A_4$ - draw 1 white ball and 1 black ball from first box and 1 black from second box and put them in third box. $A_5$ - draw 2 black balls from first box and 1 white from second box and put them in third box. $A_6$ - draw 2 black balls from first box and 1 black from second box and put them in third box. $B$ - draw white ball from third box. $$P(B) = \sum_{i = 1}^{6} P(B \mid A_i)P(A_i)$$ I think $P(B\mid A_i)$ are pretty obvious so i won't write them. After long brute force i came up with this answer $$\frac{ac(5(a-1) + 6b + b(b-1))}{3(a+b)(a+b-1)(c+d)}$$ I want to know if there is a shorter answer.,"['probability', 'conditional-probability']"
460541,What is the domain and the range of the function given below?,"The plot of function & the function definition is here: https://www.desmos.com/calculator/p4y97ww37l Edit In case the above link isn't working,here's the function definition: $$y=\left \lceil x \right \rceil.sin\frac{\pi}{\left \lceil x+1 \right \rceil}$$ Spikes are also observed at x=(2^n)-1 where n=1,2,3... Can anyone provide any explanation for the observed peaks? Also what would be the Domain & Range of this function?
Please also provide a method for finding it without plotting it.",['functions']
460548,A Möbius transformation maps circles and lines to circles and lines. What exactly does that mean?,"The title pretty much says it all. I am also looking for a concrete example if possible. I have looked at the proof, but I'm not exactly sure what it means because I am kind of confused on what the theorem actually says. Does it mean that if g(z) is a circle and f(z) is a Möbius transformation then f(g(z)) is a circle as well?","['transformation', 'complex-analysis', 'analysis']"
460555,Rigorous Textbook for Introduction to Complex Numbers/Analysis?,"Does anybody know where I can find a rigorous textbook on developing complex numbers/analysis?  I'm currently working through Needham's Visual Complex Analysis, which is interesting but non-rigorous.  I would like to supplement that text.  Thanks.","['complex-numbers', 'book-recommendation', 'reference-request', 'complex-analysis']"
460579,How to compute $\prod_{n=1}^\infty\left(1+\frac{1}{n!}\right)$?,"Does $$p=\prod_{n=1}^\infty\left(1+\frac{1}{n!}\right)$$ have any closed form in terms of known mathematical constants? The computer says 
  $$p=3.682154\dots$$
  but I don't even know how do devise the converging upper and lower bounds to obtain this result. edit Jan. 15: I've got rid of the infinite product in favor of an fastly converging infinite sum over finite products here . Thoughts: $$p=\lim_{n\to \infty}p_n\hspace{.7cm}\text{where}\hspace{.7cm} p_n=p_{n-1}\cdot \left(1+\frac{1}{n!}\right)\hspace{.7cm}\text{with}\hspace{.7cm} p_1=2.$$ So I looked for an emerging pattern $p_1=(1+\frac{1}{1!})$ $p_2=(1+\frac{1}{1!})(1+\frac{1}{2!})=(1+\frac{1}{1!}+\frac{1}{2!})+(\frac{1}{1!2!})$ $p_3=((1+\frac{1}{1!}+\frac{1}{2!})+\frac{1}{1!2!})(1+\frac{1}{3!})
=(1+\frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!})+(\frac{1}{1!2!}+\frac{1}{1!3!}+\frac{1}{2!3!})+\frac{1}{1!2!3!}$ It appears that $$p=1+\sum_{n=1}^\infty\sum_{m=1}^\infty a_{nm}$$ where $a_{1m}$ is the sum of terms with one inverse $\frac{1}{m!}$, and then $a_{2m}$ is the sum of (sums of) terms with two inverses $\frac{1}{r!s!}$. For example the term $\frac{1}{1!3!}$ is in the sum, and so I guess I need all the partitions into $n$ numbers. However, we don't want to count $\frac{1}{2!2!}$ and so it's more complicated. I guess the product can be written as a sum of term $(e-1)^n$ minus something, as for example $(e-1)^2 
= \left(\frac{1}{1!} + \frac{1}{2!}+ \frac{1}{3!}+\cdots\right)\left(\frac{1}{1!} + \frac{1}{2!}+ \frac{1}{3!}+\cdots\right)
=\sum_{n=1}^{\infty}\sum_{m=1}^{\infty} \frac{1}{  m!\,n!}$. The logarithm of it is also a sum of sums which somewhat resembles the series expansion of the exponential function, but there, I think, the coefficients are powers of $\frac{1}{n!}$.","['sequences-and-series', 'infinite-product']"
460588,Compare the sum of the squares of the median of a triangle to the sum of the squares of sides,You have to compare the sum of the squares of the median of a triangle to the sum of the squares of sides?,"['geometry', 'triangles']"
460590,Is my proof correct?,"I'm a new user so if my question is inappropriate, non-uniform or ill-shaped; please comment (or edit maybe). First of all, I'm asking that if my proof is correct or not. Of course, you can prove it nicer and this helps me but my main reason for asking this question is a check for my proof. Let $a \in V \subseteq X \subseteq \mathbb{R} $. If for an open interval $I$, $I \cap X \subseteq V$,  we call $V$ as ""$X$-neighbourhood of $a$"". We will prove following statement: ""Let $X \subseteq \mathbb{R}$ and assume that for all $x \in X$ there exist a finite $X$-neighbourhood of $x$. Then, $X$ must be countably infinite."" EDIT: It doesn't have to be infinite, it just must be countable. My proof : Because of the fact that $X \subseteq \mathbb{R} $, we can just show that $X$ is not uncountably infinite. But$_*$ also, we should show that $X$ cannot be finite. Let's assume that $X$ is uncountably infinite and let's define a set $A$ as $A = \{Y$: The set $X \setminus Y$ is still uncountably infinite$ \} $. Now$_{**}$ we will pick a maximal$_{***}$ element $B$ in $A$. Then, if $x \in X\setminus B$ there must be a finite $X$-neighbourhood of $x$. Let's call this neighbourhood as $W$ and call the open interval as $I$ (there might be more than one open interval, just pick one of them) which make $W$ a $X$-neighbourhood of $x$ .Then, obviously $(X \setminus B) \cap I \subseteq W $. But, then $(X \setminus B) \cap I \in A $ and if we take $J = (X \setminus B) \cap I$, $(X \setminus B) \setminus J  = X \setminus (B \cup J)$ must be in $A$ and that is a contradiction because we take $B$ as a maximal element. $_*$: With edit, this part is wrong. $_{**}$: We need to show that A is well-defined and there exists a maximal element in A. $_{***}$: If for a $k_1 \in A$, there exists no $k_2 \in A$ such that $k_2 \subset k_1$, we call $k_1$ as the maximal element. For completion we should prove that $_{**}$ but I think you can easily show it. Also, there are little things, for example, $B$ must be non-empty. Thanks for any help and please bear in mind that I cannot understand high-level topological explanations.","['proof-verification', 'real-analysis']"
460628,Dual of an isometry,"Let $T : X \to Y$ be a linear isometry between normed spaces $X,Y$. Must the dual map $T^* : Y^* \to X^*$ be an isometry?",['functional-analysis']
460649,The largest of $N$ random numbers over a uniform distribution?,"So I read somewhere than if you have $N$ numbers picked independently from a uniform distribution, say $[0,1]$, the greatest number has an expected value of $\frac{N}{N+1}$. So if you have 2 numbers the greatest has expected value $2/3$. The smallest has expected value of $1/3$. The expected values are uniformly distributed. This makes sense, but is there a clear/intuitive proof of this? Thanks :)","['statistics', 'probability']"
460690,How many 32 digit binary number combinations are possible?,"How many 32 digit binary number combinations are possible? For example: $$00000000-00000000-00000000-00000000$$
$$00000000-00000000-00000000-00000001$$
$$00000000-00000000-00000000-00000010$$
$$.$$
$$.$$
$$.$$
$$11111111-11111111-11111111-11111110$$
$$11111111-11111111-11111111-11111111$$ Well, we can easily convert the last number to decimal to get the number of combinations and the answer would be $2^{32}$ combinations. But I need a general explanation with respect to general concepts like probability, permutations or combinations, as to how we get $2^{32}$ combinations. P.S. I am not a mathematician. So, please try to explain in a simple way. Thanks a lot!","['permutations', 'probability', 'combinations', 'binary', 'combinatorics']"
460696,How to find the value of $a$ for which $\;\tan^2x + (a+1)\tan x-(a-3)<0$ is true,"I wanted to know, how can I find the value of $a$ for which the inequality $\tan^2x + (a+1)\tan x-(a-3)<0$ is true for at least one $x\in(0,\pi/2)$. I don't know how to proceed, any help is appreciated.","['trigonometry', 'algebra-precalculus']"
460703,Arctanh to exp: Prove two equations are equivalent,"For some peace of mind in a project, I am trying to prove two equations are somewhat equivalent. I have these two equations.
$$
i_{1} = \frac{-I_M}{2}\frac{2i_2\left(1+e^{\left(\frac{2i_2R_E}{V_T}\right)}\right)+i_e\left(-1+e^{\left(\frac{2i_2R_E}{V_T}\right)}\right)}{2i_2\left(-1+e^{\left(\frac{2i_2R_E}{V_T}\right)}\right)+i_e\left(1+e^{\left(\frac{2i_2R_E}{V_T}\right)}\right)}
$$ $$
i_1 = \frac{I_M}{2}\frac{\left(-1\pm e^{\left(\mp2\frac{i_2R_E + V_T\operatorname{Arctanh}\left[\frac{i_2}{i_e}\right]}{V_T}\right)}\right)}{\left(1\pm e^{\left(\mp 2\frac{i_2R_E + V_T\operatorname{Arctanh}\left[\frac{i_2}{i_e}\right]}{V_T}\right)}\right)}
$$ I know these equations are equivalent because their Taylor series coefficients are pretty much the same except for one factor of 2 on the denominator. I have probably made a mistake with the formation of one of the two equations above, but I can't find it, and I think if I convert the top one to a form similar to the bottom one I can 'debug' the error.
I also know the Arctanh to exponential identity gives a very similar form to the top one, (seen here 5th one down) but I don't know how to convert between the two with the extra variables in there. I have tried many times but this is abit beyond me. Does someone want to have a go a converting Eq. 1 to Eq. 2 or vice versa? Even if it's not close, it might give me some insight. Thanks a lot. Edit: added missing $V_T$ and minus sign into eq. 2.","['trigonometry', 'algebra-precalculus', 'solution-verification']"
