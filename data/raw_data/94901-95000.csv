question_id,title,body,tags
1300730,$3^x + 4^y = 5^z$ [duplicate],"This question already has answers here : Positive integral solutions of $3^x+4^y=5^z$ (3 answers) Closed 9 years ago . This is an advanced high-school problem. Find all natural $x,y$, and $z$ such that 
  $3^x + 4^y = 5^z$. The only obvious solution I can see is $x=y=z=2$. Are there any other solutions?","['number-theory', 'elementary-number-theory', 'algebra-precalculus']"
1300772,When can we move a Fréchet derivative under a Lebesgue integral?,"Under what conditions can we move a Fréchet derivative under a Lebesgue integral?  Specifically, when does $$
G'(x) = h\in X\mapsto \int_{\Omega} \left(F_x^\prime(x,t)h\right) \mu(dt)
$$ where $$
G(x)=\int_{\Omega} F(x,t) \mu(dt)?
$$ I suspect this has something to do with the Dominated Convergence Theorem .  What's causing me issues, though, is the definition of a Fréchet derivative.  If we were to use a Gatteaux derivative, I can see how this works because we start with the expression for $G$, write out the definition of a directional derivative, and then move the limit to the inside of the integral.  With a Fréchet derivative, the limit sits outside of a norm expression, so it's not clear to me how to use the Dominated Convergence Theorem.","['derivatives', 'lebesgue-integral', 'measure-theory', 'integration']"
1300780,Does equation $f(g(x))=a f(x)$ have a solution?,"Suppose $g: [0,1] \to [0,1]$ is a strictly increasing, continuously differentiable function with $g(0)=0$ and $g(1) < 1$, and $a \in (0,1)$.
Is there a function $f:[0,1] \to \mathbb{R}$ such that $f(g(x))=a f(x)$ for all $x \in [0,1]$? I know that when $g$ is linear, then there are many such functions $f$. But how about arbitrary (sufficiently smooth) function? Background: it is a part of larger project and I have already shown that $g$ is a certain function with nice properties. I have strong intuition that $f$ function should exists. If not generally, then with some additional properties that $g$ probably has. Also, if it helps, then in all cases relevant to my project, $a$ and $g(1)$ are small.","['recurrence-relations', 'real-analysis', 'functions']"
1300799,Algebra with element having empty spectrum?,"The definition of the spectrum makes sense for any algebra. I guess we can go to the unitization to make sense of it even non-unital algebras. Recalling the well-known fact that for normed algebras, the spectrum of each element is always non-empty, I was wondering if there are examples of algebras having an element with empty spectrum. Maybe one might have some examples in mind where we actually have a topology on the algebra. Due to the useful comments, I make my setting more precise. I only consider complex algebras and define the spectrum as $$\sigma(x) := \{\lambda\in \mathbb{C}: \lambda 1 - x \text{ not invertible}\}.$$","['banach-algebras', 'spectral-theory', 'functional-analysis']"
1300853,Exact value of a sum involving harmonic numbers,"Could somebody tell me the exact value of this series?
$$
\sum_{k=1}^{\infty} (-1)^k\frac{H_k^{(5)}}{k}
$$
where
$$
H_k^{(n)}=\sum_{i=1}^{k}\frac{1}{i^n}
$$ Thanks!","['summation', 'sequences-and-series', 'harmonic-numbers', 'discrete-mathematics']"
1300859,Steve Nash’s expected value from his one-and-one free throw situation is 1.72 points. What is his free-throw percentage?,"The one-on-one free throw situation works like this - for the first throw, if you make it, you get to do it again. If you miss, you don't get another chance. If you make it the second time, you get two points total. If Steve Nash's expected value is 1.72 points on average, what is his free throw percentage (number of times he makes the basket)? Please do not research this on the internet as Steve Nash just retired with the highest free throw percentage, so the answer would be on the internet.","['probability', 'statistics', 'quadratics']"
1300877,Determinant proof using its properties,"Prove without expanding:
\begin{equation}
\begin{vmatrix}bc&a^2&a^2\\b^2&ac&b^2\\c^2&c^2 & ab\end{vmatrix} = \begin{vmatrix}ac&bc&ab\\bc&ab&ac\\ab&ac&bc\end{vmatrix}
\end{equation} Tried to multiply by 'abc' in all rows then take common factors. Tried to expand determinant into two determinants. I used the determinant properties shown here: http://www.vitutor.com/alg/determinants/properties_determinants.html","['determinant', 'linear-algebra', 'matrices']"
1300881,Hoeffding’s inequality extension,"In Hoeffding’s inequality we assume that the random variables $X_i$ ,$i=1,..,n$ are i.i.d. and bounded . Is there any extension to Hoeffding’s inequality  for the case that $X_i$ are identically disributed but not independent? Thanks","['probability-theory', 'probability', 'statistics', 'machine-learning']"
1300885,"If a polynomial maps a region onto a neighborhood of zero, does it follow that it has a zero in some ""robust"" sense?","Let $B^n\subseteq\Bbb R^n$ be a unit ball, $P: B^n\to\Bbb R^m$ is polynomial in each component, and assume that the image of $P$ contains $0$ in its interior. Does it follow that for some $\epsilon$, each continuous $g: B^n\to\Bbb R^m$ with $\|g-P\|_\infty\leq\epsilon$ has a root? For non-polynomial continuous functions $P$, the answer is clearly no. For example, $P: B^2\to\Bbb R^2$ defined in polar coordinates by $P(r,\phi)=(r,4\cos \phi)$, maps $B^2$ onto $B^2$ and each circle of radius $r$ is mapped surjectively to itself with degree $0$ (the ""$4>\pi$"" is needed to ensure that it goes over all the circle, there and back). There are arbitrary close continuous perturbations of $P$ with no root, because one can only change $P$ inside an arbitrary small ball $B(\epsilon)$ and avoid zero inside. The question is: can something like that happen, if we require $P$ to be a polynomial?","['algebraic-topology', 'algebraic-geometry', 'calculus']"
1300907,"prove $\sum \limits_{k=1}^n A(n,k){x+k-1 \choose n}=x^n$","A descent in the permutation $\sigma = a_1 \cdots a_n \in S_n$ is an index $i\in[n-1$] for which $a_i > a_{i+1}$. Let A(n, k) be the number of permutations of $[n]$ with $k-1$ descents where $n \geq 1$. Let $A(0,0) = 1$ and $A(0,k) = 0$ for $k \geq 1$ and let: $A(n+1,k)=kA(n,k)+(n-k+2)A(n,k-1)$ For $n \geq 1$ prove that: 
\begin{equation}
\sum \limits_{k=1}^n A(n,k){x+k-1 \choose n}=x^n
\end{equation} Proof by Induction: For n = 1 :
$\sum \limits_{k=1}^1 A(1,k){x+k-1 \choose 1}= A(1,1)\binom{x}{1}=(A(0,1)+A(0,0))x = x=x^1$ Suppose:
$\sum \limits_{k=1}^n A(n,k){x+k-1 \choose n}=x^n$ $\sum \limits_{k=1}^{n+1} A(n+1,k){x+k-1 \choose n+1}$ $=\sum \limits_{k=1}^{n} A(n+1,k){x+k-1 \choose n+1}+ A(n+1,n+1){x+n \choose n+1}$ $=\sum \limits_{k=1}^{n} \big( kA(n,k)+(n-k+2)A(n,k-1)\big){x+k-1 \choose n+1}+ A(n+1,n+1){x+n \choose n+1}$ $=\sum \limits_{k=1}^{n} kA(n,k){x+k-1 \choose n+1} + \sum \limits_{k=1}^{n}(n-k+2)A(n,k-1){x+k-1 \choose n+1} + A(n+1,n+1){x+n \choose n+1}$ $=k\sum \limits_{k=1}^{n} A(n,k){x+k-1 \choose n+1} + (n-k+2)\sum \limits_{k=1}^{n}A(n,k-1){x+k-1 \choose n+1} + A(n+1,n+1){x+n \choose n+1} \\ = ???????????$ how to complete the proof?","['discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
1300913,Laplace-Beltrami on a Curve,"Is there a way to write out Laplace-Beltrami operator explicitly for a  sufficiently smooth plane curve given by implicit equation $\,s(x,y)=0\,$? If I knew knew the parametrization of the curve I could have computed metric tensor $\,g_{ij}\,$ and use well-known expression
$$
\Delta_{LB} u = \left\lvert g\right\rvert^{-1/2}\partial_i\big(\left\lvert g\right\rvert \,g^{ij}\,\partial_j u \big),
$$
where $g^{ij}$ is the dual metric, and $\,\left\lvert g\right\rvert\,$ is the determinant of  $\,g_{ij}$. However, I am looking for an explicit formula for $\,\Delta_{LB}u\,$ which could be useful without knowing parametrization of the curve.","['laplacian', 'plane-curves', 'differential-geometry', 'multivariable-calculus']"
1300936,Laplace operator defined on a Sobolev space,"Consider the Laplace operator $$A:W^{2,2}(\mathbb{R})\to L^2(\mathbb{R})\;\;\\A u = -u^{\prime \prime}$$
I want to know why this operator is closed (I'm using the closed graph theorem): Let $(u_n)\subseteq W^{2,2}(\mathbb{R})$ be a sequence such that $u_n\to x$ in $L^2(\mathbb{R})$ and $Au_n=-u_n^{\prime \prime}\to y$ in $L^2(\mathbb{R})$. Now, why is $x\in  W^{2,2}(\mathbb{R})$? (It must be proven that $Ax=y$, but this is ok for me..) I'm stuck on: Is $(u_n)$ a cauchy sequence $W^{2,2}(\mathbb{R})$ with respect to $\|u\|_{2,2}^2=(\|u\|_{L^2}^2+\sum\limits_{|\alpha|\le 2}\|D^{\alpha}u\|_{L^2}^2)$? I know that $(u_n)$ and $(u_n)$ are cauchy sequences in $L^2(\mathbb{R})$ but I know nothing about $(u_n')$. Regards","['sobolev-spaces', 'ordinary-differential-equations', 'functional-analysis']"
1300964,Coordinates of the center of the circle,"I am stuck on this problem: If the lines $y=x+\sqrt{2}$ and $y=x-2\sqrt{2}$ are two tangents of a
   circle and $(0,\sqrt{2})$ lies on this circle then what is the equation of the circle? I found out the distance between the two  tangents  $y=x+\sqrt{2}$ and $y=x-2\sqrt{2}$ is $3$. The radius is $3/2$ but I don't know how to find the center. I tried forming the equations but could not succeed. Please tell me the easiest way. Thank you","['geometry', 'analytic-geometry']"
1300969,Predual of $l^1(\Gamma)$,"Let $\Gamma$ be an uncountable index set. For example $\Gamma=\mathbb R$. Let 
$l^1(\Gamma)$ be the set of functions with countable support and
finite sum:
$$
\sum_{a\in\Gamma}|f(a)|<\infty.
$$
The space $l^1(\Gamma)$ is a Banach space with the norm $\|f\|:=\sum_{a\in\Gamma}|f(a)|$. It is not separable. My question is: does $l^1(\Gamma)$ have a separable pre-dual space? I have seen statements that $l^1(\Gamma)$ is isometric to the dual space of $c_0(\Gamma)$,
however I did not found a definition of $c_0(\Gamma)$ nor a statement about its separability.
The usual Krein-Milman based argument does not fail as in the $L^1$ case (the unit ball of $l^1(\Gamma)$ is the closed convex hull of its extreme points).","['lp-spaces', 'functional-analysis', 'measure-theory']"
1300994,Number of primes between $2k$ and $(\sqrt{k}-1)^2$.,"I would like to prove the following. Let $\pi$ denote the prime counting function. Then for $k\geq 81$ we have
$$
\pi(2k)-\pi\left(\left\lfloor(\sqrt{k}-1)^2\right\rfloor\right)\geq 6.
$$ What I have done is just some experimental calculation which suggests that even if I write 19 on the right hand side of the inequality it will still hold because the difference seems to be slowly growing with $k$ (it is not that surprising as far as I know even if sometimes it decreases a bit). However, I have never attempted to solve similar exercises/problems before and do not know how to start proving it.","['prime-numbers', 'number-theory']"
1301019,Convergence for every measurable set,Let $(f_n)$ non-negative measurable functions such that $f_n\to f$ and $\int f_n\to \int f<\infty$. We have to prove that $\int_E f_n\to \int_Ef$ for each $E$ measurable. I know that if $f_n\to f$ then $f_n\cdot \chi_E\to f\cdot \chi_E$. Maybe we can use that in order to prove $\int f_n\cdot\chi _E\to\int f\cdot\chi_E$. Could you give me any hint to do this? Thanks.,"['real-analysis', 'measure-theory']"
1301028,Techniques to prove FDD convergence,"When examining a sequence of stochastic processes $(\textbf{X}_n)$, $n\geq1$ convergence of marginals, i.e. $\mathbf{X}_n(t)\to\mathbf{X}(t)$ (in distribution) is often not too hard to establish for any fixed $t\in [0,\infty)$. On the other hand convergence of finite dimensional distributions (FDD-convergence) is rather hard. Are there any ""standard"" techniques, or at least nice tricks one can try? I don't need an exhaustive list, maybe just ideas/starting points/references/example proofs,... My impressions so far: If one has some kind of Markov property one tries to prove those results by induction. I also saw some argument with test functions somewhere, but I cannot recall where and how it worked. Thanks!","['probability-theory', 'stochastic-processes']"
1301036,Determine $\int \limits_0^{\infty} \frac1{x^4+1}dx$,"Let $$f(z)=\frac1{1+z^4}$$ (a) Find the sinularity of $f(z)$ in the first quadrant where $Re(z), Im(z) \ge 0$. (b) Find the residue of the singular point found in the first quadrant. (c) Let $\Gamma_R$ be the quarter circle $\Gamma_R: |z|=R$, $Re(z), Im(z) \ge 0$, positively oriented. Show that $$\lim \limits_{R \rightarrow \infty} \int _{\Gamma_R} f(z) \, \, dz =0$$ (d) Determine $$\int \limits_0^{\infty} \frac1{x^4+1}dx$$ Attempt: For (a) I got $$z_0 = \frac{\sqrt2}{2} +\frac{\sqrt2}{2}i$$ For (b) I got that this is a simple pole since the degree of is $1$ and $f(z_0)$ doesn't make the numerator vanish. So using the limit formula $$Res (f,z_0)= -\frac{\sqrt2}{8}-\frac{\sqrt2}{8}i$$ Used $ML$ Lemma for (c). Stuck on (d). What should i make my region? I was thinking $\Gamma = \Gamma_R + \nabla R$ where $\Gamma_R$ is as stated in the question and $\nabla_R$ is the line from $0$ to $R$ in the real axis. But this would mean $\Gamma $ is not closed. Is this a problem? From using this i got the answer to (d) as $$\frac{\pi \sqrt2}4 -\frac{\pi \sqrt2}4i$$ but really unsure on this since my chosen region is not closed...",['complex-analysis']
1301042,Intuition of partial-ordered set.,"Recently I've come in front of partial ordered set . I've read the wiki article but couldn't comprehend it especially the concept of set together with a binary relation . Can anyone please explain me what partial ordered set means? A partially ordered set (or poset) formalizes and generalizes the intuitive concept of an ordering, sequencing, or arrangement of the elements of a set. What is the meaning of this statement? Please help.",['elementary-set-theory']
1301063,Classifying groups of order 18,"I am trying to classify groups of order 18. So far, I have shown that a group $G$ of order 18 is given by $G\cong C_9 \rtimes_{\varphi} C_2$ or $G\cong (C_3 \times C_3)\rtimes_{\varphi} C_2$. If $G\cong C_9 \rtimes_{\varphi} C_2$, then $\mid \varphi(1) \mid$ divides $2$, so that $\varphi(1)$ is trivial or inverts a generator of $C_9$. I concluded that $G \cong C_{18}$ in the former case and $G \cong D_{18}$ in the latter case. I am now considering the case $G\cong (C_3 \times C_3)\rtimes_{\varphi} C_2$, but I am stuck. I have found this article , but they do not do it the same way as me (finding the image of $\varphi(1)$ in $Aut(C_3 \times C_3)$). Is there a way to do this using my method? My goal is to be able to do questions like this on my algebra qual without having to fiddle around. I was messing around with the fact that $Aut(C_3 \times C_3)\cong GL_2(C_3)$.","['abstract-algebra', 'group-theory']"
1301064,Proving this two equations are same and true,"If $\sqrt{a} - \frac{1}{\sqrt{a}} = 1$, then $a + \frac{1}{a} = 3$. Why this statement is true? I tried to square the first equation, but it didn't work. I can't understand why there is a 3 in the second equation.",['algebra-precalculus']
1301066,What's wrong with this reasoning? (Cauchy integral theorem),"Asumme that $f$ is analytic and for $z\in \overline{B(x,r)}$:
$$|f(z)|\leq d$$
Then for $z\in B(x,r)$:
$$|f'(z)|=\frac{1}{2\pi}\left|\oint_{|\alpha-x|=r}\frac{f(\alpha)}{(\alpha-z)^2}d\alpha\right|\leq \frac{d}{2\pi}\left|\oint_{|\alpha-x|=r}\frac{1}{(\alpha-z)^2}d\alpha\right|=0$$ Where in the first equality I use the Cauchy integral theorem. In the inequality I use that $|f(z)|<d$ over the integration curve. And in the last equality I use that
$$
    \oint_{|\alpha-x|=r}\frac{1}{(\alpha-z)^n}d\alpha= 
\begin{cases}
    2\pi i,& \text{if } n=-1\\
    0,              & \text{otherwise}
\end{cases}
$$ However this result cannot be correct, because it does not even require $d$ to be small. According to this reasoning we would conclude that if an analytic function is bounded on a domain, then it's derivative must be $0$, which is absurd. So I'm sure that I'm doing something wrong here, but I just don't see what. Thanks Edit: there was no point in talking about the difference between $f$ and $g$.",['complex-analysis']
1301075,"Is $[X,Y] \neq 0$ the sufficient condition of $e^{X+Y} \neq e^Xe^Y$?","We know that if X commutes with Y, where X and Y are $n\times n$ matrices,  then we have $$e^{X+Y}=e^Xe^Y$$ However, can we conclude that $e^{X+Y} \neq e^Xe^Y$ if X doesn't commute with Y ?
Is there any counterexample ?
Or prove if it is right.",['matrices']
1301078,Proving that disjoint unions of presentations are coproducts of groups,"I'm working through Aluffi's Algrebra: Chapter 0 and I need some assistance with an excercise. Aluffi, Ex. II.8.7 Let $(A|R)$, resp. $(A'|R')$, be a presentation for a group $G$ in Grp , resp. $G'$; we may assume that $A, A'$ are disjoint. Prove that the group $G \ast G'$ presented by
  \begin{equation}
(A \cup A'|R \cup R')
\end{equation}
  satisfies the universal property for the coproduct of $G$ and $G'$ in Grp . (Use the universal properties of both free groups and quotients to construct natural homomorphisms $G \to G \ast G', G' \to G \ast G'.$) What I have done so far: First off, we have natural set-functions $A,A' \to F(A \cup A')$. Hence we have unique homomorphisms $F(A),F(A') \to F(A \cup A')$ whose restrictions to $A,A'$ are equal to the functions $A,A' \to F(A \cup A')$, by the universal property of free groups. By combining these homomorphisms with the natural projection $F(A \cup A') \to F(A \cup A')/(R \cup R')$, we get homomorphisms $F(A),F(A') \to F(A \cup A')/(R \cup R')$. Since $a(R) = b(R) \Rightarrow a(R \cup R') = b(R \cup R')$, we get a natural homomorphism $\pi_1:G \cong F(A)/(R) \to F(A \cup A')/(R \cup R')$, by the universal property of quotients. Similarly, we get a natural homomorphism $\pi_2:G' \cong F(A')/(R') \to F(A \cup A')/(R \cup R') = G \ast G'$. If I'm not mistaken, these homomorphisms simply map $a(R) \mapsto a(R \cup R')$, for all $a(R) \in G$, and similarly for elements of $G'$. If we have a group $H$ and homomorphisms $f:G \to H, g:G' \to H$, then the only function $\varphi:G \ast G' \to H$ s.t. $\varphi \circ \pi_1 = f, \varphi \circ \pi_2 = g$, must map $a(R \cup R') \mapsto f(a(R))$ for all $a \in F(A)$, and similarly for all $b \in F(A'), b(R \cup R') \mapsto g(b(R'))$. All that is left, is to show that this defines a function $\psi$. So, we need to show that $ab^{-1} \in (R \cup R') \Rightarrow \psi (ab^{-1}(R \cup R')) = e_H$, for any $a,b \in F(A \cup A')$. This is what I can't do. How do I go about showing this, or am I going in a wrong direction? Edit: Note that (R) stands for the normal closure of R in F(A). One answer: Note that $(R \cup R') := \langle \{ghg^{-1} \mid g \in F(A \cup A'), h \in R \cup R'\} \rangle$. Now, for any $h \in R \cup R', g \in F(A \cup A')$, we have 
\begin{align}
\psi (ghg^{-1}(R \cup R'))  & = \psi (g(R \cup R')) \psi (h(R \cup R')) \psi (g^{-1}(R \cup R'))
\\ & =  \psi (g(R \cup R')) \psi (g^{-1}(R \cup R'))
\\ & =  \psi (gg^{-1}(R \cup R'))
\\ & = e_H.
\end{align}
Hence, for any $a \in (R \cup R')$, we have $\psi (a) = e_H$, which completes the proof.","['abstract-algebra', 'group-theory', 'category-theory']"
1301115,What is the mean value theorem for the Fréchet (total) derivative?,"What is the mean value theorem for the Fréchet (total) derivative?  Off the top of my head, it's something like
$$
\|F(x+h)-F(x)\|\leq \sup_{c\in[0,1]} \|F^\prime(x+ch)\|\|h\|
$$
but the double direction of $h$ on the right hand side feels odd to me and I'm not entirely sure what all of the assumptions behind the statement should be.","['multivariable-calculus', 'real-analysis', 'functional-analysis', 'derivatives']"
1301143,Counting clarification,"In the text I am reading there's a question: From the digits $0, 1, 2, 3, 4, 5, 6$, how many four-digit numbers with
distinct digits can be constructed? How many of these are even numbers? I get the first part correctly by multiplying $6*6*5*4 = 720$. To calculate the second part, I follow this process. The unit's place can be chosen 4 different ways $(0,2,4,6)$. The ten's place can be chosen 6 ways ($7-1$ ways) The hundred's place can be chosen 5 ways($7 - 2$ already chosen) The thousand's place can be chosen 3 ways(6 (digits excluding 0) - 3 already chosen). So, this becomes $4*6*5*3 = 360$. But the answer in the text is $420$. Where am I going wrong?",['combinatorics']
1301154,"Trace theorems for arbitrary differentiability $k$, with embedding constants under control as $k\to\infty$","The usual trace theorem (with non-optimal exponents, but I don't care for those at the moment) says that $$
W^{1,p}(\Omega)\hookrightarrow L^p(\partial\Omega)
$$ 
for Lipschitz domains. When $\Omega=\mathbb{R}^n_+$ is an upper half space, we even have $$
W^{k,p}(\mathbb{R}^n_+)\hookrightarrow W^{k-1,p}(\mathbb{R}^{n-1})\quad\forall k\in\mathbb{N}
$$
and even more, the embedding constant can be chosen independent of $k$! However, I have already problems controlling the embedding constants in the case where $\Gamma\subset\partial\Omega\subset\mathbb{R}^n$ is (part of) a graph of a polynomial. It is easily shown that $$
\|f\|_{W^{k-1,p}(\Gamma)}\leq C(k)\|f\|_{W^{k,p}(\Omega)}
$$
for finite $C(k)$, (works for any smooth boundary) and one way to bound $C(k)$ is:
If $\phi\colon U\subset\mathbb{R}^{n-1}\to\Gamma$ is a polynomial of degree $m$ that parametrizes $\Gamma$, then we have to check that
$f\circ \phi\in W^{k-1,p}(U)$. All boils down (by chain rule) to showing
$$\|\sum_{|\alpha|=0}^{k-1}((D^{\alpha}f)\circ\phi) H_{\alpha,\phi}\|_{L^p(U)}\leq C(k)\|f\|_{W^{k,p}(\Omega)}$$
where $H_{\alpha,\phi}$ is a sum of products of powers of derivatives of $\phi$ up to order $|\alpha|$. Using that all derivatives of $\phi$ vanish for $|\alpha|\geq m$, I can show with very crude arguments that $\|H_{\alpha,\phi}\|_{L^\infty(U)}\leq C_0^{|\alpha|^{C(n,m)}}$ , and conclude by applying the usual trace theorem (say with embedding constant $C_1$) to all $D^\alpha f$ and the $L^\infty$ bound to $H_{\alpha,\phi}$:
$$\|\sum_{|\alpha|=0}^{k}((D^{\alpha}f)\circ\phi) H_{\alpha,\phi}\|_{L^p(U)}\leq C_0^{k^{C(n,m)}}\sum_{|\alpha|=0}^{k-1}\|((D^{\alpha}f)\circ\phi) \|_{L^p(U)}\\ \leq C_0^{k^{C(n,m)}}C_1\sum_{|\alpha|=0}^{k-1}\|f\|_{W^{|\alpha|+1,p}(\Omega)}\\ \leq C_1 k^dC_0^{k^{C(n,m)}}\|f\|_{W^{k,p}(\Omega)}
$$ This should also work if $\Gamma$ is a rigid transformation of a (part of a ) graph of a polynomial (by IFT); however, then the calculations get even messier. My questions: Are there better bounds on $C(k)$ than the one I described? Are there bounds for more general classes of boundaries than piecewise polynomial boundaries? And related to all this: is there a more intrinsic way (than using parametrizations) that allows one to capture statements like ""the boundary has only $m$ non-vanishing derivatives"" (true for pieceiwse polynomials), or ""all derivatives of the boundary are uniformly bounded"" (think of a piecewise $sin(x)$ boundary in $R^2$) Intuitively, I would think a ball is just as good as a piecewise polynomial boundary, but I fail to completely to show any bound in this case.","['sobolev-spaces', 'reference-request', 'functional-analysis']"
1301176,When are the eigenvalues of the second fundamental form equal to the principal curvatures?,"I am confused about the following concerning the second fundamental form. Consider a surface $S$ $\subset R^3$ If we consider a chart at a point $p \in S$, $f$: $R^2$$\to S$  and suppose $\partial f/\partial x$ and $\partial f/\partial y$ are orthonormal, Does it then follow that the eigenvalues of the second fundamental form are the principal curvatures and the eigenvectors are the principal directions? Moreover If  $\partial f/\partial x$ and $\partial f/\partial y$ are not orthonormal this may not be true? Thanks in advance",['differential-geometry']
1301187,theorem relating mersenne numbers?,"For $(x2^9)^2=2^q-1+y^2q^2$,where $q$ is prime, is it possible to show that there exists only an unique solution for the pair $\{x,y\}$?","['prime-numbers', 'number-theory', 'elementary-number-theory']"
1301196,Evaluate $\sin\left(-\frac{\pi}{6} + \frac{1}{2}\arccos\left(\frac{1}{3}\right)\right)$.,My task is to evaluate $$\sin\left(-\frac{\pi}{6} + \frac{1}{2}\arccos\left(\frac{1}{3}\right)\right).$$ I think I've gotten most of the way there but I keep running into trouble... any suggestions?,['trigonometry']
1301197,Multiplication Principle and Inclusion-Exclusion: $2^n = \sum_{i = 0}^n (-1)^i \binom{n}{i} \binom{2n - 2i}{n - 2i}$,"I began to compose an unnecessarily complicated answer to this question : If we had 25 people all who have 2 different balls, how would you work out how many combinations there would be if we want to choose 25 balls, but no person can have both of their balls in the choice? The most direct way is to visit each of the twenty-five people and choose one ball for a total of $2^{25}$ choices. My convoluted solution makes use of inclusion-exclusion as follows: Let $A_i$ be the set of all 25-ball combinations that contain both of person
   $i$'s balls. Since we want the number of ways in which no person has
   both of their balls chosen, we want to compute $$ \binom{50}{25} -
 \left| \bigcup_{i=1}^{25} A_i \right|. $$ By the principle of
   inclusion and exclusion, this becomes \begin{align*} \binom{50}{25} -
 \left| \bigcup_{i=1}^{25} A_i \right| &= \binom{50}{25} - \sum_{i =
 1}^{25} (-1)^{i+1} \binom{25}{i} |A_1 \cap \cdots \cap A_i|\\ &=
 \binom{50}{25} - \sum_{i = 1}^{25} (-1)^{i+1} \binom{25}{i} \binom{50
 - 2i}{25 - 2i}\\ &= \sum_{i = 0}^{25} (-1)^i \binom{25}{i} \binom{50 - 2i}{25 - 2i}\\ \end{align*} I find that I am unable to directly simplify this to $2^{25}$ without appealing to the combinatorial argument I made at the beginning. Note that the terms in the summation are all zero for $i \geq 13$. One could generalize the problem slightly to allow for $n$ people each with two balls, in which case we would obtain
$$
2^n = \sum_{i = 0}^n (-1)^i \binom{n}{i} \binom{2n - 2i}{n - 2i}.
$$
Is there a non-combinatorial proof of this fact that I'm overlooking?","['summation', 'binomial-coefficients', 'combinatorics']"
1301199,How do I restrict k to ensure my matrix has exactly 3 distinct eigenvalues?,"$$A=\begin{bmatrix}-1&-1&0\\-12&3&-1\\k&0&0\end{bmatrix}$$ How do I restrict $k$ to ensure that my matrix has 3 distinct real eigenvalues? I tried going about it the long way by using the characteristic polynomial and factorizing, but I'm sure there is a faster way.","['matrices', 'eigenvalues-eigenvectors', 'linear-transformations', 'vectors', 'linear-algebra']"
1301212,Find minimum value of multivariable-function,"A tent with 2 rectangle shaped sides (no floor) and 2 isosceles triangles shaped gables with the volume $V$ is to be constructed. Determine the height so that the minimum amount of cloth is needed. The tent is a prism with isosceles triangle bases. Let the height of the triangle (i.e. the height of the tent) be denoted $x$, the base $2y$ and the length of the tent $L$. Then the volume is $$V(x,y,L)=xyL$$
and the area of the tent will be $$A(x,y,L) = 2(xy+L\sqrt{x^2+y^2}).$$ Since A is a continuous function on a compact set (or can this actually be said, since V is not a boundary but a function of the variables?), there will be a minimum and maximum value. These are found when $grad \, V \, || \, grad \, A$. Since $$ grad \, V = (yL, xL, xy)$$ and $$grad \, A =2(y + \frac{xL}{\sqrt{x^2+y^2}}, x + \frac{yL}{\sqrt{x^2+y^2}}, \sqrt{x^2+y^2})$$
we must find $\lambda$ such that
\begin{cases} y+\frac{xL}{\sqrt{x^2+y^2}} = \lambda yL \\ x+ \frac{yL}{\sqrt{x^2+y^2}} = \lambda xL \\ \sqrt{x^2+y^2} = \lambda xy \end{cases} I have no idea how to solve this or if this even would be the correct approach. Any help is appreciated.",['multivariable-calculus']
1301221,Redundance of the Smoothness of the Inversion Map in the Definition of a Lie Group.,"$\DeclareMathOperator{\inv}{inv}$ I am trying to understand the proof of the following from this document: Let $M$ be a smooth manifold which admits a group structure such that the multiplication map $m:G\times G\to G$ defined as $m(g, h)=gh$ for all $g, h\in G$ is a smooth map.
Then the inversion map $\inv:G\to G$ defined as $\inv(g)=g^{-1}$ for all $g\in G$ is a smooth map. The proof in the document proceeds as follows:
First note that the multiplication map is a constant rank surjective smooth map, and is therefore a submersion. Therefore, the level set $\Delta=m^{-1}(e)$ of $e\in G$ , $e$ being the identity of the group structure, is an embedded submanifold of $G\times G$ of dimension $n$ . Now let $\pi_1:G\times G\to G$ be the projection on the first coordinate.
Consider the map $\pi_1\circ i:\Delta\to G$ , where $i:\Delta\to G\times G$ is the inclusion map, which we know is a smooth embedding. It is claimed in the document that $\pi_1\circ i$ is a diffeomorphism.
The reasoning given seems to be this: The map $\pi_1\circ i$ is smooth and is a homeomorphism and hence by the inverse function theorem, it is also a diffeomorphism. This seems to suggest that any smooth homeomorphism is a diffeomorphism. But this is not true since the map $x\mapsto x^3:\mathbf R\to \mathbf R$ is a smooth topological embedding but not an immersion at $x=0$ . How do I show that that composition $\pi_1\circ i$ is a diffeomorphism?","['differential-topology', 'lie-groups', 'differential-geometry', 'smooth-manifolds']"
1301269,Understanding a proof of the strong Markov property of Lévy processes,"I don't understand the the last sentence of a proof of the Markov property for Lévy processes given in Jochen Wengenroth's textbook ""Wahrscheinlichkeitstheorie"" (de Gruyter, 2008). I will appreciate the community's help. In what follows I will state the theorem and outline the proof. I will then describe the two points that I do not understand. I will then describe my attempts to tackle these difficulties. I The following is taken from p. 142 (the first sentence) and from p. 144 (the rest) in Wengenroth's book (translated from German). Given a filtration $\mathcal{F} = (\mathcal{F}_t)_{t \geq 0}$ , the right-continuous filtration $\mathcal{F}^+$ is defined as follows: $\mathcal{F}^+_t \equiv \bigcap_{s > t} \mathcal{F}_s$ . A right-continuous stochastic process $(X_t)_{t \geq 0}$ that is adapted to the filtration $\mathfrak{F}$ and such that, for every $t \geq 0$ , $X_t$ takes values in a separable, normed space, is called an $\mathcal{F}$ -Lévy process . Theorem 7.14 (Strong Lévy property) Let $X = (X_t)_{t \geq 0}$ be a Lévy process adapted to the filtration $\mathcal{F}$ and let $\tau$ be a real-valued $\mathcal{F}$ stopping time. Then the following process $Y_t \equiv X_{\tau + t} - X_\tau$ is independent of $\mathcal{F}^+_\tau = (\mathcal{F}^+)_\tau$ and satisfies $Y \overset{d}{=} X$ . The following is an outline of the proof of the theorem, adapted from pp. 144-145 in Wengenroth's book. The full proof (in German) can be found at this link . Step 1 For every $n \in \{0, 1, 2, \dots\}$ we define the stopping time $\tau_n$ as follows $\tau_n \equiv k/2^n$ whenever $\tau \in [(k-1)/2^n, k/2^n)$ . It is shown that the processes $Y^n$ defined by $Y^n_t \equiv X_{\tau_n + t} - X_{\tau_n}$ are independent of $\mathcal{F}_{\tau_n}$ , respectively, and satisfy $Y^n \overset{d}{=} X$ . Step 2 Since $\tau \leq \tau_n \rightarrow \tau$ , we have that $Y^n_t \rightarrow Y_t$ (pointwise on $\Omega$ ), whence $Y \overset{d}{=} Y^n \overset{d}{=} X$ , and therefore, since $\mathcal{F}^+_\tau \subseteq \mathcal{F}_{\tau_n}$ , the independence of $Y$ and $\mathcal{F}^+_\tau$ follows. QED II The two points that I don't understand in the proof appear in step 2. Why is it the case that $Y \overset{d}{=} Y^n$ ? Why are $Y$ and $\mathcal{F}^+_\tau$ independent? III Following are my (unsuccessful) attempts at tackling the two points that I don't understand. If we think of $Y^n$ and $Y$ as measurable functions from $\Omega$ to the set of right-continuous functions, then we may use the well-known fact that almost-sure convergence entails convergence in distribution. However, this does not explain why Wengenroth writes $Y \overset{d}{=} Y^n$ rather than $Y^n \overset{d}{\rightarrow} Y$ . Another caveat is that the only metric I am familiar with on the set of right-continuous functions (actually on the set of continuous functions) is the metric of uniform convergence, or some variation thereof, whereas the convergence of $Y^n$ to $Y$ is only pointwise . Since $\sigma(Y^n) \subseteq \bigvee Y^n = \sigma(\bigcup \sigma(Y^n))$ , $Y$ is $\bigvee Y^n$ -measurable, so it suffices to show that $\bigvee Y^n$ and $\mathcal{F}^+_\tau$ are independent. If $\bigcup \sigma(Y^n)$ was a $\pi$ -system, this would follow from that fact that $\sigma(Y^n)$ and $\mathcal{F}^+_\tau$ are independent (see, for instance, lemma 3.6 on p. 50 in Kallenberg's ""Foundations of Modern Probability"", 2nd edition, Springer 2002 ). However, is $\bigcup \sigma(Y^n)$ a $\pi$ -system?","['probability-theory', 'levy-processes', 'markov-process', 'stochastic-processes']"
1301282,Understanding the Definition of a derivative as slope of a tangent line,"I'm trying to understand the derivative and am wondering why the derivative is described as the slope of the tangent line and not the slope of a function itself. Say $f(x) = 2x+5$
where $\frac{d}{dx}=2$, which is the slope of $2x+5$ We would say in algebra that $2$ is the slope of $f(x)$ but in calculus we now say that it is the slope of the tangent line. Is it incorrect to say that the derivative is the slope of the function at an infinitesimally small change in $x$?","['derivatives', 'calculus', 'integration']"
1301324,Proof of the right and left cancellation laws for Groups [duplicate],"This question already has answers here : How to prove $b=c$ if $ab=ac$ (cancellation law in groups)? (6 answers) Closed 8 years ago . I was asked to proof the right and left cancellation laws for groups, i.e. If $a,b,c \in G$ where $G$ is a group, show that $ba = ca \implies b=c $ and $ab = ac \implies b = c$ For the first part, I went about saying $$ba = ca \iff a = b^{-1}ca \iff b^{-1}c = e \iff (b^{-1})^{-1} = c \iff b = c$$ Similar proof for the second part. However, I am afraid that I am thinking in circles here. Is this a valid proof?","['abstract-algebra', 'group-theory', 'proof-verification']"
1301325,Finding the limit of a recursively defined sequence (recurrence relation). Specifically and generally,"Whilst reading Goldrei's Classic Set Theory, I have come across a recursively defined sequence $a_0=0, a_1=1, a_n=\frac{1}{2}\left(a_{n-1} + a_{n-2} \right) $ The first few terms of which are: $0, 1, \frac{1}{2}, \frac{3}{4}, \frac{5}{8}, \frac{11}{16}, ... $ It is easy to show the successive terms get closer to one another $ |a_n - a_{n-1} |= | \frac{1}{2}\left(a_{n-1} + a_{n-2}\right) - a_{n-1} |$
$ = \frac{1}{2}|a_{n-1} - a_{n-2}|  $ Inducting on the ""first difference"" gives $ |a_n - a_{n-1} | = \frac{1}{2}^{n-1}|a_1 - a_0| $
$ = \frac{1}{2}^{n-1} $ So I have shown that the difference between each successive term approaches zero, i.e. the sequence approaches a limit. How do I find the limit of the recursively defined sequence? How are these types of problems (recursively defined functions) generally approached? It is: Show the sequence converges ...","['limits', 'recurrence-relations', 'sequences-and-series', 'recursion', 'cauchy-sequences']"
1301353,Function with Multiple Periods,"Basically I'm trying to fit some data with seasonal effects to a periodic function, and the problem I'm running into is that the local minima usually occur around April, and the local maxima usually occur around December. So the distance from peak to trough is 4 months, but the distance from trough to peak is twice that. I'm wondering what the general form of a function with that behavior looks like. Thank you!","['periodic-functions', 'statistics', 'algebra-precalculus']"
1301365,Does a homogeneous metrizable space admit a compatible homogeneous metric?,Assume that X is a compact metrizable topological space for which the action of homeomorphism group is transitive. Is there a compatible metric d on X such that the action of group of isometries of X is a transitive action? What about if we restrict X to be a manifold?,"['metric-spaces', 'smooth-manifolds', 'riemannian-geometry', 'general-topology']"
1301369,solution to differential equation from deriving power series,"Find the solution of the differential equation 
$$y'= 2xy$$
statisfying $y(0)=1$, by assuming that it can be written as a power series of the form $$ y(x)=\sum_{n=0}^\infty a_nx^n.$$ Im advised to derive the reccurrence relation between the coefficient of thie series and write out the first three non-zero terms of the series explicitly. Struggling to understand and fully complete these types of problems. I have only been able get to a stage where I combine like terms then get lost on where to take it. I'd very much appreciate an explanation to this.","['power-series', 'calculus', 'ordinary-differential-equations']"
1301375,Stochastic calculus - Ito confusion,"We have $W(t) = f(t)X(t)$. My textbook says that $dW = fdX + X\dfrac{df}{dt} dt$. I don't get how they arrived at this conclusion. I get the first part, because $\dfrac{dW}{dX}dX = fdX$. But for the second part, I have no clue how they arrived there. $(\dfrac{dW}{dt} + \dfrac{1}{2} \dfrac{d^2W}{dX^2})dt \stackrel{?}{=} X\dfrac{df}{dt} dt$ If so, could someone please explain why?","['stochastic-calculus', 'derivatives']"
1301378,martigale convergence theorems,"Let $S_n = X_{1}+\cdots + X_{n}$ be a martingale satisfying $E[X_{k}^{2}]\leq k<\infty$, for all $k$. Show that $S_{n}$ obeys the weak law of large numbers:
$$P\left(\left|\dfrac{S_{n}}{n}\right|>\epsilon\right)\rightarrow 0,$$ as $n\rightarrow \infty,$ for any positive $\epsilon$. Note: I used the inequality Markov and got catching up $\dfrac{1}{2\epsilon^{2}}$ $\displaystyle{E[S_{n}^{2}]=\sum_{i=1}^{n}E[X_{i}^{2}]+\sum_{0\leq i<j\leq n}^{n}E[X_{i}X_{j}]}$, but as $S_n$ is martingale we have that $E[X_{i}X_{j}]=0$ Can anyone help me?","['probability-theory', 'martingales', 'law-of-large-numbers', 'stochastic-processes']"
1301388,Probability of drawing a pair of brown socks,"You have a drawer with $6$ loose blue socks, and $10$ loose brown socks. If you grab two socks from the drawer in the dark (random draw), what is the probability that you draw a brown pair? I have $\frac{5}{8}=\frac{10}{16}=.625$.",['probability']
1301414,Prove that $|\sin^{−1}(a)−\sin^{−1}(b)|≥|a−b|$,"Question: Using the Mean Value Theorem, prove that $$|\sin^{−1}(a)−\sin^{−1}(b)|≥|a−b|$$ for all $a,b∈(1/2,1)$. Here, $\sin^{−1}$ denotes the inverse of the sine function. Attempt: I think I know how to do this but I want to make sure that I am as detailed as possible so I get all the marks. Here is my attempt: Define $f:[-1,1] \rightarrow [-\pi/2,\pi/2]$ by $f(x)=\sin^{-1}(x)$. This is a differentiable function on $(-1,1)$ and continuous on $[-1,1]$. 'Without loss of generality' assume $a<b$. Our $f$ is continuous on $[a,b]$ and differentiable on $(a,b)$ since $[a,b] \subset [-1,1]$. By MVT, there exists $c \in (-1,1)$ such that $$\frac{f(b)-f(a)}{b-a}=\frac{\sin^{−1}(a)−\sin^{−1}(b)}{b-a}=f'(c)=\frac1{\sqrt{1-c^2}}\geq 1$$ which gives us: $\sin^{−1}(a)−\sin^{−1}(b) \geq b-a$ and then giving the desired result by putting modulus on both sides. My concern is that i said $a<b$. Am i allowed to do that? And more importantly I let $c \in(-1,1)$ and not $(a,b)$. Is that wrong? If I did let it in $(a,b)$ then its impossible to say that it is $\geq 1$...",['real-analysis']
1301429,problems with differential equation,"i have problems solving eq. 
$$ u + \log(u-1) = \log (x); \quad u= \frac{y}{x}$$
which comes from solving diff equation 
$$x \frac{dy}{dx} - y= x\frac{y-x}{y+x}$$
any hints? thanks in advance",['ordinary-differential-equations']
1301432,"For any rng $R$, can we attach a unity?","Let $R$ be an rng. (There may be no unity) Then, does there always exist a ring (with unity) $A$ such that $R$ is a subrng of $A$?","['abstract-algebra', 'rngs', 'ring-theory']"
1301434,unramified quadratic extensions of 2-adic numbers,"i already know how to get the 7 quadratic extensions of $\mathbb{Q}_2$ from hensel's lemma. they are $\mathbb{Q}_2(\sqrt{d})$ for d = -10, -5, -2, -1, 2, 5, 10. question: which of these are unramified? i looked it up (local fields, cassels) and it says the answer is d=5 is unramified and the rest are totally ramified, but his argument uses the discriminant which wasn't covered in the course i'm taking EDIT: so i can work out that the ones where d is even are totally ramified by using the result that L/K is totally ramified iff L=K[a] where a is a root of an eisenstein polynomial, so that leaves the three odd cases","['number-theory', 'local-field']"
1301448,System of 3 differential equations,"I'm trying to solve this system
$$
\begin{align}
x'&=x-3y+3z\\
y'&=-2x-6y+13z\\
z'&=-x-4y+8z
\end{align}
$$
must be reduced to a single equation
I tried to express the x 3 and substitute in the other two
but then I have not reduced y or z
I can not understand how to solve it Euler method can not be solved because it is written in the job to reduce to a single equation","['systems-of-equations', 'ordinary-differential-equations']"
1301450,Irreducible curve contained in linear subspace,Can someone give me a starting point for the following question? I don't know where to begin! Let $C \subset \mathbb{P}^n$ be an irreducible curve of degree $d$. Show that $C$ is contained in a linear subspace of $\mathbb{P}^n$ of dimension $d$.,['algebraic-geometry']
1301465,Proof Bell-Number $B(n+1)=\sum\limits_{i=0}^n\binom{n}{i}B(i)$,"Let B(0) := 1 und B(n) for n$\geq$1 the counts of all sets partitions of [n]. The numbers B(n) are the Bell-numbers. For $n \geq 0$ prove that: 
\begin{equation}
B(n+1)=\sum\limits_{i=0}^n\binom{n}{i}B(i)
\end{equation} I think to construct a subset of i-elements $A_i$ of [n] split $A_i$ in k not empty and disjunct blocks $B_1\dots B_k$ where $A_i= \bigcup \limits_{i=1}^k B_i$ We have another k+1 block $B_{k+1}=[n]$ \ $A_i \cup \{n+1\}$
So we have a set of partion of [n+1] in k+1 portions for 1: there are $\binom{n}{i}$ ways
for 2: there are B(n) ways if we sum on n then we become $B(n+1)=\sum\limits_{i=0}^n\binom{n}{i}B(i)$ What is wrong in this proof ?","['discrete-mathematics', 'combinatorics']"
1301477,Application Stokes's Theorem,"I am a bit unsure the way Stoke's theorem is applied in this case. Evaluate $\oint\limits_C {xydx + yzdy + zxdz} $ around the triangle with vertices $(1,0,0), (0,1,0), and (0,0,1)$, oriented clockwise as seen from the point $(1,1,1)$ My reasoning Since Stokes's theorem says that we can sum up individual microscopic rotations, i.e. we can turn a line integral into a double integral: $$\oint\limits_C {xydx + yzdy + zxdz}  = \iint\limits_D {\nabla  \times \vec F \cdot \hat NdS} =  - \iint\limits_D {(y,z,x) \cdot \hat NdS}$$ Then, I used parametrization $r = (u,v,1 - u)$. The surface element turns out to be $$d{\mathbf{S}} = \frac{{\partial (x,y,z)}}{{\partial (u,v)}}dudv  = (1,0,1)dudv$$ So, the integral is
$$\iint\limits_{D'} {u + vdudv} = \int\limits_0^1 {\int\limits_0^{1 - v} {u + vdudv = \int\limits_0^1 {(1 - v)v + \frac{{{{(1 - v)}^2}}}{2}dv}  = \frac{1}{2}\int\limits_0^1 {1 - {v^2}dv}  = \frac{1}{2}\int\limits_0^1 {1 - {v^2}dv}  = \frac{1}{3}} } $$ According to the answer, it should be $1/2$. Is this correct application of Stokes's theorem?","['surface-integrals', 'calculus', 'multivariable-calculus']"
1301488,maximal linear subspaces contained in the cone over the Clifford torus.,"Forgot: this is about Find a subspace of $\mathbb{R}^4$ for which $x^T*A*x$ = 0 I was a little surprised to find that, in the cone $x^2 + y^2 = z^2 + w^2$ in $\mathbb R^4,$ there are infinitely many 2-planes passing through the origin and completely contained in the cone. Indeed, take any real vector $(A,B,C,D)$ with $A^2 + B^2 = C^2 + D^2,$ we can make a 2-plne in the cone from the linear span of
$$ (A,B,C,D) \; \; \; \rm{and} \; \; (-B,A,-D,C).  $$
We get a different 2-plane (I think) from the sapn of
$$ (A,B,C,D) \; \; \; \rm{and} \; \; (-B,A,D,-C).  $$
I also think that is it, for each nonzero vector in the cone, two 2-planes containing it. So far, I do not see anything in my many quadratic forms books that predicts this, but I could be looking in the wrong places. I would like confirmation of all that. The cone over the Clifford torus is an important object in the differential geometry of minimal and constant mean curvature submanifolds. An early reference is Blaine Lawson (1970) in the Annals. Meanwhile, given positive integers $(p,q)$ and the cone in $\mathbb R^{p+q}$ given by
$$ x_1^2 + \cdots + x_p^2 \; = \;   x_{p+1}^2 + \cdots + x_{p+q}^2,   $$
what is the highest dimension of a linear subspace (through the origin) that is entirely contained in the cone? Finally, is there some finiteness result such as I got above, given this many independent vectors in the cone, these complete to a maximal linear subspace in exactly two(?) ways? A few hours later: managed to relate this to something familiar. In $\mathbb R^3,$ the hyperboloid of one sheet $x^2 + y^2 = z^2 + 1$ is doubly ruled, two families of straight lines. If we intersect the cone $x^2 + y^2 = z^2 + w^2$ with the 3-plane $w=1,$ we get that doubly ruled hyperboloid. Furthermore, the original cone contains the cone over each of those straight lines, giving two $2$-planes for each point in the hyperboloid. http://en.wikipedia.org/wiki/Hyperboloid and http://en.wikipedia.org/wiki/Ruled_surface","['algebraic-geometry', 'differential-geometry', 'quadratic-forms']"
1301498,Graph of the function $y = 2 + (x + 1)^3$,"I know that this function will have the behavior of $Y = X^3$ but as I will translate for this function $(Y = X^3)$? I do this: 
$$(x + 1)^3 = x^3 + 3x^2 + 3x + 3 \quad y = x^3 + 3x^2 + 3x + 5$$
But don't know how to make the next step, for example I want to do the same with what I did with this function: 
$$y = x^4$$
$$y = (x^2)^2$$
$$Y = X^2 \quad Y = y^X = x^2 \rightarrow x = \sqrt X$$ It is possible? **UPDATE : The solution I wanted to find was: Y = X³ y = 2 + (x + 1)³ y - 2 = (x + 1)³ Y = y - 2 X = x + 1 So the origin (0,0) of my graph is: y = 2 x = -1 This is pre-calculus and is only required to have an intuitive notion. I find it much more practical to think in the graph itself","['algebra-precalculus', 'functions']"
1301499,Proof that $n\Bbb Z \leq \Bbb Z$ and are the only subgroups of $\Bbb Z$,"My challenge is Prove that if $n = 0,1,2,\ldots$ and $n\Bbb Z = \lbrace nk: k \in \Bbb Z \rbrace$, show that $n\Bbb Z$ is a subgroup of $\Bbb Z$ and are the only subgroups. I handled the first point by saying that i) Identity is 0, and $0\in n\Bbb Z$ and $0 \in \Bbb Z$ ii) For any $a,b \in n\Bbb Z$ $a+b = na_2 + nb_2 = n(a_2+b_2) \in n \Bbb Z$ iii) For any $na \in n\Bbb Z$, its inverse $n(-a) \in n\Bbb Z$. For the second point, I said that all of the subgroups should be infinite, because for any finite group the largest element $a+a \notin H$, where $H$ is the potential subgroup, which is a contradiction. So $H$ must be of infinite order. For any $a \in H, -a$ should also be in $H$. The difference between any $a,b \in H$ should also be in $H$, i.e. $(a-b) \in H$. This leaves only the whole group or any group of the form $n\Bbb Z$. Is my proof complete?","['abstract-algebra', 'group-theory', 'proof-verification', 'infinite-groups']"
1301507,Confused about proof that diameter of a closure of a set is the same as the diameter of the set.,"Definition Let $E$ be a nonempty subset of a metric space $X$ , and let $S$ be the set of all real numbers of the form $d(p,q)$ , with $p,q \in E$ . The supremum of $S$ is called the diameter of $E$ . Theorem If $\bar{E}$ is the closure of the set $E$ in a metric space $X$ , then $ \text{diam}  \ \bar{E} = \text{diam} \  E.$ Proof Since $E \subset \bar{E},$ it is clear that $$ \text{diam} \  E \leq \text{diam} \ \bar{E}.$$ Fix $\epsilon > 0,$ and choose $p,q \in \bar{E}.$ By the definition of $\bar{E}$ , there are points $p', q',$ in $E$ such that $d(p,q') < \epsilon$ and $d(q,q') < \epsilon.$ Hence \begin{align*}
d(p,q) &\leq d(p,p') + d(p',q') + d(q',q)\\
&< 2 \epsilon + d(p',q')\\ 
&\leq 2 \epsilon + \text{diam} \ E.
\end{align*} It follows that $$ \text{diam} \ \bar{E} \leq 2 \epsilon +  \text{diam} \ E,$$ and since $\epsilon$ was arbitrary, (a) was proved. The step prior to the last, namely that $ \text{diam} \ \bar{E} \leq 2 \epsilon +  \text{diam} \ E$ , was lost to me. We have $d(p,q) \leq \text{diam} \ \bar{E} $ , but how do we know $ \text{diam} \ \bar{E}$ is less than or equal to the term on the right in the previous inequality?","['analysis', 'metric-spaces']"
1301519,Find the number of possible points $R$.,"$P(3,1),Q(6,5)$ and $R(x,y)$ are three points such that the angle $\angle PRQ=90^{\circ}$ and the area of the triangle $\triangle PRQ=7$.The number of such points $R$ that are possible is . $a.)\ 1\\
b.)\ 2\\
c.)\ 3\\
d.)\ 4\\
e.)\ 0\\$ For $\angle PRQ$ to be right angled, The point should lie on equation of circle with $PR$ as diameter. $\left(x-\dfrac92\right)^2+(y-3)^2=\left(\dfrac52\right)^2$ And with the formula for area of triangle i found, $4x-3y=-5\ \text{or}\\
4x-3y=23$ By graphing it i found that no possible values for $R$. How do i find that by pen and paper. I look for a short and simple method. I have studied maths upto $12th$ grade.","['geometry', 'coordinate-systems']"
1301550,Simple trigonometry equation,"The previous class we were doing trigonometry exercises. Before the class finished, our teacher wrote exercises on the table. I am stuck with the following one: $$
\cos(2x) + 1 + 3\sin x = 0
$$ I have come up with this: $$
1= \sin^2 x + \cos^2 x
$$
$$
\cos(2x) = \cos^2 x - \sin^2 x
$$ When we substitute we get $$
2\cos^2 x + 3\sin x = 0
$$ Need to find $x\ldots$",['trigonometry']
1301557,Can a $1d$ space never be curved?,"I was wondering about this: Wikipedia article I refer to (here I refer to the first part: metric)
This wikipedia article claims that this hyperbolic space model has constant curvature $-1.$ I believe they are talking about sectional curvature here, because they write down a metric in $n-$ coordinates. Now, I have two questions: What is about $n=1$: In that case, I think a Riemann curvature tensor will always be zero due to its symmetry properties, so there cannot be any curvature for the $1d$ case, right? Is there a way to argue that since the sectional curvature is $-1$ in the case of $n=2$ (Gauss curvature of Poincaré disk is -1) it has to be $-1$ for $n \ge 3$ and any plane, too? By a symmetry argument, the sectional curvature should be independent of the plane we are considering at a point for $n \ge 3$(because the metric is the same in all coordinates). Actually, I would assume that a metric that is conformal to the identity always has this property. Despite, I don't see why it has to be $-1$ too for $n \ge 3$ without carrying out a cumbersome calculation.","['riemannian-geometry', 'real-analysis', 'manifolds', 'differential-topology', 'differential-geometry']"
1301602,period of $\cos(x) + x - \lfloor x \rfloor$?,"What is the period of $\cos(x) + x - \lfloor x \rfloor$? This is what I have done: $x = \lfloor x \rfloor + \{x\}$ $\cos(x)$ has period $2\pi$ $\{x\}$ has period $1$ so $\cos(x) + \{x\}$ should be periodic with the period of LCM of $2\pi$ and $1$ but the solution is stated as NOT PERIODIC.
How is the function non-periodic?",['functions']
1301630,Decomposition of hyper-rectangles into congruent simplices,"Let $(a_1, \ldots, a_d) \in \mathbb{N}_+^d$ be positive integers and the semi-axes of the $d$-dimensional $\ell_1$-ellipse 
$$ E_{\bf a} := \{{\bf x} \in \mathbb{R}_{\geq 0}^d: \sum_{j=1}^d \frac{x_j}{a_j} \leq 1 \}, $$
which also is a simlex with the $(d+1)$ integer vertices $(0,\ldots,0), (a_1,0,\ldots,0)$, $(0,a_2,0,\ldots, 0), \ldots,  (0,\ldots,0,a_d)$ .
Now, $E_{\bf a}$ is contained in $R_{\bf a} := \{{\bf x} \in \mathbb{R}_{\geq 0}^d: \frac{x_j}{a_j} \leq 1 \}$, i.e. the multi-dimensional rectangle anchored at ${\bf 0}$ that has side-lengths $a_j$. We can assume that the a_j are ordered, i.e. $a_1 \geq a_2 \geq \ldots \geq a_d \geq 1$. In the two-dimensional setting $d=2$, we can decompose the rectangle $R_{\bf a}$ into
$$ R_{\bf a} =  E_{\bf a} \cup \hat{E}_{\bf a},$$
where 
$$\hat{E}_{\bf a} := \{ (a_1 - x_1, a_2 - x_2) | (x_1,x_2) \in E_{\bf a}  \}$$
also has integer vertices . Moreover, $E_{\bf a} \cap \hat{E}_{\bf a}$ is a null set and $\hat{E}_{\bf a}$ is congruent to $E_{\bf a}$. Now comes my question: Is such a construction also possible in the higher dimensional setting, i.e. $d\geq 3$? I suppose (by comparing volumes) one needs at least $d!$ (congruent) copies of $E_{\bf a}$? Unfortunately, I have severe difficulties with spatial visualization and already for $d=3$, I was not able to figure out a valid decomposition of $R_{\bf a}$. I hope someone can guide me to a solution or tell me the vertices of the $6$? tetrahedrons. Thanks!","['triangulation', 'geometry', 'discrete-mathematics']"
1301656,Behavior of MGF of Quadratic Combination of Dependent Multivariate Gaussians,"Sorry if the formatting is poor, this is my first time asking a question.  I'm investigating how squared gaussians behave, using the techniques provided here , which are giving me inconsistent results.  Here's the (simplified) setup:  I have four random variables, $Q_1, Q_2, Q_3, Q_4$, which are distributed as follows:
$$
\left[ \begin{array}{c}
Q_1\\
Q_2\\
Q_3\\
Q_4\\
\end{array} \right] \sim 
N_4\left(\left[\begin{array}{c}
0\\
0\\
0\\
0
\end{array} \right],
\left[ \begin{array}{cccc}
1&0&\alpha&0\\
0&1&0&\beta\\
\alpha&0&1&0\\
0&\beta&0&1\\
\end{array} \right]\right)\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \alpha,\beta \in [0,1]
$$ I'm dealing with the distribution $BQ_1^2 + CQ_2^2 - 2Q_1Q_2$ (D1) where $B,C$ are constants.  Furthermore I want to contrast the behavior of that distribution to distribution $\frac{1}{2}(BQ_1^2 + CQ_2^2 - 2Q_1Q_2 + BQ_3^2 + CQ_4^2 - 2Q_3Q_4)$ (D2), under the circumstances where $\alpha = \beta = 1$.  Ideally, and as I understand it, they are distributed the same way under that correlation assumption, as the repeated terms are perfectly correlated.    Using the techniques mentioned in the linked question, and an ""A"" matrix (again, see the question I linked to above) that looks like
$$
\left[ \begin{array}{cccc}
B&-1&0&0\\
-1&C&0&0\\
0&0&B&-1\\
0&0&-1&C\\
\end{array} \right]
$$ I get that (D2) as above is distributed according to $$\frac{1}{2}\left(\left(\frac{\sqrt{1 - \alpha}}{2} + \frac{\sqrt{1 + \alpha}}{2}\right)^2 BT_1 + \left(\frac{\sqrt{1 - \beta}}{2} + \frac{\sqrt{1 + \beta}}{2}\right)^2 CT_2 + \left(\frac{\sqrt{1 - \alpha}}{2} + \frac{\sqrt{1 + \alpha}}{2}\right)^2 BT_3 + \left(\frac{\sqrt{1 - \beta}}{2} + \frac{\sqrt{1 + \beta}}{2}\right)^2 CT_4\right)$$ where each $T_i$ is an independent chi square random variable with d.o.f. 1.  Under the assumption that $\alpha = \beta = 1$, this becomes
$$\frac{1}{2}\left(\frac{1}{2}BT_1 + \frac{1}{2}CT_2 + \frac{1}{2}BT_3 + \frac{1}{2}CT_4\right)$$
  However, using a truncated $A$ matrix to discern the distribution of $D1$,
$$
\left[ \begin{array}{cc}
B&-1\\
-1&C\\
\end{array} \right]
$$
And similarly a truncated covariance matrix that is just the 2X2 identity,
I get that $(D1)$ is distributed according to 
$$\frac{1}{2}(B + C - \sqrt{4 + B^2 - 2 B C + C^2})Y_1 + \frac{1}{2}(B + C + \sqrt{4 + B^2 - 2 B C + C^2})Y_2$$
Where $Y_i$ are again independent chi square random variables with d.o.f. 1. My issue is that $\frac{1}{2}(B + C - \sqrt{4 + B^2 - 2 B C + C^2})Y_1 + \frac{1}{2}(B + C + \sqrt{4 + B^2 - 2 B C + C^2})Y_2$ doesn't particularly look like $\frac{1}{2}\left(\frac{1}{2}BT_1 + \frac{1}{2}CT_2 + \frac{1}{2}BT_3 + \frac{1}{2}CT_4\right)$, even though we would expect that $BQ_1^2 + CQ_2^2 - 2Q_1Q_2 = \frac{1}{2}(BQ_1^2 + CQ_2^2 - 2Q_1Q_2 + BQ_3^2 + CQ_4^2 - 2Q_3Q_4)$ when $Q_1 = Q_3$ and $Q_2 = Q_4$.  I've tried massaging them to work out the same to no avail; it turns out the rest of my mathematics not shown here allows me to put these ""into"" moment generating functions.
The relevant term for $(D1)$ becomes $$(1- (B + C - \sqrt{4 + B^2 - 2 B C + C^2}))^\frac{1}{2}(1-(B + C + \sqrt{4 + B^2 - 2 B C + C^2}))^\frac{1}{2}$$
and the relevant term for (D2) becomes $$(1-\frac{1}{2}B)^\frac{1}{2}(1-\frac{1}{2}C)^\frac{1}{2}(1-\frac{1}{2}B)^\frac{1}{2}(1-\frac{1}{2}C)^\frac{1}{2}$$
$$=(1-\frac{1}{2}B)(1-\frac{1}{2}C)$$
which appears to have no hope of being equal just by virtue of dimensionality.
What am I doing wrong?  I am fairly convinced that these things should be equal in the perfectly correlated case, and yet here I am, and they are not at all equal.
Something else I noted was that the distribution for (D2) isn't sensitive to adjustments in the off diagonal values of the $A$ matrix, but the distribution for (D1) is.  That is to say, if we replace all the values of $-1$ in the matrices by $-\sqrt{2}$, the chi squared decomposition for (D2) remains the same but is different for (D1). As I said at the top, I left some things out.  I can include them if this picture is not clear enough.","['statistics', 'linear-algebra', 'moment-generating-functions']"
1301688,What is $X\cap\mathcal P(X)$?,"Does the powerset of $X$ contain $X$ as a subset, and thus $X\cap \mathcal{P}(X)=X$, or is $X\cap \mathcal{P}(X)=\emptyset$ since $X$ is a member of the 
$\mathcal{P}(X)$, and not a subset?",['elementary-set-theory']
1301692,"$M_1 \to M_2 \to M_3 \to 0$ exact iff $0 \to \text{Hom}_A(M_3, N) \to \text{Hom}_A(M_2, N) \to \text{Hom}_A(M_1, N)$ is exact. [duplicate]","This question already has answers here : Characterization of short exact sequences (2 answers) Closed 9 years ago . Let $M_1 \to M_2 \to M_3 \to 0$ be a sequence of homomorphisms of $A$-modules. Is this sequence exact if and only if the induced sequence of abelian groups$$0 \to \text{Hom}_A(M_3, N) \to \text{Hom}_A(M_2, N) \to \text{Hom}_A(M_1, N)$$is exact for every $A$-module $N$?","['exact-sequence', 'abstract-algebra', 'modules']"
1301701,What is $\mathbb{Z}[i] \otimes_{\mathbb{Z}[2i]} \mathbb{Z}[i]$?,"What is $\mathbb{Z}[i] \otimes_{\mathbb{Z}[2i]} \mathbb{Z}[i]$? Also, since $\mathbb{Z}[i]$ is a PID, we should be able to write this $\mathbb{Z}[i]$-module as a direct sum of cyclic $\mathbb{Z}[i]$-modules. Can we?","['abstract-algebra', 'tensor-products', 'modules', 'ring-theory']"
1301708,"Given $\csc\theta=-\frac53$ and $\pi<\theta<\frac32\pi$, evaluate sine ,cosine, and tangent of $2\theta$","If $\csc\theta=\frac{-5}{3}$, what is the exact value of $\tan(2\theta)$, $\sin(2\theta)$, and $\cos(2\theta)$ on the interval of $\left(\pi, \frac{3\pi}{2}\right)$? I think I'm getting the fraction negatives wrong. I've used the sine formula($2\sin{\theta}\cos{\theta}$), the cosine formula ($2\cos^2{\theta}-1$) and the tangent formula, $\left(\frac{\sin(2\theta)}{\cos(2\theta)}\right)$ originally answering the problem I got $\sin(2\theta)=\frac{24}{25}$,
 $\cos(2\theta)=\frac{7}{25}$, and $\tan(2\theta)=\frac{24}{7}$",['trigonometry']
1301712,Lines on a quadric surface,"I want to show that: Let $Q$ be a quadric surface of rank 3 in $\mathbf{P}^3$(over $\mathbf{C}$), then any line in $Q$ must pass through the only singular point of $Q$. I know that up to a transform of coordinate, we can assume that $Q=\{x_0^2+x_1^2+x_2^2=0\}$ and therefore the singular point is $(0:0:0:1)$. But I have no idea how to proceed. Thanks for any help.","['euclidean-geometry', 'algebraic-geometry', 'geometry', 'projective-geometry']"
1301728,"Looking for a proof of Cleo's result for ${\large\int}_0^\infty\operatorname{Ei}^4(-x)\,dx$","In this answer Cleo posted the following result without a proof:
$$\begin{align}\int_0^\infty\operatorname{Ei}^4(-x)\,dx&=24\operatorname{Li}_3\!\left(\tfrac14\right)-48\operatorname{Li}_2\!\left(\tfrac13\right)\ln2-13\,\zeta(3)\\&-32\ln^32+48\ln^22\cdot\ln3-24\ln2\cdot\ln^23+6\pi^2\ln2,\end{align}\tag1$$
where $\operatorname{Ei}$ is the exponential integral :
$$\operatorname{Ei}(x)=-\int_{-x}^\infty\frac{e^{-t}}tdt.\tag2$$
The result confirms numerically with at least 1000 decimal digits of precision. How can we prove this result?","['calculus', 'special-functions', 'closed-form', 'definite-integrals', 'integration']"
1301736,"Angle form, 1-form, proof verification.","Check that the $1$-form $d\,\text{arg}$ in $\mathbb{R}^2 - \{0\}$ is just the form$${{-y}\over{x^2 + y^2}}\,dx + {{x}\over{x^2 + y^2}}\,dy.$$ My solution is as follows. Observe that we can define $\text{arg}\,z= \tan^{-1}(y/x)$ locally. This definition only works if $\text{arg}\,z$ is congruent to $\theta$ modulo $2\pi$ for some $\theta \in (-\pi/2,\pi/2)$. If $\text{arg}\,z$ is outside this range, we just add $\pi$ to it, leaving the exterior derivative unchanged. Taking this to be a $0$-form, we calculate its exterior derivative, as follows.$$d\left(\tan^{-1}\left({y\over{x}}\right)\right) = {{\partial f}\over{\partial x}}dx + {{\partial f}\over{\partial y}}dy = -{y\over{x^2 + y^2}}dx + {x\over{x^2 + y^2}}dy.$$In neighborhoods of $\pm\pi/2$, we instead define $\text{arg}\,z = \cot^{-1}(x/y)$, seeing that it is not clear that our earlier definition of $\text{arg}\,z$ is even continuous near $\pm\pi/2$. $\cot^{-1}(x/y)$ gets us the same exterior derivative as $\tan^{-1}(y/x)$, and it is well-defined, so we are done. My question is, is what I have valid? And is there a cleaner/simpler way of doing the problem/alternate perspective I'm missing? Much thanks in advance.","['real-analysis', 'manifolds', 'general-topology', 'differential-geometry', 'multivariable-calculus']"
1301749,Examples of base points of linear systems,"I'm reading Fulton's algebraic curves book and we have the following definitions: A divisor $D=n_1P_1+\ldots,n_kP_k$ ($n_i$'s are integers and $P_i$'s are points) over a curve. A linear system as the set of divisors $\{(f)+D\mid f\in L(D)\}$ A base point of a linear system is a point which is contained in every divisor of the linear system. I'm a really beginner with this subject which I'm finding very hard. I'm looking for simple examples of base points of a linear system. This would be a great motivation for me to learn these concepts and definitions. Any help is very welcome! Thanks","['algebraic-geometry', 'algebraic-curves']"
1301807,Triangle with Ratio of Sides Equal to Ratio of Angles,"In an equilateral triangle, the side lengths are in ratio 1:1:1, as are the angle measures. Are there also non-equilateral triangles in which the ratio of the side lengths is the same as the ratio of the angle measures? If so, what is an example of such a triangle?","['triangles', 'trigonometry']"
1301929,"Are there spaces that 'look the same' at every point, but are not homogeneous?","A metric space is homogeneous if for any two points there is a global isometry that maps one into the other. It is locally homogeneous if any two points have isometric neighborhoods, i.e. the space 'looks the same' near them. Take open flat disk, it is clearly locally homogeneous, but there is no global isometry that maps its center to any other point. However, the disk is incomplete near the boundary, and if we complete it boundary points will no longer 'look the same' as interior ones. Can complete connected Riemannian manifold be locally homogeneous but not homogeneous? How about closed one? I suspect yes, but I can not think of any examples. In cosmology locally homogeneous is usually just called homogeneous, but I wonder if this is in line with mathematical usage even for 'nice' spaces.","['geometry', 'riemannian-geometry', 'differential-geometry']"
1301935,Does the product functor preserve quotient maps?,"In Hatcher's Algebraic Topology , he presents a proof that if $(X,A)$ satisfies the homotopy extension property, and $A$ is contractible, then $X \simeq X/A$. Part of Hatcher's proof goes: Suppose that $q: X \to X/A$ is the quotient map. Taking a homotopy $f : X \times I \to X$ such that $f_t(A) \subseteq A$ for all $t$, he then reasons that $q \circ f: X \times A \to X /A$ descends to a homotopy $X /A \times I \to X/A$. It's clear to me how to define such a map for each $t$. I asked myself why a map defined that way for each $t$ should then be continuous on $X /A \times I$, and I wasn't sure. One way that we could guarantee it was continuous is if $q \times 1_I: X \times I \to X/A \times I$ had the characteristic property of the quotient. But I'm not sure whether this is the case. My questions are Is he reasoning that if $\varphi: S \to \overline{S}$ is a quotient map, then
$\varphi \times 1_T: S \times T \to \overline{S} \times T$ is a quotient map
for any topological space $T$? [ Edit: this is not true.] What is going on here categorically?
    I haven't before seen a situation where starting with a product $S \times T$, we then obtain $\overline{S} \times T$, where $\overline{S}$ is a quotient of $S$ (however we may define a quotient categorically). With regard to 1, I tried to prove this more general proposition, but ran into some problems. Taking $U \subseteq S \times T$ to be an open saturated set, I wanted to show that $(\varphi \times 1_T)(U)$ was open. Letting $x \in U$ I take a basic neighborhood of $x$ of the form $\mathcal{O}_S \times \mathcal{O}_T$, and I would like to show that it has open image $\varphi (\mathcal{O}_S) \times \mathcal{O}_T$. I can say that $\varphi (\mathcal{O}_S)$ is open if I know that $\mathcal{O}_S$ is saturated, but I'm not sure why I can assume this. Edit: I see here that since $I$ is locally compact Hausdorff, we have the result we want about the quotient, but the result is not true in general. I still wonder about the categorical part. Also, I wonder if what I'm saying is implicit in his presentation, or I am missing something easier.","['algebraic-topology', 'general-topology', 'category-theory']"
1301953,Does map induced by rotation preserve the volume form?,"Let $A: \mathbb{R}^n \to \mathbb{R}^n$ be a rotation. My question is, does the map of $S^{n-1}$ onto $S^{n-1}$ induced by $A$ necessarily preserve the volume form?","['real-analysis', 'manifolds', 'general-topology', 'differential-geometry', 'multivariable-calculus']"
1301972,How to prove the elementary inequality?,"The inequality is the following:
$$\frac{(1+x)^q-1}{x+x^q} \leq C(q),$$
where $q\in [1,+\infty)$  and $x > 0$, and the constant $C$ depends only on $q$. It's very nice if someone can provide the minimal value of $C(q)$, I guess the minimal value is $q$.",['analysis']
1301978,Questions about torsion of a curve in $\mathbb{R}^3$ and analogues of torsion in higher dimensions,"Suppose we have a curve $\alpha(s) : I \to \mathbb{R}^3$ parametrized by arc-length that has nowhere-vanishing second derivative, so that we are able to define the torsion $\tau(s)$ for every $s \in I$. It is clear to me that one can deform a curve in a way that can change the curvature by large amounts while keeping $\tau = 0$ everywhere. I think that it is possible to deform a curve in a way that we can vary torsion while keeping curvature fixed. I was wondering if anybody could give me a nice example of this. My second question involves extending the idea of torsion. As far as I understand, torsion measures the planarity of a curve. For a curve that is embedded in $\mathbb{R}^n$ is there a quantity indicating how far the curve is from being embedded in $\mathbb{R}^{n-1}$, and is this even useful?","['differential-geometry', 'curves']"
1301989,Let $f$ be a non-constant entire function. Prove that $f(z)=cz^n$ for some constant $c$ and positive integer $n$,"Let $f$ be a non-constant entire function satisfying the following conditions: $$f(0)=0$$ for each $M \gt 0$ the set $$\{z \mid \lvert f(z)\rvert \lt M\}$$ is connected. Prove that $f(z)=cz^n$ for some constant $c$ and positive integer $n$. My try: Since $f(0)=0$ and the zeroes of $f$ are isolated (as $f$ is non-constant), there exists a $r \gt 0$ such that $f(z) \ne 0$ for all $z$ satisfying $\{\lvert z\rvert \le r\}$ except $z=0$. (Call the set $C = \{z \mid \lvert z\rvert \le r\}$). Now $f(z)$ attains its minimum (say $\delta \gt 0$) on the circle $\{\lvert z\rvert = r\}$. Then $S = \{z \mid \lvert f(z)\rvert \lt \delta\}$ intersects $C$, and since $S$ is connected, it has to lie completely inside $C$. Moreover there is no zero of $f$ other than $0$. (Had it been so, it would have belonged to the set $S$ and hence would have lied completely inside $C$ which would have violated the choice of $r$. Somehow this should imply that $f$ is bounded away from the origin. I try to proceed by contradiction: Suppose not. Then for every $M \gt 0$ there exists a $z_0$ such that $\lvert z_0\rvert \gt r$ for any $r \gt 0$ we have $\lvert f(z_0)\rvert \gt M$. I go nowhere from here. If I can conclude that $f$ is bounded away from origin, then I would be through for then $f$ would have a pole at $\infty$ and hence $f(z) = z^n$. How do I conclude that?? Thanks for the help!!","['analysis', 'complex-analysis']"
1301997,Show that $f(z)$ is constant,"If $f(z)=u(x,y) + iv(x,y)$ is an entire function such that $u\cdot v$ is constant then $f(z)$ is constant. I know that I need to use the Cauchy-Riemann equations, but I don't know how to start. Should I differentiate $u\cdot v$ with respect to $x$ or $y$ then substitute with Cauchy-Riemann?",['complex-analysis']
1302015,What is the relationship betweeen a pdf and cdf?,"I am learning stats. On page 20, my book, All of Statistics 1e,  defines a CDF as function that maps x to the probability that a random variable, X, is less than x. $F_{x}(x) = P(X\leq x)$ On page 23 it gives a function $P(a < X < b ) = \int_{a}^{b}f_{X}dx$ and then says that ""the function $f_{X}$ is called the probability density function. We have that..."" $F_{x}(x) = \int_{-\infty}^{x}f_{X}dt$ I am a little confused about how to characterize the most important difference between them. The equation above says that the cdf is the integral of the pdf from negative infinity to x. Is it fair to say that the cdf is the integral of the pdf from negative infinity to x?",['statistics']
1302016,"If $ x=\frac{\sin^3 t}{\sqrt{\cos 2t}}$ and $y = \frac{\cos^3 t}{\sqrt{\cos 2t}}\;,$ Then $ \frac{dy}{dx}$ in terms of $t$","If $\displaystyle x=\frac{\sin^3 t}{\sqrt{\cos 2t}}$ and $\displaystyle y = \frac{\cos^3 t}{\sqrt{\cos 2t}}\;,$ Then $\displaystyle \frac{dy}{dx}$ in terms of $t$ $\bf{My\; Try::}$ Using The Formula $\displaystyle \frac{dy}{dx} = \frac{\frac{dy}{dt}}{\frac{dx}{dt}}.$ Now Given $$\displaystyle x= \frac{\sin^3 t}{\sqrt{\cos 2t}}.$$ So $$\displaystyle \frac{dx}{dt} = \frac{\sqrt{\cos 2t}\cdot 3\sin^2 t \cdot \cos t-\sin^3 t \cdot \frac{1}{2\sqrt{\cos 2t}}\cdot -\sin 2t \cdot 2t}{\cos 2t}$$ So we get $$\displaystyle \frac{dx}{dt} = \frac{\cos 2t \cdot 3\sin^2 t \cdot \cos t+\sin^3 t \cdot \sin 2t \cdot t}{\cos 2t \cdot \sqrt{\cos 2t}}$$ Similarly Given $$\displaystyle y=\frac{\cos^3 t}{\sqrt{\cos 2t}}.$$ So $$\displaystyle \frac{dy}{dt} = \frac{-\sqrt{\cos 2t}\cdot 3\cos^2 t \cdot \sin t-\cos^3 t\cdot \frac{1}{2\sqrt{\cos 2t}}\cdot -\sin 2t \cdot 2t}{\cos 2t}$$ So we get $$\displaystyle \frac{dy}{dt} = \frac{-\cos 2t \cdot 3\cos^2 t \cdot \sin t+\cos^3 t\cdot \sin 2t\cdot t}{\cos 2t \cdot \sqrt{\cos 2t}}$$ So $$\displaystyle \frac{dy}{dx} = \frac{-3\cos^2 t \cdot \sin t\cdot \cos 2t+\cos^3 t\cdot \sin 2t\cdot t}{\cos 2t \cdot 3\sin^2 t \cdot \cos t+\sin^3 t \cdot \sin 2t \cdot t}$$ But this method seems complicated. Is there is any other method by which we can calculate $\displaystyle \frac{dy}{dx}$?",['algebra-precalculus']
1302039,"Is the powerset of the reals any ""more uncountable"" (in some sense) than the reals are?","I know that $\mathbb{N}$ is countable and has cardinality $\aleph_0$, and that $\mathbb{R}$ has cardinality $2^{\aleph_0} = \text{C}$ and is uncountable. Are sets with cardinalities greater than $\text{C}$ (like $2^{\mathbb{R}}$, for instance) ""more uncountable"" in some sense than the reals are? Edit: I am familiar with the proof of the fact that there is no bijection from a set to its powerset. What I'm looking for is this: do we lose some more properties when we go from $\mathbb{R}$ to $2^{\mathbb{R}}$, like we lose countability when we go from $\mathbb{N}$ to $\mathbb{R}$? Are there any notions of ""higher countability"", or some sort of analog of countability, that $\mathbb{R}$ has, but which we miss when we consider the powerset of the reals?","['elementary-set-theory', 'cardinals']"
1302054,$X - Y$ in a finite set,"Question: The domain is the power set of a finite set. $X$ is related to $Y$ if $X - Y$ is not empty. Is it a partial or strict order? If it is a partial order or strict order, is it also a total order? I don't quite understand this. Can anyone explain it to me in simple terms? Does $X - Y$ mean an element $X$ subtracted by an element $Y$ ?","['elementary-set-theory', 'definition']"
1302056,Could someone please explain double-angle identities?,"I don't understand how to do maths, mostly because I don't understand why formulae work they way they do, or the reasoning behind equations, etc. I tried to explain the $\sin(2\theta)$ double-angle identity to myself but failed: Hypothetically if: $$\text{opp} = 1 \qquad \text{adj} = 2 \qquad \text{hyp} = 3$$ then $$\begin{align*}
\sin(2\theta) &= 2\sin(\theta)\cos(\theta)\\\\
\left(\frac{\text{opp}}{\text{hyp}}\right)\cdot 2 &= 2\cdot\left(\frac{\text{opp}}{\text{hyp}}\right)\left(\frac{\text{adj}}{\text{hyp}}\right)\\\\
\frac{1}{3}\cdot 2 & = 2\left(\frac{1}{3}\right)\left(\frac{2}{3}\right)\\\\
\frac{2}{3} &\neq \frac{4}{9}
\end{align*}$$ Where did I go wrong?
How do the double-angle identities work?",['trigonometry']
1302099,$l^p$ space not having inner product,"I know that $l^2$ space is a Hilbert space. But for other $l^p$ spaces, where $p\geq1$, I have to show that they do not satisfy the parallelogram equality. But, I can't find appropriate sequences that become counterexamples of the parallelogram equality. Could anyone suggest me some sequences?","['lp-spaces', 'inner-products', 'hilbert-spaces', 'functional-analysis']"
1302105,Can every torsion-free nilpotent group be ordered?,"I know that a torsion-free abelian group can be ordered and have done two proofs for that too. But the next two question that popped up in my mind were- Can every  torsion-free nilpotent group be ordered? Can every  torsion-free solvable group be ordered? After googling I got to know that answer to first is positive but I could not  find a proof. I am thinking on it. May be use induction on class of nilpotent group as it is usually useful with nilpotent groups. If anyone can guide me on that , I will be thankful. What is the answer for solvable, or is it unknown?","['ordered-groups', 'group-theory']"
1302106,Finding the mode of the negative binomial distribution,"The negative binomial distribution is as follows: $\displaystyle f_X(k)=\binom{k-1}{n-1}p^n(1-p)^{k-n}.$ To find its mode, we want to find the $k$ with the highest probability. So we want to find $P(X=k-1)\leq P(X=k) \geq P(X=k+1).$ I'm getting stuck working with the following: If $P(X=k-1)\leq P(X=k)$ then $$1 \leq \frac{P(X=k)}{P(X=k-1)}=\frac{\binom{k-1}{n-1}p^n(1-p)^{k-n}}{\binom{k-2}{n-1}p^{n}(1-p)^{k-n-1}}.$$ First of all, I'm wondering if I'm on the right track.  Also, I'm having problems simplifying the binomial terms.","['probability', 'statistics']"
1302108,Do positive-definite matrices always have real eigen values?,"Do positive-definite matrices always have real eigenvalues? I tried looking for examples of matrices without real eigenvalues (they would have even dimensions). But the examples I tend to see all have zero diagonal entries. So they are not positive definite. Would anyone have an example of positive-definite matrix without any real eigenvalue? Or it is a property of positive-definite matrices that they always have some real eigenvalues? EDIT: A matrix $A$ is positive definite iff $\forall x, x^TAx>0$. No symmetry is implied here.","['linear-algebra', 'matrices']"
1302129,Filter of sets containing a subset converges,"I'm just learning about filters, and I came across the following exercise in Willard's Topology : Let $X$ be a topological space and $A \subset X$. The cluster points
  of the filter $\mathcal{F} = \{ U \subset X \mid A \subset U \}$
  include each point of $\overline{A}$. Under what conditions (on $A$ or
  on the topology) will $\mathcal{F}$ converge to some point? The answer I got was: $\mathcal{F}$ will converge to some point $x \in A$ iff it converges to every point $x \in A$ iff the subspace topology on $A$ is the indiscrete topology. In particular, if $A$ is not a singleton, $X$ cannot be Hausdorff if $\mathcal{F}$ converges to some point. Does anyone see any mistakes, or have anything to add?","['filters', 'general-topology']"
1302136,"Strings in a dictionary. A partial order, strict order, and total order?","Question: 
The domain is the set of all words in the English language (as defined by, say, Webster's dictionary). Word $x$ is related to word $y$ if $x$ appears as a substring of y. For example, ""ion"" is related to the word ""companions"" because the letters i-o-n appear in order in the word ""companions"".
Is it a partial order, strict order, and is it a total order? My thoughts:
It is reflexive because a $x$ being a substring of $y$ makes it a substring of itself. It is transitive because if it is a substring of $y$ and $y$ is a substring of $z$ then it is a substring of $z$. It is antisymmetric because if $x$ is a substring of $y$ and $y$ is a substring of $x$ then they are the same. Am I doing this right?","['elementary-set-theory', 'definition']"
1302155,Straight line equation is linear or not?,I read somewhere that for the linearity the equation should pass through the origin in this regard the equation of straight line y=mx+c is linear or not?,"['linear-algebra', 'algebra-precalculus', 'functions']"
1302181,Any hyperelliptic curve is never a complete intersection.,"Show that any hyperelliptic curve is never a complete intersection. As any curve of genus greater than 1 is either hyperelliptic or canonical, I think  we can equivalently show that any curve of genus greater than 1 which is a complete intersection must be canonical. Any ideas?",['algebraic-geometry']
1302212,$e^{2\pi i x} = (e^{2\pi i})^x$: What happens if x is rational? [duplicate],"This question already has answers here : What is wrong with this fake proof $e^i = 1$? (2 answers) Closed 9 years ago . I'm a bit embarrassed that I've had difficulty on getting around this one: $$e^{2\pi i x}$$ Solving it by itself, we can reduce it down to $(e^{2\pi i})^x = 1^x$ such that $e^{2\pi i x} = 1$ for all $x$. However, directly plugging in non-integer rational numbers, chiefly $x = 1/2$, we get results that does not stay true to the above equality. I'm a bit perplexed of trying to explain the different results for this one. I admit that I haven't had too much experience with complex numbers compared to other fields.","['complex-analysis', 'complex-numbers']"
1302226,Convergence of a sum of random variables,Let $(X_n)$ be a sum of i.i.d. positive random variables such that $\mathbb{E}(X_1)=1$ and $\mathbb{P}(X_1\neq 1)>0$. Put $M_n=X_1\ldots X_n$. Show that $\sum _{n\geq 1}\sqrt{M_n}< +\infty $ a.e. It can be show that $M_n$ is a martingale so that $\sqrt{M_n}$ is a supermartingale but this doesn't help. I don't see how to use the condition $\mathbb{P}(X_1\neq 1)>0$ in order to show that this serie converge.,['probability']
1302240,How to precisely define $C^\infty$ in $f(x) \in C^\infty$,"In single variable calculus, a common way to denote a function that is continuous for all derivatives is to write $f(x) \in C^\infty$ i.e. $f(x) = \exp(x)$ Is there a more rigorous way to define $C^\infty$ (using set notations, so forth such that it can be generalized to higher dimensions)?","['exponential-function', 'calculus', 'functions']"
1302247,Decomposition into partial fractions to compute an integral,"I'm having problems with: $$\int_{-\infty}^{\infty}\frac{x^4+1}{x^6+1}dx$$ I was thinking: $\frac{x^4+1}{x^6+1}$ is an even function and the interval $(-\infty,\infty)$ is symmetric about 0, we could write the integral like: $$2\int_{0}^{\infty}\frac{(x^4+1)}{x^6+1}dx$$ And for $\frac{x^4+1}{x^6+1}$, I will use the partial fractions. I will write $x^6+1$ like a sum of cubes $x^6+1=(x^2)^3+1^3$ and use the formula $a^3+b^3=(a+b)(a^2-ab+b^2)$ and in the end we will have 
$$x^6+1=(x^2+1)(x^4-x^2+1)$$ But now I'm stuck and do not know how to decompose $x^4-x^2+1$. I was thinking about $(x^2-1)x^2+1$ or $(x^2-\frac{1}{2})^2+\frac{3}{4}$ but I need a form for that like $-(-1+\sqrt3 x-x^2) (1+\sqrt3 x+x^2)$... A little help here?","['calculus', 'partial-fractions', 'improper-integrals', 'definite-integrals', 'integration']"
1302275,Second order derivation of Quadratic form,"I would like to find the second order derivative of a Quadratic form. Assume we have a random complex column vector $x$ and a real constant value $C$. I am interested in computing the following:
$$ \frac{\partial^2}{\partial x^H \partial x}(x^H C x) = ~? $$ The differentiation of the quadratic form is:
$$ d(x^H C x) = 2 \mathcal{R}( x^H C dx) $$
where $\mathcal{R}(\cdot)$ denotes the real part. Are the following expressions correct? $$d^2(x^H C x) = 2\mathcal{R}(C dx^H dx)$$
since $C$ is real and also the outcome of $dx^H dx$ is real, the operator $\mathcal{R}(\cdot)$ can be ignored and therefore: $$ \frac{\partial^2}{\partial x^H \partial x}(x^H C x) = 2 C $$ And how about, if $C$ is a constant matrix with property $C = C^H$?","['quadratic-forms', 'linear-algebra', 'random-matrices', 'matrices']"
1302279,Maximum independent sets of $k$-partite graphs,"Consider a $k$-partite graph $G=(V,E)$. This means that its vertices can be partitioned into $k$ different independent sets, say $V_1,\dots, V_k$. 
Assume further that $|V_1|=\dots = |V_k|$. Under which condition(s) these $k$ independent sets are the only maximum independent sets of the graph $G$? (This is clearly not always the case, see this post .)","['graph-theory', 'combinatorics']"
1302292,First order differential equation: how do I prove that $u$ satisfies the differential equation,"So I'm given this differential equation, that Bernoulli equation:
$$\frac{dy}{dx} + p(x)y = q(x)y^{n} $$ now it says: Show that if $y$ is the solution of the above Bernoulli differential
  equation and $u = y^{1−n}$, then $u$ satisfies the linear differential
  equation: $$\frac{du}{dx} + (n-1)p(x)y = (1-n)q(x)$$ I'm not sure how to prove this exactly My plan is to substitute $u$ in there and show $rhs = y^3 *q(x)$ or something first idea is to find $du/dx$
So $u=y^{1-n}$ So I know that by chain rule
 $$\frac{du}{dx} = \frac{du}{dy} \times \frac{dy}{dx} $$ I know that $\frac{du}{dy} = (1-n)y^{-n}$ now for $dy/dx$ i re-arrange $u=y^{1-n}$ to $u=\frac{y}{n}$,  $un=y$ Hence holding $u$ and $n$ constant
$$\frac{dy}{dx}= \frac{d}{dx}(un) = 0 $$ $$ \frac{du}{dx} = (1-n)y^{-n}\times 0 = 0  $$ So subbing in $du/dx$ and this i get... $$(1-n)p(x) = (1-n)q(x) $$","['calculus', 'ordinary-differential-equations']"
1302310,Derivation of divergence in spherical coordinates from the divergence theorem,"I'm trying to find the expression of the divergence of a vector field $\vec{E}$ in spherical coordinates from the theorem : $$\iint_{S(V)}(\vec{E}.\vec{n})dS = \iiint_{V}div(\vec{E})dV$$ but if I write $\vec{E}$ in spherical coordinates: $$\vec{E} = E_r\vec{e_r}+E_{\phi}\vec{e_{\phi}}+E_{\theta}\vec{e_{\theta}}$$ and if I consider a spherical volume and its surface, I find that $\vec{n} = \vec{e_r}$ since $\vec{n}$ is orthogonal to the spherical surface at any point... So I'm left with $(\vec{E}.\vec{n})  = E_r$ and $$\iint_{S(V)}E_rdS = \iiint_{V}div(\vec{E})dV$$ I don't understand how I'm supposed to get to
 $$div(\vec{E}) = \frac{1}{r^2}\frac{\partial (r^2 E_r)}{\partial r} + \frac{1}{r sin\theta}\frac{\partial E_\phi}{\partial\phi}+\frac{1}{r sin\theta}\frac{\partial(sin\theta E_{\theta})}{\partial \theta}$$","['vector-analysis', 'multivariable-calculus']"
1302362,How to determine the generating function?,"So I have $$\overset{*}{F} = \overset{*}{F}_{n-1} + \overset{*}{F}_{n-2} + g(n)$$ where $\overset{*}{F}$ is NOT a Fibonacci number for $n \geq 2$. $g(n)$ is any function $g: \mathbb{N} \to \mathbb{R}$. And $\overset{*}{F}_0 = g(0)$ and $\overset{*}{F}_1 = g(1)$. I think that $\overset{*}{F}_n$ would be a sequence of $g(n)$s. Actually, I have found that
$$\overset{*}{F}_n = f_{n-1}\cdot g(0) + f_n\cdot g(1) + f_{n-1}\cdot g(2) + f_{n-2}\cdot g(3) + \dots + f_1\cdot g(n)$$ Here $f_n$ is the n-th Fibonacci number. So to clarify, let n = 5, then:
$$\overset{*}{F}_5 = f_4\cdot g(0) + f_5\cdot g(1) + f_4\cdot g(2) + f_3\cdot g(3) + f_2\cdot g(4) + f_1\cdot g(5)$$
$$\overset{*}{F}_5 = 3\cdot g(0) + 5\cdot g(1) + 3\cdot g(2) + 2\cdot g(3) + 1\cdot g(4) + 1\cdot g(5)$$ My question is how to find the generating function of $\overset{*}{F}_n$ if $$G(x) = \sum^{\infty}_{n=0}g(n)\cdot x^n$$
applies? I have difficulties representing the generating function of the Fibonacci numbers reversed. Even though that I know that the regular g.f. $F(x) = \frac{1}{1-x-x^2}$ Maybe I should somehow transform this:
$$\overset{*}{F}_n = f_{n-1}\cdot g(0)x^0 + f_n\cdot g(1)x^1 + f_{n-1}\cdot g(2)x^2 + f_{n-2}\cdot g(3)x^3 + \dots + f_1\cdot g(n)x^n$$
and use $G(x)$ to get the generating function for all $\overset{*}{F}_n$?","['recurrence-relations', 'fibonacci-numbers', 'functions', 'sequences-and-series', 'generating-functions']"
