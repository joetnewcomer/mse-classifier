question_id,title,body,tags
127122,Integration Problem Proof  ($\sin x$),"Problem: Integration of $\displaystyle\int_{-1}^1 {\sin x\over 1+x^2} \; dx = 0 $ (according to WolframAlpha Definite Integral Calculator) But I don't understand how. I tried to prove using integration by parts.
Here's the work:
$$
\int_{-1}^1 {\sin x\over 1+x^2} \; dx = \int_{-1}^1 {\sin x}{1\over 1+x^2} \; dx
$$ Let $u = \sin x,\quad du = \cos x\; dx\;$ and $v = \tan^{-1}x,\quad dv = {1\over 1+x^2}dx\;$.
So
$$
\int_{-1}^1 u dv = \left[uv\right]_{-1}^1 - \int_{-1}^1 v du =\left[ \sin x (\tan^{-1}x)\right]_{-1}^1 - \int_{-1}^1 \tan^{-1}x \cos x\; dx.
$$ Next let $u = \tan^{-1}x, du = {1\over 1+x^2}$ and $dv = \cos x, v = \sin x$... I stopped here, because I feel like I'm going in a circle with this problem. What direction would I take to solve this because I don't know whether integration by parts is the way to go? Should I use trig substitution? Thanks.","['trigonometry', 'integration']"
127154,What is the periodicity of the function $\sin(ax) \cos(bx)$ where $a$ and $b$ are rationals?,"So, I have a general question first.
What happens to the periodicity when we multiply two periodic trig functions with one another ? The next one is very specific, what is the period of the function $g(x)=\sin{(ax)}\cos{(bx)}$, where $a$ and $b$ are rational numbers ? I'd be interested in a proof of sorts. Cheers, Dave","['trigonometry', 'functions', 'periodic-functions']"
127160,Independence of Random Variables (kernel ICA),"In the paper Bach, F. R., & Jordan, M. I. (2002). Kernel Independent Component
  Analysis. Journal of Machine Learning Research, 3(1), 1-48.
  doi:10.1162/153244303768966085 I stumpled upon the following claim involving a correlation measure the authors define, the $\mathcal F$- correlation of two univariate random variables $x_1,x_2$ relative to a vector space $\mathcal F$ of functions from $\mathbb R$ to $\mathbb R$,
$$
\rho_{\mathcal F}=
\sup_{f_1,f_2\in\mathcal F}
\text{corr}\left(f_1(x_1),f_2(x_2)\right)=
\sup_{f_1,f_2\in\mathcal F}
\frac{
\text{cov}\left(f_1(x_1),f_2(x_2)\right)
}{
\text{var}\left(f_1(x_1)\right)^{1/2}
\text{var}\left(f_1(x_1)\right)^{1/2}
}.
$$ The authors state that if $x_1,x_2$ are independent, then $\rho_\mathcal{F}(x_1,x_2)=0$, but they also claim that the converse ($\rho_{\mathcal F}=0~\implies$ $x_1,x_2$ are independent) also holds when $\mathcal F$ is large enough. My question: As an example, they say that it is well known that if $\mathcal F$ contains the Fourier basis (i.e. functions $f_\omega(x) = \exp(i\omega x)$ with $\omega \in \mathbb R$) then $\rho_{\mathcal F}=0~\implies$ $x_1\bot\!\!\!\bot x_2$. My problem is, that I do not see how this is obviously true and I also failed at proving it. Unfortunately, there is no reference or proof for that claim in the paper. When I tried to prove it myself, I could not find a good starting point. First, I thought that the proof could be done via properties of the characteristic function, but I did not get far with that. I am explicitly interested in the claim for the Fourier basis and not so much in the more general claim of Bach and Jordan. If anyone could show me how to prove it (or point at a reference) I would be grateful?","['statistics', 'correlation', 'fourier-analysis', 'probability']"
127168,Essential singularity,"This is an exercise from Gamelin. If $f(z)$ is a complex function with a not removable singularity in $ z_{0} \ $, then $e^{f(z)} \ $ has an essential singularity in $z_{0} $. Any hint?",['complex-analysis']
127198,integration with indicator function,"I was trying to solve the following simple integration involving indicator function $I_{(a,b]}$ in a journal article. Here are the equations (in LaTeX notation):
$$
f(u) = \int_{0}^{1} (I_{(0,s]}(u) - s)\; ds\tag{1}
$$
$$
g(u,v) = \int_{0}^{1} (I_{(0,s]}(u) - s)(I_{(0,s]}(v) - s)\; ds\tag{2}
$$
where $0 < u, v < 1$. I was thinking that the integration will be simply just
$$
f(u) = \int_{0}^{1} (1 - s)\; ds\tag{1}
$$
$$  
g(u,v) = \int_{0}^{1} (1 - s)(1 - s)\; ds
\tag{2}
$$
But, I'm not so sure about this. The constraint on both $u$ and $v$ confused me. Any pointer to this solution? Thanks Wayan",['calculus']
127199,How to solve an exponential equation with two different bases: $3^x - 2^x = 5$,"Can anyone tell me how to solve this equation
  $$3^x - 2^x = 5$$
  other than graphically? I'm stunned. I don't know what to do in the first step.","['calculus', 'roots']"
127211,Kernel of the Lie bracket,"Let $\mathfrak{g}$ be a dimension 3 Lie algebra and $[\quad,\quad]$ be a rank 1 map from $\bigwedge^{2}\mathfrak{g} \rightarrow \mathfrak{g}$. In this case, the kernel of $[\quad,\quad]$ is $3 - 1 = 2$ dimensional. Why does this mean that for some $X \in \mathfrak{g}$, the kernel consists of all vectors of the form $X \wedge Y$ with $Y$ ranging over all of $\mathfrak{g}$?","['linear-algebra', 'lie-algebras']"
127225,Does there exist a function that is differentiable but not integrable? or integrable but not differentiable?,It has become very complicated to me to find out a function which is differentiable  but not integrable or integrable but not differentiable.,"['functional-analysis', 'integration', 'functions']"
127280,Free groups and Kazhdan's property (T),Showing non-amenability of a (non-abelian) free group  is somewhat easy and one can do this immediately after the definition of amenability. Is there an easy proof of the fact that free groups do not have property (T)?,"['functional-analysis', 'geometric-group-theory', 'representation-theory', 'group-theory']"
127293,Branch points of rational functions,Let $f$ be a rational function on a compact connected Riemann surface $X$.  The rational function $f$ induces a holomorphic map $\overline{f}:X\to \mathbf{P}^1(\mathbf{C})$. Let $x$ be a point on the Riemann sphere $\mathbf{P}^1(\mathbf{C})$. How can I check that if $b$ is a branch point of $\overline{f}$ by looking at the derivative of $f$? How does this work when $X=\mathbf{P}^1(\mathbf{C})$?,"['covering-spaces', 'riemann-surfaces', 'derivatives', 'complex-analysis']"
127303,Burnside's Theorem,"I have seen two statements of Burnside's Theorem and they are as follows. Statement 1: Let $p, q$ be distinct prime numbers and $a,b \in \mathbb{Z}_{\geq 0}$. There does not exist a non-abelian simple group $G$ of order $p^aq^b$. Statement 2. Let $p,q$ be distinct prime numbers and $a,b \in \mathbb{Z}_{\geq 0}$. Then any group $G$ of order $p^aq^b$ is solvable. So as these statements are equivalent does this mean that every solvable group is not non-abelian and simple? Why is this the case?",['group-theory']
127304,Functional inverse of $(a + b\sin\theta)^2\tan\theta$,"So, I revisited to the situation involved in my previous question , with the intent of generalizing it to any two masses and charges. When I started going through the model again, beginning with the solution for equal-masses-unequal-charges, I found out that my equation (of the form $\frac{Q}{4L^2} = \tan\theta\,\sin^2\theta$) was incorrect. It should have actually been $$Q = \tan\theta\,(x + 2L\sin\theta)^2$$
(that is to say, there was an $x$ that had to be added to the sine term before squaring and multiplying) which looks even nastier than before. $Q$ is to be the input value (encompassing both charges and most of the fixed parameters), and $L$ and $x$ are fixed. The range of values for $\theta$ is now $-\pi/2\lt0\lt\pi/2$, and $x$ can be any real number. The method of solving it from before hasn't helped much, because I have no idea what to do with the middle term of the expansion of the square (which is $4xL\,\sin\theta\,\tan\theta = 4xL\,\tan^2\theta\,\cos\theta$). Edit: I toyed around with the equation and some trig formulas, and ulitmately I got to the following (defining $\alpha = \tan\frac\theta2$, and noting that $(1-\alpha^2)^2+4\alpha^2=(1+\alpha^2)^2$):
$$\begin{align*}Q&=\tan\theta\,(x + 2L\sin\theta)\\
&=x^2\tan\theta+4xL\sin\theta\tan\theta+4L^2\sin^2\theta\tan\theta\\
&=x^2\frac{\tan\theta(1+\tan^2\theta)}{1+\tan^2\theta}+4L^2\frac{\tan^3\theta}{\sec\theta}+4xL\frac{\sin^2\theta}{\cos\theta}\\
&=\frac{x^2\tan\theta(1+\tan^2\theta)+4L^2\tan^3\theta}{1+\tan^2\theta}+4xL\cdot\left(\frac{2\alpha}{1+\alpha^2}\right)^2\cdot\frac{1+\alpha^2}{1-\alpha^2}\\
&=\frac{x^2\cdot\frac{2\alpha}{1-\alpha^2}\cdot\left(1+\left(\frac{2\alpha}{1-\alpha^2}\right)^2\right)+4L^2\cdot\left(\frac{2\alpha}{1-\alpha^2}\right)^3}{1+\left(\frac{2\alpha}{1-\alpha^2}\right)^2}+4xL\frac{4\alpha^2}{(1+\alpha^2)(1-\alpha^2)}\\
&=\frac{\frac{2x^2\alpha}{1-\alpha^2}\cdot\frac{(1-\alpha^2)^2+4\alpha^2}{(1-\alpha^2)^2}+\frac{32L^2\alpha^3}{(1-\alpha^2)^3}}{\frac{(1-\alpha^2)^2+4\alpha^2}{(1-\alpha^2)^2}}+\frac{16xL\alpha^2}{1-\alpha^4}\\
&=\frac{2x^2\alpha((1-\alpha^2)^2+4\alpha^2)+32L^2\alpha^3}{(1-\alpha^2)^3}\cdot\frac{(1-\alpha^2)^2}{(1-\alpha^2)^2+4\alpha^2}+\frac{16xL\alpha^2}{(1+\alpha^2)(1-\alpha^2)}\\
&=\frac{2x^2\alpha(1+\alpha^2)^2+32L^2\alpha^3}{(1+\alpha^2)(1-\alpha^2)^2}+\frac{16xL\alpha^2(1-\alpha^2)}{(1+\alpha^2)(1-\alpha^2)^2}\\
&=\frac{2x^2\alpha^5+16xL\alpha^4+(4x^2+32L^2)\alpha^3+16xL\alpha^2+2x^2\alpha}{(1+\alpha^2)(1-\alpha^2)^2}\\
&=\frac{2\alpha(\alpha^2x+4\alpha L+x)^2}{(1+\alpha^2)(1-\alpha^2)^2}
\end{align*}$$
The identities that I used were $\sec^2\theta=1+\tan\theta$, $\cos\theta=\frac{1-\tan^2\theta/2}{1+\tan^2\theta/2}$, and $\tan\theta=\frac{2\tan\theta/2}{1-\tan^2\theta/2}$. This seems to be a function that would have a really complex and often multivalued inverse, so I think that I can just say the result is the solution to this equation.$$\frac{kq\,_1q\,_2}{mg}=\tan\theta(x+2L\sin\theta)^2=\frac{2\alpha(\alpha^2x+4\alpha L+x)^2}{(1+\alpha^2)(1-\alpha^2)^2}$$
I guess I can call this more or less answered, then.","['trigonometry', 'algebra-precalculus', 'inverse-function']"
127339,Stochastic variable belonging to sigma-field,"I'm studying Markov Processes in Rick Durrett - Probability: Theory and Examples and he's doing something I simply don't understand, though I reckon it's probably quite simple. Here goes (an example from introducing conditional expectations): Given a probability space $\left(\Omega,\mathcal{F}_{0},P\right)$ a $\sigma\text{-field}\,\mathcal{F}\subset\mathcal{F}_{0}$ and a random variable $X\in\mathcal{F}_{0}$... What does it mean for $X\in\mathcal{F}_{0}$? I mean, the image of X has to be Borel, right?
It belonging to a $\sigma$-algebra in our probability space doesn't make sense to me. Hope someone will help,
Henrik p.s. Wow the math on this site works good!","['probability-theory', 'measure-theory']"
127351,computing a trignometric limit,"I am trying to show that $$\lim _{n\rightarrow \infty }\dfrac {1+\cos \dfrac {x} {n}+\cos \dfrac {2x} {n}+\ldots +\cos\dfrac {\left( n-1\right) x} {n}} {n } = \dfrac{\sin x}{x}$$ I have attempted a number of approaches such as trigonometric tricks and the most recent with substitution of $\cos \dfrac {x} {n}=\dfrac {e^{i\frac {x} {n}}+e^{-\frac {ix} {n}}} {2}$
Starting from the left hand side i ended up with an expression such as $$\lim _{n\rightarrow \infty }\frac {\frac {1-e^{ix}} {1-e^{\frac {ix} {n}}}+\frac {1-e^{-ix}} {1-e^{\frac {-ix} {n}}}} {2n}$$ I am unsure how i could possibly rearrange this so upon taking the limit i can convert to RHS. Any help with this method or even an alternative proof strategy would be much appreciated.","['sequences-and-series', 'real-analysis', 'limits']"
127355,"Solving $\lim\limits_{(x,y)\to(0,0)}\;\frac{x^5 + \,y^5}{x^3+\,y^3}$","How do I solve the limit $$\lim_{(x,y)\to(0,0)}\;\frac{x^5+y^5}{x^3+y^3}\quad ?$$ I have tried using polar coordinates, but I don't think an answer would be valid because theta is not fixed. What else can I do?","['multivariable-calculus', 'limits']"
127361,Second order partial derivatives - notation,"I have seen both of these used, and people around me seem to disagree, so which one is correct: (first derivative with respect to x, then y): (1) $$\frac{\partial }{\partial y}(\frac{\partial f}{\partial x}) = \frac{\partial^{2} f}{\partial x\partial y}$$ (2) $$\frac{\partial }{\partial y}(\frac{\partial f}{\partial x}) = \frac{\partial^{2} f}{\partial y\partial x}$$ and why? (reasons, history?)","['notation', 'multivariable-calculus', 'calculus', 'derivatives']"
127372,Prove that $||x|-|y||\le |x-y|$,"I've seen the full proof of the Triangle Inequality 
\begin{equation*}
|x+y|\le|x|+|y|. 
\end{equation*}
However, I haven't seen the proof of the reverse triangle inequality: 
\begin{equation*}
||x|-|y||\le|x-y|.
\end{equation*}
Would you please prove this using only the Triangle Inequality above? Thank you very much.","['absolute-value', 'inequality', 'real-analysis']"
127374,Extending a continuous function defined on the rationals,"Is there an elementary way of proving that for any continuous function $f:\mathbb{Q}\to[0,1]$ there is such an $x\in\mathbb{R}\setminus\mathbb{Q}$ that $f$ can be extended to a continuous function $\mathbb{Q}\cup\{x\}\to[0,1]$, without resorting to the fact that $\mathbb{Q}$ is not a $G_\delta$-set in $\mathbb{R}$ and the Theorem (4.3.20. in General Topology by Engelking): If $Y$ is a completely metrizable space, then every continuous mapping $f:A\to Y$ from a dense subset of a topological space $X$ to the space $Y$ is extendable to a continuous mapping $F:B\to Y$ defined on a $G_\delta$-set $B\subset X$ containing $A$. which seem an overkill to me in this case?","['general-topology', 'real-analysis']"
127381,Is the series $\sum \sin^n(n)$ divergent?,"I'm almost sure that the series $\sum \sin^n(n)$ is not convergent, but lack proof.
Thank for any help.",['real-analysis']
127401,"If a holomorphic function $f$ has modulus $1$ on the unit circle, why does $f(z_0)=0$ for some $z_0$ in the disk?","I don't understand the final step of an argument I read. Suppose $f$ is holomorphic in a neighborhood containing the closed unit disk, nonconstant, and $|f(z)|=1$ when $|z|=1$. There is some point $z_0$ in the unit disk such that $f(z_0)=0$. By the maximum modulus principle, it follows that $|f(z)|<1$ in the open unit disk. Since the closed disk is compact, $f$ obtains a minimum on the closed disk, necessarily on the interior in this situation. But why does that imply that $f(z_0)=0$ for some $z_0$? I'm aware of the minimum modulus principle, that the modulus of a holomorphic, nonconstant, nonzero function on a domain does not obtain a minimum in the domain. But I'm not sure if that applies here.",['complex-analysis']
127415,Real VS Complex for integrals: $\int_0^\infty \frac{dx}{1 + x^3}$,"The integral
$$\int_0^\infty \frac{dx}{1 + x^4} = \frac{\pi}{2\sqrt2}$$
can be evaluated both by a complex method (residues) and by a
real method (partial fraction decomposition).
The complex method works also for the integral 
$$\int_0^\infty \frac{dx}{1 + x^3} = \frac{2\pi}{3\sqrt3}$$
but partial fraction decomposition does not give convergent integrals. I would like to know if there is some real method for evaluating this last integral.","['definite-integrals', 'complex-analysis', 'integration', 'real-analysis']"
127426,How is this function additive?,"Linear functions are said to be additive:
$f(x + y) = f(x) + f(y)$ But if I have this simple function $f(x)= 7x+3$, I get, for example(at $x=5$ and $8$): $f(5)=38$ and $f(8)= 59$. The sum is $97$. $f(5+8)= 7\cdot 13+3 = 94$. $94\ne 97$. How come? What did I miss?",['functions']
127447,"If $\alpha_{1},\ldots,\alpha_{m}$ are vectors different from zero vector, then there is a linear functional $f$ such that $f(\alpha_{i})\neq 0$","I am self-studying Hoffman and Kunze's book Linear Algebra . This is exercise 14 from page 106. Let $\mathbb{F}$ be a field of characteristic zero and let $V$ be a
  finite-dimensional vector space over $\mathbb{F}$. If
  $\alpha_{1},\ldots,\alpha_{m}$ are finitely many vectors vectors in
  $V$, each different from zero vector, prove that there is a linear
  functional $f$ such that $f(\alpha_{i})\neq 0, i=0,\ldots,m.$ I thought that prove by induction on $m$ would work. I showed the base case, but I got stuck on inductive step. I would appreciate your help.",['linear-algebra']
127459,Each discrete space is a Polish Space,"I'm trying to solve exercise 6.3#7 from Sidney A. Morris' ""Topology without tears"" : ""Prove that each discrete space [...] is a Polish space."" I started by proving that discrete spaces are always completely metrizable with the discrete metric. But then I got stuck. As far as I know, the only dense subset of a discrete space is the whole space. But does that not mean that only countable discrete spaces are separable (and therefore Polish) spaces?",['general-topology']
127469,Parameterizing a rational curve,"I'm having trouble finding a parameterization for the following curve: $x^4 - 2x^2yz + y^2z^2 - y^3z = 0$ taken to be a curve in $\mathbb{C}\mathbb{P}^2$. I followed the example on Wikipedia where they parameterized a circle's equaton, ie., I demohogenized the polynomial at $z$, so I reduce to the curve $x^4 - 2x^2y + y^2 - y^3 = 0$. Then I observed that the curve contains the point $(0,1)$, so I considered the line through $(0,1)$ with slope $t$, ie. $y = tx + 1$ and I plugged this into my equation. I ended up with an ugly quartic polynomial in $x$ with coefficients in $t$...Specifically, I got $x^4 -2tx^3 + (2+t^2)x^2 + (-t-2t)x + 2 = 0$ and hopefully I didn't make any mistakes. Solving for $x$ doesn't seem easy. Is this the right approach to doing this?","['algebraic-geometry', 'algebraic-curves']"
127481,Question about supremum,"Let $f:U\rightarrow\mathbb{R}^n$ be a differentiable function over an open convex set $U\subset\mathbb{R}^m$. Show that $\sup_{x\neq y}\dfrac{|f(x)-f(y)|}{|x-y|}=\sup_{z\in U}|(Df)_z|.$ I know I must use the Mean Value theorem to show this, and since the set $U$ is convex I will have the equality, but how can I reach this equation?",['multivariable-calculus']
127489,Number of invertible 0-1 matrices,"Define the set $S_n=\{A_n|  A_n \hbox{is invertible 0-1 matrix}\}$. What is the size of $S_n$? When $n=2$, it is easy to see $\sharp S_2=6$. I guess $\sharp S_n=\prod_{k=1}^n(2^n-2^{k-1})$.","['matrices', 'linear-algebra', 'combinatorics']"
127492,"How many 2-card swaps until a ""card deck"" is close to true random?","Let's define a ""card deck"" as a sequence of the first $x$ natural numbers, and a ""swap"" as the creation of a new sequence where the $i$th and $j$th member of the original sequence are exchanged e.g. swapping cards $2$ and $3$ so that $[1, 2, 3, 4 ] \longmapsto [1, 3, 2, 4]$. My question is, how many swaps (where i and j are randomly chosen) must be made before a sequence is created that can be pronounced random?  Is there a faster way to achieve randomness if i and j and not chosen randomly? EDIT: I suppose I don't care how random it is, though let's say the sequence is a real deck of cards; the randomness should be close to what you would get with $7$ good riffles (see Shuffling ).  Even better would be a way to control the degree of randomness, i.e. estimate $z$, where your odds of predicting the location of a particular card in the deck are $\frac1x + z$. Note: It seems that picking i and j randomly is not the best way to achieve randomness.  See Fisher-Yates shuffle .","['sequences-and-series', 'random']"
127503,Prove the sample variance is an unbiased estimator,I'm trying to prove that the sample variance is an unbiased estimator. I know that I need to find the expected value of the sample variance estimator $$\sum_i\frac{(M_i - \bar{M})^2}{n-1}$$ but I get stuck finding the expected value of the $M_i\bar{M}$ term. Any clues? I would also like to calculate the variance of the sample variance. In short I would like to calculate $\mathrm{Var}(M_i - \bar{M})^2$ but again that term rears its ugly head.,"['statistics', 'parameter-estimation']"
127509,How do I obtain an appropriate energy functional from the weak formulation of a partial differential equation?,"I'm reading a textbook example on the finite element method: $\nabla^T[D(x,y,z)\nabla u] - a(x,y,z)u + f = 0 $ in R $\partial R= \partial R_1 \bigcup \partial R_2$, $\partial R_1 \bigcap \partial R_2 \neq \varnothing$ u=r(x,y,z) on $\partial R_1$ $D \nabla u \centerdot n = -p(x,y,z)u + q(x,y,z)$ on $\partial R_2$ where $n$ is a unit outward normal vector, and $D(x,y,z) > 0$ and $a(x,y,z),p(x,y,z),$ and $q(x,y,z)\ge0$. I understand how to obtain the weak formulation using the test function $v$: $\iiint\limits_R [-D\nabla u\centerdot \nabla v -auv + fv]dV + \iint\limits_{\partial R_2}[-puv+qv]dA$, where dV and dA are the volume and area differentials. I'm looking for a bound on the Galerkin method error.  The book I'm reading seems to use an energy functional of the form: $F(u) = \iiint\limits_R \{ \frac{1}{2}D|\nabla u|^2 + \frac{1}{2}au^2 - fu \}dV + \iint\limits_{\partial R_2} \{ pu^2 - qu \} dA$. I'm not sure exactly how this energy functional was derived.  It almost looks like the weak formulation integrated once with respect to u, then integrated over the respective domains.  But I don't think this is true for the $|\nabla u|^2$ term.  How could I have come up with this appropriate energy functional on my own?  What guidelines can I follow, in general, to obtain this functional for numerical error analysis?","['calculus-of-variations', 'functional-analysis', 'partial-differential-equations', 'numerical-methods']"
127514,Finding pairs of triangular numbers whose sum and difference is triangular,"The triangular numbers 15 and 21 have the property that both their sum and
difference are triangular.  There are another 4 pairs less than 1000. To complete this problem,
I have done like this: To satisfy the conditions, we have to find $u$, $v$, $w$, $x$ such that 
$$\begin{align*}
\frac{u(u+1)}{2} + \frac{v(v+1)}{2} &= \frac{w(w+1)}{2}\\
\frac{v(v+1)}{2} - \frac{u(u+1)}{2} &= \frac{x(x+1)}{2}.
\end{align*}$$
Multiplying by 8 and completing the squares, we have;
$$\begin{align*}
\Bigl( (2u+1)^2 -1\Bigr) + \Bigl( (2v+1)^2-1\Bigr) &= (2w+1)^2-1\\
\Bigl( (2v+1)^2 - 1\Bigr) - \Bigl( (2u+1)^2 - 1\Bigr) &= (2x+1)^2 - 1.
\end{align*}$$ For convince representation, consider, $a = 2u +1$, $b = 2v + 1$, $c = 2w+1$ and $d = 2x +1$. Then, we have; $a^2 + b^2 - 1 = c^2$ and $b^2 - a^2 + 1 = d^2$
by adding $2b^2 = c^2 + d^2$, hence  $c^2 - b^2 = b^2 - d^2$
$$\frac{c-b}{b-d} = \frac{b+d}{b+c} = \frac{m}{n}$$
say, where $\gcd(m,n)=1$, $n\gt m$.
Hence
$$\begin{align*}
-nb +nc &= -md + mb\\
b(m+n) -nc &= md\\
nd + nb &= mb + mc\\
b(n-m) &= mc - nd
\end{align*}$$ I am so sorry...thereafter what to do and how to complete this problem, I don't know. If any one can solve, I am so grateful to them or discuss some other method to complete this problem.","['elementary-number-theory', 'diophantine-equations', 'number-theory']"
127521,Draw online polygon/triangle [duplicate],This question already has answers here : Software for drawing geometry diagrams (26 answers) Closed 6 years ago . Is there is any website where I can draw a polygon/triangle online. A website with an option to use coordinates to plot points and other tools to draw polygons.,"['geometry', 'online-resources', 'math-software']"
127530,space of bounded measurable functions,"Let $(\Omega, \Sigma)$ be a measurable space. Is the space of bounded measurable functions $B_b(\Sigma)$ equipped with the supremum norm a Banach space, i.e. complete?","['measure-theory', 'functional-analysis', 'banach-spaces']"
127538,Number of Equivalence Relations over $A$ with Restrictions,"Given the set $A=\{1,2,3,4,5,6\}$ how many equivalence relations ( symmetric, reflexive and transitive ) can you form if the following pairs are disallowed: $\{ (3,4),(2,4),(2,3),(1,4),(1,3),(1,2)\}$ ? All six must not be present. I saw this on a final exam and had no idea how to even approach it.","['elementary-set-theory', 'combinatorics']"
127551,Combinatorial Proof for a $ p\mid\binom{p}{k} \ \ \ \ \ 0<k<p$ .,"I'm looking for a combinatorial proof to the following statement: $$ p\mid\binom{p}{k} \ \ \ , \ \ 0<k<p \ \ \ \ \ \ \text{and} \ \  p \   \text{is prime}.$$ Thank you.","['divisibility', 'elementary-number-theory', 'combinatorial-proofs', 'binomial-coefficients', 'combinatorics']"
127552,Exercise from Stein again - characterization of BV functions,"I find this pretty hard and it would be awesome if someone could help me. The problem is the following (Problem 6/Chapter 3 from S&S's Real Analysis ). Suppose $F$ is a bounded measurable function on $\mathbb{R}$. If $F$ satisfies either one of the two following conditions: (a) $\int_{\mathbb{R}}{|F(x+h)-F(x)|dx} \leq A|h|$, for some constant $A$ and all $h\in \mathbb{R}$; (b) $|\int_{\mathbb{R}}{F(x)\phi '(x) dx}| \leq A$, where $\phi$ ranges over all $C^{1}$ functions of bounded support with $\sup_{x \in \mathbb{R}}{|\phi (x)|} \leq 1$;
then $F$ can be modified on a set of measure zero as to become a function of bounded variation on $\mathbb{R}$. Moreover, on $\mathbb{R}^{d}$ we have the following assertion. Suppose that $F$ is a bounded measurable function on $\mathbb{R}^{d}$. Then, the following two conditions on $F$ are equivalent: (a') $\int_{\mathbb{R}^d}{|F(x+h)-F(x)|dx} \leq A|h|$, for some constant $A$ and all $h\in \mathbb{R}^d$; (b') $|\int_{\mathbb{R}^d}{F(x)\frac{\partial {\phi}}{\partial{x_{j}}} dx}| \leq A$, for all $j=1,\ldots, d$, for all $\phi \in C^{1}$ of bounded support with $\sup_{x \in \mathbb{R}^d}{|\phi(x)|} \leq 1$. I proved already that if $F$ is a BV function then (a) and (b) hold; so the first part should be a converse for that..","['bounded-variation', 'measure-theory', 'real-analysis']"
127611,determination of a holomorphic function by its poles and zeros,"While reading a text about the application of complex analysis to elasticity, I thought about the following problem: Let $f$ be a holomorphic function in all $\mathbb{C}$. Is $f$ uniquely determined by the list of its poles and zeros (and their orders, of course)? EDIT: By ""the list of its poles and zeros"" I include also the point at $\infty$. I assume that $f$ has a proper limit at infinity. I guess that if that was true it was an undergrad theorem that I'm supposed to know.",['complex-analysis']
127613,Closest point on circle edge from point outside/inside the circle,"Alright, I am programming a plugin for a game that requires me to get the closest point on a circle when all you have is a point B, which is outside of the circle, the radius of the circle, and the location of the center of the circle. Say I have this situation: So, how would I be able to get the coordinates of point C? I need a formula that allows me to calculate those coordinates when I only know the radius of the circle and the coordinates of B. I sketched the line for ease of understanding, but all I start with is just the circle and point B. OH, one other thing, B isn't a static point, each time this calculation will be executed B will be at another position. And, as a bonus (not really needed) would you care to show an example on how to do the same thing, but then when point B is inside the circle. Thanks in advance!","['geometry', 'circles']"
127616,An application of partitions of unity: integrating over open sets.,"In Spivak's ""Calculus on Manifolds"", Spivak first defines integration over rectangles, then bounded Jordan-measurable sets (for functions whose discontinuities form a Lebesgue null set). He then uses partitions of unity to define integration over arbitrary open sets (top of p.65). Used in the proof of this assertion is the claim that if: i) $\Phi$ is subordinate to an admissible cover $J$ of our open set $A$. ii) $f:A\rightarrow \mathbb{R}$ is locally bounded in $A$. iii) The set of discontinuities of $f$ is Lebesgue-null. then each $\int_A \phi\cdot|f|$ exists. I cannot see how this statement makes sense, seeing as the integral is thus far only defined for bounded Jordan-measurable sets. Perhaps I am missing something simple here?","['multivariable-calculus', 'calculus', 'differential-geometry']"
127641,trivial but non-trivial equivalence relations,"Define a binary relation $R$ on a set $A$ by saying $xRy$ iff $x$ and $y$ have the same whatever . ""Whatever"" is of course some specified function on $A$. This is a ""trivial"" equivalence relation: you specify it in effect by specifying the partition of the set $A$. Define another binary relation $S$ on $A=\{\ldots,-3,-2,-1,0,1,2,3,\ldots\}$ by saying $xSy$ iff $x-y$ is a multiple of $3$. Undergraduates who haven't thought about this do not instantly say ""Oh, I see: $xSy$ iff $x$ and $y$ leave the same remainder on division by $3$.""  Instead they go through proving reflexiveness, symmetry, and transitivity from the definition.  In proving transitivity they ask whether $x-y$ is a multiple of $3$ and $y-z$ is a multiple of $3$ implies $x-z$ is a multiple of $3$, and they may have to think about it before they come up with $x-z=(x-y)+(y-z)$.  After all, what would possess anyone to subtract $y$ only to instantly add it back in again? So this is a ""nontrivial"" equivalence relation in that one doesn't instantly specify the partition of $A$, and proving the three properties requires some algebra rather than just knowing the definition of the three properties or knowing which partition is used.  In fact, after they've proved the three properties it's not obvious until they think further just what the partition is.  But on the other hand, it's trivial in that they can do the algebra without having abstruse ideas in algebra appear to be what the problem is all about. What other examples of this sort are there, suitable as exercises in a class where the idea of equivalence relations is first introduced? In other words, examples are sought in which Reflexiveness, symmetry, and transitivity will not be obvious in virtue of the relation having been defined by saying what the set-partition is; Proving those three properties takes more work that merely chasing the definitions of those three properties; But proving them isn't so hard that that becomes the hard part of the problem; After they've proved them, they still have to do some further thought to figure out what the partition is. Later edit: I'd like things that are usable in a course I'm teaching, whose only prerequisite is first-semester calculus, which is not actually used.  I can't use concepts that would take substantial time to develop.","['logic', 'education', 'discrete-mathematics']"
127646,Minimal axioms for a group,"My group theory is very rusty. If I want to just start with left inverses and left identities, must I link the axioms, or can I leave them independent? e.g., is it enough to say ""there exists at least one $e \in G$ s.t. $ea=a$ for all $a \in G$"" and ""for each $a$ in $G$, there exists $a^{-1} \in G$ s.t. $a^{-1}a$ is an identity"", or must I say ""there exists at least one $e \in G$ s.t. ($ea=a$ for all $a \in G$ AND for each $a \in G$ there exists $a^{-1} \in G$ s.t. $a^{-1}a=e$)"". This seems like it must be a FAQ, but I just can't find it. If I don't assume the linkage, I run into problems where I show (for example) that if $a^{-1}a=e_1$, $b=aa^{-1}$, $b^{-1}b=e_2$, then $b=e_2$. That will get me things like $ae_1=a$, but not the general case.","['group-theory', 'abstract-algebra']"
127648,What does the symbol $\operatorname{Tr}$ in the Yang-Mills action mean?,"I find that many authors write the Yang-Mills action as follows:
$$\mathcal{J}= \int \operatorname{Tr}(F \wedge  \star F).$$
I have yet to find a formal description of the symbol $\operatorname{Tr}$ and am especially interested in its relation to differential geometry. How should I understand it?","['mathematical-physics', 'gauge-theory', 'quantum-field-theory', 'differential-geometry']"
127677,Integer solutions of $x^4 + 16x^2y^2 + y^4 = z^2$,"I come across this question very long ago. I just got one solution by my computer search. If any one know the other solutions and resolvability, please let me know. $$x^4 + 16x^2y^2 + y^4 = z^2$$ has a solution $(1,2,\color{brown}9)$. ( Typo corrected .) Can we find others? I seem to remember proving that for there to be a solution there needed to be a smaller one.  Using the given one as that gave new solutions.  I can't find my work on it though, if any member can...Please discuss","['elementary-number-theory', 'diophantine-equations', 'number-theory']"
127685,List of the minimal addition chains,"The question of finding the Minimal Addition Chain (MAC) for needed for Addition chain exponentiation seems to be NP-complete . As such, it would be nice to have a list for the small powers already computed. Wikipedia lists the MAC's for $n\le16$. I'm looking for the known MAC's for $n>16$.","['sequences-and-series', 'computer-science', 'reference-request', 'online-resources', 'combinatorics']"
127689,Why does an infinite limit not exist?,"I read in Stewart ""single variable calculus"" page 83 that the limit $$\lim_{x\to 0}{1/x^2}$$ does not exist . How precise is this statement knowing that this limit is $\infty$ ?. I thought saying the limit does not exist is not true where limits are $\infty$ . But it is said when a function does not have a limit at all like $$\lim_{x\to \infty}{\cos x.}$$","['calculus', 'terminology']"
127695,Proving that a set is countable by finding a bijection,"$Z$ is the set of non-negative integers including $0$. Show that $Z \times Z \times Z$ is countable by constructing the actual bijection $f: Z\times Z\times Z \to \mathbb{N}$ ($\mathbb{N}$ is the set of all natural numbers). There is no need to prove that it is a bijection. After searching for clues on how to solve this, I found $(x+y-1)(x+y-z)/z+y$ but that is only two dimensional and does not include $0$.  Any help on how to solve this?",['elementary-set-theory']
127698,normality and cohen-macaulay condition,"I am not an expert in the geometric meaning of normality/Cohen Macaulay, so the following questions could seem very stupid. Are there examples of connected varieties over a field whose irreducible components are smooth and they intersect in a closed of codimension $> 1$? Are these varieties normal even if they are not irreducible? If the whole variety is Cohen-Macaulay, with smooth irreducible components, does this imply that they intersect in codimension $> 1$? In the cases where I have Cohen-Macaulay + intersection in codimension $> 1$, do I have normality of the whole stuff or I need also irreducibility? In general one needs normality to extend sections of a line bundle. Does the condition that the singular locus has codimension $> 1$ make it work also in the not irreducible case? By this I mean that I have a line bundle on these smooth components outside their  intersections and I want to extend it to the whole variety, possibly in a unique way. Thanks","['cohen-macaulay', 'algebraic-geometry']"
127716,How do I get good at Math? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 8 months ago . Improve this question How do I get good at math? I'm a freshman in college, and I've always done OK in math. I never had any good teachers in High school, and I always have done the bare minimum. Over the course of this year, I really came to understand how important math is and how much potential I have to enjoy it. I'm taking a discrete 2 course and I love it. (I'm a Computer Science major) Even though I passed Calculus 3, I don't feel I understand Calculus. I have an excellent memory and was able to memorize formulas and apply them when I was supposed to. I don't understand anything though. I came to the realization that I should put some effort into getting better at math.
Over spring break, I went through almost all of Khan Academy's exercises just to make sure that I have a good grasp on the very basics. I'm going to finish them up in a couple of days. what should I do next? My plans are to start at the beginning of my Calculus book (Thomson's Early Transcendental) and work my way through the book (one part a day), reading everything and doing every problem. 
I don't know how good of a book this is though. I've done some googling and a lot of people recommend Spivak's and Apostle's Calculus books. Is it worth purchasing one of these (or something else) if I really want to comprehend the material? Are they good for self-teaching? I usually have some sort of project like this going on (except never math based), and I'm completely willing to put time into this goal. Some direction would be nice though.","['calculus', 'soft-question', 'learning']"
127725,Riemannian Connection (Very basic question),"We know that a connection $\nabla$ in a manifold M hashas the purpose of performing the same role as the covariant derivative   of vector fields  of surfaces in $\mathbb{R}^3$. Such analogies are clearly perceived in the connection definition. When M has a Riemannian metric,$~~ g~~$,  to make things even more similar to the case in $\mathbb{R}^3$ we introduce the concept of Riemannian connection or Levi-Civita connection, which is a connection satisfying: compatibility with the metric: $Xg(Y,Z)=g(\nabla_X Y,Z)+g(Y,\nabla_X Z)$ torsion-free: $T(X,Y)=\nabla_X Y-\nabla_YX-[X,Y]\equiv 0$ where $ X, Y, Z $ are vector fields on $M.$ What I understand is the need / intuition of the second property, torsion-free,what would work well if not we assume this hypothesis?","['riemannian-geometry', 'reference-request', 'differential-geometry']"
127736,Definition of group action,"I'm currently taking a class in abstract algebra, and the textbook we are using is Ted Shifrin's Abstract Algebra: A Geometric Approach. In the chapter on group actions and symmetry, he defines a group actions as follows $$\phi: G \mapsto \operatorname{Perm}(S)$$ where $G$ is a group acting on set $S$. However, most internet sources I've come across define a group action as $$\phi: G \times S \to S$$ There are a few sources that talk about how the two are equivalent, but the explanations are overly brief. Can someone help me reconcile these two definitions?","['symmetry', 'group-theory', 'abstract-algebra']"
127750,Is this limit correct: $\lim_{x \to+\infty} \frac{\log_{2}(x-1)}{x} = 0$?,"Find $\space\ \begin{align*} \lim_ {x \to+\infty} \left [ \frac{\log_{2}(x-1)}{x}\right]  
\end{align*}$. After some minutes around this limit I did it this way: $\log_{2}(x-1)=y \Leftrightarrow 2^y=x-1$ So,$\space x=2^y+1$. When $x \to +\infty$,$\space y \to +\infty$ also. By substitution: $\begin{align*} \lim_ {y \to+\infty} \left [ \frac{\log_{2}(2^y+1-1)}{2^y+1}\right]=\lim_ {y \to+\infty} \left [ \frac{\log_{2}(2^y)}{2^y+1}\right]=\end{align*}$ $\begin{align*}\lim_ {y \to+\infty} \left [ \frac{y}{2^y+1}\right]=\lim_ {y \to+\infty} \left [ \frac{1}{\frac{2^y+1}{y}}  \right]=\lim_ {y \to+\infty} \left [ \frac{1}{\frac{2^y}{y}+\frac{1}{y}}\right]= \frac{1}{+\infty+0}=0 
\end{align*}$ Is this correct?Are there any other easy way to find this limit?Thanks",['limits']
127754,Question about non-homogeneous and homogeneous linear D.E.,Suppose $y_1$ is a solution of a non-homogeneous linear D.E. and $y_2$ is a solution to a homogeneous equation. Which of the following is/are true? a. $-y_1$ is a solution to the non-homogeneous equation. b. $-y_2$ is a solution to the homogeneous equation. c. $y_1-y_2$ is a solution of the non-homogeneous equation. d. $y_2-y_1$ is a solution of the homogeneous equation.,['ordinary-differential-equations']
127756,Help with basic high school math. What happens to $j^2$?,"I know my math is very rusty, actually, it has always been that way. but I need help with this. The question below has me stumped. I've tried to show the steps I went through to get the answer. Please tel me where I made the mistake. If $x=a$ and $x=b$ are two roots of a quadratic equation, then $(x-a)(x-b) = 0$ gives the quadratic equation. That is $$(x - a)(x - b) = x^2 - (a + b)x + ab = 0.$$ Here, the two roots are $x= -2 + j\sqrt5$ and $x = -2 - j\sqrt5$ so that $$(x – [-2 + j\sqrt5])(x – [-2 - j\sqrt5]) = 0.$$ That is $$x^2 - x[-2 + j\sqrt5 - 2 - j\sqrt5] + [-2 + j\sqrt5][-2 - j\sqrt5] = 0.$$ I understand that \begin{gather*}
x^2 - x[-2 + j\sqrt5 - 2 - j\sqrt5] + [-2 + j\sqrt5][-2 - j\sqrt5] = 0\\
x^2 - x[-2 - 2] + [-2 + j\sqrt5][-2 - j\sqrt5] = 0\\
x^2 - x[-4] + [-2 + j\sqrt5][-2 - j\sqrt5] = 0\\
x^2 + 4x + [-2 + j\sqrt5][-2 - j\sqrt5] = 0.
\end{gather*} if we separate out the last term for simplicity: \begin{align*}
[-2 + j\sqrt5][-2 - j\sqrt5] & = (-2)(-2) + (-2)(-j\sqrt5) + (-2)(+j\sqrt5) + (+j\sqrt5)(-j\sqrt5)\\
& = 4 + (2j\sqrt5) - (2j\sqrt5) +(-j\sqrt5)^2\\
& = 4 + (2j\sqrt5) - (2j\sqrt5) +(-j^2)(-\sqrt5)^2\\
& = 4 +j^2 5
\end{align*} Putting this last term back into the main equation results in $$x^2 + 4x + (4+j^2 5) = 0.$$ In the book ( Advanced Engineering Mathematics )* this equation works out to $$x^2 + 4x + 9 = 0.$$ What I don’t understand is what happened to $j^2$ . How does it just magically disapear? *If you use the Amazon ""Look inside"" feature you can see it on page 4.","['factoring', 'complex-numbers', 'algebra-precalculus', 'solution-verification']"
127764,Strong Markov property - Durrett,"I recently had great success with my first question here so I will boldly go on to a second.
Here goes: I'm studying Markov Chains in Rick Durrett - Probability: Theory and example and I'm stuck with the definition of the strong markov property - I know more or less what it should be, but do not understand his way of saying it. I'm gonna give you a lot of information, hopefully enough but please ask for more if you need it. Some definitions: We have some nice (1-1 map between S and R) measurable space $(S,\mathcal{S)}$ and we then define 
$$\Omega=\{{(\omega_{1},\omega_{2},...):\omega_{i}\in\text{}S}\}$$
$$\mathcal{F}=\mathcal{S}\times\mathcal{S}\times...$$
$$P=\mu\times\mu\times...\text{where }\mu\text{ is the distribution of }X_{i}$$ 
$$X_{n}(\omega)=\omega_{n}$$ We have $$P(X_{j}\in B_{J},0\leq j \leq n)=\int_{B_{0}}\mu(dx_{0})\int_{B_{1}}p(x_{0},dx_{1})...\int_{B_{n}}p(x_{n-1},dx_{n})$$
Where the p's are transition probabilities (for fixed x (first variable) it's a probability measure and fixed set (second variable) a measurable function).
The probability measure is consistent so Kolmogorov's extension theorem gives us the infinite one (as I understand). His definition is then as follows: Suppose that for each n, $Y_{n}:\Omega\rightarrow\mathbb{R}$ is measurable and $|Y_{n}|\leq M\; \forall n$ Then 
$$E_{\mu}(Y_{N}\circ\theta_{N}|\mathcal{F}_{N})=E_{X_{N}}Y_{N}\quad on\:\{N<\infty\}$$
N is a stoptime and theta a shift operator (""drops the first N elements of the omega-sequence"") So i know i am being a bit imprecise here - I reckon I know what all the elements of the theorem are, but have trouble adding it all up. I hope someone bothers to help. Thanks in advance,
Henrik Update v3.b: I almost figured it out, I will update with my findings shortly (hope someone cares). So I still have some problems; can someone help me with these notions:
$P_{x}=P_{\delta_{x}}$, why $P_{\mu}(A)=\int P_{x}(A)\, \mu(dx)$ and what $E_{X_{n}}$ looks like explicitly.","['probability-theory', 'markov-chains']"
127773,Do countable unital rings with uncountably many distinct right ideals have uncountably many maximal right ideals?,Suppose we are given a countable unital ring $R$ with uncountably many distinct right ideals. Does it follow from this that $R$ has uncountably many maximal right ideals?,"['ring-theory', 'ideals', 'abstract-algebra']"
127779,"G acts primitively, faithfully on A. |A| is even, show |G| is divisible by 4","I want to ask for a hint to this problem:
G acts primitively, faithfully on A. |A| is even, show that |G| is divisible by 4",['group-theory']
127786,Is a subset of a topological space able to induce a quotient space,"As far as I know, a quotient space of a topological space must be defined wrt an equivalence relation on the topological space. But then I wonder what the equivalence relation is in the following
example from Wikipedia : In topology, especially algebraic topology, the cone $CX$ of a
  topological space $X$ is the quotient space: $$
         CX = (X \times I)/(X \times \{0\})\, $$ of the product of $X$ with the unit interval $I = [0, 1]$. Intuitively we make $X$ into a
  cylinder and collapse one end of the cylinder to a point. Is a subset of a topological space able to induce an equivalence
relation on the topological space, and to induce a quotient space? I know it is true for a subspace
of a vector space. Thanks and regards!",['general-topology']
127794,How to prove that r is a double root if and only if it is a root of a polynomial and of its derivative.,I don't know how to start the question. The title is self explanatory. How to approach and make a formal proof?,"['roots', 'derivatives']"
127809,Equivalence of norms in Sobolev space,"I am trying to prove an equivalence between two norms in the Sobolev space $H^1(\Omega)$ over a bounded Lipschitz domain $\Omega$, namely the standard norm $$||u||_{H^1(\Omega)}^2=\int_{\Omega} u^2 \,dx + \int_{\Omega} |\nabla u|^2\,dx$$ and the norm $$||u||_{\partial}^2= \int_{\partial \Omega} u_{|\partial \Omega}^2 \,d\sigma + \int_{\Omega} |\nabla u|^2\,dx$$ The second sumands are the same in both cases, so since in the first one we integrate the positve function $u^2$ over a larger domain, it is clear that $||u||_{\partial} \leq ||u||_{H^1(\Omega)}$, so it now suffices to find a positive constant $C$ such that $C||u||_{H^1(\Omega)}\leq ||u||_{\partial}$. Now we can use the following projection theorem: given a Hilbert space $H$ and a closed subspace $V\subset H$, for every $X\in H$ there exists a unique $P_Vx\in V$ such that $$||x-P_vx||=\inf_{v\in V} \{||v-x||\}$$ and besides $x-P_Vx\in V^{\perp}$. In our case, this yields a decomposition $$u=u_0+E(u_{|\partial \Omega})$$ where $E(u_{|\partial \Omega})$ is an extension to $\Omega$ of the restriction $u_{|\partial \Omega}$ and $u_0\in H_0^1(\Omega)$ and therefore $$||u||_{H^1(\Omega)}^2=||u_0||_{H^1(\Omega)}^2+||E(u_{|\partial \Omega})||_{H^1(\Omega)}^2$$ Note that by the projection theorem we have that $$||E(u_{|\partial \Omega})||_{H^1(\Omega)}^2=\inf\{||v||_{H^1(\Omega)}: v\in H^1(\Omega), v_{|\partial \Omega}=u_{|\partial \Omega}\} \stackrel{def}{=} ||u_{|\partial \Omega}||_{H^{1/2}(\partial \Omega)}$$ Does this lead towards our purpose? Thanks in advance for any insight.",['functional-analysis']
127813,What are the restrictions on the covariance matrix of a nonnegative multivariate distribution.,"This question is a step in answering this question on the stats.se. Given a distribution $F(X_1,\ldots,X_n)$ on the nonnegative orthant $\mathbb{R}_+^n$ (i.e. each of the marginals is supported on the nonnegative reals).  Where the mean of each marginal is 1 (i.e. $E(X_i)=1$ for all $i$).  What are the restrictions on the covariance matrix (assuming that it exists, other than positive semi-definiteness)? The idea is to be able to recognize a covariance matrix as coming from a nonegative multivariate distribution.  For example $\pmatrix{4&-3\\-3& 4}$ is a perfectly fine covariance matrix, it is symmetric and positive definite, but it cannot come from a non-negative multivariate ditribution with mean $\mathbf 1$ because $\text{Cov}(X_1,X_2)=E(X_1X_2)-1\ge-1$ as $E(X_1X_2)$ is positive.  I am certain that this is not the only such restriction.","['functional-analysis', 'probability']"
127818,Recurrence relation for number of ternary strings that contain two consecutive zeros,"The question is: Find a recurrence relation for number of ternary strings of length n that contain two consecutive zeros. I know for ternary strings with length one, there are 0. For a length of 2, there is just 1 (00), and for a length of 3, there are 5 (000,001,002,100,200). I did a similar problem, finding a relation for the number of bit strings of length n with two consecutive zeros: $$a_n = a_{n-1} + a_{n-2} + 2^{n-2}$$ Since you can add ""1"" to the end of all the $a_{n-1}$ strings, ""10"" to all the $a_{n-2}$ strings, and ""00"" any string of size $n-2$. For the ternary string problem, I'm pretty sure you would replace the $2^{n-2}$ with $3^{n-2}$, but confused about the other terms of the relation. My guess is that it would have the coefficient $2$ in front of the other terms, since you can add either $1$ or $2$ to the end of $a_{n-1}$ and either $01$ or $02$ at the end of $a_{n-1}$. So I believe the answer for the relation is: $$a_n = 2a_{n-1} + 2a_{n-2} + 3^{n-2}$$ How does that look?","['recurrence-relations', 'discrete-mathematics']"
127819,How does one find $z\in \mathbb{C}$ such that $\sin z=100?$,"I am self-studying Complex Analysis and I am suppose to find $z\in \mathbb{C}$ such that $\sin z=100.$ I know that $$\sin z=\sin x \cosh y+i\cos x\sinh y$$ So I must have $\sin x \cosh y=100.$ I looked in Wolfram and I found that $y=i(x-\sin^{-1}(100))$.  I was not able to solve this question. How does one find that solution? If fact, I was not expecting to find $y$ in function of $x$.","['complex-numbers', 'complex-analysis']"
127829,Bound for error term in Taylor expansion of $\arctan x$.,"I'm trying to solve the following problem from Apostol, Calculus, Volume I (p. 284) and could use some help: Prove:
  $$\arctan x = \sum_{k=0}^{n-1} \dfrac{(-1)^k x^{2k+1}}{2k+1} + E_{2n} (x), \qquad |E_{2n} (x)| \leq \dfrac{x^{2n+1}}{2n+1} \quad \text{if } 0 \leq x \leq 1.$$ Getting the Taylor expansion of $\arctan x$ is straightforward (and is worked out as an example in the text). My question : how do I prove the requested bound on the error term? This exercise is in the section immediately following the proof and examples of this Theorem (and some slight variations) for estimating the error term which states that: If the $(n+1)$st derivative of $f$ satisfies
$$ m \leq f^{(n+1)}(t) \leq M$$
then 
$$ m \dfrac{(x-a)^{n+1}}{(n+1)!} \leq E_n (x) \leq M \dfrac{(x-a)^{n+1}}{(n+1)!} \quad \text{if } x > a,$$
and
$$ m \dfrac{(a-x)^{n+1}}{(n+1)!} \leq (-1)^{n+1} E_n (x) \leq M \dfrac{(a-x)^{n+1}}{(n+1)!} \quad \text{if } x < a.$$ In order to apply this I need to get bounds $m$ and $M$ on the $(n+1)st$ derivative of $\arctan x$, which I cannot seem to arrive at. Updated :Taking successive derivatives, I find: $$\begin{align*}
f'(x) &= \dfrac{1}{1+x^2}\\
f''(x) &= \dfrac{-2x}{(1+x^2)^2}\\
f^{(3)} (x) &= \dfrac{6 (x^2 - 1/3)}{(1+x^2)^3}\\
f^{(4)} (x) &= \dfrac{-24 x (x^2 - 1)}{(1+x^2)^4}\\
f^{(5)} (x) &= \dfrac{120 (x^4 - 2x^2 + 1/5)}{(1+x^2)^5}
\end{align*}$$ I should add, from the formula for $|E_{2n} (x)|$ that we are trying to prove it seems the bound $M$ must be $(2n)!$. So, it seems clear the $n!$ term I want is there, but I can't seem to figure out how to explicitly bound this.  It seems that it should be rather obvious from here, but I'm having trouble. Any help is appreciated (hints or full solutions are equally welcome).","['calculus', 'taylor-expansion']"
127834,Use of determinants,"I have been teaching myself maths (primarily calculus) throughout this and last year, and was stumped with the use of determinants.  In the math textbooks I have, they simply show how to compute a determinant and some properties about them (i.e. Cramer's Rule), but not why they are used and how they work. So my question is, how do they work and why/when would I know to use them to help solve something?","['matrices', 'linear-algebra', 'self-learning', 'determinant']"
127838,Calculating $\int_{0}^{\infty}\sin(x^{2})dx$,"I am supposed, in an  exercise, to calculate the above integral by integrating $f(z) = e^{-z^{2}}$ on the following countor: I began by separating the path $\gamma$ into three paths (obvious from the picture), and parametrizing each as follows: $\gamma_{1} : [0, R] \rightarrow \mathbb{C}$ with $\gamma_{1}(t) = t$ $\gamma_{2} : [0, \frac{\pi}{4}] \rightarrow \mathbb{C}$ with $\gamma_{2}(t) = Re^{it}$ $\gamma_{3} : [0, \frac{\sqrt{2}R}{2}] \rightarrow \mathbb{C}$ with $\gamma_{3}^{-}(t) = t + it$ (with reverse orientation). Then we can say that $\displaystyle\int_{\gamma} f(z) dz = \displaystyle\int_{\gamma_{1}} f(z) dz + \displaystyle\int_{\gamma_{2}} f(z) dz - \displaystyle\int_{\gamma_{3}^{-}} f(z) dz = 0$ since the path is closed. Now $\displaystyle\int_{\gamma_{1}} f(z) dz = \displaystyle\int\limits_{0}^{R} e^{-t^{2}} dt$. We also get $\displaystyle\int_{\gamma_{3}^{-}} f(z) dz = -(i + 1) \displaystyle\int\limits_{0}^{\frac{\sqrt{2}R}{2}}e^{-2it^{2}} dt$. After playing around with sine and cosine a bunch to evaluate that last integral, I get: $$0 = \int\limits_{0}^{R} e^{-t^{2}} dt + \int\limits_{\gamma_{2}} f(z) dz - \frac{i + 1}{\sqrt{2}} \int\limits_{0}^{R} \cos(u^{2}) du + \frac{i - 1}{\sqrt{2}} \int\limits_{0}^{R} \sin(u^{2}) du$$ I could not evaluate the integral along the second path, but I thought it might tend to 0 as $R \rightarrow \infty$. Then taking limits and equating real parts we get $$\frac{\sqrt{2 \pi}}{2} = \displaystyle\int\limits_{0}^{\infty} \sin(u^{2}) du + \displaystyle\int\limits_{0}^{\infty} \cos(u^{2}) du$$ If I could argue that the integrals are equal, I would have my result.. But how do I? So I need to justify two things: why the integral along $\gamma_{2}$ tends to zero and why are the last two integrals equal.","['calculus', 'complex-analysis']"
127854,Gagliardo-Nirenberg inequality?,"For $1\leq p<n$, we define the Sobolev conjugate of$p$ as $p^{\ast}=\frac{np}{n-p}$. Recall the Gagliardo-Nirenberg inequality $$||u||_{L^{p^{\ast}}(\mathbb{R}^n)}\leq C ||\nabla u||_{L^p(\mathbb{R}^n)}$$ for some constant $C$ depending only on $n$ and $p$ for any function $u\in C_c^1(\mathbb{R}^n)$. From this, one derives easily the following estimate for $W^{1,p}$: let $U$ be a bounded open subset of $\mathbb{r}^n$, an open disk say. Assume that $1\leq p<n$ and let $u\in W^{1,p}(U)$. Then $u\in L^{p^{\ast}}(U)$ with $$||u||_{L^{p^{\ast}}(U)}\leq C||u||_{W^{1,p}(U)}$$ I came accross the following inequality $$||u||_{L^2(\partial U)}\leq C||u||_{L^p(U)}^{1-1/p} ||u||_{W^{1,p}(U)}^{1/p}, \quad u\in W^{1,p}(U)$$ Is this a consequence of the previous inequalities? I am even confused about the appropriateness of the 'u' in the left hand side: I would expect the restriction to $\partial U$ of a function $v\in W^{1,p}(U)$. Since the restriction operator $\tau:W^{1,p}(U)\rightarrow L^2(\partial U)$ is continuous, then $$||v_{|\partial U}||_{L^2(\partial U)}=||\tau(u)||_{L^2(\partial U)}\leq C||u||_{W^{1,2}(U)}$$ and from here I am wondering if the inequalities above shed some light.","['partial-differential-equations', 'inequality', 'real-analysis']"
127887,Riesz Representation Theorem from Rudin Real and Complex Analysis,"I've been annotating the steps in Riesz Rep. Theorem. So far, I have almost all of them. I just have six questions, some are short questions. So these questions are for anyone who has Rudin Real and Complex analysis on hand. (1) My first question starts on page $44$ for step IV. We start with two disjoint compact sets $K_1, K_2$. I'm not really clear on what $f(x) = 0$ on $K_2$. My reasoning is that we can an open set $V$ such that it contains $K_1$ and $V \cap K_2 = \emptyset$. So using Urysohn's lemma, we get $K_1 \prec f \prec V$ for some $f \in C_c(X)$. The support of $f$ lies in $V$, and since $K_2 \cap V = \emptyset$, $f(x) = 0$ for all $x \in K_2$. Are we guaranteed that we can find such open set $V$? (2) My next question is on the same step but at equation $(13)$. So far, it says $(9)$ shows that $(13)$ holds. I don't see how this is obvious. For me, i started with step I, used that $\mu(E) \leq \sum_{1}^{\infty}\mu(E_i)$. I just use the fact that there must be infinite number of zero sets or else $\mu(E) < \infty$ is violated. Also there must be finite number of non-zero sets, so is that why we get $(13)$? (3) On page 46 Step $X$. Rudin says, ""Clearly, it is enough to prove this for real $f$"". I don't have a complex analysis background but is he insinuating that the case for $f$ being complex is almost the same? (4) On the same page, between equation $(18)$ and $(19)$, Rudin mentions that the sets $E_i$ are therefore disjoint Borel sets whose union is $K$. I understand this paragraph except the part that $E_i$ are Borel sets. I'm thinking that I have to verify that $E_i$ are either closed or open. We have that $f$ is continuous so the pre-image of an open set is open. But I am having trouble getting to verify that fact. (5) In the same paragraph, Rudin says ""There are open sets $V_i \supset E_i$ such that $\mu(V_i) < \mu(E_i) + \frac{\epsilon}{n}$"" equation $(19)$ and such that $f(x) < y_i + \epsilon$ for all $x \in V_i$. Using equation $(2)$, I understand that $\mu(E_i) + \epsilon > \mu(V)$ for some open set $V$ such that $V \supset E$. Why does Rudin define equation $(19)$ as that way (the epsilon term divided by n) and was wondering why $f(x) < y_i + \epsilon$ for $x \in V_i$ <--- for this part, I can get a $V_i$ satisfying this inequality but dont see how it also satisfy $(19)$ (6) Same page, at the bottom, Rudin says that Step II shows that $\mu(K) \leq \Lambda(\sum h_i) = \sum \Lambda h_i$. This isn't obvious at all. I looked at $\mu(K) = \inf\{\Lambda f \mid K \prec f\}$ but we have that $h_i \prec V_i$. I tried showing that $K \prec \sum h_i$. But what seems to be the trouble is verifying that $0 \leq \sum h_i \leq 1$ for all $x \in X$ Thanks a bunch!","['measure-theory', 'riesz-representation-theorem', 'functional-analysis', 'real-analysis']"
127890,There exists an isometric embedding,"Let $W$ be a closed linear subspace of a normed vector space $V$. Let $i_V: V \to V^{**}$. and $i_W: W \to W^{**}$ be the canonical embeddings of V and W into their second duals. Prove that there exists an isometric embedding $\Phi: W^{**} \to V^{**}$. 
Show that $\Phi(W^{**}) = (W^{\perp})^{\perp}$. Can you help me to prove this? $(W^{\perp})^{\perp}=\{\Gamma \in V^* | F(f) = 0 \quad \text{for all} \quad f \in V^* s.t. f(W)=0\}$ I think I have to use Hahn Banach theorem, but I don't know how.","['normed-spaces', 'functional-analysis', 'banach-spaces']"
127893,Showing that $\lceil (\sqrt{3} + 1)^{2n} \rceil$ is divisible by $2^{n+1}$.,I have a question which has fluxommed me and my pals for the past few days. Any help or solution is welcome Show using Binomial theorem that the integer just after $(3^{1/2} + 1)^{2n}$ is divisble by $2^{n+1}$. here n belongs to natural numbers (positive integers).,"['algebra-precalculus', 'binomial-coefficients']"
127894,Prove that curve with zero torsion is planar,"I have proved that a planar curve of zero curvature is a straight line. It follows from the Frenet equations.
But now I need to prove that if $\varkappa=0$, then the space curve $\mathbf{r}(t)$ is planar.
From the condition and the Frenet equations it follows that
$$ \left\{
\begin{aligned}
\frac{d}{ds}\mathbf{v}&=k(s)\mathbf{n}(s),\\
\frac{d}{ds}\mathbf{n}&=-k(s)\mathbf{v}(s),\\
\frac{d}{ds}\mathbf{b}&=0.\\
\end{aligned}
\right. $$ But how can be technically deduced from these equations that the curve is planar? Update: from a related question planar curve if and only if torsion I have realized that I need to show that $(\mathbf{r}(t)-\mathbf{r}(t_0))\cdot\mathbf{b}(t)=0$ for any $t$ and some $t_0$. The question now is how to do that.
I appreciate any help.",['differential-geometry']
127912,Why is Klein's quartic curve not hyperelliptic,"Let $X$ be Klein's quartic curve given by $x^3y + y^3z+z^3x=0$ in $\mathbf{P}^2$. It is isomorphic to $X(7)$. How do I easily show that $X$ is not hyperelliptic? I can see that $X$ is of genus $3$ and has gonality $\leq 3$ (consider the projection). I'm trying to prove that it has gonality $3$. More generally, what is a computationally feasible way to check if a curve is not hyperelliptic? Note that I'm not really asking for a criterion. For example, to check if a variety is  normal you could try to show that it is regular (which is easier to me). Is the obvious morphism $X\to \mathbf{P}^1$ of degree $3$ Galois? That is, do we have that $X$ is a cyclic cover of degree $3$?","['galois-theory', 'riemann-surfaces', 'algebraic-geometry', 'algebraic-curves']"
127914,How to calculate scalar curvature in a local chart,I want to find a complete manifold with infinite diameter which has uniformly positive scalar curvature. And I want to show that $M^n = S^2(r) \times \mathbb{R}^{n-2}$ with $n \geq 3$ is an example which satisfying the properties above. How do I calculate the scalar curvature of $M$ in a local chart? How do I begin the calculations? Could everyone give me some hints or reference? Thank you very much!,"['riemannian-geometry', 'differential-geometry']"
127915,"Path-Connected implies Connected without knowing that [0,1] is connected","We all know the classical proof that a path-connected topological space $X$ is also connected. I will recall it briefly, so that we all talk about the same thing. Let $X$ be a path-connected topological space and assume for a contradiction that $X=A \cup B$, where $A \cap B = \emptyset$ and $A,B \neq \emptyset$ (i.e. $X$ isn't connected). Choose $a \in A$, $b \in B$
Let $\gamma: [0,1] \rightarrow X$
be a path in $X$ such that $\gamma(0)=a$, $\gamma(1)=b$. Then by continuity of $\gamma$ there is a decomposition $$[0,1]=\gamma^{-1}(A) \cup \gamma^{-1}(B)$$ and this decomposition implies that $[0,1]$ is not connected, which is not true. Hence we conclude that $X$ cannot be path-connected, if it isn't connected. Is there a proof, which does not use the connectedness of $[0,1]$? I would like a slick short proof similar to the one above, if you know one.
Or is there a good reason, why the connectedness of $[0,1]$ should be essential?",['general-topology']
127920,Pointwise convergence counter example.,"Can anyone think of a counter example that for $f_n:[a,b] \to \mathbb{R}$ regulated and $f_n \to f$ pointwise but $f$ is not a regulated function? Thanks!",['analysis']
127929,Moments and weak convergence of probability measures,"I was wondering, if you have a sequence of probability measures $(\mu_n)_n$ on $\mathbb R$ and you know that there is a probability measure $\mu$ such that for all $k\in\mathbb N=\{0,1,2,\cdots\}$ 
$$
\lim_{n\rightarrow\infty}\int x^kd\mu_n(x)=\int x^kd\mu(x),
$$
does it imply that for any continuous and bounded function $f$ you have
$$
\lim_{n\rightarrow\infty}\int f(x)d\mu_n(x)=\int f(x)d\mu(x) \qquad ?
$$
And if no, what if $\mu$ has compact support ? EDIT : I'm kind of lost : I understand reading the answers that it is somehow necessary that $\mu$ is characterized by its moments, but on an other hand, I come up with this proof, where I don't see what's wrong with. Could you help ? Since $\mu_n$ converges towards $\mu$ in moments, we have by density of the polynomials in $C_c(\mathbb R)$ that for any $h\in C_c(\mathbb R)$
$$
\lim_{n\rightarrow\infty}\int h(x)d\mu_n(x)=\int h(x)d\mu(x).
$$
Now, let $f\in C_b(\mathbb R)$, take any $h\in C_c(\mathbb R)$ satisfying $0\leq h \leq 1$, and write
$$
\left|\int f(x)d\mu_n(x)-\int f(x)d\mu(x)\right|
$$
$$
\leq \left|\int f(x)d\mu_n(x)-\int f(x)h(x)d\mu_n(x)\right|+\left|\int f(x)h(x)d\mu_n(x)-\int f(x)h(x)d\mu(x)\right|+\left|\int f(x)h(x)d\mu(x)-\int f(x)d\mu(x)\right|.
$$
Thus, using $\lim_n\mu_n(\mathbb R)=\mu(\mathbb R)$ (i.e the convergence of the ""$0$-th moment""), we obtain
$$
\limsup_n\left|\int f(x)d\mu_n(x)-\int f(x)d\mu(x)\right|\leq 2\|f\|_{\infty}\int(1-h(x))d\mu(x).
$$
Finally, given $\epsilon >0$, one can choose $g$ such that
$$
\int(1-h(x))d\mu(x)\leq \frac{\epsilon}{2\|f\|_{\infty}},
$$
I have the impression that I obtain the result... Where's the mistake ? Thanks in advance !","['measure-theory', 'convergence-divergence', 'real-analysis', 'analysis']"
127939,Convolution of measures,"We say that a family of measures $\mu_{t}\to \mu$ weakly if for any $g\in C_{0}$, $\int g d\mu_{t} \to \int g d\mu$. Show that if $\mu_{t}\to \mu$ weakly, then $\nu*\mu_{t}\to \nu*\mu$ weakly, where $\nu*\mu$ denotes the convolution of the measures $\mu$ and $\nu$.","['convolution', 'measure-theory', 'functional-analysis']"
127943,Zeroes of derivatives of high order,"The problem is following.
Let $f:(-1,1)\to [-1,1]$ has $n$ derivatives. Prove that there exists a number $\alpha_n$ (independent from $f$) such that condition $|f'(0)|\geq \alpha_n$ implies that equation $f^{(n)}(t)=0$ has at least $n-1$ distinct zeroes on $(-1,1).$ I can prove this for $n=2.$ In this case it is enough to take $\alpha_2>2.$ Unfortunatley, I can't proceed further and prove the general case.",['derivatives']
127952,A question about Lagrange multiplier,"Is there any explanation or interpretation of the concept of Lagrange multipliers $\nabla f(x_0)= \delta \nabla g(x_0) $ for some constant $\delta$ and $f$ is a differentiable function and g is the constraint of $f$. I know that this comes from the proof and I have read the proof, but does it give any geometrical meaning? Also, it is possible that $\nabla f(x_0)= \delta \nabla g(x_0) $ but $x_0$ doesn't give extremal points?","['multivariable-calculus', 'calculus', 'analysis']"
127969,Proof of Pinsker's inequality.,How to prove the following known (Pinsker's) inequality? For two strictly positive sequences $(p_i)^n_{i=l}$ and $(q_i)^n_{i=l}$   with  $\sum_{i=1}^np_i=\sum_{i=1}^nq_i=1$ one has $$\sum_{i=1}^np_i\log\frac{p_i}{q_i}\ge \frac{1}{2}\left(\sum_{i=1}^n|p_i-q_i|\right)^2.$$,"['probability-theory', 'information-theory', 'inequality', 'analysis']"
127992,How to plot this function,"I want to plot functions (using some software, any recommendations?) that looks like this below. Could someone suggest equations of functions that would look like the graph below?","['graphing-functions', 'functions']"
128029,Variance of product of Brownian motions,"Let $\{B_{t}\}_{t\geq0}$ be Brownian motion. What is the variance
of $B_{t}B_{s}$?","['probability', 'brownian-motion']"
128055,How to show a sequence is not uniformly integrable,"Let $(X,\Omega,\mu)$ be a measure space.  A sequence $f_n$ is said to be uniformly integrable if for every $\epsilon \gt 0$ there is a $\delta \gt 0$ such that for every measurable set $A$ with $\mu(A)\lt \delta$ , $\int_A |f_n|~d\mu \lt \epsilon$ , for every $n\in \mathbb{N}$ . A sequence is said to be tight if for every $\epsilon \gt 0$ there is a measurable set $B$ of finite measure such that $\int_{X\setminus B} |f_n|~d\mu \lt \epsilon $ , for every $n\in \mathbb{N}$ . I claim the $f_n = n\cdot 1_{[0,1/n]}$ is not uniformly integrable and $g_n = 1_{[n,n+1]}$ is not tight. Proof. Fix $\epsilon \gt 0$ . Pick $n$ sufficiently large so that for every $\delta \gt 0$ , $n\delta \gt 1/2.$ Then there is an $n$ such that $\int_A |f_n| \gt 1/2.$ Let $\mu(B)\lt \infty$ . Suppose to the contrary that $g_n$ were tight. Then $\mu\left((X\setminus B)\cap [n,n+1]\right) \lt \epsilon$ .   If I can get that $\mu(B) = \infty$ , then I would have a contradiction, but I don't see how. Is what I have done above right?",['measure-theory']
128061,Check if point is on or below line when either x or y = 0,"I have two points $(0,0)$ and $(93,3)$ I'm trying to work out whether a point is on or below the line segment defined by those two point. Currently I'm using $Ax+By+C=0$ to see if a point is on or below this line segment and this works correctly except for when the point is of the form $(0,y)$ or $(x,0)$ What am I doing wrong? Do I need to use a different form of the linear equation?","['geometry', 'algebra-precalculus']"
128075,"Why is $SO(3, \mathbb{C}) \cong PSL(2, \mathbb{C})$?","Why is $SO(3, \mathbb{C}) \cong PSL(2, \mathbb{C})$? I can't seem to be able to construct an explicit isomorphism between them.","['matrices', 'abstract-algebra']"
128085,Is the Hausdorff outer measure regular?,"An outer measure $\mu^*$ is said to be regular if for every set $A \subset X$ $$\mu^\ast (A)=\inf\{\mu^*(E) : E\supset A \text{ is } \mu^\ast\text{-measurable} \}$$ To check that an outer measure is regular, we just have to check whether $$\mu^\ast(A)\geq\inf\{\mu^*(E) : E\supset A \text{ is } \mu^\ast\text{-measurable} \}$$ since the other inequality follows from the outer measure axioms. I have to find out whether the $s$ -dimensional Hausdorff outer measure For any $s \geq 0$ and $\delta\gt0$ we define the $\delta$ -approximating $s$ -dimensional Hausdorff outer measure, $$\mathfrak{h}_{s,\delta}^\ast (A)=  \alpha_s \inf\left\{\sum_{i=1}^\infty \text{diam}^s(A_i): A \subset \bigcup_{i=1}^\infty A_i, \text{diam}(A_i)\lt\delta\right\}$$ and the $s$ -dimensional Hausdorff measure, $$\mathfrak{h}_{s}^\ast(A)=\sup_{ \delta\gt0}  \mathfrak{h}_{s,\delta}^\ast(A)= \lim_{\delta \downarrow 0} \mathfrak{h}_{s, \delta}^\ast(A)$$ Here $0\lt\alpha_s\lt\infty$ is chosen so that for $s \in \mathbb{N}$ the $s$ -dimensional Hausdorff measure of the $s$ -dimensional unit cube is one. is regular. Since the Lebesgue outer measure is one of these measures, and it is regular, I'm trying to prove the Hausdorff outer measure is regular. So far I've got to for any $A \subset X $ and $\delta\gt0$ $$\mathfrak{h}_s^\ast(A) \geq \inf\{\mathfrak{h}_{s,\delta}^\ast(E):A \subset E \text{ is } \mathfrak{h}_s^\ast\text{-measurable}\}$$ but I don't know how to show I'm allowed to swap my sup and my inf.  If indeed I am.","['measure-theory', 'geometric-measure-theory', 'analysis']"
128086,Convergence in probability: $\lim_{n\to\infty}\int_0^1\cdots\int_0^1\frac{x_1^2+x_2^2+\cdots+x_n^2}{x_1+x_2+\cdots +x_n}dx_1\cdots dx_n=\frac23$,"How to prove the following:
$$ \lim_{n \to \infty} \int_0^1 \int_0^1 \cdots \int_0^1 \frac{x_1^2+x_2^2+ \cdots +x_n^2}{x_1+x_2+ \cdots +x_n} dx_1 dx_2 \cdots dx_n = \frac23 $$ I would really appreciate if you could help me!","['probability-theory', 'convergence-divergence', 'integration']"
128097,"If $\mu^*$ is an outer measure induced by a premeasure and $E$ is locally measurable, then why is $E$ measurable?","This is essentially Exercise 1.21 in Folland's Real Analysis , which states the following: If $\mu^*$ is an outer measure induced by a premeasure and $\overline{\mu}$ is the restriction of $\mu^*$ to the $\mu^*$-measurable sets, then $\overline{\mu}$ is saturated. Definition: Folland says a measure $\overline{\mu}$ on a space $(X, \mathcal{M})$ is saturated if every locally measurable set is measurable, where a set $E$ is locally measurable if and only if $E \cap A$ is measurable for every $A \in \mathcal{M}$ with $\overline{\mu}(A) < \infty$. I'm having trouble showing that when $E$ is a locally measurable set with $\mu^*(E) = \infty$, then $E$ is measurable.  (The finite case is not hard.) Here's what I have so far.  Write $\mu_0$ for the premeasure, $\mathcal{A} \subset \mathcal{P}(X)$ for the algebra on which $\mu_0$ is defined, and $\mathcal{M}$ for the collection of all $\mu^*$-measurable sets.  Also, let $\mathcal{A}_{\sigma}$ be the collection of countable unions of sets in $\mathcal{A}$.  The hint is to use an earlier exercise: for any $\varepsilon > 0$, there is $A \in \mathcal{A}_{\sigma}$ with $E \subset A$ and $\mu^*(A) \leq \mu^*(E) + \varepsilon$.  So I obtain $E = \bigcup_{j=1}^{\infty} E \cap A_j$, where each $A_j \in \mathcal{A}$.  Then I want to use the locally measurable property, but it may be the case that $\mu_0(A_j) = \infty$ for some $j_0$. Any ideas?  We don't have any assumption that $\overline{\mu}$ is $\sigma$-finite, for example...",['measure-theory']
128098,Show that any abelian transitive subgroup of $S_n$ has order $n$,Can anybody tell me what is known about the classification of abelian transitive groups of the symmetric groups? Let $G$ be a an abelian transitive subgroup of the symmetric group $S_n$. Show that $G$ has order $n$. Thanks for your help!,"['abelian-groups', 'finite-groups', 'symmetric-groups', 'group-actions', 'group-theory']"
128102,Why is the Zariski topology on $\Bbb A^2$ not the product topology on $\Bbb A^1\times\Bbb A^1$?,Could you please give a hint how to show that the zariski topology on $\mathbb{A}^2$ is not the product topology on $\mathbb{A}^1\times\mathbb{A}^1$,"['general-topology', 'algebraic-geometry']"
128106,Why is the group of covering transformations relative to the quotient map isomorphic to a subgroup of the Fundamental Group?,"I'm trying to prove the classification theorem for covering spaces. I've got to the stage where I need to show the following: If $H$ a subgroup of $\Pi_1(X,x_0)$ then $\exists Y$ covering space of $X$ such that $\Pi_1(Y,y_0) = H$. Now I've shown that if $\tilde{X}$ the universal cover of X, then we may take $Y$ to be the group of $H$-orbits of $\tilde{X}$, where I'm identifying $H$ with the group of covering transformations relative to the covering map $r:\tilde{X}\rightarrow X$. Indeed let $q:\tilde{X}\rightarrow Y$ be the quotient map, then the natural map $p:Y\rightarrow X$ is a covering map (hard to prove, but shown here ). I then know that $\Pi_1(Y,y_0) = \Gamma(q)$, the group of covering transformations relative to $q$ on $\tilde{X}$. Clearly $H \leq \Gamma(q)$, but how do I prove the other inclusion? In particular how do I know that $\nexists g \in \Pi_1(X,x_0)$ s.t. $g \notin H$ and $q\circ g = q$? Many thanks in advance, and do tell me if I'm not being clear! Edit - maybe this argument works... Suppose $g$ satisfies the 'bad' properties I gave above. Let $x \in \tilde{X}$. Then in particular  $q \circ g = q$ means that $g(x) = h(x)$ for some $h \in H$. But then $g$ is the unique covering transformation sending $x$ to $h(x)$. But indeed $h$ is also a covering transformation sending $x$ to $h(x)$. So $g = h \in H$. But this is a contradiction! Hence $\nexists$ such a $g$, as required. Could someone possibly verify that this is correct?","['algebraic-topology', 'covering-spaces', 'classifying-spaces', 'group-theory']"
128108,"This multiple integral notation, has it got a name? $\int dx \int dy \, f(y,x)$","I've encountered, on Wikipedia (examples below), an integration notation which seems to be prefix-style: the integral sign is immediately followed by the $\mathrm dx$ (or $\mathrm dy$, or what have you), and this is followed by the function to be integrated. Multiple integration is done by multiple prefixes. I have two questions: Does this notation have a name (and perhaps a Wikipedia article)? In this prefix notation, are the integrals evaluated left-to-right, or inner-to-outer? First place I've encountered the notation: Wikipedia on multiple integration . Most relevant bit: If the domain D is normal with respect to the x-axis, and  is a continuous function; then α(x) and β(x) (defined on the interval [a, b]) are the two functions that determine D. Then:
  $$\iint_D f(x,y)\ dx\, dy = \int \limits_a^b dx \int \limits_{ \alpha (x)}^{ \beta (x)} f(x,y)\, dy.$$ Second place I've encountered the notation: Wikipedia on integration by parts . Most relevant bit: Consider the iterated integral:
  $$ \int_a^z \mathrm dx\ \int_a^x \mathrm dy \, h(y). $$
  In the order written above, the strip of width d is integrated first over the y -direction (a strip of width dx in the x direction is integrated with respect to the y variable across the y direction) as shown in the left panel of the figure, which is inconvenient especially when function h(y) is not easily integrated.","['notation', 'math-history', 'integration']"
128135,"How to prove $\int_0^1 \frac{1+x^{30}}{1+x^{60}} dx = 1 + \frac{c}{31}$, where $0 < c < 1$","This is an exercise from Apostol (p.285) that I'm having trouble with (in fact, I'm having trouble with the whole section): Prove that $\displaystyle{\int_0^1 \frac{1+x^{30}}{1+x^{60}} = 1 + \frac{c}{31}}, \qquad \text{where } 0 < c < 1.$ This comes from the section of Exercises following Taylor expansions, and Taylor's formula with error term.  It seems like the approach should involve getting this as the error term of the Taylor expansion of a function that we know something about?  I'm having trouble making much more progress than that. Updated Progress: From the definition of the error term of the Taylor expansion we have: $$E_n (x) = \frac{1}{n!} \int_a^x (x-t)^n f^{(n+1)} (t) dt$$ Alternatively, we may express this in the Lagrange form of the error term (derived from the weighted mean value theorem of integrals): $$E_n (x) = \frac{f^{(n+1)}(c)}{(n+1)!} (x-a)^{n+1} \qquad \text{where } a < c < x.$$ Now, let $a = 0$, $x = 1$, $n = 30$, $f^{(n+1)}(t) = \dfrac{1+t^{30}}{(1+t^{60})(1-t)^{30}}$, and set the two alternative expressions of $E_n(x)$ equal to each other: $$\begin{align*}
\implies & \frac{1}{n!} \int_a^x (x-t)^n f^{(n+1)}(t) dt & = & \dfrac{f^{(n+1)}(c)}{(n+1)!} (x-a)^{n+1}\\
\implies & \frac{1}{30!} \int_0^1 (1-t)^{30} \dfrac{1+t^{30}}{(1+t^{60})(1-t)^{30}} & = & \dfrac{1}{31!} \dfrac{1+c^{30}}{(1+c^{60})(1-c)^{30}}\\
\implies & \int_0^1 \dfrac{1+t^{30}}{1+t^{60}} & = & \frac{1}{31} \frac{1+c^{30}}{(1+c^{60})(1-c)^{30}}.
\end{align*}
$$ I cannot seem to get from here to $=1 + \dfrac{c}{31}$. If someone can show me pretty explicitly, step-by-step how to tackle this problem, I'd appreciate it.  Dealing with the error term on Taylor expansions is giving me quite a bit of trouble, so hopefully seeing a full solution will help clear things up.","['calculus', 'taylor-expansion']"
128144,Verifying - Trigonometry Homework,"I have a major problem with verifying a Trigonometric identity. (My teacher couldn't really get it, so I would like to find it just in case it appears on a test) The problem goes like this: $$\sin(\theta) + \cos(\theta) = \frac{\sin(\theta)}{1 - \cot(\theta)} + \frac{\cos(\theta)}{1 - \tan(\theta)}$$ Where I must verify that this is true. I have tried numerous operations, mostly getting to $\sin + \cos$ along with a crazy fraction in the numerator and another fraction in the numerator. As I have said, my teacher showed my something, but it really did not work after I continued simplifying. If there is anyone who would help guide me in this, it would be much appreciated.",['trigonometry']
128152,How to compute $\lim_{\beta\to \infty} \beta \mu(f \geq \beta)$?,"Let $(X, \Omega, \mu)$ be a measure space. Given that $f(x) = \frac{1}{x(1-\log x)}$, on $[0,1]$, how can I compute $\lim_{\beta\to \infty} \beta \mu(f \geq \beta)$?",['measure-theory']
128153,question on connection on tensor bundle induced by a linear connection,"I have a question regarding the definition of the covariant derivative of tensor fields, as given by John Lee in the book Riemannian Manifolds: An Introduction to Curvature On page 53 he states the following lemma: Let $\triangledown$ be a linear connection on $M$. There is a unique connection in each tensor bundle $T^k_l(M)$, also denoted $\triangledown$, such that the following conditions are satisfied: (a) On TM, $\triangledown$ agrees with the given connection (b) on $T^0M$, $\triangledown$ is given by ordinary differentiation on functions:
$$
\triangledown_X f = Xf
$$ This connection satisfies the following additional property: For any $F \in \mathcal{T}^k_l(M)$, vector fields $Y_i$ and 1-forms $\omega^j$, $$
\begin{eqnarray}
&(\triangledown_X F) (\omega^1, \dots \omega^l,Y_1, \dots Y_k) = 
 X( F (\omega^1, \dots \omega^l,Y_1, \dots Y_k)) \\
&- \sum_{i = 1}^l F (\omega^1, \dots , \triangledown_X \omega^i, \dots \omega^l,Y_1, \dots Y_k) \\
&- \sum_{i = 1}^k F (\omega^1, \dots ,  \omega^l,Y_1, \dots, \triangledown_X Y_i, \dots Y_k)
\end{eqnarray}
$$ Now, if I apply this property, say, to the Euclidean metric and the Euclidean connection, I obtain the following. Let $Y = Y^i \partial_i$ and $Z = Z^i \partial_i$ be vector fields in local coordinates. Let the Euclidean Connection $\overline{\triangledown}$ be given by 
$$
\overline{\triangledown}_X Y = (X Y^i) \partial_i
$$
Let $g$ denote the Euclidean metric, so that
$$
g(Y,Z) = \sum_i Y^iZ^i
$$
Then, the above property gives 
$$
\overline{\triangledown}_X g(Y,Z) = X(\sum_i Y^iZ^i) - \sum_i (XY^i)Z^i - \sum_i Y^i(XZ^i) = 0
$$ .. this does look strange - what am I doing wrong ?","['riemannian-geometry', 'differential-geometry']"
128181,An arctan series with a parameter $\sum_{n=1}^\infty \arctan \left(\frac{2a^2}{n^2}\right)$,"I'm trying to evaluate $$\sum_{n=1}^\infty \arctan \left(\frac{2a^2}{n^2}\right) \ , \ a >0. $$ The answer I get only seems to be correct for small values of $a$. What accounts for this? Using the principal branch of the logarithm, I get $$
\begin{align}
&  \sum_{n=1}^\infty \arctan \left(\frac{2a^2}{n^2}\right) \\ & =  \text{Im} \sum_{n=1}^\infty \log \left( 1 + \frac{2ia^2}{n^2} \right) \\
& = \text{Im} \log \prod_{n=1}^\infty \left(1 + \frac{2ia^2}{n^2} \right) \\ 
& = \text{Im} \log \prod_{n=1}^\infty \left(1 - \frac{(\sqrt{-2i}a)^2}{n^2} \right) \\
& =\text{Im} \log \left(\frac{\sin (\pi \sqrt{-2i}a)}{\pi \sqrt{-2i}a} \right) \\
& = \text{Im} \log \left(\frac{\sin \left(\pi (1-i)a\right)}{\pi (1-i)a} \right) \\
& = \text{Im} \log \left(\frac{\sin (\pi a) \cos (i\pi a) - \cos (\pi a) \sin (i \pi a)}{\pi (1-i)a} \right) \\
& = \text{Im} \log \left(\frac{\sin (\pi a) \cosh (\pi a) - i\cos (\pi a) \sinh (\pi a)}{\pi (1-i)a} \right) \\ 
& = \text{Im} \log \left(\frac{\sin (\pi a) \cosh (\pi a) + \cos(\pi a) \sinh (\pi a) + i \left( \sin (\pi a) \cosh (\pi a) -  \cos (\pi a) \sinh ( \pi a) \right)}{2\pi a} \right) \\
& = \text{Arg} \  \Big(\sin (\pi a) \cosh (\pi a) + \cos(\pi a) \sinh (\pi a)+ i \left( \sin (\pi a) \cosh (\pi a) -   \cos (\pi a) \sinh ( \pi a) \right) \Big)
\end{align}
$$","['branch-cuts', 'logarithms', 'sequences-and-series', 'complex-analysis']"
128186,Riemann sum of $\sin(x)$,"I would like to calculate the Riemann sum of $\sin(x)$. Fun starts here: $$R = \frac{\pi}{n} \sum_{j=1}^n \sin\left(\frac{\pi}{n}\cdot j\right)$$ What would be the simplest way to calculate the sum of $\sin\left(\frac{\pi}{n}\cdot j\right)$, so that one could proceed to evaluating the limit and thus getting the value of the Riemann sum, in other words - the integral? There maybe a way using $\mathbb{C}$?","['sequences-and-series', 'integration', 'limits']"
128193,Find the Bayes estimate of $θ$,"Can someone help me solve this out, please? Thanks a lot. Find the Bayes estimate of $\theta$ based on a single observation of $5$ from a distribution that is uniform on the interval 0 to $\theta$. Use square-error loss and a prior distribution of $\theta$ which has p.d.f. $p(\theta) = \theta \cdot \mathrm{e}^{-\theta}$ where  $0<\theta <\infty$.",['statistics']
128195,"Prove that the Lie derivative of a vector field equals the Lie bracket: $\frac{d}{dt} ((\phi_{-t})_* Y)|_{t=0} = [X,Y]$","Let $X$ and $Y$ be vector fields on a smooth manifold $M$, and let $\phi_t$ be the flow of $X$, i.e. $\frac{d}{dt} \phi_t(p) = X_p$. I am trying to prove the following formula: $\frac{d}{dt} ((\phi_{-t})_* Y)|_{t=0} = [X,Y],$ where $[X,Y]$ is the commutator, defined by $[X,Y] = X\circ Y - Y\circ X$. This is a question from these online notes: http://www.math.ist.utl.pt/~jnatar/geometria_sem_exercicios.pdf .","['lie-algebras', 'differential-geometry']"
128205,Maps that preserve measure zero property,"Consider a map $f: \mathbb{R}^n \to \mathbb{R}^m$ that is differentiable (usually even smooth). If $B \subset \mathbb{R}^m$ has measure zero (Lebesgue measure), then what types of maps $f$ satisfy $A = f^{-1}(B)$ also has measure zero? To provide some context: I have a property $\mathcal{P}$ that holds almost everywhere in $\mathbb{R}^m$; now I want to characterize the class of maps $f$ such that $\mathcal{P}(f(\cdot))$ holds almost everywhere in $\mathbb{R}^n$","['measure-theory', 'real-analysis']"
