question_id,title,body,tags
3431716,Can't solve a difficult limit,"I need to solve this limit ${\lim_ {x\to {+∞}}}{\frac{{x}(\sqrt{x^2 + x} - x) +\cos(x)\ln(x)}{\ln(1+\cosh(x))}}$ I've tried to use Taylor's Theorem with Peano's Form of Remainder, but first time I forgot that ${x\to{+∞}}$ , so I made a substitution ${t=\frac{1}{x}}$ , then I just didn't get anything (I've got ${o({\frac{1}{t}})}$ (or ${o((t-1)^3)}$ and too complicated expression) which doesn't disappear). I've thought to use L'Hospital's rule, but there's a problem with defining indeterminate form. Here we have ${\cos(x)\ln(x)}$ that sometimes becomes ${0\cdot∞}$ . Then I thought about the existence of this limit and... WolframAlpha says it doesn't exist. But the answer in my book is 1/2. So now Ii don't know how to solve it or does it even exist or not. Can anyone give me at least a hint of how to solve this problem?",['limits']
3431722,Darboux's Theorem and Kahler manifolds,"Suppose that $(M,g,J)$ is a complex manifold such that $g$ is a Hermitian metric. Then the Kahler form can be written $$\omega = i \sum_{j,k} g_{j \bar{k}}dz^j \wedge d \bar{z}^k$$ However, $\omega$ is also a symplectic form. Then shouldn't Darboux's theorem imply that there is a coordinate chart $U$ so that $$\omega|_U= i \sum_{j =1}^m dz^j \wedge d \bar{z}^j$$ However, this would imply that every Kahler manifold is locally flat which is certainly false. I think I am misunderstanding what vector space $\omega$ is supposed to be a symplectic form for. Can somebody explain why Darboux's theorem doesn't seem to apply even though $\omega$ is a symplectic form for $M$ ?","['complex-geometry', 'kahler-manifolds', 'differential-geometry']"
3431771,Intersection of equivalence classes of two equivalence relations,"Let $A$ be a nonempty set and $\sim$ and $\thickapprox$ two equivalence relations on the set $A$ . Relation $\triangle$ is defined like this: $x,y\in A,\;x\;\triangle\;y\;\iff x\;\sim\;y\;\wedge\;x\;\thickapprox\;y.$ Prove these statements: $1)$ $\triangle\; $ is an equivalence relation on the set A. $2)$$P\in A_{/\triangle}\iff \exists \;Q\in A_{/\sim}\;\wedge\;R\in A_{/\thickapprox}\;\;P=Q\cap R$ $P,Q,R$ are classes of equivalence (respectively) $$Q\in[a]_1,\; R\in[a]_2$$ By definition, an equivalence relation is reflexive, symmetric and transitive. reflexive property: $$\forall x\in A\; x\sim x\;\implies x\in[x]$$ symmetric property: $$\forall x,y\in A\;x\sim y\;\wedge\;y\sim x\;\;[x]=[y]$$ transitive property: $$\forall x,y,z\in A\; x\sim y\;\wedge\; y\sim z\implies x\sim z$$ It is analogous for the $\thickapprox$ relation.
Therefore, the conjunction holds the properties of both $\sim\;\&\thickapprox$ .
With: $$[a]:=\{x\in A: a\sim x\;\wedge\;a\thickapprox x\}\iff\{(x\in A:\;\;a\sim x)\;\wedge\;(x\in A:\;a\thickapprox x)\}\;
$$ $$\iff\{\;[a]_1\;\cap\;[a]_2\;\}$$ $A_{/\triangle}=\{[a] : a\in A\}=\{\;[a]_1\;\cap\;[a]_2\;\}\implies P\in A_{/\triangle}\iff\;P\in ([a]_1\cap\;[a]_2)\;$ $\iff \exists \;Q\in A_{/\sim}\;\wedge\;R\in A_{/\thickapprox}\;$ so that $\;P=Q\cap R$ Is this legitimate?","['elementary-set-theory', 'equivalence-relations', 'proof-verification']"
3431773,Trouble with proof by induction,"I am trying to prove that the following recursive function $$f(n)=\begin{cases}1,\ n=0,\ \\ (2n-1)f(n-1),\ n>0,\end{cases}$$ can be expressed as $$f(n)=\frac{(2n)!}{n!2^{n}}.$$ I know that this should be done by induction. It is easy to see that for $n=0$ the statement holds, i.e., $f(0)=1$ . As for the induction step I have assumed that $$f(n-1)=\frac{(2n-1)!}{(n-1)!2^{n-1}}$$ holds for some $n\in$ $\mathbb{N}$ . From the recursive definition I have that $f(n)=(2n-1)f(n-1)$ in which I have tried to arrive at the desired statement but to no avail. I have tried calculating $(2n-1)f(n-1)$ in various ways but nothing seems to get me there. Furthermore, I am not sure whether this even is the right approach. $\textbf{Side note:}$ In the problem it is not clear as to how $(2n)!$ is defined which also confuses me a bit. I am assuming it is defined as $(2n)!=2n(2n-1)!$ but it could also be $(2n)!=2n(2(n-1))!$ which obviously results in completely different answers. Any hints would be highly appreciated. Thanks in advance.","['induction', 'recurrence-relations', 'discrete-mathematics']"
3431801,Is it possible to produce a field with three operations?,"A Field $F$ is defined such that: There is a first operation, say $+$ (addition), that is closed, associative and commutative over $F$ , and has an identity element $0 \in F$ and an inverse element $-x \in F$ for each $x \in F$ (that is, $(F, +)$ is a commutative group); There is a second operation, say $\cdot$ (multiplication), that is closed, associative and commutative over $F \setminus \{0\}$ , and has an identity element $1 \in F \setminus \{0\}$ and an inverse $1/x \in F \setminus \{0\}$ for each $x \in F \setminus \{0\}$ (that is, $(F\setminus \{0\}, \cdot)$ is a commutative group); The second operation distributes over the first operation. My question is this : Is it possible to define a third operation, say $*$ , for $F$ such that $(F\setminus \{0,1\}, *)$ , is a commutative group and $*$ distributes over multiplication? In other words, is it possible to have $(F, +, \cdot, *)$ where both $(F,+, \cdot)$ and $(F\setminus \{0\},\cdot, *)$ are fields? My gut feeling is no. In all fields I am familiar with $(\mathbb{Q,R,C,Z}_p)$ , the multiplication is provably equivalent to that field's analytic continuation of iterated addition, but the analytic continuation of iterated multiplication (that is, exponentiation) is provably not a commutative group operation on $(F \setminus \{0,1\})$ (and catastrophically so, it fails on all counts! It's not even well-defined!) However, the coincidence that multiplication is equivalent to iterated addition feels like just that, a coincidence, as the definition of field makes no claims about the relation between the two operations other than the distributive property. Is my gut feeling correct, or am I right to be skeptical?","['field-theory', 'abstract-algebra']"
3431851,"What is a generally accepted definition of ""curve"" in mathematics?","I am wondering if there is a generally accepted definition of the term curve in mathematics.  If one does exist, is there any requirement of continuity, beyond what is required by the piecewise differentiable property defined and applied to the definition of a curve in what follows? Some authors call an entire hyperbola a curve, even though its two branches nowhere share a point. That is somewhat contrary to the naive concept of curve , but isn't too difficult to accept. On the other hand, the following definitions seem to leave a lot of room to produce things which satisfy the definition of curve , but we would never call curves in real life. This is from Thomas's Calculus and Analytic Geometry, 2nd Edition, 1953. The cardinal principle of analytic geometry is that an equation $F(x,y)=0$ describes a curve which is the locus of all and only those points $P(x,y)$ whose coordinates satisfy the given equation. In that context, the meaning of the term curve is closer to what Gray, et al., are calling the trace of a curve in the following taken from Modern Differential Geometry of Curves and Surfaces with Mathematica,3rd Edition: From Thomas's definition we could produce an equation that determines a set of points, none of which are connected.  I assume he was merely giving the historical definition, and not intending to be rigorous. So, is the mathematical definition of curve really wide open, beyond piecewise differentiability?","['analytic-geometry', 'geometry', 'definition', 'differential-topology', 'differential-geometry']"
3431876,How to prove $\mathbb Z_3\rtimes(\mathbb Z_2\mathbb \times\mathbb Z_2) \cong S_3\times\mathbb Z_2$?,"I know that there is a unique semidirect product $\mathbb Z_3\rtimes(\mathbb Z_2\times \mathbb Z_2)$ , defined by mapping two of the order two generators of $\mathbb Z_2\times \mathbb Z_2$ to the inversion automorphism of $\mathbb Z_3$ . However, I am not exactly sure how to proceed to show that $\mathbb Z_3\rtimes(\mathbb Z_2\mathbb \times\mathbb Z_2) \cong S_3\times\mathbb  Z_2$ . What exactly is the map I could construct?","['semidirect-product', 'group-theory', 'abstract-algebra']"
3431917,Example of a linear operator has no continuous inverse [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Construct a linear mapping $T : X → Y$ between two normed linear spaces X
and Y such that T is one-to-one, onto, and continuous, but $T^
{−1}$ is not continuous. I can not find any example because of linear mapping. Thanks for any hint with that.","['functional-analysis', 'real-analysis']"
3432058,"$P,Q$ Sylow subgroups $\implies$ $PQ$ a subgroup","$|G|<+\infty$ , $p\not=q$ primes, $n_p=p+1$ , $n_q=q+1$ . I want to show that $\exists P\in Syl_p(G), Q\in Syl_q(G)$ s.t. $PQ=P\times Q<G.$ I understand this exercise as to show that $PQ$ is a subgroup. If one of tham is normal, then the statement is trivial. However, neither $n_p$ nor $n_q$ is $1$ , we don't know the normalities of $P$ and $Q$ . The main problem is showing the closedness of the operation: $a=p_1q_1, b=p_2q_2.$ $ab=p_1q_1p_2q_2\in PQ?$ From the Sylow theorems, I've got some facts like $$|G|=p^nq^mA\implies p+1|q^mA,\ q+1|p^nA$$ but how to connect them to the closedness.","['group-theory', 'abstract-algebra', 'sylow-theory']"
3432083,About solving $f(z) = \frac{1}{4} (f(-1-z) +2 f(-1-2z)+ 2f(-1+2z) +f(-1+z))$,"Final update on 11/29/2019: I have worked on this a bit more, and wrote an article summarizing all the main findings. You can read it here . I am looking for a solution where $f(z)\geq 0$ and $\int_{-\infty}^{\infty} f(z) dz = 1$ . I believe there is only one solution. That solution also satisfies $f(z) = f(-z)$ and $f(0) = f(-1) = f(1)$ . In fact $f$ is the density of $Z$ , with $$ Z= X_1 + X_1 X_2 + X_1 X_2 X_3 +\cdots $$ with the $X_i$ 's being i.i.d with the following distribution: $$P(X_i= -1) = P(X_i =-0.5) = P(X_i = 0.5) = P(X_i = 1) = 0.25.$$ We also have $$E(Z^k) = \int_{-\infty}^{\infty} z^k  f(z) dz = \frac{1}{2}
\Big(1+ \frac{1}{2^k}\Big) \int_{-\infty}^{\infty} (1+z)^k f(z)dz$$ if $k$ is even, or zero otherwise. Note that the characteristic function of $Z$ satisfies $$\frac{d^k \psi_Z}{dt^k}(0) = \frac{d^k E(\exp it Z)}{dt^k}(0)= i^k E(Z^k).$$ The reason why I am interested in this problem can be found here . The empirical percentile distribution of $Z$ is pictured below: Update This is a particular case of a more general problem: solving $F_Z = F_{g(X,Z)}$ where $g$ is any function, $F$ represents the distribution associated with the density $f$ , and $X, Z$ are independent random variables. In this case, $g(X,Z) = X(1+Z)$ . Another case involving $g(X, Z) = \sqrt{X+Z}$ was discussed here . Despite the smooth appearance of $F_Z$ , it is possible that $F_Z$ is nowhere differentiable. Similar distributions have been analyzed by David Bailey in his book Experimental Mathematics in Action , published in 2007. In particular, sections 5.2 and 5.3 (pages 114-137) are very relevant to this context. One of the densities he has studied, namely $2qf(x) = f(\frac{x-1}{q}) + f(\frac{x+1}{q})$ , is very similar to the one I posted on Math.Stackexchange, here , leading to the same discussion as to when it is smooth or not, an unsolved problem in many (but not all) cases. All these problems end up in some functional equations like the one discussed in this question. A possible way to find a numerical solution is as follows. Build a sequence of densities $f_n$ that are piecewise uniform on the support domain, starting in this very particular case with $f_1(x) = \frac{1}{2}$ if $x\in [-1, 1]$ and $f_1(x) = 0$ otherwise. In fact, it's quite possible that $f$ is constant on $[-1, 1]$ based on empirical evidence. Each $f_n$ must satisfy $f_n(x) \geq 0, f_n(x) = f_n(-x)$ , and $\int_{-\infty}^{\infty} f(x) dx = 1$ . Of course this assumes that the density exists, and that the solution satisfying these constraints is unique. It also assumes that the algorithm in question converges to the solution. For instance, $f_n$ might be defined using $n$ intervals $I_{n1}, \cdots, I_{nn}$ , with $f_n(x) = c_{nk}$ constant $(k=1,\cdots,n)$ if $x\in I_{nk}$ . The intervals $I_{nk}$ 's and the constants $c_{nk}$ 's are chosen so as to minimize some error criterion $E_n$ , for instance $$E_n = \sup |F_{Z}^{(n)}(x) - F_{g(X,Z)}^{(n)}(x)| \mbox{ or } E_n = \int_{-\infty}^{\infty} |F_{Z}^{(n)}(x) - F_{g(X,Z)}^{(n)}(x)| dx.$$ Here $F^{(n)}$ is the distribution attached to $f_n$ . Techniques about how to solve this problem are described in my article New Perspectives on Statistical Distributions and Deep Learning . I will add an illustration in the next few days, if I find the time.","['functional-equations', 'statistics', 'probability-distributions', 'sequences-and-series', 'probability-theory']"
3432094,"Let $K = \{f \in \mathcal F \mid f \text{ is constant function}\}$, prove that $K$ is the smallest element of $F/S$ in the partial order $T$.","$$\mathcal F = \{f \mid f: \mathbb R \rightarrow \mathbb R\}$$ $$R = \{(f,g) \mid \exists h \in \mathcal F (f = h \circ g )\}$$ $$S = R \cap R^{-1}$$ $$[f]_S = \{h : hSf\}$$ $$F/S = \{[f]_S \mid f \in \mathcal F\}$$ $T \subseteq \mathcal F / S \times
 F / S$ , such that for all $f,g \in \mathcal F$ , $[f]_ST[g]_S$ iff $fRg$ , and $T$ is a partial order on $\mathcal F /S$ . $K = \{f \in \mathcal F \mid f \text{ is constant function}\}$ Prove that $K$ is the smallest element of $\mathcal F/S$ in the partial
order $T$ . My attempt: What we know S is an equivalence relation on $\mathcal F$ $\mathcal F/S$ is a partition (Follows from the fact that $S$ is an equivalence relation) $K \in F/S$ (I tried to show it here ) Now take $X \in F/S$ . Take $f \in K$ and $g \in X$ . We know that $f$ is a constant function, thus $f = f \circ g$ and $fRg$ . Since $f,g$ were arbitrary, we conclude that for all $f \in K$ and for all $g \in X$ , $fRg$ . Hence $(K,X) \in T$ . Since $X$ was arbitrary, we have $$\forall X \in F/S\bigl((K,X) \in T\bigr)$$ Thus $K$ is the smallest element of $F/S$ . $\Box$ Is it correct?","['elementary-set-theory', 'functions', 'proof-verification']"
3432153,Rolle's theorem for second derivative,"A problem asks the following $f$ is a twice-differentiable function on some segment $[a,b]$ such that $f(a)=f(b)$ and $f'(a)f'(b)<0$ . 
it asks to prove that the second derivative of $f$ vanishes at some point between $a$ and $b$ (strictly). What about this situation","['rolles-theorem', 'derivatives']"
3432180,"If $A^3 =0$, what is the determinant of $(A-3I)$? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question From $A^3 = 0$ , I can conclude that A must be singular. But how to proceed from there?","['matrices', 'determinant', 'linear-algebra']"
3432213,Proving a Function is Strictly Greater than Another Using the Derivative,"Let $f:[0,1]→\mathbb R$ and $g:[0,1]→\mathbb R$ be differentiable with $f(0)=g(0)$ and $f'(x)>g'(x)$ for all $x\in [0,1]$ . Prove $f(x)>g(x)$ for all $x\in (0,1]$ There only seems to be a related theorem, but only applies if $f'(x)=g'(x)$ . I think it might be modifiable to fit this case. The theorem states: Suppose that $f$ and $g$ are continuous on $[a,b]$ and differentiable on $(a,b)$ and that $f'(x)=g'(x)$ for all $x\in (a,b)$ . Then there is a real number $k$ such that $f(x)=g(x)+k$ for all $x\in [a,b]$ . So, we want the case that $f'(x)>g'(x)$ . Although, I'm not sure if I would use this theorem for this problem. Do I have to use IVT or construct a new function?","['derivatives', 'analysis', 'real-analysis']"
3432243,Pushing in negation in first order logic,"Assume you have a formula $$\neg (\forall_y \exists_x p(x,y))$$ Can this formula be rewritten using the $\delta$ rule: $\neg \forall_x A(x)$ rewritten to $\neg A(a)$ Thereby, $\neg (\forall_y \exists_x p(x,y))$ rewrites to $\neg \exists_x p(x,y)$ ? I am a little unsure of how to apply this $\delta$ rule properly?","['predicate-logic', 'first-order-logic', 'quantifiers', 'logic', 'discrete-mathematics']"
3432267,"Let a and b be natural numbers. Use induction to prove that if gcd(a,b) = 1 then for all natural numbers n, gcd(a,b^n) = 1.","Is my proof correct? Thank you! Let $gcd(a,b)=1$ . Suppose $gcd(a,b^n)=1$ for all $n\in\mathbb{N}$ . This is proven by induction. Let $p(n): gcd(a,b^n)=1$ . For the base case, we need to verify that $p(1)$ is true. If $n=1$ then $gcd(a,b^n)=gcd(a,b)=1$ . Hence, $p(1)$ is true. For the inductive step, we must prove that $p(k)$ is true for some k implies $p(k+1)$ is true. Suppose $p(k)$ is true for some k then $gcd(a,b^k)=1$ . Now we want to show $gcd(a,b^{k+1})= gcd(a,b^kb)=1$ . By Bezout's identity, since there are non-zero integers $x,y,u,v$ so that ${ax+by=1}$ and ${au+cv=1}$ , we have $$
\begin{align}
bycv=(1-ax)(1-au)\\
=1-a(x+u-axu)\\
a(x+u-axu)+bcvy
=1.
\end{align}
$$ Therefore, $(a,bc)=1$ since it is a linear combination of $a$ and $bc$ that equals 1. If $a$ and $bc$ had a common factor, that common factor would divide any linear combination of $a$ and $bc$ . Applying Bezout's Identity to our problem, we know since there are non-zero integers $x,y,u,v$ so that $ax+by=1$ and $au+b^kv=1$ , we have $$byb^kv = (1-ax)(1-au)\\ =1-a(x+u-axu)\\$$ $$
a(x+u-axu)+b^kbvy = 1.$$ Thus, $(a,b^kb)=1$ since it is a linear combination of $a$ and $b^kb$ that equals 1. If $a$ and $b^kb$ had a common factor, that common factor would divide any linear combination of $a$ and $b^kb$ . Therefore $gcd(a,b)=1, gcd(a,b^k)=1$ . We know if $gcd(a,b)=1$ and $gcd(a,c)=1$ then $gcd(a,bc)=1$ by Bezout's identity. Therefore $p(k+1)$ is also true. Therefore, $p(n)$ is true for all natural numbers n by induction (i.e., $gcd(a,b^n)=1$ for all $n\in\mathbb{N}$ ).","['induction', 'proof-verification', 'discrete-mathematics', 'real-analysis']"
3432368,Prove that $\frac{\arccos(x)}{\sqrt{1-x}}$ is decreasing,"I want to show that $$f(x):=\frac{\arccos(x)}{\sqrt{1-x}}$$ is a decreasing function. I tried to differentiate but than I have to show that $$\arccos(x)\sqrt{1+x} \leq 2 \sqrt{1-x}.$$ Everytime I tried something I ended up with a even more complex problem or in general something like finding roots of some nonlinear functions. E.g. I could transform the above inequality to $$\int_{-1}^x2\arccos(y)\mathop{}\!\mathrm{d}y +(1-x)\arccos(x)\leq 2\pi,$$ but it didn't helped me a lot. Is there a way to prove analytically that the function $f$ is decreasing? EDIT: The domain is $-1\leq x\leq 1$ . This is valid, since $$ \lim_{x\to 1^{-}}f(x)=\sqrt{2}.$$","['analysis', 'real-analysis', 'calculus', 'trigonometry', 'inequality']"
3432370,On two variable real positive functions,"Suppose $$ H(x,y)=x \exp^{\pi y}-\frac{x(\pi-x)}{\pi}e^{xy}+(\pi-x)(\frac{\pi^2}{12}-1)e^{xy}-\frac{\pi^2}{12}x \sinh(\pi y)\\ +(1-\frac{\pi^2}{12})(\pi-x)-x,$$ $$R(x,y)=(e^{xy}-1)+\frac{(\pi-2)(\pi-x)}{2 \pi}e^{xy}.$$ With some calculating, I guess that, there exists $0.4<\alpha<0.5$ such that $$A)\quad H(x,y)\geq 0,\quad (x,y) \in [\alpha,\pi)\times [0, \infty)$$ and $0.4<\beta<0.5$ such that $$B)\quad R(x,y)\geq 0,\quad (x,y) \in [\beta,\pi)\times [0, \infty)$$ $$C)\quad R(x,y)\geq 0,\quad (x,y) \in [0,\pi]\times [\frac{1}{\pi}, \infty)$$ Our main purpose is finding the proof of A, B and C and the exact value of $\alpha$ and $\beta$ . Also we have, $$1)\,H(0,y)=0,\, y\geq0, \qquad 2)\,H(\pi,y)\geq 0,\, y\geq 0.$$ But we can't get the complete proof. I appreciate any solutions, comments and hints.","['calculus', 'functions', 'inequality']"
3432401,Prove $\mathbb{Q}$ is a path-connected topological space,"I am trying to comprehend how path-connectedness of a topological space is proved in essence to solve another problem (to prove the plane $\mathbb{R}^2$ without a line is not path-connected) and have troubles with it. There is a quite intuitive definition of path-connectedness: a topological space is path-connected if for any two points in that space there exists a continuous function from a compact $[a,b]$ to that space such that its $f(a)$ and $f(b)$ are equal to those points respectively. Now, I've made this simple problem (stated in the title) for myself to understand how it's proved. The way I think (although it's a hand-waving proof, I do not understand the flaw I've made): Let's split a closet interval $[0,1]$ into semi-intervals like $(x_1,x_2]$ with $x_2 > x_1$ (and keep the first one starting from 0 to be a closed interval for the sake of symmetry, i.e. the first one is $[0,x]$ ). Obviously, I can split this interval into countable amount of such semi-intervals. Therefore, since between any two rational points $a$ and $b$ there're countable amount of rationals, I can construct a function mapping these semi-intervals to points in $[a,b]\cap\mathbb{Q}$ (e.g. I can identify each semi-interval with a rational point enclosed in between to get an enumeration and that match each semi-interval to each point in enumerated set of points in $[a,b]\cap\mathbb{Q}$ with some bijection $f:\mathbb{N}\to\mathbb{N}$ ). A function constructed as such is continuous because for any rational point in $[a,b]\cap\mathbb{Q}$ there exists a whole neighbourhood mapped to this single point.
And since we can construct such a continuous function for any two rational points, Q is path-connected. Thank you!","['general-topology', 'analysis', 'connectedness']"
3432534,Dimension of projection of projective variety on hyperplane,"I have given a closed projective variety $X$ of dimension $k$ and a hyperplane $H$ in $\mathbb{P}^n$ . When we take a point $P \notin H$ we can construct the projection $\pi$ by $P$ on $H$ . I managed to show that the map $\pi$ is a closed morphism and hence $\pi(X) \subset H$ is a closed variety. However, I'm having trouble by proving some dimension claims about $\pi(X)$ . There are actually three different cases: (1) $P \notin X$ : in this case, we have to prove that $\dim(X) = \dim \pi(X)$ . So far, I managed to show that the dimension of $\pi(X)$ is at most $k$ because if $V \subset \pi(X)$ is a closed subvariety then, $\pi^{-1}(V)$ is a closed subvariety of $X$ . However, when we have a chain of chain of subvarieties $U_i \subset X$ then we know that $\pi(U_i) \subset \pi(X)$ is also a subvariety, but I think we can't assume that they are distinct. Is there a way to fix this? (2) $P \in X$ but there is a $Q \in X$ such that the line $PQ$ is not fully contained in $X$ . I also have to prove that $\dim(X) = \dim\pi(X)$ . I think I need to 'choose' a specific chain of subvarieties with the help of the point $Q$ but I don't know how I can construct this. (3) $P \in X$ but for all $Q \in X$ , the line $PQ$ is fully contained in $X$ . I now have to prove that $\dim\pi(X) = \dim(X) - 1$ . It is clear that $\pi(X)$ = $X \cap H$ so I'm wondering if I can say something about the dimension of the intersection of two projective varieties, but again, I don't really have an idea on how to start.","['algebraic-geometry', 'projective-varieties']"
3432576,"Find the number of natural solutions for $x_1 +x_2 + \cdots + x_k = n$, with $ x_i \notin 3\mathbb{N}$.","Find the number of natural solutions for $$x_1 +x_2 + \cdots + x_k = n,$$ with the constraints $x_i \notin 3\mathbb{N}$ for $i=1,2,\dots,k$ . My Attempt: the generating function of the equation is: $f(x) =(x+x^2)(1+x^3 +x^6+\cdots +x^{3k} +\cdots)$ Now I know that for $g(x) = 1+x+x^2+\dots +x^k +\cdots = \ \sum_{k=0}^\infty x^k =  \frac{1}{1-x}$ does that mean that $f(x) =(x+x^2)(1+x^3 +\cdots +x^{3k} +\cdots)= \sum_{k=0}^\infty (x^{3k})\cdot(x+x^2) = \frac{(x+x^2)}{1-x^{3k}}$ But How do I Continue with my function?","['proof-verification', 'combinatorics', 'discrete-mathematics', 'generating-functions']"
3432579,"Is there a correspondence between $\operatorname{Spec}K[x_1,\dotsc,x_n]/\operatorname{Gal}(K/k)$ and $\operatorname{Spec}k[x_1,\dotsc,x_n]$?","The prime ideals of $\mathbb{C}[x]$ are $(0)$ and $(x-a)$ for $a\in\mathbb{C}$ . Similarly, the prime ideals of $\mathbb{R}[x]$ are $(0)$ , $(x-a)$ for $a\in\mathbb{R}$ and $(x^2+ax+b)$ for an irreducible quadratic. This suggests that we can see $\operatorname{Spec}\mathbb{R}[x]$ as the quotient of $\operatorname{Spec}\mathbb{C}[x]$ by the action of the Galois group $\operatorname{Gal}(\mathbb{C}/\mathbb{R})$ . The same correspondence holds for $\operatorname{Spec}\mathbb{R}[x,y]$ , I think. I would like to know then under what conditions we have a bijection correspondence between $\operatorname{Spec}k[x_1,\dotsc,x_n]$ and $\operatorname{Spec}K[x_1,\dotsc,x_n]/\operatorname{Gal}(K/k)$ for a field extension $K/k$ . If we have such a bijection, is it also a homeomorphism for the Zariski topology? My attempts of proof seem to suggest that we need $K/k$ to be Galois, but I am not sure.","['algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
3432683,The convergence of $\sum_{n=1}^\infty (-1)^n\left(\frac{n}{e}\right)^n\frac{1}{n!}$,"I'm trying to figure out if the $\sum_{n=1}^\infty (-1)^n\left(\frac{n}{e}\right)^n\frac{1}{n!}$ converges or not. I've tried the Leibnitz test for alternating series, but it leads to Stirling's formula and I was wondering if there's any other way so I could avoid using it. I'll be grateful for any idea.","['power-series', 'convergence-divergence', 'sequences-and-series', 'real-analysis']"
3432725,Trying to apply Rolle's Theorem,"Let $f$ be a differentiable function in the interval $[a,b]$ . Prove that 
  there exists $c\in ]a,b[$ such that $$f'(c)=f(c)\dfrac{(a+b-2c)}{(c-a)(c-b)}$$ My ideas are: maybe we need to find a function having a derivate similar to $\dfrac{(a+b-2x)}{(x-a)(x-b)}f(x)$ ?","['real-analysis', 'calculus', 'rolles-theorem', 'algebra-precalculus', 'derivatives']"
3432757,What are all simplifiable fractions k/N (0<=k<=N) called and how can one generate them?,"The problem I am trying to solve is as follows: Take a positive integer $N$ . Give the function $f$ , such that $f(N)$ generates the sequence of all fractions $\frac{k}{N}$ where $(0 \le k \le N)$ such that $\frac{k}{N}$ can be simplified ( $k$ and $N$ are not co-prime*) *This might actually not be sufficient to say (since 0 is co-prime to 1 for example), so below the definition I came up with, that includes 0 and N itself. Fractions where the numerator and denominator share some factor. a.k.a some fraction $\frac{i}{j}$ can be found such that $\frac{i}{j} = \frac{k}{N}$ where $\frac{i}{j}$ itself can't be simplified further or an integer $I$ can be found such that $I = \frac{k}{N}$ . An example would be: Let $N = 12$ Now $f(12) = \{\frac{0}{12} , \frac{2}{12} ,\frac{3}{12} ,\frac{4}{12} ,\frac{6}{12} ,\frac{8}{12} ,\frac{9}{12} ,\frac{10}{12} ,\frac{12}{12} \}$ Which when simplified would become: $f(12) = \{0, \frac{1}{6} ,\frac{1}{4} ,\frac{1}{3} ,\frac{1}{2} ,\frac{2}{3} ,\frac{3}{4} ,\frac{5}{6} ,1 \}$ My related questions are: What is this sequence called? How would one name the sequence of all $GCM(k, N)$ (e.g. $\{0,2,3,4,6,8,9,10,12\}$ ) What would the function to generate this sequence look like? Research I have already performed: All factors of $N$ form a subset of the numerators namely up to $\frac{N}{2}$ , any numbers between $\frac{N}{2}$ and $N$ are therefore not included. All prime numbers generate the sequence $\{0, 1\}$ as they have no factors or numbers with which they share factors. I concluded I wanted a sequence of numbers for which the numerator and denominator aren't co-prime , but including $\frac{0}{N}$ and $\frac{N}{N}$","['fractions', 'coprime', 'functions', 'sequences-and-series']"
3432788,"Prove that $\mathcal{P}(A)\cap\mathcal{P}(B)\subseteq\mathcal{P}(A\cap B)$ for all $A, B$","Problem. Prove that $\mathcal{P}(A)\cap\mathcal{P}(B)\subseteq\mathcal{P}(A\cap B)$ for all $A, B$ This is what I have so far but not sure if it's right. Let $X \in \mathcal{P}(A \cap B)$ . Then each element of $X$ is an element of $A$ and $B$ , hence $X$ is also in $\mathcal{P}(A)$ and $\mathcal{P}(B)$ $\Longrightarrow$ $X \in \mathcal{P}(A) \cap \mathcal{P}(B)$ . Now Let $Y \in \mathcal{P}(A) \cap \mathcal{P}(B)$ . Then $Y \in \mathcal{P}(A)$ and $Y \in \mathcal{P}(B)$ . Therefore each element of $Y$ is an element of $A$ and $B$ . Hence each element of $Y$ is in $A \cap B$ $\Longrightarrow$ $Y \in \mathcal{P}(A \cap B)$ . Hence we have shown that any set in $\mathcal{P}(A \cap B)$ is in $\mathcal{P}(A) \cap \mathcal{P}(B)$ and vice versa.",['discrete-mathematics']
3432819,Prove that every ideal of $R=\mathbb{Z}[x]$ can be generated by at most two elements of $R$,Prove that every ideal of $R=\mathbb{Z}[x]$ can be generated by at most two elements of $R$ . $\mathbb{Z}[x]$ is polynomial ring over $\mathbb{Z}$ . Thank you,"['ring-theory', 'abstract-algebra', 'commutative-algebra']"
3432833,"Let $f(x)=(x+1)(x+2)(x+3)(x+4)+5$ where $x\in[-6,6]$. If the range of the function is [a,b] where $a,b\in N$, then find the value of (a+b)","Let $f(x)=(x+1)(x+2)(x+3)(x+4)+5$ where $x\in[-6,6]$ . If the range of the function is [a,b] where $a,b\in N$ , then find the value of (a+b) My attempt is as follows:- Rewrite $f(x)=g(x)+5$ where $g(x)=(x+1)(x+2)(x+3)(x+4)$ Let's find the maximum value of g(x) It can be clearly seen that from $x=-6$ to $x=6$ , maximum value of $g(x)$ is at $x=6$ . $$g(6)=5040$$ Let's find the minimum value of $g(x)$ From the sign scheme one can see that negative value of $g(x)$ occurs in the interval $(-4,-3)$ and $(-2,-1)$ Hence intuitively it feels that the minimum value of g(x) would be at $x=-\dfrac{3}{2}$ or at $x=-\dfrac{7}{2}$ as in case of parabola also, minimum value is at average of both the roots. So $g\left(-\dfrac{3}{2}\right)=-\dfrac{1}{2}\cdot\dfrac{1}{2}\cdot\dfrac{3}{2}\cdot\dfrac{5}{2}=-\dfrac{15}{8}$ At $x=-\dfrac{7}{2}$ , $g\left(-\dfrac{7}{2}\right)=-\dfrac{5}{2}\cdot\dfrac{3}{2}\cdot\dfrac{1}{2}\cdot\dfrac{1}{2}=-\dfrac{15}{8}$ So range of $g(x)$ would be $[\dfrac{-15}{8},5040]$ Hence range of $f(x)$ = $\left[\dfrac{25}{8},5045\right]$ But it is given that the range is $[a,b]$ where $a,b\in N$ I am stuck here.  I am also not able to prove mathematically that at $x=-\dfrac{3}{2}$ or $x=-\dfrac{7}{2}$ , minimum value of $g(x)$ will occur. Please help me in this.","['maxima-minima', 'inequality', 'functions', 'quadratics']"
3432835,Can $\left| \bar{X} \right|$ be greater than $\left| \mathscr{P}(X) \right|$?,"Let $X$ be a a subset of a linear continuum (consider with the order topology). Can $\left| \bar{X} \right|$ be greater than $\left| \mathscr{P}(X) \right|$ ?
I know it can be equal, (e.g. for $\mathbb{Q}$ in $\mathbb{R}$ ). But can it be greater than that? I couldn't find any example neither any proof discarding it. Even such sets exist, is there any upper bound to the cardinality? It'll be great if anyone can shed some light. EDIT : A linear continuum $X,<$ is a totally ordered set with l.u.b. property and $\forall x, y \in X$ with $x<y$ , $\exists z \in X$ such that $x < z <y$ .","['general-topology', 'cardinals']"
3432875,Proof verification: Product of two Hausdorff spaces is Hausdorff.,"Let $X, Y$ be Hausdorff spaces. Then $X\times Y$ is a Hausdorff space. My proof: Let $(x,y)$ , $(x',y')$ be distinct points in $X\times Y$ . Assume that $x\ne x'$ and $y\ne y'$ , then because $X$ and $Y$ are Hausdorff, there exist disjoint neighborhoods $U, U'$ of $x,x'$ and disjoint neighborhoods $V,V'$ of $y,y'$ . Then $U\times V$ , $U'\times V'$ are disjoint neighborhoods of $(x,y),(x',y')$ , so that $X\times Y$ is Hausdorff. If $x=x'$ , then choose disjoint neighborhoods $V,V'$ of $y,y'$ . Then $X\times V$ , $X\times V'$ are disjoint neighborhoods of $(x,y), (x',y')$ . (Symmetrical argument for when $y=y'$ .) Have I missed anything with this proof? I ask because it is simpler than another proof I read.","['self-learning', 'general-topology', 'proof-verification']"
3432957,How to find a Cartan subalgebra of $\mathfrak{so}(n)$?,"To find a Cartan subalgebra for $\mathfrak{su}(n)$ we take advantage that $\mathfrak{su}(n)$ consists of anti-hermitian matrices. If a set of elements of $\mathfrak{su}(n)$ commute then they can be simultaneously diagonalized. This means that if we take a linearly independent set $\{X_a\}$ of commuting elements (which we shall take as a basis for the Cartan subalgebra), we can always find a unitary $U$ such that the set $\{U^\dagger X_a U\}$ is a set of linearly independent diagonal matrices. Thus a Cartan subalgebra can be generated by a maximal set of diagonal matrices of zero trace. This yields a subalgebra of dimension $n-1$ with the generators of the form $$\begin{pmatrix}i & 0 & \cdots & 0\\ 0 & 0 & \cdots & \vdots\\\vdots & \vdots & \ddots & \vdots\\ 0 & 0 & \cdots & -i\end{pmatrix},\quad \begin{pmatrix}0 & 0 & \cdots & 0\\ 0 & i & \cdots & \vdots\\\vdots & \vdots & \ddots & \vdots\\ 0 & 0 & \cdots & -i\end{pmatrix},\quad \dots$$ Now for $\mathfrak{so}(n)$ this seems harder. The elements have zero diagonal so we cannot even expect to have some clever argument that allows us to look for diagonal matrices. My only idea was to take the usual basis $\{E_a\}$ of $\mathfrak{so}(n)$ fix $X_1 = E_1$ and then look for matrices commuting with $X_1$ . Then inside that subspace pick some $X_2$ and look for matrices commuting with $X_1,X_2$ , and so on, until not being able to find any other matrix. This seems to work for specific values of $n$ , but there ought to be a better approach for general $n$ like $\mathfrak{su}(n)$ . So: how do we find a Cartan subalgebra for $\mathfrak{so}(n)$ ?","['lie-algebras', 'representation-theory', 'abstract-algebra', 'linear-algebra', 'problem-solving']"
3433038,"Find G. C. F. of $(8n^3 + 8n, 2n+1)$","I'm stuck with this problem, I divided $8n^3 + 8n$ by $2n+1$ and obtained $5$ , so now my G. C. F is $\gcd(2n+1, -5)$ . What's next? I can't divide $2n+1$ by $-5$ .",['discrete-mathematics']
3433078,Number of ways to put two different knights on a chessboard so they attack each other,"This question is in my textbook: What is the number of ways to put two non-identical knights on a chessboard so they attack each other? My solution: If two knights attack each other, they can be fit inside a $2 *3$ rectangle. There are $84$ ways to pick a $2 *3$ rectangle from the chessboard(horizontal and vertical) and there's $4$ ways to put $2$ non-identical knights inside such a rectangle so the answer is $4*84=336$ . But my textbook says it's $672$ . I checked out this question and it said the number of ways to put $2$ attacking identical knights in a $n*n$ board is $4(n-1)(n-2)$ and substituting $8$ yields $4*7*6 = 168$ . Note that since the knights are non-identical, we need to multiply $168$ by $2$ which results in the same answer as mine. So I'm fairly certain my answer is right and the textbook's is wrong but I wanted to make $100\%$ sure. Thank you in advance!","['chessboard', 'combinatorics']"
3433158,Is the set of functions with 1 discontinuity equinumerous to the set of continuous functions?,"Let $D(\mathbb{R})$ be defined as $\{f: \mathbb{R}\rightarrow \mathbb{R} | \text{$f$ is continuous for all points except for at most 1 point} \}$ . Is this set equinumerous to the set of continuous functions $C(\mathbb{R})$ ? I am not quite sure where to start. Intuitively it seems that it is equinumerous, but I am not sure.","['elementary-set-theory', 'continuity']"
3433245,"Why is cosine approximated by $\frac12(f^n(\frac{x}{2^{n-1}}+1)-1)$, where $f(x)=x(x-2)$ and $f^n$ indicates repeated composition?","Let $f(x) = x(x-2)$ . When $f$ is applied to itself, all points that have a y of 3 stay at 3 since $3(3-2) = 3$ . The function is centred at 1 so adding 1 to the x centers it at 0. This lead to the function, $g(x) = f^{n}(x+1)$ , where the superscript is the number of iterations of the function onto itself. When the graph is stretched along the x-axis by a factor of $2^{n-1}$ , lowered by 1, and then divided by 2, the function seems to approximate cosine. Why does this approximate cosine? $$g(x) = \frac{(f^n(\frac{x}{2^{n-1}} + 1) - 1)}{2} \approx \cos(x)$$ Example, n = 10, the function on top is $g(x)$ , on bottom is $cos(x)$ :","['approximation', 'algebra-precalculus', 'trigonometry', 'recurrence-relations']"
3433255,Does compact orbit imply periodicity?,"A continuous dynamical system on a metric space $X$ is given by: $\varphi : \mathbb{R} \times X \rightarrow X$ - continuous s.t. $\varphi (0,x) = x$ for every $x \in X$ $\varphi (t, \varphi(s,x) ) = \varphi(s+t, x)$ for all $s, t \in
\mathbb{R}, \ \ x \in X $ and $\gamma(x) = \{y \in X| \exists t\in \mathbb{R}; \varphi(t,x) = y \}$ is the orbit of $x$ . $x \in X$ is periodic iff $x =\varphi(T,x)$ for some $0 \neq T \in \mathbb
 R$ . The question is the following: Assume that $x$ is periodic. Show that $\gamma(x)$ is compact. Is the converse true? For the first part, if $x$ is periodic of period $T \ge 0$ then $\gamma(x)= \varphi (\{x\} \times[-T,T])$ which is an image of a compact set, hence compact. However, I am not sure about the converse. All I know is that for some sequence $t_n \to \infty$ , $\varphi(t_n,x) \to x'$ for some $x' \in \gamma(x)$ . Hence $\exists t' \in \mathbb{R}$ such that $\varphi (t',x) = x'$ . On the other hand, we also have a continuous bijection from $\mathbb R$ to a compact set. At first sight this does not seem enough though. Thank you. P.S. The problem is from Bhattia & Szego: Stability Theory of Dynamical Systems","['general-topology', 'metric-spaces', 'ordinary-differential-equations', 'dynamical-systems']"
3433267,Proof of a few equations involving $\int_{\alpha}^{\infty}\frac{1}{t\left(e^{t}\pm1\right)}dt$,"I derived these formulas with the Laurent series and Euler-Maclaurin summation formula. I can demonstrate this later if anyone's curious.  I'm wondering if there is another way.  I'm also interested in finding generalized formulas. $$\lim\limits_{\alpha\to 0}\left[\frac{\ln\left(\alpha\right)}{2}+\int_{\alpha}^{\infty}\frac{1}{t\left(e^{t}+1\right)}dt\right]=\frac{1}{2}\left(\ln\left(\pi\right)-\ln\left(2\right)-\gamma\right)$$ $$\lim\limits_{\alpha\to 0}\left[\frac1\alpha+\frac{\ln\left(\alpha\right)}{2}-\int_{\alpha}^{\infty}\frac{1}{t\left(e^{t}-1\right)}dt\right]=\frac{1}{2}\left(\ln\left(\pi\right)+\ln\left(2\right)-\gamma\right)$$ A manipulation of these equations yields $$\lim\limits_{s\to -1}\left[\frac{1}{\ln|s|}+\left(-\frac{1}{s+1}+\frac{1}{2}\right)\ln|\ln|s||+\int_{s}^{\infty}\frac{\ln\left(\ln\left(u\right)\right)}{\left(u+1\right)^{2}}du\right]=\frac{1}{2}\left(\ln\left(\pi\right)-3\ln\left(2\right)-\gamma\right)$$ $$\lim\limits_{s\to 1}\left[\frac{1}{\ln\left(s\right)}+\left(\frac{1}{s-1}+\frac{1}{2}\right)\ln\left(\ln\left(s\right)\right)-\int_{s}^{\infty}\frac{\ln\left(\ln\left(u\right)\right)}{\left(u-1\right)^{2}}du\right]=\frac{1}{2}\left(\ln\left(\pi\right)+\ln\left(2\right)-\gamma\right)$$ Here is my elementary method of deriving these: Begin with the Euler-Maclaurin summation formula: $$
\begin{align}
\frac{1}{h}\int_a^b f(t)dt
&=\sum_{k=0}^n f(kh+a)-\left(\frac{f(a)+f(b)}{2}\right)
\\&-\sum_{k=1}^n \frac{h^{2k-1}B_{2k}}{(2k)!} \left(f^{(2k-1)}(b)-f^{(2k-1)}(a)\right)
\\&-R
\end{align}
$$ where $h=\frac{b-a}{n}$ and $R$ is the remainder term. Letting $n=\frac{b-a}{x}$ and rearranging we get $$
\begin{align}
\sum_{k=1}^{(b-a)/x} \frac{x^{2k-1}B_{2k}}{(2k)!} \left(f^{(2k-1)}(b)-f^{(2k-1)}(a)\right)
&=\sum_{k=0}^{(b-a)/x} f(kx+a)-\left(\frac{f(a)+f(b)}{2}\right)
\\&-\frac{1}{x}\int_a^b f(t)dt
\\&-R
\end{align}
$$ Limiting $b\to 0$ and $a\to -\infty$ , we have $$
\begin{align}
\lim\limits_{\substack{%
     a \to -\infty\\
     b \to 0}}
\sum_{k=1}^{-a/x} \frac{x^{2k-1}B_{2k}}{(2k)!} \left(f^{(2k-1)}(b)-f^{(2k-1)}(a)\right)
&=\lim\limits_{\substack{%
     a \to -\infty\\
     b \to 0}}\left(\sum_{k=0}^{-a/x} f(kx+a)-\left(\frac{f(a)+f(b)}{2}\right)-\frac{1}{x}\int_a^b f(t)dt\right)
\end{align}
$$ The remainder disappears as $n\to\infty$ . Now make a variable substitution in the limit $a\to -ax$ . $$
\begin{align}
\lim\limits_{\substack{%
     a \to \infty\\
     b \to 0}}\sum_{k=1}^{a} \frac{x^{2k-1}B_{2k}}{(2k)!} \left(f^{(2k-1)}(b)-f^{(2k-1)}(-ax)\right)
&=\lim\limits_{\substack{%
     a \to \infty\\
     b \to 0}}\left(\sum_{k=0}^{a} f((k-a)x)-\left(\frac{f(-ax)+f(b)}{2}\right)-\frac{1}{x}\int_{-ax}^b f(t)dt\right)
\\&=\lim\limits_{\substack{%
     a \to \infty\\
     b \to 0}}\left(\sum_{k=0}^{a} f(-kx)-\left(\frac{f(-ax)+f(b)}{2}\right)-\frac{1}{x}\int_{-ax}^b f(t)dt\right)
\end{align}
$$ Now use the following hint. $$\frac{1}{z(e^z-1)}=\frac{1}{z^2}-\frac{1}{2z}+\sum_{k=1}^\infty\frac{B_{2k}}{(2k)!}z^{2k-2}$$ which when we integrate we get $$\begin{align}
\int_x^\infty\frac{1}{z(e^z-1)}dz
&=K-\left(-\frac{1}{x}-\frac{\ln{|x|}}{2}+\sum_{k=1}^\infty\frac{B_{2k}}{(2k)!(2k-1)}x^{2k-1}\right)
\end{align}$$ Where $K$ stands for the integral evaluated at $\infty$ . Let $f(x)=\text{Ei}\left(x\right)-\ln\left|x\right|-\gamma$ . Note that $\lim\limits_{t\to 0}f^{(m)}(t)=\frac1m$ and $\lim\limits_{t\to -\infty}f^{(m)}(t)=0$ for $m\ge1$ . Further note that $\lim\limits_{t\to 0} f(t) = 0$ so we may substitute the sum: $\sum_{k=0}^{a} f(-kx)=\sum_{k=1}^{a} f(-kx)$ . Now we have $$
\begin{align}
\sum_{k=1}^\infty\frac{B_{2k}}{(2k)!(2k-1)}x^{2k-1}
&=\lim\limits_{\substack{%
     a \to \infty\\
     b \to 0}}\left(\sum_{k=1}^{a} f(-kx)-\left(\frac{f(-ax)+f(b)}{2}\right)-\frac{1}{x}\int_{-ax}^b f(t)dt\right)
\\&=\lim\limits_{\substack{%
     a \to \infty\\
     b \to 0}}\left(\sum_{k=1}^{a}\text{Ei}(-kx)-\sum_{k=1}^{a}\ln\left|-kx\right|-\sum_{k=1}^{a}\gamma-\left(\frac{f(-ax)+f(b)}{2}\right)-\frac{1}{x}\int_{-ax}^b f(t)dt\right)
\\&=-\int_x^\infty\frac{1}{z(e^z-1)}dz+\lim\limits_{\substack{%
     a \to \infty\\
     b \to 0}}\left(-a\ln|x|-\ln|a!|-a\gamma-\left(\frac{f(-ax)+f(b)}{2}\right)-\frac{1}{x}\int_{-ax}^b f(t)dt\right)
\\&=-\int_x^\infty\frac{1}{z(e^z-1)}dz+\frac{1}{x}+\frac{\ln\left|x\right|}{2}+\frac{1}{2}\left(\gamma-\ln\left(2\pi\right)\right)
\end{align}
$$ (The limit is tricky which is why I left out some steps). Therefore $$\begin{align}
\int_x^\infty\frac{1}{z(e^z-1)}dz=\frac12 (\gamma-\ln(2\pi))+\frac{1}{x}+\frac{\ln{|x|}}{2}-\sum_{k=1}^\infty\frac{B_{2k}}{(2k)!(2k-1)}x^{2k-1}
\end{align}$$ We can derive the other equation with $f(x)=-\text{Ei}(x)+2\text{Ei}(2x)-\ln|4x|-\gamma$ .","['integration', 'closed-form', 'real-analysis']"
3433388,Fibonacci sum: $\sum\limits_{k\ge0}\frac{F_{2k+1}}{2k+1}\left(\frac{2+2\sqrt{2}}{1+\sqrt{\frac{17+8\sqrt{2}}{5}}}\right)^{2k+1}(-\frac{1}{5})^k$,"Prove $$\frac{3\pi}{8}=\sum\limits_{k\ge0}\left(-\frac{1}{5}\right)^k\frac{F_{2k+1}}{2k+1}q^{2k+1}$$ where $q=\frac{2+2\sqrt{2}}{1+\sqrt{\frac{17+8\sqrt{2}}{5}}}$ , and $F_n$ are the Fibonacci numbers. This result is from Wolfram . My ideas as to a proof are limited. I know that this is some sort of series for the inverse tangent because $3\pi/8=\arctan(1+\sqrt{2})$ , but I have never seen any series for $\arctan$ involving the Fibonacci numbers. Essentially, it comes to the explicit evaluation of the function $$f(x)=\sum_{k\ge0}\frac{F_{2k+1}}{2k+1}x^{k}.$$ Indeed, the sum in question is the value $qf(-q^2/5)$ . Potentially connected is the closed form $$\sum_{k\ge0}F_kx^k=\frac{x}{1-x-x^2},$$ perhaps we could get some sort of $\arctan$ -related integral out of this. Could I have some help evaluating $f$ ? Thanks.","['fibonacci-numbers', 'sequences-and-series', 'closed-form', 'real-analysis']"
3433417,"Prove there are no simple groups of even order $<500$ except orders $2$, $60$, $168$, and $360$.","In Dummit & Foote, Abstract Algebra , $\S6.2$ , Exercise 17(b) is: Prove there are no simple groups of even order $<500$ except orders $2$ , $60$ , $168$ , and $360$ . The fact that the we have to check all groups of less $<500$ makes me think there is a faster way of solving this rather than brute force. Even using various formulas to wipe out entire families of orders still seems like it would take an unreasonable amount of effort for an exercise. Is there something I'm missing with this problem? Is there a faster way to reduce the work that I am not seeing?","['simple-groups', 'group-theory', 'abstract-algebra', 'finite-groups']"
3433421,Are there any theorems out there where we prove a set is finite by contradiction?,"This might be a strange question... Proving there are infinitely many primes numbers can be done by contradiction where we suppose there are finitely many primes and show a contradiction. However, is there a proof/theorem out there where we suppose a certain set of numbers is infinite and show a contradiction to prove it is finite? Clearly, there are certain sets that are finite that fall under this category. However, I was wanting to know if there was a set that really, truly seems like it could be infinite but it turns out not by a proof by contradiction.","['set-theory', 'infinity', 'soft-question', 'discrete-mathematics']"
3433444,Artin's theorem and Brauer's theorem on Characters,"Artin: Let $\chi$ be rational valued complex character of (finite) group $G$ . Then $\chi$ can be written as $\mathbb{Q}$ -linear combination of characters $1_H^G$ for some cyclic subgroups $H$ of $G$ . In the theorem of Brauer, the subgroups $H$ are allowed to be elementary subgroups it is quite general than Artin's theorem in following sense: Brauer: Every irreducible complex character $\chi$ of $G$ can be written as $\mathbb{Z}$ -linear combinations of characters $\lambda_H^G$ for some subgroups $H$ of $G$ , which are elementary subgroups, and $\lambda$ is a linear character of $H$ . Q. In the theorem of Brauer, comparing with Artin, 1) subgroups $H$ are allowed to be elementary (which include cyclic subgroups of $G$ also). 2) For elementary subgroups $H$ , we consider $\lambda_H^G$ , with $\lambda$ a linear character of $H$ , not necessarily $1$ . I was wondering, what will happen if we consider subgroups $H$ to be elementary but the characters of $G$ to be $1_H^G$ (instead of $\lambda_H^G$ ); these induced characters are rational valued; so by integral combination of such characters of $G$ , can we get all the rational valued characters of $G$ ? A (sub)group $K$ is said to be $p$ -elementary, for a prime $p$ , if $K=C_m\times P$ where $C_m$ is cyclic group of order coprime to $p$ (may be trivial) and $P$ is a $p$ -group (may be trivial). We say that $K$ is elementary (sub)group if it is $p$ -elementary for some prime $p$ .","['representation-theory', 'group-theory', 'finite-groups', 'characters']"
3433492,Is there a proof that all analytic functions only have one unique Taylor series representation?,"I know that a function can admitted multiple series representation (according to Eugene Catalan), but I wonder if there is a proof for the fact that each analytic function has only one unique Taylor series representation. I know that Taylor series are defined by derivatives of increasing order. A function has one and only one unique derivative. So can this fact be employed to prove that each function only has one Taylor series representation?","['power-series', 'calculus', 'proof-writing', 'sequences-and-series']"
3433518,Did I correctly prove this?(Group theory),"Let the $G$ is a group $s.t.$ its order is $150$ And Uniquely exists subgroup of the $G$ $s.t.$ its order is $6$ Show the existence of the subgroup whose order is $30$ When I solve this question, I don't have a confidence that my solution is right or not. Any advice or comments would be appreciated. My attempt) $150 = 2\cdot 3 \cdot 5^2$ By the sylow thm, There are sylow 2, 3 subgroups in $G$ respectively. Let the Sylow 2 group $P_2$ and sylow 3 group $P_3$ Since $H = P_2  \times P_3 $ and $H$ is a unique, Hence Each $P_2$ and $P_3$ are  unique. (I.e. $P_2 \unlhd G, P_3 \unlhd G$ ) Hence $H \unlhd G $ $s.t.  \vert H \vert  = 6$ Plus there are the other sylow 5 subgroup $P_5$ $s.t.\vert P_5 \vert = 25$ Surely By cauchy thm, $\exists g \in P_5$ $ s.t.$ $\vert g \vert = 5$ So, $\langle g \rangle \leq P_5$ and $\vert \langle g \rangle  \vert = 5 $ Therefore $\langle g \rangle$$H$ is a subgroup of the $G$ , and its order is $30$ .","['group-theory', 'abstract-algebra', 'sylow-theory']"
3433548,"If $a^{7!} +b^{8!} +c^{9!} +d^{10!} =x$ where a,b,c and d are natural numbers that are not multiples of 10, the.....","If $a^{7!} +b^{8!} +c^{9!} +d^{10!} =x$ where a,b,c and d are natural numbers that are not multiples of 10, then how many distinct values of unit's digit of x are possible ? How to proceed in such question, I don't have any idea on this. .. please guide thanks a lot ...","['elementary-number-theory', 'algebra-precalculus']"
3433554,Find Ratio of Integrals $I:J$,Given: $$I=\int_{0}^{1}\frac{x^{\frac{5}{2}}(1-x)^{\frac{7}{2}}\:dx}{12}$$ and $$J=\int_{0}^{1}\frac{x^{\frac{5}{2}}(1-x)^{\frac{7}{2}}\:dx}{(x+3)^8}$$ Find Value of $\frac{I}{J}$ My attempt:The Integral $I$ is easy to evaluate using Beta Function. So i was trying to Manipulate $J$ to convert it to $I$ as follows: We can write $J$ as: $$J=\int_{0}^{1}\frac{x^{6}\left ( \frac{1}{x} -1\right )^\frac{7}{2}}{x^{8}\left ( 1+\frac{3}{x} \right )^8}$$ Now put $\frac{1}{x}=t$ we get: $$J=\int_{1}^{\infty}\frac{(t-1)^{\frac{7}{2}}}{(1+3t)^8}$$ Using integration by Parts taking $u=(t-1)^{3.5}$ and $v=\frac{1}{(1+3t)^8}$ we get: $$J=\frac{1}{6}\times \int_{1}^{\infty}\frac{(t-1)^{\frac{5}{2}}}{(1+3t)^7}$$ Repeating Parts again and again: $$J=\frac{1}{432}\times \int_{1}^{\infty}\frac{\sqrt{t-1}}{(1+3t)^5}\:dt$$ Any way to proceed from here?,"['beta-function', 'algebra-precalculus', 'definite-integrals']"
3433654,"Proving that $\text{Var}(X)\cdot\text{Var}(Y)\geq\text{Cov}(X,Y)^2$ for real-valued random variables.","Consider nondegenerate real-valued random variables $X$ and $Y$ with finite mean and variance. We can prove the inequality $$\text{Var}(X)\cdot\text{Var}(Y)-\text{Cov}(X,Y)^2\geq0$$ in a variety of ways: (1) We can recognize left-hand side as the determinant of the variance-covariance matrix of the random vector $(X, Y)$ , and then invoke the fact that variance-covariant matrices are positive semidefinite. (2) The variance and covariance are invariant under shifting by a constant, so by mean-centering $X$ and $Y$ , the inequality reduces to $E(X^2)E(Y^2)-E(XY)^2\geq0$ , which follows from Cauchy-Schwarz for random variables . (3) We can try to prove the inequality “directly” by unraveling the left-hand side as $$\big(E(X^2)-E(X)^2\big)\big(E(Y^2)-E(Y)^2\big)-\big(E(XY)-E(X)E(Y)\big)^2$$ which upon simplifying gives (if I haven’t made an error) $$\color{blue}{E(X^2)E(Y^2)-E(XY)^2}+\color{red}{2E(XY)E(X)E(Y)-E(X^2)E(Y)^2-E(Y^2)E(X)^2}$$ According to the argument in (2), using shift-invariance of variance and covariance, the red term should vanish, but I’m not seeing why. What algebraic cleverness am I missing?","['inequality', 'probability-theory', 'probability', 'random-variables']"
3433683,Abelian subgroup of the unit quaternions,"Let $\Bbb S^0(\Bbb H)\cong \mathrm{SU}(2)$ denote the multiplicateive group of unit quaternions .
This group is non-abelian. Of course, the subgroups generated by as $\def\<{\langle}\def\>{\rangle}\<1,i\>$ , $\<1,j\>$ and $\<1,k\>$ are commutative and also isomorphic to $\Bbb S^0(\Bbb C)\cong\mathrm U(1)$ (the multiplicative group of unit complex numbers).
And there are probably other such subgroups conjugate to the ones named above.
And of course, any subgroup of such a conjugate is also abelian. Question: Are there other abelian subgroups of $\Bbb S^0(\Bbb H)$ ?","['unitary-matrices', 'representation-theory', 'group-theory', 'abelian-groups', 'quaternions']"
3433751,Optimal strategy for this d6 game,"In my attempts to learn the foundations, I was given the following game in a mock interview: Two players each roll a d6, and are not able to see each other's
  rolls. The player with the higher value wins \$1. After the players
  roll their dice, each player may either pay \$0.25 to increase their
  individual roll by 2 or keep their roll. What is the optimal strategy
  and payout? Consider the cases for which i) nothing happens when both
  players roll the same number, and ii) the players keep rerolling (for free) until
  different numbers appear. What is the best strategy here? Is it important for both players to have the same strategy for Nash/symmetric equilibrium (not sure what the terminology I should be using is)? What should my considerations be in calculating the expected value? Please help prod me to attempt deriving the strategy, thanks!","['expected-value', 'game-theory', 'dice', 'probability']"
3433779,Help getting new bounds for a change of variable,"I have the domain $D: x^2-y^2=1, x^2-y^2=4,y=0, y=\frac{x}{2}$ where $x\geq 0$ . I have to calculate this double integral: $$\iint_D \left(1-\left(\frac{y}{x}\right)^4\right)e^{x^2-y^2} dxdy $$ So my first idea was, to use these new variables: $$u=\frac{y}{x}, v=x^2-y^2; 
$$ $$J=\frac{1}{2(u^2-1) } $$ So this would give me : $$\iint (1-u^4)e^v\frac{1}{2(u^2-1)}dudv = -\frac{1}{2}\iint (1+u^2)e^v dudv$$ But I have a problem getting the bounds for $u$ . The other one is easy, $v\in [1,4]$ , and I got $u=\frac{1}{u}$ . Is it safe to assume: $u\in[0,1]$ ? I am unsure about this one. Did I do the above steps correctly? Any help/insight would be appreciated.","['integration', 'multivariable-calculus', 'calculus', 'change-of-variable']"
3433815,Is it true that at least two of any consecutive $2m$ positive integers cannot be divided by odd prime numbers less than $2m$?,"Let $m>1$ and $p_2,\cdots,p_k$ are all odd prime numbers less than $2m$ . $q,a_2,\cdots,a_k$ are arbitrarily selected integers(I mean no matter how you choose these numbers). $$G_1=\lbrace n\in \mathbb Z|q < n \leq q+2m \rbrace,$$ $$G_i=\lbrace n\in \mathbb Z|n\not\equiv a_i \mod {p_i}\rbrace,$$ for $i=2,3,\cdots,k$ . $$G=\bigcap_{i=1}^k{G_i}.$$ Is it always true that # $|G|\geq 2$ ? Especially,is it true that at least two of any consecutive $2m$ positive integers cannot be divided by odd prime numbers less than $2m$ ? In other words, if you write $2m$ consecutive positive integers and cross out the multiples of $3, 5,\cdots,p_k$ , then at least two of these $2m$ numbers will not be crossed out. (1) When $m=2,k=2,p_2=3,$ four consecutive integers $q+1,q+2,q+3,q+4$ ,no matter what is $a_2$ ,we know that $G$ has at least two elements. (2) For every $m>1$ , we can choose $q$ and $a_i$ so that # $|G|=2$ ,for example, if $$q=\frac{R-1}{2}-m,R=\prod_{i=2}^k{p_i},$$ $$a_i=0,i=2,\cdots,k,$$ then $G=\lbrace \frac{R-1}{2},\frac{R+1}{2} \rbrace.$ (3) The case $m=3,k=2,p_2=3,p_3=5.$ # $|G_1 \setminus G_2|=6/3=2,$ # $|G_1 \setminus G_3|\leq [6/5]+1=2,$ hence # $|G|\geq 2.$ (4) When $m\geq 36$ , as $$\sum_{2<p<2m}{[\frac{2m}{p}]}>2m-2$$ maybe hold, I don't know if there's a counterexample.","['analytic-number-theory', 'number-theory', 'combinatorial-number-theory']"
3433841,"What is an example of a sequence which ""thins out"" and is finite?","When I talk about my research with non-mathematicians who are, however, interested in what I do, I always start by asking them basic questions about the primes.  Usually, they start getting reeled in if I ask them if there's infinitely many or not, and often the conversation remains by this question. Almost everyone guesses there are infinitely many, although they ""thin out"", and seem to say it's ""obvious"": ""you keep finding them never mind how far along you go"" or ""there are infinitely many numbers so there must also always be primes"". When I say that's not really an argument there then they may surrender this, but I can see they're not super convinced either.  What I would like is to present them with another sequence which also ""thins out"" but which is finite .  Crucially, this sequence must also be intuitive enough that non-mathematicians (as in, people not familiar with our terminology) can grasp the concept in a casual conversation. Is there such a sequence?","['number-theory', 'big-list', 'education', 'sequences-and-series', 'recreational-mathematics']"
3433870,Can we approximate a vector field on the plane with non-vanishing vector fields in $L^2$?,"Let $V$ be a compactly-supported smooth vector field on $\mathbb{R}^2$ , whose zeros inside some open neighbourhood of the closed unit disk $\mathbb{D}^2$ are isolated. Does there exist a sequence of vector fields $V_n \in C^\infty \cap L^{2}$ on $\mathbb{R}^2$ , such that $V_n \to V$ in $L^2$ and $V_n$ do not vanish on $\mathbb{D}^2$ ?","['vector-fields', 'singularity-theory', 'real-analysis', 'lp-spaces', 'differential-topology']"
3433896,"If a random variable is bounded, does it mean its expectation is bounded?","Suppose I have random variables $(X_n)_n$ that have a lower bound $$X_n > a \qquad \forall n$$ and that are finite (which I think this means that they also have an upper bound, and so $|X_n|< b$ for some $b>0$ , but I am not sure about the definition of finite random variables, cause I can't find it anywhere). Does it mean that $X_n$ are bounded in $\mathcal{L}^1$ ? In other words, does it mean that $$\sup_n \mathbb{E}[|X_n|] <\infty$$ What about $\sup_n\mathbb{E}[|X_n|^p]<\infty$ for $p>1$ ? Basically my question is: knowing that the random variables are bounded, do we know if their expectation is bounded?","['statistics', 'stochastic-processes', 'probability-theory', 'probability', 'random-variables']"
3433904,How many elementary methods are there to show that a set is infinite ( either countably or not)?,"I'm not asking precisely for the exact number of methods, but rather for the various mathods available to show a set is infinite. I'm interested in a sort of methodological review. In order to show a set S is countably infinite I think one can : show that S has ( at least) one proper subset T such that there is ( at least) one bijection from T to S. show that there is a bijection from S to the set of natural numbers In order to show a set S is uncountably infinite, I think one can : show that there is (at least) one  bijection from S to the set of real numbers show that there is a function from N ( set of natural numbers) to S such that this function is injective but not surjective ( which would leave some elements of S "" alone"" and prove that S has more elements than N  has) [ WRONG SUGGESTION ACCORDING TO COMMENTS , SEE BELOW] I cannot go further. Are there other available methods?","['elementary-set-theory', 'infinity']"
3433908,How to convert a column vector into a diagonal matrix with same entries in same order?,Assume $c$ is a column vector. What mathematical operation or expression can produce a diagonal matrix with entries of that of $c$ in same order. Does such an expression exist? Basically I know that the sum of entries of $c$ is zero. I want to write it in an matrix expression/equation. I am hoping if I get a diagonal matrix and then say trace of that matrix is zero.,"['matrices', 'linear-algebra']"
3433938,Splitting Integral of Brownian motion over stopping times,"Let $B_s$ be a Brownian Motion and denote be $E^y$ the law of BM started at $B_0 = y \in \mathbb{R}$ . The stopping time $\tau_{[a,b]}$ denotes the exit time from the intervall $[a,b]$ . Now let $a\leq b\leq x \leq c$ be real one dimensional numbers and consider a function $f:[a,c]\rightarrow \mathbb{R}$ (such that the integrals below make sense). Are the following equalities true? I splitted the integration intervall in the first step and used the Markov property in the second step. $$E^x(\int_0^{\tau_{[a,c]}} f(B_s) ds)= E^x(\int_0^{\tau_{[b,c]}}f(B_s)ds)+E^x(\int_{\tau_{b}}^{\tau_{[a,c]}} f(B_s)ds ~|~ \tau_b < \tau_c)=E^x(\int_0^{\tau_{[b,c]}}f(B_s)ds)+E^b(\int_{0}^{\tau_{[a,c]}} f(B_s)ds)$$ Thanks in advance","['integration', 'markov-process', 'stopping-times', 'brownian-motion', 'probability-theory']"
3433974,Describing bursts of Poisson arrivals: help verify whether these two perspective or models the same.,"Introduction: I currently have a sensor that picks up the inter-arrival times of vehicles. These inter-arrival times occur in aggregated bursts because there is a traffic light up-stream. So essentially, we have very short inter-arrival times clustered together with mean batch size $N$ which are separated by long inter-arrival times. Problem Description I am interested in two different perspectives that are taken to describe these batches of short inter-arrival times. They are as follows: We have a Poisson process with rate $\mu$ such that vehicles are separated on average by $\frac{1}{\mu}$ amount of time within this batch. This Poisson process is only allowed to be active for an Exponential distributed amount of time $\frac{1}{\lambda}$ . This is like a continuous-time Markov process that dictates how long the active Poisson process may run for. We take a Renewal style approach to this. We have i.i.d. Exponential distributed inter-arrival times of length $\frac{1}{\mu}$ . We observe on average $N$ of these inter-arrivals. We would observe $N(t)$ to be a Poisson Process with rate $\lambda$ . I would like to show that these two perspectives are the same. My attempt: To show that they are the same, it will suffice to show that $P(N(t)=k)$ is the same for both. Here $t$ is the duration of the batch/burst/activity and N(t) is the amount of vehicles or inter-arrivals that are found in the batch. Case 1: We have a Poisson process with rate $\mu$ that is only allowed to run for $t$ amount of time. However, $E[t] = \frac{1}{\lambda}$ . Hence, $$ P(N(t)=k) = \frac{(\mu t)^k e^{-(\mu t)}}{k!} $$ $$\therefore P(N(t)=k) = \frac{(\frac{\mu}{\lambda})^k e^{-(\frac{\mu}{\lambda})}}{k!} = P \left( N \left( \frac{1}{\lambda} \right) =k  \right)   $$ We must note that $\mu > \lambda$ such that $t_{burst} > t_{arrival}$ . We can thus say $N = \max\{n: n \leq \frac{\mu}{\lambda} \} $ Case 2: This perspective is tricky for me. A Poisson process usually has to be observed for a fixed interval of time. We have an expected fixed interval of time which is the length of a burst. So our Poisson data/counts gives rise to a rate in the form of $n$ counts per $E[t]$ interval of time. Here $E[t]$ should be the sum of $N$ inter-arrivals each of which have mean length $\frac{1}{\mu}$ . Intuitively, we then have $N \times \frac{1}{\mu}$ as the the length of the burst. But $E[N]=\lambda$ such that $E[t] = \frac{\lambda}{\mu}$ . Hence the overall process is Poisson with rate $\frac{\mu}{\lambda}$ as in case 1. I try to describe the intuitive explanation in more Math-like terms. Let $$ S_{N(t)} = \sum_{i=1}^{N(t)} X_i $$ $S_{N(t)}$ would then be a burst length. Furthermore, it has an Erlang probability distribution function. Now we have $$P(N(t)=k) = P(S_k \leq E[t]; X_{k+1} \geq E[t] - S_k)$$ $$ \therefore P(N(t)=k) = P(S_k \leq \frac{1}{\lambda}; X_{k+1} \geq \frac{1}{\lambda} - S_k)$$ $$  \therefore P(N(t)=k) = \int_0^{\frac{1}{\lambda}} \int_{\frac{1}{\lambda}-s}^{\infty} \left(  \frac{\mu^k s^{k-1} e^{-\mu s}}{(k-1)!}  \right) \mu e^{-\mu x} \, dx \, ds $$ $$ \therefore P(N(t)=k) = \frac{\mu^k}{(k-1)!} \int_0^{\frac{1}{\lambda}} (s^{k-1} e^{-\mu s}) e^{-\mu (\frac{1}{\lambda} - s)} \, ds $$ $$ \therefore P(N(t)=k) = \frac{(\frac{\mu}{\lambda})^k e^{-(\frac{\mu}{\lambda})}}{k!}   $$ This is the same as in above. Conclusion: Would you agree with what I have done? I am not too confident in the reasoning of what I have used. I've tried to solve this problem in between a lot of chaos hence the lack of confidence in what has been provided. Please verify if you believe it to be correct and please correct me where wrong. Ideally, I would love for more explanations/solutions of a more elegant nature to be provided. Thank you for your time","['statistics', 'renewal-processes', 'stochastic-processes', 'exponential-distribution', 'poisson-process']"
3433984,In what a sense we we can understand a geometric space well by understanding the functions on this space?,"The following is from Vakil’s notes page 99. we can understand a geometric space (such as a manifold) well by
  understanding the functions on this space. More precisely, we will
  understand it through the sheaf of functions on the space. If we are
  interested in differentiable manifolds, we will consider
  differentiable functions; if we are interested in smooth manifolds, we
  will consider smooth functions; and so on. I know some basic notions of diffrential manifolds and know nothing about scheme, and I couldn’t come up with an good example illustrating the above slogan, which says we could understand a space by understanding the functions on the space. Actually this seems too general for me. What do we mean by understanding a space? What kind of properties of the space do we want to study? It seems necessary to figure out these questions in order to have a good understanding about how the slogan works as well as why understanding the space in that way is a natural consideration. Could you give some examples to illustrate this? Thanks in advance.","['manifolds', 'algebraic-geometry', 'differential-geometry']"
3434001,"Closed form of $\int_{0}^{1} \frac{\log(1+x)\log(2+x) \log(3+x)}{1+x}\,dx$","In https://math.stackexchange.com/a/3414337/198592 I have mentioned some integrals which I could not solve. One of them is $$i_{1}=\int_{0}^{1} \frac{\log(1+x)\log(2+x)\log(3+x)}{1+x}\,dx \simeq 0.295123\tag{1}$$ I have tried several approaches like partial integration and series expansion but with no avail. The substiution $$\log(x) = \int_0^{\infty } \frac{e^{-t}-e^{-t\; x}}{t} \, dt\tag{2}$$ did allow doing the $x$ -integral but already the first integration of the triple integral failed. Interestingly, with ""one $\log$ less"" or without the denominator $1+x$ the integration leads to a closed expression. Problem : find a closed expression for $i_1$ or, equivalently, for $$i_{1s}=\int_{0}^{1} \frac{\log(1+x)\log(1+\frac{x}{2})\log(1+\frac{x}{3})}{1+x}\,dx \simeq 0.0130713\tag{3}$$","['integration', 'definite-integrals', 'logarithms']"
3434005,"Is a well-ordered subset of $(\mathbb{R},<)$ countable? [duplicate]","This question already has an answer here : Is there any well-ordered uncountable set of real numbers under the original ordering? (1 answer) Closed 4 years ago . Suppose $X \subseteq \mathbb{R}$ is well-ordered by $<$ , the normal ordering on $\mathbb{R}$ . Is it then countable? If so, how to prove this. I've tried to set up a bijection as follows: $$
\phi : \mathbb{N} \to X : n \mapsto \ <\textrm{-least element of } X \backslash \phi(\mathbb{N} \upharpoonright n)
$$ I.e, $0$ maps to the least element of $X$ , 1 maps to the least element of $X \backslash \{x_1\}$ , $2$ maps to the least element of $X \backslash \{x_1,x_2\}$ etc. This is injective by construction, but I'm not sure if it is surjective.",['elementary-set-theory']
3434022,What sort of manifold does a periodic polygon make?,"Taking a square or rectangle and enforcing periodic boundary conditions (i.e. identifying opposite edges) forms a torus, which is a genus 1 manifold. What sort of torus-like structure is formed if we use a different polygon as our starting point, such as a hexagon? The polygon certainly must be able to tile a plane for the construction to work, but doesn't need to be regular. As an extension it would be interesting to know what happens if we enforce anti-periodic boundary conditions instead. In the case of a rectangle, mixing periodic and anti-periodic boundaries gives the Klein bottle. Edit: My primary interest was in the context of the First Brillouin Zone of a 2D lattice (the Wigner Seitz cell of the reciprocal lattice). In condensed matter this concept is ubiquitous and in general (in 2D) it will be some polygon with periodic boundary conditions. For a square or rectangular lattice, it is obvious that it must form a torus, but it seems less obvious to me that when it is, for example, a hexagon, the FBZ will still be a torus.","['geometric-topology', 'general-topology', 'geometry', 'differential-geometry']"
3434054,Fermat's last theorem and Ramanujan's formulas,Ramanujan's identities gave instances of the solutions to equations $$x^3+y^3=z^3\pm 1$$ hence these are solutions failing FLT by plus or minus 1. Are there powers $n$ other than $3$ for which such close enough identities to FLT known?,"['number-theory', 'algebraic-geometry']"
3434059,Law of Large Numbers and Bernoulli Distribution,"Let ${X_i}$ be a sequence of random variables which follows the Bernoulli distribution with $Bernoulli(\frac1i)$ , for each $i = 1,...,n$ . In other words, $P(X_i=1) = \frac 1i$ and $P(X_i=0) = 1 - \frac 1i$ for each $i = 1,...,n$ . Show that $X_n$ tends in probability to $0$ . I have no idea how to even get started on this, so any tips would help greatly. My lecturer has just covered the Law of Large Numbers, convergence in probability and what makes a good estimator (unbiased, efficient and consistent) but I think I speak for the whole class when I say that we understood little of what she was teaching. EDIT I would first like to thank the kind souls who gave me hints on how I should go about solving this and also vetting what I had come up with. This is my answer: To show $X_n \to 0$ , we should aim to show $P(|X_n - 0| > \epsilon) = 0$ for any positive $\epsilon$ . Then, since $X_n$ follows a Bernoulli Distribution, so $X_n$ can only take on non-negative integer values. Thus, $P(|X_n - 0| > \epsilon) = P(X_n > \epsilon)$ . Now, I make use of Markov's Inequality, so $P(X_n  > \epsilon) \leqslant \frac 1\epsilon E(X_n) = \frac 1\epsilon \frac 1n$ . As $n \to \infty$ , $\frac 1n \to 0$ , so $P(|X_n - 0| > \epsilon) = 0$ and we can conclude that $X_n$ tends in probability to $0$ . Any further comments on how I can improve this answer are welcome :) or if anyone has any other more elegant ways to answer the question, they are welcome too!","['statistics', 'law-of-large-numbers', 'probability']"
3434092,An integer divisible by 8 and 15 must also be divisible by 24. Why?,"I have a question on the GRE that says ""If an integer is divisible by both 8 and 15, then the integer must also be divisible by"" and the choices are: 16 24 32 36 45 The answer is 24. I guess I could figure out that the first common multiple of 8 and 15 is 120 and plug in the numbers, but is there a more sophisticated way to do it? Something that follows from the properties of 8 and 15? It happens that 24 is the only number that goes into 120 but what if it wasn't? Is there a way to prove that 24 is the only one that works?","['elementary-number-theory', 'algebra-precalculus']"
3434128,Intuitive Explanation of the Inner Product,"I'm currently studying Linear Algebra, and we've arrived at the topic of Inner Products and orthogonality. I have been searching online to try and help myself understand what the inner product actually is. I understand it is supposedly an generalisation of the dot product, and I understood that the dot product was useful in calculating the angle between two vectors in 3D space, etc. What is the inner product of two elements of real/ complex spaces? Is it a formula? What is the use of the inner product, and can it be applied to any vector space or specifically the real/ complex spaces? How does this idea extend to inner product spaces? I don't understand it intuitively and any help/ guidance on how to grasp the concept better would be really appreciated. Thanks.","['inner-products', 'linear-algebra', 'vector-spaces']"
3434150,Is there an explicit solution of $y_{n}$ in this binomial coefficient relation?,"In following, $x_{n}$ is a set of given numbers, n = 0, 1, 2, ..., $y_{n}$ is defined by the following relation: For example: ${\displaystyle {x_{1}=x_{0}y_{1} }}.$ ${\displaystyle {x_{2}={\binom {1}{0}}x_{0}y_{2} + {\binom {1}{1}}x_{1}y_{1}  }}.$ ${\displaystyle {x_{3}={\binom {2}{0}}x_{0}y_{3} + {\binom {2}{1}}x_{1}y_{2}  + {\binom {2}{2}}x_{2}y_{1}  }}.$ For simplicity, we can assume $x_{0} = 1$ . Q: Is there an explicit solution of $y_{n}$ in term of $x_{n}$ ? Thank you.","['stochastic-processes', 'binomial-coefficients', 'probability', 'random-variables']"
3434172,What is the distribution of the product of these two R.V?,"Let $X$ be a random variable with gaussian distribution $N$ ( $\mu$ , $\sigma^2$ ).  Suppose $Z$ is a Bernoulli $B(p)$ , independent of $X$ . Find the distribution of $Y = (2Z − 1)X$ Here is my attempt: $P(Y \leq y)= P((2Z-1)X \leq y)= P((2Z-1)X\leq
 y|Z=0)P(Z=1)+P( (2Z-1)X\leq y|Z=1)P(Z=0)=P(X\geq-y)p+P(X\leq y)(1-p)$ We know that if $X$ is standard normal then, I can claim that $P(X\geq-y) =P(X\leq y)$ , so that $P(Y \leq y)=P(X\leq y)$ which is the cdf of a normal. But what if $X$ was not standard normal?","['probability-distributions', 'probability-theory', 'probability']"
3434225,"If $f(x)=f(1/x)$, is it possible for $f'(x)=f'(1/x)$?","If $f:\mathbb{R} \to \mathbb{R}$ such that $f(x) = f(\frac{1}{x})$ for all $x \neq0$ and $$\lim_{x \to \infty}f(x) = \lim_{x \to -\infty}f(x) = f(0),$$ then we say $f$ is an inverse reflective function. All inverse reflective functions are completely described on $[-1,1]$ , which is the most intriguing feature I can think of. One example is $$g(x) = \frac{x}{x^2+1}.$$ Let $$D := \{f \mid f\text{ is inverse reflective and $f$ is differetiable everywhere}\}.$$ Question: Does there exists a non-constant $f \in D$ such that $f'$ is inverse reflective? I personally believe the answer is no, but my belief is not based on any mathematical deductions.","['derivatives', 'real-analysis']"
3434254,Simple random walk on infinite tree (recurrence / transience),"Short Version : I'm reading Probability on Trees and Networks and I am currently struggling with Exercise 3.4 (page number 80 / page 97 in the PDF) which asks ""For simple random walk on $T$ to be transient, is it necessary that $\operatorname{br} T > 1$ ?"". The hint says to consider spherically symmetric trees. Of course, an infinite spherically symmetric tree $T$ with branching number $\operatorname{br} T = 1$ would be the tree where every node has exactly one child ( $=$ a root with an infinite line of nodes attached). The simple random walk on this graph is recurrent, so $\operatorname{br} T \geq 1 \nRightarrow \textrm{transient}$ . Hence, we need $\operatorname{br} T > 1$ to infer transience. My question is about the other direction: does transience imply $\operatorname{br} T > 1$ ? Or is there an infinite tree with $\operatorname{br} T = 1$ which has a transient simple random walk? Another way to phrase this question is: does it hold that $$\operatorname{br} T = 1 \iff \textrm{simple random walk on } T \textrm{ is recurrent}$$ (if this holds, then transience would imply $\operatorname{br} T > 1$ ; the direction $\impliedby$ is clear since $\operatorname{br} T > 1 \implies \textrm{transient}$ ) In summary, I'm looking for either of these two: either an example of an infinite tree $T$ with $\operatorname{br} T = 1$ and a transient simple random walk or a proof that $\operatorname{br} T = 1$ implies recurrence Long Version : Let $T$ be a locally finite infinite rooted tree (infinitely many nodes, but every node has only finitely many neighbors). The branching number $\operatorname{br} T$ is not completely straightforward to define, but it measures something like the average number of children of a node. In the book mentioned above, there is a good definition in Section 1.2 (page number 2 / page 19 in the PDF). Consider a simple random walk (taking every edge with equal probability) starting at the root. The random walk is transient if the probability of never returning to the root is positive, and recurrent otherwise. The branching number $\operatorname{br} T$ is closely connected to recurrence and transience, see Section 1.4, Theorem 1.7 in the book (page number 7, page 24 in the PDF). This theorem also implies that $\operatorname{br} T > 1 \implies \textrm{transient}$ for simple random walks. The case $\operatorname{br} T = 1$ for simple random walks is not covered by the theorem, however. My question above is exactly about that case. In this question , 1. bullet point, almost the same question was asked. The answer, however, is not correct in my opinion. A simple random walk on the modified binary tree given in the answer is recurrent, and not transient, as claimed in the answer (I'm quite confident that this is correct, but feel free to leave a comment if you think it is transient). There was only this one reply to that question, so I'm still looking for a correct answer.","['graph-theory', 'probability-theory', 'random-walk']"
3434287,Elementary proofs for weaker statements than the Twin Prime Conjecture,"I know that the closest proven statement to the Twin Prime Conjecture is Chen's theorem, stating that there is an infinite number of primes $p$ such that $p+2$ is either prime or semiprime. The proof is however highly complicated; I was wondering if any of the following weaker statements have simpler or clever proofs: Existence of an infinite number of primes $p$ such that $p+2$ has a bounded number of prime factors (either existence of bound or explicit bound) Existence of an infinite number of primes $p$ and existence of a number $n$ (explicit or not) such that $p+n$ has a bounded number of prime factors Existence of an infinite number of positive integers $k$ such that both $k$ and $k+2$ have a bounded number of prime factors Existence of an infinite number of positive integers $k$ and of a positive integer $n$ such that both $k$ and $k+n$ have a bounded number of prime factors By number of prime factors I guess that both number of $distinct$ prime factors and number of $overall$ prime factors in the factorisation are alright (although bounded number of overall factors implies bounded number of distinct factors so it suffices).","['number-theory', 'twin-primes', 'reference-request']"
3434331,Maximal parahoric subgroups,"I am trying to prove Proposition 2.7.3 from I.G. Macdonald's book ""Spherical Functions on a Group of $p$ -adic Type"": Proposition 2.7.3: Every compact subgroup of $G$ is contained in a maximal compact subgroup. The maximal compact subgroups are precisely the maximal parahoric subgroups, and form $(l+1)$ conjugacy classes. All parahoric subgroups are open and compact. $G$ itself is locally compact, but not compact. For context, here $G$ is a simply connected group of $p$ -adic type (and specifically with a specific $BN$ -pair and subgroups $(U_\alpha)_{\alpha\in \Sigma}$ defined earlier in the book, $N$ and $U_\alpha$ are closed subgroups of $G$ and $B$ is an open compact subgroup of $G$ ). The second half of this seems quite straightforward (and it mentions it in the book), where the parahoric subgroups are finite unions of cosets $BwB$ so they are compact, while $G$ is not a finite union of the $BwB$ so it isn't compact. But I can't quite wrap my head around the first part. Thank you in advance!","['algebraic-geometry', 'group-theory', 'abstract-algebra']"
3434443,Prove constant exists such that a function is uniformly continuous,"Let $p(x)$ be a given polynomial. Show that there is a constant $K$ such that the function $g$ defined by $g(x)=\ln(p(x)+K)$ is uniformly continuous on the interval $[-10,10]$","['functions', 'uniform-continuity']"
3434503,"Terence Tao, Analysis I, Ex. 5.4.5: There is a rational between any two reals","Terence Tao, Analysis I, 3e, Exercise 5.4.5: Prove Proposition 5.4.14. (Hint: use Exercise 5.4.4. You may also need
  to argue by contradiction.) Proposition 5.4.14: Given any two real numbers $x < y$ , we can find a
  rational number q such that $x < q < y$ . Exercise 5.4.4: Show that for any positive real number $x > 0$ there
  exists a positive integer $N$ such that $x > 1/N > 0$ . What I've found so far (with the help of this answer, and Pratik Apshinge's comment): From Exercise 5.4.4, there is a positive real number $$y - x > 1/N > 0, $$ $$yN - xN > 1, $$ $$yN - 1 > xN.$$ Since there is an integer $m$ between $yN$ and $yN - 1$ , we have that $$yN > m \ge yN - 1 > xN$$ $$yN > m > xN$$ $$y > m/N > x$$ Since $m$ and $N$ are integers, there exists a rational between $y$ and $x$ . But how could a proof by contradiction help in this case?","['proof-verification', 'real-analysis']"
3434510,"Is it correct to say, as a general rule, that the range of a function cannot be bigger than the domain of this function?","The following reasoning seems correct to me, but is it valid for all sets ( finite and infinite)? (1) If the range is strictly bigger than the domain,then the domain is trictly smaller that the range. (2) If the domain is smaller, some element of the domain will have to be related to more than one element of the range in order every element of the range to have a pre-image ( unless it would not belong to the range). (3) But in that case, it is no longer a function.",['elementary-set-theory']
3434543,Relative magnitude of moments of a probability density to its cumulants,"Consider a probability density $f(X)$ of some random variable $X\leq0$ , with moments $\mu_n'=\left< X ^n \right>$ and cumulants $\kappa_n$ . I aim to proof $$ \Delta_n := (-1)^n \left(\mu_n'- \frac{\kappa_n}{(n-2)!}  \right) \geq 0  \quad \text{for }n=(2,3,\ldots,\infty)  $$ which I have been able to confirm for the first two coefficients, $$ \Delta_2 = \mu_2' - \kappa_2 = \mu_2' -(\mu_2' - \mu_1'^2) = \mu_1'^2 \geq 0$$ $$ \Delta_3 = -(\mu_3' - \kappa_3) = -(\mu_3' - (\mu_3' - 3 \mu_2'\mu_1' + 2\mu_1')) =\mu_1'(2\mu_1'^2 - 3\mu_2') \geq 0 \quad (\text{since }\mu_2' \geq \mu_1'^2) $$ where I introduced the central moments $\mu_n=\left< (X -\left<X\right>)^n \right>$ . Any help would be very much appreciated. Note that $(-1)^n(\mu_n' - \kappa_n) \geq 0$ would also proof the above, though being a somewhat stricter requirement.","['inequality', 'probability-theory', 'probability', 'cumulants']"
3434557,How to solve a linear congruence $8n+9\equiv 0\pmod{\!1163}$,"Problem : Solve in $\mathbb N$ : $8n+9\equiv 0\pmod{1163}$ The mathematics give me : $n=435+1163k$ , $k\in\mathbb N$ $1163$ is a prime number $8n\equiv -9\pmod{1163}$ $8n\equiv 1154\pmod{1163}$ I don't know any ideas to complete my work ? I have to see your hints","['number-theory', 'elementary-number-theory', 'prime-numbers']"
3434605,Etale topology on the projective line,"Let $X=\mathbb{P}_{\mathbb{C}}^1$ . I am trying to get a better handle on an etale topology on $X$ . I know that every open immersion is etale, and so open subsets of $X$ in the Zariski topology should also be open subsets in the etale topology. What are some examples of open subsets on $X$ in the etale topology which are not open in the Zariski topology?",['algebraic-geometry']
3434639,What is the most surprising / interesting application of the inverse function theorem you have ever seen?,"The inverse function theorem states that: Suppose that $f: U \subset \mathbb{R}^m \rightarrow \mathbb{R}^m$ is a $C^k$ -function 
and that there exists $a \in U$ such that $f'(a): \mathbb{R}^m \rightarrow \mathbb{R}^m $ is an isomorphism. Then, there exist $\delta > 0$ and an open ball $B_{\delta} : = B(a, \delta) \subset U$ such that $f \mid_{B_{\delta}} : B_{\delta} \rightarrow V \ni f(a)$ is a diffeomorphism, with $V$ being an open set. There are two remarkable applications of this theorem: 1- Existence of matrices $X$ such that $X^ k = Y$ where $Y$ is a 
matrix sufficiently close to the identity; 2- Differentiable perturbation of the identity: Let $U \subset \mathbb{R}^m$ a convex and open set. If $ \varphi : U \rightarrow \mathbb{R}^m$ is $C^k$ , with $|\varphi'(x)| \leq \lambda < 1$ for all $x \in U$ , then $f : U \rightarrow \mathbb{R}^m$ given by $f(x) = x + \varphi(x)$ is a diffeomorphism on $U$ onto its image $f(U)$ . My goal with this question is to broaden the knowledge about the application/importance of this theorem in other contexts in the areas of Analysis, Geometry, Differential Topology, etc...","['analysis', 'morse-theory', 'partial-differential-equations', 'differential-topology', 'differential-geometry']"
3434656,How to find the third eigenvalue/eigenvector pair?,"We are given a $3 \times 3$ real matrix $A$ , and we know it has three eigenvalues. One eigenvalue is $\lambda_1=-1$ with corresponding eigenvector $v_1=\left[\begin{matrix}
    0 \\
    1 \\
    0 \\
   \end{matrix}\right]$ and another eigenvalue $\lambda_2=1+i$ and corresponding eigenvector $v_2=\left[\begin{matrix}
    1 \\
    2 \\
    i \\
   \end{matrix}\right]$ . Given this, how can we find the third eigenvalue/eigenvector pair $(\lambda_3, v_3)$ ? The point is ultimately to be able to find the general solution to the linear DE system $x'=Ax$ . The context is that this problem came up in a qualifying exam. My linear algebra is incredibly rusty so I imagine there's just some eigenvalue/eigenvector related trick I'm not seeing. Now, considering the characteristic polynomial, it should be clear that the third eigenvalue is $\lambda_3 = 1-i$ . What's not clear to me is determining the corresponding eigenvector. Clearly, it must be linearly independent from the other two, but how can we use the given eigenvectors to deduce the third one?","['linear-algebra', 'ordinary-differential-equations']"
3434662,"Tonelli's theorem holds for an arbitray $(Y,\mathcal{Y},\nu)$ measurable space in this case","My question is the exercise 10.M) of Bartle's book. I want to prove that Tonelli's theorem holds for an arbitrary $(Y,\mathcal{Y},\nu)$ measurable space if $(X,\mathcal{X},\mu)$ is the measurable space with $X=\Bbb{N},\mathcal{X}=\mathcal{P}(X)$ is the $\sigma-$ algebra of all subsets of $X$ , and $\mu$ is the counting measure in $\mathcal{X}.$ The Tonelli's theorem suppose that $(X,\mathcal{X},\mu),(Y,\mathcal{Y},\nu)$ are $\sigma-$ finite measurable spaces. The demonstration follows by: (i) First proving the case where $F$ is the characteristic function of a measurable set, (ii) then proving the case where $F$ is a simple function by linearity, and, finally, (iii) proving the case where $F$ is a nonnegative measurable arbitrary function. It defines increasing sequences of simples functions converging to each integral $f(x)=\int_{Y}F_{x}d\nu,g(y)=\int_{X}F^{y}d\mu.$ Then, applies the Monotone Convergence Theorem to prove that $\int_{X}fd\mu=\int_{Y}gd\nu=\int_{Z}Fd\pi,$ where $Z=X\times Y$ and $\pi$ is the product measure (unique by $\sigma-$ finiteness). In my question, $(X,\mathcal{X},\mu)$ is a $\sigma-$ finite space, but $(Y,\mathcal{Y},\nu)$ doesn't needs to be it. I found two problems: Proving that (i) $\implies$ (ii) is easy, since the assumption of $\sigma-$ finiteness is not used. But I have two problems: 1) How can I prove (i) if $(Y,\mathcal{Y},\nu)$ is not a $\sigma-$ finite in this case? Is there something about $(\Bbb{N},\mathcal{P}(\Bbb{N}),\mu)$ that make it true? 2) How can I deal with the problem that $\pi$ is not the unique product measure in $Z=X\times Y$ ?","['measure-theory', 'product-measure']"
3434799,Prove $N_n \equiv\frac{n(n+1)}{2}\mod 9$,"Prove $$N_n \equiv\frac{n(n+1)}{2}\mod 9$$ where $N_n$ is the number
  obtained by writing 1 to n one after the other. For example, $$N_{12}
 = 123456789101112$$ My Attempt:
First, I listed the first ones: $$N_1=1\equiv 1\mod 9$$ $$N_2=12\equiv 3\mod 9$$ $$N_3=123\equiv 6\mod 9$$ , and the remainder did match the pattern $\frac{n(n+1)}{2}$ . So I tried to do proof by induction. Assume $$N_k \equiv\frac{k(k+1)}{2}\mod 9$$ , then
I figured out that $$N_{k+1} = 10^{\lfloor \log_{10}(k+1)+1\rfloor}N_k + k+1$$ , so I need to prove $$10^{\lfloor \log_{10}(n+1)+1\rfloor}N_k + k+1 \equiv \frac{(k+1)(k+2)}{2} \mod 9 $$ But got lost from here...Maybe induction is not the best way to proof this.","['modular-arithmetic', 'discrete-mathematics']"
3434831,Cone in algebraic geometry: useful construction?,"Let $S$ be a scheme. Let $\mathcal{A}$ be a quasi-coherent graded $\mathcal{O}_S$ -algebra. Assume that $\mathcal{O}_ S = \mathcal{A}_0$ . The affine cone associated to $\mathcal{O}_S$ -algebra $\mathcal{A}$ is the $S$ -scheme $C:= \underline{\mathop{\mathrm{Spec}}}_ S(\mathcal{A})$ . I understand the definition and my geometric intuition is that it generalizes the geometric construction of a ""ray"" space of projective space; nevertheless I'm far away from fully comprehending what are the advantages and usage of the cone construction in algebraic geometry. Which kind of problems can be conceptually attacked effectively using this construction and what is the intuition making it a useful tool one should have? Is it more than an introducing model example of Grothendieck's relative point of view? Can its role in algebraic geometry be compared with the role of cone construction in topology? In that setting a cone provides a space, which contains the original space, but has a bunch of nice topological properties, which making it interesting for homotopy theory. In algebraic geometry we have also a zero section $i_0: S \to C$ . The point is: what is the bunch of properties making the cone in a certain way easier to work with (possibly like better control over regularity, certain nice properties for birational geometry, from intersection theoretical viewpoint, and so on, I don't know; to gather at least the most important ones is precisely the motivation for posting this question), while on the other hand keeping enough information about the original space that we can draw back conclusions about it (and so that justify its advantages)?","['algebraic-geometry', 'schemes']"
3434833,Using Eulers Polyhedron Formula to show that the following statement is not true,"We divide a piece of paper in 12 parts. Moreover we have 30 pieces of cellotape. We connect two pieces of paper, if they have a common ""borderline"". Show that the following Statement is not true: "" 30 pieces of cellotape aren't enough to fix the paper. "" My work: In order to better understand the situation I visualise the situation. This would be an example for 4 pieces of paper and 4 cellotapes. So how can I Show that the Statement above is not true? My idea was to use Euler's polyhedron Formula. $$ V - E + F = 2 $$ where $V$ is verticles, $E$ is edges and $F$ faces.
I would say that $F$ is 12 ( pieces of paper ) and $E$ is 30 ( cellotapes ). Now I'm stucked.","['graph-theory', 'discrete-mathematics']"
3434902,Is there any algorithm or procedure for an *automatic* translation of English sentences to symbolic logic? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 4 years ago . Improve this question I see that there are methods for processing a sentence manually, I mean looking for ""if"", ""then"", ""and"", ""or"", etc. and then generating the equivalent logical expression. However, I was looking for something where I can give many sentences and the algorithm would generate the equivalent logical expressions automatically. Thanks and regards. Masud","['logic', 'discrete-mathematics']"
3434936,How Are Generalized Eigenvalues used in Differential Equations?,"I understand the process for how Eigenvalues are involved in Differential Equations.  If you have Differential System of Equations like this $$ \vec{x}' = \begin{pmatrix} 2 & 1 \\ 0 & 1 \end{pmatrix}\vec{x} $$ The solution to that System of Differential Equations is a Linear Combination of e to the power of the eigenvalues times the corresponding eigenvectors. $$ \vec{x} = C_1e^{2t}\begin{pmatrix} 1 \\ 0 \end{pmatrix} + C_2e^t\begin{pmatrix} -1 \\ 1 \end{pmatrix} $$ However, what I am struggling with figuring out how Generalized Eigenvalues translate to the solutions in Differential Equations.  If you take this System of Differential Equations $$ \vec{x}' = \begin{pmatrix} 1 & 0 & 0 \\ 3 & 1 & 0 \\ 6 & 3 & 1 \end{pmatrix}\vec{x} $$ The solution to this Differential Equations is $$ \vec{x} = C_1e^t\begin{pmatrix} 1 \\ 3t \\ 6t + \frac{9}{2}t^2 \end{pmatrix} + C_2e^t\begin{pmatrix} 0 \\ 1 \\ 3t \end{pmatrix} + C_3e^t\begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} $$ But the eigenvectors of this matrix (including the generalized eigenvectors) are $$ \vec{v}_1 = \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix},\:\: \vec{w}_1 = \begin{pmatrix} 0 \\ 1 \\ 3 \end{pmatrix},\:\: \vec{w}_2 =  \begin{pmatrix} 1 \\ 1 \\ 3 \end{pmatrix} $$ These eigenvectors do share some similarities to the solution to the System of Equations.  However, the $$ 6t + \frac{9}{2}t^2$$ term in the solution is one I have no idea how generalized eigenvectors relate.  May someone please explain how these eigenvectors translate into Differential Equations?","['ordinary-differential-equations', 'eigenvalues-eigenvectors']"
3434979,"Triple integral $\iiint_D x^2yz \,dx\,dy\,dz$ over a strange area","Fairly simple triple integral $$\iiint_D x^2yz \,dx\,dy\,dz$$ over the area $D = \{(x,y,z):0 \leq x \leq y+z \leq z \leq 1\}$ . I'm not sure how to interpret this area, this is what I have done so far: Since the area is strictly positive we get from $0 \leq x \leq y+z \leq z \leq 1$ $$\begin{align} 0 &\leq x \leq 1 \\ -z &\leq y \leq 0 \qquad \text{and} \\ 0 &\leq z \leq 1\end{align}$$ Which gives me the integral: $$\int_0^1 \int_{-z}^0 \int_0^1 (x^2yz) \,dx\,dy\,dz$$ This I can fairly easily calculate, giving me the final answer $\frac{1}{24}$ , (I dont have the key). I'm not sure my integration limits are correct, if not any pointers to how I can figure them out would be greatly appreciated. Thanks in advance.","['integration', 'multivariable-calculus', 'multiple-integral', 'definite-integrals']"
3435079,Consider $\sum_{n=1}^\infty(n^{1/n}-1)^a$. Find out all the values of $a$ for which this converges.,"Consider $$\sum_{n=1}^\infty(n^{1/n}-1)^a$$ Find out all the values of $a$ for which this converges. Let me include my try: First observation, we know that $\operatorname{log}x \leq x-1$ . Now putting $x=n^{\frac1n}$ we get $\operatorname{log}n^{\frac1n} \leq n^{\frac1n}-1 \Rightarrow \frac1n \operatorname{log} n \leq n^{\frac1n}-1\Rightarrow \operatorname{log}n \leq n(n^{\frac1n}-1)\Rightarrow 1 \leq \operatorname{log}n \leq n(n^{\frac1n}-1)\text{ for $n>3$}\Rightarrow \frac1n \leq \frac {\operatorname{log}n} n\leq (n^{\frac1n}-1)\text{ for $n>3$}\Rightarrow (\frac1n)^a \leq (\frac {\operatorname{log}n} n)^a\leq (n^{\frac1n}-1)^a\text{ for $n>3$}$ Now $\sum_{n=1}^\infty (\frac1n)^a$ diverges for all $a \leq 1$ so we get $\sum_{n=1}^\infty(n^{\frac1n}-1)^a$ diverges for all $a \leq 1$ . Second observation, $\lim_{x \to 1} \frac{\operatorname{log}x}{ x-1}=1$ . So putting $x=n^{\frac1n}$ and observing that $x \to 1$ if $n \to \infty$ , we get $\lim_{n \to \infty} \frac{\operatorname{log}n^{\frac1n}}{ n^{\frac1n}-1}=1 \Rightarrow \lim_{n \to \infty} (\frac{\operatorname{log}n^{\frac1n}}{ n^{\frac1n}-1})^a=1 $ . So, $\sum_{n=1}^\infty(n^{1/n}-1)^a$ and $\sum_{n=1}^\infty(\operatorname{log}n^{\frac1n})^a$ converge and diverge simultaneously. So we might find a condition for what values of $a$ , $\sum_{n=1}^\infty(\operatorname{log}n^{\frac1n})^a$ converges!","['contest-math', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
3435142,Nakayama's lemma implies isomorphism,"It was originally related to this . I think it worthy to ask separately. Known is: $X=\mathrm{Spec}(S),\ Y=\mathrm{Spec}(R)$ are affine, $f$ is finite morphism, actually the fiber has only one point at $y$ which is $\mathrm{Spec}(\mathbb C)$ . If needed we can also think they are just closed subsets of $\mathbb {A}^n,\mathbb {A}^m$ . Now consider the fiber product: $$\require{AMScd}
\begin{CD}
Z @>>> X\\
@V{f'}VV @VV{f}V \\
\mathrm{Spec}(\mathscr{O}_{Y,y}) @>>> Y
\end{CD}$$ We want to conclude that $Z\to \mathrm{Spec}(\mathscr{O}_{Y,y})$ isomorphism. We can translate into commutative algebra by reversing the arrows: $$\require{AMScd}
\begin{CD}
R @>>> R_{\mathfrak{p}}\\
@V{g}VV @VV{g'}V \\
S @>>> S\otimes_{R}R_{\mathfrak{p}}
\end{CD}$$ We know that the $g,g'$ arrows are finite. $B:=S\otimes_{R}R_{\mathfrak{p}}$ is a finite $R$ -algebra. The author in proposition 2.6 just claimed that $B$ is also local and then by Nakayama, they are isomorphism? I do not understand these arguments.","['algebraic-geometry', 'commutative-algebra']"
3435144,Doubt about Taylor series: do successive derivatives on a point determine the whole function?,"I'm currently relearning Taylor series and yersterday I thought about something that left me puzzled. As far as I understand, whenever you take the Taylor series of any function $f(x)$ around a point $x = a$ , the function is exactly equal to its Taylor series, that is: $$ f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n $$ For example, if we take $f(x) = e^x$ and $x = 0$ , we obtain: $ e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!} $ My doubt is: the only variables in the Tayor series formula are $f(a), f'(a), f''(a),$ etc., that is, the successive derivatives of the function $f$ evaluated in one point $x = a$ . But the Taylor series of $f(x)$ determine the whole function! How is it possible that the successive derivatives of the function evaluated in a single point determine the whole function? Does this mean that if we know the values of $f^{(n)}(a)$ , then $f$ is uniquely determined? Is there an intuition as to why the succesive derivatives of $f$ on a single point encode the necessary information to determine $f$ uniquely? Maybe I'm missing a key insight and all my reasoning is wrong, if so please tell where is my mistake. Thanks!","['calculus', 'functions', 'taylor-expansion']"
3435158,Self Study General Relativity from Scratch from a Mathematician's Point of View,"I've been studying General Relativity for a while from physics books and I could understand most of the materials. My problem is I'd like to study the mathematics of GR to really understand the subject as well as its formulation. I have a background in physics, so I'm asking in here for a mathematician's point of view. And what I am looking for is a path and resources from calculus to all of the mathematics which has been used in GR. I say from calculus because as a physics major, they haven't taught us thoroughly and rigorously like how mathematicians study it so I'm willing to study from scratch. And also I started a book on General Relativity for Mathematicians and I couldn't understand anything. So I was hoping I could start from somewhere which could lead me to that book on the end. I'm sorry because this question is similar to others but I couldn't find any answer to my question.","['self-learning', 'book-recommendation', 'reference-request', 'general-relativity', 'differential-geometry']"
3435160,How to calculate the probability of matching ONLY the Thunderball?,"I'm looking for an explanation of a probability value. The UK has a lottery game called Thunderball. The player chooses 5 Main Numbers from 1 to 39 and also 1 Thunderball from 1 to 14. The Thunderball machine does the same and if all of your 6 numbers match then you win the jackpot. Odds for Thunderball Game I understand that the odds of winning the jackpot are 1 in 8,060,598. What I don't understand is why the odds of matching ONLY the Thunderball are 1 in 29?
Surely it should be 1 in 14? For more info on the Thunderball game, please visit Wikipedia at: https://en.wikipedia.org/wiki/National_Lottery_(United_Kingdom)#Thunderball Thank you for your help.","['combinatorics', 'probability']"
3435209,Partial derivatives: Why do results vary?,"When I attempt to compute $f_{y}(0,0)$ , I first set $x = 0$ such that $f(0,y) = \frac{y^2}{y^2} = 1$ , and so $f_{y}(0,y) = 0$ . So its passes differentiability w.r.t.y near $(0,0,f(0,0))$ . However, if I compute this exact partial derivative using the definition of differentiation: $\lim_{h \to 0}\frac{f(0+h)-f(0)}{h}$ , I end up obtaining $\lim_{h \to 0}\frac{1}{h}$ which reveals that $f_{y}(0,0)$ does not exist. How can such contradicting result be explained?","['partial-derivative', 'derivatives']"
3435253,Better understanding of the pre sheaf kernel,"I'm currently reading chapter II of Hartshorne's algebraic geometry and there defines kernel ,cokernel.....etc. everything is define on sheaf of Abelian groups. we know that for  a sheaf morphism $\phi :\mathcal{F}-\mathcal{G}$ kernel is $\ker{\varphi}$ for sheaf of  abelian group or ring ...etc. But if $\mathcal{F},\mathcal{G}$ are sheaf of sets, then what is the equivalent condition of kernel . Thanks in advance.",['algebraic-geometry']
3435395,How big is the smallest triangle inscribed in a square,"A square is divided in 7 areas as show on the figure.
The dots show the corners of the square and the middle points on the edges. How large a fraction is area $D$ and how do I work it out? I have tried using trigonometry to calculate the area A. If we say each side of the square is $1$ , and look at the triangle $ABC$ using Pythagoras, it's hypotenuse must be $ \sqrt {1 \cdot 1 + 0.5 \cdot 0.5} = 1.118$ . Then using the sine relation we see that the $ \hat A$ is $\sin A = 1/1.118 = 63.43°$ . It then follows the other angles must be $90°$ and $71.57°$ . If I use Heron's formula I can calculate the area of $A = \sqrt {p(p−a)(p−b)(p−c)} = \frac 1 {12}$ .
I know $C$ is $ \frac1 {16}$ just by looking at the figure. 
The area of $ABC$ is $ \frac 1 4 $ , so $B$ must be $\frac 1 4 - C - A = \frac 5 {48}$ .
Now the area of $BD$ must be $ \frac 1 8$ . It therefore follows that $D = \frac 1 8 - \frac 5 {48} = \frac 1 {48}$ . The trigonometry part just seems too elaborate, and I was wondering if there is a much more simple solution I am missing?",['trigonometry']
3435457,Finding the minimal polynomial of an $n \times n$ matrix,How would one find the minimal polynomial of $$ A= \begin{pmatrix}0&-1&-2&\cdots&1-n\\1&0&-1&\cdots&2-n\\2&1&0&\cdots&3-n\\\vdots&\vdots&\vdots&\ddots&\vdots\\n-1&n-2&n-3&\cdots&0\end{pmatrix}$$ Where $A$ is an $n \times n$ matrix with $n\ge 3$ ?,"['matrices', 'minimal-polynomials']"
3435466,5 points determine uniquely a conic,"I'm reading ""Multiple View Geometry"" by Richard Hartley and Andrew Zisserman.
On pages 30-31 they have a section which proves that 5 points determine a conic.
now, I know this question has been asked before but I would like an answer for the specific presentation which I describe below. First, they describe a conic by the equation: $$ax^2+bxy+cy^2+dx+ey+f=0$$ So by aggregating 5 points $(x_i,y_i)$ for $i\in\{1,\ldots,5\}$ which hold the above equation we get the matrix equation: $$\begin{bmatrix}x_1^2&x_1y_1&y_1^2&x_1&y_1&1\\x_2^2&x_2y_2&y_2^2&x_2&y_2&1\\x_3^2&x_3y_3&y_3^2&x_3&y_3&1\\x_4^2&x_4y_4&y_4^2&x_4&y_4&1\\x_5^2&x_5y_5&y_5^2&x_5&y_5&1\end{bmatrix}\mathbf{c}=0$$ where $\mathbf{c}=(a,b,c,d,e,f)^T$ . Finally, they claim the following: ""...the conic is the null vector of this $5\times$ 6 matrix . This shows that a conic is determined uniquely (up to scale) by five points in general position."" I have 2 questions about their derivation: 1) I know from other sources that 5 points where no 3 of them are collinear determine uniquely a conic so I guess that here the authors meant general linear position (which in this case translate to the condition that no 3 of the 5 points are collinear) and not some other kind of notion of general position. Am I right? 2) From a Linear algebraic point of view I would say that the immediate conclusion of the above matrix equation is that if the rank of such matrix is 5 then those 5 points determine uniquely a conic so I guess that this condition (of rank=5) can be translated to the condition for the 5 points to be in general position but I can't see why it is the same.","['conic-sections', 'projective-geometry', 'linear-algebra', 'geometry']"
3435476,How do I know $a+a+...+a$ $n$ times is $na$,For a cardinal $a$ and a positive integer $n$ This seems almost trivial but I’m not sure how I can show it is true. Is it defined to be this way or must it be shown?,"['elementary-set-theory', 'cardinals']"
3435508,Series expansion of a function defined through an integral,"I am trying to study the following function defined in terms of an integral $$f(x) = -\int_{x}^{\infty} \sqrt{1-\frac{x^2}{k^2}}\log\left( 1- e^{-k}\right) dk$$ with $x\geq 0$ . So far I was able to compute: $f(0)= \frac{\pi^2}{6}$ . Using a saddle point approximation I was able to determine the asymptotic form $f(x) \approx c \frac{e^{-x}}{x^{3/2}}$ for large $x$ with $c$ a numerical constant. Moreover, I can evaluate numerically the integral and see that the function is monotonically decreasing and always positive. I add the numerical plot between 0 and 1 for completeness After a week of tinkering, I am tempted to give up. I am missing: 1) a form for $f$ in terms of known functions (probably this is not possible) 2) at least the series expansion of $f(x)$ in a neighborhood of $0$ a.k.a. compute $f'(0)$ and $f''(0)$ . Thank you very much for your help!","['integration', 'sequences-and-series']"
3435592,Hard functional equation: $ f \big ( x y + f ( x ) \big) = f \big( f ( x ) f ( y ) \big) + x $,"Let $ \mathbb R _ { > 0 } $ be the set of positive real numbers. Find all functions $ f : \mathbb R _ { > 0 } \to \mathbb R _ { > 0 } $ such that $$ f \big ( x y + f ( x ) \big) = f \big( f ( x ) f ( y ) \big) + x $$ for all positive real numbers $ x $ and $ y $ . What I thought: We could change $ x $ by $ y $ , and then subtract. Source: Brazil National Olympiad 2019 #3","['contest-math', 'functional-equations', 'functions']"
3435599,"Given a function f, check, if it is Lebesgue integrable.","I'm not sure if my attempt is fruitful or not. The exercise is as follows: Given the function $f: [0,1] \rightarrow \mathbb{R} \cup \{\infty\}$ , $~f(x) := \frac{1}{\sqrt(x)}$ , $x \neq 0$ and $f(x) := \infty$ , $~x = 0$ . Check if f is Lebesgue-integrable. My assumption is, that $f$ is not integrable (although it is measurable). The reason is, that for $x \rightarrow 0$ the convergence rate of f towards the y-axis is not fast enough. ( $\textbf{Question 1:}$ Is there a way to put my very rough and possibly wrong estimation into more mathematical terms?) Since f(x) $\geq 0$ for each $x\in [0,1]$ , I want to show, that there exists a measurable simple function $s, $ $0\le s\le f$ , such that sup{ $\int_{_{[0,1]}}s ~d\lambda$ : $s$ integrable } $=\infty$ . ( $\textbf{Question 2:}$ Is it enough to show this?) Let $I_k := [\frac{1}{k+1},\frac{1}{k}]$ and $s_n := \sum_{k=1}^n \sqrt{k} ~~\chi_{_{I_k}}$ . Then for each $n\in \mathbb{N}$ the inequality $0 \leq s_n \leq f(x)$ holds. To make this a little bit shorter: In the following I would show, that the inequality $\int_{_{[0,1]}}s_{2n} ~d\lambda - \int_{_{[0,1]}}s_n ~d\lambda \geq \frac{1}{2}$ holds. Next I'd conclude, that the growing sequence $\{ \int_{_{[0,1]}}s_n ~d\lambda \}_{n\in \mathbb{N}}$ converges to $\infty$ , such that the supremum of this sequence would be $\infty$ .","['measure-theory', 'lebesgue-integral']"
