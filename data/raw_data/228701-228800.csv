question_id,title,body,tags
4734916,Can you solve two unknowns with one equation?,"For example, this equation: $\dfrac{x}{3} = \dfrac{x}{2} \cdot y$ When you graph it out, you can see that there are two lines which intersect perpendicularly. Giving the answers $x = 0$ and $y = \dfrac{2}{3}$ . If you try replacing $x$ with any number, say $18$ , $y$ will always be equal to $\dfrac{2}{3}$ . Same with $y$ . If you replace it with any number $x$ will always be zero. Below is a graph of the equation. I’ve always thought that a minimum of two equations were needed to figure out 2 unknowns. Someone please explain what’s going on.","['algebra-precalculus', 'graphing-functions']"
4734950,Construction of a graph $G$ with $\lvert V(G)\rvert = 13$ vertices and minimum degree of every vertex $\delta_0 = 3$ aiming to maximize its diameter,"How would you construct a connected undirected graph $G$ to attain the longest diameter $d =\text{diam}(G)$ (i.e. the longest distance between any pairs of vertices in $G$ ) possible? Parameters $G$ needs to satisfy: number of vertices, i.e. order $\lvert V(G)\rvert = 13$ minimum degree of every vertex $\delta_0 = 3$ (i.e. the number of adjacent vertices of any vertex in $G$ must be $\geq 3$ ) My approach was constructing segments of sub-graphs that are only connected via one edge in order to force using these and spread out the outer vertices ( $A_1, A_{13}$ ). This gives me a maximum diameter of $d = 7$ (marked blue). Can you construct a graph with $d > 7$ ?
Is there a better approach constructing graphs with maximum diameter? Edit:
I found a classical theorem due to Erdös, Pach, Pollack and Tuza (Diameter and Minimum Degree, Journal of Combinatorial Theory 47 (1989), 73-79): A pdf of this paper can be found here Does this imply that for my special case with $n=13$ and $\delta = 3$ the diameter $d =\text{diam}(G) \leq \left \lfloor \dfrac{3 \cdot 13}{3 + 1} \right \rfloor - 1 = 8$ ?
And since $\delta = 3 \leq 5$ , the equality case cannot hold so $d=7$ is indeed the greatest diameter possible for this specific $G$ ?","['graph-theory', 'extremal-graph-theory', 'discrete-mathematics', 'algorithms']"
4734953,Trivial principal bundles and curvature.,"Let $\mathcal{M}$ be a smooth manifold, $G$ a Lie group with Lie algebra $\mathfrak{g}$ and $\mathcal{P}\xrightarrow{\pi}\mathcal{M}$ a principal bundle. If $A\in\Omega^{1}(\mathcal{P},\mathfrak{g})$ is a connection form, we can define its curvature $F^{A}\in\Omega^{2}(\mathcal{P},\mathfrak{g})$ . Now, it is a general fact that, since $F^{A}$ is ""horizontal and of type Ad'', it can be identified with an element $F^{A}_{\mathcal{M}}\in\Omega^{2}(\mathcal{M},\mathrm{Ad}(\mathcal{P}))$ , where $\mathrm{Ad}(\mathcal{P}):=\mathcal{P}\times_{\mathrm{Ad}}\mathfrak{g}$ denotes the adjoint bundle. Now, let us assume that $\mathcal{P}$ is the trivial $G$ -bundle, i.e. $\mathcal{P}\cong\mathcal{M}\times G$ . As a consequence, also the adjoint bundle is the trivial vector bundle, i.e. $\mathrm{Ad}(\mathcal{P})\cong\mathcal{M}\times\mathfrak{g}$ (correct me if I am wrong). In particular, this implies that $F_{\mathcal{M}}^{A}\in\Omega^{2}(\mathcal{M},\mathfrak{g})$ . Now, since $\mathcal{P}$ is trivial, there is a global section $s\in\Gamma^{\infty}(\mathcal{P})$ and we can define $F_{s}:=s^{\ast}F^{A}\in\Omega^{2}(\mathcal{M},\mathfrak{g})$ . Is there any relation between $F_{\mathcal{M}}^{A}$ and $F_{s}$ , both
of which are elements of $\Omega^{2}(\mathcal{M},\mathfrak{g})$ ? If $G$ is abelian, then the answer is clearly yes, since in this case, one can easily show that $F_{s}$ is independent of the choice of $s$ , by the transformation law of $F^{A}$ under gauge transformations. However, in the non-abelian case, it is not clear.","['principal-bundles', 'smooth-manifolds', 'gauge-theory', 'lie-groups', 'differential-geometry']"
4734957,Is there any difference between a $G$-module and a $KG$-module?,"The following is the definition of a left $R$ -module: Definition 1 : Let $R$ be a ring with multiplicative identity $1$ . A left $R$ -module is an abelian group $M$ with a mapping from $R\times M$ to $M$ , $(r,x)\mapsto rx$ , such that $r(x+y)=rx+ry,$ $(r+s)x=rx+sx,$ $(rs)x=r(sx),$ $1x=x.$ In the book The Symmetric Group the author, B. Sagan, defines a $G$ -module in the following way Definition 2 : Let $V$ be a vector space and $G$ be a group with identity $\epsilon$ . Then $V$ is a $G$ -module if there is a multiplication, $g\mathbf{v}$ , of elements of $V$ by elements of $G$ such that $g\mathbf{v}\in V$ , $g(c\mathbf{v}+d\mathbf{w})=c(g\mathbf{v})+d(g\mathbf{w})$ , $(gh)\mathbf{v}=g(h\mathbf{v})$ , $\epsilon\mathbf{v}=\mathbf{v}$ , for all $g,h\in G;\mathbf{v},\mathbf{w}\in V$ ; and scalars $c,d$ of the field. Any vector space is an abelian group and the group algebra $KG$ is a ring. We can therefore consider $V$ as a $KG$ -module satisfying the conditions in Definition 1, and it is easy to see that it then also satisfies the conditions in definition 2. My question therefore is, is there any difference between a $G$ -module and a $KG$ -module?","['representation-theory', 'modules', 'ring-theory', 'abstract-algebra', 'group-theory']"
4735030,"Do ""for all"", ""exists"" and ""in"" necessitate difference of elements?","Let's say we have the following definition: A relation $\rho$ on a set $A$ is called transitive if $a \rho b \wedge b \rho c \Rightarrow a \rho c$ is true for all $a,b,c \in A$ . Another example: $\forall a, b, c \in A (\dots)$ . Do these statements automatically mean/give the condition that $a \neq b \neq c$ or would that have to be specified separately?
I know this question is very basic, but I did not find an answer when searching in my words, so I thought I'd ask here and maybe the answer could help others along the way. Thanks a lot!","['elementary-set-theory', 'logic']"
4735078,Open cover of $\mathbb C$,"Today one of my students asked an interesting question, which I was unable to answer. Concretely: Let $(z_n)_{n\in \mathbb N^+}$ be an enumeration of $\mathbb Q+\mathrm i\mathbb Q$ . The question is, whether $(B_{1/n}(z_n))_{n\in \mathbb N^+}$ is a cover of $\mathbb C$ , i.e. if $$
\mathbb C\subseteq \bigcup_{n=1}^\infty B_{1/n}(z_n).
$$ It is intuitively clear (?) that this should hold. For every $z\in \mathbb C$ there exists a subsequence $(z_{n_k})_{k\in \mathbb N}$ converging to $z$ , since $\mathbb Q+\mathrm i\mathbb Q$ is dense in $\mathbb C$ . I am however unable to show that we can find $k\in \mathbb N$ , such that $|z-z_{n_k}|<\frac{1}{n_k}$ . It's somewhat awkward, since we have the same index $n_k$ on both sides and I am not sure how to deal with this. Thanks for any insights!",['general-topology']
4735085,Using beta reduction on $ \lambda y. ( \lambda x. \lambda y. y x)(\lambda z. y z)$,"I have a few questions regarding this exercise: $$ \lambda y. ( \lambda x. \lambda y. y x)(\lambda z. y z)$$ This is what I have come up with: $ \lambda y. ( \lambda x. \lambda \color{red}u. \color{red}u x)(\lambda z. y z)  = \lambda y. ( \lambda u. u (\lambda z. y z))$ My questions are: 1. While analyzing the expression from left to right, I have two lambda expressions: $\lambda y.$ and $ (\lambda x. \lambda y. yx)$ I would need to apply the first one to the second one (i.e. ""plug in"" the 2nd one in the 1st one) which doesn't make sense. This is why I opted to apply $ (\lambda x. \lambda y. yx)$ to $(\lambda z. y z)$ 2. By applying $ (\lambda x. \lambda y. yx)$ to $(\lambda z. y z)$ , I changed the name of the variable ""y"" to ""u"" in the first expression since it is bound there, and it also appears in the second expression. Did I perform a correct alpha-conversion? Can I reduce this further? 3. I am always confused then I have something like this: $u(\lambda z. yz)$ . I would know what to do if I had $(\lambda z. yz)u$ : I'd apply the function to the argument $u$ . However, now that their positions are reversed, I don't know what to do. Any help would be greatly appreciated!","['lambda-calculus', 'logic', 'discrete-mathematics', 'computability']"
4735116,Second (and Third) Order Non-linear differential equation,"I want to solve the following equation for $f(x)$ (where $f: \mathbb{R}\mapsto\mathbb{R}^+$ ): $$
f(x)=\exp{\left(-\int_{-x}^{\infty}(y+x)^rf(y)\,dy\right)}\,\,,
$$ where $r\in\mathbb{N}$ and $f(-\infty)=1$ and $f(+\infty)=0$ . I am interested in particular in the cases $r=1$ and $r=2$ . I can manipulate the equation by defining an auxiliary function $a(x)$ : $$
a(x)\equiv \ln{f(x)}\,,\quad \text{where} \quad a(-\infty)=0\,;
$$ deriving both sides I get: $$
a'(x)=-r\int_{-x}^{\infty}dy(y+x)^{(r-1)} e^{a(y)}\,.
$$ Case $r=1$ : Deriving another time both sides I get the following second order non-linear differential equation: $$
a''(x)=-e^{a(-x)}\,.
$$ Defining $b(x)\equiv a(-x)$ , it is possible to write a system of two differential equations $$
\left\{\begin{array}{ll} a''(x)=-e^{b(x)} &  \\ b''(x)=-e^{a(x)} &  \end{array}\right.
$$ where some conditions must be imposed: $a(0)=b(0)$ , $a(-\infty)=0$ , $a'(-\infty)=0$ and $-a'(0)=b'(0)$ . Case $r=2$ : In this case I derive both sides twice to get: $$
a'''(x)=-2e^{a(-x)}\,.
$$ In the same spirit of the $r=1$ case we can use $b(x)$ to write: $$
\left\{\begin{array}{ll} a'''(x)=-2e^{b(x)} &  \\ b'''(x)=2e^{a(x)} &  \end{array}\right.
$$ where now the conditions to be imposed are: $a(0)=b(0)$ , $a(-\infty)=0$ , $a'(-\infty)=0$ , $a''(-\infty)=0$ , $-a'(0)=b'(0)$ and $a''(0)=b''(0)$ . This idea to manipulate these equations can be generalized to arbitrary $r$ and it is due to @yarchik from this question about numerical solutions. Is there a way to analytically deal with these equations? The present question is also related to this one, which is the case $r=0$ , that is analytically solvable.","['systems-of-equations', 'analysis', 'ordinary-differential-equations']"
4735139,Real integral using residue,"Im trying to solve $$\int_{0}^{\infty}\dfrac{x^2}{x^6+1} dx$$ So I begin by considering the function $f(z) = \frac{z^2}{z^6+1}$ , I consider the isolated singularities, which are indeed simple poles given by $z_k = e^{i\left(\frac{\pi}{6}+\frac{2\pi k}{6}\right)}$ for $k$ from 0 to 5. None of these poles lie on the real axis, and furthermore, I consider the first 3 poles that are in the upper half-plane, $z_0$ , $z_1$ , and $z_2$ . Therefore, I can calculate the integral using the residue theorem by integrating over the semicircle centered at 0 with a radius of $R$ . Thus, $$
\int_{0}^{\infty} \frac{x^2}{x^6+1} \, dx = \frac{1}{2}\int_{-R}^{R}f(x) \, dx +\int_{\gamma} f(z) \, dz = 2\pi i \left(\text{Res}(f,z_0)+\text{Res}(f,z_1)+\text{Res}(f,z_2)\right).
$$ I have difficulties finding the residues as evaluating the limit becomes complicated and tedious. Is there a more elegant way to solve these residues?","['complex-analysis', 'complex-integration']"
4735141,Convergence of Euler scheme for ODEs,"Consider the initial value problem for the ODE \begin{align}
\frac{dy}{dt}&=f(y), \\
y(0)&=y_0,
\end{align} where $f$ is a Lipschitz continuous function on $\mathbb{R}.$ Since $f$ is globally Lipschitz, the IVP admits a unique solution globally on $\mathbb R.$ Now, consider the Euler approximation given by \begin{align}
y^{n+1}=y^
n+ \Delta t f(y^n).
\end{align} For any $T>0$ and a $\Delta t > 0,$ with $N_0 \Delta t=T,$ how to prove the following estimate: \begin{align}
\left|y(T)-y^{N_0}\right| \leq C \Delta t,
\end{align} where $C>0$ and is independent of $\Delta t.$ P.S.: I am looking for a very general proof, i.e, for any time $T>0$ and with minimal restrictions on $f.$ I would greatly appreciate a clean proof or a precise reference that contains the proof.","['numerical-methods', 'analysis', 'ordinary-differential-equations', 'eulers-method']"
4735161,Classical groups generated by tensor products of subgroups,"Let $ G $ denote a classical group. Question:
Is it the case that $$
\langle G_n \otimes G_m,G_m \otimes G_n\rangle=G_{nm}
$$ as long as $ n \neq m $ ? For example, if $ G $ is the classical group $ GL(\mathbb{C}) $ , then the question becomes: is $$
\langle GL_n(\mathbb{C}) \otimes GL_m(\mathbb{C}),GL_m(\mathbb{C}) \otimes GL_n(\mathbb{C})\rangle=GL_{nm}(\mathbb{C})
$$ as long as $ n \neq m $ ? If $ n=m $ then we have $
\langle G_n \otimes G_n,G_n \otimes G_n\rangle=G_n \otimes G_n 
$ .
And $ G_n \otimes G_n \neq G_{n^2} $ (assuming $ n \neq 1 $ ). Interesting to note that, for the connected classical groups, https://mathoverflow.net/questions/62456/in-a-compact-lie-group-can-two-closed-connected-subgroups-generate-a-non-closed shows that $ \langle G_n \otimes G_m,G_m \otimes G_n\rangle $ must be closed. And I expect it is closed for all classical groups, even the non connected ones. This implies that the question of density in $ G_{nm} $ presented in the original question is actually just a question of equality with $ G_{nm} $ .","['algebraic-groups', 'representation-theory', 'topological-groups', 'group-theory', 'lie-groups']"
4735163,Refine product topology to make Borel sets be clopen,"I'm working on Exercise 2.28 in Prof. David Marker's notes http://homepages.math.uic.edu/~marker/math512/dst.pdf on refining the topology to make Borel sets clopen. Question : Suppose $X$ is a Polish space and $ B \subseteq X \times X $ is Borel. Is it
always possible to put a new Polish topology on $X$ such that $B$ is clopen in the
new product topology on $X \times X$ ? Theorem 2.24 in the notes above tells us that we can find a new topology $\tau'$ on $X \times X$ such that $B$ is clopen, then is it possible to make this $\tau'$ a product topology? What I can see is, maybe we can refine $\tau'$ again with projection maps on each cordinate. Denote it as $\tau''$ . But it only shows that $\tau''$ is at least finer than the product topology. Any help will be appreciated!","['general-topology', 'descriptive-set-theory', 'polish-spaces']"
4735164,Sum the series $3+6+15+42+123….$ to $n$ terms,"This question is from my mathematics exam for 11th graders. This was the last problem on the test and it has stumped me. The question is as follows: Sum the series $3+6+15+42+123…$ to $n$ terms. I tried to solve it but it got me nowhere. At first I set: $$S=3+6+15+42+123…$$ $$\frac{S}{3}=1+2+5+14+41...$$ $$\frac{S}{3}=3+(6-1)+(15-1)+(42-1)...$$ $$\frac{S}{3}=3+6+15+42...-1(n-2)$$ $$\frac{S}{3}=S-(n-2)$$ $$(n-2)=\frac{2S}{3}$$ $$S=\frac{3(n-2)}{2}$$ But this sum is clearly wrong. I also attempted this: $S=3+(3+3^1)+(3+3^1+3^2)+(3+3^1+3^2+3^3)+(3+3^1+3^2+3^3+3^4)...$ But this also doesn’t seem to lead me anywhere. I’d appreciate any help with this question. I should also mention that this exam is for Engineering stream students, who are required to take “advanced math” from Grade 10 onwards to qualify for this stream, which also includes calculus. So calculus based answers are also acceptable as long as they aren’t undergrad level stuff","['algebra-precalculus', 'sequences-and-series']"
4735175,Volume of intersection of two partial spheres having origins at different coordinate frames using spherical coordinates,"Assume I have a world coordinate frame $\mathbf{w}$ . Assume I have a second coordinate frame that can be parameterized as a $4\times4$ homogenous transformation matrix with respect to the world coordinate frame: $\mathbf{^{w}T_{s_1}}$ . The origin of the first sphere $s_1$ has a 6DoF pose represented by the transformation matrix $\mathbf{^{w}T_{s_1}}$ . $s_1$ can be parameterized in spherical coordinates (mathematical convention) as $(\rho_1, \theta_1, \phi_1)$ where $(0 \leq \theta_1 \leq 2\pi)$ and $(-\frac{\pi}{4} \leq \phi_1 \leq \frac{\pi}{4})$ . The restriction of $\phi_1$ means that $s_1$ is in fact a partial sphere that looks like a round bottomed cone. The central axis of the cone is pointing in the direction of the Z-axis of coordinate frame $\mathbf{^{w}T_{s_1}}$ . Assume I have a third coordinate frame that can be parameterized as a $4x4$ homogenous transformation matrix also with respect to the world coordinate frame: $\mathbf{^{w}T_{s_2}}$ . The origin of the second sphere $s_2$ has a 6DoF pose represented by the transformation matrix $\mathbf{^{w}T_{s_2}}$ . $s_2$ can be parameterized in spherical coordinates (mathematical convention) as $(\rho_2, \theta_2, \phi_2)$ where $(0 \leq \theta_2 \leq 2\pi)$ and $(-\frac{\pi}{4} \leq \phi_2 \leq \frac{\pi}{4})$ . The restriction of $\phi_2$ means that $s_2$ is also a partial sphere that looks like a round bottomed cone. The central axis of the cone is pointing in the direction of the Z-axis of coordinate frame $\mathbf{^{w}T_{s_2}}$ . What is the volume of intersection of the partial spheres $s_1$ and $s_2$ ? It seems that given the coordinate transformations and different axis orientations, I may need to convert the spherical coordinates back to cartesian coordinates and then try to solve but I am not sure. Thanks!","['multivariable-calculus', 'spherical-coordinates', 'spherical-geometry', 'differential-geometry']"
4735184,Find the value of $1996^2-1995^2 + 1994^2-1993^2 + \dots + 2^2-1^2.$,Find the value of $$1996^2-1995^2 + 1994^2-1993^2 + \dots + 2^2-1^2.$$ What is wrong with the following reasoning. By the difference of squares formula we have that the sum can be broken into $$(1996-1995)(1996+1995) + (1994-1993)(1994+1993) + \dots + (2-1)(2+1)$$ but all the terms with minus signs are $1$ so we are left with $$1996+1995+1994+1993+\dots+2+1 = \frac{1996(1997)}{2}=1993006$$ which is incorrect as the correct answer should be $998000$ .,['sequences-and-series']
4735211,Duistermaat and Kolk: definition of separating family of seminorms,"I am reading the book ""Distributions: Theory and Applications"" by Duistermaat and Kolk. In chapter 8, Definition 8.5., they say that a family of semi-norms $\mathcal{N}$ is separating if For every $x\neq 0$ , there exists an $n\in \mathcal{N}$ such that $n(x)\neq 0$ . For every $n,m \in \mathcal{N}$ , there exists a $p\in \mathcal{N}$ , such that $n(x),m(x)\le p(x)$ , for all $x$ . However, in every other source I looked at, only the first requirement was stated. Do the authors include the second requirement because given a family of semi-norms that satisfies only the first, we can always extend it to one that also satisfies the second, by say including all finite sums?","['functional-analysis', 'distribution-theory']"
4735223,Having trouble thinking of homeomorphisms as topological isomorphisms,"In short: I find it intuitive that isomorphic algebraic structures (be it groups, rings, fields, vector spaces,...) have the same algebraic properties. Yet I do not find it as intuitive that two homeomorphic topological spaces have the same properties (insofar as these properties deal exclusively with their topology). Instead I find it intuitive to define a 'topological isomorphism' not as a homeomorphism, but as I have defined it below so as to follow the pattern of defining isomorphisms in algebra. The next section can be skipped; it just serves to explain why I find algebraic isomorphisms intuitive, as opposed to homeomorphisms, as well as to why I think homeomorphisms 'break the pattern' in terms of how isomorphisms are defined in algebra. My concise questions are at the end of the post. As I see it, an group isomorphism $\phi:(G_1,+)\to (G_2,\times)$ is a 'renaming' of the elements of $G_1$ and of its operator: any $x\in G_1$ is renamed to $\phi(x)\in G_2$ , and $+$ is renamed to $\times$ . Under that view "" $x + y = z$ "" says the same as "" $\phi(x)\times\phi(y) = \phi(z)$ "", yet with different symbols. Given two isomorphic groups $(G_1, +)$ and $(G_2, \times)$ it is intuitive to me that any 'group-theoretic' property holds in one group if and only if it holds in the other. A vector space consists of an abelian group of vectors $(V,+_V)$ , a field of scalars $(F,+,\times)$ , and scalar multiplication $(\cdot):F\times V$ . Thus a vector space can be seen as a $6$ -tuple $(V,+_V, F, +, \times, \cdot)$ . I would define a 'vector space isomorphism' between $(V_1,+_{V_1}, F_1, +_1, \times_1, \cdot_1)$ and $(V_2,+_{V_2}, F_2, +_2, \times_2, \cdot_2)$ as a pair $(f,g)$ of bijections $f:V_1\to V_2$ and $g:F_1\to F_2$ that 'preserve vector space operations' i.e. $f(v+_{V_1}u)=f(v)+_{V_2}f(u)$ for any $v,u\in V_1$ . $g(a+_1b)=g(a)+_1g(b)$ for any $a,b\in F_1$ . $g(a\times_1b)=g(a)+_1g(b)$ for any $a,b\in F_1$ . $f(a\cdot_1v)=g(a)\cdot_2 f(v)$ for any $a\in F_1, v\in V_1$ . Essentially I'm saying that $f$ is a bijective linear map, that $g$ is a field isomorphism, and that $f$ and $g$ 'preserve' scalar multiplication i.e. $4)$ holds. A linear map is a specific case of the above. As with groups, it is possible to see $f$ and $g$ as 'renaming' the vectors, scalars, and operations between them. Given two vector spaces and a bijective linear map between them, it is intuitive to me that any 'linear-algebra-theoretic' property holds in one vector space if and only if it holds in the other. That intuition remains with me for all algebraic structures I have studied, however given two topological spaces and a homeomorphism (often called a ""topological isomorphism"") between them, it is not intuitive to me that any property (that deals exclusively with their topology) holds in one space if and only if it holds in the other. The reason being that a homeomorphism does not seek to preserve any operators (unlike group isomorphisms, linear maps, etc). If it was defined so as to preserve 'topological operators' it would -I think- be defined as follows: Definition: given two topological spaces $(X,\tau_X)$ and $(Y,\tau_Y)$ a topological isomorphism $(f,\phi)$ is a pair of bijections $f:X\to Y$ and $\phi:\tau_X\to\tau_Y$ that preserve 'topological operations' i.e. Given $x\in X$ and $A\in \tau_X$ , we have that $x\in A$ if and only if $f(x)\in \phi(X)$ . Given an arbitrary collection $\{A_\alpha\}\subseteq \tau_X$ we have $$\phi\left(\bigcup_\alpha A_\alpha\right) = \bigcup_\alpha \phi(A_\alpha).$$ Given $A,B\in\tau_X$ we have $$\phi\left(A\cap B\right) = \phi(A)\cap \phi(B).$$ The following results are almost immediate. Notably, since $1)$ and $2)$ below deal with concepts which definition does not require us to use "" $\in$ "" (closed sets, basis, countability) their proof requires only the use of $\phi$ . However, since the definition of a Hausdorff space uses the $\in$ operator, the proof of $3)$ below does make use of $f$ , the function which ""translates"" $\in$ from $(X,\tau_X)$ to $(Y,\tau_Y$ ) Theorem: if there is some topological isomorphism $(f,\phi)$ between $(X,\tau_X)$ and $(Y,\tau_Y)$ , then $A$ is closed in $\tau_X$ if and only if $f(A^c)$ is closed in $\tau_Y$ . $\tau_X$ is second-countable if and only if so is $\tau_Y$ . $\tau_X$ is Hausdorff if and only if so is $\tau_Y$ . $\ldots$ Why are topological isomorphisms (as I have defined them) not ever used in topology? How do topological isomorphisms relate to homeomorphisms? PS: I know very little universal algebra or category theory.","['general-topology', 'abstract-algebra', 'soft-question', 'definition']"
4735249,$u(x)=\frac{1}{4\pi} \int_{G} \Bigl[\nabla_y \frac{1}{\lvert x-y\rvert} \Bigr] \times \omega(y) dy+A(x)$ for $\omega=\nabla \times u$ and harmonic $A$,"Let $U$ be an open region in $\mathbb{R}^3$ and $G \subset U$ be another open set whose closure is compact in $U$ . Then, for any smooth divergence-free $u : U \to \mathbb{R}^3$ , I ran into the statement that \begin{equation}
u(x)=\frac{1}{4\pi} \int_{G} \Bigl[\nabla_y \frac{1}{\lvert x-y\rvert} \Bigr] \times \omega(y) dy+A(x) \text{ for } x \in G
\end{equation} where $\omega=\nabla \times u$ and $A : G \to \mathbb{R}^3$ satisfies $\Delta A=0$ componentwise. There is no detailed proof and just a brief mention of Hodge's Theorem. But, I cannot see how to make use of the theorem. Also, I have difficulty with proving the formula directly with vector calculus.. Could anyone please help me? Edit : I forgot the divergence-free condition for $u$ , so I add it to the main body.","['multivariable-calculus', 'calculus', 'vector-analysis', 'differential-geometry']"
4735273,$ \int \sin 3x/(\sin x + \cos x)dx=1$ or $1-π/4$?,"This question is from Cengage book Q. $$ \int \sin 3x/(\sin x + \cos x)dx$$ The solution provided in the book is as follows: Sol: $I={\int_0^{\frac{\pi}{2}} \frac{\sin 3 x-\sin x}{\sin x+\cos x} d x  (I1)}+{\int_0^{\frac{\pi}{2}} \frac{\sin x}{\sin x+\cos x} d x (I2)}$ $$
\begin{array}{l}
I_2=\int_0^{\frac{\pi}{2}} \frac{\sin x}{\sin x+\cos x} d x \\\\
I_2=\int_0^{\frac{\pi}{2}} \frac{\cos x}{\cos x+\sin x} d x
\end{array}
$$ Adding,we get $$
2 I_2=\frac{\pi}{2}
$$ $$
\begin{aligned}
I_2 & =\frac{\pi}{4} \\\\
I_1 & =\int_0^{\frac{\pi}{2}} \frac{2(\cos 2 x) \sin x}{\sin x+\cos x} d x \\\\
& =2 \int_0^{\frac{\pi}{2}} \sin x(\cos x-\sin x) d x \\\\
& =\int_0^{\frac{\pi}{2}} \sin 2 x d x-\int_0^{\frac{\pi}{2}} 2 \sin ^2 x d x \\\\
& =\left[-\frac{\cos 2 x}{2}\right]_0^{\frac{\pi}{2}}-\int_0^{\frac{\pi}{2}}(1-\cos 2 x) d x\\\\
& =1-\frac{1}{2}\left[x-\frac{\sin 2 x}{2}\right]_0^{\frac{\pi}{2}} \\\\
& =1-\frac{\pi}{4}
\end{aligned}
$$ Therefore, $I=1$ My solution is as Follows: We know that, $$
\begin{array}{l}
\sin 3x = 3\sin x - 4\sin^3 x\\\\
I=\int_0^{\pi / 2} \frac{\sin 3 x}{\sin x+\cos x} d x\\\\
\therefore I=\int_0^{\pi / 2} \frac{3 \sin x-4 \sin ^3 x}{\sin x+\cos x}-(i) \\\\
\therefore I=\int_0^{\pi / 2} \frac{3 \cos x-4 \cos ^3 x}{\sin x+\cos x}-\text { (ii) }
\end{array}
$$ Adding (i) and (ii) $$
\begin{aligned}
2 I & =\int_0^{\pi / 2} \frac{3(\sin x+\cos x)-4\left(\sin x-\sin x \cos ^2 x+\cos x-\cos x \sin ^2 x\right)}{\sin x+\cos x} \\\\
2 I & =4 \int_0^{\pi / 2} \sin x \cos x d x-\int_0^{\pi / 2} 1 \cdot d x \\\\
2 I & =2-\frac{\pi}{2} \\\\
I & =1-\frac{\pi}{4} \approx 0.2146018366
\end{aligned}
$$ I also checked it in online calculator and it gives the following result, \begin{gathered}
\int \frac{\sin (3 x)}{\sin (x)+\cos (x)} \mathrm{d} x \\
=-\frac{\ln (|\tan (x)+1|)}{2}+\frac{\ln \left(\tan ^2(x)+1\right)}{4}-\frac{\operatorname{ar}}{\text { Rewrite/simplify: }} \\
=-\frac{\ln (|\tan (x)+1|)+\ln (|\cos (x)|)-\sin (2 x)-}{2}
\end{gathered} Note: The result is too wide for the screen. Scroll horizontally to see everything! DEFINITE INTEGRAL: $$
\begin{aligned}
& \int_0^{\frac{\pi}{2}} \boldsymbol{f}(\boldsymbol{x}) \mathbf{d} \boldsymbol{x}= \\
& \frac{2 \ln (2)-2 \ln (-2)-\pi+4}{4}+\frac{\ln (-1)}{2}
\end{aligned}
$$ Approximation:
0.2146018366025517 Which matches my answer but I can't find any mistake in any of the solutions. Is my solution wrong? Thanks in advance.","['integration', 'trigonometry', 'definite-integrals', 'trigonometric-integrals']"
4735286,How to prove $\det{AB}=\det{A}\det{B}$ with Leibniz formula in terms of Levi-Civita symbol and Einstein summation notation? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 12 months ago . Improve this question Prove that $\det{AB}=\det{A}\det{B}$ with Leibniz formula in terms of Levi-Civita symbol and Einstein summation notation Here is a similar question asked 6 years ago. The OP answered in the question that ""expanding will give the answer which is then trivial by inspection"", but I still can't understand why it is ""trivial"".","['determinant', 'tensors', 'matrices', 'linear-algebra', 'index-notation']"
4735293,reference and full statement for the fundamental group of $\Bbb{P}_n^k-Y$ is $\Bbb{Z}/(d)$?,"In Vakil’s FOAG, exercise 15.4.M, there is a remark: 15.4.M. EXERCISE: A TORSION PICARD GROUP. Suppose that $Y$ is a hypersurface in $\Bbb{P}^n_k$ corresponding to an irreducible degree d polynomial. Show that $Pic(\Bbb{P}^n_k-Y) = Z/(d)$ . (For differential geometers: this is related to the fact that $π_1(\Bbb{P}^n_k - Y)= Z/(d)$ .) Is there any reference for the related differential geometry fact? and what is the full statement for it? Is the topology still using the Zariski topology? If not, should the field $k$ be the $\Bbb{C}$ ? Thank you in advance.","['picard-group', 'reference-request', 'fundamental-groups', 'algebraic-geometry', 'differential-geometry']"
4735299,Integrating a formula involving quantisation (floor function),"I have a gamma correction function of the following form: $$f(x) = x^\gamma \text{ for } 0 \le x \le 1, \gamma \in \mathbb{R}^+$$ For example, a simplified approximation of the sRGB electro-optical transfer function (EOTF) is $f(x) = x^{2.2}$ , i.e. $\gamma=2.2$ . I'm trying to analyse the magnitude of deviation between this ""ideal"" gamma correction function, when calculated in a continuous manner, versus a variant where the space is quantised into an $n$ -bit value. The $n$ -bit quantised version of the gamma function can be represented as: $$f_Q(x) = \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ for } 0 \le x \le 1, n \in \mathbb{N}^+, \gamma \in \mathbb{R}^+ $$ By subtracting $f_Q(x)$ from $f(x)$ we get a function that describes the magnitude of quantisation error across the input range: $$f_{Q\Delta}(x) = f(x) - f_Q(x)$$ To turn this into a single value representing the total magnitude of quantisation error, I'd like to calculate the definite integral: $$\int_0^1 f_{Q\Delta}(x) \text{ dx} = \int_0^1 x^\gamma - \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ dx} \text{ for } 0 \le x \le 1, n \in \mathbb{N}^+, \gamma \in \mathbb{R}^+ $$ It's been 17 years since I last did definite integrals, so I'm more than a bit out of practice. My first thought was to tackle the initial step where $\lfloor 2^n x^\gamma \rfloor = 0$ . The upper bound of this first quantised step is the point where $\lfloor 2^n x^\gamma \rfloor > 0$ , which is $\left(\frac{1}{2^n}\right)^{1/\gamma}$ or $2^{-n/\gamma}$ . This simplifies the definite integral to: $$\int_0^{2^{-n/\gamma}} x^\gamma \text{ dx}$$ I'm pretty sure this is the solution of the integral for this first step: $$\int_0^{2^{-n/\gamma}} x^\gamma \text{ dx} = \frac{\left(2^{-n/\gamma}\right)^{\gamma+1}}{\gamma+1} $$ This seems to match up with the numbers I got when calculating the integral through the Desmos graphing calculator online. My next thought was to figure out the intervals for each quantised step. The end of each step should be: $$\left(\frac{k}{2^n}\right)^{1/\gamma} = k^{1/\gamma} \space 2^{-n/\gamma}$$ So, the start of each step should simply be: $$\left(\frac{k-1}{2^n}\right)^{1/\gamma} = \left(k-1\right)^{1/\gamma} \space 2^{-n/\gamma}$$ This lines up with the previous definite integral bounds: for $k=1$ we get $\left(\frac{1}{2^n}\right)^{1/\gamma}$ and $\left(\frac{0}{2^n}\right)^{1/\gamma} = 0$ . So this would mean that my original definite integral can be expressed as the following summation of definite integrals, each describing one quantised step: $$\int_0^1 x^\gamma - \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ dx} = \sum_{k=1}^{2^n} \int_{\left(k-1\right)^{1/\gamma} \space 2^{-n/\gamma}}^{k^{1/\gamma} \space 2^{-n/\gamma}} x^\gamma \text{ dx}$$ However, this is where I got stuck. How do I rework these summed definite integrals to come up with a single formula for the whole definite integral? Or is there another approach I can use?","['integration', 'ceiling-and-floor-functions', 'definite-integrals']"
4735303,Why does the measure of the geometric difference yield a complete metric space on the $\sigma$-algebra?,"I was talking with a professor, and he mentioned the following theorem: Let $(X,\mathcal{F},\mu):=([0,1],\mathcal{B},\lambda)$ be the interval with the usual Lebesgue measure on the Borel sets. For $A,B\in\mathcal{F}$ , we declare $A\sim B$ whenever $\mu(A\Delta B)=0$ , and so we get an equivalence relation on $\mathcal{F}$ . If we define on $\check{\mathcal{F}}:=\mathcal{F}/\sim$ a metric $d$ by setting $d([A],[B]):=\mu(A\Delta B)$ , this is a well defined metric space. Until here, there is no problem, however, here is my doubt: According to my professor, $(\check{\mathcal{F}},d)$ is a complete metric space. I have been struggling a lot to prove this. I imagine one can take an arbitrary Cauchy sequence and construct a limit, but I haven't been succesful there. Could anyone help me with this or give a good place to find a proof of it? Also, for which other measure spaces $(X,\mathcal{F},\mu)$ can the construction of $(\check{\mathcal{F}},d)$ also be a complete metric space? And where can it be polish? Is there a theorem giving good sufficient conditions for this? Thanks in advance for any answer.","['measure-theory', 'descriptive-set-theory', 'real-analysis']"
4735308,"Closed form of $a_1=x$, $a_n=\left\lfloor\dfrac{(n+2)a_{n-1}-2}{n}\right\rfloor,n\ge 2$","Find the closed form of the following sequence of integers: $a_1=x>0$ , $$a_n=\left\lfloor\dfrac{(n+2)a_{n-1}-2}{n}\right\rfloor, n \ge 2$$ I calculated a few terms, and $a_1=x$ , $a_2=2x-1$ , $a_3=2x-6+\lfloor \frac{4x}{3}\rfloor$ . However, the terms get really ugly after this. Then, I tried to find the closed form for certain values of $x$ . For example, when $x=5$ , I found that consecutive terms differ by $4$ , $5$ , $6$ ..., so the closed form is $a_n=\frac{n^2}{2}+\frac{5n}{2}+2$ . Firstly, I'm not sure how to prove this, and secondly, this method does not always work for other values of $x$ , so I'm not sure what to do next. Thanks in advance!","['elementary-number-theory', 'algebra-precalculus', 'recurrence-relations', 'ceiling-and-floor-functions']"
4735321,Elementary Differential Geometry - Reparametrization,"I started reading ""Elementary Differential Geometry"" by Andrew Pressley. I've been confused about Proposition 1.3.6, which reads: A parametrized curve has a unit-speed reparametrization if and only if it is regular. I've been looking over the converse portion of the proof. We're given a regular curve $\gamma: (\alpha, \beta) \rightarrow \mathbb{R}^n$ . The proof uses arc-length s to set up a reparametrization map $s^{-1} : (\tilde{\alpha}, \tilde{\beta}) \rightarrow (\alpha, \beta)$ After setting up the reparametrization map, however, the proof follows: We take $\phi = s^{-1}$ and let $\tilde{\gamma}$ be the corresponding reparametrization of $\gamma$ , so that $\tilde{\gamma}(s) = \gamma(t)$ . What I do not understand is how we're able to automatically assume the existence of reparametrization. I'm confused how we can ensure that the reparametrization would map to the same image of the original curve. The proof seems to imply that a reparametrization exists if we're given a reparametrization mapping. Another part of the proof that I'm confused about is establishing the arc-length as the unique unit-speed parameter on a regular curve. By the end of the proof, arc-length is confirmed to be the unit-speed parameter. However, I don't really understand its uniqueness as a unit-speed parameter.",['differential-geometry']
4735353,Product of distances from a point on the circle to equidistant points on the circle,"Question (IIT 2023) : Let $A_i\ (1 \le i \le 8)$ be the vertices of the regular octagon that lie on the circle of radius $2$ . Let $P$ be a point on the circle and let $|PA_i|$ denote the distance between the point $P$ and $A_i$ for $1\le i\le 8$ . If $P$ varies over the circle, then the maximum value of the product is $\prod_{i=1}^{8}|PA_i|$ , is: My Solution : As all the points are of a octagon they are equally aligned at $\dfrac{\pi}{4}$ with each other and taking point $P$ to be at an angle of $\theta$ with the $x$ -axis we can rewrite the product as : $$\prod_{i=1}^{8} 4\sin\left(\frac{i\pi}{8}+\frac{\theta}{2}\right)$$ which can be further simplified into $2^9\sin(4\theta)$ which gives us our answer $2^9$ at $\theta = \dfrac{\pi}{8}$ . Now there's another solution floating around online which relies on complex numbers and is quite shorter and it goes as following : what I am not getting here is how does maximizing the product of the roots of $z^8-2^8=0$ produces the same result as asked in the question, as maximizing the roots of $z^8-2^8$ should give the value of product of the distances if $P$ were to be taken at center of circle. Is there any relation between my solution and the other which verifies this...","['trigonometric-series', 'algebra-precalculus', 'trigonometry', 'complex-numbers']"
4735361,"Given a matrix $A$ and vector $x$, is it possible to find the permutation of $x$ that minimizes $\lVert APx \rVert$?","Let $A$ be some $n\times n$ matrix, and $x$ be a column vector of length $n$ . I am looking to find the permutation matrix $P$ of size $n\times n$ that minimizes the vector norm of $APx$ . There are $n!$ such permutation matrices, so to exhaustively search for the minimizing $P$ quickly becomes intractable. I'm wondering if it is possible to show analytically what this $P$ should be, but am having trouble proceeding on this question. Any help or leads would be much appreciated! EDIT: While interested in the general case, which seems to be NP-complete, I would be happy to hear if there are special results concerning the special case that $A = QQ^\dagger-I$ , where $Q^\dagger$ is the Moore-Penrose inverse of $Q$ .","['permutations', 'optimization', 'least-squares', 'linear-algebra']"
4735374,Simple functional equation: $f(x)=f(y) \implies f(ax)=f(ay)$,"Let $a$ be real number and variable $x,y\in\mathbb R^n$ . Solve for all continuous function $f$ such that it is ""proportional-invariance"": $f(x)=f(y)\implies f(ax)=f(ay)$ for all $a$ . Let's start at one dimension. For $n=1$ , it is straightforward strict monotonic function or constant are solutions. Edit: power-like functions are also solutions. I have no idea how to deal with it when $n=2$ , besides requiring that $f$ is also monotonic in both directions. Can anyone give me a hint for the simple case when $n=2$ and $a$ is positive? Example: $f(x_1,x_2)=g(x_1+x_2)$ and $g$ is monotonic. Edit: after reading the answers, my guessed solution is $f(x)=|x|g(\frac{x}{|x|})$","['functional-equations', 'functional-analysis', 'real-analysis']"
4735398,Is the degree of a differential equation of any use?,"When it is written as a polynomial equation in the unknown function and its derivatives, its degree of the differential equation is, depending on the context, the polynomial degree in the highest derivative of the unknown function, or its total degree in the unknown function and its derivatives. - Wiki Now this definition means that one is allowed to manipulate the given DE to a polynomial form to determine the degree. This is what is also taught in most schools. However, this allows many absurd manipulations and contradicting answers. For example, consider $$y'=x\;\;\;\;,\;\;\; y'^3=x^3$$ Both equations are equivalent and satisfy the polynomial definition, but have different degrees. This led to many claiming $^{\dagger}$ that the degree must be determined in the purest, given form, with no form of simplification, which goes against the original definition of possible polynomial manipulation. Some answers on this site tell me that most modern texts do not talk about the degree at all $^{\dagger\dagger}$ . This makes me think that degree is just a useless concept that offers no insight into the solution of the DE itself, at the same time being so ill-defined, unlike the order which offers information on the number of constants. Is my conclusion right, or, is there actually any valuable insight that the degree provides? $^{\dagger}$ Order and degree of a differential equation Differential equation degree doubt How to find degree of a differential equation. $^{\dagger\dagger}$ https://math.stackexchange.com/a/2446912/734160","['calculus', 'soft-question', 'ordinary-differential-equations']"
4735418,"If n distinct objects are distributed randomly into n distinct boxes, what is the probability that exactly two boxes are empty?","My approach: There are two configurations possible: $$
0031111... \tag{1}
$$ $$
0022111... \tag{2}
$$ Where the numbers represent the number of objects in the each box for n boxes. Step $1$ : Choose the empty boxes $$
\binom{n}{2}
$$ Step $2$ : We solve for case $(1)$ Step $2.a$ : Choose the box where $3$ distinct items will go: $$
\binom{n-2}{1}
$$ Step $2.b$ : Now, we have a sequence of assignments of the objects to their corresponding boxes. We permutate them: $$
\frac{n!}{3!}
$$ Step $3$ : We solve for case $(2)$ Step $3.a$ : Choose the $2$ distinct boxes which will have $2$ distinct objects each: $$
\binom{n-2}{2}
$$ Step $3.b$ : Now, we have a sequence of assignments of the objects to their corresponding boxes. We permutate them: $$
\frac{n!}{2!2!}
$$ Final answer: $$
\binom{n}{2}\left( \binom{n-2}{1}\frac{n!}{3!} + \binom{n-2}{2}\frac{n!}{2!2!} \right)
$$ I am highly doubtful of this approach. Especially Steps $2.b$ and $3.b$ . For getting the probability we divide the answer by: $n^n$",['combinatorics']
4735435,Assuming two functions are the same [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 12 months ago . Improve this question If we know the following: $$\int_a^b f(x) \,dx= k$$ and: $$\int_a^b g(x) \,dx= k$$ Can we deduce that $f(x) = g(x)$ ? If not, could someone find me an example where the above is the case and $f(x)$ does not equal $g(x)$ ?
Thanks in advance.",['integration']
4735460,"Why does the function $e^{ix}$ have a real part, without using the Euler's formula","I would like to intuitively understand why $e^{ix}$ has a real part, if the the function $e^{ix}$ has an imaginary argument. I know that $$e^{ix}=\cos x + i\sin x$$ and I don't need convincing that it is so. I understand how $e^{ix}$ behaves when I rewrite it in the sine/cosine form and that this function can be visualized/illustrated by a circle in complex plane. I also understand how it is derived from Maclaurin series, but it doesn't shed any light on this issue - I see it as ""mindless"" proof. I struggle to intuitively grasp why this function can even have a real part, when the argument is purely imaginary. Since this function is also periodic, I also don't understand why it even ""falls down"" at any point, when $e^x$ does not even have a single stationary point. I assume that it follows from the fact that $i^n$ is periodic, which I comfortably understand, but I can't see how multiplying imaginary number by a real number in an exponent has the same effect. Side note for context: I am a soon-to-be third semester physics student, in which I am going to have a course on optics, which heavily relies on Euler's formula.","['intuition', 'exponentiation', 'functions', 'complex-numbers']"
4735466,Prove $ \lg (n + 1) - 1\le h \le \lg n\implies h=\lfloor\lg n\rfloor$,"For integer $n>0$ and integer $h$ prove ( $lg$ means $log_2$ ) $$
\lg (n + 1) - 1\le h \le \lg n\implies h=\lfloor\lg n\rfloor
$$ I'm thinking I may use $x-1<\lfloor x \rfloor \le x \le \lceil x \rceil<x+1$ , but it seems like I cannot because we have $\lg (n + 1) - 1$ instead of $\lg n - 1$ . I tried some values and this seems true, the only integral solution in $[\lg (n + 1) - 1,\lg n]$ indeed seems to be $\lfloor\lg n\rfloor$ n =1 [0,0]
n =2 [0.584963,1]
n =3 [1,1.58496]
n =4 [1.32193,2]
n =5 [1.58496,2.32193]
n =6 [1.80735,2.58496] The background (which I think is irrelevant to this question) is that I'm trying to answer Show that an n-element heap has height $\lfloor\lg n\rfloor$ [1] because for heap (similar to a complete binary tree in terms of tree shape), every level (from $0,...,h-1$ ) except the last one (level $h$ ) must be full. Heap of height $h$ must contain a min of $2^h$ and a max of $2^{h+1}-1$ elements. This gives $2^h\le n \le 2^{h+1}-1$ and upon solving I obtained the above inequality. [1] Introduction to Algorithms, Fourth Edition. MIT press.","['trees', 'analysis', 'discrete-mathematics', 'inequality', 'computer-science']"
4735500,"$G$ finite metabelian group, $P$ a Sylow $p$-subgroup. Show that $P'$ is abelian and normal in $G$","Let $G$ be a finite metabelian group and let $P$ be a Sylow $p$ -subgroup of $G$ . I have to observe that the derived subgroup $P'$ is abelian and normal in $G$ . Since $G'$ is abelian, the subgroup $P' \leq G'$ is abelian too, and it's normal in $G'$ . How can I obtain the normality in the entire $G$ ?","['finite-groups', 'derived-subgroup', 'normal-subgroups', 'sylow-theory', 'group-theory']"
4735506,When/What are we allowed to do to identities?,"Starting with $(x+1)^2 = x^2 + 2x+1$ we can find new identities by substituting. However if I sub $x=2x^2 - 5$ into the equation, giving $(x+1)^2 = (2x^2 -5)^2 +2x +1%$ I get a true statement which holds for all $x$ such that $x + 5 - 2x^2 = 0$ just as my substitution said. However as you can see I only substituted for one of the $x$ in the equation (in particular the one being squared), am I allowed to choose which parts of the identity I want to substitute for, or do I have to substitute for all the $x$ in the identity? (Making what I did forbidden).
Thanks in advance.",['algebra-precalculus']
4735601,"Knowing the sum, can I solve a finite exponential series for r? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 10 months ago . Improve this question I know a geometric expression can be written down as: $$
\sum_{k=1}^{n} ar^{k-1} = \frac{a(1-r^n)}{1-r}
$$ Is it possible to solve this for r, knowing the total sum? (how about if you know the last value in the sequence instead of the first? - to me intuitively this would just result in r becoming 1/r)",['sequences-and-series']
4735629,Proving that $f(x)$ satisfying $2f(x)f(1)\leq f(x)f(1)+1\leq 2f(2x)$ for all $x>0$ is a constant function,"How do I prove the following, where $f:[0,\infty)\to[0,\infty)$ : For $x>0$ if $f(x)$ satisfies $$2f(x)f(1)\leq f(x)f(1)+1\leq 2f(2x)$$ then $f(x)$ is a constant function. I have out found out that when $f(x)=1$ this inequality is satisfied So I tried to prove by contradictory by supposing  where when there exists $a$ that satisfies $f(a)>1$ or when satisfies $0<f(a)<1$ , but I failed.","['contest-math', 'analysis', 'real-analysis', 'functions', 'inequality']"
4735663,"For $ \{n\pmod{2 \pi}: n \in \{\ 0, 1, 2 ... 2^x\ \} \} $, is it possible to put a bound in terms of $x$ on the smallest difference between elements?","Is it possible to put some sort of bounds on the smallest difference between elements for a limited range of integers $\mod 2\pi$ ? $$ A =\bigl\{n\pmod{2\pi} : n \in \{\ 0, 1, 2, ... 2^x\ \} \bigl\} $$ (or similarly $ A = \bigl\{n\cdot \frac{1}{2\pi} \bmod 1 : n \in \{\ 0, 1, 2, ... 2^x\ \}\} $ ) Where the smallest difference is defined as: $$d_{min} = \min(\ \{\ |a - b|\ :\ a,b\in \ A,\  a \ne b\}\ )$$ Can I show that some sort of bounds exist for $d_{min}$ such as (intuitively/pessimistically via Dirichlet approximation theorem): $$ 2^{-2x} < d_{min} < 2^{-x} $$ If not, what are the tightest bounds we can place on $d_{min}$ ? I'm comfortable with the answer here that shows $\{n\pmod{2 \pi}: n\in\Bbb N\}$ is dense in $[0,{2 \pi}]$ since $\pi$ is irrational, but the proof depends on arbitrarily large $n$ . In my concrete (software) case, I need to represent 44-bit integers as an angle in radians i.e. $(x=44)$ , and would like to know the smallest number of fixed point precision bits that would be needed to uniquely represent these values $\pmod{2 \pi}$ to ensure no collisions. It's easy to show that some of the smallest distances where $ b = 0$ are likely to occur for values of $a$ that are numerators in convergents of continued fraction approximations  of $2\pi$ , e.g. for: $$a = 44 ,\  b = 0,\ \ (2\pi \approx \frac{2\times22}{7})$$ or $$a = 710,\  b = 0,\ \ (2\pi \approx \frac{2\times355}{113})$$ or even the semiconvergents - the sum of numerators/denominators such that the denominator becomes even, e.g. $$a = 377,\  b = 0, \ \ (2\pi \approx \frac{355+22}{\frac{113+7}{2}})$$ So one might suppose that the smallest distances occur with numerators of the most accurate continued fraction approximations of $2\pi$ , but pairs like $$a = 103993, \ b = 0, \ \ (2\pi \approx \frac{103993}{\frac{33102}{2}}) $$ (ostensibly $\pi$ accurate to 9.2 decimal places) produce smaller gaps than the next (more accurate) approximation of $\pi$ (9.5 decimal places) $$a = 208696,\  b = 0, \ \ (2\pi \approx \frac{2\times104348}{33215}  \approx \frac{208341 + 355}{\frac{66317 + 113}{2}})$$ (This is probably because the smaller numerator already has an even denominator, so there's no need to double the numerator, and thus double the error). Edit: as Eric points out in his answer below, I should be looking at convergents of $2\pi$ directly, since I was using double the convergents of $\pi$ , the above musing can be ignored For the $b = 0$ case, is it sufficient to only look at numerators of convergents/semiconvergents which have an even denominator? Would another approach to this be better? Edit, having thought about it a bit more: If distance is defined $$ d(m, n) = | (m\pmod{2\pi}) - (n\pmod{2\pi}) |\ \ \text{for}\ m,n \in \Bbb{N}$$ I think we can say that the distance $d(a + b, b) = d(a,0)$ for $b \in \Bbb N$ , so all the minima from $a$ being a convergent numerator where $n = 0$ will be trivially replicated at $ m = a+b $ for $n = b$ . The same applies for $d(a, b - a) = d(0,b)$ for $a \in \Bbb N$ , and due to the symmetry of $a$ and $b$ , this allows the reduction of any pair of values into a single measure of accuracy of an approximation of $2\pi$ . Could there be other minima where $ n > 0 $ that don't correspond to a trivial $ m = a+b $ case, i.e. could there be a $b$ such that $d(a, b) < d(a,0)$ ? I think all members of $A$ must be positive, and so finding a smaller minimum where $b > 0$ is a matter of looking for $n$ such that $n\pmod{2\pi}$ is as close as possible to but not equal to $ m\pmod{2\pi}$ . In the case where $$n\pmod{2\pi} < m\pmod{2\pi}$$ this is effectively trying to find a tighter approximation of ${2\pi}$ , and can likely only happen with a ""better"" continued fraction convergent numerator. In the case of $$(m\ \text{mod}\ {2\pi}) < (n\ \text{mod}\ {2\pi}) < 2(m\ \text{mod}\ {2\pi}) $$ due to the symmetry in the definition of distance, $m$ and $n$ can be swapped, and the problem again becomes one of trying to find a  ""better"" continued fraction convergent numerator. The relationship for a convergent $ \frac{p}{q}$ is: $$p\pmod{2\pi} = (2\pi - \frac{p}{q})\times q$$ Via the mediant inequality, I think we can always find a midpoint between 2 convergents by adding the numerators together (and denominators), and I think this applies whether the 2 convergents are overestimates or underestimates... If you have one overestimate and one underestimate, then the new estimate for $2\pi$ becomes better than either. $$\frac{p}{q} < \frac{p+a}{q+b} < \frac{a}{b}$$ It follows that you can do this an arbitrary number of times to get successively closer distances between pairs of convergents, but how quickly does that grow the $d_{min}$ ? This implies a sort of fractal scale which evenly distributes integer values across $[0,2\pi]$ at a granularity roughly the ""scale"" of the preceding convergent numerator, then as soon as the next convergent numerator is reached, the scale gets smaller, and so on, so the $d_{min}$ for any number $n$ can never be smaller than the value of the largest convergent numerator smaller than n $\pmod{2\pi}$ . So my question rearranges to $$\log(p\pmod{2\pi}) = \log(\lvert2\pi - \frac{p}{q}\rvert) + \log(q)$$ Which is almost the same question as this Does that mean $2^{−(x+\epsilon)}$ is enough, where $\epsilon$ is how much better the convergent is than the size of the denominator (the negation of the right hand term above)? If so, does that mean for $\mu(\pi) =2$ that $\epsilon \leq x$ ?","['continued-fractions', 'integers', 'diophantine-approximation', 'real-analysis']"
4735687,"2022 MIT Integration Bee, Qualifying Round, Question 17","I attempted the following integral from the 2022 MIT Integration Bee Qualifying Round: $$\int\frac{1}{1+\sin x} + \frac{1}{1+\cos x}+ \frac{1}{1+\tan x} + \frac{1}{1+\cot x} + \frac{1}{1+\sec x} + \frac{1}{1+\csc x}dx$$ $$\int\frac{1-\sin x}{\cos^2 x} + \frac{1-\cos x}{\sin^2 x} + \frac{\cos x}{\cos x + \sin x} + \frac{\sin x}{\cos x + \sin x} + \frac{\cos x}{\cos x + 1} + \frac{\sin x}{\sin x + 1}dx$$ $$x\,+\,\int(\sec^2 x -\sec x\tan x)\,+\,(\csc^2 x - \csc x\cot x)dx + \int\frac{\cos x(1 - \cos x)}{\sin^2 x}+ \frac{\sin x(1 - \sin x)}{\cos^2 x}dx $$ $$x\,+\,\tan x - \sec x - \cot x + \csc x + \int\cot x\csc x-\cot^2 x + \tan x\sec x-\tan^2 x dx $$ $$x\,+\, \tan x - \sec x - \cot x + \csc x-\csc x+\sec x - \tan x + x + \cot x + x = \fbox{3x} $$ This is the correct answer, but I have been trying to find a shorter way to compute this integral. Is there maybe a way to combine some of the terms in the original integral to make it shorter, or this essentially the best way to do it? Thank you.","['integration', 'indefinite-integrals']"
4735740,"Non-isomorphic groups which are ""quasi-isomorphic"".","This is a follow up question of this topic . Most of the following recap stems from the valuable answer therein. Let $G,\overline G$ be groups, and $f\colon G\to\overline G$ a bijection. With reference to the following diagram: $$\begin{array}{c}
G & \stackrel{f}{\longrightarrow} & \overline G \\
\downarrow{\mathfrak c} & & \downarrow{\mathfrak{\overline c}} \\
\operatorname{Sym}(G) & \stackrel{\psi_f}{\longleftarrow} & \operatorname{Sym}(\overline G)  
\end{array}
$$ where $\mathfrak c$ and $\overline{\mathfrak c}$ are Cayley's embeddings and $\psi_f\colon\operatorname{Sym}(\overline G)\to\operatorname{Sym}(G)$ is defined by $\sigma\mapsto f^{-1}\sigma f$ , the following results hold true: \begin{alignat}{1}
&1)\space\forall g,h\in G: &&f(gh) = f(g)f(h) &&&\iff \mathfrak c=\psi_f\bar{\mathfrak c}f \\
&2)\space\exists\bar k\in\overline G,\forall g,h\in G: \space&&f(gh) = f(g)\bar kf(h) &&&\iff \operatorname{im}(\mathfrak c)=\operatorname{im}(\psi_f\bar{\mathfrak c}f) \\
\end{alignat} Both $1)$ and $2)$ define an equivalence relation in the set of all the groups of a given cardinal; in fact, the inverse $f^{-1}$ is still a map fulfilling $1)$ or $2)$ . The equivalence classes are made of pariwise isomorphic groups, in case $1)$ , and pairwise ""quasi-isomorphic"" (my definition) groups, in case $2)$ . While as usual $G\cong\overline G$ denotes an isomorphism, let $G\approx\overline G$ denote a quasi-isomorphism. Since $2)$ boils down to $1)$ for the special case $\bar k=1_\overline G$ , isomorphic groups are also quasi-isomorphic, but not necessarily viceversa: there might well be non-isomorphic groups which nonetheless  turn out to be quasi-isomorphic . So, a quasi-isomorphism looks like an ""isomorphism in a broader sense"", though not to the point of equalling ("" $\approx$ "") an abelian with a nonabelian group; in fact: \begin{alignat}{1}
&(G\text{ abelian)}\wedge(f\text{ quasi-isomorphism)} &&\iff \\
&\exists\bar k\in\overline G,\forall g,h \in G: f(g)\bar kf(h)=f(h)\bar kf(g) &&\iff \\
&\exists\bar k\in\overline G,\forall \bar g,\bar h \in \overline G: \bar g\bar k\bar h=\bar h\bar k\bar g &&\iff \\
&\overline G\text{ is abelian} \\
\end{alignat} (for the last "" $\iff$ "", see e.g. here ). As a first (minimal) test, does $C_4\stackrel{f}{\approx} K_4$ ? The answer is no, because, once set $C_4=\langle x\rangle$ and $f\colon C_4\to K_4$ the candidate quasi-isomorphism, we get: $f(x^2)=$ $\bar kf(x)^2=$ $\bar k$ , whence $f(x^3)=$ $\bar kf(x^2)f(x)=$ $\bar k^2f(x)=$ $f(x)$ , a contradiction because $x^3\ne x$ . Question . I'm looking for a pair of (possibly low order) non-isomorphic groups (necessarily both abelian or both nonabelian), which are quasi-isomorphic. Edit . with reference to the following diagram: $$\begin{array}{c}
\overline G & \stackrel{f'}{\longleftarrow} & G & \stackrel{f}{\longrightarrow} & \overline G \\
\downarrow{\mathfrak{\overline c}} & & \downarrow{\mathfrak c} & & \downarrow{\mathfrak{\overline c}} \\
\operatorname{Sym}(\overline G) & \stackrel{\psi_{f'}}{\longrightarrow} & \operatorname{Sym}(G) & \stackrel{\psi_f}{\longleftarrow} & \operatorname{Sym}(\overline G)  
\end{array}
$$ the result in the answer can be written as: $$\operatorname{im}(\mathfrak c)=\operatorname{im}(\psi_f\bar{\mathfrak c}f)\Longrightarrow \mathfrak c=\psi_{f'}\bar{\mathfrak c}f'$$ where $f'(g):=f(1_G)^{-1}f(g)$ . Edit #2 . For $\overline G=$ $(\mathbb R,+)$ , such ""quasi-isomorphism"" seems instead to match the definition of quasi-morphism mentioned in the answer, with defect equal to $|f(1_G)|$ .","['group-theory', 'group-isomorphism']"
4735759,How does $\frac{2\sqrt{7}}{3}\cos\left (\frac13\arccos\frac{1}{2\sqrt{7}}\right)+\frac23$ simplify to $1+2\cos\frac{2\pi}{7}$?,"$$\frac{2\sqrt{7}}{3}\cos\left (\frac{1}{3}\arccos\left (\frac{1}{2\sqrt{7}}  \right )  \right )+\frac{2}{3}$$ This is actually a solution for $x^3-2x^2-x+1$ , and I tried to solve and got that solution. And I have found this simplified solution $$1+2\cos\left(\frac{2\pi}{7}\right)$$ on the internet. However, I do not know how to even start to simplify it. Any help what are the steps for that simplification?","['trigonometry', 'polynomials']"
4735767,"Let $f : D → D$ be analytic with $f(0) = f''(0) = 0, f'''(0) = 1$. Prove $\exists r$ independent of $f$ where $B_r(0)\subset f(D)$.","Let $D$ be the unit disc centered at the origin. Assume $f : D → D$ is analytic with $f(0) = f''(0) = 0,$ and $f'''(0) = 1$ . Prove $\exists r$ independent of $f$ where $B_r(0)\subset f(D)$ . I'm completely lost on what to do here - the idea I initially started with was to use Schwarz's Lemma, which led me to the conclusion that $f(z) = \alpha z^3/6$ for some $|\alpha|<1$ . I don't feel particularly confident about this, though. Any ideas would be greatly appreciated. Edit: An attempted solution by another member of this site, which has since been deleted, tried using Schwarz Lemma on $g(z)=f(z)/z^2$ , which is only analytic if $f'(0)=0$ as well.  However, this is unfortunately not an assumption we are allowed to make. So, this either needs to be proven or a different method is needed.",['complex-analysis']
4735780,How can I transform a point on a square to a point on a circle?,"Given a unit square of bounds (-1, -1), (-1, 1), (1, 1), (1, -1) how can I find a point on a circle of radius 1 inside the square such that each increment on the square represent an evenly spaced incremented point on the circle. I tried the following equation but it only covers 180 degrees and I can't figure out how to extend it to a full 360 degrees. Also bonus if you can explain how to convert in reverse from circle to square: float2 SquareToCircle(float2 vertex)
{
    float bound = max(abs(vertex.x), abs(vertex.y));
    float theta = (vertex.x + bound + vertex.y + bound) * PI / 4;
    vertex.x = sin(theta) * bound;
    vertex.y = cos(theta) * bound;
    return vertex;
} When extended out to 3 dimensions, this is the result of my formula. It doesn't handle the right and left side coords very well:",['trigonometry']
4735786,"How to integrate $\int_{0}^{1}g'(x)f(g(x),x)dx$","I know how to integrate $$\int_{0}^{1}g'(x)f(g(x))dx$$ for $g$ differentiable, I just need to take $s = g(x)$ and then I find $$\int_{g(0)}^{g(1)}f(s)ds$$ But what happens when $f$ depends explicitely on $x$ , i.e. how to do the integration for $$ \int_{0}^{1} g'(x)f(g(x),x)dx$$ For now, my only idea is to write this integral as $$ \int_{0}^{1}(g'(x), 1). (f(g(x),x),0)dx $$ so that I have $(g(x),x)'$ . But it does not seem to work ...","['integration', 'contour-integration', 'analysis']"
4735805,Is every measurable function the conditional expectation of some random variable?,"Let $X$ and $Y$ be two random variables defined on the same probability space $(\Omega,\mathcal F,\mathbb P) $ and taking value respectively in $\mathcal X:=[0,1]^d$ and $\mathcal Y:=\{-1,+1\}$ . Denote by $\rho $ the joint law of $(X,Y) $ . Because the conditional expectation $\mathbb E_{(X,Y)\sim\rho}[Y\mid X] $ exists, we can consider the map $\varphi : x\in[0,1]^d \mapsto \mathbb E_{(X,Y)\sim\rho}[Y\mid X=x]$ which is measurable and $[-1,1]$ -valued. My question concerns the converse statement : given a measurable map $\eta:[0,1]^d\to[-1,1]$ , when does there exist a distribution $\varrho $ on $\mathcal X\times\mathcal Y $ such that $\eta(x) = \mathbb E_{(X',Y')\sim\varrho}[Y'\mid X'=x] $ ? And when it does exist, can it be expressed ""explicitly"" in terms of $\eta$ ?","['conditional-expectation', 'measure-theory', 'probability-theory']"
4735811,Does there exist a functional definition for a sequential limit? [duplicate],"This question already has answers here : Is there a ""functional"" definition of a limit? (2 answers) Closed 11 months ago . Consider the sequence $a_n$ . We say that $\lim a_n = c$ if for every $\epsilon > 0$ , there exists a natural number $N$ such that, if $n \geq N$ , then $|a_n - c| < \epsilon$ . This definition suggests that $N$ will always be a function of $\epsilon$ , including a constant function (in which case $N$ is independent of $\epsilon$ ). Therefore, I'm wondering if we can instead define the limit $\lim a_n = c$ as follows: We say that $\lim a_n = c$ if there exists a function $N : (0,\infty) \to \mathbb N$ such that if $|a_n - c| \geq \epsilon$ , then $n < N(\epsilon)$ . This definition does not seem that useful (and is likely missing some conditions), so I'm wondering if a better one can be constructed.",['limits']
4735817,"Subset $B$ of $S\subseteq\mathbb{N}^+$ such that no two elements in $B$ add up to another element in $B$, and $|B|\ge \frac 13 |S|$.","Given a set $S\subseteq\mathbb{N}+$ with a finite number of elements, show that one can always choose a set $B\subseteq S$ such that for all $x, y, z\in B$ (not necessarily distinct), $x+y\neq z$ and $|B|\ge \frac 13|S|$ . So far, I have found that if $S$ is the set of the first $n$ positive integers, the result is true because one can take all the elements that are $1\pmod 3$ , and the sum of two of them will never equal to another element. The sum of two elements will always be $2\pmod 3$ , which no element in this subset is. However, I am having trouble generalizing this to all sets. Thanks in advance!!","['elementary-set-theory', 'elementary-number-theory', 'algebra-precalculus']"
4735901,Total number of squares possible on $n\times n$ square dots,"For total  number of squares possible on $n\times n$ square dots, I know the formula is $$\frac{n^2(n^2-1)}{12}
$$ But this is only works for the squares formed by lines which join the the $n\times n$ dots. For example Here the squares formed by the intersection of lines are not considered. Here the squares $L_1g_5e_4h_5$ , $g_5J_1j_5e_4$ , $e_4j_5B_1i_5$ , $h_5e_4i_5N_1$ are not counted. If we connect all lines it will look something like this. More squares will emerge here. I looked for total possible numbers of lines and dots here 1 2 . But I could not proceed any further. I was wondering if there is some general formula for finding all possible number of squares if we consider all the squares which are formed by intersection of lines on $n\times n$ dots i.e all possible number of squares formed by all the points. I am also hoping for something similar for total number of triangles. Edit: To be more precise I want all these squares to be counted in $3 \times 3 $ dots grid, But the aforesaid formula only considers these squares, For $4 \times 4$ dots grids, I made this manually, so I might have missed some squares.","['combinations', 'combinatorics']"
4735939,A set of algebra homomorphisms from the real sequence space,"I was myself wondering the following question. Consider the sequence space $\mathbb{R}^{\mathbb{N}}$ , that is $\mathbb{R}^{\mathbb{N}} := \{ (x_{k})_{k=1}^{\infty} \; | \; x_{k} \in \mathbb{R} \}$ . It has a structure of a (real) commutative associative algebra with the unit, with the multiplication given by $(x_{k})_{k=1}^{\infty} \cdot (y_{k})_{k=1}^{\infty} = (x_{k} \cdot y_{k})_{k=1}^{\infty}$ . Equivalently, $\mathbb{R}^{\mathbb{N}}$ is a direct product algebra $\prod_{k=1}^{\infty}\mathbb{R}$ or an algebra of maps $f: \mathbb{N} \rightarrow \mathbb{R}$ . Question : I am interested in the set of all algebra homomorphisms (preserving the unit) from $\mathbb{R}^{\mathbb{N}}$ to the algebra $\mathbb{R}$ . I have the following remarks/observations: This set certainly contains all projections $\pi_{j}(x_{k})_{k=1}^{\infty} = x_{j}$ , so this set has to be at least as big as $\mathbb{N}$ . If one replaces $\mathbb{R}$ with $\mathbb{Z}$ , it contains only these projections. This is a well-known statement, see e.g. What are the ring homomorphisms $\mathbb{Z}^\mathbb{N} \to \mathbb{Z}$? . This means that in this case, the set in question is precisely $\mathbb{N}$ . In the same question they claim that the result holds for any ring $R$ which is UFD with at least two distinct prime elements. But $\mathbb{R}$ has no prime elements. Any homomorphism $f: \mathbb{R}^{\mathbb{N}} \rightarrow \mathbb{R}$ must act as a scalar multiple of a projection $\pi_{j}$ on sequences with finitely many non-zero elements. This is easy to see - if $\mathbf{e}_{a}$ is the sequence with $1$ on the $a$ -th place and zeros everywhere else, one can show that $f(\mathbf{e}_{a}) \neq 0$ only for a single $a \in \mathbb{N}$ , which follows from the equation $f(\mathbf{e}_{a} \cdot \mathbf{e}_{b}) = f(\mathbf{e}_{a}) \cdot f(\mathbf{e}_{b})$ and the fact that $\mathbf{e}_{a} \cdot \mathbf{e}_{b} = 0$ for $a \neq b$ . Hence $f(x)_{k=1}^{n} = \lambda x_{a}$ for some $a \in \mathbb{N}$ and $\lambda \in \mathbb{R}$ for any sequence $(x_{k})_{k=1}^{n}$ with finitely many non-zero elements. However, one cannot repeat the argument from the reference in 2. to show that $f$ acts in this way on any sequence. Clearly, the set in question is a subset of the dual space $(\mathbb{R}^{\mathbb{N}})^{\ast}$ . Since $\mathbb{R}^{\mathbb{N}} = (\mathbb{R}^{\infty})^{\ast}$ , where $\mathbb{R}^{\infty}$ is a set of all sequences with finitely many non-zero terms (that is $\mathbb{R}^{\infty} = \bigoplus_{k=1}^{\infty} \mathbb{R}$ ), we are looking for a subset of the double dual $(\mathbb{R}^{\infty})^{\ast \ast}$ which is supposedly an ugly space. It known that $\mathbb{R}^{\infty}$ embeds as a proper subspace into $(\mathbb{R}^{\infty})^{\ast \ast}$ . Is there some explicit or useful description (or at least some nice examples) of elements of the double dual (that is of $(\mathbb{R}^{\mathbb{N}})^{\ast}$ ) which are not in this subspace? I was thinking that maybe some of these examples would be also an algebra homomorphism, proving that the set of all homomorphisms from $\mathbb{R}^{\mathbb{N}}$ to $\mathbb{R}$ is strictly bigger then $\mathbb{N}$ . Bonus Question: Instead of $\mathbb{N}$ , I would like to know the result for general set $M$ , that is consider a direct product algebra $\prod_{m \in M} \mathbb{R}$ , or equivalently the algebra of all functions $f: M \rightarrow \mathbb{R}$ , and ask the same question - what is the set of all homomorphisms from this algebra to $\mathbb{R}$ ? It is easy to show that for a finite $M$ , it is isomorphic to $M$ . Is there some answer for a general $M$ ?","['abstract-algebra', 'linear-algebra']"
4735974,How to maximize $\min_k a_k$ under constraints $\sum_k a_k=A$ and $\sum_k a_k^2=B$?,"Suppose I want to find the tuple of positive real numbers $a_k>0$ that maximize the cost $\min_k a_k$ , under the constraints $\sum_k a_k=A$ and $\sum_k a_k^2=B$ , for some given $A,B>0$ . Assume $k=1,...,n$ for some $n$ . Normally, for this kind of problem, I'd use Lagrange multipliers, defining the Lagrangian $$L = \min_k a_k + \alpha \left(\sum_k a_k-A\right) + \beta \left(\sum_k a_k^2-B\right),$$ and working out the conditions that come out imposing $\nabla L=0$ . However, in this case, the $\min$ function defining the cost has a discontinuous derivative, which makes me unsure as to how to proceed. For concreteness and better clarity, let's work out the $n=2$ case. The problem is here to find the max of $\min(a_1,a_2)$ under the given constraints. I'd then write the Lagrangian function $$L = \min(a_1,a_2) + \alpha \left(\sum_{k=1}^2 a_k-A\right) + \beta \left(\sum_{k=1}^2 a_k^2-B\right) .$$ From this, imposing $\partial_{a_k}L=0$ , we'd get the conditions $1+\alpha+2\beta a_1=0$ and $\alpha+2\beta a_2=0$ , which can be solved for $\alpha,\beta$ . But in this simple case, the constraints also directly impose the conditions $a_1+a_2=A$ and $a_1^2+a_2^2=B$ , which can be directly solved to give $$a_1^\pm = \frac{A}{2} \pm \frac12\sqrt{2B-A^2}, \qquad a_2 = A- a_1.$$ It's not hard to see from basic arithmetic considerations that $2B-A^2\ge0$ , and thus $0\le a_1^-,a_2^- \le A/2$ .
Thus we can always write $\min(a_1,a_2) = \frac A2 - \frac12\sqrt{2B-A^2}$ , and that's the final answer, as here there's no room for further optimisation (and introducing the Lagrangian is effectively useless). Let's try to tackle the slightly less boring case with $n=3$ . Now the constraints don't automatically determine $a_1,a_2,a_3$ . If I try to work out the problem with the simplified Lagrangian $$L=a_1 + \alpha \left(\sum_{k=1}^3 a_k-A\right) + \beta \left(\sum_{k=1}^3 a_k^2-B\right),$$ imposing vanishing gradient I get the three conditions $$\begin{cases}1+ \alpha + 2\beta a_1=0, \\
\alpha + 2\beta a_2 =0, \\
\alpha + 2\beta a_3 =0,\end{cases}$$ which imply $\beta(a_2-a_3)=0$ and $2\beta(a_3-a_1)=2\beta(a_2-a_1)=0$ . Thus we must have $\beta\neq0$ , which in turn implies $a_2=a_3$ , and we go back to a situation where the constraints determine $a_1$ , now via $a_1+2a_2=A$ and $a_1^2+2a_2^2=B$ , which give $$a_1^\pm = \frac{A}{3} \pm \frac{\sqrt2}{3}\sqrt{3B-A^2}.$$ This is more or less where I hit the problem: I'm tempted to say that, by symmetry, this tells me the stationary points for each individual variable $a_1,a_2,a_3$ . But what I actually want is the stationary points (and in particular the max) for their min, and I'm not sure how to convert from one problem into the other using a relatively ""elegant"" argument (that is to say, possibly without having to work out a plethora of subcases to get there). Furthermore, I think the solutions obtained imposing $\nabla L=0$ (with the $L$ using $\min a_k$ as cost function) only tell me the local stationary points in regions where the cost is smooth (or at least is differentiable), so all regions corresponding to some $a_j=a_k$ are probably left out.","['nonlinear-optimization', 'lagrange-multiplier', 'maxima-minima', 'optimization', 'algebra-precalculus']"
4736002,Question about equality of sets in a relation,"I have come up with the following conjecture which I am trying to prove: Let $A$ and $B$ be sets such that $|A|=|B|= 3$ if $R$ is a relation from A to B where $|R|=9$ and $R^{-1}=R$ then $A=B$ . The following is my attempt at a proof: Proof: Since $|R|=9$ , $|A \times B|=|A||B| = 3\cdot3 = 9 $ and since $R \subseteq A\times B$ , $R = A \times B$ . First we show that $A \subseteq B$ . Let $x \in A$ . If $(x, y) \in R$ for some $y \in B$ , as $R = R^{-1}$ , $(x, y) \in R^{-1}$ and so it follows that $(y, x) \in R$ . Since $R = A \times B$ , we have that $x \in B$ , and as x was arbitrary $A \subseteq B$ . Next we show that $B \subseteq A$ . Let $y \in B$ . If $(x, y) \in R$ for some $x \in A$ , as $R = R^{-1}$ , $(x, y) \in R^{-1}$ and so it follows that $(y, x) \in R$ . Since $R = A \times B$ , it follows that $y \in A$ , hence as y was arbitrary $B \subseteq A$ . Since $A \subseteq B$ and $B \subseteq A$ , $A = B\space\space\square$ Is this argument correct? My main assumption is that if we have two sets of cardinality 3 then the relation must be the entire Cartesian product $A \times B$ . By assuming this I can then work with elements being confident that each $(x, y)$ has $x \in A$ and $y \in B$ .","['elementary-set-theory', 'solution-verification', 'relations']"
4736015,Finding real and imaginary part with polar coordinates,"I'm stuck with a really basic problem, and would appreciate help to understand what I am doing wrong. The task is to find imaginary and real part of $$\Big(\frac{-1+ i \sqrt{3}}{2}\Big)^3$$ Solution so far: $$z^n=re^{i \theta n}$$ $$r=|z| = \sqrt{\frac{1}{4}+\frac{3}{4}}=1$$ $$\theta = \arg(z)=\arctan\Big(\frac{y}{x}\Big)=\arctan\Big(\frac{\sqrt{3}/2}{-1/2}\Big)=\frac{-\pi}{3}$$ Which gives me that $$\displaystyle z^n=re^{i \theta n} = e^{-i\frac{3\pi}{3}} = e^{-i\pi}$$ The correct answer is $$e^{i\frac{2\pi}{3}}$$ What in the calculation of $\theta$ am I doing wrong? Thanks!","['complex-analysis', 'trigonometry', 'complex-numbers', 'polar-coordinates']"
4736020,Struggling to Prove Cantor's Theorem (textbook guided exercise),"I am self-teaching and have hit a barrier learning about power sets and Cantor's Theorem ( pages 34-35 Understanding Analysis, Abbott, 2nd ed ). The theorem is presented as: Theorem 1.6.2 (Cantor’s Theorem). Given any set $A$ , there does not exist a function $f : A \rightarrow P(A)$ that is onto . The theorem itself feels intuitively correct for finite sets, but is applicable to infinite sets too. The text guides the reader through exercises which together form a proof of Cantor's Theorem. We start by assuming, for later contradiction, that there is a function $f: A \rightarrow P(A)$ that is onto. Since $f$ is onto, every subset of $A$ appears as $f(a)$ for $a \in A$ . The idea is to construct a set $B \subseteq A$ in such a way that it leads to a contradiction, thus exposing the assumption that $f$ can be onto is false. We construct $B= \{ a \in A: a \notin f(a) \}$ . That is, $B$ contains $a$ if $a$ does not appear in $f(a)$ . I wanted to check I understood this so the following are two examples of possible sets, $A$ , $f$ and $B$ : $A = \{a,b,c\}$ , $f(x)=x$ , and so $B=\emptyset$ . $A = \{a,b\}$ , $f(a)=b$ and $f(b)=a$ , and so $B=\{a,b\}$ . The textbook then claims: Because we have assumed that our function $f : A \rightarrow P(A)$ is onto, it must be that $B = f(a′)$ for some $a′ \in A$ . This is where my problems start: First, the statement $B = f(a')$ confuses me as the LHS $B$ is a set, but the RHS is an expression $f(a')$ . I guess it means the elements of $B$ are $f(a')$ but I wanted to check as the author of this book is normally very precise elsewhere. Second, the truth of the statement is not obvious to me. Let me try. First, because $f$ is onto, then every subset of $A$ is in in $P(A)$ . That includes the individual elements of $A$ . That is $A \subseteq P(A)$ . Now $B$ is defined to be a subset of $A$ , so $B \subseteq A \subseteq P(A)$ , which includes the possibility $B=\emptyset$ . I agree that some $a'\in A$ give $f(a') \in A$ , but I can't agree that this all omeans $f(a') \in B$ . What am I missing? Question: I would appreciate help understanding the above two points. The above problems prevent me continuing to the desired contraditicion and hence proof that $f$ can't be onto.","['elementary-set-theory', 'cardinals']"
4736077,Computing $\mathrm{Fix}(\phi)$ for autormophisms $\phi$ of free groups,"Let $F_A$ be the free group generated by the finite set $A$ and let $\phi\colon F_A \to F_A$ be a group-automorphism. It is known [1] that $$ \mathrm{Fix}(\phi) = \{g \in F_A : \phi(g) = g\} $$ is (freely) finitely generated. Moreover, if $\phi$ is positive , that is, if $\phi(a)$ is a product of the generators for all $a \in A$ , then there is an algorithm for computing $\mathrm{Fix}(\phi)$ [2]. My question is whether someone knows an implementation of this algorithm. I tried the usual sources (SageMath, Mathematica) without success. Even if there is an implementation that works for particular cases, it'd be useful for me. [1] D. Coope. Automorphisms of Free Groups Have Finitely Generated Fixed Point Sets, 1987. [2] M. Marshall & M. Lustig. On the dynamics and the fixed subgroup of a free group automorphism.","['automorphism-group', 'group-theory', 'free-groups', 'algorithms']"
4736097,"Prove: if $\lim \frac{s_n}n=L\neq0$, then the sequence $s_n$ is not bounded.","If $$\lim_{n\rightarrow \infty} \frac{s_n}{n}= L \ne 0$$ then $\{ s_n \}$ is not bounded. How to prove this generally (i.e. without help of examples)? I've sketched a proof below. Is it right.  If not what is the flaw? My attempt of proof: If $$\lim_{n\rightarrow \infty} \frac{s_n}{n}= L \ne 0$$ then $ |\frac{s_n}{n}- L |< \epsilon ,     (n\ge N)$ $L- \epsilon < \frac{s_n}{n}< L+ \epsilon$ $\frac{s_n}{n}< L+ \epsilon \implies s_n <n (L+\epsilon)$ When $n \rightarrow \infty , s_n < \infty$ Then we can't find an N such that for any $M>0$ , $|s_n |\le M$ i.e. for any $(n\ge N)$ we can't find an N such that $s_n \le -M$ .","['analysis', 'real-analysis', 'upper-lower-bounds', 'sequences-and-series', 'limits']"
4736126,"For a Wiener process, when can one exchange “for all $t$” and “almost surely”?","Certain local properties of the Wiener process $W_t$ are quick to prove at $t = 0$ , for instance: almost surely $W_t$ is monotonous on no interval beginning at $t = 0$ ; almost surely $W_t$ is not right-differentiable at $t = 0$ . Then, because $W_{t_0+t} - W_t$ is a Wiener process, we can conclude that for any $t \ge 0$ , almost surely $W_t$ is monotonous on no interval beginning at $t$ , for any $t \ge 0$ , almost surely $W_t$ is not right-differentiable at $t$ . Thus at any countable set of times, in particular a dense one, both hold almost surely.
Now, if the first holds at a certain $t = t_0$ then it holds for all $t$ in a nonempty open interval to the right of $t_0$ , so almost surely it must hold for all $t$ .
We have successfully exchanged “for all $t$ ” and “almost surely” for the first property. For the second property we are less fortunate: there are continuous functions not differentiable on a countable dense subset but differentiable on its complement. Yet this “exchange of quantifiers” is still valid here: almost surely $W_t$ is nowhere differentiable. However the proofs I have seen are considerably more involved than that for only $t = 0$ . Hence my question: is there a clean condition on the events $A_t$ under which $$\inf_{t\ge0} \Pr(W \in A_t) = 1 \implies \Pr\Bigl( W \in \bigcap_{t\ge0} A_t \Bigr) = 1 \text?$$ I am interested in “local” events $A_t$ ; let's suppose $$A_t \in \bigcap_{\varepsilon>0} \sigma(\, W_{t+\delta} \colon 0 \le \delta < \varepsilon \,) \text, \quad \text{$t \ge 0$.}$$ An obvious starting point would be $$A_t \subseteq \bigcup_{\varepsilon>0} \bigcap_{0\le\delta<\varepsilon} A_{t+\delta} \text,$$ as with the first property concerning monotonicity above.
It would be extra nice if the condition applied to the second property about differentiability.","['wiener-measure', 'quantifiers', 'almost-everywhere', 'derivatives', 'brownian-motion']"
4736173,Comparing two definite integrals analytically,"How do you find which one is greater analytically: $\displaystyle \int_{0}^{\int_0^1e^{-x^2}\mathrm dx} e^{x^2}\mathrm dx$ or $\displaystyle \int_{0}^{\int_0^1e^{x^2}\mathrm dx} e^{-x^2}\mathrm dx$ ? SMMC is an international undergrad level math competition (Eastern counterpart of the Putnam). This is a sample question from their site . There's a solution put up there which I'm presenting here in a more detailed manner. Define as follows, $f(t):=\displaystyle \int_{0}^{\int_0^t e^{-x^2}\mathrm dx} \exp(x^2)\mathrm dx\tag{01}$ $g(t):=\displaystyle \int_{0}^{\int_0^t e^{x^2}\mathrm dx} \exp(-x^2)\mathrm dx\tag{02}$ Clearly, $f(0)=g(0)=0$ . We intend to compare $f(1)$ and $g(1)$ . Differentiating w.r.t. $t$ (use the fundamental theorem of calculus and the chain rule), $f'(t)=\displaystyle \exp\left[\left(\int_0^t e^{-x^2}\mathrm dx\right)^2\right]\cdot e^{-t^2}\tag{03}$ $g'(t)=\displaystyle \exp\left[-\left(\int_0^t e^{x^2}\mathrm dx\right)^2\right]\cdot e^{t^2}\tag{04}$ It looks like both $f$ and $g$ are increasing functions because $f'$ and $g'$ are $+$ ve for all $t$ . Given their initial value is same i.e., $0$ at $t=0$ , it’s sufficient to check which one of them grows faster to compare their values at $t=1$ . $\displaystyle \frac{f'(t)}{g'(t)}=\exp\left[\left(\int_0^t e^{-x^2}\mathrm dx\right)^2+\left(\int_0^t e^{x^2}\mathrm dx\right)^2-2t^2\right]\tag{05}$ By A.M.-G.M. inequality, we have: $\displaystyle\left(\int_0^t e^{-x^2}\mathrm dx\right)^2+\left(\int_0^t e^{x^2}\mathrm dx\right)^2\\ \displaystyle \geq 2\int_0^t e^{-x^2}\mathrm dx\cdot \int_0^t e^{x^2}\mathrm dx\tag*{}$ Notice that $e^{x^2}$ is increasing and $e^{-x^2}$ is decreasing over the interval $(0, t)$ . We can apply the continuous analog of Chebyshev’s sum inequality . If $f(x)$ is an increasing function and $g(x)$ is a decreasing function (or vice-versa) over the interval $(a,b)$ , we have the following inequality: $\displaystyle \frac{1}{b-a}\int_a^b f(x)\cdot g(x)\ \mathrm dx \\ \displaystyle \leq \left(\frac{1}{b-a}\int_a^b f(x)\mathrm dx\right)\cdot\left(\frac{1}{b-a}\int_a^b g(x)\mathrm dx\right)\tag*{}$ The inequality is reversed if $f(x)$ and $g(x)$ are both increasing or both decreasing.
This is valid for discrete sum as well, where instead of functions, we consider sequences. $\displaystyle \int_0^t e^{-x^2}\mathrm dx\cdot \int_0^t e^{x^2}\mathrm dx\\ \geq \displaystyle (t-0)\int_0^t e^{-x^2}\cdot e^{x^2}\mathrm dx =t^2 \tag*{}$ Now we have established that: $\displaystyle \left(\int_0^t e^{-x^2}\mathrm dx\right)^2+\left(\int_0^t e^{x^2}\mathrm dx\right)^2> 2t^2\tag{06}$ The equality holds only if $t=0$ .
From $(05)$ and $(06)$ , we have that: $\displaystyle \frac{f'(t)}{g'(t)}>1 \text{ i.e., } f'(t)>g'(t)\tag*{}$ $\therefore$ $f$ grows faster than $g$ . $f(0) = g(0)$ and hence, $f(1)>g(1)$ . $\blacksquare$ I hope there is no mistake in my solution. Is there any alternate way to do this without making use of the sum inequality?","['calculus', 'solution-verification', 'definite-integrals']"
4736202,Derivation of integral formula with Dirac delta function over level sets,"Let $\Omega \subset \mathbb{R}^{n}$ be open, $f: \Omega \to \mathbb{R}$ be smooth and satisfy $\nabla f(x) \neq 0$ for evert $x$ . I am trying to derive the following identity: $$\int_{\Omega} \delta(f(x))h(x)dx = \int_{f(x) = 0}\frac{h(x)}{|\nabla f(x)|}dS(x).$$ I know the right hand side of the above formula is defined to be the pullback of $\delta$ with $f$ . Let $u \in \mathcal{D}'(\mathbb{R})$ be a given distribution and $\varphi$ a given test function. The pullback $f^{*}u$ of $u$ with (the smooth function) $f$ is, by definition, the distribution defined by the equality: $$\langle f^{*}u,\varphi \rangle = \langle u, \varphi_{f}\rangle$$ with: $$\varphi_{f}(t) = \frac{d}{dt}\int_{\{x \in \Omega: f(x)<t\}}\varphi(x)dx.$$ I know the standard argument to start the proof of the desired formula. Let $x_{0} \in \Omega$ be fixed. Because $\nabla f(x_{0}) \neq 0$ , there exists some $j=1,...,n$ , which without loss of generality we assume to be $j=1$ , such that $\frac{\partial f(x_{0})}{\partial x_{1}} \neq 0$ . In this case, by the inverse function theorem, there exists some neighborhood $U_{x_{0}}$ of $x_{0}$ and a neighborhood $V_{x_{0}}$ of $f(x_{0})$ such that $f: U_{x_{0}}\to V_{x_{0}}$ is a diffeomorphism. Hence, the function $\rho: U_{x_{0}} \to V_{x_{0}}$ given by: $$\rho^{-1}: (x_{1},...,x_{n}) \mapsto (f(x),x_{2},...,x_{n}) = (y_{1},...,y_{n})$$ is a diffeomorphism. Let $\varphi$ be a test function which we can assume to be such that $\text{supp}\varphi \subset U_{x_{0}}$ . We can then change coordinates to obtain: $$\varphi_{f}(t) = \int_{\mathbb{R}^{n-1}}\varphi(\rho(t,y'))|\det D\rho(t,y')|dy'$$ If the underlying distributin $u$ is taken to be $u = \delta$ , then: $$\langle f^{*}\delta,\varphi\rangle = \varphi_{f}(0) = \int_{\mathbb{R}^{n-1}}\varphi(\rho(0,y'))|\det D\rho(0,y')|dy'$$ Could someone help me complete the proof? I was trying to follow the proof in these notes , but I was a little confused with their argument at each step that $y' \mapsto F(0,y')$ parametrizes $M = \{x \in \Omega: f(x) = 0\}$ so it is given by $F(0,y') = (g(y'),y')$ for some function $g$ given by the implicit function theorem. Could you guys help me?","['dirac-delta', 'proof-explanation', 'analysis', 'distribution-theory', 'multivariable-calculus']"
4736277,Group of order $1575$ is solvable,"Let $G$ be a group of order $1575 = 3^25^27$ . Show that $G$ is solvable. So far, my idea is to show that $n_7, n_5 $ or $n_3$ equals $1$ , so that there exists a unique Sylow subgroup of order $7, 5^2$ or $3^2$ which is normal. For example, suppose that $n_7 = 1$ . Then, I can take the quotient group $H = G/P_7$ , where $P_7$ is a $7$ -Sylow subgroup. Then, $|H| = 3^25^2$ . Now, in $H$ , we have that $n_5=1$ , so there exists a unique $5$ -Sylow subgroup in $H$ . Then, $H/P_5$ has order $3^2$ , which is abelian. Hence, $P_5$ and $H/P_5$ are solvable groups, whence $H$ is solvable. Applying the same argument on $H = G/P_7$ , since $P_7\leq G$ is solvable, then $G$ is solvable. However, I can not make sure that $n_7=1$ , since $n_7$ could be $n_7 = 15 $ or $n_7 = 225$ . The old trick of assuming that $n_7>1$ would give me more elements of order $7$ than the number of elements of $G$ doesn't work here. Is there any other idea I could use to rule out the cases $n_7 = 15$ , $n_7 = 225?$ I am aware of this question here , but in this case it is assumed that we have a normal $3$ -Sylow subgroup.","['group-theory', 'sylow-theory', 'finite-groups', 'solvable-groups']"
4736288,Competition prep question: 168 ways to stitch patches of four colors into 4 x 4 grid so that no patch touch another of the same color,"I'm helping the high school son of a friend prepare for a maths competition. This question has me stumped. The text of the puzzle is as follows: My grandson makes wall hangings by stitching together 16 square patches of fabric into a 4 x 4 grid. I asked him to use patches of red, blue, green, and yellow, but to ensure that no patch touches another of the same colour, not even diagonally. The picture shows an attempt which fails only because two yellow patches touch diagonally. In how many different ways can my grandson choose to arrange the coloured patches correctly? The pictures shows the wall hanging as follows: row 1: G B R Y row 2: R Y G B row 3: G B Y R row 4: Y R G B The answer is $168$ , something I've confirmed by writing a program that brute force checked every option. How does one find the $168$ otherwise? For instance: The top left $2 \times 2$ sub grid has $4!$ options. For each one of those permutations, how does one arrive at the fact that the remaining twelve squares in the grid have $168/4! = 7$ options?",['combinatorics']
4736329,"Given a smooth map Φ:M→M , does there always exist a proper submanifold S such that Φ(S)=S?","As opposed to tracking any individual point, what I'm concerned with is a manifold that occupies the same set of points as its image under the smooth map. Suppose $\Phi(x,y)=(x+1,y)$ . Consider an arbitrary horizontal line $y=a$ . While no individual points end up where they were before, it's nonetheless true that the horizontal line simply shifts to the right. Thus, the new horizontal line entirely coincides with the old horizontal line. Consider the map $\Phi(x,y)=(y^3,x^3)$ . Under this transformation, most individual points will not end up where they were before. However, the line $y=x$ will rearrange itself once again into the same $y=x$ line. The same is true for the line $y=-x$ . The degenerate hyperbola $x^2=y^2$ could be said to be the most general set of points that will rearrange themselves into the same exact curve as before. This is what I mean by a manifold (or, in these two examples, a curve) that occupies the same set of points as its image, or - in other words - entirely coincides - or overlaps - with its image under $\Phi$ . It seems analogous to the eigenvectors of a linear transformation.",['differential-geometry']
4736331,Is there a closed form of $\int_0^{+\infty} t^n \cos (\pi t) e^{-m t}dt$ for any non-negative integer $n$ and $m>0$?,"Instead, let’s first evaluate the integral $\displaystyle I(a)=\int_0^{\infty} \cos (\pi t) e^{-a t} d t \tag*{} $ where $a>0$ .
Using Euler identity : $e^{xi}=\cos x+i\sin x$ , we have $\displaystyle \begin{aligned}I(a) & =\int_0^{\infty} \cos (\pi t) e^{-a t} d t \\& =\Re \int_0^{\infty} e^{(\pi i-a) t} d t \\& =\Re\left[\frac{e^{(\pi i-a) t}}{\pi i-a}\right]_0^{\infty} \\& =\Re\left(\frac{1}{a-\pi i}\right) \\& =\frac{a}{a^2+\pi^2}\end{aligned}\tag*{} $ Then differentiating $I(a)$ w.r.t. $a$ yields $\displaystyle I^{\prime}(a)=-\int_0^{+\infty} t \cos (\pi t) e^{-a t} d t= \frac{a^2-\pi^2}{\left(a^2+\pi^2\right)^2}\tag*{} $ Again, differentiating $I’(a)$ w.r.t. $a$ further gives $\displaystyle I^{\prime \prime}(a)=\int_0^{+\infty} t^2 \cos (\pi t) e^{-a t} d t= \frac{2 a\left(a^2-3 \pi^2\right)}{\left(a^2+\pi^2\right)^3}\tag*{} $ In general, for any non-negative integer $n$ and $m>0.$ $\displaystyle \boxed{ \left.\int_0^{+\infty} t^n \cos (\pi t) e^{-m t}dt=(-1)^n \frac{d^n}{d a^n}\left(\frac{a}{a^2+\pi^2}\right)\right|_{a=m}}\tag*{} $ My Question Is there a closed form for $$\int_0^{+\infty} t^n \cos (\pi t) e^{-m t}dt \textrm{  or } \left.(-1)^n \frac{d^n}{d a^n}\left(\frac{a}{a^2+\pi^2}\right)\right|_{a=m}$$ for any non-negative integer $n$ and $m>0$ ?","['integration', 'improper-integrals', 'calculus', 'trigonometry', 'derivatives']"
4736359,Why does CDF tend to be a power-law around 0?,"If we look at CDF of various famous random variables around 0, they tend to be well approximated by a power law. Why? Below are 24 examples, notable exceptions are log-normal, Frechet, Inverse Gamma and Inverse Normal, the rest appear to be fit with a power law. $$\left(
\begin{array}{cc}
 \text{ChiSquared} & \sqrt{\frac{2}{\pi }} \sqrt{x} \\
 \text{Marchenko-Pastur} & \frac{2 \sqrt{x}}{\pi } \\
 \text{Beta(1/2,1)} & \sqrt{x} \\
 \text{ArcSin} & \frac{2 \sqrt{x}}{\pi } \\
 \text{Weihbul(1/2,2)} & \frac{\sqrt{x}}{\sqrt{2}} \\
 \text{Exponential} & x \\
 \text{Chi} & \sqrt{\frac{2}{\pi }} x \\
 \text{Student-T} & \frac{2 x}{\pi } \\
 \text{Normal} & \sqrt{\frac{2}{\pi }} x \\
 \text{Cauchy} & \frac{2 x}{\pi } \\
 \text{Semicircle} & \frac{2 x}{\pi } \\
 \text{Gumbel} & x \\
 \text{F-ratio(2,2)} & x \\
 \text{Gamma(1,2)} & \frac{x}{2} \\
 \text{Extreme Value} & \frac{x}{e-1} \\
 \text{Logistic} & \frac{x}{2} \\
 \text{Uniform} & x \\
 \text{Inverse Normal} & -\frac{e x^2}{16}-\frac{x^2}{16}+\sqrt{\frac{2}{\pi }} e^{-\frac{(x-2)^2}{8 x}} \sqrt{x} \\
 \text{Erlang(2,2)} & 2 x^2 \\
 \text{Triangle} & 2 x^2 \\
 \text{Kumaraswamy(2,3)} & 3 x^2 \\
 \text{Bates(3)} & \frac{9 x^3}{2} \\
 \text{LogNormal} & -\frac{e^{-\frac{1}{2} \log ^2(x)}}{\sqrt{2 \pi } \log (x)} \\
 \text{InverseGamma} & e^{-2/x} \\
 \text{Frechet(2,1,0)} & e^{-\frac{1}{x^2}} \\
 \text{Pareto(1,2)} & 0 \\
\end{array}
\right)$$ Notebook","['statistics', 'probability-distributions', 'asymptotics', 'soft-question', 'probability']"
4736429,"How large $\mathbb{E} \bigg[\max_{k \in \{1,\dots,K\}}\sum_{t=1}^T \mathbb{I}\{X_t=k\}\bigg] - \frac{T}{K}$ can be?","For each $K \in \mathbb{N}$ , assume that $X_1,X_2,\dots$ is an i.i.d. sequence of (discrete) uniform random variables on the set $\{1,\dots,K\}$ and, for each $T \in \mathbb{N}$ , define the quantity $$
   f(K,T):=\mathbb{E} \bigg[\max_{k \in \{1,\dots,K\}}\sum_{t=1}^T \mathbb{I}\{X_t=k\}\bigg] - \frac{T}{K}
$$ I'm looking for a function $K^*:\mathbb{N} \to \mathbb{N}$ such that $$f\big(K^*(T),T\big) = \Omega(T^\alpha)\;,$$ for $\alpha>0$ as big as possible. So far, what it seems clear to me is that for $K=2$ this is basically equivalent to computing the expected deviation of a symmetric random walk in dimension one from the origin, so $f(2,T)=\Omega\big(\sqrt{T}\big)$ . On the other hand, if $K^*(T) \gg T$ , the intuition suggests that $f\big(K^*(T),T\big)=O(1)$ (with high-probability, each $k \in \{1,\dots,K\}$ occurred just once). So, if we pick $K^*(T) = 2$ we get $\alpha = 1/2$ , and if we get $K^*(T)$ too big, then $\alpha = 0$ . However, what happens in between? What's a sensible way to select $K^*$ to get $\alpha$ as big as possible? Any suggestions, pointers, or references?","['stochastic-processes', 'large-deviation-theory', 'probability-theory']"
4736460,Topology on a sigma-algebra,"I was thinking about how to define the support of a (positive) measure $\mu$ on $(X,\Sigma)$ . In order to mimic the standard definition for that of functions, I'm tempted to define something like $$\text{spt}\mu= \bigcap_{A}\overline{\{A\in \Sigma: \mu(A)>0\}}.$$ To make this definition go through, we need a topology on the sigma algebra $\Sigma$ . So suppose $X$ is a topological space, then one can put various topologies on its power set $\mathcal{P}(X)$ which is canonically isomorphic to $f:X\to T$ where $T$ is a two point space. If we equip $T$ with a topology (I'm not sure which one, but probably discrete), the typical induced topology on $\mathcal{P}(X)$ is the compact-open topology, which in turn induces a topology on $\Sigma\subset \mathcal{P}(X)$ . So through this abstract prescription, a topology on $X$ induces a topology on (for example), its Borel sigma algebra $\Sigma=\mathcal{B}(X)$ . The ""standard"" definition of the support of a Boreal measure $\mu$ is defined as $$\text{spt}\mu=\bigcap_{C \text{ closed}} \{C:\mu(X-C)=0\}.$$ My question is are these two definitions equivalent?","['general-topology', 'measure-theory']"
4736513,"Consider $A(3, 1)$ and $C(4, 3)$. There is a point $B(x, y)$ on the curve $y = x^2$. Minimise $|AB|^2 + |BC|^2$.","I took B as $B(x, x^2)$ . So far, I tried using the distance formula to get an expression for $|AB|^2 + |BC|^2$ . I got $(3 - x)^2 + (1 - x^2)^2 + (x - 4)^2 + (x^2 - 3)^2$ . Expanding this out gives $2x^4 - 6x^2 - 14x + 35$ . I defined a function $f(x) = 2x^4 - 6x^2 - 14x + 35$ . Then, $f'(x) = 8x^3 - 12x - 14$ . To get the minimum point of $f(x)$ , I tried finding the root of $8x^3 - 12x - 14 = 0$ . $4x^3 - 6x - 7 = 0$ , which gives $x = 1.609$ to 4.s.f. $2(1.609)^4 - 6(1.609)^2 - 14(1.609) + 35 = 10.345324$ I was wondering if there is a way to get an exact answer to this question instead of a decimal.","['coordinate-systems', 'maxima-minima', 'calculus', 'functions', 'derivatives']"
4736516,"Minimizing $(q_1, q_2, \dots, q_K) \mapsto \left(\sum_{i=1}^K\frac{p_i^2\sigma_i^2}{q_i}\right)\left( \sum_{i=1}^Kq_i\tau_i\right)$ with a constraint","$$ \begin{array}{ll} \underset {q_1, q_2, \dots, q_K} {\text{minimize}} & \displaystyle \left( \sum\limits_{i=1}^K \frac{p_i^2\sigma_i^2}{q_i} \right) \left( \sum\limits_{i=1}^K q_i\tau_i\right) \\ \text{subject to} & \displaystyle \sum\limits_{i=1}^K q_i = 1 \end{array} $$ It turns out that, the optimal $q_i$ is $$ q_i^* = \dfrac{\frac{p_i\sigma_i}{\sqrt{\tau_i}}}{\sum\limits_{\ell = 1}^K \dfrac{p_{\ell}\sigma_{\ell}}{\sqrt{\tau_{\ell}}}}.$$ The first method that comes to mind is by using Lagrangian method. I have $$
\mathcal{L}(q,\lambda) = \left(\sum_{i=1}^K\frac{p_i^2\sigma_i^2}{q_i}\right)\left( \sum_{i=1}^Kq_i\tau_i\right) + \lambda\left(\sum_{i=1}^Kq_i - 1 \right).
$$ Then, $$
\frac{\partial \mathcal{L}}{\partial q_j} = \left(-\frac{p_i^2\sigma_i^2}{q_i^2} \right)\left( \sum_{i=1}^Kq_i\tau_i\right) + \tau_j\left(\sum_{i=1}^K\frac{p_i^2\sigma_i^2}{q_i}\right) + \lambda.
$$ So, $\frac{\partial \mathcal{L}}{\partial q_j} = 0$ implies $$
q_j = \frac{p_j\sigma_j\sqrt{\sum_{\ell = 1}^Kq_{\ell}\tau_{\ell}}}{\sqrt{\tau_j\sum_{\ell = 1}^K\frac{p_{\ell}^2q_{\ell}^2}{q_{\ell}} + \lambda}}.
$$ Usually, to find $\lambda$ I would just solve $$
\sum_{j=1}^K \frac{p_j\sigma_j\sqrt{\sum_{\ell = 1}^Kq_{\ell}\tau_{\ell}}}{\sqrt{\tau_j\sum_{\ell = 1}^K\frac{p_{\ell}^2q_{\ell}^2}{q_{\ell}} + \lambda}} = 1
$$ for $\lambda$ . But the equation looks very difficult to solve. Is there a trick that I can use to solve this? Motivation This question comes from a theoretic study of Monte Carlo simulation for reducing variance. One technique to reduce variance is called stratified sampling . The idea is to create partition of the population you want to sample from. But, how do we choose the allocation? This optimization problem is to find the optimal allocation.","['optimization', 'multivariable-calculus', 'monte-carlo', 'lagrange-multiplier']"
4736529,Integration on foliated domain: more like Fubini-Tonelli or coarea?,"This is (should be) a very basic question in differential geometry/analysis, but I'm not quite sure. Everybody knows Fubini-Tonelli theorem, where if you integrate over a domain $\Omega$ in, say, $\mathbb{R}^3$ , you can actually integrate on the slices, or integrate line by line etc (this is actually Fubini or Tonelli theorem, I don't remember which is which, one of the two involves exchanging the order of integration, but whatever). So if you take, say, a cube $[0,1]^3$ in $\mathbb{R}^3$ you get $$ \int_{[0,1]^3} f(x,y,z) dxdydz = \int_{[0,1]} \left( \int_{[0,1]^2} f(x,y,z) dx dy\right) dz= \int_{[0,1]^2} \left(\int_{[0,1]} f(x,y,z) dx\right)dy dz = \dots ,$$ for an appropriate $f$ . Of course this generalizes to $n$ dimensions without a problem. Now, a big leap forward and one sees coarea formula, where given a Lipshitz function $f$ and a measurable function $g$ one has $$ \int_{E} g |\nabla f| = \int_{\mathbb{R} } \left(\int_{E \cap f^{-1} (t)} g  \right) dt,$$ where the inner integral is with respect to an appropriate Hausdorff measure, over rectifiable sets which are the level sets of $f$ in $E$ . Now, if I have a domain $\Omega$ which is foliated by some collection of submanifolds, which are not necessarily the level sets of some function, what is the correct formula? I suspect there is a way to view this as a particualr case of coarea with $|\nabla f|=1$ , because my feeling is that if you have a domain $(x,y) \in \Omega \subset \mathbb{R}^n \times \mathbb{R}^m$ and $$\Omega = \cup _{x \in \Omega' } M_x $$ with $M_x$ disjoint $m$ -manifolds, I suspect $$\int_{\Omega} f(x,y) dxdy= \int_{\Omega'} \left( \int_{M_x} f \right)dx ,$$ and that this can be rigorously proved by exhibiting a vector valued projection whose level sets are precisely the submanifolds $M_x$ and whose coarea factor is identically equal to 1. But maybe I am wrong or maybe it's simpler, I am not sure.","['integration', 'analysis', 'real-analysis', 'manifolds', 'differential-geometry']"
4736547,Differentiability implies continuity proof doubt,"I have a question in one of the steps taken to prove that a differentiable function at a point a is also continuous there.
On Spivak book, the proof is done in the following manner:
Looking at the limit as h approaches zero of the difference f(a+h)-f(a) we say that is equal to the limit as h approaches zero of the product of the secant line slope between points (a,f(a)) and (a+h,f(a+h)) times h. Now, the limit of the quotient exists since f is differentiable by hypothesis at a and the limit as h tends to zero of h exists and equals zero. Hence, the whole limit can be said to equal some real number f’(a) times 0 which as a whole is just 0. Now, this next step is where my doubt is. Having concluded that the limit as h approaches zero of the difference f(a+h)-f(a) equals 0, it looks like this limit is equal to the difference if the separate limits as h approaches zero of f(a+h) and f(a) exist; so by subtracting by f(a) from both sides, we conclude that the limit of f(a+h) as h approaches zero equals f(a) which I know is equivalent to saying that f is continuous at a. My doubt is why can you say that the limit of the difference is the difference of limits in this case? Don’t you need to verify that the separate limits exist to do that (as it was done similarly to say that whole limit = f’(a) * 0 )?","['limits', 'calculus', 'real-analysis']"
4736604,A high school mathematical problem about the application of logarithmic function properties.,"The following question about the application of logarithmic function properties is one of the questions in my course exam. For this question, our teacher only gave the answer without giving the detailed dissolution steps, so I added my own solution steps, but I am not sure whether it is correct, so please help me point out the mistakes in my dissolution steps and give me the correct approach. Given the function $f(x)=| \log_e (x) |$ , if $m>n>0$ and $f(m)=f(n)$ ,  select the correct terms from the following conclusions: $
\ \
a.m+n=2;  \qquad b.mn=1;  \qquad c.\frac{2}{m} + \frac{1}{n} \ge 2\sqrt 2;  \qquad d.\frac{1}{m} + \frac{2}{n} \ge 3;
$ For option a, I don't know how to get the specific value of $m+n $ by using the question conditions, so I skip the steps of a here. If you can help me supplement the steps of option a, I will be very grateful to you. For choice b, use the two conditions of the question: a. $f(m)=f(n)$ b. $m>n>0$ The following conclusions can be drawn: a. $\|log_em\| = \|log_en\|$ , $ log_em = -log_en$ b. $m>1$ , c. $ 0<n<1 $ , d. According to a. the conclusion can be drawn : $m*n=1,\quad m=\frac{1}{n}$ For option c, using the conclusion $m=\frac{1}{n}$ from 2, make the following inferences: $$
2n + \frac{1}{n} \ge 2\sqrt2 \\
\Rightarrow 2n^2 + 1 \ge 2\sqrt2 *n \\
\Rightarrow 2n^2 - 2\sqrt2 *n + 1 \ge 0 \\
\Rightarrow (\sqrt2n - 1)^2 \ge 0
$$ This converts the inequality of option c into a quadratic equation, let $f(x)=(\sqrt2x-1)^2$ , from the graph of the function, which has only one point of intersection with the X-axis: $(\frac{\sqrt2}{2},0) $ , the function image is above the X-axis, which satisfies $(\ sqrt2n-1)^2 \ge 0$ , so option B is also the correct conclusion. For option d, the following inference is made using the conclusion $m=\frac{1}{n}$ obtained from 2: $$
\frac{1}{m} + \frac{2}{n} \ge 3 \\
\Rightarrow n^2 - 3n + 2 \ge 0
$$ Let $f(x)= n^ 2-3n + 2$ , according to the quadratic equation to find the root formula, we can see that the equation has two real roots, respectively $x_1=1,x_2=2$ , we can see from the function image, when $1 \le x \le 2$ , $f(x) \le 0$ is constant. According to the conclusion of 2. c. $0<n<1 $ , $f(x) is always greater than 0$ in the interval (0,1). So $n^2-3n + 2 \ge 0$ works. So choice D is also the correct conclusion. To sum up, the conclusion of this topic is BCD. Please help me check if there is any problem with my steps and correct them. I would be very grateful if you could help me supplement the analysis steps of option a.","['functions', 'logarithms']"
4736655,Probability Theory is Applied Measure Theory?,"So I’ve taken a probability theory class and I’m studying for a measure theory class next quarter. While I always knew probability theory incorporated a lot of measure theory, it seems to me like it really is just applied measure theory. It incorporates some other notions like Bayesian probability results, but it is otherwise just renaming notions from measure theory and developing special cases of measures and $\sigma-$ algebras. Is this an unjustified understanding of probability theory?","['measure-theory', 'probability-theory', 'real-analysis']"
4736682,An Alternate Definition for n! [duplicate],"This question already has answers here : Expressing a factorial as difference of powers: $\sum_{r=0}^{n}\binom{n}{r}(-1)^r(l-r)^n=n!$? (6 answers) Closed 12 months ago . TL; DR: Is this equation true, and how do I prove it? $$
\sum_{k=0}^n \binom{n}{k}(-1)^k(n-k)^n = n! \;\; \forall \;\; n \; \in N
$$ Context: I came across this question while thinking about powers of natural numbers. Imagine you have a list of numbers like this: $$
1^3 \;\; 2^3 \;\; 3^3 \;\; 4^3 \;\; 5^3 \;\; 6^3 \;\; ...
$$ Then if you difference of each number with its neighbor, from right to left: $$
\;\;\;\;\;\;\;\;1^3 \;\; 2^3 \;\; 3^3 \;\; 4^3 \;\; 5^3 \;\; 6^3 \;\; ...\\
\text \/ \;\;\text \/\;\;\text \/\;\;\text \/\;\;\text \/ \\
\;\;\;\;\;\;7 \;\; 19 \;\; 37 \;\; 61 \;\; 91 \;\; ...\\
\;\;\text \/ \;\;\text \/\;\;\text \/\;\;\text \/\;\; \\
\;\;\;\;\;\;12 \;\;18 \;\; 24 \;\; 30 \;\; ...\\
\;\;\;\text \/ \;\;\text \/\;\; \text \/ \;\;  \\
\;\;\;\;\;\;\;6 \;\;\;\ 6 \;\;\;\; 6 \;\ ... 
$$ If we try another, say with the degree n=4: $$
\;\;\;\;\;\;\;\;1^4 \;\; 2^4 \;\; 3^4 \;\; 4^4 \;\; 5^4 \;\; 6^4 \;\; ...\\
\text \/ \;\;\text \/\;\;\text \/\;\;\text \/\;\;\text \/ \\
\;\;\;\;\;\;\;15 \;\; 65 \; 175 \; 369 \; 671 \;\; ...\\
\;\;\text \/ \;\;\text \/\;\;\text \/\;\;\text \/\;\; \\
\;\;\;\;\;\;\;\;50 \;110 \; 194 \; 302 \;\; ...\\
\;\;\;\text \/ \;\;\text \/\; \;\text \/ \;\;  \\
\;\;\;\;\;\;\;\;60 \;\; 84 \;\; 108 \;\ ... \\
\;\;\;\text \/ \;\;\text \/  \\
\;\;\;\;\;\;\;\;\;\;24\;\;\;24 \;\;...
$$ Or, with n=2: $$
\;\;\;\;\;\;\;\;1^2 \;\; 2^2 \;\; 3^2 \;\; 4^2 \;\; 5^2 \;\; 6^2 \;\; ...\\
\text \/ \;\;\text \/\;\;\text \/\;\;\text \/\;\;\text \/ \\
\;\;\;\;\;\;\;\;3 \;\;\;\; 5 \;\;\; 7 \;\;\;\; 9 \;\;\; 11 \;\;\;\; ...\\
\;\;\;\text \/ \;\;\text \/ \;\;\text \/ \;\;\text \/\;\; \\
\;\;\;\;\;\;\;2 \;\;\;\; 2 \;\;\;\; 2 \;\;\;\; 2  \;\; ...\\
$$ A clear pattern begins to emerge. For degree n, the ""final"" difference leads to n!. With n=2, the final row appears to be a infinite row of $2 = 2! = n!$ With n=4, final row is $24 = 4! = n!$ Finally, if I rewrite the diagram like this: $$
\;\;\;\;\;\;\;\;1^3 \;\;\;\;\;\;\;\;\;\; 2^3 \;\;\;\;\;\;\;\;\;\; 3^3 \;\;\;\;\;\;\;\;\;\; 4^3 \\
\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\text \/ \;\;\;\;\;\;\;\;\;\;\text \/\;\;\;\;\;\;\;\;\;\;\text \/\;\;\;\;\;\;\;\;\;\; \\
\;\;\;\;\;\;\;\;\;\;\;2^3 - 1^3 \;\;\; 3^3 - 2^3 \;\;\; 4^3 - 3^3  \\
\;\;\;\;\;\;\;\;\text \/ \;\;\;\;\;\;\;\;\;\;\text \/ \\
\;\;\;\;\;\;\;\;3^3 - 2(2^3) + 1^3 \;\;\;\;\;\; 4^3 - 2(3^3) + 2^3 \\
\;\;\;\;\;\;\;\;\text \/  \\
\;\;\;\;\;\;\;4^3 -3(3^3) + 3(2^3) - 1^3
$$ If I rewrite each diagram in this format, I end up with the final difference as: $
n = 2: 1(3^2) - 2(2^2)  + 1(1^2) \\
n = 3: 1(4^3) - 3(3^3) + 3(2^3) - 1(1^3) \\
n = 4: 1(5^4) - 4(4^4) + 6(3^4) - 4(2^4) + 1(1^4)\\
...\\
$ Notice how the coefficients form Pascal's Triangle. It makes sense that Pascal's Triangle should show up, since the construction of this diagram is strikingly similar to the construction of Pascal's Triangle, the only difference being, well, a difference rather than a sum of the neighbors. Recall how earlier it was noticed that the final difference always seems to be n!. The equation that I seek to prove and ask for help is: $$
\sum_{k=0}^n \binom{n}{k}(-1)^k(n-k)^n = n! \;\; \forall \;\; n \; \in N
$$","['summation', 'binomial-coefficients', 'discrete-mathematics']"
4736694,sequence of Riemann-integral integrable functions that converges to 0,"Question: Prove or disprove the following statement. If $\{f_n\}$ is a non-decreasing sequence of Riemann-integrable functions on $R = [0,1] \times [0,1]$ so that $f_n(x) \to 0$ for almost all $x \in R$ , then $\lim_n \int_{R} f_n \, dx = 0.$ I believe this statement is false. However, I am not able to find a counterexample with $\lim_n \int_R f_n\, dx \neq 0$ . Any hints are appreciated.","['measure-theory', 'real-analysis']"
4736695,"The equation $r^2 \frac{\partial ^3\Psi(r,s)}{\partial r^3}=s^2 \frac{\partial \Psi(r,s)}{\partial s}.$ Possible connections in physics and math?","Recently I wrote down the following linear third order partial differential equation: $$r^2 \frac{\partial ^3\Psi(r,s)}{\partial r^3}=s^2 \frac{\partial \Psi(r,s)}{\partial s} \tag{1}$$ The particular solution I obtained for $(1)$ is: $$\Psi(r,s)=2 \sqrt{\frac{r}{s}}K_1(2\sqrt{r s})$$ where $K_1$ is the modified Bessel function of the second kind and $r,s>0.$ I'll be honest, I guessed the solution, so I don't know the normal method. I searched online for a list of most common partial differential equations but didn't see anything that resembled the form of $(1).$ I also talked to some people knowledegable in physics but most of the differential equations applied are second order. I learned from them that $(1)$ is dimensionally inconsistent and that one can make it dimensionally consistent using physical constants with the right units. At this moment I'm not interested in the steps to obtain my solution. I would like to know if the PDE or the analytic solution I found are connected to other areas of math or physics. I tried thinking of an ansatz that would help but couldn't come up with anything. I actually don't see anything of this form appearing in the literature so I can't just learn from someone else's solution and explanation. I thought, Bessel functions are applied in physics...the Bessel differential equation. Some solutions find applications in vibrating membranes. However, there's some crucial differences in my case because I'm dealing with a modified Bessel function, of fixed index and it's $2$ dimensional i.e. is a function of $r,s.$ Does $(1)$ appear in the literature anywhere? Is $(1)$ or the solution $\Psi(r,s)$ connected to other problems in math or physics? Thanks for the possible resources and/or feedback.","['analysis', 'partial-differential-equations', 'physics', 'soft-question', 'bessel-functions']"
4736736,"Étale covering of nodal cubic curve, Hartshorne exercise 10.6.","I was trying to solve exercise III.10.6 of Hartshorne and found this post about it. My problem is that I am struggling to show that the morphism $f : X \longrightarrow Y$ (following notation of the post, $X$ is the étale covering and $Y$ the nodal curve) is flat. In the post it is said that we can use Proposition III.9.7 of the book. The Proposition assumes that $Y$ is regular, but he nodal cubic curve $Y$ is not regular at (0,0), right? Then, how could we prove that this morphism is flat? Thanks in advance.","['algebraic-curves', 'curves', 'algebraic-geometry', 'flatness']"
4736750,"Showing that if $f \in C^k$ and $\dot{x}(t) = f(x(t),t)$, then $x \in C^{k+1}$ (Proof verification)","I came across the following easy fact (Lemma 3.17) in Meiss' Differential Dynamical Systems . Here is my paraphrased version: Lemma. Let $E \subseteq \mathbb{R}^d$ , let $I \subset \mathbb{R}$ be a compact interval, let $f \in C^k(E,\mathbb{R}^d)$ for some $k \geq 0$ , and suppose that $x: I \to \mathbb{R}^d$ solves the IVP $$\dot{x}(t) = f(x(t)), \; x(0) = x_0.$$ Then $x \in C^{k+1}(I,\mathbb{R}^d)$ . I am trying to use this lemma to prove the following analogous claim for nonautonomous IVPs: Claim. Let $E$ and $I$ be as in the lemma, let $f \in C^k(E \times I, \mathbb{R}^d)$ , and suppose that $x: I \to \mathbb{R}^d$ solves the IVP \begin{equation}
    \dot{x}(t) = f(x(t),t), \quad x(0) = x_0. 
\end{equation} Then $x \in C^{k+1}(I,\mathbb{R}^d).$ Here is my proof attempt. Proof. Firstly, we can write $x(t) = (x_1(t),\ldots,x_d(t))$ and $f(x,t) = (f_1(x,t),\ldots,f_d(x,t))$ , where $x_i: I \to \mathbb{R}$ and $f_i: \mathbb{R}^d \times I \to \mathbb{R}$ for each $i=1,\ldots,d$ . Now define $\tilde{x}: I \to \mathbb{R}^{d+1}$ by \begin{equation}
   \tilde{x}(t) := (x_1(t),\ldots,x_d(t),t) \qquad \forall t \in I. 
\end{equation} Then for each $i = 1,\ldots,d$ , define $\tilde{f}_i: \mathbb{R}^{d+1} \to \mathbb{R}$ by \begin{equation}
    \tilde{f}_i(s_1,\ldots,s_d,s_{d+1}) := f_i((s_1,\ldots,s_d),s_{d+1}) 
\end{equation} for all $s = (s_1,\ldots,s_{d+1}) \in \mathbb{R}^{d+1}$ .  Now note that \begin{align*}
   \tilde{f}_i(\tilde{x}(t)) &= \tilde{f}_i(x_1(t),\ldots,x_d(t),t) \\[3pt]
                             &= f_i((x_1(t),\ldots,x_d(t)),t)  \\[3pt]
                             &= f_i(x(t),t). 
\end{align*} Next, define $\tilde{f}: \mathbb{R}^{d+1} \to \mathbb{R}^{d+1}$ by \begin{equation}
   \tilde{f}(s) := (\tilde{f}_1(s),\ldots,\tilde{f}_d(s),1) \qquad \forall s \in \mathbb{R}^{d+1}. 
\end{equation} Clearly, $\tilde{f} \in C^k(\tilde{E},\mathbb{R})$ , where $\tilde{E} := E \times I$ . Let $x_0 := (x_0^{(1)},\ldots,x_0^{(d)})$ and define $\tilde{x}_0 := (x_0^{(1)},\ldots,x_0^{(d)},0)$ . Now observe that $\tilde{x}$ solves the autonomous IVP \begin{equation}
    \dot{\tilde{x}}(t) = \tilde{f}(\tilde{x}(t)), \quad \tilde{x}(0) = \tilde{x}_0, 
\end{equation} since \begin{align*}
   \dot{\tilde{x}}(t) &= (\dot{x}_1(t),\ldots,\dot{x}_d(t),1)  \\[3pt]
                      &= (f_1(x(t),t),\ldots,f_d(x(t),t),1)    \\[3pt]
                      &= (\tilde{f}_1(\tilde{x}(t)),\ldots,\tilde{f}_d(\tilde{x}(t)),1) \\[3pt]
                      &= \tilde{f}(\tilde{x}(t)). 
\end{align*} It then follows by the lemma that $\tilde{x} \in C^{k+1}(\tilde{E},\mathbb{R})$ , which then implies that $x \in C^{k+1}(E,\mathbb{R}). \qquad \square$ My main question is: Is this proof correct? I just want to make sure my reasoning is sound. Update 7/16/23: Thanks to @Filippo for pointing out a much simpler proof: Proof : Fix $k \geq 0$ and let $f \in C^k(E \times I,\mathbb{R}^d)$ . We prove that $x \in C^j(I,\mathbb{R}^d)$ for all $j \in \{0,1,\ldots,k+1\}$ by induction on $j$ . Base case $(j = 0)$ : By assumption $x$ is differentiable and hence and hence continuous, and so $x \in C^0(I,\mathbb{R}^d)$ . Inductive step: Fix an arbitrary $j \in \{0,1,\ldots,k\}$ and assume $x \in C^j(I,\mathbb{R}^d)$ . Then the map $t \mapsto f(x(t))$ is in $C^j(I,\mathbb{R}^d)$ being that it's the composition of the maps $f \in C^j(E \times I,\mathbb{R}^d)$ and $t \mapsto (x(t),t) \in C^j(I,\mathbb{R}^d \times I)$ . Hence, $\dot{x} \in C^j(I,\mathbb{R}^d)$ and so $x \in C^{j+1}(I,\mathbb{R}^d)$ . This completes the proof.","['initial-value-problems', 'ordinary-differential-equations', 'dynamical-systems']"
4736763,"Finding a formula for the sequence $\{1, 7, 17, 30, 48, 70, 95, 125, \ldots\}$","I have a sequence $$f = \{1, 7, 17, 30, 48, 70, 95, 125, \ldots\}$$ The difference between the entries of f is $$\triangledown f = \{6, 10, 13, 18, 22, 25, 30, \ldots\}$$ Finally, the difference between the entries of $\triangledown f$ is $$\{4, 3, 5, 4, 3, 5, 4, 3, \ldots\}$$ repeating. I've been trying to find an equation for $f$ , but am struggling to piece it together. Hints would be greatly appreciated, thanks!","['number-theory', 'recurrence-relations', 'sequences-and-series', 'algebra-precalculus', 'pattern-recognition']"
4736851,Is there notion of a relation in category theory?,"From a set-oriented point of view, a relation between sets $A$ and $B$ is a subset $\rho \subset A \times B$ of their product. By imposing further axioms (e.g. left-totality, right-totality, symmetry, transitivity, etc.) we may produce a number of useful concepts: (partial) functions, equivalence relations, (partial) orders, etc. $\rho$ is a function if and only if it is left-total and right-unique. $\rho$ is a partial function if and only if it is right-unique. $\rho$ is an equivalence if and only if it is reflexive, symmetric, transitive... What I find interesting is how this process generalizes to contexts other than sets. Consider groups. Let $A$ and $B$ be groups, then a subgroup $\rho \leq A \times B$ (direct sum) may be called a relation of groups . Observe how $\rho$ is a group homomorphism if and only if it is left-total and right-unique. Explanation: Since $\rho$ is a subgroup of $A \times B$ , we have $(1, 1) \in \rho$ ; in other words, $1\rho = 1$ . If $x\rho = x'$ and $y\rho = y'$ , i.e. $(x, x'), (y, y') \in \rho$ , then $(xy, x'y')$ , i.e. $(xy)\rho = (x\rho)(y\rho) = x'y'$ . And if $x\rho = x'$ or $(x, x') \in \rho$ , then also $(x^{-1}, x'{}^{-1}) \in \rho$ , so $x^{-1}\rho = (x\rho)^{-1} = x'{}^{-1}$ . $\rho$ is a partial group homomorphism if and only if it is right-unique. $\rho$ is a congruence relation if and only if it is reflexive, symmetric, transitive. I am quite sure that this works for $G$ -sets, rings, $R$ -modules, and others. So this is quite beautiful; we only need a notion of a subobject and of a product and then we get the rest (such as homomorphisms, orders, congruences) for free. And category theory can provide us with both. I am interested in whether there is a general notion of a relation or ""relation object"" in category theory and how one further derives the notions above from this. Or maybe category theory has a completely different approach to defining these. What is this approach? I am particularly interested in how the process described above extends to more general categories (say, Cartesian closed categories).","['abstract-algebra', 'cartesian-closed-categories', 'category-theory']"
4736854,"If $f : \mathbb{R}^3 \to \mathbb{R}$ is Schwartz, is $F(x):=\int_{\mathbb{R}^3} \frac{f(y)}{\lvert x-y \rvert} d^3y$ also Schwartz?","I am having trouble proving / disproving the question in the title. That is, let $f : \mathbb{R}^3 \to \mathbb{R}$ be a real-valued Schwartz function. Then, I wonder if \begin{equation}
F(x):=\int_{\mathbb{R}^3} \frac{f(y)}{\lvert x-y \rvert} d^3y
\end{equation} is also a Schwartz function. At least it seems clear from the property of convolution that $F(x)$ is smooth. However, I cannot figure out decay properties of $F(x)$ . Could anyone please help me?","['calculus', 'schwartz-space', 'functional-analysis', 'real-analysis']"
4736889,A curious family of integrals that give $\pi$,"I have edited the question to include what I think is an interesting property of this integral. I have noticed experimentally that: $$\int_{0}^{1} \frac{1-x^2}{x^4+2x^3+2x^2-2x+1} dx=\frac{\pi}{4},\tag{1}$$ $$\int_{0}^{1} \frac{x}{x^4+2x^3+2x^2-2x+1} dx=\frac{\pi}{8},\tag{2}$$ $$\int_{0}^{1} \frac{1+x-x^2}{x^4+2x^3+2x^2-2x+1} dx=\frac{3\pi}{8}.\tag{3}$$ So a little variation in the numerator seems to produce always something like $n\pi$ . Here is my new question: what is exactly the relation between $n$ and the numerator of the integrand? The closest thing to my formula is formula $(34)$ in this list of formulas , but it is not exactly the same as mine.","['integration', 'calculus', 'reference-request']"
4736912,Evaluate $\lim\limits_{x\to 0} \frac{x(1-\cos x)}{x - \sin(x)}$ without Taylor series or L'Hôpital's rule?,"I want to evaluate $\lim\limits_{x\to 0} \frac{x(1-\cos x)}{x - \sin(x)}$ . We know that its plot is: And also with attention to the Taylor series we know that its series expansion at $x=0$ is: $$3 - x^2/10 - x^4/4200 + O(x^6)$$ So the limit is $3$ . But I want to evaluate it without Taylor series or L'Hôpital's rule. What I tried: $$\begin{aligned}
\lim\limits_{x\to 0} \frac{x(1-\cos x)}{x - \sin(x)}& =\\
&\lim_{x\to 0}\frac{x\cdot2\sin^2\frac{x}{2}}{x - \sin x} = \lim_{x\to 0}\frac{2x\cdot\sin^2\frac{x}{2}}{x\cdot(1 - \frac{\sin x}{x})} = 
\\&\lim_{x\to 0}\frac{2\sin^2\frac{x}{2}}{1 - \frac{\sin x}{x}}
\end{aligned}$$ But that did not help to evaluate the indeterminate form. Also I want to know is there a geometric representation for $x - \sin(x)$ which helps us to evaluate the limit?","['limits', 'calculus', 'limits-without-lhopital', 'trigonometry']"
4736928,"Conjecture: $\,\lim\limits_{n\to\infty}\int_0^1 (1+|\sin{nx}|)^{-2}\mathrm dx=\frac{4}{3\pi}$","I was playing with integrals, and came up with $$L=\lim_{n\to\infty}\int_0^1 \frac{1}{(1+|\sin (nx)|)^2}dx.$$ Conjecture: $L=\dfrac{4}{3\pi}$ Is my conjecture true? Remarks on numerical investigation: Desmos and Wolfram don't do a good job with numerical investigation of this limit, but we can consider the series $f(n)=\dfrac{1}{n}\sum\limits_{k=1}^n \dfrac{1}{(1+|\sin{k}|)^2}$ . $f(10^3)\approx0.999568\left(\frac{4}{3\pi}\right)$ $f(10^6)\approx0.999999635\left(\frac{4}{3\pi}\right)$ $f(10^9)\approx0.999999999807\left(\frac{4}{3\pi}\right)$ This suggests that $\lim\limits_{n\to\infty}f(n)=\frac{4}{3\pi}$ . Using Riemann sums, we have $\lim\limits_{n\to\infty}f(n)=L$ . My attempt: I tried to use $\,\sin nx = \dfrac{1}{2i}(e^{nxi}-e^{-nxi})\,$ in $\;\displaystyle\int_0^1 \dfrac{1}{(1+|\sin (nx)|)^2}\,\mathrm dx\;,\;\;$ to no avail. I also tried to use complex numbers in the series $f(n)$ , as in answers to a question about $\sum_{n=1}^{\infty} \frac{\cos (n)}{n}$ , to no avail.","['conjectures', 'definite-integrals', 'real-analysis', 'sequences-and-series', 'limits']"
4736933,Set Theory and Logic,"Given, $A$ and $B$ are disjoint, prove that $A - B = A$ . I don't have any problem with the question itself. The proof was fairly simple and straight forward until I noticed something. Let $y \in A$ . $$\implies y \in A \textrm{ and }  y \not\in B$$ $$\implies y \in A - B$$ $$\implies A \subseteq A - B$$ This last step is where I have problem. Why shouldn't it directly imply that $A=A-B$ ? My teacher told that ""we have proved that every element of $A$ belongs to $A-B$ but not yet proved that those are the only elements in $A-B$ "" But how can $A-B$ ever have more elements than $A$ ? Is there a flaw in my logic?",['elementary-set-theory']
4736958,Probability of a survivor,"In a room stand n armed and angry people. At each chime of a clock, everyone simultaneously spins around and shoots a random other person. The persons shot fall dead and the survivors spin and shoot again at the next chime. Eventually, either everyone is dead or there is a single survivor. As n grows, what is the limiting probability that there will be a survivor? I have been trying to solve this problem for a while but couldn't find a good approach. Any insight is appreciated! Here are the probabilites for the small values of $n$ : $n = 2$ -> $0$ $n = 3$ -> $3 / 4$ $n = 4$ -> $48/81$ For much larger values of n, I ran some computer simulation and found that the answer gets close to $1 / 2$ .","['random-graphs', 'probability']"
4736962,Why do we multiply by the value on the normal curve instead of the area under the curve in naive anomaly detection algorithm?,"In the naive unsupervised anomaly detection algorithm, we go through each feature and calculate the probability of getting the value. Then, we multiply the probability for each feature to calculate the net probability. But, in multiplication, we use the actual value on the normal curve: $$\frac{1}{\sigma \sqrt{2 \pi}} \exp{\left(-\frac{(x - \mu) ^ 2}{2\sigma^ 2}\right)}$$ Shouldn't we multiply by the area under the curve for getting such an extreme value i.e. the area under the curve for $(-\infty, -x) \cup (x, \infty)$ I can imagine a scenario where the $\sigma$ is high (the curve is highly spread out) and so even the probability of getting the mean is low. How does this work then? Sorry if this is a stupid question, I am new to statistics. Thanks!","['statistics', 'normal-distribution', 'probability']"
4737012,"Geometric, arithmetic, and harmonic mean ratio proof.","If $G$ be the geometric mean between two quantities $A$ and $B$ , show that the ratio of the arithmetic and harmonic means of $A$ and $G$ is equal to the ratio of the arithmetic and harmonic means of $G$ and $B$ . $A, G, B$ are in geometric progression. Therefore $\dfrac{B}{G}=\dfrac{G}{A}$ , or $G^2=AB$ The arithmetic mean of $A$ and $G$ by definition is $\dfrac{A+G}{2}$ , and the harmonic mean $H$ of $A$ and $G$ can be found by recognizing the arithmetical progression is the inverse of the harmonical progression: $A,\dfrac{1}{H}, G$ $\dfrac{1}{H}-A=G-\dfrac{1}{H} \Rightarrow \dfrac{2}{H}=A+G \Rightarrow H=\dfrac{2}{A+G}$ Ratio of arithmetic and harmonic means of $A$ and $G$ : $\dfrac{\dfrac{A+G}{2}}{\dfrac{2}{A+G}}=\dfrac{(A+G)^2}{4}$ Arithmetic mean of $G$ and $B$ : $\dfrac{G+B}{2}$ Harmonic mean: $G,\dfrac{1}{H}, B \Rightarrow \dfrac{1}{H}-G=B-\dfrac{1}{H} \Rightarrow \dfrac{2}{H}=G+B \Rightarrow H=\dfrac{2}{G+B}$ Ratio fo arithmetic and harmonic mean of $G$ and $B$ : $\dfrac{\dfrac{G+B}{2}}{\dfrac{2}{G+B}} \Rightarrow \dfrac{(G+B)^2}{4}$ $\dfrac{(A+G)^2}{4}=\dfrac{(G+B)^2}{4} \Rightarrow A+G=G+B \Rightarrow A=B$ This result is wrong because $A,G,B$ are in geometric progression, so $A \neq B$ . I also don't really understand if $A,G,B$ are in geometric progression, how could it also be in arithmetical progression at the same time (if that's what the question means). Thanks.",['algebra-precalculus']
4737023,Special case of chain rule,"Suppose $H$ is a Hilbert space, $I:H \to \mathbb{R}$ is a functional and $\eta_t:\mathbb{R} \to H$ . I want to understand why \begin{equation*}
\frac{d}{d t} I\left(\eta_t\right)=\left(I^\prime\left[\eta_t\right],\frac{d}{d t}  (\eta_t)\right),
\end{equation*} where $(.,.)$ is the inner product of $H$ . I know that the formula is true when $H$ is a finite dimensional space (for example, $\mathbb{R}^n$ ), for then you can write coordinates $x_1,\dots, x_n$ and with the chain rule the inner product naturally appears. My question is how to show this formula is true when $H$ is an arbitrary Hilbert space.","['hilbert-spaces', 'functional-analysis', 'chain-rule']"
4737027,"Geometry problem: A circle surrounded by circles, find the radius","Problem Consider the following image that shows a centre circle with radius $=1$ and $n=7$ smaller circles with radius $r$ ; Calculate $r(n)$ . Initial try Let $\alpha$ be the angle between the vertical (larger) radius and the “first” circle; and let $\beta$ be the angle between the radii for 2 tangent circles; We get $$\cos(\alpha)=\frac{1-r}{1+r}, \qquad \sin(\beta/2)=\frac{r}{1+r}.$$ Summing up “full circle” for the larger circle we get $$(n-1)\beta+2\alpha=2\pi$$ or $$
(n-1)2\arcsin\left(\frac{r}{1+r}\right)+2\arccos\left(\frac{1-r}{1+r}\right)=2\pi
$$ $$
\iff (n-1)\arcsin\left(\frac{r}{1+r}\right)+\arccos\left(\frac{1-r}{1+r}\right)=\pi.
$$ I don't get further than this (if it is even the right approach) and the equation looks hard to solve. Any other approach that gives a “neater” (and explicit) result for $r(n)$ ? TIA. Here are some additional graphs for $n=21$ ; and $n=100$ ; It is not hard to let Mathematica (numerically) solve the equation for any $n$ and draw these images, but an explicit expression would be much nicer. If we let $$S(n,r)=(n-1)2\arcsin\left(\frac{r}{1+r}\right)+2\arccos\left(\frac{1-r}{1+r}\right)$$ we get $$S'_r(n,r)=\frac{2 \left(n+\frac{\sqrt{\frac{2
   r+1}{(r+1)^2}}}{\sqrt{\frac{r}{(r+1)^2}}}-
   1\right)}{(r+1)^2 \sqrt{\frac{2
   r+1}{(r+1)^2}}}>0$$ for all $r>0$ and $n\ge2$ . Hence $S(n,r)$ is increasing. Note that $S(n,0)=0$ . For $n=\{2,3\}$ we have a special case where the outer circles are larger than the centre circle with $r(2)=4$ and $r(3)=\phi$ (the Golden Mean) (an interesting property in its own). For $n=4$ we have a part of a regular hexagon hence $r(4)=1$ . For $n\ge5$ we have $S(n,1)=\frac{1}{3}(2+n)\pi\ge\frac73\pi>2\pi$ . Since $S(n,r)$ is increasing and $S(n,0)=0$ and $S(n,1)>2\pi$ there is a solution $r_0\in(0,1)$ for the equation $S(n,r)=2\pi$ .","['contest-math', 'geometry']"
4737042,Prove that in an acute triangle the circumcenter falls in the interior of the triangle? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 12 months ago . The community reviewed whether to reopen this question 11 months ago and left it closed: Original close reason(s) were not resolved Improve this question How can we prove the above theorem using synthetic geometry.","['euclidean-geometry', 'geometry']"
4737091,Distances of Fermat point from vertices of a triangle,"Consider a triangle $ABC$ and a point $T$ .
Given that $∠ATB=∠ATC=∠BTC=120°$ and $AC=3$ , $BC=4$ , $∠ACB=90°$ ,
find $(9BT + 7CT)/AT$ . From the question we can imply that the point $T$ is the Fermat-Torricelli point of the triangle. The question wants us to basically find the distance from the vertex to this fermat's point .I have tried applying law of cosines but unable to solve further.","['triangles', 'triangle-centres', 'geometry']"
4737104,Angle of tilt of a cup so that the water surface touches the rim,"A cup is in the shape of a right circular conical frustum with bottom diameter $4 cm$ and top diameter $8 cm$ , and slant height $10 cm$ .  It is filled to $\dfrac{2}{3}$ of its height with water, then the cup is tilted by an angle $\theta$ such that the water surface touches the rim of the cup (See attached image).  Find the tilt angle $\theta$ . My attempt: First, complete the frustum down to the vertex of the cone.  Compute the volume of the cone from the vertex to the water surface, let this volume be $V_0$ . Next, I derived that the ellipse of the cut has a semi-major axis length $a$ and semi-minor axis length $b$ where, $ a = \dfrac{ z_0 \tan \theta_c \cos \theta }{ 1 - \sin^2 \theta \sec^2 \theta_c } $ $ b = \dfrac{ z_0 \tan \theta_c \cos \theta }{ \sqrt{1 - \sin^2 \theta \sec^2 \theta_c} } $ where $\theta_c$ is the semi-vertical angle of the cone (i.e. the angle between the axis of the cone and its surface). $z_0$ is the distance between the vertex and the intersection point of the axis with the cutting plane. $\theta$ is the acute angle between the axis of the cone and the normal vector to the cutting plane. In addition, the altitude of the tilted cone (the perpendicular distance between the vertex of the cone and the cutting plane) can be computed as $z_0 \cos \theta $ . Also, $z_0$ can be directly related to the slant height (along the side of the cup) and angles $\theta_c$ and $\theta$ . With all that, the volume of water in the tilted cup can be expressed as function of $\theta$ and equated to $V_0$ (the volume before tilting).  The resulting equation can be simplified into a simple trigonometric equation in double the angle $\theta$ , and can be solve for $\theta$ .  With the given values, I found that the tilt angle $ \theta = 41.458^\circ $ Any comments, hints, and alternative solutions are highly appreciated.","['analytic-geometry', 'conic-sections', 'geometry', 'quadrics', 'trigonometry']"
4737130,"how to use concentration inequality to prove a function is positive, given its mean is positive?","Given a function $f(w,x)$ where $x$ is independent variable and $w$ is random variable. How to prove it is positive given (1) its expectation is positive, i.e. $P(Ef>0)=1$ (2) it concentrates to its mean, i.e. $P(|f-Ef|\geq t)\leq 2\exp{(-t^2)}$ . I tried the following two ways:
Let $\alpha>0$ , then
(1) \begin{equation}
\begin{aligned}
P(f>0)>P(f>\alpha)&=P(f-Ef+Ef>\alpha)\\
&>P(f-Ef>\alpha \text{ and }Ef>0)\\
&\geq P(f-Ef>\alpha)+P(Ef>0)-1\\
&=P(f-Ef>\alpha)+1-1\\
&\geq \\
\end{aligned}
\end{equation} (2) \begin{equation}
\begin{aligned}
P(f<0)&=P(f-Ef+Ef<0)\\
&<P(f-Ef<0\text{ or }Ef<0)\\
&\leq P(f-Ef<0)+P(Ef<0)\\
&=P(f-Ef<0)
\end{aligned}
\end{equation} Then I don't know how to proceed. Update: I came up with the following, and could you help to check whether this is correct? First, assume we know hat $f$ concentrates to its mean in the way that $$P(f-Ef\leq -t)\leq \exp(-t^2)$$ where $t>0$ (left tail probability). Equivalently $$P(f\leq Ef-t)\leq \exp(-t^2)$$ Consider $t>Ef$ , take $-a:=Ef-t<0$ , then $$P(f\leq -a)\leq \exp(-(Ef+a)^2)$$ where $a$ actually represents the deviation of $f\leq -a$ from being $f>0$ . From this inequality we can see that when $a$ increases (i.e. deviation increases), the upper bound $\exp(-(Ef+a)^2)$ decreases. Thus, we can say: $f>0$ with high probability, since the more we deviation from what we expected (i.e. $f>0$ ), the smaller the probability is.","['probability-theory', 'probability']"
4737223,"Why can you not divide both sides of the equation, when working with exponential functions?","We recently started with exponential functions, and I did this task for fun, but I apparently did everything wrong. I just don't get why it is wrong. I am aware of some logarithmic properties like $\log(\frac{x}{y})= \log(x)-\log(y)$ and $\log(x\cdot y)=\log(x)+\log(y)$ (though i don't really understand why that works and if $x$ and $y$ have to be variables or parameters. And I also don't know when to use these properties.) The task: Find the intersection point of $g(x)=3\cdot0.4^x$ and $f(x)=0.5\cdot1.5^x$ This is how i did it (and the solution is wrong): $0.5\cdot1.5^x=3\cdot0.4^x$ $(0.5\cdot1.5^x)\cdot\frac{1}{3}\cdot\frac{1}{1.5^x}=(3\cdot0.4^x)\cdot\frac{1}{3}\cdot\frac{1}{1.5^x}$ $\frac{1}{6}=\frac{0.4^x}{1.5^x}$ $\frac{1}{6}=(\frac{0.4}{1.5})^x$ $\frac{1}{6}=x\cdot \log(\frac{4}{15})$ $\frac{1}{6\cdot \log(\frac{4}{15})}=x$ $-0,290$ , which is terribly wrong. The correct solution/approach: $0.5\cdot1.5^x=3\cdot 0.4^x$ $\log(0.5\cdot 1.5^x)=\log(3\cdot 0.4^x)$ $\log(0.5)+\log(1.5^x)=\log(3)+\log(0.4^x)$ $\log(0.5)+x\cdot \log(1.5)=\log(3)+x\cdot \log(0.4)$ $\log(0.5)-\log(3)=x\cdot \log(0.4)-x\cdot \log(1.5)$ $\log(0.5)-\log(3)=x\cdot (\log(0.4)-\log(1.5))$ $\frac{\log(0.5)-\log(3)}{\log(0.4)-\log(1.5)}=x=1,36$ I would appreciate if someone could tell me why I wasn't able to divide and basically do the first approach.","['algebra-precalculus', 'exponential-function', 'logarithms']"
4737244,Is there an identity for $\sum_{k=0}^{n-1}\csc(w+ k \frac{\pi}{n})\csc(x+ k \frac{\pi}{n})\csc(y+ k \frac{\pi}{n})\csc(z+ k \frac{\pi}{n})$?,"What I'd like to find is an identity for $$\sum_{k=0}^{n-1}\csc\left(w+ k \frac{\pi}{n}\right)\csc\left(x+ k \frac{\pi}{n}\right)\csc\left(y+ k \frac{\pi}{n}\right)\csc\left(z+ k \frac{\pi}{n}\right)$$ Further I wonder if a method can be extended to $$\sum_{k=0}^{n-1}\csc\left(x+ k \frac{\pi}{n}\right)\csc\left(y+ k \frac{\pi}{n}\right)\csc\left(z+ k \frac{\pi}{n}\right)$$ Here it is shown that, $$\sum_{k=0}^{n-1}\csc\left(x+\frac{k\pi}n\right)\csc\left(y+\frac{k\pi}n\right)=\frac{n\sin n(x-y)}{\sin(x-y)\sin nx\sin ny}$$ So I thought I could extend this idea using the trigonometry product to sums identity giving: $$\cos \left(\theta +\frac{\pi  k}{n}\right) \cos \left(\frac{\pi  k}{n}+\tau \right) \cos \left(\frac{\pi  k}{n}+\phi \right)=\frac{1}{4} \left(\cos \left(\theta +\frac{\pi  k}{n}+\tau -\phi \right)+\cos \left(\theta +\frac{\pi  k}{n}-\tau +\phi \right)+\cos \left(-\theta +\frac{\pi  k}{n}+\tau +\phi \right)+\cos \left(\theta +\frac{3 \pi  k}{n}+\tau +\phi \right)\right)$$ and $$\cos \left(\theta +\frac{\pi  k}{n}\right) \cos \left(\frac{\pi  k}{n}+\tau \right) \cos \left(\frac{\pi  k}{n}+\omega \right) \cos \left(\frac{\pi  k}{n}+\phi \right)=\frac{1}{8} \left(\cos (\theta +\tau -\omega -\phi )+\cos (\theta -\tau -\omega +\phi )+\cos (\theta -\tau +\omega -\phi )+\cos \left(\theta +\frac{2 \pi  k}{n}+\tau -\omega +\phi \right)+\cos \left(\theta +\frac{2 \pi  k}{n}+\tau +\omega -\phi \right)+\cos \left(\theta +\frac{2 \pi  k}{n}-\tau +\omega +\phi \right)+\cos \left(-\theta +\frac{2 \pi  k}{n}+\tau +\omega +\phi \right)+\cos \left(\theta +\frac{4 \pi  k}{n}+\tau +\omega +\phi \right)\right)$$ and then taking the logarithmic derivative and making use of Chebyshev polynomials however I cannot quite manipulate this to work.","['summation-method', 'summation', 'trigonometric-series', 'contour-integration', 'trigonometry']"
4737260,IMO proposal question. prove $\sum_{k=1}^{n} k \cos(\frac{2 \pi a_k} n) = 0$,"I was looking into the problems from the art of problem solving by paul zeitz. I was stuck with the following question. Let $n$ be a positive integer having at least two distinct prime factors. Show that there
is a permutation $(a_1,a_2, . .. ,a_n)$ of $(1,2, . . . ,n)$ such that $$\sum_{k=1}^{n} k  \cos\left(\frac{2  \pi  a_k}  n\right) = 0$$ I can see that we can use some arrangements of roots of unity multiplied with $k$ which can lead to sum $0$ . Example for $n = 6$ , we can do $3+\omega+5\omega^2+4\omega^3+2\omega^4+6\omega^5=0$ where $\omega$ is a sixth root of unity.
I am not able to generalize this further.","['contest-math', 'roots-of-unity', 'geometry', 'complex-numbers']"
4737278,The total number of all different integers in all partitions of n with smallest part $\geq 2$,"I want to show that the total number of all different integers in all partitions of $n$ with smallest part $ \geq 2$ is $p(n-2)$ . Example: partitions of $7$ with smallest part $ \geq 2$ are (7), (5,2), (4,3), (3, 2, 2). Let’s count distinct parts in each, so we get respectively 1 + 2 + 2  + 2 = 7 = p(7 - 2) = p(5). Could you give any reference to the proof of that fact? Or maybe some hints to prove it in laconic way?","['integer-partitions', 'combinatorics', 'generating-functions']"
4737294,Sum of integrals of gaussian function,"The background for this question is inferential statistics. I am trying to derive some characteristics about estimators in the context of design-based inference. Let us assume I have a population of $N$ elements. Each element is associated to a value $\beta_i$ . I do not know the individual values of $\beta_i$ for each population element, but I know their mean (denoted as $\mu_\beta$ ) and variance (denoted as $\sigma_\beta^2$ ). To each population element, I apply the function: $$\int_{2-\beta_i}^{\infty} \, e^{-t^2/2} \, dt. $$ Now, I want to sum the result of this function over each population element. I believe I can formally write this problem in the following format: $$ \sum_{i=1}^{N} \int_{2-\beta_i}^{\infty} \,  e^{-t^2/2}  \, dt. $$ Do you think this can be simplified, expressed, or solved as a function of the only valid information I have, namely the mean and variance of $\beta_i$ ? EDIT:   After the very good answers from Henry and Eduardo, there doesn't appear to be any further simplification possible. However, what would happen if I knew the distribution of values of βi, in addition to their mean and variance? Could this potentially lead to a multivariable calculus problem? BTW I hope this edit in within the forum policy, I can create a new post if necessary....","['statistical-inference', 'statistics', 'normal-distribution', 'calculus', 'gaussian-integral']"
4737309,Derivative with respect to inner function with differing inputs?,"There's a conceptual deal with derivatives of composite functions that I'm really struggling to understand. Let $g(t)$ be some continuous, differentiable function. $f(t) = g(t) + g(t + 1) + g(t^2)$ Now, $\frac{df}{dt}$ is trivial to solve with the chain rule. What's $\frac{\bf df}{\bf dg}$ ? Naïvely, treating $g$ as just the input into $f$ , it seems analogous to $\frac{d}{dx}(x+x+x) = 3$ . But in the equation for $f$ above, it doesn't seem right that the three $g$ terms, which could all represent vastly different quantities for any given input, should have the same instantaneous rate of change. Is it really true that for an infinitesimal change to the output of $g$ , the output of $f$ simply changes by 3 times as much, for any value of x? Or am I wrong? Or am I asking a completely nonsensical question? (For context, I'm working on some homebrewed alternative neural network structures, and I'm treating some neurons as compositions of functions. For error measurement purposes, it would be great to take derivatives of the outer functions with respect to the inner function alone.)","['continuity', 'calculus', 'derivatives']"
4737350,Adjoint differential equations - Relation,"In my ODE book (ODE by Wolfgang Walter), I have this exercise. Let $G(x)$ be a fundamental matrix of $$
y^{\prime}=A(x) y .
$$ Show that $\left(G(x)^{-1}\right)^{\top}$ is a fundamental matrix of $$
z^{\prime}=-A(x)^{\top} z.
$$ I solved this Problem, but I can still leave it here open as a puzzle.","['matrix-calculus', 'ordinary-differential-equations']"
4737375,Is there a solution to this ODE: $ax'' - bx^γ+c = 0$?,"I have arrived here when analysing the adiabatic oscillations of a piston in a cylinder with (pressurised) air behind it and and a vacuum in front, with the pressure force from the air on the piston balanced by a weight on a cable over a pulley. I have found an approximate solution for values of $a$ , $b$ and ω in the form of $x = a + b \cos(ωt)$ using numerical methods and a spreadsheet, but am curious to know if there is a calculus solution to the ODE or if the numerical approximation is the only answer. I have reviewed the literature and am unable to find a clue to the solution. Please note, this is not a homework question, it is a problem I have arrived at in my private study of gas properties.",['ordinary-differential-equations']
