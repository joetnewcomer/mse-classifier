question_id,title,body,tags
4770458,"Are the complements of two compact, homeomorphic subsets of $\Bbb R^2$ also homeomorphic?","I am studying Real Analysis with the book ""Real mathematical analysis"" and it has been a very challenging (but not impossible) read for me so far. However, some of the exercises are pretty brutal, so one I have been stuck on is (page.129/exercise 47) Suppose $A,B\subseteq\mathbb{R}^2$ (a) If $A$ and $B$ are homeomorphic, are their complements homeomorphic (b) If $A$ and $B$ are homeomorphic and compact, are their complements homeomorphic (c) If $A$ and $B$ are homeomorphic, compact and connected, are their complements homeomorphic As the conditions get progressively more restrictive, I am very sure, that only the last one has a chance of being true and indeed, it is . For the first one, I simply used the fact, that $(0,1)$ is homeomorphic to $\mathbb{R}$ , but their complements are not homeomorphic, and set $A=(0,1)\times \{0\}$ and $B=\mathbb{R}\times\{0\}$ , where the complement of $A$ is connected, while the complement of $B$ is not. However, with the added restriction of compactness, I can't disconnect $\mathbb{R}^2$ , as that would require an unbounded set, and after 2 hours of banging my head against the wall, I still can't find a counterexample and so I want to ask here for one. I can probably wager, that both $A$ and $B$ are disconnected, and that the counterexample will arise from the complement of $A$ being disconnected, while the complement of $B$ will be connected, as that has been the only tool mentioned so far for distinguishing non homeomorphic sets.","['general-topology', 'real-analysis']"
4770530,Is the notion of random variable always necessary?,"I'm quite confused by the notion of random variable in the proper measure-theoretic framework. Let's first state the notation and definitions: Let $(\Omega, \Sigma, \operatorname{P})$ be a probability space. Then, a real-valued random variable is a measurable function $X \colon \Omega \to \mathbb{R}$ and its probability distribution is the pushforward measure $\operatorname{P}_{X} := \operatorname{P} \circ X^{-1}$ . If $\operatorname{P}_{X}$ is absolutely continuous with respect to the Lebesgue measure $\lambda$ we also know that there is a probability density function $f\colon \mathbb{R} \to \mathbb{R}$ such that $\operatorname{P}_{X}(B) = \int_B f \, \mathrm{d} \lambda$ for $B \in \mathcal{B}(\mathbb{R})$ (by the Radon–Nikodym theorem). Now let's see a simple example that is often used to illustrate the notion of random variable: Random variable that represents the sum of two dice. In this case $\Omega = \{1, 2, 3, 4, 5, 6\}^2$ , $\Sigma = \mathcal{P}(\Omega)$ , and $\operatorname{P}(A) = \frac{\#A}{36}$ for $A \in \Sigma$ , $X \colon (\omega_1, \omega_2) \mapsto \omega_1 + \omega_2$ and e.g. $\operatorname{P}_X(3) = \operatorname{P}(\{(1, 2), (2, 1)\}) = \frac{1}{18}$ . This is all crystal clear but the two examples below break my little mind: Normal random variable. What is $(\Omega, \Sigma, \operatorname{P})$ now? Others have given the answer that the underlying probability space is just abstract and unspecified. But why then, is it necessary to use the notion of random variable in the first place here? Wouldn't it be easier just to say that we are working with a probability space with $\Omega = \mathbb{R}$ , $\Sigma = \mathcal{B}(\mathbb{R})$ , and $\operatorname{P}(A) = \int_A \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2}\left(\frac{x - \mu}{\sigma}\right)^2}\, \mathrm{d}\lambda(x)$ for $A \in \Sigma$ ? Random variable that represents the outcome of the toss of a fair coin. As explained here , the underlying probability space is again some abstract space of all conceivable futures. But why do we even need that? Why not directly use $\Omega = \{0, 1\}$ , $\Sigma = \mathcal{P}(\Omega)$ , and $\operatorname{P}(A) = \frac{\#A}{2}$ for $A \in \Sigma$ ? If it is indeed beneficial to introduce random variables in these two cases, what are the benefits?","['measure-theory', 'probability-theory', 'probability']"
4770649,Relations that ensure continuity,"We say that a function $f: \mathbb{R} \rightarrow \mathbb{R}$ preserves the binary relation $\sim \subseteq \mathbb{R}^2$ if $x \sim y$ implies $f(x) \sim f(y)$ for all $x,y\in\mathbb{R}$ . We say that $\sim$ ensures continuity if every function $f: \mathbb{R} \rightarrow \mathbb{R}$ that preserves $\sim$ is continuous. Part 1. Is there any binary relation that ensures continuity? A well-ordering would work for this, I think (edit: Silly me, I realized this is not actually true. But a totally rigid relation exists on any set given Choice anyway.) But I'd like to see something better (in Part 2), and if possible something that doesn't require Choice for Part 1. Part 2. Is there any binary relation that ensures continuity, and is preserved by at least two different functions?","['model-theory', 'logic', 'relations', 'real-analysis', 'continuity']"
4770678,"There two types of tiles, we need to construct a $2 \times n$ rectangle filled with them. How many ways are there to do that?","Two types of tiles are defined: tile $B$ : a simple $1 \times 1$ sqaure tile, tile $B$ : we divide a $2×2$ square tile with segments connecting the centers of opposite sides into four $1 \times 1$ tiles, and then remove one of these four tiles. In how many ways can a $2×n$ rectangle $(n \geq 1)$ be filled with tiles of those $2$ types? Write a suitable equation or system of recursive equations and give the general formula. On the place n, we can put: $2$ tiles $A$ , in one possible way and with assumption that the rectangle $2 \times n-1$ is correct - so we get $a_{n-1}$ , those are the ways: $1$ tile $A$ with $1$ tile $B$ , in one of $4$ ways and with assumption that the rectangle $2 \times n-2$ is correct - so we get $4a_{n-2}$ , those are the ways: ; ; ; $2$ tiles $B$ , in one of $2$ ways and with assumption that the rectangle $2 \times n-3$ is correct - so we get $2a_{n-3}$ , those are the ways: ; Therefore, my idea of recursive formula goes as follows: $a_n = a_{n-1} + 4a_{n-2} + 2a_{n-3}$ These are all the combinations of tiles I can come up with. Other seem to be obtained by combination of those. From that I get: ${ \lambda}^{3}-{ \lambda}^{2}-4{ \lambda} -2 = ({ \lambda} +1) ({ \lambda}^2 - 2{ \lambda} - 2)  = ({ \lambda} +1)({ \lambda} - (1- \sqrt{3}))({ \lambda} - (1 + \sqrt{3}))$ So I get: $$a_n = b(-1)^n + c(1- \sqrt{3})^n + d(1 + \sqrt{3})^n$$ Then I calculate first $3$ terms manually: $a_1 = 1$ , because we can only choose: $2$ tiles of type $A$ ( $\{ A,A \}$ ) $a_2 = 5$ , because we can choose: $4$ tiles of type $A$ ( $\{A,A \}$ ) OR one of $4$ possible sets of tile $B$ combined with tile $A$ ( $\{ B+A \}$ ), $a_3 = 1 + 4 \cdot 2 + 2 = 11$ , because we can choose: $6$ tiles of type $A$ ( $ \{ A,A,A \}$ ) OR one of $4$ possible sets of tile $B$ combined with tile $A$ together with $2$ tiles of type $A$ and then put them all together in one of $2$ ways ( $\{B+A,A \}$ or $\{A,B+A \}$ ) OR $2$ tiles of type $B$ combined in one of $2$ ways ( $ \{B+B \} \times 2$ ) $a_4 = 1 + 4 \cdot 4 + 4 \cdot 3 + 2 \cdot 2 = 1 + 16 + 12 + 4 = 33$ , because we can choose: $8$ tiles of type $A$ ({ A,A,A,A }) OR one of $4$ possible sets of tile $B$ combined with one of $4$ possible sets of tile $B$ ({ B+A,B+A }) OR one of $4$ possible sets of tile $B$ combined with tile $A$ together with $4$ tiles of type $A$ and then put them all together in one of $3$ ways ( $\{B+A,A,A \}$ or $\{A,B+A,A \}$ or $\{ A,A,B+A \}$ ) OR one of $2$ possible sets of $2$ tiles $B$ combined together with with $2$ tiles of type $A$ and then put them all together in one of $2$ ways ( $\{B+B,A \}$ or $\{A,B+B \}$ ) $a_5 = 1 + 4 \cdot 4 \cdot 3 + 4 \cdot 4 + 2 \cdot 3 + 2 \cdot 4 \cdot 2 = 1 + 48 + 16 + 6 + 16 = 87$ , because we can choose: $10$ tiles of type $A$ ({ A,A,A,A,A }) OR one of $4$ possible sets of tile $B+A$ combined with one of $4$ possible sets of tile $B+A$ combined with tiles $A$ in one of $3$ ways ({ A, B+A,B+A } or { B+A, A, B+A } or { B+A, B+A, A } ) OR one of $4$ possible sets of tile $B+A$ combined with tile $A$ together with $6$ tiles of type $A$ and then put them all together in one of $4$ ways ( $\{B+A,A,A,A \}$ or $\{A,B+A,A,A \}$ or $\{ A,A,B+A,A \}$ or $\{ A,A,A,B+A \}$ ) OR one of $2$ possible sets of $2$ tiles $B$ combined together with with $4$ tiles of type $A$ and then put them all together in one of $3$ ways ( $\{A,A,B+B \}$ or $\{A,B+B,A \}$ or $\{A,A,B+B \}$ ) one of $2$ possible sets of $2$ tiles $B$ combined together with with tile of type $B$ joined with tile of type $A$ and then put them all together in one of $2$ ways ( $\{B+B,B+A \}$ or $\{B+A,B+B \}$ ) Now, to get the ultimate solution, I need to solve the system of equations: $a_1 = 1 = -b + c(1- \sqrt{3}) + d(1 + \sqrt{3})$ $a_2 = 5 = b + c(1- \sqrt{3})^2 + d(1 + \sqrt{3})^2$ $a_3 = 11 = -b + c(1- \sqrt{3})^3 + d(1 + \sqrt{3})^3$ After some attempts I did that using matrix calculator. The correct values should be: $b = 1$ $c = \frac{-\sqrt{3}}{3}$ $d = \frac{\sqrt{3}}{3}$ And from that I get: $$a_n = (-1)^n + \frac{-\sqrt{3}}{3}(1- \sqrt{3})^n + \frac{\sqrt{3}}{3}(1 + \sqrt{3})^n$$ The formula works for values $a_4$ and $a_5$ : $a_4 = (-1)^4 + \frac{-\sqrt{3}}{3}(1- \sqrt{3})^4 + \frac{\sqrt{3}}{3}(1 + \sqrt{3})^4 = 33$ $a_5 = (-1)^5 + \frac{-\sqrt{3}}{3}(1- \sqrt{3})^5 + \frac{\sqrt{3}}{3}(1 + \sqrt{3})^5 = 87 $ Therefore I assume the solution is correct.","['solution-verification', 'recurrence-relations', 'tiling', 'discrete-mathematics']"
4770745,Convergence in measure and convergence of integral,"Let $g_n:\mathbb{R} \rightarrow \mathbb{R}$ are measurable, suppose $g_n \rightarrow 0$ in measure, and $\int g_n^2 dm\leq 1$ for all $n$ . Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a measurable function such that $\int f^2 dm< \infty$ , prove that $\int fg_n dm \rightarrow 0$ as $n \rightarrow \infty$ . Here $m$ stands for the Lebesgue measure. My attempt is: since $g_n \rightarrow 0$ in measure, $\forall \epsilon>0, \exists N>0$ s.t. $m(\{|g_n|>\epsilon\})<\epsilon$ . So by Cauchy -Schwarz inequality, $$\left|\int fg_n\right| \leq \int_{\{|g_n|>\epsilon\}}|fg_n|+\int_{\{|g_n|\leq\epsilon\}}|fg_n|\leq \left(\int_{\{|g_n|>\epsilon\}}f^2 \right)^{1/2}\left(\int_{\{|g_n|>\epsilon\}}g_n^2 \right)^{1/2} + \epsilon\int_{\{|g_n|\leq\epsilon\}}|f|$$ Here I got stuck, the $(\int_{\{|g_n|>\epsilon\}}g_n^2)^{1/2} \leq 1$ is obvious, but I don't know how to bound $(\int_{\{|g_n|>\epsilon\}}f^2 )^{1/2}$ and $\int_{\{|g_n|\leq\epsilon\}}|f|$ . Any hint or help would be greatly appreciated","['self-learning', 'measure-theory', 'real-analysis']"
4770777,prove $ (A^C \cup B) \cap (B \cup C) \cap (C \cup A) = (A^C \cup B) \cap (C \cup A) $,Prove using the counting laws for quantities: showing left side is equal to right side $[(A^C ∩ (B∪C)) ∪ (B∩ (B∪C)) ] ∩ (C∪A) = $ $[(A^C ∩ B) ∪ (A^C ∩ C) ∪ (B∩B) ∪ (B∩C) ] ∩ (C∪A) =$ $[(A^C ∩ B) ∪ (A^C ∩ C) ∪ B ∪ (B∩C) ] ∩ (C∪A) =$ $[(A^C ∩ B) ∪ (A^C ∩ C) ∪ B] ∩ (C∪A) =$ $[(A^C ∩ B) ∪ (B ∪ A^C) ∩ (B∪C) ] ∩ (C∪A) =$ $[(A^C ∩ B) ∪ (A^C ∪ B) ∩ (B∪C) ] ∩ (C∪A) =$ $[(A^C ∩ B) ∪ A^C) ∪ B ∩ (B∪C) ] ∩ (C∪A) =$ $[(A^C ∩ B) ∪ A^C) ∪ B ] ∩ (C∪A) =$ $ (A^C ∪ B) ∩ (C∪A) $ is this correct? I'm unsure if line 4 to line 5 is right,"['elementary-set-theory', 'discrete-mathematics']"
4770782,Extremely rigorous (research level) treatment of the laplace transform,"Edit: I have found what I needed in Schwartz's Mathematics for the Physical Sciences . Will type up a reply when I have time. Bourbaki does not explain the justifications behind operational calculus The quantum book below does not justify the LT of the dirac distribution, nor the unbounded exponentials. Schwartz's original: Theorie des distributions has partial explanations. I am looking for an extremely rigorous treatment of the laplace transform . Stating the usual formulas for convenience: $$
\mathcal{L}: ?\to?\quad\mathcal{L}(f)(s) = \int_{\mathbb{R}^n}f(x)\operatorname{exp}(-\langle s,x\rangle)dx
$$ Or as a map on the space of tempered distributions (is it even well defined?), $$
\mathcal{L}: ? \to ?\quad\langle \mathcal{L}(F), \phi\rangle_{(\mathcal{S}', \mathcal{S})} = \langle F, \mathcal{L}(\phi)\rangle_{(\mathcal{S}', \mathcal{S})}
$$ Starting from a measure-theoretic, functional-analytic standpoint, I would like to know the following: Can we restrict the LT to some kind of isomorphism? What are the convergence/continuity properties? If its domain/codomain differs from that of the Fourier Transform (which is a toplinear isomorphism on the space of tempered distributions) - what topology are we using? If the LT is defined on all tempered distributions, can we extend the domain from $\mathcal{S}'$ to a bigger space? Is the LT injective/surjective? Is there a duality like in the Fourier Transform, regularity as a distribution gets converted to integrability? With regards to solving differential equations, how is the recovery of a regular solution possible? Is viewing the LT from a purely algebraic perspective , the way researchers today understand the LT? The following is a common scenario in the applied sciences that I would want the proof (in the positive or negative) of. Let $X$ and $Y$ be 'function spaces in a real variable' (left imprecise), and $H: X\to Y$ be a linear map. If $H$ is shift-invariant , meaning $$
H(\tau_a f) = \tau_a H(f)\quad \tau_af(x) = f(x-a)\quad\forall a,x\in\mathbb{R}
$$ then we can apply the Laplace Transform. Somehow in this definition we have left out the usual a.e identifications/regularity assumptions that were present if the domain of $H$ were to include the point mass at the origin $\delta_0$ : a tempered distribution defined by the duality pairing: $$
\langle \delta_0, f\rangle_{(\mathcal{S}', \mathcal{S})} = f(0)
$$ for every $f\in \mathcal{S}$ in the Schwartz space. It is often claimed (but not proven), that every linear, shift invariant 'operator' $H$ admits a rational 'transfer function' in the 'Frequency domain' $$
\mathcal{L}(h)\mathcal{L}(f) = \mathcal{L}(H(f))
$$ Setting where $h = H(\delta_0)$ is commonly called the 'impulse response' of the 'system' $H$ . It is also often claimed that the LT does not work for functions that are not of 'exponential order', $$
E_{order} = \biggl\{f: \mathbb{R}\to\mathbb{R},\: \exists C,k\in\mathbb{R},\: \vert f(x)\vert\leq C\operatorname{exp}(kx)\: \forall x\in\mathbb{R} \biggr\}
$$ but somehow is compatible with extreme irregularity like $\delta_0$ and linear combinations of its derivatives. Smooth functions like $f(x) = \operatorname{exp}(\vert x\vert^2)$ are locally integrable, thus defines a distribution. It is well known the space of test functions (we refer to $C_c^\infty$ as test functions , and $C^\infty$ as smooth functions ), is dense in $\mathcal{S}'$ . It is bizarre to rule out the functions that are above exponential order, if we were to take the 'distributional' approach to the LT. Moreover, the domain of the LT has to extend beyond the Schwartz functions, because we allow for the 'causal' (or even 'eternal' exponentials, so $g(x)=e^{kx}$ ) exponentials $f(x)=e^{kx}$ for $x\geq 0$ and $f(x)=0$ for $x<0$ , where $k\in\mathbb{R}$ to be 'transformed' into reciprocals $$
\mathcal{L}(f)(s) = \dfrac{1}{s-k}\forall \operatorname{Re}(s)>k
$$ In sum: The LT clearly converges for every test function, The point mass $\delta_0$ is in the domain of the LT, The domain of the LT has to extend beyond the Schwartz functions, No additonal regularity is imposed, because we also allow for the unit step $u(x)=0$ for $x<0$ and $u(x)=1$ for $x\geq 0$ to be LT-able but we somehow exclude a subset of $L_{loc}^1$ from the domain? Next, to my knowledge there is no agreed upon definition for the mathematical object $\mathcal{L}(f)(s)$ in the last equation. Should we extend $\mathcal{L}(f)$ for $\operatorname{Re}(s)<k$ by zero? Then we can identify $\mathcal{L}(f)$ with a distribution. I have looked at the following posts but the answers (and the texts provided) are not satisfying. Looking for a rigorous treatment about Laplace transform. Why does the mathematics of Laplace transform and fourier transform look so dodgy and non rigouruos and not well formulated? Compare Fourier and Laplace transform Relation Fourier/Laplace Transform Is the Laplace transform essentially a generalized version of the Fourier transform? (seems promising but the link is broken, edit: found the link , but is just a magic transform table derived using integration by parts) along with countless (with respect) pseudo-explanations such as the LT is 'just like' the FT, (no proof, no concrete definitions) the LT converts differentiation, integration into pointwise multiplication (ok, but what function space? a.e class? duality pairing identification? what about $\delta_0$ ? weak derivatives?, we cannot integrate distributions and how about inversion?) the fourier transform does the same. Some more oddities: function which is of exponential order, whose LT does not converge function which is above exponential order, whose LT converges On a related note, what is the unilateral/one-sided/causal Laplace Transform? What is the rigour behind it? Thank you for reading this long post.","['fourier-analysis', 'laplace-transform', 'reference-request', 'real-analysis', 'functional-analysis']"
4770868,Showing permutation does not change output of commutative operation (recursion theorem),"(In what follows, NB that $\mathbb{N}^\times$ is the positive natural numbers, and $\mathbb{N}$ includes 0.) I am working on Exercise 1 of Amann and Escher Analysis I , and the problem is essentially asking: Show that if $X$ is a set with a commutative and associative (addition) operation defined thereon, then $\sum_{j=0}^n x_j = \sum_{j=0}^n x_{\sigma(j)}$ where $\sigma$ is any permutation (bijection) of $\{0,1,...,n\}$ . I am really baffled as to how to even start. It's obviously true, but I need to prove it using the recursion theorem of set theory (Amann and Escher's Proposition 5.11). I understand how the standard sum notation ought to interpreted. I've written: We must first interpret the notation $\sum_{j=0}^n x_{\sigma(j)}$ . Given the definition for general associative operations in Example 5.12, one is led to presume that this notation refers to a recursive definition which is induced by the original. The original $\sum_{j=0}^n x_j$ is technically defined by Prop 5.11 in terms of some sequence $x_0,x_1,x_2,...$ in $X$ and some sequence of functions $V_n: X^n \to X, (y_0,...,y_{n-1}) \mapsto y_{n-1} + x_n$ for $n \in \mathbb{N}^\times$ . Now take the unique function $f: \mathbb{N} \to X$ (by Prop 5.11) for which $f(0) = x_0$ and for all $n \in \mathbb{N}$ , $f(n+1) = V_{n+1}(f(0),...,f(n)) = f(n) + x_{n+1}$ . Then define $\sum_{j=0}^n x_j := f(n)$ . I am guessing that I need to interpret the notation $\sum_{j=0}^n x_{\sigma(j)}$ somehow in terms of a recursive definition related to the sequence $V_n$ which defined $\sum_{j=0}^n x_j$ (and then perhaps I need to use induction somehow?), but I can't see how given that $\sigma$ is defined for fixed $n$ , among other things. Can anyone provide a hint or even a sketch of a proof, with careful attention paid to what $\sum_{j=0}^n x_{\sigma(j)}$ really means? For those interested in all the gory details of what I have, I have attached a couple pictures of relevance, but hopefully my question is valid as it stands.","['elementary-set-theory', 'binary-operations', 'induction', 'recursion']"
4770887,Riemann sum $\displaystyle F(x)=\lim_{n\to\infty}\frac{1}{\ln(n)}\sum_{k=1}^{n}\text{sinc}(\pi(x+k)) \ln\left(\sin\left(\frac{k\pi}{2n}\right)\right)$,"I need help calculating this limit as a function of $x$ : $$F(x)=\lim_{n\to\infty}\frac{1}{\ln(n)}\sum_{k=1}^{n}\frac{\sin(\pi(x+k))}{\pi(x+k)}\ln\left(\sin\left(\frac{k\pi}{2n}\right)\right)$$ I wanted to use the Riemann sum method in such a way $F(x)$ as to write as an integral, but the logarithm appears and I can't find a way to write it differently. Thanks in advance to anyone who can give me a suggestion I believe that the solution is: $$F(x)=\frac{1}{2\pi}\int_{0}^{\pi}\sin\left(xt\right)\cot\left(\frac{t}{2}\right)\mathrm{d}t+\frac{\sin\left(\pi x\right)}{2\pi x}-\frac{1}{2}$$ (or something like that) but I don't know how to prove it. There could be a correlation since $\dfrac{\mathrm{d}}{\mathrm{d}x}\ln(\sin(x))=\cot(x)$ I think it might also be useful to consider the Riemann–Stieltjes integral: $${\displaystyle \int _{a}^{b}f(x)\,\mathrm {d} g(x)=f(b)g(b)-f(a)g(a)-\int _{a}^{b}g(x)\,\mathrm {d} f(x)}$$","['integration', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
4770899,How do I find the limit of $\frac{n^3 \sin(n!)}{n^5 +1}$?,"I have to evaluate the following limit $$\lim_{n\to\infty}\frac{n^3\sin(n!)}{n^5+1}$$ I know the answer is zero and since $$\lim_{n\to\infty}\frac{1}{n^5+1}=0$$ I want to show that $n^3\sin(n!)$ is bounded. I know for every $n\in\mathbb{N}$ , $$-1\leq\sin(n!)\leq1$$ But I don't know what can I do with $n^3$ . When I tried to use WolframAlpha, it says $$-69\leq n^3\sin(n!)\leq59$$ However, I have no idea how to get these values.",['limits']
4770929,"The n-person hat matching problem in probability for n=3, doesn't match derangement formula","Suppose all $n$ people at a party throw their hats in the center of the room. Each person then randomly selects a hat. The probability that none of the $n$ people selects their own hat is $$1/2! - 1/3! + 1/4! - ... + (-1)^n/n!$$ The formula aligns with what one could derive by using derangements. I try to compute it for $n = 3$ . Let $E_i$ be the event that the $i$ th person picks the wrong hat and $E_{ij}$ be the event that the $i$ th person picks the wrong hat by picking the $j$ th person's hat. We are looking for $P(E_1 \cap E_2 \cap E_3)$ . We know $P(E_1 \cap E_2 \cap E_3)$ = $P(E_1) * P(E_2|E_1) * P(E_3|E_1 \cap E_2)$ . We have: $P(E_1) = 2/3$ $P(E_2|E_1) = P(E_2 \cap E_1)/P(E_1)$ [Letting P(E_ij) be the probability that the ith person wrongly picks the jth person's hat.] Then, $$P(E_2 \cap E_1) = P(E_2 \cap (E_{12} \cup E_{13}))$$ $$= P((E_2 \cap E_{12}) \cup (E_2 \cap E_{13}))$$ $$= P((E_2 \cap E_{12})) + P((E_2 \cap E_{13})) - P((E_2 \cap E_{12}) \cap (E_2 \cap E_{13}))$$ $$= P((E_2 \cap E_{12})) + P((E_2 \cap E_{13}))$$ $$= P(E_{12}) * P(E_2) + P(E_{13}) *P(E_2)$$ $$= 1/3 * 1 + 1/3 *1/2$$ $$= 1/3 + 1/6$$ $$= 1/2$$ As a result, $P(E_2 | E_1) = P(E_2 \cap E_1)/P(E_1) = 1/2 * 3/2 = 3/4$ . Of course, $P(E_3|E_1 \cap E_2) = 1$ . Finally, this leads to $P(E_1 \cap E_2 \cap E_3) = 2/3 * 3/4 * 1 = 1/2$ . But according to the formula, $P(E_1 \cap E_2 \cap E_3) = 1/3$ , which is right and can be arrived at via going to complement route, i.e. by finding the probability that at least 1 person picks the right hat and subtracting that from 1. Can someone help in pointing out where I am going wrong in the derivation above? EDIT: As pointed out by the comment, the issue is in computing $P(E_3|E_1 \cap E_2)$ . Here, person 1 can pick 2's hat and 2 picks 1's hat, then 3 gets their hat for sure. Then, $P(E_3|E_1 \cap E_2) = 1 - P(E_{33}|E_{12} \cap E_{21})$ . Note that $P(E_{33}|E_{12} \cap E_{21}) = (1/3 * 1/3 * 1/3)/(1/3 * 1/3)$ . As a result, $P(E_3|E_1 \cap E_2) = 1 - 1/3 = 2/3$ . Then, we match the formula perfectly.","['derangements', 'combinatorics', 'probability']"
4770960,Is there any way I can calculate this double integral?,"$$
S = \int_{-8}^{8} \int_{-\frac{21}{2}}^{21} \left(1 + \frac{1}{8} x^2 + \frac{64}{3969} y^2\right)^{\frac{1}{2}} dy \, dx
$$ I'm trying to finish a high school assignment, and because of the question I chose for myself, where I'm calculating the area of a surface above some region $R$ in the $xy$ -plane, it turned into this double integral that I have tried to solve. My problem is with calculating the inner integral , where I cannot use the reverse chain rule for single-variable integrals because there are two variables, and I'm unsure what other methods I can use. Any help would be greatly appreciated, thanks!","['integration', 'surface-integrals', 'multivariable-calculus', 'definite-integrals']"
4770969,Catalan numbers in numerical sequences,"How to show that the number of sequences of the form ( $a_1$ , $a_2$ , ..., $a_n$ ) when $\sum_{k=1}^i(a_k) \geq i$ for each $i$ and $\sum_{k=1}^n(a_k)$ = $n$ is equal to the corresponding Catalan number ( $C_n$ )? In my proof that the number of terms of the decomposition of a polynomial of the form $\prod_{i=1}^n(x_1 + ... + x_i)$ is $C_n$ , I went so far as to be able to show that the number of these terms is equal to the number of sequences ( $a_1$ , $a_2$ , ..., $a_n$ ) mentioned above And then I can't find a pattern Ideas are also accepted to prove my original goal. I will be grateful to everyone","['discrete-mathematics', 'catalan-numbers', 'linear-algebra', 'combinatorics']"
4770974,modes of convergence and their probabilistic interperetation,"I'm studying probability theory and as it's a known fact in real analysis and measure theory there are modes that a random variable(also any sequence of measurable functions in a given measure space) can converge namely convergence in measure(in the probabilistic sense convergence in probability), convergence in $L^1$ norm(or $L^p$ norm for any $p \geq 1$ ), convergence almost everywhere(in the probabilistic sense convergence almost surely) and also other modes of convergence that this question is not mentioning. I'm trying to get a probabilistic intuition about what does convergence in any of these modes means. For example,  I believe for example convergence in probability, means that if one toss a fair coin a lot of times, it will be more and  more probable that one gets the ratio of heads and tails closer and closer to $\frac{1}{2}$ (thanks to weak law of large numbers). but what about other modes of convergences? Also note that for example convergence a.e implies convergence in probability hence the same argument given above about the fair coin holds again but I think there is something lost in giving this example again since convergence in probability not necessarily implies convergence a.e. (at least certain circumstances are required for such a conclusion to hold and it would be very helpful if one can give some probabilistic intuition about what these circumstances mean) Thanks.","['probability-theory', 'real-analysis']"
4771028,Icosahedron with asymmetric coloring,"I am trying to determine the number of unique solutions when placing ""dots"" on the sides of an icosahedron. There can be up to three dots placed symmetrically on each side. The dots are aligned with the corners. If I let 0, 1, 2, or 3 dots be represented by a color, I can use Polya's theorem with four colors, which will give me about 1,8*10^10 possibilities. $$
P_{G} = \frac{1}{60}(z_1^{20}+24z_5^4 + 15z_2^{10}+20z_1^2 z_3^6)
$$ However, that will not take the rotational asymmetry for 1 and 2 dots into account. So, the solution will be a lower bound. I would appreciate some help in understanding how to handle this asymmetry and how much it will increase the number of possibilities. A similar (even more interesting) variant is when the dots can have two different colors. Again I can assume 7 different colors, but that solution probably be even worse. With different colorings I mean unique patterns that can't be replicated through any of the 60 available rotations. I.e. a duplicate is a solution that is identical to another solution after rotation and should therefore not be counted. Note, this is a real world problem involving viruses.","['polyhedra', 'coloring', 'graph-theory', 'polya-counting-theory', 'combinatorics']"
4771069,"If $f_n\nearrow f$ pointwise monotone on a compact set $C$, does $\inf f_n(C) \to \inf f(C)$?","Given a sequence of continuous, real-valued functions $(f_n)_{n\in\mathbb{N}}$ and a compact set $C$ , $f_n$ converge monotonically (increasing) and pointwise to an extended-real valued lower-semicontinuous function $f$ which may take values in $\mathbb{R}\cup\{+\infty\}$ ( $f$ is $+\infty$ at those points for which $f_n(x)\nearrow +\infty$ ; we can assume there is a nonempty compact subset of $C$ where $f$ is finite). I am curious if $$\inf_{x\in C}f_n(x)\to \inf_{x\in C} f(x)?$$ If $f$ were real and continuous on $C$ , we could just use Dini's theorem to get uniform convergence. However, we do not need (or get) uniform convergence here; we only need convergence of the infima. But I cannot find a proof (or counterexample) of this statement. Edit: This link discusses a related problem on the real number line. Additionally assuming convexity of all functions here would be okay as well, I suppose.","['convergence-divergence', 'functional-analysis', 'analysis', 'compactness']"
4771133,Finding all possible valid values of a set based on a list of rules.,"I'm working on a programming project and I stumbled into a bit of a problem. I think it's not an impossible problem, but I'm guessing it would involve some math. It would be amazing if anyone can either help me, or point me in the right direction so I can solve it myself. The project involves checking the validity of a structure. This is being done by checking if each variable is initialized. Lets say that I create a set up integers from 1 until k from the variables in the structure. These are the indices of the variables, so if there are $k$ variables in the structure then: $$K = \{1, 2, 3, \dots, k\}$$ When a variable is instantiated, it's index is added to the set $K'$ . I know the accent ' might not be the normal math notation, but I don't know what is. For the rest of the explanation: the accented sets are the actual instantiated variables, and the unaccented sets are all variables that can be instantiated, so: $$ K' \subseteq K $$ The goal is to check if $K'$ is valid, because if $K'$ is valid, then the structure is instantiated correctly. But there are some rules to this sets validity based on the kinds of the variables, which I'll explain. Each variable is one of three kinds: optional, mandatory, or grouped. They are treated differently based on their kind. Optional ( $O$ ): their presence in $K'$ is completely ignored. They're not important in this problem. The amount of optional variables is called $o$ Mandatory ( $M$ ): all indices from the mandatory variables need to be in $K'$ . This is still a pretty simple case. The amount of mandatory variables is called $m$ Grouped ( $G$ ): the variable is associated with one or more sets, each with their own ""rule"", or function. This is the part where I have a question about. The amount of grouped variables is called $g$ and the amount of groups is called $a$ In other words, lets say that we have two sets $O$ and $M$ , and a list of sets $G$ , where $$ K = O \cup M \cup (G_1 \cup G_2 \cup \dots \cup G_a) $$ $$ k = o + m + g $$ These sets are mutually exclusive from eachother, except between the sets in $G$ $$O \cap M = O \cap (G_1 \cup G_2 \cup \dots \cup G_a) = M \cap (G_1 \cup G_2 \cup \dots \cup G_a) = \emptyset$$ And the same rules apply to $K'$ , $G'$ , $M'$ and $O'$ If variable $n$ is in set $G_i$ AND it is initialized, then $n$ is in $G_i'$ , so $G_i' = G_i \cap K'$ . Checking the validity of the set $G_i'$ is done through checking its cardinality with an single associated function. There is one of three types of functions associated with each set in $G$ (or $G'$ ): at_least(x), at_most(x) and exact(x). For each of these functions you can assume that $0 < x < g$ . I.e. if variables 5, 7, 8 and 9 are in with $G_i$ , and variables 7 and 8 are in K', and the associated function to $G_i$ is at_least(3), then $G_i'$ is invalid. At least one more variable, either 5 or 9, needs to be initialized for $G_i'$ to be valid. The list of sets $G'$ is valid when all of its sets are valid. $K'$ is valid when both $M'$ and $G'$ are valid. I said that I already know how to deal with $M'$ , just check if all mandatory variables are initialized, check if $M' = M$ , or check if $|M'| = m$ . We can skip this part as well. Now I can tell my problem: I want to know every possible value of $K' \cap (M \cup O)$ where $K'$ is valid. In other words, I want every possible combination of indices where all groups are valid. Is there a way to not brute force it, and try all $2^g$ combinations? Also, how would I express this with a mathematical equation? I kinda fumbled my way through the explanation, hoping it was understandable.","['combinatorics', 'discrete-mathematics', 'algorithms']"
4771163,Getting 2 answers for a limit,The limit in question is $$\lim_{x\to 0} \frac{\sin^2(x) - x^2}{x^2 \sin^2(x)} $$ If we solve it via L'Hopitals method we get the answer to be $\frac{-1}{3}$ While we could also simplify it $$\lim_{x\to 0} \frac{\sin^2(x) - x^2}{x^2 \sin^2(x)} = \lim_{x\to 0} \frac{1}{x^2} -\lim_{x\to 0}\frac{1}{x^2}\frac{x^2}{\sin^2(x)} $$ $$\lim_{x\to 0} \frac{\sin^2(x) - x^2}{x^2 \sin^2(x)} = \lim_{x\to 0}\frac{1}{x^2} - \lim_{x\to 0}\frac{1}{x^2}.\lim_{x\to 0}\frac{x^2}{\sin^2(x)} $$ $$\lim_{x\to 0} \frac{\sin^2(x) - x^2}{x^2 \sin^2(x)} = \lim_{x\to 0}\frac{1}{x^2} - \lim_{x\to 0}\frac{1}{x^2} = 0$$ Which is different from the above answer Wolfram Alpha also says the answer is $\frac{-1}{3}$,"['limits', 'calculus', 'analysis', 'real-analysis']"
4771220,Separating subspheres from each other; what are the weakest hypotheses required in Hatcher exercise $2B.4$?,"The task: Take integers $p,q\ge1$ and define $S^{p-1}\subset S^{p+q-1}\subset\Bbb R^{p+q}$ to be the subsphere consisting of points of $S^{p+q-1}$ whose last $q$ coordinates are zero, and define $S^{q-1}\subset S^{p+q-1}$ to be the subsphere consisting of points whose first $p$ coordinates are zero. Show that $S^{p+q-1}\setminus S^{p-1}\cong S^{q-1}\times\Bbb R^p$ and that it strongly deformation retracts onto $S^{q-1}$ . Conclude, using the previous exercise, that: $S^{p-1}$ and $S^{q-1}$ are not the boundaries of any pair of disjointly embedded disks $D^p$ and $D^q$ in $D^{p+q}$ The preceding exercise: Say $n\ge0$ and $(D,S)\subseteq(D^n,S^{n-1})$ has: (i) $D\cap S^{n-1}=S$ and (ii) $(D,S)\cong(D^k,S^{k-1})$ for some $k\ge0$ . Show that the inclusion $S^{n-1}\setminus S\hookrightarrow D^n\setminus D$ induces an isomorphism on homology. This is a fun problem with very strong intuitive justification. I was able to solve it... under a suitable interpretation of ""boundaries"". Specifically, if $h:D^p\to D^{p+q}$ and $h':D^q\to D^{p+q}$ are the disjoint embeddings in question I assumed that $S^{p-1}=h(S^{p-1})=h(D^p)\cap S^{p+q-1}$ and I assumed that $S^{q-1}\subseteq h'(D^q)$ . Note the asymmetry here; I could get away with making weaker assumptions on $h'$ but seemingly not with $h$ . However, it would be reasonable to interpret Hatcher as just saying, $h(S^{p-1})=S^{p-1}$ (two different meanings of $S^{p-1}$ , but what can you do?) and similarly for $h'$ . These are weaker assumptions and my proof strategy does not seem to work in this case. However, the preceding exercise does not seem to apply in this case either... so what's going on? I am not sure what the most general correct form of the statement is, and if one can weaken the hypotheses successfully I would appreciate a proof or proof sketch of how to achieve that. I have faith the stronger form of the theorem holds because, playing with examples in $D^2$ and $D^3$ , it's ""obvious"" - in the naive, visual sense - that the strong version is correct. But visual intuition only gets you so far. Below I write my solution and discussion for my interpretation of the exercise. The deformation retraction thing is easy. It follows that $S^{q-1}\hookrightarrow S^{p+q-1}\setminus S^{p-1}$ induces an isomorphism on (reduced) homology. It also follows from the preceding exercise that $S^{p+q-1}\setminus S^{p-1}\hookrightarrow D^{p+q}\setminus h(D^p)$ induces an isomorphism on (reduced) homology, so the overall composite $S^{q-1}\hookrightarrow D^{p+q}\setminus h(D^p)$ induces an isomorphism on (reduced) homology. However, we can factor this inclusion as: $$S^{q-1}\hookrightarrow h'(D^q)\hookrightarrow D^{p+q}\setminus h(D^p)$$ Using the fact that $h'$ and $h$ have disjoint image (observe we can get away with $h(D^p)$ being a subset of $h'(D^q)$ which avoids $S^{q-1}$ ). Since the middle term has trivial reduced homology in all degrees we conclude (from this being an isomorphism and $S^{q-1}$ not having trivial reduced homology in all degrees) that something is wrong with our premises and no such $h,h'$ can exist. This crucially relies on $S^{p+q-1}\setminus S^{p-1}\hookrightarrow D^{p+q}\setminus h(D^p)$ inducing an isomorphism on homology, which is horribly false if we relax the assumption $S^{p-1}=h(D^p)\cap S^{p+q-1}=h(S^{p-1})$ to the assumption $h(S^{p-1})=S^{p-1}$ . There is a partial fix to this , namely that I am confident we can amend the previous exercise to get that: $S^{p+q-1}\setminus(h(D^p)\cap S^{p+q-1})\hookrightarrow D^{p+q}\setminus h(D^p)$ is an isomorphism on homology (Hatcher doesn't state this, though I think my proof can be adapted). From this perspective, we can then work with the slightly weakened hypotheses: $h,h'$ are embeddings and $S^{q-1}\subseteq h'(D^q)$ and $S^{p-1}=h(D^p)\cap S^{p+q-1}$ (i.e. we do not care what $h(\partial D^p)$ is) But working with the reasonable alternative interpretation of what Hatcher meant, we'd have an issue in that $S^{p+q-1}\setminus(h(D^p)\cap S^{p+q-1})$ doesn't, in general, deformation retract onto $S^{q-1}$ !","['general-topology', 'homology-cohomology', 'algebraic-topology', 'spheres']"
4771258,Why dividing equation by absolute value gives bad result,"I have to solve $x^2 + 4x + 4 = 7|x+2|$ . I did this: $(x + 2)^2 = 7|x+2|$ And we know that $|w| = w \iff w ≥ 0$ , so: $|x+2|^2 = 7|x+2|$ because the $(x+2)^2$ is always $≥0$ Then, I divided this equation by $|x+2|$ (I think I can, because the $|x+2|^2 = |x+2||x+2|$ so I got $|x+2|=7$ It means that $x = 5$ or $x = -9$ . But it's bad, because the valid result is $x=-9$ or $x=5$ or $x=-2$ . I know another approach that will give appropriate result, but why this one doesn't work?","['algebra-precalculus', 'absolute-value']"
4771266,Simplifying $\frac{\sin(3x)+\sin(4x)+\sin(5x)}{\sin(x)+\sin(2x)+\sin(3x)}$,"To simplify: $$\frac{\sin(3x)+\sin(4x)+\sin(5x)}{\sin(x)+\sin(2x)+\sin(3x)}.$$ I know that in the denominator, $\sin(2x)$ can be re-written as $2\sin x\cos x$ using the double-angle identity. I also know that for the numerator $\sin(3x)+\sin(5x)=2\sin(4x)\cos x$ and likewise for the denominator $\sin x+\sin(3x)=2\sin(2x)\cos x$ . After that, I get: $$\frac{2\sin(4x)\cos x +\sin(4x)}{2\sin(2x)\cos x + 2\sin x\cos x}.$$ If necessary, the $\sin(4x)$ in the numerator can also become $2\sin(2x)\cos(2x)$ . This would make the fraction: $$\frac{2\sin(4x)\cos x + 2\sin(2x)\cos(2x)}{2\sin(2x)\cos x + 2\sin x\cos x}.$$ From here, one can factor out a two from both numerator and denominator and thereby cancel them out (though I'm not sure this is helpful in the long run): $$\frac{\sin(4x)\cos x +\sin(2x)\cos(2x)}{\sin(2x)\cos x +\sin x\cos x}.$$ And then, stuck. No like terms that I can see and which identity is helpful here, I do not know. Can someone help with some hints for the next steps in order to simplify?",['trigonometry']
4771284,Must every Cauchy-Riemann condition be fulfilled simultaneously?,"Working through problems in my complex analysis book, and I have to determine where the derivative exists for a function. I know that the derivative can exist only along a certain curve, however I don't know if that must be true simultaneously or not. For instance, one such function I've been given is $f(z) = \frac{ix + 1}{y}$ which gives $u(x,y) = \frac{1}{y}$ and $v(x,y) = \frac{x}{y}$ , and for the derivatives, you get $u_x = 0, v_y = \frac{-x}{y^2}, u_y = \frac{-1}{y^2}, and -v_x = \frac{-1}{y}$ . I know that this implies the derivative exists when $\frac{-x}{y^2} = 0$ (i.e. $x = 0$ ) and when $\frac{-1}{y^2} = \frac{-1}{y}$ (i.e. $y = 1$ ), but I don't know if this implies the derivative exists when EITHER of those things is true (derivative exists at $(0, a)$ and $(b, i)$ ) or only when BOTH of those things are true (derivative exists at $(0, i)$ ). I'm only asking for clarity on that front. Thank you!","['cauchy-riemann-equations', 'complex-analysis', 'partial-derivative', 'derivatives', 'complex-numbers']"
4771311,A Question About Coprime Actions,"I'm dealing with the following problem in Isaacs Finite Group Theory [4D.3], I would appreciate if you could help: Problem : Let $A$ act via automorphisms on $G$ , where $(\vert G \vert, \vert A \vert ) = 1.$ Suppose that $A$ acts trivially on every $A$ -invariant proper subgroup of $G$ , but that the action of $A$ on $G$ is nontrivial. Show that $G$ is $p$ -group for some prime $p.$ My attempt : For a contradiction, assume that $G$ is not a $p$ -group. Using Glauberman Lemma, we can see that there exists an $A$ -invariant Sylow $p$ -subgroup of $G$ for each prime. Due to hypothesis, for any $A$ -invariant Sylow $p$ -subgroup $P$ , it must be $[P,A]=1$ . That is each such a Sylow $p$ -subgroup is contained in $C_G(A)$ . From the hypothesis again, we know that $C_G(A) \neq G.$ How can I get the desired result from this point? Thanks.","['group-theory', 'group-actions', 'finite-groups']"
4771315,How to enumerate unique lattice polygons for a given area using Pick's Theorem?,"Pick's Theorem Suppose that a polygon has integer coordinates for all of its vertices. Let $i$ be the number of integer points interior to the polygon, and let $b$ be the number of integer points on its boundary (including both vertices and points along the sides). Then the area $A$ of this polygon is: $$A = i + \frac{b}{2} - 1$$ Example Let integer area $A = 5$ , these are the possible pairs of boundary $b$ and interior $i$ points that satisfy Pick's Notice that some pairs $(b,i)$ have multiple unique shapes For $b=6,i=3$ above, found $7$ unique shapes so far. Are there others that I missed? I'm just visually checking and haven't written any code to determine the exact number, yet. The Pick's integer solutions are $$\forall A>0, \quad 1 < n \leq (A+1) : b = 2n, \, i = (A + 1) - n, \quad n,A \in \mathbb{Z}$$ Brute-Force Approach Find all possible pairs of boundary $b$ and interior $i$ points that satisfy Pick's Theorem. For each $(b, i)$ pair, attempt to generate all unique simple lattice polygons. Count the unique shapes for the given area $A$ . Question Given an integer area $A$ , I'm curious about how many unique shapes can be formed on a $2D$ lattice?","['euclidean-geometry', 'combinatorics', 'polygons']"
4771390,A possible characterization of WSC spaces,"A Banach space $X$ is weakly sequentially complete (WSC) if every weakly Cauchy sequence in $X$ is weakly convergent. I will use the following classical result: Rosenthal's $\ell_1$ theorem : Every bounded sequence in a Banach space $X$ either contains a weakly Cauchy subsequence, or a subsequence equivalent to the $\ell_1$ basis. It follows from the fact that a closed subspace of a WSC space is WSC, that every subpace of a WSC space is either reflexive or contains $\ell_1$ . This observation, if localized, actually gives us a characterization of WSC spaces, namely: Proposition. For a Banach space $X$ TFAE: $X$ is WSC; Every bounded sequence in $X$ has either a weakly convergent subsequence, or a subsequence equivalent to the $\ell_1$ basis; Every weakly precompact (i.e. not containing a sequence equivalent to the $\ell_1$ basis) bounded set in $X$ is relatively weakly compact. It would thus feel plausible that the ""nonlocalized"" version of this Proposition could be true as well. Namely, I would like to know if: Question: Let $X$ be a Banach space such that every closed subspace $Y$ of $X$ is either reflexive or contains $\ell_1$ , is $X$ then weakly sequentially complete? As mentioned above, the converse implication is true. I have, however, not managet to prove/disprove the Question above. Any help will be appreciated.","['banach-spaces', 'weakly-cauchy-sequences', 'functional-analysis']"
4771422,"Difference between partially ordered, totally ordered, and well ordered sets.","I just started studying set theory and I'm a bit confused with some of these relation properties. Given a set A = {8,4,2}, and a relation of order R such that a R b means ""a is a multiple of b"", we would have the following relations: {8 R 8, 8 R 4, 8 R 2, 4 R 4, 4 R 2, 2 R 2} (I think a correct notation for this set of relations would be A/R but frankly I'm not too sure so if anybody could confirm or deny that, it'd be appreciated) If my understanding of relations is correct (which it might very well not be), the relation would be reflexive, transitive and antisymmetric, therefore we would have a partial relation of order. Now, since in this partial order all elements are related to each other, it would be a total order relation. And since all non empty subsets of the set A would have a least element, it's a well ordered set If, however,  instead of A = {8,4,2}, we had A = {8,4,2,3}, we would just have a relation of partial order since 3 wouldn't be related to any of the other elements in the set. On another note, in order to have a well-ordered set, we first need a totally ordered set, right? Also lastly, if A started out at $2^n$ where $n = \infty$ and $n$ descended until 1, the set would be totally ordered but not well ordered,  right? I'm aware this notation might be terrible but I don't know how to get the idea across otherwise so yeah. Any help and advice with notation and general understanding is also appreciated Edit: A correction on this last paragraph: after reading some of the replies and re-reading my own message I've noticed how what I've written makes basically no sense, so I'm going to re-do the question: The set I was (very poorly) trying to describe was A = { $2^n  |  n \in \Bbb N $ } only backwards for some reason. So reading the replies, they say it's a totally ordered set but not a well ordered set. Seeing as $2^n  |  n \in \Bbb N $ has a least element (if $n = 0$ ), I was wondering why it wouldn't be a well ordered set. In other words, do all of the subsets of any set with a least element also have a least element?","['elementary-set-theory', 'order-theory', 'well-orders', 'relations']"
4771424,$\infty$-multifactorial: $\displaystyle z!_{(\infty)}:=\lim_{\alpha\to\infty}z!_{(\alpha)}$,"Introduction Let $z!_{(\alpha)}$ the $\alpha$ -multifactorial. $$z!_{(\alpha)}=\alpha^{\frac{z}{\alpha}}\Gamma\left(1+\frac{z}{\alpha}\right)\prod_{j=1}^{\alpha-1}\left(\frac{\alpha^{\frac{\alpha-j}{\alpha}}}{\Gamma\left(\frac{j}{\alpha}\right)}\right)^{C_{\alpha}(z-j)}$$ Where $$C_{\alpha}(z)=\frac{1}{\alpha}\left(1+2\sum_{k=1}^{\left\lfloor\frac{\alpha-1}{2}\right\rfloor}\cos\left(\frac{2k\pi}{\alpha}z\right)+\text{mod}(\alpha-1,2)\cos(\pi z)\right)$$ My intent I would like to calculate the limit of the multifactorial formula for $\alpha$ which approaches infinity. Leaving aside the various steps that are long and irrelevant to the question I arrived at this formula: $$z!_{(\infty)}=\exp\left(\sum_{j=1}^{\infty}\text{sinc}(z-j)\ln(j)\right)$$ Where $\text{sinc}(x):=\begin{cases}\dfrac{\sin(\pi x)}{\pi x}&\text{if }x\neq0\\1&\text{if }x=0\end{cases}$ Unfortunately I can't move forward with this last sum :/, does anyone have any suggestions? (It would also be acceptable to write it as an integral) At the end of everything, a function with the following characteristics must emerge: $n!_{(\infty)}=n$ for $n\in\mathbb{N}^{+}$ $n!_{(\infty)}=1$ for $n=-1,-2,-3,...$ $\displaystyle\prod_{i=0}^{\infty}(z-i)!_{(\infty)}=z!$ This is the graph: I'll also leave this link which leads to the desmos graph I made in case anyone wants to try their hand at trying to solve it. Update 1 The series is equal to $$z!_{(\infty)}=\exp\left(\frac{\sin(\pi z)}{\pi}\sum_{n=1}^{\infty}(-1)^n\frac{\ln(n)}{z-n}\right)\qquad \text{for }z\not\in\mathbb{N}^{+}$$ I take inspiration from an answer to make a clarification: It would be useful to be able to use a result like this : $$\sum_{k=-\infty}^{\infty}\frac{(-1)^k}{z-k}f(k)=\pi\frac{f(z)}{\sin(\pi z)}$$ Applying this result with $f(n)=\begin{cases}\ln(n)&\text{if }n>1\\0&\text{if }n\leq 1\end{cases}$ the result would be: $$z!_{(\infty)}=\begin{cases}z&\text{if }z>1\\1&\text{if }z\leq 1\end{cases}$$ Unfortunately: In this case it is not applicable because one of the hypotheses requires that $f(n)$ is entire and the logarithm is not (and it can not be continued analytically to an entire function). $z!_{(\infty)}$ is a complex variable function, $\mathbb{C}$ is not ordered so it's not possible to say things like "" $z>1$ "" or "" $z\leq 1$ "" According to this solution for "" $z\leq 1$ "" the series should ALWAYS be $0$ . Update 2 $$x!_{(\infty)}=\exp\left(-\text{sinc}(x)\sum_{n=1}^{\infty}\eta'(n)x^n\right)$$ Where $\eta'(s)$ is the derivative of the Dirichlet Eta function.","['real-analysis', 'gamma-function', 'calculus', 'sequences-and-series', 'limits']"
4771425,"How to evaluate the integral $\int_0^t\frac{xe^x}{1+e^x}\,dx$?","$$I=\int_0^t\frac{xe^x}{1+e^x}\,dx$$ I tried this method to solve this integral by using an operator y, so the integral could be formed as : $$I(y)=\int_0^t\frac{\partial}{\partial y}\ln{(1+e^{y x})}\,dx$$ Then we can write it as : $$I(y)=\frac{\partial}{\partial y}\int_0^t\ln{(1+e^{y x})}\,dx$$ We calculate the integral of $$\int_0^t\ln(1+e^{yx})\,dx$$ It would give us as we substitute $$u=e^{yx}$$ then
we have $$du=ye^{yx}dx$$ so $$dx=\frac{du}{yu}$$ $$\frac{1}{y}\int_1^{e^{yt}}\frac{\ln(1+u)}{u}\,du$$ We substitute $$v=-u$$ $$dv=-du$$ $$-\frac{1}{y}\int_1^{e^{yt}}\frac{\ln(1-v)}{v}\,dv=-\frac{1}{y}\int_0^{e^{yt}}\frac{\ln(1-v)}{v}\,dv-\frac{1}{y}\pi^2\frac{1}{6}$$ Then we get $$\frac{1}{y}\operatorname{Li}_2(-e^{yt})-\frac{1}{y}\pi^2\frac{1}{6}$$ Intering the partial derivative $$I(y)=\frac{\partial}{\partial y}(\frac{1}{y}\operatorname{Li}_2(-e^{yt})-\frac{1}{y}\pi^2\frac{1}{6})$$","['integration', 'calculus', 'derivatives', 'analysis']"
4771461,When is $\exp(f(x))$ concave?,"I'm interested in the set of twice-differentiable functions $f$ such that $\exp(f(x))$ is concave for $x \in [0,1]$ . This is equivalent to asking for the set of functions $f$ such that $$
\left(\frac{df}{dx}(x)\right)^2 + \frac{d^2 f}{dx^2}(x) < 0
$$ for every $x \in [0,1]$ . The reasoning for this equivalence is below. I'm purposefully avoiding a non-strict inequality to avoid the trivial solution $f(x) = c$ for some constant $c \in \mathbb R$ . If the entire set can’t be characterized, I would be satisfied with a single example of $f$ . Because \begin{equation}
\frac{d \exp \circ f}{dx}(x) = \exp(f(x)) \cdot \frac{df}{dx}(x)
\end{equation} and so \begin{align}
\frac{d^2 \exp \circ f}{dx^2}(x) &= \exp(f(x)) \cdot \frac{df}{dx}(x) \cdot \frac{df}{dx}(x) + \exp(f(x)) \cdot \frac{d^2f}{dx^2}(x) \\
&= \exp(f(x)) \cdot \left[\left(\frac{df}{dx}(x)\right)^2 + \frac{d^2f}{dx^2}(x)\right]
\end{align} Because $\exp(f(x)) \geq 0$ for every $x \in [0,1]$ , then we want to determine the functions $f$ such that $$
\left(\frac{df}{dx}(x)\right)^2 + \frac{d^2f}{dx^2}(x) < 0
$$ for every $x \in [0,1]$ .","['convex-optimization', 'convex-analysis', 'ordinary-differential-equations']"
4771533,Can a hexagonal grid embed rectangular coordinates?,"I'm trying to figure out if a hexagonal grid can embed rectangular coordinates in whole numbers of ""Y-steps"".  In the image below, one ""Y-step"" is the spacing between red hexagon centers in the Y dimension. For some arbitrary hexagonal grid size, how many hexagons do I need to produce some whole-valued number of ""Y-steps"" in the X dimension? Another way to ask this might be: Select four hexagons whose centers create the corners of a square.  In the hexagon grid orientation shown below, how many horizontal hexagons are needed to create such a square, and then how many vertical ""steps"" are needed in the Y dimension ?  Both X and Y values need to be whole integers. In case it helps, this site provides great info in hexagonal coordinates, but I've not figured out how to pin down a way to solve this.  We are using the ""pointy top"" orientation.","['graph-theory', 'coordinate-systems', 'geometry']"
4771608,Solving the differential equation $y'=\frac{3y^2+x}{4y^2+5}$,Ley $y=ƒ(x)$ be the solution of the differential equation $y'=\frac{3y^2+x}{4y^2+5}$ where $y(\frac{15}{4})=0$ then which of the following are correct (A) $y'\ge\frac{3}{4} \forall x\ge \frac{15}{4}$ (B) $\int\limits_{\frac{{15}}{4}}^{\frac{{27}}{4}} {f\left( x \right)dx}  \ge \frac{{27}}{8}$ (C) $\int\limits_{\frac{{15}}{4}}^{\frac{{27}}{4}} {f\left( x \right)dx}  < \frac{{27}}{8}$ (D) $f'(x)\ge 0 \forall x\ge 0$ My approach is as follow $y' = \frac{{3{y^2} + x}}{{4{y^2} + 5}} \Rightarrow y' = \frac{3}{4}\left( {\frac{{4{y^2} + \frac{{4x}}{3}}}{{4{y^2} + 5}}} \right) \Rightarrow y' = \frac{3}{4}\left( {\frac{{4{y^2} + 5 + \frac{{4x}}{3} - 5}}{{4{y^2} + 5}}} \right)$ $ \Rightarrow y' = \frac{3}{4}\left( {\frac{{4{y^2} + 5}}{{4{y^2} + 5}}} \right) + \frac{3}{4}\left( {\frac{{\frac{{4x}}{3} - 5}}{{4{y^2} + 5}}} \right) \Rightarrow y' = \frac{3}{4} + \frac{1}{4}\left( {\frac{{4x - 15}}{{4{y^2} + 5}}} \right)$,"['calculus', 'ordinary-differential-equations']"
4771623,Reference or proof for number of permutations of [2n] with longest increasing subsequence of length n.,In A267433 the result $a(n) \sim 16^n (n-1)! / (\pi e^2)$ is quoted as being from Vaclav Kotesovec with a link to his page . However I can't find the result in any of those papers. Does anyone know a reference or proof for this result?,"['combinatorics', 'asymptotics', 'reference-request']"
4771636,Energy minimization doesn't seem to yield a geodesic,"I'm minimizing (through optimization using gradient descent) the energy $E(\gamma)=\int_{t_1}^{t_2} g_{\alpha\beta}(\gamma^{\alpha})'(\gamma^{\beta})'\operatorname{d}\!t$ of a curve using the inner product induced by the metric tensor. In my case the metric tensor is from information geometry (the Fisher metric) which is very simple for a univariate gaussian. However, given that I'm using the Fisher metric as the metric tensor, I would expect that a geodesic of a univariate gaussian to follow an arc (e.g. shortest path between two univariate gaussian distributions is not a straight line as shown here ). However, after optimizing the curve to minimize the energy, I'm always getting a straight line as distance between two univariate gaussians (using the same start/end points of the linked article from geomstats). Am I missing something ? More details: I'm using a parametrized cubic spline curve (just as in here ), just to give more details about which curve I'm using. Trying to make the question more simple I'm using the following metric (the Fisher metric as linked above) for computing the inner products: $[ 1/scale, 2/scale ]$ (the matrix is 2x2, this is the diagonal, other elements are zero) I have 2 parameters (mean, scale), and as you can see, the metric depends only on the scale. These parameters are parametrizing a univariate gaussian distribution (w/ mean and scale), and it is known that this metric induces an hyperbolic geometry (you can understand this better by looking at this animation , just click and drag and you will see the curve geodesic in the parameter space). (note that y is my scale and x is mean, the dark black arc line is the geodesic, but this is not what I'm getting ) Now, if I minimize $E(\gamma)$ (using gradient descent) to optimize the curve parameters, what I get is a straight line connecting the parameters in the parameter space, while I would expect it to be curved as induced by the metric tensor.","['information-geometry', 'fisher-information', 'differential-geometry']"
4771659,Number of pulsations given an specific keyboard,"I am given a piano that has 88 keys and I am asked to find how many different melodies with 123 pulsations (each pulsation has obviously one key) are there. However, there is a restriction: there has to be exactly one key that does not appear in the melody. My attempt is the following: To begin with, I choose which of the keys does not appear: there are $88$ options. To continue, since each pulsation is different and the keys too (the order is important here), this is the same as looking for the number of surjective applications between a set of $123$ elements and another with the remaining $87$ elements. There are $87!S(123,87)$ of these applications, where $S(n,k)$ is a Stirling number of the second kind. Therefore, using the product rule, there are $88\cdot87!\cdot S(123,87) = 88!\cdot S(123,87)$ different melodies given this restriction. Am I right?","['applications', 'combinatorics', 'discrete-mathematics']"
4771682,On sixth powers $a^6+b^{12}+c^{12} = d^6+e^{12}+f^{12}$?,"To recall, there are infinitely many primitive solutions to, $$a^4+b^8+c^8 = d^4+e^8+f^8$$ such as, $$14805^4 + 86^8 + 149^8  = 18939^4 + 35^8 + 142^8$$ discussed here . This almost violates the Lander-Parkin conjecture (which states that for ESLP with $k>3$ , at least $k$ terms are needed). I. Sixth Powers Going higher, it turns out there are infinitely many primitive solutions to, $$x_1^6+x_2^6+x_3^{\color{blue}{12}} = y_1^6+y_2^6+y_3^{\color{blue}{12}}$$ small ones of which are, $$\; 179^6 + 275^6\, + 6^{\color{blue}{12}} = 276^6 + 65^6 + 13^{\color{blue}{12}}$$ $$111^6 + 230 ^6 + 11^{\color{blue}{12}} = 26^6 + 13^{\color{blue}{12}} + 15^{\color{blue}{12}}$$ To find infinitely more of the first kind, we use the $6$ th-power parameterization with the smallest known degree, the Brudno-Delorme Identity , \begin{align}
a &= -n^4 - n^3 - 5n^2 + 8n + 8\\
b &= (n^3 + 7n - 2)(n + 2)\\ 
c &= 9n^2 + 6n + 12\\
d &= -n^4 + n^2 + 14n + 4\\
e &= -4n^3 - 5n^2 - 8n + 8\\
f &= (n^2 - n + 3)(n + 2)^2
\end{align} which obeys at least three relations, $$a^6+b^6+c^6 = d^6+e^6+f^6$$ $$a^2+b^2+c^2 = d^2+e^2+f^2$$ $$3a+b+c = 3d+e+f$$ To make two of its terms as squares, we simply solve, \begin{align}
9n^2 + 6n + 12 &= \square_1\\[4pt]
n^2 - n + 3 &= \square_2\end{align} starting with initial rational point $n = -13/24.$ Converting this into an elliptic curve , one can then find infinitely more points. II. Question Since, $$a^6 + b^6 + c^{\color{blue}{12}} = d^6 + e^{\color{blue}{12}} + f^{\color{blue}{12}}$$ has at least one non-trivial solution given above, can we in fact also solve, $$a^6 + b^{\color{blue}{12}} + c^{\color{blue}{12}} = d^6 + e^{\color{blue}{12}} + f^{\color{blue}{12}}$$ where $(a,b,c)\neq(d,e,f)$ ?","['computational-mathematics', 'number-theory', 'diophantine-equations']"
4771702,Automorphisms for direct products of finite commutative nilpotent rings.,"Let $(R, +, \cdot)$ be an associative commutative nilpotent ring of cardinality $2^n$ such that $$
r^2 = 0,
$$ for every $r\in R$ . Also $(V, +)$ is a vector space over $\mathbb{F}_2$ .  Let $\operatorname{Aut}(R)$ be a group of ring automorphisms. That is a group of bijective maps $\phi: R\to R $ such taht for every $r,s\in R$ and $*\in \{+, \cdot\}$ $$
\phi(r*s) = \phi(r)*\phi(s).
$$ I want to know how the group of automorphisms for the direct product $$
\underbrace{R\oplus R \oplus\ldots \oplus R}_{k}
$$ is structured. Of course it contains trivial diagonal automorphisms of the form $$
\Phi(r_1, \ldots, r_k) = (\phi_1(r_1), \ldots, \phi_k(r_k)),
$$ where $\phi_i\in \operatorname{Aut}(R)$ .
Also there are automorphisms acting as permutations, that is for $\sigma \in S_k$ $$
\Psi_{\sigma}(r_1, \ldots, r_k) = (r_{\sigma(1)}, \ldots, r_{\sigma(k)}).
$$ But what about more subtle maps? It is interesting how the whole group of automorphisms for $\underbrace{R\oplus R \oplus\ldots \oplus R}_{k}$ is structured. My attempts. I'm trying to start from investigation for $$
R\oplus R
$$ automorphisms. Let $\phi$ be such automorphism. Then since $\phi$ is $+$ automorphism there exist $\alpha, \beta, \gamma, \delta \in \operatorname{Hom_+}(R,R)$ such that $$
\phi(x,y) = (\alpha(x) + \beta(y), \gamma(x) + \delta(y)),
$$ (this is usual matrix product). Then since $\phi$ preserves multiplication we have $$
\phi(xz,yt) = \phi(x,y)\phi(z,t),
$$ for arbitrary $x,y,z,t\in R$ .
Combining this with the above equality and using the fact that we working in vector space over $\mathbb{F}_2$ we can obtain that $\alpha,\beta, \gamma, \delta$ are also multiplicative homomorphisms. Then $\phi$ is automorphism if and only if for all $x,y,z,t\in R$ we have $$
\begin{array}{l}
\alpha(x)\beta(t) = \beta(y)\alpha(z) \\
\gamma(x)\delta(t) = \delta(y)\gamma(z) \\
\end{array}
$$ and $\phi$ is bijection.
Next, I'm stuck.","['automorphism-group', 'finite-groups', 'ring-theory', 'abstract-algebra', 'linear-algebra']"
4771723,Can we find a periodic function $f$ with a non-zero smallest period such that $f(x^2)$ is also periodic?,"Let $f$ be a periodic function such that it has a (non-zero) fundamental period (Smallest nonzero period). Can 
 $f(x^2)$ also be periodic? So the constant functions and Dirichlet function are not examples we want here. If $f$ is continuous, then it is impossible, because $f(x^2)$ fails to be uniformly continuous.",['real-analysis']
4771725,Universality of Hecke algebra of a finite group,"I am solving an assignment problem on the Hecke algebra of a finite group, and looking for an idea that might help find a right direction. Given a pair of finite groups $G\geq K$ , the Hecke algebra $\mathcal{H}_{G,K}$ can be defined as $$ \mathcal{H}_{G,K} = \mathbb{C}[K\backslash G/K], $$ equipped with the convolution product s.t. $\delta_{KgK} \cdot \delta_{KhK} = \sum_{k\in K}\delta_{K(gkh)K}.$ Given a representation $\pi:G\to \mathrm{GL}(V)$ , it is straightforward that $\mathcal{H}_{G,K}$ acts on the space $V^K$ of $K-$ invariants $$ V^K = \{v\in V : \pi(k) v = v, \; \forall k\in K\}. $$ The question is to figure out in what sense $\mathcal{H}_{G,K}$ acts ""in a universal way"" to $V^K$ , given the hint that one may invoke Frobenius reciprocity. However, I have no idea to proceed on. Am I supposed to formulate the answer in terms of the usual categorical notion of universal property? What aspects of $\mathcal{H}_{G,K}$ should I ponder on? Any kind of instruction will be greatly appreciated.","['group-theory', 'abstract-algebra', 'representation-theory', 'hecke-algebras']"
4771744,Fourier transform of $\frac{1}{|x|}$ on $\mathbb{T}^{n}$,"Let $|x|=\sqrt{x_1^2+\cdots+x_n^2} ~$ for $~x\in\mathbb{T}^n=[-\frac{\pi}{2},\frac{\pi}{2}]^n$ , $~n\geq 2$ . We can define the Fourier transform of $f(x)=\frac{1}{|x|}$ as $$ \hat{f}(k)= \int_{\mathbb{T}^n}\frac{e^{2ik\cdot x}}{|x|} dx$$ for $k\in\mathbb{Z}^n$ , since $f\in L^{1}(\mathbb{T}^n)$ if $n\geq 2$ . My question: is $\hat{f}\in l^{p}(\mathbb{Z^n})$ for $p=1$ , or other possible value of $p$ ? By Haursdorff-Young's inequality, we can partially answer this question. But I want some refined estimates. Another related function is $g(x)=\frac{1}{w(x)}$ , where $$ w(x)=\sqrt{\sin^{2}\left({x_1}\right)+\sin^{2}\left({x_2}\right)+\cdots+\sin^{2}\left({x_n}\right)}.$$ And I have the same question to $\hat{g}$ . In my point of view, the property of $\hat{g}$ is more important. If we can obtain the sharp upper decay of $\hat{f}$ or $\hat{g}$ , or we can prove that $\hat{g}\in l^1(\mathbb{Z^n})$ , that will be excellent.","['fourier-analysis', 'harmonic-analysis', 'fourier-transform', 'analysis', 'fourier-series']"
4771747,Measurability of indicator of two hitting times at the stopped $\sigma$-algebra,"Let $\mathcal{F}$ be the complete filtration generated by the Brownian motion $B$ , and let $a<0<b$ . Define the stopping times $\tau_a=\inf\{t\ge 0|B_t=a\}$ and $\tau_b=\inf\{t\ge 0|B_t=b\}$ .
Then is the indicator $1_{\tau_b<\tau_a}$ measurable with respect to $\mathcal{F}_{\tau_b}$ ? The claim holds if one of $\tau_a$ and $\tau_b$ is replaced by a deterministic time. Does the claim hold with the hitting times? Intuitively, if we know the history of $B$ up to the time once it first hits $b$ , when should know whether it already hits $a$ or not, right?","['measure-theory', 'stopping-times', 'brownian-motion']"
4771772,"Convexity of a connected, compact, and locally convex set in $\mathbb{R}^n$","Is a compact, connected, and ""locally convex"" set in $\mathbb{R}^n$ convex? Here I mean a space $A$ locally convex as: For any point $x\in A$ , there exists a neighborhood $U$ of $x$ s.t. $U$ is convex. This question comes from a conversation with my friend, and we cannot find a way to prove or disprove it since we know few techniques regarding convexity.
Things we have noticed are: Compactness cannot be deleted because annulus in $\mathbb{R}^2$ without boundary points is a counterexample. Connectness cannot be deleted because separated open disks in $\mathbb{R}^2$ is a counterexample. Besides this, we obtain few results. It would be appreciated if someone could provide related texts or techniques.","['convex-geometry', 'general-topology', 'locally-convex-spaces']"
4771823,Le poisson modulo un,"I found this image and you can see a cut fish and the words "" Le poisson modulo un "", meaning ""the fish modulo $1$ "". I wanted to ask what this means, if it is a joke or a metaphor. Also, this image was linked with the words: ""An illustration for $\mathbb{R}/\mathbb{Z}$ "".","['art', 'group-theory']"
4771875,"All terms of the sequence are ""$x^2+(x+1)^2$""","Let $a_1=1$ , $a_2=13$ , and $a_{n+2}=14a_{n+1}-a_n$ for $n\in\Bbb N$ . Prove that for all $a_i$ , there exists $x\in\Bbb N$ such that $a_i=x^2+(x+1)^2$ . I listed the first few terms: $$\begin{aligned}
a_1&=0^2+1^2,\\
a_2&=2^2+3^2,\\
a_3&=9^2+10^2,\\
a_4&=35^2+36^2,\\
a_5&=132^2+133^2,\\
&\cdots
\end{aligned}$$ If we can find the pattern of $0$ , $2$ , $9$ , $35$ , $132\dots$ , induction would easily work. But I see no pattern here.","['algebra-precalculus', 'recursion', 'sequences-and-series']"
4771902,Count permutations with given longest increasing subsequence,"Problem: Given $n \in \mathbb{Z}_+$ and a set $A \subset \{ 1,\ldots,n \}$ sorted in ascending order, find the number of permutations $\sigma \in S_n$ such that $A$ is a longest increasing subsequence of $\sigma$ . ( $A$ need not be the only longest increasing subsequence of $\sigma$ .) A solution might be expressed as a formula or an algorithm. This question is inspired by this puzzle on Puzzling SE . Can you get a solution efficient enough to answer that question? Clearly, checking all $n!$ permutations is out of the question, as each one requires $O(n\log n)$ time by a clever Patience Sort algorithm (or $O(n^2)$ by dynamic programming).","['permutations', 'combinatorics', 'algorithms', 'sequences-and-series']"
4771911,Is this property of flat morphisms accurate?,"In Lazarsfeld's Positivity 1, pg. 246, the following is stated: If $f: X \to Y$ is a flat mapping of schemes, with $Y$ integral and $X$ generically reduced, then $X$ must be everywhere reduced. This seems wrong to me. For example, take $Y = \operatorname{Spec} k$ and $X$ any generically reduced, but non-reduced, $k$ -scheme. (For example, introduce nilpotents to a closed point on a positive dimensional integral $k$ scheme. ) However, this is true if the map is assumed to be finite, and $X$ is assumed to be irreducible. A justification is recorded below. Let's look locally so that $f$ is induced by $A \hookrightarrow B$ , a flat finite extension of rings. We claim there is some $\delta \in A$ so that $B_\delta$ is reduced. To see this, we just need to show that if $V \subset \operatorname{Spec} B$ is the reduced locus, there is some nonempty open subset $U$ of $\operatorname{Spec} A$ so that $f^{-1}(U) \subset V$ . To this end, let $K = \operatorname{Spec} B - V$ . Since $\operatorname{Spec} B$ is irreducible, this is strictly of lower dimension than $B$ . Hence, $f(K) \subset \operatorname{Spec} A$ is a strict closed subset, so its complement is the set $U$ we're looking for. Once we have this $\delta \in A$ so that $B_{\delta}$ is reduced, an argument in the book (pg. 246) shows that $B$ is reduced. Is the linked claim as false as I suspect it is? Also, is there a way to prove this when $X$ is not irreducible, or are there counterexamples in this case too?","['algebraic-geometry', 'commutative-algebra']"
4771915,A characterization of closure of a certain class of sets in $\mathbb{R}^n$,"Consider a set $K\subset \mathbb{R}^n$ that is symmetric ( $B = -B$ ) and verifies $aK\subset bK$ if $|a|<|b|$ . Can I conclude that $\overline{K} = \cap_{a>1}aK$ ? If not, does the result hold assuming extra properties, like $K$ being convex? Thoughts: when drawing it in the plane it seems pretty clear. I know this is not the best argument, but I don't think this is something that depends on dimension, so I think working in $\mathbb{R}^n$ would suffice. It seems a good idea to me to use that $x\in \overline{K} \iff d(x,K) = 0$ , but I am not sure of how to write the proof. I also am interested if the property holds in general normed vector spaces.","['normed-spaces', 'topological-vector-spaces', 'analysis', 'real-analysis', 'general-topology']"
4771922,Is $a_n=\ln(n)/\sqrt n$ increasing or deacreasing,How do we proving that: $$\forall n\ge 9 : a_n = \frac{\ln(n)}{\sqrt n}$$ increasing or decreasing My methode Let : $f(x)=\frac{\ln x}{\sqrt x} $ where $ x \ge 9$ $$f'(x)=\frac{\frac{\sqrt x}{x}-\frac{\ln x}{2\sqrt x}}{x}=\frac{1}{x^2}\left({\sqrt{x} - \frac{1}{2}\sqrt{x}\ln x}\right)$$ We have : $$x \ge 9 \implies f'(x) \le 0$$ therefore : $f(x)$ decreasing Finally: $a_n$ decreasing $\forall n\ge 9$ My question: are another way method ? I appreciate your interest,"['sequences-and-series', 'analysis', 'real-analysis']"
4771969,Modeling the probability of $k$-mer collisions between DNA sequences,"Let's imagine that I have a DNA sequence of known origin. Such a sequence can simply be thought of as a string of characters $(A|C|G|T)^l$ where $l$ is the length of the sequence. For purposes of this problem, we can also convert any sequence into a set of distinct $k$ -mers where $k$ is the length of a substring (e.g. 'ATGGT' is a $5$ -mer). Such a set could be defined as $\{x\in (A|C|G|T)^k |~x$ is a substring in the sequence $\}$ Now, imagine that we generate a completely random string of characters $(A|C|G|T)^m$ where $m$ is the length of this random sequence and $m<<l$ . For simplicity, we can assume that the chance of each character is equal. Once again, I can convert this random string of characters into a set of distinct $k$ -mers with the same $k$ as before. Finally, to the problem: I'd like to model the probability that I observe a particular number of shared $k$ -mers or more between the random sequence and the known one. For example, let's say that I am using $k=20$ and have a known sequence with $4,500,000$ distinct $20$ -mers. Next, I generate a random sequence of $m=500$ . Such a sequence has at most $500-20+1=481$ distinct $20$ -mers (although it could be less, let's assume that it actually has 481) and I observe that $10$ of these $481$ $20$ -mers are in the known sequence. What is the probability that $10$ or more $k$ -mers are shared with the known sequence? My original intuition: Much like a classic experiment to test for the fairness of a coin, this could be modeled with a Binomial distribution. The known sequence has $4,500,000$ out of the total $4^{20}$ possible $20$ -mers. This would give us our value of $p$ ( $p=\frac{4500000}{4^{20}}$ ). The ""number of trials"" $n$ in this case is the number of distinct $20$ -mers in the random sequence. Therefore, this could be modeled with $B(n=481, p\approx 0.00000409272)$ . The probability of observing $10$ or more collisions is more or less obvious after that point. The issue: For 1 extremely obvious reason I can think of, I cannot assume that the trials within my Binomial model are independent: Logically, each distinct $k$ -mer overlaps substantially with $k$ -mers on either side of it within the string. (e.g. If 'ATGGT' is within either sequence 'TGGTX' where $X \in \{A, C, G, T\}$ must be there as well, assuming that the first $5$ -mer was not at the end of my sequence) This leads me at last to my actual question: Is there a better way of modeling this problem statistically? (E.g a better distribution to use or a different way entirely)","['biology', 'statistics', 'probability-distributions', 'probability-theory']"
4772086,"Group formed on Parabola similarly to how an Elliptic curve forms a group (by drawing lines, circles, intersecting, or taking tangent lines)","There's probably other ways of doing this, but I've found this to be the simplest way (group law) that does indeed work: To add points $A, B \in \{(x, f(x)) : x \in \Bbb{C}\} = G$ where $f$ is any parabola with vertex $E \in G$ , we treat $E$ as zero.  Now draw a line between $A, B$ and then draw a parallel line to this line that passes through $E$ .  The unique intersection point (other than $E$ , unless of course $A = B = E$ or $A = -B$ ) is then the value of the group law. I've checked all the axioms of a group using Geogebra.  This also works on a circle if I recall correctly. I'm wondering: How do we express $AB$ the abelian group law algebraically?","['elliptic-curves', 'geometric-construction', 'conic-sections', 'abstract-algebra', 'group-theory']"
4772108,Element of order $p + 1$ in $\mathrm{GL}_2(\mathbb{F}_p)$,"Is there a way to explicitly construct a matrix of (multiplicative) order $p + 1$ in $\mathrm{GL}_2(\mathbb{F}_p)$ ? I am aware that by considering the cyclic multiplicative group $\mathbb{F}_{p^2}^\times \subseteq \mathrm{GL}_2(\mathbb{F}_p)$ , there is in fact a matrix of order $p^2 - 1$ , which gives us a matrix of order $p + 1$ (see e.g. this ). However, this method is not exactly constructive, and I wonder if there's an easier way to get one of order $p + 1$ .","['matrices', 'finite-fields', 'linear-algebra']"
4772168,What is the motivation for Besov spaces?,I am trying to understand the definition of Besov spaces. With such a complicated definition I wonder what is the motivation behind them and why are they so often used in PDE? What advantage do they give over Sobolev spaces? Are there any nice (hopefully short) references that introduce them?,"['function-spaces', 'besov-space', 'functional-analysis', 'partial-differential-equations']"
4772181,"Prove that $\forall P$, $Q \in \mathbb{B}.$ $(P \Rightarrow Q) \Leftrightarrow(\neg P \vee Q)$ without using truth table","Prove that $\forall P$ , $Q \in \mathbb{B}.$ $(P \Rightarrow Q) \Leftrightarrow(\neg P \vee Q)$ without using truth table The grader says that my proof below is wrong: “To prove an iff statement, you should prove from two directions instead of cases. In this question, you need to prove $(P \Rightarrow Q) \Rightarrow (\neg P \vee Q)$ AND $(\neg P \vee Q) \Rightarrow (P \Rightarrow Q).$ ” I don't think that the grader is right about my approach. Is my proof correct or wrong? To prove that $(P \Rightarrow Q)$ and $(\neg P \vee Q)$ are equivalent, we first consider the ways for the equivalence to fail; there are two such cases: Case 1. Suppose that $(P \Rightarrow Q)$ is true and $(\neg P \vee Q)$ is false. In this case, since $(\neg P \vee Q)$ is false, $Q$ and $\neg P$ must all be false, which means that $P$ is true. So, $P$ is true and $Q$ is false, which means that $(P \Rightarrow Q)$ is false, which contradicts our statement. So Case 1 is impossible. Case 2. Suppose that $(P \Rightarrow Q)$ is false and $(\neg P \vee Q)$ is true. In this case, since $(P \Rightarrow Q)$ is false, we know that $P$ is true and $Q$ is false. So, $\neg P$ is false. Since both $\neg P$ and $Q$ are false, $(\neg P \vee Q)$ is false, which contradicts our statement. Thus, Case 2 is also impossible. Since the only two cases for the equivalence to be false are impossible, we  conclude that for all $P$ , $Q \in \mathbb{B}.$ $(P \Rightarrow Q) \Leftrightarrow(\neg P \vee Q).$","['solution-verification', 'logic', 'discrete-mathematics']"
4772222,"Why $\operatorname{Proj}\mathbb{Z}[x,y,z]/(y^2z+yz^2-x^3+xz^2)$ is fibered surface over $\operatorname{Spec}\mathbb{Z}$?","I am reading the Liu's Algebraic Geometry and arithmetic curves, p.348, Example 3.2. and stuck at some point. Definition 3.1 ( In his book p.347 ). Let $S$ be a Dedekind scheme. We call an integral, projective, flat $S$ -scheme $\pi : X \to S$ of dimension $2$ a fibered surface over $S$ . The generic point of $S$ will be denoted by $\eta$ . We call $X_{\eta}$ the generic fiber of $X$ . A fiber $X_s$ with $s\in S$ closed is called a closed fiber . When $\operatorname{dim}S=1$ , $X$ is called a projective flat $S$ -curve (see Lemma  3.3). Note that the flatness of $\pi$ is equivalent to the surjectivity of $\pi$ . (C.f. Fibered surface is flat if and only if it surjects onto the base ) We will say that $X$ is normal (resp. regular ) fibered surface if $X$ is normal (resp. regular). Example 3.2. Let $S:= \operatorname{Spec}\mathbb{Z}$ and $X:=\operatorname{Proj}\mathbb{Z}[x,y,z]/(y^2z+yz^2-x^3+xz^2)$ . Let us show that $X$ is a normal fibered surface. The only point needing verification is that $X$ is normal. ( Next argument for showing normality is omitted ). I don't understand why the bold statement is true. $X$ is integral, projective scheme (over $S$ ). My question is, for $X$ to become fibered surface over $S$ , Q.1. Why $X$ has dimension $2$ ? EDIT : First attempt to the first question. Note that by the Liu's book, p.53, Lemma 3.41, letting $I :=(f(x,y,z):=y^2z+yz^2-x^3+xz^2)$ , $ \operatorname{Proj}\mathbb{Z}[x,y,z]/I$ is isomorphic to a closed subscheme of $\mathbb{P}^{2}_{\mathbb{Z}}$ , with support ( i.e., with underlying topological space) $V_{+}(I)$ . So, $\dim \operatorname{Proj}\mathbb{Z}[x,y,z]/I = \dim V_{+}(I)$ and it suffices to show that $\dim V_{+}(I)=2$ . First note that $V_{+}(I)$ is a proper closed subset of $\mathbb{P}^{2}_{\mathbb{Z}}$ (True?). So, $$  \dim V_{+}(I) < \dim \mathbb{P}^{2}_{\mathbb{Z}} = \dim Z + 2 = 3 .$$ so that $\dim V_{+}(I) \le 2$ . So it suffices to show that $ 2 \le \dim V_{+}(I)$ . Now I arrange some preliminary definitions for showing this. We set $A_{+} := \oplus_{d \ge 1} A_d$ . This is a graded ideal. More generally, if $I \subseteq A$ is a homogeneous ideal, we set $I_{+} := I \cap A_{+}$ . This is again a homogeneous ideal. A homogeneous prime ideal $\mathfrak{p} \subset A$ is called relevant if it does not contain $A_{+}$ , i.e., if $\mathfrak{p}_{+} \subsetneq A_{+}$ . Proposition 13.4. (Gortz's Algebraic Geometry, p.369) Let $A$ be a graded ring. For a subset $Y \subseteq \operatorname{Proj}A$ define $$ I_{+}(Y) := (\cap_{\mathfrak{p} \in Y} \mathfrak{p}) \cap A_{+}.$$ (2) The maps $Y \mapsto I_{+}(Y)$ and $I \mapsto V_{+}(I)$ define mutually inverse, inclusion reversing bijections between the set of homogeneous ideals $I \subseteq A_{+}$ such that $I=\operatorname{rad}(I)_{+}$ and the set of closed subsets of $\operatorname{Proj}A$ . Via this bijection, the closed irreducible subsets correspond to ideals of the form $\mathfrak{p}_{+}$ , where $\mathfrak{p}$ is relevant prime ideal. Note that $\mathbb{Z}[x,y,z]_{+} = (x,y,z)$ (True?). And note that the above $I$ is homogeneous relevant prime ( In fact $I$ is a prime ideal since $f(x,y,z):=y^2z+yz^2-x^3+xz^2$ can be viewed as $-x^3 + z^2 x + (y^2z +yz^2) \in \mathbb{Z}[y,z][x]$ and applying the Eisenstein's Criterion ) ideal of $\mathbb{Z}[x,y,z]$ such that $I = I \cap \mathbb{Z}[x,y,z]_{+} =: I_{+}$ . So we have $I = I_{+}(V_{+}(I))$ . Note that if we can find two relevant prime ideal $\mathfrak{p}_1$ , $\mathfrak{p}_2$ such that $$I = I_{+}(V_{+}(I)) \subsetneq \mathfrak{p}_{1, +} \subsetneq \mathfrak{p}_{2, +}$$ ,
then by the above inclusion reversing bijection, we obtain chain of closed irreducible subsets $$ V_{+}(\mathfrak{p}_{2, +}) \subsetneq V_{+}(\mathfrak{p}_{1, +}) \subsetneq V_{+}(I) .$$ ( $\divideontimes$ If $C \subseteq X$ is closed and $F \subseteq X$ is closed irreducible subset in $X$ such that $F \subseteq C$ , then $F$ is closed irreducible in $C$ . ) And so we have $ 2 \le \dim V_{+}(I)$ . And we really can find such $\mathfrak{p}_1$ , $\mathfrak{p}_2$ ? Is it possible? EDIT : Yes. It seems possible. Let $\mathfrak{p}_1 := (f, x,z)$ and $\mathfrak{p}_2:= (f,x,z,7y,7)$ where $f(x,y,z):=y^2z+yz^2-x^3+xz^2$ . Such ideals may works. C.f. Are there homogeneous prime ideals $p_1 , p_2 \nsupseteq (x,y,z)$ such that $I:=(y^2z+yz^2-x^3+xz^2) \subsetneq p_{1,+} \subsetneq p_{2,+}$? . Q.2. why $X$ is flat over $S$ ? Or equivalently (as the bold statement in the above definition 3.1.), why $X$ is surjective over $S$ ? Here I think that the morphism $\pi : X\to S$ is as : What is explicit description of the structure morphism $\operatorname{Proj}A \to \operatorname{Spec}R$? . EDIT : First attempt for the question 2 : I tried to show the flatness of $X$ over $S$ directly. Note https://stacks.math.columbia.edu/tag/01U5 and https://stacks.math.columbia.edu/tag/0AUW . From these, it sufficient to show that there is an open cover $X = \pi^{-1}(S) = \cup_{ i \in I} U_i$ such that $\mathbb{Z} = \mathcal{O}_S(S) \to \mathcal{O}_X(U_i)$ is torsion free for all $i\in I$ . In particular, note that $X = \cup _{i \in I} D_{+}(f_i)$ where $f_i$ is homogeneous elements of $A_{+}$ where $A:= \mathbb{Z}[x,y,z]/(y^2z+yz^2-x^3+xz^2)$ . My question is, the induced ring maps $\mathbb{Z} = \mathcal{O}_S(S) \to \mathcal{O}_X(D_{+}(f_i)) = A_{(f_i)}$ is torsion free ? If so we are done. Second attempt for the question 2 : I tried to show the surjectivity of the $\pi : X \to S$ which is equivalent to the flatness, as I mentioned above. As I linked What is explicit description of the structure morphism $\operatorname{Proj}A \to \operatorname{Spec}R$? , the $\pi : X \to S$ is constructed from glueing next morphisms ( $f\in A_{+}$ homogeneous elements ) $$\psi_{f} : D_{+}(f) \xrightarrow{\cong} \operatorname{Spec}A_{(f)} \xrightarrow{^al_f} \operatorname{Spec}A_{0}= \operatorname{Spec}\mathbb{Z}$$ , where $l_f : A_0 \to A_{(f)}$ be the natural map $a \mapsto \frac{a}{1}$ . Note that $A_0 = \mathbb{Z}/(I\cap \mathbb{Z}) = \mathbb{Z}$ . To show the surjectivity of $\pi$ , let $(p)$ be a prime ideal of $\mathbb{Z}$ . Then, my question is, "" does there exists homogeneous element $ f\in A_{+}$ and there exists $\mathfrak{q} \in \operatorname{Spec}A_{(f)}$ such that $^a l_f (\mathfrak{q}) = l_f^{-1}(\mathfrak{q}) = \{n \in A_0=\mathbb{Z} : \frac{n}{1} \in \mathfrak{q} \} = (p)$ . ""
? Assume that $\{n \in A_0=\mathbb{Z} : \frac{n}{1} \in \mathfrak{q} \} = (p)$ is true for some $f$ and $\mathfrak{q}$ . Then If $np \in  (p)$ , then $\frac{np}{1} \in \mathfrak{q}$ . If $n\in l_f^{-1}(\mathfrak{q})$ so that $\frac{n}{1}\in \mathfrak{q}$ , then $n \in (p)$ From these, can we guess such $f \in A_{+}$ and $\mathfrak{q}$ ? Can any one provide such $f \in A_{+}$ and $\mathfrak{q}$ ? Third attempt for the question 2 : Now I'm trying to show the sujectivity of $\pi :X \to S$ in other direction, helped from below hint of Aphelli. Let $s= (p) \in S:= \operatorname{Spec}\mathbb{Z}$ . It suffices to show that $\pi^{-1}(s) \neq \varnothing$ . Note that by the Liu's Algebraic geometry book, p.82, Proposition 3.1.9., we have ( $I:= (y^2z+yz^2−x^3+xz^2)$ ) $$ \pi^{-1}(s) \cong \operatorname{Proj}(\mathbb{Z}[x,y,z]/I) \times _ {\operatorname{Spec}\mathbb{Z}}\operatorname{Spec}k(s) \cong \\ \operatorname{Proj}(\mathbb{Z}[x,y,z]/I \otimes_{\mathbb{Z}} k(s)) \cong \operatorname{Proj}( k(s)[x,y,z]/Ik(s)[x,y,z]) \cong V_{+}(Ik(s)[x,y,z]) \subseteq \mathbb{P}^{2}_{k(s)}$$ ( C.f. The final isomorphism is true by the Liu's Lemma 2.3.41 (p.53). For the third isomorphism, see Quotients and extensions of scalars in polynomial algebras . True? ) Note that $k(s) = \mathbb{Q}$ when $p=0$ and $k(s)=\mathbb{Z}/(p)$ when $p$ is prime number. So we can view the $Ik(s)[x,y,z]$ as the principal ideal generated by $f(x,y,z):= y^2z+yz^2-x^3+xz^2$ whose coefficients are  viewed as in $\mathbb{Q}$ or $\mathbb{Z}/(p)$ . If this polynomial is irreducible over $\mathbb{Q}$ and $\mathbb{Z}/(p)$ , then $V_{+}(Ik(s)[x,y,z]) \subseteq \mathbb{P}^{2}_{k(s)}$ is of codimension $1$ by the following thorem (Gortz's Algebraic Geometry, Corollary 5.42 ) so that it is nonempty so that $\pi^{-1}(s)$ is nonempty and we are done Corollary 5.42. Let $Z\subseteq \mathbb{P}^n_{k}$ be an integral closed subscheme. Then $Z$ is of codimension $1$ if and only if $Z=V_{+}(f)$ for an 'irreducible' homogeneous polynomial $f$ . Q. And $f(x,y,z)$ is irreducible over $\mathbb{Q}$ and $\mathbb{Z}/(p)$ ? Fourth attempt for the question 2 : Through communicating with Liu, I noticed that we may use next theorem ( Corollary 4.3.10 in Liu's book ) : Corollary 4.3.10. Let $Y$ be a Dedekind scheme, and $f:X\to Y$ be a non-constant morhpism ( i.e., $f(X)$ is not reduced to a point ) with $X$ integral. Then $f$ is flat. So, my question is, the above $\pi : X \to S$ is non-constant? Is there any criteria for the non-constancy of a morphism ? P.s. I am struggling with this issue for few hours. It will be appreciate for someone who can give a any crucial hint. Can anyone helps?",['algebraic-geometry']
4772292,Find the minimum positive value that $(f(x)-g(x)+3)$ may attain.,"Let $f:\mathbb R\to \mathbb R$ be two non-constant differentiable functions. If $f'(x)-g'(x)=g'(x)(f(x))^2-f'(x)(g(x))^2$ for all $x\in\mathbb R$ and $f(1)=1, g(1)=\frac13$ and if there is no $x$ for which $f(x)=-2$ or $g(x)=2$ then find the minimum positive value that $(f(x)-g(x)+3)$ may attain. My Attempt: $f'(x)(1+(g(x)^2)=g'(x)(1+(f(x))^2)$ $\frac{f'(x)}{1+(f(x))^2}=\frac{g'(x)}{1+(g(x))^2}$ $\big[\arctan(f(x))\big]_1^x=\big[\arctan(g(x))\big]_1^x$ $\arctan(f(x))-\arctan1=\arctan(g(x))-\arctan\frac13$ $\arctan(f(x))-\arctan(g(x))=\arctan1-\arctan\frac13=\arctan\frac12$ Not sure what to do next. Perhaps the answer is $2√5-1$ .","['contest-math', 'calculus', 'ordinary-differential-equations']"
4772326,"Does sequence of monomials form a Frame in $L^2[0,1]$?","A sequence $(x_n)_{n \in \mathbb{N}}$ is said to be Frame, if there exist constants $A,B > 0$ such that $$ A \lVert x \rVert^2 \leq \sum_{n=0}^{\infty} \lvert (x,x_n) \rvert^2 \leq B \lVert x \rVert^2$$ for all $x \in H$ . Consider the Hilbertspace $L^2[0,1]$ endowed with the Lebesgue measure and the sequence of monomials, i.e. the functions $x_n(t) = t^n, t \in [0,1], n \in \mathbb{N}$ . Using Hilbert's inequality one can verify that $(x_n)_{n \in \mathbb{N}}$ fulfills $$\sum_{n=0}^{\infty} \lvert (f,x_n)\rvert^2 \leq B \lVert f \rVert^2$$ for all $f \in L^2[0,1]$ . Furthermore it is a consequence of Lusin's theorem that the span of $(x_n)_{n \in \mathbb{N}}$ is dense in $L^2[0,1]$ . My question is if $(x_n)_{n \in \mathbb{N}}$ is a frame, that is it fulfills the lower frame bound. Since I have no idea from what I could infer a lower bound, my first thought was that it is not a frame. Since a frame provides expansions of the form $$ f = \sum_{n=0}^{\infty}a_n x^n$$ with complex coefficients $a_n$ where the series converges unconditionally and hence also in $L^2$ -norm, I'm trying to find a $f \in L^2[0,1]$ which does not have a power series expansion of this form. Is this true or is $(x_n)_{n \in \mathbb{N}}$ a frame after all (or something inbetween, since the latter statement, if false, does not imply that $(x_n)_{n \in \mathbb{N}}$ is a frame).","['frame-theory', 'polynomials', 'functional-analysis']"
4772330,Decoupling $n$ Gaussian random variables using linear algebra,"For a bivariate normal distribution $\begin{pmatrix} X \\ Y \end{pmatrix}$ with mean $\begin{pmatrix} \mu_X \\ \mu_Y\end{pmatrix}$ and variance $\begin{pmatrix} \sigma_X^2 & \rho \sigma_X \sigma_Y \\ \rho \sigma_X \sigma_Y & \sigma_Y^2\end{pmatrix}$ , we can turn these into a pair of independent random variables by rewriting (for example) $Y$ as a linear function of $X$ so that the covariance will be $0$ . So letting $Y = aX + Z$ , we require $\text{cov}(X, Y - aX) = 0 \Rightarrow a = \frac{\sigma_X}{\sigma_Y}\rho$ and then $Z = Y - \frac{\sigma_X}{\sigma_Y}\rho X$ and $Y$ are uncorrelated. It's now easier to carry out calculations. To make things even nicer we can also standardise these variables. I want to now extend this reasoning to higher dimensions, for example three Gaussian random variables in a multivariate Gaussian distribution. How can I rephrase my above argument in terms of matrices and linear algebra? Including the standardisation step. How can I use that rephrasing to extend this to general multivariate Gaussian?","['statistics', 'normal-distribution', 'linear-algebra', 'linear-transformations', 'probability']"
4772331,"Let $S$ be a finite set of real numbers, and let $T$ be the set of all $n\times n$ matrices having entries in $S$.","Let $S$ be a finite set of real numbers, and let $T$ be the set of all $n\times n$ matrices having entries in $S$ . Prove that $$\sum\limits_{A\in T}\mbox{trace}(A^2)=\sum\limits_{A\in T}(\mbox{trace}(A))^2$$ Here I tried to proceed with the eigenvalue but since $A$ is real matrix eigenvalues many not be real. In that case, how we can prove the result","['trace', 'linear-algebra']"
4772386,Markov Process with time varying transition probabilities.,"I am interested in studying the evolution of a variable $\alpha_t\in [0,1]$ governed by the following stochastic dynamical system: $$
\begin{cases}
\alpha_0\in [0,1]\\ 
\alpha_{t+1}=\frac{t+1}{t+2}\alpha_{t} + \frac{1}{t+2}W_t\\
W_t\sim Bernoulli(P(\alpha_{t})) 
\end{cases}
$$ where $P:[0,1]\to[0,1]$ is a continuous decreasing function such that $P(0.5)=0.5$ and there exist $0<a<1/2<b<1$ such that $P(x)=1$ for $x\in [0,a]$ and $P(x)=0$ for $x\in [b,1]$ . A qualitative study of the system reveals that $\alpha_t$ will be eventually bound in $[a,b]$ . At the same time, I would like to have a more precise prediction about the asymptotic behavior of $\alpha_t$ . Running all sorts of simulation, one has that asymptotically $$\alpha_t\to 1/2$$ This is somewhat intuitive because, for a very large $T$ we have $\frac{T+1}{T+2}\approx 1$ and $\frac{1}{T}\approx 0$ and $P(1/2)=1/2$ . Hence, the system moves with equal probability infinitesimally to the left or infinitesimally to the right. My limited knowledge of stochastic dynamical systems prevents me from proving formally $$\alpha_t\xrightarrow{prob.}1/2$$ I would like to know if there is a way. My attempts so far are: a) Observe that $$\alpha_T=\frac{1}{T+1}\alpha_0+\frac{\sum_{i=0}^{T-1}W_t}{T+1}$$ hence, for $T\to\infty$ the first term drops, while the second may be evaluated via a weak law of large numbers. The point is that, not only variables $W_t$ are all correlated, but also they are not identically distributed. Hence, I do not know any law of large numbers to apply here. In particular, while the covariance between the $W_t$ should go to zero, they do not have fixed mean and variance and I cannot apply the law for weakly stationary processes. b) Try to study the evolution of $\alpha_t$ considering a Markov process on an extended state space, namely allowing the state to be $$(t,\alpha_t,w_t)\in\mathbb{N}\times[0,1]\times\{0,1\}$$ with transition specified by the following Markov kernel $$(t,\alpha_t,w_t)\in\mathbb{N}\times[0,1]\times\{0,1\}\mapsto\delta_{t+1}\otimes \{P(\alpha_t)\delta_{\frac{(t+1)\alpha_t+1}{t+2}}+(1-P(\alpha_t))\delta_{\frac{(t+1)\alpha_t}{t+2}}\}\otimes \{P(\alpha_t)\delta_{1}+(1-P(\alpha_t))\delta_{0}\}\in\Delta(\mathbb{N}\times[0,1]\times\{0,1\})$$ where $\otimes$ denotes the independent product of measures. I don't really know how to study such a Markov process, as my knowledge is limited to simpler cases. In particular, beside the complicated state space, the point is that starting from the same $\alpha$ at two different times $t,t'$ the support of the probability distribution describing the transitions from this point is different from time $t$ to time $t'$ . Any help would be more than welcome.","['measure-theory', 'markov-chains', 'stochastic-processes', 'probability-theory', 'probability']"
4772392,Empirical distribution learns w.r.t total variation distance,"I am trying to prove or disprove that the empirical distribution can learn any continuous distribution w.r.t the total variation distance. The context is the one of statistical learning. I am quite sure that the proposition is false, but I might likely be wrong. I have looked online and into some books, but I couldn't find a similar formulation for the problem, so if you know some literature  that would also be appreciated. (edit: as pointed out in the comment, the distance I am defining here coincides with the total variation distance in this context.) I am considering distributions on the real numbers and the set $$ \mathcal F = \{ g \in \mathcal C^b(\mathbb R) \ \mid \ \lVert {g}\rVert_\infty \leq 1 \} $$ and the corresponding F-divergence $$ d_\mathcal F (\mu \mid \nu ) = \sup_{g \in \mathcal F} \Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\nu \  \Big |  .$$ I need to prove (or negate) the following: For any $\mu$ continuous probability distribution, given i.i.d samples $X_1, \dots , X_n$ from $\mu$ , prove that the empirical distribution $\tilde \mu _n = \frac{1}{n} \sum_{i=1}^n \delta_{X_i} $ converges in probability to $\mu$ w.r.t $d_\mathcal F $ , i.e. $$ P( d_\mathcal F (\mu \mid \tilde \mu_n ) > \epsilon) \xrightarrow[ n \to \infty ]{} 0, \text{   } \ \forall \epsilon>0 $$ With $\delta_x$ I am denoting Dirac's delta. Some more information and my considerations It can be proved that convergence w.r.t to $d_\mathcal F$ is equivalent to convergence with respect to $$ \tilde d (\mu \mid \nu ) = \sup_{g \in \mathcal C^c(\mathbb R) \\ \lVert {g}\rVert_\infty \leq 1 } \Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\nu \  \Big |  .$$ This might be helpful in proving the proposition, since $\mathcal C^c(\mathbb R)$ is separable: the countable and dense subset could be used to take care of the $\sup$ I believe, but I don't exactly see how. Moreover, I don't see how am I supposed to use the density of $\mu$ . Despite Chebyshev's inequality/WLLN proves convergence for any single $g \in \mathcal F$ , with rate indipendent from $g$ $$ P\Big (\Big |  \int_\mathbb R g \ d\mu - \int_\mathbb R g\ d\tilde \mu_n \  \Big | > \epsilon \Big ) \leq \frac{Var(g(X_1))}{\epsilon^2 n} \stackrel{g(X) \in [-1,1] \ P \ a.s. }{\leq} \frac{1}{\epsilon^2 n}  $$ it seems quite hard to me that such convergence can happen uniformly over $g$ . One could restrict the problem to the subset of functions in $\mathcal F$ s.t. $\mathbb E [g(X_1)] = 0 $ by taking the expected value inside the random variable, but that isn't much and I'm not even sure if that would be a good idea. I have been thinking of using some trivial continuous distribution (such as the gaussian or uniform distributions) as a counterexample, but proving that converge doesn't happen in such case is still hard: my main problem is taking care of the $\sup$ inside the probability. Maybe there's some known theorem which can be used and is going over my head: Glivenko-Cantelli guarantees that $\tilde \mu _n $ learns any probability distribution w.r.t to the divergence corresponding to the half-line's indicators, but I don't think that helps.","['machine-learning', 'statistics', 'functional-analysis', 'borel-measures']"
4772404,Calculate $E[\Phi(aX+b)^n]$,"I am working on a project, where this expected value shows up again and again, where $X \sim N(0,1)$ and $\Phi$ is the cdf of a standard normal distribution. $$E[\Phi(aX+b)^n]$$ However, I have not yet been able to solve it. I am aware of the solution if $n=1$ , given for instance in the answer to this post . I am also aware that if $a=1$ and $b=0$ , then $\Phi(X)$ would be uniformly distributed and it would then be easy to find. Thank you very much for your time and help!","['integration', 'normal-distribution', 'expected-value', 'calculus', 'probability']"
4772406,Can $\operatorname{Tr}[A^{-1} BAB^\top]$ be shown to be always positive if $A$ is real and positive definite? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 9 months ago . Improve this question Let $A$ be a real symmetric positive definite matrix and $B$ is a real matrix with all eigenvalues zero. Can we prove or disprove that $\operatorname{Tr}[A^{-1} BAB^\top]$ is a positive number?","['matrices', 'trace', 'positive-definite']"
4772410,Change of variables $s^2=r^2+b^2$,"I am trying to understand why this change of variables breaks down. Let $f$ be a smooth continuous function on an interval $[0,a]$ with $a>0$ , and let $b>0$ . I want to compute $$\int_0^af(r^2+b^2)\,dr.$$ I want to use the change of variables $s^2=r^2+b^2$ , $2s\,ds=2r\,dr$ so $dr=\frac{s}{\sqrt{s^2-b^2}}ds.$ Therefore $$\int_0^af(r^2+b^2)\,dr=\int_{b}^{\sqrt{a^2+b^2}}f(s^2)\frac{s}{\sqrt{s^2-b^2}}\,ds.$$ But this integral does not converge as $s\rightarrow b^+$ . I am confused because a smooth continuous function on a closed interval should be finite.","['integration', 'lebesgue-integral', 'analysis', 'real-analysis', 'functional-analysis']"
4772429,Inequality for a complex polynomial,"Let $p(z), q(z)$ , and $r(z)$ be polynomials with complex coefficients in the complex plane. Suppose that $|p(z)|+|q(z)| \leq|r(z)|$ for every $z$ . Show that there exist two complex numbers $a, b$ such that $|a|^2+|b|^2=1$ and $a p(z)+b q(z)=0$ for every $z$ . I tried the following approach but not sure if it is correct or not: To find the complex numbers $a$ and $b$ such that $|a|^2+|b|^2=1$ and $a p(z)+b q(z)=0$ for every $z$ , we can use the given inequality and the properties of complex numbers and their modulus. Given the inequality $$
|p(z)|+|q(z)| \leq|r(z)|
$$ we can consider the functions $f(z)$ and $g(z)$ defined by $$
\begin{aligned}
& f(z)=a p(z)+b q(z) \\
& g(z)=a p(z)-b q(z)
\end{aligned}
$$ We want to find $a$ and $b$ such that $f(z)=0$ for every $z$ .
From the triangle inequality, we have that $$
|f(z)|+|g(z)|=|a p(z)+b q(z)|+|a p(z)-b q(z)| \leq|r(z)|+|r(z)|=2|r(z)| \text {. }
$$ We want to find $a$ and $b$ such that $|f(z)|=0$ . This means that we want to minimize $|f(z)|$ , subject to the constraint $|a|^2+|b|^2=1$ . To minimize $|f(z)|$ , we can write $f(z)$ in terms of $r(z)$ and differentiate with respect to $z$ . Setting the derivative equal to zero gives $$
\frac{d}{d z}|f(z)|=\frac{d}{d z}|a p(z)+b q(z)|=0,
$$ which yields the condition that $$
a \frac{d}{d z} p(z)+b \frac{d}{d z} q(z)=0 .
$$ Thus, we have a system of equations for $a$ and $b$ : $$
\left\{\begin{array}{l}
a p(z)+b q(z)=0, \\
a \frac{d}{d z} p(z)+b \frac{d}{d z} q(z)=0 .
\end{array}\right.
$$ We also have the constraint $|a|^2+|b|^2=1$ .
We can solve this system of equations for $a$ and $b$ using various methods, such as substitution or elimination. Once we find $a$ and $b$ , we can verify that they satisfy $|a|^2+$ $|b|^2=1$ .","['complex-analysis', 'roots', 'polynomials', 'complex-numbers']"
4772475,Inequality with complex numbers with the same modulus,"I got stuck at the following problem. Prove that for every three distinct complex numbers $a$ , $b$ , $c$ with $|a| = |b| = |c| > 0$ , the following inequality holds: $
\sum_{\text{cyclic}} |(a+b)(b-c)(c-a)|^2\ \geq \left|\sum_{\text{cyclic}} (a-b)(b+c)(c+a)\right|^2
$ If we divide the inequality by $|(a+b)(b+c)(c+a)|^2$ , the inequality reduces to: $
\sum_{\text{cyclic}} \left|\frac{b-c}{b+c}\right|^2 \cdot \left|\frac{c-a}{c+a}\right|^2 \geq \left|\sum_{\text{cyclic}} \left(\frac{a-b}{a+b}\right)\right|^2
$ Then we write $a=r(\cos(t_1)+i\sin(t_1))$ , $b=r(\cos(t_2)+i\sin(t_2))$ , and $c=r(\cos(t_3)+i\sin(t_3))$ . Thus, $
\frac{a-b}{a+b} = i\tan\left(\frac{t_1-t_2}{2}\right)
$ So the inequality we have to prove becomes: $
\sum_{\text{cyclic}} \left(\tan\left(\frac{t_1-t_2}{2}\right)\right)^2 \cdot \left(\tan\left(\frac{t_1-t_3}{2}\right)\right)^2 \geq \left(\sum_{\text{cyclic}} \tan\left(\frac{t_2-t_3}{2}\right)\right)^2
$ Then I tried denoting $x = \frac{t_1 - t_2}{2}$ , $y = \frac{t_2 - t_3}{2}$ , $z = \frac{t_3 - t_1}{2}$ , where x+y+z=0. Thus, we have to prove that: $
\sum_{\text{cyclic}} (\tan(x))^2 \cdot (\tan(y))^2 \geq (\sum_{\text{cyclic}} \tan(z))^2
$ and I got stuck here. How can I continue the problem?","['contest-math', 'inequality', 'trigonometry', 'complex-numbers']"
4772544,Find $\lim\limits_{x\to0}\frac{|x|}{\cos^2 (\pi/x) + 1}$,"I need help checking/cleaning my proof of section 2.4, problem 27 of Velleman's Calculus: A Rigorous First Course . Find $\lim\limits_{x\to0}\frac{|x|}{\cos^2 (\pi/x) + 1}$ . First note that for all $x\neq0$ we have $0 \le \cos^2 (\pi/x) \iff 1 \le \cos^2 (\pi/x) + 1 \iff \frac{1}{\cos^2 (\pi/x) + 1} \le 1 \iff \frac{|x|}{\cos^2 (\pi/x) + 1} \le |x|$ . Also it's clear that for all $x\neq0$ we have $0 \le \frac{|x|}{\cos^2 (\pi/x) + 1}$ since the numerator and and denominator are both positive. Since $0 \le \frac{|x|}{\cos^2 (\pi/x) + 1} \le |x|$ and $\lim\limits_{x\to0} 0 = \lim\limits_{x\to0} |x| = 0$ , then by the Squeeze Theorem $\lim\limits_{x\to0}\frac{|x|}{\cos^2 (\pi/x) + 1} = 0$ .","['limits', 'calculus', 'trigonometry', 'real-analysis']"
4772545,Determine if the convergence of $\sum|a_{n+1} - a_n|$ implies the convergence of $\sum |a_n|$.,"Let $(a_n)$ a sequence of reals with the property that $\sum a_n$ is finite. Determine if the convergence of $\sum|a_{n+1} - a_n|$ implies the convergence of $\sum |a_n|$ . After contemplating it, I assume it is indeed true. My attempts to prove it failed where the hardest part for me is using the convergence of $\sum a_n$ . So far my main observation I suppose is
that for each $m > n > 1$ we have $ |a_n| \leq \sum_{k=n}^{m} |a_k - a_{k-1}| $ Any idea will be appreciated","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
4772622,What tools can show that (possibly irregular) dodecahedra do not fill space?,"Here is a fairly natural question: Can three-dimensional space be filled with convex polyhedra of the same incidence structure (if not the same geometry) as the regular dodecahedron, such that four pieces meet at every vertex? We don't require that the cells be congruent to one another, but we'll say that each dihedral angle must be strictly less than 180 degrees so as to forbid degenerate cases that actually form polyhedra with fewer faces. We'll also require that the tiling be ""face-to-face"", such that every point in space is in one of four categories: Strictly within the interior of a dodecahedron. On the boundary of exactly two (closed) dodecahedra, and strictly within the interior of a face of each. On the boundary of exactly three dodecahedra, and strictly within the interior of an edge of each. On the boundary of exactly four dodecahedra, and a vertex of each. That is, every face meets exactly one congruent face on the opposite side, every edge is shared between all its members without any sliding or offsets, etc. This makes the combinatorial incidence structure especially straightforward. I strongly suspect the answer is ""no"", and I'd like to give the following argument for it: As we build up any attempt at such a construction, we will be ""filling out"" the incidence structure of the cells of the 120-cell , with each decision forced by the way in which the dodecahedra must meet one another. So we can place an initial cell, and lay down its 12 neighbors; this will force 20 more to fill out the vertices one edge away from a vertex of the original cell in a second layer. After placing these, we'll lay down another 12 touching our first layer on the face opposite that which they touch the central cell. After that, we'll place another 30, then another 12, then another 20, then another 12, and then we'll find that the resulting union is a single dodecahedron, requiring exactly one more piece at each vertex, which is now forced to be concave and in fact to ""wrap around"" the entire arrangement in one go, its interior equal to the full rest of space. However, this argument doesn't seem incredibly rigorous, and it rests heavily on a particular four-dimensional object in a way that doesn't clearly generalize to similar questions. I'd like something more systematic. This argument is perhaps easier to feel the force of for the analogous two-dimensional question of tiling the plane with convex pentagons three to a vertex: when one tries, they cannot help but find themselves drawing a skeleton of the dodecahedron, and after completing two rings around a central pentagon there is nowhere to go: In the two-dimensional case, this less-than-perfectly-rigorous argument can be replaced with a more precise appeal to some invariants using Euler's formula: Consider a finite patch of pentagons in a tiling. Assign to every pentagon in this tiling a score as follows: if $a$ vertices are shared by one other pentagon in the patch, and $b$ vertices are shared by two other pentagons, the score is $1-a/4-b/6$ . Using Euler's formula $V-E+F=2$ , it's easy enough to see that the total score in a finite simply connected patch is always equal to $1$ . Now, suppose we had a tiling of the plane. Take a simply-connected patch $P$ of at least 7 pentagons, and add all pentagons sharing an edge with any of those 7 to create a larger simply connected patch $Q$ . Each of our starting pentagons now has a score of $1/6$ (since $b=5$ for a fully surrounded pentagon), so they contribute more than $1$ to the total in $Q$ . This means that at least one of the outer pentagons in $Q$ must have a negative score. But there is only one local arrangement that assigns a negative score to a pentagon, and it requires that none of that pentagon's neighbors be fully surrounded; since all of these outer pentagons border an inner pentagon, this is a contradiction. So it is impossible to arrange pentagons in the plane in a degree-3 way, even far enough out to surround a group of 7 central pentagons. (Note that this argument doesn't actually use convexity, only the graph-theoretic incidence structure.) However, I don't see how to perform an analogous argument in the polyhedral case, because the Euler characteristic for polychora is $V-E+F-C=0$ , which is invariant to e.g. having twice as many of everything so doesn't naturally lead to any upper bounds. I've spent some time playing with different possible invariants, and despite my intuitive feeling that some kind of resource is being used up as more dodecahedra are added, I haven't found a metric that describes this in a satisfactory way; most angles of attack on the problem end up petering out in a way that relates to the zero Euler characteristic. What sorts of machinery can be used to settle questions like these? Are there existing methods in the literature I should examine?","['polyhedra', 'combinatorial-geometry', 'geometry', 'tiling']"
4772643,Must a linear functional on a TVS with a sequentially closed kernel be sequentially continuous?,"Let $(X, \tau)$ be a Hausdorff topological vector space, $\mathbb{K}$ the scalar field with its usual topology and $\Lambda : X \to \mathbb{K}$ a linear functional. There is this general criterion concerning the continuity of $\Lambda$ , which you can find a concise proof of in Rudin's Functional Analysis as the Theorem $1.18$ for example: The assertions below are equivalent: $\Lambda$ is continuous; $\ker \Lambda$ is closed; $\ker \Lambda$ is not dense; $\Lambda$ is bounded on at least one neighbourhood of $0$ . The equivalence ""1. $\Leftrightarrow$ 2."" can also be shown directly in normed spaces due to continuity and boundedness coinciding in metrisable TVSs and hence in normed spaces. This in particular has been done several times on this site: see A second proof of the fact that a linear functional $f$ on a normed vector space $\mathcal{X}$ is bounded iff $f^{-1}(0)$ is closed. , or The kernel of a continuous linear operator is a closed subspace? , and so on... My question is then simple: Do we have that $\Lambda$ is sequentially continuous iff $\ker \Lambda$ is sequentially closed? The ""only if"" direction is fairly easy to prove: consider a sequence $(x_n)_n$ in $\ker \Lambda$ converging to $x \in X$ . By sequential continuity, $\Lambda(x_n) = 0 \to \Lambda(x)$ , yet $0 \to 0$ , hence by uniqueness of the limit in $\mathbb{K}$ we get $\Lambda(x) = 0$ , and $x$ belongs in $\ker  \Lambda$ . Thus, what I have trouble with is the ""if"" direction. I have a suspicion that it's just not a true claim due to the lack of MSE questions about functionals with sequentially closed kernels (if I type ""sequentially closed kernels"" in the search bar, there are only ten results, with seemingly only one mentioning those concepts in the same sentence, namely When is a sequentially closed subspace the kernel of a sequentially continuous linear functional? but it's in the opposite direction from my current question), though the lack of questions is of course not actual evidence of the claim being true nor of it being false. I'm probably just missing something simple to be fair. What I've tried is first starting from "" $\Lambda$ not sequentially continuous"" and attempting to prove that $\ker \Lambda$ is not sequentially closed. Since sequential continuity is the same as sequential continuity at $0$ thanks to linearity, there exists a sequence $(x_n)_n$ in $X$ converging to $0$ and such that $(\Lambda(x_n))_n$ does not converge to $\Lambda(0) = 0$ , and then, taking a $y \in X$ such that $\Lambda(y) = 1$ , we can consider the sequence $(x'_n)_n := (x_n - \Lambda(x_n) y)_n$ to have a sequence belonging to $\ker \Lambda$ ... but then what? If $(\Lambda(x_n))_n$ was known to have a finite non-zero limit point $\alpha$ , I could exhibit a subsequence $(x'_{\varphi(n)})_n$ converging to $-\alpha y$ which would not belong in $\ker \Lambda$ , hence the latter would not be sequentially closed and we would be done, however what if all we have is $|\Lambda(x_n)| \to \infty$ or the only finite limit point is $0$ ? Feel free to edit or re-tag if/when adequate.","['continuity', 'linear-algebra', 'functional-analysis', 'topological-vector-spaces']"
4772659,Evaluating $\lim_{x\to\infty}\frac{\ln\cos\frac {48} x}{\ln\cos\frac{1}{12x}}$ without using L'Hopital,"I've seen some similar question, but none with $x\to\infty$ $$\lim_{x\to\infty}\frac{\ln\cos\frac {48} x}{\ln\cos\frac{1}{12x}}$$ one of the ideas that i tried is, with $t=\frac{48}{x}$ , changing the limit to: $$\lim_{t\to0}\frac{\ln\cos t}{\ln\cos\frac{t}{576}}$$ but it got me stuck pretty much there. Thanks and sorry if it's basically a duplicate.","['limits', 'calculus', 'limits-without-lhopital']"
4772730,On Siegel's Theorem in integer points.,"Siegel’s theorem on integer points :
Let $P \in {\mathbb{Q}}[x,y]$ be an irreducible polynomial of two variables, such that the affine plane curve $C = \{ (x,y): P(x,y)=0\}$ either has genus at least one, or has at least three points on the line at infinity, or both. Then $C$ has only finitely many integer points $(x,y) \in \mathbb{Z}\times\mathbb{Z}.$ Question: Is there any generalization for irreducible polynomials on more variables?","['algebraic-curves', 'algebraic-geometry', 'integer-lattices']"
4772764,"""Adding one dimension"" to an infinite dimensional topological vector space","Let $V$ be an infinite-dimensional Hausdorff topological vector space over $\mathbb{R}$ . Is it true that $V\oplus\mathbb{R}$ is isomorphic (as a TVS) to $V$ itself? (How about $V\oplus V$ ?) If yes, I also wonder whether for every $v \ne 0$ in $V$ there exists an isomorphism $f : V \cong V \oplus \mathbb{R}$ such that the projection of $f(v)$ to $\mathbb{R}$ is nonzero. If no: What is the simplest counterexample? What are some minimal conditions (complete/locally convex/normed/inner product etc.) that guarantee the existence of such isomorphisms? (If $V$ is a Hilbert space, desired isomorphisms exist in all three cases above.) I looked briefly into Schaefer and Wolff's Topological Vector Spaces but did not find any clue.",['functional-analysis']
4772833,"How to do induction proof for all $n \ge 1$, $((-1)^n+1)n = (1-(-1)^n(2n+1))$?","Having trouble with this proof by induction: $\forall n \in \mathbb{Z}: n \ge 1, $ $$1 - 2 + 3 - 4 +... + (-1)^{n+1}n = \frac{1-(-1)^{n}(2n+1)}{4} $$ So far I've got to this stage below but I've had trouble simplifying the left side to match the right: $$\frac{1-(-1)^k (2k+1)}{4} + (-1)^{k+2}(k+1) = \frac{1-(-1)^{k+1}(2(k+1)+1)}{4} $$ $$\frac{1-(-1)^k (2k+1)  +  4((-1)^{k+2}(k+1))}{4} = \frac{1-(-1)^{k+1}(2k+3)}{4} $$ Does anyone have any solutions?","['induction', 'proof-writing', 'discrete-mathematics']"
4772835,Chernoff bound and Polynomial Markov,"I'm currently struggling the following statement; Show that upper bound of polynomial Markov is better than the Chernoff upper bound; that is, for given $\delta > 0,$ $$\inf_{k = 0,1,2,...} \frac{\mathbb E [X^k]}{\delta^k} \le \inf_{\lambda \ge 0} \frac{\mathbb E [e^{\lambda X}]}{e^{\lambda \delta}}$$ I tried to use the Taylor's expansion in $e^{\lambda X}$ for both exponentials; $$ \mathbb E [e^{\lambda X}] = \mathbb E [ 1 + \frac{\lambda X}{1!} + \frac{(\lambda X)^2}{2!} + ...]$$ $$e^{\lambda \delta} = 1 + \frac{\lambda \delta}{1!} + \frac{(\lambda \delta)^2}{2!} + ...$$ , but failed to show more things. It would be grateful for any hint regarding this inequality (or any errors or uncertain points in the above statement).","['statistics', 'solution-verification', 'probability-theory']"
4772845,"Can we evaluate the integral $ I(a)=\int_0^{\infty} \frac{\sin x}{x^a} e^{-x} d x, $ without Gamma functions?","Encountering the integral in the post stating that $$
\int_{0}^{\infty} \frac{e^{-x} \sin(x)}{x}\,dx=\frac\pi4,
$$ I started to investigate the integral in a more general form as $$
I(a)=\int_0^{\infty} \frac{\sin x}{x^a} e^{-x} d x,
$$ where $1<a<2$ . Using the Euler’s identity: $e^{xi}=\cos x+i\sin x$ , we have $$
\begin{aligned}
I(a) & = \Im \int_0^{\infty} \frac{e^{xi} \cdot e^{-x}}{x^a} d x \\
& = \Im\int_0^{\infty} \frac{e^{-(1-i) x}}{x^a} d x \\
& = \Im \int_0^{\infty} x^{-a} e^{-(1-i) x} d x \\
& =\Im\left[\frac{\Gamma(1-a)}{(1-i)^{1-a}}\right]
\end{aligned}
$$ By expressing the denominator in polar form, we have $$
\frac{1}{(1-i)^{1-a}}=\left(\sqrt{2} e^{-\frac{\pi}{4} i}\right)^{a-1} =2^{\frac{a-1}{2}} e^{\frac{(1-a) \pi}{4}i} 
$$ Now we can conclude that $$
\boxed{I(a)=2^{\frac{a-1}{2}} \Gamma(1-a) \sin \frac{(1-a) \pi}{4}}
$$ For example, $$
I\left(\frac{3}{2}\right) =2^{\frac{1}{4}} (-2 \sqrt{\pi})\left(-\sin \frac{\pi}{8}\right) =2\sqrt[4]{2}\cdot\frac{\sqrt{(2-\sqrt{2} )\pi}}{2}=\sqrt{2(\sqrt{2}-1)\pi}
$$ Do we have any other methods to evaluate the integral?
Your comments and alternative methods are highly appreciated.","['integration', 'improper-integrals', 'definite-integrals', 'gamma-function', 'calculus']"
4772889,Does $S_n$ always embed into $GL_{n-1} (\mathbb{F}_p$)?,"$S_n$ is the symmetry group of the standard $n-1$ -simplex, which is the convex hull of the standard basis vectors in $\mathbb{R}^n$ . One can orthogonally project this shape onto the plane $x_1 +...+ x_n = 0$ , which is isomorphic to $\mathbb{R}^{n-1}$ . This yields an embedding of $S_n$ into $GL_{n-1}(\mathbb{R}$ ). Is there some other trick one can use for more general fields, like prime fields? It seems likely, because $GL_{2} (\mathbb{F}_2)$ is isomorphic to $S_3$ , and $GL_{3} (\mathbb{F}_2$ ) contains a copy of $S_4$ according to: https://people.maths.bris.ac.uk/~matyd/GroupNames/163/GL(3,2).html . And as $n$ grows large the order of $GL_{n-1} (\mathbb{F}_p)$ vastly exceeds the order of $S_n$ . I have no idea how one would go about proving it though.","['general-linear-group', 'representation-theory', 'finite-groups', 'symmetric-groups', 'group-theory']"
4772890,Plane through feet of normals to ellipsoid,"The problem If $P,Q,R,P',Q',R'$ be the feet of six normals drawn from a point to the ellipsoid $$\frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} - 1=0$$ and the plane $PQR$ is represented by $lx+my+nz-p=0$ , show that the plane $P'Q'R'$ is represented by $$\frac{x}{a^2l} + \frac{y}{b^2m} + \frac{z}{c^2n} + \frac{1}{p} = 0$$ What I have done so far : If the original point is $(\alpha, \beta, \gamma)$ , then any foot of the perpendicular is of the form: $$(\frac{\alpha a^2}{\lambda+a^2}, \frac{\beta b^2}{\lambda+b^2}, \frac{\gamma c^2}{\lambda+c^2})$$ where $\lambda$ is parameter. Putting this in the ellipsoid, I get a six degree equation as: $$\frac{\alpha^2 a^2}{(\lambda+a^2)^2}+ \frac{\beta^2 b^2}{(\lambda+b^2)^2}+ \frac{\gamma^2 c^2}{(\lambda+c^2)^2} - 1 = 0$$ Assuming the other plane to be $l'x + m'y + n'z +p'=0$ , I put the values of the parametric point and multiply the two planes. $$(lx+my+nz-p)(l'x+m'y+n'y-p')=0$$ or $$(l\frac{\alpha a^2}{\lambda+a^2}+m\frac{\beta b^2}{\lambda+b^2}+n\frac{\gamma c^2}{\lambda+c^2}-p) (l'\frac{\alpha a^2}{\lambda+a^2}+m'\frac{\beta b^2}{\lambda+b^2}+n'\frac{\gamma c^2}{\lambda+c^2}-p')=0$$ Comparing coefficients, this should be equal to the parametric ellipsoid equation. But to arrive at the result, I have to make the $\alpha^2\beta^2$ terms zero. How do I do that? Is my approach correct?","['ellipsoids', '3d', 'conic-sections', 'geometry', 'quadrics']"
4772935,Dealing with log(1) in computational linguistics,"I am not sure this is the right venue for this question: if you think it is not, I will move it to another StackExchange board. Explanation I am trying to calculate phonotactic probability on a corpus of consonant-vowel-consonant (CVC) words. Phonotactic probability can be defined as follows: Phonotactic probability refers to the frequency with which a
phonological segment, such as /s/, and a sequence of phonological
segments, such as /s^/, occur in a given position in a word ( Kansas University ) And can be calculated on segments of various length, such as monograms, bigrams, trigrams, etc. In simple terms: For a word like blick in English, the unigram average would include
the probability of /b/ occurring in the first position of a word, the
probability of /l/ in the second position, the probability of /ɪ/
occuring in the third position, and the probability of /k/ occurring
in the fourth position of a word. Each positional probability is
calculated by summing the log token frequency of words containing that
segment in that position divided by the sum of the log token frequency
of all words that have that position in their transcription. The
bigram average is calculated in an equivalent way, except that
sequences of two segments and their positions are used instead of
single segments. So for blick that would be /bl/, /lɪ/, /ɪk/ as the
included positional probabilities In matemathical terms, the phonotactic probability of the word blick would be calculated as follows: Given an example corpus (e.g., the one from CorpusTools documentation ): The phonotactic probability of blick would be calculated as follows: Question Unfortunately, in my corpus, some bigrams (e.g., /Aw/, 'Aw': [1, 1, 1, 1] ) appear in only words with token frequency one. As such, when calculating the sum of log() frequencies of words starting with /Aw/, the sum ammounts to log(1) + log(1) + log(1) + log(1) Which in turn returns 0 . Indeed, this is not very representative, since the bigram appears in at least four words. Is there a way to deal with this from a mathematical perspective?","['statistics', 'logarithms']"
4772954,Can every integer $\geq 2$ be written as a linear combination of prime numbers with imposed conditions?,"I wonder if the following conjecture can be proved either by elementary means, or by assuming known results like Vinogradov's theorem or Goldbach's weak conjecture or perhaps even unknown results like Goldbach's conjecture. Let $N\geq 2.$ Define $\mathbb{P}_{\leq N}$ to be the set of all
primes $\leq N.$ Conjecture: There exists a subset (sub-permutation) $\{x_1, x_2,
 \ldots, x_n\}\ $ of $\ \left\{ 1,2,\ldots, \lceil \ln N \rceil
 \right\}\ $ and a subset (sub-permutation) of $\{y_1, y_2, \ldots, y_n\}\ $ of $\mathbb{P}_{\leq N}$ such that $$ \sum_{k=1}^{n} x_k y_k = N. $$ I have checked for the first few values of $N$ by hand up to about $50,$ and also some values of $N$ in the hundreds and I didn't find any counter-examples.","['number-theory', 'elementary-number-theory', 'prime-numbers']"
4772956,Connectedness of the boundary of a domain,"I've been struggling to prove the following lemma: "" Let $\Omega\subset\mathbb{R}^{d}$ be open and bounded with a Lipschitz boundary and such that $\mathbb{R}^{d}\setminus\partial\Omega$ has exactly two connected compnents. Then $\partial\Omega$ is connected ."" It seems an evident result when you think about it for 5 minutes, but I am struggling with a formal proof (a reference would be really welcome). It also looks like the typical result that you find in some old calculus book, but I haven't been able to find one yet. I have thought a complex analysis approach, but this would only solve the 2-dimensional case, which we know is not equivalent to prove the d-dimensional case and cannot be generalized. So far I have clarified some things to understand the result better: In all of these cases, the domain $\Omega$ has some different dimensional holes $\Gamma_0$ : a $d$ -dimsnsional hole in the first picture (however this contradicts the hypothesis of "" $\mathbb{R}^{d}\setminus\partial\Omega$ has exactly two connected compnents ""), a $d-1$ -dimensional slit in the second picture (this contradicts the Lipschitz boundary hypothesis), and a set with positive $d-1$ -dimensional Hausdorff measure in the last picture (this also contradicts the Lipschitz boundary hypothesis). It is easy to see these contradictions (with handwaving, sadly), but I cannot seem to prove rigorously the whole lemma (are there any more cases to consider? how do I handle the Lipschitz hypothesis to reach the contradiction in the two latter cases? am I missing something? can it even be trivial?). So far, my best attempt to the proof is the following: "" There are two possibilities: either $\mathbb{R}^{d}\setminus\Omega$ is connected or $\mathbb{R}^{d}\setminus\Omega$ has at least two disjoint connected components (we will handle the case of $\mathbb{R}^{d}\setminus\Omega$ having exactly two connected components since the cases with more than two connected components are analogous). When $\mathbb{R}^{d}\setminus\Omega$ is connected the result comes straightforward from [Czarnecki-Kulczycki-Lubawski, 2011] . On the other hand, say that $\mathbb{R}^{d}\setminus\Omega=\Gamma_{0}\cup\Gamma_{1}$ , where $\Gamma_{0}$ is a connected component which is bounded and $\Gamma_{1}$ is a connected component which is unbounded (the fact that one is bounded and the other is unbounded comes from the fact that $\Omega$ is bounded). Recalling that the $d$ -dimensional Hausdorff measure and the $d$ -dimensional Lebesgue measure coincide in $\mathbb{R}^{d}$ , there are two other possibilities: either $\mathcal{L}^{d}(\Gamma_{0})>0$ or $\mathcal{L}^{d}(\Gamma_{0})=0$ . In the first case we have that $\mathbb{R}^{d}\setminus\partial\Omega=int(\Gamma_{0})\cup\Omega\cup\Gamma_{1}$ which are, at least, three disjoint connected components and therefore lead to a contradiction. In the latter case, recalling the set $C=\{x+yn:x\in B_{r}(p)\cap H,-h<y<h\}$ from the definition of a Lipschitz domain, for any $p\in\partial\Gamma_{0}$ , when $\mathcal{L}^{d}(\Gamma_{0})=0$ we have that $\partial\Gamma_{0}=\Gamma_{0}$ and hence, that $\Gamma_{0}\cap C=(\partial\Gamma_{0})\cap C$ which is a contradiction with $\Gamma_{0}$ being a Lipschitz domain. Therefore $\Gamma_{0}=\emptyset$ and the result comes straightforward from [Czarnecki-Kulczycki-Lubawski, 2011] ."" This looks wrong to me, but I can't say where exactly. Any help will be welcome, thank you.","['calculus', 'general-topology', 'lipschitz-functions', 'connectedness']"
4772968,What is the minimum and the maximum perimeter of a triangle with area $x$ that can be inscribed in a circle?,"Posted in MO since it has been open in MSE for over 2 months. The area of the largest triangle that can be inscribed in a circle of raidus $1$ is $\displaystyle \frac{3 \sqrt{3}}{4}$ for a equilateral triangle and it also gives the perimeter is $3\sqrt{3}$ . For any $\displaystyle 0 \le x \le \frac{3 \sqrt{3}}{4}$ we can ask the minimum perimeter $f(x) $ and maximum perimeter $g(x)$ of triangles with area $x$ inscribed in a circle of radius $1$ . I ran a simulation to calculate the values of $f(x)$ and $g(x)$ for all $x$ in this interval and obtained the plot below. For the maximum perimeter, trivially $g(0) = 4$ and $\displaystyle g\left(\frac{3 \sqrt{3}}{4}\right) = 3 \sqrt{3}$ . The graph of $g(x)$ appears to be a straight line as shown by the blue line. Fitting a straight line through these two points gives the model $$
g(x) = 4 + \left(4 - \frac{16}{3\sqrt{3}}\right)x \tag 1
$$ Can this be proven? For the minimum perimeter we have trivially $f(0) = 0$ and $\displaystyle f\left(\frac{3 \sqrt{3}}{4}\right) = 3 \sqrt{3}$ and $f(1) = 2+2\sqrt{2}$ corresponding to an isosceles right triangle. Fitting a curve with the data for $g(x)$ suggests a model of the form $f(x) = (2+\sqrt{2})x^a$ with $a \approx 0.306$ however this model with inconsistent with the fact that $\displaystyle f\left(\frac{3 \sqrt{3}}{4}\right) = 3 \sqrt{3}$ hence this model was discarded. Question : What is the minimum and the maximum perimeter of a triangle with area $x$ and circumradius $1$ ?","['euclidean-geometry', 'geometry', 'maxima-minima', 'calculus', 'triangles']"
4773000,Does every metrizable space have a complete metric?,"Cauchy sequences are not preserved between homeomorphic metric spaces, e.g. the sequence $x_n=1/(n+1)$ in $(0,1)$ is cauchy but not when passing to $\mathbb{R}$ by $1/x$ . A natural follow up is if every metric space has a metric under it is complete. I would think that $\mathbb{Q}$ fails this, but it's not clear how to show this.","['general-topology', 'metric-spaces']"
4773005,Left-adjoint to Yoneda embedding,"Let $C$ be locally small. Consider the Yoneda embedding $Y:C\rightarrow [C^{op},Set]$ . Since limits in functor categories are computed pointwise and since the hom-functor preserves limits, the Yoneda embedding is limit-preserving. A natural question to ask then is, whether or when the Yoneda embedding has a left adjoint. Categories whose Yoneda embedding has a left adjoint are called total . Apparently the category of sets and the category of groups are both total. What are the left adjoints of the Yoneda embedding (of these or other interesting examples) explicitely?","['examples-counterexamples', 'category-theory', 'abstract-algebra', 'yoneda-lemma', 'adjoint-functors']"
4773054,Can we extend the Divisor Function $\sigma_s$ to $\mathbb{Q}$ by extending Ramanujan Sums $c_n$ to $\mathbb{Q}$?,"It can be shown that the divisor function $\sigma_s(k)=\sum_{d\vert k} d^s$ defined for $k\in\mathbb{Z}^+$ can be expressed as a Dirichlet series with the Ramanujan sums $c_n(k):=\sum\limits_{m\in(\mathbb{Z}/n\mathbb{Z})^\times}e^{2\pi i\frac{m}{n}k}$ defined for $k\in\mathbb{Z}$ and $n\in\mathbb{Z}^+$ with the following identity $$\boxed{\forall k\in\mathbb{Z}^+:\sigma_s(k)=\zeta(1-s)\sum_{n=1}^\infty\frac{c_n(k)}{n^{1-s}}}$$ It is easy to show that, since $m\mapsto-m$ is a bijection on $(\mathbb{Z}/n\mathbb{Z})^\times$ , $c_n(-k)=c_n(k)$ as we only permute the invertible elements. This suggests by looking at the previous Dirichlet series that $\sigma_s(k)$ could be extended to $k\in\mathbb{Z}\setminus\{0\}$ as $\sigma_s(-k)=\sigma(k)$ . This is quite intuitive as it means that $\sigma_s(k)=\sum_{d\vert k}d^s$ runs over the positive divisors $\forall 0\neq k\in\mathbb{Z}$ . Notice as well that we could extend $\sigma_s(k)$ to $k=0$ by looking at the previous series as $$\sigma_s(0)=\zeta(1-s)\sum_{n=1}^\infty \frac{c_n(0)}{n^{1-s}}=\zeta(1-s)\sum_{n=1}^\infty \frac{\varphi(n)}{n^{1-s}}=\zeta(1-s)\frac{\zeta(-s)}{\zeta(1-s)}=\zeta(-s)$$ This is also intuitive noting that the positive divisors of $0$ are $\{1,2,3,...\}$ so one would informally guess $\sigma_s(0)=1^s+2^s+3^s+...=\zeta(-s)$ . So the previous series let's us expand the domain of $\sigma_s(k)$ to $k\in\mathbb{Z}$ . In fact, it can also be shown that this extension is also multiplicative in the sense that if $n_1$ and $n_2$ are coprime then $\sigma_s(n_1 n_2)=\sigma_s(n_1)\sigma_s(n_2)$ . But this is not the end of the story. Coprimality can also be considered in $\mathbb{Q}$ where we say that $x,y\in\mathbb{Q}$ are coprime $\iff \forall p\in\mathbb{P}:\nu_p(x)=0$ or $\nu_p(y)=0$ where $\nu_p$ is the rational $p$ -adic valuation . Then, $\sigma_s(x)$ can be defined for all $x\in\mathbb{Q}$ by defining $\forall p\in\mathbb{P}$ prime and $\alpha\in\mathbb{Z}:\sigma_s(p^\alpha)=\frac{1-p^{s(1+\alpha)}}{1-p^s}$ , $\sigma_s(0)=\zeta(-s)$ and allowing it to be multiplicative on $\mathbb{Q}$ . As an example, $$\sigma_2\left(\frac{64}{63}\right)=\sigma_2\left(2^6\cdot3^{-2}\cdot7^{-1}\right)=\frac{1-2^{14}}{1-2^2}\cdot\frac{1-3^{-2}}{1-3^2}\cdot\frac{1-7^{0}}{1-7^2}=5461\cdot\left(-\frac{1}{9}\right)\cdot 0=0$$ In fact, if $\nu_p(x)=-1$ for some $p\in\mathbb{P}$ , then $\sigma_s(x)=0$ . My question then is Q: Is there a natural extension of Ramanujan sums $c_n(x)$ to $x\in\mathbb{Q}$ such that the former Dirichlet series identity holds true for every $k\in\mathbb{Q}$ ? That is, such that the following identity holds $$\boxed{\forall x\in\mathbb{Q}:\sigma_s(x)=\zeta(1-s)\sum_{n=1}^\infty\frac{c_n(x)}{n^{1-s}}}$$ One guess could be $c_n(x):=\sum\limits_{m\in(\mathbb{Z}/n\mathbb{Z})^\times}e^{2\pi i\frac{m}{n}x}$ but I don't know if it actually works. I won't consider the proof of existence as a complete answer since I would like to find an explicit extension of $c_n$ to $\mathbb{Q}$ . $\color{red}{\bf\text{Update:}}$ As noted on Wikipedia , Hölder proved the identity $$c_n(k)=\mu\left(\frac{n}{(n,k)}\right)\frac{\varphi(n)}{\varphi\left(\frac{n}{(n,k)}\right)}$$ where $(\cdot,\cdot):\mathbb{Z}\times\mathbb{Z}\to\mathbb{Z}$ is the gcd function. One can naturally extend the gcd to $\mathbb{Q}$ by allowing the property $\forall x,y,\lambda\in\mathbb{Q}:(\lambda x,\lambda y)=|\lambda|(x,y)$ . This extension also respects the property that $\nu_p((x,y))=\min\{\nu_p(x),\nu_p(y)\}$ . With this in mind, one can extend $c_{n}(x)$ to rational $x$ as above. For example, if $p$ is a prime, then $$c_n\left(\frac{1}{p}\right)=\mu\left(\frac{n}{(n,1/p)}\right)\frac{\varphi(n)}{\varphi\left(\frac{n}{(n,1/p)}\right)}=\mu\left(\frac{pn}{(pn,1)}\right)\frac{\varphi(n)}{\varphi\left(\frac{pn}{(pn,1)}\right)}$$ $$=\mu\left(pn\right)\frac{\varphi(n)}{\varphi\left(pn\right)}=\begin{cases}0 & \text{ if } p\ \vert\ n\\ -\frac{\mu(n)}{p-1} & \text{ if } p\ \not\vert\ n\end{cases}$$ It is easy to show that $\sum_{n=1}^\infty\frac{\mu(pn)}{n^s}=-\frac{p^s}{1-p^s}\frac{1}{\zeta(s)}$ which leads us to the following $$\sum_{n=1}^\infty\frac{c_n(1/p)}{n^s}= -\frac{1}{p-1}\sum_{n=1\\ p\not\vert n}^\infty\frac{\mu(n)}{n^s}=-\frac{1}{p-1}\left(\sum_{n=1}^\infty\frac{\mu(n)}{n^s}-\sum_{n=1}^\infty\frac{\mu(pn)}{p^sn^s}\right)$$ $$=-\frac{1}{p-1}\left(\frac{1}{\zeta(s)}+\frac{1}{1-p^s}\frac{1}{\zeta(s)}\right)=-\frac{1}{p-1}\left(1+\frac{1}{1-p^s}\right)\frac{1}{\zeta(s)}$$ But this doesn't work as it would lead to $$\sigma_s(p^{-1})=-\frac{1}{p-1}\left(1+\frac{1}{1-p^{1-s}}\right)\neq0$$ Moreover, if $\alpha\geq2$ is an integer, then $\mu\left(\frac{n}{(n,p^{-\alpha})}\right)=\mu(p^\alpha n)=0$ as $p^\alpha n$ is not square-free and, in turn, this would lead to $c_n(p^{-\alpha})=0\Rightarrow \sigma_s(p^{-\alpha})=0$ . This is quite interesting but not what I wanted (nor what I expected). But maybe there's a better extension of the formula proven by Hölder that does the trick.","['number-theory', 'analytic-number-theory', 'dirichlet-series', 'generating-functions', 'sequences-and-series']"
4773064,Smallest ellipsoid which includes two equal radii balls,"Consider $C_0, v \in \mathbb{R}^n$ with $\|v\| = 1$ and $\epsilon > 0$ , then $C_1 = C_0 + \epsilon \cdot v$ and $C_2 = C_0 - \epsilon\cdot v$ . What is the smallest volume ellipsoid containing $\mathcal{B}(C_1, R) \cup \mathcal{B}(C_2,R)$ for some $R> 0$ . I guess its centre should be in $C_0$ so one looks for $(x-C_0)^T\cdot P \cdot (x-C_0) \leq 1$ . But how to proceed? Should one consider the two centers as focal points ?","['ellipsoids', 'geometry']"
4773068,Show the conditional probability,"Let $\theta, U_1, U_2,\ldots$ be independent and uniform on $(0,1)$ . Let $X_i = 1$ if $U_i\le\theta$ , $X_i=−1$ , if $ U_i >\theta$ , and let $S_n = X_1 + \cdots+ X_n$ . In words, we first pick $\theta$ according to the
uniform distribution and then flip a coin with probability θ of heads to generate a
random walk. Compute $\mathbb{P}(X_{n+1} = 1\mid X_1, \ldots,X_n).$ Let $i_1,\ldots,i_{n}\in \left\{-1,1\right\}$ and $N= \text{the cardinality of} \left\{1\le i\le n:X_i=1 \right\}$ . $$\mathbb{P}(X_1=i_1,\ldots,X_n=i_n)=\theta^{N}(1-\theta)^{n-N},$$ $$\mathbb{P}(X_{n+1} = 1,X_1=i_1,\ldots,X_n=i_n)=\theta^{N+1}(1-\theta)^{n-N},$$ $$\mathbb{P}(X_{n+1} = 1\mid X_1=i_1, \ldots,X_n=i_n)=\theta.$$ However, I have a sense that it may not be correct.","['stochastic-processes', 'markov-chains', 'probability-theory', 'probability']"
4773073,The Collector’s Problem,"I have the following Question in my text book , where the Answer is given. I have got my own alternative Answer. I want to know whether that alternative Answer is Correct & Equivalent to the text book Answer. Suppose that each package of bubble gum contains the picture of a baseball player, that the pictures of $r$ different players are used, that the picture of each player is equally likely to be placed in any given package of gum, and that pictures are placed in different packages independently of each other. The problem now is to determine the probability $p$ that a person who buys $n$ packages of gum ( $n$ ≥ $r$ ) will obtain a complete set of $r$ different pictures. The textbook answers as follows: For i = 1, ..., r, let $A_{i}$ denote the event that the picture of player i is missing from all n packages. Then $ \bigcup \limits_{i=1}^{r}A_{i} $ is the event that the picture of at least one player is missing. We shall find $Pr \left( \bigcup \limits_{i=1}^{r}A_{i}\right) $ Since the picture of each of the r players is equally likely to be placed in any particular package, the probability that the picture of player i will not be obtained in any particular package is $\frac{r-1}{r}$ . Since the packages are filled independently, the probability that the picture of player i will not be obtained in any of the n packages
is $\left [ \frac{r-1}{r}  \right ] ^n$ , hence $$
Pr \left( A_i \right) =  \left ( \frac{r-1}{r}  \right ) ^n
$$ Now consider any two players i and j . The probability that neither the picture of
player i nor the picture of player j will be obtained in any particular package is $\frac{r-2}{r}$ . Therefore, the probability that neither picture will be obtained in any of
the n packages is $\left [ \frac{r-2}{r}  \right ] ^n$ . Thus, $$
Pr \left( A_i\bigcap A_j \right) =  \left ( \frac{r-2}{r}  \right ) ^n
$$ If we next consider any three players i , j , and k , we find that $$
Pr \left( A_i\bigcap A_j \bigcap A_k \right) =  \left ( \frac{r-3}{r}  \right ) ^n
$$ By continuing in this way, we finally arrive at the probability $Pr \left( A_i\bigcap A_j \bigcap... \bigcap A_r \right)$ that the pictures of all r players are missing from the n packages. Of course, this probability is 0. $$
Pr \left( \bigcap \limits_{i=1}^{r} A_i \right) = r\left( \frac{r-1}{r}  \right)^n - \binom{r}{2} \left( \frac{r-2}{r}  \right)^n + ...
 + \left(-1 \right)^r \binom{r}{r-1}\left(\frac{1}{r}  \right)^n = \sum_{j=1}^{r-1}\left( -1\right) ^{j+1}
\binom{r}{j}\left(1- \frac{j}{r}  \right)^n 
$$ Since the probability p of obtaining a complete set of r different pictures is equal to $$
1 − Pr \left( \bigcup \limits_{i=1}^{r}A_{i}\right)
$$ it follows from the foregoing derivation that p can be written in the form: $$
p=\sum_{j=0}^{r-1}\left( -1\right) ^{j}\binom{r}{j}\left(1- \frac{j}{r}  \right)^n 
$$ I just used another method to solve this.
Each package has r choices, so the total outcomes would be $r^n$ and then we first select r packages out of n to have a complete set of r pictures, there are $\binom{n}{r}$ combinations, and then arrange those r packages with r! choices. The remaining n-r packages each have r different arrivals. so my calculation is : $$
\frac{ \binom{n}{r}r!r^{n-r}}{r^n}
$$ I don't know whether it's correct or not. I can understand the procedure provided by the textbook, so are these two answers the same?","['statistics', 'combinations', 'independence', 'coupon-collector', 'probability']"
4773092,Asymptotics of $\left(\sum_{k=0}^\infty\frac {k^n}{k!}\right)^\frac1n$ at $n\to\infty$,"Solving the problem on Quora , I tried also to get a reasonable approximation of $$ (S_n)^\frac1n=\left(\sum_{k=0}^\infty\frac {k^n}{k!}\right)^\frac1n\,\text{at}\,n\to\infty$$ Using Laplace method (which, frankly speaking, is not formally applicable in this case), I got $$(S_n)^\frac1n\sim \frac {n\,e^{\frac1{W(n)}}}{e\,W(n)}$$ where $W(n)$ is Lambert function. The approximation works rather well - in spite of arbitrary usage of the method: $\displaystyle n=100 \quad\frac{\ln n}n\left(S_n\right)^\frac1n\bigg|_{n=100}=0.667365...\,;\quad \frac {\ln n\,\,e^{\frac1{W(n)}}}{e\,W(n)}\bigg|_{n=100}=0.672337...$ $\displaystyle n=1000 \quad\frac{\ln n}n\left(S_n\right)^\frac1n\bigg|_{n=1000}=0.585123...\,;\quad \frac {\ln n\,\,e^{\frac1{W(n)}}}{e\,W(n)}\bigg|_{n=1000}=0.585692...$ etc. My question is whether we can prove the result in a rigorous way, or provide a more accurate and justified asymptotic, using some other evaluation technics? Follow up The asymptotic of Bell numbers solves the problem;
@Command Master and @Cactus - thank you for the information. One of the ways of evaluation (by means of complex integration) can be found in this pape . It is interesting to note that the correct first term of the asymptotics can be obtained in one line by simply applying the Laplace method. I got $$\sum_{k=0}^\infty\frac {k^n}{k!}=\frac1{\sqrt{W(n)+1}}\left(\frac {n\,e^{\frac1{W(n)}}}{e\,W(n)}\right)^n$$ what coincides with the first term of the asymptotics in the paper. The formula in Wikipedia is not quite accurate (contains $\frac1{\sqrt{W(n)}}$ instead of $\frac1{\sqrt{W(n)+1}}$ ). The formula gives good approximation already for small $n\sim 10$ .","['limits', 'asymptotics', 'sequences-and-series']"
4773132,A problem about perpendicular lines and areas bounded by coordinate axes,"I did not want to publish this problem and I wanted to solve it myself, but I was tired of dealing with this difficult problem. This problem, in a way, tells us that we need some theorems that start from areas to calculate lengths. There are many theorems in the opposite direction, but I hardly see any theorems that start from areas.  The lengths are calculated The problem first occurred to me four days ago the problem: We have the Descarte coordinate system and two perpendicular straight lines intersecting at a point that does not belong to the coordinate axes and does not match the coordinate axes, and they limit the Areas $A,B,C$ shown in the above figure. If the data are $A,B,C$ values, how Can we find out the coordinates of their intersection $P$ ? (Suppose we know at what level of the Cartesian level the point $P$ ) there are several ways I tried to deal with the problem but I haven't come up with a final solution yet, I will put some ideas on the problem: perhaps the first idea and the easiest idea is to know that the two triangles are in the area. The same is equal to the square of the similarity, this idea gave me a large number of proportions that can be formulated, and certainly the theorem of Pythagoras also appears with these existing triangles and square proportions, but this method was a great confusion, in front of me a large number Of the equations and distractions and I don't know what to do. A second idea to proceed with the solution: we know that one of the definitions of the hiperbola is that it represents the geometrical place of a moving straight line that confines a fixed space by its intersection with two fixed intersections. $f(x):y=\frac{-(A+C)}{2x}$ , $g(x):y=\frac{B}{2x}$ $f'(x)=\frac{A+C}{2x^2}$ , $g'(x)=\frac{-B}{2x^2}$ $\frac{A+C}{2{x_1}^2}\cdot\frac{-B}{2{x_2}^2}=-1$ $x_2=\frac{\sqrt{B(A+C)}}{2x_1}$ $Δ_1:y+\frac{A+C}{2x_1}=\frac{A+C}{2{x_1}^2}\cdot(x-x_1)$ $Δ_2:y-\frac{B}{2x_2}=\frac{-2{x_1}^2}{A+C}\cdot(x-x_2)$ But I stopped here and couldn't finish I suppose we can continue by finding the equation of the area enclosed between $Δ_1,Δ_2$ and the two coordinate axes and then finding when this equation equals $A$ A third way to deal with the problem is to calculate the lengths in the figure in terms of an optional major length and then deal with that length separately $PS=a$ $OS=\frac{a\sqrt{A+C}}{\sqrt{A+B}}$ $OT=\frac{2B\sqrt{A+B}}{a\sqrt{B}}$ $PT=\frac{2(A+B)}{a}$ $OV=\frac{a\sqrt{B}}{\sqrt{A+B}}$ All of these methods may give some hope and insight to solve this specific problem, but I think that the problem is that the problem is in the lack of theorems that start from the Areas and give a few lengths, and we must start making and collecting them. The lengths are based on given areas. Thank you","['euclidean-geometry', 'geometry']"
4773172,"Double complex branch cut integration, how to?","I'm working on a small project of mine, but I have gotten stuck on a particularly challenging integral: $$\int_{-\infty}^{\infty}\frac{dx}{\sqrt{x^2+1}\sqrt{x^2+ax+b}}$$ With the condition that $a^2-4b<0$ , so all roots will be complex-valued. I'd like to try contour integration around the positive semicircle with center $0$ , but I haven't been able to make it work. Even taking branch cuts as the half-lines $[i, \infty]$ and $[\frac{1}{2}\left(-a + i\sqrt{4b-a^2}\right), \infty]$ did not work, as the estimation lemma decides to render every integral around any point to $0$ , and the integral over the semicircle itself goes to zero as well, as the denominator contains 2 factors of R. What has gone wrong? The contour I've chosen . For clarity I've chosen the nontrivial branch point in the first quadrant, but it might at well be in the second. I can't quite figure out where the nonzero value is hiding, as all integrals I evaluate end up being $0$","['integration', 'definite-integrals', 'complex-analysis', 'contour-integration', 'branch-cuts']"
4773257,Is there a formula that genrates only and all primitive Pythagorean triples?,"The most common formula for generating Pythagorean triples is Euclid's, shown here as $$A=m^2-k^2\qquad B=2mk\qquad C=m^2+k^2$$ It generates all primitves but also generates trivals, doubles,  square multiples, and doubles of square multiples of primitives. A variation of this is \begin{align*}
&A=(2n-1+k)^2-k^2&&=(2n-1)^2+2(2n-1)k\\ 
&B=2(2n-1+k)k    &&=\phantom{(2n-1)^2+{}} 2(2n-1)k+2k^2\\ 
&C=(2n-1+k)^2+k^2 &&=(2n-1)^2+2(2n-1)k+2k^2
\end{align*} It generates no trivials and all primitives but also generates odd square multiples of primitives. In the latter, if we let $\,n=1\implies \big(A=2k+1\quad B=2k^2 + 2k\quad C=2 k^2 + 2 k + 1\big),\,$ or $\,k-1\implies \big(A=4n^2-1\quad B=4n\quad C=4n^2+1\big)$ we get only primitives but not all primitives. Is there a formula that genrates only and all primitives besides the one that generates the ternary tree ?  I doubt such a formula exists but I would love to see it if it does.","['elementary-number-theory', 'algebra-precalculus', 'pythagorean-triples']"
4773277,Find the Area Bounded by $y = \frac{2}{π} [|\cos^{-1}(\sin x)| - |\sin^{-1}(\cos x)|]$ and $x$-axis between $ \frac{3π}{2}≤x≤2π $.,"Find the area bounded by $\displaystyle y = \dfrac{2}{π} \left[ \space \left|\cos^{-1}(\sin x)\right| - \left|\sin^{-1}(\cos x)\right| \space \right]$ and $x$ -axis between $ \dfrac{3\pi}{2}≤x≤2\pi $ .
Here, $\big[ \space $ . $ \space \big]$ means the greatest integer function. My approach was using $\cos^{-1}x = \frac{π}{2} - \sin^{-1}x$ and the same for $\sin^{-1}x$ . $\displaystyle \therefore y = \dfrac{2}{π} \left[ \space \left|\frac{π}{2} - \sin^{-1}(\sin x)\right| - \left|\frac{π}{2} - \cos^{-1}(\cos x)\right| \space \right] $ $ \sin^{-1}(\sin x) = x$ only when $\displaystyle x \in \left[-\dfrac{\pi}{2},\dfrac{\pi}{2}\right] $ $\cos^{-1}(\cos x) = x$ only when $x \in \left[0, \pi \right]$ Since $ \sin(x-2π) = \sin x$ and $ \cos(2π-x) = \cos x $ , $\displaystyle y =  \dfrac{2}{\pi} \left[ \space \left|\dfrac{\pi}{2} - (x-2\pi)\right| - \left|\frac{\pi}{2} - (2\pi-x)\right| \space \right] \iff y = \dfrac{2}{\pi} \left[ \space \left|\dfrac{5\pi}{2}-x\right| - \left|-\dfrac{3\pi}{2}-x\right| \space \right] $ Then, $\displaystyle \left|\dfrac{5\pi}{2}-x\right| > 0$ and $\displaystyle -\left|-\dfrac{3\pi}{2}-x\right| < 0 \implies y = \dfrac{2}{\pi}[\pi-2x]$ After this I do not know how to calculate the area or draw the graph of this function.","['trigonometry', 'functions', 'area', 'inverse-function']"
4773292,Find $\lim\limits_{x\to \infty}\frac{(2+x)\sin^2 x}{x^2 (2+\sin x)}$,"Self studying and would like some reassurance, all criticism/corrections are welcome. We show $\lim_{x\to \infty}\frac{(2+x)\sin^2 x}{x^2 (2+\sin x)} = 0$ First we note that $-1 \le \sin x \iff 1 \le 2 + \sin x \iff \frac{1}{2+\sin x} \le 1$ and $0 \le \sin^2 x \le 1$ . So we can write $\frac{(2+x)\sin^2 x}{x^2 (2+\sin x)} \le \frac{(2+x)\sin^2 x}{x^2} = \frac{\sin^2 x}{x} + \frac{2 \sin^2 x}{x^2} \le \frac{1}{x} + \frac{2}{x^2}$ and $\lim_{x\to \infty} \frac{1}{x} + \frac{2}{x^2} = 0$ . From the previous inequalities we can see $\lim\limits_{x\to \infty}\frac{(2+x)\sin^2 x}{x^2 (2+\sin x)}$ is nonnegative for $x > 0$ . We have $2+x > 0$ , $\sin^2(x) \ge 0 $ and $x^2 >0$ because they are squares, and $2 + \sin x \ge 1 > 0$ as shown above. Since these are all nonnegative, the main expression is nonnegative. Therefore for large $x$ , we have $ 0 \le \frac{(2+x)\sin^2 x}{x^2 (2+\sin x)} \le (\frac{1}{x} + \frac{2}{x^2})$ and by the squeeze theorem $\lim\limits_{x\to \infty}\frac{(2+x)\sin^2 x}{x^2 (2+\sin x)} = 0$ . (from Velleman's Calculus: A Rigorous First Course )","['limits', 'calculus', 'trigonometry', 'real-analysis']"
4773337,P almost continuous version of a stochastic process,"I am studying continuous stochastic processes and I would like to show that if my stochastic process $X$ satisfies the hypothesis of the well known Kolmogorov continuity theorem, I can find a set $A$ with $\mathbb{P}(A)=1$ on which $X_{t}(.)$ is $\delta$ Holdër continuous. Here is the important part of the Kolmogorov continuity theorem that I use to show this (that is the existence of a modification\version $Y$ satisfying the following inequality) : Given assumptions we assume here on a stochastic process $X$ , there exists a version $Y$ of $X$ satisfying for all $\delta\in[0, \frac{\beta}{\alpha}[$ $$
\mathbb{E}\Big[\Big(\sup\Big\{\frac{\lvert Y_s - Y_t\rvert}{\lvert s -t\rvert^{\delta}} : s\neq t\in [0,1]\Big\}\Big)^{\alpha}\Big]<\infty.
$$ where $\alpha,\beta>0$ . Here is my attempt : I denote $k_{\delta} := \sup\big\{\frac{\lvert Y_s - Y_t\rvert}{\lvert s -t\rvert^{\delta}} : s\neq t\in [0,1]\big\}$ . This random variable is finite almost surely from the theorem. Thus, we have $$
\mathbb{P}\Big(\omega \,\big\vert\, \forall\delta\in[0,\frac{\beta}{\alpha}[, \forall s\neq t\in[0,1] : \frac{\lvert Y_s(\omega)- Y_t(\omega)\rvert}{\lvert s -t\rvert^{\delta}}\leq k_{\delta}(\omega)\Big).
$$ By continuity of the process, we have $$
\mathbb{P}\Big(\bigcap_{s\neq t\in [0,1]\cap\mathbb{Q}}\bigcap_{\delta\,\in\, [0,\frac{\beta}{\alpha}[\,\cap\,\mathbb{Q}}\big\{\omega :\lvert Y_s(\omega)- Y_t(\omega)\rvert\leq k_{\delta}(\omega)\lvert s -t\rvert^{\delta}\big\}\Big).
$$ From there, I don’t know how to proceed. I would like to take out the intersection and transform it as a limit, but I cannot justify this. I would like to know if what I have done so far is okay, and, if not, how to improve it. Thank you a lot!","['continuity', 'probability-theory', 'stochastic-processes']"
4773443,"$G = \{c \in \{1, 2, \ldots, n-1\} \mid \gcd(c,n) = 1\},H = \{c \in G \mid \text{ord}(c) \text{ is odd}\}$ Proof H is closed under multiplication","Defining the Groups : $G = \{c \in \{1, 2, \ldots, n-1\} \mid \gcd(c,n) = 1\}$ represents the group of units mod $n$ . These are the integers in the range $1$ to $n-1$ that are coprime to $n$ . $H = \{c \in G \mid \text{ord}(c) \text{ is odd}\}$ represents the subset of elements in $G$ whose multiplicative order modulo $n$ is odd. Proving that H is a Subgroup of G : Attempt For H to be a subgroup of G, it must satisfy the following properties: H is non-empty. Closure: For any two elements x and y in H, the result of the operation x * y is also in H. Associativity: The operation * is associative on H. Identity Element: The identity element of G is also in H. Inverse Element: For each element x in H, the inverse x⁻¹ (in G) is also in H. Proof: H is closed under inversion. Let $k=ord(c)$ it implise $c^k\equiv 1 \mod n \to (c^k)^{-1}\equiv 1 \to (c^{-1})^{k}\equiv 1 \to c^{-1} \in H$ Identity element 1 exist. The first try on $H$ is closed under multiplication: Suppose $a$ and $b$ are two elements in $H$ . This means $\text{ord}(a)$ and $\text{ord}(b)$ are odd. Now, consider the element $ab$ . We want to show that $\text{ord}(ab)$ is odd. Let $\text{ord}(a)=2c+1$ , $\text{ord}(b)=2d+1$ , WLOG let 2c+1 < 2d+1, then we have $\mod n: a^{2c+1} \equiv 1, b^{2d+1} \equiv 1 \to a^{2c+1} b^{2d+1} \equiv 1 \to (ab)^{2c+1} b^{2(d-c)} \equiv 1$ . The second try with proof by contradiction: If $\text{ord}(ab)$ were even, then we'd have $(ab)^{2k} \equiv 1 \mod n$ , which implies $a^{2k}b^{2k} \equiv 1 \mod n$ .","['elementary-number-theory', 'group-theory', 'modular-arithmetic']"
4773444,Finding the relationship (equivalence or implication) between two expressions,"I am trying to find the relationship between $$\exists X \; (p(X) ∧ q(X))$$ and $$\exists X \; p(X) ∧ \forall X \; q(X).$$ I believe that quantifiers cannot be used in forming truth tables, after all both expressions become equal if we take out the quantifiers. Without a truth table I do not know how to find the relationship between these two expression.","['predicate-logic', 'logic', 'discrete-mathematics', 'logic-translation']"
4773454,Does parallel transport apply to points or vectors?,"My current understanding of parallel transport is the following: Let $P \xrightarrow{\pi} M$ be a principal $G$ -bundle and $\gamma: [a,b] \rightarrow M$ a curve in $M$ . For a given connection $A$ , we may define a map $$\Pi_\gamma^A: P_{\gamma(a)} \rightarrow P_{\gamma(b)}\\
p \mapsto \gamma_p^*(b)$$ where $\gamma^*_p$ is the horizontal lift of $\gamma$ such that $\gamma^*_p(a) = p$ . Thus we see that parallel transport is a way to map a point in one fiber to another, hence it maps points in $P$ to points in $P$ . What has been confusing me is that many resources, such as Wikipedia or Wolfram MathWorld , instead describe parallel transport as transporting vectors. I do not see how the above definition of parallel transport has anything to do with vectors unless we consider $(\Pi_\gamma^A)_*$ , the pushforward of the parallel transport map, but this is never mentioned. What is the connection between these two viewpoints?","['principal-bundles', 'connections', 'differential-geometry']"
4773588,"Prove that $d(X,Y) = |X\setminus Y| + |Y\setminus X|$ is a distance","I was trying to prove that, for $S$ the power set of $\{1,2,\dots,n\}$ , the following function $$d(X,Y) = |X\setminus Y| + |Y\setminus X|$$ is a distance function. I managed to prove positivity and symmetry easily, but I am stuck in how to prove the triangle inequality $d(X,Z) \leq d(X,Y) + d(Y,Z)$ . I have tried to look at particular cases, like $Y \subseteq Z$ , but I can't seem to get to a solution. Any hints would be appreciated.","['elementary-set-theory', 'triangle-inequality', 'metric-spaces']"
4773626,why universe is a set?,"Recently, I study algebraic geometry, and the first time I doubt the axiom.
There exists a universe defined to be a set $U$ with these properties: $x \in u \in U \Rightarrow x \in U$ $u \in U$ and $v \in U$ $\Rightarrow \{u,v\}, \langle u,v \rangle, \text{ and } u \times v$ are in $U$ . $x \in U \Rightarrow$ the power set of $x$ is in $U$ and the union of $x$ is in $U$ . $\omega$ , the set of all finite ordinals, is in $U$ $f : a \rightarrow b$ is a surjective function with $a \in U$ and $b \subset U$ , then $b \in U$ If there is an example, then I will be fine. However,  many book let the existence be true, and I was wonder why this is natural like the other axiom in the Euclidean space. I mean, how can I show that universe is ""a set"". I think it is large enough ( $\Bbb N \in U $ and so $\{\Bbb N\}\in U$ ), in this manner recursive. Why many book decide consider universe is actually a set, not a proper class?","['set-theory', 'algebraic-geometry', 'category-theory']"
4773697,"Is there reason for concern with this proof that ""there is a bijective function from $\{1,...,m\}$ to $\{1,...,n\}$ only if $m = n$""?","I am trying to prove that the notion of cardinality for finite sets (defined as the $n$ in $\{1,...,n\}$ with which a given finite set is in bijective correspondence) is well-defined. To that end, it's necessary for me to verify that Let $m,n$ be positive naturals. Then there is a bijective function from $\{1,...,m\}$ to $\{1,...,n\}$ only if $m = n$ . I was initially of the opinion that this answer resolved my problems, but I am no longer so certain. I am making a new question just because the answerer is not active and, therefore, I thought this was the best way to get a consensus answer. Below I give my objections to the accepted answer (perhaps my objections are ill-founded, in which case, I'd appreciate it if someone can set me straight). Ostensibly, the argument (when the answerer writes, ""it suffices"") proves $\operatorname{Card}{\{1,...,m\}} = \operatorname{Card}{\{1,...,n\}}$ but there are two problems with that: (1) We are using this theorem/lemma to prove that $\operatorname{Card} X$ is well-defined in the first place! Thus we cannot make mention of the notion which is not, as yet, well-defined. (2) Even if (1) were not a problem, $\operatorname{Card}{\{1,...,m\}} = \operatorname{Card}{\{1,...,n\}}$ just means, by definition, that both have a bijection to some $\{1,...,k\}$ , which is to say (by composition of bijections) there is a bijection between $\{1,...,m\}$ and $\{1,...,n\}$ . But that was our hypothesis in the first place, and is certainly not the claim that $m = n$ ! I am suspicious that perhaps my issue here is with the dubious ellipsis in the $\{1,...,m\}$ etc. set definitions, and that if I could make that more precise then I would be able to show that which I want to show.","['elementary-set-theory', 'foundations']"
4773717,Is the axiom of choice needed to show that the initial topology is a topology?,"Given any function $f:X \to Y$ and any topology $\tau_Y$ on $Y$ , there is an induced topology $\tau_X$ on $X$ (called the initial topology) whose open sets are the inverse images of the open sets in $\tau_Y$ under $f$ . Now, the inverse image of a union is the union of the inverse images. But given a family of sets $(U_i)_{i \in I}$ in $\tau_X$ , it seems that one needs to use the axiom of choice to choose for each $U_i$ an open set $V_i \in \tau_Y$ for which $f^{-1}(V_i)=U_i$ . Once that is done, one could then show that the union of the $U_i$ s is also in $\tau_X$ . But is the axiom of choice really needed? I think that the answer is no, since if one does not know how to choose a $V_i$ , then one could simply take the union of all the open sets in $\tau_Y$ that would work for $V_i$ .","['axiom-of-choice', 'general-topology']"
