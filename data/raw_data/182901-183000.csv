question_id,title,body,tags
3342062,Is $T$ (defined below) a distribution?,"How to show that $$ 
\langle T, \varphi\rangle = \int\limits_{0}^{+\infty} \frac{\varphi(x)-\varphi(0)}{x^{3/2}} dx,\quad \varphi \in C_0^\infty(\mathbb{R}),
$$ is a distribution? I would first rewrite the definition of $T$ , using $ \varphi(x)-\varphi(0) = \int_0^x \varphi'(t) dt $ . But how to get around the fact that $ \int_{0}^{+\infty} x^{-3/2} dx $ is divergent, how to ""tame"" this integral in order to show that $ \lvert \langle T, \varphi\rangle \rvert \leq C \: \text{sup}_{K} \lvert \varphi'(x) \rvert $ for all $ \varphi \in C_0^\infty(K)$ ?","['integration', 'distribution-theory', 'functional-analysis', 'real-analysis']"
3342083,"Calculus Books, preferably Soviet.","I would like some book recommendations on calculus books for novices. I love old Russian texts and if you you suggest such books(no issue if they are rigorous), I would be very grateful. If the text is quite challenging, I have no problem. But it should be interesting with proper exposition of topics. The book should be good for self-study, preferably a textbook(again, for beginners). And it's not necessary for it to be Soviet. Just anything good. I merely like Soviet/Slavic books and so, the title. Thanks to you all. Edit again:Please try to abstain from suggesting analysis books. All I want is a nice, rigorous Book on Integral and Differential Calculus. Doesn't matter which origin(at this point), but should be translated into English. Thanks.","['calculus', 'soft-question', 'book-recommendation']"
3342110,How to apply SETs properties in this example?,"Let $$ A=\{1,2,3,4,5\}$$ and $$ B=\{1,2,3,6,7\}$$ and $$ C=\{1,2,3,8,9\}$$ is it correct to state: $$(A \cup B)-C = \{1,2,3,4,5,6,7\}-\{1,2,3,8,9\}=\{4,5,6,7\}$$ $$A \cup (B-C) = \{1,2,3,4,5\} \cup \{6,7\}=\{1,2,3,4,5,6,7\}$$ hence $$(A \cup B)-C\neq A \cup (B-C)$$",['elementary-set-theory']
3342141,A question about dihedral group,"The presentation of the dihedral group is $$
D_{2n}= \langle r,s \mid r^{n}=s^{2}=1, (sr)^2=1 \rangle.
$$ Now, let $G$ be a group of order $2n$ . Is it true that if $G$ contains two elements $a,b$ such that $ord(a)=n$ , $ord(b)=2$ and $ord(ba)=2$ , then $G\cong D_{2n}$ ? Edit : If not, what are the conditions that $G$ has to fulfill in order to be isomorphic to $D_{2n}$ ?","['group-presentation', 'group-theory', 'finitely-generated', 'dihedral-groups']"
3342154,"Norms, Metrics, Measures, and Volume on $\mathbb{R}^n$","I want to understand better the interaction of norms (and metrics derived from them) and measure and volume in $\mathbb{R}^n$ . The volume or measure of a set on $\mathbb{R}^n$ is usually defined via the Lebesgue measure using the euclidean volume of cubes covering a set (the product of the length of the sides). With this you end up with some nice properties like translation and rotation invariance of volume. This is consistent with the Euclidean norm whose unit balls also share these properties. However, with other norms on $\mathbb{R}^n$ this isn't the case. If we consider balls defined by the p-norms, $\left\lVert x\right\rVert_p$ with $p>2$ , this is no longer the case. If we take such a ball and then rotate it, it will have the same volume according to the Lebesgue measure but it no longer includes all points of unit distance from its center. My Question Why not define measures that are compatible with the norm (and the corresponding metric induced by the norm) over $\mathbb{R}^n$ ? It seems that the Hausdorff Measure does this, i.e., assigning a fix volume to all unit balls based on the metric. The consequence of such a measure is that rotation invariance is no longer preserved.","['measure-theory', 'lebesgue-measure', 'normed-spaces', 'metric-spaces']"
3342246,Rise function (Gomp),"I am a biologist trying to understand the ODE of growth tumour: Let $N(t)$ denote the number of cancerous cells at time $t$ , which are proliferating at a rate form $$\frac{dN}{dt}=\frac{\lambda N}{\alpha}\left[1-\left(\frac{N}{\theta}\right)^{\alpha}\right] ... (1)$$ where $\alpha(\geq 0 )$ and $\theta(\geq 0 )$ are determined from the growth characteristics of the tumour. and then it says that the solution to this equation is: $$ N(t) = N_0 \{ \left[ \frac{N_0}{\theta} \right]^{\alpha} + e^{\lambda t} \left( 1-\left[ \frac{N_0}{\theta}\right]^{\alpha}\right)  \}^{-1/\alpha} ...(2)$$ where $N_0 = N(t=0)$ . I still don`t understand how you get this answer, I tried to do the simple form, i.e, solving the Gompertzian growth rate, $$\frac{dN}{dt}= -\lambda N \ ln \left( \frac{N}{\theta}\right) $$ , I solved this using the method of separable variables and with some help hehe My first question is: How can you generalised Gompertzian growth into (1) ? It is not clear for me how you can get (2)? And then the paper at some point consider now the effect of exposing a tumour cell population to a cycle-nonspecific  drug at concentration $C(t)$ , thus it gets a new generalised equation: $$ \frac{1}{N} \ \frac{dN}{dt} = \begin{cases}
 \lambda - \mu C(t), \ N \leq N_c,\\
\lambda + \frac{\lambda_1}{\alpha} \left[1- \left(\frac{N}{N_c}\right)^{\alpha}\right]- \mu C(t) , \ N \geq N_c
\end{cases}$$ Here my question is why is the meaning of the cases in the paper, for example, biologically talking, what does it mean considering the case $N_0 \geq N_c \lambda - \mu C_0 \geq 0$ ? This is the paper: https://core.ac.uk/download/pdf/82695656.pdf Really, I would appreciate your hints, help, comments to understand this paper. Thank you for your time and help in advance.","['biology', 'ordinary-differential-equations']"
3342250,Identifying a dense subspace of a Hilbert space,"If $H$ is a Hilbert space with subspace $A$ such that the orthogonal complement $A^\perp$ of $A$ is trivial, i.e. $A^\perp = \{ 0 \}$ , must $A$ be dense in $H$ ?","['hilbert-spaces', 'functional-analysis']"
3342361,Showing $\sum_{k=3}^{n} (-1)^{k}{n\choose k}\sum_{j=1}^{k-2}{j(n+1)+k-3\choose n-2}=(-1)^{n-1} \left[\binom{n}{2}-\binom{2n+1}{n-2}\right]$,"I would like to prove the following binomial identity $$
(*)\quad\quad\sum_{k=3}^{n}
     (-1)^{k}{n\choose k}\sum_{j=1}^{k-2}{j(n+1)+k-3\choose n-2}=(-1)^{n-1} \left[\binom{n}{2}-\binom{2n+1}{n-2}\right]
$$ for every $n\geq 3$ .
Let me say that $(*)$ is implied by the following binomial identity $$
(**)\quad\quad\quad\quad \sum_{k=0}^{n}
     (-1)^{k}{n\choose k}F(k)=0
$$ which seems holding, for any $n\geq 0$ , when defining $$
F(k):=\sum_{j=1}^{k-2}{j(n+1)+k-3\choose n-2}\quad \text{for $k\geq 3$}
$$ and $$
F(2)=0\ ,\quad F(k):=-\sum_{j=k-1}^0{j(n+1)+k-3\choose n-2}\quad \text{for $k=0,1$} 
$$ (latest definitions are given coherently with the principle of domain additivity, that is $\sum_{i=a}^bf(i)+\sum_{i=b+1}^cf(i)=\sum_{i=a}^cf(i)$ , see e.g. the Phira's answer to Upper limit of summation index lower than lower limit? ). Anyway, I'm not able to prove identity $(**)$ , as well! Notice that $(**)$ is equivalent to say that there exist a polynomial $P(x)$ of degree $\deg P\leq n-1$ such that $$
\forall\,k=0,\ldots,n\quad P(k)=F(k)
$$ by $n$ -th finite difference. This fact seems not to be trivial, as the number of monomials of $F(k)$ depends on $k$ , so $F$ is not directly a polynomial in $k$ .","['combinatorics', 'discrete-mathematics']"
3342409,General solution for 1st order differential equation $(1-\sqrt{3})\frac{dy}{dx} + y\sec x = y^{\sqrt3}\sec x$,"How do I find general solution for $$(1-\sqrt{3})\frac{dy}{dx} + y\sec x = y^{\sqrt3}\sec x$$ What I tried $$y^{-\sqrt3}(1-\sqrt{3})\frac{dy}{dx} + y^{1-\sqrt3}\sec x = \sec x$$ Then, $u=y^{1-\sqrt3}  \Rightarrow \frac{du}{dy}=(1-\sqrt3)y^{-\sqrt3}$ $\frac{du}{dx}+u\sec x=\sec x$ $$e^{\int \sec x \,dx}=e^{\ln |\sec x+\tan x|}=\sec x+\tan x$$ $$(\sec x+\tan x)\frac{du}{dx}+u(\sec^2x+\tan x\sec x)=sec^2x+\tan x\sec x$$ $$\frac{d{\bigl((\sec x+\tan x)u\bigr)}}{dx}=\sec^2x+\tan x\sec x$$ After integrating both sides - $\int dx$ , $$(\sec x+\tan x)u=\sec x+\tan x\\
u=1=y^{1-\sqrt3}\\
y=1$$ Where am I doing the mistake ?",['ordinary-differential-equations']
3342501,How to answer problems in set theory and other fields of higher mathematics,"I've recently begun teaching myself some higher mathematics, and am using the textbook Transition to Higher Mathematics, Structure and Proof (2nd Ed.) by Dumas and McCarthy. I've read through the first chapter on set theory and am working on the exercises. The first exercise is below: Show that the following set is empty: $$\{ n \in \mathbb{N} \mid \text{$n$ is odd} \land \text{$n = k(k + 1)$ for some $k \in \mathbb{N}$} \}.$$ Being unfamiliar with the proper way to answer such problems, the solution I would provide is as follows: When $k$ is neither $-1$ nor $0$ , $k(k+1)$ is equal to the product of a an odd and an even number, which is always even. When $k$ is either $-1$ or $0$ , $k(k+1)$ is equal to 0, which is neither odd nor even. $k$ is never odd, thus the set is empty. I would very much appreciate if someone could provide advice on how to answer this and similar problems in a more ""mathematical"" way.","['elementary-set-theory', 'proof-writing']"
3342519,Notation for function where first argument determines domain of second argument,"$\newcommand{\cM}{\mathcal{M}}
\newcommand{\R}{\mathbb{R}}$ I'm writing about a machine learning model selection problem where we have
a finite set $\cM$ of models, each having its own abstract parameter space $\Theta_M$ .
The learning problem induces a reward function $R_M(\theta) : \Theta_M \mapsto \R$ defining the ""goodness"" of a particular model and choice of parameters for that model. Although each $R_M$ has a different domain,
semantically they all compute the ""goodness"" for the same learning task.
In some parts of the exposition, it would help to have a unifying notation
for the ""function"" $R$ that computes: inputs: $M \in \cM,\ \theta \in \Theta_M$ outputs: $R_M(\theta)$ . But it doesn't make sense to define $R : \cM \times \bigcup_M \{ \Theta_M \} \mapsto \R$ because $R(M_i, \theta \in \Theta_j)$ is undefined when $i \neq j$ .
Another place where difficulty arises is talking about the
""universal optimization algorithm"" $A$ that, given $M \in \cM$ , outputs some $\theta \in \Theta_M$ . Is there a preferred way to handle $R$ and $A$ in notation?
Or, an alternate way to frame the problem that avoids this issue entirely?","['notation', 'functions']"
3342549,When is the derivative of $f(g(x))$ equal to $g(f'(x))$?,"By the chain rule, we know that the derivative of $f(g(x))$ is $f'(g(x))g'(x)$ . Question : When is the derivative of $f(g(x))$ equal to $g(f'(x))$ ? Trivial solutions include the following: Let $f$ be any differentiable function and $g$ be the identity function ( $g(x)=x$ ) or the zero function ( $g(x)=0$ ). Let $f$ be any constant function and $g$ be any differentiable function that fixes zero. On the other hand, $f(x)=x^2$ and $g(x)=\sin x$ form a nontrivial solution (by the double angle formula for sine). If $g(x)=x+a$ , where $a$ is a constant, then $f'(x+a)=f'(x)+a$ , so $f(x)=\frac{1}{2}x^2+bx+c$ would work for any two constants $b$ and $c$ . Finally, if $f(x)=mx+b$ , where $m$ and $b$ are constants, then $mg'(x)=g(m)$ , so $g'(x)=\frac{g(m)}{m}$ and $g(x)=\frac{g(m)}{m}x+c$ for some constant $c$ . But this must in particular be true for $x=m$ , so $c$ must be zero and $g(x)=nx$ would then work for any constant $n$ . But I do not know any other solutions. Can anyone help find one? Note that $f$ may be replaced by any other function with the same derivative (i.e. differing from $f$ by a constant) without changing the validity of the equation, so we may assume without lost of generality that $f$ fixes zero (assuming, of course, that zero is in the domain of $f$ ).","['functions', 'derivatives', 'chain-rule', 'real-analysis']"
3342577,Why is adelic approximation a generalisation of Chinese remainder theorem?,"Let $F$ be a global field and $S$ a nonempty finite set of places. Then the image of $F$ under the diagonal adelic embedding $F \to F_S$ is dense. I often read that this fact should be seen as a generalisation of the Chinese remainder theorem, however I don't seen any relation between both (for me Chinese remainder is about the structure of $\mathbb{Z}/n\mathbb{Z}$ , which can be decomposed accordingly to the prime decomposition of $n$ ; or about finding solutions of a system modular equations). Does someone have a clarification, through examples or clear arguments, of this assertion?","['number-theory', 'chinese-remainder-theorem', 'algebraic-number-theory', 'adeles']"
3342602,British Mathematical Olympiad - December 2001 - Round 1 - Question 4,"Twelve people are seated around a circular table. In how many ways
can six pairs of people engage in handshakes so that no arms cross?
(Nobody is allowed to shake hands with more than one person at once.) I don't even understand what this question is asking. My best guess is that people can shake hands over the table (i.e. with someone on the opposite to them on the table) but that seems like something they'd mention in the brackets at the end.","['combinatorial-geometry', 'combinatorics']"
3342620,"What is the $n^\text{th}$ perfect power, $P(n)$?","Let $P(n)$ denotes the $n^\text{th}$ perfect power of natural numbers (in ascending order without repetition). So, $P(1)=1, P(2)=4, P(3)=8, P(4)=9, P(5)=16, P(6)=25, P(7)=27, P(8)=32, \dots$ . Is there any formula to find $P(n)$ for a natural number $n$ ? Say what is $P(75)$ ? I think there is no explicit formula for $P(n)$ since the sequence $P(1), P(2), P(3), \dots$ has no common difference of any order, has no common ratio, and has no pattern in the slopes. What I mean is; if we sketch the line graph $y=P(x)$ , then $P'(x)$ at $x=n$ is always positive, but not always increasing nor always decreasing. Any help to find the $n^\text{th}$ perfect power would be appreciated. THANKS!","['exponentiation', 'elementary-number-theory', 'discrete-mathematics', 'sequences-and-series', 'perfect-powers']"
3342649,How to calculate the residue of a holomorph application germ in $\mathbb{C}^{n}$,"Let $f : U \longrightarrow V $ be a holomorphic map germ defined by $f = (f_{1}, f_{2}) = (z_{2} + z_{1}^{2}, z_{1}^{2} + z_{2}^{2})$ , where $U$ and $V$ are open in $\mathbb{C}^{2}$ both containing $0 \in \mathbb{C}^{2}$ . Note that $f^{-1}(0) = \lbrace (i, 1), (-i, 1), (0,0)\rbrace $ . Let $\overline{U_{0}}$ the closure of a neighborhood $U_{0} \subset U$ of origin such that $\overline{U_{0}} \cap f^{-1}(0) = \lbrace 0 \rbrace$ (*) According with: Multidimensional Residues and Their Applications (A.K.Tsikh) (in our example) the local residue of meromorphic  form $\omega = \dfrac{hdz_{1} \wedge dz_{2}}{f_{1}.f_{2}}$ at the point $(0,0)$ is the integral : $$\text{res}_{(0,0)}\omega = \dfrac{1}{(2 \pi i)^{2}} \int_{\Gamma_{(0,0)}} \dfrac{hdz_{1} \wedge dz_{2}}{f_{1}.f_{2}}$$ where $\Gamma_{(0,0)} = \lbrace z \in U_{0} ; |f_{j}(z)| = \varepsilon_{j} \,, j = 1, 2 \rbrace$ . My doubts are: 1) Is it always possible to get a neighborhood like $U_{0}$ satisfying (*)? 2) If so, how to calculate the residue at $(0, 0) $ according to the definition above?  Can the function $h$ be $\text{det}J(f_{1}, f_{2})$ ? I tried to use power series in the denominator, but was unsuccessful in calculations. References, suggestions and help will be welcome. Thanks a lot.","['complex-analysis', 'residue-calculus', 'several-complex-variables']"
3342652,What method to use for differential equations,"I'm having doubts as to what method to use in the following ODE: $$2t+3x+(x+2)x'=0$$ As this can be changed into: $$x'=\frac{-2t-3x}{x+2}$$ I'm thinking it can be solved by using homogeneous equations method, but I'm not sure this applies because for the $x+2$ in the denominator I'm not sure it would be a homogeneous equation (grade 0 and all). What would you suggest? Thanks!",['ordinary-differential-equations']
3342688,Krull's Principal Ideal Theorem for tangent spaces,"In ""Foundations of Algebraic Geometry"" by Ravi Vakil (page $333$ , problem $12.1.B$ ) there is the following problem Suppose $A$ is a ring, and $m$ a maximal ideal. If $f ∈ m$ , show that the Zariski tangent space of $A/f$ is cut out in the Zariski tangent space of $A$ by $f $ mod $(m ^2 )$ . At this point my question is the following : What is the corresponding precise mathematical statement in terms of isomorphism of vector spaces? Does it mean the following isomorphism of vector spaces: $(m/(f)/(m/(f))^2)^* \cong (m/m^2 -f+m^2)^*$ ? (I mean what is the precise mathematical statement of the part which says ""cut out in the Zariski tangent space""?) Any help from anyone is welcome.","['co-tangent-space', 'algebraic-geometry', 'commutative-algebra', 'tangent-spaces']"
3342711,Euclidean Geometry v.s. Origami Geometry,"It's well known that you can't trisect an arbitrary angle with a traditional straight-edge and compass. However, using methods in traditional Origami, we can trisect an angle. Typically, when discussing these two topics, it's usually in light of demonstrating things that can be done with Origami that can't be done with Euclidean Geometry. However, one notable fact is that you can't construct a circle via techniques in Origami. So for example, the famous $9$ -point circle theorem can't be achieved by methods of Origami. Are there other notable constructions in Euclidean Geometry that can't be accomplished in Origami Geometry?","['euclidean-geometry', 'geometry', 'origami']"
3342729,Theta function identity,"Let us consider the Theta function $$\theta(\tau) =  \sum_{n \in \mathbb{Z}} e^{\pi i n^2 \tau} \text{ for } \mathrm{Im}(\tau)>0.$$ Then it is rather easy to see that $$\theta(\tau+2)=\theta(\tau)$$ and $$\theta(\tau)+\theta(\tau+1)=2 \cdot \theta(4 \tau).$$ Further, one can prove that $$\theta(-1/ \tau) = \sqrt{\frac{\tau}{i}} \cdot \theta(\tau).$$ All together, this yields $$\theta(1- \frac{1}{\tau}) = \theta(- \frac{1}{\tau}) + \theta(1- \frac{1}{\tau}) - \theta(- \frac{1}{\tau}) = 2 \cdot \theta(- \frac{4}{\tau}) - \theta(- \frac{1}{\tau}) = \sqrt{\frac{\tau}{i}} \cdot (\theta(\frac{\tau}{4}) - \theta(\tau)).$$ Here $\sqrt{}$ always denotes the principal branch of the square root. Next, my textbook claims that $$f(\tau) := \theta^4(\tau)-\theta^4(\tau+1)+\tau^{-2} \cdot \theta^4(1- \frac{1}{\tau})$$ fulfils both $f(\tau+1) = - f(\tau)$ and $f(- \frac{1}{\tau}) = - \tau^{2}  \cdot f(\tau)$ (and uses this to deduce that actually $f = 0$ ). It should be possible to derive these using the above $\theta$ -identities, but I am completely stuck here. Any help is appreciated!","['number-theory', 'theta-functions', 'modular-forms']"
3342731,How to solve the following initial value problem?,"Let $f:\mathbb{R}\to \mathbb{R}$ be a  Lipschitz function such that $f(x)=0$ if and only if $x=\pm n^2$ where $n\in \mathbb{N}$ . Consider the initial value problem $$y'(t)=f(y(t)),\ y(0)=y_0$$ Then which of the following are true? $y$ is a monotone function for all $y_0\in \mathbb{R}$ . For any $y_0\in \mathbb{R}$ , there exists $M_{y_0}>0$ such that $|y(t)|\leq M_{y_0}$ for all $t\in \mathbb{R}$ . there exists a $y_0\in \mathbb{R}$ , such that the corresponding solution $y$ is unbounded $\sup_{t, s\in \mathbb{R}}|y(t)-y(s)|=2n+1$ if $y_0\in (n^2, (n+1)^2), \ n\geq 1$ I was trying it by considering a linear function on subintervals $(n^2, (n+1)^2)$ and $0$ on end points. But not able to conclude anything. Plese help.","['initial-value-problems', 'ordinary-differential-equations']"
3342750,Identifying $\mathbb P^L$ with the space of $N+1$- tuples of homogeneous polynomials of degree $d$ in $N+1$ variables,"Let $k$ be a field. $N,d$ be positive integers and define $L= {N+d \choose d } (N+1)-1 $ . Then can we identify $\mathbb P^L$ with the space of $N+1$ - tuples of homogeneous polynomials of degree $d$ in $N+1$ variables , with at least one polynomial non-zero, such that each $f=[f_0,...,f_N] \in \mathbb P^L$ defines a rational map $ f : \mathbb P^N \to \mathbb P^N$ ? Note: I am trying to understand the first few lines of the introduction of this paper https://arxiv.org/pdf/1607.05772","['algebraic-geometry', 'projective-varieties']"
3342754,Reference for Functional Analysis [duplicate],"This question already has answers here : Good book for self study of functional analysis (16 answers) Closed 4 years ago . I am in search for Functional Analysis Books. I need a book which have lots of elementary problems. I mean it should force us to think more which will give a deeper insight for functional analysis. To be precise, I need lots of problems like Is $A$ open in the space $\ell^1$ with respect to norm $\|.\|_2$ . Find a counterexample to this statement and etcetera. I mean it shouldn't ask us trivial questions. It should ask us questions which will force us to think more and more from functional analysis","['book-recommendation', 'functional-analysis', 'reference-request']"
3342781,Why is this map from Leray spectral sequence zero?,"In Stacks Project Lemma 32.37.7 (0C0T) , one considers a finite morphism $f:X\rightarrow Y$ of schemes and the Leray spectral sequence for $\mathcal O_X^*$ and $f$ . It induces an edge map $$H^1(X, \mathcal{O}_ X^*) \longrightarrow H^0(Y, R^1f_*\mathcal O_ X^*).$$ Then it claims that Stacks Project Lemma 30.17.1 (0BUT) shows the above edge map is zero. The cited lemma 30.17.1 says that for any invertible $\mathcal O_X$ -module $\mathcal L$ and $y\in Y$ , there exists an open neighbourhood $V\subseteq Y$ of $y$ such that $\mathcal L\mid_{f^{-1}(V)}$ is trivial. I cannot perceive how this says that the above edge map is zero. I cannot even tell what the image of an invertible module under the edge map is. Any help is sincerely appreciated. Thanks in advance.","['spectral-sequences', 'algebraic-geometry', 'sheaf-cohomology']"
3342810,Differentiating $\frac{dy}{dx}=3x+2y+xy$?,"What would $y''$ be of $\frac{dy}{dx}=3x+2y+xy$ ? In other words, what is the result ( $y''$ ) if I differentiate $y'=3x+2y+xy$ ? Can I do the following: Set $$f(x,y) = 3x+2y+xy$$ then $$f'(x,y) = \frac{df}{dx} + \frac{df}{dy}\frac{dy}{dx}$$ $$ f'(x,y) = (3 + y)+(2+x)(y')$$ $$ f'(x,y) = 3 + y + 2y'+ xy'$$ ?","['calculus', 'derivatives']"
3342856,Optimal control problem with minimization of cost,"Consider the scalar system $\dot{x}=x+u$ , given the constraint $u(t+T)=u(t)$ . Find the control that drive $x(0)=1$ to $x(2T)=0$ and minimizes $$\int_0^{2T}u^2(t)\,\mathrm{d}t$$ Attempt: substituting $u(t)$ we get $$J=2\int_0^T (\dot{x}^2-2x\dot{x}+x^2 )dt$$ Now i can use Euler Lagrange's eq to find a differential equation of the form $$\ddot{x}=x \implies x(t)=c_1e^{t}+c_2e^{-t}$$ Now i can find $c_1$ and $c_2$ using Initial conditions, then find $x(t)$ and after that i can get the optimal control $u^{*}=\dot{x}-x$ .
Is my attemp correct ? i'm unsure about using the constrain given, in the first step of the integral i took out the factor $2$ with incorporates the constrain, is this a valid method ?","['optimal-control', 'optimization', 'control-theory', 'ordinary-differential-equations']"
3342860,Norm of the sum of random vectors from a unit ball,"Let $x_1,\dots, x_n\in \mathbb{R}^d$ be independently distributed from a uniform distribution on a ball of radius $1$ . That is for every $i$ : $x_i \sim U(\{x\in \mathbb{R}^d: \|x\|_2\leq 1\})$ . We look at the norm of the sum of the vectors: X = $\left\|\sum_{i=1}^n x_i \right\|_2$ . I need the following properties of X: 1) $\mathbb{E}[X] = ?$ 2) $Var(X) = ?$ 3) Given some $\alpha >0$ what is $P(X \leq \alpha)$ ? If the vectors would have been distributed by a standard Gaussian distribution then I could answer these questions by considering the coordinate-wise distribution of the sum, which would also be Gaussian with a mean of $0$ and variance of $\sqrt{n}$ . Thus, we could also calculate the mean and variance of the norm of the sum of the vectors, and for the third question the probability would be exponentially small. Also, if we would consider a uniform distribution on the cube it could be calculated quite easily. But I don't know how to do the same calculation for a uniform distribution on the unit ball (note that this is not the unit sphere, the vectors may have different norms).","['vectors', 'probability']"
3342875,"Is it true that if $\limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| > 1$, then $\sum a_n$ diverges?","I am reading ""A Course in Analysis vol.2"" by Kazuo Matsuzaka. There is the following theorem (""ratio test"") in this book. Let $a_n \neq 0$ for all $n$ . (a) If $\limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| < 1$ , then $\sum a_n$ converges absolutely. (b) If $\left|\frac{a_{n+1}}{a_n}\right| \geq 1$ for all $n \geq N$ for some $N$ , then $\sum a_n$ diverges. Is the following statement false? (b') If $\limsup\limits_{n \to \infty}\left|\frac{a_{n+1}}{a_n}\right| > 1$ , then $\sum a_n$ diverges.","['calculus', 'sequences-and-series', 'real-analysis']"
3342898,Qualitative estimations on the first exceeding time,"I am trying to understand some probability theory, but I'm stuck on a very fascinating problem that I do not manage to solve. After the statement of the problem, I'll list some of my unsuccessful thoughts. Let $X_1, \dots, X_n,\dots$ be a sequence of independent random variables, uniformly distributed on $[0,1]$ . Define $$N_n = \min \{ k: \text{such that} \sum_1^k X_i > \frac{n}{2}+ \sqrt{\frac{n}{12}} \}$$ Compute : $\lim_n \mathbb{P}(\frac{N_n}{n} > 1).$ Unsuccessful thoughts: There might be an implicit hint to use the Irvin-Hall distribution formula. I tried to readjuct the definition of $N_n$ by $$N_n = \min \{ k: \text{such that } S_n - \sum_k^n X_i > \frac{n}{2}+ \sqrt{\frac{n}{12}} \}$$ in order to apply some variant of the central limit theorem , but without success. Numerical estimations show that the limit should be close to $1$ . Intuition suggests that the expected value of $N_n$ should be $n$ , but how to show it? And how to use it in order to solve the exercise?","['probability-distributions', 'probability-theory', 'central-limit-theorem']"
3342965,Example of non random variable,"Given that a random variable $X$ defined on a sample space which takes value on the real line is defined as the set of all outcomes such that $X(outcome)\le r$ , with $r$ a real number, that belongs to the event space for every $r$ , can you provide me with one example (or more) of a non-random variable? 
Please give an example that contradicts the part of the statement relative to the fact that the set belongs to the event space, because it is easy to show that a $X$ not defined on the sample space or that takes values outside the real number set is non-random by definition.
I could not use latex properly to write rigorously the definition, however is the definition of Mood, Introduction to the theory of Statistics.","['statistics', 'probability', 'random-variables']"
3342977,When should Pollard Rho be used as opposed to trial division?,"How does one know which factorization algorithm to use on a given integer? More specifically, when should Pollard Rho Brent be used instead of simple trial division? Given the random nature of Pollard Rho Brent it's hard to know with certainty how long it will take to work (e.g. you could get lucky and pick  a starting value that quickly leads to a cycle).","['number-theory', 'integers', 'discrete-mathematics', 'algorithms']"
3342989,"If $ a + b + c = 90^{\circ}$, prove $ \tan(a) \cdot \tan(b) + \tan(b) \cdot \tan(c) + \tan(c) \cdot \tan(a) = 1 $","If $ a + b + c = 90^{\circ}$ , prove $ \tan(a) \cdot \tan(b) + \tan(b) \cdot \tan(c) + \tan(c) \cdot \tan(a) = 1 $ Attempt: Notice that $$ \tan(a+b+c) = \frac{\tan(a+b) + \tan(c)}{1 - \tan(a+b)\tan(c)} $$ $$ = \frac{\frac{\tan(a) + \tan(b)}{1 - \tan(a)\tan(b)} + \tan(c)}{1 - \frac{\tan(a) + \tan(b)}{1 - \tan(a)\tan(b)} \tan(c)} $$ $$ = \frac{\tan(a) + \tan(b) + \tan(c) - \tan(a) \tan(b) \tan(c)}{ (1-\tan(a)\tan(b)) - \tan(a) \tan(c) -\tan(b) \tan(c) } $$ Then the denomenator must be $0$ , so it is proven? Another way: $$ \sin(a+b+c) = 1 \implies \sin(a+b) \cos(c) + \sin(c) \cos(a+b) = 1  $$ $$ \sin(a)\cos(b)\cos(c) + \sin(b)\cos(a)\cos(c) + \sin(c) \cos(a) \cos(b) - \sin(c) \sin(a) \sin(b) = 1$$ $$ \tan(a) \cos(a) \cos(b)\cos(c) + \tan(b) \cos(a) \cos(b) \cos(c) + \tan(c) \cos(a) \cos(b) \cos(c) - \sin(a) \sin(b) \sin(c) = 1$$ $$ \cos(a)\cos(b)\cos(c) (\tan(a) + \tan(b) + \tan(c) - \tan(a)\tan(b)\tan(c)) = 1 $$","['contest-math', 'algebra-precalculus', 'trigonometry']"
3342996,Solving $\sin[\cot^{-1}(x + 1)]=\cos[\tan^{-1}x]$ in two ways gives contradictory results,"I came across this problem to solve for $x$ : $$\sin[\cot^{-1}(x + 1)]=\cos[\tan^{-1}x]$$ I tried to do it initially by converting the cosine term on the right to sine by using $\sin(\frac{\pi}{2}-x)=\cos x$ , but for some reason this doesn't work: $$\sin[\cot^{-1}(x + 1)]=\sin[\frac{\pi}{2}-\tan^{-1}x]$$ $$\implies\cot^{-1}(x + 1)=\frac{\pi}{2}-\tan^{-1}x$$ $$\implies\cot^{-1}(x + 1)=\cot^{-1}x$$ $$\implies x + 1=x$$ $$\implies 1=0$$ Yet, if instead I use $\sin(\frac{\pi}{2}+x)=\cos x$ : $$\sin[\cot^{-1}(x + 1)]=\sin[\frac{\pi}{2}+\tan^{-1}x]$$ $$\implies\cot^{-1}(x + 1)=\frac{\pi}{2}+\tan^{-1}x$$ $$\implies\frac{\pi}{2}-\tan^{-1}(x + 1)=\frac{\pi}{2}+\tan^{-1}x$$ $$\implies\tan^{-1}(-x - 1)=\tan^{-1}x$$ $$\implies-x-1=x$$ $$\implies x=-\frac{1}{2}$$ And this is indeed the correct answer according to the book. What I don't get is why the first method failed. The identity $\tan^{-1}x + \cot^{-1}x = \frac{\pi}{2}$ should hold for all real numbers, so I don't think that is the problem. Moreover, if I plug $\frac 1 2$ and $-\frac 1 2$ into $\cot^{-1}x$ , I get different answers, so this isn't a problem with the cancellation either. What's going wrong here? EDIT: It appears that the problem is that since the value of $x$ is negative, the term $\frac \pi 2 - \tan^{-1}x$ becomes positive and lands outside the range where $\sin x$ is injective, and so the two inputs are different despite the fact that the output of their sine is equivalent. I guess a follow up question here is how one would figure this out without knowing that the answer is negative. It seems impossible to know which conversion to use beforehand without that knowledge.",['trigonometry']
3342998,Geometry behind the definition of Central simple algebra,"Let $A$ be a finite dimensional central simple algebra(CSA) over $k$ . I want to view the definition of CSA geometrically. So If I treat $A$ just as a algebra it means that $A$ is a $k-$ vector space with with distinguished element $1 \in A$ and there is multiplication map $A \otimes_{k} A \rightarrow k$ . Suppose if we fix basis say $\lbrace u_{i} \rbrace$ , then $u_{i}u_{j} = \sum c_{ijk} u_{k}$ ,  where $c_{ijk} \in k$ . If we assume $A$ is associative then it just says that there are relations $\mathcal{R}$ between $c_{ijk}$ , so geometrically it gives a closed subscheme $Spec(k[c_{ijk}]/\mathcal{R})$ inside $Spec(k[c_{ijk}])$ . What is the geometric interpretation of ""simple algebra"" condition and ""central algebra"" condition on that subscheme. Can someone help me in understanding this definition geometrically?","['algebraic-geometry', 'arithmetic-geometry']"
3343010,Confusion over L2 Spaces,"I'm new to stochastic calculus, so hopefully this isn't too silly of a question. Setup: Let $(\Omega,\mathcal{F},\mathcal{F}_t,\mathbb{P})$ be a filtered probability space on which a Brownian motion $W_t$ is defined (and adapted) and fix $T>0$ .  Let $\mathcal{L}^2(W)$ denote the Hilbert space of all progressively measurable stochastic processes $\phi$ defined on $(\Omega,\mathcal{F},\mathcal{F}_t,\mathbb{P})$ which satisfy $$
\|\phi\|_{\mathcal{L}^2(W)}\triangleq \mathbb{E}\left[
\int_0^T \phi_s^2 d[W]_s
\right]<\infty.
$$ Let $H$ denote the Hilbert subspace $$
\left\{
X \in L^2_{\mathbb{P}\otimes m}(\mathcal{F}\times \mathcal{B}([0,\infty)):\,
(\exists \phi \in \mathcal{L}^2(W) ) \, X_t = \int_0^{T} \phi_s dW_s
\right\}
,
$$ where $m$ is the Lebesgue measure on $[0,\infty)$ . Question: Does there exist a bi-Lipschitz function (or even better, a linear isometry) between $L^2_{\mu}([0,\infty))$ and either of these two spaces: ${\mathcal{L}^2(W)}$ ? $H$ ? Where $\mu$ is a Borel measure, defined on the Borel $\sigma$ -algebra $\mathcal{B}([0,\infty))$ ?","['stochastic-analysis', 'stochastic-processes', 'brownian-motion', 'probability-theory', 'stochastic-calculus']"
3343037,Differentiate $\sqrt{\frac{1 +\sin x}{1 -\sin x}}$,I have tried a lot of ways to solve this question but I am unable to get the answer as same as my textbook. The text book answer is as follow: $$\frac{1}{2}\sec^2\left(\frac{\pi}{4}+\frac{{x}}{2}\right)$$ The steps which I took is as follows: $$\sqrt{\frac{1+ \sin x}{1-\sin x}\cdot \frac{1+\sin x}{1+\sin x}}$$ Then Secondly $$\sqrt{\frac{\left(1+\sin x\right)^2}{1-\sin^2 x}}$$ Then I got $$\dfrac{1+\sin x}{\cos x}$$ When I differentiated this I got the following $$\frac{\cos ^2\left(x\right)+\sin \left(x\right)\left(1+\sin \left(x\right)\right)}{\cos ^2\left(x\right)}$$ Can Anyone tell me what I am doing wrong? I also know that $$\sec^2\left(\frac{\pi}{4}+\frac{{x}}{2}\right)=\frac{2}{\left(\cos  \frac{x}{2}-\sin\frac{x}{2}\right)^2}$$ Thank you for the help!,"['trigonometry', 'derivatives']"
3343062,Integral of the form $\int_{-\infty}^{\infty} \frac{e^{-(ax)^2}}{1 + x^2}dx$,"I was reading a paper on nuclear physics when I came across the following definite integral: $$\int_{-\infty}^{\infty}\frac{\zeta}{2\sqrt\pi} \frac{e^{-\frac{\zeta^2}{4} y^2}}{1 + y^2}\mathrm dy$$ The paper gives the expression of the above integral as: $$\int_{-\infty}^{\infty}\frac{\zeta}{2\sqrt\pi} \frac{e^{-\frac{\zeta^2}{4} y^2}}{1 + y^2}\mathrm dy = \frac{\zeta \sqrt\pi}{2} e^{\frac{\zeta^2}{4}}\left(1-\operatorname{erf}\left (\frac{\zeta}{2}\right )\right)$$ Basically, I have no clue where this result comes from. I have tried the substitution $u = \tan^{-1}y$ so that $\mathrm du = \frac{1}{1 + y^2}\mathrm dy$ , but I get the following expression: $$\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}\frac{\zeta}{2\sqrt\pi} e^{-\frac{\zeta^2}{4} \tan^2(u)}\mathrm du$$ Which I do not know how to evaluate. Any help on the above integral would be greatly appreciated. Even a hint as to how to proceed further is welcomed. Thank you so much in advance! PS: This is my first question so I hope the formatting/question wording is not too confusing. Best, Nathan","['integration', 'calculus', 'definite-integrals']"
3343190,Calculate $\int_0^{\pi} \frac{ \cos ( kx ) }{ 1 - 2 \tau \cos (x ) } dx$,"I need to calculate the following integral: $$\int_0^{\pi} \frac{ \cos ( kx ) }{ 1 - 2 \tau \cos (x ) } dx$$ for $k \geq 0$ and $| \tau | < \frac{1}{2}$ . For $k=0$ , I use the reparameterization $t = \tan (x /2)$ , but I have no idea how to do it for $k \geq 1$ . Thanks!","['integration', 'calculus', 'trigonometry']"
3343231,Gelfand-Kolmogorov Theorem for the space $C(X)$ with compact $X$: ring vs algebra version.,"A theorem by Gelfand and Kolmogorov comes in two different guises, depending on which structure we consider on $C(X)$ , namely if that of unital commutative ring or that of algebra. Ring version Let X and Y be compact spaces. Then, $C(X)$ and $C(Y)$ are isomorphic as rings if, and only if, $X$ and $Y$ are homeomorphic. Moreover, every rings isomorphism $T : C(Y)→ C(X)$ is of the form $Tf = f\circ h$ where $h:X →Y$ is a homeomorphism. Identically, we have: Algebra version Let X and Y be compact spaces. Then, $C(X)$ and $C(Y)$ are isomorphic as algebras if, and only if, $X$ and $Y$ are homeomorphic. Moreover, every algebra isomorphism $T : C(Y)→ C(X)$ is of the form $Tf = f\circ h$ where $h:X →Y$ is a homeomorphism. Now these two versions are claimed equivalent, but I cannot find an explicit proof of the fact, nonetheless I think the equivalence is based on the following Lemma : Each nonzero ring homomorphims $\omega:C(Y)\rightarrow \mathbb{R}$ is surjective and for each constant $c\in\mathbb{R}$ , letting $\delta\equiv 1$ , 
  we have $\omega(c\delta)=c$ . Is this sufficient to prove that any ring homomorphism $\lambda: C(X)\rightarrow C(Y)$ is also an algebra homorphism? If not how to prove it? Morover, I think the two equivalent versions of the theorem have a categorical rephrasing: basically we have two contravariant functors: $C(−):Top→ComRing$ $C(−):Top→ComAlg $ Can we say something more about the categorical interpretation of
this theorem? Has the Lemma or whatsoever the result needed to prove the
equivalence, or the equivalence itself, a categorical interpretation
too?","['proof-verification', 'category-theory', 'abstract-algebra', 'functional-analysis', 'general-topology']"
3343255,Prove that $A^5 \neq I$,"$A \in M_{5}(\mathbb{C})$ , $\operatorname{trace}(A) = 0$ , $I-A$ is invertible. Prove that $A^5 \neq I$ I think this problem has something to do with eigenvalue and the fact that trace of a matrix = sum of the eigenvalues. But, I have no idea how to proceed! Thanks!","['matrices', 'trace', 'linear-algebra']"
3343266,Find a recurrence relation which describes the number of possible differences routes which bring the man to the roof,"A man interesting to climb a tower with $n$ floors. Each step he can jump one floor or two floors at once. The man can stop at most one time for rest (but he does not have to). Find a recurrence relation which describes the number of possible differences routes which bring the man to the roof. My attempt: 
If the men can not stop at most one time so $A_n=A_{n-1}+A_{n-2}$ but I don`t know how to take into account the possibility of stopping. EDIT:
An example for the problem:
A rest is one of the steps in the route to the roof.
The following routs are not equivalent:
1-2-3,
1-2-2-3,
1-1-2-3,
1-2-3-3,
when the first number indicates the floor which the man came after one step, the second after two steps and so on..","['combinatorics', 'recurrence-relations', 'discrete-mathematics']"
3343324,types of morphisms in Differential/Algebriac geometry,"In differential geometry, given two manifolds, only special types of morphisms between them are, submersions/immersions/and some one or two other types of maps. In Algebriac geometry, given two schemes, there are more than 10 types of maps between schemes that are of interest. Separated Quasi compact Locally of finite presentation Proper Affine Finite Flat Smooth Unramified Etale Embedding Closed embedding fpqc morphism and many more whose names itself far from my reach. It is difficult to even remember some names, let alone how they are defined. Question : Why is it the case that maps between schemes are super different from that of manifolds? Or, are there analogues of above maps in differential geometry setup as well?","['algebraic-geometry', 'differential-geometry']"
3343363,Characteristic functions agree in a neighborhood of zero,"Suppose I have two random variables $X,Y$ with finite mean . Let's say that their characteristic functions agree in a small neighborhood of zero (this means that there is some $\epsilon>0$ such that $\Bbb E[e^{itX}] = \Bbb E[e^{itY}]$ for all $|t|<\epsilon$ ). Can I conclude that $X \stackrel{d}{=} Y$ ? Remarks: If I remove the condition of finite mean then certainly the answer is no. This is a trivial consequence of Polya's criterion (see Theorem 3.3.22 in Durrett's book). On the other hand, if I instead impose the stronger moment condition that $\Bbb E[e^{\lambda|X|}]< \infty$ for some small $\lambda >0$ , then $X$ and $Y$ certainly must have the same distribution (because then the characteristic functions extend to analytic functions on some domain of $\Bbb C$ which contains the entire real line). Hence the real underlying question is: what is the minimal number of moments needed by $X,Y$ so that $X \stackrel{d}{=} Y$ under the given assumptions on characteristic functions? I suspect that the mgf condition is the minimal one (and tried to construct a counterexample using the lognormal distribution), but I could not prove it. If that's wrong then my next guess is that two moments or one moment would suffice, hence the original question.","['fourier-analysis', 'characteristic-functions', 'probability-distributions', 'real-analysis', 'probability-theory']"
3343401,Are free groups residually simple?,"Let $F_k$ be a free group of rank $k\ge2$ . Given $g\in F_k$ with $g\neq e$ , is there $N \vartriangleleft F_k$ such that $g\notin N$ and $F/N$ is finite simple?","['simple-groups', 'group-theory', 'normal-subgroups', 'free-groups']"
3343433,Does this limit exist and what's its value? $\lim_{n\to\infty}n^y\sum_ {i=1}^{n}\left[e^{-i}-\left(1-\frac{i}{n}\right)^{\!n}\right]$,"Find $$\lim_{n\to \infty}\left\{n^y \sum_ {i=1}^{n}\left[\;e^{-i} -\left(1- \frac {i} {n}\right)^{\!n}\;\right]\right\}$$ I became interested in this problem because the YouTube series BlackPenRedPen (as part of the solution of another limit problem: https://www.youtube.com/watch?v=nPNB26hxLPc&t=7s ) solved the problem in the case $y = 0$ by interchanging sum and limit without justification. I realized that the methods used to correctly solve the case $y = 0$ (i.e., the Monotone Convergence Theorem) might solve the stated problem. Before starting to work on the the problem, I was trying to ascertain if the solution was known or easier than I thought. This problem has been criticized because I didn't supply the reason I was interested in its solution. If one needs a reason to study mathematical questions (beyond interest), then we we should stop working on The Twin Prime Conjecture, Goldbach's Conjecture, the Collatz Problem, the ABC Conjecture, etc.","['limits', 'calculus']"
3343452,What happens to $f(x) = \left\lceil \dfrac{x}{a} \right\rceil \cdot a$ as $x \rightarrow \infty$?,"Consider the function $f(x) = \left\lceil \dfrac{x}{a} \right\rceil \cdot a~~~$ where $a \in R$ and $a \neq 0 $ . Now let us say we are interested in the behavior of $f(x)$ as $x \rightarrow \infty$ . It seems like $f(x) \sim x$ , but I'm trying to come up with a formal proof. For an illustration, refer here .",['limits']
3343453,"Find the $n$th derivative for the function $y=\sin(kx)$, $n\in\mathbb{R}$.","I created a question for a high school calculus exam: Find the $n$ th derivative, $\dfrac{d^ny}{dx^n}$ , for the function $y=\sin(kx)$ , $n\in\mathbb{N}$ . The solution: \begin{align}
\dfrac{d}{dx}\sin(kx)&=k\cos(kx) =k\sin k(x+\frac{\pi}{2})\\
\dfrac{d^2}{dx^2}\sin(kx)&=\dfrac{d}{dx}k\sin k(x+\frac{\pi}{2})=k^2\cos k(x+\frac{\pi}{2})=k^2\sin k(x+\pi)\\
\vdots \\
\dfrac{d^n}{dx^n}\sin(kx)&=k^n\sin k(x+\frac{n\pi}{2})
\end{align} One of my students had asked me ""Why did you include $n\in\mathbb{N}$ in the question?  Does that mean it's possible to be asked for $n\in\mathbb{R}$ later on?"" I'm aware of the existence of the fractional derivative, but I'm unable to give it any meaning or explain it.  So the problem I want to find a solution for is (and I'm totally aware that this is well beyond any high school calculus content): Find the $n$ th derivative for the function $y=\sin(kx)$ , $n\in\mathbb{R}$ . BONUS: Find the $n$ th derivative for the function $y=x^2e^x$ , $n\in\mathbb{R}$ .","['calculus', 'derivatives', 'fractional-calculus']"
3343454,Is the morphism $\mathcal F^\dagger \to \mathcal G^\dagger$ induced by $f$ injective?,"Let $f: \mathcal F\to \mathcal G$ be an injective morphism of presheaves, is the morphism $\mathcal F^\dagger \to \mathcal G^\dagger$ induced by $f$ injective?","['algebraic-geometry', 'sheaf-theory']"
3343497,Prove that matrix $A\in \mathbb{R}^{n \times n}$ is invertible if $A^T = p(A)$,I have to prove that a matrix $A\in \mathbb{R}^{n \times n}$ is invertible if $A^T = p(A)$ where $p(A)$ is a polynomial with non-zero last coefficient. I've tried to use that if $A^T=p(A)$ then $A=p(A^T)$ and to look at $$AA^T = (a_0E+a_1A^T+...+a_m(A^T)^m)(a_0E+a_1A+...+a_mA^m)$$ and somehow to get the expression like $cE=A(...)$ or $cE=A^T(...)$ which will prove what I need but failed.,"['matrices', 'transpose', 'linear-algebra']"
3343537,Reference request - Theory of rational multivariate generating functions (extracting coefficients of their taylor expansion),"I'm looking for a book/text/paper/etc. that develops the theory of multivariate (/bivariate) generating functions with special focus on how to extract coefficients. If possible, I'd like the source to develop a theorem that allows one to directly transform the rational generating function into the underlying coefficient-sequence. In the case of univariate generating functions this theory looks roughly like this: Given a rational generating function $F(x)= \frac{P(x)}{Q(x)}$ of $ \sum_{n\ge 0}a_n x^n$ determine the reciprocals of the zeroes of $Q(x)$ with their multiplicity. This then gives us the function class of $a_n$ . We substitute in the first few values and solve the equation system for the unknowns, and arrive at a formula for $a_n$ . Can anybody hint me to good references for this theory?","['reference-request', 'combinatorics', 'taylor-expansion', 'discrete-mathematics', 'generating-functions']"
3343591,Prove an inverse and identity of a group exists,"A set $G$ has an operation $\ast$ and is closed and associative under that operation. (a) there exists $e$ in $G$ such that $a \ast e=a$ Prove $e$ is the identity by showing $e\ast a=a$ (b) For all $a$ in $G$ there exists $b$ such that $a \ast b=e$ Prove $b$ is an inverse by showing $b \ast a=e$ For (a) I tried $e \ast e=e$ , $e \ast a \ast e= a \ast e$ , and $e \ast a = a$ . But I'm not sure if that's allowed since I'm very new to abstract still. For (b) I'm completely stumped. My professor gave the hint to start with $b \ast a$ and develop $e$ but I keep thinking to do it via commutative ways which I know isn't guaranteed to happen in a group. Is there a way to manipulate associativity and closure to get there? Any help is appreciated.","['group-theory', 'abstract-algebra', 'inverse', 'semigroups']"
3343625,Integrating $\int_a^b\left[ \left(1 - \frac{a}{x} \right)\left(\frac{b}{x}-1 \right) \right]^\frac{1}{2}dx$,"We are interested in the following integration: $$ \int_a^b \left[ \left(1 - \frac{a}{x} \right)\left(\frac{b}{x}-1 \right) \right]^{1/2} dx. $$ I try to use substitution with: $$u = \left(1-\tfrac{a}{x}\right)\left(\tfrac{b}{x} -1\right) = (a+b)x^{-1} - 1 - (ab)x^{-2}.$$ $$ du = \left( (-a-b)x^{-2} + (2ab)(x^{-3}) \right)dx $$ or $$  dx = du \left( \left( (-a-b)x^{-2} + (2ab)(x^{-3}) \right)^{-1} \right)$$ Now the integration becomes something ugly. I try integration by parts on the ugly part, and it becomes even uglier. Obviously, I don't see some easier ways. I would appreciate some advices or the solution! Edit: It may be easier to see the problem as $$ \int_a^b \left[ (a-x)(x-b)x^{-2}  \right]^{1/2} dx .$$","['integration', 'calculus', 'definite-integrals']"
3343741,Is $\mathbb{Q}(\sin\frac{2\pi}{n})$ Galois over $\mathbb{Q}$?,"I have shown that $\mathbb{Q}(\cos\frac{2\pi}{n})$ is Galois over $\mathbb{Q}$ since it's contained in the $n$ -th cyclotomic field. But I don't think it's also true for $\mathbb{Q}(\sin\frac{2\pi}{n})$ . I tried the case $n=5$ as follows: Since $\sin\frac{2\pi}{5}=\sqrt\frac{5+\sqrt 5}{8}$ , its minimal polynomial over $\mathbb{Q}$ is $f(x)=x^4-\frac{5}{4} x^2+\frac{5}{16}$ . So $\pm$$\sqrt\frac{5+\sqrt 5}{8}$ and $\pm$$\sqrt\frac{5-\sqrt 5}{8}$ are its roots. But I don't know whether $\sqrt\frac{5-\sqrt 5}{8}$ is in $\mathbb{Q}(\sin\frac{2\pi}{n})=\mathbb{Q}(\sqrt\frac{5+\sqrt 5}{8})$ . Maybe I should assume the contrast and lead to a contradiction? If $\mathbb{Q}(\sin\frac{2\pi}{n})/\mathbb{Q}$ is Galois, then $\mathbb{Q}(\sin\frac{2\pi}{n},\cos\frac{2\pi}{n},i)/\mathbb{Q}$ is also Galois... But again I get lost. Can someone give me some hints? Many thanks.","['field-theory', 'galois-theory', 'abstract-algebra']"
3343777,A matrix of order 8 over $\mathbb{F}_3$,"What is an example of an invertible matrix of size 2x2 with coefficients in $\mathbb{F}_3$ that has exact order 8? I have found by computation that the condition that the 8th power of a matrix $\begin{bmatrix}a & b\\c & d\end{bmatrix}$ is the identity is $$
b c (a + d)^2 (a^2 + 2 b c + d^2)^2 + ((a^2 + b c)^2 + 
   b c (a + d)^2)^2=1, \qquad b (a + d) (a^2 + 2 b c + d^2) (a^4 + 4 a^2 b c + 2 b^2 c^2 + 
   4 a b c d + 4 b c d^2 + d^4)=0, \qquad c (a + d) (a^2 + 2 b c + d^2) (a^4 + 4 a^2 b c + 2 b^2 c^2 + 
   4 a b c d + 4 b c d^2 + d^4)=0, \qquad b c (a + d)^2 (a^2 + 2 b c + 
    d^2)^2 + (b c (a + d)^2 + (b c + d^2)^2)^2=1
$$ and the condition for invertibility is $ad\neq bc$ . If the 4th power is not the identity, then no power that is not a multiple of 8 is not the identity (because we could cancel out to either get that the first power is the identity or that the second power is the identity, both lead to contradiction). That is another cumbersome condition to write out. I hope somebody can suggest a nicer way.",['linear-algebra']
3343784,Finding the maxima of a multivariable function using Lagrange's Multipliers,"I'm practicing Lagrange Multipliers (LM) $^{[1]}$ with the following self-made question: Given $a + b + c + d + e = 1$ , where $a, b, c, d, e \notin R^-$ . Find the maximum value of $ab + bc + cd + de$ I already know that the answer is $1/4^{[2]}$ . But, as an exercise, I want to use LM. My Attempt: Let, $$ f(a, \ ... \ ,e) = ab + bc + cd + de \\
g(a, \ ... \ ,e) = a + b + c + d + e = 1 $$ Then, define: $$ \mathcal{L}(a, \ ... \ ,e, \lambda) = f(a, \ ... \ ,e) - \lambda \cdot [g(a, \ ...\ ,e) - 1] \\
\therefore \mathcal{L}(a, ... ,e, \lambda) = ab + bc + cd + de - \lambda \cdot [a + b + c + d + e - 1] $$ Now, $\nabla\mathcal{L} = 0$ would give maxima / minima. On partial differentiation, we get, $$ \begin{align}
b = \lambda \qquad (from \ \ \frac{\delta\mathcal{L}}{\delta a}) \tag 1\\ 
d = \lambda \qquad (from \ \ \frac{\delta\mathcal{L}}{\delta e}) \tag 2\\ 
a + c = \lambda \qquad (from \ \ \frac{\delta\mathcal{L}}{\delta b}) \\ 
c + e = \lambda \qquad (from \ \ \frac{\delta\mathcal{L}}{\delta d}) \\ 
b + d = \lambda \qquad (from \ \ \frac{\delta\mathcal{L}}{\delta c}) \tag 3
\end{align}$$ Here, equations $(1)$ , $(2)$ and $(3)$ seems contradicting. Why it is so? Note: I tested the same approach with $2$ , $3$ and $4$ variables and it gave me correct results. Why so? References: [1]: Lagrange multipliers, examples - Khan Academy [2]: If $a,b,c,d,e,f$ are non negative real numbers such that $a+b+c+d+e+f=1$, then find maximum value of $ab+bc+cd+de+ef$","['maxima-minima', 'multivariable-calculus', 'lagrange-multiplier']"
3343831,Problem in solving an inequality.,"Let $a,b,c,d \in \Bbb R^{+}$ be such that $a>b$ and $c>d$ with $a+b=c+d.$ If $a > c$ (and consequently $b<d$ ) then show that $$\sqrt a + \sqrt b < \sqrt c + \sqrt d.$$ My attempt $:$ Suppose on the contrary we have $$\sqrt a + \sqrt b \geq \sqrt c + \sqrt d.$$ Squaring both sides we have $$a+b + 2\sqrt {ab} = c+d + 2 \sqrt {cd}.$$ Since $a+b= c+d$ we have $$\sqrt {ab} \geq \sqrt {cd}.$$ Again squaring we have $$ab \geq cd.$$ Now how do I draw a contradiction from here? I note that If $b \geq c$ then $a+b > 2c$ since it is given that $a>c.$ Now since $c > d$ so we have $a+b > c+d,$ a contradiction to the fact that $a+b=c+d.$ So we must have $b < c.$ $b<d$ as well for the same reason. Hence we can conclude that $a>c>d>b.$ Does it help me anyway in proving the required inequality? Any help will be highly appreciated. Thank you very much.","['algebra-precalculus', 'proof-writing', 'inequality']"
3343868,Combinatorics problem about odd counts,"There are boys and girls studying at a school. A group of boys is called good if every girl knows at least one boy from the group. A group of girls is called good if every boy knows at least one student in the group. Prove that if the number good boy groups is odd, the number of girl good groups is also odd. (knowledge is mutual) The problem is from a Romanian National Olympiad, and I tried solving it for about two hours but made no apperant progress. I will be happy if someone can explain it to me. Thank you in advance!","['invariance', 'combinatorics']"
3343884,How to apply chain rule to $\log$ function,"I'm doing my economics reading and I find this equation for elasticity of substitution: $$\sigma \equiv \frac{F_K \cdot F_L}{F \cdot F_{KL}}$$ and then $$\frac{d(\log(F_K/F_L))}{d(\log(K/L))}=-\frac{1}{\sigma}.$$ How do I do the later derivative? By chain rule or anything else?
Many thanks.","['economics', 'derivatives', 'chain-rule']"
3343902,We have a function which takes a two-dimensional input and has two parameters. How to find (∂𝑓/∂(𝑤_2)),"Question: We have a function which takes a two-dimensional input $x = (x_1, x_2)$ and has two parameters $w = (w_1, w_2)$ given by $f(x, w) = σ(σ(x1w1)w_2 + x_2)$ where $σ(x) = 1/(1+e^{-x}))$ . We use backpropagation to estimate the right parameter values. We start by setting both the parameters to
0. Assume that we are given a training point x1 = 1, x2 = 0, y = 5. Given this information
answer the next two questions. What is the value of $∂f/∂w_2$ ? Solution: Write $σ(x_1w_1)w_2 + x_2$ as $o_2$ and $x_1w_1$ as $o_1$ $∂f/∂w_2=∂f/∂o_2*∂o_2/∂w_2$ $∂f/∂w_2= σ(o_2)(1 − σ(o_2)) × σ(o_1)$ # Need to understand here $∂f/∂w_2
= 0.5 ∗ 0.5 ∗ 0.5
=0.125$ Can some one help me to understand the solution?
What is the $f$ equation, which partially derivated with $o_2$ to get $σ(o_2)(1 − σ(o_2))$ ? And not understood, from where $0.5$ came. Please help.","['partial-derivative', 'machine-learning', 'derivatives']"
3343930,"Intuition for why gluing two $\operatorname{Spec} k[\varepsilon]$ gives $\operatorname{Spec} k[\varepsilon_1, \varepsilon_2]$","Sorry for the terse title; the 150-character limit really gets in the way when you have to include ""\varepsilon"" in the title several times. Write $k[\varepsilon]$ for the dual numbers, i.e. $k[x]/(x^2)$ . If we glue two copies of $\operatorname{Spec} k[\varepsilon]$ along their closed points, we get $\operatorname{Spec} k[\varepsilon_1, \varepsilon_2]$ . In geometric terms, if we take two points, each with ""one dimension's worth of tangent information"" attached, and glue the points together, we get a point with ""two dimensions' worth of tangent information attached.""  This is related to the fact that tangent spaces always really are vector spaces, even in cases where the tangent cone is not. In contrast, if we glue, say, two copies of $\operatorname{Spec} k[x]$ together at one of their points we'd get $\operatorname{Spec} k[x,y]/(xy)$ , a space where you can move away from the glue point in two distinct directions. So if you glue two lines together you somehow preserve the fact that some directions are along the lines and others aren't, whereas if you glue two ""infinitesimal lines"" together you can no longer see what direction the infinitesimal lines had pointed in from the resulting space alone. By ""directions"" here I mean that the inclusion of e.g. $\operatorname{Spec} k[x] \hookrightarrow \operatorname{Spec} k[x,y]/(xy)$ determines a tangent vector in $T_{(0,0)} \operatorname{Spec} k[x,y]/(xy)$ . I can calculate that all these things are true, but I've never really been able to internalize the idea.  Does anyone have a nice way of thinking about this?","['algebraic-geometry', 'soft-question', 'schemes', 'singularity']"
3344100,Is it true that every Banach space has Bolzano Weierstrass property?,"Is it true that every bounded sequence in $C[0,1]$ with sup norm has convergent subsequence? I really feel this statement is true and the crux of the proof will lie in that $C[0,1]$ is complete. But I am unable to prove it mathematically by constructing a Cauchy subsequence for any random sequence ( which will eventually be convergent). Also is my observation correct that every Banach space has this property?","['banach-spaces', 'functional-analysis', 'real-analysis']"
3344109,Differential of exponential function,"I have the following theorem and proof in my lecture, which I don't quite understand: Let $M$ be a smooth manifold, $p \in M$ . Then it holds that $(d \exp _p)_0=: T_0 T_pM \cong T_pM \rightarrow T_pM$ is the identity. On the proof it says:
 Since $\exp(tv)= \gamma_v(t)$ for $v \in T_pM$ , it holds $$(d  \exp _p)_0 (v)= \biggl.\dfrac{\partial}{\partial t} \biggr|_0  \exp (tv)=v$$ ( $\gamma_v$ is the unique maximal geodesic with $\gamma^{'}(0)=v$ ). Now what I don't understand: The exponential function is only defined on a neighboorhood of $0$ in $TM$ right, so $(d \exp_p)_0: T_0 D$ where $D \subset T_pM$ , right? I don't understand the proof at all, where does the $\frac{\partial}{\partial t}$ come from? Can somebody explain this?","['semi-riemannian-geometry', 'geodesic', 'riemannian-geometry', 'differential-geometry']"
3344167,Range of functions,"What is the range of the function: $$f(x,y)=\frac{7}{x^2+y^2+1}$$ I was thinking maybe, given that $x^2+y^2$ does not equal $-1$ , then it could be any number from 0 to infinity? Or is that wrong?","['functions', 'derivatives', 'interval-arithmetic', 'integral-domain']"
3344196,What is the adjoint representation of $\operatorname{GL}_n(\mathbb{R})$?,"This question has been asked several times, and virtually every introductory textbook on Lie groups and Lie algebras will cover this. But every single explanation goes beyond me. Let $G$ be a Lie group. Let $\Psi : G \to \operatorname{Aut}(G)$ be the map sending $g \in G$ to the conjugation map $h \mapsto g h g^{-1}$ . For any $g \in G$ , the conjugation map $\Psi(g) : G \to G$ admits a total derivative $d\Psi(g)_e : T_e G \to T_e G$ . Varying $g$ , this may be expressed as a representation $\operatorname{Ad} : G \to \operatorname{Aut}(T_e G)$ . Then, we define $\operatorname{ad} : T_e G \to \operatorname{End}(T_e G)$ to be the total derivative $d \operatorname{Ad}_e$ . Question. What is $\operatorname{ad}$ when $G = \operatorname{GL}_n(\mathbb{R})$ ? What I know. Suppose $A$ is a matrix in $\operatorname{GL}_n(\mathbb{R})$ . Then $\Psi(A)$ is the map sending a matrix $M$ to $AMA^{-1}$ . We can take the derivative of $\Psi(A)$ , which is a map $d \Psi(A)_e : T_e \operatorname{GL}_n(\mathbb{R}) \to T_e \operatorname{GL}_n(\mathbb{R})$ . As $\operatorname{GL}_n(\mathbb{R})$ is an open submanifold of $\operatorname{Mat}_n(\mathbb{R})$ , I can identify the tangent space of $\operatorname{GL}_n(\mathbb{R})$ with $\operatorname{Mat}_n(\mathbb{R})$ . Moreover, for every matrix $X$ , I have a particularly simple choice of a path $\gamma : I \to \operatorname{GL}_n(\mathbb{R})$ passing through $I_n$ with derivative $X$ at $t = 0$ , namely, $\gamma(t) = I_n + tX$ . So to find out what $\operatorname{Ad}(A)$ is, I can write $d\Psi(A)_e(X)$ , for any matrix $A$ in $\operatorname{GL}_n(\mathbb{R})$ and for any element $X \in T_e \operatorname{GL}_n(\mathbb{R}) = \operatorname{Mat}_n(\mathbb{R})$ , as $$d \Psi(A)_e(X) = \frac{d}{dt} \Psi(A)(I + tX) = \frac{d}{dt} A(I + tX)A^{-1} = \frac{d}{dt} (I + AtX A^{-1}) = AXA^{-1}.$$ So, $\operatorname{Ad}(A)$ is $d\Psi(A)_e$ , which is the map $X \mapsto AXA^{-1}$ . But then you have to take a further derivative. And here the limit of my capacity is reached. The complexity of the objects and maps involved simply impede me from seeing what it even means to take a derivative anymore, let alone being able to calculate it.","['lie-algebras', 'smooth-manifolds', 'matrices', 'lie-groups', 'differential-geometry']"
3344200,Find n in sum that results in a number $aaa$,"Lets say that we have the sum $1+2+3+\ldots+n$ where $n$ is a positive natural number and that this sum should equal a three digit number in which all the digits are the same, for example $111, 222,$ and so on. What would be the best way to find the $n$ that would result in such a number? I guess you could solve $\frac{n(n+1)}{2}=111x$ but that seems a bit too hard. From trial and error we know that the only solution is $n=36$ which gives $666$ .","['number-theory', 'algebra-precalculus', 'summation', 'elementary-number-theory']"
3344207,Is this enough to prove that every continuous function $u:\mathbb{R}\rightarrow \mathbb{R}$ is measurable?,"In one exercise I am asked to prove that every continuous function $u:\mathbb{R}\rightarrow \mathbb{R}$ is $\mathcal{B}/\mathcal{B}$ - measurable. I have an answer for this question but it does not look the same as the suggested one, so I would like to know if I am doing something wrong or the two are equivalent. My answer goes as follows: We know that for every continuous function we have that the pre-image of an open set is again an open set. a function $u$ is $\mathcal{B}/\mathcal{B}$ - measurable  iff $u^{-1}(B)\in \mathcal{B},  \forall B\in\mathcal{O}$ , where $\mathcal{B}$ is the Borel sigma algebra, and $\mathcal{O}$ is the family of open sets on $\mathbb{R}$ ( a generator of the Borel sigma-algebra). Hence I take an open set $B\in \mathcal{O}$ and by the first point we have that $u^{-1}(B)$ is an open set. It follows that $ u^{-1}(B)\in \mathcal{O}\subset \mathcal{B}$ . Is this enough as a prove?
Thanks in advance.","['measure-theory', 'proof-verification']"
3344246,Convolution of measures and stochastic dominance,"Consider two probability measures on $\mathbb{R}$ , namely $\mu$ and $\nu$ . Suppose that $\mu$ stochastically dominates $\nu$ so that $\mu \ge \nu$ . Here I am considering the first-order stochastic dominance, i.e. $$ \mu \ge \nu \iff \int_{\mathbb{R}} f(x) \: \mathrm{d}\mu(x) \ge \int_{\mathbb{R}} f(x) \: \mathrm{d}\nu(x)  $$ for all non decreasing measurable functions $f$ . My question is: does the convolution between measures preserve this ordering? In particular, is the following statement true? $$ \mu \ge \nu \implies \mu^{*n} \ge \nu^{*n}$$ where $\mu^{*n}=\underbrace{\mu*\mu*\dots*\mu}_{n \text{-times}}$ . I think this is trivial but I don't see how to prove it rigorously.","['measure-theory', 'functional-analysis', 'probability', 'stochastic-calculus']"
3344253,Show that the torsion satisfies $\tau(s)=\frac{-\alpha'(s)\wedge\alpha''(s)\cdot\alpha'''(s)}{|\kappa(s)|^2}$,"Let $\alpha:I\rightarrow\mathbb{R}^{3}$ a curve parametrized by arc lenght $s$ . Denote by $t(s)=\alpha'(s)$ the tangent vector, $\kappa(s)=|\alpha'(s)|$ the curvature, $n(s)=\alpha''(s)/\kappa(s)$ the normal vector, $b(s)=t(s)\wedge n(s)$ the binormal vector. The torsion is the number $\tau(s)$ such that $b'(s)=\tau(s)n(s).$ I need to show that $$\tau(s)=\frac{-\alpha'(s)\wedge\alpha''(s)\cdot\alpha'''(s)}{|\kappa(s)|^2}$$ . I already showed that $$\frac{-\alpha'(s)\wedge\alpha''(s)\cdot\alpha'''(s)}{|\kappa(s)|^2}n(s)=
\frac{-t(s)\wedge n(s)\cdot\alpha'''(s)}{\kappa(s)}n(s),$$ and, since $b'(s)=t'(s)\wedge n(s)+t(s)\wedge n'(s),$ I need to prove that $$\frac{-t(s)\wedge n(s)\cdot\alpha'''(s)}{\kappa(s)}n(s)=t'(s)\wedge n(s)+t(s)\wedge n'(s). $$ How can I do that?","['curves', 'curvature', 'differential-geometry']"
3344266,"Are there mathematical concepts that exist in dimension $4$, but not in dimension $3$?","Are there mathematical concepts that exist in the fourth dimension, but not in the third dimension? Of course, mathematical concepts include geometrical concepts, but I don't mean to say geometrical concept exclusively. I am not a mathematician and I am more of a layman, so it would be appreciated if you could tell what the concepts are in your answer so that a layman can understand.","['philosophy', 'big-list', 'soft-question', 'geometry']"
3344307,Proof that the Identity Relation is a subset of a Relation composed with its Inverse,"I found this problem in my professor's set theory notes: $""$ Let $R \subseteq A \times A$ .  Prove $$I_{A} \subseteq R \circ R^{-1} \quad \text{ and } \quad I_{A} \subseteq R^{-1} \circ R.""$$ First off, while I did attempt a solution (shown below), this problem doesn't even sound right.  If anything I would think $R \circ R^{-1}, R^{-1} \circ R \subseteq I_{A}$ . By definition $$I_{A}=\{ (a,a) \in A \times A | a \in A\},$$ ergo it seems to be capable of containing many elements not found in $R \circ R^{-1}, R^{-1} \circ R$ . Anyways, here is my attempt at a solution: Take $(x,x),(y,y) \in I_{A}$ such that $xRy$ .  Note $xRy$ implies $yR^{-1}x$ . Note also that $xRy$ and $yR^{-1}x$ imply $$(x,x) \in R^{-1} \circ R$$ and $$(y,y) \in R \circ R^{-1} \text{.}$$ Hence, if $(x,x),(y,y) \in I_{A}$ , then $(x,x) \in R^{-1} \circ R$ and $(y,y) \in R \circ R^{-1}$ . Thus $I_{A} \subseteq R^{-1} \circ R, R \circ R^{-1}$ . Anyways, he's got the phD and I don't so I'm probably wrong somewhere in my thinking.  Any help would be appreciated guys, thank you!","['elementary-set-theory', 'proof-verification', 'logic', 'relations']"
3344380,To find derivative of $x!$ W.R.T $x$ [duplicate],"This question already has answers here : Did I derive a new form of the gamma function? (3 answers) Closed 4 years ago . I was curious to find the derivative of $x!$ and tried it myself on a basic level. This is what I tried :- (Please forgive me for not writing it in text I am bit slow in that and lazy too!) My question is whether this answer is correct or not since i find answers which are really beyond my knowledge:- Please help me figuring out whether my answer is correct or not and if correct then why wolfram shows such answer.
(I am student and have no idea about those functions)
Thanks!","['calculus', 'derivatives']"
3344418,Which of the following are subspaces of $C(\mathbb{R})$,"I got a question: Let $C(\mathbb{R})$ be the collection of all continuous functions from $\mathbb{R}$ to $\mathbb{R}$ . Then $C(\mathbb{R})$ is a real vector space with pointwise addition and scalar multiplication defined by $$(f + g)(x) = f(x) + g(x) \text{ and } (rf)(x) = rf(x)$$ for all $f, g \in C(\mathbb{R})$ and all $r, x \in \mathbb{R}$ . Which of the following are subspaces of $C(\mathbb{R})$ ? I. { $f: f \text{ is twice differentiable and } f''(x) - 2f'(x) + 3f(x) = 0$ for all x} II. { $g: g \text{ is twice differentiable and } g''(x) = 3g'(x)$ for all x} III. { $h: h \text{ is twice differentiable and } h''(x) = h(x) + 1$ for all x} I believe that all three are correct, since they are all continuous functions on $\mathbb{R}$ . However, the answer says that only I and II are correct. Could anyone tell me what is wrong with III? Also, I don't see anything meaningful for the two constraints by the pointwise addition and scalar multiplication. Could anyone also tell me why do they matter here and how will they affect the answer to this question if these two constrains are not here? Thanks! ---Follow ups from answers: So is it safe for me to conclude that h fails ALL multiplication tests and addition tests, since the general form of h = $Ae^{-x} + Be^x - 1$ , and any attempt to add or multiply to this formula will screw up the constant part -1?","['functions', 'linear-algebra']"
3344454,Conservation of the Hamiltonian,"I'm struggling with the following calculus of variation problem. For an autonomous problem, it is often said that the Hamiltonian is constant along an extremal trajectory. However, the proofs of that fact that I found in the literature rely on the optimal trajectory being twice continuously differentiable, and on a bruteforce differentiation of the Euler-Lagrange equation. Is there a simple argument for a once continuously differentiable extremal? I tried to apply DuBois-Reymond lemma but failed.","['ordinary-differential-equations', 'calculus-of-variations', 'complex-systems', 'euler-lagrange-equation', 'dynamical-systems']"
3344462,Methods for spline fitting for transcendental functions? How to place the knots?,"I was thinking about the following problem the other day: Fit a spline $s(t)$ to some transcendental function $f(t)$ , so that: $$s(t) = \cases{P_k(t), \text{ if } t_k \leq t \leq t_{k+1}}$$ For polynomials $P_k(t)$ : $$P_k(t) = \sum_{i=0}^{N} c_{ik}t^i$$ Now we seek $c_{ik}$ so that $s(t)$ approximates $f(t)$ well on interval $t\in [t_0,t_{max}]$ . How can we do this? How to choose the $t_k$ knot points? Which boundary conditions should be obeyed there? If the knot points were fixed then the problem could be approached like some least squares norm minimization: $$\sum_l\|s(t_l)-f(t_l)\|_2^2 + \epsilon(\text{boundary terms})$$ All would be linear. But how to tackle the non-linearity that is introduced with not knowing where knot points should be placed?","['calculus', 'spline', 'linear-algebra', 'optimization', 'numerical-methods']"
3344468,Combinatorics problems that can be solved more easily using probability,"I'm looking for examples of combinatorics problems which would be very difficult to solve by direct enumeration, but can be easily solved using ideas from probability, like independence, commuting sums and expectations, etc.  I know I have seen such problems before, especially in the HMMT combinatorics subject tests, but I can't now recall any good examples. I am NOT looking for probabilistic existence proofs (the so-called "" probabilistic method "" introduced by Erdos).  The sort of problems I'm interested in are enumerative.","['probabilistic-method', 'big-list', 'combinatorics', 'discrete-mathematics', 'probability']"
3344487,"If $\phi$ is a character of $G$ such that $\langle \phi,\phi \rangle=4$, then there exists a character $\chi$ of $G$ such that $\phi=2\chi$","I am stuck on the following problem that says: If $\phi$ is a character of $G$ such that $\langle \phi,\phi \rangle=4$ , then there exists a character $\chi$ of $G$ such that $\phi=2\chi$ My Attempt : I know that if $\phi=2\chi$ and $\langle \phi,\phi \rangle=4$ it implies $\langle 2\chi,2\chi \rangle=4$ and $\langle \chi,\chi \rangle=1$ , so we conclude that $\chi$ is an irreducible character. But, here I couldn't find any idea further to proceed, Can someone help me out? Thanks in advance for your time!","['group-theory', 'representation-theory', 'characters']"
3344504,"Solving $ \{ \varnothing, \{ x\} \} = \{ y, \{ \varnothing \} \}$.","The equation is: $$ \{ \varnothing, \{ x\} \} = \{ y, \{ \varnothing \} \}$$ where $ \varnothing $ denotes empty set. I guess I need to break this into cases for each side. Help me get started.",['elementary-set-theory']
3344522,Volume of a solid created by an extended tetrahedron,Every edge of a tetrahedron with length $p$ is extended through the vertices by $p$ . Now all 12 points create a new solid $J$ of which I seek the volume dependent on the volume of the tetrahedron in the centre. With some help the solution becomes clear: The whole Volume of all pyramids is: $$V_P=4\cdot\frac{1}{6}\cdot\left(\frac{a}{\sqrt{2}}\right)^3 +4\cdot\frac{1}{6}\cdot\left(\sqrt{2}a\right)^3 =\frac{3}{\sqrt{2}}a^3 \tag{1}$$ The side of the large cube is $$s=\frac{3}{\sqrt{2}}a\tag{2}$$ and the Volume is respectively $$V_C=\left(\frac{3}{\sqrt{2}}a\right)^3=\frac{27\sqrt{2}}{4}\cdot a^3 \tag{3}$$ The last step is subtracting the Volume of the pyramids. $$V_J=V_C-V_P= \frac{27\sqrt{2}a^3}{4}-\frac{3}{\sqrt{2}}a^3=\frac{21\sqrt{2}a^3}{4} \tag{4}$$ Thx for the help.,"['solid-geometry', 'geometry', 'volume']"
3344530,Integrate $\int_{0}^\infty \frac{\tanh(x)}{x^3}-\frac{\operatorname{sech}(x)}{x^2}dx$,"I would like to integrate: $$
\int_{0}^{\infty}
\left[{\tanh\left(x\right) \over x^{3}}-{\operatorname{sech}\left(x\right) \over x^{2}}\right]
\mathrm{d}x
$$ I'm not sure where I found this integral, but I have a feeling I wrote it down because its solution. I want to say it's related to the Zeta Function, but I'm not sure. I've managed to rewrite it as: $$\small
\sum_{n = 1}^{\infty}\!\!\left(-1\right)^{n + 1}\!\!
\left[\!2\ln\left(\!2n - 1 \over n - 1\!\right)\! +\!
4n\ln\left(\!n - 1 \over 2n - 1\!\right)\! +\!
2n^{2}\ln\left(\!n \over n - 1\!\right)\! +\!
4n\ln\left(2\right)\! -\! 2n\! -\! 2\ln\left(2\right)\! +\! 1\!\right]
$$ Above follows by writing the hyperbolic functions in terms of exponential functions and then using series. Then I used differentiating under the integral. This makes me think otherwise about the Zeta Function/having a closed form for the original integral. I would appreciate any help in solving this.","['integration', 'improper-integrals', 'calculus', 'definite-integrals']"
3344545,Problem on completeness.,"Which of the following is/are true? (0,1) with usual topology admits a metric which is complete. (0,1) with usual topology admits a metric which is not complete. [0,1] with usual topology admits a metric which is not complete. [0,1] with usual topology admits a metric which is complete. Since every subspace of a metric space is complete iff it is closed. 
So R taken as topological space with usual topology and (0,1) &[0,1] as subspace of R .then (0,1) is open and [0,1] is closed. 
So options should be true 2&4.
But options are true 1,2&4.(According to CSIR) Also I'm seeing 1&2 are negation of each other. 
Where is my misunderstanding? Please convince me!! I will appreciate any efforts by you. Thanks in advance. 😊","['general-topology', 'metric-spaces']"
3344552,Resources on function factoring,"From time to time I come across statements like (not verbatim) ""...function $f$ can be decomposed into surjection $g$ followed by injection $h$ ..."" or ""...by canonical decomposition..."" or something to that effect. My question is if there's one (nice) place (books, websites) that has a collection of main elementary theorems and definitions about this topic? My own exposure to set theoretic functions is just the elementary stuff that usually precedes elementary real analysis books.  I am guessing this is a bit more advanced (naive) set theory. And/or category theory. Either way, I only want familiarity with a few theorems related to the topic of decomposing a function into a bunch of injections, surjections and isomorphisms just to get the gist of what it is about. Thanks.","['elementary-set-theory', 'soft-question', 'category-theory']"
3344595,Polynomial with no real roots implies that $\det(P(A))\ge 0$,"Let $P \in \mathbb{R}[X]$ be a polynomial of degree $n$ , $n\in \mathbb{N}$ , which has no real roots. If $A\in \mathcal{M_n(\mathbb{R})}$ , then prove that $\det(P(A))\ge 0$ . I don't know how to approach the general case, but for $n=2$ I was able to prove this by using the canonical form of a quadratic. However, I don't think that this can be generalised to any $n\in \mathbb{N}$ and I don't have any other approaches to this question.","['matrices', 'determinant', 'linear-algebra', 'polynomials']"
3344598,Symmetric linear least squares solution,"Given an overdetermined linear system $AX=Y$ with known $A$ and $Y$ , how would I go about finding the least squares solution $X$ under the constraint that it is symmetric ( $X=X^T$ )?","['matrices', 'pseudoinverse', 'least-squares', 'linear-algebra', 'symmetric-matrices']"
3344615,Expected value of $2$nd highest draw from uniform dist out of n draws,"Jane wants to auction off an item, but does not know where to go to find bidders. David offers to find bidders for her, but will charge her $\$10$ per bidder he gets to show up. Each bidder will uniformly value the item between $[500, 1000)$ . The highest bidder will win the item and pay the second-highest bidder's price (Vickrey auction). How many bidders should Jane pay David to find? I need to maximize the difference between $E[\text{second largest bid out of n bidders}]$ and $10n$ . I'm not sure how to find $E[\text{2nd largest big}]$","['discrete-mathematics', 'auction-theory', 'combinatorics', 'probability']"
3344625,Does existence of a bijection between $2$ different sets implies that they have the same cardinality?,"Let $f$ be our bijection from $A$ to $B$ . $$f: A \to B$$ For it to be a bijection, each element in $A$ must be mapped to a different element in $B$ ; and each element in $B$ must correspond to at least one element in $A$ by the definition. So therefore it must be true that, $$s(A) = s(B).$$ But what if they are of infinite cardinality?","['elementary-set-theory', 'functions']"
3344648,Probability of the outcome of this simple card game,"I have a deck of $N$ cards. $n$ of the cards are red circles and $N-n$ cards are blue circles. I also have an unlimited supply of red square and blue square cards. I play the following game and want to know the probability distribution of the outcome: Repeat the following process until no circle card left: Pick one of the circle cards from the deck at random and replace it with a square card of the same color (let's call this color $c$ ). Then pick another card from the deck (it could be a circle or square card of any color) at random and replace it with another square card of color $c$ . Note that in each repeated step of the above process, the second replaced card could possibly be the same as the first square card of that step. Every time you repeat this process, you replace one or two of the circle cards with square cards. In the end, we will have $N$ square cards. I want to know the probability $P(n'|n)$ of having $n'$ red squares and $N-n'$ blue squares at the end, given $n$ initial red circles. What do I want: Ideally $P(n'|n)$ . If that's not easy, a large $N$ approximation could be equally helpful. Alternatively, finding the mean and the variance of $n'$ would be equally helpful. I'm guessing the mean of $n'$ is $n$ . The mean and variance of $n'$ for large $N$ would also be good enough if nothing else works. Update 1 : Numerically, it looks like $\left\langle n'\right\rangle = n$ , and for large $N$ , $\text{var}(n') \approx\frac{3n(N-n)}{4N}$ . Update 2 : antkam's answer gives a beautiful symmetry proof for $\left\langle n'\right\rangle = n$ . Now, all I need is: Prove $\text{var}(n') \approx\frac{3n(N-n)}{4N}$ for large N. Update 3 : Some more numerical results that may help to find a proof: as in antkam's answer , we can define the variable $X_i\in\{0,1,2\}$ to be the number of square cards resulted from the $i$ 'th circle card. $n'$ can be written as $$n'=\sum_{i=1}^n X_i.$$ We can write the Var( $n'$ ) as $$
\begin{align}
\text{Var}(n') &= \left\langle\left(\sum_{i=1}^n X_i\right)^2\right\rangle - \left\langle\sum_{i=1}^n X_i\right\rangle^2\\
&=n\left(\text{Var}(X_1)+(n-1)\text{Cov}(X_1,X_2)\right)
\end{align}
$$ Numerically, I have found ( Edit : Now both of these partial results are proven in joriki's answer below): $\text{Var}(X_1) = 3/4$ Probabilities are $P(X=0) = P(X=2) = 3/8$ and $P(X=1)=1/4$ . Observations: The equality of $P(X=0) = P(X=2)$ can be justfied through the following observation: For $\sum_{i=1}^N X_i = N$ to be satisfied, the number of $X_i=0$ should be exactly the same as the number of $X_j=2$ . For $\text{Var}(n')$ to be $\frac{3n(N-n)}{4N}$ , the value of $\text{Cov}(X_1,X_2)$ should be $-\frac{3}{4N}$ to first order in $1/N$ .","['probability-distributions', 'combinatorics', 'card-games', 'probability']"
3344671,Why is this proof invalid?,"I don't understand why this theorem is false. Suppose that $A \subseteq C$ , $B \subseteq C$ , and $x \in A$ . Then $x \in B$ . Invalid Proof: Suppose that $x \notin B$ . Since $x \in A$ and $A \subseteq C$ , $x \in C$ . Since $x \notin B$ and $B \subset C$ , $x \notin C$ . But now we have proven both $x \in C$ and $x \notin C$ , so we have reached a contradiction. Therefore $x \in B$ . I'm thinking that $$\forall x(x \in B \implies x \in C) = \forall x(x \notin B \vee x \in C)$$ It's true that $x \notin B$ , so this statement is true, and can't be used to prove through contradiction that $x \in B$ . But I'm not completely sure, so any clarification would help here. Thanks.","['proof-verification', 'discrete-mathematics']"
3344706,What is the meaning of a space-time white,"For reference this is from page 27 here Consider the stochastic heat equation $$ \begin{cases}
\dfrac{\partial u}{\partial t}(x,t)=\dfrac{\partial ^2 u}{\partial x^2}(x,t) +f(u(x,t))\dot{W}(x,t) & t >0, x\in[0,L]
\\ \dfrac{\partial u}{\partial x}(0,t)=\dfrac{\partial u}{\partial x}(L,t)=0 &t>0
\\ u(x,0)=u_0(x) &x \in[0,L]
\end{cases} $$ $\dot{W}(x,s$ ) is refered to as the space-time white noise. But this doesn't make sense to the defintion of white noise given in the same text. $\textbf{White Noise}$ here is defined as follows: The gaussian process $\{\dot{W}(A)\}_{A \in \mathscr B(\mathbb R^n)}$ with $E(\dot{W}(A))=0$ and $E(\dot{W}(A)\dot{W}(B))=\lambda^n(A\cap B)$ where $\lambda ^n$ is the n-dimensianal Lesbegue measure is called White Noise. It then goes on to say that we can consider for $A \in \mathscr B(\mathbb R^n)$ that $\dot{W}(A) = \int 1_A dW$ and for $h\in L^2(\mathbb R^n)$ we define $\dot{W}(h) = \int h(t)dW(t)$ which is the standard Wiener Integral. This is also the same definition given in the Walsh notes So my question is, what is $\dot{W}(x,t)$ ? Could it be $\dot{W}(0\times t) \times (0,x])$ ? Also how does this definition relate to the definitions given in this question ? In particular to notion that White noise, $\dot{W}$ , is the weak derivitive of Brownian motion. Ie: If $W_t$ is a standard Brownian motion then $\dot{W}$ is a distribution on the set of test functions such that $$ -\int W_t\dfrac{\partial \phi}{\partial t}(t)dt=\int\dot{W}_t\phi(t)dt $$","['stochastic-processes', 'brownian-motion', 'probability-theory', 'probability']"
3344719,"Define $ \mu_1 = \int_a^b xdx,$ and inductively: $\mu_k = \int_a^b x d \mu_{k-1}$. What will be $\mu_k?$","Define the following sequence of measures given by $\mu_0 = dx$ (Lebesgue measure), $\mu_1([a,b]) = \int_a^b x \;dx, \mu_k([a,b]) = \int_a^b x\; d\mu_{k-1}, [a,b] \subset [0,1].$ What will be $\mu_{k}?$ This problem was posted by our professor as a challenge, and at the moment we don't have Radon Nikodym theorem at disposition. Well, what I tried was to define a sequence of functions $\varphi_n$ which I know how to calcule the integral with respect to $\mu_1$ for each term and which converges monotically to $f = x$ . So by the monotone convergence theorem, it would follow that: $$\int_a^b x d\mu_1 = \lim_n \int_a^b \varphi_n d\mu_1$$ The sequence which I tried is given by: $$ \varphi_n = \sum_{j=0}^{2^n-1}(a+j\cdot \frac{b-a}{2^n})\chi_{[a+j\cdot \frac{b-a}{2^n},\, a+(j+1)\cdot \frac{b-a}{2^n}]}, $$ which basically is a step function defined on and constant at each $2^n$ intervals by the infimum of the function there. The problem, as you may notice, is to calculate this limit: $\lim_n \sum_{j=0}^{2^n-1} (a+j\cdot\frac{b-a}{2^n}) \mu_1\bigg ( \bigg [a+j\cdot \frac{b-a}{2^n}, a+(j+1)\cdot \frac{b-a}{2^n} \bigg ] \bigg).$ How to proceed with this? Any good suggestions? Edit Solution to the hint given in the answer: Let $f,g = x$ . Then exists an increasing sequence $(\varphi_n)$ of simple functions such that $\lim \varphi_n = g, x \in [a,b] =  A.$ Write for each $ \varphi_n = \sum_k a_{k,n}\chi_{E_{k,n}}$ for each $n$ . Since $(\varphi_n)$ is an increasing function, by the monotone convergence theorem we have that $$ \int_A g d\nu = \lim_n \int_A \varphi_n d\nu = \lim_n \sum_k  a_{k,n}\nu(E_{k,n}) = \lim_n\sum_k a_{k,n} \int_{E_{k,n}}f d\mu = $$ $$\lim_n \int_A \sum_k a_{k,n} f \cdot \chi_{E_{k,n}} d\mu = \lim_n \int_A \varphi_nf d\mu. $$ Now we note that $(\varphi_n f)$ is also an increasing sequence $(f$ is also positive) whose terms are also measurable and positive and such that $\lim_n \varphi_n f = gf $ (as $f$ is bounded on $A$ ). Hence, once more by the monotone convergence theorem we have $$ \int_A g d\nu = \lim_n \int_A  \varphi_n f d\mu = \int_A \lim_n \varphi_n f d\mu = \int_A gf d\mu.$$",['measure-theory']
3344720,Hard Inverse Matrix calculation,I tried so hard but I am unable to solve this problem. Find the inverse of the matrix $I+ab^T$ . Hint : Try the form $cI+dab^T$ and find $c$ and $d$ .   What happens if $a^T b = −1$ ? This is an exercise from A Primer  on  Linear models by Monahan ( Appendix A.69),"['matrices', 'self-learning', 'inverse', 'matrix-decomposition']"
3344759,Finding classes of non-piecewise functions which have graphs that resemble sine curves but contain periodic hole discontinuities,"Discussing continuity in my Calc class today got me wondering: Can we define a non-piecewise sine curve with periodic ""hole"" discontinuities? In this case, when I say sine curve, I am referring to functions of the traditional $f(x)=a\sin{x}$ shape. So I did a little bit of digging. $f(x)=\frac{\sin{x}}{x}$ did not work. I plotted it on Desmos and the resulting curve was sinusoidal but wonky; the function approached an absolute maximum in the neighborhood of $x=0$ . Next, I tried $f(x)=\frac{\sin{2x}}{\sin{x}}$ . This actually worked; the function resembled a ""normal"" sine curve, the only difference being its discontinuities. I added a photo of it here. Next, I tried $f(x)=\frac{\sin{3x}}{\sin{x}}$ , which worked. $f(x)=\frac{\sin{3x}}{\sin{2x}}$ , did not, with the resulting graph resembling a secant function. I didn't stop there. I found that the following functions also worked. $f(x)=\frac{\sin{4x}}{\sin{2x}}$ . $f(x)=\frac{\sin{6x}}{\sin{3x}}$ , $f(x)=\frac{\sin{8x}}{\sin{4x}}$ . Each of these functions produced a curve of the same shape as the previous. My question then is, is there a class of functions of a certain form that fit this criteria, namely, graphing as a sine curve with periodic ""hole"" discontinuities? My investigation would have me think that functions of the form $f(x)=\frac{\sin{mx}}{\sin{nx}}$ where $\frac{m}{n}=2$ satisfy the criteria, but I am not sure if 1 , this is always true, or 2 , there other classes of functions that also satisfy the criteria. My testing showed that when $\frac{m}{n}\neq2$ , the function did not meet the criteria. Could anyone provide proof or heuristics regarding the existence of this, or another class of functions that satisfies this criteria? Are there infinitely many classes of functions that work? A little bit of context. Our teacher had us draw an arbitrary function with 4 discontinuities. We had to then list the left and right hand limits at each discontinuity, and whether or not the limit existed. This got me thinking about drawing a sine curve. Thank you for reading.","['trigonometry', 'functions', 'real-analysis']"
3344774,Intuitive understanding behind exterior algebra construction,"I'm trying to get deeper intuition into the exterior algebra construction on a finite dimensional $\mathbb{R}$ -vector space. Our accustomed notion of volume given by measure is neither multi-linear nor anti-symmetric, so I don't buy construction of a 'volume function' as an a priori motivation for an exterior algebra. It's great that $v_1 \wedge \cdots \wedge v_n = \alpha \ e_1 \wedge \cdots \wedge e_n$ computes the (signed) volume $\alpha$ of the parallelotope spanned by these vectors. But this fact seems rather arbitrary and a priori unexpected. It would be nice to have a narrative as to why constructing an exterior algebra on a vector space is just the natural thing to do. For instance, generalizing from metric spaces to topological spaces is very natural once we realize that metrics just generate open sets, and that continuity of functions can be characterized by their behavior on open sets alone. Is there any reason why one would intuitively anticipate beforehand that constructing an alternating algebra on a vector space would give a device to compute volumes, detect linear dependence etc.? Or should the recognition of these facts just be considered a random encounter in the process of experimentation with mathematical constructs?","['vector-spaces', 'abstract-algebra', 'linear-algebra', 'multilinear-algebra', 'soft-question']"
3344787,Why are Hermitian matrices called a generalization of real symmetric matrices?,"I frequently see people explaining Hermitian matrices as a generalization of real symmetric matrices e.g. Wikipedia , Math StackExchange . I understand that all real symmetric matrices are Hermitian matrices, but it seems like there's really two changes between real symmetric matrices and Hermitian matrices: (1) permit complex numbers, and (2) the transpose must equal the element-wise complex conjugate. Why was this second step included in the definition of Hermitian matrices? My guess would be that it has something to do with physicists wanting to ensure particular sequences of linear transformations produce real-valued outputs; is this correct?","['linear-algebra', 'complex-numbers', 'symmetric-matrices']"
3344838,Prove $S^2(x) + C^2(x) = 1$,"Suppose $S, C : \Bbb R \to \Bbb R$ are differentiable and that (1) $S'(x) = C(x)$ and $C'(x) = −S(x)$ for all $x \in \Bbb R$ , and (2) $S(0) = 0$ and $C(0) = 1$ . Prove that $S^2(x) + C^2(x) = 1$ for all $x \in \Bbb R$ . I tried using the limit definition of differentiable in setting the limit as $x$ approaches $a$ of $((S(X)-S(a))/x-1)=C(x)$ and setting the limit as $x$ approaches $a$ of $((C(X)-C(a))/x-1)=-S(x)$ but I don't know if that gets me anywhere. Hints or anything would be greatly appreciated!","['derivatives', 'real-analysis']"
3344850,Explanation for Eigenvalues or Characteristic values of Projection Operator,Question: I need to give what are possible eigenvalues/characteristic value of projection operator with an explanation. My Attempt: Let E be any projection on vector space V . Assume R be the range of E and N be null space of E My Doubt: I have got c=1 and c=0; there is and in between by the condition of independence so how does this imply c is either 1 or 0 Please help me in understanding how the above equation gives that c has possible eigenvalue either 0 or 1 .,"['independence', 'linear-algebra', 'projection-matrices', 'eigenvalues-eigenvectors']"
3344851,Birational smooth curves,"Let $X$ and $Y$ be connected schemes that are smooth and proper of relative dimension 1 over $\mathbb{Z}[1/n]$ for some positive integer $n$ . If the function fields of $X$ and $Y$ are isomorphic, are $X$ and $Y$ isomorphic themselves?",['algebraic-geometry']
3344853,"""Elegant"" way to assign 4 distinct objects into 4 bins","Suppose you have four objects to distribute among four people. Suppose people can carry any number of objects (none, one, two, three, or all four objects) at once. In how many ways can the four objects be distributed? My solution Let the four people be named A,B,C,D. Distribution type 1 If each person gets exactly one object, the distribution looks like A B C D
1 1 1 1 of which there are $4!=4\cdot 3 \cdot 2 \cdot 1 = 24$ distinct ways (since the objects are distinct). Distribution type 2 If one person gets 2 objects and two others get 1 object, the possible distributions look like A B C D
2 1 1 0
2 1 0 1
2 0 1 1
1 2 1 0
1 2 0 1
0 2 1 1
1 1 2 0
1 0 2 1
0 1 2 1
1 1 0 2
1 0 1 2
0 1 1 2 and for each of the above distributions, there are $12$ distinct ways to distribute the distinct objects. Distribution type 3 If two people get 2 objects, the possible distributions look like A B C D
2 2 0 0
2 0 2 0
2 0 0 2
0 2 2 0
0 2 0 2
0 0 2 2 and for each of the above distributions, there are $6$ distinct ways to distribute the distinct objects. Distribution type 4 If one person gets 3 objects and another person gets 1 object, the possible distributions look like A B C D
3 1 0 0
3 0 1 0
3 0 0 1
1 3 0 0
0 3 1 0
0 3 0 1
1 0 3 0
0 1 3 0
0 0 3 1
1 0 0 3
0 1 0 3
0 0 1 3 and for each of the above distributions, there are $4$ distinct ways to distribute the distinct objects. Distribution type 5 If one person gets all 4 objects, the possible distributions look like A B C D
4 0 0 0
0 4 0 0
0 0 4 0
0 0 0 4 for each of the above distributions, there is only $1$ distinct way to distribute the distinct objects. Totaling the ways The total number of ways is then \begin{align}
&\textrm{ type 1 + type 2 + type 3 + type 4 + type 5 }\\
=& 1(24) + 12(12) + 6(6) + 12(4) + 4(1) \\
=& 24 + 144 + 36 + 48 + 4 \\
=& 256\textrm{ ways }
\end{align} My questions I have 3 questions: Is there a more elegant way (using $_n P_k$ or $_n C_k$ notation) of counting the amount of each distribution type (the numbers 1, 12, 6, 12, 4) that appear in the final calculation? Is there a more elegant way (using $_n P_k$ or $_n C_k$ notation) of counting the number of ways for each distribution type (the numbers 24, 12, 6, 4, 1) that appear in the final calculation in parentheses? (Clearly the 24 is just $_4 P_4$ , but what about the others?) Why is all of this just equal to $4^4$ ? This isn't immediately obvious to me.","['permutations', 'combinations', 'combinatorics']"
3344877,"Find and classify the spectrum of an integral operator $K: L^2 (0,1) \rightarrow L^2 (0,1)$","Define the bounded linear operator $K: L^2(0,1) \rightarrow L^2(0,1)$ by $$(Kf)(x) = \int_0^1 xy(1-xy)f(y) dy.$$ Find the spectrum of $K$ and classify it. My attempt: Since the kernel of $K$ is $k(x,y) = xy(1-xy)$ , whicch is a real-valued function, $K$ must be self adjoint. Thus $\sigma_r(K) = \emptyset$ . Then, since the norm $\|k(x,y)\|_{L^2}$ is finite, $K$ is a Hilbert-Schmidt operator and thus is compact. Then, $0 \in \sigma_{pt} (K)$ and the spectrum of $K$ only contains eigenvalues. At this point, I'm not sure how to proceed. Clearly, if $\lambda \in \sigma_{pt}(K)$ , then for some $f \in L^2 (0,1)$ , $$Kf = \int_0^1 xy(1-xy)f(y) dy = \lambda f(x),$$ but I'm not sure how to proceed with this calculation.","['hilbert-spaces', 'spectral-theory', 'compact-operators', 'functional-analysis']"
3344882,Show that a solution of the IVP is bounded,"in my way to understand ODE's I've found some problems that I have no idea how to tackle and how to relate to what I've learn so far. For example, this one: Let $x(t)\in C^{1}([0,T])$ be a solution of the IVP $\dot x = A(t)x$ , $x(0)=x_{0}$ with $(t,x) \in [0,T]\times \mathbb{R}^{n}$ and $x_{0} \in \mathbb{R}^{n}$ . Suppose $A(t)v \cdot v \leq M|v|^{2}$ for all $v \in \mathbb{R}^{n}$ and $M>0$ some constant. Show that $|x(t)|\leq |x_{0}|e^{Mt}$ . Any help would be really appreciated. Thanks so much for all your help. :)","['calculus', 'ordinary-differential-equations', 'real-analysis']"
3344913,Visualizing Lagrange multipliers,"Sorry if this seems like a very basic question but I am having trouble visualizing Lagrange multipliers. Particularly the equation: $ \nabla f = \lambda * \nabla g $ f = function to maximise. g = constraint. I don't understand why equating the gradients in such a way produces the extremum. I watched a Khan Academy video and the explanation was as follows: Plotting Contours of f and g My question is:
Why does the extremum occur only where the contours of f touch the constraint at one point? Why can they not occur where there are multiple points? For example: Ex: Contours of f meeting g at two points Also, why is it that equating the gradients in such a way produces the point where they touch at only one point? My understanding is $ \nabla $ f is the gradient vector of f and $ \nabla $ g is the gradient vector for g. It seems to be there may be infinitely many points which may satisfy the equation but are not necessarily the extremum. Kindly help me visualise what is going on here. Thanks in advance. EDIT: My understanding of gradients","['multivariable-calculus', 'lagrange-multiplier']"
