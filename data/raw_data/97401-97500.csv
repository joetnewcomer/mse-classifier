question_id,title,body,tags
1343878,second fundamental form and connection forms,"I am reading this paper that has the following: Suppose $M$ is an (n-1) dimensional closed hyper surface immersed in $\mathbb{R}^{n}$. Let $e_1, \cdots, e_n$ be orthonormal frame in $\mathbb{R}^n$ such that $e_1,\cdots, e_{n-1}$ are tangent to $M$ and $e_n$ is the outer normal. Let $\omega_i$ be the corresponding coframes and $\omega_{i,j}$ be the connection forms. And use the same notation for the pull back of the forms through immersion. Then the second fundamental form is defined by the symmetric matrix $\{h_{ij}\}$ with $$\omega_{i,n+1}=h_{ij}\omega_j.$$ I use Boothby's An introduction to differentiable manifolds and Riemannian geometry for reference on differential geometry. In this book, the notations are like this: $e_1,\cdots,e_n$ are the orthonormal frames. $\omega^i$ are the coframes. (so I figured this is equal to $\omega_i$ in the paper.) $\omega_{j}^{k}$ are defined so that $\nabla_{X} e_j = \Sigma_k \omega_{j}^{k}(X)e_k$, where $X$ is a vector field. $\omega_{i,j}=\Sigma_k \omega_{i}^kg_{kj}$. In this case, since this is an orthonormal frame, I guess $\omega_{i,j}=\omega_i^j$. I assume the symmetric matrix is defined by $h_{ij}=\langle e_n,\nabla_{e_i}e_j\rangle$. (Correct me if I am wrong.) Using 3 and 4, I get $h_{ij}=\omega_{j,n+1}(e_i)$. To arrive at the equation in the paper, I will have to justify (note that $\omega_j=\omega^j$) $$\Sigma_j \omega_{j,n+1}(e_i)\omega_j = \omega_{i,n+1}.$$ I am stuck at this step. Can anyone help me?","['differential-geometry', 'riemannian-geometry']"
1343904,Are polynomials infinitely many times differentiable?,"Are polynomials infinitely many times differentiable? If so, does it only mean that at some point we reach 0 and then we keep on getting 0? Thank you!","['polynomials', 'derivatives']"
1343915,Joint Distribution Implies Independence...?,"Consider the measurable space $(\mathbb{R}, \mathcal{B})$ and a probability space $(\Omega, \mathcal{F}, P)$.  Define a finite sequence of random variables $X_1,\ldots,X_n: \Omega \to \mathbb{R}$.  Each $X_i$ induces a probability distribution measure on $\mathcal{B}$ given by $\mu_i(B_i) = P(X_i^{-1}(B_i))$ for $B_i \in \mathcal{B}$.  This part is clear to me. Now place these random variables into a vector, $X = (X_1,\ldots,X_n)$ and consider the target space $(\mathbb{R}^n, \mathcal{B} \otimes \cdots \otimes \mathcal{B})$. Here's one part I'm not sure about.  We now have $X: \Omega \to \mathbb{R}^n$, and I guess since each $X_i$ is $\mathcal{F}$-measurable we get that $X$ is somehow $\mathcal{F}$-measurable and so we may define a ""joint"" probability distribution measure on $\mathcal{B} \otimes \cdots \otimes \mathcal{B}$ given by $\mu(B) = P(X^{-1}(B))$ for $B = B_1 \times \ldots \times B_n \in \mathcal{B} \otimes \cdots \otimes \mathcal{B}$. However, as I understand, a measure on a product space is called a product measure and is defined such that $\mu(B) = \mu_1(B_1)\cdots \mu_n(B_n)$.  But then $P(X^{-1}(B)) = P(X_1^{-1}(B_1))\cdots P(X_n^{-1}(B_n))$ and so the random variables are independent automatically. I've clearly misunderstood and/or overlooked something, so I would appreciate my errors being pointed out!","['probability-theory', 'measure-theory']"
1343950,A few questions on the later chapters in Principles of Mathematical Analysis by Walter Rudin (3rd Edition),"I am currently reading Principles of Mathematical Analysis by Walter Rudin (3rd Edition). I am enjoying the book and it's terseness, which isn't an issue for me. What I do have a problem with is that I hear the later chapters (chapters 9-11 specifically) aren't very good. I have a couple of questions. 1)What precisely makes these chapters subpar? Is it still worth reading, but adding in some supplements? 2)I plan on reading Real and Complex Analysis by Walter Rudin after this book, does it fill in the supposed missing quality of the last few chapters? Like, I know Lebesgue Theory and the Lebesgue Integral are important and that apparently isn't treated nicely in Principles of Mathematical Analysis (it would be nice if you could tell me exactly why this is so) either, but is it developed better in Real and Complex Analysis ? Thanks in advance for any response.","['analysis', 'real-analysis']"
1343983,Prove that $Df(p)=f(p)T$ where $T(q)=\int_{0}^1q$,"Let $E=\mathcal{C}[0,1]$ provide with $\|\cdot\|_\infty$ norm. Let $f:E\to \mathbb{R}$, given by $f(p)=e^{\int_0^1 p}$.  I need to prove that $f$ is differentiable. My approach: Let $p,q\in\mathcal{C}[0,1]$ then,
$$f(p+tq)-f(p)=e^{\int_0^1 p+tq}-e^{\int_0^1 p}=e^{\int_0^1 p}\left( e^{t\int_{0}^1 q}-1\right)=f(p)\left(1+t\int_{0}^1q+t\ o(1)-1 \right)$$
The last equality is true, just applying Taylor's Formula. Then we have $$\lim_{t\to 0}\frac{f(p+tq)-f(p)}{t}= f'_{q}(p)=f(p)\int_{0}^1 q$$
So I deduce that if $f$ is differentiable, then $Df(p)=f(p)T$, where $T(q)=\int_{0}^1q$. The operator $f(p)T$ is linear because $T$ is linear, and is continuous because: $\left|f(p)\int_{0}^1 q \right|\leq f(p)\|q\|_{\infty}$, from this I know that $\left(\int_{0}^1q\right)^2\leq \|q\|_{\infty}^2$. Maybe my question is silly, but how can I prove that:
$$f(p+q)-f(p)=f(p)T(q)+\|q\|_{\infty}\ o(1)$$ I tried for longer but finally I'm stuck! Thanks in advance.",['analysis']
1343988,"Using the complex logarithm as a conformal mapping,","I want to map the upper half plane, y>0, conformally onto the semi-infinite strip u>0, $-\pi < v < \pi$ in the w-plane. I then studied the complex logarithm, and noticed that the principal branch, Log(z), maps every point z in $C - R^- \bigcup {0}$ to w = ln|z| + iArg(z), where Arg(z) ranges from $-\pi$ to $\pi$. So, the images of the whole plane, minus the negative real axis (and 0), have positive real part and imaginary part between $-\pi$ to $\pi$. Is my work done?  Can I conclude that the mapping from the UHP to the semi-infinite strip is just $$w = Log(z)?$$ Something seems a little off, since all of C (minus the negative real axis) maps to the horizontal strip. Thanks,","['mobius-transformation', 'complex-analysis', 'conformal-geometry', 'logarithms']"
1344000,Value of $\sum 1/p^p$,"A very simple question, but I can't seem to find anything relating to it : Is there any research, are there any results that have focused on or given insight on $\sum 1/p^p$, ${p \in \mathbb P}$ ? A very basic series, converges extremely fast, its value is around .29. What more can there be said about it ? From what little I know about more advanced number theory, similar sequences (I can think of a few similar ones that I can't find any relevant research or results about) can be very non-trivial to compute or to analyse.","['prime-numbers', 'sequences-and-series']"
1344027,Is simply connectedness preserved after deleting a high codimension set,"Suppose $X$ is a complex manifold of complex dimension $n$, $Z$ is a subvariety of complex codimension at least $2$. Suppose $\pi_1(X)=0$, do we have $\pi_1(X-Z)=0$? Do we have $\pi_1(X-Z)=\pi_1(X)$ in general?","['algebraic-geometry', 'fundamental-groups', 'algebraic-topology']"
1344036,Open sets in the product topology,"Let $\{X_{\alpha}\}_{\alpha\in A}$ be a family of topological spaces. The product topology on $X=\prod_{\alpha\in A}X_{\alpha}$ is the weak topology generated by the coordinate maps $\pi^{}_{\alpha}:X\to X_\alpha$. The following is an exercise about open sets in $X$ endowed with the product topologyï¼š If $A$ is infinite, a product of nonempty open sets $\prod_{\alpha\in A}U_{\alpha}$ (where $U_\alpha$ is open in $X_\alpha$) is open in $X$ iff $U_\alpha=X_\alpha$ for all but finitely many $\alpha$. Observing that the sets of the form $\bigcap_1^n \pi^{-1}_{\alpha_j}(U_{\alpha_j})$ form a base for the product topology, I can show the following direction: If the open sets $U_\alpha=X_\alpha$ for all but finitely many $\alpha$, then 
  the product of nonempty open sets $\prod_{\alpha\in A}U_{\alpha}$is open in $X$. Could anyone suggest an idea for the other direction?",['general-topology']
1344047,Prove that $\prod_1^{\infty}(1-a_i) > 0$ iff $\sum_1^{\infty}{a_i} < \infty$,"Suppose $\{a_i\}_1^{\infty} \subset (0,1)$ a) $\prod_1^{\infty}(1-a_i) > 0$ iff $\sum_1^{\infty}{a_i} < \infty$ b) Given $\beta \in (0,1)$, exhibit a sequence $\{a_i\}$ such that $\prod_1^{\infty}(1-a_i) = \beta$ This is not my homework, but I'm learning measure theory from Real Analysis of Folland, and I get stuck on this problem. My idea is to prove that $\sum_1^{\infty}{\ln(1-a_i)} > -\infty$ (for sure this sum is smaller than 0). At the first glance, I try to prove that $\ln(1-x) + x > 0$, but finally, the inequality should be reversed. Using maclaurine expansion, I can expand:
$$\ln(1-x) = -(x + x^2/2 + x^3/3 +...)$$ So seem like I can't find a function $f(x)$ such that $\ln(1-x) +f(x) > 0$. Can anyone give me some hint to solve this? For the second problem, I got no idea. Thanks so much. I really appreciate!","['sequences-and-series', 'convergence-divergence', 'real-analysis', 'measure-theory']"
1344050,"How to find $I=\int_{-4}^4\int_{-3}^3 \int_{-2}^2 \int_{-1}^1 \frac{x_1-x_2+x_3{-}x_4}{x_1+x_2+x_3+x_4} \, dx_1 \, dx_2 \, dx_3 \, dx_4$","How can I find this integral $$I=\int_{-4}^4\int_{-3}^3 \int_{-2}^2 \int_{-1}^1 \frac{x_1-x_2+x_3{-}x_4}{x_1+x_2+x_3+x_4} \, dx_1 \, dx_2 \, dx_3 \, dx_4$$","['definite-integrals', 'integration']"
1344069,Counting points on the Klein quartic,"In Moreno's book ""Algebraic Curves over Finite Fields"", he mentions the following in passing with no further comments ($K$ denotes the Klein quartic defined by $X^3 Y + Y^3 Z + Z^3 X = 0$): The Jacobian of $K$ is a product of three elliptic curves all isogenous to the elliptic curve with complex multiplication over the field $Q(\sqrt{-7})$. This last fact implies the existence of a formula for counting the number of rational points on $K$ over the field $\mathbb{F}_p$ which depends on how the prime $p$ splits in the ring $\mathbb{Z}[\sqrt{-7}]$. Does anyone know what he is referring to? The Klein quartic is the same as the modular curve $X(7)$ which has genus 3, so I'd be very interested in such a formula! EDIT: After some computation, it appears that the number of points on $X(7)$ over $\mathbf{F}_q$ is precisely $q+1$ as long as $q \not\equiv 1 \bmod 7$ (*). Otherwise, the behaviour of the error term $a_q = q+1-\#X(7)(\mathbf{F}_q)$ is kind of complicated, but it appears to be constant if we restrict attention to primes $q$ lying in certain quadratic progressions, for example when $q$ is of the form $28n^2 - 28n + 43$ my data suggests that we always have $a_q = -12$. Does anyone have any idea what's going on here? Note that when $q \equiv 1 \bmod 7$ then $a_q/3 = b_q$ where $b_n$ are the Fourier coefficients of the unique cusp form of weight 2 for the congruence subgroup $\Gamma_0(49)$. Furthermore, what would the moduli interpretation be of statement (*) above? We know $X(7)$ has 24 cusps, but the only time there are elliptic curves defined over $\mathbf{F}_q$ with complete rational 7-torsion is when $q \equiv 1 \bmod 7$ and the trace of Frobenius is 2 mod 7... so why should there be precisely $q-23$ noncuspidal points on $X(7)$ when $q \not\equiv 1 \bmod 7$?","['modular-forms', 'moduli-space', 'algebraic-geometry', 'quartics', 'finite-fields']"
1344074,Proving a trigonometric identity with tangents [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Prove that: $$\tan^227^\circ +2 \tan27^\circ \tan36^\circ=1$$ any help, I appreciate it.","['proof-verification', 'trigonometry']"
1344097,Uniform Sampling on Intersection of Simplices,"I'm trying to sample uniformly on the intersections of faces of several simplicies, with all coordinates being non-negative. That is, given constraints
$$A\vec{w}=\vec{b} \ \ and \ \ \vec{w} \geq \vec{0} \ \ and \ \ \sum w_i = 1,$$
I want to sample $\vec{w}$ uniformly. $A$'s dimension is about $100 \times 10000$. A concrete example will be: 
$$A = \begin{bmatrix} 
    1 & 1 & 1 \\
    0 & 1 & 2
\end{bmatrix}, \ 
b=\begin{bmatrix} 
    1  \\
    0.7
\end{bmatrix}$$,
sample $\vec{w}$ uniformly from $Aw=b$ subject to $\vec{w} \geq \vec{0}$ and $\sum w_i = 1$ (This makes the sampling space bounded). Below is a graphical representation of the problem -- to sample uniformly from the red intersection line. I am well aware that rejection-sampling and MCMC sampling can theoretically solve this problem. However, I have already implemented both approaches in programming, and neither of these two methods performs well enough. This is because the dimension of my sampling space usually goes up to 10000, and rejection sampling simply throws away too many points and MCMC is taking forever to converge. Therefore, I'm desperate to try new methods. Many thanks in advance!! (please do not provide answers using rejection sampling; methods that already have open-source programming implementations are favored)","['geometry', 'statistics', 'uniform-distribution', 'convex-analysis', 'linear-algebra']"
1344105,Simulation of interacting Ornstein-Uhlenbeck processes,"I would like to simulate the following system of interacting OU processes on $[0,T]$: $$dX_t^1=(X_t^2-X_t^1)\,dt+\sigma_1 \,dW_t^1,\quad X_0^1=x_1$$ $$dX_t^2=(X_t^1-X_t^2)\,dt+\sigma_2 \,dW_t^2,\quad X_0^2=x_2$$ where $W^1$ and $W^2$ are two independent Wiener processes. I am aware of the fact there is a closed-form formula for the classical one-dimensional OU process, but in the case of two interacting processes as above I don't believe this is possible. As a result, my first idea was to naively apply the Euler-Maruyama scheme, as follows: $$X_{t_{k+1}}^1=X_{t_k}^1+(X_{t_k}^2-X_{t_k}^1)h+\sigma_1(W_{t_{k+1}}^1-W_{t_k}^1)$$ $$X_{t_{k+1}}^2=X_{t_k}^2+(X_{t_k}^1-X_{t_k}^2)h+\sigma_2(W_{t_{k+1}}^2-W_{t_k}^2)$$ with $X_{t_0}^1=x_1$, $X_{t_0}^2=x_2$, $t_k=\frac{kT}{N}$, N being the number of subdivisions, and $h=\frac{T}{N}$. However, I am not sure whether the Euler-Maruyama scheme can be applied to this interacting case, and whether or not the scheme would effectively converge in this specific context. Any ideas or references to literature would be greatly appreciated, thanks.","['probability-theory', 'monte-carlo', 'stochastic-calculus', 'stochastic-processes', 'simulation']"
1344117,Lines in the plane from Concrete Mathematics. How many bounded regions are there?,"I'm studying Concrete Mathematics by Donald Knuth. While doing the warmup questions, from the recurrence chapter, I stumbled upon an interesting problem. I have an intuition about the solution but I don't know how to express it. If you can give me any pointers I would greatly appreciate it. The problem that I'm interested in is based on this original problem: What is the maximum number $L(n)$ of regions defined by $n$ lines in the plane. The book goes to explain the recurrence $L(n) = L(n-1) + n$. We identify this pattern from generating solutions for the first few smaller scenarios $L(0) = 1$ $L(1) = 2$ $L(2) = 4$ $L(3) = 7$ and so on... The book then identifies the ""closed form"" $L(n) = n(n + 1)/2 + 1$ And now the problem I'm trying to solve: Some of the regions defined by $n$ lines in the plane are infinite, while others are bounded. What's the maximum possible number of bounded regions? Knuth stresses the importance of looking at smaller scenarios when we try to first understand a problem. In doing so I realized that when $n$ is $0, 1$ or $2$` we don't have any bounded areas. Once we get to $n = 3$` we get one bounded area. This would be our base case. If we go further we notice that the maximum bounded areas for $n = 4$ are $2$, $n = 3$ are $4$, $n = 5$ are $7$. It seems like the initial recurrence is happening again but for bounded areas it starts with $n = 3$ instead of $n = 0$. So the new recurrence would look like this for bounded areas: $L(n) = L(n - 3) + n - 3$. Am I reasoning correctly about this problem and is there a better way to look at it? Can anybody offer suggestions on how to express this rational better if it is correct or if it's not correct why that's the case?","['recurrence-relations', 'induction', 'discrete-mathematics']"
1344132,Constructing Polynomial Function from Set of Points and Slopes,"I only have a basic knowledge of calculus but I would like to know if it's possible to, given a set of points each with their own slopes, construct the simplest (or any) polynomial function that perfectly fits the given information. In other words, a polynomial $P(x)$ would need to take on the value of each given ordinate at each given abscissa, and it's derivative, $P'(x)$ would need to take on the value of each given slope and each given abscissa. I'm thinking that it might not be possible because if there's a series of points  that lie on a straight line among many other, randomly distributed ones, the derivative $P'(x)$ would have a segment of constant value in the middle of the chaotic curvature surrounding it. I don't think that polynomial functions can have this kind of behavior, can they? If it's indeed impossible to do this, is there any other way to construct a curve that fits the given data?","['taylor-expansion', 'calculus', 'interpolation', 'polynomials', 'derivatives']"
1344136,"Students in a class, girls sitting with boys and boys sitting with girls","This is a very interesting word problem that I came across in an old textbook of mine. So I mused over this problem for a while and tried to look at the different ways to approach it but unfortunately I was confused by the problem and I don't really understand it either, hence I am unable to show my own working or opinion. The textbook gave no hints really and I'm really not sure about how to approach it. Any guidance hints or help would be truly greatly appreciated. Thanks in advance :) So anyway, here the problem goes: There are $30$ students in a class. They sit at $15$ double desks; each desk seats two students. Half of the girls sit with the boys. Is it possible to make a rearrangement so that half of the boys sit with the girls?","['problem-solving', 'combinations', 'elementary-number-theory', 'word-problem', 'combinatorics']"
1344139,Choosing the right sign for inverse functions?,"If I have to find an inverse function and through the algebra I get a $\pm$ sign how do I know which one to choose from if its in a given interval? For example a question asks: The function $\left(\frac1{x^2}\right)$ is a one to one function on the interval $(0,\infty$) Find a formula for the inverse function on that domain. Sketch the graph of both functions from $0 < x < 4$ So I found the inverse function by doing this... $$y = \left(\frac1{x^2}\right)$$
$$ x^2 = \left(\frac1y\right)$$
$$ x = \pm\left(\frac1{\sqrt{y}}\right)$$
$$ y = \pm\left(\frac1{\sqrt{x}}\right)$$ So now I have two inverse equations? How do I know which one to use?","['inverse', 'functions']"
1344161,How to show this fraction is not an integer,Suppose $k\geq 2$ is an integer. I want to show $$\frac{1+k+k(k-2)}{1+\frac{k-1}{k}+\frac{(-1-\sqrt{k-1} )^2}{k(k-2)}}$$ is not an integer. It is equal to $$\frac{(k-2) k (k^2-k+1)}{2 (k^2-2 k+\sqrt{k-1}+1)}.$$ If I can show this then I will be able to finish my proof of the Friendship Theorem . We may assume $k$ is even if that helps any.,"['arithmetic', 'integers', 'algebra-precalculus']"
1344170,$\sum_{n=1}^{\infty} \frac{1}{(n+1)!} \prod_{k=1}^{n} f(k)$ diverges [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How can I prove the divergence of the series $$\sum_{n=1}^{\infty} \left(\frac{1}{(n+1)!} \prod_{k=1}^{n} f(k)\right) $$ if $f:\mathbb{N} \rightarrow \mathbb{N}$ is injective? $     $","['real-numbers', 'calculus', 'summation', 'real-analysis', 'sequences-and-series']"
1344216,Determinant of the Transpose of an Operator.,"Let $V$ be a vector space over a field $F$ of characteristic $0$.
A linear operator $T$ on $V$ induces a linear operator $\Lambda^k T:\Lambda^k V\to \Lambda^k V$ such that $\Lambda^k T(v_1\wedge \cdots\wedge v_k)=Tv_1\wedge\cdots\wedge Tv_k$ for all $v_1, \ldots, v_k\in V$. If $n=\dim V$, then since $\dim(\Lambda^n V)=1$, we know that there is a unique $c\in F$ such that $\Lambda^n T(v_1 \wedge \cdots\wedge v_n)=c\cdot(v_1\wedge \cdots\wedge v_n)$.
We call this constant the determinant of $T$. From this definition of the determinant, it immediately follows that $\det(TS)=(\det T)(\det S)$ for all linear operators $S$ and $T$ on $V$. Can we also easily show that $\det T^t=\det T$ for all $T\in \mathcal L(V)$? Here $T^t$ denotes the transpose of $T$.","['multilinear-algebra', 'determinant', 'tensor-products', 'linear-algebra']"
1344217,Finding a bijective function between an open disk and the open square,"How can I find a bijective function between these two sets?
  $$\{(x,y)\in\mathbb{R}^2 \,|\, x^2+y^2<1\}, \quad (-1,1) \times (-1,1) .$$ I already thought of first writing between 2nd and set of real numbers, but then I find myself stuck with finding between the reals and the 1st set. Any help would be appreciated.",['elementary-set-theory']
1344227,Hausdorff LindelÃ¶f Space is Regular?,"I think we can use same argument for saying regular LindelÃ¶f space is normal to prove Hausdorff LindelÃ¶f space is regular. But, I didn't heard about this proposition. What is the problem of using same argument?",['general-topology']
1344235,Underdetermined vs Overdetermined Problem,"I'm trying to create a model which is of the form $$y = (a_0 + a_1l)[b_0+\sum_{m=1}^M b_m\cos(mx-\alpha_m)] [c_0 +\sum_{n=1}^N c_n\cos(nz-\beta_n)]$$ In the above system, $l$,$x$ and $z$ are independent variables and $y$ is the dependent variable. The $a$, $b$ and $c$ terms are the unknowns. To solve for these unknowns, I have two separate data sets that I can use. Using data set $1$ creates an overdetermined system providing me with more observations than unknowns, while data set $2$ creates an underdetermined system with less observations than unknowns. In such a case, which approach would be better - underdetermined or overdetermined? and Why?","['statistics', 'linear-algebra', 'numerical-methods', 'systems-of-equations']"
1344278,How to calculate this limit as $x\rightarrow 0$?,"Not sure how to evaluate this one any hints?$$\lim_{x\rightarrow 0} \frac{\tan^3(x)}{x}$$ I think I have an answer, would it be $0$. Since we can write is as $$\frac{\sin(x)}{x} \frac{\sin^2(x)}{\cos^3(x)}$$ and then use algebra of limit and established result for left hand limit?",['limits']
1344282,Boundedness of the function,"Let $x\in(0,1)$ and $S_{n-1}=\sum\limits_{k=0}^{n-1}x^k$. Then define $f$ as the following :$$f(x)=\sum_{n=1}^{\infty}\left|\frac{nx^n}{S_{n-1}}-1\right|$$
I need to show that $\lim\limits_{x\to1^-}f(x)$ exists. Or at least, I want to show that $f$ is bounded on the given interval. Thanks for your helps.","['sequences-and-series', 'convergence-divergence', 'limits', 'supremum-and-infimum']"
1344287,Example: Operator with empty spectrum,"I tried Google and a few books but couldn't find a suitable example. Does anyone know an example of an (unbounded closed) Operator BETWEEN HILBERTSPACES(!), that has empty spectrum? Thanks for your help!","['hilbert-spaces', 'spectral-theory', 'operator-theory', 'functional-analysis']"
1344302,If $f(x)=4x^2+ax+a-3$ is negative for at least one negative $x$ find all possible values of $a$,If $f(x)=4x^2+ax+a-3$ is negative for at least one negative $x$ find all possible values of $a$ I don't know how to find all possible values. I tried making the lower of the two roots as negative. That does not seem to work out. As $4>0$ the curve will be concave up. There can be numerous cases possible.,"['algebra-precalculus', 'functions']"
1344314,$(x+y+z)^3-(y+z-x)^3-(z+x-y)^3-(x+y-z)^3=24xyz$?,"The question given is Show that $(x+y+z)^3-(y+z-x)^3-(z+x-y)^3-(x+y-z)^3=24xyz$. What I tried is suppose $a=(y+z-x),\ b=(z+x-y)$ and $c=(x+y-z)$ and then noted that $a+b+c=x+y+z$. So the question statement reduced to $(a+b+c)^3-(a^3+b^3+c^3)$. Then I tried to invoke the identity $(a^3+b^3+c^3-3abc)=(a+b+c)(a^2+b^2+c^2-ab-bc-ac)$ by adding and subtracting $3abc$ in the question statement. After doing all this when I substituted back the values of $a,b$ and $c$, I ended up with the initial question statement. Any hints will be appreciated.","['arithmetic', 'algebra-precalculus', 'problem-solving']"
1344321,Maximum number of edges in a subgraph of hypercube,"Let $H_n$ is an $n$-dimensional hypercube, $|V(H_n)|=2^n, |E(H_n)|=n2^{n-1}$. Let $M\subset V(H_n), |M|=2^k, 1\le k<n$, and $G_M$ is a subgraph of $H_n$ induced by $M$, $V(G_M)=2^k$. Prove that the maximum $|E(G_M)|$ is achieved iff $G_M$ is a $k$-dimensional hyperface of $H_n$ (then $|E(G_M)|=k2^{k-1}$). I found this sequence and this paper . But I believe that simple and beautiful proof exists for this particular case.","['graph-theory', 'combinatorial-geometry', 'discrete-mathematics']"
1344435,"Convergent $x_n,y_n$ and $x_n^{y_n}$ diverges","Let $x_n, y_n > 0$. I need an example of convergent sequences $x_n,y_n$ such that $x_n^{y_n}$ diverges. Could you help me?","['sequences-and-series', 'real-analysis']"
1344455,"Proving that $\int_0^1 \frac{\log \left(\frac{1}{t}\right) \log (t+2)}{t+1} \, dt=\frac{13}{24} \zeta (3)$","Are we aware of an elementary way of proving that? $$\int_0^1 \frac{\log \left(\frac{1}{t}\right) \log (t+2)}{t+1} \, dt=\frac{13}{24} \zeta (3)$$ Of course, with the help of Mathematica it can be done, but I wonder if there exists an elementary, simple, easy way of finishing it. $$\int \frac{\log \left(\frac{1}{t}\right) \log (t+2)}{t+1} \, dt=$$
$$=\text{Li}_3\left(\frac{t+2}{t}\right)-\text{Li}_3\left(-\frac{t+2}{t}\right)+\text{Li}_3(-t)+\text{Li}_3(t+2)-\left(\text{Li}_2\left(\frac{t+2}{t}\right)-\text{Li}_2\left(-\frac{t+2}{t}\right)\right) \log \left(-\frac{t+2}{t}\right)-\text{Li}_2(-t-1) \left(\log \left(\frac{1}{t}\right)+\log (t)\right)-\text{Li}_2(-t) \left(\log (t+2)-\log \left(-\frac{t+2}{t}\right)\right)-\text{Li}_2(t+2) \left(\log \left(-\frac{t+2}{t}\right)+\log (t)\right)-\frac{1}{2} \left(-\log \left(\frac{2 (t+1)}{t}\right)+\log \left(-\frac{2}{t}\right)+\log (t+1)\right) \log ^2\left(-\frac{t+2}{t}\right)-(\log (-t-1)-\log (t+1)) \log (t+2) \log \left(-\frac{t+2}{t}\right)-\log (t) \log (t+1) \log (t+2)-\frac{1}{2} (\log (t+1)-\log (-t-1)) \log (t+2) (\log (t+2)-2 \log (t))$$ that is obtain by Mathematica. EDIT: I think once we rewrite all as $$ \frac{1}{2}\int_0^1 \left(\frac{\log ^2\left(\frac{t+2}{t}\right)}{t+1}-\frac{\log ^2(t+2)}{t+1}-\frac{\log ^2\left(\frac{1}{t}\right)}{t+1}\right) \, dt$$
and employ the proper variable change, we're almost done, the idea that just crossed my mind. The hardest part is probably the integral 
$$\int_0^1 \frac{\log ^2\left(\frac{t+2}{t}\right)}{t+1} \ dt$$ where 
by letting $t/(t+2)\mapsto t$, we obtain the far nicer form $$2\int_0^{1/3} \frac{\log ^2(t)}{1-t^2} \, dt$$
$$=\int_0^{1/3} \frac{\log ^2(t)}{ 1-t} \ dt+\int_0^{1/3}\frac{\log ^2(t)}{ 1+t} \, dt$$
where then using geometric series and swapping the integration and summation, we obtain that$$\int_0^1 \frac{\log ^2\left(\frac{t+2}{t}\right)}{t+1} \ dt=$$
$$2\text{Li}_3\left(\frac{1}{3}\right)-2\text{Li}_3\left(-\frac{1}{3}\right)+ \log (3) \left(4 \text{Li}_2\left(\frac{1}{3}\right)-\text{Li}_2\left(\frac{1}{9}\right)+\log (2) \log (3)\right) \tag1$$
Using geometric series again, we easily get that $$\int_0^1 \frac{\log ^2\left(\frac{1}{t}\right)}{t+1} \, dt=\frac{3}{2} \zeta (3) \tag2$$
The last integral can be reduced by variable change to a well-known integral treated by Leonard Lewin in his book about polylogarithms, that is $$\int_0^1 \frac{\log ^2(t+2)}{t+1} \, dt=\int_1^2 \frac{\log ^2(t+1)}{t} \, dt$$
So, we can use the fact that 
$$\int_0^t \frac{\log ^2(1+t)}{t} \, dt$$
$$=\log(t)\log^2(1+t)-2/3\log^3(1+t)-2\log(1+t)\operatorname{Li}_2\left(\frac{1}{1+t}\right)-2\operatorname{Li}_3\left(\frac{1}{1+t}\right)+2\zeta(3)$$ So, using the foregoing result, we immediately get that 
$$\int_1^2 \frac{\log ^2(t+1)}{t} \, dt$$
$$=-2 \text{Li}_3\left(\frac{1}{3}\right)-2 \text{Li}_2\left(\frac{1}{3}\right) \log (3)+\frac{7 \zeta (3)}{4}-\frac{1}{3} 2 \log ^3(3)+\log (2) \log ^2(3) \tag3$$ Combining $(1) (2) (3)$, we obtain that
$$\int_0^1 \frac{\log \left(\frac{1}{t}\right) \log (t+2)}{t+1} \, dt$$
$$=2 \text{Li}_3\left(\frac{1}{3}\right)-\text{Li}_3\left(-\frac{1}{3}\right)-\frac{1}{2} \left(\text{Li}_2\left(\frac{1}{9}\right)-6 \text{Li}_2\left(\frac{1}{3}\right)\right) \log (3)-\frac{13 \zeta (3)}{8}+\frac{\log ^3(3)}{3}$$ Using $(20)$ from here http://mathworld.wolfram.com/Dilogarithm.html and then the identity and $(1)$ from this question/answer Proving $\text{Li}_3\left(-\frac{1}{3}\right)-2 \text{Li}_3\left(\frac{1}{3}\right)= -\frac{\log^33}{6}+\frac{\pi^2}{6}\log 3-\frac{13\zeta(3)}{6}$? , we get that $$\int_0^1 \frac{\log \left(\frac{1}{t}\right) \log (t+2)}{t+1} \, dt=\frac{13}{24} \zeta (3).$$ A SPECIAL ADDENDUM: The present integral can be viewed as the key core of calculating a pretty tough integral that was posted on MSE some time go, 
$$\int_0^1 \frac{\text{Li}_2 \left(-\frac{1}{1-z}\right)-\text{Li}_2 \left(-\frac{1}{1+z}\right)}{z}dz$$ at this link Evaluating $\int_0^1 \frac{\text{Li}_2 \left(-\frac{1}{1-z}\right)-\text{Li}_2 \left(-\frac{1}{1+z}\right)}{z}dz$ . Simple integration by parts combined with the use of the geometric series shows that $$\int_0^1 \frac{\text{Li}_2 \left(-\frac{1}{1-z}\right)-\text{Li}_2 \left(-\frac{1}{1+z}\right)}{z}dz$$ 
$$=\int_0^1 \frac{\log (z+2) \log (z)}{z+1}dz+\underbrace{\int_0^1\frac{\log (2-z) \log (z)}{1-z} \ dz}_{\large \sum _{n=1}^{\infty } \frac{(-1)^n H_n}{n^2}=-5/8  \zeta (3)}-\underbrace{\int_0^1\frac{\log (1-z) \log (z)}{1-z}dz}_{\large\sum _{n=1}^{\infty } \frac{H_n}{(n+1)^2}=\zeta (3)}-\underbrace{\int_0^1\frac{\log (z+1) \log (z)}{z+1} \, dz}_{\large \sum _{n=1}^{\infty } \frac{(-1)^n H_n}{(n+1)^2}=-1/8\zeta (3)}$$
where since the integral unknown is calculated in this post, we conclude that $$\int_0^1 \frac{\text{Li}_2 \left(-\frac{1}{1-z}\right)-\text{Li}_2 \left(-\frac{1}{1+z}\right)}{z}dz$$ 
$$=-\frac{49}{24}\zeta(3).$$ A SPECIAL ADDENDUM $2$: By a careful approach of the previous results, we also obtain the value of the very beautiful series $$\sum _{k=1}^{\infty } \sum _{n=1}^{\infty } \frac{(-1)^k }{k2^k n 2^n (k+n)}=\frac{1}{12} \left(3 \text{Li}_3\left(\frac{1}{4}\right)+6\log (2) \text{Li}_2\left(\frac{1}{4}\right) +4 \log ^3(2)-4 \zeta (3)\right)$$ Q.E.D.","['calculus', 'real-analysis', 'definite-integrals', 'integration']"
1344461,Homomorphisms from $\mathbb{C}$ to $M_2(\mathbb{R})$ are conjugate,"Let $\phi_1$ and $\phi_2$ be two ring homomorphisms from $\mathbb{C}$ to $M_2(\mathbb{R})$. Show that there exists $g\in GL_2(\mathbb{R})$ such that $\phi_2(x) = g\phi_1(x)g^{-1}$ for all $x\in\mathbb{C}$. $\phi(1) = I$ by definition of ring homomorphism.  By additivity, $\phi(-1) = -I$.  $\phi(i)^2 = \phi(i^2) = \phi(-1) = -I$ and hence the minimal polynomial of $\phi(i)$ in field $\mathbb{R}$ is $x^2+1$.  If we consider the rational forms of $\phi(i)$, then we see that there exists $g\in GL_2(\mathbb{R})$ such that $\phi_2(i) = g\phi_1(i)g^{-1}$. If we can show that $\phi(r) = rI$ for all $r\in\mathbb{R}$, then we are done because $1$ and $i$ are a basis for $\mathbb{C}$ over $\mathbb{R}$.  It's easy to see that $\phi(q) = q$ for all $q\in\mathbb{Q}$. I want to use the fact that $\mathbb{Q}$ is dense in $\mathbb{R}$, but I'm stuck here. Any suggestion? Thanks.","['abstract-algebra', 'matrices']"
1344480,Existence of differentiable functions on $\mathbb R$ whose derivative is constant on the complement of uncountable set but not everywhere,"Let $ A $ be a countable subset of the set of real numbers and $f:\mathbb R \to \mathbb R$ be a differentiable function such that $f'$ is constant on $\mathbb R \setminus A$ , then I know that $f'$ is constant on $\mathbb R$ . My question is ; is it true that for every $c \in \mathbb R$ and uncountable set $B \subseteq \mathbb R$ , there exists a differentiable function $f:\mathbb R \to \mathbb R$ such that $f'(x)=c , \forall x \in \mathbb R \setminus B$ but $f'$ is not constant on $\mathbb R$ ?","['elementary-set-theory', 'real-analysis', 'derivatives']"
1344487,Integral curves on immersed submanifold,"An exercise of the book ""Introduction to smooth manifolds - John M. Lee"" asks to prove that if $S$ is a closed embedded submanifold of a manifold $M$, and $X$ is a vector field on $M$ tangent to $S$, then every integral curve of $X$ that intersect $S$ is contained in $S$. Can someone show me a counteresample in the ""closed-immersed"" case?",['differential-geometry']
1344493,Epsilon-Delta proof of $\lim_{x\to 2} x^2=4$,"I have seen and understand the delta-epsilon proof of the limit of $x^2$ for $x\to2$, such as explained here: https://www.youtube.com/watch?v=gLpQgWWXgMM Now I am wondering, is there also another way? How about this: Verify that $\lim x^2=4$ (for $x\to2$) STEP A: Express epsilon in terms of $x$:
\begin{align}
|x^2-4| &< \varepsilon\\
-\varepsilon &< x^2-4 < \varepsilon\\
4-\varepsilon &< x^2 < 4+\varepsilon\\
\sqrt{4-\varepsilon} &< x < \sqrt{4+\varepsilon}
\end{align} STEP B: Express delta in terms of $x$
\begin{align}
|x-2| &< \delta\\
-\delta &< x-2 < \delta\\
2-\delta &< x < 2+\delta
\end{align} STEP C: Now we can express $\delta$ in terms of $\varepsilon$ hence proving the limit. If we take $\delta=\min\{-2+\sqrt{4+\varepsilon},2-\sqrt{4-\varepsilon}\}$ then the limit is proven Did I make any mistake? Thanks! Cheers!","['quadratics', 'limits', 'epsilon-delta']"
1344506,Is $H^2(\Omega)\cap H_0^1(\Omega)$ compactly embedded on $H_0^1(\Omega)$?,"Considering $\Omega$ bounded and $\partial \Omega$ smooth. 
I already know that $H^2(\Omega)\cap H_0^1(\Omega)$ is continuously embedded on $H_0^1(\Omega)$, thus if I take a bounded sequence in $H^2(\Omega)\cap H_0^1(\Omega)$ it is also bounded on $H_0^1(\Omega)$, and it has a weakly convergent subsequence, but I didn't succeed with that approach. I also tried to use Rellich Theorem that gives me a strongly convergent subsequence $u_{k_j}$ on $ L^{2}(\Omega)$ when I take $ \{ u_k\}\subset H^2(\Omega)\cap H_0^1(\Omega) : \|u_k\|_{H^2(\Omega)}\leq M $. Because $u_k$ is also bounded on $H_0^1(\Omega)$. But then I don't know how to make 
$$\int\limits_\Omega |Du_{k_j}|^2$$
convergent.
Can anyone please help me with that? 
Thanks in advance.","['regularity-theory-of-pdes', 'functional-analysis']"
1344517,"After switching a lamp on and off infinitely many times in one minute, is it on or off? [duplicate]","This question already has answers here : Thomson's Lamp and the possibility of supertasks (8 answers) Closed 8 years ago . So we have a lamp. It's switched on. let's represent its state of being switched on with associating it with $1$ and being off with $-1$. after half a minute passes, you turn it off, after another quarter of a minute passes you turn it on and so on. Now this process will take : $1/2+1/4+1/16+...=1$ minute and this is the states of the lamp put into a sequence: $(1,-1,1,-1,1,...)$ After a minute of switching it on an off passes, will it be on or off? I'm well aware that the limit of this sequence does not exist, however, my intuition dictates that after a minute passes, it is either on or off. So does this lamp have a final state(on or off) which is impossible for us to know? or it does not have a finals state(it seems to me, it must have one!)?","['analysis', 'sequences-and-series', 'infinity']"
1344528,"Function equation, find the function evaluated at the certain point.","Let $f(x)$ be a polynomial with real coefficients such that $f(0) = 1,$ $f(2)+f(3)=125,$ and for all $x$, $f(x)f(2x^{2})=f(2x^{3}+x).$ Find $f(5).$ The constant term, $a_0 = f(0) = 1$. Let: $$f(x) = \sum_{k=0}^{n} a_k x^k$$ $f(2) = \sum_{k=0}^{n} a_k 2^k$ and $f(3) = \sum_{k=0}^{n} a_k 3^k$ $$f(1)f(2) = f(3)$$ But I have no clue. Hints please, no complete answers!","['contest-math', 'polynomials', 'algebra-precalculus', 'combinatorics']"
1344536,A sequence avoiding 3-term power progressions,"Rankin 1 studied sequences of integers that avoid 3-term geometric progressions,
$(a, a c, a c^2)$,
e.g.,
$$\{1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 19, \ldots \} \;$$
So, $18$ is excluded because $(2,6,18)=(2,2 {\cdot} 3, 2 {\cdot} 3^2)$ forms a geometric progression. He showed that the asymptotic density of that greedy sequence exceeds $0.71$. I wondered about sequences that avoid 3-term power progressions ,
$(a, a c, a c^k)$, where $c\ge 2$ and $k\ge 2$ are natural numbers.
Here I start again with $(1,2)$ and continue to add the first number that
avoids all 3-term power progressions:
$$\{1, 2, 3, 5, 6, 7, 10, 11, 13, 14, 15, 17, 19, 21, 22, 23, 26, 29, 
30, 31, 33, 34, 35, 37, \ldots \}\;.$$
For example, $8$ is excluded because $(1,2,8)=(1,1{\cdot} 2, 1 {\cdot} 2^3)$
is a power sequence.
Much later, $945$ is excluded because $(35,105,945)=(35, 35{\cdot} 3, 35 {\cdot} 3^3)$. Q . What is the asymptotic density of the above greedy sequence
  that avoids all 3-term power progressions? The density appears to be about $0.63$, up to $644$ terms ending in $1021$.
Note that the square-free integers have density $6/\pi^2 \approx 0.61$.
My sequence is square-free, cube-free, etc., because $(1, c, c^k)$ is a 
power progression. 1 R. Rankin. ""Sets of integers containing not more than a given number of terms in arithmetical progression."" Proc. Roy. Soc. Edinburgh Sect. A . 65 (1961).
Cited by Nathan McNew in poster, ""Avoiding Geometric Progressions in the Integers."" ( PDF download .)","['sequences-and-series', 'number-theory']"
1344548,Formula to represent 'equality',"I am trying to find the appropriate formula in order to calculate and represent the 'equality' between a set of values. Let me explain with an example: Imagine 3 people speaking on an a TV Show that lasts 45 minutes:
Person 1 -> 30 minutes spoken
Person 2 -> 5 minutes spoken
Person 3 -> 10 minutes spoken I want to find a number that expresses how ""equal"" was this discussion in matters of time spoken per person. The ideal would be to speak 15 minutes each (100% equality) and the worst case scenario would be to speak only one person for 45 minutes (0% equality). My first thought, is to use the standard deviation. When the standard deviation is 0 we have perfect equality. As the standard deviation gets larger, the equality is reduced. The problem with standard deviation, is that is not easily readable for a person who is not familiar with statistics. Can you think of a formula that can help me represent the standard deviation (maybe in conjunction with the mean) as a percentage between 0% and 100% ?",['statistics']
1344549,Is this operator $A = \pmatrix{1&1\\0&1}$ self-adjoint?,"Is this operator
$$A = \pmatrix{1&1\\0&1}$$
self-adjoint? I think not, because
$$\pmatrix{1&1\\0&1}^T\neq A$$
where $T$ is the transposition of the matrix. What do you all think?","['adjoint-operators', 'operator-theory', 'matrices']"
1344560,Trigonometry equation maximum,"Given the equation: $\cos x + \sqrt3 \sin x = a^2$  find the maximum value for $a$ for which the equation has solutions and for this case solve the equation, $a \in \mathbb{R}$. I'm guessing I need to find the maximum for the function and for this I have to differentiate it and solve it when it's derivative is $0$? At a first glance I'd say the maximum for $a$ is $\sqrt2$ when $x=\frac{\pi}{3}$, but how do I go around proving this?",['trigonometry']
1344581,Separate real and imaginary part of $\arccos(z)$,"Beginning with $$i \cos \left[ \frac{1}{n} \arccos \left( \frac{i}{\epsilon} \right) + \frac{m \pi}{n} \right]$$ where $m,n \in \mathbf{Z}$, $\epsilon >0$, $\epsilon \in \mathbf{R}$ and $i$ is the imaginary unit, I would like to obtain separately the real and imaginary part of the cosine argument: (1) $$\frac{1}{n} \arccos \left( \frac{i}{\epsilon} \right) + \frac{m \pi}{n} = x + iy$$ By simply applying the definition : (2) $$\frac{1}{n} \arccos \left( \frac{i}{\epsilon} \right) = \frac{\pi}{2n} + i \frac{1}{n} \ln \left[ \frac{1}{\epsilon} (\sqrt{1 + \epsilon^2} - 1) \right]$$ Similarly, if we apply the definition of complex $\arcsin$, we obtain: $$\arcsin \left( \frac{i}{\epsilon} \right) = -i \ln \left[ \frac{1}{\epsilon} (\sqrt{1 + \epsilon^2} - 1) \right]$$ Remembering (as stated here ) that $$\mathrm{arsinh}(z) = -i\arcsin(iz)$$ we obtain $$\mathrm{arsinh} \left( \frac{1}{\epsilon} \right) = - \ln \left[ \frac{1}{\epsilon} (\sqrt{1 + \epsilon^2} - 1) \right]$$ So we can write $$x + iy = \frac{m \pi}{n} + \frac{\pi}{2n} + i\frac{1}{n} \ln \left[ \frac{1}{\epsilon} (\sqrt{1 + \epsilon^2} - 1) \right]$$ $$x + iy = \frac{\pi}{2} \left( \frac{2m + 1}{n} \right) - i\frac{1}{n} \mathrm{arsinh} \left( \frac{1}{\epsilon} \right) = \frac{\pi}{2} \left( \frac{2m - 1}{n} \right) - i\frac{1}{n} \mathrm{arsinh} \left( \frac{1}{\epsilon} \right)$$ But the correct result should be (3) $$x + iy = \frac{\pi}{2} \left( \frac{2m - 1}{n} \right) + i\frac{1}{n} \mathrm{arsinh} \left( \frac{1}{\epsilon} \right)$$ So, are there any errors? How to obtain (3) from (1)?","['hyperbolic-functions', 'complex-analysis', 'complex-numbers', 'trigonometry']"
1344599,How do we know the joint probability distribution measure is valid?,"Let $X,Y$ be $\mathbb{R}$-valued random variables on $(\Omega, \mathcal{F})$.  Then $(X,Y) : \Omega \to \mathbb{R}^2$ induces a joint probability distribution measure $\mu_{X,Y}: \mathcal{B} \otimes \mathcal{B} \to [0,1]$ given by
$$
\mu_{X,Y}(A) = P((X,Y) \in A).
$$ Now, if $A = A_1 \times A_2$ for $A_1, A_2 \in \mathcal{B}$ then I suppose $P((X,Y) \in A) = P(X \in A_1 \cap Y \in A_2)$, and since both $\{X \in A_1\}, \{Y \in A_2\} \in \mathcal{F}$ we get $\{X \in A_1\} \cap \{Y \in A_2\} \in \mathcal{F}$ and so this is a measurable set. But what about general Borel subsets of $\mathbb{R}^2$?  Why would I expect $\{(X,Y) \in A\} \in \mathcal{F}$?",['probability-theory']
1344627,"How to use Chebyshev Polynomials to approximate $\sin(x)$ and $\cos(x)$ within the interval $[âˆ’Ï€,Ï€]$?","I have approximated $\sin(x)$ and $\cos (x)$ using the Taylor Series (Maclaurin Series) with the following results: $$f(x)=f(0)+\frac{f^{(1)}(0)}{1!}(x-0)+\frac{f^{(2)}(0)}{2!}(x-0)^2+\frac{f^{(3)}(0)}{3!}(x-0)^3+\cdots$$
$$\begin{align}\implies \sin(x)&=x-\frac{x^3}{3!}+\frac{x^5}{5!}-\frac{x^7}{7!}+\frac{x^9}{9!}-\cdots\\&=\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)!}x^{2n+1} \end{align}$$ $$f(x)=f(a)+\frac{f^{(1)}(a)}{1!}(x-a)+\frac{f^{(2)}(a)}{2!}(x-a)^2+\frac{f^{(3)}(a)}{3!}(x-a)^3+\cdots$$
$$\begin{align} \implies \cos(x)&=1-\frac{x^2}{2!}+\frac{x^4}{4!}-\frac{x^6}{6!}+\frac{x^8}{8!}-\frac{x^10}{10!}+\cdots \\&=\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!}x^{2n} \end{align}$$ How can I use Chebyshev Polynomials to approximate $\sin(x)$ and $\cos(x)$ within the interval $[âˆ’Ï€,Ï€]$? Thanks in advance!","['taylor-expansion', 'bessel-functions', 'chebyshev-polynomials', 'trigonometry']"
1344633,"$P\left(\limsup \left(X_n=0, X_ {n+1}=1,X_ {n+2}=0 \right)\right)$","""Let $X_1, X_2, ...$  independent random variables where $X_n\sim B(p_n)$ and $p_n = \frac{1}{n}$. Calculate $P\left(\limsup \left(X_n=0, X_ {n+1}=1,X_ {n+2}=0 \right)\right)$"" I suppose that i can use the lemma of Borel-Cantelli, but I don't know how interpret that limsup... Thank you very much!","['probability-theory', 'independence', 'borel-cantelli-lemmas', 'limsup-and-liminf']"
1344642,How many ways can I connect labeled trees into a tree.,"Suppose I have the labeled trees $T_{1}, \ldots, T_{n}$ with $b_{1}, \ldots, b_{n}$ vertices respectively. I would like to know how many ways I can compose a tree from these trees by using all trees? In this problem editorial they claim that there are $\prod_{i=1}^{n}{b_{i}} \cdot \left( \sum_{i = 1}^{n}{b_{i}} \right)^{n - 2}$ such compositions. I don't know how to prove this and there is no proof linked on the editorial either. Could someone help me with this?","['combinatorics', 'trees']"
1344669,Relationship between completeness and well ordering (meta).,"Here is the definition for completeness of the reals (there are many equivalent formulations but I am interested in this one); Completeness : Every non-empty subset of the reals which is bounded above has a least upper bound. This can be translated to the following: Suppose $ \displaystyle A$ is a non-empty set of real numbers bounded above. Then the set $ \displaystyle B = \{ b \in \mathbb{R} : (\text{ for all } a \in A)(b \ge a)\}$ has a minimum element. In other words, given a non-empty (bounded above) subest of real numbers , we can produce a natural set which has a minimum element. Well ordering : Every non-empty subset of the natural numbers has a least element. In other words, given a non-empty subest of natural numbers , we can produce a natural set which has a minimum element. Question: Is this a coincidence, or is there some deeper structure or theory which can encapsulate this kind of behaviour, for the formulations are very close (almost) identical, i.e. beginning with an arbitrary subset which is non-empty and producing a minimum element?","['elementary-set-theory', 'meta-math', 'real-analysis']"
1344670,How do i find $\tan(\theta)$ such that : $\frac{16}{\sin^6(\theta)} + \frac{81}{\cos^6(\theta)}=625$??,How do i find $\tan(\theta)$ such that :$$\frac{16}{\sin^6(\theta)} + \frac{81}{\cos^6(\theta)}=625$$? Note : i used some trigono-form but sorry i didn't succed . Thank you for any help.,"['real-analysis', 'algebra-precalculus']"
1344679,How to show that $\mathcal{K}/\mathcal{O}$ is isomorphic to$\sum_{P\in X} i_P(I_P)$,"This a Hartshorne exercise (Ex II 1.21d)
Let $X=\mathbb{P}^1$. Let $\mathcal{K}$ be the constant sheaf of the quotient field of X. Then we need to show that
 $\mathcal{K}/\mathcal{O}$ is isomorphic to the direct sum of sheaves: $\sum_{P\in X} i_P(I_P)$, where $I_P=K/\mathcal{O}_P$, and $i_P(I_P)$ is the skyscraper sheaf at point $P\in X$. I would like to check the stalks.
If Q is a closed point of X, then $(\mathcal{K}/\mathcal{O})_Q=K/\mathcal{O}_Q$, and $(\sum_{P\in X} i_P(I_P))_Q=I_Q=K/\mathcal{O}_Q$. My problem is their stalks at the generic point $\eta\in X$. $(\mathcal{K}/\mathcal{O})_\eta=0$, since $\mathcal{O}_\eta=K$. How about $(\sum_{P\in X} i_P(I_P))_\eta =\sum_{P\in X} i_P(I_P)_\eta=\sum_{P\in X} I_P = \sum_{P\in X} K/\mathcal{O}_P$ Is the last direct sum equal to zero? or I made any mistakes? Thanks",['algebraic-geometry']
1344688,"Solve $x^2-|5x-3|-x<2,\ \ x\in \mathbb{R} $","Solve $x^2-|5x-3|-x<2,\ \ x\in \mathbb{R} $ I tried $x^2-|5x-3|-x<2$  , case $1$ ,  $x^2-(5x-3)-x<2,\ x\geq 0 \\
x^2-6x+1<0 \\
3-2\sqrt2 < 3+2\sqrt2 \\
 0.17<x<5.8\\
$ $x^2-(5x-3)-x<2$  , case $2$ ,  $x^2+(5x-3)-x<2,\ x< 0 \\
x^2+4x-5<0 \\
-5 < x< 1\\
$ The region common is $3-2\sqrt2<x<1$ But the book gives answer $-5<x<3+2\sqrt2$ .  I am confused.","['quadratics', 'absolute-value', 'algebra-precalculus', 'inequality']"
1344690,Is it possible to find the vertices of an equilateral triangle given its center point?,"I was wondering how to find the vertices of an equilateral triangle given its center point? Such as: A
        /\
       /  \
      /    \
     /   M  \
  B /________\ C Provided that AB, AC, BC = x and M = (50,50) and M is the middle of the triangle, I want to find A , B and C . Thanks.","['euclidean-geometry', 'geometry', 'triangles']"
1344695,Prove a sequence converges using sub-sequences,"Let there be a sequence $a_n$ The following sub-sequences converge: $a_{n^3},a^3_{2n+3}-a^3_{2n+4},a^2_{2n+3}-a^2_{2n+4},a_{2n+15}$ Prove: $a_n$ converges I think it has something to do with binomial due to the given sub-sequences for example: $(a_{2n+3}-a_{2n+4})\cdot (a_{2n+3}+a_{2n+4})=a^2_{2n+3}-a^2_{2n+4}$ so can I say something about the components of $a^2_{2n+3}-a^2_{2n+4}$?","['sequences-and-series', 'calculus']"
1344699,Can any function of the second moment of a random variable be recovered from its quantile function?,"Summary of question It is known that the expected value of a random variable can be obtained from integrating its survival function. This is easily restated in terms of the quantile function as:
$$
\int_0^\infty S(x)\;dx = \int_0^1F^{-1}(x)
$$ whose equivalence can be seen graphically as integrating over the same area. This is useful, as when dealing with empirical or stochastically generated CDFs, layer loss statistics can be estimated directly off of the empirical quantile/CDF. It would be useful to be able to extract layer loss variance information in a similar way. Is there any similar relationship or method to extract higher moments, limited or unlimited, from the quantile function? Detailed question Background It is a known property that given a random variable $X$ with density $f(x)$, cumulative distribution function (CDF) $F(x)$, survival function $S(x)$, and quantile function $F^{-1}(x)$, there is the following relationship between S(x) and E(X):
$$
E(X) = \int_0^\infty xf(x)\;dx = \int_0^\infty S(x)\;dx = \int_0^1F^{-1}(x)\;dx
$$ The last form, obtained by solving for the area in terms of y instead of x, is particurlarly convenient when forced to estimate these calculations in tabular formal (like Excel). Somewhat less known is that what we call the ""layer loss cost"" or the amount of the random variable that pierces a threshold but is capped by a limit is also recoverable from the survival function. Let $E(X\wedge A)$ be defined as the limited expected value of $X$ capped at $A$, or:
$$
E(X\wedge A) = \int_0^A xf(x)\;dx + A\int_A^\infty f(x)\;dx
$$
Given random variable $Y$, the loss in the layer between $A$ and $B$, defined as $\min(B-A, \max(0, X - A))$, or equvalently $\textrm{median}(0, B-A, X-A)$, the following relationship also holds:
$$
\begin{align}
E(Y) &= E(X\wedge B) - E(X\wedge A)\\
&= \int_A^B (x - A)f(x)\;dx + (B-A) \int_B^\infty f(x)\;dx\\
&= \int_A^B S(x)\;dx
\end{align}
$$ So it can be said that the CDF/survival function encodes information about the first moment (limited and unlimited) which can be relatively easy to extract. Proof for first moment Both relationships are usually proved by integration by parts, and can be proved generally without recourse to the specific form of the distribution at hand.
$$
\begin{align}
E(Y) &= \int_A^B (x - A)f(x)\;dx + (B-A) \int_B^\infty f(x)\;dx\\
&= \int_A^Bxf(x)\;dx - A \int_A^Bf(x)\;dx + (B - A)S(B)\\
&= \int_A^Bxf(x)\;dx - A\left[S(A) - S(B)\right] + BS(B) - AS(B)\\
&= \int_A^Bxf(x)\;dx - AS(A) + AS(B) + BS(B) - AS(B)
\end{align}
$$
Now to focus on the first term. Using the fact that $S(x) = 1 - F(x)$ we have
$$
\frac{d}{dx}S(x) = -f(x)
$$ So using integration by parts, we can let $u = x, du = 1, dv = f(x), v = -S(x)$ and state generally that:
$$
\begin{align}
\int_A^B xf(x)\;dx &= -xS(x)\bigg\vert_A^B + \int_A^B S(x) dx\\
&= \int_A^B S(x)\;dx - BS(B) + AS(A)
\end{align}
$$
Substituting the above in the original question we get
$$
\begin{align}
E(Y) = \int_A^B S(x)\;dx &- BS(B) + AS(A) \\
&- AS(A) + AS(B) + BS(B) - AS(B)
\end{align}
$$
All the non-integral terms cancel, leaving us with $E(Y) = \int_A^B S(x)\;dx\;\blacksquare$. Attempt for second moment I am interested in the variance of the random variable $Y$ as defined above. The most starightforward way to approach this would be to calculate $E(Y^2)$ and the subtract $E(Y)^2$ as obtained from the quantile function per above. This could be stated as:
$$
E(Y^2) = \int_A^B (x - A)^2 f(x)\;dx + (B-A)^2\int_B^\infty f(x)\;dx
$$
Expanding the terms, engaging in some algebraic manipulation and cancellation, and using the result from above for the first moment, we get (if I have not made a mistake):
$$
\int_A^B x^2 f(x)\;dx - 2A\overbrace{\int_A^BS(x)\;dx}^{\textrm{Can use } F^{-1}(x)} - A^2S(A) + B^2S(B)
$$ At this point I am stuck, since to use integration by parts to handle the first term would require knowing the antiderivative of the general survival function, which I don't know, nor do I know how to convert that into using the quantile function, as could be done for the survival function itself. Specific problem Using the same integration by parts technique on $\int_A^B x^2 f(x)\;dx$, the term
$$
\int_A^B x S(x)\;dx
$$ arises, and I do not know how to proceed from there. Recap As mentioned in the summary, often I will have an ground-up (0 to infinity) empirical distribution function for a random variable representing a loss severity, and I am interested not only in the expected loss in a layer but the variance of said loss, so being able to extract the second moment from the ECDF/quantile table would be very helpful. Thank you. Updated with Answer For completeness sake, for unlimited moments, just as:
$$
E(X) = \int_0^\infty S(x)\;dx
$$
the corresponding formula for the second moment is:
$$
E(X^2) = 2\int_0^\infty xS(x)\;dx
$$
And for layer values $Y$ as defined above, just as
$$
E(Y) = \int_A^B S(x)\;dx
$$
the second moment of $Y$ can be recovered as:
$$
E(Y^2) = 2\int_A^B (x-A)S(x)\;dx
$$ Updated with more complete and elegant answer to the general (non-layered) case See this question for a closed form answer for getting the moments of a distribution through integrating its quantile function, as well as the solution to $\int_0^\infty xS(x)dx$.","['actuarial-science', 'probability', 'statistics']"
1344706,Are continuous functions with compact support bounded?,While studying measure theory I came across the following fact: $\mathcal{K}(X) \subset C_b(X)$ (meaning the continuous functions with compact support are a subset of the bounded continuous functions). This seems somehow odd to me; I've tried to prove it but did not succeed. Could someone help me out here? Thanks!,"['functional-analysis', 'real-analysis', 'general-topology', 'measure-theory']"
1344727,Differentiate the Function $f(x)= \sqrt{x} \ln x$,Differentiate the Function $f(x)= \sqrt{x} \ln x$,"['calculus', 'derivatives']"
1344734,Intuition behind Chebyshev's inequality,"Is there any intuition behind Chebyshev's inequality or is that only pure mathematics? What strikes me is that any random variable (whatever distribution it has) applies to that. $$
    \Pr(|X-\mu|\geq k\sigma) \leq \frac{1}{k^2}.
  $$","['probability-theory', 'intuition', 'inequality']"
1344739,Find the general values of $x$ satisfying the trigonometric equation,"Find the general values of $x$ satisfying 
  $$
  \frac{\tan^2 x \sin^2 x}{1-\sin^2 x \cos2x}+\frac{\cot^2 x \cos^2 x}{1-\cos^2 x \cos2x}+\frac{2\sin^2 x}{\tan^2 x+\cot^2 x}=\frac{3}{2}
$$ It seems to me just some equality case of an inequality. But I am unable to find the inequality. Thanks.","['inequality', 'trigonometry']"
1344743,What to call & how to compute errors in a very asymmetric sample,"Consider the following sample $\{1.25,1.5,1.75,2.0,2.25,2.5,2.75,10.\}$. Mean is $\mu=3.$, standard deviation is $\sigma\approx 2.69$. I am wondering how to compute and what to call error bars in the context of this sample. Using the standard error ($\mu \pm \sigma$) will obviously not be very useful as it would comprise the complete sample except for one outlier. Using 1st and 4th quartile $[1.75,2.5]$ describes the sample much better but seems odd to use for plotting error bars as well as the mean is not inside this interval. One could use the mean deviation of all upper (above the mean) and all lower (below the mean) observations, which would give $[2.,10.]$, but there does not seem to be a proper name for this concept (discussed here ). I tend to favor this option but have trouble referring to what is plotted in a convenient way (calling it ""mean deviation"", ""standard deviation"", ""standard errors"", or ""mean errors"" is just plain wrong; calling it ""errors"" or ""upper/lower errors"" seems unspecific and also seems to imply some kind of estimation which is not involved; calling it ""upper/lower deviation"" is unspecific and readers would likely assume it to refer to something like the standard deviation). How are error bars usually computed for such a sample and what are they then usually referred to (other than ""error bars"")?","['statistics', 'standard-deviation']"
1344755,Solve for $x$ in: $e^{2\ln(x)-\ln(x^2+x-3)} = 1$,"So the question is to solve for x in: $$e^{[2\ln(x)-\ln(x^2+x-3)]} = 1$$ I took the natural log of both sides, and simplified. Here is what I've gotten it down to:
$$2\ln(x)  = \ln(x^2+x-3)$$
And I'm not sure if you can raise e to the power of each side with that 2 there.
Thanks in advance.","['exponential-function', 'algebra-precalculus', 'logarithms']"
1344777,Under what conditions does $M \oplus A \cong M \oplus B$ imply $A \cong B$?,"This question is fairly general (I'm actually interested in a more specific setting, which I'll mention later), and I've found similar questions/answers on here but they don't seem to answer the following: Let $R$ be a ring. Are there any simple conditions on $R$-modules $M, A$ and $B$ to ensure that $M \oplus A \cong M \oplus B$ implies $A \cong B$? This is obviously not true in general: a simple counterexample is given by $ M= \bigoplus_{n \in \mathbb{N}} \mathbb{Z}, A = \mathbb{Z}, B = 0 $. In the more specific setting that I'm interested in, $R$ is noetherian, each module is finitely generated, reflexive and satisfies $\text{Ext}_R^n(M,R) = 0$ for $n \geqslant 1$ (or replacing $M$ with $A$ or $B$), and $A$ is projective. In this case, do we have the desired result?","['homological-algebra', 'abstract-algebra', 'modules', 'ring-theory']"
1344783,Evaluating the indefinite integral $\int\log\!\left(x+\sqrt{x^2-1}\right)\!dx$,"I came across the following integral, and I don't know how to solve it.
$$
\int\log\left(x+\sqrt{x^2-1}\right)dx
$$
I tried the ""obvious"" substitution of $x=\sec\theta$, which gives you:
$$
\int\tan\theta\sec\theta\log\left(\tan\theta+\sec\theta\right)d\theta
$$
However, this doesn't simplify it much, in the sense that I have no idea how to solve this now! Take out the common factor of $\sec$ from the log, or perhaps do $u=\tan\theta+\sec\theta$, but both of these lead to dead ends (at least for me). In case you are wondering, Wolfram|Alpha claims the answer is:
$$x\log\left(x+\sqrt{x^2-1}\right)-\sqrt{x^2-1}+c$$","['calculus', 'indefinite-integrals', 'integration']"
1344825,What is wrong in my $f'(x)$?,"We have $f:\mathbb{R}\rightarrow\mathbb{R}, f(x)=\frac{x^2-x+1}{x^2+x+1}$ and we need to find $f'(x)$. Here is all my steps: $$\begin{align}f'(x)&=\frac{(2x-1)(x^2+x+1)-(x^2-x+1)(2x+1)}{(x^2+x+1)^2}\\&=\frac{(2x-1)(x^2+1)-(2x+1)(x^2+1)}{(\cdots)^2}\\&=\frac{(x^2+1)(2x-1-2x-1)}{(\cdots)^2}\\&=\frac{2(1-x)(1+x)}{(\cdots)^2},\forall x\in\mathbb{R}\end{align}$$ But in my book they say that $f'(x)=\frac{2(x-1)(x+1)}{(x^2+x+1)^2}$. What is wrong in my method ?","['calculus', 'derivatives']"
1344843,"General notions of ""basis"" in algebra/model theory","Free groups, free abelian groups, and vector spaces all have a notion of 'basis': a subset $B$ of the structure such that everything in the structure can be written uniquely as a finite combination of elements of $B$. What is the most general (model theoretic) structure for which it makes sense to think about a basis? Do all of these structures have theorems along the lines of ""if $S$ is a structure with a basis and $T$ is a substructure, then $T$ must also have a basis""? This certainly is true for free (abelian) groups and vector spaces.","['abstract-algebra', 'model-theory']"
1344864,Hints on solving $y'=\frac{y}{3x-y^2}$,$$y'=\frac{y}{3x-y^2}$$ My attempt: $$\frac{dy}{dx}=\frac{y}{3x-y^2}$$ $$dy\cdot(3x-y^2)=dx\cdot y$$ $$dy\cdot3x-dy\cdot y^2=dx\cdot y$$ Any direction? I need hints please $\color{red}{not}$ a full answer,['ordinary-differential-equations']
1344917,How do i solve this equation ${\mathbb{R}}$: $3 \sin^3x+2 \cos^3x=2 \sin x+\cos x$?,How do I solve this equation ${\mathbb{R}}$: $3 \sin^3x+2 \cos^3x=2 \sin x+\cos x $? Note : I have tried using trigonometric transformation but it seems very complicated to get the result .. may there is a clear variable change or some thing as this ... Thank you for any help .,"['numerical-methods', 'trigonometry']"
1344924,How to solve $y' = -2x -y$,"My thought: $\displaystyle\frac{dy}{dx}+x^0y=-2x$ Considering it as the form of linear equation, $\displaystyle\frac{dy}{dx}+P(x)y=Q(x)$ Multiplying $e^{\int1dx} = e^x$ on both sides, $e^x\displaystyle\frac{dy}{dx}+e^xy=-2xe^x$ $\displaystyle\frac{d}{dx}(e^xy)=-2xe^x$ $e^xy=\int-2xe^xdx$ $e^xy=-2(xe^x-e^x)$ $y=-2(x-1)+C$ It seems to me that the solution is wrong because i cannot move back to my original question from here. Is my answer correct? If not, can anyone tell me how to solve this problem with explanation.",['ordinary-differential-equations']
1344933,If $f(f(x))=x$ does that mean $f(x)$ equals its inverse?,"Given any real function, if $f(f(x))=x$ does that mean $f(x)$ is its own inverse? I am confused since $f^{-1}(f(x))=x$ and this is a fact, so can we assume that $f(x)$ will equal $f^{-1}(x)$ by substitution? Specify if possible if it is never, sometimes, or always true.",['functions']
1344943,diffeomorphism inbetween two subsets of $\mathbb{R}^2$,"Consider the function $$f: \mathbb{R}^2 \to \mathbb{R}^2, \space\space f(x, y) := \pmatrix{x(1-y) \cr x y}$$ Now first, why is $f$ continuously differentiable? Then, I want to prove that $f$ transforms the strip $(0, \infty) \times (0, 1)$ diffeomorph into the quadrant $(0, \infty) \times (0, \infty)$. What I thought: would it already be sufficient for the first statement to determine the Jacobi matrix? Or would I have to do more to show it's indeed continuously differentiable? And in order to be a diffeomorphism, $f$ needs to be bijective on the said domain, and $f$ aswell as $f^{-1}$ need to be continuously differentiable. I don't really know how to show this though.","['analysis', 'multivariable-calculus', 'derivatives']"
1344971,Why is the Householder matrix orthogonal?,"A Householder matrix $H = I - c u u^T$ , where $c$ is a constant and $u$ is a unit vector, always comes out orthogonal and full rank. Why is $H$ orthogonal? I am looking for an intuitive proof rather than a rigorous one. How come it is full rank when $\mbox{rank} \left( u u^T \right) = \mbox{rank} (u) = 1$ ?","['reflection', 'orthogonal-matrices', 'linear-algebra', 'matrices']"
1344978,Convolution with standard mollifier,"Let $\Omega \subset \mathbb{R}$ open and $f \in L^p(\Omega).$ Now, we define $$\eta(x):=\chi_{[-1,1]}(x) e^{\frac{-1}{1-x^2}}.$$ Then we define $$\eta_h(x):=\frac{1}{h} \eta\left( \frac{x}{h}\right).$$ This means that $\mathrm{supp}(\eta_h) \subset [-h,h].$ Now, we clearly have $f * \eta_h \in L^p(\Omega).$ Does anybody know if we have $$||f * \eta_h ||_p \le ||f||$$ and $$||f - f* \eta_h || \rightarrow 0$$ for $h \rightarrow \infty, $ too?","['real-analysis', 'functional-analysis', 'analysis', 'lebesgue-integral', 'partial-differential-equations']"
1344979,finding polynomials to approximate a multivariable function,"Let $U := B_1(0) \subseteq \mathbb{R}^2$, with $B_1(0) := \{(x, y) \in \mathbb{R}^2,\space \|(x, y)\| _1 < 1\}$. Now consider the function: $$g: U \to \mathbb{R}^2, (x, y) \mapsto \frac{1}{1-x-y}$$ For each $n \in \mathbb{N}_0$, I now want to find a polynomial function $p_n$, so that $g(x, y) = p_n(x, y) + o(\|(x, y)\|^n)$ for $(x, y) \to 0$. (Where $o(\cdots)$ is the ""Small O"" Landau symbol.) I must admit that I don't really know how to approach this. What's the technique or formula to determine these polynomials?","['analysis', 'polynomials', 'multivariable-calculus']"
1344984,Integral involving a trig. term,"I came across the following integral.
$$
\int\frac{dx}{1+\sin x}
$$ I have no idea how to solve it! I went for the obvious substitution of $u=1+\sin x$, but then you get an annoying $\cos x$ kicking around. I tried to eliminate this by writing $\cos x=\sqrt{1-(u-1)^2}$, but I couldn't get this idea to work.","['calculus', 'integration']"
1344991,The position of a ladder leaning against a wall and touching a box under it,"I was reading a newspaper and there was a little math riddle, I thought ""how funny, that's gonna be easy, let's do it"" and here am I... The problem goes as follow :
in a barn, there is a 1 meter cubic box against a wall and a 4 meter ladder is leaning against the wall, touching the box at its corner. Here is a picture : So, the big triangle has a hypotenuse $FE$ of $4$, the square $ABDC$ has sides of length 1 and is basically ""insquared"" at the right angle, i.e. $D\in \overline{FE}$.
The question is ""what is the length of the biggest cathetus"", here $AF$. So far, no problem. Now here are my solutions: By Thales' intercept theorem, $\frac{FB}{FA}=\frac{BD}{AE}$, by hypothesis, $FB=FA-1$ and $BD=1$. Now by Pythagoras, $FA^2+AE^2=FE^2$; by hypothesis, $FE=4$, so we end up with a system of equations, letting $h=FA, d=AE$: $$ \begin{align} &\frac{h-1}{h}=\frac{1}{d} \\ &h^2+d^2=4^2  \end{align} $$
Which solves (removing 3 non-relevant solutions) into $d \cong 1.3622$ and $h \cong 3.76091$. Now, if I consider the ""function"" of the line : $f(x)=\frac{-h}{d}x+h$, I know that $f(1)=1$ and I end up with Pythagoras with the system :$$ \begin{align} &\frac{-h}{d}+h=1 \\ &h^2+d^2=4^2  \end{align} $$
it solves again into the same, again removing 3 non-relevant solutions Okay, this means that using Pythagoras is no good since it ends up giving a quartic equation (4 answers of which 3 are ""non-relevant""). Now if I consider the length of the arc $f(x)$ between $0$ and $d$ it has to be $4$ and again $f(1)=1$ I end up with the system:
$$ \begin{align} &\frac{-h}{d}+h=1 \\ &\int_0^d \sqrt{1+(f'(x))^2} dx =\int_0^d \sqrt{1+\left(\frac{-h}{d}\right)^2} dx = d \sqrt{1+\left(\frac{-h}{d}\right)^2}   \end{align} $$
Which solves again into the same answers, but this time removing only 2 non-relevant solutions (i.e. it gives a cubic equation instead of a quartic). I tried also using the areas and the smaller trangles $FAD$ and $AED$ for example : $\frac{h \cdot d}{2} = \frac{h\cdot 1}{2}+\frac{d\cdot 1}{2}$ Yet I wasn't able to get to any ""hand solvable"" solution : if I were able to bring it down to some quadratic equation, that would be nice, since it is a common assumption, here, that everybody has seen the ""general formula for solving quadratic equations"" in school and so would be able to solve this, I may then see how it is seen as a funny riddle in the newspaper. My best trial, with ""just"" a cubic equation, is way too complicated for the normal readers of this newspaper, so it's bugging me. What am I missing? Some basic properties maybe? It's really bugging me, not being able to solve this without Wolfram.","['euclidean-geometry', 'geometry', 'triangles']"
1344996,When can I use the natural log to help solve an integral?,Why is it okay to do this: $\int \frac{1}{x-2}dx = \ln(x-2)$ but not this: $\int \frac{1}{1-x^2}dx   = \ln(1-x^2)$,"['derivatives', 'logarithms', 'calculus', 'integration']"
1344997,Solving for a variable in an inverse function,"I was asked to solve this formula for $R_2$: $$\frac{1}{R} = \frac{1}{R_1} + \frac{1}{R_2} + \frac{1}{R_3}$$ So I did the following: \begin{align*}
\frac{1}{R_2} &= \frac{1}{R} - \frac{1}{R_1}-\frac{1}{R_3} \\[8pt]
 &= \frac{R_1R_3-RR_3-RR_1}{RR_1R_3}
\end{align*}
Then I took the inverse of both sides to get:
$$R_2 = \frac{RR_1R_3}{R_1R_3-RR_3-RR_1}$$ It seems to be correct but I don't know. So is it?","['proof-verification', 'algebra-precalculus']"
1345011,Curl: invariant under change of basis or not?,"I wondered how the curl$$\text{rot}\mathbf{F}=\left( \begin{array}{ccc}\partial_y F_3-\partial_z F_2 \\ \partial_z F_1-\partial_x F_3 \\ \partial_x F_2-\partial_y F_1 \end{array} \right)$$of a vector field $\mathbf{F}=(F_1,F_2,F_3)$ changes when the basis $\mathbb{R}^3$ is changed. I would have thought that it is invariant, because of the intuitive and physical interpretation of the curl and because, if I correctly understand other quantities typical of vector fields, like divergence, are (if I am not wrong $\text{div}\mathbf{F}$ is the trace of the Jacobian matrix $J_{\mathbf{F}}$ of $\mathbf{F}$, and the trace of $E J_{\mathbf{F}} E^{\text{T}}$ - see below - is the same of $J_{\mathbf{F}}$), but I have got serious problem to prove it. Trial : If I am not wrong, if $E\in\text{O}(3)$ is the basis change matrix, and if we define the function $\mathbf{G}$ as $\mathbf{y}\mapsto E\mathbf{F}(^t E \mathbf{y})$, invariancy is equivalent to $$E\text{rot}\mathbf{F}=\text{rot}\mathbf{G}$$please correct me if I am wrong. The Jacobian matrix $J_{\mathbf{G}}(\mathbf{y})$ of $\mathbf{G}$ in $\mathbf{y}$ should be:$$J_{\mathbf{G}}(\mathbf{y})=E J_{\mathbf{F}}(\mathbf{x}) E^{\text{T}}$$where $E^{\text{T}}$ is the transpose, and inverse, matrix of $E$. I have used such an identity to find the expression of $\text{rot}\mathbf{G}(\mathbf{y})$ in terms of the components of $J_{\mathbf{F}}(\mathbf{x})$ and $E$, but my calculations do not give me the expected result: for example, in the first component of the expression of $\text{rot}\mathbf{G}$ calculated in such a way , the coefficient of $\partial_x F_2$ is $(e_{21}e_{32}-e_{22}e_{31})$, while, in the first component of $E\text{rot}\mathbf{F}$, the coefficient of $\partial_x F_2$ is $e_{13}$... Is the curl invariant under a change of orthogonal basis and, if it is, how can it be correctly proved? Thank you so much for any answer!","['multivalued-functions', 'linear-algebra', 'multivariable-calculus']"
1345028,How biased is this biased coin,"Suppose that we have a coin that we suspect is biased, but that we don't know precisely how biased it is: all we know is that its probability p of landing heads is some fixed value between .4 and .6, inclusive. We flip the coin 100 times, and it lands heads 70 times. I'm curious how to find the probability that .4 â‰¤ p â‰¤Â .55. My approach was to find $$\frac{\int_{.4}^{.55}\binom{100}{70}p^{70}(1-p)^{30} dp}{\int_{.4}^{.6}\binom{100}{70}p^{70}(1-p)^{30} dp} â‰ˆ .057$$ but this seems too simplistic. Where am I going wrong? EDIT: Apologies, I meant to say that p is uniformly distributed on [.4, .6], though I'm now curious how we would solve if we knew that p is normally distributed on [.4, .6].",['probability']
1345035,Showing that infinite product of random variables goes to zero: $\prod^\infty X_i \rightarrow 0 \text{ a.s.}$,"I am doing the following exercise: Let $X$ be a strictly positive rv with $\mathbb E[X]=1$ but $X \neq 1$ almost surely. Let $X_1, X_2 \dots$ be iid with same distribution as $X$. Now let $M_0=1$ and 
$$M_n = \prod_{k=1}^{\infty} X_k$$
The task is to show that $M_n \rightarrow 0$ almost surely. Some sub-problems preceding showing this convergence was to show that $\mathbb E[\ln(X)]<0$ and that $\mathbb E[M_n]=1$. That is straightforward. Then one is asked to show the said convergence by considering 
$$
M_n = e^{\sum^n \ln X_k}
$$
So I have tried to reason that in order for $e^{\sum^n \ln X_k} \rightarrow 0$ almost surely, we need $\sum^n \ln X_k \rightarrow -\infty$ almost surely. Here I have some doubts as to how to proceed. I have tried to think in terms of Borel-Cantelli and show this by making an argument along the lines of: for any $N \in (-\infty, 0]$ 
$$
\mathbb P(M_n < N \text{ eventually}) = 1
$$
etc but it seems that this ends up requiring me to know things about the distribution of $M_n$ which I know nothing about (except its mean). Any help highly appreciated.","['probability', 'random-variables']"
1345042,"Can a square be in the form $2x + 1$, when $x$ is odd?","I was given this question, and I think I have solved it, but I'm not sure it is correct because this differs from how the answer is given. What is the most common way to solve this problem? Let's suppose there was a square that could be written as $$2x + 1$$ x being odd. Then: $$2x + 1 = S^2$$ and $$2x = (S + 1)(S - 1)$$ and $$x = \left(\frac{S + 1}{2}\right)(S-1)$$ Now, if $x$ is odd, then $S$ must be odd too. So $S + 1$ is even, therefore $$x = N(S - 1)$$ [with] $N$ being a natural number. And since $S - 1$ is also even, we have $$x = NE.$$ A contradiction, as any number multiplied by even must be even, and $x$ is supposed to be odd.","['number-theory', 'proof-verification', 'square-numbers']"
1345052,$\operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z}$,"I am looking for a group $G$ such that $\operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z}$ . Obviously $\operatorname{Aut}(\Bbb{Z}_n)\ncong \Bbb{Z}/8\Bbb{Z}$ for any $n$ . Also $\operatorname{Aut}(D_4)\cong D_4$ , neither symmetric/alternating groups are of any help here. May be there is no group for which $\operatorname{Aut}(G)\cong \Bbb{Z}/8\Bbb{Z}$ , this also raises a question can any finite/finitely  generated (why not infinite) group can be generated as an automorphism group of some $G$ Update- It is clear now that $G$ has to be abelian, and no finite abelian satisfy it. Also I found a paper from 1957 by H. de Vries and A.B. de Miranda which says $C_8$ does not occur as Aut group of any torsion-free abelian group. So this settles the question.","['automorphism-group', 'abelian-groups', 'abstract-algebra', 'group-theory', 'examples-counterexamples']"
1345063,Map of smooth manifolds,"Let $M$ and $N$ be smooth, connected $n$-dimensional manifolds. Let $M$ be compact and non-empty. Show that every embedding $f: M \to N$ is a diffeomorphism. So because $f$ is a embedding we have that $f(M) \subset N$ is a submanifold and especially that $f: M \to f(M)$ is a diffeomorphism. My idea would be to show that $f(M) = N$ and that's somehow related to $M$ being compact but I don't really know how.","['differential-geometry', 'smooth-manifolds', 'compact-manifolds', 'general-topology']"
1345078,Convergence of $\prod_{n=1}^{\infty}\left(1-\frac{z^2}{n^2}\right)$,"I'm looking at some notes from my previous complex variables course and I need help verifying some things about the convergence of $$
\prod_{n=1}^{\infty}\left(1-\frac{z^2}{n^2}\right)
$$ on compact subsets of $\mathbb{C}$ . My professor shows its convergence by using the property of infinite products which states that $\prod_{n=1}^{\infty}(1-a_n)$ converges if and only if $\sum_{n=1}^{\infty}\log(1-a_n)$ converges, given $a_n\neq 1$ for each $n$ . I have a few issues I would like to work out with this: $\mathbf{\frac{z^2}{n^2}=1}$ when $\mathbf{z=\pm n}$ , which one would think makes the property inapplicable . I believe I have maneuvered around this hurdle because if $z$ belongs to an arbitrary compact subset of $\mathbb{C}$ , then $\frac{z^2}{n^2}=1$ for only finitely many $n$ , there exists an $N\in\mathbb{N}$ such that $\frac{z^2}{n^2}\neq 1$ for all $n\geq
N$ , and it suffices to check convergence of $\sum_{n=N}^{\infty}\log\left(1-\frac{z^2}{n^2}\right)$ . The
only thing that concerns me is that this point wasn't mentioned in
the notes whatsoever. Convergence $\mathbf{\sum_{n=1}^{\infty}\log\left(1-\frac{z^2}{n^2}\right)}$ is shown by noticing $\mathbf{\sum_{n=1}^{\infty}\left|\frac{z^2}{n^2}\right|}$ converges uniformly on compact subsets of $\mathbf{\mathbb{C}}$ (through the Weierstrass M-test, for example). I've thought this through but I don't see it at all. I was thinking
it might be because $\log\left(1-\frac{z^2}{n^2}\right)$ ,
could be thought of as a function of $\frac{z^2}{n^2}$ , but this
cannot hold always since $\sqrt{\frac{1}{n^2}}$ is a function of $\frac{1}{n^2}$ but the sum of these terms clearly does not
converge. Any help on these points is greatly appreciated. Thanks in advance.","['compactness', 'sequences-and-series', 'convergence-divergence', 'complex-analysis', 'infinite-product']"
1345098,For any $n$ positive integers ($n\geq 5$) exactly 3 or 4 of them are equal to each other modulo $2^m$ for some $m$,"How can one prove that for any $n$ distinct positive integers, $n\geq 5$, there exists $m$ such that exactly 3 or 4 of them are equal to each other modulo $2^m$? I tried to prove it for small $n$. For example, for $n=5$ I came up with the following heuristic argument: 3 or 4 or 5 of them are all odd or all even, so we need to exclude the ''5''-case. Assuming they all are, for example, even, we compare them modulo 4, and get the same alternative, and so on. Since we have finite number of the powers of 2, at some point we have to arrive to the desired. But I don't know how to handle the general case. Maybe someone has a better idea?","['number-theory', 'modular-arithmetic']"
1345125,Markov Chains - Strong Markov Property,"I'm struck with an exercise. I tried, but the results don't seem to fit to those proposed. Exercise: Two players play the following game. The one who begins draws two cards from a deck of 40 cards (10 cards per suit): if they are both clubs the player wins; if they are of the same suit but not clubs, the player shuffles the cards and start again; else the player shuffles the cards and let the other player play. 1) Model the game with a Markov Chain. 2) What is the probability that who started wins? My attempt :
If $X_n$ is the player in the current turn, we have a three state MC whose state space is $\{A,\, B,\, \text{exit}\}$. The exit state is the one reached when the game ends.
The transition matrix is $$P=\begin{pmatrix}9/52 & 10/13 & 3/52 \\ 10/13 & 9/52 & 3/52 \\ 0 & 0 & 1 \end{pmatrix}$$ since the probability of staying is $\frac{3 \cdot 9}{4 \cdot 39}$ and so on. For the second question I thought I could use the Strong Markov Property (the one which states that a Markov Chain can start afresh in a Stopping Time) by using the last time I see A (or B) before the game ends. Starting from that point, the probability is just the jump from A (or B) to exit times two (to consider both the A and the B case). What's wrong with this last point?","['probability-theory', 'markov-process', 'probability', 'markov-chains']"
1345134,Group Actions: Verify a Bijective Correspondence,"This is an old exam problem: Given an action of $G$ on $X$, we can define $\varphi: G \to S_X$ by the rule $\varphi(g) = \sigma_g$, where $\sigma_g$ is left multiplication by $g \in G$. Prove that this establishes a bijective correspondence between the set of all actions of $G$ on $X$ and the set of all homomorphisms from $G$ to $S_X$. Is this question simply asking to verify that $\varphi$ is a bijection? If so, I'm at a little of a loss as to how to verify injectivity. Any advice?","['group-theory', 'group-actions']"
1345142,Prove that $2AB$ is square [duplicate],"This question already has answers here : $2AB$ is a perfect square and $A+B$ is not a perfect square (2 answers) Closed 8 years ago . Let $$A= 1! \cdot 2! \cdot 3! \cdots 1002!$$ 
$$B= 1004!\cdot 1005! \cdots 2006!$$ Prove that $2AB$ is square. Help guys, I tried, I really did but I couldn't.","['sequences-and-series', 'number-theory', 'elementary-number-theory']"
1345165,Eigenvalues of Householder matrix,What would be the eigenvalues for a Householder matrix defined as: $H = I - 2 u u^T$? Can someone explain it  to me intuitively or with a simple proof?,"['eigenvalues-eigenvectors', 'linear-algebra', 'matrices']"
1345193,Existence of Partials Imply the Existence of Gradient Vector?,"Let $f$ be a scalar function of three variables. Then the gradient vector is defined by: I read here that the existence of partial derivatives at some point $(x_0, y_0, z_0)$ does not imply the existence of the gradient vector at $(x_0, y_0, z_0)$. How is this possible, since the gradient vector is just a specific type of sum of the partial derivatives?","['partial-derivative', 'terminology', 'multivariable-calculus']"
1345228,Why is the morphism induced by this linear system birational?,"I have seen (what seems to be) the following statement used in a few places, but I am not sure why it is true. Any explanation as to why it is (or is not) true would be appreciated. Let $P$ be a point of an algebraic curve $X$. If $n$ and $n+1$ are both Weierstrass non-gaps at $P$, then the the complete linear system $|(n+1)P|$ is simple, i.e. the map it induces is birational. Since it may be something else that I am not understanding, here are references to what is confusing me: In remark 1.28 on page 15 of this expository paper by Torres, I am confused about the conclusion ""Thus $D = |n_iP|$ is a simple $g_{n_i}^i$ on $X$."" At the top of page 2 of this paper , I am confused about the conclusion ""Thus the linear series $D = |(q+1)P_0|$ is simple.""","['algebraic-geometry', 'algebraic-curves']"
1345231,Calculating the rank of a Boolean matrix and Boolean matrix factorization,"I am interesting in some sort of algorithm for calculating the Boolean rank of small $M \times N$ Boolean matrices. Just to be clear, by Boolean matrices I mean matrices with entries $0$ or $1$ where $1+1=1$, and I am defining the Boolean rank as: Matrix $X$ has $rank(X) = 1$ iff $X = ab^T$ for column vectors $a$ and $b$ Matrix $X$ has $rank(X) â‰¤ k$ if it can be represented as a sum of $k$ rank-1 matrices. Smallest such $k$ is the rank of $X$ For example, $A = \pmatrix{1&1&0\\1&1&1\\0&1&1} = \pmatrix{1\\1\\0}\pmatrix{1&1&0} + \pmatrix{0\\1\\1}\pmatrix{0&1&1} = \pmatrix{1&1&0\\1&1&0\\0&0&0}+\pmatrix{0&0&0\\0&1&1\\0&1&1}$ so $rank(A)=2$ I am also interested in some way to factor an $M \times N$ Boolean matrix with rank $k$ into $M \times k$ and $k \times N$ Boolean matrices. For example, $A = \pmatrix{1&1&0\\1&1&1\\0&1&1} =\pmatrix{1&0\\1&1\\0&1}\pmatrix{1&1&0\\0&1&1}$","['matrix-rank', 'linear-algebra', 'matrices']"
1345244,Abstract definition of a differential operator,"In Natural Operations in Differential Geometry by Kolar, Michor, and Slovak, a differential operator is said to be a rule transforming sections of a fibred manifold $Y \to M$ into sections of another fibred manifold $Y' \to M'$. Is this is a precise definition, or just a hand-wavy characterization? I would have expected that a differential operator would be required to be a sheaf homomorphism between the sheaves of smooth sections of $Y \to M$ and $Y' \to M'$. Is there any reason why KMS do not require a differential operator to be a sheaf homomorphism, but (apparently) just a function between the sets of global sections?","['differential-operators', 'manifolds', 'sheaf-theory', 'analysis', 'differential-geometry']"
1345281,Impact of random numbers on the eigen-values,"How do the eigen-values of the following tridiagonal matrix ($A$) change when adding random numbers $R_i$ (with a normal distribution with the mean 0 and variance $m$) to its diagonal. 
A is a square matrix defined as follows: For i = 1 to N
$$
A(i,i) = -2 + R_i
$$
$$
A(i,i+1) = 1
$$
$$
A(i,i-1) = 1
$$
where m and N are constants. Notice that the eigen-values are known for the case $R_i=0$: for j=1 to N;
$$ Eig(j) = -2 -2 cos(j\pi/N) $$ Numerical solution reveals that the eigen values around the maximum eigenvalue have the largest deviation from the case without random numbers ($R_i=0$). For example, the following figure shows eigen values with and without having the random numbers for m=0.1. But how we can solve the problem analytically? (Maybe by using central limit theorem)","['eigenvalues-eigenvectors', 'random-matrices', 'statistics', 'random-variables']"
1345297,"Do Electrical Engineering Researchers Usually Know Higher Math? e.g. Measure and Distribution Theory, Functional Analysis","I am an EE undergraduate student, and I recently took two courses in signals and systems. We were exposed to things like the Dirac delta (without mention of distributions ), Fourier series (without mention of convergence or function spaces ), the Laplace and Fourier transforms, and the sampling theorem. I still don't truly understand the sifting property, or why sampling is multiplication with a shifted delta instead of a shifted 1 (which would preserve the value of the signal at that point right?). I'm still not sure how to determine when a signal's Fourier series will converge, when you are allowed to take a Fourier or Laplace transform, or whether the derivations of the transform properties we learned are mathematically justified and rigorous. This led me to self study books like Tolstov's Fourier Series and Richards's Theory of Distributions , which I could not follow due to my non-rigorous math background. The Osgood Stanford lectures were quite helpful, but I still feel quite sad that I do not have a deeper understanding of my math tools. According to my school's EE graduate course catalog, there are a couple of classes covering Hilbert, Banach, and L^p spaces, and linear functionals. Is it possible to cover these topics without a formal mathematical background? Should I begin self learning real and complex analysis to prepare for these topics? Forgive me for this lengthy question. Thanks!","['soft-question', 'fourier-analysis', 'distribution-theory', 'functional-analysis', 'advice']"
1345313,Evaluating limit (iterated sine function),"The limit is $$\lim_{x\rightarrow0} \frac{x-\sin_n(x)}{x^3},$$ where $\sin_n(x)$ is the $\sin(x)$ function composed with itself $n$ times: $$\sin_n(x) = \sin(\sin(\dots \sin(x)))$$ For $n=1$ the limit is $\frac{1}{6}$, $n=2$, the limit is $\frac{1}{3}$ and so on. Can we define a recurrent relation upon that given hypothesis? Also, how do I involve $n$ into calculation, because the final limit will depend on it? Any suggestions on how to tackle this? Thank you!","['calculus', 'limits', 'trigonometry']"
1345331,Where do these Mobius transformations map the coordinate half-planes?,"They are $$\frac{z-1}{z+1}, \frac{z+1}{z-1},\frac{z-i}{z+i},\frac{z+i}{z-i}.$$ All four look virtually identical, so I would like to know how to best distinguish between them. For example, the first mapping, I notice that $1$ maps to $0$, $-1$ maps to $\infty$. But since $1$ and $-1$ are symmetric points w.r.t. the imaginary axis, the Mobius transformations always maps symmetric points to symmetric points.  So, the images, $0$ and $\infty$, being symmetric points, must mean that they are symmetric with respect to a circle.  So the real axis gets mapped to some circle centered at the origin. How do I tell how big this circle is?  And since the real axis separates the upper and lower half planes, either the upper or lower plane gets mapped inside the circle, but how can I tell? I tried a sample point:  I see that $i$ gets mapped to $i$, but is this telling me that the mapping is ""fixing"" the UHP?  I doubt it, because it's mapping stuff to some open disk. Edit: Also, with the first mapping, there doesn't seem to be a nice symmetry argument to exploit for the imaginary axis. Thanks.","['mobius-transformation', 'complex-analysis', 'conformal-geometry']"
1345383,Ring homomorphism of tensor product of algebras,"Let $B, C$ be two $A$-algebras, $f:A \to B, g: A\to C$ the corresponding ring homomorphisms. From this we can construct an $A$-algebra $B \otimes _A C$ and the mapping $ a \mapsto f(a) \otimes g(a)$ is the corresponding ring homomorphism $A \to B \otimes _A C$. The above is a summary of a definition on pages 30,31 of Atiyah's Commutative Algebra . I wonder why the mapping $ a \mapsto f(a) \otimes g(a)$ is a ring homomorphism. $$ a+b \mapsto f(a+b) \otimes g(a+b) $$
$$= f(a) \otimes g(a) + f(a) \otimes g(b) + f(b) \otimes g(a)+ f(b) \otimes g(b)$$
To be a ring homomorphism $f(a) \otimes g(b) + f(b) \otimes g(a) $ must be zero. How can I know this?","['algebras', 'abstract-algebra', 'tensor-products']"
1345413,Is there an alternative intuition for solving the probability of having one ace card in every bridge player's hand?,"I am trying to get to know probability a little better since it's a weak point for me and I was wondering what other ways there were to intuitively think about the problem of finding the probability that 4 bridge players each have exactly one ace after being dealt a deck of 52 cards. My solution started with that there are $4!$ ways of distributing the aces initially, and then subsequently there are $48 \choose 12$ ways of distributing the rest of the first hand, $36 \choose 12$ ways of distributing the rest of the second hand, and $24 \choose 12$ ways of distributing the third hand, and one way to distribute the last hand. Thus there are $4! *$ $48 \choose 12$ $*$ $36 \choose 12$ $*$ $24 \choose 12$ ways of the players having exactly one ace. The total sample space, however, is counted for by first giving the first player his hand ($52 \choose 13$), the second player has hand from the remaining deck, ($39 \choose 13$), etc.; so the sample space is $ 52\choose 13$ $*$ $39 \choose 13$ $*$ $26 \choose 13$. The final answer after simplifying is that the probability that each player receives exactly one ace is $\frac{4!48!13^{3}}{52!}$ I think this is correct (correct me if my solution is wrong), but what are the other ways of thinking of this problem?","['probability-theory', 'probability']"
