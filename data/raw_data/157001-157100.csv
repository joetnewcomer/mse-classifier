question_id,title,body,tags
2674981,Prove $\lim\limits_{n\to∞}{\sum\limits_{x=0}^n\binom nx(1+{\rm e}^{-(x+1)})^{n+1}\over\sum\limits_{x=0}^n\binom nx(1+{\rm e}^{-x})^{n + 1}}=\frac 13$,"I am trying to find limit of the following function: 
$$
\lim_{n\rightarrow \infty}\frac{\sum\limits_{x = 0}^{n}\binom{n}{x}\left[1 + \mathrm{e}^{-(x+1)}\right]^{n + 1}}{\sum\limits_{x=0}^{n} \binom{n}{x}\left[1 + \mathrm{e}^{-x}\right]^{n + 1}}.
$$ When I wrote a Python code for this, I saw that it converges to $1/3$. I am not sure how to approach this. Could somebody give a pointer about how to go about it? EDIT: I want just some positive lower bound on this. So even if limit cannot be evaluated exactly, it is okay if I get some lower bound on this.","['binomial-coefficients', 'exponential-function', 'limits']"
2674994,Operator norm and unitary matrix,"I have the following product matrix $XYZ$, with $X,Y,Z$ all $n\times n$ matrices. $X$ and $Z$ are unitary matrices, i.e., they are norm preserving: for every vector $v$, we have $\|Xv \| = \|v\|$. I am trying to prove that $\| XYZ \| = \|Y\|$, with as norm chosen the operator norm. Now I am sure that I can say $\|XYZ v \| = \|YZ v\|$, as the matrix $X$ is norm preserving for every vector (including the vector $YZ v$). But I am not sure if I can say that $\|XYZ v\| = \|XY v\|$. If the latter is also the case, I'm done.","['matrices', 'functional-analysis', 'linear-algebra', 'unitary-matrices']"
2675020,Is there a nice way to write the sum $\sum_{\sum k_i = m} \frac{1}{k_1! k_2! ... k_n!}$?,"Is there any nice way to write $$\sum_{\sum k_i = m} \frac{1}{k_1! k_2!  ...  k_n!}$$ where $m$ and the $k_i$ are positive integers and $n$ is a fixed positive integer? I thought maybe multiplying by $m!$ and trying to get to a binomial sum, but I'm not sure. This comes up in dealing with independent trials from a poisson distribution, namely when working with the statistic which sums the values of the trials.",['combinatorics']
2675052,Optional sampling theorem for bounded stopping time for a right continuous-submartingale,"I was trying to solve Problem 3.23 (b) in Chapter 1 of Karatzas and Shreve
where we need to establish the optional sampling theorem(in the picture below)for a right continuous submartingale and optional time $S\leq T$ under the assumption that $T \leq a$ for some $a>0$ . I tried to adapt the proof in the discrete case but since  we don't have bounded stopping times and the stochastic processes $X$ is not given to be closed by a last element $X_{\infty}$, I cannot apply the theorem. In particular as you can see below theorem 3.22 uses an backward submartingale argument with $X_{S_n}$ being a $\mathcal{F}_{S_n}$ backward martingale(which is due to the fact that in Theorem 3.22 we know that X is closed) Can somebody show me how does boundedness of the stopping time help in establishing the optional sampling theorem in this case? If we use the same approximating sequence of stopping times $S_n$ and $T_n$ as used in Theorem 3.22, we cannot conclude that they are bounded since they approximate $S$ and $T$ from above!","['stochastic-processes', 'martingales', 'probability-theory', 'stochastic-calculus']"
2675070,On an equivalent formulation of the Sauer–Shelah lemma.,"Directly from the Wikipedia entry on the Sauer–Shelah lemma , let $\mathcal {F}=\{S_{1},S_{2},\dots \}$ be a family of sets. The Wiki page states that the following two statements are equivalent: if $\mathcal {F}$ is a family of set with $n$ distinct elements such that $|\mathcal {F}| > \sum_{i=0}^{k-1} \binom{n}{i}$ then $\mathcal {F}$ shatters a set of size $k$. If the VC dimension of $\mathcal {F}$ is $k$, then $\mathcal {F}$ can consist of at most $\sum_{i=0}^k \binom{n}{i}$ sets. Why are these two statements equivalent? It seems to me naively that the directions are opposite.","['machine-learning', 'combinatorics', 'elementary-set-theory']"
2675079,Doubling the cube with unit sticks,"In the January 2000 issue of Erich Friedman's Problem of the Month, the problem of bracing distances – building a rigid unit-distance graph where two vertices are the required distance apart – was considered. The first question there dealt with bracing polygons; it was pointed out that Maehara had proved in 1991 the equivalence of ""braceable distances"" with algebraic numbers. The easier second question dealt with bracing the square roots of integers using as few edges as possible. One of Maehara's gadgets, the fan, allows dividing arbitrary angles into any number of equal parts; this also implies that all regular polygons can be braced. Since $\pi$ is transcendental, squaring the circle is obviously out of the question. Of the three main geometric problems of antiquity, doubling the cube remains; this is the focus of my question here. What is the minimum number of unit edges required to brace $\sqrt[3]2$ ? I had this neusis construction for the constant in the back of my head for a long while: After some experimentation I obtained this variant suitable for implementation in the framework of bracing distances: $\triangle AOB$ has $\angle AOB$ right and $AO=1$ . $C$ lies on the other side of $OB$ from $A$ with $CB=CO=1$ . If $\angle ABC=120^\circ$ , $AB=\sqrt[3]2$ . (This can be easily verified by erecting an equilateral triangle on $BC$ , producing a new point $D$ , then noting that $A,B,D$ are collinear and that $A,O,B,D$ in my diagram correspond to $A,C,G,H$ in the original. The latter's correctness has been verified here .) I need to implement two constraints: $\angle AOB$ being right and $\angle ABC=120^\circ$ . To do so, I turn to one of Maehara's gadgets, the jack : The part of this gadget between $O,A,B,C$ is what he calls the reverser , which forces $\angle COB=\angle BOA$ . $AO$ is extended to $E$ and $OCDE$ is a rhombus; this forces $\angle BOD$ to be right while letting $OD$ vary. By a small modification to this gadget – defining $F$ on $OA$ and $G$ on $OC$ with $OF=OG$ and then erecting a rhombus $OFHG$ – I can also implement collinearity: $H$ must lie on the line defined by $OB$ . Here are the standard and collinear jacks in my bracing of $\sqrt[3]2$ , labelled with the corresponding points in my construction: Note how $\angle ABC=120^\circ$ is enforced by a simple extension of the trusses keeping the jack's bars straight. This reuse of the intermediate points created when realising the gadgets is crucial to minimising the edge count. The whole framework uses 113 edges to brace $\sqrt[3]2$ , highlighted below (SVG file here ): Is this optimal or can it be done better? Can fewer than 113 unit edges be linked into a rigid graph where two points are $\sqrt[3]2$ apart? Ed Pegg , this is your challenge.","['graph-theory', 'recreational-mathematics', 'geometric-construction', 'geometry']"
2675094,Find a pivotal quantity and use it to approximate a 95% confidence interval,"Suppose $Y_1, Y_2, ... , Y_n$ denotes a random sample from a uniform distribution on the interval $(-\theta, 4\theta)$, where $\theta \gt 0$ us an unknown parameter. Assume that n is sufficiently large, find a pivotal quantity in terms of $\overline{Y}$and $\theta$. Use this pivotal quantity to derive a formula of: (i) an approximate 95% confidence interval for $\theta$. (ii) an approximate 95% confidence interval for $\theta^2$. What I have tried so far: (i)
We know that $Y$ ~ $Unif(-\theta, 4\theta)$, so $\mu = 1.5\theta$ and $\sigma^2 = \frac{25\theta^2}{12}$. However, we also know that n is sufficiently large to apply the central limit theorem, so $Y$ ~ $N(1.5\theta, \frac{25\theta^2}{12})$ From that, we can create the pivotal quantity: $$\frac{\overline{Y} - \mu}{\frac{\sigma}{\sqrt{n}}} = \frac{\overline{Y} - 1.5\theta}{\frac{5\theta}{\sqrt{12n}}} $$ So now we can set the problem up as $P(Z_{0.025} \le \frac{(\overline{Y} - 1.5\theta)\sqrt{12n}}{5\theta} \le Z_{0.975})$ After going through the math, I ended up with $P((\frac{-\sqrt{12n}}{9.8} + \frac{2}{3})\overline{Y} \ge \theta \ge (\frac{\sqrt{12n}}{9.8} + \frac{2}{3})\overline{Y})$ as my interval. I'm not really sure if that is correct. It seems a bit messy. (ii)
For this part, I was having difficulty getting started. I'm not really sure how to go about finding a pivotal quantity for $\theta^2$, or if I'm just supposed to use the above pivotal quantity, which wouldn't make sense to me. I know that to be a pivotal quantity, it has to be a function of my random variable Y and my parameter $\theta$. And I also know that the distribution of my pivotal quantity has to be parameter free. But I'm otherwise stuck at this point. Any help or direction would be greatly appreciated.","['statistical-inference', 'probability-distributions', 'statistics', 'probability', 'confidence-interval']"
2675228,"If for any $k$, $\sum\limits_{n=0}^\infty a_n^k=\sum\limits_{n=0}^\infty b_n^k$, then$(a_n)=(b_{σ(n)}),\ σ \in{\mathfrak S}_{\mathbb N}$","Let $(a_n)_{n≥0}$ and $(b_n)_{n≥0}$ be two sequences of a nomed algebra such that $\sum{\| a_n\|}$ and $\sum{\| b_n\|}$ converge, and$ $$$\forall n, \  a_n, b_n \neq 0$$ Show that $(\forall  k \in \mathbb N^*,  \ \sum_{n=0}^{\infty}{a_n}^k = \sum_{n=0}^{\infty}{b_n}^k) \implies \exists\ \sigma \in{\mathfrak S}_{\mathbb N} \ ,\ (a_n) = (b_{\sigma(n)})$ The vector-space should be a finite-dimensional $\mathbb R$-vector-space. I do not see how to deal with the hypothesis. If you have ideas/hints... It would be relevant to deal with complex sequences even if it is less general. But I don't think one can generalize using real and complex cases.","['summation-by-parts', 'sequences-and-series', 'linear-algebra', 'vector-spaces']"
2675292,Elementary periodic point is a finite set in a compact manifold,"Let $f: M \to M$ to be a diffeomorphism where $M$ is a  finite dimensional compact manifold. We say that a fixed point $p$ (i.e., $f(p)=p$) is elementary if $1 \notin sp(Df_{p})$. Suppose that every fixed point of $M$ is a elementary fixed point. Claim: There exists only a finite number of elementary fixed points. I tried to show that the elementary points is discret set, but I am stuck in this. The statement is from Robinson's Dynamical systems. Thanks.","['dynamical-systems', 'differential-geometry', 'analysis']"
2675300,Probability - Statistics expected value [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question A box contains $10$ red balls and $6$ blue balls, every time a ball is taken from the box it gets replaced with the same ball, from another unlimited supply of red and blue balls. What is the expected number of balls you will need to take to have at least $2$ of each colour? (at least $2$ red and at least $2$ blue balls). Any ideas how to tackle this problem? So far i have something along the lines of... Let X be the number of balls taken from the bag until 2 of each colours has been taken. a = red ball, b= blue ball.... P(a) = 10/16, P(b) = 6/16. minimum balls needed to be taken is 4, there are 4C2 different ways of choosing these balls","['statistics', 'probability', 'expectation']"
2675315,Packing $n$-diamonds in a $n$-cube and a number theoretic conjecture?,"Background Recently I was doing some recreational mathematics and stumbled across an interesting observation: What is the maximum number of diamonds (square rotated at $45^o$) can one fit into an $n \times n$ square, where the area of the diamond  is $2$? The picture below illustrates a square of $n=3$ and fits $1$ diamond It shouldn't be hard to convince yourself that this is related to the question of how many numbers are there divisible by $2$  less than $n^2$. Why? Consider labelling each grid point with a number: A diamond is formed whenever one joins the factors of $2$ together! Of course,this is only true when $n$ is an odd number $n>1$. (Also imagine you have the number of diamonds you can fit then with Euler's characteristic formula you can find the number of vertices) Now, we can extend this for a diamonds in a $5 \times 5$ square: Similarly  for a cube we can imagine divide it into smaller cubes and labelling them: $1,2,3,4,\dots$ and join the mid-point of every $2$'nd brick and get a pyramid. which happens to be maximum packing efficiency of the pyramids in a cube. Conjecture ""The packing efficiency always is maximum for a shape created by joining the mid-point vertices in a $n$-dimensional diamond (square for $2$, pyramid for $3$, $4 =$  ?)"" Question Is there a general formula for the shape (note in the pyramid the tip is the centre of the cube rather than the midpoint of the edge)?
Is the conjecture true or false?","['graph-theory', 'packing-problem', 'number-theory', 'geometry', 'discrete-mathematics']"
2675342,Classifying automorphisms using a group presentation.,"I'm new to group presentations and after some playing around with the concept, I've tried to find some relatively clear criteria in terms of the defining relations, that would tell us if a map is an automorphism. I would appreciate any input - whether my approach is correct, and whether there's some other more general or neater way. Let $X=\{x_1,\dots ,x_n \}$ be a finite set and let $R$ be some finite set of relations on the alphabet of $X \cup X^{-1}$ . Denote $G$ the group corresponding to these defining relations - $G= \langle X \mid R \rangle =F_X / N$ , and presume $G$ is finite. I think the following might be true: Consider a map $f:X \rightarrow G$ . If $\langle f(x_1),\dots ,f(x_n) \rangle = G$ and $f(x_i)$ satisfy the corresponding relations when stated in terms of $x_i$ , then $f$ induces an automorphism. Proof: If we show that $f$ induces homomorphism $\overline{f}$ , it's surjective and hence an automorphism, so we only need to show that $f$ actually induces a homomorphism. Consider the free group $F$ on $X$ , and define $g:F \rightarrow G$ by $w \mapsto f(w_1)f(w_2)\dots f(w_m)$ . We know that $f(x_i)$ satisfy the wanted relations, and so the $N \subseteq \ker (g)$ . By the homomorphism theorem there exists a $\psi$ , such that $\psi \circ \pi_N = g$ . This $\psi$ is the wanted extension of $f$ . In some sense this seems excessive - we're dealing with finite groups. An idea of how to deal with this in finite groups: Presume that any element in $G$ can be expressed as a word in $X$ of length at most $k$ . Define a map $g$ from words of length $2k$ to $G$ induced by $f$ . If we check that for any two words of length $2k$ that represent the same element in $G$ , that their image is the same, we will be done. I know that none of this is very formal, but I would mostly like to know whether my approach is sensible. I would also appreciate if someone linked some text that deals with this in a more formal way.","['finite-groups', 'group-presentation', 'group-isomorphism', 'group-theory', 'solution-verification']"
2675369,Checking if a functional $F(x)$ is a norm in $\mathbb{R}^2$,"There is a functional given:
$$F(x) = \sqrt{2x_1^2 + 3x_2^2}$$
Of course $x\in\mathbb{R}^2 \rightarrow x = (x_1, x_2)$ It is easy to check that: 1) $\forall x \in \mathbb{R}^2$ $F(x) \ge 0$ 2) $F(x) = 0 \iff x = 0$ 3) $ F(\lambda x) = | \lambda | F(x)$ I failed however to show that $F(x+y) \le F(x) + F(y)$. How should it be proven?","['functional-analysis', 'normed-spaces']"
2675382,Calculating integer partitions,"A partition of a positive integer $n$, also called an integer partition, is a way of writing $n$ as a sum of positive integers. The number of partitions of $n$ is given by the partition function $p(n)$ Partition (number theory) . For example, $p(4) = 5$. Now, what is $p(100)$? a) $10^2$ b) $2^{10}$ c) $10^{10}$ d) ${(10 !)}^{2}$ I can't compute $p(100)$ .","['number-theory', 'combinatorics', 'integer-partitions']"
2675389,Find integral of composition of functions,"I have very interesting problem I've been trying to solve for last two days. Here it exactly is: $$\int_0^{\frac\pi2} \log(\cos(x))dx$$ I have already tried integration by parts, chain rule. It made no sense at all. I know (from reliable source) that the function has no indefinite integral but has definite one. Thank you for helping","['integration', 'definite-integrals', 'function-and-relation-composition']"
2675397,"Evaluate $ \int_{0}^{\pi/2} \frac{\sin(nx)}{\sin(x)}\,dx $ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question For every $odd$ $n \geq  1$ the answer should be $\pi/2$ For every $even$ $n \geq  2$ the possible answers are : $A )$ $ 1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots + (-1)^{n/2+1}\frac{1}{n-1} $ $B )$ $ 3(1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots + (-1)^{n/2+1}\frac{1}{n-1} )$ $C )$ $ 2(1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots + (-1)^{n/2+1}\frac{1}{n-1} )$ $D )$ $ \frac{1}{2}(1-\frac{1}{3}+\frac{1}{5}-\frac{1}{7}+\cdots + (-1)^{n+1}\frac{1}{n-1} )$ $E )$ $ 1-\frac{1}{3}-\frac{1}{5}-\frac{1}{7}-\cdots - \frac{1}{n-1} $ Does the recurrence $ (n-1)(I_{n}-I_{n-2})=2sin(n-1)x $ help?","['integration', 'trigonometry', 'calculus']"
2675441,When does the inequality change in probability problems and why does it?,"From what I've learned in my stats class when you have $P(X \gt x)$ you make it $P(X \gt x) = 1-P(X \le x)$. I think I understand that you have to do this inequality change because you can't calculate a probability of any possible number being greater than $x$, but I don't understand why greater than changes to less than or equal to. Why is this the case? Also, does it work that way in reverse? Is $P(X \ge x)=1-P(X \lt x)$?","['statistics', 'probability']"
2675460,"Prove that for a given point on an ellipse, the sum of the distances from each focal point is constant","An ellipse has equation $\frac{x^2}{25}+\frac{y^2}{9} = 1$ and $P(p,q)$ is a point on the ellipse. Points $F_1$ and $F_2$ have coordinates $(-4,0)$ and $(4,0)$. Show that the sum of the distances $|PF_1|$ +$|PF_2|$ does not depend on the value of p. First, to find  distance $|F_1P|$ $|F_1P| = \sqrt{(p+4)^2 + q^2}$ as $\frac{p^2}{25}+\frac{q^2}{9} = 1$ $\frac{9p^2}{25}+q^2 = 9$ $q^2 = 9-\frac{9p^2}{25}$ $|F_1P| = \sqrt{p^2+8p+16 + 9-\frac{9p^2}{25}}$ $= \sqrt{\frac{16}{25}p^2+8p-25}$ $= \sqrt{\frac{1}{25}(16p^2+200p-625)}$ $= \frac{1}{5}\sqrt{(4p+25)^2}$ $= \frac{1}{5}(4p+25)$ Finding the distance $|F_2P|$ $|F_2P| = \sqrt{(4-p)^2 + q^2}$ $= \sqrt{p^2-8p+16 + 9-\frac{9p^2}{25}}$ $= \sqrt{\frac{16}{25}p^2-8p-25}$ $= \sqrt{\frac{1}{25}(16p^2-200p-625)}$ $= \frac{1}{5}\sqrt{(4p-25)^2}$ $= \frac{1}{5}(4p-25)$ Therefore $|F_1P|+|F_2P|= \frac{1}{5}(4p-25)+\frac{1}{5}(4p+25) = \frac{8}{5}p$ This is exactly what we're trying to disprove. I must have made a mistake somewhere. Please can someone explain where I went wrong. My answer appears to be the negative of what it should be. I expect the correct answer will be 10 units but for some reason it does not seem to work.","['analytic-geometry', 'algebra-precalculus', 'euclidean-geometry', 'geometry', 'conic-sections']"
2675503,"If $A+B+C = 180^{\circ}$, then show that: $\sin A = \sin B \cos C + \cos B \sin C$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Here is the question : If $A+B+C = 180^{\circ}$, then show that: $\sin A = \sin B \cos C + \cos B \sin C$. I don't really have any clue where to start. The only thing I would think to do would be to change $\sin A = \sin B\cos C + \cos C\sin B$ to $\sin (B+C) = \sin B\cos C + \cos C\sin B$. But I'm not sure if that is even useful. Any suggestions appreciated. EDIT : Here is my working, can someone comment and confirm that this working is correct. We want to show that
  $$
\sin A=\sin (B+C).
$$ Since 
$$
\space A+B+C = 180^\circ, \space A =180^\circ-(B+C)
$$
And 
$$
\space \sin A=\sin (180-A),
$$
then
$$
\sin A=\sin(180-(180-(B+C))
$$
$$
\sin A=\sin(180-180+(B+C))
$$
so
$$
\sin A=\sin(B+C).
$$",['trigonometry']
2675539,Proving $\phi (n_k) \ll \frac{n_k}{\log \log n_k}.$,"Show that there is an increasing sequence of positive integers $n_1, n_2, \cdots$ such that $$\phi (n_k) \ll \frac{n_k}{\log \log n_k}.$$ I was able to prove that $\phi (n) \gg \frac{n}{\log \log n}$ (the proof is a bit lengthy, so I will not post it unless requested), but I am unsure how to show this result for an increasing sequence of positive integers. Notation: $f(x) \ll g(x)$ if $|f(x)|\leq Mg(x)$.",['number-theory']
2675543,Is the probability of getting the mail today vs tomorrow independent from the day?,"I need some help seeing if I understand independence and conditional probability. Let's say I'm expecting a package. It's priority mail so I know at most it will take $3$ days to come. The probability of getting it in the first day $\Pr(A)$ is $0.\overline{33}$. The probability of getting it the second day given it didn't arrive the day before $\Pr(B \mid \neg A)$ is $0.50$ (right?). And the probability of getting it in the $3$rd day given not day $1$ or day $2$ $\Pr(C \mid \neg A \wedge \neg B)$ is $1$ (right?). So if my logic is correct so far, if I investigate independence, I will find: $\Pr(B \mid \neg A)$ is $0.5$ and $\Pr(B)$ is $0.\overline{33}$; therefore, the events are not independent. Same applies for the third day. In English, not getting a package in a particular day influences the probability of getting it in the other two days by improving the odds, which intuitively makes sense. Or am I off the mark?","['independence', 'probability']"
2675546,"Show that only finitely many positive integers $n$ have the property that for all $m$ for which $1<m<n$ and $\text{gcd}(m,n) = 1$, $m$ is prime.","Show that only finitely many positive integers $n$ have the property that for all $m$ for which $1<m<n$ and $\text{gcd}(m,n) = 1$, $m$ is prime. I am able to show that a positive integer with the specified property is prime, but I do not know how to prove that there are ""finitely many"" of them. EDIT: Adding a proof of the mentioned claim that ""a positive integer with the specified property is prime."" If $m$ is prime $m$ has no factors but $1$ and $m$. So gcd$(m,n)$ can only equal 1 or $m$.  If gcd$(m,n) = m$ then $m|n$.  So $n \ge m$. If $n < m$ then gcd$(m,n)=1$. Conversely, if gcd$(m,n)=1$ for all $n < m$, then no number less than $m$ divides $m$ (other than $1$).  Since no number larger than $m$ divides $m$, $m$ has no divisors except itself and $1$. So $m$ is prime.",['number-theory']
2675553,How to show that $Y\cup_{f} X$ is normal when $X$ and $Y$ are normal and $f:A\to Y$ is a continuous map with $A$ closed in $X$?,"I found this problem in Bredon's Topology and Geometry. My try: Let $\pi: X\coprod Y\to Y\cup_{f}X$ be the quotient map and let $C$ and $D$ be two disjoint closed sets in $Y\cup_{f}X$. Then we write $\pi^{-1}(C)=C_{1}\coprod C_{2}$ and $\pi^{-1}(D)=D_{1}\coprod D_{2}$ where $C_{1}$ and $D_{1}$ are closed in $X$ and $C_{2}$ and $D_{2}$ are closed in $Y$. Then $C_{1}\cap D_{1}=\emptyset$ and $C_{2}\cap D_{2}=\emptyset$. Now, normality of $X$ gives us disjoint open sets $U_{1}$ and $V_{1}$ separating  $C_{1}$ and $D_{1}$, and normality of $X$ gives us disjoint open sets $U_{2}$ and $V_{2}$ separating  $C_{2}$ and $D_{2}$. Now $\pi(U_{1}\coprod U_{2})$ and $\pi(V_{1}\coprod V_{2})$ would not be disjoint open sets in $Y\cup_{f} X$ if and only if there is a fiber $f^{-1}(y)$ of $f$ that intersects both $U_{1}$ and $V_{1}$. Now we can't just subtract the problematic fibers from both $U_{1}$ and $V_{1}$ as there might be infinitely many and union of infinitely many closed sets need not be closed. This is where I am stuck. Please help.","['general-topology', 'quotient-spaces']"
2675571,"Holomorph of a group $G$, then the automorphism of $G$ are inner automorphisms","In my course notes of algebra it says: Let $G$ be a group. Then $\mathrm{Aut}(G)$ acts on $G$ in a natural way through automorphisms. This allows us to consider $A:= G \rtimes \mathrm{Aut}(G)$. In this group every automorphism of $G$ is an inner automorphism. This group is called the holomorph of $G$. I don't understand the statement concerning the inner automorphisms. The first part means $G\rtimes \mathrm{Aut}(G)$ being a group with group operation
$$
 (g,\theta) \cdot (h,\psi) = (gh^{\theta^{-1}}, \theta \psi)
$$
right? And an automorphism $\phi$ on a group $G$ is an inner automorphism if $g^\phi = h^{-1}gh$ for a certain $h\in G$. I would think the last statement means something like: For any $\phi\in \mathrm{Aut}(G)$
$$
 (g,\theta)^\phi = (h,\psi)^{-1} (g,\theta) (h,\psi) \qquad \text{for a certain } (h,\psi) \in A 
$$ But this doesn't make any sense, since $(g,\theta)^\phi$ is not even defined. Can someone help me make sense of this last statement?","['automorphism-group', 'abstract-algebra', 'group-theory', 'holomorph', 'semidirect-product']"
2675578,"If $A+B+C=180^{\circ}$, then show that: $\cos B=\sin A\sin C-\cos A\cos C$","Here is the question : If $A+B+C = 180^{\circ}$, then show that: $\cos B = \sin A \sin C - \cos A \cos C$. EDIT : Here is my reviewed working : $$
\cos B=-\cos (A+C)
$$ Since $$\space A+B+C = 180^\circ, \space B =180^\circ-(A+C)$$ And 
$$\begin{align}
-\cos B &=\cos (180+B) \\
-\cos B &=\cos(180+(180-(A+C)) \\
-\cos B &=\cos(360-(A+C)) \\
-\cos B &=\cos(A+C) \\
-\cos B &=\cos A \cos C - \sin A \sin C \\
\cos B &= \sin A \sin C - \cos A \cos C \\
\cos B &= -\cos (A+C)
\end{align}$$ Can someone confirm that my working is correct? Thanks!",['trigonometry']
2675579,"Find an unbiased estimator for $\alpha$, $\alpha^2$, and $\alpha^3$","$Y_1, Y_2,...,Y_n$ is a random sample drawn from Gamma($\alpha$, 2) (a) Find an unbiased estimator of 7 - 2$\alpha$. Verify your answer. Then find the mean square error of the estimator. Your estimator should depend on all data points. (b) Find an unbiased estimator of $\alpha^2$. Your estimator should depend on all data points. Verify your answer. (c)  Find an unbiased estimator of $\alpha^3$. Your estimator should depend on all data points. Verify your answer. What I have tried so far: First I calculated $E(Y_i) = \alpha\beta = 2\alpha$, $V(Y_i) = \alpha\beta^2 = 4\alpha$ Also following from that, $E(\overline{Y}) = 2\alpha$, and $V(\overline{Y}) = \frac{4\alpha}{n}$ (a) Since the estimator should depend on all data points, I used $\overline{Y}$. I used $E(7 - \overline{Y}) = E(Y) - E(\overline{Y}) = 7 - 2\alpha$ Since this estimator is unbiased, the MSE should be equal to just variance. So I got MSE = $V(7 - \overline{Y}) = V(\overline{Y}) = \frac{4\alpha}{n}$ (b) For this, I started with $E(\overline{Y}^2)$, which I tried to derive a formula, but I'm not sure I did this part correctly. I did this: $$E(\overline{Y}^2) = E[(\frac{1}{n}\sum_{i=0}^nY_i)^2] = \frac{1}{n^2}E[(\sum_{i=0}^nY_i)^2] = \frac{1}{n^2}\sum\sum_{i \ne j}E(Y_iY_j) = \frac{1}{n^2}[\sum_{i=0}^nE(Y_i^2) + \sum\sum_{i \ne j}E(Y_iY_j)]$$ From here, I used the identity $E(X^2) = V(X) + E(X)^2$, independence, and summation manipulation to arrive at: $$\frac{1}{n^2}[n(4\alpha + 4\alpha^2) + (n^2 -n)4\alpha^2]$$ After some simplification, I got  all of this equal to $4\alpha^2 + \frac{4\alpha}{n}$ Since this is biased with respect to $\alpha^2$, I adjusted my estimator to get $E(\frac{\overline{Y}^2}{4} - \frac{\overline{Y}}{2n})$ to get $\alpha^2$, which is unbiased. I'm not sure this part is correct, but it seemed to make sense. (c) This is where I ran into problems. I'm not sure how to approach this one. I tried looking in my text for some definitions and examples to help me, but I have no idea how to start. Any help would be greatly appreciated.","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
2675581,derivative of determinant of $I + tA$ when $t=0$,"Let us say that $A$ is a real $n \times n$ matrix and $I$ is the identity matrix (also $n \times n$). $t$ is any old real number. I'm entirely aware that there is no simple formula for $\det(I + tA)$, but I hope I can find $\frac{d}{dt}(\det (I + tA))|_{t=0}$. I just can't see how that can be done? I need it in order to move on with this bigger problem I'm addressing. It's probably simple and I'm just not seeing it, could I please get some hints?","['derivatives', 'differential-geometry', 'vector-analysis', 'determinant']"
2675583,Deduce Poisson's integral formula from the mean value theorem,"This question is from the book Complex Analysis by Stein: Let $u$ be a harmonic function in the unit disc that is continuous on it closure. Then, deduce Poisson's integral formula: $$u(z_{0}) = \frac{1}{2\pi}\int_{0}^{2\pi}\frac{1-\left\lvert z_{0}\right\rvert^{2}}{\left\lvert e^{i\theta}-z_{0}\right\rvert^{2}}\,u\!\left(e^{i\theta}\right)d\theta$$ for $\left\lvert z_{0}\right\rvert<1$ . Show that if $z_{0}=re^{i\phi}$ then, $$\frac{1-\left\lvert z_{0}\right\rvert^{2}}{\left\lvert e^{i\theta}-z_{0}\right\rvert^{2}}=\frac{1-r^{2}}{1-2r\cos(\theta -\phi)+r^{2}}$$ I have read some proofs posted here and they directly proved the general result, which is really good, such as the proof here: Deriving the Poisson Integral Formula from the Cauchy Integral Formula I understand those expert proofs, but the question in the book gives a hint which confuses me a lot. The hint: Set $u_{0}(z)=u(T(z))$ , where $T(z)=\frac{z_{0}-z}{1-\bar{z_{0}}z}$ . Prove that $u_{0}(z)$ is harmonic, the apply the mean value theorem to $u_{0}$ and make a change of variables in the integral. I am stuck in the first step, I don't really know how to show $u_{0}(z)$ is harmonic, since it is hard for me to calculate the Laplace. Is there any way out to do this question following the hint? Any explanations are really really appreciated!!! Edit 1: Okay. Thanks to the answer, I figured out how to prove $u_{0}(z)$ is harmonic, and then I proceed to next part. Now, since $u_{0}(z)$ is harmonic in the unit disc, we apply Mean-Value property for Harmonic function to $u_{0}(z)$ at $z_{0}=0$ . $u_{0}(0)=u\circ T(0)=u(z_{0})=\frac{1}{2\pi}\int_{0}^{2\pi}u_{0}(re^{i\theta})d\theta=\frac{1}{2\pi}\int_{0}^{2\pi}u\circ T(re^{i\theta})d\theta=\frac{1}{2\pi}\int_{0}^{2\pi}u(\frac{z_{0}-re^{i\theta}}{1-\bar{z_{0}}re^{i\theta}})d\theta$ , for all $0<r<1$ And I don't know how to do next. How can I get all other terms out of $u$ only learning $u(e^{i\theta})$ ? Also, why in the Poisson's integral formula, $r=1$ ? or I have to take limit $r\rightarrow 1^{-}$ ?","['complex-analysis', 'harmonic-analysis']"
2675600,"Intuition behind Lebesgue spaces: Lp, L^p, $\mathcal L^p$ or $L^p$ / $\ell^p$?","I'm trying to learn some maths on my own, and this is a reach, but I'm hoping for a reader's digest explanation. I have an idea of the need for a measure to be defined on sets, yet the definition of Lebesgue spaces on Wikipedia (if related at all) starts off with sequences and functions. Does it have anything to do, for instance with $\sigma$-algebras? Is it a solution to a problem at the crossroads of probability and topology? Where is it framed within the branches of mathematics? And what are the meanings of $\mathcal L^p$ and $\ell^p$ (the answers here being too advanced)?","['banach-spaces', 'functional-analysis', 'lp-spaces', 'measure-theory', 'general-topology']"
2675604,"If $P$ is a polynomial with $|P(1)| = \max\limits_{|z| =1} |P(z)|$, then its root on the unit circle is separated away from 0","Let $P(z)$ be a nonzero polynomial of degree $n$ such that $$|P(1)| = \max\limits_{|z| =1} |P(z)|.$$
Furthermore let $z_0 = e^{i\varphi_0}$, $\varphi_0 \in [-\pi,\pi]$ be a root of $P$ on the unit circle. I want to prove that $|\varphi_0| \geq \pi /n$. Also, by my intuition, if this becomes an equality, $P(z)$ would be a multiple of $1+z^n$. Does anyone has an idea?","['complex-analysis', 'polynomials']"
2675605,Expected number of operations on a vector until one of the coordinates becomes zero.,"Let's say we have a vector $v = (x_1, ..., x_n) \in \mathbb{N}^n$ where $x_1 = x_2 = ... = x_n$. Next we choose an ordered pair of coordinates at random $(i, j)$ where $i, j \in \{1, ..., n\}$ and $i \neq j$. Finally we substitute the vector $v$ with a new vector $v' = (x_1, ..., x_i + 1, ..., x_j - 1, ..., x_n)$. Now we choose again an ordered pair of coordinates at random and substitute the vector $v'$ with a new vector doing the same we did for $v$. We continue doing this until one of the coordinates becomes zero. What is the expected number of operations we are going to make? I know the answer for $n = 2$ because you can model this process with a random walk. If $v = (x, x)$, then the expected number of operations is the same as the expected number of steps it will take to hit $x$ or $-x$ doing a random walk starting at zero. In this case the expected number of step starting at $y$ satisfies the recurrence relation
$$E_y = 1 + \frac{1}{2} E_{y - 1} + 
\frac{1}{2} E_{y + 1}. $$
Then one can solve this linear recurrence. I tried to do the same for the original problem but the recurrence relation is more difficult. Let $F_{(x_1, ..., x_n)}$ be the expected number of operations one can make to vector $v= (x_1, ..., x_n)$ before one of the coordinates becomes zero (in this case we allow $x_1, ..., x_n$ to be different). If I'm not wrong $F$ satisfies the following relation
$$F_{(x_1, ..., x_n)} = 1 + \sum_{i, j} \frac{1}{n (n - 1)} F_{(x_1, ..., x_n) + e_{i, j}}, $$ where the $i$-th coordiante of $e_{i, j}$ is $1$, the $j$-th is $-1$ and the rest are all zero (the sum runs through all possible operations).",['probability']
2675651,Is there a sequence of unbounded closed intervals such that its intersection is empty? [duplicate],"This question already has an answer here : Intersection of a family of non-empty closed intervals (1 answer) Closed 6 years ago . Is there a sequence of unbounded closed intervals $J_1\supseteq J_2 \supseteq J_3 \supseteq \cdots$ such that $\bigcap _{n=1} ^{\infty} J_n = \emptyset$. By an unbounded closed interval I mean an interval of the form $[a,\infty) = \{x \in \mathbb{R} \mid x \ge a\}$. My answer to the question is yes taking the sequence $[1,\infty),[2,\infty),[3,  \infty), ...$ because suppose $b \in  \bigcap _{n=1} ^{\infty} J_n$. Then there exists an interval in the sequence such the $b\lt a_i$ whereby $b \notin [a_i, \infty) $ hence $b $ cannot be in $\bigcap _{n=1} ^{\infty} J_n$. Therefore the intersection is empty. Is my answer correct and if so is my reasoning correct? If not can you please provide the correct justification for the correct answer. Thanks in advance!","['real-analysis', 'sequences-and-series', 'elementary-set-theory']"
2675733,Prove that $\sum\limits_{k=1}^{n}\frac{|z_{k}|^2}{|z_{k+1}-z_{k}|^2}\ge 1$ for complex numbers $z_k$'s,"Let $n \geq 3$ . Let $z_{i}$ (for $i=1,2,\cdots,n$ ) be complex numbers. Assume that $z_{k+1} - z_k \ne 0$ for $k=1,2, \cdots, n-1$ and $z_n  - z_1 \ne 0$ . Show that $$\sum_{k=1}^{n}\dfrac{|z_{k}|^2}{|z_{k+1}-z_{k}|^2}\ge 1\tag{1},$$ where $z_{n+1}=z_{1}$ . I think can use the Cauchy-Schwarz inequality to solve it. But I think this complex inequality can't hold: $$\left(\sum_{k=1}^{n}|z_{k}|\right)^2\ge \sum_{k=1}^{n}|z_{k+1}-z_{k}|^2.$$ So how do I prove $(1)$ ?","['real-analysis', 'inequality']"
2675734,Derivative in the direction of u+v is equal to the sum of the derivative in the direction of u and the derivative in the direction of v,"I am trying to prove that $D_{u+v}f(a)=D_{u}f(a)+D_{v}f(a)$, where $a \in \mathbb{R}^n$ for any two
  vectors $u,v$ in $\mathbb{R}^n$. I try to use the definition and so forth but I could not prove it. I need to prove this only by using the definition, which is $$D_{v}f(a)=\lim_{t \to 0} \frac{f(a+tv)-f(a)}{t}$$.","['multivariable-calculus', 'calculus', 'derivatives']"
2675827,To show two formal power series equal,"I am wondering whether the following two formal power series are equal:
$A(x)=\Pi_{k=1}^{\infty}\frac{1}{1-x^{2k-1}}$, $B(x)=\Pi_{k=1}^{\infty}(1+x^k)$.","['abstract-algebra', 'combinatorics', 'formal-power-series', 'algebraic-combinatorics', 'discrete-mathematics']"
2675856,Does there exist a side-rational triangle of area $1$?,"A side-rational triangle stands for a triangle with each side rational. We know, by cosine theorem and computing the area of the triangle, we can get that each angle of the triangle is of rational $\sin$ and $\cos$. Then consider ant height of one side, we have 
$$S=h(h\cot \alpha+h\cot \beta)/2$$
Then it suffices to show that 
$$t-\frac{1}{t}+T-\frac{1}{T}\notin \mathbb{Q}^2\quad t,T\in \mathbb{Q}$$
But i am stuck on it.","['number-theory', 'triangles']"
2675866,Is the negative power of a matrix defined?,"I had a matrices exam last week and I wrote $A^{-2}$ to refer to $(A^{-1})^2$ (A being an invertible matrix). Initially, I was given the question wrong, but I told the professor that I saw in a book that $(A^{-1})^n = A^{-n} = (A^n)^{-1}$ and gave me the point. He said that $A^{-n}$ isn't defined for matrices, which I may believe since I haven't seen it in this forum yet, but I would find having to write $(A^{-1})^n$ or $(A^n)^{-1}$ very annoying just for the fact that it isn't defined. So, is it (defined)? P.D.: The book is Linear Algebra by Paul Dawkins 1 .","['matrices', 'inverse']"
2675877,To find the probability whether $X$ is rational,"Let $X$ be a random variable with the moment generating function $$𝑀_𝑋(𝑡) =\frac{6}{\pi^2}\sum_{n\geq 1}\frac{e^{\frac{t^2}{2n}}}{n^2}$$ Then $𝑃(X\in \mathbb{Q})$ , where  is the set of rational numbers, equals $(A) \space\space 0\space\space\space\space\space\space (B) \space\space \frac{1}{4}\space\space\space\space\space\space  (C)\space\space \frac{1}{2}\space\space\space\space\space\space (D) \space\space \frac{3}{4}\space\space\space\space\space\space $ I was thinking whether I can replace this sum by an integral , because I can't think of a distribution whose mgf looks like this.
Please Help!","['probability-theory', 'probability', 'probability-distributions']"
2675882,Question about the proof of the diamond isomorphism theorem on modular lattice,"A lattice $(L, \le)$ is a modular lattice @ wiki if the following modular law holds:
$$\forall x \in L: a \le b \implies a \lor (x \land b) = (a \lor x) \land b.$$ The diamond isomorphism theorem @ wiki on modular lattice says that For any two elements $a,b$ of a modular lattice, one can consider the intervals $[a \land b, b]$ and $[a, a \lor b]$. They are connected by order-preserving maps
  $$\varphi: [a \land b, b] \to [a, a \lor b],
\psi: [a, a \lor b] \to [a \land b, b]$$
  that are defined by $\varphi(x) = x \lor a$ and $\psi(y) = y \land b$.
  Then, $\varphi$ and $\psi$ are both isomorphisms between $[a \land b, b]$ and $[a, a \lor b].$ I tried to prove this theorem by first showing that $\varphi$ preserves the operations $\land$ and $\lor$ as follows: $$
\forall x_1, x_2 \in [a \land b, b]: \\
\varphi(x_1 \land x_2) = (x_1 \land x_2) \lor a\\
\varphi(x_1) \land \varphi(x_2) = (x_1 \lor a) \land (x_2 \lor a) = (a \lor x_1) \land (x_2 \lor a) =_{\text{modular law}} a \lor (x_1 \land (x_2 \lor a))
$$ What is the next to show that $\varphi(x_1 \land x_2) = \varphi(x_1) \land \varphi(x_2)$? Edit 1: Note that $a \lor (x_1 \land (x_2 \lor a)) \ge a \lor (x_1 \land x_2)$. How to show the other direction? (Maybe this relies on the fact that $\varphi$ and $\psi$ are bijections.) Edit 2: The bijection $\varphi$ is a lattice isomorphism can also be verified by showing that $\varphi$ is order-preserving , which is quite easy. A theorem connecting the order-theoretic definition and the algebraic definition of lattice isomorphism may be helpful to show that $\varphi(x_1 \land x_2) = \varphi(x_1) \land \varphi(x_2)$. Any ideas?","['abstract-algebra', 'lattice-orders', 'order-theory', 'discrete-mathematics']"
2675933,Commutant of two bounded linear operators,"Let $E$ be an infinite-dimensional complex Hilbert space and $A,B\in  \mathcal{L}(E)$. Why it is impossible to find $c\in \mathbb{C}^*$ such that $[A,B]=cI$?",['functional-analysis']
2675951,Factorize $\det\left[\begin{smallmatrix}yz-x^2&zx-y^2&xy-z^2\\zx-y^2&xy-z^2&yz-x^2\\xy-z^2&yz-x^2&zx-y^2\end{smallmatrix}\right]$ using factor theorem,"Factorize and prove that $$
\Delta=\begin{vmatrix}
yz-x^2&zx-y^2&xy-z^2\\
zx-y^2&xy-z^2&yz-x^2\\
xy-z^2&yz-x^2&zx-y^2
\end{vmatrix}\\=\frac{1}{4}(x+y+z)^2\Big[(x-y)^2+(y-z)^2+(z-x)^2\Big]^2
$$
  using factor theorem. My Attempt: $\Delta$ is a homogeneous symmetric polynomial of degree $6$. When $(x-y)^2+(y-z)^2+(z-x)^2=0$, i.e. $x=y=z$
$$
\Delta=\begin{vmatrix}
0&0&0\\
0&0&0\\
0&0&0\\
\end{vmatrix}=0
$$
Thus, $(x-y)^2+(y-z)^2+(z-x)^2$ is a factor. How do I extract the other $(x-y)^2+(y-z)^2+(z-x)^2$ from $\Delta$ $\color{red}{?}$ Does this have anything to do with all rows (or columns) being zero when $(x-y)^2+(y-z)^2+(z-x)^2=0$ $\color{red}{?}$ If I can extract that then i think I know how to proceed. The remaining factor must be a homogeneous quadratic symmetric polynomial, i.e. $p(x,y,z)=a(x^2+y^2+z^2)+b(xy+yz+zx)$
$$
\Delta(x,y,z)=\Big[(x-y)^2+(y-z)^2+(z-x)^2\Big]^2.a(x^2+y^2+z^2)+b(xy+yz+zx)
$$
$$
\Delta(1,0,0)=\begin{vmatrix}
-1&0&0\\
0&0&-1\\
0&-1&0\\
\end{vmatrix}=1=4.a\implies a=\frac{1}{4}
$$
$$
\Delta(1,1,0)=\begin{vmatrix}
-1&-1&1\\
-1&1&-1\\
1&-1&-1\\
\end{vmatrix}=\begin{vmatrix}
0&0&1\\
-2&0&-1\\
0&-2&-1\\
\end{vmatrix}\\
=\begin{vmatrix}
-2&0\\
0&-2\\
\end{vmatrix}=4=4.(2a+b)=4(1/2+b)=2+4b\\
\implies b=\frac{1}{2}
$$
$$
\Delta(x,y,z)=\Big[(x-y)^2+(y-z)^2+(z-x)^2\Big]^2.\frac{1}{4}(x^2+y^2+z^2)+\frac{1}{2}(xy+yz+zx)\\
=\frac{1}{4}\Big[(x-y)^2+(y-z)^2+(z-x)^2\Big]^2.(x^2+y^2+z^2+2xy+2yz+2zx)\\
=\frac{1}{4}\Big[(x-y)^2+(y-z)^2+(z-x)^2\Big]^2(x+y+z)^2
$$ Note: I am trying to factorize the determinant using factor theorem given the fact that the determinant is a homogeneous symmetric polynomial of degree 6.","['matrices', 'polynomials', 'symmetric-polynomials', 'determinant']"
2675968,"Prove that $\int_{2017}^{2018} (\arctan(\ln(x))-\ln(\arctan(x)))\,\mathrm dx>0$","I want to prove that
$$\int_{2017}^{2018} (\arctan(\ln(x))-\ln(\arctan(x)))\,\mathrm{d}x > 0.
$$ Here is my idea so far: By the fundamental theorem of calculus, the above mentioned function $$f(x) = \arctan(\ln(x))-\ln(\arctan(x))$$ is a continuous function at $[2017,2018]$ , therefore there exists a function $F(x)$ such that $F'(x)=f(x)$, therefore it is enough to prove that $$F(2018)-F(2017)>0$$ My idea was proving that $F(x)$ is an increasing function at $[2017,2018]$ by showing that $f(x)$ has positive values at $[2017,2018]$, but I always end up with complicated equations. My aim is to prove that without using a calculator at all… Help much appreciated!","['definite-integrals', 'trigonometry', 'calculus']"
2675971,Picard group of an elliptic complex curve,"I've followed a course about complex tori and  complex elliptic curves. At the end of the course we introduced the $Pic_0$ group and showed it is isomorphic to the cubic seen as a group. I understood what we are doing formally, but i can't manage to grasp what we are really doing. The fact that the picard zero group was isomorphic to the elliptic curve really surprised me,but I 'm still confused about what it should suggest to me. What does it ""measure"" the $Pic_0$ of a curve? Why we introduce divisors?(Let me explain : for example for me De Rham cohomology measures the failure of a certain differential condition to better understand some geometrical aspects of manifold. Is there a similar way of thinking for the Picard group?)","['cubics', 'elliptic-curves', 'complex-geometry', 'algebraic-geometry']"
2676008,a periodic sequence,Let $w$ be a primitive $2m$th root of unity. Then the sequence generated by $$x_{n+2}=\frac{w^4x_n-(w^3+w^2)x_{n+1}-wx_nx_{n+1}}{-w-(w^3+1)x_n+w^2x_{n+1}}$$ appears to have period $2m$ for almost all initial terms. I can prove this for (very) small $m$ and check it numerically for other values of $m$. I should be grateful for any ideas regarding a general proof.,"['recurrence-relations', 'sequences-and-series', 'complex-numbers']"
2676023,Proof of cotangent rule in a triangle,"I was reading a textbook and found the following identity for the triangle given in the picture: $$(m+n)\cot(θ)= m\cot(a)-n\cot(b)$$
I tried to prove it using sine and cosine on the triangles but didn't get an expression that seemed to simplify. How should one prove this rule?","['trigonometry', 'triangles', 'geometry']"
2676048,Arnolds geometric formulation of the implicit function theorem,"I have trouble understanding why Arnold's geometric formulation of the implicit function theorem is equivalent to the usual one . In his book ""Ordinary Differential Equations"", Vladimir Arnold gives the following variant of the implicit function theorem (p. 92 of the third edition): Implicit function theorem: In some neighborhood of a nondegenerate point any two smooth mappings (of spaces of fixed dimension $m$ and $n$) are equivalent. He calls a smooth mapping $f:\mathbb{R}^m\to\mathbb{R}^n$ nondegenerate in the origin if its derivative has maximal rank there (i.e. the rank equals the minimum of $m$ and $n$). He supposes that $f(0)=0$ and calls two such mappings $f$ and $g$ equivalent in the origin if there exist diffeomorphisms $h:\mathbb{R}^m\to\mathbb{R}^m$ and $k:\mathbb{R}^n\to\mathbb{R}^n$ in the domain and target space that leave the origin fixed and such that $f\circ h = k\circ g$. Local equivalence is thus given if the two functions can be written by the same formulas if suitable local coordinates systems are used in the domain an target space. Arnold writes The reader accustomed to more complicated statements of the implicit function theorem will easily verify that these more complicated statements are equivalent to the simple geometric statement above. In spite of being advertized as an easy exercise, I have not succeeded in proving either that the usual formulation implies Arnold's formulation nor the other way around.","['implicit-function-theorem', 'differential-geometry']"
2676058,Skeptical about an Elementry point concerning polynomials of linear operators,"Consider the following scenario. We have a linear operator $p(T) = c_0I+c_1T+c_2T^2+\cdot\cdot\cdot+c_mT^m$ over the finite dimensional vector space 
$V$ such that $p(T)v = 0$ for some non-zero $v\in V$. Now lets say that we are able to factorize the aforementioned polynomial to yield $p(T) = \beta(T-\lambda_1I)(T-\lambda_2I)\cdot\cdot\cdot(T-\lambda_mI)$ where $\beta\neq 0$ consequently $\beta(T-\lambda_1I)(T-\lambda_2I)\cdot\cdot\cdot(T-\lambda_mI)v = 0$ does this then imply that $(T-
\lambda_jI)v = 0$ for at least one $j\in\{1,2,....,n\}$ and if not why not? I know this is an elementrary point but i seem to be having some trouble understanding it?","['eigenvalues-eigenvectors', 'polynomials', 'linear-algebra']"
2676080,Proving conditions for angles in two triangles with one equal angle,"If in triangles $ABC$ and $DEF$, we have $\angle BAC = \angle EDF$ and $AB:DE = BC:EF$. Then prove that either $\angle ACB + \angle DFE = 180^\circ$ or $\angle ACB = \angle DFE$. My attempt: If $\angle ABC = \angle DEF$  then the two triangles are similar and hence $\angle ACB = \angle DFE$. If $\angle ABC \neq \angle DEF$ then let $\angle ABC > \angle DEF$. We have, $$\angle ACB + \angle DFE = \angle ACB + (\angle ACB + \angle ABC - \angle DEF)$$ $$= 180^\circ - \angle BAC + \angle ACB - \angle DEF$$
So it all boils down to proving that $\angle ACB = \angle BAC + \angle DEF$. How do I do that? This is a diagram of the second case","['angle', 'triangles', 'proof-verification', 'geometry']"
2676128,Probability problem: $60$ workers in an industry,"Let's say there is an industry that employs $60$ workers, among these $60$ workers, $57$ are honest and the other $3$ are spies of another industry. Let's say that the industry starts a new project, so $4$ workers from the $60$ are randomly chosen (without replacement). We guess that the project will leak if among those $4$ workers selected, there is at least $1$ spy. i) What's the probability of choosing all $3$ spies? ii) What's the probability of project not to leak? iii) Taking as a fact that the project leaked, what's the probability of that all 3 spies are chosen? What I have achieved so far: i) There are $\binom{60}{4}$ ways to chose $4$ workers from $60$ . Chosing all the spies mean that the team created has $3$ spies and $1$ honest worker. So there are $\binom {3}{3}$ ways to chose $3$ spies and $\binom {57}{1}$ to choose $1$ honest worker. Let $A$ be the probability of chosing all spies, the answer is : $$P(A) = \frac{\binom {3}{3}\cdot\binom{57}{1}}{\binom {60}{4}}.$$ ii) If we want the project not to leak, we need to create a team with $4$ honest workers and $0$ spies. So, there are $\binom {57}{4}$ ways to chose $4$ workers from $57$ honest ones. Let $B$ be the probability of project not to leak, the answer is: $$P(B) = \frac{\binom {3}{0}\cdot\binom{57}{4}}{\binom {60}{4}}.$$ iii) Here we have conditional probability and we need to find $$P(A \mid B') = \dfrac{P(A\cap B')}{B'}.$$ Now I am not really sure what to do exactly. Any hint would be valueable.","['combinatorics', 'probability']"
2676167,How to find integration with Unknown,"I am given the following problem which I have problem to know where to even start: The question: $\lim_{x\to 0}
\frac{\int_0^x\frac{t^2}{\sqrt{a+2t^5}}dt}
{bx-esinx}=\frac{1}{\pi}$ The part where I will like to know where to start: 
$\int_0^x\frac{t^2}{\sqrt{a+2t^5}}dt$ I appreciate suggestions on how I may get about solving the integration part before I move on to solve the limit question as a whole.","['integration', 'limits']"
2676190,Prove that $\begin{vmatrix} xa&yb&zc\\ yc&za&xb\\ zb&xc&ya\\ \end{vmatrix}=xyz\begin{vmatrix} a&b&c\\ c&a&b\\ b&c&a\\ \end{vmatrix}$ if $x+y+z=0$,"If $x+y+z=0$, then prove that
  $$
\begin{vmatrix}
xa&yb&zc\\
yc&za&xb\\
zb&xc&ya\\
\end{vmatrix}=xyz\begin{vmatrix}
a&b&c\\
c&a&b\\
b&c&a\\
\end{vmatrix}
$$ I can do it by Sarrus' law but how can I prove it by matrix operations without actually expanding the determinant ? My Attempt $$
\begin{vmatrix}
xa&yb&zc\\
yc&za&xb\\
zb&xc&ya\\
\end{vmatrix}=xyz\begin{vmatrix}
a&\frac{yb}{x}&\frac{zc}{x}\\
c&\frac{za}{y}&\frac{xb}{y}\\
b&\frac{xc}{z}&\frac{ya}{z}\\
\end{vmatrix}=xyz\begin{vmatrix}
a&-b-\frac{zb}{x}&-c-\frac{yc}{x}\\
c&-a-\frac{xa}{y}&-b-\frac{zb}{y}\\
b&-c-\frac{yc}{z}&-a-\frac{xa}{z}\\
\end{vmatrix}=xyz\begin{vmatrix}
a&b+\frac{zb}{x}&c+\frac{yc}{x}\\
c&a+\frac{xa}{y}&b+\frac{zb}{y}\\
b&c+\frac{yc}{z}&a+\frac{xa}{z}\\
\end{vmatrix}=xyz\begin{vmatrix}
a&b&c+\frac{yc}{x}\\
c&a&b+\frac{zb}{y}\\
b&c&a+\frac{xa}{z}\\
\end{vmatrix}+xyz\begin{vmatrix}
a&\frac{zb}{x}&c+\frac{yc}{x}\\
c&\frac{xa}{y}&b+\frac{zb}{y}\\
b&\frac{yc}{z}&a+\frac{xa}{z}\\
\end{vmatrix}\\
=xyz\bigg(\begin{vmatrix}
a&b&c\\
c&a&b\\
b&c&a\\
\end{vmatrix}+\begin{vmatrix}
a&b&\frac{yc}{x}\\
c&a&\frac{zb}{y}\\
b&c&\frac{xa}{z}\\
\end{vmatrix}+\begin{vmatrix}
a&\frac{zb}{x}&c\\
c&\frac{xa}{y}&b\\
b&\frac{yc}{z}&a\\
\end{vmatrix}+\begin{vmatrix}
a&\frac{zb}{x}&\frac{yc}{x}\\
c&\frac{xa}{y}&\frac{zb}{y}\\
b&\frac{yc}{z}&\frac{xa}{z}\\
\end{vmatrix}\bigg)\\
$$
I need to prove that the sum of last three terms is zero.
$$
\begin{vmatrix}
a&b&\frac{yc}{x}\\
c&a&\frac{zb}{y}\\
b&c&\frac{xa}{z}\\
\end{vmatrix}+\begin{vmatrix}
a&\frac{zb}{x}&c\\
c&\frac{xa}{y}&b\\
b&\frac{yc}{z}&a\\
\end{vmatrix}+\begin{vmatrix}
a&\frac{zb}{x}&\frac{yc}{x}\\
c&\frac{xa}{y}&\frac{zb}{y}\\
b&\frac{yc}{z}&\frac{xa}{z}\\
\end{vmatrix}=\begin{vmatrix}
a&b&\frac{yc}{x}\\
c&a&\frac{zb}{y}\\
b&c&\frac{xa}{z}\\
\end{vmatrix}+\begin{vmatrix}
a&\frac{zb}{x}&\frac{-zc}{x}\\
c&\frac{xa}{y}&\frac{-xb}{y}\\
b&\frac{yc}{z}&\frac{-ya}{z}\\
\end{vmatrix}\\
$$ Solution by expansion $$
\Delta=\begin{matrix}
xa&yb&zc&xa&yb\\
yc&za&xb&yc&za\\
zb&xc&ya&zb&xc\\
\end{matrix}=xyz(a^3+b^3+c^3)-abc(x^3+y^3+z^3)
$$
We have $x^3+y^3+z^3-3xyz=(x+y+z)(x^2+y^2+z^2-xy-yz-zx)=0$ as $x+y+z=0$. Thus, $x^3+y^3+z^3=3xyz$
$$
\Delta=xyz(a^3+b^3+c^3)-abc(3xyz)=xyz(a^3+b^3+c^3-3abc)\\
=xyz\bigg[ a\big(a^2-bc\big)-b\big(ac-b^2\big)+c\big(c^2-ab\big) \bigg]\\
=xyz.\bigg[a\begin{vmatrix}
a&b\\
c&a\\
\end{vmatrix}-b\begin{vmatrix}
c&b\\
b&a\\
\end{vmatrix}+c\begin{vmatrix}
c&a\\
b&c\\
\end{vmatrix}\bigg]
=xyz\begin{vmatrix}
a&b&c\\
c&a&b\\
b&c&a\\
\end{vmatrix}
$$","['matrices', 'linear-algebra', 'determinant']"
2676233,How to show $|\sin(2x)-\sin(2a)|$ is bounded by $2|\sin(x-a)|$?,"I came across a problem in section 3.4 on uniform continuity in Wade's 4th ed Introduction to Analysis. The exercise is just to apply the definition of uniform continuity to $f(x)=x\sin(2x)$ on $x\in(0,1)$. The function is clearly uniformly continuous, which I don't have any problem showing. But I wanted to check on a step from the solution manual where there is an interesting global bound given: $|\sin(2x)-\sin(2a)|\leq 2|\sin(x-a)|$. It is not stated as a global bound, but it seems to be one. I am able to derive it as a bound on $(0,1)$, but my sequence of steps seems too complicated for a basic undergrad advanced calc exercise. My questions: Is this a well-known bound that most undergrads should have encountered? What is the quickest way to derive the bound, both globally and on $(0,1)$? Here is my method for $(0,1)$. Assume $x,a\in(0,1)$ and $x>a$. $$\begin{aligned}
|x\sin(2x)-a\sin(2a)|
&\leq|x\sin(2x)-x\sin(2a)| \qquad &\text{ (since $x>a$) }\\
&\leq|\sin(2x)-\sin(2a)| \qquad &\text{ (since $0<x<1$) }\\
&=|2\sin(x)\cos(x)-2\sin(a)\cos(a)| \qquad &\text{ (double angle identity) }\\
&\leq2|\sin(x)\cos(x)-\sin(a)\cos(x)| \qquad &\text{ ($x>a$ & $\cos$ decr.) }\\
&\leq2|\sin(x)\cos(a)-\sin(a)\cos(x)| \qquad &\text{ ($x>a$ & $\cos$ decr.) }\\
&=2|\sin(x-a)| \qquad &\text{ (angle difference identity) }\\
\end{aligned}$$ This argument uses the fact that $x,a\in(0,1)$ when I use the fact that $\cos(x)$ is decreasing on that interval and allows us to swap $\cos(x)$ and $\cos(a)$ in lines 4 and 5 in the above equation. Is there a quicker way to get from line 2 to line 6? It will need to be elementary, something that an undergrad in a very basic intro to analysis course might know. I suppose it could be the case that a sufficiently complicated argument is required and this just happens to be one of the harder problems.","['real-analysis', 'trigonometry']"
2676265,Diffusion equation if f and φ are periodic the solution is also periodic,"If I have the diffusion equation $$ \frac{\partial u}{\partial t}-D \frac{\partial^{2}u}{\partial x^{2}}=f(x,t) $$ with the initial condition $$u(x, 0) = φ(x).$$ How would I prove that if $f$ and $φ$ are p-periodic in $x$, that is for some $p > 0$ the identities f(x+p, t) = f(x, t)
and $φ(x + p)$ = $φ(x)$ hold for all x and t, then the solution is also p-periodic in x, i.e.
$$u(x + p, t) = u(x, t)$$","['periodic-functions', 'ordinary-differential-equations', 'partial-differential-equations']"
2676278,"Evaluate $\iint_D2x-2y \ dx \, dy$ using polar coordinates.","Evaluate $$\int_\gamma y^2\,dx+x^2\,dy,$$ where $\gamma:(x-a)^2+(y-b)^2=r^2$ , running one revolution
counterclockwise. I have that $(P,Q)=(y^2,x^2)$ and $\frac{\partial Q}{\partial x}=2x$ , $\frac{\partial P}{\partial y}=2y.$ By Greens theorem I have $$\int_\gamma P\,dx+Q\,dy=\iint_D\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y}\right) \ dx\,dy=\iint_D(2x-2y) \ dx \, dy.$$ Polar coordinates: $$\left\{
  \begin{array}{rcr}
    x & = & R\cos{\theta}+a \\
    y & = & R\sin{\theta}+b\\
  \end{array}
\right.\implies E:\left\{
  \begin{array}{rcr}
    0 \leq R \leq r \\
    0 \leq \theta \leq 2\pi
  \end{array}
\right.$$ So my integral is $$2\iint_Dx-y \ dx\,dy=\int_0^{2\pi}\int_0^r R(\cos\theta-\sin\theta) + a-b =4\pi r(a-b).$$ The correct answer is $2\pi r^2(a-b),$ I'm off by a factor of $\dfrac r2$ . Can't find the error.","['multivariable-calculus', 'solution-verification']"
2676285,Musical and combinatorial proof,"How many distinct rhythms can a musical measure have? Obviously the answer is not ""$\infty$"", so to answer this question we set a minimum rhythm  $\frac{1}{4}$. We will consider both notes and rests and not consider irregular groups like triplets and others. So we'll consider notes and rests as $\frac{1}{4 }$, $\frac{2}{4}$, $\frac{3}{4 }$ ...
As regards musical measure we'll consider $\frac{L}{4}$ where $L$ is the length of measure and consider only $L>0$.
Then calculate the number of combinations of rhythms in a measure: So the sequence found is: $1,2,5,13,34,...$ and this is a possible relation with Fibonacci's bisection:
$$ F(0)=1 $$
$$ F(1)=2 $$
$$F(L)= 3 \cdot F(L-1) - F(L-2); \quad L>1$$
How is it possible to proof that this recurrence relation is valid for each $L>1$? IMPORTANT EDIT: Sorry i have forgotten to write that we consider rhythms from the acoustic view point, so we consider for example that two rests of $\frac{1}{4}$ acoustically equal to a rest of $\frac{2}{4}$ and so we will consider only the rest of $\frac{2}{4}$. Furthermore rhythms of arbitrary duration are allowed, for example we can have a note of $\frac{5}{4}$ with a invented symbol.","['combinatorics', 'fibonacci-numbers', 'music-theory']"
2676359,Generating samples within a sphere according to a specified distribution,"Let's consider a ball in $\mathbb{R}^n$ centered at some point $x$ with radius $r$. I am interested in generating samples (random points) within this ball. It is well known that, according to sources such as link , using Gaussian random variables and normalizing them produces random points that are uniformly distributed within a sphere. Now let's say I want to generate random points within this ball according to a specified distribution. Are there general procedures for doing this? Or, are there other known specific approaches that produce specific distributions within the ball?","['reference-request', 'probability-distributions', 'statistics', 'geometry', 'random-variables']"
2676364,How to evaluate the sum of infinite series numerically? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question As mentioned in document, Mathematica can evaluate Riemann Zeta function to arbitrary numerical precision. I see related posts which takes advantage of the property of Zeta function. But for a converged general series without closed form, how do we evaluate it numerically? Do we have to sum many terms one by one. When should we stop? How do we know the result reaches given precision? And the sum of all remaining terms won't affect the result? If the sum of the series converges very slowly, the computation would be very expensive. ==== UPDATE Since this post is on hold, I know that there is no general way to evaluate the sum of infinite series. Many thanks to your replies. They give me a good start point for further study.","['numerical-methods', 'summation', 'sequences-and-series']"
2676436,Uniform Convergence on open subset,"I have a sequence of continuous functions $f_{n}:[0,1]\rightarrow\mathbb{R}$ that converge pointwise to $0$ on $[0,1]$. I have to prove that given $\epsilon>0$ I can find a non-empty interval $(a,b)\subset [0,1]$ and N such that: $|f_{n}(t)|<\epsilon$ for all $t\in(a,b)$ and $n\geq N$. My attempt: I look at $E_{N}=\{x\in[0,1]:|f_{n}(t)|<\epsilon, \forall n\geq N\}$. Then $E_{N} \subset E_{N+1}$. Forthermore, as $f_{n}$ converges pointwise to $0$, we have that for any $x$ in $[0,1]$ there exists some $n$ such that $x \in E_{n}$. 
So we must have that $\cup_{N=0}^{\infty} E_{N}=[0,1]$. I don't know how to conclude that there exists such an $(a,b)$.","['uniform-convergence', 'analysis']"
2676451,why do we use the hyperbolic functions? [duplicate],"This question already has answers here : Real world uses of hyperbolic trigonometric functions (10 answers) Closed 6 years ago . The first time I knew about the hyperbolic function was when I was studying the derivatives.
And I know that the derivative of 
 $\sinh x=  ( e^x - e^{-x} )/ 2$ , but i still confused with what are they really are? and how did we get them and for what we are using them? Thanks very much, and i hope that wasn't a long question.","['derivatives', 'calculus']"
2676464,How could I go about proving this summation of a rising factorial?,"$$\sum_{r=1}^{n}r(r+1)(r+2)...(r+p-1) = \frac{1}{p+1}n(n+1)(n+2)...(n+p)$$ So I get how to do this with limited terms, like r(r+1) just ends up with some summations of r, r^2 and onward, but how could I prove this generalization? I tried doing something with induction, but I got lost on how would the p increment for the n+1 case.","['combinatorics', 'summation', 'induction', 'discrete-mathematics']"
2676518,"Let $f : Q\to \mathbb{R}$ be bounded. Then $f$ is integrable over $Q$ if and only if given $\epsilon> 0$, there is a $\delta> 0$ such that","Prove the following: Theorem. Let $f : Q\to \mathbb{R}$ be bounded. Then $f$ is integrable over $Q$ if and only if given $\epsilon> 0$, there is a $\delta> 0$ such that $U(f, P) -L(f, P) <\epsilon$ for every partition $P$ of mesh less than $\delta$. Proof. (a) Verify the ""if"" part of the theorem. (b) Suppose $|f(x)| < M$ for $x\in Q$. Let $P$ be a partition of $Q$. Show
that if $P""$ is obtained by adjoining a single point to the partition of
one of the component intervals of $Q$, then $$0\leq L(f, P"") - L(f, P)\leq 2M(\text{mesh} P) (\text{width} Q)^{n-1}$$ Derive a similar result for upper sums. (c) Prove the ""only if"" part of tbe theorem: Suppose $f$ is integrable
over $Q$. Given $\epsilon> 0$, choose a partition $P'$ such that $U(f, P')- ­
L(f, P') < \epsilon/2$. Let $N$ be the number of partition points in $P'$; then
let $$\delta= \epsilon/8M N (\text{width} Q)^{n-1}$$ Show that if $P$ has mesh less than $\delta$, then $U(f, P) - L(f, P) <\epsilon$ . [Hint: The common refinement of $P$ and $P'$ is obtained by adjoining
at most $N$ points to $P$.] (a) if $\epsilon>0$ then there is a $\delta>0$ such that $U(f,P)-L(f,P)<\epsilon$ for any partition of norm smaller than $\delta$, if $P$ a partition of norm smaller than $\delta$, then $U(f,P)-L(f,P)<\epsilon$ and thus $f$ is integrable. (b) I know that if $P''$ is a partition finer than $P$ then we have to $L(f,P)\leq L(f,P'')$, with which $0\leq L(f,P'')-L(f,P)$. I am entangled in testing the other inequality, I know that $L(f,P'')-L(f,P)=\sum_{R\subset P''}m_R(f)v(R)-\sum_{R\subset P}m_R(f)v(R)$, but I do not know how to limit that, could someone help me please? (c) I do not know how to prove this, could someone give me a help or do a test? Thank you very much.","['real-analysis', 'calculus', 'multivariable-calculus', 'integration', 'vector-analysis']"
2676557,Prove that T is diagonalizable if and only if the minimal polynomial of T has no repeated roots.,"Prove that T is diagonalizable if and only if the minimal polynomial of T has no repeated roots. EDIT: ( Over $\Bbb C $ ) though it is obvious i am working over $\Bbb C $ as one of my statements is not true over $ \Bbb R $ I would like a better proof of this result what i did is below, there is the same question on here somewhere but only has an answer to one direction im looking for both. I proved the result by using a different equivalent statement to diagonalizable looking for any complete proof that is shorter. We notice that it is equivalent to prove that V has a basis consisting of eigenvectors of T iff the minimal polynomial of T has no repeated roots by theorem. $(\Rightarrow ) $ First suppose that there is a basis $\beta = (v_1,\cdots , v_n ) $ consisting of eigenvectors of T. let $\lambda_1 , \cdots , \lambda_m $ be distinct eigenvalues of T. Then for each $ v_i $ there exists a $\lambda_k $ with $(T- \lambda_k I) v_i =0 $ it then follows that $(T- \lambda_1 I) \cdots (T- \lambda_mI) v_i =0 $ for each i as we can commute the operators. Since an operator that sends each vector in a basis to the $0$ vector is the $0$ operator we have that $(T- \lambda_1 I) \cdots (T- \lambda_mI) =0 $ Thus the polynomial $(z-\lambda_1) \cdots (z-\lambda_m ) $ when applied to T gives 0. but by theorem we know that that the minimal polynomial of T is a divisor of $(z-\lambda_1) \cdots (z-\lambda_m ) $ which has no repeated roots so the minimal polynomial cannot possibly have repeated roots the result follows. $(\Leftarrow ) $ Let us assume that the minimal polynomial has no repeated roots; if we let $ \lambda_1 \cdots \lambda_m $ denote the distinct eigenvalues of T, this means the minimal polynomial of T is $(z-\lambda_1) \cdots (z-\lambda_m ) $ It follows that $(T- \lambda_1 I) \cdots (T- \lambda_mI) =0 $ Let $U_m $ be the subspace of a generalized eigenvectors corresponding to the eigenvalue $\lambda_m $. Since $ U_m $ is invariant under T by theorem we consider $ v\in U_m $ let $u= (T- \lambda_m I) v $ it follows that $u\in U_m $  Hence $$ (T|_{U_m} - \lambda_1 I ) \cdots (T|_{U_m} - \lambda_{m-1}I) u =   (T- \lambda_1 I) \cdots (T- \lambda_mI) v =0 $$ by theorem we have that $( T- \lambda_m I )|_{U_m} $ is nilpotent by previous question we have that 0 is the only eigenvalue of $( T- \lambda_m I )|_{U_m} $. Thus $T|_{U_m} - \lambda_jI $ is an invertable operator on $U_m $ for $j= 1, \cdots , m-1 $ it then follows by $$ (T|_{U_m} - \lambda_1 I ) \cdots (T|_{U_m} - \lambda_{m-1}I) u =   (T- \lambda_1 I) \cdots (T- \lambda_mI) v =0 $$ that $u=0$ in other words, $v$ is an eigenvector of T! We have shown that every generalized eigenvector of T corresponding to the eigenvalue $\lambda_m $ is an eigenvector of T. However we choose $ \lambda_m $ arbitrarily we could of just of easily relabeled the eigenvalues so that any of them was called $ \lambda_m $. Therefore we have that every generalized eigenvector of T is actually an eigenvector of T. By theorem we have that there is a basis for V consisting of generalized eigenvectors of T but by above we have that there is a basis of V consisting of eigenvectors of T the desired result.",['linear-algebra']
2676579,"Solve the reccurence relation $a_n = 3a_{n-1}+4_{n-2}, a_0=a_1 = 1$","This is my first time working through this type of problem and I am looking to see if I have worked it out correctly, thanks! Solve the reccurence relation $$a_n = 3a_{n-1}+4a_{n-2}, a_0=a_1 = 1$$ First we get the characteristic equation: $$x^n = 3x^{n-1}+4x^{n-2}$$ Dividing by the smallest we get, $$x^2=3x+4$$
$$x^2-3x-4 = 0 $$
$$x = 4,-1$$ Using the auxiliary equation we get the general solution: $$a_n = A_1x^{n+1} + A_2x^{n+1}$$ Using conditions in the equation and our solution for $x$ gives, $$a_0 = 1 = A_1(4) + A_2(-1) = 4A_1 - A_2$$
$$a_1 = 1 = A_1(4)^2 + A_2(-1)^2 = 16A_1 + A_2$$ Solving for $A_1, A_2$ I got $A_1 = \frac{1}{10}, A_2 = -\frac{3}{5}$ Therefore plugging into the general solution I got, $$a_n =\left(\frac{1}{10}\right)(4)^{n+1}+\left(-\frac{3}{5}\right)(-1)^{n+1}$$ Did my workings come out correct?","['combinatorics', 'recurrence-relations', 'discrete-mathematics']"
2676620,Mean return time Markov Chain,"A Markov chain has states $0,1,2$ with transition probabilities $$P=\begin{pmatrix} 0.8 & 0.1 & 0.1 \\ 0.3 & 0.5 & 0.2 \\ 0.2 & 0.4 & 0.4 \end{pmatrix}.$$ I struggle to calculate the mean return time to state 1 given that we start at state 1. Define $T=\min{\{n\geq1 :X_n=1\}}$ and $g_i=E(T|X_0=i)$ . I seek $g_1$ . By total probability and Markov property $$g_i=\sum_{j\in {1,2,3}}E(T|X_0=i,X_1=j)P(X_0=i,X_1=j))) =\sum_{j\in {1,2,3}} E(T+1|X_0=j)P(X_0=i,X_1=j))=\sum_{j\in {1,2,3}}g_ip_{ij}+1$$ So I get the system of equations \begin{cases}
g_0 = 0.8g_0+0.1g_1+0.1g_2+1 \\
g_1 = 0.3g_0+0.5g_1+0.2g_2+1 \\
g_2 = 0.2g_0+0.4g_1+0.4g_2+1 \\
\end{cases} which has no solution. What is wrong with my equations?","['stochastic-processes', 'markov-chains', 'probability']"
2676623,"Let $f : Q\to \mathbb{R}$ be bounded. Then the statement that $f$ is integrable over $Q$, with $\int_{Q}f = A$, is equivalent to the statement","Theorem. Let $f : Q\to \mathbb{R}$ be bounded. Then the statement that $f$
is integrable over $Q$, with $\int_{Q}f = A$, is equivalent to the statement
that given $\epsilon>0$, there is a $\delta>0$ such that if $P$ is any partition of mesh less than $\delta$, and if, for each subrectangle $R$ determined by $P$,
$x_R$ is a point of $R$, then
$|\sum_{R}f(x_R)v(R) - A|<\epsilon$. The exercise of which I am doing one is the following: Let $f : Q\to \mathbb{R}$ be bounded. Then $f$ is integrable over $Q$ if and only if given $\epsilon> 0$, there is a $\delta> 0$ such that that still has no answer and I would like to know how to demonstrate that too. Suppose that $f$ is integrable with $\int_{Q}f$, then by the exercise, given $\epsilon>0$ there exists a $\delta>0$ such that if $P$ is a partition with a norm smaller than $\delta$, we have that $U(f,P)-L(f,P)<\epsilon$. Let $x_R\in R$ then we have the following inequalities $\sum_{R}f(x_R)v(R)\leq U(f,P)$ and $A\geq L(f,P)$ and so $\sum_{R}f(x_R)v(R)-A\leq U(f,P)-L(f,P)<\epsilon$, but I do not know how to prove this so I can keep the absolute value. Could anyone help me, please? For the other direction, suppose the second part of the theorem, then we will have that $U(f,P)-L(f,P)\leq |U(f,P)-L(f,P)|\leq |U(f,P)-A|+|L(f,P)-A|<2\epsilon$ and thus $f$ is integrable.","['real-analysis', 'riemann-integration', 'calculus', 'multivariable-calculus', 'integration']"
2676639,How to read off the facets of polytopes from their Gale diagrams and affine Gale diagrams?,"We have this theorem: Let $P = conv(V) \subset \mathbb{R}^d $ be a d-polytope. Let B be the Gale transform of $\{v_1,...,v_n\}$. Then $conv\{v_j|j \in J\}$ is a face of P iff either $J=[n]$ or $0 \in relint(conv\{b_k|k \not\in J\}) \subset \mathbb{R}^{n-d-1} $ When it comes to actual problems that I want to solve by hand, such as these two: the Gale diagram (for the first problem) makes it hard to read off the facets. Are there any other ways to do it by hand?","['discrete-geometry', 'polytopes', 'discrete-mathematics']"
2676662,Can I skip part III in Dummit and Foote?,"I am reading Abstract Algebra by Dummit anfd Foote. I have already taken an introductory course in linear algebra, mostly at the level of Strang's MIT OCW Linear Algebra . My question is: Can I skip 'Part III: Modules and Vector spaces' and jump directly to chapter 13: Field Theory in Dummit and Foote? Will that be harmful? (Note that I am planning to cover Part I up to 5.3 and Part II up to 9.5, as suggested in preface of D&F. )","['abstract-algebra', 'advice', 'group-theory', 'reference-works']"
2676680,Having trouble understanding a property of modular congruence,"I am given that
$$a \equiv 11 \pmod {19}$$
and $$ c \equiv 13a \pmod {19}$$ 
and I am asked to solve for a $c$ that is between $0$ and $18$ inclusive. From looking at problems online, it seems that the easiest way to do this is as follows: $$ c \equiv 13(11) \pmod {19}$$
$$ c \equiv 143 \pmod {19}$$
$$ 143 = 19(7) + 10$$
therefore
$$ c = 10$$
because $$ 19 \mid (143-10). $$ So I have two questions: how is it possible to substitute $11$ as $a$, as my book does not prove this nor mention it and I have a very hard time with proving things myself? And is that last step (solving for $c$) a trial and error approach, as it seems to be that way?","['discrete-mathematics', 'modular-arithmetic', 'elementary-number-theory']"
2676755,What IS the successor function without saying $S(n) = n + 1$?,"I get really frustrated that all these real analysis books and online webpages say $S(n) = n + 1$ but then say addition is defined in terms off the relationships $a + 0 = a$ and $a + S(b) = S(a+b)$. I feel like this is a bit of a circular definition because we haven't really defined $S(n)$ and I don't like labeling it ""$S(n) = n + 1$"" because that feels like a cheap way of appealing to intuition when the whole point of analysis is to rigorously define the very things we normally take for granted and find obvious so that we more accurately understand what we are and are not permitted to do with these numbers. Can we just treat it as a mapping to some other distinct element? If I look at it this way then I would end up defining axioms like this: Zero is a number. If $a$ is a number, then the successor of $a$, denoted $S(a)$, is a number. $a$ and $S(a)$ are considered distinct numbers. If two numbers have the same successors, then they themselves are equal numbers. Zero is not the successor of any other number. So I am envisioning a sort of linked-list relationship: $$0 \rightarrow \alpha \rightarrow \beta \rightarrow \gamma \rightarrow \delta \rightarrow \epsilon \rightarrow \zeta \rightarrow \eta...$$ The labels are arbitrary but I am seeing natural numbers as just nodes linked together where successor just means ""whatever this node points to"". So you wouldn't see something like $\alpha$ (or anything else) point to two different nodes, or anything pointing to $0$, or anything pointing to itself. And then if we want to compute $\beta + \gamma$ using our definition of addition we see that: $$\beta + \gamma = \beta + S(\beta) = S(\beta + \beta)$$ $$\beta + \beta = \beta + S(\alpha) = S(\beta + \alpha)$$ $$\beta + \alpha = \beta + S(0) = S(\beta + 0)$$ $$\beta + 0 = \beta$$ Combining: $$\beta + \gamma = S(S(S(\beta)))$$ Which makes sense intuitively, taking the third successor to $\beta$. And if we want to define $\beta$ relative to $0$ or its eventual node in the list we could replace it with successors and then show that $$\beta + \gamma = S(S(S(S(\alpha)))) = S(S(S(S(S(0))))) = \epsilon$$ I mean is this the right way to think of it? Am I right to find $S(n) = n + 1$ problematic or am I missing some point as to why it's always defined this way?","['real-analysis', 'natural-numbers', 'notation', 'definition']"
2676757,Closed and bounded but not compact subset of $\ell^1$,"I need to prove that $$A=\{a\in \ell^1:\sum_{i=1}^{\infty}|a_n| \le 1\}$$ is closed, bounded and not a compact subset in $\ell^1$. Boundedness is trivial, but I get stuck in the other two. Proving subsets of $l^1$ are not closed seems easy, because one sequence whose limit is not in the subsets does it, but I’m stuck in proving that any sequence converges to a point in $A$. Thanks in advance!","['real-analysis', 'functional-analysis', 'lp-spaces', 'compactness', 'metric-spaces']"
2676791,Finite Morphism of Schemes is Proper,"Let $f: X \to Y$ a finite morphism of schemes (therefore $f$ affine and the quasi koherent $\mathcal{O}_Y$-algebra $\mathcal{A}= f_*(\mathcal{O}_X)$ such that $X = Spec(\mathcal{A})$ is a finite $\mathcal{O}_Y$-algebra) Therefore practically that means that for every affine open set $V = Spec(S) \subset Y$ the $S=\Gamma(V,\mathcal{O}_Y)$-algebra $A= \Gamma(V,\mathcal{A})$ is finite I want to show that then $f$ is proper. Here my attempts: I want to use following valuative criterion for properness : $f$ is proper (so  separated, of finite type, and universally closed) if and only if in every diagram $$
\require{AMScd}
\begin{CD}
Spec(F)  @>{g}  >> X   \\
@VViV  @VVfV   \\
Spec(R) @>{t}>> Y 
\end{CD}
$$ for every discrete valuation ring $R$ and $F = Frac(R)$ there exist $l:Spec(R) \to X$ such that $a = l \circ i$ and $t = f \circ l$ holds. The spectrum of DVR $R$ has the structure $Spec(R) = \{\sigma, \eta\} = \{\sigma\} \cup Spec(F)$ with generic point $ \eta$ and unique maximal ideal $\sigma$. Since $Spec(F)$ is a sigleton, we can reduce the problem to affine case $X= Spec(A), Y = Spec(S)$ with $A$ finite $S$-algebra. For underlying topological spaces it's obviously how to define $l: Spec(R) \to X = Spec(A)$: Let $s_0:= t(\eta), s_1 := t(\sigma)$. Obviously $s_0 \subset s_1$ as prime ideals. Because $= s_0= t \circ i (\eta) = f \circ g(\eta)$, we conclude that $a_0:= g(\eta)$ is lying over $s_0$. Since $f$ is finite morphism the going up theorem holds, therefore there exist a $a_1$ lying over $s_1$. Define $l$ set theoretically by setting $l(\eta)= a_0, l(\sigma) := a_1$. Now to my problem: How to see that $l$ defined in this way provides a morphism of schemes , not only a map which commutates with the commutative square?","['algebraic-geometry', 'commutative-algebra']"
2676833,Hartshorne Direct Image for Divisors on a Curve (IV.2.6),"I'm having some trouble proving the first part of Exercise IV.2.6 in Hartshorne's Algebraic Geometry . In particular, it wants me to prove that for any divisor $D$ on a curve (nonsingular, proper, etc.) $X$, $$\det (f_* \mathcal{L} (D))  \cong \det (f_* \mathcal{O}_X) \otimes \mathcal{L}(f_*D),$$ where $f_* (\sum n_ip_i) =  \sum n_i f(p_i)$. My attempt is to follow the hint given in the text, namely consider first an effective divisor $D$, and the short exact sequence $$0 \to \mathcal{L}(-D) \to \mathcal{O}_X \to \mathcal{O}_D \to 0.$$ We can check that the direct image of sheaves is an exact functor, so applying $f_*$ and using exercise II.6.11b gives that $\det f_* \mathcal{O}_D \cong \det f_* \mathcal{O}_X \otimes \det f_* \mathcal{L}(-D)^*.$  Since this is in the Picard group, we can rearrange to obtain $$\det f_* \mathcal{L}(-D) \cong \det f_* \mathcal{O}_X \otimes \det f_* \mathcal{O}_D^*.$$ From here, we notice that $f_* \mathcal{O}_D$ is a locally free sheaf of rank $n$, and we can identify $f_* \mathcal{O}_D \cong \oplus \mathcal{O}_{f_*D},$ which implies (by exercise II.6.11b) that $\det f_* \mathcal{O}_D \cong \mathcal{L}(f_* D)$. Putting this all together, we get that $$\det f_* \mathcal{L}(-D) \cong \det f_* \mathcal{O}_X \otimes \mathcal{L}(-f_* D)$$ where you can see that there are two extraneous minus signs from what I want to show. From here I'm not sure how to proceed, as this seems contradictory to the statement I'm trying to show. I tried to look up hints online to see where I went wrong, and I found many people using a short exact sequence for $D = D_1-D_2$ of the form $0 \to \mathcal{L}(D) \to \mathcal{L}(-D_2) \to \mathcal{O}_{D_1} \to 0$, which I am almost completely convinced is wrong, as this exact sequence does reproduce the earlier one when $D_2 =0$. I'm looking for help completing this problem, either via a good hint or a critique of my attempt.","['algebraic-curves', 'algebraic-geometry']"
2676878,Riemannian geometry identity,"Let $(M,g)$ be a Riemannian manifold and $f\in C^{\infty}(M)$. Why does the equality $$\nabla^j\nabla_i\nabla_jf-\nabla_i\nabla^j\nabla_jf=R_{ij}\nabla^jf$$ hold? I tried writing $$\nabla^j\nabla_i-\nabla_i\nabla^j=g^{jk}(\nabla_k\nabla_i-\nabla_i\nabla_k)=g^{jk}R(e_k,e_i)$$ assuming $[e_i,e_j]=0$, but now I'm stuck.","['riemannian-geometry', 'differential-geometry', 'curvature']"
2676890,Direct calculation of the canonical bundle of the complex projective space,"Let $\mathrm{P}_{\mathbb{C}}^{n}$ be the n-dimensional projective space, we pick the local charts
\begin{equation}
U_i=\lbrace [z]\in\mathrm{P}_{\mathbb{C}}^n\mid z_i\ne0\rbrace,\quad\phi_i([z_0:\dots:z_n])=(z_0/z_i,\dots,z_{i-1}/z_i,z_{i+1}/z_i,\dots,z_n/z_i)
\end{equation}
then the transition maps are $(i>j)$
\begin{equation}
\phi_{ij}(u_1,\dots,u_n)=(u_1/u_i,\dots,u_{j-1}/u_i,1/u_i,u_j/u_i,\dots,u_{i-1}/u_i,u_{i+1}/u_i,\dots, u_n/u_i).
\end{equation}
If instead we consider
\begin{equation}
\tilde{\phi}_{ij}(u_1,\dots,u_n)=(u_1/u_i,\dots,u_{j-1}/u_i,u_j/u_i,\dots,u_{i-1}/u_i,1/u_i,u_{i+1}/u_i,\dots, u_n/u_i)
\end{equation}
then Huybrechts claims that $\phi_{ij}$ is the composition of $\tilde{\phi}_{ij}$ with the
  permutation $(j+1,i)$ of parity $(-1)^{i-j-1}$. Huybrechts, Daniel , Complex geometry. An introduction , Universitext. Berlin: Springer (ISBN 3-540-21290-6/pbk). xii, 309 p. (2005). ZBL1055.14001 . See page 92, Remark and Proposition 2.4.3. Is this claim true? To obtain $\phi_{ij}$ from $\tilde{\phi}_{ij}$ I need to move $1/u_i$ from the $i$-th place to the $j$-th place, which is done by $i-j$ subsequent transpositions. E.g.: Moving $7$ to the 3rd place:
\begin{equation}
123456789\to 123457689\to 123475689\to 123745689\to127345689
\end{equation} is achieved in $7-3=4$ steps. The previous fact is used to prove that the determinant of the jacobian is \begin{equation} \det
 \operatorname{J}\phi_{ij}=(-1)^{i-j+1}\det \operatorname{J}\tilde{\phi}_{ij}=(-1)^{i-j}(1/u_i)^{n+1}, \end{equation}
  where $\det \operatorname{J}\tilde{\phi}_{ij}=-(1/u_i)^{n+1}$. \begin{equation}
\lvert \operatorname{J}\tilde{\phi}_{ij}\rvert=\begin{vmatrix}
u_i^{-1} &            &            &             &          &            &-u_1u_i^{-2}         &\\
         &\ddots      &            &             &          &            &\vdots    &\\
         &            & u_{i}^{-1} &             &          &            &-u_{j-1}u_i^{-2 }    &\\
         &            &            &  u_{i}^{-1} &          &            & -u_j u_{i}^{-2}            &\\
         &            &            &             &\ddots    &            & \vdots                &\\
         &            &            &             &          & u_{i}^{-1} & - u_{i-1}u_{i}^{-2}\\
         &            &            & 0           &          &            & \fbox{$-u_i^{-2}$} &           &\\
         &            &            &             &          &            &  -u_{i+1}u_{i}^{-2}    &  u_{i}^{-1}\\
         &            &            &             &          &            &                               \vdots&  &            &\ddots      &\\
         &            &            &             &          &            &  -u_nu_i^{-2}                             &        &            &            &u_{i}^{-1}\\
\end{vmatrix}=-(u_i)^{-(n+1)}.
\end{equation} If instead I calculate $\det \operatorname{J}\phi_{ij}$ \begin{equation}
\operatorname{J}\phi_{ij}=\begin{bmatrix}
u_i^{-1} &            &            &             &          &            &-u_1u_i^{-2}         &\\
         &\ddots      &            &             &          &            &\vdots    &\\
         &            & u_{i}^{-1} &             &          &            &-u_{j-1}u_i^{-2 }    &\\
         &            &            & 0           &          &            & \fbox{$-u_i^{-2}$} &           &\\
         &            &            &  u_{i}^{-1} &          &            & -u_j u_{i}^{-2}            &\\
         &            &            &             &\ddots    &            & \vdots                &\\
         &            &            &             &          & u_{i}^{-1} & - u_{i-1}u_{i}^{-2}\\
         &            &            &             &          &            &  -u_{i+1}u_{i}^{-2}    &  u_{i}^{-1}\\
         &            &            &             &          &            &                               \vdots&  &            &\ddots      &\\
         &            &            &             &          &            &  -u_nu_i^{-2}                             &        &            &            &u_{i}^{-1}\\
\end{bmatrix}
\end{equation}
I expand with respect to the row of the $(j,i)$-element, which yields
\begin{equation}
\det \operatorname{J}\phi_{ij}=(-1)^{i+j}(-u_i^{-2})(u_i^{-1})^{n-1}=(-1)^{i-j+1}(u_i)^{-(n+1)}.
\end{equation}
This differs from Huybrechts' result by a factor $(-1)$. Moreover the jacobian of $\phi_{ij}$ should be related to that of $\tilde{\phi}_{ij}$ by moving the $j$-th row below the $i$-th one (i.e. below $-u_{i-1}u_i^{-2}$) which requires $i-j$ switches, consistently with what I said before. So I am probably making some mistakes in both the computation of the parity of the permutation and that of the determinant, which should be embarrassingly easy, but nonetheless I can't see where. I'm so concerned about this $(-1)^{i-j}$ because it is interpreted as the Čech coboundary of $\lbrace U_i,(-1)^i\rbrace$ so that the cocycle of $K_{\mathrm{P}_{\mathbb{C}}^{n}}$ and that $\mathcal{O}_{\mathrm{P}_{\mathbb{C}}^{n}}(-n-1)$ are equal in Čech cohmology. Can someone help?","['complex-geometry', 'algebraic-geometry', 'proof-verification', 'proof-explanation', 'linear-algebra']"
2676897,Odds of winning a superlottery,"The problem: There's a lottery (or a ""superlottery"", I'm not really sure how that's different). In order to play, I select 8 numbers from the first 90 positive integers (so, 1-90 inclusive). Also, a computer selects 12 numbers from the first 90 positive integers. If all of my 8 numbers are in the set of 12 selected by the computer, I win. Assuming all numbers are randomly selected, what are the odds of winning? My solution: Once the computer has chosen its 12 numbers, there are $\binom{12}{8}$ ways for me to pick a winning set of numbers, and $\binom{90}{8}$ ways to pick a set of 8 numbers overall. So, the odds of winning are $\frac{\binom{12}{8}}{\binom{90}{8}}=\frac{1}{156597013}\approx6.38*10^{-9}$. My friend's solution: There are $\binom{12}{8}$ ways to choose winning numbers. The odds of the first number matching are $\frac{12}{90}$, the odds of the second number matching are $\frac{11}{89}$, and so on. So the odds of all the numbers matching are $\binom{12}{8}*\frac{12}{90}*...*\frac{5}{83}=\frac{495}{156597013}\approx2.107*10^{-6}$. Which of us is right (if either), and what mistake is the other person making?","['combinations', 'statistics', 'probability', 'discrete-mathematics']"
2676917,Beautiful sum of trigonometric roots [duplicate],"This question already has answers here : Sum of the squares of the reciprocals of the fixed points of the tangent function (6 answers) Closed 3 years ago . I was studying the sinc function, it led me to the study the following equation on $\mathbb{R}$
$$
x=\tan\left(x\right) \ \ \ \ \left(\star\right)
$$
The equation $\left(\star\right)$ has a unique solution $x_n$ on $\displaystyle I_n=\left]\frac{\pi}{2}+n\pi, \frac{\pi}{2}+\left(n+1\right)\pi\right[$ for $n \in \mathbb{Z}$ with $x_{n}=-x_{-n}$ and $x_0=0$, which allows us to define a sequence on $\mathbb{N}$ only. I've read somewhere the following ( astonishing ) equality $$
\sum_{n=0}^{+\infty}\frac{1}{\left(x_n\right)^2}=\frac{1}{10}
$$ This sum does exist, because I've shown that
$$
\frac{1}{\left(x_n\right)^2} \underset{(+\infty)}{\sim}\frac{1}{\pi^2 n^2}
$$
But I dont know how to compute it. I thought about residue theorem making $x_n$ appears in a pôle but cannot find a way to prove it. Any help would be great.","['roots', 'trigonometry', 'sequences-and-series']"
2676936,Finite Morphisms Closed,"My question refers to following older thread: Finite morphisms of schemes are closed Let $f: X \to Y$ be a finite morphism of schemes. How the Going-Up theorem imply that this morphism is closed? Clearly we can reduce it to affine case $X = Spec(A), Y = Spec(R)$ and going up holds for finite morphisms since they are integral. Going up says that if $p_0 \subset p_1$ are prime ideals of $R$ and $P_0$ prime ideal of $A$ lying over $p_0$ then there exists a prime ideal $P_1$ lying over $p_1$ . But this just says that $f$ is surjective. How does it imply that it is also closed?","['algebraic-geometry', 'commutative-algebra']"
2676969,"Prove that if $a\equiv b \pmod {p^{2}-p}$, then $a^{a}\equiv b^{b} \pmod{p}$ where $p$ is any prime and $a$ and $b$ are nonzero integers.","I have shown the case in which $p=2$, so now I'm considering $p\geq 3$. I see that $p^{2}-p = p(p-1)$, in which case we can apply the Chinese Remainder Theorem to obtain $a\equiv [b,b] \mod{[p,\phi(p)]}$, since $p$ and $(p-1)$ are coprime and $\phi(p)=(p-1)$ where $\phi$ is Euler's totient function. Also, I see that $a\equiv b \pmod{\phi(p)}$ implies that $x^a\equiv x^b \pmod{p}$ for some $x\in \Phi(p)$ by the Fermat-Euler theorem. However, I'm not sure if this is the best approach or how to continue from here. Any help is appreciated, thanks! Edit: Now I see that $x^a\equiv x^b \pmod{p}$ is true for all $x\in \mathbb{Z}$. Because $p$ is prime, $x$ will either be coprime, or a multiple of $p$. In each case the statement is still true. This is why we can let $x = b$. Then we can use $a^a\equiv b^a \pmod{p}$ and $b^a\equiv b^b \pmod{p}$, and we're done.","['number-theory', 'modular-arithmetic', 'elementary-number-theory']"
2676976,"Showing that the Gamma Function has Poles by ""staying close"" to its integral identity $\Gamma(z) = \int_0^\infty x^{z-1}e^{-x}dx$","Consider the canonical definition of the gamma function on $\mathbb{C}$: $$\Gamma(z) = \int_0^\infty x^{z-1}e^{-x}dx$$ Problem: How can one show that $\Gamma$ has poles for $z=0, -1, \ldots$? One proof I've seen uses various facts about the gamma function to show that: $$\Gamma(z) = {\Gamma(z + n + 1) \over z(z+1) \ldots (z +n)}$$ This clearly shows the result in question; however, this latter representation of the gamma function is ""far away"" from the former, canonical representation. Question: Is there a way to show that $\Gamma$ has poles by sticking close to its canonical representation (i.e., by using facts about integrals and so forth)?","['complex-analysis', 'gamma-function']"
2677013,A map $\phi:M\rightarrow N$ is smooth if and only if $g\in\mathfrak{F}(N)\implies g\circ\phi\in\mathfrak{F}(M)$,"I'm trying to prove the next: A map $\phi:M\rightarrow N$ is smooth if and only if $g\in\mathfrak{F}(N)\implies g\circ\phi\in\mathfrak{F}(M).$ Here, $\mathfrak{F}(M)$ is the set of all functions $f:M\rightarrow\mathbb{R}$ such that $f$ is smooth. $M,N$ are smooth manifolds. The first implication follows because the composition of smooth maps is smooth. My problem is on the other; I'm trying to express $\phi$ as composition of compatible charts such that the composition of one o them with $\phi$ be in $\mathfrak{F}(N)$, but I don't get any useful. Any kind of help is thanked in advanced.","['real-analysis', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
2677050,probability of getting the same number of tails,"Alice tosses a fair coin $n$ independent times and Bob tosses a fair coin $m$ independent times. Find an elegant or clever argument to compute the probability that they have equal numbers of Tails.  It had better not involve any lengthy sums. The only way I can think of to approach this problem is to express the probability as a sum: $$\sum_{k = 1}^{\min(m, n)} P(\text{Alice gets $k$ tails})*P(\text{Bob gets $k$ tails}) \\ = \sum_{k = 1}^{\min(m, n)} \binom{n}{k} 0.5^n * \binom{m}{k} 0.5^m \\ = 0.5^{n + m}\sum_{k = 1}^{\min(m, n)} \binom{n}{k}\binom{m}{k} $$ However, I am not supposed to involve lengthy sums, but I cannot think of a more elegant way to solve this.",['probability']
2677150,Solve the differential equation $t y''-y'+4t^3y=0$,"Solve the differential equation $t y''-y'+4t^3y=0$  using method reduction where $y_1=\sin (t^2)$ my attempt: $y_2=vy_1=v\sin (t^2)$
$y_2'=v'\sin(t^2)+2t\cos(t^2)\\
y_2''=v''\sin (t^2)+4tv\cos(t^2)+2v\cos(t62)4t^2v\sin(t^2)$ Hence $t y_2''-y_2'+4t^3y_2=0\\
tv''\sin (t^2)+4t^2v\cos(t^2)+2vt\cos(t^2)+4t^3v\sin(t^2)-v'\sin(t^2)-2t\cos(t^2)-4t^3v\sin(t^2)=0\\
v''t\sin(t^2)+4t^2v'\cos(t^2)-v'\sin(t^2)=0$ how to proceed from here?",['ordinary-differential-equations']
2677239,Find all real solutions for $x$ in $2(2^x−1)x^2+(2^{x^2}−2)x=2^{x+1}−2$.,"Find all real solutions for $x$ in $2(2^x−1)x^2+(2^{x^2}−2)x=2^{x+1}−2$. I started off by dividing $2(2^x- 1) x^2 + (2^{x^2}-2)x = 2^{x+1} -2$ by $2$, and I got $(2^x-1)x^2 + (2^{x^2-1}-1)x = 2^x -1$. I tried dividing by $2^x-1$ on both sides which would give me a simple quadratic to solve for $x$, but I don't know how to simplify $\frac{(2^{x^2}-1)}{(2^x-1)}$. Am I missing a simple trick here, or am I on a completely wrong path to solving this?","['algebra-precalculus', 'exponential-function', 'polynomials']"
2677260,Higher order Sturm-Liouville form,"The differential equation book I was reading briefly mentions about the generalization S-L form and it says if we consider the BVP $L(y)=\lambda r(x)y$ where $L(y)=\displaystyle P_n(x)\frac{d^ny}{dx^n}+\dots +P_1(x)\frac{dy}{dx}+P_0(x)y$, then the problem is said to be self-adjoint if $(L(u),v)=(u,L(v))$ and this requires $L$ to be of even order. I'm not sure why the last condition requires $L$ to be of even order, I tried to google and found some documentations saying $L$ is self-adjoint if it's of even order and anti self-adjoint(i.e. $(L(u),v)=-(u,L(v)))$ if it's of odd order but couldn't find any explanation. Can anyone explain this to me?","['boundary-value-problem', 'sturm-liouville', 'ordinary-differential-equations']"
2677309,$\psi:M\rightarrow B$ a submersion. A map $\phi:B\rightarrow N$ is smooth if and only if $\phi\circ\psi$ is smooth.,I'm stuck proving the next equivalence: Let $\psi:M\rightarrow B$ a submersion. A map $\phi:B\rightarrow N$ is smooth if and only if $\phi\circ\psi$ is smooth. The first implication is clear because the composition of smooth maps is smooth and the submersion is smooth. For the other direction I'm stuck. I've tried to use a bump function together charts for both manifolds and try to prove smoothness in a local way but I don't get any useful. Is there another way to prove this? Any kind of help is thanked in advanced.,"['smooth-manifolds', 'differential-geometry', 'differential-topology']"
2677429,Does a complex number have finitely many distinct powers?,"Let's say I have a complex number, $z=a+bi$ such that $z$ is a root of unity. It's clear that $\mathrm {arg}(z)= \arctan\left(\frac{b}{a}\right)$. Can I conclude that $z$ has $\left|\frac{2\pi}{\mathrm {arg}(z)}\right|$ distinct integral powers? What can we say if I raise $z$ to real powers rather than integral? And lastly what about complex powers? Will there be finite distinct powers?","['complex-analysis', 'complex-numbers']"
2677440,Probability problem: $4$ kids hitting a balloon,"Let's say there is a balloon that blows if it gets a hard hit or 2 medium hits. During a party, if a kid  hitsthe balloon, he has $\frac{1}{4}$ probability getting a hard hit on the balloon and $\frac{1}{4}$ probability for a medium hit and $\frac{1}{2}$ probability of missing the hit. If $4$ kids consecutively hit the balloon(a kid can hit only one time), what's the probability of the balloon to blow? All hits are independent. Any hint would be valuable.","['independence', 'probability']"
2677494,Find a function that satisfies certain conditions,"Is it possible to find a function with certain conditions? $$x \gt 0 \Rightarrow f(x) \gt 0$$
$$x = 0 \Rightarrow f(x) = 0$$
$$f'(1)+f'(6)=a \ne 0$$
$$f'(2)+f'(5)=0$$
$$f'(3)+f'(4)=0$$
$$f'(1) \ne 0$$
$$f'(2) \ne 0$$
$$f'(3) \ne 0$$
$$f'(4) \ne 0$$
$$f'(5) \ne 0$$
$$f'(6) \ne 0$$ I don't care how function behaves when $x<0$. The function as well as its derivative should be continuous. Possibly, there is some approach to build such function. Thank you.","['algebra-precalculus', 'calculus']"
2677611,What is the area of the triangle ABC?,"$ABC$ is an equaliteral triangle.
Suppose $DB=4$, $DA=4\sqrt{3}$ and $DC=8$. Find the area of the triangle $ABC$.","['euclidean-geometry', 'triangles', 'area', 'geometry']"
2677622,Can sextic resolvent of an irreducible quintic have repeated root?,"Consider formal variables $x_1,\cdots,x_5$. Denote $$\theta_1 = x_1^2 x_2 x_5 + x_1^2 x_3 x_4 + x_2^2 x_1 x_3 + x_2^2 x_4 x_5 + x_3^2 x_1 x_5 + x_3^2 x_2 x_4 + x_4^2 x_1 x_2 + x_4^2 x_3 x_5 + x_5^2 x_1 x_4 + x_5^2 x_2 x_3$$ The stabilizer of $\theta_1$ under the action of $S_5$ is a group $M$, which has order $20$ (isomorphic to the general affine group over $\mathbb{F}_5$). The orbit consists of six elements, denote them by $\{\theta_1, \cdots, \theta_6\}$. Any conjugates of $M$ in $S_5$ is the stabilizer of some $\theta_i$ (because $M$ is self-normalizing in $S_5$). When $x_i$ are subsituted as roots of an irreducible quintic $f$ (say over a field $k$ with characteristic
$0$), denote the polynomial $f_{20}(x):=(x-\theta_1)\cdots(x-\theta_6)$, evidently it is in $k[x]$. In this well-known paper , it is stated that $f(x)$ is solvable by radical iff  $f_{20}(x)$ has a root in $k$. Assuming $f_{20}(x)$ has distinct roots, this equivalence is easy to establish. Indeed, if Galois group is $A_5$ or $S_5$, since they act transitively on $\{\theta_1, \cdots, \theta_6\}$, if one roots is in $k$, then all roots are the same, contradiction. On the other hand, if Galois group is conjugate to $M, D_5$ or $C_5$, then it is contained in the stabilizer of some $\theta_i$, this $\theta_i$ must be in $k$. Now there is a subtleties lurking in the background, what if $f_{20}(x)$ has repeated root? In this case, one implication still holds: that is Galois group is $D_5, C_5$ or $M$ $\implies$ $f_{20}(x)$ has a root in $k$ However, I am troubled in establishing the reverse. If Galois group is $A_5$ or $S_5$, then either $f_{20}(x)$ has no root in $k$, or it has and all roots are the same. I could not remove the latter possibility. So my question is Given an irreducible quintic, can $f_{20}(x)$ have repeated root? What if we impose an additional assumption that the Galois group of $f$ is $A_5$ or $S_5$? I tried to factorize the difference $\theta_i - \theta_j$, but it turn out cannot be factorized. The paper I mentioned above completely ignores this issue. Maybe this is really something trivial, but I cannot figure this out. Thank you for your time.","['abstract-algebra', 'galois-theory', 'field-theory', 'group-theory']"
2677651,Question on Proof in Evans' PDEs: Sobolev Inequality,"I've currently started to study about Sobolev inequalities and here is Gagliardo-Nirenberg-Sobolev inequality from Evans' book: I understand the whole proof except for some details I'm about to ask: In $\;(12)\;$ the last inequality results from general Holder inequality for $\;(\int_{\mathbb R} \vert Du(x) \vert\;dy_i)^{\frac{1}{n-1}}\;$. However this inequality states that in generall $\;\int_{\mathbb R} \vert u_{x_1}\dots u_{x_n}\vert \;dx \le (\int_{\mathbb R} {\vert u_{x_1} \vert}^{p_1}\;dx)^{1/{p_1}} \dots (\int_{\mathbb R} {\vert u_{x_n} \vert}^{p_n}\;dx)^{1/{p_n}}\;$. Which are the appropriate $\;p_i\;$ here and why I can't see them? In the first two lines, I don't fully understand why $\;\vert u(x) \vert \le\int_{\mathbb R} \vert Du(x_1,\dots,y_1,\dots,x_n)\;dy_i\;$ Any help would be valuable. Thanks in advance!","['inequality', 'partial-differential-equations', 'functional-analysis', 'proof-explanation', 'sobolev-spaces']"
2677657,An algorithm determining whether two subgroups of a free group are automorphic,"In the book Lyndon, Schupp, Combinatorial Group Theory, the edition from 2000 P.30 They mention an unpublished work by Waldhausen that is said to give an algorithm to determine whether two subgroups are automorphic given their free generators. I searched for papers written by Waldhausen But I didn't find it. Has Waldhausen or anyone else published a solution to this problem? Where can i find it?","['combinatorial-group-theory', 'reference-request', 'group-theory', 'free-groups']"
2677706,$A^2-B^2=\alpha(AB-BA)$,"Let $A, B \in M_n(\mathbb{R})$ , $\alpha\in\mathbb{R}$ , such that $A^2-B^2=\alpha(AB-BA)$ . Prove that $a)$ If $\alpha=0$ and $n$ odd, then $\det(AB-BA)=0$ $b)$ If $\alpha\neq0$ then $(AB-BA)^n=0_n$ For $a)$ we use the fact that $$\det(A+B)(A-B)=\det(A-B)(A+B)$$ which means that $$\det(AB-BA)=\det(-(AB-BA))$$ and since $n$ is odd we obtain the conclusion. The second point is, however, a little bit trickier. I managed to show just that $\det(AB-BA)=0$ . Using the same method as for $a)$ , we observe that $$\det((\alpha+1)(AB-BA))=\det((\alpha-1)(AB-BA))$$ and since $\alpha\neq0$ , we obtain that our determinant is $0$ , but from here I don't have any idea what should I do next.","['matrices', 'linear-algebra', 'determinant']"
2677713,When is $4n^4+1$ prime?,"Find all natural numbers $n$ such that $4n^4+1$ is prime. 
$4n^4+1$ is obviously prime when $n=1$. But can we prove that no other $n$ works?","['number-theory', 'prime-factorization', 'prime-numbers']"
2677742,Moore-Penrose equals original matrix,"I'm a bit stuck with my homework in a subject called ""Matrices in Statistics"". The task is as follows: Prove, that if $A$ is symmetric ($A=A^{T}$) and idempotent ($A=A^2$). Then $$ A^{+} = A $$
Where $A^{+}$ is called the Moore-Penrose generalized inverse matrix. Can you give me any ideas/tips, how to get started with this one?
I would be very thankful.","['matrices', 'statistics', 'symmetric-matrices', 'linear-algebra']"
2677780,"Find the general formula to compute $\det(A_n)$ and then proof by induction, problem with the proof...","I have to find the general formula to compute the determinant of a matrix which has all the diagonal elements $0$ and all non-diagonal elements $1$. I have calculated the $\det$ starting from $n=1$, $n=2$, $n=3$, $n=4$ and $n=5$ For $n=1$,  $\det(A) =  0$ For $n=2$,  $\det(A) = -1$ For $n=3$,  $\det(A) =  2$ For $n=4$,  $\det(A) = -3$ For $n=5$,  $\det(A) =  4$ For $n=6$,  $\det(A) = -5$ From this pattern I saw that every time the value is $n-1$ and the sign is alternating, so I created this general formula based on the results I got: $$\det(A) = (-1)^{n+1} \cdot (n-1)$$ Now I need to proof this by induction, when I do the base case $n=0$, I get $0=1$, does that mean that I should only start from $n\ge 1$ since there is no matrix with dimension $0$, or I am doing something wrong which I cannot see?","['matrices', 'linear-algebra', 'determinant']"
2677839,For $n$-degree complex polynomial $p(z) = a_nz^n + \cdots + a_1z + a_0$ defined on $S^2$ is $p$ homotopic to $z^n$?,"If I have an $n$-degree complex polynomial $p : S^2 \to S^2$, can I just construct the straight-line homotopy on all non-leading coefficients from $a_i$ to $0$? Is this continuous? Full disclosure, this is for a homework problem (Hatcher's Algebraic Topology 2.2.8) but this fact is not the primary focus of the problem. Edit: added that this is $S^2 \to S^2$ instead of $\mathbb C \to \mathbb C$ (which is kind of important...)","['algebraic-topology', 'complex-analysis']"
2677845,"Looking for ${f_n}$ such that $\int_0^1 (x-t)^{m-1}f_n(t) dt = \delta_{n,m}$","Good day, I am wondering whether it is possible to find a sequence of functions $f_n$ such that $$\int_0^1 (1-t)^{m-1}f_n(t) dt = \delta_{n,m}$$ for every $0<n,m$. Thank you.","['real-analysis', 'kronecker-delta', 'functional-analysis', 'integration', 'definite-integrals']"
2677862,"Find a recurrence relation for the number of n-digit ternary $(0,1,2)$ in which no $1$ appears any where to the right of a $2$","My question is as follows: Find a recurrence relation for the number of n-digit ternary $(0,1,2)$ in which no $1$ appears any where to the right of a $2$ If we introduce an auxiliary variable: let $b_n$ be the number of ternary sequences of length $n$ that do not contain a $2$. If a sequence of length $n$ contains a $2$, you can append a $0$ or a $2$; if it does not contain a $2$, you can append a $0$, a $1$, or a $2$. In particular, you can always append a $0$ or a $2$, and if it does not contain a $2$, you can also append a $1$. Thus, $$a_{n+1}=2a_n+b_n\;.$$ Clearly $b_{n+1}=2b_n$, and in fact it’s not hard to see that $b_n=2^n$: you’re just counting binary strings of length $n$. Thus, $$a_{n+1}=2a_n+2^n\;.$$ Is this the correct recurrence relation?","['combinatorics', 'recurrence-relations', 'discrete-mathematics']"
2677874,Find all derangements for $n=4$ and $n=5$,"Find all derangements for $n=4$ and $n=5$ Solution for $n=4$ I know there are 9 possibilities $(2,1,4,3), (2,3,4,1), (2,4,1,3), (3,1,4,2),(3,4,1,2), (3,4,2,1) (4,1,2,3),(4,3,1,2), (4,3,2,1)$ Solution for $n=5$ I know there are 44 of them, I am wondering if someone had a link to a list of them, or possibly a program that would spit them out, or could help me in general, thanks!","['combinatorics', 'discrete-mathematics']"
