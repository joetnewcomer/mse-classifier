question_id,title,body,tags
1395538,Prove $\sum\limits^m_{k=0} \frac{2n-k\choose k}{2n-k\choose n}\frac{2n-4k+1}{2n-2k+1}2^{n-2k}=\frac{n\choose m}{2n-2m\choose n-m}2^{n-2m}$ for-,Let $n$ be a positve integer. Prove that$$\sum\limits^m_{k=0} \frac{2n-k\choose k}{2n-k\choose n}\frac{2n-4k+1}{2n-2k+1}2^{n-2k}=\frac{n\choose m}{2n-2m\choose n-m}2^{n-2m}$$ for each non-negative integers $m\leq n$. I know this is to be done by induction. Base case is easy. But I can't simplify expression for $(m+1)$. Please guide. Edit: $\large P(m+1)=P(m)+\frac{2n-(m+1)\choose m+1}{2n-(m+1)\choose n}\cdot\frac{2n-4(m+1)+1}{2n-2(m+1)+1}\cdot2^{n-2(m+1)}$ $\Large=\frac{n\choose m}{2n-2m \choose n-m}.2^{n-2m}+\frac{2n-m-1\choose m+1}{2n-m-1\choose n}\cdot\frac{2n-4m-3}{2n-2m-1}.2^{n-2m-2}$ It must be equal to $\Large\frac{n\choose m+1}{2n-2m-2\choose n-m-1}.2^{n-2m-2}$ So lets try to simplify it- $\Large=\frac{n!(n-m)!}{m!(2n-2m)!}.2^{n-2m}+\frac{n!(n-m-1)!}{(m+1)!(2n-2m-2)!}\cdot\frac{2n-4m-3}{2n-2m-1}\cdot2^{n-2m-2}$ $\Large=\frac{2^{n-2m-2}\cdot n!(n-m-1)!}{m!(2n-2m-2)!(2n-2m-1)}[\frac{2}{1}+\frac{1}{(m+1)}\cdot\frac{2n-4m-3}1]$ $\Large=\frac{2^{n-2m-2}\cdot n!(n-m-1)!}{m!(2n-2m-2)!(2n-2m-1)}[\frac{2n-2m-1}{m+1}]$ $\Large=\frac{2^{n-2m-2}\cdot n!(n-m-1)!}{(m+1)!(2n-2m-2)!}$ $\Large=\frac{\frac{n!}{(m+1)!(n-m-1)!}}{\frac{(2n-2m-2)!}{(n-m-1)!(n-m-1)!}}\cdot2^{n-2m-2}$ $\Large=\Large\frac{n\choose m+1}{2n-2m-2\choose n-m-1}.2^{n-2m-2}$ I think it is right. But is there any shorter way also?,"['induction', 'proof-verification', 'binomial-coefficients', 'combinatorics']"
1395566,Show $\int_{0}^{1} \frac{\ln x}{1-x}dx$=$\sum_{1}^{\infty}\frac{1}{n^2}$ and converges,"I found this question a) show that the follow integral converges: $\int_{0}^{1} \frac{\ln x}{1-x}dx $ b) $\int_{0}^{1} \frac{\ln x}{1-x}dx$=$\sum_{1}^{\infty}\frac{1}{n^2}$ for the first part I try with comparison test because $f(x):=\frac{\ln x}{1-x} \le0$ in $ [0,1]$
and I know from L'HÃ´pital's rule that $\lim_{x\to1} \frac{\ln x}{1-x}=-1 $ thanks ahead","['calculus', 'improper-integrals', 'integration']"
1395572,What is the derivative of $|x^3|$?,"Let $f(x)=|x^3|$. I found two ways to differentiate this function. Apparently method 2 is wrong, but I cannot figure out why. So the question is, is method two wrong and why? Method 1 (according to wolfram mathematica) $$f(x)=|x^3|=|x|^3$$ $$f'(x)=3|x|^2 \text{Sgn}(x)=3|x^2|\frac{x}{|x|}=3|x|x$$ Method 2 (using chain-rule) $$f'(x)= \text{Sgn}(x^3)\cdot3x^2$$ With method 2 it seems $f'(0)$ is not defined, since $\text{Sgn}(0)$ is not defined. However, this is not true according to WolframAlpha .","['calculus', 'absolute-value', 'derivatives']"
1395575,Image of a function under unit disk.,"What can we say about the image of the following function under open unit disk:
$$f(z)=\frac{1}{(1-z)(1-a z)},\quad 0<a\leq1.$$ I think the complement of the image domain is a convex set. But I don't have proof.",['complex-analysis']
1395596,$\text{vec}\left(A\otimes B\right)$ is not $\text{vec}\left(A\right) \otimes \text{vec}\left(B\right)$,"Let $A$ and $B$ be two square matrices of dimension $a$ and $b$. $\text{vec}\left(\cdot\right)$ is the vectorization of a matrix . Now $v_0=\text{vec}\left(A\otimes B\right)$ is not $v_1=\text{vec}\left(A\right) \otimes \text{vec}\left(B\right)$, but the set of vector elements in both is equal, but $v_0$ and $v_1$ seem to be related by a permutation of elements: $v_0 = P_{a,b} v_1$ Can this permutation matrix $P_{a,b}$ be described in general?","['vectorization', 'kronecker-product', 'matrices']"
1395619,Difference between Null set and empty set,"One of my friend asked this doubt.Even in lower class we use both as synonyms,he says that these two concepts have difference.Empty set $\{ \}$ is a set which does not contain any elements,while null set ,$\emptyset$ says about a set which does not contain any elements. I could not make out that...is his argument correct ? if so how ?",['measure-theory']
1395629,"Notation/terminology for ""independent"" subspaces/subalgebras","Let $V$ denote a vector space (or any other kind of algebraic structure). Question. Letting $I$ denote a fixed set and $X$ denote an $I$-indexed family of subspaces (subalgebras) of $V$, is there better
  notation than $\bigoplus_{i:I} X_i = \sum_{i:I}X_i$ and/or
  $\bigsqcup_{i:I} X_i = \bigvee_{i:I}X_i$ to mean that the projection
  $\bigsqcup_{i:I} X_i \twoheadrightarrow \bigvee_{i:I}X_i$ is injective? Also: is there accepted terminology for this condition? For example, if $A$ denotes an $n \times n$ real matrix and $X : \mathrm{Eigenvalue}(A) \rightarrow \mathrm{Subspace}(\mathbb{R}^n)$ is the corresponding eigenspace function, then I'd like to be able to say: ""$X$ satisfies [whatever].""","['abstract-algebra', 'notation', 'terminology', 'linear-algebra']"
1395657,On counting and generating all $k$-permutations of a multiset,"Let $A$ be a finite set, and $\mu:A \to \mathbb{N}_{>0}$.  Let $M$ be the multiset having $A$ as its ""underlying set of elements"" and $\mu$ as its ""multiplicity function"".  (Hence $M$ is finite.) Let $0 \leq k \leq \left|M\right|$ be an integer. This question is about the set $\mathbf{P}(M, k)$ of all $k$-permutations of elements from the multiset $M$. For example, if $k = 3$ and $M$ is the multiset $\{0, 0, 1, 2\}$, then $\mathbf{P}(M, k)$ comprises these 12 $k$-permutations: $$
(0, 0, 1), (0, 0, 2), (0, 1, 0), (0, 1, 2), (0, 2, 0), (0, 2, 1), \\
(1, 0, 0), (1, 0, 2), (1, 2, 0), (2, 0, 0), (2, 0, 1), (2, 1, 0)
$$ I am interested in an efficient (and preferably non-recursive) algorithm for generating all the elements of $\mathbf{P}(M, k)$ (in any order); a way to determine the cardinality of the set $\mathbf{P}(M, k)$ without generating all its elements (IOW, without resorting to the solution of (1)). (I had no trouble coming up with a recursive algorithm to generate all the elements of $\mathbf{P}(M, k)$, but it is impractical, for two reasons, both having to do with my algorithm's recursive structure: (1) its space requirements grow very rapidly with $\left|A\right|$, and (2) there is no simple way to implement it so that it can be ""gracefully interrupted"" (e.g. in an interactive setting) 1 .  These two shortcomings are not independent: the severity of (1) is what makes the interruptibility mentioned in (2) desirable.) My guess is that a fair bit of work has been done on this problem, but all the searches I've tried are swamped by hits pointing to similar-sounding but substantially different problems.  (Many of these false hits turn out to be easier special cases of the problem described here.)  Similarly, I spent some time flipping through Stanley's Enumerative Combinatorics , v. 1 , but I was not able to find what I was looking for (even though odds are that the problem is discussed somewhere in this work). Therefore, in lieu of answers to 1 and 2 above, I could also use search keywords that will lead to the prior work on this problem; (in particular, is there a name for the integers $\mathbf{P}(M, k)$?) 1 By this I mean that the computation can be aborted (e.g. through some user-initiated signal or some pre-configured time-out) without having to bring down the entire process.","['algorithms', 'combinatorics']"
1395679,How would I find a point on a sphere with a UV coordinate?,"I'd like to do the opposite of the example specified here: https://en.wikipedia.org/wiki/UV_mapping Can somebody explain to me how to do it? Thanks, For any point $P$ on the sphere, calculate $\hat d$, that being the unit vector from $P$ to the sphere's origin. Assuming that the sphere's poles are aligned with the $Y$ axis, UV coordinates in the range $[0, 1]$ can then be calculated as follows:
\begin{align}
u &= 0.5 + \frac{\text{arctan2}(d_z, d_x)}{2\pi}
\\
v &= 0.5 - \frac{\arcsin(d_y)}{\pi}
\end{align}",['trigonometry']
1395699,differentiation of 1-norm of a vector,Assume you want to find the minimum of the following expression $\|x\|_1 + \alpha \|Ax-b\|_2$ where $x\in R^N$. So basically I want to calculate the derivative of $\|x\|_1$ so I could finally set the equation to zero and solve for $x^*$. What is the best approach to tackle this problem?,"['normed-spaces', 'matrix-calculus', 'derivatives']"
1395757,$\int\frac{dx}{(x^2+a^2)(x^2+a^2+b^2)^{\frac12}}$,I am trying to solve below integration $$\int\frac{dx}{(x^2+a^2)(x^2+a^2+b^2)^{\frac12}}$$ I tried substituting $x=a \tan u$ . Then I ended up with $$\int\frac{du}{(a)(b^2+a^2\sec^2u)^{\frac12}}.$$ I am not able to continue after this. Appreciate a small help on this.,"['trigonometry', 'integration']"
1395770,Arbitrarily large values for $|Li(x) - \pi(x)|$,"I was wondering whether there are arbitrarily large values for the $|Li(x) - \pi(x)|$. I do know that $Li(x) - \pi(x)$ changes sign infinitely often, but this does not imply that the difference stays bounded (does it?) If an answerer could also reference me to a paper exploring this difference (especially if there is some relationship to Riemann Hypothesis), I would be grateful. Thanks in advance.","['prime-numbers', 'number-theory', 'reference-request']"
1395801,Residue of $\text{sech}^2(z)$,"I am trying to find the residue of $\text{sech}^2(z)$ at $z=\pi/2 i$. The function has a second order pole at $\pi/2 i$. I find the residue to be zero. However, the integral $\int \limits_{-\infty}^\infty dx~ \text{sech}^2(x)=2$ which can also be evaluated using Cauchy's formula using a rectangular path connecting points $(-R,0), (R,0), (R, i\pi)$ and $(-R,i\pi)$ in the complex plane and letting $R\to\infty$. However, since the residue is zero, the integral is also zero. Don't know what is wrong. Any input would be appreciated. Thanks.","['complex-analysis', 'integration']"
1395808,Area of shaded region circle help,Find the area of the shaded region Area of the sector is $240^\circ$ or $\frac{4\pi}{3}$ Next find $\frac{b\cdot h}{2}$ which is $\frac{2\cdot2}{2}$ which is $2$. Then subtract the former from the latter: $\frac{4\pi}{3} - 2$ Therefore the answer is $~2.189$? Is this correct?,"['algebra-precalculus', 'trigonometry']"
1395811,conjecture about primes and a certain q-series.,"Using wolfram Mathematica ,I observed an interesting and surprising property concerning prime numbers and q-series which I could not prove.Yet there is strong evidence supporting it.
I would be happy if anyone can find a counter-example.On the other hand,if it could turn out to be true,it would no doubt have amazing consequences in prime number theory. Let $p$ be an odd prime and $$\frac{1}{(q;q^4)_{\infty}^p}=\prod_{n=0}^{\infty}\frac{1}{(1-q^{4n+1})^p}=1+\sum_{n=1}^{\infty} \phi(n)\,q^n$$ with the usual convention $$(a;q)_{\infty}=\prod_{k=0}^{\infty} (1-aq^{k})$$ then $$\phi(n)\equiv 0\pmod{p}$$ is true for all natural numbers $\{1,2,3,\dots\}$ except at multiples of $p$. For example, $$\frac{1}{(q;q^4)_{\infty}^3}=1 + 3q +6q^2 + \color{brown}{10}q^3 + 15q^4 + 24q^5+ \color{brown}{37}q^6+\dots$$ $$\frac{1}{(q;q^4)_{\infty}^5}=1 + 5q +15q^2 + 35q^3 + 70q^4 + \color{brown}{131}q^5+ 235q^6+405q^7+\dots$$ Note: $\phi(n)$ is just a notation I chose as a matter of personal taste.
Can any one try to prove the conjecture or rather verify it by numerical methods,thanks in advance.","['modular-forms', 'conjectures', 'prime-numbers', 'number-theory']"
1395840,Then the value of $ [f(2)] $ where [.] represents the greatest integer function is?,"A differentiable function f is satisfying the relation $$f(x+y) = f(x) + f(y) + 2xy(x+y) - \dfrac{1}{3} $$ $ \forall $  $  x , y $ belongs to $\Re$ and $$lim_{h \to 0} \dfrac{3f(h)-1}{6h} = \dfrac{2}{3}. $$Then the value of $ [f(2)] $ where [.] represents the greatest integer function is? I think  $g(x+y)=g(x)+g(y)$ then we use the limit condition, I need help, and If someone can complete my solution I'll appreciated","['ceiling-and-floor-functions', 'algebra-precalculus', 'functions']"
1395864,Set theory venn diagram help. Homework,"I am new to set theory and one of our exercises is the following question:
decide on the truth or falsity of the claim that, for all sets A, B, C, D
[A â© B â C â© D] â [(AâB) â (CâD)]. I have drawn the following Venn diagrams And thus, from this visual proof, I conclude that the claim is false. If someone could validate my answer that would be appreciated, but even better if someone could tell me how I could prove this using set notation that would be even better or just put me in the direction of some helpful websites. Anyway all feedback is appreciated.",['elementary-set-theory']
1395879,Calculate $S=3\sqrt{\sqrt[3]{5}-\sqrt[3]{4}}-\sqrt[3]{2}-\sqrt[3]{20}+\sqrt[3]{25}$,"Calculate $$S=3\sqrt{\sqrt[3]{5}-\sqrt[3]{4}}-\sqrt[3]{2}-\sqrt[3]{20}+\sqrt[3]{25}$$ $\color{red}{\text{without using calculator}.}$ Please help me, I can't find any solution to sovle it.",['algebra-precalculus']
1395881,Determinant of $ n \times n$ matrix and its characteristic polynomial.,"Suppose, $M_4, M_5,..M_n$ is as follows then determinant and characteristic polynomial of $M_n$. $M_4=\left(
\begin{array}{cccc}
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1 \\
	1 & 0 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
\end{array}
\right),M_5=\left(
\begin{array}{ccccc}
	0 & 0 & 1 & 1 & 0 \\
	0 & 0 & 0 & 1 & 1 \\
	1 & 0 & 0 & 0 & 1 \\
	1 & 1 & 0 & 0 & 0 \\
	0 & 1 & 1 & 0 & 0 \\
\end{array}
\right),M_6=\left(
\begin{array}{cccccc}
	0 & 0 & 1 & 1 & 1 & 0 \\
	0 & 0 & 0 & 1 & 1 & 1 \\
	1 & 0 & 0 & 0 & 1 & 1 \\
	1 & 1 & 0 & 0 & 0 & 1 \\
	1 & 1 & 1 & 0 & 0 & 0 \\
	0 & 1 & 1 & 1 & 0 & 0 \\
\end{array}
\right), \quad M_8=\left(
\begin{array}{cccccccc}
	0 & 0 & 1 & 1 & 1 & 1 & 1 & 0 \\
	0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 \\
	1 & 0 & 0 & 0 & 1 & 1 & 1 & 1 \\
	1 & 1 & 0 & 0 & 0 & 1 & 1 & 1 \\
	1 & 1 & 1 & 0 & 0 & 0 & 1 & 1 \\
	1 & 1 & 1 & 1 & 0 & 0 & 0 & 1 \\
	1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 \\
	0 & 1 & 1 & 1 & 1 & 1 & 0 & 0 \\
\end{array}
\right)$","['spectral-graph-theory', 'determinant', 'linear-algebra', 'matrices']"
1395893,Determine all functions satisfying $f(x + f(x + y)) + f(xy) = x + f(x + y) +yf(x)$,"Let $\Bbb R $ be the set of real numbers .Determine all functions $f:\Bbb R \rightarrow \Bbb R $ satisfying the equation $$f(x + f(x + y)) + f(xy) = x + f(x + y) +yf(x)$$ for all real numbers $x$ and $y$. My work 
$$f(x + f(x + y)) + f(xy) = x + f(x + y) +yf(x)$$
Setting $y=0$
$$f(x + f(x)) + f(0) = x + f(x )$$
$$\implies f(x + f(x))  = x + f(x ) -f(0)$$
$$\implies f(t)  = t -f(0)$$
Setting $x=0$
$$f(f(y)) + f(0) = 0 + f(y) +yf(0)$$
$$f(f(y)) =  f(y) +f(0)(y-1)$$ Setting $y=1$
$$f(x + f(x + 1))  = x + f(x + 1)$$","['contest-math', 'functional-equations']"
1395915,What function looks like $\overbrace{}$?,"Here's my awesome drawing: Basically it's a function that takes a high (or infinite) value at $0$, then falls off logarithmically for a while before falling off exponentially. It doesn't need to be symmetric, it would be ok if the negative $x$ values were 
reversed in sign or something like that. I really only care about $x\ge0$. Edit: I would prefer if the function is not periodic.",['functions']
1395917,Is $f$ constant when each point is local minimum or maximum?,"Let $X$ be a connected topological space and $f:X\to \mathbb R$ be continuous. Further, we know that all $x\in X$ are local extrema. Does that imply that $f$ is constant? I think in case $X$ is second-countable that should be the case because of the proof of Theorem 2 here (it is only stated for separable metric spaces there but I think the same proof works for second-countable spaces). But what about an arbitrary connected topological space $X$?","['connectedness', 'real-analysis', 'general-topology']"
1395928,Morphism between surfaces,Suppose that $S$ is a surface of general type. Let $K_S$ the canonical bundle of $S$ and $\phi=\phi_{K_S}$ the canonical map. Suppose that the canonical map is a morphism from $S$ to $\mathbb{P}^{p_g-1}$ of degree 1. Can i say that $\phi$ is an embedding between $S$ and its image in the projective space?,"['projective-geometry', 'algebraic-geometry']"
1395985,Can a sequence have infinitely many limits among its subsequences?,"Suppose we have an extended real (countably) infinite sequence $(x_n)$. Then consider all of its possible subsequences $(x_{n_k})$. We could then consider the set $$A = \{a\in \overline{\mathbb{R}}:x_{n_k}\rightarrow a \text{ for some subsequence}\}.$$ Must this set necessarily be finite? Otherwise we have countably many numbers that the original sequence approaches arbitrarily closely countably many times in its tail. Is there some kind of argument that this would require an uncountable sequence? My thought is we could take the supposed countable set, and then choose some $\epsilon>0$ so that no two limits live in the same $\epsilon$-ball. Far enough down each subsequence, no element in the tail of one subsequence can also be in the tail of another. From here, is the argument like Cantor's diagonalization? Limits: subseq $a_1 : x_{n_1}, x_{n_2}, x_{n_3}, \dots$ $a_2 : x_{m_1}, x_{m_2}, x_{m_3}, \dots$ $a_3 : x_{o_1}, x_{o_2}, x_{o_3}, \dots$ We would need uncountably many limits for these subsequences to be unique, and this contradicts the original sequence being countable.","['infinity', 'sequences-and-series']"
1395989,"Functions Satisfying $u,\Delta u\in L^{1}(\mathbb{R}^{n})$","In this paper , the authors assert that ...the domain of realization of the Laplacian in $L^{1}(\mathbb{R}^{n})$ is not contained in $W^{2,1}(\mathbb{R}^{n})$ if $n>1$ . However, it is continuously embedded in $W^{1+\beta,1}(\mathbb{R}^{n})$ for each $\beta\in(0,1)$ . Therefore, if $u$ and $\Delta u$ are in $L^{1}(\mathbb{R}^{n})$ , then any first order derivative $D_{i}u$ , $i=1,\ldots,n$ , belongs to $W^{\beta,1}(\mathbb{R}^{n})$ for each $\beta$ , and by Sobolev embedding it belongs to $L^{p}(\mathbb{R}^{n})$ for each $p<n/n-1$ , with $$\left\|D_{i}u\right\|_{L^{p}}\leq C(p)\left(\left\|u\right\|_{L^{1}}+\left\|\Delta u\right\|_{L^{1}}\right)$$ Question. Could someone help me with a sketch for proving the continuous embedding into $W^{1+\beta,1}(\mathbb{R}^{n})$ ? Here's what I know. If $u\in L^{1}(\mathbb{R}^{n})$ and $\Delta u=f\in L^{1}(\mathbb{R}^{n})$ , then in the sense of (tempered) distributions $$(-2\pi i)^{2}\left|\xi\right|^{2}\widehat{u}=\widehat{\Delta u}=\widehat{f}$$ Since $u,f\in L^{1}(\mathbb{R}^{n})$ , $\widehat{u}$ , $\widehat{f}$ belong to $C_{0}(\mathbb{R}^{n})$ and away from the origin $\widehat{u}(\xi)=-4\pi^{2}\widehat{f}(\xi)\left|\xi\right|^{-2}$ . I wanted to arrive at $u=f\ast K$ , where $K$ is the fundamental solution of the Laplacian, and try to go from there; however, I hit the wall at this point.","['sobolev-spaces', 'functional-analysis', 'harmonic-analysis', 'regularity-theory-of-pdes', 'partial-differential-equations']"
1395998,"Step functions on $[a,b]$ are dense in $\mathcal C^0([a,b])$.","Let $\|f \|=\sup_{[a,b]}|f|$. We consider ($\mathcal C^0([a,b]),\|\cdot \|)$ and $(\mathcal E([a,b]),\|\cdot \|)$ where $\mathcal E([a,b])$ is a set of the step functions on $[a,b]$. I have to show that $\mathcal E([a,b])$ is dense in $\mathcal C^0([a,b])$. There is my proof: Let $f\in\mathcal C^0([a,b])$ and $\varepsilon>0$. Since $f$ is continuous on $[a,b]$ it's also uniformly continuous and thus, there is a $\delta>0$ s.t. $|f(x)-f(y)|<\varepsilon$ for all $x,y\in[a,b]$ s.t. $|x-y|<\delta$. Let $a=x_0<x_1<...<x_n=b$ such that $x_{i+1}-x_i<\delta$ for all $i$. We set $\varphi(x)=f(x_i)$ for all $i=0,...,n-1$ and $\varphi(x_n)=f(x_n)$. Therefore, if $x\in[a,b[$, there is a $i$ such that $x_i\leq x<x_{i+1}$ and thus $$|f(x)-\varphi(x)|=|f(x)-\varphi(x_i)|<\varepsilon$$ since $|x-x_i|<\delta$. Finally, since $f(b)=\varphi(b)$ we get that 
$$\forall x\in[a,b], |f(x)-\varphi(x)|<\varepsilon$$
and thus $$\|f-\varphi\|=\sup_{[a,b]}|f-\varphi|<\varepsilon$$
what prove the claim. Q1) Is it correct ? Q2) Something is strange to me. If $A$ is dense in $B$, in particular $A\subset B$, but here, how can $\mathcal E([a,b])\subset \mathcal C^0([a,b])$ since an element of $\mathcal E([a,b])$ is not necessarily continuous ?","['real-analysis', 'functional-analysis']"
1396002,Proof that $\lim_{n\to\infty}\|x_n-x\|=0$ with weak convergence,"I want to prove that in a normed linear space $H$, that if $x_n$ is weak convergent to $x$, and $\lim_{n\to\infty} \|x_n\| = \|x\|$ then: $$\lim_{n\to\infty}\|x_n-x\|=0$$ Can I please have a hint? Also does $\langle x,x\rangle^{\frac12}=\|x\|$ or something? The impression I have is, essentially $\lim_{n\to\infty}\|x_n\|-\|x\|=\lim_{n\to\infty}\|x_n - x\|$ due to the weak convergence, otherwise in the general case: $$\|x\|-\|y\|=\|x - y\|$$ could be true, but only if they are in opposite directions. My definition of weak convergence is $\lim_{n\to\infty} \langle x_n,y\rangle =\langle x,y\rangle$, so I suspect that this is a hilbert space.",['functional-analysis']
1396022,Non-integrability of distribution arising from 1-form and condition on 1-form,"Suppose $M$ is a $(2k+1)$-dimensional manifold on which a 1-form $\alpha$ is defined. $M$ is termed as a contact manifold if the distribution arising from $\alpha$ is nowhere integrable, i.e. if:
$$\xi_q=\{v\in T_qM:\alpha(v)=0\}$$
is a distribution that admits no integral manifolds whatever point you look for an integrable manifold at. I have read that this is equivalent to:
$$\alpha\wedge(d\alpha)^k\neq0.$$
How do I prove this?","['differential-geometry', 'differential-forms', 'contact-topology']"
1396045,Evaluate the integration : $\int\sqrt{\frac{(1-\sin x)(2-\sin x)}{(1+\sin x)(2+\sin x)}}dx$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question $$\int{\sqrt{\frac{(1-\sin x)(2-\sin x)}{(1+\sin x)(2+\sin x)}}dx}$$ $$\int\sqrt{\frac{(1-\sin x)(2-\sin x)}{(1+\sin x)(2+\sin x)}}dx=\int \frac{(1-\sin x)(2-\sin x)}{\sqrt{(1-\sin x)(2-\sin x)(1+\sin x)(2+\sin x)}}dx$$ I am stuck. Please help me....",['integration']
1396090,A probability puzzle about mountain villages,"I hope this puzzle will be of some interest. The mountain villages $A,B,C$ and $D$ lie at the vertices of a tetrahedron, and each pair of villages is joined by a road. After a snowfall the probability that any road is blocked is $p$, and
is independent of the conditions of any other road. The probability that, after a snowfall, it is possible to travel from any village to any other village by some route is $P$. What is $P$ in terms of the probability $p$?","['probability', 'puzzle']"
1396126,What do trivial and non-trivial solution of homogeneous equations mean in matrices? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . The community reviewed whether to reopen this question 4 days ago and left it closed: Original close reason(s) were not resolved Improve this question Suppose I have system of 3 equations
$$a_1x+b_1y+c_1z=0$$
$$a_2x+b_2y+c_2z=0$$
$$a_3x+b_3y+c_3z=0$$
and cofficient matrix $A=\begin{equation}
\begin{pmatrix}
a_1 & b_1 & c_1 \\
a_2 & b_2 & c_2 \\
a_3 & b_3 & c_3
\end{pmatrix}
\end{equation}$
So I have been told that solution of this matrix will be non-trivial if $|A|=0$ and trivial in any other case. As far as I know non trivial solution means solutions is not equal to zero but in any case $x,y,z=0$ will satisfy given equations regardless of it's value of determinant. So, why do we call it ""non-trivial"" solution?","['systems-of-equations', 'linear-algebra', 'matrices']"
1396134,Prove that $\sum_{k=1}^{n} \frac1{\sin^2 \frac{\left( 2k-1\right)\pi}{4n+2}}=2n\left( n+1\right)$,Prove that $$\frac{1}{\sin^{2}\frac{\pi }{4k+2}}+\frac{1}{\sin^{2}\frac{3\pi }{4k+2}}+\frac{1}{\sin^{2}\frac{5\pi }{4k+2}}+\cdots+\frac{1}{\sin^{2}\frac{(2k-1)\pi }{4k+2}}=2k(k+1)$$,"['summation', 'sequences-and-series', 'trigonometry']"
1396154,"$f(x,y) = e^\left({\frac{1}{x^2+y^2-1}}\right)$ continuity","for $x^2+y^2<1$ we have: $$f(x,y) = e^\left({\frac{1}{x^2+y^2-1}}\right)$$ for $x^2+y^2\ge 1$ we have: $$f(x,y) = 0$$ I'm asked in which sets these functions are continuous. That's what I did: for the set $\{x^2+y^2<1\}$, we have that the functions is continuous, as there is no breaks in the function. for the set $\{x^2+y^2=1\}$ we have the function undefined, because we get: $$e^\left({\frac{1}{1-1}}\right)$$ for the set $\{x^2+y^2>1\}$ we have that the limit of $f(x,y)$ when $(x,y)$ 'goes to infinity' we have that $f(x,y)$ goes to $1$, which does not approaches $0$, therefore for this set, the function is not continuous. So I concluded that it is continuous only for the set $\{x^2+y^2<1\}$. Am I rigth? Update: All I'm trying to do is to analise the behaviour of the function
  outside the set $\{x^2+y^2<1\}$. That is,  I need to find the
  'directions' where, when I approach the boundaries, I approach $0$.","['calculus', 'limits', 'multivariable-calculus']"
1396165,Products of adjugate matrices,"Let $S$ and $A$ be a symmetric and a skew-symmetric $n \times n$ matrix over $\mathbb{R}$, respectively. When calculating (numerically) the product $S^{-1} A S^{-1}$ I keep getting the factor $\det S$ in the denominator, while I would expect to get the square $$S^{-1} A S^{-1} = \frac{(\text{adj }S) A (\text{adj }S)}{(\det S)^2},$$ where $\text{adj }S$ is the adjugate of $S$. Is there a way to prove that the combination $(\text{adj }S) A (\text{adj }S)$ already contains a factor of $\det S$?","['determinant', 'linear-algebra', 'matrices']"
1396186,Not understanding the case where $G$ is abelian with every element of order $2$,"Suppose an abelian finite group $G$ (with $o(G)>2$) has every non-identity element of order $2$. Show that there exists a non-trivial automorphism on $G$. After a bit of searching, I found a few similar questions that have been asked, and answered on this site. This is the question whose answer has almost always been given by taking a recourse to Vector Spaces and describing some weird relationship with $\mathbb Z/2\mathbb Z$. I could not understand any one of those answers. My background: I have done a course on Linear Algebra and therefore I know something about Vector Spaces. I have started learning Group Theory and have just read about isomorphism. I know the first law of isomorphism, but nothing more. No knowledge at all of how one suddenly talks about vector spaces while answering a question on abstract algebra. And it's funny that all the answers are quite exactly the same. Is this problem very well-known? I found it in Tipics of Algebra as a ""starred"" exercise. Please explain if this question can be answered within Group Theory only. I mean, by not talking about vector spaces at all. If you are more comfortable with a vector space argument, that's fine with me, but please do explain every thing clearly. Thank you very much.","['abstract-algebra', 'group-theory', 'vector-spaces', 'group-isomorphism']"
1396187,Puzzles and topology,"I like problem solving. In fact, that is the reason I wanted to study mathematics; This is a field where I could learn the underlying logic of the results rather than just learning ideas even the foremost experts did not necessarily understand. The issue is that mathematics for the last few semesters have been becoming increasingly abstract, and the distance between what I am learning and actual problem solving seems larger than ever before. However, I have also read about how the fields I am struggling with are being used in puzzles (a la puzzles Martin Gardner would write about). For instance, Numberphile has three videos on a problem called ""Pebbling a Chessboard"" in whih the mathematician says that functional analysis is used to prove a result. Also, Euler's solution to the Seven Bridges of KÃ¶nigsberg problem is the first result of topology. Are there any books through which one can learn topology through problem solving?","['book-recommendation', 'recreational-mathematics', 'general-topology']"
1396190,"If $p(x,y) \in \mathbb{Q}[x,y]$ is such that $p(x,e^x) = 0$, then $p(x,y) = 0$ too.","Suppose that for some two variable rational polynomial that evaluation of the second variable at $e^x$ gives 0, then the evaluation at any $y$ also gives 0. I've seen a proof that uses a calculus-based limiting argument, but I was wondering if there was some sort of algebraic proof, maybe using the transcendence of $e$ over $\mathbb{Q}$? Any ideas? Thanks!",['abstract-algebra']
1396220,Step in five-lemma's proof.,"Consider the following commutative diagram, where rows are exact:
$$\require{AMScd}
\begin{CD}
M_1 @>f_1>> M_2 @>f_2>> M_3 @>f_3>> M_4 @>f_4>> M_5 \\
@Vh_1VV @Vh_2VV @Vh_3VV @Vh_4VV @Vh_5VV \\
N_1 @>g_1>> N_2 @>g_2>> N_3 @>g_3>> N_4 @>g_4>> N_5
\end{CD}
$$ All modules and homomorphisms above. Then the exercise asks me to check three things: (a) If $h_1$ is an epimorphism and $h_4$ is a monomorphism, then $\ker h_3 = f_2(\ker h_2)$; (b) If $h_2$ is an epimorphism and $h_5$ is a monomorphism, then $g_3^{-1}({\rm im}\,h_4) = {\rm im}\, h_3$; (c) If $h_1, h_2, h_4$ and $h_5$ are isomorphisms, so is $h_3$. I managed to solve item (b), and assuming item (a) too, I managed to solve item (c). I'm having trouble with item (a). The inclusion $\ker h_3 \supseteq f_2(\ker h_2)$ is easy to check. Then take $x \in \ker h_3$. So $h_3(x) =0$, and $g_3(h_3(x)) = h_4(f_3(x)) = 0$. From this, $f_3(x)= 0$ and $x \in \ker f_3 = {\rm im}\,f_2$, so $x=f_2(y)$ for some $y$. If I could prove that $y\in \ker f_2$, I would be done. What I can see is that $h_3(f_2(y)) = g_2(h_2(y)) =0$, so $h_2(y) \in \ker  g_2 = {\rm im}\,g_1$, so $h_2(y)=g_1(z)$ for some $z$. But $z=h_1(w)$ for some $w$, so $h_2(y) = g_1(h_1(w))=h_2(f_1(w))$, and from here $y-f_1(w)\in \ker h_2$. But I can't prove that $f_1(w)\in\ker h_2$ to conclude the $y\in \ker h_2$ that I want. Help?","['exact-sequence', 'abstract-algebra', 'diagram-chasing', 'modules']"
1396251,Normal group that contains its centralizer,"I am studying for my Algebra qual and I came across this question: Let $G$ be a finite group with a normal subgroup $N$ such that $C_G (N) \leq N$. Show that
$$
|G|\leq |N|!.
$$ Here $C_G (N)$ is the centralizer of $N$ in $G$. So far I have tried letting $G$ act on the elements of $N$ by conjugation. This induces a homomorphism from $G$ into $S_{|N|}$ with $C_G (N)$ as the kernel. So what I can get is that $$
\frac{|G|}{|C_G(N)|} \leq |N|!.
$$ It is here that I get stuck. Any help would be great, thanks!","['abstract-algebra', 'group-theory', 'finite-groups']"
1396260,Maximize the Cyclic sum,"Let $x_1,x_2,\dots ,x_6$ be nonnegative real numbers such that $x_1+x_2+x_3+x_4+x_5+x_6=1$, and $x_1x_3x_5+x_2x_4x_6 \geq \frac{1}{540}$. Let $p$ and $q$ be positive relatively prime integers such that $\frac{p}{q}$ is the maximum possible value of $x_1x_2x_3+x_2x_3x_4 + x_3x_4x_5 + x_4x_5x_6 + x_5x_6x_1 + x_6x_1x_2$. Find $p+q$. Hints only! This was a very difficult problem actually. A possibility is: $x_k = \frac{1}{6}$ so that: $\sum_{cyc} x_1x_3x_5 = 1/108 > \frac{1}{504}$, which is a possiblity (true). I took: $540 = 5(3^3)(2^2)$ Obviously, $x_k < 1$ so, the bigger each number, the bigger the total max value. I would think $1/6$ is the best, to get: $6\cdot \frac{1}{216} = \frac{1}{36}$ But this seems way too easy! Hints only!","['contest-math', 'algebra-precalculus', 'elementary-number-theory', 'combinatorics', 'probability']"
1396264,prove if f(x) has an infinite limit then limit of 1/f(x) is = 0,"I wanted to ask if someone can do me the favor pointing out the mistakes I might of made in proving the theorem below. Also is there a way to prove the theorem without using the definition of limits? Theorem: If $\lim_{x\to c}$f(x) =$\infty$ then $\lim_{x\to c} \frac{1}{f(x)}$ = $0$ Proof: Rewriting the above statement using the definition of limits and definition of infinite limits: ($ 0<|x-c|<\delta \Rightarrow f(x)>M)$ $\Longrightarrow (0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $) where $\epsilon$ and $M$ are both greater than zero and M denotes any real number. Taking the second conditional statement:      ($0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $) we can see that (i) $$-\epsilon <\frac{1}{f(x)} <\epsilon$$ Taking the first conditional statement:
 $ 0<|x-c|<\delta \Rightarrow f(x)>M$, we can conclude using the reciprocal of inequalities that $f(x)>M>0$ is equivalent to (ii)$$0<\frac{1}{f(x)}<\frac{1}{M}$$ From (i) and (ii) we get$$0<\frac{1}{f(x)}<\frac{1}{M}<\epsilon.$$ Meaning for any chosen value of $\epsilon>0$ and $M>0$ we can rewrite the theorem as 
($ 0<|x-c|<\delta \Rightarrow \frac{1}{f(x)}<\frac{1}{M}<\epsilon )$ $\Longrightarrow (0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $)
which shows that for any $\epsilon$ there exists a$\frac{1}{f(x)}$  that is always lower than $\frac{1}{M}$.","['alternative-proof', 'calculus', 'limits', 'proof-verification', 'proof-writing']"
1396281,"Probability, that a sequence of $n$ coin-flips contains $k$ changes of the lead","A fair coin is flipped $n$ times. What is the probability $p_k$, that the lead
between ""heads"" and ""tails"" changes exactly $k$ times ? For example, the sequence $$HHTTTHH$$ contains two changes because ""heads"" leads
at the beginning, after $HHTTT$ , ""tails"" is in the lead and at the end, ""heads""
has the lead. A tie (equal number of throws with ""heads"" and ""tails"") is not 
considered as a change of a lead. I tried to model this situation by a random walk. Then changing the lead means
changing the sign of the value of the random variable in the process. But this
did not lead anywhere.","['probability-theory', 'random-walk']"
1396318,Probability that a random bridge board does not contain a sequence?,"Two cards with adjacent values and the same suit produce a SEQUENCE. For example,
the heart-ten and the heart-jack form a sequence. The order of the values in
bridge is $$23456789TJQKA$$ -What is the probability that a random bridge board contains no sequence in any
 hand ? (That means, for example : If North holds the queen of spades, he neither
 holds the jack nor the king of spades ) A long time ago, I approached this problem by first determining all possible
combinations not containing a sequence (for example kt742) , and then calculate
the number of boards from that. I remember that the probability is very low.
But there should be a better method, perhaps inclusion-exclusion or something
like that.","['probability-theory', 'card-games']"
1396330,Exists polynomial satisfying following?,"Let $s, u \in M_m(\mathbb{k})$ be a pair of commuting matrices such that $s$ is a diagonal matrix and $u$ is a strictly triangular matrix (with zeros on the diagonal). Put $a = s + u$. Does there exist a polynomial $f(x) = c_1x + \cdots + c_dx^d \in \mathbb{k}[x]$, without constant term and such that one has $s = f(a)$ (a matrix equality), where $f(a) := c_1a + \cdots + c_da^d$?","['polynomials', 'vector-spaces', 'linear-algebra', 'matrices']"
1396363,Why is this sum well-defined?,"Let $$S=\mathbb{N}[1/2]$$ be the set of rational numbers greater than $0$ which has a power of $2$ as its denominator. Let $R$ be any commutative ring. Let us consider $R^S,$ the infinite direct product. It is clear that we can write the elements as $\sum_{s\in S } a_s x_s$ with $a_s \in R.$ Consider the $R$-submodule $M$ which isformed by the elements $\sum a_s x_s$ which satisfy the following property: (*) For every real number $r >0,$ there is an $\epsilon >0 $ such that $a_s = 0$ if $r-\epsilon \leq s <r.$ Let now $\alpha = \sum a_s x_s$ and $\beta = \sum b_s x_s$ be two elements of $M.$ I want to show that (*) implies that for any $s \in S$ the products $$a_{s'}b_{s''}$$ with $s'+s''=s$ are almost all zero. Does anyone have a short proof of this fact?","['abstract-algebra', 'summation', 'real-analysis']"
1396401,"Fraction field of $F[X,Y](f)$ isomorphic to $F(X)[Y]/(f)$","Assume $F$ is a field and $f$ is an irreducible polynomial in $F[X,Y]$ which involves the variable $Y$. Then, by Gauss's lemma, $f$ is irreducible also in $F(X)[Y]$ so that $F(X)[Y]/(f)$ is a field (where $(f)$ is the ideal generated by $f$). I'm looking for a simple way to see that the fraction field of the integral domain $F[X,Y]/(f)$  is isomorphic to $F(X)[Y]/(f)$.","['extension-field', 'abstract-algebra', 'field-theory', 'commutative-algebra']"
1396410,Why am I getting two answers for 8th root of continued fraction,"Find value of $x$: $x=\sqrt[8]{2207-\frac{1}{2207-\frac{1}{2207-....and\,so\, on}}}$ On solving ,we have $x^8=2207-\frac{1}{x^8}$ $x^8+\frac{1}{x^8}=2207$ $x^4+\frac{1}{x^4}=47$ $x^2+\frac{1}{x^2}=7$ $x+\frac{1}{x}=3$ $x=\frac{3+\sqrt{5}}{2}\,,\frac{3-\sqrt{5}}{2}$ But $x$ can take only one value. The problem is which of these two values is to be accepted/rejected and why.","['sequences-and-series', 'quadratics', 'continued-fractions', 'algebra-precalculus']"
1396446,Calculating $\int_0^{\infty} \frac{\log^2(1 - e^{-x})\:x^5}{e^x - 1} \: dx $ [duplicate],"This question already has an answer here : Compute this integral (1 answer) Closed 8 years ago . I am having trouble calculating the following improper integral:
$$\displaystyle \int\limits_0^{\infty} \frac{\log^2(1 - e^{-x})x^5}{e^x - 1} \, dx $$ Can someone give me a way that I can calculate this?","['improper-integrals', 'calculus', 'definite-integrals', 'integration']"
1396447,What's the kernel of the codiagonal $k[x] \otimes_k k[x] \rightarrow k[x]$?,"maybe this question is really stupid, but I could not solve it after thinking for a while. Let $I$ be the kernel of the codiagonal map $$k[x] \otimes_k k[x] \rightarrow k[x]$$ given by $f(x) \otimes g(x) \mapsto f(x)g(x)$. If $k$ is a field (and, hence, an integral domain), then $I = 0$. However it's know in algebraic geometry that the sheaf of relative differentials $\Omega_{k[x]/k} = I/I^2$ is isomorphic to $k[ dx]$ as a $k[x]$-algebra! So, clearly there's a problem here! What's wrong with my argument? Thanks in advance.","['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
1396481,"Show that there are numbers c and d such that F(A) = cTr(A^2) + d(Tr(A))^2,","Suppose F(A) is a quadratic function of a real symmetric matrix, A.  This means that there are numbers $f_{ijkl}$ so that F(A) = $\sum_{ijkl}f_{ijkl}a_{ij}a_{kl}$. Suppose that $F(A) = F(QAQ^t)$ for every orthogonal matrix, Q.  Show that there are numbers c and d so that $F(A) = cTr(A^2) + d(Tr(A))^2$.  Here, Tr(A) is the trace of A. Edited work: Since A is symmetric, then we know that A is orthogonally diagonalizable, so that there's an orthogonal matrix Q such that $QAQ^t$ = D, where D is a diagonal matrix with the eigenvalues of A on the main diagonal. Using the assumption that F is invariant under all orthogonal similarity transformations, including (of course) the transformations that diagonalize A, I have that: $$F(A) = F(QAQ^t)$$ $$= F(D)$$
$$=\sum_{i,j,k,l} f_{i,j,k,l}d_{ij}d_{kl}$$
$$=\sum_{i,k} f_{iikk}d_{ii}d_{kk}$$
$$= F(Q_1DQ_1^t)$$
$$= F(Q_2DQ_2^t)$$
$$= F(Q_3DQ_3^t)$$
$$....$$ $$=\sum_{i,k} f_{iikk}d_{ii}d_{kk},$$ where $Q_i$ is an orthogonal, permutation matrix, so that $Q_iDQ_i^t$ is swapping the eigenvalues on the diagonal, resulting in a permuted diagonal matrix, still with the eigenvalues of A on the main diagonal. Now, the problem reduces to proving the equation for diagonal matrices. As whacka stated in his answer below, considering only the permuted, diagonal matrices, then F defines a quadratic form in the variables $\lambda_i$, for $1\le i \le n$. So, we have $$ F(\lambda_1, ... \lambda_n) = \sum_{i,k} f_{iikk}\lambda_i \lambda_k $$ $$ = \sum_{i=k} \alpha_i (\lambda_i)^2 + \sum_{i,k} \beta_{ik}\lambda_i \lambda_k $$ $$ = \sum_{i=k} \alpha_i (\lambda_i)^2 + \sum_i \sum_k \beta_{ik}\lambda_i \lambda_k$$ $$ ?? = \sum_{i=k} \alpha_i (\lambda_i)^2 + \beta_{ik} (\sum_i\ \lambda_i\sum_k  \lambda_k) $$ $$ = \alpha_i Tr(A^2) + \beta_{i,k}(Tr(A))^2$$ $$=F(A)$$ And, since F is invariant under any permutation of the eigenvalues on the diagonal, then this quadratic polynomial is also invariant; hence, the coefficients $\alpha_i$ and $\beta_{i,k}$ exist, are well-defined, and unique. How is my proof?  I don't feel confident about the equality that I labeled (??).  But somehow, I have got to make that number, $\beta_{i,k}$ not dependent on the indices, in order to pull it outside of the summation, so that I can get my $(tr(A))^2$. Any hints or suggestions are welcome and greatly appreciated. Thanks,","['matrices', 'orthogonality', 'quadratics', 'linear-algebra', 'trace']"
1396485,"How to design/shape a polyhedron to be nearly spherically symmetrical, but not a platonic solid?","There are only 5 platonic solids, but take a look at these images: How are these things designed? How are they shaped? It looks to me like those hexagons are all the same size and shape, and evenly distributed to approximate a sphere. Same thing with the triangles in the second picture. So how is it possible? Are some of the hexagons actually slightly smaller or irregular? Can someone show me in the blueprint exactly where the properties of a platonic solid are NOT met?","['geometry', 'platonic-solids']"
1396532,"First sheaf cohomology $H^1(\mathscr{O}_D, \mathbb{D})=0$","Can I get a hint on this problem? Given a finite divisor $D=p_1+\dots +p_m -q_1 -\dots -q_n$ on the unit disk $\mathbb{D}$, how do I show that the first sheaf cohomology group $H^1(\mathscr{O}_D, \mathbb{D})=0$? I was first only considering effective divisors, which would make $\mathscr{O}_D$ a subset of the holomorphic functions. We can also pick a covering $(U_i)$ such that each $p$ is only contained in a single open set $U$. Then I could split any cochain $(f_{ij})$ into $g_j-g_i$ of holomorphic functions. Then I want to somehow get the functions $g_i$ to be zero at the necessary points, maybe by multiplying $g_i$ by $(z-p_i)$ locally in $U_i$. But this doesn't seem to be likely to work. My motivation for doing this is to show that on any compact riemann surface X, a covering $(U_i)$ where all the $U_i$ are isomorphic to disks is a leray covering relative to any sheaf of a divisor $\mathscr{O}_D$.","['algebraic-geometry', 'sheaf-cohomology', 'riemann-surfaces']"
1396568,"What, and how can, topological invariants can be computed from a space's algebra of functions?","The Gelfrand duality says that the category of locally compact Hausdorff spaces (with proper continuous functions) is equivalent to the category of commutative $C^*$ algebras (with proper $*$-homomorphisms).  For instance, of $X$ is such a topological space, then $C_0(X) = \{f: X\to \mathbb{C}, f$ is continuous and $f$ vanishes at $\infty \}$ is its related $C^*$ algebra.  We can go the other way by looking at a $C^*$ algebra $\mathcal{A}$ and taking its set of characters $\text{Hom}(\mathcal{A},\mathbb{C})$ under pointwise convergence to recover the topological space. So say one has a commutative $C^*$ algebra $\mathcal{A}$, how does one recover topological invariants, like say, the number of connected components of $\text{Hom}(\mathcal{A},\mathbb{C})=X$, from $\mathcal{A}$ itself? Is this even possible?  Or am I wrongly asserting that equivalence of categories says something about the individual objects? edit many responses focus on the number of connected components, which I appreciate, but that was only meant as an example of the sort qualitative info I would like to recover. Can we recover the singular homology of $X$ from $\mathcal{A}$ ? The fundamental group? Is X metrizable?","['noncommutative-geometry', 'operator-algebras', 'functional-analysis', 'general-topology', 'algebraic-topology']"
1396578,"Various definitions of ""topological immersion""","In Spivak's book on differential geometry he defines a topological immersion $f$ as ""$f$ is a continuous function that is locally one-one"". In my limited experience with the category $\mathsf{Top}$, this seems like the wrong definition, and I was wondering if anyone here agreed. Wouldn't the definition consistent with the $\mathsf{SM}$ definition be ""$f$ is a local homeomorphism onto its image""? It seems strange to think that for instance, every injective map into an indiscrete space falls under the heading of immersion.","['continuity', 'general-topology']"
1396600,"Derivative of $f(3x+1,3x-1)=4$","This exercise asks me to take the derivative of $$f(3x+1,3x-1)=4$$ where this equality is said to be valid for all $x$.
The exercise specifically asks me to prove that $$\frac{â}{âx}f(3x+1,3x-1)=-\frac{â}{âx}f(3x+1,3x-1)$$ The first thing I though was to apply the partial derivative operator to the both sides of the function: $$\frac{â}{âx}f(3x+1,3x-1)=\frac{â}{âx}4 \implies \frac{â}{âx}f(3x+1,3x-1) = 0 \implies \\ \frac{â}{âx}f(3x+1,3x-1) = - \frac{â}{âx}f(3x+1,3x-1)$$ but the exercise uses the chain rule, so I'm assuming that this can't be made. Could someone clarify for me what am I doing wrong here?","['partial-derivative', 'calculus', 'multivariable-calculus', 'derivatives']"
1396602,How can dimension reduction lead to better results?,Can someone please explain why a model fitted using a linear combination of the parameters can have better results (lower error) than a plain vanilla one with all the parameters? Can I think about this like adding a bunch of interaction variables to the model to get to better $R^2$?,"['statistics', 'machine-learning']"
1396608,Finiteness In Tonelli's And Fubini's Theorems,"Why do we suppose in Tonelli's Theorem that  $(X,ÃÂ£_X , ÃÂ¼_x)$ and  $(Y,ÃÂ£_Y , ÃÂ¼_y)$ to be ÃÆ-finite? Does the theorem fail when it is not? If yes, could someone provide an example? We also suppose in Fubini's theorem that : 
$\int_{XÃâY}|f(x,y)|$ $d(ÃÂ¼_xÃâÃÂ¼_y) < \infty$ Does that mean it is not true when the integral = $\infty$ ? If yes, could someone provide an exmaple?","['real-analysis', 'measure-theory']"
1396614,Linear independence and the Wronskian,"Suppose I have two linearly independent solution vectors \begin{bmatrix}x_1,_1(t)\\x_1,_2(t)\end{bmatrix} and \begin{bmatrix}x_2,_1(t)\\x_2,_2(t)\end{bmatrix} If I take the Wronskian of these 2 solution vectors, it comes out to a nonzero number since they are stated to be Linearly Independent. My question is, if you take the Wronskian of the same solution vectors but their derivative: \begin{bmatrix}x'_{1,1(t)}&x'_{2,1(t)}\\x''_{1,1(t)}&x''_{2,1(t)}\end{bmatrix} Would it still be linearly independent? (Would the Wronskian still be a nonzero number?","['wronskian', 'linear-algebra', 'ordinary-differential-equations']"
1396619,Residue theorem for line segment,"I am working through this problem:- Show that $\int_0^ \infty \frac{1}{1+x^n} dx= \frac{ \pi /n}{\sin(\pi /n)}$ , where $n$ is a positive integer. I follow it all, except for part (3) - I think this must a technique I haven't encountered yet, why does the integral on the incoming ray tend to $ -e^{\frac{2 \pi i}{n}} \int_{0}^{\infty}\frac{dx}{1+x^n} $ ? I tried - because the function is analytic, it is path independent - $ \lim_{{R}\to{\infty}}  \int_{R}^{0}f(z)dz = f(0) - f(R) $. Not promising. What I can sort of see, might be to paramerterize $ z= Re^{\frac{2 \pi i}{n}}, dz=e^{\frac{2 \pi i}{n}}dR $
and then find $ \lim_{{R}\to{\infty}} e^{\frac{2 \pi i}{n}} \int_{0}^{R}\frac{dR}{1+R^ne^{2 \pi i}}$ but thats no better than the original problem.  A hint on the approach would be very helpful, thanks",['complex-analysis']
1396639,Sum of (arithmetic?) infinite series,"How the heck do I find the sum of a series like $\sum\limits_{n=3}^\infty\frac{5}{36n^{2}-9}$? I can't seem to convert this to a geometric series and I don't have a finite number of partial sums, so I'm stumped.",['sequences-and-series']
1396640,Show $\frac{d^2x}{dt^2}=(1+\cos x)(x+\sin x)$,Show $\dfrac{d^2x}{dt^2}=(1+\cos x)(x+\sin x)$ given $\dfrac{dx}{dt}=x+\sin x$. Thought it would just be $(1+\cos x)$.,"['calculus', 'ordinary-differential-equations', 'derivatives']"
1396649,"Prove or disprove: If the positive integer m divides the positive integer n, then the Fibonacci number $f_{m}$ divides $f_{n}$","I have $f_{n}=f_{n-1}+f_{n-2}; f_{n}= [0,1,1,2,3,5,8,13,21,34,55,89,144,233,...]$ for which I note that indeed, 2 divides 4, and $f_{2}$ divides $f_{4}$. I am wondering if a proof by induction is sufficient, and exactly how would I go about doing that in this case? Or could I use the closed form formula to prove it: $\dfrac {1} {\sqrt {5}} [( \dfrac {1+\sqrt {5}} {2}) ^{n}-( \dfrac {1-\sqrt {5}} {2}) ^{n}]$ Thanks!",['discrete-mathematics']
1396661,Is there any interesting relationship between a Hermitian matrix and its corresponding entrywise absolute?,"In general, a Hermitian matrix can have complex off-diagonal terms. Given any Hermitian matrix $[A]_{n,m}$, I can construct another matrix $[\vert A\vert ]_{n,m} =\vert A_{n,m} \vert$. I would like to know if there are any known relationships between two such matrices. Some more specific questions that I was thinking about but don't have an answer to are the following: Is it possible to transform using a unitary $UAU^{\dagger}$ or using a convex combination of unitary matrices $\sum_i p_i U_iAU_i^{\dagger}$ where $\sum_i p_i =1$? It seems to be possible for $2 \times 2$ positive semi-definite matrices. Are there any inequalities relative their trace norms $\operatorname{tr}(\sqrt{A^\dagger A})$ and $\operatorname{tr}(\sqrt{\vert A \vert^\dagger \vert A \vert})$? Such as if one is always bigger than the other. Any information will be helpful for general Hermitian matrices will be helpful, but if you would like to know, I am looking at two special cases matrices right now: a) $A$ is a positive definite matrix. b) $A$ is a hollow (zero main diagonal), banded, Toeplitz and Hermitian matrix  that looks like the following: \begin{bmatrix}
0 & a_1 & a_2 & \ldots & a_n \\
a_1^* & 0 & a_1 &\ldots & \vdots \\
a_2^* &a_1^* & 0 & \ldots &\vdots \\ 
\vdots & & & \ddots & \vdots\\
a_n^* & a_{n-1}^* & a_{n-2}^* &\ldots &0
\end{bmatrix} Thanks for all your help.","['eigenvalues-eigenvectors', 'normed-spaces', 'linear-algebra', 'matrices']"
1396669,Finding the derivative of an absolute value,"This one I just don't know how to derive. $\ln\|x^4\cos x\|$ I know the derivative of $\ln\ x$ , is just $\frac{1}{x}$ . It is the absolute value that throws me off. My question is, does the absolute value stay as is or does it disappear? $\frac{1}{|x^4\cos x|}$ $\frac{1}{x^4\cos x}$ Or is there an extra step that I should preform?","['calculus', 'derivatives']"
1396676,Is axiom of choice necessary for proving that every infinite set has a countably infinite subset?,"Is it possible to prove the following fact without axiom of choice ? "" Every infinite set has a countably infinite subset"". 
Can it be proved that axiom of choice is necessary here ?","['elementary-set-theory', 'axiom-of-choice']"
1396703,"Manifold, exist smooth nonnegative function with regular value at 0?","If $X$ is any manifold with boundary, then does there exist a smooth nonnegative function $f$ on $X$, with a regular value at $0$, such that $\partial X = f^{-1}(0)$?","['manifolds', 'general-topology', 'differential-topology', 'differential-geometry', 'multivariable-calculus']"
1396765,Compute $\int_M \omega$,"Let $M=\{(x,y,z): z=x^2+y^2, z<1\}$ be a smooth 2-manifold in $\Bbb{R}^3$. Let $\omega=xdy\wedge dz+ydz\wedge dx+zdx\wedge dy\in \Omega^2(\Bbb{R}^3)$. Compute $$\int_M \omega.$$ I parametrised $M$ (up to a null-set) with $g(r,\theta)=(r\cos \theta, r\sin \theta,r)$ where $(r,\theta)\in (0,1)\times(0,2\pi)$, then computed $g^*\omega$ and found that it is zero, hence $$\int_M \omega = \int_{(0,1)\times(0,2\pi)} g^*\omega=0.$$ Is my result correct?
I feel like there might be an easier way to see that the integral is zero, avoiding finding an explicit parametrisation. Is that true? If so, how could one have argued?","['differential-topology', 'differential-forms', 'integration']"
1396772,$\int \frac{dx}{\sin x \sqrt{\sin(2x+\alpha)}}$,"$\int \frac{dx}{\sin x \sqrt{\sin(2x+\alpha)}}$ I tried: $\int \frac{dx}{\sin x \sqrt{\sin(2x+\alpha)}}=\int \frac{dx}{\sin x \sqrt{\sin2x\cos \alpha+\cos 2x\sin \alpha}}$ ,then i could not solve and changed the method. Let $\sqrt{\sin(2x+\alpha)}=u\Rightarrow dx=\frac{u du}{\cos(2x+\alpha)}$ $\int \frac{dx}{\sin x \sqrt{\sin(2x+\alpha)}}=$ But this way is also not working.Please help me suggesting the proper method.Thanks..",['integration']
1396816,Finite conjugacy classes in a certain group with three generators,"Def. We say that group G has non-trivial finite conjugacy class if there is a conjugacy class $C=\lbrace g_i \rbrace$ such that $g_i \neq 1$ of G with $|C|<\infty$. Let G be group $$<a,b,c \quad | \quad c^n=1, [a,b]=c >$$ Suppose $n>1$. How can I prove G has no non-trivial finite conjugacy class?","['abstract-algebra', 'group-theory']"
1396820,Does the fixed point in the Brouwer's Fixed-Point Theorem have to be an interior point?,"As the question suggests, does the fixed point in the Brouwer's Fixed-Point Theorem have to be an interior point? Many thanks in advance. To be clear, I'm using the statement of Brouwer's Fixed-Point Theorem from $\S$2.2 of Guillemin-Pollack, which is stated as follows. Any smooth map $f$ of the closed unit ball $B^n \subset \mathbb{R}^n$ into itself must have a fixed point; that is, $f(x) = x$ for some $x \in B^n$.","['differential-topology', 'fixed-point-theorems', 'differential-geometry', 'manifolds']"
1396822,"A compact, connected, abelian Lie group is a torus?","How to prove that a compact, connected, abelian Lie group is a torus? It seems very intuitive. Any reference?","['lie-groups', 'abstract-algebra', 'group-theory', 'manifolds', 'reference-request']"
1396839,find Limit $a_n= \frac{1}{n+1}+\frac{1}{n+2}+...+\frac{1}{n+n}$ [duplicate],"This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 8 years ago . show sequence $a_n= \frac{1}{n+1}+\frac{1}{n+2}+...+\frac{1}{n+n}$
converges to log2 my attempt: sequence $a_n$ is monotonic increasing 0<$a_n$<1/2 how to find limit?",['sequences-and-series']
1396842,What is the obstruction to extending a linear map on tangent spaces of a variety to a regular map on neighborhood?,"Suppose that $X$ and $Y$ are algebraic varieties of the same dimension $n$. If $p$ and $q$ are points in $X$ and $Y$ respectively, suppose that there is a linear map $i : T_p X \to T_q Y$. My vague question is this: What is the obstruction to ""extending"" $i$ to a map on Zariski open neighborhoods of $p$ and $q$, $f : U \to V$, with $df_p = i$? I ask this question because I have just learned a result in Riemannian geometry that could be interpreted as saying that curvature is the obstruction in the Riemannian case. (Do Carmo Riemannian Geometry pg. 157). In that setting one uses strongly the existence of exponential maps and parallel transport (and curvature!), so I don't expect anything to carry over literally. I am just curious if one can make a connection in this way. I know that one can always extend when the map $i$ is replaced by an $k$-algebra isomorphism of the germ of functions at those points.  (This is exercise 4.7 in Hartshorne.) So in a way I am asking the following commutative algebra question: If $(R,M)$ and $(S,N)$ are local $k$-algebras admitting an $k$-linear isomorphism $N/N^2 \to M/M^2$, what is the obstruction to extending this to an isomorphism of $R$ to $S$?","['algebraic-geometry', 'commutative-algebra']"
1396882,"Primitive polynomials $P$ with $\gcd(P(x),P(y))=1$ for infinitely many $x,y$","Characterize all primitive polynomials $P$ having integer coefficients such that there exist infinitely many natural numbers $x,y$ with $\gcd(P(x),P(y))=1$ NOTE: A primitive polynomial is defined as a polynomial whose coefficients are coprime. CONTEXT: I encountered the following problem a while ago. Let $P$ be a polynomial with integer coefficients such that $P(0)=0$ and $\gcd(P(0), P(1), P(2), \ldots ) = 1.$ Show there are infinitely many $n$ such that $\gcd(P(n)- P(0), P(n+1)-P(1), P(n+2)-P(2), \ldots) = n.$ I thought that the following lemma might be useful. LEMMA: If a polynomial $P$ is primitive, then there exist infinitely many naturals $x,y$ with $(P(x),P(y))=1$. Of course, as I soon figured out, the above lemma is wrong. An easy counterexample can be given using Fermat's little theorem. Just take $P(x)=x^p-x$, with $p$ a prime. The polynomial is primitive but has common factor $p$ for all $x$. I am pretty sure this is a famous result, but can't seem to find it. Any help regarding this will be appreciated. Thanks.","['polynomials', 'number-theory']"
1396888,How to integrate to find each function and its limit (if it exists)?,"Find the expression for following three functions and then evaluate their limit.
$$f(x,y) = \int\limits_y^x-\cos({\pi t})\ln{t}\quad dt\qquad\qquad x\gt y$$ $\mathbf 1.$
$$\lim\limits_{x\to\infty} f(x,1)$$ $\mathbf 2.$
$$\lim\limits_{n\to\infty} f(n+1,n)\qquad n\in\mathbb{N}$$ $\mathbf 3.$
$$\lim\limits_{n\to\infty} f(n,n-1)\qquad n\in\mathbb{N}$$","['calculus', 'limits', 'definite-integrals', 'functions', 'convergence-divergence']"
1396896,Number of non-decreasing functions?,"Let $A = \{1,2,3,\dots,10\}$ and $B = \{1,2,3,\dots,20\}$ . Find the number of non-decreasing functions from $A$ to $B$ . What  I tried: Number of non-decreasing functions = (Total functions) - (Number of decreasing functions) Total functions are $20^{10}$ . And I think there are ${20 \choose 10}$ decreasing functions. Since you choose any $10$ codomain numbers and there's just one way for them to be arranged so that the resultant is a decreasing function. However my answer doesn't match. Where am I going wrong? How can I directly compute the non-decreasing functions like without subtracting from total?","['permutations', 'algebra-precalculus', 'functions', 'combinations', 'combinatorics']"
1396919,Integral of $2^{2^{2^x}}$?,"$$\int2^{2^{2^x}}~\mathrm{d}x$$ Derivative is $\ln^3(2)2^{2^x+x+2^{2^x}}$. So no substitution technique can be used. So please guide, I am confused. Is this elliptic?","['derivatives', 'indefinite-integrals', 'integration']"
1396928,A fiber product is a fiber bundle,"Let $F,B$ be topological spaces. A fiber bundle $E$ over the basis $B$ with fiber $F$ is a topological space $E$ endowed with a continuous surjection $\pi:E\to B$ such that there exists an open cover $\{U_\alpha\}_\alpha$ of $B$ and homeomorphisms $\phi_\alpha:\pi^{-1}(U_\alpha)\to U_\alpha\times F$ such that $\pi=\pi_1\circ\phi_\alpha$, where $\pi_1:U_\alpha\times F\to U_\alpha$ is the projection on the first factor. Let $A,B,C$ general sets and $f:A\to C$, $g:B\to C$ be general maps. We define the fiber product of $f$ and $g$ as
$$
A\times_C B:=\{(a,b)\in A\times B:f(a)=g(b)\}
$$
Then define the projections $g':A\times_CB\to A$ and $f':A\times_CB\to B$. In my lecture notes it's written that i f $B$ is a fiber bundle over $C$ with fiber $F$ and projection $g$, then also $A\times_C B$ is a fiber bundle over $A$ with fiber $F$ and projection $g'$ . I want to prove this last statement. My idea is to suppose, first of all, $f,g$ continuous.
Then, if I prove that $f\circ g'=g\circ f$ (it immediately follows by definition of fiber product), we have that there is a morphism of fiber bundles between $B$ and $A\times_C B$, i.e. there exist $f':A\times_C B\to B$, $f:A\to C$ continuous map such that $f\circ g'=g\circ f$. Since there is a morphism of fiber bundles, then $f\circ g'=g\circ f$ must be a fiber bundle. Right?","['vector-bundles', 'fiber-bundles', 'general-topology', 'differential-geometry', 'algebraic-topology']"
1396990,How to simplify elegantly $\arcsin(2t-1)+2\arctan\left(\sqrt{\frac{1-t}{t}}\right)$?,"I currently try to simplify the following trigonometric expression:
$$
\arcsin(2t-1)+2\arctan\left(\sqrt{\frac{1-t}{t}}\right)
$$
where $t\in(0;1]$. I know that $\arctan(x)=\arcsin\left(\frac{x}{\sqrt{1+x^2}}\right)$ and I am also aware that there are formulas to simplify $\arcsin(x)+\arcsin(y)$, but they depend on different cases, as it can be seen here . Is there a rather elegant way to solve the problem? Any help is highly appreciated.","['calculus', 'trigonometry']"
1397011,"$\mathrm{Z}(\mathfrak{gl}(2,\Bbb F))$ where the Lie bracket is $[X,Y]=XY-YX$","I want to find $\mathrm{Z}(\mathfrak{gl}(2,\Bbb F))$ where the Lie bracket is $[X,Y]=XY-YX$ So then this will depend on the field, but no harm in direct computation for arbitrary matrices:
$$x=\begin{bmatrix}a&b\\c&d\end{bmatrix},y=\begin{bmatrix}\alpha&\beta\\\gamma&\delta\end{bmatrix}$$
$$[x,y]=\begin{bmatrix}a\alpha+b\gamma-\alpha a - \beta c&a\beta+b\delta-\alpha b-\beta d\\c\alpha+d\gamma -\gamma a - \delta c&c\beta + d\delta - \gamma b-\delta d\end{bmatrix}$$ I want to find $x\in\mathfrak{gl}(2,\Bbb F)$, $[x,y]=0,\forall y$ In $\Bbb C$ or $\Bbb R$, the only possible elements are $\begin{bmatrix}0&0\\0&0\end{bmatrix},I$ In $\Bbb Z_2$, the top left position gives us $b=c=0$, so $$[x,y]=\begin{bmatrix}a\alpha-\alpha a&a\beta-\beta d\\d\gamma -\gamma a &  d\delta -\delta d\end{bmatrix}$$ That's easier to handle and we get $d-a=a-d=0$, which means the centre is: $$Z(\mathfrak{gl}(2,\Bbb Z_2))=\left\{\begin{bmatrix}0&0\\0&0\end{bmatrix},I\right\}$$ How would I go about checking the centre for all fields? Will this always be the same?","['finite-fields', 'group-theory', 'lie-algebras', 'matrices']"
1397016,Does there exists an approximate identity in FrÃ©chet algebra $\mathcal{S}(\mathbb R)$?,"We put $\|f\|_{(N, \alpha)}:=  \sup_{x\in \mathbb R} (1+|x|)^{\alpha} | D^{\beta}f(x)|; $ and he Schwartz space, $S(\mathbb R): = \{f\in C^{\infty}(\mathbb R): \|f\|_{(N, \alpha)}< \infty , \forall \alpha, N \in \mathbb N \cup \{0\} \}.$ It is well-known that
(1) $\mathcal{S}(\mathbb R)$ is a FrÃ©chet space with the topology defined by the norms $\|\cdot\|_{(N, \alpha)}$ (2) $\mathcal{S}(\mathbb R) \ast \mathcal{S} (\mathbb R) \subset \mathcal{S}(\mathbb R).$ [For the proof you may see Folland , Real Analysis chapter 8] And we may say $\mathcal{S}(\mathbb R)$ is a FrÃ©chet algebra with respect to convolution. My naive questions are: (1) What is a notion of approximate identity in FrÃ©chet algebra $\mathcal{S}(\mathbb R)$ ? How to define it? (I am familiar with the notion of approximate identity in $(L^1, \ast)$ ; and in fact in $L^{1},$ the approximate identity is uniformly bounded; for instance take we may take, $\phi_{t}(x)=t^{-1}\phi(t^{-1 }x), t>0$ for $\phi \in L^{1}$ ) (2) Does there exists an approximate identity in $\mathcal{S}(\mathbb R)$ ? Is it uniformly bounded?","['banach-algebras', 'functional-analysis']"
1397018,Is $e^x=\exp(x)$ and why?,"In the comments to this question a discussion came up wether we have $e^x=\exp(x)$ by definition and what the ""correct"" definition of $\exp(x)$ is. Building on that, I want to line out the problem with this question and give one way to prove $e^x=\exp(x)$ for $x\in\mathbb R$. (Be warned: this is a long post)","['notation', 'calculus', 'definition', 'exponential-function']"
1397097,How to show that $L^p$ norm is monotone increasing?,"I am trying to solve the following (very standard) exercise: Let $(X,\mathcal M,\mu)$ be a measure space and $f\in L^r\cap L^\infty$ for some $1\leqslant r<\infty$. Then $f\in L^p$ for $1\leqslant p < r$ and $$\lim_{p\to\infty} \|f\|_p = \|f\|_\infty.$$ I have worked through the proof here: Limit of $L^p$ norm and find it satisfactory, however I am trying to take a different approach. I'd like to show that $$r\leqslant p \implies \|f\|_r\leqslant \|f\|_p$$ and then use monotone convergence to prove the result. I am stuck on how to prove this inequality though.","['lp-spaces', 'convergence-divergence', 'functional-analysis']"
1397099,"What is the probability that Raj and Rana have atleast 3 persons between them,given raj and rana are standing in a row and there are 9 peoples.","Question: Raj and Rana are standing in a row. There are 9 persons including Raj and Rana. What is the probability that at least 3 people will stand between Raj and Rana? My solution: $9$ people can be arranged in $9!$ ways. Excluding Raj and Rana, out of $7$ people. Case 1: I select 3 people $^7C_3$ who can be arranged in $3!$ ways. Remaining $(9-(3+2))=4$ people can be arranged in $4!$ ways Therefore required arrangement=$^7C_3*3!*4!*2!$   ----$(i)$ Case 2: I select 4 people $^7C_4$ who can be arranged in $4!$ ways Remaining $(9-(4+2))=3$ people can be arranged in $3!$ ways Therefore required arrangement=$^7C_4*4!*3!*2!$   ----$(ii)$ Case 3: I select 5 people $^7C_5$ who can be arranged in $5!$ ways Remaining $(9-(5+2))=2$ people can be arranged in $2!$ ways Therefore required arrangement=$^7C_3*5!*2!*2!$   ----$(iii)$ Case 4: I select 6 people $^7C_6$ who can be arranged in $6!$ ways Remaining $(9-(6+2))=1$ people can -be arranged in $1!$ way. Therefore required arrangement=$^7C_6*6!*1!*2!$   ----$(iv)$ Case 5: I select 7 people $^7C_7$  which can be arranged in $7!$ ways Remaining $(9-(7+2))=0$ people can be arranged in $1!$ ways Therefore required arrangement=$^7C_7*7!*1!*2!$   ----$(v)$ Adding equations $\frac{(i)+(ii)+(iii)+(iv)+(v)}{9!}$ we get the  required probability. Is it a correct approach and if there exists any shorter method, could you please tell me? Correct answer is $\frac5{12}$.",['probability']
1397120,Validity Michael Hardy's proof of Pythagoras Theorem using differentials,"A proof of the pythagorean theorem has been published by Mike Hardy during 1988 in Mathematical Intelligencer (Hardy, Michael, ""Pythagoras Made Difficult"". Mathematical Intelligencer, 10 (3), p. 31, 1988.). The proof can be found at https://en.wikipedia.org/wiki/Pythagorean_theorem under the section ""Proof using Differentials"". In this proof, Hardy is using an approximation and the proof is based on the fact that two triangles are approximately similar due to very small differentials. On the left image, the similar triangles are CDE and ABC. Based on that he derives into a differential equation that solving it produces the pythagorean theorem formula we all know. My question is regarding the validity of the approximation. If the same way of though is used for any non-right triangle as seen in the right image, you can derive the pythagorean theorem formula for any triangle and thus make a wrong assumption as the pythagorean theorem does not stand for non-right triangles. Thanks in advance.",['trigonometry']
1397131,Finding the $n^{th}$ derivative of $\frac{x^n}{(1+x)}$,"Find the $n^{th}$ derivative of $\frac{x^n}{(1+x)}$ .
I think we have to use Leibnitz's Formula to evaluate this, but I haven't succeeded in it as well. I have already received an answer of $\frac {x^n}{(1+x)}$, that was a bit simpler maybe, but I could not get this one...hope some one can help.","['closed-form', 'calculus', 'derivatives']"
1397132,"Why can't some integral be""found"" though they are anti-derivative & exist?","In my book, a list of integrals have been given which the author states ... such anti-derivatives ""cannot be found"". Some of the members of the list are as under: $\int\dfrac{\sin x}{x} dx$ , $\int\dfrac{1}{\log x} dx$, $\int\sqrt{1 - k^2\sin^2x}dx$, $\int\sqrt{\sin x}dx$, $\int\cos(x^2) dx$, $\int x\tan xdx$ , $\int e^{-x^2}dx$, $\int\dfrac{x^2}{1 +x ^5}dx$, $\int\sqrt{1 + x^3}dx$. The author only mentions that: ...not every anti-derivatives, even when it exists , is expressed in closed form .... Now, can anyone tell me why these integrals ""cannot be found""? Are they discontinous, non-differentiable or what? Also, what did the author mean by closed form ??","['intuition', 'integration']"
1397190,Find sum of $1 + \cos \theta + \frac{1}{2!}\cos 2\theta + \cdots$,Find the sum of following series: $$1 + \cos \theta + \frac{1}{2!}\cos 2\theta + \cdots$$ where $\theta \in \mathbb R$. My attempt: I need hint to start.,"['sequences-and-series', 'trigonometry']"
1397219,Does this functional equation have a non-trivial closed form solution?,"$$P(c \cdot x) = \cos(x) P(x)$$ For $c=2$, $P(x) = \sin(x)/x$ is a solution to this.  I don't know if there's a closed-form
solution for $c \ne 2$. Rather than add my own attempt at solution, which is dubious at best, I'll add context. I've been trying to solve a rather odd line integral here , and I ended up with a very nice infinite product solution. Robert Israel, put this solution into the form of recurrence relation. So, in attempt to continue the wild-goose-chase, I'm pursuing a solution for this recurrence relation. (I'll take any solution, as long as the ""special functions"" used are not tautological and have a public-access paper written about them)","['closed-form', 'recurrence-relations', 'trigonometry']"
1397224,Show that $n$ does not divide $2^n - 1$ where $n$ is an integer greater than $1$? [duplicate],"This question already has answers here : For $n \geq 2$, show that $n \nmid 2^{n}-1$ (4 answers) Closed 7 years ago . Show that $n$ does not divide $2^n - 1$ where $n$ is an integer greater than $1$ ? Clearly $2^n - 1$ is an odd integer, therefore, let $n$ be an odd integer and it divides $2^n - 1$ . We can write $2^n - 1 = (2-1)(2^{n-1} + \cdots \cdots + 1) = (2^{n-1} + \cdots \cdots + 1)$ From here on I don't know how to proceed?","['contest-math', 'number-theory', 'divisibility', 'elementary-number-theory']"
1397248,Mean value theorem for vector valued multivariable function,"In the general situation of $f:S\to \mathbb R^m$ where $S\subset \mathbb R^n$. There is a form of the mean value theorem: $a\cdot (f(y)-f(x))=a\cdot (f'(z)(y-x))$ which requires a vector $a$ and dot products. In Tom Apostol's Mathematical Analysis (Second Edition), page No. 355, I found that after choosing $a$ to be a unit vector and using Cauchy-Scwarz inequality, they have written $\parallel f(y)-f(x)\parallel\leq \parallel f'(z)\parallel \parallel y-x\parallel$. But how have they got rid of $a$ in the left hand side. If I choose the unit vector in the direction of the vector $f(y)-f(x)$, then it is possible, but how will it follow for an arbitrary unit vector? Please help!","['calculus', 'real-analysis', 'multivariable-calculus']"
1397255,"Integrating $ \frac{{ \int_{0}^{\infty} e^{-x^2}\, dx}}{{\int_{0}^{\infty} e^{-x^2} \cos (2x) \, dx}}$","I need help calculating the following integrals. For the top integral we can use the jacobin, right? But how do I calculate the bottom one?:
$$ \frac{{ \int_{0}^{\infty} e^{-x^2}\, dx}}{{\int_{0}^{\infty} e^{-x^2} \cos (2x) \, dx}}$$","['calculus', 'improper-integrals', 'multivariable-calculus', 'trigonometry', 'complex-analysis']"
1397259,"How can I complete this proof the cantor set does not meet $\left(\frac{3s+1}{3^k}, \frac{3s+2}{3^k}\right)$?","We define the cantor set $K$ as the set of all ternary numbers $0.{a_1a_2a_3\cdots}$ such that $a_i = {0, 2}$ for all $i$, i.e. no digit is allowed to be 1, and the first one is zero. Here is my proof in progress. Theorem For all $x \in K$, either $x \leq \frac{3s + 1}{3^k}$ or $x \geq \frac{3s + 2}{3^k}$ Proof We proceed by induction on $k$. (Base Case) For $k = 1$ we show that $x \in K$ implies $x \leq s + \frac{1}{3}$ or $x \geq s + \frac{2}{3}$ for all natural $s$. By case analysis on the first digit, either $x \leq \frac{1}{3}$ or $x \geq \frac{2}{3}$. Notice $x \leq \frac{1}{3}$ implies $x \leq \frac{1}{3} + s$ for all $s$. For $s \geq 1$, $s + \frac{2}{3} \geq \frac{5}{3} > 1$ and so there is no $x \in K$ such that $x \geq s + \frac{2}{3}$. (Inductive case)
Suppose that $x = 0.a_1a_2\cdots$. If $a_1 = 0$, then $3x \in K$ so by the inductive hypothesis we have two cases. The first case is $3x \leq \frac{3s + 1} {3^k}$  for all $s$, so $x \leq \frac{3s+1}{3^{k + 1}}$ for all $s$. The second case is that $3x \geq \frac{3s + 2}{3^k}$ for all $s$, so $x \geq \frac{3s + 2}{3^{k + 1}}$ for all $s$. Now here is where I get stuck. If $a_1 = 2$, then $3x - 2 \in K$, so we can apply the inductive hypothesis and similar reasoning to obtain that, for all $s$ either $x \leq \frac{3s + 1}{3^{k + 1}} + \frac{2}{3}$ or $x \geq \frac{3s+2}{3^{k + 1}} + \frac{2}{3}$. The problem is of course that rescaling the interval $[\frac{2}{3}, 1]$ to $[0, 1]$ ""shifts"" the $s$ value when compared to the intervals excluded in the previous step of the induction. I have an intuition that if $a_1 = 1$ it suffices to consider the case where $\frac{3s + 1}{3^{k + 1}} \geq \frac{2}{3}$, as the other cases are covered by the case where $a_1 = 0$, but I have no idea how to formalise this intuition. So could someone give me hints as to how to complete this proof, or at least how to formalise the aforementioned intuition?","['cantor-set', 'real-analysis', 'general-topology']"
1397274,Showing $U(n)/Z(U(n))=SU(n)/Z(SU(n))$,"I was working on the following problem from Stillwell's Naive Lie Theory . Prove that $U(n)/Z(U(n))=SU(n)/Z(SU(n))$. It was shown earlier in the text that $Z(U(n))=\{ e^{i\theta} \textbf{1}: \theta \in \mathbb{R} \} \cong S^{1}$ and $Z(SU(n))=\{ \omega \textbf{1}: \omega^{n}=1 \text{ and } \omega \in \mathbb{C} \}$.  We have that $\textbf{1}$ denotes the identity matrix. When thinking about this problem, I first considered the case where $n=2$. We have that unitary matrices in $U(2)$ are of the form
\begin{equation*}
e^{i\theta}
\begin{bmatrix}
\alpha &-\beta \\ \bar{\beta} & \bar{\alpha} 
\end{bmatrix}
\end{equation*}
We have that the relation which sends $e^{i\theta}
\begin{bmatrix}
\alpha &-\beta \\ \bar{\beta} & \bar{\alpha} 
\end{bmatrix}$ to $
\begin{bmatrix}
\alpha &-\beta \\ \bar{\beta} & \bar{\alpha} 
\end{bmatrix}$ seems to be a well defined function from $U(2) \rightarrow  SU(2)/Z(SU(2)$ since the center $Z(SU(2))$ consists of the matrices $\pm \textbf{1}$. This function even is a homorphism that  has $Z(U(2))$ as it's kernel. From here we can conclude that $U(2)/Z(U(2))=SU(2)/Z(SU(2))$ $\textbf{However, I am having trouble generalizing from here}$","['abstract-algebra', 'lie-groups']"
1397277,Commutativity in terms of the Jordan Normal Form.,"Let us consider requirements for commutativity of matrices in terms of the Jordan Normal Form, Say we have two matrices $\bf A$ and $\bf B$. Then ${\bf A} = {\bf S}^{-1}{\bf JS}$, where $\bf J$ can be written in block matrix form: $${\bf J} = \left[ \begin{array}{ccccc} {\bf \Lambda_1} & \bf 0 & \cdots & \bf 0  & \bf 0 \\ \bf 0 & \bf \Lambda_2 & \cdots &\bf 0 & \bf 0\\
\bf 0&\bf 0 &\bf \ddots & \bf 0 & \bf 0 \\ \bf 0&\bf 0&\cdots&\bf \Lambda_{n-1}& \bf0\\ \bf 0 &\bf 0&\cdots& \bf 0 & \bf\Lambda_n \end{array}\right] $$ where $$ {\bf \Lambda_k} = \left[ \begin{array}{ccccc} {\bf \Lambda_{k,1}} & \bf 0 & \cdots & \bf 0  & \bf 0 \\ \bf 0 & \bf \Lambda_{k,2} & \cdots &\bf 0 & \bf 0\\
\bf 0&\bf 0 &\bf \ddots & \bf 0 & \bf 0 \\ \bf 0&\bf 0&\cdots&\bf \Lambda_{k,m-1}& \bf0\\ \bf 0 &\bf 0&\cdots& \bf 0 & \bf\Lambda_{k,m} \end{array}\right] $$ where each $$ {\bf \Lambda_{k,l}} = \left[ \begin{array}{cccc} {\lambda_{k}} & 1 & 0 & 0  \\  0 & \lambda_{k} & \ddots & 0 \\
 0& 0& \ddots &  1  \\ 0& 0&0& \lambda_k \end{array}\right]$$ where the matrix size may be individual for each $l$. Let us now assume that we can write $\bf B = S^{-1}J_BS$. For which $\bf J_B$ will this commute? Any necessary or sufficient conditions? Clarification: I did not intend $\bf J_B$ to be a Jordan matrix like $\bf J$ above. Are there any other types of matrices for which it could work? What could we say about such a matrix? Does it need to have any specific type of block structure?","['jordan-normal-form', 'linear-algebra', 'matrices']"
1397283,If a line bundle admits a non-vanishing section then it is trivial,"Suppose $\pi:E\to B$ is a line bundle. Let $s:B\to E$ a non-vanishing section, i.e. for every $b\in B$ $s(b)\ne 0$ and $\pi\circ s=Id_B$. I have to prove that the line bundle above is trivial. Idea : Since $s$ is a section, for every $b\in B$, $0\ne E_b:=\pi^{-1}(b)=s(b)\cong\mathbb{R}$. I want to define an isomorphism between $E$ and $B\times\mathbb{R}$. Define
$$
F:B\times \mathbb{R}\to E\\
(b,\lambda)\mapsto \lambda s(b)
$$
How can I go on?","['vector-bundles', 'fiber-bundles', 'general-topology', 'differential-geometry', 'algebraic-topology']"
1397294,"Computing expectation of: $\small E\left[f(Z,U)e^{\frac{V^2-(V+W)^2}{2}} \right] $","Suppose we have three mutually independent random variables  $U,V,W$ where
$W \sim \mathcal{N}(0,1)$, $V \sim \mathcal{N}(0,c)$ and $E[U]=0$, $E[U^2]=1$. Lets define $Z=U+V+W$. Can we compute (or simplify) the following  quantity
\begin{align}
E\left[f(Z,U)e^{\frac{V^2-(V+W)^2}{2}} \right]
\end{align}
where $f$ is some deterministic function. For now I don't want to make any assumptions about $f$ but if we need to here are some assumptions that we can make: $f(Z,U)>0$ $0 \le E\left[f(Z,U)\right] \le 1$ I was thinking some thing like this \begin{align}
E\left[f(Z,U)e^{\frac{V^2-(V+W)^2}{2}} \right]&=
E\left[ E\left[f(Z,U)e^{\frac{V^2-(V+W)^2}{2}} \Big| Z,U\right] \right]\\
&=E\left[ f(Z,U)E\left[e^{\frac{V^2-(V+W)^2}{2}} \Big| Z,U\right] \right]
\end{align} Now the question is how to compute the quantity $E\left[e^{\frac{V^2-(V+W)^2}{2}} \Big| Z,U\right]$. The good think is that $V$ and $W$ is are Gaussian. Note that we can rewrite $E\left[e^{\frac{V^2-(V+W)^2}{2}} \Big| Z,U\right]=E\left[e^{\frac{-W^2-2VW}{2}} \Big| Z,U\right]$.
The above looks like a moment generating function (but conditioned) and is related to this question. Thank you in advance  for any help.","['probability-theory', 'conditional-expectation', 'probability', 'expectation']"
1397369,"Let $g(x)=f(x)+x$, where $f(x)$ is the Cantor function from $[0,1]$ to $[0,1]$. prove that $B$ is Lebesgue measurable but not Borel measurable.","Let $g(x)=f(x)+x$, where $f(x)$ is the Cantor function from $[0,1]$ to $[0,1]$. We know for the Cantor set $C$, $g(C)$ contains a nonmeasurable set A. Let $B=g^{-1}(A)$, prove that $B$ is Lebesgue measurable but not Borel measurable. I can show the first one since $B$ is the subset of a null set, which means $B$ is measurable. What about the second one?","['lebesgue-measure', 'real-analysis', 'measure-theory']"
1397378,The theory in probability,"Consider a real-life experiment (perhaps written as a problem in a textbook): A coin is continually tossed until two consecutive heads are observed. Assume that the results of the tosses are mutually independent and the coin is fair. What is the expected number of tosses before the experiment ends? Now, how would one solve this problem? First, we would need to define a probability space to model the experiment. The issue is that there are so many possibilities: We could define the sample space to be an uncountable set of all infinite-length strings of $H$ and $T$. This sample space already does not seem to fulfill the experiment's condition: that it terminates once two consecutive heads are observed. E.g. $HHTTTTT...$ and $HHHHHHH...$ are different outcomes in the sample space but are actually considered the same in the experiment (since we terminate after two heads). So to say that a sample space consists of all possible distinct outcomes of an experiment seem wrong to me. And yet, according to many sources, this is a natural space to use. Also, there can be infinitely many $\sigma$-algebras so there's the question of which one to use too. Lastly for the probability measure we can use the assumption that the coin is fair and the results of the tosses are independent so $P(\text{outcome starts with }TH) = P(\text{first toss is }T)P(\text{second toss is }H) = 0.25$, for example. We could take outcomes of the experiment to be the entire string of heads and tails from the start until termination of the experiment. So our sample space has all finite-length strings of $T$ and $H$ ending with $HH$, as well as infinite length strings that do not contain $HH$ as a substring. This space is uncountable, so again there are infinitely many $\sigma$-algebras. Now how do we define a probability measure? We should have $P(\text{outcome starts with }HHH) = P(\text{first toss is }H)P(\text{second toss is }H)P(\text{third toss is }H) = 0.125$ since the coins are fair and independent, but there are no outcomes starting with $HHH$ in this sample space, so this probability should actually be $0$. So my guess is that, instead we assume that $P(\text{$k$-th toss is heads | outcome starts with $s$}) = 0.5$, where $s$ is any $(k-1)$-length string containing no $HH$. Now this is stated nowhere in the given problem, and yet is very intuitive in the conventional sense of ""independence"" in the real world. Is this correct? We could only take the finite-length strings of $T$ and $H$ that end with $HH$, and ignore the infinite length strings. Now the question is: how do we know this is indeed the set of all outcomes? How do we know this is a valid assumption? Of course this simplifies a lot of things since the space is now discrete. We could even take the last 4 (or less) coin flips of finite runs as well as infinite runs as the sample space, so $$\Omega = \{HH, THH, \text{ends with }TTHH, \text{ends with }HTHH\}\cup \{s : s\text{ is an infinite string of $H$ and $T$}\}.$$ Now independence is defined only in the context of a probability space. So in this space we have $$\begin{eqnarray*}P(HH) &=& P(\text{last toss is }H \cap \text{2nd last toss is }H) \\&=& P(\text{last toss is }H)P(\text{2nd last toss is }H) \\&=& 0.25\\
P(THH) &=& 0.125\\
P(\text{ends with }TTHH) = P(\text{ends with }HTHH) &=& 0.0625.\end{eqnarray*}$$ So $P(\text{infinite string of $H$ and $T$}) = 1 - 0.25 - 0.125 - 0.0625 - 0.0625 = 0.5$. But clearly this does not conform to the above 3 models. So can we use this as a probability space? What is the issue here? Intuitively I can see how the probability spaces 1 to 3 all compute the same expectation. There are also countless other spaces that do too. The question is, is it possible to rigorize all this? It seems that each space above has some problems with it that raises the question of whether it is appropriate. Am I right to say that this portion relies completely on intuition and cannot possibly be rigorized? That is, the theory and mathematical rigor only starts after we have defined the probability space. Of course, then the question comes: how do we know our probability space ""works"" aside from intuition? Can we know that two different probability spaces will give us the same answer to a question? Also, am I right that there are actually way more assumptions in probability aside from the probability space? For instance: Independence in mathematical context is just $P(A \cap B) = P(A)P(B)$ but in real life we say that this means occurrence of $A$ does not affect probability of $B$ -- is this an assumption? $P(A | B) = P(A \cap B)/P(B)$ but in real life, we say $P(A | B)$ is the chance that $A$ occurs, given that $B$ has happened -- is this an assumption? The expected value of random variable $X$ is just defined as $E(X) = \sum_{\omega\in\Omega}P(\omega)X(\omega)$ in discrete spaces but in real life, we say it is the mean of $X$ if the experiment is repeated many many times -- is this an assumption? So all in all, there seems to be many assumptions in probability. So when does the theory start and end? EDIT: I've read a bit more about this issue and found that the reason why probability spaces give the same answer is likely due to them being extensions of each other. Terence Tao wrote about this once and if I'm not mistaken, the extension he talks about essentially shows the equivalence of the first 3 probability spaces I mentioned. Is this correct? According to this, independence should then be preserved under extension, so it doesn't make sense that independence ($P(A \cap B) = P(A)P(B)$) doesn't work under probability space 2 but works under 1. What I'm thinking might be the resolution is that when we state that ""the results of some coin tosses are mutually independent"", we are assuming that every single one of these independent coin tosses are performed in every single outcome . So in probability space 2, even though an outcome string might be of finite length, we assume that the other infinitely many coin tosses have also been performed (although their results are irrelevant for this outcome). Is this way of thinking correct? But now it seems strange that $P(\text{the $100$-th coin is heads}) = 0.5$, since after all the $100$-th coin is only tossed in the event that the $99$ coins before it do not contain consecutive heads. What is wrong here?","['probability-theory', 'axioms', 'independence', 'probability', 'mathematical-modeling']"
1397427,Existence of the law of a random variable,"Here is the definition of the law of a random variable. Let $X$ be a random variable on $(\Omega,\mathcal{F}, \mathbb{P})$. Then, the law of $X$, denoted by $L_{X}$, is a probability measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$ such that for all $B \in \mathcal{B}$, $L_X(B) = \mathbb{P}(X \in B)$, where $\mathcal{B}$ denotes the Borel set of $\mathbb{R}$. I understand the definition, but what I am wondering is that, how do we know such $L_X$ as in this definition exist? Can we construct one explicitly? or do we know, by some theorem, that at least one $L_X$ exists?","['probability-theory', 'probability']"
