question_id,title,body,tags
1547321,What's the importance of conics and quadrics in the context of a course of pure mathematics?,"I've studied conics and quadrics in the past (specifically, in a course of analytic geometry). For these courses, we usually learn the basics of linear algebra and we apply these to conics and quadrics. And then, there is something interesting: There are simple forms of a conics/quadrics in which every other conics/quadrics accross the euclidean space are isometric to it. By applying this isometry, it becomes easy to classify the conic/quadric and to obtain the coordinates of several important points as center, focal points, etc. This is interesting because it gives the idea that It's possible to simplify a lot of calculations on their quadratic forms to obtain their essential features and it could be very complicated to do it without these simplifications. The problem here is that this doesn't seems to be about conics, it seems to be about isometries/congruence. For the conics, we are introduced to certain properties of these curves, for example: If you pass a light through the focus of an ellipse, then it will reflect to the other focus. For every reflection comming to the interior of a parabola, it will always reflect to Its focus. But this seems to be more interesting to engineering/physics than to mathematics, this property is used to build better antennas, for example. I'm curious about two things: Where are these conic/quadric properties used in the context of pure mathematics? In general: What's the importance of conics/quadrics in a course of pure mathematics?","['geometry', 'conic-sections']"
1547326,What are we doing when we raise $10$ to some decimal number?,"This is something I am having some difficulty to understand. When I have $10^x$ where $x$ is some integer  greater than $0$ , I understand  that this is equivalent to write $$\underbrace{10\cdot 10 \cdot 10 \cdots 10}_{x  \text {times}} $$ but when I have the case that $10$ is raised to some decimal number  $x$ I really lack the intuition of what's going on here. I ask this question because ,for example ,when I read that $10^{0,48}=3,01...$ I simply don't understand how we have that $10$ raised to some number equals $3$.In general why is it that every number can be described as $10^x$ ? P.s I  guess it's important that I say that I am yet in high school,so you know what kind of answers might be appropriate for me.",['number-theory']
1547397,Can you determine a differential equation from its solutions?,"A linear first-order differential equation has two solutions:
  $$y_1(x)=x^2 \\y_2(x)=\frac{1}{x}$$ Determine the differential
  equation I did some research and I think I can use the wronskian to determine my original DE but I dont' really get how it works. Can someone show me how it's done? (It would be nice if you could use a different example so I can solve this question myself).",['ordinary-differential-equations']
1547447,"Looking for a Simple Argument for ""Integral Curve Starting at A Singular Point is Constant""","Let $U$ be an open subset of $\mathbf R^n$ and $V:U\to\mathbf R^n$ be a differentiable vector field on $U$. Let $\mathbf p\in U$ be a singular point of $V$, that is, $V(\mathbf p)=\mathbf 0$. Then the only integral curve which starts at $\mathbf p$ is the constant curve. I know that one could simply use the theorem of ""uniqueness of integral curves"" and in fact adapt the same proof for this particular case. But is anybody aware of a simple argument for this?","['analysis', 'real-analysis', 'ordinary-differential-equations']"
1547480,Fair die: Probability of rolling $2$ before rolling $3$ or $5$,"Independent trials consisting of rolling a fair die are performed, what is the probability that $2$ appears before $3$ or $5?$ There are $36$ cases if we take two trials like $11 12 13 14 15 16 
..21 22 23 24 25 26..31 32 33 34 35 36$ like this . But two has occurred before , so total $6$ cases , favourable just two$(23 25)$ so ${2\over 6} ={1\over 3}$
what is wrong in this approach , answer given is $3\over 8$ .",['probability']
1547487,Prove that the product of $n$ bounded and uniformly continuous functions are also uniformly continous [duplicate],"This question already has answers here : two functions are uniformly continuous on some interval I and each is bounded on I then their product is also uniformly continuous on I . [closed] (3 answers) If $f,g$ are uniformly continuous prove $f+g$ is uniformly continuous but $fg$ and $\dfrac{f}{g}$ are not (4 answers) Closed 6 years ago . Let $f_{1}(x),f_{2}(x),\dots,f_{n}(x)$ be $n$ bounded and uniformly continuous functions on $\mathbb{R}$. Prove that their product $f_1(x)f_2(x)\cdots f_n(x)$ is also a uniformly continuous function on $\mathbb{R}$ My approach is to use mathematical induction. At the last step, I need to prove that the product of two uniformly continuos functions (which are the product of the first $n-1$ uniformly continuous functions by inductive hypothesis and the $n^{\text{th}}$ function), which doesn't require me to use the fact the functions are bounded. So, I sense that this approach is not correct (but I'm not sure why) as I didn't use the fact that the functions are bounded. If it's really wrong, how do I make use of the fact that the functions are bounded? Thank you :)","['analysis', 'uniform-continuity']"
1547502,Find area of rectangle,"This is not kind of homeworks and please teke easy to consider. I found interesting problem which is very elementary but not easy (for me).
The problem is to find an area of this rectangle.
I have tried but don't know well...
Can you find it?","['geometry', 'area']"
1547505,Self-adjoint extensions of Laplacian over half line,"Let be $A=-\Delta$ the Laplace operator in $L^2(\mathbb{R}^+)$, with domain $D=\mathscr{C}^\infty_0(\mathbb{R}^+)$ the compact supported smooth functions. This operator $A$ isn't bounded, neither closed; but is symmetric in its domain and so is closable. I know that the operator is not essentially self-adjoint, but what is the domain of $A^*$? Moreover, analyzing deficiency spaces
$$Z_+ = \ker(A^* -i),\,\,Z_- = \ker(A^*+i)$$ 
I think they should be isometric by complex coniugate, but if I pick a basis $\{u_n\}$ of $Z_+$, how do I prove that $\{\bar{u}_n\}$ is a basis of $Z_-$? Is this sufficient to show that deficiency indices are the same and so conclude that $A$ has self-adjoint extensions? Thank you very much! EDIT. If my argument above is correct, how does look like a such extension of $A$? Is praticable to classify all the self-adjoint extensions using unitary operators in the well-known manner?","['real-analysis', 'functional-analysis']"
1547510,"If $J$ is tangent point of $GH$ with incircle of $FGH$ and $D$ is intersection of $F$-mixtilinear inclrcle with $(FGH)$, then $\angle FGH=\angle GDJ$.","Let $FGH$ be a triangle with circumcircle $A$ and incircle $B$ , the latter with touchpoint $J$ in side $GH$ . Let $C$ be a circle tangent to sides $FG$ and $FH$ and to $A$ , and let $D$ be the point where $C$ and $A$ touch, as shown here. Prove that $\angle FGH = \angle GDJ$ .","['euclidean-geometry', 'plane-geometry', 'geometry', 'triangles', 'circles']"
1547520,Separable version of Banach-Alaoglu,"My notes say that the theorem of Banach-Alaoglu states the following:
If $X$ is a normed separable space, then every bounded sequence in $X'$ has a weak-* convergent subsequence. How is this equivalent to the usual formulation from Wikipedia, etc - i.e. the closed unit ball being weak-*-compact, for a (not necessarily separable) normed space $X$? Or is it a special case?",['functional-analysis']
1547553,Why does the domain and range of $\sqrt x$ contain only positive real numbers?,"Consider the function $f(x)=\sqrt x$. Pretty much every resource I can find gives its domain as $\{x\in \mathbb{R} \mid x \ge 0\}$ and its range as $\{y\in \mathbb{R} \mid y \ge 0\}$ I don't see why the domain needs to be restricted to positive numbers. Isn't the square root of a negative number defined? That is, the square root of a negative number is a complex number of the form $a + bi$. So why isn't the domain of $f(x)=\sqrt x$ instead $\{x\in \mathbb{R}\}$ and its range $\{y\in \mathbb{C} \mid y \ge 0\}$? What am I missing?","['elementary-set-theory', 'real-analysis', 'functions']"
1547593,Find the limit $\lim_\limits{x\to 0^+}{\left( e^{\frac{1}{\sin x}}-e^{\frac{1}{x}}\right)}$,"Find the limit:
  $$\lim_\limits{x\to 0^+}{\left( e^{\frac{1}{\sin x}}-e^{\frac{1}{x}}\right)}$$ Using graph inspection, I have found the limit to be $+\infty$, but I cannot prove this in any way (I tried factorizing, using DLH)... Can anyone give a hint about that? The limit should be done without any approximations, because we haven't been taught those yet.",['limits']
1547602,Can you solve $y'+x+e^y=0$ by series expansion?,"Find an approximate solution by series expansion of $y(x)$ around $x =
0$ up to fourth order in $x$ given the inital conditions $y(0)=0$ Let 
$$
y=\sum_0^{\infty}a_nx^n \implies y'=\sum_0^{\infty}a_n nx^{n-1} \\ 
\implies \sum_0^{\infty}a_n nx^{n-1}+x+e^{\sum_0^{\infty}a_nx^n}=0
$$ Usually I would try to combine my terms but I can't do it here. Is this even the right approach?",['ordinary-differential-equations']
1547668,Prove continuity/discontinuity of the Popcorn Function (Thomae's Function).,"I have to prove that a function $f:]0,1] \rightarrow \Bbb R$ :
$$
f(x) =
\begin{cases}
\frac1q,  & \text{if $x \in \Bbb Q$  with $ x=\frac{p}q$ for $p,q \in \Bbb N$ coprime} \\
0, & \text{if $x \notin \Bbb Q $}
\end{cases}
$$ is discontinuous in every point $x \in \ ]0,1] \cap\Bbb Q$. And then to consider $x \in \ ]0,1] \backslash \Bbb Q$ and prove that it is continuous. For now I learned different ways to prove continuity (epsilon-delta, sequences), but I'm never sure what would be better to use in each different case. I wanted to prove the discontinuity by using sequences:
$$\forall x_n \quad x_n\rightarrow a \quad \Rightarrow \quad f(x_n) \rightarrow f(a)$$ I tried creating a sequence $ x_n=\frac1n + a$, we know it converges to $a$ but $f(x_n)\ $ doesn't  converges to $\ f(a)$ because there would still be some points not in our set (irrational numbers that creates gaps). But I don't think it works, so I'm asking you if you could help me solving the two questions.","['sequences-and-series', 'continuity', 'real-analysis']"
1547698,What's the multiplier to morph the ramp of a sine wave period?,Let say I've this sine wave (which is sin(x * 2) ): and I want to increase/decrese the ramp such as (sorry for my paint): I need to multiply the argument for... what? Tried log(x) but I get strange results.,['functions']
1547715,Linear functions and intersections of null subspaces,"Let $V$ be a vector space of a finite dimension $n$ over the field $K$. Let $\phi, \psi$ be two non-zero functionals on $V$. Assume that there is no non-zero element $c \in K$ such that $\psi= c \phi$. Show that $\ker \phi \cap \ker \psi$ has dimension $n -2$. There is a coordinate-based argument I know, which I am not writing out here, but I do not like these as they are a little hard to generalize to other situations. If you have a nicer coordinate free argument you may share it. Here is my coordinate-free argument: Define $f: V \rightarrow K \times K: f(v) = (\phi (v), \psi (v))$. Then $f$ is non-zero since both $\phi$ and $\psi$ are not and also the dimension of $f(V)$ cannot be $1$ since there exists no non-zero $c$ such that $\psi = c\phi$. Hence, $\dim f(V) = 2$ and $ \ker f = \ker \phi \cap \ker \psi $ so that by the Rank-Nullity Theorem we get the result.","['vector-spaces', 'duality-theorems', 'linear-transformations', 'matrix-rank', 'linear-algebra']"
1547719,Number of ways to pair off $2n$ points such that no chords intersect,"For $n \geq 0$ evenly distribute $2n$ points on the circumference of a circle, and label these point cyclically with the numbers $1, 2 . . . , 2n$ Let $h_n$ be the number of ways in which these $2n$ points can be paired off as $n$ chords where no two chords intersect I want to find a recursive formula for $h_n$. First I find $h_1,h_2,h_3$ to see the recursive nature. $h_1 = 1$ as their only one way to make one chord $h_2 = 2$ Now $\require{enclose}
     \enclose{horizontalstrike}{h_3=4}h_3=5$ ((1,4), (2,3), (5,6) case is missed in image) I found a wikipedia link Motzkin numbers and it is very close to my problem, But in this link you don't need to pair off $n$ chords. But I can't get to come up with a recursive formula for my question. If I would to guess I would say $h_n = 2 \times h_{n-1}$, And would this means that $h_4 = 8$ ??","['discrete-mathematics', 'catalan-numbers', 'combinatorics', 'recurrence-relations']"
1547720,How to Evaluate $\lim_{x\to0}\frac{(1-x)^{1/3}-1}{4^x-3^x}$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How to find this limit without using L'Hospital rule $$\lim_{x\to0}\frac{(1-x)^{1/3}-1}{4^x-3^x}$$","['limits-without-lhopital', 'limits']"
1547747,Sequence of bounded functions or pointwise bounded,"We have sequence of function $\{f_n(x)\}$ defined on set $E$ and $n\in \mathbb{N}$. What does mean sequence of bounded functions ? Is it pointwise bounded ? Definition: We say that $\{f_n\}$ is pointwise bounded on $E$ if the sequence $\{f_n(x)\}$ is bounded for every $x\in E$, that is, if there exists a finite-valued function $\phi$ defined on $E$ such that $$|f_n(x)|<\phi(x) \quad (x\in E, n\in \mathbb{N}).$$ Can anyone explain to me please?",['real-analysis']
1547804,Cauchy's Theorem - Prove that $\sum_{n=1}^\infty \frac{1}{\lambda_{n}^2} $ = $\frac{1}{10}$,"I seek to prove that $$\sum_{n=1}^\infty \frac{1}{\lambda_{n}^2}   = \frac{1} {10},$$ by applying Cauchy Theorem to $$ f(z) =  \left(\frac{z\tan(z)}{z-\tan(z)}+\frac{3}{z}\right) \frac{1}{z^2},$$ where $\lambda_n$ are positive solutions to $\tan(x) = x$. How can I solve this?","['complex-integration', 'complex-analysis', 'complex-numbers']"
1547867,Differentiable limit theorem of a Continuous nowhere differentiable function,"I am looking at Abbott's second edition of Understanding Analysis , and I am unsure if my answer is accurate. Exercise: The function $g(x) =\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}$ has been used as an example of a continuous nowhere differentiable function. What happens if we try to use the Differentiable Limit Theorem to explore whether g is differentiable? My solution: $g(x) =\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}$ $g'(x) =\frac{d}{dx}\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}=\sum_{n=0}^{\infty}\frac{d}{dx} \frac{\cos (2^{n}x)}{2^{n}}$ Consider the nth term $y =\frac{\cos (2^{n}x)}{2^{n}}$ Let $\Delta x$ be a small increment given to $x$, and $\Delta y$ the corresponding increment in $ y.$ $\Delta y=\frac{\cos (2^{n}(x+\Delta x))}{2^{n}}-\frac{\cos (2^{n}x)}{2^{n}}$ $=\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x) \sin 2^{n-1}\Delta x)$ Divide by $\Delta x$ $\frac{\Delta y}{\Delta x}=\frac{1}{\Delta x}\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x) \sin 2^{n-1}\Delta x)$ As $\Delta x$ tends to $0$, $\frac{\sin \Delta x}{\Delta x}$ tends to $1$ $=\frac{\Delta y}{\Delta x}=\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x))2^{n-1}$ $= (-2 \sin 2^{n-1}(2x))$ Thus it gives some answer for derivative of nth term","['real-analysis', 'derivatives']"
1547868,Which version of Taylor Theorem is this?,"Suppose $X$ is a random variable and $\psi(t)=E[\exp(itX)]$ is its characteristic function. Let $K(t)$ be the principal value of the logarithm of $\psi(t)$. Suppose further that $E(|X|^{r+2})<\infty$ for some integer $r\geq 0$. Then, my reading material (the question is self-contained, link included for completeness) claims that the Taylor's Theorm implies
$$
K(t)=\sum_{j=0}^{r+2}\kappa_j\frac{(it)^j}{j!}+o(\tau^{r+2}),\quad t\in\mathbb{R},
$$
where
$$
\kappa_j=\frac{K^{(j)}(0)}{i^j},\quad j=0,\ldots,r+2,
$$
are the cumulants of $X$. Question : which version of Taylor's Theorem is this and where can I find its rigorous statement (and proof)? (preferred source: textbook) I only know 2 verions of Taylor's Theorem: one deals with real functions of real variables (univariate or multivariate) and one deals with holomorphic functions. As $K$ may not have all of its derivatives, I don't think the latter applies.","['probability-theory', 'taylor-expansion', 'asymptotics', 'reference-request', 'complex-analysis']"
1547875,Does convergence in distribution of components imply convergence for the random vector too?,"If $X_1,X_2,\ldots$ are $\mathbb{R}^d$-valued random variables such that along each component $j:1 \leq j \leq d,$ we have $\{(X_n)_j\} \xrightarrow{\mathcal{D}}U[0,1]$, where $U[0,1]$ denotes the uniform random variable on $[0,1].$ Can we say that $\{X_n\} \xrightarrow{\mathcal{D}}U[0,1]^d$ ? Does the converse hold true ? i.e, if $\{X_n\} \xrightarrow{\mathcal{D}}U[0,1]^d$ then does $\{(X_n)_j\} \xrightarrow{\mathcal{D}}U[0,1]$ hold true ?","['probability-theory', 'weak-convergence', 'probability', 'probability-distributions']"
1547892,Prove that if A is M-matrix then A is also a P-matrix,"$A \in \mathbb{R}^{n \times n}$ is a $P$ -matrix if all its principal minors are positive. Let $I$ be the identity matrix of rank $n$ . $A \in \mathbb{R}^{n \times n}$ is a non-singular $M$ -matrix if $A=I-B$ where $B \in \mathbb{R}^{n \times n}$ has only non negative entries and the largest eigenvalue of $B$ (or maximum of moduli) is strictly smaller than one. Claim $1$ : Nonsingular $M$ -matrices are a subclass of $P$ -matrices. I am trying to prove claim $1$ . If we call $\mathbb{M}$ the set of non-singular $M$ -matrices and $\mathbb{P}$ the set of $P$ -matrices, then proving the above claim comes down to taking one (any) element of the set $\mathbb{M}$ and showing that this element also belongs to $\mathbb{P}$ . It seems long but doable for $n=2$ . Suppose $A=I-B \in \mathbb{M}$ . Take a matrix $B$ with non-negative entries $b_{11}=a$ , $b_{12}=b$ , $b_{21}=c$ , $b_{22}=d$ . We compute the largest eigenvalue of $B$ (case where $\Delta$ is zero or strictly positive gives 6 different cases to consider). For example for the case $\Delta =0$ with $a=d$ and $b=c=0$ we get $$\lambda_1=\lambda_2 = \frac{a+d}{2}$$ Since $A$ is in $\mathbb{M}$ we have the condition: $$ a < 1$$ For A to also be in $\mathbb{P}$ the following must be satisfied: $$ (1 - a)(1 -d) - bc \geq 0$$ $$\Leftrightarrow (1-a)^2 \geq 0$$ which is always true. Other cases get longer and messier. Then to suppose the hypothesis holds for n and show it for n+1 seems also long. any suggestions of a straight forward way to prove the claim ? Also for $n=2$ we can take $A \in \mathbb{P}$ and suppose that $A \not \in \mathbb{M}$ . We get a contradiction directly for the case $a=d$ and $b=c=0$ (and with more effort we check it for the other cases)... Thank you","['linear-programming', 'matrices']"
1547948,Are there $n$ groups of order $n$ for some $n>1$?,"Denote $N(n)$ : the number of groups with order $n$. Can $N(n)=n$ hold for some $n>1$ ? I checked the OEIS-sequence as well as the squarefree numbers $n$ in the range $[2,10^6]$ and found no example. For many $n$, we have $N(n)<n$ and for some $n$ we have $N(n)>>n$, for example for $n=512$ or $n=1024$. So, I do not see an obvious reason why the equality could not hold for some $n>1$.","['number-theory', 'group-theory', 'finite-groups', 'groups-enumeration']"
1547972,Why is $\sin(x^{2})$ similar to $\sin(x) \cdot x$?,"Why is $\sin(x^2)$ similar of  $\ x \sin(x)$? I graphed it using desmos and when I look at it, the behavior as x approaches zero seems to be to oscillate less. Yet as x approaches infinity and negative infinity $\sin(x^2)$ oscillates between y=1 and y=-1 while $\ x *sin(x)$ oscillates between y=x and y=-x. I was wondering why these functions are so similar yet so different. I'm in 10th grade and I""m currently learning precalculus so if answers could be targeted to a precalculus level that would be great.",['functions']
1547991,What's exactly the deal with differentials? (Confessions of a desperate calculus student),"So I don't know if I'm the only one to feel this, but ever since I was introduced to Calculus, I've had a slight (if not to say major) aversion to differentials. This sort of ""phobia"" started from the very first moment I delved into integrals. Riemann sums seemed to make sense, though for me they were not enough for justifying the use of ""dx"" after the integral sign and the function. After all, you could still do without it in practice (what's the need for writing down the base of these rectangles over and over?). I was satisfied by thinking it was something merely symbolic to remind students what they were doing when they calculated definite integrals, and/or to help them remember with respect to what variable they were integrating (kinda like the reason why we sometimes use dy/dx to write a derivative). Or so I thought. Having now been approached to differential equations, I'm starting to realize I was completely wrong! I find ""dy"" and ""dx"" spread out around equations! How could that be possible if they are just a fancy way of transcribing derivatives and integrals? I imagined they had no meaning outside of those particular contexts (i.e.: dy/dx, and to indicate an integration with respect to x or whatever). Could anybody help me out? I'm really confused at the moment. I'd really appreciate it :)  (P.S.: Sorry to bother you all on Thanksgiving - assuming some of you might be from the US.) EDIT: I don't think my question is a duplicate of Is $\frac{\textrm{d}y}{\textrm{d}x}$ not a ratio? , as that one doesn't address its use in integrals and in differential equations. Regardless of whether dy/dx is a ratio or not; what I'm really asking is why we use dx and dy separately for integration and diff. equations. Even if they're numbers, if they tend to 0, then dx (or dy) * whatever = 0. Am I wrong in thinking that way?","['derivatives', 'calculus', 'integration']"
1548043,"Royden Real Analysis, Chapter $3$ Proposition $9$","This is from Royden Real Analysis Chapter $3$ Proposition $9$ Page $60$ Let $f_{n}$ be a sequence of measurable functions on $E$ that converges pointwise almost everywhere on $E$ to the function $f$ . Then $f$ is measurable. In the proof author have introduced natural numbers $n$ and $k$ for which $f_{j}(x)<c-1/n$ for all $j\geq k$ The proof is completed by stating the following. 
Since the union of a countable collection of measurable sets is measurable $\left \{ x \in E | f(x)< c \right \}$ = $\bigcup_{1\leq k,n<\infty}$$[\bigcap_{j=k}^{\infty}\left \{ x\in E\left | f_{j}(x)<c-1/n \right \} \right]$ is measurable. Hence $f$ is measurable. I do not understand the purpose of introducing $n$ in this proof. Is it possible to avoid introducing $n$ and just use $f_{j}(x)<c$ and take union over $k$ alone.",['measure-theory']
1548047,"Closed form for ${\large\int}_0^\infty\frac{\arctan(x)\,\operatorname{arccot}(x+1)}{x}dx$","I'm looking for a closed form for this integral:
$$I=\int_0^\infty\frac{\arctan(x)\,\operatorname{arccot}(x+1)}{x}dx.$$ Mathematica and Maple could not evaluate it symbolically. Numerically,
$$I\approx1.3513049368715095284050230093075694014884142059538...$$ WolframAlpha and ISC+ could not find a plausible closed form for this number. Still, I hope that it exists, because the integral looks nice.","['calculus', 'closed-form', 'definite-integrals', 'trigonometry', 'integration']"
1548061,"Given any finite string of number, is it true there exists a perfect square whose leading numbers are the string","Given any finite string of number, is it true there exists a perfect square whose leading numbers are the string? For example, given the string 123456, can I find a perfect square with leading digits 123456? I think the answer is a positive one because number of integers with the string are infinite so one can keep increasing the number to obtain a perfect square?  Appreciate all advice, thank you","['decimal-expansion', 'algebra-precalculus']"
1548073,Fractional Sobolev Space Trace Inequality,"Let $\phi\in\mathcal{S}(\mathbb{R}^{n})$ be a Schwartz function, such that ${\phi}\equiv 1$ on the unit ball $|\xi|\leq 1$ and $\text{supp}({\phi})\subset B_{2}(0)$. Set $\phi_{0}=\phi$ and $\phi_{j}=\phi(2^{-j}\cdot)-\phi(2^{-j+1}\cdot)$ for $j\geq 1$. Write $P_{j}f:=(\widehat{f}{\phi}_{j})^{\vee}$. For $1<p<\infty$ and $s\in\mathbb{R}$, define the space $H^{s,p}(\mathbb{R}^{n})$ by
    $$H^{s,p}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \left\|\left(\sum_{j=0}^{\infty}2^{2js}|P_{j}f|^{2}\right)^{1/2}\right\|_{L^{p}}<\infty\right\}$$
One can show that $H^{s,p}$ is equivalent to the Bessel potential space $\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : ((1+|\xi|^{2})^{s/2}\widehat{f})^{\vee}\in L^{p}(\mathbb{R}^{n})\right\}$ with an equivalence of norms. $H^{s,p}$ is a special case of the Triebel-Lizorkin space $F_{p,q}^{s}$, where the $2$ above is replace by $0<q\leq\infty$. Similarly, for $0<p<\infty$, and $0<q<\infty$, we define the Besov space $B_{p,q}^{s}(\mathbb{R}^{n})$ by
    $$B_{p,q}^{s}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \left(\sum_{j=0}^{\infty}2^{jqs}\|P_{j}f\|_{L^{p}}^{q}\right)^{1/q}<\infty\right\}, \quad B_{p,\infty}^{s}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}'(\mathbb{R}^{n}) : \sup_{j}2^{js}\|P_{j}f\|_{L^{p}}<\infty\right\}$$ Using the following lemma, Lemma. Let $n\geq 2$. Suppose $f\in L^{p}(\mathbb{R}^{n})$ has Fourier support in the ball $|\xi|\leq R$, then $\|f\|_{L^{p}(\mathbb{R}^{n-1})}\leq R^{1/p}\|f\|_{L^{p}(\mathbb{R}^{n})}$ for $1\leq p\leq\infty$. I am trying to show that for $f\in\mathcal{S}(\mathbb{R}^{n})$, where $n>1$, the trace $f(\cdot,0)$ on $\mathbb{R}^{n-1}$ satisfies
    $$\|f(\cdot,0)\|_{H^{s-\sigma,p}(\mathbb{R}^{n-1})}\lesssim_{n,p,s,}\|f\|_{H^{s,p}(\mathbb{R}^{n})}\tag{*}$$
where $1/p<\sigma\leq s$. I can establish the lemma, and by applying the lemma to the Littlewood-Paley projections $P_{k}f$, I believe that I can show that for $f\in\mathcal{S}(\mathbb{R}^{n})$, we have
    $$\|f(\cdot,0)\|_{B_{p,q}^{s-1/p}(\mathbb{R}^{n-1})}\leq\|f\|_{B_{p,q}^{s}(\mathbb{R}^{n})}$$
where $1<p<\infty$, $1\leq q\leq\infty$, and $s>1/p$. Let us abuse notation, and write $f$ instead of $f(\cdot,0)$ for the trace of $f$ on the hyperplane $\mathbb{R}^{n-1}\subset\mathbb{R}^{n}$. Now we have the following embeddings, which can readily be verified from Minkowski's integral inequality and the nesting property of sequence spaces,
    $$B_{p,1}^{s}({\mathbb{R}^{m}})\hookrightarrow H^{s,p}(\mathbb{R}^{m})\hookrightarrow B_{p,\max\{2,p\}}^{s}(\mathbb{R}^{m}),\quad B_{p,q}^{s+\epsilon}(\mathbb{R}^{m})\hookrightarrow B_{p,r}^{s}(\mathbb{R}^{m})$$
for $1<p<\infty$, $0<q\leq \infty$, and $0<r\leq\infty$, $\epsilon>0$, and $m\geq 1$. Combining these two facts, we obtain that for any $s>\sigma>1/p$,
    $$H^{s,p}(\mathbb{R}^{n})\hookrightarrow B_{p,\max\{2,p\}}^{s}(\mathbb{R}^{n})\hookrightarrow B_{p,\max\{2,p\}}^{s-1/p}(\mathbb{R}^{n-1})\hookrightarrow B_{p,1}^{s-\sigma}(\mathbb{R}^{n-1})\hookrightarrow H^{s-\sigma,p}(\mathbb{R}^{n-1})$$
since $s-1/p>s-\sigma$. Note, implicitly I'm using the density of Schwartz functions in these spaces to obtain a bounded operator on the whole space, but this isn't an issue. I feel like there is a more direct and elegant route for establishing the trace inequality that doesn't make use of embeddings between the Sobolev space $H^{s,p}$ and the Besov spaces, which I am failing to see. Unfortunately, no one is around right now due to the holiday due to discuss the matter, so I thought I turned to Math SE for thoughts.","['besov-space', 'sobolev-spaces', 'functional-analysis', 'harmonic-analysis', 'littlewood-paley-theory']"
1548079,Problem in understanding the proof of Lebesgue-Radon-Nikodym Theorem,"On Folland's Real Analysis book page $90$, the Lebesgue-Radon-Nikodym Theorem is given as Let $\nu$ be a $\sigma$-finite signed measure and $\mu$ a $\sigma$-finite positive measure on $(X,\mathcal{M})$. There exists unique $\sigma$-finite signed measure $\lambda,\rho$ on $(X,\mathcal{M})$ such that $\lambda\perp \mu$, $\rho\ll\mu$, and $\nu=\lambda+\rho$. Moreover, there is an extended $\mu$-integrable function $f: X\to\mathbb{R}$ such that $d\rho=fd\mu$, and any two functions are equal $\mu$-a.e. To prove this theorem, we first can consider the case that $\nu$ and $\mu$ are ""finite"" and ""positive"". Then, we can extend that to the case where $\nu$ and $\mu$ are ""$\sigma-$finite"" and ""positive"". Finally, since $\nu = \nu^+ - \nu^-$, we can conclude that for signed measure $\nu$. But I have problem in understanding the second step. In this step, we can write $X = \cup_j A_j$ where $A_j$'s are disjoint and $\nu(A_j)< \infty$ and $\mu(A_j) < \infty$. Then, we can define, $\nu_j(E) = \nu(E \cap A_j)$ and $\mu_j(E) = \mu(E \cap A_j)$ where $\nu_j$ and $\mu_j$ are finite. So, from the results of the first step, we know that $\lambda_j\perp \mu_j$, $\rho_j\ll\mu_j$, and $\nu_j=\lambda_j+\rho_j$, $d\rho_j=f_jd\mu_j$. But then, it says that if we define $\lambda = \sum_j \lambda_j$ and $f = \sum_j f_j$, we have $\nu=\lambda+\rho$ where $d\rho = fd\mu$. We know that $\rho_j\ll\mu_j$ and $\lambda_j\perp \mu_j$. To show that $\rho\ll\mu$ and $\lambda \perp \mu$, is it true to say that since for every $j$, $\rho_j\ll\mu_j$ and $\lambda_j\perp \mu_j$, then
 we can conclude that $\sum_j\rho_j\ll \sum_j\mu_j$ and $\sum_j\lambda_j\perp \sum_j\mu_j$?","['lebesgue-measure', 'radon-nikodym', 'real-analysis', 'measure-theory']"
1548091,Asking for some exercises to help me understanding abelian varieties better?,"I want to study Mumford's Abelian Varieties in the coming winter break. I tried to study it before, but I didn't find my self really understanding(or memorizing) too much. I guess a better and more solid way to learn something is to go over many exercises. So I'm asking for some exercises(or problems?) on abelian varieties, it would be nice if I can get them online. Thanks in advance. And about the exercises: I wish it would be kind of like the ones in Hartshorne, so that I can solve them if I understand the material well. And not too hard, I guess I'm not looking for some research level questions... Also I wish those exercises may focus more on the algebraic/arithmetic side. I know the description above might seem a little picky, I'd be very appreciated if anyone has any idea or source about this, thanks again in advance...","['abelian-varieties', 'algebraic-geometry', 'reference-request', 'arithmetic-geometry']"
1548094,$f^m = f^k$ Proofs,"$1$. Prove that for any  $f :J_n → J_n $, there exists a positive integer $m$ such that $f^m = f^k$ for some positive integer $k < m$. $2.$ Let $f :J_n → J_n$ be a function, and let $m$ and $k$ be positive integers such that $f^m = f^k$
and $m > k$. Prove that the restriction of $f$ to $f^k(J_n)$ is a bijective function from $f^k(J_n)$ to $f^k(J_n)$ Note : $J_n$ represents the set consisting of the positive integers from $1$ to $n$. For  example $J_5=\{1,2,3,4,5\}$. For $1$, I know that $f^m = f^{m-k} \circ f^k$. But, I have no idea on how to proceed beyond that. Any help I can get is appreciated.","['proof-explanation', 'discrete-mathematics', 'real-analysis', 'functions', 'function-and-relation-composition']"
1548120,What is this notation? $V(\Bbb Z/p\Bbb Z)$,"I'm trying to write a blog post, and I've run into a stumbling block with notation. Is $V(\Bbb Z/p\Bbb Z)$ a standard notation in algebraic number theory? Does it mean a variety restricted to the integers mod $p$? If not, what does it mean / could it mean in this context? Context: I attended a lecture recently on Strong Approximation in number theory. The speaker began by talking about Markoff's surface
$$x^2+y^2+z^2-3xyz=0,$$
and told us about a group $\Gamma$ which generates the integral solutions of this equation. He then made a conjecture, which didn't seem to be tied to Markoff's surface in particular: Conjecture: The action of $\Gamma$ on $X(\Bbb Z_p)$ has precisely two orbits, one of which is $\{0\}$. After digging around online, I found notes for another talk he had given. On page 12, he defines $X^*(p)=V(\Bbb Z/p\Bbb Z)\smallsetminus\{0\}$, so I'm assuming my $X$ is that $X^*$ but with $\{0\}$ included. He defines ""$V$"" as the Zariski closure of an orbit $O\subseteq \Bbb Z^n$ on page 3, but I'm not sure it's the same $V$.","['algebraic-geometry', 'number-theory', 'notation', 'algebraic-number-theory']"
1548128,Arcsin domain under differentiation,"according to my solutions manual, the derivative of: $$ f(x) = \arcsin \left(\frac{a}{x}\right)$$ is $$f'(x) = \frac{-a}{x\sqrt{x^2-a^2}}$$ however, my work on this problem has found this answer to be incomplete: Knowing that the arcsin() function has domain ($-1 \le x \le 1$), shouldn't the answer be: $$f'(x) = \frac{-a}{|x|\sqrt{x^2-a^2}}  ; \quad x \ne 0  ?$$ (Please note the absolute value function $|x|$ on the denominator instead of using only $x$ and that $x = 0$ is not in the domain)","['trigonometry', 'derivatives']"
1548130,How would you differentiate this? I can't get anywhere,"Let's say that $F$ is a nice well-behaved function. How would I compute the following derivative? $\frac{\partial}{\partial t} \left\{ \int_{0}^{t} \int_{x - t + \eta}^{x + t - \eta} F(\xi,\eta) d\xi d\eta \right\}$ I'm guessing I need the fundamental theorem of calculus, but the double integral is REALLY throwing me off - especially that the $t$ is contained in the limits of both integrals. Can someone help me out? EDIT: Given the problem that this came up in, I have hunch that the above derivative is zero.","['derivatives', 'calculus', 'integration']"
1548133,prove that $n(n+1)$ is even using induction,"Prove that $n(n+1)$ is even using induction The base case of $n=1$ gives us $2$ which is even. Assuming $n=k$ is true, $n=(k+1)$ gives us $ k^2 +2k +k +2$ while $k(k+1) + (k+1)$ gives us $k^2+2k+1.$ whats is the next step to prove this by induction? I can't seem to show $ k^2 +2k +k +2$ = $k^2+2k+1$","['induction', 'proof-verification', 'discrete-mathematics', 'proof-writing']"
1548138,Limit as n to infinity of sum to n -- changing upper bound to infinity?,"I am just wondering if, in general, $$\lim_{n\to\infty} \sum_{i=1}^n x_i = \sum_{i=1}^\infty x_i$$ or perhaps it is specific to probability, where I am currently seeing it, such as
$$\lim_{n\to\infty} \sum_{i=1}^n P(B_i) = \sum_{i=1}^\infty P(B_i)$$
with $B_i$ all being disjoint sets, if that matters. Is this a definition? If it is, can someone provide me a credible link that confirms it? I believe you, but my google searching is not yielding any links that say it is a definition. If it is not a definition how could I prove it? It seems to me the standard $\epsilon$-$\delta$ definition of limit wouldn't be very helpful here, as we are not talking about the limit at a point but instead the limit is changing the number of terms summed... thats why I am leaning towards this being a definition. Thanks","['summation', 'arithmetic', 'probability', 'limits']"
1548164,Are $e^t$ and $\sin(t)$ dependent since the Wronskiian vanishes for certain t-inputs?,"I calculated the Wronskiian of $e^t$ and $\sin(t)$, and got $e^t\cos(t)-e^t\sin(t)$. This would be zero at $t = \sqrt{2}/2$. I know the Wronskiian has to be non-zero for the solutions to be independent; however, I still think the two solutions are independent in this case. Can someone please explain why or why I'm wrong? The differential equation is $y'''' - y = 0$. Thank you in advance!",['ordinary-differential-equations']
1548196,Number of squares in a certain grouping,"I got this problem from a professor for a class that I am taking, and I have made some progress on it but am not sure what to do now. Suppose I have a $2n \times 2n$ grid of unit squares where $n>1$ . Suppose we partition this grid into $2 \times 2$ contiguous grids of unit squares. We have a valid grouping of these squares if: At least one of the four squares in each $2$ x $2$ is in the grouping. For any pair of squares in the grouping, there exists a sequence of squares in the grouping that starts with the first square and ends with the second square and has any two consecutive squares sharing a side. What is the minimum number of squares in the grouping, in terms of $n$ ? After testing this for small values of $n$ , I think that it is $\left\lceil\frac{3n^2}{2}\right\rceil - 2$ . I got this through purely bashing out small cases and creating a function for it. How can I prove this is correct formula? (I think it's wrong...) If this is wrong, what is the actual formula, and proof?","['optimization', 'geometry', 'combinatorics']"
1548229,"Coordinate of $S(s,t)$ for Which Area of Quadrilateral is Maximum.","Let $P(-2,3)\;\;,Q(-1,1)\;\;,R(s,t)$ and $S(2,7)$ be $4$ points in order on the parabola $y=ax^2+bx+c$ . Then the coordinates of $R(s,t)$ such that the area of Quadrilateral $PQRS$ is maximum. $\bf{My\; Try::}$ Here $P(-2,3)\;,Q(-1,1)\;\;,S(2,7)$ be the points lie on the parabola $y=ax^2+bx+c$ So Put $(x,y) = (-2,3)$ in $y=ax^2+bx+c\;,$ We get $4a-2b+c=3.................(1)$ Similarly  Put $(x,y) = (-1,1)$ in $y=ax^2+bx+c\;,$ We get $a-b+c=1...........(2)$ Similarly  Put $(x,y) = (2,7)$ in $y=ax^2+bx+c\;,$ We get $4a+2b+c=7...........(2)$ Now Solving These three equation , We get $a=1\;,b=1\;,c=1$ So we get equation of parabola be $y=x^2+x+1$ Now $\bf{Area\; of\; Quadrilateral\; PQRS = Area\; of \; \triangle PQR+Area\; of \; \triangle PRS}$ So  Area Of Quadrilateral $$A(s,t) = \begin{vmatrix}
 -2& 3 & 1\\ 
 -1& 1 & 1\\ 
 s & t & 1
\end{vmatrix}+\begin{vmatrix}
 -2& 3 & 1\\ 
 s& t & 1\\ 
 2 & 7 & 1
\end{vmatrix}$$ So $$A(s,t) = 2s+t+1+20+4s-4t = 6s-3t+21$$ Now $R(s,t)$ lie on $y=x^2+x+1.$ So we get $t=s^2+s+1$ So we get $$A(s) = 6s-3(s^2+s+1)+21 = -3s^2+3s+18$$ So using Derivative Test $A'(s)=-6s+3$ and $A''(s)=-6$ So for Max. or min., Put $\displaystyle -6s+3=0\Rightarrow s=\frac{1}{2}$ and $\displaystyle t=\frac{1}{4}+\frac{1}{2}+1 = \frac{7}{4}$ My Question is can we solve it any Shorter way, Means Maximise area using Inequality or Geometrically If yes Then plz explain here. Thanks","['optimization', 'geometry', 'conic-sections', 'derivatives']"
1548257,Prove independence of events given random variables are iid and have continuous cdf,"Let $Y_1, Y_2, \ldots$ be independent and identically distributed random variables in $(\Omega, \mathscr{F}, \mathbb{P})$ s.t. their distributions are continuous. Denote common distribution a $$F(y) := F_{Y_1}(y) = F_{Y_2}(y) = \cdots$$ For $m = 1, 2, \ldots $ and $i \le m$ , define $$A_{i,m} := (\max\{Y_1, Y_2, \ldots, Y_m\} = Y_i), B_m := A_{m,m}$$ It can be shown that $$P(B_m) = P(A_{m-1,m}) = \cdots = P(A_{2,m}) = P(A_{1,m}) = 1/m$$ How do we rigorously establish independence of the $B_m$ 's? I get it intuitively: Given $\omega \in \Omega$ If $\forall i \le m, \omega \in B_i$ , then $\forall i \le m, (\max\{Y_1, Y_2, \ldots , Y_i\} = Y_i)$ , that is, $Y_i$ is the max among $Y_1, Y_2, \ldots , Y_i$ Now whether or not $\omega \in B_{m+1}$ ( $Y_{m+1}$ is the max among $Y_1, Y_2, \ldots , Y_{m+1}$ ) seems to be independent of whether or not $Y_i$ is the max among $Y_1, Y_2, \ldots , Y_i$ or even which among the $Y_1, Y_2, \ldots , Y_i$ is the maximum  because the $Y_n$ 's are independent. But how does one prove this rigorously? If I show that $\forall m \in \mathbb N$ , $$P(B_m\mid\sigma(B_1, \ldots, B_{m-1})) = P(B_m)$$ then we will have independence of the $B_m$ 's. I tried induction: Given $P(B_k\mid\sigma(B_1, \ldots, B_{k-1})) = 1/k$ , prove $$P(B_{k+1}\mid\sigma(B_1, \ldots, B_k))$$ I deduced that that is equivalent to: Given $P(B_k \cap C_k) = P(C_k)(1/k)$ , prove $$P(B_{k+1} \cap C_{k+1}) = P(C_{k+1}) (1/(k+1))$$ where $C_k \in \sigma(B_1, \ldots, B_{k-1})$ and $C_{k+1} \in \sigma(B_1, \ldots, B_{k})$ . It seems that in proving $P(B_{k+1} \cap C_{k+1}) = P(C_{k+1}) (1/(k+1))$ , we need to check only $C_{k+1} \in \sigma(B_{k})$ as $C_{k+1} \in \sigma(B_1, \ldots, B_{k-1})$ are already covered by assumption. So all I have to do is show that $P(B_{k+1} \cap B_k) = (1/(k)(k+1))$ and $P(B_{k+1} \cap B_k^C) = (k-1)/(k)(k+1)$ , the latter of w/c can be deduced from the former, which is proven by noting that $$P(B_{k+1} \cap B_k) := P(Y_k > Y_1, \dots Y_{k-1}; Y_{k+1} > Y_1, \dots Y_{k-1}, Y_k) = P(Y_k > Y_1, \dots Y_{k-1}; Y_{k+1} > Y_k)$$ and then making use of the iid of the $Y_n$ 's and evaluating: ( What if the pdfs don't exist? ) $$P(B_{k+1} \cap B_k) = \int_{\mathbb R} \int_{-\infty}^{y_{k+1}} \int_{-\infty}^{y_k} \cdots \int_{-\infty}^{y_k} \int_{-\infty}^{y_k} f(y_1)f(y_2) \cdots f(y_{k-1})f(y_k)f(y_{k+1}) \, dy_1 \, dy_2 \cdots dy_{k-1} \, dy_k \, dy_{k+1}$$ $$= \int_{\mathbb R} \int_{-\infty}^{y_{k+1}} [F(y_k)]^{k-1} f(y_k) f(y_{k+1}) \, dy_k \, dy_{k+1}$$ $$= \int_{\mathbb R} \frac{(F(y_{k+1}))^{k}}{k} f(y_{k+1}) dy_{k+1} = \frac{1}{(k)(k+1)}$$ Is that right? And if the pdf's don't exist , can we evaluate the ff? $$P(B_{k+1} \cap B_k) = \int_{\mathbb R} \int_{-\infty}^{y_{k+1}} \int_{-\infty}^{y_k} \cdots \int_{-\infty}^{y_k} \int_{-\infty}^{y_k} \, dF(y_1) \, dF(y_2) \cdots dF(y_{k-1}) \, dF(y_k)\,dF(y_{k+1})$$","['probability-theory', 'probability-distributions', 'measure-theory', 'continuity', 'independence']"
1548275,Examples of little Lipschitz functions,"Suppose that $(X,d)$ is a metric space. A function $f:X \rightarrow \mathbb{R}$ is called little Lipschitz if for all $\epsilon>0$, there exists a $\delta>0$ such that for all $x,y \in X$, 
$$d(x,y)<\delta \Rightarrow |f(x)-f(y)|\leq \epsilon d(x,y).$$ Question: What are the examples of little Lipschitz functions? When $X=\mathbb{R}$, I can only think of zero function as we have 
$$\dfrac{|f(x)-f(y)|}{|x-y|} \leq \epsilon$$
for all $\epsilon>0$.","['lipschitz-functions', 'definition', 'functional-analysis']"
1548276,Show that the system $\ddot x+x\dot x+x=0$ is reversible,"Show that the system $\ddot x+x\dot x+x=0$ is reversible My attempt was to use a property from the book that if the system $\dot x = f(x,y)$ $\dot y = g(x,y)$ is reversible then $f(x,-y)=-f(x,y)$ and $g(x,-y)=g(x,y)$. I tried to convert the system into a system like the one above by letting $\dot x=y$ $\ddot x=\dot y=-x-xy$ However, this system does not satisfy the second criteria, namely that $g(x,y)=-x-xy \ne g(x,-y)=-x+xy$ Is there another way to show that this system is reversible?","['dynamical-systems', 'ordinary-differential-equations']"
1548291,If $ \lim_{h\to 0}\frac{f(x+h)-f(x-h)}{h}$ exists then $f$ is differentiable,"TRUE or FALSE : If $f:\mathbb R\to \mathbb R$ be such that $\displaystyle \lim_{h\to 0}\frac{f(x+h)-f(x-h)}{h}$ exists for all $x\in \mathbb R$ then $f$ is differentiable. Let , $l=\displaystyle \lim_{h\to 0}\frac{f(x+h)-f(x-h)}{h}=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}+\lim_{h\to 0}\frac{f(x)-f(x-h)}{h}=f'(x)+\lim_{h\to 0}\frac{f(x)-f(x-h)}{h}$. Then ..??","['analysis', 'calculus', 'real-analysis']"
1548377,$d(\iota_v\rho)=0 \implies d(\phi\iota_v\rho)=d\phi(v)\rho$?,"My motivation is physical, but my question is purely mathematical. Everybody knows, that the power of the electric current in a piece of wire is $$P=UI$$ where the wire is regular domain $V$ in a 3-dimensional orientable differentiable manifold M: it is a flow tube between two level set pieces $A$ and $B$ of a function $\phi: M\to \mathbb R$, $U = \phi(B)-\phi(A)$. $I = \int_B\iota_v\rho$, where $v$ is a vector field: ths is the velocity field of the moving charges. $\rho$ is a 3-form: this is the charge density 3-form, so $\iota_v\rho$ is the current density 2-form. We suppose that the current is stationary, i.e. $d(\iota_v\rho) = 0$ the velocity field $v$ of the moving charges in the wire is everywhere tangent to the side wall of the tube. Because of these assumptions
$$0=\int_V d(\iota_v\rho) =\int_{\partial V}\iota_v\rho=\int_B\iota_v\rho+\int_A\iota_v\rho = 0$$ hence $\int_A\iota_v\rho = -I$. Because of assumption 2.
 $$\int_{\partial V}\phi\iota_v\rho=\int_B\phi\iota_v\rho+\int_A\phi\iota_v\rho = \phi(B)\int_B\iota_v\rho+\phi(A)\int_A\iota_v\rho = (\phi(B)-\phi(A))I=UI=P$$
By applying Stokes theorem, this means that
$$ P = \int_Vd(\phi\iota_v\rho)$$
On the other hand, we know also, that the power of the electric field $E=d\phi$ is
$$ P = \int_V E(v)\rho = \int_V d\phi(v)\rho$$ 
That's why I suspect that for any vector field $v$ and 3-form $\rho$ having $d(\iota_v\rho)=0$ and for any function $\phi$ $$d(\phi\iota_v\rho)=d\phi(v)\rho$$
Is this really true?","['differential-geometry', 'differential-forms']"
1548392,Can a metrizable TVS be induced by a non-translation invariant metric?,"Is it possible to have a topological vector space $(X, \tau)$ with its topology induced by a metric $d$ which is not translation invariant? I'm asking this because in Rudin's 'Functional Analysis' Theorem 1.28, he automatically assumed the metric of a metrizable TVS is translation invariant (he defined a metrizable TVS to be one which topology can be induced by a metric, no requirement on the metric being translation invariant or not). It seems that Rudin is usually careful about his assumptions, so I wonder if I'm missing something?","['functional-analysis', 'topological-vector-spaces']"
1548407,A trigonometric inequality: $\cos(\theta) + \sin(\theta) > 0$,"How can I find $\theta$ such that
$$\cos(\theta)+\sin(\theta)>0$$","['calculus', 'inequality', 'trigonometry']"
1548426,Why does $A \circ {B^{ - 1}} + {A^{ - 1}} \circ B \ge 2{I_{n \times n}}$?,"Let $A, B \in M_n$ be positive definite and $A \circ B = \left[ {{a_{ij}}{b_{ij}}} \right]$. Why does $A \circ {B^{ - 1}} + {A^{ - 1}} \circ B \ge 2{I_{n \times n}}$ ?","['linear-algebra', 'matrices']"
1548440,Book on Algebraic Spaces?,"I'm actually studying ""the geometry of scheme"" of Eisenbud Harris, after that I want to begin with a generalization of scheme that is algebraic spaces, I know only the book of Knutson ""Algebraic Spaces"", but, it can appear quite babyish, the character in which is written that book (that is the usual character of Springer's book) is very annoying to me. Other references?","['book-recommendation', 'algebraic-geometry', 'reference-request']"
1548454,Represent total variation of continuous function by integration of counting function,"$f : [a,b] \to \mathbb R$ is continuous, let $M(y)$ be the number of points $x$ in $[a,b]$ such that $f(x)=y$. prove that $M$ is Borel masurable and $\int M(y)dy$ equals the total variation of $f$ on $[a,b]$ This is an exercise in 'real analysis for graduate students'(Richard.F.Bass) At first time, I thought  $M(y)=\mu(\{x \mid f(x)=y\})$ where $\mu$ is counting measure. But I cannot find the relation between Borel measurability and $\mu(\{x \mid f(x)=y\})$ Is there anyone would help me?","['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
1548487,Is this a correct/good way to think interpret differentials for the beginning calculus student?,"I was reading the answers to this question, and I came across the following answer which seems intuitive, but too good to be true: Typically, the $\frac{dy}{dx}$ notation is used to denote the derivative, which is defined as the limit we all know and love (see Arturo Magidin's answer). However, when working with differentials, one can interpret $\frac{dy}{dx}$ as a  genuine ratio of two fixed quantities. Draw a graph of some smooth function $f$ and its tangent line at $x=a$ . Starting from the point $(a, f(a))$ , move $dx$ units right along the tangent line (not along the graph of $f$ ). Let $dy$ be the corresponding change in $y$ . So, we moved $dx$ units right, $dy$ units up, and stayed on the tangent line. Therefore the slope of the tangent line is exactly $\frac{dy}{dx}$ . However, the slope of the tangent at $x=a$ is also given by $f'(a)$ , hence the equation $$\frac{dy}{dx} = f'(a)$$ holds when $dy$ and $dx$ are interpreted as fixed, finite changes in the two variables $x$ and $y$ . In this context, we are not taking a limit on the left hand side of this equation, and $\frac{dy}{dx}$ is a genuine ratio of two fixed quantities. This is why we can then write $dy = f'(a) dx$ . By Brendan Cordy","['ratio', 'calculus', 'infinitesimals', 'ordinary-differential-equations', 'derivatives']"
1548495,Proof that product topology of subspace is same as induced product topology,"Let's assume that $A\subseteq X$ is product of $A_{i}\subseteq X_{i}(i\in I)$. Then product topology of $A$ is the same than the topology induced by $X$. I have proved this few different times now, and for this one I need help. I like to try all kinds of proofs. Collection $\mathcal{B}_{A}$ has sets $V:=\prod_{i\in I} V_i$, where $V_i\subseteq A_{i}$ by every $i\in I$ and $V_i\neq A_i$ finitely many $i$. Collection $\mathcal{B}_{X}$ has sets $\prod_{i}U_{i\in I}\cap \prod_{i}A_{i\in I}$, where and $U_{i}$ is element of basis of $X_{i}$. Notation $U:=\prod_{i}U_{i\in I}$. There is theorem that says $\mathcal{B}$ is basis for topology iff every open $U\subseteq X$ can be shown in the form
$$
U=\bigcup_{a\in A} B_{a},
$$
where $B_{a}\in\mathcal{B}$ for all $a\in A$. Now what I am trying to do in this proof attempt is that I want to try out the theorem above. There are problems with the notion and that is one main thing where I need tips. I hope that you get the idea what I am after here. Proof: $Z$ belongs in the product topology of $A$. $\Leftrightarrow$ 
$$
Z=\bigcup_{i\in I} \big(\prod_{i\in I} V_{i} \big)_{i}\quad\text{Where } V_{i}\in \mathcal{T}_{A_{i}}\text{ for all }i\in I.
$$
$\Leftrightarrow$
$$
Z=\bigcup_{i\in I} \big(\prod_{i \in I}U_{i}\cap A_{i} \big)\quad\text{Where }U_{i}\in\mathcal{T_{i}}\text{ for all }i\in I.
$$
$\Leftrightarrow$
$$
Z=\bigcup_{i\in i} (\prod_{i\in I} U_{i}\cap \prod_{i\in I} A_{i})_{i}
$$
$\Leftrightarrow$
$$
Z=\big(\bigcup_{i\in I}\big(\prod_{i\in I} U_{i} \big)_{i} \big)\cap \prod_{i\in I} A_{i}
$$
$\Leftrightarrow$ $Z$ belongs to product topology induced by $X$.","['solution-verification', 'product-space', 'general-topology']"
1548569,How do i solve $\frac{dy}{dx}- \frac {dx}{dy}= \frac {x}{y}-\frac {y}{x}$?,I came up with this question in my exam. But i didn't get it right. Can someone show me how to solve this differential equation $$\frac{dy}{dx}- \frac {dx}{dy}= \frac {x}{y}-\frac {y}{x}$$,['ordinary-differential-equations']
1548579,Convergence of Series Whose Terms are Defined Recursively,"My recursively defined sequence $(a_n)_{n\in\mathbb{N}}$ is given trough $$a_1 = 1, \quad a_2=\frac{1}{2}\quad a_{n+2}=a_{n}a_{n+1}\quad \text{for } n\geq1$$ and I have to show that the series $$\sum_{n=1}^{\infty}a_n$$ converges. I have 4 questions to my approach(es) I did to deal with that: I noticed that $a_n$ can be represented as $$a_n = 2^{-f_{n-1}}$$
whereas $f_n$ is the $n$-th Fibonacci number. For this claim I did this proof by induction: $$ n=1: a_1 = 1 = 2^0 = 2^{f_0} = 2^{-f_0} = 2^{-f_{1-1}} \\
 n=2: a_2 = \frac{1}{2} = 2^{-1} = 2^{-f_1} =  2^{-f_{2-1}}$$
and by multiplying the premises $A(n)$ and $A(n+1)$ in order to get $A(n+2)$
$$""n+1\to n+2"":\quad a_n \cdot a_{n+1}  = 2^{-f_{n-1}} \cdot 2^{-f_n} \quad\Longleftrightarrow\\  a_{n+2} = a_n \cdot a_{n+1} = 2^{-f_{n-1}} \cdot 2^{-f_n} = 2^{-(f_n + f_{n-1})} = 2^{-f_{n+1}}.$$
...is that valid? Given that $a_n = 2^{-f_{n-1}}$ is true I proceeded with the ratio test
$$q := \lim_{n\to\infty} \left|\frac{a_{n+1}}{a_n}\right| = \lim_{n\to\infty} \left|\frac{2^{-f_{n}}}{2^{-f_{n-1}}}\right| = \lim_{n\to\infty} \frac{2^{f_{n-1}}}{2^{f_{n}}} =\\
	= \lim_{n\to\infty} \frac{1}{2^{f_{n} - f_{n-1}}} = \lim_{n\to\infty}\frac{1}{2^{(f_{n-2} + f_{n-1}) - f_{n-1}}} = \lim_{n\to\infty}\frac{1}{2^{f_{n-2}}} < 1.$$
Is that sufficient to show the convergence? Follow-up question: given the $a_n = 2^{-f_{n-1}}$ term - is there a better way than this ratio test to show convergence of $\sum a_n$ now that I have this representation? Another approach would be to find a sequence $(b_n)_{n\in\mathbb{N}}$ with
$$\sum_{n=1}^{\infty}b_n < \infty \quad\wedge\quad |b_n| > |a_n|\quad\forall n\geq1.$$
For what it's worth I struggle to find such a series - am I missing something? Is there something immediate that should come to mind? $a_n$ and $b_n$ have to be zero sequences, how can I do the estimate in its recursively defined form? Another ""please correct me if I'm wrong""-question: I did an approach where I proved that $a_{n+1}< a_{n}$ for all $n\geq1$ (which is similar to question 1: $$n=1:\quad a_1 = 1 \geq \frac{1}{2} = a_2\\
n=2: a_3 = a_1a_2 = 1 \cdot \frac{1}{2} = \frac{1}{2},\quad\therefore a_2 = \frac{1}{2} \geq \frac{1}{2} = a_3$$
and
$$""n+1 \to n+2"":\quad a_n \cdot a_{n+1} \geq a_{n+1} \cdot a_{n+2} \Longleftrightarrow\\
a_{n+2} = a_n \cdot a_{n+1} \geq a_{n+1} \cdot a_{n+2} =  a_{(n+1)+2} = a_{n+3}$$
respectively) and after that I did the ratio test
$$q := \lim_{n\to\infty} \left|\frac{a_{n+1}}{a_n}\right| = \lim_{n\to\infty} \left|\frac{a_{n+2}}{a_{n+1}}\right| = \lim_{n\to\infty} \left|\frac{a_n a_{n+1}}{a_{n+1}}\right| = \lim_{n\to\infty}\left|a_{n}\right| \stackrel{*}{<} 1.$$
(with (*) denoting that $a_{n+1}<a_{n}$ and $a_2 <1$). Is that a sufficient answer to my problem? ...thank you so much, guys!","['analysis', 'sequences-and-series', 'convergence-divergence', 'fibonacci-numbers']"
1548590,Adjoint or Formal adjoint? Confusion regarding gradient and laplacian,"I have recently become a bit confused with the distinction of adjoint and formal adjoint. I looked at some old threads here but did not really find the explanation I am looking for. So, I know that the formal adjoint of $\nabla$ is $-\nabla^t$ i.e. the divergence operator. However, if I consider the space $C^\infty_c(\Omega)$ is this then also the actual adjoint? As far as I can see
\begin{equation*}
\langle \nabla u, v \rangle=\int_\Omega \nabla u \cdot v ~dV=-\int_\Omega u\nabla\cdot v~dV+\int_{\partial \Omega} uv \cdot n~dS= \langle u, -\text{div} v\rangle,
\end{equation*}
and differentiation preserves compact support and infinite differntiability. Is this correct? Does it therefore follow that the $-\Delta$ is self-adjoint on $C^\infty_c(\Omega)$ (since $-\Delta = \nabla^* \nabla$)? Any help clearing this up would be much appreciated.","['operator-theory', 'functional-analysis', 'partial-differential-equations']"
1548614,Ordinary Differential Equations used in Cosmology,"I'm just reading over some Cosmology notes and there is a little ODE solve that I am not quite understanding. I have an equation of the form: $$
\ddot{R}=-\frac{GM}{R^{2}}
$$ Integrating gives: $$
\dot{R}^{2}=+\frac{2GM}{R}+C
$$ The notes are essentially saying that this can be solved with a parameter $\theta$: Could anyone run through the method for solving ODE's such as this. In terms of density this can be written as: $$
\dot{R}^{2}=\frac{4\pi{G}}{3}\rho_{0}R
$$",['ordinary-differential-equations']
1548633,Is it possible to convert a divergent series by subtracting a constant?,"This question came to my mind after learning about the existence of the Euler Mascheroni constant. I think that if each term of the divergent series is depressed by a certain amount then maybe the series might become convergent. However, this is just my fancy and if there is solid argument that proves that this is impossible then I would greatly appreciate as I was planning to do research on this question.","['sequences-and-series', 'calculus', 'convergence-divergence']"
1548645,Throwing the dice - wrong interpretation still yields correct result,"Imagine the following game: You are throwing two fair dice and you will be awarded with the sum of the points in cents. How much should participants of this game pay so that the game itself is fair. Let $X$ denote the sum of points then we can easily count the possibilities for each $X=2,\ldots,12$ and the corresponding expected profit for participants is $$\begin{align}\mathbb{E}[X]=2\cdot\frac{1}{36}+3\cdot\frac{2}{36}+\ldots+7\cdot\frac{6}{36}+\ldots+11\cdot\frac{2}{36}+12\cdot\frac{1}{36}=7\end{align}$$ hence players of the game should pay $7$ cents to make the game fair. I have seen a different approch to this problem where it is assumed that each of the outcomes has probability $\frac{1}{11}$ interpreting it as one of eleven possible sums. Surprisingly the computation of the expected profit with this probability for each outcome yields $$\mathbb{E}[X]=\frac{1}{11}\sum_{k=2}^{12}k=7.$$ For this particular scenario this yields the same profit but it feels like it is just coincidence and definitely not correct. The question is now whether the assumption for probabilities $\frac{1}{11}$ is reasonable or is the result really just coincidence - how can either of these be proven?","['dice', 'discrete-mathematics', 'probability', 'combinatorics']"
1548665,Find the sum of the series $1+\frac{1}{3}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4^2}+\frac{1}{7}\cdot\frac{1}{4^3}+\cdots$ [duplicate],This question already has an answer here : Evaluate $ 1 + \frac{1}{3}\frac{1}{4}+\frac{1}{5}\frac{1}{4^2}+\frac{1}{7}\frac{1}{4^3}+\dots$ (1 answer) Closed 3 years ago . Find the sum of the series : $$1+\frac{1}{3}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4^2}+\frac{1}{7}\cdot\frac{1}{4^3}+\cdots$$,"['sequences-and-series', 'real-analysis']"
1548708,Finding DFS in undirected graph,"Consider the following sequence of nodes for the undirected graph given below. a b e f d g c a b e f c g d a d g e b c f a d b c g e f A Depth First Search (DFS) is started at node a. The nodes are listed in the order they are first visited. Which all of the above is (are) possible output(s)? 1 and 3 only 2 and 3 only 2, 3 and 4 only 1, 2 and 3 only My attempt : After f is visited, c or g should be visited next. Visited depth Visited depth After c is visited, e or f should be visited next. Can you explain in more formal way, please?","['graph-theory', 'algorithms', 'discrete-mathematics', 'trees']"
1548709,"Is there a number $n$, such that there are $22$ groups of order $n$?","Denot : $N(n)$ : the number of groupfs of order $n$ ? Is there a number $n$ with $N(n)=22$ ? Checking the first about $2000$ numbers, I noticed that there is no $n\in [1,2000]$ with $N(n)=22$. Does such an $n$ exist ? And if no, why ? Generalization : Given a number $k$, can we determine whether there is a $n$ with $N(n)=k$ in a reasonable time ?","['computational-complexity', 'group-theory', 'finite-groups']"
1548716,The shape of a room that's bigger on the inside,"I have an advanced facility with many floors containing experimental technology. One of these floors goes on forever. What shape is it? More specifically: within the room, you can move as far as you like in any given direction. It is possible to travel an infinite distance in a straight line, in the sense that you'll need to travel that same distance in order to get back to your starting point; travelling costs time and energy; there is (eventually) a speed of light delay in communications, etc etc. There are no observable edges to the room, so upon entering you appear to be have emerged the centre of a vast featureless space. Objects do not visibly appear distorted when moving through the space, but everything in the room is small enough to have been brought in through the door (let's say vehicle-garage-size). This room is however not particularly useful, because despite its apparent size, you can't put very much in it - the storage capacity of the room is still limited by the containing building: the volume within the room is no greater than the volume of any other floor of the building with an equivalent external footprint. Trying to put more objects into the room than would fit into a conventional space will result in Bad Things™ happening (certainly not anything a protagonist would want to experience first-hand). the mass that can be contained within the room is limited by the supporting structure of the building, the same as on any other floor. Overload it and the floor will collapse. This is likely to result in problems connected to the first point, too, unless whatever process is maintaining the spatial distortion is turned off quickly by the destruction. Trying to flood the level with water or cement would certainly be a very bad idea. The cause of this effect is obviously waaay beyond the scope of a SE question, and anyway the protagonist isn't interested. However, for us creators with weaker math-fu, what would be a rigorous mathematical description of the effect on space that's being observed within the room? I'm leaning towards something like a four-dimensional version of a shape along the lines of a Menger sponge, which demonstrates a similar effect to the room, in that it has infinite surface area but zero volume (or perhaps its inverse, which - I assume - also has infinite surface area, but unit volume). Moving on the surface of a Menger sponge would be slightly similar to a 2D version of the above, in that you could move infinitely on certain paths, but remain within an enclosed space. Is there a fractal shape that fits the results described above and can be used to describe the space within the room? i.e. infinite lengths possible between points in the space it encloses, finite 3D volume for the whole shape. The space doesn't have to appear empty, if unpacking a 4D shape into 3D would necessarily result in singularities or mathematically correct terms creating areas that can't be moved through cleanly / spaces that don't line up (it would actually be a bonus to have ""free"" floor and support struts throughout, that aren't real objects with mass), similarly to how you can't travel in an endless straight line in any direction on the infinite surface of the Menger sponge (I think). (solutions that allow an infinite volume to be contained within the space are acceptable, if this is an otherwise impossible request - I can always use the weight limit to prevent the space from being useful, but limiting volume seems more interesting for the story)","['low-dimensional-topology', 'geometry']"
1548737,Recursively defined set subset proof,"Consider the subset $S$ of the set of integers recursively defined by BASIS STEP: $3 \in S$. RECURSIVE STEP: If $x \in S$ and $y \in S$, then $x+y \in S$. Q: Show that the set $S$ is the set of all positive integers that are multiples of $3$. This is an example from Rosen's Discrete Mathematics and Its Applications . It first proves that $A$, the set of all positive integers divisible by $3$, is a subset of $S$. I understand this part. Then $S \subseteq A$ proof is given as the following: To prove that $S$ is a subset of $A$, we use the recursive definition
  of $S$. First, the basis step of the definition specifies that $3$ is
  in $S$. Because $ 3 = 3\times 1$, all elements specified to be in $S$ in
  this step are divisible by $3$ and are therefore in $A$. To finish the
  proof, we must show that all integers in $S$ generated using the
  second part of the recursive definition are in $A$. This consists of
  showing that $x+y$ is in $A$ whenever $x$ and $y$ are elements of $S$
  also assumed to be in A. Now if $x$ and $y$ are both in $A$, it
  follows that $3\mid x$ and $3 \mid y$. It follows that $3 \mid x+y$,
  completing the proof. If we are assuming $x,y$ to be in $A$, how does this show $S \subseteq A$?","['induction', 'discrete-mathematics', 'recursion']"
1548755,Equidistant sequence in a normed space,"Let $(X, \|\cdot\|)$ be a normed linear space of dimension $n < \infty$. Is it always true that we can find a sequence of $m = n + 1$ points $x_i$ such that $\|x_i - x_j\| = c > 0$ for all $i\neq j$? Can we choose $m$ to be bigger than $n+1$ without violating the first property? In case $X$ is not finite-dimensional, does there always exist a countable sequence of $x_i$ with the desired property? Inspired by this question .","['linear-algebra', 'banach-spaces']"
1548761,Ask for different ways to solve $(x+y)dy+(y+1)dx=0$,"$(x+y)dy+(y+1)dx=0$ Rewrite the equation to 
$\frac{dx}{dy}+\frac{x}{y+1}=\frac{-y}{y+1}$ I can use used the integrating factor $μ(y)=e^{-\int\frac{1}{y+1}dy}$ to solve it. The answer is $x=\frac{-y^2}{2(y+1)}+\frac{C}{y+1}$ I'm curious that are there any other methods to solve this ODE. I am asking for a different method because sometimes I am not able(or haven't enough time, this one costs me about half an hour to solve it ) to  rewrite the equation into a proper form. So, if I could obtain other methods to solve this kind of ODEs, I may have more chances to solve it in a exam.",['ordinary-differential-equations']
1548803,Continuous map from Projective Plane to Torus,"Is there a continuous map from the $\mathbb{R}P^2$ to the torus which
  is not homotopic to a constant map? My working: I am pretty sure the answer is no. But I am not sure how to present the answer ""properly"". Is it correct to say that any map $f:\mathbb{R}P^2\to T$ induces $f^*:\mathbb{Z}/2\mathbb{Z}\to\mathbb{Z}\times\mathbb{Z}$. $f^*(1+1)=f^*(1)+f^*(1)$ But $f^*(1+1)=f^*(0)=0$ This means $f^*(1)=0$, and $f^*(0)=0$, and so $f$ must be the constant map. Thanks for any help.","['algebraic-topology', 'general-topology']"
1548807,What is the name of partition without pairwise disjoint property?,"Wiki definition of partition: Equivalently, a family of sets P is a partition of X if and only if all of the following conditions hold:[2] P does not contain the empty set. The union of the sets in P is equal to X. (The sets in P are said to cover X.) The intersection of any two distinct sets in P is empty. (We say the elements of P are pairwise disjoint.) If we remove the third condition, does the result sets have specific name in set theory?","['elementary-set-theory', 'terminology', 'general-topology']"
1548827,Rigorous proof of this limit,"I have shown that the function $$f(x):=\int_{[-\pi,\pi]^n} \frac{e^{-i\langle k,x \rangle}}{1-\frac{1}{n} \sum_{i=1}^n \cos(k_i)}dk$$ exists everywhere for $n \ge 3$. Now, I want to show that $\lim_{x \rightarrow \infty} f(x) \|x\|^{n-2}=c$ for some non-zero constant $c.$ Here $\lim_{x \rightarrow \infty}$ means that $x_1,\ldots,x_n \rightarrow \infty.$ Does anybody know how to do this?","['calculus', 'fourier-analysis', 'real-analysis', 'functional-analysis', 'analysis']"
1548870,Formula for cos(k*x),"I need to prove that:
\begin{align}
c_k =&\; \cos(k\!\cdot\!x)\\
c_k :=&\; c_{k-1} +d_{k-1}\\
d_k :=&\; 2d_0\!\cdot\!c_k +d_{k−1}\\
d_0 :=&\; −2\!\cdot\!\sin^2{(x/2)}\\
\end{align} I've got an explicit formula for $d_k$ which should be: \begin{align}
d_k&=d_o+\sum_{i=1}^k{2\!\cdot\!d_o\!\cdot\!c_i} 
&&\implies&
c_k &=c_{k-1}+ \sum_{i=1}^k{2\!\cdot\!d_o\!\cdot\!c_i}
\end{align} Now I want to do a proof by induction. Assuming that $c_p=\cos(p\!\cdot\!x)$ for every $p<k$.
This would get me the following:
$$c_k =\cos\left(\left(k-1\right)\!\cdot\!x\right)+\sum_{i=1}^k{2\!\cdot\!d_o\!\cdot\!\cos(p\!\cdot\!x)}$$
Using this formula I found: \begin{align}
\sum_{k=1}^n \cos(kx) & = \frac{\sin\left(\frac{nx}2\right)}{\sin \left(\frac{x}2\right)}\, \cos\left(\frac{(n+1)\,x}2\right)
\end{align} I tried to play around with trigonometric addition formulas but I am getting nowhere.","['summation', 'induction', 'trigonometry']"
1548882,How to show $1 +x + x^2/2! + \dots+ x^{2n}/(2n)!$ is positive for $x\in\Bbb{R}$?,"How to show $1 + x + \frac{x^2}{2!} + \dots+ \frac{x^{2n}}{(2n)!}$ is positive for $x\in\Bbb{R}$? I realize that it's a part of the Taylor Series expansion of $e^x$ but can't proceed with this knowledge? Also, I can't figure out the significance of $2n$ being the highest power.","['taylor-expansion', 'real-analysis']"
1548940,Sharper Lower Bounds for Binomial/Chernoff Tails,"The Wikipedia page for the Binomial Distribution states the following lower bound, which I suppose can also be generalized as a general Chernoff lower bound. $$\Pr(X \le k) \geq \frac{1}{(n+1)^2} \exp\left(-nD\left(\frac{k}{n}\left|\right|p\right)\right) \quad\quad\mbox{if }p<\frac{k}{n}<1$$ Clearly this is tight up to the $(n+1)^{-2}$ factor. However computationally it seems that $(n+1)^{-1}$ would be tight as well. Even (n+1)^{-.7} seems to be fine. It's not as easy to find lower bounds for tails as it is upper, but for the Normal Distribution there seems to be a standard bound : $$\int_x^\infty e^{-t^2/2}dt \ge (1/x-1/x^3)e^{-x^2/2}$$ My question is thus, is the $\frac{1}{(n+1)^2}$ factor the best known? Or can $\frac{1}{n+1}$ be shown to be sufficient? Update: Here is the region in which the conjecture holds numerically, by Mathematica:","['concentration-of-measure', 'distribution-tails', 'probability', 'binomial-distribution', 'inequality']"
1548962,Sample statistics probability bernoulli trials,"Problem There are two restaurants on the campus of a university. Each can feed 120 students. We know that there are 200 students attending the university who will want to eat lunch in one of the restaurants. The restaurant is chosen randomly by the student, for example by tossing a fair coin. What is the probability that there will not be enough meals in one of the restaurants? My Answer Each students choice is a Bernoulli trial with even probabilities on each of the two outcomes that is: $X_i = 1 $ with $ p=1/2$ or $X_i = 0 $ with $ p=1/2$ where $X_i$ is a random variable which denotes student i's choice. So we want $P(\Sigma_1^{200} X_i \gt 120) \bigcup P(\Sigma_1^{200} X_i \lt 80)$ But from here I don't really know where to go with it? Any help would be great.","['probability-theory', 'order-statistics', 'statistical-inference', 'statistics', 'probability']"
1548963,Proof that the solutions are algebraic functions,"I am looking at the following: $$$$ $$$$ I haven't really understood the proof... Why do we consider the differential equation $y'=P(x)y$ ? Why does the sentence:  ""If $(3)_{\mathfrak{p}}$ has a solution in $\overline{K}_{\mathfrak{p}}(x)$, then $(3)_{\mathfrak{p}}$ has also a solution $y_{\mathfrak{p}}$ in $\overline{K}_{\mathfrak{p}}[x]$."" stand? Also why do we put $\displaystyle{y_{\mathfrak{p}}=\prod_i (x-\overline{\alpha}_i)^{c_i}}$ ? $$$$ EDIT1: I found now the following sentence: The constant field of the differential field $k((x))$ is $k((x^p))$. 
Hence if $(1)_p$ has a solution in $k((x))$, multiplication by a suitable constant yields a solution in $k[[x]]$. Do we maybe have the following? We suppose that $(3)_{\mathfrak{p}}$ has a solution in $\overline{K}_{\mathfrak{p}}(x)$. 
The constant field of $\overline{K}_{\mathfrak{p}}(x)$ is $\overline{K}_{\mathfrak{p}}(x^p)$. 
So if we multiply the equation by a suitable constant, it follows that $(3)_{\mathfrak{p}}$ has a solution also in $\overline{K}_{\mathfrak{p}}[x]$. $$$$ EDIT2: Could you explain to me how exactly we conclude that $\beta_i \in \mathbb{Q}$ ?","['number-theory', 'ideals', 'abstract-algebra', 'differential-algebra', 'elementary-number-theory']"
1548996,This infinitely nested root gives me two answers $ \sqrt{4+\sqrt{8+\sqrt{32+\sqrt{512+\sqrt{\frac{512^2}{2}+\sqrt{...}}}}}} $,"I am trying to evaluate
$$ \sqrt{4+\sqrt{8+\sqrt{32+\sqrt{512+\sqrt{\frac{512^2}{2}+\sqrt{...}}}}}} $$
where those numbers inside roots are
$$ a_{n+1}=\frac{a_n^2}{2}$$
And I found two ways to solve it that give different answers. I believe one of those is not right, but I don't know which and why. Please help. Method-1. $$x+1=\sqrt{x^2+2x+1}=\sqrt{x^2+x+\sqrt{x^2+2x+1}}\\
=\sqrt{x^2+x+\sqrt{x^2+x+\sqrt{x^2+2x+1}}}=...$$
$x=1\rightarrow$
$$2=\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{...}}}}}}$$
Therefore
$$\begin{align}
&4=2\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{...}}}}}}\\
&=\sqrt{2^2\cdot2+2^2\cdot\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{...}}}}}}\\
&=\sqrt{8+\sqrt{2^4\cdot2+2^4\cdot\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{...}}}}}}\\
&=\sqrt{8+\sqrt{32+\sqrt{512+\sqrt{\frac{512^2}{2}+\sqrt{...}}}}}\end{align}$$
Finally,
$$\sqrt{4+4}=\sqrt{4+\sqrt{8+\sqrt{32+\sqrt{512+\sqrt{\frac{512^2}{2}+\sqrt{...}}}}}}=2\sqrt2$$ Method-2. $$\begin{align}
&x+2=\sqrt{x^2+4x+4}=\sqrt{x^2+3x+\sqrt{x^2+8x+16}}\\
&=\sqrt{x^2+3x+\sqrt{x^2+7x+\sqrt{x^2+32x+256}}}\\
&=\sqrt{x^2+3x+\sqrt{x^2+7x+\sqrt{x^2+31x+\sqrt{x^2+512x+256^2}}}}...
\end{align}$$
$x=1\rightarrow$
$$3=\sqrt{4+\sqrt{8+\sqrt{32+\sqrt{512+\sqrt{\frac{512^2}{2}+\sqrt{...}}}}}} $$ Alternative Method-2. $$\begin{align}
&3=\sqrt9=\sqrt{4+5}=\sqrt{4+\sqrt{25}}=\sqrt{4+\sqrt{8+17}}\\
&=\sqrt{4+\sqrt{8+\sqrt{2\cdot16+16^2+1}}}\\
&=\sqrt{4+\sqrt{8+\sqrt{32+\sqrt{2\cdot16^2+16^4+1}}}}\\
&=\sqrt{4+\sqrt{8+\sqrt{32+\sqrt{512+\sqrt{2\cdot16^4+16^8+1}}}}}\\
&=\sqrt{4+\sqrt{8+\sqrt{32+\sqrt{512+\sqrt{\frac{512^2}{2}+\sqrt{2\cdot16^8+16^{16}+1}}}}}}=...
\end{align}$$ So, I have two answers $2\sqrt2$ and $3$. Which one is correct and what's the problem in the other solution?? Thanks. Now I think I understand. Thanks for all the answers.
Let me post this method-3 just to show that it could be any number $\geq2\sqrt2$ and conclude this topic. Method-3. $$\begin{align}
&\sqrt{10}=\sqrt{4+6}=\sqrt{4+\sqrt{36}}=\sqrt{4+\sqrt{8+28}}\\
&=\sqrt{4+\sqrt{8+\sqrt{32+752}}}\\
&=\sqrt{4+\sqrt{8+\sqrt{32+\sqrt{512+564992}}}}\\
&=\sqrt{4+\sqrt{8+\sqrt{32+\sqrt{512+\sqrt{\frac{512^2}{2}+\sqrt{...}}}}}}=...
\end{align}$$","['sequences-and-series', 'nested-radicals']"
1549007,Complex equation has two roots inside $|z|=1$,"Prove that the equation $z^3[\exp(1-z)]=1$ has exactly $2$ roots inside $|z|=1$.
I have tried applying Rouche Theorem , without any result...",['complex-analysis']
1549008,What does it mean when two Groups are isomorphic?,"I'm not asking for the formal definition I know it. An isomorphism is a bijective homomorphism. In my book it's indicated many times when two groups are isomorphic, and I don't understand what's the reason for that. What can we ""do"" when we know that 2 groups are isomorphic? What does it really mean when 2 groups are isomorphic?","['abstract-algebra', 'group-theory', 'group-isomorphism', 'soft-question']"
1549017,Condition for $\mu^*$-measurable set,"Let $\mu:\mathcal A\to[0,\infty]$ be a measure, where $\mathcal A$ is an algebra and let $\mu^*:\mathcal P(X)\to[0,\infty]$ be the outer measure generated by $\mu$. $\Big($i.e. $\mu^*(E)=\inf\Big\{\sum_{i=1}^\infty \mu(A_i):E\subset \bigcup_{i=1}^\infty A_i,\;\ A_i\in\mathcal A\;\ \forall i\in\Bbb N\Big\}$ $\Big)$ Lets suppose that $\forall E\subset X$ and $\forall\epsilon>0\;\ \exists\ A\in\mathcal A$ s.t. $\mu^*(E\mathbin\triangle A)<\epsilon$, so I'm trying to prove that: $$E\in\mathcal A^*$$ Proof: (What I've got)
So, since $\mathcal A^*=\{E\subset X:\mu^*(B)=\mu^*(B\setminus E)+\mu^*(B\cap E)\ \forall B\subset X\}$ is a $\sigma-$algebra and if $\mu^*(F)=0\Rightarrow F\in\mathcal A^*$, it's sufficient to prove that:
$$\mu^*(E)<\epsilon,\;\ \forall \epsilon>0$$ Thereby, let $E\subset X$ and $\epsilon>0$, so there$\;\exists\ A\in\mathcal A$ s.t. $\mu^*(E\mathbin\triangle A)<\frac{\epsilon}{2}$, but $$E\setminus A\subset E\mathbin\triangle A\\
A\setminus E\subset E\mathbin\triangle A$$ so, since an outer measure is monotone, $$\mu^*(E\setminus A)<\frac{\epsilon}{2}\\
\mu^*(A\setminus E)<\frac{\epsilon}{2}$$ and $$\mu^*(E)=\mu^*(E\setminus A\ \cup\ E\cap A)\le \mu^*(E\setminus A)+\mu^*(E\cap A)<\frac{\epsilon}{2} + \mu^*(E\cap A)$$ so I need to show that $\mu^*(E\cap A)<\frac{\epsilon}{2}$, but got stuck here since I have tried some set rewriting and the only ""usefull"" thing I got so far is that $\mu^*(E\cap A)\le \mu^*(A)$ which doesn`t tell me much. And $\mathcal A-$covers of $E$ don't think could help or I can't see how. Any ideas would be appreciated.","['lebesgue-measure', 'elementary-set-theory', 'measure-theory']"
1549029,What am I misunderstanding about this constructive proof that $\mu(\mathbb{Q}) = 0$?,"In class we were given a constructive proof that $\mu(\mathbb{Q}) = 0$, with $\mu$ the Lebesgue measure. Of course it is clear that they have measure zero since they are countable, but this constructive proof doesn't sit well with me. Let $\{ q_n\}_{n=1}^{\infty}$ be an enumeration of the rationals. Then fix $\varepsilon > 0$ and for each $q_n$ take the interval $A_n = (q_n - \frac{\varepsilon}{2^n}, q_n + \frac{\varepsilon}{2^n})$. Then $$\mu^*\left(\{q_n\}_{n=1}^{\infty}\right) \leq \sum_{n=1}^{\infty} \mu (A_n) = \sum_{n=1}^{\infty} \frac{\varepsilon}{2^{n-1}} = 2 \varepsilon$$ So the measure is zero since $\varepsilon$ was arbitrary. However, the part that doesn't sit well with me is that it seems that eventually it must be that this covering of the rationals by open sets must eventually cover the entire real line. Indeed, if there were some ""gap"" in the cover, no matter how small, since the rationals are dense then there must be some rational (infinitely many rationals, actually) that are not covered. So then the combined measure of these intervals could not be zero since their union is the real line. What is wrong with my thinking?",['measure-theory']
1549042,"Canonical probability distribution associated with the ""harmonic mean""","Is there a canonical continuous probability distribution, the center of which is best characterized with the harmonic mean , given by
  $$
\mathrm{HM}(X) = n \cdot \left( \sum\limits_{k=1}^{n} x_k^{-1} \right)^{-1}?
$$ With ""canonical"" I mean: similar to the way we typically associate the normal distribution with the arithmetic mean ,
$$
\mathrm{AM}(X) = \sum\limits_{k=1}^{n} \dfrac{x_k}{n},
$$
or the log-normal distribution with the geometric mean ,
$$
\mathrm{GM}(X) = \prod\limits_{k=1}^{n} x_k^{\frac{1}{n}}.
$$ Update: Because zero is not invertible, I guess that the support of such a distribution would have to be a subset of $\mathbb{R} \setminus \{ 0 \}$, maybe $\mathbb{R}_{>0}$.","['probability-theory', 'descriptive-statistics', 'probability-distributions']"
1549067,"Indefinite integral $\int \frac{1-x}{\sqrt{1+x-2x^2}}\,dx $","For my engineering math course I got a couple of exercises about indefinite integrals. I ran trought all of them but stumbled upon the following problem. $$\int \frac{1-x}{\sqrt{1+x-2x^2}}\,dx $$ We can write $1+x-2x^2$ as $(1-x)(2x+1)$ So I got: $$
\int \frac{1-x}{\sqrt{1+x-2x^2}}\,dx = \int \frac{1-x}{\sqrt{(1-x)(2x+1)}}\,dx 
$$ We can also replace $1-x$ in the denominator with $\sqrt{(1-x)^2}$ $$
\int \frac{1-x}{\sqrt{(1-x)(2x+1)}}\,dx = \int \frac{\sqrt{(1-x)^2}}{\sqrt{(1-x)(2x+1)}}\,dx
$$ If we simplify this fraction we get: $$
\int \frac{\sqrt{1-x}}{\sqrt{2x+1}}\,dx
$$ Next we apply the following substitutions $$
u = -x
$$
so : $-du = dx$ We can rewrite the integral as following: $$-\int \frac{\sqrt{1+u}}{\sqrt{1-2u}}\,du$$ Then we apply another substitution: 
$\sqrt{1+u} = t $ so $ \frac{1}{2\sqrt{1+u}} = dt $ We rewrite: $ \sqrt{1+u} $ to $\frac{1}{2}t^2 \,dt $ We can also replace $\sqrt{1-2u} $ as following: $$\sqrt{-2t^2+3}=\sqrt{-2(1+u)+3}=\sqrt{1-2u}$$ With al these substitutions the integral has now the following form: $$-\frac{1}{2}\int \frac{t^2}{\sqrt{-2t^2+3}}\,dt$$ Next we try to ''clean'' up the numerator: $$-\frac{1}{2} \int \frac{t^2}{\sqrt{\frac{1}{2}(6-t^2)}} \, dt$$ $$-\frac{\sqrt{2}}{2} \int \frac{t^2}{\sqrt{6-t^2}} \, dt$$ And that's where I got stuck. I can clearly see that an arcsin is showing up in the integral but don't know how to get rid of the $t^2$.","['substitution', 'calculus', 'indefinite-integrals', 'integration']"
1549139,Comparing a probability to Chebyshev's Theorem.,"I am a little confused with this questions I was assigned. For the experiment, flip a coin until heads shows, assume that the probability on heads on one flip is $$\frac{3/4}$$ . We define a RV X = the number of flips. The probability distribution function for X I calculated was p(X=x) = 3/4(1/4)^x-1. 1) What is the expected number of flips? My result: 4/3 2) What is the standard deviation of the number of flips until heads shows? 
My result: 2/3 3) Compute the probability P(4/3-2/3 < x < 4/3+2/3) and compare to what Chebyshev's Theorem says it should be. My result (for first half): .33438","['probability', 'statistics', 'random-variables']"
1549150,Proving that $\sum\limits_{k=0}^{2n}(-1)^k\binom{4n}{2k}=(-4)^n$,I need sum this numerical serie. $\sum\limits_{k=0}^{2n} (-1)^k \begin{pmatrix}4n\\2k\end{pmatrix}$ I know that the result will be $(-4)^n$ but i don't know how can I get it. Could you help me with it please?,"['induction', 'discrete-mathematics', 'summation', 'sequences-and-series', 'combinatorics']"
1549151,Interpretation of $d\phi(z)$ in differential geometry,"In ""Exercises and Solutions in Mathematics"", Ta-Tsien, 2nd Edition, exercise 3343. Statement of the exercise Let $(\mathbb{H}, g)$ be the two-dimensional hyperbolic space, where \begin{equation}
\mathbb{H} = \{(x, y) \in \mathbb{R}^2 : y > 0\}
\end{equation} is the upper half plane of $\mathbb{R}^2 = \mathbb{C}$ and the metric $g$ is given by \begin{equation}
g = \frac{dx^2 + dy^2}{y^2}
\end{equation} Suppose $a$, $b$, $c$ and $d$ are real numbers such that $ad - bc = 1$. Define \begin{equation}
\phi(z) = \frac{az + b}{cz + d}
\end{equation} for any $z = x + \sqrt{-1} y$. Prove that $\phi$ is an isometry for $(\mathbb{H}^2, g)$. Statement of the answer To prove that $\phi$ is an isometry, the authors compute: \begin{equation}
d\phi = \frac{a(dz)(cz+d) - c(dz)(az+b)}{(cz + d)^2}
\end{equation} and after some computations, concludes that since: \begin{equation}
\Vert d\phi(z) \Vert^2 = \frac{d\phi(z) d\overline{\phi(z)}}{[Im \phi(z)]^2}
= \frac{dx^2 + dy^2}{y^2} = \Vert dz \Vert^2
\end{equation} then $\phi$ is an isometry. My question What is the mathematical nature of the operator $d$ in this context ? It seems to me that in order to prove that $\phi$ is an isometry, one has to prove that: $g = \phi^* g$ i.e. that the pullback of $g$ by $\phi$ is $g$. In the context of differential geometry, I have only seen $d\phi$ standing for the exterior derivative of $\phi$ or for the differential map associated to $\phi$. In a more ""intuitive"" manner, considering small variations of $\phi(z)$ and $z$, I understand that an isomorphism maps a small increment $dz$ to a small increment $d\phi(z)$. But I would like to understand the differential geometry meaning. Is $dz$ a differential form in the context of this exercise ? Then what is the precise meaning of $\Vert dz \Vert^2$ ? Is $d\phi(z)$ of the same nature than $dz$ ? Is it a vector-valued differential form ?","['differential-geometry', 'infinitesimals', 'differential-forms']"
1549174,Proving that $\binom{n}{0}+\binom{n-1}{1}+\binom{n-2}{2}+\cdots =F_{n+1}$ where $F_{n+1}$ is the $n+1$ th Fibonacci number [duplicate],This question already has answers here : How to show that this binomial sum satisfies the Fibonacci relation? (6 answers) Closed 8 years ago . I have to proove this this identity which connects Fibonacci sequence and Pascal's triangle: $$\begin{pmatrix}n\\0\end{pmatrix}+\begin{pmatrix}n-1\\1\end{pmatrix}+\dotsm+\begin{pmatrix}n-\lfloor\frac{n}{2}\rfloor\\\lfloor\frac{n}{2}\rfloor\end{pmatrix} = F_{(n+1)}$$ Example: ${6\choose0} + {5\choose1} + {4\choose2} + {3\choose3} = 13 = F_{7}$,"['summation', 'binomial-coefficients', 'discrete-mathematics', 'fibonacci-numbers']"
1549226,Domain strictly contained in the intersection of localizations at the primes of height one,"If $R$ is a Noetherian normal domain, then it is equal to the intersection of its localizations at height one primes. What is an example of a non-normal domain that is strictly contained in such an intersection? I'd prefer an example that is a finitely generated $\mathbb{C}$-algebra, and all I want is a candidate suggested. I'd prefer to verify it myself.","['integral-domain', 'commutative-algebra']"
1549239,Galois' theory: fixed subfield formula.,"In a homework dealing with Galois' theory, I am asked to prove the following standard statement, known as the fixed subfield formula: Theorem. Let $L$ be a field and $G$ be a finite subgroup of $\textrm{Aut}(L)$, then: $$\left[L:L^G\right]=|G|\textrm{ and }G=\textrm{Aut}_{L^G}(L).$$ However, I am bound to use very specific tools that I shall introduce to you. First, let me give you a: Definition 1. Let $L$ be a field, $G$ be a finite subgroup of $\textrm{Aut}(L)$ and $V$ be a $L$-vector space. One says that a map $\cdot:G\times V\mapsto V$ is a $L^G$-structure of $V$ if and only if: (i) $\cdot:G\times V\rightarrow V$ is a group action of $G$ on $V$. (ii) For all $\sigma\in G$,$V\ni v\mapsto\sigma\cdot v\in V$ is a $L^G$-linear map. (iii) For all $(\lambda,v)\in L\times V$, $\sigma\cdot\lambda v=\sigma(\lambda)(\sigma\cdot v)$. From there, I have shown the: Proposition 1. Let $L$ be a field, $G$ be a finite subgroup of $\textrm{Aut}(L)$ and $V$ be a $L$-vector space. (i) $V^G$ is a $L^G$-subvector space of $V$. (ii) Let $(v_i)_{i\in\{1,\ldots,n\}}\in(V^G)^n$ be $L^G$-linearly independent in $V^G$, then $(v_i)_{i\in\{1,\ldots,n\}}$ is $L$-linearly independent in $V$. Besides, I have also derived the two following constructions: Proposition 2. Let $L$ be a field and $G$ be a finite subgroup of $\textrm{Aut}(L)$. (i) Let $V$ be a finite-dimensional vector space over $L$ and $(v_i)_{i\in I}$ a $L$-basis of $V$, then $V$ is equipped with a $L^G$-structure given by:
  $$\left\{\begin{array}{ccc}G\times V & \rightarrow & V\\\displaystyle\left(\sigma,\sum_{i\in I}\lambda_iv_i\right) & \mapsto & \displaystyle\sum_{i\in I}\sigma(\lambda_i)v_i\end{array}\right..$$ (ii) The $L$-vector space $\textrm{Map}(G,L)$ of the maps from $G$ to $L$ is equipped with a $L^G$-structure given by: $$\left\{\begin{array}{ccc}G\times\textrm{Map}(G,L) & \rightarrow & \textrm{Map}(G,L)\\(\sigma,\Phi) & \mapsto & G\ni\tau\mapsto\sigma(\Phi(\sigma^{-1}\circ\tau))\end{array}\right..$$ Thus far, here my: Theorem's proof: Let $m:=\left[L:L^G\right]$, $n:=|G|$ and assume by contradiction that $m<n$. Let $(x_i)_{i\in\{1,\ldots,m\}}\in L^m$ be a $L^G$-basis of $L$ and $\sigma_1,\ldots,\sigma_n$ be the distinct elements of $G$. Since $m<n$ there exists $(y_i)_{i\in\{1,\ldots,n\}}\in L^n$ a nonzero solution to the following homogeneous system: $$\forall i\in\{1,\ldots,m\},\sum_{i=1}^n\sigma_j(x_i)Y_i=0_L.$$
Let $x\in L$, there exists $(\lambda_i)_{i\in\{1,\ldots,m\}}\in(L^G)^m$ such that: $$x=\sum_{i=1}^m\lambda_ix_i.$$
One derives from the construction of $(y_i)_{i\in\{1,\ldots,n\}}$: $$\sum_{i=1}^n\sigma(x)y_i=\sum_{i=1}^m\lambda_i\sum_{j=1}^n\sigma_i(x_j)y_i=0_L.$$
Therefore, one has: $$\sum_{i=1}^n\sigma y_i=0_{\textrm{Map}(G,L)}.$$
Since $(y_i)_{i\in\{1,\ldots,n\}}$ is nonzero and $\sigma_1,\ldots,\sigma_n$ are pairwise distinct, here a contradiction to Dedekind's lemma. Therefore, one has $m\geqslant n$. $\Box$ I struggle to prove that $m\leqslant n$, I tried to use the $L^G$-structure on $\textrm{Map}(L,G)$ from proposition $2.$ (ii) along with the proposition $1.$ (ii) but I didn't manage to succeed. Any hints will be appreciated.","['extension-field', 'galois-theory', 'linear-algebra']"
1549240,Interchanging Malliavin derivative with Lebesgue integral,"I am reading Oksendal's book ""Malliavin calculus for Levy processes with application to finance"". In the proof of Lemma 4.9 (page 47), the author interchanges the Malliavin derivative $D_t$ with the Lebesgue integral $ds$.
$$D_t\int_0^T u^2(s)\,ds = 2\int_0^T u(s)D_tu(s)\,ds$$
Could anyone shed any light?","['probability-theory', 'lebesgue-integral', 'malliavin-calculus', 'stochastic-processes', 'stochastic-analysis']"
1549283,Proof for Steinhaus theorem,"I try a very long time to understand the proof of this theorem from here: https://en.wikipedia.org/wiki/Steinhaus_theorem I'm pretty sure it's wrong - the part where they say that $K+V\subset U$ just can't be true. For example if I take $A=[0,1]$ and $U=(-0.1,1.1),\, K=[0.1,1]$ and I will take the cover $V_1=(-0.5,0.1)$ with $k_1=0.4$ and $V_2=(-0.4,0.3)$ with $k_2=0.8$ so $-0.2\in V$ and $0.1\in K$ but $-0.2+0.1\notin U$ Am I wrong or there is something I'm missing?","['lebesgue-measure', 'measure-theory']"
1549293,Is there a standard name for this infinite group?,"Consider the group of sequences
$$\{(a_1,a_2,\dots): a_i\in\mathbb{Z}/2\mathbb{Z}\}$$
where the group operation is component-wise addition. Is there a standard name for this group, such as $(\mathbb{Z}/2\mathbb{Z})^{\infty}$, $(\mathbb{Z}/2\mathbb{Z})^{\mathbb{N}}$, or something similar? It is isomorphic to $\mathbb{Z}/2\mathbb{Z}[x]$ under addition, but I want to emphasize the additive group structure and not assign it any multiplicative structure. EDIT: Silly me, it's not isomorphic to $\mathbb{Z}/2\mathbb{Z}[x]$. See below.","['group-theory', 'infinite-groups']"
1549304,Number of Taxicab routes in a triangular city,"I am assuming a triangle that is ""almost"" half a rectangular city with taxicab geometry. I am trying to find the number of paths in this triangular city. Assuming that the ride starts from the corner of the city. If we move p steps in one direction, and q steps in the perpendicular direction, the number of paths in case of a rectangular city is known and is given by: $$\binom{p+q}{p} ~ or ~ \binom{p+q}{q}$$ For example, assume the 45-degree rotated city in the following figure (left). Complete and half cities If we start from the point where the arrow is pointing, the numbers at the cross-points refer to the number of possible paths from the start point to each cross-point. Now, assume the figure on the right side. Again, the numbers at the cross-points refer to the number of possible paths from the start point to each cross-point. I obtained these numbers using a combination of counting and observation. The main observation is that the number of paths in the triangular city is a ratio of the rectangular city. Take for example the 7'th row, we find the following (Can you explain why?): 924/(7/1)=132 462/(7/2)=132 210/(7/3)=90 84/(7/4)=48 28/(7/5)=20 7/(7/6)=6 1/(7/7)=1 This applies to all rows. Now to my question. Assume the following shape of a city, where the inlets are at the left edge, and the outlets are at the bottom edge. My problem What I want to do is to find the number of paths from any of the inlets to any of the outlets. Hopefully a formula, and a proof. In Figure 2 is what I got so far. If the outlet is less than or equal to the input, this can be directly obtained using the formula for the rectangular case. Assuming that this is correct, note that up to the diagonal, numbers are following the rules of Pascal's triangle. After the diagonal, which represents the boundary of the city, it does not follow the same rules, but there is a pattern. 1st diagonal after the half (subtract 1) 6= (6+1)-1 20=(6+15)-1 34=(15+20)-1 2nd (subtract 6) 20=(20+6)-6 48=(20+34)-6 62=(34+34)-6 3rd (subtract 20) 4th (subtract 48) 5th (subtract 90) 6th (subtract 132) Which are the numbers in the row corresponding to inlet 7 (Again, can you explain why?).","['geometry', 'proof-writing']"
1549349,Structure theorems for infinitely generated Abelian groups,The classification theorem for finitely generated Abelian groups is well known and plays big role in mathematics. Are there any structure theorems about infinitely generated Abelian groups known?,"['abstract-algebra', 'group-theory', 'abelian-groups']"
1549389,Evaluate the integral of function involving $\cosh$,"Evaluate the integral 
$$
\int_0^{\infty} \frac{\cosh(ax)}{\cosh(x)}\,dx,
$$
where $|a|<1$. Consider the closed loop integral of $\displaystyle\frac{e^{az}}{\cosh(z)}$ where the contour $C$ is $y=0, y=\pi, x=-R$, and $x=R$. So far I have found that $$\displaystyle\int_C \frac{e^{az}}{\cosh(z)}\,dz=2\pi e^{\frac{\pi i a}{2}}$$ by the residue theorem.  Not sure how to compare this to the first part where we are integrating from $0$ to infinity.","['calculus', 'contour-integration', 'residue-calculus', 'integration', 'complex-analysis']"
1549410,Using $y=\sum_{n = 0}^\infty a_nx^n$ in order to find recurrence relation of $a_n$'s for $y'=x-y^2$,"I have to solve the differential equation $y'=x-y^2 => y''' = -2y'y' - 2yy''$. I plugged in the series $\sum_{n = 0}^\infty a_nx^n$ to get: $$\sum_{n = 0}^\infty a_{n+3}(n+3)(n+2)(n+1)x^n + \sum_{n = 0}^\infty \sum_{n = 0}^\infty 2(a_{n+1}(n+1)x^n)^2 \\
+ \sum_{n = 0}^\infty \sum_{n = 0}^\infty 2(a_nx^n)(a_{n+2}(n+2)(n+1)x^n) = 0$$ How do I further solve this? The double summation is throwing me off. Thank you in advance.","['sequences-and-series', 'calculus', 'ordinary-differential-equations']"
1549418,Adjunction of pushforward and pullback,"Let $f:(X,\mathscr{O}_X)\to (Y,\mathscr{O}_Y)$ be a morphism of ringed spaces. Then for any $\mathscr{O}_X$-module $\mathscr{F}$ and $\mathscr{O}_Y$-module $\mathscr{G}$, there is a natural bijection of sets $$
\operatorname{Hom}_{\mathscr{O}_X}(f^*\mathscr{G},\mathscr{F})\cong \operatorname{Hom}_{\mathscr{O}_Y}(\mathscr{G},f_*\mathscr{F})
$$
giving the adjunction $f^*\dashv f_*$. After some checking, I think more is true: First, we have 
$$
\operatorname{Hom}_{\mathscr{O}_X}(f^*\mathscr{G},\mathscr{F})\cong \operatorname{Hom}_{\mathscr{O}_Y}(\mathscr{G},f_*\mathscr{F})
$$
as $\Gamma(Y,\mathscr{O}_Y)$-modules, where $\operatorname{Hom}_{\mathscr{O}_X}(f^*\mathscr{G},\mathscr{F})$ has the $\Gamma(Y,\mathscr{O}_Y)$-module structure given by the contraction $\Gamma(Y,\mathscr{O}_Y)\to \Gamma(X,\mathscr{O}_X)$. Therefore, it leads to me concluding that there is an isomorphism of $\mathscr{O}_Y$-modules
  $$
f_*\mathscr{H}om_{\mathscr{O}_X}(f^*\mathscr{G},\mathscr{F})\cong \mathscr{H}om_{\mathscr{O}_Y}(\mathscr{G},f_*\mathscr{F})
$$
  and equivalently an isomorphism of $\mathscr{O}_X$-modules
  $$
\mathscr{H}om_{\mathscr{O}_X}(f^*\mathscr{G},\mathscr{F})\cong f^*\mathscr{H}om_{\mathscr{O}_Y}(\mathscr{G},f_*\mathscr{F}).
$$ Please correct me if I am wrong, I want to be sure.","['abstract-algebra', 'algebraic-geometry', 'quasicoherent-sheaves', 'sheaf-theory']"
1549420,Is $\sqrt{\cos^2(x)} = |\cos x|$?,"I am taking the principal root of $\cos^2(x)$ so I thought it would be, but when you ask wolfram alpha it says it's only sometimes true, when $x > 0$ (see here ). Can someone explain why this is to me and give a value of $x$ for which it is not true? 
I'm just an $11$th grader in trig, so I probably won't understand it if you make it too complex.
Thanks. Sorry if the tag is off.",['trigonometry']
1549446,"Let $X=\ell^\infty$, $f_m \in X^*$ be defined as $f_m(\langle x_n\rangle)=x_m$. Does $(f_n)_{n\in \bf N}$ has a weak* convergent subsequence?","Let $X=\ell^\infty$, $f_m \in X^*$ be defined as $f_m(\langle x_n\rangle)=x_m$.Does $(f_n)_{n\in \bf N}$ has a weak* convergent subsequence? I think $(f_n)$ does not have convergent subsequence but unable to prove this properly. Please help!","['weak-convergence', 'functional-analysis']"
1549449,Inverse Trigonometry Question (Stuck in Algebraic Simplification),"The original question: If x and y are of same sign, then find the value of $$\cfrac{x^3}{2} \csc^2 \left(\cfrac{1}{2}\tan^{-1} \cfrac{x}{y}\right) + \cfrac{y^3}{2} \sec^2 \left(\cfrac{1}{2}\tan^{-1} \cfrac{y}{x} \right) $$ This is my attempt to the question: $$\cfrac{x^3}{2\sin^2 \left(\cfrac{1}{2}\tan^{-1} \cfrac{x}{y}\right)} + \cfrac{y^3}{2\cos^2 \left(\cfrac{1}{2}\tan^{-1} \cfrac{y}{x} \right)} $$
$$
=\cfrac{x^3}{1-\cos(\tan^{-1} (x/y))} + \cfrac{y^3}{1+\cos(\tan^{-1}(y/x))} $$
$$
=\cfrac{x^3}{1 - \cfrac{|y|}{\sqrt{x^2+y^2}}} + \cfrac{y^3}{1+\cfrac{|x|}{\sqrt{x^2+y^2}}} $$ I'm not sure how to simplify this further. I've been trying to simplify this further for a long time but couldn't get any desirable answer. Options are: (A) $(x-y)(x^2+y^2)$
(B) $(x+y)(x^2-y^2)$
(C) $(x+y)(x^2+y^2)$ Also, any other better/alternate way to approach the question is welcomed.","['calculus', 'trigonometry']"
1549454,Is there a stable probability distribution on the rational numbers?,"Does there exist a (non-trivial) probability distribution on the rational numbers
$$\sum_{r\in\mathbb{Q}}p_r=1$$
with $0\leq p_r$, which is stable, meaning that the sum of two i.i.d. random variables with this distribution has a scaling of this distribution (by a rational number, obviously)? Or in other words, does there exist a $p_r$ and $s\in\mathbb{Q}$ such that for each $r\in\mathbb{Q}$
$$\sum_{t\in\mathbb{Q}}p_t p_{r-t}=p_{sr}?$$
I think the answer is no but I can't prove it. The approach I was originally trying to use was to construct a stable distribution by constructing a 'characteristic function' of it on the Pontryagin dual of the rationals, since solving for 'multiplicative scaling' ($f(x)\cdot f(x) \propto f(\alpha x)$) is a lot easier than solving for 'convolutional scaling' ($f(x)\star f(x) \propto f(\alpha x)$), but the Pontryagin dual of the rationals is rather complicated and everything I can think of seems to boil back down to the original problem or seems like a non-starter. The only approach I can come up with to prove that it's impossible is to think of the distribution as a weird real-valued distribution and to use the central limit theorem (or a generalization) to show that the sum of a sequence of i.i.d. rational-valued distributions always converges in distribution to something that can't correspond to a rational-valued distribution.","['probability-theory', 'rational-numbers', 'probability-distributions', 'characters', 'harmonic-analysis']"
