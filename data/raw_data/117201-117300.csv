question_id,title,body,tags
1730299,Eigenvalues of block matrix related,"What are the eigenvalues of following block matrix? $$\begin{bmatrix}
A & B \\ 
B^T & O
\end{bmatrix}$$ Here, $A$ and $B$ are any square matrices of order $n$ , $O$ is zero matrix of order $n$ .","['matrices', 'eigenvalues-eigenvectors', 'block-matrices']"
1730313,Combinatorial argument for $1+\sum_{r=1}^{r=n} r\cdot r! = (n+1)!$ [duplicate],"This question already has an answer here : Calculating $\sum_{k=1}^nk(k!)$ combinatorially [duplicate] (1 answer) Closed 8 years ago . Combinatorial argument for $$1+\sum\limits_{r=1}^{r=n} \ r\cdot r! = (n+1)!$$ 
The algebraic proof is easy as $r=(r+1)-1$.","['combinatorics', 'factorial', 'summation', 'combinatorial-proofs']"
1730327,"If $n = a^2 + b^2 + c^2$ for positive integers $a$, $b$,$c$, show that there exist positive integers $x$, $y$, $z$ such that $n^2 = x^2 + y^2 + z^2$.","If $n = a^2 + b^2 + c^2$ for positive integers $a$, $b$,$c$, show that there exist positive integers $x$, $y$, $z$ such that $n^2 = x^2 + y^2 + z^2$. I feel that the problem basically uses algebraic manipulation even though it's in a Number Theory textbook. I don't realize how to show $(a^2+b^2+c^2)^2$ as the sum of three squares. I have tried algebraic manipulation but this is the stage I have reached. $$(b^2 + c^2)^2 + a^2(a^2 + b^2 + c^2 + b^2 + c^2)$$ Could you give me some hints on how to proceed with this question? Thanks.","['number-theory', 'sums-of-squares', 'elementary-number-theory']"
1730344,"Laurent series of function, partial fraction decomp. problem","Find the Laurent series of $f(z)$ in the region $1<|z-i|<\sqrt{2}$
$$f(z) = \frac{1}{z(z-i)^2(z-1)} $$
The region doesn't include any of the singularities hence expansion is possible The problem is there is too much going on, I don't know what to do with the $\frac{1}{(z-i)^2}$ term in this situation. I could look at two separate factors
$$\frac{1}{z(z-1)}\cdot \frac{1}{(z-i)^2} = \frac{A}{z(z-1)} + \frac{B}{(z-i)^2}, A,B\in\mathbb{C}$$
but I can't determine $A,B$. Assuming $A,B$ are determined the first series is easy and for the second we can use the fact that $-\left (\frac{1}{z-i}\right )' = \frac{1}{(z-i)^2}$. Trouble is, what to do with $A,B$? And how would the final series look like? Can we just add the two series together? Alternative ideas also welcome. Attempt: We have
$$A(z-i)^2 + Bz(z-1) = 1 = Az^2 -2Aiz -A + Bz^2 -Bz $$
We know that $(2Ai+B)z = 0\Longrightarrow 2Ai + B=0$, meaning $B=-2Ai$, but now I don't see where I would get enough information to determine what $A$ is. Scratch that - unnecessary work","['laurent-series', 'complex-analysis']"
1730352,Demystifying modular forms,"I am really struggling to understand what modular forms are and how I should think of them. Unfortunately I often see others being in the same shoes as me when it comes to modular forms, I imagine because the amount of background knowledge needed to fully appreciate and grasp the constructions and methods is rather large, so hopefully with this post some clarity can be offered, also for future readers.. The usual definitions one comes across are often of the form: (here taken from wikipedia ) A modular form is a (complex) analytic function on the upper
  half-plane satisfying a certain kind of functional equation with
  respect to the group action of the modular group, and also satisfying
  a growth condition. A modular form of weight $k$ for the modular group $$
 \text{SL}(2,\mathbb{Z})=\left\{\begin{pmatrix} a & b \\ c & d
 \end{pmatrix}| a,b,c,d \in \mathbb{Z} , ad-bc = 1 \right\} $$ is a
  complex-valued function  $f$  on the upper half-plane $\mathbf{H}=\{z
 \in \mathbb{C},\text{Im}(z)>0 \}$, satisfying the following three
  conditions: $f$ is a holomorphic function on $\mathbf{H}.$ For any $z \in \mathbf{H}$ and any matrix in $\text{SL}(2,\mathbb{Z})$ as above, we have: $$
 f\left(\frac{az+b}{cz+d}\right)=(cz+d)^k f(z) $$ $f$ is required to be holomorphic as $z\to i\infty.$ Questions : (a): I guess what I'm having least familiarity with is the modular group part. My interpretation of $\text{SL}(2,\mathbb{Z}):$ The set of all $2$ by $2$ matrices, with integer components, having their determinant equal to $1.$ But where does the name come from, as in why do we call this set a group and what modular entails? (b): If I understand correctly, the group operation here is function composition, of type: $\begin{pmatrix}a & b \\ c & d\end{pmatrix}z = \frac{az+b}{cz+d}$ which is also called a linear fractional transformation. How should one interpret the condition $2.$ that $f$ has to satisfy? My observation is that, as a result of the group operation of $\text{SL}$ on a given integer $z,$ the corresponding image is multiplied by a polynomial of order $k$ (which is the weight of the modular form). (c) The condition $3.$ I interpret as: $f$ should not exhibit any poles in the upper half plane, not even at infinity. About right? (d) A more general question: Given the definition above, it is tempting to see modular forms as particular classes of functions, much like the Schwartz class of functions, or $L^p$ functions and so on. Is this an acceptable assessment of modular forms? (e) Last question: It is often said that modular forms have interesting Fourier transforms, as in their Fourier coefficients are often interesting (or known) sequences. Is there an intuitive way of seeing, from the definition of modular forms, the above expectation of their Fourier transforms?","['number-theory', 'complex-analysis', 'modular-forms']"
1730353,Determine the convergence of the following series $\sum_{n=2}^{\infty} (-1)^n \frac{1}{\sqrt{n} + (-1)^n}$,"$\sum_{n=2}^{\infty} (-1)^n \frac{1}{\sqrt{n} + (-1)^n}$ Now i know that this is alternating series which means that i should determine the  absolute convergence $|a_n|=\frac{1}{\sqrt{n} + (-1)^n}$ but i don't know how to do it, d'Alembert's test isn't working Cauchy tests can't help here here either so i am out of ideas now.","['sequences-and-series', 'calculus']"
1730359,Tangent Space Well Defined?,"Question: Let $M$ be a $k$-manifold of class $C^r$ in $\mathbb R^n$. Let  $p\in M$. Show that the tangent space to $M$ at $p$ is well-defined, independent of choice patch. Unsure if I'm understanding what this is asking of me. What does it mean to be well defined and how do I prove it? From Munkres Calculus on Manifolds Thanks in advance!","['manifolds', 'differential-geometry']"
1730383,combinatorics - why my reasoning is wrong?,"we have 22 balls (5 red, 7 green and 10 blue). i wrote this as an anwser to the question : what is the probability to get 3 colors when picking 8 balls at once ? $$\frac{C_5^1 * C_7^1 * C_{10}^1*C_{19}^5}{C_{22}^8} $$ it appears that this is wrong. anyone help understand why?
for me i can choose a ball from each color and then choose the rest. I also tried : $$1-\frac{C_{12}^8 + C_{15}^8 + C_{17}^8}{C_{22}^8}$$ thinking that we can take the event having one or two colors. Also this appears not to be true. Anyone can help?","['inclusion-exclusion', 'combinatorics']"
1730384,Area of a circle $\pi r^2$,"So, today I learned that the area of a circle is $\pi r^2$. So, I thought that since $r$ is $1$ dimensional, $r^2$ will be $2$ dimensional. In this case, a square, as you only multiply $2$ dimensions (without additional manipulation to change the shape). But then, what does $\pi$ do to the square? How can a square become a circle with $\pi$? Possible answers that I thought are that the area of the circle is equal to $3.1415\ldots$ squares (with $r$ side length). And that the formula $\pi r^2$ is derived from a long formula(I would like to know the long formula if this is true, because how do mathematicians get the area of the circle before comparing in the first place?) I asked my teacher about this but he can't really understand me. So, I hope experts at StackExchange understand my problem. A picture I drew, showing that $r^2$ is a square","['circles', 'area', 'pi', 'geometry']"
1730393,How to evaluate $\lim_{n\rightarrow \infty }n\left [ \widetilde{H_{n}}-H_{2n}+H_n \right ]$?,How to evaluate this limit with harmonic numbers $$\lim_{n\rightarrow \infty }n\left [ \widetilde{H_{n}}-H_{2n}+H_n \right ]$$ where $$\displaystyle \widetilde{H_{n}}=\sum_{j=1}^{n}\frac{\left ( -1 \right )^{j-1}}{j}$$ is the alternating harmonic number?,"['real-analysis', 'limits', 'integration', 'harmonic-numbers', 'sequences-and-series']"
1730413,Find the value of sum (n/2^n) [duplicate],"This question already has answers here : What does $\sum_{k=0}^\infty \frac{k}{2^k}$ converge to? (3 answers) Closed 7 years ago . I have the series $\sum_{n=0}^\infty \frac{n}{2^n}$. I must show that it converges to 2. I was given a hint to take the derivative of $\sum_{n=0}^\infty x^n$ and multiply by $x$ , which gives $\sum_{n=1}^\infty nx^n$ , or $\sum_{n=0}^\infty nx^n$. Clearly if I take $x=\frac{1}{2}$ , the series is  $\sum_{n=0}^\infty \frac{n}{2^n}$. How do I proceed from here?","['real-analysis', 'limits', 'sequences-and-series', 'calculus', 'convergence-divergence']"
1730418,Derivative of a logarithm and Dirac delta function,"I'm reading Polyakov's book, Gauge fields and strings. There is this formula (9.247) which I do not really understand how to get.
The formula states that in two dimensions, taking $z$ as my holomorphic and $\bar{z}$ as my antiholomorphic variable, the following relation holds $$\partial_{\bar{z}}\frac{1}{z-w}=-\pi \delta(z-w)$$ How does one find this?","['complex-analysis', 'dirac-delta']"
1730468,Group theoretic meaning of natural isomorphisms between certain functors,"So imagine you have a group $G$ and we consider the set of group homomorphisms from $\mathbb{Z}$ to  $G$ specified by  $\forall g$ $\in G$ $\exists$   $\phi(1)=g$. Each of these homomorphisms is in 1-1 relation with the elements of $G$. Consider groups for a moment in the context of category theory, viewing the groups as one object categories and thereof group homomorphism as functors. What would a natural isomorphism mean in group theory terms for G? My thoughts are that the natural transformations equate to maps between homomorphisms and since the homomorphisms are in 1-1 relation with the elements of G, then a natural transformation is a map between group elements, i.e another element of the group. I'm not entirely convinced by this. Anyway continuing my reasoning a natural isomorphism is a map between the homomorphisms that has an inverse, the thing is in relation to the elements of G this is every element? Furthermore I'm looking to find an equivalence class defined by this natural isomorphism, is this just a collection of the elements that are each others inverses? Thanks in advance for any assistance.","['category-theory', 'group-theory']"
1730551,Probability of triangle to be obtuse,"Two points $A,B$ fixed on a plane(distance = 2). C - random choosen point inside circle with radius $R$ with center at the center of $AB$ Find probability of triangle $ABC$ to be obtuse My thoughts: If $C$ lies in the circle - $ABC$ will be rectangular Opposite the larger angle is large side, so using cosine theorem: 
$$
b^2+c^2<a^2=4R^2,
$$
where $a$ - the diagonal, $b=AC, c=BC$ And then I don't know...","['probability-theory', 'geometric-probability', 'geometry']"
1730590,Is this casino promotion exploitable?,The promotion is like this: Starting credit: 500 dollars Maximum bet: 500 dollars Win up to 10000 dollars and get 10000 dollars free . House edge 52.5%. Is this exploitable?,"['probability', 'gambling']"
1730593,Average Perimeter With n Points on the Unit Circle,"A couple days ago, a friend challenged me to solve a problem: You have N vertices, each randomly placed on the edge of a unit circle. What is the formula (given N) that yields the average perimeter of these polygons. Note that the points are not connected by the order in which they were placed, but rather by which points are closest together. i.e. You sweep in a clockwise direction tracing the polygon by the order you come across the points after the points have been randomly placed. After some hard thought, I came up with what I think may be the solution: $$n\int_0^{2\pi} \frac{(n-1)(1-\frac{x}{2\pi})^{n-2}}{2\pi} \times \sqrt{2-2\cos {x}} \, dx$$ This formula finds the average secant length length for $n$ vertices and multiplies that length by the number of sides; however, I have a feeling this does not solve the problem because the lengths of the secants in the polygon depend on each other. I would like someone to confirm my suspicions, tell me that my formula works, or give me a different reason why the formula doesn't work. Please Do Not Solve This Problem For Me I still want to solve it on my own if this is not the solution.","['geometric-probability', 'polygons', 'calculus', 'probability', 'geometry']"
1730607,Computing the Picard group of Number Fields in analogy with genus $0$ curves,"It is possible to compute the Picard group of (some? all?) genus $0$ curves in the following manner: For concreteness let, $A = k[x,y]/(x^2+y^2-1)$ and $X = \operatorname{Spec} A$. Let $Y$ denote $\operatorname{Proj} k[x,y,z]/(x^2+y^2-z^2)$. Let $k$ be any field for now. Then, either by general theory or by explicit computation, we can find an isomorphism $\pi: Y \to \mathbb P^1$. Now $X$ is an open subscheme of $Y$ that either misses two degree one points or one degree two points depending on whether $k$ contains $\sqrt{-1}$. By the above isomorphism, we know that $\operatorname{Pic} Y = \operatorname{Pic} \Bbb P^1 = \Bbb Z$. The Picard group is easily seen to be isomorphic to the Class groups in this case and the excision sequence gives us the following:
$$G \to \operatorname{Cl} Y \to \operatorname{Cl} X \to 0$$
where $G = \Bbb Z$ or $\Bbb Z\oplus \Bbb Z $ depending on whether $X$ misses one point or two. This lets us compute the class group of $X$ and it turns out to be either trivial or $\Bbb Z/2$. The analogy: I believe there is some sort of strong analogy between $A$ and $\Bbb Z[\sqrt{-5}]$ when $k$ does not contain $\sqrt{-1}$. For instance, I think both rings are not UFD's ""only"" because of the factorizations:
$$x^2 = (1-y)(1+y), 2\times 3 = (1+\sqrt{-5})(1+\sqrt{-5})$$
where $x$ is roughly equivalent to $2/3$ and $y$ is $\sqrt{-5}$. Both factorizations seem to occur because we can write a square as a difference of two squares($5 = 3^2-2^2$.) Questions: Can one make this analogy precise? Does it extend to other genus $0$ curves/(quadratic?) number fields? What about higher genus? If one can make this analogy precise, does the above method also let us compute the Class groups of number fields? A reference(with maybe a short explanation if possible) would be perfectly acceptable as an answer.","['algebraic-curves', 'ideal-class-group', 'algebraic-number-theory', 'algebraic-geometry']"
1730628,Why are differential equations with sinusoidal source terms easier to solve than others?,"I am a software engineer trying to wrap my tiny human brain around Fourier Transforms for a project I'm currently working on. Although I will ultimately use an open source Math library to do all the heavy lifting for me, I don't like to do anything without at least having a basic understanding of it, so I came here. My understanding is that linear differential equations with non-sinusoidal source terms are hard to solve (though I don't understand why). And so Fourier Transform helps convert these problems into several component linear differential equations with sinusoidal source terms, which are apparently easy to solve. So first, if I have misunderstood the motivation/reasoning behind the use of Fourier Transforms, please begin by correcting me! Assuming I'm more or less correct, there are a few mental blockers for me here: Does Fourier Transform only apply to linear differential equations? If so, why? How many smaller ""component"" functions (with sinusoidal source terms) does Fourier Transform produce? Moreover, why (from a 30,000 ft view) is solving something like this (don't get hung up on the specific functional definitions, I'm just providing these as straw men examples): L[y(t)] = 3t^2 + 4t + 8          // Non-sinusoidal source term harder to solve than something like this: L[y(t)] = 2sin(4*PI + t) - 20    // Sinusoidal source term ? Thanks for any-and-all clarification/help.","['fourier-analysis', 'soft-question', 'motivation', 'ordinary-differential-equations', 'fourier-transform']"
1730629,A simple betting game,"Consider the following betting game: Two players each have 100 cents to bet. If one player bets more than the other then that player gains a point and the other player loses a point. The goal of the game is to get two points. The betted money is lost from the game entirely (In other words, each player can only bet 100 cents in total). In principle one could make a finite (expect for the zero loop) game tree for this game and there would be a winning strategy. Now suppose we modify the game, players can bet any real number between zero and one. The game tree is no longer finite. But is there still a winning strategy? What is this strategy? Naively, you could in principle construct game trees for the finite games, but further subdivide the interval $[0,1]$. Is it plausible to expect some kind of convergence of winning strategies to the continuous case? I have no knowledge of game theory whatsoever, but I find this an interesting question. Maybe this is well-known, but google didn't find a solution immediately. Thanks in advance for any ideas.","['game-theory', 'probability-theory']"
1730687,Simplification of surds $\frac{x}{\sqrt{x^2 - x^4}}$,"$$\frac{x}{\sqrt{x^2 - x^4}}$$ I believe that I can factor out the $x^2$ in the square root to get
$$\frac{1}{\sqrt{1-x^2}} .$$ However, Wolfram Alpha doesn't do the simplification, hence my confusion.","['algebra-precalculus', 'radicals']"
1730703,What's the minimal $k$ satisfying these conditions? Graph theory problem.,"I'm thinking following problem. There are five pairs of couples (So, ten people total) and $k$ clubs satisfying following three conditions. Let $A,B$ are arbitrary people among those 10, If $A$ and $B$ are a couple, they never belong to same club. If $A$ and $B$ are two people and not a couple, exactly one club contains both of them. There exists at least one person that belongs to exactly two clubs. What is the minimum number $k$ satisfying above conditions? I believe the graph theoretic interpretation is useful to solve this problem. To get some intuition, I tried three couples case. and it seems minimal $k$ is $4$ , I think. but for the case of five couples, I still don't know. Is there any systematic way to approach these kinds of problems? Also, can we solve above problem for arbitrary $n$ couples case?","['combinatorics', 'graph-theory', 'contest-math', 'extremal-combinatorics']"
1730724,Evaluating a line integral of an ellipse with initial and terminal points; unsure about how to parametrize ellipse.,"I'm working on a calculus 3 problem where I am asked to evaluate a line integral given initial and terminal points. However, the question specifies that I should let C be the upper half of the ellipse, where the intersection of the ellipsoid is $$
x^2+y^2+3z^2=3
$$ and the plane $$ y=\sqrt{2}x $$ What confuses me is how I should parametrize this ellipsoid. I'm assuming because they're asking for the top half of the ellipse, I should assume $$0\leq t \leq \pi$$ More specifically, does the direction matter when I'm parametrizing an ellipsoid (clockwise vs. counter-clockwise)? I'm also not that great at parametrization in general so I'm not sure if I'm on the right track or not. What I have so far is $$ x^2+y^2+3z^2=3$$
$$ y=\sqrt{2}x$$ which led me to $$ x=\sqrt{3-y^2-3z^2}$$
$$ y=\sqrt{2}x$$ I'm unsure of how to proceed after this to complete my parametrization. Any help or tips would be greatly appreciated! Thanks!","['multivariable-calculus', 'parametrization']"
1730766,"What is the quotient space of $\mathbb{Z}$-indexed $\{0,1\}$-sequences with resprect to shifts?","Let $V=\{0,1\}^{\mathbb{Z}}$ be equipped with product topology. For $k\in\mathbb{Z}$ let $T^k:V\rightarrow V$ be the shift-by-$k$-operator, so
$$T^k((x_j)_{j\in\mathbb{Z}}):=(x_{j+k})_{j\in\mathbb{Z}}.$$
Two elements $x,y\in V$ are called equivalent (denoted by $x\sim y$) iff there is a $k\in\mathbb{Z}$ such that $T^k(x)=y$. What is the quotient space of $V$ with respect to $\sim$, what is it homeomorphic to?","['general-topology', 'group-theory']"
1730781,Proving that $0\cdot x=0$ using field axioms,"Consider the following axiomatic definition of a field: A field is a set $F$ together with two binary operations $+$ and $\cdot$ on $F$ such that $(F,+)$ is an Abelian group with identity $0$ and $(F\setminus\{0\},\cdot)$ is an Abelian group with identity $1$, and the following left-distributive law holds: $$a\cdot(b+c)=(a\cdot b)+(a\cdot c)\quad\forall a,b,c\in F.$$ I want to show that $0\cdot x=0$ for any $x\in F$ using these, and only these , field axioms. I can prove that $x\cdot 0=0$ using left-distributivity, but multiplication with $0$ is not necessary commutative a priori [that $(F\setminus\{0\},\cdot)$ is an Abelian group does not say anything about multiplication with $0$]. Any hint would be appreciated. To elaborate on my point, let me prove that $x\cdot 0=0$ for any $x\in F$:
\begin{align*}
0+0=&\,0\\
\Downarrow&\,\\
x\cdot(0+0)=&\,x\cdot0\\
\Downarrow&\,\text{(left-distributivity)}\\
(x\cdot 0)+(x\cdot 0)=&\,x\cdot 0\\
\Downarrow&\,\\
[(x\cdot 0)+(x\cdot 0)]+[-(x\cdot 0)]=&\,x\cdot 0+[-(x\cdot 0)]\\
\Downarrow&\,\\
(x\cdot0)+\{(x\cdot0)+[-(x\cdot0)]\}=&\,0\\
\Downarrow&\,\\
(x\cdot0)+0=&\,0\\
\Downarrow&\,\\
x\cdot0=&\,0.
\end{align*}
My problem is I would need to exploit right-distributivity to show that $0\cdot x=0$, but right-distributivity does not follow immediately from the axioms.",['abstract-algebra']
1730792,suppose a sample is taken from a symmetric distribution whose tails decrease more slowly than those of a normal distribution,"I was wondering how to go about this question about Probability QQ Plots, the question is, suppose a sample is taken from a symmetric distribution whose tails decrease more slowly than those of a normal distribution. what would be the qualitative shape of a normal probability plot of this sample?",['statistics']
1730851,Trigonometric polynom,"Prove that $$\cos\frac{\pi}{7},\cos\frac{3\pi}{7},\cos\frac{5\pi}{7}$$ roots of polynomial $8x^3-4x^2-4x+1=0$
I'm confused, what can i do with $\frac{\pi}{7}$","['polynomials', 'trigonometry', 'calculus']"
1730867,Show that the triangle is equilateral triangle,"If a triangle $ABC$ has the equality $$h_a\cdot\sqrt{3} +\frac{a}{2}= b + c$$ $h_a$ is the height from $A$, then show that the triangle is equilateral. Using sine rule, I tried to show that bring equality to a form of showing that $A=B=C=\frac{\pi}{3}$ but I managed. Does anyone have a solution? Thank you very much!",['trigonometry']
1730868,Find $g(x)$ given $f(x)$ and the composition $(g \circ f)(x)$,"I've been stuck on this final math problem for ages I'm given $$f(x) = x^2 + 1$$ and the final composition is $$(g \circ f)(x) = \frac{1}{x^2 + 4}.$$ I'm asked to find that $g(x)$ was in order to make this true, but I'm not sure how?",['functions']
1730884,Series solution to this differential equation,"$$ y' - e^{x^2}y = 0 $$ I've learned how to get the series solution for such differential equations when the multiplicating function is polynomial, but I have no clue what to do with another function.  Here's what I've tried : $$ \sum_1^\infty na_nx^{n-1} - e^{x^2}\sum_0^\infty a_nx^n = 0$$ $$ \sum_0^\infty (n+1)a_{n+1}x^n - e^{x^2}\sum_0^\infty a_nx^n = 0$$ Then I'm stuck because I don't know what to do with the exponential function.  If it was polynomial, I could simply distribute it in the sum and do a variable change, but how can I treat a such case? Thank you. Actually, I only need to find the first few terms, not the general solution to it (which is probably complicated).",['ordinary-differential-equations']
1730894,Apparently the conormal sheaf of the diagonal constructs differentials ... how do I plug in vectors?,"Let me specify the construction I am thinking about, then I have a specific question to ask at the end. We are given a morphism of schemes $f: X \to Y$ (let's just say separated to avoid something else I am confused about). Then $\Delta : X \to X \times_Y X$ is a closed immersion, and we can construct the conormal sheaf on $X$ as $\Delta^*(I)$, where $I$ is the ideal sheaf cutting out $\Delta : X \to X \times_Y X$. Let $p_1$ and $p_2$ denote the two projection maps from $X \times_Y X \to X$. Given a section $f \in \Gamma(U,O_X)$, we can build a section of $I$ on $X \times_Y X$ by $p_1^*(f) - p_2^*(f)$. I am pretty confused about the construction (though I can understand the details of the following proofs in Ravi that show it is naturally / universally isomorphic on affines to the sheafification of the Kaehler differential construction). If this is supposed to be a differential, how can I plug in tangent vectors to it? I'm talking calculus here, hopefully nothing fancy... we are pulling back (polynomial) functions on $\mathbb{R}$ via the projections $\mathbb{R}^2 \to \mathbb{R}$ and taking their difference - the tricky spot is that one has to do something in pulling it back to a sheaf on $X$. But I guess there is a calculus style way to interpret this, and I am missing that piece of intuition. One can try to push forward tangent vectors from the diagonal (it's a closed immersion), and then try to plug them into $p_1^*(f) - p_2^*(f)$. How can this be done? Is my question clear?","['algebraic-geometry', 'calculus']"
1730952,Left and right derivatives of characteristic function $X_Q$,"Find the left and right derivatives of a characteristic function of $Q$. My attempt: I tried deriving the result from the definition of right and left derivatives, which are $$D^+f(x)=\lim\limits_{h \to 0}\left[\sup\limits_{0<|t|\leq h}\frac{f(x+t)-f(x)}{t}\right] \text{  and  } D^-f(x)=\lim\limits_{h \to 0}\left[\inf\limits_{0<|t|\leq h}\frac{f(x+t)-f(x)}{t}\right]$$ Now, let $Q$ be a set of rationals where $f(x) = 1$ for every $x\in Q$, and $f(x) = 0$ otherwise. Now, we see that for $x\in Q$, no matter how small $h$ is, we can always find $t<0$ such that $f(x+t) = 0$. Therefore, $f(x+t) - f(x) = -1$, so for $t<0$, $D^+f(x) =  \infty$.  Similarly, for $x\in Q$, $D^-f(x) = -\infty$ as there exists some $t>0$ such that no matter how small $h$ is, $f(x+t) = 0$. Similarly, for $x\notin Q$, no matter how small $h$ is, there exists a $t\in (0,h)$ such that $x+t\in Q$. Thus, $D^+f(x) =  \infty$ in this case. Obviously, since we can always pick $t$ such that no matter how small $h$ is, $x+t\notin Q$. Thus, $D^-f(x) = 0$. Can anyone please help review my argument above to see if it's correct? If not, please help correct it if you can.","['derivatives', 'measure-theory']"
1730965,Simple predicate question,"I know if a set $A$ is $A=\{x\mid P(x)\}$, then $x\in A$ if and only if $P(x)$. My qeustion is what is $A=\{x\in B\mid P(x)\}$? $x\in B$ and $P(x)$ if anf only if $x\in A$?",['elementary-set-theory']
1731014,What is an equivalence class of an equivalence relation?,"I might be interpreting this wrong but in my book it says: If ~ defines an equivalence relation on $A$ then the set of equivalence classes of ~ form a partition of $A$. To me, this means that the set of equivalence classes of the elements of $A$ forms a partition $A_i$ for some $i \in I$ (I is an indexing set). ex: let $A = \{a,b,c\}$ and let ~$ \subseteq A \times A$ denote the equivalence relation ~, where the set of equivalence classes are $\{\langle a,c\rangle,\langle c,a\rangle \}$ since the equivalence of $a$ is $c$ and the equivalence of $c$ is $a$. (is this a correct use of these terms?). So the set $\{\langle a,c\rangle,\langle c,a\rangle \}$ is a partition of $A$? I don't get why this becomes a partition, assuming what I did was correct.","['equivalence-relations', 'elementary-set-theory']"
1731030,Why does addition not make sense on infinite vectors?,"I was reading http://www.math.lsa.umich.edu/~kesmith/infinite.pdf to learn more about infinite dimensional vector spaces, and the author argues that the standard basis ($e_i$ is the sequence of all zeroes except in the i-th position, where there appears a 1), does not form a basis for $\mathbb{R}^\infty$ because the span is only defined over the sum over finitely many basis vectors. So, she argues, a vector like $(1,1,1,\dots)$ is not in the span. If we allow the span to be defined over an infinite sum, then, the author argues, something like $(1,1,1,\dots)+(2,2,2,\dots)+(3,3,3,\dots)$ does not make sense, and thus we have to restrict the span to a finite sum. I do not understand why this is not simply $(6,6,6,\dots).$ More fundamentally, why can't we generalize the span to include an infinite sum of the basis vectors?","['sequences-and-series', 'vector-spaces']"
1731053,"Induction Proof: If $B \subseteq A$, then $|B| \leq |A|$.","Prove by induction that if $A$ is a finite set and $B$ is a subset of $A$, then $|B|≤ |A|$. I can prove the base case with $n=0$ easily, but am stuck as to how to proceed from there.","['induction', 'proof-writing', 'elementary-set-theory']"
1731077,Probability of drawing cards in ascending order,Given 200 cards where each card has a unique number from 1 to 200. We randomly pick 30 cards (the order we pick them matters). What is the probability the unique numbers of the cards we pick are in ascending order?,['probability']
1731086,Prove that $\int_1^{\frac{1+z}{1-z}} \frac{d^n}{dz^n} (z^2-1)^n= -\frac{2(z-1)^n}{(n+1)! }\frac{d^n}{dz^n} (\frac{z}{z-1})^{n+1} $,"Prove that 
  $$\int_1^{\frac{1+z}{1-z}} \frac{d^n}{dz^n} (z^2-1)^n= -\frac{2(z-1)^n}{(n+1)! }\frac{d^n}{dz^n} (\frac{z}{z-1})^{n+1} $$ Here are some attempts. $\frac{d^n}{dz^n} (z^2-1)^n=2^n n! L_n(z),$ where $L_n(z)$ is the Legendre polynomials. I tried to use following formula for Legendre polynomials 
$$\frac{x^2-1}{n} \frac{d}{dx}L_n(x)=xL_n(x)-L_{n-1}(x).$$
But I get tripped up on it.","['derivatives', 'orthogonal-polynomials']"
1731094,Integrating Dirichlet Distribution,"Let's say that $(X_1, \dots, X_4) \sim Dirichlet(\alpha_1, \dots, \alpha_4)$ with $\sum_{i=1}^4 X_i=1$. I want to find the distribution of $(X_1, X_2)$. I know the marginal distributions of the $X_i$ (answered in other questions on this site) but it doesn't seem that this has been answered. Denote the full joint pdf by $f_0$ so that $f_0(x_1, x_2, x_3, x_4) = \frac{1}{B(\vec \alpha)} \prod_{i=1}^4 x_i^{\alpha_i-1}$. I'll denote the joint pdf of $(X_1, X_2)$ by $g$. First of all, since $X_4 = 1 - X_1 - X_2 - X_3$ it seems that I should only consider $X_1$, $X_2$, and $X_3$ and therefore I'll only need to do a single integration. This means that I'll be working with 
$$
f(x_1, x_2, x_3) := \frac{x_1^{\alpha_1 - 1} x_2^{\alpha_2 - 1} x_3^{\alpha_3 - 1}(1-x_1-x_2-x_3)^{\alpha_4-1}}{B(\vec \alpha)}.
$$ From this it follows that
$$
g(x_1, x_2) = \int_{x_3}  f(x_1, x_2, x_3) dx_3
$$ $$
= \frac{x_1^{\alpha_1-1} x_2^{\alpha_2-1}}{B(\vec \alpha)} \int_{x_3}  x_3^{\alpha_3-1} (1-x_1-x_2-x_3)^{\alpha_4-1} dx_3.
$$ My questions: What are the limits of integration here? How do I actually do this integral? I assume that I need to shoehorn it into a beta integral but I don't see how. For the limits of integration, certainly $x_3 \geq 0$, but I don't know what the upper bound is. Would it just be $0 \leq x_3 \leq 1 - x_1 - x_2$? As for the actual integral, if I'm correct about $0 \leq x_3 \leq 1 - x_1 - x_2$ then I just need to be able to do
$$
I = \int_{0}^{1-k} t^{\alpha-1}(1-k-t)^{\beta-1} dt
$$
where $k = x_1 + x_2$, $\alpha = \alpha_3$, and $\beta = \alpha_4$. This looks really close to an incomplete beta but not quite.","['integration', 'probability-distributions']"
1731096,"Understanding limits and how to interpret the meaning of ""arbitrarily close""","I have read several introductory notes on limits of functions, and in all of them they introduce the notion of a limit of a function $f(x)$ by discussing what happens to the value of $f$ as $x$ approaches a given value, say $x=a$. In doing so they use phrases of the form ""if $\lim_{x\rightarrow a}f(x)=L$ exists, this means that given a value of $x$ sufficiently close to $a$ (but not equal to $a$), we can make $f(x)$ arbitrarily close to $L$"" . What confuses me about this is, if one has the result $\lim_{x\rightarrow a}f(x)=L$, does this mean that one should take ""arbitrarily close"" as ""equal to"" ? Is it that since arbitrarily close values of $x$ to $x=a$ lead to the value of $f$ being arbitrarily close to its value at $x=a$, we can imply that the limiting value of $f$ is exactly equal to $L$!? The primary reason I ask is because the derivative is defined as the limit of a diffence quotient that itself is undefined at the point we are approaching, so how is one to interpret the limiting value of this difference quotient $$\lim_{\Delta x\rightarrow 0}\frac{f(x+\Delta x)-f(x)}{\Delta x}=f'(x)$$ how can one state that its limiting value is exactly equal to the slope of the tangent line to the point $x$, equivalently the instantaneous rate of change in the value of the function $f$ with respect $x$ at the point $x$. How can we be certain that this is true? I feel like I might have missing something important here. If anyone can enlighten me it would be much appreciated!","['derivatives', 'intuition', 'limits']"
1731101,Lebesgue integrability implies finite almost everywhere,"Let $(X,\mathcal{M},\mu)$ be any positive measure space. Suppose $f \in \mathcal{L}(X,\mathcal{M},\mu)$. Prove that $f(x)$ must be finite $\mu$-almost everywhere. I have defined a set $$E_n= [{x\in X : |f(x)|\geq n}]$$ which is a measurable set, and have that $$ \int_{E_n}{|f|}d\mu \leq \int_{X}{|f|}d\mu = C$$ for some constant C. At some point I'll have to take the limit of $n$ as $n$ approaches $\infty$, while at the same time using the fact that $E_\infty \subset E_n$. I am unsure of the details or whether this approach is correct.","['lebesgue-integral', 'measure-theory']"
1731114,Ideas for solving this IVP,"I am curious how to approach solving the initial value problem: $\begin{cases} y'(t) = 5t - 3\sqrt{y} \\ y(0) = 2 \end{cases}$. The equation isn't separable, and more generally it is not an exact equation.  Nor does it seem to be readily convertible into an exact equation via an integrating factor.  I am interested in obtaining at least an implicit expression for $y$.  Is it possible to use a Laplace transform to solve this nonlinear IVP?  If not, what approach might one take? How do I solve the ODE by hand, without the help of Maple?","['problem-solving', 'ordinary-differential-equations', 'initial-value-problems']"
1731133,"If $n\in N$ and $f(x)=\ln(1+x^{2n})$, then derivative $f^{(2n)}(-1)=0$.","If $n\in N$ and  $f(x)=\ln(1+x^{2n})$, then derivative  $f^{(2n)}(-1)=0$. I try: $e^{f(x)}=1+x^{2n}$ ,$(f'e^f)'=f''e^f+(f')^2e^f$ but I don't know what next.",['analysis']
1731174,$fg\in L^1$ for every $g\in L^1$ prove $f\in L^{\infty}$,"Let $(X,\mathcal{A}, \mu)$ be an arbitrary measure space. Let $f$ be an extended complex-valued $\mathcal{A}-$measurable function on $X$ such that $|f|<\infty$ $\mu$-a.e. on $X$. Suppose that $fg\in L^1(X,\mathcal{A}, \mu)$ for every $g\in L^1(X,\mathcal{A}, \mu)$. Show that $f\in L^{\infty}(X,\mathcal{A}, \mu)$. Can anyone verify my answer? Does anyone know a better elementary approach? (It'll be great if similar approach can be generalized to the case of $L^p$ and $L^q$) Related question: On $\sigma-$ finite space $fg\in L^1$ for every $g\in L^q$ prove $f\in L^p$ My answer:
For any given $f\notin L^{\infty}$, define $E_n=\{x\in X|n-1<f(x)\leq n\}$, there is a subsequence $E_{n_1}$,...$E_{n_j}$ such that $\mu(E_{n_j})>0$ for each $j$. Define $\displaystyle g=\sum_{j=1}^{\infty}\frac{1}{j^2\mu(E_{n_j})}\mathbb{1}_{E_{n_j}}$, we have $\displaystyle \int_{X}|g|d\mu=\sum_{j=1}^{\infty}\frac{1}{j^2}<\infty$ so $g\in L^1$. However $$\int_{X}|fg|d\mu=\int_{X} \sum_{j=1}^{\infty} \frac{|f|\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}$$
because $f$ is finite almost everywhere and the last expression
$$\int_{X} \sum_{j=1}^{\infty} \frac{|f|\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}>\int_{X} \sum_{j=1}^{\infty} \frac{(n_j-1)\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}>\int_{X} \sum_{j=1}^{\infty} \frac{(j-1)\mathbb{1}_{E_{n_j}}}{j^2\mu(E_{n_j})}=\sum_{j=1}^{\infty}\frac{j-1}{j^2}=\infty$$ by limit comparison with harmonic series. Therefore $fg\notin L^1$","['functional-analysis', 'real-analysis', 'alternative-proof', 'proof-verification']"
1731183,Convert vector into diagonal matrix,"Given a vector $[x_1,x_2,x_3, \dots, x_n]^T$ , is it possible to obtain a diagonal matrix, $
\left[\begin{array}{c c c c c}
x_1 & 0 & 0 & \dots & 0\\
0 & x_2 & 0 & \dots & 0\\
0 & 0 & x_3 & \dots & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \dots & x_n\\
\end{array}
\right]
$ using matrix operations (like multiplication and/or addition with identity matrix etc)? This seems trivial, but I am unable to work it out! I need to do this for automation of process in Maxima, so that I don't have to manually type in the elements diagonally.
Thanks. EDIT: I recently found a direct function diag_matrix(x1,x2,x3,...) in Maxima. Which means that if we have a list [x1, x2, x3] , we can use apply(diag_matrix, [x1, x2, x3]) . I am not sure if it is introduced in a recent version or it existed before I posted this question.",['matrices']
1731195,On $\sigma-$ finite space $fg\in L^1$ for every $g\in L^q$ prove $f\in L^p$,"Let $(X,\mathcal{A}, \mu)$ be an  measure space. Let $f$ be an extended complex-valued $\mathcal{A}-$measurable function on $X$ such that $|f|<\infty$ $\mu$-a.e. on $X$. Suppose that $fg\in L^1(X,\mathcal{A}, \mu)$ for every $g\in L^q(X,\mathcal{A}, \mu)$. Show that $f\in L^{p}(X,\mathcal{A}, \mu)$. $(p>1, q>1, \frac{1}{p}+\frac{1}{q}=1)$ A similar problem I asked $fg\in L^1$ for every $g\in L^1$ prove $f\in L^{\infty}$ but I cannot find similar construction of counterexample in this case $f\notin L^p$. Almost the same problem Given $f\notin L^p$ find $g\in L^q$ s.t. $fg\notin L^1$ , the construction given in the answer require $\mu(f\geq t)$ to be finite, but that is not a condition of the problem (nor can we derive from $f\notin L^p$). Looking for an answer using little or no functional analysis technique.","['functional-analysis', 'real-analysis', 'alternative-proof']"
1731216,Spivak's Chain Rule Proof (Image of proof provided),"If $g$ is differentiable at $a$ , and $f$ is differentiable at $g(a)$ , then $f \circ g$ is differentiable at $a$ , and $$
(f \circ g)^{\prime}(a)=f^{\prime}(g(a)) \cdot g^{\prime}(a).
$$ Define a function $\phi$ as follows: $$
\phi(h)= \begin{cases}\frac{f(g(a+h))-f(g(a))}{g(a+h)-g(a)}, & \text { if } g(a+h)-g(a) \neq 0 \\ f^{\prime}(g(a)), & \text { if } g(a+h)-g(a)=0 .\end{cases}
$$ It should be intuitively clear that $\phi$ is continuous at $0:$ When $h$ is small, $g(a+h)-g(a)$ is also small, so if $g(a+h)-g(a)$ is not zero, then $\phi(h)$ will be close to $f^{\prime}(g(a)) ;$ and if it is zero, then $\phi(h)$ actually equals $f^{\prime}(g(a))$ , which is even better. Since the continuity of $\phi$ is the crux of the whole proof we will provide a careful translation of this intuitive argument. We know that $f$ is differentiable at $g(a) .$ This means that $$
\lim _{k \rightarrow 0} \frac{f(g(a)+k)-f(g(a))}{k}=f^{\prime}(g(a)).
$$ Thus, if $\varepsilon>0$ there is some number $\delta^{\prime}>0$ such that, for all $k$ , $$ \text{if $0<|k|<\delta^{\prime}$, then $\left|\frac{f(g(a)+k)-f(g(a))}{k}-f^{\prime}(g(a))\right|<\varepsilon$}. \tag{1} $$ Now $g$ is differentiable at $a$ , hence continuous at $a$ , so there is a $\delta>0$ such that, for all $h$ , $$\text{ if $|h|<\delta$, then $|g(a+h)-g(a)|<\delta^{\prime} .$}\tag{2}$$ Consider now any $h$ with $|h|<\delta .$ If $k=g(a+h)-g(a) \neq 0$ , then $$
\phi(h)=\frac{f(g(a+h))-f(g(a))}{g(a+h)-g(a)}=\frac{f(g(a)+k)-f(g(a))}{k} ;
$$ it follows from $(2)$ that $|k|<\delta^{\prime}$ , and hence from (1) that $$
\left|\phi(h)-f^{\prime}(g(a))\right|<\varepsilon.
$$ (transcribed from this screenshot) Here is a proof of the chain rule in Spivak's Calculus. Note there is a second page, but I understand it, and this is the meat of the proof. I have a few questions. $\textbf{1.}$ ""It should be intuitively clear that $\phi$ is continuous at $0$ ."" Do we care that it is continuous at zero so we will not have a division by zero since $g(a+h)-g(a)$ is in the denominator and could equal zero? I am not sure I understand why it is continuous at zero. I understand what he was saying but I was always under the impression continuity was when there were no breaks in the graph visually. Here, I am imagining $\phi(h)$ being continuous up to zero, then it jumping to another point when it is zero. $\textbf{2.}$ At (2),I do not understand what we are trying to do here. We randomly switched to $h$ and are defining continuity I think. The switch back and forth from $k$ to $h$ is confusing me.","['derivatives', 'real-analysis', 'chain-rule', 'calculus', 'proof-explanation']"
1731243,Stochastic modeling. A bidding Model,"The Question: 
Let $U_1,U_2,...$ be independent RVs, each uniformly distributed over $(0,1]$. These random variables represent successive bids on an asset that you're trying to sell, and that you must sell by time $t = 1$. As a strategy you adopt a secret number $θ$, and you will accept the first offer that is greater than $θ$. For example, you accept the second offer if $U_1≤θ$ while $U_2>θ$. Suppose that the offers arrive according to a unit rate Poisson process ($λ=1$). What is the probability that you sell the asset by time $t=1$? What is the value for $θ$ that maximizes your expected return? (You get nothing if you don't sell the asset by $t = 1$). To improve your return you adopt a new strategy, which is to accept an offer at time $t$ if it exceeds $θ(t)=(1−t)/(3−t)$. What are your new chances of selling the asset, and what is your new expected return? Just for the first part (1) I'm still quite unsure what to do. What seems somewhat reasonable to me is to calculate $$Pr[X_T(t)>θ|X(t)>0]$$ where $T=\max(U_1,...,U_T>θ)$.  I'm not sure how to calculate this probability either though. Hints and clarifications would be very much appreciated thanks.","['stochastic-processes', 'statistics']"
1731249,Show $f'(0)$ exists and is $L$,"Our assumptions for this problem are: $f$ is continuous on an interval containing $0$ and differentiable for all $x$ not $0$. Moreover, $$\lim_{x \to 0} f'(x) = L.$$ We must show that $f'(0)$ exists and is $L$. My thoughts so far:
I am able to produce a (somewhat drawn out) argument for the case in which $f'$ is differentiable at $0$ but cannot seem to account for when that is not necessarily the case. Any help in reducing this argument to that end is appreciated.","['derivatives', 'limits']"
1731364,Expected value of the Max of three exponential random variables,"So the question asks: Let $X_1,X_2,X_3\sim \operatorname{Exp}(\lambda)$ be independent (exponential) random variables (with $\lambda> 0$). (a) Find the probability density function of the random variable $Z = \max \{X_1,X_2,X_3\}$. (b) Let $T = X_1+X_2/2+X_3/3$, use moment generating functions to prove $Z\sim T$ (same distribution). Find $E[Z]$ and $\operatorname{Var}[Z]$. So far I got: (a)$F(x) = 1-e^{-\lambda x}$ $F_Z(z) = P (Z \leq z) = P(\max(X_1,X_2,X_3) ≤ z) = P(X_1\leq z, X_2 \leq z, X_3 \leq z)= P(X_1\leq z)P(X_2\leq z) P(X_3\leq z) = (1-e^{-\lambda z})^3$ $f_Z(z) = F_Z'(z) = (1-e^{-\lambda z})^3 =3\lambda e^{-3\lambda z}(e^{\lambda z}-1)^2$ (b) for this part, I did not quite understand what it wanted me to prove actually... I got: $M_X(t) = λ/(λ-t )$ $M_Z(t) = M_{X_1}(t)M_{X_2}(t) M_{X_3}(t) = [\lambda/(\lambda-t )]  [\lambda /(2(\lambda-t) ]  [\lambda /(3(\lambda-t) ]=  [\lambda/(\lambda-t)]^3/6$ So what does it mean by  proving $Z\sim T$ (same distribution) ? And for the $E[Z]$ and $\text{Var} [Z]$, I actually tried to do it using the standard method which is $$
E[Z]=\int z\cdot3\lambda e^{-3\lambda z}(e^{\lambda z}-1)^2dz
$$ which becomes super complicated... So is there a simple way to calculate the $E[Z]$ and $\text{Var} [Z]$ without literally solving the integration?","['integration', 'probability', 'moment-generating-functions', 'probability-distributions']"
1731373,Solve this system of equations using elimination for $x(t)$ and $y(t)$,"I'm taking an online Differential Equations class and don't understand how to solve this system of equations using elimination. I tried the typical algebraic method but am running into trouble: $x'+y'-x=5$ $x+y'+y=1$ So $y=x'-2x-4$ $x=-5+x'+y'$ But I can't imagine this is how I leave the equation.  My guess is the equation should be in some form where I can use separation of variables or something, but I'm not entirely sure. Any help is greatly appreciated.","['ordinary-differential-equations', 'systems-of-equations']"
1731382,Is the catenary the trajectory of anything?,"Notice that the parabola, defined by certain properties, is also the trajectory of a cannon ball. Does the same sort of thing hold for the catenary? That is, is the catenary, defined by certain properties, also the trajectory of something?",['calculus']
1731384,How to approximate the derivative of a stock price over time?,"My high school marketing class is about to do a unit on stocks. We're going to make ""pretend"" investments over the next month or so, and have a competition to see who has the highest gains. These are relatively short term investments, so I'm thinking that looking at trends will be key to success. It occurred to me, that trying to approximate the derivative of a stock price over time could be useful to some extent. I'm wondering how I could do that though, given stock price is kind of jerky and irregular, and is also technically discontinuous? Sorry if this is a kind of stupid question. I have some ideas, but I'm not sure if they're the best.","['derivatives', 'continuity']"
1731407,"Continuous bijection from $(a,b) \to S^1$?","This question started bothering me after working on an exercise. I know that there cannot be a contiuous bijection $S^1 \to (a,b)$ because if there was it would be a homeomorphism but $S^1$ and $(a,b)$ are not homeomorphic. But the theorem that implies this is that a continuous bijection from a compact into a Hausdorff space is a homeomorphism. Hence it cannot be applied to the opposite direction. I still suspect that the answer will turn out to be negative, i.e. there is no continuous bijection from $(a,b) \to S^1$ but I don't see how to prove it because the inverse is not required to be continuous. So somehow there still remains a faint possibility for such a map. Please could someone help me resolve my confusion and tell me whether
  there is or is not a continuous bijection $(a,b) \to S^1$?",['general-topology']
1731441,How to compute this double integral,I'm trying to show that $\int_0^1\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}dxdy \neq \int_0^1\int_0^1\frac{x^2-y^2}{(x^2+y^2)^2}dydx$ by computing these integrals directly. I tried using polar coordinates with no success as the bounds of integration caused problems. I also tried the substitution $x=ytan\theta$ but ended up getting something of the form $\infty-\infty$. Can anyone offer a hint as to how I can compute these directly please??? Thanks in advance!,"['multivariable-calculus', 'integration']"
1731455,Interesting representation of $e^x$,"So I discovered the following formula by using the Taylor series for $\ln (x+1)$ $$x= \ln (x+1)+\frac{1}{2}\ln(x^2+1)-\frac{1}{3}\ln(x^3+1)+\frac{1}{2}\ln(x^4+1)-\frac{1}{5}\ln(x^5+1)-\frac{1}{6}\ln(x^6+1)$$$$-\frac{1}{7}\ln(x^7+1)+\frac{1}{2}\ln(x^8+1)-\frac{1}{10}\ln(x^{10}+1)-\frac{1}{11}\ln(x^{11}+1)-\frac{1}{6}\ln(x^{12}+1)$$$$-\frac{1}{13}\ln(x^{13}+1)-\frac{1}{14}\ln(x^{14}+1)+\frac{1}{15}\ln(x^{15}+1)+\frac{1}{2}\ln(x^{16}+1)+...$$
I then realized that this means that $$e^x=\prod_{n=1}^{\infty}(x^n+1)^{a_n},$$ where $a_1 =1$ and $a_n$ is defined by the recurrence relation $$a_n=\sum_{d|n \land d > 1} \frac{a_{\frac{n}{d}}(-1)^d}{d}$$ when $n > 1$. So far, I've noticed the following properties about $a_n$:$$a_{2^m}=\frac{1}{2}$$$$a_p=-\frac{1}{p}$$$$a_{p^k}=0$$ for prime $p>2$, positive integer $m$, and integer $k>1$. When I plugged in the denominators of $a_n$ into OEIS, the closest sequence I got was the sequence of integer radicals . I am interested in the following things: How can we prove my conjecture about $a_n$ (look below, under ""EDIT"")? For what values of $x$ does this product converge? Has this formula for $e^x$ been documented anywhere (I'm sure it has, but I'd like to read the paper)? How does this representation of $e^x$ relate to other representations? Thanks in advance! EDIT After plugging in more values for $a_n$, I realized that my original conjecture that $$\lvert a_n \rvert = \begin{cases}
  \displaystyle\operatorname{rad}(n)^{-1}, & \mbox{if } n \neq p^k \\
  0,  & \mbox{if } n=p^k 
\end{cases}$$ for prime $p>2$ and integer $k>1$, was incorrect when I found that $a_{18}=0$. However, I was able to formulate a new conjecture about $a_n$ based on my findings: $$ a_n = \frac{\mu \left( \operatorname{Od}(n) \right) }{\operatorname{rad}(n)} = \frac{\mu \left( \frac{n}{2^{\nu_2 (n)}} \right) }{\operatorname{rad}(n)} $$
where $\mu(n)$ is the Möbius function , $\nu_p(n)$ is the p -adic order of $n$, $\operatorname{Od}(n)$ is the odd part of $n$, and $\operatorname{rad}(n)$ is the radical of $n$. I had a friend test values for this and it holds for all values up to at least $1024$. Unfortunately, though, I have no idea how to prove this conjecture. NOTE @ZhenhuaLiu has answered my biggest question by proving my conjecture. However, if you do have an answer to any of my other questions, feel free to leave an answer about it.","['recurrence-relations', 'infinite-product', 'number-theory', 'summation', 'sequences-and-series']"
1731462,true or false statements based on predicate logic,"Q) Let $P(x,y)$ be the predicate $y=2x$. Consider the statements a)$\forall x \exists y P(x,y)$ b)$\forall y \exists x P(x,y)$ c)$\exists y \forall x P(x,y)$ where $x$ and $y$ range over the integers. Write whether each statement is true or false and give a very short explanation of why For a) it is false, since for all the values of $x$ won't give the same value of a particular $y$. For b) it is false, since all the values of $y$ cannot be formed by any particular $x$. In the case of $y=1$ it requires $x=0.5$, which is not a discrete number. c) false, some values of $y$ cannot be obtained by all the values of $x$. It would require a $x=y/2$ value. Are my answers correct? Does the justification make sense? Any help would be appreciated. Thanks!","['quantifiers', 'discrete-mathematics']"
1731471,$\mathrm{Aut}(\mathbb{Q}(\pi)/\mathbb{Q})=$?,"Perhaps a silly question. I'm trying to understand trascendental field extensions, but I can't find a lot of instructive examples. Consider the extension $\mathbb{Q}(\pi)/\mathbb{Q}$. What is its group of automorphism, $\mathrm{Aut}(\mathbb{Q}(\pi)/\mathbb{Q})$?","['transcendence-theory', 'abstract-algebra', 'field-theory', 'group-theory']"
1731479,Evaluation of $ \lim\limits_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right]$,"Evaluation of $\displaystyle \lim_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right]$ $\bf{My\; Try::}$ Let $\displaystyle l=\displaystyle \lim_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right]=\lim_{x\rightarrow \infty}x\left[1+(x-1)\ln\left(1+\frac{1}{x}\right)\right]$ So we get $$l=\lim_{x\rightarrow \infty}x\left[1+(1-x)\left(\frac{1}{x}-\frac{1}{2x^2}+\frac{1}{3x^3}-\frac{1}{4x^4}-.........\infty\right)\right]$$ So we get $$l=\lim_{x\rightarrow \infty}x\left[1-1+\frac{1}{2x}-\frac{1}{3x^2}+\frac{1}{4x^3}+\frac{1}{x}-\frac{1}{2x^2}+\frac{1}{3x^3}.....\right] = \frac{3}{2}$$ My Question is How can we solve it without using series expansion, If yes then plz explain here, Thanks","['real-analysis', 'taylor-expansion', 'calculus', 'limits']"
1731491,additive integral property,"There's a common property of definite integrals:
$\int_a^bf(x) \, dx=\int_a^cf(x)\,dx+\int_c^bf(x)\,dx$.
I've often seen it said that $c$ must lie in the interval $[a,b]$. However, is this really the case?
I'm asking as a specialist mathematics high school teacher. All the examples I can think of, considering the integral as denoting the area under the curve, hold true for $c\notin[a,b]$ as well.
Thanks!","['integration', 'definite-integrals', 'area', 'arithmetic']"
1731493,Inconsistencies with multiple differentiation methods,"$$w=\sin x$$ $$\frac{dw}{dx} = \cos x$$ $$\therefore\frac{dx}{dw} = \frac{1}{\cos x}$$ Rearranging the initial relationship; $$x = \arcsin(w)$$ $$\therefore\frac{dx}{dw} = \frac{1}{(1-w^2)^{0.5}}$$ But, $$\frac{1}{\cos x} \neq \frac{1}{(1-w^2)^{0.5}}$$ What's wrong with one of the methods?",['derivatives']
1731528,Differentiable almost everywhere of antiderivative function,"Give an integrable function $h$ on $[a,\,b]$. Let $f(x) = \int_{a}^{x} h$ for all $x\in [a,\,b]$. Prove that $f$ is differentiable almost everywhere on $(a,\,b)$\ My attempt: I tried to show that $f$ is differentiable on any subinterval $[c,d]\subset (a,b)$, but I could not see how to use the assumption $h$ is integrable despite spending several hours. Can anyone please help me with this problem?","['lebesgue-integral', 'measure-theory']"
1731553,Where are measurable functions not locally integrable?,"Let $f : \mathbb R^n \rightarrow \mathbb R$ be a measurable function. We know that $f$ is not necessarily locally integrable - but how hard can a measurable $f$ fail to be so? For example, is it true that $f$ is locally integrable outside of a negligible set $N \subset \mathbb R^n$ ? Edit:
In consideration of the comment by zhw., let me correct the phrasing of the question. I was originally wondering whether the 'singular' behaviour of a measurable function can be localized to a 'small' set. A motivational example is $f(x) = 1/x$ over the real line. It is locally integrable in the complement of the origin. Hence, a conceivable phenomenon, which I had in mind originally when asking the question, could be that a measurable $f$ is integrable over open sets that are compactly contained in the complement of some negligible sets.",['measure-theory']
1731565,"Find $f(x,y )$ such that $f_{x},f_{y},f_{yx}$ are continuous,but $f_{xy}$ is not","Let $f$ be a function
 of two variables,let$(a,b)$ be a point and let $D$ be an open disk with center $(a,b)$. Assume that $f$ is $\mathcal C^{1}$ on $D$, and $f_{yx}$ exist on $D$. Further, the  mixed second partial derivative $f_{yx}$ is continuous at $(a,b)$,is the other mixed second partial derivative  $f_{xy}$ continuous at $(a,b)?$ I think there must be some counterexample to deny it, I tried to find them.
Do you have some nice counterexamples?","['real-analysis', 'examples-counterexamples', 'partial-derivative', 'calculus', 'multivariable-calculus']"
1731658,Is there a relationship between local prime gaps and cyclical graphs?,"By defining the following algorithm I was able to generate some interesting graphs using the values of the gaps between consecutive primes : Start in any prime $p_i$, this will be the initial node, and calculate the distance to the next prime, then define $d_1 = d(p_i,p_{i+1})$ The next node will be the prime $p_{i+d_1}$. Then calculate the distance to the previous prime as $d_2 = -d(p_{i+d_1},p_{i+d_1-1})$ The next node will be the prime $p_{i+d_1+d_2}$ and do as in step 1 to define $d_3$ for the current node (forward step). Then next node will be the prime $p_{i+d_1+d_2+d_3}$ and do as in step 2 to define $d_4$ for the current node (backward step). Continue doing alternatively as in steps 3 and 4, defining the subsequent forward-backward jumps $d_5,d_6...$ etc. (There are three examples below). If $d_0=0$ is defined as the initial value of the sequence of $d_k$'s, then a generic calculation for $d_k$ for an initially given $p_i$ can be defined as: $d_k=(-1 + 2(k\ mod\ 2)) \cdot d(p_{(i+\sum_{t=0}^{t=k-1} d_{t})},p_{(i+\sum_{t=0}^{t=k-1} d_{t})-1+2(k\ mod\ 2)})$ And each node $n_k$ of the graph is defined for $k \gt 0$ as: $n_k = p_{(i+\sum_{t=0}^{t=k-1} d_{t})}$ In other words, the node $n_k$ is the $(i+\sum_{t=0}^{t=k} d_{t})^{th}$ prime, and the starting node is $n_1 = p_i$. My observation (the questions are related to this) is that the graph is always (1) itself a cycle (a clean Hamiltonian path ) or (2) it arrives to a sub graph that is a cycle, so from that point if subsequent $d_k$'s are generated, the nodes will never escape from the cycle. Please note that I consider a cycle only the case in which we arrive to an already existing node $n_k$ in a second or a third time, then the next $d_k$ is calculated, and the next node $n_{k+1}$ still is not included in the graph. The reason is that it is possible two calculations when arriving to a node, jumping $d_k$ primes forwards or backwards, depending on which step of the algorithm we did arrive to the node. For instance, that happens in the case of $p_i=11$. The algorithm arrives twice to $11$ but the second time the jump to the next node is backwards (a negative $d_k$) so the nodes $11 \gt 17 \gt 5 \gt 11$ are not considered to be in a cycle. In other hand, when the algorithm arrives to $2 \gt 3$ there is not possibility to escape from that continuous loop, so it is considered a real cycle and the algorithm ends. For instance this is an example of a clean Hamiltonian path (the graph is itself a cycle): $p_i=13$ $d_1=d(13,17)=4$ $p_{i+d_1}=29$ $d_2=-d(29,23)=-6$ $p_{i+d_1+d_2}=7$ $d_3=d(7,11)=4$ $p_{i+d_1+d_2+d_3}=19$ $d_4=-d(19,17)=-2$ $p_{i+d_1+d_2+d_3+d_4}=13$ So the complete graph is as follows (black arrows are odd, thus positive-valued, $d_k$'s, red arrows are even, thus negative-valued, $d_k$'s): When the graph is itself a clean cycle, a Hamiltonian path, then: $\exists k \in \Bbb N: \sum_{k=0}^{k=t} d_k = 0$. In the other hand this is an example of graph containing a cyclical sub graph (following the same algorithm to generate the graph): Tested with Python for $\forall \ p_i \in [0,47864431]$ (it gets quite slow after that point) in all cases it is possible to generate a finite graph like the ones above. There is not an example of a prime number capable of generating a graph with infinite nodes (continuously escaping to a greater prime while following the algorithm). In all cases the graphs have finite nodes and usually the elements of the graph are part of a ""local region"" around the initial prime $p_i$ (meaning that the graphs do not have nodes whose values are very distant, they are located in a close range around the original starting prime number $p_i$). The biggest graph in the tested range [0,47864431] was for $p_i=26730589$, including $60$ nodes: Similar tests can be done over other strictly increasing sequences with a ""pseudorandom"" behavior in the gaps between consecutive elements, like in the case of the abundant numbers and even deficient numbers. I asked another question looking for more similar sequences to make more tests here . Initially all of them are related with the prime divisors of the numbers, so they are also indirectly related to the primes themselves, and somehow the behavior of the gaps regarding the graphs explained above seems to be similar as well. My first thought is that this is possible because in all cases the gap $d_k$ for a given node is always smaller than or equal to the value of the counting function of the sequence up to that node. For instance the prime counting function $\pi(x)$ in the case of the prime numbers: $\forall k: d_k \le \pi(p_{(i+\sum_{t=1}^{t=k-1} d_{t})})$ And it seems so by checking the maximal prime gaps list and the index of the $p^{th}$ prime. I would like to ask the following questions: Is this behavior similar to the ""return to zero"" concept in random walks? Does it imply that there is a relationship between the local gaps? according to the heuristics it seems that the graphs can not 
  ""escape"" from the local region around the prime. Is there a counterexample of a $p_i$ prime whose gap with the next prime $g$ is strictly bigger than $i$, $g \gt i$? What implications could have a behavior like this, if any? Thank you!","['graph-theory', 'prime-gaps', 'hamiltonian-path', 'prime-numbers', 'discrete-mathematics']"
1731662,"Let $a,b,c,d$ are non-zero real numbers such that $6a+4b+3c+3d=0$,then the equation $ax^3+bx^2+cx+d=0$ has","Let $a,b,c,d$ are non-zero real numbers such that $6a+4b+3c+3d=0$ . Then the equation $ax^3+bx^2+cx+d=0$ has: (A) At least one root in $[-2,0]$ (B) At least one root in $[0,2]$ (C) At least two roots in $[-2,2]$ (D) No root in $[-2,2]$ Let $f(x)=ax^3+bx^2+cx+d$ $f(x)$ has at least one root in [-2,0] if $f(-2)f(0)<0$ : $$(-8a+4b-2c+d)d<0$$ $f(x)$ has at least one root in [0,2] if $f(2)f(0)<0$ : $$(8a+4b+2c+d)d<0$$ $f(x)$ has at least two roots in [-2,2] if $f(2)f(0)>0$ : $$(-8a+4b-2c+d)(8a+4b+2c+d)>0$$ Am I right uptil here? I am stuck from hereon.",['calculus']
1731714,Number of ways to write $n$ as sum of odd or even number of Fibonacci numbers,"In our discrete mathematics exercises I came of with the question: Prove that the coefficients of
  $\prod_{n\geq2}{(1-x^{F_n})}=1-x-x^2+x^4+x^7+\dots$ can only be $-1,1$
  or $0$, where $F_n$ denotes the n'th fibonacci number. If we want to find the coefficient of $x^n$, we should choose some distinct terms from the products so that $n$ is written as sum of some fibonacci numbers , and because each term is in the form of $(1-x^{F_n})$, if we choose an odd number of them we will have  $-1$ and if we choose an even number of them we will have  $+1$. So the question is the same as: Prove that the number of ways to write a natural number as sum of odd
  number of fibonacci numbers differs at most $1$ number from number of ways of writing it
  as sum of even number of fibonacci numbers (Note that the noted fibonacci numbers start from $F_2$) My approach using induction is as follows: Assume the proposition is true for all values of $n<k$, we shall prove it for $n=k$. First note that for every number $k$ there exists $m$ so that $F_m\leq k < F_{m+1}$. We take $A=k-F_m$. Obviously $A<k$ so by induction hypothesis the proposition is true for $A$.There are two different possibilities for $A$: 1) $A<F_{m-2}$ In this case we have $k=F_m+A=F_{m-1}+F_{m-2}+A$. Note that because $A<F_{m-2}$, we have a one to one correspondence between the odd ways and the even ways and so the difference will stay $+1,0,-1$ depending on $A$ 2) $A\geq F_{m-2}$ I'm actually stuck here and I cant find a similar proof for this case. I'd appreciate any help.","['combinatorics', 'fibonacci-numbers', 'discrete-mathematics', 'elementary-number-theory']"
1731748,Dihedral group $D_n$ is nilpotent iff $n=2^i$,"I want to show that the dihedral group $D_n$ is nilpotent if and only if $n=2^i$ for some $i$. I have shown the direction $\Leftarrow$. Could you give me some hints for the direction $\Rightarrow$ ? We suppose that $D_n$ is nilpotent and $n=2^im$, where $2\not\mid m$, or not? How can we find a contradiction?","['abstract-algebra', 'dihedral-groups', 'group-theory', 'nilpotence']"
1731772,"a function which is 1. easy to compute and 2. equal to 1 inside a interval, and quickly transitions to zero towards the boundaries","I need a function which has a plot more or less like this: Basically, I need something which ""smooths out"" the indicator function of an interval, and which transitions to 0 at a calibratable rate. The bump function times $e$ , as it is, doesn't work, because the transition from 1 to 0 at the boundaries is too gradual. EDIT: I found out that changing the numerator of the argument of the exponential, i.e., going from $$\exp\left(-\frac{1}{0.25-x^2}\right), \ x \in (-0.5, 0.5)$$ to $$\exp\left(-\frac{0.001}{0.25-x^2}\right), \ x \in (-0.5, 0.5)$$ works perfectly: so I could as well as close the question now :) However, I'm still curious how this is done usually in (applied?) mathematics. I don't need strictly compact support, i.e., my function needs only to asimptotically vanish, but it doesn't need to be exactly equal to zero anywhere on the real line. Thus the following function works: $$\frac{1}{(1+\exp(-100(x+0.5))(1+\exp(-100*(x-0.5))}$$ Is it usual to use this kind of function to ""smooth out"" the indicator function, or is it more common to use the bump function? I seem to remember that during university we were shown a lot of functions with a similar graph, so it must be something quite common, but I can't recall their expressions.","['real-analysis', 'functions']"
1731791,Are there results for relations between upward and downward closed partitions of some powerset?,"I stumbled upon this, given some set $X$ and its powerset $\mathcal{P}(X)$ and some incomparable set $\mathbb{S}\subseteq\mathcal{P}(X)$, i.e. for any $S,S'\in\mathbb{S}$ we have $S\setminus S'\neq\emptyset$. Then upward closure of $S$ is defined as $up(\mathbb{S})=\{S'\supseteq S\mid S\in\mathbb{S}\}$. Given an upward closed set its minimal elements define an incomparable set. Similarly for incomparable $\mathbb{T}\subseteq\mathcal{P}(X)$ we can define a downward closure $do(\mathbb{T})=\{T'\subseteq T\mid T\in\mathbb{T}\}$. And for any downward closed set its maximal elements define an incomparable set. Now the interesting part starts: Each upward closed set $up(\mathbb{S})$ uniquely defines a downward closed set $do(\mathbb{S})=\mathcal{P}(X)\setminus up(\mathbb{S})$ and vice versa. Thus also each incomparable set of minimal elements uniquely defines an incomparable set of maximal elements and vice versa. I was wondering if there is some research on this relations between such maximal and minimal sets. Cases where computation of one from the other allows for an efficient algorithm? Or knowledge on given cardinality of one do we know something about cardinality of the other? The whole question seems so obvious but still I can not come up with an idea of in which area of mathematics to successfully look for results. Just a few examples on how these maximal and minimal sets are related: $\mathbb{S}_1=\{\{x\}\mid x\in X\}$, $\mathbb{T}_1=\emptyset$, cardinalities $\lvert\mathbb{S}_1\rvert=\lvert X\rvert$ and $\lvert\mathbb{T}_1\rvert=0$. $\mathbb{S}_2=\{X\}$, $\mathbb{T}_2=\{\{X\setminus x\}\mid x\in X\}$, cardinalities $\lvert\mathbb{S}_2\rvert=1$ and $\lvert\mathbb{T}_2\rvert=\lvert X\rvert$. $\mathbb{S}_3=\{\{x,y\}\mid x,y\in X,x\neq y\}$, $\mathbb{T}_3=\{\{x\}\mid x\in X\}$, cardinalities $\lvert\mathbb{S}_3\rvert={\lvert X\rvert\choose{2}}$ and $\lvert\mathbb{T}_3\rvert=\lvert X\rvert$. $\mathbb{S}_4=\{\{a,b\},\{a,c\}\}$, $\mathbb{T}_4=\{\{a\},\{b,c\}\}$, cardinalities $\lvert\mathbb{S}_4\rvert=\lvert\mathbb{T}_4\rvert=2$. $\mathbb{S}_5=\{\{a,b\},\{c,d\},\{e,f\}\}$, $\mathbb{T}_5=\{\{a,c,e\},\{a,c,f\},\{a,d,e\},\{a,d,f\},\{b,c,e\},\{b,c,f\},\{b,d,e\},\{b,d,f\}\}$, cardinalities $\lvert\mathbb{S}_5\rvert=3$ and $\lvert\mathbb{T}_5\rvert=8$. generalization of (5): $\mathbb{S}_6=\{\{x_{1,i},x_{2,i}\}\mid 1\leq i\leq n\}$, $\mathbb{T}_6=\{\{x_{i,1},x_{j,2} ... x_{k,n}\}\mid i,j...k\in\{1,2\}\}$, cardinalities $\lvert\mathbb{S}_6\rvert=n$ and $\lvert\mathbb{T}_6\rvert=2^n$. $\mathbb{S}_7=\{\{a,c,e\},\{a,c,f\},\{a,d,e\},\{a,d,f\},\{b,c,e\},\{b,c,f\},\{b,d,e\},\{b,d,f\}\}$, $\mathbb{T}_7=\{\{a,b,c,d\},\{a,b,e,f\},\{c,d,e,f\}\}$, cardinalities $\lvert\mathbb{S}_7\rvert=8$ and $\lvert\mathbb{T}_7\rvert=3$. generalization of (7): $\mathbb{S}_8=\mathbb{T}_6$, $\mathbb{T}_8=\{\bigcup\mathbb{S}_8\setminus S\mid S\in\mathbb{S}_6\}$, cardinalities $\lvert\mathbb{S}_8\rvert=2^n$ and $\lvert\mathbb{T}_8\rvert=n$. complementary to (4): $\mathbb{S}_9=\mathbb{T}_4=\{\{a\},\{b,c\}\}$, $\mathbb{T}_9=\{\{b\},\{c\}\}=\{X_9\setminus\{a,c\},X_9\setminus\{a,b\}\}$, cardinalities $\lvert\mathbb{S}_9\rvert=\lvert\mathbb{T}_9\rvert=2$. not exactly complementary to (4): $\mathbb{S}_{10}=\{\{b,c\}\}$, $\mathbb{T}_{10}=\mathbb{S}_4=\{\{a,b\},\{a,c\}\}$, cardinalities $\lvert\mathbb{S}_{10}\rvert=1$ and $\lvert\mathbb{T}_{10}\rvert=2$. Particulary Examples (7) and (8) highlight a few things: In the general case there will not be polynomial time algorithms (where plain $\mathbb{S}$ or $\mathbb{T}$ serves as input and plain $\mathbb{T}$ or $\mathbb{S}$, resp. should be the output) for any direction. If the input is size $o(n)$ and the output is supposed to be $o(2^n)$ we need exponential time. Looks like some kind complement transformation relation between incomparable sets where $\mathbb{S}$ is swapped with $\mathbb{T}$. Not sure though what the exact relation is. For instance $\mathbb{T}=\mathbb{S}_4$ does not work as a complentary version of Example (4), opposed to Example (9), illustrated in Example (10). I believe the complement construction however works if we consider complement minus $\bigcap\mathbb{T}$. Anyhow for this assumption we would need to fix or talk about $X$, $\bigcup\mathbb{S}$ and $\bigcap\mathbb{T}$ first.","['order-theory', 'reference-request', 'lattice-orders', 'elementary-set-theory']"
1731798,Positive distribution $\Lambda$ as positive Radon measure,"Exercise 4 of Chapter 6 in Rudin's Functional Analysis states that every ""positive"" distribution $\Lambda\in D^{'}(\Omega)$, i.e, $\Lambda\psi\geq 0$ whenever $\psi\in D(\Omega)$, is a positive measure in $\Omega$, where $\Omega\subseteq\mathbb{R}^d$ open and $ D^{'}(\Omega)$ is the space of test functions on it. My question is that does problem directly follow from the Riesz Representation theorem that says every positive linear functional on the space of compactly supported smooth functions on a locally compact Hausdorff space is a positve Radon measure?","['functional-analysis', 'real-analysis', 'distribution-theory', 'measure-theory']"
1731808,Is it true that $F\cap \overset{\circ}{E}=\emptyset\implies F\cap \overset{\_}{E}=\emptyset$?,"Let $E,F\subset \mathbb{R}^n$ where $F$ is open and $E$ is arbitrary. Is it true that:
$$
F\cap \overset{\circ}{E}=\emptyset\implies F\cap \overset{\_}{E}=\emptyset
$$
Intuitively I think this is true, but my intuition on open and closed sets has proven to be not that good. How to prove it or how to construct a counter example? Edit: How about 
$$
F\cap E=\emptyset\implies F\cap \overset{\_}{E}=\emptyset
$$","['general-topology', 'real-analysis', 'multivariable-calculus']"
1731816,Rolle's Theorem for Complex Functions,We know the Rolle's theorem in valid for a real-valued function. Why can't we have Rolle's theorem in the for complex-valued functions?,"['complex-analysis', 'real-analysis']"
1731916,Three dimensional spherical excess formula,"We all know the spherical excess formula: in a unit sphere, the area of a geodesic triangle is equal to the exceeding from $\pi$ of the sum of the three angles of the triangle. Is there a similar formula for a geodesic tetrahedron in a 3-sphere? I'm sure there must be, but it seems to be tricky. Thanks in advance.","['riemannian-geometry', 'problem-solving', 'soft-question', 'geometry', 'differential-geometry']"
1731963,Finding fixed points of an equation when the derivative is not defined,"For a dynamical system governed by the equation $f(x) = \mathrm{d}y/\mathrm{d}x = 2(1-x^2)^{1/2}$. Find stable and unstable fixed points. The fixed points for the above equation are $+1$ and $-1$. I took the derivative of given equation and set it equal to zero.
If $f'(x)<0$, it's a stable point and if $f'(x)>0$, it's an unstable point.
The derivative is
$$\frac{-2x}{(1-x^2)^{1/2}}$$
Now if I plug $x=1$ or $x=-1$, it's not defined. How do I find the stability of fixed points in this case?","['classical-mechanics', 'ordinary-differential-equations']"
1731991,Why does the Elo rating system work?,"The Elo rating system is used to rank players in games such as chess. I can find plenty of explanations online of how to compute someone's Elo rating, how to actually crunch the numbers in practice, but I can't find a single clear conceptual explanation of what the rating is supposed to mean and why. The only information I can find is that apparently the Elo rating of two players allows you to calculate the odds that one player will win against the other. But every page I've been able to find that talks about this just drops the formula for how to calculate these odds on you and says ""there you go, that gives the probability of winning"", without explaining why . Wikipedia mentions something about the assumption that ""chess performance is normally distributed"", but doesn't go any further. What is the underlying probabilistic model for two-player games that the Elo system is based on? What are its basic assumptions, and what is the proof, from those assumptions, that the Elo system does indeed allow you to calculate win probabilities?","['applications', 'probability']"
1732011,Meaning of distance between two codes in coding theory,"Suppose I have been given two codes $x$ and $y$ such that $x = x_1 x_2 . . . .x_m$ and $y = y_1 y_2 . . . .y_m$ where ${x_i} 's$ and ${y_i} 's$ are binary digits. Then we define the concept of distance between $x$ and $y$ as $$\delta (x,y) = |\{  j : x_j \neq y_j \}|$$ i.e. we compare $x$ and $y$ term by term and count how many digits are different at corresponding positions in $x$ and $y$. That count gives the value of distance between $x$ and $y$ . I am unable to understand the concept of this distance. From above theory I can only understand the way in which distance between two codes is calculated but not what actually a distance between two codes mean ?","['coding-theory', 'discrete-mathematics']"
1732047,Prove that the intersection point of lines $AK$ and $CL$ lies on the line $BO$,"$AA', BB'$ and $CC'$ heights of an acute triangle $ABC$. The circle with center $B$ and radius $BB'$ intersects the line $A'C'$ in the points $K$ and $L$. Prove that the intersection point of lines $AK$ and $CL$ lies on the line $BO$, where $O -$ center of the circle circumscribed about the triangle $ABC$. My wotk so far: $H -$ orthocenter of triangle $ABC$ is the center of the inscribed circle of triangle $A'B'C'$","['euclidean-geometry', 'triangles', 'geometry']"
1732048,Is there a name for smoothed maximum value function?,"I have several arrays that look something like this: Spectrum Plot .  Think gaussian curves, but shorter and with lots of noise. I've been comparing values for the sake of peak detection .  Through experimentation, I've modified the comparison to be the average of x number of values around (and including) the maximum value. I'm really sorry I can't figure out the Math Jax thing, but here's a rough translation of my c# code: double[]     trace =      GetSpectrum();
double[]     baseline =   GetAverageOfAllTraces();
List<double> deviations = GetStandardDeviationOfEachTrace();

for (int i = 1; i < baseline.Length; i++)
    baseline[i] = (baseline[i] + baseline[i - 1]) / 2) + deviations.Average();

int index = trace.IndexOf(trace.Max());
int x = 2;
double maximum = trace.SubArray(index - x, index + x).Average();
if (maximum > baseline[index])
    bool validPeak = true; If someone wants to translate, I'd be very grateful. $$
average(maxIndex-2, maxIndex+2) > average(all) + stddev(all)
$$ I've started calling this a smoothed maximum , but is there a name for what I'm doing? Additionally, if there's some term for what I'm doing entirely and I'm just reinventing the wheel here, that would also be nice to know.","['terminology', 'statistics', 'optimization']"
1732049,Show that $x^2 + y^2 + z^2 = x^3 + y^3 + z^3$ has infinitely many integer solutions.,"Show that $x^2 + y^2 + z^2 = x^3 + y^3 + z^3$ has infinitely many integer solutions. I am not able to find an idea on how to proceed with the above questions. I have found only the obvious solution $(1,1,1)$. Could you please provide some hints and ideas on how to proceed with the above question? Also, can we find the solutions? Thanks.","['number-theory', 'sums-of-squares', 'diophantine-equations', 'elementary-number-theory']"
1732057,A family of open sets of measure $<1$ such that the union of any two has measure $\ge 1$,"Can someone give me a few hints about how to solve this problem? Let  $m$ be the Lebesgue measure on the real line and $P$ the collection of all the open sets $U$ of $\mathbb{R}$ such that $m(U)<1$. Let $Q \subseteq P$ such that for each couple $V_1, V_2 \in Q$, with $V_1 \neq V_2$, we have $m(V_1 \cup V_2) \geq 1$.  Show that $Q$ is at most countable.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1732077,Relationship between eigenvectors of correlation and covariance matrices,"For the purpose of computing principal components of a dataset, represented as matrix $X$ of dimensions $n \times p$ with $n$ samples and $p$ features, we can compute sample covariance matrix $S$, and compute its eigenvalue decomposition:
$$
    S = Q^t D Q
$$
The principal components are then given by $Z = X \cdot Q$. An alternative method is to use sample correlation matrix: $\hat{S} = \sigma^{-1} S \sigma^{-1} $, where $\sigma = \mathrm{diag}\left(\sigma_1, \cdots, \sigma_p\right)$ is the diagonal matrix of sample standard deviations:
$$
    \hat{S} = \hat{Q}^t \hat{D} \hat{Q}
$$
The resulting principal components $\hat{Z} = X \cdot \hat{Q}$ are different, but span the same vector space, hence there exists a matrix $T$, such that $Z = \hat{Z} \cdot T$. For reasons of numerical stability it is preferred to work with the correlation matrix. I was wondering if it is possible to use $\sigma$, $\hat{D}$ and $\hat{Q}$ to compute $Q$, and avoid doing the eigenvalue decomposition of $S$ recombined from $\sigma$, $\hat{D}$ and $\hat{Q}$ ?","['svd', 'data-analysis', 'linear-algebra']"
1732083,"Are polylogarithms the simplest functions that decay exponentially in one limit, and grow polynomially in another limit?","I have a function $f(x)$ which is defined as the solution to a certain differential equation. The boundary conditions are that in the $x\rightarrow \infty$ limit, it should be asymptotically equivalent to $\exp(-x)$, i.e. 
$$\lim_{x\rightarrow \infty} \frac{f(x)}{\exp(-x)}=c_{\infty}$$
where $c_{\infty}$ is some finite constant (not $\infty$, not 0). In the $x\rightarrow -\infty$ limit, it should be asymptotically equivalent to a polynomial, say $x^n$:
$$\lim_{x\rightarrow -\infty} \frac{f(x)}{x^n}=c_{-\infty}$$
where $c_{-\infty}$ is some finite constant (not $\infty$, not 0). I hoped to approximate this function with elementary functions, or at least with fairly well-known special functions. So, I thought, which functions behave exponential-like in one limit but polynomial-like in the other? The sigmoid function $\frac{1}{1+\exp(-x)}$ is an example, it approaches $\exp(x)$ in one limit and $1$ in the other limit. By repeated integration of the sigmoid function, we can find a function that behaves like $\exp(x)$ in one limit, and like $x^n$ in the other. This works fine, but, alas, repeatedly integrating $\frac{1}{1+\exp(-x)}$ gives rise to Polylogarithms , which are still somewhat more complicated than I would have hoped. So: are there functions that can be expressed in terms of elementary functions, that behave like $\exp(-x)$ for very large positive $x$ and like $x^n$ for very large negative $x$? Edit: Repeated integration of any sigmoid-like function (like tanh, arctan or the error function) would work, though I would be surprised if elementary sigmoid-like functions existed whose integrals are simpler than those of $\frac{1}{1+\exp(-x)}$. Multiplying a sigmoid with a polynomial does not work - doing that makes at least one of the limits diverge.","['special-functions', 'functions', 'limits']"
1732111,Questions about the Zappa–Szép product,"Which groups with composite order are not a Zappa–Szép product of smaller groups ? A solvable group with a composite order is always a Zappa–Szép product of smaller groups, but I am not sure about the non-solveable case. If the group has a normal-Hall-subgroup, it is a Zappa–Szép product of smaller groups. If not every group with composite order is a Zappa–Szép product of smaller groups, what is the smallest counter-example ?","['finite-groups', 'group-theory']"
1732114,Counting Methods with Combinatorics Problems (2),"I have a couple of problems with my attempts at them. I was wondering if I could get some verification/help if possible! A college sent a report saying that 119 students took Calc. I in a Fall Semester. The report says that during the next term, 96 of those students were in Calc. II, 53 of them took Discrete Mathematics, and 39 of them took Physics II. The report also says that 38 of the students took both Calc. II and Discrete Mathematics, 31 of the students took both Discrete Mathematics and Physics II, 32 of the students took both Calc. II and Physics II, and 22 of the students took all three courses. We examine the report and sense an error is present. Why? 119 students total from the Fall semester. 96-Calc II 53-Discrete Mathematics 39-Physics II 38-Calc II and Discrete 31-Discrete and Physics II 32-Calc II and Physics  II 22-Calc II, Discrete, and Physics II My guess is that if 22 students took all three courses, that would leave a remainder of 74 that are taking Calc II, 31 taking Discrete Math, and 17 taking Physics II which adds up to 122 students. 122>119. Is that the error? Or am I approaching this wrong? 2. We are going to count banana splits: These are ice cream treats that have 3 scoops of ice cream (two or three of the scoops could be the same flavor), three toppings (two or three could be the same flavor), whipped cream (always), a choice of nuts or no nuts, and a choice of a cherry or no cherry, all placed atop two banana halves. If there are 18 different flavors of ice cream and 5 choices of toppings, how many different banana split orders are possible? Note that people do care which toppings end up on which scoops, so the positions of the scoops should be labeled. So, we have to have 3 scoops of ice cream that have 18 different flavors and they can be repeated 3 toppings that have 5 different kinds and they can be repeated always whipped cream nuts or no nuts and a cherry or no cherry. I'm going to take a wild shot at this, and I'm probably overthinking it. Order matters and repetition is allowed for the toppings on the scoops. So, we have 18 flavors for our 3 scoops of ice cream. We would use $k^n= 18^3= 5,832$ different scoop & flavor combinations. Same approach with the toppings: $5^3=125$ different combinations. I attempted to go further with this, but yielded an incredibly high number...so, I'm stopping here. I think I'm doing something wrong. Any suggestions are appreciated very much!","['combinatorics', 'discrete-mathematics']"
1732124,Poisson Distribution from first arrival?,"Sorry if the question is too obvious or strange, I'm learning about Poisson distributions by myself. Say I have some independent process that follows a Poisson distribution of unknown rate (10 particles in 1D that have to get to a specific position where the process finishes) and that I know the mean time at which the first particle gets to that position (I run simulations and I can identify the first time a particle reaches that position, for example). How can I estimate the mean time at which the 10 particles have arrived to that position? Thanks a lot for any help! I thought it was just 10*time of the first one but that doesn't seem right, does it?","['poisson-process', 'poisson-distribution', 'probability', 'probability-distributions']"
1732178,Help Understanding Difference in P-Value & Critical Value Results,"I'd appreciate help in understanding how changing the significance level effects the results of the t-test. I have conducted an experiment where a group of 15 participants took a test, played a game, and took the original test again. The data set follows: Round 1 (Before Game) Scores: 6,  4, 7,  8, 12,  6,  7,  5, 11,  4,  7,  1,  6, 10,  4 Round 2 (After Game) Scores: 2,  3,  7, 11, 11,  9,  7, 12,  5, 15, 11, 11,  7,  4,  7 mean test score before game play: 6.53 mean test score after game play: 8.13 Accordingly I formulated a null hypothesis that game play does not effect test scores and an alternative hypothesis that game play increases scores (see below). Using the data and R I calculated the t-statistic, critical value, and p-value $H_0: \mu_0 = 6.53$ and $H_1: \mu_1 > 6.53$ $\alpha = 0.05, \mu_0 = 6.53, \overline x = 8.13, \sigma = 3.70, n = 15$ $$ t = \frac{8.13 - 6.53}{\frac{3.70}{\sqrt 15}} = 1.67 $$ Critical value = 1.76 and p-value = 0.94 T-value < Critical Value $ \to $ $1.67 < 1.76 \therefore$ accept $H_0$ $p-value > \alpha$ $\to 0.94 > 0.5 \therefore$ accept $H_0$ But when I re-calculate with a  $\alpha$ of 0.1 the critical value changes to 1.35, while the p-value stays the same at 0.94. At this point, accepting/rejecting diverges based on which value comparison is made. Did I make a mistake in the calculation or am I misunderstanding some other factor(s)? Thanks.","['statistics', 'hypothesis-testing']"
1732183,Question about the Jacobian of a function,"Let $f:U\rightarrow V$ , $U$ and $V$ open subsets of $\mathbb{R}^2$, be a smooth function. Let $Jf_p$ be the jacobian of $f$ in the point $p\in U$ and set $M_p:=\sup\{|df_pv|:\|v\|=1\}$ and $m_p:=\inf\{|df_pv|:\|v\|=1\}$. If fear I'm missing something quite basic, but I can't understand why is it true $Jf_p=M_pm_p$. Can you give some hints? Thank you!","['real-analysis', 'differential-geometry', 'analysis', 'analytic-geometry']"
1732204,$f\to L$ and $f''$ bounded implies $f'\to 0$,"Let $f$ be a $C^\infty(\mathbb R,\mathbb R)$ function. I'm reading a proof where the author bluntly states the following: Since $\lim_{x\to \infty}f(x)=L$ and $f''$ is bounded, $\lim_{x\to \infty}f'(x)=0$ Since no proof is given, I'm assuming this is something basic, but I haven't found a proof. Consider two reals $x$ and $x_0$. From $\displaystyle f(x)=f(x_0)+f'(x_0)(x-x_0)+\int_{x_0}^x (x-t)f''(t) dt$ I derive $$|f'(x_0)|\leq \left|\frac{f(x)-f(x_0)}{x-x_0}\right|+ \sup \left|f''\right|\frac{|x-x_0|}2$$ If I let $x\to \infty$, the RHS goes to $\infty$ and the proof is ruined... If I choose $x$ close to $x_0$, the inequality looks like $$\sup \left|f''\right|\frac{|x-x_0|}2\geq 0$$ Not good...","['derivatives', 'real-analysis']"
1732237,Prove that the union of two equivalence relations on the same set an equivalence relation iff?,"Let $R$ and $E$ be equivalence relations on set $A$. Prove that $R\cup E$ is an equivalence relation on set A  iff for all $a\in A$,  $[a]_{R} \subseteq [a]_{E}$ OR $[a]_{E} \subseteq [a]_{R}$. Someone can help me here ?
I don't have any idea. Thanks.","['equivalence-relations', 'elementary-set-theory']"
1732276,Is a matrix over a PID similar to its transpose?,"We say that two matrices $A,\,B\in M_n(R)$ are similar if there is some invertible matrix $P$ such that $P^{-1}AP=B$ . Now, if $R$ was a field (or certainly an algebraically closed field) then it is straightforward to show $A$ and $A^T$ are similar. Simply use the Jordan form. I am wondering if this result also holds true over more general rings, say a PID. As a starting position I was thinking of looking over $\mathbb{Z}$ and perhaps using the Smith Normal Form in some way.","['jordan-normal-form', 'matrices', 'abstract-algebra', 'transpose', 'principal-ideal-domains']"
1732364,Painting plane with 2 colors (2 points separated by 10 cm different colors ),"Can you paint a plane using 2 colours, so that any 2 points which are separated by 10 cm will have different colours?","['graph-theory', 'geometry']"
1732393,Asymptotic behavior of an integral involving the gamma function,"I'm trying to obtain an asymptotic large-$k$ approximation for the integral
$$I(k) := e^{-k^2}\int_0^1 \frac{(1 + \xi^2)\Gamma(0, \xi^2 k^2) - 2\Gamma(0, k^2)}{1 - \xi} d\xi$$
where $\Gamma$ is the incomplete gamma function $$\Gamma(0, x) = \int_x^\infty \frac{e^{-t}}{t}\,dt$$
(also expressible in terms of the exponential integral ). Specifically, I would like to show that as $k\to\infty$, $I(k)$ becomes negligible with respect to $e^{-k^2}\ln k^2$. My first thought was to use the series expansion
$$\Gamma(0, z) = e^{-z}\biggl(\frac{1}{z} - \frac{1}{z^2} + \cdots\biggr)$$
but the problem is that $\xi^2 k^2$ goes all the way down to zero, so it takes values where this series will converge arbitrarily slowly. It might be possible to show that the region of the integral where this effect is significant is small enough not to matter, but I can't think of a way to do that. I also thought to do a series expansion of the integrand around $\xi = 1$, or $\xi = 0$, and integrate that, or perhaps to split the integral in half and use a different series for each. But the series coefficients I obtained (using Mathematica) depend on positive powers of $k$, increasing with each order of $\xi$ (or $1 - \xi$), which does not bode well for convergence. Inspired by another question , I tried transforming the expression into a form that would allow me to apply Watson's lemma , but I couldn't find a transformation that would satisfy the conditions. So, can anyone offer a way to derive the asymptotic behavior? It seems like it shouldn't be that hard, but I'm too tired to keep thinking about this at the moment. For what it's worth, numerical evaluation suggests that
$$I(k) \sim \frac{C e^{-k^2}}{k}$$
where $C = 1.77245\ldots \overset{?}{=} \sqrt{\pi}$. But I would much prefer to have a symbolic demonstration of this, and not just rely on numerics.","['integration', 'asymptotics', 'gamma-function']"
1732397,Motivation behind Arithmetic Mean,"I know that the arithmetic mean $(x_1+x_2+...+x_n)/n$ is the value that minimizes $f(x)=\sum_{k=1}^n (x_k-x)^2$; however, I'm looking for an intuitive relationship between the mean and $g(x)=\sum_{k=1}^n \left\vert{x_k-x}\right\vert$. I'm aware that the mean doesn't necessarily minimize $g$; instead, one of the ${x_k}'s$ does (although maybe not uniquely), but I noticed that, using the triangle inequality, $$h(x)=n\left\vert{x-((x_1+x_2+...+x_n)/n)}\right\vert\le\sum_{k=1}^n\left\vert{x_k-x}\right\vert$$ and the value that minimizes $h$ is the arithmetic mean. That is, the point at which the minimum of this lower bound function of $g$ occurs is the mean. However, I'm unable to think of an intuitive explanation for this. Perhaps it's just a coincidence? Basically, I'm looking for any intuitive connections between the mean and the sum of absolute differences. Any ideas/comments would be greatly appreciated!","['intuition', 'means', 'statistics', 'motivation']"
1732536,Proving that holomorphic on $D \setminus \gamma$ and continuous on $D$ function is holomorphic on $D$,"Let's consider an arbitrary region $D \subset \mathbb{C}$ and let $\gamma \in D$ be a smooth curve. I would like to prove that if $f$ is holomorphic in $D \setminus \gamma$ and continuous in $D$, then $f$ is holomorphic on $D$. Probably, the idea of applying the Riemann's theorem on removable singularities might work (since we know that if $a \in D$, and $f$ is holomorphic on $D \setminus \{a\}$, then $f$ can be extended to a holomorphic function on $D$) but it still unclear how to make use of it (or maybe it's not as benefitial as it can be seen on the first glance). Are there any hints that might help?",['complex-analysis']
1732550,Plotting $y=x^{1/y}$,"So I was toying around with the idea of recursive functions, where there are two variables, and one of them is on both sides of the equation. 
I stumbled upon/came up with this function:
y = x^(1/y), or ""the y th root of x equals y"" Now I started wondering how this function would look like. There are the obvious coordinates like (4|2) or (1|1). Pretty much everything after x = 1 is also pretty clear because there is one definitive y coordinate. x=0 is obviously not defined. But what about negative x values and values and values between 0 and 1? What would the function look like there? I entered it into wolframalpha (because no other function plotter would accept my function) and it showed me this: https://i.sstatic.net/LZKqG.jpg What the hell does that mean? What is this strange blue part in the range of 0-1? And why is there no negative part?
Wouldn't there at least be an imaginary negative part? Could someone explain this to me and help me with plotting the function and showing me what it would really look like?","['recursion', 'functions', 'graphing-functions']"
1732559,Base-point free linear sheaf and extending the base field,"This is a question from Ravi Vakil's notes I've been stuck on, namely 18.2.I. Let $X$ be a scheme over a field $k$, and let $K/k$ be any field extension. Let $\mathcal{L}$ be an invertible sheaf on $X$. Then I would like to show $\mathcal{L}$ is base-point free if and only if the pullback of $\mathcal{L}$ to $X_K$, say $\mathcal{L}\otimes K$, is base-point free. I know that $H^0(X, \mathcal{L})\otimes K\cong H^0(X_K, \mathcal{L}\otimes K)$. In particular, a basis of $H^0(X,\mathcal{L})$ over $k$ yields a basis of $H^0(X_K, \mathcal{L}\otimes K)$ after tensoring with $K$. If $\mathcal{L}$ is base-point free, then so too must the pullback be base-point free. Otherwise there exists a base point $p$ in $X_K$, whose image in $X$ is $q$. As $q$ is not a base-point of $\mathcal{L}$, there exists some global section $s$ such that $s$ doesn't vanish at $q$, and thus the pullback of $s$ doesn't vanish at $p$. I'm not sure how to proceed showing the converse, namely that $\mathcal{L}\otimes K$ being base-point free implies $\mathcal{L}$ is. If I try to proceed by contradiction I run into the issue where a point of #X# may not have a point in $X_K$ lying over it (as $K/k$ is not necessarily algebraic). Could someone point me in the right direction?","['quasicoherent-sheaves', 'algebraic-geometry']"
1732583,"If $M$ is a connected manifold, does $M\setminus\{p\}$ have finitely many components?","Let $M$ be a connected manifold and $p\in M$ . Is it true that $M\setminus\{p\}$ has only finitely many connected components? (We can also suppose $M$ is compact if that helps.) I think this is true but I can't prove it yet. This is what I thought: $M$ looks the same as some $\mathbb{R}^n$ locally. Let $U\subseteq M,V\subseteq\mathbb{R}^n$ be homeomorphic open sets with $p\in U$ and $V$ some open ball. If $M\setminus\{p\}$ has infinitely many components, would that imply that $V\setminus\{x\}$ ( $x$ is the image of $p$ ) must also have infinitely many components? That would prove that $M\setminus \{p\}$ must have only finitely many components. What do you think? Thank you.","['general-topology', 'differential-topology']"
1732603,Confused by the SVD of a real symmetric matrix,"For a real symmetric matrix A , it's true that: $$A A^T = A^T A = A^2$$ And since the right and left singular vectors of $A$ are the eigenvectors of $A^T A$ and $A A^T$ respectively, the right and left singular vectors ought to be identical. Here's the particular situation that is causing my confusion. Let $$A = \begin{bmatrix} 4 & 1 & -2 & 2 \\ 1 & 2 & 0 & 1 \\ -2 & 0 & 3 & -2 \\ 2 & 1 & -2 & -1\end{bmatrix}$$ Now when I try to take the SVD of this matrix, the matrices $U$ and $V$, of the left and right singular vectors respectively, are identical. Just as I thought they would be. In particular, for $U$, $\Sigma$, and $V$ I get: $$U = V = \begin{bmatrix} -0.718 & 0.202 & 0.177 & -0.642 \\ -0.221 & 0.789 & 0.178 & 0.544 \\ 0.557 & 0.580 & -0.288 & -0.520 \\ -0.353 & 0.010 & -0.924 & 0.144 \end{bmatrix}$$ and $$\Sigma = \begin{bmatrix} 6.845 & 0 & 0 & 0 \\ 0 & 2.269 & 0 & 0 \\ 0 & 0 & 2.198 & 0 \\ 0 & 0 & 0 & 1.084 \end{bmatrix}$$ But if I use this to calculate $U \Sigma V^T$ I don't get $A$. This already confuses me, but to make matters worse, if I take $V$ to be $U$ except with the signs changed on the third column, then it comes out correctly! I feel like I must be misunderstanding something about the SVD or Eigenvectors in general, as I thought that as long as each eigenvector had norm 1, it didn't matter what the sign of it was (i.e. I think about it as more of an eigendirection). Can anyone point out why I'm getting these results?","['eigenvalues-eigenvectors', 'matrices', 'svd', 'symmetric-matrices', 'linear-algebra']"
1732611,Proving Chi-squared Distribution [duplicate],"This question already has answers here : Proof of $\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}$ (5 answers) Closed 3 years ago . I have some problems solving the following problem: Let $X = (X_1, X_2,\ldots, X_n)$, be random sample , where $X_{i} \sim N(\mu, \sigma^{2})$. Show that: $$U:= \frac{n-1}{\sigma^2} S^2 \sim \chi^2 (n-1); \text{ where } S^2:= \frac{1}{n-1}\sum_{i=1}^n (X_i - \overline{X})^2.$$ Do I need to prove first that the statistic, the sample mean, is sufficient? Or show the independence through Basu's Theorem? Thanks for any help!","['statistics', 'probability-distributions']"
1732658,"Number of functions from n-element set to {1, 2, …, m}","I've gotten stuck at the following exercise; There are m functions from a one-element set to the set {1, 2, …, m }.
  How many functions are there from a two-element set to {1, 2, …, m }?
  From a three-element set? Give a recurrence for the number of T(n) of
  functions from an n -element set to {1, 2, …, m }. Solve the recurrence. I'm not sure how to begin solving it?","['combinatorics', 'functions', 'discrete-mathematics']"
