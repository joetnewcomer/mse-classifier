question_id,title,body,tags
62166,Finding asymptotes to $y = \frac{2x^2 + 3x - 6}{2x + 1}$,"I need to find the asymptotes of 
$y = \frac{2x^2 + 3x - 6}{2x + 1}$.
The asymptote at $x = -1/2$ is clear. If one long divides they can easily see that there is an asymptote of $y = x + 1$ as $x$ goes to infinity. However, what is wrong with this reasoning? I claim that as $x$ goes to infinity, the $2x^2$ term will dominate, so the graph will be on the order of $y = 2x^2$, which has no asymptote. So $y = x + 1$ is not an asymptote.",['calculus']
62167,"A combinatorial proof for the identity $\sum_i \sum_j \min(i,j) = \sum_k k^2$","I have to prove this (a combinatorally proof, counting a set in two different ways): $$\sum_{i=1}^n\sum_{j=1}^n\mathrm{min}(i,j)=\sum_{k=1}^nk^2 .$$ This is what I have done: take the set $$\{(x_1,x_2,x_3)\in\mathbb{Z}^3:1\leq x_1, x_2 \leq k, x_3=k, k=1,\ldots,n\}.$$ This set consists of $n$ squares with increasing side. I noticed that if you count the set adding the points diagonally square by square, you get the formula with the minimum. I mean if $n=3$, then the diagonals with $1$ point are $5$, the diagonals with $2$ points are $3$ and the diagonal with $3$ points is $1$, so you have $$1+1+1+1+1+2+2+2+3.$$ But I can't formalize that, could you help me please?","['summation', 'combinatorial-proofs', 'combinatorics']"
62171,Proving $1^3+ 2^3 + \cdots + n^3 = \left(\frac{n(n+1)}{2}\right)^2$ using induction,How can I prove that $$1^3+ 2^3 + \cdots + n^3 = \left(\frac{n(n+1)}{2}\right)^2$$ for all $n \in \mathbb{N}$? I am looking for a proof using mathematical induction. Thanks,"['faq', 'induction', 'summation', 'algebra-precalculus']"
62172,The number of subsets of a set of cardinality $n$,"Please help with this question. Show that for a finite set $A$ of cardinality $n$ , the cardinality of $P(A)$ is $2^n$ , where $P(A)$ is the power set of $A$ . Thank you in advance for any help that is given.","['elementary-set-theory', 'combinatorics']"
62177,Existence of a well-ordered set with a special element,"One of the most mind boggling results in my opinion is, with the axiom of choice/well-ordering principle, there exist such things as uncountable well-ordered sets $(A,\leq)$. With this is mind, does there exist some well ordered set $(B,\leq)$ with some special element $b$ such that the set of all elements smaller than $b$ is uncountable, but for any element besides $b$, the set of all elements smaller is countable (by countable I include finite too). More formally stated, how can one show the existence of a well ordered set $(B,\leq)$ such that there exists a $b\in B$ such that $\{a\in X\mid a\lt b\}$ is uncountable, but $\{a\in X\mid a\lt c\}$ is countable for all $c\neq b$? It seems like this $b$ would have to ""be at the very end of the order.""","['elementary-set-theory', 'order-theory']"
62178,Showing $2(n+5)^2 < n^3$,"I stumbled upon this in my homework and can't seem to get it, any help would be great. Find the smallest $n$ within $\mathbb N$ such that $2(n+5)^2 < n^3$
  and call it $n_0$. Show that $2(n+5)^2 < n^3$ for all $n \geq n_0$.","['inequality', 'algebra-precalculus']"
62182,How do I rotate a matrix transformation with a centered origin?,"This is actually something I'm doing in Objective-C programming, but since it's very math-oriented I thought I'd post it here. I was reading up on linear transformations: http://en.wikipedia.org/wiki/Matrix_(mathematics) Basically I need to rotate a shape around its center. With my current implementation, the rotation is done using the top left as its origin. Here's a screenshot: Here's the code I'm using to create each x,y coordinate: CGFloat angle = 0.261799; // (15 degrees)
CGFloat xr = x1 * cosf(angle) + y1 * -sinf(angle) + tx;
CGFloat yr = x1 * sinf(angle) + y1 * cosf(angle) + ty; I realize there are functions (CGAffineTransformRotate, etc) in Objective-C that do this for me, but since I'm not using a UIView, I need to do it manually. Plus, it would be nice to know. :) So when I plug in 35.0 for tx and -35.0 for ty, (numbers I just found that seemed to work, through trial and error) here is what I get: That's what I want! Now I just need some way to figure out these tx and ty translation values to center the shape's origin, based on the given angle, width or height values. (I'm also seeing different results when setting tx and ty if the original x,y coordinates of the shape are different.) Any help would be much appreciated. Thanks!","['geometry', 'linear-algebra', 'transformation', 'rotations']"
62187,Limits of Expectations,"I've been fighting with this homework problem for a while now, and I can't quite see the light.  The problem is as follows, Assume random variable $X \ge 0$, but do NOT assume that $\mathbb{E}\left[\frac1{X}\right] < \infty$.  Show that $$\lim_{y \to 0^+}\left(y \, \mathbb{E}\left[\frac{1}{X} ; X > y\right]\right) = 0$$ After some thinking, I've found that I can bound $$
\mathbb{E}[1/X;X>y] =  
\int_y^{\infty}\frac1{x}\mathrm dP(x) \le 
\int_y^{\infty}\frac1{y}\mathrm dP(x)
$$ since $\frac1{y} = \sup\limits_{x \in (y, \infty)} \frac1{x}$ resulting in $$
\lim_{y \to 0^+} y \mathbb{E}[1/X; X>y] \le 
\lim_{y \to 0^+} y \int_y^{\infty}\frac1{y}\mathrm dP(x) = P[X>0]\le1
$$ Of course, $1 \not= 0$.  I'm not really sure how to proceed... EDIT: $\mathbb{E}[1/X;X>y]$ is defined to be $\int_y^{\infty} \frac{1}{x}\mathrm dP(x)$.  This is the notation used in Durret's Probability: Theory and Examples .  It is NOT a conditional expectation, but rather a specifier of what set is being integrated over. EDIT: Changed $\lim_{y \rightarrow 0^-}$ to $\lim_{y \rightarrow 0^+}$; this was a typo.","['probability-theory', 'limits']"
62201,Proof of max product of partitions of n,"For $n \in \mathbb{Z} : n \geq 1$ $
f(n) = \displaystyle\max_{\substack{	x_1+\dotsm+x_k = n\\ x_i\in\mathbb{Z}^{+} }}
          x_1 x_2 \dotsm x_k
$ $$
f(n) = \begin{cases}
    1 & \text{if $n = 1$}, \\
    3^{\left\lfloor\frac{n}{3}\right\rfloor}& \text{if $n \mod 3 = 0$},\\
    3^{\left\lfloor\frac{n}{3}\right\rfloor-1} \cdot 2^2& \text{if $n \mod 3 = 1$},\\
    3^{\left\lfloor\frac{n}{3}\right\rfloor} \cdot 2& \text{if $n \mod 3 = 2$},
\end{cases} $$ Proof : First observe that for any $x_i = 1$ in our product we do not increase the value of the final product. Therefore we want $x_i > 1$. However, for any set of three $x_i = 2$ we want to refactor this set into two $x_i = 3$ since $3\cdot3 > 2\cdot2\cdot2$. Now, for any $x_i > 4$ observe that $2(x_i-2) = 2x_i - 4 > x_i$. Thus to maximize our product we have at most two 2's and as many 3's as possible. What is my proof possibly missing? Here's an updated proof. Proof : First observe that for any $x_i = 1$ in our product we do not increase
the value of the final product. Therefore we want $x_i > 1$. However,
for any set of three $x_i = 2$ we want to refactor this set into two
$x_i = 3$ since $3*3 > 2*2*2$. Now, for any $x_i > 4$ observe that
subtracting 2 from our term increases our total product. That is
$2(x_i-2) = 2x_i - 4 > x_i$ for $x_i > 4$. We can repeat this process
until $x_i \leq 4$ and this limits our individual factors to being no
greater than 4. For any $x_i = 4$ where there are no existing factors
equal to 2 we do not necessarily need to factor this into $2 \cdot 2$
since this product is equal to $4$ and will not increase our total
product. Thus to maximize our product we have at most two 2's, or a single 4, and
as many 3's as possible. This leads to our piecewise defined function.
For any n divisible by 3 we will have a product comprised of 3 raised to
the power $\frac{n}{3}$. If we have a remainder of 1 when dividing n by
3 we want one less factor of 3 than $\frac{n}{3}$ provides so that we
can create a factor of $2^2$ or $4$. Finally, if n divided by 3 has a
remainder of 2 we will just include the remainder as a factor in our
final product.","['proof-writing', 'number-theory']"
62209,Example of a submodule of $\mathbb{Z} \oplus \mathbb{Z}$ that is not a direct summand,"We will call a submodule $A$ a direct summand of $K$ if there exists a submodule $B$ such that $A \oplus B = K$.  I think this is a question that can be formulated in terms of rank of a proper free sumbmodules but I am not sure how to ask it. Consider the $\mathbb{Z}$-module $\mathbb{Z} \oplus \mathbb{Z}$.  Is there an example of two submodules of $A,B$ of $\mathbb{Z} \oplus \mathbb{Z}$ such that $A$ and $B$ are direct summands of $\mathbb{Z} \oplus \mathbb{Z}$ but $A+B$ is not a direct summand of $\mathbb{Z} \oplus \mathbb{Z}$? I first thought that $\mathbb{Z}\oplus 0$ and $ 0 \oplus \mathbb{Z}$ was an example until I realized every module is a direct summand of itself...","['modules', 'linear-algebra', 'abstract-algebra']"
62212,Good book for self study of a First Course in Real Analysis,"Does anyone have a recommendation for a book to use for the self study of real analysis? Several years ago when I completed about half a semester of Real Analysis I, the instructor used ""Introduction to Analysis"" by Gaughan. While it's a good book, I'm not sure it's suited for self study by itself.  I know it's a rigorous subject, but I'd like to try and find something that ""dumbs down"" the material a bit, then between the two books I might be able to make some headway.","['book-recommendation', 'reference-request', 'soft-question', 'real-analysis', 'learning']"
62213,Prove $\| A(A^TA)^{-1}A^T\|_2 = 1$ when rank of matrix $A$ is $n$,Given a matrix $A \in R^{m \times n}$ and whose rank is $n$. I need to show $\| A(A^TA)^{-1}A^T\|_2 = 1$. Can any hint me the direction in which I should solve this problem. Should I use any decomposition of matrix $A$ to show the result?,['linear-algebra']
62238,How to find the Period and Phase angle?,"I'm currently brushing up my trig and found these two problems. I'm totally clueless on how to start. Please help. Find the period , amplitude , and phase angle, and use these to sketch a) $$3\sin(2x − π)$$ b) $$−4\cos(x + π/2)$$","['trigonometry', 'algebra-precalculus']"
62249,Blockwise Moore-Penrose pseudoinverse?,"There exists a convenient formula for computing the inverse of a block matrix consisting of 4 matrices $\mathbf{A, B, C, D}$ $ \begin{bmatrix}\mathbf{A} & \mathbf{B} \\ \mathbf{C} & \mathbf{D}\end{bmatrix} ^{-1}$ the inverse can be written as a function of $A^{-1}$ and $(A-B D^{-1}C)^{-1}$ ( wikipedia ) $\begin{bmatrix} \mathbf{A}^{-1}+\mathbf{A}^{-1}\mathbf{B}(\mathbf{D}-\mathbf{CA}^{-1}\mathbf{B})^{-1}\mathbf{CA}^{-1} & -\mathbf{A}^{-1}\mathbf{B}(\mathbf{D}-\mathbf{CA}^{-1}\mathbf{B})^{-1} \\ -(\mathbf{D}-\mathbf{CA}^{-1}\mathbf{B})^{-1}\mathbf{CA}^{-1} & (\mathbf{D}-\mathbf{CA}^{-1}\mathbf{B})^{-1} \end{bmatrix}$ I wonder if a similar formula exists for the pseudo-inverse of non-invertible block matrices.","['matrices', 'pseudoinverse', 'linear-algebra', 'inverse']"
62253,Calculating Limit $ \lim\limits_{x\to 0} \frac{\mathrm d^2}{\mathrm dx^2} \frac{f(x)}{x} $,"Today I had an exam and the following problem came up.
I have absolutely no idea how to approach this.
Any help in solving this is appreciated! $$ \lim_{x\to 0} \frac{\mathrm d^2}{\mathrm dx^2} \frac{f(x)}{x},\qquad f(0) = 0$$","['calculus', 'limits']"
62254,Best way to integrate $ \int_0^\infty \frac{e^{-at} - e^{-bt}}{t} \text{d}t $,"Today I had an exam and I mixed up the integration by parts formula. 
The question was to integrate
$$ \int\nolimits_0^\infty \frac{e^{-at} - e^{-bt}}{t} \text{d}t $$ I will try solve this again with the right formula when I arrive home. I would appreciate if somebody could tell me the solution so I can double check and maybe give a hint to another way of solving this instead of integration by parts (if possible).","['calculus', 'integration']"
62272,Does convergence on finite intervals imply uniform convergence?,"Let $f_n(x) \rightarrow 0$, $n\rightarrow \infty$ for all $x \in \mathbb{R}$. Does this imply $f_n(x) \rightarrow 0$ uniformly on finite intervals? I could think it could be proofen like this maybe: Let the interval $I$ be compact without loss of generalization Choose a finite subcover for $I$ take $N := \sup N_j$ for the $\epsilon$-$\delta$-proof But I am not sure if it is okay this way, or if it can be done more easy. Is it maybe a known lemma?",['real-analysis']
62279,Weird derivative of $\tan^{-1} x$,"I've seen this in Stewart calculus book: $$\frac{\mathrm d \tan^{-1} x}{\mathrm dx} = \frac1{1+x^2}$$ But how do I get it? If I do it myself, $$\frac{\mathrm d \tan^{-1} x}{\mathrm dx} = \frac{\mathrm d \frac{\cos x}{\sin x}}{\mathrm dx} = \frac{-1}{\sin^2 x}$$ How can he get rid of the trigonometric functions ($\sin$, $\cos$)? Thanks!","['trigonometry', 'calculus']"
62310,Is there any way to integrate $\frac1{f(x)}$ in terms of the integral of $f(x)$?,"Is there any way to find $$\int \frac1{f(x)}\mathrm dx$$ in terms of $\int f(x) \mathrm dx$, $f(x)$ and its derivatives?","['calculus', 'integration', 'functions']"
62316,Simple Counting Question,"How many solutions to the equation $x_1 + x_2 + x_3 = 11$ for positive integers, are there?? Please explain your answer as much as possible.","['discrete-mathematics', 'combinatorics']"
62318,Origin of the dot and cross product?,"Most questions usually just relate to what these can be used for, that's fairly obvious to me since I've been programming 3D games/simulations for a while, but I've never really understood the inner workings of them... I could get the cross product equation as a determinant of a carefully-constructed matrix, but what I want to ask is... How did the dot and cross product come to be? When were they ""invented""? Some detailed proofs? Did someone say: ""Hey, wouldn't it be nice if we could construct a way to calculate a vector that is perpendicular to two given operands?"" Basically, how/why do they work? I would appreciate explanations, links to other explanations, other web resources... I've been searching the Internet lately for explanations, but most of them are on how to use it and nothing that really gives substance to it.","['cross-product', 'linear-algebra', 'math-history']"
62331,Three finite groups with the same numbers of elements of each order,"There exist pairs of finite groups $G$ and $H$ such that $G$ and $H$ are not isomorphic, yet they have the same number of elements of each order.  For example, if $p$ is an odd prime, then the group $$H_{p} = \left\{\begin{pmatrix} 1 & a & b \\ 0 & 1 & c \\ 0 & 0 & 1\end{pmatrix} : a,b,c\in\mathbb{Z}_{p}\right\}$$
 and the group $\mathbb{Z}_{p}^{3}$ both have exponent equal to $p$ and order $p^{3}$.  Also, for any such pair $G$ and $H$, at least one of $G$ and $H$ must be non-commutative.  My question is this: Do there exist three groups $A$, $B$ and $C$, of the same finite order, such that no two of them are isomorphic and such that all three of $A$, $B$ and $C$ have the same number of elements of each order? Ideally, I'd like a nice, concrete description of any examples that might exist (preferably, the smallest such), or a reference to a proof that there is no such example.","['reference-request', 'finite-groups', 'group-theory']"
62338,Diagonalizable transformation restricted to an invariant subspace is diagonalizable,"Suppose $V$ is a vector space over $\mathbb{C}$ , and $A$ is a linear transformation on $V$ which is diagonalizable. I.e. there is a basis of $V$ consisting of eigenvectors of $A$ . If $W\subseteq V$ is an invariant subspace of $A$ (so $A(W)\subseteq W$ ), show that $A|_W$ is also diagonalizable. I tried supposing $A$ has distinct eigenvalues $\lambda_1,\ldots,\lambda_m$ , with $V_i=\{v\in V: Av=\lambda_i v\}$ . Then we can write $V=V_1\oplus\cdots\oplus V_m,$ but I'm not sure whether it is true that $$W=(W\cap V_1)\oplus\cdots\oplus (W\cap V_m),.$$ If it is true, then we're done, but it may be wrong.","['linear-algebra', 'eigenvalues-eigenvectors', 'diagonalization']"
62346,"Given the area and height of a rectangle, what is the width of the base of a circular segment with the same height and area?","Given a rectangle of height $h$ and area $A$, what is the width $c$ of the chord at the base of a circular segment with the same height and area? I've made a diagram of the problem: My progress so far has come from manipulating equations from here .  The best equation I have is $(\frac{1}{2}) (\frac{c^2}{8 h}+\frac{h}{2})^2 \left(2 \arccos\left[\frac{\frac{c^2}{8 h}-\frac{h}{2}}{\frac{c^2}{8 h}+\frac{h}{2}}\right]-\sin\left[2 \arccos\left[\frac{\frac{c^2}{8 h}-\frac{h}{2}}{\frac{c^2}{8 h}+\frac{h}{2}}\right]\right]\right)=h w$, which according to Mathematica is not solvable for $c$.","['geometry', 'euclidean-geometry']"
62348,Assessing discreteness of the random variable by its characteristic function,"It is easy to spot a discrete integer valued random variable by looking at its characteristic function, as that is periodic with period $2 \pi$, i.e. for binomial distribution it is $\phi(t) = (1-p+p \, \mathrm{e}^{i t})^n$. I recently came across Khintchine's result that $\phi(t) = \frac{\zeta(s + i t)}{\zeta(s)}$ is a characteristic function of a random variable for $s > 1$. After some fudging, I determined that it corresponds to $x_k = -\log(k)$, where $k$ follows Zipf distribution with parameter $s-1$. Indeed: $$
   \mathbb{E}( \mathrm{e}^{ -i t \log(k)} ) = \mathbb{E}( k^{-i t} )  = \sum_{k \ge 1} k^{-i t} \frac{k^{-s}}{\zeta(s)} = \frac{\zeta(s+i t)}{\zeta(s)}
$$ This characteristic function, thus, also corresponds to a discrete random variable. This brings up a question : Can one easily spot a discrete random variable from it's characteristic function ? Or is inverting the characteristic function the only way ?
How does one go about doing the inversion ? Ordinary inverse Fourier transform would produce distributions, right ? Thank you.","['probability-distributions', 'probability']"
62349,Some trigonometric formula,"How to prove that $1+2(\cos a)(\cos b)(\cos c)-\cos^2 a-\cos^2 b-\cos^2 c=4 (\sin p)(\sin q) (\sin r)(\sin s)$, where $p=\frac{1}{2}(-a+b+c)$, $q=\frac{1}{2}(a-b+c)$, $r=\frac{1}{2}(a+b-c)$, $s=\frac{1}{2}(a+b+c)$. Thanks.",['trigonometry']
62351,Linear isomorphisms with dense graph,"Is it true that for each infinite dimensional Banach space $X$ there exists a linear bijection $f: X \rightarrow X$ with a dense graph? A graph of $f$ it is the set $\Gamma(f):=\{(x, f(x)): x \in X \} \subset X \times X$. ($X\times X$ is a Banach space with natural addition and multiplication by scalars and norm defined by $\|(x,y)\|=\|x\|+\|y\|$ for $x,y \in X$.) It seems that it is true when $X$ is separable. Thanks.","['functional-analysis', 'banach-spaces']"
62358,Integral around unit sphere of inner product,"For arbitrary $n\times n$ matrices M, I am trying to solve the integral $$\int_{\|v\| = 1} v^T M v.$$ Solving this integral in a few low dimensions (by passing to spherical coordinates) suggests the answer in general to be 
$$\frac{A\,\mathrm{tr}(M)}{n}$$
where $A$ is the surface area of the $(n-1)$-dimensional sphere. Is there a nice, coordinate-free approach to proving this formula?",['linear-algebra']
62372,Can $\pi$ be a root of a polynomial under special cases?,"What if we consider polynomials whose coefficients are either rational or $e$, that is, a polynomial in $\mathbb{Q} \cup \{e\}$ with $\pi$ as a root. Can this happen? Does it matter if we change rational to integer in the definition?","['pi', 'transcendental-numbers', 'abstract-algebra', 'polynomials']"
62378,Real symmetric matrix similar to diagonal matrix,"Let $A$ be a $2\times 2$ matrix with real entries, which is symmetric. Prove that $A$ is similar over $\Bbb{R}$ to a diagonal matrix.","['matrices', 'linear-algebra']"
62383,What is the asymptotic behavior of a linear recurrence relation (equiv: rational g.f.)?,"The question sounds simple: find the roots of the characteristic equation, take the one with the largest absolute value, and find its coefficient.  Repeated roots do not substantially complicate matters. But what about two roots with equal absolute value?  Is there any way to determine the asymptotic behavior of such a sequence? For example,
$$a_n = 4a_{n-2} - 6a_{n-4} + 4a_{n-6} - a_{n-8}$$ has characteristic equation $x^8-4x^6+6x^4-4x^2+1=(x-1)^4(x+1)^4$ and so it has two roots of equal magnitude and multiplicity.  In this case the asymptotic behavior should be $|a(n)|=O(n^3)$, and finding the corresponding polynomials from the initial values should allow a lower bound as well as coefficients.  In this case the sequence is a quasipolynomial, so there's no interference between the values.  But can there be?  Are there sequences with nontrivial† characteristic polynomial, e.g., $(x-2)^4(x+2)^4(x-1)^3$ that, because of cancellation, yields a sequence that is actually $O(n^2)$? † That is, leading coefficient not zero -- the characteristic equation is of the lowest degree for the particular starting values, or equivalently the g.f. is written with gcd(numerator, denominator) = 1.  (No writing $a_n=4a_{n-2}$ if $a_n=2a_{n-1}$, for example.)","['generating-functions', 'recurrence-relations', 'combinatorics']"
62389,Relationships between bounded and convergent series,"I would like to know the relationships between bounded and convergent series. By bounded series I mean a series whose sequence of partial sums is bounded. For example, it seems natural that if a series is convergent, it is also bounded, but does the converse hold? Thanks in advance,","['sequences-and-series', 'calculus']"
62392,"Is the space of uniformly left continuous functions on [0,1] complete?","We'll say that a function on $[0,1]$ is uniformly left continuous if for every $\epsilon > 0$ there exists $\delta > 0$ such that $x \in (y - \delta, y)$ implies $|f(x) - f(y)| < \epsilon$ for every $x, y \in [0,1]$.  I want to know if the space of all such functions is complete with respect to the uniform norm. I'm interested in this space because I suspect that it is the completion of the space of piecewise constant functions which are continuous from the left. Thanks in advance for the help! EDIT:
As was pointed out in the comments, what I wrote above is equivalent to uniform continuity.  I think the following revised definition captures what I want.  $f$ is uniformly left continuous if for every $\epsilon$ there is a partition $0 = t_0 < t_1 < \ldots < t_n = 1$ such that $|f(x) - f(y)| < \epsilon$ whenever $t_0 \leq x \leq y \leq t_1$ or $t_i < x \leq y \leq t_{i+1}$ for $i > 0$.  So with this definition the characteristic function of $(1/2,1]$ is uniformly left continuous while the characteristic function of $[1/2,1]$ is not. Here are the examples that I'm really trying to kill.  Take $f$ to be the function which is 0 on the interval $[0,1/2]$ and let $f(x) = 1/(x-1/2)$ on $(1/2,1]$.  This is left continuous, but it shouldn't be uniformly left continuous.  Even if you insist that $f$ be bounded, you could set $f(x) = \sin(1/(x-1/2))$ for $x$ in $(1/2,1]$ and get a left continuous function which is not uniformly left continuous.  If you can think of a better definition that captures this intuition, let me know.","['calculus', 'banach-spaces', 'real-analysis', 'analysis']"
62398,Generalization of Bertrand's Postulate,"Bertrand's postulate states that there is a prime $p$ between $n$ and $2n-2$ for $n>3$. According to Dirichlet's theorem we have that a sequaence
$$a\cdot n+b$$
has infinite primes iff $a$ and $b$ are relatively prime. So in some sense, Bertrand's postulate gives a maximum of time for encountering a prime in the sequence
$$2\cdot n+1$$
So, the question is: there is a generalization of Bertrand's Postulate for sequences $a\cdot n+b$ that accomplish the Dirichlet's theorem? EDIT: (For a more concise explanation of the particular generalization.) We know that given 
$$a_n=2\cdot n+1$$
we have that for all $m$ there is a prime in the sequence greater than $a_m$ and less than $a_{2m}$. So, the thing is that if there is some generalization of Bertrand's Postulate using the sequence form, for an arbitrary sequence
$$c_n=a\cdot n+b$$
with $a$ and $b$ coprime. Something as, for every relatively prime $a$ and $b$, there is a $k\leq a\cdot b$, such that for all $m$ there is a prime in the sequence between $c_m$ and $c_{k\cdot m}$. Such kind of thing is what I am looking for.",['number-theory']
62411,"A function is not continuous, but the image of convergent sequences converge","Building off a previous question, I'm trying to prove some properties about a certain function, but I may be flubbing the whole thing. Suppose I have a well-ordered set $(B,\leq)$ where there is a unique $b\in B$ such that $\{a\in B\mid a\lt b\}$ is uncountable, but $\{a\in B\mid a\lt c\}$ is countable for all $c\neq b$. With this set $(B,\leq)$ in mind, I can set up a base with the intervals of form $\{a\in B\mid a\lt x\}$, $\{a\in B\mid a\gt y\}$, and $\{a\in B\mid x\lt a\lt y\}$ for various $x,y\in B$. This covers $B$ and the intersection of two intervals is another interval (when the intersection is nonempty) so this family is indeed a base. I'll call it $\mathcal{B}$, and take the associated topology on $B$. Now let $\phi\colon B\to \{0,1\}$ be defined as $\phi(b)=1$ and $\phi(a)=0$ for any $a\neq b$. Let $\{0,1\}$ have the discrete topology. So I believe $\phi$ is not continuous since $\phi^{-1}(\{1\})=\{b\}$ is not open in $B$ as $\{b\}$, as a singleton, cannot possibly have one of the three forms of intervals in $\mathcal{B}$. Am I correct in thinking this? I want to finally show that for any convergent sequence $\{a_i\}$ in $B$, then $\lim_{i\to\infty}\phi(a_i)=\phi(\lim_{i\to\infty}a_i)$. How can one do this? Let $a_i\to a$. My thinking is I just need to show any nbhd of $\phi(a)$ contains all but finitely many $\phi(a_i)$. So the only nbhds of $\phi(a)$ are $\{\phi(a)\}$ and $\{0,1\}$. Clearly $\{0,1\}$ contains all $\phi(a_i)$. If $\phi(a)=0$, then all but finitely many $a_i$ map to $\phi(a)$, since only $\phi(b)=1$. I think there might be more that needs to be said about this, my worry is that maybe $b$ shows up in the sequence infinitely many times?. And if $\phi(a)=1$, I'm not sure what to do. I'd appreciate an explanation on how this property holds. Many thanks.","['general-topology', 'functions']"
62422,Proof of the equality $\sum\limits_{k=1}^{\infty} \frac{k^2}{2^k} = 6$,"Show that for $k$ running over positive integers 
$$ \sum_{k=1}^\infty \frac{k^2}{2^k}=6 .$$ We can use finite calculus.","['elementary-number-theory', 'sequences-and-series', 'algebra-precalculus']"
62434,Algebra Question System of Equations,"How would one go about solving the system of five equations: $p^2=p+q-2r+2s+t-8$, $q^2=-p-2q-r+2s+2t-6$, $r^2=3p+2q+r+2s+2t-31$, $s^2=2p+q+r+2s+2t-2$, $t^2=p+2q+3r+2s+t-8$ over the integers? I have no immediate way of answering this question, since it looks to be solved by some ""trick."" Inequalities may help, although it says ""over the INTEGERS"" and most inequalities only deal with positive reals. EDIT: I dont see how congruence's can work, as that may limit the number of solutions, but only to a certain congruence class. For example, we may find that p=1 mod 3, say, but this will only give us an infinite number of p's to check. Unless, of course, we get a congruence contradiction, in which case there would be no solution, but the solution $(3,2,1,5,4)$ works-noted below. (sorry my computer is acting up and wont let me comment)","['algebra-precalculus', 'diophantine-equations']"
62435,Expert Minesweeper Probability Question,"This is just a question I thought of while playing minesweeper. I think that finding the solution might be kind of fun, so I'm sharing it with you guys. If you have no concept of what minesweeper is, this question might be kind of tough. Also, if you have no concept of what minesweeper is go play it. It's fun. It's an expert board. That means you have a grid of 16 by 30, for a total of 480 squares. A random 99 of these squares have a mine hidden under them. When you click a square, three things can happen. You can click a mine, resulting in an instant loss. You can click on a square next (diagonal included) to at least one mine, resulting in a number being shown under the square. Or you can click on a square that isn't a mine and isn't next. When this is done, all 8 surrounding squares are revealed. If any of those squares are also not next to any mines, all of the surrounding squares that are not yet revealed become revealed. That should make sense if you've played minesweeper before. You're playing expert mode. The mines are spread randomly. What is the average number of squares revealed by your first click? I would count clicking a mine as 0 squares revealed. Have fun!","['recreational-mathematics', 'probability']"
62436,"Where can I find good, free resources on differential equations?","I'd like to know if there are any good online books, lecture notes, videos, tutorials, or similar that are free to the public (on differential equations).  Suggestions are welcome!","['ordinary-differential-equations', 'reference-request']"
62445,Visualizing the domain of the square root,"I would like to show someone the domain of the complex square root function (the 2-sheeted riemann surface).  Is there a good interactive visualization software for this? I would like some sort of GeoGebra style app where there is a forbidden point or disk, but outside of that you can drag a point around.  As you drag around the pole, it changes from red to blue smoothly, so that on the bottom sheet it is red, and on the top sheet it is blue (or some reasonable periodic color scheme where 50% apart is always very distinct). It would be doubly nice if one could have simple geometric shapes do the same.  Basically I want a nice double covering of a plane symmetry group that is still very geometric. It would be n -tuply nice if one could handle n th roots and the n -sheeted Riemann surface, but n =2 suffices for me, I think. I've used other people's geogebra apps, but never made my own, and have no idea how to keep track of what sheet the point is on (or honestly how to animate the color, though I assume once I have a 0…4π valued argument function, I should be fine). Some pretty images from wikipedia :","['riemann-surfaces', 'visualization', 'complex-analysis']"
62448,"Infinite sequence of nested, falling, colliding spheres","Imagine an infinite collection of nested, concentric spheres, of radius 1, $\frac{1}{2}$ , $\frac{1}{4}$ , $\frac{1}{8}$ , and so on.  Suppose they are somehow suspended in space, fixed on their
common center $x$ .  Then the outermost sphere is ""released"" from its center, and falls
vertically under the influence of gravity, while all the other spheres remain ""pinned""
with their centers on $x$ .  Next, the top interior of the $r=1$ sphere collides with the top exterior of the $r=\frac{1}{2}$ sphere, knocking it loose from $x$ via a perfectly elastic collision, sending it
downward.  And so on. Essentially my question is: What happens ?  It would be pleasing to understand
the behavior of this system without resorting to explicit calculation of
all the interactions.  Assume the spheres are made of some homogenous, thin
material so that their weight is proportional to their surface area
(or circumference if you'd prefer to drop down to $\mathbb{R}^2$ ).
I cannot see intuitively the sequence of collisions and overall behavior,
and I have not yet tried careful calculations.  Perhaps there is a line
of reasoning that demystifies the apparent complexities...?","['geometry', 'classical-mechanics']"
62449,Quotient group properties,"Let $H$ and $E$ be normal subgroups of a group $G$ such that
$$G/H \cong E.$$
Under what sort of conditions would we also have
$$G/E \cong H?$$ Thanks.","['group-theory', 'abstract-algebra']"
62466,Eigenvalues of anti-circulant matrices using 1-circulant matrices,"Is there any theorem to find the eigenvalues of any anti-circulant matrix using the equivalent (with the same first row) circulant matrix. I found out that,
for any anti-circulant matrix, the eigenvalues (taken as $\mu$) of the anti-circulant matrix can be written as,
\begin{equation}
\mu = \pm \mid{\lambda_j}\mid
\label{mu_alpha}
\end{equation}
where $\lambda_j$ is an eigenvalue of 1-circulant matrix with the same first row. This seems valid since any anti-circulant matrix should be symmetric resulting in real eigenvalues. Can anyone send me a link to any reference which has this proof..? or can you please comment if you think that this should not be correct ?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra', 'reference-request']"
62468,Interpretations of the Correspondence Theorem (4th Isomorphism Theorem),"I know of this version of the correspondence theorem for Groups (From Herstein's Abstract Algebra ): ''Let $\phi$ be a group homomorphism from G onto G' with kernel $K$. If $H' \leq G'$ and $H = \{ a \in G : \phi(a) \in H '\}$, then $H$ is a subgroup of $G$ that contains $K$ and $H/K \cong H'$. To illustrate this, consider the following homomorphism $\phi$ from $S_4$ to $S_3$: Partition the set of 4 indices $\{1,2,3,4\}$ into pairs of subsets in the following way: $\Pi_1 = \{1,2\} \cup \{3,4\}$ $\Pi_2 = \{1,3\} \cup \{2,4\}$ $\Pi_3 = \{1,4\} \cup \{2,3\}$. Then take say the cycle $(1234)$ in $S_4$ and let it act on each of the $\Pi_i's$. It should be immediate that $(1234)$ switches $\Pi_1$ and $\Pi_3$ while fixing $\Pi_2$. So we see can define $\phi$ by the action of $(1234)$ on the $\Pi_i's$ (I don't even know if this is correct terminology). In addition we see that $(1234)$ is mapped to $(13)(2)$ in $S_3$. So now if I consider the subgroup $H' = \{e, (12)\}$ of $S_3$, we can see that the kernel of $\phi$ contains the elements $\{e, (12)(34), (13)(24), (14)(23) \}$. So if we form the quotient $H/K$, it will just  contain the elements $\{ [e], [(1324)] \}$. It is then apparent that $H/K$ is isomorphic to $H'$. However I also know that there is a one to one correspondence between the subgroups of $S_4$ containing the kernel and $S_3$. For example another such correspondence would be between the alternating group $A_4 \leq S_4$ and the subgroup in $S_3$ generated by the cycle $(123)$. For any groups $G$, $G'$ and $H, H'$ defined as above, how is $H/K \cong H'$ equivalent to there being a bijective correspondence between the subgroups of $G'$ and those of $G$ containing the kernel? Thanks.",['group-theory']
62472,Expectation of the cardinality of the intersection of subsets,"Let A be a set of n distinct elements, and let A' and A'' be independent permutations of A, where |A'| = |A''| = k.   What is the expectation for |A' ∩ A''| for any given k <= n?","['permutations', 'discrete-mathematics', 'probability']"
62477,What is the correct way to plot histogram?,"When we plot the frequency histogram, the frequency is equal to the area of the bar or the height of the bar?
Is $\text{height} = \frac{\text{frequency}}{\text{size of the class}}$ ? If so, then how to label the vertical axis? For example, based on the following data, Class   Frequency
[0,9)      10
[10,19)    20
[20,39)    40 Then what is the label for vertical axis? Is it ""frequency"" or ""frequency density""? The height of first class is 10 or 1.0? For the 3rd class, is it 20, 2.0, or 40? Possible solution (or answer) Based on the information I studied from several links,
when the width of the class is different, one needs to use ""Frequency density"" for the vertical axis. Then, $\text{frequency} = \text{height} \times \text{width of the class}$ If the class are in the same width, then one can use ""Frequency"" for the vertical axis, then all the heights of the bars are point to the value directly.","['statistics', 'graphing-functions']"
62483,Minimum Generators of Finite Groups vs. Subgroups,"For infinite groups (ex. Free Groups), a subgroup may have more number of  generators than the group. For finite groups, is the number of  generators of subgroup less than  number of generators of group? [Of course, we understand number of generators to mean ""minimum number of generators""].",['group-theory']
62486,Ten soldiers puzzle,"This is a puzzle from one popular book called ""The Man Who Counted: A Collection of Mathematical Adventures"",author is Malba Tahan. How to arrange ten soldiers in five lines in such a way
that each line contains four soldiers exactly?","['geometry', 'puzzle', 'recreational-mathematics', 'intuition']"
62497,Matrix is conjugate to its own transpose,"Mariano mentioned somewhere that everyone should prove once in their life that every matrix is conjugate to its transpose. I spent quite a bit of time on it now, and still could not prove it. At the risk of devaluing myself, might I ask someone else to show me a proof?","['matrices', 'linear-algebra', 'transpose']"
62499,Proving $\cot(A)\cot(B)+\cot(B)\cot(C)+\cot(C)\cot(A)=1$,"I was stumped by another past-year question: In $\triangle ABC$, prove that $$\cot(A)\cot(B)+\cot(B)\cot(C)+\cot(C)\cot(A)=1.$$ Here's what I have done so far: I tried to replace $C$, using $C=180^\circ-(A+B)$. But after doing this, I don't know how to continue. I would be really grateful for some help on this, thanks!","['trigonometry', 'triangles']"
62512,When is the determinant of a Hessian matrix positive?,"Let $f:\mathbb{R}^n\to \mathbb{R}^n$ be a $C^2$-function and let $H=\left(\frac{\partial^2f}{\partial x_i \partial x_j}\right)_{1\le i,j\le n}$ be its Hessian matrix. Suppose I know that $ \det H(x_1,\ldots,x_n)\ge 0$ for all $x=(x_1,\ldots,x_n)$. Does this have any geometric meaning for $f$? e.g., when $n=1$, this means that $f$ is convex. This no longer holds for $n\ge 2$, but when $f$ is convex the Hessian determinant is certainly positive, so perhaps one could wonder if a weaker property holds.","['multivariable-calculus', 'vector-analysis', 'real-analysis']"
62514,Prove that $ \frac{1}{1}-\frac{1}{4}+\frac{1}{7}-\frac{1}{10}+\ldots= \frac{1}{3} \left( {\frac{\pi}{\sqrt{3}}+ \log 2} \right)$,"How do I show that $$ \frac{1}{1}-\frac{1}{4}+\frac{1}{7}-\frac{1}{10}+\ldots= \frac{1}{3} \left( {\frac{\pi}{\sqrt{3}}+ \log 2} \right)?$$ This problem belongs to Riemann Theory of Definite Integral, and not to any series summation. I recommend an answer which is to the topic i.e., Riemann Theory of D.I.. Thanks!","['calculus', 'real-analysis']"
62524,"Why is $\det(\vec{A},\vec{B}) = |\vec{A} \times \vec{B}|$?","In the multivariable calculus class the teacher showed us the formula of the cross product $$ \vec{A} \times \vec{B} =\begin{vmatrix}\hat{\imath}& \hat{\jmath}& \hat{k} \\
a_1 & a_2 & a_3 \\b_1 & b_2 & b_3 \end{vmatrix}$$ And formula for determinant in two dimensions which can calculate the area of parallelogram in two dimensions by $$\det(\vec{A},\vec{B}) =\begin{vmatrix}a_1 & a_2 \\b_1 & b_2 \\\end{vmatrix}$$ Then teacher talked about the area of a parallelogram also being equal to the length of $\vec{A} \times \vec{B}$, that is $|\vec{A} \times \vec{B}|$, but gave no proof. I wanted to check this, so I used  $a_3=0,b_3=0$ just to have the $3 \times 3$ in the form that could be compared to $\det(\vec{A},\vec{B})$ form. When I expand the calculation, I do end up with  $|\hat{k}(a_1b_2 - a_2b_1)|$, and that equals to $(a_1b_2 - a_2b_1)$ The two forms are equal. Is this reasoning correct?","['cross-product', 'linear-algebra']"
62525,Dissection of square into triangles,"Prove that a square cannot be dissected into an odd number of triangles of equal area. Got to read about the question and its history in ""Algebra and Tiling Homomorphisms in the Service of Geometry by  Sherman Stein and Sándor Szabó quite an interesting question, neither my doubt nor my homework, just want to see the various ideas that people here would come up with it. edit: the proof i have seen involves higher mathematics which I have not yet completed in my college courses. Posting here mainly to see if anyone can come up with an idea that would be understood by me or a similar pre college student",['geometry']
62539,Doubt in Application of Integration - Calculation of volumes and surface areas of solids of revolution,"I am using two books for my calculus refresher. Thomas' Calculus Higher Math for Beginners by Ya. B. Zeldovich My question is : When applying Integral Calculus for calculation of volumes of solids, generated by curves revolved around an axis, we use slices of 'cylinders' to approximate the volume of the resulting solid and then integrate the sum of those infinitesimal cylinders. However, when we are using the same techniques to calculate the surface area of the surfaces generated by revolving curves around an axis, we consider the 'slope' of the differential length of curve 'dx', calculate the total length of the curve and derive the required surface area. Are we not supposed to use the same 'slope' for calculating the volumes of the infinitesimal 'cylinders' for calculation of volumes? Shouldn't we use 'sliced portions of 'cones' as the infinitesimal volumes?? When it come to calculation of volumes of solids of revolution, why are we neglecting the slope of the curve for the differential length and simply assume that it is an infinitesimal cylinder?? Ex: Let us say we want to calculate the surface area and the volume of the solid generated when the parabola y = 10 . x^2 is revolved about the y-axis, with limits of x from 0 to 5. In such cases, when calculating the volume of the solid, we consider infinitesimal 'cylinders', ignoring the 'slope' of the curve for the differential element 'dx', but when calculating the surface area, we consider the 'slope' of the differential element 'dx'.","['calculus', 'integration', 'analysis']"
62544,free $R$-algebras: when does $R\langle X\rangle\cong\!R\langle Y\rangle$ $\Rightarrow$ $|X|\!=\!|Y|$ hold?,"An analogous question regarding free groups can be found here . INTUITION: A free $R$-algebra on indeterminates $X_1,\ldots,X_n$ is the noncommutative analogue of the polynomial ring $R[X_1,\ldots,X_n]$, which is a free commutative $R$-algebra on $X_1,\ldots,X_n$. DEFINITIONS: For a commutative ring $R$ with $1_R$ and any set $X\!=\!\{X_i;\:i\!\in\!I\}$, the free (associative) unital $R$-algebra on $X$ , denoted $R\langle X\rangle\!=\!R\langle X\,|\,\emptyset\rangle$, is the free $R$-module with basis the free monoid on $X$ of all (noncommutative) words (possibly empty) over $X$. Thus every element of $R\langle X\rangle$ has the form $$\sum r_iX_{j_1}\ldots X_{j_i}$$ and is called a noncommutative polynomial , where $r_i\!\in\!R$ (only finitely many non-zero) and $X_{j_1},\ldots,X_{j_i}\!\in\!X$ and $j_i\!\in\!\mathbb{N}_0$ (when $j_i\!=\!0$, the word $X_{j_1}\ldots X_{j_i}$ is empty, denoted with $1$); furthermore, $X$ is called the alphabet , $X_i$ are called indeterminates or variables or letters or generators , $X_{j_1}\ldots X_{j_i}$ are called monomials or words , and $r_i$ are coefficients . Multiplication is defined as follows: the product of two basis elements (monomials) is their concatenation, i.e.
    $$(X_{i_1}\!\ldots X_{i_m}) \cdot (X_{j_1}\!\ldots X_{j_n}) := X_{i_1}\!\ldots X_{i_m}X_{j_1}\!\ldots X_{j_n};$$
    the product of any two elements (polynomials) just takes into account that $\cdot$ must be $R$-bilinear. For example, for $\alpha,\beta,\gamma,\delta\!\in\!R$ we have $(\alpha X_1X_2^2\!+\!\beta X_2X_3)\cdot(\gamma X_3\!+\!\delta X_2^3X_3X_1)$ $=$ $\alpha\gamma X_1X_2^2X_3+\alpha\delta X_1X_2^5X_3X_1+\beta\gamma X_2X_3^2+\beta\delta X_2X_3X_2^3X_3X_1$. When $|X|\!=\!n\!<\!\infty$, this algebra is denoted $R\langle X_1,\ldots,X_n\rangle$. In short, for any set $X$, the free unital $R$-algebra on $X$ is $$R\langle X\rangle:=\bigoplus_{w\in X^\ast}Rw$$ with the $R$-bilinear multiplication that is concatenation on monomials/words, where $X^\ast$ is the free monoid on $X$ and $Rw\!=\!\{rw;\:r\!\in\!R\}$ is the formal free module on $w$, i.e. $rw\!=\!r'w\Leftrightarrow r\!=\!r'$. The empty word/monomial of $X^\ast$ is the identity $1$ of $R\langle X\rangle$. The map $i\!:X\!\rightarrow\!R\langle X\rangle$, $X_i\!\mapsto\!X_i$ is called the canonical injection . If we replace $X^\ast$ with $X^+$ (the free semigroup on $X$, i.e. $X^\ast$ without the empty word) in the above construction, we create the free nonunital $R$-algebra on $X$ : $R\langle X\rangle^+\!=\!R\langle X\,|\,\emptyset\rangle^+$. DEFINITIONS: For $S\!\subseteq\!R\langle X\rangle$, an algebra presentation , denoted $R\langle X|S\rangle$, is the $R$-algebra $R\langle X\rangle/\langle\!\langle S\rangle\!\rangle$, where $\langle\!\langle S\rangle\!\rangle$ denotes the algebra ideal, generated by $S$. The notation $\langle X\,|\,p_i\!=\!p'_i;\, i\!\in\!I\rangle$ simply means $\langle X|p_i-p'_i; i\!\in\!I\rangle$. Any $R\langle X|S\rangle$ is finitely generated / finitely related / a finite presentation if $X$ is finite / $S$ is finite / $X$ and $S$ are finite. An arbitrary (unital) $R$-algebra $A$ is finitely generated / finitely related / finitely presented if it has a presentation $R\langle X|S\rangle\!\cong\!A$ that is finitely generated / finitely related / finite. Elements of $S$ are relations or relators . These notions are analogously defined for the free nonunital $R$-algebra on $X$; the presentation is then denoted $R\langle X|S\rangle^+$. COMMENT: Rings are $\mathbb{Z}$-algebras, so the above construction gives us the free ring on $X$ , namely $\mathbb{Z}\langle X\rangle^+$, and free unital ring on $X$ , namely $\mathbb{Z}\langle X\rangle$. PROPOSITION (universal property): Let $i\!:X\!\rightarrow\!R\langle X\rangle$ be the canonical injection. For any unital $R$-algebra $A$ and any map $f\!:X\!\rightarrow\!A$, there exists a unique unital algebra homomorphism $\overline{f}\!:R\langle X\rangle\!\rightarrow\!A$ such that $f\!=\!\overline{f}\!\circ\!i$, namely $\overline{f}(\sum r_iX_{j_1}\ldots X_{j_i})=\sum r_if(X_{j_1})\cdot\ldots\cdot f(X_{j_i})$. Proof: $\overline{f}$ must be a homomorphism and $f\!=\!\overline{f}\!\circ\!i$, so $\overline{f}(\sum r_iX_{j_1}\!\ldots\!X_{j_i}\!)\!=\!\sum r_if(X_{j_1}\!)\!\cdot\ldots\!\cdot\!f(X_{j_i}\!)$  must be satisfied, hence uniqueness of $\overline{f}$. It is also evident that such $\overline{f}$ is a unital algebra homomorphism. To prove it is well defined, assume $\sum r_iX_{j_1}\ldots X_{j_i}\!=\!0$. By definition, $R\langle X\rangle$ is a free module on $X^\ast$, thus $r_i\!=\!0$. Therefore $\overline{f}(0)\!=\!0$, and $\overline{f}$ is well defined. $\blacksquare$ COMMENT: by the universal property, $R\langle X\rangle$ is the free object on $X$ in the category of unital $R$-algebras. PROPOSITION: Every unital $R$-algebra $A$ has a presentation, i.e. $\forall A\:\exists X,S\!:\: A\!\cong\!R\langle X|S\rangle$. Proof: Let $A$ be generated by $X\!\subseteq\!A$ ($X:=A$ suffices) and let $f\!:X\!\hookrightarrow\!A$ be the inclusion. By the universal property, $\exists!$ algebra homomorphism $\overline{f}\!:R\langle X\rangle\!\rightarrow\!A$ that extends $f$. We have $X\!\subseteq\!\mathrm{Im}\,\overline{f}$, so $\overline{f}$ is surjective. Therefore $A\!\cong\!R\langle X\rangle/\mathrm{Ker}\,\overline{f}\!=\!R\langle X| \mathrm{Ker}\,\overline{f}\rangle$. $\blacksquare$ QUESTION: how can I prove the statement $R\langle X\rangle\!\cong\!R\langle Y\rangle\:\Rightarrow\:|X|\!=\!|Y|$ ? I've thought of using the following theorem from Grillet's Abstract algebra (page 333): However, this just gives us $|X^\ast|\!=\!|Y^\ast|$. I've also thought of abelianising both algebras, so we get $R[X]\!\cong\!R[Y]$. But I'm not sure how to continue from here.",['abstract-algebra']
62548,Why is a finite integral domain always field?,"This is how I'm approaching it: let $R$ be a finite integral domain and I'm trying to show every element in $R$ has an inverse: let $R-\{0\}=\{x_1,x_2,\ldots,x_k\}$, then as $R$ is closed under multiplication $\prod_{n=1}^k\ x_i=x_j$, therefore by canceling $x_j$ we get $x_1x_2\cdots x_{j-1}x_{j+1}\cdots x_k=1 $, by commuting any of these elements to the front we find an inverse for first term, e.g. for $x_m$ we have $x_m(x_1\cdots x_{m-1}x_{m+1}\cdots x_{j-1}x_{j+1}\cdots x_k)=1$, where $(x_m)^{-1}=x_1\cdots x_{m-1}x_{m+1}\cdots x_{j-1}x_{j+1}\cdots x_k$. As far as I can see this is correct, so we have found inverses for all $x_i\in R$ apart from $x_j$ if I am right so far. How would we find $(x_{j})^{-1}$?","['ring-theory', 'finite-rings', 'integral-domain', 'abstract-algebra', 'field-theory']"
62557,Topology exercise. Quotient Space,"I found this exercise I'm not able to solve. EXERCISE : Let's call $X$ the topological space obtained quotienting $\mathbb{R}^{n}$ by the equivalence relation $\sim$ : $x\sim y \Leftrightarrow x=y$ or $||x||=||y||$ or $||x||\cdot ||y||=1$. Is $X$ an Hausdorff space ($T2$)?? Is $X$ compact??
Can anyone help me? The only idea i had is this one but I had plenty of doubt about its correctness..
Using hyperspherical coordinates (http://en.wikipedia.org/wiki/N-sphere#Hyperspherical_coordinates) can I say that $\mathbb{R}^{n}$ is omeomorph to $\mathbb{R}\times \left[ {0,\pi } \right] \times \cdots \times \left[ {0,\pi } \right] \times \left[ {0,2\pi } \right[$ ???
And if that was true, using the fact that $\sim$ act only on the norm and not on the angles, can I say that $\mathbb{R}^{n}/\sim {\rm{ }} = \left( {\mathbb{R}\times \left[ {0,\pi } \right] \times \cdots \times \left[ {0,\pi } \right] \times \left[ {0,2\pi } \right[} \right)/\sim {\rm{ }} = \mathbb{R}/\sim$ ???
Thanks in advance.",['general-topology']
62567,Is the use of $\lfloor x\rfloor$ legitimate to correct discontinuities?,"Is the use of $\lfloor x\rfloor$ legitimate to correct discontinuities? In functions like $\tan^{-1}(a \tan(x))$, the angle wraps and the result is discontinuous. Is it legitimate to redefine the equation as in $\tan(a \tan^{-1}(x)) + \pi\lfloor \pi x + \frac{1}{2} \rfloor \mathop{\rm sgn}(a)$ to keep it continuous?  Or is it better to write it $\tan(a \tan^{-1}(x)) + (x - \tan^{-1}(\tan(x))) \mathop{\rm sgn}(a)$, or some other way–or should this never be corrected in the first place? I realize this example is rather trivial due to the multivalued nature of the arctangent.  Here is one that is not so trivial: the arc length of the cycloid. Unless I'm missing something, the problem with simply calculating integral for the arc length $\int \sqrt{2 - 2\cos(t)} dt = 2 \int |\sin(\frac{t}{2})| dt = 4-4\cos(\frac{t}{2})\mathop{\rm sgn}(\sin(\frac{t}{2}))$ is that it jumps back down to zero every $2\pi$.  This could be corrected in one of the above ways.  If left alone it is simply incorrect except in $0 < t < 2\pi$. Now Wolfram|Alpha gives a terribly convoluted function for it.  How did W|A redefine the process to come out correct for all $t$ (not to mention so convoluted)?  Is this more natural or otherwise more legitimate than simply adding a floor function to it? In other words: is there a mathematical reason to prefer one method over another?","['trigonometry', 'calculus', 'functions']"
62581,Convert coordinates from Cartesian system to non-orthogonal axes,I have a 2D coordinate system defined by two non-perpendicular axes. I wish to convert from a standard Cartesian (rectangular) coordinate system into mine. Any tips on how to go about it?,"['geometry', 'coordinate-systems']"
62588,Correspondence between the projective space associated to a vector space and the dual space of the vector space?,"Let $V$ be a vector space over $\mathbb{C}$ and $V^*$ be its dual space. Let $\mathbb{P}V$ be the projective associated to $V$. It is said that homogeneous coordinates of $\mathbb{P}V$ correspond to elements of $V^*$. What is the correspondence? Suppose that $V=\langle v_1, \ldots, v_k \rangle$ and $V^*=\langle v^*_1, \ldots, v^*_k \rangle$ where $v^*_i(v_j)=\delta_{ij}$. We can let $(a_0, \ldots, a_k) \in \mathbb{P}V$ corresponds to $f\in V^*$ where $f(v_i)=a_i$. Is this the correct correspondence? Thank you very much.",['algebraic-geometry']
62602,understanding covariant derivative (connexion),"My lecturer defined the covariant derivative as in this section from Wikipedia: http://en.wikipedia.org/wiki/Covariant_derivative#Vector_fields . From this, he defines the operator $\nabla_X Y$ to mean the covariant derivative of $X$ along $Y$. I'm confused as to the role $\nabla$ plays here: all I understand is that  $\nabla_X Y|_p$ is the result of taking in a tangent vector (given by $X(p)$) and doing something with it and $Y$, but $Y$ takes a point as input, not a tangent vector. On some other site I found this covariant derivative defined as a directional derivative but I don't see how that relates. Maybe once I understand this I can understand why  $\nabla_X Y = 0 $ means that $Y$ is parallel along $X$.","['riemannian-geometry', 'differential-geometry']"
62614,Chain Rule Intuition,"We know that the chain rule is used to differentiate  a composite function ,say $$f(x) = h(g(x))$$ It's defined as the derivative of the outside function times the derivative of the inner function or the other way around. $$\frac{\mathrm{dy} }{\mathrm{d} x} = \frac{\mathrm{dy} }{\mathrm{d} u} \cdot \frac{\mathrm{du} }{\mathrm{d} x}$$ Despite we know that the above expression is not a fraction (even though it's a fractional notation of the derivative used by Leibnitz) you can ""cancel"" the two du's and get back dy/dx. My question is: How can you even think of cancelling du from dy/du and du from du/dx when they are not even fractions. Just because it's been multiplied do they automatically become fractions?Are they really being ""multiplied""? I'am really looking for an intuition behind this.To me this is some kind of fantasy.It doesn't appear to be real.","['chain-rule', 'calculus', 'intuition', 'definition']"
62633,Orthogonal projection of a point onto a line,"How would I go about solving the following problem? Find an orthogonal projection of a point T$(-4,5)$ onto a line $\frac{x}{3}+\frac{y}{-5}=1$.","['matrices', 'geometry', 'linear-algebra', 'analytic-geometry']"
62644,Does the operation of $G/A$ on $A$ by conjugation just give a trivial homomorphism?,"I'm having doubts about an exercise, since I reach a trivial conclusion. I hope it's not an issue to see if I'm screwing up. Let $G$ be a group, and $A$ a normal abelian subgroup. Show $G/A$ operates on $A$ by conjugation and in this way get a homomorphism of $G/A$ into $\text{Aut}\ (A)$. So the action is $gA\bullet a=gAa(gA)^{-1}=gAag^{-1}A=gAaAg^{-1}=gAg^{-1}=A$. Also $(gAhA)\bullet a=gA\bullet(hA\bullet a)$ and $A\bullet a=A$. So is this just a trivial homomorphism which maps everything to $A$? I think I'm applying things wrong since I thought it's supposed to be $A\bullet a=a$ and the action should return elements of $A$, not $G/A$. How to interpret correctly?","['group-theory', 'abstract-algebra']"
62648,Probability of balls in the box,"In a box there are 12 balls; 4 defective, 8 not defective. What is the probability that when 3 balls are drawn, at least two of them are defective. I know the answer is $$\frac{{4 \choose 2}{8 \choose 1} + {4 \choose 3}}{{12 \choose 3}}$$ But why isn't the answer also $$\frac{{4 \choose 2}{10 \choose 1}}{{12 \choose 3}} $$? Because I choose 2 balls from the 4 defective, and 1 from the remaining 10 (it will either be defective or not).",['probability']
62653,Semidirect product uniqueness argument for classifying groups of small order,"I'm having trouble understanding the following method for determining the number of semidirect products between two groups in simple cases that arise when trying to classify certain groups of small order. Here is an example, but I'm really interested in understanding the ""general"" (i.e. applies in lots of special cases for classifying small order groups) argument. For example, I was just trying to classify groups of order $140=2^2\cdot 5\cdot 7$. Sylow's theorems immediately give $n_5=n_7 = 1$, so we have that the group is either
$(\mathbb{Z}_2\oplus \mathbb{Z}_2) \ltimes (\mathbb{Z}_5 \oplus \mathbb{Z}_7)$
or
$\mathbb{Z}_4 \ltimes (\mathbb{Z}_5 \oplus \mathbb{Z}_7)$ depending on the 2-Sylow subgroup. Now, so clearly for each map
$$\mathbb{Z}_4 \to \operatorname{Aut}(\mathbb{Z}_5 \oplus \mathbb{Z}_7) \simeq \mathbb{Z}_4 \oplus \mathbb{Z}_6$$ and 
$$\mathbb{Z}_2\oplus \mathbb{Z}_2 \to \operatorname{Aut}(\mathbb{Z}_5 \oplus \mathbb{Z}_7) \simeq \mathbb{Z}_4 \oplus \mathbb{Z}_6$$ I can count these, but I'm not exactly sure how to prove that they all lead to unique semidirect products which I think happens to be the case. I don't really understand the argument given here , for example. I particularly don't understand how to deal with the fact that in this case, both factors in the semidirect product have order divisible by 2, so it seems like an isomorphism could mix things up in ways that you could probably prove can't happen when the orders are relatively prime. Thanks!","['groups-enumeration', 'finite-groups', 'group-theory', 'abstract-algebra']"
62655,On factorizing  and solving the polynomial: $x^{101} – 3x^{100} + 2x^{99} + x^{98} – 3x^{97} + 2x^{96} + \cdots + x^2 – 3x + 2 = 0$,"The actual problem is to find the product of all the real roots of this equation,I am stuck with his factorization: $$x^{101} – 3x^{100} + 2x^{99} + x^{98} – 3x^{97} + 2x^{96} + \cdots + x^2 – 3x + 2 = 0$$ By just guessing I noticed that $(x^2 – 3x + 2)$ is one factor and then dividing that whole thing we get $(x^{99}+x^{96}+x^{93} + \cdots + 1)$ as the other factor , but I really don't know how to solve in those where wild guessing won't work! Do we have any trick for factorizing this kind of big polynomial? Also I am not sure how to find the roots of  $(x^{99}+x^{96}+x^{93} + \cdots + 1)=0$,so any help in this regard will be appreciated.",['algebra-precalculus']
62657,What is the prerequisite knowledge for learning discrete math?,"To become a better computer programmer I would like to take the time to learn discrete mathematics, but I am positive that I do not have the required existing knowledge to do so. So I would like to hear from the experts about what I really need to know to be able to take a discrete math class or to even be able to pick up a book and learn it on my own. The extent of my math knowledge now is basic algebra. Probably not even high school senior level. Where should I start? I am guessing I should start with college algebra(or possibly even a remedial algebra), but I don't know where to go from there. Do I need trigonometry? The calculus? Calc II? I wish I had worked harder in high school, but I didn't. Thanks for your answers.","['discrete-mathematics', 'soft-question']"
62667,When can a pair of groups be embedded in each other?,"This is a question I made up, but couldn't solve even after some days' thought. Also if any terminology is unclear or nonstandard, please complain. Given groups $G$ and $H$, we say that $G$ can be embedded in $H$ if there exists an injective homomorphism $\varphi : G \to H$. (Note that the image $\varphi(G)$ is then isomorphic to $G$.) I am interested in the situation where a pair of groups $G$ and $H$ can be embedded in each other. Of course, this is guaranteed to be the case when $G \cong H$. But is the converse true? More precisely: Q1. Do there exist non-isomorphic groups $G$ and $H$ such that each of them can be embedded in the other? I am interested in this because, in my mind, this question is analogous to the Cantor-Bernstein-Schroeder theorem in set theory. Of course, this view could be too naive or useless. Oh well. The only ""progress"" I could make is to create another question. Let $\varphi_G:G \to H$ and $\varphi_H:H \to G$ be a pair of embeddings as in the question. Then the homomorphism $\varphi := \varphi_H \circ \varphi_G : G \to G$ is also injective; i.e., it is an embedding. I can show that the image of this map ($K := \varphi(G)$) is a proper subgroup of $G$ unless $G \cong H$. This leads me to another question: Q2. Does there exists a group $G$ that is isomorphic to a proper subgroup of itself? If the answer to this is negative, then so is the case for Q1 . Though both of these seem ""obviously false"", I cannot prove them. Nor can I construct a counterexample. Any suggestions? Some remarks: Nothing is inherently special about groups here. I suppose one could ask the same question for rings, fields, or other structures; I focused on this specific question for clarity. I tried to search through Wikipedia and Google books, but I cannot figure out the answer or where I can find the answer. I have no idea as to how easy or difficult these questions are. If they are trivial/easy (say, the level of a standard undergrad homework exercise), then please give me hints rather than a complete solution :-).","['hopfian', 'group-theory', 'abstract-algebra']"
62688,Example of not being a sigma algebra as complement property does not hold,"I am working on a homework problem and am somewhat lost. I know that an answer will not be given on a silver platter and am fine with that - I need to know what I am missing in understanding so that I can solve the problem. I need an infinite collection of subsets of $\mathbb{R}$ that contains $\mathbb{R}$, is closed under the formation of countable unions and countable intersections, but is not a $\sigma$-algebra. So I immediately thought that the only requirement not mentioned to make it a $\sigma$-algebra is the closure under complementation. That is why I thought of maybe using $\mathcal{P}(\mathbb{R})-\{\varnothing\}$, the powerset 'minus' the null set.  Is this okay? Can you subtract 'nothing' like this? Otherwise I am quite lost and any direction would be greatly appreciated. Nate P.S> I could not find suitable suggestions to my question by looking around on the site.","['measure-theory', 'real-analysis']"
62696,What is the explanation for the elements of this set?,"From Stephen Abbott's Understanding Analysis (some parts omitted): Exercise 1: (a) Using the particular set $A = \{a,b,c\}$ , exhibit two different $1-1$ mappings from $A$ into $P(A)$ . (b) Letting $B = \{1,2,3,4\}$ , produce an example of a $1-1$ map $g: B \to P(B)$ . Exercise 2: Construct $B$ using the following rule. For each element $a \in A$ , consider the subset $f(a)$ . This subset of $A$ may contain the element $a$ or it may not. This depends on the function $f$ . If $f(a)$ does not contain $a$ , then we include $a$ in our set $B$ . More precisely, let $B = \{a \in A: a \notin f(a) \}$ . Return to the particular functions constructed in Exercise 1 and construct the subset $B$ that results using the preceding rule. In each case, note that $B$ is not in the range of the function used. Solution Exercise 1: (a) Given set $A = \{a,b,c\}$ , $A$ can be mapped in a $1-1$ fashion into $P(A)$ in many ways. For example, we could write (i) $a \to \{a\}$ , $b \to \{ a,c\}$ , $c \to \{a,b,c\}$ . As another example we might say (ii) $a \to \{b,c\}$ , $b \to \emptyset$ , $c \to \{a,c\}$ . (b) An example of a $1-1$ mapping from $B$ to $P(B)$ is: $1 \to \{1\}$ , $2 \to \{ 2,3,4\}$ , $3 \to \{1,2,4\}$ , $4 \to \{2,3\}$ . Solution Exercise 2: For the example in (a) (i), the set $B = \{b\}$ . For example (ii) we get $B=\{a,b\}$ . In part (b) we find $B = \{3,4\}$ . In every case, the set $B$ fails to be in the range of the function that we defined. Question(s): Could someone please help me understand what I am missing? I don't think I had any trouble with the first exercise, but my answer to the second was different. For (a) (i), I would have thought that $B = \{b,c\}$ . For (a) (ii), I had $B = \{ a,b,c\}$ . For (b), I had $\{ 2,3,4\}$ . I can't really seem to find a pattern, or figure out what I am doing wrong. I thought I might be getting confused with distinctions between elements and ""the sets containing"" elements, but I am not sure. For instance, with (a) (i) is the image $\{ \{ a\}, \{ a,c\} \{ a,b,c\}\}$ ? Is $a$ getting mapped to $a$ or to ""the set containing $a$ "" which is written as $\{ a\}$ ? If it were the latter, I would think $B = \{ a,b,c\}$ instead, but this doesn't seem to make much sense... So, as I said, if someone could help explain it all to me, I would really appreciate it. Thanks! Edit: The solutions in the block-text are not my own, they were those provided by the author...",['elementary-set-theory']
62726,l'Hôpital guidelines,"Suppose we want to evaluate $$\lim_{x \to 0} \; x \log (x)$$ If we write this in the form $x/(1/\log(x))$, then l'Hôpital's rule does not work, but if we write it as $\log(x)/(1/x)$, it does. Is there any sort of general guideline to choosing the numerator and denominator?","['calculus', 'limits']"
62728,What properties are used to assert that there is always a number between two given numbers?,"What properties of ""numbers"" are used to assert that for given numbers $a$ and $b$, $a≠b$, there exists a number $x$ such that $a < x < b$ ? In the texts I've read, this seems to be assumed without explanation in discussions that are otherwise quite careful about such things. For example, in Spivak's Calculus (4E, p. 123) this fact is used to demonstrate that the function $f(x) = x^2$ does not take on its maximum on the interval (0,1) because for any $0 ≤ y < 1$ there is an $x$ such that $y < x < 1$. Up to that point, the only properties of ""numbers"" (whatever they may be) that have been defined are those of an ordered field, and it is not clear to me that this property can be derived from those. I gather this amounts to the ""numbers"" in question having ""dense order"". (Correct me if I'm wrong.) But I'm unclear where that comes from. Also note: up to the point where this question arises, there has been no mention of what ""numbers"" are (i.e., whether they are $\mathbb Q$ or $\mathbb R$), only that they have the properties of an ordered field.",['real-analysis']
62737,A subgroup containing all the squares. Groups of order 8.,I can not solve the following two problems on Group Theory. A subgroup $H$ of a group $G$ has the property that $x^2 \in H$ for every $x\in G$. Prove that $H$ is normal in $G$ and $G/H$ is abelian. Let $G$ be a group of order 8 and $x$ be an element of $G$. Prove that $x^2$ is in the center of $G$.,['group-theory']
62742,Does little Bézout theorem hold for smooth functions?,"As a special case of little Bézout theorem, if we have a polynomail $f(x)$ with $f(0)=0$, then there exists another polynomial $g(x)$ such that $f(x)=xg(x)$. It's easy to see that this fact generalizes to analytic functions because we have Taylor expansion. Now my question is whether little Bézout theorem holds for smooth functions. More precisely, my question is: If $f(x)\in C^{\infty}(\mathbb{R})$ with $f(0)=0$, does there exist $g(x)\in C^{\infty}(\mathbb{R})$ such that $f(x)=xg(x)$? EDIT: As pointed out by Jason, the above question has positive answer and it actually holds in arbitrary dimensions, that is, If $f(x)\in C^{\infty}(\mathbb{R^n})$ with $f(0)=0$, then there exist $g_i(x)\in C^{\infty}(\mathbb{R^n})$ such that $f(x)=\sum_{i=1}^{n} x_ig_i(x)$. Multiplying a cutoff function on both sides, one obtains, If $f(x)\in C^{\infty}_c(\mathbb{R^n})$ with $f(0)=0$, then there exist $g_i(x)\in C^{\infty}_c(\mathbb{R^n})$ such that $f(x)=\sum_{i=1}^{n} x_ig_i(x)$. With a cleverer use of cutoff function, one can also obtain, If $f(x)\in \mathscr{S}(\mathbb{R^n})$ with $f(0)=0$, then there exist $g_i(x)\in \mathscr{S}(\mathbb{R^n})$ such that $f(x)=\sum_{i=1}^{n} x_ig_i(x)$. Here $\mathscr{S}((\mathbb{R^n})$ denotes the Schwartz space.","['calculus', 'smooth-functions', 'analysis']"
62743,Mackey and relatively projective modules,"While reading over Alperin's Local Representation Theory and reminding myself how a module is relatively H -projective iff H contains some vertex of the module, I realized I could not prove a basic lemma about relatively H -projective modules using my current favorite definition. Definition: A G -module U is relatively H -projective if U is a direct summand of $(U_H)^G$. Lemma: If H ≤ K ≤ G and U is a G -module that is relatively H -projective, then U is relatively K -projective. Proof: Use Prop 9.1.2 to change definitions of relatively projective back to the good ole relative homological definition I used to like: H -split implies G -split.  Clearly K -split implies H -split just by restricting the direct sum, but then relatively H -projectivity (Prop 9.1.2 style) gives G -split, but this suffices to show relative K -projectivity (Prop 9.1.2 style).  $\square$ However, when I try to do this with $U|(U_H)^G$ I get confused and can't seem to use Mackey correctly.  In Alperin's proof on page 67 he uses a similar but more convenient definition: that U is a direct summand of an induced H -module.  Assuming my previous question is right, this is exactly the same as a direct summand of a relatively free module.  However, I'm not sure I see how $U|(U_H)^G$ is equivalent to $U|S^G$ for some H -module S .  Presumably this is Frobenius reciprocity, but again something is going wrong when I try to do it.  At any rate, with the ""S"" definition it is just transitivity of induction, so I'd like to understand both.","['finite-groups', 'representation-theory', 'group-theory']"
62758,Jacobian when representing integral of differential form by Riemann integral?,"In Terence Tao's note : If $Ω$ is any open bounded domain in $R^n$ , we then have the identity
  $$\int_Ω f (x)dx_1 ∧ . . . ∧ dx_n = \int_Ω f (x) dx$$ where on the left we have an integral of a differential form (with $Ω$
  viewed as a positively oriented n-dimensional manifold), and on the
  right we have the Riemann or Lebesgue integral of $f$ on $Ω$. From Wikipedia (basically same as in baby Rudin): Let $$\omega=\sum a_{i_1,\dots,i_k}({\mathbf x})\,dx^{i_1} \wedge \cdots
 \wedge dx^{i_k} $$ be a differential form and $S$ a differentiable $k$-manifold over
  which we wish to integrate, where $S$ has the parameterization $$S({\mathbf u})=(x^1({\mathbf u}),\dots,x^n({\mathbf u}))$$ for $u$ in the parameter domain $D$. Then (Rudin 1976) defines the
  integral of the differential form over $S$ as $$\int_S \omega =\int_D \sum a_{i_1,\dots,i_k}(S({\mathbf u}))
 \frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}\,du^1\ldots
 du^k$$ where $$\frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}$$ is the determinant of the Jacobian. I wonder if in the case of Wikipedia, the change of variable can be
eliminated just as in Terence Tao's, for example, \begin{align} \int_S \omega  &=\int_D \sum
a_{i_1,\dots,i_k}(S({\mathbf u})) 
\frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}\,du^1\ldots
du^k \\ &=\int_S \sum a_{i_1,\dots,i_k}(x) \,dx^{i_1}\ldots dx^{i_k}
? \end{align} If not, when can it be? If the manifold $S$ is not a subset of $R^n$, the Jacobian will not make sense. Can $\int_S \omega $
still be represented by Riemann/Lebesgue integral? How is that like if yes? Thanks and regards!","['differential-forms', 'integration', 'differential-geometry']"
62762,the degree of a splitting field of a polynomial,"Let $f(x)\in F[x]$ be a polynomial of degree $n$. Let $K$ be a splitting field of $f(x)$ over $F$. Then [K:F] must divides $n!$. I only know that $[K:F] \le n!$, but how can I show that $[K:F]$ divides $n!$?","['abstract-algebra', 'field-theory']"
62764,Difference between Logarithms of different bases,"Every time i see a logarithmic function and if it so happens that i'am required to take the derivative or the integral of that particular function i get stumped and i tend to avoid that problem. What i'am saying is $$\frac{\mathrm{d} }{\mathrm{d} x}\left ( \log _{10}x \right )$$ and $$\frac{\mathrm{d} }{\mathrm{d} x}\left ( \ln x \right )$$ are the same i.e $$\frac{1}{x}$$ Why is that? Infact they both are different right? One is to the base 10 and the other one is to the base e ,the logarithm with base e is called as the Naperian or natural logarithm and what's the log base 10 called as?unnatural or artificial logarithm?  They are required to have different derivatives right? Is that because every property of logarithms holds good for logs of both the bases? Is there any particular reason for that? These are some of the basics on which i need clarity before i move on with my mathematical studies.I'll be very happy if someone could give me an insight on these aspects.","['logarithms', 'algebra-precalculus', 'intuition', 'learning']"
62773,Brownian motion introduction,"I didn't get any answers to my previous question ; so I am trying a different tack. I am familiar with a first course in probability theory using measure theory, to the extent of proving the Central Limit Theorem. As a next step I would like to know the basics about Brownian motion, for example to understand one-dimensional Brownian motion in $\mathbb R$, and to be able to use the concept of Wiener measure on the path space, not just the definition, but to use it to prove interesting results, such as the Central limit theorem as mentioned in my previous question. So, what is a suitable introductory book to Brownian motion for someone familiar with basics of probability? The reference need not prove the CLT as I had asked earlier; but if it does it will be a nice addition.","['probability-theory', 'stochastic-processes', 'reference-request', 'brownian-motion']"
62776,Differential operator acting on the eigenfunctions of a commuting operator,"I am reading an article at the moment and there is one step that I am having trouble understanding. The article proves that if $P$ and $Q$ are commuting differential operators there is a non-trivial polynomial $f(s,t)$ such that $f(P,Q)=0$. In order to to this it considers the eigenvalue problem $Py=Ey$ for any number $E$. This problem has $n$ ($n$ being the order of $P$) linearly  independent solutions by basic existence and uniqueness theorem. These span a space, $V_E$. The article takes as a basis of this space the solutions $y_i$ with $\frac{d^j y_i}{dx^j}(0)=\delta_{ij}$. If $Q$ commutes with $P$ then $Q$ maps $V_E$ into itself. Now the article claims, and this is the step I do not understand, that the matrix elements will be polynomials in $E$. Anyone who can explain this will get my gratitude. Edit: The article I am reading is ""Methods of algebraic geometry in the theory of non-linear equations"" by Krichever in Russian Math Surveys 32, 1977 . The operators the article studies are ordinary differential operators acting on $C^\infty(\mathbb{R},\mathbb{C})$. Operators are assumed to have constant leading coefficient. (So $P=\sum_{i=0}^n a_i x^i$ where $a_n$ is a non-zero constant.) The theorem is Theorem 2.1 on page 9 of the pdf. It is specifically the second sentence of the proof that I have problems with. I know that there actually is such a polynomial as claimed in the article as I know algebraic proofs of this fact. I am however trying to understand the analytic proof given by Krichever.",['ordinary-differential-equations']
62778,"Does every $\mathbb{R},\mathbb{C}$ vector space have a norm?","Is there a canonical way to define on any vector space over $\mathbb{K}=\mathbb{R},\mathbb{C}$ a norm ?
(Or, if there isn't, can someone give me an example of a vector space over $\mathbb{K}$ that is not normable ?) I have now looked through several books on the subject but nowhere is something like this mentioned and I also wasn't able to find a way to construct such norm (or to find a counterexample).","['topological-vector-spaces', 'normed-spaces', 'functional-analysis']"
62779,Determinant and power series,"Is there something like a power series expansion for a determinant? I mean the following thing: if $k$ is a field (of characteristic zero) and $M$ and $N$ are two square matrices of the same size over $k$, can we then express $\det(M + tN)$ in a nice way as a power series - which should actually be a polynomial - in $t$?","['linear-algebra', 'calculus']"
62780,Example of an infinite dimensional vector space that is not isomorphic to its dual [duplicate],This question already has answers here : Closed 12 years ago . Possible Duplicates: Why are vector spaces not isomorphic to their duals? Dual space question Can someone give an (as easy as possible) example (together with a proof) of an infinite dimensional vector space that is not isomorphic to its dual ?,"['linear-algebra', 'functional-analysis']"
62789,What does 'linear' mean in Linear Algebra?,"Why Linear Algebra named in that way?
Especially, why we call it linear ? What does it mean?","['linear-algebra', 'terminology']"
62820,Metrizable compactifications,"Suppose $X$ is a metric space. When does it have a metrizable compactification? Of course it is enough to discuss complete metric spaces, but separability may not be assumed here. I know that locally compact spaces have one point compactification, however I am not even sure if those are always metrizable. In the separable case I think I can prove it, however these are two extra assumptions.","['general-topology', 'metric-spaces', 'compactness']"
62842,An algorithm for making conditionally convergent series take arbitrary values?,"This thread reminded me of an old unsettled question I have. Given an arbitrary conditionally convergent series $\beta=\sum\limits_{k=1}^\infty a_k$ and a target value $\alpha$, is there an algorithm for finding the permutation of the original series that will make it sum to $\alpha$? Alternatively, if the permutation cannot be explicitly given, is there an algorithm for finding the first few terms of the rearrangement of the series for $\beta$ to make it sum to $\alpha$? So far, what I've seen is a method for rearranging the alternating harmonic series $\log\,2=\sum\limits_{k=1}^\infty \frac{(-1)^k}{k}$ in Stan Wagon's Mathematica in Action . I would like to know if the method there is generalizable to arbitrary conditionally convergent series.","['sequences-and-series', 'algorithms']"
62847,Applications of Compound Poisson Processes,"I'm reading the book Non-Life Insurance Mathematics, an introduction with Stochastic Processes by Thomas Mikosch and I'm interested in applications of the Cramer-Lundberg Process to concrete examples in insurance.
I tried unsuccessfully to search such examples on the Internet. Could someone suggest to me a paper or a book where I can find something? Thanks!","['stochastic-processes', 'probability-theory', 'finance', 'poisson-process', 'probability']"
62852,"In set theory, how are real numbers represented as sets?","In set theory, if natural numbers are represented by nested sets that include the empty set, how are the rest of the real numbers represented as sets? Thanks for the answers. Several answers basically said for irrational numbers that 
A Dedekind cut is a pair of sets of rational numbers $\{L, R\}$. The set of real numbers is defined to be the set of all Dedekind cuts, where a Dedekind cut is a pair of sets of rational numbers $\{L, R\}$ which have no elements in common, and where all the elements of $L$ are less than any element of $R$.  Each Dedekind cut is a real number. This is where I have a problem - surely that can’t be correct. The set $L$ is a set of all rationals, and there must be a rational in the set $L$ that is greater than all other rationals in that set, even if we have no method of determining it. And similarly, there must be a rational in the set $R$ that is less than all other rationals in that set, even if we have no method of determining it. If every irrational number has a corresponding set $L$, then each irrational number has some such corresponding largest element of that set $L$, and then each irrational number has some corresponding rational number. And that would mean that the irrational numbers are countable. So, with Dedekind cuts,  the only conclusion is that there must be irrational numbers $x$ which are either greater or lesser than some irrational cut $y$ of the rationals, and between $x$ and $y$ there is no rational number.  But that is impossible, so that the Dedekind cuts cannot be the correct representation of the real numbers. Surely the problem with Dedekind cuts is in using sets of rationals that include all rationals up to a certain rational. But there is an alternative method of representing irrationals can be defined in terms of infinite sets of rational numbers. For example, in binary notation, the non-integer part of $\pi$ is $.00100100\ 00111111\ 01101010\ 10001$. You define a set by: if the nth digit is a $1$, then  the natural number $n$ is in the set. And then we have that, for the real numbers between $0$ and $1$, that the set of real numbers is simply the set of all subsets of natural numbers. Each subset corresponds to some real number between $0$ and $1$. And in this way, all real numbers can be considered to be some set based only on nested sets of the empty set. But I still haven’t got a satisfactory answer for how negative numbers can be represented in terms only of sets containing the empty set. Any ideas?",['elementary-set-theory']
62856,Does every Noetherian domain have finitely many height 1 prime ideals?,"Let $A$ be a Noetherian domain. Is the set $\{P\subset A \mid P \mbox{ prime ideal, } \dim A_P=1\}$ always finite? I can prove for $f \neq 0, f\in A$, the set $\{P\subset A \mid \dim A_P=1, f\in P\}$ is finite (by using the primary decomposition of $\sqrt{(f)}$). The above statement is just the case when $f=0$.","['commutative-algebra', 'algebraic-geometry']"
62878,Proving Irrationality,How is it possible to prove a number is irrational? First part of that question: How it possible to know that a number will go on infinitely? Second part: How is it possible to know that no repetition will occur during the infinite sequence of digits? Any examples of proofs of irrationality?,"['irrational-numbers', 'number-theory']"
62881,"In/out equivalent to left/right ""chirality""","Apologies if this is off-topic, but we're having a problem over on English Language with this question , and I thought you guys might be able to help. Basically it's a matter of topology. We know the word chirality , for distinguishing between two things that are either identical in all respects, or differ only in their left/righthandedness. Is it meaningful in mathematics/theoretical physics to distinguish between ""inside-outness"" and ""outside-outness"" in the same way? If so, is there a word analogous to chirality to convey that distinction? I ask here because I know there is debate about the ""shape"" of the space-time continuum (which I don't fully understand), so it seems at least possible to me that some hypothetical frameworks which are mathematically describable might actually be verbalised using a word such as we seek.","['general-topology', 'intuition', 'low-dimensional-topology', 'terminology']"
62882,Is it always possible to simply expand a simple 2D polygon with any point?,"Given a simple 2D polygon P = ( M1 .. Mn ) and a point M, is it always possible to construct a new simple polygon P' by ""adding"" M to P as a new vertex? If so, is this always possible without altering the order of P's vertices? I think that the answer to those 2 questions is yes, but I tried to prove it, and failed. My approach was to try to define some kind of distance between M and each of P's side, whereby the ""closest"" such side would be the one to break to insert M as a new vertex. Obviously, the usual orthogonal distance from a point to a line doesn't work. The larger context is a drawing program I am writing where I allow the user to add vertices to her polygons, but where I strive to keep the polygons simple. (simple polygon: a polygon where no two sides cross). PS: English is a foreign language to me, especially when talking maths. I apologize if my question comes across as awkwardly worded.","['general-topology', 'geometry', 'computational-geometry']"
62904,Differentiability of $f(x)$ and continuity of $f'(x)$: same thing or different?,"If a function $f(x)$ is differentiable $f'(a+)=f'(a-)$ at any point $a$ , so does it mean necessarily that $f'(x)$ is continuous at that point. Also vice versa.. if $f'(x)$ is continuous at any point, does it mean $f(x)$ is differentiable at that point?
which of above two conclusion is valid ? My main confusion is about following question - $$
f(x)= 
\left\{ \begin{array}{lr} 
     x^2 \sin\left(\frac{1}{x}\right) & x>0 \\ 
     0 & x=0 \\
     x^2 \sin\left(\frac{1}{x}\right) & x < 0
    \end{array} \right.
$$
Here function is differentiable at $x=0$, but $f'(x)$ is not continuous at $x=0$ ...","['calculus', 'derivatives']"
62908,How can an ordered pair be expressed as a set?,"My book says 
\begin{equation}
(a,b)=\{\{a\},\{a,b\}\}
\end{equation} I have been staring at this for a bit and it doesn't make sense to me. I have read several others posts on this, but none made any sense to me. For example, Definition of an Ordered Pair Based on how my ignorant brain is viewing this, I don't see why the definition could not be. \begin{equation}
(a,b)=\{\{a\},\{b\},\{a,b\}\}
\end{equation} aka the power set. What is the significance of the {a} in that definition? Please keep things simple if possible. Normally definitions have a valid and clear reason for being defined that way. Clarification First, I understand what an ordered pair is. I just don't see how the set notation says that. Second, 
\begin{equation}
(a,b) = \{\{a\},\{a,b\}\}=\{\{a,b\},\{a\}\}
\end{equation}
Sets don't preserve order, but ordered pairs do. How does the third part of the equality apply to the definition? Third, another issue with the notation that I have starts with the Product Property of Sets \begin{equation}
\text{Let $X$ and $Y$ be sets} :\ X=\{a,b,c\}\text{ and }Y=\{a,d,e\}.
\end{equation}
\begin{equation}
\text{Then }X \times Y = \{(a,a),(a,d),(a,e),(b,a),(b,d),(b,e),\dots,(c,e)\}
\end{equation}
If we look at the first ordered pair and our given definition we have \begin{equation}
(a,a)=\{\{a\},\{a,a\}\}
\end{equation} How can this be so, you can't have duplicates in sets? I guess what I am looking for in an answer, is not a proof or a definition of ordered pairs, but rather something like, ""This notation says what it says because..."". Except for the second to last point I get the terminology, I just don't get the connection between the two different uses of notation.","['elementary-set-theory', 'definition']"
62916,How to show that $\lim\limits_{x \to \infty} f'(x) = 0$ implies $\lim\limits_{x \to \infty} \frac{f(x)}{x} = 0$?,"I was trying to work out a problem I found online. Here is the problem statement: Let $f(x)$ be continuously differentiable on $(0, \infty)$ and suppose $\lim\limits_{x \to \infty} f'(x) = 0$. Prove that $\lim\limits_{x \to \infty} \frac{f(x)}{x} = 0$. (source: http://www.math.vt.edu/people/plinnell/Vtregional/E79/index.html ) The first idea that came to my mind was to show that for all $\epsilon > 0$, we have $|f(x)| < \epsilon|x|$ for sufficiently large $x$. (And I believe I could do this using the fact that $f'(x) \to 0$ as $x \to \infty$.) However, I was wondering if there was a different (and nicer or cleverer) way. Here's an idea I had in mind: If $f$ is bounded, then $\frac{f(x)}{x}$ clearly goes to zero. If $\lim\limits_{x \to \infty} f(x)$ is either $+\infty$ or $-\infty$, then we can apply l'Hôpital's rule (to get $\lim\limits_{x \to \infty} \frac{f(x)}{x} = \lim\limits_{x \to \infty} \frac{f'(x)}{1} = 0$). However, I'm not sure what I could do in the remaining case (when $f$ is unbounded but oscillates like crazy). Is there a way to finish the proof from here? Also, are there other ways of proving the given statement?","['calculus', 'limits']"
62936,Transforming $2D$ outline into $3D$ plane,"I am writing a program where I would like to allow the user to draw 4 connecting lines, such as: And convert this shape into a 3D plane. Is this possible? Is there an existing algorithm to do so? If not, any idea of the steps I should be taking? Things we can assume: the camera is at $0,0,0$, facing $[0,0,-1]$. The plane we create will be centered at $0$ on the $z$-axis. Ideally I'd like the result to be in the form of a set of rotate, scale, translate vectors for a rectangle centered at $[0,0,0]$ of size $[1,1]$. Please let me know if you need any more information. I don't really know where to start on this... (I'm not sure if this question would be more suitable for stackoverflow or gamedev. If so, please feel free to move it. However the question is mainly math related so I'm going to try here first.)","['geometry', '3d', 'algorithms', 'projective-geometry']"
62946,A simple question about Galois groups,"When talking about field extensions of degree two I understand the automorphisms in the Galois group intuitively as analogous to complex conjugation. I lose my understanding when going to field extensions generated by cubics. Suppose we have roots $a_1, a_2, a_3$ so that $K=F(a_1, a_2, a_3)$. It's possible for $G(K/F)$ to have order 3 even though there are six possible permutations of these roots. So where did the other 3 go? I see two possibilities: Some permutations of the roots are not automorphisms. This seems unlikely because I think $F(x,y)\cong F(y,x)$ always, correct? Some permutations are equivalent. I don't understand how this could be. Is there a third option I didn't think of? Am I missing the point entirely?","['galois-theory', 'abstract-algebra']"
62947,Is Topology an important class to take before Functional Analysis?,"I am starting a graduate degree in math pretty soon and I am planning to take a course in Functional Analysis and Spectral Theory. Topology is being offered next semester as well but I don't think it is required. Am I doing myself a major disservice if I decide not to take it anyway? Update: As for my background: I have had two extremely challenging upper division Linear Algebra courses, and my Analysis professors covered a lot of material on toplogical and metric spaces, but for example the only stuff I know about homotopy is stuff I have read on my own. Here is the stated content of Functional Analysis: Topologische und metrische Räume, Konvergenz, Kompaktheit,
Separabilität, Vollständigkeit, stetige Funktionen, Lemma von
Arzela-Ascoli, Satz von Baire und das Prinzip der gleichmäßigen
Beschränktheit, normierte Räume, Hilberträume, Satz von Hahn und
Banach, Fortsetzungs- und Trennungssätze, duale Räume, Reflexivität,
Prinzip der offenen Abbildung und Satz vom abgeschlossenen
Graphen, schwache Topologien, Eigenschaften der Lebesgue-Räume,
verschiedene Arten der Konvergenz von Funktionenfolgen, Dualräume
von Funktionenräumen, Spektrum linearer Operatoren, Spektrum und
Resolvente, kompakte Operatoren. And the professor posted the following additional text: Funktionalanalysis ist die Theorie unendlichdimensionaler Vektorräume. Schlagworte aus dem Inhalt: Banachräume, Bairscher Kategoriensatz, Lineare Funktionale und reflexive Räume, Hilberträume, Distributionen, $L^p$- und Sobolevräume, kompakte Opratoren und Fredholmtheorie. Here is the same for Topology: Grundkonzepte der allgemeinen Topologie (metrische Räume,
Konvergenz, topologische Räume, stetige Abbildungen, Unterräume,
Summe und Produkt, Quotientenräume, Trennungsaxiome,
Zusammenhang, Kompaktheit), Homöomorphie und Homotopie,
simpliziale Komplexe und simpliziale Approximation, Euler-Charakteristik,
Gruppen und Homomorphismen, Präsentation einer Gruppe durch
Erzeuger und Relationen, Fundamentalgruppe, Überlagerungen,
geometrische Anwendungen, Klassifikation der geschlossenen Flächen. There isn't anything posted yet for Spectral Theory. If any of the German needs explaining, let me know, but most of the words are pretty similar to their English equivalents.","['general-topology', 'functional-analysis', 'soft-question']"
