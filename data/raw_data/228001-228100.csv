question_id,title,body,tags
4716166,Distribution of midpoints in a unit disk,"I'm trying to find a probability distribution $m(r,\theta)$ defined over a unit disk which represents the probability of a point being the midpoint of two randomly chosen points in said disk. I think that I'm pretty close to the answer, but I'm off by a factor of 16 and I don't understand why. Given that the distribution of points is uniform, i.e. $f(r,\theta) = \frac{1}{\pi}$ , my reasoning is as follows: The first and second points chosen are $P_{1}$ and $P_{2}$ respectively. If we fix the first point chosen inside the disk, the set of points which are possible midpoints for $P_{1}P_{2}$ form a disk of radius $\frac{1}{2}$ . (Edit: see the figure below for an illustration) Since for each possible $P_{1}$ there is a unique circle of size $\frac{\pi}{4}$ generated representing all the possible midpoints where $P_{1}$ is one of the points, then $m(r,\theta)$ should be proportional to the total ""height"" of all the unique circles that overlap onto the point $(r,\theta)$ , if we imagine each of the radius- $\frac{1}{2}$ circles as having some infinitesimal ""height"". I found the ""height"" of the overlapping circles to be $2(\frac{\arccos{r}}{4}-\frac{r}{2}\sqrt{\frac{1}{4}-\frac{r^{2}}{4}}) = \frac{1}{2}(\arccos{r}-r\sqrt{1-r^{2}})$ . This is the area of overlap between two circles of size $\frac{\pi}{4}$ , reason being that since the center of the radius- $\frac{1}{2}$ disks we formed in step 2 will fall within a radius- $\frac{1}{2}$ disk that is concentric to the unit disk, then the set of radius- $\frac{1}{2}$ disks which do not overlap onto $(r,\theta)$ must be more than a distance of $\frac{1}{2}$ from this point. Hence, the set of radius- $\frac{1}{2}$ disks which do form the ""height"" at point $(r,\theta)$ will have centers within a distance of $\frac{1}{2}$ from the point, and this is the leaf-shaped area between two circles - essentially the expression above. I'm not sure whether this is the correct way to be thinking about the ""height"" at the point - or if ""height"" is even the right way to think about it - so I would appreciate if anyone can point out a more rigorous direction. Assuming step 3 is correct, then because $f(r,\theta) = \frac{1}{\pi}$ , then since we are choosing 2 points, we scale step 3 by $\frac{1}{\pi^{2}}$ . However, if we take this as $m(r,\theta)$ , then $\int_{0}^{1}\int_{0}^{2\pi}m(r,\theta)r d\theta dr = \frac{1}{16}$ . I'm not very well versed in geomtery and probability, so there is definitely something wrong with my logic. Can anyone point me to where the missing factor of 16 comes from, or whether my entire chain of logic is incorrect? Figure for step 1:
We just need to show that the boundary of the set of possible midpoints forms a circle. Consider the diameter that goes through $P_{1}$ and the center of the circle. If $P_{2}$ is on either $D_{1}$ or $D_{2}$ , then the midpoint will be at $M_{1}$ or $M_{2}$ respectively. Consider if $P_{2}$ is anywhere else on the larger circle, let's say $A$ (any point on the circle will form the boundary case), then its midpoint we call $X$ . $M_{1}P_{1} = \frac{1}{2}D_{1}P_{1}, XP_{1} = \frac{1}{2}AP_{1}$ and $\angle{M_{1}P_{1}X} = \angle{D_{1}P_{1}A}$ , so $M_{1}P_{1}X$ and $D_{1}P_{1}A$ are similar triangles by a factor of $\frac{1}{2}$ . A similar argument can be applied for $D_{2}$ and $M_{2}$ . Hence we have that $D_{1}D_{2}A$ is similar to $M_{1}M_{2}X$ by a factor of $\frac{1}{2}$ . Since $D_{1}D_{2}A$ is a right triangle, so is $M_{1}M_{2}X$ , and as A varies, X will trace out a circle of radius $\frac{1}{2}$ . P.S. I am quite sure that other than the factor of 16, everything else should be correct, because this is part of a larger problem that I am solving, which I have shown to be correct assuming that the factor of 16 is there.","['integration', 'geometry', 'probability']"
4716184,"Show $\bigcup\limits_{n\mid n\geq N}A_{n,m}=\left\{\sup\limits_{n\mid n\geq N}\left|\frac{S_n(\omega)}{n}-p\right|\geq\frac{1}{m}\right\}$","Let be $m,n\in\mathbb{N}$ , $p\in(0,1)$ , $S_n$ is a binomially distributed random variable and $
\begin{align*}
&A_{n,m}:=\left\{\omega\in\Omega\mid \left|\frac{S_n(\omega)}{n}-p\right|\geq \frac{1}{m}\right\}.
\end{align*}
$ Here, $\Omega=\{0,1\}^{\mathbb{N}}$ and we can assume that there exists a probability space $(\Omega,\mathcal{F},P)$ such that $A_{n,m}\in \mathcal{F}$ . Show that $
\begin{align*}
\bigcup\limits_{n\mid n\geq N}A_{n,m}=\left\{\omega\in\Omega\mid\sup\limits_{n\mid n\geq N}\left|\frac{S_n(\omega)}{n}-p\right|\geq\frac{1}{m} \right\}.
\end{align*}
$ The relation $\subset$ is not a problem but I am not sure why $\supset$ holds. I tried to prove it with a contraposition $(\lnot B\implies \lnot A)\iff (A\implies B)$ but it gets me nowhere: We choose an $\omega\in\Omega$ with $\sup\limits_{n\mid n\geq N}\left|\frac{S_n(\omega)}{n}-p\right|\geq\frac{1}{m}$ and fix it. If we assume that there exists no $n\geq N$ such that $\left|\frac{S_n(\omega)}{n}-p\right|\geq \frac{1}{m}$ , then there must be a $n\geq N$ with $\left|\frac{S_n(\omega)}{n}-p\right|< \frac{1}{m}$ . But this doesn't lead to a contradiction... Any suggestions? Am I missing someting?","['random-variables', 'supremum-and-infimum', 'probability-theory', 'real-analysis']"
4716219,A recurrence Relations problem that I found in a manga,"So this question is from the manga series, “Assassination Classroom”. The Japanese Roughly above given on the cyborg translates to : “Find the general solution for a[n] as defined in following recurrence-relation sequence.” The recurrence relation sequence in this scan looks something is shown at the bottom of that cyborg Here’s a drawing of mine trying to depict said recurrence relation clearly. I’m not sure if something like that would count as a recurrence relation or if the vertical “=“ signs are actually quotations (“ “) Anyway, a character “solves” the question and has written the solution (or at least, a trick) on a grenade. :
a[n+1]/3[n+1] and a[n]/3[n] So, can somebody help me interpret what the recurrence relation in the question is and what the steps are to finding the solution? Thank you.","['recurrence-relations', 'discrete-mathematics']"
4716269,How to compare the time complexity of $n^n$ and $2^{n\log_2(n^2)}?$,"Here is what I did for this, using $\lim\limits_{x\to\infty}\dfrac{f(x)}{g(x)}$ to get the result. $$2^{n\log_2(n^2)}=2^n\cdot2^{\log_2(n^2)}=2^n\cdot n^2$$ $$\frac{f(x)}{g(x)}=\frac{n^n}{2^n\cdot n^2}=\frac{n^{n-2}}{2^n}$$ then I stuck here, how should I compare $n^{n-2}$ and $2^n\;?$","['limits', 'derivatives']"
4716303,Closed form for $\int_0^1 t^n \log(t^4-t^2+1) dt$,"I want to evaluate the following integral: $$I(n)=\int_0^1 t^n \log(t^4-t^2+1) dt$$ The motivation is that, for odd values of $n$ , Wolfram suggests beautiful closed forms, but I can't see the pattern. For even values of $n$ it does find closed forms, but not always. Therefore I want to see if there is a general closed form for the general case, that could explain this even-odd disparity. By integrating by parts, I got the following integral: $$I(n)=-\frac{1}{n+1}\int_0^1\frac{t^{n+1}(4t^3-2t)}{t^4-t^2+1}dt$$ From here, doing partial fractions with the four roots of the denominator, $+e^{i\frac{\pi}{6}}$ , $-e^{i\frac{\pi}{6}}$ , $+e^{-i\frac{\pi}{6}}$ , $-e^{-i\frac{\pi}{6}}$ , we get four integrals of the form $$\int_0^1\frac{t^{n+1}(4t^3-2t)}{t+a}dt$$ But from here? How to proceed? Any help would be appreciated.","['integration', 'calculus', 'definite-integrals']"
4716356,Evaluate $\int_{-\pi/2}^{\pi/2}\frac{\arctan(\sin^2(x))}{\sin^2(x)}dx$,"As per the title the integral, $$\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}\frac{\arctan \left(\sin^2(x) \right)}{\sin^2(x)} \,dx$$ I tried Feynman’s integral trick as that seemed like the obvious step to me, but after differentiating and what seemed like a fairly obvious substitution, I got an integral that had a seemingly not trivially factorable $4$ th-degree polynomial in the denominator. Can anyone provide a solution, process, or hints as to what I need to do to take down this monster? This is not for a class but for my mathematical endeavors.","['integration', 'calculus', 'definite-integrals', 'trigonometric-integrals']"
4716366,Antidifference of alternating sequence for $\sum_{k=1}^{n-2} [(-k + (-1)^k)^2 - 3]$,"I'd like to find a closed-form formula for $$\sum_{k=1}^{n-2} [(-k + (-1)^k)^2 - 3]$$ using the indefinite summation method. That would be fine besides this annoying factor $(-1)^k$ for the expanded form of the summands: $k^2 - 2(-1)^kk + 1 - 3$ . I am fine with using antidifferences to $k^1, k^2$ but here I am not sure. Is there some neat way to find the antidifference of this sequence?","['summation', 'summation-by-parts', 'discrete-mathematics']"
4716391,"Links between ""productive"" and ""completely productive"" sets?","In a computability course I met the two following notions : A set $B$ is ""completely productive"" if there exists a total computable function $f$ such that : $\forall x \in \mathbb N \ (f(x) \in \overline B \Leftrightarrow f(x) \in \mathcal W_x)$ . and A set $B$ is ""productive"" if there exists a total computable function $f$ such that : $\forall x \in \mathbb N \ (\mathcal W_x \subseteq B \Rightarrow f(x) \in B\setminus\mathcal W_x)$ . I was wondering what were the links between these two notions ? I noticed that if we consider the complement of the halting set $\mathcal K$ , it was both ""completely productive"" and ""productive"". For instance, is one of the notion stronger than the other one ? Thanks in advance ! Edit : The result of equivalence between these two notions has been proved by Myhill (Rogers, theory of recursive functions and effective computability ) !","['elementary-set-theory', 'computability', 'computer-science']"
4716393,Let $S_n := \sum_{i=0}^{n-1} \frac{1}{(i+1) \left ( 1 +\frac{1}{2} + \cdots + \frac{1}{n-i} \right )}$. Does $(S_n)_{n\ge 1}$ converge?,"We define a sequence $(S_n)_{n\ge 1}$ by $$
S_n := \sum_{i=0}^{n-1} \frac{1}{(i+1) \left ( 1 +\frac{1}{2} + \cdots + \frac{1}{n-i} \right )}.
$$ Clearly, $(S_n)_{n\ge 1}$ does not have a form of a series, so I could not use convergence tests .  Could you elaborate on the convergence of $(S_n)_{n\ge 1}$ ? Thank you so much for your help!","['calculus', 'sequences-and-series', 'real-analysis']"
4716400,Handling the differentiation of piecewise functions,"When I differentiate $\large f(x) = x|x|$ using the product rule i get: $$\large f'(x)=x\frac{d}{dx}|x| + |x|$$ the problem is that the derivative of $\large |x|$ is not defined when $\large x=0$ : $$\large \frac{d}{dx}|x|=\begin{cases}-1,x<0\\1,x>0 \end{cases}$$ so $\large f'(x)$ becomes: $$\large f'(x)=\begin{cases}2x,x>0\\-2x, x<0\end{cases}$$ But in reality $\large f(x)$ is differentiable for $\large x=0$ You can correctly differentiate $\large f(x)$ by ""merging"" first the functions $\large |x|$ and $\large x$ into a single piecewise function: $$\large f(x)=\begin{cases}x^2,x≥0\\-x^2,x<0\end{cases}$$ $$\large f'(x)=\begin{cases}2x,x≥0\\-2x,x<0\end{cases}$$ So, how can I differentiate piecewise functions like this one and always obtain the correct domain for the derivative? Is it enough to ""merge"" the functions and then check if the breakpoints are differentiable by checking if the left and right hand derivatives are the same?","['calculus', 'derivatives']"
4716424,Why does $ x \in (A \cap B)^c \implies x \in A^c \cup B^c $?,"The following is true: $$ \boxed{ x \in (A \cap B)^c \implies x \in A^c \cup B^c }$$ Notation - here $S^c$ is the complement of the set $S$ . Question: Why is this true? I know it is true by constructing a Venn diagram to show that it is. However I would like to see a step-by-step argument based on the fundamental definitions of sets and the union/intersection/complement operators. This question also asks the same question but the comments and answers fail to provide a solution to the specific question of why . Further research: Understanding Analysis, Second Edition, by the well respected Stephen Abbott, has an exercise and an official solution by the author. To quote the step I am not understanding: If $x \in (A \cap B)^c$ then $x \notin (A \cap B)$ . But this implies $x \notin A$ or $x \notin B$ . Why does this imply $x \notin A$ or $x \notin B$ ? This is not obvious to me. Again, to clarify, I can draw Venn diagrams to confirm the truth but I would like to see logical steps based on fundamental definitions or axions if possible. Attempting to think about this in plain English with a real-world example to see if it helps .. doesn't seem to help: If it is not summer and hot, then it is not summer or not hot.",['elementary-set-theory']
4716432,Alternative expression for the pseudo-determinant $\operatorname{Det}(A^T \operatorname{diag}(b) A)$?,"Let $\det(\cdot)$ denote the determinant and let $\operatorname{Det}(\cdot)$ denote the pseudo-determinant, which for any square matrix $A \in \mathbb{R}^{n \times n}$ can be defined as $$
\operatorname{Det}(A) := \lim_{\delta \to 0} \frac{\det(A + \delta I)}{\delta^{n - \operatorname{rank}(A)}}.
$$ Now, let $A \in \mathbb{R}^{k \times n}$ , $b \in \mathbb{R}^k$ be a vector with strictly positive entries, and assume that $k \geq n$ . For the usual determinant, we have the identity $$
\det(A^T \operatorname{diag}(b) \, A) = \det(\operatorname{diag}(b)) \det(A A^T).
$$ In the case that $\ker(A) \neq \{ 0 \}$ , then both sides of the above reduce to 0. Question: is there an analogous way to express the pseudo-determinant $$
\operatorname{Det}(A^T \operatorname{diag}(b) \,A)
$$ as a product of factors involving determinants and/or pseudo-determinants of the matrices involved? It is clear that in general $\operatorname{Det}(A^T \operatorname{diag}(b) \,A) \neq \det(\operatorname{diag}(b)) \operatorname{Det}(A A^T)$ . I have tried manipulating the limit definition of the pseudo-determinant using the SVD of $A$ and the matrix determinant lemma, but I have not managed to get a clean expression out of this. I am beginning to think that there is no simple expression, or at least not one that is cleaner than given here . For example, two exemplars I have computed are: $$
A = \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix}, \quad \operatorname{Det}\left( A^T \operatorname{diag}(b) \, A \right) = 2(b_1 + b_2), \quad \operatorname{Det}\left( A A^T \right) = 4,
$$ and $$
A = \begin{bmatrix} 1 & 0 & -1 \\ -1 & 1 & 0 \\ 0 & -1 & 1  \end{bmatrix}, \quad \operatorname{Det}\left( A^T \operatorname{diag}(b) \, A \right) = 3(b_1 b_2 + b_2 b_3 + b_1 b_3), \quad \operatorname{Det}(A A^T) = 9.
$$","['matrices', 'determinant', 'linear-algebra']"
4716449,How to prove that $\sin(\arctan(x))=\frac{x}{\sqrt{1+x^2}}$,"I want to prove that $\sin(\arctan(x))=\frac{x}{\sqrt{1+x^2}}$ Let $y = \sin(\arctan(x))$ and $z=\arctan(x)$ . Then, $y = \sin(z)$ $$\frac{\sin(z)}{\cos(z)}=\tan(z)= \frac{y}{\pm \sqrt{1-y^2}}$$ $$\iff \tan(\arctan(x))= \frac{y}{\pm \sqrt{1-y^2}} \\ \iff x^2= \frac{y^2}{1-y^2} $$ $$\therefore y=\pm \frac{x}{\sqrt{1+x^2}}$$ However, I cannot get rid of the negative sign.","['algebra-precalculus', 'trigonometry']"
4716546,"Prove that triangle is right if $s=2R+r$, where $R$, $r$, $s$ are its circumradius, inradius, and semiperimeter","Let $R$ and $r$ be circumradius and inradius respectively of a triangle with semiperimeter $s$ . Prove that it is right if $$s=2R+r$$ It is not hard to find $$s = {a\over \sin \alpha} + (s-a)\tan{\alpha \over 2}$$ Labeling $x=\tan{\alpha\over 2}$ we have $$(2s-a)x^2-2sx +a=0 $$ which has solution $x=1$ and $x= \displaystyle{a\over b+c}$ . If $x=1$ we are done else $${a\over b+c} = \tan{\alpha\over 2} = {r\over s-a}\hspace{2cm} (1)$$ We can do the same for other two angles and if some is right then we are done, else we have also $${b\over c+a} = \tan{\beta\over 2} = {r\over s-b}\hspace{2cm} (2)$$ and $${c\over a+b} = \tan{\gamma\over 2} = {r\over s-c}\hspace{2cm} (3)$$ Multiplying all equations (1),(2) and (3) we have $$s(s-a)(s-b)(s-c)abc = r^3s(a+b)(b+c)(c+a)$$ $$S^2abc = r^3s(a+b)(b+c)(c+a)$$ $$sabc = r(a+b)(b+c)(c+a)$$ $$sbc = (a+b)(s-a)(c+a)$$ $$(a+b+c)bc = (a(a+b+c)+bc)(b+c-a)$$ $$ abc+(b+c)bc = a(b^2+c^2+2bc-a^2)+ bc(b+c)-abc$$ $$ 0 = a(b^2+c^2-a^2)$$ and we are done. Is there more nice synthetic solution without trigonometry?","['alternative-proof', 'euclidean-geometry', 'trigonometry', 'geometry']"
4716561,Is self homotopy equivalence close to self homeomorphism?,"It is known that self homotopy equivalence of closed surfaces is homotopic to a self homeomorphism . I wonder whether this statement holds for all closed manifolds. Note that no smoothness of the self homeomorphism is required. I suspect this statement would fail in a low dimension. A potential conterexample is the map $X \times Y \xrightarrow{f \times g} Y \times X \xrightarrow{\sigma} X \times Y$ , where $f: X \rightarrow Y$ and $g: Y \rightarrow X$ are homotopy equivalences between two closed manifolds (e.g. $L(7,1)$ and $L(7,2)$ ), and $\sigma: Y \times X \rightarrow X \times Y$ is the exchange map. Is this example valid? And what is the greatest dimension such that this statement still holds true?","['general-topology', 'homotopy-theory', 'low-dimensional-topology']"
4716591,The area of the circle that is the limit of a sequence of circumscribed regular polygons.,"Let $a_n$ be the sequence of circumscribed regular polygons, such that $a_n$ is the smallest $(n+2)\operatorname{-gon}$ that circumscribes $a_{n-1}$ . For example: $a_1$ is a triangle with side length of 1. $a_2$ is the smallest square that circumscribes $a_1$ . Let $b_n$ be $a_n$ with the added restriction that the polygons share a vertex. Below is the construction of $b_7$ . Note $b_7$ is only the nonagon. Let the sequence of circumscribed polygons and circles be $c_n$ and $c_1 = a_1$ . All 3 sequences monotonically increase $\land \forall n\ \operatorname{area}(a_n) \leq \operatorname{area}(b_n) \leq \operatorname{area}(c_n) \land \lim \limits_{n \to \infty} \operatorname{area}(c_n)$ converges, therefore both $\lim \limits_{n \to \infty} \operatorname{area}(a_n)$ and $\lim \limits_{n \to \infty} \operatorname{area}(b_n)$ also converge. Questions: What does $\lim \limits_{n \to \infty} \operatorname{area}(a_n)$ converge to? What does $\lim \limits_{n \to \infty} \operatorname{area}(b_n)$ converge to? EDIT Jaap Scherphuis has brought to my attention that the construction in the figure contradicts the definition of the sequence. So I changed the question to have 2 parts.","['geometry', 'sequences-and-series']"
4716714,"If every element of $G/H$ has a square root and every element of $H$ has a square root, then every element of $G$ has a square root.","I have tried to prove this statement but cannot. Does it require the group $G$ to be abelian? This assumption is not stated in the text I am reading, but all I can get is that if we consider that $gH = b^2H$ for some $b$ , then $gb^{-2} \in H$ so $gb^{-2} = f^2$ for some $f$ , but it requires the group to be abelian to say $g = (bf)^2$ .","['quotient-group', 'group-theory', 'abstract-algebra']"
4716732,Prime numbers $p$ such that $p-1$ has no small odd factors,"I am interested in a (simple) proof of this result: There exists $\alpha>0$ and infinitely many prime numbers $p$ such that $p-1$ does not have any odd prime factor smaller than $p^\alpha$ . I know that one can do much better by using complicated sieves, such as the Brun-Hooley sieve or the ""lower bound sieve"" as seen in Cojocaru & Murty, chapter 10, for instance, but I am only interested in this weaker form and a simpler proof. I tried using Brun's pure sieve and the Bombieri-Vinogradov theorem but it didn't really work out. If my original question is too complicated, I would also appreciate a simple proof of this (slightly weaker) result: There exists $C$ and infinitely many prime numbers $p$ such that $\omega(p-1)<C$ . Edit: I wish to clarify that I intend to find a proof with a reduced degree of technicality when it comes to the sieving part. I do allow the usage of powerful theorems, such as Bombieri-Vinogradov.","['number-theory', 'prime-numbers', 'sieve-theory']"
4716746,"Why is the compactified $\overline{\mathcal{M}}_{0,5}$ a stack?","I have question related to the Deligne-Mumford compactification of $\mathcal{M}_{0,5}$ in Chapter V of the book ""Counting Surfaces"" by Bertrand Eynard, available for free on http://bertrand.eynard.free.fr/book_chap6.pdf . The same example is also worked out in section 5 (page 81) of his lecture notes on compact Riemann surfaces https://arxiv.org/pdf/1805.06405.pdf . I'm a string theorist who happens to be very interested in the theory of moduli spaces of Riemann surfaces for several reasons but I'm not a Mathematician who received formal Algebraic Geometry education. My question is why \begin{equation}
\overline{\mathcal{M}}_{0,5} \sim \overline{\mathbb{C}} \times \overline{\mathbb{C}} \cup \mathbb{C} \cup \mathbb{C} \cup \mathbb{C}
\end{equation} specifically is a stack? Is it because it's an orbifold (with singular points)? If so what is the finite automorphism group that acts a stabilizer? Or is it because the boundary is a union of different pieces that have different dimensions? Are the two facts related? What makes it a stack specifically? Why is $\overline{\mathcal{M}_{0,4}}$ for example not a stack? In the book and in the notes, Eynard says it's a complex manifold . Is it because after compactification, it simply has the topology of $\mathbb{C}P^1$ ? I'm trying to match the different elements of this example to the formal definition of a stack I usually encounter in terms of groupoids, e.g. here https://stacks.math.columbia.edu/tag/02ZH . In this simple example of $\overline{\mathcal{M}}_{0,5}$ , what is the coarse moduli space, the fibers, a site $\mathcal{C}$ , etc.? I'm trying to use this example to get an intuition into the meaning of an Deligne-Mumford stack. Any guidance would be highly appreciated.","['complex-analysis', 'algebraic-geometry', 'algebraic-topology']"
4716774,"Is there a sequence $(t_n)_{n\ge 0}$ such that $\lim_n t_n = \infty$, $\lim_n \Delta_n = 0$ and $\sup_n S_n < \infty$?","Let $(t_n)_{n\ge 0}$ be a strictly increasing sequence of non-negative real numbers such that $t_0 =0$ . We define induced sequences $(S_n)_{n\ge 1}$ and $(\Delta_n)_{n\ge 1}$ by $$
\begin{align}
S_n &:= \sum_{i=0}^{n-1} \frac{t_{i+1} - t_i}{t_n - t_i}, \\
\Delta_n &:= \sup_{i \in \{ 0, \ldots,n-1\}} \frac{t_{i+1}-t_i}{t_n}.
\end{align}
$$ In this thread, I got that there is a sequence $(t_n)_{n\ge 0}$ such that $\lim_n t_n = \infty$ and $\sup_n S_n < \infty$ . Now I would like to ask if there is a sequence $(t_n)_{n\ge 0}$ such that $\lim_n t_n = \infty$ , $\lim_n \Delta_n = 0$ and $\sup_n S_n < \infty$ . Thank you so much for your elaboration!","['convergence-divergence', 'supremum-and-infimum', 'summation', 'sequences-and-series']"
4716806,Is there any faster way to factor $x^3-3x+2$?,"$$x^3-3x+2$$ $$x^3-3x+x^2+2-x^2$$ $$x^2-3x+2+x^3-x^2$$ $$(x-2)(x-1)+x^2(x-1)$$ $$(x-1)[x^2+x-2]$$ $$(x-1)(x+2)(x-1)$$ Is there a better, faster way to factor this cubic trinomial?","['cubics', 'algebra-precalculus', 'polynomials', 'roots-of-cubics']"
4716835,Asymptotic sum of set of natural numbers with positive natural density,"Let $d(A)$ denote the natural density of $A\subset \mathbb{N}.$ If $0 < \alpha < 1\ $ and $\ d(A) = \alpha,\ $ then is this enough to imply $$ \lim_{ N\to\infty } \left( \frac{ \displaystyle\sum_{n\in A}^{n\leq N} \frac{1}{n} }{ \displaystyle \sum_{n\in \mathbb{N}}^{n\leq N} \frac{1}{n} } \right) \equiv \lim_{ N\to\infty } \left( \frac{ \displaystyle\sum_{n\in A}^{n\leq N} \frac{1}{n} }{ \log(N) } \right) = \alpha\ ? $$ I think it should be ""obviously"" true if, for example, $\ A = \lbrace{ \left\lceil \frac{n}{\alpha} \right\rceil: n\in\mathbb{N} \rbrace},\ $ but to me it is not so obvious for general $A.$ I was hoping to use Stolz–Cesàro, but don't quite see how. Or maybe by looking at lots of intervals like $[N, 1.01N]$ for very large $N,$ but I don't have anything concrete yet. Or maybe there is a counter-example. Edit: maybe the result is (also?) true for $\ \alpha=0\ $ and/or $\ \alpha = 1.$","['divergent-series', 'real-analysis', 'natural-numbers', 'sequences-and-series', 'limits']"
4716844,How to prove $\sum_{k=p}^n (-1)^k\binom{n}{k}\binom{k}{p} = (-1)^p$ by using generating functions,"I am learning about generating functions and I tried to prove some identity using it: $\sum_{k=p}^n (-1)^k\binom{n}{k}\binom{k}{p} = (-1)^p$ for $n=p$ and $=0$ for else. Let $n =p$ , then I don't even need the generating function to see the equality
we have $(-1)^n \binom{n}{n} \binom{n}{n}=(-1)^n$ on the LHs and $(-1)^p=(-1)^n$ on the RHS Let $n \neq p$ The generating function of the LHS would be $(-1)^k\binom{n}{k}\binom{k}{k} + (-1)^{k+1}\binom{n}{k+1}\binom{k+1}{k}x+...+(-1)^n\binom{n}{n}\binom{n}{n}x^{n-1}$ The generating function on the RHS would be $0+0x+0x^2+...$ Here is my first problem, obviously $(-1)^k \binom{n}{k} \neq 0$ so it seems like that I have  misunderstood something.
Could someone please explain where my mistake is.","['summation', 'binomial-coefficients', 'combinatorics', 'discrete-mathematics', 'generating-functions']"
4716856,Evaluate : $¥int_0^{¥frac{¥pi}{2}} ¥frac{¥ln(¥sec ^2 x)¥sec^2x }{(¥sec ^2 x+1)¥tan x}¥mathrm dx$,"I need to evaluate : $$I=¥int_0^{¥frac{¥pi}{2}} ¥frac{¥ln(¥sec ^2 x)¥sec^2x ¥mathrm dx}{(¥sec ^2 x+1)¥tan x}$$ By substituting $x¥to ¥frac{¥pi}{2} - x$ , I get : $$I =¥int_0^{¥frac{¥pi}{2}} ¥frac{¥ln(¥csc^2 x)¥csc^2x ¥mathrm dx}{(¥csc ^2 x+1)¥cot x}$$ But I do not know how to proceed with this. I also tried the substitution $¥tan x = u$ which transform $I$ to : $$I = ¥int_0^¥infty ¥frac{¥ln(u^2 +1)¥mathrm du}{u^3+ 2u}$$ But still I cannot proceed further from here because I have never solved such type of integrals with the limited techniques I know.","['integration', 'improper-integrals', 'definite-integrals', 'analysis', 'real-analysis']"
4716864,Closed form for a look-alike Fibonacci sequence,"I’m trying to get the closed form for the following sequence: $x_1=1$ , $x_2=x$ \begin{align*}
x_n=x_{n-2}+x^{n-1} \quad\text{if } n\geq3.
\end{align*} After some calculations the only thing I get is: \begin{align*}
x_n=\sum_{k=0}^{\frac{n-1}{2}} x^{2k} \quad\text{if $n$ is odd,}
\end{align*} and \begin{align*}
x_n=\sum_{k=0}^{\frac{n}{2}} x^{2k+1} \quad\text{if $n$ is even.}
\end{align*} But I'd like to get a closed form that doesn’t depend on the parity of $n$ . Note that in the summation form, there is a problem when it is the empty sum, since by ""convention"" it is zero.
Is there a way to get $1$ or $x$ with an empty sum or another way I could fix it?","['fibonacci-numbers', 'closed-form', 'sequences-and-series']"
4716899,How is $\sin(w_0x)+a\sin(w_1x)\cos(w_0x)=\sqrt{1+(a\sin(w_1x))^2}\sin(w_0x+\arctan(a\sin(w_1x)))$,"This comes from telecomunications, Armstrongs modulator. This $$\sin\left(w_{0}x\right)+a\sin\left(w_{1}x\right)\cos\left(w_{0}x\right)$$ is equal to $$\sqrt{1+\left(a\sin\left(w_{1}x\right)\right)^{2}}\sin\left(w_{0}x+\arctan\left(a\sin\left(w_{1}x\right)\right)\right)$$ I plotted them in desmos and they indeed are equal.","['algebra-precalculus', 'trigonometry']"
4716942,"Evaluating $\int_{-\infty}^{\infty}\frac{\arctan(\sin^2(x))}{x^2}\,dx$. My answer: $\pi\sqrt{2(\sqrt{2}-1)}$","I think I have evaluated the following integral to be: $$I=\int_{-\infty}^{\infty}\frac{\arctan(\sin^2(x))}{x^2}\,dx=\pi\sqrt{2(\sqrt{2}-1)}
$$ I want to know if my answer is correct and if not was my method wrong? Here is what I did. I considered rewriting the integral over the whole real line as a sum of integrals that together span the real line. More specifically I did. $$I= \int_{-\infty}^{\infty}\frac{\arctan(\sin^2(x))}{x^2}\,dx=\sum_{n\in\mathbb{Z}}\int_{(2n-1)\frac{\pi}{2}}^{(2n+1)\frac{\pi}{2}}\frac{\arctan(\sin^2(x))}{x^2}\,dx
$$ Then, considering we converge over this interval we make the substitution $x\longrightarrow{x+n\pi}$ Which yields: $$I=\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}}\arctan(\sin^2(x))\sum_{n\in\mathbb{Z}}\frac{1}{(x+n\pi)^2}\,dx
$$ And since $$\cot(x)=\sum_{n\in\mathbb{Z}}\frac{1}{x+n\pi}$$ It follows that $$\csc^2(x)=\sum_{n\in\mathbb{Z}}\frac{1}{(x+n\pi)^2}$$ So we finally get that $$I=2\int_{0}^{\frac{\pi}{2}}\frac{\arctan(\sin^2(x))}{\sin^2(x)}\,dx=\pi\sqrt{2(\sqrt{2}-1)}
$$ Any thoughts?","['integration', 'calculus', 'definite-integrals']"
4716991,Number of parallelograms in a hexagon of equilateral triangles,"The figure shows a regular hexagon divided into 24 congruent equilateral triangles.  How many parallelograms are there in the figure? How would you solve this problem? Is there a generalisation for larger hexagons? My attempt: I counted 87 parallelograms. My method was to count the number of parallelograms in one orientation and then multiply this answer by three. The image below is meant to illustrate the three orientations (red, green and blue). The number on each vertex is the number of blue parallelograms such that the vertex is at the top left. $87 = 3 (1+2+3+4+2+3+4+3+4+3)$ This method seems difficult to generalise and I was hoping to see some other solutions. (I am also not certain the answer is correct) Reference: This question is an investigation that appears on page 3 of the solutions to the 2022 UKMT senior challenge solutions","['contest-math', 'combinatorics']"
4717022,Evaluating gamma functions.,"I am a bit lost on Gamma functions and would like to have the following evaluation from a textbook explained to me: $\frac{\Gamma(k+1/2)}{\sqrt{\pi}} = \frac{\Gamma(k+\frac{1}{2})}{\Gamma(\frac{1}{2})} = (k-\frac{1}{2})(k-\frac{3}{2})...\frac{1}{2} = \frac{1}{2^k}(2k-1)!! = \frac{(2k)!}{4^k*k!}$ The first two equalities I understand, but when it comes to evaluating the factorials I'm not sure, since I assume that $\Gamma(1/2)$ is the irrational constant $sqrt(\pi)$ and can't really be neatly factored out.","['probability-distributions', 'analysis', 'real-analysis', 'gamma-function', 'probability']"
4717047,Find the number of subsets of n chairs in a circle containing at least three adjacent chairs,"Find the number of subsets of $n$ chairs in a circle containing at least three adjacent chairs. I know that the answer for $n=10$ is $581$ , and the solution is here for instance. I'm not sure if it's possible to derive a recurrence relation for this problem, but if it is, it would be very useful for the general case. In the case of 10 chairs, there are only two disjoint groups of four chairs, where in each group the first chair is not in the subset and the next three are in the subset, while for the general case, there could be arbitrarily many such groups. Such groups of four chairs exist iff not all chairs are filled, where a chair is filled if it's in a given subset. It seems that the principle of inclusion and exclusion would be too unwieldy for this problem; one could consider the number of subsets where adjacent chairs appear in groups of 1 or 2 and there is at least one group of 2 and the number of subsets where no chairs are adjacent. Note that the latter value is much easier to find than the former value and the latter value equals $\sum_k {n-k+1\choose k} - {n-k-3\choose k-2},$ where the sum is over nonnnegative integers k using the convention that ${n\choose k}=0$ for $n<k$ . Is there a recurrent relation for the general case?","['contest-math', 'combinatorics', 'dynamic-programming', 'discrete-mathematics', 'recreational-mathematics']"
4717055,Why is $g(A) \cap g(B) \subseteq g(A \cap B)$ not true?,"The following is from Understanding Analysis, Stephen Abbott. Show that, for an arbitrary function $g : \mathbb{R} → \mathbb{R}$ , it is always true
that $$g(A \cap B) \subseteq g(A) \cap g(B)$$ for all sets $A, B
> \subseteq R$ . Question: I want to understand this better by also understanding why the opposite statement is not true: $$g(A) \cap g(B) \subseteq g(A \cap B)$$ My flawed attempt at answering the original question is as follows: let's say $y \in g(A \cap B)$ if $x \in A \cap B$ then both of the following statements must be true: (1) $x \in A$ and (2) $x \in B$ using only the first statement: if $x \in A$ then $y \in g(A)$ using only the second statement: if $x \in B$ then $y \in g(B)$ but since both statements have to be true, we can say $y \in g(A) \cap g(B)$ that is, $g(A \cap B) \subseteq g(A) \cap g(B)$ The reason I believe this is flawed , is because it doesn't allow me to say why the opposite $g(A) \cap g(B) \subseteq g(A \cap B)$ is not true. Exploration I can think of examples to show why the opposite is not true, for example: $g(x) = x^2$ and $A=[-2,-1], B=[1,2]$ has $A \cap B = \emptyset$ , but $g(A) = g(B) = [1,4]$ One of the ideas I am trying to explore is which step of the above proof would not work for the opposite: I can ""split the domain"" , a statement about $A \cap B$ into two statements, one about $A$ and one about $B$ . But I can't ""merge the co-domains"" , statements about $g(A)$ and $g(B)$ into a single statement about $A \cap B$ And the reason for this is because the co-domains might not be 1-to-1 unique (injective function?). I would appreciate identifying the flaw in the attempted proof, which will I hope shed light on why the opposite statement is not true.",['elementary-set-theory']
4717075,Why are we confident in the ability of ZFC to formalise mathematics if very few proofs are actually converted into ZFC?,"$\mathsf{ZFC}$ is often introduced in logic textbooks as a first-order theory with equality and a single non-logical symbol $\in$ . However, even stating the axioms of $\mathsf{ZFC}$ in this language is a cumbersome task: for instance, while the axiom of choice is often written as $$
\forall X \left( \varnothing \notin X \implies \exists f \colon X \rightarrow \bigcup X \quad \forall a \in X \, ( f(a) \in a ) \right)
$$ this uses the symbols $\varnothing$ , $\bigcup$ , and function notation, and the ""official"" statement of the axiom of choice is a much longer string of symbols. It seems that even statements which feel utterly trivial take many lines to be proven; for instance, in this post, there is a 25 line natural deduction proof that the empty set is unique. As far as I know, very few proofs in ordinary mathematics have actually been converted into formal proofs in $\mathsf{ZFC}$ . For instance, I have never seen a formal proof of the consistency of $\mathsf{PA}$ , even though it is universally agreed by logicians and set theorists that it is a consequence of the $\mathsf{ZFC}$ axioms. So my question is: why are we confident that ""ordinary proofs"" can be converted into formal proofs in $\mathsf{ZFC}$ when so few actually are? In other words, why are we confident that the only thing stopping us from doing this conversion in practice is the sheer tediousness of it all?","['elementary-set-theory', 'philosophy', 'foundations', 'logic']"
4717095,Is is possible to manually solve $10x = 1 - (1+x)^{-12}$ with a simple calculator only?,"Context: although I'm not a mathematician, I'm a curious software engineer which remember high school Math and had my time with calculus at college. I'm trying to manually calculate the amortization rate of a loan (so really none of the fields i now something about). given that I've already deduced the amortization formula , i was given a problem like this: principal = U\$ $1000$ , monthly payment = U\$ $100$ , $12$ monthly payments in total. What is the monthly rate of this loan? I've ended at this: $$10x = 1 - (1+x)^{-12}$$ from all possible roots , there's a single positive real root ~0.0292 that matches the solution (the loan monthly rate should be 2.92% per month, so this is right towards the correct answer). my problem is: if i had to solve this with pen and paper without any computer to aid me (like wolfram alpha or any online solver), how should i manipulate this to get that $0.0292$ root? is this possible?","['algebra-precalculus', 'roots', 'polynomials']"
4717173,"In an order topology, are connected sets convex, and are they intervals?","Problem : $X$ is an ordered set with order topology. Is it true that (1) $A\subseteq X$ is connected $\implies$ $A$ is convex (2) $A\subseteq X$ is connected $\implies$ $A$ is an interval ? (Here interval can be open, closed, half-open half-closed, and boundary can be $(-\infty$ or $+\infty)$ , or has one element since $\{a\}=\{x\ :\ a\le x\le a \}$ ). Motivation : In the order topology of $\mathbb{R}$ (which is the same as usual topology on $\mathbb{R}$ ),  it is easy to see that $A\subseteq \mathbb{R}$ is connected $\iff$ $A$ is convex $\iff$ $A$ is an interval. I want to know if this holds for general order topology. Now I have worked out four arrows: (1) Convex does not imply connectedness. counterexample: the order topology on $\mathbb{Z}_{\ge 0}$ with subset $\{2,3,4\}$ . $\{2,3,4\}=\left(\{2,3,4\}\cap\{x\in\mathbb{Z}_{\ge 0}\ :\ 1< x<3\} \right) \cup\left( \{2,3,4\}\cap\{x\in\mathbb{Z}_{\ge 0}\ :\ x>2\}\right)  $ and is hence not connected. (2) Convex does not imply being an interval, counterexample: the order topology on $\mathbb{Q}$ and the subset $\mathbb{Q}\cap (\alpha, \beta)$ , where $\alpha$ , $\beta\in\mathbb{R}-\mathbb{Q}$ . (3) Being an interval implies convex: obvious. (4) Being interval does not imply connectedness: the counterexample in (1) again works. I did not work out the two arrows in my question.","['general-topology', 'order-topology', 'connectedness']"
4717174,If $⊥$ is an operation on $X$ inversely compatibile at $x$ in $X$ with the order $\mathcal O$ on $X$ then is it directly compatible at $x$ too?,"If $\bot$ is an operation on a set $X$ then we say that it is directly compatibile on the left with an order $\mathcal O$ on $X$ at any $x$ in $X$ if the inequality $$
x_1\prec_\mathcal Ox_2
$$ with $x_1$ and $x_2$ in $X$ implies the inequality $$
x\,\bot\,x_1\prec_\mathcal O x\,\bot\,x_2
$$ whereas we say that it is directly compatibile on the right if the first inequality implies the inequality $$
x_1\,\bot\,x\prec_\mathcal O x_2\,\bot\,x
$$ Moreover, we say that $\bot$ is inversely compatibile on the left with $\mathcal O$ at $x$ if the inequality $$
x\,\bot\,x_1\prec_\mathcal O x\,\bot\,x_2
$$ implies the inequality $$
x_1\prec_\mathcal O x_2
$$ whereas we say that it is inversely compatibile on the right if the inequality $$
x_1\,\bot\,x\prec_\mathcal O x_2\,\bot\,x
$$ implies the inequality $$
x_1\prec_\mathcal O x_2
$$ So, if $\bot$ is directly and inversely compatible on the left or on the right with $\mathcal O$ at $x$ then we say that it is simply compatible at $x$ . Finally, we say that $\bot$ is directly or inversely compatible on the left or on the right with $\mathcal O$ if it is directly or inversely compatibile on the left or on the right at each $x$ in $X$ so that we say simply that $\bot$ is directly or inversely compatible with $\mathcal O$ if it is directly or inversely compatibile with $\mathcal O$ at each $x$ in $X$ . So, I observed that if the inclusion $$
A\subseteq B
$$ with $A$ and $B$ in $\mathscr P(X)$ holds then even the inclusion $$
A\cup X\subseteq B\cup X
$$ holds so that by commutativity of $\cup$ I concluded that $\cup$ on $\mathscr P(X)$ is compatibile with $\subseteq$ at $X$ however it is not inversely compatible since if $B$ is empty and $A$ is $X$ then $A$ is not contained into $B$ if $X$ is not empty. So, I am searching now a counterexample showing that if $\bot$ is inversely compatibile (on the left or on the right) with $\mathcal O$ at any $x$ then it is not necessarily directly compatibile too: so, do this counterexample exists? perhaps inversly compatibile implies directly? Could someone help me, please? N.B. I point out that if $\mathcal O$ is totally then directly and inversely compatibility (on the left or on the right) at any $x$ are equivalent.","['elementary-set-theory', 'order-theory', 'abstract-algebra', 'examples-counterexamples']"
4717214,"Boundedness of $\dfrac{W_2(\mu_1+\varepsilon (\mu_2-\mu_1),\mu_1)}{\varepsilon}$ for 2 -Wasserstein metric","Let $\mathcal{P}_2(\mathbb{R}^{n})$ the space of Borel probability measures of finite second moment in $\mathbb{R}^{n}$ equipped with the $2$ -Wasserstein metric $W_2$ . Let $\mu_1$ , $\mu_2 \in \mathcal{P}_2(\mathbb{R}^{n})$ and $\varepsilon >0$ , can we show $$\dfrac{W_2(\mu_1+\varepsilon (\mu_2-\mu_1),\mu_1)}{\varepsilon}<C(\mu_1,\mu_2)?$$ where $C(\mu_1,\mu_2)$ is some constant depending on $\mu_1$ , $\mu_2$ . I think it is true for $1$ -Wasserstein metric by the Kantorovich duality.","['measure-theory', 'optimal-transport', 'wasserstein', 'probability-theory', 'probability']"
4717221,Is there a geometric picture between Chern class and Chern character?,"I'm new to the characteristics classes. When I learn the definition of Chern class and Chern character, the total Chern class is defined as: $$c(\mathcal F)=\det(I+\frac{i \mathcal F}{2\pi}),$$ where $\mathcal F$ is the curvature matrix or field strength, $i=\sqrt{-1}$ . The total Chern character is defined as: $$\operatorname{ch}(\mathcal F)=\operatorname{tr}(\exp(\frac{i \mathcal F}{2\pi})).$$ You see there is a $\det$ and a trace, which remind me of the famous identity in Lie group: $\det(\exp(A))=\exp(\operatorname{tr}(A))$ , which leads to the fact that there is a $\det(A)=1$ in definition of $\mathrm{SL}$ , so there is a trace=0 in $\mathrm{sl}$ . So my question is, is there also a similar geometric picture between Chern class and Chern character? similar to the relationship between a Lie group and its Lie algebra? I see only their algebraic equivalence in the textbooks I can find.
Thank you.","['characteristic-classes', 'fiber-bundles', 'algebraic-topology', 'differential-geometry']"
4717241,Rademacher complexity of Binary classification,"I am trying to show the inequality below, please note that in this case I am considering the labels to be $Y_i \in \{0, 1\}$ , I state this since I have seen results but for labels that are in $\{0,1\}$ . The inequality  I want to show is: $$ 
\mathbb{E}\max_{f\in F}\left[ \frac{1}{n}\sum_{i=1}^n\epsilon_i\mathbb{1} \{ y_i\neq f(x_i) \} \right]\leq \mathbb{E}\max_{f\in F}\left[ \frac{1}{n}\sum_{i=1}^n\epsilon_i f(x_i) \right]
$$ where $\epsilon_i$ is a Rademacher random variable and the labels $Y_i\in \{ 0,1 \}$ as well as the outputs of $f$ , the $\mathbb{1} \{ y_i\neq f(x_i) \}$ is the indicator function. My attempt of solution: I rewritten the indicator function as follows: $$
\mathbb{1} \{ y_i\neq f(x_i)\}=y_i + f(x_i) - 2y_if(x_i)
$$ And replaced it into the expression that became the following: $$ 
\mathbb{E}\max_{f\in F}\left[\frac{1}{n}\sum_{i=1}^n\epsilon_i\mathbb{1} \{ y_i\neq f(x_i) \} \right]=\mathbb{E}\max_{f\in F}\left[\frac{1}{n}\sum_{i=1}^n\epsilon_i f(x_i)-\frac{1}{n}\sum_{i=1}^n\epsilon_i (2f(x_i)-1)y_i  \right]
$$ I rewritten it this way since the term $(2f(x_i)-1)$ has a similar distribution as the Rademacher random variable, but I don't know how to continue or if this approach is correct, thanks for any help.","['machine-learning', 'statistics', 'rademacher-distribution']"
4717363,How did this gradient get derived?,I am reading Pattern Recognition and Machine Learning by Bishop and equation 6.2 for gradient of regularized least squares is $$J(w) = \frac{1}{2}\sum^{N}_{n=1}\{\mathbf{w^T}\phi(\mathbf{x_{n}})-t_{n}\}^2+\frac{\lambda}{2}\mathbf{w^Tw}$$ then in the next step it says taking the gradient with respect to w leads to: $$w = -\frac{1}{\lambda}\sum_{n=1}^{N}\{\mathbf{w^T}\phi(\mathbf{x_{n}})\}\phi(\mathbf{x_{n}})$$ but I don't understand where the $-\frac{1}{\lambda}$ is coming from? wouldn't the differential be: $$\lambda\mathbf{w} + \sum_{n=1}^{N}\{\mathbf{w^T}\phi(\mathbf{x_{n}})\}\phi(\mathbf{x_{n}})$$,['derivatives']
4717394,Prove $\sum_{n=0}^\infty(-1)^n \frac{\Gamma\left(\frac{n+2}{2}\right)}{\Gamma\left(\frac{n+3}{2}\right)}=\frac{1}{\sqrt{\pi}}(\pi-2)$,"I am trying to evaluate this sum: $$\sum_{n=0}^\infty(-1)^n \frac{\Gamma\left(\frac{n+2}{2}\right)}{\Gamma\left(\frac{n+3}{2}\right)}$$ Wolfram alpha is not able to get a closed form, but the approximation it gives resembles the value of $$\frac{1}{\sqrt{\pi}}(\pi-2)$$ and this can be proved using an integral and interchanging it with the sum. However, I am looking for a proof that doesn't require the use of integrals , if it exists. By the way, this is just a special case of the most general $$\sum_{n=0}^\infty(-1)^n \frac{\Gamma\left(\frac{n+a+1}{2}\right)}{\Gamma\left(\frac{n+a+2}{2}\right)}=\frac{2^{a-1}}{\sqrt\pi}\frac{a\Gamma^2\left(\frac{a}{2}\right)-2\Gamma^2\left(\frac{a+1}{2}\right)}  {\Gamma(a)}$$ I wasn't able to prove this result, in any way, so If someone knows a proof to this or the previous result I'd like to read it. EDIT: Thank you all for your solutions. Now in order to try to solve the general $a$ sum, consider that it is sufficient to evaluate the following integral: $$\int_0^{\frac{\pi}{2}}\frac{\cos^a(x)}{1+\cos(x)}dx$$ Just expand $\frac{1}{1+\cos(x)}$ as a geometric series and then use Wallis integral to convince yourself of this fact. I didn't include this fact before because I didn't want solutions that rely on this integral, since it seems much more doable then the sum, but now I feel it can help to get a full proof that otherwise would be very tough. I tried to evaluate the integral and got the infamous series, so if you have any ideas...","['integration', 'definite-integrals', 'gamma-function', 'calculus', 'sequences-and-series']"
4717464,Can I use Frobenius method when there is no regular singular point under the condition?,"Problem is solve the differential equation $$2x^2y''-xy'+(1-x)y=0,~x>0$$ and I've only learned Frobenius method to solve differential equation with this kind of form.
But $$p(x)=2x^2$$ which means when $$x>0$$ there is no regular singular point so I'm not sure if I can apply Frobenius method here. Can I use it?",['ordinary-differential-equations']
4717469,The Sum of Independent Poisson Random Variables is Poisson: Converse,"Suppose we have random variables $X \sim \text{Poisson}(\lambda)$ and $Y \sim \text{Poisson}(\mu)$ such that $X+ Y \sim \text{Poisson}(\lambda + \mu)$ . Must $X$ and $Y$ be independent? Contrasting with the analogous case with normal random variables (where the variances sum up correctly), this is true as long as $X$ and $Y$ are jointly normal. Moreover, a covariance calculation shows that $X$ and $Y$ are uncorrelated, so it would be sufficient to show that uncorrelated Poisson random variables are independent.","['independence', 'probability-theory', 'probability']"
4717580,List of 3 unique triplets from a group of 9 where every row is unique as well.,"Say we have 9 people. Every week, they will form into groups of 3. The condition is that the triplet that is formed must never have been seen together before. So let's say for week 1, we have: ABC, DEF, GHI. That means in the subsequent weeks, ABC cannot appear again. But ABD is fine. And the table goes on until all triplets have been exhausted. I have a solution but it was done by brute force. I was wondering if this has anything to do with Steiner Systems, specifically S(3,3,9) if I am not mistaken. I have read that when t=k, the Steiner System is trivial. Since I am not a mathematician, can someone explain whether the Steiner System is relevant to the above scenario? Feel free to point me towards something else that is more relevant.","['combinatorial-designs', 'combinatorics']"
4717584,How to find the function of a surface,"Let’s say we have $f(x)=\sqrt{x}$ in range $\,x\in[0,5]\,$ and we revolved around the $x$ -axis what would the function $z=z(x,y)$ of this new surface? How can I find this surface? I have the volume of this surface: $$\int_{0}^{5}\pi xdx = V$$ in 2D the rate of change of the area under the curve is $f(x)$ will this be the same in 2D with the volume, how can I find the equation $\,z=z(x,y)\,?$ I was trying: $$A = \int\pi xdx$$ $$\frac{dA}{dx} = \pi x$$","['surfaces', 'multivariable-calculus', 'calculus', 'parametric', 'solid-of-revolution']"
4717608,High school level question of two quadratic equations sharing a common root.,"The quadratic equation is $$
(a^2+b^2)x^2 - 2b(a+c)x + (b^2+c^2) = 0
$$ $a$ , $b$ , and $c$ are non-zero, real and distinct numbers.
This equation has non-zero real roots $(D \geq 0)$ .
One of the roots of the above equation is also the root of which equation from the following: A) $$(b^2-c^2)x^2 + 2a(b-c)x - (a^2) = 0$$ B) $$(b^2+c^2)x^2 - 2a(b+c)x + (a^2) = 0$$ C) $$(a^2)x^2 + a(c-b)x - (bc)=0$$ D) $$(a^2)x^2 - a(b-c)x + (bc)=0$$ Using $D \geq 0$ , I got $b^2=ac$ , and substituting the value of $b^2$ in the original equation, I get : $$ax^2 - 2bx + c = 0$$ How should I proceed further?","['algebra-precalculus', 'polynomials', 'discriminant']"
4717610,Probability density of two random variables using characteristic function,"I've been trying to solve the following question : $X$ and $Y$ are two real random variables with a probability density of : $$f(x,y) = e^{-y} *\mathscr{1}_{0<x<y}(x,y)$$ where $\mathscr{1}$ is the characteristic function. Verify that $f$ is a probability density. Give the marginal probability $f_1$ of $X$ and $f_2$ of $Y$ . Are $X$ and $Y$ independent? Determine $\mathbb P{\left\{\frac{X}{Y}\le z  \mbox{ and } Y \le y \right\}}$ for $z \in [0,1]$ . Give then the law of $\frac{X}{Y}$ . Are the $\frac{X}{Y}$ and $Y$ independent variables? For the first question I tried checking the condition of normalization : $\int_{R^2} f(x,y)dxdy = 1$ so I did : $\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dxdy$ $\int_{0}^{\infty}\int_{x}^{\infty} e^{-y} dydx = \int_{0}^{\infty} e^{-x} dx = 1$ But I'm not sure of this manipulation. For the second question I did : $$f_{1}(x) = \int_{-\infty}^{\infty} f(x,y) dy = \int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dy = \int_{x}^{\infty} e^{-y} dy = e^{-x}$$ $$f_{2}(y) = \int_{-\infty}^{\infty} f(x,y) dx = \int_{-\infty}^{\infty} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dx = \int_{0}^{y} e^{-y} dx = ye^{-y}$$ But I'm also not sure. For the third question I think I should try to check if $f(x,y) = f_1(x)f_2(y)$ but I don't know how to handle out the characteristic function in the equality. For question 4 I tried the following : $P{\left\{\frac{X}{Y}\le z  \mbox{ and } Y \le y \right\}}$ for $z \in [0,1]$ = $P$ { ${\frac{X}{Y}\le z}$ } * $P$ { ${Y\le y}$ } $P$ { ${X{\le}Y}$ } $= \int_{-\infty}^{\infty} \int_{-\infty}^{y} f(x,y) dxdy = \int_{-\infty}^{\infty} \int_{-\infty}^{y} e^{-y} *\mathscr{1}_{0<x<y}(x,y)dxdy = \int_{0}^{\infty} \int_{0}^{y} e^{-y}dxdy = \int_{0}^{\infty}e^{-y} \int_{0}^{y} dxdy = \int_{-\infty}^{\infty}ye^{-y}dy = 1$ and $P$ { ${Y{\le}y}$ } = 1 Thus, the answer is 1*1=1 and the law of the fraction is yexp(-y). For the rest sincerely I have no clue. Thank you for any advice !","['statistics', 'characteristic-functions', 'probability-distributions', 'marginal-probability', 'random-variables']"
4717640,I can't solve this derivative problem which contains $\cos x$ and $\sin x$,"I want to calculate the derivative of the following function $$ y = {(\cos x - 1)}^{\sec x - 1}$$ I searched and found a video on YouTube which started solving this by applying natural logarithm in both sides. $$ \ln (y) = \ln {(\cos x - 1)^{\sec x - 1}}$$ $$\Rightarrow \frac{y'}{y} = (\sec x - 1).[\ln(\cos x - 1)]$$ Here is the part I do not understand. Since we used natural logarithm we must have $$\cos x - 1> 0 \Rightarrow \cos x > 1$$ For logarithm to be well defined, however it is impossible for any x. So, I don't know whether the video from YouTube made a mistake or whether my reasoning has some flaw I can't find. Please help me understand the mistake and calculate the derivative properly!
Thanks in advance!",['derivatives']
4717680,Multivariable calculus texts,"I would like to buy a book to study multivariable calculus. Currently, the texts I have in mind are: Vector Calculus, Linear Algebra, and Differential Forms A Unified Approach by Hubbard & Hubbard Multivariable Calculus with Applications by Lax & Terrell Functions of Several Real Variables by Moskowitz & Paliogiannis I want a book that has a clear expositions of the subjects of multivariable calculus. Also, I would like a book that avoids leaving proofs as excercises to the reader, or at least that does not do it most of the time. If possible, a book that also contains multiple examples/exercises with (fully) detailed explanations/solutions to at least some of the examples/exercises. I do not mind a rigorous approach to the subject as long as the content is explained with detail. Which of the books mentioned above fits best the description? Also, if you have other books in mind, feel free to recommend them as well. Thanks in advance! Note: I have taken two proof-based calculus classes and one proof-based linear algebra class.","['manifolds', 'multivariable-calculus', 'soft-question', 'vector-analysis']"
4717726,"If random variables $X$ and $Y$ are equal in distribution, then there exists a measurable function $f$ such that $X(\omega)=Y(f(\omega))$ a.s.","Let $X$ and $Y$ be two identically distributed random vectors in $\mathbb{R}^{d}$ defined on the same underlying probability space $(\Omega,\mathcal{A},P)$ . Suppose that $P$ is non-atomic. Does there exist a measurable function $f:\Omega\to \Omega$ that is measure-preserving such that $X(\omega) = Y(f(\omega))$ a.s.? Note this is similar to a number of questions that have been asked before (links posted below). However, none of the solutions to these questions have been super clear to me. The general conclusion seems to be ""yes,"" at least if $(\Omega,\mathcal{A},P)$ is a standard probability space. But I am looking for a bit of explanation, and then some solid references that will help me see the result clearly for myself. Let's settle the issue once and for all! Anyone up to the challenge? Some previous posts: Link 1 , Link 2 , Link 3 , Link 4 , Link 5 .","['measure-theory', 'probability-distributions', 'almost-everywhere', 'probability', 'random-variables']"
4717731,Why the following two graphs have the same flow polynomials and the same Tutte Polynomials.,Please consider the following two graphs I am obtaining that the two graphs have the same flow polynomial given by $$\left(\lambda -1\right) \left(\lambda -2\right) \left(\lambda -3\right) \left(\lambda^{5}-15 \lambda^{4}+95 \lambda^{3}-323 \lambda^{2}+602 \lambda -497\right)$$ From other side I am obtaining that the two graphs have the same Tutte polynomial given by My question is: why these two graphs have the same flow polynomial and Tutte polynomial?,"['graph-theory', 'computational-mathematics', 'geometric-topology', 'discrete-mathematics', 'computational-complexity']"
4717737,Can the supremum of an uncountable family of measures be replaced by the supremum over a countable subfamily?,"Consider a measurable space $(X,\mathcal{A})$ . Let $\mathcal{M}$ denote the family of all countably additive measures $\mu\colon \mathcal{A}\to [0,+\infty]$ . This family can be made into a partially ordered set by setting $\mu\leq \nu$ iff $\mu(V)\leq \nu(V)$ for every $V\in \mathcal{A}$ . It can be shown, see for instance https://arxiv.org/pdf/2104.06753v1.pdf , that $\mathcal{M}$ forms a complete lattice, which means that every $M\subseteq \mathcal{M}$ , possibly uncountable, has the lowest upper bound $\bigvee\limits_{\mu\in M}\mu$ , i.e., the lowest measure $\mu_0\in \mathcal{M}$ with the property that $\mu\leq \mu_0$ for each $\mu\in M$ , and the greatest lower bound, which is defined similarly. My questions are as follows: given $M\subseteq \mathcal{M}$ , can I found a countable subfamily $M_0\subseteq M$ such that $\bigvee\limits_{\mu\in M}\mu=\bigvee\limits_{\mu\in M_0}\mu$ ; if not, does this property hold under some additional assumptions on $\mathcal{A}$ , for instance, if $\mathcal{A}$ is countably generated, i.e., there exists a countable family $\mathcal{E}\subseteq \mathcal{A}$ such that $\mathcal{A}=\sigma(\mathcal{E})$ , where the latter denotes the smallest sigma-algebra containing $\mathcal{E}$ . Let me provide some of my thoughts on this and some additional information. First, I give an explicit definition of the supremum of an arbitrary family $M\subseteq \mathcal{M}$ . For every $V\in \mathcal{A}$ , define \begin{equation*}
\mu_0(V)=\sup \sum\limits_{n=1}^{+\infty} \mu_n(V_n),
\end{equation*} where the supremum is taken over all pairs $(\{\mu_n\}_{n\in \mathbb{N}}, \{V_n\}_{n\in \mathbb{N}})$ , where $\{\mu_n\}_{n\in \mathbb{N}}\subseteq M$ and $\{V_n\}_{n\in \mathbb{N}}$ is a partition of $V$ into $\mathcal{A}$ -measurable sets. It turns that thus defined $\mu_0$ lies in $\mathcal{M}$ and is the desired supremum of $M$ . From this definition, it is obvious that for every fixed (!) set $V\in \mathcal{A}$ we can find a countable family $M_0(V)\subseteq M$ such that \begin{equation*}
\mu_0(V)=\bigg(\bigvee\limits_{\mu\in M_0(V)} \mu\bigg)(V_0).
\end{equation*} This observation gave me a hope that the property from my question may hold for countably generated sigma-algebras. The second thing I want to mention is that the desired property holds when restricted to those $M\subseteq \mathcal{M}$ all measures from which are absolutely continuous with respect to some fixed measure. Such a property is discussed in https://mathoverflow.net/questions/316651/uncountable-infimum-of-measurable-functions , at least for subset of Euclidean space equipped with the standard sigma-algebra and measure. As I understand, the same holds in general, so let me give some general details. Let $\lambda\in \mathcal{M}$ , let me also assume that $\mathcal{A}$ is complete with respect to $\lambda$ , let $F$ be a family of $\lambda$ -measurable functions $X\to [0,+\infty]$ . The lowest upper bound of $F$ can be defined as the $\lambda$ -a.e. lowest $\lambda$ -measurable function $f_0\colon X\to [0,+\infty]$ such that $f(x)\leq f_0(x)$ for $\lambda$ -a.e. $x\in X$ . Then, as I believe, it can be shown by the same arguments as in the mentioned discussion that there exists a countable family $F_0\subseteq F$ such that \begin{equation*}
f_0(x)=\sup\limits_{f\in F_0}f(x)
\end{equation*} for $\lambda$ -a.e. $x\in X$ . If this indeed holds, then the desired property also holds in this concrete case. I will be grateful for any help.","['measure-theory', 'supremum-and-infimum', 'measurable-functions', 'lattice-orders']"
4717741,$\cup B$ in Zorn's lemma,"In Zorn's lemma we have if for every chain $B\subseteq A$ , we have $\cup B\in A$ , thereby $A$ contains a maximal element.
My question is that isn't $\cup B$ just equal to the maximal element of $B$ ? For exmaple: $A = \{a,b,c,d\}$ , $B = \{a,b,c\}$ , $a\subseteq b \subseteq c$ so $B$ is a chain in $A$ . Isn't $\cup B$ just equal to $c$ ? And of course $c\in A$ because $B\subseteq A$ . So For every chain in $A$ , its union is in $A$ . What's the point? Where am I wrong?",['elementary-set-theory']
4717783,"Are closure of open subsets of [0, 1] “almost open”?","This might sound a bit weird, but given any open subset $O$ of $[0, 1]$ , is it necessarily true that the closure of $O$ is “almost open” under the Lebesgue measure, in the sense that there exists an open subset $U$ which equals $ \bar{O}$ up to a null set? This holds for all intervals, hence also for all finite unions of intervals. It also holds for open dense sets. I feel like it shouldn’t be true in general but I couldn’t find a counterexample. Any help would be appreciated.","['general-topology', 'lebesgue-measure']"
4717790,How is a complex elliptic curve a torus?,"I have been learning about elliptic curves. In particular, I have been trying to understand the proof that an elliptic curve (let's assume it's nonsingular, if it matters), say $E:y^2=x^3+ax+b=:f(x)$ over $\mathbb C$ is always isomorphic as a topological group to $\mathbb C/\Lambda$ for some lattice $\Lambda$ (that of course depends on the coefficients $a,b$ ). I think that I can follow the argument based on showing that the Weierstrass $\wp$ -function works as such an isomorphism. However, I cannot reconcile this with my mental picture about what an elliptic curve looks like. Just topologically, I don't see how $E(\mathbb C)$ could possibly be homeomorphic to a torus. Let's assume that $f$ has distinct roots $x_1,x_2,x_3$ . Then, for every $x$ in the complex plane except for these three points, there are exactly two corresponding values of $y$ on the elliptic curve due to the fundamental theorem of algebra. Therefore, my naïve mental picture for $E(\mathbb C)$ is that of two infinite planes joined at $3$ points corresponding to the roots of $f$ . Even accounting for the points at infinity, my mental image ends up being something like a sphere ""squashed down"" such that the northern and southern hemispheres touch at three points. What I described doesn't seem like it could be possibly homeomorphic to a torus, although I have to admit I cannot prove this rigorously. What's gone wrong in my logic? Thanks in advance!","['elliptic-curves', 'number-theory', 'topological-groups', 'complex-analysis', 'general-topology']"
4717800,"Diffeomorphisms of $(-1,1)^n$ sending fixed point to origin","Consider $I^n\equiv(-1,1)^n:=\{(x_1,\dots,x_n)\in \mathbb{R}^n: |x_i|<1 \ \text{for each} \ 1\leq i\leq n\}.$ Let's fix a point $a=(a_1,\dots,a_n)\in I^n$ . Question: How to construct a $C^1$ -diffeomorphism $\Phi:I^n\to I^n$ such that $\Phi(a)=\vec{0}$ ? I believe it suffices to construct a diffeomorphism $f:I\to I$ such that $f(a)=0$ , where $a$ is some fixed point in $I$ . I tried to come up with some constructions but they did not work out.
I know usually one needs to show some efforts but in this case I don't have anything to show.","['diffeomorphism', 'smooth-functions', 'smooth-manifolds', 'real-analysis', 'differential-geometry']"
4717819,Is orthogonality between gradient and level curve in 3D preserved when projected to 2D x-y plane?,"let $Z(x,y)$ define a surface in 3D. It can also be written as $f(x, y, z) = Z(x, y) - z = 0$ . Consider a level curve on the surface satisfying $Z(x,y) = c$ . The curve is the intersection of the surface with some horizontal plane at $z = c$ . We can parametrize the curve as $r(t) = (x(t), y(t), z(t))$ with $z(t) = c$ from the level curve constraint. The gradient of the surface $Z$ at a point P is $(\partial Z/ \partial x, \partial Z/ \partial y, -1)$ . The gradient projected to the $x$ - $y$ plane is thus $(\partial Z/ \partial x, \partial Z/ \partial y)$ . Do we always have the projected gradient perpendicular to the level curve (also projected to $x$ - $y$ plane) ( $x(t)$ , $y(t)$ ) at point $P$ ?","['analytic-geometry', 'geometry', 'differential-geometry']"
4717825,A question about trace class operatos and partial isomertry,"I'm a beginner in operator theory and I'm trying to understand just one step in a proof,which claims that if $H$ is a Hilbert space, $A\in B_1(H)$ (that is , $A$ is a trace-class operator), and $U$ is a partial isometry such that $UA=|A|$ , then $A=U^*UA=U^*|A|$ . I have tried to prove the equation "" $A=U^*UA$ "" but all my attempts have failed. For example, I can prove that $U^*U$ is the projection onto the initial sapce. And I have tried to set $z:=U^*UA-A$ and   attempted to prove that $z^*z=0$ . But I still can't prove the equation $A=U^*UA$ . Can anyone help? And sorry for the language barrier.","['operator-theory', 'isometry', 'functional-analysis', 'operator-algebras']"
4717840,"Counterfeit coin, conditional probability","I am doing Problem AT9 [[ Harvard-MIT Math Tournament February 27, 1999 ]] here: https://hmmt-archive.s3.amazonaws.com/tournaments/1999/feb/adv/solutions.pdf As part of his effort to take over the world, Edward starts producing his own currency. As part of an effort to stop Edward, Alex works in the mint and produces 1 counterfeit coin for every 99 real ones. Alex isn’t very good at this, so none of the counterfeit coins are the right weight. Since the mint is not perfect, each coin is weighed before leaving. If the coin is not the right weight, then it is sent to a lab for testing. The scale is accurate 95% of the time, 5% of all the coins minted are sent to the lab, and the lab’s test is accurate 90% of the time. If the lab says a coin is counterfeit, what is the probability that it really is? I'm confused by the part that says: The scale is accurate 95% of the time, 5% of all the coins minted are sent to the lab If the scale is accurate 95% of the time, shouldn't the percentage of coins minted sent to the lab be $$(.01)(.95) + (.99)(.05) = .059?$$ And not 5% as asserted?","['contest-math', 'algebra-precalculus', 'conditional-probability', 'probability']"
4717843,Prime divisors of the conductor of a primitive element for a number field,"Let $L/K$ be an extension of number fields, and $\theta\in \mathcal{O}_L$ a primitive element for $L/K$ , so that $L = K(\theta)$ . The conductor of $(L/K,\theta)$ is the ideal of $\mathcal{O}_L$ : $$\mathfrak{F} := \{\alpha\in\mathcal{O}_L\;|\;\alpha\mathcal{O}_L\subset\mathcal{O}_K[\theta]\}$$ How are the prime divisors of $\mathfrak{F}$ related to the ramified primes? Are they contained in the ramified primes? Are they equal to the ramified primes? Is there an example where the conductor is divisible by a non-ramified prime? I know in the case of conductors of elliptic curves over $\mathbb{Q}$ , the primes dividing the conductor are exactly the primes of bad reduction. Is something like that true here too?","['number-theory', 'algebraic-number-theory']"
4717854,Solving recurrence with 2 variables,"I am about to solve the recurrence $a(n,m)=\frac{1}{2}a(n,m-1)+\frac{1}{2}a(n-1,m)$ with boundary conditions $a(0,m)=(\frac{1}{2})^m, \forall m\in\mathbb N$ and $a(n,0)=(\frac{1}{2})^n, \forall n\in\mathbb N$ where $a:\mathbb N^2 \to \mathbb R$ . My questions are For this specific problem, I found the solution $a(n,m)=(1/2)^{n+m}\binom{n+m}{n}$ using graphics (see my sketch here ). Is there an algebraic way to solve this problem? For ""1D"" linear constant-coefficient difference equation, we know that a geometric sequence with proper base is a fundamental solution to the difference equation. Can we generalise this notion to ""2D difference equations""? Is there a closed-form general solution to the ""2D difference equation"" without boundary condition? ** Side note ** I found this problem as I was analysing a simplified Swiss tournament model. $a(n,m)$ represents the portion of teams which won $n$ games and lost $m$ games after $n+m$ games.","['recurrence-relations', 'discrete-mathematics']"
4717895,How to define this set using Macaulay2,"Context Consider a polynomial in $d$ variables of degree $N>1$ . When $d=1$ , it is a well-established fact that such a polynomial can be expressed as a product of polynomials, each of degree 1. However, for $d>1$ , this is no longer the case. A $d$ -variate polynomial of degree $N$ can be decomposed into a product of irreducible polynomials, with the sum of their degrees equating to $N$ . To elucidate the structure of these irreducible components, we introduce the following notation: A partition of $N$ is denoted by $\lambda = (1^{m_1}, \ldots, \lambda_1^{m_{\lambda_1}})$ , where $m_i$ represents the number of irreducible polynomials of degree $i$ in the decomposition of $P$ . A multipartition of $l(\lambda)$ into $N$ components is denoted by $\mu = (\mu^{(1)}, \ldots, \mu^{(N)})$ , where each component $\mu^{(i)}$ is itself a partition of $m_i$ , representing the multiplicities of the irreducible polynomials of degree $i$ in the decomposition of $P$ . The concatenation of the partition $\lambda$ and its associated multipartition $\mu$ is written as $\lambda_{\mu}$ . Definition We now define the generalized coincident root locus, denoted by $X_{\lambda_\mu}$ , associated with a partition $\lambda$ and a multipartition $\mu$ as follows. For $\lambda \vdash N$ and $\mu \vdash_N l(\lambda)$ with $\mu^{(i)} \vdash m_i(\lambda)$ , $X_{\lambda_\mu}$ is the set of all polynomials that decompose into irreducible components in accordance with $\lambda_\mu$ : $X_{\lambda_\mu}\equiv $ $ \{ P \in \mathbb{C}[x_0,...,x_{d-1}]_N ~|~
P=\prod_{i=1}^{l(\lambda)} \prod_{j=1}^{l(\mu^{(i)})} P_{i,j}^{\mu_{i,j}} \text{, with } P_{\alpha,\beta} \in \mathbb{C}[x_0,...,x_{d-1}]_\alpha,~ \beta \in \mathbb{N}\}$ where the $P_{\alpha,\beta}$ are irreducible and distinct. Challenge The primary objective is to construct the set $X_{\lambda_\mu}$ in Macaulay2, with the aim of determining the ideal $I = I(X_{\lambda_\mu})$ and computing a Gröbner basis for this ideal. Guidance and methodologies for implementing this in Macaulay2 are sought, as I am at the preliminary stage of familiarity with Macaulay2. Nb : Should there be an alternative tool that facilitates a more streamlined approach than Macaulay2, and provided that you are adept at utilizing this alternative for a comprehensive response, I would deem such a response to be acceptable. Example To fix ideas, let the irreducible decomposition of a $d$ -variate polynomial $P$ of degree 12 reads $P=P_{1,1}^2\cdot P_{2,1} \cdot P_{2,2}^2 \cdot P_{4,1}$ , where $P_{i,j}$ denotes the $j$ -th degree $i$ polynomial constituting the irreducible decomposition of $P$ . The associated $\lambda_{\mu}$ reads $(1^2,2^3,4^1)_{((2),(1,2),(1))}$ . Therefore, $P\in X_{\lambda_\mu}$ .","['macaulay2', 'algebraic-geometry']"
4717929,Evaluate $\int_{-1}^{1} \frac{1}{(1+x^4)\sqrt{1-x^2}}dx$ using complex integration,"Evaluate $$I=\int_{-1}^{1} \frac{1}{(1+x^4)\sqrt{1-x^2}}dx$$ by integrating along the following complex contour: When we take $R\rightarrow 1$ and $ε\rightarrow 0$ , the contour integral itself will be $2πi$ times the sum of the 4 residues of the function, which we can get easily enough using L'Hopital's rule, or factorising $1+x^4$ and so on. My real trouble comes when we consider the lower integral along the real line, $$\int_{1}^{-1} \frac{1}{(1+x^4)\sqrt{1-x^2}}=\int_{1}^{-1} \frac{1}{(1+x^4)\sqrt{1-xe^{2πi}}\sqrt{1+xe^{2πi}}}$$ Where I have included $e^{2πi}$ explicitly since it's the lower path. My intuition is telling me that this piece of the contour shouldn't just be the same as the piece above because of this $e^{2πi}$ inside the square root. Furthermore, if it were the exact same then the two pieces would cancel exactly... So how we can we separate out the 'effects' of this $e^{2πi}$ to get this piece in the form of constant * $I$ ?","['complex-analysis', 'contour-integration']"
4717939,Prove that $x^3$ is strictly increasing on the real numbers using inequality properties,"I'm attempting to prove that $x^3$ is strictly increasing on $\mathbb{R}$ , but I'm encountering two issues. Firstly, I'm uncertain about the precise definition of a strictly increasing function. Definition: $f$ is said to be a strictly function on the interval $I$ if, and only if, $$\forall x_1,x_2\in I, x_1<x_2\rightarrow f(x_1)<f(x_2).$$ What is the specific form of argument used in this definition? Why? (I think b is correct) a. $p \wedge (q\rightarrow r)$ b. $(p \wedge q)\rightarrow r$ The second issue I face is determining how to prove the following statement using properties of inequalities. $$\forall a,b\in\mathbb{R},a>b\rightarrow a^3>b^3$$","['proof-explanation', 'functions']"
4717948,Law of iterated logarithm and hitting time distribution,"Let $X_i$ be a collection of independent standard normal variables and $S_n = \sum_1^n X_i$ . The by the law of iterated logarithm $${S_n \over \sqrt{2n \log \log n}} > 0.8$$ infinitely often, where $0.8$ is arbitrary and could be any number less than $1$ . Is anything known about the probability distribution of the smallest $n$ for which the above condition holds? My question is motivated by numerical experiments where even for large $N$ , a large fraction of paths don't meet the above condition for any $n<N$ .",['probability-theory']
4717964,How to deduce this inequality from the assumptions?,"I am referring to this paper , p. 22. On that page, from the inequality $$
\begin{align*}
&\mathbb{H}(f^{n+1})-\mathbb{H}(f^n)+\Delta t\left(\frac{1}{\varepsilon^2}-\eta\bar{m}_2\right)\Vert f^{n+1}-\rho^{n+1}\mathcal{M}\Vert_{2,\gamma}^2+\Delta t\eta\underline{m}_2\Vert\rho^{n+1}\Vert_2^2\\
&\leq\Delta t\eta\left(\sqrt{\overline{m}_4-\underline{m}_2^2}+\frac{C_P\sqrt{\overline{m}_2}}{\varepsilon}\right)\Vert f^{n+1} - \rho^{n+1}\mathcal{M}\Vert_{2,\gamma}\Vert\rho^{n+1}\Vert_2\tag{1}
\end{align*}
$$ the authors conclude that for any $\eta\in (0,\eta_2)$ with $$
\eta_2:=\frac{\underline{m}_2}{(\sqrt{\overline{m}_4-\underline{m}_2^2}+C_P\sqrt{\overline{m}_2})^2+\underline{m}_2\overline{m}_2}\tag{2}
$$ and $\varepsilon\in (0,1)$ one has $$
\mathbb{H}(f^{n+1})-\mathbb{H}(f^n)+\Delta t K(\eta)(\Vert f^{n+1}-\rho^{n+1}\mathcal{M}\Vert_{2,\gamma}^2+\Vert\rho^{n+1}\Vert_2^2)\leq 0\tag{3}
$$ with $$
K(\eta)=\frac{1}{2}\min(1-\eta\overline{m}_2,\eta\underline{m}_2).\tag{4}
$$ Could somebody please explain to me how to deduce $(3)$ ? I am trying for hours, but I simply do not get it. Is there some trick behind it? I guess its a pure algebraic deduction and one does not need to know how all the notations appearing here are actually defined (this is why I omit the various definitions here...). Actually, I have no concrete idea how to start. To shorten the notation a little bit, I set $$
x:=\Vert f^{n+1}-\rho^{n+1}\mathcal{M}\Vert_{2,\gamma},\qquad y:=\Vert\rho^{n+1}\Vert_2.
$$ Since $(1)$ is equivalent to $$\small{
\begin{align*}
&\mathbb{H}(f^{n+1})-\mathbb{H}(f^n)+\Delta t\left(\frac{1}{\varepsilon^2}-\eta\bar{m}_2\right)x^2+\Delta t\eta\underline{m}_2y^2-\Delta t\eta\left(\sqrt{\overline{m}_4-\underline{m}_2^2}+\frac{C_P\sqrt{\overline{m}_2}}{\varepsilon}\right)xy\leq 0
\end{align*}}
$$ I guess that, in order to show $(3)$ , one has to prove that, for $\eta\in (0,\eta_2)$ and $\varepsilon\in (0,1)$ , $$
\begin{align*}
K(\eta)(x^2+y^2)\leq\left(\frac{1}{\varepsilon^2}-\eta\bar{m}_2\right)x^2+\eta\underline{m}_2y^2-\eta\left(\sqrt{\overline{m}_4-\underline{m}_2^2}+\frac{C_P\sqrt{\overline{m}_2}}{\varepsilon}\right)xy
\end{align*}
$$ (I did not manage to continue from here, however. It nearly drives me crazy.)","['algebra-precalculus', 'inequality', 'real-analysis']"
4717999,Show that the probability: $P(A^c \cup C) \geq 7/8$,"Let $A,B,C$ be pairwise independent events with $P(A \cap B) = 0.1$ and $ P(B\cap C)=0.2$ . Show that $P(A^c \cup C) \geq 7/8$ . This is what I could do Since $P(B) \geq 2/10$ and $P(A)P(B)=1/10$ , $P(A) \leq 0.5$ and $1-P(C) \leq 4/5$ so $P(A \cap C^c) \leq 2/5$ i.e $P(A^c \cup C) \geq 3/5$","['probability-theory', 'probability']"
4718103,"Is there a topology which makes $[0,1)$ compact and Hausdorff?","Consider the interval $X= [0,1)$ . Is there a topology which makes the interval Hausdorff and compact? My intuition tells me that such a topology cannot be found. I have attempted to prove that, if $\{a_n\}_n$ is a sequence which approaches $1$ from within the interval, $X\setminus a(\mathbb{N})$ would have to be open under a Hausdorff topology. If that were the case, one may be able to find $W_n$ open which such that $a_k \not \in W_n, \forall k >n$ , and then $\{X\setminus a(\mathbb{N})\} \cup \{a_k\}_{k \in \mathbb{N}}$ would be an open cover for $X$ with no finite subcover, proving that the set cannot be compact. There are many holes in my argument, though. For instance, I have been unable to prove the closedness of $a(\mathbb{N})$ . Am I on the right track? Any help is appreciated.",['general-topology']
4718176,Understanding the precise definition of limit,"I'm attempting to understand the exact definition of a limit, but I'm struggling to do so. For instance, why is it incorrect to say that the limit of x as it approaches 2 is equal to 10? $\lim_{x\rightarrow 2}x=10$ $$\forall\epsilon>0,\exists\delta>0,0<|x-c|<\delta\longrightarrow|f(x)-L|<\epsilon$$ I choose $\delta=100$ . So why the following statement is not correct? $$0<|x-2|<100\longrightarrow|x-10|<\epsilon,\quad\forall \epsilon>0$$","['limits', 'calculus', 'functions', 'solution-verification']"
4718198,Closed forms of the integral $ \int_0^1 \frac{\mathrm{Li}_n(x)}{(1+x)^n} d x $,"(This is related to this question ). How would one find the closed forms the integral $$ \int_0^1 \frac{\mathrm{Li}_n(x)}{(1+x)^n} d x?
 $$ I tried using Nielsen Generalized Polylogarithm as mentioned in the linked post, but it doesn't produce anything. Another approach I tried was IBP, which seemed a bit too tedious. Does anyone have a closed form of this function?
Thank you!","['integration', 'definite-integrals', 'special-functions', 'polylogarithm', 'closed-form']"
4718209,Characteristic function of Dirichlet Process,"Suppose $P \sim \text{DP}(\alpha,G) $ where $G \sim N(0,1)$ is the base measure and $\alpha > 0$ is the concentration parameter. The stick breaking representation says that $P$ can be expressed as \begin{align*} P = \sum_{j=1}^{\infty} W_j \delta_{\theta_j} \; \; \; \; \; \; \; , \; \; \; \; W_j = V_j \prod_{l=1}^{j-1} (1-V_l)    \end{align*} where $\theta_j \stackrel{iid}{\sim} N(0,1) $ and $ V_l \stackrel{iid}{\sim} \text{Beta}(1,\alpha) $ . It follows that the characteristic function of $P$ is given by $$ \varphi_{P}(t) = \sum_{j=1}^{\infty} W_j e^{\mathbf{i}  t \delta_j  } $$ It seems intuitively clear to me that $\left| \varphi_P(t) \right|$ is bounded away from zero (even at large $t$ ) with high probability but I don't know how to make this rigorous. Specifically, how does $$ \mathbb{P}( \left| \varphi_P(t)   \right| \leq \epsilon ) $$ behave as $ |t| \rightarrow \infty $ and $\epsilon \rightarrow 0$ .","['stochastic-processes', 'statistics', 'probability', 'real-analysis']"
4718213,Commutator of two elements in group algebra $\mathbb F_{5}D_{30}.$,"I want to understand how to find the commutator of two elements in the group algebra $\mathbb{F}_{5}D_{30}$ using GAP. Additionally, I would like to determine the nilpotency class of the nilpotent group $1+J(\mathbb{F}_{5}D_{30})$ which is a subgroup of unit group, where $J(\mathbb{F}_{5}D_{30})$ represents the Jacobson radical of the group algebra $\mathbb{F}_{5}D_{30}$ . In this context, $D_{30}=\{{a,b\mid a^{15}=b^2=1, bab=a^{-1}}\}$ denotes the dihedral group of order $30.$ Here, $\mathbb{F}_{5}$ is a field of characteristic $5$ , consisting of $5$ elements. It is already known that $({1+J(\mathbb{F}_{5}D_{30})})^5=1$ since $(J(\mathbb{F}_{5}D_{30}))^5=0$ . The nilpotency class of $1+J(\mathbb{F}_{5}D_{30})$ has been determined to be $4$ through calculations, but I would like to verify this using GAP. How to demonstrate the nilpotency class of the nilpotent group $1+J(\mathbb{F}_{5}D_{30})$ as $4$ , and to compute the commutator $(x,y)=x^{-1}y^{-1}xy$ where $x=a^3$ and $y=1+4b+a^9b$ ? I only know how to define group algebra in GAP. gap> LoadPackage(""laguna"");
true
gap> G:=DihedralGroup(30);;
gap> FG:=GroupRing(GF(5),G);
<algebra-with-one over GF(5), with 3 generators>
gap> IsGroupAlgebra(FG);
true
gap> RadicalOfAlgebra(FG);
<algebra of dimension 24 over GF(5)> I am not familiar with GAP and would appreciate a thorough explanation of the example. If someone explains this example in detail, it will greatly assist me in applying the same methodology to any group algebra. Your assistance is greatly appreciated.  Thank you in advance.","['gap', 'group-theory', 'nilpotent-groups']"
4718241,How can I solve this limit of a function defined in $R^2$?,"I have to find out for which $\alpha>0$ this limit equals to $0$ : $$\lim\limits_{(x, y) \to (0, 0)}\frac{1+\sin(|x|^\alpha y)-\cos(x^2+y^4)}{(x^2+y^4)^{3/2}}$$ I tried to separate it in two parts: $$\lim\limits_{(x, y) \to (0, 0)}\frac{1-\cos(x^2+y^4)}{(x^2+y^4)^{3/2}}+\frac{\sin(|x|^\alpha y)}{(x^2+y^4)^{3/2}}$$ Now the first term doesn't depend on $\alpha$ and it is asymptotic to: $$\frac{1-1+\frac{(x^2+y^4)^2}{2}}{(x^2+y^4)^{3/2}}=\frac{(x^2+y^4)^{1/2}}{2}$$ So this term tends to $0$ when $(x, y)$ tends to $(0, 0)$ . Then I tried to study the other term using the squeeze theorem in this way: $$0\le \left \vert \frac{\sin(|x|^\alpha y)}{(x^2+y^4)^{3/2}} \right\vert \le \left \vert \frac{|x|^\alpha y}{(x^2+(y^2)^2)^{3/2}} \right\vert \le \left \vert \frac{|x|^\alpha y}{(2|x||y|^2)^{3/2}} \right\vert \le \frac{|x|^{\alpha-3/2}}{|y|^2} $$ At this point I thought that if x goes to $0$ faster than y, then the whole thing tends to $0$ : meaning, I set $\alpha - \frac{3}{2} > 2$ and therefore $\alpha > \frac{7}{2}$ . Honestly I see so many possible mistakes in this procedure, but I couldn't find another way to solve this problem, so I'd like to know if this is correct, and if not, how should I have done it?","['limits', 'multivariable-calculus', 'real-analysis']"
4718251,weak convergence equivalence statements,"We define $\mathcal{M}_{F}(X)$ for $X$ metric space to be the set of all finite measures defined on the borel sigma algebra. Problem. Assume $(X,d)$ is a metric space and $\mu_n,\mu \in \mathcal{M}_{F}(X)$ . Then $\mu_n\rightarrow_{w} \mu$ if and only if $\mu(C)\geq \lim_n \sup_n \mu_n(C)$ for any closed set $C$ and $\lim_n \inf \mu_n(X)\geq \mu(X)$ . Forward direction.
Assume $\mu_n$ converges weakly to $\mu$ . Hence for each $n$ , Let $f_n$ be a measurable function such that $0\leq f_n(x)\leq 1$ for all $x$ and $f_n|_{C}=1$ and $\lim_{n\rightarrow \infty}f_n(x)=\chi_{C}(x)$ for all $x\in X$ . Now the result follows from Fatou's lemma and the dominated convergence theorem. The reverse inclusion is also true. Why does the backwards direction follow?","['measure-theory', 'real-analysis']"
4718267,Polynomial Factors of $f(f(x))-x$,"Given a function $f$ , it can be seen that the solutions of the equation $f(x)=x$ also satisfy the equation $f(f(x))=x,$ since $$f(f(x))=f(x)=x.$$ If we choose $f(x)-x$ to be a polynomial with no repeated roots, then this implies that $f(f(x))-x=(f(x)-x)g(x)$ , since $f(f(x))-x=0$ whenever $f(x)-x=0$ . However, after experimenting with several polynomials, this result still seems to hold when $f(x)-x$ has repeated roots. For example, if \begin{align*}f(x)-x&=(x-1)^2=x^2-2x+1\\f(x)&=x^2-x+1,\end{align*} then \begin{align*}f(f(x))-x&=\left(x^2-x+1\right)^2-\left(x^2-x+1\right)+1-x\\&=x^4-2x^3+2x^2-2x+1\\&=\left(x^2-2x+1\right)\left(x^2+1\right)\\&=(f(x)-x)\left(x^2+1\right).\end{align*} Here, $(x-1)^2$ is a factor rather than just $x-1$ . I also tested this with several other polynomials with repeated roots, and the result still seems to hold. Does this result hold in general, and if so, how can one prove it? Edit: Fixed wording in the first sentence (thank you @lulu for pointing it out)","['functions', 'polynomials']"
4718268,Evaluate series: $\sum_{k=1}^\infty (-1)^k\left[ k\ln\left(\frac{k^4+2k^3+k^2}{k^4+2k^3+3k^2+2k+2}\right)+\ln\frac{k^2+2k+1}{k^2+1} \right]$,"The series is $$\sum_{k=1}^\infty (-1)^k\left[ k\ln\left(\frac{k^4+2k^3+k^2}{k^4+2k^3+3k^2+2k+2}\right)+\ln\left(\frac{k^2+2k+1}{k^2+1}\right)  \right] $$ You won't believe it: this has a closed form! It's the beautiful $$4\coth^{-1}(e^\pi)$$ and Wolfram agrees. By the way, I tried to prove it: the arguments of the $\ln$ 's all factor, and with lots of simplifications the summand inside the brackets reduces to $$[\ 2k\ln(k)+2(k+1)\ln(k+1)-(k+1)\ln(k^2+1)-k\ln(k^2+2k+2)\ ] $$ With this new representation and some struggle (it's not difficult, just some algebraic manipulations), I managed to equate the original sum to the sum $$\sum_{k=1}^\infty (-1)^k\left[\ -2k \tanh^{-1}\left(\frac{k+1}{k^2+k+1}\right)- (k+1)\ln\left(\frac{k^2+1}{(k+1)^2}\right) \right] $$ but from here, I couldn't proceed any further. At this point, I even think this made it only worse. In addition, notice that $$4\coth^{-1}(e^\pi)=2\ln\left(\frac{e^\pi+1}{e^\pi-1}\right)=2\ln\left(\coth\left(\frac\pi2\right) \right)$$ which follows just from the definition of inverse $\coth$ , and maybe this is a bit easier to work with. If anyone has any idea on how to attack this monster, or comes up with a full solution, please share, I look forward to read it.","['integration', 'improper-integrals', 'analysis', 'real-analysis', 'sequences-and-series']"
4718277,How to solve $y-y''=x^a$,"I need to solve this differential equation $$y-y''=x^a$$ I am not well-versed in differential equations.
I found the complementary solution first, and that was simple $$y-y''=0$$ $$y_c=C_1\cosh x+C_2\sinh x$$ I could not find the particular solution. I tried to induce a pattern based on specific cases of $a$ $$y_p=\frac{7!}{7!}x^7+\frac{7!}{5!}x^5+\frac{7!}{3!}x^3+\frac{7!}{1!}x, \space a=7$$ $$y_p=\frac{6!}{6!}x^6+\frac{6!}{4!}x^4+\frac{6!}{2!}x^2+\frac{6!}{0!},\space a=6$$ $$y_p=\sum_{n=0}^{⌊a/2⌋}\frac{a!}{(a-2n)!}x^{a-2n}$$ I think this solution works only when $a$ is a natural number. When I plug in $a=1/2$ , I get 0, but WA says the solution requires the incomplete gamma function, so the solution is clearly not a polynomial. How can I solve this differential equation? a = 0.5 general case","['gamma-function', 'ordinary-differential-equations']"
4718301,Analytic Spaces and Formal Duals,"On nLab, the authors characterize an analytic space as locally modeled on formal duals of sub-algebras of power series algebras with desirable convergence properties. I have seen the definition for (complex) analytic spaces, and while I understand the basic construction, I'm having trouble understanding this idea of ""formal duality"" in a more general context. For example, in scheme theory, there is the usual adjunction between $\operatorname{Spec}$ and $\Gamma$ restricting to an equivalence $\mathsf{Aff}\leftrightharpoons \mathsf{CRing}^\text{op}$ . Somewhat similarly, the functor $C^\infty(-):\mathsf{SmoothMfd}\longrightarrow \mathsf{Alg}_\mathbb{R}^\text{op}$ can be shown to be fully faithful, and so restricts to an equivalence into the (full) subcategory of $\mathsf{Alg}_\mathbb{R}^\text{op}$ of objects in the image of $C^\infty(-)$ . On the nLab page about analytic spaces, their hyperlink associated to ""formal duals"" leads to their page on Isbell duality. This leads me to believe (given my limited knowledge of category theory) that the two examples above are specific instantiations of this duality, but I'm having trouble making that connection. Returning to the first paragraph, is there a similar adjunction to $\operatorname{Spec}\dashv \Gamma$ for analytic (or even locally ringed) spaces which restricts to an equivalence of local model spaces? I know this post has around three questions wrapped up in the body; I really appreciate any help or comments! Thank you.","['complex-geometry', 'equivalence-of-categories', 'algebraic-geometry', 'category-theory']"
4718332,Number of Chess Games Possible: Parity Discussion,"Chess is an incredibly intricate game, offering an immense number of moves and combinations. Due to this complexity, determining the precise count of legal chess games poses a significant challenge. As of my knowledge, the total number of possible legal chess games remains unknown due to the vast array of potential moves and positions that can emerge during gameplay. However, I've been pondering an intriguing question: Can we establish whether the total number of legal chess games is odd or even? It's a captivating puzzle that has captured my attention. I've given it considerable thought, but I must admit that I'm still uncertain about the parity of the total number of games. Can anyone direct me how to approach this?","['chessboard', 'puzzle', 'combinatorics']"
4718340,"Finding the minimal value of $A(x) = \left(\sum\limits_{i=1}^n|S_ix - t_i|^p\right)^\frac{1}{p}$ with $t_i,S_i \in \mathbb Q$ and $p > 1$","I’ve been attempting to minimize this function to little avail. $$A(x) = \left(\sum\limits_{i=1}^n|S_ix - t_i|^p\right)^\frac{1}{p}$$ Where $t$ and $S$ are lists of $n$ rational numbers and $p$ is an integer greater than 1. I took the derivative of the function and set it equal to zero, $$\frac{((\sum\limits_{i=1}^n|S_ix - t_i|^p)^{\frac{1}{p}-1})  (\sum\limits_{i=1}^n\frac{S_i|S_ix - t_i|}{S_ix - t_i}^p)}{n^\frac{1}{p}p}=0$$ Solving for $x$ is where I get stuck. We can divide both sides by $n^\frac{1}{p}p$ which eliminates that term, but I’m not sure how to progress further. Perhaps there is a different method of approaching this problem that someone could help me understand. Thanks for any future answers! :)","['maxima-minima', 'summation', 'functions', 'derivatives']"
4718341,"Green's Theorem does not check out, spot the mistake.","We have a square on the plane of sides 2 from (-1,-1) to (1,1), and $P(x,y)=x^2+y^2,Q(x,y)=2x^2y$ . $$
\oint_L (x^2+y^2)dx+2x^2ydy=2\int_{-1}^1(x^2+1)dx+2\int_{-1}^12ydy=\frac{16}{3}+0=\frac{16}{3}
$$ as on the horizontal lines $dy=0$ and $y=\pm1$ and in the direction [1,-1] $dx<0$ , and same reasoning on the verticals. With Green's Theorem the line integral becomes $$
\int_{-1}^1\int_{-1}^1(4xy-2y)dxdy=\int_{-1}^12ydy\int_{-1}^1(2x-1)dx=0\int_{-1}^1(2x-1)dx=0.
$$ I think I made a mistake in the last Green's Theorem calculation, as to another nameless theorem (can't post the proof here as it's 2 pages in my textbook): For the closed line integral inside a simply connected region $S$ $$
\oint_L P(x,y)dx+Q(x,y)dy=0\iff \frac{\partial P}{\partial y} = \frac{\partial Q}{\partial x}\iff 2y=4xy,
$$ which is not the case. But I am not sure where my mistake is, as I verified all conditions and calculations.","['greens-theorem', 'multivariable-calculus']"
4718344,Finding $\operatorname{Aut}(X)$ where $X$ is the Fermat cubic surface in $\mathbb{P}^3$.,"I am trying to understand the automorphism group of the Fermat Cubic surface $$x_0^3 + x_1^3 + x_2^3 + x_3^3 = 0$$ in $\mathbb{P}^3$ to solve Hartshorne's exercise V.4.16. The way I thought to go about this was to find a subgroup, and argue that the order of this subgroup is as large as the whole group to conclude that this subgroup is actually the whole thing. To this end, $\operatorname{Aut}(S)$ has a subgroup isomorphic to $S_4$ obtained by permuting the variables, and in each varable we can act my multiplication by a third root of unity. These will yield $G \subset \operatorname{Aut}(X)$ where this is the subgroup generated by the aforementioned automorphisms. It's not hard to show that $G$ is an extension of $S_4$ and $\mathbb{F}_3^3$ , so $|G| = 648$ . Now to conclude, I would like to show that if $X$ is a cubic surface, then $|\operatorname{Aut}(X)| \leq 648$ . This is where I'm stuck. There should be some way to look at the action of $\operatorname{Aut}(X)$ on the configuration of the $27$ lines but it's not clear to me how to do so, since this configuration is quite complicated, and the whole automorphism group of the configuration is much too large to be useful. (It's $W(E_6)$ which has order $51,840$ .) Thanks!",['algebraic-geometry']
4718383,Interesting combinatorics problem from 1977 All Soviet Union Mathematical Olympiad,"Let $m$ and $n$ be positive integers. Positive integers $x_1,x_2,...,x_n,y_1,y_2,...,y_m$ satisfy the following conditions: $x_1+x_2+...+x_n=y_1+y_2+...+y_m<mn$ . Prove that it is possible to remove some terms from both sides (but not all terms) of the equality, so that the equality is still satisfied. I have tried to write an inductive proof, but it seems to lead nowhere. Even considering some simpler cases, for example, fixing $n=2$ , it is still not obvious why the problem statement is true. On the other hand, the condition $<mn$ would maybe suggest that the solution should involve some clever use of the Pigeonhole principle, for example, if we consider the number of different sums we can get on both sides by removing terms. Again this also seems to fail. For some context, even though this problem originates from a mathematical competition intended for high-school students, this problem was given, a while ago, as an exercise in my college Combinatorics class. Considering that, I am very skeptical of using some standard ""olympiad"" techniques, and just wondering if this could have any connection to partitions or some clever use of generating functions? Link to AOPS thread (which is empty :( ): https://artofproblemsolving.com/community/u492589h1869901p27929397","['contest-math', 'combinatorics']"
4718394,"Uncertain about the statement ""equivalent condition for an isometry of Riemannian manifolds"" in Lee's Intro to Riemannian Manifolds","In Professor Lee's Introduction to Riemannian Manifolds, second edition on page 12,
the first paragraph on Isometries reads Suppose $(M,g)$ and $(\tilde{M},\tilde{g})$ are Riemannian manifolds with or
without boundary. An isometry from $(M,g)$ to $(\tilde{M},\tilde{g})$ is a diffeomorphism $\phi\colon M\to\tilde{M}$ such that $\phi^*\tilde{g}=g$ .
Unwinding the definitions shows that this is equivalent to the requirement that $\phi$ be a smooth bijection and each $d\phi_p\colon T_pM\to T_{\phi(p)}\tilde{M}$ be a linear isometry. Only one part of a proof eludes me. That is, given a smooth bijection $\phi$ such that each $d\phi_p\colon T_pM\to T_{\phi(p)}\tilde{M}$ is a linear isometry, I haven't been able to prove that $\phi^{-1}$ is smooth if $M$ has nonempty boundary. When $M$ has no boundary, I can use his Introduction to Smooth Manifolds, second edition (ISM)
Proposition 4.8(a) and ISM Exercise 4.9 to get that $\phi$ is a local diffeomorphism
and ISM Proposition 4.6(f) to get that $\phi$ is a diffeomorphism. ISM Proposition 4.8(a)
relies on the Inverse Function Theorem for Manifolds (ISM Theorem 4.5) which
Professor Lee warns us ""can fail for a map whose domain has nonempty boundary."" Is a map with invertible differential that maps boundary to boundary a local diffeomorphism? might be part of an answer if I
could prove that $\phi$ mapped the boundary of $M$ into the boundary of $\tilde{M}$ . (I can already prove that it maps the interior of $M$ into the
interior of $\tilde{M}$ using ISM Problem 4-2.) Of course, such a requirement is necessary for $\phi$ to be a diffeomorphism by the
Diffeomorphism Invariance of the Boundary Theorem (ISM Theorem 2.18), but I haven't been able to prove that $\phi$ maps boundary to boundary either. So, how can $\phi^{-1}$ be proven to be smooth, or is the statement in the book incorrect?","['diffeomorphism', 'riemannian-geometry', 'smooth-manifolds', 'isometry', 'differential-geometry']"
4718399,About the bounds of accuracy for $\sum_{r=0}^a\binom{a}{r}\sum_{m=0}^r\sum_{k=0}^m\binom{m}{k}\binom{r}{m}(-1)^{m-k}2^{m-k}\sin(k)=\sin(a)$,"I noticed that the following sine formula: $$\sum_{r=0}^{a} \binom{a}{r} \sum_{m=0}^{r} \sum_{k=0}^{m} \binom{m}{k} \binom{r}{m} (-1)^{m-k} 2^{m-k} \sin(k) = \sin(a)$$ seem to hold for integer values of 'a' but only numerically up to 7. 8 and above, the formula only approximates to sin(a) and the accuracy becomes worse for larger values of 'a' May there be a proper reason why? or might it just be a program error?",['trigonometry']
4718422,"Can ""equipping"" a set with structure be given a precise definition?","An algebraic structure such a group can be formally defined as an ordered pair $(G,\cdot)$ , where $G$ is a set and $\cdot$ is a binary operation on $G$ satisfying various axioms. This is not the only way to define groups: for instance, a group may be defined as an ordered quadruple $(G,\cdot,^{-1},e)$ , where $\cdot$ is a binary operation (on $G$ ), $^{-1}$ is a unary operation, and $e$ is a constant; this definition is more in line with universal algebra. However, my experience is that in practice, algebraists tend not to use either definition in their mental picture of groups. Instead, a group is described more informally as a set ""equipped"", ""endowed"", or ""enriched"" with some extra structure. The same goes for other algebraic structures of any kind. This way of thinking is reflected by how, in practice, algebraic structures are almost always referred to by the name of their underlying set. Usually, the formal way to make sense of this ""equipping"" is just to define algebraic structures as $n$ -tuples with certain properties. But I wonder if there is a way of defining them which feels closer to how they are actually conceived of. In particular, I would like to be able to speak of ""elements of a group/ring/vector space"" directly. In the usual formalism, that phrase has to be interpreted as a shorthand for ""elements of the underlying set of a group/ring/vector space""; can this be avoided?","['foundations', 'definition', 'abstract-algebra']"
4718455,What is the connection between algebraic groups and topoi?,"I have a longstanding interest in topos theory. (See this MSE search of my questions about topos theory .) I am studying for a postgraduate research degree in linear algebraic group theory. Naturally, I wonder what connections there are between the two. A quick Google search produces this page , in which it states In 1973, Grothendieck gave three lectures series at the Department of Mathematics of SUNY at Buffalo, the first on ‘Algebraic Geometry’, the second on ‘The Theory of Algebraic Groups’ and the third one on ‘Topos Theory’. If, my reasoning goes, Grothendieck worked on algebraic groups around the time he worked on topos theory, then perhaps there's a connection between the two! My Question: What, if anything, is the connection between algebraic groups and topoi? Further Context: It has been too long since I sat down & did any topos theory, so please pitch answers at an advanced undergraduate level, if possible. A Small Request: Please let me know where I can find out more about the connection(s), if any exist.","['algebraic-groups', 'category-theory', 'algebraic-geometry', 'group-theory', 'topos-theory']"
4718471,Bijection $S^1\rightarrow S^1$ inducing bijection between collections of open balls of different sizes,"Let $S^1$ be the circle with circumference $1$ . For each $0<r<1$ , let $\mathcal{B}_r$ be the collection of open balls of diameter $r$ in $S^1$ (a.k.a.  open arcs of length $r$ along $S^1$ ). If $r\ne s$ , can there exist a bijection $f: S^1\rightarrow S^1$ which induces a bijection $\mathcal{B}_r \rightarrow \mathcal{B}_s$ (via the canonical map $B\rightarrow f(B)$ for $B\in \mathcal{B}_r$ )? If $r$ and $s$ differ sufficiently, then (assuming $r>s$ ) there exists a subcover of $\mathcal{B}_r$ with fewer elements than any subcover of $\mathcal{B}_s$ , hence the desired bijection cannot exist. For example, if $r={2\over 3}$ , and $s = {1\over 3}$ , then it is possible to cover $S^1$ with two elements of $B_r$ (take, for example, the two arcs of diameter ${2\over 3}$ centered around two antipodal points on $S^1$ ); however, $S^1$ cannot be covered with two elements of $B_s$ since the maximal length of a union of two elements of $B_s$ is ${2\over 3}$ . Any bijection $f$ satisfying the above properties would need to send covers to covers (of the same cardinality), hence in this case no such bijection can exist. But what if $r$ and $s$ do not differ sufficiently? Can such a bijection never exist if $r\ne s$ , or can it exist if $r$ and $s$ are sufficiently close together?","['general-topology', 'circles', 'geometry', 'measure-theory']"
4718521,"Ladders on a rung, $1/2$ chance to go up and $1/2$ chance to go down, with a twist","I am doing this problem here from the HMMT competition: https://hmmt-archive.s3.amazonaws.com/tournaments/1999/feb/oral/solutions.pdf You are somewhere on a ladder with 5 rungs. You have a fair coin and an envelope that contains
either a double-headed coin or a double-tailed coin, each with probability 1/2. Every minute you
flip a coin. If it lands heads you go up a rung, if it lands tails you go down a rung. If you move
up from the top rung you win, if you move down from the bottom rung you lose. You can open
the envelope at any time, but if you do then you must immediately flip that coin once, after which
you can use it or the fair coin whenever you want. What is the best strategy (i.e. on what rung(s)
should you open the envelope)? Here's the solution. I understand everything that follows and had independently come up with the same: First consider the probability of winning if you never open the envelope. Let $q(n)$ be the probability of winning from the nth rung with just the fair coin, then $q(n) = (q(n−1)+q(n+1))/2$ , so it is not hard to calculate that $q(n) = n/6$ . If we open the envelope, then there’s a $1/2$ chance that it is heads and we win, and a $1/2$ chance that it is tails and we end up one rung down with just the fair coin (obviously we keep using the double sided coin iff it is double headed). Let us start by analyzing rung $1$ . If we don’t open the envelope, then we have a $1/2$ chance of losing and a $1/2$ chance of ending up on rung $2$ with the envelope. If we do open the envelope, then we have a $1/2$ chance of losing and a $1/2$ chance of winning, which is a better outcome, so we should open the
envelope on rung $1$ . Next we look at rung $5$ . If we don’t open the envelope, then we have a $1/2$ chance of winning and a $1/2$ chance of moving down to rung $4$ with the envelope. If we do open
the envelope, then we we have a $1/2$ chance of winning and a $1/2$ chance of moving down to rung $4$ without the envelope. Let $p(n)$ be the probability of winning from rung $n$ if we are there with
the envelope still unopened. Then clearly $p(n) \ge q(n)$ for all $n$ if we’re using optimal strategy, so
we should not open the envelope on rung $5$ . Next we look at rung $4$ . If we open the envelope,
then our chance of winning is $1/2 + q(3)/2 = 3/4$ . If we don’t, then our chance of winning is $p(5)/2 + p(3)/2$ . We do know that $p(5) = 1/2 + p(4)/2$ , but this is not enough to tell us what to
do on rung $4$ . Looking at rung $3$ , we can open the envelope for a probability $1/2 + q(2)/2 = 2/3$ of
winning, and we can not open the envelope for a probability $p(4)/2 + p(2)/2$ of winning. On rung $2$ , we can open the envelope for a probability $1/2 + q(1)/2 = 7/12$ of winning, and we can not open
the envelope for a probability $p(3)/2 + p(1)/2 = p(3)/2 + 1/4$ of winning. Now we can use all this information together for the complete answer. However, I don't understand how any of the assertions in the next sentence follow from what's already been quoted. We know $p(2) \ge 7/12$ ,
therefore $p(3)\ge p(4)/2 + 7/24$ , and we know $p(4) \ge p(5)/2 + p(3)/2 \ge
(1/2+p(4)/2)/2 + p(3)/2 \ge (1/2+p(4)/2)/2 + (p(4)/2+7/24)/2$ . I don't even understand how it follows that $p(2) \ge 7/12$ , much less anything that follows. Can anyone help?","['contest-math', 'conditional-probability', 'markov-chains', 'algebra-precalculus', 'probability']"
4718547,Linear Algebra Question On Augmented Matrix,"I read the book Linear Algebra by David Lay and stumbled upon a paragraph on page $40$ that read: If an augmented matrix [A b ] has a pivot position in every row, then the equation Ax = b may or may not be consistent. I can't seem to provide myself with an example for each case, and would appreciate any help. Thanks WY. Note: There is a similar question that has been posted here but it is really not the same as this one.","['matrices', 'linear-algebra']"
4718560,More direct approach to a combinatorial problem,"Suppose we randomly arrange $n$ objects of which $s$ are of silver, $1$ is of gold and the remaining $n-s-1$ are of copper. The question I looked at is: what is the probability that all eventual predecessors of the golden object are of silver? We could rephrase this as: what is the probability that among the eventual predecessors of the golden object are no copper objects. I defined the described event as $E$ and approached the answer by first defining $E_i$ (this for $i=0,1,\dots,s$ ) as the event that the golden object is on spot $i+1$ and its predecessors are all of silver. Then we find: $$P(E_i)=\frac1n\binom{s}i\binom{n-1}i^{-1}=\frac1n\binom{n-1}s^{-1}\binom{n-i-1}{n-s-1}$$ and making use of the hockey-stick identity we arrive at: $$P(E)=\sum_{i=0}^sP(E_i)=\frac1n\binom{n-1}s^{-1}\binom{n}{n-s}=\frac1{n-s}$$ That is a nice result. So nice that IMV it clearly indicates the existence of more direct way to find it. I tried to, but failed. So my question is: Can you provide me a more direct solution? Thank you for taking notice of this and sorry in advance if this appears to be a duplicate question. Edit My original question did not mention the word ""copper"" neither the rephrasing of the question that uses the word ""copper"". In my (narrow) thinking I was purely focused on gold and silver. This fact provided the blind spot that I am now released from. In situations like this a sort of battle takes place within me. I am very eager to find the smart solution myself . I can pose it as a question but my pride first forbids me to do so. After some struggling I set this (stupid) pride aside and decide to show my shortcomings. A healthy process. Thank you all for your answers.","['alternative-proof', 'combinatorics', 'probability']"
4718569,Possible values of c in the polynomial $x^3+ax^2+bx+c$.,"I'm studying for a GRE and this is a question from an old test: Let $p(x)$ be the polynomial $x^3+ax^2+bx+c$ , where $a,b,$ and $c$ are real constants. If $p(-3)=p(2)=0$ and $p'(-3)<0$ , which of the following is a possible value of $c$ ? Of the options given (-27, -18, -6, -3, -0.5), I have already solved the problem to see that -27 is the only possible value given, but my solution is lengthy, to say the least, and this is the GRE, so ideally problems should be solvable in approximately 2.5 minutes. I was wondering if anyone could think of faster ways to see how to solve this problem that avoids the copious amount of arithmetic I sort through to find the answer? Here's my solution: $$p(-3)=-27+9a-3b+c=0=8+4a+2b+c=p(2)$$ and so we may see that $a=b+7$ after several steps of time consuming arithmetic. Then, $$p'(x)=3x^2+2(7+b)x+b$$ $$\Rightarrow p'(-3)=27-6(7+b)+b<0 $$ and so we get that $b>-3$ after several more steps of arithmetic. Now, since $p$ has two real roots in $\mathbb{R}$ , it must split completely in $\mathbb{R}$ , and so $$p(x)=(x+3)(x-2)(x-\alpha)$$ for some $\alpha \in \mathbb{R}$ . Expanding this expression we get, $$x^3+x^2(1-\alpha)+x(-\alpha-6)+6\alpha $$ $$\Rightarrow a=1-\alpha\\ b=-\alpha-6\\c=6\alpha $$ And so, finally, since $b>-3 \Rightarrow \alpha<-3 \Rightarrow c<-18$ . And so we're done. This isn't a particularly challenging problem, in my opinion, but the solution is lengthy even without me including my actual arithmetic. Just writing it out takes longer that 3 minutes, let alone the time built in to actually thinking about the problem/ figuring out where to go next. So, I feel like there must be a simpler way to think about this problem and approach finding a solution, no?","['gre-exam', 'calculus', 'derivatives', 'polynomials']"
4718603,"Cardinality of the set of all bit strings not containing the bit ""0"" (i.e. $11$, $111$ ...)","I need to show the cardinality of $S$ , the set of all bit strings that don't contain the bit $0$ . I came up with a function that maps $\mathbb{N}$ to $S$ in the following way: $f(n) = \sum_{i=0}^{n-1} 10^i$ . I think that this is a valid mapping because each natural number $n$ gets mapped to the string that contains exactly $n$ bits. My question: I am having trouble understanding if this function is bijective. My attempt: Injectivity: Well, I'd need to prove that for $f(a) = f(b) \implies a=b$ $$f(a) = \sum_{i=0}^{a-1} 10^i = .f(b) = \sum_{i=0}^{b-1} 10^i$$ $10^0 + 10^1 + ...+ 10^{a-1} = 10^0 + 10^1 + ... + 10^{b-1}$ I'm stuck here. I don't know if I can cancel out all terms except the $10^{a-1}$ and $10^{b-1}$ (mostly because I can't operate on the presumption that $a=b$ , that's what I need to prove). Surjectivity : I don't know how to prove this mathematically. Can anyone help?","['elementary-set-theory', 'cardinals', 'functions']"
4718680,Minimising time taken for 3 people to walk to the same point,"Suppose there are $3$ people that are positioned in $3$ different places on a flat plane. Assume all 3 people walk at the same speed. The $3$ people begin walking (in a direct path) toward a single point $P$ (which is also positioned on the flat plane), and the last person to get to $P$ takes $T$ seconds to do so. My question is as follows: How can we find the point $P$ such that $T$ is minimised? Let the $3$ people begin at points $(x_1,y_1),(x_2,y_2)$ and $(x_3,y_3)$ : I first assumed that the point $P$ would just be the average of the $3$ points (By average I mean taking the average of all the $x$ coordinates and the average of all the $y$ coordinates), but by fiddling around with desmos I could see that this wouldn't be correct. Perhaps Fermat's point might come into this question? I'm not too sure. I've spent too long on this question and any help would be greatly appreciated (It would also be interesting to see if there are solutions for $n$ points in $2$ D space)","['triangles', 'optimization', 'trigonometry', 'geometry']"
4718707,How to find the maximum value of $x^2-\frac {1}{x^2}$ if the real number $x$ satisfies $x^3-\frac{1}{x^3}=\frac {28}{27}$,"Suppose the real number $x$ satisfies $x^3-\dfrac{1}{x^3}=\dfrac {28}{27}.$ Find the maximum value of $x^2-\dfrac {1}{x^2}.$ A) $\frac{1}{6}\sqrt{37}$ B) $\frac{1}{9}\sqrt{37}$ C) $\frac{1}{3}\sqrt{37}$ D) $\frac{1}{5}\sqrt{37}$ E) $\frac{1}{2}\sqrt{37}$ Attempt. Let $x^3=y$ , so $y-\dfrac {1}{y}=\dfrac {28}{27}$ . Hence $27y^2-28y-27=0$ . The determinant is $D=28^2+4\times27\times 27=3700$ so $y=x^3=\dfrac {14\pm 5\sqrt {37}}{27}$ . But I'm stuck here doing this calculation $x=\sqrt[3]{\dfrac {14\pm 5\sqrt {37}}{27}}.$ How do I progress further?","['contest-math', 'algebra-precalculus', 'radicals', 'nested-radicals']"
4718723,Convexity of $f(\boldsymbol{p}) = \sum_i p_i \log \sum_j p_j \frac{4 a_i a_j}{(a_i + a_j)^2}$,"Question Given that $\boldsymbol{a} > 0$ , how to prove $$f(\boldsymbol{p}) = \sum_i p_i \log \sum_j p_j \frac{4 a_i a_j}{(a_i + a_j)^2}$$ is a convex function of probability distribution $\boldsymbol{p}$ ? Is it possible to generalize from the convexity of the negative entropy $p \log p$ ? Attempts Midpoint convex + continuous => convex: to prove $$f\left(\frac{\boldsymbol{p} + \boldsymbol{q}}{2}\right) \le \frac{f(\boldsymbol{p}) + f(\boldsymbol{q})}{2}$$ It reduces to $$\prod_i \left(\sum_j \frac{p_j+q_j}{2} \frac{4 a_i a_j}{(a_i + a_j)^2}\right)^{p_i+q_i} \le \prod_i \left(\sum_j p_j \frac{4 a_i a_j}{(a_i + a_j)^2}\right)^{p_i} \left(\sum_j q_j \frac{4 a_i a_j}{(a_i + a_j)^2}\right)^{q_i}$$ and the original GM-HM trick for $p \log p$ does not work. It looks very similar to Holder's inequality but I failed to gain more insights... Hessian: the $(m,n)$ entry of Hessian is $$\frac{b_{m,n}}{\sum_j p_j b_{m,j}} + \frac{b_{n,m}}{\sum_j p_j b_{n,j}} - \sum_i p_i \frac{b_{i,m} b_{i,n}}{(\sum_j p_j b_{i,j})^2}$$ where $b_{i,j} = \frac{4 a_i a_j}{(a_i + a_j)^2}$ . Simulation suggests the Hessian is generally positive semidefinite, but finding a proof seems nontrivial. Thank you very much for the attention.","['multivariable-calculus', 'convex-analysis', 'real-analysis']"
4718790,Categorical probability theory: Fritz' diagram categories,"1. Context . In the seventh chapter of his 2019 paper A synthetic approach to categorical probability theory Tobias Fritz introduces certain diagram categories. Supposedly, these allow for a categorical approach to stochastic processes. Fritz illustrates this with an example — which I do not understand. Consider the posetal category $\mathcal{D}=\mathbb{Z}$ , where the objects are the integers and there is a morphism $n\rightarrow m$ if and only if $n\geq m$ . Let $\mathcal{C}=\text{BorelStoch}$ be the category whose objects are standard Borel spaces and whose morphisms are Markov kernels between them. Note that the category $\mathcal{C}$ is a full subcategory of the Markov category $\text{Stoch}$ discussed in Chapter four of Fritz' paper. Next, consider the subcategory $\mathcal{C}_{\text{det}}$ of $\mathcal{C}$ which has the same objects as $\mathcal{C}$ but whose morphisms are the deterministic morphisms. In the case $\mathcal{C}=\text{BorelStoch}$ , the deterministic morphisms can be identified with measurable maps between standard Borel spaces. Denote by $I$ the constant functor $\mathcal{D}\rightarrow \mathcal{C}_{\text{det}}$ that sends every integer to the singleton measurable space. In chapter seven Fritz introduces the full subcategory $\operatorname{Fun}(\mathcal{D},\mathcal{C})$ of the functor category $[\mathcal{D},\mathcal{C}]$ . Its objects are functors $\mathcal{D}\rightarrow \mathcal{C}_{\text{det}}$ . Fritz indicates a correspondence between morphisms $I\rightarrow X$ in this category $\operatorname{Fun}(\mathcal{D},\mathcal{C})$ (i.e. natural transformations) and stochastic processes with indexing set $\mathbb{Z}$ .
He writes: The functors $\mathcal{D}\rightarrow \mathcal{C}_{\text{det}}$ can be identified with infinite diagrams of measurable spaces $$ \ldots \rightarrow X_{n+1}\rightarrow X_n \rightarrow X_{n-1}\rightarrow \ldots$$ where all the maps involved are measurable functions. We think of each component $X_n$ as the space of joint values of a stochastic process over all times $t\leq n$ , where the map $X_{n+1}\rightarrow X_n$ amounts to forgetting the value of the process at time $n+1$ . A morphism $I\rightarrow X$ in $\operatorname{Fun}(\mathcal{D},\mathcal{C})$ then assigns a probability measure to each of the measurable spaces $X_n$ in such a way that the projections $X_{n+1}\rightarrow X_n$ are measure-preserving; thus such a morphism exactly turns $X$ into a stochastic process. 2. Questions . How can a morphism $I\rightarrow X$ in the functor category $\operatorname{Fun}(\mathcal{D},\mathcal{C})$ be seen as a (discrete-time) stochastic process? Fritz spells out what the objects and morphisms in the functor category $\operatorname{Fun}(\mathcal{D},\mathcal{C})$ are in our case. This I understand. However, I fail to see how to relate these structures to stochastic processes. This might be related to the Daniell-Kolmogorov extension theorem — I don't see how, though. Conversely, how does a (discrete-time) stochastic process give rise to a morphism $I\rightarrow X$ in the functor category $\operatorname{Fun}(\mathcal{D},\mathcal{C})$ ? My attempt at an explanation is given below. (In what sense) are these constructions inverses? What is meant by the following sentence? We think of each component $X_n$ as the space of joint values of a stochastic process over all times $t\leq n$ , where the map $X_{n+1}\rightarrow X_n$ amounts to forgetting the value of the process at time $n+1$ . 3. Ideas Let $(Y_i)_{i\in \mathbb{Z}}$ be a stochastic process with sample space $(\Omega, \mathcal{F}, P)$ and state space $(S,\Sigma)$ . For each $n\in \mathbb{Z}$ , define the set $X_n\colon =\{(Y_i(\omega))_{i\leq n}\ \vert \ \omega \in \Omega\}\subset \prod_{i\leq n}S$ and the projection $\pi_n\colon X_n\rightarrow X_{n-1}$ which deletes the $n$ -th component. For each $n\in \mathbb{Z}$ , consider the image $S_n\colon =\operatorname{im}(Y_n)$ . For each $n\in \mathbb{Z}$ , define the subspace $\sigma$ -algebra $\Sigma_n\colon =\{A\cap S_n \ \vert \ A\in \Sigma\}$ . Next, consider a pushforward measure on $(S_n,\Sigma_n)$ , namely $\mu_n(A) \colon = P(\pi_n^{-1}(A))$ for $A \in \Sigma_n$ . For each $n\in \mathbb{Z}$ , we obtain a probability space $(S_n,\Sigma_n,\mu_n)$ . Next, we define a $\sigma$ -algebra $\mathcal{B}$ on the infinite product $\prod_{i\leq n}S_i$ as done here . Then we endow the pair $(\prod_{i\leq n}S_i, \mathcal{B})$ with the probability measure $\prod_{i\leq n}\mu_i$ as (again) defined here . Am I on the right track?","['measure-theory', 'functors', 'category-theory', 'stochastic-processes', 'probability-theory']"
4718816,Number of ways to interleave two strings,"An existing problem goes that:
Suppose we have two finite, ordered sequences x=(x1,…,xm) and y=(y1,…,yn). How many ways can we create a new sequence of length m+n from x and y so that the order of elements is preserved? This new problem is different because we stress that there are elements appearing in both x and y. This differs from all existing problem which are either assume that x and y consist of different types of elements or accept that assumption without claiming it. All answers I find adapt an assumption that x and y have no common elements, which leads to an easy closed form answer C(n+m,n). However, things go messy if existence of common elements is allowed. Consider x=(1,2), y=(1,1). The number of ways would be 3 (1211,1121,1112), which makes the classic combination result fail. I try using DP. Naturally, it goes that dp[i][j]=dp[i][j-1]+dp[i-1][j] when all elements are different. The inclusion-exclusion principle helps a special situation that the two strings (or substrings) are like ****ab and ****cb. We will have dp[i][j]=dp[i][j-1]+dp[i-1][j]-dp[i-1][j-1]. But it still works only on an extremely small subset of all the possible problems. The title of this problem use ""string"" instead of ""array"" to stress the existence of common elements. I want to know that whether there is a P algorithm to solve this problem. Furthermore, you may assume that the set of characters is a limited constant; that means a ""pseudo-P"" algorithm is also good enough to be satisfying. If you are confused about the concept of interleaving two strings, you may check a classic DP problem that requires verifying whether a string can be constructed by interleaving two other given strings.","['computational-mathematics', 'combinatorics', 'computability', 'computer-science']"
4718834,"Showing that in a triangle $ABC$, $\angle ABC = 60°$ , the following intersection points, and points $B$, and $C$ lie on the same circle","The problem: In an acute-angled triangle $ABC$ , point $H$ is the orthocenter , point $O$ is the center of the circumscribed circle , point $J$ is the center of the inscribed circle , $\angle BAC = 60°$ . Prove that points $B, H, O, J, C$ lie on the same circle.* The figure: I didn't know how to even approach this problem, so I used a hint from the textbook, that says the following: Prove that the points $H, O, J$ belong to the points locus, from which the segment $BC$ is seen from an angle of $120°$ . At first I saw that $\angle BOC = 120°$ , since it's a central angle that rests on the same arc as the inscribed $\angle BAC$ of the given circle. After quite some time of looking at the figure, I also saw that $\angle BHC = 120°$ , since it's simply adjacent to the angle that's measure is $60°$ . I got stuck at the point where needs to be proven that $\angle BJC = 120°$ as well. I can't see how to prove that. So I've tried to prove what's initially asked, but at that point I did stuck completely, I don't understand how the given in the textbook hint proves that they are on the same circle. How to prove that ? P.s. Please, note, that this problem is from an 8th grade school textbook, so any angle functions or similar, more advanced tools cannot be used here. The problem itself is on the matter ""Inscribed and central angles"".","['locus', 'triangles', 'circles', 'geometry']"
4718843,Distribution of the square of a random normal variable,"If we have $X \sim N(\mu, \sigma^2)$ , then what distribution does $X^2$ follow? In the case of the standard normal distribution, this is the chi-squared distribution, and in the case of unit variance - the non-central chi-squared distribution. However, is there a particular distribution for the case of zero mean and non-unit variance, or in the general case? Are the PDF and CDF of closed form?","['statistics', 'probability-distributions', 'normal-distribution']"
4718846,Does the weak convergence of probability measures imply some uniform over all sets estimates between these measures and the limit measure?,"Let $X$ be a metric space. If it is necessary, one can assume that it is complete and separable, or even compact. Consider a sequence of Borel probability measures $(\mu_n)$ on $X$ that weakly converges to a Borel probability measure $\mu$ on $X$ . It is well known that there are equivalent characterizations for this convergence, namely, that \begin{equation*}
\limsup\limits_{n\to +\infty} \mu_n(F)\leq \mu(F)
\end{equation*} for every closed set $F\subseteq X$ and that \begin{equation*}
\liminf\limits_{n\to +\infty} \mu_n(G)\geq \mu(G)
\end{equation*} for every open set $G\subseteq X$ . My question, roughly speaking, if these estimates, after passing to a subsequence of $(\mu_n)$ , can be made uniform over all Borel subsets of $X$ ? Let me explain what I mean. Suppose that $\mu$ is fully supported on $X$ , that is, $\mu(G)>0$ for every nonempty open set $G\subseteq X$ , fix $\varepsilon>0$ . Can I find a subsequence $(\mu_{n_k})$ such that for any Borel set $V\subseteq \mathrm{X}$ and any $k\in \mathbb{N}$ one has \begin{equation*}
\mu_{n_k}(V)\leq (1+\varepsilon)\mu(V)?
\end{equation*} If $\mu$ is not fully supported, one can consider arbitrary fully supported probability measure $\nu $ on $X$ and replace $(1+\varepsilon) \mu(V)$ with $\mu(V)+\varepsilon \nu(V)$ in the expression above. Are there some sufficient conditions for this property to hold? Or it fails dramatically? The only thoughts on this I have are as follows. Suppose we are given a countable family $\mathcal{V}$ of closed subsets of $X$ such that $\mu(F)>0$ for each $F\in \mathcal{V}$ . As it seems to me, standard Cantor's diagonal argument and the equivalent characterization of the weak convergence above imply that there is a subsequence $(\mu_{n_k})$ such that the desired property holds for all sets from $\mathcal{V}$ . Explicitly, \begin{equation*}
\mu_{n_k}(F)\leq (1+\varepsilon)\mu(F)
\end{equation*} for every $F\in \mathcal{V}$ and for every $k\in \mathbb{N}$ . Does this imply the inequality for each Borel subset of $X$ , if we take an appropriate family $\mathcal{V}$ , for instance, a generating set for the Borel sigma-algebra on $X$ in the case of its countable generatedness? Or there are some other arguments? Will be greatful for any help!","['measure-theory', 'functional-analysis', 'weak-convergence', 'borel-measures']"
