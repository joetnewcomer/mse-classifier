question_id,title,body,tags
2693807,How to visualize the elements of $\mathbb{Z}[\sqrt{2}]^\times / \langle 1 + \sqrt{2} \rangle $,"I would like to count the elements of $\mathbb{Z}[\sqrt{2}]$ modulo its units, so I'll remove the set $\{ 0\}$ but also the group of units $\{ (1 + \sqrt{2})^n : n \in \mathbb{Z}\}$.  So this would be the quotient set $\mathbb{Z}[\sqrt{2}]^\times /  (1 + \sqrt{2})^\mathbb{Z} $. So I am going to place my copy of $\mathbb{Z}[\sqrt{2}]$ in the plane using: $$ \mathbb{Z}[\sqrt{2}] = \{ (a,b\sqrt{2}): a,b \in \mathbb{Z}  \}\hookrightarrow \mathbb{R}^2 $$ One possible lattice point counting problem could be a circle or an ellipse, we could count elements of the set: $$ \{ x^2 + y^2 < R^2\} \cap  \{ (a,b\sqrt{2}): a,b \in \mathbb{Z}  \} $$ This does not seem natural since the norm for $\mathbb{Q}(\sqrt{2})$ has to do with hyperbolas : $$ N(a + b \sqrt{2}) = a^2 - 2b^2 = n $$
where $n \in \mathbb{Z}$ ranges over the integers.  This is a family of hyperbolas, preserved under the action of $ \times \,(\,1 + \sqrt{2})$. In that case, what are the quotient sets of $\mathbb{C}^\times $ modulo the action of $ \times \,(\,1 + \sqrt{2})$ ? I have drawn the folation and transverse foliations of the hyperbola, which cover the pictured Euclidean plane: \begin{eqnarray*}
x^2 - 2y^2&=& a \\
\sqrt{2} \, xy&=& b 
\end{eqnarray*} Here the element $1 + \sqrt{2}$ acts as: $$ (1 + \sqrt{2}) (a + b \sqrt{2}) = (a + 2b) + \sqrt{2}(a+b) $$ and this can be modeled as a $2 \times 2$ matrix $$ 1 + \sqrt{2} \leftrightarrow 
\left[ \begin{array}{cc} 1 & 2 \\ 1 & 1 \end{array}  \right] $$ Back to the original problem I'd liked to list elements of $\mathbb{Z}[\sqrt{2}]$ that are ""smaller than"" say 100 up to the action of the unit $1 \pm \sqrt{2}$.  This has motivated me to define some peculiar sets of the plane, but I still cannot get an answer. Hopefully I have explained what I am looking for.","['combinatorics', 'algebraic-number-theory', 'elementary-set-theory']"
2693818,Finding potential for a vector field,Find the potential function for the vector field $$\frac{16x}z\hat{\mathbf i}+\frac{18y}z\hat{\mathbf j}+\left(1-\frac{8x^2 +9y^2}{z^2}\right)\hat{\mathbf k}$$ which has no constant terms. So far I have $$f = \frac8z x^2 +\frac9z y^2 +g(z).$$ The $z$ term kinda messes things up and I'm not really able to get any further.,"['multivariable-calculus', 'integration', 'partial-derivative']"
2693852,Optimal strategy for guessing game,"The game goes like this: I pick a random number between 1 and 1000. You have to guess what the number is. If you guess right, you get 1150. If you guess wrong, you lose 98. You may also ask for any number of hints, but the first hint will cost you 2, the second hint will cost 4, third will cost 8, etc. The hints are only yes/no questions. What is the optimal strategy? I thought about doing this with binary search but that uses too many hints. However binary search removes half the values every time and I can't figure out something that is more efficient. Is there a better strategy?","['game-theory', 'probability']"
2693896,Product of sines general formula: $ \sin{x}\sin{2x}\sin{3x}...\sin{nx}$,"I've stumbled upon this product of sines:
$$ \sin{x}\sin{2x}\sin{3x}...\sin{nx}$$ 
I have to find a general formula for it. So far I tried to use the complex definition for the sine:
$$\sin{x}=\frac{e^{ix}-e^{-ix}}{2i}$$ $$\sin{x}\sin{2x}\sin{3x}...\sin{nx}=\prod_{k=1}^{n}\frac{e^{kix}-e^{-kix}}{2i}=\frac{1}{(2i)^n}\prod_{k=1}^{n}e^{-kix}(e^{2kix}-1) \\
=\frac{1}{(2i)^n}\prod_{k=1}^{n}e^{-kix}\prod_{k=1}^{n}(e^{2kix}-1)$$
I got stuck when it came to this product: $$ \prod_{k=1}^{n} {e^{2kix}-1}$$ What would you suggest? What should I do next?","['products', 'trigonometry', 'complex-numbers']"
2693905,Non-principal filter of $\mathcal P(\mathbb N)$ cannot contain singleton,"Let $F$ be a non-principal ultrafilter of $\mathcal P(\mathbb N)$. My book says that because $F$ is non-principal, it cannot contain a singleton. I don’t see why this is the case. As far as I know, a principal filter is simply a point generated upset, so we have $\{X\in \mathcal P(\mathbb N):A\subset X\}$, for some $A$. How does $\{x\}\in F$ make $F$ a principal filter? I would say that $F$ in that case contains a principal filter of $\{x\}$. I'm guessing my definition of a principal filter isn't right, but this is what I got from the book and wiki.","['filters', 'elementary-set-theory']"
2693913,"How do you show that $\lim_{(x,y)\to(0,0)} \frac{xy}{x^2+y}$ doesn't exist?","I have to prove that this limit doesn't exist. $$\lim_{(x,y)\to(0,0)} \frac{xy}{x^2+y}$$ I tried this parametrization: $\begin{cases} x = t \\ y = mt^\alpha\end{cases}$ obtaining as result that the previous limit in this specific case would be equivalent to $$\lim_{t\to0} \frac{mt}{t^{2-\alpha}+m}$$ which would be null for each value of $\alpha,m$. Using a polar coordinate system doesn't seem effective too. How do I prove that this doesn't exist?",['limits']
2693936,differentiability - neighborhood,"Could someone let me know if I'm on the right track? And if not give me a hint or let me know what doesn't make sense? Thanks in advance!! Suppose $f\colon \mathbb{R}\ \to \mathbb{R} $ is differentiable at
  $x_{0}$ $\in$ $(a,b)$ and $f'(x_{0})>0$. Prove $\exists$ a
  neighborhood $I$ of $x_{0}$ s.t. $\forall x \in I$ we have $x<x_{0}
 \implies f(x_{})<f(x_{0})$ and $x>x_{0} \implies f(x_{})>f(x_{0})$. This is what I was thinking: Suppose there doesn't exist such an interval $I$. Then $\forall n \in \mathbb{N}$ we can find an $x_{n} \in (x_{0}-\frac{1}{n},x_{0}+\frac{1}{n})$ s.t. if $x_{n}<x_{0} \implies f(x_{n})\ge f(x_{0})$ and if $ x_{n}>x_{0} \implies f(x_{n})\le f(x_{0})$. This defines a sequence $\{x_{n}\}$, where $x_{n} \ne x_{0} \space \forall n \in \mathbb{N}$, with $\{x_{n}\} \to x_{0}$. Choose $\{x_{n_{k}}\}$ to be the subsequence of $\{x_{n}\}$ s.t. $x_{n_{k}} \lt x_{0} \space\forall n_{k}\in \mathbb{N}$. Note $\{x_{n_{k}}\} \to x_{0} $. We know $f$ is differentiable at $x_{0}$. So we have that $\{\frac{f(x_{n_{k}})-f(x_{0})}{x_{n_{k}}-x_{0}}\}$ $\le 0$ so that $f'(x_{0})$ $\le 0$. Contradiction - since by hypothesis $f'(x_{0})$ $\gt 0$. Thus, there does exist such an interval. Edit: Also, I don't understand where the interval $(a,b)$ comes to play. Why are we given it? We are given the domain of $f$ is $\mathbb{R}$ so I feel like its redundant information?","['derivatives', 'real-analysis', 'calculus']"
2693946,Principled way to find a shape with symmetries given by a group,"Recently I've learned how groups correspond to symmetries of objects so I've been trying to find shapes corresponding to groups that I know (all with finite groups). For example, I know $\mathbb Z / p \mathbb Z$ for $p$ prime is cyclic so it makes sense to try a prime-sided regular polygon because it has no reflectional symmetries, so there's nothing to do except rotate it by one turn until you've done $p$ rotations and are back where you started. But for non-cyclic groups I don't know in general how to proceed. My problem is that so far I've basically been guessing and checking. Like I figured out a shape that has $K_4$ as its symmetries, but I wasn't actually looking to find $K_4$, I was trying to find a different group. How can I do a better job of producing a shape that I want? An example: $\mathbb Z / 4 \mathbb Z$. I can't think of what to use. An isosceles triangle seems to correspond to $\mathbb Z / 2 \mathbb Z$ since the only symmetry is reflection along the line bisecting the non-congruent angle. So I tried gluing two isosceles triangles together along the non-congruent side, but that's how I ended up with $K_4$. And the other shapes I've tried, like a square or 6 pointed star, all have too much symmetry. Is there even a single shape giving $\mathbb Z / 4 \mathbb Z$? Is this a general thing for $\mathbb Z / n \mathbb Z$ when $n$ is not prime? I know this is connected to the dihedral group -- what does that mean for my endeavor? Am I only able to find such a shape if the group in question is a dihedral group? Sorry if this has been asked before, I searched and didn't see it but clearly I'm pretty new to group theory so i might have not recognized a solution when I saw it. Thanks for any help. As an example of the kinds of shapes I want, I basically want polygons. This is $K_4$ taken from the wikipedia article on it. I'm very happy with this shape. For $\mathbb Z / 5 \mathbb Z$, there's the regular pentagon. That works great for me. That sort of shape. I have been thinking very much in terms of ""classical"" shapes although I'd definitely be interested in broadening my ""shape"" horizons if that's insightful.","['dihedral-groups', 'group-theory', 'geometry']"
2694006,Number of 4x4 matrices such sum of all rows and columns is zero.,"The number of matrices $A = [a_{ji}], 1 \le i,j \le 4$ such that $a_{ij} = +- 1$ and $\sum_{i = 1}^{4}a_{ij} = \sum_{j=1}^{4}a_{ij} = 0$ is... I solved it by first selecting two values of “i” which is $\binom{4}{2}$ and two values of “j” similarly. Now if I fill thes four positions by 1, the value of remaining positions also get fixed because sum of all rows and columns is zero. So answer should be 36 $(\binom{4}{2}\times \binom{4}{2})$but the correct answer is 90. Why this method is wrong and what is the correct way of solving this?","['matrices', 'combinatorics']"
2694015,Probability : Roll of Die,"$\textsf{A}$ and $\textsf{B}$ are playing a game with $2$ standard dice. Both the dice are rolled together and the total is counted. $\textsf{A}$ says that a total of $2$ will be rolled first. $\textsf{B}$, whereas, says that two Consecutive totals of $7$′s will be rolled first. They keep rolling the dice till one of them wins !. What is the probability that $\textsf{A}$ wins the game ?. For a total of $2$, $\{(1,1)\}$ and for a total of $7$, $\{(1,6),(6,1),(2,4),(4,2),(3,4),(4,3)\}$ are the required scenarios. I don't understand how we need to incorporate the probabilities of $\textsf{A}$ winning, i.e., $1/36$ and $\textsf{B}$ winning, i.e. $6/36$ into a game of infinite rounds, i.e. until $\textsf{A}$ wins. –",['probability']
2694023,Limit of recursive sequence with floor,"Sequences $x_n$ and $y_n$ are defined as
  $$x_n=\left\lfloor x_{n-1}\frac{y_{n+1}}{y_{n-1}}\right\rfloor,\\
y_n=y_{n-1}+1,\\
x_0=2015,\ y_0=307.$$
  Compute $$\lim_{n\to\infty}\frac{x_n}{y_n^2}$$ My attempt: $y_n=307+n$ so $$x_n> x_{n-1} \frac{308+n}{306+n}>x_0\frac{(308+n)(309+n)}{306\cdot 307}\approx O(n^2),$$
so the limit is approximately $\dfrac{2015}{306\cdot 307}$. However, the answer is given as $\dfrac{2}{101}$. How to obtain this value?","['recurrence-relations', 'limits', 'calculus', 'contest-math', 'sequences-and-series']"
2694099,intersection of sigma algebras is a sigma algebra,"I am new to $\sigma$-algebras and I am having some conceptual difficulty with the proof regarding the fact that an intersection of $\sigma$-algebras is again a sigma algebra. So formally the question is this Let $X$ be a set. let $\{\mathcal{H}_i\}_{i\in I}$ be a family of $\sigma$-algebras on $X$. Prove that $\mathcal{H}=\bigcap \{\mathcal{H}_{i};i \in I \}$ is again a $\sigma$-algebra. So the proof is to go through the Axioms 1 by 1  (though my issue with the proof revolves mainly around the first axiom). From the first Axiom of sigma algebras as $X \in \mathcal{H}_{i}$ for all $i \in I$. Hence We see that  $X \in \mathcal{H}$ by definition of the intersection $\Box $. Here is my issue. I don't see how we know that $X \in \mathcal{H}$ just by the definition of the intersection, i.e. how do we know that $X \notin \bigcup \{\mathcal{H}_{i};i \in I \}\setminus  \bigcap \{\mathcal{H}_{i};i \in I \}$ ?",['measure-theory']
2694102,"the sequence $n!+2,...,n!+n$ is made up of only composite numbers [duplicate]","This question already has answers here : If $n = 51! +1$, then find number of primes among $n+1,n+2,\ldots, n+50$ (4 answers) Closed 6 years ago . I have found the claim that given that $n\geq2$, we have that the sequence of $n-1$ numbers $n!+2,n!+3,...,n!$ is made up of only composite numbers. Is there a proof of this? I found this pretty fascinating but I am not sure how to go around it. It seems to hold for the first few examples $n=2$:  $S=\{4\}$ $n=3$: $S=\{8,9\}$ $n=4$: $S=\{26,27,28\}$","['number-theory', 'prime-numbers', 'sequences-and-series']"
2694105,Soft question - a subset of a Hilbert space endowed with subspace topology,"I am considering a Hilbert space $X$, endowed with its weak topology. I need to work with a subset (but not a subspace) $S$ of $X$. However I need to endow $S$ with the subspace topology (so $U$ is weakly open in $S$ if and only if there is a weakly open set $V$ in $X$ such that $U=S \cap V$). I have quite a lot to write about this, and I am worried that the reader will misunderstand when I speak about $S$ with the subspace topology, thinking that I have misunderstood $S$ to be a vector subpspace. I am also worried that when I say subspace topology the reader will not realise it's the one induced from $X$ with its weak topology. Is there a better way to phrase myself? Perhaps another way to refer to the subspace topology as to not confuse $S$ with a vector subspace of $X$? I am struggling to find a concise and clear way to phrase it.","['functional-analysis', 'general-topology', 'weak-topology', 'soft-question']"
2694137,Solve $\frac{x^2}{\left(a+\sqrt{a^2+x^2}\right)^2}+\frac{x^2(1+x^2)}{\left(a+\sqrt{a^2+x^2(1+x^2)} \right)^2}=1$,"I have been trying to solve the following equation for $x$:
\begin{align}
\frac{x^2}{\left(a+\sqrt{a^2+x^2}\right)^2}+\frac{x^2(1+x^2)}{\left(a+\sqrt{a^2+x^2(1+x^2)} \right)^2}=1,
\end{align}
for some fixed $a \in (0,1/2]$. This equation came from an analysis of an electrical circuit. The solution is the current. However, after trying to solve it by hand using the software it doesn't appear that there is a good way of finding a solution. My question:  Can we at least give a good estimate of the position of the positive zero?    For example, can show that the zero belong to the specific interval? Here is an equaivalent polynomial:
\begin{align}
x^4 - 4a^4 - 4a^3(a^2 + x^2)^{1/2} + x^6 - 4a^3(x^2(x^2 + 1) + a^2)^{1/2} - 4a^2(x^2(x^2 + 1) + a^2)^{1/2}(a^2 + x^2)^{1/2}=0.
\end{align}","['algebra-precalculus', 'calculus']"
2694164,Constructing a vector bundle,"I have just started to study vector bundles, and I just know the definition, i.e. a vector bundle over a variety $X$ is a variety $F$ with a map $\pi:F\rightarrow X$ and a covering by open sets, that for each opens set accepts a map $\psi_i:\pi^{-1}(U_i)\rightarrow U_i\times K^r$, and the composition of $\pi$ with this map is the projection. And also there is transition functions that are linear. The definition is pretty similar with the tangent bundle, so it seems fine. But the text suggests an exercise after the definition, and I am having trouble with it. It asks to construct a rank two vector bundle over the smooth quadric $X\subset\mathbb P^4$ defined by $x_0x_3+x_1x_4+x_2^2$ by gluing the local equations of the line $L$ defined by $x_0=x_1=x_2=0$. So I know that looking to the local equations I will be able to obtain the matrix of transition, but I am afraid that I cannot find the local equation (is it defined locally by the ideal $(x_0,x_1,x_2)/(x_0x_3+x_1x_4+x_2^2)$?) Any hint in how to procede is appreciated. Thanks in advance.","['vector-bundles', 'algebraic-geometry']"
2694171,Kolmogorov 0-1 law with almost sure convergence,"Recently I've tried to solve next problem: consider the sequence of $\{X_n\}_{n=1}^{\infty}$ of independent random variables and $X_n \rightarrow X$ in probability. Prove that the limit $X$ is degenerate ($\exists c \in R: P(X = c) = 1$). The solution is: as we have convergence in probability we can find a subsequence $n_k$ in $X_n$ such that $X_n \rightarrow X$ almost sure. After that, we need use Kolmogorov 0-1 law, but I don't really understand how. So, the question is: Consider sequence $X_n$ of independent random variables defined on probability space. We know that $X_n$ converge almost sure to $X$. I would like to use Kolmogorov 0-1 law to show that $X$ is degenerate. For that, I need to show that $X$ is measurable with respect to tail sigma algebra. Why that's true?","['probability-theory', 'measure-theory']"
2694278,Vanishing on the boundary for Sobolev subspace,"Let $W^{m,p}(\Omega) = \{ f \in L^p(\Omega): \partial^\alpha f \in L^p(\Omega) \text{ for multi-indices } |\alpha| \leq m\}$, where $\partial$ denotes the weak derivative. Define $W_0^{m,p}$ to be the closure of $C_c^\infty(\Omega)$ in $W^{m,p}(\Omega)$. From my understanding, all elements of $W_0^{m,p}$ must vanish on the boundary of $\Omega$, as well as their derivatives up to order $m-1$. I don't quite understand why the derivative of order $m$ need not vanish. Take for example $m=1$ and $p=2$, with norm $||f||^2_{W^{1,2}}=||f||_{L^2} + ||D^1 f ||_{L^2}$. If $f \in W_0^{1,2}$, then there exists a sequence $f_k \in C^{\infty}_c$ such that $f_k \to f$ in $W^{1,2}$. Thus $$||f_k - f||_{W^{(1,2)}} = ||f-f_k||_{L^2} + ||D^1 (f-f_k) ||_{L^2} \to 0 \text{ as } k \to \infty$$ Given each $f_k$ has vanishing derivative on the boundary (more so, outside its support), I don't see why $f$ need not have vanishing derivative at the boundary. I guess this question is an extended question from this post: Some basics of Sobolev spaces","['functional-analysis', 'sobolev-spaces']"
2694315,Upper triangular matrices (Solving),"If $T=\begin{bmatrix}A & C\\0 & B\end{bmatrix}$ is upper triangular with $A$ and $B$ upper triangular as well ($C$ is an arbitrary matrix), then what must $R$ be so that: $$
S^{-1}TS = \begin{bmatrix}A & 0\\0 & B\end{bmatrix} \,,
$$
where $S = \begin{bmatrix}I & R\\0 & I\end{bmatrix}$? My attempt I tried to compute the equivalent statement $TS = S\begin{bmatrix}A & 0\\0 & B\end{bmatrix}$ first, which gave me: $$
\begin{gather*}
\begin{bmatrix}A & C\\0 & B\end{bmatrix}\begin{bmatrix}I & R\\0 & I\end{bmatrix} = \begin{bmatrix}I & R\\0 & I\end{bmatrix}\begin{bmatrix}A & 0\\0 & B\end{bmatrix} \\
\begin{bmatrix}A & AR+C\\0 & B\end{bmatrix} = \begin{bmatrix}A & RB\\0 & B\end{bmatrix} \\
\Rightarrow AR+C = RB
\end{gather*}
$$
then I'm stuck. How do I extract matrix $R$ from this? I think there's probably a need to use the fact that $A$ and $B$ are upper triangular, but I don't know how. Note that this is the question as posed, I do not have the dimensions of any of the matrices.","['matrices', 'linear-algebra']"
2694316,Approximating the limit of a Cauchy sequence in a Banach space,Let $E$ be a Banach space and consider a sequence $(x_n)_n$ in $E$ satisfying the following condition: $$||x_n-x_{n-1}||\leq 3^{-n}\mbox{ for all }n\in\mathbb{N}.$$ Clearly $(x_n)_n$ is a Cauchy sequence and therefore converges to an element $x\in E$ . Question: How to prove that $||x-x_n||\leq \frac{1}{2}3^{-n}$ for all $n\in\mathbb{N}$ ?,"['real-analysis', 'banach-spaces', 'cauchy-sequences', 'limits', 'calculus']"
2694329,Shape with area $a$ and shortest average distance between any two points,"Consider the collection $\mathcal{X}$ of compact and connected subsets of $\mathbb{R}^2$ , that are the closure of some open subset of $\mathbb{R}^2$ , and have area $a$ . For any $\Omega \in \mathcal{X}$ and any $x,y \in \Omega$ , let $d(x,y,\Omega)$ be the length of the shortest path lying entirely inside $\Omega$ and connecting $x$ to $y$ . Also, let $\mathbb{1}(x,y,\Omega)$ be the indicator function that equals $1$ if $x$ and $y$ are both in $\Omega$ , and zero otherwise. I am interested in the following problem: $$\min_{\Omega \in \mathcal{X}} \int_{x\in \mathbb{R}^2}\int_{y\in \mathbb{R}^2} d(x,y,\Omega) \mathbb{1}(x,y,\Omega) dx dy$$ Is there a well-known solution to this problem? Is it possible to show that a solution to this problem must be convex? Is the problem even well-defined (e.g., does $d(x,y,\Omega)$ always exist? I tried to help guaranteeing it by including only closed and connected sets in $\mathcal{X}$ , but I am not 100% sure that's enough)? Is the problem guaranteed to have a solution without more regularity conditions? Some related problems are described here: https://link.springer.com/article/10.1007/s10958-012-0717-3 . Unfortunately, these related problems either (1) focus on ""networks"" rather than ""thick"" sets, (2) focus right away on convex sets, or (3) do not fix the area and instead impose an additional ""cost"" to the minimization problem for increasing the area.","['optimization', 'average', 'geometry']"
2694331,"Intuition behind ""surface measure"" in integration formula for polar coordinates","In ""Real Analysis"" by Stein & Shakarchi, the polar coordinates of a point $x \in \mathbb{R}^d - \{0\}$ are the pair $(r,\gamma)$ where $0 < r < \infty$ and $\gamma$ belongs to the unit sphere $S^{d-1} = \{x \in \mathbb{R}^d : |x| =1\}$, determined by 
$$r = |x|, \quad \gamma = \frac{x}{|x|}.$$
Furthermore, polar integration is defined as 
$$\int_{\mathbb{R}^d} f(x)\,dx = \int_{S^{d-1}} \int_0^\infty f(r\gamma) r^{d-1}\,drd\sigma(\gamma).$$
This is explained in the text as the result of defining two measure spaces $(X_1,\mathcal{M}_1,\mu_1)$ and $(X_2,\mathcal{M}_2,\mu_2)$, where $\mathcal{M}_1$ is the collection of Lebesgue measurable sets in $X_1 =
 (0,\infty)$ and $d\mu_1(r) = r^{d-1}\,dr$. Regarding the second measure space, we take $X_2 = S^{d-1}$ and the authors say that when $E \subseteq S^{d-1}$, to consider the set $\tilde{E} = \{x \in \mathbb{R}^d : x/|x| \in E, 0 < |x| < 1\}$ to be the subset of the unit ball. If $\tilde{E}$ is Lebesgue measurable, we say that $E \in \mathcal{M}_2$ and define $\mu_2(E) = \sigma(E) = d\cdot m(\tilde{E})$, where $m$ is the Lebesgue measure in $\mathbb{R}^d$. I am seeking intuition behind the ""surface measure."" How should I interpret the set $\tilde{E}$; that is, what does this set look like ? Furthermore, if the measure $\mu_2 = \sigma$ is defined in terms of the Lebesgue measure in $\mathbb{R}^d$, what is the significance of the factor of $d$? Why not define $\sigma(E) = m(\tilde{E})$?",['measure-theory']
2694336,Why is $\sum_\limits{k=1}^{n}\sum_\limits{j=1}^{k}j = \frac12\left(\sum_\limits{k=1}^{n}k^2+\sum_\limits{k=1}^{n}k\right)$,"Why is $$\sum_\limits{k=1}^{n}\sum_\limits{j=1}^{k}j = \frac12\left(\sum_\limits{k=1}^{n}k^2+\sum_\limits{k=1}^{n}k\right)?$$ I'm not seeing why they're equivalent. The first expression can be viewed as a half pyramid of some sort, but I don't see what the $k^2$ comes from in the second expression.","['algebra-precalculus', 'discrete-mathematics']"
2694396,"Let $X,Y$ be r.v.'s on $\Omega$. Do there exist for all laws $\pi$ on $\mathbb R^2$ with marginals $\mu_x,\mu_Y$, a r.v. $Z$ s.t. $\pi=\mu_Z$?","Fix a probability space $(\Omega,\mathcal F,\mathbb P)$, and let $X,Y:\Omega\to\mathbb R$ be random variables with laws $\mu_X,\mu_Y$ respectively. Let $\pi$ be a probability measure on $\mathbb R^2$ with marginal distributions $\mu_X,\mu_Y$. Does there exist a random variable $Z:\Omega\to\mathbb R^2$ such that $\mu_Z=\pi$? Intuitively this seems true, and if it is true, it seems like something that would be a classical well-known fact in probability. However, I have not read any such statement anywhere.","['probability-theory', 'measure-theory']"
2694430,Dimension factor in definition of the Weyl tensor,"tl;dr Where do the $\frac{1}{n-2}$ and $\frac{1}{(n-1)(n-2)}$ factors come from in the definition of the Weyl tensor? The Weyl tensor is the trace-free component of the Riemann curvature tensor. Therefore, it can be simply computed by subtracting the traces. In dimension $1$, the Riemann curvature vanishes by its symmetries so the trace free part also vanishes. The Weyl tensor also vanishes in dimension $2$ and $3$, as at least two indices are always equal, so the Riemann curvature is entirely described by its traces. For dimensions $n \geq 3$, (apparently) $W$ is given by
$$W_{ijkl} = R_{ijkl} - \frac{1}{n-2}\left(-g_{jl}R_{ik}+ g_{jk}R_{il}+ g_{il}R_{jk}- g_{ik}R_{jl}\right) - \frac{1}{(n-1)(n-2)}\left(g_{ik}g_{jl}R - g_{il}g_{jk}R\right)$$ However, I don't understand where the $\frac{1}{n-2}$ and $\frac{1}{(n-1)(n-2)}$ factors come from. Why is the formula not
$$W_{ijkl} = R_{ijkl} - \frac{1}{n}\left(-g_{jl}R_{ik}+ g_{jk}R_{il}+ g_{il}R_{jk}- g_{ik}R_{jl}\right) - \frac{1}{n^2}\left(g_{ik}g_{jl}R - g_{il}g_{jk}R\right)$$
This seems sensible to me as you are dividing by the factor of the trace of the metric.","['tensors', 'conformal-geometry', 'differential-geometry', 'curvature']"
2694445,Precise definition of a Riemann surface associated to a function,"$\newcommand{\C}{\mathbb{C}}$
Let $\Omega \subset \C$ be an open and $f: \Omega \to \C$ be a meromorphic function.  I want a precise definition of THE Riemann surface associated to $f$(and some uniqueness statement). Cause for my confusion:  In every book that I can find, I have seen examples of Riemann surfaces associated to a function but no precise definition. Here is my first stab at a definition. A Riemann surface for $f$ is a pair $(X,F)$, where $X$ is a Riemann surface, $F: X \to \C$ is meromorphic and $F|_U=f$ for some chart and coordinates $U \subset X$. Obviously the Riemann surface for $f$ is not unique in any sense right now. The uniqueness statement that I want is something like Given $(X,F)$, $(Y,G)$ as above, then there is an isomorphism $X \cong Y$ such that the following diagram commutes $\require{AMScd}$ $\begin{CD}
X @>F>> \C\\
@| @|\\
Y @>G>> \C
\end{CD}
$ Is this too much to ask?  And is there a definition of the Riemann surface associated to a function so that I can get such a uniqueness statement?","['complex-analysis', 'complex-geometry']"
2694483,Central and inscribed angles,"We know that the inscribed angle is half of the central angle. But, I believe that there are other points inside the circle (the point(s) B in the figure below other than the origin of the circle), such that: $\beta= \frac{1}{2}\alpha$. I tried using geogebra to change the position of point B (without changing the points A, C, and D) in such a way the relation above holds but I cannot prove it.
Any help is appreciated.","['circles', 'angle', 'geometry']"
2694505,Six dice blank on five sides. How to roll as one?,"I have six six-sided dice. Five of their faces are blank and identical. One face on each die contains the number 1,2,3,4,5, or 6. Suppose I roll them together, the output from this random event is an unordered set for example: {B,B,3,1,B,6} (blank side results, for our purposes, are indistinguishable.) What is a simple way to use this result like an ordinary, fair six-sided die? My first thought was to keep rolling until the only non-blank results are permutations of {A,B,B,B,B,B} {A,A,B,B,B,B} {A,A,A,B,B,B} {A,A,A,A,B,B} {A,A,A,A,A,B} {A,A,A,A,A,A} where A is some repeated number 1-6 and B is blank. This would work but it is not efficient. Obviously the many {B,B,B,B,B,B} results can’t be used (probably?) but, what about mixed results? For any result where one number is repeated more than the rest I could take the most repeated number as the result... but how can I interpret {1,2,1,2,4,B,6}? Basically, I’m looking for a simple function that a human* could remember easily that maps the results of this random event to the numbers 1-6 with equal frequency. *A table is another solution, but I would like fewer than 5 or 6 dead simple rules that use all of the results that are not {B,B,B,B,B,B}. If there is a way to use {B,B,B,B,B,B} that is even better.",['probability']
2694521,Multiplication cancellation property by Peano axioms,"I am trying to prove cancellation property of multiplication of natural numbers, $xy=xz$ implies $y=z$, with Peano axioms and arithmetic but not using or defining order on natural numbers. It can be done for addition. But for proving multiplication cancellation property one uses order. Why is that so?",['peano-axioms']
2694539,Why is Hausdorff measure Borel regular?,"Definition of Hausdorff measure: I already knew that all borel sets are measurable. So the problem is that given any subset $A$, how to find some borel set containing $A$ that has the same measure. I have read some text, but they only say that we can replace the definition with open sets or closed sets and get the same definition (and this part I can understand), but then they claim that Hausdorff measure is borel regular as a corollary without explanation. Can any one give a detailed proof? Thanks a lot. Explanation of the fact we can replace the definition with open/closed subsets:","['hausdorff-measure', 'geometric-measure-theory', 'measure-theory']"
2694566,Find a matrix A such that $\operatorname{rank}{A} = \operatorname{rank}{A^2} \neq \operatorname{rank}{A^3}$,"Let $A$ be a complex square matrix of order 2 ($A \in M_{2,2}$).
Then, does there exist $A$ such that $\operatorname{rank}{A} = \operatorname{rank}{A^2} \neq \operatorname{rank}{A^3}$? If that doesn't exist, how can I prove it?","['matrices', 'matrix-rank']"
2694582,"Are there any ""nonstandard"" special angles for which trig functions yield radical expressions?","Everyone learns about the two ""special"" right triangles at some point in their math education—the $45-45-90$ and $30-60-90$ triangles—for which we can calculate exact trig function outputs. But are there others? To be specific, are there any values of $y$ and $x$ such that: $y=\sin(x)$; $x$ (in degrees) is not an integer multiple of $30$ or $45$; $x$ and $y$ can both be written as radical expressions? By radical expression, I mean any finite formula involving only integers, addition/subtraction, multiplication/division, and $n$th roots. [Note that I require $x$ also be a radical expression so that we can't simply say ""$\arcsin(1/3)$"" or something like that as a possible value of $x$, which would make the question trivial.] If yes, are they all known and is there a straightforward way to generate them? If no, what's the proof?",['trigonometry']
2694653,Solve the wave equation in an infinite sector,"Consider the following wave equation:
  $$\begin{align}
u_{tt}-u_{xx} &=0, \quad 0<t<tx, k>1\\
u|_{t=0}&=\phi_0(x),\quad x\ge 0\\
u_t|_{t=0}&=\phi_1(x),\quad x\ge 0\\
u|_{t=kx}&=\psi(x)\end{align}
$$
  In which $\phi_0(0)=\psi(0)$. The problem is that on part of the sector where $t>x$ d'Alembert's formula isn't applicable. It seems we will have to do some sort of extension or reflection, but how to start?","['real-analysis', 'partial-differential-equations', 'calculus', 'wave-equation', 'ordinary-differential-equations']"
2694731,Evaluate infinite sum involving n!,"Evaluate
$\sum_{n=1}^\infty \frac{1}{n×n!}$ I really don't know where to begin with this but I'm pretty sure $e$ is involved somehow. If it can help, $n×n!=(n+1)!-n!$",['sequences-and-series']
2694762,Construct a smooth curve with length $10$ and enclosing an area $6$,"The problem is the title and when I tried to construct such a curve I found my always obtain an ellipse, but failed to calculate the length of it. Are there any better constructions?
I forget to add a condition.","['differential-geometry', 'calculus']"
2694775,Are all adjacency matrices of connected graph diagonalizable?,"The related question has been asked in the following link: Are all adjacency matrices (graph theory) diagonalizables? However, the answer does not give a formal proof or explicit answer. My question is: For any connected graph (undirected graph), is its adjacency matrix diagonalizable? Note: it is obviously that it does not have to be full rank, for example a tree graph.","['matrices', 'graph-theory']"
2694788,What is the derivative of $(u^v)$?,"The derivative of a sum is the sum of the derivatives, ie, $$d(u+v)=du+dv$$ The derivative of a product is a little more complicated: $$d(u\cdot v)= u\ dv + v\ du$$ But what about the derivative of a power? I'm not talking $x^n$ or $a^x$ or even $x^x$, but $u^v$ - an arbitrary function of $x$ raised to the power of another arbitrary function of $x$.","['derivatives', 'calculus']"
2694795,The polarization of the determinant is invariant?,"Given $n \in \mathbb N$, I am asked to show that there is a multilinear symmetric $\operatorname{GL}_n$-invariant form $\phi : (M_{n \times n})^l \to \mathbb R$ (for some $l \geq 0$) such that $\phi(A,A,...,A) = \det A$ for all $A \in \mathbb M_{n \times n}(R)$. Using the idea of polarizing an algebraic form, I decided to do the following: by definition, we have
$$
\det(A) = \sum_{\sigma \in S_n} \operatorname{sgn}(\sigma) \prod_{i=1}^n A_{i \sigma(i)} 
$$ and therefore we could define $\phi$ with $l=n$, but taking $n$ independent copies of $A$ and adding another permutation into the mix, just like the polarization formula. This gives:
$$
\phi(A^{1},A^2,...,A^n) = \frac 1{n!} \sum_{\pi \in S_n} \sum_{\sigma \in S_n} \operatorname{sgn}(\sigma)\prod_{i=1}^n A^{\pi(i)}_{i\sigma(i)}
$$ This formula is multilinear, symmetric and $\phi(A,A,..,A) = \det A$. However, I am not quite getting how to prove invariance : $\phi(g^{-1}A^1g, g^{-1}A^2g,...,g^{-1}A^ng) = \phi(A^1,A^2,...,A^n)$ for all $A^i$, $i = 1 \to n$. While this may not work out, I am inclined to think it does, since I used the definition of polarization to obtain all the conditions, and got the one I need additionally. However, proceeding by simple expansion does not work (creating a bunch of $g^{-1}$ and $g$ indexed terms, and therefore discombobulation), and therefore I need some help on why this is the case.","['matrices', 'invariant-theory', 'determinant']"
2694796,Question about tangent conics,"Suppose we have two conic section curves (the red one and the blue one) that are each tangent to a third conic (the black one) in two places. The picture shows ellipses, but I don't think that matters. Now suppose we draw four lines as shown: two lines connecting opposite intersection points (the green ones), and two lines connecting opposite tangency points (the pink ones). It appears that the four lines meet at a point. Is that true? Is this a known result, and, if so, does it have a name? Proof or reference, please?","['algebraic-geometry', 'projective-geometry', 'analytic-geometry', 'geometry', 'conic-sections']"
2694809,Affine cover of blow-up along ideal,"I would like to find affine cover of blow-up $X = Bl_{I} \mathbb A^2$, where $I=(x^3, xy, y^2)$. I know that $X=\{((x_1, x_2),[y_1,y_2,y_3])\subset \mathbb A^2\times\mathbb P^2: x_1^3y_2=x_1x_2y_1, x_1^3y_3=x_2^2y_1, x_1x_2y_3=x_2^2y_2 \}$. I've tried to use standard cover, i.e. $X\cap (\mathbb A^2\times U_i)$. I don't know how to see what is it. Thank you in advance.","['blowup', 'algebraic-geometry', 'commutative-algebra']"
2694820,solving the differential equation : $y' = \sqrt{4x+2y+1}$,"I tried solving the differential equation : $$y' = \sqrt{4x+2y+1}$$ but I really have no direction as to how to solve it. The fact both $x$ and $y$ are under the same root makes for difficulty when solving, since there seems to be no way to separate the two variables. Ideas?","['ordinary-differential-equations', 'calculus']"
2694867,How many solution for the equation $x+y=m+6$,"$$ x+ y = m + 6 $$
$$ 1 \le x,y \le 6 $$ My calculations are definitely wrong. I'm trying to solve the following equation instead: $$ w_1+ w_2 = m + 4 $$
$$ w_1=x-1, w_2=y-2$$
$$ 0 \le w_1,w_2 \le 5 $$ I'm having a hard time to understand why the amount of solutions for the above equation is equal to the number of solutions for the first one. Thirdly, to solve the above, I will calculated how many solutions for: $$ w_1+ w_2 = m + 4 $$
$$ 6 \le w_1 (or) 6 \le w_2 $$ To calculate how many solutions for the above, I will calculate how many solutions for: $$ w_1+ w_2 = m + 4 $$
$$ 0 \le w_1,w_2 $$ Which is $ \binom{m+5}{m+4} = m+5$. I solved it by ordering $(m+4)$ a and $1$ b in a line. and how many solutions for: $$ z_1+ w_2 = m - 2,w_1+ z_2 = m - 2,z_1+ z_2 = m - 8 $$
$$ z_1=w_1-6, z_2=w_2-6 $$
$$ 6 \le z_1,z_2,0 \le w_1,w_2 $$ The amount of solutions for $ z_1+ w_2 = m - 2 $ is $ m-1 $.
The amount of solutions for $ w_1+ z_2 = m - 2 $ is $ m-1 $.
The amount of solutions for $ z_1+ z_2  = m - 8 $ is $ m-7 $. So the amount of solutions for $ w_1+ w_2 = m + 4 $ with the restrication of $ 6 \le w_1 or 6 \le w_2 $ is: (by the Inclusion–exclusion principle ) $$ m-1 + m-1 - (m-7) = m+5 $$ As you can notice, I'm definitely wrong because the amount of solutions to the same equation with and without restrictions is the same. The final result for $ x+ y = m + 6 $ is $ 0 $ which is absolutly wrong .","['combinatorics', 'inequality', 'discrete-mathematics']"
2694869,Basic question about significance of statistical tests,"Apologies for the basic question this is really not my area at all but I’m trying to help a friend out. Whilst reading the Wikipedia page for the Shapiro-Wilk test I came across the following:
“As with most statistical tests, the test may be statistically significant from a normal distribution in any large samples. Thus a Q–Q plot is useful for verification in addition to the test” I interpret this to mean that if we sampled a large amount of data from what was in fact a Normal population, the test may in fact reject the null hypothesis that the parent population was Normal. Is this interpretation correct? If so, why is this the case? I thought in general larger samples gave better testing?! Any intuition on this would be very much appreciated.","['statistics', 'hypothesis-testing', 'statistical-inference']"
2694917,Disproving Cantor's diagonal argument,"I am familiar with Cantor's diagonal argument and how it can be used to prove the uncountability of the set of real numbers. However I have an extremely simple objection to make. Given the following: Theorem: Every number with a finite number of digits has two representations in the set of rational numbers. Proof: It follows from the fact that 0,9999... = 1, that any integer $n$ can be represented as $(n-1),9999...$
This similarly works for rational numbers with finite digits, as follows:
let $n_i$ be the $i$-th digit after the comma of a rational number with a finite number of digits $k$. Then $n,n_1n_2...n_k = n,n_1n_2...(n_k-1)999...$. Now, going through Cantor's diagonalization argument, assume that I built what I claim to be an exhaustive list of all real numbers in binary representation. Then, Cantor would claim that the number created by concatenating the negated $i$-th digit of the $i$-th number is not contained in my list. To which I would reply: ""Yes, but can you prove that your number is not the alternative representation of one already present in the list?"", following the theorem above. How does my remark not disprove or at least require further efforts in Cantor's proof? Has this point already been made? EDIT: The point is invalid if the base is different from 2, giving Cantor the choice of avoiding the more ""offending"" decimals 9 and 0. However, in the case of binary representation, which is the most commonly thought in universities, how could he make sure that happens by simply flipping bits as described above? It seems to me that he would have to go through the rather complex process of converting the binary number to another base, flipping its digits avoiding 0s and 9s, and converting back.","['real-numbers', 'elementary-set-theory']"
2694921,Prime in $\mathbb Z [\sqrt{-5}]$ but not in $\mathbb Z [\sqrt{5}]$,"Determine whether $\sqrt{-5}$ is irreducible and/or prime in $\mathbb Z[\sqrt{-5}]$ . What is a prime $p>5$ which is prime in $\mathbb Z [\sqrt{-5}]$ not prime in $\mathbb Z [\sqrt{5}]$ ? For the first one, I believe $\sqrt{−5}$ is irreducible as $N(\sqrt{−5}) = 5$ and the only integers that divide $5$ are $1$ (where all elements with norm $1$ are units) and $5$ (where only $±\sqrt{−5}$ have norm $5$ ). Is this a good explanation? I'm guessing that $\sqrt{-5}$ is prime but I'm not sure how to justify why. For the second one, I can't think of any primes over 5. Help would be great!","['number-theory', 'ring-theory', 'prime-numbers', 'field-theory']"
2694923,Relation between independent/dependent variable for substitution in ODE,"I have the following ODE:
$$
y'=y^2\cos t-\frac{1}{10}y
$$
substituting $z=1/y$, I understand this is $z(t)=1/y(t)$. I know $t$ is the independent variable and $y$ is dependent variable. What is the role of $z$ here? Does it change the dependent variable when $y(t)=1/z(t)$? I saw in the book that it is written:
$$
y'=\frac{-z'}{z^2}
$$
does this mean that:
$$
y'(t)=\frac{dz}{dy}\frac{dy}{dt}
$$
is the relation $z(y(t))$? Can someone explain the implicit differentiation in this expression? What are the dependent and independent variables here? I understand how to finish this, but I want to know the intuition behind. I always confuse what are the dependent and independent variables when doing substitution, and to what variable I need to implicitly differentiate.","['derivatives', 'chain-rule', 'calculus', 'integration', 'ordinary-differential-equations']"
2694929,Ideal sheaf of intersection,"Let $p_1,p_2,p_3$ be the points in the general position in $\mathbb{P}^2$ and $\mathcal I$ be their ideal sheaf. I want to find locally free resolution of $\mathcal I$. I can write $0\to\mathcal{O}(-2)\to\mathcal{O}(-1)^2 \to \mathcal I_{p_i}\to0$ and i know that 
$\mathcal I = \mathrm{im}\left(\mathcal I_{p_1}\otimes \mathcal I_{p_2}\otimes \mathcal I_{p_3} \to \mathcal O\right)$ but i has stuck with computing latter expression.
Really i am trying to express $\mathcal{O}(1)$ on the blow-up of $\mathbb{P}^2$ in those three points in nice terms. And that resolution is for inclusion of that blow-up in projective bundle. Am i on the right way?","['line-bundles', 'algebraic-geometry', 'blowup']"
2694935,Completion with respect to stronger norm is no subset?,"Let $M$ be a normed vector space equipped with two norms $\| \cdot \|_1$ and $\| \cdot \|_2$, where $\| \cdot \|_1$ is stronger than $\| \cdot \|_2$, i.e.
\begin{equation}
\forall x \in M: \| x \|_2 \leq c \|x\|_1
\end{equation}
Let now $\bar{M}_i$ denote the completion (cp. Reed Simon, Thm. I.3) of $M$ with respect to $\| \cdot \|_i$. Now I wanted to show, that $\bar{M}_1 \subset \bar{M}_2$ holds. But somehow, the proof does not work. Therefore recall, how the completion works: The completion of $M$ w.r.t. $\| \cdot \|_i$ is defined as the set $B_i$ of all sequences that are Cauchy in $M$ w.r.t. $\| \cdot \|_i$ modulo the equivalence relation:
\begin{equation}
(x_n) \sim_i (y_n) \Leftrightarrow \lim_{n \rightarrow \infty} \| x_n - y_n \|_i = 0
\end{equation}
I.e. $\bar{M}_i = B_i /\sim_i$. We now have $B_1 \subset B_2$, since $\| \cdot \|_2$ is weaker than $\| \cdot \|_1$. Let $i: B_1 \hookrightarrow B_2$ be the corresponding injective embedding. Now $i$ does descend to an injective map $j: B_1 / \sim_1 \hookrightarrow B_2 / \sim_2$ if and only if $\forall (x_n), (y_n) \in B_1: (x_n) \sim_1 (y_n) \Leftrightarrow i( (x_n)) \sim_2 i((y_n))$ ($\Rightarrow$ is needed for the existence and $\Leftarrow$ for injectivity). But since $\| \cdot \|_2$ is weaker than $\| \cdot \|_1$, $ \Leftarrow$ does not hold in general. Hence in general $\bar M_1 \subset \bar M_2$ does not hold. This seems for me quite strange, especially, since the closure of a dense subspace in a complete space is a completion, and here the assertion holds (i.e.: Let X be a normed space, which is complete w.r.t. $\| \cdot \|_i$ and $\| \cdot \|_1$ is stronger than $\| \cdot \|_2$. Let $Y \subset X$. Then the closure of Y in X w.r.t. $\| \cdot \|_2$ contains the closure of Y in X w.r.t. $\| \cdot \|_1$). What am I missing?","['functional-analysis', 'normed-spaces', 'general-topology', 'metric-spaces']"
2694941,How many minimal prime Ideals in an integral domain?,"I am wondering right now whether every ring, which is commutative, has a 1, and is reduced (i.e. no nilpotent elements) always has just one minimal prime Ideal. Does anyone have a proof or a counterexample? The motivation for this question is that said rings correspond to coordinate rings $k[X]$ for irreducible algebraic sets $X$. And the minimal prime ideals should correspond to the irreducible components of $X$, which in case that $X$ itself is irreducible should just be $X$. Possible it is necessary to assume that $k$ is also an integral domain. As there was some confusion, because I did not phrase the question clearly (sorry for that) and  the answer is so simple, here is the short solution:
If $R$ is an integral domain then $0$ is a prime ideal, and clearly it is also the unique minimal prime ideal. If $R=k[X]$ (i.e. $R$ is the coordinate ring of $X$), then $0$ corresponds to $X$ and $X$ is irreducible.","['ring-theory', 'algebraic-geometry']"
2694951,Sequence of polygons converging,"Let $P$ be a polygon ($P$ doesn't have to be regular, convex... it's just $n$ distinct points of $\mathbb{R}^2$). We construct the sequence $(P^{(n)})_n$ with $P^{(0)}=P$ and $P^{(n+1)}$ is the polygon obtained the following way : we consider the points cutting all the sides of $P^{(n)}$ in half, $P^{(n+1)}$ is the polygon with these points as vertices. Formally :
$$P^{(0)}=(x_1,\dots , x_n)\in \mathbb{C}^n$$
$$ P^{(n+1)}=\left( \dfrac{x_1^{(k)}+x_2^{(k)}}{2},\dots , \dfrac{x_{n-1}^{(k)}+x_n^{(k)}}{2}, \dfrac{x_n^{(k)}+x_1^{(k)}}{2}\right) .$$ I proved that $(P^{(n)})_n$ converges to the barycenter of $P^{(0)}$ (using algebraic arguments). I really want to learn more around this result but I can't find anything either in books that I know nor in the internet. For example a question that I would like to have an answer to is the speed of the convergence. Does this result have a name? So if you know a book or a pdf file that studies this problem, it would be very nice of you to let me know. Thank you in advance.","['reference-request', 'polygons', 'reference-works', 'geometry']"
2694952,"Integration trick $\int^{2\pi}_{0} f(a+ r \cos \theta, b+r\sin \theta)d\theta=2\pi f(a,b)$","While looking for some nice integrals that are not taught in school, I found this theorem: Suppose $f$ is a bivariate harmonic function; $(a,b)$ is a point in the plane; and $r$ is a positive real number. Then, $$
\int^{2\pi}_{0} f(a+ r \cos \theta, b+r\sin \theta)d\theta=2\pi f(a,b)
$$ Is there a nice way to prove the theorem above? Unfortunately I have no idea how to start proving this, but I suspect it's related to Euler's formula since there is an example there that can be solved that way. Source $\longrightarrow$ Integration Tricks | Brilliant Math & Science Wiki","['harmonic-functions', 'proof-writing', 'integration']"
2694975,How to prove $\textbf{n}d^2\sigma=\frac{\partial r}{\partial u} \times \frac{\partial r}{\partial v}dudv$,"How to prove $$\textbf{n}d^2\sigma=\frac{\partial r}{\partial u} \times \frac{\partial r}{\partial v}dudv$$ where $\sigma$ is an open surface that has a smooth parameterization $\textbf{r}(u,v)$ and $\textbf{n}$ is the unit vector normal to the oriented surface, using the notion of a Jacobian? I understand that the cross product gives a vector normal to the surface, but I am not sure how to justify this rigorously. On the internet, most sources use this fact as if it is obvious so I am finding it difficult to find a formal argument that justifies this claim. Perhaps someone has an idea how to prove this?",['multivariable-calculus']
2694987,Analogue of Fermat’s Little Theorem,The question is “Establish an analogue of Fermat’s Little Theorem for the ring $\mathbb{Z} [\sqrt{-2}]$.” I know how to do this for the cases where $\mathbb{Z} [\sqrt{3}]$ and $\mathbb{Z} [\sqrt{5}]$ by letting $\alpha \in \mathbb{Z} [\sqrt{3}]$ so there exists integers $a$ and $b$ s.t $\alpha^{p}=(a+b\sqrt{3})^p$ where $p$ is prime. Then by binomial expanding and using Fermat’s Little Theorem you get $\alpha^{p}=a+b(\sqrt{3})^{p}$ mod$p$. Then you can use Euler’s criterion and the definition of the Legendre symbol for $(\frac{3}{p})$ to establish an analogue. However if I follow this through for the ring $\mathbb{Z} [\sqrt{-2}]$ I get the Legendre Symbol $(\frac{-2}{p})$and I have no idea how to calculate it. Am I doing something wrong or is this the correct method and am I just stumbling at the final part?,"['number-theory', 'legendre-symbol']"
2696009,Some doubts in derivative questions containing function,I am learning questions in which we have to prove that a function is differentiable and continuous at a point. Let I have to find that a function f is differentiable at x = 3. Then i saw on some place they simply find $\frac{f(x)-f(3)}{x-3}$ at limit x $\to$ 3 and then LHD and RHD. On some places they find only LHD and RHD. Similarly for checking function is continuous. So i want to ask which method is correct?,"['derivatives', 'functions']"
2696034,"A box has an unknown number of tickets serially numbered 1,2,...,N. Two tickets are drawn using simple random sampling without replacement","A box has an unknown number of tickets serially numbered 1,2,...,N. Two tickets are drawn using simple random sampling without replacement (SRSWOR) from the box. If X and Y are the numbers on these two tickets and $Z = max(X,Y )$, show that (a) Z is not unbiased for N (b) $aX+bY +c$ is unbiased for N if and only if $ a+b = 2 \text{ and}\ c = −1.$ What is the the pmf of Z,  Any tips on how to proceed?","['self-learning', 'statistics', 'estimation', 'sampling']"
2696087,Relation between matrices and a function composed with itself,"I was looking through an older notebook and I saw this problem that I dont understand, it says if$$f(x) =\frac{3x+1}{1-x},x\neq1
 $$Compute $$F=\underbrace{f \circ \dots \ \circ f(4)}_{2016\:\text{times} }$$ I have  this as a solution. 
Consider: $$A=\begin{pmatrix} 3&1\\-1&1\end{pmatrix}$$ then $$A\begin{pmatrix} x\\1\end{pmatrix}=
\begin{pmatrix} 3x+1\\-x+1\end{pmatrix}$$ and $$F=A^n \begin{pmatrix} x\\1\end{pmatrix}$$ It's indeed easy to prove by induction after computing a few powers of A that $$A^n=2^{n-1}\begin{pmatrix}n+2&n \\-n&-n+2\end{pmatrix}$$now taking $x=4$ and multiplying both sides by $\begin{pmatrix} x\\1\end{pmatrix} $ we have that$$A^n\begin{pmatrix} 4\\1\end{pmatrix}=2^{n-1}\begin{pmatrix}5n+8\\-5n+2\end{pmatrix} $$So for $n=2016$ we have $$F=\frac{5\cdot2016+8}{-5\cdot2016+2}=-\frac{5044}{5039}$$ Now, to be clear I don't understand why putting the coefficients of a function into a matrix would not deteriorize my answer, or why does this work? Can we use the same method to higher powers of $x$? and what if we had for example $$f(x)=(3x+1)(1-x)$$ what matrix should be considered? I would love to get clarifications if possible, many thanks in advance!","['matrices', 'functions']"
2696097,Evaluate $ \lim_{n\to \infty} ( \lim_{x\to0} (1+\tan^2(x)+\tan^2(2x)+ \cdots + \tan^2(nx)))^{\frac{1}{n^3x^2}} $,"$ \lim_{n\to \infty} ( \lim_{x\to0} (1+\tan^2(x)+\tan^2(2x)+ \cdots + \tan^2(nx)))^{\frac{1}{n^3x^2}} $ The answer should be $ {e}^\frac{1}{3} $ I haven't encountered problems like this before and I'm pretty confused, thank you. I guess we must use the remarkable limit of $ \frac{\tan(x)}{x} $ when $ x $ approaches $ 0 $ by dividing and then multiplaying with $x$.","['calculus', 'limits']"
2696120,"How to show that $\Psi: E \rightarrow E$, $\Psi(f) = \sin(f(t))$ is continuous and differentiable?","Let $E = \mathcal{C}([0,1],\mathbb{R})$ a Banach space of continuous fonctions mapping from $[0,1]$ to \mathbb{R}, with the norm $||f|| = \underset{t \in [0,1]}{\sup}|f(t)|$. Let $\Psi : E \rightarrow E$ defined as $\Psi(f) = \sin(f(t)), \forall f \in E, \forall t \in [0,1] $. 1) Verify that $\Psi$ is continuous 2) Show that $\Psi$ is Frechet differentiable on $E$, and find its differential. I trying to solve this exercise, but I struggle a lot. I think that to show its continuity, you have to show that $\Psi$ is a composite function of two continuous functions. Once you manage to describe $\Psi$ with the composition of two functions, answering the second question might be more easier. The issue I get with the composition, is that my intuition first tells me that $$\Psi(f) = g \circ u $$ where $u:E \rightarrow \mathbb{R}$ such that $u(f) = f(t)$ and $g: \mathbb{R} \rightarrow \mathbb{R}$ such that $g(x)=sin(x)$ Now this is obviously false as $\Psi$ maps to $E$ and not $\mathbb{R}$. Can someone help me to find the two functions that fit?","['derivatives', 'frechet-derivative']"
2696122,Prove: $|\mathbb{N}|\leq |\mathbb{R}|$,"Prove: $|\mathbb{N}|\leq |\mathbb{R}|$ Note: $|\cdot|$ denotes cardinality. My work Suppose $|\mathbb{N}|\geq |\mathbb{R}|$ We can write $\mathbb{R}=\mathbb N\cup(\mathbb Q-\mathbb N)\cup\mathbb{I}$ then  $$|\mathbb{R}|=|\mathbb N\cup(\mathbb Q-\mathbb N) \cup \mathbb{I}| = |\mathbb{N}| + |\mathbb{Q-N}| + |\mathbb{I}| = |\mathbb{N}| + |\mathbb{Q}| - |\mathbb{N}|+|\mathbb{I}|$$ Then, $$|\mathbb{N}|+|\mathbb{Q}|-|\mathbb{N}|+|\mathbb{I}|\leq|\mathbb{N}|\implies |\mathbb{Q}|+|\mathbb{I}|\leq|\mathbb{N}|$$ Here i'm stuck. Can someone help me?",['elementary-set-theory']
2696148,Counter example which violate uniform continuity...,"For a given continuous function $f:\mathbb{R}\rightarrow\mathbb{R}$, define a sequence of function $\{f_n\}_{n\in \mathbb{N}}$ by $$f_n(x):=f\Big(x+\frac{1}{n}\Big).$$
Now if $f$ is uniformly continuous, then I can show that {$f_n$}
converges to $f$ uniformly. At this point, I was thinking about the converse, i,e; if {$f_n$} defined above converges to $f$ uniformly, does that imply the uniform continuity of $f$. I think the answer is negative, but I am not getting any counter example for that. Does anyone have any counter example?","['uniform-continuity', 'real-analysis', 'uniform-convergence']"
2696162,Is this the (real) algebraic numbers?,"I want to construct the real algebraic numbers from $\mathbb{Q}$ in a manner that sort of ""looks like"" the construction of the complex numbers from the reals, in a superficial manner. I can't define a single ""irrational unit"", but I instead tried to start with the set $\{ \sqrt{z} \mid z \in \mathbb{Q} \}$ and build the algebraic numbers from there. This is what I'm thinking: Let $A_{0} = \{ q + p \sqrt{z} \mid  q, p, z \in \mathbb{Q} \}$. In general, let $A_{n} = \{ q + p \sqrt{z} \mid q, p, z \in \mathbb{Q} \cup A_{0} \cup \dots \cup A_{n-1} \}$. Let $A = \cup_{i=0}^{\infty} A_{i}$. Is $A = \mathbb{A}$? If not, what's missing, and if so, can this description be simplified in some way? Thanks all.","['complex-numbers', 'abstract-algebra', 'extension-field', 'rational-numbers', 'field-theory']"
2696239,Comparing sets of possible values,"Say $x$ is a real number, can one argue that the set of possible values for $x$ when $x < 2$ is less than when $x < 4$? Is this mathematically true? One could argue that the set of possible values in the latter case contains that of the former case, plus other values. But, we are comparing infinite values.","['real-numbers', 'infinity', 'elementary-set-theory']"
2696241,"$n$th order linear IVP with explicit time dependent coefficients, existence and uniqueness","I am looking for the proof that the following $n$th order ODE
$$
y^{(n)}(t)+p_{n-1}(t)y^{(n-1)}(t)+\cdots+p_1(t)y'(t)+p_0(t)y(t)=g(t)
$$
for $t\in (a,b)$ and $p_i$ and $g$ continuous on $(a,b)$ with 
$$
y(t_0)=y_0,y'(t_0)=y_0',\dots,y^{(n-1)}(t_0)=y_0^{(n-1)}
$$
for some $t_0\in (a,b)$ has a unique solution on the entire interval $(a,b)$. This is as stated in Boyce and De Prima. However, a proof is not offered. Furthermore, I dug up the referenced text and couldn't find a proof there either (the edition was different, so it is possible I missed it). Hirsch Smale and Devaney just asserts a result for non explicitly $t$ dependent coefficients and then moves on to fully nonlinear equations and dynamics. I am hoping for a more nitty gritty proof. And for convenience, I would be fine with taking $n=2$ if it extrapolates nicely. My ideas to proceed; we can certainly reduce this to a system of first order ode's (and I think it suffices to examine the homogeneous version by variation of parameters) and try and prove existence and uniqueness in the first order cases. However, what troubles me is I don't see how to use Picard's theorem to get existence and uniqueness on the whole interval where all the $p_i$ are continuous. Wouldn't we need to restrict to a (sufficiently small) compact subset to make sure the integral operator we define is a contraction for the Banach fixed point theorem argument to go through? I confess I haven't worked out all the details myself, so I apologize if I missed something obvious. I am also not that familiar with the Wronskian, and maybe that's where the solution will come from.","['functional-analysis', 'reference-request', 'real-analysis', 'ordinary-differential-equations']"
2696314,"Prove that $\mathbb{Q}^{*} \cong (\mathbb{Z}[x],+)$","Let $\mathbb{Q}^{*}$ be the multiplicative group of positive rational numbers. Prove that $\mathbb{Q}^{*}$ is isomorphic to $(\mathbb{Z}[x],+)$. My intuition is telling me that this is not true, but this is what my book is asking me to prove. I have tried to think of a isomorphic mapping for a while now and the best I can do is a homomorphism namely, 
$$\phi(a_0+a_1x+ \cdots a_nx^n)=\frac{a_0}{a_n}$$
If anyone could verify that these really aren't isomorphic or give me a hint on how to get started that would be greatly appreciated, thanks! EDIT: From the hint in the comments I have come up with this,  Let $a=p_1^{a_0}p_2^{a_1}\cdots p_n^{a_n}$ and $b=p_1^{b_0} p_2^{b_1} \cdots p_n^{b_n}$ so that $\frac{a}{b}=p_1^{a_0-b_0} \cdots p_n^{a_n-b_n}$ and then considering the mapping 
$$\phi(\frac{a}{b})=(a_0-b_0)+(a_1-b_1)x+ \cdots (a_n-b_n)x^n$$ then verifing that this is an isomorphism. Would this be correct?","['abstract-algebra', 'polynomials']"
2696339,What is the area of the shaded region in this rectangle?,What is the area of the shaded region below? I think the solution requires subtracting the area of each of the four triangles from the area of the rectangle. I can calculate the area of triangles a and b since I have a base and height. But I don't see how to calculate the height of triangles c and d. I've tried drawing a line parallel to the 3 cm width of the rectangle that intersects with the point where triangles c and d touch. The height of that line (call it h) along the 4 cm height of the rectangle would give me the height of both triangles c and d. But I don't see how to derive h.,"['area', 'triangles', 'geometry']"
2696411,Zeros of power series with polynomially bounded integer coefficients,"Consider the set $\mathbb{Z}_P[[X]]=\left\{ \sum_{n=0}^\infty a_n X^n \in \mathbb{Z}[[X]]\mid \exists k \in \mathbb{N_0}\colon (a_n)_{n\in\mathbb{N}_0} \in \mathcal{O}(n^k)\right\}$. It is easy to show that the elements of $\mathbb{Z}_P[[X]]$ have radius of convergence equal to 1, except for the polynomials. I am interested in the set $N_P =\left\{ \beta \in (-1,1) \mid \exists f(X) \in \mathbb{Z}_P[[X]] \colon f(\beta) = 0\right\}$. We have $\mathbb{A} \cap (-1,1) \subseteq N_P$, were $\mathbb{A}$ are the algebraic numbers. Question: What is known about the set $N_P$? Do we have $N_P = \mathbb{A} \cap (-1,1)$, or $N_P = (-1,1)$, or neither? Some things to note: If we consider uniformly bounded coefficents – that is, we replace $\mathcal{O}(n^k)$ above with $\mathcal{O}(1)$ – the functions we get are all rational functions ( see for example this paper by Borwein et al. ). The set of corresponding zeros is thus equal to $\mathbb{A} \cap (-1,1)$. Edit : I may have misunderstood the paper. I will follow up on this. Edit 2 : I definitely misunderstood the paper. The functions are not in general rational functions. The following theorem holds: For $\gamma \in (-1,1)$ there is a power series with integer coefficients $g(X) \in \mathbb{Z}[[X]]$ such that $g(\gamma) = 0$ ( see for example this math.stackexchange question ). The question is whether one can construct $g$ in such a way that the coefficients are polynomially bounded.","['abstract-algebra', 'formal-power-series', 'power-series']"
2696453,Prove that Voronoi cells are path-connected,"Let we have a similarity function $d: \mathbb{R}^n \times \mathbb{R}^n \to \mathbb{R}$. It can be a metric, but not necessarily it. We introduce the natural generalization of Voronoi cells in terms of this similarity function. Let we have a finite set of $n$-dimensional vectors $X$. We call the Voronoi cell $R_k$ associated with the element $x_k \in X$ the following set
$$ R_k = \{x \in \mathbb{R}^n| d(x, x_k) < d(x, x_j)~\forall j\ne k \}$$ My question is: what property we have to require from $d(x,y)$ for all Voronoi cells be path-connected for all possible finite sets $X$? My conjecture is that this is in some way related to convexity $d(x,y)$. I can prove path-connectedness in some particular cases of $d(x,y)$. For example, if $d(x,y) = \|x-y\|_2$ then the border between two points is linear, so every Voronoi cells is a polyhedron is this case. Another easy case is linear functions. In this case let $u$ and $v$ be arbitrary points from one Voronoi cell $R_x$ for $x \in X$. So $d(x, u) < d(w, u)$ and $d(x, v) < d(w, v)$ for $\forall w \ne x$. Hence
$$ d(x, tu + (1-t)v) < d(w, tu + (1-t)v),~t\in[0,1] $$
So the Voronoi cell is convex. It would be wonderful to find a necessary and sufficient condition for the path-connectedness of Voronoi cells, but it is enough for me to simply have a richer class of functions than the ones I have. Great thanks for any advices, ideas, papers and so on!","['general-topology', 'computational-geometry', 'functions', 'geometry']"
2696472,Why use 95% confidence interval?,"May I ask why $95\%$ confidence is so commonly used? Does it have anything to do with $\frac{d}{d\alpha}e_n(\alpha)$, where $e_n(\alpha) = Z_{\alpha/2}\frac{S_n}{\sqrt n}$? (My professor asks me to evaluate this derivative at $\alpha = 0.05$, given $S_n = 4.7, n = 100$.)","['derivatives', 'confidence-interval', 'normal-distribution']"
2696505,How to find the image under a Möbius transformation.,"Find the image of the set $D_1\cap D_2$, where $$D_1 = \{z : |z| < 1\}$$ and
$$D_2 = \{z : |z + 1/2| > 1/2\}$$ under the transformation
$$f(z) = \frac{z − i}{z + 1}$$ I have done the picture of $D_1\cap D_2$, but I don't know how to do it. If anybody could help me, please. Thanks!",['complex-analysis']
2696539,"Surjective map from $\mathrm{SL}(2, \mathbb{Z})$ to $\mathrm{SL}(2,\mathbb{Z}/n\mathbb{Z})$","Can anyone refer me to a complete proof of that there exist such surjective maps? I looked this up and in these notes the part of showing $b'$ exist is omitted. I still haven't figured out how to show, for example, $(b+x·(a,n),a)=1$ can be solved for $x$ when $(a,b,n)=1$ . Thank you! Edit: I'm not sure how to show that taking all coefficients $\bmod n$ will give you a surjective map. In Conrad's notes from the link above, one step is omitted: given three integers $a,b,n$ such that $\gcd(a,b,n)=1$ , there must exist an integer $b'$ such that $b'\equiv b \bmod n$ and $b'$ is coprime with $a$ . If there is another way of showing that the $\bmod n$ map is surjective, I'd like to hear about that, too.","['smith-normal-form', 'matrices', 'determinant', 'gcd-and-lcm', 'elementary-number-theory']"
2696541,How to prove the following application of the Stiltjes series expansion,"We begin with a density given by
$$
\tag 1
K(\xi)=\sum_{k=1}^K p_k\delta\left(\xi -\xi_k\right) 
$$ The question is how to prove the following
$$
\tag 2
\int_0^{max(\xi)}K(\xi)\frac{(z\xi)^{1-K}}{1-z\xi}d\xi=\sum_{k=1-K}^{K}z^kM_k
$$ where the moment equation 
$$
\tag 3
\sum_{k=1}^Kp_k(\xi_k)^m=M_m,
$$
holds. 
I don't understand how the summation limits in (2) are derived and why the term $(z\xi)^{1-K}$ is needed. I also don't understand how this relates to the formula for the Stiltjes transformation given here Motivation:
The reasoning behind this is to find the values of $\xi_k$. This is done using the theorem, which states that if we would define 
$$
f(z)=\int_0^\infty\frac{d\phi(u)}{1-zu}
$$
for a real, non-decreasing and bounded function $\phi(x)$ for $x\in[0,\infty)$, for $\forall z \in \mathbb{C}\setminus \left ( \mathbb{R}^+ \right ) $ exists the series expansion in terms of the moments $f_j$
$$
f(z)=\sum\limits_{j=0}^\infty f_j z^j
$$ By using the $[N+1][N]$ Pade expansion it can be shown that $$
f(z)=\frac{a_0+a_1z+a_2z^2+\dots +a_{N+1}z^{N+1}}{b_0+b_1z+b_2z^2+\dots +a_{N}z^{N}}=\sum\limits_{i=1}^N\frac{w_i}{z-z_i}.
$$ In that case the poles $z_j$ are simple and real. The proof of the above statement can be found in this paper . (pdf link)","['complex-analysis', 'pade-approximation', 'measure-theory', 'power-series']"
2696571,Equivalence between a SDE and an ODE,"Let $X$ be a continuous semimartingale. We look at the following SDE $$dY(t)=Y(t)dX(t)$$ with $Y(0)=1$ and $Y>0$. The above notation means $Y(t) = 1 + \int_0^t Y(s) \, dX(s)$, it's just a notation. Wikipedia says that if $X$ is differentiable (meaning it sample paths are differentiable), the equation is equivalent to the ODE $$Y'(t)=Y(t)X'(t)$$ Is there a way to see this without solving the SDE ?","['stochastic-processes', 'real-analysis', 'stochastic-integrals', 'ordinary-differential-equations', 'stochastic-calculus']"
2696598,Evaluate $\int_0^\infty{\frac{\tan x}{x^n}dx}$,"For$$PV\int_0^\infty{\frac{\tan x}{x^n}dx}$$
I can prove that it converges when $0<n<2$. I know the ways to evaluate$$PV\int_0^\infty{\frac{\tan x}{x}dx}=\frac\pi2$$
but both of these 2 ways doesn't work. First, using contour integration: the path used in evaluating the second integral doesn't fit in with the first one and I can't find a suitable path to the integral. Second, seperating the integral: I had to calculate
$$\sum_{k=0}^{\infty}{\int_0^{\pi /2}{\tan t\left( \frac{1}{\left( k\pi +t \right) ^n}-\frac{1}{\left( \left( k+1 \right) \pi -t \right) ^n} \right) dt}}$$
which is unable to be solved by Mathematica. I can't go further.","['integration', 'definite-integrals', 'calculus']"
2696600,Application of rook polynomials (GFs) to pairing problem.,"There has to be a way to use rook polynomials to solve this question : How do I find the number of ways 8 people can be formed into pairs with the constraint that they cannot work with the same person they worked with [on a previous] project? The restricted cells on the board would naturally be the diagonal (participants cannot be paired with themselves), as well as the cells corresponding to the pairings in the first project. There are $105$ possible pairs of $8$ people. In addition, the pairs of participants force symmetry along the diagonal. The calculus of the coefficients is probably in the sequence AO54479 - OEIS as noted in one of the answers. However, I would like to see how these coefficients can be built up from the ground up.","['generating-functions', 'combinatorics', 'discrete-mathematics']"
2696628,Multiplying both sides of an equation in proofs,"I'm learning the basics of group theory, and must justify every step of a proof by referring to the basic axioms/theorems. Which axioms/theorems justify multiplying or adding an element of a group to both sides of an equation?","['axioms', 'group-theory']"
2696637,Translation of integration contour,"I have an argument where, with a meromorphic function $\phi$ satisfying $\phi(s) = \phi(1-s)$, the following equality appears:
$$\int_{(2)} \phi(s) y^{-s} \, ds = \int_{(1/2)} \phi(s) y^{-s} \, ds$$ where the integration domains are the vertical lines of real part fixed to $2$ and $1/2$ respectively. For me a change of variables would give a relation between integrals on $(2)$ and $(-1)$, because these are symmetric with respect to $s \mapsto 1-s$, however I do not understand why the equality above is true. Is there any standard trick I should see to prove it?","['complex-analysis', 'analytic-number-theory', 'riemann-zeta', 'analytic-continuation']"
2696645,What is the structure sheaf of an $S$-scheme?,"Let $X$ be an $S$-scheme. That is there exists a morphism of schemes $X \to S$, in particular we can view $X$ as a family over $S$. Also, suppose that $X$ is a $k$ scheme, i.e there exists a morphism $X \to \operatorname{Spec} k$? How would you describe the structure sheaf on $X$ as a scheme over $k$ vs. the structure sheaf on $X$ as a scheme over $S$? More generally, I am a bit confused as to how the ring of functions on a scheme $X$ is affected by a scheme parameterizing $X$. Maybe there exists something like a relative structure sheaf $\mathcal{O}_{X/S}$ vs. $\mathcal{O}_X$...","['schemes', 'algebraic-geometry']"
2696650,An Example dealing with the Chi-Square Test,"Problem: In $60$ tosses of a coin, $37$ heads and $23$ tails were observed. Test the
hypothesis that the coin is fair, using a significant level of (a) $0.05$, (b)
$0.01$. Answer: \begin{eqnarray*}
df &=& 2 - 1 = 1 \\
\chi^2 &=& \frac{(37-30)^2}{30} + \frac{(30-23)^2}{30} \\
\chi^2 &=& \frac{49}{30} + \frac{49}{30} = \frac{49}{15} \\
\chi^2 &=& 3.26667 \\
\end{eqnarray*}
Using software I find that $P(\chi^2 < 3.26667) = 0.93$. Therefore, I reject the idea the coin is fair at both the $0.05$ and $0.01$ levels. The book's answer is: The hypothesis cannot be rejected at either level. What did I do wrong? Bob","['statistics', 'probability', 'probability-distributions']"
2696652,Prove $\nabla^2 f(x) \preceq L I$ for convex $f$ with Lipschitz gradient,"I am given a convex and twice differentiable function $f$ whose gradient is Lipschitz with constant "" $L$ "". I am trying to prove $$
\nabla^2 f(x) \preceq L\,I.
$$ I recognize that this is pretty easy, and suspect the proof will invoke the definition of the Hessian. From $f$ having Lipschitz gradient, we know $\|\nabla f(x) - \nabla f(y)\| \lt L\,\|x - y\|$ . And therefore $$
\lim_{x \to y} \frac{\|\nabla f(x) - \nabla f(y)\|}{\|x - y\|} \lt 
\frac{L\,\|x - y\|}{\|x - y\|}
~~\Longrightarrow ~~\nabla^2 f(x) \preceq LI.
$$ But this isn't quite right since the Hessian is a matrix and the quantities inside the limit to the left of the implication arrow are scalars. What is the proper way to prove this? Any help here would be helpful :-)","['multivariable-calculus', 'real-analysis', 'convex-analysis']"
2696661,How does Law of Total Probability apply here?,Cumulative Distribution Function for Sum of Continuous Distributions That means $X\in x$ is a partition of $X+Y$ ? But how could that be? It only accounts for the $X$ part.,['statistics']
2696725,How to cut fried eggs with mathematical elegance and perfection,"Suppose you have fried $N$ eggs and your entire, perfectly circular pan is filled with egg white and $N$ perfectly circular, non-overlapping egg yolks of equal size. How would you cut the egg white using only a finite amount of straight lines so that each of your $N$ egg sandwiches will have exactly one yolk and the same amount (area) of egg white? It is allowed to let the lines pass trough the yolk, but you do not actually cut it; the yolk circles have to remain intact (until you pop them and let the delicious yolk flow over your sandwich). EDIT: (From a discussion in the comments) The yolks do not actually have to stay connected to the egg white, you can picture the yolks as holes in the white. When the white has been distributed well, the yolks can then be added to each sandwich. EDIT 2: For the sake of clarity, I'd like to add that in my original train of thought, line segments and half lines are also allowed as cuts, not just lines. Just like you would be able to cut in real life. But the line-only case could be interesting, too! Bonus points if you manage to solve it that way :) For $N=2$, I have found out that taking the midpoint $M$ between the centres of the two yolks and cutting along the line that passes trough the centre $C$ of the pan and M cuts the white evenly almost always, although in some cases you have to ""jump over"" the yolks while cutting, but this is okay (see image below). The only exception is $C=M$, but in that case just cut along the perpendicular of the line between the midpoints of the yolks! This is a (rather simple) case-by-case construction and I was wondering if there is a construction that just works as it is, without having to consider cases. I'm looking for a case-free solution (construction) to the general problem, too. Any construction for other specific cases are welcome too! I'm having trouble formulating what tools are exactly ""allowed"" for the construction, so right now I'd say: anything goes, as long as it's nothing trivial like ""take the line that cuts surface A precisely in half"" without specifying how to construct that line. I hope this example gives you an idea of what I'm looking for, or at least what I'm not looking for. On the other hand, anything interesting that can be said regarding this (kind of) problem, perhaps form a more abstract and deep mathematical point of view, is also very appreciated! For instance, I would find it interesting to see an answer which does use these kind of ""trivial"" lines like I described above, although it will not answer my question! An example of the ""jump over"" case as described above:","['recreational-mathematics', 'euclidean-geometry', 'geometric-construction', 'geometry']"
2696747,Limits Involving $e$ - Is this acceptable?,"I'm currently studying a course in real analysis and have come across the following well known limit: $$\lim _{n\to\infty}\left(1 + \frac{1}{n}\right)^n=e$$ My question is: If you were given a question that asked you to compute $\lim _{n\to\infty}e^{1/n}$, would it be acceptable to do the following? $$\lim _{n\to\infty}e^{1/n}=\lim _{n\to\infty}\Bigg(\left(1 + \frac{1}{n}\right)^n\Bigg)^{1/n}=1$$ I know you could just take the limit of the power of $e$ in this case, but I'm just thinking for harder questions that I have found.","['real-analysis', 'limits']"
2696772,I need a function that abides by this definition: $F(x+1)-F(x)=x$,"I am trying to find a solution to the differential equation:
$$\frac{\mathrm{d}y}{\mathrm{d}x}=\lfloor{x}\rfloor.$$
And one solution is $$F(x+1)-F(x)=x.$$
I do not know any strategies to determine the definition of the function $F(x)$. I have seen that some Riemann functions have some functional definitions like this, and I was wondering if anyone knows a function that has the definition: $F(x+1)-F(x)=x$.",['ordinary-differential-equations']
2696808,"Unbiased Estimator for $\sigma^2$ in $N(0,\sigma^2)$","Consider $N(\mu,\sigma^2)$ and pick independent $X_1, \cdots, X_n$. It is a well known fact that the MLE estimator $$ S_n^2= \frac 1 n\sum(X_i - \overline X_n)^2 $$ is a biased estimator for $\sigma^2$. If we suppose $\mu= 0$, then I get it is unbiased. Am I wrong? Thanks!","['probability-theory', 'probability', 'statistics', 'statistical-inference']"
2696816,lower limit topology to the metric topology,"Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a function that is continuous from the right; that is, for all $a \in \mathbb{R}$, $\lim_{x \to a^{+}} f(x) = f(a)$ a) Show that $f$ is continuous when viewed as a function from $\mathbb{R}$ with the lower limit topology to $\mathbb{R}$ with the metric topology. b) Describe the set of functions $f: \mathbb{R} \rightarrow \mathbb{R}$ that are continuous when the domain is given the metric topology and the codomain is given the lower limit topology. What I am thinking: Since $f$ is right continuous at $a$: $\forall \epsilon >0$ $\exists \delta >0$ such that $\forall x$ with $a < x < a +\delta$ then $|f(x) - f(p)| < \epsilon$. So for any open neighborhood of $U$ of $f(a)$, we have an open neighborhood $V$ of $a$ so that $f(V) \subseteq U$. Thus $f: (\mathbb{R},\mathcal{T}_1)\rightarrow (\mathbb{R}, \mathcal{T}_2)$ which goes from the lower limit topology to the metric toplogy. I'm not sure this answers the question in its entirety and I'm not even sure if I'm correct. And for part B, I'm just genuinely confused, I think I have an idea but I'm pretty sure I'm wrong, so any help is really appreciated.",['general-topology']
2696823,Probability - A Conceptual Doubt,"Why, when calculating the conditional probability of A given B, do we assume
that the probability of B is greater than zero?","['combinatorics', 'probability']"
2696860,Seemingly negative set cardinality in textbook,"So in a textbook, the question states: There are 90 students and each of them must study at least one of Biology, Physics, or Chemistry. There are 36 students who study Biology, 42 who study Physics, and 40 who study Chemistry. Moreover, 9 study Biology and Physics, 8 study Biology and Chemistry, and 7 study Physics and Chemistry. How many students study all 3 subjects? Initially, I tried to solve it with the inclusion-exclusion principle. As such, I rearranged the equation $n(A\cup B\cup C)=n(A)+n(B)+n(C)-n(A\cap B)-n(A\cap C)-n(B\cap C)+n(A\cap B\cap C)$ into $n(A\cap B\cap C)=n(A\cup B\cup C)-n(A)-n(B)-n(C)+n(A\cap B)+n(A\cap C)+n(B\cap C)$, and substituted the values in, which is $n(A\cap B\cap C)=90-36-42-40+9+8+7$. However, this means that $n(A\cap B\cap C)=-4$, and hence the set has negative cardinality unless I have done something wrong. The answer is the back of the book is $4$, which leads me to believe that there is a mistake in the question. I also checked with a venn diagram, which also supports the answer being $-4$. Are there any issues with my working, or is the question incorrect?","['inclusion-exclusion', 'elementary-set-theory']"
2696866,Theorem: Annihilator of a $Y$ a subspace of $X$,"If $X$ is a normed vector space and $Y$ is a closed subspace, then $X^{*}/Y^{0}$ is isometrically linearly isomorphic to $Y^{*}$. Here, $X^{*}$ denotes dual space of $X$; $Y^{0}$ denotes annihilator of $Y$. Please provide some hints to prove this statement. I have been able to prove that for an $f\in Y^{*}$ there exists an $f_{\text{ext}}\in X^{*}$ with the same norm, using Hahn-Banach theorem. But I am struggling with proving the linearity part. For example, if $f,g\in Y^{*}$ with norms $\|f\|$ and $\|g\|$, and have extensions $f_{\text{ext}}$ and $g_{\text{ext}}$. Does $f+g$ has the extension $f_{\text{ext}}+g_{\text{ext}}$ with same norm as $\|f+g\|$. Note: The same question has been asked at annihilator subspace of normed space . But it does not contain a reasonable answer.","['functional-analysis', 'self-learning']"
2696999,Verifying Christoffel Symbols of Sasaki Metric,"In Sasaki's original 1958 paper defining his metric on the tangent bundle $TM$, he gives expressions for the Christoffel symbols, in terms only of quantities from $M$ (pg. 352). For the simple example of a 2D surface $(x,y,f(x,y))$ where the metric tensor is the first fundamental form, I wanted to compute the Christoffel symbols of the associated Sasaki metric. Unfortunately, I am unable to reproduce his results, unless i am misreading them. My question is: what are the Christoffel symbols of $TM$ for the 2D surface defined above? Here are the details of what I'm trying to do.
Consider the surface defined by $z=f(x,y)$ as a manifold $(M,g)$ with metric tensor given by
$$ g = \begin{bmatrix} 1 + f_x^2 & f_xf_y\\ f_xf_y & 1 + f_y^2 \end{bmatrix} $$
where $\partial_x f = f_x$ and $\partial_y f = f_y$. Let $n=2$ be the dimension. Given $g$, we can compute the Christoffel symbols $\Gamma_{jk}^i$ and Riemann curvature tensor $R_{ijk\ell}$. (These correspond to the ""manual"" quantities in the code below). Next, consider the tangent bundle $TM$ (where $M$ is as just above). We want to consider $TM$ as a Riemannian manifold $(\hat{M},g_\text{Sasaki})=(TM,\hat{g})$, where $\hat{g}$ is the Sasaki metric, defined via:
$$
\begin{cases}
\displaystyle\hat{g}_{jk} = g_{jk} + g_{\beta \gamma}\Gamma_{\mu j}^\beta \Gamma_{\eta k}^\gamma v^\mu v^\eta \displaystyle \\
\displaystyle \hat{g}_{j(n+k)} = g_{k\mu}\Gamma_{\lambda j}^\mu v^\lambda\\
\displaystyle\hat{g}_{(n+j)(n+k)} = g_{jk} 
\end{cases}
$$
written in terms of the quantities from the lower ""base"" manifold $M$, with indices going from $1$ to $2$. 
$v=(v^1,v^2)$ are coordinates on the tangent space. In this case, $g$ is $2\times 2$, so $\hat{g}$ is $4\times 4$, because $T\hat{M}=TTM$. (As an aside, this is almost directly from Sasaki's paper; hopefully I did not make a notational mistake or misunderstanding. In particular, I translated 
$[\lambda\;j,k]$ 
as 
$g_{k\mu}\Gamma_{\lambda j}^\mu$. Also, I suspect my error may involve $v$, because at no point do I specify what $v$ is in the code). Overall, my goal is to compute the Christoffel symbols $\hat{\Gamma}$, Riemann tensor $\hat{R}$, Ricci tensor, and Ricci scalar of $(\hat{M},\hat{g})$, i.e. $TM$. However, I can't get my Christoffel symbols to match with the expressions given by Sasaki. In particular, he writes:
\begin{align}
%\begin{cases}
\hat{\Gamma}^I_{(n+j)(n+k)} &= 0\\
\hat{\Gamma}^i_{(j+n)k} &= \frac{1}{2}R_{kj\lambda}^\ell v^\lambda\\
\hat{\Gamma}^{n+i}_{(n+j)k} &= \Gamma_{jk}^i - \frac{1}{2}\Gamma_{\mu h}^iR_{kj\lambda}^h v^\lambda v^\mu \\
\hat{\Gamma}^{i}_{jk} &= \Gamma_{jk}^i + \frac{1}{2}\left( R_{kh\mu}^\ell\Gamma^h_{\lambda j} + R_{j h \mu}^\ell\Gamma^h_{\lambda k} \right)\\
\hat{\Gamma}_{jk}^{n+i} &= \frac{1}{2}\left( R^\ell_{j\lambda k} + R^\ell_{k\lambda j} + 2\frac{\partial \Gamma_{jk}^i}{\partial x^\lambda} \right)v^\lambda + \frac{1}{2}\Gamma_{\eta h}^h\left( R_{k\mu\ell}^h\Gamma^\ell_{\lambda j} + R_{j\mu\ell}^h\Gamma^\ell_{\lambda k} \right)v^\lambda v^\mu v^\eta
%\end{cases}
\end{align} However, when I simply take the coordinates $x,y,v^1,v^2$, compute the expression for $\hat{g}$, and run it through a library to get the Christoffel symbols, it does not match with the values given by the paper.
(My current code does not check all of the above expressions, just the first three.) In other words, I compute $g$, $\Gamma$, $R$, and $\hat{g}$ manually (well, actually I computed them separately with the same GR package). Then I compute $\hat{\Gamma}$ via (1) manually with Sasaki's expressions and (2) with a GR library. I then compare the expressions produced each way. Since, even in this simple case, the calculations are horribly long, here is a script to help in the computations.
I used the GR package GRQuick for Mathematica (just paste into the source folder to use).
(I figured the math here was more the focus than the Mathematica, else I would have posted there; let me know if that makes sense.) (** Manually define the tensors for (x,y,f(x,y)) in Cartesian coords **)
ClearAll[""Global`*""]
metricM[x_,y_] := Simplify[{ 
    {  1 + D[ f[x,y], x]^2 ,                       D[ f[x,y], x] D[ f[x,y], y]  }, 
    {  D[ f[x,y], x] D[ f[x,y], y] ,    1 + D[ f[x,y], y]^2  } 
}];
metric = metricM[x,y]
n=2
christoffelManual={{{(Derivative[1, 0][f][x, y]*Derivative[2, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2), 
    (Derivative[1, 0][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)}, 
   {(Derivative[1, 0][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2), 
    (Derivative[0, 2][f][x, y]*Derivative[1, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)}}, 
  {{(Derivative[0, 1][f][x, y]*Derivative[2, 0][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2), 
    (Derivative[0, 1][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)}, 
   {(Derivative[0, 1][f][x, y]*Derivative[1, 1][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2), 
    (Derivative[0, 1][f][x, y]*Derivative[0, 2][f][x, y])/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)}}}

riemannManual= {{{{0, (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2}, 
    {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}}, 
   {{0, -(((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)}, 
    {((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}}}, 
  {{{0, ((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2}, 
    {-(((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
       (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2), 0}}, 
   {{0, (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2}, 
    {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
      (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 0}}}}
ricciManual= {{-(((1 + Derivative[1, 0][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
     (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2), (Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*
     (-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2}, 
  {(Derivative[0, 1][f][x, y]*Derivative[1, 0][f][x, y]*(-Derivative[1, 1][f][x, y]^2 + Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
    (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2, 
   -(((1 + Derivative[0, 1][f][x, y]^2)*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/
     (1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)}}

manualRicciScalar = -((2*(Derivative[1, 1][f][x, y]^2 - Derivative[0, 2][f][x, y]*Derivative[2, 0][f][x, y]))/(1 + Derivative[0, 1][f][x, y]^2 + Derivative[1, 0][f][x, y]^2)^2)

(** Use GRQuick to get Sasaki metric **)
<< ""path/to/GRQUICK.m"";
(*** Construct Sasaki metric ***)
v = {v1, v2};
upperG[p_,v_,j_,k_] :=  metric[[j,k]] + Sum[  (* k,j \in {1,2} *)
metric[[beta,gamma]] christoffelManual[[beta,mu,j]]christoffelManual[[gamma,ell,k]]v[[mu]]v[[ell]],  
{beta,1,2},{gamma,1,2},{mu,1,2},{ell,1,2}
] 
offG[p_,v_,j_,k_] := Sum[
metric[[ell,k]] christoffelManual[[ell,lambda,j]] v[[lambda]],
{lambda,1,2}, {ell,1,2}
]
sasakiGMet[x_,y_,v1_,v2_] := FullSimplify[{
{ upperG[{x,y},{v1,v2},1,1], upperG[{x,y},{v1,v2},1,2], offG[{x,y}, {v1,v2},1,1], offG[{x,y}, {v1,v2},1,2] },
{ upperG[{x,y},{v1,v2},2,1], upperG[{x,y},{v1,v2},2,2], offG[{x,y}, {v1,v2},2,1], offG[{x,y}, {v1,v2},2,2] },
{ offG[{x,y}, {v1,v2},1,1],    offG[{x,y}, {v1,v2},2,1],     metric[[1,1]], metric[[1,2]] },
{ offG[{x,y}, {v1,v2},1,2],    offG[{x,y}, {v1,v2},2,2],     metric[[2,1]], metric[[2,2]] }
}]
Metin[sasakiGMet[x,y,v1,v2],{x,y,v1,v2}];

(** Checks against Sasaki's calculations **)
christoffelManualSasaki = Table[ (* Upper index first *)
Simplify[ Christoffel[{{i},{j,k}}] ],
    {i,0,3},{j,0,3},{k,0,3}
];
(* Check 1 *)
Table[christoffelManualSasaki[[ii,n+j,n+k]],{ii,1,4},{j,1,2},{k,1,2}] (* Should be all zero *)
(* Check 2 *)
(* Should be zeros; notice they vanish if I change the sign! *)
Table[Simplify[christoffelManualSasaki[[i,n+j,k]] - (1/2)(Sum[riemannManual[[i,k,j,lambda]]v[[lambda]],{lambda,1,2}]) ],{i,1,2},{j,1,2},{k,1,2}]
(* Check 3 *)
Table[
    FullSimplify[
        christoffelManualSasaki[[n+i,n+j,k]] - 
        (
            christoffelManual[[i,j,k]]  -  
            (1/2) (Sum[
            christoffelManual[[i,mu,h]] riemannManual[[h,k,j,lambda]]v[[lambda]] v[[mu]],
        {lambda,1,2}, {mu,1,2},{h,1,2}
        ] )
        )
    ],
{i,1,2},{j,1,2},{k,1,2}
] My hope is that there is some simple thing I am missing.","['riemannian-geometry', 'proof-verification', 'manifolds', 'tangent-bundle', 'differential-geometry']"
2697020,Integrating the following function,"I am asked to evaluate the integral
$$\int_{R^n}e^{-\sum_{i=1}^na_i^2x_i^2}\,dx$$
given that $a_1,a_2,\cdots,a_n$ are real numbers different from $0$. I am clueless on how to approach this, since I have never been exposed to these types of integrals. Any help is appreciated!","['real-analysis', 'integration', 'lebesgue-measure']"
2697038,How to check a function is positive definite?,"I recently learned about characteristic functions and in particular the Bochner Theorem which helps us ascertain when a given function is a characteristic function for some probability distribution. The standard version of Bochner's theorem from Wikipedia states that: 
For any normalized continuous positive definite function $f$ on $G$ (normalization here means $f$ is $1$ at the unit of $G$), there exists a unique probability measure on ${\displaystyle {\widehat {G}}}$ such that $${\displaystyle f(g)=\int _{\widehat {G}}\xi (g)d\mu (\xi )}$$ i.e. $f$ is the Fourier transform of a unique probability measure $\mu$ on ${\displaystyle {\widehat {G}}}$. In other words, any continuous positive-definite function on the real line is the Fourier transform (characteristic function) of a (positive) finite measure. Another version, which combines Khinchine’s theorem is stated as follows: Let $\phi: \mathbb{R} \to \mathbb{C}$ be a continuous function with $\phi(0) =1$. Then $\phi$ is a characteristic function $\iff$ $\forall n \in \mathbb{N}, t_i \in \mathbb{R}$ and $\lambda_i \in \mathbb{C}$ for $i = 1, \dots, n$, we have 
$$\sum_{i, j =1}^n \phi(t_i - t_j) \lambda_i \overline{\lambda_k} \geq 0$$ Wikipedia notes that the trouble with these theorems is that computational verification of the positive-definiteness is not easy. I'm curious to learn whether there is an effective/efficient way to check for positive definiteness of a function (or the condition in the second version provided below) because based on the definition of positive-definiteness for functions, it seems like we would have to prove the square matrices for all sizes and possible permutations are Hermitian. I am also aware of Polya's criterion as an alternative to deal with the problem motivating Bochner's theorem but are there any easy ways to verify that there exists a distribution such that a given function corresponds to the characteristic function for it. Until now, I have defined appropriate random variables to solve relatively direct problems (convex combinations of characteristic functions and square of the absolute value of a characteristic function also define characteristic functions).","['real-analysis', 'fourier-analysis', 'characteristic-functions', 'probability-theory', 'fourier-transform']"
2697062,Nyquist theorems for sampling in regularly spaced Taylor bases?,"The Nyquist / Shannon sampling theorem is like super famous in signal processing. It says that when doing regularly spaced point-wise sampling we need to sample a sinusoidal signal at least two times each period to avoid frequency aliasing . But what happens if we don't just sample the function value in instants in time, but say a local Taylor approximation? $$f_k(x) = \sum_{l=0}^Nc_{kl}(x-k\Delta_x)^l$$ For $N=0$ this becomes the usual sampling $f_k(x) = c_{k0}$, we only measure the function values but none of the derivatives. Below is an illustration of Nyquist phenomenon on a typical chirp signal. We see the catastrophy that occurs when the local frequency increases above the sampling rate prescribed by Nyquist. But what would happen if we could measure also the slope at the green points or even the second derivatives et.c.? Could we push the bound upwards?","['fourier-analysis', 'signal-processing', 'sampling', 'functional-analysis', 'soft-question']"
2697151,"If $\lim\limits_{x \to \infty} f(f(x))= \infty$, $\lim\limits_{x \to \infty} f(x)=\pm \infty$","Let $f: \mathbb{R} \to \mathbb{R}$ such that  $\displaystyle \lim_{x \to \infty} f(f(x))= \infty$ and $\displaystyle \lim_{x \to -\infty} f(f(x))= -\infty$ and $f$ has the intermediate value property (it is not necessarily continuous). Prove that $\displaystyle\lim_{x \to \infty}f(x)$ and $\displaystyle\lim_{x \to -\infty}f(x)$ exist and are infinite. I managed to prove that those two limits exist. But I have a really hard time proving that they are infinite. I supposed that $\displaystyle \lim_{x \to \infty} f(x)=a \in \mathbb{R}$ and tried to get a contradiction from here, but since $f$ is not continuous, I must somehow use the intermediate value property and. I see that, for all $\epsilon>0$, there is $\delta>0$ such that when $x>\delta$, $f(x)$ is getting bounded in $(a-\epsilon, a+\epsilon)$ and so $(f\circ f)((\delta,\infty))\subset f((a-\epsilon,a+\epsilon))$, but I couldn't proceed further.","['functions', 'real-analysis', 'calculus', 'limits']"
2697154,Derangement formula for multisets,"The usual derangement formula, for permutations of $\{1,\dots,n\}$ without fixed points, is given as follows: $$\sum_{i=0}^n (-1)^{n-i}i!\binom{n}{i} = D(n).$$ Richard Stanley, in his Enumerative Combinatorics (bottom of page 269), gives the following formula for derangements of a multiset of type $\alpha=(\alpha_1,....,\alpha_k)$ : $$D(\alpha) = \sum_{\beta_{1} =0}^{\alpha_1} ... \sum_{\beta_k=0}^{\alpha_k} \binom{\alpha_1}{\beta_1}\binom{\alpha_2}{\beta_2}...\binom{\alpha_k}{\beta_k}(-1)^{\beta_1+....+\beta_k}
\binom{\sum (\alpha_i-\beta_i)}{\alpha_1-\beta_1,\alpha_2-\beta_2,...,\alpha_k-\beta_k}.$$ In the solution it says the derangement formula of $D(n)$ can be straightforwardly generalized to the sum above for the given type $\alpha=(\alpha_1,...., \alpha_k)$ , where $M_\alpha$ is the multi-set $\{1^{\alpha_1},....,k^{\alpha_k}\}$ . Stanley defines a derangement of $M_\alpha$ as ""a permutation $a_1a_2...a_n$ (where $\sum\alpha_i=n$ ) of $ M_\alpha$ such that it disagrees with every position we get by listing the elements of $M$ in a weakly increasing order, for example for the set $\{1,2^2,3\}$ the two possible derangements are $(2132,2312)$ ."" My question is how is that generalization straightforward? I don't see how that is achieved.","['inclusion-exclusion', 'combinatorics', 'derangements']"
2697164,Distributing identical balls in boxes with minimum and maximum per box,"I'm trying to solve the following problem: In how many ways can you distribute 100 identical balls among 3 different boxes (box A, box B and box C), such that each box will get at least 20 and at most 50 balls? I'm trying to solve it using a generating function. 
Please help me check the correctness. And please let me know if there's an easier way to solve this problem. So I'm trying to find the integer solution to: $c_1+c_2+c_3=100$ with c1, c2, c3 varying from 20 to 50 balls. The associated polynomial associated with the given equation is:
$(x^{20}+x^{21}+x^{22}+...+x^{50})^3$ I think the solution to the problem is the coefficient of $x^{100}$ in the equation $(x^{20}+x^{21}+x^{22}+...+x^{50})^3$, so I'm trying to find the coefficient of $x^{100}$. $(x^{20}+x^{21}+x^{22}+...+x^{50})^3={(x^{20})}^3 {(1+x+x^2+...+x^{30})}^{3}$
$= {(x^{60})} {(1+x+x^2+...+x^{30})}^{3}$ Using the geometric series, this becomes: ${(x^{60})} { ( \frac{1-x^{31} }{1-x} ) }^{3}$
$= {(x^{60})} { ( 1 -3x^{31}+3x^{62}-x^{93} ) }{(1-x)}^{-3}$ Next I'm trying to find ways the coefficients of $x^{100}$ can be obtained: $x^{60}x^{0}x^{40}$ $x^{60}x^{31}x^{9}$ Then I'm trying to find the value of the coefficient of $x^{100}$ by summing the values of these coefficients: $1*1 * {3+40-1 \choose 40} + 1*-3*{3+9-1 \choose 9}$
$=  {42 \choose 40} -3 *{11 \choose 9}$ 
$= 861 - 3 * 55 = 696$","['generating-functions', 'combinatorics', 'binomial-coefficients']"
2697197,Surface Integral of a 2-form,"Let $\alpha=x\,dx+y\,dy+z\,dz, \gamma=xy\,dz$ Let $D$ be the square $0 \leq x \leq 1, 0 \leq y \leq 1, z=1$ oriented with the upward normal. Calculate $\iint_D \alpha \wedge \gamma$. My professor have a totally different approach then using the formula that is commonly found over the internet, which seems to work on all cases. My attempt: parameterize the surface $\sigma(u,v)=(u,v,1)$  such that it is a transformation from $\mathbb{R}^2$ to $\mathbb{R}^3$ $\alpha \wedge \gamma=-x^2y\,dz\,dx+xy^2\,dy\,dz$ $dX(u,v)=\frac{dX}{du}du+\frac{dX}{dv}dv=1du$ $dY(u,v)=\frac{dY}{du}du+\frac{dY}{dv}dv=1dv$ $dZ(u,v)=\frac{dZ}{du}du+\frac{dZ}{dv}dv=0$ $$\begin{align}
\iint_D \alpha \wedge \gamma & = \iint_{D} -x^2y\,dz\,dx+xy^2\,dy\,dz \\
& = \int_0^1\int_0^1 -u^2v\,dZ\,dX+uv^2\,dY\,dZ\\
&= \int_0^1\int_0^1-u^2v(0)(1du)+uv^2(1dv)(0)\\
&= \int_0^1\int_0^1 0 \\
&= 0
\end{align}$$ Is it correct?","['multivariable-calculus', 'surface-integrals', 'differential-forms']"
2697218,"Studying the extrema of $f(x,y) = x^4 + y^4 -2(x-y)^2$","Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ such that $f(x,y) = x^4 + y^4 - 2(x-y)^2$. Study its extrema. So here was my approach. We have $$\frac{\partial f}{\partial x}(x,y) = 4(x^3 -x + y),\frac{\partial f}{\partial y}(x,y)= 4(y^3 -y + x) $$
I have to find $(x_0,y_0) \in \mathbb{R}^2$ such that $ \frac{\partial f}{\partial x}(x_0,y_0)= \frac{\partial f}{\partial y}(x_0,y_0) = 0 $ So we have: $$\left\{\begin{matrix}
x(x^2-1)+ y  =0\\ 
y(y^2 -1) + x =0
\end{matrix}\right. $$
Thus we have $x-x^3 = y$, and by replacing $y$ with $x-x^3$ in the second line, we get: $$ y(y^2 -1) + x =0 = (x-x^3)((x-x^3)^2 -1)+x  =x^5(-x^4 -x^2 -3) = 0 $$ And the only solution for this is $x=0$. As $y = x^3 -x$ we immediately have $y=0$. So the only extremum possible is at $(0,0)$. Now, I need to study its Hessian matrix. We have: $$\frac{\partial ^2f}{\partial x^2}(x,y) = 12x^2 -4 , \frac{\partial ^2f}{\partial y^2}(x,y) = 12y^2 -4, \frac{\partial^2 f}{\partial x \partial y}(x,y) = \frac{\partial^2 f}{\partial y \partial x}(x,y) = 4$$ Thus $$H(x,y) \begin{bmatrix}
 12x^2 -4&4 \\ 
 4& 12y^2 -4
\end{bmatrix} $$ At $(x,y)=(0,0)$ we have 
$$H(0,0) \begin{bmatrix}
 -4&4 \\ 
 4&  -4
\end{bmatrix} $$ As we have $\text{det}(H(0,0)) = 0$ and $\text{Tr}(H(0,0)) = -8$ the eigenvalues are $0$ and $-8$. As it has $0$ as eigenvalue, I need to study the differential at a higher order. But here I lack understanding. What exactly should I do? Should I compute the third order partial differentials and then restudy their Hessian Matrix?","['derivatives', 'hessian-matrix', 'differential', 'optimization', 'partial-derivative']"
2697223,Why does $\nabla$ behave like a member of $\mathbb{R}^3$ (Euclidean vector in 3d space) in many cases?,"Is there a reason why $\vec{\nabla} = \left[\; \dfrac{\partial}{\partial x}, \dfrac{\partial}{\partial y}, \dfrac{\partial}{\partial z}\; \right]$ , behaves like a member of $\mathbb{R}^3$ (Euclidean vector in 3d space) in so many cases: Dot products and cross products of $\vec{\nabla}$ with multivariable vector function like $\vec{\nabla} \cdot \mathbf{\vec{f}}$ and $\vec{\nabla} \times \mathbf{\vec{f}}$ or with scalar functions (gradient) are vectors (i.e. independent of particular choice of co-ordinates). Properties like the Lagrange's formula that are valid for vectors have direct analogues involving the $\vec{
\nabla}$ operator. We can write pseudo-determinants for curls just like we could with components of vectors. Most of its vector properties hold if $\vec{\nabla}$ is replaced by any other vector. There will be separate proofs for all of these properties. But is there any underlying reason that works for all such properties? Is there a fundamental reason why $\vec{\nabla}$ is $\mathbb{R}^3$ vector-ish ?","['multivariable-calculus', 'vector-analysis']"
2697237,Do there exist energy-minimizing immersions?,"Let $M,N$ be $d$ -dimensional connected oriented Riemannian manifolds, possibly with boundary, $M$ compact. Let $E_d:C^{\infty}(M,N) \to \mathbb{R}$ be the $d$ -energy, i.e. $$ E_d(f)=\int_M |df|^d \text{Vol}_M.$$ Set $E_{M,N}=\inf \{ E_d(f) \, | \,\, f \in C^{\infty}(M,N) \text{ is an immersion} \}$ , and suppose that $E_{M,N} >0$ . Does $E_{M,N}$ always obtained? i.e. does there exist an immersion with minimal energy? (I am assuming there exist at least one immersion from $M$ to $N$ .  ) I am specifically considering the $d$ -energy between $d$ -manifolds, and not the $2$ -energy; for the $2$ -energy the answer can be negative; it is known that $$\inf_{f \in \text{Diff}(\mathbb{S}^n) }  E_2(f) =0$$ when $n >2$ ,
but there is no immersion with zero $2$ -energy. However, the identity map $\text{Id}_{M^d}$ has minimal $d$ -energy among all diffeomorphisms. (So, in particular, for any simply-connected and closed $M$ , we have $E_{M,M}=E_d(\text{Id}_{M})$ as any immersion is a diffeomorphism).","['harmonic-functions', 'riemannian-geometry', 'variational-analysis', 'calculus-of-variations', 'differential-geometry']"
2697267,A series that converges to π/3 [duplicate],"This question already has answers here : Find the value of $\sum_{n=0}^\infty\frac{1}{9n^2+9n+2}$ (4 answers) Showing $ \sum_{n=0}^{\infty} \frac{1}{(3n+1)(3n+2)}=\frac{\pi}{3\sqrt{3}}$ (7 answers) Closed 6 years ago . While surfing on YouTube, I stumbled into this video which gave me a new insight about the well-known series 
$$
\frac{\pi}{4} = 1 - \frac{1}{3} + \frac{1}{5} - \frac{1}{7}+ \ldots
$$
The idea shown there consists of counting (in a very clever way) how many points of the 2d integer lattice lie on a generic circumference of radius $\sqrt{r}, r \in \mathbb{N}$, centered at the origin. Then, we name $N(R)$ the number of points of this kind that lie inside the circumference of radius $\sqrt{R}$: as $R$ grows, we can think of $N(R)$ as a fairly good approximation of the area $\pi R$ of the circle, since each of the $N(R)$ points can be thought as the center of a square of area $1$. From the equality $\pi R = N(R)$ we get the series above. I was fairly amazed by the way this result was obtained, and I started wondering: what if we used the hexagonal lattice (I mean $\mathbb{Z} \times \zeta_3\mathbb{Z}$, where $\zeta_3$ is a non-trivial third root of unity) instead of the integer lattice? Will I get another series to approximate $\pi$? After some work, following the same kind of argument, I came to this formula:
$$
\frac{\pi}{3} = \sqrt{3} \left (1 - \frac{1}{2} + \frac{1}{4} - \frac{1}{5} + \frac{1}{7} - \frac{1}{8} + \ldots \right ) 
$$
or equivalently 
$$
\frac{\pi}{3} = \sum_{k=0}^\infty \frac{\sqrt{3}}{9k^2+9k+2}
$$
I have some questions: Can anyone give me a proof of this result which does not follow the argument I sketched above? I checked by doing some simple calculations (I also asked Wolfram) and the result seems to hold, but I'd like to be 100% sure... The $\frac{\pi}{4}$ formula relates to the expansion of $\arctan(x)$, but I couldn't find any straightforward connection between the $\frac{\pi}{3}$ formula and $\arctan(x)$. I actually couldn't find any connection to the ""pi facts"" I know or I was able to find. Do anybody know anything that can explain ""easily"" what's happening here? Thanks in advance!","['complex-numbers', 'tessellations', 'number-theory', 'pi', 'sequences-and-series']"
