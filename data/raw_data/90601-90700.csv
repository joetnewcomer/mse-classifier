question_id,title,body,tags
1220615,"Linear algebra terminology: unique, trivial, non-trivial, inconsistent and consistent",Let me get this straight: Unique solution- has an exact solution (such as a POI of 2 intersecting lines) Trivial solution- when 0 needs to equal the zero vector in $Ax=0 vector$ Non-Trivial-? Perhaps when 0 does not equal the zero vector in $Ax=0$. This is due to the presence of free variables in Matrix A. Consistent- Where there is a unique solution? Inconsistent? When there is an inequality such as 4 can't equal 3 meaning the solution can not be solved. This is due to parallel lines. Am I correct on these  technical terms? I put inequality in italics because I'm not sure if I used it correctly.,"['terminology', 'linear-algebra']"
1220619,What is the reason behind the Pythagorean relation in a hyperbola?,"I am currently (in my Pre-Calculus course) deriving the equations of the conic sections. I very much understand how the relationship, in an ellipse , between $a, b$, and $c$ is established. Knowing that in an ellipse, the sum of the distances from each focus to the point $(0, b)$, one endpoint of the minor axis, is equivalent to the sum of the distances from each focus to the right-hand vertex, by the very locus definition of the ellipse. Seeing this fact, I set the distance from $(0, b)$ to $(c, 0)$ equal to the distance from $(a, 0)$ to $(c, 0)$ and, through algebra, arrived at the Pythagorean relationship $b^2=a^2-c^2$. (*Note - this is based on an ellipse centered at the origin with major axis lying on the x-axis, but of course I understand how the relationship is maintained no matter how we translate and orient the ellipse. I just used this basic case for the derivation.) However, I cannot say that I understand the Pythagorean relation established by the hyperbola. I began the derivation with a hyperbola centered at the origin and transverse axis lying on the x-axis. The point $(0, b)$ is not even on the hyperbola itself, while $(a, 0)$ and $(c, 0)$ are, being representative of the right-hand vertex and right-hand focus respectively; yet my textbook throws out the relationship $a^2+b^2=c^2$ out of nowhere and uses that relationship to finish the derivation of the equation. I am comfortable with all other parts of the derivation except this Pythagorean relationship. It comes quite literally completely out of nowhere to me, and I have searched the internet for hours today trying to find the proof of this relationship, and have found absolutely nothing. One site I went to, Purplemath, even wrote verbatim that the proof was ""long and painful"" and said to just ""memorize"" the relationship and ""move on."" My ultimate question is thus: where on earth does this relationship, $a^2+b^2=c^2$, for a hyperbola, even come from? What is the geometric/algebraic reasoning? I want to fully understand this derivation and this is the sole hindrance. Thanks very much!","['conic-sections', 'analytic-geometry', 'algebra-precalculus']"
1220623,Centralizer of $\mathbb{C}[G]$ in $\mathbb{C}[H]$,"I found this result, but can't understand how to prove. Let $H$ be a subgroup of $G$. Then prove $Z(\mathbb{C}[G],\mathbb{C}[H])$ is commutative iff every irreducible $G$ module when restricted to $H$ splits into irreducible $H$ modules of multiplicity at most $1$. Where $Z(M,N)=\{m \mid mn=nm , \forall n\in N\}$","['abstract-algebra', 'group-theory', 'representation-theory']"
1220629,Limit $\lim_{x \to0^-}\ln x$,"Can i ask for the limit as $x$ approaches $\lim_{x \to 0-}\ln x$ ? Please explain. Its because since the limit of a function only exists if the lim as $x$ approaches some number $n$ from both the positive and negative side is the same, im not sure that im convinced that the limit as $x$ approaches $0$ for $\ln x$ exists. i know its negative infinity from the positive side, but from the negative side?",['limits']
1220649,Proving trigonometric identity $1+\cot x\tan y=\frac{\sin(x+y)}{\sin x\cos y}$,"$$1+\cot x\tan y=\frac{\sin(x+y)}{\sin x\cos y}$$ I have worked through most of this question, and I believe I am so close to finding the answer, but I have run into some issues where I am not sure about what to do next. This is what I did:
$LS$C
$\sin^2x + \cos^2x+1/\tan x(\sin y/\cos y)$
$=\sin^2x+\cos^2x+ 1/\sin x/\cos x(\sin y/\cos y)$ After this point, I am not certain what to do.  If someone could please help me, it'd be much appreciated!","['trigonometry', 'algebra-precalculus', 'functions']"
1220655,What does Fatou's Lemma really say?,"Fatou's lemma says that if $f_n:X \rightarrow [0,\infty]$ are measurable,then $$\liminf_{n\rightarrow \infty}\left(\int_X f_n \,\mathrm{d} \mu\right) \geq \int_X \liminf_{n\rightarrow \infty} f_n \,\mathrm{d}\mu$$ I like to know what this Lemma really says. That is, how can I express in words (rather informally) what this lemma actually says?",['measure-theory']
1220679,Prove that if $A \subset B$ then $P(A) \leq P(B)$,"I'm supposed to prove that if $A \subset B$, then $P(A) \leq P(B)$. The hint it gives is confusing me even more. It says use a venn diagram to convince yourself $ B = A \cup (A^c \cap B)$ and $A$ and $A^c \cap B$ are disjoint. I know that I can do this: $A \cup (A^c \cap B) = (A \cup A^c) \cap (A \cup B)$ Since $(A \cup A^c) = U$ that means if it intersects with $A \cup B$ we just have a venn diagram with everything shaded in. How do I use this to my advantage to prove the original question? And wouldn't the two sets $A$ and $A^c \cap B$ being disjoint hurt me? Since I want to show that everything in $A$ is in $B$?","['probability', 'statistics']"
1220689,Limit of the function $(\cos{\pi x})^{2n}$ as $n\to\infty$,"I just came across this question. Kindly point out where I am wrong. Finding $\lim (\cos{\pi x})^{2n}$ What I did :  $((\cos{\pi x})^2)^n$, then made $3$ categories, $x\lt 0$, $x\gt 0$ and $x=0$.
but due to the ""square"" it reduces to only $2$.
we know $\cos{\pi n} = (-1)^n$ so squaring gives the value as $1$. thus $\lim (\cos{\pi x})^2n = (1)^n$ . Taking limit to infinity , thus equals $1$.
Is this correct ?","['limits', 'real-analysis']"
1220706,Constructing a quasiconvex function,"Let $C\subset\mathbb{R}^2$ be a nonempty convex set. A function $f:C\rightarrow\mathbb{R}$ is called convex if 
$$
f(\lambda u+(1-\lambda)v)\leq\lambda f(u)+(1-\lambda)f(v), \quad\forall u,v\in C, \forall\lambda\in(0,1);
$$ quasiconvex if
$$
f(\lambda u+(1-\lambda)v)\leq\max\{f(u), f(v)\}, \quad\forall u,v\in C, \forall\lambda\in(0,1).
$$ It is easy to very find that convexity implies quasiconvexity. The reverse implication is not true in general. Counterexample. The function
$$
f(x,y) = \begin{cases} 0 &\mbox{if } \quad0<x<1, y=1, \\ 
1 & \mbox{if } \quad\text{otherwise}. \end{cases}
$$
is quasiconvex but  not convex on $C=[0,1]\times[0,1]$. $f$ is not convex on $C$. Indeed, we have $(0.5,1), (0,0)\in C$ and
$$
f\left(\frac{1}{2}(0.5,1)+\frac{1}{2}(0,0)\right)=f(0.25,0.5)=1>0.5=\frac{1}{2}f\left(0.5,1\right)+\frac{1}{2}f(0,0).
$$ $f$ is quasiconvex on $C$. Indeed, let $u, v\in C$. We consider two cases: Case 1. $u, v\in (0,1)\times\{1\}$ Then, $\lambda u+(1-\lambda)v\in  (0,1)\times\{1\}$ for all $\lambda\in(0,1)$ and so
$$
f(\lambda u+(1-\lambda)v)=0=\max\{f(u),f(v)\};
$$ Case 2. $u\notin (0,1)\times\{1\}$ or $v\notin (0,1)\times\{1\}$ Then, $\max\{f(u),f(v)\}=1$, and so
$$
f(\lambda u+(1-\lambda)v)\leq\max\{f(u),f(v)\}, \quad \forall \lambda\in (0,1).
$$ Question. We would like to construct a function $f(x,y):C\rightarrow\mathbb{R}$ with $C\subset\mathbb{R}^2$ being convex such that: (1) $f(x,y)$ is not convex on $C$; (2) $f(x,y)+\lambda y$ is quasiconvex on $C$ for all $\lambda\in\mathbb{R}$
. Thanks for all helping and comments.","['convex-optimization', 'convex-analysis', 'functions']"
1220718,"If $\int f=0$ and $f(x) \ge 0$ for all $x \in \mathbb{R}^d$, then $f=0$ a.e.","If $\int f=0$ and $f(x) \ge 0$ for all $x \in \mathbb{R}^d$, then $f=0$ a.e. I let $E \subset \mathbb{R}^d$ be a finite measurable set. I try to break this into two cases: Case 1: If $f(x)=0$ on $E$, then we are done (as trivially $f=0$ a.e.). Case 2: If $f(x) > 0$ on $E$, then $\lim_{n \to \infty} \sum_{k=1}^n a_k m(E_k)=0$. I think I can prove by contradiction here. Can I assume $f \not= 0$, which means $f > 0$ in this case? Then, do I need to show that $\int_E f > 0$, which would contradict the hypothesis of $\int_E f = 0$. Is this a good approach to this?","['real-analysis', 'lebesgue-integral', 'measure-theory']"
1220735,Product $\sigma$-algebra on $\mathbb R^{\mathbb N}$,"Let $\mathbb R^{\mathbb N}=\mathbb R\times\mathbb R\times\ldots$ be the space of all real sequences and endow it with product topology. Is the productÂ $\sigma$-algebra generated by Borel subsets of $\mathbb R$ the same as the Borel $\sigma$-algebra generated by the product topology:
$$\mathscr B(\mathbb R)\otimes\mathscr B(\mathbb R)\otimes\ldots=\mathscr B(\mathbb R\times\mathbb R\times\ldots)?$$
More generally, it is true if $\mathbb R$ is replaced by a second-countable topological space? If not, does at least $\subset$ or $\supset$ hold? What about uncountable products? It is quite well-known that the claim is true for finitely many products (even for general second-countable topological space), but I can't seem to find a proof or disproof for the (un)countably infinite case. Any input is appreciated.","['general-topology', 'measure-theory']"
1220760,What is the difference between natural numbers and positive integers?,"I was reading sets and came to some reserved letters for a few sets.
Two of them really confused me. They were - $\mathbb N$ :  For the set of natural numbers. $\mathbb Z^+$ : For the set if all positive integers. In my sense, both the sets contain $\{1,2,3,\dots\}$ Then, why are they considered different? I searched a little on this topic and got this , but it doesn't tell anything about significance of two different sets.","['notation', 'integers', 'discrete-mathematics']"
1220799,Ito's Integral's definition: Importance of isometry,"I'm reading Oksendal's Stochastic Differential Equations (5th edition). He defines the Ito integral of $f$ as the limit
$$\lim_{n\to\infty} \int^T_S \phi_n(t,\omega) dB_t(\omega)$$
Where $\{\phi_n\}$ are elementary functions that satisfy
$$E\bigg[\int^T_S (f-\phi_n)^2 dt\bigg]\to 0\;\;\;\;\text{ for }n\to\infty$$
(I left out a lot of details for brevity, if they are needed, I will add them upon request) He then says that thanks to the Ito's isometry
$$E\Big[\Big(\int^T_S \phi_t(\omega)\; dB_t(\omega)\Big)^2\Big]=E\Big[\int^T_S
\phi_t(\omega)^2\; dt \Big]$$
the limit in the definition exists and does not depend on $\phi_n$ as long as they satisfy the said condition. I don't understand why is the isometry needed. To me it seems like from $\|f-\phi\|_{L^2}\to 0$ and the reverse triangle inequality we already get $\|\phi\|_{L^2}\to\|f\|_{L^2}$ which (for $\sigma$-finite measure spaces) implies convergece in $L^1$. Where am I wrong?","['probability-theory', 'stochastic-integrals']"
1220800,Calculation of real root values of $x$ in $\sqrt{x+1}-\sqrt{x-1}=\sqrt{4x-1}.$,"Calculation of x real root values from $ y(x)=\sqrt{x+1}-\sqrt{x-1}-\sqrt{4x-1} $ $\bf{My\; Solution::}$ Here domain of equation is  $\displaystyle x\geq 1$. So squaring both sides we get $\displaystyle (x+1)+(x-1)-2\sqrt{x^2-1}=(4x-1)$. $\displaystyle (1-2x)^2=4(x^2-1)\Rightarrow 1+4x^2-4x=4x^2-4\Rightarrow x=\frac{5}{4}.$ But when we put $\displaystyle x = \frac{5}{4}\;,$ We get $\displaystyle \frac{3}{2}-\frac{1}{2}=2\Rightarrow 1=2.$(False.) So we get no solution. My Question is : Can we solve above question by using comparision of expressions? Something like $\sqrt{x+1}<\sqrt{x-1}+\sqrt{4x-1}\; \forall x\geq 1?$ If that way possible, please help me solve it. Thanks.",['algebra-precalculus']
1220811,What does the notation $\mathbb R[x]$ mean?,"What does the notation $\mathbb R[x]$ mean? I thought it was just the set $\mathbb R^n$ but then I read somewhere that my lecturer wrote $\mathbb R[x] = ${$\alpha_0 + \alpha_1x + \alpha_2x^2 + ... + \alpha_nx^n : \alpha_0, ..., \alpha_n \in \mathbb R$} Edit: The reason why I asked this question was because I had a tutorial question that said: Check whether a system {$v_1,...,v_m$} of vectors in $\mathbb R^n$ (in $\mathbb R[x]$) is linearly independent. I just assumed it meant the same thing when they put it in brackets like that. Since it isn't the case, how must I interpret this question.","['polynomials', 'vector-spaces', 'linear-algebra', 'definition']"
1220823,Having difficulty understanding topological groups.,"Let $G$ be a group and $x,y\in G$. We say that a topology $\mathcal{T}$ is a group topology if the functions $$f: G\times G \rightarrow G,\quad (x,y)\mapsto xy$$ and $$g: G\to G,\quad x\mapsto x^{-1}$$ are continuous. We call the pair $(G,\mathcal{T})$ a topological group. I am trying to understand the above definition by playing around with some basic examples. To create an example for myself, I tried to take the symmetric group $S_{3}$ and tried to turn it into as many topological groups as possible. Right away, I've dismissed the discrete and trivial topology as intuitively obvious as topological groups and I feel like there are no other group topologies on $S_{3}$. Is this true? I tried to constructively create a third group by setting $(123) \in S_{3}$ as an open set for my soon to be topology. Using the definition of a topology we know that $$\{\emptyset, (123), S_{3}\}\subseteq \mathcal{T}.$$ Now, if I require $f$ to be continuous, I am already extremely lost to the extent that I don't know what to say. We have that $f$ is a function from $G\times G \rightarrow G$ as function on group elements; but the definition of continuity requires $f: X\rightarrow Y$ where $X$ and $Y$ are topological spaces. My inclination would be to ignore this technical detail by assuming that $G\times G$ and $G$ can act as topological spaces, which leads me back into a circle as to what the open sets of $G$ have to be. Do the open sets of $G$ as a topological space also have to be a topological group?  How would I begin to pick a topology on $G\times G$? The box topology is the most natural, but why not a more exotic one? This seems to have opened up a much larger barrel of worms for me when all I did was conjecture to myself that the only two group topologies on $S_{3}$ are the discrete topology and the trivial one.",['general-topology']
1220902,Maximal ideals of commutative Artinian rings,"I would like some help on an exercise I thought I had done correctly at first glance, but obviously have doubts about. The question is; Let $R$ be a commutative Artinian ring. Then R has finitely many maximal ideals. The exercise has two previous subsections, showing that $Ann_R(R/m)=m$ for maximal ideals $m$, and $R/m_1 \cong R/m_2$ iff $m_1 = m_2$. Also, a hint for the question says to consider the semi-simple case, and then generalise. My proof so far; Letting $J = J(R)$ be the Jacobson radical, because of commutativity it is the intersection of all maximal two sided ideals. I know that $R/J$ is semi-simple as $R$ is artinian and $R/J$ has Jacobson radical $0$. So $R/J$ has finitely many ideals, it has finitely many maximal ideals and is isomorphic to a direct sum of quotients of maximal ideals in $R/J$ . I also know these quotients to be simple $R$-modules . Then, the quotient map $R/J\to R/m$ for maximal ideal $m$ is well defined and by some simple arguments, we have $R/m$ is module isomorphic to a quotient in the decomposition of $R/J$. By the exercise above, we then have only a finite number of choices of $m$. But I feel I am brushing over the decomposition part of the proof. I do not believe it is as complicated as what I have written, but I do not see what I am missing.","['abstract-algebra', 'commutative-algebra', 'proof-verification', 'ring-theory']"
1220923,Improper integral of a rational function:$\int_0^\infty \frac{5t^6}{1+t^{10}}dt$,"Find the value of the integral
$$\int_0^\infty \frac{x^{\frac25}}{1+x^2}dx.$$
I tried the substitution $x=t^5$ to obtain
$$\int_0^\infty \frac{5t^6}{1+t^{10}}dt.$$
Now we can factor the denominator to polynomials of degree two (because we can easily find all roots of polynomial occured in the denominator of the former integral by using complex numbers) and then by using partial fraction decomposition method find the integral! Is there any simple method to find the integral value??!!","['calculus', 'closed-form', 'improper-integrals', 'definite-integrals', 'integration']"
1220951,if $|a|<1$ so $\lim_{n\to \infty}na^n=0$.,Prove that if $|a|<1$ ($a$ is real) so $\lim_{n\to \infty}na^n=0$. I know that I need to use squeeze theory (because I have $-1<a<1$) but I dont see how. thanks,"['sequences-and-series', 'limits']"
1220953,A difficult integral [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question For $\gamma>0,\delta>0$ , How do I evaluate this integral? $$ I=\int_0^H\frac{e^{i t x} \log\left(\frac{H}{H-x}\right) ^{\frac{1}{\gamma }-1} \left(\left(\frac{k}{H \log \left(\frac{H}{H-x}\right)}\right)^{-1/\gamma }+1\right)^{-\gamma -\delta -1}}{\gamma  (H-x)}\,\mathrm{d}x,$$ with gratitude. I tried the usual tricks, with no result so far.","['probability-theory', 'gamma-function', 'probability-distributions', 'integration', 'complex-analysis']"
1220966,"$f :\mathbb N \to \mathbb R$ be the function $f(0)=0 , f(n)=\dfrac 1 n , \forall n >0$;is $\mathbb N$ induced with the metric $|f(x)-f(y)|$ compact?","Let $\mathbb N$ be the set of non-negative integers and $f :\mathbb N \to \mathbb R$ be the function $f(0)=0 , f(n)=\dfrac 1 n , \forall n >0$ , then obviously $f$ is injective , so $d : \mathbb N \times \mathbb N \to \mathbb R $ defined as $d(x,y)=|f(x)-f(y)|$ induces a metric on $\mathbb N$ . Then , is it true  that $(\mathbb N , d)$ is compact ?","['metric-spaces', 'compactness', 'functions']"
1220967,How to simplify $\sum_{i=1}^{k}\binom{n + i - 1}{i}$? [duplicate],"This question already has answers here : Prove $\sum\limits_{i=0}^n\binom{i+k-1}{k-1}=\binom{n+k}{k}$ (a.k.a. Hockey-Stick Identity) [duplicate] (4 answers) Sum of combinations with varying $n$ [duplicate] (2 answers) Closed 9 years ago . How to simplify $\sum_{i=1}^{k}\binom{n + i - 1}{i}$? I tried reducing the sum to $\binom{n}{1}, \binom{n}{2}, \binom{n}{3}$ and so on but couldn't get a pattern.",['algebra-precalculus']
1220995,"Why $\max \left\{ {{x^T}Ax:x \in {R^n},{x^T}x = 1} \right\}$ is the largest real eigenvalue of A?","Let $A \in {M_n}(R)$ and A is symmetric.Why $\max \left\{ {{x^T}Ax:x \in {R^n},{x^T}x = 1} \right\}$ is the largest real eigenvalue of A?","['linear-algebra', 'matrix-calculus', 'matrices']"
1221010,Negative Zero in the set of real numbers,"So according to the laws of algebra for a given $x$, one denotes by $-x$ the number such that $x+y = 0$ and is called negative of x. The subtraction operation is given by $z - x = z + (-x)$. It is easy to prove that $-0 = 0$, thus they have the same value. But this mean that -0 and 0 are equivalent or are they different elements, $-0 \in \mathbb{R}$ and $0 \in \mathbb{R}$ s.t. $-0 = 0$?","['real-numbers', 'algebra-precalculus']"
1221015,Intuition of Greens Theorem in the plane,"I'm trying to understand a special case of Greens Theorem. Let $V: \Omega \to \mathbb{R}^2$ be a $C^1$ vector field defined an open set  $\Omega \subseteq \mathbb{R}^2$. Let $\gamma$ be a $C^1$-kurve, that is closed and has no loops and runs in the positive direction. Then $$
\int_{\gamma} V \cdot \mathrm{d}r = \int_E \left( \dfrac{\partial V_2}{\partial x}(x,y) - \dfrac{\partial V_1}{\partial y}(x,y)\right) \mathrm{d}(x,y)
$$
where $E$ is the area enclosed by $\gamma$. If $V$ is a closed vector field, meaning that $\dfrac{\partial V_1}{\partial y} = \dfrac{\partial V_2}{\partial x}$ then what does Greens theorem state? Now I can see that I'm integrating $0$ but I don't understand whats going on here. I'm very new to integrals in higher dimensions, so I'm lacking a severe amount of intuition.","['vector-analysis', 'multivariable-calculus']"
1221034,$f ' (x) = f(x - (x+1)^t + 1)$,"Let $x > 0 $ and $c $ a given real $> 0.$
Let $t $ be between $0 $ and $1.$ How to find $f(x)$ or good asymptotics for $ f(x)$ such that $$ f ' (x) = f(x - (x+1)^t + 1) $$ And $ f(1) = 1 + c$.
Also $f$ is a nonlinear function and twice differentiable for $x > 0$.","['asymptotics', 'calculus', 'ordinary-differential-equations']"
1221043,"On the equidistant distribution of $n$ points on a sphere $S^2$ by algorithm and their ""validity"" measures by statistical methods","I have found an algorithm for distributing $n$ points $P_0, P_1, ..., P_n$ (approximately) equidstantly on a sphere where $$\varphi_i = \pi(\phi - 1)i \qquad \theta_i= \mathrm {asin} (2i/n - 1), i=0,1,2, ..., n$$ ( $\phi$ is the golden section)
and I want to check the validity (how close it is to an absolutely equidistant distribution of points like e.g. inscribed platonic solids) of the algorithm as follows: Let $S_n= [s_{ij}]$ be a left triangular $n \times n$ matrix which contains the distance between the $i$ -th and the $j$ -th point for a given $n$ for all $i > j$ which I'have calculated to be: $$s_{ij} = \mathrm {acos} \bigg ( \sqrt {\bigg [ 1 - (2i/n-1)^2 \bigg ] \bigg [ 1 - (2j/n-1)^2 \bigg ]}  + \\ \cos (\pi(\phi -1)(i-j)) \big ( 2i/n -1)(2j/n -1) \bigg )$$ I have defined a variable $E$ which represents the minimum spherical distance from each point (note that it is computed only one time for each pair of points) and I am trying to express the relative standard deviation of $E$ as a function of $n$ . I have computed some values of the relative standard deviation (CV) with SAGE for n between 10 and 45: n | RSD
11 | 1.02609762420603
12 | 0.762321484903851
13 | 0.955047530174084
14 | 0.817050849631392
15 | 0.865552073858752
16 | 0.745372438342098
17 | 0.775660954187498
18 | 0.701857093394853
19 | 0.611822141608497
20 | 0.631861271946514
21 | 0.701092228468854
22 | 0.540483778240496
23 | 0.659987407100965
24 | 0.672830188457424
25 | 0.652372883095057
26 | 0.685352476850355
27 | 0.739996218384178
28 | 0.723356854298303
29 | 0.735561195103908
30 | 0.718544791870398
31 | 0.722160137598222
32 | 0.664300701441229
33 | 0.691263058551244
34 | 0.679994429078862
35 | 0.628303047521343
36 | 0.646751221409871
37 | 0.670926863221861
38 | 0.643799084939139
39 | 0.684100431791817
40 | 0.707904019539385
41 | 0.738481416277019
42 | 0.764314173516170
43 | 0.756728802421113
44 | 0.777566826519663
45 | 0.754029151732675 Plotting: Makes me think that $\mathrm{CV} (n) = a_1e^{-a_2n} \cos(a_3n + a_4) + a_5 $ but this is just an estimation. Is there a way to actually express CV in terms of $n$ (not by estimation and model fitting practices)?","['spherical-coordinates', 'spherical-geometry', 'geometry', 'statistics', 'computational-complexity']"
1221058,product of densities,"One can frequently read, that the product of the densities of two INDEPENDENT random variables is also a density - the joint density of the two variables. (see for example: http://en.wikipedia.org/wiki/Joint_probability_distribution#Joint_distribution_for_independent_variables ) One can also read, that IN GENERAL the product of two normal pdf is a Gaussian, but not a normal pdf.  i.e. one would have to multiply the product with a scaling factor (normalization constant) to get a normal pdf. (see for example: http://www.tina-vision.net/docs/memos/2003-003.pdf page 3, first paragraph) My naive interpretation of this would be, that in case of independence, the normalization constant equals 1.  But the formula given for the scaling factor in the second source does not seem to support this... Where is my misunderstanding? Now, for the multivariate case, i.e. the product of two joint pdf, each one being the joint pdf of a vector of jointly normal variables, but the two vectors being independent of each other, one finds: ""The vectors x1, x2 are statistically independent if their joint distribution is f(x1, x2) = f(x1)f(x2) or, equivalently, if f(x1|x2) = f(x1) and f(x2|x1) = f(x2)."" (I do not have enough reputation points to post more than two links, so I replace the ""tt"" in http with ""**"": h**p://www.le.ac.uk/users/dsgp1/COURSES/THIRDMET/MYLECTURES/5XMULTISTAT.pdf, the above quote can be found on page 3, number 6) On the other hand, it says in another source:  ""Suppose f(x) = N (x;1;1) and f(y) = N (x;2;2) are two INDEPENDENT d-dimensional Gaussian densities. Sometimes we want to compute the density which is proportional to the product of the two Gaussian densities, i.e. f(z) = cf(x)f(y), in which  c is a proper normalization constant to make f(z) a
valid density function."" h**p://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=28A2A856531E5FF9FABEC67397A87B5D?doi=10.1.1.1.2635&rep=rep1&type=pdf"" - above quote is the first paragraph in section 7 on page 9 - here slightly modified notation. These two last sources seem to contradict each other.  Is there a reconciling fact I'm missing? Finally, the previous source given above provides an application in section 8.2 on page 11, where the Bayes theorem is applied to estimate the vector of mean values of a multivariate normal, the Bayes theorem is written there as follows: f(y|x) = cf(x|y)f(y) with c being a ""normalization constant"". more ""traditional"" descriptions of the Bayes theorem look more like this: f(y|x)f(x) = f(x|y)f(y) (see e.g.:  ""h**p://en.wikipedia.org/wiki/Bayes%27_theorem#For_random_variables"" (slightly rearranged here) This seems to imply, that the ""normalization constant"" is actually (always) 1/f(x). Is this correct? Best, JQ","['probability', 'statistics']"
1221072,Expression for codifferential in terms of interior product,"Let $(M^n,g)$ be a Riemannian manifold with local orthonormal frame $\{e_1,\ldots,e_n\}$ with dual basis $\{e^1,\ldots,e^n\}$ and with Levi-Civita connection $\nabla$. It can be checked on basis  that $d \colon \Omega^k M \to \Omega^{k+1} M$ can be represented in the form
$$
   d = \sum_{i=1}^n e^i \wedge \nabla_{e_i}.
$$
I have to show that the coddiferential $\delta \colon \Omega^{k+1} M \to \Omega^k M$ can be represented in the form
$$
   \delta = -\sum_{i=1}^n e_i \, \lrcorner \, \nabla_{e_i}.
$$
We have the following formulas:
$$
   \langle X \, \lrcorner \, \omega, \tau \rangle = \langle \omega, X^\flat \wedge \tau \rangle, \quad X \in TM, \; \omega \in \Lambda^k M, \; \tau \in \Lambda^{k-1} M,
$$
and
$$
e^i \wedge \nabla_{e_i} \tau = \nabla_{e_i} ( e^i \wedge \tau) - (\nabla_{e_i} e^i) \wedge \tau.
$$
Using these formulas we find that
$$
   \langle e^i \wedge \nabla_{e_i} \tau, \omega \rangle = \langle \nabla_{e_i} (e^i \wedge \tau), \omega \rangle - \langle (\nabla_{e_i} e^i) \wedge  \tau, \omega \rangle \\
   = - \langle \tau, e_i \, \lrcorner \, \nabla_{e_i} \omega \rangle - \langle \tau, (\nabla_{e_i} e^i)^\sharp \, \lrcorner \, \omega \rangle.
$$
Hence, the last scalar product must always vanish, but I'm not sure that it is always true. Am I missing something?","['differential-geometry', 'riemannian-geometry']"
1221076,Compute a chern class $c(K^n)$ for a non-singular algebraic hypersurface $K^n$ of degree $d$ in $P^{n+1}(C)$.,"This is Problem 16-D in Characteristic classes by John W. Milnor and James D. Stasheff. Problem 16-D) 
If the complex manifold $K^n$ is complex analytically embedded in $K^{n+1}$ with dual cohomology class $u \in H^2(K^{n+1},\mathbb{Z})$, show that the total tangential Chern class $c(K^n)$ is equal to the restriction to $K^n$ of $c(K^{n+1})/(1+u)$. For any cohomology class $x \in H^{2n}(K^{n+1};\mathbb{Z})$ show that the Kronecker index $\langle x|K^n, \mu_{2n} \rangle$ is equal to $\langle xu, \mu_{2n+2} \rangle$. Using these constructions, compute $c(K^n)$ for a non-singular algebraic hypersurface $K^n$ of degree $d$ in $P^{n+1}(\mathbb{C})$, and prove that the characteristic number $s_n[K^n]$ is equal to $d(n+2-d^n)$. (An algebraic hypersurface of degree $d$ is the set of zeroes of a homogeneous polynomial of degree $d$.) My approach) Recall Theorem 11.3. If $M$ is embedded as a closed subset of $A$, then the composition of the two restriction homomorphisms $H^k(A,A-M) \rightarrow H^k(A) \rightarrow H^k(M)$, with $\mod 2$ coefficients, maps the fundamental class $u^{'}$ to the top Stiefel-Whitney class $w_k(v^k)$ of the normal bundle.
Similarly, if $v^k$ is oriented, then the corresponding composition with integer coefficients maps the integral fundamental class $u^{'}$ to the Euler class $e(v^k)$. Let $i : K^n \rightarrow K^{n+1}$ be an embedding and let $v^1$ be a complemental line bundle of $\tau_{K^n}$ of $K^n$ in $K^{n+1}$.
$H^2(K^{n+1},K^{n+1}-K^n;\mathbb{Z}) \rightarrow H^2(K^{n+1};\mathbb{Z}) \rightarrow H^2(K^n;\mathbb{Z})$ 
Then the dual cohomology class $u \in H^2(K^{n+1})$ is sent to $e(v^1) = c_1(v^1) \in H^2(K^n;\mathbb{Z})$.Therefore,
$i^{*}c(\tau_{K^{n+1}}) 	= c(i^{*}\tau_{K^{n+1}}) 
						= c(\tau_{K^n} \oplus v^1) 
						= c(\tau_{K^n})c(v^1) 
						= c(\tau_{K^n})i^{*}(1+u).$ Recall the result from Problem 11-C,
Let $M = M^n$ and $A = A^p$ be compact oriented manifolds with smooth embedding $i : M \rightarrow A$. 
        Let $k = p-n$. 
        Show that the Poincare duality isomorphism $\cap \mu_A : H^k(A) \rightarrow H_n(A)$ maps the cohomology class $u^{'}|A$ dual to $M$ to the homology class $(-1)^{nk}i_{*}(\mu_M)$. 
By using Problem 11-C, $\langle xu, \mu_{2n+2} \rangle 	=	\langle x, u \cap \mu_{2n+2} \rangle 
									=	\langle x, i_{*}(\mu_{2n}) \rangle 
									=	\langle i^{*}(x), \mu_{2n} \rangle.$ Now, I want to compute a chern class $c(K^n)$ for a non-singular algebraic hypersurface $K^n$ of degree $d$ in $P^{n+1}(C)$. But I do not know a dual cohomology class when $K^n$ is embedded in $P^{n+1}(\mathbb{C})$. It may be integral multiples of $c(\gamma^1)$ where $\gamma^1$ is a canonical line bundle and this may be related with the degree of $K^n$. But I can not catch anything now. Can you explain how to compute $c(K^n)$?","['algebraic-geometry', 'algebraic-topology', 'vector-bundles', 'characteristic-classes']"
1221104,Series of independent random variables are independent again,"Let $\{X^i_j : i=1,..n, j\in\mathbb{N}\}$ be an independent set of random variables on a probability space $(\Omega, A, \mathbb{P})$,
$$X^k_l: \Omega \to \mathbb{R^+} := \{x \in \mathbb{R} : x \ge 0\}$$
$$Y^m := \sum_{i=1}^\infty X^m_i$$ Show that $$Y^1, ..., Y^n$$ is an independent set of random variables Defintion of independence for a set of random variables:
A set of random variables is mutually independent if and only if for any finite subset $X_1, \ldots, X_n$ and any finite sequence of numbers $a_1, \ldots, a_n$, the events $\{X_1 \le a_1\}, \ldots, \{X_n \le a_n\}$ are mutually independent events. Edit : The random variables are now non-negative","['probability-theory', 'random-variables']"
1221114,What is the volume of $A'EF-ABD$?,"$ABCD-A'B'C'D'$ is a cube with a edge length of $6$. $E$ is the midpoint of $A'B'$ and $F$ is the point on $A'D'$ where $|A'F|=2|D'F|$. The question is: what is the volume of $A'EF-ABD$ ? I have two methods, one is integral. Let $x$ be the length of $AA_2$, I get $$V_{A'EF-ABD}=\int_{0}^{6}\frac{1}{2}(6-\frac{x}{2})(6-\frac{x}{3})dx=69$$ The other method is to divide it into two parts. \begin{align*}
V_{A'EF-ABD} &= V_{D-A'EF}+V_{D-A'EBA} \\ 
 &= \frac{1}{2}\times 3\times 4\times 6\times \frac{1}{3}+(3+6)\times 6\times \frac{1}{2}\times 6\times \frac{1}{3}\\ 
 &= 12+54\\ 
 &= 66\\ 
\end{align*} It's obvious that $69\neq 66$, what causes the difference?","['solid-geometry', 'geometry']"
1221121,Eigenvalues of adjugate matrix of a singular matrix,"Given a singular matrix $A$, find the eigenvalues of the adjugate matrix of $A$. The same question with $A$ being invertible is trivial since $A\operatorname{adj}A=(\operatorname{adj}A)A=(\det A) I$. If $\operatorname{rank}A\leq n-2$, it is well-known that $\operatorname{adj}A=0$ and $0$ is the only eigenvalue. It remains to deal with the case $\operatorname{rank}A= n-1$. It is easy to check that $\operatorname{rank}\operatorname{adj} A=1$. Hence $0$ is an eigenvalue of $\operatorname{adj} A$ with multiplicity at least $n-1$. There's at most one other eigenvalue, say $\lambda$. How can I find $\lambda$ ?","['linear-algebra', 'matrices']"
1221130,Is the number of elements$g$ in a finite Abelian group $G$ such that the $| g|= k$ always equal to a multiple of $\varphi(k)$?,"Let $G $ be a finite Abelian group.  I know that if $G$ is cyclic then there are exactly $\varphi(k)$ elements in $G$ that have order $k$ for each $k$ that divides $|G|$. I also know that $G$ can be written as a group direct product of cyclic groups.  This gives me a hazy notion that the number of elements $g$ in $G$ that have order $k$ is a multiple of $\varphi(k)$.  In other words, it seems like if I construct a cycle graph of $G$ then every element must be on some cycle C and that on this cycle there would be exactly $\varphi(k)$ elements of order $k$ for each $k$ that divides the length of the cycle $C$. What I am ultimately trying to prove is that the number of elements in a modulo multiplication group that have order $2$ is always odd.  (for $n>2$).","['number-theory', 'group-theory']"
1221134,"If $a_i\geq 0,$ prove $\sum\limits_{n=1}^\infty\frac{a_1+a_2+\cdots+a_n}{n}$diverges.","If $a_i\geq0,a_n\not\equiv 0,$ prove  $\sum\limits_{n=1}^\infty\frac{a_1+a_2+\cdots+a_n}{n}$ diverges. I have known that if $\sum\limits_{n=1}^\infty a_n$converges, then  $\sum\limits_{n=1}^\infty \sqrt[n]{a_1a_2\cdots a_n}$and $\sum\limits_{n=1}^\infty\frac{n}{\frac{1}{a_1}+\frac{1}{a_2}+\cdots+\frac{1}{a_n}}$converges, but how can I prove $\sum\limits_{n=1}^\infty\frac{a_1+a_2+\cdots+a_n}{n}$ diverges? Sincerely thanks for your help. Add : Such stupid as I am, we do not need the condition $\sum a_n$ converges. Strictly, rewrite $\sum\limits_{n=1}^\infty\frac{a_1+a_2+\cdots+a_n}{n}=\sum\limits_{n=k}^\infty\frac{a_1+a_2+\cdots+a_n}{n}\geq a_k\sum\limits_{n=k}^\infty\frac 1n\to 
\infty$, where $a_k$ is the first $a_i\neq 0$.","['analysis', 'sequences-and-series']"
1221138,Understanding probability,"I'm stariting to study probability and some really interesting questions starting to bother me. Let's consider the unit circle $C$ and $D$ - the circle with radius $\frac{1}{2}$. I know that the probability of randomly picked point $p$ of C to be in $D$ too is $\frac{\text{area of } D}{\text{area of } C} = \frac{1}{4}$, while the probability $p$ to lie over any particular line through $C$ is $0$. People say that this is because the line does not have area, while the circle has. So I guess this is the case with curves as well, but if the curve is very thick (like $\sin \frac{1}{x}$ near $0$) is the probability of point to lie over such curve still $0$?","['probability-theory', 'probability', 'area']"
1221159,"Function, Relation, Operation and Cartesian Product","An operation is a kind of function. A function is a kind of relation. A relation is a subset of a Cartesian product. A Cartesian product is an operation. Back to 1. It seems to me that there's something wrong. Can we explain $X$ in terms of $Y$, while $Y$ needs $X$ in order to be explained?","['foundations', 'binary-operations', 'functions']"
1221175,On the good set principle and sigma fields.,"Following Probability and measure Theory by Ash (2000). let $\Omega$ be a set, let $C$ be a class of subsets of $\Omega$ and $A \subset \Omega$, we denote by $C \cap A$ the class $\{ B \cap A : B \in C \} $.
And the minimal sigma field over $C$ is denoted by $\sigma(C) = F$. Ash wants to show that $B \cap A \in \sigma_A (C \cap A)$. Let $L$ consist of those sets $B \in F$ s.t. $B \cap A \in \sigma_A (C \cap A)$. Now Ash states that $C \subset L$. Why is this true? Edit with original text:","['elementary-set-theory', 'self-learning', 'measure-theory']"
1221199,Structure of antiautomorphisms of a group,"Surely, the set of automorphisms of a group $G$ becomes another group $\text{Aut}(G)$. Can I say something about the set of $anti$-automorphisms of a group? It is not a group, but I guess there is a theory on it. At least, can I classify the antiautomorphisms in some nontrivial cases, in any sense?","['abstract-algebra', 'group-theory']"
1221203,Wiener process - proof of independent increments,"I have defined the Wiener process to be a stochastic process $X_t$ with values in $\mathbb{R}$ such that $X_0=0$, the paths $t \mapsto X_t$ are continuous, and for any times $0<t_1<\dots<t_n$ and Borel sets $A_1,\dots,A_n \subset \mathbb{R}$: $$
\mathbb{P}(X_{t_1} \in A_1, \dots, X_{t_n} \in A_n) = \int_{A_1}\dots\int_{A_n}p_{t_1}(0,x_1)\dots p_{t_n-t_{n-1}}(x_{n-1},x_n) \; \textrm{d}x_1\dots \textrm{d}x_n
$$ where $$
p_t(x,y) = \frac{1}{\sqrt{2\pi t}}e^{-\frac{(x-y)^2}{2t}} 
$$ is the transition density. From this definition, how do I prove that for any $0=t_0 \leq t_1 \leq \dots \leq t_n$, the increments $$
X_{t_1}-X_{t_0}, \dots, X_{t_n}-X_{t_{n-1}}
$$ are independent? In general, the only way I know how to show that two RVs are independent is to show that their joint density function factorises into the product of the marginals, but I can't see how to do that here. Thanks for any help.","['probability-theory', 'brownian-motion', 'probability']"
1221214,definition of cycle theoretic fibre,"I am studying the definition of Chow variety on Kollar's Rational Curves on Algebraic Varieties, and I am having some trouble in understanding Definition 3.9. Here we have a proper morphism of schemes $g_i:U_i\rightarrow W$ where $U$ is irreducible and $W$ is reduced. There is an open subset $W_i\subset g_i(U_i)\subset W$ such that $g_i$ is flat over it and of relative dimension $d$. Now he takes $T$ to be the spectrum of a DVR and a morphism $h:T\rightarrow W$ which sends the closed point $T_0\mapsto w\in W$ and the generic point to a point in $W_i$. Now let $h^\ast U_i$ be the pullback of $U_i$ via $h$ and define $J\subset\mathcal{O}_{h^\ast U_i}$ to be the ideal given by functions whose support is contained in the special fiber of $h^\ast U_i$ over $T$. Set  $f:(U_i)'_T=\text{Spec}(\mathcal{O}_{h^\ast U_i}/J)\rightarrow T$: it is a flat map by construction so the central fibre $Z_0$ has pure dimension $d$. Then one names the cycle theoretic fibre of $g_i$ at $w$ along $h$ to be the cycle $[Z_0]\in Z_d(g_i^{-1}(w)\times_w T_0)$. What I think I am not understanding properly is how to picture the scheme $(U_i)'_T$. Moreover, and I think that this is the important question, I don't understand what is the point behind the construction of $(U_i)'_T$. I mean, why can't we just take the special fibre of $h^\ast U_i\rightarrow T$ and define its fundamental cycle to be the cycle theoretic fibre of $g_i$ at $w$ along $h$?","['algebraic-geometry', 'moduli-space', 'intersection-theory']"
1221215,An example where Egorov's theorem fails,"This is p.62 of Folland Real Analysis book. Here the measure of X is supposed to be finite. But, I want to know the case in which the theorem doesn't work if X is of infinite measure. I tried to think of one myself, but have failed.. Could anyone show me some example?","['real-analysis', 'measure-theory']"
1221221,Continuity of left derivative implies differentiability?,"Suppose $f:\mathbb{R}\rightarrow \mathbb{R}$ is continuous and has a left derivative, $f^-$, everywhere in a neighborhood of $x.$ Suppose $f^-$ is continuous at $x.$ Does this imply that $f$ is differentiable at $x$?","['calculus', 'derivatives']"
1221261,Usefulness of Functional analysis,"I heard that functional analysis can be applied to many problems in signal processing. I'm trying to explain to my engineer friend why it is useful, but I learnt it in a pure math setting. Can anyone give me some insight on how functional analysis can be applied in the domain of engineering?",['functional-analysis']
1221262,Are curves in a level set continuous?,"Wikipedia defines a level set as a level set of a real-valued function of $n$ real variables $f$ is a set of the form $$L_c(f) = \left\{ (x_1, \cdots, x_n) \, \mid \, f(x_1, \cdots, x_n) = c \right\}$$ I often seen level sets drawn as curves in $\Bbb{R}^2$ like this My Question: Why do we assume a level set is continuous? Why couldn't it be just a collection of random points all with the same value instead of curves?","['calculus', 'multivariable-calculus']"
1221267,Prove that finite dimensional $V$ is the direct sum of its generalized eigenspaces $V_\lambda$,"Let $T$ be a linear operator on a finite dimensional complex vector space $V$ . Prove that $V$ is the direct sum of its generalized eigenspaces. I already proved that every eigenspace $V_\lambda$ is a $T$ invariant subspace of $V$ . I can find a proof that the generalized eigenspaces are linearly independent. Can anyone help direct me towards a reasonably straightforward method of proving the rest of this? Can I prove that the dimensions of the eigenspaces sum to the dimension of $V$ ? That would complete this, but I can't think of how to do that.","['eigenvalues-eigenvectors', 'linear-algebra']"
1221270,Connectedness of level sets,"I have a $C^{1}$ real valued function $f$ defined on a connected manifold $M$, it doesn't have critical points, lets assume that $f^{-1}(0)$ is a (compact) connected submanifold of $M$, does that imply that every level set will be connected?",['differential-geometry']
1221281,Matrix problem with inductive solution,"Yesterday I was at an interview and was given the following problem: Consider a matrix A that has dimensions NxM. Every element of the matrix is the average of its adjacent (up to 8) elements. Given that the element at position A[1][1]=1, find the element at A[N][M]. It was easy to notice that in such a matrix, all elements should be equal. Thus the element A[N][M]=1 . I proved it for a 2x2 matrix, by assigning x,y,z to the unknown elements, getting a system of 3 equations and solving it. The explanation to my answer A[N][M]=1 was that for any such NxM matrix you will get a system of n*m-1 equations with as many variables, which after solving will all be equal to the A[1][1] element. The interviewer requested an inductive solution. I claimed that this cannot be proved by induction as the P(n)(m) does not necessarily depend on P(n-1)(m-1). He proved it in the following steps. Prove it for the 2x2 matrix. (which I did) Assume that [N-1]x[M-1] is a matrix of all ones Enlarge the [N-1]x[M-1] matrix by one row and one column and start filling the final NxM matrix in the following way: Consider all the bottom and right 2x2 sub-matrices that include 2 known elements 1 and 2 unknown elements. As we had proved that 2x2 matrix can only have all ones, then the unknown elements should also be ones. Fill the Nth row and Mth column square by square to get the final matrix consisting of all 1s. I have doubts that this is a correct method of solving this problem. Could you share your opinions and tell me whether the inductive step is acceptable?","['induction', 'matrices']"
1221331,When does the variance of a consistent estimator go to zero?,"I came across the following statement (marked as true ) in multiple-choice section of an old exam: The variance of a consistent estimator goes to zero with the growing sample size. As far as I can tell, it can be translated as Convergence in probability to a constant implies convergence in $L^2$. Which is clearly false. Is there a way to repair the statement? I mean maybe the professor forgot to mention some additional assumption typical for the context. (E.g. how convergence in probability and uniform integrability together imply $L^1$ convergence, but it seems to be irrelevant for the above statement.)","['probability-theory', 'statistical-inference', 'statistics', 'probability', 'convergence-divergence']"
1221378,Complex entire functions without taking values on a segment are constant!,"Let $a,b$ be two distinct complex numbers and $f$ be an entire complex function, i.e. a complex function which is analytic on the whole complex plane, and
$$R(f)\subset\mathbb C-\{\lambda a+(1-\lambda)b|
\lambda\in[0,1]\}$$
Then $f$ is a constant function! Comments: With taking $g(z)=\frac{f(z)-a}{b-a}$ we may suppose that the segment is $[0,1]$. Obviously we can't use Picard's theorem!","['maximum-principle', 'complex-analysis', 'complex-integration']"
1221410,Solving the diophantine equation $p^2+n-3=6^n+n^6$,"What are the pairs ($p,n$) of non-negative integers where $p$ is a prime number, such that $$p^2+n-3=6^n+n^6$$ How can I solve  this diophantine equation?","['prime-numbers', 'number-theory', 'diophantine-equations', 'elementary-number-theory']"
1221429,When Are We Allowed to Break Up A Triple Integral?,"I was looking over the triple integral below: And I was wondering, when exactly are we allowed to break up a triple integral into the product of its components?",['integration']
1221467,Characterization of compactness in terms of closed sets,"I came across an exercise that asked to characterize compactness in terms of closed sets.  This is what I came up with: Claim: $X$ is compact $\Leftrightarrow$ for every set of closed sets $\{C_\alpha\}$ with $\cap_{\alpha}C_\alpha=\emptyset$ has a finite subset $\{C_{\alpha_1},\dots,C_{\alpha_n}\}$ s.t. $C_{\alpha_1}\cap\dots\cap C_{\alpha_n}=\emptyset$. But apparently the correct characterization is: $X$ is compact $\Leftrightarrow$ any collection of closed sets with the finite intersection property has non-empty intersection. That seems like a much more complicated way to do it.  So my question is, what's wrong with my characterization?  Is mine wrong?  If so, where's the mistake in the following proof?  If mine is not wrong, why don't I find this characterization anywhere, while I find the other version everywhere?  Thank you for any help! Proof of Claim: $(\Rightarrow)$ Suppose $X$ is compact.  Let $\{C_\alpha\}$ be a collection of closed sets s.t. $\cap_{\alpha}C_\alpha=\emptyset$.  Then $\{C_\alpha^c\}$ is a collection of open sets and $\cup_\alpha C_\alpha^c=(\cap C_\alpha)^c=\emptyset^c=X$.  Thus $\{C_\alpha^c\}$ is an open cover of $X$.  Since $X$ is compact there is a finite subcover $C_{\alpha_1}^c, \dots, C_{\alpha_n}^c$.  Since $C_{\alpha_1}^c\cup \cdots\cup C_{\alpha_n}^c=X$, $\emptyset=X^c=(C_{\alpha_1}^c\cup \cdots\cup C_{\alpha_n}^c)^c=C_{\alpha_1}\cap \cdots\cap C_{\alpha_n}$. $(\Leftarrow)$ Let $\{U_\alpha\}$ be an open cover of $X$.  Then $\{U_\alpha^c\}$ is a collection of closed sets s.t. $\cap_\alpha U_\alpha^c=(\cup U_\alpha)^c=X^c=\emptyset$.  Thus $\exists$ finite subset $\{U_{\alpha_1}^c,\dots,U_{\alpha_n}^c\}$ s.t. $U_{\alpha_1}^c \cap\dots \cap U_{\alpha_n}^c=\emptyset$.  But then $(U_{\alpha_1}^c \cap\dots \cap U_{\alpha_n}^c)^c=U_{\alpha_1} \cup\dots \cup U_{\alpha_n}=X$.  So $\{U_\alpha\}$ has a finite subcover.","['general-topology', 'compactness']"
1221495,An exercise on components of $\mathbb{S}^2$ as a closed combinatorial surface.,"Suppose that the sphere $ \mathbb{S}^2 $
  is given the structure of a closed combinatorial surface.
  Let $C$ be a subcomplex that is a simplicial circle. Suppose that $ \mathbb{S}^2\backslash C$
  has two components. Indeed,
  suppose that this is true for every simplicial circle in $ \mathbb{S}^2
$
  . Let $E$ be one of these components. [In fact,
  $ \mathbb{S}^2\backslash C$ must have 2 components, but we will not attempt to prove this.] Let $\sigma _1$ be a 1-simplex in $C$ . Since $\mathbb{S}^2$
  is a closed combinatorial surface, $\sigma _1$ is adjacent to two
  2-simplices. Show that precisely one of these 2-simplices lies in $\overline{E}$. Would it be possible for a hint on how to approach this? I thought about using the connectedness of $\overline{E}$, which gives an edge path between any two vertices of $\overline{E}$, but can't seem to make it work. The full question leads on to a proof of a weaker Jordan Curve Theorem if that helps. Thanks in advance.","['simplicial-complex', 'general-topology']"
1221516,derivatives of non-analytic smooth functions,"I would like to know how to calculate the derivative of a non-analytic smooth function? Suppose $f:\mathbb R\rightarrow \mathbb R$ is in $\mathcal C^\infty\backslash \mathcal C^\omega$ and in particular has no Taylor series expansion at $x$. The right (left) derivative at point $x$ is: \begin{equation}
f'(x)=\lim_{\epsilon\rightarrow 0}\frac{1}{\epsilon}\Big(f(x+\epsilon)-f(x)\Big)
\end{equation} The limit, due to smoothness, exists even though we can't expand, but there is no way to find the limit by means of a calculation or is there? thanks a lot!","['analyticity', 'real-analysis', 'derivatives']"
1221531,The totient of Fibonacci numbers is divisible by $4$,"Let $\{f_i\}_{i\in\mathbb N}$ be the sequence of Fibonacci numbers, i.e. $1,2,3,5,8,13,21,34,55,\cdots$, For every integer $n\gt3$ prove that
$$4\mid\phi(f_n)$$
where $\phi$ is Euler's totient function. By using the formula $\phi(p_1^{\alpha_1}\ldots p_k^{\alpha_k})=p_1^{\alpha_1-1}\ldots p_k^{\alpha_k-1}(p_1-1)\ldots(p_k-1)$ for distinct primes $p_i$ and natural numbers $\alpha_i$, we can say that the problem is equivalent to show that for $n\gt3$, $f_n\notin \{2^{\epsilon}q^k|k\in \mathbb N, q\equiv3\pmod4 \text{ be a natural prime number},\epsilon\in\{0,1\}\}$.","['totient-function', 'number-theory', 'modular-arithmetic', 'fibonacci-numbers', 'elementary-number-theory']"
1221548,How find limit $\displaystyle \lim_{n\to\infty}n\left(1-\tfrac{\ln n}{n}\right)^n$,How find this limit $$\displaystyle \lim_{n\to\infty}n\left(1-\dfrac{\ln n}{n}\right)^n$$,"['calculus', 'limits', 'algebra-precalculus']"
1221566,Covering the plane by squares!,"$K_n$ is a sequence of squares of area $a_n$. Show that if $\sum_{n=1}^\infty a_n=\infty$ then we can arrange the squares $K_n$ to cover $\mathbb{R}^2$. Comments: -obviously we can suppose that $a_n\to0$ as $n\to\infty$. -WLoG we can moreover suppose that $a_1\gt a_2\gt a_3\gt\ldots$. -That's enough to prove that we can cover unit square in the plane, because unit square is compact.","['real-analysis', 'sequences-and-series', 'geometry', 'general-topology', 'analysis']"
1221571,Finding $\cos(\pi/8)$ with half angle identities,I did $$\cos\left(\frac{45^\circ}{2}\right) = \sqrt{\frac{1 + \frac{\sqrt{2}}{2}}{2}}$$ and ended by getting $\sqrt{\frac{2 + \sqrt{2}}{4}}$. But the answer in the book is $\frac{\sqrt{2 + \sqrt{2}}}{2}$.,['trigonometry']
1221622,"Prove the triangle inequality for $d(x,y) = \min(|xây|,1â|xây|)$.","Let $X$ be the set $[0,1)$ . Define a non-standard metric on X as follows: For two numbers $x,y â X$ , take $d(x,y) = \min(|xây|,1â|xây|)$ . Show that this is a metric. In order to show this is a metric, I need to prove the triangle inequality for the metric. That is, for any $x, y, z \in X,\quad d(x,z) \le d(x,y)+d(y,z)$ . I try to prove this with the inequality $|x-y|+|y-z|\ge|x-z|$ , but I was lost when I reached the case: $d(x,z)=|x-z|,\,d(x,y)=|x-y|,\,d(y,z)=1-|y-z|$ . Could anyone give some hints?","['analysis', 'metric-spaces']"
1221663,Write the piecewise function in terms of unit step functions,"Write the piecewise function $f(t) = \begin{cases} 
      2t, &   0\leq t < 3 \\
      6,  &   3 \le t < 5 \\
      2t, &   t \ge 5 \\
   \end{cases}
 $ in terms of unit step functions. So here is what i;ve got just guessing , I don't think i'm correct. I really need some help. But I got: $f(t) = 2t[u(t-0) - u(t-3)] + 6[u(t-3) - u(t-5)] + 2t[u(t-5) - u(t - \infty)]$ Which becomes $f(t) = 2t[u(t) - u(t-3)] + 6[u(t-3) - u(t-5)] + 2t[u(t-5)]$",['ordinary-differential-equations']
1221669,"Definition of $L^1(\mu)$, Lebesgue integrable function with respect to measure $\mu$","Here is an excerpt from Rudin's  Real and Complex Analysis In Defintion 1.31, I am wondering why Rudin writes $f = u + iv$, where $u$ and $v$ are real measurable functions on X AND $f \in L^1(\mu)$. Doesn't $f \in L^1(\mu)$ already give that $f$ is complex measurable, according to Definition 1.30?? So, instead of saying what Rudin says, wouldn't this be enough to say that $f = u + iv$, where $u$ and $v$ are real measurable functions on X and $\int_X |f|  < \infty$. ------------------added----------------------",['measure-theory']
1221696,Propagation of a Shock,"I understand that we do not know the value of $u(x,t)$ when $0<x<1$ and $tâ¥1$ (because the charachtersitics do not pass through these points). However I am confused by 'ahead of the shock'. If I sketch $u(x,t)$ at $t=1$ (with reference to the graph $\color{green}{(*)}$ as below by using the values of u after the shock at $x=0$ and before the shock have switched around. However my notes state that  that up to $t=1$ the value of $u$ before the shock is $1$ and after it is $â1$. Where am I going wrong here?","['multivariable-calculus', 'partial-differential-equations']"
1221701,Maximum Volume of a rectangular box in ellipsoid,"This is the problem I am working on: Find the maximum volume of a rectangular box that can be inscribed in the ellipsoid : $x^2/25 + y^2/4 + z^2/49 = 1$ with sides parallel to the coordinate axis I know the Volume equation is going to be $V = 8xyz$. Using Lagrange: $\nabla V = \lambda\nabla g = \langle8yz, 8xz, 8xy\rangle = \lambda\langle2x/25, 2y/4, 2z/49\rangle$ Solving for y: $x = 25y/4, z = 49y/4$ Plugging that into $g$, I get $y= .453$, and then $x = 2.831, z = 5.548$, for a $V = 56.9$ This is the wrong answer. Can someone walk me through this and tell me where I went wrong? Thank you in advance!","['volume', 'optimization', 'multivariable-calculus']"
1221723,"Why in RSA, the public exponent $e$ must be coprime with $\phi (n)$","I'm trying to understand the RSA cryptosystem, and that's what I know so far: If we think about some number $m$ as the message, then we are searching a $e$ and $d$ such that $$m^{ed} \equiv m \ \ (\mbox{mod} \ n)$$ So someone can encrypt the message by doing $$m^e \ \ (\mbox{mod} \ n)$$
And the person that holds $d$ can decrypt it by doing $$(m^e \ \ (\mbox{mod} \ n))^d (\mbox{mod}\ n) = m$$
*(not the best notation but you guys get the idea) $d$ can be calculated by using Euler's theorem, which states that: $$m^{\phi(n)}\equiv 1 \ (\mbox{mod} \ n) \tag{2}$$ where $m$ coprime with $n$ Then, by some modular arithmetic properties, we can do this in $(2)$: Raise both sides by $k$, so we get: $$m^{k\phi(n)}\equiv 1 \ (\mbox{mod} \ n)$$
*because $1^k$ is $1$ Then multiply both sides by $m$: $$m^{k\phi(n)+1}\equiv m \ (\mbox{mod} \ n)$$ By comparing this congruency with the one we've been searching: $$m^{k\phi(n)+1}\equiv m \ (\mbox{mod} \ n)$$ $$m^{ed} \equiv m \ \ (\mbox{mod} \ n)$$ We just need to solve for $d$ by doing: $$ed = k\phi(n)+1\implies d = \frac{k\phi(n)+1}{e}$$ So $d$ can be easely calculated if you know the factorization of $n$, because for a number $n$, $\phi(n)$ is $\phi(p)\phi(q)$ where $n = pq$ (in other words, $p$ and $q$ are the prime factors of $n$). So since we think (for centuries) that factorization of large numbers is a difficult problem, we assume that no one will be able to find $d$ in a reasonable amount of time, unless they know wich prime numbers form $n$. My questions are: I don't know if I understand that the requirement that $e$ is a prime
  number. For me, any number would work in the process I described. Also, why $m$ is not assumed to be coprime with $n$ at $(2)$? Since
  $m$ is the message, it can happen that $m$ is not coprime with $n$. In the wikipedia article , it says that $e$ must be less that
  $\phi(n)$. Why? Why, in the wikipedia article where he proves it using fermat's
  little theorem , it assumes that $ed$ is congruent to $1$ mod
  $\phi(n)$? I've seen all this at khan academy , but the process they described does not answer my questions.
I would like some help with the intuition, as always. I'm not looking for some one line proof, so please help me understand the requirement that $e$ is prime, for example, by using the process I described. Please be patient, I'll give time to choose the answers, so you guys have time to write a good one <3","['computer-science', 'cryptography', 'number-theory', 'discrete-mathematics']"
1221739,How can we show that for $\lambda <0$ we get the trivial solution $X(x)=0$?,"Find the solution of the problem $$u_t(x, t)-u_{xx}(x, t)=0, 0<x<1, t>0 \tag {*} \\ u(0, t)=0, t>0 \\ u_x(1,t)+u_t(1,t)=0, t>0$$ I have done the following: We are looking for solutions of the form $$u(x, t)=X(x) \cdot T(t)$$ $$u(0, t)=X(0) \cdot T(t)=0 \Rightarrow X(0)=0 \\ X'(1) \cdot T(t)+X(1) \cdot T'(t)=0 \Rightarrow \frac{X'(1)}{X(1)}=-\frac{T'(t)}{T(t)}$$ $$(*) \Rightarrow X(x) \cdot T'(t)-X''(x) \cdot T(t)=0 \\ \Rightarrow \frac{X(x) \cdot T'(t)}{X(x) \cdot T(t)}-\frac{X''(x) \cdot T(t)}{X(x) \cdot T(t)}=0 \\ \Rightarrow \frac{T'(t)}{T(t)}=\frac{X''(x)}{X(x)}=-\lambda$$ So, we get the following two problems: 
$$\left.\begin{matrix}
X''(x)+\lambda X(x)=0, 0<x<1\\ 
X(0)=0 \\
\frac{X'(1)}{X(1)}=\lambda \Rightarrow X'(1)-\lambda X(1)=0
\end{matrix}\right\}(1)
$$ $$\left.\begin{matrix}
T'(t)+\lambda T(t)=0, t>0
\end{matrix}\right\}(2)$$ For the problem $(1)$ we do the following: The characteristic polynomial is $d^2+\lambda=0$. $\lambda<0$: General solution: $X(x)=c_1 e^{\sqrt{-\lambda }x}+c_2e^{-\sqrt{-\lambda}x}$ $$X(0)=0 \Rightarrow c_1+c_2=0 \Rightarrow c_1=-c_2$$ $$X(1)=c_1e^{\sqrt{-\lambda}}+c_2e^{-\sqrt{-\lambda}}=c_1(e^{\sqrt{-\lambda}}-e^{-\sqrt{-\lambda}})$$ $$X'(x)=\sqrt{-\lambda}c_1e^{\sqrt{-\lambda }x}-\sqrt{-\lambda}c_2 e^{-\sqrt{-\lambda}x} \\ X'(1)=\sqrt{-\lambda}c_1e^{\sqrt{-\lambda }}-\sqrt{-\lambda}c_2 e^{-\sqrt{-\lambda}}=\sqrt{-\lambda}c_1(e^{-\lambda}+e^{-\sqrt{-\lambda}}$$ $$X'(1)-\lambda X(1)=0 \Rightarrow \sqrt{-\lambda}c_1(e^{\sqrt{-\lambda}}+e^{-\sqrt{-\lambda}})-\lambda c_1(e^{\sqrt{-\lambda}}-e^{-\sqrt{-\lambda}})=0 \Rightarrow c_1 [ e^{\sqrt{-\lambda}}(\sqrt{-\lambda}-\lambda)+e^{-\sqrt{-\lambda}}(\sqrt{-\lambda}+\lambda)]=0$$ How could we continue to show that for $\lambda <0$ we get the trivial solution $X(x)=0$ ?? $$$$ EDIT: $\lambda <0$ : $X(x)=c_1 \sinh (\sqrt{-\lambda} x)+c_2 \cosh (\sqrt{-\lambda}x)$ Using the initial values we get that $X(x)=0$, trivial solution. $\lambda=0$ : $X(x)=c_1 x+c_2$ Using the initial values we get that $X(x)=0$, trivial solution. $\lambda >0$ : $X(x)=c_1 cos (\sqrt{\lambda}x)+c_2 \sin (\sqrt{\lambda}x)$ $X(0)=0 \Rightarrow c_1=0 \Rightarrow X(x)=c_2=\sin (\sqrt{\lambda}x)$ $X'(1)-\lambda X(1)=0 \Rightarrow \tan (\sqrt{\lambda})=\frac{1}{\sqrt{\lambda}}$ That means that the eigenvalue problem $(1)$ has only positive eigenvalues $0<\lambda_1 < \lambda_2 < \dots < \lambda_k < \dots $ that are the positive roots of the equation $\tan \sqrt{x}=\frac{1}{\sqrt{x}}$. Is this correct?? Why can we say that the number of the eigenvalues is countable ?? How can we show that $$\lim_{k \rightarrow +\infty} \frac{\sqrt{\lambda_k}}{k \pi}=1$$ ??","['ordinary-differential-equations', 'partial-differential-equations']"
1221752,how to prove $\int{f}d\mu=\sum_{x\in\Omega}f(x)$,"Prove that $\int{f}d\mu=\sum_{x\in\Omega}f(x)$ when $f$ is absolutely summable, where $\mu$ is a counting measure on the measure space $(\Omega,\mathscr{F})$. Can someone give me hints?","['real-analysis', 'lebesgue-integral']"
1221756,homogeneous coordinate rings of isomorphic projective varieties,"As i understand, there are two notions of ""equivalence"" of projective varieties. The first is projective equivalence, under which projective varieties $X,Y$ of $\mathbb{P}^n(k)$ are mapped to
each other by an invertible $(n+1) \times (n+1)$ matrix. In that case 
their corresponding homogeneous coordinate rings are isomorphic as 
$k$-algebras. The second notion is weaker and is the notion of the two
varieties being isomorphic, under which a biregular morphism exists
between $X,Y$. Question: What can we say about the homogeneous coordinate rings
of two isomorphic projective varieties? Of course, the two rings will must have the same Krull dimension,
but can we say anything else?",['algebraic-geometry']
1221758,Prove or disprove a claim related to $L^p$ space,"The following question is just a toy model: Let $f:[0,1] \rightarrow \mathbb{R}$ be Lebesgue integrable, and suppose that for any $0\le a<b \le1$, $$\int_a^b |f(x)|dx \le \sqrt{b-a}$$ then prove or disprove that $$ \sup \left\{\frac{\int_E |f|dx}{|E|^{1/2}}: E \subset [0,1]\right\}<+\infty$$ If the claim above is false, then is it possible to prove that for any fixed $0<t<1/2$,  $$ \sup \left\{\frac{\int_E |f|dx}{|E|^{t}}: E \subset [0,1]\right\}<+\infty$$ Motivation : This is a long story. Throughout the following, we assume that $f$ is a measurable function from a bounded regular open set $\Omega \subset \mathbb{R}^n$ to $\mathbb{R}$. We know that if $f$ is $L^p(\Omega) \space(p>1)$, then by Holder's inequality, $$ \sup \left\{\frac{\int_E |f|dx}{|E|^{1-1/p}}: E \subset \Omega\right\}<+\infty \quad \quad\quad\quad(*)$$Then naturally I wanted to ask the inverse question: 
$\space$ Does $(*)$ imply $f \in L^p(\Omega)$? One of my smart friends figured out that $(*)$ is equivalent to $f$ is weak $L^p$. See the answer here: a characterization of $L^p$ space . Then naturally I want to know in $(*)$, instead of taking supremum over all measurable sets, what would happen if taking supremum over all cubes or balls? This leads to the toy model I asked at the beginning: the toy model is for $p=2, n=1$, $f$ is integrable, and cube is thus just an interval. Now let me formulate my question neatly as follows: Set $M_p:=\left\{f:\sup \left\{\frac{\int_E |f|dx}{|E|^{1-1/p}}: E \subset \Omega\right\}<+\infty\right\}$ $\tilde{M_p}:=\left\{f:\sup \left\{\frac{\int_B |f|dx}{|B|^{1-1/p}}: \text{$B$ is a ball $\subset \Omega$}\right\}<+\infty\right\}$ $L_p^w$ := the weak-$L^p$ space. $\tilde{L_p}:=\{f \in L^q(\Omega): \forall 1\le q<p\}$ Then by my friend's result and interpolation theorem, $$L_p^w=M_p \subset \tilde{L_p}$$Also trivially, $M_p \subset \tilde{M_p}$. So the ultimate goal is that I want to know the relationship between $M_p, \tilde{M_p}$, and $\tilde{L_p}$. In particular, the toy model I asked at the beginning focuses on whether $M_p = \tilde{M_p}$. An equivalent statement of whether $M_p=\tilde{M_p}$ is the following: Let $0<s<1$. If $\mu$ is a finite measure on $\Omega$ and absolutely continuous with respect to Lebesgue measure in $\mathbb{R}^n$, and 
$\lim\sup _{r \rightarrow 0} \frac{\mu({B_r(x)})}{r^{ns}} \le 1, \forall x\in \Omega$ , is it true that $sup \{\frac{\mu(E)}{|E|^s}: E \subset \Omega\}<+\infty$ ? I also want to understand the following question: $\space$ If $M_p = \tilde{M_p}$ and $f \in M_p$, is it true that $\sup \left\{\frac{\int_E |f|dx}{|E|^{1-1/p}}: E \subset \Omega\right\}=\sup \left\{\frac{\int_B |f|dx}{|B|^{1-1/p}}: \text{$B$ is a ball $\subset \Omega$}\right\}?$ Or what can we say about the ratio? By the way, the definition $\tilde{M_p}$ here is the same as $M^p$ defined in Gilbarg and Trudinger on Page 164, which is the so called Morrey Space. I looked up some references but didn't find any claims whether or not $M^p \subset L^q \quad \forall 1 \le q < p$. Maybe I'm thinking too much. I should focus on solving one problem and then go step by step. My effort: In terms of the possible approaches, I think the approximate continuity of any measurable function and a nice covering argument would be helpful. Also, if $f$ is integrable, then one can observe that if $$T_pf(x):=\lim\sup_{r \rightarrow 0} \frac{1}{|B_r(x)|^{1â1/p}}\int_{B_r(x)}|f(y)|dy$$ is bounded in $\Omega$, then $$\mathcal{M}_pf(x):=\sup_{r > 0} \frac{1}{|B_r(x)|^{1â1/p}}\int_{B_r(x)}|f(y)|dy$$ is also bounded, and vice versa. Also, $$T_pf(x)=0,\mathcal{H}^{s}-a.e, \forall s\ge 1-1/p$$ So the size of the blow-up points should be very small, and thus a nice covering argument may be applied, at least we don't need to worry about cover the singular sets by balls or other arbituary sets. Maybe at least $\tilde{M_p} \subset M_q, \forall 1\le q<p$ can be provable. I have a lot of other observations, but it is cumbersome to type them down. Overall, I think these problems should be related to geometric measure theory and are not trivial. Also, my smart friend suggests me try to apply the Littlewood-Paley Theory. He thinks of them as standard problems in harmonic analysis. Any ideas, comments and partial result would be fully appreciated. I've no idea even about the toy model proposed.","['measure-theory', 'functional-analysis', 'harmonic-analysis', 'geometric-measure-theory', 'littlewood-paley-theory']"
1221766,Norm of the sum of two vectors,"This problem has two parts. Part a) : $x$ and $y$ are vectors. If $||x|| = 7, ||y|| = 11$, what is the smallest value possible for $||x+y||$? (Note: the || || denotes the norm of a vector). This is what I have tried so far: I put vector $x$ equal to $\begin{pmatrix} a \\ b  \end{pmatrix}$ and vector $y$ equal to $\begin{pmatrix} c \\ d \end{pmatrix}$. $||x|| = 7$ would then be, after simplification, $a^2+b^2 = 49$. Similarly, for $||y|| = 11$, after simplification, $c^2+d^2 = 121$. Then, $||x+y|| = \sqrt{(a+c)^2 + (b+d)^2}$. Expanding gives us $\sqrt{(a^2+b^2) + (c^2+d^2) + 2(ac+bd)} = \sqrt{49+121+2(ac+bd)} = \sqrt{170+2(ac+bd)}$. That is where I was stuck--any hints for the next few steps? Part b) : $x$ and $y$ are vectors ( these are not the same vectors as in part a ). If $||x|| = 4, ||y|| = 5, ||x+y|| = 7,$ what is $||2x-3y||$? Using the same approach as in part a), where vector $x$ is equal to $\begin{pmatrix} a \\ b  \end{pmatrix}$ and vector $y$ is equal to $\begin{pmatrix} c \\ d \end{pmatrix}$, $a^2+b^2 = 16$ and $c^2+d^2 = 25$. Similarly, for $||x+y||$, after simplification, it equals $41+2(ac+bd) = 49$ -> $ac+bd = 4$. I'm not sure what to do next after this part too. Any hints?","['geometry', 'calculus', 'algebra-precalculus', 'trigonometry']"
1221767,A bessel function integral,$$\int_{-\infty}^{\infty} dy \frac{J_1 \left ( \pi\sqrt{x^2+y^2} \right )}{\sqrt{x^2+y^2}} = \frac{2 \sin{\pi x}}{\pi x} $$ How do I show this?,"['bessel-functions', 'contour-integration', 'calculus', 'laplace-transform']"
1221790,Principal submatrices of a positive definite matrix,"Let $\mathbf{A}\in\mathbb{R}^{N \times N}$ be symmetric positive definite. For some $1\leq k<N$ , partition $$\mathbf{A}=\begin{pmatrix}\mathbf{A}_{11} & \mathbf{A}_{12} \\ \mathbf{A}_{12}^T & \mathbf{A}_{22}\end{pmatrix},$$ where $\mathbf{A}_{11}$ is $k\times k$ and $\mathbf{A}_{22}$ is $(N-k)\times (N-k)$ . I'm trying to show that the principal submatrices $\mathbf{A}_{11}$ and $\mathbf{A}_{22}$ are also symmetric positive definite. I've been able to show that $$\left [ \begin{array}{cc}
\mathbf{A}_{11} & \mathbf{A}_{12}\\
\mathbf{A}_{12}^T & \mathbf{A}_{22} \end{array} \right ] = \mathbf{A} = \mathbf{A}^T = \left [ \begin{array}{cc}
\mathbf{A}_{11}^T & \mathbf{A}_{12}\\
\mathbf{A}_{12}^T & \mathbf{A}_{22}^T \end{array} \right ]$$ This implies that $\mathbf{A}_{11} = \mathbf{A}_{11}^T$ , and $\mathbf{A}_{22} = \mathbf{A}_{22}^T$ . Thus, $\mathbf{A}_{11}$ and $\mathbf{A}_{22}$ are symmetric. I'm struggling to show that $\mathbf{A}$ is positive definite. Does anyone have any ideas?","['positive-definite', 'symmetric-matrices', 'matrices', 'block-matrices', 'linear-algebra']"
1221792,approximation of measurable functions,"Hi we know we can approximate measurable function by simple function however can we increase the conditions such that we can approximate by at most countable functions that is there exists sequence {$s_n$} of non negative F/B* measurable functions such that each assumes at most countable many values, all values finite and $s_n \rightarrow$ f """"""uniformly"""""" ? I tried to change the proof for approximation of simple functions given below however I am having troubles I don't see how I can get the result for those extended simple functions. Here F/B* are defined as follows F is a sigma field on $\Omega$ and define F/B* as follows:
Let A $\in$ F be nonempty, and let f : A $\rightarrow$ $R^{*}$ denote a function. We will say that f is F/B*-measurable iff $f^{-1}(B)$ $\in$ F and both $f^{-1}$({$\infty$}) and $f^{-1}$({-$\infty$}) are in F.","['lebesgue-measure', 'measure-theory']"
1221804,Cholesky Factorization with submatrices,"Let $\mathbf{A}\in\mathbb{R}^{N \times N}$ be symmetric positive definite. For some $1\leq k<N$, partition 
$$\mathbf{A}=\begin{pmatrix}\mathbf{A}_{11} & \mathbf{A}_{12} \\ \mathbf{A}_{12}^T & \mathbf{A}_{22}\end{pmatrix},$$
where $\mathbf{A}_{11}$ is $k\times k$ and $\mathbf{A}_{22}$ is $(N-k)\times (N-k)$. Let $\mathbf{A}=\mathbf{L}\mathbf{L}^T$ be a Cholesky factorization, where 
$$\mathbf{L}=\begin{pmatrix}\mathbf{L}_{11} & \mathbf{0} \\ \mathbf{L}_{21} & \mathbf{L}_{22}\end{pmatrix}.$$
The $k\times k$ matrix $\mathbf{L}_{11}$  and the $(N-k)\times (N-k)$ matrix $\mathbf{L}_{22}$ 
are lower triangular. Express the submatrices  $\mathbf{L}_{ij}$ in terms of the submatrices $\mathbf{A}_{ij}$ and 
appropriate Cholesky factors. I've been able to find that, $$\mathbf{A}_{11} = \mathbf{L}_{11}\mathbf{L}_{11}^T$$
$$\mathbf{A}_{12} = \mathbf{L}_{11}\mathbf{L}_{21}^T$$
$$\mathbf{A}_{12}^T = \mathbf{L}_{21}\mathbf{L}_{11}^T$$
$$\mathbf{A}_{22} = \mathbf{L}_{21}\mathbf{L}_{21}^T + \mathbf{L}_{22}\mathbf{L}_{22}^T,$$ but I am unsure of how to solve for the $\mathbf{L}_{ij}$'s. Does anyone have any ideas?","['numerical-linear-algebra', 'matrices', 'matrix-decomposition', 'cholesky-decomposition', 'linear-algebra']"
1221839,Flatness under reduction,Suppose that $f : X \to Y$ is a flat morphism of schemes.  Is $f_\text{red} : X_\text{red} \to Y_\text{red}$ necessarily flat?  Are there any hypotheses that would guarantee this?,"['algebraic-geometry', 'commutative-algebra']"
1221877,Isomorphism on dense subset,"I am wondering if the following could be done.
I want to show two Banach spaces $X$ and $Y$ are isomorphic.
If $A$ is dense in $X$, and $B$ is dense in $Y$, is it sufficient to show there is an isomorphism $S : A\to B$ to deduce (extending in the obvious way) that $X$ and $Y$ are isomorphic?","['banach-spaces', 'functional-analysis']"
1221905,The irrational rotation is ergodic. The proof should use the idea of density point.,"Consider $f_{\alpha}:S^{1}\rightarrow S^{1}$ the rotation of unit circle of angle  $2\pi\alpha$, and let $\mu$ the Lebesgue measure in $S^{1}$. Let $\alpha$ irrational, show that $\left(f,\mu\right)$ is ergodic.  You should use the idea of density point. Remark: This is a idea of the proof: I understand the idea of proof, I do not understand is why it says: A small neighborhood of the $y_{0}$ consist basically of points of the set $B$.","['lebesgue-measure', 'ergodic-theory', 'measure-theory']"
1221908,Contour Integral of $\log(z)/(1+z^a)$ where $a\gt1$,"I am asked to prove that:
$$ \int_{0}^{+\infty}\frac{\log z}{1+z^{\alpha}}\,dz = -\frac{\pi^2}{\alpha^2}\cdot\frac{\cos\frac{\pi}{\alpha}}{\sin^2\frac{\pi}{\alpha}},$$
provided that $\alpha > 1$, with a complex analytic method, i.e. contour integration. However, I was not able to find a good candidate as a meromorphic function to integrate, neither a proper contour. Would you mind giving me a hand?","['contour-integration', 'complex-analysis', 'complex-integration', 'integration']"
1221930,"if $w$ is a normal distribution where $n(0,1)$, then find the mgf of $w^2$.","if $w$ is a normal distribution where $n(0,1)$, then find the mgf of $w^2$. I have looked it up and the answer is chi squared but i cannot seem to find a way to integrate this correctly. I start the problem by generalizing it as 
$e^{(tx)}* f(x^2)= e^{(tx)}*[1/\sqrt{2\pi } * e^{-(x^2/2)}]^2$ Am I starting this problem of incorrectly ?","['statistics', 'calculus']"
1221934,"Are ""most"" operators on an infinite-dimensional complex Banach space ""diagonalizable""? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question does not appear to be about math within the scope defined in the help center . Closed 9 years ago . Improve this question This is true for finite-dimensional spaces, of course. To be precise, let $T$ be an operator on a complex Banach space $X$ which is not finite-dimensional. For each $\lambda \in \mathbb{C}$, let $V_\lambda \subseteq X$ be the subspace $\mathrm{ker} (\lambda I - T)$ on which $T$ acts by the scalar $\lambda$. Say that $T$ is diagonalizable if $\sum_\lambda V_\lambda$ is dense in $X$. Or provide a better definition if this one is deficient! Are ""most"" operators diagonalizable? For instance, is the set of diagonalizable operators comeagre? Of course, there are lots of operators which are not diagonalizable, but perhaps, as in the finite-dimensional case, they form a ""small"" set. I suppose it's natural to consider just bounded operators, although I'd be interested in results about unbounded operators, too. Of course, if the answer depends on the Banach space $X$, I'd be very interested to learn about that. In a Hilbert space, we can consider the additional condition that the $V_\lambda$ be orthogonal and probably a lot more can be said; I'm interested in this, but I think I'm primarily interested in the more general notion of diagonalizability I gave. Also, the question makes perfect sense for any topological vector space; I'm interested in non-Banach spaces, too. EDIT I've asked this question on mathoverflow ; answers may fit better over there.","['operator-theory', 'banach-spaces', 'functional-analysis']"
1221962,How to prove tensor product is exact when acted on split short exact sequence?,"I know tensor product is right exact, but I can't figure out why it's exact when it is acted on a split short exact sequence. In addition, can you give an example that tensor product acts on a short exact sequence but the result sequence is not exact? Thank you.","['exact-sequence', 'abstract-algebra', 'tensor-products', 'modules']"
1221982,Marginal Distribution of the sum of Bernoulli rv,"consider the conditional on probabilities $p_1, \ldots, p_n$, with independent Bernoulli random variables $Y_1, ..., Y_n$ given that 
$P(Y_i = 1\mid p_1, \ldots, p_n) = p_i, \  P(Y_i = 0\mid p_1, \ldots, p_n) = 1 â p_i$  for  $i = 1, \ldots, n$. if each $p_i$ is a random draw from a distribution with mean $p$.
we are looking for the distribution of $X = Y_1 + \cdots + Y_n$. I am thinking that $X$ follows a bin. distribution. Am I wrong?","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
1221987,basic concept about edge graphs (line graphs),I was learning about the edge graphs or line graphs $L(G)$ of a graph $G$. I read about the relation between degree of any two vertices $u$ and $v$ in $G$ and that of edge $uv$ in $L(G)$. I am just anxious to know is there any relation between the eccentricity of vertices of these two graphs? Any help or suggestion is welcomed. Any link to study in detail about line graphs?,"['discrete-mathematics', 'graph-theory', 'combinatorics']"
1222026,"If $H$ is a Hilbert space, does the coordinate projection $\pi :H\oplus H\rightarrow H$ take closed subspaces to closed subspaces?","Here $H\oplus H$ has the product topology, which is induced from the ""$\ell^2$-norm"" $\|(x,y)\|:=\sqrt{\|x\|^2+\|y\|^2}$. This is indeed a Hilbert space via the inner product $\langle (x,y), (x',y')\rangle := \langle x,x'\rangle + \langle y,y'\rangle$. Now we have a projection $\pi : H\oplus H \rightarrow H$, given by $(x,y)\mapsto x$. My question is: if $M$ is a closed subspace of $H\oplus H$, then is $\pi(M)$ a closed subspace of $H$?","['hilbert-spaces', 'functional-analysis']"
1222070,Why does my covariant derivative look different?,"It is known for $f$ a smooth function and vector fields $X$ , the covariant derivative obeys product rule $$\nabla_Y(fX) = (Yf)\nabla_YX+f\nabla_Y X$$ I just did this calculation and i keep getting $\nabla_Y(fX) = X \nabla_Yf +f\nabla_Y X$ . Basically, $\nabla_Y(fx) = (Y(fX^1), \dots, Y(fX^n))$ . Now $Y(fX^1) = <grad(fX^1), Y> = <X^1gradf,Y>+ <fgrad X^1, Y>$ . So putting it back I should get $\nabla_Y(fX) = X \nabla_Yf +f\nabla_Y X$ . But my first term does not match",['differential-geometry']
1222089,Right-exactness of KÃ¤hler-Differential and zeroth relative homology functor,"In Commutative Algebra: with a View Toward Algebraic Geometry Eisenbud describes the KÃ¤hler-Differential as a functor that assigns $\Omega_{S/R}$ to an $R$-Algebra $S$ and to a commutative diagramm
$$
S \xrightarrow{\hspace{1cm}} S' \\
\uparrow \hspace{1.5cm} \uparrow \\
R \xrightarrow{\hspace{1cm}} R'
$$
of rings the corresponding morphism $\Omega_{S/R} \to \Omega_{S'/R'}$ which makes the diagramm
$$
\Omega_{S/R} \xrightarrow{\hspace{.5cm}} \Omega_{S'/R'} \\
\uparrow \hspace{1.5cm} \uparrow \\
S \xrightarrow{\hspace{1cm}} S'
$$
commute. Then he writes It is right-exact in the same sense that the zeroth relative homology functor is a right-exact functor of pairs of spaces in topology. Question: What is that supposed to mean? Does he maybe mean the relative cotangent sequence ? For ringmorphisms $R \to S \to T$ we get an exact sequence of $T$-modules
$$ T \otimes_S \Omega_{S/R} \to \Omega_{T/R} \to \Omega_{T/S} \to 0.$$ As I understand this, the two left morphisms in this exact sequence come from the construction above. However I don't understand how this statement can be understood as right-exactness, because we would have to start with an exact sequence but we don't. Also I couldn't find anything to understand his statement about the zeroth relative homology functor.","['exact-sequence', 'general-topology', 'commutative-algebra']"
1222113,95% Confidence Intervals,"I was solving this problem from a textbook In a random sample of three pupils, $x_i$ is the mark of the $i$ th pupil in a test on volcanoes and $y_i$ is the mark of the $i$ th pupil in a test on glaciers. All three pupils sit both tests. It is believed that the difference between the results in these two tests follows a normal distribution with variance $16$ marks. If the mean mark on the volcano test was $23$ and the man mark for the glacier test was $30$ , find a $95\%$ confidence interval for the improvement in marks from the volcano test to the glacier test. My attempt was, letting the desired distribution be $\overline{Y-X}$ . We know that the mean is $\overline{y-x} = \bar{y} - \bar{x} = 30-23= 7$ . Standard deviation is given as $16$ , $\Phi^{-1}(0.975) = 1.959$ , and number of samples is $n=3$ . Hence average improvement, $\mu$ , would lie in the interval, $$ \bar{x} - 1.959 \frac{4}{\sqrt{3}} < \mu  < \bar{x} + 1.959 \frac{4}{\sqrt{3}}$$ giving our confidence interval $[ 2.478, 11.524 ]$ . However, the actual interval from the textbook is $ [ -11.1, 25.1 ] $ May someone explain why? Thank you so much!","['means', 'probability-distributions', 'statistics', 'standard-deviation', 'probability']"
1222117,Quadratic Variation of Increasing Process?,"I am looking through my notes and I came across the following statement: Let $X_s$ be a positive local martingale and let $M_t = max_{0 \le s \le t} X_s$. Then since $M_t$ is an increasing process, $[X,M] = [M] = 0$. Why is this true? On a similar note, the claim is made that in terms of stochastic integrals, $dM_s$ is $0$ unless $X_s = M_s$. I'm not sure why this holds either.","['probability-theory', 'stochastic-calculus', 'stochastic-integrals', 'stochastic-processes']"
1222129,Generalization of Minkowski inequality,"I am wondering if the following is true: Suppose continuous function $g: [0, \infty) \to [0, \infty)$ satisfying $g(0)=0$ is increasing and strictly convex and (therefore) invertible. Let $||f ||^g$ denote $g^{-1}(\int_X g \circ |f| d \mu)$ where $f$ is measurable for measurable space $(X, M, \mu)$. Then for any measurable functions $f_1$ and $f_2$ we have $$ || f_1 +f_2||^g \le ||f_1||^g + ||f_2||^g$$ I think this is true, but am particularly interested if it is true for when $g(x) = (x+1)^p -1$ with $(X, M, \mu)$ being the usual Lebesgue measure space with $X=R^n$. Any insights, ideas, or references would be appreciated.","['lp-spaces', 'reference-request', 'real-analysis', 'measure-theory']"
1222137,Visualising surface integrals,"For a current problem I am working on, I have run into angular surface integrals, i.e. the differential solid angle $\text{d}\Omega$. Specifically the surface integrals are defined by 
\begin{equation}
A_{\mu\nu} = \int\int_{\rm S} \text{d}\Omega~ \frac{x_\mu x_\nu}{r^2},
\end{equation}
where $x_\mu=\{x,y,z\}$ for $\mu=1,2,3$ and $r = \sqrt{x_1^2+x_2^2+x_3^2}$ and the differential solid angle is the usual definition $\text{d}\Omega=\sin(\theta)d\theta d\phi$. It is easy to show, by evaluating the integrals analytically that 
\begin{equation}
A_{\mu\nu} = \frac{4\pi}{3}\delta_{\mu\nu}.
\end{equation}
Here $\delta_{\mu\nu}$ is the Kronecker delta. What if I wanted to visualise these surface integrals? I tried plotting the angular functions which are being integrated i.e. for $A_{22}$
\begin{equation}
A_{22} = \int\int_{\rm S} \text{d}\Omega~ \frac{x_2 x_2}{r^2} = \int\int_{\rm S} \text{d}\Omega~ \left(\sin(\theta)\sin(\phi)\right)^2
\end{equation}
I plotted the angular function $f(\theta,\phi)=\left(\sin(\theta)\sin(\phi)\right)^2$, and get the figure below Now for $A_{23}$, which equals zero, I get the following 
\begin{equation}
A_{23} = \int\int_{\rm S} \text{d}\Omega~ \frac{x_2 x_3}{r^2} = \int\int_{\rm S} \text{d}\Omega~ \left(\sin(\theta)\sin(\phi)\cos(\theta)\right)
\end{equation}
which when plotted looks like I can obviously see the symmetries and anti-symmetries for two different surfaces although I can't figure out why the second one has a surface integral of zero. To me it should be the first, as they cancel. Am I plotting these surface integrals correctly? Can someone explain the difference between the two surfaces, and why the second is equal to zero and not the first? Thanks.","['calculus', 'visualization', 'integration', 'graphing-functions', 'multivariable-calculus']"
1222142,prove that 2 by 2 Jacobian is equal to $|f'(z_0)|^2$,"This is a question in Complex Analysis for Mathematical Science and Engineering by Saff and Snider. It's on pg 62. Question:
The Jacobian of a mapping $u = u(x,y)$ $v = v(x,y)$ from the xy-plane to the uv-plane is defined to be the determinant 
$$ J(x_0,y_0) := \begin{vmatrix} \frac{\partial{u}}{\partial{x}} &&  \frac{\partial{u}}{\partial{y}} \\ \frac{\partial{v}}{\partial{x}} &&  \frac{\partial{v}}{\partial{y}} \end{vmatrix}$$ Where the derivatives are all evaluated at $(x_0, y_0)$. Show that if $f = u + iv$ is analytic at $z_0 = x_0 + iy_0$, then $J(x_0,y_0) = |f'(z_0)|^2$. My attempt to answer:
Given f'(z) is analytic $f'(z) = \frac{\partial{u}}{\partial{x}} + i\frac{\partial{v}}{\partial{x}}$ which leads us to $|f'(z_0)|^2 = \frac{\partial{u}}{\partial{x}}^2 - \frac{\partial{v}}{\partial{x}}^2$. We can now use the Cauchy-Riemann equations as substitutions; 
$$|f'(z_0)|^2 = \frac{\partial{u}}{\partial{x}}\left(\frac{\partial{y}}{\partial{y}} \right)- \frac{\partial{v}}{\partial{x}}\left(-\frac{\partial{v}}{\partial{x}}\right) $$ But now the minus signs in the second term cancel and it is positive. The second term from the determinant should be negative. What did I do wrong?",['complex-analysis']
1222143,Principal component analysis - calculating variance,"Quoting Rahul's answer : It's not hard to show that if the covariance matrix of the original
  data points $x_i$ was $\Sigma$, the variance of the new data points is
  just $u^{T}\Sigma u$. The covariance between sets $X$ and $Y$ is defined as $\sum_i = \frac{1}{n}(x_i-\bar{x})(y_i-\bar{y})$, where $\bar{x}$ and $\bar{y}$ denote the mean. In some other material I've found it says something else than what I've quoted:
Here, the variance is not equal to $u^{T}\Sigma u$. It would be if $A$ in this case were multiplied by $\frac{1}{n}$. They say $A$ would be a covariance matrix if the coefficient was present. But it's not. It looks 'a bit' incompatible with the statement in the quote. The question is - who is wrong here and what is variance equal to? I suppose Rahul is right saying that the variance is equal to $u^{T}\Sigma u$, where $\Sigma$ is the covariance matrix. But the picture below proves a different equality, so what's going on here? Here on page 8, the author derives the equality supporting Rahul's claim (I can't quite understand what's going on there). Which one is correct? Source","['statistics', 'linear-algebra']"
1222155,Modifying a smooth function with respect to conditions on its partial derivates,"Let $\{U_i\}_{i\in I}$ be a locally finite collection of open subsets of $\mathbb{R}^n$, $K_i\subseteq U_i$ compact subsets, $\epsilon_i>0$ positive real numbers and a nonnegative natural number $k$. Let now $K$ be another compact subset of $\mathbb{R}^n$. Since the collection is locally finite, $K$ intersects only finitely many of the $U_i$ nontrivially, let's say these are $U_1,...,U_n$. Let $f\colon\mathbb{R}^n\rightarrow\mathbb{R}$ be a smooth function (all partial derivatives of all order exists and are differntiable) such that $\frac{\partial^{|\alpha|}}{\partial x^\alpha}f(x)<\epsilon_i$ for all $x\in K_i$, $i\in\{1,...,n\}$ and all multiindices $\alpha$ of order $|\alpha|\le k$, e.g. all partial derivatives of $f$ up to order $k$ are $\epsilon_i$-bounded in the compact subsets, which might intersect $K$. Is there a smooth function $f'\colon\mathbb{R}^n\rightarrow\mathbb{R}$ for which the condition above does hold for all $i\in I$ and which agrees with $f$ on $K$? My attempt was the following: Choose a bump function $\delta\colon \mathbb{R}^n\rightarrow (0,\infty)$ which is $1$ on a neighborhood of $K$ and $0$ outside a small compact subset $L$ which includes $K$ and try $f'=\delta f$, but that seemed not to work out since a couldn't control the partial derivatives of the bump function in the area where it goes from $1$ to $0$.","['real-analysis', 'functional-analysis', 'general-topology', 'differential-topology', 'differential-geometry']"
1222170,Probability of sub-probability,"I have 3 clients whose advertising is shown in some mobile app. Each client has a list of ads that can be shown with equal probability. As a concrete example: Client A is featured 20% of the time, and has 5 ads Client B is featured 30% of the time, and has 10 ads Client C is featured 50% of the time, and has 15 ads So given an arbitrary pageview, there is a 50% chance that client C will have one of its 15 ads displayed to the user. Question How do I calculate the probability of a specific ad from client C being displayed? How do I express ((1 out of 15) out of 50%) in terms of the overall probability?","['probability', 'discrete-mathematics']"
1222175,Number of integral coordinates in a given region.,"The number of points, having both coordinates as integers, that lie in the interior of the triangle with
vertices $(0,0) ,(0, 41$) and $(41,0)$ , is: (1) 901   (2) 861   (3) 820   (4) 780. I tried to find out the number of points manually, but it didn't look like the optimal method.
Thanks in advance.","['euclidean-geometry', 'geometry']"
1222187,Why does group action by conjugation on sylow subgroups define a homomorphism into the symmetric group?,Sylow theorems state that sylow p subgroups of a group G are conjugate. Often I see argumentation that if there are n sylow p subgroups in G then we can define a group action on it by conjugation and hence create a homomorphism from G into Symmetric group or order n. Please provide a proof that this homomorphism is legitimate and why conjugation by any element on a sylow p subgroup takes you to another sylow p subgroup?,"['sylow-theory', 'group-theory']"
1222200,Entropy for three random variables [duplicate],"This question already has answers here : Calculating conditional entropy given two random variables (2 answers) Closed 9 years ago . I'm just working through some information theory and entropy, and I've come into a bit of a problem. In many texts, it's easy to find the ""chain rule"" for entropy in two variables, and the ""conditional chain rule"" for three variables, respectively;
$$H(Y|X) = H(X,Y) - H(X)$$
$$H(X,Y|Z) = H(Y|Z) + H(X|Y,Z) = H(X|Z) + H(Y|X,Z)$$ However, I'm trying to determine the entropy of three random variables: $H(X,Y,Z)$. I haven't done a lot of probability/statistics before, and googling hasn't really turned up anything too fruitful. Can anyone help me derive this result??","['entropy', 'probability', 'statistics', 'information-theory']"
1222237,A Characterization of Categories with a Conservative Forgetful Functor to SET,"Examples of categories over $\bf{Set}$ such that the forgetful functor is conservative include the ""algebraic"" categories of groups, rings, modules, monoids, etc., but does not include the ""higher-order"" categories of topological spaces, smooth manifolds, schemes, etc. or some ""relational"" categories like posets. Is there any intrinsic characterization of the difference in behavior here? Do we know that certain classes of categories always have conservative forgetful functors to $\bf{Set}$? I'd be particularly interested in a model-theoretic description (i.e. something like the fact that the first examples are categories of models of an algebraic first order theory while the later ones are not), but I'd also be interested in a description in terms of categorical properties. EDIT : As pointed out in the answers, it's often possible to give a conservative faithful functor to $\bf{Set}$. However, these aren't the ""underlying set"" forgetful functors; they include extra information. Maybe the question becomes more interesting if we require the functor to be ""canonical"". This doesn't make much sense in terms of categories alone, but perhaps it does in terms of model theory: given a (perhaps higher-order) theory $\mathbb{T}$, when is the forgetful functor $\text{MOD-}\mathbb{T}(\bf{Set}) \rightarrow \bf{Set}$ conservative?","['abstract-algebra', 'logic', 'model-theory', 'category-theory']"
1222255,Showing $T$ equivalent to linear map,"Let $T$ be a $(1,1)$ tensor over a vector space $V$.  Let $\left\{e_a\right\}$ be a basis for $V$ and $\left\{f^a\right \}$ be its dual basis.  Show that $T$ is equivalent to a linear map $V^* \rightarrow V^*$.  Similarly, show that $T$ is also equivalent to a linear map $V \rightarrow V$. Attempt:
$T$ being a $(1,1)$ tensor means that it is a linear map $V^* \times V \rightarrow \mathbb{R}$ or explicitly, I think I can write $T : (\lambda, X) \mapsto \lambda_a X^aT^i_{\,\,j} \in \mathbb{R}$ where $T^i_{\,\,j}, \lambda_a$ and $X^a$ are coefficients of the tensor, co-vector and vector respectively in basis $\left\{f^a, e_a\right\}$ . Now the book goes onto write the following: Given a $(1, 1)$ tensor $T$ and $\lambda \in V^*$, we can form the $(0, 1)$ tensor $T(\lambda, \cdot)$, i.e.
$T(\lambda, \cdot) \in V^*$.  Thus $T$ defines a linear map $V^* \rightarrow V^*$, $Î» \mapsto T(\lambda, \cdot).$  I don't really understand this paragraph. How can such a tensor be formed? It looks like some sort of contraction, however contraction of a $(1,1)$ tensor would only produce $(0,0)$ tensor as far as I understand. (Contraction of $T^i_{\,\,j} \rightarrow T^i_{\,\,i}$). Similarly, why is $T(\lambda, \cdot)$ even a $(0,1)$ tensor? As far as I understand, the notation $(0,1)$ means the map feeds on zero covector arguments and one vector argument which is not what $T(\lambda, \cdot)$ suggests given that $\lambda \in V^*$. Many thanks!","['vector-spaces', 'vectors', 'differential-geometry', 'linear-algebra', 'tensors']"
1222284,Use of $L^2$ norm in calculus of variations,"I am trying to make an introduction to the calculus of variations. This field has many connections with  functional analysis, in which I do not have an experience. I recently learned about function spaces, for example the space of all continuous functions $C[a,b]$ on the interval $[a,b]$ and the space of square integrable functions $L^2[a,b]$ on the interval $[a,b]$. It seems that in many resources about Calculus of Variations, the functional derivative in the direction of a function $v$ is given with the inner product $\langle \nabla J[u],v\rangle$ where $\nabla J[u]$ is the functional gradient. The inner product is defined as the $L^2$ norm of the form $\langle f, g \rangle = \int_{b}^{a}f(x)g(x)dx$. From there it follows the derivation of the Euler-Langrange formula, etc. My question is, why does one chooses the $L^2$ norm here specifically, in the context of Calculus of Variations? It seems that there are different norms associated with different function spaces in functional analysis: Doesn't this limit the candidate functions in an optimization problem to be in $L^2$ space? Maybe the reason is that $L^2$ norm can be seen as a natural expansion of the dot product in finite Euclidean spaces to infinite dimensional function spaces? I have not well understood this point; maybe I am asking something too obvious, excuse me if it is so, since I am a beginner in this field.","['calculus-of-variations', 'real-analysis', 'functional-analysis']"
