question_id,title,body,tags
3720983,Value of $n$ for which the function $x^n \sin {\frac{1}{x}}$ is continuous at $x=0$,"The question is as follows, Determine the values of $n$ for which the function, $$f(x) = \begin{cases}x^n\sin\left(\frac1x\right) & ,x\neq 0 \\ 0 & ,x=0\end{cases}$$ is continuous at $x=0$ The way I tried to solve it is by using inequalities, starting with, $$-1 \leq \sin \left(\frac1x\right) \leq 1$$ $$-x^n \leq x^n\sin \left(\frac1x\right) \leq x^n$$ $$\lim_{x\rightarrow 0} -x^n \leq \lim _{x\rightarrow0} f(x) \leq \lim_{x\rightarrow 0} x^n $$ Which gives us, continuity $\forall \;n$ This seems right but I'm not sure, could someone confirm it and also is there a better method?","['continuity', 'functions']"
3720989,What can be concluded about the probability: $\mathbb{P}(\sum\limits_{n\ge1}\frac{X_n}{n} \quad\text{converges})$?,"Let $\{X_n\}_{n\ge1}$ be a sequence of i.i.d. random variables with $\mathbb{P}(X_n=1)=\mathbb{P}(X_n=-1)=\frac{1}{2}$ . What can be concluded about the probability: \begin{align}
\mathbb{P}(\sum\limits_{n\ge1}\frac{X_n}{n} \quad\text{converges})?
\end{align} I believe that I have a solution which doesn't utilize the fact that they are identically distributed at all, so I am wondering if the following is correct? Note that $\{X_n\}_{n\ge1}$ is an independent sequence of r.v.'s $\implies$ that $\{\frac{X_n}{n}\}_{n\ge1}$ is an independent sequence of r.v.'s. Now note that: \begin{align}
A:&=\{\sum\limits_{n\ge1}\frac{X_n}{n} \quad\text{converges}\}\\
&=\{\sum\limits_{n\ge k}\frac{X_n}{n} \quad\text{converges}\} \quad\text{for all}\ k\ge 1\\
&\in \sigma(\frac{X_k}{k},\frac{X_{k+1}}{k+1},\frac{X_{k+2}}{k+2},...) \quad\text{for all}\ k\ge 1\\
\end{align} Hence, $A \in \bigcap\limits_{k\ge1}\sigma(\frac{X_k}{k},\frac{X_{k+1}}{k+1},\frac{X_{k+2}}{k+2},...)=\tau$ and therefore by Kolmogorov's 0-1 law: $\mathbb{P}(A)=0\ \text{or}\ 1 $ . Am I missing something and this solution is incorrect? Otherwise, I don't see a need to even mention the distribution of the $X_n$ 's.","['self-learning', 'probability-distributions', 'probability-theory', 'probability']"
3721042,Is there an entire function with domains for which $f(A)=B$ and $f(B)=A$?,"Let $f$ be an entire function. Suppose that there exist two nonempty disjoint, open, connected non-empty sets $A,B$ in the plane such that $f(A)=B$ and $f(B)=A$ . Does it follow that $f$ is linear? Equivalently, if a meromorphic function satisfies this condition is it necessarily an automorphism? Neither of the conditions of disjointness and openness can be dropped, of course. I tried to see if results in dynamics about 2-periodic domains apply, but they usually only regard Fatou components or are otherwise not suitable. But it does seem like a question simple enough that it ""ought to"" be amenable to such machinery. Any ideas?","['complex-analysis', 'complex-dynamics']"
3721047,Turning An Algebraic Number Into An Algebraic Integer,"We know that for any algebraic number $\alpha$ $\exists$ $m\in\mathbb{Z}\setminus\{0\}$ such that $m\alpha$ is an algebraic integer. If $\alpha$ is an algebraic integer then $m=1$ suffices. But if $\alpha$ is not an algebraic integer but an algebraic number then we have the following theorem. Theorem: Let $$f(X)=a_nX^n+a_{n-1}X^{n-1}+\ldots+a_1X+a_0\in\mathbb{Z}[X]\;(a_n>0)$$ be the unique irreducible polynomial with $\gcd(a_n,a_{n-1},\ldots,a_1,a_0)=1$ and $\alpha$ as a root. Then $a_n\alpha$ is an algebraic integer. Proof: Consider the monic polynomial $$P(X)=X^n+a_{n-1}X^{n-1}+a_na_{n-2}X^{n-2}+\ldots+a_n^{n-2}a_1X+a_n^{n-1}a_0\in\mathbb{Z}[X]$$ Then $$P(a_n\alpha)=(a_n\alpha)^n+a_{n-1}(a_n\alpha)^{n-1}+a_na_{n-2}(a_n\alpha)^{n-2}+\ldots+a_n^{n-2}a_1(a_n\alpha)+a_n^{n-1}a_0\\=a_n^{n-1}(a_n\alpha^n+a_{n-1}\alpha^{n-1}+a_{n-2}\alpha^{n-2}+\ldots+a_1\alpha+a_0)=a_n^{n-1}f(\alpha)=0$$ Hence $a_n\alpha$ , being a root of the monic polynomial $P(X)$ in $\mathbb{Z}[X]$ , is an algebraic integer. My question: Denote the set of algebraic integers by $\mathbb{A}$ . Then the theorem says for a particular algebraic number $\alpha$ the set $$S_{\alpha}=\{|m|:m\in\mathbb{Z},m\alpha\in\mathbb{A}\}\setminus\{0\}\neq\emptyset$$ Consider the algebraic number $\frac{\sqrt{2}}{3}$ . Clearly $3\in S_{\frac{\sqrt{2}}{3}}$ . The minimal polynomial in $\mathbb{Z}[X]$ for $\frac{\sqrt{2}}{3}$ is $9X^2-2$ . Hence by the theorem $9\in S_{\frac{\sqrt{2}}{3}}$ . Moreover since $\frac{\sqrt{2}}{3},\frac{2\sqrt{2}}{3}$ are not algebraic integers we have $\min(S_{\frac{\sqrt{2}}{3}})=3$ . This example shows that $a_n$ is not necessarily $\mathrm{min}(S_{\alpha})$ . But by Well-ordering principle $\min(S_{\alpha})$ exists. Can we compute $\min(S_{\alpha})$ in terms of $\alpha$ ?","['number-theory', 'abstract-algebra', 'algebraic-number-theory', 'algebraic-numbers']"
3721081,"For every natural number $n$, $f(n) =$ the smallest prime factor of $n.$ For example, $f(12) = 2, f(105) = 3$","QUESTION: Let $f$ be a continuous function from $\Bbb{R}$ to $\Bbb{R}$ (where $\Bbb{R}$ is the set of all real numbers) that satisfies the following property: For every natural number $n$ , $f(n) =$ the smallest prime factor of $n.$ For example, $f(12) = 2, f(105) = 3.$ Calculate the following- $(a)\lim_{xâ†’âˆž}f(x)$ $(b)$ The number of solutions to the equation $f(x) = 2016$ . MY SOLUTION: I do not have a problem in understanding part $(a)$ . Clearly, $\infty$ is not a number and we cannot find any smallest prime factor for it. Or we can also argue that for any even number- $f(even)=2$ And for any odd number it depends on the type of the odd number.. in case it's prime then $f(prime \space x)=x$ and in case it's not prime then the answer is something else.. Anyway, we find that there are numerous possibilities and since all of these possibilities directly depend on the number we have chosen so, we cannot account for what happens in the case of $\infty$ . Coming to the second part, the question itself bounced over my head. Let's see carefully what it says- We know, $f(x)=$ the smallest prime factor of $x$ . Therefore, $f(x)=2016$ must imply (by the same logic that)- The smallest prime factor of $x$ is $2016$ . Wait. What?! Firstly, 2016 is not prime. So how can I account for $x's$ which have such an impossible prime factor.. secondly, even if we assume that $2016$ is the smallest factor of $x$ there are infinite $x's$ which satisfies such a property. Our answer in that case is not bounded (although it's nowhere mentioned it should be).. So what does the second part even mean? ðŸ¤” Thank you in advance for your kind help :).","['prime-factorization', 'functions', 'prime-numbers']"
3721097,"If $A$, $B$ and $C$ are sets, where $A \triangle C = B \triangle C $, then $ A = B $","I have to prove or disprove the following claim: If $A$ , $B$ and $C$ are sets, where $A \triangle C = B \triangle C $ , then $ A = B $ My proof is the following: Consider any sets $A$ , $B$ and $C$ , where $A \triangle C = B \triangle C $ . We need to prove, that $ A = B $ by showing that $ A \subseteq B $ and $ B \subseteq A $ . First, we will show that $ A \subseteq B$ . For this, consider any $ x \in A $ . We will prove that $ x \in B $ . Notice, that either $ x \in C $ or $ x \not\in C $ . Therefore we will proceed by cases: $ x \in C $ . Since $ x \in A $ and $ x \in C$ , we see that $ x \not\in A \triangle C $ . Consequently, as $ A \triangle C = B \triangle C $ , we know that $ x\not\in B \triangle C $ . This means that $ x \in B $ . $ x \not\in C $ . This means that $ x \in A \triangle C $ . Consequently, $ x \in B \triangle C $ . Therefore $ x \in B $ . The second part of the proof (to show that $ B \subseteq A $ ) is very similar to this. Can someone please take a look at the proof and criticize it? I'm especially interested in this part: Note, that either $ x \in C $ or $ x \not\in C $ . Therefore we will proceed by cases: Is it okay to proceed this way or is it unclear or incorrect? I'd be also grateful if someone could provide another simpler proof if there exists one.","['elementary-set-theory', 'proof-writing', 'solution-verification', 'alternative-proof']"
3721113,Heat equation solution using Fourier transform,"I want to solve the equation $$x^2\frac{\partial^2 u(x,t)}{\partial x^2}+ax\frac{\partial u(x,t)}{\partial x}=\frac{\partial u(x,t)}{\partial t}$$ with $u(x,0)=f(x)$ for $0<x<\infty$ and $t>0$ . Substituting $U(y,t)=u(e^{-y},t)$ and $F(y)=f(e^{-y})$ we get $$ \frac{\partial^2 U(y,t)}{\partial y^2}+(1-a)\frac{\partial U(y,t)}{\partial y}=\frac{\partial U(y,t)}{\partial t},$$ with the solution $$\hat U(\xi,t)=\hat F(\xi)e^{(-4\pi\xi^2+(1-a)2\pi i\xi)t},$$ since $\hat U(\xi,0)=\hat F(\xi)$ . Taking the Fourier transform in the y variable (assuming that u satisfies the necessary conditions and $\hat {\frac{\partial U}{\partial t}}$ = $\frac{\partial}{\partial t}\hat U$ ), and using $$\hat F(\xi)=\int_{-\infty}^{\infty} F(x)e^{-2\pi xi\xi} dx=\int_{0}^{\infty} \frac{f(y)}{y}e^{2\pi i\log(y)\xi} dy,$$ we are supposed to get $$u(x,t)=\frac{1}{\sqrt{4\pi t}}\int_0^{\infty}e^{-(\log(v/x)+(1-a)t)^2/(4t)}f(v) \frac{dv}{v},$$ whereas I get $$\int_{-\infty}^{\infty} \int_0^{\infty} e^{(-4\pi^2\xi^2+(1-a)2\pi i\xi)t}e^{2\pi\log(y/x)i\xi} \frac{f(y)}{y} dyd\xi$$ and don't know how to simplify it.","['complex-analysis', 'fourier-analysis', 'fourier-transform', 'heat-equation']"
3721124,$I_n \sim I_m $ iff $ n=m $ by induction over n,"This question is related to Prove that if $A \sim I_n$ and $A \sim I_m$ then $n=m$ in which basicaly the same was proof in another way.Now my aim is to understand the following proof by mathematical induction I have the following proof in my lecture notes: Clearly if $n=m$ , the identity mapping over $I_n$ is bijective and then $I_n \sim I_m $ Viceversa, let $I_n \sim I_m $ and let's uppose $n\leq m$ . If $n=1$ and $\varphi:I_1 \rightarrow I_m$ is bijective, then it is also surjective: therefore m=1.
Let's supposse the thesis is true for a fixed $n \geq 1$ and let's verify it for $n+1$ . Let $\varphi:I_{n+1} \rightarrow I_m$ be bijective and let $u=\varphi(n+1) \in I_m$ . The mapping: $$\tau: I_m \rightarrow I_m $$ $$k \rightarrow\begin{cases} 
k, &\text{if }k \neq u,m\\
u, &\text{if } k=m\\
m, &\text{if } k=u 
\end{cases}$$ is bijective, and so is $\tau \circ\varphi:I_{n+1} \rightarrow I_m$ Because $\tau \circ\varphi(n+1)=\tau(u)=m,$ it follows that $\varphi_{\big|I_n}$ is a bijection from $I_n$ to $I_{m-1}$ , so by inductive hypothesis $n=m-1$ , that is $n+1=m$ . The thesis is then proved by induction I have two questions about this proof Is there an error in the last part?: Shouldn't it be ( $\tau \circ\varphi)_{\big|I_n}$ instead of $\varphi_{\big|I_n}$ ? Why do I need to define $\tau$ and $\tau \circ \varphi$ for? Can't I just define : $\theta: I_n \rightarrow I_{m}\setminus{\varphi(n+1)}$ which is bijective since I am only taking $(n+1,\varphi(n+1)) $ out of $\varphi$ and then apply the inductive hypothesis to it, so that $n=m-1$ , that is $n+1=m$ .","['elementary-set-theory', 'induction']"
3721157,Is this Linear Algebra Approach for Tangent Plane of an Ellipsoid Legal?,"In my vectorial calculus course, I was basically asked for finding a tangent plane for an ellipsoid parallel to a given plane by means of the gradient. Exactly the question was: Find the values of m for which the plane $x - 2y -2z  + m = 0$ is
tangent to the ellipsoid $x^2 +4y^2 +16z^2 = 144$ I solve it using the gradient, but I thought it could be a more interesting way to solve it. Firstly, I suppose that if we were making the exact same problem with a sphere of radius 12, we could take advantage of its symmetryâ€¦ Modify the scale of the coordinates to transform the ellipsoid into a sphere, by making the substitutions $x = x'$ , $ y = \frac{1}{2} y'$ , $z = \frac{1}{4}z'$ . Hence I am working in a kind of $\rm I\!R^{'3}$ instead of $\rm I\!R^3$ Apply the same exact substitution to the plane, in order to bring it to my new space, as well. Use the normalised vector normal to the plane, and find the scalar $\alpha$ for which the vector line intersects the surface of the sphere. Let's call it $v_1^{'}$ . Technically speaking, that vector represents the point in which the the plane in $\rm I\!R^{'3}$ is tangent to the sphere. Apply a linear transformation T to $v_1^{'}$ , so that $T:\rm I\!R^{'3} \rightarrow  \rm I\!R^3$ whose associate matrix is \begin{bmatrix}
1 & 0 & 0\\
0 & 2 & 0\\
0 & 0 & 4
\end{bmatrix} In order to bring my $v_1^{'}$ to the original space. Once I have my new vector $v_1$ , It also touches the ellipsoid at it's surface. But is clear that is not normal to my original plane. However, as it is the point of hypothetical contact of the plane with the ellipsoid, I just calculate the norm of the projection of $v_1$ on the my normal vector $n$ , and used it as the distance required for my plane to move in order to be tangent to the ellipsoid. Using the distance between planes equation, I found my final m and finished the exercise. However, I'm not sure if it's completely legal. And if it was, is there any other application of this technique?, we can use if for more complex problems?","['multivariable-calculus', 'linear-algebra', 'vectors', 'vector-analysis']"
3721171,What is the name of the numbers defined by this recursion based on the expansion of exp(1)?,"I was playing around and deduced that for $n$ a whole number $\sum_{j=0}^{\infty} \frac{j^n}{j!} = f(n)e$ . The integer coefficients $f(n)$ with $f(0)=1$ , satisfy the recursion $f(n+1)=\sum_{j=0}^n ($$\begin{matrix}n\\j\end{matrix}$$)f(j)$ . The first values $f(1)$ to $f(8)$ are stated on page 13, (Formula 0.248) of Gradshteyn and Ryzhik 6'th edition. No name is given for these numbers which grow faster than an exponential function of $n$ .","['terminology', 'discrete-mathematics', 'sequences-and-series']"
3721174,Is the Wallman compactification of a locally compact $T_1$ space locally compact?,"Let $X$ be a $T_1$ topological space which is locally compact (in the sense that every point has a local base of compact neighbourhoods). Let $W(X)$ be the Wallman compactification of $X$ . Is $W(X)$ locally compact? As a step towards this, is the remainder $X^*= W(X)\setminus X$ locally compact? The remainder $X^*$ is certainly closed in $W(X)$ , and hence compact. To see this, suppose that $X$ is non-compact and that $K$ is a compact neighbourhood of a point $x\in X$ , with interior $U$ . Let $C$ be the complement of $U$ in $X$ . Then $C$ belongs to every free closed ultrafilter $\cal F$ on $X$ , for otherwise, by the disjointness of ultrafilters, there is closed set $D$ belonging to $\cal F$ disjoint from $C$ . Then $D\subseteq U\subseteq K$ , and hence $D$ is compact, and thus $\cal F$ is a fixed ultrafilter. Hence the closure of $C$ in $W(X)$ is $C\cup X^*$ . It follows that $U$ is open in $W(X)$ , and thus that $X^*$ is closed.","['general-topology', 'compactification', 'compactness']"
3721190,When will an ellipse â€˜fallâ€™ into a parabola?,"Consider the parabola $y=x^2$ and an ellipse which â€˜restsâ€™ on it, given by the equation $$\frac{x^2}{a^2} +\frac{(y-h)^2}{b^2}=1$$ The goal is to find all ordered pairs $(a,b)$ for which the ellipse doesnâ€™t fall to the origin, namely it touches the parabola at two distinct points. Replacing $y$ by $x^2$ in the equation of the ellipse, we get $$\frac{x^2}{a^2} +\frac{(x^2-h)^2}{b^2}=1 $$ I could calculate the discriminant of this quadratic in $x^2$ and set it $\gt 0$ . Is there a quick and neat way to express $h$ in terms of $a,b$ ? Or maybe another approach to solve this problem?","['coordinate-systems', 'tangent-line', 'conic-sections', 'geometry']"
3721209,What is the limiting probability distribution of a prime random walk,"This random walk has an infinite amount of possibility. these are the moves ranked most common to least $(\times 0+1,+1,\times2,\times3,\times5,\times7,\times11,\times13,\times17,\times19,\times23,\times29,...,\times P(n),...)$ the most common operation has a probability of 1/2, the second 1/4, the kth most common has a $1/(2^k)$ chance to happen.
So a possible walk would be $((((((1)\times0+1)+1)\times7)+1)\times2)$ the place it would have landed on would be $30$ . so let's say $P_m(k)$ is the probability that k is the end of an m step walk
I would like to know the limit as m goes to infinity or a good estimation for $f(k)$ $$f(k) = \lim_{m \to \infty} P_m(k)?$$","['random-walk', 'markov-chains', 'probability', 'prime-numbers']"
3721344,Probability of different winners in a two candidate election (range voting vs majority),"I was clicking through the xkcd comics, and I came upon xkcd 2225 . I didn't know about "" Range Voting "", so decided to read about this voting system. I came up with the following problem based off it: Let there be $2$ candidates in an election, $C_1$ and $C_2$ . Each voter will randomly assign both candidates a score, choosing from the standard uniform distribution, $U(0, 1)$ . The winner, counting by range voting, will be the candidate who got the greater sum of scores. The winner, counting by majority voting, will be the candidate who got the greater number of high scores. What is the probability that the two winners are different as the number of voters approaches $\infty$ ? I fear that explanation was unclear, so let me illustrate an example: Let there be $5$ voters. Then the scores could be $$[0.1, 0.2]$$ $$[0.6, 0.7]$$ $$[0.9, 0.1]$$ $$[0.4, 0.5]$$ $$[0.8, 0.9]$$ Then $C_1$ would be the winner by range voting since $0.1 + 0.6 + 0.9 + 0.4 + 0.8 = 2.8 > 2.4=0.2+0.7+0.1+0.5+0.9$ . $C_2$ would be the winner by majority because they secured voters $1, 2, 4, 5$ , whereas $C_1$ only secured voter $3$ . I can rewrite the problem as $$2 \mathbb{P}(C_1 \text{ winning range} \cap C_2 \text{ winning majority})$$ This can in turn be written as $$2 \sum_{k=1}^{n/2}\mathbb{P}(C_1 \text{ winning range} \cap C_1 \text{ getting exactly k in majority vote})$$ Let $s_i$ be the value of the vote cast by the $i$ th voter for $C_1$ minus the value of the vote cast for $C_2$ . The values of $s_i$ will follow the distribution of $1 - |x|$ with $-1 < x < 1$ . The inner probability can be written in terms of integrals, although it is very ugly, to get $$2\sum_{k = 1}^{n/2}\binom{n}{k} \int_0^1 ... \int_0^1 \int_{-1}^0 ... \int_{-1}^0 \prod_{i=1}^{k}(1-s_i) \prod_{i=k+1}^n (1+s_i) \left[\sum_{i=1}^n s_i > 0\right] ds_n...ds_{k+1} ds_k...ds_1$$ where $[$ $]$ denotes the Iverson bracket . From here, the integral can be rewritten to get $$2\sum_{k = 1}^{n/2}\binom{n}{k} \underbrace{\int_0^1 ... \int_{0}^1 \prod_{i=1}^{n}s_i \left[\sum_{i=k+1}^n s_i - \sum_{i=1}^k s_i > n-2k \right] ds_n...ds_1}_{I_{n, k}}$$ Using Mathematica, I found that $I_{2, 1} = \frac{1}{8}, I_{3, 1} = \frac{19}{720}, I_{4, 1} = \frac{191}{40320}, I_{5, 1} = \frac{887}{1209600}, I_{6, 1} = \frac{6797}{68428800}, I_{5, 2} = \frac{10117}{1209600}, I_{6, 2} = \frac{467009}{239500800}$ . However, I wasn't able to simplify the sum any further. I found that the approximation for $n = 3$ is $\frac{19}{120}$ , for $n = 5$ it is $\frac{21121}{120960}$ , and for $n = 7$ , it is $\frac{56332921}{311351040} \approx 0.181$ . I didn't include results about even $n$ because of possible ambiguity with the $k = n/2$ case. It seems that $I_{2k, k} = \frac{1}{2^{2k+1}}$ , and $$\lim_{k \to \infty} \frac{\binom{2k}{k}}{2^{2k+1}} = 0$$ so this would confirm that ignoring the $k = n/2$ case would have no impact as $n \to \infty$ . My questions: Would it be possible to find a closed form for $I_{n, k}$ ? If so, what is it? What is the closed form for the limit of the probability as $n$ approaches $\infty$ ? Edit: I can instead use the sums of the integral as the bounds. I get $$I_{n, k} = \int_0^k \int_{n-2k+S_1}^{n-k} P_{k}(S_1)P_{n-k}(S_2)dS_2 dS_1$$ where $P_m(x) = \int_0^1 ... \int_0^1 \prod_{i=1}^m s_i \left[\sum s_i = x\right]ds_m ... ds_1$ $P_m(x)$ can be rewritten as $$\int_{x-1}^{x} (x-t) P_{m-1}(t) dt $$ with $P_m(x) = 0$ for $x < 0$ and $x > m$ . I found that $P_1(x) = x$ for $0 \le x \le 1$ , $$P_2(x) = \left\{\begin{array}{ll} \frac{1}{3!}x^{3} & : 0 \le x \le 1\\ \frac{1}{3!}(-x^3 + 6x - 4) & : 1 \le x \le 2 \end{array} \right.$$ $$P_3(x) = \left\{\begin{array}{ll} \frac{1}{5!}x^{5} & : 0 \le x \le 1\\ \frac{1}{5!}(-2x^5 + 30x^3 - 60x^2 + 45x-12) & : 1 \le x \le 2 \\ \frac{1}{5!}(x^5 - 30x^3 + 60x^2 + 45x-108) & : 2 \le x \le 3 \end{array} \right.$$ $$P_4(x) = \left\{ \begin{array}{ll} 
\frac{1}{7!}x^7 &: 0 \le x \le 1
\\ \frac{1}{7!}\left(-3x^{7}+84x^{5}-280x^{4}+420x^{3}-336x^{2}+140x-24\right) &: 1 \le x \le 2
\\ \frac{1}{7!}\left(3x^{7}-168x^{5}+560x^{4}+420x^{3}-4368x^{2}+6860x-3480\right) &: 2 \le x \le 3
\\ \frac{1}{7!}(-x^{7}+84x^{5}-280x^{4}-840x^{3}+4704x^{2}-4480x-1536) &: 3 \le x \le 4
\end{array} \right.$$ I wasn't able to find a closed form for $P_m(x)$ , but I suspect that it might be related to the Irwin-Hall distribution . Here is what I found so far for $P_m(x)$ : $$\left\{ \begin{array}{ll} 
\frac{1}{(2m-1)!}x^{2m-1} &: 0 \le x \le 1
\\ \frac{1}{(2m-1)!}\left(x^{2m-1}-\left(2m-1\right)\cdot m\left(x-1\right)^{2m-2}-m\left(x-1\right)^{2m-1}\right) &: 1 \le x \le 2
\end{array} \right.$$ Edit $2$ : Letting $P_{m, k}(x)$ be $P_m(x)$ for $k \le x \le k+1$ and repeatedly using the recurrence relation, I found that $$P_{m, k}(x) = \int_{x-1}^{k}\left(x-x_{1}\right)P_{m-1,k-1}\left(x_{1}\right)dx_{1}+\sum_{t=1}^{m-k-1}\frac{1}{\left(2t+1\right)!}\left(\left(x-k\right)^{2t}\int_{k-1}^{k}P_{m-t-1,k-1}\left(x_{2}\right)\left(2kt+x-\left(1+2t\right)x_{2}\right)dx_{2}+\int_{k-1}^{x-1}P_{m-t-1,k-1}\left(x_{2}\right)\left(1-x+x_{2}\right)^{2t}\left(-2t-x+x_{2}\right)dx_{2}\right)$$ However, when I try to use this for $P_{m, 2}(x)$ , I get a really long and nasty function with hypergeometric functions. Edit $3$ : I was able to get that $$P_{m, m-1}(x) = (-1)^{m+1} \sum_{n=m-1}^{2m-1} \frac{\binom{m}{n-m+1}}{n!}(x-m)^n = \frac{(m-x)^{m-1}\ _1F_1(-m; m; m-x)}{(m-1)!}$$","['integration', 'summation', 'voting-theory', 'probability']"
3721404,Prove $x^4 + x^2 +1$ is always greater than $x^3 + x$,"Let's say P is equal to $x^4 + x^2 +1$ and $Q$ is equal to $x^3 + x$ .
For $x <0$ , $P$ is positive and $Q$ is negative. Hence, in this region, $P>Q$ . For $x=0$ , $P>Q$ . Also, for $x = 1$ , $P>Q$ . For $x > 1$ , I factored out $P$ as $x^2(x^2+1) + 1$ and $Q$ as $x(x^2+1)$ . For $x > 1$ , $x^2(x^2+1) > x(x^2+1)$ , hence $P>Q$ . The part where I have the problem is I can't prove this for the range $0 < x < 1$ without the help of a graphing calculator. Can anyone help? What I've done in this region so far is: Prove that $P$ and $Q$ is always increasing in this region, The range for $P$ starts from $1 < P < 3$ , and The range for $Q$ starts from $0 < Q < 2$ . The only thing I need to prove now is that $P$ and $Q$ will not intersect at $0 < x < 1$ , but I can't prove this part.","['algebra-precalculus', 'polynomials', 'inequality']"
3721486,How is the rank of a matrix affected by centering the columns of a matrix?,"For some $n$ by $p$ matrix $X$ , I'm trying to figure out how the rank of $X$ is affected if each column in $X$ is centered by the mean of that column (call the centered design matrix $Z$ ). If $p < n$ and $X$ is full column rank, $Z$ is full column rank if multicollinearity is not present. If $p = n$ and $X$ is full rank, $Z$ has rank $n-1$ due to the constraint from centering the variables, regardless of whether multicollinearity is present or not. If $p > n$ and $X$ is full row rank, $Z$ has rank $n-1$ due to the constraint imposed from centering the variables Which means rank of $Z \leq$ rank of $X$ . I'm wondering if these observations are correct, and if so, if there's a technical way to show them, especially a).","['matrices', 'matrix-rank', 'linear-algebra']"
3721507,Showing $\frac{d\theta }{ d \tan \theta}=\frac{ 1}{ 1+ \tan^2 \theta}$,"I suppose that $$
\frac{d\theta }{ d \tan \theta}=\frac{d \arctan  x }{ d x}=  \frac{1}{1+x^2}=\frac{ 1}{ 1+ \tan^2 \theta} 
$$ So is $$
\frac{d\theta }{ d \tan \theta}=\frac{ 1}{ 1+ \tan^2 \theta} 
$$ correct? And $$
\frac{d (\theta)  }{ d \tan \frac{\theta}{2}}=\frac{ 2}{ 1+ \tan^2 \frac{\theta}{2}} \; ?
$$","['trigonometry', 'derivatives']"
3721532,Generalizing Catalan numbers: number of ways where we cross the diagonal $k$ times.,"Let's say we have a square grid with n steps each. One starts at the lower left corner, takes $2n$ steps; $n$ of them to the right and $n$ of them to the upwards and ends up at the upper right corner. If we want to count the number of paths that don't cross the main diagonal and stay on a particular side of it, we get the Catalan numbers, $C_n=\frac{2n \choose n}{(n+1)}$ . Accounting for both sides, the total paths that don't cross the main diagonal then become $2 C_n$ . A natural question to ask is: how many paths cross the main diagonal exactly $k$ times? Let's call this number $R_{k,n}$ . I want to find a closed-form expression for $R_{k,n}$ . Obviously, $R_{0,n}=2C_n$ My attempt and some thoughts The question here: Using the Catalan numbers provides a warm-up. Both @joriki and @robjohn calculate the number of paths that have a segment that is positive (possibly empty) followed by a segment that is negative (possibly empty). Let's denote this sequence, $G_n$ as joriki does. They do this by noting that conditional on some cut-off point, we simply get two Catalan sequences. Hence, the number of such paths becomes the convolution of the Catalan numbers with themselves. joriki notes that this sequence will have a generating function that is the square of the generating function of the Catalan numbers. He uses this to determine that it is simply the $n+1$ th Catalan number. Another way to go about finding this would have been to use the general formula here: Proof of identity about generalized binomial sequences. with $k=2$ . The two yield the same answer. This can be used to get $R_{1,n}$ per the following equation (we divide $R_{1,n}$ by 2 because the sequence only considers paths which were negative first and then positive while $R_{1,n}$ includes sequences that were positive first): $$G_n=C_{n+1}=2C_n+\frac{R_{1,n}}{2}$$ $$=> R_{1,n}=2C_{n+1}-4C_n$$ Now, can we apply this ""convolution trick"" to get $R_{k,n}$ ? One way is to consider paths that have three sections. They start off with a section (possibly empty) below the main diagonal. Then, they cross it and there is a section (possibly empty) above the main diagonal. Then, they cross it again and there is a third section (possibly empty) that stays below the main diagonal. Unlike before, there are two cut-off points and it seems we have a three-way convolution of the Catalan numbers with themselves. The first thought is that the number of such paths (say $H_n$ ) will have a generating function that is the cube of that of the Catalan numbers. And if we increase the number of segments further, we get higher and higher powers of the generating function. But this can't be right since as we keep increasing the number of such segments, the number of paths should keep increasing per equation (5.70) here: Proof of identity about generalized binomial sequences. . In reality, we'll reach an upper bound at some point when we simply cover all ${2n \choose n}$ paths. So, what is the error in the ""three way convolution leading to a generating function becoming the cube of the Catalan number generating function"" argument? One resolution might be that the argument is fine, but increasing the cut-off points starts double and triple counting the paths.","['catalan-numbers', 'binomial-coefficients', 'combinatorics', 'sequences-and-series']"
3721536,Chern-Weil theory in the cohomological Atiyah-Singer theorem,"I am interested in the following piece of data appearing in the cohomological Atiyah-Singer theorem. My reference is ""The index of elliptic operators. III"" by Atiyah and Singer. Let $D:\Gamma(E)\to\Gamma(F)$ be an elliptic operator where $E\to X$ and $F\to X$ are complex vector bundles over a closed manifold $X$ . The principal symbol of $D$ is a bundle isomorphism $\pi^\ast E\to\pi^\ast F$ , where $\pi$ is the restriction of the projection $T^\ast X\to X$ to the complement of the zero section. Given a Riemannian metric on $X$ , the Thom space $\operatorname{Th}_X$ of $T^\ast X\to X$ is the topological space arising as the one-point compactification of the unit ball subbundle of $T^\ast X$ . Using the above bundle isomorphism (and the obvious extension across the zero section), one extends $\pi^\ast E-\pi^\ast F$ to an element of $K(\operatorname{Th}_X)$ . The Chern character gives an element of cohomology on the Thom space, and the cohomological Thom isomorphism gives an element of cohomology on $X$ . Now, the de Rham theorem says that this final cohomology element can be represented by a smooth differential form. My question is: can such a smooth form be prescribed in differential-geometric terms from the principal symbol, the (choice of) Riemannian metric on $X$ , and perhaps a choice of hermitian bundle metrics and metric-compatible connections on $E\to X$ and $F\to X$ ? This seems non-obvious since the Thom space does not seem to have a natural smooth structure, and so the use of the Chern character in the above presentation doesn't seem immediately amenable to the Chern-Weil approach. But, given the context and the conclusion, it seems unnatural to be forced to reach into the theory of topological characteristic classes. If I understand correctly, the answer to my question is ""essentially yes"" according to Quillen's article ""Superconnections and the Chern character,"" which identifies such a differential form via a choice of ""superconnection"" on $\pi^\ast E\oplus\pi^\ast F.$ However, Quillen's article seems to be answering a more general question, and has nothing to do with, for instance, the Thom space. Can one make use of the more special situation above to give a simpler answer than Quillen's?","['algebraic-topology', 'k-theory', 'homology-cohomology', 'characteristic-classes', 'differential-geometry']"
3721613,"How to evaluate $\int_{0}^{1} \! \frac{-\ln(1-t)}{t} \, \mathrm{d}t$ without using taylor series expansion?","I want to prove the Basel Problem and I managed to turn it into an integral which I can't solve.
I am interested to know how it can be evaluated without using Taylor series expansions, perhaps with the use of special functions? $$\int_{0}^{1} \! \frac{-\ln(1-t)}{t} \, \mathrm{d}t.$$ I tried using substitutions that can relate it to the Gamma or Beta function but I always hit a seemingly insurmountable roadblock.
I will highly appreciate a detailed answer. Thank you!","['integration', 'calculus', 'gamma-function']"
3721655,"Let $A$ & $B$ be sets. Prove that $\{A,B\}$ is a set.","Here are the axioms that I'm allowed to use. Axiom of Existence: There exists a set. Axiom of Belonging: If $x$ is an object and $A$ is a set, then $x \in A$ is a proposition. Axiom of Extension: Two sets are equal iff they have the same members. Axiom Schema of Specification: Let $S$ be a set and let $p(x)$ be an open sentence about the objects in $S$ . Then, $\{x \in S: p(x)\}$ is a set. Axiom of Unions: Let $F$ be a family of sets. Then, $\cup F$ is a set and it contains all objects that belong to at least one set in the family $F$ . Axiom of Powers: Let $S$ be a set. There exists a set $P(S)$ whose elements are all the subsets of $S$ . So, all of this is what I'm allowed to prove this result and nothing more. I think this is sufficient context based on the book that I'm using. Now, I will present my argument. Proof Attempt: Let $A$ and $B$ be sets. By the Axiom of Unions, $A \cup B$ is a set. By the Axiom of Powers, $P(A \cup B)$ is a set. Since $A \subset A \cup B$ and $B \subset A \cup B$ , it follows that $A \in P(A \cup B)$ and $B \in P(A \cup B)$ . We define the following: $$\phi = \{x \in P(A \cup B): (x = A) \lor (x = B) \}$$ By the Axiom Schema of Specification, $\phi$ is a set. Then, the Axiom of Extension implies that $\phi = \{A,B\}$ and it follows, then, that $\{A,B\}$ is a set. That proves the desired result. I'm kind of not happy with that first line that uses the Axiom of Unions. It just feels wrong. But perhaps that's just me being stupid about this. In any case, is the argument above correct? If not, what's wrong with it and how can I fix it?","['elementary-set-theory', 'solution-verification']"
3721665,Is Rolle's Theorem true when the function..,"Is Rolle's Theorem true when the function is not continuous at the end points? Suppose we define a function $f(x)=x$ for $0<x\leq 1$ and define $f(0)=1$ then it satisfies all the conditions of above theorem, except continuity at $x=0$ . Is Rolle's Theorem true in such cases?","['rolles-theorem', 'calculus', 'derivatives']"
3721694,"Prove that: $\sqrt{2\sqrt{3\sqrt{4\cdots\sqrt{n}}}}<3,\,\forall n\in\mathbb N.$","I know that: $\sqrt{1+2\sqrt{1+3\sqrt{1+4\sqrt{1+\cdots}}}}=3,$ which is one of Ramanujan's infinite radicals. So surely the expression in question is less than $3.$ But how can I prove this without mentioning this or in general how to prove: $\sqrt{2\sqrt{3\sqrt{4\sqrt{\cdots\infty}}}}<3$ ? I'm not quite sure, how to approach this? Expressing the expression as an infinite product: $$\prod_{i=1}^{n} i^{\frac1{2^{i-1}}},\text{ as }n\to\infty$$ and then using some sort underlying inequalities might help! Please suggest. Thanks in advance.","['nested-radicals', 'real-analysis']"
3721706,Evaluating triple integral in a different sphere,"I have been stuck with this problem for a while:
Evaluate $$ \iiint_D\frac{1}{x^2 + y^2 + (z-1)^2}\,dx\,dy\,dz \,,$$ where $D$ is a sphere centered at $(0,0,0)$ with a radius of $1/2$ . I couldn't make any progress without the use of spherical coordinates. Furthermore substituting $D(x, y, z)$ with spherical coordinates centered at $(0,0,0)$ leads to a very complex integral. It is obvious that we need to substitute $x, y, z$ to spherical coordinates centered at $(0, 0, 1)$ so that our denominator simplifies to $r^2$ . The problem arises when you try to represent D(the $(0,0,0)$ radius $= 1/2$ sphere) with spherical coordinates, because they need to be centered at $(0,0,1)$ . Any help?","['integration', 'multivariable-calculus', 'spherical-coordinates', 'multiple-integral']"
3721722,What are the differences between $\mathbb{R}^{k+m}$ and $\mathbb{R}^{k}Ã—\mathbb{R}^{m}$ [duplicate],"This question already has answers here : What is the difference between $\Bbb{R^n}\times\Bbb{R^m}$ and $\Bbb{R^{m+n}}$? (3 answers) Closed 4 years ago . For $k,m \in \mathbb{N}$ are the two sets exactly the same? Or they are same only for $k = m = 1$ ?",['elementary-set-theory']
3721742,"How to estimate this probability of sum of $(-1,+1)$ valued random variables?","Let $x_1,\ldots,x_n$ be independent random variables and $\mathbb{P}(x_i=\pm1)=1/2.$ Prove that exists $C>0$ such that for $0\leq\Delta \leq n/C$ , $$
\mathbb{P}\big(\sum_{i=1}^n x_i>\Delta\big)\geq\frac{1}{C}\exp(-\frac{\Delta^2}{Cn})
$$ The Chernoff bound is an upper bound of the probability, while what I want to prove is lower bound.  Is the statement correct? Is there a reference about the lower bound estimate?","['large-deviation-theory', 'probability-theory', 'probability']"
3721744,Turning a definite integral equation into a differential one.,"Consider the following equation where $p(u)$ is a probability distribution and where $g$ is the unknown : \begin{equation}
 g = \int_{-\infty}^\infty p(u)f(u,g)  \mathrm{d} u
\end{equation} Using the definition of a functional derivative : $$ \frac{\delta F[f(x)]}{\delta f(y)}=\lim _{\epsilon \rightarrow 0} \frac{F[f(x)+\epsilon \delta(x-y)]-F[f(x)]}{\epsilon}$$ Am I allowed to say that the first equation is equivalent to : $$ \frac{\delta g[p(u)]}{\delta p(u_0)} = f(u_0,g)$$ If not, where is my mistake ? I am trying to understand how to invert definite integral equations. Any reference or advice is always welcome. Thank you.","['integral-equations', 'functional-analysis']"
3721763,Proving $r \binom{n}{r}=n\binom{n-1}{r-1}$ combinatorially. (Advice on combinatorial proofs in general?) [duplicate],"This question already has an answer here : Help finding a combinatorial proof of $k {n \choose k } = n {n - 1 \choose k -1}\;$ (1 answer) Closed 4 years ago . How do you combinatorially prove the following? $$r \binom {n}{r} = n \binom  {n-1}{r-1}$$ I find it easy to prove such equalities algebraically, but have a hard time finding the right combinatorial intuition. Any advice for coming up with combinatorial proofs myself?","['combinations', 'binomial-coefficients', 'combinatorics', 'combinatorial-proofs']"
3721793,About equivalence between geometric vector bundles and locally free $\mathcal{O}_X$-modules of finite rank,"I have a last question about the book by Wedhorn/GÃ¶rtz (Algebraic Geometry I: Schemes), chapter 11 (on vector bundles). They define first the quasi coherent bundle defined by $\mathcal{E}$ as follows: (see definition 11.2 and proposition 11.3): The objective is now to prove an equivalence between geometric vector bundles and locally free $\mathcal{O}_X$ modules of rank $n$ (see definition 11.5 for how they define a geometric vector bundle over a scheme $X$ ): I don't quite understand how from the reasoning above, it follows that $\mathbb{V} (\mathcal{E})$ is a geometric bundle of rank $n$ ? I understand that we have these isomorphisms $c: \mathcal{E}_{|U} \xrightarrow{\sim} (\mathcal{O}_{U}^{n})^{\vee}$ . Does he now apply the fact from earlier, i.e. that $\text{Hom}_{\mathcal{O}_X} (\mathcal{F}, \mathcal{E}) \rightarrow \text{Hom}_X (\mathbb{V} (\mathcal{E}), \mathbb{V} (\mathcal{F}))$ is injective? i.e. does he apply the functor $\mathbb{V}$ to the above isomorphisms? Here is also the converse direction: I understand that we may assume that $V = \mathbb{V} (( \mathcal{O}_X^n)^{\vee})$ . However, I don't understand how from proposition 11.3 it follows that then $\mathscr{S}(V/X) = \mathcal{O}_X^{n}$ ?? Also, how can one prove the equation (11.4.1), i.e. that $$ f^{*} \mathscr{S} (V/X) = \mathscr{S} ((V \times_X X^{'})/ X^{'}) $$","['algebraic-geometry', 'schemes']"
3721806,The probability of repeating a test with a 30% chance of being wrong.,"I got in a bit of an discussion with my dad about this and thought about it a lot. Would like some insight. So the question: if you have a test (ex: a virus antibody test) that returns positive or negative and has a 30% chance of having an incorrect result, how many tests would you need to make to have significant confidence (>99%) that the overall mode of all tests is correct? My dad argued that repeating tests does not increase confidence and I thought that it would.",['probability']
3721827,"Olympiad question: In the regular pentagon $ABCDE$, the perpendicular at $C$ to $CD$ meets $AB$ at $F$. Prove that $AE + AF = BE$.","From the Iranian Geometry Olympiad, 2017: In the regular pentagon $ABCDE$ , the perpendicular at $C$ to $CD$ meets $AB$ at $F$ . Prove that $AE + AF = BE$ .
Construction: https://www.geogebra.org/calculator/bnmgctmk I can't seem to make much headway on this problem. You could probably use trigonometry to find the length of $BE$ , but I am guessing there is a much easier (and elegant) solution that is eluding me.","['contest-math', 'euclidean-geometry', 'geometric-construction', 'geometry', 'plane-geometry']"
3721836,Derivative of $p\left( x \right) = \frac{1}{{\sqrt {2\pi } }}\int\limits_x^\infty {{{\mathop{\rm e}\nolimits} ^{ - \frac{{{u^2}}}{2}}}du} $?,"I found a result,
I have, $p\left( x \right) = \frac{1}{{\sqrt {2\pi } }}\int\limits_x^\infty  {{{\mathop{\rm e}\nolimits} ^{ - \frac{{{u^2}}}{2}}}du} $ $y =  - p\left( x \right)\log p\left( x \right) - (1 - p\left( x \right))\log (1 - p\left( x \right))$ I found a solution for the derivative of $y$ at $x=0$ is, $\frac{{dy\left( 0 \right)}}{{dx}} = \frac{2}{\pi }$ But I could not able to show that. It comes zero for me every time.","['calculus', 'probability-distributions', 'derivatives', 'ordinary-differential-equations']"
3721966,How to show $\int_0^\infty\frac1{(1+x^2)(1+x^p)}$ doesn't depend on $p$?,"$$\int_0^\infty\frac1{(1+x^2)(1+x^p)} \; \mathrm{d}x$$ This integral should have the same value for all $p$ . I showed that it converges for all $p.$ I confirmed the result for $p=0,1,2$ : $$\int_0^\infty\frac1{(1+x^2)(1+x^p)} \; \mathrm{d}x=\frac \pi4$$ Any ideas on how to solve this in general? Integration by parts or substitution doesn't seem to work. (I suppose $p$ is a real, but it isn't mentioned in the problem)","['integration', 'calculus', 'definite-integrals']"
3721972,Confusion over a trigronometric function,"I found 2 solutions But they say it is: It feels like there's a mistake in the shift here, I tested it on Desmos and the functions doesn't reflect the perihelion and aphelion years. Do you guys have a different understanding of the shift here? Thanks :)","['trigonometry', 'mathematical-modeling']"
3722025,Evaluate $\int_0^1 \ln{\left(\Gamma(x)\right)}\cos^2{(\pi x)} \; {\mathrm{d}x}$,I have stumbled across the following integral and have struck a dead end... $$\int_0^1 \ln{\left(\Gamma(x)\right)}\cos^2{(\pi x)} \; {\mathrm{d}x}$$ Where $\Gamma(x)$ is the Gamma function. I tried expressing $\Gamma(x)$ as $(x-1)!$ then using log properties to split the integral.  Maybe there should be a summation in combination with the integral??    I believe this integral has a closed form but I would like help finding it.,"['integration', 'improper-integrals', 'definite-integrals', 'calculus', 'contour-integration']"
3722056,Finding Mass of Object Given Density,"I need to find the mass of an object that lies above the disk $x^2 +y^2 \le 1$ in the $x$ - $y$ plane and below the sphere $x^2 + y^2 + z^2 = 4$ , if its density is $\rho(x, y, z)=2z$ . I know that the mass will be $\iiint_R 2z$ $dV$ , and I just need to determine the region $R$ which bounds the object. If I were to use spherical coordinates, I'd have $(r, \theta, \phi)$ where $0 \le r \le 1$ (since the radial distance is restricted by the disk), $0 \le \theta \le 2\pi$ (since we can complete a full revolution just fine), however I am unsure how to determine the upper limit of $\phi$ . Am I going in the right direction using spherical coordinates? And how would I find the upper limit of $\phi$ ? Thanks.","['definite-integrals', 'coordinate-systems', 'solid-geometry', 'multivariable-calculus', 'multiple-integral']"
3722072,Homotopy groups of quotient groups.,"I'd like to ask how to compute homotopy groups of quotient groups, whose homotopy groups I already know. I found this answer, but I don't understand how to derive the homotopy group of $\pi_n (G/H)$ using the long exact sequence. In general, if I know $\pi_n(G)$ and $\pi_n(H)$ , can I compute $\pi_n(G/H)$ ? What if $\pi_n(G)$ is trivial? Or $\pi_n(H)= \mathbb{Z}_N$ ? What about a combination of the two? Any special cases that are easy? What about $n=1$ ? I know these are many questions so to clarify, in principal I'd like the most general answer but if one is not known, then any examples where a computation can be done is acceptable.","['higher-homotopy-groups', 'exact-sequence', 'homotopy-theory', 'group-theory', 'algebraic-topology']"
3722078,Find the affine transformation to minimize the distance between two sets of points,"Definition: Let $A=\{a_1,\cdots,a_n\}$ and $B=\{b_1,\cdots,b_n\}$ two sets with the same cardinality. Then define the distance between two sets as $$d(A,B):=\min_{\sigma}\sum_i||a_i-b_{\sigma(i)}||,\text{where }\sigma \text{ is a bijection from }\{1,2,\cdots, n\} \text{ to itself}.$$ Problem: Given two sets of points $A$ and $B$ in the Euclidean space with the same cardinality, find the affine transformation ${\bf M}$ such that distance between the sets ${\bf M}(A)$ and $B$ is minimized, where ${\bf M}(A) = \{{\bf M} {\bf p}:{\bf p}\in A\}$ .","['computational-geometry', 'nonlinear-optimization', 'metric-spaces', 'linear-algebra', 'computational-complexity']"
3722083,"Quadrilateral $ABCD$ with $AB=AD$, $\angle BAD=60^\circ$, $\angle BCD=120^\circ$. Prove $BC+DC=AC$ [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question In a given quadrilateral $ABCD$ , we have $$AB = AD, \angle BAD = 60^\circ, \angle BCD = 120^\circ$$ Prove that $$ BC + DC = AC$$ I know the quadrilateral is cyclic. I have been able to solve this for the special case where $C$ is the midpoint of arc $BD$ , but I am not sure how to generalize.","['quadrilateral', 'euclidean-geometry', 'triangles', 'geometry']"
3722115,Is there a name for a group-like structure under a unary operation?,"It seems to me that the set, $$
S=\{ \sin, \cos, -\sin, -\cos \}
$$ forms something like a cyclic group under differentiation. But I understand groups to be defined to have a binary operation. Is there a name for a group-like structure under a unary operation?",['group-theory']
3722129,What is the range of $ f(x)=\sqrt \frac{x^2}{x^2-1}$,"$$\sqrt{\frac{x^2}{x^2-1}}$$ I am stuck at finding the range of the given function mathematically. I could deduce from  its graph that the range is $[1,\infty)$ .
But that is incorrect. Could anyone help me? It would help improve my concept","['functions', 'real-analysis']"
3722153,Proving/Disproving there are always two uncountable sets whose intersection is uncountable.,"I have been trying to prove the following: Let $\mathcal{C}$ be an uncountable family of uncountable subsets of $\mathbb{R}$ . Either prove or disprove that there are always two sets in $\mathcal{C}$ whose intersection is an uncountable set. My intuition tells me that the statement is true and that it is connected to the axiom of choice. Although, no matter what I try, it doesn't seem to go anywhere.","['elementary-set-theory', 'general-topology', 'real-analysis']"
3722254,Which items to buy if the best one will always be stolen?,"The Problem: A store sells $N$ items. Each item $i$ is priced at $p_i \ge 0$ and you value the $i$ th item at $x_i \ge p_i$ . You can carry at most two items. To complicate matters, when you leave the store you will be attacked by a bully who will steal the item you value most among the items you have bought.
(If you buy no items the bully leaves you alone; if you buy one item he steals it and if you buy items $i$ and $j$ , say, with $x_i \ge x_j$ he steals item $i$ ). Which items do you buy? I am wondering whether this problem has an explicit, ""simple"" solution. If not, is it possible to prove that there is no simple solution? The only way of solving it I can come up with is brute force: Example with $N=3$ : $$x_1 = 10, x_2 = 5, x_3 = 4$$ $$p_1 = 3, p_2 = 2, p_3 = 1.$$ If you buy two items you can keep either item 2 or item 3 since item 1 would always be stolen. If you want to keep item 2 you must also buy item 1 and so you get $5-(3+2)=0$ If you want to keep item 3 you must also buy either item 1 or item 2. In the first case you get $4-3-1=0$ ; in the second case you get $4-1-2=1.$ If you buy only one item it will be stolen but you will have paid a positive price for it, so you get less than zero. If you buy no item you get zero. So in this example the optimal thing to do is to buy items 2 and 3.","['combinatorics', 'discrete-mathematics', 'combinatorial-game-theory', 'discrete-optimization', 'optimization']"
3722313,Is there a relation between fractional power and logarithm functions?,"Something that has always bothered me is that there's no way to get $x^{-1}$ by differentiating $x^a$ for some $a$ , even though all other negative powers of $x$ can be achieved by differentiating some power of $x$ . So I began to mess around with equations trying to find some sort of connection. I realized that $$\lim_{a\rightarrow\infty}\left(\frac{d}{dx}\left( ax^{\frac{1}{a}}\right)\right) = x^{-1}$$ And, upon further delving that $$\lim_{a\rightarrow\infty} ax^{\frac{1}{a}} - a = \ln(x)$$ Is there a some sort of relation here? I understand that logarithms are intrinsically linked to powers, but I don't understand why a very small power is equal to a scaled, offset logarithm.","['exponentiation', 'derivatives', 'logarithms']"
3722334,Expectation and asymptotic equivalence,"This is a simplified version of the original question asked, it seems that some parts are unnecessary and only confuse. I will therefore here ask a related, but I believe simpler, version of the question. Let $0 < \lambda < 1$ and let $$S_n = X_1 + \dots + X_n$$ be a random walk with i.i.d. increments $X_i$ with law $P(X_1 =0) = P(X_1 =1 ) = 1/2$ . Now, consider $$ E \left( \frac{\lambda^{S_n}} {\sum_{k=0}^{n-1} \lambda^{S_k}} \right).$$ The task is to find a sequence $f(n)$ (possibly random) such that $$ E \left( \frac{\lambda^{S_n}} {\sum_{k=0}^{n-1} \lambda^{S_k}} \right) \Big/ {f(n)} \to 1 $$ and thus, find the growth behavior of the expectation at question.
Note that $\sum_{k=0}^{n-1} \lambda^{S_k} \to L:= \sum_{k=0}^{\infty} \lambda^{S_k}$ a.s. Here the question from before (first part deleted): [...] Then, I am interested in general, what is the asymptotic growth behavior of $$ E \left( \frac{\lambda^{S_n} (1- \lambda^{S_n})}{\lambda^{S_n} + \sum_{k=0}^n \lambda^{S_k}} \right) ?$$","['stochastic-processes', 'probability-theory', 'asymptotics', 'real-analysis']"
3722352,Sum of $f(x)$ and $f(\frac{1}{x})$ for a monotonic function,"I came across this question from a competitive exam: $\textbf{Problem: }$ Given $f:[\frac{1}{2},2]\to\mathbb{R}$ a strictly increasing function, define $g:[1,2]\to\mathbb{R}$ by $g(x)=f(x)+f(\frac{1}{x})$ . Does there exist a suitable $f$ for which there is a partition $P$ of $[1,2]$ such that $U(P,g)=L(P,g)$ ? Here, $U(P,g)$ and $L(P,g)$ are the upper and lower Riemann sums respectively. I could figure this out and the answer is $\textbf{Yes}$ . One can take $f(x)=\log x$ , $f(x)=\frac{x-1}{x+1}$ , etc. So this is alright. I thought of making $g$ to be a constant function to construct the above examples. While trying to come up with these examples, I made some rough graphs that satisfied the hypotheses of the problem and observed something that I want to ask about. Later, I drew several graphs in Desmos as well and observed the same thing. My question is, is the following true? $\textbf{Question:}$ For $a>1$ , given $f:[\frac{1}{a},a]\to\mathbb{R}$ a monotonic function, define $g:[1,a]\to\mathbb{R}$ by $g(x)=f(x)+f(\frac{1}{x})$ . Is $g$ always non-decreasing? I feel it is true. But I could not prove it. Neither could I construct a counterexample. Any hints to prove/disprove the above statement are appreciated. If the above result is true, then the only possible candidates for $g$ in the above original problem can be constants, right? That is why I got interested in this. $\textbf{Please note:}$ I am not assuming any continuity conditions anywhere. Just monotonicity.","['functions', 'monotone-functions', 'analysis', 'real-analysis']"
3722417,Does proximity of moment generating functions implies proximity of characteristic functions?,"Let's assume that $U$ and $V$ are non-negative random variables.     Suppose that \begin{align}
 \sup_{t \ge 0 } \frac{| M_U(-t) - M_V(-t)|}{t} \le \epsilon 
\end{align} where $M_U(t)$ and $M_V(t)$ are moment generating functions. A few facts: Technically $M(-t)$ is known as Laplace transform. $M(t)$ unique on an open interval. Therefore, this question is well defined. $ t \to M(-t)$ is decreasing. Question: Does this imply that \begin{align}
 \sup_{t \in \mathbb{R} } \frac{| \phi_U(t) - \phi_V(t)| }{|t|}\le f(\epsilon) 
\end{align} where $\phi_U(t)$ and $\phi_V(t)$ are characteristic functions, and $f$ is some function that goes to zero as $\epsilon \to 0$ . I was thinking of using that $\phi(t)=M(it)$ , but this doesn't work out.","['moment-generating-functions', 'characteristic-functions', 'probability-theory', 'probability']"
3722435,Solving $\textbf{r}''(t)=\frac{GM}{(r(t))^3}\textbf{r}(t)$,"I have the following problem that I don't know how to solve: Let $\textbf{r}(t)$ be a curve and let $r(t):= |\textbf{r}(t)|$ . Let the curve $\textbf{r}(t)$ be defined by: $$\textbf{a}(t)=\frac{GM}{(r(t))^3}\textbf{r}(t)$$ Where $\textbf{a}(t) = \textbf{r}''(t)$ is the acceleration of the particle and $G,M \in \mathbb{R}$ . Suppose that $\textbf{r}(t)$ and $\textbf{r}'(t)$ are not parallel. The objective is to determine the trajectory $\textbf{r}(t)$ in polar coordinates. So basically we have the following equation: $$\textbf{r}''(t)=\frac{GM}{(r(t))^3}\textbf{r}(t)$$ The thing is that I don't know how I should proceed from now on. If we'd have just normal scalar function this would be a differential equation and I think I would be able to solve it, but like this I have no idea how to approach the problem. How can I solve this? Edit:
If $$\textbf{r}(t):=(x(t),y(t))$$ then the equation turns into the following system of equations: $$x''=\frac{GM}{(\sqrt{x^2 + y^2})^3}x$$ $$y''=\frac{GM}{(\sqrt{x^2 + y^2})^3}y$$ I don't know if this helps but I think that this turns thing easier perhaps.","['polar-coordinates', 'ordinary-differential-equations']"
3722543,Embedding of countable linear orders into $\Bbb Q$ as topological spaces,"Any set $X$ with a linear order has a uniquely associated order topology generated by the open intervals.  That makes it into a linearly ordered topological space (LOTS). It is also a standard result that any countable linear order is isomorphic as a linear order to a subset of $\Bbb Q$ (uses the fact that $(\Bbb Q, <)$ is a dense linear order).  See for example here . Now in general there are many ways a linear order can be embedded into $\Bbb Q$ .  For example consider these two subsets: $$A_1=\{0\}\cup\{1/n:n=1,2,\ldots\}$$ $$A_2=\{-1\}\cup\{1/n:n=1,2,\ldots\}$$ They are isomorphic to each other as linear order, and hence have the same intrinsic LOTS topology.  But as topological subspaces of $\Bbb Q$ they are very different.  The first one is compact, and the second one has the discrete topology, but only the first one has its intrinsic LOTS topology match its topology as a subspace of $\Bbb Q$ .  So an embedding that makes the subspace and order topologies match is special in a way. Here is my question: Given a countable set $X$ with a linear order, is it possible to embed it into $\Bbb Q$ by a linear order isomorphism so that the order topology on $X$ matches the subspace topology from $\Bbb Q$ ? Anything you want to add explaining the relationship between the two topologies would be very interesting.  For example one topology always stronger than the other.  And are there some cases for the linear order $X$ where the two topologies always coincide independently of a linear order embedding?","['order-theory', 'general-topology']"
3722567,Geometry problem I am having trouble to solve,"Prove that $AC = \sqrt{ab}$ $a$ is $AB$ ; $b$ is $CD$ ; the dot is the origin of the circle. ABCD is a trapezoid, meaning AB || DC. My attempt at solving: According to this rule, $$MA^2 = MB \cdot MC$$ I can apply this rule and say that $DA^2 = b\cdot DE$ . If I manage to prove that $DE = a$ , I solve the problem, because if $DE = a$ , that means that $DA = BE$ , which leads to $BE = AC$ , because both are diagonal of the equilateral trapezoid (ABCE) in the circle.","['power-of-the-point', 'euclidean-geometry', 'geometry']"
3722577,"Distribution of $\frac{2X_1 - X_2-X_3}{\sqrt{(X_1+X_2+X_3)^2 +\frac{3}{2} (X_2-X_3)^2}}$ when $X_1,X_2,X_3\sim N(0,\sigma^2)$","Given that $X_1, X_2, X_3 $ are independent random variables form $N(0, \sigma^2 )$ , I have to indicate that the statistic given below has a $t$ distribution or not. \begin{equation}
\frac{2X_1 - X_2-X_3}{\sqrt{(X_1+X_2+X_3)^2 +\frac{3}{2} (X_2-X_3)^2}}
\end{equation} In my attempt of solving this problem: I start by showing that we can write the numerator as $a^TX$ , where $a^T = (2 -1 -1)$ and $X^T= (X_1 X_2 X_3)$ . Thus we have that $a^TX \sim N(0, a^T(\sigma^2 I)a)= N(0, 6\sigma^2)$ . And so $\frac{1}{\sqrt{6\sigma^2}} a^TX \sim N(0,1)$ or $\frac{1}{\sqrt{6\sigma^2}}(2X_1-X_2-X_3)\sim N(0,1)$ . Next, we know that $(X_1+X_2+X_3) \sim N(0, 3\sigma^2)$ . This implies that $\frac{1}{\sqrt{3\sigma^2}}(X_1+X_2+X_3) \sim N(0,1)$ and thus, $\frac{1}{{3\sigma^2}}(X_1+X_2+X_3)^2 \sim \chi^2(1)$ . Similarly, $\frac{1}{2\sigma^2}(X_2-X_3)^2 \sim \chi^2(1)$ . Therefore, $\frac{1}{{3\sigma^2}}(X_1+X_2+X_3)^2 + \frac{1}{2\sigma^2}(X_2-X_3)^2 \sim \chi^2(2)$ or $\frac{1}{{3\sigma^2}}\left((X_1+X_2+X_3)^2 + \frac{3}{2}(X_2-X_3)^2 \right) \sim \chi^2(2)$ . As a third step I have to show that $\frac{1}{\sqrt{6\sigma^2}}(2X_1-X_2-X_3)$ and $ \frac{1}{{3\sigma^2}}\left((X_1+X_2+X_3)^2 + \frac{3}{2}(X_2-X_3)^2 \right)$ are independent and I am not sure how to show that. Any help would be appreciated.","['statistics', 'probability-distributions', 'normal-distribution']"
3722620,Do the numbers preceding primes have on an average fewer divisors than the numbers succeeding primes?,"I wanted to see if the numbers preceding primes behaved differently in any way form the numbers succeeding primes so I calculated at the average number of divisors of number of the form $p-1$ and $p+1$ where $p$ is a prime. Let $d(n)$ be the number of divisors of $n$ . Define $f(x) = \sum_{p \le x} d(p-1)$ and $g(x) = \sum_{p \le x} d(p+1)$ where $p$ is a prime. I observed that there are only $3251$ instances where $f(x) < g(x)$ . The largest value of $x$ for which this is true is $x = 3752789$ . After checking till $x \le 1.9 \times 10^{10}$ , I could not find the inequality reversing again. This the data shows that the numbers preceding primes have on a average fewer number of divisors than the numbers succeeding primes. The graph below shows the actual data. Question : Is there any reason why this should be true? Source code import numpy
p = 2
i = fd = fp = 0
d1 = d2 = p1 = p2 = 0
target = step = 10^6

while True:
    i  = i + 1  
    d1 = d1 + len(divisors(p-1))
    d2 = d2 + len(divisors(p+1))
    if d1 > d2:
        fd = fd + 1
    
    p1 = p1 + len(prime_factors(p-1))
    p2 = p2 + len(prime_factors(p+1))
    if p1 > p2:
        fp = fp + 1
        
    if i > target:
        print i,p,d1,d2,fd, d2-d1,(d2-d1)/i.n(), p1,p2,fp, p2-p1
        target = target + step
        
    p = next_prime(p)","['number-theory', 'elementary-number-theory', 'analytic-number-theory', 'divisor-sum', 'prime-numbers']"
3722648,"One missing step in proving $\mathbb{Z}\times \mathbb{Z} \cong \langle a,b\,|\, [a,b]=1\rangle$","In order to understand the topic of ""presentation of a group"", I would like to work out the following example: $\def\Z{\mathbb{Z}} \def\iso{\cong} \def\llg{\langle} \def\rrg{\rangle}$ $\Z\times \Z \iso \langle a,b\,|\, [a,b]=1\rangle$ , where $[a,b]:=a^{-1}b^{-1}ab$ . This example appears in Section 6.3 of Dummit and Foote's Abstract Algebra . The definition of generators and relations there is somehow confusing. It begins with a given group $G$ and a subset $S$ of $G$ such that $G=\llg S\rrg$ and then assume a subset $R$ of the free group $F(S)$ has the property that its normal closure in $F(S)$ equals to the kernel of the group homomorphism $\pi$ , where $\pi$ is defined by the following commutative diagram: where $\iota_k$ , $k=1,2$ , are the inclusion maps. This a priori appearance of the group $G$ in the definition makes statements like the example above difficult to understand. To approach the example above, I will use the following definition instead: Let $S$ be a set and $F(S)$ the free group on $S$ . Let $R$ be a set of words in $F(S)$ , i.e. $R\subset F(S)$ , and $N$ the normal closure of $R$ in $F(S)$ . The group $\llg S|R\rrg$ is defined as $$
\llg S|R\rrg=F(S)/N
$$ Now let $S=\{a,b\}$ , $\varphi(a)=(1,0)$ , $\varphi(b)=(0,1)$ . By the universal property of $F(S)$ , there exists a unique group homomorphism $\pi: F(S)\to \Z\times\Z$ such that the following diagram commutes: i.e., $\pi\circ\iota=\varphi$ . If I can establish the following, $N=\ker\pi$ ; $\pi$ is surjective, (trivial because $\pi(a^mb^n)=m\pi(a)\oplus n\pi(b)$ ) then by the first group isomorphism theorem, the proof is done. The inclusion $\ker\pi\supset N$ is easy; since $\ker\pi$ is a normal subgroup, it suffices to show that $\ker\pi\supset R$ : $$
\pi([a,b])=[\pi(a),\pi(b)]=[(1,0),(0,1)]=(0,0)\;.
$$ How can I show the other direction $\ker\pi\subset N$ ? Or is there anything else I can do to get around this step?","['group-presentation', 'combinatorial-group-theory', 'abstract-algebra', 'free-groups', 'group-theory']"
3722654,Diffeomorphism from $\mathbb{R}^m\to\mathbb{R}^n$,"I have a question about diffeomorphism between $\mathbb{R}^m$ and $\mathbb{R}^n$ . From this page of the internet we have the following definition: Let $U\subseteq\mathbb{R}^m$ and $V\subseteq\mathbb{R}^n$ . A function $F:U\to V$ is called a Diffeomorphism from $U$ to $V$ if $F$ has the
following properties: a) $F:U\to V$ is bijective. b) $F:U\to V$ is smooth. c) $F^{âˆ’1}:V\to U$ is smooth. But in this post , it is proven that there is no diffeomorphism between $\mathbb{R}^2$ and $\mathbb{R}^3$ . In fact, the spaces $\mathbb{R}^m$ and $\mathbb{R}^n$ are not diffeomorphic when $m \neq n$ . Therefore, there cannot be a diffeomorphism between $\mathbb{R}^m$ and $\mathbb{R}^n$ . But by this definition, as the symbol $\subseteq$ is used, it implies that the open sets $U$ and $V$ can be $\mathbb{R}^m$ and $\mathbb{R}^n$ . So, the definition is "" wrong "", in the sense that there is no diffeomorphism between $\mathbb{R}^m$ and $\mathbb{R}^n$ ? Would the definition be correct if the symbol $\subset$ was used? That is, is it possible to construct diffeomorphism between open sets of $\mathbb{R}^m$ and $\mathbb{R}^n$ ?","['multivariable-calculus', 'diffeomorphism', 'analysis']"
3722672,Does the alternating composition of sines and cosines converge to a constant?,"Let $f(x) = \cos(\sin(x))$ and let $c(f, n)(x)$ denote the function $\underbrace{f\circ f\circ...\circ f}_{n \text{ times}}$ . For example, $c(f, 1)(x) = f(x)$ , $c(f, 2)(x) = f(f(x))$ and so on. My question is: does $c(f, n)(x)$ approach any constant function if $n \to +\infty$ ? I graphed this for some values of $n$ and the function seems to approach some value a little bit over $0.76$ . Does anyone have any insight as to whether that is true? If so, what value is it approaching and why? Any sort of help or material helps; this question has been stuck in my head for quite some time now! Thanks in advance!","['trigonometry', 'functions', 'graphing-functions']"
3722728,How to prove that perpendicular from right angled vertex to the hypotenuse is at most half the length of hypotenuse of a right triangle?,"In a right-angled triangle $\Delta ABC$ , prove that the perpendicular $BD$ , drawn from the right-angled vertex $B$ to the hypotenuse $AC$ , is at most half the hypotenuse $AC$ . My approach: Assume that $AB=x$ , $BC=y$ , $AC=k$ where $k$ is some arbitrary constant I used Pythagoras theorem in $\Delta ABC$ $$y^2=k^2-x^2,\  y=\sqrt{k^2-x^2}$$ I used formula of area of right triangle ABC by two methods & equate them $$\frac12(BD)\cdot(AC)=\frac12x\cdot y\implies BD=\frac{xy}{k}$$ $$BD=\frac{x\sqrt{k^2-x^2}}{k}$$ I differentiated $BD$ with respect to $x$ $$\frac{d}{dx}BD=\frac{k^2-2x^2}{\sqrt{k^2-x^2}}$$ putting $d(BD)/dx=0$ , I got $x=k/\sqrt2$ & $y=k/\sqrt2$ The maximum length of altitude BD will be $$\frac{xy}{k}=\frac{(k/\sqrt2)\cdot(k/\sqrt2)}{k}=\frac k2$$ Above value proves that maximum value of $BD$ is half the hypotenuse AC. It is fine but I don't want to use this lengthy proof by calculus . My question: Is there any simple or easy proof by using trigonometry, geometry, or other way?","['trigonometry', 'calculus', 'triangles', 'geometry']"
3722754,Are there other ways to find local extrema for multivariable functions without the second derivative test?,"I've got a problem where I'm being asked to find the extrema for the equation $f(x,y) = \cos (y)e^x$ . Assuming I haven't missed anything, the first derivative with respect to x is identical to the given equation, which equals zero at $y = -\pi/2$ and $y = 3\pi/2$ . When I plug those points into the first derivative with respect to $y$ : $-\sin (y)e^x$ , there is seemingly no way to find a critical point given that neither $-\sin (y)$ nor $e^x$ can be zero. Is it still possible then, to find any local extrema or is the problem dead?","['multivariable-calculus', 'calculus', 'derivatives', 'trigonometry']"
3722756,Using Uniqueness Result for Analytic Functions,"I am reviewing for an Analysis qual and stumbled upon this question. In particular, I am having difficulties with part (ii). My attempt is the following: Using the hint, let $\Omega = \mathbb{C}$ , $S=\{1/n : n\in \mathbb{N}\}$ , and $g(z)=z^2$ . We have that since $S \subset \Omega$ and both $f$ and $g$ are entire, then $f$ and $g$ are analytic on $S$ . Per the uniqueness result, if $g(z)=f(z)$ for all $z\in S$ , we know that since $0$ is a limit point of $S$ that is in $\Omega$ , then it must be the case that $g(z)=f(z)$ for all $z\in \Omega$ . However, we are given that $|f(i)| =2$ , yet $|g(i)| = 1$ . So in this case, just because $|g(z)| = |f(z)|$ for all $z\in S$ , we don't have $g(z)=f(z)$ . My strategy is then to find different functions $g$ such that $|g(z)| = |f(z)|$ for all $z\in S$ and $|g(i)|=2$ . After finding all these different $g's$ , I should have all the possible values of $|f(-i)|$ by just calculating $|g(-i)|$ . However, I'm having trouble finding even a single function $g$ that satisfies these two conditions, much less finding all of them. Is there some systematic way I can go about finding these different $g$ functions?",['complex-analysis']
3722793,Operator norm of a matrix in terms of its coefficients,"Let $M:\mathbb{C}\to \mathbb{C}$ be a matrix and equip $\mathbb{C}$ with the norm $$\|x\|_\infty=\max_{1\le j\le n}|x_j|.$$ If the operator norm is given by $$\|M\|=\sup_{\|x\|=1}|Mx|,$$ is it possible to compute the operator norm exactly in terms of the matrix entries? Since $(Mx)_i=\sum_{j=1}^nm_{ij}x_j$ , we have $$\|M\|=\sup_{\|x\|_\infty=1}\max_{1\le i\le n}\bigg|\sum_{j=1}^nm_{ij}x_j\bigg|.$$ From here, it is clear how one might bound this norm, but it is not clear to me how to compute it exactly without knowledge of the matrix.","['matrices', 'matrix-norms', 'functional-analysis']"
3722836,Approximation of a functionâ€™s derivative,I came across this result when I was tinkering with some summations and integrals. Any ideas if it could be useful? $\frac{d}{dx}f(x)\approx f(x+\frac{1}{2})-f(x-\frac{1}{2})$,"['calculus', 'derivatives', 'approximation']"
3722842,Application of quadratic functions,"Kevin wants to fence a rectangular garden using $14$ rails of $8$ -foot rail, which cannot cut. What are the dimensions of the rectangle that will maximize the fenced area? So the number of rails in each dimension the rectangle could be either $2$ in the width by $5$ in the length $($ area $2(8)\cdot5(8)=640$ ft $^2)$ or, $3$ in the width by $4$ in the length $($ area $3(8)\cdot4(8)=1,152$ ft $^2)$ , $1$ in the width and $6$ in the length $($ area $1(8)\cdot6(8)=384$ ft $^2)$ . Therefore the dimensions that maximize the fenced area are $24$ feet by $32$ feet. But I did that by trial and error. Not using a quadratic function. This is what I did using quadratic function. Let be $w$ the number of rails in the width and $l$ the number of rails in the length. The perimeter would be: $$2w+2l=14$$ $$\frac{2w}{2}+\frac{2l}{2}=\frac{14}{2}$$ $$w+1=7$$ $$w=7-l$$ The area would be: $$A=w\cdot l$$ $$A=(7-l)\cdot l$$ $$A=7l-l^2$$ $$l=\frac{-7}{2(-1)}$$ $$l=\frac{-7}{-2}$$ $$l=\frac{7}{2}$$ $$l=3.5$$ $$l\approx 4$$ Shall I round this to $4~$ ? Since I can't cut the rail? $$w=7-l$$ $$w=7-4$$ $$w=3$$ So the dimension of the length is $4(8)=32$ ft and the width is $3(8)=24$ ft Is this right?","['algebra-precalculus', 'quadratics']"
3722881,Connection between trigonometric identities and secant/tangent lines,"Assuming the relationship I am asking about is obvious to most students, I hope this post is an opportunity for some to have fun exploring a basic question. What I'm wondering about is the relationship to the trigonometric identities I learned about in PreCalculus and the secant/tangent lines that are used to estimate a rate of change at the start of Differential Calculus (or Calc I). While I am can solve problems using the secant identity, $sec=\frac{r}{x}$ , and I understand what it is (the inverse of cosine), I am having trouble connecting the relationship this identity has with the line I draw between two points on a curve, $m_{sec}=\frac{f(x)-f(a)}{x-a}$ , also known as the difference quotient. The same question comes up when I find the slope of a tangent line using the secant line. What is the relationship between the tangent I know from Trigonometry, $tan = \frac{y}{x}$ , and the slope of the tangent line that I find in Calc I, $m_{tan} = \lim_{x \to a} \frac{f(x)-f(a)}{x-a}$ ? I'm having trouble finding resources that address my questions directly online. So, any help would be greatly appreciated! I'll put in the time if you can point me in the right direction. Thank you!","['tangent-line', 'limits-without-lhopital', 'secant', 'calculus', 'trigonometry']"
3722896,How to study high-dimensional topology?,"I really would like to learn about the foundations of high-dimensional topology, the study of manifolds of dimensions 5 or greater.  I learned the algebraic topology, but much of focus in what I learned in topology, such as geometric topology, has been low-dimensional manifolds.  I concluded that I am intensely more interested about high-dimensional manifolds than low-dimensional manifolds; unfortunately, it seems that there are no introductory textbooks or monographs about high-dimensional manifolds. Where should I begin with?  What topics should I study that are core of high-dimensional topology?  I have a feeling that surgery and cobordism theories are important, but I am not sure.  Should I instead trying to read past research articles than specific textbooks?","['geometry', 'geometric-topology', 'manifolds', 'differential-topology', 'algebraic-topology']"
3722913,$R$ Gorenstein implies $\operatorname{Proj}(R)$ Gorenstein,"Let $k$ be a field and let R be a Gorenstein $k$ -algebra which has a non-negative grading $R=\oplus_{k\geq 0} R_k.$ Assume further that $R_0=k$ and that $R$ is generated in degree one. I've seen it asserted without proof that the scheme $\operatorname{Proj}(R)$ is Gorenstein. How does one prove this? To explain where I'm stuck: I know $\operatorname{Proj}(R)$ is covered by the degree zero pieces of localizations $R_f$ for homogeneous $f$ (these localizations are Gorenstein). However, I don't know why taking degree zero piece preserves Gorensteiness.","['gorenstein', 'algebraic-geometry', 'commutative-algebra']"
3722915,$f(1)+f(-1)=0$ prove $f(x)$ does not divide $x^n -1$,Let $f(x)$ be an irreducible polynomial in $\Bbb Z[x]$ satisfying $f(1)+f(-1)=0$ .  Prove that $f(x)$ does not divide $x^n-1$ for any positive integer $n$ . with $f(1)+f(-1)=0$ it means sum of all even terms is $0;$ how is that related to divisibility to $x^n -1$ ? I can't figure out and would appreciate any help. Thanks!,"['number-theory', 'abstract-algebra', 'cyclotomic-polynomials', 'polynomials']"
3722977,Unable to prove an exercise in Continuous functions in Topology,I am self studying Topology from C. Wayne Patty and I am unable to solve the following question in exercise 1.7 Adding image-> I tried by assuming a sequence $x_n$ $ \epsilon $ A which converges to x . I got f( $x_n$ ) = g( $x_n$ ) but  I am not able to move forward. Please give some hint. No need to fully answer it.,"['general-topology', 'analysis']"
3723071,What can we say about the probability of two events when $A$ implies event $B$?,"Suppose we have two events $A$ and $B$ where $A$ implies $B$ . What can we say about their probabilities? My try: I can come up with two events $A=\{\text{rainy weather}\}$ and $B=\{\text{cloudy weather}\}$ where $A \rightarrow B$ . Also, we all know intuitively $\Pr\{\text{rainy weather}\}  \leq \Pr\{\text{cloudy weather}\}$ . Can you prove my argument rigorously using probability laws? I do not want showing this fact by words.","['probability-theory', 'probability']"
3723074,When can you switch the limites of integration of a line integral?,"I was looking into why the property that $\int_a^b f(x) \ dx = -\int_b^a f(x) \ dx$ holds true. I found that 2 common answers were that It comes from $\int_a^b f(x) dx + \int_b^c f(x) dx = \int_a^c f(x) dx$ for arbitrary $a \le b \le c$ (for example, in this answer ). It comes from the fundamental theorem of calculus $\int_a^b f(x)\,dx = F(b) - F(a)$ (for example, in this answer ). From my understanding of these answers, the first one has a more lenient hypothesis, since to apply F.T.C. we need the function to have an antiderivative, which is not always the case. Knowing this, I was wondering about the extension of this question into a line integral. Let's say that $C$ is a path that starts at point $p$ and ends at point $q$ . If I define $C^*$ to be the same path but staring at $q$ and ending at $p$ , is it generally true that $$
\int_{C} \mathbf{F} \cdot d\mathbf{r} = - \int_{C^*} \mathbf{F} \cdot d\mathbf{r} \quad ?
$$ where here $r:[t_0, t_f]\subset \mathbb{R} \to C$ , with $r(t_0) = p$ and $r(t_f) = q$ being a biyective parametrization of our path. I know that I can show this to be true if $\mathbf{F}$ happens to be a conservative field using the gradient theorem , in a similar manner as the 1D case can be shown by F.T.C., but since this is not always true I don't know if I can say that this holds in general . Is there a way to show that this always holds? Or alternatively, is there a counterexample where this fails? Thank you!","['integration', 'multivariable-calculus', 'line-integrals', 'vector-analysis']"
3723083,Identify directly illuminated surface of a volume,"Let $s$ be a light source emitting rays located at $[s_x,s_y,s_z]$ , a  volume $V$ . Without loss of generality, I will consider a rectangular volume of sizes $[L_x,L_y,L_z]$ . Assuming the source is located outside the volume, I wish to identify the directly illuminated surface of $V$ . By directly, I mean disregarding propagation of light and considering light which moves in a ray manner. This image illustrates: In the blue example, only the front face of the volume will be directly illuminated while on the yellow example all 3 visible faces of the volume are illuminated. Is a mathematical formulation to identify the un-obscured surfaces? I have seen this paper which does the exact same work for a point cloud but I do not know how to alter this method for surfaces. Any ideas on the matter? Is this at all possible?","['combinatorial-geometry', 'geometry', '3d', 'computer-science']"
3723136,The Fourier transform of $1/p^3$,"The Fourier transforms we use are \begin{align}
\tilde{f}(\mathbf{p})&=\int d^3x\,f(\mathbf{x})
 e^{-i\mathbf{p}\cdot\mathbf{x}}\\[5pt]
f(\mathbf{x})&=\int \frac{d^3p}{(2\pi)^3}\,\tilde{f}(\mathbf{p})
 e^{i\mathbf{p}\cdot\mathbf{x}}
\end{align} I want to calculate the transfom of $1/p^3$ \begin{align}
I=\int \frac{d^3p}{(2\pi)^3}\,\frac{1}{p^3}
 e^{i\mathbf{p}\cdot\mathbf{x}}
\end{align}","['integration', 'fourier-transform', 'complex-analysis', 'calculus', 'multivariable-calculus']"
3723242,Is there an elementary expression for every real sequence?,"By elementary expression for the sequence $\{a_n\}_{n=0}^\infty$ , I mean an elementary function $f : X \to \mathbb C$ , where $\mathbb N \subset X \subset \mathbb R$ , such that $f(n)=a_n$ for all $n$ . The set of elementary functions , is the smallest set that contains constant functions $f(x)=c\in\mathbb C$ ; contains $f(x)=x$ ; is closed under addition $f(x) + g(x)$ , multiplication $f(x)g(x)$ and exponentiation $f(x)^{g(x)}$ , where exponentiation is restricted to where $f(x)\in\mathbb R^+$ for convenience; is closed under composition $f(g(x))$ is closed under exponentiation $\exp f(x)$ and logarithm $\ln f(x)$ by the principal branch. In particular, trigonometric functions and their inverses are also elementary ( $\sin(x) = \frac{-i}2(e^{ix}-e^{-ix})$ , $\arctan x=\frac{1}{2}i[\ln(1-ix)-\ln(1+ix)]$ , etc). And the Gaussian function $\lfloor x\rfloor, x\in \mathbb R\backslash \mathbb Z$ is elementary by fiddling with $\arctan \cot x$ (which resembles the fractional part function). A very important elementary sequence is the prime number sequence $p_n = \text{the } n^{\text {th}} \text{ prime}$ . This sequence IS elementary! To see this, construct $$c = \sum_{i=1}^{\infty} p_i 10^{-i(i+1)/2},$$ which converges and is a constant , thus satisfying our criteria despite containing infinite sums. We can then construct $f(i)=\left\lfloor c10^{i(i+1)/2}\right\rfloor - \left\lfloor c10^{i(i-1)/2}\right\rfloor10^{i}$ to extract the primes, since $p_i < 10^i$ . In this way, we can construct elementary expressions for any positive integer sequence, as long as it can be bounded by another elementary sequence. And by a clever construction here (contains unfixed minor errors) or here (Chinese) , we can see that all positive integer sequences can be bounded, and thus have elementary expressions. We can easily generalize this to all rational sequences. So the question is: Can this result be generalized to real sequences? (Of course, complex sequences easily follows.) Note that it does not suffice to use the counting argument, since there are $\beth^{\mathbb N}_1 = \beth_1$ real sequences, which is equal to the number of elementary expressions. And the method we used before cannot be generalized, because similar encodings will almost always involve fiddling with digits, which leads to decoding functions containing dense discontinuities. And elementary functions can't be discontinuous on a dense set.","['elementary-functions', 'sequences-and-series']"
3723323,Chebyshev formula question,"I'm stuck with this problem, I want to show that if $f$ is an integrable function then $$\lim_{t\rightarrow \infty}t\mu\{x\in \mathbb{R}^d:|f(x)|>t\}=0.$$ I have the feeling that I should use the Chebyshev's inequality, but I don't know how to use it in this case. Any ideas? Thanks in advance!!","['multivariable-calculus', 'calculus']"
3723342,Using Euler-Lagrange equations to prove Cauchy's Theorem,"In complex analysis, there is a theorem that says whenever two curves $\gamma_0$ and $\gamma_1$ are homotopic and contained in an open set $\Omega$ in which $f$ is holomorphic, then we have $\int_{\gamma_0}f(z)dz = \int_{\gamma_1}f(z)dz$ I spotted, with an informal derivation, that this obeys the Euler-Lagrange conditions, for $z(t)$ being the function that varies in the functional. Could you then argue, loosely speaking, that as the 'functional limit' (I haven't studied functionals in any great detail) is zero everywhere, then the functional must be constant?","['complex-analysis', 'functional-equations', 'euler-lagrange-equation']"
3723352,Find two numbers to minimize the sum of squares,"Suppose we are given a sequence of positive numbers $0<a_1<a_2< \cdots < a_n$ . Step 1. Choose an integer $m$ where $m \in \{1,2,\cdots,n\}$ . After choosing $m$ , we divide our numbers into two subgroups $\{a_1,\cdots,a_m\}$ and $\{a_{m+1},\cdots,a_n\}$ . Step 2. Given two numbers $a', a'' \in \mathbb{R}$ ,
we can calculate the sum of squares in the two subgroups $$SS = \sum_{i=1}^{m} (a_i-a')^2+\sum_{j=m+1}^n (a_j-a'')^2.$$ My question is how to choose $m, a', a''$ to minimize the $SS$ . The $a'$ and $a''$ are easy to solve. In fact, $a'$ should be the mean of the first subgroup, i.e. $\frac{a_1+\cdots + a_m}{m}$ and $a''$ should be the mean of the second subgroup, i.e. $\frac{a_{m+1}+\cdots + a_n}{n-m}$ . To solve $m$ , I guess that we can firstly compute the mean $\bar{a}$ of the whole group, i.e. $\frac{a_1+\cdots+a_n}{n}$ and then $m$ should be the largest integer such that $a_m<\bar{a}$ . But I don't know how to prove it.","['optimization', 'statistics', 'least-squares']"
3723370,"Permutation Problem on number greater than 30000 and less than 9,999,999 and divisible by 5","Determine how many numbers bigger than 30,000 and smaller than
9,999,999 and divisible by 5 can be formed using the digits 0, 1, 2,
3, 5, 8 and 9. The answer is 156,407. Please help on the approach to get this answer! Thank you. This is what I have tried: total 5 digit numbers possible that will be divisible by 5 $= 2 \cdot 7 \cdot 7 \cdot 7 \cdot 6$ (unit place on the left) total 6 digit numbers possible that will be divisible by $5 = 2\cdot7\cdot7\cdot7\cdot7\cdot6$ total 7 digit numbers possible that will be divisible by 5 $= 2\cdot7\cdot7\cdot7\cdot7\cdot7\cdot6$ Then I added all these answers & subtracted those 5 digit numbers lesser than 30,000 and divisible by 5 Then I subtracted 1 (9,999,999 is not to be included). The answer i get does not match with the one on the book.","['permutations', 'combinations', 'linear-algebra', 'discrete-mathematics']"
3723398,Verify the identity $\frac{\tan(a+b)}{\tan(a-b)}$ = $\frac{\sin(a)\cos(a)+\sin(b)\cos(b)}{\sin(a)\cos(a)-\sin(b)\cos(b)}$,I've been asked to verify the following identity but I don't know how to do it. $$\frac{\tan(a+b)}{\tan(a-b)} = \frac{\sin(a)\cos(a)+\sin(b)\cos(b)}{\sin(a)\cos(a)-\sin(b)\cos(b)}$$ When I try I get $$\frac{\tan(a+b)}{\tan(a-b)} = \frac{\dfrac{\sin(a+b)}{\cos(a+b)}}{\dfrac{\sin(a-b)}{\cos(a-b)}} = \frac{\dfrac{\sin(a)\cos(b)+\cos(a)\sin(b)}{\cos(a)\cos(b)-\sin(a)\sin(b)}}{\dfrac{\sin(a)\cos(b)-\cos(a)\sin(b)}{\cos(a)\cos(b)+\sin(a)\sin(b)}}$$ But I don't know really where to go from here.,['trigonometry']
3723410,Consider $\dot{x}=4x^{2}-16$.,"I am solving the ODE above, it is a question from Strogatz Nonlinear dynamics and chaos, chapter 2 question 2.2.1. Question \begin{equation}
\dot{x}=4x^{2}-16
\end{equation} Answer \begin{equation}
\frac{\dot{x}}{4x^{2}-16} = 1\\
\frac{\dot{x}}{x^{2}-4} = 4\\
 {{dx\over dt}\over x^2-4}=4 \\
 {{dx\over dt}\over x^2-4}. dt=4. dt  \\
 {dx\over x^2-4}=4dt \\
\int \frac{1}{x^{2}-4} dx = \int 4 dt \\
\frac{1}{4} \ln(\frac{x-2}{x+2}) = 4t + C_{1} \\
x = 2 \frac{1 + C_{2}e^{16t}}{1 - C_{2}e^{16t}}
\end{equation} \begin{equation}
C_{2}(t=0) = \frac{x-2}{x+2}
\end{equation} Summary I am looking to understand the intermediary step in the proof above. How do we get to this step $\frac{1}{4} \ln(\frac{x-2}{x+2}) = 4t + C_{1} $ from the previous step. Can we remove the constant $\frac{1}{4} $ then integrate the remaining portion?","['ordinary-differential-equations', 'proof-explanation', 'calculus', 'solution-verification', 'physics']"
3723433,Hopf fibration is a riemannian submersion,"Reference: Peter Petersen, Riemannian Geometry, 3rd edition, Example 1.1.5 Hopf fibration $F: S^3(1) \to S^2 (1/2)$ is defined by $$F(z,w) = \left(\frac{1}{2} (|w|^2 - |z|^2), z\overline{w}\right)$$ if we think of $S^3(1) \subset C^2$ and $S^2(1/2) \subset R \oplus C$ .
I want to show that $F$ is a Riemannian submersion. Definition : a Riemannian submersion $F:(M,g_M) \to(N,g_N)$ is a submersion $F:M \to N$ such that for each $p\in M$ , $DF:\ker(DF)^\perp \to T_{f(p)}N$ is a linear isometry. That is, if $v,w \in T_pM$ are perpendicular to the kernel of $DF: T_pM \to T_{F(p)N}$ , then $$g_M(v,w) = g_N(DF(v),DF(w)).$$ To show that $F$ is a Riemannian submersion, I tried to find $\ker (DF)$ . Since I don't know the method to find $DF$ when $F$ is not a real function, I set $F$ as a real-valued function as below. $$F(a,b,c,d) = \left(\frac{1}{2} ((a^2 - b^2) - (c^2 -d^2)), ac+bd, bc-ad\right).$$ Then I computed $$DF =\begin{pmatrix} a & -b & -c & d \\ c & d & a & b \\ -d & c& b& -a\end{pmatrix}$$ To find a kernel, I used elementary row operations to an augmented matrix $(DF|0)$ . This calculation is very messy, so I am not sure whether this method is right or not. p.s. I know there are similar questions( The hopf fibration is a submersion. Hopf fibration is a submersion ), but I didn't understand their answers. Moreover, What I want to do is to find $\ker(DF)$ .","['hopf-fibration', 'riemannian-geometry', 'differential-geometry']"
3723479,Differentiate $\mathrm{e}^{x\arctan\left(x\right)}$,"I was trying to differentiate the question and I did it in the following 2 ways: METHOD $1:$ Using the cain rule, we get, $$\frac{\,d}{\,dx}\mathrm{e}^{x\arctan\left(x\right)}=\mathrm{e}^{x\arctan\left(x\right)}\frac{\,d}{\,dx}x\arctan\left(x\right)=\mathrm{e}^{x\arctan\left(x\right)}\left\{\arctan\left(x\right)+\frac{x}{x^2+1}\right\}\tag1$$ METHOD $2:$ But, when we try to do implicit differentiation, we get $$y=\mathrm{e}^{x\arctan\left(x\right)}$$ $$\ln y=x\arctan\left(x\right)$$ $$\frac{\,d}{\,dx}\tan\left(\frac{\ln\left(y\right)}{x}\right)=\frac{\,d}{\,dx}x$$ $$\frac{1}{\cos^2\left(\frac{\ln\left(y\right)}{x}\right)}\frac{1}{xy}yâ€™=1$$ $$yâ€™=\cos^2\left(\tan^{-1}\left(x\right)\right)x\mathrm{e}^{x\arctan\left(x\right)}$$ $$yâ€™=\frac{x}{x^2+1}\mathrm{e}^{x\arctan\left(x\right)}$$ But these give different answers, please help me where have I gone wrong.",['derivatives']
3723482,Applying Stokes Theorem Without Vector Field,"Q: Evaluate $\oint_S 4x dx + 9y dy + 3(x^2 +y^2) dz$ where $S$ is the boundary of the surface $z=4-x^2-y^2$ where $x,y,z \ge 0$ , oriented counterclockwise as viewed from above. I am a bit confused with how to do this question since I'm not given a vector field. Do I not apply Stoke's theorem? Any push in the right direction would be greatly appreciated. Edit: I now know that I can express this as a vector field F $=4x$ i $+9y$ j $+3(x^2+y^2)$ k . Using the cross product, I have found curl F $=6y$ i $-6x$ j , and want to evaluate $\oint_S 4x dx + 9y dy + 3(x^2 +y^2) dz$ using Stokes' theorem ( $\iint_S$ curl F $\cdot$ n $dA$ ). However, I am unsure how to calculate n , the unit normal of $S$ which in this case would be the surface $z=4-x^2-y^2$ restricted to $x,y,z \ge 0$ . Does anyone have any pointers?","['multivariable-calculus', 'stokes-theorem', 'vector-analysis']"
3723511,How to decide whether $n+\varphi(n)$ can divide $n^2+k$?,"How can we decide whether for a given positive integer $k$ , $\varphi(n)+n$ can divide $n^2+k$ , where $\varphi(n)$ denotes the totient function ? Some cases are easy : $n=1$ is a solution for odd $k$ . $n=2$ is the smallest solution for $k\equiv 2\mod 6$ For $k=214$ , the smallest solution is $4\ 359\ 549$ . For $k=382$ , I have not found a solution yet. According to my calculations, there is no solution $n\le 2\cdot 10^9$ Is there any systematic way to find the solutions (or at least one) or to prove that there is none ?","['number-theory', 'totient-function', 'divisibility', 'elementary-number-theory']"
3723526,Value of $\alpha$ for which $x^5+5\lambda x^4-x^3+(\lambda\alpha-4)x^2-(8\lambda+3)x+\lambda\alpha-2=0$ has roots independent of $\lambda$,"Consider the equation $$x^5 + 5\lambda x^4 -x^3 + (\lambda \alpha -4)x^2 - (8\lambda +3)x + \lambda\alpha - 2 = 0$$ The value of $\alpha$ for which the roots of the equation are independent of $\lambda$ is _______ My approach : The equation can be rewritten as: $$\underbrace{(x-2)(x^4 + 2x^3 + 3x^2 + 2x + 1)}_{f(x)} + \lambda\underbrace{(5x^4 + \alpha x^2 -8x + \alpha)}_{g(x)} = 0$$ For this equation to be valid independent of $\lambda$ , $f(x) = g(x) = 0$ . $f(x)$ has $2$ as one of it's roots. Solving $g(2) = 0$ , the value of $\alpha$ comes out to be $$\alpha = -\frac{64}{5}$$ which is unfortunately not the correct answer. Where is my approach breaking down?","['algebra-precalculus', 'roots', 'polynomials']"
3723531,Completeness of $L^p$,"I have some doubts with the proof on this theorem (Bartle Elements of Integration) $\textbf{Theorem:}$ The vector space $L^p(X,\mathcal{F},\mu)$ is complete with the norm $$ \Vert \overline{f} \Vert_p = (\int \vert f \vert ^p )^{1/p} $$ I will write $f$ instead of your class. $\textbf{Proof:}$ Let $(f_n)$ a Cauchy sequence in $L^p$ . Then, exists a subsequence $(g_k)$ of $(f_n)$ such that $\Vert g_{k+1}-g_k \Vert < 2^{-k}$ . Define $$ (*)g(x) = \vert g_1(x) \vert + \sum_{i=1}^{\infty} \vert g_{k+1}(x) - g_k(x) \vert \implies \vert g(x) \vert ^p = (\vert g_1(x) \vert + \sum_{i=1}^{\infty} \vert g_{k+1}(x) - g_k(x) \vert)^p$$ Note that $g: X \rightarrow \overline{R}$ is measurable and $g \geq 0$ . Then by Fatou's lemma (notice that the sequence on the right converges to $\vert g \vert ^p$ ) $$ \int \vert g \vert^p d\mu \leq \text{liminf}\int (\vert g_1(x) \vert + \sum_{i=1}^{n} \vert g_{k+1}(x) - g_k(x) \vert)^p d\mu $$ $$ \implies (\int \vert g \vert^p d\mu)^{1/p} \leq \text{liminf} \lbrace \int (\vert g_1(x) \vert + \sum_{i=1}^{n} \vert g_{k+1}(x) - g_k(x) \vert)^p d\mu \rbrace^{1/p} $$ By Minkowski's and because $\Vert g_{k+1}-g_k \Vert < 2^{-k}$ we have $$ \implies (\int \vert g \vert^p d\mu)^{1/p} \leq \text{liminf} (\Vert g_1 \Vert_p + \sum_{i=1}^n \Vert g_{k+1} - g_k \Vert_p) = 1 + \Vert g_1 \Vert_p  $$ $\textbf{Here comes my first question}$ , in the book it says that if we consider $E=\{x \in X / g(x)< \infty \}$ then $E \in \mathcal{F}$ and $\mu(X \setminus E)=0$ . I can't understand why $\mu(X \setminus E)=0$ . After this he says that $g$ converges $\mu-a.e$ (I guess it will refer to (*)) and $g \chi_{E}$ is in $L^p$ . $\textbf{Here my second question}$ , because it is necessary to work with E?. I know that $g$ can take $\infty$ , but from the above we can see that $\int \vert g \vert^p d\mu < \infty $ because $g_1 \in L^p$ and so $\Vert g_1 \Vert_p < \infty$ and then $g \in L^p$ . Anyway, following the proof of the book, we define $f: X \rightarrow \mathbb{R}$ by $$f(x) = g_1(x) + \sum_{i=1}^{\infty} g_{k+1}(x)-g_k(x), \hspace{0.1cm} x\in E $$ $$f(x) = 0, \hspace{0.1cm} x\notin E $$ Applying the triangle inequality we have $\vert g_k \vert \leq \vert g_1 \vert + \sum_{i=1}^{k-1} \vert g_{j+1}-g_j \vert \leq g$ and then $\vert g_k \vert^p \leq g^p$ . Because $\vert g_k \vert^p \rightarrow \vert f \vert^p$ converge in $E$ (i.e $\mu$ -a.e) by the Dominated Convergence Theorem : $f \in L^p$ . Then we have $\vert f -g_k \vert \leq 2 \text{max}\{ \vert f \vert, \vert g_k \vert \}\leq 2g $ i.e $\vert f-g_k \vert^p \leq 2^p g^p$ , by the Dominated Convergence Theorem $$ 0 = \int \lim \vert f-g_k \vert^p = \lim \int \vert f-g_k \vert^p \implies \lim \Vert f-g_p \Vert_p = 0 $$ Then $g_k \rightarrow f$ in $L^p$ . Finally, because $(f_n)$ is Cauchy, for $\epsilon > 0$ , exists $n_0 \in \mathbb{N}$ such that $m,n>n_0$ implies $$ \int \vert f_m-f_n \vert^p < \Vert f_m - f_n \Vert_p <\epsilon^p $$ $\textbf{Here my third question}$ , in the book says that we have consider $k$ (bigger) such that $$ \int \vert f_m-g_k \vert^p < \epsilon^p $$ What means this ?, I understand that means that we can always choose a index of subsequence such that is greater than $n_0$ but I'm not sure. And then applying Fatou's Lemma $$ \int \vert f_m-f \vert^p \leq \text{liminf} \int \vert f_m-g_k \vert ^p  \leq \epsilon^p $$ And then $f_n \rightarrow f$ in $L^p$ , so $L^p$ is complete. Thank you very much for reading all this proof and I hope you can understand what my doubts were.","['measure-theory', 'analysis']"
3723567,How to show $\frac{d}{d x}\left(|x|^{1/2}\right)=\frac{x}{2|x|^{3/2}}$?,"$$\frac{d}{d x}\left(|x|^{\frac{1}{2}}\right)=\frac{x}{2|x|^{\frac{3}{2}}}$$ and also the second derivative $$\frac{d^{2}}{d x^{2}}\left(\sqrt{|x|}\right)=\frac{\delta(x)}{\sqrt{|x|}}-\frac{x^{2}}{4|x|^{\frac{7}{2}}}$$ I know this may seem basic. But I don't get how the Dirac delta (thanks for the comments for correcting me) comes in. Is it just a way someone has decided to write the result for $x >0$ , $x<0$ and $x=0$ cleverly in one line. Is it arbitrary as long as the Kronecker term beats the other term? If anyone has a clean derivation for these I'd be grateful. EDIT: thanks for a lot of your answers, I've learnt a lot.
Still not entirely sure with the second derivative, the formula is here: https://www.wolframalpha.com/input/?i=second+derivative+of+%7Cx%7C%5E1%2F2 , is this wrong? I still think it is probably correct. From taking something like. d/dx( $\operatorname{sign}(x) \frac{1}{2|x|^{\frac{1}{2}}} )=1/2 ($$\frac{\delta(x)}{\sqrt{|x|}} -\frac{sign(x)*x}{2|x|^{5 / 2}})$ Don't know why first summand is missin 1/2. I know its distributions, but can't you still differentiate sign(x), you just have to be careful and when evaluating use test functions and integrals","['calculus', 'analysis', 'real-analysis']"
3723584,for which a values $\int_{\mathbb{R^{2}}} \frac{sin(x^2+y^2)}{(x^2+y^2+1)^a}dxdy $ converges?,"For which a values $\displaystyle \int_{\mathbb{R^{2}}} \frac{\sin(x^2+y^2)}{(x^2+y^2+1)^a}\,dx\,dy$ converge?
I believe that only for $a\geq 0.5$ but I don't how to prove it.
I was able to reduce the problem for only one variable $\displaystyle \frac{1}{2r^2+1}$ but I don't know how to prove this converges for $a>0.5$ or diverges for $a\leq 0.5$ .","['indefinite-integrals', 'multivariable-calculus']"
3723634,"If $ g_1, g_2, g_3 ,..., g_n$ are representatives of conjugacy classes of a group $G$ such that the elements pairwise commute, then $G$ is abelian.","The question says, Let $ g_1, g_2, g_3 ... g_n$ be representatives of all the distinct conjugacy classes of a finite group $G$ , such that these elements pairwise commute. Prove that $G$ is abelian. I just want my proof to get verified, as this is really simple, I'm a little sceptical about it. Proof: Let $C_G(g_i)$ be the centraliser of the element $g_i$ . Since it is given all the $g_i$ 's pairwise commute, we have $$  C_G(g_1) \cap C_G(g_2) \cap ... \cap C_G(g_n) \supset \{g_1, g_2, g_3 ... g_n\} $$ . Let us assume $|G|=N$ . Since we have $|C_G(g_i)| \geq n, \forall i \in \{1,2,...,n\}$ , from the class equation we have $$ |G| = \sum_{i=1}^n{|G : C_G(g_i)|} $$ or, $$ N \geq \left( \frac{N}{n}\right) .n$$ and the equality holds iff $|C_G(g_i)|=n \forall i \in \{1,2,...,n\}$ . Thus we have, $C_G(g_i)=\{g_1, g_2, g_3 ... g_n\}  \forall i \in \{1,2,...,n\}$ . However, from the class equation, we have $C_G(g_i)=G$ for at least one $g_i$ , which belongs to the centre of the group $Z(G)$ . Hence $G= \{g_1, g_2, g_3 ... g_n\}$ and the group is abelian ( Proved ). Is it all right or am I missing something?","['group-theory', 'abstract-algebra', 'solution-verification']"
3723653,Calculating $\cos\frac\pi4$ from the half-angle formula gives $\sqrt{\frac12}$ instead of $\frac{\sqrt{2}}2$. What went wrong?,"I am using the formula $$\cos\left(\frac x2\right)=\sqrt{\frac{1+\cos(x)}2}$$ to find $\cos\left(\frac{pi}{4}\right)$ but it does not give me the correct result. $$
\cos\left(\frac{\pi}{4}\right)
= \sqrt{\frac{1+\cos\left(\frac{\pi}{2}\right)}2}
= \sqrt{\frac{1+0}2}
= \sqrt{\frac12}
$$ This contradicts $\cos\left(\frac{\pi}{4}\right) = \frac{\sqrt{2}}{2} $ . What did I do wrong?",['trigonometry']
3723667,"The 1st term is $\frac{1}{a}$, 2nd term is $\frac{1}{a+d}$, 3rd term is $\frac{1}{a+2d}$. Find the 5th term of the sequence?","If for some number a and d,if first term is 1â„a, second term is 1/(a+d) ,thrid term is 1/(a+2d) and so on, then 5th term of the sequence is :________? I am attempting to answer the question above. I assumed that I would just add a 'd' for every term, so I did the following: First term: $\frac{1}{a}$ Second term: $\frac{1}{a+d}$ Third term: $\frac{1}{a+2d}$ Fourth term: $\frac{1}{a+3d}$ Fifth term: $\frac{1}{a+4d}$ My answer is $\frac{1}{a+4d}$ ; however, I worry that merely adding a 'd' might be wrong.","['arithmetic', 'discrete-mathematics', 'sequences-and-series']"
3723731,Integration identity.,"could you help me with the following problem please: Verify the following identity $\displaystyle \iint_{\partial{W}} f \frac{\partial{f}}{\partial{\hat{n}}} \,dS=\iiint_{W} \left \| \nabla f \right \| ^2\,dx\,dy\,dz$ if $f$ is harmonic My main question is, what do you mean $\displaystyle \frac{\partial{f}}{\partial{\hat{n}}}$ or if the problem is badly posed, thank you very much in advance","['integration', 'multivariable-calculus', 'contour-integration']"
3723759,A lie theoretic interpretation of $e^\text{cycle} = \text{permutation}$?,"It is well known that exponentiating the EGF(exponential generating function) for cycles gives the EGF for permutations: link here . This is something summarized by the slogan all = exp(connected) . I wonder if it is possible to give a lie-theoretic explanation to this phenomenon where we have group = exp(algebra) . Is there some way to relate the ""counting"" done by the exponential generating function to an actual exponential between the Lie group and its algebra? Perhaps there is some way to use the representation theory of $S_n$ to establish some connection? Is this connection one of those near-misses that holds nothing deeper?","['symmetric-groups', 'combinatorics', 'lie-algebras', 'lie-groups']"
3723813,Intuition for a Proof of the Fundamental Theorem of Algebra (According to 3Blue1Brown),"I have recently watched this video by $3$ Blue $1$ Brown, regarding winding numbers and the fundamental theorem of algebra. I am trying to formalize the idea he shows in the video (starting at 21:26). Specifically, I am trying to connect his proof to a one I've seen in
complex analysis classes: Theorem. Fundamental theorem of algebra. Let $P(z)=z^d+a_1 z^{d-1}+a_2z^{d-2}+\ldots+a_{d-1}z+a_d\in \Bbb{C}[x]$ be a monic complex polynomial of degree $d$ . So the sum of all orders of $P$ 's zeroes is exactly $d$ . Proof. For a function $f$ , denote the sum of orders of all its zeros as $N_f$ . Let $Q(z)=z^d$ . It is obvious that $N_Q=d$ . Subtracting $Q$ from $P$ gives a polynomial of degree $d-1$ , therefore $\frac{|P(z)-Q(z)|}{|Q(z)|}\to0$ as $z\to\infty$ . Let $R_0$ be large enough so that for every $R>R_0$ , every $|z|=R$ satisfies $|P(z)-Q(z)|\le |Q(z)|$ . Using RouchÃ©'s theorem for the path $\gamma(t)=R e^{it}$ for $t\in[0,2\pi]$ , we deduce that $N_P=N_Q=d$ . $\tag*{$\blacksquare$}$ Understanding 3Blue1Brwon's Video In his video, $3$ B $1$ B defines a winding number of a complex function on a path as the total number of times the image of the function on the path ""goes through all hues"" of the color map (with negative and positive directions), and explains why a nonzero winding number means that the function has a zero within the area of the path. Qustion 1: What does he mean by this winding number? I.e., what is the formal definition of a ""winding number"" of a function ? I am familiar with the definition $$\operatorname{Ind}_\gamma (a) := \frac{1}{2\pi i} \oint_\gamma \frac{\text{d}z}{z-a},$$ which defines the index of a (closed) path in respect to a point . He then explains that the winding number of $Q(z)=z^d$ (in his video, $d=5$ ) around $0$ is $d$ (around some circular path). This I can intuitively understand - as $x$ goes along the unit circle, for example, the function $x^d$ goes around the circle $d$ times. Qustion 2: How is it connected to $0$ being a zero of order $d$ of $Q(z)$ ? Now, as $z\to\infty$ , the leading term of $P(z)$ is the only significant one, so $3$ B $1$ B explains that in a large enough circle, the index of $P$ and $Q$ will be the same. This argument is quite similar to the one in the proof above - Qustion 3: I assume that using RouchÃ©'s theorem ""hides under the surface"" some of the intuition in the proof. Is there a way of explicitly using this index equality of $P$ and $Q$ in a large enough circle formally in order to prove the fundamental theorem? Moreover, I know that paths that are homotopy equivalences, have the same index. Are $P$ and $Q$ in fact homotopy equivalences in the area outside the circle? Summing up, I am looking for a more ""mathematically complete"" explanation of $3$ B $1$ B's argument, rigorous yet intuitive. Edit: Question 4: RouchÃ©'s theorem is proved using the so called argument principle, as Oliver Diaz's answer mentions. I assume that, intuitivly, we would have wanted to write $\int_\gamma \frac{f'(z)}{f(z)} \ \text{d}z=\ln(b)-\ln(a)$ (if $\gamma(0)=a$ and $\gamma(1)=b$ ), but that is of course nonsense, since the complex logarithm is not holomorphic in $[-\infty,0]$ . That does remind me of the work done in a non-conservative field. Is this really the intuitive reason that the argument principle ""works""?","['complex-analysis', 'complex-integration', 'intuition']"
3723919,Proving $(x_1 x_2 \cdots x_n)^{-1} = x_n^{-1} x_{n-1}^{-1} \cdots x_2^{-1}x_1^{-1}$ for $x_i $ in group $G$,"Let $x_1, x_2, \ldots, x_n \in G$ for some group $G$ . We wish to prove that $$(x_1 x_2 \cdots x_n)^{-1} = x_n^{-1} x_{n-1}^{-1} \cdots x_2^{-1} x_1^{-1}.$$ I'm not sure if the correct way to proceed is by showing the multiplication out, which doesn't seem to me to be required for the inductive step. Here is what I have so far. Proof. Let $x_1, x_2, \ldots, x_n \in G$ for some group $G$ . We proceed by induction on $n$ .
When $n = 1$ , we have $$x_1^{-1} = x_1^{-1}.$$ Less trivially, when $n = 2$ , we have $$\begin{align}
(x_1 x_2)(x_2^{-1} x_1^{-1}) &= x_1 (x_2 x_2^{-1})x_1^{-1} \\
&= x_1 e x_1^{-1} \\
&= (x_1 e)x_1^{-1} \\
&= x_1 x_1^{-1} \\
&= e,
\end{align}$$ and $$\begin{align}
(x_2^{-1} x_1^{-1})(x_1 x_2) &= x_2^{-1} (x_1^{-1} x_1)x_2\\
& = x_2^{-1} e x_2 \\
&= x_2^{-1} (ex_2) \\
&= x_2^{-1} x_2 \\
&= e,
\end{align}$$ so $(x_1 x_2)^{-1} = x_2^{-1} x_1^{-1}$ .
Supposing inductively that the result holds when $n = k$ , $$
(x_1 x_2 \cdots x_k)^{-1} = x_k^{-1} x_{k-1}^{-1} \cdots x_2^{-1} x_1^{-1},$$ we prove the result when $n = k + 1$ : \begin{align*}
(x_1 x_2 \cdots x_k x_{k+1})^{-1} & = ((x_1 x_2 \cdots x_k)x_{k+1})^{-1} = x_{k+1}^{-1} (x_1 x_2 \cdots x_k)^{-1} \\
& = x_{k+1}^{-1} (x_k^{-1} x_{k-1}^{-1} \cdots x_2^{-1} x_1^{-1}) \\
& = x_{k+1}^{-1} x_k^{-1} x_{k-1}^{-1} \cdots x_2^{-1} x_1^{-1}.
\end{align*} How does this look?","['group-theory', 'solution-verification', 'induction']"
3723967,Is every module automorphism diagonalized by irreps?,"Let $G$ denote a finite group, and let $V$ be a complex and finite dimensional $G$ module; that is, there is a group representation $G\to GL(V)$ . Finally, let $T\colon V\to V$ be an intertwining map, that is, a linear map such that $T(gv)=g T(v)$ for all $v\in V$ and $g\in G$ . By the theorem of Maschke , there are irreducible $G$ -modules $V_1, V_2, \ldots, V_n$ such that $$
V=V_1\oplus V_2 \oplus \ldots \oplus V_n.$$ Question . Is it true that $$T v_j=\lambda_j v_j, \qquad \forall v_j\in V_j,$$ for some $\lambda_1,\ldots,\lambda_n\in\mathbb C$ ? The lemma of Schur says that this is the case provided that $$\tag{*}T(V_j)\subset V_j.$$ This is because, in this case, $T$ restricts to an intertwining self-map of $V_j$ , which is irreducible. Therefore such restriction must be a scalar multiple of the identity. But is it true that (*) always holds with the given assumptions? EDIT . This question arises from the following observations. Suppose that $G$ is finite and abelian, and let $L^2(G)$ denote the space of all complex-valued functions on $G$ , which is a $G$ -module with the representation $gf(x):=f(x-g)$ . (This seemingly complicated notation hints at more general cases, with infinite groups). Let $\chi\in L^2(G)$ denote a character, that is, a homomorphism of $G$ into $\mathbb C^\times$ . Then an intertwining map $T\colon L^2(G)\to L^2(G)$ satisfies $$T\chi=\lambda_\chi \chi, $$ as it is easy to prove. And since the irreps are in this case the 1-dimensional subspaces $$
\operatorname*{span}(\chi), $$ it follows that intertwining maps of the $G$ -module $L^2(G)$ are diagonalized by irreps. (As the accepted answer clearly shows, intertwining maps of other $G$ -modules need not be even diagonalizable! This is the reason why I found that answer surprising and enlightening). Let us consider an infinite and non-abelian case. Suppose that $T\colon L^2(\mathbb S^{d-1})\to L^2(\mathbb S^{d-1})$ is rotation-invariant; $$
(Tf)(R^{-1}x)=T(f(R^{-1}\cdot))(x).$$ Then $T$ is diagonalized by spherical harmonics. Precisely, letting $$\{Y_{n, j}\ :\ j=1, \ldots, N(n)\}$$ denote a complete orthonormal system of spherical harmonics of degree $n$ , we have that $$
Tf=\sum_{n=0}^\infty \lambda_n \sum_{j=1}^{N(n)} \hat{f}(n, j) Y_{n, j}, $$ where we have let $\hat{f}(n, j)$ denote the coefficient $\langle f | Y_{n, j}\rangle.$ This latter example actually is a consequence of the lemma of Schur. Indeed, the decomposition of the $SO(d)$ -module $L^2(\mathbb S^{d-1})$ into irreps is precisely $$
\bigoplus_{n=0}^\infty \operatorname*{span}\{ Y_{n,j}\ :\ j=1, \ldots, N(n)\}, $$ and these irreps are pairwise non-isomorphic, because $N(n)$ is not a constant. (Actually, $N(n)$ has a well-known combinatorial expression, which there is no need to write down explicitly here).","['harmonic-analysis', 'representation-theory', 'linear-algebra']"
3723970,"Answer true or false: For A and B sets, A âˆ© B = B âˆ© B'","Answer true or false: For sets $A$ and $B:$ $A \cap B = B \cap B'.$ The statement is false. Let $A$ and $B$ be non-empty sets with $A = B$ and let $X = \{ a , b , c \}.$ Then $A \cap B = \{ a \} \cap \{ a \} = \{ a \} $ and $B \cap B'= \{ a \} \cap \{ b , c\}.$ Since for all set $A, \emptyset \subseteq A$ , note that $\{ a \} \cap \{ b , c \} = \emptyset.$ But then $A \cap B \neq B \cap B'$ because $\{a\} \neq  \emptyset.$ Is my answer correct? This is an exercise taken from my workbook.","['elementary-set-theory', 'solution-verification']"
3723990,Approximating a derivative: How to complete this proof of $f'(x_2) = \frac{f_0 - 8f_1 + 8f_3 - f_4}{12 h} + \frac{h^4}{30}f^\mathrm{V}(\xi)$?,"Fix five equally spaced nodes as $x_i = x_0 + ih$ where $h > 0$ , $x_0\in\mathbb{R}$ , and $i = 0, 1, 2, 3, 4$ . Let us also denote $f_i := f(x_i)$ . Exercise. Assume that $f\in \operatorname{C^5}[x_0, x_4].$ Show that there exists some $\xi(x_2)=:\xi\in[x_0, x_4]$ such that $$f'(x_2) = \dfrac{f_0 - 8f_1 + 8f_3 - f_4}{12 h} + \dfrac{h^4}{30}f^\mathrm{V}(\xi).\label{E}\tag{E}$$ Solution. Using a method of undetermined coefficients and approximation by Taylor polynomials with Lagrangian remainders, I believe to have shown that $$f'(x) = \dfrac{f_0 - 8f_1 + 8f_3 - f_4}{12 h} + \frac{h^4}{30} \frac{16\, f^\mathrm{V}(\xi_2) - 4\, f^\mathrm{V}(\xi_1)}{12} \tag{1}$$ where $\xi_1, \xi_2 \in[x_0, x_4]$ , and $x:=x_2.$ Here is the more detailed explanation. (Skip forward to section named Question if you wish). First for $k = 1, 2$ using Taylor polynomials and Lagrangian remainders $$f(x\pm kh) = f(x) \pm f'(x)\, kh + f''(x)\, \frac{k^2 h^2}{2} \pm f'''(x)\, \frac{k^3 h^3}{6}
 + f^\mathrm{IV}(x)\,\frac{k^4 h^4}{24} \pm f^\mathrm{V}(\xi_\pm^k)\,\frac{k^5 h^5}{120} \label{A1}\tag{A1}$$ where $\xi_\pm^k$ is between $x$ and $x \pm k h$ . Note also that $x_1 = x - h$ , $x_3 = x + h$ and so on. Let us view the expression $Af_0 + Bf_1 + Cf_3 + Df_4$ where $A, B, C, D$ are to be determined. After substituting $f_0, f_1, f_3, f_4$ from the earlier Taylor expansion $\eqref{A1}$ into this expression, one gets after further dividing both sides by $h$ that \begin{align*}\frac{Af_0 + Bf_1 + Cf_3 + Df_4}{h} = \, (&A + B + C + D)\,\frac{f(x)}{h} + (-2A - B + C + 2D)\, f'(x)\\
+&(4A + B + C + 4 D)\,f''(x)\, \frac{h}{2}  \\
+&\, (-8A -B + C + 8D)\,f'''(x)\, \frac{h^2}{6} + (16A + B + C + 16D)\, f^\mathrm{IV}(x)\,\frac{ h^3}{24}\\
+& \left[-32A\, f^\mathrm{V}(\xi_-^2) - B\, f^\mathrm{V}(\xi_-^1) + C\, f^\mathrm{V}(\xi_+^1) + 32D\, f^\mathrm{V}(\xi_+^2)\right]\,\frac{h^4}{120}.
\label{A2}\tag{A2}\end{align*} Next we attempt to determine the coefficients $A, B, C, D$ in such a way that we are left with $f'(x)$ and $h^4$ terms on the RHS of $\eqref{A2}$ . This gives us the system $$
\begin{cases}
	A + B + C + D = 0,\\
	-2A - B + C + 2D = 1, \\
    4A + B + C + 4 D = 0, \\
    -8A -B + C + 8D = 0,\\
    16A + B + C + 16D = 0.
\end{cases}\label{A3}\tag{A3}
$$ The unique solution is $A = - D = \dfrac{1}{12}$ , $-B = C = \dfrac{2}{3}.$ If we denote the $h^4$ term by $-\mathcal R(x)$ , then substituting the values of the coefficients back into $\eqref{A2}$ , we get $$\dfrac{f_0 - 8f_1 + 8f_3 - f_4}{12 h} + \mathcal R(x) = f'(x).\label{A4}\tag{A4}$$ Comparing this to $\eqref{E}$ , what remains to be shown is that the expression $$\mathcal R(x) = \left[32A\, f^\mathrm{V}(\xi_-^2) + B\, f^\mathrm{V}(\xi_-^1) - C\, f^\mathrm{V}(\xi_+^1) - 32D\, f^\mathrm{V}(\xi_+^2)\right]\,\frac{h^4}{120}\label{A5}\tag{A5}$$ or, after substituting the solution coefficients and simplifying, that the expression $$\mathcal R(x) = \frac{h^4}{30} \frac{8\, f^\mathrm{V}(\xi_-^2) - 2\, f^\mathrm{V}(\xi_-^1) - 2\, f^\mathrm{V}(\xi_+^1) + 8\, f^\mathrm{V}(\xi_+^2)}{12}\label{A6}\tag{A6}$$ is somehow equal to $$\dfrac{h^4}{30}f^\mathrm{V}(\xi)\label{A7}\tag{A7}$$ for some $\xi\in[x_0, x_4]$ . Because $f^\mathrm{V}$ is continuous, by the intermediate value theorem we get \begin{align*}
f^\mathrm{V}(\xi_-^1) + f^\mathrm{V}(\xi_+^1) = 2 f^\mathrm{V}(\xi_1),\label{A8}\tag{A8}\\
f^\mathrm{V}(\xi_-^2) + f^\mathrm{V}(\xi_+^2) = 2 f^\mathrm{V}(\xi_2),\label{A9}\tag{A9}
\end{align*} where $\xi_1 \in(x - h, x + h)$ and $\xi_2 \in(x - 2h, x + 2h)$ . Therefore, $$\mathcal R(x) = \frac{h^4}{30} \frac{16\, f^\mathrm{V}(\xi_2) - 4\, f^\mathrm{V}(\xi_1)}{12}.\label{A10}\tag{A10}$$ Question. If I could show that for some $\xi\in [x_0, x_4]$ $$16f^\mathrm{V}(\xi_1) - 4f^\mathrm{V}(\xi_2) = 12f^\mathrm{V}(\xi),\label{Q}\tag{Q}$$ the proof would be complete. Is this achievable? If it isn't always possible to do, there is probably a mistake somewhere...","['analysis', 'solution-verification', 'numerical-calculus', 'numerical-methods', 'derivatives']"
3724007,The ratio of moments in a normal distribution,"I'm reading a paper where they (Mann and Whitney) want to show the limiting distribution they get is normal. They do this by looking at a ratio of moments. They do a computation then conclude the limiting distribution is normal by a ""well known theorem"". Can someone provide a reference? The relevant part of the paper is copied below:","['statistics', 'probability-distributions', 'normal-distribution', 'probability-theory', 'probability']"
3724018,Help with proof of Euler's criterion,"Problem This problem is about finding square roots modulo a prime $p$ . (a) Prove that $x^2 \equiv y^2 \pmod p$ if and only if $x \equiv y \pmod p$ or $x \equiv -y \pmod p$ . An integer $x$ is called a square root of $n$ mod $p$ when $x^2 \equiv n \pmod p$ . An integer with a square root is called a square mod $p$ . Assume that $p$ is an odd prime and $n \not \equiv 0 \pmod p$ . It turns out there is a simple test we can perform to see if $n$ is a square mod $p$ : Euler's Criterion i. If $n$ is a square modulo $p$ , then $n^{(p-1)/2} \equiv 1 \pmod p$ . ii. If $n$ is not a square modulo $p$ , then $n^{(p-1)/2} \equiv -1 \pmod p$ . (b) Prove Case (i) of Euler's Criterion. (c) Prove Case (ii) of Euler's Criterion. Solution (a) Prove both directions of the if and only if: Assume that $x^2 \equiv y^2 \pmod p$ . Then: $$\begin{align}
  &x^2 - y^2 \equiv 0 \pmod p \\
  &\Rightarrow(x+y)(x-y) \equiv 0 \pmod p \\
  &\Rightarrow p\text{ | }(x+y)(x-y) \\
  &\Rightarrow [p\text{ | }(x+y)]\text{ or }[p\text{ | }(x-y)] &\text{(since }p\text{ is prime)} \\
  &\Rightarrow [x+y \equiv 0 \pmod p]\text{ or }[x-y \equiv 0 \pmod p] \\
  &\Rightarrow [x \equiv -y \pmod p]\text{ or }[x \equiv y \pmod p]
  \end{align}$$ Assume that $x\equiv y \pmod p$ or $x\equiv -y \pmod p$ . In both cases, squaring both sides gives $x^2\equiv y^2 \pmod p$ . (b) Assume that $x^2 \equiv n \pmod p$ for some $x, n, p$ . Since $n \not \equiv 0 \pmod p$ and $p$ is prime, $n$ and $p$ are relatively prime. Then, $x^2$ and $p$ are also relatively prime. Therefore, $x$ must be relatively prime to $p$ . Then, by Fermat's theorem, $x^{p - 1} \equiv 1 \pmod p$ . So: $$\textrm{rem}(n^{(p-1)/2}, p) = \mathrm{rem}((x^2)^{(p-1)/2}, p) = \mathrm{rem}(x^{p-1}, p) = 1,$$ which proves (i). (c) Assume that $n$ is not a square modulo $p$ . Since $n$ and $p$ are relatively prime, by Fermat's theorem, $n^{p - 1} \equiv 1 \pmod p$ . Since $p$ is odd, $p - 1$ is even, so this can be rewritten as: $$(n^{(p - 1)/2})^2 \equiv 1 \pmod p.$$ Then, from (a), it must be the case that either $n^{(p - 1)/2} \equiv 1 \pmod p$ or $n^{(p - 1)/2} \equiv -1 \pmod p$ . I got stuck at this point . I don't know how to infer, from the above facts, that $n^{(p-1)/2} \equiv -1 \pmod p$ . Any hints on how to proceed?","['elementary-number-theory', 'solution-verification', 'discrete-mathematics']"
3724155,A Polynomial Formed from the Roots of Another Polynomial ad infinitum,"Let $P(x)$ be a monic polynomial of degree $d$ with complex coefficients. Let $r_1(P),r_2(P),\dots, r_d(P)$ denote the set of roots, ordered so that $|r_1(P)| \leq |r_2(P)|\leq\dots\leq |r_d(P)|$ . Define the map $T$ by: $$(TP)(x)=x^d+r_1(P)x^{d-1}+r_2(P)x^{d-2}+\dots+r_d(P),$$ i.e. $TP$ is the monic polynomial whose coefficients are the roots of $P$ . Let us call a monic polynomial periodic if $T^KP=P$ for some $K>0$ . The question is: for any $d>0$ , does there exist a periodic polynomial of degree $d$ , other than the trivial solution $x^d$ ? Remark on the definition of T As pointed out in the comments, the definition of $TP$ is ambiguous if there are two roots $r_i(P)$ and $r_j(P)$ such that $|r_i(P)|=|r_j(P)|$ and $r_i(P)\neq r_j(P)$ . If the roots of $P$ have this property, then you may break the ties however you please. For example, if $P(x)=x^3-x$ , then it is up to you whether to set $r_2(P)=1$ and $r_3(P)=-1$ or $r_2(P)=-1$ and $r_3(P)=1$ . However, either ordering still must have $r_1(P)=0$ , since there is no ambiguity there. Note that the set of polynomials that have this ambiguity has measure zero, so I suspect such considerations will not influence the solution of the problem anyway. Empirical Evidence If $d=1$ then the answer is clearly yes (any $P(x)=x-a$ will do the job, with $a\ne 0$ ). If $d=2$ then $P(x)=x^2+x-2$ is a fixed point of $T$ , so in particular is periodic with period 1. I examined other low degrees by numerical simulation. Note that this requires relaxing the definition of a cycle, since testing for exact equality of floating point numbers is impossible. Thus, for these simulations, the condition $T^KP=P$ was replaced with $\|T^KP-P\|_\infty<\varepsilon$ , with $\varepsilon=10^{-10}$ . In particular, these simulations can only find polynomials $P$ that are periodic up to some fixed error tolerance. The simulation was done by first initializing the coefficients of $P$ using values drawn from a standard normal distribution, and then iteratively applying $T$ 1000 times and checking whether the obtained sequence was eventually periodic (up to error $<\varepsilon$ ). Note that this method might not find all cycles. The periods found thusly for low degrees are: $$
\begin{array}{rc}
d=3 & \text{possible periods}= 1 ; 11 \\
4 & 21 \\
5 & 4 ; 56 \\
6 & 34 ; 44 \\
7 & 10 ; 15 ; 26 ; 234 \\
8 & 3 ; 38 ; 83 ; 292 \\
9 & 256 ; 311 ; 466 \\
10 & 275 ; 336
\end{array}
$$ Furthermore, for degrees $\leq 8$ , all of the simulated sequences eventually became periodic, however this was not true for $d=9$ or $10$ (of course, this does not imply that these sequences never become periodic, just that they did not before the simulation ended). Crossposted to Mathoverflow:https://mathoverflow.net/questions/364359/a-polynomial-formed-from-the-roots-of-another-polynomial-ad-infinitum","['dynamical-systems', 'polynomials', 'complex-numbers', 'sequences-and-series']"
3724260,Maximal Solution (ODE) of $x' = x^2 - t^2$,"$\DeclareMathOperator{\dom}{dom}$ Let $\gamma(t)$ be a the maximal solution of the diferential equation $x' = x^2 - t^2$ with initial condition $\gamma(0) = 0$ . Show that $\gamma(t) \leq |t|$ , for any $t \in \dom(\gamma)$ and conclude that $\dom(\gamma) = \mathbb{R}$ . Attempt: Assuming that $\gamma(t) \leq |t|$ , for any $t \in \dom(\gamma)$ , I was able to conclude that $\dom(\gamma) = \mathbb{R}$ , using the fact that $\gamma (t)$ is a maximal solution. Also, note that $(x^2 - t^2)' = 2x(x^2 - t^2) - 2t$ . I tried to analyse for $t\geq 0$ and $t<0$ , but there's not much I can infer about about $(x^2 - t^2)'$ since I don't know the sign of $x$ . Is there any algebraic manipulation that could be helpful to procced with this idea? Any help would be appreciated!","['analysis', 'ordinary-differential-equations']"
3724344,"Fixed subfield of symmetric rational functions $K(s_1,\ldots,s_n)$ under $A_n$","Let $K$ be a field of characteristic $\operatorname{char} K\neq 2$ , and let $L=K(x_1,\ldots,x_n)$ be the field of rational functions of $n$ variables with coefficients from $K$ . Denote $F=L^{S_n}=K(s_1,\ldots,s_n)$ , the fixed subfield of $S_n$ (where $s_1,\ldots,s_n$ are the elementry symmetric polynomials). Show that $$L^{A_n}=F\left(\prod_{1\le i<j \le n} (x_i -x_j)\right).$$ My attempt : Denote the RHS $E'$ and the LHS $E$ , and $f=\prod_{1\le i<j \le n} (x_i -x_j)$ . Since every $\sigma \in A_n$ acts on $f$ as identity (as any transposition does not change $f$ ), we have $E'\subseteq E$ . The other direction is more challenging. I tried using the fact that $S_n$ is generated by a full cycle and one transposition, but I am not sure how to continue. I assume there are tricks using the discriminant (or rather the discriminant uses this trick?).
Moreover, is $L/F$ even Galois? I am not sure if it is possible to use the fundamental theorem of Galois theory.","['permutations', 'galois-representations', 'galois-theory', 'abstract-algebra', 'symmetric-groups']"
