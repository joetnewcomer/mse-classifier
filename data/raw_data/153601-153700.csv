question_id,title,body,tags
2585923,Solving $\nabla \times \mathbf{b} = \mathbf{b} \times \mathbf{a}$,"Suppose we are given a fixed vector field $\mathbf{a}$. I am interested in the problem of determining a vector field $\mathbf{b}$ such that 
$$\nabla \times \mathbf{b} = \mathbf{b} \times \mathbf{a}.$$
This has another interpretation. Suppose $\alpha$ and $\beta$ are the 1-forms dual to $\mathbf{a}$ and $\mathbf{b}$. The above equation can be written as
$$d \beta = \beta \wedge \alpha,$$ 
and so we can interpret this problem as finding, for a fixed 1-form $\alpha$, a foliation $\mathcal{F} = \text{ker}\ \beta$ such that $\alpha$ determines the Godbillon-Vey class of $\mathcal{F}$. It seems unlikely to me that a solution always exists, but I have been unable to prove anything beyond the obvious fact that we must have $\mathbf{b} \cdot \nabla \times \mathbf{b} = 0$, and that $\mathbf{b} \cdot \nabla \times \mathbf{a} = \mathbf{a} \cdot \nabla \times \mathbf{b}$ (take the divergence), which implies (Mark's comment) that $\mathbf{b}$ is orthogonal to $\nabla \times \mathbf{a}$. Are there any known results about such equations, or techniques one could use to construct a solution other than crunching through the PDEs for each component?","['multivariable-calculus', 'cross-product', 'foliations']"
2585937,Integer solution,"I would like to solve the following equation for $\alpha$ under the condition that $\alpha$ is an integer (positive or negative) $$\alpha(\alpha-1)(\alpha-2)(\alpha-3)-2n(n-1)(\alpha-1)(\alpha-2)+[n(n-1)-2]n(n-1)=0$$ where $n$ is an integer. Is there a systematic way/method to solve it or I just have to use trial and error? For some background, this is a relation that follows from the differential equation
$$\alpha(\alpha-1)(\alpha-2)(\alpha-3){\cal G}_{n}+4(1-\mu^{2})\frac{d^{2}{\cal G}_{n}}{d\mu^{2}}-4(1-\mu^{2})\alpha \frac{d^{2}{\cal G}_{n}}{d\mu^{2}}+2(1-\mu^{2})\alpha(\alpha-1)\frac{d^{2}{\cal G}_{n}}{d\mu^{2}}+(1-\mu^{2})^{2}\frac{d^{4}{\cal G}_{n}}{d\mu^{4}}-4\mu(1-\mu^{2})\frac{d^{3}{\cal G}_{n}}{d \mu^{3}}=0
$$
where ${\cal G}_{n}$ obeys the equation $$(1-\mu^{2})\frac{d^{2}{\cal G}_{n}}{d\mu^{2}}+n(n-1){\cal G}_{n}=0$$","['algebra-precalculus', 'polynomials', 'ordinary-differential-equations', 'sequences-and-series']"
2585941,Touch-axiomatization of point-set topology,"This MathOverflow post presents an alternative axiomatization of point-set topology that closely aligns with the intuitive notion that a topology on a set tells you which points are ""infinitesimally close"" to each other. The relevant part of the post is paraphrased below. Definition: A touch relation on a set $X$ is a binary relation $\lessdot$ between the members of $X$ and the subsets of $X$ (we read $x \lessdot A$ as ""$x$ touches $A$"") that satisfies the following axioms: No element of $X$ touches the empty set. If $x \in A$, then $x \lessdot A$. If $x \lessdot (A \cup B)$, then $x \lessdot A$ or $x \lessdot B$. If $x \lessdot A$ and every element of $A$ touches $B$, then $x \lessdot B$. I would like to prove that these axioms are indeed equivalent to the usual axioms for a topology in terms of open sets. To do this, I need to exhibit for any given set $X$ a bijective correspondence between touch relations on $X$ and topologies on $X$. I believe the correct correspondence is as follows: Given a touch relation on $X$, we obtain a topology on $X$ by declaring $A \subseteq X$ to be open if and only if no member of $A$ touches $X \setminus A$. Given a topology on $X$, we obtain a touch relation on $X$ by declaring that $x \lessdot A$ if and only if $x \in \overline{A}$, where $\overline{A}$ denotes the topological clousure (intersection of all closed supersets) of $A$. So far I have been able to show that both of these maps are well-defined (i.e., that they do produce a topology from a touch relation and vice versa). I can also show that the first map is a left inverse of the second (i.e., by starting from a topology $T$ on $X$, constructing the touch relation $\lessdot$ induced by $T$, and then constructing the topology $T'$ induced by $\lessdot$, we always have that $T = T'$). To finish off the proof, I need to show that the first map is a right inverse of the second, which I haven't yet figured out how to do. If I've unwound the definitions correctly, showing that the touch relation $\to$ topology $\to$ touch relation round-trip is the identity map amounts to proving the following: If $\lessdot$ is a touch relation on $X$, then $x \lessdot A$ if and only if $x$ is a member of every superset $B$ of $A$ with the property that $b \lessdot B \implies b \in B$. (Let's call such a set $B$ ""touch-closed."") The left-to-right implication is easy, but the right-to-left implication eludes me. Question: Let $\lessdot$ be a touch relation on $X$, and let $A \subseteq X$ be given. Suppose that $x$ is a member of every touch-closed superset of $A$. How can I  prove that $x \lessdot A$? My partial proof attempt follows. Proof: Let $C$ be the intersection of every touch-closed superset of $A$. By hypothesis, $x \in C$, so $x \lessdot C$. Using the fourth touch axiom, it suffices to show that every element of $C$ touches $A$. To do this, suppose the the sake of contradiction that some element $c \in C$ does not touch $A$. Then I claim that there exists a touch-closed superset $B$ of $A$ not containing $c$. Indeed...","['general-topology', 'axioms']"
2585960,"Evaluate $\int_0^{\infty}\frac{\log x}{1+e^x}\,dx$","Evaluate
$$\int_0^{+\infty}\frac{\log x}{1+e^x}\,dx.$$ I have tried using Feynman's Trick (in several ways, but for example by introducing a variable $a$ such that $I(a)=\int_0^{+\infty}\frac{\log ax}{1+e^x}\,dx$), but that doesn't seem to work. Also integration by parts and all kinds of substitutions make things worse (I have no idea how to substitute such that $\log$ and $\exp$ both become simpler. (Source: Dutch Integration Championship 2013 - Level 5/5)","['improper-integrals', 'integration', 'definite-integrals']"
2585974,"An irregular ball rolling on a plane, if know the path on ball surface, how to find the path on the plane?","An irregular ball has its local radius or curvature different at any surface point. It has pure rolling movement on the plane P. Several questions here: If I know the path curve from A to B on the ball, how to know the path on the plane, and vice versa? If I know the path on the ball is the geodesic from A to B , does it have a simpler solution on the plane? Or the other way, if the path on plane is straight, how is the path on the irregular ball? Is there a situation(for example how the ball have to be, or probably the plane have to be some kind of special curved plane,etc), the problem becomes path independent, that is to say, if I know the destination point B (and start point A) on the ball, I then know the point B on the (special) plane and vice versa. If only specify on the ball the start point A and a tangent direction $\hat{t}_A$ at A, the destination B and a tangent direction $\hat{t}_B$ at point B, meanwhile on the plane the start point A' and a tangent direction $\hat{t}_A'$ at A', the destination B' and a tangent direction $\hat{t}_B'$ at point B', is it possible to find a path on the ball (and the correspondent path on the plane), so that point A and A', point B and B', direction $\hat{t}_A$ and $\hat{t}_A'$ ,direction $\hat{t}_B$ and $\hat{t}_B'$ coincide, respectively? Thanks!",['differential-geometry']
2585976,"Permutations of the set $\{1, 2, 3, 4, 5\}$ fulfilling certain conditions - Combinations Theory","Problem: Among all the possible permutations of the set $\{1, 2, 3, 4, 5\}$, in how many fulfills that: the element $1$ is in the first position? the element $2$ is in the second position? the first three elements occupy the first three positions? Any of first three elements is not in their correct position? What have I tried? #1: If the element $1$ remains in first position I see it as a permutation of the other elements which is: $$
4! = 4 \cdot 3 \cdot 2 \cdot 1 = 24
$$ #2: I see this problem as the same as the first question but just for another element so I believe it to be the same answer which is: $$
4! = 24
$$ #3: If the first three elements remained in their original positions, I see that as a permutations of the remaining 2 elements which appears to be: $$
2! = 2 \cdot 1 = 2
$$ #4: $\color{red}{\text{I am not sure how to correctly proceed with this question. }}$ But from my understanding, it would be a situation where: The first element remains in it's original position with permutations of the other element then the same for the second then the third element. Also, when the first two elements remain, then the second two and finally the first and third. And would it be correct that it is the same as: $$
3(4!) + 3(3!) = 3\cdot24 + 3\cdot6 + 2 = 72 + 18 = 80
$$ Would these be correct and if not where did I go wrong and how do I correct it?","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2585977,Understanding partial derivative of logistic regression cost function,"I'm following along in Andrew Ng's great lecture series on machine learning, and he presents the following as the cost function for a logistic regression model [ link ]: $$L(a,y) = -(y \log(a) + (1 - y) \log(1 - a)) $$ He then builds a little math graph, or series of equations, that can be used as helpers for computing the partial derivatives of $L$ with respect to various variables [ link ]: $$ z = w_1x_1 + w_2x_2 + b $$
$$ \hat{y} = a = \sigma(z) $$ Next he says that the following represents the derivative of $L$ wrt $a$ [ link ]: $$ \frac{\partial L}{\partial a} = -\frac{y}{a} + \frac{1-y}{1-a} $$ Unfortunately, he doesn't give any clues as to how this can be derived. Does anyone here know how to derive this partial derivative given the equations above? I'd be very grateful for any insights others can offer on this question!","['derivatives', 'logistic-regression', 'partial-derivative', 'calculus']"
2585992,Prove vector space is the direct sum of subspace and its orthogonal complement,"$V$ is finite-dimensional over $\Bbb{C}$ and the form $\langle \cdot , \cdot \rangle$ is Hermitian. $U$ is a subspace of $V$ . Show that $V = U \oplus U^\perp$ I've been able to show that $U \cap U^\perp = \{0\}$ . I don't know how to approach the problem showing that every vector $v\in V$ can be written as $v = u + u'$ , where $u, u'$ are in $U$ and $U^\perp$ respectively.","['direct-sum', 'bilinear-form', 'inner-products', 'linear-algebra', 'vector-spaces']"
2586022,Show that$\sum_{r\text{ odd}}^n r {n \choose r} = n2^{n-2}$,"I want to show that $\displaystyle \sum_{r\text{ odd}}^n r {n \choose r} = n2^{n-2}$ while $r$ is odd. I have been able to show that:
$\sum_{r=0}^n r {n \choose r} = n2^{n-1}$ for all indices. How can I go from the second expression to the first. Any help would be appreciated.","['combinatorics', 'binomial-coefficients', 'discrete-mathematics']"
2586057,Difficulty with the multivariate chain rule,"I am having a minor issue with the chain rule. I remember its properties but I just cannot quite remember if I am doing it correctly. If someone could just check if this identity is correct that would be great. It is the last thing I appealed to in a proof Ive been working on for leisure and I want to make sure I don't embarrass myself by rememvering wrong. $(f(g(x),h(x)))' = f'(g(x),h(x)) * g'(x) + f'(g(x),h(x)) * h'(x)$ I know that each derivative of $f$ in above is the partial derivative with respect to each argument, but is that right? I just want to make sure I am not forgetting something vital.","['multivariable-calculus', 'chain-rule']"
2586091,"$55$ gangsters shoot the nearest gangster to them, where all the distances between them are different. Prove that at least one gangster will survive.","My thinking was that if gangster A shoots gangster B, then gangster B will also shoot gangster A since they are the closest together, forming a pair. Since 55 is odd, then one must survive since 55 is 1 mod 2. P.S The question assumes the following : If distance from any gangster A to any gangster B is x then distance from gangster B to gangster A is also x. No gangster commits suicide.","['puzzle', 'combinatorics']"
2586153,Why does $\lvert x^2 \rvert < 16$ imply $\lvert x \rvert < 4$?,"Suppose I have something like $\lvert x^2 \rvert < 16$. The properties of absolute value state that $\lvert x^2 \rvert = \lvert x \rvert^2$. While this makes sense, I'm having trouble understanding the rather basic fact that this would imply that $\lvert x \rvert < 4$. Does this follow from simply taking the principal root of both sides, if that's even a valid step? I guess I'm not seeing how we wouldn't end up with something like $\pm \lvert x \rvert < \pm 4$. In other words, what it is that allows us to drop the $\pm$ symbol? My apologies if this is really basic. (I think the tag I've used here is appropriate for this reason.) I would appreciate any help on this.","['algebra-precalculus', 'absolute-value']"
2586214,Why the infinity of prime numbers can be proved topologically?,"I was reading Proofs from THE BOOK by Martin Aigner, Günter M. Ziegler and was very impressed by the following proof of infinity of prime numbers with topology: Edit: The proof can also be found here . Though I understand every step of this proof logically, I still find using topology to prove this classical result in Number Theory amazing. I wonder why there is a topological proof to the infinity of prime numbers. What is the intuition that motives this proof? Are there any topological proofs to other famous results in other fields of mathematics?","['intuition', 'number-theory', 'proof-explanation', 'general-topology', 'prime-numbers']"
2586261,Lie algebra of a horizontal vector field and a fundamental vector field,"Let $G$ be a Lie group, $\mathfrak{g}$ be its Lie algebra, $(P,M,G)$ be a principal $G$ bundle with connection $\omega$. By a horizontal vector field on $P$, we mean a vector field $X:P\rightarrow TP$ such that $X(p)\in T_pP$ is actually a horizontal vector for each $p\in P$. Given an element $A\in \mathfrak{g}$ we define a vector field on $P$, calling it fundamental vector field associated to $A$, as $X(p)=(R_p)_{*,e}(A)$ where $R_p:G\rightarrow P$ is defined as $g\mapsto pg$. Just to emphasise it’s relation with $A$ we denote it by $A^*$. Now the question is to prove that if $X$ is a horizontal vector field on $P$ and $A^*$ is a fundamental vector field associated to $A$, then the Lie brakcte$[X,A^*]$ is a horizontal vector field. I do not really understand how can one check something is a horizontal vector field. There is a proof which uses the notion of lie derivative relation with lie bracket. I am getting confused with that. Are there any other methods to prove this..?","['principal-bundles', 'vector-fields', 'differential-geometry', 'connections']"
2586280,Evaluation of limiting value of given series,"For a given sequence,  $a_1=1$ and $a_n=n(1+a_{n-1})$ $\forall n\geq 2$, then value of given limit: $$\lim_{n\to \infty} \bigg(1+\frac{1}{a_1}\bigg)\bigg(1+\frac{1}{a_2}\bigg)\cdots\bigg(1+\frac{1}{a_n}\bigg)$$ Usually such type of questions are solved by squeeze theorem or by converting them into definite integral but don't see neither working here. Could someone give me little help to proceed","['calculus', 'limits']"
2586287,Gaps between numbers on the real number line,"I was reading a book called Calculus Basic Concepts for High Schools , and, under the topic limit, it was discussed that one cannot have two limits for a given sequence, provided the sequence has a limit. And the immediate implication of this is that there cannot be a neighboring number because one can always find a number between any selected numbers; however, close they may be. So in an open interval $(a,b)$, one cannot find the largest number. I want someone to elaborate on this piece of text from ""Calculus Basic Concepts for High Schools: L. V. Tarasov"": However, if there were a point
  neighboring 1, after the removal of the latter this ""neighbor""
  would have become the largest number. I would like
  to note here that many ""delicate"" points and many ""secrets""
  in the calculus theorems are ultimately associated with the
  impossibility of identifying two neighboring points on the
  real line, or of specifying the greatest or least number on an
  open interval of the real line. What would happen if we can find a neighboring number? How is calculus associated with the impossibility of identifying two
neighboring points on the real line?","['real-numbers', 'sequences-and-series', 'calculus', 'limits']"
2586298,image of parametric quadratic curve with three components contained in a plane,"I am studying Differential geometry I tried to prove this by taking all three components as quadratic with $t$ as a parameter but could not be successful. If all three component functions of a space curve $\gamma$ are quadratic functions, prove that the image of $\gamma$ is contained in a plane.","['curves', 'differential-geometry', 'plane-curves']"
2586326,Finding the differential equation given certain solutions,"I'm stuck at this exercise of my notes: Find the differential equation that has the solutions: $$\phi_1= e^{2t}
(13\cos{t}, −26\sin{ t}, −26 \sin {t})$$
  $$\phi_2= 7e^{2t}(−2 \cos{t} − 3 \sin {t}, −6 \cos{t} + 4 \sin {t}, −6 \cos{t} + 4 \sin {t}) + 2e^{−3t}(7, 8, 34)$$
  $$\phi_3=e^{2t}(\sin {t}, 2 \cos{t}, 2 \cos{t})$$ It's the first exercise on my notes like this. How do we usually attack this kind of exercises? What's the procedure to follow?","['derivatives', 'ordinary-differential-equations', 'curves', 'calculus']"
2586360,How can I solve this partial differential equation? Wolfram alpha can't interpret it right.,"I stumbled upon a differential equation which I do not know how to solve but would love to know the answer. I tried plugging it in wolfram alpha but it didn't help. For some reason WA wasn't interpreting it right. $$ \frac{ \partial y}{\partial x} \bigg( { \frac{\partial^2 y}{\partial \epsilon \partial x}\bigg) } = 0 $$ I am looking for $y(x, \epsilon)$ with these conditions:
$$\frac{\partial y}{\partial x} {(0, \epsilon)} = 0$$
$$y(x, \epsilon_0) = y(x, -\epsilon_0) = h$$
where $h \in \mathbb{R}_{>0}$ If not analytical, can someone at least give me a hint as to what the numerical solution would like so that I know, intuitively, if this model is right.","['multivariable-calculus', 'partial-derivative', 'partial-differential-equations']"
2586363,"In a square ABCD with side 14cm, 2 quadrants were made with centres A & B respectively and AB as radius. Find area of region I and II",https://photos.app.goo.gl/5ibXDN5u6s0yo6KB3 I could do the following: II + III = $\frac{1}{4}$ × $π$ × $14^2$ = $49π$ = $154cm^2$ II + IV = $\frac{1}{4}$ × $π$ × $14^2$ = $49π = 154 cm^2$ Area of square = $I + II + III + IV$ = $14^2 = 196 cm^2$ $(I + II + III +।V ) - ((II + III) + (II + IV)) = 196 - (154 + 154) = -112$ $\mapsto$ I - II = -112 $\mapsto$ II - I = 112 Am I going on the correct path?,"['area', 'algebraic-geometry']"
2586375,$xy' + 1 = e^{x-y}$,I need help solving this differential equation $xy' + 1 = e^{x-y}$ I wrote this as $xe^ydy = (e^x-e^y)dx$ and tried finding integrating factor but unsuccessfully. Any help will be much appreciated. I found this problem from entrance exam for some university,['ordinary-differential-equations']
2586429,"Given a set $A \subseteq \{1,2,3...150\}$ such that $|A|=25$. Prove there are $a,b,c,d\in A$ satisfying $a+b=c+d$","Given a set $A \subseteq \{1,2,3...150\}$ such that $|A|=25$. Prove using Pigeonhole Principle there are 4 different elements $a,b,c,d\in A$ satisfying $a+b=c+d$ A direction or hint would be appreciated.","['combinatorics', 'pigeonhole-principle', 'discrete-mathematics']"
2586493,Normalizer of subnormal subgroup. Problem 2.A.9 from FGT by Isaacs,"I try to solve problem 2.A.9 from M. Isaacs Finite Group Theory (FGT). I give it here. Let $G$ be a finite group and $\pi$ be a set of primes. Let $H$ be a subnormal subgroup of $G$ and assume that
  $H=O^{\pi}(H)$, where $\pi$ is the set of primes. Show that
  $O_{\pi}(G)$ normalizes $H$. I explain the notations. $O^{\pi}(H)$ is the smallest normal subgroup of $H$ such that $H/O^{\pi}(H)$ is a $\pi$-group (that is every prime, which divide the order of the group $H/O^{\pi}(H)$) is contained in $\pi$). $O_{\pi}(G)$ is the largest normal  $\pi$-subgroup of $G$. I try to use the standard approach using induction on $|G|$. But this does not lead to success. Maybe there is another approach in this problem?","['finite-groups', 'abstract-algebra', 'normal-subgroups', 'group-theory']"
2586517,"How to prove $L(s, \chi_0 \chi^*) = 0$ if and only if $L(s, \chi^*) = 0$?","Let $\chi$ be a Dirichlet character modulo $q$ and 
suppose $\chi = \chi_0 \chi^*$ where $\chi_0$ is the principal character mod $q$ and $\chi^*$ is the primitive character inducing $\chi$. I am wondering how can one prove that  $L(s, \chi) = 0$ if and only if  $L(s, \chi^*) = 0$? (I am only interested in $s$ in the critical strip)
Any comments are appreciated. Thank you very much.","['number-theory', 'complex-analysis', 'dirichlet-series']"
2586584,a range of an operator from $l^p$ to $l^p$,"Let T be an operator $T:l^2→l^2$ defined by $T(x_n )=x_n/(n^2+1)$ , then the range of this operator is not closed ..
Iam trying to find a sequence in $l^2$  under $T$ which its limit is not in $l^2$ ..
My attempt is as the following:
Let $(x_n )=(1,1,1,…,1,0,0,0,..)$ then $(x_n)$ in $l^2$ because $∑|x_n |^2=0<+∞$ 
But $T(x_n )=(1,1/5,1/10,…,0,0,0,..)$ in $l^2$ for the same previous reason 
Now Iam not sure about the next steps :
The limit of this sequence is $(1,1/5,1/10,1/17,…)$ which is not in $l^2$  is that right?","['functional-analysis', 'operator-theory']"
2586596,Vector field contour for a linear system,"Let's say $\boldsymbol{\vec F}$ is a field vector with a liner relationship $$\boldsymbol{\vec F}(\boldsymbol{\vec  x})=\boldsymbol A \boldsymbol{\vec  x}$$ where $\boldsymbol{\vec  x}$ is a vector of size $n$ and $\boldsymbol A$ is a constant $n\times n$ square matrix. For a given point $\boldsymbol{\vec  x}_0$, how can I find the hyper-surface $S(\boldsymbol{\vec  x})=0$ which crosses $\boldsymbol{\vec  x}_0$ and it is perpendicular to the vector field $\boldsymbol{\vec F}$? I believe this there is an explicit form of the surface which depends on $\boldsymbol{\vec  x}_0$ and $\boldsymbol A$. On hyper-surface $S$, there will be $n-1$ degree of freedom. I am looking for a solution for an $n$ dimension vector field. This image is just for illustration. PS. This question is a special case (linear form) of my previous question .","['vector-fields', 'matrices', 'control-theory', 'vectors', 'vector-analysis']"
2586599,"Let $G=\langle a \rangle$. Show that the generators of $G$ are of the form $a^r$ where $\gcd(r,n)=1$","Exercise : Let $G=\langle a \rangle$ be a cyclic group of order $n \in \mathbb N$ . $(i) \space $ Show that $\langle a^s\rangle = \langle a^t \rangle$ if and only if $\gcd(s,n)=\gcd(t,n)$ . $(ii)$ Using $(i)$ , show that the rest generators of $G$ are of the form $a^r$ where $\gcd(r,n)=1$ $(iii)$ Show that, for every divisor $d$ of $n$ , the group $G=\langle a \rangle$ has a unique subgroup of order $d$ and that this is the only possible subgroup of $G$ . Discussion : I have solved (correctly, I think) $(iii)$ as follows, but I'm totally stuck at $(i)$ and $(ii)$ as I don't seem to grasp how to start. There is a similar question for $(i)$ here , but do not rush to mark it as duplicate , as the solution discussed there uses the fact that is given to prove at $(iii)$ and since the exercise expects a different approach than taking advantage of the uniqueness. For $(iii)$ , I have showed the following : We are given from the hypothesis of the exercise that the order of $G$ is $n \in \mathbb N \Rightarrow |G| = n$ . Let $d$ be a divisor of $n$ . Consider $H=\{ x \in G : x^d =1 \}$ . Then $H$ is a subgroup of $G$ and $H$ contains all elements of $G$ that have order $d$ . If $K$ is a subgroup of $G$ of order $d$ , then $K$ is cyclic, generated by an element of order $d$ . Hence, $K\subseteq H$ . On the other hand, $x\in H$ iff $x=α^k$ with $0\le k < n$ and $α^{kd}=1$ , where $α$ is a generator of $G$ as mentioned at the hypothesis. Hence, $kd=nt$ and so $k=(n/d) t$ . The restriction $0\le k<n$ implies $0\le t<d$ , and so $H$ has exactly $d$ elements. Therefore, $K=H$ . Question/Discussion : I would really appreciate if someone could lead me through $(i)$ and $(ii)$ since I don't seem to grasp how to approach them. Please correct me if I approached $(iii)$ wrongly though. I'm a beginner on our abstract algebra courses, so I'm sorry if this is considered an easy exercise.","['number-theory', 'abstract-algebra', 'elementary-number-theory']"
2586601,Let $\{f_n\}^\infty_{n=1}$ be a sequence of continuous real valued functions defined on $\mathbb{R}$,"Let $\{f_n\}^\infty_{n=1}$  be a sequence of continuous real valued functions defined on $\mathbb{R}$ which converges pointwise to a continuous real valued function $f$. d Which of the following statements are true? a. If $0\le f_n \le f$ for all $n\in \mathbb{N}$, then $$\lim_{n\to \infty} \int_\infty^{-\infty} f_n(t)\,dt=\int_\infty^{-\infty } f(t) \, dt$$ b. If $|f_n(t)|\le |\sin t|$ for all $t\in \mathbb{R}$ and for all $n\in \mathbb{N}$, then 
 $$\lim_{n\to \infty} \int_\infty^{-\infty } f_n(t) \, dt=\int_\infty ^{-\infty } f(t) \, dt$$ c. If $|f_n(t)|\le e^t$ for all $t\in \mathbb{R}$ and for all $n\in \mathbb{N}$, then for all $a,b \in \mathbb{R}$ . $a<b$ $$\lim_{n\to \infty} \int_b^a f_n(t) \, dt=\int_b^a f(t) \, dt$$ since sequence of continuous real valued functions defined on $\mathbb{R}$ which converges pointwise to a continuous real valued function $f$ so 1 is true (but ia m not sure) can you hlep me with other options too..thank you","['uniform-continuity', 'real-analysis', 'sequences-and-series', 'uniform-convergence']"
2586620,Curves of arithmetic genus $1$,"If $C$ is a projective integral curve over $\mathbb C$, suppose its arithmetic genus $p_a(C)=1$, then what kind of curve $C$ could be? According to Hartshorn Ex. 1.8 page 298, if $\tilde C \to C$ is the normalization, then $p_a(\tilde C)+\delta = p_a(C)=1$, hence either $C$ is an elliptic curve or $\tilde C = \mathbb P^1$ and $\delta =1$. Ex. 1.8 (c) claims that node or cusp will have $\delta=1$. It seems that these are the only possibilities, but why?","['algebraic-curves', 'elliptic-curves', 'algebraic-geometry']"
2586625,Does the set $S=\{x\mid x\in S\}$ exist?,"Consider the set $$S=\{x\mid x\in S\}.$$ For every element $x$, either $x\in S$ or $x\not\in S.$ If we know that $x$ is in fact element of $S$, then, by definition, $x\in S$ so it is true that $x\in S$. If we know that $x\not\in S$, then, by definition, $x\not\in S$ so it is true that $x\not\in S$. But if my question is what elements does $S$ contain, then the answer is ""not certain.""",['elementary-set-theory']
2586660,Is 2018 special because of these properties?,"I discovered that: $$2018=(6^2)^2+(5^2)^2+(3^2)^2+(2^2)^2$$
We also have:  $$13^2+43^2=2018$$ And we have: $$2018=44^2+9^2+1^2$$ I somehow tend to believe that there could be a finite number of these numbers that are sum of two squares, three squares and four fourth powers. So we have a system of three Diophantine equations: $$n=a^2+b^2$$ and $$n=c^2+d^2+e^2$$ and $$n=f^4+g^4+h^4+i^4$$ where, $n,a,b,c,d,e,f,g,h,i \in \mathbb N$. Is there a finite number of these numbers? Edit : Also, it is $$2018=35^2+26^2+8^2+7^2+2^2$$ a sum of five squares. And of $$2018=11^3+7^3+7^3+1^3$$ four cubes.","['number-theory', 'diophantine-equations']"
2586679,Finite collection of Lipschitz functions.,"Let $I=\{1,...,n\}$, $\{f_i\}_{i\in I},f_i:\mathbb{R}\rightarrow\mathbb{R},\forall i$, $a>0$. Assume:
$$|f_i(x)-f_i(y)|\leq a|x-y|,\forall x,y\in \mathbb{R},i\in I.$$
Put: $$f(z)=\max_{i\in I}f_i(z),\forall z\in \mathbb{R}$$ Can we have that: $$|f(x)-f(y)|\leq a|x-y|,\forall x,y\in \mathbb{R}.$$","['functional-analysis', 'real-analysis', 'analysis', 'functions']"
2586714,How did operations on elliptic curves appear naturally in math history?,"I understand the basic operations on elliptic curves (e.g. points on $y^2 = x^3+7$, point at infinity, addition, multiplication, etc.). I also see how it can be used for cryptography, based on the fact that given $G$ and $K=k*G$, it's very difficult to inverse the multiplication and recover $k$. But here is the question: How did mathematicians first get the idea of looking at the points on such curves $y^2 = a x^3+b$, and above all, how did they get the idea of defining such an exotic addition? (i.e. drawing a line from $P_1$ and $P_2$, then take the intersetion with the curve, then reflect in the x-axis , why this?). (I understand that with this definition, it allows to have an associative addition, and a group, but how did this appear?) How did this suddenly appear as an interesting math object to study, with such a non-obvious addition?","['number-theory', 'math-history', 'elliptic-curves', 'group-theory']"
2586734,Integral of the function $ (1+|x|^2)^{-k}$,"I want to prove that the $$\int _{ { R }^{ n } }{ \frac { 1 }{ { (1+{ |x| }^{ 2 }) }^{ k } }  } <\infty $$ if $k>\frac n 2$; where |x| is the usual norm in ${R}^{n}$. I tried this: $$\int _{ { R }^{ n } }{ \frac { 1 }{ { (1+{ |x| }^{ 2 }) }^{ k } }  }=\int _{ { R }^{ n }-{ B }_{ 1 }(0) }{ \frac { 1 }{ { (1+{ |x| }^{ 2 }) }^{ k } }  } + \int _{ { B }_{ 1 }(0) }{ \frac { 1 }{ { (1+{ |x| }^{ 2 }) }^{ k } }  } $$ where ${ B }_{ 1 }(0)$ is the unit ball, the second term of the sum is finite since $$\int _{ { B }_{ 1 }(0) }{ \frac { 1 }{ { (1+{ |x| }^{ 2 }) }^{ k } }  } \le \int _{ { B }_{ 1 }(0) }{ \frac { 1 }{ { ({ |x| }^{ 2 }) }^{ k } }  }<\infty $$ if $k>\frac n 2$ but i do not know how to estimate the first term of the sum, any idea?","['real-analysis', 'polar-coordinates', 'calculus', 'multivariable-calculus', 'integration']"
2586742,Formation of Six Letter Strings that Conform to Specific Criterias - Combination Theory,"Problem: How many strings of 6 characters can you create that starts and ends with the same letter (eg: ""ANDREA""), reads equally forward as well as backward (eg: Consider that you are working with the capital letters of the English alphabet). From what I understand, for these conditions to be met, the first three and last three letters will have to be the same and the permutations of the first three letters will be equal to that of the last three. Did I miss anything? But I am not sure how to determine the combination. Can someone help me to better understand and resolve this problem?","['permutations', 'combinatorics', 'discrete-mathematics']"
2586747,Evaluate lim$_{n\rightarrow\infty}$ $\frac{1-2+3-4+5-...............+\left(-2n\right)}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}$ [duplicate],"This question already has answers here : Compute: $\lim_{n \rightarrow \infty}\sqrt{n}(A_{n+1} − A_n)$ where $A_n = \frac{1}{n}(a_1 + a_2 + \cdots + a_n)$ (2 answers) Closed 5 years ago . Evaluate $$\lim_{n\rightarrow\infty}\frac{1-2+3-4+5-\cdots+\left(-2n\right)}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}.$$ My Approach Let $A_{n}=1+3+5+\cdots\left(2n-1\right)$ and $B_{n}=2+4+6+\cdots\left(2n\right)$, then $A_n=\frac{n}{2}\left(1+2n-1\right)=n^{2}$
and
$B_{n}=\frac{n}{2}\left(2+2n\right)=n+n^{2}$.
Therefore,
$$\lim_{n\rightarrow\infty}\frac{A_{n}-B_{n}}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}=\lim_{n\rightarrow\infty}\frac{-n}{\sqrt{n^{2}+1}+\sqrt{n^{2}-1}}=-\frac{1}{2}.$$
But the book mentions that the answer is $0$.","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'limits']"
2586755,Distribution continuity of an AR(1) process,"Let $\epsilon_n$ be i.i.d. random variables with mean $0$ and finite positive variance. Let $X=\sum_{k=0}^\infty \rho^k \epsilon_k$, where $0<|\rho|<1$. The series converges a.s. by the variance criterion. My question is: can one prove or disprove the claim $P(X=x)=0$ ($X$ has a continuous distribution)? Remark 1: The motivation comes from understanding the distribution property of the stationary solution of the AR(1) equation:
$X_n=\rho X_{n-1}+\epsilon_n$, which has the same distribution as $X$ above. Remark 2: If $\epsilon_n$ has a continuous distribution, then the claim can be shown as follows: note that $X$ has the same distribution as $\rho X+\epsilon$, where $\epsilon$ is independent of $X$ and has the same distribution as $\epsilon_n$. Then by independence (disintegration),
$$
P(X=x)=P(\rho X+\epsilon=x)=\int P(\epsilon=x-\rho u)~ dP_X(u)=0.
$$
where $P_X$ is the distribution of $X$. Remark 3: A positive example of the claim when $\epsilon_n$ is discrete: if $P(\epsilon_n=\pm 1)=1/2$, $\rho=1/2$, then it is well-known that $X$ is uniformly distributed on [-2,2].","['time-series', 'probability', 'measure-theory', 'random-variables']"
2586775,What is $\frac d{dx} (x!)$?,"Background: I was investigating the factorial function due to their importance in the binomial expansion. They play an important role in calculating the coefficients of the terms of the binomial expansion. Question: What is the derivative of the function $y = x!$ ? My (failed) attempt: I first plotted some points on a graph paper and tried to join them. I tried smoothing out the graph and then I tried to connect them with straight lines. Both techniques seemed to not work and produced something I understood was wrong as the derivative had gone beserk. Then I tried it on Desmos: https://www.desmos.com/calculator/6opi7buw86 . The graph made me want to publish an official complaint against Desmos for intentionally scamming me but thought better of it. I googled up $x!$ and learnt about the $\Gamma$ function which produced this unexplainable graph. I understand the basics of it (or so I believe) but I am not confident that I can continue this quest. Reason for posting this question: What is this $\Gamma$ function? What is the meaning of $\frac 12!$ ? How does it have a value, as well as all the other non-integer values? Especially the negative values which makes no sense to my incompetent brain. Can I use the $\Gamma$ function to find an equation for the derivative of $x!$ (or $\Gamma (x)$ for this matter)? I would prefer explanations as simple and elaborate as possible. Please excuse me for my apparent lack of knowledge. Thanks in advance! P.S. Was this question already posted? I could not find this question. Could anyone direct me to such a question (if it exists)? And please try to avoid Youtube links as I learned that they are not always true (specially Numberphile).","['factorial', 'ordinary-differential-equations', 'soft-question']"
2586848,Solving $\cos x + \cos 2x - \cos 3x = 1$ with the substitution $z = \cos x + i \sin x$,"I need to solve 
$$\cos x+\cos 2x-\cos 3x=1$$
using the substitution$$z= \cos x + i \sin x $$ I fiddled around with the first equation using the double angle formula and addition formula to get 
$$\cos^2 x+4 \sin^2x\cos x-\sin^2 x=1$$ 
which gets me pretty close to something into which I can substitute $z$, because $$z^2= \cos^2 x-\sin^2 x+2i\sin x\cos x$$ 
I have no idea where to go from there.",['trigonometry']
2586898,How to evaluate this notoriously hard exponential integral,"I am trying to evaluate the following integral
$$I = \int_{T}^{\infty} \exp\left[\beta t^{1-2H} - \gamma t^{2 - 2H} \right]t^{H-2} \log ^{\alpha}(t) \mbox{d}t$$
or alternatively if it is simpler in anyway
$$J = \int_{T}^{\infty} \exp\left[\beta t^{1-2H} - \gamma t^{2 - 2H} \right]t^{H-2} \left[(1-H) \log ^{\alpha}(t) - \alpha \log ^{\alpha - 1}(t)\right] \mbox{d}t$$
where $\alpha, \beta, \gamma$ are all non-zero constants and $H \in \left(0, 1\right)$ I have tried integrating by parts, differentiating under the integral sign (Feynman's technique), tried to substitute in $y = t^{2H}$ but have not had much luck. Another thought i had was to try complete the square which gave an additional exp term. Is there a way to compute this tricky integral. Your help is greatly appreciated. edit Upon Substituting $\log (t) = y$, I get the following representation $$\int_{e^T}^{\infty} y^{\alpha } \exp\left[\beta e^{(1-2 H) y}-\gamma  e^{(2-2 H) y}+(H-1) y\right] \mbox{d}y$$
not sure if it is much easier to work with. edit2 How about an asymptotic form for the integral, will that be easier to derive ?","['integration', 'calculus', 'probability-distributions']"
2586932,Find the MLE of a GLM,"(Note this is not an assignment, but revision for a topic from Cambridge past exam papers) I have been trying to attempt the below question, and I am struggling with part (b). For (a) it is obvious that the pmf is the same as the Bernoulli and so $$ f(y;p) = \exp\left(y\log\left(\frac{p}{1-p}\right)+\log(1-p) \right).$$ Then for (b) , the log-likelihood is given by 
$$\ell(\beta,y) = \sum_{i=1}^n \left(y_i\log\left(\frac{p_i}{1-p_i}\right)+\log(1-p_i) \right)$$ Now, $\log(\frac{p}{1-p}) = \beta^Tx \Rightarrow \log(1-p) = \log(p) - \beta^Tx$ And so, \begin{align}
\ell(\beta,y) &= \sum_{i=1}^n y_i\beta^Tx_i + \sum_{i=1}^n \log(p) - \sum_{i=1}^n \beta^Tx_i\\
&= \sum_{i=1}^n y_i\beta^Tx_i + \sum_{i=1}^n \log\left(\frac{e^{\beta^Tx}}{1+e^{\beta^Tx}}\right) - \sum_{i=1}^n \beta^Tx_i
\end{align} And i am unsure how to deal with this middle term, particularly when differentiating, as i cannot get the final answer.","['logistic-regression', 'maximum-likelihood', 'statistics', 'log-likelihood', 'summation']"
2586942,Choosing diagonals in an $n$-gon,"Let $n>3$ be odd. Find the least value of $k$ such that in any convex $n$-gon, the sum of the lengths of $k$ arbitrarily chosen diagonals is at least as large as the sum of the lengths of the other unchosen diagonals. I have a bound $k\geq\left(\binom{n}{2}-n\right)-\tfrac{1}{2}(n-3)+1$. This is because we can take a ""water droplet"" shape, with $n-1$ points arranged along a semicircle, and the last point arbitrarily far away. Then effectively the only diagonals that matter are those $n-3$ diagonals joining our far away point to the others. Clearly, we need to take more than half of these $n-3$ diagonals, and this gives the claimed bound. However, I have no idea whether this bound is tight/can be improved.",['combinatorics']
2586953,Strange point lies on common tangent of 9-point circle and incircle,"Let $ABC$ be a triangle, with medial triangle $DEF$ and intouch triangle $PQR$ . Let $J$ be the midpoint of $\overline{AD}$ , and let $BJ$ meet $AP$ at $K$ . Let $X$ be the point on ray $\overrightarrow{CB}$ such that $CX=CA$ . Let the line through $K$ parallel to $BC$ meet $AX$ at $U$ . Let $RU$ meet $BC$ at $T$ . Prove that $T$ lies on the common tangent of the nine-point circle and the incircle of $\triangle ABC$ . I have a proof with barycentric coordinates. We can compute $K=(2(s-b):s-c:s-b)$ , $X=(0:b:a-b)$ , $U=(a-b+c:b:a-b)$ and $T=(0:a-c:a-b)$ . The common tangent of the nine-point circle and incircle has equation $$(a-b)(a-c)x+(b-c)(b-a)y+(b-c)(a-c)z=0,$$ and the result follows. However, as you might guess, I'm interested in a synthetic solution to this problem.","['euclidean-geometry', 'geometry']"
2586964,"Exercise 2 from Terry Tao's blog on Euler-Maclaurin, Bernouilli numbers, and the zeta function","In the blog post The Euler-Maclaurin formula, Bernoulli numbers, the zeta function, and real-variable analytic continuation , Terry Tao looks at the commonly-cranked 'absurd' formulae
$$\begin{align}
\sum_{n \geq 1} 1 &= -1/2 \tag{1} \\
\sum_{n \geq 1} n &= -1/12 \tag{2},
\end{align}$$
where of course I do not intend these to be taken literally. These are the correct values if we interpret the left sums as $\zeta(0)$ and $\zeta(-1)$, extended through analytic continuation. But one of the big points of Terry Tao's blog post is to show that one can approach $(1)$ and $(2)$ from a completely real-variable method involving smoothed sums. Let $\eta: \mathbb{R}^+ \longrightarrow \mathbb{R}$ be a smooth, compactly supported, bounded cutoff function which is $1$ in a neighborhood of $0$. Corresponding to $(1)$ and $(2)$ are
$$\begin{align}
\sum_{n \geq 1} 1 \cdot \eta(n/N) &= -\frac{1}{2} + C_{\eta, 0} N + O\big(\frac{1}{N}\big) \tag{3} \\
\sum_{n \geq 1} n \cdot \eta(n/N) &= - \frac{1}{12} + C_{\eta, 1} N^2 + O\big(\frac{1}{N}\big), \tag{4}
\end{align}$$
where
$$ \zeta_{\eta, j} = \int_0^\infty x^j \eta(x) dx.$$ In the blog post, Exercise 2 concerns resolving an 'apparent inconsistency' in $(1)$ and $(2)$. Adding $(1)$ and $(2)$ (formally) shows that $\sum_{n \geq 1} (1+n) = -7/12$. Subtracting the integer $1$ from $(2)$ shows (formally) that $\sum_{n \geq 2} n = \sum_{n \geq 1} (1+n) = -13/12$. Working with the smoothed sums, adding $(3)$ and $(4)$ shows that
$$ \sum_{n \geq 1} (1+n) \eta(n/N) = -\frac{7}{12} +  C_{\eta, 1} N^2 + C_{\eta, 0}N + O\big( \frac{1}{N} \big). \tag{5}$$
Subtracting $1$ (or rather $\eta(1/N)$, which is $1 + O(1/N)$ from a Taylor expansion) from $(4)$ shows that
$$ \sum_{n \geq 2} n \eta(n/N) = \sum_{n \geq 1} (1+n) \eta\big( \frac{n+1}{N} \big) = -\frac{13}{12} + C_{\eta, 1} N^2 + O\big( \frac{1}{N} \big). \tag{6}$$
We see that the difference between $(5)$ and $(6)$ is entirely in the smoothing function $\eta(n/N)$ vs $\eta( \frac{n+1}{N} )$, and this is not apparent in the ""formal"" manipulation leading to the apparent inconsistency. My Question In his post, Terry Tao puts as Exercise 2 that one can use $(3)$ and the Taylor expansion for $\eta(\frac{n+1}{N})$ to derive $(6)$ from $(5)$. (Thus these are not only consistent but essentially equivalent). But I don't see how to do this. Initial thoughts towards a solution There are two ways that seem natural to expand $\eta$ in a Taylor series. We could use an expansion centered at $0$, leading to expressions of the form
$$ \eta\left( \frac{n+1}{N} \right) = 1 + \eta'(0) \left( \frac{n+1}{N} \right) + \frac{\eta''(c)}{2} \left( \frac{n+1}{N} \right)^2, \qquad c \in (0, \tfrac{n+1}{N})$$
or perhaps several expansions centered at $n/N$, leading to expressions of the form
$$ \eta \left( \frac{n+1}{N} \right) = \eta \left( \frac{n}{N} \right) + \eta' \left( \frac{n}{N} \right) \frac{1}{N} + \eta''(c) \frac{1}{N^2}, \qquad c \in (\tfrac{n}{N}, \tfrac{n+1}{N}).$$
The expansions centered at $n/N$ have many advantages. In the earlier Exercise 1 in the blog post, using Taylor expansions centered at $n/N$ led to an easy solution, so I suspect that this is the way to proceed. Further, as $\eta$ is compactly supported, we have $\eta''(c) = 0$ for large $c$. But using this Taylor expansion in the series in $(6)$, we find
$$ \sum_{n \geq 1} (1+n) \eta \left( \frac{n+1}{N} \right) = \sum_{n \geq 1} (1+n) \Big[ \eta \left( \frac{n}{N} \right) + \eta' \left( \frac{n}{N} \right) \frac{1}{N} + \eta''(c_n) \frac{1}{N^2}\Big].$$
The first terms
$$ \sum_{n \geq 1} (1+n) \eta \left( \frac{n}{N} \right)$$
are understood from $(3)$ and $(4)$ above. The error term summands are each $O(1/N)$, leading to an error term of size $O(1)$. (This indicates that one should use probably use one more term in the Taylor expansion, but that's not what I find to be the obstacle).
The secondary term is what I find confusing. We want to understand
$$ \sum_{n \geq 1} \frac{(1+n)}{N} \eta' \left( \frac{n}{N} \right),$$
but how are we to do this? I suspect there is either not much more to this line of thought, or a different line of thought is necessary.","['analytic-number-theory', 'summation-method', 'zeta-functions', 'number-theory', 'analytic-continuation']"
2587001,Understanding step in derivation of softmax function,"I'm reading Eli Bendersky's blog post that derives the softmax function and its associated loss function and am stuck on one of the first steps of the softmax function derivative [ link ]. His notation defines the softmax as follows: $$S_j = \frac{e^{a_i}}{ \sum_{k=1}^{N} e^{a_k} } $$ He then goes on to start the derivative: $$ \frac{\partial S_i}{\partial a_j} = \frac{ \partial \frac{e^{a_i} }{ \sum_{k=1}^N e^{a_k}} } {\partial a_j} $$ Here we are computing the derivative with respect to the $i$th output and the $j$th input. Because the numerator involves a quotient, he says one must apply the quotient rule from calculus: $$ f(x) = \frac{g(x)}{h(x)} $$
$$ f'(x) = \frac{ g'(x)h(x) - h'(x)g(x) } { (h(x))^2 } $$ In the case of the $S_j$ equations above: $$ g_i = e^{a_i} $$
$$ h_i = \sum_{k=1}^N e^{a_k} $$ So far so good. Here's where I get confused. He then says: ""Note that no matter which $a_j$ we compute the derivative of $h_i$ for, the answer will always be $e^{a_j}$"". If anyone could help me see why this is the case, I'd be very grateful.","['derivatives', 'partial-derivative', 'calculus']"
2587045,Analytical Way of Estimating Sums of Floor Functions,"Hi Math Stack Exchange, I'm working on a problem that involves the difference between a sum series of floor functions. I have tried taking the more standard number theory approach by looking at remainder classes and modular arithmetic but haven't had real success so I'm hoping to take an analytical approach and was looking for help. Let, $$f(L) = \sum_{k=2}^{\frac{L}{2}}{\lfloor{\frac{L}{k}}\rfloor}$$ and $$\Delta(c,L) = f(L+c) - f(L) = \sum_{k=2}^{\frac{L}{2}}{\lfloor{\frac{L+c}{k}\rfloor - \lfloor\frac{L}{k}}\rfloor}$$ For the problem we can assume c is an integer and is very very small in comparison to L. So given the above equations I have a couple questions and any help on any of them would be great! 1) Does there already exist a quick identity for f(L) or $\Delta(c,L)$? 2) If there doesn't exist a nice identity, is there an analytical way to estimate f(L) or $\Delta(c,L)$ or approximate them? Thank you guys for taking the time to look over this!","['real-analysis', 'analytic-number-theory', 'divisor-counting-function', 'number-theory', 'ceiling-and-floor-functions']"
2587047,Is the following a group for all topologies?,"Let $\mathcal{T}$ be a topology on $X$ and let $S$ be the set of all self-homeomorphisms on $X$. Let $\sim$ be an equivalence relation defined on S as follows: $a\sim b$ iff there exists $f:[0,1]\to S$ such that: $f(0) = a, f(1) = b(f(r))(x)$ is a continuous function of $r$ from $[0,1]$ to $X$ for each $x\in X.$ What this should amount to is that two self-homeomorphisms are equivalent iff you can continuously deform one into the other. For example: All strictly increasing continuous bijections from R to R are equivalent All strictly decreasing continuous bijections from R to R are equivalent No strictly increasing continuous bijection is equivalent to any strictly decreasing bijection. Let P be the set of all equivalences classes on S resulting from the equivalence relation $~$. Let a binary operation $*$ be defined as follows: $[a]*[b] = [a \circ b]$ for $a,b \in S$. Let $G$ be the group on $P$ with binary operation $*$. First, I would like to know if $*$ is well defined for all topologies $\mathcal T$. If so, then $G$ is a group for all topologies $\mathcal T$. (If you could provide a proof that $*$ is well defined or direct me to one that would be great as well) Second, if $*$ is well defined, is there a name for this group resulting from a given topology? Third, if $*$ is well defined then I would like to know the following: Does there exist a homogeneous connected topology $\mathcal T$ that results in a group other than $\mathbb Z_2$ or $\mathbb Z_1$ ? If so please give a specific example. The essence of this question is that any euclidean space can be ""turned inside out"" in a sense. For example, $\mathbb R$ with the euclidean metric can be stretched in various ways but never continuously deformed so that it has been ""flipped around"". I'd like to generalize this idea to all topologies and capture this behaviour as a group. Or course if there is a name for this sort of thing I would like to know. Also the reason I specifically ask for group other than $\mathbb Z_2$ or $\mathbb Z_1$ for a homogeneous topology is because if you don't require homogeneity you can easily construct examples. For example the following topology results in the symmetric group on 4 elements: $X$ is a subset of $\mathbb R^2$ such that $X = \{(0,a):a \in \mathbb R\} \cup \{(a,0):a \in \mathbb R\}$ and
$\mathcal T$ is the topology induced by the euclidean metric on $X$. Great thanks to all of you, I do believe the mapping class group is what I am looking for.","['general-topology', 'group-theory']"
2587059,How to find the third coordinate of a triangle with specific conditions,"I am writing a physics paper relating the motion of objects using Loedel diagrams and standard trigonometry. I am attempting to prove that an object's velocity can be found by using a specific type of triangle, and it has led me to this problem for which I need assistance: Using a standard Cartesian coordinate system, and for a given triangle $abc$, with angles $A,B,C$, where $a$ is opposite to $A$, $b$ opposite $B$, and $c$ opposite $C$: If side $c$ of the triangle is bounded at coordinates $(0,0)$ and $(1,0)$, and angles $A$ and $B$ are acute angles, then: Find the equation for the $x$- and $y$-coordinates of the third point of the triangle such that for any given angle $A$, $a = h/b$, where $h$ is the height of the triangle, and therefore: $$\sin A = a$$","['trigonometry', 'geometry']"
2587081,Find the nth derivative,"Find the $n$th derivative of the function 
  $$y=\ln(ax+b).$$ I have computed the following derivatives:
$$y'=\frac{a}{ax+b}$$
$$y''=\frac{-a^2}{(ax+b)^2}$$
$$y'''=\frac{2a^3}{(ax+b)^3}$$
I think
$$y^{(n)}=\frac{(-1)^n c a^n}{(ax+b)^n}$$
But I could not determine the pattern for the constant $c$
How can I determine it?","['derivatives', 'calculus']"
2587085,"Minimal Sufficient statistic for Uniform($\theta, \theta+1$)","We have that $\mathbf{X}$ is a random sample from Uniform$(\theta, \theta+1)$ and we want to find a sufficient statistic for $\theta$ and the determine whether it is minimal. The likelihood function is given by $$ L(\mathbf{x}| \theta) =  \prod \mathbf{1} [ \theta < x_i < \theta+1] = \mathbf{1} [\min (\mathbf{x}) > \theta] \mathbf{1} [\max (\mathbf{x}) < \theta+1]$$ so that by Neyman-Pearson factorization theorem, $T(\mathbf{X}) = (m,M)$ where $m := m (\mathbf{X})$ and $M := M(\mathbf{X})$ are the minimum and the maximum of $\mathbf{X}$, respectively. Now we want to determine whether the statistic is minimal. Despite the rule of thumb, (that if the dimension of the statistic is greater than the dimension of the parameter, then the statistic is not minimal), I have the hunch that the statistic is actually minimal. So we proceed by definition: A statistic $T$ is minimal sufficient if the ratio $f_θ(x)/f_θ(y)$ does not depend on $\theta$ if and only if $T(x) = T(y)$. In order to skirt any indeterminacy problems, we can take the first condition to be $f_\theta (x) = k(x,y) f_\theta (y)$. It is here that I get stuck.",['statistics']
2587106,Confusion with definition of foliation,"Below is the definition of foliation of a manifold appearing in the book Introduction to Foliations and Lie Groupoids by Moerdijk and Mrčun. Definition 1. Let $M$ be a smooth manifold of dimension $n$. A foliation atlas of codimension $m$ of $M$ is an atlas $$(\varphi_i:U_i\to \mathbb R^n\cong \mathbb R^{n-m}\times \mathbb
 R^m)_i$$ of $M$ for which the change-of-charts diffeomorphisms
  $\varphi_{ij}$ are locally of the form
  $$\varphi_{ij}(x,y)=(g_{ij}(x,y),h_{ij}(y))$$ with respect to the
  decomposition $\mathbb R^n\cong \mathbb R^{n-m}\times \mathbb R^m$. I am confused by this definition. Question 1. I don't understand why $h_{ij}$ need not be the identity - don't we want the hyperplane at height $y$ to map into itself? In the book Geometric Theory of Foliations by Camacho and Neto, §1 begins by considering the usual submersion $\mathbb R^n\to \mathbb R^m$ and then writing: The diffeomorphisms [...] which preserve the leaves of this foliation locally have the following form $$\varphi_{ij}(x,y)=(g_{ij}(x,y),h_{ij}(y)).$$ However Figure 1 seems to suppose $\varphi_{ij}$ does map the horizontal line at height $y$ into itself, which would make $h_{ij}$ the identity. From a formal perspective, the reasonable condition to ask seems to be the commutativity of the triangle with broken sides below, where the broken arrows are defined by composites of the obtuse triangles. Using the universal property of the product commutativity then implies $\varphi_{ij}=(g_{ij},\pi_2|_{\varphi_iU_{ij}})$, making $h_{ij}$ the identity as expected. Let $(U_i)$ be an open cover of $M$ and consider a family of bundles $(\begin{smallmatrix}L_i\\
\downarrow\\
U_i\end{smallmatrix})$. Recall that descent data for the family $(\begin{smallmatrix}L_i\\
\downarrow\\
U_i\end{smallmatrix})$ consists of transition isomorphisms $\varphi_{ij}:\begin{smallmatrix}L_j\\
\downarrow\\
U_j\end{smallmatrix}|_{U_{ij}}\cong \begin{smallmatrix}L_i\\
\downarrow\\
U_i\end{smallmatrix}|_{U_{ij}}$ satisfying the cocycle condition. Recall also the existence of a bundle over $M$ pulling back to the family $(\begin{smallmatrix}L_i\\
\downarrow\\
U_i\end{smallmatrix})$ is equivalent (at least in the topological case) to the existence of descent data for this family. It seems the above definition of foliation is very closely related to the specification of descent data. Moreover, a foliation can be viewed as a smooth bijection $L\to M$ from the leaf manifold, and I feel the leaf manifold should perhaps by obtained using the usual gluing construction of bundles using descent data. Question 2. What is the descent data and the family of bundles here and how do they give rise to the smooth bijection from the leaf manifold $L\to M$? Added. Following Eric Wofsey's answer, here's the correct diagram (generally not commutative).","['descent', 'smooth-manifolds', 'foliations', 'manifolds', 'differential-geometry']"
2587124,"I believe this problem has a typo, but I want to make sure before telling my teacher. Does it?","An amphitheater charges $74$ dollars for each seat in Section A, $59$ dollars for each seat in Section B, and $28$ dollars for each lawn seat. There are three times as many seats in Section B as in Section A. The revenue from selling all $13,000$ seats is $\$503,000$. Let $x$ be the number of seats in A, $y$ be the number of seats in B, and $z$ be the number of lawn seats. Which system of equations represents the situation? There are 2 answers to the question, the problem is multiple choice. The first answer is below: $$y=3x$$ $$x+y+z=503,000$$ $$74x+59y+28z=13,000$$ The second: $$y=3x$$ $$x+y+z=13,000$$ $$74x+59y+28z=503,000$$ Wouldn't the correct answer be: $$x=3y$$ $$x+y+z=13,000$$ $$74x+59y+28z=503,00$$",['algebra-precalculus']
2587140,When will open morphisms be flat?,"In this MSE answer adapted from this answer the infinitesimal extension $\Bbbk[\varepsilon]\to \Bbbk$ is given as an example of an open morphism which is not flat. Are all open non-flat morphisms ""of this kind"" i.e fail because of
square-zero ideals somewhere? Why? If not, what are some geometric examples of open maps non-flat morphisms of a different nature? What are some criteria making open morphisms flat apart from 'being
an immersion'?","['schemes', 'affine-schemes', 'algebraic-geometry', 'flatness']"
2587153,"If $A\thicksim B$ and $C\thicksim D$, then $^{A}C\thicksim$ $^{B}D$.","Is the following proof Correct? SOME PRELIMARY NOTATION $A\thicksim B\Leftrightarrow$ There is a bijection from A to B $5.3.2$ - if $f:A\to B$ and $f^{-1}:B\to A$ then $f\circ f^{-1} = i_B = \{(x,x)| x\in B\}$ and $f\circ f^{-1} =i_A=\{(y,y)|y\in A\}$ Theorem. For any sets $A$ and $B$ let $^{A}B$ denote the set of all functions from $A$ to $B$. If $A\thicksim B$ and $C\thicksim D$, then $^{A}C\thicksim$ $^{B}D$. Proof. Assume that $A\thicksim B$ and $C\thicksim D$ consequently we invoke the existence $h_1:A\to B$ and $h_2:C\to D$ such that $h_1$ is a bijection from $A$ to $B$ and $h_2$ is a bijection from $C$ to $D$. We know define the the function $\mathcal{Z}:^{A}C\to$ $^{B}D$ and show that is a bijection from $^{A}C$ to $^{B}D$.
$$\mathcal{Z}(f) = h_2\circ f\circ h_1^{-1}$$ Now let $f_1$ and $f_2$ be arbitrary functions in $^{A}C$ and assume that $\mathcal{Z}(f_1) = \mathcal{Z}(f_2)$ consequently $h_2\circ f_1\circ h_1^{-1} = h_2\circ f_2\circ h_1^{-1}$, making use of theorem $\textbf{5.3.2}$ we have  the following equivalences.
$$\Leftrightarrow h_2\circ f_1\circ h_1^{-1} = h_2\circ f_2\circ h_1^{-1}$$
$$\Leftrightarrow h_2\circ f_1\circ (h_1^{-1}\circ h_1) = h_2\circ f_2\circ (h_1^{-1}\circ h_1)$$
$$\Leftrightarrow h_2\circ f_1\circ i_A = h_2\circ f_2\circ i_A$$
$$\Leftrightarrow h_2\circ f_1= h_2\circ f_2$$
$$\Leftrightarrow (h_2^{-1}\circ h_2)\circ f_1= (h_2^{-1}\circ h_2)\circ f_2$$
$$\Leftrightarrow i_C\circ f_1 = i_C\circ f_2$$
$$\Leftrightarrow f_1 = f_2$$
Since our choice of $f_1$ and $f_2$ was arbitrary it follows that $\mathcal{Z}(f)$ is one-to-one . Now let $g$ be an arbitrary function in $^B{D}$ and consider the function $f = h_2^{-1}\circ g\circ h_1$ consequently we see that $\mathcal{Z}(f) = h_2\circ(h_2^{-1}\circ g\circ h_1)\circ h_1^{-1}$
using associativity of function composition in conjunction with theorem $\textbf{5.3.2}$ we have the following equivalences.
$$\Leftrightarrow (h_2\circ h_2^{-1})\circ g\circ (h_1 \circ h_1^{-1})$$
$$\Leftrightarrow i_D \circ g\circ i_B$$
$$\Leftrightarrow (i_D \circ g)\circ i_B$$
$$\Leftrightarrow g\circ i_B$$
$$\Leftrightarrow g$$
Thus $\mathcal{Z}(f) = g$, since our choice of $g$ was arbitrary it follows that $\mathcal{Z}$ is onto . With this we have established that $\mathcal{Z}$ is a bijection from $^{A}C$ to $^{B}D$ consequently $^{A}C\thicksim$ $^{B}D$.","['elementary-set-theory', 'proof-verification']"
2587188,Generalizing a sequence.,"Consider a sequence of the form: $x[n]=-1,-1...,1,1,...,-1,-1...,1,1... \quad n>0$ One can think of this as a square wave ($\pm1$) with a 50 % duty cycle (coming from EE). For the simplest case of such a series i.e. $-1,+1,-1,+1,-1...$, a general equation is quite trivial ($x[n]=-1^n$). Can we have e general equation for the other cases i.e. when there are multiple $-1$'s followed by $+1$'s ?",['sequences-and-series']
2587204,How to find the number of triangles in this figure?,"What is the way to find the number of triangles in the figure below?
What is the method or logical way to derive this? I am not looking for formulas but principle that will help me to conquer other shape counting problems i.e. more complex ones?",['combinatorics']
2587245,Proof of Theorem 7 (Chapter 5) in Hoffman and Kunze's *Linear Algebra* is unclear,"Let $V$ be a free module of rank $n$ over a commutative ring $K$ with identity. We denote the space of all $r$-linear forms on $V$ by $M^r(V)$ and the space of all alternating $r$-linear forms by $\Lambda^r(V)$. For $L \in M^r(V)$ and any permutation $\sigma$ of $\{1,\dots,r\}$, we obtain another $r$-linear function $L_\sigma$ by defining $$L_\sigma(\alpha_1,\dots,\alpha_r) = L(\alpha_{\sigma 1},\dots,\alpha_{\sigma r})$$ for all $(\alpha_1,\dots,\alpha_r) \in V^r$. For each $L \in M^r(V)$, we define the alternating $r$-linear function $\pi_r L$ by $$\pi_r L = \sum_\sigma (\operatorname{sgn} \sigma) L_\sigma$$ where the sum is over all permutations $\sigma$ of $\{1,\dots,r\}$. Now, Theorem 7 of Chapter 5 in Hoffman and Kunze's Linear Algebra states the following: Theorem $7$. Let $K$ be a commutative ring with identity and let $V$ be a free $K$-module of rank $n$. If $r > n$, then $\Lambda^r(V) = \{0\}$. If $1 \leq r \leq n$, then $\Lambda^r(V)$ is a free $K$-module of rank $\binom{n}{r}$. Proof. Suppose $\{ \beta_1,\dots,\beta_n \}$ is an ordered basis for $V$ with dual basis $\{ f_1,\dots,f_n\}$. If $L \in M^r(V)$, then $$L = \sum_H L(\beta_{h_1},\dots,\beta_{h_r})\ f_{h_1}\! \otimes \dots \otimes f_{h_r} \tag{5-37}$$ where the sum extends over all $r$-tuples $H = (h_1,\dots,h_r)$ of integers between $1$ and $n$. If $L \in \Lambda^r(V)$, this sum need be extended only over the $r$-tuples $H$ for which $h_1,\dots,h_r$ are distinct because if $L$ is alternating then $$L(\beta_{h_1},\dots,\beta_{h_r}) = 0$$ whenever two subscripts $h_i$ are the same. If $r > n$ then in each $r$-tuple some integer must be repeated. Thus $\Lambda^r(V) = \{0\}$ if $r > n$. Now, suppose $1 \leq r \leq n$. We define an $r$-shuffle of $\{ 1,\dots, n\}$ to be an $r$-tuple $J = (j_1,\dots,j_r)$ such that $1 \leq j_1 < \dots < j_r \leq n$. There are $$\binom{n}{r} = \frac{n!}{r!(n-r)!}$$ such shuffles. Suppose we fix an $r$-shuffle $J$. Let $L_J$ be the sum of all the terms in $(5\text{-}37)$ for which the indexing $r$-tuple $H$ is a permutation of the $r$-shuffle $J$. If $\sigma$ is a permutation of $\{1,\dots,r\}$, then $$L(\beta_{j_{\sigma 1}},\dots,\beta_{j_{\sigma r}}) = (\operatorname{sgn} \sigma) L(\beta_{j_1},\dots,\beta_{j_r}).$$
Thus, $$L_J = L(\beta_{j_1},\dots,\beta_{j_r}) D_J \tag{5-38}$$ where $$\begin{align} D_J &= \sum_\sigma (\operatorname{sgn} \sigma)\ f_{j_{\sigma 1}}\! \otimes \dots \otimes f_{j_{\sigma r}} \tag{5-39}\\ &= \pi_r(f_{j_1}\! \otimes \dots \otimes f_{j_r}). \end{align}$$
We see from $(5\text{-}39)$ that each $D_J$ is alternating and that $$L = \sum_{\text{shuffles $J$}} L(\beta_{j_1},\dots,\beta_{j_r}) D_J \tag{5-40}$$ for every $L$ in $\Lambda^r(V)$. The assertion is that the $\binom{n}{r}$ forms $D_J$ constitute a basis for $\Lambda^r(V)$. We have seen that they span $\Lambda^r(V)$. It is easy to see that they are independent. Hence, proved. My doubt is how in Equation $(5\text{-}39)$ we can go from the first line to the second line. It does not seem to follow directly from the definition of $\pi_r L$, because $$\pi_r(f_{j_1}\! \otimes \dots \otimes f_{j_r}) := \sum_\sigma (\operatorname{sgn} \sigma) (f_{j_1}\! \otimes \dots \otimes f_{j_r} )_\sigma \stackrel{?}{=} \sum_{\sigma} (\operatorname{sgn} \sigma)\ f_{j_{\sigma 1}}\! \otimes \dots \otimes f_{j_{\sigma r}}.$$ If someone can give me a step-by-step proof of the equality it would be really helpful.","['linear-algebra', 'linear-transformations', 'multilinear-algebra']"
2587248,Verify surjectivity of the function $f$ satisfying: $f(x)+f(x^2)=x$,"Verify surjectivity of the function $f:\Bbb R \rightarrow \Bbb R$ satisfying: $\forall x \in \Bbb R:f(x)+f(x^2)=x$ I know how to check a function is surjective if we have its explicit formula,but have no idea for this type of question involving a functional equation!","['functions', 'functional-equations']"
2587279,Question about inverse function,"As a high school student, I have learnt about inverse functions, but not its theorem (inverse function theorem). I looked at wikipedia but the mathematics is too hard for me to understand. Can somebody explain in simple terms the conditions required for a function to have an inverse function? That is, if $y$ is a function of $x$ , under what conditions should $x$ be a function of $y$ ? Edit: If we know that $y$ is not a function of $x$ , then is it necessary that $x$ is also not a function of $y$ ? How can we prove that?","['algebra-precalculus', 'inverse-function', 'calculus', 'functions']"
2587310,Is $\text{ker} (\delta_{\nabla^E}d_{\nabla^E})$ always non-zero?,"Let $E$ be a vector bundle over a smooth manifold $M$, equipped with a metric $\eta$ and a metric-compatible connection $\nabla$. Denote by $\delta_{\nabla^E}:\Omega^1(M,E) \to \Omega^{0}(M,E)=\Gamma(E)$ the adjoint of the connection $${\nabla^E}: \Gamma(E)\to \Omega^1(M,E).$$ Note that $\delta_{\nabla^E}\circ{\nabla^E}: \Gamma(E) \to  \Gamma(E)$. Question: Is $\text{ker} (\delta_{\nabla^E}\circ{\nabla^E})$ always non-zero? While it is known that $\text{ker} (\delta_{\nabla^E})$ is infinite-dimensional , it is not clear to me that there are non-zero elements in the $\text{ker} (\delta_{\nabla^E})$ which are in the image of $\nabla^E$. (Note: for a generic connection $\nabla^E$, $\text{ker}(\nabla^E)=0$. My motivation is trying to understand things about the minimizing properties of harmonic maps.","['riemannian-geometry', 'partial-differential-equations', 'adjoint-operators', 'vector-bundles', 'differential-geometry']"
2587339,Perpendicular from incenter of a triangle to any side is equal to the radius of the incircle,"Given a triangle $ABC$ with incenter $I$, it is said that the perpendicular line segment from $I$ to any of the sides $AB$, $AC$, or $BC$ is equal to the radius of the incircle. (See the second picture on this page: http://mathworld.wolfram.com/RightTriangle.html ) I tried to prove it without any success. Can someone please give me a hint?","['trigonometry', 'triangles', 'geometry']"
2587378,Benedict Gross Abstract Algebra,"I recently started watching Harvard's Abstract Algebra Course by Benedict Gross. I am not able to find his lecture notes and problem set and they are not given on the Harvard website. 
Anybody has them or knows where I can find them",['abstract-algebra']
2587408,Proving that $\sum_{n=1}^{\infty} \left(\frac{a_1^{1/s}+a_2^{1/s}+\cdots +a_n^{1/s}}{n}\right)^s$ converges when $\sum_{n=1}^{\infty}a_n $ converges,"Assume that $a_n\ge0$ such that $\sum_{n=1}^{\infty}a_n $ converges, then show that for every $s>1$ the following series converges too:
  $$\sum_{n=1}^{\infty} \left(\frac{a_1^{1/s}+a_2^{1/s}+\cdots +a_n^{1/s}}{n}\right)^s.$$ I failed to handle this with Hölder inequality. Any tips or hint will be appreciated. Also it might be helpful to see that there is a Césaro sum of $(a_n^{1/s})_n$ appearing in the last series.","['real-analysis', 'sequences-and-series', 'calculus', 'summation', 'convergence-divergence']"
2587415,Integral of Euler class of tangent bundle and the generalized Gauss-Bonnet Theorem,"Definition of Euler Class that I've been given Let $\Sigma$ be a compact orientable manifold of dimension 2 with metric $g$ on the tangent bundle $T\Sigma$, and connection $\nabla$ and curvature $F_{\nabla}$. For sections $s_1$, $s_2$ of $T\Sigma$, we can define the map
$$
\omega(s_1,s_2) = g(F_{\nabla}s_1,s_2)
$$
It can be seen that $\omega\in \Omega^{2}(\Sigma; \Lambda^{2}T^{*}\Sigma)$ and that $\nabla\omega = 0$. For any two local frames $\{s_1,s_2\}$ and $\{s'_1,s'_2\}$ of $T\Sigma$ with the same orientation, we find that $s_1\wedge s_2 = s'_1\wedge s'_2$, and hence $\Lambda^{2}T\Sigma$ admits a nowhere vanishing section, say $\sigma\in \Omega^{2}(\Sigma; \Lambda^{2}T\Sigma)$. If we take $e$ to be the natural pairing $\langle\omega,\sigma\rangle$, then the Euler class of $T\Sigma$, $\varepsilon(T\Sigma)$, may be defined as the cohomology class of $e$, i.e. $\varepsilon(T\Sigma) = [e]\in H^{2}(\Sigma)$. It can be shown that this is independent of the choice of metric and connection. Definition of Riemann Curvature For vector fields $X,Y,Z,W$, we may define
$$
R(X,Y,Z,W) = g(F_{\nabla}(X,Y)Z,W)
$$
This satisfies the expected symmetry and anti-symmetry properties, as in http://mathworld.wolfram.com/RiemannTensor.html . In particular, for the manifold $\Sigma$, we can relate the Riemann curvature to the Gauss curvature $K$ and a non-vanishing section $\sigma \in \Omega^{2}(\Sigma; \Lambda^{2}T\Sigma)$ by the following formula (for $x\in \Sigma$)
$$
R(X,Y,Z,W)\mid_{x} = K(x)\sigma(X,Y)\sigma(Z,W)
$$ What I've been asked to show $$
\int_{\Sigma}\varepsilon(T\Sigma) = \int_{\Sigma}K\sigma
$$ What I'm trying to understand This formula looks very like the Gauss-Bonnet formula for surfaces to me, especially if I consider the case where $\sigma = dS$, some surface element. In this case, I would expect that the left-hand-side of the equation should equal $2\pi\chi(\Sigma)$. Unfortunately, I don't fully understand how to reconcile my definition of the Euler class with a formula for the Euler characteristic. Different (presumably compatible) definitions have been mentioned in other questions on this site (e.g. the answer given by Elden Elmanto in Euler class of tangent bundle of the sphere , and also here: How to interpret the Euler class? ), but I can't figure out how they tie back to this integral formula. Would it be wiser to try to solve the problem using the pairing $\langle \omega, \sigma\rangle$, rather than going through the Gauss-Bonnet theorem? Any help would be greatly appreciated.","['manifolds', 'characteristic-classes', 'vector-bundles', 'differential-geometry']"
2587429,Inequality $||\nabla f(x)|| \geqslant c|f(x)|^{\frac{1}{2}}$ (S. Łojasiewicz),"I need to prove the special case of Łojasiewicz inequality: Fact. Let $\Omega \subset \mathbb{R}^m$ be open and $0 \in \Omega$. Let $f \in \mathcal{C}^2(\Omega,\mathbb{R})$ and $f(0)=0$. Suppose also that the matrix of second partial derivatives is invertible. Prove that there exists an open neighbourhood $U \subset \Omega$ of $0$ such that the following inequality holds:
$$||\nabla f(x)|| \geqslant c|f(x)|^{\frac{1}{2}}$$
for some constant $c>0$. My attempt: We can use Taylor expansion formula and hence for $||u||$, small enough, we have:
$$|f(u)| \leqslant c||u||^2$$
(derivatives are continuous).
But what to do next? Writing down Taylor formula for $f'$ seems to me fine but I have no idea how to figure that out. 
Thanks in advance.","['multivariable-calculus', 'real-analysis', 'inequality']"
2587436,"Is there an algebraic proof for $\sum_{m=k}^{n-k} \binom{m}{k}\binom{n-m}{k} = \binom{n+1}{2k+1}, n\ge2k\ge0$","$\sum_{m=k}^{n-k} \binom{m}{k}\binom{n-m}{k} = \binom{n+1}{2k+1}, n\ge2k\ge0$ An combinatorial proof of the identity above states as follow: (1)Number of ways of picking (2k+1) numbers from 1 to (n+1) should be $\binom{n+1}{2k+1}$ (2)We pick (2k+1) numbers from 1 to (n+1) with median value (m+1).  Then, k numbers must be selected from 1~m, and the other k numbers must be chosen from (m+2)~(n+1). Thus there are $\binom{m}{k}\binom{n-m}{k}$ ways for picking (2k+1) numbers with median value (m+1). Since $n-k\ge m\ge k$, there are total $\sum_{m=k}^{n-k} \binom{m}{k}\binom{n-m}{k}$ ways. Since (1)=(2), the statement is true.
But is it possible to sketch an algebraic proof that doesn't require building combinatorial models?","['combinatorics', 'binomial-coefficients', 'combinatorial-proofs']"
2587442,"Prob. 8 (b), Sec. 10, in Munkres' TOPOLOGY, 2nd ed: The union of any collection of disjoint well-ordered sets indexed by some well-ordered set ...","Here is Prob. 8, Sec. 10, in the book Topology by James R. Munkres, 2nd edition: Problem 8 (a): Let $A_1$ and $A_2$ be disjoint sets, well-ordered by $<_1$ and $<_2$, respectively. Define an order relation on $A_1 \cup A_2$ by letting $a < b$ either if $a, b \in A_1$ and $a <_1 b$, or if $a, b \in A_2$ and $a <_2 b$, or if $a \in A_1$ and $b \in A_2$. Show that this is a well-ordering. Problem 8 (b): Generalize (a) to an arbitrary family of disjoint well-ordered sets, indexed by a well-ordered set. I think I'm clear as to the proof required in  Prob. 8 (a). My Attempt at Prob. 8 (b): Let $J$ be a (non-empty) well ordered set; let $$\left\{ \ A_\alpha \ \colon \ \alpha \in J \ \right\}$$ be a collection of non-empty, (pairwise) disjoint well-ordered sets indexed by set $J$; and let $$ A \colon= \bigcup_{\alpha \in J} A_\alpha. $$
  For each $\alpha \in J$, let $<_\alpha$ denote the well-ordering relation on the set $A_\alpha$. For any two elements $a, b \in A$, let us define $a < b$ to mean the following: Either $a, b \in A_\alpha$ for some $\alpha \in J$ and $a <_\alpha b$, or $a \in A_\alpha$, $b \in A_\beta$ for some $\alpha, \beta \in J$ such that $\alpha <_J \beta$. Then the set $A$ is a well-ordered set. Is this statement correct? If so, then here is my proof: Let $S$ be a non-empty subset of the set $A = \bigcup_{\alpha \in J} A_\alpha$. Let $J_0$ be the following subset of $J$. 
  $$ J_0 \colon= \left\{ \ \alpha \in J \ \colon \ S \cap A_\alpha \neq \emptyset \ \right\}. $$
  Then the set $J_0$ is non-empty, and as such it has a smallest element, say $\alpha_0$. Then $\alpha_0 \in J$ and $S \cap A_{\alpha_0}$ is a non-empty subset of $A_{\alpha_0}$ and so has a smallest element $a_{\alpha_0}$, which is also the smallest of $S$ with respect to the order relation on $A$. Is this proof correct? If so, then is my presentation accessible enough? If not, then where have I erred?","['well-orders', 'proof-verification', 'logic', 'order-theory', 'elementary-set-theory']"
2587461,Evaluating $\lim_{n\to \infty} \sum_{r=1}^{n}\frac{r}{n^2+n+r}$ [duplicate],"This question already has answers here : Evaluation of $\lim_{n\rightarrow \infty}\sum^{n}_{r=1}\frac{r}{n^2+n+r}$ (2 answers) Closed 4 years ago . The motive is to evaluate the following limit: $$\lim_{n\to \infty}\sum_{r=1}^{n} \frac{r}{n^2 + n + r}$$ I wrote it as $$ \lim_{n\to \infty}\sum_{r=1}^{n}\frac{r/n}{1 + 1/n + r/n^2} \approx ^{?} \int_{0} ^{1} x \, dx  = \frac{1}{2}$$ Now is this correct? Doesn't seem very correct to me. Thanks for your thoughts :) Oliver Oloa gave a hint on Sandwich theorem but removed answer. $$\sum_{r=1}^{n} \frac{r}{n^2 + n + n} \le \sum_{r=1}^{n} \frac{r}{n^2 + n + r} \le \sum_{r=1}^{n} \frac{r}{n^2 + n + 1}$$ Using this I think we get $1/2 \le L \le 1/2$ so limit is $1/2$.","['summation', 'sequences-and-series']"
2587462,connected components of open sets are open,I would like to prove that the connected components of an open set are open. Take $U$ an open set in a space $X$ and $U=\cup_\alpha C_\alpha$ where the $C_\alpha$ are the connected components. Suppose that there exists a $C_\alpha$ which is closed. Then ${C_\alpha}^c$ is open and ${C_\alpha}^c\cap U$ is open. However $$U= U\cap X = U\cap(C_\alpha\cup{C_\alpha}^c) = C_\alpha\cup ({C_\alpha}^c\cap U)$$ which is neither open nor closed. So we have a contradiction. Is this proof correct?,"['general-topology', 'connectedness']"
2587512,Is the series $\sum_{k=1}^{\infty}(\sqrt[k]{k}-1)$ divergent or convergent? [duplicate],"This question already has answers here : Convergence of $\sum_{n=1}^\infty{\left(\sqrt[n]{n}-1\right)}$ (3 answers) Closed 6 years ago . I find this series to be a bit troublesum. I can't find a proper method that works. Root test doen't seem to be useful. Ratiotest got ugly. Integral test seems to force me to integrate a function $x^{1/x},$ which doesn't have any elementary primitive. I can't find an apropriate limit to compare it to and do a limit test comparison.","['sequences-and-series', 'calculus']"
2587523,"How many numbers between 1 and 1000 are divisible by 2, 3, 5 or 7?","How many numbers between 1 and 1000 are divisible by 2, 3, 5 or 7? My try: Let $A_2, A_3, A_5, A_7$ be the set of numbers between 1 and 1,000 that are divisible by 2, 3, 5, and 7 respectively. I used the inclusion-exclusion formula for $|A_2\cup A_3\cup A_5\cup A_7|= |A_2|+|A_3|+|A_5|+|A_7|-|A_2\cap A_3|-|A_2\cap A_5|-|A_2\cap A_7|-|A_3\cap A_5|-|A_3\cap A_7|-|A_5\cap A_7|+|A_2\cap A_3\cap A_5|+|A_2\cap A_3\cap A_7|+|A_2\cap A_5\cap A_7|+|A_3\cap A_5\cap A_7|-|A_2\cap A_3\cap A_5\cap A_7| = 500+333+200+142-166-100-71-66-47-28+33+23+14+9-4 = 772 $ And the result I received was -  772. I would appreciate if you could confirm my method and result, and I'd be happy to see a different, more elegant approach.","['inclusion-exclusion', 'combinatorics']"
2587564,Question about complex analysis; writing $f(iy) = u(y) + iv(y)$,"Let $f(z) = z^n + a_{n-1}z^{n-1} + ... $ be a monic polynomial of
  degree $n$, and assume that $f(iy) \ne 0$ for all $y \in \mathbb R$.
  Write $f(iy) = u(y) + iv(y)$ and express the number of roots of $f$ in
  the right half plane {$\Re(z)> 0$} in terms of the number and mutual
  position of the real roots of $u$ and $v$. Now we have the first constant is equal to 1 and I searched and got the idea that it is always possible to write $f(z)=u(x,y)+iv(x,y)$ in here . But I do not know where to start in this question. Any help is appreciated!","['complex-analysis', 'polynomials']"
2587577,Largest number of sides and diagonals,"I have asked to solve the following: For given an integer number $n\ge3$, find the largest positive number $k_n$ for which: for every convex $n-$polygon (with $n$ sides), we can find $k_n$ segments, each segment is a side or a diagonal of this $n-$polygon, such that for any two segments, they always has a common point. For example: $n=3$: Triangle $ABC$ we can choose the set $\{AB,BC,CA\}$ that is
$k_3=3$. $n=4$: Quadrilateral $ABCD$ then we can choose $\{AB,BC,AC,BD\}$ that is $k_4=4$. I have no idea to solve this? Could anyone help me?","['combinatorics', 'contest-math', 'combinatorial-geometry']"
2587599,Inequality for the measure of a set,"Let $(X,\mu)$ be a measure space such that $\mu(X)=1$. Let $f \in L^{p}(X)$ for $1<p<\infty$ and $t\in \mathbb{R}$ such that $0<t<\|f\|_{1}$. Then for $q \in\mathbb{R}$ such that $1/q+1/p=1$ we have: \begin{equation}
\mu(\{x:|f(x)|\geq t\}) \geq \bigg(\frac{\|f\|_{1}-t}{\|f\|_{p}}\bigg)^{q}
\end{equation} Could you please provide me a hint on how to prove this? Thank you.","['integration', 'measure-theory']"
2587604,Prove that this sequence is a submartingale,"Let $X_1, X_2,\cdots$ be i.i.d. random variable on $(\Omega, \mathbb F)$ with $EX_1=0$ and $VX_1 = \sigma^2$. Consider a filtration $\mathbb F_n = \mathbb F(X_1,\cdots, X_n)$. I want to show that $Y_n = \left( \sum_{k=1}^n X_k \right)^2$ is a
  submartingale. This is my attempt: \begin{eqnarray}
E[Y_{n+1} | \mathbb F_n] &= E \left[ \left( \sum_{k=1}^{n+1} X_k \right)^2 \,\,\big|\,\, \mathbb F_n \right] \\
&= E \left[ \sum_{i,j=1}^{n+1} X_iX_j \,\,\big|\,\, \mathbb F_n \right] \\
&= \sum_{i,j=1}^{n+1} E \left[ X_i \,\,\big|\,\, \mathbb F_n \right] E \left[ X_j \,\,\big|\,\, \mathbb F_n \right] \\
&= \sum_{i,j=1}^{n} X_i X_j + 2 \sum_{i=1}^{n+1} X_i E \left[ X_{n+1} \,\,\big|\,\, \mathbb F_n \right] \\
&= Y_n + 2 \sum_{i=1}^{n+1} X_i E \left[ X_{n+1} \,\,\big|\,\, \mathbb F_n \right]
\end{eqnarray} How can I proceed from here? Of course if I knew $X_i\geq 0$ I would be done, but as is I don't know what to do next. Moreover, I'm not sure how to show that $E |Y_n| < \infty$ when we don't know that $X_i\geq 0$. Any help is MUCH appreciated.","['probability-theory', 'probability', 'martingales']"
2587607,Solve the ODE : $(x\sin(y)+y\cos(y))dx+(x\cos(y)-y\sin(y))dy=0$,"$$(x\sin(y)+y\cos(y))dx+(x\cos(y)-y\sin(y))dy=0$$ I tried this: $$y'=-\frac{x\sin(y)+y\cos(y)}{x\cos(y)-y\sin(y)} = -\frac{\frac{x}{y}\tan(y)+1}{\frac{x}{y}-\tan(y)}$$ This looks like substitution to me, but I'm not sure what to substitute. Any help is appreciated! Thanks.","['substitution', 'ordinary-differential-equations']"
2587634,Prove that these functions are linearly independent,"Given $ \alpha_1 > \alpha_2 > \cdots > \alpha_n \geq 0$, $f_1(x)= e^{-\alpha_1x},..., f_n(x)=e^{-\alpha_nx}$, prove that they are linearly independent . Hint: don’t forget the limit $ x \rightarrow \infty $. I have already seen proofs about similar questions. What you have to do is to set the combination of those functions (or polynomials) equal to 0 and show that all coefficients have to be 0. But here, the coefficients are in the exponent, they can’t be equal to each other, and the negative exponent disturbs me a bit. Thanks for your help.","['real-analysis', 'linear-algebra']"
2587663,Find the solution of $(xy^2+2x^2y^3)dx+(x^2y-x^3y^2)dy=0$,"Find the solution of $(xy^2+2x^2y^3)dx+(x^2y-x^3y^2)dy=0$ My attempt: it is of form
$yf_1(xy)dx + xf_2(xy)dy = 0$ Integrating factor = $\frac{1}{Mx-Ny}$ But it is getting complicated. Any easier methd???",['ordinary-differential-equations']
2587694,On convergence of series of the generalized mean $\sum_{n=1}^{\infty} \left(\frac{a_1^{1/s}+a_2^{1/s}+\cdots +a_n^{1/s}}{n}\right)^s.$,"Assume that $a_n>0$ such that $\sum_{n=1}^{\infty}a_n $ converges. Question: For what values of $s\in \Bbb R$ does the following series :
  $$ I_s= \sum_{n=1}^{\infty} \left(\frac{a_1^{1/s}+a_2^{1/s}+\cdots +a_n^{1/s}}{n}\right)^s.$$ converges or diverges? This question is partially  motivated by some comments on this post where it is shown that $I_s$ converges for $s>1$. Moreover, it is well known that 
$$\lim_{s\to\infty}\left(\frac{a_1^{1/s}+a_2^{1/s}+\cdots +a_n^{1/s}}{n}\right)^s = \left(a_1a_2\cdots a_n\right)^{1/n}$$ Accordingly, Taking  $b_n= 1/a_n$ is  one readily get, $$\lim_{\color{red}{s\to-\infty}}\left(\frac{a_1^{1/s}+a_2^{1/s}+\cdots +a_n^{1/s}}{n}\right)^s = \left(a_1a_2\cdots a_n\right)^{1/n}$$ 
it draws from Carleman's inequality that : $$\color{red}{ I_{-\infty}}=I_\infty= \sum_{n=1}^{\infty}\left(a_1a_2\cdots a_n\right)^{1/n} \le e  \sum_{n=1}^{\infty} a_n<\infty .$$
Patently it is also true that the convergence holds for $s=-1$ this is proven here .  Whereas the convergence fails for $0<s<1$ 
Indeed, $$\sum_{n=1}^{\infty} \left(\frac{a_1^{1/s}+a_2^{1/s}+\cdots +a_n^{1/s}}{n}\right)^s \ge  \sum_{n=1}^{\infty} \frac{a_1}{n^s}=\infty$$ So we have that $I_s$ converges for $1<s\le\infty$ or $s=\in\{-1,-\infty\}$ and diverges for $0<s<1$ . Hence the original question reduces on studying $I_s$ for $s\le0$ can anyone help? Clearly the hope is that $I_s$ converges for for $-\infty\le s\le -1 $ and  diverges for $-1<s<0.$` I don't know if one could infer some conjecture for the case $s=0$ since it seems pathological.","['real-analysis', 'sequences-and-series', 'calculus', 'summation', 'convergence-divergence']"
2587743,Do two similar boolean matrices have same number of non-zero entries?,"I was just wondering: is it necessarily the case that if $A$ is a $(0, 1)$ matrix, and $SAS^{-1}=B$, where $B$ is also a $(0,1)$ matrix, then do $A$ and $B$ have the same number of $1$s? I have the gut feeling that this may not be true. However, let us consider this special case which arises in graph theory (coherent configurations): suppose $\{A_1, A_2,..., A_r\}$ is a set of $(0,1)$ matrices such that $\sum_iA_i=J$, with $J$ being the all $1$s matrix, and some subset of it sums to the identity matrix. Let $\{B_1, B_2,...,B_r\}$ be another set satisfying the same conditions. If $SA_iS^{-1}=B_i$, then do $A_i$ and $B_i$ have the same number of $1$s for all $i$? Thanks!","['matrices', 'combinatorics', 'graph-theory', 'coherent-rings']"
2587768,Weighted Hardy-Littlewood-Sobolev inequality in one dimesion,"Weighted Hardy-Littlewood-Sobolev inequality in one dimesion states: Let $1 < p, q < \infty, 0 < t < 1, a, b \in \mathbb{R}$ such that: $$ -t \leq a + b \leq 0, \frac{1}{p} < a + 1, \frac{1}{q} < b + 1, \frac{1}{p} + \frac{1}{q} = a + b + t + 1 $$ Then there exists $C$ (depending on $a,b,p,q,t$ ) such that: $$ \int_{\mathbb{R}}\int_{\mathbb{R}} \frac{|x|^{a}|f(x)||y|^{b}|g(y)|}{|x-y|^{1-t} }dxdy \leq C\left\| f\right\| _{L^p(\mathbb{R})}\left\| g\right\| _{L^q(\mathbb{R})}.$$ The proof can probably be done by applying Marcinkiewicz interpolation. This is similar to the unweighted case, but the kernel is giving me more problems here, so some help is welcome.","['functional-analysis', 'harmonic-analysis', 'fourier-analysis', 'interpolation']"
2587775,Union and intersection of functions,"Please who can explain why
$$f(A \cup B) = f(A) \cup f(B)$$
(And I know how to prove it using set theory symbols )
But 
$$f(A \cap B) \subseteq f(A) \cap f(B)$$ And the equality arises if and only if $f$ is injective. Thanks in advance","['elementary-set-theory', 'functions']"
2587787,Infinite limit of a differentiable function,"Let $f:[a,+\infty) \to \Bbb{R}$ be a differentiable function with the property: $$\inf\{f'(x)|x>a\}>0$$Prove that $\lim_{x \to +\infty}f(x)=+\infty$ Here is my solution: Let $c=\inf\{f'(x)|x>a\}>0$ and $x \geq a+1$ From Mean Value Theorem exists $x_0 \in [a+1,x]$ such that $$f(x)=f(a+1)+f'(x_0)(x-a+1)$$ But $f'(x) \geq c,\forall x \geq a+1$ Thus $$f(x) \geq f(a+1)+c(x-a+1),\forall x \geq a+1 \Rightarrow \liminf_{x \to +\infty}f(x)=+\infty$$ Thus $\lim_{x \to +\infty}f(x)=+\infty$ Is my solution correct or am i missing something? Thank you in advance.","['derivatives', 'real-analysis', 'limits', 'proof-verification', 'calculus']"
2587796,Generating a $C_0$-semigroup on $L^2$,"Consider the linear operator $$A : H^4(\mathbb{R}; \mathbb{R}) \to L^2(\mathbb{R};\mathbb{R})$$ defined by $u\mapsto -(1-\partial_{xx}^2)^2$. Show that $A$ generates a $C_0$-semigroup on $L^2$. I believe I was suggested to use Fourier transforms, so I found that \begin{align}F(Au)(\omega)&=F((-1+2\partial_{xx}^2-\partial_{xxxx}^4)u)(\omega)=(-1-2\omega^2-\omega^4)F(u)(\omega)\\ 
&=-(\omega^2+1)^2F(u)(\omega).\end{align} But from here on I am totally lost. I know that I should use some theorem like Hille-Yosida or Lumer–Phillips, but I have no idea how to combine it with Fourier transforms. Thanks in advance and happy New Year!","['functional-analysis', 'semigroup-of-operators', 'fourier-transform']"
2587804,Probability that the ball drawn from $n$th urn is white,"There are $n$ urns each having $a$ white and $b$ black balls. One ball is taken from urn 1 and is transferred to urn 2. Then one ball is taken from urn 2 and transferred to urn 3 and so on. Find the probability that the ball drawn from $n$th urn is white. I get the intuition that the answer should be $\frac{a}{a+b}$, but I'm unable to prove it.",['probability']
2587816,differential equation $y(t)[y''(t)+2\lambda y'(t)]=(y'(t))^2$,"Can anyone please help me solve the following differential equation
$$y(t)[y''(t)+2\lambda y'(t)]=(y'(t))^2$$
with $y(0)=0$. If $\lambda=0$ then clearly $y(t)=Ge^{\alpha t}$. But what if $\lambda\not=0?$",['ordinary-differential-equations']
2587825,How to evaluate $1 - \frac{\binom{n^2}{1}}{\binom{n+1}{1}} + \frac{\binom{n^2}{2}}{\binom{n+2}{2}} - \frac{\binom{n^2}{3}}{\binom{n+3}{3}} + ..$,"How to evaluate $1 - \frac{\binom{n^2}{1}}{\binom{n+1}{1}} + \frac{\binom{n^2}{2}}{\binom{n+2}{2} } - \frac{\binom{n^2}{3}}{\binom{n+3}{3}} + \frac{\binom{n^2}{4}}{\binom{n+4}{4}} - ......$ I really have no idea how to proceed in this question. Expanding it by the formula isn't helping as much as I can see. And the options are extremely sofisticated as well like 1/n, 1/(n+1), 1. How to proceed?","['combinatorics', 'binomial-coefficients']"
2587838,Closed form for the harmonic approximation sum $\sum _{k=1}^{\infty } \left(H_k^{(2)}-\zeta (2)\right){}^2$,"Question Is there a closed form of this harmonic approximation sum $$s=\sum _{k=1}^{\infty } \left(H_k^{(2)}-\zeta (2)\right){}^2\tag{1}$$ The notation is standard. Motivation This question concerns a field which was treated frequently by many contributors here  where, generally speaking, an appropriate functional of the difference of a summand an its asymptotic approximation is summed up, and mostly it is asked if there is a closed form of this sum in terms of ""standard constants"". The approximation as well as the functional must be chosen such that the resulting infinite sum in convergent. There are many examples of such ""approximation sums"". Recently [1] I posted a question related to the approximation sum $$\sum _{k=1}^{\infty } \left(H_k-(\log(k) + \gamma)\right){}^2\tag{2}$$ This led to the problem of a sum containing an uncommon $\log$-factor instead of the common polynomial in the index. In an attempt to get rid of the $\log$ but still retain a non trivial problem I ask here to find a closed form for $s$ defined in (1). A natural generalization is the generating function $$s_{m,p}(x)=\sum _{k=1}^{\infty } x^k \left(H_k^{(m)}-\zeta (m)\right){}^p\tag{3}$$ To my knowledge, approximation sums containing modified harmonic numbers have not been investigated here. The numerical value is $$N(s_2) = 0.900362625200937377409205241520956358081230891307664$$ Solution attempt We consider partial sums and write $s = \sigma_1+\sigma_2+\sigma_3$ where $$\sigma_1 = \sum _{k=1}^{n } \left(H_k^{(2)}\right){}^2\tag{4a}$$
$$\sigma_2 =-2 \zeta(2) \sum _{k=1}^{n } H_k^{(2)}{}\tag{4b}$$
$$\sigma_3 = n \zeta(2)^2\tag{4c}$$ The sum in $\sigma_2$ can be calculated: $$\sum _{k=1}^n H_k^{(2)}=(n+1) H_{n+1}^{(2)}-H_{n+1}\tag{5}$$ so that $$\sigma_2 =-2 \zeta(2)\left( (n+1) H_{n+1}^{(2)}-H_{n+1}\right)\tag{6}$$ and we are left with $\sigma_1$ which can be easily shown by the reader to reduce to the calculation of either $$h_2 = \sum _{k=1}^n \frac{H_k}{k^2}\tag{7}$$ or $$h_4 = \sum _{k=1}^n \frac{H_{k}^{(2)}}{k}\tag{8}$$ These sums have been discussed (and christianed) earlier in [2] where also this relation has been derived $$h_2+h_4 =H_n  H_{n}^{(2)} + H_{n}^{(3)}\tag{9}$$ which means that knowledge of one of these function is suffient. It would be nice to see an explicit form for the ( finite ) sums $h$ in terms of the elements of the set containing (modified) harmonic numbers and scalars. But for the present task only the limit of large index must be determined. References [1] Generating function for harmonic number times log ($H_k log(k)$) [2] Sum of powers of Harmonic Numbers","['harmonic-numbers', 'sequences-and-series', 'approximation']"
2587841,Find $\lim\limits_{n \rightarrow \infty}n\bigg(\cos \bigg(\frac {1}{\sqrt n} \bigg) - 1\bigg)$,"$$\lim_{n \rightarrow \infty}n\bigg(\cos \bigg(\frac {1}{\sqrt n} \bigg) - 1\bigg)$$ I'm surprisingly struggling with this limit, could you give me a hint how to handle it (no L'Hospital and no prior knowledge what the limit value is)? Generally what are some basic methods to handle $\infty \cdot 0$?","['real-analysis', 'limits', 'trigonometry', 'calculus', 'limits-without-lhopital']"
2587900,Do harmonic numbers have a “closed-form” expression?,"One of the joys of high-school mathematics is summing a complicated series to get a “closed-form” expression. And of course many of us have tried summing the harmonic series $H_n =\sum \limits_{k \leq n} \frac{1}{k}$, and failed. But should we necessarily fail? More precisely, is it known that $H_n$ cannot be written in terms of the elementary functions, say, the rational functions, $\exp(x)$ and $\ln x$? If so, how is such a theorem proved? Note . When I started writing the question, I was going to ask if it is known that the harmonic function cannot be represented simply as a rational function? But this is easy to see, since $H_n$ grows like $\ln n+O(1)$, whereas no rational function grows logarithmically. Added note: This earlier question asks a similar question for “elementary integration”. I guess I am asking if there is an analogous theory of “elementary summation”.","['abstract-algebra', 'functions', 'closed-form', 'number-theory', 'harmonic-numbers']"
2587917,Criteria for smoothness of the pointwise limit of a sequence of functions,"Let $\#$ denote cardinality, and fix $p\in[1,\infty]$. Let $(f_n)_{n\in\mathbb{N}}$ be a sequence of functions from $[0,1]$ to $\mathbb{R}$ with the properties $f_n\in C^{n-1}([0,1])$ $f^{(n)}_n$ is continuous on $[0,1]\setminus A_n$ where
$\#A_n<\infty$ but $ \underset{n\to\infty}{\lim}\#A_n=\infty$ $\underset{n\to\infty}{\lim}||f_n^{(m)}||_p$ exists and is finite $\forall m\in\mathbb{N}_0$ $f_n$ converge pointwise to a function $f$ For what values of $p$ do these imply $f\in C^\infty([0,1])$? For those $p$ where a counterexample exists, how to construct such an example and/or what would be a convenient additional condition to avoid its existence? Attempt with $p=\infty$: Assume that $f^{(0)}$ is not continuous. Then there exists $x\in(0,1)$ and $\varepsilon>0$ such that however small $\delta>0$ is, there exists $x_0$ satisfying $0<|x-x_0|<\delta$ such that $|f(x_0)-f(x)|>\varepsilon$. Moreover $0<|(x_0(\delta)-(x+\delta))/2|<\delta$, and
if $p=\infty$ then 3) implies $\infty>\underset{n\to\infty}{\lim}|f_n^{(1)}(x)|$. A contradiction follows: $$\infty>\underset{n\to\infty}{\lim}|3f_n^{(1)}(x)|
=\underset{n\to\infty}{\lim}\left(\underset{\delta\to 0^+}{\lim}\left|\frac{f_n(x+\delta)-f_n(x)}{\delta}\right|+2\underset{\delta\to 0^+}{\lim}\left|\frac{f_n(x_0(\delta))-f_n(x+\delta)}{x_0(\delta)-(x+\delta)}\right|\right)
\hspace{6.4cm}\text{ }\\\hspace{4cm}
>\underset{n\to\infty}{\lim}\left(\underset{\delta\to 0^+}{\lim}\left|\frac{f_n(x+\delta)-f_n(x)}{\delta}\right|+\underset{\delta\to 0^+}{\limsup}\left|\frac{f_n(x_0(\delta))-f_n(x+\delta)}{\delta}\right|\right)
\\\hspace{2.15cm}
>\underset{n\to\infty}{\lim}\underset{\delta\to 0^+}{\limsup}\left|\frac{f_n(x+\delta)-f_n(x)}{\delta}+\frac{f_n(x_0(\delta))-f_n(x+\delta)}{\delta}\right|
\\\hspace{2cm}
=\underset{n\to\infty}{\lim}\underset{\delta\to 0^+}{\limsup}\left|\frac{f_n(x_0(\delta))-f_n(x)}{\delta}\right|
\hspace{4.6cm}\text{ }\\
\overset{\text{???}}{=}\underset{\delta\to 0^+}{\limsup}\underset{n\to\infty}{\lim}\left|\frac{f_n(x_0(\delta))-f_n(x)}{\delta}\right|
\hspace{2.6cm}\text{ }\\
=\underset{\delta\to 0^+}{\limsup}\frac{|f(x_0(\delta))-f(x)|}{\delta}
>\underset{\delta\to 0^+}{\limsup}\frac{\varepsilon}{\delta}=\infty
\hspace{0.5cm}\text{ }$$ so $f^{(0)}$ is continuous and replacing $f$ and $f_n$ by their derivative smoothness follows by induction. Unless the part with those ""???"" is wrong?!","['derivatives', 'pointwise-convergence', 'uniform-convergence']"
2587951,Proof that $\mathbb{N}$ is a model of the induction schema [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How can we show the proof that $\mathbb{N}$ is a model of $$\forall \overline{y} (\varphi(0,\overline{y})\land \forall x (\varphi(x,\overline{y})\rightarrow \varphi(s(x),\overline{y}))\rightarrow \forall x\, \varphi(x,\overline{y})).$$","['logic', 'discrete-mathematics']"
2587970,Solving a Sum of Complex Exponentials,"Suppose I have the following equation. $$e^x+e^{\omega x}+e^{\omega^2 x}=0$$ where $\omega=e^{2i\pi/3}$.  How do I find all solutions to this equation in the complex plane?  Do I need to use numerical techniques or are there algebraic ways to solve this?  I think the answer to the algebraic is ""no"" but I was wondering if there was a tried and true method. Also, what about the variants below $$e^x+\omega^2 e^{\omega x}+\omega e^{\omega^2 x}=0$$ $$e^x+\omega e^{\omega x}+\omega^2 e^{\omega^2 x}=0$$ Certainly, $x=0$ is a solution to these, but how would i find others?","['complex-analysis', 'singularity', 'exponential-function']"
2587979,Generalized Formula for the Probability of the Union of $n$ events occurring?,"Consider $$
P(A \cup B) = P(A) + P(B) - P(A \cap B)
$$ What is the generalization of this formula for $n$ events occuring? That is $$
P(\cup A_i) = \sum P(A_i) + \ldots ?
$$",['probability-theory']
2587986,"About the Center of the Special Linear Group $SL(n,F)$","I want to classify the center of the Special Linear Group.
I already determined the center for $SL(n,F)$ : $$Z(SL(n,F))=\left\{ \lambda I_n:\lambda^n=1 \right\}.$$ I showed that $Z(SL(n,F))$ is itself a group and now I want to show that $Z(SL(n,F))$ is cyclic and has a order dividing $n$ . I thought this is possible by regarding the map $SL(n,F)\rightarrow P(F)$ , $P(F)$ being the projective space. The kernel of this map is $Z(SL(n,F))$ . How do I have to argue now?","['abstract-algebra', 'roots-of-unity', 'group-theory', 'cyclic-groups']"
2587996,How to solve (in)equality of three variables with trigonometric solutions,"I'm working through a set of inequality problems and I'm stuck on the following question: Find all sets of solutions for which $$(a^2+b^2+c^2)^2=3(a^3b+b^3c+c^3a)$$ holds. Note that $a,b,c\in\mathbb{R}$. Firstly, one can easily see that when $a=b=c$ then the equality holds: $$\text{LHS}=(a^2+a^2+a^2)^2=(3a^2)^2=9a^4$$ and $$\text{RHS}=3(a^4+a^4+a^4)=3(3a^4)=9a^4.$$ A hint is given to use the substitutions $a=x+2ty$, $b=y+2tz$ and $c=x+2tz$ for real $t$. The LHS is rather nice in that it simplifies to $$(4t(xy+xz+yz)+(1+4t^2)(x^2+y^2+z^2))^2$$ but I can't find a similar simplification for the RHS. I guess this is a type of uvw question but I don't know where to start. There are actually four sets of solutions: $$a=b=c,$$ $$\frac{a}{\sin^2\frac{4\pi}7}=\frac{b}{\sin^2\frac{2\pi}7}=\frac{c}{\sin^2\frac{\pi}7},$$ $$\frac{b}{\sin^2\frac{4\pi}7}=\frac{c}{\sin^2\frac{2\pi}7}=\frac{a}{\sin^2\frac{\pi}7},$$ and $$\frac{c}{\sin^2\frac{4\pi}7}=\frac{a}{\sin^2\frac{2\pi}7}=\frac{b}{\sin^2\frac{\pi}7}$$ I have no idea how the  trigonometric expressions are obtained. How could the equality be solved?","['inequality', 'polynomials', 'trigonometry', 'buffalo-way', 'uvw']"
2588022,Probability of flopping a royal flush,"I have no stats training, so I am asking if I am attacking this simple statistical problem correctly. What are the chances of flopping a royal flush in Texas hold’em? My attempt: The first card dealt to the player must be either a $10,J,Q,K,$ or $A$, any suit.  So the probability of the first card deal would be $\frac{5}{13}$.  Then the second card dealt to the player must be the same suit, and one of the values mentioned above, meaning the probability is $\frac{4}{51}$.  It follows that the next three cards on the flop must be the three remaining cards needed to complete the royal flush, with probabilities: $(\frac{3}{50})(\frac{2}{49})(\frac{1}{48})$.  Therefore I believe the odds of flopping a royal flush is: $\frac{5!}{13\cdot 51\cdot 50\cdot 49\cdot 48}$ I would think that this probability would be independent of how many players are in the game.  The odds of the deck the be stacked in the perfect way according to how many players there are to give you the royal flush on the flop seem to be the same. Have I made any mistakes?  Thanks in advance.","['statistics', 'poker', 'probability', 'solution-verification']"
2588025,as convergence of $n$ roots of product of uniform random variables,"Let $X_1,X_2,\dots$ be i.i.d. random variables with continuous uniform distribution $U(0,1)$. $\forall\ n\in\mathbb{N}:\text{we define } Y_n:=\prod\limits_{i=1}^nX_n$. Prove that the sequence $Y_1,\sqrt[2]{Y_2},\sqrt[3]{Y_3},\dots$ converges almost surely and find the limit. I am not sure what the limit is but I feel that maybe its $\frac{1}{2}$. I know that it is enough to show that $\sum\limits_{n=1}^\infty\Pr[|\sqrt[n]{Y_n}-\frac{1}{2}|\geq\epsilon]<\infty$. $\Pr[|\sqrt[n]{Y_n}-\frac{1}{2}|\geq\epsilon]=$ $\Pr[\{\sqrt[n]{Y_n}-\frac{1}{2}\geq\epsilon\}\cup\{\sqrt[n]{Y_n}-\frac{1}{2}\leq-\epsilon\}]=$ $\Pr[\{Y_n\geq(\epsilon+\frac{1}{2})^n\}\cup\{Y_n\leq(\frac{1}{2}-\epsilon)^n\}]\leq$ $\Pr[Y_n\geq(\epsilon+\frac{1}{2})^n]+\Pr[Y_n\leq(\frac{1}{2}-\epsilon)^n]\stackrel{\text{Markov}}{\leq}$ $\Big(\frac{1/2}{1/2+\epsilon}\Big)^n+\Pr[Y_n\leq(\frac{1}{2}-\epsilon)^n]$ What will I do with the second term? Is $\frac{1}{2}$ even the limit?","['probability-limit-theorems', 'probability-theory', 'probability']"
2588061,"Given $3\cos x - 4 \sin x = 2$, find $3 \sin x + 4 \cos x$ without first solving for $x$","If $$3\cos{x}-4\sin{x}=2$$
find $$3\sin{x} +4\cos{x} $$ I have solved the equation for $x$, then calculated the required value, but I think there is a direct solution without solving the equation.",['trigonometry']
2588083,"Determine $a,b$ such that $y= \begin{cases} 2x^2+x+1 & x\leq 0 \\ ax+b & x > 0 \end{cases} $ is differentiable at $0$","Let $$y= \begin{cases} 
      2x^2+x+1 & x\leq 0 \\
      ax+b & x >  0 
   \end{cases}
$$ Determine $a,b$ such that $y$ has a derivative at $0$. So, I used the definition of the derivative: $$\lim_{x \to 0^+} \frac{y(x)-y(0)}{x} = \lim_{x \to 0}\frac{ax+b-1}{x}$$
but the limit is $+\infty$. What am I doing wrong?","['derivatives', 'calculus', 'limits']"
