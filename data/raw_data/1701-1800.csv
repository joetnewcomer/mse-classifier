question_id,title,body,tags
11971,Intuition behind conjugation in group theory,"I am learning group theory, and while learning automorphisms, I came across conjugation as an example in many textbooks. Though the definition itself, (and when considering the case of abelian groups), it seems pretty innocent, I have to admit that I have no intuition about whats happening, or why even such a map is important. Did anyone feel this way when you learnt it? Any examples/references that you have found useful when you learnt it?","['intuition', 'group-theory']"
11980,Does equality in distribution imply equality of expected value?,"In other words, if X = Y in distribution, is it true that EX = EY? I think this must be true, but I've tried to prove it a few times and I always get stuck. Thanks in advance for any hints or reference.",['probability']
11991,order and binary relation,"Are order and binary relation the same thing, or order is just some special binary relation? If it is the latter, what kinds of properties distinguish an order from a general binary relation? Thanks and regards! Sorry for the confusion already caused. What I thought was that a partial order is just some special order, and there are other orders that are not partial orders, such as preorder , the order on a directed set . So I was wondering how an order was defined then, and I saw there was no definition for an order in the Wikipedia page for order theory. I believe  I was not lazy or could not read, what I understood was different from yours, and I did not realize that when I first posted my question. So sorry about that! At the end, if possible, I would like to know if there is a concept that can include partial order, preorder and the ""order"" on a directed set, but more special than a binary relation. Thanks!","['relations', 'elementary-set-theory', 'order-theory']"
12007,Reconstructing a Monthly problem: tree growth on the 2D integer lattice,"I'm trying to reconstruct a problem I saw in the Monthly, years ago. Perhaps it'll look familiar to someone. In the integer lattice in the plane, we grow a tree in the following natural way: Initially the tree is just the origin. At each step, we find the set of lattice points that are neighbors (distance 1) to precisely one vertex of our tree, and add them (simultaneously) to the tree. Thus on day 0 the tree is $\{(0,0)\}$; on day 1 it contains $\{(0,0), (1,0), (-1,0),(0,1),(0,-1)\}$; on day 2 it contains those vertices along with $(2,0),(-2,0),(0,2)$ and $(0,-2)$ (note that $(1,1)$ is not added because it has two neighbors already in the tree), and on day 3 we add 12 new vertices. It looks like a pretty familiar fractal. The thing I'm not sure of is what exactly was asked of that tree... Possible candidates include its asymptotic density, some sort of simple formula to determine which lattice points ultimately make it into the tree and the # of vertices added on day $n$. There are lots of interesting questions and I'm happy to try and solve them but I prefer to work on the ones that were actually posed!","['discrete-geometry', 'reference-request', 'fractals', 'number-theory']"
12016,What does it mean for a polynomial with integer coefficients to have a root in $p$-adic integers?,"I have just begun delving into $p$ -adic number theory. I was wondering, given a poynomial $f(x)$ with integer coefficients, what does it mean when we say, $f(x)$ has a root in $\mathbb{Z}_2$ , for instance.",['number-theory']
12017,Why is there no Latin square of order 7 with an autotopism group of order 7?,"The group $S_n \times S_n \times S_n$ acts on the set of Latin squares $L$ of order $n$, with $\theta:=(\alpha,\beta,\gamma)$, starting from $L$, permuting the rows by $\alpha$, permuting the columns by $\beta$ and permuting the symbols by $\gamma$.  Each $\theta \in S_n \times S_n \times S_n$ is called an isotopism .  In some instances $\theta(L)=L$, whence we call $\theta$ an autotopism of $L$.  The set of autotopisms of a Latin square forms a group under composition. [Side note: we reserve the name automorphism for autotopisms of the form $(\alpha,\alpha,\alpha)$ to correspond with the notions in group theory and quasigroup theory] From Brendan McKay's data , we can deduce that no Latin square of order 7 has an autotopism group of order 7.  [There are autotopisms of order 7, but no autotopism group has order 7.] What's a clever proof of this observation that doesn't look through all the non-isotopic Latin squares? Alexander Hulpke, Petteri Kaski, Patric R. J. Östergård, The number of Latin squares of order 11 , claims that there is a Latin square of order 11 that admits an autotopism group of order $11$.","['latin-square', 'combinatorics']"
12026,What does smooth curve mean?,"In this problem, I know that the hypothesis of Green's theorem must ensure that the simple closed curve is smooth, but what is smooth? Could you give a definition and an intuitive explanation?",['calculus']
12030,Calculating $\oint_{L} \frac{xdy - ydx}{x^2 + y^2}$ PartII,"The orginal problem is ""Calculating $\oint_{L} \frac{xdy - ydx}{x^2 + y^2}$, where L is a smooth, simple closed, and postively oriented curve that does not pass through the orgin"". But what if I modify the hypothesis and allow non-simple closed curve? I mean is there something like green formula that allows us calculuating ""non-simple closed curve integral""? EDIT : It seems to me that this integral should also resemble the simple closed one. Because common interior line integral should be canceled only remaining the outter curve. Am I right?","['multivariable-calculus', 'calculus']"
12032,These calculations are correct ? About  $\int\frac{e^{-x}}{x}dx$,"Was trying to calculate $$\int_{0}^{\infty}e^{-x}\ln x dx=-\gamma$$ and I found this question: I want to analyze $$\int\frac{e^{-x}}{x}dx$$ With $u=\displaystyle\frac{1}{x} \Rightarrow du = \displaystyle\frac{-1}{x^{2}} dx  $,  and $dv=e^{-x} \Rightarrow v=-e^{-x}$ Then $$\int\frac{e^{-x}}{x}dx = \displaystyle\frac{1}{x}\cdot-e^{-x}-\int-e^{-x}\cdot\displaystyle\frac{-1}{x^{2}} dx = -\displaystyle\frac{e^{-x}}{x}-\int \displaystyle\frac{e^{-x}}{x^{2}} dx$$ Integrating from the same form gives: $$\int\frac{e^{-x}}{x}dx = -\displaystyle\frac{e^{-x}}{x} + \displaystyle\frac{e^{-x}}{x^{2}} + 2\int\frac{e^{-x}}{x^{3}}dx$$ Are these calculations are correct?, and more is  valid say : $$\int\frac{e^{-x}}{x}dx = \displaystyle\sum\limits_{n=0}^\infty (-1)^{n+1}n!\frac{e^{-x}}{x^{n+1}}\ ?$$ $\bf{EDIT}$: This series  helps me to
  calculate it ? :
  $$\int_{0}^{\infty}e^{-x}\ln xdx=-\gamma$$ I don't know  how to turn
  this series in something harmonic. If
  not, is this the way to calculate that this
  integral converges to $-\gamma$, which
  is the form ? Thanks","['calculus', 'integration']"
12034,What are the conditions for existence of the Fourier series expansion of a function $f\colon\mathbb{R}\to\mathbb{R}$,What are the conditions for existence of the Fourier series expansion of a function $f\colon\mathbb{R}\to\mathbb{R}$?,"['fourier-series', 'real-analysis']"
12042,Recurrence relation satisfied by $\lfloor(1+\sqrt{5})^n\rfloor$,"Let $L(n)=\lfloor(1+\sqrt{5})^n\rfloor$. What kind of a linear recurrence is satisfied by $L(n)$? I have no idea how to go about this, because of the presence of the greatest integer function. Please feel free to retag it as I kept getting an error on every tag I thought was appropriate.",['discrete-mathematics']
12047,Proving basic/standard trigonometric identities,"How to prove the following trigonometric identities ? 1) If $\displaystyle \tan (\alpha) \cdot \tan(\beta) = 1 \text{ then } \alpha + \beta = \frac{\pi}{2}$ I tried to prove it by using the the formula for $\tan(\alpha + \beta)$ but ain't it valid only when $\alpha + \beta \neq \frac{\pi}{2}$ ? 2) $\displaystyle\sec\theta + \tan \theta = \frac{1}{ \sec\theta - \tan \theta}, \theta \neq (2n+1)\frac{\pi}{2}, n \in \mathbb{Z} $ For this one I tried substituting them with the sides of the triangle, but not successful to the final result. These are not my homework, I am trying to learn maths almost on my own, so ...",['trigonometry']
12052,Series $\sum_{n=1}^{\infty} (\sqrt[3]{n+1} - \sqrt[3]{n-1})^{\alpha}$ converge or diverge?,"Given the following series: $\sum_{n=1}^{\infty} (\sqrt[3]{n+1} - \sqrt[3]{n-1})^{\alpha}$ 
where $\alpha \in \mathbb{R}$. Does the series converge or diverge? Attempts to solve the problem: 1) $\lim_{n\to\infty} (\sqrt[3]{n+1} - \sqrt[3]{n-1})^{\alpha } = 0$ - not helpful. 2) Used the formula $a^{3} - b^{3} = (a-b)(a^{2} + ab + b^{2})$ - not helpful. 3) The ration test is not helpful either.","['radicals', 'sequences-and-series', 'calculus']"
12054,How to use the Lagrange's remainder to prove that log(1+x) = sum(...)?,"Using Lagrange's remainder, I have to prove that: $\log(1+x) = \sum\limits_{n=1}^\infty (-1)^{n+1} \cdot \frac{x^n}{n}, \; \forall |x| < 1$ I am not quite sure how to do this. I started with the Taylor series for $x_0 = 0$: $f(x_0) = \sum\limits_{n=0}^\infty \frac{f^{(n)}(x_0)}{n!} \cdot x^n + r_n$, where $r_n$ is the remainder. Then, I used induction to prove that the n-th derivative of $\log(1+x)$ can be written as: $f^{(n)} = (-1)^{n+1} \cdot \frac{(n-1)!}{(1+x)^n}, \forall n \in \mathbb{N}$ I plugged this formula into the Taylor series for $\log(1+x)$ and ended up with: $f(x_0) = \sum\limits_{n=1}^\infty (-1)^{n+1} \cdot \frac{x^n}{n} + r_n$, which already looked quite promising. As the formula which I have to prove doesn't have that remainder $r_n$, I tried to show that $\lim_{n \to \infty} r_n = 0$, using Lagrange's remainder formula (for $x_0 = 0$ and $|x| < 1$). So now I basically showed that the formula was valid for $x \to x_0 = 0$. I also showed that the radius of convergence of this power series is $r = 1$, that is to say the power series converges $\forall |x| < 1$. What is bugging me, is the fact, that to my opinion, the formula is only valid for $x \to 0$. I mean sure, the radius of convergence is 1, but does this actually tell me that the formula is valid within $(-1,1)$? I've never done something like this before, thus the insecurity. I'd be delighted, if someone could help me out and tell me, whether the things I've shown are already sufficient or whether I still need to prove something.","['taylor-expansion', 'power-series', 'analysis']"
12062,How to prove this inequality without use of computers?,"With help from Maple, I got 
$$\left(\frac{ax+by+cz}{x-y}\right)^2+\left(\frac{ay+bz+cx}{y-z}\right)^2+\left(\frac{az+bx+cy}{z-x}\right)^2-(c-a)^2-(c-b)^2$$
equal to
$$\frac{(c(x^3+y^3+z^3)+(a-c)(x^2y+y^2z+z^2x)+(b-c)(x^2z+y^2x+z^2y)-3(a+b-c)xyz)^2}{(x-y)^2(y-z)^2(x-z)^2}$$ which of course is $\ge 0$. But with no help from a computer algebra, how would one prove:$$\left(\frac{ax+by+cz}{x-y}\right)^2+\left(\frac{ay+bz+cx}{y-z}\right)^2+\left(\frac{az+bx+cy}{z-x}\right)^2\ge (c-a)^2+(c-b)^2 ?$$","['inequality', 'calculus', 'contest-math']"
12063,A subtle relationship from class field theory,"Recently, I consider a problem: Let $E/F$ is a Galois extension of number field, denote the idele group of $E$ (resp $F$) by $I_E$ (resp $I_F$). There is a homomorphism induced by norm map $N_{E/F}$: $$N: I_E/E^{\ast} \to I_F/F^{\ast}$$ If there is a finite abel extension $K/E$ ,from Global Class Field Theory,there is an isomorphism called Artin map: $$A_K/E: I_E/E^{\ast} \text{Nm}(I_K) \to \text{Gal}(L/K)$$ If there is a subset $U$ of $I_E/E^{\ast}$ s.t $A_K/E(U) = 1$, where $1$ is the identity element of $\text{Gal}(K/E)$, So i really want know is there a special relationship between $U$ and the set $\text{Ker}(I_E/E{\ast} \to I_F/F^{\ast})$? Thanks!","['algebraic-number-theory', 'number-theory']"
12067,The product of $n$ consecutive integers is divisible by $ n!$ (without using the properties of binomial coefficients),"How can we prove, without using the properties of binomial coefficients, the product of $n$ consecutive integers is divisible by $n$ factorial?","['factorial', 'elementary-number-theory', 'divisibility', 'discrete-mathematics']"
12068,expectation of $ \left(\sum_{i=1}^n {x_i} \right)^2 $,"If $x_i$ is exponentially distributed $(i=1,...,n)$ with parameter $\lambda$ and $x_i$'s are mutually independent, what is the expectation of $\left(\sum_{i=1}^n {x_i} \right)^2$ in terms of $n$ and $\lambda$ and possibly other constants? Note: This question has gotten a statistical answer on https://stats.stackexchange.com/q/4959/2148 . The readers would take a look at it too.","['statistics', 'probability']"
12069,"Given a function $f(x)$ where $x$ is uniformly distributed between $a$ and $b$, how do I find the probability density function of $f$?","For example, if $f(x) = \sin x$ and $x$ is uniformly distributed on $[0, \pi]$, how is the equation found that satisfies the probability distribution function of $f(x)$? I imagine the distribution function will be greater when the derivative of $f(x)$ is closer to zero, but this is just a guess. I apologize if this question is vague or not advanced enough, but I can't find the answer anywhere.","['statistics', 'probability']"
12077,Closure of a subset in a metric space,"Let $(X,d)$ be a metric space and $S \subset X$. Show that $d_S(x):=\text{inf}\{d(x,s): s \in S\}=0 \Leftrightarrow x \in \overline S .$ Notes: $\overline S$ is the closure of S. Maybe you can use that a closed set is also closed for sequences in the set? I think the difficult part is when S is open, otherwise its trivial as the closure would be equal to S.","['general-topology', 'metric-spaces']"
12082,Field reductions,"If there is a field $F$ that is a field reduction of the real numbers, that is $F(a)=\mathbb{R}$ for some $a$, let's also denote this $F=\mathbb{R}(\setminus a)$, then given $x \in \mathbb{R}$ is there a general method to determine whether $x$ is in $F$ or $x$ is in $\mathbb{R}\setminus F$ ?","['abstract-algebra', 'field-theory']"
12084,The empty set and the cartesian product of two power sets,"The empty set is a member of $P(\{a,b\}) \times P(\{p,q\})$. True or false? My first instinct was false, since the empty set is a member of each power set individually, but when multiplied together, you get $(\emptyset,\emptyset)$, which I'm not sure represents the empty set. But my counter argument is that the empty set is a member of the power set of anything, right?",['elementary-set-theory']
12088,Real numbers and countability,"No subset of the real numbers is countable. True or false. In looking at the wikipedia article for real numbers, I'm not really clear on the answer to this. They use the words computable and countable, and I'm not sure of the difference. Also, I dont think I fully understand the term countable. The definition states that a set is countable if it has the same cardinality as some subset of the natural numbers, but I'm not sure what that means.","['real-numbers', 'elementary-set-theory']"
12093,Counting number of moves on a grid,"Imagine a two-dimensional grid consisting of 20 points along the x-axis and
10 points along the y-axis. Suppose the origin (0,0) is in the bottom-left corner and the
point (20,10) is the top-right corner. A path on the grid consists of a series of moves in
which each move is either one unit to the right or one unit up. Diagonal moves are not
allowed. How many diﬀerent ways are there to construct a path starting at (0,0) and
ending at (20,10)? I'm a little stuck on this one. I feel I'm headed towards the right direction, but I'm not sure if I'm doing this right. For every move, there are 2 possible choices. If we want to get to (20,10), then there are 200 points from the origin to this point. And I think order matters here, so we would use permutations, so I come up with 200 P 2, which is 39,800.","['permutations', 'discrete-mathematics', 'combinatorics']"
12097,Probability of the maximum (Levy Stable) random variable in a list being greater than the sum of the rest?,"Original post on Mathoverflow here . Given a list of identical and independently distributed Levy Stable random variables, $(X_0, X_1, \dots, X_{n-1})$, what is the is the probability that the maximum exceeds the sum of the rest?  i.e.: $$ M = \text{Max}(X_0, X_1, \dots, X_{n-1}) $$
$$ \text{Pr}( M > \sum_{j=0}^{n-1} X_j - M ) $$ Where, in Nolan 's notation, $X_j \in S(\alpha, \beta=1, \gamma, \delta=0 ; 0)$, where $\alpha$ is the critical exponent, $\beta$ is the skew, $\gamma$ is the scale parameter and $\delta$ is the shift.  For simplicity, I have taken the skew parameter, $\beta$, to be 1 (maximally skewed to the right) and $\delta=0$ so everything has its mode centered in an interval near 0. From numerical simulations, it appears that for the region of $0 < \alpha < 1$, the probability converges to a constant, irregardless of $n$ or $\gamma$.  Below is a plot of this region for $n=500$, $0< \alpha < 1$, where each point represents the result of 10,000 random draws.  The graph looks exactly the same for $n=100, 200, 300$ and $400$. For $1 < \alpha < 2$ it appears to go as $O(1/n^{\alpha - 1})$ (maybe?) irregardless of $n$ or $\gamma$.  Below is a plot of the probability for $\alpha \in (1.125, 1.3125)$ as a function of $n$.  Note that it is a log-log plot and I have provided the graphs $1/x^{.125}$ and $1/x^{.3125}$ for reference.  It's hard to tell from the graph unless you line them up, but the fit for each is a bit off, and it appears as if the (log-log) slope of the actual data is steeper than my guess for each.  Each point represents 10,000 iterations. For $\alpha=1$ it's not clear (to me) what's going on, but it appears to be a decreasing function dependent on $n$ and $\gamma$. I have tried making a heuristic argument to the in the form of: $$\text{Pr}( M > \sum_{j=0}^{n-1} X_j - M) \le n \text{Pr}( X_0 - \sum_{j=1}^{n-1} X_j > 0 )$$ Then using formula's provided by Nolan (pg. 27) for the parameters of the implicit r.v. $ U = X_0 - \sum_{j=1}^{n-1} X_j$ combined with the tail approximation: $$ \text{Pr}( X > x ) \sim \gamma^{\alpha} c_{\alpha} ( 1 + \beta ) x^{-\alpha} $$
$$ c_{\alpha} = \sin( \pi \alpha / 2) \Gamma(\alpha) / \pi $$ but this leaves me nervous and a bit unsatisfied. Just for comparison, if $X_j$ were taken to be uniform r.v.'s on the unit interval, this function would decrease exponentially quickly.  I imagine similar results hold were the $X_j$'s Gaussian, though any clarification on that point would be appreciated. Getting closed form solutions for this is probably out of the question, as there isn't even a closed form solution for the pdf of Levy-Stable random variables, but getting bounds on what the probability is would be helpful.  I would appreciate any help with regards to how to analyze these types of questions in general such as general methods or references to other work in this area. If this problem is elementary, I would greatly appreciate any reference to a textbook, tutorial or paper that would help me solve problems of this sort. UPDATE :  George Lowther and Shai Covo have answered this question below.  I just wanted to give a few more pictures that compare their answers to some of the numerical experiments that I did. Below is the probability of the maximum element being larger than the rest for a list size of $n=100$ as a function of $\alpha$, $\alpha \in (0,1)$.  Each point represents 10,000 simulations. Below are two graphs for two values of $\alpha \in \{1.53125, 1.875\}$.  Both have the function $ (2/\pi) \sin(\pi \alpha / 2) \Gamma(\alpha) n (( \tan(\pi \alpha/2) (n^{1/\alpha} - n))^{-\alpha} $ with different prescalars in front of them to get them to line up ( $1/4$ and $1/37$, respectively) superimposed for reference. As George Lowther correctly pointed out, for the relatively small $n$ being considered here, the effect of the extra $n^{1/\alpha}$ term (when $1 < \alpha < 2$) is non-negligible and this is why my original reference plots did not line up with the results of the simulations.  Once the full approximation is put in, the fit is much better. When I get around to it, I will try and post some more pictures for the case when $\alpha=1$ as a function of $n$ and $\gamma$.","['reference-request', 'probability', 'analysis']"
12098,Drawing heart in mathematica,"It's not really a typical math question. Today, while studying graphs, I suddenly got inquisitive about whether there exists a function that could possibly draw a heart-shaped graph. Out of sheer curiosity, I clicked on Google, which took me to this page . The page seems informative, and I am glad to learn certain new things! Now I am interested in drawing them by my own using Mathematica. So my question is: is it possible to draw them in Mathematica? If yes, please show me how.","['geometry', 'plane-curves', 'mathematica']"
12106,Factorial of a non-integer number,"My TI-83 calculator doesnt allow me to do this, but using Windows calculator, I can compute the factorial of say 5.8. What does this mean and how does it work?","['factorial', 'number-theory']"
12107,Is $\lim\limits_{n \to \infty}\frac{1}{n}\left( \cos{\frac{\pi}{n}} + \cos{\frac{2\pi}{n}} + \ldots + \cos{\frac{n\pi}{n}} \right)$ a Riemann sum?,"This is probably simple, but I'm solving a practice problem: $\lim_{n \to \infty}\frac{1}{n}\left( \cos{\frac{\pi}{n}} + \cos{\frac{2\pi}{n}} + \ldots +\cos{\frac{n\pi}{n}} \right)$ I recognize this as the Riemann sum from 0 to $\pi$ on $\cos{x}$, i.e. I think its the integral $\int_0^\pi{ \cos{x}dx }$ which is 0, but the book I'm using says it should be $ \frac{1}{\pi}\int_0^\pi{ \cos{x}dx }$ Still 0 anyway, but where did the $\frac{1}{\pi}$ in front come from?","['calculus', 'integration', 'limits']"
12122,Show that $V = \mbox{ker}(f) \oplus \mbox{im}(f)$ for a linear map with $f \circ f = f$,"Question: Let $V$ be a $K$-Vectorspace and $f: V \rightarrow V$ be linear. It holds that $f \circ f = f$. Show that $V = \mbox{ker}(f) \oplus \mbox{im}(f)$. My attempt: So i guess that the $\oplus$ denotes a direct sum which means i have to show that (i) $V = \mbox{ker}(f) + \mbox{im}(f)$ and (ii) $\mbox{ker}(f) \cap \mbox{im}(f) = \{0\}$. I tried to do (ii) first: Let $v \in \mbox{im}(f) \cap \mbox{ker}(f)$ $\Rightarrow \exists u: f(u)=v \wedge f(v) = 0$ (can i put a ""Rightarrow"" here?) $(f \circ f)(u)=f(f(u)) = f(v) = 0$ As for (i) i am having difficulty with an approach to showing that $V = \mbox{ker}(f) + \mbox{im}(f)$. Should I even be trying to do this in the first place? if so, any advice as to how?",['linear-algebra']
12132,Finding the inverse of a matrix via the adjugate and the determinant,"Let's consider a $3 \times 3$ matrix, $\bf A$ . Its inverse can be found by computing the adjoint of the matrix and dividing it by its determinant. Can someone please explain why this process work and how it can be visualized? I know that the determinant can be thought of as the volume spanned by the column vectors and that the adjoint of matrix $\bf A$ is $\bf A^\top$ 's cofactors. The cofactors of the matrix $\bf A$ can be found by the cross product of each of its column vectors. So what does the cofactor matrix tell us?","['matrices', 'linear-algebra', 'inverse', 'determinant']"
12139,Number of relations that are both symmetric and reflexive,"Consider a non-empty set A containing n objects. How many relations on A are both symmetric and reflexive? The answer to this is $2^p$ where $p=$ $n \choose 2$. However, I dont understand why this is so. Can anyone explain this?","['relations', 'discrete-mathematics', 'combinatorics']"
12160,Roots of Legendre Polynomial,"I was wondering if the following properties of the Legendre polynomials are true in general. They hold for the first ten or fifteen polynomials. Are the roots always simple (i.e., multiplicity $1$)? Except for low-degree cases, the roots can't be calculated exactly, only approximated (unlike Chebyshev polynomials). Are roots of the entire family of Legendre Polynomials dense in the interval $[0,1]$ (i.e., it's not possible to find a subinterval, no matter how small, that doesn't contain at least one root of one polynomial)? If anyone knows of an article/text that proves any of the above, please let me know.  The definition of these polynomials can be found on Wikipedia .","['legendre-polynomials', 'special-functions', 'roots', 'orthogonal-polynomials', 'real-analysis']"
12163,Calculate $\lim\limits_{y\to{b}}\frac{y-b}{\ln{y}-\ln{b}}$,"How can we find $\displaystyle \lim_{y\to{b}}\frac{y-b}{\ln{y}-\ln{b}}$ without using: (a) L'Hôpital's rule, (b) the limit $\displaystyle \lim_{h \to 0}\frac{e^h-1}{h} = 1$, and (c) the fact that $\displaystyle \frac{d}{dx}\left(e^x\right) = e^x$. The reason for the conditions is that with this limit I'm trying to prove (c), and I've done so with (b) and I gather it would be circular to use (a). So that's that. Also, I would appreciate if you could share one or more ways of proving that the derivative of $e^x$ is $e^x$. Thanks a lot for your time.","['calculus', 'limits']"
12166,Numbers of circles around a circle,"""When you draw a circle in a plane of radius $1$ you can perfectly surround it with $6$ other circles of the same radius."" BUT when you draw a circle in a plane of radius $1$ and try to perfectly surround the central circle with $7$ circles you have to change the radius of the surround circles. How can I find the radius of the surround circles if I want to use more that $6$ circles? ex :
$7$ circles of radius $0.4$ $8$ circles of radius $0.2$","['geometry', 'circles']"
12167,The set of rationals has the same cardinality as the set of integers,"The set of rationals $\mathbb{Q}$ has the same cardinality as
the set of integers $\mathbb{Z}$. True or false? This was a question on an old exam for our class. The correct answer is true. However, I did some additional reading and came across Cantor's transfinite numbers. In the book I'm reading, it says that ""there are more real numbers (which include rational and irrational numbers) than there are integers"". So can it also be said that there are more rational numbers than integers? And so can we say that the above statement is false?","['integers', 'elementary-set-theory', 'rational-numbers']"
12179,How to diagonalize a large sparse symmetric matrix to get the eigenvalues and eigenvectors,"How does one diagonalize a large sparse symmetric matrix to get the eigenvalues and the eigenvectors? The problem is the matrix could be very large (though it is sparse), at most $2500\times 2500$. Is there a good algorithm to do that and most importantly, one that I can implement it into my own code? Thanks a lot!","['matrices', 'linear-algebra', 'algorithms', 'numerical-methods']"
12205,"The greatest common divisor $\gcd(x_1x_2\pm y_1y_2, x_1y_2\mp x_2y_1)$","I wonder if someone could shed some light in the following question Let $(x,y)$ denote the greatest common divisor of $x$ and $y$, and let $x_1,y_1,x_2,y_2$ be integers. Is  the following statement true? If $(x_1,y_1)=(x_2,y_2)=(x_1^2+y_1^2,x_2^2+y_2^2)=1$, then $$(x_1x_2\pm y_1y_2, x_1y_2\mp x_2y_1)=1$$ If not, what further hypotheses are necessary to guarantee the claim? Thanks in advance,
Guillermo","['elementary-number-theory', 'number-theory']"
12213,Can a collection of subsets of $\mathbb{N}$ such that no one set contains another be uncountable?,"Let C be a collection of subsets of $\mathbb{N}$ such that $A,B\in C \Rightarrow A \not\subseteq B$. Can C be uncountable?",['elementary-set-theory']
12220,Symmetrize eigenvectors of degenerate (repeated) eigenvalue,"I have a Hermitian matrix $A$ that satisfies some symmetries which I can express via $AS = SA$ for a unitary matrix $S$ . Now I am interested in the eigenvectors of $A$ , but I want that these eigenvectors also respect my symmetries ( compare to Bloch waves in physics where the eigenvectors are chosen to reflect the translational invariance of the lattice). Since $A$ has degenerate (repeated) eigenvalues, the standard numerical techniques will return some arbitrary (yet orthonormal) eigenvectors spanning the eigenspace. I, however, want to obtain unique results and thus want to make use of the symmetries. How can I do this numerically? I know that commuting matrices can be diagonalized simultaneously - in theory. But I don't know how to do it practically. Would I have to diagonalize one of them, apply the unitary transform thus obtained to the other one, arriving at a block diagonal form where I then have to diagonalize each block separately? Or is there something more elegant I can do? EDIT: The matrix is dense, but quite small (12x12 to 18x18). The symmetry would be something like translation symmetry: $$\begin{pmatrix} 0 & 0 & 0 & -1 \\ 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0  & 0 & 1 & 0 \end{pmatrix}$$ where each entry is a 3x3-block in the case of a $12 \times 12$ matrix, which looks something like $$\begin{pmatrix} a & b & 0 & -b\\ b&a&b&0\\ 0&b&a&b\\ -b&0&b&a\end{pmatrix}$$","['numerical-linear-algebra', 'matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
12237,How do I determine if my variance is significant?,"For a given group of data, I have both a mean and variance (already calculated). Looking over the raw spread of data, and its numerous outliers, I expect that variance will be high. My question is -- now that I have my variance calculated, what do I need to compare it to to determine if the variance is significant (i.e., indicative of highly skewed data)?",['statistics']
12238,A relation between permanents and determinants,"I have skimmed this video that I found on mathoverflow: http://tube.sfu-kras.ru/video/407?playlist=397 At about 15:05 the lecturer wrote down an equality
$\sum F(m_1, \ldots, m_m)z^{m_1}\ldots z^{m_m} = \frac{1}{det(zI - A)}$, where F is given in terms of coefficients of the $m$-by-$m$ matrix $A$. The definition of $F$ doesn't yet make much sense to me, but that's beyond the point. My question is, how is this equality possible? the right hand side obviously has poles—the eigenvalues of $A$, but the left hand side is just a polinomial, it can't have poles! Is there something I'm missing? EDIT: well, it was actually
$\sum F(m_1, \ldots, m_m) z_1^{m_1}\ldots z_m^{m_m} = \frac{1}{det(z - A)}$.
Here I have abused the notation slightly: the z means actually the diagonalization of the corresponding vector. However, when you take $z_1 = \ldots = z_m$, the question still stands. The domain is real, as I understand from the context of the lecture :), so the use of the term pole isn't really correct, I just forgot the right word in English :)","['abstract-algebra', 'linear-algebra', 'real-analysis']"
12239,Indefiniteness of KKT system,"I know this is a trivial problem but am stuck with this thing. $A \in \mathbb{R}^{m \times m}$ is a symmetric positive definite matrix and $C \in \mathbb{R}^{m \times p}$ How do I show that the matrix $$B = \begin{bmatrix} A & C \\ C^T & 0 \end{bmatrix}$$ is indefinite? I can show that there exists a vector $v$ such that $v^TBv > 0$.
(This is trivial. For instance, $v = [x , 0]^T$ where $x \in \mathbb{R}^{1 \times m}$ and $0 \in \mathbb{R}^{1 \times p}$) Now how do I find a vector such that $v^TBv < 0$. I do not need the answer. A clue/hint is welcome. You can assume that $p \leq m$ and the matrix $C$ is full rank that is to say that all the constraints are linearly independent. Thanks","['optimization', 'linear-algebra']"
12240,Stuck at the proof of the existence of the partial fraction expansion,"Let $P$ and $Q$ be complex polynomials with $deg(P) < deg(Q)$. Let $Q(z) = (z-z_1)^{k_1} (z-z_2)^{k_2}...(z-z_m)^{k_m}, z_i \in \mathbb{C} \text{ and } k_i \in \mathbb{N}$ be a complete decomposition. Then, I have to prove that there exists a unique exposition of the following form: $\frac{P(z)}{Q(z)} = \sum\limits_{i=1}^m \sum\limits_{j=1}^{k_i} \frac{a_{ij}}{(z-z_i)^j}, a_{ij} \in \mathbb{C}$ I started with the proof of the uniqueness of this exposition and succeeded. However, I don't feel like I am doing well now, while trying to prove its existence. Basically, I want to do two inductions: First I want to do an induction over $deg(Q)$ with $deg(P) = 0$, then I want to go on with an induction over $deg(P)$ with an arbitrary $deg(Q)$. The start of the first induction is easy, but I can't get to an end at the induction step. I have something like: $\frac{P}{Q} = \frac{P}{(z-z*)Q'} = \frac{1}{z-z*} \frac{P}{Q'}$, where $Q'$ is a polynomial with $deg(Q') = n$. What do I do next? I know that a unique exposition exists for the latter fraction and if $z* = z_i$ for some $i$, it's proven I guess. But what if this $z*$ is a completely new complex number?",['analysis']
12255,Terminology - Nth rule,"I'm trying to help my son study 8th grade math (in Texas).  He's having trouble with the ""Nth rule"".  Is anyone familiar with this terminology?  I think that it may be related to the Nth term in a series, but I also think that it has a more specific meaning.","['sequences-and-series', 'terminology']"
12256,Tetrahedron inside a sphere,What's the largest regular tetrahedron (having side length $x$) you can fit inside a sphere with a unit radius?,"['geometry', 'polyhedra']"
12273,Minimum multi-subset sum to a target,"This is some sort of standard puzzle, which many do it using trial and error or brute-force method. The question goes like this, given the numbers, 11,13,31,33,42,44,46 what is choices of numbers (a number can be chosen more than once) so that sum adds up to 100. Is there a formula like way or approach to this other than brute force only?",['combinatorics']
12274,stationary non-isotropic spatial stochastic processes,"Are there any interesting examples of second order stationary processes on ${\mathcal R}^2$ or ${\mathcal R}^3$ that are not isotropic? The book I am looking at has no examples. Update : I asked this question in mathoverflow, apparently such examples are not easy to come by. Update: Processes with anisotropic variograms are examples of non-isotropic stationary processes.","['probability-theory', 'statistics']"
12275,"Writing $f(x,y)$ as $\Phi(g(x) + h(y))$","Could you prove or disprove the following statement? Let 
  $f\colon[0,1]^2\rightarrow \mathbb R$ 
  be a continuous function.  Then
  there are continuous functions 
  $g,\ h\colon [0,1]\rightarrow \mathbb R$ and
  $\Phi\colon \mathbb R \to \mathbb R$
  such that  $$ f(x,y) = \Phi(g(x) + h(y)).$$ (This problem popped up in my mind while I was thinking about this related one on MO.  I couldn't find an easy proof or a disproof. This version is much weaker than the one asked at MO, since $g$ and $h$ do depend on $f$ here.)",['real-analysis']
12276,Is there any connection between Green's Theorem and the Cauchy-Riemann equations?,"Green's Theorem has the form: 
$$\oint P(x,y)dx = - \iint \frac{\partial P}{\partial x}dxdy , \oint Q(x,y)dy = \iint \frac{\partial Q}{\partial y}dxdy $$
The Cauchy-Riemann equations have the following form:(Assuming $z = P(x,y) + iQ(x,y)$)
$$\frac{\partial P}{\partial x} = \frac{\partial Q}{\partial y}, \frac{\partial P}{\partial y} = - \frac{\partial Q}{\partial x}$$ Is there any connection between this two equations?","['greens-theorem', 'multivariable-calculus', 'cauchy-riemann-equations', 'complex-analysis']"
12287,"Approaching to zero, but not equal to zero, then why do the points get overlapped?","It is my question when I was in Senior High School. Up to now, I have no idea about the correct explanation. I just accept it by faith :D Here  is the question: If the symbol $\Delta x \to 0$ does not mean $\Delta x =0$, how can the points $A$ and $B$ get overlapped which in turn, how can the line joining $A$ and $B$ become $C$, the tangent line to the curve $y=f(x)$ at point $A$? Thank you in advance.",['calculus']
12291,System of parameters which have linear independent images in the cotangent space,"Given a Noetherian, local ring $(R,m)$, can we always find a system of parameters whose images in the cotangent space $m/m^2$ are linearly independent? We can do this in the regular case, by just choosing a basis for the cotangent space and looking at their preimages in $m$ under the canonical map. By Nakayama's lemma these generate $m$ and hence form a system of parameters. Can we do this for any general Noetherian, local ring?","['commutative-algebra', 'algebraic-geometry']"
12299,Help solving a differential equation,"my Calculus II class is nearing the end of the quarter and we've just started differential equations to get ready for Calculus III. In my homework, I came upon these problems. One of the problems was: Find the general solution to the differential equation 
$$\frac{dy}{dt} = t^3 + 2t^2 - 8t.$$ The teacher just said to integrate. So I did. Then in question 8a it gives the differential equation: $$\frac{dy}{dt} = y^3 + 2y^2 - 8y.$$ and asks ""Why can't we find a solution like we did to the previous problem? My guess was: ""In 7 we were integrating with respect to t. Since this equation is the highest order derivative, we can't solve it like # 7"". Although, I have no confidence in that answer and I'm not sure it makes total sense even to me. Also, part 8B. asks: Show that the constant function $y(t) = 0$ is a solution. I've done a problem like this before, except that it wasn't a constant function. This problem seems like a question that asks: ""show that every member of the family of functions $y = (\ln x + C)/x$ is a solution to the differential equation (some diff. equation)"" except it seems a little bit different. Any hints on how I can solve this? Thank you.",['ordinary-differential-equations']
12307,How to calculate $\lim_{x \to \infty} \left ( \frac{x+2}{x} \right )^{x}=e^{2}$,"I know from an online calculator http://www.numberempire.com/derivatives.php that 
$\lim_{x \to \infty} \left ( \frac{x+2}{x} \right )^{x}=e^{2}$.  How do you calculate this step by step?","['exponential-function', 'calculus', 'limits']"
12314,Examples of manifolds that cannot be embedded in $\mathbb R^4$,"Could someone give me an example of a (smooth) $n$-manifold $(n=2, 3)$ which cannot be embedded (or immersed) in $\mathbb R^4$? Thanks in advance! S. L.","['general-topology', 'differential-topology']"
12316,What is the name of the matrix used to weight an inner product?,"In Linear Algebra, when computing an inner product $<x,y> = y^*Wx$, what is the name of the matrix W? If it doesn't have a name, where can I find a practical explanation of how to construct it for a particular problem or space? Is there a text on the subject that explains this simply? A note on my background, I am approaching this from the perspective of an engineering student and not that of a mathematician; I don't have an understanding of the finer points of topology or differential geometry (not yet at least :) ). I believe that this is the same matrix used in vector calculus to perform a change of variables. As in, we perform our change of variables, then multiply the new expression by $\frac{det(J(W))}{det(J(V))}$ where $W$ is this magic matrix in the new space, $V$ is this magic matrix the old space, and J(X) is the Jacobian operator.  Am I correct? Also, is this related to one of the the matrices that comes up in Singular Value Decomposition (namely the diagonal matrix containing the singular values)?","['linear-algebra', 'inner-products', 'terminology', 'differential-geometry']"
12320,"Proof that if group $G/Z(G)$ is cyclic, then $G$ is commutative [duplicate]","This question already has answers here : If $G/Z(G)$ is cyclic, then $G$ is abelian (4 answers) Closed 9 years ago . I am looking for a correct proof of this statement: If $G$ is a group such that $G/Z(G)$ is cyclic, then $G$ is commutative. Proof: $G/Z(G)$ is isomorphic to $\operatorname{Inn}(G)$ and is cyclic, and then for every $a$ and $b$ in $G$ the inner isomorphisms $\gamma_a$ and $\gamma_b$ satisfy $\gamma_a \gamma_b = \gamma_{ab} = \gamma_{ba} = \gamma_b \gamma_a$, and therefore for every $a,b \in G$, $ab = ba$. Is that proof complete, or am I missing something? Thanks a lot for the help.",['group-theory']
12322,How to prove DeMorgan's law?,"How to prove DeMorgan's Law? $$A - (B \cup C) = (A - B) \cap (A - C)$$
$$A - (B \cap C) = (A - B) \cup (A - C)$$ EDIT : Here is what I have tried so far: Considering the first equation, assuming $x \in A - (B \cup C)$ then $x \in A$ and $x \not\in B$ and $x \not\in C$, while the right hand means ($x \in A$ and $x \not\in B$) or ($x \in A $ and $x \not\in C$) which is the same as $x \in A$ and $x \not\in B$ and $x \not\in C$. So the two set is the same. But I do not know whether this is sufficient for a proof. Am I wrong?",['elementary-set-theory']
12328,RSA: Fast factorization of N if d and e are known,"I stumbled across this paragraph in a paper: Hence, user b cannot decrypt C
  directly. But using e and d , user b
  can quickly factor N. How is  it possible to speedup the prime factorization when knowing e (public key) and d (private key)? For clarification: RSA provides us with these equations: $n = pq$ $\phi = (p-1)(q-1)$ $gcd(e, \phi) = 1$ $de = 1\pmod{\phi}$ In order to determine $p$ and $q$ an attacker has to factor n which is not feasible. However the paper stated that it is easy to reconstruct $p$ and $q$ when a person knows both (his) private and public keys.","['cryptography', 'number-theory']"
12329,How to find finite groups,"How possible methods for finding groups of given order we have? Sylow theorems - and next? We know something about center of group, about possible orders of these elements and subgroups. But what is most effective way, to find all non-isomorphic groups of given order? Is there any other strong ""weapon"" for this (like Sylow theorems)? For example, I took groups order 15. Commutative group is only $\mathbb{Z}_{15}$. About non-commutative we know, they have 1 Syllow 3-subgroup and 1 Syllow 5-subgroup. And next, that $M_3 \cup M_5 = G$ (if $M_3$, resp. $M_5$ is Syllow 3-subgroup, resp. Syllow 5-subgroup). $M_3$ and $M_5$ are single generated, than we can choose elements $f$ and $g$ satysfaing $<f>=M_3$ and $<g>=M_5$. Because there are characterictis, we get these equations: $f^{-1}gf=g^m$, where $m \in \{1,2,3,4\}$ and $g^{-1}fg=f^n$, where $n \in \{1,2\}$. $m$ and $n$ must supplying $|g|=|g^m|$ and $|f|=|f^n|$. But there is end of my way, i don't know how continue... Can anyone help? (Sorry for bad English)",['group-theory']
12331,Help understanding the definition of tangent vector or tangent plane?,"Here is what my textbook told me: Assuming the formula for surface $\Sigma$ is $$F(x,y,z) = 0$$ 
Suppose $X_0 = (x_0, y_0, z_0)$ is a point on the surface $\Sigma$ and we assuming F(x,y,z) is differentiable and $$\mathbf{J}F(X_0) = (\frac{\partial F(X_0)}{\partial x}, \frac{\partial F(X_0)}{\partial y}, \frac{\partial F(X_0)}{\partial z}) \neq 0$$ 
Draw a line $\Gamma$ in the surface $\Sigma$ passing through the point $X_0$, assuming the equations for $\Sigma$ is $$x = x(t), y = y(t), z = z(t)$$  $t = t_0$ correspond to the point $X_0$ and $x'(t_0), y'(t_0), z'(t_0)$ does not all vanish. Because of the line $\Gamma$ is on the surface $\Sigma$, so $$F(x(t), y(t), z(t)) = 0$$ So $$ \frac{dF}{dt}\mid_{t=t_0} = {F_x}'(X_0)x'(t_0) + {F_y}'(X_0)y'(t_0) + {F_z}'(X_0)z'(t_0) = 0 $$ So $$ ({F_x}'(X_0), {F_y}'(X_0), {F_z}'(X_0))\cdot(x'(t_0), y'(t_0), z'(t_0)) = 0 $$ We know the vector $\mathbf{T} = (x'(t_0), y'(t_0), z'(t_0))$ is the tangent vector for the line $\Gamma$ on the point $X_0$ My questions are Why the vector $\mathbf{T}$ is the tangent vector for line $\Gamma$ at point $X_0$? Why the $\mathbf{J}F(X_0)$ should not equal to zero? What if it is zero? Why $x'(t_0), y'(t_0), z'(t_0)$ should not all vanish? What if all vanish?","['geometry', 'calculus']"
12340,What is limit of $\sum \limits_{n=0}^{\infty}\frac{1}{(2n)!} $?,"What is the limit of the series $1 \over (2n)!$ for n in $[0, \infty)$ ? $$ \sum_{n = 0}^{\infty}{1 \over (2n)!}$$
I've ground out the sum of the 1st 1000 terms to 1000 digits using Python,
(see here ), but how would a mathematician calculate the limit? And what is it? No, this isn't homework. I'm 73. Just curious. Thanks",['sequences-and-series']
12348,probability of getting 50 heads from tossing a coin 100 times,"folks, i am new to this forum and not a math expert. so please bear with me if am asking silly questions. The question is ""probability of getting 50 heads from tossing a coin 100 times"". So the answer for this is, I guess, ${100 \choose 50} (2 ^{-100})$. So all am trying to get is easier way to calculate ${100 \choose 50}$, or another approach to the parent problem only. Thanks all, appreciate that. raj",['probability']
12356,Conditions for existence of divergence of a vector field,"What are the necessary and sufficient conditions on a vector field $F$ for the divergence $\nabla\cdot F$ to exist at a given point. EDIT In Divergence in the second line under the heading "" Application in Cartesian coordinates "", why is it assumed that $\vec{F}$ to be a continuously differentiable vector field ? EDIT 2 Ideally one would expect each component of $F$ to be differentiable at a given point $\vec{a}$ no matter through which continuous contour you traverse the point $\vec{a}$. EDIT 3 Or is it that each component of $F$ to be differentiable and the derivative being continuous at a given point $\vec{a}$ no matter through which continuous contour you traverse the point $\vec{a}$.",['multivariable-calculus']
12381,Explicit examples of functions with flow?,"Let's say that $f(x)=f^{1}(x)$ and that $f(f(x))=f^{2}(x)$. Moreover, $f^{n}(x)$ is the n-th iterate of $f(x)$, for $n \in \mathbb{N}$. I'm curious about extending iteration to larger number sets. For $n \in \mathbb{R}$, there's the concept flow (I think?). I don't understand the Wikipedia-article on this subject very well, though. I was hoping for some nice, concrete examples of iterated functions extended to the real or even complex numbers with which I might understand things better. If we take $f(x) = x^2 +3$, for example, what would $f^{\sqrt(2)}(x)$ be? Or, even more ambitiously, say that $g(x)=e^x$ How do we find $g^{\pi^2 + 3i}(x)$? Thanks, Max Muller Editorial to the moderators: perhaps this should be CW?","['functional-analysis', 'big-list']"
12382,Relative Cohomology Isomorphic to Cohomology of Quotient,"Given a topological space (with nice enough conditions, maybe Hausdorff, compactly generated, or CW complex, I'm not sure) $X$ and a subspace $A\subset X$, is it true that $H^n(X,A)\cong H^n(X\backslash A)$ whenever there is an open set containing $A$ which can be retracted to $A$?  Can this be shown easily using the Mayer-Vietoris Sequence, or something else similar to that? (I'm basically assuming simplicial or singular cohomology here, with integer coefficients.)","['general-topology', 'algebraic-topology']"
12383,Determine the matrix relative to a given basis,"Question: (a) Let $f: V \rightarrow W$ with $ V,W \simeq \mathbb{R}^{3}$ given by: $$f(x_1, x_2, x_3) = (x_1 - x_3, 2x_1 -5x_2 -x_3, x_2 + x_3).$$ Determine the matrix of $f$ relative to the basis $\{(0,2,1),(-1,1,1),(2,-1,1)\}$ of $V$ and $\{(-1,-1,0),(1,-1,2),(0,2,0)\}$ of $W$. (b) Let $n \in \mathbb{N}$ and $U_n$ the vector space of real polynomials of degree $\leq n$. The linear map $f: U_n \rightarrow U_n$ is given by $f(p) = p'$. Determine the matrix of $f$ relative to the basis $\{1,t,t^{2},...,t^{n}\}$ of $U_n$. My attempt so far: 
(a): First relative to the bases of $W$ I found the coordinates of an arbitrary vector: $\left( \begin{array}{r} a \\ b \\ c \end{array} \right) = x \left( \begin{array}{r} -1 \\ -1 \\ 0 \end{array} \right) + y \left( \begin{array}{r} 1 \\ -1 \\ 2 \end{array} \right) + z \left( \begin{array}{c} 0 \\ 2 \\ 0 \end{array} \right)$ $\begin{array}{l} a = -x + y \\ b = - x - y + 2z \\ c = 2y \end{array}$ or $\begin{array}{l} x = -a + \frac{1}{2}c \\ z = -\frac{1}{2}a + \frac{1}{2}b + \frac{1}{2}c \\ y = \frac{1}{2}c \end{array}$ At this point I believe I have the linear combinations of the given basis in $W$ for an arbitrary vector, so next I take the vectors from $V$ and send them to $W$ using the given function: $\begin{array}{l} f(v_1) = f(0,2,1) = (-1,-11,3) = (1 + \frac{3}{2})w_1 + \frac{3}{2}w_2 + (\frac{1}{2} - \frac{11}{2} + \frac{3}{2})w_3 \\ f(v_2) = f(-1,1,1) = (-2,-8,2) = (2+1)w_1 + w_2 + (1 - 4 +1)w_3 \\ f(v_3) = f(2,-1,1) = (1,8,0) = w_1 + (-\frac{1}{2} + 4)w_3 \end{array}$ or $\left( \begin{array}{rrc} \frac{5}{2} & 3 & 1 \\ \frac{3}{2} & 1 & 0 \\ -\frac{7}{2} & -2 & \frac{7}{2}\end{array} \right)$ Was I taking the correct steps? I didn't really do anything differently based on the fact that $V,W$ were isometric... Is there a particular significance or interpretation for the resulting matrix? (b): Not really sure here... $f(p) = p'$ would it make sense to write something like: $f(1,t,t^{2},\dots, t^{n}) = (0,1,2t, \dots, nt^{n-1})$? and if a basis for $(1,t,t^{2},\dots, t^{n})$ would be $A = \left( \begin{array}{ccccc} 1 & 0 & 0 & \cdots & 0 \\ 0 & 1 & 0 & \cdots & 0 \\ 0 & 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\0 & \cdots & \cdots & 0 & 1 \end{array} \right)$ could i write: $A' =  \left( \begin{array}{ccccc} 0 & 0 & 0 & \cdots & 0 \\ 1 & 0 & 0 & \cdots & 0 \\ 0 & 1 & 0 & \cdots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\0 & 0 & 0 & 1 & 0 \end{array} \right)$?","['matrices', 'linear-algebra']"
12394,Given a radius and velocity calculate position of an aircraft banking to make a turn,"I have a radius, R , for an aircraft traveling at velocity, V . If we start at point, (X,Y) , what is the position of the point at time, t . For example: The aircraft is at point (0,0) and traveling at 250 knots and initiates a turn with a bank angle, phi, of 5 degrees. Assume that the aircraft can instantaneously rotate to the five degree bank. The equation for the turn radius, R where g is the acceleration due to gravity (9.81) is:
\begin{equation}
\text{R} = \frac{V^2}{\text{g} \tan{\phi}}
\end{equation} For this example, R = 10.4 nautical miles. Where is the aircraft at t = 2 if the aircraft is traveling at a heading of 90 degrees (straight along the y axis)?","['geometry', 'physics']"
12400,"$\operatorname{Stab}(x_1)$ in $\text{Aut}( F(x_1,\ldots,x_n ) )$","Let $F_n$ be an $n$-generator free group with a free basis $x_1,\ldots,x_n.$ Is it true that the stabilizer of $x_1$ in $\mathrm{Aut}(F_n)$ is generated by all left and right Nielsen moves $\lambda_{ij}$ and $\rho_{ij}$ such that $i \ne 1$ and by the element of order two $\epsilon_n$ such that $\epsilon_n(x_n)=x_n^{-1}$ while other elements of the basis remain fixed. Let $i \ne j$ and $1 \le i,j \le n.$ The left Nielsen move $\lambda_{ij}$ takes $x_i$ to $x_j x_i$ and the right Nielsen move $\rho_{ij}$ takes $x_i$ to $x_i x_j;$ both $\lambda_{ij}$ and $\rho_{ij}$ fix all $x_k$ with $k \ne i.$",['group-theory']
12410,Particle moving at constant speed with Poisson setbacks,"Consider a particle starting at the the origin and moving along the positive real line at a constant speed of 1.  Suppose there is a counter which clicks at random time intervals following the exponential distribution with parameter $\lambda$ and whenever the counter clicks, the position $x > 0$ of the particle at that time instantaneously changes to the position $x/2$.  We wish to calculate the expected average speed of the particle. I don't really have any idea of how to go about solving this.  Here are a couple of related problems which seem even more difficult to me: Modify the puzzle so that when the counter clicks, the particle moves from $x$ to a point chosen uniformly at random from $[0,x]$. The particle starts moving as above but whenever the counter clicks, its speed increases by 1 (the initial speed was 1).  What is the expected time when the particle hits the position 1?  What is the expected speed when the particle hits the position 1? This is not a homework problem.  Any solutions, hints, thoughts will be appreciated. Thanks,","['puzzle', 'probability']"
12413,Is there an empty set in the complement of an empty set?,Currently taking a logic class and trying to understand this. You have two set $A$ and $B$. Both sets are empty sets. Is set $A$ a subset of the complement of set $B$? Assume the context is the universal set.,['elementary-set-theory']
12416,Recurrence relation satisfied by $\lfloor(1+\sqrt{3})^n\rfloor$,"This is a follow up to a question I had asked earlier about a linear recurrence relationship satsified by $\lfloor(1+\sqrt{5})^n\rfloor$. I messed up there, and I actually meant to ask about $L(n)=\lfloor(1+\sqrt{3})^n\rfloor$. Following Douglas' suggestion I have determined that the values (at least the first 1000) satisfy the following recurrence: $L(2n+5)=8L(2n+3)-4L(2n+1)$ The question is how do I prove something like this. I can prove the recurrence for the values inside the floor function, but floor function in general does not commute with addition and multiplication. Explicitly, it's easy to show $(1+\sqrt{3})^{2n+5}=8(1+\sqrt{3})^{2n+3}-4(1+\sqrt{3})^{2n+1}$ but I am not sure how to prove the recurrence from here.",['discrete-mathematics']
12423,Supremum length of space curves contained in the open unit ball having always less than unity curvature,"I am in the process of proving that if a space curve (in $R^3$) has infinite length and the curvature tends towards $0$ as the natural parameter $s$ tends to infinity, the curve must be unbounded - i.e. not contained in any sphere of finite radius. This seems correct intuitively, but I have no guarantee it is correct, unless I am missing something obvious. One way to prove my hunch, I have deduced, is to use a lemma that any curve contained in the open unit ball with curvature always less than one must have a finite upper bound on its length (possibly $2π$, but it could be greater for all I know). How might one go about proving such an upper bound exists, or if it exists? It might also be nice to know what the bound specifically is, too. I've thought it might be possible to pose this as a variational problem - maximizing length - and then reducing it into a simpler problem, but that appears to be hellishly complicated. Thoughts?","['calculus-of-variations', 'differential-geometry']"
12433,Probability of dice sum just greater than 100,"Can someone please guide me to a way by which I can solve the following problem.
There is a die and 2 players. Rolling stops as soon as some exceeds 100(not including 100 itself). Hence you have the following choices: 101, 102, 103, 104, 105, 106. 
Which should I choose given first choice. 
I'm thinking Markov chains, but is there a simpler way? Thanks. EDIT: I wrote dice instead of die. There is just one die being rolled","['game-theory', 'probability']"
12439,"What does $H=GL(2,\mathbb{R})/(Z(GL(2,\mathbb{R}))\cdot O(2,\mathbb{R}))$ mean?","Let $H=\left\{ z\in\mathbb{C}\mid\Im\left(z\right)>0\right\}$  be the upper-half Poincare plane. Let $GL\left(2,\mathbb{R}\right)$ be the general linear group, $Z\left(GL\left(2,\mathbb{R}\right)\right)$ be the center of the general linear group and $O\left(2,\mathbb{R}\right)$ be the orthogonal subgroup of $GL\left(2,\mathbb{R}\right)$. What does it mean to say $H=GL\left(2,\mathbb{R}\right)/\left(Z\left(GL\left(2,\mathbb{R}\right)\right)\cdot O\left(2,\mathbb{R}\right)\right)$? The left-hand side is a metric space and the right hand side is a set of cosets of $GL\left(2,\mathbb{R}\right)$. So I'm confused about what it means to write that they are equal or to say ""the upper half plane is..."" It seems like this would be the group of orientation preserving isometries of H, but I still find the terminology confusing. I've been trying to figure out what this could possibly mean, but my searches on the internet have not been fruitful. I've also looked at 2 sources on standard modular groups but they make no mention of this fact. An explanation or reference would be greatly appreciated. Motivation: I am reading a paper titled ""On Modular Functions in characteristic p"" by Wen-Ch'ing Winnie Li which can be found at http://www.jstor.org/stable/1997973 . The claim appears on page 3 of the pdf (page 232 of the journal). It is also stated on the wikipedia page: http://en.wikipedia.org/wiki/Poincar%C3%A9_half-plane_model","['geometry', 'reference-request', 'group-theory']"
12442,"How is $\operatorname{GL}(1,\mathbb{C})$ related to $\operatorname{GL}(2,\mathbb{R})$?","I am trying to get a grasp on what a representation is, and a professor gave me a simple example of representing the group $Z_{12}$ as the twelve roots of unity, or corresponding $2\times 2$ matrices. Now I am wondering how $\operatorname{GL}(1,\mathbb{C})$ and $\operatorname{GL}(2,\mathbb{R})$ are related, since the elements of both groups are automorphisms of the complex numbers. $\operatorname{GL}(\mathbb{C})$, the group of automorphisms of C, is (to my understanding) isomorphic to both $\operatorname{GL}(1,\mathbb{C})$ and $\operatorname{GL}(2,\mathbb{R})$ since the complex numbers are a two-dimensional vector space over $\mathbb{R}$. But it doesn't seem like these two groups are isomorphic to each other.","['lie-groups', 'representation-theory', 'group-theory']"
12447,Closure Operation on a Uniform Topology,"I started reading about uniform spaces in Bourbaki, and the closure operation has been defined as such: $$\bar{A}=\bigcap_{V\in\mathcal{U}}V(A)$$ Where $\mathcal{U}$ is the uniform structure of the space, and $V(A)$ is the set of all left-relatives of $A$. One thing I don't understand is why $\bar{A}=\bar{\bar{A}}$, as is necessary for a closure operation. In particular, I don't see why $\bar{\bar{A}}\subseteq\bar{A}$. After playing around with it for a while, I have this. Take some $s\in\bar{\bar{A}}$. So $s\in V(\bar{A})$ for all $V\in\mathcal{U}$. So taking any $V$, there is some $r\in\bar{A}$ such that $(s,r)\in V$. But $r\in V(A)$, so $(r,t)\in V$ for some $t\in A$. Is there some why to show that $(s,t)\in V$, to conclude that $s\in V(A)$? At best I can see that $(s,t)\in V\circ V$.",['general-topology']
12451,Typical applications of Fubini's theorem and Radon-Nikodym,"Can someone please share references (websites or books) where I can find problems related with Fubini's theorem and applications of Radon-Nikodym theorem? I have googled yes and don't find many problems. What are the ""typical"" problems (if there are any) related with these topics? [Yes, exam is coming soon so I don't know what to expect and don't have access to midterms from previous years]. Thank you",['measure-theory']
12453,Is there an easy way to show which spheres can be Lie groups?,"I heard that using some relatively basic differential geometry, you can show that the only spheres which are Lie groups are $S^0$, $S^1$, and $S^3$.  My friend who told me this thought that it involved de Rham cohomology, but I don't really know anything about the cohomology of Lie groups so this doesn't help me much.  Presumably there are some pretty strict conditions we can get from talking about invariant differential forms -- if you can tell me anything about this it will be a much-appreciated bonus :) (A necessary condition for a manifold to be a Lie group is that is must be parallelizable, since any Lie group is parallelized (?) by the left-invariant vector fields generated by a basis of the Lie algebra.  Which happens to mean, by some pretty fancy tricks, that the only spheres that even have a chance are the ones listed above plus $S^7$.  The usual parallelization of this last one comes from viewing it as the set of unit octonions, which don't form a group since their multiplication isn't associative; of course this doesn't immediately preclude $S^7$ from admitting the structure of a Lie group.  Whatever.  I'd like to avoid having to appeal to this whole parallelizability business, if possible.)","['differential-topology', 'lie-groups', 'differential-geometry']"
12460,"Is Knopp's ""Theory and Application of Infinite Series"" out of date?","Is Knopp's Theory and Application of Infinite Series out of date? It's looks terrific to me, but the Dover edition I bought new maybe a year ago: http://preview.tinyurl.com/2eprqps seems to be the same as an edition published in 1951 and may go back as far as 1921. 60 or 90 years is a lot of math years. How about it? Does my book leave out some important developments? Is it old-fashioned in some other ways? I've seen this question: what is the current state of the art in methods of summing ""exotic"" series? but it doesn't have a full answer yet. Thanks",['sequences-and-series']
12462,"Is $f(x)=1/x$ continuous on $(0,\infty)$?","I've never actually done a delta-epsilon proof, so I thought I'd try my hand at one. I decided to try it out for $f(x)=1/x$. If I understand correctly from the wikipedia article, I want to show for any $\varepsilon>0$, there exists a $\delta>0$ such that if $|x-c|<\delta$, then $|f(x)-f(c)|<\varepsilon$. Anyway, I noticed that I want something like $$|f(x)-f(c)|= \left| \frac{1}{x} - \frac{1}{c} \right|=\frac{|x-c|}{|xc|}<\varepsilon .$$ So $|x-c|<|xc|\varepsilon$, which looks similar to the fact that I want $|x-c|<\delta$. However, I've also heard that one is never supposed to let $\delta$ depend on $x$. Is this the right direction? How would I use this information to find a corresponding $\delta$ for each $\epsilon$? Thanks!",['calculus']
12477,Does anyone know an interesting introductory topic involving vector spaces over the rationals,"Many introductory books on vector spaces mention that the scalars need not be reals, and might even have sections discussing complex vector spaces or vector spaces over the integers mod 2.  I have never seen any such book mention that all of the theory goes through as well if one restricts the scalars to be just rational numbers.  Perhaps this is because there is a dearth of interesting problems about such vector spaces accessible at this level that couldn't simply be discussed in the context of real scalars. I wonder if there is an interesting introductory-level problem or topic about vector spaces that would be most naturally conducted by allowing rational number scalars.  Does anyone know of such, perhaps one with a number-theoretic aspect? (By introductory:  I envision a first course on linear algebra, including non-math majors.  They would be seeing vector spaces (and that level of abstraction) for the first time.  Perhaps they would be seeing matrix multiplication for the first time.  Usually, in my experience, such courses primarily use the real numbers as scalars.)",['linear-algebra']
12485,What's known about recurrences involving $(a_n)^2$?,"I've run across the recurrence $a_{n+1} = (a_n)^2 + 1$ in the past.  Unfortunately, the referrence escapes me.  However, my impression was that recurrences involving the product of previous terms (such as $a_{n+1} = (a_n)(a_{n-1})$) are difficult to solve.  I'm wondering what is known for this very general problem. (1)  Is there a known way to solve recurrences involving the product of previous terms?  Or, what is known about these? (2)  What are these recurrences called?  Do they have a general name (such as non-linear recurrences)? (3)  Where can I find more literature on the subject? (4)  Who are some experts that have dealt with this?","['recurrence-relations', 'sequences-and-series']"
12486,Calculus of Variations and Lagrange Multipliers,"A general problem for the Calculus of Variations asks us to minimize the value of a functional $A[f]$, where $f$ is usually a differentiable function defined on $\mathbb{R}^n$. What if, however, the domain of $A$ is not actually all differentiable functions. Suppose there is a constraint equation on $f$, such as (for example): $L[f] = \int_{-1}^1 \sqrt{1 + f'(x)^2} dx = \pi$ and we want to minimize over functions satisfying the above and the property that $f(-1)=f(1)=0$ the functional $A[f] = \int_{-1}^1 f(x) dx $ This sort of problem seems to me to be very similar to the problem in multivariate calculus of minimizing a function $f(x)$ with respect to a constraint equation $g(x) = 0$. In this case we are trying to minimize a functional $A[f]$ with respect to a functional constraint equation $L[f] = \pi$. In the former, one can use Lagrange multipliers to reduce the problem to that of solving a system of equations. Is there such a technique for the variational version?","['calculus-of-variations', 'calculus', 'real-analysis']"
12487,Characterizations of Euclidean space,"There are presumably three ways of characterizing the abstract Euclidean space $E^n$ that are quite different in spirit: axiomatically (with axioms concerning dimension) by the abstract Euclidean group $E(n)$ (as its symmetry group, determining $E^n$ uniquely) by presupposing a metric and requiring that the space is a maximal one with respect to the property that the $(n+1)$ -dimensional Cayley-Menger determinant vanishes for all $(n+2)$ -tuples of points and does not vanish for all $k$ -tuples of points ""in general position"" for $k < n+2$ . [Having tried to ""rescue"" 3 by adding conditions in italics , due to Robin's comment.] Question 1: Is it correct, actually, that $E^n$ is uniquely
  determined via 2 and 3? Question 2: What are other ways of
  characterizing $E^n$ that are quite different in spirit?","['geometry', 'euclidean-geometry']"
12507,Are translations of a polynomial linearly independent?,"I've been wondering about the following question:
Suppose that $P$ is a polynomial of degree $n$ with complex coefficients. Assume that $a_0, a_1, \dots, a_n \in \mathbb{C}$ are distinct. Are the polynomials $$P(x + a_0), P(x + a_1), \dots, P(x + a_n)$$ linearly independent?","['linear-algebra', 'polynomials']"
12512,$n! =\sqrt{2n\pi}\left(\frac{n}{e}\right)^n e^r$?,"Is it even worth the theorem below? For every positive integer $n$, there is a real number $r$, 
and $\frac{1}{12n+1} \lt r \lt\frac{1}{12n}$, such that:
$$ n! = \sqrt{2n\pi}\left(\frac{n}{e}\right)^n e^r.$$ I saw this statement on some sites, but got no further details.
I think the statement refers to an exact value of $n!$, not an approximation.",['number-theory']
12520,Is the greatest integer function periodic?,"Can we call the greatest integer function as a periodic function with no fundamental period or is it just non-periodic. Please explain your answer. To my understanding, if we consider $f(x) = [x]$ now, $f(3) = [3] = 3$ and $f(3+0.5) = [3.5] = 3$ So, can't we say that it is periodic ( A constant function is periodic with no fundamental period ) ? But the problem is to derive the fundamental period. EDIT: After checking out some aswer I am quite inquisitive to know is it really necessary to have a fundamental period to call a function periodic? However,If you go by my book it is not.",['functions']
12522,Period of a function,What is the value of n $\in \mathbb{Z} $ for which the function $\displaystyle f(x) = \frac{\sin nx} { \sin \biggl( \frac{x}{n} \biggr) } \text { has } 4\pi $ as period? Also could it be possible to solve this if we need $x\pi$ as period ?I am interested in learning the general approach for this particular type of the problem.,['trigonometry']
12526,A map on the unit ball,"Let $B$ be the unit ball of $\ell^2(\mathbb{N})$, i.e. $B=\lbrace x\in \ell^2(\mathbb{N}): \|x\|\le 1\rbrace.$ For each $x=(x_1,x_2,\cdots)\in B$, let 
$$f(x)=(1-\|x\|,x_1,x_2,\cdots).$$ Define $T:B\to 2^B$ by $$T(x)=B(f(x),r(x))\cap B, \mbox{ where }r(x)=\frac{1}{2}(\|x-f(x)\|).$$
Is it true that $$D(Tx,Ty)\le \|x-y\| \mbox{ for all }x,y\in B?$$
Here $B(y,r)$ denotes the closed ball with radius $r$ centered at $y$, and $D$ is the Hausdorff metric defined by $$D(A,B)=\inf\lbrace r>0: N_r(A)\supset B, 
N_r(B)\supset A\rbrace,$$ $N_r(S) =\lbrace x\in C: d(x,S)\lt r\rbrace$ being the 
$r$-neighborhood of $S$.","['geometry', 'metric-spaces', 'functional-analysis']"
12531,"Show that the set of all symmetric, real matrices is a subspace, determine the dimension","Question: Let $V \subset M(n,n,\mathbb{R})$ be the set of all symmetric, real $(n \times n)$ matrices, that is $a_{ij} = a_{ji}$ for all $i,j$. Show that $V$ is a subspace of $M(n,n,\mathbb{R})$ and calculate dim$(V)$. My attempt so far:
First part: To show that $V$ is a subspace I need to show:
 (a) $ 0 \in V$ and 
 (b) $\forall A,B \in V:
 	(i) A + B \in V
 	(ii) \lambda A \in V$ For (a) I would say: Let $a_{ij} \in 0$(this should represent a zero matrix, is that how to write it?) $a_{ij} = 0 = a_{ji} \Rightarrow 0 \in V$ For (b) I am actually confused since I would first think: both a $(2 \times 2)$ matrix and a $(3 \times 3)$ matrix belong to $V$ but addition of matrices of different size is undefined $\Rightarrow$ $V$ is not closed under addition $\Rightarrow$ $V$ is not a subspace of $M(n,n,\mathbb{R})$... what am I missing here? (To start I don't really understand the notation $M(n,n,\mathbb{R})$... what exactly does the $\mathbb{R}$ represent there?). Disregarding my confusion I would still try to show (b), but my mathematical notation is still lacking competence... Is the following somewhat clear? Would anyone ever use ""$\in$"" to denote ""is an element of matrix""? (i)Let $a_{ij},a_{ji} \in A$ and $b_{ij}, b_{ji} \in B$. Let $A,B \in V$ $\Rightarrow a_{ij} = a_{ji}, b_{ij} = b_{ji}$ $A + B = C \Rightarrow c_{ij} = (a_{ij}+b_{ij}) = (a_{ji} + b_{ij}) = (a_{ij} + b_{ji}) = c_{ji} = (a_{ji} + b_{ji})$ $\Rightarrow C \in V$ (ii) Let $A\in V, \lambda \in \mathbb{R}$. Let $a_{ij},a_{ji} \in A$. $\Rightarrow a_{ij} = a_{ji}$ $\lambda \cdot A = A'$ with $\lambda a_{ij} = \lambda a_{ji} \Rightarrow A' \in V$ Second part: I feel that I understand the answer... For an $(n \times n)$ matrix, the diagonal length $ = n$ and these are the elements which have no counterpart and are not critical to the symmetry. When these elements are subtracted from the total$(n^{2})$, half of the remainder can be independently selected and the other half will follow as a result. Therefore I think it makes sense to write that dim$(V) = n + \frac{n^{2}-n}{2}$. Is this correct? If so, given the context of the exercise, how could I make my answer more acceptable?",['linear-algebra']
12544,Can $n!$ be a perfect square when $n$ is an integer greater than $1$?,"Can $n!$ be a perfect square when $n$ is an integer greater than $1$ ? Clearly, when $n$ is prime, $n!$ is not a perfect square because the exponent of $n$ in $n!$ is $1$ .  The same goes when $n-1$ is prime, by considering the exponent of $n-1$ . What is the answer for a general value of $n$ ?  (And is it possible, to prove without Bertrand's postulate. Because Bertrands postulate is quite a strong result.)","['number-theory', 'elementary-number-theory', 'square-numbers', 'factorial', 'diophantine-equations']"
12547,What is the spectral theorem for compact self-adjoint operators on a Hilbert space actually for?,"Please excuse the naive question.  I have had two classes now in which this theorem was taught and proven, but I have only ever seen a single (indirect?) application involving the quantum harmonic oscillator.  Even if this is not the strongest spectral theorem, it still seems useful enough that there should be many nice examples illustrating its utility.  So... what are some of those examples? (I couldn't readily find any nice examples looking through a few functional analysis textbooks, either.  Maybe I have the wrong books.)","['functional-analysis', 'examples-counterexamples', 'big-list']"
12555,$e$ to 50 billion decimal places,"Sorry if this is a really naive question, but in my reading of a lot of textbooks and articles, there is a lot of mention of how many decimals we know of a certain number today, such as $\pi$ or $e$. An excerpt from my textbook: In 1748, Leonard Euler used the sum of the infinite series of $e$ (mentioned in the book in a section about Taylor Series) to find the value of $e$ to 23 digits. In 2003, Shigeru Kondo, again using the series, computed $e$ to 50 billion decimals places My question is why does it matter how many decimals we know? Isn't this just a huge waste of time? What could we ever do with so many decimal places? And, if $e$ can be represented as a sum of infinite series of $1/n!$, can't we just plug that into a computer that just loops the same equation but increasing $n$ every iteration, and find as many decimals of $e$ as we like? (Once again, I realize this may be an ignorant/naive question, but I've always been curious about this)","['calculus', 'soft-question', 'taylor-expansion']"
12563,Solving systems of linear equations over a finite ring,"I want to solve equations like this (mod $2^n$): $$\begin{array}{rcrcrcr} 3x&+&4y&+&13z&=&3&\pmod{16} \\ x&+&5y&+&3z&=&5&\pmod{16} \\ 4x&+&7y&+&11z&=&12&\pmod{16}\end{array}$$ Since we are working over a ring and not a field, Gaussian elimination doesn't work. So how can I still solve these types of equations?","['gaussian-elimination', 'linear-algebra', 'finite-rings', 'number-theory']"
12573,Integration over the unit square,"Let $f$ be Lebesgue measurable in $[0,1]$ and assume $f$ takes finitely many values. Assuming $f(x) - f(y)$ is Lebesgue measurable in $[0,1] \times [0,1]$ show that $f$ is integrable over $[0,1]$. Stuck for a while with this one. (Not homework, just practice)",['measure-theory']
12584,How do I generate doubly-stochastic matrices uniform randomly?,A doubly-stochastic matrix is an $n \times n$ matrix $P$ such that $$ \sum_{i=1}^n p_{ij} = \sum_{j=1}^n p_{ij} = 1 $$ where $p_{ij}\ge 0$ . Can someone please suggest an algorithm for generating these matrices uniform randomly?,"['matrices', 'birkhoff-polytopes', 'probability', 'stochastic-matrices']"
12587,How many ways are there for 8 men and 5 women to stand in a line so that no two women stand next to each other?,"I have a homework problem in my textbook that has stumped me so far. There is a similar one to it that has not been assigned and has an answer in the back of the textbook. It reads: How many ways are there for $8$ men and $5$ women to stand in a line so that no two women stand next to each other? The answer is $609638400$, but no matter what I try I cannot reach that number. I have tried doing $2(8!5!/3!)*(8!/5!)$ since each woman must be paired with a man in order to prevent two women getting near each other. But of course, it's the wrong answer. What am I doing wrong here?","['permutations', 'combinatorics']"
12596,"Finite sub cover for $(0,1)$","While learning topology one learns about compact set. The standard definition is: A set $X$ is said to be compact if open cover has a finite subcover. Since $[0,1]$ is compact, if we take a open cover for this we should be able to get a finite subcover. I know, that $(0,1)$ is not compact, so there must exists some open cover for $(0,1)$ which doesn't admit any finite subcover. But how does one prove this fact?","['general-topology', 'compactness', 'analysis']"
12600,"Given a plane and a 3d-Vertex, what are U and V?","I have a plane defined through a point P and two 3D-vectors $\overrightarrow{X}$ and $\overrightarrow {Y}$. I wish to convert coordinates of points on this plane between local 2D-parametric and world 3D coordinate systems. I know the conversion from 2D Parametric to 3D is $C(u, v) = P + u\cdot \overrightarrow {X} + v\cdot \overrightarrow {Y}$ however i have been unable to find a way for the inverse case $C'(x, y, z)$ which should give me the parameters $u$ and $v$ for any point $(x, y, z)$ in the plane. How does this conversion work?",['geometry']
12601,Blow-up. Graph of canonical map: is a complex manifold no closed or a topological space no closed,"I am reading by myself this book http://tinyurl.com/37z4bbt . But to be honest, I have several problems to fully understand some part of the text. Maybe because I have not yet solid knowledge or I still need to learn more about the subject, hence asked a little help To be exact, is this part of the construction concerning to Algebraic Blow-Up that I do not understand like trying... I quote part of the building in which I do not understand how to deal with some concepts Consider the canonical map from $\mathbb{C}^2$ to the projective line $\mathbb{CP}^1$ that associates with each point $(x,y)$ different from the origin, the line {$(tx, ty) : t \in \mathbb{C}$} passing through this point. The graph of this map is a complex 2-dimensional surface in the complex 3-dimensional manifold (the Cartesian product) $\mathbb{C}^2$ × $\mathbb{CP}^1$, which is not closed . To obtain the closure, one has to add the exceptional curve $E={0} \times \mathbb{CP^{1}} \subset \mathbb{C^{2}} \times \mathbb{CP^{1}}$. then, I do not understand is how to handle this graph. If, as a topological space or as complex manifold . Well, in the sense of complex manifold, say it is not closed, it means that the manifold is not compact without boundary. I am really a little confused","['general-topology', 'ordinary-differential-equations', 'algebraic-topology']"
