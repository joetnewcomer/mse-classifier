question_id,title,body,tags
3775734,Hoeffding's Inequality Assumptions,"I'm looking for the assumptions of the Hoeffding's inequality to check it is applicable to my problem. So far the only assumptions I can find are the variables $Z_i$ are IID and bounded. However, Im wondering if there is some assumption I am missing that assumes the underlying distribution is Gaussian or Sub-Gaussian. Am I missing any assumptions or is Gaussian or sub-Gaussian implied?","['statistics', 'probability-theory', 'upper-lower-bounds', 'inequality']"
3775770,Can we further refine $\int_{0}^{1}x^{x^x} \ dx=\frac 1 2+\sum_{n=1}^{\infty}(-1)^n\sum_{k=1}^{\infty}\frac {(n-k)^k}{(k+1)^{n+1}} \binom {n}{k}$,"Question Can we further refine the integral $$\int_{0}^{1}x^{x^x}\ dx=\frac 1
 2+\sum_{n=1}^{\infty}(-1)^n\sum_{k=1}^{n}\frac {(n-k)^k}{(k+1)^{n+1}}
 \binom {n}{k}$$ ? To compute the result, first note that $0<x<x^{x^x}<1$ when $0<x<1$ . Hence by dominated convergence, supposing that $a>0$ , we have $$\lim_{a \to 0^+}  \int_{0}^{1} x^a x^{x^x}\ dx = \int_{0}^{1}x^{x^x}\ dx $$ and therefore \begin{align} 
\int_{0}^{1} x^a x^{x^x}\ dx &= \int_{0}^{1} x^a e^{x^x \ln x}\ dx \\
&= \sum_{n=0}^{\infty}\frac 1 {n!}\int_{0}^{1}x^a(x^x \ln x)^n\ dx \\
&=\sum_{n=0}^{\infty}\frac 1 {n!}\sum_{k=0}^{\infty}\int_{0}^{1}x^a (\log x)^n \frac {(nx \log x)^k}{k!}\ dx \\
&= \sum_{n=0}^{\infty}\sum_{k=0}^{\infty}\frac {n^k}{n!k!}\int_{0}^{1}x^{k+a}{(\log x)}^{n+k}\ dx \\
&= \sum_{n=0}^{\infty}\sum_{k=0}^{\infty}\frac {n^k}{n!k!}\int_{1}^{\infty}t^{-k-a-2}{(\log t)}^{n+k}\ dt \\
&= \sum_{n=0}^{\infty}\sum_{k=0}^{\infty}\frac {(-1)^{n+k}n^k}{n!k!(k+1+a)^{n+k+1}}\int_{0}^{\infty} e^{-u} u ^{n+k}\ du
\end{align} where in the last line we made the transformation $(k+1+a) \log t = -u$ . Taking the limit $a \to 0^+$ and on further calculations, we get $$\int_{0}^{1}x^{x^x}\ dx=\frac 1 2+\sum_{n=1}^{\infty}(-1)^n\sum_{k=1}^{n}\frac {(n-k)^k}{(k+1)^{n+1}} \binom {n}{k}$$ The result has two summations in the answer. I want to know can we further improve the answer? Thank you for your help!","['integration', 'calculus', 'definite-integrals', 'real-analysis']"
3775808,Prove $\int_0^{\infty} \frac{\arctan{(x)}}{x} \ln{\left(\frac{1+x^2}{{(1-x)}^2}\right)} \; \mathrm{d}x = \frac{3\pi^3}{16}$,"Prove that $$\int_0^{\infty} \frac{\arctan{(x)}}{x} \ln{\left(\frac{1+x^2}{{(1-x)}^2}\right)} \; \mathrm{d}x = \frac{3\pi^3}{16}$$ This is not a duplicate of this post , the bounds are different and the integral evaluates to a slightly different value.  I tried looking at the solution from the linked post but I'm not familiar with harmonic numbers or complex analysis and the real solution is long.  I tried IBP but got no where.  Any advice for this monster integral (real analysis only please)?","['integration', 'improper-integrals', 'definite-integrals', 'real-analysis', 'calculus']"
3775840,"$f$ absolutely continuous and $f'\in L^3[0,1]$, which values of $\alpha $ does $\lim_{x\rightarrow 0^+} x^{-\alpha}f(x)=0$?","I'm working my way through some old analysis quals at my university and I came across this question. Let $f$ be absolutely continuous on $[0,1]$ with $f(0)=0$ and $f'\in L^3([0,1])$ . For which values of $\alpha$ does $$ \lim_{x\rightarrow 0^+} x^{-\alpha}f(x)=0$$ for all such $f$ ? I have tried the following approach. Using the FTOC for Lebesgue integrals and Holder's inequality: $x^{-\alpha}f(x)=\int_0^xf'(t)x^{-\alpha}dt\leq ||\chi_{[0,x]}|f'(t)|^3||_{3,[0,1]}x^{-\alpha/3}$ . The quanitity on the right hand side will go to zero if $\alpha>0$ . So this doens't seem to be super helpful. How should I proceed?","['absolute-continuity', 'measure-theory', 'lp-spaces', 'lebesgue-integral']"
3775849,List all the possible values for $\int_{\mathbb{R}}\sup_{k\in\mathbb{N}}f_k(x)dx$ under these conditions...,"Question : Let $\{f_k(x)\}_{n=1}^\infty$ be a sequence of nonnegative functions on $\mathbb{R}$ such that $\sup_{x\in\mathbb{R}}f_k(x)=\frac{1}{k}$ , and $\int_{\mathbb{R}}f_k(x)dx=1$ .  List all the possible values for $\int_{\mathbb{R}}\sup_{k\in\mathbb{N}}f_k(x)dx$ . My Thoughts :  I am a bit confused on how we are going to relate the supremum over $x\in\mathbb{R}$ of $f_k(x)$ , as in the hypothesis, and the supremum over $k\in\mathbb{N}$ of $f_k(x)$ , as in what we are trying to prove... are they the same?   Since the $f_k$ 's are integrable, we can say they are measurable, so the Monotone Convergence Theorem would imply, I believe, that $\lim_{k\rightarrow\infty}\int_{\mathbb{R}}\sup_{x\in\mathbb{R}}f_k(x)dx=\int_\mathbb{R}\frac{1}{k}$ (maybe I can't put that supremum inside the integral like that....)  But then I am not sure how to use $\int_{\mathbb{R}}f_k(x)dx=1$ ....  any help is greatly apprecaited!  Thank you.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3775858,Question about the sheaf of differentials of a fibre,"Let $f: X \to Y$ be a morphism of finite type of noetherian schemes. Let $f(x) = y$ . I would like to see a proof of $$
(\Omega_{ f^{-1}(y) / \operatorname{Spec} \kappa (y) })_x = (\Omega_{X/Y})_x \otimes_{O_{Y,y}} \kappa (y). 
$$ This is mentioned in the proof of Theorem 3 Section III. 5 in Mumford's Red Book without explanation. I have tried to reduce to the affine case and apply facts about Kahler differentials on page 186 in Matsumura's Commutative Algebra , but I have not managed to make this work yet... Thank you.","['localization', 'algebraic-geometry', 'tensor-products', 'sheaf-theory', 'schemes']"
3775873,can incentre lie on the Euler line for an obtuse triangle?,"I know that  incentre lie on the Euler line for equilateral and isosceles triangle but I found a claim
that incentre can lie on the Euler line for obtuse triangle. So, is this claim true?Also does there exist any scalene and acute ( but neither equilateral or isosceles ) triangle for which incentre lies on the Euler line? Finally, if incentre is on Euler line, then is it at a unique location with respect to other centres (orthocentre, circumcentre, centroid)?","['triangles', 'trigonometry', 'geometry']"
3775883,USA TST 2018/P1: Prove that the $n^{\text{th}}$ smallest positive integer relatively prime to $n$ is at least $\sigma(n)$,"Let $n \ge 2$ be a positive integer, and let $\sigma(n)$ denote the sum of the positive divisors of $n$ . Prove that the $n^{\text{th}}$ smallest positive integer relatively prime to $n$ is at least $\sigma(n)$ , and determine for which $n$ equality holds. My Progress: Really hard problem!!! Obviously, I looked at examples! For n=2, $\sigma(2)=3$ and the second positive relatively prime to 2 was 3. For n=3, $\sigma(3)=4$ and the third positive relatively prime to 3 was 4. For n=4, $\sigma(4)=1+2+4=7$ and the fourth positive relatively prime to 4 was 7. For n=5, $\sigma(5)=1+5=6$ and the fifth positive relatively prime to 5 was 6. For n=6, $\sigma(6)=3\cdot 4=12$ but the sixth  positive relatively prime to 6 was 17. So, from here I conjectured that the equality case is true  if and only if $n =$ perfect power of a prime. Firstly, let $S(n)$ be the $n^{\text{th}}$ smallest positive integer relatively prime to $n$ . Now, for $n=$ prime.It works, since $\sigma(n)=p+1$ and $S(n)=p+1$ , since only $p$ is not relatively prime to $p$ and $p+1$ is . Before proceeding further I would like to state the formula which I got and can be proved by induction or just simple modular arithmetic . For a given integer $x$ and a perfect power of prime $""l^k""$ . We get that $x$ is the $[x-Q(x,l)]^{\text{th}}$ number which is relatively prime to $l^k$ . where $Q(x,l)$ is the quotient when $x$ is divided by $l$ . Now $n=p^k$ , for some prime $p$ and $k>1$ . So we get that, $\sigma(p^k)= 1+p^2+\dots +p^k$ . We claim that $S(p^k)=1+p^2+\dots +p^k$ . we can prove this by using the fact that $S(n)$ is unique or in other words , we can show that $1+p^2+\dots +p^k$ is the ${p^k}^{\text{th}}$ relatively prime number  rather than finding the ${p^k}^{th}$ relatively prime number . But by the formula we stated, we get that $1+p^2+\dots +p^k$ is the $[1+p^2+\dots +p^k - Q(1+p^2+\dots +p^k,p)]=[1+p^2+\dots +p^k -(1+p^2+\dots +p^{k-1})]= p^k$ And we are done! I am stuck in showing that equality case doesn't for multiples prime . The handout which I am using, gave these hints for the general problem: $1$ . $\sum_{d|n} \phi(d)=n$ . $2$ . We basically reverse construct the $\sigma(n$ ) as the sum of the divisors and construct intervals which each have a different $d_i$ number of relatively prime numbers. I couldn't even understand the $2^{\text{nd}}$ hint. Please give a try to this beautiful problem and hope one can give me hints for this problem. Thanks in advance.","['contest-math', 'elementary-number-theory', 'combinatorics', 'divisor-sum']"
3775911,Center of mass on an unbounded interval [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 9 months ago . Improve this question I am having a hard time locating the center of mass of $y=\frac{1}{x}$ on $(1,\infty)$ . I used the formula but I get a value of infinity for the mass of the lamina alone. I was able to get an improper integral after using the formula but then it just gave me an infinity as value at the end. I tried to check it with the graph and it seems that it isn't at infinity. How do we solve center of mass when the interval is unbounded? Any idea is greatly appreciated. Thank you so much.","['multivariable-calculus', 'calculus', 'algebra-precalculus']"
3775923,What is the difference between $dy$ and $Δy$ and why is $dx$ is same as $Δx$ when $x$ is an independent variable and $y$ is dependent one?,"I have two questions, say we have a function $y=f(x)$ $Q1.$ $x$ is the independent variable here, then how is $dx$ = $Δx$ ? Here, $dx$ is an infinitesimal while $\Delta x$ is just the finite change in x values, then how can infinitesimal change $=$ finite change. Shouldn't $dx=\lim_{\Delta x\rightarrow 0}{\Delta x}$ ? $Q2.$ What is the difference between $dy$ and $Δy$ ? If we look at $dy$ and $Δy$ . $dy = \lim_{\Delta x\rightarrow 0}{f(x+\Delta x) - f(x))}$ $Δy$ = ${f(x+\Delta x) - f(x)}$ So $dy$ is the limiting case of $\Delta y$ , Am I right about this? I was totally confused by this thing that even after seeing several explanations about this, I still can't wrap my head around it.","['calculus', 'derivatives', 'infinitesimals']"
3775960,Set of prime integers,"Let $S$ be a set of primes such that $a,b\in S$ ( $a$ and $b$ need not be distinct) implies $ab+4\in S$ . Show that $S$ must be empty. (Hint use modulo 7) I don't have an idea how to use the hint, any further hint will be appreacited","['elementary-set-theory', 'elementary-number-theory', 'prime-numbers']"
3775973,$L^p$ compactness for product of two sequences of functions,"Let $f_n:[a,b] \to \mathbb R$ , $n \in \mathbb N$ , be a sequence of $L^p$ functions for some $p \in (1,\infty)$ . For every fixed $m\in \mathbb N^*$ , suppose that the sequence of functions $$\{f_{n}\psi_m(f_n)\}_{n \in \mathbb N}$$ has a strongly convergent subsequence in $L^p([a,b])$ . Here $\psi_m$ is a smooth function such that $$\psi_m(f) = 
\begin{cases}
1 \qquad \text{ if } |f|\ge 1/m \\
0 \qquad \text{ if } |f|\le 1/(2m)
\end{cases}
$$ and $0 \le \psi_m \le 1$ . Is it true that $\{f_n\}_{n\in \mathbb N}$ also has a strongly convergent subsequence in $L^p([a,b])$ ? I wanted to apply a diagonal argument: [1] , but I can't make it work properly.","['lp-spaces', 'functional-analysis', 'real-analysis']"
3775987,Polynomial bijections from $\mathbb{Q}$ to $\mathbb{Q}$,"Prove or Improve : Polynomials $f\in \mathbb{Q}[x]$ which induce a bijection $\mathbb{Q}\to\mathbb{Q}$ are linear. The question of existence of a polynomial bijection $\mathbb{Q}\times\mathbb{Q}\to \mathbb{Q}$ is open, as discussed in this MO thread , this post by Terry Tao , and many more places. However, I cannot find much about the simpler question of polynomial bijections $\mathbb{Q}\to \mathbb{Q}$ (probably because this is easier and less interesting). Here are a few somewhat immediate observations: One quickly notes that any such bijection can always be put in the form $$a_nx^n+\dots+a_1x$$ for $a_1,\dots,a_n\in \mathbb{Z}$ by composing with an appropriate linear polynomial. From there, I have tried to use the rational root theorem to obtain some sort of result, but to no avail. Note that, unlike the $\mathbb{Q}\times\mathbb{Q}\to \mathbb{Q}$ case, it is quite easy to obtain an injection. For example, $f(x)=x^3+x$ is clearly injective, but unfortunately fails to be surjective ( $f(x)=1$ yields $x^3+x-1=0$ , which has only irrational roots by the rational root theorem, hence $1$ has no rational inverse). Is this a known result, and if so, how would one prove it? Or is there some higher order bijective polynomial on $\mathbb{Q}$ ?","['number-theory', 'polynomials', 'rational-numbers']"
3776072,Estimating number of people in a group based on knowing the number of birthdays for today,"Lets say there is a group of people and we don't know how big is this group. Lets say that we are told that 3 people had a birthday today. For simplicity we can assume that birthdays are uniformly distributed and there is 365 days in a year. Can I, based on this information only, estimate the number of people in this group? Putting it other way I would like to answer the questions: Given that 3 people had a birthday today what is the probability that the group has 100 people?

Given that 3 people had a birthday today what is the probability that the group has 251 people? So lets X be a random variable representing a number of people in a group then P(X = x | number_of_people_who_had_birthday_today = n) is a probability of a group being of size x given number of the people having birthday today is n. It is obvious that: P(X = 0 | number_of_people_who_had_birthday_today = 3) = 0
P(X = 1 | number_of_people_who_had_birthday_today = 3) = 0
P(X = 2 | number_of_people_who_had_birthday_today = 3) = 0 since because 3 people had a birthday there must be at least 3 people in this  group. I would like to find formula for P. But, I struggle to put my head around it. If I would somehow be able to model the initial number of people in a room as some distribution with a given mean \mu. Lets say I would be coming back on some number of consecutive days and asking how many people had birthday today. Lets say that after 5 days I would get a list of answers [2,3,2,3,4]. I believe that I could use my initial distribution and the above list to somehow update my initial believe using Bayes theorem. But for that I would need P(N | x)(if I am not mistaken) but I don't know what it is.","['birthday', 'probability']"
3776114,"Why doesn't u-Substitution work for $\int \ln({e^{6x-5}})\,dx$?","I was trying to evaluate the indefinite integral $\int \ln({e^{6x-5}})\,dx$ . I know that the correct way to solve it is to use the following property of logarithms: $$\ln{e^{f(x)}}=f(x)\ln{e}=f(x)$$ Using this property, the integral becomes $\int 6x-5\,dx$ , and we can use the Reverse Power Rule to get $\color{red}{3x^2-5x+C}$ as the answer. The above method was not my first attempt. I initially tried to solve it using u-substitution but got a different answer. I cannot find where the mistake occurs. Here was my first attempt: $$u=6x-5 \\ du=6\,dx \Rightarrow \dfrac{1}{6}du=dx \\ \dfrac{1}{6}\int \ln{e^u}\,du=\dfrac{1}{6}\int u\,du \\ \dfrac{1}{6} \cdot \dfrac{1}{2}u^2+C \Rightarrow \color{red}{\dfrac{1}{12}(6x-5)^2+C}$$ I already checked that the two answers are not the same as their graphs are different. Where does the mistake occur?","['integration', 'calculus']"
3776130,Lie Bracket of vector fields,"I would like to show that the following identity holds: $$\frac{d}{dt}\Bigr|_{t=t_0} d\phi_{-t}^X(\phi_t^X(m))Y(\phi_t^X(m))=d\phi_{-t_0}^X(\phi_{t_0}^X(m))[X,Y](\phi_{t_0}^X(m)),$$ $\phi_t^X(m)$ is the flow of the smooth vector field $X$ , given by: $\frac{d}{dt}\phi_t^X(m)=X(\phi_t^X(m)), \quad  \phi_0^X(m)=m.$ And the Lie bracket $[X,Y]$ is given by: $[X,Y](m)=dY(m)X(m)-dX(m)Y(m)$ . My try: I use the fact that (provided as a hint): $d\phi_{-t}^X(\phi_t^X(m))=(d\phi_t^X(m))^{-1}$ and additionally for a matrix $\dot {A(t)^{-1}}=-A(t)^{-1} \dot A(t) A(t)^{-1} $ , $\dot{(\space)}=\frac{d}{dt}$ : $$\frac{d}{dt}\Bigr|_{t=t_0} d\phi_{-t}^X(\phi_t^X(m))Y(\phi_t^X(m))=\frac{d}{dt}\Bigr|_{t=t_0} (d\phi_t^X(m))^{-1}Y(\phi_t^X(m))=$$ $$-(d\phi_{t_0}^X(m))^{-1}(\frac{d}{dt}\Bigr|_{t=t_0}d\phi_t^X(m))(d\phi_{t_0}^X(m))^{-1}Y(\phi_{t_0}^X(m))+ $$ $$(d\phi_{t_0}^X(m))^{-1}dY(\phi_{t_0}^X(m))\frac{d}{dt}\Bigr|_{t=t_0}\phi_t^X(m)=$$ $$\text{Now I use:}$$ $$\frac{d}{dt}\Bigr|_{t=t_0} \phi_t^X(m)=X(\phi_{t_0}^X(m));$$ $$\frac{d}{dt}\Bigr|_{t=t_0} d\phi_t^X(m)=dX(\phi_{t_0}^X(m)).$$ $$=(d\phi_{t_0}^X(m))^{-1} \bigg[-dX(\phi_{t_0}^X(m))\color{red}{(d\phi_{t_0}^X(m))^{-1}Y(\phi_{t_0}^X(m))}+dY(\phi_{t_0}^X(m))X(\phi_{t_0}^X(m))\bigg ].$$ This is almost correct but the red part screws it up. Could someone please help me with this, I can't seem to be able to solve it. EDIT: (Using the comments from @Ted Shifrin below, I've come up with this) We have: $\frac{d}{dt}\Bigr|_{t=t_0} (d\phi_t^X(m))^{-1}Y (\phi_t^X(m))=$ $$\text{Let's suppose I take a new variable } \tilde{t}=t-t_0,$$ $$\text{this should hold: } \frac{d}{dt}\Bigr|_{t=t_0}=\frac{d}{d\tilde{t}}\Bigr|_{\tilde{t}=0}.$$ $$\text{Using this and } \color{red}{d\phi^X_{\tilde{t}+t_0}(m)=d[\phi^X_{\tilde{t}}\circ \phi_{t_0}^X](m)=d[\phi_\tilde{t}^X(\phi_{t_0}^X)](m)=d\phi_{\tilde{t}}^X(\phi^X_{t_0}(m))d\phi^X_{t_0}(m),} $$ $$\text{we have:}$$ $$=\frac{d}{d\tilde{t}}\Bigr|_{\tilde{t}=0}(d\phi^X_{\tilde{t}+t_0}(m))^{-1} \space Y(\phi_{\tilde{t}+t_0}^X(m))=\frac{d}{d\tilde{t}}\Bigr|_{\tilde{t}=0}(d\phi_{t_0}^X(m))^{-1}d\phi_{\tilde t}^X(\phi_{t_0}^X(m)) Y(\phi_\tilde{t}^X(\phi_{t_0}^X(m))=$$ $$\text{I've used the fact that: } (AB)^{-1}=B^{-1}A^{-1}. \text{If we now factor out }(d\phi_{t_0}^X(m))^{-1}, \text{we get}:$$ $$ =(d\phi_{t_0}^X(m))^{-1} \frac{d}{d\tilde{t}}\Bigr|_{\tilde{t}=0}d\phi_{\tilde t}^X(\phi_{t_0}^X(m)) Y(\phi_\tilde{t}^X(\phi_{t_0}^X(m))=(d\phi_{t_0}^X(m))^{-1}L_XY(\phi_{t_0}^X(m))=(d\phi_{t_0}^X(m))^{-1}[X,Y](\phi_{t_0}^X(m)).$$ Bounty :Could someone please verify that the above derivation (especially the red part) is correct? $d\phi^X_{\tilde{t}+t_0}$ is meant as $d(\phi^X_{\tilde{t}+t_0}(m))$ right?","['multivariable-calculus', 'general-topology', 'differential-topology', 'differential-geometry']"
3776138,Bertini's theorem and hypersurfaces,"I am reading ""Algebraic Geometry, a first course"", then I can't solve the following question that is an application of Bertini's theorem: Exercise $17.17$ : Use Bertini's theorem to show that (a) the general hypersurface of degree $d$ in $\mathbb{P}^{n}$ is smooth and more generally (b) for $k<n$ if $F_{1},...,F_{k}$ are general homogeneous polynomials of degree $d_{1},..,d_{k}$ in $n+1$ variables the corresponding hyperurfaces in $\mathbb{P}^{n}$ intersect transversely  in a smooth $(n-k)$ -dimensional variety. In the book, Bertini's theorem is stated as: ""If $X$ is any quasi-projective variety, $f: X \to \mathbb{P}^{n}$ a regular map, $H\subset \mathbb{P}^{n}$ a general hyperplane, and $Y = f^{-1} (H)$ , then $Y_{sing}=X_{sing}\cap Y$ . What is a general hypersurfaces? Because I know that there is a hypersurface that is not smooth, then general does not mean any hypersurface. I really don't have idea how to solve this question.",['algebraic-geometry']
3776189,Find exact value of $f^{-1}(f(a))$,"Given the function $$
f(x)=\frac{1}{4}\left((x-1)^{2}+7\right)
$$ The first part of the question asks to find the largest domain containing the value $x=3$ for which $f^{-1}(x)$ exists. I determined the domain to be $x≥1$ . The second part of the question is: Let $a$ be a real number not in the domain found in the previous part, find the exact value of $f^{-1}(f(a))$ . My thinking process was since $a<1$ , based from the domain we found previously, then therefore $f(a)=f(-a)$ . Do I use the inverse function i.e. $f^{-1}(x)=1+\sqrt{4x+7}$ and just sub in $-a$ ? I'm not entirely sure if this is correct. Any help is greatly appreciated!","['functions', 'inverse-function']"
3776204,Tiling the plane with consecutive squares,"For which $n$ is it possible to find a region $R$ made of non-overlapping squares of side length $1,2,\ldots,n$ which tiles the plane? $n=1$ is trivial, and $n=2$ works as well. However, for $n\geq3,$ I am unable to find $R$ that work. Obviously, we can try every possible combination for smaller values, but I want to know for arbitrary $n$ what the conditions are for $R$ to exist.","['discrete-geometry', 'geometry', 'combinatorial-geometry', 'plane-geometry', 'tiling']"
3776206,How to factorize $a^2-2ab+a^2b-2b^2$?,I have been stuck on factorizing this: $$a^2-2ab+a^2b-2b^2$$ I thought I could solve it by making $(a+b)$ as one factor but it didn't work then I tried to add and deduct some terms which that didn't lead me to anything either. I don't really know what to do next.,['algebra-precalculus']
3776221,Integrable function $f$ such that $\int_I f(x)dx=0$ for intervals of arbitrarily small length.,"A past qual question from my university reads:
Let $f$ be an integrable function satisfying $\int_0^1 f(x)dx=0$ . Prove that there are intervals $I$ of arbitrarily small positive length such that $$\int_I f(x)dx=0$$ I'm not sure how to approach the problem. One has that $\nu(E)=\int_E f(x)dx$ is a signed measure with a Hahn decomposition of $[0,1]=P\cup N$ where $f\geq 0$ on P and $f\leq 0$ on N. But I can't seem to be able to come up with a way of finding an interval with the desired property.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
3776227,"What's the difference between $v = a\cdot t$ and $\vec{v} = \int \vec{a} \, \mathrm dt$","In highschool, I learned $v = at$ and in university, I am learning $\vec{v} = \int \frac{\vec{F}}{m} \, \mathrm dt = \int \vec{a} \, \mathrm dt$ . I understand one is for $v= at$ is for one-dimension and the latter for multiple dimensions. However, I don't understand why in one dimension, we don't do $v = \int a(t) \, \mathrm dt$ but rather multiply it by the time to get the acceleration at time $t$ . Shouldn't the acceleration accumulate and therefore do the integral instead? I am confused. As an example, A particle of mass $m=2$ is acted on by a force $$
\mathbf{F}=\left(4 t, 6 t^{2},-4 t\right)
$$ At $t=0,$ the particle has velocity zero and is located at the point $(1,2,3)$ . Find the velocity vector $\mathbf{v}(t)$ for $t \geq 0$ We can easily know that $\vec{a} = \langle 2t,3t^2,-2t\rangle$ . However, the velocity is not $\vec{a}\cdot t$ (which is possible with no problem since $t$ is a scalar and it still returns a vector), but rather anti-integral of the vector?","['vector-fields', 'calculus', 'mathematical-physics']"
3776240,Defining the natural almost complex structure on a complex manifold.,"The definition of an almost complex structure is as follows. If $X$ is a differentiable manifold and $TX$ is its tangent bundle, then the endomorphism $I: TX \to TX$ defines an almost complex structure if $I \circ I = -1$ on all the fibers. If $X$ is a complex manifold, it would be easy to define $I$ locally (on the holomorphic tangent bundle) on a chart $U_i$ with the trivialization $\Phi_i : U_i \times \mathbb{C}^n \to \pi^{-1}(U_i)$ by letting $I_i(p, v) = (p, iv)$ . Then clearly, $I_i^2 = -1$ so every chart has an almost complex structure. This would then give a natural map $I_i': \pi^{-1}(U_i) \to \pi^{-1}(U_i)$ by $I_i' = \Phi_i I_i \Phi^{-1}_i$ which satisfies the conditions of an almost complex structure on $TU_i$ . However, I'm having trouble seeing how this extends to a global endomorphism $I$ . To do so, we would need $I_i \equiv I_j$ on $\pi^{-1}(U_i \cap U_j).$ If $U_j$ has a local trivialization $\Phi_j$ , then the transition map $\Phi_j^{-1} \circ \Phi_i: (U_i \cap U_j )\times \mathbb{C}^n \to (U_i \cap U_j )\times \mathbb{C}^n$ is given by $(p, v) \mapsto (p, \tau_p(v))$ for some differentiable map $\tau: U_i \cap U_j \to GL(n, \mathbb{C})$ . Then, in order for $I_i' = I_j'$ , we would need $\Phi_i I_i \Phi_i^{-1} = \Phi_j I_j \Phi_j^{-1}$ which is true iff $\Phi_j ^{-1} \Phi_i I_i = I_j \Phi_j^{-1} \Phi_i$ which is true iff $(p, \tau_p(iv)) = (p, i \tau_p(v))$ which is obviously true by the fact that $\tau_p \in GL(n, \mathbb{C})$ . Does this prove that X has an almost complex structure? Also, is there a more clear way to construct it? The book I'm reading from dismisses this fact as obvious which makes me concerned. Thank you!","['complex-geometry', 'vector-bundles', 'almost-complex', 'differential-geometry']"
3776257,Cat and mouse question,"I got the following recurrence relations, letting $t_i$ be the expected number of mouse moves to get to room 6 from room $i$ : $$
t_6 = 0\\
t_5 = \frac{1}{2} + \frac{1}{2}(1+t_2)\\
t_4 = 1 + t_1\\
t_3 = 1 + t_2\\
t_2 = \frac{1}{3}(1 + t_5) + \frac{1}{3}(1 + t_1) + \frac{1}{3}(1 + t_3)\\
t_1 = \frac{1}{2}(1 + t_2) + \frac{1}{2}(1 + t_4)
$$ which I solved to find $t_1 = 19$ . Does this seem right and does anyone have a quicker way to solve these kinds of questions?","['solution-verification', 'markov-chains', 'probability']"
3776305,A Rational Parameterization of Multiple Simple Expressions (Or the intersection of two rational parameterizations),"Context I am interested specifically in all rational values of $x$ for which $\sqrt{1-x}$ and $\sqrt{1+x}$ are rational. In general; however, I am curious if there is a method for taking any number of expressions in the form $\sqrt{n_i \pm x}$ and finding all rational values for x that ensure all of the expressions are rational. What I have tried I have tried a few different methods: Method 1 I have tried calculating rational parameterizations of both expressions individually by taking the rational point $(0,1)$ and finding the intersection between a line with a rational slope through that point and the graphs individually. For $y=\sqrt{1-x}$ I used the line $x=t(y-1)$ Plugging this into $y=\sqrt{1-x}$ I get $y=\sqrt{1-t(y-1)}$ By solving this for $y$ (and ultimate $x$ ) in terms of $t$ , I get $x=-t^2-2t$ Similarly for $y=\sqrt{1+x}$ with this method I get $x=t^2+2t$ But I have not been able to parameterize the intersection of these two parameterizations. Method 2 I have tried calculating rational parameterizations of both expressions together by combining them into the system: $$y=\sqrt{1-x}$$ $$z=\sqrt{1+x}$$ and taking the rational point $(0,1,1)$ and finding the intersection between a line with a rational slope through that point and the surface $(x,\sqrt{1-x},\sqrt{1+x})$ . By this method I get a long and messy formula that does not guarantee rational coordinates. Method 3 I have tried using the same techniques to rationally parameterize $y=\sqrt{1-x}+\sqrt{1+x}$ with a similarly messy result. Method 4 Since $x$ is rational, $x=\frac{a}{b}$ where $a$ and $b$ are co-prime integers, the expressions above can be rewritten as: $$\sqrt{1-x}=\sqrt{1-\frac{a}{b}}=\sqrt{\frac{b-a}{b}}$$ $$\sqrt{1+x}=\sqrt{1+\frac{a}{b}}=\sqrt{\frac{b+a}{b}}$$ For these to be rational either $a$ must contain $b$ as a factor (which is impossible because $a$ and $b$ are defined co-prime) or $b$ must be a square integer $b=c^2$ . I performed a search for all positive integers in certain range that where $\sqrt{c^2-a}$ and $\sqrt{c^2+a}$ are integers to attempt to identify a pattern. The first few fully reduced fractions (where $a \neq 0$ ) that I found are: $$\frac{24}{25},\frac{120}{169},\frac{240}{289},\frac{336}{625},\frac{840}{841},\frac{840}{1369},\frac{720}{1681},\frac{2520}{2809},\frac{1320}{3721},\frac{2016}{4225},\frac{3696}{4225},\frac{5280}{5329},\frac{2184}{7225},\frac{5544}{7225},\frac{6240}{7921},...$$ The denominators (the value of $c$ , not $c^2$ ) seem to correspond directly to the ""Ordered hypotenuses (with multiplicity) of primitive Pythagorean triangles"" OEIS A020882 and the numerators to ""Common differences in triples of squares in arithmetic progression, that are not a multiples of other triples in (A $198384$ , A $198385$ , A $198386$ )"" OEIS A198438 . With this information, I am unsure how to prove that these sequences will enumerate a full rational parameterization of my two initial expressions without missing any rational points, and how to generate a parameterization of these rational values. Final Notes Any hints, ideas, or references would be much appreciated! Edit Thanks to John Omielan and using my techniques above, I have determined that $\sqrt{1-x}$ and $\sqrt{1+x}$ are rational when $x=\frac{4t(t^2-1)}{(t^2+1)^2}$ for all rational values of $t$ .","['number-theory', 'algebraic-geometry', 'diophantine-equations']"
3776308,When is $-3$ a quadratic residue mod $p$?,"Going over a past exam in my elementary number theory course, I noticed this question that caught my attention. The question asked for the conditions that allowed $-3$ to be a quadratic residue mod $p$ . Doing some experimentation, I found that this was possible when $p \equiv 1 \pmod 3$ . So I guess I have answered part of the question. But the proof is obviously nagging me: Prove $-3$ is a quadratic residue in $\Bbb Z_p$ if and only if $p \equiv 1\pmod 3$ . I've done a bit of work on this, but haven't been able to come up with anything close to elegant nor conclusive. Any help would be appreciated.","['number-theory', 'quadratic-residues', 'elementary-number-theory', 'quadratic-reciprocity']"
3776312,"Topologically, how does a ""super continuum"" differ from the reals?","This is a question I've wondered about for a while. Consider the following setup. Suppose you take a non-Archimedean ordered field, a strict field extension of the reals, and then you form its Dedekind completion. We are interested in these structures in terms of the topology that appears; not algebra - algebraically, they are generally rather badly behaved due to the presence of ""sticking points"" (nonzero elements $a$ such that $a + b = a$ for some other, nonzero $b$ ). The purpose of the algebra is just that it provides a convenient base from which to build them on. We call such a construction a super continuum : Definition: A super-continuum or super-line is a Dedekind completion of a non-Archimedean ordered field extension of the reals. This therefore gives us a whole class of ""line-like"" spaces that are similar to the reals in that they are connected and thus ""continuous"" in some way, but may be quite different, and what I'm interested in is just how, from a topological point of view. Moreover, such a thing seems of interest because it could potentially permit the generalization of some hitherto ""reals-only"" topological concepts like path-connectedness and manifolds to more general kinds of spaces. In particular, we can at the very least construct such a space that cannot be homeomorphic to the reals by creating a suitably large ordered field extension of $\mathbb{R}$ that is itself so big that it is bigger than $\mathbb{R}$ , then performing the Dedekind completion. As its cardinality will then be larger, homeomorphism will not be possible. What, then, may be the properties of such spaces? Moreover, do their attendant extensions of the ideas of path-continuity, say, have any use?",['general-topology']
3776315,"If $\lim_{x \to \infty} f(x) - xf'(x)$ exists, does $\lim_{x \to\infty} f'(x)$ exist as well?","Let $f(x)$ be a differentiable function on $(0, \infty)$ with $\lim_{x\to \infty} f(x) - xf'(x) = L\in \mathbb{R}$ . I'm trying to prove or disprove that $\lim_{x\to\infty} f'(x)$ exists as well. Here's what I have so far: if the limit does exist, it must also equal $\lim_{x\to\infty} \frac{f(x)}{x}$ (divide the limit condition by $x$ ). Then I rewrote the condition as $x^2 \frac{d}{dx} \frac{f(x)}{x} \to L$ , and from this I expect (using some $1/x^2$ asymptotic argument) my statement to be true - but I'm not sure how to rigorously proceed with this argument.. Can someone provide some next steps, or a counter example?","['limits', 'derivatives', 'real-analysis']"
3776324,If $A\cap B^\complement=\emptyset$ then $A\cap B=A$,I need help with this excercise. If $A\cap B^\complement=\emptyset$ then $A\cap B=A$ I try $$A\cap B^\complement =\emptyset$$ $$(A\cap B^\complement)\cap B =\emptyset \cap B$$ $$A\cap (B^\complement\cap B )= B$$ $$A=B$$ Is this reasoning correct?,"['elementary-set-theory', 'solution-verification']"
3776341,"Given that $x_0$ is a real root of $x^3+px + q = 0$, how can I show that $p^2 \geq 4x_0q$?","Given a equation $x^3 + px + q = 0$ and $x_0$ as a real root of this equation, how can I show that $p^2 \geq 4{x_0}q$ ? My attempt: Since this equation has at least one real root, it must then have a discriminant greater or equal to 0 (*not true as the fellas bellow pointed), this led me to $4p^3 + 27q^2 \leq 0$ but I'm not sure how to get to the other relation, and I don't even know if this is the right approach.","['cubics', 'roots', 'examples-counterexamples', 'polynomials', 'algebra-precalculus']"
3776367,Evaluating limits of integrals,"How to evaluate $$\lim_{n \to \infty}\sum_{m=1}^{\infty}\int_{0}^{\infty} \left(\frac{ m+x}{(m^n+x^n)^n} \right )dx$$ I made the substitution $$x = mt$$ and factored out $$m^{-(n^2-2)}$$ . I got this: $$\lim_{n \to \infty} \left(\sum_{m=1}^{\infty}m^{-(n^{2}-2)}\right)\int_{0}^{\infty} (1+t)(1+t^n)^{-n} dt $$ After that I tried the substitution: $$t^{n}=tan^{2}\theta$$ but after substitution I got two beta integrals after which I couldn't proceed further. I got the following: $$\frac{2}{n}\lim_{n \to \infty} \left(\sum_{m=1}^{\infty}m^{-(n^{2}-2)}\right)\int_{0}^{\frac{π}{2}} (\sin^{(\frac{2}{n}-1)}{\theta}\cos^{(2n-\frac{2}{n}-1)}\theta +
\sin^{(\frac{4}{n}-1)}{\theta}\cos^{(2n-\frac{4}{n}-1)}\theta)
 d\theta $$ I couldn't proceed further.The answer is 3/2. Could someone clarify ?
Thank you.","['limits', 'definite-integrals']"
3776371,USATST 2018/P4 : Prove that $OA\perp RA$ [Proof Verification needed],"Acute triangle $ABC$ is inscribed in circle $\omega$ . Let $H$ and $O$ denote its orthocenter and circumcenter, respectively. Let $M$ and $N$ be the midpoints of sides $AB$ and $AC$ , respectively. Rays $MH$ and $NH$ meet $\omega$ at $P$ and $Q$ , respectively. Lines $MN$ and $PQ$ meet at $R$ . Prove that $OA\perp RA$ . I will be very grateful if someone can verify this proof . I am very new to radical axis. Also, Please post your solutions too. We learn a lot from other's solutions too. Thanks in advance. My Proof : Before proceeding further, I would like to state a lemma. Lemma : Let $ABC$ be a triangle with orthocenter $H$ , and suppose that $E$ and $F$ are the feet of the $B$ and $C$ -altitudes. Suppose that the circumcircle of triangle $AEF$ meets the circumcircle of triangle $ABC$ again at $K$ . Let $M$ be the midpoint of $BC$ . Then we have $K, H,$ and $M$ are collinear. Proof of the Lemma : Sine $HF\perp AB$ and $HE\perp AC$ , we note that $H\in (AEF)$ . So $\angle AKH= \angle AFH = 90^{\circ}$ Let $KH\cap(ABC)=X$ . Note that since, $\angle AKH=90^{\circ}$ , we have $X=$ diametrically opposite point of $A$ . But by a known lemma , we know that $H,M,X$ are collinear . So we have $K$ , $ H,$ M$ are collinear. Now, using this Lemma, we claim that $MNPQ$ is cyclic Claim : $MNPQ$ is cyclic Proof: By the above Lemma, we get $H'MHP$ and $QHN{H'}_1$ are collinear, where $H""M=HM$ and $H'$ is the antipode of $P$ wrt $(ABC)$ and $N{H'}_1=HN$ and ${H'}_1$ is the antipode of $Q$ wrt $(ABC)$ . Hence by $POP$ , $\Bbb P(H, (ABC))=HH'\cdot HP=QH\cdot H{H'}_1$ . But $HM=\frac {1}{2} HH'$ and $HN=\frac {1}{2}H{H'}_1= HN \implies HM\cdot HP=QH\cdot HN$ . Hence by converse of $POP$ , we have $MNPQ$ cyclic . Claim : $AMON$ is cyclic with diametre $AO$ . Proof of the Claim : Just note that $AM \perp OM$ and $AN \perp ON$ . Main Proof : Now, using the fact that pairwise radical axis of 3 circles concur, we get that for circles $(MNPQ),(ABC),(AMON)$ ; the pairwise radical axis concur at $PQ\cap MN=R$ . But note that the radical axis of $(ABC)$ and $(AMON)$ is nothing but the line tangent to $(AMON)$ at $A$ . Since $AO$ is the diameter of $(AMON)$ , hence $OA\perp RA$","['contest-math', 'euclidean-geometry', 'solution-verification', 'geometry']"
3776408,Finding the general solution of a system of Differential Equations,"I need helping find the general solution to the following systen $$ x'=2t^2+2-4x+6y $$ $$ y'=-2t^2-t+6-3x+5y $$ I know i need to turn the 2 equations into a matrix, but I can't figure out how to do it. So far I have the matrix for the $x$ and $y$ values and for $t$ , but I don't know what to do with the $+2$ and $+6$ in each equation.","['systems-of-equations', 'ordinary-differential-equations']"
3776416,Minimum Solution Over Closed Ball of $H_0^1(\Omega)$,"Let $\Omega\subset \mathbb{R}^n$ an open bounded domain. Let $\kappa:\Omega \to \mathbb{R}$ a continuous function which $\beta\leq \kappa(x)\leq M \quad \forall x \in \Omega$ , where $0<\beta,M.$ Define $$S:=\{v \in H_0^1(\Omega):\quad \|v\|_{H^1(\Omega)}\leq 1\}.$$ Show that for any $u \in H_{0}^1(\Omega)$ exists a unique $g \in S$ such that $$\int_{\Omega}\kappa(x)|\nabla u(x)-\nabla g(x)|^2dx=\min_{v \in S} \int_{\Omega}\kappa(x)|\nabla u(x)-\nabla v(x)|^2dx.$$ My attempts :
Of course S is closed and convex subset of $H_0^1(\Omega)$ . According to the Approximation Theorem for Hilbert Spaces there is a unique $g \in S$ $$\| u-g\|^2_{H^1(\Omega)}=\min_{v\in S}\int_{\Omega}|u(x)-v(x)|^2+\int_{\Omega}|\nabla u(x)-\nabla v(x)|^2dx$$ and $\langle u-g,v\rangle_{H^1(\Omega)} = 0 \quad \forall v \in V $ . Now we can employ another inner product such as: $$\langle u,v \rangle_\kappa := \int_{\Omega} \frac{1}{\kappa(x)}\nabla u(x)\nabla v(x)dx+\int_{\Omega} \kappa(x)u(x)v(x)dx$$ and $\|u\|_{\kappa}=\langle u,u \rangle^{1/2}_\kappa$ . Of course, $\min\{\frac{1}{M},\beta\}\|u\|^2_{H^1(\Omega)}\leq \|u\|^2_\kappa \leq \max\{\frac{1}{\beta},M\}\|u\|^2_{H^1(\Omega)}$ , then $H^1_0(\Omega)$ is still a Hilbert space and $S$ remains closed and convex. So we can say that exist a unique $g \in S$ . Such that, $$\| u-g\|^2_{\kappa}=\min_{v\in S}\int_{\Omega}\frac{1}{\kappa(x)}|u(x)-v(x)|^2+\int_{\Omega}\kappa(x)|\nabla u(x)-\nabla v(x)|^2dx$$ Where $\langle u-g,v \rangle_\kappa = 0 \quad \forall v \in S$ . There is a way to get conclusion from here or we need to find another approach?","['hilbert-spaces', 'banach-spaces', 'sobolev-spaces', 'functional-analysis']"
3776443,The way to produce a random but ordered series of numbers?,"(Assume that ""Rand()"" can produce truly random real number so we can only produce truly random number through this function.) The common way is to produce a disordered sequence firstly and then sort them. But my question is, can we find a faster way to do this?
Since it's ordered, maybe we can let an initial number grow bigger randomly and then we get an ordered sequence directly with no need to sort it, but it is difficult to guarantee its randomness.
Is it possible? I am a high school student and just curious about the answer.","['computational-complexity', 'probability']"
3776534,Calculating Strange Union,"Hello everyone assume that we set $A$ = {{1 ,2} , {2 ,3} ,{4 ,3}} so what is $\cup_{B \in A} (B)$ ?",['elementary-set-theory']
3776640,Relation: Module structure on the dual and braiding?,"1. Context Let $H$ be a Hopf algebra over a field $\mathbb k$ . Let $(V, p)$ be a finite dimensional (left) $H$ -module.
We want to endow its dual vector space $V^*$ with the structure of a (left) $H$ -module.
For that end define the map $$
  p' \colon H \xrightarrow{\enspace S \enspace} H \xrightarrow{\enspace p \enspace} \operatorname{End}(V) \xrightarrow{\enspace (-){^*} \enspace} \operatorname{End}(V^*) ,
$$ where $(-)^* \colon \operatorname{End}(V) \rightarrow \operatorname{End}(V^*)$ , $f \mapsto f^*$ . In a strict monoidal category we have a graphical calculus. In the following we consider a strictification of $\mathrm{vect}_{\mathbb k}$ .
Then one can write down in string diagrams the definition of the above (left) $H$ -action on $V^*$ as follows: 2. Questions This picture seems to show that the braiding enters in the definition of the induced (left) $H$ -module structure on $V^\vee$ from the (left) $H$ -module structure on $V$ . Correct? How so?","['monoidal-categories', 'modules', 'abstract-algebra', 'hopf-algebras', 'dual-spaces']"
3776653,Weak Topology and the induced topology,"Given a normed space $E$ with a subspace $M$ , it is known that the weak topology on $M$ is the same as the induced topology of the weak topology on $E$ . Why is this the case? From the Hahn-Banach theorem, we can extend the linear functionals on $M$ to $E$ . So my intuition is that any element in the weak topology on $M$ is in the induced topology of the weak topology on $E$ . But why does the other way also hold? I am not really clear how to work with a linear functional on $E$ which cannot be obtained by extending a linear functional on $M$ .","['functional-analysis', 'weak-topology']"
3776685,prove that if $|f(z)|\geq |z|+|\sin(z)|$ then it cannot be an entire function,"Problem: Prove that if $\forall z \in \mathbb{C}.|f(z)|\geq |z|+|\sin(z)|$ then it cannot be an entire function. I thought about claiming that $f$ must be a polynomial because it has a pole in infinity, but I stuck why it polynomial cannot satisfy this property.","['complex-analysis', 'entire-functions']"
3776701,Proof that preimage of a subgroup to quotient group is a subgroup,"Sorry about the slight mess of a title. Let $G$ be a finite group and $N$ a normal subgroup of $G$ . If $H$ is a subgroup of $G/N$ , prove that $\phi^{-1}(H)$ is a subgroup in $G$ of order $|H| \cdot |N|$ , where $\phi : G \to G/N$ is the canonical homomorphism. Attempted solution: First of all, $\phi^{-1}(H) = \{ g \in G : \phi(g) \in H \}$ . To show that it is a subgroup in $G$ , it is sufficient to prove that the set is non-empty and that if $g, h \in \phi^{-1}(H)$ , then $gh^{-1} \in \phi^{-1}(H)$ . Clearly it is nonempty since $H < G/N$ which implies $H$ contains at least the identity. Let $g,h \in \phi^{-1}(H)$ . Then $\phi(gh^{-1}) = \phi(g) \phi(h^{-1}) = gNh^{-1}N = gh^{-1}N$ , since $N$ is normal in $G$ . Note that if $\phi(h) \in H$ , then so must $\phi(h^{-1}) \in H$ , since $H$ is a subgroup. This proves that $\phi^{-1}(H) < G$ . To prove that the order is $|H| \cdot |N|$ , I think it is enough to refer to the fact that $G/N$ contains disjoint subsets of $G$ each of order $N$ (since $G$ is finite) and it is ""obvious"" that we have $|H|$ such subsets so the order of $\phi^{-1}(H)$ is just the product $|H| \cdot |N|$ . However, I'm not sure this is so obvious. Is this proof actually correct?","['group-theory', 'abstract-algebra', 'finite-groups']"
3776708,Asymptote and a function,"If the line $x=1$ is a vertical asymptote to a function, $f(x)$ , then is it true that $f(x)$ is not defined at $x=1$ . Can you lighten me with an example, also? I think it's true??","['calculus', 'functions']"
3776710,A convex closed set with disconnected boundary: is it necessarily a strip?,"Consider the following Problem: Suppose $X \subset \Bbb R^n$ is a closed convex set. Can we deduce that its boundary $\partial X$ is connected? At first sight, I was thinking about spheres, so that this seemed to be true. Then I found a counterexample: the strip between two parallel hyperplanes. For example $$X= \{ (x_1, \dots , x_n) : 0 \le x_1 \le 1\}$$ is a counterexample. However it seems that no other counterexample can be produced. Indeed a convex set is an intersection of some half-spaces, determined by hyoerplanes, and if I pick any two non parallel hyperplanes they would intersect ""forming a connection in the boundary"". Can we write down a formal proof about this? True Question: Suppose $X \subset \Bbb R^n$ is a closed convex set whose boundary $\partial X$ is not connected. Prove that $X$ has the form $$X= \{ \mathrm x \in \Bbb R^n : a \le \mathrm v \cdot \mathrm x \le b \}$$ for some $\mathrm v \in \Bbb R^n$ and $a,b \in \Bbb R$ .","['multivariable-calculus', 'general-topology']"
3776734,"Evaluate $\int_0^{\pi/2} \frac{\cos ((1-a) x)}{\cos ^{a-1}(x) (\cosh (2 b)-\cos (2 x))} \, dx$","How to prove $$\int_0^{\pi/2} \frac{\cos ((1-a) x)\cos ^{1-a}(x)}{ (\cosh (2 b)-\cos (2 x))} \, dx=\frac{\pi  e^{(a-1)b}}{4\sinh (b) \cosh ^a(b)}$$ So far I've got no idea of tackling it (my intuition is on contour integration). I'd like you to give some suggestions. Thanks in advance! Update: I found an alternate proof for @pisco's general formula. By using Fourier expansion $$\frac{\sinh (2 b)}{\cosh (2 b)-\cos (2 x)}=2 \sum _{k=1}^{\infty } e^{-2kb} \cos (2 k x)+1$$ and trigonometric identities $\cos*\cos\to \cos+\cos$ , one have $$\small I=\int_0^{\pi /2} {\frac{{{{(\cos x)}^a}\cos cx}}{{\cosh 2b - \cos 2x}}dx} =\frac{\sum _{k=1}^{\infty } \exp (-2 b k) (f(a+1,c+2 k)+f(a+1,c-2 k))+f(a+1,c)}{\sinh (2 b)}$$ Where $f$ denotes the classic Cauchy integral ( $\Re v>0$ ) $$f(v,a)=\int_0^{\frac{\pi }{2}} \cos (a x) \cos ^{v-1}(x) \, dx=\frac{\pi }{2^v v B\left(\frac{1}{2} (a+v+1),\frac{1}{2} (-a+v+1)\right)}$$ Performing the summation using definition of hypergeometric functions one have $$\small I=\frac{\pi  2^{-a-1} \text{csch}(2 b) \left(e^{-2 b} \left(\frac{\, _2F_1\left(1,\frac{1}{2} (-a-c+2);\frac{1}{2} (a-c+4);-e^{-2 b}\right)}{B\left(\frac{a+c}{2},\frac{1}{2} (a-c+4)\right)}+\frac{\, _2F_1\left(1,\frac{1}{2} (-a+c+2);\frac{1}{2} (a+c+4);-e^{-2 b}\right)}{B\left(\frac{1}{2} (a+c+4),\frac{a-c}{2}\right)}\right)+\frac{1}{B\left(\frac{1}{2} (a+c+2),\frac{1}{2} (a-c+2)\right)}\right)}{a+1}$$ Which, after simplifications, should agree with @pisco's result (it passed my numeric verification so I won't simplify it further).","['integration', 'complex-analysis', 'definite-integrals', 'fourier-analysis']"
3776738,"If $15$ distinct integers are chosen from the set $\{1, 2, \dots, 45 \}$, some two of them differ by $1, 3$ or $4$.","$\blacksquare~$ Problem: If $15$ distinct integers are chosen from the set $\{1, 2, \dots, 45 \}$ , some two of them differ by $1, 3$ or $4$ . $\blacksquare~$ My Approach: Let the minimum element chosen be $n$ . Then $n + 1 , n + 3 , n + 4 $ can't be taken. We make a small claim. $\bullet~$ Claim: In a set of $~7$ consecutive numbers at most $2$ numbers can be chosen. $\bullet~$ $\textbf{Proof:}$ Let us name the elements of the set as $\{ 1,2,3,\dots,7 \}$ . Now let's consider the least element is chosen. If the least element is $1$ , then $2,4,5$ can't be chosen. So we are left with $3, 6, 7$ . $\circ~$ If $~3~$ is chosen, then $6, 7$ can't be in the set. And if $~3~$ is not chosen, then only any one of the 2 elements $\{ 6, 7  \}$ be chosen. So, a maximum of $2$ elements can be chosen in this case. $\circ \circ~$ If the least element is $2,$ then $3, 5, 6$ can't be there in the set. So, possible elements are 4, 7. So,  one of these two can be chosen. Then, a maximum of 2 elements can be chosen in this case. $\circ \circ~$ If the least element is $3$ , then $4,6,7$ gets cancelled. so only $5$ is left in the set i.e., $2$ elements at most. $\circ \circ~$ If the least element is $4,$ then $5,7$ gets cancelled. So the only element left is $6$ . Similarly, $\circ \circ~$ If $5$ is the least element then $6$ gets cancelled and only $7$ is left. i.e., two elements. If the least element is either $6$ or $7$ , then there is only one element. So a maximum of two elements in a set of $7$ consecutive elements can be chosen. Hence, the proof of the claim is done! So, for $42$ elements, a maximum of $2 \times 6 = 12$ can be taken. However, $3$ more elements are required from $3$ more consecutive elements, which is not possible since only 2 elements at most can be chosen from a set of 3 consecutive elements. So, a $14$ element subset can be formed such that, no two of them differ by $1, 3, 4$ . Hence the $15$ th element is one of the cancelled elements, that is, there exists a pair with their difference being $1, 3$ or $4.$ Hence, done! Please check the solution for glitches and give new ideas too :).","['pigeonhole-principle', 'solution-verification', 'combinatorics', 'discrete-mathematics']"
3776745,Prove $\sum_{n=0}^{\infty} \frac{\Gamma(n+(1/2))}{4^n(2n+1)\Gamma(n+1)}=\frac{\pi^{3/2}}{3}$,"Prove $$\sum_{n=0}^{\infty} \frac{\Gamma\left(n+\frac{1}{2}\right)}{4^n\left(2n+1\right)\Gamma\left(n+1\right)}=\frac{\pi^{\frac{3}{2}}}{3}$$ The original sum is multiplied by $\frac{\sqrt{\pi}}{2}$ and so it equals $\frac{\pi^2}{6}$ but I pulled the constant out because the actual series troubles me.  I dont know how to evaluate this.  I think maybe the Gammas and $4^n$ simplify and leave some constant divide by $2n+1$ which is the familiar arctan series. Wolfram can't help simplify it, just compute it.  Any help please?","['calculus', 'sequences-and-series', 'taylor-expansion', 'real-analysis']"
3776793,Why can we cover $\mathbb R^N$ with open balls of radius $r$ such that each point is in at most $N + 1$ balls?,"If $N \geq 3$ , why can we cover $\mathbb R^N$ with open balls of a fixed radius $r$ such that each point is in at most $N + 1$ balls? This is a claim in a proof of Lions' Vanishing Lemma, as presented in Willem's Minimax Theorems (Lemma 1.21). Probably very simple but I am not able to write a proper proof.","['combinatorial-geometry', 'combinatorics', 'geometry', 'metric-spaces']"
3776801,Convergence a.s from a sub-sequence,"Let $(X_n)_n$ be a sequence of independent random variables. Let $Y_n=\frac{1}{n}\sum_{k=1}^nX_k.$ Prove that if $(Y_n)_n$ converges in probability to $0$ and if $Y_{2^n}$ converges a.s to $0$ then $Y_n$ converges a.s to $0$ . $Y_n$ converges a.s if $\forall \epsilon>0,\lim_n P(\sup_{k \geq n}|Y_k|>\epsilon)=0,$ any ideas how to use the above facts to prove the result?","['measure-theory', 'convergence-divergence', 'probability-theory']"
3776825,"$|f'(x)| \le g(x)$ implies $|f(b) - f(a)| \le \int_a^b g(x) dx$, without assuming $f'$ to be integrable.","In a recent answer I needed an argument of the following kind: Let $f, g: [a, b] \to \Bbb R$ be functions with the following
properties: $f$ is differentiable, $g$ is continuous, $|f'(x)| \le g(x)$ for all $x \in [a, b]$ . Then $|f(b) - f(a)| \le \int_a^b g(x) \, dx$ . Seems pretty easy: We have $$ \tag{*}
 |f(b) - f(a)| = \left| \int_a^b f'(t) \, dt \right| 
\le \int_a^b |f'(x)| \, dx \le \int_a^b g(x) \, dx \, .
$$ There is just one problem: We have used the fundamental theorem of calculus , and that requires $f'$ to be Riemann integrable (or Lebesgue integrable and absolutely continuous), compare Necessity of a hypothesis in the fundamental theorem of calculus . This is for example satisfied if $f'$ is continuous. But the above statement holds without additional assumptions on $f'$ : Let $n$ be a positive integer and $x_k = a + \frac kn (b-a)$ , $0 \le k \le n$ , be a partition of the interval $[a, b]$ . We apply the mean-value theorem to each subinterval $[x_k, x_{k+1}]$ : $$
 f(x_{k+1}) - f(x_k) = (x_{k+1} - x_k) f'(c_{n, k})
$$ for some $c_{n, k} \in [x_k, x_{k+1}]$ . It follows that $$
|f(b) - f(a)| \le \sum_{k=0}^{n-1}| f(x_{k+1}) - f(x_k)| \le \sum_{k=0}^{n-1} (x_{k+1} - x_k) g(c_{n, k}) \, .
$$ $g$ is continuous and therefore Riemann integrable. The expression on the right is a Riemann sum for $\int_a^b g(x) \, dx$ with the partition size $(b-a)/n$ . It follows that $$
 \lim_{n \to \infty } \sum_{k=0}^{n-1} (x_{k+1} - x_k) g(c_{n, k})  = \int_a^b g(x) \, dx
$$ and therefore $|f(b) - f(a)| \le \int_a^b g(x) \, dx$ . My question: Is there a simpler proof of the statement? It seems pretty basic, therefore I wonder if there is a simpler proof, without going into technical details such as partitions and Riemann sums. Perhaps it is a consequence of some other theorem about integration which I failed to find?","['integration', 'reference-request', 'real-analysis']"
3776830,"If $|G|=120$ and $|H|=24$ and $H$ has at least two Sylow $2$-subgroups, then does $G$ acts faithfully on $G/H$?","If $|G|=120$ and $|H|=24$ and $H$ has at least two Sylow $2$ -subgroups, then does $G$ acts faithfully on $G/H$ ? I know that, if $n$ is the number of Sylow $2$ -subgroups of $H$ , then by Sylow's theorems, $n\mid \frac{24}{8}=3$ , so $n=3$ because $n\geq 2$ . Also, I know that the kernel of the action of $G$ on $G/H$ by left translations is $\bigcap\limits_{g\in G}gHg^{-1}$ . Actually I am trying to do the last item from the exercise 10 of section 1.13 of Jacobson's Basic Algebra 1 about a characterization of $S_5$ , but I do not know if the information I obtained about $H$ is sufficient to it. I tried to follow the hints from someone in this page: An Abstract Characterization of $S_5$ using involutions and their centralizers , that suggests me to prove first that the kernel $K$ of the action is a proper subgroup of $H$ , that $K$ is centralized by an element of order $5$ , looking at $\mathrm{Aut}(K)$ , so it cannot contain elements of order $2$ , and to prove that $K=Z_3$ would be normal in $G$ , leading to a contradiction. But I do not know even how to prove that $K\neq H$ . I tried to do this: If $K=H$ , then $\bigcap\limits_{g\in G}gH^{-1}g=H$ , so $H$ is a normal subgroup of $G$ , then $G/H$ is a group isomorphic to $Z_5$ and the action would be a homomorphism from $G$ to $G/H\cong Z_5$ , but after this I am stuck.","['group-theory', 'group-actions', 'finite-groups', 'sylow-theory']"
3776840,2D cubic Bezier curve. Point of self-intersection,"I have a 2D cubic Bézier curve defined by a set of control points A, B, D and C.
How can I find a point of self-intersection P (two parameter values t)?","['cubics', 'parametric', 'bezier-curve', 'geometry']"
3776856,Compute the matrix of norms of $A=\begin{bmatrix}3&4\\1&-3\end{bmatrix}$,"My work so far Using the following $\hspace{30px} L^1\ =\displaystyle \max_{\small 1\le j\le m}(\displaystyle \sum_{i=1}^n |a_{ij}|)\\ \hspace{30px} L^2\ =\sigma_{max}(A)\\ \hspace{30px} L^F\ =\sqrt{\displaystyle \sum_{i} \displaystyle \sum_{j} |a_{ij}|^2}\\ \hspace{30px} L^\infty\ =\displaystyle \max_{\small 1\le i\le n}(\displaystyle \sum_{j=1}^m |a_{ij}|)\\$ Thus, $L^1=\begin{bmatrix}3&\textbf{4}\\1&\textbf{3}\end{bmatrix}=7\\
L^2=?\\
L^F=\sqrt{3^2+4^2+1^2+(-3)^2}=\sqrt{35}=5.916079783\\
L^\infty=\begin{bmatrix}\textbf{3}&\textbf{4}\\1&-3\end{bmatrix}=7$ However, I'm unsure how to get $L^2$ . How would I start off doing this part?","['matrices', 'linear-algebra']"
3776889,Interpreting almost sure convergence,"I'm reading: https://en.wikipedia.org/wiki/Convergence_of_random_variables#Almost_sure_convergence and here it says that Given a probability space $(\Omega,\mathcal{F},P)$ and a random variable $X:\Omega \rightarrow \mathbb{R}$ almost sure convergence stands for $$P\left(\omega \in \Omega: \lim_{n \rightarrow \infty} X_n(\omega)=X\right)=1.$$ [...] almost sure convergence can also be defined as follows: $$P\left(\limsup_{n \rightarrow \infty} \left\{\omega \in \Omega: |X_n(\omega) - X(\omega)| > \varepsilon\right\}\right)=0, \quad \forall \; \varepsilon>0.$$ My question is, what is the intuition behind this equivalence? I understand the first definition, but why do we use $\limsup$ in the second one to make the equivalence work? Thanks","['almost-everywhere', 'convergence-divergence', 'probability-theory', 'probability', 'random-variables']"
3776893,Why must $\int_\gamma f(z)\;d z = 0$ for *any* contour $γ$ to define antiderivative of $f$?,"Whilst I was reading the following proposition from Dexter Chua's lecture notes on Complex Analysis: Let $U \subseteq \mathbb{C}$ be a domain (i.e. path-connected non-empty open set), and $f: U \to \mathbb{C}$ be continuous. Moreover, suppose $$
    \int_\gamma f(z)\;d z = 0
  $$ for any closed piecewise $C^1$ -smooth path $\gamma$ in $U$ . Then $f$ has an antiderivative. I am not sure where in the proof does use the property that the integral must vanish on a closed path except at its well-definedness. Sketch Proof: Pick any point $a_0\in U$ and let $\gamma_w$ be any path from $a_0$ to $w.$ Define $F(w) = \int_{\gamma_w} f(z)\;d z,$ we will show it is an antiderivative, now use the hypothesis that the integral around a closed path must vanishes shows that such $F(w)$ is independent of the path chosen. Since $U$ is open, we can pick $\epsilon > 0$ such that $B(w; \varepsilon) \subseteq U$ . Let $\delta_h$ be the radial path in $B(w, \varepsilon)$ from $w$ to $w + h$ , with $|h| < \varepsilon$ . Now note that $\gamma_w * \delta_h$ is a path from $a_0$ to $w + h$ . Now we can show, $$\left|\frac{F(w+h)-F(w)}{h}-f(w)\right|\to 0$$ as $h\to 0$ [I have skipped a great detail of the proof, the full proof can be found here . Page 22] My confusion: Why do we need $F$ to be independent on the path taken? Why can we not have the situation where each path will yield a different anti-derivative? Moreover suppose the definition of $F(w)$ does depend on the path taken (and so different path gives different $F$ ), would it not be true that for each path $\gamma_i$ , the induced $F_{\gamma_i}(z)$ will have the property that $F_{\gamma_i}'(z)=f(z)$ , simply because the above limit, where $h\to 0$ will still stand? (I know this will not be true since if this is true then any continuous function will have an anti-derivative but I cannot seem to see where, other than well-defineness, does it use the integral must vanish property.) Many thanks in advance!","['integration', 'complex-analysis', 'indefinite-integrals', 'proof-explanation']"
3776957,A Question Based on Properties of Direct Product of Fields,"I am unable to solve this particular problem in abstract algebra: Let $p\geq$ 5 be a prime and $\mathbb{F}_p $ be field of p elements. Then is following statement true or false: $\mathbb{F}_p $ × $\mathbb{F}_p $ has at least five subgroups of order $p$ . I think it is false as I think subgroup of $\mathbb{F}_p$ × $\mathbb{F}_p$ must be of form $H_{1} $ × $H_{2}$ , where $H_{1} $ , $H_{2} $ are subgroups of $\mathbb{F}_p $ and using Lagrange theorem I get only four subgroups of $\mathbb{F}_p$ × $\mathbb{F}_p$ . But the answer is that it's true for which I have no clue.","['field-theory', 'group-theory', 'abstract-algebra', 'cyclic-groups']"
3776966,Given the following tangent circles chain to draw the next circle of the chain,the chain is from the yellow circles. What I want is a way to draw the next yellow circle given all the ones before it: I know how to draw the first circle $(P_0Q_0X)$ . I know the (nameless in the picture) contact point of the $n-th$ circle with the $n+1-th$ one lies on a circle centered at $H = P_0Q_0 \cap BC$ passing through $C$ . I know lines $P_nQ_n$ all meet in $H$ . I know quads $P_nP_{n+1}Q_{n+1}Q_n$ are cyclic. I still can't find a simple way to construct the next circle given the previous one.I know there are one or two inversions that can do the trick but I would prefer if we avoid the temptation of looking for invertions. I can't prove but I know the circles $P_nQ_nC$ are tangent to $BC$ at $C$ EDIT: also don't just use the general apollonius solution unless you can make sure you can show some symetry from this particular problem. For example: because we know the contact points between two circles lie on a circle centered at $H$ passing through $C$ we don't need the full $CCC$ but we can use $PCC$ (of course you guys are suposed to show more simplifications),"['homothety', 'circles', 'geometry']"
3776981,The set of all sequences of complex numbers with limit $0$ is a subspace of $\mathbb{C}^{\infty}$,"In Axler's Linear Algebra Done Right , they set an example for a subspace: The set of all sequences of complex numbers with limit 0 is a subspace of $\mathbb{C}^{\infty}$ , where $\mathbb{C}^{\infty}$ denotes the vector space of complex sequences over $\mathbb{C}$ . How can I interpret the ¨with limit 0¨ part? does it mean, looking at an element of the subspace as a function f(z), that $$\lim_{z\rightarrow z_o} f(z) = 0$$ ? How can we go on about to prove sub set of functions is a subspace?",['linear-algebra']
3776996,Combinatoric question on preimage of a function,"Got stuck on the following combinatoric question. Will be glad for any suggestions. Find the number of functions $f:\{1,2,3,4\} \rightarrow \{1,2,3,4\}$ so that for all $1\le i\le4$ , $f^{-1}(\{i\})≠\{i\}$ . (i.e. Find the number of these functions in which the pre-image of a subset with a single member is different from the set containing that member.) Now, finding the number of injective functions that fulfill this is pretty easy (it's called the number of ""derangements"" of a set and is the number of injective functions with no fixed point, equal in this case to 9) but there are so many other possibilities that checking them all, seems to be too tedious. For example a partly injective function such as $f(1)=2 ,\ f(2)=2, \ f(3)=1, \ f(4)=3$ fulfills the condition in spite of $2$ being a fixed point, since the pre-image of $2$ is $\{1,2\}$ which is different from $\{2\}$ .","['functions', 'combinatorics']"
3777016,Evaluating $\int_{0}^{\frac{\pi}{2}} \frac{1}{\sin^m x+\cos^m x}dx$,"I evaluated the following integral: $$I=\int_{0}^{\frac{\pi}{2}} \frac{1}{\sin^8x+\cos^8x}dx$$ My Method: Divide up and down by $\cos^8x$ and substitute $t=\tan x$ , so the integral converts to $$I=\int_{0}^{\infty}\frac{(1+t^2)^3}{1+t^8}\mathrm{d}t$$ I evaluated this integral by substituting $t^8=u$ and using the general result $$\displaystyle \int_{0}^{\infty}\frac{u^{n-1}}{1+u}\mathrm{d}u=\frac{\pi}{\sin n\pi}$$ which can be evaluated easily. However, I wanted to generalise this integral $$I(m)=\int_{0}^{\frac{\pi}{2}}\frac{1}{\sin^mx+\cos^mx}dx$$ But the above method doesn't apply to any value of $m$ . So, what should be the approach for the above integral? We also know that $I(0)=\frac{\pi}{4}$ , so maybe we could make a recurrence relation or perhaps, feynmann's technique ...","['integration', 'calculus', 'definite-integrals', 'trigonometric-integrals']"
3777017,Galois Group of $x^4 - 7$ over $\mathbb{F}_5$,"I am asked to find the Galois Group of the polynomial $x^4 - 7$ over $\mathbb{F}_5$ . I am wondering if the following is correct: The splitting field of $x^4 - 7 = x^4 - 2$ over $\mathbb{F}_5$ is $\mathbb{F}_5(\sqrt[4]{2},i)$ where $i,\sqrt[2]{2}$ lie in a fixed algebraic closure of $\mathbb{F}_5$ and $i^2 = -1$ and $(\sqrt[4]{2})^4 = 2$ . Since $2^2 = 4 = -1 \in \mathbb{F}_5$ we see that $i = 2$ . Now, $x^4 - 2$ does not have any roots in $\mathbb{F}_5$ and so $[\mathbb{F}_5(\sqrt[4]{2}): \mathbb{F}_5] = 2$ or $4$ which means the Galois Group is either order $2$ or $4$ . If it were $2$ , then $\sqrt[4]{2} = a + b\sqrt{2}$ where $a,b \in \mathbb{F}_5$ . After squaring we must have that $a^2 + b^2 = 0$ and $2ab = 1$ . This is an impossibility and so the degree of this extension (and hence the order of the Galois group) is $4$ . Consider $\sigma: \mathbb{F}_5(\sqrt[4]{2}) \to \mathbb{F}_5(\sqrt[4]{2})$ given by $\sigma(\sqrt[4]{2}) = 2\sqrt[4]{2}$ . This is an automorphism of $\mathbb{F}_5(\sqrt[4]{2})$ of order $4$ and so must be the the galois group is $\langle \sigma \rangle$ .","['field-theory', 'galois-theory', 'abstract-algebra', 'solution-verification']"
3777027,What is the difference between stochastic process and random variable?,"I am having a hard time grasping the core difference between a random variable and a stochastic process. A random variable assigns a number to every outcome of an experiment. A random process assigns a function of time to every outcome of an experiment.
But the values of this function of time can be represented with ONE SINGLE random variable as well. So what is the point in having a stochastic process when you can represent an experiment with only random variables? Could somebody make one or two examples where the difference is clear? Appreciate it","['stochastic-analysis', 'stochastic-processes', 'probability-theory', 'stochastic-calculus', 'random-variables']"
3777040,Consistency of summation methods,"Two summation methods $\Sigma_1, \Sigma_2 : (\mathbb{N} \rightarrow \mathbb{C}) \rightharpoonup \mathbb{C}$ are consistent iff $\Sigma_1 \cup \Sigma_2$ is functional (right-unique), i.e. $$ \forall x \in (\operatorname{dom} \Sigma_1 \cap \operatorname{dom} \Sigma_2) : \Sigma_1(x) = \Sigma_2(x) $$ Many of the well-known summation methods (Cesàro summation, Abel summation, Borel summation, Euler summation, etc.) turn out to be consistent with each other. Are there any examples of mutually inconsistent summation methods that are not ad hoc , i.e. motivated by or constructed for the purpose of being mutually inconsistent? If not, is there some explanation behind this fact? Is it possible there's some kind of ideal ""general summation"" that all these methods are approaching? Note that this is different from the question of non-constructive extensions such as those given by the Hahn-Banach theorem .","['summation-method', 'divergent-series', 'summation', 'sequences-and-series']"
3777052,Every mixed Poisson process is also a compound Poisson process?,"In section 3.6 of this paper: https://www.jstor.org/stable/25472639?read-now=1&seq=8#page_scan_tab_contents , the authors state that mixed Poisson distributions that are infinitely divisible can be represented as some Compound Poisson distribution. An example of this is the Negative Binomial point process (which is a Poisson mixture with the rate parameter being gamma distributed). It can also be considered a Compound Poisson point process with a logarithmic distribution being the compounding distribution. What I don't understand is how these two kinds of point processes can be the same. For example, consider the number of events from the point process in some interval, $\delta t$ . As $\delta t \to 0$ , the number of events with the Mixed Poisson process should be either $0$ or $1$ . It should be very unlikely to encounter $2$ events in a very small interval. For a Compound Poisson, this shouldn't be so unlikely since we only need a Poisson arrival in the small interval and then the compounding distribution can easily be $2$ or more. What is wrong with my reasoning?","['poisson-distribution', 'statistics', 'poisson-process', 'probability']"
3777129,Set Operation $D = (A \times B) - (B \times C)$,"I want to find $$
D = (A \times B) - (B \times C)
$$ where $$
A = \{x.y,z\}, \ B = \{1,2\}, \ C = \{x,z\} 
$$ So far I have computed $$
A \times B = \{(x,1), (x,2), (y,1),(y,2),(z,1),(z,2)\} 
$$ and $$
B \times C = \{(1,x),(1,z),(2,x),(2,z)\} 
$$ Hence $$
D = \{(x,1), (x,2), (y,1),(y,2),(z,1),(z,2)\} - \{(1,x),(1,z),(2,x),(2,z)\}
$$ This is where I am stuck because cartesian product order matters. The answer is $$
D = \{(x,1), (x,2), (y,1),(y,2),(z,1),(z,2)\} 
$$ and I have no idea why. Is difference sets when set doesn't share something together like example $\{1,2,3\} - \{2,3,4\} = \{1\}$ if I am not mistaken.",['elementary-set-theory']
3777176,"Show that the set $A=\big\{ f_y\,\big|\, y\in[0,1]\big\}$ is compact in ${\mathcal C}[0,1]$.","Let $f:[0,1]\times[0,1]\to\mathbb R$ be continuous.
For each $y\in[0,1]$ define $f_y:[0,1]\to\mathbb R$ by $f_y(x)= f(x,y)$ .
Show that the set $A=\big\{ f_y\,\big|\, y\in[0,1]\big\}$ is compact in ${\cal C}[0,1]$ . I tried to use the Arzela-Ascoli Theorem, that is $A$ is comapct if and only if $A$ is closed, pointwise bounded and equicontinuous. I managed to show that $A$ is pointwise bounded by Extreme Value Theorem. I am not sure how to prove that $A$ is closed and equicontinuous.","['arzela-ascoli', 'general-topology', 'functional-analysis', 'real-analysis']"
3777261,How to prove: If $A_2 ⊆ A_1 ⊆ A_0 $ and $A_2 ≈ A_0$ then $A_2 ≈ A_1 ≈ A_0$,"$A_0$ is a set, "" $A_0 ≈ A_2$ "" means there is a bijective function from $A_0$ to $A_2$ . So, how to prove the following proposition? If $A_2 ⊆ A_1 ⊆ A_0$ and $A_2 ≈ A_0$ then $A_2 ≈ A_1 ≈ A_0$ .",['elementary-set-theory']
3777272,"Is $\phi =\angle A""OB"" = \measuredangle(AB,A""B"")=\measuredangle(A'B',A""B"")$? [Doubt]","Can someone clarify this doubt ? We denote the spiral similarity by $S$ , the rotation centered at $O$ with
angle $\phi$ by $\rho _O ,\phi$ , and the homothety centered at $O$ with ratio $k$ by $\chi _{ O, k}$ , then $S _{O, k, \phi}$ = $\rho_O, \phi \circ \chi _{ O, k}$ . Consider the following image : We are given a triangle $ABC$ which is being dilated by a spiral symmetry $S$ centred at $O$ with ratio $k$ and and angle $\phi$ . I noted that since angles are preserved in dilation and homothety, we get that $\Delta ABC \sim \Delta A""B""C"" $ . Also $\Delta OAB \sim \Delta OA""B""$ . And we have $\angle A""OB""=\angle AOB$ . And we also have $\measuredangle(AB,A""B"")=\measuredangle(A'B',A""B"")$ (since $A'B'||AB$ ) . But I couldn't understand how $\measuredangle(AB,A""B"")=\measuredangle(A'B',A""B"")=\phi$ . Isn't $\phi =\angle A""OB""$ ? Here is the whole explanation of the book:","['contest-math', 'euclidean-geometry', 'geometry', 'geometric-transformation', 'rotations']"
3777277,Why is the following method of finding out a conserved quantity wrong?,"Let a system be defined by $\dot{x}=y; \dot{y}=f(x).$ And let $E(x,y)$ be a conserved quantity of the system. Then $$
\frac{\partial{E}}{\partial{x}}\dot{x}+\frac{\partial{E}}{\partial{y}}\dot{y}=0.
$$ My question is why cannot I just rewrite this equation as $$
\frac{\frac{\partial{E}}{\partial{x}}}{{\frac{\partial{E}}{\partial{y}}}}=\frac{-\dot{y}}{\dot{x}}.
$$ $$
\frac{dy}{dx}=\frac{-\dot{y}}{\dot{x}}.
$$ Now the separation of variables would easily give me a curve in $(x,y)$ space which can also be thought of as a conserved quantity. Looking at examples in Strogatz, I figured out that this  method is wrong, but I am unable to find out why?",['ordinary-differential-equations']
3777291,how to solve derivative of a function including two absolute functions,"So I don't understand how to solve the derivative of a function with two absolute functions. $$f(x) = |x - 1| + |x^2 - 2x|.$$ Here is the function. I need to solve the maximum and minimum values in the domain $[0,2]$ but can't figure out the derivative.","['maxima-minima', 'calculus', 'derivatives', 'absolute-value']"
3777305,"Special value of hypergeometric function $\, _2F_1\left(a,a+\frac{1}{3};\frac{4}{3}-a;-\frac{1}{8}\right)$","How can one prove $$\, _2F_1\left(a,a+\frac{1}{3};\frac{4}{3}-a;-\frac{1}{8}\right)=\frac{\left(\frac{2}{3}\right)^{3 a} \Gamma \left(\frac{2}{3}-a\right) \Gamma \left(\frac{4}{3}-a\right)}{\Gamma \left(\frac{2}{3}\right) \Gamma \left(\frac{4}{3}-2 a\right)}$$ This originate from an integral of algebraic functions. What exact transformation can be used to prove this identity? I'd like you to give some suggestions. Thank you! Update:
The following Mathematica commands verify the quartic transformation given in @pisco's answer: DifferentialRootReduce[Hypergeometric2F1[4 b/3, (4 b + 1)/3, (4 b + 5)/6, x], x]
DifferentialRootReduce[(1 + 8 x)^(-b) Hypergeometric2F1[b/3, (b + 1)/3, (4 b + 5)/6, 64 x (1 - x)^3/(1 + 8 x)^3], x]
Series[Hypergeometric2F1[4 b/3, (4 b + 1)/3, (4 b + 5)/6, x], {x, 0, 2}]
Series[(1 + 8 x)^(-b) Hypergeometric2F1[b/3, (b + 1)/3, (4 b + 5)/6, 64 x (1 - x)^3/(1 + 8 x)^3], {x, 0, 2}]
Limit[(1 + 8 x)^(-b) Hypergeometric2F1[b/3, (b + 1)/3, (4 b + 5)/6, 64 x (1 - x)^3/(1 + 8 x)^3], x -> -1/8, Direction -> -1]","['gamma-function', 'special-functions', 'hypergeometric-function', 'sequences-and-series']"
3777312,formula for the $k$th coefficient of a polynomial plugged into itself $n$ times,"If a polynomial with coefficients $a_k$ is plugged into itself $n$ times, this will result in another polynomial with polynomial coefficients $b_k$ . Find an explicit formula for $b_k$ given $a_k$ , and $n$ . For example, $f(x)$ is a polynomial with the following coefficients $a_0=1$ , $a_1=2$ , and $a_2=3$ . All other coefficients $a_m$ where $m>2$ are zero. This will result in the following polynomial. $$
f(t) = 1 + 2x + 3x^2
$$ We want to find the polynomial coefficients of this polynomial after it is plugged into itself 1 time, thus $n=1$ . $$
f(f(t)) = 1 + 2(1 + 2x + 3x^2) + 3(1 + 2x + 3x^2)^2
$$ $$
f(f(t)) = 6 + 16 x + 36 x^2 + 36 x^3 + 27 x^4
$$ Thus $b_0=6$ , $b_1=16$ , $b_2=36$ , and so on. So, in summary, if a polynomial with polynomial coefficients $a_k$ plugged into itself $n$ times, what are the coefficients of the resulting polynomial $b_k$ ?","['number-theory', 'abstract-algebra', 'polynomials', 'real-analysis']"
3777321,"A question based on quadratic forms in linear algebra ( rank, representation)","This particular question was asked in masters of mathematics exam of a university and I am unable to solve it. So I am asking it here. Consider the quadratic form $Q(v)=v^{t} A v$ , where $$A=\begin{bmatrix}
1 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 \\
0 & 0 & 0 & 1 \\
0 & 0 & 1 & 0
\end{bmatrix},\quad v=(x, y, z, w)$$ Then $Q$ has rank 3 . $x y+z^{2}=Q(P v)$ for some invertible $4 \times 4$ real matrix $P$ $x y+y^{2}+z^{2}=Q(P v)$ for some invertible $4 \times 4$ real matrix $P$ . $x^{2}+y^{2}-z w=Q(P v)$ for some invertible $4 \times 4$ real matrix $P$ . Attempt: Determinant of $D_{1} $ =1 , $D_{2}$ = 1 , $D_{3}$ =-1 for some matrix and $D_{4}$ = -1 . So matrix is neither positive definite nor negative definite. Also, I have read everything about quadratic forms from wikipedia as quadratic forms were not covered in my linear algebra class. So, can anyone please tell how to solve this question. Can anyone please tell any textbook of linear algebra which covers quadratic forms in detail? I shall be really thankful.","['matrices', 'linear-algebra', 'quadratic-forms']"
3777324,if continuous function $f$ is zero almost everywhere then $f = 0$ everywhere,"If the function $f:G \to \mathbb{R}$ with $G$ a domain in $\mathbb{R}^n$ ,and $f$ is continuous. Prove if $f = 0$ almost everywhere(In Lebesgue measure) then $f = 0$ everywhere. My attempt: w.l.o.g assume $f(x)>0$ for some $x$ ,since $f$ is continuous ,there exist a neighborhood of $x$ with all $f(y)>0$ on the neighborhood,and the neighborhood is not measure zero.So we have the result. Is my proof correct?","['measure-theory', 'solution-verification', 'real-analysis']"
3777375,How to prove that the induced topology is the coarsest and identification topology is the finest topology that keeps the map continuous?,"I am reading maps between topological space from Isham, Chris J. Modern differential geometry for physicists. Vol. 61. World Scientific, 1999. . Here he defines the induced topology and the identification topology in the following way If $(Y,\tau)$ is a topological space and $f$ is a map from $X$ to $Y$ then the induced topology on $X$ is defined to be $$
 f^{-1}(\tau):=\{f^{-1}(O)|O \in \tau\} $$ The key property of the
induced topology is that it is the coarsest topology such that $f$ is
continuous Another important example arises when $(Y,\tau)$ is a topological
space and there is a surjective map $p: Y \to X$ . The identification topology on $X$ is defined as $$ 
p(\tau) := \{A\subset X | p^{-1}(A) \in \tau\}
 $$ The key property of this topology is that it is the
finest one on $X$ such that $p$ is continuous. I want to prove that the induced topology is the coarsest topology such that $f$ is continuous the identification topology is the finest topology such that $p$ is continuous I know that a map $f:(W,\tau) \to (V,\tau')$ is a continuous map if for all $O \in\tau', f^{-1}(O) \in \tau$ . I also know that in general, any maps between two sets ( $f:A\to B$ ) have the property $$
f^{-1}(A\cap B) = f^{-1}(A) \cap f^{-1}(B) \\
f^{-1}(A \cup B) = f^{-1}(A) \cup f^{-1}(B)
$$ This comes handy to prove that both of the induced and identification topologies are topologies. But I don't know where to start with the proofs.","['general-topology', 'open-map']"
3777387,"Show that the inequality $\left|\int_{0}^{1} f(x)\,dx\right| \leq \frac{1}{12}$ holds for certain initial conditions","Given that a function $f$ has a continuous second derivative on the interval $[0,1]$ , $f(0)=f(1)=0$ , and $|f''(x)|\leq 1$ , show that $$\left|\int_{0}^{1}f(x)\,dx\right|\leq \frac{1}{12}\,.$$ My attempt: This looks to be a maximization/minimization problem. Since the largest value $f''(x)$ can take on is $1$ , then the first case will be to assume $f''(x)=1$ . This is because it is the maximum concavity and covers the most amount of area from $[0,1]$ while still maintaining the given conditions. Edit: Because of the MVT and Rolle's Theorem, there exists extrema on the interval $[0,1]$ satisfying $f'(c)=0$ for some $c\in[0,1]$ . These extrema could occur at endpoints. Then $f'(x)=x+b$ and $f(x)=\frac{x^2}{2}+bx+c$ . Since $f(0)=0$ , then $c=0$ and $f(1)=0$ , then $b=-\frac{1}{2}$ . Remark: Any function with a continuous, constant second derivative will be of the form $ax^2+bx+c$ and in this case, $a=-b$ and $c=0$ . Now, $$\begin{align*}\int_{0}^{1}f(x)\,dx&=\frac{1}{2}\int_{0}^{1}(x^2-x)\,dx\\&=\frac{1}{2}\bigg[\frac{x^3}{3}-\frac{x^2}{2}\bigg]_{x=0}^{x=1}\\&=-\frac{1}{12}\end{align*}$$ Next, we assume that $f''(x)=-1$ and repeating the process yields $$ \begin{align*}\int_{0}^{1}f(x)\,dx&=\frac{1}{2}\int_{0}^{1}(-x^2+x)\,dx\\&=\frac{1}{2}\bigg[\frac{-x^3}{3}+\frac{x^2}{2}\bigg]_{x=0}^{x=1}\\&=\frac{1}{12}\end{align*}$$ Thus we have shown that at the upper and lower bounds for $f''(x)$ that $\frac{-1}{12}\leq\int_{0}^{1}f(x)\,dx\leq \frac{1}{12} 
 \Longleftrightarrow \left|\int_{0}^{1}f(x)\,dx\right|\leq\frac{1}{12}$ because $f''(x)$ is continuous on $[0,1]$ . I was wondering if this was 'rigorous' enough to be considered a full proof and solution to the problem.","['definite-integrals', 'proof-writing', 'real-analysis', 'solution-verification', 'integral-inequality']"
3777401,Does real dimension equal rational dimension?,"Say $v_1,v_2,\dots,v_k\in\mathbb{Q}^n$ . Let $V$ be the subspace spanned by these vectors and let $W\subseteq\mathbb{R}^n$ be the vector subspace in $\mathbb{R}^n$ spanned by these vectors. Is it true that $\dim_\mathbb{Q} V=\dim_\mathbb{R} W$ ? The equality seems very obvious and it's in fact easy to prove it using induction on $n$ : If $n=1$ , then the equality holds as either both $V$ and $W$ are $0$ or $V=\mathbb{Q}$ and $W=\mathbb{R}$ . For $n>1$ , if $\dim V<n$ , then the theorem holds via induction. Hence I assume that $\dim V=n$ so $V=\mathbb{Q}^n$ . But in this case $W$ also must be equal to $\mathbb{R}^n$ and hence the dimensions are equal. Is there a more natural/intuitive way to see why this equality holds?","['linear-algebra', 'vector-spaces']"
3777437,How can wheel factorization be used to speed up sieving?,"I've seen optimizations to the Sieve of Eratosthenes that (claim to) use ""wheel factorization"". If the goal is to generate a list of prime numbers up to a certain value, I'm wondering how exactly is wheel factorization used? The Wikipedia article contains some information but it doesn't make sense to me. For example sieve up to $15$ : $\{1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\}$ Starting with 2 strike off multiples $\{1,2,3,\_,5,\_,7,\_,9,\_,11,\_,13,\_,15\}$ Then strike off multiples of 3: $\{1,2,3,\_,5,\_,7,\_,\_,\_,11,\_,13,\_,\_\}$ For wheel factorization with base primes $2$ and $3$ the idea is composites occur periodically with 3 in a row, then one. So how are these two ideas ""merged"" when creating a list of prime numbers? Is it just wheel factorization is used to create an initial list of candidates before sieving? But that doesn't seem to save any time because SoE has the pitfall where it strikes off all ready stricken off composites (for example 15 is stricken off on 3 and 15 so what good would wheel factorization of circumference 6 do)? Is anyone able to provide an example of wheel factorization used with a sieve? TL;DR how is wheel factorization used with sieving?","['sieve-theory', 'elementary-number-theory', 'discrete-mathematics', 'algorithms']"
3777438,Proving $\int_0^\infty\left(\frac{x^xe^{-x}}{\Gamma(x+1)}-\frac1{\sqrt{2\pi x}}\right)dx=-\frac13$,"In this post the OP proposed the following ""Knuth integral"" without a rigorous proof $$\int_0^\infty\left(\frac{x^xe^{-x}}{\Gamma(x+1)}-\frac1{\sqrt{2\pi x}}\right)dx=-\frac13$$ I know a proof of corresponding Knuth series by Borwein, which used additional nontrivial techniques other than Lagrange inversion and Lambert W identities, mentioned in the post. However method for that proof is not suitable for this problem. How can we prove it? Any help will be appreciated.","['integration', 'gamma-function', 'definite-integrals', 'sequences-and-series']"
3777443,$\mathbb{R}$ is not isomorphic to a proper subfield of itself,"let $\mathbb{R}$ be the field of real numbers. I found stated in this pretty work On Groups that Are Isomorphic to a Proper Subgroup , that there is no proper subfield $K$ of $\mathbb{R}$ which is isomorphic to $\mathbb{R}$ itself.
Does someone have a proof of this fact? Thank you very much for your help in advance. NOTE1. Contrast this situation with the case of the field $\mathbb{C}$ of complex numbers, for which there exist proper subfields isomorphic to $\mathbb{C}$ itself: see e.g. Automorphisms of the Complex Numbers , Concluding Remark 2. NOTE2. This issue arouse in my post Proper Subgroup of O_2(R) Isomorphic to O_2(R) about whether the orthogonal group $O_2(\mathbb{R})$ is co-Hopfian or not.","['field-theory', 'abstract-algebra']"
3777457,Coproducts exist in the category of groups (need help understanding proof),"First let me put down the proof (by Serge Lang) I think this proof is beautiful but there are several points I can't get over. Here are my questions: What does "" $S_i$ be denumerable if $G_i$ is finite"" mean? Is it even possible to pick $S_i = \mathbb{N}$ in this case, since $\mathbb{N}$ is denumerable? Or should I consider $S_i$ to be a random countable set containing all elements of $G_i$ ? Why would we assume that $\operatorname{card}(G)=\operatorname{card}(S)$ ? I don't understand his motivation by embedding $G$ as a factor in a product $G \times S_\gamma$ . Why $f_i \circ g_*=g_i$ ? If I'm right, the universal element, which determines the coproduct, is $\{f_i:G_i \to G\}$ . There should be a unique morphism $g_*$ in the category of groups such that $g_* \circ f_i = g_i$ , by definition of coproduct. I'm assuming that writing $f_i \circ g_*$ is a typo. What he was doing in the last two paragraphs is proving the existence and uniqueness of the desired morphism $g_*$ . In case you are not familiar with Lang's terminology, I'm writing down some terminologies that you may find different on other books. Let $\mathcal{C}$ be a category. An object $P$ of $\mathcal{C}$ is called universally attracting if there exists a unique morphism of each object of $\mathcal{C}$ into $P$ , and is called universally repelling if for every object of $\mathcal{C}$ there exists a unique morphism of $P$ into this object. (When context clear, we shall call $P$ as above universal . In this proof, being universal means being universal repelling) Let $\{A_i\}$ be a family of objects in a category $\mathcal{C}$ . By their coproduct one means a pair $(S,\{f_i\}_{i\in{I}})$ consisting of an object $S$ and a family of morphisms $$
\{f_i:A_i \to S\}
$$ Satisfying the following property. Given a family of morphisms $\{g_i: A_i \to C\}$ , there exists a unique morphism $h: S \to C$ such that $h \circ f_i = g_i$ for all $i$ . Anyway, feel free to answer the question or point out what is wrong with me. Appreciated.","['proof-explanation', 'group-theory', 'category-theory']"
3777484,Is Theory of ODEs by Coddington and Levinson still a good source for learning ODEs?,The book seems to cover interesting topics and I read an old review which said the book would be helpful in showing students the concrete side of analysis before delving into the more theoretical side of things. Is this book still relevant today?,"['ordinary-differential-equations', 'reference-request']"
3777493,Geometric proof of chain rule with the derivative of $\sin(2x)$,"I'm following this post https://math.stackexchange.com/a/2169/612996 as my example and I've figured out how it works for $\sin(\theta)$ , During my first try: I keep on missing the factor of $2$ when it's $\sin(2\theta)$ . I always get $\cos(2\theta)$ In my work, I've made the angle $2\theta$ and then changed everything that has $\theta$ to $2\theta$ , but I've kept the increase in the angle $\Delta\theta$ . I think I could reverse-engineer the answer so I use $\Delta 2 \theta$ and get the right answer, but I don't know why that should work and not $\Delta\theta$ since isn't it just a small increase in the angle anyway? (Or is it a small increase that is relative to the angle, and that's why there's a 2?) During my second try: I understand the algebraic way of doing the chain rule but I want to do it with some sort of geometric intuition.","['circles', 'calculus', 'trigonometry', 'derivatives', 'chain-rule']"
3777537,Proof of $\bigcup_{i\in I}A_i=\bigcup_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ and similar statements.,"Not a duplicate of Discover and prove a theorem relating $\bigcap_{i \in J}A_i$ and $\bigcup_{X \in \mathcal{F}}(\bigcap_{i \in X}A_i)$. This is exercise $3.7.5$ from the book How to Prove it by Velleman $($$2^{nd}$ edition $)$ : Suppose $\mathcal F$ is a nonempty family of sets. Let $I=\bigcup\mathcal F$ and $J=\bigcap\mathcal F$ . Suppose also that $J\neq\emptyset$ , and notice that it follows that for every $X\in\mathcal F$ , $X\neq\emptyset$ , and also that $I\neq\emptyset$ . Finally, suppose that $\{A_i|i\in I\}$ is an indexed family of sets. $(a)$ Prove that $\bigcup_{i\in I}A_i=\bigcup_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . $(b)$ Prove that $\bigcap_{i\in I}A_i=\bigcap_{X\in\mathcal F}(\bigcap_{i\in X}A_i)$ . $(c)$ Prove that $\bigcup_{i\in J}A_i\subseteq\bigcap_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . Is it always true that $\bigcup_{i\in J}A_i=\bigcap_{X\in\mathcal F}(\bigcup_{i\in X}A_i)?$ Give either a proof or a counterexample to justify your answer. $(d)$ Discover and prove a theorem relating $\bigcap_{i\in J}A_i$ and $\bigcup_{X\in\mathcal F}(\bigcap_{i\in X}A_i)$ . Here are my proofs: Part $a$ : $(\rightarrow)$ Let $x$ be an arbitrary element of $\bigcup_{i\in I}A_i$ . So we can choose some $i_0$ such that $i_0\in I$ and $x\in A_{i_0}$ . Since $I=\bigcup\mathcal F$ , $i_0\in\bigcup\mathcal F$ . So we can choose some $X_0$ such that $X_0\in\mathcal F$ and $i_0\in X_0$ . From $i_0\in X_0$ and $x\in A_{i_0}$ , $x\in\bigcup_{i\in X}A_i$ . From $X_0\in\mathcal F$ and $x\in\bigcup_{i\in X}A_i$ , $x\in\bigcup_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . Since $x$ is arbitrary, $\bigcup_{i\in I}A_i\subseteq\bigcup_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . $(\leftarrow)$ Let $x$ be an arbitrary element of $\bigcup_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . So we can choose some $X_0$ such that $X_0\in\mathcal F$ and $x\in\bigcup_{i\in X_0}A_i$ . So we can choose some $i_0$ such that $i_0\in X_0$ and $x\in A_{i_0}$ . From $X_0\in\mathcal F$ and $i_0\in X_0$ , $i_0\in\bigcup\mathcal F$ . Since $I=\bigcup\mathcal F$ , $i_0\in I$ . From $i_0\in I$ and $x\in A_{i_0}$ , $x\in\bigcup_{i\in I}A_i$ . Since $x$ is arbitrary, $\bigcup_{X\in\mathcal F}(\bigcup_{i\in X}A_i)\subseteq\bigcup_{i\in I}A_i$ . Ergo $\bigcup_{i\in I}A_i=\bigcup_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . $Q.E.D.$ Part $b$ : $(\rightarrow)$ Let $x$ be an arbitrary element of $\bigcap_{i\in I}A_i$ . Let $X$ be an arbitrary element of $\mathcal F$ . Let $i$ be an arbitrary element of $X$ . Since $X\in\mathcal F$ and $i\in X$ , $i\in\bigcup\mathcal F$ . Since $I=\bigcup\mathcal F$ , $i\in I$ . From $x\in\bigcap_{i\in I}A_i$ and $i\in I$ , $x\in A_i$ . Since $i$ is arbitrary, $x\in\bigcap_{i\in X}A_i$ . Since $X$ is arbitrary, $x\in\bigcap_{X\in\mathcal F}(\bigcap_{i\in X}A_i)$ . Since $x$ is arbitrary, $\bigcap_{i\in I}A_i\subseteq\bigcap_{X\in\mathcal F}(\bigcap_{i\in X}A_i)$ . $(\leftarrow)$ Let $x$ be an arbitrary element of $\bigcap_{X\in\mathcal F}(\bigcap_{i\in X}A_i)$ . Let $i$ be an arbitrary element of $I$ . Since $I=\bigcup\mathcal F$ , $i\in\bigcup\mathcal F$ . So we can choose some $X_0$ such that $X_0\in\mathcal F$ and $i\in X_0$ . From $x\in\bigcap_{X\in\mathcal F}(\bigcap_{i\in X}A_i)$ and $X_0\in\mathcal F$ , $x\in\bigcap_{i\in X_0}A_i$ . From $x\in\bigcap_{i\in X_0}A_i$ and $i\in X_0$ , $x\in A_i$ . Since $i$ is arbitrary, $x\in\bigcap_{i\in I}A_i$ . Since $x$ is arbitrary, $\bigcap_{X\in\mathcal F}(\bigcap_{i\in X}A_i)\subseteq\bigcap_{i\in I}A_i$ . Ergo $\bigcap_{i\in I}A_i=\bigcap_{X\in\mathcal F}(\bigcap_{i\in X}A_i)$ . $Q.E.D.$ Part $c$ - proof: Let $x$ be an arbitrary element of $\bigcup_{i\in J}A_i$ . So we can choose some $j_0$ such that $j_0\in J$ and $x\in A_{j_0}$ . Let $X$ be an arbitrary element of $\mathcal F$ . Since $J=\bigcap \mathcal F$ , $j_0\in\bigcap\mathcal F$ . From $j_0\in\bigcap\mathcal F$ and $X\in\mathcal F$ , $j_0\in X$ . From $j_0\in X$ and $x\in A_{j_0}$ , $x\in\bigcup_{i\in X}A_i$ . Since $X$ is arbitrary, $x\in\bigcap_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . Since $x$ is arbitrary, $\bigcup_{i\in J}A_i\subseteq\bigcap_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . $Q.E.D.$ Part $c$ - counterexample: Suppose $\mathcal F=\Bigr\{\{1,2\},\{2,3\},\{1,2,3\}\Bigr\}$ . Suppose $A_1=\{1\}$ , $A_2=\{2\}$ , and $A_3=\{1\}$ . Then $1\in\bigcap_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ but $1\notin \bigcup_{i\in J}A_i$ and so $\bigcap_{X\in\mathcal F}(\bigcup_{i\in X}A_i)\nsubseteq\bigcup_{i\in J}A_i$ . Ergo $\bigcup_{i\in J}A_i\neq\bigcap_{X\in\mathcal F}(\bigcup_{i\in X}A_i)$ . Part $d$ : Let $x$ be an arbitrary element of $\bigcup_{X\in\mathcal F}(\bigcap_{i\in X}A_i)$ . So we can choose some $X_0$ such that $X_0\in\mathcal F$ and $x\in\bigcap_{i\in X_0}A_i$ . Let $i$ be an arbitrary element of $J$ . Since $J=\bigcap\mathcal F$ , $i\in\bigcap\mathcal F$ . From $i\in\bigcap\mathcal F$ and $X_0\in\mathcal F$ , $i\in X_0$ . From $x\in\bigcap_{i\in X_0}A_i$ and $i\in X_0$ , $x\in A_i$ . Since $i$ is arbitrary, $x\in\bigcap_{i\in J}A_i$ . Since $x$ is arbitrary, $\bigcup_{X\in\mathcal F}(\bigcap_{i\in X}A_i)\subseteq \bigcap_{i\in J}A_i$ . $Q.E.D.$ Alternative ways to prove parts $a$ and $b$ : Part $a$ : Let $x$ be an arbitrary element of $\bigcup_{i\in I}A_i$ . $%
\require{begingroup}
\begingroup
\newcommand{\calc}{\begin{align} \quad &}
\newcommand{\op}[1]{\\ #1 \quad & \quad \unicode{x201c}}
\newcommand{\hints}[1]{\mbox{#1} \\ \quad & \quad \phantom{\unicode{x201c}} }
\newcommand{\hint}[1]{\mbox{#1} \unicode{x201d} \\ \quad & }
\newcommand{\endcalc}{\end{align}}
\newcommand{\Ref}[1]{\text{(#1)}}
\newcommand{\then}{\rightarrow}
\newcommand{\when}{\leftarrow}
\newcommand{\fa}[2]{\forall #1 \left( #2 \right) }
\newcommand{\ex}[2]{\exists #1 \left( #2 \right) }
\newcommand{\exun}[2]{\exists ! #1 \left( #2 \right) }
\newcommand{\F}{\mathcal F}
\newcommand{\equiv}{\leftrightarrow}
%$ \begin{align}
x\in\bigcup_{i\in I}A_i & \equiv \exists i(i\in I\land x\in A_i) \\
 & \equiv \exists i\Bigr(i\in \bigcup\mathcal F\land x\in A_i\Bigr) \\ 
 & \equiv \exists i\Bigr(\exists X(X\in\mathcal F\land i\in X)\land x\in A_i\Bigr)\\
 & \color{red}{\equiv} \exists X\exists i\Bigr(X\in\mathcal F\land(i\in X\land x\in A_i)\Bigr)\\ 
 & \color{red}{\equiv} \exists X\Bigr(X\in\mathcal F\land\exists i(i\in X\land x\in A_i)\Bigr)\\
 & \equiv \exists X\Bigr(X\in\mathcal F\land x\in\bigcup_{i\in X}A_i\Bigr)\\
 & \equiv x\in\bigcup_{X\in\mathcal F}\Bigr(\bigcup_{i\in X}A_i\Bigr)
\end{align} Since $x$ is arbitrary, $\bigcup_{i\in I}A_i=\bigcup_{X\in\mathcal F}(\bigcup_{i\in X}A_i).$ $Q.E.D.$ Part $b$ : Let $x$ be an arbitrary element of $\bigcap_{i\in I}A_i$ . \begin{align}
x\in\bigcap_{i\in I}A_i & \equiv \forall i(i\in I\rightarrow x\in A_i)\\
 & \equiv \forall i\Bigr(i\in \bigcup\mathcal F\rightarrow x\in A_i\Bigr)\\ 
 & \equiv \forall i\Bigr(\exists X(X\in\mathcal F\land i\in X)\rightarrow x\in A_i\Bigr)\\
 & \equiv \forall i\Bigr(\lnot\exists X(X\in\mathcal F\land i\in X)\lor x\in A_i\Bigr)\\ 
 & \equiv \forall i\Bigr(\forall X(X\notin\mathcal F\lor i\notin X)\lor x\in A_i\Bigr)\\
 & \color{red}{\equiv} \forall X\forall i\Bigr(X\notin\mathcal F\lor(i\notin X\lor x\in A_i)\Bigr)\\
 & \color{red}{\equiv} \forall X\Bigr(X\notin\mathcal F\lor\forall i(i\notin X\lor x\in A_i)\Bigr)\\
 & \equiv \forall X\Bigr(X\notin\mathcal F\lor\forall i(i\in X\rightarrow x\in A_i)\Bigr)\\
 & \equiv \forall X\Bigr(X\notin\mathcal F\lor x\in\bigcap_{i\in X}A_i\Bigr)\\
 & \equiv \forall X\Bigr(X\in\mathcal F\rightarrow x\in\bigcap_{i\in X}A_i\Bigr)\\
 & \equiv x\in\bigcap_{X\in\mathcal F}\Bigr(\bigcap_{i\in X}A_i\Bigr)\\
\end{align} Since $x$ is arbitrary, $\bigcap_{i\in I}A_i=\bigcap_{X\in\mathcal F}(\bigcap_{i\in X}A_i).$ $Q.E.D.$ I tried to be less superfluous and verbose this time. Are my proofs and counterexample valid $?$ What about the $\color{red}{\text{red iff arrows}}$ in the alternate proofs $?$ Are they valid $?$ Could you please provide alternate proofs for parts $c$ and $d$ as well $?$ Thanks for your attention.","['proof-writing', 'examples-counterexamples', 'alternative-proof', 'solution-verification', 'elementary-set-theory']"
3777551,Understanding a short exact sequence of sheaves associated to a divisor,"Let $M$ be a complex manifold and $D = \sum_i a_i V_i$ is an effective divisor where $V_i$ 's are irreducible analytic hypersurfaces. Let $s_0 \in H^0(M,\mathcal{O}([D]))$ be a holomorphic section of the bundle $\mathcal{O}([D])$ in which $[D]$ is defined to be the image of $D$ under the short exact sequence of cohomology $$H^0(M,\mathrm{Div}) \to \mathrm{Pic}(M) = H^1(M,\mathcal{O}^{\times})$$ associated to the short exact sequence of sheaves $$0 \to \mathcal{O}^{\times} \to \mathcal{M}^{\times} \to \mathrm{Div} \to 0$$ where $\mathcal{O}^{\times},\mathcal{M}^{\times}$ are sheaves of holomorphic and meromorphic functions nonzero everywhere, respectively. If $E$ is any holomorphic vector bundle, write $\mathcal{E}(D)$ for the sheaf of meromorphic functions on $E$ with poles of order $\leq a_i$ along $V_i$ . Then, tensoring by $s_0^{-1}$ gives us an identification $$\mathcal{E}(-D) \overset{\otimes s_0^{-1}}{\rightarrow} \mathcal{O}(E \otimes [-D])$$ In Griffiths & Harris, Principles of Algeraic Geometry, page $139$ the authors assert that In particular if $D$ is a smooth analytic hypersurface, the sequence of sheaves $$0 \to \mathcal{O}_M(E \otimes [-D]) \overset{\otimes s_0}{\rightarrow} \mathcal{O}_M(E) \to \mathcal{O}_D(E_{\mid D}) \to 0$$ is exact. My question is why we need the condition of $D$ to be smooth here? In that case, could someone clarify the above sequence in more details. Any concrete example would be approciate.","['complex-geometry', 'algebraic-geometry', 'sheaf-cohomology']"
3777607,sum with partial multinomial coefficients,"I have been motivated by answer on this question: Special sum of multinomial coefficients! $$ S=\sum_{\substack{a_1+a_2+\dots+a_k=2n\\ a_i\text{ even}}}\frac{(2n)!}{a_1!a_2!\dots a_k!}=\frac{1}{2^k}\sum_{j=0}^{k}\binom{k}{j}(k-2j)^{2n}. 
$$ I am wondering if it is possible to find an explicit formula for $$
S=\sum_{\substack{a_1+a_2+\dots+a_k=2n\\ \text{only $m\leq k$-components of } a_i\text{odd}}}\frac{(2n)!}{a_1!a_2!\dots a_k!}
$$","['summation', 'combinations', 'combinatorial-proofs', 'combinatorics', 'multinomial-coefficients']"
3777611,Statistical Inversion Problem $F = Ku + \mathcal{E}$ derive conditional probability density $p(f | u)$,"Consider the following Inversion Problem $f = Ku + \varepsilon$ where $f \in \mathbb{R}^{m}$ , $u \in \mathbb{R}^{n}$ , $K \in \mathbb{R}^{m,n}$ and $\varepsilon$ is an additive, Gaussian noise. In the Bayesian approach towards Inverse Problems, where you don't rely on explicit regularizers, you consider this problem as $F = Ku + \mathcal{E}$ where $F$ and $\mathcal{E}$ are random variables, $\mathcal{E} \sim \mathcal{N}(0, \Sigma_{\varepsilon})$ . Apparently one can then determine the conditional probability density of $F$ given $u$ as $$
p(f | u) \propto \operatorname{exp}(-\frac{1}{2}\|f - Ku\|^2_{{\Sigma_{\varepsilon}}^{-1}})
$$ where $\|y\|^2_{A} := y^{T}Ay$ . How is this derived?","['conditional-probability', 'statistics', 'bayesian', 'inverse-problems']"
3777636,Weaker conditions for differentiating under the integral sign,"Standard theorems of real analysis give conditions under which it holds $$\int_0^1 \partial_x f(x,y)dy = \frac{d}{dx}\int_0^1 f(x,y)\,.$$ In most of the formulations that I have found, it is required that, for almost every $y$ , $f$ is everywhere differentiable. I'm wondering if this condition can be weakened, at least in some particular setting. Consider an integral operator $F$ on $L^2(0,1)$ which maps an element $\phi$ to $$ F\phi(x) = \int_0^1 k(x,y)\phi(y)dy\,.$$ $k(x,y)$ is supposed to be some bounded continuous function on $(0,1)^2$ .
If $k$ is of class $C^1$ , then all functions in the image of $F$ are of class $C^1$ . But can we give some weaker condition in order to have an image at least differentiable? For example if $k(x,y)=|x-y|$ , then it can be proven explicitly (just by writing down the definition of derivative and by bounding the remainder) that it holds $$\frac{d}{dx}F\phi(x) = \int_0^1sign(x-y)\phi(y)dy\,.$$ which is $C^0$ and so $F\phi(x)$ is even $C^1$ . Is this a particular case of some general and well known result?","['integration', 'derivatives', 'functional-analysis', 'real-analysis']"
3777705,"If $f:X\to X$, $f(f(x))=x$, is $f$ onto?",I have been trying following question and was unable to solve. Let $f: X \to X$ such that $f(f(x)) = x$ for all $x\in X. \space$ Then: Is $f$ 1-1? Is $f$ onto? Clearly $f$ is 1-1 . But I am unable to deduce why $f$ must be onto or not.,['functions']
3777746,Prove that $ f(1)\leq f(x)<f(0)$ and another conjecture .,"It's a problem found with the help of WA . Let $0<x$ a real number and $n\geq 1$ a natural number then we have : $$ f(1)\leq f(x)=(1+x)^{\frac{-1}{(nx)}}+\Big(1+\frac{1}{x}\Big)^{-\frac{x}{n}}<f(0)$$ I have also conjectured that : Let $1\leq x$ a real number and $n\geq 1$ a natural number then we have : $$f\Big(\frac{x+\frac{1}{x}}{2}\Big)\leq f(x)$$ This conjecture I think is useful because of this fact : Let $g(x)=\frac{x+\frac{1}{x}}{2}$ and $x\geq 1$ a real number then we have : $$f(1) \leq f(g_n(x))\leq f(g_{n-1}(x))\leq \cdots \leq f(g(x))\leq f(x)\leq f(g^{-1}(x))\leq \cdots\leq f(g^{-1}_n(x))<f(0)$$ Where we speak about the inverse of the function $g(x)$ and the iteration ( $n$ to $n$ times) of the function $g(x)$ with itself . So the idea is to prove more generaly that $x=1$ is a minimum and $x=0$ is an infimum . Well I have tried the same method as here by user Robin Aldabanx (first answer with bounty) for the first case or $n=1$ . I have tried power series as well without success this time . I have been also inspired by the Polya's proof of Am-Gm but no good issues . Update Case $n=1$ One can prove that the function : $$h(x)=(1+x)^{\frac{-1}{x}}$$ is concave on $(0,\infty)$ . So we can apply Karamata's inequality and a majorization to get something of the kind : $$h(x)+h\Big(\frac{1}{x}\Big)\geq h(y)+h\Big(\frac{1}{y}\Big)\quad (1)$$ The inequality $(1)$ gives information on $f(x)$ in the case where $n=1$ .Via the majorization we can say as it's increasing or decreasing . Moreover I think we can apply this  method to the general case $n\geq 1$ . I don't know if it's really relevant but the inverse function of $h(x)$ is : $$h^{-1}(x)=\frac{\operatorname{W}(x\log(x))-\log(x)}{\log(x)}$$ With the Lambert's function . If you have a nice way to solve it . Thanks you very much .","['exponentiation', 'inequality', 'derivatives']"
3777747,A question whether a transformation is 1-1 and onto or not if its vector space satisfies some condition,"I'm  trying assignment questions and I was unable to solve this particular problem. Let V be the space of twice differentiable functtions on $\mathbb{R} $ satisfying $f''-2f'+f =0$ . Define $T:V\to\mathbb{R^2}$ by $T(f) =(f'(0), f(0))$ . Then $T$ is: One -One or not. Onto or not. Using condition of $1-1$ I got $f(0)=g(0)$ and $f'(0)=g'(0)$ but one can say that $f=g$ from this information. So, I don't think $f$ is $1-1$ . I think $f$ is onto as for all $(x,y)$ belonging to $\mathbb R^{2} $ as $f$ can be chosen so that $f'(0) =x, f(0)=y$ . But I did not used condition $f''-2f'+f =0$ in my answers So, are my answers correct?","['functions', 'linear-algebra', 'solution-verification']"
3777750,Analysis of frequency and amplitude at Hopf bifurcation,"I am analyzing the following system, where $I_{in}$ is a scalar parameter: $$
\begin{aligned}
&\dot{V} = 10 \left( V - \frac{V^3}{3} - R + I_{in} \right) \\
&\dot{R} = 0.8 \left( -R +1.25V + 1.5 \right)
\end{aligned}
$$ It is a simplified version of the Fitzhugh-Nagumo equations for neuronal excitability (reference to book below). There is a single equilibrium, that varies with $I_{in}$ , so we need to calculate the Jacobian at those equilibrium values and perform a stability analysis. Such an analysis reveals that as $I_{in}$ increases from zero to around 1.5, the system undergoes a supercritical Hopf bifurcation [ edit : it undergoes what I intuitively thought was a supercritical bifurcation]: We go from a stable center to an unstable center at a critical value (zero real eigenvalue) at $I_{crit}=0.966064$ . Note that I calculated the limit cycle boundaries in that diagram by just getting the minimum and maximum values of V for each loop through the limit cycle (examples of such loops are shown below in Figures 3 and 4). ( Edit : I added my derivation of $I_{crit}$ below). You can see the nature of the transition in the trace-determinant diagram in the following Figure 2: As $I_{in}$ increases, the equilibrium point turns from a sink to a (stable) spiral, and then we hit the critical point at $I_{crit}$ , after which we have a spiral source surrounded by a (stable) limit cycle, and eventually a stable source also surrounded by a limit cycle. So far, so good, I think. This all seems pretty straightforward. So what is the problem? At this point I am confused about a couple of things. In my book it says the following two facts (corollaries of the Hopf Bifurcation theorem) should be true near $I_{crit}$ : The amplitude of oscillations will be very small. The frequency of oscillation should be close to $\omega/2\pi$ Hz, where $\omega$ is the imaginary part of the eigenvalue. It seems that neither of these facts is true here. First, the oscillation amplitude starts out very large, as you can see in the bifurcation diagram in Figure 1. There is none of that textbook ramping up of the amplitude. Indeed, even when $I_{in}$ is less than $I_{crit}$ , there already a large, stable, limit-cycle-like orbit in this phase space! The following figure shows some full orbits in the phase space (left), and a couple of V trajectories on the right. This is for $I_{in}=I_{crit}-0.00874$ : That is, we have lots of large-amplitude stable orbits cycling around some stable centers (such damped oscillations occur only for orbits that are close to the equilibrium point). So not only does the limit cycle start out with a large amplitude past $I_{crit}$ , it seems there is already a kind of harbinger of a limit cycle with a large amplitude even before the bifurcation. That said, the above two facts do seem to apply to the damped spirals in Figure 2: the amplitude of the spiral is very small (tending toward zero), and its frequency is basically exactly $\omega/2\pi$ -- it is basically double the frequency of the large-amplitude pseudo-limit cycle that encloses it. Could that be what my text is referring to? This brings me explicitly to the second fact above: at $I_{crit}$ the eigenvalues are $\pm 3.05i$ . Hence, the frequency of oscillation should be about 0.5 Hz, a period of 2 s. But instead I see a period of 4 seconds (0.25 Hz), as the following diagram of V versus time for $I=I_{crit}+0.000001$ shows: I calculate the period based on the distance between the red X's. I'll mention again, though, if we were to do the same analysis of the oscillations of the damped spirals (as in Figure 3) the frequencies of those damped oscillations would basically be right -- it is the full limit cycles that seem off (though their order of magnitude is right). Overall, this system is supposed to be approachable because of its simplicity but I've already spent about a week hitting my head against it, still not sure of some of the most basic facts about Hopf Bifurcations. Derivation of the critical value Note the Jacobian of the system is: $$
J = 
\begin{bmatrix}
\frac{\partial F_1}{\partial V} & \frac{\partial F_1}{\partial R}\\
\frac{\partial F_2}{\partial V} & \frac{\partial F_2}{\partial R}
\end{bmatrix} = 
\begin{bmatrix}
10(1-V^2) & -10 \\
1 & -0.8
\end{bmatrix}
$$ Our task is essentially to determine the system's (V,R) equilibria for different values of $I_{in}$ . Then, we can plug these equilibrium values into the Jacobian for our stability analysis, and find the coefficient matrix where the real part of the eigenvalues go to zero. How do we find this? First, I found the equilibrium value of V that would yield purely imaginary eigenvalues, and I did this using the trace. That is, the sum of the eigenvalues is the same as the sum of the values in the coefficient matrix (the trace). From the equation for the Jacobian above, we know the trace is zero when: $$
9.2 - 10V^2 = 0 \implies V = \pm \sqrt{0.92} = \pm 0.959
$$ Focusing on the negative root for now, this implies that our critical value of $I_{in}$ will be the one that generates $V_{eqm}=-0.959$ . How do we find this value of $I_{in}$ ? I did it by substitution, using the nullcline equations of our system. Namely, the equations for the nullclines of our system are given by: $$
\begin{aligned}
&R = V - \frac{V^3}{3} + I_{input}\\
&R = 1.25V + 1.5
\end{aligned}
$$ So, if given a value $V_{eqm}$ we can plug the second nullcline equation $R(V)$ into the first, and solve for $I_{in}$ in terms of $V$ . Namely, given a value of $V_{eqm}$ , the $I_{in}$ that produces that will be: $$
I_{in}=\frac{V^3}{3} + 0.25V + 1.5
$$ So, looping back to our question, if we plug in $V_{eqm}=-0.959$ into this equation, that yields $I_{crit}=0.966$ . Note also that plugging this $I_{crit}$ into the original system of equations and numerically solving for the equilibrium using Python's fsolve() yields the equilibrium point (V, R) = (-0.959, 0.301) , which gives secondary confirmation of our result. The Jacobian at this equilibrium point is: $$
J = 
\begin{bmatrix}
0.8 & -10 \\
1 & -0.8
\end{bmatrix}
$$ This coefficient matrix has purely imaginary eigenvalues $\pm3.06i$ , as expected. So it seems we have a critical value where the real part of the eigenvalues reaches zero, as originally claimed. QED, maybe? To address a question from a comment: when $I=0.866$ the equilibrum point is $(V, R) = (-1.04, 0.20)$ , and the eigenvalues of the Jacobian are $-0.8\pm3.16i$ . This, coupled with the secondary confirmation of the calculations from the trace-discriminant curve (Figure 2 above), make me think there isn't a mistake in the calculation of $I_{crit}$ above. That said, I have definitely made worse mistakes in my lifetime, and thought I was right, so we definitely shouldn't exclude this possibility. Different question about same equations Hopf bifurcation and limit cycles Reference Wilson (1999) Spikes, decisions, and actions: dynamical foundations of neuroscience . OUP.","['ordinary-differential-equations', 'eigenvalues-eigenvectors', 'bifurcation', 'nonlinear-system', 'dynamical-systems']"
3777755,The orbit of a non zero vector $v$ in $\mathbb{R}^n$ is $\mathbb{R}^n \setminus \{0\}$,"Prove that given any non zero vectors $v$ and $w$ in $\mathbb{R}^n$ , there exists an invertible $n\times n$ matrix $A$ such that $Av=w$ . (I don't know where to start. Any hints will be appreciated)","['matrices', 'group-theory', 'linear-algebra']"
3777798,"Prove $\forall t\in [0,1):\, t\le \frac{1-t^t}{1-t}$","How do I prove $$\forall t\in [0,1):\,t\le \frac{1-t^t}{1-t}?$$ Do not use derivatives or integrals and assume that irrational exponentiation is defined by limits and define $0^0=1$ . My attempt: Let $t=\frac{1}{a}$ , thus $a\gt 1$ . The case for $t=0$ is trivial. So $$\begin{align}\frac{1}{a}&\le \frac{1-\left(\frac{1}{a}\right)^{\frac{1}{a}}}{1-\frac{1}{a}}\\&=\frac{\left(1-a^{-\frac{1}{a}}\right)a}{a-1}\\&=\frac{a-a^{1-\frac{1}{a}}}{a-1}\\a&\ge \frac{a-1}{a-a^{1-\frac{1}{a}}}\\a^2-a^{2-\frac{1}{a}}-a+1&\ge 0.\end{align}$$ Now $a^{2-\frac{1}{a}}\le a^2$ but I don't know how to use this fact to compare $a^{2-\frac{1}{a}}+a$ to $a^2$ .","['inequality', 'real-analysis']"
3777803,How to simplify a given expression?,"Suppose $$ y  = 10 \log \left|1 + \frac{a}{2b} \left[ \frac{1+\phi+(\phi-1) e^{-2i \theta_{2}}}{1+\phi-(\phi-1)e^{-2i\theta_{2}}} \right] \right|^{2} $$ where $$ \phi = \frac{c}{a} \left( \frac{e^{2i \theta_{1}}-1}{e^{2i \theta_{1}}+1} \right) .$$ Here $a,b,c,\theta_{1}$ and $\theta_{2}$ are fixed constants. We need to prove that $$ y = 10 \log \left[ 1+ \left( \frac{a}{2b} \frac{\tan{\theta_{2}+\frac{c}{a} \tan{\theta_{1}}}}{1-\frac{c}{a} \tan{\theta_{2}} \tan{\theta_{1}}} \right)^{2}\right]. $$ My idea: I try to rationalize $y$ and $\phi$ separately and then divided whole expression by $cosine$ function, but not able to remove imaginary parts, please help me to simplify this.","['rationalising-denominator', 'trigonometry']"
3777828,"Evaluate $\int_0^1 \ln^2{\left(x^4+x^2+1\right)} \, \mathrm{d}x$","Evaluate $$\int_0^1 \ln^2{\left(x^4+x^2+1\right)} \, \mathrm{d}x$$ First thing I saw is $x^4+x^2+1=(x^2+x+1)(x^2-x+1)$ so the integral is the same as: \begin{gather*}
\int_0^1\ln^2{\left(x^2+x+1\right)} \, \mathrm{d}x
+ \int_0^1\ln^2{\left(x^2-x+1\right)} \, \mathrm{d}x \\
+ 2\int_0^1\ln{\left(x^2+x+1\right)}\ln{\left(x^2-x+1\right)} \, \mathrm{d}x
\end{gather*} I dont know if this helps though.  The last integral above seems to be the hardest, but still I don't even know how to evaluate first 2 integrals (perhaps Feynman's method)? Source: https://tieba.baidu.com/p/4794735082","['integration', 'definite-integrals', 'real-analysis', 'complex-analysis', 'calculus']"
3777858,Relation between $f(x)$ and $f(\sqrt{x})$,"This might be silly, but if $f(\sqrt{x})=\frac{0.1}{a}x$ , is $f(x)=\frac{0.1}{a}x^2$ ?",['functions']
3777859,Calculate the limit $\lim_{n\to\infty} \left(\prod_{k=1}^{n}(1+\frac{k}{n})\right)^{\frac{1}{n}}$,"I have to calculate this limit $$  \lim_{n\to\infty} \left(\prod_{k=1}^{n}\left(1+\frac{k}{n}\right)\right)^{\frac{1}{n}}$$ I tried it just first to calculate the limit inside the product, but I think I got the answer 1. Any help?",['limits']
3777959,"Problem with showing $\lim_{n\rightarrow \infty} \int_A \cos(nxy) \, d\lambda_2=0$","I need to show that $$\lim_{n\rightarrow \infty} \int\limits_A \cos(nxy) \, d\lambda_2=0$$ for every Borel set $A\subset \mathbb{R}^2$ which has finite Lebesgue measure. I tried to use the definition of Lebesgue measure, namely $$ \int \chi_A \;\operatorname d\mu := \mu(A),   $$ but when I am trying to use this fact it is not occurring very helpful in my opinion. Is it a good idea to use Lebesgue's dominated convergence theorem? Then the integrable function $g$ would be equal to one if I am thinking correctly. Thanks in advance.","['integration', 'lebesgue-measure', 'lebesgue-integral', 'functions', 'limits']"
3777970,Mathematical status of Jansen's linkage,"Does Jansen's linkage mechanism achieve a genuinely flat segment of the foot's cycle or merely an approximation? Dimensions of mechanism given here, though presumably the actual measurements require more precise definition.","['classical-mechanics', 'calculus', 'geometry']"
3777992,Can $\sqrt{n}$ be dropped from the asymptotic normality of an MLE?,"Referencing the site below: http://gregorygundersen.com/blog/2019/11/28/asymptotic-normality-mle/ We have the asymptotic normality property of maximum likelihood estimators: Theorem: Assuming sufficient regularity, we have: $$\sqrt{n}(\hat{\theta} - \theta_0) \xrightarrow{\mathcal{D}} \mathcal{N}(0,\mathcal{I}(\theta_0)^{-1})$$ On the next line, the site claims that this property implies: Corollary: $$\hat{\theta} \xrightarrow{\mathcal{D}} \mathcal{N}(\theta_0,\mathcal{I}(\theta_0)^{-1})$$ I have two questions: Why is the $\sqrt{n}$ factor allowed to be dropped? What is the formal reason for this? I just want to make sure, is it correct that the corollary is equivalent to $(\hat{\theta}-\theta_0) \xrightarrow{\mathcal{D}} \mathcal{N}(0,\mathcal{I}(\theta_0)^{-1})$ ?","['statistics', 'probability-limit-theorems', 'maximum-likelihood', 'probability-theory', 'probability']"
3777999,How should I notate this function?,"My apologies for the vague, non-descript title, I couldn't come up with a concise way to describe what I mean. Basically, I have a sequence $A$ such that $\forall \;x \in A: x \in \{0, 1, 2, ..., n\}$ , where $n \in \mathbb{N}$ . Let's take $n = 6$ as an example. $A$ could look like this, for example: ╔═══╦═══╦═══╦═══╦═══╦═══╦═══╦═══╦═══╦═══╗
║ 3 ║ 1 ║ 4 ║ 4 ║ 5 ║ 1 ║ 6 ║ 2 ║ 2 ║ 3 ║
╚═══╩═══╩═══╩═══╩═══╩═══╩═══╩═══╩═══╩═══╝ Now, I want to have a function that takes in a sequence $X$ and an index $i$ and returns the number of times that $X_{i}$ has appeared in $X$ up until $i$ . An example would probably help here. Let's say that our index is $4$ and we're using sequence $A$ . We look at what's in the fourth place in $A$ ; it's the number 4. Then, starting from the beginning of the sequence, we check every item in the sequence to see if it equals 4. However, once we reach the $i$ -th element, we stop. ╔═══╦═══╦═══╦═══╦═══╦═══╦═══╦═══╦═══╦═══╗
║ 3 ║ 1 ║ 4 ║ 4 ║ 5 ║ 1 ║ 6 ║ 2 ║ 2 ║ 3 ║
╚═══╩═══╩═══╩═══╩═══╩═══╩═══╩═══╩═══╩═══╝
          ^   ^    we don't even bother 
          |   |    checking all of these In this case, the function would return 2. Is there any way that I could notate this? It doesn't even have to be compact or particularly legible, I just need a way to describe what I'm talking about mathematically. Thanks.","['notation', 'functions', 'sequences-and-series']"
