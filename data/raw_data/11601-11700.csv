question_id,title,body,tags
90053,Find the expected number of rolls for a fair die until two different number show up,"A fair 6-sided die is thrown repeatedly until two different numbers appear. What is the expected number of rolls? My intuition tells that this is a geometric distribution with parameter $(\dfrac{5}{6})$ . So the expected value is $\dfrac{6}{5}$. But I am not sure. The place where I am confused is a general geometric distribution random variable is defined by its pdf $P(X=k) = (1-p)^{k-1}p, k = \{1,2,3,...\}$. However, in this question, it seems it is off by 1 since $P(X=1)=0$. Can someone explain this to me?","['probability-distributions', 'probability']"
90054,Minimizing the variance of weighted sum of two random variables with respect to the weights,"Suppose $X$ and $Y$ are two random variables. I would like to see if the solution to
$$
\min_w \quad \mathrm{Var}(wX+(1-w)Y)
$$
can be negative. I know that
\begin{align*}
&\mathrm{Var}(wX+(1-w)Y) 
\\ &= w^2 \mathrm{Var} X + 2w(1-w)\mathrm{Cov}(X,Y) + (1-w)^2 \mathrm{Var}Y
\\&= w^2 (\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y) + 2w(\mathrm{Cov}(X,Y) - \mathrm{Var}Y) + \mathrm{Var}Y
\end{align*}
Since $$\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y 
\geq \mathrm{Var} X - 2\sqrt{\mathrm{Var} X \, \mathrm{Var} Y}+ \mathrm{Var}Y \geq 0, $$
the minimizer is 
$$
w^*=-\frac{\mathrm{Cov}(X,Y) - \mathrm{Var}Y}{\mathrm{Var} X - 2\mathrm{Cov}(X,Y) + \mathrm{Var}Y}
$$ So if I am correct so far, the problem of whether $w^*$ can be negative becomes whether it can be true that
$$
\mathrm{Cov}(X,Y) - \mathrm{Var}Y > 0?
$$ Thanks!",['probability']
90064,Is this a proper use of induction? ($(n^2+5)n$ is divisible by 6),"Just want to get input on my use of induction in this problem: Question. Use mathematical induction to prove that $(n^2+5)n$ is divisible by $6$ for all integers $n \geqslant 1$. Proof by mathematical induction. (1) show base case ($n=1$) is true: 
$$
((1)^2 + 5) (1) = 6
$$
$6$ is indeed divisible by $6$, so base case ($n=1$) is true (2a) Assume case $n$ is true: $(n^2+5)n$ is divisible by $6$. (2b) Show that case $n$ $\implies$ case $(n+1)$
$$
\begin{align*}
((n+1)^2+5)(n+1) 
&\rightarrow 
((n^2+2n+1)+5)(n+1)  
\\ &\rightarrow  
[(n^2+5)+(2n+1)](n+1)
\\ &\rightarrow  
(n^2+5)n + (n^2+5)+(2n+1)n+ (2n+1)
\\ &\rightarrow  
(n^2+5)n + [(n^2+5)+(2n^2+n)+ (2n+1)]
\\ &\rightarrow  
(n^2+5)n + [(3n^2+3n)+6]
\end{align*} 
$$ Now we can see case $(n+1)$ $= (n^2+5)n + (3n^2+3n)+6$. We know $6$ is divisible by $6$ and we are assuming $(n^2+5)n$ is divisible by $6$ already, so all we need to do is show $(3n^2+3n)$ is divisible by $6$: Letting $n=1$ for $(3n^2+3n)$ gives: $(3(1)^2+3(1)) = 6$ Thus, it has been demonstrated that $(n^2+5)n$ is divisible by $6$ for all integers $n \geqslant 1$. I'm not sure if letting $n=1$ for that last expression is enough to prove it is divisible by $6$","['induction', 'discrete-mathematics', 'proof-writing']"
90069,Tautological vector bundle over $G_1(\mathbb{R^2})$ isomorphic to the Möbius bundle,"Let $V$ be a finite dimensional vector space, and let $G_k(V)$ be the
  Grassmannian of $k$-dimensional subspaces of $V$. Let $T$ be the
  disjoint union of all these $k$-dimensional subspaces and let
  $\pi:T\rightarrow G_k(V)$ be the natural map sending each point $x \in S$ to $S$. Then $T$ has a unique smooth manifold structure making
  it into a smooth rank-$k$ vector bundle over $G_k(V)$, with $\pi$ as a
  projection and with the vector space structure on each fiber inherited
  from $V$. $T$ is called the tautological vector bundle over $G_k(V).$ What I want to prove is that tautological vector bundle over $G_1(\mathbb{R^2})$ is isomorphic to the Möbius bundle. (This is a problem from Introduction to Smooth Manifolds by Lee and Möbius bundle is defined as in Lee's book, page 105. Also I took the definition of the tautological vector bundle over $G_k(V)$ from Lee's book as well.)","['grassmannian', 'vector-bundles', 'differential-geometry']"
90100,Normal subgroup of $\operatorname{SL}_2(K)$,"The setup: Let $K$ be a field which is not of characteristic 2 and which contains at least seven elements. Let $N$ be a normal subgroup of $\operatorname{SL}_2(K)$ which contains a matrix $A \neq \pm I$ . The problem: (a) Show that $N$ contains an upper triangular matrix other than $\pm I$ . (b) Show that $N$ contains a unit upper triangular matrix other than $\pm I$ . Now the problem goes on, and the end goal is to show that there are infinitely many nonabelian simple groups. I've got part (c) through (f), but I simply can't get anywhere with these two. There is a hint attached to part (a), suggesting we conjugate to get a 0, then compute a commutator with a diagonal matrix to place the 0. Conjugation isn't exactly the most elegant operation here. For any $\begin{pmatrix} a&b\\c&d \end{pmatrix}$ in $N$ , and any $\begin{pmatrix} r&s\\t&u\end{pmatrix}$ in $\operatorname{SL}_2(K)$ , we have $$ \begin{pmatrix} u&-s\\-t&r\end{pmatrix}\begin{pmatrix} a&b\\c&d\end{pmatrix}\begin{pmatrix} r&s\\t&u\end{pmatrix} = \begin{pmatrix} u(ar+bt)-s(cr+dt)&u(as+bu)-s(cs+du)\\r(cr+dt)-t(ar+bt)&r(cs+du)-t(as+bu)\end{pmatrix},$$ and none of those look particularly easy to force to be 0. (I can get the bottom left to $-b$ or $-c$ , but those haven't been helpful on their own.) I don't know what to do for the commutator yet, but to be fair, I don't know where my 0 is supposed to be, so that will hopefully resolve with the issue above. I'm hoping my problems with part (b) also stem from my lack of progress with part (a), so any hints would be greatly appreciated. Thanks!","['matrices', 'group-theory']"
90116,how to show convergence in probability imply convergence a.s. in this case?,"Assume that 
$X_1,\cdots,X_n$ are independent r.v., not necessarily iid, Let $S_n=X_1+\cdots+X_n$, suppose that $S_n$ converges in probability, how can we show that $S_n$ converges a.s.?","['probability-theory', 'probability']"
90120,Mean Value of a Multiplicative Function close to $n$ in Terms of the Zeta Function,"Let $f(n)$ be a multiplicative function defined by $f(p^a)=p^{a-1}(p+1)$, where $p$ is a prime number.  How could I obtain a formula for $$\sum_{n\leq x} f(n)$$ with error term $O(x\log{x})$ and express the main term constant in terms of values of Riemann zeta function?","['riemann-zeta', 'number-theory', 'asymptotics', 'analytic-number-theory', 'multiplicative-function']"
90127,TFAE: Completeness Axiom and Monotone Convergence Theorem,"I'm looking to write a proof that shows Completeness Axiom / L.U.B. Property of $\mathbb{R}$$\iff$ Monotone Convergence Theorem. However, it's quite perplexing to me how a proposition about real numbers can imply such an in-depth result about sequences and series. Could anyone offer me some starting points? I'm thinking by contradiction for $\Leftarrow$, but I have no idea how to do $\Rightarrow$.","['sequences-and-series', 'real-analysis', 'analysis']"
90130,Oscillatory integral giving me the willies,"So now that my term's over, I've been brushing up on my quantum field theory, and I came across the following line in my textbook without any justification: $$\frac{1}{4\pi^2}\int_m^{\infty}\sqrt{E^2-m^2}e^{-iEt}dE \sim e^{-imt}\text{ as }t\to\infty$$ Well, I can see intuitively that if most of the integral cancels out, the main contribution will be from the region $E\approx m$, since (under a coordinate transformation) that's the region of stationary phase.  But I'm a mathematician, dangit, not a physicist, and I want this to be rigourous. The Riemann-Lebesgue lemma, if I'm not mistaken, doesn't apply since $\sqrt{E^2-m^2}$ is unbounded as $E\to\infty$, and it certainly isn't $L^1$.  And I guess I could shift the path of the integral off the real axis in the complex plane, but I don't see why that would be the right way to take the integral.  The whole thing is giving me the heebie-jeebies, and I was hoping one of you folks could assuage my fears.","['distribution-theory', 'integration']"
90146,When $L^p \subset L^q$ for $p <q$.,"Assume that $(X, \mathfrak{B}, m)$ is a measure space such that there exists a constant $\alpha>0$ such that for every $E \in \mathfrak{B}$ the following holds:
$$ m(E)=0 \  \ or \ \ m(E)\geq \alpha.$$ Is it then true that for every $1\leq p \leq q \leq \infty$
$$L^p((X, \mathfrak{B}, m) \subset L^q(X, \mathfrak{B}, m)?$$ I know that it is true for spaces $l^p$ (it is a particular case of $L^p$ when $X=\mathbb{N}$, $\mathfrak{B}=2^\mathbb{N}$ and $m$ is a counting measure) -proof is for example here How do you show that $l_p \subset l_q$ for $p \leq q$? . My question is related to the last theorem in the another answer https://math.stackexchange.com/a/66038/20924 . Here is its proof, but not all is clear for me. 
 I have one doubt. It seems that here the following equalities are used:
$$\|f\|_{L^p}=\sum_{j=1}^n a_j m(E_j)^{1/p},$$
$$\|f\|_{L^q}=\sum_{j=1}^n a_j m(E_j)^{1/q}$$
 for $f(x)=\sum_{j=1}^n a_j \chi_{E_j}$, where $E_j$ are pairwise disjoint,
which are generally not not true even for $l^p$ and $l^q$.","['measure-theory', 'lp-spaces', 'real-analysis']"
90152,Different ways of coloring a $4 \times 4$ game board,"In how many ways a $4 \times 4$ game board can be colored using four colors (red, green, blue, yellow) in such a way that each small square has a single color and the board looks exactly the same from all sides? For this particular problem since the board's dimension is $4 \times 4$ we could probably check by brute-forcing but I am inquisitive about how to solve this one for a $n \times n$ board with $n$ or $\space x$ colors?","['puzzle', 'combinatorics']"
90153,Extension of Vector bundles is a Vector bundle?,"I guess this is quite easy, but I don't see a counterexample: let $X$ be a noetherian scheme (maybe with more hypotheses, but I don't think this will change much), then I have the feeling that it is not true that every extension of a vector bundle by a vector bundle is again a vector bundle, i.e. if $0 \rightarrow F \rightarrow G \rightarrow H \rightarrow 0$ is an exact sequence of modules on $X$ with $F$ and $H$ locally free of finite rank, then
is does not follow that $G$ is again locally free of finite rank?",['algebraic-geometry']
90156,Find the limit of $(e^{2x}+1)^{1/x}$,I want to find $\lim \limits_{x\to \infty}(e^{2x}+1)^{1/x}$. The first thing I thought is that $\lim  \limits_{x\to\infty}\frac{1}{x}=0$. So the limit would be $\lim  \limits_{x\to \infty}(e^{2x}+1)^{1/x}= 1$ but I am pretty sure that this is not the right answer. Then I read in wikipedia that I can apply L'Hospital on $\infty^{0}$. The only problem is that I don't know how to do it. Do I have to transform it in something like  $\infty^{\infty}$ or $0^{0}$?,"['calculus', 'limits']"
90171,"How to show that $x=e^y$, where $y=\sum \limits_{n=1}^\infty \frac{(-1)^{n-1}}{n} (x-1)^n$, not using logarithm?","Let $|x-1|<1$ and $y= \displaystyle \sum_{n=1}^\infty \frac{(-1)^{n-1}}{n} (x-1)^n$. How to show, without using the fact that $y=\ln x$, but using properties of absolutely convergent series, that $e^y=x$?","['sequences-and-series', 'real-analysis', 'analysis']"
90177,Subgroup of $\mathbb{R}$ either dense or has a least positive element?,"Let's say $G$ is some additive subgroup of $\mathbb{R}$ that has at least two elements. From what I understand, $G$ is then either dense in $\mathbb{R}$, or has some least positive element. What is the reason for this?","['general-topology', 'real-analysis']"
90181,How to deduce open mapping theorem from closed graph theorem?,These two theorems are equivalent but I can not figure out how to deduce the open mapping from the closed graph. Can anyone give a hint or some reference?,"['alternative-proof', 'functional-analysis', 'banach-spaces']"
90188,Parameter Curves are Geodesics,"So let's suppose we have a surface $M$ that is embedded in $\mathbb{R}^3$ with an orthogonal parametrization. Further, assume that the parameter curves (i.e., $X(u$ 0 $, v)$ and $X(u, v$ 0 $)$ ) are geodesics that are unparametrized (i.e., not necessarily unit speed). What can we say about the Gauss curvature of $M$?",['differential-geometry']
90206,Are free modules injective?,"Let $A$ be a commutative ring and consider the category of $A$-modules. Let $F$ be free $A$-module. Then the functor $Hom_A(F,\cdot)$ is exact. Is the functor $Hom_A(\cdot,F)$ also exact? Equivalently, is a free module injective?","['modules', 'abstract-algebra']"
90211,"Is there a $z$ for which $z$, $1+i$, $(1+i)z$ and $e^z$ are collinear?","Is there a $z$ for which $z$, $1+i$, $(1+i)z$ and $e^z$ are collinear? There is a close call around $z = .18 + 1.09i$ but I'd like to see a mathematical solution.","['complex-numbers', 'complex-analysis']"
90213,Non degenerate bilinear form,"Problem: Let $F:V \times W \to \mathbb{R}$ be a non degenerate bilinear form. The question is: prove that $V$ and $W$ have the same dimension (the vector spaces $V$ and $W$ are finite dimensional) My answer is: $F$ is non degenerate, then the matrix of $F$ is invertible, which means it's square and this implies that $V$ and $W$ have the same dimension. Is my assumption that the matrix of a non degenerate bilinear form is invertible true? Also let me know if my answer is true?","['matrices', 'linear-algebra', 'bilinear-form']"
90214,Does proving (second countable) $\Rightarrow$ (Lindelöf) require the axiom of choice?,"Background: This question came up in my homework (but was not a homework problem).  The problem was proving one direction of the Heine-Borel theorem. As with all proofs of compactness, one begins with, ""Suppose $A$ is closed and bounded, and $\mathcal{U}$ is an open cover ...""  My proof, which I believe is typical, constructed a convergent sequence of points and derived a contradiction.  The problem: to construct a sequence, one needs the cover to be countable. So I invoked that second-countability implies Lindelöf.  This is not controversial, of course, but I included a little argument along the lines of the answers in this question: Every open cover has a countable subcover (Lindelöf's lemma) . In particular, for each $x\in A$ there is some $U$ in $\mathcal{U}$ with $x\in U$; second-countability implies for each $x\in A$ there is some basis element $Q$ with $x\in Q\subset U$; the set of all such $Q$ covers $A$ and each $Q\subset U$ for at least one $U\in\mathcal{U}$, so picking one $U\supset Q$ for each $Q$ gives a countable cover of $A$. I noticed that the answers in that thread included similar phrases: ""Now for each $B\in\mathcal{B}U$ choose some $U(B)\in U$ such that $B\subseteq U$"", ""for each element $O$ of $\Sigma$ choose an element $U$ of $\Omega$ containing it"" My argument and the arguments suggested in the thread linked both seem to assume the Axiom of Choice.  I'm not sure that I understand the axiom of choice, though.  So, two questions: 1) Are we actually using the axiom of choice in these arguments? 2) Does (second countable) $\Rightarrow$ (Lindelöf) require the axiom of choice? Thanks!","['general-topology', 'set-theory', 'second-countable', 'axiom-of-choice']"
90225,Continuous non-decreasing image of a measure zero set,"I am looking at an old qualifying exam to study for my finals; it asks the following true/false question: Let $f$ be a continuous, non-decreasing function defined on $[0,1]$, and let $E$ be a set of Lebesgue measure zero. Then, $f(E)$ is a set of Lebesgue measure zero. I suspect this is false, but am not sure. Can anyone think of a solution without using the notion of absolute continuity? The reason for this is because AC won't be covered on the final.","['measure-theory', 'real-analysis']"
90229,"Proof: If $n \in \mathbb{N}$ is not the sum of two squares, then $n$ is also not the sum of two rational squares","I have to prove the following: If $n \in \mathbb{N}$ is not representable by the sum of two squares, then $n$ is also not representable by the sum of two rational squares. How do I start here? Any ideas would be fine.",['number-theory']
90232,Neumann series in an incomplete normed algebra,"Let $\mathcal{A} \equiv (A, \|\cdot\|_A)$ be a unital (associative) normed algebra over the real or complex field, and assume that $\mathcal{A}$ is not complete. Provided $\mathcal{B}_\mathcal{A}$ is the open unit ball of $\mathcal{A}$, define $N$ to be the set of all $a \in \mathcal{B}_\mathcal{A}$ such that the Neumann series $\sum_{n=0}^\infty a^n$ does not converge in $\mathcal{A}$. Questions. 1) Is $N$ dense in $\mathcal{B}_\mathcal{A}$? 2) And what about $\mathcal{B}_\mathcal{A}\setminus N$? Edit (11 Dec 2011). Following Davide's comment below, let $\mathcal{C}^0([0,1],\mathbb{R})$ be the usual Banach algebra (over the real field) of all continuous functions $[0,1] \to \mathbb{R}$ endowed with the uniform norm $\|\cdot\|_\infty$. Define $A$ to be the subalgebra of $\mathcal{C}^0([0,1],\mathbb{R})$ of all polynomial functions. For each $\phi \in A$ such that $\|\phi\|_\infty < 1$, the Neumann series $\sum_{n=0}^\infty \phi^n$ converges in $\mathcal{C}^0([0,1],\mathbb{R})$ to $(1 - \phi)^{-1}$, but it does not in $\mathcal{A} \equiv (A,\|\cdot\|_\infty)$ so far as $\phi$ is not a constant. Thus, $N$ is dense in $\mathcal{B}_\mathcal{A}$, and indeed in the unit ball of $\mathcal{C}^0([0,1],\mathbb{R})$ (by the Stone-Weierstrass theorem).","['operator-theory', 'normed-spaces', 'functional-analysis']"
90239,Prove or disprove this calculus limit result by geometric approach,"my question is: Could we prove the this conversion of variable work by my formula on the bottom? $$\iint_R f(r,\theta) \ dxdy = \int_a^b \int_0^{r(\theta)} f(r,\theta) r (dr)\ d\theta$$ as $d r$ and $d \theta$ approach $0$. Prove or disprove that: $$((r+\Delta r) \cos(a +\Delta \theta) -r \cos a) \cdot ((r+\Delta r) \sin(a + \Delta \theta) -r \sin a) / (r \;\Delta \theta \; \Delta r)=1 .$$ where the variable represent as in this graph : as $\Delta r $ and $\Delta \theta$ approach $0$ This question is inspired from $dx\;dy=r \;dr \;d \theta$.",['multivariable-calculus']
90268,How is the law of a stochastic process defined?,"Let $(Ω, F, P)$ be a probability space, $T$ some index
set, and $(S, Σ)$ a measurable space. $X : T × Ω → S$ is a
stochastic process. Let $S^T$ be the collection of all functions
from $T$ into $S$. In Wikipedia : the law of a stochastic process is the measure that the process
  induces on the collection of functions from the index set into the
  state space.   The process $X$ induces a function $Φ_X : Ω → S^T$,
  where $$
         \left( \Phi_{X} (\omega) \right) (t) := X_{t} (\omega). $$ The law of the process $X$ is then defined to be the pushforward measure
  $$
         \mathcal{L}_{X} := \left( \Phi_{X} \right)_{*} ( \mathbf{P} ) = \mathbf P \circ \Phi_X^{-1} $$ on $S^T$. I was wondering if the $\sigma$-algebra on $S^T$ is defined as $\{ A
    \subseteq S^T: \Phi_X^{-1}(A) \in F\}$? Formally, I can understand the meaning of pushforward measure too.
But I still don't feel it natural, perhaps because I don't actually
grasp the intuition about the $\sigma$-algebra and  the measure
$\mathcal{L}_{X}$ defined on $S^T$. So hope to see some insights
here. When $(S, \Sigma)=(\mathbb{R}, \mathcal{B}(\mathbb{R}))$, I heard
about a different way but cannot remember correctly: $\forall n \in \mathbb{N}, t_1, \dots, t_n \in T, B_i \in  \mathcal{B}(\mathbb{R}), i=1,\dots,n$, define a subset of
  $\mathbb{R}^T$ $$ [B_1, \dots, B_n]:= \{f \in \mathbb{R}^T: f(t_i) \in  B_i, i=1,\dots,n \} $$ and the $\sigma$-algebra on $S^T$ is the
  one
  generated from all $[B_1, \dots, B_n]$-like subsets (?). Then define the measure on $[B_1, \dots, B_n]$ to be $$ P(X_{t_1} \in  B_1, \dots, X_{t_n} \in B_n) $$ and extend this in some way to
  be a measure on the $\sigma$-algebra of $S^T$ (?). If the above way (after filling out the question marks) is correct,
is it equivalent to the Wikipedia way quoted in part 1, for inducing
$\sigma$-algebra and measure on $S^T$ by the process $X$? I would also like to know some references that can address my questions. Thanks and regards!","['probability-theory', 'stochastic-processes', 'measure-theory']"
90285,$L^p$ spaces with negative $p$,"Let $p$ be a negative real number and $X$ a measure space. Define $L^p(X)$ to be the vector space of all measurable functions $X \to \mathbb{C}$. Then define a ""norm"" on this space as is usual in the non-negative case: $\| f\| = (\int|f|^{p}dx)^{1/p}$. If $f$ is equal to zero on a set of positive measure it makes sense to interpret the integral as having an infinite value, which would make the ""norm"" equal zero. The same interpretation should apply in the case where the integral diverges. I realize this isn't a norm in the usual sense, but it still seems to retain some interesting properties, for example, it has the property of positive homogeneity. So I've been wondering: Are such spaces being studied? Is there any good literature available where one might learn about them? I have tried searching google but couldn't find anything useful. Thanks in advance.","['functional-analysis', 'reference-request']"
90290,Importance of Least Upper Bound Property of $\mathbb{R}$,"My professor asserts that the Least Upper Bound Property of $\mathbb{R}$ (Completeness Axiom) is the most essential piece in the study of real analysis. He says that almost every theorem in calculus/analysis relies directly upon on this Property. I know that the Archimedian property of $\mathbb{R}$ directly uses the property for the proof, but I'm trying to think of other major theorems that use the property directly. Do you think he means consequences of the property? Because then the gates are wide open... Does anyone know of any other theorems that use the properly directly? Sorry this is more of a general question","['real-analysis', 'analysis']"
90292,The generating function for permutations indexed by number of inversions,"For $\sigma\in S_n$ an inversion is a pair $(\sigma_i,\sigma_j)$ such that $i<j$ and $\sigma_i>\sigma_j$. Could you help me to prove that the generating function of $S_n$ by number of inversions is $(1+x)(1+x+x^2)\cdots(1+x+x^2+x^3\cdots+x^{n-1})$? (this is not homework)","['permutations', 'generating-functions', 'combinatorics']"
90303,Given $f\notin L^p$ find $g\in L^q$ s.t. $fg\notin L^1$,"This is the second part of the Exercise 2 in Chapter 8 of Measure and Integral by Zygmund and Wheeden: Show also that for real valued $f\notin L^p(E)$, there exist a function $g\in L^q(E)$, $\frac{1}{p}+\frac{1}{q}=1$, s.t. $fg\notin L^1(E)$. (Construct $g$ of the form $\sum a_kg_k$ for appropriate $a_k$ and $g_k$ satisfying $\int_E fg_k\to \infty$.) In the following the integrals are taken over $E$. Trying to follow the hint, if we assume $1\lt p\lt\infty$ note that $a_k=k^{-(q+1)}$, $b_k=k$ satisfies $$\begin{cases} \sum a_kb_k\lt\infty\\ \sum a_kb_k^q=\infty\end{cases}$$
In view of $$\begin{align*}
&\Vert g\Vert_q=\Vert \sum a_kg_k\Vert_q\leq \sum a_k\Vert g_k\Vert_q\\
&\Vert fg \Vert_1=\int fg =\sum a_k\int fg_k
\end{align*}$$
we just need $g_k$ such that $\Vert g_k\Vert_q=k$ and $\int fg_k=k^q$. Suppose that there exist a set $A_k\subseteq E$ such that $\int_{A_k} \vert f\vert^p=k^q$, then the sequence given by $$g_k=\vert f\vert^{p-1}\chi_{A_k}=\vert f\vert^{p/q}\chi_{A_k}$$
will do the job. I need to justify the existence of the $A_k$s. So, I'm looking for something like the following. Let $E\subseteq \mathbb{R}^d$. Let $f$ a function with $$\int_E \vert f\vert=\infty.$$ My question is: Given $t\in[0,\infty[$, does there exist a set $A_t\subseteq E$ s.t. $$\int_{A_t}\vert f\vert=t?$$ Let $C_t$ the cube around the origin with volume $t\geq 0$. I was trying to prove that the function $F:[0,\infty[\to\mathbb{R}\cup\{\infty\}$ given by $$F(t)=\int_{C_t\cap E}\vert f\vert$$
is continuous. My idea seems to have no future, because for example $f$ could be $\infty$ in any subset of positive measure. If this is not possible, how can I approach this problem?","['measure-theory', 'analysis']"
90309,Banach theorem example,"By Banach fixed point theorem, if a metric on a metric space $X$ is such that $d(f(x),f(y))\leq K d(x,y)$ for $K\in (0,1)$ then $f$ has one unique fixed point. Is there an example where $d(f(x),f(y))\leq K d(x,y)$ does not have a fixed point if $K=1$? What if $X$ is a compact space?","['fixed-point-theorems', 'real-analysis']"
90324,Need help finding limit $\lim \limits_{x\to \infty}\left(\frac{x}{x-1}\right)^{2x+1}$,Facing difficulty finding limit $$\lim \limits_{x\to \infty}\left(\frac{x}{x-1}\right)^{2x+1}$$ For starters I have trouble simplifying it Which method would help in finding this limit?,"['calculus', 'limits']"
90336,Existence of a random variable $Y$ that minimizes $\lVert X-Y\rVert_2$.,"In here , stated as a theorem is: Let $\mathcal{G}\subseteq\mathcal{F}$ be $\sigma$-algebras, $X\in L_2$ be a random variable on the probability space. Then, there exists a random variable $Y\in\mathcal{G}$ such that $E||X-Y||_2=\inf_{Z\in\mathcal{G}}E||X-Z||_2$ How do I prove such an element exists up to almost surely equivalence? Also, how can I show that this is $E[X|\mathcal{G}]$. In this appendix, $E[X|\mathcal{G}]$ is defined as this, but what if we start with the usual definition that this conditional expectation satisfies the properties that for all $G\in\mathcal{G}$, $\int_{G} E[X|\mathcal{G}]dP=\int_G XdP$ and $E[X|\mathcal{G}]$ is $\mathcal{G}$-measurable and integrable?",['probability-theory']
90349,probability textbooks,"Has anyone compiled a moderately comprehensive list on the web or elsewhere of textbooks on probability For students who have not been introduced to the subject before That introduce both discrete and continuous probability distributions
and their cumulative distribution functions, and include things like
the Poisson limit theorem, the central limit theorem (say the former
with proof and the latter not necessarily), and That perhaps cover the simplest stochastic processes like the Poisson process or
infinite sequences of Bernoulli trials?","['reference-request', 'probability']"
90371,F.g. groups with a finite index abelian subgroup,"It is well known that a virtually cyclic group is either finite, or finite-by-(infinite cyclic) or finite-by-(infinite dihedral). I want to know if there is some similar description for f.g. virtually abelian groups, or even for simpler groups (e.g. virtually (free abelian of rank 2)).
In the affirmative case, are the proofs easy/short? References are welcome too. Thank you!",['group-theory']
90373,Likelihood ratio interpretation,"I have $X_1, \ldots, X_n$ and $Y_1, \ldots, Y_n$ as as random samples from two normal distributions with means $0$ and variances $\theta_1$ and $\theta_2$ respectively.The null hypothesis is $\theta_1 = \theta_2$ and the alternative is $\theta_1$ not equal to $\theta_2$ I calculated the likelihood ratio (which is shown below) and now I am trying to figure out what this likelihood ratio is a function of. I believe it is a function of $F$ but I am unsure how to show that it is $F$-distributed with $v_1 = n$, and $v_2 = m$. Thanks for the help.
$$
\lambda={   
{  
\left\{
{\textstyle 1\over\textstyle  2\pi\bigl[\,(\,\sum x_i^2+\sum y_i^2\,)/(n+m)\, \bigr]}
\right\}^{n+m\over2}
}
\over
\biggl[{    {\textstyle1\over\textstyle 2\pi(\sum x_i^2 /n)}      }\biggl]^{n/2}
\biggl[{    {\textstyle1\over\textstyle 2\pi(\sum y_i^2 /m)}      }\biggl]^{m/2}
}
$$","['statistics', 'probability']"
90375,self-study problem: the behavior of conformal mapping at the Boundary,"I am reading Rudin's book, Real and Complex Analysis, and face a problem about the proof of Theorem 14.18. Here is my problem: The hypothesis of the theorem is ""$f$ is a conformal mapping of $\Omega$ onto $U$"". However, in the proof, it seems that the author blindly assumed $f$ is one-to one, because he said ""Let $g$ be the inverse of $f$"". I don't know why $f$ has a inverse, so I check the definition of conformal mappings. In the book, conformal mappings are defined as holomorphic functions with nonvanishing derivative. I know a one-to-one holomorphic function must have a nonvanishing derivative. However, nonvanishing derivative generally cannot imply a holomorphic function is one-to-one, but imply it is locally one-to-one. Maybe it's a very stupid problem. Any explanations will be appreciated. BTW: I've checked lots of textbooks relevant to the theorem. However, some books define confomal mappings as one-to one holomorphic functions with nonvanishing derivative. Others state $f$ is biholomorphic in the hypothesis of the theorem. Nothing is helpful for me to understand the theorem in Rudin's book.",['complex-analysis']
90394,Presentation of a group,"Let $a, b \in \mathbb{N},\ a, b\neq 0$ such that $(a,b)=1.$ Suppose $G$ is a group with presentation 
$$ G=\langle x, y \mid x^{-1}y^{-1}xy^{a+1}=1,\ y^{-1}x^{-1}yx^{b+1}=1\rangle. $$
Prove that $G= \langle x \rangle \times \langle y \rangle \simeq C_b\times C_a$.","['group-theory', 'group-presentation']"
90404,Problem based on Composite Functions.,"Let $f(x) = \sin^{2}{x} + \sin^{2}\left(x + \frac{\pi}{3}\right) + \cos{x}\cos\left(x + \frac{\pi}{3}\right)$ 
and $g(x) = \left\{\begin{array}{rcc} 2x,\quad0\le x<1 \\x + \frac{1}{4},\quad 1 \le x<2  \end{array}\right.$ ,   then find $g\{f(x)\}$. I am really confused on this one.","['self-learning', 'algebra-precalculus', 'functions']"
90406,How to detect when continued fractions period terminates,"I'm doing continued fractions arithmetic. Is there a method to detect when a continued fractions period terminates? Let me give you an example:
$\sqrt{2} = [1; \overline{2}]$, $\sqrt{7} = [2; \overline{1, 1, 1, 4}]$ and $\sqrt{14} = [3; \overline{1, 2, 1, 6}]$. Now clearly $\sqrt{2} \times \sqrt{7} = \sqrt{14}$, but if we do continued fractions arithmetic we get: $[1; \overline{2}] \times [2; \overline{1, 1, 1, 4}] = 3, 1, 2, 1, 6, 1, 2, 1, 6, 1, 2, 1, 6, \dots$. Obviously this sequence never ends, since the continued fraction can always input a term from either $\sqrt{2}$ or $\sqrt{7}$ (as they are infinite). So my question is: is there a mathematical method to detect when the period ends (during addition, subtraction, multiplication and division), rather than guessing and checking? Maybe using the $z$ object ( this ""thing"" )? For example, after it emits the first $1$ it is:
$\left \langle \begin{matrix}13 & 31 & 28 & 67\\ 
 11 & 27 2& 8 & 20
\end{matrix}\right \rangle$ and when the period starts again:
$\left \langle \begin{matrix} 549 & 1317 & 2226 & 5335\\ 95 & 239 & 814 & 2010 \end{matrix} \right \rangle$ and again: $\left \langle \begin{matrix} 92029 & 222405 & 122610 &  296283\\ 41317 & 99487 & 37841 & 91039 \end{matrix} \right \rangle$. Is there some kind of a pattern? I've noted none. Thank you, rubik","['algebra-precalculus', 'continued-fractions']"
90418,Showing a distribution function is right but not left-continuous,"I am having difficulty proving right-continuity of a distribution function. My problem is that my method for showing right-continuity works also to show $F$ is left-continuous. My proof of both must therefore be wrong but I do not know where. A distribution function of a random variable $X$ can be defined as $F(x)=\mu(-\infty,x]=P[X\leq x],$ where $P$ is the probability measure of the underlying probability space $(\Omega,\mathscr{F},P)$, and $\mu$ is a probability measure on the 1-dimensional Borel sets $\mathscr{R}$. Using the monotonicity of $\mu$ we see that $F$ is non-decreasing. Also for $a\leq x$ we have $\mu(a,x]=\mu(-\infty,x]-\mu(-\infty,a]$. I think the fact that $F$ is defined as $\mu(-\infty,x]$ and not $\mu(-\infty,x)$ means that $F$ can have a jump discontinuity say at $a$ as $x$ approaches from the left but not from the right - i.e $F$ is right but not left-continuous. My proofs rely on the following result: if $A_{n}$ and $A$ lie in $\mathscr{F}$ and $A_{n}\downarrow A$, and if $\mu(A_{1})<\infty$, then $\mu(A_{n})\downarrow \mu(A)$. Here is my proof for right-continuity; Let $y_{n}\downarrow x$. Then $(x,y_{n}]\downarrow \emptyset:(x,y_{1}]\supseteq(x,y_{2}]\supseteq...$ and $\cap_{n}(x,y_{n}]=(x,x]=\emptyset$. Since $(x,y_{n}]$ and $\emptyset$ are in $\mathscr{F}$, and $\mu(x,y_{1}]\leq 1<\infty$, then we have $\mu(x,y_{n}]\downarrow\mu(\emptyset)=0$. Equivalently $F(y_{n})-F(x)\downarrow 0:F(y_{1})-F(x)\geq F(y_{2})-F(x)\geq...$ and $F(y_{n})-F(x)\rightarrow 0$. Thus we have $F(y_{1})\geq F(y_{2})\geq ...$, and $F(y_{n})\rightarrow F(x)$. So $F$ is right-continuous: $lim_{y\downarrow x}F(y)=F(lim_{y\downarrow x})$. My ""proof"" for left-continuity is as follows; Let $y_{n}\uparrow x$. Then $(y_{n},x]\downarrow\emptyset:(y_{1},x]\supseteq(y_{2},x]\supseteq...$ and $\cap_{n}(y_{n},x]=(x,x]=\emptyset$. Since $(y_{n},x]$ and $\emptyset$ are in $\mathscr{F}$, and since $(y_{1},x]\leq 1<\infty$ then $\mu(y_{n},x]\downarrow\mu(\emptyset)=0$, or in terms of $F$ we have $F(x)-F(y_{n})\downarrow 0$. Thus $F(x)-F(y_{1})\geq F(x)-F(y_{2})\geq...$ and $F(x)-F(y_{n})\rightarrow 0$ or equivalently $F(y_{n})\uparrow F(x):F(y_{1})\leq F(y_{2})\leq...$ and $F(y_{n})\rightarrow F(x)$. So $F$ is left-continuous: $lim_{y\uparrow x}F(y)=F(lim_{y\uparrow x})$. Where am I going wrong? Any help would be greatly appreciated.","['measure-theory', 'probability-distributions']"
90419,Combination with repetition with an upper bound,"I am trying to calculate the number of ways to divide $30$ oranges between $10$ kids, with the restriction that each kid will get no more then $5$ oranges. So, as far as I know I need to use the Inclusion–exclusion principle but I'm not sure how exactly. 
Here's what I have so far: Count the number of division with no restrictions so we have $\binom{30+9}{10}$.
Subtract the number of ways with restriction that one kid (or two or three) gets at least $6$ so we have $-\binom{(24+9)}{10}, -\binom{18+9}{10}$ and so on... How do I continue from here? How do I calculate the intersection of $\binom{24+9}{10}$ and $\binom{18+9}{10}$? Thanks...",['combinatorics']
90422,"$\{\gamma \in C^0([0,1],M): \gamma (0)=p, \gamma (1)=q\}$ with the compact-open top has the homotopy type of a CW complex","...where $M$ is a smooth manifold and $p, q \in M$.  Does anyone know of any slick or accessible proofs of this?  I was referred to Milnor's ""On Spaces Having the Homotopy Type of a CW Complex"" which is a bit over my head.  I was wondering if anything simpler had been discovered in the intervening decades. Edit:  It looks like these are the steps Milnor takes (for proofs of which he cites papers I can't find or papers in languages i don't read): Lemma 1: Let $X$ be a topological space.  $X$ has the homotopy type of an absolute neighborhood retract (ANR) iff $X$ has the homotopy type of a countable CW complex Lemma 2:  If $Y$ is compact metric and $X$ is an ANR then the space of maps $Y\rightarrow X$ is an ANR. From these lemmas I can prove that $\{\gamma \in C^0([0,1],M)\}$ has the homotopy type of a CW-complex since I can prove $M$ has the homotopy type of a countable CW-complex. But I don't know how to get from there to the homotopy type of a subspace where the endpoints are fixed.  And I don't know how to prove the lemmas.","['general-topology', 'differential-topology']"
90427,Countable Chain Condition for separable spaces?,"I'm trying to find a proof behind a small proposition. Recall that a topological space satisfies the countable chain condition if each disjoint collection of open sets is countable. Why is it the case that every separable spaces satisfies the CCC, but the converse is not true? Thanks.",['general-topology']
90428,Notation for elements of a vector,"If I want $x_i$ to be an arbitrary element of a vector $\vec{x}$ can I use the following notation: $x_i \in \vec{x}=[x_1\;x_2\;\cdots\;x_n]^T\in \mathbb{R}^n$ ? And if I later want to specify the interval of each $x_i$ to be between $0$ and $1$ , can I then say that $x_i \in [0,1]\;\forall i$ ? Is this mathematically correct usage of $\in$ for both cases? The actual problem I have is that I want to say that $y_i\in\vec{y}$ for $i\in\{1,2,\cdots,n\}$ and that each $y_i$ is binary $y_i\in\{-1,+1\}$ . Should I stick to something like $\vec{y}\in\{-1,+1\}^n$ instead?","['notation', 'linear-algebra', 'elementary-set-theory']"
90433,Weak convergence as convergence of matrix elements,"Let $H$ be a Hilbert space with orthonormal basis $(e_h)_{h \in \mathbb{N}}$ and let $(A_n)_{n \in \mathbb{N}}$ and $A$ be bounded linear operators. We say that $A_n$ converges weakly to $A$ if $$\forall \xi, \eta \in H, \quad (\eta, A_n\xi)\to (\eta, A\xi).$$ Question Is it true that $A_n$ converges weakly to $A$ if and only if $$\forall h, k \in \mathbb{N},\quad (e_h, A_n e_k) \to (e_h, Ae_k)?$$ Indeed, I'm wondering if it is correct to think at weak convergence as convergence of the matrix entries associated to the operators $A_n$ and $A$. Thank you.","['operator-theory', 'hilbert-spaces', 'functional-analysis']"
90446,How different are inductively ordered set from posets that satisfy the ascending chain condition?,"I'd like to show that posets that satisfy the ascending chain condition (ACC) have maximal elements.  I noticed this statement looks much like Zorn's lemma which holds for inductively ordered sets.  Posets satisfying the ACC themselves look like inductively ordered sets: in the former every chain should terminate, while in the latter every chain has an upper bound. The question is: How different are inductively ordered set from posets that satisfy the ACC? How different is the proof of posets that satisfy the ACC having maximal elements from that of Zorn's lemma?  Does it require the Axiom of Choice?","['axiom-of-choice', 'elementary-set-theory', 'order-theory']"
90450,2nd degree differential equation with non-constant coefficients,"I'm having a really hard time solving $$xy'' + 2y' + 4xy = 0$$ I basically tried a lot of substitutions and series but couldn't find it.
I realize this isn't as hard as I make it out to be so I'm assuming there is a certain trick that I am not seeing. Thanks in advance!",['ordinary-differential-equations']
90463,How can I calculate the centroid of polygon?,"What is the way to calculate the centroid of polygon? I have a concave polygon of 16 points, and I want know the centroid of that. thanks","['geometry', 'mathematica']"
90473,Problem about the sum of independent exponential variable,"Let $X_1,\ldots,X_{n}$ be independent exponential variables with mean 1, and let $S_k = X_1+\cdots+ X_k$, it is not hard to get $\mathbb{E}(S_k)=k$. Let random variable $Y_k=|S_k-k|$, My first question is: what is the probability of $Y>t$ for some $t>0$, in another word: $\Pr(Y>t)$? Define another random variable $Z=\max_{k=1}^n Y_k$ The second question is: how to calculate $\Pr(Z>t)$ for some $t>0$ or $\mathbb {E} (Z)$.",['probability']
90475,Let $G$ be a singular graph with $n=10$ and $|E|= 28$. Show that $G$ contains a cycle of length $4$,"Let $G = (V(G),E(G))$ be a singular graph with $n=10$ and $|E|= 28$. Show that $G$
  contains a cycle of length $4$. The question says it all. Our teacher gave us the hint
that it is similar to another question that we answered using
combinatorics and double counting techniques with properties of singular graphs.
(in that case: we had $G' = (V(G),E(G))$ singular, with $n=10$ and $|E|=38$, show that $G$ contains $K_{4}$.) But I don't know how to solve this one, I don't know how to start with this proof. What is the best way? Constructive proof where we draw the graph and show that we avoid having a cycle of length $4$ and that eventually, you have to have a connection which gives length $4$ or is this solveable in other ways?","['graph-theory', 'constructive-mathematics', 'combinatorics']"
90482,Expectation product of pairwise uncorrelated variables,"Suppose I have three uncorrelated random variables $X, Y$ and $Z$ (discrete or continuous) such that $$\newcommand{\Cov}{\mathrm{Cov}}\Cov(X,Y)=0;\quad \Cov(Y,Z)=0;\quad \Cov(X,Z)=0 \tag{$\ast$}$$ I am to prove or disprove the fact that $$E(XYZ) = E(X)\cdot E(Y)\cdot E(Z)$$ It is evening here already and my head is somewhat dumb; now the obvious step I took was that $$\Cov(XY, Z) = E(XYZ) - E(XY)\cdot E(Z)$$ Now that $X$ and $Y$ are uncorrelated, it implies that $$\Cov(XY, Z) = E(XYZ) - E(X)\cdot E(Y)\cdot E(Z)$$ If I could prove or disprove that from $(\ast)$ implies $\Cov(XY,Z)=0$, then I would succeed. Can you please help me with that? Thank you in advance!","['probability-theory', 'correlation', 'probability']"
90491,Is a measure for a sigma algebra determined by its values for a generator of the sigma algebra?,"If the value of a measure on any subset in a generator of a sigma algebra is known, will the measure for the sigma algebra also be uniquely determined? Thanks!",['measure-theory']
90492,Number of non-isomorphic regular graphs with degree of 4 and 7 vertices?,"I'm faced with a problem in my course where I have to calculate the total number of non-isomorphic graphs. The graph is regular with an degree 4 (meaning each vertice has four edges) and has exact 7 vertices in total. What is the correct way of handling this question? After drawing a few graphs and messing around I came to the conclusion the graph is quite symmetric when drawn. I mean there is always one vertice you can take where you can draw a line through the graph and split in half and have two equal mirrored pieces of the graph. If you build further on that and look I noticed you could have up to 45 or more possibilities. But I don't have a final answer and I don't know if I'm doing it right. Any help would be appreciated. Kind Regards, Floris","['graph-theory', 'discrete-mathematics']"
90509,Solve $y '' + 3y ' + 2y = \frac{1}{e^{x} + 1} $,"I am trying to solve this differential equation.
$$y'' + 3y' + 2y = \frac{1}{e^{x} + 1}$$ I know that I have to solve $$x^2+3x+2=0$$ when the solutions of this equation are $(x_1,x_2) = (-2,-1)$ so $$y_0(x) = c_1 e^{-2x}+c_2e^{-x}$$ Then I am looking for a solution of $y(x) = K \frac{1}{e^x +1}$ and I calculate $y'$ and $y''$. The problem is that I end up to nowhere. Can someone help me?",['ordinary-differential-equations']
90518,Finding an outer automorphism of $S_6$,"From Wikipedia I found out about the fact that $S_6$ has outer automorphisms. So the idea is that first you find a transitive copy of $S_5$ in $S_6$. This I was able to do, I found that for example $\langle (1 2 3 4 5),\ (1 5)(2 3)(4 6)\rangle \cong S_5$ . This gives you a subgroup of index $6$ in $S_6$, let's call it $H$. And so we can use the left coset action or conjugation on $H$ to construct an automorphism of $S_6$ (for conjugation you have to show $[G : N_G(H)] = 6$ ). Then it turns out that this mapping does not send a transposition to its conjugate (another transposition) but to a product of three disjoint transpositions. This means that it is not an inner automorphism. Okay, makes sense to me. But I have no idea how one should calculate the coset representatives for $H$ by hand, and how to determine how different elements of $S_6$ act on the cosets? I know it should be enough to determine how $(12)$ and $(123456)$ act on the cosets because $S_6$ is generated by these elements. I was able to brute-force a solution with GAP, but it is not a very satisfying way to do it..",['group-theory']
90520,Proving a function is surjective,"Is this a valid proof for the following? Let $f$ and $g$ be functions such that $f: A \to B$ and $g: B \to C$.
Prove or disprove that if $g(f(x))$ is surjective, then $g$ is surjective. To show that $g$ is onto, it must be shown that for every element $c \in C$, $g(b) = c$ for some $b \in B$. Since we know that $g(f(x))$ is onto, then for every element $c \in C$, $g(f(a)) = c$ for some $a \in A$, which means that for every element $b \in B$, $f(a) = b$ for some $a \in A$. That is,
$g(f(a)) = g(b) = c$. Therefore, we have shown that $g$ is onto $C$.","['proof-verification', 'elementary-set-theory', 'functions']"
90526,Proof of Product Rule for Derivatives using Proof by Induction,"I am trying to understand the proof of the General Result for the Product Rule for Derivatives by reading this . Relevant parts are as follows: Basis for the induction $$
D_x \left({f_1 \left({x}\right) f_2 \left({x}\right)}\right) = D_x \left({f_1 \left({x}\right)}\right) f_2 \left({x}\right) + f_1 \left({x}\right) D_x \left({f_2 \left({x}\right)}\right)
$$ Induction Hypothesis $$
D_x \left({\prod_{i=1}^k f_i \left({x}\right)}\right) = \sum_{i=1}^k \left({D_x \left({f_i \left({x}\right)}\right) \prod_{j \ne i} f_i \left({x}\right)}\right)
$$ Induction Step $$
\begin{align}
\tag{1} \kern-30pt D_x \left({\textstyle\prod\limits_{i=1}^{k+1} f_i \left({x}\right)}\right) 
&=  D_x \left({\left({\textstyle\prod\limits_{i=1}^k f_i \left({x}\right)}\right) f_{k+1} \left({x}\right)}\right) \\ 

&= \tag{2}  D_x \left({f_{k+1} \left({x}\right)}\right) \left({\textstyle\prod\limits_{i=1}^k f_i \left({x}\right)}\right) + D_x \left({\textstyle\prod\limits_{i=1}^k f_i \left({x}\right)}\right) f_{k+1} \left({x}\right) \\

&=\tag{3}  D_x \left({f_{k+1} \left({x}\right)}\right) \left({\textstyle\prod\limits_{i=1}^k f_i \left({x}\right)}\right) + \left({\sum_{i=1}^k \left({D_x \left({f_i \left({x}\right)}\right) \textstyle\prod\limits_{j \ne i} f_i \left({x}\right)}\right)}\right) f_{k+1} \left({x}\right)  \\

&= \tag{4}  \sum_{i=1}^{k+1} \left({D_x \left({f_i \left({x}\right)}\right)\textstyle \prod\limits_{j \ne i} f_i \left({x}\right)}\right)  

\end{align}
$$ Question I am stuck at (3). How do I go from (3) to (4)? Specifically, what sort of algebraic manipulations need to be done and what are the motivations for doing those algebraic manipulations in order to arrive at (4)? To put it in another way, I would like to know that is the thought process that one goes through when simplifying (3) to (4). Note: I hope someone can correct my LaTeX typesetting. I was under the impression that the align environment would automatically number the formulas I write. Thanks in advance.","['induction', 'calculus', 'derivatives']"
90538,Interesting Property of Numbers in English,"I was playing with the letters in numbers written in English and I found something quite funny. I found that if you count the number of letters in the number and write this as a number and then count the number of letters in this new number and keep repeating the process, you will arrive at the number 4. 
I've confirmed this (using a computer program) for all numbers up to 999999 and was wondering if there's a way to prove this or to find a counter example for which it does not hold. Just to give an example of the above statement, let's start with thirty seven (I chose this randomly)
Thirty seven has 11 letters in it, Eleven has 6 letters in it, Six has three letters in it, Three has 5 letters in it, Five has 4 letters in it.
It may look like I just picked this number, so let me show this for another random number, say 999.
Nine hundred and ninety nine has 24 letters in it, Twenty four has 10 letters in it, Ten has 3 letters in it, Three has 5 letters in it, Five has 4 letters in it. What are your thoughts on how to prove this? (Just a note: I only confirmed this for numbers written in the standard British way of writing numbers - for example 101 is one hundred and one)","['conjectures', 'sequences-and-series', 'number-theory']"
90541,Determining the Value of a Gauss Sum.,"Can we evaluate the exact form of $$g\left(k,n\right)=\sum_{r=0}^{n-1}\exp\left(2\pi i\frac{r^{2}k}{n}\right) $$ for general $k$ and $n$?  For $k=1$, on MathWorld we have that 
$$g\left(1,n\right)=\left\{ \begin{array}{cc}
(1+i)\sqrt{n} & \ \text{when}\ n\equiv0\ \text{mod}\ 4\\
\sqrt{n} & \text{when}\ n\equiv1\ \text{mod}\ 4\\
0 & \text{when}\ n\equiv2\ \text{mod}\ 4\\
i\sqrt{n} & \text{when}\ n\equiv3\ \text{mod}\ 4
\end{array}\right\} .$$ I know how to generalize to all $k$ when $n=p$ is a prime number, but what do we do when $n$ is not prime? Is there a simple way to rewrite it using whether or not $k$ is a square?  I have a suspicion it should be fairly close to the form above, any help is appreciated. Thanks,","['exponential-sum', 'gauss-sums', 'analytic-number-theory', 'number-theory']"
90544,Does almost everywhere convergence imply convergence in $L^p$?,"Is it true that if $\Omega$ is an open, bounded subset of $R^{N}$, $u_{n} \to u$ almost everywhere, $1<p<\infty$, then $\|u_{n} - u\|_{L^{p}} \to 0$? Here sequence and the function are in $L^{p}$ My proof uses dominated convergence theorem to $v_{n}(x) = |u_{n}(x) - u(x)|^{p}.$
and the fact that $\Omega$ is bounded. thanks","['convergence-divergence', 'real-analysis', 'analysis']"
90552,Eisenstein series estimate from Stein-Shakarchi's Complex Analysis,"I need help with this exercise from Stein-Shakarchi's Complex Analysis (page 280), Chapter 9 (An Introduction to Elliptic Functions), Exercise 8 Let $$E_{4}(\tau)=\sum_{(n,m)\neq (0,0)}{\frac{1}{(n+m\tau)^{4}}}$$ be the Eisenstein series of order $4$ . Show that $$\left|E_{4}(\tau)-\frac{\pi^{4}}{45}\right|\leq c e^{-2\pi t}\ \text{if}\ \tau = x + it\ \text{and}\ t \geq 1.$$ and deduce that $$\left|E_{4}(\tau)-\tau^{-4}\frac{\pi^{4}}{45}\right|\leq c t^{-4} e^{-2\pi/ t}\ \text{if}\ \tau = it\  \text{and}\  0 < t \leq 1.$$ My idea is to use the estimates from the proof of Theorem 2.5 of pp. 277, but I can't see a finish. Thanks in advance! EDIT: On page 277, we have the information that in general $$E_{k}(\tau)=\sum_{(n,m)\neq (0,0)}{\frac{1}{(n+m\tau)^{k}}} = 2 \zeta(k) + \frac{2 (-1)^{k/2} (2 \pi)^{k} }{(k-1)!} \sum_{m >0 } {\sum_{l=1}^{\infty}{l^{k-1}e^{2\pi i \tau m l }}}.$$","['modular-forms', 'complex-analysis']"
90558,Is $\prod_{\mathbb{R}}\mathbb{R} = \mathbb{R}^\mathbb{R}$?,"(If the title is unclear, I'm looking at infinite cartesian product of $\mathbb{R}$ indexed by $\mathbb{R}$.) I thought that I had reasoned this rather well, as follows: $\mathbb{R}^\mathbb{R} = \{f\mid f:\mathbb{R}\rightarrow\mathbb{R}\}$. Note that this includes functions whose range is not $\mathbb{R}$, $\mathbb{R}$ here is just the codomain. Now consider an element $\textbf{x} \in \prod_{\mathbb{R}}\mathbb{R}$. This is an  ""uncountably infinite sequence,"" so to speak, so it does represent a function, where the index indicates the $x$ coordinate and the value at that index indicates the $y$ coordinate. (Consider a constant $x_i = 1 \;\forall\; i\in\mathbb{R}$, a straight line.) But this does not account for functions with vertical asymptotes, or functions which are not surjective (e.g. $f(x) = x^2$), so we conclude that   $\prod_{\mathbb{R}}\mathbb{R} \subsetneq \mathbb{R}^\mathbb{R}$. If we union in $\{+\infty, -\infty\}$, then we can get functions with vertical asymptotes, and if we allow coordinates $x_i = \emptyset$, then we get surjective functions as well. (If that even makes sense semantically). This seems to make sense to me, and I find it a satisfying answer. However, I was reading this wikipedia article which states that: An uncountable product of metric spaces need not be metrizable. For example, $\mathbb{R}^\mathbb{R}$ is not first-countable and thus isn't metrizable. Which implicitly states that $\prod_{\mathbb{R}}\mathbb{R} = \mathbb{R}^\mathbb{R}$. So what am I missing? I feel like it must be something rather obvious.","['general-topology', 'products', 'functions']"
90563,Lie Group Multiplication in Coordinates,"I'm having a bit of trouble with the last bit of Problem 3.2 in Kirillov Jr.'s Introduction to Lie Groups and Lie Algebras . (3.2) Let $f: \mathfrak{g} \rightarrow G$ be any smooth map such that $f(0)=1_G$ and $f_*(0) = \text{id}_{\mathfrak{g}}.$  Show that the group law in this coordinate system near the identity has the form $f(x) f(y) = f(x+y+B_f(x,y)+ \cdots )$ for some bilinear map $B: \mathfrak{g} \otimes \mathfrak{g} \rightarrow \mathfrak{g}$ and that $B_f(x,y)-B_f(y,x)= [x,y]$. The inverse function theorem lets us write $f(x)\cdot f(y) = f(\mu_f(x,y))$ for some smooth map $\mu_f: \tilde{U} \rightarrow \mathfrak{g}$ defined on some open set $\tilde{U} \subset \mathfrak{g} \times \mathfrak{g}$.  Restricting to $x=0$ then $y=0$ in the Taylor expansion of $\mu_f$ around $0 \times 0$ reveals that $\mu_f(x,y) = x+y+ B_f(x,y) + \cdots$ for some bilinear map $B_f : \mathfrak{g} \otimes \mathfrak{g} \rightarrow \mathfrak{g}$ which is defined everywhere even though $\mu_f$ might not be since we can rescale.  We know that in the case where $f= \text{exp}: \mathfrak{g} \rightarrow G$ we have $B_{\text{exp}} (x,y)= \frac{1}{2} [x,y]$, which means it's enough to show that for any other $\tilde{f}$ satisfying the conditions of the problem statement we have $$B_f(x,y)-B_f(y,x)=B_{\tilde{f}}(x,y)-B_{\tilde{f}}(y,x)$$ for all $x,y \in \mathfrak{g}$.  This is all I've got so far - I can't seem to find the right view to take in order to finish the problem. Note that unlike the exponential map, in general we don't expect there to be a relationship between $f(x)$ and $f( \lambda x)$ for $\lambda \in \mathbb{R}$ since all we know is that $f$ is smooth. Any help would be greatly appreciated!","['lie-algebras', 'lie-groups', 'differential-geometry']"
90607,closed subschemes of projective space over a scheme,"Let $X$ be an integral Noetherian scheme. If $Z \subset \mathbb{P}^n_{\mathbb{Z}}$ is a closed subscheme, under what conditions can we say that the codimension of $X \times Z \subset \mathbb{P}^n_X$ is equal to the codimension of $Z \subset \mathbb{P}^n_{\mathbb{Z}}$? I am really interested in the case that $Z$ has codimension one, i.e. $Z$ is a Weil divisor on $\mathbb{P}^n_{\mathbb{Z}}$. Edit: this is not always true. If the subscheme is of an ""arithmetic"" nature, e.g. $\mathbb{P}^n_{\mathbb{F}_p} \subset \mathbb{P}^n_{\mathbb{Z}}$, then the result depends very much on the characteristic in which $X$ lives.","['projective-space', 'algebraic-geometry', 'schemes']"
90608,Does the Banach algebra $L^1(\mathbb{R})$ have zero divisors?,"Assume that the functions $f,g: \mathbb{R}\rightarrow \mathbb{R}$ are integrable and equal to zero on $(-\infty,0)$, (i.e $f,g \in L^+$). Then by Titchmarsh's theorem: $f*g$ is zero almost everywhere iff $f$ or $g$ is zero almost everywhere. Hence the Banach subalgebra $L^+$ of $L^1(\mathbb{R})$ has no zero divisors. Is the same true for arbitrary integrable $f$ and $g$ on $\mathbb{R}$ ?","['banach-algebras', 'fourier-analysis', 'functional-analysis', 'real-analysis']"
90610,Gaussian distribution on a $2$-sphere,"I am wondering if there is a probability distribution function that emulates a Gaussian like distribution on a sphere. The mean $\mu$ would correspond to one single point on the sphere and $\sigma$ is a number that gives the standard deviation. I would guess that the pdf should be such that if $\sigma \rightarrow \infty$, then the pdf converges to a uniform distribution and if $\sigma \rightarrow 0$, then the pdf converges to a delta function on the sphere concentrated at the point $\mu$. Is there a well-known function of this type? If there is none, I would appreciate any hints towards obtaining such a function. Thank you all for your help.","['probability', 'differential-geometry']"
90625,What does it mean to say a polynomial has an isolated singularity,"In algebraic geometry, what does it mean when people say a polynomial $f$ has an isolated singularity at the origin?","['commutative-algebra', 'algebraic-geometry']"
90629,Why is this equation $\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=\lambda +\lambda^2$ true?,"Why is $$\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=\lambda +\lambda^2$$ For the context: I am trying to calculate $E(X^2)$, where X is a poisson distributed random variable. All my calculations lead to a dead end. Is there a trick to process the $k^2$? The only thing I see worth doing is pulling out $1/e^\lambda$. Edit: Considering @Srivatsan's hint I got: $$\sum_{k=0}^{\infty}k^2\frac{\lambda^k}{k!e^\lambda}=e^{-\lambda}\sum_{k=0}^{\infty}(k(k-1)+k)\frac{\lambda^k}{k!}=e^{-\lambda}\left( \sum_{k=0}^{\infty}k(k-1)\frac{\lambda^k}{k!}+\sum_{k=0}^{\infty}k\frac{\lambda^k}{k!}\right)$$
$$=e^{-\lambda}\sum_{k=0}^{\infty}k(k-1)\frac{\lambda^k}{k!}+e^{-\lambda}\sum_{k=0}^{\infty}k\frac{\lambda^k}{k!}=e^{-\lambda}\lambda^2\sum_{k=2}^{\infty}\frac{\lambda^{k-2}}{(k-2)!}+e^{-\lambda}\lambda\sum_{k=1}^{\infty}\frac{\lambda^{k-1}}{(k-1)!}$$
$$=e^{-\lambda}\lambda^2\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}+e^{-\lambda}\lambda\sum_{k=0}^{\infty}\frac{\lambda^k}{k!}$$
$$=\lambda^2+\lambda$$ And here we are! Thank you very much, @Srivatsan!","['sequences-and-series', 'probability']"
90631,Are Lie algebras of non-isomorphic central simple algebras non-isomorphic?,"Comments to my answer to this MO question , which is isomorphic to this MSE question , point out that I was tacitly assuming that the associated Lie algebras to non-isomorphic quaternion algebras over $\mathbb Q$ remain non-isomorphic. This should have a simple, decisive answer, but I'm unable to really get anywhere. Specifically, let $A_1$ and $A_2$ be central simple algebras over a field $k$ (of characteristic zero, but not algebraically closed), so $A_i\simeq M_{n_i}(D_i)$, where $D_i$ is a division algebra. Put a Lie algebra structure on the $A_i$ in the standard way by $[x,y]=xy-yx$. Write ${\rm Lie}(A_i)$ for $A_i$ considered as a Lie algebra. The question is: If ${\rm Lie}(A_1)\simeq{\rm Lie}(A_2)$, is $A_1\simeq A_2$? If the $A_i$ are not central (meaning the center strictly contains $k$), the answer is no. For example, if $K$ is a quadratic extension of $k$, then $K$ and $k^2$ will be isomorphic as Lie algebras (since they are isomorphic as vector spaces and both have trivial bracket operation). [Edit: Of course, $k^2$ is not simple. To salvage this example, replace $k^2$ with a second quadratic extension $K'$.] Added later: Coming back to this, assume $A_1$ is split by an extension $K$ of $k$, and $A_2$ is not. Then $A_1\otimes_kK\simeq M_n(K)$, while $A_2\otimes_kK\simeq M_m(D)$, where $D$ is a non-trivial division algebra over $K$ and $n=md$. Then, we just need to show that ${\rm Lie}\big(M_n(K)\big)\not\simeq{\rm Lie}\big(M_m(D)\big)$. This would answer my question in the affirmative, under the assumption that the $A_i$ are split by different extensions. In this case, the question becomes: Is there a simple proof that ${\rm Lie}\big(M_n(K)\big)\not\simeq {\rm Lie}\big(M_m(D)\big)$? I still can't get this to work. One strategy is to show that $M_n(K)$ has a subalgebra that $M_m(D)$ can't have (e.g., by dimension considerations). (Note that the Lie subalgebras are in 1-1 correspondence with the ""normal"" subalgebras.) For example, a quaternion division algebra does not have a three-dimensional subalgebra, but $M_2(K)$ does.","['algebraic-groups', 'lie-algebras', 'abstract-algebra']"
90636,Abelianization of finite index subgroup of a perfect group,"Suppose $G$ is a perfect group, i.e. it is equal to its commutator subgroup, or equivalently has trivial abelianization. If $H<G$ is a finite index subgroup, can anything be said about the abelianization of $H$? For instance, must it be finite?",['group-theory']
90637,$\sum \limits_{n=1}^{\infty}n(\frac{2}{3})^n$ Evalute Sum [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: How can I evaluate $\sum_{n=1}^\infty \frac{2n}{3^{n+1}}$ How can you compute the limit of 
$\sum \limits_{n=1}^{\infty} n(2/3)^n$ Evidently it is equal to 6 by wolfram alpha but how could you compute such a sum analytically?","['sequences-and-series', 'real-analysis', 'limits']"
90642,What is the intuitive meaning of the scalar curvature R?,"Background: Let $M$ be a smooth, Riemannian manifold with metric $g$ and dimension $n$.  Let $R^a_{bcd}$ be the Riemann tensor with respect to the Levi-Civita connection for $g$. Question: Is there any rigorous result that gives a good intuitive sense of the meaning of the scalar curvature $R = R^{ab} R_{ab}$? Discussion: What I have in mind is something like the following: For $n =2$, the volume of a geodesic ball of radius $\epsilon$ in $M$ is $\pi \epsilon^2 [1 - (R / 48) \epsilon ^2 + O(\epsilon^4) ]$.  I may have the numerical factors wrong, but the point is this: $R$ tells you the difference between the volume of a geodesic ball and an ordinary Euclidean ball (for small radius).  That's the kind of result I'm looking for. My problem with this result is that it holds in normal geodesic coordinates but not in general coordinates.  (Note that a choice of coordinates is necessary to define 'a geodesic ball of radius $\epsilon$').  If you know how to generalize this result to arbitrary coordinates, or you know another result that gives some intuition for $R$, please let me know. Thanks for any help!","['riemannian-geometry', 'differential-geometry']"
90661,Why is the Kendall tau distance a metric?,"So I am trying to see how the Kendall $\tau$ distance is considered a metric; i.e. that it satisfies the triangle inequality. The Kendall $\tau$ distance is defined as follows: $$K(\tau_1,\tau_2) = |(i,j): i < j, ( \tau_1(i) < \tau_1(j) \land \tau_2(i) > \tau_2(j) ) \lor ( \tau_1(i) > \tau_1(j) \land \tau_2(i) < \tau_2(j) )|$$ Thank you in advance.",['statistics']
90662,compactness and continuity in metric spaces,"Any help please with the following problem? Let $f:X\rightarrow Y$  be a continuous one-to-one and surjective mapping between
compact metric spaces. Prove that the inverse mapping $f^{-1}:Y\rightarrow X$ is continuous. I tried the following: I assumed $C$ a subset of $X$, then by compactness of $X$, C is also compact and hence it is closed. $f$ is continuous and $C$ is compact, then $f(C)$ is compact and hence it is closed. Any help how to go from here to prove that $f^{-1}$ is continuous?","['general-topology', 'real-analysis', 'analysis']"
90665,A function is continuous if its graph is closed,"Any help with the following problem: Prove that if a function $f: \mathbb{R}\rightarrow \mathbb{R}$ is bounded and its graph is a closed subset of $\mathbb{R}^{2}$, then $f$ is continuous.","['general-topology', 'continuity', 'real-analysis', 'analysis']"
90668,A function that is $L^p$ for all $p$ but is not $L^\infty$?,"Let $X$ be the interval $[0,1]$ with Lebesgue measure. Is there a function $f\in L^p(X)$ for all $p\in[1,\infty)$ that is not $\in L^\infty(X)$? If so, what is an example? Motivation: In a course on measure theory this fall, I've learned proofs that $L^p(X)\supset L^q(X)$ if $q>p$ and that if $f\in L^\infty(X)$, then $\|f\|_\infty = \lim \limits_{p\to\infty} \|f\|_p$.  This prompted me to wonder if $L^\infty(X) = \bigcap _p L^p(X)$. A classmate gave me a general theoretical reason to believe the contrary: $L^p(X)$ is a reflexive space for $1 \lt p \lt \infty$ but not for $p=1,\infty$; but intersections of reflexive spaces are reflexive. This logic seems sound to me; but it implies the containment $L^\infty(X) \subset \bigcap_p L^p(X)$ is strict.  If so, there must be a function that is $L^p$ for all $p$ but not a.e. bounded. What is it?","['measure-theory', 'functional-analysis', 'real-analysis']"
90674,"Etymology of the word ""isotropic""","Given a quadratic form $q : V \rightarrow k$, a nonzero vector $v \in V$ is said to be isotropic if $q(v) = 0$.  Any subspace of $V$ containing such a vector is also said to be isotropic, and the quadratic form itself is also said to be isotropic.  The word ""isotropic"" is Greek for ""the same in every direction.""  What does this have to do with being a zero of a quadratic form?","['quadratic-forms', 'linear-algebra', 'terminology']"
90681,Find the radius of convergence for this series,"Let $[a_1,a_2,a_3,...,a_n]$ be the least common multiple of numbers $a_1,a_2,...,a_n$. Then what should the radius of convergence be for the following series:$$\sum_{n=1}^{\infty} \frac{z^n}{[1,2,...,n]}$$","['analytic-number-theory', 'sequences-and-series']"
90692,Hensel's Lemma: $f'(x) \equiv 0 \pmod{p}$ case.,"I understand Hensel's Lemma and how you lift a root $f(b_{j}) \equiv 0 \pmod{p^\alpha}$ to one $f(b_{j+1}) \equiv 0 \pmod{p^{\alpha+1}}$, as long as $f'(b_{j}) \not\equiv 0 \pmod{p}$. The equation is actually quite simple: $b_{j+1} \equiv b_{j} - f(b)*(f'(a)^{-1}) \pmod{p^{\alpha+1}}$. My question is what happens when $f'(b) \equiv 0 \pmod{p}$. The best I can find is that there are multiple solutions, but nothing I can find says how to find them. Is there a nice equation for $b_{j+1}$ (or the multiple values it can take on) given $b_{j}$.",['number-theory']
90694,Probability with Combinations (Coin Toss),"Toss a fair coin six times. What is probability of : a- all heads b- one head c- two heads d- an even number of heads e- at least four heads. I have the answers so I ask if you could explain how you should derive rather than just giving me the answers please. I know for a, you just multiple 1/2 6 times.
But for the rest I need your help please.","['probability', 'combinatorics']"
90701,A combinatorial proof of $n^n(n+2)^{n+1}>(n+1)^{2n+1}$?,"The statement is simply that the sequence $\left(1+\frac{1}{n}\right)^n$ is increasing. Since the numbers $n^m$ have quite natural combinatorial interpretations, it makes me wonder if a combinatorial proof exists, but I haven't been able to find one. For example, if we let $S_{n,m}$ denote the set of function $\{1, \dots, n\} \to \{1, \dots, m\}$, then a proof would follow from the construction of an injection $S_{2n+1,n+1} \hookrightarrow S_{n, n} \times S_{n+1,n+2} $, or of a surjection going the other way.","['inequality', 'sequences-and-series', 'combinatorics']"
90715,Minmax problem for polygons,"Let $\text{Pol}_n$ be the set of all convex polygons on a plane with $n$ sides. For $P\in \text{Pol}_n$ denote by $\text{Tr}(P)$ the set of all triangles whose vertices are some vertices of $P$. I want to find an explicit formula for the function
$$
\Phi(n)=\inf\limits_{P\in \text{Pol}_n}\max\limits_{T\in \text{Tr}(P)}\frac{\text{area}(T)}{\text{area}(P)}
$$
It is not hard to prove that $\Phi(3)=1$, $\Phi(4)=1/2$. For $n\geq 5$ we have an estimation $\Phi(n)\geq 1/(n-2)$.","['optimization', 'geometry']"
90737,Shortest proof for 'hairy ball' theorem,"I want to make a project at differential geometry about the Hairy Ball theorem and its applications. I was thinking of including a proof of the theorem in the project. Using the Poincare-Hopf Theorem seems easy enough, but I was thinking that this proves the desired result using a stronger theorem (just like proving Liouville's Theorem in complex analysis using Picard's theorem). Is there a simple proof of the fact that there is no continuous non-zero vector field on the even dimensional sphere? It is good enough if the proof works only for $S^2$, because that is the case I will be focusing on in the applications.","['reference-request', 'differential-geometry']"
90740,Checking if abelian group,"Let $G=\{x \in \mathbb R \mid x>0 , x\neq 1 \}$.  Define $*$ operation on $G$ by $a*b:=a^{\ln(b)}$
for all $a,b \in G$. Prove that $G$ is an abelian group under the operation $*$. I know that definition of abelian group is like this A group  $G$ is said to be abelian if $a*b=b*a$   for all $a,b \in G$. But how  $a^{\ln b}$  should be equal to $b^{\ln(a)}$? I did not understand this and please help me, if $a*b=a^{\ln(b)}$   then by the same logic is not $b*a=b^{\ln(a)}$?if so how are they equal to each other? Thanks a lot.","['group-theory', 'abstract-algebra']"
90746,"If $Y$ is connected, why is $A\cup Y$ connected in this case?","If $(X,\mathcal{T})$ is a connected space, and $Y$ a connected subset, and $X\setminus Y=A\cup B$ for separated sets $A$ and $B$, then why is $A\cup Y$ connected as well? Thank you kindly.","['general-topology', 'connectedness']"
90748,"Explanation of ""generic point"" with examples?","Could someone please explain to me why $X$ and $Y$ are generic points of $\mathbb{R}[X, Y]/(XY)$? And why is the ideal generated by irreducible polynomial is a generic point in $\mathbb{R}[X, Y]$?",['algebraic-geometry']
90758,The Aleph numbers and infinity in calculus.,"I have a fairly fundamental question. What is the difference between infinity as shown by the aleph numbers and the infinity we see in algebra and calculus? Are they interchangeable/transposable in any way? For example, could you describe the infinity of a limit with an aleph number? Does it have cardinality? Thank you.","['cardinals', 'calculus', 'elementary-set-theory', 'infinity']"
90782,The minimum of two independent geometric random variables,"here's a question I got for homework (sorry if my translation is a bit unclear): Let $X\sim‬G(p_1)$ , $Y\sim ‬G(p_2)$ , $X$ and $Y$ are independent. Prove that the minimum is also geometric, meaning: $\min(X,Y)\sim G(1-(1-p_1)(1-p_2))$ . Instructions: first calculate the probability $P(\min(X,Y) > k)$ and compare it to the parallel probability in (of?) a geometric random variable. I have no idea where to start, even with the great clue that they've supplied. Any hints?",['probability']
90798,Help on normal family,"Suppose, I have a function $f(z)=\xi z$ where $|\xi|=1$ but $\xi$ is not a root of unity. Then, from the fact that the $n$-th iteration $f^{\circ n}(z)$, $z \in \mathbb{C}$, is dense on the circle around $0$ and radius $|z|$, how can I can deduce that $\{f^{\circ n}\}$ is a normal family? Thanks for any help!",['complex-analysis']
90821,How to find the closed form to the fibonacci numbers? [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Prove this formula for the Fibonacci Sequence How to find the closed form to the fibonacci numbers? I have seen is possible calculate the fibonacci numbers without recursion, but, how can I find this formula? Where it come from? Appreciate helps, thx.","['fibonacci-numbers', 'closed-form', 'algebra-precalculus']"
90849,Product of Taylor polynomials,"I'm trying to prove the following proposition: Let $U\in R^n$ be open, and $f,g\colon U\to R$ be $C^k$ functions, then the Taylor polynomial of $fg$ is computed as $P_{f,a}^k(a+\vec{h})\cdot P_{g,a}^k(a+\vec{h})$ and discarding the terms of degree > $k$,
  where $P_{f,a}^k(a+\vec{h})$ denotes the degree $k$ Taylor polynomial of $f$ at $a$. And here's what I've got so far: $$P_{fg,a}^k=\sum_{m=0}^k\sum_{I\in I_n^m}\frac{1}{I!}D_I(fg)(a)$$ using the definition of Taylor polynomial of multi-variable functions. ($I=(i_1,i_2,...,i_n)$ and $D_If=D_1^{i_1}D_2^{i_2}...D_n^{i_n}f)$. Then I think $D_I(fg)$ can be written as $D_I(f)g+fD_I(g)$ using the product rule so that
$$P_{fg,a}^k(a+\vec{h})=P_{f,a}^k(a+\vec{h})\cdot g+f\cdot P_{g,a}^k(a+\vec{h})$$ but I can't figure out how this leads to the final result.","['multivariable-calculus', 'taylor-expansion']"
90861,Critical region and power function for hypothesis test,"Hi all I have a question about Hypothesis test, could you please help me? If $X_{1},X_{2},\ldots,X_{n}$  are independent, where $X_{i}$  is $N(\theta_{i},1)$ , find the critical region and power function for the Most Powerful test of size $\alpha$  of $H_{0}:\theta_{1}=\cdots=\theta_{n}=0$  against $H_{1}:\theta_{1}=\cdots=\theta_{r}=\frac{1}{2} , \theta_{r+1}=\cdots=\theta_{n}=-\frac{1}{2}$",['statistics']
90864,Proper application of Cauchy integral formula,"I'm being asked to integrate $f(z) = \frac{e^z}{z^2 + 2z + 1}$ around a $5 \times 5$ square, centered at $i$, in the counter clockwise direction. It seems to me that applying Cauchy's integral formula for the first derivative directly yields an answer, but I am concerned the approach is incorrect due to a double pole at $z =-1$. Is there any special case that I am missing?","['complex-analysis', 'contour-integration']"
90894,product of six consecutive integers being a perfect square,"A 1939 paper of Erdos ( Note on Products of Consecutive Integers , J. London Math. Soc. 14 (1939), 194–198) shows that a product of consecutive positive integers cannot be a perfect square. He cites a 1917 paper by Narumi which proves that a product of at most 202 consecutive positive integers cannot be a perfect square. I cannot seem to easily find Narumi's paper. Although this result is known, I am curious about self-contained elementary proofs of special cases. It's not too difficult to come up with fairly quick proofs for two, three, four, five, or seven consecutive integers. Is there a short self-contained elementary proof that the product of six consecutive positive integers cannot be a perfect square? Or is it perhaps fair to say that this is the first ""tricky"" case?","['elementary-number-theory', 'number-theory']"
90914,Sum of squares of roots of a polynomial $P(x)$,"Well, I recently proved a formula (at least, I think) to the sum of the inverse of the roots $x_{1}, x_{2}, x_{3},\ldots, x_{n} \in \mathbb{C}$, and $\neq 0$. It starts: Let a polynomial $P(x) = a_nx^n+a_{n-1}x^{n-1}+\cdot\cdot\cdot+a_1x + a_0$ of roots $x_{1}, x_{2}, x_{3},\ldots,x_{n} \in \mathbb{C^*}$ and $a_n \neq 0$. So, $$\frac{1}{x_1} + \frac{1}{x_2} + \frac{1}{x_3}+\cdots+ \frac{1}{x_n} = -\frac{a_1}{a_0}, \qquad a_0 \neq 0.$$ Now, I am trying to prove another formula, the sum of the square of the roots, but I think it's getting pretty difficult to me. Let $x_{1}^{2} + x_{2}^{2} + x_{3}^{2}+\cdots+x_{n}^{2}=u.$ So, if $x_1\cdot x_2\cdot x_3 \cdots x_n = (-1)^n\frac{a_0}{a_n}$, then 
$$x_1 =(-1)^n\frac{a_0}{(x_2\cdot x_3 \cdots x_n)a_n},$$ and 
$$x_1^2 =(-1)^nx_1\frac{a_0}{(x_2\cdot x_3 \cdots x_n)a_n}.$$ So, $$\begin{align*}
x_{1}^{2} &+ x_{2}^{2} +\cdots+x_{n}^{2}=u\\
&=(-1)^nx_1\frac{a_0}{(x_2\cdot x_3 \cdots x_n)a_n} + (-1)^nx_2\frac{a_0}{(x_1\cdot x_3 \cdots x_n)a_n} \\
&\qquad +\cdots+(-1)^nx_n\frac{a_0}{(x_1\cdot x_2 \cdots x_{n-1})a_n}.
\end{align*}$$ It can be written as 
$$(-1)^n\cdot \frac{a_0}{a_n}\left(\frac{x_1}{x_2\cdot x_3 \cdots x_n} + \frac{x_2}{x_1\cdot x_3 \cdots x_n} +\cdots+ \frac{x_n}{x_1\cdot x_2 \cdots x_{n-1}}\right) = u,$$
And I'm stuck here. That's my question. How can I write $u$ in function of the coefficients (or its impossibility)? Any help will be very appreciated. I'm young, and I do not have experience with proving things. That's all. Thank you.","['algebra-precalculus', 'polynomials']"
90917,Maximizing gambling performance over the long run,"Background. We can play a game in which we can put one dollar and get out $X$ dollars, where $X$ is 2 dollars with probability $p>1/2$, or zero dollars with probability $1-p$. We also assume that different plays of this game are independent. Note that $E[X] > 1$, meaning that we have an advantage. We begin with one dollar and start playing this game, such that we play with a fraction $f\in[0,1]$ of our current fortune each time we play. Thus—and here we let $X,X_1,X_2,\ldots$ denote (independent) random variables having the distribution of our plays as described above—our initial fortune is $F_0 = 1$, our fortune after 1 play is $F_1 = 1-f+fX_1 = 1+f(X_1-1)$, and in general, it is easily calculated that our fortune after $n$ plays is
$$F_n = \prod_{i=1}^n(1+f(X_i-1)).$$ Since the plays are independent, our expected fortune after $n$ plays is
$$E[F_n] = E\bigg[ \prod_{i=1}^n(1+f(X_i-1)) \bigg] = (1+f(E[X]-1))^n.$$
Since $E[X] > 1$, it is clear that $E[F_n] \to \infty$ no matter what $f$ we choose. However, for any given $n$ we see that $E[F_n]$ is largest for $f=1$. Does this mean we should choose $f=1$? This is probably a bad idea, because in this case, the probability of going broke after $n$ or fewer plays is $1-p^n$, which approaches one as $n\to\infty$. In other words, if we choose $f=1$, we will eventually go broke for sure. (For a further explanation of this, feel free to refer to my previous question, Resolving a paradox concerning an expected value .) So what strategy should we take to maximize our long-term performance? Some authors have suggested the approach of maximizing the “exponential rate of growth.” Let me explain. Imagine that $F_n = e^{nG_n}$. Here, $G_n$ is the “exponential rate of growth” of $F_n$. We can write
$$G_n = \frac{1}{n}\log(F_n) = \frac{1}{n}\log\bigg( \prod_{i=1}^n(1+f(X_i-1)) \bigg) = \frac{1}{n} \sum_{i=1}^n \log(1+f(X_i-1)).$$
Using the law of large numbers, we find that
$$G_n \to E[\log(1+f(X-1))] \quad \text{almost surely}.$$
Now, $G := E[\log(1+f(X-1))]$ is what some authors refer to as the “exponential rate of growth” that we should aim at maximizing. Indeed, $G$ seems to be the “exponential rate of growth” at the “infinity,” in some sense. In our present case, we find that
$$G = \log(1+f)p + \log(1-f)(1-p),$$
which—interestingly—is maximized at $f=2p-1$. According to this, we have the largest exponential rate of growth if we choose $f=2p-1$, and this is the value for $f$ at which some authors suggest gamblers place their bets. Question 1. Why should I care about this? Can you give me some intuitive explanation of why my goal should be to maximize the exponential rate of growth, as opposed to maximizing $E[F_n]$ (i.e. to choose $f=1$), or choosing $f=0.99$ to keep $E[F_n]$ high while avoiding that almost sure bankruptcy? I don’t have a natural feel for what to do and why, in order to get as much growth as possible in the long run. Question 2. How can it be possible that the exponential rate of growth is maximized at $f=2p-1$, yet $E[F_n]$ is always the highest for $f=1$? That doesn’t make much sense to me. Wouldn’t you expect $E[F_n]$ to eventually become the highest at $f=2p-1$? In other words, how can I we—in the “infinity”—have the greatest growth at $f=2p-1$ but the greatest expectation value at $f=1$? Question 3. Here is a graph that shows $G$ as a function of $f$ for $p=2/3$. The maximum is indeed at $2p-1=1/3$. However, something interesting happens around $f\approx 0.618$, when the curve goes below zero. Supposedly, this is the point beyond which we are almost sure to end up with a loss, i.e. end up with less than 1 dollar. Do you understand why this is? Furthermore, it still remains a mystery to me why the curve for $E[F_n]$ wouldn’t show similarly interesting features, instead of being a monotonically increasing function of $f$.","['finance', 'infinity', 'probability']"
90923,Isomorphism of sets,"What is an isomorphism of sets? I know in general an isomorphism is a structure-preserving bijective map between two algebraic structures. But what algebraic structure does a set have? Does a function between sets needs to be anything more than bijective to be an isomorphism of sets? The reason I ask is that the term is used on PlanetMat's Finite Field page in explaining why a field $F$ of characteristic $p$ has cardinality $p^r$, where $r$ is the degree of the extension $F/ \mathbb{F}_p$. It says ""Since $F$ is an $r$-dimensional vector space over $\mathbb{F}_p$ for finite $r$, it is set isomorphic to $\mathbb{F}_p^r$ and so has cardinality $p^r$.""","['finite-fields', 'terminology', 'abstract-algebra']"
90939,Is the definite integral over a continuous function always finite?,"eg. is
$$\int_a^b{f(x)}\mathrm{d}x$$
always finite for a continuous function $f:\mathbb R\rightarrow\mathbb R$ ? If not are there any particular constraints that $f$ must obey for this to be true?","['definite-integrals', 'integration']"
90952,How do I factor a polynomial function with a degree higher than 2 without guessing numbers of $\frac{p}{q}$?,"I have an equation $f(x)=x^4+4x^3+2x^22-x+6$. In the past I was taught to factor it by getting the zeros by getting $p/q$, and start guessing zeros, and plugging them into the function. Once I got one or two, I would try to divide the function by them to get the rest. It would seem to me that there has to be a much easier way of doing this. Some kind of trick. If the equation was only something like $f(x)=x^2+5x-6$, then it would be easy. just find the number that multiplies together to equal $-6$, and adds up to equal $5$. The answer would be $(x+6)(x-1)$. Is there some trick like this for functions with a degree higher than $2$?","['factoring', 'algebra-precalculus', 'functions', 'polynomials']"
