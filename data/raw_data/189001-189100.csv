question_id,title,body,tags
3536084,"Flatness of $A=F[x_1,\dots,x_n]/\langle f_1,\dots,f_k \rangle$","This question asks for a proof of the following fact:
Let $R$ be a commutative ring and $f_1,\dots,f_k\in R[x_1,\dots,x_n]$ polynomials such that the Jacobian $J=(\partial f_{j}/\partial x_i)_{i,j}$ has total rank in every residue field $k(P)$ for $P\in\text{Spec}(R)$ Then the following $R$ -algebra is flat $$A=R[x_1,\dots,x_n]/(f_1,\dots,f_k).$$ I am not sure if I understand it correctly, so I ask: Question 1: Is it true that if we take $R=F$ a field (of characteristic zero), $k=n$ , 
  and the Jacobian of $f_1,\ldots,f_n$ is a non-zero scalar,
  then the claim says that $$A=F[x_1,\dots,x_n]/(f_1,\dots,f_n).$$ is flat as an $F$ -module? (or as an $F[x_1,\ldots,x_n]$ -module?) EDIT: Actually, what I really wish to ask is: Question 2: Is the quoted result dealing with $k \leq n$ only,
  or is it dealing with $k > n$ also? I am confused: On the one hand, no restriction on $\{k,n\}$ is mentioned in the quoted question, but on the other hand, the two references i ii in its comment seem to deal with $k \leq n$ (if I am not wrong). Examples for question 2 (see this question): (1) $f_1=x^2+y,f_2=y$ , $R=k[x]$ , $n=1$ . $\frac{k[x][y]}{\langle x^2+y,y \rangle}= \frac{k[x]}{\langle x^2 \rangle}$ is not flat over $k[x]$ , by the result quoted here .
However, the it is not possible to apply the above result (assuming that $k > n$ is ok), since the Jacobian is the one-row matrix $(1 1)$ (partial derivatives of $f_1,f_2$ with respect to $y$ ), so the rank is one (the rank is not total= not equals two). (2) $f_1=x^2+y,f_2=x$ , $R=k[x]$ , $n=1$ . $\frac{k[x][y]}{\langle x^2+y,x \rangle}= \frac{k[x,y]}{\langle x,y \rangle}=k$ .
Actually, it is not possible to apply the above result (assuming that $k > n$ is ok), since the Jacobian is the one-row matrix $(1 0)$ (partial derivatives of $f_1,f_2$ with respect to $y$ ), so the rank is one (the rank is not total= not equals two). (3)!!! $f_1=x+y^2,f_2=y+x+y^2$ , $R=k[x]$ , $n=1$ . Again, $\frac{k[x][y]}{\langle x+y^2,y+x+y^2 \rangle}= \frac{k[x,y]}{\langle x,y \rangle}=k$ . 
Here the Jacobian is the one-row matrix $(2y, 1+2y)$ (partial derivatives of $f_1,f_2$ with respect to $y$ ), and the rank is total (two).
It seems that this example shows that it is NOT possible to take $k > n$ , since $k$ is not a flat $k[x]$ -module, by the flatness criterion presented in the first answer to this question, with the action of $k[x]$ on $k$ defined as follows: $x \lambda=0$ , for all $\lambda \in k$ , and scalars are computed as ususal, in $k$ . Remarks: (1) This MO question seems relevant.
(2) This paper seems relevant, but it deals with $n=1$ and instead of taking $(f_1)$ it takes $I$ and shows that it must be a principal ideal. (We can take $R=k[y]$ and then deal with $k[y][x]$ . But it is not possible to apply the stronger results, since $R$ is required to be quasi-local). Thank you very much!","['jacobian', 'algebraic-geometry', 'flatness', 'commutative-algebra']"
3536114,Basic Burgers Equation Energy Estimate,"This is a super simple estimate and I have been banging my head against the wall that I can't figure it out. I am trying to estimate the $||\cdot||_{H^k}$ norm of $u_t+uu_x=0$ and can't figure out the nonlinear term. I'm reading along with a paper, my goal is $\frac{d}{dt}||\partial_x^ku||_{L^2}^2\lesssim||u_x||_{L^\infty}||\partial_x^k u||_{L^2}^2$ . Is the following valid for estimating the nonlinear term (assuming $u\in C_0^\infty(\textbf{R})$ )? \begin{align*}
\left|\int_{\mathbf{R}}\,\partial_x^k{u}\partial_x^k(uu_x)\,dx\right|
  &= \left|(-1)^k\int_{\mathbf{R}}\,(uu_x)\partial_x^{2k}(u)\,dx\right| \\
&= \left|\int_{\mathbf{R}}\,(uu_x)\partial_x^{2k}(u)\,dx\right| \\
  &\leqslant
    ||u_x||_{L^\infty}\left|\int_{\mathbf{R}}\,u\partial_x^{2k}u\,dx
    \right| \\
&=
    ||u_x||_{L^\infty}\left|(-1)^k\int_{\mathbf{R}}\,(\partial_x^{k}u)^2\,dx
    \right| \\
  &=||u_x||_{L^\infty}||\partial_x^ku||_{L^2}^2
\end{align*} Seems like cheating and I am wondering if there is an inner product identity I am unaware of which makes this smoother. I am doubting myself because I thought I had it earlier and realized that I had made a pretty bad mistake. Thanks!","['inequality', 'analysis', 'partial-differential-equations']"
3536153,Frame bundle is parallelizable - Kobayashi,"Let $M$ be a Riemannian manifold, and let $L(M)$ be the associated frame bundle. At the end of page 40 of Kobayashi's book , as I understand, it is stated that: There exsits $n^2$ connection forms $\omega_j^i$ on $L(M)$ which are nowhere vanishing. And hence together with the $n$ canonical/solder forms $\theta_i$ , they give $L(M)$ an absolute parallelism. I could prove that the $n$ solder forms are nowhere vanishing. My question is, what are the Kobayashi's $n^2$ connection forms on $L(M)$ ? Are they related to the Levi-Civita connection forms on $M$ ? (which can be $0$ everywhere if I choose a flat manifold?). And how do we prove that they are nowhere vanishing (if it is not direct from the definition).",['differential-geometry']
3536162,Cardinality of the set of all mathematical statements,"Let A = {x|x is a mathematical statement}. What is the cardinality of A? This was a question my friend asked me yesterday. At first, I thought A is a countable set because one can count the number of statements. Namely, I can establish a bijection between A and set of natural numbers, by assigning a unique natural number to each statement. However, my friend then asked ""How about having a math statement such that x = y, while x and y are arbitrary element of real number set? Then, the total number of mathematical statement would be equal to the cardinality of the power set of real number set?"" After listening to his argument, I became completely puzzled. Can anyone verify whether one of us have a correct reasoning? Or both of us are wrong?","['elementary-set-theory', 'real-numbers', 'cardinals']"
3536179,What Function has these 4 Properties?,"Two questions: 1) Find a function $g$ so that: The domain of $g$ is at least $(0, \infty)$ $g$ is continuous on its domain $g$ is concave up on its domain $\lim_{x\to\infty} g(x) = -\infty$ I'm confused about how properties 3 and 4 can happen at the same time? Can somebody help with what function this might be? 2) Find a function $h$ so that The domain of $h$ is $(-\infty, \infty)$ $h$ has no max $h$ has no min The sup of $h$ on its domain is 2 The inf of $h$ on its domain is 0 Not, sure how to deal with having no max and min at the same time.","['calculus', 'functions']"
3536201,"How do we prove that $\max\{x_1 + x_2+ \ldots + x_n - n + 1,0\} \leq C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\}$?","I am interested in proving the generalized version of the Fréchet-Hoeffding inequality. Precisely speaking, given a $n$ -copula $C:[0,1]^{n}\rightarrow[0,1]$ , how do we demonstrate that $$
\max\{x_1 + x_2 + \ldots + x_n - n + 1, 0\} \leq C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\}
$$ MY ATTEMPT Since $\textbf{x} = (x_1,x_2,\ldots,x_n) \leq (1,1,\ldots,1)$ , I have been able to prove the upper bound inequality as next \begin{align*}
C(\textbf{x}) & \leq C(x_1,x_2,\ldots,x_{n-1},1)\\
& \leq C(x_1,x_2,\ldots,1,1) \leq \ldots\\
& \leq C(x_1,1,\ldots,1,1) = x_1
\end{align*} because copulas are non-decreasing in each argument and have uniform margins. Once the same reasoning applies to each coordinate, the result $C(\textbf{x}) \leq \min\{x_1,x_2,\ldots,x_n\}$ follows. But what about the first inequality? Any help is appreciated.","['statistics', 'analysis', 'copula', 'probability']"
3536211,What does this equal to???,"From Rosen's Discrete Mathematics and Its Applications, 3ed, chapter 6 p. 390: There seems to be something missing at the place underlined in red.  Could this be ∅ (null symbol)?",['discrete-mathematics']
3536225,Lie algebra of a linear algebraic group acts on functions by derivations: what does this mean?,"Let $G$ be a linear algebraic group over an algebraically closed field of characteristic zero.  Let $X$ be an affine variety on which $G$ acts.  Then $G$ naturally acts on the coordinate ring $\mathcal O_X(X)$ by the formula $g.f(x) = f(g^{-1}.x)$ .  I often see the claim ""The Lie algebra $\mathfrak g$ of $G$ also acts on $\mathcal O_X(X)$ by derivations.""  What exactly does this mean? For example, suppose we take $X = G$ , with $G$ acting by conjugation.  If $\xi \in \mathfrak g$ , and $f$ is a regular function on $G$ , what would $\xi.f$ be? I'm a little more familiar with the case of real Lie groups.  If $G$ was a smooth Lie group with an action on a smooth manifold $X$ , and $f$ was a smooth real valued function on $X$ , then I would expect $\xi.f$ would be $$\xi.f(x) = \lim\limits_{t \to 0} \frac{f(\exp(t \xi).x )-f(x)}{t}$$","['algebraic-geometry', 'algebraic-groups', 'differential-geometry']"
3536245,Where does this conclusion come from?,"From Rosen's Discrete Mathematics and Its Applications, 3ed, chapter 6 p. 394: The part of concern is underlined in red.  How did they reach that conclusion?","['combinatorics', 'discrete-mathematics']"
3536270,"If $A, B$ are positive semi-definite, then $Tr(AB) = 0$ iff $AB = 0.$","I am trying to prove the statement above, and should note that I am new to linear algebra, especially matrices. Here is my attempt, which has been inspired by this post and Wikipedia readings: If $AB = 0,$ $Tr(AB) = 0$ trivially. Now suppose $Tr(AB) = 0$ . $$ Tr(AB) = Tr(BA) \\
= Tr(B^{1/2}B^{1/2}A) \\
= Tr(B^{1/2}AB^{1/2}) \\
= Tr(B^{1/2}A^{1/2}A^{1/2}B^{1/2}) \\
= Tr(A^{1/2}B^{1/2}A^{1/2}B^{1/2}).$$ The first equality holds by the commutativity of trace, the 2nd since $B$ is PSD $\implies B^{1/2}$ exists, similarly for A. The last equality holds since we can consider $B^{1/2}A^{1/2}A^{1/2}B^{1/2}$ as the product of three symmetric matrices, and thus can permute them however we want. But at this point, I am stuck. Maybe we can bring in the initial assumption now, but I'm not sure how it fits in exactly. I'd appreciate any help/clarification!","['positive-semidefinite', 'proof-explanation', 'trace', 'matrices', 'linear-algebra']"
3536282,"Calculate $\int_{0}^{3}\sqrt{4-x^2}\,dx$ using a Riemann sum","What is the Riemann intergral of $\sqrt{4-x^2}$ from $0$ to $3$ ? I tried to write down the Riemann sum $\sum_{i=1}^n\sqrt{4-\frac{(3i)^2}{n^2}}\frac{3}{n}$ . Then I tried to take limit as $n \to \infty$ , but I don't know how to evaluate it. I don't know what to do with the square root.","['integration', 'real-analysis', 'calculus', 'sequences-and-series', 'riemann-sum']"
3536332,Powers modulo higher residues,"Say $p$ is an odd prime number, $k$ a positive integer and $p^{\gamma + 1} || k$ . I would like to prove the following result: If $y \in \mathbf{Z}$ is a $k$ -th power modulo $p^\gamma$ , then it is also a $k$ -th power modulo $p^t$ for any $t \geqslant \gamma$ . I don't know how standard this fact is. Stated like this, it seems to be a rather simple fact. However, I do not find any simple proof for this fact, and I try to write below the only thing I have in mind to justify it properly. Any comment on the proof or any proposal for a more elegant argument is welcome. The proof is essentially working on rephrasing the sentence "" $y$ is a $k$ -th power modulo $n$ "". Let $n = p^\gamma$ in this paragraph. Since $p\geqslant 3$ , we know that $(\mathbf{Z}/n\mathbf{Z})^\times$ is cyclic, say generated by the element $x$ . Thus, the element $y \in (\mathbf{Z}/n\mathbf{Z})^\times = \langle x \rangle$ can be written $y=x^a$ for a certain $a \geqslant 0$ . Moreover, we assumed that $y$ is a $k$ -th power modulo $p^\gamma$ , that is to say $y = (x^b)^k = x^{kb}$ for a certain $b \geqslant 0$ . So that we get $x^a = x^{kb}$ , that is finally $x^{a-kb} = 1$ . That is possible if and only if $\phi(n) \mid a - kb$ . By Bezout identity, this is equivalent to $(\phi(n), k) \mid a$ . Assume $n = p^t$ for a certain $t\geqslant \gamma$ . We have $\phi(n) = p^{t-1}(p-1)$ and $(\mathbf{Z}/p^t \mathbf{Z})^\times = \langle x \rangle$ for a certain $x \in \mathbf{Z}/p^t\mathbf{Z}$ . Finally, $y=x^a$ is a $k$ -th power if and only if $(p^{t-1}(p-1), k) \mid a$ . By definition, $p^{\gamma - 1} \mid k$ , so that we also have \begin{equation}
(p^{t-1}(p-1), k) \mid a \Longleftrightarrow (p^{t-\gamma}(p-1), kp^{1-\gamma}) \mid a p^{1-\gamma}.
\end{equation} Assume $n = p^\gamma$ . We have $\phi(n) = p^{\gamma-1}(p-1)$ and $(\mathbf{Z}/p^\gamma \mathbf{Z})^\times = \langle x^{p^{t-\gamma}} \rangle$ for a certain $x \in \mathbf{Z}/p^t\mathbf{Z}$ . Thus, $y=x^{ap^{t-\gamma}}$ is a $k$ -th power if and only if $(p^{\gamma-1}(p-1), k) \mid a p^{t}$ so that \begin{equation}
(p^{\gamma-1}(p-1), k) \mid ap^{t-\gamma} \Longleftrightarrow (p-1, kp^{1-\gamma}) \mid ap^{1-\gamma}.
\end{equation} Finally, for all $t \geqslant \gamma$ , I would like to say that the first relation is implied by the second, so that any $k$ -th power modulo $p^\gamma$ is also a $k$ -th power modulo $p^t$ . Thanks in advance! This questions comes from my misunderstanding of the following statement, from Vaughan:","['number-theory', 'arithmetic']"
3536408,The number of the subset(What point do I have a mistake)[easy question],"$Q)$ Let the $U = \{1,2,3,4,5,...,10\}$ and its subset $A, B$ Find the number of the ordered pair $(A,B)$ satisfying the all the (1) and (2) $(1)$ $\Vert A  \Vert \leq \Vert B  \Vert$ $(2)$ $\Vert A  \cap B \Vert = 4$ and $\Vert A  \cup B \Vert = U$ The answer is at the bottom of this post. As you might see, This is a really easy and elementary question in my lecture's note. He doesn't add his solution in his note. Plus I don't know why my answer is false. My attempt) 
Deciding the element for the $\Vert A  \cap B \Vert = 4$ first, So ${10 \choose 4}$ And there are 4 possibilities that $(\Vert A-(A\cap B)  \Vert , \Vert B-(A\cap B)  \Vert)$ $\in \{(6,0),(5,1),(4,2),(3,3)\} $ So only we have to do just choosing the element in $B$ , so there are ${6 \choose 0} + {6 \choose 1} + {6 \choose 2}+{6 \choose 3}$ Hence the my answer is ${10 \choose 4} \times ({6 \choose 0} + {6 \choose 1} + {6 \choose 2}+{6 \choose 3})$ = $8820$ But the answer was 19320. Still I don't know what point I've missed. I believe that the lecture's answer is incorret.","['combinatorics', 'discrete-mathematics']"
3536410,How to solve this non-linear 1st order differential equation?,"I am trying to solve the following first order differential equation: $$ g'(R)=-2 \sqrt{R^2-g(R)}+2 R$$ By direct substitution it can be verified that an obvious solution is $$g(R)=R^2.$$ However, when doing the transformation $y(R)=R^2-g(R)$ , we get $$y'(R)=2 \sqrt{y(R)} $$ which is separable and gives (for some constant $C$ ): $$\int \frac{dy}{2y^{1/2}}=R+C $$ or $$y^{1/2}= R+C,\\
y=(R+C)^2.$$ Remembering that $y(R)=R^2-g(R)$ we finally get $$ g(R)= -C^2-2C R .$$ I also tried solving it with Mathematica , but it also misses the other solution. So, my question is where did the obvious solution $g(R)=R^2$ go?","['solution-verification', 'ordinary-differential-equations']"
3536412,How to show weak convergence of $\mathrm{sign}(\sin(nx))$ as $n \to \infty$?,"How to show weak convergence of $\mathrm{sign}(\sin(nx)) \rightharpoonup 0$ in $L^2(0,2\pi)$ (or some $L^p$ space) as $n \to \infty$ ? Without the sign function there, the proof uses I think Parseval's identity. I don't know how to tackle this.","['functional-analysis', 'weak-convergence']"
3536417,"Does the following limit exist? $\lim \limits_{(x,y) \to (0,0)} \left(\frac{(x^4+y^4) \sin(\frac{1}{x})}{x^2+y^2}\right)$","I'm having some trouble solving the following limit: $\lim \limits_{(x,y) \to (0,0)} \left(\frac{(x^4+y^4) \sin(\frac{1}{x})}{x^2+y^2}\right)$ Wolfram is suggesting that it doesn't exist. https://www.wolframalpha.com/input/?i=limit%5B%28x%5E4%2By%5E4%29sin%281%2Fx%29%2F%28x%5E2%2By%5E2%29%2C+x+to+0%2C+y+to+0%5D Can you point out where I am making a mistake? $0 \le \lvert \frac{(x^4+y^4) \sin(\frac{1}{x})}{x^2+y^2} \rvert \le \lvert \frac{x^4+y^4}{x^2+y^2} \rvert \le \lvert \frac{x^4+y^4+2x^2y^2}{x^2+y^2} \rvert = \lvert x^2+y^2 \rvert \to 0 $ as $(x,y) \to (0,0)$ By the squeeze theorem I get that the limit is $0$ . Any help is appreciated c:","['limits', 'real-analysis']"
3536477,Limit of $\lim_{x\to \infty} \sqrt[3]{x^3+2x}-\sqrt{x^2-2x}$,$$\lim_{x\to \infty} \sqrt[3]{x^3+2x}-\sqrt{x^2-2x}$$ I tried to used $(a^3-b^3)=(a-b)(a^2+ab+b^2)$ but it did not worked out so I tried to use the squeeze theorem. $$0=\sqrt[3]{x^3}-\sqrt{x^2}\leq \sqrt[3]{x^3+2x}-\sqrt{x^2-2x}\leq\sqrt[3]{8x^3}-\sqrt{4x^2}=2-2=0$$ But on the right hand I have inrcrased $\sqrt{x^2-2x}$ rather then deceased Another attempt: $$\lim_{x\to \infty} \sqrt[3]{x^3+2x}-\sqrt{x^2-2x}=\lim_{x\to \infty} \sqrt[3]{x^3(1+\frac{2}{x^2})}-\sqrt{x^2(1-\frac{2}{x})}=\\=\lim_{x\to \infty} x\sqrt[3]{(1+\frac{2}{x^2})}-x\sqrt{(1-\frac{2}{x})}=\lim_{x\to \infty} x[\sqrt[3]{(1+\frac{2}{x^2})}-\sqrt{(1-\frac{2}{x})}]$$,"['limits', 'calculus']"
3536486,Find a $p $ such that $q \mapsto q^Tg + 2 p^T S q + q^T S q$ is the constant zero map.,"I have the following problem: given the map $$p \mapsto p^T g + p^T S p$$ where the operation in the first term of the sum is the dot product, and in the second matrix multiplication, I would like to find its critical points. [The context for the interested is that $g$ and $S $ represents the gradient and the Hessian, respectively, of a twice differentiable map from $\mathbb R^n$ to $\mathbb R$ .] My approach is to differentiate the map w.r.t. $p $ . Then, assuming that $S $ is symmetric, I get that for each $p$ the derivative is the map $$q \mapsto q^Tg + 2 p^T S q + q^T S q$$ Now how can I find a $p $ such that this represents the constant zero function? Thanks in advance! EDIT Here is how I tried to calculate the derivative of the function at a
given point $p $ To begin with, my definition of a derivative of a map $m$ from $\mathbb R^n$ to $\mathbb R$ at a point $p$ is a linear map $A$ from $\mathbb R^n $ to $\mathbb R$ such that $$\lim_{h \to 0 } \frac{|m(p+h) - m(p) - Ah|}{|h|}=0$$ My approach is to differentiate the two maps $p \mapsto p^Tg $ and $p
 \mapsto p^TS p$ individually and then add those two functions.  And we
differentiate them by finding a function that ""fits"" the definition
given above. Since the map $p \mapsto p ^T g$ is linear it is immediate that $$\lim _{h \to 0 } \frac {|((p+h)^T g - p^T g - h^T g | } {|h | } =
 \lim_{h \to 0}\frac{0}{|h|} $$ and thus that the map is its own derivative. For the second term I assume that $S$ is symmetric [a similar
derivation would work otherwise]. Then since $$(p+h)^T S (p+h) = p^T S p + 2 p^T S h + h^T S h$$ we have simarily as above that $$\lim_{h \to 0 } \frac{|(p+h)^T S (p+h) - p^TS p - (2 p^T S h + h^T S
 h)| }{|h|}= \lim_{h \to 0 } \frac{0}{|h|}=0$$ and so the mat $q \mapsto p^T S q + q^T S q$ would be a derivative at
the point $p$ of the map $q \mapsto q^T S q$ . Then combining those two derivatives we get the map $$q \mapsto q^Tg + 2 p^T S q + q^T S q$$ is the derivative of $$q \mapsto q^T g + q^T S q$$ at the point $p$ . SECOND EDIT I found the error I made above. Since the map $$q \mapsto q^T S q $$ isn't linear we cannot have it in the derivative of the function $$q \mapsto q^T S q $$ as this would make the map I stated as the derivative at the point $p $ , namely $q \mapsto p^T S q + q^T S q$ , nonlinear. Insted we simply use that $\lim _{h \to 0 } h^T S h = 0$ (see here) and thus we have $$\lim_{h \to 0 } \frac{|(p+h)^T S (p+h) - p^TS p - 2 p^T S h | }{|h|}= \lim_{h \to 0 } \frac{|h^T S h|}{|h|}=0$$","['multivariable-calculus', 'derivatives']"
3536506,Verify (ir)reducibility of systems of polynomials arising from representation problems over polynomial ring,"Let $K$ be a field. Often, the problem of solving an equation over the polynomial ring $K[X]$ can be translated into solving a system of equations over $K$ . For example, consider the following property a polynomial $f \in K[X]$ of degree $2m$ can have. There exist $f_1, f_2, f_3 \in K[X]$ of degree at most $m$ such that $f = f_1^2 + f_2^2 + f_3^2$ . Writing $f_j = \sum_{i=0}^m A_i^{(j)}X^i$ for each $j \in \lbrace 1, 2, 3 \rbrace$ , the above property can be translated into the solvability over $K$ of a system of $2m+1$ equations in the $3m+3$ variables $(A_i^{(j)})_{i, j}$ . I am interested in whether this system is (absolutely) irreducible. That is, if we assume $K$ is algebraically closed, whether the equations defining this system generate a prime ideal of the polynomial ring in the variables $(A_i^{(j)})_{i, j}$ . How could one approach this problem?","['systems-of-equations', 'affine-varieties', 'algebraic-geometry', 'abstract-algebra', 'polynomials']"
3536511,$ \sin{x}\ +\ \frac{1}{2}\sin{2x}\ +\ \frac{1}{3}\sin{3x}\ +\ \frac{1}{4}\sin{4x}\ =\ \frac{2}{3}\left(\cos{x}+1\right)\left(\sin^5x\ +\ 4\right)$,"SORRY IF MY TITTLE IS UNCLEAR WITH ONLY MATH FUNCTIONS. IT'S MORE THAN 150 CHARACTERS This is my math problem $$ \sin {x}\ +\ \frac{1}{2}\sin {2x}\ +\ \frac{1}{3}\sin {3x}\ +\ \frac{1}{4}\sin {4x}\ =\ \frac{2}{3}\left(\cos {x}+1\right)\left(\sin ^5x\ +\ 4\right) \left(*\right)
$$ This is my effort $$ \left(*\right) <=> 12\sin {x\left(1+\cos x\right)\ +\ 12\sin {x}\ -\ 16\sin ^3x\ +\ 12\sin {\left(x\right)\cos {\left(x\right)}\cos {\left(2x\right)}}}\ =\ 8\left(\cos x\ +\ 1\right)\left(\sin ^5x\ +\ 4\right)
$$ $$   <=> 12\sin {x\left(1+\cos x\right)\ + 4\sin {x\left(2\cos {\left(2x\right)\left(1+\cos {x}\right)\\ +\ \left(1+\cos {x}\right)\left(2\cos ^2x\ -\ 2\cos {x\ +\ 1}\right)}\right)}}\ =\ 8\left(\cos x\ +\ 1\right)\left(\sin ^5x\ +\ 4\right) 
$$ $$ <=> 4\sin {x\left(1+\cos {x}\right)\left(6\cos ^2x\ -\ 2\cos {x\ +\ 2}\right)\ =\ 8\left(\cos x\ +\ 1\right)\left(\sin ^5x\ +\ 4\right)}
$$ Now $$\cos {x} = -1
$$ or $$ 6\sin {x}\cos ^2x\ -\ 2\cos {x}\sin {x}\ +\ 2\sin {x}\ -\ 2\sin ^5x\ -\ 8\ =\ 0 
$$ To here I tried many ways like converting all to \sin , group somes together but it didn't work. Please give me some HINTS","['trigonometry', 'proof-writing', 'a.m.-g.m.-inequality']"
3536521,What is the difference between these two theorems?,"From Rosen's Discrete Mathematics and Its Applications, 3ed, chapter 6 p. 428-429: It seems to me that both of them are talking about partitioning a set of n elements into k subsets.  It seems like it does not matter if the objects are distinguishable or not.  What exactly is different?","['set-partition', 'combinations', 'combinatorics', 'discrete-mathematics']"
3536529,"$f(G)$ of $f(x,y):= \begin{pmatrix} e^x \cos y \\ e^x \sin y \end{pmatrix} $ with $G = \mathbb{R} \times (-\pi, \pi)$","Let $G \subset \mathbb{R^2}$ given by $$f(x,y):= \begin{pmatrix} e^x \cos y \\ e^x \sin y \end{pmatrix} $$ Let $G = \mathbb{R} \times (-\pi, \pi)$ . To get $f(G)$ can we just put the values in the function? Meaning: $$f(G)= \begin{pmatrix} e^{-\pi} \cos (-\pi) \\ e^\pi \sin \pi  \end{pmatrix}  = \begin{pmatrix} -0.0432 \\ 0  \end{pmatrix} $$ And how can one prove that $f$ has a locally differentiable inverse function in every point $(x,y)^T$ ? Is there a formula for the derivative of that inverse function?","['proof-writing', 'inverse-function', 'analysis', 'functions', 'transpose']"
3536534,Conjecture about a continued fraction,"Conjecture: $$\large 2^{n-1}+\frac{1}{2+\cfrac{1}{2^{n}-1+\cfrac{1}{2+\cfrac{1}{2^{n}-1+\cfrac{1}{2+\ddots}}}}}=\frac{1+\sqrt{3a_n}}{2}\tag*{[1]}$$ such that $a_n=4a_{n-1}+1$ and $a_0=0$ . $\quad(n\geqslant 1)$ Ex. If $n=1$ , then $a_n=4a_0+1=4\times 0 + 1 = 1$ . $$\therefore 1+\frac{1}{2+\cfrac{1}{1+\cfrac{1}{2+\cfrac{1}{1+\cfrac{1}{2+\ddots}}}}}=\frac{1+\sqrt{3}}{2}\tag*{[2]}$$ This can be proven using the formula $x=a+\dfrac{1}{b+\dfrac{1}{x}}=a+\dfrac{1}{b+\dfrac{1}{a+\dfrac{1}{b+\dfrac{1}{a+\ddots}}}}$ Solving for $x$ results in a quadratic equation for which $x=\dfrac12\left\{a+\sqrt{a\left(a+\dfrac4b\right)}\right\}$ . Substituting $a=1$ and $b=2$ yields $[2]$ as required. Problem is, I am unsure on how to (dis)prove this conjecture given the recursive sequence involved. How do I appropriately go about this? Any suggestions or counter-examples? Thanks :)","['conjectures', 'number-theory', 'proof-writing', 'sequences-and-series', 'continued-fractions']"
3536567,Sum of prime generating numbers.,"I was trying to solve a project euler problem which goes like : Find the sum of all positive integers $n$ not exceeding $100,000,000$ such that for every divisor $d$ of $n$ , $d+\frac nd$ is prime. So this is what I did. if $d + \frac nd$ is prime and $1$ is always a divisor of $n$ thus for $d=1$ , this should be true. Thus we'll get $1+n$ should be prime. Meaning $n$ is even. Now if $n$ is even then $2$ becomes a divisor of $n$ . Thus $\left(2+\frac n2\right)$ should also be prime which means $\frac n2$ should be odd and so we get $n$ should not be a multiple of $4$ . So from above what we have is $n+1$ is prime and $n$ is not a multiple of $4$ . I couldn't find any more constraints on $n$ . How do I proceed further? I have a feeling that these are all the constraints I need on $n$ but I'm not able to prove this. Edit: As peter in comments suggested $n$ also needs to be square-free. So we have another condition on $n$ .","['number-theory', 'prime-numbers']"
3536622,"Quadratic function with roots in $[0,1]$. Prove that $f(0) \geq \frac49$ or $f(1) \geq \frac49$","Let $a,b$ in $[0,1]$ be such that the polynomial $f(x) = (x-a)(x-b)$ satisfies $f(\tfrac12) \geq \frac1{36}$ . I have found a quite complicated proof of the following inequality using calculus: $$f(0) \geq \frac49 \quad\text{or}\quad f(1) \geq \frac49.$$ Can you find a simple argument? (with geometric flavour if possible)","['real-numbers', 'conic-sections', 'geometry', 'inequality', 'quadratics']"
3536711,Prove that $\int_1^a \frac{T_n(x) T_n(x/a)}{\sqrt{a^2 - x^2} \sqrt{x^2 - 1^2}} \frac{a}{x} \mathrm{d}x = \frac{\pi}{2}$,"In the paper, Representation of a Function by Its Line Integrals, with Some Radiological Applications , A. M. Cormack, Journal of Applied Physics 34, 2722 (1963), an integral identity is expressed which can be reduced to: $$I_n(a) = \int_1^a \frac{T_n(x)  T_n(x/a)}{\sqrt{a^2 - x^2} \sqrt{x^2 - 1^2}}  \frac{a}{x} \mathrm{d}x = \frac{\pi}{2}$$ where $T_n(x)$ is the $n^\text{th}$ order Chebyshev polynomial of the first kind. I'm not quite sure where this result comes from, and was looking to see how it could be derived. The paper notes that it can be shown that $$I_{n+1} = I_{n-1}, \quad I_0 = I_1 = \frac{\pi}{2}$$ from which then it is apparent that $I_n(a) = \frac{\pi}{2}$ However, I'm not sure where the $I_{n+1} = I_{n-1}$ comes from. Attempting to substitute the recurrence relationship $$T_n(x) = \frac{T_{n-1}(x) + T_{n+1}(x)}{2x}$$ seemed like a good start, but ends up converting the integral to a form that's different from $I_{n-1}(a)$ and $I_{n+1}(a)$ , and also generates some unwanted cross terms. Could anyone suggest a push in the right direction?","['integration', 'proof-explanation', 'definite-integrals', 'chebyshev-polynomials']"
3536888,Large subgroups of Symmetric Group,"Let $n \geq 5$ . It is easy to prove that if $H \leqslant S_n$ has index $\leq n$ , then $H$ is $A_n$ or $S_{n-1}$ . So my question: can this be improved to $n^2$ ?
I mean, if $[S_n:H] \leq n^2$ , is it true that $H$ is one among $A_n$ , $S_{n-1}$ , $A_{n-1}$ , $S_{n-2}$ , $S_{n-2} \times S_2$ ?","['symmetric-groups', 'group-theory', 'finite-groups', 'extremal-combinatorics']"
3536937,"In ""Functional Analysis,"" is the word ""Functional"" an adjective, or a noun?","Does 'functional' mean ""relating to functions"" or ""a mapping from a space to its scalars""?","['soft-question', 'functional-analysis']"
3537006,What is the mistake when I write down the class equation?,"Let $(G,\cdot)$ be a finite group with $n$ elements which has a trivial center. If we consider $G=\{e, x_1, x_2, ..., x_{n-1} \}$ , then from the class equation we have that $$n=1+ \sum_{k=1}^{n-1} [G:C(x_k)].\tag{1}$$ By Lagrange's theorem we have that $n=|C(x_k)|\cdot [G:C(x_k)], \forall k=\overline{1,n-1}$ , so $(1)$ rewrites as $$n=1+\sum_{k=1}^{n-1}\frac{n}{|C(x_k)|}.\tag{2}$$ If we let $M=\max\{|C(x_k)| | k=\overline{1,n-1}\}$ (this is possible since these sets are finitee), we have that $\frac{n}{|C(x_k)|}\ge  \frac{n}{M}$ , so $(2)$ implies that $$n-1\ge \frac{n(n-1)}{M}\iff M\ge n\tag{3}$$ and since $M\le n$ , we obtain that $M=n$ , which contradicts the fact that $Z(G)=\{e\}$ . Where did I go wrong?","['group-theory', 'abstract-algebra', 'solution-verification']"
3537052,Bound the size of the union of intersecting family,"Let $F \subset 2^{[n]}$ , where $[n] = \{ 1, 2, \dots , n \}$ . $F$ is an intersecting family if $\forall A,B \in F, A \cap B \ne \emptyset$ . If $F_{i} \subset 2^{[n]} : i \in [t]$ are intersecting families, show that $\left| \cup_{i \in [t]} F_{i} \right| \leq 2^{n} - 2^{n-t}$ . I was thinking   that this bound implies that if the union were greater, then a set and its complement must be contained in the union but I dont know how to proceed.",['combinatorics']
3537073,"Help with proof by induction, please! I may not be understanding how to work with factorials.","Prove that for all integers $n \ge 1, 1\cdot1! + 2\cdot2! + 3\cdot3! + \cdots + n\cdot n! = (n+1)! - 1$ . OK, so I verified base case $n = 1: 2! - 1 = 1$ I assumed that for all $k \ge n, P(k) = (k+1)! - 1$ I am unsure how to prove true for $P(k+1)$ , though I understand that the first step is to replace all $k$ values with $k+1$ which yields $$1\cdot1! + 2\cdot2! + 3\cdot3! + \cdots + k!\cdot k! + (k+1\cdot k+1)! = (k+2)! - 1$$ What next?","['algebra-precalculus', 'induction']"
3537132,conditions for Product of convex and concave function to be concave,"This has been asked (in a a way) here , but I don't understand how the accepted answer addresses this. It links a theorem and says that the theorem gives conditions, but I don't see how, so perhaps I am simply not understanding how to apply the theorem. Anyway, to restate the question, suppose I have two functions, $f(x),g(x)$ , and $f(x)$ is convex and $g(x)$ is concave. What are some
  conditions that will guarantee that $f(x)g(x)$ is concave? My thoughts: If I want $f(x)g(x)$ to be concave, then I need $-f(x) g(x)$ to be convex. But $-f(x)g(x) = f(x)\times (-g(x))$ , and $-g(x)$ is convex, so now I have the product of two convex functions. Then do I just apply the results of the theorem here to this? Is it possible to relax the condition that both convex functions be
  positive? For example, $Log(x+1)*\frac{5-x}{5}$ is concave from 0 to 5, and $Log(x+1)$ is concave and $\frac{5-x}{5}$ is convex (granted it is also concave)$ Perhaps this suggests that Log concavity might be of use? Maybe if $f$ is Log-concave and $g$ is log-convex their product will be concave?","['convex-optimization', 'functions', 'convex-analysis']"
3537152,Dudley's integral inequality: tail bound,"This is problem 8.1.7 in Vershynin's High Dimensional Probability book. Let $(X_t)_{t\in T}$ be a random process indexed by a metric space $(T,d)$ with sub-gaussian increments(i.e. $||X_t-X_s||_{\psi_2} \leq Kd(s,t)$ for all $s,t\in T$ ). Then for every $u\geq 0$ , the event $$ \sup_{t,s\in T} |X_t-X_s| \leq CK \left( \int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \right)$$ with probability $1-2\exp(u^2)$ where $C$ is just some absolute constant. If we assume $T$ is second countable then we may prove it just for the case when $T$ is finite by applying dominated convergence theorem and apply a limit argument. Furthermore, the tail bound is trivially true when $T$ is unbounded so assume $\text{diam}(T)<\infty$ . With these assumptions, lets move on to the issues I'm having proving the result. To prove this result we are given the following hints. Define $\epsilon_k=2^{-k}$ and $T_k$ is an $\epsilon_k$ covering of with cardinality $|T_k|=\mathcal{N}(T,d,\epsilon_k)$ . Then if $t\in T$ we define $\pi_k(t)\in T_k$ to be the closest element in $T_k$ to $t_0$ for some fixed element $t_0$ . In particular we can show that $$\sup_{t\in T} (X_{\pi_k(t)}-X_{\pi_{k-1}(t)}) \leq CK\epsilon_{k-1}(\sqrt{\log|T_k|}+z)$$ with probability at least $1-2\exp(-z^2)$ . So proving this was fairly straight forward.
The next hint was to prove a bound for $$ \sup_{t\in T} |X_t-X_{t_0}| \leq CK \left( \int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \right)$$ using the previous result. We note that we can write $$\int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) = \int_0^{\text{diam}(T)}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon)} + u \right) d\epsilon$$ Since $T$ is finite there exists a $\kappa_0, K_0 \in \mathbb{Z}$ such that $T_{\kappa_0} = \{t_0\}$ and $T_{K_0} = T$ . So we can write $$\int_0^{\text{diam}(T)}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon)} + u \right) d\epsilon \sim \sum_{k\geq{\kappa_0+1}} \epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u \right) $$ Next we form the chain and note that $\pi_{k_0}(t) = t_0$ and $\pi_{K_0}(t)=t$ so we have $$\sup_{t\in T}|X_t-X_{t_0}|\leq \sum_{k=\kappa_0+1}^{K_0} \sup_{t\in T}|X_{\pi_k(t)}-X_{\pi_{k-1}(t)}|$$ If we let $$\sup_{t\in T}|X_t-X_{t_0}|\geq CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + z_k \right)$$ be our event $E$ then from a union bound we have $$P(E) \leq 2\sum_{k=\kappa_0+1}^{K_0}\exp(-z_k^2)$$ Vershynin then suggests we choose $z_k=u+\sqrt{k-\kappa_0}$ . If we plug this into our sum we get $$2\sum_{k=\kappa_0+1}^{K_0}\exp(-z_k^2) \leq \exp(-u^2)$$ So, in particular, we have that by another union bound that $$ \sup_{s,t\in T}|X_s-X_{t}|\geq 2CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u + \sqrt{k-\kappa_0} \right)$$ Has probability less than $2\exp(-u^2)$ Which is almost a larger event than the original one were proving. My only issue is how to absorb the additional term $\sum_{k=\kappa_0+1}^{K_0} \epsilon_{k-1} \sqrt{k-\kappa_0}$ . If I can deal with that I have what I wanted to prove because $$  2CK\int_0^\infty \sqrt{\log\mathcal{N}(T,d,\epsilon)} d\epsilon + u \text{diam}(T) \geq C' 2CK\sum_{k=\kappa_0+1}^{K_0}\epsilon_{k-1}\left( \sqrt{\log\mathcal{N}(T,d,\epsilon_k)} + u \right)$$","['statistics', 'probability-theory', 'probability', 'inequality']"
3537165,A question about integration by parts in $\mathbb{R}^n$,"Let $h \in L^2(\mu)$ and $\mu = \rho(x)dx$ , where $dx$ is Lebesgue measure and $\rho(x)$ is $C^1$ . Also, $b(x) = (b_1(x), \cdots, b_n(x))$ is also a $C^1$ function on $\mathbb{R}^n$ . Then, does the following integration by parts hold? $$\int_{\mathbb{R}^n} b \cdot \nabla(h^2)\rho \,dx = - \int_{\mathbb{R}^n} h^2 \nabla \cdot (b\rho)\,dx$$ The issue for me is, of course, the boundary term. Is there any reason to say the boundary term is $0$ ? If not, could it hold if we impose some restrictions on $b(x)$ or $h$ , such as $h$ is a Schwartz function? Any help would be really appreciated!","['integration', 'measure-theory', 'real-analysis']"
3537167,Integral with binomial to a power $\int\frac{1}{(x^4+1)^2}dx$,"I have to solve the following integral: $$\int\frac{1}{(x^4+1)^2}dx$$ I tried expanding it and then by partial fractions but I ended with a ton of terms and messed up. I also tried getting the roots of the binomial for the partial fractions but I got complex roots and got stuck. Is there a trick for this kind of integral or some kind of helpful substitution? Thanks. EDIT: I did the following: Let $x^2=\tan\theta$ , then $x = \sqrt{\tan\theta}$ and $dx=\frac{\sec^2\theta}{2x}d\theta$ Then: $$I=\int\frac{1}{(x^4+1)^2}dx = \int\frac{1}{(\tan^2\theta+1)^2} \frac{\sec^2\theta}{2x}d\theta=\int\frac{1}{\sec^4\theta} \frac{\sec^2\theta}{2x}d\theta$$ $$I=\frac{1}{2}\int{\frac{1}{\sec^2\theta \sqrt{\tan\theta}}}d\theta$$ . After this I don't know how to proceed.","['integration', 'calculus']"
3537191,Inner automorphisms of group algebras vs. inner automorphisms of the group,"Let $k$ be a commutative ring, $G$ a finite group and $\alpha\in\operatorname{Aut}(k[G])$ an automorphism of $k$ -algebras. If we know that $\alpha\in\operatorname{Inn}(k[G])$ and $\alpha(G)=G$ , can we conclude that there is a group element $g\in G$ with $\alpha(x)=gxg^{-1}$ ? In other words: Is the canonical map $\operatorname{Out}(G) \to \operatorname{Out}(k[G])$ injective? Such an $\alpha$ looks suspiciously like an inner automorphism of $G$ . For example, $\alpha$ maps every conjugacy class to itself. In particular it acts trivially on $Z(G)$ and every normal subgroup is $\alpha$ -invariant. But is it really an inner automorphism of $G$ ? If it is not generally true, is it at least true for some special rings like $k=\mathbb{Z}$ for example?","['automorphism-group', 'group-theory', 'abstract-algebra', 'finite-groups']"
3537210,Probability of Picking Socks finding the intersection of two dependent events,"A box is filled with 15 different socks: 10 green and 5 yellow. Three socks are picked from the box (leaving 12 in the box). Let $x$ be the random variable describing the number of green socks that are selected. Let events $A$ and $B$ be described as follows: $A$ = the event that not all three socks are green. $B$ = the event where the first sock selected is green. Find $P(A)$ , $P(B)$ , and $P(A\text{ and }B)$ . Show any appropriate $nCr $ expressions. I know for this problem that $P(A) = 1 - (\frac{10}{15} \times \frac{9}{14} \times \frac{8}{13})$ and $P(B) = \frac{10}{15}$ , but I'm not sure how to find $P(A\text{ and }B)$ . I know these events are dependent.","['probability-theory', 'probability']"
3537216,Showing group action consists of homomorphisms,"In Lang's algebra I see the following definition: ""Let $G$ be a finite cyclic group of order $n$ , generated by an element $\sigma$ . Assume that $G$ operates on a an abelian group $A$ and let $f:A\to A$ be the endomorphism of $A$ given by $f(x)=\sigma x - x$ ..."" Why is $f$ an endomorphism? I thought $\sigma$ is just a permutation on $A$ and we don't have $\sigma(x+y)=\sigma x + \sigma y$ . Edit--The question Lang's Algebra: Herbrand quotient has Lang's exercise written out fully with some slight corrections, but also the assumption $\sigma(x+y)=\sigma x + \sigma y$ , so there is probably some typo or ambiguity in the definitions. I just wanted to make sure the homomorphism property didn't somehow follow from the $G$ being a finite cylclic group and/or $A$ being abelian.","['group-homomorphism', 'cyclic-groups', 'finite-groups', 'group-theory', 'group-actions']"
3537226,Number of ‘acceptable’ pairs in card drawing game,"A deck contains six cards, one pair labelled '1', another pair labelled '2' and the last labelled '3'. The deck is shuffled and you a pair of cards at a time until there are no cards left. A pair of cards $(i,j)$ is called acceptable if $|i-j|\leq1$ . What is the probability you have drawn only acceptable pairs? How does your answer change if there are $n$ pairs and the condition becomes $|i-j|\leq k$ ? I'm quite stuck on the last bit of the problem. Here's my approach to the first part: My solution so far: 
My idea is that as long as a pair $(1,3)$ or $(3,1)$ is drawn, then set contains an unacceptable pair. The probability $(1,3)$ or $(3,1)$ is drawn first is $$2\left(\frac26\times\frac25\right)=\frac4{15},$$ the probability $(1,3)$ or $(3,1)$ is drawn second is $$\left(1-\frac4{15}\right)\frac4{15}=\frac{44}{225},$$ and the probability $(1,3)$ or $(3,1)$ is drawn last is $$\left(1-\frac4{15}-\frac{44}{225}\right)\frac4{15}=\frac{484}{3375},$$ so the probability of having only acceptable pairs is $$1-\frac4{15}-\frac{44}{225}-\frac{484}{3375}=1-\frac{900}{3375}-\frac{660}{3375}-\frac{484}{3375}=\frac{1331}{3375}.$$ (Correct me if this is wrong please!) However, I am unsure of how to extend this to a more general number of cards and relaxed constraint. Taking the complement seems to be less efficient compared to finding the actual probability, but I'm not sure if there's a closed form. Qualitatively, all I can see is the probability dropping to zero as the number of cards increases. Could someone provide better insight? Cheers!","['card-games', 'probability']"
3537235,Lower bound on tail probability for maximum of independent random variables,"I'm having difficulty solving a problem from van der Vaart & Wellner (1996). Problem 2.3.2 on page 120 asks the reader to prove: For independent random variables $\xi_1, \ldots, \xi_n$ , $$
P\left(\max_i |\xi_i| >x\right) \ge \frac{\sum_i P(|\xi_i|>x)}{1 + \sum_i P(|\xi_i|>x)}.
$$ There is a hint: For $x\ge 0$ , one has $1-x\le \exp(-x)$ and $1-e^{-x}\ge x/(1+x)$ . I'm not sure how to start with proving this statement. Clearly the form $x/(1+x)$ in the hint is the same as the form on the rhs of the inequality, however I'm not sure how to get the $1-e^{-x}$ in there. Any hints / suggestions as to how to attack this problem would be appreciated.","['inequality', 'probability-theory', 'probability']"
3537270,Finite groups with all maximal subgroups isomorphic,"Suppose $G$ is a finite group such that any two maximal subgroups of $G$ are isomorphic. What can be said about such a group? Can they be classified? The finite groups that have a unique maximal subgroup are exactly the cyclic groups of prime power order, $\mathbb{Z}/p^n\mathbb{Z}$ - these are the simplest examples of such groups. Also powers of $\mathbb{Z}/p^n\mathbb{Z}$ , i.e. $(\mathbb{Z}/p^n\mathbb{Z})^m = \mathbb{Z}/p^n\mathbb{Z} \times \ldots \times \mathbb{Z}/p^n\mathbb{Z}$ , have this property, and I think this covers all abelian groups with this property. In general I think such a group has to be a $p$ -group, by considering maximal subgroups containing Sylow subgroups for different primes. This paper https://bib.irb.hr/datoteka/402744.SiCh.pdf calls such groups isomaximal , but seems to only handle $2$ -groups up to order $64$ . Further question: what about groups $G$ such that any two maximal subgroups are isomorphic under some automorphism of $G$ (i.e. $\operatorname{Aut}(G)$ acts transitively on the set of maximal subgroups)? (Note: if this is strengthened to any two maximal subgroups being conjugate, then by this answer it becomes the same as having a unique maximal subgroup.)","['group-theory', 'abstract-algebra', 'finite-groups', 'group-isomorphism']"
3537381,Counting deltahedra with $2n$ faces,"A deltahedron is, according to Wikipedia, a polyhedron whose faces are all equilateral triangles. There is only one deltahedron with four faces: the tetrahedron . Likewise, there is only one deltahedron with six faces: the triangular bipyramid There are two with eight faces: the octahedron the biaugmented tetrahedron (not convex) And at least five with 10 faces: the pentagonal bipyramid the augmented octahedron (contains coplanar faces) the three triaugmented tetrahedra I'm looking to see if anyone has computed the number of deltahedra with $2n$ faces. I did a cursory OEIS search , but didn't find anything. Is there a known formula or recurrence relation for the number of deltahedra that can be constructed from $2n$ equilateral triangles? If so, is there a corresponding OEIS entry?","['discrete-geometry', 'polyhedra', 'combinatorics', 'oeis']"
3537417,Evaluating improper integral $\lim_{\epsilon \rightarrow 0} \int_{0}^{1} (\frac{\phi(x)}{x+i\epsilon}- \frac{\phi(x)}{x-i\epsilon}) dx$,"I want to evaluate the improper integral $$\displaystyle\lim_{\epsilon \rightarrow 0}\int_0^1{\left( \frac{\phi \left( x \right)}{x+i\epsilon}-\frac{\phi \left( x \right)}{x-i\epsilon} \right)}dx
$$ where $\phi(x) : [0, 1] \rightarrow \mathbb{R}$ is a continuous function. What I’ve tried is just simplify integrand as $\displaystyle  \frac{2i\epsilon \phi(x)}{x^2 + \epsilon^2}$ . I just guess it can be evaluated by some complex analytic method since the integrand involves $i$ . But I can’t see how to use what I know(basic residue theorem, cauchy’s integral formula, etc.). Could you give a direction to solve this? I appreciate your comment and answer.","['complex-analysis', 'complex-integration', 'improper-integrals']"
3537437,Orthogonal Random Variable $\mathcal{L}^{2}$ (Hard?),I am self-studying Probability Theory and for me the following problem is challenging.,"['self-learning', 'measure-theory', 'independence', 'probability-theory', 'random-variables']"
3537456,Why are the hyperbolic functions defined the way they are?,I know that $\sinh(x) := \frac{e^x-e^{-x}}{2}$ and $\cosh(x) := \frac{e^x + e^{-x}}{2}$ by definition. But what exactly is the significance of this and how is it related to trigonometry? I get that $\sinh(x)$ is just the difference between the graphs $\frac{e^x}{2}$ and $\frac{e^{-x}}{2}$ and that $\cosh(x)$ is just the sum of $\frac{e^x}{2}$ and $\frac{e^x}{2}$ when viewed geometrically. I would like to know why mathematicians have used half of both $e^x$ and $e^{-x}$ instead of defining say $\sinh(x)$ to be equal to just $e^x-e^{-x}$ without needing to divide by $2$ . Thanks in advance.,"['conic-sections', 'algebra-precalculus', 'exponential-function', 'trigonometry']"
3537531,Coronavirus growth rate and its (possibly spurious) resemblance to the vapor pressure model,"The objective is the model the growth rate of the Coronavirus using avaibale data. As opposed to the standard epidemiology models such as SIR and SEIR , I tried to model a direct relation between the number of infected or deaths as a function of time so as to capture the early days trends. I collected the latest data on the coronavirus from Johns Hopkins University as shown and fitted different curves to this data to model the relationship between the number of confirmed patients $P$ who are/were infected as function of time $T$ taking 20-Jan-20 as day 1. The curve fitting software I used has well known models form different branches of science as well as we could build our own custom models which I did as shown in the image below. The score against the name of a model gives how well a model fits this data. The higher the score, the better the fit and the maximum possible score is 1000. Although we have data only for 18 days (as of 7-Feb 2 AM GMT) one model always kept appearing at top as the best fit and this was the vapor pressure model. After checking for various boundary conditions, I rejected many of models but I could not find any immediately reason to reject the vapor pressure model. Similarly when I modeled the number of reported deaths against time, the vapor pressure model once again gave the best fit which for which I could not find any obvious reasons to reject. So I did some research on the vapor pressure model. Basic concept of vapor pressure Because the molecules of a liquid $L$ are in constant motion and possess kinetic energies, at any moment some fraction of them has enough energy to escape from the surface of the liquid to enter the gas phase. This process, called evaporation, generates a vapor pressure $P_L$ above the liquid. Molecules in the gas phase can collide with the liquid surface and reenter the liquid via condensation. Eventually, a steady state is reached in which the number of molecules evaporating and condensing per unit time is the same, and the system is in a state of dynamic equilibrium. Under these conditions, a liquid exhibits a characteristic equilibrium vapor pressure that depends only on the temperature $T_L$ . Volatile liquids are liquids with high vapor pressures, which tend to evaporate readily from an open container; nonvolatile liquids have low vapor pressures. When the vapor pressure equals the external pressure, bubbles of vapor form within the liquid, and it boils. We can express the nonlinear relationship between vapor pressure and temperature as an almost linear relationship using the Antoine equation . $$
P_L = exp\Big(a + \frac{b}{T_L} + c\log T_L\Big)
$$ Next I did some research what is known about how the coronavirus spreads and if it is related to liquids. Here is what I found. How coronavirus spreads : When an infected person coughs or sneezes, they shed droplets of saliva, mucus, or other bodily fluids. If any of those droplets fall on you—or if you touch them and then, say, touch your face—you can become infected as well. Hospital for communicable diseases define exposure as being within six feet of an infected person for 10 minutes or longer. Time and distance matters. The coronavirus spreads when it escapes from an infected person through microscopic droplets of liquid carrying the virus through air. I wonder this has anything to do with why the vapor pressure model keeps coming on the top as the best fit even though there is no apparent pressure or temperature as in the vapor pressure equation and I cannot see how they could be elated. May be all this just a mere coincidence . As a bad scientist but a concerned human, I thought I must report this
  observation in case there is anything worth in it. Question : My objective was mainly for reporting this given the seriousness of the situation. But since the community rules mandates a question, it I will ask one. Given this limited data what can we infer about the corona virus and how can we reject the vapor pressure model as a mere coincidence. Note 1 : I will be posting this in the Physics community where it is more relevant. But with 638 deaths in the last two weeks, I have posted it in MSE just in case someone else might find it useful. Note 2 : I am well aware of spurious correlation. But with only 3 weeks of data, we many not be able to detect a different trend this early. Hence I am reporting the best fit regardless.","['statistics', 'mathematical-modeling', 'curves', 'physics', 'numerical-methods']"
3537611,Show $f(z)=e^x(x\cos y-y\sin y)+ie^x(y\cos y+x\sin y)$ is analytic,"Show $f(z)=e^x(x\cos y-y\sin y)+ie^x(y\cos y+x\sin y)$ is analytic. Then find its derivative. So I have $u = e^x(x\cos y-y\sin y)$ and $v = e^x(y\cos y+x\sin y)$ . Then I have ${\partial(u)\over\partial(x)} = e^x(x\cos y-y\sin y) + e^x(\cos y)$ , and ${\partial(v)\over\partial(x)} = e^x(y\cos y+x\sin y) + e^x(\sin y)$ . I'm having trouble with finding ${\partial(u)\over\partial(y)}$ and ${\partial(v)\over\partial(y)}$ .  Also with finding the derivative of a complex function as well. I've seen examples with general form in $z$ but not with functions like these...","['complex-analysis', 'complex-numbers']"
3537631,Confused about $O_X$ ideals and closed subschemes,"I am trying to understand a passage in Mumford's Red Book (Section II. 5, page 146 in the old version). Let $X$ be a scheme, $Q$ is a subsheaf of $O_X$ such that for all $U$ , $Q(U)$ is an ideal in $O_X(U)$ , (I assume he means open $U$ here) and we call such an object an $O_X$ - ideal. The part I am trying to understand is the following: We claim that $Q$ determines the closed subschemes up to canonical isomorphisms. For first of all, $Y = \{ x \in X : Q_x \neq O_X \}$ , the sequence $$
0 \to Q_x \to O_{x,X} \to O_{x, Y} \to 0
$$ is exact, and secondly $O_Y$ extended by zero is canonically isomorphic to the cokernel of $Q \to O_X$ . Thus a closed subscheme is really just an $O_X$ -ideal. I am struggling to see how this explains $Q$ determines closed subschemes. 
I have been trying to understand parts of this so I have asked couple related question, but it seems that I am getting more confused...  I would greatly appreciate clarification about this. Thank you very much!","['algebraic-geometry', 'schemes']"
3537637,"Limit associated with a recursion, connection to normality of quadratic irrationals","Update on 3/2/2020 . All the material below and much more has been incorporated into a comprehensive article on this topic. The question below is discussed in that article, entitled ""State-of-the-Art Statistical Science to Tackle Famous Number Theory Conjectures"", and available here . I posted a popular question 5 months ago about the following recursion, see here . If $z_n < 2y_n$ Then $y_{n+1} = 4y_n - 2z_n$ $z_{n+1} = 2z_n + 3$ $d_{n+1}=1$ Else $y_{n+1} = 4y_n$ $z_{n+1} = 2 z_n - 1$ $d_{n+1}=0$ Back then, I wrote: The sequence $d_n$ represents the binary digits of some unknown number $x$ , a number that depends on the initial conditions. It
  turns out that if $y_1=2,z_1=5$ then that number is $x=\sqrt{2}$ . Here I offer a full solution and a potential path to proving the normality of quadratic numbers. My question is about proving that my main result (below) is correct. It is backed by very strong empirical results involving computations with thousands of digits. By normality, I mean that 50% of the binary digits of $x$ are equal to 1. This is one of the most challenging unsolved mathematical conjectures of all times. Below is a Perl script that does all the computations. It uses the Bignum library to perform exact arithmetic (computation of millions of binary digits for each number, using the formulas described here.) The variable called number in the code corresponds to $x$ . use strict;
use bignum;

my $y;
my $ z;
my $u;
my $ v;
my $k;
my $ c;
my $even;

my $counter;
my $ seed_y;
my $seed_z;
my $ number;
my $denominator;
my $ c1;
my $c2;

$counter=0;

open(OUT2,"">collatzr.txt""); # summary stats
open(OUT,"">coll2.txt"");     # details and digits for each number


for ( $seed_y=1; $ seed_y<=5; $seed_y++) {
for ($seed_z=$seed_y; $seed_z<=10; $ seed_z++) { $y=$ seed_y; $z=$ seed_z; $u=2*$ y- $z; 
  $ v=2*$z+3; $number=0;
  $ denominator=1; $c1=0;
  $ c2=0;

  for ( $k=1; $ k<200; $k++) { # compute 200 digits

    if ( $u>0) { 
      $even=1;  # digit equal to 1
      $c1++;
      $y=4*$y-2*$z;
      $z=2*$z+3;
      $u=4*$u-$v;
      $v=2*$v+3;
    } else {
      $even=0;  # digit equal to 0
      $c2++;  
      $y=4*$y; 
      $z=2*$z-1;
      $u=4*$u+$v-2;
      $v=2*$v-5;  
    }            
    print OUT ""$ seed_y\t $seed_z\t$ k\t $even\n""; 
    $ denominator= $denominator/2;  
    $ number= $number+$ even* $denominator;
    $ c= $z*$ denominator;
  } $counter++;
  if ($ counter%5 == 0) { print "" $seed_y\t$ seed_z\n""; select()->flush(); }
  print OUT2 "" $seed_y\t$ seed_z\t $c1\t$ c2\t $c\t$ number\n"";


}
}

close(OUT);
close(OUT2); 1. Main result Let $$x = \sum_{k=0}^\infty \frac{d_k}{2^k}, \mbox{ with } d_0=0 \tag 1$$ Then, assuming $y_0, z_0$ are positive integers, we have: $y_0=0 \Rightarrow x=0$ $z_0 = 2y_0 \Rightarrow x=\frac{1}{2}$ $z_0 < y_0 \Rightarrow x=1$ In all other cases (referred to as the standard case ), $x$ is an irrational quadratic number solution of $2x^2 +(z_0-1)x -y_0=0$ , more specifically: $$x =\frac{-(z_0-1)+\sqrt{(z_0-1)^2+8y_0}}{4} \tag 2$$ My question Can you prove the above result? It was obtained empirically. 2. Useful tips to answer my question In the standard case, we have the following result (not proved yet): $$\lim_{n\rightarrow\infty}\frac{z_n}{2^n}=\sqrt{(z_0-1)^2 + 8y_0}.$$ Also, using $u_n=2y_n-z_n$ and $v_n = 2z_n+3$ , the recurrence can be rewritten as: If $u_n>0$ Then $u_{n+1}=4u_n -v_n$ $v_{n+1} = 2v_n + 3$ $d_{n+1}=1$ Else $u_{n+1}=4u_n + v_n-2$ $v_{n+1} = 2v_n-5$ $d_{n+1}=0$ Finally, $\mbox{mod}(v_n, 8) = 5$ , that is, $(v_n - 5)/8$ is an integer. If $n>1$ we have: $$d_n = \mbox{ mod}\Big(\frac{v_n-5}{8},2\Big).$$ This leads to the following simple reverse recurrence involving only one variable, allowing you to compute the digits of $x$ backward, starting with a large $n$ and moving backward down to $n=1$ : $$\mbox{If mod}\Big(\frac{v_{n}-5}{8}, 2\Big) = 1, \mbox{ then } v_{n-1}=\frac{v_{n}-3}{2}, d_{n}=1, \mbox{ else } v_{n-1}=\frac{v_{n}+5}{2}, d_{n} = 0.$$ The very tough problem, outlined in the next section, is to prove that each of these two outcomes is equally likely to occur, on average. This would indeed be true if each $v_n$ is arbitrary, but this is not the case here. Also, if for some large $n$ , we have $d_n=1$ , then a run of $R$ successive digits $d_{n-1},\dots,d_{n-R}$ all equal to zero can only go so far, unless $v_n$ is a very special number not leading to $x$ being irrational. Maybe $R=\lfloor 2\sqrt{n}\rfloor$ is an upper bound. This is something worth exploring. Property of the reverse recurrence : If $\mbox{mod}(v_n,8)=5$ and $v_n
> 5$ , then the sequence $v_n, v_{n-1},\dots$ is strictly decreasing until it reaches $5$ and stays there permanently; also each term is congruent to $5$ modulo $8$ . This is true whether or not $v_n$ was generated using our forward recurrence. An interesting application of this property is as follows. Take an arbitrary number, say $x = \log 2$ . Multiply by a large power of $2$ , say $2^{30}$ . Round the result to the closest integer congruent to $5$ modulo $8$ , and let this be your $v_n$ . In this case, $v_n =\lfloor 2^{30} \log 2 \rfloor$ . Compute $v_{n-1}, v_{n-2}$ and so on, as well as the associated digits, using the reverse recurrence. Stop when you hit $5$ . The digits in question are the first binary digits of $\log 2$ yielding the approximation $0.693147175\dots$ while the exact value is $0.693147180\dots$ A similar reverse recurrence is also available for the original system:
  If $\mbox{mod}(\frac{z_{n}-1}{4}, 2) = 1$ , then $z_{n-1}=\frac{z_{n}-3}{2}$ , $d_{n}=1$ , else $z_{n-1}=\frac{z_{n}+1}{2}$ , $d_{n} = 0$ . We also have $\mbox{mod}(z_n,4)=1$ . 3. Connection to normality of irrational quadratic numbers This is not part of my question, just interesting, extra material for the curious reader, and to provide some background as to why I am interested in this recursion. Do not even try to solve my problem below: contrarily to the main result, this stuff is incredibly hard; it could keep you busy and depressed for many years. Let $S_n$ denotes the number of binary digits $d_k$ of $x$ , that are equal to 1, for $k=1,\cdots, n$ . If irrational quadratic numbers were indeed normal as we all believe they are, then, there is an absolute constant $K$ (not depending on $x$ ), and for each $x$ , there is a number $N(x)$ denoted as $N$ , such that $$\mbox{If } n > N, \mbox{ then } S_n - K\sqrt{n} \leq \frac{n}{2} \leq S_n + K\sqrt{n}  \tag 3$$ This is a consequence of the Berry-Hessen theorem applied to Bernouilli variables. It is discussed in sections 1.1 and 1.2 in this article . The chart below shows $\frac{|2S_n - n|}{\sqrt{n}}$ on the Y-axis, with $n$ between 0 and 530,000 on the X-axis, for the case $y_0 = z_0 = 1$ leading to $x=\frac{\sqrt{2}}{2}$ . It suggests (not a proof) that in this case, $N = 0$ and $K = 0.90$ might work. To prove that $x$ has 50% of its binary digits equal to 1, a potential approach thus consists in proving that if the previous inequality is true for $n$ large enough, then it is also true for $n+1$ , by looking at the worst case scenario for the potential distribution of the first $n$ binary digits of $x$ , using the recurrence relation introduced at the beginning, or the backward recurrence. Some of the numbers $x$ that I tested are approaching the 50% ratio in question rather slowly, for instance if $y_0=1, z_0=16$ . Indeed, I am wondering if some of these quadratic irrationals, maybe a finite number of them, even though normal, do not satistfy $(3)$ , but instead a weaker result, say with $\sqrt{n}$ replaced by $n^{3/4}$ or $\frac{n}{\log n}$ . To the contrary, a very fast convergence, say $n^{1/4}$ or $\log n$ instead of $\sqrt{n}$ in $(3)$ , would also mean, even though $x$ may be normal, that its digits are not distributed like i.i.d. Bernouilli $(\frac{1}{2})$ variables. The only way for this Bernouilli behavior to happen, is if the convergence to the 50% ratio occurs at the right speed, that is with $\sqrt{n}$ in inequality $(3)$ . In other words, for a specific $x$ , any asymptotic departure from $\sqrt{n}$ in $(3)$ would mean that its binary digits are not distributed in a purely random way. This ""pure randomness"" criterion is stronger than having 50% of the digits equal to 1. For instance, $x=\frac{2}{3}=0.10101010\dots$ (in base 2) has 50% of its digits equal to 1, but the term $O(\sqrt{n})$ in $(3)$ can be replaced by the optimum bound $O(1)$ , and the digits look anything but random. I am doing some simulations and testing at this moment, see for instance my recent question on CrossValidated, here . Another spectacular result that might be more easier to prove is that the correlation between the binary digits of $px$ and $qx$ is equal to $\frac{1}{pq}$ if $p, q$ are odd, co-prime, non-zero integers: see here . A corollary is that if $\alpha,\beta$ are irrationals linearly independent over the set of rational numbers, then their binary digits have zero cross-correlation.","['number-theory', 'irrational-numbers', 'recurrence-relations', 'sequences-and-series', 'limits']"
3537728,How do ultrafilters of subgroups look like?,"In my work related to the axiom of choice one of the central notions is a filter of subgroups. Namely, if $G$ is a group, a filter of subgroups is a non-empty collection of subgroups which is closed under supergroups and finite intersections. But we are not interested in any filter, but specifically in normal filters which satisfy the clause that if $g\in G$ and $H$ is in the filter, then $g Hg^{-1}$ is also in the filter. Are there also ultrafilters (maximal proper filters) of subgroups? Certainly there are principal ones, e.g. all the groups which contain a certain element of $G$ is the principal ultrafilter generated by the subgroup $\langle g\rangle$ . But are there free ultrafilters? If there are, are there any normal ultrafilters (ultrafilters which are also normal), or do the two conditions clash in some way? I know that we can think about the filters of subgroups as just filters on $G$ in the standard set theoretic sense, and then considering all the subgroups generated by sets in the filter. But this doesn't help me understand how might a free and normal ultrafilter of subgroups can look like, especially since this is not a bijection between the two notions (look at the case where a subgroup can be generated by two disjoint subsets).","['filters', 'group-theory', 'abstract-algebra']"
3537762,Random point in a triangle,"This subject has already been covered here , and my question is slightly different. Preliminary warning: i'm quite a noob (and probably will continue to be unless i go back to school), but i do love some maths, the one i can't do with programming. Please excuse my lack of ""academism"". If the question is too informal, please let me know, i will ask my question elsewhere. In an euclidean space I got a triangle ABC, quite special, i don't know how to name it : A is (0, 0) B is (width, 0) C is (cx, cy) So 3 numbers are enough to describe ABC. I want to pick a random point inside ABC.
How to do it ? I tried the following: 
Get a random point in the parallelogram, then ""squeeze"" into ABC. let randomPoint = (width, C) => {
    let r1 = Math.random()
    let y = C.y * r1
    let r2 = Math.random()
    let x = width * r2 * (1 - r1) + C.x * r1
    return new Point(x, y)
} Of course, there's to much points near C. So i believed i would be able to fix that by changing the distribution along y. So i got better results: let randomPoint = (width, C) => {
    let r1 = Math.random() * Math.random()
    let y = C.y * r1
    let r2 = Math.random()
    let x = width * r2 * (1 - r1) + C.x * r1
    return new Point(x, y)
} But this is very empiric, and obviously, this is not uniform. Is there a way to change the computation of r1 the random number to have a distribution that will be uniform inside ABC ? NB: i realize my self that it should be a simplier solution by mirroring point in the upper triangle (BCA') to the first triangle ABC. I will post the solution in an anwser. Still however any comment will be much appreciated since I feel myself like fumbling in the fog.","['programming', 'random', 'geometry']"
3537791,Convergence of $u_{k+1} = \frac{1}{2-u_k u_{k-1}}$,"Let $u_0, u_1 \in \mathbb{R}$ be arbitrary. I am interested in the sequence defined by: $$u_{k+1} = \frac{1}{2-u_k u_{k-1}}.$$ In particular I would like to find $\lim_{k\rightarrow \infty} u_k$ for this sequence.
For a value $\bar u$ to be a potential limiting point, this value should at least satisfy: $$
\bar u = \frac{1}{2-\bar u^2},
$$ it is not hard to see that this equation has $3$ solutions, namely: $$
\bar u = 1, -\frac{1}{2}(1+\sqrt{5}), \frac{1}{2}(-1+\sqrt{5}).
$$ I can numerically verify that the first two candidates do not attract the sequence $(u_k)_k$ , thus we only have $u_k \rightarrow 1$ resp. $u_k\rightarrow -\frac{1}{2}(1+\sqrt{5})$ when $u_0,u_1 = 1$ resp. $u_0,u_1=-\frac{1}{2}(1+\sqrt{5})$ whilst the third seems to be an attractor for the sequence. Furthermore there is the special case where $u_0 \cdot u_1 = 2$ , which we exclude as $u_2$ is not defined in this case. However, I am unable to prove that for any $u_0, u_1 \notin \{-1, -\frac{1}{2}(1+\sqrt{5})\}$ and $u_0 \cdot u_1 \neq 2$ , we have $u_k \rightarrow \frac{1}{2} (-1+\sqrt{5})$ . A related problem was studied here , and I understand the proof given there, but I do not see how to extend this new problem.","['calculus', 'convergence-divergence', 'recurrence-relations']"
3537822,When does $U\subset V$ induce maps on homology of finite rank?,"Question 1. Let $X$ be a topological manifold, $U\subset V\subset X$ open subsets. The inclusion $\iota:U\to V$ induces corresponding maps on homology $\iota_*:H_\bullet(U)\to H_\bullet(V)$ . We take the coefficients to lie in some fixed field. Under what conditions can we conclude that $\iota_*$ has finite rank (as a linear map)? In particular, I am interested in whether the following is sufficient: $\overline{U}\subset V$ and $\overline{U}$ is compact. I encountered this problem when reading Gromov's paper Curvature, diameter and Betti numbers . The setting is on a complete Riemannian manifold $(M,g)$ where we may consider balls $B(p,r):=\{x\in M:d(p,x)<r\}$ . The content of such a ball is defined by $$\operatorname{cont}B(p,r):=\operatorname{rank}(B(p,r/5)\subset B(p,r)),$$ where the rank refers to the rank of the induced map on homology. I need to know that this number is always finite. I encountered the second question when reading the proof of the results in the aforementioned paper of Gromov in the book Riemannian Geometry by Peter Petersen. The author remarks without proof the following: Question 2. Notation as above. For $r$ large enough, $$\operatorname{cont}B(p,r)=\sum b_i(M)$$ where $b_i:=\dim H_i(M)$ is the Betti number of $M$ . Now this is obvious if $M$ is compact. But why is it true for noncompact complete manifolds? I'm a bit rusty on algebraic topology, but I really don't see why these should hold. Any help is highly appreciated!","['homology-cohomology', 'riemannian-geometry', 'algebraic-topology', 'differential-geometry']"
3537834,Number of automorphisms in a graph,"I have searched all over YouTube and Google about finding the number of all possible automorphisms in a graph, but couldn't find anything except some trivial examples. I would like to know how you would approach this type of problem, also would appreciate useful links/documents. Our lecturer told us to fix points one by one in a process, but his explanation was simply horrible. I have tried solving multiple problems, but 90% of times I get the wrong answer, thanks in advance. For example how would you count the number of automorphisms for octahedron graph:","['graph-theory', 'automorphism-group', 'discrete-mathematics']"
3537853,How do I find the minimum value of this function?,"The question is: Consider the domain $\{ (x,y) \in \mathbb{R}^2 ; x \le y \}$ The function $h$ is mapped from this domain to $R$ — the set of all real numbers: $$h(x,y) = (x-2)^4 + (y-1)^4.$$ Find the minimum value of this function. I found out the necessary partial derivatives — $h_x$ and $h_y$ and equated them to $0$ to get $x=2$ and $y=1$ . Further, $h_{xx}$ , $h_{yy}$ and $h_{xy}$ are all zero for these values of $x=2$ and $y=1$ . 
So,H = $h_{xx}h_{yy} - h_{xy}^2$ is coming out to equal 0. How should I proceed now?","['multivariable-calculus', 'calculus', 'functions', 'maxima-minima']"
3537857,What is the largest sequence of open balls around rational numbers that does not cover $\mathbb R$?,"Let $\mathbb Q = \{q_1,q_2,\dots\}$ be the rational numbers. Let $B_n = \{x \in \mathbb R: |x-q_n| < 2^{-n}\}$ be the open ball of radius $2^{-n}$ around $q_n$ . Then the Lebesgue measure of $U=\cup_{n=1}^\infty B_n$ is at most $$\lambda(\cup_{n=1}^\infty B_n) \le \sum_{n=1}^\infty \lambda(B_n) = 1$$ In particular, $U \subsetneq \mathbb R$ . But this is surprising since $\mathbb Q$ is dense in $\mathbb R$ ! Now let $$C_n = \{x \in \mathbb R: |x-q_n| < c_n\}$$ where the $c_n$ are positive numbers in $\mathbb R$ . Obviously, if $\sum_{n=1}^\infty c_n < \infty$ the same argument as above shows that $\cup_{n=1}^\infty C_n \subsetneq \mathbb R$ . But what about nonsummable $(c_n)$ ? For example, if $c_n = \frac{1}{n}$ , do we still get $\cup_{n=1}^\infty C_n \subsetneq \mathbb R$ or will $\cup_{n=1}^\infty C_n$ now cover $\mathbb R$ ? More generally, given a fixed enumeration of the rationals, can we characterize a ""slowest-declining"" monotonous sequence $(c_n)$ such that $\cup_{n=1}^\infty C_n \subsetneq \mathbb R$ ?","['measure-theory', 'real-analysis', 'sequences-and-series', 'general-topology', 'soft-question']"
3537885,Bank vaults and probability,"A burglar breaks into a bank with the intention to open the vaults and steal some gold coins.
  He knows that each vault contains a number of 1 to 100 such coins with equal probability for each number. Since he is what we call an “ethical burglar”, he will only get 100 coins to help some people in need. How many vaults must he breach on average? This is really confusing because we are not given how many vaults we have. Is it safe to say that since the numbers from 1 to 100 have equal probability, then we have 100 vaults? 
Then, if vault Number 1 has 1 coin, 2 has 2 etc, we need to open as many that will give sum of 100? And then get the average? I need help with the interpretation and solution please! Ok after having asked several people, here is my interpretation:
We may have any number of vaults, not necessarily 100 (maybe more, maybe less) but the number of coins in them has been placed randomly, with equal probability for each number from 1 to 100. The burglar will stop once he has collected 100 or more coins: That is, if, after the last vault, he has 99, he may open another one, with 23 coins, so he will have a total of 122 and this is OK. Any ideas for the solution? Thank you!",['probability']
3537941,"Find the point, if any, the graph of $f(x) = \sqrt{8x^2+x-3}$ has a horizontal tangent line","Section 2.5 #14 Find the point, if any, the graph of $f(x) = \sqrt{8x^2+x-3}$ has a horizontal tangent line. Okay, so having a horizontal tangent line at a point on the graph means that the slope of that tangent line is zero. The derivative of a function is another function that tells us the slope of the tangent line at any given point on the graph of the original function. Thus, to find where the graph of $f(x) = \sqrt{8x^2+x-3}$ has a horizontal tangent line, we need to take the derivative, set it equal to zero, and solve for $x$ . This will give us the $x$ -coordinate of where the graph of $f(x)$ has a horizontal tangent line. To find the corresponding $y$ value, we plug the $x$ value that we found into the original equation. In this problem, when we plug the $x$ value we find into the original equation, we get an imaginary number, which means that no point on the graph of $f(x)$ has a horizontal tangent line, and thus our answer is DNE, does not exist. Let's go through the motions!!! $f(x) = \sqrt{8x^2+x-3}=(8x^2+x-3)^{1/2}$ $f'(x) = \frac{d}{dx}(8x^2+x-3)^{1/2}$ Time do the chain rule!!! $$\begin{align}
f'(x) &= \frac{(8x^2+x-3)^{-1/2}}{2}\frac{d}{dx}(8x^2+x-3)\\
&= \frac{(8x^2+x-3)^{-1/2}}{2}(16x+1)\\
&= \frac{(16x+1)}{2(8x^2+x-3)^{1/2}}
\end{align}$$ Alright, we have our derivative. We want to find horizontal tangent lines, so we set this equal to zero and solve for $x$ $$0 = \frac{(16x+1)}{2(8x^2+x-3)^{1/2}}$$ multiplying both sides of the equation by $2(8x^2+x-3)^{1/2}$ we get $0 = (16x+1)$ And thus $x = \frac{-1}{16}$ Now, we plug this value into the original equation to get the corresponding $y$ value, because remember, we are looking for a point on the graph where the horizontal line is tangent, so our answer will be in $(x,y)$ format, is it exists, (which in this case, it won't).. $f(\frac{-1}{16}) = \sqrt{8(\frac{-1}{16})^2+\frac{-1}{16}-3}$ But $8(\frac{-1}{16})^2+\frac{-1}{16}-3<0$ , so taking its square root will give us an imaginary number. Thus the answer is DNE","['calculus', 'solution-verification', 'derivatives']"
3537950,An angle inside a regular pentagon,"A student sent me a question and I am stucked. I'd like to use classical geometry, instead of hard trigonometry if possible (can be trigonometric, but I'd like to not use scientific calculator; the only answer I got I need this), but I am in circles. The pentagon $ABCDE$ is regular. The answer is $48^\circ$ (I've constructed in Geogebra). Thank you in advance!","['triangles', 'geometry']"
3538014,Increasing and decreasing function doubt,"This is a question of increasing and decreasing functions. $f(x)=\sin x + \cos x$ , $x$ belongs to $[0, 2\pi]$ Derivative of this function $f'(x) = \cos x - \sin x$ For increasing function we put $f'(x) > 0$ . I tried to solve it this way: $\cos x - \sin x > 0$ $\cos x > \sin x$ $\tan x < 1$ $x$ belongs to $\left(0, \dfrac{\pi}{4}\right)\cup \left(\dfrac{\pi}{2}, \dfrac{5\pi}{4}\right) \cup \left(\dfrac{3\pi}{2}, 2\pi\right)$ But the answer given in the book is $x$ belongs to $\left(0, \dfrac{\pi}{4}\right)\cup \left(\dfrac{5\pi}{4}, 2\pi\right)$ . Any help.","['calculus', 'trigonometry', 'inequality']"
3538289,"What makes two things (or two representations of a thing) ""the same""?","This is an extremely general question, so I'm going to use fields as a specific example and hopefully work from there. Keep in mind, though, that a similar ""re-encoding"" process can be performed for just about anything which is suitably algebra/structure-like: topological spaces, lattices, relational algebras, logics, even languages. Note: In this context $2\times F=\{0,1\}\times F=F\sqcup F=\cdots$ Let $\mathcal{F}=\langle F,+,\cdot\rangle$ be a field . Let $Cd(\mathcal{F})=\langle 2\times F,*\rangle$ , where $*:(2\times F)^2\to2\times F$ is defined as follows: $$x*y=\begin{cases}(0,x_2+y_2)&x_1=y_1=0\\(0,x_2\cdot y_2)&x_1\ne y_1\\(1,x_2\cdot y_2)&x_1=y_1=1\end{cases}$$ Observe that $Cd(\mathcal{F})$ satisfies the following axioms: Associativity: $$x_1=y_1=z_1\implies x*(y*z)=(x*y)*z$$ Commutativity: $$x*y=y*x$$ Distributivity: $$x_1=1\land y_1=z_1=0\implies x*(y*z)=(x*y)*(x*z)$$ Identity: $$x_1=i\implies x*e^i=e^i*x=x\quad:\quad i=1,2$$ Inverse: $$x_1=i\implies x*\overline{x}=\overline{x}*x=e^i\quad:\quad x\ne(1,0)$$ Clearly, $\mathcal{F}\ne Cd(\mathcal{F})$ , nor is $\mathcal{F}$ isomorphic to $Cd(\mathcal{F})$ ; $Cd(\mathcal{F})$ is not even a field! Yet $Cd(\mathcal{F})$ is similar to $\mathcal{F}$ in extremely obvious ways, to the extent that $\mathcal{F}$ and $Cd(\mathcal{F})$ are ""basically the same thing,"" or, at the very least, $\mathcal{F}$ and $Cd(\mathcal{F})$ ""encode"" the same thing. Of course, without clarification, any two things can be likened to one another, regardless of how disimilar they actually are. One could easily say that a group is ""basically the same"" as a Lie algebra and proceed to justify why this is the case - but such an arbitrary comparison is intuitively less reasonable than that made above. Since there are clearly ""reasonable"" and ""unreasonable"" comparisons, there ought to be a way to distinguish between them. This leads me to my question: how can I formalise the notion of ""sameness""? Is it possible to define a single ""sameness"" relation, or are there distinct classes of ""sameness""? Update: The notion which I am trying to capture is that $A$ and $B$ are the ""same"" if $A$ can encode $B$ and $B$ can encode $A$ . The relation in question ranges over [classes of] structures, theories, categories, or languages ( provided that ""language"" comes with rewrite rules and/or semantics); these can be used almost interchangeably because for any structure, there is a ""theory of that structure"" (up to isomorphism), for any theory, there is a ""category of that theory,"" etc. After doing some reading, I can confidently say that ""sameness,"" as presented in the example, is distinct from polynomial equivalence, term equivalence, and isotopy. This is because each of these relations apply only to algebras over the same set/universe. Even extending these notions to ""polynomial/term isomorphism"" - if that's a thing - does not account for the differences between $\mathcal{F}$ and $Cd(\mathcal{F})$ because any map between $F$ and $2\times F$ which would be suitably ""isomorphism-like"" would have to send each element of $F$ to two elements in $2\times F$ . It might be possible to bijectively map $n$ -tuples of elements and operations of $\mathcal{F}$ to those of $Cd(\mathcal{F})$ in a way that preserves the algebraic properties of $\mathcal{F}$ . At this point, I think it would be helpful to try and create a hierarchy (or partial order) of equivalence relations ordered by logical implication. My ""sameness"" relation ought to be ""that thing just above 'term-isomorphism'."" This seems like a more fruitful approach, since it would both clarify the particular relation I am talking about while and shine a light on the connection with other, ""nearby"" relations (like term-equivalence).","['universal-algebra', 'intuition', 'abstract-algebra', 'category-theory']"
3538345,Integral $\int_0^{\pi/2}x\arctan\left(\tfrac{1}{\sqrt3}+\tfrac{2}{\sqrt3}\tan x\right)dx$,"Evaluate the integral $$P=\int_0^{\pi/2}x\arctan\left(\tfrac{1}{\sqrt3}+\tfrac{2}{\sqrt3}\tan x\right)dx.$$ Context: I started trying to evaluate the integral $$J=\int_0^\infty \frac{\arctan(x)^2}{x^2+x+1}dx,$$ and the integral $P$ is part of the process. At first, I tried $x\mapsto 1/x$ , but it just ended up showing that $$J=\frac{\pi^2}{4}\int_0^\infty \frac{dx}{x^2+x+1}-\pi\int_0^\infty \frac{\arctan x}{x^2+x+1}dx+J,$$ which is of no use. Next, I tried integration by parts, using $$\int\frac{dx}{x^2+x+1}=\frac{2}{\sqrt3}\arctan\frac{2x+1}{\sqrt3},$$ so that $$J=\frac{\pi^3}{4\sqrt3}-\frac{4}{\sqrt3}\int_0^\infty\arctan(x)\arctan\left(\tfrac1{\sqrt3}+\tfrac{2}{\sqrt3}x\right)\frac{dx}{1+x^2}.$$ Then with $x\mapsto \tan x$ we have $$J=\frac{\pi^3}{4\sqrt3}-\frac{4}{\sqrt3}P.$$ Theoretically, integration by parts if possible from this point, as Wolfram provides an awful closed form for the anti-derivative of $\arctan\left(\tfrac{1}{\sqrt3}+\tfrac{2}{\sqrt3}\tan x\right)$ , but I do not think this is really that realistic of an approach. Is there a better way to evaluate the integral $P$ ?","['integration', 'definite-integrals', 'real-analysis', 'trigonometric-integrals', 'closed-form']"
3538379,Difference equation with one definition for odd $n$ and another for $n$ even.,"Let us define the difference equation: $u_{n+1} - au_n + u_{n-1} = 0 $ , if $n$ is odd, $u_{n+1} - bu_n + u_{n-1} = 0$ , if $n$ is even. I've been struggling to solve this equation for the last few days and I'm very stuck. I know that if either of the equations above was standalone $\forall n$ it would be a simple characteristic equation, but I'm not sure what to do here with how to split into an odd or even cases. I thought about writing $u_n$ in a piecewise way: $u_n=v_n$ for $n$ odd and $u_n = w_n$ for $n$ even. And treating it as a system: $v_{n+1} - av_n + v_{n-1} = 0$ $w_{n+1} - bw_n + w_{n-1} = 0$$ But I didn't get very far with this approach. Thank you for your help.","['recurrence-relations', 'discrete-mathematics']"
3538382,binomial determinant,"Let $n > 0$ , then : $$ \det \left( {2n \choose n+i-j} \right)_{i,j=0}^{n-1} = \prod_{i=0}^{n-1} \frac{2n+i \choose n}{n+i \choose n}  $$ The LHS appears to be the determinant of a symetric Toeplitz matrix with binomial coefficients. Does anyone have an idea on how to proove this formula ?","['matrices', 'determinant']"
3538439,A circle and an ellipse,"Consider an ellipse and a circle inside it. They have the same center. Let $P$ be a moving point on the ellipse. Through $P$ , draw the two tangents to the circle, which meet the ellipse at $A,B$ . Again, through $A,B$ respectively, draw the tangents to the circle, which meets each other at $Q$ . What's the locus of $Q$ ? By software graphing, it seems to be an ellipse too. But how to prove this without much computation? It's better to explain by projective geometry .","['projective-geometry', 'geometry']"
3538459,On proving that a finitely generated group has a finite number of subgroups with index $n$.,"Theorem : If $G$ is a finitely generated group, then it has a finite (maybe zero) number of subgroups of index $n$ for any $n\in \mathbb{N}$ . Here is a sketch of a proof. It consists of assuming such a subgroup $H$ exists, and allowing $G$ to act on $G/H$ by left multiplication. Such action defines a homomorphism $$\phi :G \rightarrow \text{Sym}(G/H)\cong \mathbb{S}_n$$ If $G=\langle g_1, \ldots ,g_r\rangle$ , then the homomorphism is uniquely determined by where it sends the generators $g_i$ . In particular, there are at most $(n!)^r$ such homomorphisms. The last step of the proof requires one to notice that a different subgroup $H'$ of index $n$ in $G$ would produce a different homomorphism, and here is where I'm struggling. I've been able to show that $\text{ker}(\phi )=\text{core}(H)$ , yet haven't been able to rule out the possibility of $\text{core}(H)=\text{core}(H')$ .","['proof-explanation', 'combinatorial-group-theory', 'abstract-algebra', 'group-theory', 'group-actions']"
3538591,$\{T_n\}$ Folner $\implies \{S_n\} = \{\bigcup_{k=1}^{n}T_k\}$ Folner?,"Given an countable amenable group $G$ , let $\{T_n\}_{n \in \mathbb{N}}$ be a Folner sequence for $G$ , i.e., $\lim_{n \to +\infty} \frac{|gT_n \Delta T_n|}{|T_n|} = 0$ , for every $g \in G$ . Now, for each $n \in \mathbb{N}$ , consider $S_n = \bigcup_{k=1}^n T_k$ . My question is whether or not $\{S_n\}_{n \in \mathbb{N}}$ is a Folner sequence. Obviously, if $\{T_n\}$ is increasing, the answer is yes, but I am not being able to prove the case when $\{T_n\}$ is not increasing and I don't even know if this is true. What I did so far is: given $g \in G$ and $n \in \mathbb{N}$ , \begin{align*}
\frac{|gS_n \Delta S_n|}{|S_n|} &\leq \frac{|\bigcup_{k=1}^n(gT_k \Delta T_k)|}{|S_n|}\\
&\leq \frac{\sum_{k=1}^{n}|gT_k \Delta T_K|}{|S_n|}\\
&= \sum_{k=1}^{n} \frac{|gT_k \Delta T_K|}{|S_n|}\\
&= \sum_{k=1}^{n} \frac{|gT_k \Delta T_K|}{|T_k|}
\end{align*} and I know that what is inside the sum goes to zero, but this does not help me (or at least I don't see how it could help me). Does someone know how to prove it or have a counterexample?","['amenability', 'group-theory']"
3538593,Partial Sum of Random Variables - Order Statistics,"Let $U_1, U_2,\ldots,U_n$ be iid uniform random variables on $[0,1]$ . $U_{1,n}\leq U_{2,n}\leq\cdots\leq U_{n,n}$ be the order statistics. Show that, as $\frac{k_n}{n}\to p$ and $0\leq p\leq 1$ $$\frac{\sqrt{n}(U_{k_n,n}-\frac{k_n}{n+1})}{p(1-p)^{1/2}} \to N(0,1)$$ This is what I have tried: Using Renyi Rerepresentation: $$U_{k_n,n} = \frac{S(k_n)}{S(n+1)}$$ $$U_{k_n,n}-\frac{k_n}{n+1}=\frac{S(k_n)-k_n}{S(n+1)}-\frac{(S(n+1)-(n+1))k_n}{(n+1)S(n+1)}$$ This is where I get stuck Eventually I want to get to something like $\frac{S(k_n)-k_n}{\sqrt{k_n}}$ multiply by other fractions, those fractions converge to 1 and the whole transformation converges to $N(0,1)$","['statistics', 'central-limit-theorem', 'weak-convergence', 'order-statistics', 'sequences-and-series']"
3538650,Sum of magnitudes of coefficients of polynomial $(x-1)(x-2)(x-3)\cdots(x-(n-1))$,"The title says most of it. I have found that the sum of the coefficients of the polynomial $(x-1)(x-2)(x-3)\cdots(x-(n-1))$ yields $n!$ . For example, the coefficients of the polynomial $(x-1)(x-2)$ sum to $1+3+2=6=3!$ and similarly the coefficients of $(x-1)(x-2)(x-3)$ sum to $1+6+11+6=24=4!$ . My question, then is how might I prove this more generally. I have the feeling that induction might be an optimal way to go about this, but am unsure of the specifics. Any help is appreciated!","['algebra-precalculus', 'proof-writing', 'polynomials']"
3538652,Frobenius norm and operator norm inequality,"Let $A$ be a $k\times m$ matrix and B be a $m\times n$ matrix, I wonder how to prove the following inequality $$\|AB\|_F\le\|A\| \|B\|_F,$$ where $\|\cdot\|_F$ is the Frobenius norm (square root of the sum of all squared entries and $\|\cdot\|$ is the 2-operator norm ) Note if $n=1$ , i.e when $B$ is a column vector, this just follows from the definition of the operator norm. But I don't know how to deal with the general case. I have thought about using SVD of $A,B$ but don't know how to simplify the LHS. Any approach will be appreciated!","['matrix-calculus', 'linear-algebra', 'functional-analysis']"
3538677,Properties of Orientation Covering: Lee's Construction,"Let $M$ be a smooth, connected manifold of dimension $n>1$ , and $\mathscr O_p$ an orientation of $T_pM$ . define $\widehat M=\{(p,\mathscr O_p)\}_{p\in M}$ . Then, $\widehat M$ can be made into an oriented manifold. To do this, define the projection $\hat \pi:(p,\mathscr O_p)\mapsto p,$ let $\mathscr O$ be an orientation on $U\in  \tau_M$ and declare the basis elements in $\widehat M$ to be $\widehat U_{\mathscr O}=\{(p,\mathscr O_p):p\in U\}.$ This assignment induces a topology on $\widehat M$ . No problems so far. We have $1).\ \widehat M$ is basically two copies of $M$ , because there are two orentations for $T_pM$ , which are in turn equivalence classes of bases for $T_pM:(X_i)\sim (Y_i)\Leftrightarrow $ the change of basis matrix beteween them has positive determinant. $2).\ $ The orientation $\mathscr O$ on $U$ is induced by a chart $(\phi,U)$ on $M$ . $3).\hat \pi$ is a generalized covering map ( $\widehat M$ need not be connected). So far so good. Now, paraphrasing Lee, $4).\ $ Using $\hat \pi$ we can define a pointwise orientation on $T_{(p,\mathscr O_p)}\widehat M$ : we have that $(\pi_*)_p:T_{(p,\mathscr O_p)}\widehat M\to T_pM$ . We can define a pointwise orientation as the ""unique orientation such that $(\pi_*)_p$ os orientation-preserving."" The orientation on $T_pM$ is either $\mathscr O_p$ or $-\mathscr O_p$ . Is Lee saying that we pick one, compute the det of $\hat \pi_*$ and if it comes out positive, then we assign that as the orientation of $T_{(p,\mathscr O_p)}\widehat M$ , and if not then we take the opposite orientation? I am confused. $5).\ $ The orientation defined in $3).$ agrees with the pullback induced by $\hat \pi$ from $(U,\mathscr O)$ so the pointwise orientation is continuous. I computed the pullback but have not been able to show that the orientation it induces agrees with the previous one. Here is the paragraph from Lee's book that I am having trouble with: I have seen this construction using top forms (Jeffrey Lee), and homology (Hatcher) both of which I understand (I think!), but I want to understand clearly what is going on in Lee's construction, because it is very basic which  means that I am missing some fundamental ideas, which I want to get straight.","['smooth-manifolds', 'orientation', 'covering-spaces', 'algebraic-topology', 'differential-geometry']"
3538719,Differential forms without derivatives?,"Recently, I've drawn increasingly attracted to using differential forms for routine calculus computations - for instance, I've come to like the equation $$dy=2x\,dx$$ which clearly states that the rate of change of $y$ is $2x$ times the rate of change of $x$ far better than the equation $$\frac{dy}{dx}=2x$$ which states that ""the derivative of $y$ with respect to $x$ "" (whatever that means) is $2x$ . I like the former equation due to the way that the differential form notation easily generalizes to many dimensions (since rates of change can be written as sums of several other rates, if desired), to implicit equations (since no variable is prioritized), and to problems involving multiple variables with relations between them (since differential forms allow for substitution just the same as any other object we do algebra with). While it's easy enough to explain the notation of differential forms intuitively - and indeed, that is why I like them - it seems very difficult to pin down what they are formally for someone who is unfamiliar with calculus and linear algebra, since the usual definition of ""A differential 1-form on a smooth manifold is an a section of the cotangent space of the manifold"" rests upon a solid foundation in the calculus of functions $\mathbb R^n\rightarrow\mathbb R^n$ - so is pretty useless for explanation! In particular, suppose I wanted to set up an intuitive framework where we imagine $y=x^2$ as defining a parabola that we may freely move upon. It's not so hard to see that if $x$ is negative, then increasing $x$ would decrease $y$ and if $x$ is positive, increasing $x$ increases $y$ - and that as we get further from $x=0$ , changing $x$ by a little by changes $y$ by an ever growing proportion - and that we could also, equally well, imagine changing $y$ and see what happens to $x$ . Basically, we have some set of states that we could be in, and we recognize that, if we had some ""velocity"" and were changing the state in some smooth manner, the quantities $y$ and $x$ would also be changing at some rates - and the way that these changes responded to a change in state are somehow encapsulated in the symbols $dy$ and $dx$ - and finally, that these rates turn out to be related if $y$ always equals $x^2$ . This seems all well and good until you want to define $dx$ and $dy$ and to try to prove $dy=2x\,dx$ . This formal side works out fine if you take the usual quotient $\lim_{h\rightarrow 0}\frac{(y+h)^2 - y^2}{h}$ and while this might be fine later to argue about a relation, it doesn't get us any closer to understanding what $dx$ and $dy$ are - and we'd be breaking an inherent symmetry of the differential forms by declaring that our theory only will work if $y$ is a function of $x$ . We could think about parameterized curves on $y=x^2$ and define instantaneous velocity, and say that $dy$ and $dx$ are (linear) rules for assigning rates of change to these velocities, but now our differential forms look very abstract - and we still had to define calculus to define velocity. Maybe we could more explicitly try to think of differential forms as ""local approximations of a function up to a linear term"", but this seems rather abstract. The most promising idea I can think of would be to search of a way to satisfying describe a tangent space as some sort of space of allowed ""velocities"" at a point on a curve/surface and then to define differential forms on that space - but I don't have a good sense of how to do this. Is there a good way to explain differential 1-forms as the fundamental objects of calculus, without relying upon pre-existing calculus knowledge?","['calculus', 'differential-forms', 'differential-geometry']"
3538729,delta-epsilon definition of a limit,Suppose $\displaystyle \lim_{n\to \infty}x_n=-\infty$ . I want to know the form of delta-epsilon definition. Can we write it as: there exists $n_0\in \Bbb N$ such that $x_n<-n$ whenever $n\ge n_0$ . ?,"['limits', 'epsilon-delta', 'analysis', 'real-analysis']"
3538737,Similar Matrices and Conjugate Flows,"This question is an attempt to resuscitate and generalize this question , which lived one hour and was deleted by its author for reasons unknown. The notion of topological conjugacy of flows is central to the theories of dynamical systems and ordinary differential equations, for it formalizes the concept that the orbit structure of two flows may be equivalent; that is, that the flows exhibit essentially the same behavior.  Specifically, we say that two flows $\phi_A$ and $\phi_B$ on a topological space $X$ are conjugate when there exists a homeomorphism $h:X \to X \tag 1$ such that for all $x \in X$ and $t \in \Bbb R$ $h(\phi_A(x, t)) = \phi_B(h(x), t). \tag 2$ A simple and particularly useful class of flows arises from linear time-invariant ordinary differential equations $\dot x = Ax, \tag 3$ where we assume $x \in \Bbb C^n \tag 4$ and $A \in M(n, \Bbb C), \tag 5$ the set of square complex matrices of size $n$ ; the solution to (3) which takes the value $x(t_0)$ at $t_0$ is well-known to be $x(t) = e^{A(t - t_0)}x(t_0); \tag 6$ thus the flow of (3) is given by $\phi_A(x, t) = e^{At} x. \tag 7$ We recall that two matrices $A, B \in M(n, \Bbb C) \tag 8$ are said to be similar if there exists a non-singular matrix $T \in M(n, \Bbb C) \tag 9$ such that $B = TAT^{-1}. \tag{10}$ The Question is then: Show that there is a linear homeomorphism $T: \Bbb C^n \to \Bbb C^n \tag{11}$ conjugating $\phi_A(x, t)$ and $\phi_B(x, t)$ if and only if $A$ and $B$ are $T$ -similar, that is, $B = TAT^{-1}. \tag{12}$ If $A$ and $B$ are real matrices, must $T$ also be real? Note Added in Edit, Saturday 8 February 2020, 11:25 AM PST: In light of Conifold's comment, we see that the existence of a suitable real $T$ gives rise to a purely imaginary matrix $iT$ which also satisfies the requisite conditions.  Therefore I modify my closing question above and ask If $A$ and $B$ are real matrices, must $T$ be either purely real or purely imaginary? End of Note.","['linear-algebra', 'ordinary-differential-equations', 'dynamical-systems']"
3538744,"If $f''\ge 0$, prove that $f(x+f'(x)) \ge f(x)$","Question: $f$ and $f'$ are differentiable, and $f''\ge 0$ . Then, prove that $\forall x \in \mathbb R$ , $f(x+f'(x))\ge f(x)$ . Since $f''\ge 0$ , I'd like to apply Jensen's theorem, which is: $$f(tx_1 + (1-t)x_2) \le tf(x_1) + (1-t)f(x_2) $$ However, it was hard to determine the value of $x_1$ and $x_2$ .
Another way came up to my mind was to set the new function $$g(x)=f(x+f'(x))-f(x)$$ and prove that $g(x)\ge 0$ by using $g'(x)$ . Unfortunately, when we calculate the derivation of $g(x)$ as following: $$ g'(x)= f''(x)f'(x+f'(x))-f'(x)$$ eventually, there was nothing I can find. Could you give some key points to this proof?
Thanks for your advice.","['calculus', 'functional-inequalities', 'convex-analysis', 'functional-analysis']"
3538758,Show that $2(a-b)$ is a period of $f$.,I am trying to show that: f(x) is a function and there exists real constants $a>b$ such that $$f(a+x)=f(a-x) $$ and $$f(b+x)=f(b-x)$$ for every real number ${x}$ . Show that $2(a-b)$ is a period of $f$ .,['functions']
3538807,Conditions that ensure a convex function is log-concave?,"Suppose we have a convex function $g(x)$ (i'm particularly interested in $g(x)$ decreasing but that's not a requirement for an answer) Are there necessary or sufficient condition(s) that we can look at to examine whether $\log g(x)$ is concave? Looking at some examples: an affine function is convex and log-concave $x^2, x^4$ , etc are convex and log-concave $e^x$ is log concave $e^{x^2}$ is not log concave So a crude guess might be that a convex function is log-concave if it does not increase ""too fast"". But I don't know if this is correct, and even if it is, I don't know what ""too fast"" is (is $e^x$ the limit?)","['convex-optimization', 'convex-analysis', 'derivatives']"
3538844,Is there a standard definition of $\sum_{-\infty}^{+\infty} a_n$? [duplicate],"This question already has answers here : Definition of convergence of $\sum_{i=-\infty}^\infty a_i$ (2 answers) Closed 4 years ago . In my class of Time Series, the professor mentioned about the sequence of real numbers $(a_n)_{n \in \mathbb Z}$ and the sum $$\sum_{-\infty}^{+\infty} a_n$$ I've searched on the Internet but could not find a definition for the sum from $-\infty$ to $+\infty$ . Is there a standard definition for this kind of sum?","['summation', 'definition', 'sequences-and-series']"
3538856,Relation between steps and turns in a simple symmetric random walk,"Let $S_0 = 0, S_n = X_1 + X_2 + \dots + X_n$ , $n\ge 1$ , be a simple symmetric random walk, i.e. $X_i$ , $i\ge 1$ , are iid random variables with $\mathrm P(X_i = 1) = \mathrm P(X_i = -1) = 1/2$ . Denote $\tau = \inf\{n\ge 1: S_n = 0\}$ the time of steps the random walker makes before returning to zero, and let also $\sigma = \#\{1\le k\le \tau-1: X_k X_{k+1} = -1\}$ be the number of turns the walker made. Is it true that $$
\mathrm{E} [\tau - 2\sigma] = 1?\tag{1}
$$ The problem here is that $\mathrm{E} [\tau] = \mathrm{E} [\sigma] = \infty$ . Here are some ideas why $(1)$ may be true: For any $x\in \mathbb Z$ , denote $\tau(x) = \#\{0\le k\le \tau-1: S_k = x \}$ the number of steps made from $x$ and $\sigma(x) = \#\{1\le k\le \tau-1: S_k = x, X_k X_{k+1} = -1\}$ the number of turns made in $x$ , $\alpha(x) = \tau(x) - 2\sigma(x)$ . Then, $\alpha(0) = 1$ , and it is easy to show that $\mathrm{E} [\alpha(x)] = 0$ , $x\neq 0$ . However, despite that $\tau - 2\sigma = \sum_{x\in \mathbb Z} \alpha(x)$ , this does not immediately imply $(1)$ : something is needed to swap the sum and expectation signs. Denote $\sigma_n = \#\{1\le k\le n-1: X_k X_{k+1} = -1\}$ , the number of turns before moment $n\ge 1$ and let $M_n = n - 2\sigma_n$ . Then, $M_n$ is a martingale (actually, a simple symmetric random walk) starting from $M_1 = 1$ , and $\tau - 2\sigma = M_\tau$ . But this also does not imply $(1)$ . There are some related approaches, including certain direct enumeration, which confirm $(1)$ but lack rigor. In order to validate these arguments, it suffices to prove that $$
\mathrm{E} [|\tau - 2\sigma|]<\infty.
$$ Edit: the symmetry is false. Indeed, $\mathrm{P}(\tau-2\sigma=0) > \mathrm{P}(\tau=2) =1/2$ . Unfortunately, I can't edit the bounty description.","['random-walk', 'expected-value', 'combinatorics', 'martingales', 'probability']"
3538882,Injective Lie Group Homomorphism is Immersion? [duplicate],"This question already has answers here : $\varphi:G\to H$ is a Lie Group Homomorphism, then $\ker \varphi$ has Lie algebra $\ker D_e \varphi$ (2 answers) Closed 4 years ago . How do I prove the claim of the title? My definition of Lie Group homomorphism is a smooth group homomorphism. 
I have to show that $Df(e)(v)=0$ will imply $v=0$ . Viewing this as a derivation, this means $Df(e)(v)(g)=0$ for all smooth functions $g$ on $H$ . Here $f$ is the Lie group homomorphism from $G$ to $H$ .","['smooth-manifolds', 'lie-groups', 'differential-geometry']"
3538893,How many 4 digit numbers without $0$ between $1000$ and $9999$ are divisible by $3$?,"Determine the number of numbers we can make between $1000$ and $9999$ of $4$ different digits without $0$ . How many of those numbers are
  divisible by $3$ ? To calculate how many numbers there are between $1000$ and $9999$ of $4$ different digits without $0$ , we calculate $9*8*7*6=3024$ . To calculate how many of those numbers are divisible by $3$ , I tried to combine that the sum of the digits must be divisible by $3$ and the stars and bars theorem. Since we have 4 different digits the maximum sum of the digits is $9+8+7+6=30$ and the minimum is $1+2+3+4=10$ . The possible sums of the digits for which the number is divisible by $3$ are thus $12,15,18,21,24,27$ and $30$ . But with the stars and bars I didn't really know how to do its because we have to have 4 different digits and no zeros. The solution my book gave was simply $42*4!$ , so I think I'm on the wrong track, but  I have no idea how they got to their solution. Any nudge in the right direction is appreciated :) EDIT I figured out the solution from my book. If we take the numbers 1 to 9 we can divide them in 3 sets mod 3.
0 mod 3  would be the numbers {3,6,9} 1 mod 3 would be the numbers {1,4,7} 2 mod 3 would be the numbers {2,5,8} Now we can use that the sum of the 4 digits must be $0$ . We can take 1 number from the 0 mod 3 set and 3 from the 1 mod 3 set, for example 3147. There are 4! ways to use the numbers {3,4,1,7}. There are 3 ways to select 1 number from 0 mod 3 set and 3 from the 1 mod 3 set. Other ways to get a sum of 3: 2 numbers from the 0 mod 3 + 1 number from 2 mod 3+ 1 number from 1 mod 3. There are 3*3*3=27 ways to do this. 3 numbers from 2 mod 3+1 from  0 mod 3 . There are 3 ways to do this. 2 numbers from 1 mod 3 + 2 numbers from 2 mod 3. There are 3*3= 9 ways to do this. So there are  3+27+3+9=42 ways to get a 4 digit number with sum equal to 3, and we have 4! ways to rearrange those numbers, so 42*4! numbers between 1000 and 9999  comply with all the requirements.",['discrete-mathematics']
3538901,Nice exercises on Hilbert's basis theorem,"I am teaching an extremely basic course in algebraic geometry and I would like to find more exercises on Hilbert's basis theorem , a result from commutative algebra. Unfortunately, I have not been able so far to find interesting exercises in all the books and lecture notes that I've seen. Could you advise me some exercises on this topic?","['abstract-algebra', 'commutative-algebra', 'reference-request']"
3538920,Constructing an outer measure on a set whose measurable sets are exactly a given sigma algebra on the set.,"Consider an arbitrary set $X$ and an arbitrary $\sigma$ -algebra $\mathcal{M}$ on $X$ . My question is that can one construct an outer measure on the set $X$ whose measurable sets is exactly the collection $\mathcal{M}$ . I tried to find an answer for finite sets and found this proposition to be true. The solution is, let $X$ -finite set, $\mathcal{M}$ -algebra on $X$ (and hence a $\sigma$ -algebra on $X$ ) and $\mu_{0}(A)=|A|$ (cardinality of A) $\forall A \in \mathcal{M}$ . It is easy to verify that $\mu_{0}$ is a pre-measure on the algebra $\mathcal{M}$ as $\mu_{0}(\emptyset)=0$ and it is countably additive (over here only finite additivity suffices). Thus we construct the outer measure on $\mathcal{P}(X)$ using $\mu_{0}$ , call it $\mu^*$ . Let $B\subset X(\notin \mathcal{M})$ . So $(X\setminus B) \notin \mathcal{M}$ . Then $\mu^*(B)>|B|$ as all the elements of $\mathcal{M}$ containing $B$ has higher cardinality. If possible $B$ is $\mu^*$ -measurable. So we can check $|X|=\mu^*(X)= \mu^*(B) + \mu^*(X\setminus B)>|B|+|X\setminus B|=|X|$ . Hence this is a contradiction and hence $B$ is not $\mu^*$ -measurable. Hence the only $\mu^*$ -measurable sets are the sets in $\mathcal{M}$ . I have no idea how to proceed with this problem for infinite sets and maybe more general cases. Any kind of help and idea is highly appreciated. Thanks. Edit: I also figured out that even in infinite sets, if the concerned $\sigma$ - algebra is a finite one, we can define a pre-measure on it in the same way and check that these are the only measurable sets.","['measure-theory', 'outer-measure']"
3538935,"Average decrease of a random number in ""subtracting every prime by one in factorization""","Question : Consider $n=p_1^{\alpha_1}\cdots p_\omega^{\alpha_\omega}$ be the prime factorization of $n$ . Define $a(n)=(p_1-1)^{\alpha_1}\cdots (p_\omega-1)^{\alpha_\omega}$ and $A(n)=\sum_{k\le n}a(k)$ . Calculate the value of $$\lim_{n\to\infty}\frac{A(n)}{n^2/2}.$$ Hence deduce the average order of $a(n)$ . Quick Result $a$ is a completely multiplicative function with $a(p)=p-1$ . Attempt It is not hard to see $a$ is the Dirichlet inverse of $\mu\cdot\varphi$ , where $\cdot$ denotes the ordinary multiplication. Hence, the Dirichlet generating function of $a$ is $$\left(\sum_{n=1}^\infty\frac{\mu(n)\varphi(n)}{n^s}\right)^{-1}=\prod_{p}\frac{1}{1-p^{-s}(p-1)}$$ But the Dirichlet g.f. can be also written as $$\sum_{n=1}^{\infty}{\frac{a(n)}{n^s}}=1+\sum_{n=1}^{\infty}{A(n) \left( \frac{1}{n^s}-\frac{1}{\left( n+1 \right) ^s} \right)}=1+s\int_1^{\infty}{\frac{A( x )}{x^{s+1}}\mathrm{d}x}$$ Apply inverse Mellin transform, for $x>1$ , $$A( x ) =\frac{1}{2\pi}\int_{-\infty}^{\infty}{\frac{x^z}{z}\left( \sum_{n=1}^{\infty}{\frac{a(n)}{n^z}} -1 \right) \text{d}t},\ (z=\sigma +it,\ \sigma>2)
\\
=\frac{1}{2\pi}\int_{-\infty}^{\infty}{\frac{x^z}{z} \prod_p\frac{1}{1-p^{-z}( p-1 )} \mathrm{d}t}-1
$$ So the next thing may be investigating $\prod_p\frac{1}{1-p^{-z}\ ( p-1 )}$ , but I am not able to do that. Computational Result Mathematica suggests that the limit $\lim_{n\to\infty}\frac{A(n)}{n^2}\approx0.25727$ and even $A(n)=Cn^2+o(n\ln n)$ for some constant $C$ .","['complex-analysis', 'number-theory', 'limits', 'asymptotics']"
3538941,Find $f(x) = \lim_{n\to\infty}\frac{\lfloor x \rfloor + \cdots + \lfloor x^n \rfloor}{x^n}$,"I found this cool problem in a textbook. I googled it and used MSE's search tool to check if it has been asked before or not, but it seems that it hasn't been asked before. Find the function $f(x)$ that the following limit defines: $$f(x) = \lim_{n\to\infty}\frac{\lfloor x \rfloor + \cdots + \lfloor x^n \rfloor}{x^n}$$ I have already solved it and I have shared my solution as an answer. Other solutions are welcome too.","['limits', 'calculus', 'ceiling-and-floor-functions']"
3538960,Show that $\int\limits_0^1 \left(x^{x}\right)^{\left(x^{x}\right)^{\left(x^{x}\right)^{\left(x^{x}\right)^{⋰}}}}\ \mathrm{d}x=\frac{\pi^2}{12}$.,How can it be shown that $$\lim_{p\to\infty}I(p)= \lim_{p \to \infty}\int^{1}_0 (x^x)^{\scriptscriptstyle {(x^x)^{(x^x)^{(x^x)^{(x^x)^{(x^x)...(p \; times)}}}}}} dx= \frac{\pi^2}{12}$$ $I(1)=\int^{1}_0 x^x dx=\sum_{n=0} ^{\infty} \frac{1}{n!}\int^{1}_0 \ln(x)^nx^n dx$ also $\int^{1}_0 \ln(x)^nx^n dx=(-1)^n (1+n)^{-1-n}n!$ . I don't know how to calculate $I(p)$ beyond $p=1.$ Note: This integral was proposed on Romanian Mathematical Magazine and two solutions can be found here .,"['integration', 'definite-integrals', 'pi', 'limits', 'tetration']"
3538971,Wrong inverse function,"Let $f: P(\mathbb{N})\to P(\mathbb{N})  $ $$f(A) = \{x|x-4\in A\}$$ What if the inverse function of this function? I thought it's $ g:P(\mathbb{N})\to P(\mathbb{N})  $ such that $$g(A) = \{x|x\in A\}\cup\{x-4|x\in A\}$$ An example would be $f(\{5,1\})=\{5\}$ , and $g(\{5\})=\{5,1\}$ But apparently this is not the correct answer. What is my mistake?","['elementary-set-theory', 'functions', 'discrete-mathematics']"
3538999,Nonexistence of a simple group of order 420,"From Dummit & Foote, Abstract Algebra , $\S6.2$ , Exercise 17(a). Prove that there is no simple group of order 420. Suppose not; label such group $G$ . the number of Sylow 7-subgroups of $G$ is 15. Let $G$ act on the set of Sylow 7-subgroups (denoted hereon by ""letters"") by conjugation. There is only one orbit of size 15 (by Sylow 2nd), thus each stabilizer on one letter has size 420/15 = 28. The action induces an injective homomorphism of $G$ into $A_{15}$ . Each stabilizer on a single letter should have an element of order 7 (by Cauchy), permuting the remaining 14 letters. Naturally, this element then generates the unique Sylow 7 within the stabilizer. I now assume that the element of order 7 is a product of 2 disjoint 7-cycles. Is this valid, and why? In particular, am I able to eliminate the possibility of the element being a single 7-cycle? If the above assumption is valid, then I am now able to eliminate the possibility of order 14 and 28 elements, since order 14 implies single 14-cycle (odd) or product of single 7-cycle and some 2-cycles (2nd power is single 7-cycle), likewise for order 28. Now use the fact that the Sylow 7 is normal within the stabilizer: the permutations that sends a 7-cycle to its power by conjugation is either a product of 3 2-cycles (sends to inverse), 2 3-cycles (sends to 2nd/4th power), or a 6-cycle (sends to 3rd/5th power). By similar calculations, permutations that switch between the two 7-cycles are either 7 2-cycles, a 2-cycle and 3 4-cycles, a 2-cycle and 2 6-cycles, a 2-cycle and a 12-cycle, or a 14-cycle. Since the remaining elements are either order 2 and 4, our choices are either 6 2-cycles, 7 2-cycles (odd), or a 2-cycle and 3 4-cycles (third power breaks the pairing of the two 7-cycles). Are my calculations and reasoning correct here? The pair of fixed letters in the 2 7-cycles then determines the whole of the permutation, but noting that the two different fixed letter 2-cycles (per 1 7-cycle) result in a product of a 7-cycle, we conclude that the pairings of fixed letters must be disjoint for two different elements. Then, the number of possible remaining elements is 7 out of a required 21; contradiction. In general, is there a cleaner way to go about this exercise, or proving nonexistence of groups of some highly composite order? I only know the method of embedding the group in an alternating group and trying to derive a contradiction from there (outside the usual repertoire).","['finite-groups', 'simple-groups', 'abstract-algebra', 'sylow-theory', 'group-theory']"
3539024,"Is the map $re^{i\theta} \to re^{i\alpha\theta}$ in $W^{1,2}$?","Let $\alpha>1$ be a real number, and consider the map $F$ defined on the closed unit two-dimensional disk $D \subseteq \mathbb{R}^2$ after removing a ray, by $re^{i\theta} \to re^{i\alpha\theta}$ . Does $F \in W^{1,2}(D,\mathbb{R}^2)$ ? When $\alpha=n$ is a positive integer, I proved that the answer is positive (see below, I hope I don't have a mistake). I am not sure what to do when $\alpha \notin \mathbb{N}$ . The main difference is that when $\alpha=n$ is a positive integer, we have that $F(z)=F(re^{i\theta})= re^{in\theta}=\frac{z^n}{|z|^{n-1}}$ is defined and smooth on the entire disk without the origin $D \setminus \{0\}$ . However, when $\alpha \notin \mathbb{N}$ , we have to use the complex logarithm in order to define $F$ , so (I think) we only get a well-defined map which smooth on the disk with a ray removed from it. Here is the computation that shows that $F \in W^{1,2}$ when $\alpha=n$ is an integer: $F(z)=\frac{z^n}{|z|^{n-1}}=\big( \frac{z}{|z|^{\frac{n-1}{n}}}\big)^n$ is the $n$ -th power of a continuous bounded function defined on the entire disk, and smooth on $D \setminus \{0\}$ . Thus, it suffices to show that $z \to \frac{z}{|z|^{\frac{n-1}{n}}}$ has a derivative which is in $L^2$ . Writing $\beta:=\frac{n-1}{n}$ , we need to differentiate $g(z)=\frac{z}{|z|^\beta}=(\frac{x}{(x^2+y^2)^{\frac{\beta}{2}}},\frac{y}{(x^2+y^2)^{\frac{\beta}{2}}})$ . By symmetry, it suffices to check $G(x,y)=\frac{x}{(x^2+y^2)^{\frac{\beta}{2}}}$ . $G_x=(x^2+y^2)^{-\frac{\beta}{2}}[1-\beta \frac{x^2}{x^2+y^2}]$ , so (since $0<\beta<1$ ), we get $|G_x| \le (x^2+y^2)^{-\frac{\beta}{2}}=r^{-\beta}$ . Thus $|G_x|^2 \le r^{-2\beta}$ , so $|G_x|^2 \in L^1$ iff $ \int_0^1 r^{-2\beta} rdr < \infty$ . Since $-1<1-2\beta=\frac{2-n}{n} \le 0$ ,
this holds. Similarly, $|G_y|=|(x^2+y^2)^{-\frac{\beta}{2}}\frac{2xy}{x^2+y^2}| \le (x^2+y^2)^{-\frac{\beta}{2}}$ , so we are done.","['distribution-theory', 'complex-analysis', 'real-analysis', 'multivariable-calculus', 'sobolev-spaces']"
3539053,Uniformly integrable martingale and $L^1$ convergence,"I want to show the following property: Let $(X_t)_{t\geq 0}$ be a uniformly integrable martingale, then there exists a random variable $X_\infty \in L^1(\Omega)$ with $X_\infty = \lim_{t \to \infty} X_t$ a.s. and such that $X_t = E[X_\infty \mid \mathscr{F}_t]$ . Here is my proof: The first statement follows from the fact that all $X_t$ are integrable together with the martingale convergence theorem.
By dominated convergence, \begin{align*}
    \lim_{t \to \infty} \int_\Omega |X_t - X_\infty| dP =  \int_\Omega\lim_{t \to \infty} |X_t - X_\infty| dP =0,
\end{align*} so $X_t \to X_\infty$ in $L^1$ as well. It remains to show the conditional expectation property. But since for any $A_s \in \mathscr{F}_s$ we have \begin{align*}
    \int_{A_s} X_t dP = \int_{A_s} X_s dP,
\end{align*} the property follows from $\int_{A_s} X_t dP \stackrel{t \to \infty}{\longrightarrow} \int_{A_s} X_\infty dP$ . I didn't use the uniform integrability...But I can't see my mistake. Can somebody enlighten me?","['stochastic-calculus', 'stochastic-processes', 'martingales', 'probability-theory', 'probability']"
3539064,Local homeomorphism which is one-to-one in a closed is a homeomorphism in a neighborhood of this set,"Let $M, N$ be Hausdorff spaces, $M$ locally compact with a countable basis, $\phi\colon M \to N$ a local homeomorphism, $A \subset M$ closed in $M$ and $\phi|_A$ one-to-one.
Then there exists a neighborhood $V$ of $A$ in $M$ such that $\phi|_V$ is a homeomorphism. The above is an unproven claim in I. Chavel, Riemannian Geometry: A Modern Introduction [doi:10.1017/CBO9780511616822] which appears at the very end of the proof of Theorem I.3.2. I was wondering if someone could lend me a hand in showing this result.","['general-topology', 'differential-geometry']"
3539134,Suppose $U$ is bounded and $p>q$. Does $f_n\rightharpoonup f$ in $L^p(U)$ implies $f_n\to f$ in $L^q(U)$?,Suppose $U$ is bounded and $p>q$ . We know $L^p(U)$ is stronger then $L^q(U)$ in the sense that $f_n\to f$ in $L^p(U)$ implies $f_n\to f$ in $L^q(U)$ . Can we relax the convergence on the stronger space and still retain the result? So is it the case that $f_n\rightharpoonup f$ in $L^p(U)$ implies $f_n\to f$ in $L^q(U)$ ?,"['weak-convergence', 'lp-spaces', 'functional-analysis', 'analysis']"
3539229,"Find the equation of tangents for $x^3+y^3-3xy=0$ at $x=0,y=0$","$$x^3+y^3-3xy=0$$ Find the equation of tangents at $x=0,y=0$ My attempt is as follows:- Attempt $1$ : $$3x^2+3y^2\dfrac{dy}{dx}-3\left(x\dfrac{dy}{dx}+y\right)=0$$ $$\dfrac{dy}{dx}(y^2-x)=y-x^2$$ $$\dfrac{dy}{dx}=\dfrac{y-x^2}{y^2-x}$$ but when placing $x=0,y=0$ we are getting undefined quantity. But actual answer is $xy=0$ , how can we proceed here? Attempt $2$ : (Parametric method) $$\dfrac{y}{x}=t$$ $$y=xt$$ Putting this in the original equation $$x^3+x^3t^3-3x^2t=0$$ $$x^2(x+xt-t)=0$$ $$x=\dfrac{t}{t+1}$$ $$y=\dfrac{t^2}{t+1}$$ $$\dfrac{dy}{dx}=\dfrac{\dfrac{2t(t+1)-t^2}{(t+1)^2}}{\dfrac{t+1-t}{(t+1)^2}}$$ $$\dfrac{dy}{dx}=t^2+2t$$ $x=0$ , then $\dfrac{t}{t+1}=0 \implies t=0$ $y=0$ , then $\dfrac{t^2}{t+1}=0$ also $\implies t=0$ So we are getting slope as $0$ , hence $y=0$ can be the answer, but actual answer is $xy=0$","['calculus', 'derivatives', 'tangent-line']"
3539273,Topology induced by a norm,"I came across the notion of a $\textit{topology induced by a norm}$ . If $(X,\Vert\ . \Vert)$ is a normed space w.r.t a norm $\Vert\ . \Vert: X \to \mathbb{R}$ . Most sources define the topology $\tau$ on $X$ induced by $\Vert\ . \Vert$ as the sets $U \subset X$ open w.r.t. the metric $d: X \times X \to \mathbb{R}$ given by $d(x,y) = \Vert x - y \Vert$ . But would I be correct in assuming that an equivalent definition would be $\tau = \{\Vert\ . \Vert^{-1}(U) \mid U \subset \mathbb{R}\ \textrm{open} \}$ ?","['general-topology', 'normed-spaces', 'analysis', 'real-analysis']"
3539504,Spectral theorem for fractional Laplacian,"Let $(\lambda_k,\phi_k)$ be the eigenvalues/eigenvectors of the Laplacian operator ( $-\Delta$ ) on a smooth and bounded domain $\Omega \subset \mathbb{R^n}$ . From the spectral theorem in Hilbert spaces we know that the eigenvectors form a complete orthonormal basis for $L^2(\Omega)$ . Thus for $u \in L^2(\Omega)$ we may write $$
u = \sum_k \langle u,\phi_k\rangle\ \phi_k \quad \text{and} \quad -\Delta u = \sum_k \lambda_k\langle u,\phi_k\rangle\ \phi_k
$$ In this setting, I have read that we can define fractional powers of the Laplacian as $$
-\Delta^s u = \sum_k \lambda_k^s \langle u,\phi_k\rangle\ \phi_k
\quad,\quad s \in \mathbb{R} \tag{$\star$}
$$ Questions But, is ( $\star$ ) valid for every $s \in \mathbb{R}$ ? Isn't the above sum diverging for certain $s \in \mathbb{R}$ ? Under what conditions? Is it true that we can find any pair $(\lambda_k,\phi_k)$ corresponding to a fractional Laplacian operator in $\Omega$ using only ( $\star$ ) and the eigenvectors/eigenvalues of the Laplacian ( $s=1$ )? Where should I look for the regularity theory surrounding fractional Laplacians? Pardon me for the multiple questions, but I am also asking for a reference for further study. Thanks in advance!","['spectral-theory', 'partial-differential-equations', 'functional-analysis', 'real-analysis']"
3539552,"Maximize $\sum_{i=1}^n\ln\left(\frac{2x_i}{\theta}\mathbf{1}_{[0,\theta)}(x_i)+\frac{2(1-x_i)}{1-\theta}\mathbf{1}_{[\theta,1]}(x_i)\right)$","I'm trying to solve the following problem: Consider a sample of $n$ i.i.d observations drawn from a distribution characterized by the density function $$f_{\theta}(x)= \begin{cases}{\frac{2 x}{\theta}} & {\text { if } x \in [0, \theta)} \\ {\frac{2(1-x)}{1-\theta}} & {\text { if } x \in[\theta, 1]} \\ {0} & {\text { otherwise }}\end{cases}$$ where the parameter $\theta \in (0,1)$ . Find the maximum likelihood estimator of $\theta$ . My attempt: Let $X=(X_1, \ldots, X_n)$ . Then the log-likelihood function is $$l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2 x_i}{\theta} \mathbf{1}_{[0, \theta)} (x_i) + \frac{2(1- x_i)}{1-\theta} \mathbf{1}_{[\theta,1]} (x_i) \right)$$ Let $(X_{(1)}, \ldots, X_{(n)})$ be the order statistics. Then $$l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2 x_{(i)}}{\theta} \mathbf{1}_{[0, \theta)} (x_{(i)}) + \frac{2(1- x_{(i)})}{1-\theta} \mathbf{1}_{[\theta,1]} (x_{(i)}) \right)$$ $\textbf{Case 1:}$ $\theta \in [0, x_{(1)}]$ $$l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2(1- x_{(i)})}{1-\theta}  \right) = n \ln 2 + \sum_{i=1}^n \ln (1- x_{(i)}) - n \ln (1-\theta)$$ It follows that $$\underset{\theta \in [0, x_{(1)}]}{\text{arg max}} \,\, l(\theta;x) = x_{(1)} \quad \text{and} \quad \max_{\theta \in [0, x_{(1)}]} l(\theta;x) = n \ln 2 + \sum_{i=1}^n \ln (1- x_{(i)}) - n \ln (1-x_{(1)})$$ $\textbf{Case 2:}$ $\theta \in [x_{(k)}, x_{(k+1)}]$ $$\begin{aligned} l(\theta;x) &= \sum_{i=1}^k \ln \left ( \frac{2 x_{(i)}}{\theta} \right) + \sum_{i=k+1}^n \left (\frac{2(1- x_{(i)})}{1-\theta} \right) \\ &= n \ln2+ \sum_{i=1}^k \ln(x_{(i)} ) + \sum_{i=k+1}^n \ln( 1-x_{(i)} ) -k \ln \theta - (n-k) \ln (1 - \theta)\end{aligned}$$ $\textbf{Case 3:}$ $\theta \in [x_{(n)}, 1]$ $$l(\theta;x) = \sum_{i=1}^n \ln \left ( \frac{2x_{(i)}}{\theta}  \right) = n \ln 2 + \sum_{i=1}^n \ln (x_{(i)}) - n \ln (\theta)$$ It follows that $$\underset{\theta \in [x_{(n)},1]}{\text{arg max}} \,\,  l(\theta;x) = x_{(n)} \quad \text{and} \quad \max_{\theta \in [x_{(n)}, 1]} l(\theta;x) = n \ln 2 + \sum_{i=1}^n \ln (x_{(i)}) - n \ln (x_{(n)})$$ My question: In case 2 , the critical point is $\theta' = k/n$ . But I don't know if $k/n \in [x_{(k)}, x_{(k+1)}]$ . Hence I'm unable to find the maximizer in this case. Even if I found it, I'm still unable to compare the values of $l(\theta';x)$ between 3 cases. How can I proceed to find $$\underset{\theta \in [0, 1]}{\operatorname{arg max}} l(\theta;x) \text{ ?}$$ Thank you so much!","['statistics', 'real-analysis', 'order-statistics', 'maximum-likelihood', 'optimization']"
3539618,Prove $4\sin^{2}\frac{\pi}{9}-2\sqrt{3}\sin\frac{\pi}{9}+1=\frac{1}{4}\sec^{2}\frac{\pi}{9}$.,"While attempting to algebraically solve a trigonometry problem in (Question 3535106) , I came across the interesting equation $$
4\sin^{2}\frac{\pi}{9}-2\sqrt{3}\sin\frac{\pi}{9}+1=\frac{1}{4}\sec^{2}\frac{\pi}{9}
$$ which arose from the deduction that $$\frac{1}{4}\sqrt{\frac{256\sin^{4}40^{\circ}-80\sin^{2}40^{\circ}+12-\ 8\sqrt{3}\sin40^{\circ}}{\left(16\sin^{4}40^{\circ}-4\sin^{2}40^{\circ}+1\right)}}=\cos50^{\circ}$$ Despite the apparent simplicity of the relationship, it seems quite tricky to prove. I managed to prove it by solving the equation as a quadratic in $(\sin\frac{\pi}{9})$ and then using the identity $\sqrt{\sec^2 x-1}=|\tan x|$ , the double angle formulae and finally that $\frac{\sqrt{3}}{2}\cos x-\frac{1}{2}\sin x$ can be written in the form $\sin\left(x+\frac{2\pi}{3}\right)$ . But it seems like quite a neat problem. Does anyone have a better way of proving it?","['algebra-precalculus', 'trigonometry']"
3539667,Closest point on a cylinder from a point,"I have a cylinder in a 3D world. My cylinder is defined as follow:
Point A and Point B, Radius R From a given point P in space, I would like to get the closest point X on the cylinder I have found, and implemented the algo point to line, thanks to this thread: https://diego.assencio.com/?index=ec3d5dfdfc0b6a0d147a656f0af332bd But I don't know how to apply that to a cylinder... 
Thanks for help !","['geometry', '3d']"
3539676,Is $f$ also necessarily of bounded variation?,"Let $g:[0,1] \to \mathbb{R}$ be an increasing function. Define $f:[0,1] \to \mathbb{R}~$ by $f(x)=0$ if $x=0$ and $$f(x)=\frac 1x {\int_0 ^x g(t)~dt} $$ otherwise. Is $f$ also necessarily of bounded variation? My thought was to try to prove that $f$ is increasing (which is even stronger), but the problem is it might not be true. [For example, if $g(x)=x-10$ , we have $f(0)>f(1)$ ] . Now, I see that $f$ has to be increasing on $(0,1]$ . So far so good, but this  still doesn't convince me that $f$ is of bounded variation.","['bounded-variation', 'lebesgue-integral', 'real-analysis']"
3539711,Examples of nicely shrinking sets (Rudin),"In Rudin's Real and Complex Analysis, section 7.9, the definition of nicely shrinking sets is given as follows: Let $x\in \Bbb R^k$ . A sequence $\{E_n\}$ of Borel sets in $\Bbb R^k$ is said to shrink to $x$ nicely if there is a number $\alpha>0$ with the following property: There is a sequence of balls $B(x,r_n)$ , with $\lim r_n=0$ , such that $E_n\subset B(x,r_n)$ and $$ m(E_n) \geq \alpha \cdot m(B(x,r_n))$$ for $n=1,2,\cdots$ . (Here $m$ is the Lebesgue measure) Then Rudin says that (1) A nested sequence of $k$ -cells whose longest edge is at most 1,000 times as long as its shortest edge and whose diameter tends to $0$ shrinks nicely. (2) But a nested sequence of rectangles (in $\Bbb R^2$ ) whose edges have lengths $1/n$ and $1/n^2$ does not shrink nicely. But I can't see why. I think the biggest difference is there is a upper limit of the ratio between the edges in (1), while not in (2), but how can I prove these using the definitions?","['measure-theory', 'lebesgue-measure']"
