question_id,title,body,tags
1723020,Accounting for uncertainty in an Elo rating system for Foosball,"For a Foosball game at work we implemented a rating system based on the Elo system. Allthough we achieved a sensible result so far, which provided us with a lot of fun (which is the goal) we feel we can do better by: accounting for uncertainty for new players removing/ignoring inactive players Game description A game is played by 4 players, 2 versus 2. The first team to reach 10 goals with a two point difference wins. Current rating system Each player gets an initial rating of 1000 points. When a match is played the outcome of the match is predicted by an adaptation of Elo's rating system. First we predict the probability of team A scoring a single goal before team B (team A wins one 'ball') by
$$ E_A = \frac{1}{1 + 10^{(R_B-R_A)/800}}$$
where $E_A$ is the probability that team A will win this ball and $R_{A,B}$ the sum of ratings of the players in team $A,B$ respectively. The predicted outcome of the match is then found by 'translating' this prediction to 20 balls:
$$E_{\Delta S} = 20*(E_A-\frac{1}{2}) $$
with $E_{\Delta S}$ the predicted difference in score and $E_A$ the probability of team A winning a ball. If $E_{\Delta S} > 0$ team A is expected to win with a difference of $E_{\Delta S}$ goals, if $E_{\Delta S} < 0$ team B is expected to win with a difference of $E_{\Delta S}$. The change in rating for the players in this match is then calculated from the difference between the prediction and the actual outcome $\Delta S$:
$$ \Delta r = k\cdot (\Delta S - E_{\Delta S})) $$
With $k$ a parameter to make the changes in rating more agressive. For us a value of $k=10$ works nicely since every goal different from the predicted score earns you $10$ points. A nice round number to remember in the heat of the game. The ratings for the players in the match are then updated by adding $\Delta r$ to their old rating for the players in team A, and subtracting $\Delta r$ for the players in team B. Experience I have not thoroughly examined the performance of this algorithm since I know it has some flaws. However the expected score predictions 'feel' good. They match relatively well with what we expect when playing with/against people we know. Furthermore in the last 50 of 170 the error in expected score $\epsilon = \mathrm{abs}(E_{\Delta S} - \Delta S)$ was on average 3. This may not be as accurate as it gets, but we consider this reasonable (especially since we have not accounted for the fact that games must end with a 2 point difference). Question 1 We do notice however that the most inaccurate predictions are given when a player's rating is insanely high or low because he/she has recently achieved a very improbable result (lost or won with a very large score difference). This we would like to solve by predicting how accurate the rating of a player is, and adapting the change in rating accordingly. This could also help the fact that new players start with a 1000 points which is in most cases not accurate at all. What do you think is a good measure for the accuracy of the current rating and what is an appropriate relation to the ratingchange? Question 2 We have a high throughput of employees, and so there are a lot of players that no longer play. We can however not simply delete their entries since the average amount of points per player must remain at 1000 so as to counteract inflation/deflation. What are your ideas on removing players and what should I do with their points? Thanks Also rough thoughts and ideas are welcome, we may be able to translate your thoughts and ideas to formulas ourselves.",['probability']
1723046,Solving a linear system of ODEs with repeated eigenvalues but distinct eigenvectors.,"Suppose I have a linear system of ODEs given by the system: $$\dot{\vec{x}}= A\vec{x}$$ where $A$ is an $(n\times n)$ matrix and $\vec{x}$ is a $(n\times 1)$ column vector. Now suppose that the matrix A has repeated eigenvalues but has $n$ distinct linearly independent eigenvectors . Is there a simple way to solve the system? The link below (to wolfram alpha) shows a $(6\times 6)$ matrix where this is the case. See here for an example of a matrix where this happens . I know that if there are $n$ distinct eigenvalues $\lambda_1, \ldots , \lambda_n$, the general solution is given by $$\vec{x} = \big(c_1 v_1 e^{\lambda_1t}+\ldots+c_nv_ne^{\lambda_n t}\big)$$ where $v_i$ is the corresponding eigenvector for $\lambda_i$ and $c_i$ is a constant. Also, I know what to do when there are repeated eigenvalues, with corresponding repeated eigenvectors. Is there an a similar way to solve the system with repeated eigenvalues but distinct eigenvectors? Thanks.",['ordinary-differential-equations']
1723057,Multivariable Calculus Change of Variable in Double Integral 2D Jacobian,"Let $D$ be the region in the first quadrant ($x>0$, $y>0$) of the $xy$-plane bounded by the curves $y=\sqrt x$, $y=2\sqrt x$, $x^2+y^2=1$, $x^2+y^2=4$. Using a change of variables, evaluate the double integral $$\int\int_D\frac{2x^2+y^2}{xy} dA.$$",['multivariable-calculus']
1723062,Calculate sum of infinite series by solving a differential equation,"Calculate the sum of the infinite series 
$$\sum_{n=0}^{\infty}\frac{1}{(3n)!}$$ by solving an aptly chosen differential equation. I know that one can solve a differential equation by assuming that we can write the solution as a power series in the form
$$y(x)=\sum_{n=0}^\infty a_n(x-x_0)^n$$ and then find all the different values for $a_n$'s. I'm trying to figure out how to to it the other way around? How am I supposed to find the differential equation when I have the infinite sum already? Update I've started off supposing there exists some solution, to the differential equation of the form
$$p(x)y''(x)+q(x)y'(x)+r(x)y(x)=0,$$ that can be written as 
$$y(x)=\sum_{n=0}^\infty a_n(x-x_0)^n. $$
Since I already know this solution should be of the form $$y(x)=\sum_{n=0}^\infty \frac{1}{(3n)!}$$ I know that $a_n=\frac{1}{(3n)!}, x=1, x_0=0$. Furthermore, writing $$y'(x)=\sum_{n=1}^\infty n\ a_n(x-x_0)^{n-1} \ \ and \ \ y''(x)=\sum_{n=2}^\infty n(n-1)\ a_n(x-x_0)^{n-2}. $$ and filling this in the differential equation I finally end up with the equation
$$\sum_{n=0}^\infty \left(p(x)\frac{(n+2)(n+1)}{(3(n+2))!} + q(x)\frac{(n+1)}{(3(n+1))!}+r(x)\frac{1}{(3n)!} \right)=0$$
I think that all the functions $p(x), q(x) \ $and $ r(x)$ should be evaluated at $x=1$. However, I don't know how to proceed.","['factorial', 'ordinary-differential-equations', 'sequences-and-series']"
1723102,Reference request: Fibre functor for elliptic curves is pro-representable,"I am writing a project on étale fundamental groups of elliptic curves and I want to include a proof of a key theorem: the fibre functor on the category of finite étale covers of an elliptic curve is ""pro-representable"". Firstly, let me just recall the general case: Given an algebraic variety $X$ over a field $K$ and a geometric point $\bar{x}:\text{Spec}(\bar{K})\to X$ we can consider the category of pointed finite étale covers $Y\to X$. Let's call this category $\mathsf{Cov}(X,\bar{x})$. The fibre functor $\Phi$ on this category associates to each cover $\phi: Y\to X$ the underlying set of the fibre above the geometric point $\bar{x}$ and to each morphism of covers the corresponding function on fibres. The étale fundamental group of $(X,\bar{x})$ is defined as the automorphism group of this functor, and it is a general theorem that it is pro-representable i.e. there's a projective system of étale covers of $X$ that represents $\Phi$. Now I'm able to find many quite abstract proofs of the above pro-representablity theorem (for example, in Szamuely's book it is done for connected schemes). However in the interests of not investing an impossible amount of energy into my project I am looking for a far more basic version: just the case that $X = E$ is an elliptic curve with basepoint $O\in E(K)$. In this case the category $\mathsf{Cov}(E,O)$ actually becomes a category of covers of $E$ by isogenies of elliptic curves (over extensions of $K$) once a point in the fibre above $O$ is chosen, and the fibre functor actually factors through the category of finite abelian groups because it associates to each isogeny its kernel. In this case, one of the nice results I have seen mentioned often is that the fibre functor on $\mathsf{Cov}(E,O)$ is pro-represented by the system of multiplication-by-$m$ isogenies
$$ [m]: E\to E$$
(given a partial order by division) which are étale provided $m$ is a unit in $K$ . I haven't been able to find a proof of this specific result anywhere. It's possible one doesn't exist and that a proof using the fully general construction I mentioned above is required, but I would be very happy if anyone out there can correct me and point me in the direction of a proof this result for elliptic curves. I am trying to avoid ""schemey"" arguments as much as possible but I would be happy using something that uses results about elliptic curves à la Silverman's AEC . Many thanks!","['galois-theory', 'algebraic-geometry', 'reference-request', 'elliptic-curves', 'category-theory']"
1723113,"Question on part 3 of the Star Trek problem in Williams, Probability with Martingales","Consider this M.SE question , which is E12.3 in Williams. The answer of Robert Israel (and Xoff) seems to give an exponential bound on $R_n$ almost surely. Wouldn't this imply the convergence of 
$$\sum R_n^{-1},$$
which is significantly stronger than what the problem asks to prove, which is the convergence of 
$$\sum R_n^{-2}?$$ I would like confirmation that this stronger result is actually true and that I am not missing anything.","['probability-limit-theorems', 'probability-theory', 'martingales']"
1723115,Find $\lim_{x\to -\infty}\frac{3^{\sin x}+2x+1}{\sin x-\sqrt{x^2+1}}$,"Find the value of $\lim_{x\to -\infty}\frac{3^{\sin x}+2x+1}{\sin x-\sqrt{x^2+1}}$ $\lim_{x\to -\infty}\frac{3^{\sin x}+2x+1}{\sin x-\sqrt{x^2+1}}$ Since this is in $\frac{\infty}{\infty}$ form,so i applied L Hospital rule, $\lim_{x\to -\infty}\frac{3^{\sin x}\cos x\log 3+2}{\cos x-\frac{x}{\sqrt{x^2+1}}}$ But i am stuck here.",['limits']
1723118,Zero's of non trivial solution of an second order ordinary differential equation,"What can we say about the zero's of  any non-trivial solution of the linear differential equation$$y^{''}+q(x)y=0$$ (where $q(x)$ is positive monotonically increasing continuous function of $x$). Can we say that it must have infinitely many zeros in $\mathbb{R}?$ For example $y^{''}+y=0$ has $sin(x)$ as a non trivial solution, which has infinitely many zero's. Please help me to prove the general result about infinitely many zero's. Thanks in advance.",['ordinary-differential-equations']
1723138,"Number of values of $x\in [0,\pi]$ where $f(x)=\lfloor 4\sin x-7\rfloor$ is non derivable is?","Number of values of $x\in [0,\pi]$ where $f(x)=\lfloor 4\sin x-7\rfloor$ is non derivable is? $f(x)=\lfloor 4\sin x-7\rfloor=\lfloor 4\sin x\rfloor-7$ I drew the graph of the $f(x)$ and see that there are six points in $x\in [0,\pi]$ where $f(x)$ is non-continuous and hence non derivable,but the answer given is $7$.","['derivatives', 'continuity', 'calculus', 'ceiling-and-floor-functions']"
1723147,"If $A \subseteq \mathbb{N}$, $2^n \in A$ and if $x\in A$, then $\lfloor \sqrt{x} \rfloor \in A$. Is it true that $A=\mathbb{N}$?","Let $A$ be a non-empty subset of $\mathbb{N}$, such that for all $k \in \mathbb{N}$, we have $2^k\in A$. Also, if $x \in A$ then we have $\lfloor \sqrt{x} \rfloor \in A$. Is it true that $A=\mathbb{N}$? I have tried but am not able to do anything. Taking $n \notin A$ and trying to achieve a contradiction didn't work for me. So how do we solve this, preferably by a pre-calculus approach ? Additionally, is it also true for powers of $n$ other than $2$?","['algebra-precalculus', 'elementary-number-theory']"
1723170,Formula for cumulative binomial probability,"Is there a simple formula for finding a value of a cumulative binomial probability, eg. like the ones put in cumulative binomial probability tables?
eg. X~B(50, 0.234)
Find the cumulative binomial probability for 32, with one equation.",['statistics']
1723208,"Functional equation in $x,y$: $f(x)f(y)=f\left(\frac{a}{x}\right)f\left(\frac{a}{y}\right)$","Let $f:(0,+\infty)\to \mathbb{R}$ and $a>0$ such that $f(a)=1$ . Prove that, if \begin{align*}
f(x)f(y)=f\left(\frac{a}{x}\right)f\left(\frac{a}{y}\right),\quad\forall x,y>0
\end{align*} then $f$ is constant.","['functions', 'functional-equations']"
1723224,contradictory wikipedia and mathworld.wolfram,"On https://en.wikipedia.org/wiki/Liouville_function there is written $L(n)>0.06 \sqrt n$ and $L(n)<-1.39 \sqrt(n)$ for infinitely many $n$. On http://mathworld.wolfram.com/LiouvilleFunction.html they say it is unknown if $L(n)$ changes sign infinitely many times. But those statements are contradicting each other. 
(so one has to contact that site which is wrong)
So which one of the statements is true?",['sequences-and-series']
1723229,Simplifying this (perhaps) real expression containing roots of unity,"Let $k\in\mathbb{N}$ be odd and $N\in\mathbb{N}$. You may assume that $N>k^2/4$ although I don't think that is relevant. Let $\zeta:=\exp(2\pi i/k)$ and $\alpha_v:=\zeta^v+\zeta^{-v}+\zeta^{-1}$. As it comes from the trace of a positive matrix I know that the following is real: $$\sum_{v=1}^{\frac{k-1}{2}}\sec^2\left(\frac{2\pi v}{k}\right)\frac{(\overline{\alpha_v}^N+\alpha_v^N\zeta^{2N})(\zeta^{2v}-1)^2}{\zeta^N\zeta^{2v}}.$$ I am guessing, and numerical evidence suggests, that in fact $$\frac{(\overline{\alpha_v}^N+\alpha_v^N\zeta^{2N})(\zeta^{2v}-1)^2}{\zeta^N\zeta^{2v}}$$ is real for (at least) each $v=1...(k-1)/2$. Therefore I am assuming that there is some nice simplification of it. Can anyone simplify this expression? Summing or even bounding the series would go above and beyond. Context I need to calculate or rather bound traces to calculate a distance to random for the convolution powers of a $\nu\in M_p(\mathbb{G}_k)$ for $\mathbb{G}_k$ a series of quantum groups of order $2k^2$ ($k$ odd). Update Following mercio's answer below I am now dealing with: $$\frac{2}{4^{2N+1}}\sum_{v=1}^{\frac{k-1}{2}}\sec^2\left(\frac{2\pi v}{k}\right)\left(8+8|\alpha_v|^{2N}-8\sin^2\left(\frac{2\pi v}{k}\right)\Re\left((\alpha_v\zeta)^N\right)\right).$$ I can handle the first term (it is $2(k^2-1)/4^{2N}$) and am now looking at the other two terms.","['complex-numbers', 'trigonometry', 'roots-of-unity', 'algebra-precalculus', 'summation']"
1723255,A more game related stats question,"There are an infinite amount of true-false questions. My goal is to get to 100 points. A correct answer will give me 1 point, and if I have 2 questions correct in a row, the any correct questions that are proceded by  2 correct questions will give me an additional point. So it's like a winning streak. 
(Example: right, wrong, wrong, right, right, right , wrong. I receive 5 points) A incorrect answer will have no penalty except ending the bonus streak. The question is, if I completely guess all the questions, so 50%, how many questions do I expect to play in order to get to 100 points? Thanks all!","['combinatorics', 'statistics', 'probability']"
1723285,Similarity of real matrices over $\mathbb{C}$,"$A  \underset{\mathbb{C}}{\sim} B \overset{\text{def}}{\iff} A=C^{-1}BC, \space C\in M_{n}(\mathbb{C})$ and similarly for $\underset{\mathbb{R}}{\sim}$. I want to prove that $ A \underset{\mathbb{C}}{\sim} B$ for $A,B \in M_{n}(\mathbb{R})$ therefore $A \underset{\mathbb{R}}{\sim} B$. My idea is that elementary divisors of $A,B$ over $\mathbb{C}$ are the same, and if $(x-z)^k$ is elementary divisor than $(x-\overline{z})^k$ is also elementary divisor $\implies$ $A,B$ have same elementary divisors over $\mathbb{R}$. But i think it's not clear.","['matrices', 'linear-algebra']"
1723329,For each $g$ there is $[C]\in\mathcal{M}_g$ which embeds on a K3 surface,"For each genus $g\geq 0$ there is a (smooth irreducible) curve $C$ of genus $g$ which embeds on some K3 surface. How does this follow from the surjectivity of the period map for K3 surfaces? Is there a simpler reason for this (apparently) simple fact?
(it seems to me a bit of an overkill to invoke such a strong result - can we actually avoid it?)",['algebraic-geometry']
1723346,How to solve this limit problem?-$\lim_{n\to \infty}\ \left(\frac{\ n!}{(mn)^n}\right)^{\frac{1}{n}}$,"I need to find the value of- $$\lim_{n\to \infty}\ \left(\frac{\ n!}{(mn)^n}\right)^{\frac{1}{n}}$$ where $m {\in} R$ I don't know how to even start. Would someone explain it step by step, also which type of indeterminate form is this?
Is there a simpler to solve this ? i.e. without any high mathematics theorem etc.?",['limits']
1723356,Lie derivative of a vectorfield in components,"The lecturer here wants the viewer to derive the components of the Lie derivative of a (1,1) tensor-field. But even before that I have a little question about the components of the Lie derivative of a vector field: Careful: 1) and 2) are incorrect! let $(U,x)$ be a chart and $X,Y$ vector fields on the smooth manifold $(M,\mathcal{O},\mathcal{A})$, I get: $$
({L}_X Y)^i = [X,Y]^i = (XY - YX)^i = X^m 
\left(\frac{\partial}{\partial x^m}\right) Y^i
- Y^m \left(\frac{\partial}{\partial x^m}\right) X^i
$$
1) is that correct? I suspect, since we write single components, which are real functions, that I can reorder the terms, as I please (commutativity of multiplication on $C^{\infty}M$)? And the derivatives, which are actually the basis vectors, act on the function to which this thing is applied to anyway, right? So for clarity I could move them to the far right to show this:
$$
= X^m  Y^i  \left(\frac{\partial}{\partial x^m}\right)
- Y^m  X^i  \left(\frac{\partial}{\partial x^m}\right)
$$
2) still correct? 3) Then is there any ""rule""/intuition or something why the contraction with the basis is over the ""outer"" field? If I take $(y \circ x^{-1})^i$ I can write this as $(y^i \circ x^{-1})$, basically the last function is responsible for the component I get out. In the above example it seems to be the first one applied.","['derivatives', 'lie-derivative', 'differential-geometry']"
1723454,Are ideals of the Lie algebra invariant under the adjoint action?,"Let $G$ be a connected algebraic group over a field of characteristic $p \geq 0$ and let $H < G$ be a connected closed subgroup. If the lie algebra $\mathfrak{h}$ of $H$ is an ideal of the Lie algebra $\mathfrak{g}$ of $G$, is $\mathfrak{h}$ invariant under the adjoint action of $G$ on $\mathfrak{g}$? I know that this is true if $H$ is a normal subgroup. It is also true if $p = 0$, because then there is a bijection between connected normal subgroups and ideals of the Lie algebra. What about when $p > 0$?","['algebraic-groups', 'group-theory', 'lie-algebras']"
1723465,"If $n$ is a positive integer, does $n^3-1$ always have a prime factor that's 1 more than a multiple of 3?","It appears to be true for all $n$ from 1 to 100. Can anyone help me find a proof or a counterexample? If it's true, my guess is that it follows from known classical results, but I'm having trouble seeing it. In some cases, the prime factors congruent to 1 mod 3 are relatively large, so it's not as simple as ""they're all divisible by 7"" or anything like that. It's interesting if one can prove that an integer of a certain form must have a prime factor of a certain form without necessarily being able to find it explicitly. EDITED TO ADD: It appears that there might be more going on here! $n^2-1$ usually has a prime factor congruent to 1 mod 2 (not if n=3, though!) $n^3-1$ always has a prime factor congruent to 1 mod 3 $n^4-1$ always has a prime factor congruent to 1 mod 4 $n^5-1$ appears to always have a prime factor congruent to 1 mod 5. Regarding $n^2-1$: If $n>3$, then $n^2-1=(n-1)(n+1)$ is a product of two numbers that differ by 2, which cannot both be powers of 2 if they are bigger than 2 and 4. Therefore at least one of $n-1,n+1$ is divisible by an odd prime. Regarding $n^4-1$: If $n>1$, we factor $n^4-1$ as $(n+1)(n-1)(n^2+1)$. We claim that in fact, every prime factor of $n^2+1$ is either 2 or is congruent to 1 mod 4. If $p$ is an odd prime that divides $n^2+1$, then $-1$ is a square mod $p$, but the odd primes for which $-1$ is a square mod $p$ are precisely the primes congruent to 1 mod 4. It remains just to show that $n^2+1$ cannot be a power of 2. If $n$ is even this is obvious, and if $n=2k+1$ is odd, then $n^2+1=(2k+1)^2+1=4k^2+4k+2$ is 2 more than a multiple of 4. Regarding $n^5-1$, I don't have a proof, but based on experimenting with a few dozen numbers, I conjecture that in fact, every prime factor of $n^4+n^3+n^2+n+1$ is either 5 or is 1 more than a multiple of 5.","['number-theory', 'prime-numbers']"
1723468,What is the difference between ANOVA and ANCOVA?,"In the context of using only experiment data for ANOVA analysis, ANCOVA offers post hoc statistical control. Is this a valid conclusion and why?","['statistics', 'statistical-inference']"
1723503,How do we find the solution of the problem in interlaced form?,"We consider the differnetial equation $$(x-xy(x))+(y(x)+x^2)y'(x)=0$$ I have found the integrating factor $\mu (x,y)=\sqrt{x^2+y^2}$. Using this I have to find the solution of the problem in interlaced form. Could you give me some hints what I am supposed to do? I got stuck right now... Multiplying by the integrating factor we get $$\sqrt{x^2+y^2}(x-xy(x))dx+\sqrt{x^2+y^2}(y(x)+x^2)dy=0$$ or not? How could we continue? $$$$ EDIT: Is it maybe as follows? $$y'=F(y,x) \\ \Rightarrow (x-xy(x))+(y(x)+x^2)F(y,x)=0 \\ \Rightarrow y(x)(1-x)+x^2+x+x^2F(y,x)=0 \\ \Rightarrow y(x)=-\frac{x^2F(y,x)-x-x^2}{1-x}$$",['ordinary-differential-equations']
1723509,Is this proportionality proof erroneous?,"If $a$ is directly proportional to $b$ and also directly proportional to $c$ , is it true that $a$ is directly proportional to $bc?$ (It seems like it is true.) Here is what I did, and I have a feeling I have made a pretty big mistake somewhere: From the given info, we have $$\frac{a}{b}=x$$ for some constant $x,$ and $$\frac{a}{c}=y$$ for some constant $y.$ Multiplying the two equations gives $${a}^2=bc(xy),$$ where $xy$ is a constant. So, ${a}^2$ is directly proportional to $bc.$ Update: Now for my real doubt. My physics textbook states the following: Let two objects $A$ and $B$ of masses $M$ and $m$ lie at a distance $d$ from each other. Let the force of attraction between
two objects be $F$ . According to the universal
law of gravitation, the force between two
objects is directly proportional to the product
of their masses; that is, $F ∝ M m.$ And the force between two objects is inversely
proportional to the square of the distance
between them; that is, $F ∝\frac1{d^2}.$ Combining the proportionalities we get $F ∝ \displaystyle\frac{Mm}{d^2}$ . So, does it mean that my textbook is wrong? Doesn't the combination of the two proportionalities result in $F^2$ being directly proportional to $\displaystyle\frac{Mm}{d^2}?$","['algebra-precalculus', 'physics']"
1723557,Spanish Math Olympiad,"In the circumscircle of a triangle $ABC$, let $A_1$ be the point diametrically opposed to the vertex $A$. Let $A'$ the intersection point of $AA'$ and $BC$. The perpendicular to the line $AA'$ from $A'$ meets the sides $AB$ and $AC$ at $M$ and $N$, respectively. Prove that the points $A,M,A_1$ and $N$ lie on a circle which has the center on the height from $A$ of the triangle $ABC$. This was the statement My solution: First we prove that $ANA_1M$ lie on the same circle. Observe that $A'NCA_1$ are concyclic, since $\angle NA'A_1=\angle NCA_1=90^o$, from here $\angle NA_1A'=\angle ACB$. Now it is easy to see that $\angle ANA'=\angle ABC$, hence $\angle AMN=180-(\angle BAC+\angle ABC)=\angle ACB=\angle NA_1A'$ so they lie in the same circle. Now, in order to proof that the center of the circle lie on the height from $A$ of the triangle $ABC$ we draw it, and call $P$ the intersection of it to the circle $AMA_1N$. Lets evaluate the angle $\angle AA_1P$. Since $PANA_1$ li on the same circle $\angle NA_1P=180-\angle NAP=180-(90-\angle ACB)=90+\angle ACB$. Now $\angle AA_1P=\angle NA_1P-\angle NA_1A'=90+\angle ACB-\angle ACB=90^o$ so $APA_1$ is a right-angle triangle whose circumcircle is the same as $AMA_1N$ hence the center lies on $AP$ which we said to be the height from $A$. An pretty easy problem. Is my proof correct?","['contest-math', 'proof-verification', 'geometry']"
1723584,Is this basic function space compact?,"Let $A=L^2(X)$ be the space of square integrable functions on a compact Euclidean space $X$. If we equip $A$ with the usual 2-norm, is $A$ compact? Edit:
And if we restrict AA by adding the assumption that the functions are totally bounded, i.e. the supremum norms of all the functions are bounded by a constant?","['functional-analysis', 'general-topology', 'compactness']"
1723636,Maximum value of $f(x) = \cos x \left( \sin x + \sqrt {\sin^2x +\sin^2a}\right)$,"Can we find maximum value of $$f(x) = \cos x \left(  \sin x + \sqrt
{\sin^2x +\sin^2a}\right)$$
where '$a$' is a given constant. Using derivatives makes calculation too complicated.","['trigonometry', 'calculus']"
1723688,upper bound of the expectation of the maximum of a bunch of random variables,"I met one technical problem in my project, and I wish some reference here.. Suppose $\{X_i\}_{i=1}^n$ are independent random variables. Are there some inequalities that give upper bound of $\mathbb{E}[\max_{1\leq i\leq n}X_i]$ ? By now I only know one such inequality give by Aven (1985) , that is, if $\{X_i\}_{i=1}^n$ is a sequence of random variables, then $\mathbb{E}[\max_{1\leq i\leq n}X_i] \leq \max_{1\leq i\leq n}\mathbb{E}[X_i]+\sqrt{\frac{n-1}{n}\sum_{i=1}^nVar(X_i)}$ Above inequality does not use the fact that $\{X_i\}_{i=1}^n$ are independent. I was wondering if there are some other similar inequalities that I can consider. Many thanks.","['order-statistics', 'probability', 'expected-value']"
1723789,WKB problem with 4 turning points?,"I was recently given a problem that asked to find the solvability conditions for
$$\epsilon^2y''=(W(x)-E)y;\quad y\rightarrow0\text{ as }|x|\rightarrow0$$
where $W$ was some piecewise linear, $``W""$-shaped potential function (for simplicity, let the middle peak of the W be $(0,0))$. To summarize the setup, since each region is linear, an appropriate variable substitution $z_j$ as a linear function of $x$ for each linear region of $W$ recovers the Airy ODE in each region:
$$y''=z_jy$$ with solutions
$$y(x)=A_j\cdot \text{Ai}(z_j(x))+B_j\cdot\text{Bi}(z_j(x)),\quad j=1,2,3,4$$
in each of the four intervals where $W(x)$ is linear(say we label them from left to right, where $I_4=(-\infty,a]$, $I_4=(a,0]$, $I_4=(0,b]$, and $I_1=(b,\infty)$. We require continuity of both $y$, and $y'$, so we end up with a matrix for the undetermined coefficients:
\begin{bmatrix}
\text{Ai}(z_4(b)) & -\text{Ai}(z_3(a)) & -\text{Bi}(z_3(b)) & 0 & 0 & 0\\
z_4'(b)\cdot\text{Ai}'(z_4(b)) & -z_3'(b)\cdot\text{Ai}'(z_3(b)) & -z_3'(b)\cdot\text{Bi}'(z_3(b)) & 0 & 0 & 0\\
0 & \text{Ai}(z_3(0)) & \text{Bi}(z_3(0)) & -\text{Ai}(z_2(0)) & -\text{Bi}(z_2(0)) & 0\\
0 & z_3'(0)\cdot\text{Ai}'(z_3(0)) & z_3'(0)\cdot\text{Bi}'(z_3(0)) & -z_2'(0)\cdot\text{Ai}'(z_2(0)) & -z_2'(0)\cdot\text{Bi}'(z_2(0)) & 0\\
0 & 0 & 0 & \text{Ai}(z_2(a)) & \text{Bi}(z_2(a)) & -\text{Ai}(z_1(a))\\
0 & 0 & 0 & z_2'(a)\cdot\text{Ai}'(z_2(a)) & z_2'(a)\cdot\text{Bi}'(z_2(a)) & -z_1'(a)\cdot\text{Ai}'(z_1(a))
\end{bmatrix}
Note that $B_1$ and $B_4$ must be $0$ to satisfy the $y$ bounded for large $|x|$. If the determinant of this matrix is $0$, then there are nontrivial solutions to the problem. Now, supposedly we can determine conditions on $E$ from the determinant, and we should be able to do it explicitly if we 1.) assume the case of a symmetric $W$ potential, and 2.) then use the first term asymptotic expansions of $\text{Ai}(z)$, $\text{Bi}(z)$, but I couldn't get it. Specifically for the this symmetric case with asymptotic approximations, does anyone know how to find the determinant?","['asymptotics', 'ordinary-differential-equations', 'linear-algebra', 'perturbation-theory']"
1723860,Best Fitting Pipe in parabolic trench,"A work crew is digging a pipeline. The cross section of the trench is in the shape of the parabola $y = x^2$. The pipe has a circular cross section. If the pipe is too large, then the pipe will not lay on the bottom of the trench. (a) What is the radius of the largest pipe that will lay on the bottom of the trench? (b) If the radius of the pipe is $3$ and the trench is in the shape of $y=ax^2$, then what is the largest value of $a$ that will make the pipe lay in the bottom of the trench? Any tips for starting points on how to solve this problem?","['algebra-precalculus', 'conic-sections', 'circles', 'analytic-geometry']"
1723919,What is $2^{(k+1)} +2^{(k+1)}$ equal to?,I am so confused with this question. When the powers add we get $2^{2k+2}$ but in my book it says $2^{k+2}$. How is that? Please explain.,"['algebra-precalculus', 'exponentiation']"
1723939,Folland Real Analysis 7.3,"Let $X$ be the one-point compactification of a set with the discrete topology. If $\mu$ is a Radon measure on $X$, then supp($\mu$) is countable. So if I let $X^*$ be the one-point compactification (which I assume is $X \cup \left\lbrace \infty \right\rbrace $), then my topological space is $(X^*, P(X^*))$. I know two things about the support of $\mu$ from a previous homework problem: 1) $supp(\mu)$ is the complement of $N$ where $N$ is the union of all open $U \in X^*$ with $\mu(U) = 0$. 2) $x \in supp(\mu)$ iff $\int f d\mu > 0$ for every $f \in C_c(X^*, [0,1])$ such that $f(x) > 0$ However, neither of those seem to suggest anything about the countability of the support.  I suppose if I could show there are only countably many $x \in supp(\mu)$ so that condition 2 holds, then that would work. But I don't see any way to do such a thing. Condition 1 seems easier to work with but doesn't seem to involve countability at all","['real-analysis', 'measure-theory']"
1723955,Are those two definitions of orthogonal projection equivalent in a general Hilbert space?,"I am taking a graduate level course in probability and we started off with some results in functional analysis. One thing that I feel I do not understand properly is the definition of an orthogonal projection in the context of Hilbert spaces. And I was not able to find (sufficiently) exhaustive discussion of the definition (for example not here ). To this end, let a Hilbert space, $H$, possibly infinite dimensional and not necessarily separable. Let a closed convex subset $S \subseteq H$. 1) One the one hand orthogonal projection $P_S :H \to S$ is defined as a mapping of every element $x \in H$ to the unique best approximation of $x$ in $s_0 \in S$. That is $s_0 \in S$ such that $$\|s_0 -x\| = \inf\{s \in S| \|x- s\|\}\,. $$ (Existence of such $P_s$ eventually implies that $H = S\oplus S^{c}$) 2) On the other hand, at various places, I have seen the definition of orthogonal projection to be an operator $P:H \to H$ such that: $P^2 =P$ and $P^* = P$. $\text{  }$ Here are two things I am trying to figure out: A. Are those two definitions identical in an (infinite) inseparable case? To go from 1) to 2) seems to be quite straightforward. However I could not figure out if definition 2) implies 1) in an (infinite) inseparable case. B. The other thing, if the set $S$ is not closed under addition the operator $P$ might not be linear, so is orthogonal projection required to be linear? I would appreciate any help.","['functional-analysis', 'orthogonality', 'hilbert-spaces']"
1724016,Countability of set of positive reals with bounded sum for all finite subsets,"Consider a set $B$ of positive real numbers such that the sum of elements in any finite subset of $B$ is always less than or equal to $2$. Show that $B$ is countable. I'm trying to find a bijection between $\mathbb{N}$ and $B$ but it's not clear how I would do this. I have a feeling I should be using the fact that if you have finite subsets $S$ and $T$, the sum of elements in $S \cup T$ is also $ \leq 2$... but I don't see that going anywhere.
I'd appreciate a hint, with a full solution in spoiler markdown if you can manage it.",['real-analysis']
1724032,How to reduce to the affine case? $\phi(X)$ contains a nonempty open subset of $\overline{\phi(X)}$,"Let $\phi: X \rightarrow Y$ be a morphism be varieties over an algebraically closed field.  I'm trying to prove that $\phi(X)$ contains a nonempty open subset of $\overline{\phi(X)}$.  I know how to solve the problem when $X$ and $Y$ are affine and irreducible with $\phi(X)$ dense in $Y$, and I'm trying to understand how we can reduce the problem to this case.  I am generally having trouble with problems like this, I don't understand how people can reduce to the affine case so quickly. So far I have reduced to the case where $Y$ is affine, and I'm currently trying to understand how to reduce further. By a variety , I mean a locally ringed space of $k$-valued functions with a finite open cover by open affines.  Here an affine variety is the maximal spectrum of a reduced finitely generated algebra over the (algebraically closed) field.",['algebraic-geometry']
1724043,Confidence interval of $p$ based on two random variables,"Let $f(x;p) = p\cdot f_{X_1}(x) + (1-p)\cdot f_{X_2}(x)$ where $X_1 \sim N(1,1)$ and $X_2 \sim N(0,1)$. Based on a sample of size $n = 1$ from $f(x;p)$, derive a one-sided lower $100\lambda\%$ confidence limit of $p$ I tried to find pdf of $f(x;p)$ to see if it belongs to any regular distribution but I failed. I kinda don't know any other way to approach this problem.","['statistics', 'confidence-interval']"
1724054,Is there a name for this matrix product?,"Define $A \square B = A \otimes I + I \otimes B$. Is there a name for the operation $\square$, when considered as a type of matrix product? It's a generalisation of the Cartesian product for graphs (also denoted $\square$), but I'm more interested in what can be said about it from a linear algebra point of view. Searching for ""matrix Cartesian product"" didn't turn up anything. Clearly this is quite nicely behaved in terms of eigendecomposition, since if $\mu$ and $\nu$ are eigenvalues of $A$ and $B$ then $\mu + \nu$ is an eigenvalue of $A\square B$, and the corresponding eigenvectors are also related in a simple way. Is there more that can be said about its properties than this? In addition, I am also interested in matrices that have the same pattern of zero and non-zero entries as a matrix of the form $A\square B$, but which cannot be factored into that form. Is there anything useful that can be said about the spectrum of such matrices? (If necessary, assume that the non-zero elements are all positive.) Edit: I know the answer now. (See my own answer below, which I can't accept yet for some reason.) I've asked the part about matrices with the same sign pattern as a separate question .","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1724134,Show that the group is not simple,"I want to show that: If $G$ contains a subgroup with index at most $4$ and $G$ has not a prime order, then $G$ is not a simple group. Let $N\leq G$ with $[G:N]\leq 4$. We have that $|G|=x\cdot y, \ 1<x,y<|G|$. Could yout give me a hint how we could conclude that $G$ is not simple? Do we maybe use Sylow subgroups? $$$$ EDIT: In my notes I found the following proposition: $$H\leq G, \ [G:H]=m \text{ and } |G|\not\mid m! \text{ then } G \text{ is not simple. }$$ We have that $H\leq G$ and $[G:H]=m, \ 1\leq  m\leq 4$. Suppose that $|G|\mid m!$. Then $G$ is simple. Or isn't the above proposition an off statement? If $m=1$, then $G=H$ and since $|G|\mid 1\Rightarrow |G|=1$. Therefore, $G=H=1$. In that case the group is not simple. If $m=2$, the possible values for $|G|$ are $1$ and $2$. The case $|G|=1$ is rejected. It cannot be that $|G|=2$, since $G$ has not a prime order. If $m=3$, then $|G|\mid 3!=6$, then the possible values for $|G|$ are $1,2,3,6$. 
The cases $1, 2,3$ are rejected, since $G$ has not a prime order. If $|G|=6$ then $G$ is isomorphic to $\mathbb{Z}_6$ or to $S_3$. Both of them are not simple since $\langle 2\rangle$ is normal in $\mathbb{Z}_6$ and $A_3$ is normal in $S_3$. Therefore, $G$ is not simple, a contradiction. Is this correct? If $m=4$, then $|G|\mid 4!=24$, then the possible values for $|G|$ are $1,2,3,4,6,8,12,24$. The cases $1,2,3,6$ are rejected. If $|G|=4$ we have that $G$ is abelian. We have that every subgroup of an abelian group is normal. Therefore, $G$ is not simple, a contradiction. What can we say about the cases $|G|=8$, $|G|=12$ and $|G|=24$ ?","['finite-groups', 'abstract-algebra', 'group-theory', 'simple-groups']"
1724141,Determine number of ways to distribute sixteen identical pieces of candy to five non-identical kids...,"Provided that the youngest kid must receive no more pieces than any of the others. All kids are of different ages. Just want to make sure my logic is correct... So using the pigeonhole principle, one kid will have at least 4 pieces, because 16/5 = 3 remainder 1
With that in mind, that means that the youngest kid must be getting 3 pieces at most.
I take it that it makes sense to first assign 0, 1, 2, or 3 to each then go about assigning the rest. That said, there will be 4 cases: 1) Give each 0, assign 16 to other 4:
C(20, 16) 2) Give each 1, assign 11 to other 4:
C(15,11) 3) Give each 2, assign 6 to other 4:
C(10,6) 4) Give each 3, assign 1 to other 4:
C(5,1) Then we would add them all up... Will this lead to the correct answer?","['combinatorics', 'discrete-mathematics']"
1724154,"Orthogonality Relations Exercise, Brezis' Book Functional Analysis","I studying Brezis' book and I have somes partial solutions of the exercise $1.17.$ Let be $E$ a normed space and $f\in E^*$ be a linear functional nonzero. Consider
the set  $M=[f=0]$ given by $$M=\{x\in E \ : \ \langle f,x\rangle = 0 \}.$$ Here, $\langle f,x\rangle$ denote $f(x)$ and note that $M$ is just $\ker f$. Dertemine $M^\perp.$ By definition $$M^\perp=\{g\in E^* \ : \ \langle g,x\rangle=0, \forall x\in M \}.$$ So, the first doubt is: $M^\perp$ is just $$M^\perp=\{g\in E^* \ : \ \ker f \subset \ker g  \} ?$$ Show that $\forall x\in E$, we have $d(x,M)=\inf_{y\in M}{\|x-y\|}=\frac{|\langle f,x\rangle|}{\|f\|}.$ Since $y\in M$, $|\langle f,x\rangle|=|\langle f,x-y\rangle|\le \|f\|\|x-y\|$. Then $$\frac{|\langle f,x\rangle|}{\|f\|}\le d(x,M).$$ How can I show the equality? I know that since $\{x\}$ is a compact set and $M$ is a closed subspace of $E$, there is $y_0\in M$, such that $d(x,M)=\inf_{y\in M}{\|x-y\|}=\|x-y_0\|,$ but I don't know if that it is a help. I tried to show that $\forall \varepsilon >0$, there is $z\in M$ such that $$\|x-z\|<\frac{|\langle f,x\rangle|}{\|f\|}+\varepsilon,$$ but I could not. The last doubt is: Let be $E=\{u\in C([0,1],\Bbb{R}) \ : \ u(0)=0\}$ and $f\in E^*$ given for each $u\in E$ by
  $$\langle f,u\rangle = \int_0^1 u(t)dt.$$ Show that if $u\in E-M$ then $d(u,M)$ is never achieved. For that, I tried something by absurd method but I found nothing. Can someone give a little help? Thanks.","['functional-analysis', 'normed-spaces', 'proof-verification']"
1724177,$P$ is a point on ellipse $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$ $(a>b)$ and $S$ and $S'$ are its focii,"If $P$ is a point on ellipse $\frac{x^2}{a^2}+\frac{y^2}{b^2}=1$ $(a>b)$ and $S$ and $S'$ are its focii. $\angle PSS'=\alpha$ and $\angle PS'S=\beta$, then prove that: $$
\tan\left(\frac{\alpha}{2}\right)\tan\left(\frac{\beta}{2}\right)=\frac{1-e}{1+e}
$$ I am trying to do it by taking $P$ as $(0,b)$ but not able to derive required expression. Any suggestion?","['multivariable-calculus', 'conic-sections', 'calculus', 'analytic-geometry']"
1724178,Is my current understanding of the fundamental of calculus correct?,"My current understanding: part 1) means essentially the integral is the inverse of the derivatve $$\frac {d}{dx} \int f'(x)dx = f'(x)$$ part 2) means essentially we can calculate the integral by evaluating the difference between $a$ and $b$ of the original function $$\int_{a}^{b} f'(x)dx = f(b) - f(a)$$ Is my current understanding correct? If not, a purely algebraic explanation is preferred (e.g. net change in functional value vs area under graph) - I really hate geometric interpretations. Or am I missing some crucial point? What is really particularly bothering me is that (part 1) is usually written as follows in the textbook - which I don't really understand... $$\frac {d}{dx} \int_{a}^{x}f(t)dt = f(x)$$
The change of variables between $t$ and $x$ seems redundant to me and I'm not sure if it's because of differences in personal taste or like it actually has an altogether different meaning than my interpretation - and I am actually wrong. (and this failure of understanding why unsettles me deeply)","['terminology', 'integration', 'notation', 'calculus']"
1724179,Bracket of Lie algebra-valued differential form,"In this wikipedia article: https://en.wikipedia.org/wiki/Lie_algebra-valued_differential_form the bracket of Lie algebra-valued forms is defined. At one point it mentions that it is the bilinear product $ [\cdot , \cdot]$ on $\Omega^* ( \mathfrak{g})$ such that,
\begin{equation}
[(g_1 \otimes \alpha) , (g_2 \otimes \beta)] = [g_1, g_2] \otimes (\alpha \wedge \beta) \end{equation}
for all $g_1, g_2 \in \mathfrak{g}$ and all $\alpha, \beta \in \Omega^*(M)$.
From this expression it looks like for an odd form $\alpha$, $[\alpha , \alpha] = 0$ since the second term is $0$. But this is false according to the definition 
\begin{equation}
[\alpha, \beta](X_1,\dots,X_{p+q}) := \sum_{\sigma \in S_{p+q}} \text{sgn}(\sigma) \left[\alpha(X_{\sigma(1)},\dots,X_{\sigma(p)}),\beta(X_{\sigma(p+1)},\dots,X_{\sigma(p+q)})\right]
\end{equation}
What am I missing?","['abstract-algebra', 'differential-geometry', 'lie-algebras']"
1724205,"Unit speed reparametrization, Arc-length parametrization, and Orientations.","In the text ""O'neill-Elementary differential geometry (2nd edition)"", there are following problems. As we know, any unit speed-reparametrized curve can be viewed as an arc-length reparametrizated curve. Since the arc-length reparametrized curve must achieve the positive orientation, the problem 5 can be easily proved. But, I have a question for the problem 7. $\alpha$, $\bar{\alpha}$ are unit-speed curves. Then, why we have to admit the ""minus sign""(opposite orientation)  in the problem 7? I want to know the exact difference of two problems.",['differential-geometry']
1724232,$G\times H \cong G \times K$ implies $H\cong K$,"Let $G,~H,~K$ be groups satisfying both ACC and DCC. Prove that $$G\times H \cong G \times K\Longrightarrow H\cong K$$ Prove also that $G^n \cong H^n$ implies that $G \cong H$ . By Krull-Schmidt theorem, $$G=G_1\times ...\times G_n,~H=H_1\times ...\times H_p,~K=K_1\times ...\times K_q$$ with indecomposable subgroups. If $\phi$ is an isomorphism $$\phi:~~G\times H \to G\times K$$ then $$\phi(G\times H)=\phi(G_1)\times...\times\phi(G_n)\times\phi(H_1)\times...\times\phi(H_p)$$ $$=G_1\times ...\times G_n\times K_1\times ...\times K_q=G\times K.$$ Then, what's the next step? And is second problem similar?","['abstract-algebra', 'group-theory']"
1724270,infinitely $p$-divisible elements in $A\otimes \mathbb{Z}_p$,"Let $A$ be a (possibly non-finitely generated) torsion-free abelian group. Suppose that $A$ contains no infinitely $p$-divisible elements, then does the same hold for $A\otimes \mathbb Z_p$, where $\mathbb Z_p$ denotes the $p$-adic integers? Edit: This question has been put on hold for not providing enough context, so let me give some. I encountered the problem in algebraic geometry, namely: If $A,B$ be abelian varieties, then it is well-known that the map $\mathrm{Hom} (A,B)\otimes \mathbb Z_p\rightarrow\mathrm{Hom}(T_pA,T_pB)$ is injective for all $p\neq \mathrm{char}k$, where $k$  is the ground field. I noticed that the proof of this fact would be much easier if the answer to the question were positive, which intuitively seemed plausible to me. (Of course $\mathrm{Hom} (A,B)$ is in fact finitely generated, but this is a corollary and can't be assumed in the proof). I will admit though that I don't have much confidence in my intuition in infinitely-generated situations. Here are a few thoughts I had about some intrinsic (commutative-algebra) motivation to the question: For any abelian group, we can consider the $p$-adic topology on it, just as for any $R$-module $M$ we can consider the $I$-adic topology, where $R$ is a commutative ring, and $I$ an ideal. For finitely generated modules over noetherian rings, there is a nice theory of completions. The completion $\hat M$ is itself complete and coincides with the base change to the completed ring: $\hat M\cong \hat R\otimes M$. For non-finitely-generated modules, we can still consider the $I$-adic topology, but it doesn't seem to be very well-behaved: the $p$-adic topology  in this sense on $\mathbb Q$ as a $\mathbb Z$-module is trivial. But there is another way of putting a topology on these modules: consider them as a direct limit over their finitely generated submodules, endow these with the $I$-adic topology, and look at the limit topology on $M$. In this way, $\mathbb Q$ attains the ""right"" $p$-adic topology. Since the completion of a noetherian ring is flat over the ring itself, we can also make $M\otimes \hat R$ into a topological $\hat R$-module in the same way, by writing it as the direct limit of finitely generated submodules of $M$, each tensored with $\hat R$. In the example of before we get, unsurprisingly, $\mathbb Q_p$. So now a natural question is how these objects all fit together: We have $M$ with the naive $I$-adic topology, $M$ with the limit topology, and $M\otimes \hat R$. Is $M\otimes \hat R$ the completion of $M$ with the limit topology, and is said completion itself complete? Here the completion may be defined as a projective limit over $M/U$, where $U$ ranges through open subgroups containing 0. In the question, $R=\mathbb{Z}$, $I=(p)$ and $M$ contains no infinitely $p$-divisible elements, which I think should make the naive and the limit topology on $M$ coincide and the whole situation can probably be regarded as the easiest case. If the completion is to be equal to $M\otimes \mathbb Z_p$, then there had better not be any infinitely $p$-divisible elements in there. I think this would be equivalent to the statement that $M\otimes \mathbb Z_p$ with the naive $p$-adic topology is Hausdorff. So this is more than I thought I'd write and given the speculative nature of the thing, I'm bound to have made some embarassing mistake along the way.. In any case, I'd also appreciate references about completions and the like for infinitely-generated modules. And given the above discussion, I'm also putting the commutative-algebra tag back in.","['p-adic-number-theory', 'abstract-algebra', 'commutative-algebra', 'abelian-groups', 'group-theory']"
1724342,Prove expansive function on a compact set is surjective.,"Let $M$ be a compact set and $(M,d)$ be a metric space, define function $f:M\to M$ such that for all $\,p,q\in M$ $$d(f(p),f(q))\ge d(p,q)$$
  Prove $f$ is surjective. I observed that compactness of $M$ is crucial, supposing $M$ being only closed or bounded would have counterexamples of $f$. Also I found another problem which might be related somehow, I couldn't help this but guessing we have to prove $f$ is isometric. @TommasoSeneci Thank you very much for the efforts, but as we see problem is not completely solved, so any clarification of showing $Y$(discussed in the below answer) is closed or other ways maybe, would be so appreciated!","['real-analysis', 'metric-spaces', 'compactness', 'functions']"
1724348,What is $\arctan(x) + \arctan(y)$,"I know $$g(x) = \arctan(x)+\arctan(y) = \arctan\left(\frac{x+y}{1-xy}\right)$$ which follows from the formula for $\tan(x+y)$. But my question is that my book defines it to be domain specific, by which I mean, has different definitions for different domains: $$g(x) = \begin{cases}\arctan\left(\dfrac{x+y}{1-xy}\right), &xy < 1 \\[1.5ex] 
\pi + \arctan\left(\dfrac{x+y}{1-xy}\right), &x>0,\; y>0,\; xy>1 \\[1.5ex] 
-\pi + \arctan\left(\dfrac{x+y}{1-xy}\right), &x<0,\; y<0,\; xy > 1\end{cases}$$ Furthermore, When I plot the function $2\arctan(x)$, it turns out that the book definition is correct. I don't understand how such peculier definition emerges. Thank you.","['trigonometry', 'inverse-function', 'functions']"
1724354,April Fools' Day Hoax: Fermat's Last Theorem,"I read this answer to this question on MathOverflow, and I enjoyed reading the proof given in the linked paper , but... where is the mistake? I know nothing of the Mason-Stothers Theorem except its statement and truth, and the reasoning in the paper seems to be logically sound to me. Intuitively, I feel that the result obtained (that there cannot exist complex polynomials with the given conditions) does not actually imply the statement of Fermat's Last Theorem (which deals with positive integers ), though I cannot justify this. Could anyone explain the flaw in the proof?","['number-theory', 'fake-proofs', 'proof-explanation']"
1724365,Is it true that differentiable functions can have essential discontinuity,"I was reading wiki and found this statement. Quoting it: A function f is said to be continuously differentiable if the
  derivative f'(x) exists and is itself a continuous function. Though
  the derivative of a differentiable function never has a jump
  discontinuity , it is possible for the derivative to have an essential
  discontinuity . I am confused with this statement as we know : Function is differentiable in its domain -> continuous in that domain Not continuous -> Not differentiable How does a function still be differentiable even if it is not continuous ? How It can have essential discontinuity ? I did not get it from wiki example. Please clarify :)","['derivatives', 'calculus']"
1724407,"$\Bbb Z_m \times \Bbb Z_n$ isomorphic to $\Bbb Z_{\operatorname{lcm}(m,n)}\times \Bbb Z_{\gcd(m,n)}$","I want to show the title. Let $\Bbb Z_{\operatorname{lcm}(m,n)}=\langle x\rangle$, $\Bbb Z_{\gcd(m,n)}=\langle y\rangle$, $\Bbb Z_m=\langle z\rangle$, $\Bbb Z_n=\langle w\rangle$ and $d=\gcd(m,n)$. I use the function $f\colon \Bbb Z_{\operatorname{lcm}(m,n)}\times \Bbb Z_{\gcd(m,n)}\to \Bbb Z_m\times \Bbb Z_n$ such that $f(x,1)=(z,w)$ and $f(1,y)=(z^{m/d}, w^{n/d})$ This is homomorphism, but I can't show it is injective or surjective to show that it is bijective. Help me!","['abstract-algebra', 'group-theory', 'elementary-number-theory']"
1724411,Associative neural network learning algorithm based on proximity,"For simplicity I start with a 1-layer feed-forward neural network $F$, its formula is:
$$ F: \mathbb{R}^n \rightarrow \mathbb{R}^n $$
$$ y \mapsto F(x) = ⎎(W x) $$
where ⎎ is the sigmoid function, $W$ is the $n \times n$ weight matrix. The network learns to associate inputs $x$ to outputs $y$, but it is only given reward signals (both + and - rewards).  This means, if an output is correct, the network will be given a positive reward, and vice versa. The learning algorithm generates random $x$ values, outputs its $y$ value, and get the + or - reward, adjusts its weights accordingly. My idea is:  let $y_0 = F(x_0)$.  Define an $\epsilon$-neighborhood of $y_0$ as $U(y_0)$.  The pre-image of this neighborhood is $F^{-1}(U(y_0))$. Upon getting a + reward, we want the learning algorithm to adjust the weights such that the volume of the pre-image becomes bigger, ie more points near $x_0$ will be mapped to or near $y_0$.  This is a form of generalization based on proximity. If $\epsilon$ is small, the volume of $F^{-1}(U)$ is approximately equal to the volume of $U$ scaled by the Jacobian determinant: $$ \det J = \left| \frac{\partial F^{-1}(y)}{\partial y} \right|$$ Using gradient descend (as we do in back-propagation), we want to adjust weights to maximize (or minimize if negative reward) the Jacobian, ie, in the direction of $\nabla_W \cdot |J| =  \left[\frac{\partial \det J}{\partial W} \;\right]$.  This is my reasoning. Calculations: I'm not sure if this step is correct:
$$ \det J = \left| \frac{\partial W^{-1}⎎^{-1}(y)}{\partial y}  \right| $$
$$ \stackrel{?}{=} \left| W^{-1} S \right| $$
where $S$ is a diagonal matrix with entries $1/({ ⎎'(⎎^{-1}(y)) })$. We seek the matrix $\frac{\partial \det J}{\partial W}$ whose entries are $\frac{\partial \det J}{\partial w}$ This involves finding the derivative of a determinant:
$$ \frac{\partial}{\partial w} |J| = tr( |J| \cdot J^{-1} \cdot \frac{\partial J}{\partial w})$$ 
where the last factor in the above RHS is:
$$ \frac{\partial J}{\partial w} = \frac{\partial W^{-1} S }{\partial w} $$
$$ \stackrel{?}{=} \frac{\partial W^{-1}}{\partial w}S + W^{-1} \frac{\partial S}{\partial w} $$
$$ \stackrel{?}{=} -W^{-1} \frac{\partial W}{\partial w} W^{-1} S + W^{-1} \hat{S} $$
where $\hat{S}$ is a diagonal matrix with entries:
$$ -\frac{⎎''(⎎^{-1}(y))}{⎎'(⎎^{-1}(y))^3} ⎎'(Wx) \frac{\partial W}{\partial w} x$$ Is the above correct?","['neural-networks', 'differential-geometry']"
1724419,How to test if vectors are equidistributed on the unit sphere,I can create a large collection of normalized real valued $n$-dimensional vectors from some random process which I hypothesis should be equidistributed on the unit sphere.  I would like to test this hypothesis. What is a good way numerically to test if vectors are equidistributed on the unit sphere? I am writing computer code so I will be testing that way Is there some way to visualise the distribution given that my vectors are in $n$ dimensions?,"['statistics', 'probability', 'visualization']"
1724433,The birthday paradox [duplicate],"This question already has answers here : Explain the Birthday Paradox (4 answers) Closed 8 years ago . I would like a better understanding of the famous birthday paradox. 
""What is the probability that, in a set of n randomly chosen people, some pair of them will have the same birthday?"" I understood the first part, where the probability reaches 100% when the number of people reaches 367 by the pigeonhole principle.
But I am not understanding the explanation beyond that.
How do they say that the probability is 99.9% with 70 people and 50% with 23 people? And how do you further generalize the answer?
And why is it a ""paradox""?","['birthday', 'statistics', 'probability']"
1724467,How to determine whether domain is an open or a closed region (or both open and closed)?,"Right now I am studying Partial Derivative in my university, but I am confused in its basic topic; Multi-variable Functions More specifically, I am having difficulty in understanding open or closed domain regions in XY Plane and whether they are bounded or not? For Example: Question Given that $f(x, y)=x^2 - y^2$ (a) Find the function's domain (b) Find the function's range (c) Describe function's level curves (d) Find the boundary of the function’s domain (e) Determine if the domain is an open region, a closed region, or neither (f) Decide if the domain is bounded or unbounded Solution (a) Domain: Entire XY Plane (b) Range: $(-\infty, \infty)$ (c) Level Curves: $x^2-y^2=c$ (d) Since the domain is entire plane, there is no boundary (e) Following is my understanding of open and closed domain in XY Plane: A domain (denoted by region R) is said to be closed if the region R contains all boundary points If the region R does not contain any boundary points , then the Domain is said to be open If the region R contains some but not all of the boundary points , then the Domain is said to be both open and closed The answer in book is: both open and closed , but how can we even say that if there is no boundary as answered in part (d)? (f) Following is my understanding of bounded and unbounded domains: If the boundary points form a closed loop, then the domain is said to be bounded, otherwise they are considered unbounded. OR Books Definition : A region in the plane is bounded if it lies inside a disk of finite radius. A region is unbounded if it is not bounded. The answer of this part in book is: Unbounded , and this is because I think (please correct me if I am wrong), since there is no boundary, the region can not be bounded, so by default, the region is unbounded.","['multivariable-calculus', 'functions']"
1724527,Construction of a group where nonempty words of small length are not equal to the identity element,"Let $n$ and $p$ be positive integers. Is there a finite group $G_p$ generated by elements $a_1, \dots, a_n$ such that any nonempty reduced word on $a_1, \dots, a_n, a_1^{-1}, \dots, a_n^{-1}$ of size $\leq p$ is not equal to the identity element? I know that the answer is yes (it follows from the residual finiteness of the free group of rank $n$ ). But I would like a more constructive solution. Ideally, I would like to know the examples of such $G_p$ , that satisfy $\log |G_p| = O(p)$ .","['finite-groups', 'abstract-algebra', 'group-presentation', 'finitely-generated', 'group-theory']"
1724535,Diagonals of squares on curved functions,"I just came across an integration problem. It is very easy to plug numbers into the steps of the solved problem and arrive at the right answer, but I don't understand one of the choices of formulas within the solution chain. Here is the whole problem: A solid lies between planes perpendicular to the $x$-axis of $x=0$ and $x=14$. The cross-sections perpendicular to the axis on the interval $0\leq x\leq\ 14$ are squares (Squares? What the heck??) with diagonals that run from the parabola $y=-2\sqrt{x}$ to parabola $y=2\sqrt{x}$. Find the volume of the solid. So, I am really bothered by the way that this problem uses the words ""cross-sections,"" ""squares,"" and ""diagonals."" I feel as though none of the math that I learned that lead up to this has really prepared me to be able to look at a graph of the said parabola and just come up with this solution chain. There is absolutely nothing ""diagonal"" looking about the graph of this problem. The solution chain also gives $\dfrac{D^2}2$ as the formula $A(x)$ to use as the formula for area. But why???? I can easily plug the length of the line segment that runs parallel to the $y$-axis into $A(x)$ and get $\dfrac{(|y_1|+|y_2|)^2}2 = \dfrac{(4\sqrt{x})^2}2 = 8x$. I can also easily integrate $\int^{14}_{0} 8x\,dx = 784$ cubic units. But I would never think to use $\dfrac{D^2}2$ in this problem out without looking at the solution, and I this greatly bothers me!!! Am I supposed to be thinking of this problem in three dimensions?","['volume', 'integration', 'calculus', 'solid-geometry']"
1724537,Statistics Hypothesis test on a single sample,"I'm revising for my statistics exam that's coming up but I have a few questions without solutions in the book. I've worked out an answer however I'm not sure if it's correct. This question is: In order for a clothes washer to qualify for ENERGY STAR, it must have
a Modified Energy Factor (MEF, a dimensionless quantity) of 1.42 or greater. Thirty-eight
Speed Queen commercial washers were selected at random, and the MEF for each was measured.
The sample mean was x = 1,228. Assume the distribution of MEF is normal and
σ = 0.5. Conduct a hypothesis test to determine whether there is any evidence the mean
MEF of this Speed Queen washer is less than 1.42. Use α = 0.01. So my first step was to declare the variables from the question: H0 = μ = 1.42 Ha = μ < 1.42 x̅ = 1.228 σ = 0.5 α = 0.01 Then I put that in the z score formula: z = x̅ - H0 / (σ/sqrt(n)) z = 1.228 - 1.42 / (0.5/sqrt(38)) z = -2.367 Now I can look up the z table for a p value of p = 0.0091 Then I conclude that I reject the null hypothesis because the p value is < than alpha the level of significance; 0.0091 < 0.01. Is this the correct answer/approach?","['statistics', 'hypothesis-testing']"
1724596,Equivalent definition of properly discontinuous action,"In the book An Introduction to Differentiable Manifolds and Riemannian Geometry by Boothby in Chapter $3$ the author gives the following definition: Definition($8.1$) A discrete group $\Gamma$ is said to act properly discontinuously on a manifold $M$ if the action is $C^\infty$ and satisfies the following two conditions: (i) Each $x\in M$ has a neighborhood $U$ such that the set $\{h\in \Gamma|hU\cap U\neq \emptyset\}$ is finite; (ii) If $x, y \in M$ are not in the same orbit, then there are neighborhoods
  $U , V$ of $x , y$ such that $U\cap \Gamma V =\emptyset$. In Exercise $3$ of this chapter the auther want to show that the following statement can be replaced by (i): (i') The isotropy group $\Gamma_x$, of each $x\in M$ is finite, and each $x$ has a neighborhood $W$ such that $hW\cap W=\emptyset $ if $h\notin \Gamma_x $ , and $hW=W$ if $h\in \Gamma_x$. Clearly (i') implies (i) . I want to show that (i) implies (i') and I stuck here. I know that (i) shows that $\Gamma_x$ is finite and I could find a nbd of $x$ such that $hU=U$ for $h\in \Gamma_x$ (If $\Gamma_x=\{h_1,...,h_n\}$ then $W=\cap_i^n(U\cap h_iU)$ satisfies $hW=W$ if $h\in \Gamma_x$ ) but I have o problem to show that  $hU\cap U=\emptyset $ if $h\notin \Gamma_x $.","['manifolds', 'smooth-manifolds', 'differential-geometry']"
1724599,Convergence of $\prod (1+ta_n)$ implies convergence of $\sum a_n$ and $\sum a_n^2$,"Let $a_n$ be a sequence of real numbers and assume that $\prod _n(1+ta_n)$ converges for two non-zero values of $t$ , say $t_1, t_2\in \mathbb R\setminus \{0, -1/a_1, \ldots, -1/a_i, \ldots \}$ . Prove that $\sum a_n$ and $\sum a_n^2$ converges. I'm absolutely stuck on this problem. I can't use any of the usual convergence criteria because there's no positivity assumption on the $a_n$ . I'd appreciate some hints.","['products', 'real-analysis', 'sequences-and-series']"
1724606,Proof by Contradiction relating to rational and irrational numbers,"I've been given the question: given $x,y\in\mathbb{R}\setminus\mathbb{Q}$ and $x+y =\frac{m}{n}$ , prove $x-y$ is irrational. I tried solving this using a proof by contradiction but I feel like I got a bit off base and I feel like I've screwed up somewhere. Proof by Contradiction $x,y \in \mathbb{R} \backslash \mathbb{Q}$ $x + y = \frac{m}{n}$ , $m,n \in \mathbb{Z}$ , $n \neq 0 $ $y = \frac{m}{n} - x$ Assume $x-y$ is rational $x-y = \frac{p}{q}$ , $p, q \in \mathbb{Z}$ , $q \neq 0$ $x - (\frac{m}{n} - x) = \frac{p}{q}$ , using $y = \frac{m}{n} - x$ $2x - \frac{m}{n} = \frac{p}{q}$ $\frac{2xn-m}{n} = \frac{p}{q}$ $q(2xn-m) = pn$ $2xn-m = \frac{pn}{q}$ $2xn = \frac{pn}{q} + m$ $x = \frac{(\frac{pn}{q} + m)}{2n}$ $\therefore$ Contradiction as $x$ is irrational Here is my working. Have I made any mistakes and is it okay to assume that since all the variables in the final fraction are integers that it is rational?","['irrational-numbers', 'proof-verification', 'algebra-precalculus', 'proof-explanation', 'discrete-mathematics']"
1724610,$2005$th derivative of $f$ at $0$,"So I tried using Leibnitz formula to solve by recurrence, but I can just get to one point and then it's a mess again. Problem is Let $f(x)=\frac{1}{1+2x+3x^2+\ldots+2005x^{2004}}$. Find $f^{[2005]}(0)$. What I did is to notice that $f'=-f^2g$, where $g$ is the polynomial, and then tried to expand the result to higher order derivatives. By Leibnitz formula and the last expression, I got $f^{[2005]}(0)=\displaystyle\sum_{k=0}^{2004}\binom{2004}{k}\left(f^2\right)^{[k]}(0)g^{[2004-k]}(0)=\sum_{k=0}^{2004}\binom{2004}{k}\left(f^2\right)^{[k]}(0)(2004-k)!
=\sum_{k=0}^{2004}\frac{2004!}{k!}\left(f^2\right)^{[k]}(0)$ I'd really appreciate some help here, please.","['derivatives', 'induction', 'recurrence-relations', 'calculus']"
1724715,why equal variance assumption is necessary in T-test,"So I generally understand the basis for the t-test: i.e. you take advantage of the fact that you can make $\bar{X}-\bar{Y}$ standard normal: $$Z = \frac{((\bar{X}-\bar{Y})-(\mu_X-\mu_Y))}{\sigma \sqrt{\frac{1}{n}+\frac{1}{m}}}$$ where $\sigma$ is the variance shared by the normal random variables $X$ and $Y$. Furthermore, the unbiased estimator for $\sigma^2$ is: $$S_p^2 = \frac{1}{m+n-2}\left(\sum{(X_i-\bar{X})^2}+\sum{(Y_i-\bar{Y})^2}\right)$$ which can be represented as a $\chi^2$ random variable using the fact that: $\;\;\;\;\;\;\;\;\: \dfrac{(m+n-2)S_p^2}{\sigma^2}\:\:$ is $\:\:\:\chi^2$ and then you combine these distribution functions to get a T distribution. What I don't understand is why the variances have to be equal (in this case, not talking about the wilcox test or anything like that). For example, what if you just had $\sigma_X^2 = a \sigma_Y^2$? where you knew the constant $a$. I tried to go through the derivation for the T-distribution and didn't come across any problems, I just had to include the constant $a$ in different places. If someone could direct me towards a reference or help me understand why this is the case I'd be very appreciative. I tried searching for the answer with no luck. Thanks!","['probability-theory', 'statistical-inference', 'confidence-interval', 'probability-distributions']"
1724745,Computing Sectional Curvature on Hyperbolic Plane,"For a pair of $(X,Y)$ of linearly independent vectors in $T_pM$, $p\in M$, the sectional curvature is defined as $$K_p(X,Y)=\frac{<R(X,Y)Y,X>}{|X|^2 |Y|^2 - <X,Y>^2}$$ The problem I'm looking at now asks us to compute the same on the half-plane $\mathbb{H} = \{(x,y) \in \mathbb{R}|y>0\}$ with the metric $g= 1/y^2(dx^2 + dy^2)$ (and hence show that it is the constant $-1$). The provided solution has an equality that I don't understand: $$K(\partial_1, \partial_2) = \frac{<R(\partial_1,\partial_2)\partial_2,\partial_1>}{(1/y^2)(1/y^2) - 0} = y^4\frac{1}{y^2}R^2_{112}$$ How is this last equality justified? Namely, I want to understand how the author arrived at this particular set of indices for $R$. I see that the metric is involved because of the inner product, but the details escape me. A breakdown of the steps would be much appreciated!","['manifolds', 'riemannian-geometry', 'differential-geometry', 'curvature']"
1724789,Are the weak* and the sequential weak* closures the same?,I have a question that might be easy for the experts. Let $E$ be a Banach space (non-separable) and let $E'$ be its dual space. Suppose that $X\subset E'$ and assume that $X$ is separable with respect to the weak* topology. My question is the following: Are the sequential weak* closure and the weak* closure of $X$ equal? Google was not able to help me on this.,"['functional-analysis', 'general-topology', 'banach-spaces', 'weak-convergence']"
1724812,Calculus - finding the difficult limit $\lim_{x \to 0} \frac{1-(\cos x)^{\sin x}}{x^2}$,I'm struggling with the following limit: $$\lim_{x \to 0} \frac{1-(\cos x)^{\sin x}}{x^2}$$ Don't know where to start with this. Hints/solutions very appreciated.,"['calculus', 'limits']"
1724834,Isomorphic and Homomorphic,"I was wondering if someone could explain the ideas behind isomorphisms and homomorphisms and the difference between them. I understand that a linear map is an isomorphism if it is bijective, and that an isomorphism is a bijective homomorphism but I don't fully understand what a homomorphism actually is. For example, what does it mean to say that $Hom_{\mathbb{C}}\left(\mathbb{C}^2,\mathbb{C}^3\right)\simeq MAT_{\mathbb{C} }\left(3,2 \right)$ where $MAT_{\mathbb{C}}$ is the $3\times2$ matrix with complex entries. After some research, I think that this example is saying that $Hom_{\mathbb{C}}\left(\mathbb{C}^2,\mathbb{C}^3\right)$ is essentially a perfect approximation of $MAT_{\mathbb{C} }\left(3,2 \right)$ however I am struggling to understand what the notation $Hom_{\mathbb{C}}\left(\mathbb{C}^2,\mathbb{C}^3\right)$ actually means. Note: I haven't studied a course in group theory and therefore have little knowledge on it, this is for a Linear Algebra Course","['abstract-algebra', 'group-homomorphism', 'group-isomorphism', 'group-theory', 'linear-algebra']"
1724838,Is testing on $L^2 \cap L^{\infty}$ sufficient?,"I want to show that some operator $T:L^2  \rightarrow L^2$ is a $L^{1}$ contraction, i.e. I want to show that for all $f \in L^2 \cap L^{1}$ we have $$\|(Tf)\|_1 \le \|f\|_1.$$ To do so, I used $g \in L^2 \cap L^\infty$ and proved $$|\langle Tf ,g \rangle |\le \|f\|_1 \|g\|_\infty.$$ If $L^2 \cap L^\infty$ was dense in $L^\infty$, then this would show me by Hahn-Banach that $\|Tf\|_1\le \|f\|_1.$ But unfortunately this is not true. Does anybody know whether this conclusion is still valid?","['functional-analysis', 'real-analysis', 'analysis']"
1724859,Show that the congruence $x^{p-1} \equiv 1 \pmod {p^2}$ has precisely $p-1$ solutions modulo $p^2$,"Let $p$ be a prime number. Show that the congruence $x^{p-1} \equiv 1 \pmod {p^2}$ has precisely $p-1$ solutions modulo $p^2$ I know the statment above is true for modulo $p$, but how is this imply to modulo $p^2$",['number-theory']
1724884,Steps to prove or disprove if two rings are isomorphic,"So i'm struggling on how to prove if two rings are not isomorphic to one another. My professor told me that if a ring is not isomorphic to another, the best way to prove that this is true is to find a preserved property of isomorphisms that is not held.
So i considered the following:
1.Q and R (quotients and rationals) 2.$~~\mathbb{Z}/4\mathbb{Z}\times \mathbb{Z}/4\mathbb{Z}$ and $\mathbb{Z}/16\mathbb{Z}$ (Z mod 4 cross Z mod 4 and Z mod 16) I cannot seem to think of any of the properties:
communicative, identity, integral domain, and field property that do not hold for rings. My professor told me this it isnt enough to give an example mapping like F: Q -> R and show that it isnt isomorphic.
Hence, how can i show that these two problems above arent isomorphic? Can anyone give me some finite steps to prove is something is isomorphic to something or not?","['ring-theory', 'proof-writing', 'group-theory', 'group-isomorphism']"
1724885,Discrete and continuous Girsanov,"I'm trying to write a proof of the Girsanov theorem based on a discrete version of it. Discrete version Suppose that I have a random vector $X$ and two equivalent probability measures $\mathbb{P}, \mathbb{Q}$. In $\mathbb{P}$, $X$ is an uncorrelated multivariate normal random variable. In $\mathbb{Q}$, $X$ is an uncorrelated multivariate normal random variable with mean $0$ (and the same variance). The goal is to find the change of measure $\frac{d\mathbb{Q}}{d\mathbb{P}} : \Omega \to \mathbb{R}$ to make this happen. So in symbols, we have $$ X_* \mathbb{P} \sim N(\mu, \mathrm{diag}(\sigma))$$
$$ X_* \mathbb{Q} \sim N(0, \mathrm{diag}(\sigma))$$ Writing $\lambda^n$ for the Lebesgue measure on $\mathbb{R}^n$ and writing out the densities we get: $$ \frac{d X_* \mathbb{Q}}{dX_* \mathbb{P}} (\mathbf{x}) = 
 \frac{d X_* \mathbb{Q}}{dX_* \lambda^n} (\mathbf{x})
\frac{d X_* \lambda^n}{dX_* \mathbb{P}} (\mathbf{x}) \\
= 
\frac{\prod_{i=1}^n \frac{1}{\sqrt{2 \pi} \sigma_i} \exp\left\{-\frac{x_i^2}{2\sigma_i^2} \right\}}
{\prod_{i=1}^n \frac{1}{\sqrt{2 \pi} \sigma_i} \exp\left\{-\frac{(x_i-\mu_i)^2}{2\sigma_i^2} \right\}} \\
= \exp\left\{ \sum_{i=1}^n \frac{-2\mu_ix_i + \mu_i^2}{2\sigma_i^2} \right\} \\
= \exp\left\{ - \sum_{i=1}^n \frac{\mu_ix_i}{\sigma_i^2} + \frac{1}{2} \sum_{i=1}^n\frac{\mu_i^2}{\sigma_i^2} \right\}
$$ Now let $B \in \mathcal{B}^n$ a Borel set in $\mathbb{R}^n$. $$ \mathbb{Q} (X^{-1} (B)) = X_* \mathbb{Q} (B) \\
= \int_B \frac{dX_*\mathbb{Q}}{dX_*\mathbb{P}} dX_*\mathbb{P} \\
= \int_{X^{-1}(B)} \left( \frac{dX_*\mathbb{Q}}{dX_*\mathbb{P}} \circ X  \right) d\mathbb{P} $$ So it is sufficient to choose $\frac{d\mathbb{Q}}{d\mathbb{P}} = \frac{dX_*\mathbb{Q}}{dX_*\mathbb{P}} \circ X$. Therefore $$\frac{d\mathbb{Q}}{d\mathbb{P}} = \exp\left\{ - \sum_{i=1}^n \frac{\mu_iX_i}{\sigma_i^2} + \frac{1}{2} \sum_{i=1}^n\frac{\mu_i^2}{\sigma_i^2} \right\}$$. This result is what I would call the ""discrete Girsanov formula"".
My question is whether it is possible to prove the continuous version as a limit of this one. Continuous version $X(t) = W(t) + \int_0^t \Theta(u) du$ where $W(t)$ is a $\mathbb{P}$ Brownian motion and $\Theta(u)$ is an adapted process. Assuming that $X(t)$ is a $\mathbb{Q}$ Brownian motion, $$ \frac{d\mathbb{Q}}{d\mathbb{P}}
= \exp\left\{ \int_0^t \Theta(u) dW(u) + \frac{1}{2} \int_0^t \Theta(u)^2 du  \right\} \\
= \exp\left\{ -\int_0^t \Theta(u) dX(u) + \frac{1}{2} \int_0^t \Theta(u)^2 du  \right\}$$ (This statement is paraphrased from Shreve's Stochastic Calculus for Finance, and is probably missing the $L^2$ condition) It looks an awful lot like the discrete version! My question is: is it possible to pass from the discrete to the continuous version by a partitioning argument? It doesn't have to be super-rigorous (I don't even fully understand the construction of Brownian motion).","['stochastic-processes', 'brownian-motion', 'probability', 'stochastic-calculus']"
1724897,"In $\triangle ABC$, if $\cos A\cos B\cos C=\frac{1}{3}$, then $\tan A\tan B+\tan B \tan C+\tan C\tan A =\text{???}$","In $\triangle ABC$, if 
  $$\cos A \cos B \cos C=\frac{1}{3}$$ 
  then can we find value of 
  $$\tan A\tan B+\tan B \tan C+\tan C\tan A\ ?$$ Please give some hint. I am not sure if $\tan A \tan B+\tan B \tan C+\tan C \tan A$ will be constant under given condition.","['trigonometry', 'triangles']"
1724930,Integral of quotients of $\sin$ function,"I am trying to calculate the definite integral
$$\int_0^\pi \frac{\sin(\frac{21}{2}x)}{\sin(\frac{1}{2}x)} dx.$$
Wolfram Alpha says here that the answer is $\pi$. I replaced 21 by other constants and think that in general, $\int_0^\pi \frac{\sin(\frac{n}{2}x)}{\sin(\frac{1}{2}x)} dx = \pi$ for all odd $n \in \mathbb Z$. However I have no idea how to approach this problem. I tried substituting $u = x/2$ to simplify the integral a bit to
$$2\int_0^{\pi/2} \frac{\sin(nu)}{\sin(u)}.$$
Then I thought that I could maybe use the identity $\sin(nx) = \sin(x)\cos( (n-1)x) + \sin((n-1)x)\cos(x)$. For instance, since
\begin{align*}
\sin(3x) &= \sin(2x)\cos(x) + \cos(2x)\sin(x) \\
&= 2\sin(x) \cos^2(x) + \cos^2(x)\sin(x) - \sin^3(x) \\
&= \sin(x)(3\cos^2(x) - \sin^2(x))
\end{align*}
the integral would become
$$ 2\int_0^{\pi/2} 3\cos^2(x) -\sin^2(x) dx $$
which I am able to solve:
\begin{align*}
2\int_0^{\pi/2} 3\cos^2(x) -\sin^2(x) dx &= 2[\frac{3}{2}(x+\sin(x)\cos(x)) - \frac{1}{2}(x - \sin(x)\cos(x))]^{\pi/2}_0 \\
&= [2x + 4\sin(x)\cos(x)]^{\pi/2}_0 \\
&= \pi.
\end{align*}
However I don't know how to generalize this approach because the expansion for $\sin(21x)$ would have lots of unwieldy terms. Is there another way to do this problem that I am missing?","['integration', 'calculus']"
1724945,Differential forms on a projective curve: two constructions,"Let $X$ be a projective curve on a perfect field $k$ ($k$-scheme integral, separated, of finite type) and let $K$ be the function field of $X$. Let's compare the following two constructions: 1. If $B$ be an $A$-algebra, the module of relative differential forms of $B$ over $A$ is a $B$-module $\Omega^1_{B|A}$. Therefore in my case I can define the $K$-vector space $\Omega^1_{K|k}$ which has dimension $1$. It is often called the ""vect. space of rational differential forms"" . Any element $\omega\in\Omega^1_{K|k} $ defines a divisor $(\omega)$ and for any other $\omega'\in \Omega^1_{K|k}$, we have that $(\omega)\sim(\omega')$. Any member in the class of such ""differential divisors"" is the canonical divisor of the curve $K_X$. 2. Let $s:X\longrightarrow \text{Spec}\, k$ be the structure morphism. By a glueing procedure involving $s$, which is well described in Liu's book (Prop. 6.1.17), one can define sheaf of differential forms over $X$ denoted as $\Omega^1_X$ (or $\Omega^1_{X|k}$). It is an invertible sheaf, and the associated divisor (up to equivalence) is the canonical divisor $K_X$. What is the relationship between the vector space $\Omega^1_{K|k}$
  and the sheaf $\Omega^1_X$? Why is the ``final'' canonical divisor $K_X$
  the same?","['divisors-algebraic-geometry', 'algebraic-geometry', 'differential-forms', 'schemes', 'algebraic-curves']"
1724952,holomorphic function on unit disk $D$,"Suppose $f$ is holomorphic on $D= (\ z:|z|<1)$ and $f$ is an even function 
(i.e. $f(z)=f(-z)$). Show that there is a holomorphic function $g$ on $D$ such that $g(x) = f(\sqrt{x})$ for all positive real numbers $x<1$. Here is my attempt: $f$ even $\implies f'$ odd $\implies f''$ even $\implies\cdots \implies f(z) = a_0 + a_2 z^2 + a_4 z^4 + \cdots$ Now let $g(z) = b_0 + b_1 z + b_2 z^2 + \cdots$ Is it simple to put $x$ and $\sqrt{x}$ to $f$ and $g$ respectively such that $g(x) = f(\sqrt{x})$?
How about $a_n$ and $b_n$? Are they equal?","['derivatives', 'complex-analysis', 'functions']"
1724959,a dynamical systems view of the central limit theorem?,"I have seen many heuristic discussions of the classical central limit theorem speak of the normal distribution (or any of the ""stable distributions"") as an ""attractor"" in the space of probability densities. For example, consider these sentences at the top of Wikipedia's treatment : In more general usage, a central limit theorem is any of a set of weak-convergence theorems in probability theory. They all express the fact that a sum of many independent and identically distributed (i.i.d.) random variables, or alternatively, random variables with specific types of dependence, will tend to be distributed according to one of a small set of attractor distributions . When the variance of the i.i.d. variables is finite, the attractor distribution is the normal distribution. This dynamical systems language is very suggestive. Feller also speaks of ""attraction"" in his treatment of the CLT in his second volume (I wonder if that is the source of the language), and Yuval Flimus in this note even speaks of the ""basin of attraction."" (I don't think he really means ""the exact form of the basin of attraction is deducible beforehand"" but rather ""the exact form of the attractor is deducible beforehand""; still, the language is there.) My question is: can these dynamical analogies be made precise? I don't know of a book in which they are. Roughly, I imagine taking the phase space to be a suitable infinite-dimensional function space (the space of probability densities, say with finite variance) and taking the evolution operator to be repeated convolution with an initial condition. But I have no sense of the technicalities involved in making this picture work or whether it is worth pursuing. I would guess that since I can't find a treatment that does pursue this approach explicitly, there must be something wrong with my sense that it can be done or that it would be interesting. If that is the case, I would like to hear why.","['probability-limit-theorems', 'probability-theory', 'dynamical-systems']"
1724973,Prove that $\sum_{n=1}^\infty \left(\phi-\frac{F_{n+1}}{F_{n}}\right)=\frac{1}{\pi}$,"So, I know that $$\lim_{n\to\infty}\frac{F_{n+1}}{F_n}=\phi$$ where $F_n$ stands for the n'th Fibonacci number I was interested in measuring the error of the convergence of the above limit and was drawn to the conjecture that: $$\sum_{n=1}^\infty \left(\phi-\frac{F_{n+1}}{F_{n}}\right)=\frac{1}{\pi}$$ How might we go about proving this result? Edit: The solution is actually not $\frac{1}{\pi}$. I had thought that it was due to how close the sum and $1/\pi$ actually are. I am curious (if one exists) if there is a closed form for the sum.","['summation', 'golden-ratio', 'limits']"
1724986,Is $f(x)= \frac{1}{x} - \frac{1}{e^x-1}$ monotonic?,"We have $\displaystyle f(x)= \frac{1}{x} - \frac{1}{e^x-1}$, additionally $f(0)=\frac{1}{2}$. Determine whether $f(x)$ is monotonic. I tried to do this by checking if $f'(x)<0$, however it does not look very helpful. I don't know if it's tricky, or I am just blind to something obvious here. Thanks for any hints in advance!","['derivatives', 'real-analysis', 'monotone-functions', 'analysis']"
1724991,Questions about Fine Sheaves and Resolutions,"I'm currently trying to understand the sort of ad hoc way of computing sheaf cohomology through acyclic resolutions, and related ideas.  I understand that if you want to compute the sheaf cohomology of a sheaf $\mathcal{F}$, you can find a resolution by acyclic objects $\mathcal{C}^{i}$, with an exact sequence $0 \to \mathcal{F} \to \mathcal{C}^{0} \to \mathcal{C}^{1} \to \ldots$ We can then define the sheaf cohomology of $\mathcal{F}$ to be the cohomology of the complex of global sections of the acyclic objects: $H^{q}(X, \mathcal{F}) = H^{q}(\Gamma(\mathcal{C}^{*}))$ (I) So I'm curious what the point is in defining more restrictive notions of acyclicity like fine, soft, or flasque sheaves?  In particular, I'm curious about fine sheaves.  How exactly does the existence of the partition of unity property help us to compute sheaf cohomology?  Perhaps the idea is that when you have more restrictive definitions, you have more structure available to exhibit the existence of these objects? (II) I think I understand the proofs that both flasque and fine sheaves are individually also soft and acyclic.  However, how do flasque and fine sheaves compare?  Are they just similarly refined, yet unrelated notions which are helpful in different circumstances? (III) Finally, I was hoping for a bit of intuition about fine sheaves themselves.  Is it perhaps a helpful intuitive crutch to think of a fine sheaf as a $C^{\infty}(X)$-module?  I think these are examples of fine sheaves, but perhaps the partition of unity definition is most intuitive when you imagine being able to multiply sections by bump functions on the space. Thanks in advance for any help!","['algebraic-topology', 'algebraic-geometry']"
1724994,Phase portrait of ODE in polar coordinates,"Given the system of ODEs in polar coordinates, $$r' = r(1-r^2)(4-r^2)$$ $$\theta'=2-r^2,$$ one can determine its equilibrium points and limit cycles as follows: $\gamma_1:= \begin{cases} r = 0,\\ \theta = 2t\end{cases}$, $\gamma_2:= \begin{cases} r = 1,\\ \theta = t\end{cases}$, $\gamma_3:= \begin{cases} r = 2,\\ \theta = -2t\end{cases}$. $\gamma_1$ corresponds to $(0,0)$ in the $xy$-plane, and $\gamma_2$ and $\gamma_3$ correspond to circles. Now I need to sketch the phase portrait of this system and, based on this sketch, determine the stability of the equilibrium points and limit cycles. Does one need to solve this system explicitly in order to sketch the phase portrait, or is there a neater way to do it, without solving the system? I've also tried with solving for the ODE in terms of $\frac{d\theta}{dt}$, but it doesn't appear to be an equation which is easy to plot either. Also, do you think that I've found all the possible limit cycles, or maybe missed something? I'm new to this kind of analysis.","['real-analysis', 'dynamical-systems', 'polar-coordinates', 'stability-in-odes', 'ordinary-differential-equations']"
1725048,Is $every$ prime factor of $\frac{n^{163}-1}{n-1}$ either $163$ or $1\;\text{mod}\;163$?,"This was inspired by this question . More generally, given prime $p$ and any integer $n>1$, define, $$F(n) = \frac{n^p-1}{n-1}=n^{p-1}+n^{p-2}+\dots+1$$ Q: Is every prime factor of $F(n)$ either $p$, or $1\;\text{mod}\;p$?","['number-theory', 'congruences', 'prime-factorization', 'prime-numbers']"
1725116,Pushforward of a representation?,"Suppose that $G$ is a finite group, and $G/N$ is a quotient. Given a representation of $G$, is there a ""natural"" way to construct a representation on $G/N$? (I.e. a pushforward representation, analogous to induction for an inclusion.) ""Natural"" I mean ... maybe left or right adjoint to the pullback from $Rep(G/N)$ to $Rep(G)$. I don't know exactly. If not, then maybe there is a good reason why such a thing cannot exist? I'd like to ask the the more general question: if $G$ and $E$ are finite, connected groupoids, $G \to E$ a functor, and $F : G \to Vect$ a functor. Can $F$ be pushed forward to a functor on $E$? As motivation: I would like to understand how to build the induced bundle construction categorically: we start with a representation of $H$, a functor $F$ from $BH$ (groupoid of $H$ torsors) to $Vect$, and try to push $F$ forward along the inclusion of $BH$ into the action groupoid $G/H$. (Then to get the induction construction, ""pushforward"" again to $BG$.) The question A construction of a pushforward of Vect-presheves. popped up while writing this question. There is a link to a paper of Jeffrey Morton which seems to indicate the answer to the general question is something like yes, if I'm understanding correctly (which almost surely I am not). It seems that the construction I am looking for is that of a Kan extension, at least in the case of an inclusion of groups. I'm not really sure what is going on.","['category-theory', 'representation-theory', 'group-theory', 'groupoids']"
1725180,Evaluate the integral $\int_0^{2\pi} \frac{d \theta}{5-3 \cos \theta}$,"$$\int_0^{2\pi} \frac{d \theta}{5-3 \cos \theta}$$ My attempt: Let $z=e^{i\theta}$ which gives $d\theta = \frac{dz}{iz}$ Thus, $$\oint_C \frac{1}{5-3(\frac{z+z^{-1}}{2})}\frac{dz}{iz}$$ $$=\frac{1}{i}\oint_C \frac{dz}{(3z-1)(z-3)}$$ We can ignore the singularity at $z=3$ because it lies outside the unit circle and thus we don't need to account for it when computing the residues. $$=\frac{1}{i}\oint_C f(z) \, dz = 2\pi [\operatorname{Res}(f(z),\frac{1}{3})]$$ $$\operatorname{Res}(f(z),\frac{1}{3})=\frac{\lim_{z\to1/3} (3z-1)\cdot \frac{1}{(3z-1)(z-3)}}{0!}$$ $$=-\frac{9}{8}$$ Which yields: $$=\frac{1}{i}\oint_C f(z) \, dz = 2\pi [-\frac{9}{8}]$$ $$=-\frac{9\pi}{4}$$ But how can I have a negative answer for an integration??? Did I make a mistake somewhere??","['complex-analysis', 'contour-integration', 'complex-numbers']"
1725210,"Why is $f(U) \cap V$ the zero set of $y^{n+1}, \dots, y^m$? [duplicate]","This question already has an answer here : Why is the image of a smooth embedding $f: N \to M$ an embedded submanifold? (1 answer) Closed 8 years ago . I'm studying Tu's proof (p. 123) of theorem 11.13, but I just have a question about one detail. He has that $f\colon N\to M$ is an embedding of a manifold of dimension $n$ in a manifold of dimension $m$, and he shows that given $p\in N$, there are local coordinates $(U, x^1, \dots, x^n)$ near $p$ and $(V, y^1, \dots, y^m)$ near $f(p)$ such that $f\colon U\to V$ has the form
$$
(x^1, \dots, x^n) \mapsto (x^1, \dots, x^n, 0, \dots, 0).
$$
He then says Thus, $f(U)$ is defined in $V$ by the vanishing of the coordinates $y^{n+1}, \dots, y^m$. I understand this statement to mean that
$$
f(U) \cap V = \{ q\in V \mid y^{n+1}(q) = \dots = y^m(q) = 0\}.
$$
However, I don't understand why this should be the case. Couldn't there be other points of $V$ at which the coordinates $y^{n+1}, \dots, y^m$ vanish?","['manifolds', 'smooth-manifolds', 'differential-geometry']"
1725229,Have any of the extensions of Frucht's theorem been put to good use in making other connections between group and graph theory?,"I am writing a survey paper on the topic of algebraic graph theory for my undergraduate graph theory course, and I am primarily concerned with the connections between group theory and graph theory, so one of the topics that I am covering is Frucht's theorem. As noted on the wikipedia article for Frucht's theorem, many extensions have been made to Frucht's theorem, strengthening the original theorem -- for example, that for every group $G$ there exists a cubic graph with $G$ as its automorphism group. Certainly, this result is interesting in and of itself, but I was wondering if any research has been done to use this, or any of the other extensions of Frucht's theorem to further derive connections between graph theory and group theory.","['reference-request', 'graph-theory', 'group-theory']"
1725244,"If there is a simple group of order less than 36, then it must have prime order","I want to show that if there is a simple group of order less than 36, then it must have prime order. 
Is there a quick way to show this or do I have to go through each order 1 though 36 showing that if it isn't prime, then it can't be simple?
Any help would be greatly appreciated.","['finite-groups', 'abstract-algebra', 'group-theory', 'order-theory']"
1725259,Show that $x=y+z$ for all $x \in S$,"We are given a set $S$ as a subset of the rational numbers defined by: $0 \notin S$ If $s_1 , s_2 \in S$, then $\frac {s_1}{s_2} \in S$ There exists a nonzero rational number $q \notin S$ such that every nonzero number in $Q \setminus S$ is of the form $qs$ for some $s \in S$. Prove that if $x \in S$, then there exist $y$ and $z$ in S such that $x=y+z$. Taking $s_1=s_2$ tells us that $1 \in S$, and thus $ \frac{1}{s} \in S $, and $s^k \in S$ for $k$ an integer and $s \in S$. Perhaps it can be proved by taking $y=x^a, z=x^b$ and proving integers $a$ and $b$ always exist, but I can't figure it out. Can anyone help me?","['algebra-precalculus', 'contest-math', 'rational-numbers', 'elementary-set-theory']"
1725264,Bounding the variance of a sum of independent random variables,"Suppose $\{X_i\}_{i=1}^n$ is a sequence of independently distributed random variables that take values in $[0,1]$. 
Let $\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$ denote the average of the sequence.
I'd like to find an upper bound for $\text{Var}(\bar{X})$. My strategy was to use Hoeffding's inequality, which states that
$$
\Pr(|\bar X_n - E\bar X_n| \geq t) \leq e^{-2nt^2}
$$ We therefore have
\begin{align}
E\left(|\bar X_n - E\bar X_n|^2\right) &= \int_{x \in [0,1]:\, \left(x - E\bar X_n\right)^2 \geq t}|\bar X_n - E\bar X_n|^2dP + \int_{x \in [0,1]:\, \left(x - E\bar X_n\right)^2 < t}|\bar X_n - E\bar X_n|^2dP \\
&\leq e^{-2nt^2} + t(1-e^{-2nt^2})
\end{align}
for all $t$.
Minimizing the right-hand side with respect to $t$ gives a bound for any $n$. Is it possible to provide a tighter bound than this? Thanks!","['probability-theory', 'inequality', 'probability', 'random-variables']"
1725309,Number of Edges Proof for Complete Graphs,"For any k with $ 0 \le k \le n$, prove ${n \choose 2} = {k \choose 2} + k(n - k) + {n - k \choose 2}$. The question asks for it to be done algebraically, which I've already done. However, the second part asks you to not use any algebra whatsoever and to prove it using knowledge about complete graphs. I know that ${n \choose 2}$ is equal to the number of edges in a complete graph, but I don't know where to go from there.","['graph-theory', 'discrete-mathematics']"
1725321,"How would you evaluate $\liminf\limits_{n\to\infty} \ n \,|\mathopen{}\sin n|$","How would you evaluate the limit inferior of the sequence $n\,|\mathopen{}\sin n|$? That is,
$$\liminf\limits_{n\to\infty} \ n \,|\mathopen{}\sin n|$$ Edit. Let $\mu$ be the irrationality measure of $\pi$. Since $\mu$ is not known, I will split the question: Assuming $\mu > 2$, what is $\liminf\limits_{n\to\infty} \ n\,|\mathopen{}\sin n|$? Assuming $\mu = 2$, what is $\liminf\limits_{n\to\infty} \ n\,|\mathopen{}\sin n|$? I kind of like its graph...","['real-analysis', 'limsup-and-liminf', 'sequences-and-series']"
1725327,A Conjecture based on the Complex Conjugate Root Theorem.,"The Complex Conjugate Root Theorem requires a polynomial function with real coefficients.  This seems to imply the possibility that a complex polynomial can exist with an odd number  of complex roots. True, or am I making  an assumption based on facts not in evidence?",['complex-analysis']
1725331,What can Jensen's inequality tell me about bias of an estimator?,"What can Jensen's inequality tell me about bias of an estimator? I don't really get how to use it and I would like someone to explain what convexity and Jensen's inequality has to do with bias. In particular, I am trying to learn to use Jensen's inequality to decide whether the MLE of an exponential distribution is biased. I don't really understand how the inequality works. I couldn't really find anything that explained it easily, so I decided to work backwards by guessing how to use it and see if I learned something. So far my current thinking is as follows. Let $g(x) = \theta e^{-\theta x}$. Then $$\Bbb E[g(x)] = \frac{1}{\theta}$$ Also, $$ g(\Bbb E[X]) = \theta e^{-\theta \Bbb E[X]}$$ So then Jensen's inequality says if $X$ is a rv and $g$ is a convex function, then 
$$\frac{1}{\theta} \geq \theta e^{-\theta \Bbb E[X]}$$ But I'm not really sure what this has to do with the bias of the MLE for an exponential distribution. I can also rearrange this to get $$e^{\theta \Bbb E[X]} \geq \theta^2 $$
$$\theta \Bbb E[X] \geq ln(\theta^2) $$
$$\Bbb E[X] \geq \frac{ln(\theta^2)}{\theta} $$ I don't know if that gets me anything.",['statistics']
1725351,How many parametrisations are needed to cover a sphere?,"I have seen that a sphere can be covered with 6 parametrisations, but is it possible to totally cover a sphere with less parametrisations/charts?","['spheres', 'parametrization', 'differential-geometry', 'surfaces']"
1725403,Can someone explain me this summation?,"So I need to solve this summation $$\sum _{i=0}^{n-1}\left(\sum _{j=i+1}^{n-1}\left(\sum _{k=j+1}^{n-1}\:\left(1\right)\right)\:\right)$$ and this I know that the answer is $$\frac{n^3}{6}-\frac{n^2}{2}+\frac{n}{3}$$ but how can I arrive to this answer, can someone explain me? thanks","['summation', 'discrete-mathematics']"
1725416,Understanding the construction of Exterior Algebra,"Background The tensor space of type $(r,s)$ associated with $V$ is the vector space $$\underbrace{V\otimes \ldots \otimes V}_{\text{r copies}} \otimes \underbrace{V^* \otimes \ldots \otimes V^*}_{\text{s copies}}.$$ The tensor algebra of $V$ is the direct sum $T(V)=\sum_{r,s} V_{r,s}$ for $r,s \geq 0.$ Let $C(V)$ be the subalgebra $\sum_{k=0}^{\infty} V_{k,0}$ of $T(V)$. Let $I(V)$ denote the two sided ideal in $C(V)$ generated by the set of elements of the form $v \otimes v,$ where $v \in V$ and set $$I_k(V)=I(V) \cap V_{k,0}.$$ The exterior algebra $\Lambda(V)$ is the graded algebra $C(V)/I(V)$. If we set $$\Lambda_k(V)=V_{k,0}/I_k(V)$$ for $k \geq 2$ and $\Lambda_0(V)=\mathbb{R}, \ \Lambda_1(V)=V$ then $$\Lambda(V)=\sum_{k=0}^{\infty} \Lambda_k(V).$$ Denote multiplication in the algebra $\Lambda(V)$ by $\wedge$ Questions I know very little abstract algebra so a lot of this construction is strange to me. I have the following questions: What is the point of doing the intersection $I(V) \cap V_{k,0}$ when
    defining $I_k(V)$? Why is the exterior algebra graded? Here is what I attempted to do: Let $u \in \Lambda_k(V)$ and $v \in \Lambda_l(V)$ We should show that $u       \wedge v \in \Lambda_{k+l}.$ I think $u \in \Lambda_k$
  means that $u$ is the equivalence class $u+I_{k}(V)$ and similarly
  $v$ is the equivalence class $v+I_{l}(V).$ I also think that $u
    \wedge v$ corresponds to the equivalence class of $u \otimes v$ in
  ( I don't know what space ). As you can see, my understanding of this construction is very weak. I think if I see $2$ clearly I will understand how to work with the exterior algebra. To keep this question unambiguous, please consider my attempt with question $2$ above and try to explain, explicitly, what an element in $\Lambda_n(V)$ looks like (and how I can see this from the construction above) and also to explain what $u \wedge v$ means in terms of the quotient construction.","['tensor-products', 'abstract-algebra', 'multilinear-algebra', 'differential-geometry', 'linear-algebra']"
1725440,"Is the set of natural numbers $\mathbb{N}$ Open, closed, or neither?","I figured someone would have asked the question here, but I could not find it. I know it is not open, because  $ \forall n \in \mathbb{N}$, $V_\epsilon (n) \notin \mathbb{N}$. In other words, it is made up of a bunch of isolated points. But I keep reading that it is closed, and I'm having trouble thinking about why, except that perhaps the complement is open and thus $\mathbb{N}$ is closed? Or is it closed vacuously like $\mathbb{Z}$, it contains all its limit points because it has no limit points.","['general-topology', 'real-analysis']"
1725455,Why the interior of $\mathbb{Q}$ in $\mathbb{R}$ is empty?,"I don't understand why the interior of $\mathbb{Q}$ in $\mathbb{R}$ is empty, since, for every ball with the center being a rational number, given an $\epsilon>0$, I can find an infinite sequence of rational numbers that approach this point. For example, take $\frac{1}{2}$. The sequence $\frac{1}{2}+\frac{1}{n}$ can be made as close as I want to the number $\frac{1}{2}$, therefore I can always have open balls with center $\frac{1}{2}$ such that there are rationals inside it.","['general-topology', 'metric-spaces', 'calculus']"
1725465,How to solve $\int \dfrac{x^5\ln\left(\frac{x+1}{1-x}\right)}{\sqrt{1-x^2}} dx$,"Consider the integral $$\int \dfrac{x^5\ln\left(\frac{x+1}{1-x}\right)}{\sqrt{1-x^2}}dx$$ How to start integrating?
Any hint would be appreciated.","['indefinite-integrals', 'integration', 'calculus']"
1725474,"Find $v \in H^1(0,1)$ which satisfies the following","Determine the function $v \in H^1(0,1)$ which satisfies the equation $u(0)=\langle u,v \rangle_{H^1}$ for all $u\in H^1(0,1)$ . It is clear that on $H^1(0,1)$; $u(0)=\int_{0}^{1}(uv+u'v')$.What can be  the function $v$ satisfying the above equation? Please help?","['functional-analysis', 'sobolev-spaces']"
1725487,Definition/Construction of Wiener Measure,"I want to make sure I understand this rigorously: Assume we already know that Brownian motion $B_t$ on $[0,\infty)$ exists/how to construct it. Every $\sigma$-field considered is implicitly assumed to be the standard (Borel) $\sigma$-field. To construct Wiener measure (as a measure on the space $\mathscr{C}[0,\infty)$ of continuous functions), do we (or can we) do the following? For every f $\in \mathscr{C}[0,\infty)$, we identify it with the point in $\mathbb{R}^{\mathbb{Q \cap[0,\infty)}}$ corresponding to its value f(r) at every rational r $\in \mathbb{Q}$. I.e. we identify $\mathscr{C}[0,\infty)$ with a suitable subset $D \subset \mathbb{R^{\mathbb{Q \cap [0,\infty)}}}$. We define the finite dimensional distributions on $\mathbb{R^{\mathbb{Q \cap [0,\infty)}}}$ using the distributions from $B_t$, i.e. for every r $\in \mathbb{Q}$, $X_r \sim \mathscr{N}(0,r)$. Then using the fact that every continuous function is uniquely defined by its values at rational coordinates, as well as the consistency of these distributions following from the continuity of Brownian sample paths, Kolmogorov's extension theorem allows to create a measure $\mu$ defined on all of $\mathbb{R^{\mathbb{Q \cap [0,\infty)}}}$. We define Wiener measure $\nu$ on $\mathscr{C}[0,\infty) \cong D \subset \mathbb{R^{\mathbb{Q \cap [0,\infty)}}}$ (for every measurable set $A \subset D$ in the standard Borel $\sigma$-algebra of $\mathbb{R^{\mathbb{Q \cap [0,\infty)}}}$) as follows - $\nu(A):=\frac{\mu(A)}{\mu(D)}$. I have no idea how one would perform any calculations with this definition, much less be able to define stochastic integration, but this is how I understand what we went over in my lecture.","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'stochastic-analysis', 'stochastic-calculus']"
