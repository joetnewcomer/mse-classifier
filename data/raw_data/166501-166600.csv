question_id,title,body,tags
2901325,Norm of a linear operator from $\mathbb{R}^2\to\mathbb{R}^3$,"Find $\|T\|_{\mathcal{L}}$ where $T\in\mathcal{L}(\mathbb{R}^2,\mathbb{R}^3)$ is defined by $$T(\mathbf{x})=(x,2x, 3x)\ \ \ \forall \mathbf{x}=(x,y)\in\mathbb{R}^2$$ My approach $T$ is a linear operator (easy to prove); $\|\mathbf{x}\|=\sqrt{x^2+y^2}\ \ \ \forall \mathbf{x}\in\mathbb{R}^2$ $\|T(\mathbf{x})\|=\sqrt{x^2+4x^2+9x^2}=\sqrt{14}|x|$ so $\frac{\|T(\mathbb{x})\|}{\|\mathbf{x}\|}=\frac{\sqrt{14}|x|}{\sqrt{x^2+y^2}}\le\frac{\sqrt{14}|x|}{|x|}=\sqrt{14}\ \ \ \forall\mathbf{x}\ne \mathbf{0}$ This means that $\|T\|_{\mathcal{L}}\le\sqrt{14}$. For $\mathbf{x}=(1,0)$ we have that $\|T(\mathbf{x})\|=\sqrt{14}$ so $\|T\|_{\mathcal{L}}=\sqrt{14}$. Second approach Let $\mathbf{x}$ be a unitary vector of $\mathbb{R}^2$, such that
$$\|\mathbb{x}\|=1\implies x^2+y^2=1 \ \ \ \to |x|=\sqrt{1-y^2}\ \ \ \forall y\in [-1,1]$$ so $$\|T(\mathbf{x})\|=\sqrt{14}|x|=\sqrt{14}\sqrt{1-y^2}\le\sqrt{14}\ \ \ \forall y\in [-1,1]$$ In particular $\|T(\mathbf{x})\|=\sqrt{14}$ for $(x,y)=(1,0)$, hence $\|T\|_{\mathcal{L}}=\sqrt{14}$. Are these solutions ok? Thanks.","['measure-theory', 'functional-analysis', 'linear-transformations']"
2901329,Zariski topology and product topology on $\mathbb A_k^m \times \mathbb A_k^n$,"Let $k$ be an algebraically closed field and $\mathbb A_k^n$ be the affine $n$-space. We can give the Zariski topology on it. Then consider $X=\mathbb A_k^m \times \mathbb A_k^n$ under product topology, where each of $\mathbb A_k^m$ and $\mathbb A_k^n$ are given the Zariski topology. And also consider $X=\mathbb A_k^{m+n}$ under the Zariski topology. My question is : For which $m,n\ge 1$, are these two topological spaces homeomorphic ? Note that I am not asking when two topologies are same ... I'm asking when they are not homeomorphic ...","['zariski-topology', 'general-topology', 'commutative-algebra', 'affine-geometry']"
2901344,"If $D$ is a derivation of a Lie Algebra, and $D X = \lambda X$ $\Rightarrow$ $\text{ad}(X)$ is nilpotent","I'm very stuck in this exercise, can anyone help me or give me some hints? Exercise: Let $\mathfrak{g}$ be a finite dimensional Lie Algebra (over a zero characteristic field), $D:
 \mathfrak{g}\to \mathfrak{g}$ a derivation and $X \in \mathfrak{g}$,
  such that $D(X) = \lambda X$ (with $\lambda \neq 0$). Then $\text{ad}(X)$ is nilpotent. I could only conclude that $\text{tr}(\text{ad}(X)^2) =0$. In fact, if $\langle \cdot,\cdot \rangle$ is the Killing form , then $$ \langle X,X \rangle= \frac{1}{\lambda} \langle D X, X \rangle=\frac{-1}{\lambda} \langle  X, DX \rangle = - \langle X, X \rangle,$$
follows that $ \langle X,X \rangle = 0$, and therefore $\text{tr}(\text{ad}(X)^2) = 0.$ However, this result does not give me a useful conclusion.","['linear-algebra', 'lie-algebras']"
2901355,Can I show that a positive power of $2$ plus a perfect square is not divisible by $7$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I've gotten another proof down to just having to prove that a positive power of $2$ plus a perfect square is not divisible by $7$: $$7\nmid(2^k + n^2), \; k,n \in \mathbb{N}$$ How can I do this?","['divisibility', 'discrete-mathematics']"
2901361,Prove $\sum\limits_{i=1}^n\frac1{x_i}\sqrt{x_i-x_{i-1}}\le\sum\limits_{i=1}^{n^2}\frac1i-\frac12$ for integers $1=x_0\le x_1\le x_2\le\cdots\le x_n$,"Suppose $x_{i}\in N^{+}$ , and $1=x_{0}\le x_{1}\le x_{2}\le\cdots\le x_{n}$ . Show that $$\sum_{i=1}^{n}\dfrac{\sqrt{x_{i}-x_{i-1}}}{x_{i}}\le\sum_{i=1}^{n^2}\dfrac{1}{i}-\dfrac{1}{2}$$ Maybe it can be proved by using the C-S inequality. But I am unable to find a solution.","['contest-math', 'radicals', 'real-analysis', 'sequences-and-series', 'inequality']"
2901407,Prove that $\frac{\sin x}{x}=(\cos\frac{x}{2}) (\cos\frac{x}{4}) (\cos \frac{x}{8})...$ [duplicate],"This question already has answers here : Evaluating limit $\lim_{k\to \infty}\prod_{r=1}^k\cos{\left(\frac {x}{2^r}\right)}$ (2 answers) Closed 5 years ago . How do I prove this identity: $$\frac{\sin x}{x}=\left(\cos\frac{x}{2}\right) \left(\cos\frac{x}{4}\right) \left(\cos \frac{x}{8}\right)...$$ My idea is to let 
$$y=\frac{\sin x}{x}$$
and
$$xy=\sin x$$ Then use the double angle identity $\sin 2x=2\sin x \cos x$ and its half angle counterparts repeatedly.  I see some kind of pattern, but I can't seem to make out the pattern and complete the proof.",['trigonometry']
2901451,Definition of ODE and flow on manifold.,"I have the following confusion in my recent lectures in Riemannian geometry. The idea is to define the notion of Lie derivative using the exponential map. In my lecture notes is the following: Let $ M $ be a smooth manifold. $ X $ be a vector field on $M$. Let $ F: V \rightarrow U \subset M $ be a local coordinate chart of $ M $ where $ V \subseteq \mathbb{R}^{n} $ is an open set in $ \mathbb{R}^{n} $. If $ u = (u_1,...u_n) \in V $ is the coordinate in $V$. Then we consider the following system of ordinary differential equations: $$\begin{cases}
du/dt = X(u)\\
\\
u(0)= F^{-1}(p)
\end{cases}$$
for $ p \in M $. The first question I have is what does the above equality means. More precisely, we think of tangent vectors in $ T_{p}M $ as elements that are behaves like directional derivatives. Hence $ X $ should admits the expression $ X = \sum_{j=1}^{n} X_{j} \frac{\partial_{}}{\partial{u_j}} $ which takes values in $ M $ and where $ ( \frac{\partial}{\partial{u_j}} )_{p}$ is defined such that 
$$ (\frac{\partial }{\partial{u_j}} )_p f = \partial_{e_j}( f \circ F \circ F^{-1} \circ p ) $$
where $f$ is a smooth function on $M$ defined locally near $p$. In the lecture, however, it was just said that we should interpret the above equality as
$$ du_j/dt = X_j .$$
My first question is then, is this a consequence of the above discussion? Or simply by definition? After all, $X$ is not meant to take values in $\mathbb{R}^{n}$. We then defined the solution of the above 
$$e^{tX}(p) = u(t,p)$$
corresponding to the initial position $F^{-1}(p)$. And somehow this becomes an element of $ M $. But following the above discussion $u(t,p)$ is clearly in $ \mathbb{R}^{n} $! The only reasonable explanation I can think of is that $e^{tX}(p) = F( u(t,p) ) $ would be correct notation. This is my second question. Could somebody explain what the actual definition is? Thanks!","['lie-derivative', 'riemannian-geometry', 'ordinary-differential-equations']"
2901533,"To be homeomorphic or isometric means ""to be the same"" ? What about $L^3$ and $L^{3/2}$ or $(\mathbb R^2,\|.\|_1)$ and $(\mathbb R^2,\|\mathbb \|_2)$?","I'm confuse with something : my topological teacher told us that *To be homeomorphic means to be the same"". Does it also hold for normed vector spaces or to be ""the same"" they must be isometric ? I really have problem with this because normed space are topological spaces. Let few example to illustrate : 1) Let $(\mathbb R^2, \|\cdot \|_1)$ and $(\mathbb R^2, \|\cdot \|_2)$  where $\|(x,y)\|_1=|x|+|y|$ and $\|(x,y)\|_2=\sqrt{x^2+y^2}$. I know that both norms are equivalent, and thus $\mathcal T_{1}=\mathcal T_2$ where $\mathcal T_i$ is the topology of $\mathbb R^2$ induced by $\|\cdot \|_i$. Therefore, $X_1:=(\mathbb R^2,\mathcal T_1)$ and $X_2:=(\mathbb R^2,\mathcal T_2)$ are homeomorphic, and since $\mathcal T_1=\mathcal T_2$, they are in fact the same, so $X_1=X_2$ makes sense. But they are not isometric, so there are not the same ? 2) Now, Riesz-representation says for example that $(L^1)'$ and $L^\infty $ (where $(L^1)'$ means the topological dual of $L^1$) are isometric, and thus $(L^1)'=L^\infty $ in the sense that there are the same. 3) Now, I know that for example $L^3$ and $(L^{3})''$ are isometric (and thus are the same). I know that $L^3\hookrightarrow (L^3)'$ and thus $L^3$ and $(L^3)'=L^{3/2}$ are homeomorphic. Now it doesn't make any sense to say that $L^3$ and $L^{3/2}$ are the same since for example there are function that are in $L^3$ that are not in $L^{3/2}$ and reciprocally. 4) The thing is I'm not sure that the bijection between $L^3$ and $(L^3)'$ is an homeomorphism. If it's not, suppose that $(X,\|\cdot \|_X)$ and $(Y,\|\cdot \|_Y)$ are homeomorphic but not isometric. Can we say that there are the same or not ? If not, what is the subtelty in the example 1) ? Could someone explain me the difference subtlety in those 4 examples ?","['general-topology', 'functional-analysis']"
2901568,Sums of $f(f(x))=1-x$,"We consider all real functions $f$ with the property $f(f(x))=1-x$ for all $x\in\mathbb{R}$. We define for each such function $f$ the sum:
$$S_f=f(-2017)+f(-2016)+...+f(-1)+f(0)+f(1)...+f(2017)+f(2018)$$ Determine the set of all values â€‹â€‹that such sums $S_f$ can take. To find solutions for function $f$ I used this solution .","['algebra-precalculus', 'functions']"
2901576,How to properly deduce the Holomorphic Implicit Function Theorem from the Smooth Real Implicit Function Theorem?,"I have seen at several places, incl. some notes and books, the following inference of the Holomorphic Implicit Function Theorem from the Smooth Real Function Theorem, but I believe this proof to be incorrect or rather incomplete in that it seems to be missing a non-obvious key step. I would like to know how to complete the proof if possible at all. Please note that there are of course other proofs of the Holomorphic Implicit Function Theorem that work, but my question is not about them, but about fixing this one. So, let me illustrate what I have in mind in the case of 2 complex variables: Hol. Impl. Funct. Thm. in 2 var.-s : Let $U,V \subseteq \mathbb{C}$ be open subsets and let $f:U \times V \to \mathbb{C}$ be a holomorphic function. Let $(z_0,w_0) \in U \times V$ be a point such that $f(z_0,w_0) = 0$ and $\frac{\partial f}{\partial w}(z_0,w_0) \neq 0$.
Then $z_0$ has an open neighbourhood $\widetilde{U} \subseteq U$ such that there exists a holomorphic function $g: \widetilde{U} \to \mathbb{C}$ with the property $g(z_0)=w_0$ and $\forall z\in \widetilde{U}: f(z,g(z)) = 0$. Proof: By the Real Smooth Implicit Function Theorem there exist an open neighbourhood $\widetilde{U}\ni z_0$, $\widetilde{U}\subseteq U$, and a smooth $g:\widetilde{U} \to \mathbb{C}$ such that $\forall z \in \widetilde{U}: f(z,g(z))=0$ as smooth functions.
Thus we only need to show that $g$ is holomorphic in $\widetilde{U}$.
Since $f$ is holomorphic in both variables, one computes
$$
0 = \frac{\partial}{\partial\bar{z}} f(z,g(z)) =
\frac{\partial f}{\partial w}(z,g(z)) \frac{\partial g}{\partial\bar{z}},
$$
hence at $(z_0,w_0)$
$$
0 = \frac{\partial f}{\partial w}(z_0,w_0) \frac{\partial g}{\partial\bar{z}}(z_0),
$$
from where it follows that $\frac{\partial g}{\partial\bar{z}}(z_0)=0$ since $\frac{\partial f}{\partial w}(z_0,w_0) \neq 0$ by hypothesis. $\Box$ The problem: this only shows that $g$ is complex-differentiable at the point $z_0\in\widetilde{U}$ rather than in all of $\widetilde{U}$, and none of the proofs I have seen actually justifies why the reasoning should extend to the whole neighbourhood. Attempt to rectify the problem : by continuity of $\frac{\partial f}{\partial w}$ there are neighbourhoods $U'\ni z_0$ and $V'\ni w_0$ such that $\forall (z,w)\in U'\times V': \frac{\partial f}{\partial w}(z,w)\neq 0$.
So we can take $\widetilde{U}\cap U'$ instead, but this does not suffice because we only know that $g(\widetilde{U}\cap U')\cap V' \ni w_0$, so we don't actually have that
$$
\forall z\in \widetilde{U}\cap U': \frac{\partial f}{\partial w}(z,g(z))\neq 0.
$$ Is there a way to salvage this proof without resorting to a completely different proof strategy? (For example, a completely different strategy would be to invoke the Holomorphic Inverse Function Theorem.) Feel free to add or remove tags as you see fit.","['complex-analysis', 'complex-geometry', 'several-complex-variables', 'riemann-surfaces']"
2901605,How does functional derivative transform under coordinate transformation,"The definition of functional derivative I will be using will be that described in ""Using delta function as a test function"" section of the following Wikipedia link: https://en.wikipedia.org/wiki/Functional_derivative#Using_the_delta_function_as_a_test_function Instead of $\frac{\delta F}{\delta \rho(x)}$, I would like to compute $\frac{\delta F}{\delta \rho(x')}$, where x and x' are related by, say, x=ix'. What is the relationship between $\frac{\delta F}{\delta \rho(x)}$ and $\frac{\delta F}{\delta \rho(x')}$?","['derivatives', 'functional-analysis']"
2901638,Show that $f(x)=x^r+r^x$ is increasing,I know that the function $f(x)=x^r+r^x$ is increasing where $0<r<1$ and $x\geq 2$ by the graph. How to show it? I couldn't prove it .,"['matrices', 'calculus', 'inequality']"
2901647,Correlation coefficient and regression line : Geometric intuition,"correlation coefficient $$r = \frac{1}{n}\sum_{i=1}^n\frac{(x_i-\bar x)(y_i-\bar y)}{\sigma_x\cdot\sigma_y}$$ may be thought of as cosine of angle between two $n$-dimensional vectors $$ (x_1- \bar x, x_2- \bar x,\ldots, x_n- \bar x) \text{ and } (y_1- \bar y,y_2- \bar y,\ldots,y_n- \bar y)$$ But what is special about these two vectors? why don't we take take angles between any other two vectors? Yes, I know the intuition behind the algebra,that we  subtract $\bar x\text{ and } \bar y$ so that the mean is zero and the the sign of products gives us the correlation and we divide by $\sigma_x\cdot\sigma_y$ to remove the effects of scaling of the distributions. I want to know the geometric intuition in terms of angle between two vectors. Also I would like to know the geometric intuition behind the relationship slope of regression line $$=r \cdot \frac{\sigma_y}{\sigma_x}$$ I know that when $r = 1,$ the slope of regression line should be  $\frac{\sigma_y}{\sigma_x}$ What I don't understand is how the cosine of angle between two vectors $$ (x_1- \bar x, x_2- \bar x,\ldots,x_n- \bar x) \text{ and } (y_1- \bar y,y_2- \bar y,\ldots,y_n- \bar y)$$ when multiplied to $\frac{\sigma_y}{\sigma_x}$ gives us the slope.","['regression', 'statistics', 'correlation', 'linear-regression']"
2901651,Closed form solution for this integral?,"I'm hitting a road block in finding an expression (closed form preferably) for the following integral: \begin{equation}
\int^{+\infty}_0 x^b \left ( 1-\frac{x}{u} \right )^c \exp(-a x^3) dx
\end{equation} where $a,b$ are positive constants; $b>1$ is an odd multiple of $0.5$ , while $c$ is a positive or negative odd multiple of $0.5$ ; $u$ is a (positive) parameter. Things I have considered or tried: look up in tables (Gradshsteyn and Ryzhik): there are very few explicit results for integrals involving $\exp(-a x^3)$ (or for the other factors after transforming via $y=x^3$ ). Also, tabulated results involving $\exp(-a x^p)$ for more general $p$ do not include the other factors $x^b (1-x/u)^c$ . One exception is (3.478.3): \begin{equation}
\int^{u}_0 x^b (u-x)^c \exp(-a x^3) dx, 
\end{equation} but the limits of integration do not match with my case; there is a closed form solution (3.478.1) for the simpler integral \begin{equation}
\int^{+\infty}_0 x^{d-1} \exp(-a x^3) dx = \frac{a^{-d/3}}{3} \Gamma(d/3).
\end{equation} (NB: there is also an expression for the indefinite integral.)
A binomial expansion of $[1-(x/u)]^n$ for integer $n$ would produce a solution in series form. However, in my case, the exponents $b$ and $c$ are strictly half-integer. For the same reason, integration by parts does not lead to a simpler integral without the factor $[1-(x/u)]^c$ ; Wolfram Math online did not produce a result; the integral is an intermediate step in a longer analysis, so numerical solution (with given values for the parameter) is not practical. Grateful for any pointers or solution.","['integration', 'calculus']"
2901665,Question on star shaped domains,"Let $X$ be a compact star shaped subset of $\mathbb{R}^n$ with center $x_0\in X$, that is, for every $x\in X$ the line segment $[x_0,x]=\{(1-t)x_0+tx : t\in [0,1]\}$ is contained in $X$. Suppose $X$ has nonempty interior and that $\partial X$ is homeomorphic to $\mathbb{S}^{n-1}$. My question is: does $X$ admit a center point in its interior? I'm trying to generalize the statement ""in $\mathbb{R}^n$, a compact convex set with nonempty interior is homeomorphic to the unit ball $\mathbb{D}^n$"", which I proved using the fact that we can translate the convex so that the origin belongs to its interior and then the proof does not depend on any other point than the origin (that is a center for the convex). Therefore, if the answer to my question is ""yes"", then it's true that ""in $\mathbb{R}^n$, a compact star shaped set with nonempty interior and boundary homeomorphic to $\mathbb{S}^{n-1}$ is homeomorphic to $\mathbb{D}^n$. Thanks in advance!","['general-topology', 'algebraic-topology']"
2901781,When did the $L^p$ start being mentioned and who proved that $L^p$ spaces are complete?,"I know the theorem that assures this is called ""Riesz-Fischer Theorem"" but doing a bit of research I found out that Riesz and Fischer proved simultaneously that $L^2$ is complete without mentioning any concept of ""complete"" nor ""$L^2$"". So my question is: Who did the proof that $L^p$ is complete for $p\neq 2$ and when did these spaces start being relevant? Any hep or reference would help!","['math-history', 'functional-analysis', 'analysis', 'real-analysis']"
2901831,Finding minimum value of $\mu$ in cubic $x^3-\lambda x^2+\mu x-6=0$,"If $\lambda,\mu$ are the real number such that, $x^3-\lambda x^2+\mu x-6=0$ has its real roots and positive, then the minimum value of $\mu$ is? My attempts: As it has real and positive roots its derivate too have real positive roots, i.e. $3x^2-2\lambda x+\mu=0$ applying $D\geq0\implies \lambda^2\geq3\mu>0$. I don't know how to use that $6$, may as the product of roots of a cubic, but where? How to proceed, please help.","['real-numbers', 'cubics', 'calculus', 'polynomials', 'algebra-precalculus']"
2901855,isosceles right-angled triangles defined on an infinite Go board by same-colored stones,"You start with an infinite Go board. On every point of the board you place one colored stone. There are n>1 different colors. Find all natural numbers n that no matter how the stones colored, three stones of the same color form the vertices of a isosceles right-angled triangle. The catheti (legs) of the isosceles right-angled triangles must me be on the lines of the board. This question is already answered for right-angled triangles .","['combinatorics', 'ramsey-theory']"
2901858,Are there any non-orientable integral domains?,"Let $R$ be an integral domain. Let $R_0=R-\{0\}$ and $R^*$ be the unit group of $R$. An orientation of $R$ (my terminology) is a submonoid $N\subseteq R_0$ which intersects each associate equivalence class at exactly one point. That is, if $x\sim y$ (i.e. $x=uy$ for some $u\in R^*$) where $x,y\in N$ then $x=y$, and if $x\in R_0$ then there exists $y\in N$ such that $x\sim y$. For example, $\Bbb Z^+$ is an orientation of $\Bbb Z$, and if $k$ is a field then the set of monic polynomials is an orientation of $k[X]$. Does every integral domain have an orientation? For PIDs, the answer is yes: For each prime ideal $P$, pick a prime generator $P=(p)$, and let $N$ be the set of products of these generators. Since $R$ is a UFD, no two distinct products can be associate, and moreover if $x\in R_0$ then $x$ is a product of primes, and for each prime $q_i$, if $p_i$ is the chosen generator of $(q_i)$ then $p_i\sim q_i$ so $x$ is associate to $\sum_ip_i$. There are non-orientable commutative rings that are not integral domains. For example, in $\Bbb Z/6\Bbb Z$, there are only two units, so every square must be in $N$ (since either $x\in N$ or $-x\in N$ implies $x^2\in N$), so the only possible structure is $\{1,3,4\}$; but $3\cdot 4=0$ so this is not a submonoid.","['ring-theory', 'abstract-algebra', 'integral-domain']"
2901886,Simulating a fair coin toss using a biased coin in fixed number of tosses,"For which values of $p$ can we simulate a fair coin toss using a fixed number of tosses of a $p$-biased coin? Here are some positive and negative examples: When $p = 1/2$, this is trivially possible. When $p = 1/2 \pm 1/\sqrt{12}$, this is possible since $p^3 + (1-p)^3 = 1/2$. When $p = k/n$ for odd $n$ and integer $k$, this is impossible, since after tossing the coin $m$ times, the probability of any event is an integer multiple of $1/n^m$. In particular, Is there a rational $p \neq 1/2$ for which we can simulate a fair coin toss using a fixed number of tosses of a $p$-biased coin?",['probability']
2901896,Interchanging a limit and an infinite alternate series,"I am having troubles to explain if the following equality holds or not
$$\lim_{k\to\infty}\sum_{n=1}^{\infty}(-1)^{n}(n+k)^{-1}=\sum_{n=1}^{\infty}(-1)^{n}\lim_{k\to\infty}(n+k)^{-1}=0.$$
As far as I see, I can't apply the dominated convergence theorem since $|f_{k}(n)|=|(-1)^{n}(n+k)^{-1}|=(n+k)^{-1}$ can't be dominated by  summable sequence over $n$. How could I proceed?","['convergence-divergence', 'lebesgue-measure', 'sequences-and-series']"
2901914,Continuous bijection which is not a homeomorphism.,"Given the function $f:[0,2\pi)\to S^1$, $\varphi\mapsto (\cos(\varphi), \sin(\varphi))^t$. Show that $f$ is continuous and a bijection, but not a homeomorphism. That $f$ is continuous is clear, since every component is continuous.
Furthermore it is continuous differentiable. When I want to show, that $f$ is a bijection it is easy to see, that $f$ is injective, since for $f(x)=f(y)\Leftrightarrow (\cos(x), \sin(x))=(\cos(y),\sin(y))\Leftrightarrow \cos(x)=\cos(y)\wedge\sin(x)=\sin(y)\stackrel{x,y\in [0,2\pi)}{\Leftrightarrow} x=y$ But how can I show, that $f$ is a surjection? To show, that $f$ is not a homeomorphism, I have to verify, that $f^{-1}$ is not continuous.
Can I use the inverse function theorem? I get: $Df(\varphi)=\begin{pmatrix}-\sin(\varphi)&0\\0&\cos(\varphi)\end{pmatrix}$ With determinant $\operatorname{det}Df(\varphi)=-\sin(\varphi)\cos(\varphi)$ Where $Df(\varphi)$ is not invertible for $\varphi=0$. Thanks in advance for hints and comments.","['continuity', 'general-topology']"
2901930,Tricky coin probability,"Can someone please help, I am getting the wrong answer. Consider four coins labelled as 1, 2, 3 and 4. Suppose that the probability of obtaining a â€˜headâ€™ in a single toss of the ð‘–-ð‘¡h coin is $ð‘–/4,\, ð‘– = 1, 2, 3, 4.$ A coin is chosen uniformly at random and flipped. Given that the flip resulted in a â€˜headâ€™, the conditional probability that the coin was labelled either 1 or 2 equals. I tried doing this P(coin 1 or 2 | tails) = 
P(coin 1 or 2 And Tails)/P(tails) \ 
=(1/4)(3/4)+(1/4)(2/4)   /  1/4(3/4)+(1/4)(2/4)+(1/4)(1/4)
=5/6 In improved notation:
$$P(C_1 \cup C_2 | T) = P((C_1 \cup C_2)T)/P(T) \\
= \frac{(1/4)(3/4) + (1/4)(2/4)}
{(1/4)(3/4) + (1/4)(2/4) + (1/4)(1/4)} = 5/6.$$ But this is the wrong answer as the answer is one of 1/10,2/10,3/10,4/10.
How to do this?","['statistical-inference', 'statistics', 'probability']"
2901937,"""Damped"" wave equation with Fourier method","The problem I was trying to solve is the following PDE problem $$\begin{cases} \partial_{tt}^2 u = \partial_{xx}^2 u -\gamma\partial_t u \\[5 pt]
u(0,t)= u(\pi, t) = 0 \\[5 pt]
u(x,0) = (\sin2x)^4 -{1\over 5}\sin 10x \\[5 pt]
\partial_t u(x,t)|_{t=0}=0
\end{cases}\tag 1$$ with the Fourier series method. But I got stuck on the calculations. What I've done is, first thing first, to evaluate the initial condition to eliminate that fourth power, which can be easily done, and I've got $$
u(x,0) = {3\over 8}-{1\over 2}\cos4x +{1\over8}\cos8x-{1\over 5}\sin10x
$$ This says to me that the solution ought to be of the form $$
u(x,t) = \sum_n a_n(t)\sin(nx)+b_n(t)\cos(nx)
$$ or simply by using the complex exponential, which doesn't change much. I then used the ansatz in the PDE to get two ODE's for the coefficients $a_n(t), b_n(t)$ $$
\sum_n(a''_n(t)\sin(nx)+b''_n(t)\cos(nx))= \\ =-\sum_n(a_n(t)\sin(nx)+b_n(t)\cos(nx))-\gamma\sum_n(a'_n(t)\sin(nx)+b'_n(t)\cos(nx))
$$ and got, equating the coefficients $$
a''_n(t)= -\gamma a'_n(t)-a_n(t) \\
b''_n(t)= -\gamma b'_n(t)-b_n(t)
$$ which are the same equations: the equation of a damped harmonic oscillator. To find the solution we search for the solutions of the polynomial equation $$
\lambda^2 +\gamma\lambda +1 = 0
$$ which are $$
\lambda_1 = -{1\over 2}\left(\gamma+\sqrt{\gamma^2-4}\right)\;\;\;\;\; \lambda_2 = -{1\over 2}\left(\gamma-\sqrt{\gamma^2-4}\right)
$$ Clearly the solution for the ODE's depends on the value of the ""damping coefficient"" gamma $$
\gamma^2-4 \gt 0 \implies \color{red}{a_n(t) = c^a_1e^{\lambda_1 t}+c^a_2e^{\lambda_2 t}}\\
\gamma_2-4\lt 0 \implies \lambda_{1/2} = \mu\pm i\nu \implies \color{orange}{a_n(t) = c^a_1 e^{(\mu+i\nu)t}+c^a_2 e^{(\mu-i\nu)t}} \\
\gamma^2-4=0\implies \lambda_1=\lambda_2=\lambda \implies \color{green}{a_n(t)=c^a_1 e^{\lambda t}+c^a_2 t e^{\lambda t}}
$$ and the same goes for $b_n(t)$. But then jumped to my mind that the solution would become very ugly! Knowing my professor I think that there could be a easier way to solving this. Question 1: In my solution, am I headed in the right way? Question 2: Is there a simpler method to solve this problem? Question 3: I thought about using Laplace transform but the initial condition make matter worse: could this be a viable way?","['ordinary-differential-equations', 'laplace-transform', 'wave-equation', 'partial-differential-equations', 'fourier-series']"
2902060,What are the connections between square integrable functions in the context of Fourier series and least squares regression?,"$L^2([0,1])$ integrability is a condition to express a periodic function as a Fourier series: $$\left\vert \int_{0}^L f(x)- \int_{0}^L \sum_{k=-n}^n \hat f(k)\;\mathrm e^{\frac{2\pi}{L} kx} \right \vert^2\mathrm dx\to0$$ as $n\to \infty.$ The idea is that the infinity FS converges to the function as mean square convergence. I don't know if any parallels in conceptual framework can be established between this idea of convergence and the estimation of a least square regression (OLS) hyperplane minimizing squared differences between predicted and actual values. And if so, in what sense these concepts are connected. Could the FS be interpreted as an OLS approximation to an overdeteemined problem?","['convergence-divergence', 'least-squares', 'fourier-analysis', 'functional-analysis']"
2902064,Unit disk as cartesian product,"Let $\mathbb{R}$ denote the set of real numbers. For each of the following subsets of $\mathbb{R}\times \mathbb{R}$, determine whether it is equal to the cartesian product of two subsets of $\mathbb{R}$. (a) $\{(x,y):y>x\}$ and (b) $\{(x,y): x^2+y^2<1\}$ Proof: Consider an example (b). Let $C:=\{(x,y): x^2+y^2<1\}=A\times B$ where $A,B\subset \mathbb{R}$. Since $\{0\}\times (-1,1)\subset C=A\times B$ then $(-1,1)\subset B$ and applying the same for $(-1,1)\times \{0\}$ we get that $(-1,1)\subset A$. Hence $(-1,1)\times (-1,1)\subset A\times B=C$. Taking the point $(\frac{\sqrt{3}}{2},\frac{\sqrt{3}}{2})\in (-1,1)\times(-1,1)\subset A\times B=C.$ Then by the definition of $C$ we get that $(\sqrt{3}/2)^2+(\sqrt{3}/2)^2=3/2<1$. This contradiction proves that unit circle cannot be equal to the cartesian product of some $A$ and $B$, where $A,B\subset \mathbb{R}$. Is this proof correct? If yes, would be grateful to see some alternative proof. P.S. The same reasoning is applicable for (a).",['elementary-set-theory']
2902120,Proving the Cone is not a smooth surface.,"$C:(x,y,z):z=\sqrt{x^2+y^2}$  suppose it is a smooth  surface  meaning there exists a smooth parametrization $ Ï†(u,v):UâŠ‚R^2â†’C$ such that $Ï†(u,v)=(Ï†_1(u,v),Ï†_2(u,v),Ï†_3(u,v))$ such that $Ï†_3=\sqrt{Ï†_1^2+Ï†_2^2}$ being continuously differentiable at every point but it fails at the peak since the limit at the peak of the derivative fails to be unique because if i approximate it through different paths(curves) it will be different. (So which is the the derivative( i tried taking the jacobian but not helpfull) and what limit do i  take to continue mathematically  my proof ).? Another approach similar. 
$C:(x,y,z):z=\sqrt{x^2+y^2}$  suppose it is a smooth  surface  meaning there exists a smooth parametrization $ Ï†(u,v):UâŠ‚R^2â†’C$  now consider the projectio $p:C \rightarrow R^2$. Now i know from a theorem $Ï†$ is diffeomorpishm also $p\circ Ï†$  is a diffeomorphism( havent proven why yet)  so its inverse is smooth so $Ï†\circ ((p\circ Ï†)^{-1}):R^2 
 \rightarrow  C |(x,y,\sqrt{x^2+y^2} )$ is differentiable since both  are which is a contradiction","['calculus', 'differential-geometry']"
2902124,"Munkres, Theorem 16.4","I don't understand the highlighted parts of the proof. For the first highlighted part. The statement ""$(a,+\infty)\cap Y$ and $(-\infty,a)\cap Y$ form a subbasis for the subspace topology of $Y$"" means that every set that is open in the subspace topology of $Y$ is a union of finite intersection of elements of the form $(a,+\infty)\cap Y$ and $(-\infty,a)\cap Y$. Any open set in the subspace topology of $Y$ is of the form $Y\cap U$ with $U$ open in the order topology of $X$. ($U$ is open in $X$ if it is a union of sets of the form $[a_0,b),[b_0,a),(a,b)$.) So the above statement says that any set $Y\cap U$ with $U$ open in $X$ is a union of a finite intersection of sets of the form $(a,+\infty)\cap Y$ and $(-\infty,a)\cap Y$. I don't see why this follows directly from what had been said before in the first paragraph of the text. And the implication that follows is unclear for now. For the second highlighted part. We need to show that given a set open in the order topology of $Y$, it is open in the subspace topology of $Y$. The former means that the set is a union of open rays of $Y$. Each open ray of $Y$ is the intersection of $Y$ with an open ray of $X$, so each open ray of $Y$ is open in the subspace topology of $Y$. Thus the initial set is open in the subspace topology of $Y$, being a union of open sets. What for do we need to talk about subbases?","['proof-explanation', 'general-topology']"
2902133,"Explicit Uncountable Linearly Independent Set In $C[0,1]$","Is there a somewhat elementary/analytic way to show that $\{x^{k_\alpha}\}$, or $\{\sin (k_\alpha x)\}$, or some similar set is linearly independent over the reals for any collection $\{k_\alpha\}$ of non-negative reals? My goal is to show that the set of continuous functions $C[0,1]$ has uncountable Hamel dimension with elementary tools. In the case that $k_\alpha = k\in\{0,1,2,\ldots\}$ this boils down to the Fourier basis, but I'd like to avoid using orthogonality.","['linear-algebra', 'functional-analysis', 'real-analysis']"
2902155,Why the cardinality of $\{f:\emptyset\to \emptyset \mid f\text{ a function}\}$ is one?,"Why the cardinality of $$\{f:\emptyset\to \emptyset \mid f\text{ a function}\}$$ is one ? There is no such function... the cardinality should be $0$, no ? How could a function $$f:\emptyset \to \emptyset$$ looks like ?",['elementary-set-theory']
2902168,Does every possible KÃ¤hler metric on a projective variety arise from the Fubini-Study metric for some embedding?,"Every projective variety inherits a KÃ¤hler structure from a projective embedding, by restriction of the Fubini-Study metric. They will generally admit many KÃ¤hler structures though. I was wondering if every KÃ¤hler structure, maybe only up to cohomology, can be obtained in this way from some projective embedding? Thanks!","['complex-geometry', 'algebraic-geometry', 'kahler-manifolds']"
2902188,"Expressing half-open interval [a,b) as infinite intersection of open intervals. (Answer Verification) [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I need to express the half open interval $[a,b)$ where, $(a<b)$ as the infinite intersection of open intervals. My answer/attempt is $$[a,b)=\bigcap\limits^\infty_{n=1}(a-\frac{1}{n},b)$$ I'm not sure if this is correct however.","['elementary-set-theory', 'general-topology', 'measure-theory', 'real-analysis']"
2902218,Permutations with Repetition Formula,"Let us say we are trying to compute the unique permutations of the word: $$PEPPER$$ We cannot compute this by relabeling: $$P_1E_1P_2P_3E_2R$$ Because this would simply be $6!$ and does not take into account repetition. However, I have seen the formula:
$$
\frac{6!}{3! 2!}
$$
I.e take the total number of positions, and then divide by the product of factorials of repeated elements. My question is, why does this work? Could anyone supply a combinatorial argument?","['permutations', 'combinatorics']"
2902232,"If $S$ is a Noetherian ring and $R\subset S$ is a sub-ring, prove that $R$ is Noetherian or a counterexample","If $S$ is a Noetherian ring and $R\subset S$ is a sub-ring, prove that
$R$ is Noetherian or a counterexample if this assertion is not always
certain. I have thought for a long time about this and I come to the following conclusion that I do not know if it is correct: I think this is not true in general and I think the following can work: we have that $\mathbb{Z}\subset\mathbb{R}$, is there an ideal that is not finitely generated in $\mathbb{Z}$ and that is finitely generated in $\mathbb{R}$?","['noetherian', 'algebraic-geometry', 'ring-theory', 'abstract-algebra', 'commutative-algebra']"
2902260,Geometrically interpreting $\Im ({z}/{(z + 1)^2} )$,"Here is the question from Visual Complex Analysis by Needham. Show geometrically that if |z| = 1 then $\Im\left(\frac{z}{(z + 1)^2}\right) = 0$ What other points apart from the unit circle satisfy this equation? I know that z is a point on the circle, and (z+1) is a point on the unit circle translated by a unit vector, but I do not know what squaring a complex number or taking its reciprocal corresponds to in geometry. I also have no idea how to proceed with the second half of the question (""What other points apart from the unit circle satisfy this equation?"")","['geometric-interpretation', 'circles', 'geometry', 'complex-numbers']"
2902286,Prove that this differential equation has a unique solution defined on $\Bbb{R}^+$,"We consider the following O.D.E
\begin{align}(a)\qquad\qquad\begin{cases}x'(t)=\dfrac{\rho^2(x(t))}{1+\rho^2(x(t))} & t\geq 0,\\x(0)=x_0\in \Bbb{R}&\end{cases}\end{align}
where \begin{align}\rho:\Bbb{R}\to \Bbb{R}\end{align} is a $C^1$ function. I want to prove that $(a)$ has a unique solution defined on $\Bbb{R}^+?$ CURRENT PROOF Since $\rho:\Bbb{R}\to \Bbb{R}$ is $C^1$ function, $\rho^2$ is also a $C^1$ function. Also, 
\begin{align}\dfrac{\rho^2}{1+\rho^2}\end{align}
is a $C^1$ function.
\begin{align}\rho^2(x(t))\leq 1+\rho^2(x(t)),\;\;\forall\,t \geq 0,\;x\in \Bbb{R}\end{align}
\begin{align}f(x(t))=\dfrac{\rho^2(x(t))}{1+\rho^2(x(t))} \leq 1,\;\;\forall\,t \geq 0,\;x\in \Bbb{R}\end{align} This implies that $f$ is affine. So, $(a)$ has a unique maximal solution on $[0,t_{\max})$ and $t_{\max}=+\infty$. Therefore, $(a)$ has a unique solution defined on $\Bbb{R}^+?$ Kindly confirm if this proof is fine or not. If no, alternative proofs will be accepted. Thanks!","['derivatives', 'ordinary-differential-equations']"
2902311,How to show that $\int_{t}^{\infty} e^{-\frac{x^2}{2}} dx \leq \frac{1}{t}e^{-\frac{t^2}{2}}$ where $1 \leq t$?,"How to show that $$
\int_{t}^{\infty} e^{-\frac{x^2}{2}} dx \leq \frac{1}{t}e^{-\frac{t^2}{2}}
$$
  where $t \geq 1$.","['integration', 'calculus', 'integral-inequality']"
2902401,"Integral including functions $\operatorname{erfc}(.), \exp(.) $ and $ \cos(.)$","I have following integral. MATHEMATICA evaluates it as follows for $a>0$:
$$I=\int_{0}^{\pi/2}\cos (\theta ) e^{a^2 \cos ^2(\theta )} \text{erfc}(a \cos (\theta ))d\theta=\frac{\sqrt{\pi } \left(1-e^{a^2} \text{erfc}\left(a\right)\right)}{2 a}$$ However, I have no clue how this result comes. I have checked few integral table books such as Table of Integrals, Series, and Products, and also functions.wolfram.com . But I could not find matching expressions. Does anyone have an idea?","['integration', 'analysis']"
2902441,Finding a First Integral of a System of First-Order DEs,"I am trying to show that the system $$\frac{dx_1}{dt}=ax_1, \ \ \frac{dx_2}{dt}=-x_2$$ has a first integral of the form $$K(x_1,x_2)=\ln(f(x_1))+\ln(g(x_2))a$$ My attempt: I will use the following method.
$$\frac{dx_1}{dt}=ax_1\iff \frac{dx_1}{ax_1}=dt \ \ \ \ \ \ \ \ (1)$$
$$\frac{dx_2}{dt}=-x_2\iff \frac{dx_2}{-x_2}=dt \ \ \ \ \ \ \ (2)$$
Equating $(1)$ and $(2)$ yields
\begin{align}
\frac{dx_1}{ax_1}&=\frac{dx_2}{-x_2} \\
\frac{1}{a}\ln|x_1|&=-\ln|x_2|+C \\
\ln|x_1|+a\ln|x_2|&=0 \ \ \  \ \ (C=0)
\end{align}
I do not know where to go from here. Is my working correct so far? Any advice would be greatly appreciated.","['systems-of-equations', 'proof-verification', 'ordinary-differential-equations']"
2902458,"Show that if some base can show as linear combination, then vectors in linear combination is linear indepedent","Let $Bs=\{e_1,e_2,...,e_n\}$ is standard base $\mathbb R^{n}$. If $x_1,x_2,...,x_n$ vectors from space $R^{n}$ such that $e_i\in L(x_1,x_2,...,x_n)$, $i=1:n$ then set $\{x_1,x_2,...x_n\}$ is base of space $\mathbb R^{n}$?. My answer is yes. First I write $\alpha_1e_1+\alpha_2e_2+...+\alpha_ne_n=0$. Since $e_i\in L(x_1,x_2,...,x_n)$ we can write every vector in base $Bs$ as linear combination of $\{x_1,x_2,...,x_n\}$. For example: $\begin{matrix} 
e_1=a_{11}x_1+a_{21}x_2+...+a_{n1}x_n\\
e_2=a_{12}x_1+a_{22}x_2+...+a_{n2}x_n\\
.........................\\
e_n=a_{1n}x_1+a_{2n}x_2+...+a_{nn}x_n
\end{matrix}$ then $0=x1(\alpha_1a_{11}+\alpha_2a_{12}+...+\alpha_na_{1n})+x2(\alpha_1a_{21}+\alpha_2a_{22}+...+\alpha_na_{2n})+...+xn(\alpha_1a_{n1}+\alpha_2a_{n2}+...+\alpha_na_{nn})$ If we suppose opposite that this vectors is linear dependent, then one vector can be write as linear combination of other vectors, for example if I use $x_n$ to write as linear combination, then $(\alpha_1a_{n1}+\alpha_2a_{n2}+...+\alpha_{nn}a_{1n})\not=0$ because we can not divide something with zero, if we put  $(\alpha_10+\alpha_20+...+\alpha_na_{nn})\not=0$ then $\alpha_n \not=0$,so now we have $0e_1+0e_2+...+\alpha_ne_n=0$, then $e_n=0$ but it is not true, so $ L(x_1,x_2,...,x_n)$ is base of $\mathbb R^n$, is this ok?","['linear-algebra', 'vector-spaces']"
2902467,Prove: the ratio between the areas of $ABC$ and $AB'C'$ is $AB'\cdot\frac{AC'}{(AC \cdot AB)}$,"In the accompanying figure, i am to prove that the ratio between areas $AB'C'$ and $ABC$ is $\frac{(AB' \cdot AC')}{(AC \cdot AB)}$. Any assistance is greatly appreciated. Also, does the fact that the $B'$ and $C'$ is tangent to the inscribed circle matter here? Or could the result be generalized to any two triangles with two similar sides.","['euclidean-geometry', 'area', 'circles', 'geometry']"
2902479,Do extension fields always belong to a bigger field?,"Let $F$ be a field, $E_1$ and $E_2$ are two distinct extension fields of $F$. Is it the case that we can always somehow find a field $G$ that contains both $E_1$ and $E_2$? In other words, could extensions of fields have different 'direction's such that they are incompatible? Edit: I began to think about this problem while reading a proof. $F$ is a field. $a$ and $b$ are algebraic over $F$. $p(x)$ and $q(x)$ are two polynomials in $F[x]$ of minimum degree that respectively make $a$ and $b$ a zero. The proof claims that there is an extension $K$ of $F$ such that all distinct zeros of $p(x)$ and $q(x)$ lie in $K$. For a single polynomial, I know this kind of field exists because of the existence of splitting field, why it is true for two polynomials?","['field-theory', 'abstract-algebra', 'extension-field']"
2902552,On Differentiable Functions (Khan Academy),"I am learning Khan Academy Calculus, specifically how to tell when the graph of a function is differentiable or not. Khan Academy tells me that a point on the graph of is not differentiable when: But I don't get why 2. and 3. are true.  For 2, say we have a vertical tangent line for function 1/x^2 Would it not be continuous here? And therefore, wouldn't there be at least the chance that it's differentiable? Can someone please explain to me why a function is never differentiable at the vertical asymptote? For 3, why would a function not be differentiable when it has a sharp turn? I don't get this either. Can someone please explain?","['continuity', 'calculus', 'derivatives']"
2902577,River crossing with boat,"Alan, Bill, Charly, Dean and Edgar are going to cross a river to reach the opposite river bank by using a small boat. The rules are very strict because the river is deep and dangerous:
For the boat not to sink, the 5 friends must be seated one behind the other, starting from the lightest, in order of weight. All friends are of different weight!
All they have with them is a balance scale. Given that their time is limited, they must determine the order by the least number of weightings. Can you help them? Starting with A+B we determine AB. 
Say we have $A>B$. Then we add C and weight it against, say, the lightest. $B+C$. If we have $C<B$ then $C<B<A$. But we can't go on with such a simplistic approach. There must be something clever which I am missing.",['combinatorics']
2902610,Algorithm to find relations between polynomials,"Let $p_1,\ldots,p_k\in\mathbb{C}[x_1,\ldots,x_n]$ be polynomials. Is there an algorithm to compute the ideal of relations between them? More precisely, to find a set of generators for the kernel of the ring homomorphism $$\mathbb{C}[y_1,\ldots,y_k]\to \mathbb{C}[x_1,\ldots,x_n],\quad y_i\mapsto p_i(x_1,\ldots,x_n).$$ (This enables us to compute $\mathbb{C}[p_1,\ldots,p_k]$ ). Example: Consider $$x_1x_2,x_3x_4,x_1x_3,x_2x_4\in\mathbb{C}[x_1,x_2,x_3,x_4].$$ One obvious relation between them is $$(x_1x_2)(x_3x_4)=(x_1x_3)(x_2x_4).$$ Thus, if $$\varphi:\mathbb{C}[y_1,y_2,y_3,y_4]\to\mathbb{C}[x_1,x_2,x_3,x_4]$$ is the homomorphism defined by $$y_1\mapsto x_1x_2,\quad y_2\mapsto x_3x_4,\quad y_3\mapsto x_1x_3,\quad y_4\mapsto x_2x_4,$$ then $y_1y_2-y_3y_4\in\ker \varphi$ . It is easy to see that $\ker\varphi$ is in fact generated by $y_1y_2-y_3y_4$ , so $$\mathbb{C}[x_1x_2,x_3x_4,x_1x_3,x_2x_4]\cong\mathbb{C}[y_1,y_2,y_3,y_3]/(y_1y_2-y_3y_4).$$","['ring-theory', 'abstract-algebra', 'polynomial-rings', 'polynomials', 'algorithms']"
2902663,"How to show $\operatorname{Cov}(b_0,b_1)=-\frac{\sigma\bar{x}}{S_{xx}}$","Consider the equation $y_i=\beta_0+\beta_1x_i+\epsilon_i$ for $i=1, \dotsc, n$. We have unbiased estimators $b_0$ and $b_1$ for $\beta_0$ and $\beta_1$ respectively, where $b_0=\bar{y}-b_1\bar{x}$ and $b_1= S_{xy} / S_{xx}$. How does one show that $\operatorname{Cov}(b_0,b_1)=-\frac{\sigma\bar{x}}{S_{xx}}$ I tried using $\operatorname{Cov}(b_0,b_1)=E(b_0b_1)-E(b_0)E(b_1)$ to no avail as it just equals $0$ when I try and do that. Thanks!","['regression', 'statistics', 'covariance']"
2902711,The length of a regular curve is different from its measure? (for rectifiable non absolute continuous path),"Consider a path $\pi : [a,b]\to C$ where $C$ is a curve. By definition, then length of the path is $$\ell(\pi)=\sup \sum_{i=0}^n\|\pi(t_i)-\pi(t_{i+1})\|,$$
where $\{t_0,...,t_{n+1}\}$ is a partition of $[a,b]$, and the sup is taken over all partition. I know that if $\pi$ is rectifiable but not absolutely continuous, then 
$$\ell(\pi)\geq \int_a^b \|\pi '(t)\|dt= m(C),$$
where $m$ is the Lebesgue measure. So there are case where the measure of a path is in fact not the length of the path ? That looks weird...","['measure-theory', 'real-analysis']"
2902724,What is the closed form for $ \sum\limits_{n=0}^{\infty}\frac{1}{(n!)^2}$?,"What is the closed form for $\sum_{n=0}^{\infty}\frac{1}{(n!)^2}$ ?
And is there a closed form for $\displaystyle \sum_{n=0}^{\infty}\frac{1}{(n!)^k}$ ? Edit: If there are no closed forms for the two series, how should I convert them into integrals? Now I know that $\displaystyle I_0(2)=\sum_{n=0}^{\infty}\frac{1}{(n!)^2} = \frac{1}{\pi}\int_{0}^{\pi}e^{2\cos\theta}d\theta$ , but is there an integral representation for $\displaystyle \sum_{n=0}^{\infty}\frac{1}{(n!)^k}$ ?",['sequences-and-series']
2902750,"Prove that if $a+b+c+d=4$, then $(a^2+3)(b^2+3)(c^2+3)(d^2+3)\geq256$","Given $a,b,c,d$ such that $a + b + c + d = 4$ show that $$(a^2 + 3)(b^2 + 3)(c^2 + 3)(d^2 + 3) \geq 256$$ What I have tried so far is using CBS: $(a^2 + 3)(b^2 + 3) \geq (a\sqrt{3} + b\sqrt{3})^2 = 3(a + b)^2$ $(c^2 + 3)(d^2 + 3) \geq 3(c + d)^2$ $(a^2 + b^2)(c^2 + d^2) \geq (ac + bd)^2$ Then, we have: $(a^2 + 3)(b^2 + 3)(c^2 + 3)(d^2 + 3) \geq 9(a + b)^2(c + d)^2$ . Thus, we have to prove that $9(a + b)^2(c + d)^2 \geq 256$ . Then, I used the following substitution: $c + d = t$ and $a + b = 4 - t$ . We assume wlog that $a \leq b \leq c \leq d$ . Then, $4 = a + b + c + d \leq 2(c + d) = 2t$ . Thus, $t \geq 2$ . Then, what we have to prove is: $9t^2(4 - t)^2 \geq 256$ . We can rewrite this as: $(3t(4 - t) - 16)(3t(4 - t) + 16) \geq 0$ , or $(3t^2 + 2t + 16)(3t^2 - 12t - 16) \geq 0$ , at which point I got stuck.","['tangent-line-method', 'a.m.-g.m.-inequality', 'real-analysis', 'cauchy-schwarz-inequality', 'inequality']"
2902768,"$f((x,y)^T)=\frac{xy^2}{x^2+y^2}$ not differentiable in $(0,0)^T$","$f:\mathbb{R}^2 \to \mathbb{R}$ $f\Bigg(\begin{matrix}x\\y\end{matrix}\Bigg)=\begin{cases}\frac{xy^2}{x^2+y^2},(x,y)^T \neq(0,0)^T \\0 , (x,y)^T=(0,0)^T\end{cases}$ I need to determine all partial derivatives for $(x,y)^T \in \mathbb{R}^2$: $f_x=y^2/(x^2+y^2)-2x^2y^2/(x^2+y^2)^2$ for $(x,y)^T \neq (0,0)$ $f_y=2xy/(x^2+y^2)-2xy^3/(x^2+y^2)^2$ for $(x,y)^T \neq (0,0)$ and $f_x=f_y=0$ for $(x,y)^T = (0,0)$. Then I need to determine $\frac{\partial f}{\partial v}((0,0)^T)$ for all $v=(v_1,v_2)^T \in \mathbb{R}^2$. I tried: $\frac{1}{s} (f(x+sv)-f(x))$ at $x=(0,0)^T$ is equal to $\frac{1}{s} f(sv)$=$\frac{1}{s} f\Big(\begin{matrix}sv_1\\sv_2\end{matrix}\Big)$. Which is either equal to $0$ when the argument is $(0,0)^T$ or it is $\frac{1}{s}\frac{sv_1s^2v_2^2}{s^2v_1^2+s^2v_2^2}$ which converges to $\frac{v_1v_2^2}{v_1^2+v_2^2}$ as $s \to \infty$. Is that correct so far? And how do I know if $f$ is continuously partial differentiable on $\mathbb{R}^2$? According to our professor $f$ is not differentiable at $0$. How do I show that? As far as I know it has something to do with that something is not linear but I don't know what exactly. So I guess it can't be continuously partial differentiable on $\mathbb{R}^2$ as well but I am not sure about that. Thanks for your help!","['analysis', 'real-analysis', 'continuity', 'multivariable-calculus', 'derivatives']"
2902817,The product topology on $\mathbb R_d\times \mathbb R$ vs. the dictionary order topology on $\mathbb R\times \mathbb R$,"Show that the dictionary order topology on $\mathbb R\times \mathbb R$ is the same as the product topology $\mathbb R_d\times \mathbb R$ where $\mathbb R_d$ is $\mathbb R$ with the discrete topology. My thoughts: First, the space $\mathbb R_d\times \mathbb R$ has $\{x\}\times (a,b)$ as its basis. In particular, any set of the form $\{x\}\times (-\infty,+\infty)$ is open there, since $$\{x\}\times (-\infty,+\infty)=\bigcup_{r\in \mathbb R_{<a}} \{x\}\times (r,b)\bigcup_{s\in \mathbb R_{> b}} \{x\}\times (a,s)$$ Second, the open sets in $\mathbb R\times\mathbb R$ in the dictionary order topology is one of the two forms: Consider an open set in the dictionary order topology. If it has the first form, then it is open in $\mathbb R_d\times \mathbb R$ because it is of the form $$\bigcup_{r\in \mathbb R_{> a}}\{a\}\times (a,r)\bigcup_{t\in (a,b)_{\mathbb R}}\{t\}\times (-\infty,+\infty)\bigcup_{s\in\mathbb R_{< d}} \{b\}\times (s,d).$$ A set of the second form is clearly open in the product topology. Thus the dictionary order topology is contained in the product topology. Is the above correct? The converse is somewhat unclear. If we have a set open in the product topology, it does not necessarily have one of the two forms above. It may have the form $\{x\}\times (-\infty,y_0)$ or $\bigcup_{x\in [r,s]_{\mathbb R}}\{x\}\times (-\infty,y_0)=[r,s]\times (-\infty,y_0)$. What to do in such cases? I've just realized that the sets in the picture form a basis , they are not all open sets. Then I it suffices to show that any basis element of the product topology, namely $\{x\}\times (a,b)$, is a subset of a basis element of the dictionary order topology, and conversely, right? The former is obvious. The latter is obvious for basis elements of the second type. But it's still unclear why a basis element of the first type is contained in a set of the form $\{x\}\times (a,b)$.",['general-topology']
2902855,Evaluate: $ \int \frac{\sin x}{\sin x - \cos x} dx $,"Consider $$ \int \frac{\sin x}{\sin x - \cos x} dx $$ Well I tried taking integrand as $ \frac{\sin x - \cos x + \cos x}{\sin x - \cos x} $ so that it becomes, $$ 1 + \frac{\cos x}{\sin x - \cos x} $$ But does not helps.
I want different techniques usable here.","['integration', 'indefinite-integrals', 'trigonometric-integrals']"
2902904,Complex Analysis - Application of Liouville theorem [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question If $f:\mathbb{C}\to\mathbb{C}$ is an entire function and it holds that: ""For every $z\in \mathbb{C}$, either $|f'(z)|\leq1$ or $|f''(z)|\leq 1$."" Then there exist $a,b,c \in \mathbb{C}$ such that $2|a|\leq 1$ and $f(z)=az^2+bz+c$ .",['complex-analysis']
2902913,"Function that is bijective from $(0,1)$ to $\mathbb R$ [duplicate]","This question already has answers here : Prove: Any open interval has the same cardinality of $\Bbb R$ (without using trigonometric functions) (6 answers) Closed 2 years ago . I'm trying to come up with a function that is bijective from $(0,1)$ to $\mathbb R$. This function cannot include Trig functions. Does this function exist?","['elementary-set-theory', 'functions', 'discrete-mathematics', 'real-analysis']"
2902915,Evaluate $\int_{a}^{b} \frac{\left(e^{\frac{x}{a}}-e^{\frac{b}{x}}\right)dx}{x}$,"Evaluate $$I(a,b)=\int_{a}^{b} \frac{\left(e^{\frac{x}{a}}-e^{\frac{b}{x}}\right)dx}{x}$$ given $a,b \in \mathbb{R^+}$ My attempt: we have $$I(a,b)=f(a)-g(b)$$ where $$f(a)=\int_{a}^{b} \frac{e^{\frac{x}{a}}dx}{x}$$ and $$g(b)=\int_{a}^{b} \frac{e^{\frac{b}{x}}dx}{x}$$ differentiating $f(a)$with respect to $a$ we get $$f'(a)=\int_{a}^{b}e^{\frac{x}{a}} \times \frac{-x dx}{a^2x}=\frac{e-e^{\frac{b}{a}}}{a} \tag{1}$$ Differentiating $g(b)$with respect to $b$ we get $$g'(b)=\frac{e^{\frac{b}{a}}-e}{b} \tag{2}$$ Hence $$af'(a)+bg'(b)=0$$ Any way to proceed here?","['integration', 'algebra-precalculus', 'definite-integrals', 'derivatives']"
2902925,$(\frac{x}{a})^n + (\frac{y}{b})^n = 1$ as $n \to \infty$,"To analyse what happens to the function $$\left(\frac{x}{a}\right)^n + \left(\frac{y}{b}\right)^n = 1$$ when as $n \to \infty$. Here we are given, $a=4,b=10$. When $n=1,2$ I know it is a straight line and ellispe. What happens when $n \to \infty$? I have plotted it and saw that it converges to rectangle, but can't explain it mathematically!","['graphing-functions', 'differential-geometry']"
2902963,Why avoid piecewise notation?,"A lot of people come here asking, essentially, some variation of the following: I know how to write a piecewise function that [does something].  How do I write a non-piecewise function that does the same thing? To my mind, that is like asking the following: I've written this formula in red whiteboard marker.  How do I write it in blue whiteboard marker instead? Probably there is some use to doing this, given that so many people ask for it, but I haven't the faintest idea what that use is.  Most of the time, it makes the function longer and more complex, often with some combination of $(-1)^n$, absolute value notation, and periodic functions such as sine and cosine popping up.  I don't see the use of these extra terms in most cases.  They obscure the core purpose and behavior of the function. What is the purpose of rewriting a function to avoid piecewise notation? In what contexts does it help you reason about the function?","['notation', 'functions', 'soft-question']"
2902978,"Question concerning the surface $\phi(u, v)=(u, v^3, u-v)$","Let $\phi:R^2 \rightarrow R^3$ ,$C^{\infty}$ with $\phi(u,v)=(u,v^3,u-v)$. And $\gamma(t)=(3t,t^6,3t-t^2)$ smooth curve . Prove : $\textbf{a)}$ $M=\phi(R^2)$ is a smooth surface. $\textbf{b)}$  that $\gamma(R) \subset M$. Which is the $C^{\infty}$ parametrized curve $\phi^{-1} \circ \gamma$ $\textbf{c)}$ express the velocity $\dot{\gamma(0)}$ as a linear compination of the vectors of the basis of the tangent plane $T_0M$ at $\gamma(0)=(0,0,0)$. Solution : $\textbf{a)}$ $\phi$ is smooth so only think that remains is to prove that it is an acceptable parametrization for its image. It is 1-1 as its components is 1-1. Onto into its image .its Jacobian matrix has rank 2 . Since its collumns are $(1,0,1),(0,3v^2,-1)$ which with Gauss ellimination even if $v=0$ still there are 2 independent collumns. Only think left is to prove that its inverse IS continuous.$\textbf{ How do i find its inverse?}$ $\textbf{b)}$ Let $t \in R$ then for every $(3t,t^6,3t-t^2)$ i can find $(u(t),v(t))$ such that  $\phi(u(t),v(t)=(3t,t^6,3t-t^2)$ $u(t)=3t$,$ v(t)=t^2$ so every point of the curve is on $M$. I think my justification is awkward how would i write that clearer and more rigorously mathematically??. To find the $\phi^{-1}\circ \gamma$ $\textbf{i need to find the inverse from a).}$ $\textbf{c)}$ is pure calculations it is easy.$d\phi/du(0,0)=(1,0,1)$ $d\phi/dv(0,0)=(0,0,-1)$. $\dot{\gamma(0)}=(3,0,3)=3(d\phi/du)+0(d\phi/dv)$ Are my calculations right?","['surfaces', 'differential-geometry']"
2902995,How to calculate a Bernoulli Distribution problem,"I have my statistics exam quite soon and i came upon this question : At the last referendum, $40\%$ of the Italian population supported the constitutional reform. If a random sample of size $n = 200$ is drawn, which is the probability of observing at least $100$ people who voted YES? Searching through my online notes, i found out that the explanation that the professor gave is this: If $X$ is the random variable which is equal to one if the unit voted YES, then it has a Bernoulli distribution with success probability equal $0.40$. Due to the large sample size, the Normal approximation holds. Therefore, $\hat p \sim \mathcal N(0.40, 0.012)$ and $Pr(\hat p > 0.50) = Pr(Z > 0.1/0.0346) = Pr(Z > 2.89) = 1 âˆ’ Pr(Z < 2.89) = 0.0019$. I do not understand how he went through this ... can somebody help me? Starting from the first part of the explanation , where he states: $\hat p\sim \mathcal N(0.40, 0.012)$. Where is the $0.012$ coming from ? Thanks!","['statistical-inference', 'statistics', 'bernoulli-numbers', 'probability']"
2903015,$\sum_k (-1)^k \frac{\tau(2k+1)}{2k+1}$,"The identity
$$ \sum_{k=0}^\infty (-1)^k \frac{\tau(2k+1)}{2k+1} = \frac{\pi^2}{16}$$
(where $\tau$ is the number-of-divisors function) has come up in OEIS sequence A222068 .  Surely this is ""well-known""?  Can anybody supply a reference?","['number-theory', 'reference-request']"
2903039,"How can I solve $\int_0^1\frac{\arctan(x^2)}{1+x^2}\,\mathrm dx$?","This integral $$\int_0^1\frac{\arctan(x^2)}{1+x^2}\,\mathrm dx$$ appears very similar to $\int\frac{\arctan x}{1+x^2}\,\mathrm dx$ . But, this question cannot be solved through the same simple substitution of $u=\arctan x$ . WolframAlpha cannot find a symbolic solution to this problem, and this Quora answer is the only thing I can find that appears to have the exact answer of $\frac14\log^2(1+\sqrt2)$ . I am not sure if there is some special trick to be used in solving this, but I have tried everything I know and nothing seems to work.","['integration', 'trigonometric-integrals', 'definite-integrals']"
2903044,Every graph $G$ with $d(G) \ge 4k$ has a $(k + 1)$-connected subgraph $H$ such that $\epsilon (H) > \epsilon(G) âˆ’ k$.,"I have a confusion with Theorem 1.4.3 (Mader 1972) of the Diestel book on Graph Theory which states that Let $0 \ne k \in \mathbb N$. Every graph $G$ with $d(G) \ge 4k$ has a $(k + 1)$-connected subgraph $H$ such that $\epsilon (H) > \epsilon(G) âˆ’ k$. and it's proof is as follows Put $\gamma := \epsilon(G)$ ($\ge2k$), and consider the subgraphs $G' \subseteq G$ such that
  $$|G'| \ge 2k \text{ and } \|G'\| > \gamma (|G'| âˆ’ k ).      \tag{$*$}$$
  Such graphs $G'$ exist since G is one; let $H$ be one of smallest order. No graph $G'$ as in $(âˆ—)$ can have order exactly $2k$, since this would
  imply that $\|G'\| > \gamma k \ge 2k^2 > \binom{|G'|}{2}$. The minimality of $H$ therefore implies that $\delta(H) > \gamma$: otherwise we could delete a vertex of degree at most $\gamma$ and obtain a graph $G' \subseteq H$ still satisfying $(âˆ—)$. In particular, we have $|H| \ge \gamma$. Dividing the inequality of $\|H\| > \gamma |H| âˆ’ \gamma k$ from $(âˆ—)$ by $|H|$ therefore yields $\epsilon(H) > \gamma âˆ’ k$, as desired. It remains to show that $H$ is $(k + 1)$-connected. If not, then $H$
  has a proper separation $\{U_1,U_2\}$ of order at most $k$; put $H[U_i] =: H_i$. Since any vertex $v \in U_1 \setminus U_2$ has all its $d(v) \ge \delta(H) > \gamma$ neighbours from $H$ in $H_1$ , we have $|H_1| \ge \gamma \ge 2k$. Similarly, $|H_2| \ge 2k$. As by the minimality of $H$ neither $H_1$ nor $H_2$ satisfies $(âˆ—)$, we further have $$\|H_i\| \le \gamma (|H_i| âˆ’ k)$$ for $i=1,2$. But then 
  \begin{align}
\|H|| &\le \|H_1\| + \|H_2\| \\
      &\le \gamma (|H_1| + |H_2|- 2k) \\
      &\le \gamma (|H| - k) \qquad \text{(as $|H_1 \cap H_2| \le k$),} \\
\end{align}
  which contradicts $(âˆ—)$ for $H$. In this proof why they select Graph $G'$ with condition $(*)$? why we are not able to find a graph $G'$ as in $(*)$ can have order exactly $2k$? How they would imply the condition $\|G'\| > \gamma k \ge 2k^2 > \binom{|G'|}{2}$ ?","['graph-theory', 'proof-explanation', 'algebraic-graph-theory', 'combinatorics', 'discrete-mathematics']"
2903099,Probability and Statistics Books for Distributions and Introduction to Data Mining/Machine Learning,"In college, I took a probability class using Sheldon Ross' A First Course in Probability. It was not my best semester to say the least. However, I am returning back to probability and statistics as it relates to what I want to do later in life. Since then I have learned some basic data mining, regression modeling, more generalized statistics topics, but without any real theory. I would like to learn the theory because as the modeling gets more complicated, more theory comes into play and I would like to understand more than the general explanation. However, my foundation of probability is not well-rounded. I know of mean, standard deviation, variance, hypothesis testing, linear model assumptions, but there are not that complex. Specifically, I would like to explore more of the different types of distributions (gamma, poisson, etc), and explore topics related to modeling (logistic, support vectors, random forest, etc), but also topics in Data Mining and Machine Learning. I have a B.A. in Mathematics and Economics from an okay school, but have taken courses and understood topics in Linear Algebra, Multivariate Calculus, Econometrics, Statistics (for Economics), Mathematical Models (covered predator and prey, linear regression, differentiable equations), and Analysis (which I mostly understood). Based on the above, I am looking for books that would help me get to where I want to be with DETAILED examples and walkthroughs. I am not a big person on books that say this is trivial or make general assumptions without explaining the topic. I know it won't all be in one book. The two books I have are: An Introduction to Statistical Learning: with Application in R and R Data Mining: Implement data mining techniques through practical use cases and real world datasets . I am in the process of finishing the second book, but just encountered Maximum Likelihood and got thrown for a loop.  In case you can't tell by the titles, I am also learning R. Any advice would be well received as well as suggestions to free copies. Thank you.","['statistics', 'book-recommendation', 'data-mining', 'machine-learning', 'probability']"
2903100,A conjecture on the closeness of twin primes,"Let $p_1$ and $p_2$ be twin primes, and let $p_1-1=a_1\times b_1$ and $p_2+1=a_2\times b_2$ be such that $|b_1-a_1|$ and $|b_2-a_2|$ are minimised. Similarly,  let $p_1+1=p_2-1=a\times b$ be such that $|b-a|$ is minimised. Now assume the twin prime conjecture, and let $$\mathcal P_n=\frac{\#\text{twin primes} \le n:\min\{|b_1-a_1|,|b-a|,|b_2-a_2|\}\neq|b-a|}{\#\text{twin primes} \le n}$$ What is the value of $\mathcal P_\infty$ ? Note that by convention the pair $(2,3)$ are not twin primes. For twin primes less than $100$ , we have that $p_1=5,17$ . Hence I think that if there are infinitely many such primes then they will be exceedingly sparse. Here is a table showing $\mathcal P_n$ for increasing values of $n$ . Credits to Enzo Creti for running the program. $$\small\begin{array}{c|c}\log_{10}n&1&2&3&4&5&6&7&8&9&10&11\\\hline \mathcal P_n&\frac12&\frac14&\frac{17}{35}&\frac{93}{205}&\frac{600}{1224}&\frac{4326}{8169}&\frac{31939}{58980}&\frac{243876}{440312}&\frac{1928700}{3424506}&\frac{15661079}{27412679}&\frac{129632703}{224376048}\\\hline\text{decimal}&\small 0.5&\small0.25&\small0.4857&\small0.4537&\small0.4902&\small0.5296&\small0.5415&\small0.5539&\small0.5632&\small0.5713&\small0.5777\end{array}$$ This can be seen more clearly in the following plot; more interesting is the behaviour after $n=10^4$ . There is a slight dip at $n=10^2,10^4$ but otherwise it looks like there is a converging increase in $\mathcal P_n$ . It is unlikely, but if there reaches a point where $\mathcal P_k=\mathcal P_{k+1}$ then the twin prime conjecture will be disproved.","['number-theory', 'conjectures', 'twin-primes', 'prime-numbers']"
2903157,Calculate number of subsets,"I want to find how many subsets $A$ contains the set $\{ 1,2, \dots, 7 \}$ with the property  $$(3 \in A \iff 2 \in A).$$ The set $\{ 1,2, \dots, 7\}$ has in total $2^7=128$ subsets, right? In order to find the number of subsets $A$ with the property $(3 \in A \iff 2 \in A)$, we have to find the number of subsets that do not contain both $2$ and $3$ and subtract the result by $128$, right? But how do we find the number of subsets of $\{ 1,2, \dots, 7 \}$ that do not conatin both $2$ and $3$ ?","['elementary-set-theory', 'probability']"
2903161,Is there a general mathematical method that determines whether any sequence of natural numbers is generated by a particular mathematical law?,"My question is: In mathematics is there a general method that determines whether any sequence of natural numbers is generated by a particular mathematical law/function/closed-form expression/recurrence-relation? What I'm looking for is not how this is a function or closed-form expression. I am simply looking for a general method of determining whether the given sequence is distributed by a certain mathematical law or by random. Example; For sequence $a_n$ , $$a_n=\left\{ 1,1,2,4,7,11,16,22,29,37,46,56,67,79...\right\}$$ there is a ""mathematical relation"" : $a_n=a_{n-1}+n-1$ What I want to know is to determine whether this formula exists without having to find any formulas. Is there such a mathematical/statistical method? For example, is it possible to do this by visualizing any series?","['soft-question', 'natural-numbers', 'discrete-mathematics', 'sequences-and-series']"
2903163,Lagrangian Mechanics & Derivatives,"I don't really know whether to put this in Physics forums since it is relating to Mechanics, or Math since the question is actually about the math being done. Don't criticize me over it. So for the question: I was doing some review problems on Lagrange's equations, KE+PE, and I found this document . In the first question's solution, the writer differentiates without explaining the step. They have these: $$\begin{cases}
x = r \sin(\theta) \cos(\phi)\\[5 pt]
y = r \sin(\theta) \sin(\phi)\\[5 pt]
z = r \cos(\theta)
\end{cases}
$$ and this: $$T = {m\over 2}(\dot x^2 +\dot y^2 +\dot z^2)$$ I never really studied the spherical coordinate system much, and obviously never thought about the derivatives of the conversion into Cartesian. Can someone find or explain the process of taking the derivatives of the first three equations, plugging into the equation for Kinetic Energy, and simplifying? There is a probably a different calculus method for the coordinate system, which I don't know. Thanks! EDIT: While doing taking the derivatives, was the method used actually a separate form of calculus beyond I and II, or was it normal first-order differentiation? If so, how? Here is the part I am speaking of: Solution: The kinetic energy is $T=\frac m2(\dot x^2+\dot y^2+\dot z^2)$ . We substitute $$\begin{cases}
x = r \sin(\theta) \cos(\phi)\\[5 pt]
y = r \sin(\theta) \sin(\phi)\\[5 pt]
z = r \cos(\theta)
\end{cases}
$$ Differentiating these, substituting into $T$ , and simplifying, we find $$T=\frac m2 (\dot r^2 +r^2\dot\theta^2+r^2\sin^2\theta\dot\phi^2).$$","['classical-mechanics', 'euler-lagrange-equation', 'multivariable-calculus', 'calculus', 'spherical-coordinates']"
2903169,"On the radical of a certain ideal of sixteen variable polynomial ring, generated by the entries of certain matrices","Consider the polynomial ring $R=\mathbb C[x_1,x_2,...,x_{16}]$, and set $$X=\begin{pmatrix} x_1 &x_2&x_3 &x_4\\ x_5&x_6& x_7&x_8\\x_9&x_{10}&x_{11}&x_{12}\\x_{13}&x_{14}&x_{15}&x_{16}\end{pmatrix}.$$ Now, using these three matrices $$L=\begin{pmatrix}0&-1&0&0\\1&0&0&0\\0&0&0&-1\\0&0&1&0 \end{pmatrix}$$
$$M=\begin{pmatrix}0&0&0&-1\\0&0&-1&0\\0&1&0&0\\1&0&0&0\end{pmatrix}$$
$$N=\begin{pmatrix}0&0&-1&0\\0&0&0&1\\1&0&0&0\\0&-1&0&0\end{pmatrix}$$ we create polynomials $f_i, g_i,$ and $h_i$ in the following way: $$XLX^t-L=\begin{pmatrix} f_1 &f_2&f_3 &f_4\\ f_5&f_6& f_7&f_8\\f_9&f_{10}&f_{11}&f_{12}\\f_{13}&f_{14}&f_{15}&f_{16}\end{pmatrix}$$ $$XMX^t-M=\begin{pmatrix} g_1 &g_2&g_3 &g_4\\ g_5&g_6& g_7&g_8\\g_9&g_{10}&g_{11}&g_{12}\\g_{13}&g_{14}&g_{15}&g_{16}\end{pmatrix}$$ $$XNX^t-N=\begin{pmatrix} h_1 &h_2&h_3 &h_4\\ h_5&h_6& h_7&h_8\\h_9&h_{10}&h_{11}&h_{12}\\h_{13}&h_{14}&h_{15}&h_{16}\end{pmatrix}$$ Finally, let $I = (f_i, g_i, h_i)$ be the ideal generated by these $48$ polynomials. Then how to show that the radical of $I$, i.e. $\sqrt I$, is generated by twelve linear polynomials and one quadratic polynomial ? I have no idea how to approach this problem; may be use Nullstelensatz ... ? Please help NOTE : All the matrices $L,M,N$ are orthogonal , so the three defining equations can be written as $(XL)(LX)^t=(XM)(MX)^t=(XN)(NX)^t=Id$. Now if we can find some pattern in $XL,LX,MX,XM,NX,XN$ then it could be helpful to find the zero set of the ideal $I$ ... 
Also $L,M,N$ are skew symmetric matrices and as @Balaji sb noted, $LM=-N$ ... this means $L,M,N$ works as the $i,j,k$ in the Quaternion ring ...","['matrices', 'algebraic-geometry', 'noncommutative-algebra', 'polynomials', 'commutative-algebra']"
2903224,False proof that every continuous function is holomorphic,"Let $\Omega$ be an open subset of $\mathbb{C}$ and $f:\Omega\to\mathbb{C}$ be a continuous function. Consider the following function:
$$F(z)=\int_{[z_0,z]}f(w)\:\mathrm{d}w,$$
where $z_0$ is a fixed complex number. Firstly I will prove that $F$ is holomorphic. $$\lim_{h\to 0} \frac{F(z+h)-F(z)}{h} = \lim_{h\to 0} \frac{1}{h}\left(\int_{[z_0,z+h]} f(w)\:\mathrm{d}w - \int_{[z_0,z]} f(w)\:\mathrm{d}w\right)= \lim_{h\to 0} \frac{1}{h}\int_{[z,z+h]} f(w)\:\mathrm{d}w= \lim_{h\to 0} \int_0^1 f(z+th)\:\mathrm{d}t= \int_0^1 \lim_{h\to 0}f(z+th)\:\mathrm{d}t= f(z)$$ We can pass the limit under the integral sign by the following reason: $[0,1]$ is compact and $f$ is continuous. Hence there exists a real number $M>0$ such that $|f(z+th)|\leq M$ for all $t\in[0,1]$. This means that we can use the continuity under the (Lebesgue's) integral sign theorem. Since $F$ is holomorphic and holomorphic functions have derivatives of all orders, $F'=f$ also has derivatives of all orders. In particular, $f$ is holomorphic. Ok, this is clearly an absurd. However I don't know where is my error.",['complex-analysis']
2903232,Under what conditions does $\mathcal{P}(\cup A) = A$ hold,"I'm studying ZF axiomatic set theory and I've encountered this question: Under what conditions does $\mathcal{P}(\cup A) = A$ holds? I easily proved that $A \subseteq\mathcal{P}(\cup A)$ and now I'm wondering whether the other inclusion holds. I first noted that it holds for $A = \{\varnothing\}$ and does not hold for $A = \varnothing$. But the first one is the only case? I tried to suppose that $A\neq \varnothing$ and that $A$ has an element other than $\phi$. Taking an such element, say $a = \{a_i\}$ in $A$, we have that every $a_i$ is in $\cup A$ so that any subset $\{a_{k_i}\}$ of $a$ must a subset of $\cup A$, that is, $\mathcal{P}(a)\subseteq \cup A$. I think I must arrive at a contradiction from here but I don't know what to conclude from this. Any help will be appreciated. (Obs.: I don't know for sure which of the two tags of set theory I must choose, once this question is not so elementary in the sense of common set theory used in math. I entered both but feel free to change if you know what is the correct one).",['elementary-set-theory']
2903262,combinatorics: a variant of set covering/subset selection problem?,"Given a set $N = \{1, 2, \dotsc,n\}$, let $F \subseteq 2^N$ represent a family of subsets of $N$. Each subset $S \in F$ has a reward $+1$ or $-1$. We seek to select a subset $K \subseteq N$ such that the total ""collected"" rewards of sets $S \in F$ is maximized. The reward corresponding to a set $S \in F$ is ""collected"" if and only if $K \subseteq S$. Example : Let $N = \{1, 2, 3, 4, 5\}$. Define $S_1 = \{1, 2, 5\}$, $S_2 = \{2, 4\}$ and $S_3 = \{1, 2, 3\}$ with weights $+1$. Also, define $S_4 = \{2\}$, $S_5 = \{2, 4, 5\}$, $S_6 = \{1, 4\}$ with weights $-1$. The optimal selection is $K = \{1, 2\}$ as it can collect the $+1$ reward for both $S_1$ and $S_3$. If we choose $K = \{2\}$, while we collect the $+1$ reward for $S_1$, $S_2$ and $S_3$, we also collect the $-1$ reward for $S_4$ and $S_5$. Is there any well-known combinatorial problem with a structure similar to the above problem? In particular, one that can be reduced to this problem for complexity analysis.","['order-theory', 'computational-complexity', 'combinatorics']"
2903280,"Cauchy's Theorem, Stokes' Theorem, de Rham Cohomology","I've been struggling these last couple of days to see the connection, if at all there is one, between the following facts: For holomorphic functions $f$, $\mathrm{d}(f(z)\mathrm{d}z) = 0$. In a simply connected domain, a holomorphic function has a primitive, i.e. there exists a function $g$ defined over this domain such that $g'=f$. The de Rham Cohomology ""measures the failure of closed forms to be exact"". Trying to convince myself that Cauchy's theorem is somehow geometrically intuitive led me to the one-line proof where point 1 above is combined with Stoke's theorem, which in turn has led me to wonder if there was something going on at the level of differential forms over $\mathbb{C}$. I apologise if the question is unclear; as I said, I have the feeling like there's a revelation about holomorphic functions dancing just out of my reach.","['complex-analysis', 'de-rham-cohomology']"
2903288,Does $GL_5(\mathbb{R})$ has subgroup of index $2$?,"Does $GL_5(\mathbb{R})$ has subgroup of index $2$? My answer - Yes. Let's say that $\tau$ is a function, which is the sign of the determinant of the matrices in $GL_5(\mathbb{R})$  ( easy to see that it is homomorphism). Then we have $Im(\tau)=\{1,-1\}$, and by the first isomorphism theorem, we get that the index of $ker(\tau)$ is $2$. Is it correct? Did I miss something?","['group-homomorphism', 'group-theory', 'proof-verification', 'group-isomorphism']"
2903289,"Guessing the other dice number, given two dice were rolled, and one of them rolled a 3","An argument i had with a friend followed this question:
""Given two dice were rolled, and one of them rolled a 3. What would you bet the other dice rolled?"" The phrasing is just to enhance that there might be some number that has an higher probability of showing on the other dice. One of us said that since 7 is the most likely number to be rolled by two dices, then 4 should be the answer. The other said that once the 3 was set on one dice, we should not be looking at anything other than the other cube - so any number would be an equal guess.","['dice', 'probability']"
2903309,"If $Q$ is hermitian and unitary, prove that $Q=I-2P$ for some orthogonal projection $P$?","Good afternoon everyone. I am in a numerical linear algebra class, and have come across this problem: Prove that for $V$ a subspace of $\mathbb{C}^m$, $P$ the orthogonal projector onto $V$, and $Q=I-2P$, $Q=Q^*$ ($Q$ is hermitian) and $Q^*Q=QQ^*=I$ ($Q$ is unitary) and conversely, Prove that $\forall Q \in \mathbb{C}^{m\times m}. ((Q=Q^*)\land (Q^*Q=I) \implies \exists P \in \mathbb{C}^{m\times m}. (P=P^*) \land (Q=I-2P))$ or in other words If $Q$ is both hermitian and unitary then $Q=I-2P$ for some orthogonal projector $P$. I have succeeded in proving the first part of the problem by using some properties of the conjugate transpose (namely $(A+B)^*=A^*+B^*$) and some simple algebra, but the second one puzzles me. My paper literally just looks like this right now: $Q=Q^*$, $Q^*Q=I$ $Q^2=I$ And I'm stuck. Do I proceed by supposing a projection onto $V$? Do I somehow prove that $P$ is an orthogonal projector? Thanks much.","['matrices', 'projection', 'projection-matrices', 'linear-algebra']"
2903330,ArzelÃ â€“Ascoli theorem for the space $C_b^k(\overline{\Omega})$,"Let $S \subseteq \mathbb{R}^m$ and $C_b^k(S)$, for $k \in \mathbb{N}$,  the set of continuous functions from $S$ to $\mathbb{R}$ with bounded and continuous partial derivatives of any order $\leq k$. I need to show that if $\Omega \subseteq \mathbb{R}^m$ is a bounded open set, $\{ u_n\}_n \subseteq 
C_b^k(\overline{\Omega})  $ is bounded in $C_b^k(\overline{\Omega})$, then there is a subsequence of $\{ u_n\}_n$ which converges in $C_b^k(\overline{\Omega})$ and hence in $H^k(\Omega)$. The norm in $C_b^k(\overline{\Omega})$ is
$$||u||_{k, \infty}:= \max_{|\alpha| \leq k}||D^{\alpha}u||_{\infty} $$
There is a hint: use ArzelÃ â€“Ascoli theorem. But I don't know how can I use that theorem for that sequence and why convergence in $C_b^k(\overline{\Omega})$ implies convergence in $H^k(\Omega)$. I know that in this case ArzelÃ â€“Ascoli theorem implies convergence of a subsequence in $C_b(\overline{\Omega})$, but how can I guarantee convergence in $C_b^k(\overline{\Omega})$?. Can you help me, please?","['arzela-ascoli', 'sobolev-spaces', 'functional-analysis']"
2903406,"If $p,q,r$ are all primes,and $p|qr-1$,$q|pr-1$ and $r|pq-1$,find all possible values of $pqr$.","If $p,q,r$ are all primes,and $p|qr-1$$~~~~~~~~~~~~~$$q|pr-1$$~~~~~~~~~~$ and $~r|pq-1$. Find all possible values of $pqr$. My work: $qr-1=pk_1$ $pr-1=qk_2$ $pq-1=rk_3$ From the above equations, we can conclude that either $k_1,k_2,k_3$ are all even or one of the primes is $2$.
I can also get that, $p^2q^2r^2=(pk_1+1)(qk_2+1)(rk_3+1)$ Now, I cannot proceed. Please help!","['elementary-number-theory', 'prime-numbers']"
2903411,"Fulton, example 3.2.16: Application of the splitting principle.","In his ""Intersection theory"" book Fulton proves in lemma 3.2 the following fact: if a $E$ is a filtered vector bundle of rank $r$ over $X$ with quotients line bundles $L_i$, $s$ is a section of $E$ and $Z$ is the zero-set of $s$, then for any $k$ cycle $\alpha$ on $X$, there exists a $(k-r)$ cycle on $\beta$ on $Z$ with $$c_r(E) \cap \alpha = \prod_i c_1(L_i) \cap \alpha = \beta \ \ \text{in} \ A_{k-r}(X).$$ Now in example 3.2.16 it is claimed that it holds without the assumption that $E$ is filtered as a consequence of the splitting principle. I don't quite see how to proceed. All previous applications of splitting principle first took the flat pullback along $p: \mathbb{P}(E) \to X$. So I first tried considering the following diagram: $\hspace{6cm}$ Then using flat pullback I get $$p^{*} (c_r (E) \cap \alpha) = c_r(p^*E) \cap (p^* \alpha) = \beta$$ where $\beta$ now is an element of $A_{k-1} (p^{-1}(Z))$, since $s$ induces $p^*s$ with zero set $p^{-1}Z$. I am not quite sure what to do next, how to descend $\beta$ to an element of $A_{k-r} (Z)$ is not clear at all. One idea I had is to actually use later theorem 3.3, but I had no success with it too. Any help would be appreciated!","['algebraic-geometry', 'intersection-theory']"
2903426,"If $f(x)<g(x)$, can $\int_a^b f(x)\,dx = \int_a^b g(x)\,dx$?","I couldn't find anything on the internet to clear this up to me. If $f(x)<g(x)$ on an interval $[a, b]$, does that imply $\int_a^b f(x)\,dx \leq \int_a^b g(x)\,dx$ or strictly $\int_a^b f(x)\,dx < \int_a^b g(x)\,dx$. I encountered this problem while trying to prove the latter using the Riemann definition of integration, $$\int_a^b f(x)\,dx = \lim_{n\to\infty} \left(\sum_{i=1}^n f(x_i)\,\Delta x\right)$$ So if $f(x) < g(x)$ for all $x$ in $[a, b]$ and that $x_i \in [a,b]$,
$$f(x_i) < g(x_i)$$
$$f(x_i)\,\Delta x < g(x_i)\,\Delta x$$
$$\sum_{i=1}^n f(x_i)\,\Delta x< \sum_{i=1}^n g(x_i)\,\Delta x$$ This is where my confusion is. I know that if $f(x)<g(x)$ on $[a, \infty]$, then $\lim_{x\to a} f(x) \leq \lim_{x\to a} g(x)$, as in the limits could still be equal. That, I can understand. By applying $\lim_{x\to\infty}$ to both Riemann sums, this implies that $\int_a^b f(x)\,dx \leq \int_a^b g(x)\,dx$. This seems to suggest that the integrals could be equal. But I can't seem to wrap my head, intuitively, why this is the case. Is there an example of two functions with strict inequalities but equal integrals. Or, if it's the case that the integrals CAN'T equal each other, is there a more clear proof of it? Thanks.","['integration', 'calculus', 'inequality']"
2903427,Exists an exponential matrix,"I'm struggling with this proof: Let $\phi(t)$ a square matrix of size $n$ with $C^1$ functions such that $$\phi(0)=I_n \qquad \text{and} \qquad \phi(s+t)=\phi(s)\phi(t)$$
  $\forall s,t\in\mathbb{R}$. 
  Prove that there exists a square matrix $A\in M_n(\mathbb{R})$ such that $\phi(t)=e^{tA}$, for all $t$. I'm almost sure that the matrix $\phi$ is kind of solution of an linear ODE. But I don't realize how i'm supposed to construct the matrix A","['matrix-exponential', 'linear-algebra', 'ordinary-differential-equations']"
2903431,Why defining regular conditional probability?,"Given probability space $(\Omega, \mathcal{F}, \mathbb{P})$, I can understand the definition of conditional expectation $\mathbb{E}[X\mid \mathcal{G}]$, where $\mathcal{G}$ is a sub $\sigma$-algebra of $\mathcal{F}$. If we define $\mathbb{P}(A\mid\mathcal{G}) := \mathbb{E}[\mathbb{I}_A\mid\mathcal{G}]$, we get $\mathbb{P}(A\mid\mathcal{G})$ as a conditional probability. So, why do we need to define regular conditional probability? Can I explain the reason like this? The conditional probability $\mathbb{P}(A\mid\mathcal{G})$ satisfies: $\mathbb{P}(\Omega\mid\mathcal{G})=1$ a.s.; $\mathbb{P}(A\mid\mathcal{G})\ge 0$ a.s.; $\mathbb{P}(\sum_n A_n\mid\mathcal{G}) = \sum_n \mathbb{P}(A_n\mid\mathcal{G})$ a.s. for non-intersecting sets $\{A_n: n\ge 1\}$. Taking $\mathbb{P}(\omega, A)$ as a representative of $\mathbb{P}(A\mid\mathcal{G})$ (since it is an equivalence class of random variable), we hope that $\mathbb{P}(\omega, \cdot):\mathcal{F}\to\mathbb{R}$ is almost surly a probability measure. It easily satisfies $\mathbb{P}(\omega, \Omega)=1$ and $\mathbb{P}(\omega, A)\ge 0$ a.s., but has difficulty on countable-additivity. To satisfy $\mathbb{P}(\omega, \sum_n A_n) = \sum_n\mathbb{P}(\omega, A_n)$ a.s., we must exclude a series of null sets $\{N_n: n\ge 1\}$; and for another series of $\{B_n: n\ge 1\}$, to satisfy $\mathbb{P}(\omega, \sum_n B_n) = \sum_n\mathbb{P}(\omega,B_n)$ a.s., we must exclude another series of null sets $\{M_n: n\ge 1\}$... Then totally we need to exclude 
a big set 
$$
\left(\bigcup_{n=1}^\infty N_n\right) \cup \left(\bigcup_{n=1}^\infty M_n\right) \cup \cdots
$$
which may no longer be a null set. To deal with this difficult, we introduce the concept of regular conditional probability $\mathbb{P}(\cdot, \cdot): \Omega\times\mathcal{G}\to[0,1]$, such that $\mathbb{P}(\omega,\cdot)$ is a probability measure on $\mathcal{G}$ for every $\omega\in\Omega$. $\mathbb{P}(\cdot,A)$ is a measurable function on $(\Omega,\mathcal{G})$ for every $A\in\mathcal{G}$, and $\mathbb{P}(\omega,A)=\mathbb{P}(A\mid\mathcal{G})$ a.s. Since we can tolerance difference between $\mathbb{P}(\omega,A)$ and $\mathbb{P}(A\mid\mathcal{G})$ on null sets, we can just directly remove the ""almost surly"" suffix of $\mathbb{P}(\omega,\Omega)=1$ and $\mathbb{P}(\omega,A)\ge 0$. Please point out my mistakes.","['conditional-expectation', 'conditional-probability', 'probability-theory']"
2903446,Only three types of limit of distributions truncated to a finite interval in the upper tail?,"Suppose random variable $X$ has a continuous probability distribution with an unbounded upper tail; that is, the CDF of $X$ (call it $F$) is absolutely continuous and $F(x)<1$ for all $x\in\mathbb{R}.$ Now consider the conditional CDF of ${X-a\over w}$ given that $a\le X\le a+w$, for $w>0$:$$G(y,a,w):=\mathbb{P}\left({X-a\over w}\le y\ {\LARGE \mid}\ a\le X\le a+w\right) ={F(a+w\,y)-F(a)\over F(a+w)-F(a)}\,1_{0\le y\le 1}+1_{y>1}.$$ WolframCloud computations lead to the following ... Observation : Apparently, for all well-known parametric families of such distributions (e.g., Normal, Lognormal, Student's t, Cauchy, Maxwell, Gamma, Gumbel, Weibull, etc.), there are only three types of limit of the CDF of ${X-a\over w}\mid a\le X\le a+w$ as $a\to\infty$ :
  $$\lim_{a\to\infty}G(y,a,w)=\lim_{a\to\infty}\mathbb{P}\left({X-a\over w}\le y\ {\LARGE \mid}\ a\le X\le a+w\right) \\[3ex]
= \begin{cases} 
1_{y>0} & \text{(Type 1: Degenerate at $0$)}\\[2ex]
y\,1_{0\le y\le 1}+1_{y>1} & \text{(Type 2: Uniform on $[0,1]$)}\\[2ex]
{1- e^{-y\,w/\beta}\over 1-e^{-w/\beta}}1_{0\le y\le 1}+1_{y>1} & \text{(Type 3: Exponential$(\beta/w)$ on $[0,1]$)}
\end{cases}$$ 
  where $\beta$ is a parameter depending on the $X$ distribution. NB : The Type 3 limit depends on both $w$ and the $X$ distribution, but the Type 1 and Type 2 limits are free of w and free of all parameters of the $X$ distribution , which seems quite remarkable. NB : Letting $Y_a={X-a\over w}$, for all three types (and any other type, if there are any) we have $$\begin{align}y\le 0&\implies \{Y_a\le y\}\cap\{0\le Y_a\le 1\}=\{Y_a=0\}\implies \lim_{a\to\infty}G(y,a,w)=0\\
y\ge 1&\implies \{Y_a\le y\}\cap\{0\le Y_a\le 1\}=\{0\le Y_a\le 1\}\implies \lim_{a\to\infty}G(y,a,w)=1\end{align}$$
since $\mathbb{P}(Y_a=0)=0$ due to the distribution of $X$ (hence $Y_a$) being continuous;  thus, the types of limit differ only for $y$ in the open interval $(0,1)$ . Here are pictures of these three types of limit: Questions : How generally does this observation hold, and how can it be proved analytically? (Is this something well-known?) What $X$ distributions (if any) do in fact yield a limit not among these three types? In the Degenerate case, the limit is not right-continuous at $y=0$, so it fails to be a CDF. Nevertheless, as $a\to\infty$ the probability mass clearly concentrates in an arbitrarily small neighborhood of $y=0$ (as indicated by the plots below); so, is there a valid interpretation of this as a limiting distribution? (My original motivating question concerned only the asymptotic variance for just Normal vs. Lognormal. These variances of course follow from the above limiting distributions.) Examples Degenerate Limit Here are the CDFs (left) and corresponding PDFs (right) for Normal($0,1$), showing the CDFs, PDFs labeled as $G(y,a,w),\ g(y,a,w)$ for various $a$ with $w=1$: Computations show that the limit of the distribution is degenerate at $0$ for apparently any Normal, Gumbel, Rayleigh or Maxwell distribution, or any Weibull distribution with shape parameter $> 1.$ Uniform Limit Here are the CDFs (left) and corresponding PDFs (right) for LogNormal(0,1), showing the CDFs, PDFs labeled as $G(y,a,w),\ g(y,a,w)$ for various $a$ with $w=1$: Computations show that the limit distribution is Uniform on $[0,1]$ for apparently any LogNormal, Student-t, Cauchy, Levi, Pareto, or Inverse Gamma distribution, or any Weibull distribution with shape parameter $< 1.$ Exponential Limit Here are the CDFs (left) and corresponding PDFs (right) for Gamma($\alpha=2,\beta=3$), showing the CDFs, PDFs labeled as $G(y,a,w),\ g(y,a,w)$ for various $a$ with $w=1$: Computations show that the limit distribution is Exponential on $[0,1]$ for apparently any Gamma distribution (which includes the Weibull distribution with shape parameter $= 1$), or any Logistic, Laplace, or Extreme Value distribution. For reference, here's the Wolfram code I used: (* Find limit(a->infinity) Pr[(X-a)/w <= y | a<=X<=a+w] for 0<y<1 *)
FindLimit[distr_,asms_]:=Module[{assms=asms~Join~{0<y<1,a>0,w>0}}, 
G[y_,a_,w_]:=Probability[(X-a)/w<=y\[Conditioned]a<=X<=a+w,X\[Distributed]distr];
Glim[y_,w_]:=Simplify[Cancel[Limit[G[y,a,w],a->Infinity]]];
Print[""0<y<1: "", Assuming[assms,Glim[y,w]]];] 

(* Examples: *)

(* In[]= *)
FindLimit[ NormalDistribution[\[Mu],\[Sigma]],{\[Mu]\[Element]Reals ,\[Sigma]>0} ] 
(* Out[]= *)
0<y<1: 1

(* In[]= *)
FindLimit[ LogNormalDistribution[\[Mu],\[Sigma]],{\[Mu]\[Element]Reals ,\[Sigma]>0} ] 
(* Out[]= *)
0<y<1: y

(* In[]= *)
FindLimit[ GammaDistribution[\[Alpha],\[Beta]],{\[Alpha]>0,\[Beta]>0} ]
(* Out[]= *)
0<y<1: (E^(w/\[Beta]) (1-E^(-((w y)/\[Beta]))))/(-1+E^(w/\[Beta]))","['statistics', 'probability-distributions', 'asymptotics']"
2903447,How to evaluate the integral $\int_{0}^{1} \frac{\log x}{\sqrt {1+x^2}}dx$,"$$I=\int_{0}^{1} \frac{\log x}{\sqrt {1+x^2}}dx$$ My attempt:$$I=\int_{0}^{1}\log x d(\log(x+\sqrt{1+x^2}))$$
$$=\log x\log(x+\sqrt{1+x^2})|_0^1-\int_{0}^{1}\frac{\log(x+\sqrt{1+x^2})}{x}dx$$
I don't know how to proceed below, please help me.
That is different to me.","['integration', 'calculus', 'definite-integrals']"
2903455,A simple proof for the relationship between the eigenvalues of a positive definite matrix and its Cholesky decomposition,"Can anyone present to me an elegant elementary proof of the relationship between the eigenvalues of a positive definite matrix and its Cholesky decomposition? More formally, suppose $\mathbf{A}$ is an $n\times n$ positive definite matrix and let $\mathbf{A} = \mathbf{R}^\top \mathbf{R}$ be its Cholesky decomposition. Establish the relationship between the eigenvalues of $\mathbf{A}$ and that of $\mathbf{R}$ . EDIT (Additional remarks): My question specifically wants to find, if possible, an equation or function, say $f$ , that relates the eigenvalues, i.e., $f\left(\lambda_i(\mathbf{R})\right) = \lambda_i(\mathbf{A})$ , with uniqueness up to order being considered if necessary.","['eigenvalues-eigenvectors', 'cholesky-decomposition', 'matrices', 'linear-algebra', 'positive-definite']"
2903468,"Prove that $\int_0^1\,\frac{\ln(x)}{\sqrt{1-x^2}}\,\text{d}x=-\frac{\pi}{2}\,\ln(2)$.","I have discovered via contour integration that $$\int_0^\infty\,\frac{\exp(t\,u)}{\exp(u)+1}\,\text{d}u={\text{csc}(\pi\,t)}\,\left(\frac{\pi}{2}-\int_0^{\frac{\pi}{2}}\,\frac{\sin\big((1-2t)\,y\big)}{\sin(y)}\,\text{d}y\right)\tag{*}$$ for all $t\in\mathbb{C}\setminus\mathbb{Z}$ such that $\text{Re}(t)<1$ .  By taking $t\to 0$ , I deduce that $$\int_0^\infty\,\frac{1}{\exp(u)+1}\,\text{d}u=\frac{2}{\pi}\,\int_0^{\frac{\pi}{2}}\,y\,\cot(y)\,\text{d}y\,.$$ With a step of integration by parts, I obtain $$\int_0^\infty\,\frac{1}{\exp(u)+1}\,\text{d}u=-\frac{2}{\pi}\,\int_0^{\frac{\pi}{2}}\,\ln\big(\sin(y)\big)\,\text{d}y\,.$$ Setting $x:=\sin(y)$ , I get $$\int_0^\infty\,\frac{1}{\exp(u)+1}\,\text{d}u=-\frac{2}{\pi}\,\int_0^1\,\frac{\ln(x)}{\sqrt{1-x^2}}\,\text{d}x\,.$$ This shows that $$\int_0^1\,\frac{\ln(x)}{\sqrt{1-x^2}}\,\text{d}x=-\frac{\pi}{2}\,\int_0^\infty\,\frac{1}{\exp(u)+1}\,\text{d}u\,.$$ The integral $\displaystyle\int_0^\infty\,\frac{1}{\exp(u)+1}\,\text{d}u$ can be easily obtained since $$\int\,\frac{1}{\exp(u)+1}\,\text{d}u=u-\ln\big(\exp(u)+1\big)+\text{constant}\,.$$ That is, I have $$\int_0^1\,\frac{\ln(x)}{\sqrt{1-x^2}}\,\text{d}x=-\frac{\pi}{2}\,\ln(2)\,.\tag{#}$$ However, this proof is a very roundabout way to verify the equality above.  Is there a more direct way to prove that (#) is true?  Any technique is appreciated. A nice consequence of (*) is that $$\int_0^\infty\,\frac{\sinh(t\,u)}{\exp(u)+1}\,\text{d}u=\frac{\pi}{2}\,\text{csc}(\pi\,t)-\frac{1}{2\,t}$$ for all $t\in\mathbb{C}\setminus\{0\}$ such that $\big|\text{Re}(t)\big|<1$ .  This provides a proof that $$\eta(2r)=\frac{1}{(2r-1)!}\,\int_0^\infty\,\frac{u^{2r-1}}{\exp(u)+1}\,\text{d}u=\frac{\pi^{2r}}{2}\,\Biggl(\left[t^{2r-1}\right]\Big(\text{csc}(t)\Big)\Biggr)$$ for $r=1,2,3,\ldots$ .  Here, $\eta$ is the Dirichtlet eta function.  In addition, $[t^k]\big(g(t)\big)$ denotes the coefficient of $t^k$ in the Laurent expansion of $g(t)$ about $t=0$ .  This also justifies the well known results that $$\eta(2r)=\frac{\left(2^{2r-1}-1\right)\,\big|B_{2r}\big|\,\pi^{2r}}{(2r)!}\text{ and }\zeta(2r)=\frac{2^{2r-1}\,\big|B_{2r}\big|\,\pi^{2r}}{(2r)!}$$ for $r=1,2,3,\ldots$ , where $\left(B_j\right)_{j\in\mathbb{Z}_{\geq0}}$ is the sequence of Bernoulli numbers and $\zeta$ is the Riemann zeta function. Similarly, $$\begin{align}\int_0^\infty\,\frac{\exp(t\,u)-1}{\exp(u)-1}\,\text{d}u&=\ln(2)+2\,\int_0^{\frac{\pi}{2}}\,\frac{\sin\big((1-t)\,y)\,\sin(t\,y)}{\sin(y)}\,\text{d}y\\
&\phantom{aaaaa}-\cot(\pi\,t)\,\left(\frac{\pi}{2}-\int_0^{\frac{\pi}{2}}\,\frac{\sin\big((1-2t)\,y\big)}{\sin(y)}\,\text{d}y\right)\,,\end{align}$$ for all $t\in\mathbb{C}\setminus\mathbb{Z}$ such that $\text{Re}(t)<1$ .
This gives $$\int_0^\infty\,\frac{\sinh(t\,u)}{\exp(u)-1}\,\text{d}u=\frac{1}{2\,t}-\frac{\pi}{2}\,\cot(\pi\,t)$$ for all $t\in\mathbb{C}\setminus\{0\}$ such that $\big|\text{Re}(t)\big|<1$ . Another consequence of (*) is that $$\int_0^{\frac{\pi}{2}}\,\frac{\sin(k\,y)}{\sin(y)}\,\text{d}y=\frac{\pi}{2}\,\text{sign}(k)$$ for all odd integers $k$ .  It is an interesting challenge to determine the integral $\displaystyle \int_0^{\frac{\pi}{2}}\,\frac{\sin(k\,y)}{\sin(y)}\,\text{d}y$ for all even integers $k$ .","['integration', 'improper-integrals', 'definite-integrals', 'calculus', 'contour-integration']"
2903488,About the proof that $\int_0^\infty\frac{dx}{x^2+6x+8} =\frac12\log2$ via residue formula,"In the text ""Functions of one Complex Variable"" by Robert E.Greene and Steven G.Krantz is my understanding of the proof to $\text{Proposition (1.1)}$ correct ? $\text{Proposition (1.1)}$ $$\int_{0}^{ \infty} \frac{dx}{x^{2} + 6x + 8} = \frac{1}{2} \log(2) \, \, $$ $\text{Proof}$ For the sake and using Complex-Analytic techniques the author considers the following integral. $$\oint_{\eta_{R}} \frac{\log(z)}{z^{2} + 6z + 8}dz$$ As an exercise, it was left to us by the author that $\log(r)$ is a well defined holomorphic function. To address a trivial proof, one can define $\log(z)$ on $U \equiv \mathbb{C} 
\setminus 
\{x : x \geq 0 
\}$ by $\{ \log(re^{i \theta}) = (\log(r)) + i \theta$  when $0 < \theta < 2 \pi, r > 0 \}$. Before proceeding any further, take note that $$u(r, \theta)=\log(r) \ \ \ \text{ and } \ \ \ v(r, \theta) =\theta.$$ Now it's easy to note that
$$
 \big(  \partial_{r}u \big) =\frac{1}{r}= \frac{1}{r} \cdot 1 = \frac{1}{r} \cdot \left(  \partial_{\theta} v\right)\ \ \ \ \ \text{and } \ \ \ \  \big(  \partial_{r}u \big) = 0 = \frac{-1}{r}\cdot 0 = \frac{-1}{r} \cdot \big( \partial_{\theta} u \big)
$$ So indeed, $log(z)$ is analytic. But before proceeding further he defines $\eta_{R}$ such that, $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{1}(t)  =  t + i/\sqrt{2R},  \, \, \, \,   1/\sqrt{2R} \leq t \leq R,$$ $$\eta_{R}^{2}(t)= Re^{it}, \, \, \, \,  \theta_{0} \leq t \leq 2 \pi - \theta_{0},$$ where $\theta_{0} = \theta_{0}(R) = \sin^{-1}(1/(R \sqrt{2R}))$ $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{3}(t)  =  R -t -i/\sqrt{2R},  \, \, \, \, 0 \leq t \leq R-1/\sqrt{2R},$$ $$\eta_{R}^{4}(t)  =  e^{it}/\sqrt{R}, \, \, \, \, \,  \, \, \, \, \, \, \, \, \, \, \, \, \, \pi/4 \leq t \leq 7 \pi /4.$$ $\text{Remark}$ For those who don't have the book on hand a picture of the Contour employed can be found in $\text{Figure (1.1)}$ $\text{Figure (1.1)}$ $\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, $ The author now says that: $(*)$
$$ \bigg| \lim_{R \rightarrow \infty}\oint_{\eta_{R}^{4}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \rightarrow 0$$ , and that $(**)$ $$ \bigg| \lim_{R \rightarrow \infty}\oint_{\eta_{R}^{2}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \rightarrow 0.$$ A particular device that the author cites to justify convergence over $\eta_{R}^{2}$ and $\eta_{R}^{4}$ consider on faith $$\bigg(\log \bigg( \frac{x + i \sqrt{2R}}{(x-i/\sqrt{2R}} \bigg) \bigg)\rightarrow -2 \pi i.$$ We will come back to this after dealing with the integrals over $\eta_{R}^{2}$ and $\eta_{R}^{4}$. One should note that $$ \sum_{\psi}^{4} \bigg(\oint_{\eta_{R}^{\psi}} \frac{\log(z)}{z^{2} + 6z + 8}dz \bigg).$$ Now over $\eta_{R}^{2}$ we have, \begin{align*}
\bigg| \oint_{\eta_{R}^{2}}\frac{\log(z)}{z^{2} + 6z + 8}dz\bigg|& = \bigg| \int_{-R}^{+Ri} \frac{\log(Re^{it})}{(Re^{it})^{2} + 6(Re^{it}) + 8} iRe^{i \theta} d \theta\bigg|\\&=  \int_{-R}^{+Ri} \bigg|\frac{\log(Re^{it})}{(Re^{it})^{2} + 6(Re^{it}) + 8} \bigg| \big| iRe^{i \theta} d \theta \big|\\&= \int_{-R}^{+Ri} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|(Re^{it})^{2} + 6(Re^{it}) + 8 \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg| \\& = \int_{\theta_{0}}^{2 \pi - \theta_{0}} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|(Re^{it})^{2} + 6(Re^{it}) + 8 \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg|
\end{align*} Now we can establish a precise estimate over $\eta_{R}^{2}$, $$\bigg| \oint_{\eta_{R}^{2}} \frac{\log(z)}{z^{2} + 6z + 8}dz\bigg| \leq  \frac{\ln(R) + \pi }{R^{2} - 13} \pi r \, \, \text{as} \, \, \, R \rightarrow \infty $$ There by proving $(*)$. A similar process can be done for $\eta_{R}^{4}$, hence: \begin{align*}
\bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  dz\bigg|& =  \oint_{\eta_{R}^{4}} \bigg| \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  iRe^{i \theta} d \theta\bigg|\\&= \oint_{\eta_{R}^{4}}  \frac{\bigg|\log(e^{it}/\sqrt{R}) \bigg|}{\bigg|(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8 \bigg|}  iRe^{i \theta} d \theta \\&= \oint_{\eta_{R}^{4}}  \frac{\bigg| \log(e^{it})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|\frac{e^{2it}}{\sqrt{2R}} + (e^{it} / \sqrt{R})(6) +8 \bigg|} \bigg|  iRe^{i \theta} d \theta \bigg|\\& =\oint_{\frac{\pi}{4}}^{\frac{7 \pi}{4}}  \frac{\bigg| it\log(e^{})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|\frac{e^{2it}}{\sqrt{2R}} + (e^{it} / \sqrt{R})(6) +8 \bigg|} \bigg|  iRe^{i \theta}\bigg| d \theta \bigg|.  \end{align*} Now finally a precise estimate for $\eta_{R}^{4}$ $$\bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{(e^{it}/ \sqrt{R})^{2} + (e^{it} / \sqrt{R})(6) +8}  dz\bigg|  \leq  \text{length}(\eta_{R}^{4})  \cdot \sup_{\eta_{R}^{4}}(g) \leq \pi R \frac{O(\log(R))}{\sqrt{R}} \, \text{as} \, R \rightarrow \infty  $$ Thus proving $(**)$ After achieving our preliminary results now we have that, $(***)$ \begin{align*}
 \bigg( \oint_{\eta_{R}^{1}} g(z) dz + \oint_{\eta_{R}^{3}} g(z) dz \bigg)& = \lim_{R \rightarrow \infty }  \bigg( \oint_{\mu_{R}^{1} } \frac{\log(x+  \sqrt{2R})}{(\log(x+  \sqrt{2R}))^{2} + 6(\log(x+  \sqrt{2R})) + 8} - \oint_{\mu_{R}^{3} } \frac{\log(x - i/ \sqrt{2R})}{(\log(x -i /\sqrt{2R}))^{2} + 6(\log(x - i  /\sqrt{2R})) + 8}   \bigg) \\&= -2 \pi i \lim_{R \rightarrow \infty}\int_{0}^{R} \frac{dt}{t^{2} + 6t + 8} \\&
 \end{align*} Using the Residue Theorem it's easy to observe that: $(****)$ $$ \oint_{\eta_{R}} g(z) dz  = 2 \pi i (\operatorname{Res_{g}}(-2) \cdot + Res_{g}(-4) \cdot 1) = - \pi i \log(2)$$ Finally putting $(****)$, $(***)$, $(**)$ and $(*)$ together yields that the, $$\lim_{R \rightarrow \infty}\int_{0}^{R} \frac{dt}{t^{2} + 6t + 8} = \frac{1}{2}\log(2).$$","['complex-analysis', 'proof-explanation', 'contour-integration']"
2903493,Proving that congruent triangles have equal area,"I'm searching different ways to prove ""If $\triangle ABC$ and $\triangle PQR$ congruent triangles then  areas of $\triangle ABC$ and $\triangle PQR$ are equal."" This is the ""best"" way to me. Let $a$, $b$, $c$ be sides of the $\triangle ABC$. then there exists sides $a^\prime$, $b^\prime$, $c^\prime$ in $\triangle PQR$ such that $a=a^\prime$, $b=b^\prime$, $c=c^\prime$. Hence, with $s=\frac12(a+b+c)=\frac12(a^\prime+b^\prime+c^\prime)$, by Heron's Formula ,
$$\text{area of $\triangle ABC$} = \sqrt{s(s-a)(s-b)(s-c)} =\sqrt{s(s-a^\prime)(s-b^\prime)(s-c^\prime)}= \text{area of $\triangle PQR$}$$ Thus, the area of $\triangle PQR$ equals the area of $\triangle ABC$. $\square$ I can think of another one or two ways (that may or may not be mathematical proof). but I like to see your opinion, as a motivation to math. What are the ways you can think-of? Comment or answer below. Thanks.","['euclidean-geometry', 'trigonometry', 'proof-writing', 'triangles']"
2903517,"Prove that if $f:D\to D$ is analytic and has two distinct fixed points, then $f$ is the identity","A complex number $w\in D$ is a fixed point for the map $f:D \to D$ if $f(w)=w$. Prove that if $f:D\to D$ is analytic and has two distinct fixed points, then $f$ is the identity,that is,$f(z)=z$ for all $z\in D$. If $f(0)=0$ , I can use Schwarz lemma to show that $f(z)=ze^{i\theta}$ and $\theta=0$. How could I deal with the condition when $f(0)=z_0 \neq 0$.",['complex-analysis']
2903533,Finding a First Integral of the Lotka-Volterra System,"For the Lotka-Volterra system below
  $$\frac{dF}{dt}=-aF+\alpha FR$$
  $$\frac{dR}{dt}=bR-\beta FR$$
  show that $V=R^aF^b e^{-\alpha R-\beta F}$ is a first integral, that is, $V(t)$ is constant along any trajectory. What can you conclude about the behaviour of the solutions? My attempt: $$\frac{dF}{dt}=-aF+\alpha FR \iff \frac{dF}{-aF+\alpha FR}=dt \ \ \ \ \ (1)$$
$$\frac{dR}{dt}=bR-\beta FR\iff \frac{dR}{bR-\beta FR}=dt \ \ \ \ \ \  \ \ \ \ \ \ (2)$$
Equating $(1)$ and $(2)$
\begin{align} 
\frac{dF}{-aF+\alpha FR}&=\frac{dR}{bR-\beta FR} \\
\int \frac{b}{F}-\beta \ dF&=\int -\frac{a}{R}+\alpha \ dR \\
\ln|F^b|+\ln|R^a|&=\alpha R+\beta F+C \\
F^bR^a&=e^{\alpha R+\beta F}e^C \\
V&=R^aF^be^{-\alpha R-\beta F} \ \ \ \ \ (V=e^C\in\mathbb{R})
\end{align}
Is this a correct method? I do not know what this tells us about the behaiour of the solutions.","['systems-of-equations', 'proof-verification', 'ordinary-differential-equations']"
2903542,Show that every group of order $224 = 2^5*7$ has an element of order 14.,"I am reading a proof to the problem stated above and I have a few questions that I hope somebody helps me clarify. THe proof goes as follows: Let $G$ be a subgroup of order 224 and $S$ be the set of $7$ Sylow subgroups of $G$. THe cardinality of $S$ divides 32 and is congruent to 1 mod 7, so has to be 1 or 8. Let $H$ be a 2-Sylow subgroup of $G$. It has 32 elements and acts on $S$ by conjugation. This is my first question, how do we know that $H$ acts on $S$ by conjugation. My guess is that since $S$ is the set of $7$-sylow subgroups and the $7$ sylow subgroups are conjugate, then action by conjugation of an element $h \in H$, will just send one 7 Sylow subgroup to another one and so the conjugation of $S$ will just be $S$. Is this right or is there any other reason to have this action? If it is not right, how could we know when to use the action by conjugation? Let $N\in S$ be a $7$-Sylow subgroup, and let $U$ be its stabilizaer subgroup in $H$. The $H$-orbit of $N \in S$ has at most 8 elements, so the stabilizer has $32/8=4$ elements. Here I have another question, why does the stabilizer have just 4 elements? The group $U$ normalizes $N$. Let $\phi:U \rightarrow Aut(N)$ be the group homomorphism associated with the conjugation action of $U$ on $N$. Since $Aut(N)$ has $6$ elements and the number of elements of $U$ is divisible by $4$, the group homomorphism $\phi:U \rightarrow Aut(N)$ cannot be injective. It is still not clear for me why $\phi$ cannot be injective. Can someone explain the relationship between $Aut(N)$ having 6 elements, $U$ being divisible by $4$ and $\phi$ not being injective? We can choose a nontrivial element of order 2 in the kernel of $\phi$. We can also choose $g$ be a generator of $N$. Then $h$ and $g$ commute,$h$ has order 2 and $g$ has order 7. Then $hg$ has order 14.","['group-theory', 'abstract-algebra']"
2903563,Continuity of argmax?,"Let $f(\cdot,\cdot):\Omega\to\mathbb{R}$ be a continuous function with $\Omega$ a compact subset of $\mathbb{R}^n\times\mathbb{R}^m$. From these assumptions, $f(x,\cdot)$ must possess a maximum for each $x\in\mathcal{X}$, where $\mathcal{X} = \{x\in\mathbb{R}^n: (x,y)\in\Omega \text{ for some } y\in\mathbb{R}^m\}$. In general, however, $f(x,\cdot)$ may contain multiple global maximizers. My question is -- are there any (mild) conditions that we can impose on $f$ to ensure that a function $F:\mathcal{X}\to\mathcal{Y}$
$$F(x) \in \operatorname{argmax} f(x,\cdot),$$
where $\mathcal{Y} = \{y\in\mathbb{R}^m: (x,y)\in\Omega \text{ for some } x\in\mathbb{R}^n\}$, is continuous? In other words, $F(\cdot)$ is such that
$$f(x,F(x)) = \max_{y\in\Omega_x} f(x,y),$$
where $\Omega_x = \{y\in\mathbb{R}^m: (x,y)\in\Omega\}$. And I mean other than the ""trivial"" case of $f(x,\cdot)$ having exactly one global maximizer for each $x$ and thus $F(x)$ being uniquely defined. EDIT: Follow-up question: Under the conditions that I stated (or other similar mild ones), where $F$ is non-unique, must one of them be continuous? EDIT 2: Scratch the previous follow-up question. I guess the better question is: are there any mild conditions on $f$ (and/or $\Omega$) that ensure that at least one particular $F$ (when the argmax may not be uniquely defined) must be continuous?","['optimization', 'general-topology', 'real-analysis']"
2903649,What are the odds of sitting next to the same person on two flights?,"My wife left on a business trip this morning. 20 people from the same company caught two consecutive flights. Each person checked in independently, yet my wife ended up sitting next to the same colleague on both flights! What are the odds? Assume both aeroplanes had 150 seats, in 3+3 configuration, in 25 rows. It's not exactly right but will do for the purposes of the exercise.
Assume also that all other passengers checked in independently, so there are no couples choosing or being assigned seats next to each other, thus changing the odds. This isn't right either, but will also do for the purposes of the exercise. My wife and colleague were sitting next to each other, not across the aisle from each other.",['probability']
2903650,"If $G$ is an abelian group, then $H=\{g\in G \mid |g| \text{ divides }12\}$ is a subgroup of $G$","$$H=\{g\in G \mid |g| \text{ divides }12\}$$ We have to prove that $H$ is a subgroup of $G$. Consider $a\in G$ and, the group $\langle a \rangle$ where $|a|=12$. This group will contain elements orders of which will be divide 12. This is a cyclic subgroup I think this should be equal to H but I am not sure as I don't know if G is finite.","['abelian-groups', 'abstract-algebra', 'cyclic-groups']"
2903663,Continuous function that takes rationals to irrationals and vice-versa?,"In this question - https://www.quora.com/Can-you-create-a-continuous-function-that-takes-rational-numbers-to-irrational-ones-and-vice-versa How $|f(\Bbb{Q})| \leq |\Bbb{Q}|$ ? in the first answer, I understood that $|f(\Bbb{Q}^c)| \leq |\Bbb{Q}|$ de to the fact that $|$Codomain$| \leq |$range$|$. After that how do I think of this? - It then follows that f is a constant function because a non-constant continuous real-valued function has an uncountable image. Also any other approach to this question?","['real-analysis', 'continuity', 'calculus', 'functions', 'rational-numbers']"
2903718,Evaluate $\lim_{x\rightarrow -\infty}{e^{\frac {1}{2-x}}\cdot\frac{x^2+2x-1}{x-2}}-x$,I want to find the following limit: $$\lim_{x\rightarrow -\infty}{e^{\frac {1}{2-x}}\cdot\frac{x^2+2x-1}{x-2}}-x$$ This is what I do. I change the variable $t=-x$ and I have the following limit: $$\lim_{t\rightarrow +\infty}{e^{\frac {1}{2+t}}\cdot{\frac{t^2-2t-1}{-t-2}}+t}=\lim_{t\rightarrow+\infty}{h(x)}$$ We have $e^{\frac{1}{2+t}}\rightarrow1$ for $t\rightarrow+\infty$ Therefore I think (this is the passage I'm less sure about) $$h(x)\sim \frac{t^2-2t-1}{-t-2}+t=\frac{t^2-2t-1+t(-t-2)}{-t-2}=\frac{t^2-2t-1-t^2-2t}{-t-2}=\frac{-4t-1}{-t-2}\sim{\frac {-4t}{-t}}\rightarrow4$$ The solution should actually be $3$. Any hints on what I'm doing wrong?,['limits']
2903751,"Probability measure on $(0,\infty)$","What can be a possible probability measure on $(0,\infty)$? Give an example. For $(0,1)$ Lebesgue measure can be used and it easily satisfies all the properties of probability measure. But when the set is $(0,\infty)$, Lebesgue measure will not lie in 0 to 1 range. I am thinking that some mapping from $(0,\infty)$ to $(0,1)$ would do the trick. Am I right?",['probability-theory']
2903788,Uniform convergence of convolution of a distribution with a test function,"For an exercise I have to show the following: Let $u_j \to u$ in $\mathcal{D'(\mathbb{R}^n)}$ and let $\phi_j \to \phi$ in $C^{\infty}_0(\mathbb{R}^n)$. Show that $$ \lim_{j\to \infty} u_j * \phi_j = u*\phi $$ in $C^{\infty}(\mathbb{R}^n)$. What I have tried so far This means that for all compact sets $K \subset \mathbb{R}^n$, and all orders of differentiations $\alpha \in \mathbb{Z}_{\geq 0}$, it must hold that
\begin{equation}
 \partial^{\alpha}(u_j*\phi_j) \to \partial^{\alpha}(u*\phi) 
\tag{1}
\end{equation}
uniformly on $K$. I can use that $\partial^{\alpha}(u_j*\phi_j) = u_j*(\partial^{\alpha} \phi_j)$, and since $\partial^{\alpha} \phi_j \in C^{\infty}_0(\mathbb{R}^n)$, we only have to show (1) for $\alpha = 0$, because the other values follow by induction. Let $K \subset \mathbb{R}$. Then we know that 
\begin{equation}
|(u_j * \phi_j)(x) - (u*\phi)(x)| \leq |(u_j*\phi_j)(x) - (u_j*\phi)(x)| + |(u_j*\phi)(x) - (u*\phi)(x)|
\end{equation}
I will now show that both terms go to zero. We use the translation operator $T_x$ ($T_x \phi(y) = \phi(y-x)$) and the reflection operator $S$ ($S\phi(y) = \phi(-y)$). Now the first term is given by
\begin{equation}
(u_j*\phi_j)(x) - (u_j*\phi)(x) = u_j(T_x \circ S(\phi_j-\phi))
\end{equation}
Because of the convergence of $\phi_j$ we know that there exists a compact set $A$ such that $\text{supp }\phi_j \subset A$ and $||\phi_j-\phi ||_{C^k} \to 0$ for all $k$. Hence we find that 
\begin{equation}
\text{supp }(T_x \circ S(\phi_j-\phi)) = x - \text{supp }(\phi_j-\phi) \subset K+(-A) := B
\end{equation}
Since $B$ is the sum of two compact sets, it itself is compact. We can now use the uniform boundedness theorem to find that 
\begin{equation}
|u_j (T_x \circ S(\phi_j -\phi))| \leq c || T_x \circ S(\phi_j -\phi)||_{C^k} = c ||\phi_j -\phi||_{C^k} \to 0
\end{equation} We now look at the second term. Let $v_j = u_j-u \to 0$ in $\mathcal{D}'(\mathbb{R}^n)$. Now by the same arguments as above we find by the uniform boundedness theorem
\begin{equation}
|v_j(T_x \circ S\phi)| \leq c || \phi||_{C^k} \leq M
\end{equation}
Now for $x,y \in K$ we find that 
\begin{equation}
|v_j*\phi(x) - v_j*\phi(y)| \leq |x-y| \sup_{z \in K} \partial (v_j*\phi)(z) \leq |x-y|M
\end{equation}
So that for all $\epsilon > 0$ we can pick $\delta = \frac{\epsilon}{M}$ and $|x-y| < \delta$ implies $|v_j*\phi(x) - v_j*\phi(y)|<\epsilon$. We now invoke the ArzelÃ -Ascoli theorem to find a uniformly convergent subsequence $v_{j_k}*\phi \to 0$. Since $v_j \to 0$ it must be that $v_j*\phi \to 0$ uniformly on $K$. My question I feel the first part of the proof is good and complete, but I am not so sure about the second part. Could you please point out if there are any mistakes, or if there are some missing arguments?","['convolution', 'distribution-theory', 'functional-analysis', 'uniform-convergence', 'sequences-and-series']"
2903823,"Proof for the dimension of a subspace of M(n,R)","First I will state the exercise and then show what I could get. Let $A_{1},...,A_{k} \in M(n,R)$ such that for all $ 1 \le i \neq j \le k $:  $ A_{i}^{2}=I$ and $A_{i}A_{j}+A_{j}A_{i}=0$ show that $k \le \frac{n(n+1)}{2}$ Ok, first of all we can see that the condition $ A_{i}^{2}=I$ means that all the matrices in this form are diagonalizable with eigenvalues $\in  \big\{1,-1\big\}  $, so we can state that $A_{i}$ are all invertible matrix and $A_{i}^{-1}=A_{i}$. Now if I multiply the relation between the matrices for $A_{i}$ i get that $A_{i}A_{j}A_{i}=-A_{j}$ wich means that $A_{j}$ and $-A_{j}$ are similar and because they need to share determinant it has to be 0 if the dimension of the space is odd.
I also know that they commute. I feel like I should be able to find some other relation (maybe about the Ker of the linear application) from $A_{i}A_{j}+A_{j}A_{i}=0$ but I don't know how. Thanks in advance",['linear-algebra']
2903838,Find angle UFO in the picture attached,"I sent this problem to Presh Talwalkar who suggested me to send it to this site.
I tried many things but was not able to find the correct solution. I made various segments trying to get an equilateral triangle similar to the Russian triangle problem, but no success. I also tried to flip the triangle UFO over side NO but again no success. I tried to find like triangles, but not enough. 
Could you please give me a hint? Thanks,
R. de Souza","['euclidean-geometry', 'geometry', 'triangles', 'plane-geometry', 'trigonometry']"
2903843,PlÃ¼cker embedding - Two definitions,"While reading several papers on the topic of the Grassmannian, I cam about two definitions of the PlÃ¼cker embedding.
One given as
$$ \varphi: \mathbb{A}^{n \cdot d} \rightarrow \mathbb{P}^{\binom{n}{d}-1}, A \mapsto \text{det}(A^{(I)})$$
where $ A^{(I)}$ denotes the submatrix of $A$ obtained by choosing its $I$-th columns. (I know that I can identify the affine space of this dimension with the space of matrices of size $d \times n$. Moreover, the map is  only well-defined if we look at matrices of rank $d$ which gives us the connection to elements of the Grassmannian). The other one was given as $$\psi: Gr(d,n) \rightarrow \mathbb{P}^{\binom{n}{d}-1}, U \mapsto [u_1 \wedge \dotsc \wedge u_d]$$ So my question concerns the connection of these two maps in the projective space respectively whether there is a connection at all. I assume there must be something as in the papers I've read different authors used them both for talking about the PlÃ¼cker embedding. Thank you for your help.","['grassmannian', 'algebraic-geometry', 'projective-space']"
