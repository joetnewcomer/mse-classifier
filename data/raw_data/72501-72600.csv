question_id,title,body,tags
890455,Countably infinite union,"Is it the case that $(a,b) \subseteq\bigcup_{n\in \mathbb{N}} (a+\frac{1}{n}, b-\frac{1}{n})$? Seeing as we are only indexing by positive integers? i.e we never reach $\infty$",['elementary-set-theory']
890479,How come $\sum\limits_{n=1}^{\infty}\frac{1}{2^n}=\sum\limits_{n=1}^{\infty}\frac{1}{2^n\ln(2^n)}$?,"I'm a bit puzzled with the following: $\displaystyle\sum\limits_{n=1}^{\infty}\frac{1}{2^n}=1$ $\displaystyle\sum\limits_{n=1}^{\infty}\frac{1}{2^n\ln(2^n)}=1$ Which essentially yields the identity: $$\sum\limits_{n=1}^{\infty}\frac{1}{2^n}=\sum\limits_{n=1}^{\infty}\frac{1}{2^n\ln(2^n)}$$ Now obviously, $\displaystyle\forall{n\in\mathbb{N}}:\frac{1}{2^n}\neq\frac{1}{2^n\ln(2^n)}$ In fact, the above inequity holds for all values except $n=\log_2e$ Still, when summing up each of these infinite sequences, the result is $1$ in both cases. So in essence I am looking for a ""native"" (philosophical if you will) explanation of this. Thank You.",['sequences-and-series']
890507,Terminal objects of the category of morphisms,"I'm reading Basic Category Theory for Computer Scientists by Benjamin C. Pierce and in exercice 1.4.6 , he asks what the terminal objects are in $Set^\to$. Let $C$ be a category. The category $C^\to$ is defined as a category so that: An objet in $C^\to$ is an arrow in $C$ An arrow in $C^\to$ from $f:A\to B$ to $f':A'\to B'$ is a pair $(a,b)$ so that the following diagram commutes
$$\require{AMScd}
\begin{CD}
A @>{a}>> A'\\
@V{f}VV @V{f'}VV \\
B @>{b}>> B'
\end{CD}$$ I think I have solved this exercice (but I'd really appreciate comments on the proofs): Theorem 1 : Terminal objects in $Set^\to$ are isomorphisms whose codomain is a terminal object in $Set$: Lemma 2 : Given a morphism $f:A\to B$ and an isomorphism $f':A'\to B'$, $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$ is equivalent to $\exists !b:B\to B'$. Proof 2 : Since $f'$ is an isomorphism, $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$ is equivalent to $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$. We now prove that $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$ is equivalent to $\exists !b:B\to B'$. ""$\Longrightarrow$"": Suppose $\exists !(a:A\to A',b:B\to B'), f;b;f'^{-1}=a$. The existence of $b:B\to B'$ is trivial. Suppose there were two function $b_1:B\to B'$ and $b_2:B\to B'$. By setting $a_1:=f;b_1;f'^{-1}$ and $a_2:=f;b_2;f'^{-1}$, we contradict the uniqueness hypothesis. So $\exists !b:B\to B'$. ""$\Longleftarrow$"": Suppose $\exists !b$. Defining $a:=f;b;f'^{-1}$, we get the existence of $(a:A\to A',b:B\to B')$. The uniqueness of $b$ is given by the hypothesis and the uniqueness of $a$ for a given $b$ is ensured by the equation so $\exists !(a:A\to A',b:B\to B'), f;b=a;f'$. Proof 1 : ""$\Longleftarrow$"": Let $f':A'\to B'$ be an isomorphism so that $B'$ is terminal in $Set$. By definition, we have $\forall B \in Set, \exists !b:B\to B'$. This is equivalent to $\forall A,B\in Set, \forall f:A\to B, \exists !b:B\to B'$ which is, by Lemma 1, equivalent to $\forall A,B\in Set, \forall f:A\to B, \exists !(a:A\to A',b:B\to B'), f;b=a;f'$. So $f'$ is terminal in $Set^\to$. ""$\Longrightarrow$"": Let $f':A'\to B'$ be a terminal object in $Set^\to$ (where $A'$ and $B'$ are objects of $Set$). To prove that $f'$ is injective, suppose it is not. We can find $x,y\in A'$ so that $x\not=y$ but $f(x)=f(y)$. And then the function
$$s:\left\{\begin{array}{ll}
x\mapsto y\\
y\mapsto x\\
\lambda\mapsto \lambda \text{ for } \lambda\not\in\{x,y\}
\end{array}\right.$$ that swaps $x$ and $y$ is a valid candidate for $a$. Since $Id_A$ is a distinct valid candidate, $a$ is not unique which is absurd so $f'$ is injective.
$$\require{AMScd}
\begin{CD}
{A'} @>{a:=Id_A\mid a := s}>> A'\\
@V{f'}VV @V{f'}VV \\
{B'} @>{b}>> B'
\end{CD}$$ To prove that $f'$ is surjective, suppose it is not. We can find $y\in B'$ so that $\forall x\in A', f(x)\not=y$. If $B'$ contains an element $z\in B'$ so that $z\not= y$, the function
$$p:\left\{\begin{array}{ll}
y\mapsto z\\
\lambda\mapsto \lambda \text{ for } \lambda\not=y
\end{array}\right.$$ that sends all elements to themselves except $y$ which is sent to $z$ is a valid candidate for $b$. Since $Id_B$ is a distinct valid candidate, $b$ is not unique which is absurd. If $B'=\{y\}$, $\forall x\in A', f(x)\not = y$ has to be vacuously true so $A'=\emptyset$. Setting $A:=\{y\}$, $B:=\{y\}$ and $f:=Id_{\{y\}}$, we don't have the existence of $a$ which is absurd.
$$\require{AMScd}
\begin{CD}
{A:=\{y\}} @>{a}>> A'=\emptyset\\
@V{f:=Id_{\{y\}}}VV @V{f'}VV \\
{B:=\{y\}} @>{b}>> B'=\{y\}
\end{CD}$$ Since both cases are absurd, $f'$ is surjective. Since $f'$ is injective and surjective, it is bijective and is therefore an isomorphism in $Set$. For any object $X$ of $Set$, we can take $A:=X$, $B:=X$ and $f:=Id_X$. 
$$\require{AMScd}
\begin{CD}
A:=X @>{a}>> A'\\
@V{f:=Id_X}VV @V{f'}VV \\
B:=X @>{b}>> B'
\end{CD}$$
We have $\exists !(a:X\to A',b:X\to B'), f;b=a;f'$ which is, by Lemma 1, equivalent to $\exists !b:X\to B'$. So $B'$ is terminal in $Set$. I tried to generalize this to all categories. Lemma 1 seems to be general and doesn't need any modification. In Theorem 1, the part that becomes hard is proving that $f'$ is an isomorphism. I assume I should prove that it's both monic and epic and then find a right-inverse (or a left-inverse) to prove it's an isomorphism but I wasn't able to do any of that. So my question is: Is there a generalisation of Theorem 1 for all categories? If yes, then I'd like to know the exact statement, and maybe a hint on the direction that I should take (including waiting to know more stuff if need be) but no proof (unless it's a hidden proof or a linked proof or any proof that I won't see until I want to). If not, then I'd like to know if there is a generalisation for some categories (I assume there must be something to be done with algebra categories but I haven't looked into it yet). I'd also like to see an example where it fails (hidden or linked and with juste a hint in the question if it's an example one can find). Thank you in advance.","['category-theory', 'abstract-algebra']"
890545,Solve $3^x+3^{(3x+1)}=108$,"I was helping a high school student with their homework and I ran across the following problem: solve $$3^x+3^{(3x+1)}=108.$$ I was unable to find any ""elementary way"" to do this (by which I mean something a high school student would be comfortable with like manipulating the equation until the bases are the same and then equating the power, or using logarithms to undo exponents). Can anyone solve this with $9^{th}$ or $10^{th}$ grade level math?",['algebra-precalculus']
890552,nth derivative of determinant wrt matrix,"I'm working on an expression for the nth derivative of a (symmetric) matrix, i.e.
\begin{equation}\frac{\partial^{n} \det(A)}{\partial A^{n}}\end{equation}
Starting with \begin{equation}\frac{\partial \det(A)}{\partial A}=\det(A) A^{-1}\end{equation}
Then naturally the next derivative is 
\begin{equation}\frac{\partial^{2}\det(A)}{\partial A^{2}}=\frac{\partial}{\partial A}\left(\det(A)A^{-1}\right)=\det(A)A^{-2}-\det(A)A^{-2}=0\end{equation}
I doubt this is right, can someone point out my mistake? I'm actually working on an expression for the nth derivative of $\det(A)^{-1/2}$ but a general formula for the simple case would be fine.","['matrix-calculus', 'linear-algebra', 'determinant']"
890613,Differentiable Strictly Convex Function on Interval,"Let $f:\mathbb{R}\rightarrow \mathbb{R}$ be a differentiable, strictly convex function. Let $I\subset \mathbb{R}$ be a closed, bounded interval such that $f'(x) \neq 0$ on $I$. Is $f$ strongly convex on $I$? Note: If $f$ is twice differentiable the answer is yes.","['convex-analysis', 'calculus', 'derivatives', 'analysis']"
890640,group-like structure texts.,"I was reading Dummit and Foote to be ready for my group theory text, but my teacher seems to be paying special attention to things with less structure than groups, for example monoids, semigroups, and other things I don't know the name for in english. We have proves problems similar to the 2001 A1 problem or the 2012 A2 problem. We also saw if $S$ is a semigroup with left and right cancelation then $S$ is a monoid, I later realized on my own $S$ is also a group. I would like to obtain certain mastery and intuition on these group like structures, I am looking for texts, or references of any sort that will help me become better at dealing with these things. Thank you very much in advance. Regards.","['reference-request', 'group-theory', 'abstract-algebra', 'monoid']"
890658,Geometric interpretation of $\beta_r(s) = \alpha(s) + r\mathbf{n}(s)$,"Let $\alpha(s)$ be a smooth curve parameterised by arc-length and for fixed $r > 0$ define $\beta_r(s) = \alpha(s) + r\mathbf{n}(s)$, where $\mathbf{n}(s)$ is the unit normal vector to $\alpha$ at $s$.  What is the geometric interpretation of the result: $$\left(\frac{d}{ds}\beta_r(s)\right)\cdot\mathbf{t}(s) = 0 \iff r = \frac{1}{\kappa(s)}$$ This question is from a course I am studying and isn't homework.  I have proved the result, but I am struggling to interpret it.  I can see that $\beta_r(s)$ would be the equation of the normal line at $s$ if $r$ was a parameter.  But $r$ being fixed has me somewhat confused, particularly since the result involves $r$ taking a value that is a function of the parameter $s$.  As far as I can make out, the result says that the direction of change of the normal (?) is perpendicular to the tangent vector when $r$ is one on the curvature.",['differential-geometry']
890661,Can functions be defined by relations?,"So let us say that for whatever reasons, we are not allowed to use function symbols in first-order logic. Then can we define and use a function only by relations?","['relations', 'logic', 'elementary-set-theory', 'functions']"
890672,Maximal height of subgroups in $S_n$?,"In the process of solving some exercise, I became curious about the maximum height of a chain of subgroups in $S_n$. More specifically - what is the maximum length k of a chain of subgroups $\{e\} \subset H_1 \subset \ldots \subset H_k = S_n$, where no additional conditions are imposed on the subgroups other than the inclusions being proper. Does anyone know any results in this direction? It feels somewhat beyond my current abilities. My google searches for maximal series connected me to results about composition series, chief series, which I am already familiar with. Is there some reason why a maximal series of subgroups (in a finite group) is uninteresting in general? (I guess they are certainly less interesting than their normal series cousins, since the difference between successive terms cannot be measured by a group...) Thanks in advance.","['permutations', 'group-theory']"
890693,Hartshorne Ex III5.7 c),"Suppose $X$ is a reduced proper schemes over a noetherian ring, $X_i$ are its irreducible components，$L$ is a invertible sheaf on $X$. If $L|_{X_i}$ are all ample, how do we show $L$ is ample? If $X=X_1\cup X_2$, $F$ be a coherent sheaf on $X$, then $0\to I_{X_1}\to O_{X_1\cup X_2}\to O_{X_1}\to 0$，using long exact sequence, we have $\cdots\to H^i(FI_{X_1}\otimes L^n)\to H^i(F\otimes L^n)\to H^i(FO_{X_1}\otimes L^n)\to\cdots$ When $n$ is sufficiently large, the third terms would be $0$, but how to deal with the first terms?",['algebraic-geometry']
890706,What is the oldest open problem in geometry?,"Geometry is one of the oldest branches of mathematics, and many famous problems have been proposed and solved in its long history. What I would like to know is: What is the oldest open problem in geometry? Also (soft questions) : Why is it so hard? Which existing tools may be helpful to handle it? If twenty great geometers of today gathered to work together in the problem, would they (probably) be able to solve it? P.S. The problem can be of any area of geometry (discrete, differential, etc...)","['geometry', 'math-history', 'open-problem', 'soft-question']"
890714,"Connectedness of a linear continuum [Sect-24.1, Munkres]","In Munkres' Topology p.153, we have a proof like this Proof. $\ \ $ Recall that a subspace $Y$ of $L$ is said to be convex if for every pair of points $a,b$ of $Y$ with $a<b$, the entire interval $[a,b]$ of points of $L$ lies in $Y$. We prove that if $Y$ is a convex subspace of $L$, then $Y$ is connected. $\quad$ So suppose that $Y$ is the union of the disjoint nonempty sets $A$ and $B$, each of which is open in $Y$. Choose $a\in A$ and $b\in B$: suppose for convenience that $a<b$. The interval $[a,b]$ of points of $L$ is contained in $Y$. Hence $[a,b]$ is the union of the disjoint sets $$A_0=A\cap[a,b]\quad{\rm and}\quad B_0=B\cap[a,b],$$ each of which is open in $[a,b]$ in the subspace topology, which is the same as the order topology. The sets $A_0$ and $B_0$ are nonempty because $a \in A_0$ and $b\in B_0$. Thus, $A_0$ and $B_0$ constitute a separation of $[a,b]$. $\quad$ Let $c=\sup A_0$. We show that $c$ belongs neither to $A_0$ nor to $B_0$, which contradicts the fact that $[a,b]$ is the union of $A_0$ and $B_0$. $\quad$ Case 1. Suppose that $c\in B_0$. Then $c\neq a$, so either $c=b$ or $a<c<b$. In either case, it follows from the fact that $B_0$ is open in $[a,b]$ that there is some interval of the form $(d,c]$ contained in $B_0$. If $c=b$, we have a contradiction at once, for $d$ is a smaller upper bound on $A_0$ than $c$. If $c<b$, we note that $(c,b]$ does not intersect $A_0$ (because $c$ is an upper bound on $A_0$). Then $$(d,b]=(d,c]\cup (c,b]$$ He mentions that $B_0$ is open, so there is some interval $(d, c]$ containing $c$, which is contained in $B_0$. So we know if $c=b$, $(d, c]=(d, -\infty)$, which is open in $[a, b]$ for sure. But if $a< c< b$, will $(d, c]$ still be open in this linear order? My conclusion is $(d, c]$ is not open, because we assume in advance that Definition. $\ \ $ A simply ordered set $L$ having more than  one element is called a linear continuum if the following hold: $L$ has the least upper bound property. If $x<y$, there exists $z$ such that $x<z<y$. Theorem 24.1. $\ \ $ If $L$ is a linear continuum in the order topology, then $L$ is connected, and so are intervals and rays in $L$. L is a linear continuum,  and for any $x$ and $y$, we can pick a $z$ lying between them. So if $(d, c]$ is open, we can write $(d, c]$ as $(d, e)$, but by the 2nd property of linear continuum, we can not have a number which is the minimal number in $[a, b]$, having the property ""larger than $c$"" (like what we do to prove $(a, x]$ is open is $\omega_1$). Am I correct? Thanks!",['general-topology']
890738,Find the value of $27\csc^2\theta+8\sec^2\theta$,"$10\sin^4\theta+15\cos^4\theta=6$, then find the value of  $27\csc^2\theta+8\sec^2\theta$ I don't know how to do it  have just tried by converting sin and cos into csc and sec. But can't get the answer.","['trigonometry', 'self-learning']"
890745,$a_{n+1}=|a_n|-a_{n-1} \implies a_n \; \text{is periodic}$,"Prove that any sequence of real numbers satisfying $a_{n+1}=|a_n|-a_{n-1}$ is periodic. Although it looks simple, I can't prove this statement... I tried rewriting the first few terms of the sequence, but nothing interesting showed up... I'd be mostly interested in hints for this one.",['sequences-and-series']
890751,Solve 2 connected ODEs describing a domain,"This problem confused me for a long time. I have 2 ODEs which describe part of our domain. They are connected at middle:
$$
\frac{d^2}{dx^2} u = -a, x<x_0 
$$
$$
\frac{d^2}{dx^2} u - \frac{u}{b^2}= 0, x>x_0 
$$
The whole domain is defined as
$$
-W < x  
$$
With the following conditions
$$
\lim_{x->-W} u = 0  
$$
$$
\lim_{x->+\infty} u = c \;\;or\;\; \lim_{x->L} u = c 
$$ u, u' and u'' needs to be continous. a, b, W and c are constants. If not possible with $\infty$ one can replace $+\infty$ with a constant L. Update: As a hint, the following functions are solutions of individual equations $$u_1(x) = \alpha x^2 + \beta x + \gamma  $$
    $$u_2(x) = c_1 exp(-x/b) + c_2 exp(x/b) $$
Where $\alpha$, $\beta$, $\gamma$, $c_1$ and $c_2$ are constants related to the constants in the ODEs. Problem is that we usually put $c_2 = 0$ since the exp(x/b) diverges.
    If we do so, 2nd derivative of u would not be continous at $x_0$. My numerical simulated solution looks like 
$$ \frac{1}{1+exp(x/b)}$$
But it does't match exactly.
The form of numerical solution and 2 regions are clear in the following link: http://www.wolframalpha.com/input/?i=1%2F%281%2Bexp%28x%29%29+from+x%3D-10+to+x%3D10","['ordinary-differential-equations', 'integration', 'partial-differential-equations', 'partial-derivative', 'derivatives']"
890752,Showing Hat matrix equal specific values,"Consider a one way layout model $y_{ij}$ = $\mu_i + e_{ij}$ (1 $\leq$ i $\leq$ a, 1 $\leq$ j $\leq$ $n_i$) where a = 3 and $n_1$ = 2, $n_2$ = 3, $n_3$ = 4. Show that the hat matrix for this design equals: $ H = \left| \begin{array}{ccc}
1/2 & 1/2 & 0 & 0 & 0 & 0 & 0 &  0 & 0 \\
1/2 & 1/2 & 0 & 0 & 0 & 0 & 0 &  0 & 0 \\
0 & 0 & 1/3 & 1/3 & 1/3 & 0 & 0 &  0 & 0 \\
0 & 0 & 1/3 & 1/3 & 1/3 & 0 & 0 &  0 & 0 \\
0 & 0 & 1/3 & 1/3 & 1/3 & 0 & 0 &  0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1/4 & 1/4 &  1/4 & 1/4 \\
0 & 0 & 0 & 0 & 0 & 1/4 & 1/4 &  1/4 & 1/4 \\
0 & 0 & 0 & 0 & 0 & 1/4 & 1/4 &  1/4 & 1/4 \\
0 & 0 & 0 & 0 & 0 & 1/4 & 1/4 &  1/4 & 1/4 \end{array} \right|. $ I am stuck as I am unable to find the inverse of X'X: $ X'X = \left| \begin{array}{ccc}
9 & 2 & 3 & 4  \\
2 & 2 & 0 & 0  \\
3 & 0 & 3 & 0\\
4 & 0 & 0 & 4  \\
\end{array} \right|. $ I believe that I need to put some sort of constraint on the X'X matrix, but I'm not sure how to do this.","['statistics', 'matrices', 'probability', 'regression']"
890774,How to integrate $\frac{x+4}{x^2+2x+5}$,Having a little trouble on how to break it up. How to integrate $$\frac{x+4}{x^2+2x+5}$$,"['calculus', 'integration', 'partial-fractions']"
890796,Mutually disjoint implying complements in set theory,"No homework tag because it is just practice for a final, not for marks: $\text{Let $S, T \subseteq U$. If $S \bigcap T= \emptyset$, then $S$  and $T$ :}$ A) are always complements of each other in $U$, B) are mutually disjoint, C) have no elements in common, D) choices B and C, E) none of these choices I am very confused as I thought the answer should be all of A B and C, but unless the answer is E, which would be a misleading answer for no reason, that is incorrect. My train of thought is that, since $S\bigcap T = \emptyset $ they definitely do not have any elements in common. They must be mutually disjoint as there is no intersection. They should also be complements of each other?? Where am I going wrong? Thank you! Edit: Thank you everyone! I had the wrong understanding of the definition of complement. All your answers/comments were helpful, thanks.","['discrete-mathematics', 'elementary-set-theory']"
890798,Squeeze Principle,"Let $\{a_n\}$ be a sequence of positive integers and let $f$ be a function on the integers. Suppose that for each $\epsilon \in (0,1)$ there exists an integer $L$ such that for every $n \geq L$ we have
$$
\epsilon f(n) \leq a_n \leq f(n).
$$
Is is true that we can find an $L_1$ such that $a_n = f(n)$ for every $n \geq L_1$? Thanks!","['sequences-and-series', 'calculus', 'limits']"
890811,Prove $X_n \xrightarrow P 0$ as $n \rightarrow \infty$ iff $\lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )= 0$,"Let $X_1, X_2, ...$ be a sequence of real-valued random variables. Prove $X_n \xrightarrow P  0$ as $n \rightarrow \infty$ iff $\lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )= 0$ Attempt: Suppose $X_n \xrightarrow P  0$ as $n \rightarrow \infty$. Then since $X_1, X_2, ...$  is uniformly integrable and E(|X|)<$\infty$, then $\lim_{n \to \infty} E(X_n) = E(X)$. Since $X_n \xrightarrow P  0$ as $n \rightarrow \infty$, then $\lim_{n \to \infty} E(\frac{|X_n|}{|X_n|+1} )$ must be equal to 0.","['convergence-divergence', 'statistics', 'expectation', 'real-analysis', 'probability']"
890814,Integral $\int_0^\infty \frac{x^n - 2x + 1}{x^{2n} - 1} \mathrm{d}x=0$,"Inspired by some of the greats on this site, I've been trying to improve my residue skills. I've come across the integral $$\int_0^\infty \frac{x^n - 2x + 1}{x^{2n} - 1} \mathrm{d}x=0$$ where $n$ is a positive integer that is at least $2$ .
With non-complex methods, I know that the integral is $0$ . But I know that it can be done with residue theorem. The trouble comes in choosing a contour. We're probably going to do some pie-slice contour, perhaps small enough to avoid any of the $2n$ th roots of unity, and it's clear that the outer-circle vanishes. But I'm having trouble getting the cancellation for the integral. Can you help? (Also, do you have a book reference for collections of calculations of integrals with the residue theorem that might have similar examples?)","['residue-calculus', 'improper-integrals', 'integration', 'complex-analysis']"
890827,The Moduli Stack of Elliptic curves - What is it?,"I have often heard the words ""Moduli Stack of Elliptic Curves"", but I have nowhere found a from-scratch definition of this object. I do understand the motivation: There are cusps in the moduli space that produce singularities. For me, a stack is a generalized sheaf on a site. So I am specifically asking the following questions: 1) What is the site? 2) What are the fibers (this should be categories, even groupoids?) I know that the upper half plane with the usual action of $\mathrm{SL}(2, \mathbb{Z})$ (which parametrizes elliptic curves) is an orbifold, which is a special stack (the site being the site of the topological space, and the fibers being more or less the automorphism group(oid)s). But is that all there is to it? Why don't peoply say ""orbifold"" instead of stack?","['algebraic-geometry', 'elliptic-curves', 'moduli-space']"
890828,Trigonometric Identity problem involving cot,"Simplify $\displaystyle\frac{\cot25 + \tan65}{\cot25}$ My attempt is: $$\frac{\cot25 + \tan65}{\cot25}=\frac{\cot25 + \cot(90 - 65)}{\cot25}=\frac{\cot25 + \cot25}{\cot25}= \frac{\cot50}{\cot25}$$ and that is all I got up to.. The correct answer is $2$, I know that $\cot 50$ goes into $\cot 25$ twice. But, I'm not sure if my method is right.","['trigonometry', 'algebra-precalculus']"
890843,Uniform perturbative solutions to the Mathieu equation,"The Mathieu equation is a second-order linear differential equation given by
$$y''(t) + [a - 2q\cos(2t)]y(t) = 0$$
There are two special functions defined as linearly independent solutions to Mathieu's equation: 1. The even Mathieu cosine function which I will denote as $MC(a,q,t)$, satisfying the initial conditions $MC(a,q,0)=1$ and $MC'(a,q,0)=0$ (where prime denotes $t$ derivative). 2. The odd Mathieu sine function, $MS(a,q,t)$, satisfying $MS(a,q,0)=0$ and $MS'(a,q,0)=1$. For $q=0$, Mathieu's equation reduces down to the familiar differential equation
$$y''(t) + ay(t) = 0 \tag{*}$$
for which we have even and odd solutions $\cos(\sqrt{a}t)$ and $\sin(\sqrt{a}t)$.
Let $\epsilon = \frac{2q}{a}$ and suppose that $2q \ll a$ so that $\epsilon \ll 1$. Therefore Mathieu's equation can be written as
$$\frac{1}{a}y''(t) + [1-\epsilon \cos(2t)]y(t) = 0$$
where we view it as a perturbed form of equation $(*)$. It follows that for the case of small $\epsilon$, the functions $MS$ and $MC$ should be approximated by $\sin$ and $\cos$ plus small perturbative terms. The problem with such a perturbative solution is the appearance of secular terms at $\mathcal{O}(\epsilon^2)$, i.e. terms of the form $t\cos(\sqrt{a} t)$ or $t\sin(\sqrt{a} t)$ which diverge with large $t$, whereas the functions $MC$ and $MS$ appear to be uniformly bounded. I have tried several standard methods for obtaining uniform perturbative solutions, i.e. the Poincaré - Lindstedt method and multiple scale analysis but neither method successfully gets rid of the secular terms. Does anyone know how I can (or if it's even possible) to obtain an approximation for $MC$ and $MS$ which is reasonably accurate for all $t$?","['ordinary-differential-equations', 'special-functions', 'perturbation-theory']"
890844,How to compute these probabilities?,"A pair of dice is cast until either the sum of seven or eight appears. How to compute the probability of a seven before an eight? Now, if this pair of dice is cast until a seven appears twice or until each of a six and eight have appeared at least once. How to compute the probability of the six and eight occurring before two sevens?","['statistics', 'probability', 'probability-theory']"
890849,"Matrix inner product, and operator and trace norm inequality","I have trouble proving the following inequality. Let a matrix $A \in \mathbb{R}^{M \times N}$ , and $\sigma_i(A)$ be the i-largest singular value of A. Define the operator norm and the trace norm as follow: $$
\|A\|_2 := \sigma_1(A),\ \|A\|_{tr} = \sum_{i = 1}^{\min\{M, N\}} \sigma_i(A)
$$ Could anyone provide me how to prove the below statement? $$
\langle X,Y\rangle \le \|X\|_{tr}\,\|Y\|_2
$$ Note that $\langle X,Y\rangle $ is the matrix inner product.","['normed-spaces', 'linear-algebra', 'inequality']"
890853,Is a direct proof of this possible,"Consider the following statement $x_n \to x$ if and only if every subsequence of $x_n$ has a subsequence that converges to $x$. $\implies$ is clear. A proof of the other direction is given here . 
It is a proof by contrapositive. My question is: can it be proved directly? (I obviously tried but couldn't do it)",['general-topology']
890857,How to compute of each player winning this sequence of games?,"Players A and B play a sequence of independent games. Player A throws a die first and wins on a ""six."" If A fails, then player B throws and wins on a ""five"" or ""six."" If B fails, then A throws and wins on a ""four,"" ""five,"" or ""six."" And so on. How to find the probability of each player winning the sequence?","['statistics', 'dice', 'probability', 'probability-theory']"
890870,Prove that $\frac{\tan^2\theta(\csc\theta-1)}{1+\cos\theta}=\frac{(1-\cos\theta)\csc^2\theta}{\csc\theta+1}$,Question: $$\frac{\tan^2\theta(\csc\theta-1)}{1+\cos\theta}=\frac{(1-\cos\theta)\csc^2\theta}{\csc\theta+1}$$ Prove that L.H.S.=R.H.S. My Efforts: L.H.S.$$=\frac{\tan^2\theta(\csc\theta-1)}{1+\cos\theta}\times\frac{1-\cos\theta}{1-\cos\theta}\times\frac{\csc\theta+1}{\csc\theta+1}$$ $$=\frac{\tan^2\theta(1-\cos\theta)(\csc^2\theta-1)}{(1-\cos^2\theta)(\csc\theta+1)}$$,"['trigonometry', 'self-learning']"
890872,The other ways to calculate $\int_0^1\frac{\ln(1-x^2)}{x}dx$,"Prove that
  $$\int_0^1\frac{\ln(1-x^2)}{x}dx=-\frac{\pi^2}{12}$$ without using series expansion. An easy way to calculate the above integral is using series expansion. Here is an example
\begin{align}
\int_0^1\frac{\ln(1-x^2)}{x}dx&=-\int_0^1\frac{1}{x}\sum_{n=0}^\infty\frac{x^{2n}}{n} dx\\
&=-\sum_{n=0}^\infty\frac{1}{n}\int_0^1x^{2n-1}dx\\
&=-\frac{1}{2}\sum_{n=0}^\infty\frac{1}{n^2}\\
&=-\frac{\pi^2}{12}
\end{align}
I am wondering, are there other ways to calculate the integral without using series expansion of its integrand? Any method is welcome. Thank you. (>‿◠)✌","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
890919,connection laplacian on general vector bundles,"As the title says, my question is about how to define the connection laplacian on general vector bundles. I think I understand how to define the connection laplacian on the tensorbundles: Let $M$ be a Riemannian manifold and $\mathcal{T}^k_l(M)$ be the space of smooth section of the vector bundle of $(k,l)$ -tensors on $M$ . Call elements in $\mathcal{T}^k_l(M)$ smooth $(k,l)$ -tensor fields. We think of a smooth $(k,l)$ -tensor field as a $C^{\infty}(M)$ -multilinear map $F\colon \Omega^1(M)\times\ldots\times\Omega^1(M)\times\mathfrak{X}(M)\times\ldots\times\mathfrak{X}(M)\rightarrow C^\infty(M)$ , where $\Omega^1(M)$ is the space of $1$ -forms on $M$ , $\mathfrak{X}(M)$ is the space of vector fields on $M$ , $\Omega^1(M)$ is taken $l$ -times and $\mathfrak{X}(M)$ is taken $k$ -times. For each $k,l$ he Levi-Civita-Connection on $M$ induces a connection $\nabla$ on the bundle of $(k,l)$ -tensors, so we have maps $\nabla\colon \mathcal{T}^k_l(M)\rightarrow \mathcal{T}^{k+1}_l(M)$ given by $\nabla F(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k,X):=(\nabla_XF)(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k)$ It turns out that $(\nabla^2F)(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k,Y,X):=(\nabla\nabla F)(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k,Y,X)=(\nabla_X\nabla_YF-\nabla_{\nabla_XY}F)(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k)$ Finally we define the connection laplacian $\Delta\colon \mathcal{T}^k_l(M)\rightarrow \mathcal{T}^k_l(M)$ by $(\Delta F)(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k):=tr_g((Y,X)\mapsto\nabla^2F(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k,Y,X))$ where $tr_g$ is to be understood as follows: if $G$ is a $(2,0)$ -tensor, we transform it into a $(1,1)$ -tensor by via the metric (i.e. by applying the #-operator). A $(1,1)$ tensor can be understood as an endomorphism of $T_pM$ of which the trace can be taken. If $(e_i)$ is a local orthonormal frame, we have $(\Delta F)(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k)=\sum_i \nabla^2F(\omega^1,\ldots,\omega^l,Y_1,\ldots,Y_k, e_i,e_i)$ . Now, let $E$ be a vector bundle over $M$ with a connection $\nabla$ . For any smooth section $\varphi$ of $E$ , we define $\nabla^2\varphi (X,Y):=\nabla_X\nabla_Y\varphi - \nabla_{\nabla_XY}\varphi$ where $X$ and $Y$ are vector fields. For a local orthonormal frame $(e_i)$ we set $\Delta \varphi :=\sum_i\nabla^2\varphi (e_i,e_i)$ . However, this definition is unsatisfying for me: Question 1 : Is it possible to define a ""trace"" in the setting of general vector bundles $E$ so that $\Delta \varphi$ turns out to be trace( $\nabla^2\varphi$ ) just as in the case of the tensor bundles? Edit : I found a reference that defines the connection laplace via trace (Lawson, Spin Geometry, p. 154). Could someone explain to me how the trace is to be understood in that context? Question 2 : Is there more behind the definition of $\nabla^2\varphi (X,Y)$ (as in the case of the tensor bundles, where $\nabla^2 F$ is $\nabla\nabla F$ )? That is, do $\nabla$ and the Levi-Civita-Connection induce a connection $\nabla$ on $T^*M\otimes E$ in a way that $\nabla\nabla\varphi=\nabla^2\varphi$ ? I also would appreciate any kind of reference where this is explained.","['tensors', 'differential-geometry']"
890952,Summation of infinite series,"If we know the series sum  given below converges to a value $C$(constant) 
$$\sum_{n=0}^{\infty}a_n =C \tag 2$$ Can we generate following in terms of C. values of $a_n$ will tend to zero as n goes to infinity and sum too converges to C.. $\sum_{n=0}^{\infty}na_n $ $\sum_{n=0}^{\infty} \frac{a_n}{n!}$","['power-series', 'recurrence-relations', 'sequences-and-series', 'summation', 'derivatives']"
890956,How find the value of the $a$ such $\{a^n\}$,"Let us define the sequence  $$a_{n}=\{a^n\}$$ with $a > 0$ where $\{a^n\}$ denotes the fractional part. How could we show that there is no positive real numbers $a\in Q$ such that this sequence $a_{n}$ is strictly increasing. I can find example such $a_{n}$ is increasing,such as
$$a=1+\varepsilon,\varepsilon\to 0,$$ Now achille hui have find Nice a example when $a$ is irrational, $$a=(2+\sqrt{3})$$ Now I think when $a\in Q$ is true,can someone prove it?",['sequences-and-series']
890960,Asymptotics of coefficients $[x^n] \frac{1}{\Gamma(1+x)}$ as $n$ is great,"I am interested in the behaviour, as $n$ is great, of the coefficients $g_n$ in the Maclauren expansion of $\displaystyle \frac{1}{\Gamma(1+x)} $. We have 
$$
\frac{1}{\Gamma(1+x)}=\sum_{n=0}^\infty g_n x^n
$$
with
$$
\begin{align}g_0 &=1
\\g_1 &=\gamma
\\g_2 &=\frac{\gamma^2}{2}-\frac{\pi^2}{12}
\\g_3 &=\frac{\gamma^3}{6}-\frac{\pi^2\gamma}{12}+\frac{\zeta(3)}{3}
\\...
\end{align}
$$
and $g_n \rightarrow 0.$ I would appreciate any asymptotic expansion giving the behavior of $g_n$ as $n$ tends to $+\infty$.","['sequences-and-series', 'calculus', 'euler-mascheroni-constant', 'asymptotics', 'gamma-function']"
890965,Integrate $\left[\arctan\left(x\right)/x\right]^{2}$ between $-\infty$ and $+\infty$,"I have tried to calculate
$$
\int_{-\infty}^{\infty}\left[\arctan\left(x\right) \over x\right]^{2}\,{\rm d}x
$$
with integration by parts and that didn't work. I looked up the indefinite integral and found it contained a polylogarithm which I don't know how to use so I tried contour integration  but got stuck. $${\tt\mbox{Wolfram Alpha said the answer is}}\,\,\,{\large \pi\log\left(4\right)}$$ Can anyone show me how to do this integral ?.","['calculus', 'integration']"
890980,Where do I make mistake on this derivative containing e^x^2,"My brother is preparing for the university and asked me the following multiple choice question. $$\frac{d}{dx}(x^3 * e^{x^2})$$ a)  $e^{x^2}*x^2*(1+2x)$ b)  $e^{x^2}*x^2*(3+2x)$ c)  $e^{x^2}*x^2*(3+2x^2)$ d)  $e^{x^2}*x^2*(3-2x)$ e)  $e^{x^2}*x^2*(3-2x^2)$ Even though I find $e^{x^2}*x^2*(3+2x^2)$, the answer is $e^{x^2}*x^2*(3+2x)$. I wonder where do I make the mistake. What I did is as follows: By product rule: $$(x^3 * e^{x^2})' \Rightarrow 3x^2 * e^{x^2} + x^3 * (e^{x^2})'$$
Since $(e^{x^2})' = 2x * e^{x^2}$, the equation becomes 
$$3x^2 * e^{x^2} + x^3 * 2x * e^{x^2}$$
$$e^{x^2} * x^2 * (3 + 2x^2)$$ Thanks","['exponential-function', 'calculus', 'derivatives']"
890982,Closure of a subset of a metric space is closed,"From definition, if $X$ is a metric space, if $E \subset X$, and if $E'$ denotes the set of all limit points of $E$ in $X$, then the closure of $E$ is the set $\overline{E}=E \cup E'$. I need to prove that $\overline{E}$ is closed. By a closed set, I mean that all limit points of a set are in the same set. A limit point of a set is a point whereby every neighbourhood of the point contains a $q$ such that $q$ is an element of the set. The proof provided in Theorem 2.27(a) of Rudin's Principles of Mathematical Analysis is as follows: If $p \in X$ and $p \notin \overline{E}$ then $p$ is neither a point of $E$ nor a limit point of $E$. Hence $p$ has a neighbourhood which does not intersect $E$. The complement of $\overline{E}$ is therefore open. Hence $\overline{E}$ is closed. My question is with how ""Hence $p$ has a neighbourhood which does not intersect $E$."" leads to ""The complement of $\overline{E}$ is therefore open."". To show that the complement of $\overline{E}$ is open, we need to show that $p$ has a neighbouthood which does not intersect $\overline{E}$, not just $E$. Unless it is true that if the neighbourhood (an open set, since neighbourhoods are all open sets) does not intersect $E$, then it also does not intersect $E'$. Is that true?","['general-topology', 'elementary-set-theory', 'analysis']"
891031,Smooth subvariety at smooth points,"Let $f: X \to Y$ be a finite, surjective morphism of smooth, quasi-projective varieties over a field $k$ of characteristic zero. Let $p \in X$. Is it true that I can find a subvariety $X' \subseteq X$ of codimension one such that $p$ is a smooth point of $X'$ and such that $f(p)$ is a smooth point of the closure of $f(X')$ in $Y$? Edit: Alternatively: If $\dim X >0$, can I find a smooth curve $C$ on $X$ such that $f(p)$ is a smooth point of the closure of $f(C)$ in $Y$?",['algebraic-geometry']
891037,Fourier transform of a compactly supported function.,"Can someone help me the question below?
Is there a positive-valued compactly supported function $f$ such that the Fourier transform ${{f}^{\operatorname{ft}}}\left( t \right)=\int_{-\infty }^{\infty }{f\left( x \right){{e}^{itx}}dx}, t\in\mathbb{R}$, and derivative of the Fourier transform, $\frac{d}{dt}{{f}^{\operatorname{ft}}}\left( t \right)$, decay with exponential rates at infinity ?
Thank so much for helping.",['analysis']
891044,Find $\cos(x-y)$ if $\cos x + \cos y =2$,I had a question in my Math mcq test. If $\cos x + \cos y = 2$ find the value of $\cos(x-y)$. I couldn't get a way to calculate the value. So I just substituted $x = y = 0$. (It seemed obvious to me) So I got $\cos(x-y) = \cos 0 = 1$. But can we actually solve it? I am looking for ways that can be done in short time ($2-3$) minutes. As longer solutions may not be feasible in a time bound examination...,['trigonometry']
891050,Chessboard problem in IMO2014,"This is the second problem on the IMO2014 problem list: Let n $\ge 2$ be an integer. Consider an $n \times n$ chessboard
  consisting of $n^2$ unit squares. A configuration of $n$ rooks on this
  board is peaceful if every row and every column contains exactly one
  rook. Find the greatest positive integer $k$ such that, for each
  peaceful configuration of $n$ rooks, there is a $k \times k$ square
  which does not contain a rook on any of its $k^2$ unit squares. On an $n\times n$ chessboard we want to place $n$ rooks -- this observation makes the problem so easy. Since on an $n\times n$ board there are $\left\lfloor\dfrac{n^2}{k^2}\right\rfloor$ many disjoint $k\times k$ squares, by the pigeonhole principle $k$ must be the largest such that $n\leq\dfrac{n^2}{k^2}$. In fact, $n=\left\lfloor\dfrac{n^2}{k^2}\right\rfloor$ and therefore $k=\lfloor\sqrt{n}\rfloor$. I found this solution to the problem: http://imomath.com/index.php?options=924 , which I think is an overkill. Why would someone post such a lengthy solution when there is a much simpler one? These make me think that my solution is wrong, is it?","['puzzle', 'contest-math', 'combinatorics']"
891054,Finding the number of solutions to $x+2y+4z=400$,"My question is how to find the easiest way to find the number of non-negative integer solutions to $$x+2y+4z=400$$
I know that I can use generating functions, and think of it as partitioning $400$ with $x$ $1$'s, $y$ $2$'s, and $z$ $4$'s. The overall generating function is: $$(1+x+x^2 + \cdots x^{400})(1+x^2+x^4+\cdots x^{200})(1+x^4+x^8+\cdots x^{100})$$
And then from this I have to calculate the coefficient of $x^{400}$, which I don't know how to do. If there's an easier way to do, I'd love to know.","['generating-functions', 'combinatorics']"
891078,What happen to composite of infinite number of continuous functions?,We all know that a composite of continuous functions is continuous. And this holds for any $\textbf{finite}$ number of functions. My question is what happen to infinite number of functions? Is it always discontinuous? Or it can also be continuous in some cases? Any counter examples and examples where it is discontinuous and continuous for infinite number of functions? Many thanks!,"['calculus', 'continuity', 'functions', 'limits']"
891085,Determine ellipse from two points and direction vectors at those points [duplicate],"This question already has answers here : How to find an ellipse , given 2 passing points and the tangents at them? (8 answers) Closed 9 years ago . I'm attempting to draw an ellipse based on two points. For each of these points I have a vector showing the direction the curve of the ellipse should be at this point (I suppose another way of looking at it is that I have 2 tangent lines to the to the ellipse with the intersection point for each). I know normally 2 points would not be enough to determine the ellipse, but I thought the vectors might make it possible. Ideally I'm trying to calculate the center point and the major and minor axis (I guess either the actual points or the vector from the center). I'm not quite sure how to proceed with this, or whether it's actually possible, but any help would be greatly appreciated, thanks. Edit: Added a simple example of what I'm talking about. For the record, the calculation will be in 3D space. Okay, so the I have the two tangent lines illustrated here, in the form of a point and a (normalized) vector, the point being the intersection point with the ellipse (it's part of the line and the ellipse). By vectors from the center point for the axes I just meant it as an alternative way of finding the minor and major axis points, stupid thing to put in). Edit 2: Let's assume they're not parallel.","['geometry', 'conic-sections']"
891116,If $f(2x-f(x))=x$ . Find all bijective functions.,"It is given that $f :[0,1] \rightarrow [0,1] $ and it is bijective. If $f(2x-f(x))=x$ , find all such f. Is my solution correct? My attempt $f(x)$ is bijective. thus there exists g(x) which is the inverse of f(x). $f(2x- f(x)) = x $ $=>f(x)+g(x) = 2x$ Assume $f(y)\neq y$ for some $y$. Then , $f(y) = y+ d$ and $g(y) = y-d$ for some $d$. Now, $f(y+d) \neq y+d$ as $f(y)=y+d$ and $f$ is bijective. Then, $f(y+d) = y+d+h$ for some $h$.
Therefore $g(y+d) = y+d-h$ but $g(y+d) = y$.
Thus $d=h$, which implies $f(y+d)=y + 2d$. => $f(f(y)) = y + 2d$ By iteration we get, $f^n(y)=y+nd$. There exists n such that If $d>0, y+nd >1$.
If $d<0 , y+nd<0$.
Thus we arrive at a contradiction.","['functions', 'functional-equations']"
891124,Is set with this property is homeomorphic to Cantor set?,"(1) $A$ is nonempty subset of $\mathbb{R}$. (2) For all $x<y \in A$ there is $z \notin A$ such that $x<z<y$. (3) $A$ is perfect. Then is there homeomorphism between $A$ and cantor set? Intuitively, I think this is right because $A$ is uncountable because of (3), and set is almost like distinct many points. Which is almost like Cantor set.",['analysis']
891163,Volume of a frustum,"SE users I was given the problem: Find the volume of a frustum of a right circular cone with height h, lower base radius R, and top radius r. My working looks a bit too complicated and comes out with a really complicated solution. What method should I have used to avoid this?","['volume', 'integration']"
891169,Conjecture: Tract version of Gauss--Lucas Theorem for higher derivatives.,"The Gauss--Lucas Theorem states that all zeros of a degree $n$ complex polynomial $p(z)$ are contained in the convex hull of the zeros of $p$.  By iteration, this implies that the zeros of $p',p^{(2)},\ldots,p^{(n-1)}$ are contained in the convex hull of the zeros of $p$. The Riemann--Hurwitz Theorem (among others) implies that if a tract $D$ of $p$ (namely a component of the set $\{z:|p(z)|<\epsilon\}$ for some $\epsilon>0$) contains all the zeros of $p$ in its bounded face, then all the critical points of $p$ are contained in $D$. My conjecture is that in fact, if $D$ is a tract of $p$ and contains all the zeros of $p$, then $D$ also contains all the zeros of $p',p^{(2)},\ldots,p^{(n-1)}$. This certainly does not follow by straight-forward iteration, since in general there need not be a tract of $p'$ containing all the zeros of $p'$ which is contained in $D$.  It seems that the tracts and level curves of $p'$ do not interact very nicely with the tracts and level curves of $p$ (even worse for $p'',p''',\ldots$). I have taken a look at attempting to apply the Cauchy Integral Formula (some sort of integration by parts application perhaps?), but don't seem to be able to make progress there.  Any ideas for proof or counter-example?","['roots', 'complex-analysis', 'polynomials']"
891195,Showing the following function is entire...,"The full problem asks about the following function using it's Maclaurin series:
$$f(x)=\left\{
\begin{array}{lr}
\frac{\sin(z)}{z} & : z \neq 0\\
\;\;\;\;1 & : z=0
\end{array}
\right.$$
I've represented $\dfrac{\sin(z)}{z}$ as the Maclaurin series
$$\frac{\sin(z)}{z}=\sum_{n=0}^{\infty}\frac{(-1)^nz^{2n}}{(2n+1)!}=1-\frac{z^2}{3!}+\frac{z^4}{5!}-...$$ Applying the ratio test, we find that $$\left|\lim_{n\to\infty}\frac{z^{2n+1}\cdot(2n+1)!}{z^{2n}\cdot(2n+3)!}\right|$$
$$=\left|\lim_{n\to\infty}\frac{z}{(2n+3)(2n+2)}\right|$$
$$=|z|\left|\lim_{n\to\infty}\frac{1}{(2n+3)(2n+2)}\right|$$
$$=|z|\cdot 0$$
Using the notation for radius of convergence as $R=\frac{1}{\beta}$, we have that $\beta=0$, so $R=\infty$. Does that mean that our function is entire since it converges everywhere? I mean, we know of a series that its derivative and integral will share the same radius of convergence, so then they in turn must be convergent everywhere. Now, I know when not using series, we want to satisfy the Cauchy-Riemann equations and look at if the function is analytic or not, so I figure looking at the derivative of our series and it being convergent everywhere entails entire. Anyone able to verify my thinking?","['absolute-convergence', 'power-series', 'complex-analysis']"
891200,Is this a Lipschitz function in 2d?,"I want to show that the function $A(x,y)$ is Lipschitz in two dimensions. 
The function is defined as follows $$A(x,y)=a\frac{\Phi(-y)e^{0.5(y^2-x^2)}+\Phi(-x)e^{0.5(x^2-y^2)}}{(1-a)[1-a(1-\Phi(x))(1-\Phi(y))]+2a\Phi(x)\Phi(y)}$$ where $a\in[-1,1]$ and $\Phi$ is the standard normal cumulative distribution function.
How can I show this is Lipschitz? Could anyone help me in the right direction?","['functions', 'real-analysis']"
891204,Solve $\lim_{x \to 0}x\sin(\frac{1}{x})$ Using $\lim_{\theta \to 0}\frac{\sin \theta}{\theta} = 1$,"Solve $\lim_{x \to 0}x\sin(\frac{1}{x})$ Using $\lim_{\theta \to 0}\frac{\sin \theta}{\theta} = 1$ I have solved it using the Squeeze Theorem and now I want to solve it using $\lim_{\theta \to 0}\frac{\sin \theta}{\theta} = 1$. Why can't I multiply the numerator and denominator by $\frac{1}{x}$ so I can have it in the form of $\lim_{x \to 0}\frac{\frac{1}{x}x\sin(\frac{1}{x})}{\frac{1}{x}} = \lim_{x \to 0}\frac{\sin(\frac{1}{x})}{\frac{1}{x}}$ so that I can apply $\lim_{\theta \to 0}\frac{\sin \theta}{\theta} = 1$. I understand that $\lim_{x \to 0}\frac{1}{x}$ does not exist, so does that mean that I can't solve the above mentioned using $\lim_{\theta \to 0}\frac{\sin \theta}{\theta} = 1$?","['calculus', 'limits']"
891223,How to represent the ceiling function using mathematical notation?,"How to represent the ceiling function using mathematical notation? I need an equation to input in a program because it doesn't except the ceiling function so it has to be some sort of mathematical equation. I also can't convert decimal numbers to integers within the string. I know the floor function can be represented mathematically most simply as ""x-x mod 1"" or using an arctan equation but is there something similar to these mathematical formats for the ceiling function? Thanks!!","['notation', 'functions']"
891233,Prove that $\sin(\sqrt x)$ not periodic,$\sin\sqrt x$ is not a periodic function. How can one prove this?,"['trigonometry', 'periodic-functions']"
891242,Evaluating a limit using L'Hôpital's rule,"I know that it can be also evaluate using Taylor expansion, but I am intentionally want to solve it using L'Hôpital's rule: $$ \lim\limits_{x\to 0} \frac{\sin x}{x}^{\frac{1}{1-\cos x}} = 
\lim\limits_{x\to 0}\exp\left( \frac{\ln(\frac{\sin x}{x})}{1-\cos x} \right)$$ Now, from continuity and L'hopital Rule: 
$$\lim\limits_{x\to 0} \frac{\ln(\frac{\sin x}{x})}{1-\cos x} = 
\lim\limits_{x\to 0} \frac{\frac{x}{\sin x}\cdot\frac{x\cos x - \sin x}{x^2}}{\sin x} = 
\lim\limits_{x\to 0}\frac{\frac{x\cos x - \sin x}{x\sin x}}{\sin x}$$ This is where I got stuck. If I'm not mistaken the limit is $-\frac{1}{3}$ so the orginial one is $e^{-\frac{1}{3}}$ What should I do different (Or what's is wrong with my calculation?) Thanks","['calculus', 'real-analysis', 'limits']"
891259,Are the topology of a manifold and the topology induced by the metric of a manifold the same?,"I am just learning what a topology is and from what I have understood up till now is  that a topological space is nothing but a set with a notion of nearness that is given introducing open sets. Ok, so, in the definition of manifold that I have seen (in Wald's general relativity book) a manifold is constructed mapping subsets of the manifold to be set with open subsets of $\mathbb{R}^n$. This way we introduce a topology in our manifold to be, since we can use the notion of open balls in $\mathbb{R}^n$ to define open balls of the manifold and hence we get a topology. Now, we can add more structure to the manifold endowing it with a metric and making it a metric space. Now my question. I know that a metric induces naturally a topology. But we already had a topology before itroducing the metric structure, so, are this two topologies the same topology?","['general-topology', 'riemannian-geometry', 'manifolds', 'differential-geometry']"
891271,Limit of $\lim\limits_{n\to\infty} (1 + \frac{x_n}{n})^n$,"Many websites and calculus books give this well known result
\begin{equation}
\lim\limits_{n\to\infty} \left(1 + \frac{x}{n}\right)^n = e^x
\end{equation}
However, a textbook I was reading casually mentioned that if $x_n \rightarrow x$ then 
\begin{equation}
\lim\limits_{n\to\infty} \left(1 + \frac{x_n}{n}\right)^n = e^x
\end{equation}
Why is this true? It seems very intuitive but I feel some explanation is missing. Thank you!","['sequences-and-series', 'calculus', 'real-analysis', 'limits']"
891289,Uniqueness of additive identity element of vector space (or group or monoid),"Please rate and comment. I want to improve; constructive criticism is highly appreciated.
Please take style into account as well. Proof of uniqueness of identity element of addition of vector space This proof is solely based on vector space axioms.
Axiom names are italicised .
They are defined in Wikipedia (vector space). Let $V$ be a vector space.
We prove the uniqueness of an identity element of addition (IEOA).
By Identity element of addition ,
there exists an IEOA.
Let this element be denoted by $0$.
For the sake of contradiction, we assume that the IEOA is not unique.
That is, there exists an IEOA $0'$ such that $0' \ne 0$.
Obviously, $V \ne \emptyset$. Let $v \in V$.
By Identity element of addition , $v + 0 = v$ and $v + 0' = v$.
Hence, $$v + 0 = v + 0'.$$
By Commutativity of addition , $$0 + v = 0' + v.$$
By Inverse elements of addition , there exists an additive inverse of $v$.
Let $-v$ denote the additive inverse of $v$.
Due to the foregoing equality, $$(0 + v) + (-v) = (0' + v) + (-v).$$
By Associativity of addition , $$0 + (v + (-v)) = 0' + (v + (-v)).$$
By Inverse elements of addition , $$0 + 0 = 0' + 0.$$
By Identity element of addition , $$0 = 0'.$$
The foregoing equality contradicts our assumption.
Thus, our assumption is false and its negation is true.
That is, the IEOA is unique. QED P.S.: I wrote another version of the proof , which is less roundabout.","['vector-spaces', 'linear-algebra', 'group-theory', 'solution-verification']"
891312,A cotangent series related to the zeta function,"$$\sin x =  x\prod_{n=1}^\infty \left[1-\frac{x^2}{n^2\pi^2}\right]$$ If you apply $\log$ to both sides and derivate: $$\cot x = \frac{1}{x} - \sum_{n=1}^\infty \left[\frac{2x}{n^2\pi^2} \frac{1}{1-\frac{x^2}{n^2\pi^2}}\right]$$ I have to make the expansion: $$\frac{1}{1-\frac{x^2}{n^2\pi^2}} = 1 + {\left(\frac{x^2}{n^2\pi^2}\right)} + \left(\frac{x^2}{n^2\pi^2}\right)^2 + \left(\frac{x^2}{n^2\pi^2}\right)^3 + \cdots \tag{1}$$ But for this, I'm gonna expand the infinite sum: $$\cot x = \frac{1}{x} - \left(\frac{2x}{1^2\pi^2} \frac{1}{1-\frac{x^2}{1^2\pi^2}} + \frac{2x}{2^2\pi^2} \frac{1}{1-\frac{x^2}{2^2\pi^2}} + \frac{2x}{3^2\pi^2} \frac{1}{1-\frac{x^2}{3^2\pi^2}}+\cdots\right)$$ So I can understand the boundaries of this expansion (cause the series $\frac{1}{1-x}=1 + x + x^2 + x^3 + \cdots$ as long as $|x|<1$. So, am I right in saying that I can do the expansion $(1)$ as long as $|x|<\pi$? Because for $x=\pi$ we have: $$\frac{1}{1-\frac{\pi^2}{1^2\pi^2}} = \frac{1}{1-1}$$
And if $|x|<\pi$ the other terms like: $$\frac{1}{1-\frac{\pi^2}{2^2\pi^2}}$$
Can be expanded by $(1)$ too. So: $$\cot x = \frac{1}{x} - \sum_{n=1}^\infty \left[\frac{2x}{n^2\pi^2} \left(1 + {\left(\frac{x^2}{n^2\pi^2}\right)} + \left(\frac{x^2}{n^2\pi^2}\right)^2 + \left(\frac{x^2}{n^2\pi^2}\right)^3 + \cdots \right)\right]\tag{$|x|<\pi$}$$
$$x \cot x = 1 - 2\sum_{n=1}^\infty \left[\frac{x^2}{n^2\pi^2} + \frac{x^4}{n^4\pi^4} + \frac{x^6}{n^6\pi^6} + \frac{x^8}{n^8\pi^8} + \cdots\right]$$ And finally the famous: 
$$x \cot x = 1 - 2\sum_{n=1}^{\infty} \left[\zeta(2n)\frac{x^{2n}}{\pi^{2n}}\right]\tag{$|x|<\pi$}$$ Am I right with the boundaries for $x$?","['sequences-and-series', 'calculus', 'riemann-zeta']"
891317,Area of a circle sector,"I have been given the following proportional relationship to derive the area of a circle's sector: $\large\frac{\text{ Area of the sector}}{\text{Area of the circle}}=\frac{\text{arc length}}{\text{circumference of the circle}}$ From what I understand you're making equal the ratio of areas to the ratio of lengths. I know how to derive the area of a sector formula from this, that isn't my question. My question is why does this ratio hold in the first place? If we were to describe the ratio of lengths and areas in general terms we would write: $\large \frac{A_1}{A_2}=\left(\frac{l_1}{l_2}\right)^2$, where $A_1$ and $A_2$ are areas, and $l_1$ and $l_2$ are lengths. So with this in mind why isn't the $\frac{\text{s}}{\text{circumference of the circle}}$ side of the equation that consists of length, squared? Why isn't the expression my textbook gave: $\large\frac{\text{Area of the sector}}{\text{Area of the circle}}=\left(\frac{\text{arc length}}{\text{circumference of the circle}}\right)^2$ ?","['algebra-precalculus', 'circles', 'area']"
891319,Construction of an equilateral triangle from two equilateral triangles with a shared vertex,"Problem Given that $\triangle ABC$ and $\triangle CDE$ are both equilateral triangles. Connect $AE$, $BE$ to get segments, take the midpoint of $BE$ as $O$, connect $AO$ and extend $AO$ to $F$ where $|BF|=|AE|$. How to prove that $\triangle BDF$ is a equilateral triangle. Attempt I've noticed that $\triangle BCD \cong \triangle ACE$ so that $|AE|=|BD|$, but I was stuck when proving $\triangle AOE \cong \triangle FOB$. Even though I assume that $ABFE$ is a parallelogram, I can neither prove one of three angles of $\triangle BDF$ is 60 degree nor prove $|DB|=|DF|$ through proving $\triangle DEF \cong \triangle DCB$ (which I think is right.) Could anybody give me a hand?","['geometry', 'triangles', 'proof-writing', 'geometric-transformation']"
891334,Is the U factor in LU decomposition for rectangular matrices always in row echelon form?,"I have come across the following rectangular 5 x 10 matrix and carried out a LU decomposition of it, in the form PA = LU. The following matrices were obtained by function scipy.linalg.lu from module scipy to Python language. At first I thought was a computational issue, but after a contributor obtained the same result in both matlab and R, I decided to post it here (See: https://stackoverflow.com/questions/25186560/is-the-upper-triangular-matrix-in-function-scipy-linalg-lu-always-in-row-echelon ) \begin{equation} 
    A = \begin{bmatrix}
        1 & 1 & 1 & 1 & 0 & 1 & 1 & 1 & 1 & 0 \\
        1 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 1 \\
        1 & 1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 1 \\
        1 & 1 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 \end{bmatrix}
\end{equation} \begin{equation}
    U = \begin{bmatrix}
        1 &  1 &  1 &  1 &  0 &  1 &  1 &  1 &  1 & 0 \\
        0 &  1 &  0 &  1 &  1 &  0 &  1 &  0 &  0 &  1 \\
        0 &  0 & -1 & -1 &  0 &  0 &  0 & -1 & -1 &  0 \\
        0 &  0 &  0 &  0 &  1 & -1 &  0 &  0 &  1 &  1 \\
        0 &  0 &  0 &  0 &  1 &  0 &  0 &  1 &  1 &  1
      \end{bmatrix}
\end{equation} Notice that U is upper triangular, though it is not in row echelon form. Element U[5,5] = 1, but it should be zero, since the pivot for row 4 is immediately above it. According to Strang (1988, p.72), the U factor of a LU decomposition of a rectangular matrix should be in row echelon form, with the following characteristics: ""(i) The nonzero rows come first - otherwise there would have been row exchanges - and pivots are the first nonzero entries in those rows. (ii) Below each pivot is a column of zeros, obtained by elimination. (iii) Each pivot lies to the right of the pivot in the row above. This produces the staircase pattern."" STRANG, G. Linear Algebra and its applications. 3rd Ed., Thomson, 1988. The L factor and permutation matrix P are below. Notice in P that Gaussian elimination swapped rows 2 and 4. \begin{equation}
    L = \begin{bmatrix}
         1 &  0 &  0 &  0 &  0 \\ 
         0 &  1 &  0 &  0 &  0 \\
         1 &  0 &  1 &  0 &  0 \\
         1 &  0 &  1 &  1 &  0 \\
         1 &  0 &  1 &  0 &  1
    \end{bmatrix}
\end{equation} \begin{equation}
    P = \begin{bmatrix}
         1 &  0 &  0 &  0 &  0 \\
         0 &  0 &  0 &  1 &  0 \\
         0 &  0 &  1 &  0 &  0 \\
         0 &  1 &  0 &  0 &  0 \\
         0 &  0 &  0 &  0 &  1 \\
    \end{bmatrix}
\end{equation} Say one tries to cure the problem by cancelling out element U[5,5] = 1, by subtracting row 5 from row 4, and finally producing the row echelon form. L will not be modified, since L[5,5] will remain equals 1, and $PA \neq LU$. I suspect that Gaussian elimination does not always produce the row echelon form.","['matrix-decomposition', 'linear-algebra', 'gaussian-elimination']"
891437,Pack rectangular objects of different sizes in a fixed size rectangle,"If this has been asked before, please help me find it, I have scoured Math.stackexchange and have found quite similar questions but not exactly what I am looking for. I have a rectangular space. I also have a number of rectangle objects. I want to find an algorithm that will try to fit all the objects in the rectangle and if this is not possible I want to know that so that I can show an error message. This is for a computer program that I am working with to place images on a sheet of paper so that I can print them. The idea is to waste as little paper as possible. Edit: Found this one which was a very interesting read: http://cgi.csc.liv.ac.uk/~epa/surveyhtml.html Makes me realise that there really is not a simple answer  to this problem","['geometry', 'algorithms', 'packing-problem']"
891459,How prove $ \; |f(1)|\le 2004\;$ if $\sqrt {x(1 - x)}\; \Big|f(x)\Big|\le 334$ for $f(x) = Ax^2+ Bx + C $,"Let $ \; A,B, C\in {\mathbb R} ,\;$ and  $ \; f(x) = Ax^2+ Bx + C$ and $ \sqrt {x(1 - x)} \left|f(x)\right|\le 334,\;\forall x\in [0,1]\;$. How prove  $ \; \left|f(1)\right|\le 2004\;$ ?","['approximation-theory', 'inequality', 'real-analysis', 'polynomials']"
891474,A math line interpretation,"From the text of the question posed here: ""How many whole numbers less than 2010 have exactly three factors?"" this statement is made: If there is no fourth factor, then that third factor must be the
  square root of the number. Furthermore, that third factor must be a
  prime, or there would be more factors. I don't understand this. Can you explain please.",['algebra-precalculus']
891520,"How do you derive the continuous analog of the discrete sequence $1, 2, 2, 3, 3, 3, 4, 4, 4, 4, ...$?","I was wondering what the rate of growth of the sequence $$1, 2, 2, 3, 3, 3, 4, 4, 4, 4, ...$$ was, and found the related question, Formula for the $n$th term of $1, 2, 2, 3, 3, 3, 4, 4 ,4, 4, 5, ...$ , in which one of the answers given is $$a_n = \operatorname{round}{\sqrt {2n}}$$ so the ""continuous analog"" (not sure if there's a better term) is $\sqrt{2n}$, whose rate of growth turns out to be its reciprocal, $\sqrt{2n}^{-1}$. But there's no explanation in the aforementioned answer. What are the steps behind going from a discrete sequence to the function that approximates it? Edit By trial-and-error, I would have eventually figured it out—even easier if I used hindsight (knowing that the rate of growth is $\sqrt{}$). But how would we characterize a sequence's growth to begin with, to even come up with a guess whose growth matches?","['sequences-and-series', 'discrete-mathematics']"
891543,"Text defining length, area and volume","I am looking for a geometry textbook that axiomatises concepts such as length, area and volume of objects in Euclidean space; for example, the surface area of a $2$-sphere in $3$-space. Such a text would then define length, area and volume, showing that the definitions satisfy the axioms, perhaps uniquely. It may even give different definitions that satisfy some common set of axioms. Is there such a book?","['geometry', 'book-recommendation', 'reference-request']"
891553,Entire function with zeros of even multiplicity is the square of another entire function,"Let $f: \mathbb{C} \rightarrow \mathbb{C}$ be an entire function such that the multiplicity of each of its zeros is even. Must there exist an entire $g$ such that $f(z) = g(z)^{2}$ ? Progress I thought about  using the Weierstrass Factorization Theorem, but I can't seem to get that to work. In the Weierstrass factorization theorem of $f$ we have an infinite product $\prod_{k = 1}^{\infty}(1 - z/b_{k})^{p_{k}}e^{R_{k}(z)}$ where $p_{k}$ is even, $\{b_{k}\}$ are the zeros of $f$ listed without multiplicity and $R_{k}$ is a polynomial. Then how do I know that $\prod_{k = 1}^{\infty}(1 - z/b_{k})^{p_{k}/2}e^{R_{k}(z)/2}$ is entire?","['factoring', 'roots', 'complex-analysis']"
891564,Proving that the intersection of a Sylow p-group with a normal subgroup is also a Sylow p-group,"An exercise from Dummit and Foote pg. $101$ ex. $9$ asks to show
the following: Let $G$ be a group of order $p^{a}n$ where $p$ does not divide $n$ and
  let $N\unlhd G$ so that $|N|=p^{b}m$ where $p$ does not divide $m$ and $P\leq G$ is of order $p^a$ is a Sylow p-group. Prove that $|P\cap N|=p^{b}$. I have seen other posts, but I found only hints or solutions that
uses Sylow theorms (which have yet to be proven in the text). I tried to use the second isomorphism theorem and I drew the subgroups
lattice, I have also used the fact that $|N\cap P|=p^{r}$ for some
$r$ (using Lagrange) but since I don't know what is $|PN|$ I didn't
manage to find $r$. Can someone please guide me further ?","['abstract-algebra', 'normal-subgroups', 'sylow-theory', 'finite-groups', 'group-theory']"
891570,Boundary connected sum of manifolds,"I have two related questions about the boundary connected sum of manifolds with boundaries. Let $T=S^1 \times S^1$ be a torus and let $X=T \times [0, 1]$ be the cylinder over the torus. Let $X'$ be a copy of the cylinder over the torus. I call the boundary surface $T\times 0$ the inner torus and call $T\times 1$ the outer torus. We construct a new manifold from $X$ and $X'$ using the boundary connected sum as follows. First, we apply the boundary connected sum to the outer tori of $X$ and $X'$. Namely, we identify a disk in the outer torus of $X$ with a disk in the outer torus of $X'$ via an orientation reversing homeomorphism. Let us denote by $Y$ be the resulting manifold. The manifold $Y$ contains the copies of the inner boundaries of $X$ and $X'$. Next, we apply the boundary connected sum to the those copies of inner boundaries in $Y$. We call the resulting manifold $Z$ The question is;
Is the manifold $Z$ homeomorphic to the cylinder over a 2-torus (genus 2 surface)? By construction the boundaries are tori. But I am not sure what this manifold is. Also, if this is not the cylinder over a torus, is there any similar connected sum operation that produce the cylinder over a torus?","['general-topology', 'manifolds', 'algebraic-topology', 'differential-topology']"
891573,Show that $Z\times Z$ is not cyclic... [duplicate],"This question already has answers here : $\mathbb{Z} \times \mathbb{Z}$ is cyclic. (3 answers) Closed 9 years ago . The full problem is as stated in the title. I am here to check if this is a valid proof. I thought it would be easiest using Linear Algebra. Recall that an infinite cyclic group is isomorphic to $\mathbb{Z}$. We wish to show that we do not have an isomorphism between $\mathbb{ZxZ\;and\;Z}$. Note that $\mathbb{ZxZ}$ is an infinite group (under addition of course). Now, in order for there to even be potential for an isomorphism, two spaces must have equal dimension. Since the $\mathbb{dim(\mathbb{ZxZ})}=2>\mathbb{dim(\mathbb{Z})}=1$, we know that $\nexists$ an isomorphism between our spaces. Hence, $\mathbb{ZxZ}$ is not a cyclic group. My question (besides a validity check): was there a better way to prove this? I just found this to be the easiest way. EDIT Totally wrong with this one. Back to the cutting board.","['cyclic-groups', 'abstract-algebra', 'linear-algebra', 'proof-verification', 'group-theory']"
891575,"3 Ants going at different speeds, when they will be at the same place Motion Problem","The circumference of a circle has length 90 centimeters, Three points on the circle divide the circle into three equal lengths. Three ants A, B, and C start to crawl clockwise on the circle, with starting from one of the three points. Initially A is ahead of B and B is ahead of C. Ant A crawls 3 centimeters per second, ant V 5 centimeters, and and C 10 centimeters. How long does it take for the three ants to arrive at the same spot for the first time? I tried making a list and writing down the numbers, but they seem to never be the same. I know the distance formula is d=rt , but I don't know how to use it to solve this problem. Any help? Thanks!",['algebra-precalculus']
891586,Fubini's theorem applied to heaviside step functions,"First of all, I should probably mention that I am a physicist, not a mathematician so I sincerely apologize for any lack of rigour in my explanation of my problem. Recently, I have been trying to calculate (simple) 2d Fourier transforms of time-ordered Matsubara Green's functions, but I have been having some problems with it. I can't seem to determine whether or not the order of integration matters for a double integral like the following $$
\int_{0}^{\beta} \int_{0}^{\beta} e^{i \omega_1 \tau_1}e^{i \omega_2 \tau_2} \theta(\tau_1-\tau_2) e^{g (\tau_1-\tau_2)} d\tau_1 d\tau_2 \quad (1)
$$ By my calculation (and double checking with mathematica), evaluating the above double integral iteratively as: $$
\int_{0}^{\beta} \left(\int_{0}^{\beta} e^{i \omega_1 \tau_1}e^{i \omega_2 \tau_2} \theta(\tau_1-\tau_2) e^{g (\tau_1-\tau_2)} d\tau_1\right) d\tau_2 \quad (2)
$$ gives $$
\frac{e^{i \beta  \omega _1} \left(e^{\beta  g}-e^{i \beta  \omega _2}\right)}{\left(g+i \omega _1\right) \left(g-i \omega
   _2\right)}+\frac{-1+e^{i \beta  \left(\omega _1+\omega _2\right)}}{\left(\omega _1+\omega _2\right) \left(\omega _1-i g\right)} \quad (3)
$$ whereas evaluating iteratively instead as $$
\int_{0}^{\beta} \left(\int_{0}^{\beta} e^{i \omega_1 \tau_1}e^{i \omega_2 \tau_2} \theta(\tau_1-\tau_2) e^{g (\tau_1-\tau_2)} d\tau_2\right) d\tau_1 \quad (4)
$$ gives $$
\frac{-1+e^{\beta  (g+i \omega_1)}}{(g+i \omega_1) (g-i \omega_2)}-\frac{-1+e^{i \beta  (\omega_1+\omega_2)}}{(\omega_2+i g) (\omega_1+\omega_2)} \quad (5)
$$ Such a discrepancy between results does not seem to occur when the limits of each integral is $(-\infty,\infty)$ (such a problem has been addressed in previous posts such as this one ). Furthermore, I even tried the usual variable substitution approach where I defined the following new set of variables $$
\tau = \tau_1-\tau_2, \qquad \tilde{\tau} = \tau_2 \\
\tilde{\tau} \epsilon [0,\beta], \qquad \tau \epsilon [-\tilde{\tau}, \beta-\tilde{\tau}]
$$ And this gives me the same result as (3). So I'm not sure whether I am making a mistake or that Fubini's theorem does not apply when dealing with Heaviside theta functions. But if the order of integration does matter, then which is the correct way of calculating these integrals? Surely this is crucial when calculating Matusbara Green's functions in frequency space. Any advice would be greatly appreciated!","['calculus', 'real-analysis', 'analysis']"
891598,Evaluate Left And Right Limits Of $f(x)=\frac{x}{\sqrt{1-\cos2x}}$ At $0$,Evaluate Left And Right Limits Of $f(x)=\frac{x}{\sqrt{1-\cos2x}}$ At $0$ The graph of $f(x)=\frac{x}{\sqrt{1-\cos2x}}$ appears to have a jump discontinuity at $0$ and I want to calculate the left and right limits of $f(x)$ to show there is a discontinuity at $0$. I can't figure out how to manipulate the function in order to give different left and right limits. Here's one of my attempts at trying to manipulate the funtion in to something more familiar to me: $\lim_{x \to 0}\frac{x}{\sqrt{1-\cos2x}}$ (divide numerator and denominator by $(2x)^2)$ $ =\lim_{x \to 0}\frac{\frac{x}{4x^2}}{\sqrt{\frac{-(\cos2x-1)}{2x}}}$ $= \lim_{x \to 0}\frac{\frac{1}{4x}}{\sqrt{\frac{-(\cos2x-1)}{2x}}}$ Now I was thinking that I can apply $\lim_{x \to 0}\frac{\cos(\theta)-1}{\theta} =0$ but it doesn't help me at all. Any ideas?,"['trigonometry', 'calculus', 'limits']"
891604,"Let functions $ f: A \to B$ and $g: B \to A$, suppose that $ g \circ f = i_A$. Prove that if $f$ is onto, then $g$ is one-to-one","For nonempty sets $A$ and $B$ and functions $ f: A \to B$ and $g: B \to A$ , suppose that $ g \circ f = i_A$ . Prove that if $f$ is onto, then $g$ is $1-1$ . Here is what I started, I don't think it's correct. Suppose $f$ is onto 
i.e for each element $b \in B$ there is an element of $a\in A$ , $f(a)=b$ . (definition of onto). Let $y,\ z$ be any two elements of $B$ .Then $y=f(a)$ and $z=f(b)$ for some $a,b \in A$ . If $g(y)=g(z)$ , then $g(f(a)) = g(f(b))$ ,which implies that $a=b$ , so $f(a)=f(b)$ , so $y=z$ . Thus, whenever $g$ maps $y$ and $z$ to the same element in $A$ , $y=z$ , so $g$ is one-to-one. PS: New to proof writing, any constructive criticism is much appreciated.",['functions']
891609,Differential equation which has following solution $y=\frac{1}{1+\exp(ax)}$,"Is there any linear differential equation which has following solution 
$$y=\frac{1}{1+\exp(ax)}$$
$a$ is constant.
something like:
$$ y'' + by' +cy + \alpha = 0$$
where $b$, $\alpha$ and $c$ are constants.
When I take derivative it looks more and more complicated. Update: If not possible, What if the coefficients ($b$ and $c$) can be like:
$$ b = b_0 y, \; c = c_0 y + d_0 $$","['ordinary-differential-equations', 'partial-differential-equations', 'integration', 'derivatives']"
891611,Probability and Expected Value of a guessing game,Let's say I think of a number between one and six. I will tell you to guess the number and tell you when it's wrong until you guess the correct number. What is the expected number of guesses before the correct number?,['probability']
891625,"How to solve this coupled system of ODEs: $x_1'' = x_2 $, $x_2'' = -x_1 $","I have a simple seeming system, described as below : ${x_1}'' =  x_2 $ ${x_2}'' =  -x_1 $ Can some one give me the steps to proceed, so that I can solve this?",['ordinary-differential-equations']
891626,How does $v\Phi^1=\cdots=v\Phi^k=0$ imply $v\in\ker d\Phi_p$?,"I'm confused about an immediate corollary in John Lee's Smooth Manifolds . Proposition 5.38 says Suppose $M$ is a smooth manifold and $S\subset M$ is an embedded submanifold. If $\Phi\colon U\to N$ is any local defining map for $S$, then $T_pS=\ker d\Phi_p\colon T_pM\to T_{\Phi(p)}N$ for each $p\in S\cap U$. It says an immediate corollary is that if $S\subseteq M$ is a level set of a smooth submersion $\Phi=(\Phi^1,\dots,\Phi^k)\colon M\to\mathbb{R}^k$, then $v\in T_pM$ is tangent to $S$ iff $v\Phi^1=\cdots=v\Phi^k=0$. Why does $v\Phi^1=\cdots=v\Phi^k=0$ imply $v\in T_pS$? By the proposition, how does  $v\Phi^1=\cdots=v\Phi^k=0$ imply $v\in\ker d\Phi_p$? I don't see how to relate this to the individual components though to use $v\Phi^1=\cdots=v\Phi^k=0$.","['differential-topology', 'differential-geometry']"
891645,Minimal and characteristic polynomials on tensor product spaces,"Given two finite-dimensional vector spaces $V$ and $W$ over a common field $k$ as well as $k$-linear transformations $\varphi \colon V \to V$ and $\psi \colon W \to W$, what can be said in general about the minimal and characteristic polynomials of the tensor product of the linear transformations? That is, can one describe the minimal and characteristic polynomials of $\varphi \otimes \psi \colon V \otimes W \to V \otimes W$ in terms of the minimal and characteristic polynomials of $\varphi$ and $\psi$? Moreover, what do we glean in addition by letting $\psi$ be the identity matrix? (Edit 1: the case where $\psi$ is the identity matrix for both the characteristic and minimal polynomials is explained by @darij grinberg in the comments.) Edit 2: @darig grinbeg's comments outline that the characteristic polynomial of $\varphi \otimes \psi$ is indeed determined by the characteristic polynomials of $\varphi$ and $\psi$, though we don't yet have a `nice' relation. Nothing has been said about the minimal polynomial.","['tensor-products', 'linear-algebra', 'abstract-algebra']"
891658,Binomial theorem combinatorics derivation,"We can split any term $(x+y)^n$ into a choice tree with $2^n$ path choices.  Also, we can represent each factor in terms of $x^ky^{n-k}$ It is logical to deduce we can express this with summation notation: $$\sum_{k=0}^{n}{cx^ky^{n-k}}$$ where c is the coefficient of the term.  Everything makes sense to me, except how we can find c.  Apparently, we can define c as $$\binom{n}{k}$$ But this is confusing for me, and the only definition I can find is a very intense mathematical one: The coefficient of $x^ky^{n-k}$ for a particular k is just the number of ways to choose k factors of y from the n factors of (x+y), with factors of x coming from the remaining (n−k) factors. The number of ways to choose k objects from a collection of n objects (without replacement, order not important) is just $\binom{n}{k}$. I understand everything logically, and I've been trying to figure this out all day.  I'm not new to combinatorics as I've taken a few statistics classes.  But these were the basics, such as the number of ways to chose 2 fruits from a set of 3 fruits (say an apple, orange, banana). Firstly, there are n+1 factors, and $2^n$ paths.  So I just don't get the logic behind all of this, even though it does work.","['statistics', 'combinatorics']"
891687,How do you quickly find the eigenvalues of this matrix?,"I have a final exam tomorrow, am sure a 3x3 eigen value problem like the one below is there.
But I find it very hard to find eigen values without zeros in the matrix Show me how you do it quickly so that I can apply it tomorrow;
thanks","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
891726,Uniform convergence of $xe^{-nx}$,"Does the sequence $(f_n)$ on $[0, \infty)$ given by $ f_n(x) =
> xe^{-nx} $ converge uniformly? This is from Bartle's Elements of Real Analysis . I've already proven that the sequence is convergent (not uniformly) to the zero fucntion, $f$. But I'm guessing the answer to this question is ""No"" because $x$ is present in every approximation I come up with hence the choice of $m \in \Bbb N$ such that $\forall \epsilon \gt 0(n \ge m \implies |f_n(x) - f(x)| \lt \epsilon)$ depends on $x$. But I wish to prove this by presenting a subsequence $(f_k)$ and a corresponding subsequence $(x_k) \subseteq [0, \infty)$ such that $ |f_k(x) - f(x)| $ is not less than some positive number $\epsilon_{\circ}$. Any hints would be appreciated. I am not allowed to use the series expansions of $e^x$. Just the definition $e^x = \lim \left({1 + \frac x n}\right)^n$ and maybe the logarithm-exponential relationships. PS: The next exercise on the list is on the uniform convergence of $(x^2e^{-nx})$","['self-learning', 'sequences-and-series', 'real-analysis']"
891742,General solution of Differential equation,"What is solution of the differential equation: \begin{aligned}x({yy'' + y'^2}) + yy' = 0\end{aligned} What i am confused about it is the treatment of
$$\left(\dfrac{dy}{dx}\right)^2$$
for solving this question. The given answer is \begin{aligned}ax^2 + by^2 = C\end{aligned}","['ordinary-differential-equations', 'calculus']"
891792,Notational issues on differential equations,"I am studying dynamical systems and I have some trouble in understanding the notation used for differential equations. For example when I read $$\overset{..}{x}=F(x),$$ how should I interpret it? Is it asking to find a function $x$ (defined on an open set) such that $x''(t)=F(x(t))$ for all $t$? If so, why don't they write $x''=F\circ x$, or $\overset{..}x =F\circ x$? Then I see: Let's call $y$ the velocity, i.e., the function $\overset.x$. Suppose that exists a function $V$ such that $F=\dfrac{-dV}{dx}$. Then the quantity $E(x,y)=\frac12y^2+V(x)$ is constant when $t$ changes. Does it mean that the function $t\mapsto E(x(t),y(t))=\frac12y(t)^2+V(x(t))$ is constant? What does $\frac{-dV}{dx}$ mean?  Simply $V'$?  In the definition of derivative of a function I have never seen something like ""derivative with respect to x"" or ""derivative with respect to t"".
My guess is that when they write $\frac{dV}{dx}$ they mean the derivative of the function that maps every point to its potential (in this case simply $V'$); and when they write $\frac{dV}{dt}$ they mean the derivative of the function that maps the time to the potential at that time (which in this case is the derivative of another function, the function $V\circ x$. So it is $(V\circ x)'=(V'\circ x)\cdot x'$).  Is it all right?","['notation', 'ordinary-differential-equations', 'dynamical-systems']"
891798,"Is $R=\left \{ (a,a),(a,b),(b,a),(b,b),(c,c),(c,d),(d,c),(d,d) \right \}$ an equivalence relation on $X$?","Let $X= \left \{ a,b,c,d \right \}$ and $R=\left \{ (a,a),(a,b),(b,a),((b,b),(c,c),(c,d),(d,c),(d,d) \right \}$. I want to show that $R$ is an equivalence relation on $X$. My work: $R$ is reflexive: If $a\in X$, $aRa$ since $(a,a) \in R$. $R$ is symmetric: If $a,b \in X$, then $(a,b) \in R \Leftrightarrow (b,a) \in R$. $R$ is not transitive: If $a,b,c \in X$, then $aRb$ and $bRc$ implies $aRc$. But $(b,c)$ is not an element of $R$ and $(a,c)$ is not an element of $R$. So $R$ is not an equivalence relation. But I am supposed to show that $R$ is an equivalence relation on $X$. For transitivity should $a\neq b\neq c$?","['equivalence-relations', 'discrete-mathematics']"
891803,How to test whether a set of four points can form a parallelogram,"Given four points $(x_1,y_1)$,$(x_2,y_2)$,$(x_3,y_3)$,$(x_4,y_4)$. How can we efficiently test them to make sure whether they are vertices of a parallelogram? I think evaluating and comparing the distance between two points seems to be inefficient. What do you think? Do you have any better method?",['geometry']
891810,Conditions on Poisson random variables to convergence in probability,"Let $X_1,X_2,...$ denote iid random variables such that $X_j$ has a Poisson distribution with mean $\lambda t_j$ where $\lambda$ > 0 and $t_1, t_2,...$are known positive constants. a)Find conditions on $t_1, t_2,...$so that $\Large Y_n = \frac{\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j - \lambda  }{\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)}$ converges in distribution to a standard normal variable. b) Suppose that, for each $j = 1,...,t_j$ lies in the interval $(a,b)$ where $0 < a < b < \infty$. Does it follow that $Y_n$ converges in distribution to a standard normal variable? c) Suppose that $t_j$ = j, j = 1,... Does it follow that $Y_n$ converges in distribution to a standard normal variable? Attempt at a): Since the characteristic function of a Poisson distribution with mean $\lambda $ is given by: $\hspace{15mm} \exp (\lambda[\exp(it)-1])$, we then have the following characteristic function of $Y_n$: $\hspace{15mm}$$\phi_n(t) = \exp ((\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2\lambda[\exp(it/\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j))-(\operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j))^2 - \operatorname{Var}(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)it]$ By Lemma 2.1 in Severini's ""Elements of Distribution Theory"": $\exp(it) = \sum\limits_{j=0}^n \frac{(it)^j}{j!} + R_n(t)$ where $\hspace{15mm}|R_n(t)|\leq \min(|t|^{n+1}/(n+1)!, 2|t|^n /n!$ Hence, $\hspace{15mm}exp(it/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)) = 1 + it/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j) - 1/2t^2/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2 + R_2(t)$ where $\hspace{15mm} |R_2(t)|\leq 1/6t^3/Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^{2/3}$. It follows that $\hspace{15mm}\phi_n(t) = exp(-t^2/2 + Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)^2 R_2(t)$ and that $\hspace{15mm} \lim_{ Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)\to \infty}$ $Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)R_2(t) = 0$, $-\infty < t < \infty$. Hence, $\hspace{15mm}\lim_{ Var(\sum\limits_{j=1}^n X_j /\sum\limits_{j=1}^n t_j)\to \infty}$$\phi_n(t) = exp(-t^2/2), -\infty < t < \infty$,the characteristic function of a standard normal variable. However, I can not identify the constraints on $t_1,t_2,....$ Any help would be much appreciated!","['random-variables', 'probability-theory', 'central-limit-theorem', 'probability', 'characteristic-functions']"
891812,Integration of the cardinal sine,"It is said that the integral of the cardinal sine is $1$ . How do I integrate the cardinal sine? $$ \int_{-\infty}^{\infty} \frac{\sin(a)}{a} \, {\rm d} a $$","['improper-integrals', 'calculus', 'integration']"
891823,2 of 3 dice are selected randomly and thrown. What is the probability that one of the dice shows 6,"1 red die with faces labelled 1, 2, 3, 4, 5, 6. 2 green dice labelled 0, 0, 1, 1, 2, 2. Answer: 1/9 Please can you show me how to get the answer. I'm confused about joining the events of choosing 2 of 3 dice vs. getting the probability that one of the dice chosen will get a 6 when rolled. Note: There is an equi-probable chance of getting any of the six sides on a given die.","['probability-theory', 'probability', 'combinatorics']"
891862,"Show that $C^1([0,1])$ is not reflexive","Aim of this exercise is proving that $(C^1([0,1]),\|\cdot\|_{C^1})$ is not reflexive. We know that, if $(f_h)_h\subset C^1([0,1])$ is a sequence that weakly converges to $f\in C^1([0,1])$ (that is $f_h \rightharpoonup f$),then $(f_h)_h$ and $(f'_h)_h$ pointwise converge to, respectively, $f$ and $f'$  $(*)$. Now, let $f_h(x)=\frac{x^h}{h}$, for $x\in[0,1]$. From $(*)$ it follows that $f_h(x)$ does not weakly converges in $C^1([0,1])$, because $f'_h=x^{h-1}$ pointwise converges to a discontinuous function. From this we want to conclude that $(C^1([0,1]),\|\cdot\|_{C^1})$ is not reflexive arguing by contraposition. So, suppose that $(C^1([0,1]),\|\cdot\|_{C^1})$ is reflexive. Then the unit closed ball $B$ is sequentially weakly compact. Now, to reach the absurd, I guess I have to use the sequence $(f_h)$ where $f_h=\frac{x^h}{h}$, but $\|f_h\|_{C^1}=1/h+1>1$. So, what I have to do?","['weak-convergence', 'convergence-divergence', 'functional-analysis', 'banach-spaces']"
891894,If diagonalizable matrices commute does it neccesarily mean that they can be simultaneously diagonalized?,"If matrices $M_1$ and $M_2$ can be simultaneously diagonalized, than they commute, which can be easily shown:
\begin{align}
M_1M_2&=P^{-1}D_1PP^{-1}D_2P \\
&=P^{-1}D_1D_2P \\
&=P^{-1}D_2D_1P \\
&=P^{-1}D_2PP^{-1}D_1P \\
&=M_2M_1
\end{align} But is converse also true? If diagonalizable matrices $M_1$,...,$M_n$ all mutually commute, does this mean that they can be simultaneously diagonalized? If so, how to show this? If not, what is the simplest counterexample?","['matrices', 'linear-algebra', 'diagonalization']"
891918,"Limit of differences of truncated series and integrals give Euler-gamma, zeta and logs. Why?","In the MSE-question in a comment to an naswer Michael Hardy brought up the following well known limit- expression for the Euler-gamma
$$  \lim_{n \to \infty} \left(\sum_{k=1}^n \frac 1k\right) - \left(\int_{t=1}^n \frac 1t dt\right) = \gamma \tag 1$$ I've tried some variations, and heuristically I found for small integer $m \gt 1$
$$  \lim_{n \to \infty} (\sum_{k=1}^n \frac 1{k^m}) - (\int_{t=1}^n \frac 1{t^m} dt) = \zeta(m) - \frac 1{m-1} \tag 2$$ With more generalization to real $m$ it seems by Pari/GP that eq (1) can be seen as a limit for $m \to 1$ and the Euler-$\gamma$ can be seen as the result for the Stieltjes-power-series representation for $\zeta(1+x)$ whith the $\frac 1{1-(1+x)}$-term removed and then evaluated at $x=0$ Q1: Is there any intuitive explanation for this (or, for instance, a graphical demonstration)? Another generalization gave heuristically also more funny hypotheses:
$$ \tag 3$$
$$ \small \begin{eqnarray}  
\lim_{n \to \infty} (\sum_{k=2}^n \frac 1{k(k-1)}) &-& (\int_{t=2}^n \frac 1{t(t-1)} dt) &=& \frac 1{1!} \cdot(\frac 11 - 1\cdot \log(2)) \\
\lim_{n \to \infty} (\sum_{k=3}^n \frac 1{k(k-1)(k-2)}) &-& (\int_{t=3}^n \frac 1{t(t-1)(t-2)} dt) &=& \frac 1{2!} \cdot(\frac 12 - 2\cdot \log(2) + 1\cdot \log(3) ) \\
\lim_{n \to \infty} (\sum_{k=4}^n \frac 1{k...(k-3)}) &-& (\int_{t=4}^n \frac 1{t...(t-3)} dt) &=& \frac 1{3!} \cdot(\frac 13 - 3\cdot \log(2) + 3\cdot \log(3)- 1\cdot \log(4) ) \\
 \end{eqnarray} $$
where the coefficients in the rhs are the binomial-coefficients and I think the scheme is obvious enough for continuation ad libitum. Again it might be possible to express this with more limits: we could possibly write, for instance the rhs in the third row as
$$ \lim_{h\to 0} \frac 1{3!} \cdot(- \small \binom{3}{-1+h}  \cdot \log(0+h) +1 \cdot \log(1) - 3\cdot \log(2) + 3\cdot \log(3)- 1\cdot \log(4) ) \tag 4$$ Q2: Is that (3) true and how to prove (if is it not too complicated...)? And is (4) somehow meaningful?","['sequences-and-series', 'calculus', 'riemann-zeta', 'number-theory', 'definite-integrals']"
891921,Geometric/visual interpretation of transitivity for equivalence relations on $\mathbb{R}$,"If we graph equivalence relations on $\mathbb{R}$ on the plane $\mathbb{R} \times \mathbb{R}$, the properties of reflexivity and symmetry give rise to certain geometric properties--i.e. reflexivity means the line $y = x$ must be included, and symmetry means the graph must be symmetric about this line. However, for transitivity, it being defined in terms of three different points, it's harder for me to pin down a visual interpretation in this regard. In some sense, the structures formed seem to be ""square-like"" (for example, the graph of the smallest equivalence relation containing the set
$$S = \{(x,y)\,|\,(y = x + 1) \wedge (0 < x < 2)\},$$
this example being from Ch. 1, Section 3, Exercise 5 of Munkres' Topology , for reference). In short, is the ""square-like"" interpretation true? How can this be formalized? If it's not true, what is a good way to visually interpret transitivity as a property of relations on $\mathbb{R}$ by graphing them in the plane, if such a way even exists?","['relations', 'geometry', 'equivalence-relations']"
891924,What is the connection between $\rho$ and $\sigma$ if $\rho\rho^T=\sigma\sigma^T$?,"I want to prove that there exists a Borel function $R(\rho,\sigma)$ with values in $M^{d\times d}$ defined on $D=\lbrace(\rho,\sigma)\in M^{d\times d}\times M^{d\times d}\,: \rho\rho^T=\sigma\sigma^T\rbrace$ such that $\sigma=\rho R(\rho,\sigma)$ and $RR^T=I$. My idea is: Diagonalize $\rho\rho^T=\sigma\sigma^T=QDQ^T$ where Q is an orthogonal matrix. It's obvious that $\sigma=UQ\sqrt{D}$ with U orthogonal matrix satisfies the request but is this the only possibility? I would appreciate any possible help. Thank you in advance.","['matrices', 'linear-algebra', 'numerical-methods']"
891938,Fundamental group of 7-gon with labelling scheme $abaaab^{-1}a^{-1}$,"I want to calculate the fundamental group of of a $7$-gon with labelling scheme $abaaab^{-1}a^{-1}$. I will call the quotient space $X$ with reference point $x_0$. This is what I tried: If you have the book topology of Munkres, Theorem 74.2 says that this fundamental group should be isomorphic to the quotient of the free group on the generators $a$ and $b$ by the least normal subgroup containing the element $aba^3b^{-1}a^{-1}$. So if $G_1=\langle a\rangle$ and $G_2=\langle b\rangle$ and $N$ is this least normal subgroup containing $aba^3b^{-1}a^{-1}$, then $\pi_1(X,x_0)=(G_1 *G_2)/N$. Now theorem 68.7 of the same book says that if you have two groups $H_1$ and $H_1$ and two normal subgroups $M_1\subset H_1$ and $M_2\subset H_2$ and suppose $M$ is the least normal subgroup of $H_1*H_2$ containing both $M_1$ and $M_2$ then we have the isomorphism $(H_1*H_2)/M\cong H_1/M_1*H_2/M_2$. In my case, I have a normal subgroup $N$ of $G_1*G_2$ which contains the element $aba^3b^{-1}a^{-1}$. I see that this element is a conjugate: $(ab)a^3(ab)^{-1}$. So $a^3\in N$ and we must have that $N_1$ is the least normal subgroup of $G_1$ containing the element $a^3$, that is $N_1=\langle a^3\rangle$. I cannot find a normal subgroup $N_2$ of $G_2$ which is contained in $N$ except for the trivial group. So I think that $\pi_1(X,x_0)\cong \mathbb{Z}/3\mathbb{Z}*\mathbb{Z}$. I am not sure whether this is correct. In particular, I am not sure whether $N_2$ is the trivial normal subgroup of $G_2$. Can you help me at this point? Thanks.","['general-topology', 'algebraic-topology', 'group-theory']"
891959,Does the rank of homology and cohomology groups always coincide?,"Let $(C_i)_{i \in \mathbb{Z}}$ be a chain complex of free abelian groups. Does the rank of the homology and cohomology groups of $(C_i)_{i \in \mathbb{Z}}$ always coincide, i.e. is 
$$\operatorname{rank}(H_i(C_*))=\operatorname{rank}(H^i(C_*))$$
for every integer i? If every homology group $H_i(C_*)$ is finitely generated, we can use a combination of the universal coefficients theorem and the fundamental theorem for finitely generated abelian groups to show this fact. 
But is it also true in the case where the homology groups are not finitely generated?","['homology-cohomology', 'homological-algebra', 'algebraic-topology', 'abstract-algebra']"
891960,If a function $f$ is decreasing on its domain then would its inverse be increasing or decreasing?,"I have a question concerned the inverse of a function $f$ and the sign of its derivative. If we are given a function $f$ that is decreasing on its domain, would its inverse $f^{-1}$ be increasing or decreasing. I thought that this would be decreasing: Because the formula for the derivative of the inverse is:
$$\left(f^{-1}(x)\right)' = \frac{1}{f'\left(f^{-1}(x)\right)}$$ Since $f$ is decreasing, $f'< 0$, so $\left(f^{-1}(x)\right)' < 0$, so the inverse $f^{-1}$ would be decreasing. However, I find that I am incorrect. why? EDIT This is the exact question True or false: If $f$ is decreasing on its domain, then $f^{-1}$ is decreasing on its domain The answer was false and it put ""$f^{-1}$ would be increasing.""","['functions', 'inverse', 'calculus', 'real-analysis']"
891974,"Why is $\sum_{n=-\infty}^{\infty}\exp(-(x+n)^2)$ ""almost"" constant?","I did some numerical approximation of $$\sum_{n=-\infty}^\infty \exp(-(x+n)^2)$$ and found that this function is ""almost"" constant ($\approx 1.772$). Why does the sum fluctuate little? Is there a closed form for this sum? Added: since $f(x) = \sum_{n=-\infty}^\infty \exp(-(x+n)^2)$ has period $1$ and is even, can we give an upper bound of $\sup\{ f(x)/f(y) : (x,y)\in [0,0.5]^2\}$?","['fourier-series', 'sequences-and-series']"
891992,Approximating the exponential function,"I have found experimentally something that seems graphically like an approximation of the exponential function. However, it is totally experimental and I have no idea whether it really converges towards the $\exp$. Let : $$f\left(x,h,c\right)=\left(1+\frac{x}{c^h}\right)^{c^h}\text{(A quite understandable approximation for the exponential function)}$$
$$q\left(x,h,c\right)=\sum \limits_{p=0}^h\frac{c^{\frac{p^2+p}{2}}}{\left(\prod\limits _{i=1}^p\left(c^i-1\right)\right)\prod\limits _{i=1}^{h-p}\left(1-c^i\right)}f\left(x,p,c\right)$$
My approximation is : $$\exp(x)=\underset{h,c\rightarrow+\infty}{\lim}q(x,h,c)$$ Desmos shows that it s indeed really close near $1$, and that for low $h,c$ it starts diverging afterwards (but this might be because of computational errors on huge numbers (?) ). Is that a known approximation for the exponential ?
If not, is it an approximation of the exponential at all ? Additional question that sparked from the comments : How can the comportment for low $h,c$ be analyzed ? If you wonder where that formula comes from, I can't give a full explanation (it's really experimental work) but you might be interested by one of my previous questions An expression for $U_{h,0}$ given $U_{n,k}=\frac{c^n}{c^n-1}(U_{n-1,k+1})-\frac{1}{c^n-1}(U_{n-1,k})$ .","['approximation', 'exponential-function', 'sequences-and-series']"
