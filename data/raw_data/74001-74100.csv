question_id,title,body,tags
913871,Deriving exponential distribution from geometric,"Let $\lambda$ be the expected number of events in a unit time interval $[s,s+1]$ (events are independent of each other and of the time interval), and $T$ a continuous random variable that represents the time between two events. If we divide the time interval $[0,1]$ into $n$ intervals of length $\displaystyle \frac{1}{n}$, and set the probability of an event occurring in any interval to be  $\displaystyle \frac{\lambda}{n}$, then $T$ can be approximated by a discrete geometric random variable $X$ which represents the number of time intervals of length $\displaystyle \frac{1}{n}$ between two events. Let $t\in \mathbb{R}$, then $F_T(t)$ can be approximated by $F_X(nt)$ $$
P(T<t) \approx P(X < tn)
$$ Where $P(X<nt)$ is the sum of geometric distributions
\begin{align}
P(X<nt) &= \sum_{k=1}^{\lfloor{t} n\rfloor} P(X=k) 
\\ &= \sum_{k=1}^{\lfloor{t} n\rfloor} \left(1 - \frac{\lambda}{n}\right)^{k-1}\left( \frac{\lambda}{n} \right) 
\\ &= \frac{\lambda}{n} \sum_{i=0}^{\lfloor{t} n\rfloor -1} \left(1 - \frac{\lambda}{n}\right)^i \\ &= \frac{\lambda}{n} \left( \frac{1 - (1 - \frac{\lambda}{n})^{\lfloor{t}n\rfloor }}{\lambda /n} \right) \underset{n \to \infty}{\longrightarrow} 1 - e^{-\lambda t } 
\end{align} But how to justify $$
\lim_{n \to \infty} \left( 1 - \frac{\lambda}{n} \right)^{\lfloor{t}n\rfloor } = e^{-\lambda t}
$$ How can I get rid of the floor function, in a formal way?","['probability-distributions', 'probability', 'random-variables']"
913895,Binomial theorem for matrices,Suppose we have $$(A + I)^n$$ where $A$ is matrix and $I$ is an identity matrix. Does the binomial theorem apply? I know the binomial theorem but not whether it is also applicable to matrices.,"['matrices', 'binomial-theorem']"
913925,Integration against divergence free vector fields,"Let $\chi:\Omega\to \mathbb{R}^n$ be a vector field on a bounded, smooth domain $\Omega \subset \mathbb{R}^n$. Assume that for any divergence free vector field $\eta:\Omega \to \mathbb{R}^n$ we have $
\int_\Omega \eta \cdot \chi =0
$ Does this imply that $\chi = 0$ ?","['multivariable-calculus', 'calculus', 'vector-analysis']"
913932,Is $\exp(-2\sin^2t)$ a characteristic function?,Is $\exp(-2\sin^2t)$ the characteristic function of some random variable?,"['probability-theory', 'characteristic-functions', 'random-variables']"
913934,Process to show that $\sqrt 2+\sqrt[3] 3$ is irrational,"How can I prove that the sum  $\sqrt 2+\sqrt[3] 3$
 is an irrational number ??","['algebra-precalculus', 'irrational-numbers']"
913935,Prove that $BA^{-1} B \not=-B$ if $A + B$ is invertible for $A$ invertible and $B$ non-zero matrix,"Let $A$ and $B$ be $n×n$ real square matrices. Matrix $A$ is an invertible and $B$ is a non-zero matrix. a)Prove that $BA^{-1} B \not=-B$ if $A + B$ is invertible b) Let $B= uv^T$ for $u,v \in \Bbb R^n$. Prove that $BA^{-1}B=-B$ when  $v^TA^{-1}u= -1$ I'm kind of left in the dark with this problem. I tried applying trace and using the determinants (as $\det(A + B) = 0$ ), however I don't know how to proceed,","['matrices', 'linear-algebra', 'inverse']"
913960,Are $1+ω$ and $ω+1$ isomorphic?,"In set theory, $1+ω$ is defined as the ordinal number of ordinal sum of sets $\{a\}$ and ℕ. Also $ω+1$ is defined as the ordinal number of ordinal sum of sets $\Bbb N$ and $\{a\}$. You know what the ordinal sum means: the ordinal sum of well-ordered sets $A$ and $B$ is the set $A \cup B$ ordered as you know. We know that the sets $\{a\} \cup ℕ$ and $ℕ \cup \{a\}$ are equipotent and well-ordered. And also we know by a theorem in set theory, any two equipotent well-ordered set are isomorphic (similar). Doesn't this argument contradict with the fact that in set theory, the ordinal numbers $1+ω$ and $ω+1$ are not equal to each other? Pinter mentioned in his book following theorem and he proved it: ""Theorem Let A and B be well-ordered classes; exactly one of the following three cases must be hold: i) A is isomorphic with B. ii) A is isomorphic with an initial segment of B. iii) B is isomorphic with an initial segment of A."". And he concluded "" well-ordered classes do not differ from one another except in their size"". I remind you the ""isomorphism"" concept is equivalent to ""similar"" concept; and it is a one to one correspondence between two sets and order-preserving.","['ordinals', 'elementary-set-theory', 'order-theory']"
913983,Loss of derivatives,"In many books on pdes the expression ""loss of derivatives"" is used when some estimates on solution are proved.
Can someone clarify to me (maybe with an example) the meaning of this expression?
For instance: $$\Vert e^{tD^\alpha\partial_x}u_0\Vert_{L_t^4L_x^\infty}\leq\Vert D^{\frac{1-\alpha}{4}}u_0\Vert_{L^2}$$ has a lost of $\frac{1-\alpha}{4}$ derivatives. Edit: Here is some more background and instances in which it appears. In the survey article by Ifrim and Tataru on local wellposedness for hyperbolic systems (""A key observation is that, whereas solving the linearized equation would cause a loss of derivatives, solving the paradifferential equation does not in general."") In the Encyclopedia of Math entry on nonlinear PDE (""The 'loss of one derivative' in the inversion of the second-order hyperbolic operator leads to principal obstacles in the study of non-linear hyperbolic equations"") This paper on 2nd order hyperbolic PDE (""...the Cauchy problem for $L$ is well-posed in $H^\infty$ with no loss of derivatives ."") I've heard it generally used to refer to when, in estimating some important quantity (usually an energy) $E$ , the norm $\|{f}\|_{H^{k + 1}}$ appears, when somehow we only have a priori estimates for $\|{f}\|_{H^{k}}$ .","['definition', 'regularity-theory-of-pdes', 'partial-differential-equations', 'analysis']"
913988,Square-free factorization of polynomials over finite fields,"For any $f\in\mathbb{F}_q[X]$, I want to derive an algorithm which computes a factorization $$f=\prod_{i=1}^kf_i^i\tag{1}$$ with square-free polynomials $f_i$. My Ideas: If $f'=0$, we're done ($f\in\mathbb{F}_q$) Otherwise consider $$g_1:=\gcd(f,f')$$ If $g_1=1$ we're done ($f$ is square-free) Otherwise $$f_1:=\frac{f}{g_1}$$ is square-free Now consider $$g_2:=\gcd(g_1,g_1')$$ If $g_2=1$ we're done ($f=f_1g_1$ is a square-free factorization) Otherwise $$f_2:=\frac{g_1}{g_2}$$ is square-free And so on ... This process yields a square-free factorization $$f=f_1\cdots f_{k-1}g_k\tag{2}$$ after $k<\infty$ steps. However, (2) is not the factorization (1) I'm searching for. How can I find the factorization (1) and what's the benefit from the factorization (1) in comparison to factorization (2)? EDIT Elsewhere, I've found an algorithm which exactly does what I've described, but returns $$h_i:=\frac{f_i}{f_{i+1}}\;\;\;\;\;(1\le i<k,f_k:=g_k)$$ and states the $h_i$ would fulfill $$f=\prod_{i=1}^kh_i^i$$ I don't see why this should hold.","['finite-fields', 'computer-algebra-systems', 'abstract-algebra', 'polynomials']"
913995,Is the derivative of a differentiable function continuous a.e.?,"Let $f:[a,b]\rightarrow \mathbb{R}$ be a differentiable function. I know that $f'$ does not need to be continuous on $[a,b]$. However, all counterexamples I know has finite discontinuities. I want to know whether $f'$ is continuius a.e. on $[a,b]$. (Of course, under the Lebesgue measure)",['real-analysis']
914016,"If $f$ has derivative at $1$ and $\lim_{h \to 0} {\frac{f(1+h)}{h} }=1$, then $f'(1)=0=f(1)$","I need to prove that if $f(x)$ has derivative at $x=1$ and if $\lim_{h \to 0} {\frac{f(1+h)}{h} }=1$. then I need to prove that $f'(1)=0$ $f(1)=0$. It's pretty obovious if using arithmetic of limits, but it's impossible here. Any clues or general mindset how to prove it?","['calculus', 'derivatives', 'limits']"
914036,Proof - Inverse of linear function is linear,"This is my first proof related to linear functions.
It refers to the linear-algebra-$\textit{linear}$ (not the calculus-$\textit{linear}$).
Please comment. Theorem The inverse of a linear bijection is linear. Proof Let $X,Y$ be vector spaces over a common field.
Let $f : X \rightarrow Y$ be a linear bijection.
We denote by $f^{-1}$ the inverse of $f$.
It remains to prove that $f^{-1}$ is linear,
i.e. both $\textit{additive}$ and $\textit{homogeneous}$. Additivity Let $y_1, y_2 \in Y$.
We prove that $$f^{-1}(y_1 + y_2) = f^{-1}(y_1) + f^{-1}(y_2).$$
\begin{equation*}
	\begin{split}
		f^{-1}(y_1) + f^{-1}(y_2)
			&=	f^{-1}\Big( f\big( f^{-1}(y_1) + f^{-1}(y_2) \big) \Big) && \quad \text{by bijectivity} \\
			&=	f^{-1}\Big(	f\big( f^{-1}(y_1) \big) +
												f\big( f^{-1}(y_2) \big) \Big) && \quad \text{by linearity of } f \\
			&=	f^{-1}\Big(	y_1 + f\big( f^{-1}(y_2) \big) \Big) && \quad \text{by bijectivity} \\
			&= f^{-1}(y_1 + y_2) && \quad \text{by bijectivity}\phantom{\Big(\Big)} \\
	\end{split}
\end{equation*} Homogeneity Let $y \in Y$ and let $s$ be a scalar.
We prove that $$f^{-1}(sy) = sf^{-1}(y).$$
\begin{equation*}
	\begin{split}
		sf^{-1}(y)
			&= f^{-1}\Big( f\big( sf^{-1}(y) \big) \Big) && \quad \text{by bijectivity} \\
			&= f^{-1}\Big( sf\big( f^{-1}(y) \big) \Big) && \quad \text{by linearity of } f \\
			&= f^{-1}(sy) && \quad \text{by bijectivity}\phantom{\Big(\Big)} \\
	\end{split}
\end{equation*} QED","['functions', 'linear-algebra', 'proof-verification', 'soft-question', 'proof-writing']"
914061,Limit of sequences: $\lim \frac{(2n)!}{(n!)^2} $,"Verify if the sequence $$\frac{(2n)!}{(n!)^2}$$ converges. My attempt: $$\frac{(2n)!}{(n!)^2} = \frac{(2n)(2n-1)...(n+1)}{n.(n-1)...1} \geq \frac{(n+1)^n}{n!}
$$
Maybe it is easier to show that this last sequence diverges. Thanks!","['sequences-and-series', 'real-analysis']"
914072,Finding the limit $\lim_{x\to+\infty}(x-x^2\log(1+1/x))$ in a elementary way,"How to find the limit $$\lim_{x\to+\infty}\left(x-x^2\log\left(1+\frac{1}{x}\right)\right)$$  in a elementary way? 
  I can solve with Taylor expansion, but it is placed in the beginning of my calculus book, so I should only use things like: -Main theorems involving limits, including the limits for $x\to 0$, $\lim\frac{\sin x}{x}$, $\lim\frac{e^x-1}{x}$, $\lim\frac{\log(x+1)}{x}$, $\lim\frac{(x+1)^p-1}{x}$ -$\frac{x}{1+x} \leq \log(1+x) \leq x$ or similar inequalities I cannot use derivatives, Taylor expansion, $o(x), O(x)$ and similar things. Using the inequality that I have written above and the substitution $x=\frac{1}{\sin t}$ I have been only able to prove that the limit is greater or equal than 0 and smaller or equal than 1. Any ideas?","['calculus', 'limits']"
914078,Does the symmetric decreasing rearrangement of a smooth function preserve smoothness?,"Let $A\subset \mathbb{R}^n$ a Borel set of finite Lebesgue measure. They define
  $A^*$ to be the ball centered at 0 with the same measure that
  $A$. The symmetric-decreasing rearrangement of a measurable function $f:\mathbb{R}^n \to \mathbb{R}$ is then defined by $$f^*(x):=\int_0^{\infty} \chi_{\{|f|>t\}^*}(x)dt,$$ by comparison to the ""layercake"" representation of $f$, namely
  $$f(x)=\int_0^{\infty} \chi_{\{f>t\}}(x)dt.$$ Note that one can equally define $f^*$ to be the radial symmetric, decreasing function such that the level sets of $f^*$ and $f$ have the same measure (or volume). I don't know why, but it always occurs to me that the rearrangement process is a regularizing process. Here's my question: If $f$ is $k$ times continuously differentiable, does it follow that $f^*$ possesses the same regularity?","['measure-theory', 'decreasing-rearrangements', 'derivatives', 'real-analysis']"
914129,Proof of Divergence Criterion for Functional Limits,"I'm self-studying from the book Understanding Analysis by Stephen Abbott, and I don't understand corollary 4.2.5 on page 107. To be more specific, let me first write down the theorem that precedes the corollary: (Sequential Criterion for Functional Limits) : Let $A \subseteq \mathbb{R}$, $f : A \to \mathbb{R}$ and let $c$ be a limit point of $A$. Then $\lim_{x \to c} f(x) = L$ if, and only if, for all $(x_n) \subseteq A$ satisfying $x_n \neq c$ and $(x_n) \to c$, it follows that $f(x_n) \to L$. Now, the corollary is as follows: (Divergence Criterion for Functional Limits) : Let $f : A \to \mathbb{R}$, and let $c$ be a limit point of $A$. If there exist two sequences $(x_n)$ and $(y_n)$ in $A$ with $x_n \neq c$ and $y_n \neq c$, and:
\begin{equation}
\lim x_n = \lim y_n = c \;\;\; \text{but} \;\;\; \lim f(x_n) \neq \lim f(y_n)
\end{equation}
then we can conclude that the functional limit $\lim_{x \to c} f(x)$ does not exist. The author provides no proof of the corollary and since he normally proves all theorems or gives them as exercises, I get the impression that the corollary is supposed to be trivially true. But I don't get it. Namely, if we consider the sequence $(y_n)$ discussed in the corollary, then it satisfies $y_n \neq c$ and $(y_n) \to c$, and the limit of $f(y_n)$ may also exist (nowhere in the corollary is it stated that the limit of $f(y_n)$ does not exist). Thus, in case the limit of $f(y_n)$ does exist, say $f(y_n) \to L$, then it must be that $\lim_{x \to c} f(x) = L$, and so the limit does exist. Of course, following a similar argument, if we now consider the sequence $(x_n)$ mentioned in the corollary, then we must again have that $\lim_{x \to c} f(x)$ does exist. Combining the above two arguments, the only thing I can think of is that it is impossible to have $\lim f(x_n) \neq \lim f(y_n)$ if $\lim x_n = \lim y_n = c$.","['functions', 'self-learning', 'real-analysis', 'limits']"
914131,Fractional Part of $ a^n $,"Prove that there exists a real number $ a>1 $, such that $ \{a^n\} $ belongs to $[\frac{1}{3},\frac{2}{3}]$ for all positive integers $n$ and $\lfloor a^n\rfloor$ is even iff $n$ is a prime. $a^n=\{a^n\}+\lfloor a^n\rfloor$, where $ \{a^n\} $ is the fractional part of $a^n$ and $\lfloor a^n\rfloor$ is the largest integer not greater than $ a^n $","['contest-math', 'real-analysis']"
914152,How to mark rational points on a sphere,"I found this picture on mathoverflow , which I find very intriguing and so I like to know how to draw such an image with a simple computer program. To calculate the rational point, I can draw a line from P_0(0,0,1) and P_1(u,v,0) and calculate the intersection with the sphere as follows: \begin{equation}
x=\frac{2u}{u^2+v^2+1};y=\frac{2v}{u^2+v^2+1};z=\frac{u^2+v^2-1}{u^2+v^2+1}
\end{equation} So the intersection coordinates are rational numbers where \begin{equation}
a=2u;b=2v;c=u^2+v^2-1;d=u^2+v^2+1
\end{equation} with \begin{equation}
a^2+b^2+c^2=d^2
\end{equation} If I understand correctly the guy who posted the picture he would mark the points depending on the value of d. So a value of d below a certain threshold would override the pixel color to white. Now inside a program we would loop through all pixels along the x and y axis using the following algorithm: for(int y = 0; y < height; ++y)
{
    for(int x = 0; x < width; ++x)
    {
        // does pixel ray intersect with sphere?
        // using orthgraphic projection ( all rays are parallel ) of 
        // sphere with radius of image height
        if(intersect(sphere,x,y))
        {
            // calculate the distance of the intersection of 
            // pixel ray and sphere
            double z = calc_distance(sphere,x,y);

            // the further away the darker the color
            rgb_color color = make_color(z);

            // calculate d
            // the gcd of a,b,c,d will be used to make d as small as possible
            int d = calculate_denominator(x,y)

            // 100 is made up
            if(d < 100)
            {
                color = white;
            }

            set_pixel(img,x,y,color);
        }
    }
} Could someone help in correcting my algorithm?","['geometry', 'elementary-number-theory', 'image-processing']"
914163,Construct the cross section of a cube by a plane passing through three given points,"I want to find/construct the cross section of a cube that includes the three points shown below. In other words, if a plane went through the cube such that it would slice where the points are, what would the whole cross section look like in general? Since the back two points lie on the same plane, I thought about connecting the back two points with a line. However, what is throwing me off is the fact that the line is tilted so when looking at the right side of the top face, if I extended that line, I am pretty sure it would not intersect the first line I constructed. [Original picture was lost; the picture above is a reduced copy of an image from the answer by John Hughes]","['geometry', '3d']"
914176,Closed-forms of infinite series with factorial in the denominator,"How to evaluate the closed-forms of series \begin{equation}
1)\,\, \sum_{n=0}^\infty\frac{1}{(3n)!}\qquad\left|\qquad2)\,\, \sum_{n=0}^\infty\frac{1}{(3n+1)!}\qquad\right|\qquad3)\,\, \sum_{n=0}^\infty\frac{1}{(3n+2)!}\\
\end{equation} Of course Wolfram Alpha can give us the closed-forms
\begin{align}
\sum_{n=0}^\infty\frac{1}{(3n)!}&=\frac{e}{3}+\frac{2\cos\left(\frac{\sqrt{3}}{2}\right)}{3\sqrt{e}}\\
\sum_{n=0}^\infty\frac{1}{(3n+1)!}&=\frac{e}{3}+\frac{2\sin\left(\frac{\sqrt{3}}{2}-\frac{\pi}{6}\right)}{3\sqrt{e}}\\
\sum_{n=0}^\infty\frac{1}{(3n+2)!}&=\frac{e}{3}-\frac{2\sin\left(\frac{\sqrt{3}}{2}+\frac{\pi}{6}\right)}{3\sqrt{e}}
\end{align}
but how to get those closed-forms by hand? I can only notice that
\begin{equation}
\sum_{n=0}^\infty\frac{1}{n!}=\sum_{n=0}^\infty\frac{1}{(3n)!}+\sum_{n=0}^\infty\frac{1}{(3n+1)!}+\sum_{n=0}^\infty\frac{1}{(3n+2)!}=e
\end{equation}
Could anyone here please help me? Any help would be greatly appreciated. Thank you. PS: Please don't work backward.","['closed-form', 'sequences-and-series', 'calculus', 'factorial', 'taylor-expansion']"
914195,Asymptotics on the largest prime for which $x^n+1\equiv y^n$ has no nonzero solution,"It $\let\epsilon\varepsilon\let\leq\leqslant\let\geq\geqslant$is a well known result that for every $n\in\mathbb N$, $x^n+1\equiv y^n\pmod p$ is non-trivially solvable for sufficiently large primes $p$. Let $P_n$ denote the largest prime for which it is unsolvable. Ramsey theory gives (I think the proof was first given by Schur, if I'm not mistaking) $$P_n<R(\underset{n\;3\text{'s}}{\underbrace{3,\ldots,3}}),$$ where $R(\ldots)$ denotes the Ramsey number . Since 
$$R(\underset{n\;3\text{'s}}{\underbrace{3,\ldots,3}})\leq2-n+n\cdot R(\underset{n-1\;3\text{'s}}{\underbrace{3,\ldots,3}})\leq n\cdot R(\underset{n-1\;3\text{'s}}{\underbrace{3,\ldots,3}})$$
for $n\geq2$ and $R(3,3,3)=17$, the best explicit bound I can get from this is $P_n<\frac{17}6\cdot n!$. A heuristic approach goes as follows: there are at least $\frac{p-1}n$ nonzero $n$th powers modulo primes $p$. The 'probability' that none of these yields a solution to the congruence is thus at most $\left(1-\frac{\frac{p-1}n}p\right)^{\frac{p-1}n}$, if we assume the $n$th powers to be distributed uniformly. If we want to bound this from above by a fixed $\epsilon>0$, we have
$$\begin{align*}\left(1-\frac{\frac{p-1}n}p\right)^{\frac{p-1}n}&\leq\epsilon\\
\frac{p-1}n\log\left(1-\frac1n\right)\approx\frac{p-1}n\log\left(1-\frac{p-1}{np}\right)&\leq\log\epsilon\\
p-1&\lessapprox\frac{n\log\epsilon}{\log\left(1-\frac1n\right)}=n^2\log\epsilon+O(n).\end{align*}$$
I'm not sure if these calculations make any sense at all, but from this I would conjecture that $P_n=O(n^2)$. Finally, my question: Is it known that $P_n=O(n^2)$? If not, what is the best known bound, or what do heuristics tell us?","['asymptotics', 'analytic-number-theory', 'number-theory']"
914215,"A closed-form of $\frac{1}{2}\int_0^\infty\left[\frac{x^2\cos x}{\cosh 2x-\cos x}-\frac{2x^2}{e^{4x}-2e^{2x}\cos x+1}\right]\,dx$","I am looking for a closed-form of this integral \begin{equation}
\frac{1}{2}\int_0^\infty\left[\frac{x^2\cos x}{\cosh 2x-\cos x}-\frac{2x^2}{e^{4x}-2e^{2x}\cos x+1}\right]\,dx
\end{equation} I can rewrite the integral into
\begin{equation}
\int_0^\infty\frac{x^2(e^{2x}\cos x-1)}{e^{4x}-2e^{2x}\cos x+1}\,dx
\end{equation}
But I am stuck for the next step. I have a strong feeling the integral involving gamma or beta function but I am unable to prove it. Could anyone here please help me? Any help would be greatly appreciated. Thank you.","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
914240,Limit of a Riemann Sum and Integral,"I've been trying to solve this problem, but I haven't been able to calculate the exact limit, I've just been able to find some boundaries. I hope you guys can help me with it. Let $f:[0,1] \to \mathbb{R}$ a differentiable function with a continuous derivative, calculate:
$$\lim_{n\to \infty}\left(\sum_{k=1}^nf\left(\frac{k}{n}\right)-n\int_0^1f(x)dx\right) $$
I tried using Mean Value Theorem for derivatives and integrals and I got that 
$$\lim_{n\to \infty}\left(\sum_{k=1}^nf\left(\frac{k}{n}\right)-n\int_0^1f(x)dx\right)=\lim_{n\to \infty}\left(\sum_{k=1}^nf'\left(x_k**\right)(\frac{k}{n}-x_k*)\right) $$
Where $x_k*\in [\frac{k-1}{n},\frac{k}{n}]$ and $x_k**\in [x_k*,\frac{k}{n}]$, which looks like a Riemann Sum but I'm not sure if it's a Riemann Sum of $f'$ from $0$ to $1$, if this was true I believe the limit is $f(1)-f(0)$ but I'm not really sure about this. Edit: fixed some typos with the $\frac{k}{n}$. Edit 2: $k$ starts from $1$ not $0$.","['calculus', 'integration', 'riemann-sum', 'derivatives', 'limits']"
914247,Trigonometric functions expressed as definite integrals with Bessel functions,"Prove that 
$$\frac{\sin(x)}{x}=\int_0^\frac{\pi}{2}J_0(x\cos(\theta))\cos(\theta)\,d\theta \tag{a}$$
$$\frac{1-\cos(x)}{x}=\int_0^\frac{\pi}{2}J_1(x\cos(\theta))\,d\theta  \tag{b}$$
 Hint:
$$\int_0^\frac{\pi}{2}\cos^{2s+1}(\theta)\,d\theta  = \frac{2\cdot 4\cdot6\cdots(2s)}{1\cdot3\cdot5\cdots(2s+1)}$$ I have no  idea how to approach this problem.  Any suggestions?  I did express sine function in exponential form but then I have no clue where to go from  there so that I can end up with the integral as an answer indicated above.","['closed-form', 'special-functions', 'integration', 'definite-integrals', 'bessel-functions']"
914264,Measure of Elementary Sets Proof,"I am struggling with what seems like a very simple problem from Terrence Tao's Introduction to Measure Theory book (which is available for free online by the way). What I am trying to prove is the following:
Give an alternate proof of Lemma 1.1.2(ii) by showing that any two partitions of $E$ into boxes admit a mutual refinement into boxes that arise from taking Cartesian products of elements from finite collections of disjoint intervals. The referenced Lemma is provided below: Lemma 1.1.2 (Measure of an elementary set). Let $E \subset \mathbb{R}^d$ be an elementary set. $E$ can be expressed as the finite union of disjoint boxes. If $E$ is partitioned as the finite union $B_1 \cup \ldots \cup B_k$ of disjoint boxes, then the quantity $m(E):=|B_1|+ \ldots + |B_k|$ is independent of the partition. In other words, given any other partition $B'_1 \cup \ldots \cup B'_{k'}$ of $E$, one has 
$|B_1|+ \ldots + |B_k| = |B'_1|+ \ldots + |B'_{k'}|$. The proof that is provided in the text uses a discretization argument that I do not understand, but the problem at hand is to show the same result holds regardless of the partition used. My approach was to let $X=B_1 \cup \ldots \cup B_k$ and $Y=B'_1 \cup \ldots \cup B'_{k'}$ and then show that $X=Y$. I can rewrite both of these sets as 
$X=\bigcup\limits _{i=1}^kB_i$ and $Y=\bigcup\limits_{j=1}^{k'}B'_j$, but then I am confused on how to proceed to show their measures are equivalent. The problem states to use Cartesian products, but I notice that my attempt does not seem to use it which is why I am starting to think that I am on the wrong path. Any assistance, suggestions, and/or advice on this would be greatly appreciated. Many thanks in advance.","['alternative-proof', 'measure-theory', 'real-analysis']"
914288,How to find the approximate basic period or GCD of a list of numbers?,"I want to tell the number which act as the best approximate basic period (or wavelenght as pointed out by Eric) of a list of real numbers: e.g for { 14, 21, 35 } we should obtain 7 as the basic period, the same as for { 17, 24, 38 }(same numbers with an offset) or for  { 14.5, 21.3, 34.4 }(same numbers with some error), etc. It is a kind of approximate GCD algorithm which ignores any offset. The original use case was that of determining the rate of a heartbeat received from a computer, where beats are randomly skipped, based on their timestamps. I've come to a possible solution which I'm stuck with: the solutions will minimize the variance of the remainder of the division of the values in the list by the chosen factor $T$ (that's the solution), and I have reached the following formula: being $v$ the list $\{v_1, v_2, \ldots, v_n\}$ , $\operatorname{mean}_{\sin}(v, T)$ $= \frac{1}{n}\sum_{i=1}^n\sin(2\pi v_i/T)$ $\operatorname{mean}_{\cos}(v, T)$ $= \frac{1}{n}\sum_{i=1}^n\cos(2\pi v_i/T)$ $\operatorname{period}_{appeal}(v, T)$ $= \sqrt{\operatorname{mean}_{\sin}(v, T)^2 + \operatorname{mean}_{\cos}(v, T)^2} = \frac{1}{n}\sqrt{n + 2\sum_{i\lt j}^n{\cos{\frac{2\pi(v_i-v_j)}{T}}}}$ $\Rightarrow v \approx T·x + \frac{T}{2\pi}\operatorname{atan2}(\operatorname{mean}_{\sin}, \operatorname{mean}_{\cos}), x \in \mathbb{Z}$ Note that $\operatorname{period}_{appeal}$ , as it is (rather obscurely) only dependent on the differences between the elements in the list, ignores a constant offset, that is, $\operatorname{period}_{appeal}(v, T)$ $= \operatorname{period}_{appeal}(w, T)$ where $w_i = v_i + k \ \forall{i}\forall{k}$ which is great for my original use case. However, we can tune the formula to find the approximate GCD instead, which assumes no offset is present, $\operatorname{gcd}_{appeal}(v, T)$ = $1 - \frac{1}{2}\sqrt{\operatorname{mean}_{\sin}(v, T)^2 + (\operatorname{mean}_{\cos}(v, T) - 1)^2}$ $\Rightarrow v \approx T·x, x \in \mathbb{Z}$ This is what they look like for $v = [14, 21, 35]$ , period in blue, gcd in green they both offer maximum appeal at 7, 7/2, 7/3,...,7/z, including at the $\infty$ limits (7/0), as $v_i$ are perfect multiples of 7 (and thus of 7/z). However when $v$ contains some noise, $v = [14.5, 21.3, 34.4]$ , the functions start to differ Here the optimum period is ~6.622 ( $v \approx 6.622x + 1.3266$ ) while the optimum GCD is ~7.0178, and the fractions of the optimum value lose appeal in both cases. And now my real question is, Is there any chance of finding the solutions for these functions, that is the points with maximum appeal, whithout having to try every possible number? If we assume that every $v_i$ corresponds to a different multiple of the period then the range of search for the solution can be limited to $(1, min(|v_i - v_j|)]$ Thanks for your answers. edit: You can play with the functions in CoCalc using the following code: def mean_x(factor, values):
    return sum([cos(2*pi*v/factor) for v in values])/len(values)

def mean_y(factor, values):
    return sum([sin(2*pi*v/factor) for v in values])/len(values)

def calculatePeriodAppeal(factor, values):
    mx = mean_x(factor, values)
    my = mean_y(factor, values)
    appeal = sqrt(mx^2+my^2)
    return appeal

def calculateBestLinear(factor, values):
    mx = mean_x(factor, values).n()
    my = mean_y(factor, values).n()
    y0 = factor*atan2(my,mx)/(2*pi).n()
    err = 1-sqrt(mx^2+my^2).n()
    return [factor*x + y0, err]

def calculateGCDAppeal(factor, values):
    mx = mean_x(factor, values)
    my = mean_y(factor, values)
    appeal = 1 - sqrt((mx-1)^2+my^2)/2
    return appeal You can also find a fast approximate Java implementation in this StackOverflow answer .","['optimization', 'divisibility', 'trigonometry', 'approximation', 'summation']"
914299,what is the most easy to read Algebraic Geometry book? [duplicate],"This question already has answers here : Undergraduate algebraic geometry textbook recommendations (11 answers) Closed 9 years ago . All: what is the most easy to read (most accessible) Algebraic Geometry book ? (If possible, I am looking for an introduction book, maybe for undergraduate, and maybe similar to A Friendly Introduction to Number Theory).","['algebraic-number-theory', 'algebraic-geometry', 'reference-request', 'number-theory']"
914309,Solve $2tx'(t)-x(t)=\ln x'(t)$ [duplicate],"This question already has answers here : Second-order non-linear ODE (3 answers) Closed 7 years ago . Solve $2tx'(t)-x(t)=\ln \left[x'(t)\right]$ That would be an easy Clairaut's equation if $tx'(t)$ wasn't multiplied by $2$. But unfortunately it is, and I have no idea what to do here.",['ordinary-differential-equations']
914321,Does anyone recognise this recursion sastisfied by the Bell numbers?,"I derived a recursion $$B_n=\frac{1}{n}B_0+\frac{1}{n}\sum_{k=1}^{n-1}\left[\binom{n}{k}-(-1)^{n-k}\binom{n}{k-1}\right]B_k\tag{$*$}$$ which I know should be satisfied by the moments of the unit Poisson distribution ($B_n$ denoting the $n$th moment), which happen to be the Bell numbers. Trying to check that I hadn't mucked up the derivation I looked online for recursions satisfied by the Bell numbers hoping to find the above, however I only found the standard one $$B_n = \sum_{k=0}^{n-1}\binom{n-1}{k}B_k.$$ I'm pretty sure now that the derivation of $(*)$ is fine (I've also computed the first few numbers obtained from $(*)$, with $B_0=1$, and they are the first few Bell numbers). So does anyone recognise the recursion $(*)$? Does it have a name, or, do you know of a reference that contains it? Thanks. Edit: Happy to give the bounty to anyone that posts a proof that $(*)$ is (or isn't) satisfied by the Bell numbers or a reference containing such a proof.","['recurrence-relations', 'combinatorics']"
914335,Is $\mathrm{col}(\lambda I_n-A)\subseteq \mathrm{col}(B) $ for a complex $\lambda$?,"Let $A\in\mathbb{R}^{n\times n}$, let $I_n$ denote the identity matrix of order $n$, and let $ \mathrm{col}$ denote column space. I'm interested in understanding for what values of $\lambda \in \mathbb{C} $ there exists a full column rank matrix $B\in\mathbb{R}^{n\times m}$, with $m<n$, such that $\mathrm{col}(\lambda I_n-A)\subseteq \mathrm{col}(B) $. Clearly $\lambda$ must be an eigenvalue of $A$ because otherwise $\mathrm{col}(\lambda I_n-A)$ is $n$-dimensional and hence cannot be in the $m$-dimensional subspace $\mathrm{col}(B) $. If $\lambda$ is a real eigenvalue of $A$, we can certainly find a $B$ such that $\mathrm{col}(\lambda I_n-A)\subseteq \mathrm{col}(B) $. What if $\lambda$ is a (non-real) complex eigenvalues of $A$?","['vector-spaces', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'complex-numbers']"
914338,The alternating group is generated by three-cycles,"Prove that, for $n \geq 3$, the three-cycles generate the alternation group $A_n$ Proof: We multiply on the left by 3-cycles to ""reduce"" an even permutation $p$ to the identity, using induction on the number of indices fixed by a permutation. How the indices are numbered is irrelevant. If $p$ contains a $k$-cycle with $k \geq 3$, we may assume that it has the form $p=(123\dots k)\dots$ Multiplying on the left by $(321)$ gives $$p'= (321)(123 \dots k)\dots=(1)(2)(3\dots k)\dots$$ More fixed indices. What do you think ?","['proof-verification', 'group-theory', 'abstract-algebra']"
914348,The relation between geodesics and distances on a Riemannian manifold,"My question is about computing the distance between two points in a Riemannian manifold. Suppose that $(M,g)$ is compact so that it is geodesically complete and geodesically convex. Let $X\in\Gamma(TM)$ be a vector field. Fix a point $p\in M$. Let $\gamma:\mathbb{R}\to M$ denote the unique geodesic with initial velocity $X_p$. That is, $$(\exp)_p(X)=\gamma(1) \ \ \text{ and } \ \ (\exp)_p(tX)=\gamma(t).$$ My question is, why does $$d\left((\exp)_p(X),(\exp)_p(tX)\right)=|1-t||X_p| \ ?$$ Here $d:M\times M\to \mathbb{R}$ denotes the Riemann distance function. That is $$d(p,q)=\inf\left\{\int|\rho^\prime(t)|dt \ ; \rho \text{ is an admissible curve between $p$ and $q$}\right\}$$ Since geodesics are length minimizing wouldn't $\gamma$ be the unique curve between $(\exp)_p(X)$ and $(\exp)_p(tX)$ which minimizes the distance function? But the integral of $|\gamma^\prime(t)|$ isn't $|1-t||X_p|$ ? Any help is very much appreciated.","['riemannian-geometry', 'calculus', 'differential-geometry']"
914349,Slope of a vertical line,"Find the equation of the line that satisfies the given conditions: Through $(-1,2)$; parallel to the line $x=5$ I know that the equation  of this line is $x=-1$ because $x=5$ is a vertical line and any line parallel to it would be vertical as well. So the line runs vertically along $x=-1$. But how would I solve this algebraically?",['algebra-precalculus']
914412,"$|\{0,1\}^\infty| = |\mathbb{R}|$?","Let $\{0,1\}^\infty$ = {$(a_n)_{n \in \mathbb{N}}; a_n \in \{0,1\} \forall n \in \mathbb{N}$} Is there a bijection between $\{0,1\}^\infty$ and $\mathbb{R}$? I thought about something like this: If $x \in \mathbb{R}$, then $x=a_1,a_2a_3\ldots a_na_{n+1}\ldots$, where $a_1$ is the integer part and $a_n$, $1<n$ are the decimal digits. So, $f(x)$ would be something like $f(x)=(\underbrace{1,...,1}_{a_1 number 1},0,\underbrace{1,...1}_{a_2number1},0,...)$ . I don't know if I made my self clear... So I'd like some help to formalize this and to know if I'm in the right way... Thanks!","['functions', 'real-numbers', 'real-analysis']"
914416,Hint on a limit that involves the Hurwitz Zeta function,"I will be honest. Some play with a weird integral has gotten me to this formulation:
$$\lim\limits_{n\mathop\to\infty}\frac{\zeta(2,n)}{\frac 1n+\frac 1{2n^2}}=1$$
It seems true because of the numerical approximations made and the actual evaluation of this limit at Wolfram Alpha. But i am stuck. Does anyone have an idea of where to start?","['zeta-functions', 'limits']"
914423,"Consider the sequence $f_n(x) = (\sin(πnx))^n , n = 1, 2, ...,$ on the interval $[0,1].$","Consider the sequence $f_n(x) = (\sin(πnx))^n , n = 1, 2, ...,$ on the interval $[0,1].$ Prove that for any $δ > 0$ there is a set $E ⊂ [0,1]$ with $m(E) > 1−δ,$ and a subsequence $f_{n_k} (x), k = 1, 2, 3...,$ such that $\lim_{k→∞} f_{n_k} (x) = 0$ for $x ∈ E.$ Not sure what to do.  Want to construct a set $E$ as above with $f_n$ going to zero in $L_1$ norm.  Then it would follow.","['measure-theory', 'real-analysis', 'analysis', 'lebesgue-integral', 'lebesgue-measure']"
914443,Determining whether points are collinear,"$(1,1)(3,9)(6,21)$ The way I figured that this should be solved is by finding the slope of: 
$(1,1)(3,9)$ Then, $(3,9)(6,21)$ Finally $(1,1)(6,21)$ Which are 4, 4,and 4 respectively. 
So I assume that they are collinear. Am I correct? And if not, please provide me with an explanation as to what needs to be done to find the answer rather than a direct answer.",['algebra-precalculus']
914446,"Integral of $\cos(\cos x)$ over $[0,2\pi]$","How to compute the following integral? $$\mathcal{J}_2=\int_{0}^{2\pi}\cos(\cos t)\,dt$$ I'm trying to compute this integral, but I have no idea of how to do it, can someone help me?","['calculus', 'integration', 'definite-integrals', 'trigonometry', 'bessel-functions']"
914461,Shtukas?$\mbox{}$,"Does there exist an exposition of the significance of shtukas for someone who is mathematically literate but is largelly ignorant of Drinfeld modules?
This arises in the work of Peter Scholze among others.
Is this notion accessible only to those already immersed in the Langlands conjectures?","['algebraic-geometry', 'algebraic-number-theory', 'number-theory']"
914469,"If $f(\mathbb{C})\subset \mathbb{C}-[0,1]$ then $f$ is constant [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $f:\mathbb{C}\longrightarrow\mathbb{C}$ is an entire function such that $f(z)\neq w$ for all $z\in \mathbb{C}$ and for all $w\in [0,1]\subset \mathbb{R}$, how to prove that $f$ is constant (without using Picard's little theorem). Any hint would be appreciated.",['complex-analysis']
914477,How to simplify the integral of $\int\frac{\cos(8x)}{\cos(4x)+\sin(4x)}dx$?,"So I am trying to integrate this problem $\int\frac{\cos(8x)}{\cos(4x)+\sin(4x)}dx$, and my professor went over it in class and went from $\int\frac{\cos(8x)}{\cos(4x)+\sin(4x)}dx \rightarrow \int\cos(4x)-\sin(4x)dx$ and I do not understand how he went about simplifying the integral. I've looked and all the trig identities we've gone over so far in our book and in class and I am not seeing how he got that. Thanks for all the help in advance.","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
914513,What do group automorphisms fix? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 9 years ago . Improve this question I have often found it useful to sit and contemplate what kinds of elements, subsets, or structures do the automorphisms of an object fix or permute. Sometimes the observations do not have immediate application, but they have often come back to help me later on. To help my future self, I'm asking about groups in particular. What kind of elements, subsets, or structures do automorphisms of a group fix, permute, or preserve? The examples I've compiled and some of their uses are listed below: Subgroups (and subgroups of a fixed cardinality) Normal subgroups Maximal subgroups (implies that the intersection of all maximal subgroups is characteristic) Minimal subgroups (implies that the subgroup they generate is a characteristic subgroup) Sylow $p$-subgroups for any prime $p$ Subgroups of index $n$ for any $n\in\Bbb N$ Elements of order $n$ for any $n\in\Bbb N$ Elements in the center (implies the center is characteristic) Commutators (implies the derived subgroup is characteristic) Generating sets (this helps classify the automorphisms of a cyclic group) Minimal generating sets Nongenerators Conjugacy classes (and conjugacy classes of a fixed cardinality) beautiful application Centralizers Normalizers This is a fairly big list but is certainly far from exhaustive. And I feel like if I was exposed to new examples, I would see new connections that I haven't before. Any addition to the list is much appreciated. Bonus points for an application of why the observation is useful (if I could give bonus points) .","['big-list', 'group-theory', 'abstract-algebra']"
914519,Finding the value of $\frac{\cos^4\beta}{\cos^2\alpha} + \frac{\sin^4\beta}{\sin^2\alpha}$.,"Trigonometry $\dfrac{\cos^4 \alpha}{\cos^2 \beta}+ \dfrac{\sin^4\alpha}{\sin^2\beta} = 1$ then the value of $\dfrac{\cos^4\beta}{\cos^2\alpha}+ \dfrac{\sin^4\beta}{\sin^2\alpha}$ is? NOTE: can somebody help me 
$\cos^2\alpha \left(\frac{\cos^2 \alpha}{\cos^2 \beta}\right)+ \sin^2\alpha \left(\frac{\sin^2 \alpha}{\sin^2\beta}\right)$",['trigonometry']
914535,Prove an inequality similar to Jensen's inequality,"Prove that 
$$\mathbb{E}(\sqrt{X})\leq\sqrt{\mathbb{E}Y}$$
where random variables $X,Y>0$ and $\mathbb{E}\left[\frac{X}{Y}\right]\leq1.$ My attempt:
This looks very much like Jensen's inequality. According to Jensen, $\mathbb{E}(\sqrt{X})\leq\sqrt{\mathbb{E}X},$ then the desired inequality is true if we can prove $\mathbb{E}X\leq\mathbb{E}Y.$ But this seems impossible to prove because $X$ and $Y$ are not independent. Any help will be appreciated!",['probability']
914538,"Is there $u,v\in L(E): uv-vu=id_E$",Let $E$ be a normed vector space over $\mathbb{R}$. Is there continuous linear transformations $u$ and $v$ such that: $$uv-vu=id_E$$ (.ie $\forall x\in E:u(v(x))-v(u(x))=x$) I suspect that the answer is no. When $E$ is finite dimensional we can use Trace Operator to prove that there is indeed no satisfied transformations. I don't know how to process in the case of infinite dimensional $E$.,"['linear-algebra', 'functional-analysis']"
914551,"Ramsey Numbers involving Cycles, $R(K_3, C_5)$","I've been asked to determine the value of $R(K_3, C_5)$, but I'm having a lot of difficulty putting all the pieces together. We were given the hint of using $R(3,4) = 9$, and I've tried to apply that, but I don't think my number is ""tight"" enough. For example, I wanted to consider $R(3,5)$, because, if a complete graph contains a $K_5$, I know I've got a $C_5$, so I'm done. Now, I know that; $R(3,5) \le R(2,5) + R(3,4) = 5 + 9 = 14$ So I know that, if I colour a $K_{14}$ in two colours, I'm guaranteed either a $K_3$, or a $K_5$ (and, by extension, a $C_5$), but my question is - can I do any better than this??","['ramsey-theory', 'graph-theory', 'discrete-mathematics']"
914554,Is the definition of stabilizer given at Planet Math really the currently accepted definition among group theorists?,"According to Planet Math , given a group $G$ a set $X$ a subset $S \subseteq X$ and a group action $G \times X \rightarrow X,$ then the stabilizer of $S$ is define to be: $\{g \in G \mid gS \subseteq S\}.$ I have an issue with this definition; I think the condition $gS \subseteq S$ should be replaced by $gS = S.$ (Essentially, wikipedia only defines stabilizers when $S$ is a a singleton set, thereby avoiding this issue. nLab also goes this way.) To see the problem, let $X$ denote the real line, and write $G$ for the group of automorphisms of $X$ (i.e. order-preserving bijections from $X$ back to itself). Let $S = [-1,1]$. Then according to Planet Math, the function $$g : x \in X \mapsto x/2 \in X$$ is in the stabilizer of $S$. But this seems odd, because the restriction of the above function to a mapping $S \rightarrow S$ does not yield a bijection. The problem, of course, is that $gS = [-1/2,1/2]$ is a proper subset of $S = [-1,1]$. Anyway, my question is: Question. Is the definition of stabilizer given at Planet Math really the currently accepted definition among group theorists?","['terminology', 'group-theory']"
914555,Calc II - Definite integral of sqrt(t^2 + t) from 2x to 1?,"How do I find $$\int_1^{2x}\sqrt{t^2 + t}$$ with only knowledge from a Calculus I course? I've tried plugging this puppy into Wolfram Alpha and other integral solvers, which report it as solvable (looks really long and nasty), but I think this is outside the scope of my just-entered-Calc-II knowledge and that I need to solve it in a tricky way. The problem is part of the linked green sheet. Since I don't know how to integrate this I've tried to solve the sheet without doing so, though on part D) it seems like my luck is about to run out. I doubt what I am trying to do is even legal. Please advise.","['definite-integrals', 'calculus', 'integration', 'derivatives']"
914556,"Trying to understand ""derivative or Jacobian of smooth map""","From some lecture notes I am trying to puzzle through .... ""... the derivative or Jacobian of a smooth map $f: \mathbb{R}^m \rightarrow \mathbb{R}^n$ at a point $x$ is a linear map $Df: \mathbb{R}^m \rightarrow \mathbb{R}^n$.  In terms of partial derivatives,  $Df_x(X) = (\sum_j\partial_{x_j}f_1 \cdot X_j,
\sum_j \partial_{x_j}f_2\cdot X_j, ...)$ ... "" I'm so confused I'm not even sure where to begin.  Well, first, shouldn't the derivative be a map $Df:\mathbb{R}^m\rightarrow \mathbb{R}^m\times\mathbb{R}^n$?  Third, I am familiar with 3D integral calculus, and the only Jacobian I heard discussed there doesn't look like this at all, except, of course, that they both involve partial derivatibes.  Also, I don't even know what $f_1 \cdot X_j$ means. Thanks.","['derivatives', 'differential-geometry']"
914565,How do I Solve This Kind of Differential Equation? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How do I solve this differential equation? $$y(2x+y^2)dx+x(y^2-x)dy=0$$","['ordinary-differential-equations', 'integration']"
914570,Regarding metrizability of weak/weak* topology and separability of Banach spaces.,"Let $X$ be a Banach space, $X^*$ its dual, $\mathcal{B}$ the unit ball of $X$ and $\mathcal{B}^*$ the unit ball of $X^*$. The following result is well-known Theorem . If $X$ is separable, then $\mathcal{B}^*$ endowed with the weak*-topology is metrizable. A solution would be the following: Let $(x_n)_{n\in\mathbb{N}}$ be a dense subset of $\mathcal{B}$. Then $d(\phi_1,\phi_2)=\sum_{n=1}^\infty 2^{-n}|\phi_1(x_n)-\phi_2(x_n)|$ is a metric which induces the weak*-topology of $\mathcal{B}^*$. I was wondering about the converse: Question 1 . Suppose that the weak*-topology of $\mathcal{B}^*$ is metrizable. Is $X$ (norm-)separable? My thought was: By Banach-Alaoglu $\mathcal{B}^*$ is weak*-compact. If it is also metrizable, then it is (weak*-)separable, and it follows easily that $X^*=\bigcup_{n=1}^\infty\mathcal{B}^*$ is also weak*-separable. The problem is that this does not imply that $X$ is separable ($\ell_\infty$ is a counterexample - weak$^*$-separability of $l_\infty^*$. ) My second idea was to try to compare a metric which induces the weak*-topology of $\mathcal{B}^*$ with some metric as in the proof of the theorem above, but I did not succeed. We can also consider all the ""dual statements"" and ask similar questions. More precisely, we know that the following holds: Theorem. If $X^*$ is norm-separable, then the weak topology of $\mathcal{B}$ is metrizable. We prove this by defining $d(x,y)=\sum_{n=1}^\infty 2^{-n}|\phi_n(x-y)|$ for a dense sequence $(\phi_n)_{n\in\mathbb{N}}\subseteq\mathcal{B}^*$, as expected. Then we ask the question: Question 2 . If the weak topology of $\mathcal{B}$ is metrizable, is $X^*$ necessarily norm-separable (so $X$ is norm-separable as well)? An alternative approach to answer Question 2 would be the following: Suppose $d$ is a metric inducing the weak topology of $\mathcal{B}$. Changing $d$ by $\frac{d}{1+d}$ if necessary, assume that $d$ is bounded. Let's identify $X$ as a subspace of $X^{**}$ via the canonical mapping. Goldstine's Theorem implies that the only possible metric in $\mathcal{B}^{**}$ extending $d$ and inducing the weak*-topology has to be given by
$$d'(\Lambda,\Gamma)=\inf\left\{\operatorname{diam}(U\cap X):U\text{ is weak*-open and }\Lambda,\Gamma\in U\right\}.$$
If Question 1 has a positive answer (and all the rest stated is true as well), then Question 1 implies that $X^*$ is separable. One last comment: If $X$ is reflexive, then both questions have positive answers. For Question 1, we know (as above) that $X^*$ is weakly*-separable. But reflexivity of $X$ implies that the weak and weak*-topologies of $X^*$ are equal, so $X^*$ is weakly separable, hence separable, so $X$ must also be separable. A solution for question 2 follows similarly.","['general-topology', 'metric-spaces', 'functional-analysis']"
914588,Integral operator on $L^p$ is compact,"Let $(X,\Omega,\mu)$ be an arbitrary measure space, $1<p<\infty$ , and $\frac{1}{p}+ \frac{1}{q} = 1$. If $k:X. X\to \Bbb C$ is an $\Omega.\Omega-$ measurable function such that $$M = [\int (\int |k(x,y)|^p d\mu(x))^{\frac{q}{p}} d\mu(y)]^{\frac{1}{q}}< \infty$$ and if $(Kf)(x)=\int k(x,y)f(y)d\mu(y) $, then $K$ is compact operator on $L^p(\mu)$ and $||K||\leq M$. I know that on reflexive spaces completely continuous operators are compact. Thus I started to show $K$ is completely continuous, but after a while I got stuck. Please help me. Thanks in advance.","['compact-operators', 'banach-spaces', 'operator-theory', 'normed-spaces', 'functional-analysis']"
914606,"Proof of FTC, continuity part, for Lebesgue integrable functions","The part of the FTC I am interested in says: If $f$ is a Lebesgue-integrable function on $[a,b]$, then $F(x)=\int_a^xf(t)\,dt$ is continuous. This is usually considered a lemma or something for the first part of the FTC, which adds the condition that $f$ is continuous and gets the extra information that $F$ is differentiable with $F'=f$. But this part of the theorem, without the continuity assumption, is giving me trouble. Combined with the fact that this is a Lebesgue integral and not a Riemann integral, it means that $f$ is not necessarily bounded, so I can't just prove that $F$ is Lipschitz-continuous as in the usual proof with Riemann-integrable functions. A simple example of a function that is not bounded but is Lebesgue-integrable on compact sets (and such that $F$ is continuous) is $f(x)=|x|^{-1/2}$. The weakening to Lebesgue-integrable functions is my own addition, so I don't have independent confirmation that the theorem is true, but it seems clear to me that any counterexample will essentially reproduce the characteristics of the delta function, which is not a function in the usual sense. Any ideas? Edit : It suffices to prove this for nonnegative functions $f$, because $$|F(y)-F(x)|=\left|\int_x^yf(t)\,dt\right|\le\int_x^y|f(t)|\,dt=\int_x^yg(t)\,dt=G(y)-G(x)$$
where $g(t)=|f(t)|$ and $G(x)=\int_a^xg(t)\,dt$, so if $G$ is continuous then $F$ is also continuous.","['lebesgue-integral', 'calculus', 'real-analysis']"
914652,"Trigonometric integral: $\int_{25\pi/4}^{53\pi/4} \frac{1}{(1+2^{\sin x})(1+2^{\cos x})}\,dx$ [duplicate]","This question already has answers here : Evaluate $ \int_{25\pi/4}^{53\pi/4}\frac{1}{(1+2^{\sin x})(1+2^{\cos x})}dx $ (2 answers) Closed 7 years ago . Is it possible to evaluate the following in a closed form?
$$\int_{25\pi/4}^{53\pi/4} \frac{1}{(1+2^{\sin x})(1+2^{\cos x})}\,dx$$ I found the above definite integral at I&S but the solution is not given. I have tried various methods but none of them lead me to the solution, I am honestly out of ideas for this one. Any help is appreciated. Thanks!","['definite-integrals', 'trigonometry', 'closed-form', 'integration']"
914653,Can injective function has an element that maps to nothing?,"Can injective function has an element that maps to nothing? I don't think this violate the definition of injective function. If that is the case, is it possible for a function to be bijective but its inverse not bijective since there might be an element that maps to nothing.","['elementary-set-theory', 'functions']"
914655,"$H$ of order $p$ normal in $G$ , g.c.d.$(|G|,p-1)=1$ , to prove that $H \subseteq Z(G)$","If $G$ is a finite  group and $H$ is a normal subgroup of $G$ of order
$p$(prime) such that g.c.d.$(|G|,p-1)=1$ , then how to prove that $H \subseteq Z(G)$ ? Please don't use any Sylow theorem or Cauchy theorem , I want solution with Homorphism techniques (extended Cayley's theorem is also allowed) . Thanks in advance","['finite-groups', 'group-theory', 'normal-subgroups']"
914658,"Find the sum, if exists $\sum\limits_{n=1}^{\infty} \frac{(2n)!}{2^{2n}(n!)^2(n+1)}$","$$
\sum\limits_{n=1}^{\infty}\dfrac{(2n)!}{2^{2n}(n!)^2(n+1)}
$$ By comparison test this series converges. Any nice way to work the sum? I see that this can be written as:
$$
\sum\limits_{n=1}^{\infty}\dfrac{\binom{2n}{n}}{2^{2n}(n+1)}
$$",['sequences-and-series']
914680,Distribution of n binomial trials with probability 1/i as n goes to infinity,"Consider flipping $n$ independent coins -- the $i$-th coin flipped has probability of $\frac{1}{i}$ of being heads, and tails otherwise (in particular, the first coin is always heads). For example, with $3$ coins, the first coin is 100% heads, the second is 50% heads, and the third is $\frac{100}{3}$% heads. As $n$ goes to infinity, can you proof or disproof that for any given positive integer constant $k$, the probability that there will be at least $k$ heads is $1$?","['probability', 'limits']"
914691,$G$ is torsion-free $[G:Z(G)]$ is finite $\implies$ $G$ is abelian ?,"If $G$ is a a group having no non-identity element of finite order and $Z(G)$ , the center of the group , has finite index , then is it true that $G$ is abelian ?","['group-theory', 'abelian-groups']"
914713,complement of zero set of holomorphic function is connected,"I'm stuck with the following part of exercise 1.1.8 in Hubrechts book Complex geometry : Prove that, if $U \subset \mathbb C^n$ is open connected, then $U \setminus Z(f)$, the complement of zero set of a non trivial holomorphic function $f:U\to \mathbb C$, is connected. I know I could use Riemann extension theorem, but I'm messing things with this point: suppose $U \setminus Z = A \cup B$ with $A$ and $B$ open non-empty disjoint; how do I see that there's point $x \in \overline A \cap \overline B \cap Z$?","['general-topology', 'complex-geometry', 'complex-analysis']"
914734,Proving that the cardinality of a set is even,"Let $E$ be a set and $f:E\to E$ be a function such that $f\circ f=Id$ . Let $A=\{x\in E, f(x)\neq x\}$ . Suppose that $A$ is finite. Prove that the cardinality of $A$ is even. My idea is to rewrite $A$ as a disjoint union of sets with even cardinality, but I've been unsuccessful so far. I noticed that $f$ acts as a permutation over the elements of $A$ . What should I do next ?","['cardinals', 'elementary-set-theory', 'functions']"
914774,Generating series - Finite groups of order $n$,"I am wondering if something of interest can be said about one of the two series $$G_1(x)=\sum_{n=1}^{+\infty}{\mathcal{G}(n)z^n}$$
$$G_2(s)=\sum_{n=1}^{+\infty}{\frac{\mathcal{G}(n)}{n^s}}$$ where $\mathcal{G}(n)$ is the number of finite groups of order $n$. (I don't even know if those series are converging for any $z$ or $s$...) Thanks a lot !","['generating-functions', 'finite-groups', 'complex-analysis']"
914789,Kernel density estimation in the limit of infinity many samples,"Let ($x_1, ..., x_n$) be i.i.d. samples drawn from some distribution $P$ with an unknown probability density function $f$. Its kernel density estimator is
\begin{align}
    \hat{f}_h(x) = \frac{1}{n}\sum_{i=1}^n K_h (x - x_i) \quad = \frac{1}{nh} \sum_{i=1}^n K\Big(\frac{x-x_i}{h}\Big),
\end{align}
where $K$ a symmetric non-negative function that integrates to one. I am interested what happens in the limit $n \to \infty$. Are there any publications that prove 
\begin{align}
    \hat{f}_h(x) &= \int K_h (x - x_i) \text{d}x \quad \text{or} \\
&= \int K_h (x - x_i) \text{d}P ?
\end{align}
Is then in the limit $\hat{f}_h(x) = f$?","['statistics', 'measure-theory', 'probability']"
914790,$C^{k}$-manifolds: how and why?,"First of all, I have a specific question. Suppose $M$ is an $m$ -dimensional $C^k$ -manifold, for $1 \leq k < \infty$ . Is the tangent space to a point defined as the space of $C^k$ derivations on the germs of $C^k$ functions near that point? If so, is it $m$ -dimensional? Bredon's book Topology and Geometry comments that (p.77) only in the $C^\infty$ case can one prove that every derivation is given by a tangent vector to a curve. If so, this would suggest that (if indeed given this definition), the tangent space to a $C^k$ -manifold would be bigger in the case $k < \infty$ . Additionally, out of curiosity, would anybody have an example of a derivation that is not a tangent vector to a curve? Secondly, it would seem to me that a fair share of the things I learned about smooth manifolds should fail or at least require more elaborate proofs in the $C^k$ case. We only used higher derivatives in proving Sard's theorem, but all the time we used the identification that the tangent space is  given by tangent vectors to curves; the tubular neighborhood theorem comes to mind. What are the standard facts of smooth manifolds that do fail in the $C^k$ case? Thirdly, are they really important? It seems a lot of books deal only with smooth manifolds, but a fair share also seem to deal with $C^k$ -manifolds; Hirsch's Differential Topology deals with them all throughout, and Duistermaat & Kolk's book Lie groups (p.1) defines them as $C^2$ -manifolds. Should I, as a student of topology / geometry, be paying close attention to $C^k$ -manifolds and the distinctions with the smooth case?","['differential-topology', 'manifolds', 'differential-geometry']"
914792,The Shortest Distance Between 2 Points On The Earth,"Assuming that the earth is a perfect sphere with radius 6378 kilometers, what is the expected straight line distance through the earth (in km) between 2 points that are chosen uniformly on the surface of the earth?",['calculus']
914804,"Vector space of continuous $[0,1] \to [0,1]$ over $\Bbb R$","Is there a way to define a vector space of continuous functions of type $[0,1] \to [0,1]$ over $\mathbb R$? If no, how to prove that such a vector space does not exist?","['vector-spaces', 'linear-algebra', 'abstract-algebra']"
914827,"Proof that $A^2 = A$ where A and B are square matrices , if $BA = B$ and $AB = A$. What did I do wrong?","The problem Given that for square matrices $A$ and $B$ of the same order, $AB = A$ $BA = B$ Prove that $A^{2} = A$. My proof $$
\text{Starting with the given condition ,}\\
BA = B\\
\text{Premultiplying } B^{-1} \text{ to both sides , we get ,}\\
(B^{-1} \cdot B )\cdot A = (B^{-1} \cdot B )\\
\text{so , }\ \ \ I \cdot A = I\\
\text{or , }\ \ \ A = I\\
\text{Therefore }\ \ \ A^2 = I^2 = I = A
$$ According to my teacher , this is wrong and not how it should have been proved.
I couldn't yet see what I did wrong , could some one please tell me where I made a mistake .","['matrices', 'proof-verification']"
914839,Evaluate $ \lim n \left[ 1-\frac{(n+1)^n}{en^n}\right] $,"Evaluate the following limit of sequence $$\lim_{n\to +\infty} n \left[ 1-\frac{(n+1)^n}{en^n}\right] $$ I've transformed it in a 0/0 inequality and tried to apply L'Hospital one time, but the function seems even more complicated. Thanks in advance!","['sequences-and-series', 'calculus', 'limits']"
914876,O Notation and taylor series,"Wolframalpha tells me that the Taylor series of the exponential function is $1 + x + \frac{x^2}{2}+ O(x^3).$ Taylor series I just don't get this big O there, shouldn't this be a small o?","['sequences-and-series', 'calculus', 'real-analysis', 'analysis']"
914885,Problem EA 13.2 from David Williams' Probability with Martingales,"I am stuck trying to solve this problem from Williams' Probability with Martingales: My attempt: $E(X_n) = E(e^{aS_n - bn})$ $= e^{-bn}E(e^{aS_n})$ (because $e^{-bn}$ is not random) $= e^{-bn}E(e^{a\xi_1}e^{a\xi_2}...e^{a\xi_n})$ (by definition of $S_n$) $= e^{-bn}E(e^{a\xi_1})E(e^{a\xi_2})...E(e^{a\xi_n})$ (independence) $= e^{-bn} (e^{1/2 a^2})^n $ (using the formula in the problem statement) $= e^{n(1/2a^2 - b)}$. Now this goes to $0$ iff $1/2a^2 - b < 0$, and goes to $\infty$ if $1/2a^2 - b > 0$. I am assuming $X_n \rightarrow 0 , a.s. \iff E(X_n) \rightarrow 0$ because $X_n \geq 0$ Thank you very much for your help in advance.","['probability-theory', 'measure-theory']"
914887,Solving a logarithmic expression without a calculator,"How do I find the value of this logarithmic expression without using a calculator? I'm trying to relearn algebra, but this problem has me scratching my head, and my Google tutorial searches are failing me. $2^{\log_2 10}$","['logarithms', 'algebra-precalculus']"
914896,Convergence of the series $\sum\limits_{n=3}^\infty (\log\log n)^{-\log\log n}$,I am trying to test the convergence of this series from exercise 8.15(j) in Mathematical Analysis by Apostol: $$\sum_{n=3}^\infty \frac{1}{(\log\log n)^{\log\log n}}$$ I tried every kind of test. I know it should be possible to use the comparison test but I have no idea on how to proceed. Could you just give me a hint?,['sequences-and-series']
914932,Integrable combinations - I can't seem to arrive at the given answer,"I need help! I can't seem to arrive at the answer given in our textbook. I'm new here, so I really need help. The instruction says that I need to solve this D.E by recognizing integrable combinations. $$
y(x^4 e^{xy} - y^2) \, dx + x(x^4e^{xy} + y^2) \, dy = 0 
$$
when $x = 1$, $y = 0$. And I can't seem to arrive this answer:
$$
y^2 = x^2(1 - e^{xy})
$$ Here is my sol'n:","['ordinary-differential-equations', 'calculus', 'integration', 'derivatives']"
914947,$\sup$ norm of a function,"The following is an example of Murphy's C*-algebras and operator theory: I do not know how he concludes $$\int_0^1 |k(s,t) - k(s',t)||f(t)| dt \leq \sup|k(s,t) - k(s',t)|||f||_\infty$$ Please help me. Thanks for your help.","['compact-operators', 'banach-spaces', 'operator-theory', 'normed-spaces', 'functional-analysis']"
914953,"If $f(x+y)=f(x)+f(y)$ and $f$ is monotone, prove that $f(x)=ax$","Suppose $f:\Bbb{R}\to\Bbb{R}$ is a monotone function satisfying $$f(x+y)=f(x)+f(y) \quad \forall \ x,y\in\Bbb{R}$$ Prove that $$\exists a\in \Bbb R,\forall x\in\Bbb{R}, f(x)=ax $$ I proved that $f(x)=ax \quad \forall x\in \Bbb{Q}$ . Assume it is monotonically increasing. Now let $\alpha$ be any irrational number. Then, choose sequences $\{x_n\}$ increasing to $\alpha$ and $\{y_n\}$ decreasing to $\alpha$ . Thus, $$f(x_n)\le f(\alpha)\le f(y_n)$$ i.e. $$ax_n\le f(\alpha)\le ay_n$$ Now, letting $n\to \infty$ ,  we get $f(\alpha)=a\cdot \alpha$ Is my proof correct for irrationals?","['proof-verification', 'real-analysis']"
914957,What is $f(f^{-1}(A))$?,"Suppose that $f : E \rightarrow F$. What is $f(f^{-1}(A))$? Is it always $A$? $f^{-1}$ is the inverse function. This is not a homework, I'm confused by this statement.","['elementary-set-theory', 'functions']"
914967,"Are all triangles where ""$a^2 = b^2+ c^2$"", right-angled?","For a right angle triangle, you can say that the square of the hypotenuse is equal to the sum of the squares of the other two sides.  Does the converse hold, ie. can you also say that, if the square of the hypotenuse is equal to the sum of the squares of the other two sides, then the triangle MUST be right-angled?","['trigonometry', 'triangles']"
914994,Legendre's formula,"Legendre's formula counts the number of positive integers less than or equal to a number $x$ which are not divisible by any of the first $a$ primes:
$$\begin{align}
&\phi(x,a)=\lfloor x \rfloor-\sum_{p_i\le a}\left\lfloor \dfrac{ x }{(p_i)}\right\rfloor+\sum_{p_i<p_j\le a}\left\lfloor\dfrac{ x}{(p_ip_j)}\right\rfloor-\sum_{p_i<p_j<p_k\le a}\left\lfloor \dfrac{x}{(p_ip_jp_k)}\right\rfloor+\dots
\end{align}$$
then
$\pi(x)=\phi\bigl(x,\pi (\sqrt{x})\bigr)+\pi (\sqrt{x})-1$ as given here . My question is, why does $\bigl\lfloor\phi(x,\lfloor\sqrt{x}\rfloor)+\sqrt{x}-1\bigr\rfloor$ also equal $\pi(x)?$","['prime-numbers', 'number-theory']"
915033,Is this function concave or can it be made concave?,"I am working with a point process with an event arrival rate of: $$ \lambda(t) =  \mu +  \sum\limits_{t_i<t}{\alpha e^{-\beta(t-t_i)}}$$ where $ t_1,..t_n $ are the event arrival times. The log likelihood function is therefore: $$  - t_n \mu + \frac{\alpha}{\beta} \sum{( e^{-\beta(t_n-t_i)}-1 )} + \sum\limits_{i<j}{\ln(\mu+\alpha e^{-\beta(t_j-t_i)})} $$ To obtain the maximum likelihood estimate (MLE) I need to maximize this log likelihood function under the restrictions that $\mu, \alpha, \beta > 0$ and $\beta > \alpha$. Is the log likelihood function concave? The parameters are  $\mu, \alpha, \beta$. If not, is there a reparameterization that would make it concave? In R code the log likelihood is l.loglik <- function(params, data, opt=TRUE) {
  mu <- params[1]
  alpha <- params[2]
  beta <- params[3]
  t <- sort(data)
  r <- rep(0,length(t))
  for(i in 2:length(t)) {
    r[i] <- exp(-beta*(t[i]-t[i-1]))*(1+r[i-1])
  }
  loglik <- -tail(t,1)*mu
  loglik <- loglik+alpha/beta*sum(exp(-beta*(tail(t,1)-t))-1)
  loglik <- loglik+sum(log(mu+alpha*r))
  if(!opt) {
    return(list(negloglik=-loglik, mu=mu, alpha=alpha, beta=beta, t=t,
                r=r))
  }
  else {
    return(loglik)
  }
}","['statistics', 'convex-optimization', 'optimization']"
915051,Inequality of Positive-definite matrix.,"In this question matrix $A$ is positive-definite if and only if $\forall x\ne0 :x^TAx>0$. ($A$ is not necessarily symmetric) Let $D$ be a positive-definite matrix such that it has block form: $$D=\left( \begin{array}{cc}
A & C  \\
C^T & B  \end{array} \right)$$ How can we prove that $\det D\leq\det A\det B$? EDIT1: From the perspective of the first answer I want to sum up something. It's true that $$D=\left( \begin{array}{cc}
A & C  \\
C^T & B  \end{array} \right)=\left( \begin{array}{cc}
I & 0  \\
C^TA^{-1} & I  \end{array} \right)\left( \begin{array}{cc}
A & C  \\
0 & B-C^TA^{-1}C  \end{array} \right)$$ so $\det D=\det A\det (B-C^TA^{-1}C)$. It's also true that $\det A>0$ because every real eigenvalues of $A$ is greater than $0$ and all complex eigenvalues exist in pairs. Now we need to prove that $$\det B>\det(B-C^TA^{-1}C)$$ The usual way when $A$ and $B$ are symmetric haven't worked yet because: (1) we don't know for sure if $(B-C^TA^{-1}C)$ is definite positive and (2) we don't know for sure if $\det(M+N)>\det(N)$ if $M$ and $N$ are definite positive. I also want to point out that definite positive matrices (in this question) can have complex eigenvalues. It would be great if you answer with details, not with references since almost every references consider positive-definite matrices to be symmetric.","['matrices', 'linear-algebra']"
915054,"Simpler closed form for $\sum_{n=1}^\infty\frac{\Gamma\left(n+\frac{1}{2}\right)}{(2n+1)^4\,4^n\,n!}$","I'm trying to find a closed form of this sum:
$$S=\sum_{n=1}^\infty\frac{\Gamma\left(n+\frac{1}{2}\right)}{(2n+1)^4\,4^n\,n!}.\tag{1}$$ WolframAlpha gives a large expressions containing multiple generalized hypergeometric functions, that is quite difficult to handle. After some simplification it looks as follows:
$$S=\frac{\pi^{3/2}}{3}-\sqrt{\pi}-\frac{\sqrt{\pi}}{324}\left[9\,_3F_2\left(\begin{array}{c}\tfrac{3}{2},\tfrac{3}{2},\tfrac{3}{2}\\\tfrac{5}{2},\tfrac{5}{2}\end{array}\middle|\tfrac{1}{4}\right)\\+3\,_4F_3\left(\begin{array}{c}\tfrac{3}{2},\tfrac{3}{2},\tfrac{3}{2},\tfrac{3}{2}\\\tfrac{5}{2},\tfrac{5}{2},\tfrac{5}{2}\end{array}\middle|\tfrac{1}{4}\right)+\,_5F_4\left(\begin{array}{c}\tfrac{3}{2},\tfrac{3}{2},\tfrac{3}{2},\tfrac{3}{2},\tfrac{3}{2}\\\tfrac{5}{2},\tfrac{5}{2},\tfrac{5}{2},\tfrac{5}{2}\end{array}\middle|\tfrac{1}{4}\right)\right].\tag{2}$$ I wonder if there is a simpler form. Elementary functions and simpler special funtions (like Bessel, gamma, zeta, polylogarithm, polygamma, error function etc) are okay, but not hypergeometric functions. Could you help me with it? Thanks!","['closed-form', 'special-functions', 'sequences-and-series', 'calculus', 'hypergeometric-function']"
915070,Solve $T(n) = 1 +\sum_{i=0}^{n-1}T(i)$ [duplicate],This question already has answers here : How do you solve a recurrence with a summation function inside: $t(n) = 1 + \sum\limits_{j=0}^{n-1} t(j)$ (3 answers) Closed 4 years ago . For the recurrence defined by $$T(n) = 1 +\sum_{i=0}^{n-1}T(i)$$ Apparently $T(n) = 2^n$ .. but I cannot see it. This recurrence pops up during analysis of the Rod Cutting Problem . I keep looking to find a viewpoint to look at this problem where the factors of 2 pop out ..,"['summation', 'discrete-mathematics', 'recurrence-relations']"
915083,"Integral ${\large\int}_0^1\ln(1-x)\ln(1+x)\ln^2x\,dx$","This problem was posted at I&S a week ago, and no attempts to solve it have been posted there yet. It looks very alluring, so I decided to repost it here: Prove:
  $$\int_0^1\ln(1-x)\ln(1+x)\ln^2x\,dx=24-\frac{4\pi^2}3-\frac{11\pi^4}{720}-12\ln2\\+2\ln^22-\frac16\ln^42+\pi ^2\ln2+\frac{\pi^2}6\ln^22-4\operatorname{Li}_4\!\left(\tfrac12\right)-\frac{35}4\zeta(3)+\frac72\zeta(3)\ln2.$$ I found a paper where some similar integrals are evaluated: J. A. M. Vermaseren , Harmonic sums, Mellin transforms and Integrals, Int. J. Mod. Phys. A, 14 (1999), 2037-2076, DOI: 10.1142/S0217751X99001032 , but it's not quite easy to read for me. Maybe it could be of some help for this problem.","['calculus', 'definite-integrals', 'logarithms', 'harmonic-numbers', 'polylogarithm']"
915112,Convergence of Integral near 0,"I am trying to determine the convergence of the integral
\begin{equation}
\int_0^1 \frac{f(x)}{x}\, dx
\end{equation}
given that $f(x)$ is bounded and continuous on $[0,1]$, and that $f(x)=0$.  The boundedness is just so that the question of convergence is only at the point $x=0$.  I specifically want $f$ to be only continuous on $[0,1]$ and not differentiable in a neighborhood of the origin as I could just use a Taylor expansion of $f$ to solve the problem then. I believe that the integral should converge but I can't figure out exactly how to write it down.  Since $1/x$ is the critical exponent of convergence near $0$ it seems that multiplying $1/x$ by any function which vanishes at the origin should be enough to make the integral converge.  More concretely, if $f(x)=x^{1/n} log(x)^m$ then $\lim_{x \to 0} f(x)=0$ for all positive values of $n$ and $m$, and $\int_0^1 f(x)/x \, dx < \infty$.  The derivative of these $f$ become infinite as $x\to 0$, and at faster rates for larger $m$ and $n$, so they are good candidates for $\int f(x)/x$ to not converge, yet the integral still converges. Any suggestions for a proof, or a counterexample to show the integral does not always converge would be much appreciated.","['improper-integrals', 'integration', 'real-analysis']"
915146,Three-space property,"I have found two definitions of a three-space property. One definition is: $(P)$ is a three-space property if whenever $E$ Banach space, $F\subseteq E$ is a closed linear subspace and two of the space $E$, $F$ and $E/F$ have $(P)$, then all the three spaces have $(P)$. The other case is: $(P)$ is a three-space property if whenever $E$ Banach space, $F\subseteq E$ is a closed linear subspace and $F$ and $E/F$ have $(P)$, then $E$ has $(P)$ too. Are these two definition equivalent? I have a problem when I try to prove $E/F$ has the property when $E$ and $F$ has the property. Any help would be welcome. Thanks in advanced.","['general-topology', 'functional-analysis', 'banach-spaces']"
915154,Simplify rational expression,How do I simplfy this expression? $$\dfrac{\frac{x}{2}+\frac{y}{3}}{6x+4y}$$ I tried to use the following rule $\dfrac{\frac{a}{b}}{\frac{c}{d}}=\frac{a}{b}\cdot \frac{d}{c}$ But I did not get the right result. Thanks!!,"['rational-functions', 'algebra-precalculus']"
915174,Solve $xy(1+xy^2)\frac {dy}{dx}=1$,"Solve $xy(1+xy^2)\frac {dy}{dx}=1$ Tried to solve it as an exact ODE, but it didnt work.",['ordinary-differential-equations']
915175,"Prove $\int_{0}^{\pi/2} \ln \left(x^{2} + (\ln\cos x)^2 \right) \, dx=\pi\ln\ln2 $","How to prove
  $$
\int_{0}^{\pi/2}\ln\left(\,x^{2} + \ln^{2}\left(\,\cos\left(\,x\,\right)\,\right) \,\right)\,{\rm d}x\ =\ \pi\ln\left(\,\ln\left(\, 2\,\right)\,\right)
$$ I don't know how to answer it. When I asked this integral to my brother, after less than half hours he said it has a nice closed-form involving $\pi$ and $\ln\left(2\right)$ but, as always, he didn't tell me the closed-form and how to obtain it ( I didn't believe him and I think he tried to mess around with me ). I have also searched the similar question here but it looks like nothing is similar or related. Could anyone here please help me to obtain the closed form of the integral preferably with elementary ways ( high school methods )?. Any help would be greatly appreciated. Thank you. Edit: He is being a little bit nice to me today, he said the closed form is $\pi\ln\ln2$ and it's numerically correct. This is not a duplicate problem, I am looking for a proof without using complex analysis.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
915205,How to solve 0.5 choose 4?,"I was solving this problem for homework. It says, in the problem, that if n is positive you use the generalized definition of binomial coefficients. In my case, n is positive so I just plugged n= 0.5 and r=4 into the equation n!/r!(n-r)!. However, now I'm having issues solving (n-r)! because I'm having to take the factorial of a negative number. Can someone just explain how I would go about solving this part?","['binomial-coefficients', 'probability']"
915219,Interesting identity arising from fractional factorial design of resolution III,"I am learning about statistical design of experiments, and in the process of mathematically rigorizing the concepts behind fractional factorial designs of resolution III, I derived an interesting equation: $$k = \sum_{i=1}^{3}{\lceil{\log_2{k}}\rceil \choose i},$$ for which the solutions $k$ are the Mersenne primes. How can I show this? Is the above equation algebraic? Is it even solvable analytically?","['statistics', 'ceiling-and-floor-functions']"
915238,"When $n$ is divided by $14$, the remainder is $10$. What is the remainder when $n$ is divided by $7$?","I need to explain this to someone who hasn't taken a math course for 5 years . She is good with her algebra. This was my attempt: Here's how this question works. To motivate what I'll be doing,
  consider  \begin{equation*} \dfrac{5}{3} = 1 + \dfrac{2}{3}\text{.}
\end{equation*} This is because when 5 is divided by 3, 3 goes into 5
  once (hence the $1$ term) and there is a remainder of $2$ (hence the
  $\dfrac{2}{3}$ term). Note the following: every division problem can
  be decomposed into an integer (the $1$ in this case) plus a fraction,
  with the denominator being what you divide by (the $3$ in this
  case) . So, when $n$ is divided by 14, the remainder is 10. This can be
  written as  \begin{equation*} \dfrac{n}{14} = a + \dfrac{10}{14}
\end{equation*} where $a$ is an integer. We want to find the remainder when $n$ is divided by 7, which I'll
  call $r$. So \begin{equation*} \dfrac{n}{7} = b + \dfrac{r}{7}\text{,}
\end{equation*}  where $b$ is an integer. Here's the key point to notice: notice that  \begin{equation*}
\dfrac{n}{7} = \dfrac{2n}{14} = 2\left(\dfrac{n}{14}\right)\text{.}
\end{equation*} This is because $\dfrac{1}{7} = \dfrac{2}{14}$. Thus, \begin{equation*} \dfrac{n}{7} = 2\left(\dfrac{n}{14}\right) =
2\left(a + \dfrac{10}{14}\right) = 2a + 2\left(\dfrac{10}{14}\right) =
2a + \dfrac{10}{7} = 2a + \dfrac{7}{7} + \dfrac{3}{7} = (2a+1) +
\dfrac{3}{7}\text{.} \end{equation*} So, since $a$ is an integer, $2a
+ 1$ is an integer, which is our $b$ from the original equation. Thus, $r = 3$. To her, this method was not very intuitive. She did understand the explanation. Are there any suggestions for how I can explain this in another way?","['education', 'algebra-precalculus']"
915242,Showing that $ \int_{0}^{\pi / 4} \arctan \! \left( \sqrt{\frac{\cos 2x}{2 \cos^{2} x}} \right) \mathrm{d}{x} = \frac{\pi^{2}}{24} $.,"I was wondering if an expert in integration could kindly solve the following problem, which was posed in a mathematics competition (I can’t remember which one) and was unsolved by any participant. Problem. Show that
  $$
  \int_{0}^{\pi / 4}
  \arctan \! \left( \sqrt{\frac{\cos 2 x}{2 \cos^{2} x}} \right)
  \mathrm{d}{x}
= \frac{\pi^{2}}{24}.
$$ Thanks!","['definite-integrals', 'trigonometry', 'pi']"
915249,Subgroups of Symmetric groups isomorphic to dihedral group,"Is $D_n$, the dihedral group of order $2n$, isomorphic to a subgroup of $S_n$ ( symmetric group of $n$ letters) for all $n>2$?","['finite-groups', 'group-theory', 'abstract-algebra']"
915282,Probability You Choose at least one chip of every color,"There are 16 chips: 6 red, 7 white, and 3 blue. 4 chips are selected randomly and are not replaced once selected. What is the probability that at least one chip of every color is selected? I'm not every good at figuring out how to create an equation of probability for these ""at least one of each kind"" problems. Thanks for your help and kindness in advance. It is much appreciated.","['statistics', 'probability', 'combinatorics']"
915287,Riesz-Markov-Kakutani Theorem: Various Versions,"The Riesz-Markov-Kakutani theorem usually comes in various versions. So I'm a little bit confused and wondering which of these are right. Let $\Omega$ be a locally compact space. Then: Complex Measures: $\mathcal{M}(\Omega,\mathcal{B}(\Omega))\cong\mathcal{C}_c(\Omega)^*$ Regular Measures: $\mathcal{M}_r(\Omega,\mathcal{B}(\Omega))\cong\mathcal{C}_c(\Omega)'$ Positive Measures: $\mathcal{M}_p(\Omega,\mathcal{B}(\Omega))\cong\mathcal{C}_c(\Omega)°$ where $X^*$ denotes the linear functionals, $X'$ the continuous linear functionals and $X^*$ the positive linear functionals $f:X\to\mathbb{C}$.
The first two equivalences are meant in the sense of vector spaces whereas the last one only as something in the sense of cones I guess.","['general-topology', 'measure-theory', 'functional-analysis']"
915290,Find vector field given curl,"I have an equation $\nabla \times \vec{B} = \mu_{0}\vec{J}$, where $\vec{J} = \left\langle f(x,y), g(x,y), 0 \right\rangle$ and need to solve for $\vec{B}$. I've looked elsewhere on here for how to ""undo"" the curl operator, but every answer I've found has been very theoretical and abstract, and I was hoping to get a more concrete explanation for this particular problem. Breaking down the curl of $\vec{B}$ into components and partial derivatives, I got: $$\frac{\partial B_{2}}{\partial x} - \frac{\partial B_{1}}{\partial y} = 0$$$$\frac{\partial B_{3}}{\partial y} - \frac{\partial B_{2}}{\partial z} = \mu_{0} f(x, y)$$$$\frac{\partial B_{1}}{\partial z} - \frac{\partial B_{3}}{\partial x} = \mu_{0} g(x, y)$$ And from here I'm stuck. Other examples with explicit functions have used guesswork to figure out the components, but I'm having trouble with the arbitrary functions of $f(x,y)$ and $g(x,y)$.","['multivariable-calculus', 'vector-fields', 'partial-differential-equations', 'curl', 'vector-analysis']"
915319,formula for infinite sum of a geometric series with increasing term,"I'm looking for the Expectation of the discrete random variable X, E[X], with pmf: $$p(x)=(\frac 16)^{x+1}, x=0,1,2,3...$$ so what I tried is as follows... $$E[X]= \sum_{0}^\infty xp(x) =$$ so then $$=\sum_0^\infty x(\frac 16)(\frac 16)^x =     \frac 16\sum_{0}^\infty x(\frac 16)^x $$ which is $$ \frac 16 [0(\frac 16)^0+1(\frac 16)^1+2(\frac16)^2+3(\frac 16)^3+...] $$ so if we were to use the rule that: $$ \sum_0^\infty ar^x = \frac {a}{(1-r)} $$ when |r|<1. Then it seems like the difference between that formula and my problem is the increasing coefficient on the (1/6)^x... My math book (which doesn't really say anything more about it)... states that ""there is a general increasing geometric series relation which is $$1 + 2r + 3r^2 + 4r^3+...= \frac {1}{(1-r)^2} $$ is that what I need to know? and if so, can someone please show me why? Thanks!","['sequences-and-series', 'calculus', 'probability']"
915342,Evaluation of a class of continued fractions,"Is there a closed-form way of writing the continued fraction:
$$
1 + \frac{2}{3+ \frac{4}{5 + \frac{6}{7 + ...}}}
$$ EDIT: Since the above has been determined as $\frac{1}{\sqrt{e}-1}$, is there a similar expression for:
$$
2 + \frac{3}{4+ \frac{5}{6 + \frac{7}{8 + ...}}}
$$
More generally, are there general closed-form expressions for all continued fractions of the form:
$$
a_n = n + \frac{n+1}{(n+2) + \frac{n+3}{(n+4) + ...}} \\
f(x) = x + \frac{x+1}{(x+2) + \frac{x+3}{(x+4) + \cdots}} = x + \frac{x+1}{f(x+2)} \\
f(x) f(x+2) = xf(x+2) + x+1
$$
And can said closed form be extended to all real numbers? For example, I experimented with extending the sequence to negative values of n and found that for all negative odd $n, a_n = -1$.","['closed-form', 'sequences-and-series', 'continued-fractions', 'functional-equations']"
915349,Help with problem 1-5 from Calculus by Spivak (multiplying two inequalities together),"This question involves problem 5(viii) from chapter 1 of Spivak's Calculus, third edition. I'm a layman trying to teach myself some more advanced mathematics, and although I've been making slow progress through the book, this problem has me stumped. The question is as follows: If $0 \leq a < b$ and $0 \leq c < d$, prove $ac < bd$. This question has different answers, depending on whether $a$ and $b$ are equal to zero or not. I think the most difficult case is the one where $a, b \ne 0$, so that's the one I will use here. My attempt: In an earlier question, I've proved that if $a < b$ and $c > 0$ then $ac < bc$. This is done by multiplying: $(a < b)c = ac < bc$. From now on I will use the notation that Spivak uses, where $a < b$ means that $b - a$ is in $P$. This leaves me with $b - a$ and $d - c$, both in $P$. Spivak has established that this means you can multiply the two together. I will list the steps that I followed: $(b - a)(d - c) = bd - bc - ad + ac$ $ bd - bc - ad + ac = bd - (bc + ad - ac)$ $bd - (bc + ad - ac) = bd > (bc + ad - ac)$ $bd > (bc + ad - ac) = bd > (bc + ad > ac)$ $bd > (bc + ad > ac) = bd > bc + ad > ac$ This would appear to prove that $ac < bd$ (which is what the question asked) but the part $bd > bc + ad$ is quite obviously incorrect. Just a simple example proves this: If $2 > 1$ and $3 > 2$, then $6 > 7 > 2$. Intuition tells the me that the two seperate inequalities $bd > bc > ac$ and $bd > ad > ac$ are both correct, but I have no idea how I can formally get these inequalities to 'split', so to speak. Help would be much appreciated! ... Edited for spelling. And thanks for helping me with the problem guys!","['inequality', 'calculus']"
915362,Conditional probability: At least 3 kings given there are at least 2 kings in the hand of 13.,"My first ""conditional probability"" problem. Sorry for all the questions. My instructor doesn't make sense to the class. A hand of 13 cards is to be dealt at random and without any replacement from an ordinary deck of playing cards. Find the conditional probability that there are at least three kings in the hand given that the hand contains at least two kings. A deep, good, and thorough explanation would be tremendously appreciated. Thanks","['statistics', 'probability', 'combinatorics']"
