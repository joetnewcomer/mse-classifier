question_id,title,body,tags
1447549,Prove that the function $f(z)=(Arg z)^2$ is continuous in the punctured plane $\Bbb C \setminus\{0\}$,"I started this by considering the cases about $Arg (z)$ $$ Arg(z) =
\begin{cases}
\arctan(y/x),  & \text{if $x>0$ } \\
\pi+\arctan(y/x), & \text{if $x<0,y\ge 0$}\\
-\pi+\arctan(y/x), & \text{if $x<0,y< 0$}\\
\pi/2, & \text{if $x=0,y>0$}\\
-\pi/2, & \text{if $x=0,y<0$}\\
\undefind, & \text{if$x=0,y=0$}
\end{cases}$$
Now I am not getting the way to go further. So please Help me to do further things. Thank you in Advance.","['continuity', 'complex-analysis']"
1447551,"Prove that $\sigma$-algebra of subsets of $\mathbb{R}$ of the form $(a,\infty)$ contains all the intervals.","I want to prove that if a $\sigma$-algebra of subsets of $\mathbb{R}$ contains intervals of the form $(a,\infty)$, then it contains all the intervals. Proof: Let $\mathscr{B}$ to denote the $\sigma$-algebra defined above. We have that since $(a,\infty) \in \mathscr{B}$, then since it contains the complement, we have that it also contains the intervals of the form $(-\infty,b]$, i.e. $$(-\infty,b] \in \mathscr{B}$$
In particular, we have that $(a,b) \in \mathscr{B}$. It's enough to prove that:
$$[b, \infty) \in \mathscr{B}$$
$$[a,b] \in \mathscr{B}$$
$$[a,b) \in \mathscr{B}$$
$$(a,b) \in \mathscr{B}$$
This is clear, since: 
$$[b, \infty) = \bigcap_{k=1}^{\infty} (b-\frac{1}{n}, \infty)$$
$$[a,b] = \bigcap_{n=1}^{\infty} (a-\frac{1}{n},b+\frac{1}{n})$$
$$[a,b) = \bigcap_{n=1}^{\infty} (a,b+\frac{1}{n})$$
$$(a,b) = \mathscr{B} \backslash [(-\infty,a]\cup[b,\infty)]$$
Is this proof correct?","['lebesgue-measure', 'proof-verification', 'real-analysis', 'measure-theory']"
1447558,How do I teach university level mathematics to myself? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 8 years ago . Improve this question So here I go, I have enrolled myself in maths major this year but due to less marks in SSC I couldn't secure admission in a good university so I have to take admission wherever I could get with my marks. The problems is that teachers here are not qualified enough to teach mathematics properly and they teach horrible. I feel like studying on my would be much better than that. What makes the situation much worse is that most of the students are not at all interested in learning. They abhor it. 
But I'm interested in learning mathematics. In fact I love mathematics more than anything else in this world. But I don't know what is the best way to study higher level mathematics on my own. So here are my doubts: Is it possible to study university level mathematics on my own? If yes then how and what are resources that I will need? What are the best resources available on the web? Will I be as proficient in mathematics as the students from top universities who are taught by great teachers? What is the best piece of advice you will give me if I want to get into the field of coding/programming after completing my mathematics major? How do I develop myself overall during these three years in order to become a top notch mathematics student? I'm an average learner and love doing mathematics. The syllabus that I have to cover is : Calculus 2. Elementary Algebra 3. Analytical Geometry 4. Linear and abstract algebra 5. Differential calculus 6. Multivariate Calculus 7. Real and Numerical analysis 8. Probability and Statistics 8. Linear Programming 9. Discrete mathematics and 10. Mathematical modelling Answering this question rigorously will help many out there who are seeking answer to similar question.","['calculus', 'algebraic-geometry', 'self-learning', 'probability', 'linear-algebra']"
1447587,Can $\mathbb{Z}_8$ be the commutator subgroup of a group?,I was trying to construct examples of groups with small derived subgroups. I get stuck in the construction of finite group with derived subgroup exactly equal to $\mathbb{Z}_8$. Does such group exists?,['group-theory']
1447591,Nilpotent matrix and relation between its powers and dimension of kernels,"Given a 4x4 matrix $T$ over $\mathbb{R}$ such that $T^4 = 0 $, $k_i = \textsf{dim} Ker(T^i)$, I need to check which of the following sequences, $$k_1\leq k_2 \leq k_3 \leq k_4,$$ is NOT possible : $ 1)\; 1\leq 3 \leq 4 \leq 4$ $2) \; 2\leq3\leq4\leq4$ $3) \; 3 \leq 4 \leq 4\leq 4$ $4)\; 2 \leq 4 \leq 4 \leq 4$ The only relevant thing I could recall relating to this is the fact that for nilpotent operators $$ \{0 \} \subset Ker(T) \subset Ker(T^2) \subset \ldots \subset Ker(T^{n-1})$$
But the equality in the choices is putting me off. A hint would be welcome. Thanks in advance.","['linear-algebra', 'nilpotence', 'matrices']"
1447603,"Are the subspaces $(0,1)$ and $[0,1)$ of $\mathbb{R}$ isometric?","Are the subspaces $(0,1)$ and $[0,1)$ of $\mathbb{R}$ isometric$?$ I think that this is false but I cannot figure out why. Progress . I see that I can remove $0$ from $[0,1)$ and this creates a non-disjoint set. I also see how removing any point from $(0,1)$ creates a disjoint set and thus we have two sets with differing topological properties and hence no homeomorphism can exist between the two. What I am not sure of is why no homeomorphism implies no isometry.","['metric-spaces', 'real-analysis', 'general-topology']"
1447621,Are there proper $1/2$ convex subsets of finite groups?,"According to this paper by N. H. Bingham and A. J. Ostaszewski , A subset $H$ of a group $G$ is said to be $1/2$ convex (or mid-point convex) if for each $x,y\in H$, there exist a unique element $z\in H$ satisfying the equation $z^2=xy$. My questions are, Can there be any $1/2$ convex proper subsets of finite groups? if not, why? What are the other notions of convexity on finite groups ?","['abelian-groups', 'abstract-algebra', 'group-theory', 'finite-groups', 'convex-analysis']"
1447623,Polar form (Modulus & Argument),Questions: a) Express $-4i$ in polar form b) Hence solve the equation $z^2 =-4i$ I've attempted the question and was only able to find $z=4$ using the form $r(\cos x+i\sin x)=z$. Could someone please show me or explain how to do step by step? Thankyou,"['complex-numbers', 'algebra-precalculus']"
1447634,Prove that a set is open,"I think this is right but hoping someone could verify that I am right, tell me a better way! I am trying to learn how to show that sets are open and closed. So I have a set that I wish to show is open $$
U = \{(x,y) \in R^{2}_{x}  | x+y < 1, x > 0, y >0 \}
$$ So I need to show that $$
B_{r}(a) = \{x \in U | d(x,a) < r\} 
$$
(not sure if $a \in U$ or $a\in R^2_+$) could someone clarify? if for all $x \in U$, $B_{r}(a) \in U $ then we can conclude that U is open So my first step was to let $ x = (x_1,y_1) \in U, a = (x_2, y_2) \in U$ and $r = 1 - \min(x_1,x_2) - \min(y_1,y_2)$ Then I said since: $\sqrt{ (x_1 - x_2)^2 + (y_1 - y_2)^2 } < |x_1 - x_2| + |y_1 - y_2| = \max(x_1,x_2) - \min(x_1,x_2) + \max(y_1,y_2) - \min(y_1,y_2) $ Then we can say: $\max(x_1,x_2) - \min(x_1,x_2) + \max(y_1,y_2) - \min(y_1,y_2) < 1 - \min(x_1,x_2) - \min(y_1,y_2)$ which implies: $\max(x_1,x_2) + \max(y_1,y_2) < 1 $ And since this last condition is true we can conclude that $B_r(a) \in U$ and therefore the set is open.","['real-analysis', 'general-topology']"
1447645,How to solve trigonometric equations in 2 variables?,"Find out both $x$ and $y$ , $$\cos(x)=-\cos(x+y)$$ I come up with this equation when I was finding out maxima and minima of a two variable function $$f(x,y)=\sin x+\sin y+\sin (x+y);$$ however I get a solution by hit and trial approach, that is $$x=y={\pi\over 3}$$ will satisfy this equation, but how to solve it, as I have many other problems of the same kind and this hit and trial is time consuming.","['multivariable-calculus', 'differential']"
1447659,Do Lie derivatives commute with divergence: $\mathcal{L}_\xi \nabla_\mu V^\mu = \nabla_\mu \mathcal{L}_\xi V^{\mu}$?,"So my question is: given a vector field $V^\mu$ on some manifold with metric tensor $g_{\mu\nu}$ is it necessarily true that
\begin{equation}
\mathcal{L}_\xi \nabla_\mu V^\mu = \nabla_\mu \mathcal{L}_\xi V^{\mu} \ ?
\end{equation} 
where $\nabla_\mu$ denote the covariant derivative satisfying the metric compatibility condition $\nabla_\lambda g_{\mu\nu} = 0$ and $\mathcal{L}_\xi$ is the Lie derivative. If so how do I show that?
If not, then is there any condition we could impose on $\xi$ such that this is true? i.e. Is it true if $\xi$ is a Killing vector or something like that?","['differential-geometry', 'lie-derivative']"
1447689,Are any zeros of Riemann zeta function and the zeros of the derivatives of Riemann zeta function same?,"All: Are any zeros of Riemann zeta function and the zeros of the derivatives of Riemann zeta function same ? They shall be all different, right ? Is there a proof of this statement ? Thank you.","['riemann-zeta', 'number-theory', 'elementary-number-theory', 'analytic-number-theory']"
1447692,Why is $\nabla \log{\det{X}} = X^{-1}$? Where did the trace go?,"I am studying Boyd & Vandenberghe's Convex Optimization and encountered a problem on page 642. According to the definition, the derivative $Df(x)$ has the form: $$f(x)+Df(x)(z-x)$$ and when $f$ is real-valued (i.e., $f : \Bbb R^n \to \Bbb R$ ), the gradient is $$\nabla{f(x)}=Df(x)^{T}$$ See the original text below: But when discussing the gradient of function $f(X)=\log{\det{X}}$ , author said ""we can identify $X^{-1}$ as the gradient of $f$ at $X$ "", please see below: Where did trace $\mbox{tr}(\cdot)$ go?","['derivatives', 'scalar-fields', 'matrix-calculus', 'matrices']"
1447712,Approximating intervals and squares by increasingly dense disjoint finite sets with special properties,"Apologies for the length of the question. Consider interval $I=[0,1]$. For any $n \in \mathbb{N}$ we can always find two finite sets $S_{1n} \subset I$ and $S_{2n} \subset I$ such that: a) $S_{1n}\cap S_{2n} = \emptyset$ b) There is at most one point from $S_{1n} $ between any two consecutive points of  $S_{2n}$. Similarly, there is at most one point from $S_{2n} $ between any two consecutive points of  $S_{1n}$. c) $H(S_{1n}, I) \rightarrow 0$ and $H(S_{2n}, I) \rightarrow 0$ as $n \rightarrow \infty$, where $H$ stands for the Hausdorff distance. E.g., we can always choose: 
$$S_{1n}=\left\{ \frac{k}{2^n}: \, k - \text{ odd }, \; 0 \leq k \leq 2^n\right\},$$
$$S_{2n}=\left\{ \frac{k}{2^n}: \, k - \text{ even }, \; 0 \leq k \leq 2^n\right\}.$$ Here is why property b) is interesting to me. For any given $n$, it holds that from any point $a \in (0,1)$ there is always a direction (right or left) to go where the first encountered point is going to be a point from  $S_{1n} $. Similarly, there is always a direction (right or left) to go where the first encountered point is going to be a point from  $S_{2n}$. A construction like this is not possible with three disjoint sets on $I$. $\star$ $\star$ $\star$ However, I wonder if something analogous is possible with three sets when we consider the square $I_2=[0,1]^2$. In a nutshell, I wonder if for $n \in \mathbb{N}$ we can always find three finite lattices $S_{1n} \subset I_2$, $S_{2n} \subset I_2$ and $S_{3n} \subset I_2$  such that: A*) Their projections $S^x_{1n}$, $S^x_{2n}$, $S^x_{3n}$ on the first coordinate are pairwise disjoint. Their projections $S^y_{1n}$, $S^y_{2n}$, $S^y_{3n}$ on the second coordinate are pairwise disjoint. B*) With any point $b=(b_1,b_2)\in \bigcup_{j=1}^3 S_{jn}$ associate a “cross”
$$\hat{b} = (b_1\times [0,1])\cup ([0,1]\times b_2).$$
Then for any $n$ construct the net from these “crosses”: 
$$W_n= \bigcup_{b \in S_{1n}  \cup S_{2n}  \cup S_{3n}}  \hat{b} $$ Here is a description of the property analogous to b). For any given $n$ and for any $j=1,2,3$, it holds that from any point $a \in Int(I_2)$ there is 
always a direction (either horizontal or vertical – so we have four possible directions now) to go where the first encountered point on $ W_n $ is going to be from a “cross” associated with a point from $S_{jn}$. C*) $H(S_{jn}, I_2) \rightarrow 0$as $n \rightarrow \infty$, $j=1,2,3$.","['analysis', 'approximation', 'discrete-mathematics']"
1447713,"Analytic function such that $f(1/n)=(-1)^n/n, n=1,2,\dots?$","Question is prove or disprove: There exists an analytic function such that  $f(1/n)=(-1)^n/n, n=1,2\dots$, with $0$ in the domain of $f.$ My attempt: If it exists, then clearly $f(z)=z^kg(z)$, where $k\ge0$ is the order of zero [or possible zero,I have included this by $k\gt0$] $z=0$ of $f(z).$Also,$g(0)\ne0$ So, $g(1/n)=f(1/n)n^k\implies g(1/n)=n^k\{\frac{(-1)^n}n\}$ Now the $\lim_{n\to\infty}\{\frac{(-1)^nn^k}n\}$ does not exist[of course,when $k\ge1$]$\implies g(0)$ doesn't exist. But this is a contradiction to my assumption that $f$ is analytic.So such an $f$ doesn't exist. And in case of $k=0$,above limit $\lim_{n\to\infty}g(1/n)=0$,which is again a contradiction. Is there something wrong in above procedure?Please guide me through if there is some.I'll appreciate any help towards this.Thanks in advance! PS:I stated that $g(0)\implies$ ""contradiction to my assumption that $f$ is analytic"".Well,I stated so because since by assumption $f$ is analytic and $z^k$ is entire[$k\ge0$],so $g$ must be analytic in the domain of $f$.",['complex-analysis']
1447730,Drawing Ellipse from eigenvalue-eigenvector.,"If I have two eigenvalue $\lambda_1$ and $\lambda_2$ and two associated normalized eigenvector $\mathbf e_1$ and $\mathbf e_2$ respectively, and I want to draw ellipse, How can I know which eigenvalue and eigenvector will construct the major axis and which one will be associated with minor axis ? Edit: The ellipse looks like the following :","['eigenvalues-eigenvectors', 'linear-algebra', 'conic-sections']"
1447738,Instance of Mean Value Theorem,"What's an elementary proof that there exists $c\in (a, b)$ with $$e^b-e^a=(b-a)e^c$$ without calculus, just using the standard properties of the exponential function? *By calculus I mean derivatives and integrals. The intermediate value theorem is fine, the mean value theorem is not. **Either elementary definition of the exponential function is fine, but I suspect that continuity, monotonicity and $e^{a+b}=e^a e^b$, $(e^{a})^b=e^{ab}$ should be more than enough to do this.","['analysis', 'calculus', 'exponential-function']"
1447744,Textbook on the differential geometry of fibre bundles,"I'm looking for a textbook on the differential geometry of fibre bundles containing a not too brief discussion of the following topics: Principal and associated bundles, (reduction of) structure groups . Ehresmann connections and their curvature Other common definitions of a connection on a bundle and various ways of organizing that information (connection forms etc.) Holonomy, mondromy and gauge groups Yang-Mils functionals Foliations and their holonomy Jet bundles Is there such a textbook? (By which i mean a book that contains exercise problems). If not, where can i find problem sets for these topics?","['book-recommendation', 'differential-geometry', 'fiber-bundles']"
1447773,Two conjectures of four squares,"I found a conjecture of four squares since two months ago. But I don't have a solution for the conjecture. This conjecture is nice result in Euclidean geometry. I hope that there is a solution: Conjecture 1: Let $A_iB_iC_iD_i$ for $i=1,2,3,4$ be four squares in a plane, with $A_i \rightarrow B_i \rightarrow C_i \rightarrow D_i$ all counter clockwise, (or all clockwise) for $i=1,2,3,4$. Then show that:
$$Area(A_1A_2A_3A_4)+Area(C_1C_2C_3C_4)=Area(B_1B_2B_3B_4)+Area(D_1D_2D_3D_4)$$ Conjecture 2: Let $O_X$ be the centroids of $X_1X_2X_3X_4$ for $X=A,B,C,D$ then show that $O_AO_BO_CO_D$ be a square.","['euclidean-geometry', 'geometry']"
1447793,How many triangles are there in the picture?,"There are eight points, connection between each other. See figure [1] In addition to the red dot, any three line segments do not intersect at one point. How many triangles are there in the picture? If you remove three segments, maximum number of triangles left? Thanks a lot!","['graph-theory', 'geometry']"
1447806,How to understand $G_{k_0}\bigcap R_n\subset D_n$?,"$G\subset R^N$ is a measurable set, $mG< +\infty$ ,and $\varphi_n(x)\rightarrow \varphi(x)$ in measure. $\sigma\in R,k_0\in Z^+$,$f(x,u)$ meets the Caratheodory condition
(for almost all of  $x\in G$,$f(x,u)$ is continue about $u$,and for every $u\in R$ ,$f(x,u)$ is a measurable function about $x$ on $G$). $$
G_{k_0}=\{x\in G:\forall u\in R,\text{ if } |u-\varphi(x)|<\frac{1}{k_0},
\text{ then } |f(x,u)-f(x,\varphi(x))|<\sigma
\}
$$ $$
R_n=\{x\in G:|\varphi_n(x)-\varphi(x)|<\frac{1}{k_0}\}
$$ $$
D_n=\{x\in G:|f(x,\varphi_n(x))-f(x,\varphi(x))|<\sigma
\}
$$
show that :  $G_{k_0}\cap R_n\subset D_n$","['analysis', 'measure-theory']"
1447837,Compute $\lim_{n\to +\infty}n\left(\tan\left(\frac{\pi}{3}+\frac{1}{n} \right)-\sqrt{3}\right)$ without using L' Hôpital,"Compute $$\lim_{n\to +\infty}n\left(\tan\left(\frac{\pi}{3}+\frac{1}{n} \right)-\sqrt{3}\right)$$ without using L'Hospital's rule. By using L'Hospital's rule and $$\tan'(  \Diamond  )=( \Diamond )'(1+\tan^{2}( \Diamond ))$$ I mean by $\Diamond $ a function
so I got \begin{align}
\lim_{n\to +\infty}n\left(\tan\left(\dfrac{\pi}{3}+\dfrac{1}{n} \right)-\sqrt{3}\right)
&=\lim_{n\to +\infty}\dfrac{\left(\tan\left(\dfrac{\pi}{3}+\dfrac{1}{n} \right)-\sqrt{3}\right)}{\dfrac{1}{n}}\\
&=1+\tan^{2}\left(\dfrac{\pi}{3}\right)=1+\sqrt{3}^{2}=1+3=4
\end{align} I'm interested in more ways of computing limit for this sequence.","['limits-without-lhopital', 'contest-math', 'calculus', 'limits']"
1447852,Compute this sum: $\sum_{k=0}^{n} k \binom{n}{k}$? [duplicate],This question already has answers here : How to prove this binomial identity $\sum_{r=0}^n {r {n \choose r}} = n2^{n-1}$? (10 answers) Closed 8 years ago . Compute this sum: $$\sum_{k=0}^{n} k \binom{n}{k}.$$ I tried  but I got stuck.,"['summation', 'binomial-coefficients', 'algebra-precalculus']"
1447894,Schubert calculus on Grassmannians,"Can anyone please suggest me some notes or books where I can read about Schubert calculus? I am studying Grassmannian varieties so I would like to understand how to use this tool, in particular with Grassmannians.","['algebraic-geometry', 'book-recommendation', 'schubert-calculus', 'grassmannian']"
1447917,Lie derivative w.r.t. time-dependent field,"Some time ago, I asked this question . CvZ answered, and with my additional answer I thought I had solved the problem. Yesterday evening, I copied those calculations into my thesis, and having $t$ and $s$ exchanged, I found myself in trouble as to whether I should have $\mathcal{L}_{X_t}$ or $\mathcal{L}_{X_s}$. This morning, I found this question , but it did not solve my problems, and actually it sparked more problems. It did confirm my problems were not only over-thinking. Now I have this time-dependent field $X_t$. I can defined its flow $\phi^s$ in the same way as always, i.e. by: $$\frac{d}{ds}\phi^s(p)\Big|_{s=t}=X_t(\phi^t(p)),\qquad\phi^0=id.$$ This way, when I take $x(s)=\phi^s(p)$, I follow an integral curve of the field $X_t$. I can then define the Lie derivative along $X_t$ as: $$\mathcal{L}_{X_t}\omega=\frac{d}{ds}(\phi^s)^\ast\omega\Big|_{s=0}.$$ But then, as the poster of the question I found this morning (second link) notices, $\mathcal{L}_{X_t}$ seems to be independent of $t$, i.e. for all $t,s\in\mathbb{R}$ it seems $\mathcal{L}_{X_t}=\mathcal{L}_{X_s}$ as an operator. Yet as soon as I try Cartan's formula I get an equality of this operator with something clearly time-dependent. My attempt to fix this brought me to something close to the poster of the above mentioned question. Precisely, I thought of $X_t$ as a family of fields, and defined a flow for each. So I ended up with $\phi^{s,t}$ satisfying: $$\frac{d}{ds}\phi^{s,t}(p)\Big|_{s=\tau}=X_\tau(\phi^{\tau,t}(p)),\qquad\phi^{0,\tau}=id.$$ This is pretty different from what the poster of the question did, because he required $\phi^{s,s}=0$ for all $s$, not $\phi^{0,s}$. So I was wondering why he did that. I also found this other question . There, it is suggested in a comment to lift everything up to $M\times\mathbb{R}$ and apply Cartan over there. Which is basically identical to my approach, including the requirement, since we will then have a flow over there which satisfies $\phi^0(t,p)=(t,p)$ for all $(t,p)$, so going back down with two-parameter flows we have $\phi^{0,t}(p)=p$ for all $t$. But if all this is really necessary, why did Hofer-Zehnder completely gloss over this in the proof of Darboux's theorem on symplectic manifolds? I mean, doing all this really seems like inventing an alternate proof in the attempt to explain an existing one…","['vector-fields', 'differential-geometry', 'differential-forms', 'lie-derivative']"
1447956,The Biharmonic Eigenvalue Problem on a Rectangle with Dirichlet Boundary Conditions,"I am interested in solving the following biharmonic eigenvalue problem. $$\begin{array}{cccc}
  & \Delta ^2  \Psi (x,y) = \lambda \Psi (x,y), & - a \le x \le a &  - b \le y \le b \\
  & x = \phantom{-}a & \Psi = 0 &   \dfrac{\partial \Psi }{\partial x} = 0 \\
  & x =  - a & \Psi = 0 &  \dfrac{\partial  \Psi }{\partial x} = 0 \\
  & y = \phantom{-}b & \Psi = 0 &  \dfrac{\partial  \Psi }{ \partial y} = 0 \\
 & y =  - b & \Psi = 0 &  \dfrac{\partial  \Psi }{ \partial y} = 0 
\end{array}
$$ where $$ \Delta ^2 \Psi  = \frac{\partial ^4 \Psi }{\partial x^4} + 2 \frac{\partial^4 \Psi }{\partial x^2 \partial y^2} + \frac{\partial ^4 \Psi }{\partial y^4}$$ $$\Psi  \in {{\bf{C}}^{\infty}}\left( {[ - a,a] \times [ - b,b]} \right)$$ To describe the problem in words, we are looking for the eigenfunctions of the biharmonic operator over a rectangular domain where all its derivatives are continuous. The boundary conditions are of Dirichlet type, i.e., the function and it's normal derivative are prescribed over the boundary of the rectangular domain. Facts and Motivations This problem occurs in many physical areas. One of the most famous ones is the vibration of a rectangular isotropic elastic clamp plate. It is believed among engineers that the problem doesn't have a closed form solution. It may be asked that even the problem has a solution or not. Numerical evidence shows that such a solution may exists. However, I am looking for some strong theoretical basis to prove the existence of the solution so I planned to ask this question in a society of mathematicians. After the existence is verified, one is definitely interested in looking for methods to compute these eigen-functions. Questions Is there any non-zero solution for this problem? In other words, I am asking an existence or non-existence theorem for this problem. This question is completely answered by TKS. According to TKS, it is an old result firstly proved by K. Friedrichs . Maybe the reason that many people are unaware of this is that the paper by K. Friedrichs is written in German entitled as Die Randwert- und Eigenwertprobleme aus der Theorie der elastischen Platten. (Anwendung der direkten Methoden der Variationsrechnung) The translation in English is The boundary value and eigenvalue problems in the theory of elastic plates. (Application of direct methods of variational calculus) Another short answer to this question is given by Jean Duchon on Math Over Flow . Assuming the existence, how can one compute these eigenvalues and eigenfunctions? Is there a closed form solution for this purpose? This question remained unanswered !","['real-analysis', 'functional-analysis', 'analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
1447988,Characterization of Topology,"Inspired by this question Comparison of Neighborhood Topology and Open Set Topology as well as many other similar questions asked here on Math SE. However, I could not prove it given my setup: Suppose that $\mathcal T\subseteq\mathcal P(X)$ and $\mathfrak N:X\rightarrow\mathcal P(\mathcal P(X))$ . Then it holds that $\mathcal T$ is a topology over $X$ and for each $x\in X$ and a subset $N$ of $X$ for which there exists $O\in\mathcal T$ such that $x\in O\subseteq N$ it holds that $N\in\mathfrak N(x)$ if and only if for each $x\in X$ it holds that $\mathfrak N(x)$ is a filter over $X$ , for each $N\in\mathfrak N(x)$ it holds that $x\in N$ and for each $N\in\mathfrak N(x)$ it holds that $\{z\in N:N\in\mathfrak N(z)\}\in\mathfrak N(x)$ and $\mathcal T = \{O\subseteq X\mid\forall x\in X:O\in\mathfrak N(x)\}$ . $$\\$$ In other words: $\mathcal T$ is a topology over $X$ and $N$ is a $\mathcal T$ -neighborhood for $x\in X$ (i.e. $N\in\mathfrak N(x)$ ) iff there exists a $O\in\mathcal T$ such that $x\in O\subseteq N$ if and only if for each $x\in X$ it holds that $\mathfrak N(x)$ is a filter over $X$ , for each $N\in\mathfrak N(x)$ it holds that $x\in N$ and for each $N\in\mathfrak N(x)$ it holds that $\{z\in N:N\in\mathfrak N(z)\}\in\mathfrak N(x)$ $O\subseteq X$ is $\mathfrak N$ -open (i.e. $O\in\mathcal T$ ) iff for each $x\in O$ it holds that $O\in\mathfrak N(x)$ The other questions could help me figuring out the importance and meaning of the respective axioms. Proving the equivalence is hard for me though. I have proved the "" $\Rightarrow$ ""-direction except for ""for each $N\in\mathfrak N(x)$ it holds that $\{z\in N:N\in\mathfrak N(z)\}\in\mathfrak N(x)$ "". Any hints?","['definition', 'general-topology']"
1447994,When can $*$-algebras be turned into $C^*$-algebas?,"Let $A$ be a (not necessarily unital) complex $*$-algebra, i.e. an algebra over $\mathbb{C}$ together with an involution $*: A \to A$. There exists at most one norm on $A$ turning $A$ into a $C^*$-algebra with respect to this norm. For instance, if $A = \mathcal{C}(X)$ where $X$ is a compact Hausdorff space, then the only norm on $A$ turning $A$ into a $C^*$-algebra is $\|f\| = \sup_{x \in X} |f(x)|$. However, there could still exist several or no norms on $A$ such that the completion of $A$ with respect to this norm becomes a $C^*$-algebra. For instance, if $A$ and $B$ are $C^*$-algebras and $A \otimes B$ is their algebraic tensor product, then this can be turned into a $*$-algebra in an obvious way, but in general there exists several norms on the tensor product that completes it into a $C^*$-algebra. I was wondering if there was any characterization of the $*$-algebras $A$ with the property that such a norm exists, or at least some necessary or sufficient conditions.","['c-star-algebras', 'operator-algebras', 'functional-analysis']"
1448050,How does Galois group acts on etale cohomology?,"I know this may be a trivial question, but I can't find the answer on, for example, Milne's online notes and Danilov's Cohomology of Algebraic Varieties. Suppose $K$ is a number field (say), $\overline K$ its algebraic closure, $G_K:=\text{Gal}(\overline K/K)$, $X$ is a variety over $K$, $\mathcal F$ is a locally constant (or constructible (?), don't know if it's true) abelian sheaf on $X_{\text{et}}$. It is said that for any $i\geqslant 0$, there is a continuous $G_K$ action on $H_{\text{et}}^i(X_{\overline K},\mathcal F)$. My question is, how can one define this action? I found the answer that if $i=1$ and $\mathcal F$ is the constant sheaf associated to an abelian group $A$, then $H_{\text{et}}^1(X_{\overline K},\mathcal F)=\text{Hom}(\pi_1^{\text{et}}(X_{\overline K}),A)$,
using the following exact sequence
$$
0\to\pi_1^{\text{et}}(X_{\overline K})\to
\pi_1^{\text{et}}(X)\to\pi_1^{\text{et}}(\text{Spec }K)\cong G_K\to 0
$$
we get the Galois action. But what about $i\neq 1$ or $\mathcal F$ is not constant sheaf? [EDIT] After viewing other questions on this site, I found that it is the proper base change theorem : if $f:X\to\text{Spec }K$ is proper, then there is a canonical isomorphism $H_\text{et}^i(X_{\overline K},\mathcal F_{\overline K})\xrightarrow\sim(R^if_*\mathcal F)_{\overline K}$, the latter is a $G_K$-module. (Complaint: this theorem is contained in notes I mentioned, but it relates etale cohomology to Galois representations is unmentioned, strange.) But what about $X$ not proper, for example $X=Y_1(N)$ the open modular curve? [EDIT2] Thanks for Roland's answer, but could anyone explain the simplest example: when $X=\text{Spec }k$, why does this definition of Galois action on $H_{\text{et}}^0$ coincides with the action given by the following category equivalence? \begin{align*}
\mathbf{Sh}\big((\text{Spec }k)_{\text{et}},\mathbf{Ab}\big)
&\cong\{\text{discrete abelian group with continuous }G_k\text{-action}\} \\
\mathcal F&\mapsto\varinjlim_{k'/k\text{ finite separable extension}}
\mathcal F(\text{Spec }k') \\
\big(\text{Spec }k'\mapsto A^{\text{Gal}(\overline k/k')}\big)&\leftarrow A
\end{align*} In fact, at first I thought I understand this category equivalence, but later I found that I didn't.","['galois-representations', 'algebraic-geometry', 'number-theory', 'etale-cohomology']"
1448073,"Closed form of $\ln^n \tan x\, dx$","Here is an integral I am really stuck at. I am pretty sure that a general closed form of the integral: $$\mathcal{J}=\int_0^{\pi/2} \ln^n \tan x\, {\rm d}x, \;\; n \in \mathbb{N}$$ exists. Well if $n$ is odd , then the integral is obviously zero due to symmetry. On the contrary if $n$ is even then the closed form I seek must contain the beta dirichlet function however I am unable to reach it. Setting $m=2n$ then: $$\int_{0}^{\pi/2}\ln^m \tan x\, {\rm d}x=\int_{0}^{\infty}\frac{\ln^m u}{u^2+1}\, {\rm d}u= 2\int_{0}^{1}\frac{\ln^m u}{u^2+1}\, {\rm d}u$$ If we expand the denominator in a Taylor series, namely $1+x^2=\sum \limits_{n=0}^{\infty} (-1)^n x^n$ then the last integral is written as: $$2\int_{0}^{1}\ln^m x \sum_{n=0}^{\infty}(-1)^n  x^n \, {\rm d}x = 2\sum_{n=0}^{\infty}(-1)^n \int_{0}^{1}x^n \ln^m x \, {\rm d}x = 2 \sum_{n=0}^{\infty}\frac{(-1)^n (-1)^m m!}{\left ( n+1 \right )^{m+1}}= 2 (-1)^m m! \sum_{n=0}^{\infty}\frac{(-1)^n}{\left ( n+1 \right )^{m+1}}$$ Apparently there is something wrong here. I used the result $$\int_{0}^{1}x^m \ln^n x \, {\rm d}x = \frac{(-1)^n n!}{\left ( m+1 \right )^{n+1}}$$ as presented here . Edit/ Update: A conjecture of mine is that the closed form actually is: $$\int_0^{\pi/2} \ln^{m} \tan x \, {\rm d}x=2m! \beta(m+1), \;\; m \;\;{\rm even}$$ For $m=2$ matches the result $\displaystyle \int_0^{\pi/2} \ln^2 \tan x\, {\rm d}x= \frac{\pi^3}{8}$.","['real-analysis', 'improper-integrals', 'special-functions']"
1448101,"$\{1, 2, . . . , 49\}$ is partitioned into $3$ subsets. Prove that at least $1$ of them contains $3$ different numbers $a,b,c$ such that $a+b=c$","As the title says, I'm asked to prove that at least one of the subsets contains three different numbers $a, b$ and c such that $a + b = c$. I tried to prove it but it is more difficult than it initially seemed to be. How would you do it? Edit: The original set is arbitrarily partitioned. Edit2: The exercise was given in a first year Discrete Mathematics course. I'm pretty sure they want us to somehow use the pigeonhole principle.",['discrete-mathematics']
1448134,Squeeze Theorem with strict inequalities,"Suppose that $I$ is an interval, and $g,f,h$ are functions defined on $I$, except possibly at $x_0$. Furthermore, $\forall \varepsilon>0,$ $\forall x\in I,$ and for some constant $L$,
$$ (L-\varepsilon)g(x) < f(x) \le Lh(x) .$$
Also,
$$\lim_{x\to x_0} g(x) = \lim_{x\to x_0} h(x) = 1.$$
Then is it true that $\forall \varepsilon>0,$
$$L-\varepsilon < \lim_{x\to x_0} f(x) \le L,$$
and since $\varepsilon$ can be taken to be arbitrarily small, the middle is forced to give
$$\lim_{x\to x_0} f(x)=L?$$
Note that this is essentially the Squeeze Theorem with a strict lower-bound.","['analysis', 'calculus', 'real-analysis']"
1448164,"Modulo polynomials, excluding selected solution combinations","Given
$$
(x-a)(x-b)(x-c) \equiv 0\ \ \pmod {p}
$$
$$
(x-d)(x-e)(x-f)\ \equiv 0\ \ \pmod {q}
$$ x: unknown variable. p,q : known primes. a,b,c,d,e,f : known values. Are there one or more modulo equations that will exclude the combination 
$$
(x \equiv a \pmod {p})\ AND\ (x \equiv d \pmod {q})
$$
but still allow all other combinations of x solutions? regards arthur Edit I tried $\left(mod\ pq\right)$ but couldn't get it to work. List all legal combinations and exclude the illegal one $\left(mod\ pq\right)$. Let $$r_{jk} \equiv j \left(mod\ p\right)\  and\ \  r_{jk} \equiv k \left(mod\ q\right)$$ $$(x-r_{ae})(x-r_{af})(x-r_{bd})(x-r_{be})(x-r_{bf})(x-r_{cd})(x-r_{ce})(x-r_{cf}) \equiv 0 \left(mod\  pq\right)$$ But if $x = r_{ad}$ (illegal) then $x = a +k_1p$ and $x = d + k_2q$ then $$(x-r_{ae})\dots(x-r_{bd})\dots \equiv (a+k_1p - (a + k_3p))\dots(d+k_2q-(d+k_4q))\dots\left(mod\  pq\right)$$
$$\equiv p(k_1-k_3)\dots q(k_2-k_4)\dots \equiv 0\left(mod\  pq\right)$$
The $x\equiv r_{ad}$ (illegal) produces a $p$ and a $q$ solving the equation $\left(mod\  pq\right)$. Edit 2 My application will work with the simplified problem: Let
$$(x-a)(x-b) \equiv 0\ \ \pmod {p}$$
$$(x-a)(x-b) \equiv 0\ \ \pmod {q}$$ Find equations that will allow
$$x \equiv a \ \pmod {p}\ \  and \ \ x \equiv a \ \pmod {q}$$
$$or$$
$$x \equiv b \ \pmod {p}\ \ and\ \  x \equiv b \ \pmod {q}$$
but block
 $$x \equiv a \ \pmod {p}\ \  and \ \ x \equiv b \ \pmod {q}$$
$$or$$
$$x \equiv b \ \pmod {p}\ \ and\ \  x \equiv a \ \pmod {q}$$
where $p$ and $q$ are distinct.","['prime-numbers', 'polynomials', 'number-theory', 'elementary-number-theory']"
1448186,A question on the proof of Hartshorne's II Lemma 6.1,"In the proof of Lemma II.6.1 of Hartshorne's Algebraic Geometry , Let $U=$ Spec$A$ be an open affine subset of $X$ on which $f$ is regular. Then $Z = X-U$ is a proper closed subset of $X$. Since $X$ is Noetherian, $Z$ can contain at most finitely many prime divisors of $X$. Why does $X$ being Noetherian imply that $Z$ can cantain at most finitely many prime divisors of $X$? By definition, $X$ can be covered by finitely many Spec $A_i$, where each $A_i$ is a Noetherian ring. So I think of the number of height $1$ prime ideals a Noetherian ring can contain. But this number can be infinite. Thanks to everyone.",['algebraic-geometry']
1448201,"If an outer measure adds over two $\mu^*$-finite sets, does it add over subsets of those sets?","This question occurred to me when I was reading the definition of a metric outer measure , but I couldn't think of an answer. Let $X$ be a set and let $\mu^* : \mathcal{P}(X) \to [0,\infty]$ be an outer measure on $X$. Suppose that $E,F \subset X$ are sets of finite outer measure (Edited, in light of discussion in comments)  such that $\mu^*(E \cup F) = \mu^*(E) + \mu^*(F)$. If $E' \subset E$ and $F' \subset F$, does it follow that $\mu^*(E' \cup F') = \mu^*(E') + \mu^*(F')$? What if I also take $E$ and $F$ to be disjoint?",['measure-theory']
1448210,Conjecture on minimum size of a graph,"Given a graph $G(V,E)$ , let $\chi(G)$ be its chromatic number, and $\chi_1(G)$ its 1-improper chromatic number (meaning that each node can have at most 1 neighbor with the same color; or another way of looking at this is that you are allowed to remove any matching from $G$ ). It is fairly easy to prove that a graph that satisfies $\chi_1=\chi$ has at least $2\chi-1$ vertices (a proof by induction exists). However, determining the minimum number of edges in order for the equality to hold seems more difficult. Quick drawings suggest the number of edges must be larger than $2(\chi-1)^2$ , but I cannot manage to prove it. Any suggestions? Note: it is easy to see that the number of edges must be larger than $\chi(\chi-1)$ . Indeed, extremal theory tells us the number of edges in a graph is always larger than $\chi(\chi-1)/2$ , but if we can remove any matching, it has to be larger than $\chi(\chi-1)$ . EDIT: please see the spin off of this question here","['coloring', 'graph-theory', 'extremal-graph-theory', 'combinatorics']"
1448211,"Linear map $L : C([0,1])\rightarrow C([0,1])$ continuous?","Let $X=C([0,1])$ equipped with the norm $\Vert\cdot \Vert=\max_{x\in [0,1]}|f(x)|$. If $L:X\rightarrow X$  is linear, is $L$  continuous? If not, what if $Lf\ge 0$ for $f\ge0$ for $\forall x \in [0,1]$ is assumed? Edit: Rephrased the question. Edit2: Attempt, Let, $\Vert f_n \Vert \rightarrow 0$ when $n\rightarrow \infty$ and $f_n=\sum_{i=0}^{\infty}\alpha^{(n)}_i x^{i} $ then $\Vert Lf_n\Vert=\max_{x\in [0,1]}|\sum_{i=0}^{\infty}\alpha^{(n)}_i Lx^{i}| \rightarrow 0$ Because $\forall \alpha^{(n)}_i \rightarrow 0$ when $n\rightarrow \infty$. But i don't know if this is allowed?",['functional-analysis']
1448216,"uncertain point in textbook's solution of a ""distance from point to line"" problem","We have a cube with each side equaling $1$ unit of length. We need to determine the distance from $B$ to the line $A_1C_1$ In my calculation, each side of the yellowish-shaded triangle equals $\sqrt2$. Then we just solve $$d=\sqrt{2-\frac24}=\frac{\sqrt3}{2}$$ But the textbook says: Why does the author uses the additional factor $BA_1$? Sorry if the question is too simple, I've been remiss in my studies, am now trying to catch up. (0:","['polyhedra', 'solid-geometry', 'algebra-precalculus']"
1448218,How does the Torsion of two vector fields act on their corresponding flows?,"Let $X$ and $Y$ be vector fields defined on an open neighborhhod of a smooth manifold $M$ endowed with an (arbitrary) affine connection $\nabla$ (i'm not assuming anything apart from it being a connection on $TM$). I'm trying to understand the torsion $T(X,Y)=\nabla_X Y - \nabla_Y X - [X,Y]$ of the connection in terms of flows. Here's what i have so far: Denoting the local flows of $X$ and $Y$ by $\varphi^X_t$ and $\varphi^Y_t$ resp. and their commutator by $\alpha(t)= \varphi^Y_{-t} \varphi^X_{-t}\varphi^Y_t\varphi^X_t$. We have the following relation between the lie bracket and the $\alpha$: $$[X,Y] = \frac{1}{2} \alpha ''(0)$$ So what i'm left with is finding a way to express $\nabla_X Y - \nabla_Y X$ in terms of flows. Obviously there must be some input from the connection. I tried to compute the flow by exponentiating from the lie algebra of vector fields but i didn't get very far... This problem made me realize i have no idea how integral curves and parallel are related. A word about how the they relate to each other would in any case be very helpful. Ideally I'd like to have an expression for $\nabla_X Y - \nabla_Y X$ in terms of parallel transport and the flows of $X$ and $Y$. Is there such a charactrization?","['differential-geometry', 'connections', 'riemannian-geometry', 'lie-derivative']"
1448229,Probability of getting a job when applying for 3 places,"I have the following problem. You apply for jobs and know that if you send your application then every job appointment procedure has two stages: You can be either invited or not invited to a personal interview and then You can either be selected or not selected for a job. Assuming that you do not have any further information about the process and the selection criteria, please compute the a priori probability to get at least one job offer after sending your application to three different places . My thoughts I started thinking about what events are independent and which ones are dependent. I thought that being able to get a job from place $A$ is an independent event of being able to get a job from place $B$. For this reason, I decided to consider independently the problem what is the probability of getting a job from a place $X$ . Now, the probability of being called to go to the interview (lets call this event $I$) is $\frac{1}{2}$, in other words $P(I) = \frac{1}{2}$, because we can either be called or not. Then, the probability of getting the job (lets call this event $J$) strictly depends on event $I$, because, for example, you cannot get the job, if you don't first go to the interview. What we actually want to know is the probability of being called and getting the job, in other words we want to know $P(I \text{ and } J)$. Since these events are dependent, we can use the rule that $P(A \text{ and } B) = P(A) \cdot P(B | A)$, where $P(B|A)$ is the probability of event $B$ happens given the fact that event $A$ has happened. Applying this rule to my case, I need to find $P(J | I)$, because I already know $P(I) = \frac{1}{2}$. I was thinking that this probability is $\frac{1}{4}$. Why? Basically, from $\frac{1}{2}$ of the possibilities remaining we have half of the chances to get the job, so $\frac{1}{2}$ of $\frac{1}{2}$ is $\frac{1}{4}$. I can now calculate $P(I \text{ and } J)$, which should be $P(I) \cdot P(J | I) = \frac{1}{2} \cdot \frac{1}{4} = \frac{1}{8}$. If my reasonings are correct, this should represent the probability of getting job from one place. 
Since I am applying for three different jobs (which are not dependent between each other), then I have more possibilities than $\frac{1}{8}$, so I thought we could sum the possibilities of getting a job for each individual place, thus my answer would be $\frac{1}{8} + \frac{1}{8} + \frac{1}{8} = \frac{3}{8}$. What am I doing wrong, what am I doing correct? Or can I improve something?","['probability', 'statistics']"
1448233,The derivation of the Wald interval,"I'm asking about the binomial proportion confidence interval , also known as the Wald interval. Recall that
$$\lim_{n \to \infty}{P_p \left( -z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}+\bar{X_n} \leq p \leq z_{1-\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}+\bar{X_n} \right)} = 1-\alpha, $$
with $\sigma = \sqrt{p(1-p)}$. Starting from the expression above, and the fact that for $\hat{p}=\dfrac{\sum X_i}{n},\ \hat{\sigma}=\sqrt{\hat{p}(1-\hat{p})}$  is consistent for $\sigma$ ($X_i \sim \rm Bin(1,p) )$, what argument can I use to show that 
$$\left[-z_{1-\frac{\alpha}{2}}\frac{\hat{\sigma}}{\sqrt{n}}+\bar{X_n} ,\  z_{1-\frac{\alpha}{2}}\frac{\hat{\sigma}}{\sqrt{n}}+\bar{X_n}\right]$$
is a confidence interval?","['statistics', 'statistical-inference']"
1448235,"Show that the polynomial $p_0, p_1, \ldots, p_m $ are linearly dependent.","Let $p_0, p_1, \ldots, p_m $ polynomials in $\mathbb{P}_m$ with the property that $p_j(1)=0\ \forall j$. Show that the polynomial $p_0, p_1, \ldots,p_m $ are linearly dependent. My approach for this problem is the following. Consider $$ \sum_{i=0}^m\alpha_ip_i(x)=0\ \ \forall x. \tag{1} $$ Put $x=1 $ in $(1)$ $ \implies \sum_{i=0}^m\alpha_ip_i(1)=0 \implies \alpha_i  $ can be nonzero also. Hence the given set of polynomial is linearly dependent.","['linear-algebra', 'proof-verification']"
1448240,Joint pdf of discrete and continuous random variables,"Consider two independent random variables $X$ and $Y$, where $X$ is uniformly distributed on the interval $[0,1]$ and $Y$ is uniformly distributed on the set $\{0,1\}$. Thus, the cdfs are given by 
$F_X(x) =
\begin{cases}
0 & x <0\\
x & 0 \leq x <1\\
1 &  else
\end{cases}$ and $F_Y(y) = 
\begin{cases}
0 & y <0\\
1/2 & 0 \leq y <1\\
1 &  else.
\end{cases}$ Consider the random variable $Z = (X,Y)$ with cdf is given by $F_Z(x,y) = 
\begin{cases}
0 & y<0\\
 F_X(x)/2& 0 \leq y < 1\\
F_X(x) & else.
\end{cases}$ Now, what I'm interested in is a pdf of $Z$. Is $
f_Z(x,y) = 
\begin{cases}
0 & y<0\\
f_X(x)/2& 0 \leq y < 1\\
f_X(x) & else.
\end{cases}
$ the pdf of $Z$? More generally, I'm interested in the joint pdf of independent random variables, one of which is continuous and the others (possibly more than one) are discrete. If correct, can the above be applied in this case? Thank you for your help.","['probability', 'probability-distributions', 'random-variables']"
1448250,Isomorphism between fields,"Suppose that $F$ and $G$ are two fields and $F[x]$ and $G[x]$ the polynomial rings in $x$. We know that the equivalence classes of the fractions of elements of $F[x]$ is a field $F(x)$ and the same is for $G(x)$. If $F[x]$ and $G[x]$ are isomorphic as rings and/or $F(x)$ and $G(x)$ are isomorphic as fields, what can we say about $F$ and $G$? I remember that I've read that we cannot prove that $F$ and $G$ are isomorphic, but I don't remember why and I suppose that the proof is not simple.","['abstract-algebra', 'field-theory']"
1448258,Integrating:$\int\limits_0 ^ {\infty}e^{-x^2}\ln(x)dx $,"$$ \displaystyle \int_0 ^ {\infty}e^{-x^2}\ln(x)dx = -\frac{1}{4}(\gamma +2\ln(2))\sqrt{\pi} $$
This is a well known integral.
But I want to know how to solve it??
Also, please refrain using contour integration etc, as I don't know it. $\gamma $ is the Euler-Mascheroni constant","['gaussian-integral', 'euler-mascheroni-constant', 'definite-integrals', 'integration']"
1448260,Is there another way to solve this quadratic equation?,"$$\frac { 4 }{ x^{ 2 }-2x+1 } +\frac { 7 }{ x^{ 2 }-2x+4 } =2$$ Steps I took: $$\frac { 4(x^{ 2 }-2x+4) }{ (x^{ 2 }-2x+4)(x^{ 2 }-2x+1) } +\frac { 7(x^{ 2 }-2x+1) }{ (x^{ 2 }-2x+4)(x^{ 2 }-2x+1) } =\frac { 2(x^{ 2 }-2x+4)(x^{ 2 }-2x+1) }{ (x^{ 2 }-2x+4)(x^{ 2 }-2x+1) } $$ $$4(x^{ 2 }-2x+4)+7(x^{ 2 }-2x+1)=2(x^{ 2 }-2x+4)(x^{ 2 }-2x+1)$$ $$11x^{ 2 }-22x+23=2x^{ 4 }-8x^{ 3 }+18x^{ 2 }-20x+8$$ I can keep going with all the steps I took, but is there a more elegant way to arrive at the solution for this equation? It seems as if I keep going the way I am, I will hit a dead end. No actual solution, please. Hints are much better appreciated.",['algebra-precalculus']
1448283,Find $\lim\limits_{n\to\infty}\left(\frac{a_1}{a_2}+\frac{a_2}{a_3}+\frac{a_3}{a_4}+...+\frac{a_n}{a_1}\right)$,"Find $\lim\limits_{n\to\infty}\left(\frac{a_1}{a_2}+\frac{a_2}{a_3}+\frac{a_3}{a_4}+...+\frac{a_n}{a_1}\right)$ if {$a_n$} is random sequence with positive terms. If sequence is increasing ($a_1>a_2>...>a_n$), then $L=+\infty$
What is the limit when sequence is decreasing?","['sequences-and-series', 'calculus', 'limits']"
1448300,How to compute$\int_{0}^{1}\dfrac{x\ln(x)}{(x^2+1)^2}dx$,"How to compute
  $$\int_{0}^{1}\dfrac{x\ln(x)}{(x^2+1)^2}dx$$
  I'm interested in more ways of computing this integral. My Thoughts \begin{align}
\int_{0}^{1}\dfrac{x\ln(x)}{(x^2+1)^2}dx&=\int_{0}^{1} \:\ln \left(x\right)\frac{x}{\left(x^2+1\right)^2}dx\\
&=\int_{0}^{1} \:\ln \left(x\right)\frac{x}{\left(x^2+1\right)^2}dx\\
\mathrm{Apply\:Integration\:By\:Parts}:
\end{align} $$\fbox{$u=\ln \left(x\right),\:\:u'=\frac{1}{x},\:\:v'=\frac{1}{\left(x^2+1\right)^2}x,\:\:v=-\frac{1}{2\left(x^2+1\right)}$ }$$ \begin{align}
\int_{0}^{1}\dfrac{x\ln(x)}{(x^2+1)^2}dx&
=\ln \left(x\right)\left(-\frac{1}{2\left(x^2+1\right)}\right)\biggl|_{0}^{1}-\int_{0}^{1} \frac{1}{x}\left(-\frac{1}{2\left(x^2+1\right)}\right)dx\\
&=-\frac{\ln \left(x\right)}{2\left(x^2+1\right)}\biggl|_{0}^{1}+\int_{0}^{1} \:\frac{1}{2x\left(x^2+1\right)}dx\\
&=-\frac{\ln \left(x\right)}{2\left(x^2+1\right)}\biggl|_{0}^{1}+\dfrac{1}{2}\int_{0}^{1} \:\frac{1}{x\left(x^2+1\right)}dx\\
\end{align} now let's calculate: \begin{align}
\int_{0}^{1} \frac{1}{x\left(x^2+1\right)}dx&=\int_{0}^{1} \frac{1}{x\left(x^2+1\right)}dx\\
&=\int_{0}^{1} \frac{1}{x}-\frac{x}{x^2+1}dx\\
&=\ln \left(x\right)\biggl|_{0}^{1}-\dfrac{1}{2}\int_{0}^{1} \frac{2x}{x^2+1}dx\\
&=\ln \left(x\right)\biggl|_{0}^{1}-\dfrac{1}{2}\int_{0}^{1} \frac{(x^2+1)'}{x^2+1}dx\\
&=\ln \left(x\right)\biggl|_{0}^{1}-\frac{1}{2}\ln \left(x^2+1\right)\biggl|_{0}^{1}\\
\int_{0}^{1} \frac{1}{x\left(x^2+1\right)}dx&=\left(\ln \left(x\right)-\frac{1}{2}\ln \left(x^2+1\right)\right)\biggl|_{0}^{1}\\
\end{align}
then $$\fbox{$\int_{0}^{1}\dfrac{x\ln(x)}{(x^2+1)^2}dx=-\frac{\ln \left(x\right)}{2\left(x^2+1\right)}\biggl|_{0}^{1}+\dfrac{1}{2}\left(\ln \left(x\right)-\frac{1}{2}\ln \left(x^2+1\right)\right)\biggl|_{0}^{1}$}$$ \begin{align}
\int_{0}^{1}\dfrac{x\ln(x)}{(x^2+1)^2}dx&=-\frac{\ln \left(x\right)}{2\left(x^2+1\right)}\biggl|_{0}^{1}+\dfrac{1}{2}\left(\ln \left(x\right)-\frac{1}{2}\ln \left(x^2+1\right)\right)\biggl|_{0}^{1} \\
&=\frac{1}{2}\left(\ln \left(x\right)-\frac{1}{2}\ln \left(x^2+1\right)\right)-\frac{\ln \left(x\right)}{2\left(x^2+1\right)}\biggl|_{0}^{1} \\
\end{align} or the limit of 
\begin{align}
\lim _{x\to \:0+}\left(\frac{1}{2}\left(\ln \left(x\right)-\frac{1}{2}\ln \left(x^2+1\right)\right)-\frac{\ln \left(x\right)}{2\left(x^2+1\right)}\right)&=\lim _{x\to \:0+}\left(\frac{2x^2\ln \left(x\right)-x^2\ln \left(x^2+1\right)-\ln \left(x^2+1\right)}{4\left(x^2+1\right)}\right)\\
&=\dfrac{0}{4}=0
\end{align}
and
$$\frac{1}{2}\left(\ln \left(1\right)-\frac{1}{2}\ln \left(1^2+1\right)\right)-\frac{\ln \left(1\right)}{2\left(1^2+1\right)}=\dfrac{-\ln(2)}{4} $$ Finaly $$\fbox{$\int_{0}^{1}\dfrac{x\ln(x)}{(x^2+1)^2}dx=\dfrac{-\ln(2)}{4} $} $$","['contest-math', 'calculus', 'real-analysis', 'integration']"
1448304,Minimum number of axioms for a $\sigma$-algebra,"Usually a $\sigma$-algebra is defined as: Def. A family $\mathcal F$ of subsets of $\Omega$ is said to be a $\sigma$-algebra on $\Omega$ if: (A.1) $\ \Omega\in\mathcal F$ (A.2) $\ A\in\mathcal F\implies\ A^c\in\mathcal F$ (A.3) $\ A_1,A_2,...\in\mathcal F\implies\bigcup _{i=1}^\infty A_i \in\mathcal F$ I fail to see the need of the first axiom (A.1) because the other two seem to immediately imply the first: $\Omega = A\cup A^c \in\mathcal F$. What's wrong here?",['measure-theory']
1448313,caratheodory measurability condition,"(1)
 If $E$ is a subset of $\mathbb R$ with finite outer measure, i.e. $m^{*}(E) <\infty$; and 
 (2) $E$ is not Lebesgue measurable, i.e. there exists $F$ such that
 $m^{*} (F) < m^{*}(EF) + m^{*}(FE^{c}).$ [Claim] There exists an open set $O\supset E$ with finite outer measure, such
 that 
 $$m^{*}(O E^{c})  > m^{*} (O)  - m^{*} (E).$$ My  questions are the following. (1) Is the above claim correct? I've seen this in Royden's book, but have a bit concern. Note that a set $E$ is Leb measurable if 
it satisfies caratheodory condition: $m^{*} (F) = m^{*}(EF) + m^{*}(FE^{c})$ for 
all subset $F$. If the claim is yes, it seems that measurability condition can 
be reduced from all subset $F$ to Borel set $F$. (2) If the claim is correct, a proof is needed.",['real-analysis']
1448340,What is infinity added to itself a countably infinite number of times?,"What is infinity added to itself a countably infinite number of times? Intuitively, it seems to me that $$\sum_{n=1}^\infty \infty = \infty \cdot \infty = \infty,$$ because $$ \sum_{k=1}^n \infty = n \cdot \infty = \infty,$$ but I don't know how to prove it. I asked my professor, and he said I could just use the fact that $\infty + \infty = \infty$, and I see that I can extend this by induction to the case of a finite sum, but I don't see how I can use it for the countably infinite sum. Some context: I am trying to solve a homework exercise in my measure theory course, and I need to show that a given set function is an outer measure, but I am stuck on this step. (I also don't understand why $\infty \cdot \infty = \infty$, so it'd be great if you could explain that too, but it's not my main question.)","['infinity', 'measure-theory']"
1448463,Expected value of size of subset,"Given a set $S$ such that $|S|=n$, A random item is chosen randomly from $S$, and being appended to a new set $T$. This process is being repeated $n$ times (with repetition), what is the expected value of $|T|$ ?","['probability', 'balls-in-bins', 'expectation']"
1448474,"A ""paradox"" involving the dominated convergence theorem","I have the following question regarding the dominated convergence theorem. I was trying to apply it, but then got a contradiction that I could not resolve. Let $\zeta := |.|$ be the counting measure: We can calculate the geometric series ($n \geq 1$)$$\sum_{k=0}^{\infty} \left(\frac{1}{n+1}\right)^{k} = \frac{1}{1 - (n+1)^{-1}} = \frac{n+1}{n}$$ The functions $f_{n}(k) := \left(\frac{1}{n+1}\right)^k $ are measurable functions on the measure space $(\mathbb{N},\mathcal{P(\mathbb{N})}, \zeta)$. Obviously, for $n \to \infty$,they converge pointwise to the zero function $f_{0}(k) := 0$. We also have $$\int_{\mathbb{N}} | f_{n}(k)| d\zeta(k) \leq \int_{\mathbb{N}} \left(\frac{1}{2}\right)^{k} d\zeta(k) = \sum_{k=0}^{\infty} \left(\frac{1}{2}\right)^{k} = 2 $$ so we have an integrable dominating function for the sequence $f_{n}$. By the dominated convergence theorem, we get $$\lim_{n\to\infty} \int_{\mathbb{N}} f_{n}(k) d\zeta(k) = \int_{\mathbb{N}}f_0 (k) d\zeta(k) \quad \Leftrightarrow \quad \lim_{n \to \infty}\sum_{k=0}^{\infty} \left(\frac{1}{n+1}\right)^{k} = 0$$ A contradiction to the formula above that tells us that the limit is equal to 1. Where did I go wrong?","['sequences-and-series', 'measure-theory']"
1448490,Absolute continuity and singularity of discrete measures on the real line,"I have spent the last couple of days reading up on measure theory and absolute continuity to get my head around the definitions of discrete/empirical measures, absolute continuity and singularity. I would love to have someone check that I got everything right. Let's assume $\nu$ is an empirical measure, defined as $$
\nu = \sum_{i=1}^n a_i \delta_{x_i}
$$ where $a=(a_1, \dots, a_n) \in \{u \in \mathbb{R}^n | \sum a_i=1\}$ and $X=(x_1, \dots,x_n) \in \mathbb{R}^n$. If I understood correctly, I could view $\nu$ in two different settings. View $\nu$ as a measure on its countable support $X$ In this case $\nu$ is absolutely continuous with respect to the counting measure on $X$. Let $\tau$ be the counting measure on $(X, \mathcal{P})$, which is positive sigma-finite. Then I can write $\nu$ as
$$
\forall A \subset X, \nu(A)= \sum_{x_i \in A} a_i \tau(\{x_i\})
$$
Also, by Radon-Nikodym, $\nu$ admits a density $f$ wrt $\tau$ defined by $\forall x_i \in X, f(x)=a_i$ if $x=x_i$. View $\nu$ as a measure on the measurable space $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$.
In this case $\nu$ is a radon measure on $\mathbb{R}$. 
Also, the following line of argument is valid. $\nu$ is absolutely continuous to the measure $\tau:= \delta_{x_1}+\dots+\delta_{x_n}$. Let $\lambda$ denote the Lebesgue measure on $\mathbb{R}$. Since $\delta_{x_i} \perp \lambda$ we have $\tau \perp \lambda$. And since $\nu \ll \tau$ we have $\nu \perp \lambda$. Hence, $\nu$ is singular with respect to the Lebesgue measure on $\mathbb{R}$. Lastly, by Radon Nikodym $\nu$ admits a density with respect to $\tau$ given by 
$$
f(x)
 =
\begin{cases} 
a_i & \text{if  } x=x_i \\ 
0 & \text{else}
\end{cases}
$$ Are both cases correct? Did I describe them correctly?","['probability', 'measure-theory']"
1448495,Prove that all cycles of $S_n$ are generated by these transpositions,"Prove that all cycles of $S_n$ are generated by the transpositions $\{(ij) \mid 1 \leq i < j \leq n\}$ (do not assume any other set of transpositions generate the cycles of $S_n$). So if we have a cycle $(x_1 x_2 x_3 \ldots x_n)$ then we have to show that the transpositions as stated above: $(x_1 x_n)(x_1 x_{n-1}) \ldots (x_1 x_2) (x_2 x_n) (x_2 x_{n-1}) \ldots (x_2 x_3) \ldots (x_{n- 1} x_n)$ generate this cycle. So if $k \neq 1 \neq n$, then $x_k$ is first ocurred in the cycle $(x_k, x_{k+1})$. So $x_k$ goes to $x_{k+1}$. Then $x_{k+1}$ goes to $x_{k-1}$ since the next cycle where $x_{k+1}$ is seen is in $(x_{k-1} x_{k+1}$), and then $x_{k-1}$ goes to $x_{k-2}$ (in $(x_{k-2} x_{k-1})$), etc. until finally $(x_2 x_3)$. Then $(x_1 x_2)$ and lastly $(x_1 x_3)$. So $x_k$ goes to $x_3$, which doesn't really help my case here.","['abstract-algebra', 'group-theory', 'symmetric-groups', 'permutations']"
1448508,find the solutions of initial value problem $x' = |x|^{1/2}$ with $x(0) = 0$,"Show that the initial value problem \begin{align}
&x' = |x|^{1/2}\\
&x_0 = 0
\end{align}
has four different solutions through the point $(0,0)$. 
I found three solutions which are $$x_t= \frac14 t^2,$$
$$x_t= -\frac14 t^2,$$ and $$x_t= 0$$
but I couldn't figure out the fourth one.",['ordinary-differential-equations']
1448528,Does Cauchy's estimate imply analyticity?,"Komatsu says here (Proc. Japan Acad. Volume 36, Number 3 (1960), 90-93) that a smooth function which satisfies Cauchy's estimate is analytic. How does one prove this? Surely, if Cauchy's estimates hold for the derivatives of a function, then its Taylor series converges, but that is not enough for analyticity. Is it necessary to consider the smooth function on a compact interval? In the second answer to this question, the above fact is used for a function defined on the whole real line.","['taylor-expansion', 'analyticity', 'complex-analysis']"
1448568,Find intersection of the two surfaces $x^2-y^2-z^2=1$ and $x+y=1$,"Find intersection of this two surfaces $$x^2-y^2-z^2=1$$
 and
$$x+y=1.$$ I know that the first is hyperboloid of two sheet and the second is plane, 
but how can i find the intersection? Is it possible do calculus in one variable? How?",['multivariable-calculus']
1448575,Intuition behind proof in the Rudin book that there is no largest/smallest real number. [duplicate],"This question already has answers here : Choice of $q$ in Baby Rudin's Example 1.1 (16 answers) Closed 8 years ago . In Rudin's Principles of Mathematical Analysis (3rd ed), he proves (at the very beginning: example 1.1) that the set $A$ of all positive rationals $p$ such that $p^2<2$ contains no largest number and the set $B$ of all positive rationals $p$ such that $p^2>2$ contains no smallest number. To show this, he starts by associating with each rational $p>0$, the number
$q=p-(p^2-2)/(p+2) = (2p+2)/(p+2)$. And thus $q^2-2=2(p^2-2)/(p+2)^2$. My question is actually simple: from where does he get the expression for $q$ and how does one get the intuition to come up with the form of the number $q$?","['diophantine-approximation', 'analysis', 'radicals', 'numerical-methods', 'inequality']"
1448585,Prove reflection in a hyperplane is a linear map,"Let $\alpha \in \mathbb{R}^n$, $n \geq 2$, be a non-zero vector. Define a reflection in the hyperplane perpendicular to $\alpha$ by:
  $$\sigma_{\alpha}(v) = v - \dfrac{2(v, \alpha)}{(\alpha, \alpha)} \cdot \alpha$$
  ($(x, y)$ is the usual inner product on $\mathbb{R}^n$). 1) Show $\sigma_{\alpha}$ is a linear map that fixes the hyperplane orthogonal to $\alpha$ and sends $\alpha$ to $-\alpha$. 2) Given $\alpha, \beta$ non-zero vectors, determine when the subgroup $\langle \sigma_{\alpha}, \sigma_{\beta} \rangle$ is infinite. Find its order when it is finite. For 2) I don't understand what the group is. If $\sigma_{\alpha}$ and $\sigma_{\beta}$ are elements of a group, what other elements do they generate? Like for example, $\sigma_{\alpha}(\sigma_{\beta}(v)) = \left(v - \dfrac{2(v, \beta)}{(\beta, \beta)} \cdot \beta \right) - \dfrac{2\left(v - \dfrac{2(v, \beta)}{(\beta, \beta)} \cdot \beta, \beta \right)}{(\beta, \beta)} \cdot \beta$ which I guess makes sense (in the sense that dot products work in this function since the dot product is between vectors). But how do I know when there will be an infinite many number of these, and when there will be finitely many? I can't even find an identity function $\sigma$, because a composition of $\sigma_{\alpha}$ and $\sigma_{\beta}$ is $\sigma_{\beta}$ only when $\sigma_{\alpha} = v$, but this is a constant function and does not reflect $\alpha$ about the hyperplane to $-\alpha$, so this constant function cannot be in the group.","['abstract-algebra', 'group-theory', 'finite-groups', 'linear-transformations', 'linear-algebra']"
1448606,Calculate $3\cdot 4+ 4$ in $\mathbb{Z}_7$ and $\mathbb{Z}_{10}$.,"Question: calculate $3\cdot 4+ 4$ in $\mathbb{Z}_7$  and $\mathbb{Z}_{10}$. I don't really understand how to approach this problem, any ideas are appreciated. Thanks.","['abstract-algebra', 'discrete-mathematics', 'elementary-number-theory']"
1448618,When is the additive identity not the zero vector?,"My teacher cryptically mentioned today that the zero vector is not always the additive identity. When asked for clarification I was told ""we'll get there"". He did confirm it is always 0 in matrices filled with real numbers, but I can't think of or find any matrix, whether complex or variable or whatever where anything else would work, or where the zero vector wouldn't work. It might be half a joke to keep me interested, but I'll be a minkeys uncle if it didn't work! I don't know, any ideas?","['vector-spaces', 'linear-algebra']"
1448630,Estimating numerically $\lim \limits _{x \to 0} \frac {\sin 4x} x$,"As the title says, I am looking for ways to estimate numerically $\lim \limits _{x \to 0} \frac {\sin 4x} x$. So far, I've tried filling in numbers on either end of zero to make an estimate, and keep getting answers around $.0697$ or $.0698$, but the homework website I am on is marking me wrong. Am I solving this the wrong way? Does anyone know how else I should go about this?
Please let me know.","['approximation', 'calculus', 'limits']"
1448684,Ways to arrange the letters in **BOOKKEEPER** if vowels must appear in alphabetical order?,Question How many different ways can I arrange the letters in BOOKKEEPER if vowels must appear in alphabetical order? How many different ways can I arrange the vowels? That would be 1 way. No I glue the term $eeeoo$ together and treat it as a letter of its own. That would leave me with $6$ letters left. Different ways to arrange them? $${6! \over 2!}$$ since there are $2 \;k's$. Did I do it right? Thank you in advance for your time.,['combinatorics']
1448686,Does $\lfloor x\lceil y\rceil\rfloor = \lceil x\lfloor y\rfloor\rceil$ have non-integer solutions?,"Does $\lfloor x\lceil y\rceil\rfloor = \lceil x\lfloor y\rfloor\rceil$ have any non-integer solutions? If so, how do you find them?",['discrete-mathematics']
1448690,Find the limit as $n$ approaches infinity: $\lim_{n\to \infty} \sqrt{3^n + 3^{-n}} - \sqrt{3^n + 3^{\frac{n}{2}}}$,"$$\lim_{n\to \infty} \sqrt{3^n + 3^{-n}} - \sqrt{3^n + 3^{\frac{n}{2}}}$$ I am taking calculus in university and this is the problem I have been given. I haven't even seen limits involving a variable in the exponent in the textbook, so I am really stuck. I tried graphing and I can guess that the limit will probably be $0$. I've tried laws of exponents, limit laws, but nothing gives me a good answer. Also, sorry about the formatting, but this is the best I could do - it's my first time on this website. The second part of the equation should also be under a square root, so very similar to the first square root, but with the second exponent at $\frac{n}{2}$ instead of $-n$. Thank you so much for help solving this.","['radicals', 'calculus', 'limits']"
1448697,Evaluate limit as x approaches infinity of $\lim_{x\to\infty}\frac{\sqrt{x^3 +7x}}{\sqrt{4x^3+5}}$,"I am having trouble figuring out how to answer this question by determining the degree of the numerator and/or denominator:
$$\lim_{x\to\infty}\frac{\sqrt{x^3 +7x}}{\sqrt{4x^3+5}}$$
I have tried deriving the first coefficient of the numerator and denominator, but not sure how to proceed to find the limit as $x \to \infty$.","['calculus', 'limits', 'algebra-precalculus', 'radicals', 'derivatives']"
1448733,Inverse of Permutations,"I'm having problems understanding inverting permutations, but I believe I understand how to do compositions.  I may be second guessing myself, but some answers do not make sense to me.  I've tried to use two different approaches (graphically and P ∘ P^(-1) = identity)  Below is my question: P = (5 1 4 2 3),  find the inverse of P P ∘ P^(-1)=(5 1 4 2 3)∘(a b c d e)=(1 2 3 4 5) P(P^(-1)(1))=P(a)=1⇔a=2 P(P^(-1)(2))=P(b)=2⇔b=4 P(P^(-1)(3))=P(c)=3⇔c=5 P(P^(-1)(4))=P(d)=4⇔d=3 P(P^(-1)(5))=P(e)=5⇔e=1 ∴ P^(-1)=(2 4 5 3 1) On a similar question I tried to find the inverse of (4 2 5 1 3), graphically using an arrow diagram and found that it's inverse is (4 2 5 1 3)!  Which doesn't make sense to me... unless that is suppose to be the correct answer...","['inverse', 'function-and-relation-composition', 'discrete-mathematics', 'permutations']"
1448738,Construct an example of a function with period 1 which is not a trig function and is differentiable at every point.,"This question stuck out to me as particularly difficult.  Any insight would be great! (piece-wise are ok, but keep in mind the differentiability clause).","['calculus', 'functions']"
1448767,How do i evaluate $\displaystyle \lim_{x \to -2}\frac {\sqrt{x+2}}{(\sqrt{x}+\sqrt{2} )}$?,How do i evaluate $\displaystyle \lim_{x \to -2}\frac {\sqrt{x+2}}{(\sqrt{x}+\sqrt{2} )}$. I'm confused in wolfram alpha the result is $0$ however $\sqrt{x}$ at $x=-2$ is undefined in $\mathbb{R}$ then how it is $0$ ?,"['proof-verification', 'calculus', 'real-analysis', 'limits']"
1448866,A high-level reason that $(a \times b) \cdot ((b \times c) \times (c \times a)) = (a \cdot (b \times c))^2$,"I can do the algebra to prove this identity: $$(\mathbf{a} \times \mathbf{b}) \cdot ((\mathbf{b} \times \mathbf{c}) \times (\mathbf{c} \times \mathbf{a})) = (\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c}))^2$$ in particular, by appeal to the ``BAC -- CAB'' identity mentioned on Wikipedia plus some simplifications. Is there a geometric or linear-algebraic interpretation of this? I know that the scalar triple product is the volume of the paralellopiped formed by its components, and it seems this should be related, but I'm not sure how. Where would volume squared come in?","['vectors', 'multivariable-calculus', 'cross-product']"
1448885,"Is $\sqrt{64}$ considered $8$? or is it $8,-8$?","Last year in Pre-Algebra we learned about square roots. I was taught then that $\sqrt{64}=8$ and $\sqrt{100}=10$ , which I understood and accepted. I was also taught that $\pm\sqrt{64} = 8,-8$ because both of those numbers squared is 64, which I also get.
But this year, with a new school and teacher in a different state, our teacher is telling us that: $\sqrt{64}=8,-8$ and $\pm\sqrt{64}$ also is $8,-8$ . The way to get the positive root of something is: $+\sqrt{64}=8$ And these seem to contradict each other. I was always taught that a regular square root returned a positive number and only a positive number, but now my teacher is saying a regular square root gives two numbers, and considering the square root of a number $n$ is defined as $y^2=n$ I see where he is coming from. Upon researching this Wikipedia says: For example, $4$ and $−4$ are square roots of $16$ because $4^{2} = (−4)^{2} = 16$ And Wolfram MathWorld says: Note that any positive real number has two square roots, one positive and one negative. For example, the square roots of $9$ are $-3$ and $+3$ But on the other side, Wolfram Alpha, when given ""The square root of 9"" gives only 3. So, which is right? Is $\sqrt{64}$ considered $8$ ? or is it $8,-8$ ?","['radicals', 'algebra-precalculus']"
1448919,Difference between $\sigma^2\{\text{pred}\}$ and $\sigma^2\{\hat Y_h\}$?,"Can someone explain this to me? I've read the relevant section of the text about a million times, and it was even explained in class, but I can't seem to wrap my head around it. The Statement of the Problem: Can $\sigma^2\{\text{pred}\}$ be brought increasingly close to $0$ as $n$ becomes large? Is this also the case for $\sigma^2\{\hat Y_h\}$? What is the implication of this difference? Here $$ \hat Y_h = \text{the point estimator of }E\{Y_h\}= b_0 + b_1X_h $$ $$ \text{and} $$ $$\sigma^2\{\hat Y_h\}=\text{the variability of the sampling distribution of  }\hat Y_h=\sigma^2\left[ \frac{1}{n}+\frac{(X_h-\bar X )^2}{\sum (X_i - \bar X)^2} \right] $$ $$\text{and} $$ $$\sigma^2\{\text{pred}\} = \text{the variance of the prediction error}\\ =\sigma^2\{Y_{h(new)}-\hat Y_h\}=\sigma^2\{Y_{h(new)}\}+\sigma^2\{\hat Y_h\}=\sigma^2+\sigma^2\{\hat Y_h\}.$$ I know why, mathematically , it is the case that, as $n$ becomes large, $\sigma^2\{\hat Y_h\}$ approaches $0$, and $\sigma^2\{\text{pred}\}$ does not (it approaches $1$ instead, I believe). However, I'm looking for a more intuitive, conceptual understanding here. If someone could explain a little, or even just point me towards an explanation elsewhere on the web, I'd appreciate it. Thanks. Also, if any other notation is unclear, let me know.","['statistics', 'statistical-inference', 'regression']"
1448924,How do I figure out the features of a cube in 4 dimensions?,"This is a question from Gilbert Strang's Introduction to Linear Algebra and MIT OCW How many corners does a cube have in $4$ dimensions? How many $3$D faces? How many edges? A typical corner is $(0,0,1,0)$. A typical edge goes to $(0,1,0,0)$. I know that it will have $16$ corners, but I don't know how to figure out the rest. So far, I have only learned a little about vectors, their components, and linear combinations. How can I apply this knowledge to figure out the features of this cube? The worked example in the book (for this problem) uses matrices and it is also in the middle of the next chapter. Hints only, please.",['linear-algebra']
1448942,Proving $\mathbb{Z}[\sqrt {10}]$ is not a UFD,"I am wondering how to show that $\mathbb{Z}[\sqrt {10}]$ is not a UFD. My only idea is to show that there are two factorizations of $10$, say, $ab, uv$ such that $a$ is not a unit times $u$ or $v$. In this ring $10=2\cdot5=\sqrt {10}\cdot \sqrt {10}$, so it suffices to show $2$ is not a unit times $\sqrt {10}$. Suppose $2=\sqrt {10}(a+b\sqrt{10})=a\sqrt{10}+10b$. Then $a=0$ since $\sqrt{10}$ is not rational. So $10b=2$, which has no integer solutions. So $\mathbb{Z}[\sqrt {10}]$ is not a UFD. Is my reasoning correct? What are the flaws?","['abstract-algebra', 'solution-verification', 'unique-factorization-domains']"
1448952,Weak convergence in sobolev space,"Let $u_n \in H^1(\Omega)$ Then, $u_n$ is said to converge weakly in $H^1$ to $u$ if $u_n$ converges weakly to $u$ in $L^2$ and $\nabla u_n$ converges weakly to $\nabla u$ in $L^2$. What does it mean by  $\nabla u_n$ converging weakly to $\nabla u$ in $L^2$? Does this mean that every ""component"" of the gradient of $u_n$ converges weakly to the gradient of $u$?","['sobolev-spaces', 'functional-analysis']"
1449023,Equivalence relations,"Having trouble proving this is an equivalence relation. Is it suffice to say that let $x y z$ be any string in $\Sigma^*$, $(xz \in L \iff yz \in L) \rightarrow (yz \in L \iff xz \in L)$ shows that $xRy \rightarrow yRx$?","['equivalence-relations', 'discrete-mathematics']"
1449051,How many nonnegative integer solutions does the following equation have: $x + y + z = 15$,"How many nonnegative integer solutions does the following equation
  have: $x + y + z = 15$ (1) if $1 \le x \le 6$ (2) if $x \ge 2$ and $y \le 3$ (3) if $x \ge 3$, $y \ge 2$, and $1 \le z \le 3$ I solved the first question (which is C(3+11-1,11)). Still very stuck on the next two","['discrete-mathematics', 'combinatorics', 'inequality']"
1449074,In how many ways can you arrange all coins in a row?,"A jar contains 5 quarters, 2 nickels, and 4 pennies. In how many ways
  can you arrange all coins in a row so that each arrangement: (1) begins with a quarter? (2) all quarters together? (3) two nickels are not next to each other? (4) no 2 pennies are next to each other? I believe I solved the first question. It would be 5 * (10!/(4!4!2!)) which equals 3150. For (2), I got 7!/(4!2!) = 105 For (3) I got the ""total - 2 nickels together"" approach. So (11!/(5!4!2!)) - (10!/(5!4!)) = 5670. I'm still very stuck on #4. It seems to be a MISSISSIPPI problem.","['discrete-mathematics', 'combinatorics']"
1449100,A coin tossing game with random probabilities,"Let $p$ a random variable, uniformed distributed in $[0,1]$. Two player $A$ and $B$ play the following game: Starting from A, a player gets a random value $p(\omega)\in[0,1]$, and he has two choices: i) He can flip a coin, with a probability $p(\omega)$ of an head. If he get an head he wins the game, otherwise the other player will play with the same distribution $p$. ii) He can pass the turn to the other player, but giving him a penalized  distribution, namely $p$ is replaced, for that turn, by an uniform distribution on $[0,1-p(\omega)]$ Suppose that both players play optimally, i.e. they choose between (i) and (ii) the one which gives the highest probability of winning. What is the probability of a winning for the first player? EDIT: let me try to clarify how the game is played. At each turn, the current player gets a random probability $p$ in the following way: if in the previous turn his adversary has flipped the coin (without getting head, in which case the game ended), he takes  $p$ uniformly in $[0,1]$. If his adversary hasn't flipped the coin, he takes $p$ uniformly in $[0,1-\tilde{p}]$, where $\tilde{p}$ is the probability his adversary play with during the previous turn. Now the current player can choose if to flip the coin (with a winning probability $p$), or to pass the turn.","['probability', 'game-theory']"
1449104,Join of normal subgroups of a group is normal subgroup,"Prove that the join of any nonempty collection of normal subgroups of a group is an normal subgroup. Attempt: Let $\left\langle\bigcup H\right\rangle$ be the join of $H$ , where $H$ is the join of any nonempty collection of normal subgroups of $G$ . Let $g\in G$ . Then $g\left\langle\bigcup H\right\rangle g^{-1} = g\left\langle \bigcup H_i\right\rangle g^{-1} = \left\langle g\bigcup H_ig^{-1}\right \rangle= \left\langle\bigcup gH_ig^{-1}\right\rangle = \left \langle \bigcup H_i\right\rangle = \left \langle \bigcup H\right\rangle $ So $\left\langle \bigcup H\right\rangle $ is normal. I don't know if this is a good way to approach this. Can someone please help? Maybe there is a better  approach. Thank you","['group-theory', 'normal-subgroups']"
1449106,Geometric Coset,"I am familiar with cosets, but im not sure what to do here (never had to give a ""geometric"" description of a coset): Consider $\mathbb{R}$ and the subgroup $\mathbb{Z}$. Describe a coset $t+\mathbb{Z}$ geometrically and show the set of all cosets of $\mathbb{Z}$ in $\mathbb{R}$ is $\{t+\mathbb{Z} : 0\leq t< 1\}$ Im lost, I suppose I dont understand cosets enough to put them into geometric terms..I suppose I just view them as abstract objects in groups. Any help would be great!","['abstract-algebra', 'group-theory']"
1449114,Is there a simple way of showing that the directional derivative is the dot product of grad(f) with the directional vector u?,"I am reading a sort of technical proof but I would like to prove it myself in a cleaner and shorter way. So, I want to show $$D_uf = \nabla f. u$$ Any suggestions are greatly appreciated. Thanks, EDIT:  I think I will try to work backwards, using matrix multiplication, since grad(f) can be viewed as a 1x2 matrix.","['partial-derivative', 'vector-analysis', 'real-analysis', 'multivariable-calculus', 'derivatives']"
1449122,"In NSA (ZFC+IST), what can we say about generators for $\mathbb{Z}/\nu\mathbb{Z}$ for unlimited $\nu$?","Recently I've been going through a short text on Nonstandard Analysis that uses the axiomatic approach of Nelson (Internal Set Theory - IST). Its study has led me to be curious about the properties of the fields of integers modulo $p$ prime when $p$ is unlimited ($\nu$). This is interesting because, in a sense, it contains all the arithmetic of the standard $\mathbb{Z}$ in a finite set. Although I don't necessarily expect to find anything novel, I think that it is instructive with regard to NSA/IST. As there are infinitely many primes, we know from Idealization there is an unlimited prime I will call $\nu$. We would like to look at $\mathbb{Z}/\nu\mathbb{Z}$, where $\nu$ is an unlimited prime number. This can take the usual definition (and properties) per the Transfer axiom. $$\mathbb{Z}/\nu\mathbb{Z}=\{[0],[1],[2],\ldots ,[\nu -1]\}$$ Note that in IST this is finite (despite ""containing"" all standard $\mathbb{Z}$) since there's a bijection with $\{1,2,\ldots ,\nu\}\subseteq\mathbb{N}$. (In the IST axiomatic approach to NSA, $\mathbb{N}$ itself contains nonstandard elements, unlimited numbers, that are simply ""revealed"" by the axioms. This is in contrast to the other NSA approaches that actually extend $\mathbb{N}$.) For $\mathbb{Z}/p\mathbb{Z}$ we would have the existence of a $k\in\mathbb{N}, k<p$ such that
$$\mathbb{Z}/p\mathbb{Z}=\{[0],[k^1],[k^2],\ldots ,[k^{p-1}]\}$$ Therefore, I think it is reasonable to ask if there exists a $\kappa\in\mathbb{N}, \kappa<\nu$ such that
$$\mathbb{Z}/\nu\mathbb{Z}=\{[0],[\kappa^1],[\kappa^2],\ldots ,[\kappa^{\nu-1}]\}$$ In particular, is there an unlimited $\kappa$? Is it necessarily unlimited? Necessarily limited? If so, we would have an unlimited ""generator"" for all the standard elements of $\mathbb{Z}/\nu\mathbb{Z}$ (plus some nonstandard). Although any solution is welcome, I'd particularly appreciate answers capable of elucidating the situation with the axioms of IST.","['nonstandard-analysis', 'number-theory', 'modular-arithmetic', 'abstract-algebra', 'finite-fields']"
1449132,Embedding $ \mathbb{R} \to \mathbb{R}^2$,"The question I'm looking at is as follows: Prove that there is an embedding of the line as a closed subset of the plane, and there is an embedding of the line as a bounded subset of the plane, but there is no embedding of the line as a closed and bounded subset of the plane. My understanding of embedding is that it needs to be a homomorphism from $ \mathbb{R} \to f(x) \in \mathbb{R}^2$. I.e. the entire number line needs to be in $ \mathbb{R}^2$ in some shape or form after the transformation. My thoughts for the closed subset are simply $ f(x) : x \to (1,x) $ as this is is effectively the identity function plus one dimension. It is closed as all 0 limits are contained, and unbounded as the Cauchy sequences do not converge as x approaches $ - \infty $ and $ \infty $. For bounded $ f(x) : x \to (arctanh(x),x) $ on $ (-1,1) $ which encodes the entire number line, has Cauchy sequences converging at limits, but does not contain $ x = -1 $ or $ x = 1 $. Are these intuitions correct for these parts of the question, or am I misinterpreting embedding as a concept? Are there significantly simpler answers? I feel like I'm missing something.","['analysis', 'metric-spaces', 'real-analysis', 'general-topology']"
1449149,"Newton's law of cooling, soup","Newton's law of cooling states that the temperature $T(t)$ of an object at time $t > 0$ changes at a rate proportional to the difference between the temperature of the object and the temperature $T_S$ of its surroundings, provided that this difference is not too large. That is, $T(t)$ satisfies $\quad T'(t) = k (T(t) - T_s)$ where k is a constant. Suppose that the temperature of a cup of soup obeys Newton's law of cooling. If the soup has a temperature of $\; 190^\circ\, F$ when served to a customer, and 5 minutes later has cooled to $\; 180^\circ\, F$ in a room at $\; 72^\circ\, F$, how much longer must it take the soup to reach a temperature of$ \; 135^\circ\, F$? Answer (1) in additional minutes = ? If the same cup of $190^\circ\, F$ soup is instead placed into a freezer set at $30^\circ\, F,$ what is the time required for the soup to cool from $190^\circ\, F to 135^\circ\, F$ in this situation? Answer (2) in minutes = ? -- After watching the tutorial on the Cooling Law , I tried to use formula: $ T(t) = T_{surrounding} - Ce^{-kt}$ (general formula for cooling?) $C = (T - T_s)$ $T(t) = 72 - 118e^{-kt}$ (for my case) To find k: $180 = 72 - (190-72) \cdot e^{-k \frac{5}{60}}$ $180 = 72 - 118e^{-k \frac{1}{12}}$ $ k = -12 \cdot ln(\frac{-54}{59})$ Then to get answer to (1): $135 = 72 - 118e^{-kt}$ $ 135 = 72 - 118e^{12 \cdot ln(\frac{-54}{59}) \cdot t}$ $ t = \frac{ln(\frac{-63}{118})}{12 \cdot ln(\frac{-54}{59}) \cdot t} $ But that's not the correct answer! I then tried a different formula to get answer to (1): $T(t) = (T - T_s) e^{kt} + T_s$ $T(t) = 118e^{kt} + 72$ $180 = 118e^{k \cdot 5/60} + 72$ $k = 12 ln(\frac{54}{59})$ But even with this k value I get the wrong answer, why? And yes, I absolutely have to assume that t should be in hours format.","['exponentiation', 'calculus', 'ordinary-differential-equations', 'exponential-function']"
1449177,Limit as $x\to 2$ of $\frac{\cos(\frac \pi x)}{x-2} $,"I am a kid trying to teach myself Calculus in order to prepare for next year. I have the expression $$\lim_{x\to 2}\frac{\cos(\frac \pi x)}{x-2} $$ There is a hint that says to substitute t for $(\frac \pi2 - \frac \pi x)$ and WolframAlpha evaluates this expression as $\frac \pi4$. However, I got the answer of $1$. Can someone clarify the steps to solving this problem.","['limits-without-lhopital', 'calculus', 'limits', 'trigonometry']"
1449178,"Show if $N$ is normal subgroup of $G$ and $H$ is a subgroup of $G$, then $N \cap H$ is normal subgroup of $H$.","Show if $N$ is normal subgroup of $G$ and $H$ is a subgroup of $G$, then  $N \cap H$ is normal subgroup of $H$. attempt:  Then recall $N \cap H$ is normal if and only if $h(N \cap H) h^{-1} \subset N \cap H$. Then suppose $j \in (N \cap H)$ and $h \in H$. , so $hjh^{-1} = (h^{-1})^{-1} j(h^{-1}) = k \in (N \cap H),$ for some $k$, then we can solve for $j$ so we get $j = h^{-1}kh \in h^{-1}(N\cap H)h. $ Hence $N \cap H $ is cointained in $h^{-1}(N \cap H)j$ so $N \cap H = h^{-1}(N \cap H)h$. So $N\cap H$ is normal subgroup of $H$. Can someone please verify this?
My professor said I need to choose an element from one side and show the element is in the other side too. So containment in both sides. My professor said I can't assume $h(N \cap H) h^{-1}  = hNh^{-1} \cap hHh^{-1} = N \cap H.$
Can someone please help me if this is wrong. Thank you very much!",['group-theory']
1449189,Inverse limit of $\Bbb Q/q\Bbb Z$ isomorphic to finite adeles?,"Let $\Bbb Q/q\Bbb Z$, for some positive rational $q$, denote the quotient group of the discrete rationals by the subgroup of integers times $q$. For any $q_1, q_2 \in \Bbb Q^+$ and $n \in \Bbb N^+$ such that $q_2 = n \cdot q_1$, we can form a surjective homomorphism $\Bbb Q/q_2\Bbb Z \to \Bbb Q/q_1\Bbb Z$. The set of all such $\Bbb Q/q\Bbb Z$ forms a poset with these surjections, and we can take the inverse limit to get something like a ""rational solenoid."" Is this group isomorphic to the finite adele ring $\Bbb A_\Bbb Q^f \cong \Bbb Q \otimes \hat{\Bbb Z}$? Is this group equal to the same thing you'd get if you took the inverse limit of $\Bbb Q/n\Bbb Z$ for a natural number $n$ instead of a positive rational $q$? For #1, I think it is, because the dual group should be a direct limit of localizations of $\hat{\Bbb Z}$, which I believe is isomorphic to $\Bbb Q \otimes \hat{\Bbb Z}$, which is self-dual. The same reasoning applies for #2.","['harmonic-analysis', 'number-theory', 'adeles', 'profinite-groups']"
1449200,The integration of a rapidly decreasing function is bounded?,"We say function $f$ is rapidly decreasing iff $\forall\,\,l,k>0\,\,|x|^{l}|f^{k}(x)| < \infty$ on $\mathbb{R}$. Now I need to prove the integration $$\int_{\mathbb{R}}|x|^{l}|f(x)|\,dx<\infty$$
It makes intuitive sense for me, since $f$ vanishes rather quickly, so I tried to build up a connection between rapidly decreasing function and compactly supported function. I hope I can prove that the above integration is only integrating over a finite interval, but after search, it turned out that not all rapidly decreasing function is compactly supported (am I right?). I just got stuck here, could you please show me other approaches?","['fourier-analysis', 'real-analysis', 'functional-analysis']"
1449207,Confusion about partial and total derivatives.,"I stumbled upon this: And there is something that specifically bothers me. Say $$L(q(t),\dot{q}(t),t)$$ Then I claim it makes no sense that $\frac{\partial L}{\partial t}$ only differentiates the explicit dependencies of $L$ on $t$ without also differentiating the contributions of $q(t)$ and $\dot{q}(t)$. Why do I claim this? Well suppose we have a function such that $$f(x(r,\theta),y(r,\theta))$$ Then the operator $\frac{\partial}{\partial r}$ does act on the functions and not only on ""explicit dependences"". What is going on here? It might look as if I'm an advanced student because of the image I've posted, but I really am not, so don't be misguided (if that were to be the case). Thanks.","['calculus', 'derivatives']"
1449224,Uniform Convergence of Maximum of Sequence of Functions,"Let $K$ be a compact metric space, and $\{f_n\}_{n \in \mathbb{N}}$ is a uniformly bounded, equicontinuous family of functions. Define $$g_n(x) = \max \{f_1(x),f_2(x),\ldots,f_n(x)\}.$$ Prove that $g_n$ converges uniformly on $K$. I believe this stems from the fact that $g_n$ is equicontinuous (just take the smallest deltas for $g_n$) and $g_n$ is uniformly bounded. Ergo, it has a convergent subsequence by Arzela-Ascoli. It is then a simple argument to show that if some subsequence of $g_n$ converges, so does the entire sequence. Is this a fair argument?","['analysis', 'proof-verification', 'real-analysis', 'proof-writing']"
1449228,Deriving the derivative formula for arcsecant correctly,"I have been trying to derive the derivative of the arcsecant function, but I can't quite get the right answer (the correct answer is the absolute value of what I get). I first get $\frac{d}{dy}\sec(y)=\frac{\cos^2(y)}{\sin(y)}=\frac{\cos^2(\sec^{-1}(x))}{\sin(\sec^{-1}(x))}$. Then, by examining the appropriate right triangle with angle $\theta$, hypotenuse $x$, adjacent side length $1$ and opposite side length $\sqrt{x^2-1}$, we see that $\sin(\sec^{-1}(x))=\sin(\theta)=\frac{\sqrt{x^2-1}}{x}$ and $\cos(\sec^{-1}(x))=\cos(\theta)=\frac{1}{x}$. Substituting these identities into the formula for the derivative, we get $$\frac{1}{x\sqrt{x^2-1}}$$. However, the actual answer is the absolute value of that.  I can't figure out where I am assuming $x$ is positive. It has been a while since I have mucked about with this kind of thing, so my apologies if this is a silly question. Wikipedia wasn't helpful on the matter.","['derivatives', 'calculus', 'trigonometry']"
1449239,Free Generators (Basis) for a Normal Subgroup of a Free Group,"Let $F=\langle a,b\rangle$ be a free group of rank $2$. Its commutator subgroup has a nice free-basis:
$$[a^m,b^n], \,\,\,\,m,n\in\mathbb{Z}.$$ Instead of $[F,F]$, we consider another simplest normal subgroup. Let $N$ be the smallest normal subgroup of $F$ containing $a$. Of course, $N$ will not only contain powers of $a$ but elements $bab^{-1}$ also, and in general $waw^{-1}$ for any word $w$ in $F$. Question: What is a free-basis of $N$? I was thinking analogously that $\{b^iab^{-i} \colon i\in\mathbb{Z}\}$ would be a free basis. But, this is not, since in the product of these elements, the end points will be $b$ or $b^{-1}$; in particular, $(ab)a(ab)^{-1}$ can not be obtained from this set. [ As noticed by Guerin, in last paragraph, after ""But, this ...."" is incorrect! ]","['group-theory', 'free-groups']"
1449281,iterated sine function on different arguments,"I want to evaluate the following:
$\lim_{n\rightarrow \infty} \sqrt{n} \sin^{(n)}(2/\sqrt{n})$, where $\sin^{(n)}$ is the iterated sine function. I do know the proof for $\lim_{n\rightarrow \infty} \sqrt{n} \sin^{(n)}(x_0) =\sqrt{3}$ for any non trivial $x_0 \neq k\pi$ (by using Stolz-Cesaro's theorem with $a_n=\sin^{(n)}(x_0)$,$b_n=n$, and then proving the convergence of $\lim_{n\rightarrow \infty} \frac{1}{a_{n+1}^2}-\frac{1}{a_{n}^2} =1/3$). It seems like the same proof holds for $x_0=1/\sqrt{n}$ and $x_0=2/\sqrt{n}$ and hence proves $\lim_{n\rightarrow \infty} \sqrt{n} \sin^{(n)}(2/\sqrt{n})=\sqrt{3}$. But I am not entirely sure, could you clarify?","['infinity', 'sequences-and-series', 'trigonometric-series', 'trigonometry']"
1449312,Geometric meaning of Berezin integration,"Berezin integration in a Grassmann algebra is defined such that its algebraic properties are analogous to definite integration of ordinary functions: linearity (taking anticommutativity into account), scale invariance and independence from the integration variable. Up to normalization this means that $$\int f(\theta) d\theta = \int (f_0 + f_1\theta) d\theta = f_1$$ I already have a good geometric picture of Grassmann numbers themselves as elements of an exterior algebra, but I've never understood the geometric meaning of Berezin integration. What exactly are we ""summing"" and over what domain? Why the strange scaling property $d(a\theta) = a^{-1} d\theta$?","['supermanifolds', 'supergeometry', 'exterior-algebra', 'mathematical-physics', 'integration']"
1449317,Prove that $a_n$ $\rightarrow$ L $\implies$ |$a_n$| $\rightarrow$ |L|,"The book I am using for my Advance Calculus course is Introduction to Analysis by Arthur Mattuck. Prove that $a_n$ $\rightarrow$ L $\implies$ |$a_n$| $\rightarrow$ |L|.
We are needed to make a cases to use theorem 5.3B This is my rough proof to this question. I was wondering if anybody can look over it and see if I made a mistake or if there is a simpler way of doing this problem. I want to thank you ahead of time it is greatly appreciated.So lets begin: Proof:","['analysis', 'real-analysis']"
1449323,"Derivatives, discrete and continuous, of $(1/\sqrt{n})\cos (t\log n)$ and $(1/\sqrt{n})\sin (t\log n)$ and Cauchy-Riemann equations","For any arithmetical function $f(n)$, we define its derivative to be $f'(n)=f(n)\cdot \log n$ for $n\geq 1$ (see for example [1], page 45 or Wikipedia). Fact. The functions $u(n,t)=(1/\sqrt{n})\cos (t\log n)$ and $v(n,t)=(1/\sqrt{n})\sin (t\log n)$, for integers $n\geq 1$ and real $t$, satisfy the modified Cauchy-Riemann 
  $$\begin{cases}
u_n=v_t \\
u_t=-v_n
\end{cases}$$
  where the derivative with respect to $n$ is taken in the sense of the derivative of an arithmetical function. My question, and please if someone don't understand it, and another user can edit my post, or clarify my words in a comment I am agree, is Question. Is possible (thus could be in the literature or in other case we can define it) to define a derivative $D$ acting on a complex function $f$ (this function $f$ is defined from $u$ and $v$) such that implies the system of previous modified Cauchy-Riemann equations? Or is impossible find a mixture of a discrete and continuos derivative in this way? Thanks in advance. References: [1] Apostol, Introduction to Analytic Number Theory, Springer, page 45. [2] Wikipedia, Arithmetical Function, Cauchy Riemann Equations.","['arithmetic-functions', 'derivatives']"
1449342,Domain of double adjoint,"For $T$ a densely defined linear, not necessarily bounded operator on a Hilbert space $\mathscr{H}$ , and $T^{**}$ the adjoint of $T$ 's adjoint, I read somewhere that $\text{ran}(T)=\text{ran}(T^{**})$ . Is that true?
I know that $\text{ran}(T)\subset \text{ran}(T^{**})$ because of $\text{dom}(T)\subset \text{dom}(T^{**})$ , which also gives $\ker(T)\subset \ker(T^{**})$ , but I wouldn't know how to prove $\text{ran}(T^{**})\subset \text{ran}(T)$ .","['adjoint-operators', 'operator-theory', 'functional-analysis']"
1449354,Continuous Approximation for The Kelly Criterion,"I am trying to follow the derivation of Kelly Criterion, the continuous case. Dr. Thorp shows the basics of the derivation here , pg. 22. With initial capital $V_0$, betting fraction $f$, and $X$ is a random variable representing returns where $$ P(X = m+s) = P(X = m-s) = 0.5$$ The final capital is, $$ V(f) = V_0 (1 + (1-f)r + fX)  $$ $$ V(f) = V_0 (1 + r + f(X - r))  $$ His eventual goal is to find the $f$ for the maximum $E[\log(V_f)]$, and do this on a continuous scale. So he subdivides the time into $n$ pieces, $m$, $s^2$, and $r$ are replaced by $m/n$, $s^2/n$ and $r/n$ respectively, $$ P(X_i = m/n + s/\sqrt{n}) = P(X_i = m/n - m/\sqrt{n}) = 0.5$$ $$ V_n(f)/V_0 = \prod _{i=1}^{n} (1 + r + f(X_i - r))  $$ then says take log of both sides, and apply the expectation operator. I did that, $$ \log V_n(f)/V_0 = \sum _{i=1}^{n} \log (1 + r + f(X_i - r))  $$ $$ E[\log V_n(f)/V_0] = \sum _{i=1}^{n} E[\log (1 + r + fX_i - fr)]  $$ This is where I get stuck, Thorp mentions ""we expand the result in a power series"", and I've seen a similar trick in a different book , pg 137, where the author reaches a statement like $1/1+fg$ after the derivative on a log, and he turned that into $1 - fg + ..$. However I am not able to reach a similar statement. $$  = n E[\log (1 + r + fX_n - fr)]  $$ Thorp eventually reaches a formula like $$ g(f) = r + f(m-r) - s^2f^2/2 + O(n^{-1/2})$$ Any ideas? Thanks,","['probability-theory', 'probability', 'gambling', 'stochastic-processes']"
