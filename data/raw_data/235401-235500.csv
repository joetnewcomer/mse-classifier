question_id,title,body,tags
4925916,Is it possible to find the $n$th derivative of Gamma function?,"By repeatedly differentiating $\Gamma(x)$ , I noticed that $$\frac{d^{n}}{{dx}^{n}}\Gamma(x)=\sum_{k=0}^{n-1}\binom{n-1}{k}\psi^{(n-k-1)}(x)\,\frac{d^{k}}{{dx}^{k}}\Gamma(x),$$ where $\psi^{(a)}(x)$ is the polygamma function. I don't find this expression useful as the derivative of $\Gamma(x)$ appears on both sides. Is it possible to establish a closed form for this derivative? Thank you.","['polygamma', 'gamma-function', 'closed-form', 'binomial-theorem', 'derivatives']"
4925919,Strong law of large numbers: Problem with formulation of almost sure convergence,"I have a source, where the law of large numbers is stated as follows: Let $(X_i, i \geq 1)$ be a sequence of independent random variables following the same distribution as a random variable $X$ . We assume, that $E(|X|) < + \infty$ . Then, for almost every $\omega$ (this means that there exists $N \subset \Omega$ with $P(N) = 0$ and that if $\omega \not \in N$ ): $E(X) = \lim_{n \rightarrow \infty} \frac{1}{n} (X_1(\omega) + ... + X_n(\omega) )$ I have to admit, that I don't understand this formulation. If we consider for example a dice with $\Omega = \{1, 2, 3, 4, 5, 6\}$ and $X = X_i: \Omega \rightarrow \mathbb{R}, \omega \mapsto \omega$ , i.e. for example $X_i(3) = 3$ . Then $E(x) = 3.5$ , but, for e.g. $\omega = 1$ , $\lim_{n \rightarrow \infty} \frac{1}{n} (X_1(1) + ... + X_n(1) ) = 1$ . What am I mistaking?","['law-of-large-numbers', 'probability-theory', 'probability']"
4925920,All real solutions of trigonometric equation,"Find all real number $a$ ( $0\le a<2\pi$ ), such that there exists two real numbers $b,c$ satisfying the following three conditions: $a<b<c<2\pi$ $2b=a+c$ $2\cos(a)=\cos(b)+\cos(c)$ What I’ve tried:
Let $d=b-a$ , then we can write $b=a+d$ , $c=a+2d$ and $0<d<\pi-a/2$ , then the above conditions are equivalent to $\cos(a+d)+\cos(a+2d)=2\cos(a)$ . Let $f(d)=\cos(a+d)+\cos(a+2d)$ , then it's equivalent to $2\cos(a)$ being in the range of $f$ on $(0,\pi-a/2)$ . When $a$ is no less than $\pi$ , $f'>0$ , so $f$ is strictly increasing, which can't satisfy the condition. So $0\le a<\pi$ . If $f$ is strictly decreasing and then strictly increasing, the condition reduces to $1-\cos(a/2)>2\cos(a)$ , which gives the answer. But I couldn't figure out how to prove the monotonicity of $f$ .",['trigonometry']
4925924,"$\sum a_n X_n$ where $X_n$ is gaussian $\mathcal{N}(0,\sigma^2)$","This is a problem that I've been recently wondering about. It may be trivial, but for some reason it doesn't feel so to me. Suppose I have a sequence of gaussians, and I'm trying to multiply it with non-zero scalars and add them. That is, Consider $X:=\sum_{n=1}^\infty a_n X_n$ where $X_n$ is drawn IID from $\mathcal{N}(0,\sigma^2)$ . Assuming that $a_n \neq 0$ for all $n$ , under what condition on $\{a_n\}$ is $\mathbb{E}[X]=0$ ? If $X$ is a finite series, then of course the expectation is zero due to linearity. But I am unsure what happens for infinite series. Furthermore, is there a way to quantify the rate/variance of convergence? Intuitively, if $a_n =1/n$ , then the variance of $X$ is $\sum_n \sigma^2/n^2$ , as opposed to $a_n =1$ where variance is infinite.","['statistics', 'probability-distributions', 'probability-theory', 'sequences-and-series']"
4925963,"Using CLT, Slutsky's theorem and delta method","Let $Y_n$ be a sequence of random variables with $\chi^2_n$ distribution. Using Slutsky' theorem or delta method prove that $$\sqrt{2Y_n}-\sqrt{2n-1}\stackrel{D}\to N(0,1)$$ In the first place I proved from CLT that $\frac{Y_n-n}{\sqrt{2n}}\stackrel{D}\to N(0,1)$ , but I have no idea how to prove this upper convergence using Slutsky's theorem or delta method. My attempt was to write it down as $\frac{2Y_n-(2n-1)}{\sqrt{2Y_n}+\sqrt{2n-1}}$ , but I can't see a point here.","['delta-method', 'statistics', 'central-limit-theorem']"
4925976,Transfering colored balls from random bags into identical ones,"Let's consider the following scenario: There are $n$ colors, and there are $n^2$ colored balls, where we have $n$ balls of each of the $n$ colors. There are also $n$ bags $[b_1,b_2,\dots,b_n]$ where each bag contains $n$ of the above colored balls. Note that there is no condition here as to how these $n^2$ balls are distributed among the bags Is it possible to transfer all of the balls into a new set of bags $[b'_1, b'_2, \dots, b'_n]$ , where we transfer one and only one ball from each bag $b_i$ to bag $b'_j$ for all $1\leq i,j \leq n$ , AND Each bag $b'_j$ contains one and only one ball of each of the $n$ colors. If it is not possible for all the number of ways the colored balls can be present inside the initial bags, what additional conditions are needed to make sure such a transfer is possible? Example Lets consider $n=4$ , with colors $R, G,B,Y$ , and initial bags as: $b_1=\{R,R,B,Y\}$ $b_2=\{G,G,Y,Y\}$ $b_3=\{B,B,B,Y\}$ $b_4=\{R,R,G,G\}$ Then a transfer can look like the below matrix $T$ , where the color in $i^{th}$ row and $j^{th}$ column represnt the ball which went from $b_i$ to $b'_j$ $T=\begin{bmatrix} 
R & B & R & Y \\
Y & G & Y & G \\
B & Y & B & B \\
G & R & G & R
\end{bmatrix}$ I got to this subproblem while thinking the solution for another problem here My first thought was to simply ""construct"" the transfer via a simple greedy approach, but I gave up after playing with it for a bit. Another idea I have is to model the above problem as a max flow problem in graphs, which might give the correct insights to how to solve it further, but I can't correctly model it. Putting my current idea here, though I am sure it won't help much: I am constructing a graph $G$ with $2 + 2n^2$ nodes: The first node is the source node which has $n^2$ or infite amount of in flow Next $n^2$ nodes denote the colored balls before the transfer, and each node here has an inward edge with a flow limit of $1$ from the source. Next $n^2$ nodes denote the colored balls after the transfer, I am facing problem here as to how to model the incoming edges from the previous $n^2$ nodes. We can just add an edge for all pair of balls which have the same color here, but that won't enforce the only one ball from a bag to another constaint To enforce the constraint of only one ball going from one bag to another, we can two dummy nodes for each pair of bags. Here all balls of a bag before the transfer has a directed edge to the first dummy node, which then has a directed edge to the 2nd (with flow limit 1), and lastly this 2nd dummy nide has directed edges to all balls of a bag after the transfer. But in this process, we lose the color aspect of the problem entirely. The last node is the target node which has inward edges with a flow limit of $1$ coming from the above $n^2$ nodes. If this node reaches a max flow of $n^2$ , a transfer is possible. Any help is appreciated","['constructive-mathematics', 'group-theory', 'network-flow', 'algorithms']"
4925980,Which holomorphic maps $f:\mathbb{H}\to\mathbb{H}$ satisfy $f(z+1)=f(z)-1$?,"Let $\mathbb{H}$ denote the upper half-plane. Which holomorphic maps $f:\mathbb{H}\to\mathbb{H}$ satisfy $f(z+1)=f(z)-1$ for all $z\in\mathbb{H}$ ? My guess is that none exist. I think there might be orientation issues or something. One observation that I made is that $e^{2\pi i f}$ is $1$ -periodic. I was not able to get any use out of this though. I am quite stuck. Do such maps exist? And if not, then why not?","['complex-analysis', 'functional-equations']"
4926051,Approximating $\log x$ by a sum of power functions $a x^b$,"Let's approximate $\log x$ on the interval $(0,1)$ by a power function $a x^b$ to minimize the integral of the squared difference $$\delta_0(a,b)=\int_0^1\left(\log x-a x^b\right)^2dx.\tag1$$ It's easy to verify that the minimum is attained at $a_0=-\frac34,\,b_0=-\frac13$ that gives the approximation $$\log x=-\tfrac34x^{-1/3}+\mathcal R(x),\tag2$$ where $\mathcal R(x)$ is the error term. Now, let's again approximate $\mathcal R(x)$ by a power function $a x^b$ to minimize $$\delta_1(a,b)=\int_0^1\left(\mathcal R(x)-a x^b\right)^2dx=\int_0^1\left(\log x-\left(-\tfrac34x^{-1/3}+a x^b\right)\right)^2dx.\tag3$$ The minimum is attained at $$\begin{align}a_1&=\frac{17}4-\sqrt{58} \sin \left[\frac13 \arctan \left(\frac{433}{33\sqrt7}\right)\right]\approx0.88760008404...,\\b_1&=\frac{1}{3}+\frac{4}{3} \sqrt{2} \cos \left[\frac{1}{3} \arctan\left(\frac{\sqrt{7}}{11}\right)\right]\approx2.21311796239...,\end{align}\tag4$$ which are algebraic numbers of degree $3^\dagger$ . If we repeat this process once again, we will get the next term $a_2x^{b_2}$ , where $$a_2\approx-0.1406322691...,\, b_2\approx-0.2430593194...\tag5$$ are algebraic numbers of degree $15^\ddagger$ , for which I don't know any closed form. The following steps will similarly produce pairs of algebraic numbers of higher degrees, resulting in an approximation of $\log x$ on the interval $(0,1)$ by a generalized power series $$\log x\approx-\tfrac34x^{-1/3}+a_1x^{b_1}+a_2x^{b_2}+\dots,\tag6$$ where each next term causes the integral of the squared error term to progressively decrease. The powers $b_n$ and coefficients $a_n$ are not monotone and do not exhibit any clear pattern (although the coefficients generally tend to decrease in absolute value, with some sporadic spikes). Question: What does the series $(6)$ converge to? Does it converge to $\log x$ on any interval? If it does converge to $\log x$ , then empirically the convergence appears to be quite slow and erratic. ${^\dagger}$ The corresponding minimal polynomials are $\small64 z^3-816 z^2+684 z-9$ and $\small9 z^3-9 z^2-21 z-7.$ ${^\ddagger}$ The corresponding minimal polynomials are $\small5035261952 z^{15}+180729937920 z^{14}+19190513664 z^{13}-60948402536448
   z^{12}-383744783499264 z^{11}+6281308897579008 z^{10}+50474690060451840
   z^9-155303784466089984 z^8-1906255797863421024 z^7+805421030545306296
   z^6+670389754270702752 z^5+127003127714790264 z^4+8514399973766202
   z^3+130643635592430 z^2-127629387774 z-79827687$ and $\small118098 z^{15}-1299078 z^{14}-15628302 z^{13}-52936335 z^{12}-55068660
   z^{11}+119832291 z^{10}+512627130 z^9+898647291 z^8+984822786 z^7+742152591
   z^6+396538632 z^5+150470676 z^4+39697272 z^3+6920496 z^2+715716 z+33172.$ Although the polynomials look scary, they are quite nice in some sense, e.g. $\small5035261952=2^{21}\cdot7^4$ and $\small79827687=3^8\cdot23^3,$ and they also can be factored into quintics over some $\mathbb Q[q]$ with $q$ expressible in radicals.","['approximation', 'logarithms', 'real-analysis', 'calculus', 'sequences-and-series']"
4926083,Approaches to nonstandard measure theory,"So I don't really know anything about measure theory or nonstandard measure theory or nonstandard analysis or anything like that, but my friend who is taking measure theory next semester told me about non-measurable sets which peaked my interest so I looked into Vitali sets and basically got this understanding that the problem comes from trying to add up countably many uncountable sets since you get the same problem where you can ""subtract"" the set of even numbers from the natural numbers and be left with either the odd numbers or nothing based on how you match up the terms. Anyways I thought about it for a bit and basically I came up with the idea of getting rid of the requirement that the measure of the countable union of disjoint sets be equal to the sum of the measures of the individual disjoint sets. (but you still keep this relation for finitely many sets) And then I was thinking you can say something like the Vitali set sort of has an ""infinitesimal"" measure where the union of finitely many of the sets is (essentially) 0, but if you take a union of countably many sets it suddenly has nonzero measure (and the resulting measure you get can change based on how you take the countable union).
And the only other thing is then induction doesn't really hold (but I was thinking since that's an axiom this could maybe be an example of a system where induction doesn't hold?) And I tried googling some of this to see if it was a thing and found some stuff about nonstandard measure theory and nonstandard analysis but I don't really want to do all the work to look into those more and see if they are what I'm thinking of. TLDR: Can someone who has experience with nonstandard measure theory or nonstandard analysis tell me if the idea of removing the ""countable disjoint sum requirement"" for measures to get sets with a sort of ""infinitesimal"" measure is a thing or am I cranking?","['measure-theory', 'nonstandard-models', 'nonstandard-analysis']"
4926088,"Maximum value of $f(x, y, z) = yz + xz + xy − 2xyz$ for $x, y, z \ge 1$","I know I should try to explore a limit such as $\lim_{(x,y,z)\rightarrow(\infty,a, b)} f(x,y,z)$ where $a,b$ are some constants. Is it true that I can directly replace $y$ and $z$ in the limit by way of continuity? Then the limit would become $\lim_{x\rightarrow\infty}(a+b)x + ab - 2abx = \lim_{x\rightarrow\infty} (a-2ab+b)x + ab = \pm\infty$ depending on $a,b$ therefore the function cannot have a maximum value. I'm fairly certain my thinking is wrong but I don't know how to proceed with this problem. Please help. EDIT:
Calculating the 1st partial derivatives like so: $\begin{cases}f'_x = z + y - 2zy = 0\\f'_y = x + z - 2xz = 0\\f'_z = x + y - 2xy = 0\end{cases}$ $f'_y - f'_z = (z-y) - 2x(z-y) = (1-2x)(z-y)$ where the only solution is $z=y$ since $x \ge 1 \implies x\neq 1/2$ . Then substituting into the first two equations I get: $\begin{cases}x+y-2xy=0\\2y-2y^2=0\iff y(1-y)(1+y) = 0\end{cases}$ The only solution is $y=1$ since the other fall outside of the possible values for $y$ . Then going back to $f'_y$ I get $x + 1 - 2x = 0 \iff x = 1$ . Therefore there is a critical point at $(1,1,1)$ . However $f''_{xx} = 0$ which means you can't tell anything about what kind of point it is solely off of the derivative test. How can I proceed from here?","['multivariable-calculus', 'real-analysis']"
4926138,Do rational functions eventually have monotonic derivatives?,"Given a rational function $R(x)=P(x)/Q(x)$ with real coefficients, is it true that there exists an $M>0$ such that, for every $k\geq 0$ , the restrictions $R^{(k)}|_{(-\infty,-M]}$ and $R^{(k)}|_{[M,\infty)}$ of the $k$ -th derivatives $R^{(k)}(x)$ are all monotonic?
Or, in other words, is all the interesting stuff happening inside $[-M,M]$ to all orders? If we take the $k$ -th derivative of $P/Q$ , it can be proven by induction that it will be of the form $H/Q^{2^k}$ with $\deg H\leq p+(2^k-1)q-k$ where $p=\deg P$ and $q=\deg Q$ . Idk if this is of any help. (Edit: notice that we're asking if $\exists M\forall k \ldots$ and not just if $\forall k \exists M_k\ldots$ ; the latter is easy because a polynomial changes sign only finitely many times)","['rational-functions', 'real-analysis']"
4926143,Partial derivatives and functions,"If I have $y=x^2$ and I have a function of $x$ and $y$ i.e. $f(x,y)=x+y$ , then why is it that the partial derivative of this function with respect to $x$ is 1 whereas the partial derivative of $g(x)=x+x^2$ is $1+2x$ , despite the fact that $f(x,y)=g(x)$ ?","['partial-derivative', 'multivariable-calculus', 'calculus', 'derivatives']"
4926144,Non-intersecting $ABCD$ is a rectangle if $AB = CD$ and $BC = DA$ and $AC = BD$,"I have been watching videos on how to build the base for a shed. The builders use lumber for two sides of the base (which are the same length) and different sized lumber for the other two sides. To ensure the base is a rectangle, they measure the diagonals. If the diagonals are equal, the base is rectangular. I am trying to prove this mathematically. Here’s what I have so far: Given: $ AB = CD $ $ AD = BC $ Proof: If $ AC = BD $ , then triangle $ \triangle ACD $ is congruent to triangle $ \triangle BCD )$ . And here I am stuck. Any ideas on how to prove this?",['geometry']
4926154,How pathological can an unbounded function with a closed graph be?,"This question has been inspired by the answers and comments received on this sister question . Let $I\subseteq\mathbb R$ be a non-degenerate closed (but not necessarily bounded) interval. Suppose that $f:I\to\mathbb R$ is a function with a closed graph. This means that the set $\{(x,f(x))\,|\,x\in I\}$ is a closed subset of $\mathbb R^2$ . It is clear to me (see, for example, here ) that if $f$ is also assumed to be bounded, then it must be continuous. However, continuity is not guaranteed without boundedness. For example, if $I=[0,1]$ (a compact interval) and $f:[0,1]\to\mathbb R$ is defined as \begin{align*}
f(x)\equiv
\begin{cases}
\dfrac{x}{1-x}&\text{if $x\in[0,1)$,}\\
0&\text{if $x=1$,}
\end{cases}
\end{align*} then $f$ has a closed graph but it is discontinuous at $x=1$ . More complicated examples can be constructed with a greater number of discontinuities. My question is twofold: Is there a characterization of how pathological $f$ can be? (Admittedly, this question is vague, so interpret it freely.) In particular, I conjecture (but could neither prove nor come up with a counterexample) that $f$ must be of Baire class 1 —that is, it must be a pointwise limit of continuous functions. Is this conjecture true? Any guidance regarding these questions would be greatly appreciated.","['continuity', 'general-topology', 'real-analysis']"
4926216,How can I prove that $|A - B| = |A| - |B|$ where $B\subseteq A$,"I denote the cardinality of a set $S$ as $|S|$ . Now, how do I show that if $B\subseteq A$ , then $|A - B| = |A| - |B|$ ? For this proof, I tried induction on the cardinality of $B$ . Suppose that $|B| = 0$ . I've already proved that this implies that $B = \phi$ . Thus, the LHS becomes $|A - \phi| = |A|$ . The RHS becomes $|A| - |B| = |A| - 0 = |A|$ . So, LHS = RHS and the base case is shown. But I'm not quite sure how to proceed forward. I tried using the lemma (this is already proven) that $|X - \{x\}| = |X| - 1$ where $x\in X$ but to no avail. Even trying to use the lemma $|X\cup\{x\}| = |X| + 1$ where $x\not\in X$ gave me no solution. Is there a way I can go about this task?","['proof-writing', 'discrete-mathematics']"
4926262,Ratio of radii in rings of tangential circles [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 27 days ago . Improve this question The picture of my table mat above is the inspiration for this problem. Suppose we have a central circle. Around this central circle we lay a ring of $n$ smaller circles of radius $r$ such that they are tangent to two other smaller circles and also the central circle. We then lay a ring of $n$ larger circles of radius $R$ such that each one is tangent to two smaller circles and two larger circles. This is depicted in the diagram above. What is the ratio $\frac{R}{r}$ as a function of $n$ ?","['trigonometry', 'circles', 'geometry']"
4926344,ODE book for a computer science researcher (Birkoff/Rota vs Arnold),"I've have been looking for a book on ODEs and have narrowed it down to 2 candidates: Birkoff and Rota's 'ordinary differential equations' or Arnold's 'ordinary differential equations: 3rd edition'.
From reading online and skimming the texts, it is my understanding that B&R's book teaches a traditional course on ODEs, full of all the tricks and numerical methods, whereas Arnold's book takes a less traditional geometric approach focusing less on tricks/numerical methods.
What I am unsure of is whether having a deep theoretical understanding of ODEs is more important when applying differential equations, or if learning a more traditional tricks/numerical approach is better. Currently I'm leaning more towards the side of Arnold's approach, as I can't help but feel that if differential equations were needed there would exist many programs/packages for numerical procedures making them less important for me to learn. However, other comments on questions such as this make me think going the traditional route would be the safer option.
I would appreciate any suggestions as to which approach would be better in my circumstances. edit: To clarify my intentions for reading this book , I will be immediately using it as a prerequisite it to the theoretical book John Lee's Smooth Manifolds after which point I will be reading a book on dynamical systems (which will obviously also use ODE's). However, as mentioned in the question title, my primary interest is within computer science so when choosing these texts I like to consider which may be best applicable (as most texts seem to provide adequate prerequisites for later texts).","['ordinary-differential-equations', 'book-recommendation', 'reference-request', 'soft-question', 'computer-science']"
4926354,Asymptotic behavior of $(1-x)/(1-x+\epsilon)$ as $\epsilon\to 0$ [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 26 days ago . Improve this question Consider an integral $$
I(\epsilon)=\int^{1}_{0} g(x,\epsilon)\cdot\frac{1-x}{1-x+\epsilon}dx
$$ with $g(x,\epsilon)$ a very complicated function.
Can I approximate this integral with $$
I(\epsilon)\stackrel{?}{\approx}\int^{1}_{0} g(x,\epsilon)\cdot \frac{1-x}{1-x}dx =\int^{1}_{0} g(x,\epsilon)dx
$$ as $\epsilon\to 0$ ? What puzzles me is that when $x\to 1$ , the magnitude of $(1-x)$ can be comparable to $\epsilon$ . Hence, the approximation $$
\frac{1-x}{1-x+\epsilon}\approx \frac{1-x}{1-x} = 1
$$ might be problematic as $x\to 1$ .","['integration', 'asymptotics', 'analysis']"
4926369,What is the name of this combinatorial identity?,"In the course of my physics research, I appear to have stumbled onto the following combinatorial identity: $${dn\choose m}=\sum_{\vec k} {n \choose \vec k}\,\prod_{j=0}^d {d \choose j}^{k_j},$$ where $\vec k$ is a vector $$\vec k=(k_0,k_1,\ldots,k_d)$$ of non-negative integers. In the identity, we sum over all $\vec k$ that are solutions of the Diophantine equations $$\sum_{j=0}^d k_j=n$$ $$\sum_{j=0}^d j\,k_j=m$$ and we let ${n \choose \vec k}$ denote the multinomial. Note that these conditions require $0\leq m\leq dn$ . Does anyone know the name for this identity, and/or have a reference to it?","['binomial-coefficients', 'combinatorics', 'terminology', 'reference-request']"
4926375,Rebuilding of bounded linear operator between Banach spaces,"It is possible to rebuild a bounded linear operator between Banach spaces knowing the image only through the dual elements?
Maybe we need some other hypothesis but the statement could be something like: Let $Y, X$ be Banach spaces on $\mathbb{K}\in \{\mathbb{R}, \mathbb{C}\}$ , let $X$ be endowed with weak topology, $\sigma(X, X^*)$ , let $f_{x^*} \in \mathcal{L}(Y, \mathbb{K})$ (i.e linear and bounded) $\forall x^* \in X^*$ , Then $\exists !$ (or $\exists$ ) $f\in \mathcal{L}(Y, X)$ such that $f_{x^*}=x^* \circ f, \forall x^* \in X^*$","['banach-spaces', 'operator-theory', 'functional-analysis', 'weak-convergence']"
4926405,Recommendations for a second look at core subjects,"I'm starting a master's program in mathematics in September and I would like to do some review over summer, before I start, so I am looking for book recommendations. My background is in engineering (electrical and physics), but I took some pure mathematics courses at university. However, this was a while ago, since it has been a couple of years since I graduated. Analysis My analysis class used Rudin's Principles of Mathematical Analysis . We read most of the book except the final two chapters on differential forms and Lebesgue theory, and only parts of the chapter on special functions. Overall I liked the book, though the material on special functions and functions of multiple variables was perhaps too compact; I still feel somewhat weak in these areas. (I recall the proof of the implicit function theorem to be particularly difficult.) To review analysis I am considering either to: Go back to Rudin and do more exercises. I did most of the book exercises in the early chapters (1-2), but not very many in the later chapters when I took the course (because the homework problems written by the teacher took most of my time). Instead go on to Rudin's Real and Complex Analysis . Perhaps it is more useful to take the next step, instead of dwelling on the previous? Read some other author, to get a complementary viewpoint on the material. I have considered Tao's Analysis I and II , though I am a little worried that they may be too verbose (especially for review!), requiring two whole volumes. What would you recommend? Abstract algebra My abstract algebra class used Judson's Abstract Algebra: Theory and Applications , but the course emphasis was certainly on the core theory rather than the applications. My experience with this book was not great, but that is likely largely due to mathematical immaturity; this was the first rigorous mathematics course I took, even before real analysis. I am considering using Hungerford's Algebra (not Abstract Algebra: An Introduction ) for review. It is more compact than the book by Dummit and Foote, which I have also considered. Is Hungerford's Algebra a good choice? Are there better alternatives? Update 1: I started reading Hungerford and found that he requires proper subsets to be nonempty. Similarly he excludes the trivial group from being a proper subgroup. This is annoying, and turned me off somewhat. Update 2: A commenter suggested Aluffi's Algebra: Chapter 0 , which seems promising, if perhaps a bit too conversational (and lengthy!). I like that it seems to offer quite a different perspective than Judson's text. Other topics Maybe it would also be useful to study/review some other topics before starting. For example, while I have used a lot of linear algebra (including some advanced topics) in theoretical physics, I have not properly studied linear algebra beyond the basic engineering level. Perhaps some review of discrete mathematics would also be good; I took one somewhat rigorous course in the subject, though it was aimed at engineers. For topology I have been reading Lee's Introduction to Topological Manifolds lately, and though I have only completed the beginning chapters, I believe this is enough to prepare me for the master's program. Any good recommendations for linear algebra and discrete mathematics, for a student with some mathematical maturity?","['book-recommendation', 'real-analysis', 'abstract-algebra', 'linear-algebra', 'discrete-mathematics']"
4926413,Probability of choosing 4 cards whose sum is 5 from a deck of 40 cards,"Let's say we have a deck of cards excluding face cards, so cards from Ace to 10. Which of these is the correct way of computing the probability that the sum of 4 randomly chosen cards is equal to 5? Method #1: $P(X=5)=\frac{8}{40}\cdot\frac{7}{39}\cdot\frac{6}{38}\cdot\frac{4}{37}$ My logic is that for the first card, there are 8 possibilities. 4 Aces and 4 Two's. For the second card, if the first card was an Ace, there are, 7 possibilities. 3 Aces and 4 Two's. If the second card was an Ace, the third card can be chosen from 2 Aces and 4 Two's. Finally, if the third card was an Ace, the fourth card has to be a Two, so its sample space is just 4 Two's. Method #2: $P(X=5) = \frac{8}{40}\cdot\frac{4}{39}\cdot\frac{3}{38}\cdot\frac{2}{37}$ Like Method #1, the first card can be chosen from 4 Aces and 4 Two's. This time however, we will assume that the first card turned out to be a Two. By definition, all the remaining cards have to be Aces. Method #3: $P(X=5)=\frac{4}{40}\cdot\frac{4}{39}\cdot\frac{3}{38}\cdot\frac{2}{37}$ We know that in order to have a sum of 5, we specifically need 1 Two card and 3 Ace cards. The first fraction represents the probability of choosing a Two, and the rest pertains to Aces. I think Method #3 is the most plausible of them all, but I still feel that they're all wrong and that I should just use the hypergeometric formula to find out the probability.","['combinations', 'probability-distributions', 'combinatorics', 'card-games', 'probability']"
4926416,A lower bound for finite integer sequence with $a_n > (a_{n-1} + a_{n+1})/2$,"Question Cristiano Ronaldo writes a sequence $a_1$ , $a_2$$,...,$ $a_{100}$ of integers in which the first and last terms are equal to $0$ . Except for the first and last terms, each term $a_i$ is larger than the average of its neighbours $a_{i−1}$ and $a_{i+1}$ . What is the smallest possible value for the term $a_{19}$ Initial findings Since both ends of the series, i.e., $a_1, a_{100}$ are $0$ , I have a feeling that the series is symmetrical. The series increases gradually and peaks at the middle. Also, I have observed that $a_n > \min ({a_{n-1}, {a_{n+1}}})$ I also have a feeling that the first fifty terms obey this formula, $a_n > \frac {n-1}{n}{a_{n+1}}$ And that's pretty much all I can come up with. From https://gonitzoggo.com/problem/586",['sequences-and-series']
4926418,Uniform Fréchet differentiability,"Right now, I'm studying concepts of differentiation in Banach spaces, but I'm pretty new. In several references, I've found the following property: ""Let $U\subset X$ be an open convex subset of a Banach space $X$ and $f:U\rightarrow\mathbb{R}$ . Then $f$ is uniformly Fréchet differentiable if and only if $f$ is Fréchet differentiable and the map $x\mapsto f'(x)$ is uniformly continuous"". However, none of them proved it. They all say that it's trivial, but I can't figure this out. I've tried to remove the dependence of $x$ from $\delta$ in the $\impliedby$ direction and tried to bound by $\varepsilon$ the quantity $|f'(x)(h)-f'(y)(h)|$ when $\lVert x-y\rVert<\delta$ for the $\implies$ direction, but haven't reached anything. Could you guys help me? I'd be really thankful! See you!! :) Edit: My definition of Fréchet differentiability is Let $f$ be a real-valued function on an open subset $U$ of a Banach space $X$ and let $S$ be a subset of $U$ . We say that $f$ is uniformly Fréchet differentiable (UF) if it is Fr'echet differentiable at each $x \in S$ and the limit $\lim_{t\to 0}\frac{f(x+th)-f(x)}{t}$ is uniform in $x \in S$ and also in $h \in S_X$ ; more precisely, given any $\varepsilon > 0$ , there exists $\delta := \delta(\varepsilon) > 0$ , with the following property: for every $x \in S$ , $h \in S_X$ , and $0 < |t| < \delta$ with $x + th \in U$ , we have $\left| \frac{1}{t} (f(x + th) - f(x)) - f'(x)h \right| < \varepsilon$ . Definition of Fréchet differentiability","['frechet-derivative', 'banach-spaces', 'derivatives', 'functional-analysis']"
4926438,How to represent double antiderivative of a function as a definite integral,"To represent the double antiderivative of a function $f(t)$ as a definite integral: First antiderivative : $F(x)$ can be expressed as one of antiderivative of $f(t)$ : $$
   F(x) = \int_a^x f(t) \, dt
   $$ I want to understand how to find a double antiderivative of a general fucntion as a definite integral. And understand in general for more than 2 antiderivatives too My attempt: Similar to how, with the Fundamental Theorem of Calculus for a single variable, $A(x) = \int_a^x f(t)\; dt$ is expressed as the area under the graph of $f(t)$ from $a$ to $x$ and $\frac{dA}{dx} = f(t)$ , in a similar way, I used the concept of volume under a graph for finding the double antiderivative of $f(t)$ as a definite integral. What I wanted to find is: $$
\int \left( \int f(t) \, dt \right) dt
$$ Now I found it could be expressed as (I am not totally sure about this) : $$
V(t) = \int_a^t \left( \int_a^y f(x) \, dx \right) dy
$$ This in the coordinate plane of $xy$ translates to a right-angled triangle where the area we are integrating lies between $x = a$ , $x = y$ , and $y = t$ . With this definition in mind, I am not able to express how differentiating $V(t)$ two times shall give me back my function $f(t)$ again. I can find $dV$ as: $$
dV = f(t) \cdot t \, dt + \frac{f(t)}{2} \, dt^2
$$ by considering how the volume changes for $V(t)$ with a small change $dt$ (Area of the trapezium formed by change $dt$ ). However, I am struggling to express how the rate of change of the rate of change of the volume $V(t)$ with respect to a small change $dt$ equals $f(t)$ .","['indefinite-integrals', 'multivariable-calculus', 'definite-integrals']"
4926461,Some kind of generalized Leibniz Rule,"I want to compute a modified version of the following: Defining $ \partial_i := \frac{\partial}{\partial q_i}$ we can write $$ \partial_{a_1} \cdots \partial_{a_n} \: q_{a_1} \cdots q_{a_n} = \sum_{\sigma \in S_n} \prod_{i=1}^n \delta_{a_i a_{\sigma(i)}} $$ Now if I sum over all $ \{a_i\}_{i=1}^n $ where every index ranges from 1 to N, then $$ \sum_{\{a\}}  \prod_{i=1}^n \delta_{a_i a_{\sigma(i)}} = Z(S_n; N, \dots , N) $$ where $Z(S_n)$ is the cycle index polynomial of the symmetric group $S_n$ and every cycle of any length will provide a factor of $N$ , since every cycle traces the identiy matrix. This case is straightforward because its just a permutation on the set of indices i.e. a bijection of them on themselves. Now my problem is the computation of a modified case like $$ (\prod_{j=1}^n\partial_{a_j}) \: (q_{a_1}^2 \prod_{i=3}^n q_{a_i}) $$ as you can see the index $a_1$ ""appears twice"" in the sense that if I go through with the derivatives it would be like a mapping $$ \{a_1,\dots,a_n\} \to \{a_1, a_1, a_3,\dots, a_n\} $$ but this is not a bijection and hence no permuation. Do you guys know how to give a closed form for this case and even cases where more than one $q_{a_i}$ appears quadratically?","['symmetric-groups', 'multivariable-calculus', 'group-theory', 'combinatorics']"
4926499,Counting ones in binary representation: When is the product multiplicative?,"Question: For $n \in \mathbb{Z}^+$ , define $Z(n)$ to be the number of ones in the binary expression of $n$ . For fixed positive integer $a$ , how does one describe the set of $b$ such that $Z(ab) = Z(a)Z(b)$ ? Bounty Added (Jun 6, 2024): So far there is one answer provided, and I received a similar answer by email that I paste below; additional ideas and reference pointers are most welcome! Edit (Jun 4, 2024): In response to two different comments: Corrected an image and introducing Hamming weight , which (in the case of binary strings) refers to the total number of ones in a string. With this additional vocabulary item, the main question can be rephrased as asking when the Hamming weight is multiplicative. Edit (Jun 3, 2024): I used GPT-4 ( link ) to create graphs with the following query: consider a positive integer n. define Z(n) to be the number of ones in the binary representation of n. create a 100 by 100 graph where (a,b) is colored black if Z(ab)=Z(a)*Z(b), and colored white otherwise. Here is an image of the graph that was produced: Because of a pattern that looks like the Sierpinski Triangle in the bottom right hand corner of this graph, I followed up by specifically printing graphs where both $a,b$ are in the range $[64, 128]$ and then $[128,256]$ . Those images are pasted below: I suspect this Sierpinski pattern holds for $a,b$ in $[2^k, 2^{k+1}]$ for large $k$ , but am not sure how to prove it. Ideas in this direction are welcome, although the intention of this initial question is the bolded question of the top. Edit asked by author (Jun 8, 2024) : Beautiful $100\times100$ plot (generated by GPT-4o) of the ratio $Z(ab)/(Z(a)Z(b))$ as shades of gray, as dvitek proved that this ratio was in $[0, 1]$ .","['binary', 'number-theory', 'reference-request', 'multiplicative-function', 'recreational-mathematics']"
4926514,Closed geodesics of a non positively curved manifold are minimizing,"As the title says, closed geodesics of a complete non positive sectional curvature manifold should be minimal in their free homotopy class. This should be well known but I don't know a reference.
I can imagine at least two proofs: using flat strip theorem or using Morse theory. Neither are very simple, so a reference would be preferred.","['curvature', 'geodesic', 'riemannian-geometry', 'differential-geometry']"
4926520,Sticks and stones for extended objects,"Suppose that we have a circle around which $L$ buckets are arranged. We have $k$ balls to distribute among the buckets and each bucket can contain at most one ball. For the purpose of this discussion suppose that $k\ll L$ , something along the lines of $k=10$ and $L=100$ . Now fix an integer $0<N<k$ . My task is to count the number of ways that the $k$ balls can be arranged such that they are organized into $N$ non-adjacent clusters of filled buckets. For example, take the case $N=1$ . In this case there is a single cluster, so all of the balls occupy a set of $k$ consecutive boxes on the circle. There are $L$ choices of such a region, so the answer in this case is $L$ . The next case I've worked out is $N=2$ . (EDIT: What I've written here for $N=2$ is incorrect. See the selected answer below for a correction.) In this case, we suppose that the first cluster has size $n_{1}$ and the second has size $n_{2}$ . The first cluster can be inserted in $L$ places, after which the second has $L-n_{1}-2$ possible locations. Moreover if $n_{1}=n_{2}$ we need to account for the fact that the regions are identical and divide by two. The result in this case is then given by the sum $$\sum_{n_{1}=1}^{k}\sum_{n_{2}=1}^{n_{1}}\frac{\delta(k-n_{1}-n_{2})}{1+\delta(n_{1}-n_{2})}L(L-n_{1}-2)$$ This is as far as I've gotten because things seem to get trickier for $N=3$ . In this case once you pick $n_{1}$ and $n_{2}$ , the possible locations of the third cluster are constrained by how close the first and second clusters are to one another. This correlation seems to make things trickier so I am looking for new ideas about how to proceed.","['combinatorial-geometry', 'combinatorics']"
4926522,"Proving that operator in $L^2[0,1]$ is compact","I need help with some functional analysis: Let $A$ be a continuous linear operator on $L^2[0,1]$ and for any $f \in L^2[0,1]$ the function $Af$ is Lipschitz continuous. Show that $A$ is compact. It is obvious that $\mathrm{Im}\, A \subset C[0,1]$ and that should be the only use of Lipschitz continuity here. I was told that the following theorem might help here, but still don't know how to use it: let a banach space $X$ be reflexive and $X^*$ separable (both hold for $L^2[0,1]$ ), then the unit ball is weakly sequentially compact, i.e. every sequence in $\{x: \|x\| \leq 1\}$ has a weakly convergent subsequence. Thanks for any tips!","['operator-theory', 'lp-spaces', 'compact-operators', 'functional-analysis']"
4926538,$\lim_{ r \to 0} \int_{\gamma(r)} \frac{e^z}{z}dz$,"Evaluate $\displaystyle\lim_{ r \to 0} \int_{\gamma(r)} \frac{e^z}{z}dz;\quad \gamma(r)(t)=re^{it};\quad t \in [0, \pi];\quad r>0$ . \begin{align}
\lim_{ r \to 0} \int_{\gamma(r)} \frac{e^z}{z}dz & =
\lim_{ r \to 0} \int_{\gamma(r)} \frac{e^z-1+1}{z}dz=\lim_{ r \to 0} \int_{\gamma(r)} \frac{e^z-1}{z}dz+\lim_{ r \to 0} \int_{\gamma(r)} \frac{1}{z}dz
\\[2mm] & =\lim_{ r \to 0}\left[F(-r)-F(r)+\pi {\rm i}\right] = \pi{\rm i}
\end{align} where $F$ is a primitive of the analytic function $\left({\rm e}^{z} - 1\right)/z$ that exists as its domain is a simply connected region. Is this alright ?. Any other alternatives ?.",['complex-analysis']
4926561,Polynomials with equal magnitude on the unit circle,"Let $p(z), q(z)$ be non-constant polynomials of the same degree n such that $|p(z)| = |q(z)|$ on the unit circle (where $|z| = 1$ ) and all their zeros are in the interior of the unit disk. I'm trying to prove that in that case it must be that $q(z) = ap(z)$ for some (complex) $a$ . My initial instinct is to try and somehow use the fact that for $f(z) = \frac{p(z)}{q(z)}$ we have $|f(z)| = c > 0$ on the boundary $|z| = 1$ and perhaps invoke the maximum modulus principle somehow, asserting that any singularity of $f(z)$ (where only $q(z) = 0$ ) inside the unit disk would be a pole, hence f(z) would tend to $\infty$ in a neighborhood of that point, contradicting the maximum modulus principle. But this seems off since (For example) my understanding is that to invoke max modulus principle I would need $f(z)$ to be continuous on the closure of the domain in question (the open disk), e.g. including any 'puncture points' where those aforementioned singularities would arise? Any direction would be appreciated how to approach this otherwise!",['complex-analysis']
4926570,Find the side of the square ABCD in the figure below,"In the figure, ABCD is a square.
If $\dfrac{1}{BM^2}+\dfrac{1}{BN^2} = \dfrac{1}{25}$ , calculate AB
(Answer: $AB=5$ ) I try: $\triangle ABN \sim \triangle DMN: \frac{MN}{BN} = \frac{MD}{L}=\frac{ND}{L+ND}$ $\triangle MBC:: L^2+MC^2 = MB^2$ $\triangle ABN: L^2+BN^2=(L+DN)^2$ $\triangle BCM \sim \triangle NDM: \frac{ND}{L}=\frac{DM}{MC}=\frac{MN}{BM}$ $\triangle MBC \sim \triangle NBA: \frac{BM}{BN}=\frac{L}{L+DN}=\frac{MC}{L}$","['euclidean-geometry', 'geometry', 'plane-geometry']"
4926589,Proving (p → r) ∨ (q → r) ≡ (p ∧ q) → r,"So I do understand that this could be much more easily proven using basic logical equivalences as follows: (p → r) ∨ (q → r) ≡ (¬p ∨ r) ∨ (¬q ∨ r) ≡ (¬p ∨ ¬q) ∨ r ≡ ¬(p ∧ q) ∨ r ≡ (p ∧ q) → r However, since (p → r) ∨ (q → r) ≡ (p ∧ q) → r is the same as (p → r) ∨ (q → r) ↔ (p ∧ q) → r being a tautology, I thought why not try proving the bi-conditional statement by doing direct proof both directions: For the ((p → r) ∨ (q → r)) → ((p ∧ q) → r) part: To prove this conditional, we'd have to assume (p → r) ∨ (q → r) is true and show (p ∧ q) → r becomes true from it. To show (p ∧ q) → r is true, we'd have to assume (p ∧ q) is true and r is true. Hence, we'd be assuming both (p → r) ∨ (q → r) and (p ∧ q) are true. (p → r) ∨ (q → r) means at least one of the 2 implications that give the consequence of r is true, and since both p and q are true this means r must also be true. Hence proof complete for forward implication. For the ((p ∧ q) → r) → ((p → r) ∨ (q → r)) part: This one was the main point of confusion (and what my question is all about) . Proving a implication with a disjunction as the consequent was something I was unsure how to do (and what I've seen many other people have asked too online unsure about). So I just did some logical equivalences (where for propositions x, y, and z, [x → (y ∨ z)] ≡ [(x ∧ ¬y) -> z]). to get this expression is equivalent to ((p ∧ q) → r) ∧ p ∧ ¬r) → (q → r). Therefore, I first assumed LHS was true, then assume q is true. Assuming LHS true means all propositions in conjunction are true, meaning p and ¬r should be true (meaning r is false). So LHS is hence ((T ∧ T) → F) ∧ T ∧ T) = F ∧ T ∧ T = F. Hence there's a contradiction. This last part/contradiction is what's confusing me here. What do I take from this part of the proof exactly? Is the entire implication now proven true vacuously or something? I'm lost here essentially. Kindly please let me know.","['propositional-calculus', 'logic', 'alternative-proof', 'discrete-mathematics', 'natural-deduction']"
4926596,Why $\infty=\sum_{i=1}^\infty \frac{1}{n+i}\neq\lim_{n\rightarrow\infty}\sum_{i=1}^n \frac{1}{n+i}=\log2$?,"I was wondering why $\sum_{i=1}^\infty \frac{1}{n+i}$ diverges but $\lim_{n\rightarrow\infty}\sum_{i=1}^n \frac{1}{n+i}=\log2$ . While assuming integral as limit of series, we find out that: $$
\int_1^2\frac{\mathrm{d}x}{x}=\lim_{n\rightarrow\infty}\sum\left(f;P_n^*\right)=\lim_{n\rightarrow\infty}\sum_{i=1}^nf(\xi_i)(t_i-t_{i-1}), f(x)=\frac{1}{x}
$$ where $\xi_i\in[t_{i-1},t_i]$ and $P_n^*=\{t_0,...,t_{i-1},t_i,...,t_n\}$ is a partition of $[1,2]$ , assuming $t_0=1$ and $t_n=2$ . Forcing $t_i=\frac{n+i}{n}=1+\frac{i}{n}$ , then $t_i-t_{i-1}=1+\frac{i}{n}-(1+\frac{i-1}{n})=\frac{1}{n}$ and $f(\xi_i)=\frac{1}{\xi_i}$ . Considering $\xi_i=t_i$ we have: $$
\lim_{n\rightarrow\infty}\sum_{i=1}^nf(\xi_i)(t_i-t_{i-1})=\lim_{n\rightarrow\infty}\sum_{i=1}^n\frac{1}{\frac{n+i}{n}}\frac{1}{n}=\lim_{n\rightarrow\infty}\sum_{i=1}^n\frac{1}{n+i}
$$ By one hand this is equals to $\int_1^2\frac{\mathrm{d}x}{x}$ , which is equals to $\log2$ , by other hand $\sum_{i=1}^\infty \frac{1}{n+i}$ is supposed to diverge as $\sum_{i=1}^\infty \frac{1}{i}$ diverges. I'm asking what's wrong here. See below to notice by yourselves this paradox: Valuation of $\displaystyle \sum_{i=1}^\infty \frac{1}{n+i}$ , per WolframAlpha Valuation of $\displaystyle \lim_{n\rightarrow\infty}\sum_{i=1}^n \frac{1}{n+i}$ , per WolframAlpha","['integration', 'summation', 'real-analysis', 'sequences-and-series', 'limits']"
4926617,region above the cone and inside the sphere,"I've come across a problem where \begin{array}{c}
\mbox{I have to compute the volume of the region}
\\ \mbox{above the cone}\
z^2 = \sqrt{x^2 + y^2}\ \mbox{and inside the sphere}\ x^2 + y^2 + z^2 = 1
\end{array} I can't understand one thing, since this equation of the cone depicts an open $\mbox{cone ?}$ , what would be the region above the cone and inside the sphere I can include the image of what I sketched for a better view on how I tried to do the problem I just can't seem to pinpoint what would be the region above the cone and inside the sphere as stated in my problem requirements.","['integration', 'multivariable-calculus', 'calculus', 'vector-analysis']"
4926619,"Branching Rule for GL(n,q)","let $\mathbb{F}_q$ be a finite field of order $q$ , I know that the irreducible representations of the general linear group $GL_n(\mathbb{F}_q)$ is parametrized by partition-valued functions, I want to ask if there exists some branching rule (similar to $S_n$ ) when restricting the irreducible reps of $GL_n(\mathbb{F}_q)$ to the special linear group $SL_n(\mathbb{F}_q)$ ? Thank you.","['abstract-algebra', 'representation-theory']"
4926669,Approximating the length of a circular arc using geometrical construction. How does it work?,"I was going through my Engineering Drawing textbook and came upon this topic. Using only a compass and a straightedge, one can supposedly approximate the length of a given circular arc by following the steps below. Let AB be the given circular arc. Draw chord AB and extend it to one side. Draw perpendicular bisector of AB to get its midpoint C. Mark point D on the extended chord such that AC=AD. Draw a tangent line to the given arc passing through point A. With D as center and DB as radius, draw an arc which intersects the tangent line passing through A at point E. We get AE which is the required arc length. Here is a picture from the book demonstrating the above steps. My question is how does this approximation work? Before this topic, there was a section on approximating the circumference of a circle using a compass and straightedge only. Using basic trigonometry, I realized it was using the relation $\ 2π \approx \sqrt{6^2+ (1+\sin(60 ^{\circ}))^2}$ to construct a right angled triangle whose hypotenuse would approximate the circumference of the circle utilizing above approximation, which I found pretty impressive. But, when I tried to find out how the method worked for approximating the arc length of a circular arc, I had no luck. I tried some preliminary angle chasing and later tried using coordinate geometry but couldn't come up with an expression for length of AE. How could I show that the above steps work for approximating arc length?","['approximation', 'arc-length', 'geometry', 'geometric-construction']"
4926694,Commutivity of two derivatives for exponential map,"I'm reading the book Hörmander Operators by Marco Bramanti and Luca Brandolini World Scientific, 2023 . I had a problem when reading the proof of the following theorem: Theorem 1.9 Let $X$ and $Y$ be smooth vector fields in a domain $\Omega$ such that $[X, Y] \equiv 0$ . Let $x_{0} \in \Omega$ . There
exist $\varepsilon>0$ such that for every $|t|<\varepsilon $ \begin{array}{l} \exp (t X) \exp (t Y)\left(x_{0}\right)=\exp
 (t(X+Y))\left(x_{0}\right) ; \\ \exp (-t X) \exp (-t Y) \exp (t X)
\exp (t Y)\left(x_{0}\right)=x_{0} \end{array} Proof . The second identity easily follows from the first one. To prove
the first identity, let $\varphi(t)=\exp (t X) \exp (t
 Y)\left(x_{0}\right)$ . Clearly $\varphi(0)=x_{0}$ . We will show that $$\varphi^{\prime}(t)=X_{\varphi(t)}+Y_{\varphi(t)}\tag{1.8}$$ and therefore $\varphi(t)=\exp (t(X+Y))\left(x_{0}\right) $ . Let now $$F(u, v)=\exp (u X) \exp (v Y)\left(x_{0}\right),$$ it follows that $\varphi^{\prime}(t)=\frac{\partial F}{\partial u}(t,t)+\frac{\partial F}{\partial v}(t, t) $ . For the first term we have $$\frac{\partial F}{\partial u}(t, t)=X_{\exp (t X) \exp (tY)\left(x_{0}\right)}=X_{\varphi(t)}$$ In order to evaluate $\frac{\partial F}{\partial v}(t, t)$ we set $G_{v}(u)=\frac{\partial F}{\partial v}(u, v)$ , we observe that $G_{v}(0)=   Y_{\exp (v Y)\left(x_{0}\right)}$ and that \begin{align} G_{v}^{\prime}(u) & =\frac{\partial^{2} F}{\partial v
\partial u}(u, v)=\frac{\partial}{\partial v}\left(X_{\exp (u X) \exp
(v Y)\left(x_{0}\right)}\right) \\ & =J_{X}\left(\exp (u X) \exp (v
Y)\left(x_{0}\right)\right) \frac{\partial}{\partial v}\left(\exp (u
X) \exp (v Y)\left(x_{0}\right)\right) \\ & =J_{X}\left(\exp (u X)
\exp (v Y)\left(x_{0}\right)\right) G_{v}(u) \end{align} Let now $H_{v}(u)=Y_{\exp (u X) \exp (v Y)\left(x_{0}\right)}$ ,
observe that $H_{v}(0)=Y_{\exp (v Y)\left(x_{0}\right)}$ and that \begin{aligned} H_{v}^{\prime}(u) & =J_{Y}\left(\exp (u X)\exp (v Y)
x_{0}\right) \frac{\partial}{\partial u}\left(\exp (u X) \exp (v Y)
x_{0}\right) \\ & =J_{Y}\left(\exp (u X) \exp (v Y) x_{0}\right)
X_{\exp (u X) \exp (v Y) (x_{0})} 
\end{aligned} Since the vector fields $X$ and $Y$ commute, by (1.7), $J_{X}(x)Y_{x}=J_{Y}(x) X_{x}$ and therefore \begin{aligned} H_{v}^{\prime}(u) & =J_{X}\left(\exp (u X) \exp (v Y)
x_{0}\right) Y_{\exp (u X) \exp (v Y) x_{0}} \\ & =J_{X}\left(\exp (u
 X) \exp (v Y) x_{0}\right) H_{v}(u) \end{aligned} It follows that $H_{v}$ and $G_{v}$ satisfies the same Cauchy problem
so that $$\frac{\partial F}{\partial v}(u, v)=G_{v}(u)=H_{v}(u)=Y_{\exp (u X)
 \exp (v Y)\left(x_{0}\right)} .$$ Hence $\frac{\partial F}{\partial v}(t, t)=Y_{\varphi(t)} $ and (1.8)
follows. where (1.7) is $$[X,Y]_x=J_Y(x)X_x-J_X(x)Y_x$$ $J_X$ is the Jacobian of the map $x\mapsto X_x$ . My main questions is at \begin{align} G_{v}^{\prime}(u) & =\frac{\partial^{2} F}{\partial v
\partial u}(u, v)=\frac{\partial}{\partial v}\left(X_{\exp (u X) \exp
(v Y)\left(x_{0}\right)}\right) \\ & =J_{X}\left(\exp (u X) \exp (v
Y)\left(x_{0}\right)\right) \frac{\partial}{\partial v}\left(\exp (u
X) \exp (v Y)\left(x_{0}\right)\right) \\ & =J_{X}\left(\exp (u X)
\exp (v Y)\left(x_{0}\right)\right) G_{v}(u) \end{align} There should be $$G_{v}^{\prime}(u)=\frac{\partial^2 F}{\partial u\partial v}(u,v),$$ why they can commute? It's not obviously for me, and there taking derivative for vector field and Jacobian make me confuse, it can be rewritten more strictly? Any anwser and comment are appreciate! I have recognized this theorem can be corollary of Baker-Campbell-Hausdorff formula, but I wonder is it reasonable for the original proof. Thanks for comment, it's necessary to give some definition. So $\Omega$ is a domain in some Lie group, and Lie bracket $[X,Y]$ as standard definition, where $exp(tX)(x_0)$ defined as a $C^1$ integral curve $\varphi(t)$ , is the solution as Cauchy problem \begin{align}
\begin{cases}
\varphi'(t)=X_{\varphi(t)}\\
\varphi(0)=x_0
\end{cases}
\end{align}","['vector-fields', 'differential-geometry']"
4926772,Existence of a smooth function with some boundary conditions,"Given $\epsilon > 0$ , can we find a smooth function $f:[0,\epsilon]\rightarrow [0,1]$ satisfying the following conditions? $f(0)=1$ and $f(\epsilon) =0$ . $f^{(n)}(0+) = f^{(n)}(\epsilon-)=0$ , i.e., for each $n\in\mathbb{N}$ both the right $n^{th}$ derivative of $f$ at $0$ and left $n^{th}$ derivative of $f$ at $\epsilon$ are zero. $f$ is strictly positive on $(0,\epsilon)$ . $\int_0^{\epsilon} f(x)\,dx = \frac{\epsilon}{2}$ . My natural guess was to take $f(x)=\left(\frac{e^{\frac{1}{x}}}{e^{\frac{1}{x}} + e^{\frac{1}{\epsilon - x}}}\right)^\alpha$ and choose $\alpha$ so that all the four conditions get satisfied. However, I am not able to verify the details. Am I correct on this, or do I need some other function? Thanks in advance for any help or suggestions.","['integration', 'functions', 'exponential-function', 'real-analysis']"
4926775,Find area of figure and volume of body,"Problem Find area: $$\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2=\frac{xy}{c^2},\qquad a,b,c > 0$$ My solution: The figure encloses area under itself so we're looking at: $$\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2\leq\frac{xy}{c^2},\qquad a,b,c > 0$$ The function is symmetric in first and third quadrant, therefore if $S_D$ is the total area under the function defined in domain $D$ and $D1$ is the domain only for $x\geq0$ , $y\geq0$ (first quadrant): $S_D=2S_{D1}$ $D1$ : $$(\frac{x^2}{a^2}+\frac{y^2}{b^2})^2\leq\frac{xy}{c^2} \wedge x \geq 0 \wedge y \geq 0 \wedge a,b,c > 0$$ And by chekcing $(x,y)=(0,0)$ $$0\leq\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2\leq\frac{xy}{c^2} \wedge x \geq 0 \wedge y \geq 0 \wedge a,b,c > 0$$ (But $\left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2$ is always positive for every $x$ and $y$ ) And from here I don't really know how to continue to get the double integral that calculates the area for the figure. I'm pretty sure I have to express $y$ or $x$ as a function of the other, but I don't know how to form the function which has 4th, 2nd and 1st degree terms. I also tried polar coordinates change of variables, but to no avail (but I did know it wouldn't work since there's also terms of first degree on the right side of the equation): $$S_D = 2\int \int_{D1} \left(\frac{x^2}{a^2}+\frac{y^2}{b^2}\right)^2 - \frac{xy}{c^2}\, dx\, dy$$","['integration', 'multivariable-calculus', 'calculus', 'area']"
4926778,Limit of the sequence $u_{n+1}=2^{n+1}\arctan \left(\frac{u_{n}}{2^{n+1}}\right)$,"I am interested in calculating the limit of the sequence $$
u_{n + 1} = 2^{n + 1}
\arctan\left(\dfrac{u_{n}}{2^{n + 1}}\right)
\,,\qquad\left(\ u_{0} > 0\,\right)
$$ By the inequality $\arctan\left(x\right) < x,\ \mbox{if}\quad x > 0\ ,$ we can see that: $u_{n}$ is strictly decreasing and $0 < u_{n} < u_{0}$ , thus the sequence converges. As $\arctan\left(x\right) \approx x$ ( if $x$ approaches to $0$ ) and thus $u_{n+1}\approx u_{n}$ ( if $n$ is big ), it converges very slowly. ( a $\tt Python$ script shows that we get a decrease of $0.01$ in $1000$ steps ! ). By the fixed point theorem, we can show that $$
\dfrac{u_{n}}{2^{n}} \to 0
$$ But it is too little to infer that the limit of $u_{n}$ is zero $\ldots$ Can anyone have an idea, how to prove it ?.","['limits', 'sequences-and-series']"
4926801,How to Prove $ E[X^2Y^2] \leq E[X^2]E[Y^2] $,"I'm working on a problem involving the expectations and variances of random variables, and I encountered a step that I'm not sure how to prove rigorously. Specifically, I need to show that: $ E[X^2Y^2] \leq E[X^2]E[Y^2] $ I understand that this seems related to the Cauchy-Schwarz inequality, but I'm not sure how to apply it correctly in this context. Here are the conditions I'm working with: ( X ) and ( Y ) are random variables. I do not assume that ( X ) and ( Y ) are independent. I know also that $X$ and $Y$ are uncorrelated. Could someone please provide a detailed proof or explanation for why $ E[X^2 Y^2] \leq E[X^2]E[Y^2] $ ? Thanks in advance for your help!","['cauchy-schwarz-inequality', 'probability-distributions', 'probability-theory', 'probability']"
4926906,Any reference about neumann eigenvalue problem,"I would like to get a good reference for the study of the following eigenvalue problem $$ -\Delta u + u = 0, \quad \mbox{in} \ \Omega \quad \mbox{and} \quad 
\dfrac{\partial u}{\partial \nu} = \lambda u, \quad \mbox{on} \ \partial \Omega.
$$ Here $\Omega$ is a smooth bounded domain contained in $\mathbb{R}^N$ . More precisely, i would like to find some reference that study the spectral theory of this problem and describe the eigenvalues, if the first eigenvalue is positive, if we can write $H^1(\Omega)$ as the direct sum of the eigenspaces generated by the eigenfunctions, regularity of the eigenfunctions, positivity of the first eigenfunction, this type of results. Any help is very appreciated.","['reference-request', 'functional-analysis', 'partial-differential-equations']"
4926918,Adjoint of Cartan's magic formula,"It is well-known that if $X$ is a vector field and $\omega$ is a form, then we have Cartan's ""magic"" formula $$ L_X \omega = d\iota_X \omega + \iota_X d\omega. $$ Assuming that we are on a (pseudo-)Riemannian manifold, I would like to obtain an ""adjoint"" formula for the codifferential. It is also known that $$ \langle \iota_X \omega, \eta \rangle = \langle \omega, X^\flat \wedge \eta \rangle, $$ so if we apply $\langle\langle \eta, \cdot \rangle\rangle$ (here I am taking the $L^2$ inner product and assuming the forms are compactly supported) to Cartan's formula, we get $$ \langle\langle L_X \omega, \eta \rangle\rangle = \langle\langle \omega, X^\flat \wedge d^*\eta + d^*(X^\flat \wedge \eta) \rangle\rangle. $$ For the left-hand side, we can write \begin{align*}
\langle L_X \omega, \eta \rangle &= -\langle \omega, L_X \eta \rangle + d\langle \omega,\eta\rangle(X) - (L_Xg)(\omega,\eta) \\
&= -\langle \omega, L_X \eta + \text{div}(X)\eta \rangle - \text{div}(\langle\omega,\eta\rangle X) - (L_Xg)(\omega,\eta).
\end{align*} The divergence in the second term will die after integration, but how do I deal with the last term?","['semi-riemannian-geometry', 'riemannian-geometry', 'differential-geometry']"
4926925,Existence of maximal free submodules,"Let $A$ be a domain and $M$ be a finitely generated module. Is there a free submodule which is maximal among free submodules? Answer is yes for Noetherian rings, obviously. Also the rank of any such submodule is determined by $M$ by tensoring up with $Q(A)$ . I haven't got much further than this.","['free-modules', 'abstract-algebra', 'modules']"
4926934,Higher Degree Differential Equation,"I'm having trouble with the development of this equation: $$\sin{y'}-x=0 $$ If I solve the equation with this method, I don't have any problems. $$\sin{y'}=x$$ $$y'=\arcsin{x}$$ $$\int dy=\int \arcsin{x} dx$$ $$y = x\,\arcsin\left(x\right)+\sqrt{1-{x}^{2}}+C$$ But if I try this way (relative to x) $$p= \frac{dy}{dx} = y'$$ $$\sin{p}=x$$ Where $$x = f(p, y); p=p(y) $$ $$\therefore [\sin{p}]' =[x]' \implies \cos{p}\frac{dp}{dy} =\frac{dx}{dy}$$ If $$p=\frac{dy}{dx} \implies \frac{1}{p} =\frac{dx}{dy}$$ $$\therefore \cos{p}\frac{dp}{dy}=\frac{1}{p}$$ $$p\cos{p}\frac{dp}{dy}=1$$ $$p\cos{p}dp=dy$$ $$\int p\cos{p}dp=\int dy$$ $$p\sin{p}+\cos{p}+k_1= y+k_2$$ $$ p\sin{p}+\cos{p}+C= y$$ It's at this point where I don't know how to go any further I have a clue, which would be: $$y = \arcsin{x} \implies dy = \frac{1}{\sqrt{1-x^2}} dx$$ $$\therefore p =\frac{dy}{dx} =\frac{1}{\sqrt{1-x^2}}$$ How could I come up with the solution?","['trigonometry', 'ordinary-differential-equations']"
4927010,Uniform Tightness of a Sequence of Probability Measures in $\mathbb R^{\mathbb N}$,"Consider a sequence $(P_n)_{n\in\mathbb N}$ of probability measures on $(\mathbb R^{\mathbb N}, \mathcal B)$ , where $\mathbb R^{\mathbb N}$ is the countable Cartesian product of $\mathbb R$ , and $\mathcal B$ is the $\sigma$ -algebra generated by the topology of pointwise convergence, i.e. the topology generated by the metric $$d(x,y) = \sum_{n=1}^\infty \frac{\min(1,\vert x_n - y_n\vert)}{2^n}.$$ The corresponding metric space is complete, and the generated topology is separable. Therefore, every probability measure on $(\mathbb R^{\mathbb N},\mathcal B)$ is tight. Let $P$ be a (tight) probability measure on $(\mathbb R^{\mathbb N},\mathcal B)$ . We have the following theorem: Theorem 1: $(P_n)_{n\in\mathbb N}$ converges to $P$ iff $(\pi_k\#P_n)_{n\in\mathbb N}$ converges to $\pi_k\#P$ for all $k\in\mathbb N$ . Proof . (See Example 2.6 in Billingsley ""Convergence of probability measures"" (2nd edition).) Here $\pi_k$ denotes the coordinate projection of $\mathbb R^{\mathbb N}$ onto $\mathbb R^k$ and $\pi_k\#P$ the pushforward probability measure of $P$ under $\pi_k$ . Now suppose that $(\pi_k\#P_n)_{n\in\mathbb N}$ converges to $\pi_k\#P$ for all $k\in\mathbb N$ . By Theorem 1, $(P_n)_{n\in\mathbb N}$ converges to $P$ . Since $P_n$ is tight for every $n\in\mathbb N$ , and $P$ is also tight, a Theorem due to Le Cam yields that $(P_n)_{n\in\mathbb N}$ is uniformly tight. (Is this correct?) I would like to prove the "" $\Leftarrow$ ""-direction of Theorem 1 just by using tightness + weak convergence of finte dimensional marginals. To this end, I would have to show uniform tightness of $(P_n)_{n\in\mathbb N}$ . However, I don't know how to approach this. What we have: $P_n$ is tight for each $n\in\mathbb N$ $\pi_k\#P_n$ converges to $\pi_k\#P$ for all $k\in\mathbb N$ To show: for all $\epsilon>0$ there is $K\subset\mathbb R^{\mathbb N}$ compact such that $$\sup_{n\in\mathbb N}P_n(\mathbb R^{\mathbb N}\setminus K) \leq \epsilon.$$ My idea: for any $k\in\mathbb N$ , we have that $\pi_k\#P_n$ converges to $\pi_k\#P$ by assumption. Hence, for any $\epsilon>0$ there is $A\subset\mathbb R^k$ compact such that $$\sup_{n\in\mathbb N}\,(\pi_k\#P_n)(\mathbb R^k\setminus A) \leq \epsilon.$$ I thought that the considered topology over $\mathbb R^{\mathbb N}$ allows to somehow ""embed"" a compact set $K$ in $\pi_k^{-1}(A)$ in the sense that $$P_n(\mathbb R^{\mathbb N}\setminus K)\leq P_n(\pi_k^{-1}(\mathbb R^k\setminus A)) = (\pi_k\#P_n)(\mathbb R^k\setminus A) < \epsilon.$$ I don't know how to make it rigorouos though. Edit 2: In an earlier version of this post, my proof idea had two fundamental flaws. First, I used the wrong characterization of compact sets in $\mathbb R^{\mathbb N}$ and second, I claimed that $\pi_k^{-1}(A)$ can be a subset of a compact set, which is not true as $pi_k^{-1}(A)$ is the pre-image of a closed set under a continuous function, and hence also closed. If $\pi_k^{-1}(A)$ was a closed subset of a compact set, it would be compact itself, but $\pi_k^{-1}(A)$ is clearly not compact. Therefore, I have to give up on the idea mentioned above. I will add a bounty to this question to draw some attention to it as I need some more clues on how to proceed.","['measure-theory', 'probability-limit-theorems', 'real-analysis', 'probability-theory', 'probability']"
4927013,What exactly is a Morita invariant property for rings?,I was reading some research papers on noncommutative rings and oftentimes I read that some property is not Morita invariant. Like this paper said that clean property is not Morita invariant. In one paper I read that Armendariz property of rings is not inherited by matrix rings and hence this property is not Morita invariant. So I want to ask that if some property is inherited by corner rings and matrix rings then can I say that it is Morita invariant. Also if the answers are not in terms of category theory it will be easy for me.,"['ring-theory', 'abstract-algebra']"
4927107,"Given $A_i, B_i \in \mathbb{R}^{k \times d}$, minimize $\sum_{i} \lVert U A_i V^T - B_i \rVert_F^2 $ over orthogonal $U, V$.","Given a collection of rectangular matrices $A_i, B_i \in \mathbb{R}^{k \times d}$ for $1 \leq i \leq n$ , I am looking for an analytical solution for orthogonal matrices $U \in \mathbb{R}^{k \times k}$ and $V \in \mathbb{R}^{d \times d}$ with $U^T U = I_k$ and $V^T V = I_d$ that minimize \begin{align}
\sum_{i = 1}^n \lVert U A_i V^T - B_i\rVert_F^2.
\end{align} In the case that $i=1$ the answer should reduce to something similar to this question after diagonalizing $A$ and $B$ via the SVD. I also understand that it may be the case that there are an infinity of solutions which is fine. That said, I'm finding it tricky to attack this problem. One idea I've had is to linearize the system with the Kronecker product to equivalently(?) minimize \begin{align}
\lVert W \, [ \textrm{vec}(A_1), \ldots, \textrm{vec}(A_n)] - [\textrm{vec}(B_1), \ldots, \textrm{vec}(B_n)] \rVert_F^2
\end{align} for orthogonal $W$ subject to the constraint that $W = V \otimes U$ , but I don't know how to impose the latter.","['procrustes-problem', 'matrices', 'orthogonal-matrices', 'least-squares', 'matrix-equations']"
4927113,Calculate $ \lim_{n \to \infty} \left( \sum_{k=1}^n \left( \sqrt{n^4 + k} \cdot \sin \left( 2\pi \cdot \frac{k}{n} \right) \right) \right) \ $,"$$
\mbox{What is the value of this limit ?:}\quad
\lim_{n \to \infty}\sum_{k = 1}^{n}\sqrt{n^{4} + k\,}\
\sin\left(2\pi\,\frac{k}{n}\right)
$$ I tried looking for sum Riemann sums first, nothing. I tried to bound the sum and then look for Riemann sums, nothing. I rewrote the sum making pairs: term $k$ with term $n - k$ to get the $\sin$ positive. I am stuck. Can someone help me with this limit ?.","['integration', 'limits', 'trigonometry', 'sequences-and-series']"
4927150,Elements that are automorphic images,"Consider an finite abelian group $G$ and two elements $x,y \in G$ . Is there a way to check whether there exists a $\phi \in \mathrm{Aut}(G)$ such that $\phi(x) = y$ ? Here are some necessary conditions for the property to hold that I was able to prove Consider a positive integer $k$ . If there exists in an $a\in G$ such that $a^k = x$ , then there exists a $b\in G$ such that $b^k =y$ . Furthermore, if there exists a $b\in G$ such that $b^k = y$ , then there exists an $a\in G$ such that $a^k=x$ . I feel like the problem is either well known & solved or well know & computationally difficult. Any thoughts/results about this?",['group-theory']
4927153,Why does the scalar inside a natural log dissapear when differentiating it? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 26 days ago . Improve this question For example if I was differentiating $\ln(2x)$ doesn't the chain rule dictate that it should be $2/x$ , not $1/x$ ? Why does the $2$ disappear?","['eulers-number-e', 'calculus', 'derivatives', 'logarithms']"
4927198,Derivation of a conditional expectation,"Setup. I have 3 random variables $Z_1,Z_2,\epsilon\in\mathbb{R}$ , where $$
(Z_1,Z_2)\sim
\mathcal{N}
\left(
\begin{bmatrix}
0 \\
0
\end{bmatrix},
\Sigma=
\begin{bmatrix}
\Sigma_{11},\Sigma_{22} \\
\Sigma_{22},\Sigma_{22}
\end{bmatrix}
\right).
$$ Let $Y=Z_1+\epsilon$ , and $\epsilon$ is independent of $(Z_1,Z_2)$ . I would like to compute $\mathbb{E}[Z_1|Z_2,Y]$ . Question. Given that $\epsilon\sim\mathcal{N}(0,\sigma^2)$ , then using the joint property of Gaussians, we have $$
\mathbb{E}[Z_1\,|\,Z_2=z_2,Y=y]
=z_2+\frac{\Sigma_{11}-\Sigma_{22}}{\Sigma_{11}-\Sigma_{22}+\sigma^2}y.
$$ Can we still computing $\mathbb{E}[Z_1|Z_2,Y]$ if we only know that $\mathbb{E}[\epsilon]=0$ and $\mathbb{E}[\epsilon^2]=\sigma^2<\infty$ (without knowledge of the distribution). My attempt. By the law of total expectation, we have \begin{align*}
\mathbb{E}[Z_1\,|\,Z_2=z_2,Y=y]
&=\mathbb{E}\Big[\mathbb{E}[Z_1\,|\,Z_2=z_2,Y=y,\epsilon]\Big] \\
&=\mathbb{E}[y-\epsilon] \\
&=y.
\end{align*} Is this correct? The final answer feels wrong to me because it does not tally with the case of a Gaussian $\epsilon$ , but I don't know where I went wrong. EDIT. I found my mistake, the law of total expectation formula used is wrong and should be this instead: $$
\mathbb{E}\Big[\mathbb{E}[Z_1\,|\,Z_2=z_2,Y=y,\epsilon]\Big|Z_2=z_2,Y=y\Big],
$$ but I am still unable to evaluate $\mathbb{E}[Z_1\,|\,Z_2=z_2,Y=y]$ explicitly.","['statistics', 'conditional-expectation', 'analysis', 'expected-value', 'probability']"
4927200,Non-symmetric bump function,"I am trying to create a smooth bump function $f(x;a,b,c,k_1,k_2)$ satisfying the following properties: $f$ is smooth (can be relaxed) $f$ is supported on $[a,c]$ . $f$ is increasing on $(a,b)$ . $f$ is decreasing on $(b,c)$ . $f(b) = 1$ . $k_1$ and $k_2$ are parameters that control the decay rates on the left and right side of $b$ (I know this is a bit vague but hopefully it makes sense). For simplicity, it can be assumed that $a=0, c=1$ and $0<b<1$ . Essentially, I want it to look like a non-symmetric version of the standard bump function $\mathbb{I}_{[0,1]}\exp(\frac{1}{x^2-1})$ , where the location of the peak can be controlled. If anyone has any ideas, it would be greatly appreciated.","['functions', 'graphing-functions', 'real-analysis']"
4927217,Geometric construction involving a line crossing a square with a given length,"ABCD is a unit square. Construct a point E on DC (extended) such that AE intersects BC at F with EF = 1. After trying for long, the only solution I could find was to solve for the length of $CE$ algebraically (it turns out to be $\frac{1}{2} (-1 + \sqrt{2} + \sqrt{2 \sqrt{2} - 1})$ ) and then construct that length, which can be done because it is possible to take square root of any arbitrary number via geometric construction. However, this approach is more algebraic than geometric, and I think that it undermines the style of geometric constructions. I am looking for a better solution to this problem. EDIT: The length of $CE$ can be found (by using triangle similarity) to be $\frac{1}{2} (-1 + \sqrt{2} + \sqrt{2 \sqrt{2} - 1})$ . This can easily be constructed, thus solving the problem. However, to find out the value of $CE$ , I had to solve a 4-degree polynomial (using Wolfram|Alpha ). This method seems (to me), to be kind of brute-forcing a geometrical construction problem. Generally, such problems can be solved by using innovative constructions and using patterns in the question. I am looking for a solution where geometric reasoning is used, instead of resorting to algebraic techniques. EDIT #2: After reading @heropup's comment below his answer, I think I can specify my question a little better. I am looking for a synthetic geometric proof , as opposed to the analytic method of solving for the length of $CE$ .","['geometric-construction', 'geometry', 'plane-geometry']"
4927247,Sum of two dice [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 11 days ago . Improve this question I have a question about the solution  of the following problem. More details at the end of the post. Problem: Imagine rolling two dice. Consider the sum of the outcome. What is the probability that the sum of the two dice equals $k$ ? Which sum has the highest probability? Solution: Let $\Omega=\{(i,j): 1 \leq i,j \leq 6\}$ .
Let $A_k$ be the outcome that the sum of both dice is equal to $k$ (where $2 \leq k \leq 12$ ). If $\omega$ is the outcome where the sum is equal to $k$ , then $\omega$ is of the form $\omega=(i,k-i)$ with $1 \leq i \leq 6$ and $1 \leq k-i \leq 6$ . $(*)$ Thus $(k-i) \lor 1 \leq i \leq 6 \land (k-i)$ . We will write $a \land b=\min(a,b)$ and $a \lor b =\max(a,b)$ . This means: for $k \leq 7, 1 \leq i \leq k-1$ we get $|A_k|=k-i$ for $7 \leq k \leq 12$ , $k-6 \leq i \leq 6$ we get $|A_k|=13-k$ . And $\mathcal{P}(A_k)$ is maximal for $k=7$ , yielding $\mathcal{P}(A_k)= 1/6$ . My Questions:
I do get everything said until the $(*)$ sign. I do not see how one would get from  If $\omega$ is a outcome (i.e. $\omega \in A_k$ ), then $\omega$ is of the form $\omega=(i,k-i)$ with $1 \leq i \leq 6$ and $1 \leq k-i \leq 6$ . To Thus $(k-i) \lor 1 \leq i \leq 6 \land (k-i)$ . I also am somewhat confused where the $\lor$ and $\land$ signs came from. So I couldn't really follow anything after $(*)$ . I would have probably just written $A_k$ explicitly. I.e. $A_2=\{(1,1)\}$ $A_3=\{(1,2),(2,1)\}$ $A_4=\{(1,3),(3,1),(2,2)\}$ .
.
.
and so on. Although my approach would be fine too (I guess), it seems very tedious to do. Especially if one increases the amount of dice. (For example if I would consider the sum of $10$ dice). My request would be if someone could please explain the solution of this example in detail. (I am also interested in other approaches, but my knowledge on probability theory isn't that big. I recently started learning about random variables.)","['dice', 'discrete-mathematics', 'probability-theory', 'probability']"
4927251,Solve simultaneous equation with 3 variable using Vieta relations,"Given that complex numbers x, y, z satisfy $x^2=y^2+z-1$ , $y^2=z^2+x-1$ , $z^2=x^2+y-1$ find the sum of all possible values of $x^2+y^2+z^2$ I was stuck on this question as I tried adding the equations up, resulting in x+y+z=3 and manipulated $(x+y+z)^2$ , however, both conclusions did not help solve the question. I asked one of my friends and he said it was related to Vieta. I could not see any way of applying Vieta to this and would appreciate any help or hint! This question came from P2SC","['contest-math', 'algebra-precalculus', 'complex-numbers']"
4927269,Finding the determinant of a matrix defined by row indices,"Given matrix A: $$
A\in\mathbb{R}^{n \times n}
$$ $$
A_{ij}=\begin{cases}
0 ~\text{if}~ i =j\\
2i ~\text{if}~ i\neq j 
\end{cases}
$$ Find the determinant of $A$ . How should I approach this? I tried rearranging the rows to get a triangular matrix but didn't do well.","['matrices', 'determinant', 'linear-algebra']"
4927271,"If $ (ab)^2=b^2 a^2 , \forall a , b\in G$ , then $G$ is necessarily abelian?","Let $G$ be a group such that $(ab)^2=b^2a^2 \forall a,b\in G  $ then $G$ is abelian? I tried to find a counterexample, but nothing came up. Hence I tried to prove it. We have $(aba^-)^2=ab^2a^-  $ and by definition $((ab)a^-)^2= a^{-2} (ab)^2=a^{-2}b^2a^2$ So $ ab^2a^-=a^{-2} b^2 a^2   $ gives $a^3 b^2=b^2 a^3 \forall a ,b \in G$ Update : $(ab)^3 =a(ba)^2b=a(a^2b^2)b=a^3b^3   $ So $(ab)^3=a^3b^3 \forall a, b \in G    $ Again $(ab)^4=(b^2 a^2)^2=a^4 b^4 \forall a ,b \in G$ Stuck from here. I think I am missing something trivial. Please guide.","['group-theory', 'abstract-algebra', 'abelian-groups', 'examples-counterexamples']"
4927304,priority of operations in function composition is backwards,"I feel like the priority of function composition is backwards, and I would like to have a deep understanding of the phenomenon. I do understand that function composition reads right to left: $$(f\circ g)(x)=f(g(x)).$$ This is ""fine"" (I guess we went too far down the road, and there is no way the notation $``xgf""$ will spread...). But something even more backwards is going on (and independent of reading from right to left). I realized that when proving for the $n^{th}$ time associativity of function composition. At some point, we have the following equality $$\left(f\circ (g\circ h) \right)(x)= f\left((g\circ h)(x)\right).$$ Again, I understand why it makes sense to do it so, and I am not questioning the ""how"" of why it works. But still, in the end, when we read $$``f\circ (g\circ h)"",$$ the parenthesis is saying that the second $``\circ""$ (the one of $``g\circ h""$ ) has priority over the first one, but when we apply it on $x$ , the priority is somehow reversed: we first ""break apart"" the first $``\circ""$ . (the ""problem"" disappears after proving associativity, since after having proved associativity, parenthesis are no longer pertinent). I would be happy with an intuitive answer and/or a more formal one, for example, in category theory vocabulary (I feel it has to do with contravariance, or maybe contravariance is only about reading from right to left...).","['binary-operations', 'functions', 'associativity', 'category-theory']"
4927322,"Does $ f(x, X) \overset{D}{=}h_1(x) + h_2(X)$ imply that $f$ is additive?","Let $X$ be a continuous random variable with full support on $\mathbb{R}$ . Let $f$ be a continuous function such that there exist $h_1, h_2$ functions satisfying $$
f(x, X) \overset{D}{=}h_1(x) + h_2(X), \,\,\,\,\,\,\,\,for\,\,all\,\,\,x\in\mathbb{R}. 
$$ Does this necessary mean that there exist $\tilde{h}_1, \tilde{h}_2$ functions satisfying $$
f(x, y) \overset{}{=}\tilde{h}_1(x) + \tilde{h}_2(y), \,\,\,\,\,\,\,\,for\,\,all\,\,\,x,y\in\mathbb{R}?
$$ Edit: Michael showed a valid counterexample. However it is the periodicity of $f$ that makes the counterexample exist. What is a non-trivial assumption of $f$ that makes the statement valid? If $f$ is Non-periodic? Surjective? Bijective?","['measure-theory', 'statistics', 'probability-distributions', 'probability-theory', 'probability']"
4927375,Probability of coin flip given forecasts,"Suppose you have a coin that flips $H$ or $T$ with some unknown probability. You also have access to two devices, $A$ and $B$ , where $A$ correctly predicts the outcome of the coin with $p = 0.7$ and $B$ with $p = 0.6$ . What is the probability $A's$ forecast is correct given $B$ agrees? How about when $B$ disagrees? I'm curious how we would go about using these tools. How can we
compute the conditional probability of the outcome given that $A$ and $B$ agree vs disagree. Intuitively, it does not seem possible for $A$ and $B$ to be independent of each other. How could we go about
computing their covariance if this is the case. If they were to be independent, I would say that the probability of
agreement $= 0.7 \cdot 0.6 + 0.3 \cdot 0.4 = 0.54$ So 54% of the time
you could have some level of confidence in your prediction. I wonder
if we can say this though and am trying to tie in concepts of
conditional probability and correlation. If we blindly followed tool $A$ we could correctly predict for $70%$ of the coin flips. Can we use $B$ in any way to increase that portion?
To me it seems like we can not as that would involve going against $A$ at some points which seems suboptimal. EDIT: After thinking about it, I believe A and B can have independent predictions. Let's assume they are if that's true. (however I'm curious of what would change if we increased correlation. I'm assuming it is not possible for correlation to be 1 as they must be different at some points to have differing proportions. What is max correlation in that case? My intuition tells me the higher the correlation, the less you'd consider the forecast with worse probability.)","['conditional-probability', 'statistics', 'covariance', 'correlation']"
4927408,Differentiability of a function and existence of directional derivatives,"I have a problem. In the book of Classical Elemental Analysis of Hoffman - Marsden assure that the function $f: \mathbb{R}^2 \to \mathbb{R}$ defined by $f(x,y) = \frac{xy}{x^2+y}$ if $x^2 \neq -y$ and $f(x,y) = 0$ if $x^2 = -y$ is not differentiable because the function $f$ is not continuous in $(0,0)$ but I think it is not true because it is continuous since f(0,0) = 0 and with polar coordinates: $x = r\cos{\theta}, y = r\sin{\theta}$ when $(x,y) \rightarrow (0,0)$ then $r \rightarrow 0^{+}$ , therefore \begin{aligned}
\lim_{(x,y) \rightarrow (0,0)}f(x,y) &= \lim_{(x,y) \rightarrow (0,0)} \frac{xy}{x^2+y}\\
 &= \lim_{r\rightarrow 0^{+}}\frac{(r\cos{\theta})(r\sin{\theta})}{r^2\cos^2{\theta}+r\sin{\theta}} \\
&= \lim_{r \rightarrow 0^{+}}\frac{r\cos{\theta}\sin{\theta}}{r\cos^2{\theta}+\sin{\theta}} \\
&= 0
\end{aligned} then we have to $\lim_{(x,y) \rightarrow (0,0)}f(x,y) = f(0,0)$ . The book uses that example to show that although all directional derivatives of $f$ exist at $(0,0)$ , the function is not differentiable at $(0,0)$ and use the continuity argument of $f$ in $(0,0)$ but I think it is incorrect. I sense that the function is not differentiable at (0,0) but not with the argument given in the book, I have tried multiple options but I have not been able to. Any suggestions?","['multivariable-calculus', 'calculus', 'vector-analysis', 'real-analysis']"
4927452,Understanding the domain of a function raised to another function,"So the question is to find the sum of all real solutions to the equation $\left(x^{2}-5x+5\right)^{x^{2}+4x-60} = 1$ . The solution intends us to take 3 cases: The first case is to set the base equal to $1$ , which yields two solutions ( $x = 1$ and $x = 4$ ) The second case is to set the exponent equal to $0$ , which also yields two solutions ( $x = -10$ and $x = 6$ ) The third case is to equate the base to $-1$ and the exponent to an even integer ( $2k$ ) which yields one solution ( $x = 2$ ) Adding these 5 values gives $3$ as the answer. However, my friends argued that the third case is incorrect as the domain of an arbitrary function $f(x)$ raised to another arbitrary function $g(x)$ can only be defined when $f(x) > 0$ . A quick graph on Desmos also appears to align with this argument. $x = 2$ being a solution."" />","['functions', 'exponential-function']"
4927469,Vector space define by limit,"Prove that the space of all $f \in \mathcal{C}(\mathbb{R},\mathbb{R})$ such that $$\lim_{n\rightarrow \infty }\frac{1}{n}\int_{-n}^{n}|f(x)|^2dx<+\infty$$ is a vector space over $\mathbb R$ . I have tried to show by Minkowski inequality that the sum of two elements of that space also belongs to that space but since the sequence is not monotone, it didn't work. I also tried to show by Cauchy condition but, again, it didn't work. So, I don't know what to do now.","['limits', 'normed-spaces', 'vector-spaces']"
4927507,Does the Lyons group have 2 111-dimensional representations or just 1?,"From what I can tell about the 111-dimensional representation of the sporadic Lyons group (modulo 5), an involution negates a 56-dimensional subspace. Thus, the double cover of the alternating group $A_{11}$ acts on this 56-space, while $A_{11}$ itself acts on the remaining 55 dimensions. According to this webpage , $2A_{11}$ has 2 56-dimensional representations modulo $5$ , which I assume are exchanged by an outer (parity) automorphism. Thus, I would expect each 56-dimensional representation of $2A_{11}$ to yield a different 111-dimensional representation of $Ly$ . However, according to Wilson's textbook The Finite Simple Groups , the 111-dimensional representation of $Ly$ is unique. So, is the 111-dimensional representation of Ly truly unique, or are there 2 representations that are almost identical? If possible, I'd like to see the Brauer characters of the 55-dimensional representation of $A_{11}$ , both 56-dimensional representations of its double cover, and the 111-dimensional representation of $Ly$ .","['sporadic-groups', 'group-theory', 'representation-theory']"
4927526,Does this function in $3$b$1$b has a name?,"I was watching this video from $3$ Blue $1$ Brown channel, at minute 21:00 he introduced the following function: $$
\chi(n)=
\begin{cases}
0 & \text{if } n=2k \\
1 & \text{if } n=4k+1\\
-1 & \text{if } n=4k+3
\end{cases}
$$ which gave a beautiful solution to the problem. I wonder if this function has a name or if it is a special case of another function. Or maybe if there are some nice properties about it. He already mentioned that it is multiplicative. I have already found out that if $n =  2^\gamma \times p_1^{\alpha_1}p_2^{\alpha_2}\ldots p_l^{\alpha_l} \times q_1^{\beta_1}q_2^{\beta_2}\ldots q_\ell^{\beta_\ell}$ where $p_i$ are the primes of form $4k+1$ and $q_i$ are those of form $4k+3$ , then $$\sum_{d|n}\chi(d)=\begin{cases}
\prod_{i=1}^{l}(1+\alpha_i) & \text{if $\beta_i$ are even} \\
0 & \text{otherwise}
\end{cases}$$ Any further ideas?","['number-theory', 'analytic-number-theory', 'mobius-inversion', 'multiplicative-function', 'prime-numbers']"
4927529,Using Sinus or Cosinus theorem gives an other result. What's wrong?,"Suppose we are in the following situation : So $AB= 10$ cm and $BC=5$ cm, and $\beta =43$ degree. So using Cosinus theorem, I get $$AC= \sqrt{AB^2+BC^2-2AB\cdot BC\cdot \cos(\beta )}=7,20\ cm$$ Now for $\gamma $ , using Sinus theorem I get $$\gamma =\arcsin\left(\frac{AB\cdot \sin(\beta )}{AC}\right)=71,26\ \text{degree}.$$ However, using Cosinus theorem, I get $$\arccos\left(\frac{AC^2+BC^2-AB^2}{2\cdot AC\cdot BC}\right)=108,74 \ \text{degree}.$$ Why do I get two different answer ? What's wrong in my solution ?",['trigonometry']
4927603,Let $ H $ be a Hilbert space and let $ A \in \mathcal{B}(H) $. Show that $ H = \ker A \oplus \overline{\operatorname{Im} A^*}. $,"Let $ H $ be a Hilbert space and let $ A \in \mathcal{B}(H) $ . Show that $ H = \ker A \oplus \overline{\operatorname{Im} A^*}. $ Attempt: Since $ \operatorname{Im} A^* \subseteq \overline{\operatorname{Im} A^*}$ , it follows that $(\overline{\operatorname{Im} A^*})^\perp \subseteq (\operatorname{Im} A^*)^\perp$ . Let $x \in \ker A$ and let $y \in \overline{\operatorname{Im} A^*}$ . Then $y = \lim_{n \to \infty} A^* y_n$ , ${A^* y_n}_{n \in \mathbb{N}} \subseteq \operatorname{Im} A^*$ . What now? (please look at the comments bellow) Let $x \in (\operatorname{Im} A^*)^\perp$ . Then $0 = \langle x, A^* y \rangle = \langle Ax, y \rangle$ for every $y \in H$ . From this, it follows that $Ax = 0$ , which means $(\operatorname{Im} A^*)^\perp \subseteq \ker A$ . We have thus shown that $(\operatorname{Im} A^*)^\perp = \ker A$ . Since $H = (\overline{\operatorname{Im} A^*})^\perp \oplus \overline{\operatorname{Im} A^*}$ , the desired result follows.","['inner-products', 'direct-sum', 'hilbert-spaces', 'functional-analysis', 'adjoint-operators']"
4927616,Complex analysis or real analysis books that have these special functions.,"I saw an integral question that involved the digamma function, which I know nothing about, and I want to learn more about it, its properties, and other functions like the polylogarithm function and the hypergeometric function. So, I searched through all of my analysis books (Differential Equations, Real Analysis, Complex Analysis) to find any book that mentions the digamma function, but none of them do. The only books I have that contain the digamma function are problem books, which assume the reader is familiar with it and present hard problems involving it, making them not useful for me. The other type is special functions books, which don’t contain any proofs, so they are also not useful. I know that I can search for the digamma function on Wikipedia, but I am more interested in finding an analysis book that contains the digamma function and its properties because such a book might have more interesting theories and functions that I know nothing about, like the polylogarithm function, the hypergeometric function, or even functions and theorems I didn't know existed. If there are no analysis books with these functions and the other types of books (problem books, special functions books) cannot be relied on, then how did many people learn about these functions anyway? I don't think the people learnt these functions from articles so they must have used some analysis book to learn them. So, I want to ask for analysis books (complex or real, but preferably complex analysis) that include the digamma function, the polylogarithm function, and the hypergeometric function, along with their properties and proofs. Additionally, I am looking for rigorous books that do not contain any real-world applications or physics.","['special-functions', 'book-recommendation', 'analysis', 'real-analysis', 'complex-analysis']"
4927663,"On the map $\operatorname{Top}(X,Y \times Z) \longrightarrow \operatorname{Top}(X,Y) \times \operatorname{Top}(X,Z)$","Disclaimer : We define a topological space $X$ to be compact if every open cover has a finite subcover, but $X$ is otherwise allowed to be arbitrary. I have been faced with the following problem: Let $X, Y, Z$ be arbitrary (nonempty) topological spaces and let $\operatorname{Top}(A, B)= \{ f: A \longrightarrow B \ \mid\ \text{f is continuous}\}$ be equipped with the compact-open topology. The universal property of the product allows us to find a bijective map: $$\varphi: \operatorname{Top}(X,Y \times Z) \longrightarrow \operatorname{Top}(X,Y) \times \operatorname{Top}(X,Z)$$ We are interested in whether $\varphi$ is a homeomorphism. I could not prove that $\varphi^{-1} =: \psi : \operatorname{Top}(X,Y) \times \operatorname{Top}(X,Z)  \longrightarrow \operatorname{Top}(X,Y \times Z)$ is continuous, or equivalently that $\varphi$ is an open map. The question is discussed here , here and here , but provided references and proofs rely on defining a compact space as a Hausdorff space whose open covers have finite subcovers. I am quite sure that in the above generality we do not have a homeomorphism. If we make additional assumptions on $X$ , e.g., $X$ locally compact or Hausdorff, $\varphi$ can be proven to be a homeomorphism. Seen here in the case of $X$ being Hausdorff. I am greatly interested in finding a counterexample where $\varphi$ isn't a homeomorphism. The same goes for a potential proof of $\varphi$ being a homeomorphism under the given definition of compactness. If you decide to reference anything stating that this is indeed a homeomorphism, please check the definition of compactness beforehand or whether it's used as a Hausdorff space in the proof.","['function-spaces', 'general-topology', 'examples-counterexamples']"
4927719,Is my explanation of why we can make $\frac{dy}{dx} {dx} = {dy}$ in the separable differential equations valid? [duplicate],"This question already has answers here : What am I doing when I separate the variables of a differential equation? (5 answers) Closed 24 days ago . The community reviewed whether to reopen this question 21 days ago and left it closed: Original close reason(s) were not resolved I'm trying to understand why we can separate $\frac{dy}{dx}$ in separable differential equations when rigorously it's not a fraction but an operator (AFAIK). I have an assumption, but I'm not sure that it's right. I'm not a mathematician, just a math-curious self-taught programmer and factory worker (all together). I eventually realized that I don't understand how the separation of $\frac{dy}{dx}$ actually works in the background and got kind of nerd-sniped (xkcd 356). I never took a course on rigorous Analysis, just lectures on Calculus a few years ago, from MIT OCW and Professor Leonard and such. Well, I came here to the community of mathematicians to ask if my first attempt is correct and what should I do with the second one in order to finish it, because I am stuck there. Fist attempt: $\frac{dy}{dx} = f(x)g(y)$ , $\frac{1}{g(y)}\frac{dy}{dx} = f(x)$ , we can write: $\frac{1}{g(y)}$ as: $\frac{d}{dy} \int\frac{1}{g(y)}dy$ . Then: $\frac{d}{dy} \int\frac{1}{g(y)}dy\frac{dy}{dx} = f(x)$ .
I see a similarity to the chain rule, so maybe I can use it. Recall ""The Chain Rule"": $\frac{du}{dx} = \frac{du}{dy} \frac{dy}{dx}$ ,
and let $u = \int\frac{1}{g(y)}dy$ , so if we substitute it into the chain rule, we get: $\frac{d}{dx} \int\frac{1}{g(y)}dy = \frac{d}{dy} \int\frac{1}{g(y)}dy \frac{dy}{dx}$ , since the first term of the right-hand side is simply a differentiation of an integration with respect to the same variable ${y}$ then according to the fundamental theorem of calculus: $\frac{d}{dx} \int\frac{1}{g(y)}dy = \frac{1}{g(y)} \frac{dy}{dx} = f(x)$ . Now if I integrate all this with respect to $x$ : $\int[\frac{d}{dx} \int\frac{1}{g(y)}dy]dx = \int[\frac{1}{g(y)} \frac{dy}{dx}]dx = \int f(x) dx$ . I finally get $\frac{dy}{dx}$ separated without ""abusing notation"": $\int\frac{1}{g(y)}dy = \int\frac{1}{g(y)} \frac{dy}{dx}dx = \int f(x) dx$ ; $\int\frac{1}{g(y)}dy = \int f(x) dx$ . Is this attempt correct? Second attempt (which I stuck with at the end): $\frac{dy}{dx} = f(x)g(y)$ ; $\frac{1}{g(y)}\frac{dy}{dx} = f(x)$ . Let: $G(u) = \int\frac{1}{g(u)}du$$ where $ {u} = y(x) $ and therefore $ {du} = \frac{d}{dx}y(x) $. Then I think that I can rewrite:
$ G(u) = \int\frac{1}{g(u)}du $ as: $ G(y(x)) = \int\frac{1}{g(y(x))} \frac{d}{dx} y(x)$. Then: $\frac{1}{g(y)}\frac{dy}{dx} = f(x)$ can be rewritten as: $\frac{d}{dy}G(y(x)) \frac{dy}{dx} = f(x)$ . Recall the Chain Rule: $\frac{du}{dx} = \frac{du}{dy} \frac{dy}{dx}$ and in this case the $u = G(y(x))$ , so we get: $\frac{d}{dx} G(y(x)) = \frac{d}{dy} G(y(x)) \frac{dy}{dx} = f(x)$ , then I integrate all this with respect to ${x}$ like this: $\int\frac{d}{dx} G(y(x)) dx = \int[\frac{d}{dy} G(y(x)) \frac{dy}{dx}]dx = \int f(x) dx$ , since $G(y(x)) = \int\frac{1}{g(y(x))} \frac{d}{dx} y(x)$ : $\int[\frac{d}{dx} \int\frac{1}{g(y(x))} \frac{d}{dx} y(x)] dx = \int[\frac{d}{dy} \int\frac{1}{g(y(x))} \frac{d}{dx} y(x) \frac{dy}{dx}]dx = \int f(x) dx$ And here I stuck and don't know what (and why) to do with all this mess.","['calculus', 'ordinary-differential-equations', 'infinitesimals']"
4927806,Proof of the existence of the haar measure for compact group,"I'm following these notes .
In the proof of the Theorem 4 (page 3) there is an inequality that i am not able to verify. Let $G$ a compact group and $V$ an open neighbourhood of the identity. $A$ is called a $V$ -blocking set if $A \cap gVh \neq \emptyset$ for
all $g,h \in G$ . For any multi-set $A=\{a_1,\dots,a_n\}$ we define the positive linear
functional $L_A:C(G)\to \mathbb{R}$ by $L_A := \frac{1}{n}\sum_{i=0}^n f(a_i)$ . Let $W \subseteq V$ neighbourhoods of the identity. We choose $A$ a $W$ -blocking set and $B$ a $V$ -blocking set (Note that
the blocking sets are finite and of minimum cardinality). Let $C=AB$ , then $$|L_Af-L_Cf|\leq \frac{1}{|B|}\sum_{b \in B}|L_Af-L_{Ab}f|.$$ The above inequality is obviously true if $|C|=|A||B|$ , but in general this is not verified. So ot it is the result of  simple algebraic manipulations or maybe we can traslate the blocking sets to have $|C|=|A||B|$ (a traslation of a blocking set is a blocking set and changing the blocking set is not a big deal)","['harmonic-analysis', 'measure-theory', 'locally-compact-groups']"
4927842,"In a triangle ABC : 2 externaly tangent circles, also tangent to BC with centers on line segments AB and AC : envelope of their lines of centers?","The figure here gives an illustration of the configuration described in the title in 4 cases ; consider especialy the fourth one, materialized by red circles, red center points, and a red line segment connecting them. Fig. 1 : Circles on the left (resp. right) have their centers $D_1$ (resp. $D_2$ ) on $AB$ (resp. $AC$ ). Tangency points $F$ are represented by black dots (blue dots for our 4 cases). I thought at first that the envelope of lines $D_1D_2$ coincides with the locus of the tangency points $F$ of the two circles, but this is not the case. A particular remark : the radical axis of the two circles (the line orthogonal to the line of centers $D_1D_2$ in $F$ ) crosses $BC$ in a point $M$ which is the midpoint of the orthogonal projections $P_1,P_2$ of $D_1,D_2$ onto line $BC$ . Moreover, I have established (analyticaly) that triangle $D_1MD_2$ is a right triangle in $M$ . My question : how can be described/obtained this envelope ? I have done a lot of analytical attempts but it looks very complicated in the general case. Maybe a more or less ""pure geometry approach"" is possible, but I don't see it... Same question for the arc of curve described by points $F$ . Remarks : This question is a follow-on of this partial answer I had given to a recent question ; the latter shares many features with my present question, but asked in terms of a family of parabolas with common directrix $BC$ and focus $F$ ; the question there was also about an  envelope, namely the envelope of circumscribed circles to $AD_1D_2$ , supposed to be a circular arc. As said above, I have done a lot of analytical calculations that can be followed in the SAGE program given below. In order to understand it, it suffices to say that : (WLOG) the coordinates of the vertices of  triangle $ABC$ have been taken like this : $$A(0,1), \ B(-1/a_1,0), \ C(-1/a_2,0).$$ As a consequence, lines $AB$ and $AC$ have these resp. equations : $$y=a_1 x +1, \ \ \ y=a_2 x +1$$ As a consequence, the coordinates of $D_1$ and $D_2$ resp. are : $$D_1(x_1,\underbrace{a_1x_1+1}_{y_1}), \ \ D_2(x_2,\underbrace{a_2x_2+1}_{y_2})$$ The tangency conditions are summarized into the following relationship : $$(P_1P_2)^2=4 P_1D_1 \times P_2D_2 \ \ \iff \ \ (x_1-x_2)^2=4(a_1x_1+1)(a_2x_2+1)$$ which isn't difficult to establish. This relationship, considered as a quadratic equation in $x_2$ when $x_1$ is considered as a parameter allows to take $x_1$ as the ""driving parameter"" : see the main ""for-loop"" in the SAGE program below where index $L$ is dirctly connected to $x_1$ . The coordinates of point $F$ are : $$F=(\frac{x_1y_2+x_2y_1}{y_1+y_2},\frac{2y_1y_2}{y_1+y_2})$$ SAGE program : a1=2;a2=-1/2 # slopes of lines AB and AC resp.
g=line(((0,1),(-1/a1,0),(0,0),(0,1),(0,0),(-1/a2,0),(0,1)),color='green',thickness=2)
nu=25 # number of points
for L in range(2,nu) :
   x1=(L/nu-1)/a1;
   # x2 is the solution of quadratic equation (x1-x2)^2-4*(a1*x1+1)*(a2*x2+1)=0
   # or of -(x1-x2)^2+2*(a1*x1+1)^2+2*(a2*x2+1)^2-2*(a2*x2-a1*x1)^2=0
   b=x1+2*a1*a2*x1+2*a2
   c=x1^2-4*a1*x1-4
   x2=b+sqrt(b^2-c)
   y1=a1*x1+1;y2=a2*x2+1;
   c='blue';al=0.1;th=0.5
   g+=line(((x1,y1),(x2,y2)),color=c,alpha=1,thickness=th)
   m=1/(y1+y2)
   g+=point((m*(x1*y2+x2*y1),m*2*y1*y2),color='black',size=30) # point F
   if L in range(15,19) :
      g+=point((m*(x1*y2+x2*y1),m*2*y1*y2),color='red',size=50) # point F
      al=1;
      if L==18 :
         c='red'
         th=1
         g+=line((((x1+x2)/2,0),(m*(x1*y2+x2*y1),m*2*y1*y2)),color='red') # line FM
         g+=line(((x1,0),(x1,y1),(x2,y2),(x2,0)),color='red') # line P1-A1-A2-P2
         g+=point((x1,0),color='red',size=30) # point P1
         g+=point((x2,0),color='red',size=30) # point P2
         g+=point(((x1+x2)/2,0),color='red',size=30) # point M
      g+=circle((x1,y1),y1,color=c,alpha=al,thickness=th)
      g+=circle((x2,y2),y2,color=c,alpha=al)
      g+=line(((x1,y1),(x2,y2)),color=c,alpha=1)
      g+=point((x1,y1),color=c,size=30)
      g+=point((x2,y2),color=c,size=30)
show(g)","['envelope', 'triangles', 'circles', 'geometry']"
4927860,A difficult example to show that limits and integrals can't always be switched,"I wanted an interesting one, so I started with $$\lim\limits_{N\to\infty}\int\limits_{-\infty}^{\infty} \operatorname{sech}\left(x-\sum\limits_{n=1}^{N}\frac{1}{x+n^{2}}\right)dx$$ The idea was that, by Glasser's master theorem, this direction should be easy to evaluate, as it should just become $$\lim\limits_{N\to\infty}\int\limits_{-\infty}^{\infty} \operatorname{sech}(x)dx=\lim\limits_{N\to\infty}\pi=\pi$$ Then, the other direction will be $$\int\limits_{-\infty}^{\infty}\lim\limits_{N\to\infty}\operatorname{sech}\left(x-\sum\limits_{n=1}^{N}\frac{1}{x+n^{2}}\right)dx=\int\limits_{-\infty}^{\infty}\operatorname{sech}\left(x-\sum\limits_{n=1}^{\infty}\frac{1}{x+n^{2}}\right)dx$$ Using the result from complex analysis that states $$\sum\limits_{k=1}^{\infty}\frac{1}{k^{2}+a^{2}}=-\frac{1}{2a^2}+\frac{\pi}{2a}\coth(\pi a)$$ the integral should transform into $$\int\limits_{-\infty}^{0}\operatorname{sech}(x+\frac{1}{2x}+\frac{\pi}{2\sqrt{-x}}\cot(\pi\sqrt{-x}))dx+\int\limits_{0}^{\infty}\operatorname{sech}(x+\frac{1}{2x}-\frac{\pi}{2\sqrt{x}}\coth(\pi\sqrt{x}))dx$$ A substitution $-x\mapsto x$ on the first makes it $$
\int\limits_{0}^{\infty} \operatorname{sech}\left(x + \frac{1}{2x} - \frac{\pi}{2\sqrt{x}} \cot{\left(\pi\sqrt{x}\right)}\right) + \operatorname{sech}\left(x + \frac{1}{2x} - \frac{\pi}{2\sqrt{x}} \coth{\left(\pi\sqrt{x}\right)}\right)dx$$ Now I need to either evaluate it exactly, or show it's not equal to $\pi$ . I initially thought Feynman's technique might help. If I consider $$I(p)=\int\limits_{0}^{\infty} \operatorname{sech}\left(x + \frac{1}{2x} - \frac{\pi}{2\sqrt{px}} \cot{\left(\pi\sqrt{px}\right)}\right) + \operatorname{sech}\left(x + \frac{1}{2x} - \frac{\pi}{2\sqrt{px}} \coth{\left(\pi\sqrt{px}\right)}\right)dx$$ then I want $I(1)$ . The idea was, the terms with $p$ should both vanish almost everywhere as $p\to\infty$ , so I would end up with $$\lim\limits_{p\to\infty} I(p)=\int\limits_{0}^{\infty}2\operatorname{sech}(x+\frac{1}{2x})dx$$ I would then apply Glasser's master theorem again to get $\lim\limits_{p\to\infty}I(p)=\pi$ , and use sign analysis on $I'(p)$ to show it wouldn't take this value for a finite $p$ . The issue is that Glasser's master theorem would only apply if I was subtracting the $\frac{1}{2x}$ , not adding it, so $\lim\limits_{p\to\infty}I(p)$ may be different from $\pi$ . So, I don't know what technique would allow this to progress further, and how we'd find the closed form, if there somehow is one.","['integration', 'limits', 'real-analysis']"
4927917,Why is it true that $\lfloor \sqrt{n}+\sqrt{n+1}\big\rfloor = \big\lfloor \sqrt{n}+\sqrt{n+2}\rfloor$,"I would like to prove that $$\big\lfloor \sqrt{n}+\sqrt{n+1}\big\rfloor = \big\lfloor \sqrt{n}+\sqrt{n+2}\big\rfloor$$ for all positive integers $n$ . Interestingly enough, this is not true for $\sqrt[3]{n}$ with a counter-example to be $n = 15$ . I wonder why that is true, and where in the proof it goes wrong for $\sqrt[3]{n}$ . I simplified it to the following but couldn't proceed. I need to prove that there is no integer $m$ such that $$\frac1m < m-2\sqrt n < \frac2m,$$ but couldn't proceed further.","['ceiling-and-floor-functions', 'number-theory', 'radicals', 'arithmetic', 'inequality']"
4927933,Is it possible to prove that the two triangles are isosceles given only these two facts?,"i was messing around with shapes and i have this question that i tried to solve but can't seem to prove with geometry taught in my school curriculum. given only that $AC=BD$ and $AB\parallel DC$ does that necessarily imply that $AE=BE$ and $DE=CE$ ? if so, what geometric facts/theorems can i use to prove it?
Can i use the basic Thales theorem to prove this?","['euclidean-geometry', 'geometry']"
4927952,Finding solutions to a complex integral equation,"I would like to determine whether there exists some (holomorphic) function $f:\mathbb{C}\to
\mathbb{C}$ such that the following integral equation $$
f\left( z \right) =\frac{C}{\left| z-z_0 \right|^{\alpha}}\int_0^{2\pi}{e^{-\mathrm{i}\alpha \theta}f\left( z+\left| z-z_0 \right|e^{\mathrm{i}\theta} \right) \mathrm{d}\theta}
$$ holds. Here $C$ is a constant, $z_0\in\mathbb{C}$ is a given complex number and $\alpha>0$ . My attempt: I tried whether $$
f\left( z \right) =\left( z-z_0 \right) ^{\beta}
$$ satisfies the equation for some $\beta$ . Then I ended up with the equivalent condition $$
\frac{C\left| z-z_0 \right|^{\beta}}{\left| z-z_0 \right|^{\alpha}}\int_0^{2\pi}{e^{-\mathrm{i}\alpha \theta}\left( e^{\mathrm{i}\theta}+\frac{z-z_0}{\left| z-z_0 \right|} \right) ^{\beta}\mathrm{d}\theta}=\left( z-z_0 \right) ^{\beta}
$$ and I'm not sure whether this is true for some $\beta$ .
I also tried to define a sequence of complex functions: choose $f_0\in H(\mathbb{C})$ arbitrarily. Then define $$
f_n\left( z \right) =\frac{C}{\left| z-z_0 \right|^{\alpha}}\int_0^{2\pi}{e^{-\mathrm{i}\alpha \theta}f_{n-1}\left( z+\left| z-z_0 \right|e^{\mathrm{i}\theta} \right) \mathrm{d}\theta},
$$ which gives a family of complex functions $\{f_n\}_{n\ge 0}$ . However I don't see the sequence converges. Can someone help me out? Any advice is welcomed. Edit: I'm adding some background content. Indeed, this problem concerns the generalization of $n$ -th derivative into arbitary fractional $p$ -th order derivative. It is known to us that the $n$ -th derivative for a holomorphic function is $$
f^{\left( n \right)}\left( z \right) =\frac{n!}{2\pi \mathrm{i}}\int_{\gamma}{\frac{f\left( \zeta \right)}{\left( \zeta -z \right) ^{n+1}}\mathrm{d}\zeta}.
$$ Therefore we may would like to define its $p$ -th derivative: $$
f^{\left( p \right)}\left( z \right) =\frac{\Gamma \left( p+1 \right)}{2\pi \mathrm{i}}\int_{\gamma}{\frac{f\left( \zeta \right)}{\left( \zeta -z \right) ^{p+1}}\mathrm{d}\zeta},\hspace{0.5em}p\in \mathbb{Q} _+.
$$ To handle the multiple value problem arose in this definition, we cut out a line from $z$ to $z_0$ in the complex plane, here $z_0$ is arbitrarily chosen. Such a derivative defined is denoted $D_{z_0}^{p}f\left( z \right)$ .
(For further details, see Anatoly A. Kilbas, Oleg Marichev, and Stefan Grigorievich Samko: Fractional Integrals and Derivatives Pp.421.)
Now we have (According to the preceding book, Theorem 22.1) $$
D_{z_0}^{\alpha}f\left( z \right) =\frac{\Gamma \left( 1+\alpha \right)}{2\pi \left| z-z_0 \right|^{\alpha}}\int_0^{2\pi}{e^{-\mathrm{i}\alpha \theta}f\left( z+\left| z-z_0 \right|e^{\mathrm{i}\theta} \right) \mathrm{d}\theta}.
$$ I'm interested in the existence ( nontrivial, of course ) of a solution to the ""fractional differential equations"": $$
\begin{cases}
	D_{z_0}^{\alpha}f\left( z \right) =Af\left( z \right) ,\\
	f\left( z_0 \right) =w,\\
\end{cases}
$$ which I ended up with my preceding problem on the existence of a function satisfying the integral equality. Edit again: I started to believe that finding a holomorphic solution to such an equation is very complicated. So I'm asking less, as mentioned in one of the current answer here , if $\alpha$ is an integer and $$
f(z)=\sum_{n=0}^\infty f_n(z-z_0)^n
$$ is a holomorphic solution to the integral equation, then we have $$
f_{n+\alpha}\cdot\binom{n+\alpha}{n}=f_n.
$$ What if we try to define a reasonable weak solution (not necessarily holomorphic, or holomorphic functions that in some sense best satisfy the integral equation ) to this integral equation?","['complex-analysis', 'integral-equations', 'ordinary-differential-equations']"
4928007,Graph of the functions for a system of two equations,"I'm a master student in Economics, and I'm going through a paper which involves some mathematics. I'm gonna try to make the argument as far as possible from economics. Consider the following system of two equations: \begin{equation}
\frac{A_M \alpha_M (I_H) M}{I_H - I_L} = \frac{A_H \alpha_H (I_H) H}{1- I_H}
\end{equation} \begin{equation}
\frac{A_L \alpha_L (I_L) L}{I_L} = \frac{A_M \alpha_M (I_L) M}{I_H - I_L}
\end{equation} Everything is exogenous (basically, the exogenous variables are calibrated to some arbitrary values. In other words, take them as constants), except for the two endogenous variables of the system, $I_L$ and $I_H$ . What you shall know now is that $0 < I_L < I_H < 1$ ; this condition always holds. It would be simple to plot the related curves in the $I_H$ and $I_L$ space if we did not have $\alpha()$ , which is a function depending on the endogenous. The paper does not exactly define $\alpha$ . However, what it says is that $\alpha_L (i) / \alpha_M (i)$ and $\alpha_M (i) / \alpha_H (i)$ are continuously differentiable and strictly decreasing, with $i \in [0,1]$ . The paper says that from the two equations above, it is possible to get the following graph: Could you please demonstrate the mathematical steps needed to produce this graph?
That's my attempt. I expressed the first and second equation in terms of $I_L$ and $I_H$ , respectively, as follows \begin{equation}
I_L = I_H - \frac{A_M}{A_H} \frac{\alpha_M(I_H)}{\alpha_H(I_H)} \frac{M}{H}(1-I_H)
\end{equation} \begin{equation}
I_H= I_L + \frac{A_M}{A_L} \frac{\alpha_L (I_L)}{\alpha_M (I_L)} \frac{M}{L} I_L
\end{equation} Then, for graphing this two functions, I assumed $\alpha_H \equiv e^{-i}$ , $\alpha_M \equiv e^{-1.3i}$ and $\alpha_L \equiv e^{-1.9i}$ , such that $\alpha_M/\alpha_H$ and $\alpha_L/\alpha_M$ are both strictly decreasing in $i$ . For the sake of the graphical representation, I set $I_H = x$ , $I_L = y$ , and the following parametrization: $A_L= 1$ , $A_M=1.25$ , $A_H=1.6$ , $L=40$ , $M=60$ , $H=50$ , such that \begin{equation}
y= x - (1.25/1.6)(e^{-0.3x}) (60/50) (1-x)
\end{equation} \begin{equation}
x= y + 1.25 (e^{-0.6y}) (60/40)y
\end{equation} and when I graph them, I get a reasonable result since the two curves crosses at $I_H=0.56$ and $I_L=0.211$ . However, as you can see below (the red curve refers to the first function), my graph intersects the x and y axes differently compared to the paper. What I am doing wrong?","['systems-of-equations', 'functions', 'graphing-functions']"
4928020,Linking number of irregular curves,"Let $f,g \colon S^1 \to \Bbb R^3$ be two continuous functions (not necessarily embeddings) whose images are disjoint. We define the linking number of these closed curves to be $$
L(f,g) = \text{deg}(H_{(f,g)},S^1 \times S^1,S^2),
$$ where the function $H_{(f,g)}\colon S^1 \times S^1 \to S^2$ is given by $$
H_{(f,g)}(u,v) = \frac{f(u) - g(v)}{|f(u) - g(v)|}.
$$ According to this post , if $f$ and $g$ are sufficiently regular, i.e. if $\text{Im}\, f = \partial M$ for some smooth embedded manifold $M$ of dimension $2$ and if $\text{Im}\, g$ intersects $M$ finitely many times, then the linking number (up to sign) is the number of times $\text{Im}\, g$ goes through $M$ in one direction minus the number of times it goes through $M$ in the opposite direction. Does the same statement continue to hold when $f$ and $g$ are both less regular? In order to generalize $\text{Im}\, f = \partial M$ of a less regular $f$ , let's assume that $f$ is a planar curve, i.e. $$
f(u) = (f^1(u), f^2(u), 0)
$$ for some continuous functions $f^1,f^2\colon S^1 \to \Bbb R$ (we allow $f$ to self-intersect). As for $g$ , we shall keep it simple and assume that it intersects the plane $z=0$ only twice. In particular, we let $$
g(v) = (g^1(v), g^2(v), g^3(v) ),
$$ where each $g^i\colon S^1 \to \Bbb R$ is continuous and $g^3$ satisfies $g^3(0) = g^3(\pi) = 0$ , $g^3$ is strictly increasing on $(-\pi/2,\pi/2]$ and strictly decreasing on $[\pi/2, 3\pi/2]$ (e.g. $g(v) = \sin(v) )$ , where we identify $S^1$ with its angular parametrization $(-\pi/2,3\pi/2]$ . Note that $g$ may intersect itself outside the plane $z=0$ . The curve $f$ now wraps around the points $g(0)$ and $g(\pi)$ since it is planar. Under these assumptions, it seems plausible that we have $$
L(f,g) = \text{deg}(f, S^1, g(0) ) - \text{deg}(f, S^1, g(\pi) ),
$$ at least up to sign. Is this formula well-known? If yes, could you please provide a reference to it? This equivalence seems to be known at least for more regular curves, e.g. the definition of the linking number I am using here corresponds to definition (6) of the linking number in Rolfsen's ""Knots and Links"" page 133, while the formula above seems related to definition (5) on the same page. However, Rolfsen only discuss polygonal curves there.","['reference-request', 'knot-theory', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
4928150,Does $E[E[X|X\le Y]]=E[X]$?,"This is a question I came up with while doing some related calculations. Let $X$ be a random variable defined on some probability space $(\Omega, \mathcal A, P)$ . To make everything as nicely behaved as possible, let $X$ be supported on $[a,b]\subset \mathbb R$ , and assume that $X$ has a density $f$ that is continuous and strictly positive on $[a, b]$ . Denote the cdf of $X$ by $F$ . Define $\phi: [a,b]\to \mathbb R$ by $$
\phi(t) =
\begin{cases}
E[X|X\le t]=\frac{1}{F(t)} \int_a^t x f(x) dx, & t \in (a,b],\\
a, & t=a.
\end{cases}
$$ Now let $Y$ be another random variable on $(\Omega, \mathcal A, P)$ , independent of $X$ . Assume that $Y$ is also supported on $[a,b]$ and that $Y$ has a density $g$ that is strictly positive and continuous on $[a,b]$ . Denote the cdf of $Y$ by $G$ . Question: Is it true that $$\tag{1}
E[\phi(Y)] = E[X]?
$$ Some remarks: Note that we can write $(1)$ in the suggestive form $E[E[X|X\le Y]] = E[X]$ . But I'm not sure whether this is a valid application of the law of iterated expectations. I've tried to verify $(1)$ directly but so far I haven't succeeded. Here is what I have so far: \begin{align}
E[\phi(Y)]
&= \int_a^b \frac{1}{F(y)} \int_a^y x f(x)\, dx\, g(y) dy\\
&= \int_a^b \frac{1}{F(y)} \left([xF(x)]_a^y-\int_a^y F(x)\, dx\,\right) g(y) dy\\
&= \int_a^b  \left(y-\int_a^y F(x)\, dx\,\right) g(y) dy,
\end{align} where the first equality follows from the definition, the second from integration by parts and the third because $F(a)=0$ . But I don't know how to continue from here (or if $(1)$ even holds). Thank you!","['integration', 'real-analysis', 'calculus', 'probability-theory', 'probability']"
4928196,Solve the ODE $y(x+y)dx+(1+xy)dy=0$,"I need to solve the following ODE: $$y(x+y)dx+(1+xy)dy=0$$ I can see that this is not an exact equation, and when I tried to multiply it by the integration factor $\mu(x)$ or $\mu(y)$ I got nothing. So I started to ""play"" with it. $$y(x+y)dx+(1+xy)dy=0$$ $$y(x+y)+(1+xy)y'=0$$ $$y'=-\frac{yx+y^2}{1+xy}=-\left( \frac{xy+1+y^2-1}{1+xy} \right)=-\left(1+\frac{y^2-1}{1+xy}\right)$$ What can I do from here?",['ordinary-differential-equations']
4928235,Tiling a square with rectangles.,"Is there a way to tile a square with $5$ rectangles with edges in $[1,10]$ . I am looking for an approach that turns this into a system of $10$ linear equations in $n_1, n_2, \dots, n_9, n_{10}$ . All edge lengths need to be unique.","['geometry', 'tiling']"
4928294,The centers of the circles passing through the vertices of 3 triangles lie on the same line,"Today while using the GeoGebra app I discovered a nice geometric feature We have a triangle (blue), and we drew the axes of its sides (black lines), and we assigned the points of intersection of those six axes with the sides of the triangle, which differ from the midpoints, and we made them the vertices of two triangles (green and red), where in one of the triangles we take points clockwise, and in the other we take points counterclockwise.  Clockwise, now if we draw the circles surrounding the three triangles, their centers will lie on one line (orange line) Is the property new or already known, if it is already known please point to a reference that mentions it, also I have no idea how we can prove this If someone has an idea about a suitable approach to proof please do so","['euclidean-geometry', 'geometry', 'reference-request']"
4928402,"Is Cov (X,XY) positive if X,Y >0","if X and Y are random variables which both only take values greater than 0 is their covariance $Cov(X,XY)>0$ . I was able to use the law of total covariance to get to: $Cov(X,XY)=E[Cov(X,XY|Y)]+Cov(E[X|Y],YE[X|Y])\\
         \quad \quad \quad \quad \quad=E[Y Var(X|Y)]+Cov(E[X|Y],YE[X|Y])$ The first term is clearly +ve but i cannot figure out how to sign the second.","['statistics', 'covariance', 'variance', 'inequality', 'probability']"
4928447,"Why are the closures of $(0,1)$ and $(0,+\infty)$ not homeomorphic despite the intervals themselves being homeomorphic?","It is well known that the interval $(0,1)$ is homeomorphic to $(0,+\infty)$ .
However, considering their closures, we have: The closure of $(0,1)$ is $[0,1]$ , which is compact. The closure of $(0,+\infty)$ is $[0,+\infty)$ , which is not compact. I am confused because homeomorphism implies that topological properties should be preserved, and compactness is a topological property. How can this discrepancy be explained?","['general-topology', 'compactness']"
4928455,Given arbitrary number of triangles intersecting pairwise over hexagonal regions prove that intersection of all these triangles has positive area,"Given arbitrary number of triangles intersecting pairwise over hexagonal regions prove that intersection of all these triangles has positive area. Hexagonal intersection means that every side of two intersecting triangles intersects two sides of another triangle, and all vertices of both triangles are not intersection points, as it is shown in picture below. We need to prove that blue area is positive for any number of triangles.","['elementary-set-theory', 'triangles', 'geometry']"
4928470,Best strategy to determine which of two coins is biased using only two flips,"We have two coins - one fair, and one biased with a probability of 0.6 for flipping a head. We get to make exactly two flips before making a guess as to which coin is biased. The question is which strategy gives us a higher probability of being able to determine the biased coin - flipping each coin once, or any one coin twice? Using simple probability rules and Bayes' Theorem, I determined the following probabilities, though I'm not sure how to proceed from here to determine the best strategy. Case I: We flip any one coin twice $$\mathrm P(Biased\ Coin\ |\ HH) \approx 0.59$$ $$\mathrm P(Biased\ Coin\ |\ TT) \approx 0.39$$ $$\mathrm P(Biased\ Coin\ |\ TH) \approx 0.49$$ $$\mathrm P(Biased\ Coin\ |\ HT) \approx 0.49$$ Case II: We flip both coins once each For the outcomes HH and TT, we get no new information about the coin and the probability of either of the two being biased given those outcomes is still 0.5. $$\mathrm P(First\ Coin\ Biased\ |\ HT) = P(Second\ Coin\ Biased\ |\ TH) = 0.6$$ $$\mathrm P(First\ Coin\ Biased\ |\ TH) = P(Second\ Coin\ Biased\ |\ HT) = 0.4$$ How do we decide which is a better strategy to guess the biased coin correctly? Is one even better than the other? And do we need the probabilities I've calculated for determining the same?","['bayes-theorem', 'probability']"
4928487,The density of the biggest integer set without given difference,"Given fixed positive integers $a_1<a_2<a_3<...<a_k$ . For every $n\in\mathbb{N}$ , define $S_n$ as the biggest set $S\subseteq\{1,2,3,\cdots,n\}$ which satisfies that for all $x,y\in S$ and $i\in\{1,2,3,\cdots,k\}$ , $x-y\ne a_i$ . I want to know $\lim\limits_{n\to\infty}\frac{|S_n|}{n}$ . I've already solved the case where $k=2$ by the following method: First assume $\gcd(a_1,a_2)=1$ . Then put $1,2,\dots,a_1+a_2$ on a circle: $a_2\mathrm{mod}(a_1+a_2)+1,2a_2\mathrm{mod}(a_1+a_2)+1,3a_2\mathrm{mod}(a_1+a_2)+1,\cdots,(a_1+a_2)a_2\mathrm{mod}+1$ . On this circle, every two adjacent numbers have a difference in the set $\{a_1,a_2\}$ . So we can't pick any adjacent numbers on the circle, which means we can only pick at most $\lfloor\frac{a_1+a_2}{2}\rfloor$ numbers in $1,2,\cdots,a_1+a_2$ , and so in $$c(a_1+a_2)+1,c(a_1+a_2)+2,\cdots,c(a_1+a_2)+a_1+a_2$$ for any $c$ , which means $\frac{S_p}{p}<\frac{p+a_1+a_2}{p}\frac{\lfloor\frac{a_1+a_2}{2}\rfloor}{a_1+a_2}$ . We can pick all the number that mod $a_1+a_2$ equals one of the $\lfloor\frac{a_1+a_2}{2}\rfloor$ numbers, so the answer is $\frac{\lfloor\frac{a_1+a_2}{2}\rfloor}{a_1+a_2}$ when $\gcd(a_1,a_2)=1$ . If $\gcd(a_1,a_2)>1$ , mod $\gcd(a_1,a_2)$ turns the problem into the case above with $a_1=\frac{a_1}{\gcd(a_1,a_2)},a_2=\frac{a_2}{\gcd(a_1,a_2)}$ . I tried some simple cases of $a_1,\cdots,a_k$ and get the following results: $1,2,6\to\frac27$ $2,3,4\to\frac13$ $2,3,5\to\frac27$ $3,4,5\to\frac38$ $1,3,4,5\to\frac14$ $2,3,4,5\to\frac27$ $3,7,8,9,10\to\frac5{18}$ What may the answer be?","['combinatorics', 'extremal-combinatorics', 'arithmetic-combinatorics']"
4928538,Is the cardinality of $\varnothing$ undefined?,"It is intuitive that the cardinality of the empty set is $0$ . However we are asked to demonstrate this using given definitions/axioms in Tao Analysis I 4th ed ex 3.6.2. My question arises as I think the given definitions are insufficient to cover the case of the empty set. The following two definitions are given to us, in addition to the usual basic set theory axioms. Def 3.6.1 (Equal cardinality) We say that two sets $X$ and $Y$ have equal cardinality iff there exists a bijection $f : X \to Y$ from $X$ to $Y$ . Def 3.6.5 Let $n$ be a natural number. A set $X$ is said to have cardinality $n$ , iff it has equal cardinality with $\{i ∈ N : 1 ≤ i ≤ n\}$ . We also say that $X$ has $n$ elements iff it has cardinality $n$ . My reasoning is as follows. The empty set has no bijection with any other set, because it has no elements for a function to map to the codomain. Therefore the first Def 3.6.1 doesn't apply. Therefore the cardinality of an empty set is not defined . I would value your guidance on where I have gone wrong.","['elementary-set-theory', 'definition', 'cardinals', 'first-order-logic']"
4928603,Are geometric series related to ellipses in this particular way?,"The bounty expires in 8 hours . Answers to this question are eligible for a +50 reputation bounty. Finn Bolton wants to draw more attention to this question: I want to raise awareness of this cute little fact. Consider a point $F$ and a line $l$ . Let the point $P$ be the foot of the perpendicular to $l$ passing through $F$ . Let $E$ be the ellipse with focus $F$ , directrix $l$ and eccentricity $r$ . Then $E$ intersects the line $FP$ at two points $A$ and $B$ . Assuming $AP > BP$ , then $AP/FP = 1/(1 - r)$ , which I noticed was awfully reminiscent of the formula for the sum of an infinite geometric series. Is that a coincidence?","['conic-sections', 'geometry']"
4928608,Geometric interpretation of implicit differentiation,"It is well known that, given a function $f:\mathbb{R} \to \mathbb{R} $ , $f'(x_0)$ can be interpreted as the slope of the tangent line to $f$ in $x_0$ . What about curves of the form $F(x, y, c)=0$ , which cannot be written in the form $y=f(x)$ , like the circumference $x^2+y^2-c^2=0$ ? I know that in this example, to find the tangent in the point $(x_0, y_0)$ , one may distinguish the two functions $y=\sqrt{c^2-x^2}$ and $y=-\sqrt{c^2-x^2}$ and then evaluate the derivative in $x_0$ (now ignoring $y_0$ , since those are functions) , but this procedure doesn't really convince me, as in general one should actually know how to ""split up"" the curve into two (or, I guess, more) functions. Thus, I have asked my Professor for a general working rule and he answered to use implicit differentiation. For example, suppose we want to find the slope of the tangent to $x^2+y^2-25=0$ in the point $(3,-4)$ . Then, differentiating both sides we get $$2x+2y \frac{dy}{dx}=0 \implies \frac{dy}{dx}=-\frac{x}{y}$$ Hence, the slope in $(3,-4)$ is simply $-\frac{3}{(-4)} = \frac{3}{4}$ . This is indeed the correct answer (in fact, the same I would get if I computed the derivative of $-\sqrt{25-x^2}$ and evaluated it in $x=3$ ). However, I am very confused about the meaning of $\frac{dy}{dx}$ here, since again this is not a function, and I do not understand the geometric interpretation of implicit differentiation either (that is, how/why this trick works). In the same way, my Professor showed that for every $(a,b) \in \mathbb{R^2}$ the curves $$x^2-y^2=a$$ and $$xy=b$$ are orthogonal, since $$x^2-y^2-a=0 \implies \frac{dy}{dx}=\frac{x}{y}$$ and since $$xy-b=0 \implies \frac{dy}{dx}=-\frac{y}{x}$$ Could you please clarify what I have asked before? Thanks in advance for your precious time and kindness.","['geometric-interpretation', 'implicit-differentiation', 'derivatives', 'real-analysis']"
4928634,Rewriting the second derivative of a function by substitution,"I would like to know if the equation $$
\frac{d^2T(x)}{dx^2} = \frac{1}{2}\cdot\frac{d}{dT}\left(\frac{d}{dx}T(x)\right)^2\quad(1)
$$ is true for a general function T(x). The function T(x) describes the temperature along a rod, so the function is smooth and its derivatives exist. Working through examples such as $$T(x) = \sin(x)\quad \text{or}\quad T(x) =\sqrt{a+x^2},$$ where it is easy to derive x(T), I can check that (1) is at least true in these cases. I tried to prove (1) by making the following substitution: $$
\frac{dT(x)}{dx} = u(x(T)).
$$ Applying the chain-rule to the right hand side of (1) we get: $$
\frac{1}{2}\cdot\frac{d}{dT}\left(u(x(T))\right)^2 = \frac{1}{2}\cdot2\cdot u(x(T))\cdot\frac{d}{dx}u(x(T))\cdot\frac{d}{dT}x(T).
$$ Canceling the 2's and substituting the original definition back in we get: $$
u(x(T))\cdot\frac{d}{dx}u(x(T))\cdot\frac{d}{dT}x(T) = \frac{dT(x)}{dx}\cdot\frac{d^2T(x)}{dx^2}\cdot\frac{dx(T)}{dT} =\frac{d^2T(x)}{dx^2},
$$ since $$
\frac{dT(x)}{dx}= \left(\frac{dx(T)}{dT}\right)^{-1}.
$$ So evidently $$
\frac{d^2T(x)}{dx^2} = \frac{1}{2}\cdot\frac{d}{dT}\left(\frac{dT(x)}{dx}\right)^2.
$$ Physicists (me) have a habit of bending mathematical definitions to suit their needs and to me, defining a function like $$
\frac{dT(x)}{dx} = u(x(T))
$$ feels wrong, because in a certain sense it is a recursive definition. So, is my proof valid? Or, is (1) in general false?","['substitution', 'derivatives', 'chain-rule']"
4928681,Find volume of body between surfaces,"Problem: Find volume of body defined as follows: $z^2=xy$ , $(\frac{x^2}{2}+\frac{y^2}{3})^4=\frac{xy}{\sqrt{6}}$ , $x, y, z \ge 0$ . My solution: So we're working in the all positive octant of the Eucledian space. $0\le z \le \sqrt{xy}$ . Then I did a swap to polar coordinates as follows: $$x=\sqrt{2}r\cos\theta, y=\sqrt{3}r\sin\theta \\ 0\le r\le \sqrt[6]{\sin\theta\cos\theta} \\ |J|=\sqrt{6}r \\ 0\le z \le r\sqrt{\sin\theta\cos\theta}$$ Now I tried the following 2 integrals: \begin{align}
1)\quad\sqrt{6}\int_0^\frac{\pi}{2}\int_0^\sqrt[6]{\sin\theta\cos\theta} r\sqrt{\sin\theta\cos\theta}\cdot r \ dr \,d\theta = \frac{\sqrt{6}}{3}\int_0^\frac{\pi}{2} \sin\theta\cos\theta \ d\theta= \frac{\sqrt6}{6}
\end{align} \begin{align}
2)\quad \sqrt{6}\int_0^\frac{\pi}{2}\int_0^\sqrt[6]{\sin\theta\cos\theta}\int_0^{r\sqrt{\sin\theta\cos\theta}} r \ dz \,dr \,d\theta &= \sqrt{6}\int_0^\frac{\pi}{2}\sqrt{\sin\theta\cos\theta}\int_0^\sqrt[6]{\sin\theta\cos\theta} r^2 \,dr \,d\theta\\ &= \frac{\sqrt{6}}{3}\int_0^\frac{\pi}{2}\sin\theta\cos\theta  \ d\theta=\frac{\sqrt{6}}{6}
\end{align} So is my solution correct?","['integration', 'volume', 'multivariable-calculus', 'calculus', 'solution-verification']"
4928684,"Problem 7.4 in Billingsley Probability and Measure, 3rd Edition","I'm working on the following problem in Billingsley's Probability and Measure , 3rd edition: Let $D_n$ be 1 or 0 according as $X_{2n-1}\ne X_{2n}$ or not, and let $M_k$ be the time of the $k$ th 1---the smallest $n$ such that $\sum^n_{i=1}D_i=k$ . Let $Z_k=X_{2M_k}$ . In other words, look at successive nonoverlapping pairs $(X_{2n-1}, X_{2n})$ , discard accordant pairs $(X_{2n-1}=X_{2n})$ , and keep the second element of discordant $(X_{2n-1}\ne X_{2n})$ pairs. Show that this process simulates a fair coin: $Z_1,Z_2,...$ are i.i.d. random variables, and $P[Z_k=1]=P[Z_k=-1]=\frac{1}{2}$ , whatever $p$ may be. Follow the proof of Theorem 7.1. The set up is $p\in[0,1]$ , and the $X_n=1$ with probability $p$ , and $X_n=-1$ with probability $1-p$ . For this problem, I'm not sure why the case $p=1$ is not a counterexample to this problem. For, if $p=1$ , then $M_k=\infty$ with probability 1, and so the $Z_k's$ will not equal either $1$ or $-1$ with probability 1. I'm not looking for a solution to this problem. I'm more so trying to understand if the statement is true and where my misunderstanding lies. Thanks!","['measure-theory', 'probability-theory']"
4928697,Commutativity of the wreath product,"Let $G$ be a subgroup of the symmetric group $\mathfrak{S}_n$ and $H$ be a subgroup of $\mathfrak{S}_m$ . Recall that the wreath product $G \wr H$ is the semi-direct product $G^m \rtimes H$ , where $H$ acts on the direct product $G^m$ by permuting components. We can also consider $H \wr G$ , the semi-direct product $H^n \rtimes G$ . My question is : when are $G \wr H$ and $H \wr G$ isomorphic? My suspicion is that it is only the case when $m = n$ and $G \cong H$ , or when $G$ and $H$ are both the trivial group. But I can't come up with a proof, nor with a counterexample. Attempt : First, if $|G|^m|H| \neq |H|^n|G|$ , it is obvious, because it is the cardinality of each group. Suppose it is equal, and that there exists an isomorphism $f : G \wr H \to H \wr G$ . I suspect that if $f$ is injective for both $G$ and $H$ (considered as subgroups of $G \wr H$ ), then $|H \wr G|$ must be much bigger than $|G \wr H|$ , which is a contradiction. But i don't know if this intuition is good, nor how to formalize it.","['symmetric-groups', 'wreath-product', 'group-theory', 'group-isomorphism']"
4928701,"If $g_1, g_2\in\mathscr{L}^{\infty}(X,\mathscr{A},\mu)$ are equal locally $\mu$-almost everywhere, then $T_{g_1}=T_{g_2}$.","Background Suppose that $(X,\mathscr{A},\mu)$ is an arbitrary measure space, that $p$ satisfies $1\leq p<+\infty$ , and that $q$ is defined by $\frac{1}{p}+\frac{1}{q}=1$ . Let $g$ belong to $\mathscr{L}^q(X,\mathscr{A},\mu)$ . Then $fg$ is integrable whenever $f$ belongs to $\mathscr{L}^p(X,\mathscr{A},\mu)$ (by Hölder's inequality), and so the formula \begin{align*}
    T_g(f) = \int fgd\mu
\end{align*} defines a linear functional $T_g$ on $\mathscr{L}^p(X,\mathscr{A},\mu)$ . Denote $T$ the map from $\mathscr{L}^q(X,\mathscr{A},\mu)$ to $\left(L^p(X,\mathscr{A},\mu)\right)^*$ that takes the function $g$ to the functional $T_g$ defined above. My Question Now, it is clear that if $g_1$ and $g_2$ are equal almost everywhere, then $T_{g_1}=T_{g_2}$ . However, the book I am reading pointed out that, in case $q=+\infty$ , we have if $g_1$ and $g_2$ are equal locally almost everywhere then $T_{g_1}=T_{g_2}$ . I want to prove this claim, but got stuck. My Attempt So Far I want to consider first the case when $fg_1$ and $fg_2$ are nonnegative. Let $A=\{x\in X:(fg_1)(x) \neq (fg_2)(x)\}$ . Let $h$ be the function defined by \begin{align*}
h(x)=
\begin{cases}
+\infty\quad &\text{if $x\in A$},\\
0\quad &\text{if $x\neq A$}.
\end{cases}
\end{align*} Define $\{h_n\}$ by $h_n=n\chi_{A}$ . Then $h(x)=\lim_{n\to\infty}h_n(x)$ for all $x\in X$ . So $\int hd\mu = \lim_{n\to\infty}\int h_nd\mu$ I got stuck here. What I wanted to do (but failed so far) is to show that $\int hd\mu=0$ . Then in view of $fg_1\leq fg_2+h$ , this would imply that $\int fg_1d\mu\leq\int fg_2d\mu + \int hd\mu = \int fg_2d\mu$ . Then analogously, $\int fg_2d\mu\leq\int fg_1d\mu$ , and we would have been done. Could someone please help me out? Thank you very much in advance! A property holds locally $\mu$ -almost everywhere if the set of points at which it fails to hold is locally $\mu$ -null. A set $N$ is called locally $\mu$ -null if for each set $A$ that belongs to $\mathscr{A}$ and satisfies $\mu(A)<+\infty$ the set $A\bigcap N$ is $\mu$ -null.","['integration', 'measure-theory', 'analysis', 'real-analysis', 'functional-analysis']"
4928752,How to show that a subset of a normed space isn't dense?,"Consider an arbitrary normed vector space $(X, \Vert \cdot \Vert_X)$ and let $Y \subset X$ . We say that $Y$ is dense in $X$ if and only if $$ \forall x \in X, \epsilon > 0, \, \exists y \in Y : \Vert y - x \Vert_X < \epsilon. $$ Now, my question is pretty simple: When we want to prove that $Y$ isn't dense in $X$ , what exactly do we
have to show ? My thoughts. I believe that I was able to provide a condition that answers my question, but I would like to know if there are any weaker conditions that lead me to the same outcome. So, my idea is as follows. To show that $Y$ isn't dense in $X$ , I believe that it is sufficient to find an element $x_0 \in X$ such that there exists a constant $c > 0$ satisfying $$ \Vert x_0 - y \Vert_X \geqslant c > 0, $$ for every $y \in Y$ . Now, when I mentioned a weaker condition, I was thinking about the following: If we find an element $x_0 \in X$ such that for every $y \in Y$ there exists a constant $c(y) > 0$ satisfying $$ \| x_0 - y \|_X \geqslant c(y) > 0, $$ does it also follow that $Y$ isn't dense in $X$ ? Thanks for any help in advance.","['normed-spaces', 'real-analysis', 'dense-subspaces', 'solution-verification', 'functional-analysis']"
4928769,"Evaluating $\int_0^{\pi } \log ^{n}\left(2 \sin \left(\frac{t}{2}\right)\right) \, dt$ where n is a natural number [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 8 days ago . Improve this question Could someone suggest a general approach e.g. a recursive approach or a summation formula for computing these integrals? I got these results from the Wolfram website.","['integration', 'definite-integrals']"
