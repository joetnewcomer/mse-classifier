question_id,title,body,tags
2188975,Number of Derangements of the word BOTTLE,"I am wondering how to calculate the number of derangements for the word BOTTLE. I understand how to actually do the formula for derangements already. My issue is what do you do with repeated letters. Obviously, I will be over counting if I do the typical formula. Makes me think it is the number of derangements with the letter T in their original space, but I am not sure. Can anyone help, as I am wondering if I am supposed to use PIE to solve this. Thanks.","['combinations', 'derangements', 'extremal-combinatorics', 'inclusion-exclusion', 'combinatorics']"
2189020,Compactness in $L^1$ implies equi-integrability,"I believe I have a proof for the following problem, though I do not rely on the finite measure space criterion. Any advice would be appreciated, especially if there is some connection with this problem to the $L^p$ version of Arzela-Ascoli and the Dunford-Pettis theorem. Let $\Omega$ be a finite measure space. Prove that if $K \subset L^1(\Omega)$ is compact, then $K$ is equi-integrable. Fix $\epsilon > 0$. Since $K$ is a compact metric space, it is totally bounded, so there exist $f_1,\dots,f_n$ such that $B(f_1,\epsilon), \dots, B(f_n,\epsilon/3)$ cover $K$. From standard measure theory, any given $f \in K$ is equi-integrable on its own (i.e., absolute continuity of the Lebesgue integral), so any finite set of functions is equi-integrable. Thus there exists $\delta > 0$ such that $h < \delta$ implies $\lVert{\tau_h f_i - f_i\rVert}_1 < \epsilon/3$ for each $i = 1,\dots,n$. We claim that this choice of $\delta$ works. Indeed, for any $f \in K$, there exists $N$ such that $\lVert{f - f_N\rVert}_1 < \epsilon/3$. Then for $h < \delta$,
$$ \lVert{\tau_h f - f\rVert} \leq \lVert{\tau_h f - \tau_h f_1\rVert} + \lVert{\tau_h f_1 - f_1\rVert} + \lVert{f_1- f\rVert} = 2\lVert{f - f_1\rVert} + \lVert{\tau_h f_1 - f_1\rVert} < \epsilon, $$
as desired. EDIT: $\tau_h(f) = f(x+h)$. I also realized my definition of equi-integrability is a bit different: for $\epsilon > 0$ there exists $\delta $ such that $\int_A |f| < \epsilon$ whenever $|A|<\delta$ for all $f \in K$. Does what I prove suffice though?","['functional-analysis', 'lp-spaces', 'measure-theory', 'uniform-integrability']"
2189034,Graph Theory proving planarity,"I have these set's of graphs: I used Euler's inequality, and the 4 color theorem which resulted in a inconclusive result. Using Kuratowski's theorem I was unable to create a K3 3 or K5 graph. So does this prove that the graphs are planar? How do we really know that there does not exist a K3 3 or K5? I did use planar embedding and was able to put it in a form where the edges do not overlap, but the method does not seem rigorous enough to prove planarity.","['graph-theory', 'planar-graphs', 'discrete-mathematics']"
2189037,Transitive subgroup of $S_4$,"Let $G$ be a transitive subgroup of $S_4$ . By the orbit-stabilizer theorem, $4\mid|G|$ . Hence the possible order of $G$ is $4,8,12,24$ . So it is possible to list all the possible structure of $G$ by considering all the subgroups of $S_4$ with those orders. However in An Introduction of Theory of Groups by Rotman, page $69$ , exercise $3.51$ , it is done by considering the index $[G:G\cap V]$ where $V$ is the Klein $4$ -group. (i) If $m=[G:G\cap V]$ , then $m\mid 6$ . (ii) If $m=6$ , then $G\cong S_4$ ; if $m=3$ , then $G=A_4$ ; if $m=1$ , then $G=V$ ; if $m=2$ , then either $G\cong \Bbb{Z}_4$ or $G\cong D_8$ . I don't have idea to solve part (i) yet. For part (ii), if $m=6$ then $G=S_4$ or $A_4$ by order consideration. But $A_4\cap V=V$ , then $m=3$ ; a contradiction. Hence $G=S_4$ . If $m=3$ , then similarly $G=S_4$ or $A_4$ . But $S_4\cap V=V$ , then $m=6$ ; a contradiction. Hence $G=A_4$ . If $m=1$ , then $G=G\cap V\leq V$ , hence $|G|\mid 4$ . Thus $|G|=4$ and $G=V$ . So I am stuck in proving for the case $m=2$ . So far I can note that $G\cap V \lhd G$ .","['finite-groups', 'abstract-algebra', 'group-theory']"
2189039,Manifold $M$ and affine scheme $\text{Spec}(C^\infty(M))$.,"Let $M$ be a $C^\infty$ manifold, $C^\infty(M)$ be its function ring and $X=\text{Spec}(C^\infty(M))$ be the corresponding affine scheme. Both $M$ and $X$ are locally ringed spaces. Are they isomorphic? If not, is it possible to reconstruct $M$ from $X$?","['manifolds', 'affine-schemes', 'schemes', 'differential-geometry']"
2189055,How many ways are there for arranging letters of the word AMAZING?,"How many ways are there for arranging letters of the word $AMAZING$ such that the '$I$' appears between the two '$A$'s ? Answer given is $5$!, but I doubt that. As a word $AMINZAG$ is also allowed here .","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2189105,Sum of Negative Binomial distributed r.v.,"what is the distribution of the sum of two negative binomial distributed r.v.`s $R_1$ and $R_2$, i.e.
$$ P(R_i=k) = \binom{\alpha_i + k-q}{k} p^{\alpha_i} (1-p)^k \text{ for } \alpha_i > 0 $$ Is it best to show it with the convolution of the two r.v`s?","['probability-theory', 'probability', 'negative-binomial', 'probability-distributions']"
2189137,Pick the right notation for calculus!,"Within calculus we have many different symbols attached with differentiating (or is that deriving?) a function, probably to the dismay of the modern calculus student. So here's the setup: As a modern researcher, you and your collaborators N, L, C, and E have just discovered a new field called ""kalkulus of one variable."" Unfortunately, discord has broken out among your co-horts and they simply cannot agree on whose notation is best for your collaborative research papers and text books. As the only person who didn't come up with an original notation, they have agreed to let you arbitrate and single-handedly pick the one-and-forever notation. Whose do you pick and why? For the following, interpret everything as a function of the appropriate variables. Also, ignore that all four of your collaborators weren't actually ever really active at the same time. The contenders (cribbing from wikipedia ) have sent you their notation and a short argument: Nutonne (Newton) $\dot y, ~\ddot y, ~\dot{\ddot y} , \dots, \overset{n}{\dot y}$ for derivatives..err...fluxions  and $\square y$ or $\boxed{y}$ for anti-derivatives...err...fluents...err..absements (yes, that symbol rendered correctly). Fundamental Theorem: $\square \dot y = y$ AFF: Newtonne seems to be the first of your collaborators to have developed the full theory, although he failed to email the rest of you. Claims absolute naming rights. Notation generally typesets well, unlike his nemesis's. CON: There is a historical anecdote of your contemporaries floundering for a century. Libknittz (Leibniz) $\frac{dy}{dx}, ~\frac{d^2 y}{dx^2}, \dots, \frac{d^n y}{d x^n}$ for derivatives and $\int y ~\mathrm{d}x$ for anti-derivatives: $\frac{d}{dx} \int y ~\mathrm{d}x = y$ . AFF: Emphasizes the kalkulus as being about a rate of change and we always see the dependent and independent variables. $\mathrm{d}$ for difference and $\int$ from the symbol ""long s"" for sum. Thinks like the chain rule are particularly easy to remember. CON: Screws up line spacing in typeset text. Also, is this a fraction? Can I multiply and find common denominators like I would for $\frac{a}{b}$ ? Better develop a theory differential forms and wedge operators... Couchie (Cauchy) $f', ~f'', \dots, f^{(n)}$ for derivatives and $f^{(-1)}$ for anti-derivatives: $\left(f^{(-1)} \right)^{(1)} = (f^{(-1)})' = f$ . AFF: nice and compact, emphasizes that we have a new function that is related to $f$ CON: $\sin^{-1} x$ vs $\sin^{(-1)} x$ vs $\left( \sin x \right)^{-1}$ Eyoulrrr (Euler) $Df, ~D^2 f, \dots, D^n f$ for derivatives and $D^{-1} f$ for antiderivatives: $D (D^{-1} f) = f$ . AFF: Emphasizes derivatives as an operator on function spaces, looks like the ""add exponents"" rule for multiplication CON: Pretty abstract ""A camel is a horse designed by committee"" Pick a notation for the current problem and sub-sub-field. Switch for the next problem. AFF: Get to pick and choose whichever notation emphasizes the most important aspect at hand (new function / slope / operator on function spaces /  ...) CON: Students will hate you. Edited to add Please note the soft-question tag! I am personally of the opinion that we end up using whichever notation is most convenient for the work at hand (outside of Newton's notation, which is almost solely relegated to time-derivatives and physics). Furthermore, all notation is abstract and strictly symbols on a page that we have agreed define meaning (cue linguistics discussion). If it helps, think of this as a response to the hypothetical Calc 1 student asking why you notate derivatives so many different ways. Alternatively, if you had to pick one of these notations to use for the rest of your mathematical career (and the careers of all subsequent mathematicians), which would it be and why?","['derivatives', 'math-history', 'notation', 'calculus', 'soft-question']"
2189141,"If $(f_n)\to0$ in $L^2$ and the derivatives converge in $L^2$, must the limit be 0?","Question Let $f_n:[0,1]\to\mathbb R$ be infinitely differentiable functions such that $$\lim_{n\to\infty}\int_0^1\!f_n^2\,dx=0,$$ and for all $\varepsilon>0$ there exists $N\in\mathbb N$ such that for all $n,m\geq N$ , $$\int_0^1\!(f'_n-f'_m)^2\,dx<\varepsilon.$$ Must it be true that $$\lim_{n\to\infty}\int_0^1\!{f'_n}^2\,dx=0?$$ Motivation The following is an exercise for a first course in functional analysis: Let $\Omega\in\mathbb R^n$ be compact. Prove that for all $f\in C(\Omega)$ there exists $u\in H^1(\Omega)$ such that $$\int_\Omega\!\nabla u\cdot\nabla\phi\,dx=\int_\Omega\!f\phi\,dx\quad\text{for all }\phi\in C^\infty(\Omega),$$ where $H^1$ is the completion of $C^\infty$ under the inner product $\langle f,g\rangle=\int_\Omega(fg+\nabla f\cdot\nabla g)\,dx$ . I can solve the question provided that $[f,g]=\int_\Omega fg\,dx$ in $C^\infty$ extends to an inner product on $H^1$ . If $(f_n),(g_n)$ are sequences in $C^\infty$ which are Cauchy (with respect to $\langle\cdot,\cdot\rangle$ ), it is not hard to show that $\lim_{n\to\infty}[f_n,g_n]$ exists and is independent of choice of representative Cauchy sequences, so $[\cdot,\cdot]$ is well-defined in $H^1$ . Most of the axioms of an inner product space for $(H^1,[\cdot,\cdot])$ can be recovered from those in $(C^\infty,[\cdot,\cdot])$ , except $[f,f]=0\implies f=0$ . This is equivalent to the following statement about Cauchy sequences: Let $f_n\in C^\infty(\Omega)$ such that $[f_n,f_n]=\int_\Omega\!f_n^2\to0$ , and $\forall\varepsilon>0\,\exists N\in\mathbb N\,\forall n,m\geq N$ $$\langle f_n-f_m,f_n-f_m\rangle\to0,\quad\text{ie. }\int_\Omega\!\nabla(f_n-f_m)\cdot\nabla(f_n-f_m)\,dx\to0.$$ Show that $\langle f_n,f_n\rangle\to0$ , ie. $\int_\Omega\nabla f_n\cdot\nabla f_n\,dx\to0$ . Taking the simplest case, $\Omega=[0,1]$ , gives the question stated above. Edit I am looking for solutions with preferably minimal use of tools from functional analysis. In particular, the concept of weak convergence is only covered later in the course, and weak derivatives are not covered at all, so I suppose we are not expected to be familiar with them for this question. Right now it appears to me that the question is about a sequence of functions in $C^\infty$ , or even $L^2$ , so there should be a direct solution using tools from real analysis or measure theory. If this is incorrect, it would be very helpful if someone can answer the following (admittedly much more vague) question instead: Question' : why does the above question ""live"" in $H^1$ , instead of $C^\infty$ or $L^2$ ?","['functional-analysis', 'real-analysis', 'lp-spaces', 'measure-theory']"
2189155,How does one show that $S_1=S_2$ and has the closed form of $1?$,"Consider these sum $$\lim_{n\to \infty}\sum_{k=1}^{n}\gamma^k\left(n-\Gamma\left({k\over n}\right)\right)^{-k}=S_1$$
  and 
  $$\lim_{n\to \infty}\sum_{k=1}^{n}(-\gamma)^{1+k}\left(n-\Gamma\left({k\over n}\right)\right)^{-k}=S_2$$
  Where $\gamma$ is Euler-Mascheroni Constant How does one show that $S_1=S_2$ and has the closed form of $\color{red}1?$","['euler-mascheroni-constant', 'sequences-and-series', 'gamma-function', 'limits']"
2189207,Gradient of $a^T X b$ with respect to $X$,"How can I find the gradient of the term $a^TXb$ where $X$ is a $n \times m$ matrix, and $a$ and $b$ are column vectors.  Since the gradient is with respect to a matrix, it should be a matrix.  But I do not have a clue on how to derive this gradient. Any help ?","['derivatives', 'matrices', 'matrix-calculus', 'scalar-fields', 'vector-analysis']"
2189234,Information theory applied to a dice (intuition about information theory),"Let's say I have a die that has the values 1 to 6 written on it, and I don't know the probability to get each value, I only know that when I throw the die many times I get an average value of 3.5, just like a fair die. According to information theory, I can guess the most unbiased probability to get a certain value by maximizing the uncertainty under the constraints, where the uncertainty is: $$H=−K\sum_{i} p_i\ln(p_i)$$
and the constraints are: $$\sum_{i}p_i=1$$
and $$\sum_{i}p_i⋅v_i=3.5$$ where $v_i$ are the values of the dice between 1 to 6. If I maximize $H$ under the constrains I get: $$p_i∝\exp(−v_iμ/K)$$ Where μ is the Lagrange multiplier corresponding to the second condition. My question is : Is this really the most unbiased probability we can find under the constraints? The possibility of equal probabilities ($p_i=1/6$) fulfills the constraints, and according to Occam's razor principle, it should be more likely than exponential probability. What am I missing?","['information-theory', 'statistics', 'entropy']"
2189289,TI -nspire calculator: how to create equations that use variables that are also equations,"I am trying to get my calculator to work out how to work out equations that rely on several other equations which I have defined as a variable. For example: \begin{align}w&=3\\
x&=2y\\
y&=w+2\\
z&=2y+4x\end{align} In the calculator I have created the variable $3→w$ which sets $w$ as 3. If I type $w$ and hit enter I get $3$. Now to enter the equation for $x$ I have to type: $$2y→x(w)$$ Now if I want to find $x$ I have to type $x(3)$. I want to be able to just type $x$ and the calculator automatically realises that $x$ is $6$. In this instance it isn't so bad, I just have to type $x(3)$, but it makes the whole process of entering the variable $w$ redundant as I have to enter it in subsequent equations anyway. When we get to the equation $z$ it gets very messy. I have to enter each variable as a function of such and such. So my question is, how do I get my calculator to save the answer to each variable so it will automatically calculate subsequent equations that use those variables, instead of typing each value for them manually?","['algebra-precalculus', 'calculator']"
2189317,Mean of gamma distribution.,"So I was trying to prove the mean result of gamma distribution which is $\frac{\alpha}{\lambda}$. My attempt, $E(X)=\int_{0}^{\infty }x f(x)dx$ $=\int_{0}^{\infty } \frac{\lambda^{\alpha}}{\Gamma (\alpha)}x^{\alpha}e^{-\lambda x}dx$ After integrating it, I got the result $$\frac{\lambda^{\alpha}}{\Gamma (\alpha)} \cdot\frac{\alpha}{\lambda}(\int_{0}^{\infty } x^{\alpha-1}e^{-\lambda x}dx)$$. I'm stuck here. Could anyone continue it for me and explain? Thanks a lot.","['probability-theory', 'calculus', 'probability-distributions', 'gamma-distribution', 'integration']"
2189342,Why isn't this a well ordering of $\{A\subseteq\mathbb N\mid A\text{ is infinite}\}$?,"So, to explain the title, I'm referring to the necessity of the axiom of choice in the existence of a well ordering on reals, or any uncountable set. Now, while tweaking some sets, I came across this : We start with the natural numbers, $N$.
We take the power set of the naturals, $P(N)$. Then we remove all the finite subsets of $N$ from $P(N)$.
Let us call this new set $S$.
This set is the set of all infinite subsets of $N$. It is easy to show that $S$ has uncountable cardinality, same as that of real numbers. This is because the removal of finite subsets only removes a countable number of elements. (Haven't posted this deduction, for it is very easy, but I may post it if it is not so evident) Now, we seek to find an ordering on the set $S$.
Every set in this set is an infinite subset of natural numbers, so each of these sets are well ordered by the natural ordering of $N$. Taking any two sets in $S$, say $A$, and $B$, we seek to order them by checking their elements lexicographically.
We compare the first two elements in $A$, and $B$. Let them be $a_1$, and $b_1$ respectively. If $a_1 = b_1$, then we move on to the second elements in the sets, $a_2$, and $b_2$, and so on. If, at any point, $a_n < b_n$, then $A < B$, or if $b_n < a_n$, then $B < A$. This order seems to be a well ordering of the uncountable infinity of reals.
I don't seem to have invoked the axiom of choice anywhere in the construction of this set $S$. So, why isn't this a well ordering on the uncountable of reals?","['well-orders', 'elementary-set-theory']"
2189347,Differential operators and principal symbols.,"For vector bundles $E$ and $F$ on a manifold $M$ I have seen here that a linear differential operator $L:\Gamma(E)\to\Gamma(F)$ of order $k$ can locally be written in the form $L=\sum_{\alpha\leq k}l_{\alpha}\partial^{\alpha}$, $l_{\alpha}:E\to F$ is a bundle homomorphism. How do I calculate $\partial^{\alpha}S$ when $S\in\Gamma(E)$? Do I simply pick a basis/frame for $E$ and apply $\partial^{\alpha}$ to the component functions? The symbol of $L$ in the direction of a one-form $\omega$ is the differential operator obtained by only summing over those $\alpha$ for which $\lvert\alpha\rvert=k$ and replacing $\partial^{\alpha}$ by $\omega^{\alpha}=\omega_1^{\alpha_1}\dots\omega_n^{\alpha_n}$, with $(\omega_i)_{i=1}^n$ being the components of $\omega$ in dual basis/frame. In other words, $\text{Principal symbol}(L)(\omega)=\sum_{\lvert\alpha\rvert=k}\omega^{\alpha}l_{\alpha}.$ In a calculation from this answer here , covariant derivatives, rather than derivatives, were replaced with the components of the one-form (in this one they use $\xi$ instead of $\omega$). How does the definition of the principle symbol coincide with the answer posted there?","['differential-geometry', 'partial-differential-equations']"
2189365,relation between union and intersection,"A and B are any two sets.
if A U B ≠ B
is it also true that A ∩ B ≠ A ?
and if so then why? This is just a step I am using for a bigger proof, if the above is not true then I'll have to search for a different direction. Thanks in advance.",['elementary-set-theory']
2189387,"Probabilities of blown-away package ownership, based on frequency and distance","Yesterday, because of high wind, a package got blown into our backyard. We weren't sure whether the package belonged to us or to one of our five neighbors. It occurred to me that if we knew the frequency with which each neighbor receives packages, we might be able to calculate the probability that the package was blown from each house's doorstep. But because all of our doorsteps are different distances away from where the package was found, we would have to factor in not only the frequency, but also the distance from each doorstep to the location where the package was found. I know how to compute the probabilities based only on frequency, but I'm not quite sure how to also factor in the distance.  Any tips? P.S. In case you're curious, although our household probably receives more packages than any of our neighbors, the package that we found in our backyard belonged to the neighbor furthest away from us!","['statistics', 'probability']"
2189439,Gardener and mole one-to-one correspondence question,"In a flat plane, I have an infinite number of holes in a straight line. A mole lies in one of the holes and will travel $d$ number of holes every morning, and he will move that number of holes in the same direction. We do not know which hole the mole is in. A gardener wants to catch this mole because it is destroying his crops. A gardener will only check once every night at a particular hole. If the mole is there, it is caught. If it is not there, the gardener goes back home. What should the gardener do so that he will catch the mole eventually? (Assuming there exist an infinite number of days) What I have tried: I label the holes $...,-n, -n+1, -n+2,..., -2, -1, 0, 1, 2, 3, ..., n-2, n-1, n...$. I assume that if the mole starts in hole $0$ and travels $2$ steps back, then he is in hole $-2$. If the mole starts in hole $0$ and travels $2$ steps forward, then he is in hole $2$. Suppose both the mole and the gardener starts on the same hole, and for simplicity, both the mole and gardener starts on hole $0$. What the farmer can do: Check hole $1$ on the first day, check hole $-2$ on the second day, $6$ on the third day, $-8$ on the fourth day, $15$ on the fifth day, $-18$ on the sixth day.. In general, he should check: Hole # = $n.\frac {-n}{2}$ if $n$ is even, and Hole # = $n.\lfloor \frac {n+1}{2} \rfloor$ if $n$ is odd, where $n$ is the $n^{th}$ day. In my earlier statement, I have proved that I can form a one-to-one correspondence. For example, $f(1)=1, f(2)=-1, f(3)=2, f(4)=-2,...$. Hence, the gardener is able to find a way to hunt down the moles. Hence, even though he does not know how many steps does the mole move a day or in which direction, the gardener am still able to track it down. Now here's the real problem. The gardener does not know which hole the mole is in, nor how many steps or in which direction the mole is heading. What can the gardener do to catch the mole eventually? Any answers are appreciated but I hope that you can explain why the answer works that way too! Thank you! It would be good to show me how a one-to-one correspondence works for this question too!","['problem-solving', 'proof-verification', 'functions', 'infinity', 'discrete-mathematics']"
2189447,Evaluation of the limit $\lim_{n\to\infty}\sum_{k=1}^n\frac k{k^2+n^2}$ [duplicate],"This question already has answers here : How do you calculate this limit $\lim_{n\to\infty}\sum_{k=1}^{n} \frac{k}{n^2+k^2}$? (3 answers) Closed 7 years ago . $$\lim_{n\to\infty}\sum_{k=1}^n\frac k{k^2+n^2}$$ I need to evaluate this limit, but I don't know how to start. Should i take $1/n^2$ out? 
Help required. Thank you.","['summation', 'infinity', 'calculus', 'limits']"
2189466,Limit without l'Hopital or Taylor series: $\lim\limits_{x \to 0} \frac{x\cos x- \sin x}{x^3}$,find the limit without l'Hôpital and Taylor rule : $$\lim\limits_{x \to 0} \frac{x\cos x- \sin x}{x^3}=?$$ My Try : $$\lim\limits_{x \to 0} \frac{x\cos x- \sin x}{x^3}\\=\lim\limits_{x \to 0}\frac{x\cos x \sin x- \sin x\sin x}{x^3\sin x}\\=\lim\limits_{x \to 0}\frac{x\sin 2x- \sin^2 x}{2x^3\sin x}\\~\\=?$$ what now ?,"['limits-without-lhopital', 'limits']"
2189501,Basic question about lattices,"I don't understand why $x \leq x \lor y$ and $y \leq x \lor y$ in the following basic lemma (taken from p.10, Models and Ultraproducts , Bell and Slomson (1969)): Lemma 1.12 : If the Lattice $L$ contains a maximal element then this maximal element is unique. PROOF . Suppose that $x$ and $y$ are both maximal elements of $L$ . Then $x \leq x \lor y$ and $y \leq x \lor y$ so that, since $x$ and $y$ are maximal, $x = x \lor y$ and $y = x \lor y$ . Thus $x = y$ and the lemma follows. From what elementary principle of lattices do $x \leq x \lor y$ and $y \leq x \lor y$ follow?","['order-theory', 'lattice-orders', 'elementary-set-theory']"
2189504,Why does orientability imply SO(n) holonomy?,"In each reference I check I am told, without proof, that orientable Riemannian manifolds have holonomy contained in SO$(n)$ by obviousness. I am sure I will feel bad about myself when I hear the answer given its alleged evidency, but this is not so clear to me (in terms of rigorous proof, the intuition is solid). I have a similar confusion for Calabi-Yau manifolds. I see CYs defined (compact) Kählers having SU$(n)$ holonomy or as Kählers having trivial canonical bundle. I see that having trivial canonical bundle implies a non-vanishing global section, but I do not see why the existence of a non-vanishing holomorphic section of the canonical bundle pushes us from U$(n)$ to SU$(n).$","['holonomy', 'riemannian-geometry', 'differential-geometry']"
2189526,Randomly place N balls in K buckets. Expected min number of buckets to select G balls?,"Looking for anything resembling a closed form solution of the following monte-carlo simulation. The basic idea is: Randomly place N balls in K buckets Sort the buckets from greatest to least number of balls Take buckets until you have taken at least G balls How many buckets did you have to take? from random import randint

n = 8000000 # balls
k = 80000   # buckets
g = 2000    # goal

# initialize buckets to 0
buckets = [0] * k  

# populate buckets
for _ in xrange(n):
  buckets[randint(0,k-1)] += 1

# pick buckets from largest to smallest until g is reached
picked = 0 
count = 0 
for b in reversed(sorted(buckets)):
  if picked >= g:
    break
  picked += b
  count += 1

print ""Picked %d balls in %d buckets"" % (picked, count) For the preset n,k,g, the average number of balls per bucket is 100, but if we pick only the largest buckets, most of those have ~140 balls, so it's possible to get the goal 2000 balls in around 14 or 15 buckets rather than the 20 one might expect based on the averages.","['balls-in-bins', 'statistics', 'probability', 'monte-carlo', 'discrete-mathematics']"
2189536,Matrix algebra linear transformation question,"Let $A = 4 \times 4$ matrix: 
$\begin{bmatrix}
 3 & 2 &  10 &  -6 \\ 
 1  & 0  &  2 & -4 \\ 
 0 &  1  & 2  & 3 \\ 
 1  &  4 &  10 &  8  
\end{bmatrix}$,
let $b = 4 \times 1$  matrix: 
$\begin{bmatrix}
 -1  \\
 3  \\
 -1  \\
 4  \\
\end{bmatrix}$ Is $b$ in the range of linear transformation $x \rightarrow Ax$? Why so or why not? I'm not really sure what the question is asking. Any help would be greatly appreciated. Sorry I don't know how to properly format the mathematical equations on this website yet, I did my best to make it legible.","['matrices', 'linear-algebra']"
2189540,General trignometry doubt,"We know $\cos(-x) = \cos x$ Now my doubt is that the condition is true only when $x\in [0,\pi]$
as in fourth quadrant cosine is positive . Or it belongs to every real number .",['trigonometry']
2189567,Finding orthonormal basis within the Aitchison simplex geometry,"Inside $\mathbb{R}^n$, consider the space
$$S_\kappa = \{ x \in \mathbb{R}^n \ | \ \sum_{i=1}^n x_i = \kappa, \ \text{and} \ \ x_i \in (0,1)  \ \text{for all} \ i \in \{1,..,n\}\}.$$ On this simplex, one can define the Aitchison geometry with pertubation (addition), powering (multiplication), and a scalar product (-> norms, distances), which turns it into a ""vector space"". You probably need to know this geometry in order to answer this question. Anyways, within that geometry, how do I go about finding an orthonormal basis, i.e, if $\oplus$ and $\odot$ denote pertubation and powering, then we want to find $e_i$ such that for any $x$ in $S_\kappa$, $x = \bigoplus_{i=1}^n \left( \lambda_i \odot e_i \right)$, where $e_i$ are the basis vectors in $S_\kappa$ which have unit norm and are orthogonal (using the Aitchison scalar product), and $\lambda$s are real constants.","['statistics', 'inner-products', 'orthonormal', 'vector-spaces']"
2189579,Is an injective proper morphism of schemes a closed immersion,"I have a proper morphism $f:X\to Y$ between proper $S$-schemes, where $S$ is a Noetherian base. I can show that for every field $k$ the induced map
$$
f_\ast:S\text{-}\mathbf{Sch}(\mathop{\mathrm{Spec}} k, X)\to S\text{-}\mathbf{Sch}(\mathop{\mathrm{Spec}} k, Y)
$$
is bijective. Does that imply that $f$ is a closed immersion? A reference or a counterexample would be appreciated.","['schemes', 'algebraic-geometry']"
2189590,Why $\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u})$ evaluates to $\mathbf{u}^T\nabla_{\mathbf{x}}f(\mathbf{x})$,"In Deep Learning (page 85) it is stated that: Using the chain rule, we can see that $\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u})$ evaluates to $\mathbf{u}^T\nabla_{\mathbf{x}}f(\mathbf{x})$ when $\alpha=0$. While I think to have understood that $\frac{\partial}{\partial\alpha}f(\mathbf{x} + \alpha\mathbf{u})$ is the directional derivative of $f(\mathbf{x})$ in the direction of $\mathbf{u}$, I still miss how to do the derivation using the chain rule. Also, does $\alpha=0$ mean that we are taking an infinitesimal step in the direction of $\mathbf{u}$?","['multivariable-calculus', 'vector-analysis']"
2189597,"""A Queer Coincidence,"" riddle from Dudeney's book","I'm stuck on a mathematical riddle from Dudeney's Amusement in Mathematics. I will write here the text of the riddle and my attempt. I just don't get how to proceed further. Seven men, whose names were Adams, Baker, Carter, Dobson, Edwards, Francis, and Gudgeon, were recently engaged in play. The name of the particular game is of no consequence. They had agreed that whenever a player won a game he should double the money of each of the other players—that is, he was to give the players just as much money as they had already in their pockets. They played seven games, and, strange to say, each won a game in turn, in the order in which their names are given. But a more curious coincidence is this—that when they had finished play each of the seven men had exactly the same amount—two shillings and eightpence—in his pocket. The puzzle is to find out how much money each man had with him before he sat down to play. Attempt I started to mind like this: first of all $2$ shillings and $8$ pence are $32$ pence ($1$s = $12$p). Hence at the end they all have $32$ p, which means in total there are $224$ p since there are seven players. Now, Assume the players are called $A B C D E F G$. $A$ is the first and he possesses $a$ pence, hence the other ones, in total, have $R$ pence. The first useful equation is trivial and its $$a + R = 224$$ Now: $A$ wins first, hence he has to pay everyone else twice what they have. But $R$ is what they all have, hence he pays $R$: after the first turn $A$ remains with $a - R$ pence. But then he always loses (other wins), and each turn until the end $A$ gets his sum doubled. In this way the turn are described by: $a - R$ $2(a-R)$ $4(a-R)$ $\cdots$ $64(a.R)$ After seven rounds, $A$ has $64(a-R)$ pence, which must be equal to $32$ since the text says it's what they all have at the end. Trivially we conclude $$
\begin{cases}
a + R = 224 \\
a - R = 1/2
\end{cases}
$$ Which means $a = 112.25$ which in farthings is $449$ f. Now my problem is to understand how to get the sum of the other players. I tried with a similar method but I failed. Any help?","['puzzle', 'recreational-mathematics', 'discrete-mathematics']"
2189634,Rudin chapter 3 Functional Analysis problem 3,"Suppose 
X is  a real 
vector 
space 
(without 
topology). 
Call 
a point 
$x_o\in
A\subset
X$ an 
internal 
point 
of 
$A$ 
if 
$A-x_o$
is 
an absorbing 
set. (a) Suppose 
$A $
and 
$B $
are disjoint 
convex 
sets 
in $ X$, 
and 
$A$
has an
internal 
point. 
Prove 
that  there  is 
a  nonconstant 
linear 
functional 
$f$ 
on 
$X $
such 
that 
$f(A)\cap
f(B)$  contains 
at 
most 
one 
point. (b) 
Show 
(with 
$X= 
\mathbf R^2$, 
for 
example) 
that 
it may 
not 
be 
possible 
to 
have $f(A)$ and $
f(B)$ 
disjoint, 
under 
the 
hypotheses 
of 
(a). i had already proved part (a) but i am not able to understand what part(b) want to ask. Thanks for the help in advance.","['functional-analysis', 'real-analysis']"
2189683,On the proof of Asymptotic Normality of GLM-Estimator: understanding some $o_p(1)$ statements,"Also the framework is kind of annoying, my questions at the end of the text should be rather standard: Framework I am trying to understand the proof for the asymptotical normality of the maximum likelihood estimator in a GLM-setting, which is given in the Book From Finite Sample to Asymptotic Methods in Statistics by de Lima, Singer and Sen in chapter 10.5 and have some problems following their arguments. For the exponential family of distributions they derived 
\begin{align*}
-\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta) & = \sum_{i=1}^N \{g'(\mu_i(\beta))\}^{-2}[v_i(\beta)]^{-1} x_ix_i'\\
&\quad + \sum_{i=1}^N(Y_i-\mu_i(\beta))\{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}x_ix_i' \\
= I_n(\beta)+r_n(\beta)
\end{align*}
where $\log L_n(\beta)$ is the log-Likelihood and $$I_n(\beta) =\sum_{i=1}^N \{g'(\mu_i(\beta)\}^{-2}[v_i(\beta)]^{-1} x_ix_i'=\mathbb{E}(-\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta) ) $$
is the Information matrix. They then note that $r_n(\beta)$ is a sum of independent centered random variables with finite variances $v_i(\mu_i(\beta))$ and nonstochastic matrix coefficients $G_i := \{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}x_ix_i'$ Among other things they assume (I already corrected some obvious mistakes): (10.5.31) $$\lim_{n\to \infty}\frac{1}{n^2}\sum_{i=1}^n v_i(\mu_i(\beta))trace(G_iG_i')=0$$ Define  $B(\delta)= \{\beta^*\in \mathbb{R}^q : ||\beta^*-\beta||<\delta\}$, $w_{1i}:= \{g'(\mu_i(\beta)\}^{-2}[v_i(\beta)]^{-1}$ and $w_{2i}:=\mu_i(\beta)\{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}$
we then assume that we have as $\delta\to 0$: (10.5.33)
$$\sup_{\beta^*\in B(\delta)}n^{-1}\sum_{i=1}^N || [w_{ki}(\beta^*)-w_{ki}(\beta)] x_ix_i'|| \to 0, \quad k=1,2$$ (10.5.34)
$$\mathbb{E}\{\sup_{\beta^*\in B(\delta)}n^{-1}\sum_{i=1}^n|Y_i|||[w_{2i}(\beta^*)-w_{2i}(\beta)] x_ix_i'||\} \to 0$$ Questions: They say that it follows from (10.5.31) and the Chebyshev inequality, that $$n^{-1}r_n(\beta) = o_p(1)$$
How can I see this?! In their proof, at (10.5.38), they claim that it follows from (10.5.33) and (10.5.34) that $$\sup_{\beta^* \in B(K/\sqrt{n})} || \frac{1}{n} \frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta)|_{\beta^*} - \frac{1}{n}\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta)|_{\beta}||=o_p(1)$$
I am not able to see this neither. Any help is greatly appreciated.","['maximum-likelihood', 'statistics', 'convergence-divergence']"
2189700,How do you calculate $ 2^{2^{2^{2^{2}}}} $?,"From information I have gathered online, this should be equivalent to $2^{16}$ but when I punch the numbers into this large number calculator, the number comes out to be over a thousand digits. Is the calculator wrong or is my method wrong?","['algebra-precalculus', 'tetration', 'arithmetic']"
2189714,Polynomial form of $\det(A+xB)$,"Let $A$ and $B$ be two $2 \times 2$ matrices with integer entries. Prove that $\det(A+xB)$ is an integer polynomial of the form $$P(x) = \det(A+xB) = \det(B)x^2+mx+\det(A).$$ I tried expanding the determinant of $\det(A+xB)$ for two arbitrary matrices, but it got computational. Is there another way?","['linear-algebra', 'determinant']"
2189860,Do Functions Have Truth Values?,"I'm reading through a few analysis books and I am a little confused by some of the definitions that are given for functions. Some texts define functions to be some subset of the cartesian product of two sets, given that the elements of this subset satisfy the properties of a function. This is intuitively clear to me, but others first define the idea of a relation and then define functions to be a sort of relation that satisfies the typical properties of a function. This is confusing to me since I have always thought of relations as having truth values and functions as having no truth value. Is it appropriate to think of relations as having truth values and functions as not having truth values? Are the varying definitions compatible or is one wrong? I appreciate any help.","['real-analysis', 'logic', 'functions', 'definition']"
2189926,Approximating a real number by a fraction from one side,"Dirichlet's approximation theorem tells us that for any real number $\alpha$, we have a sequence of rational approximations of $\alpha$ that are good for how big their denominator is. More precisely: given an integer $N \ge 1$, there exists a rational number $\frac pq$ with $1 \le q \le N$ such that $$\left|\alpha - \frac pq\right| < \frac1{qN}.$$ (This error is less than $\frac1{q^2}$, and Roth's theorem tells us that for algebraic numbers, the exponent here is best possible.) The absolute values tell us that the fraction $\frac pq$ is either going to be slightly smaller or slightly larger than $\alpha$. What if I want to specify which one it is? For example, suppose I want to find $\frac pq$ such that $$\frac pq < \alpha < \frac pq + \epsilon.$$ How small can I make $\epsilon$ (related to $q$, or possibly some extra parameter $N$ as above)? I'm a bit worried when it comes to numbers such as Liouville's constant $L = \sum_{k=1}^\infty 10^{-k!}$, which has extremely good approximations (by truncating the series), but all from below; similarly, $1-L$ will have extremely good approximations, but all from above.","['number-theory', 'inequality', 'diophantine-approximation']"
2189937,Determine where $f'(z)$ exists and find its value at those points.,"I am revising complex analysis for an upcoming test and I am finding it hard to finish off certain questions. I feel I start well but cannot remember how to wrap up the answers in proper form. $--------------------------------------$
Letting $z = x + iy$, for each of the following functions determine where $f'(z)$ exists and find its value at those points. (a) $f(z) = z$ Im$(z)$ (b) $f(z) = x^3 + i(1-y)^3$ $--------------------------------------$ For part (a) I am pretty certain $f'(z)$ does not exist: Let $f(z) = $Im$(z)$, then for $z, h \in \Bbb C,$ with $h \ne 0,$ we have $\frac{Im(z+h) - Im(z)}{h}$ = $\frac{Im(z)+Im(h)-Im(z)}{h}$ = $\frac{Im(h)}{h}$. Now, if $h \rightarrow 0  $ through real values, Im$(h)=0$, and $\lim \limits_{h \to 0} {\frac{Im(z+h)-Im(z)}{h}}$ = $\lim \limits_{h \to 0}{\frac{Im(h)}{h}}$. At this point I think I need to mention imaginary values and conclude that $f'(z)$ doesn't exist by using the real and imaginary values, but my notes are giving me limited assistance in how to do this correctly. $--------------------------------------$ For part (b) I had done a very similar question before, but again, I struggle to conclude my answers in a mathematical way. If $f(z) = x^3 + i(1-y)^3$ , then $u(x,y)=x^3$ and $v(x,y)=(1-y)^3$ , so that $\frac{\partial u}{\partial x}$=$3x^2$,     $\frac{\partial v}{\partial y} =-3(1-y)^2$ $\frac{\partial u}{\partial y}=0$,     $\frac{\partial v}{\partial x}=0$. The Cauchy-Riemann equations become
$3x^2 +3(1-y)^2=0$ How do I then find the points at which $f'(z)$ exists? Any help is much appreciated!!",['complex-analysis']
2189941,Is there an elementary proof that $y^2=8x^4+1$ has no integral solution for $x\ge2$?,"How can I prove that $y^2=8x^4+1$ has no integral solution with $x\ge 2$ with elementary methods ? With elementary I mean using only modular arithmetic, the unique factorization theorem and the theory of quadratic residues modulo a prime $p$. I tried various approaches , but I did not manage to prove the claim : First of all, if $x\ge 2$, there is a prime factor $p$ dividing $x$. $y^2-1=(y-1)(y+1)=8x^4$ So, if $y-1$ or $y+1$ is divisible by an odd prime, we have $p^4|y-1$ respective $p^4|y+1$. Does this lead to anywhere ? $y^2-9=8x^4-8$ , which implies $(y-3)(y+3)=8(x-1)(x+1)(x^2+1)$. Can I make use of the fact that every odd prime $p$ dividing $x^2+1$ has the form $4k+1$ ? Since the equation is closely related to the triangular numbers (The question whether a triangular number can be a fourth power leads to the given equation), I also studied the convergents of $\sqrt{2}$ (which satisfy the pell-equation $x^2-2y^2=1$). The sequence $B_n$ of the positive integers, whose squares are triangular satisfy the recurrence relation $B_1=1$ , $B_2=6$ , $B_n=6B_{n-1}-B_{n-2}$. So, showing that no $B_n$ except $1$ is a perfect square would also finish the proof. Any ideas ?","['number-theory', 'diophantine-equations', 'modular-arithmetic']"
2189990,Epsilon-delta proof that $ \lim_{x\to 0} {1\over x^2}$ does not exist,"I'd like to see an epsilon delta proof that the $\lim: \lim_{x\to 0} {1\over x^2}$ does not exist and an explanation of the exact reason it does not exist, because I am not so sure I believe that the limit does not, in fact, exist, so I need to be proved wrong. What is the relationship between a limit existing, and the function in question having a least upper bound?  Because it seems to me that the only explanation I can find as to why the limit does not exist is that the function is unbounded. I'm not sure why this is relevant because it seems to me that when $x$ approaches $0$ then ${1\over x^2}$ gets infinitely close to the y-axis which suggests to me that there does exist, in fact, an epsilon infinitely close to zero such that if $|x - a| < \delta$ then $|f(x)-L| < \epsilon$ where $\delta$ is infinitely close to zero and $\epsilon$ is infinitely close to zero. Obviously, my understanding of calculus hinges on this question, so I really need to be convinced with a bulletproof explanation, otherwise I'll continue to doubt the truth (I don't believe anything unless I fully understand it myself, for better or worse, I ignore other's authority and rely only on proof and logical understanding -- I'm sorry if this attitude offends anyone)!  Thanks in advance!","['infinity', 'calculus', 'analysis']"
2189993,Unique solution to system of nonlinear equations (non-singular Jacobian),"Suppose I have a system of $n$ nonlinear, $C^\infty$, real implicit functions with $n$ real variables: $\{f_i(x_1,...x_n)\}_{i=1}^n$. To provide more structure, we have
$f_1(x_1,...x_n)= x_1 + g(x_2,...,x_n)$, ... $f_n(x_1,...x_n)= x_n + g(x_1,...,x_{n-1})$, etc. In other words, in each $f_i$, the variable $x_i$ is additively separable. None of the equations are redundant. When can I assert that there exists at most one solution $(x_1^*,...x_n^*)$ to the system? Following the theory of system of linear equations, is it sufficient that the Jacobian matrix of the system is non-singular everywhere? The idea is from implicit function theorem. If there are $m+n$ nonlinear equations with $n$ endogenous variables and $m$ exogenous variables, and the Jacobian matrix is nonsingular at a point, then we can express the $n$ endogenous variables as functions of the $m$ exogenous variables near that point. If nonsingular everywhere, then we can do the same everywhere. The question now is what if $m=0$.","['nonlinear-system', 'implicit-function-theorem', 'linear-algebra', 'algebraic-geometry']"
2190059,Queuing with impatience,"I am considering simple M/M/1 queue with customer impatience. Customer waits and leaves the system if the delay before service is more than an exponential 
wait time. Arrival rate is $\lambda$, service rate is $\mu$, and abandonment rate due to delay is $\lambda_W$. 
I assume state probabilities $p_n$ are known. My problem is to find expected wait time given that customer receives service. My approach to the problem is very simple: if customer finds one customer in the system average queueing delay is  $E[S_1 | S_1 < W]$ = $\frac{1}{\mu + \lambda_w}$, where $S_1$ is the random variable of service time (~exp($\mu$)), and $W$ is the exponential delay. Similarly, if customer finds 2 customer in the system average queueing delay is the conditional expectation $E[S_1 + S_2 |S_1 + S_2 < W ] = \frac{1}{\mu + \lambda_w} + \frac{1}{\mu + 2\lambda_w}$ If customer finds $n$ customer  in queue and successfully receives service, total queuing delay until service time begins is the sum of $n$ independent exponentials with rates $\mu +\lambda_w$, $\mu+2\lambda_w$, $\mu +3\lambda_w$...$\mu+n\lambda_w$. Thus, the expectation of queueing delay is $\frac{1}{\mu +\lambda_w}+...+\frac{1}{\mu + n \lambda_w}$ Thus, average delay $\overline{W}_q$  conditioning on states is $\overline{W}_q = \sum_{i=1}^{\infty} E[S_n| S_n <W] p_n $. The result I obtained from this approach does not agree with simulation results. I don`t know where I am doing wrong?","['expectation', 'probability-distributions', 'probability', 'queueing-theory', 'conditional-expectation']"
2190061,"$\int_{-\infty}^{\infty }\frac{x^{2} \, dx}{x^{4}+a^{4}}$","I'm considering the following integral: $$\int_{-\infty}^{\infty }\frac{x^{2} \, dx}{x^{4}+a^{4}}$$
I do not know how to factor the denominator to calculate the residues. I'm stuck here: $$(x^{2}-|a|^{2}i)(x^{2}+|a|^{2}i)$$ Thank you so much.","['complex-numbers', 'residue-calculus', 'calculus', 'improper-integrals', 'integration']"
2190068,Probability that a bin already contains a ball of a given colour,"I am new to probability and my professor asked me the following question but i am unsure if my strategy is correct. Given $n$ balls of each of $n$ different colours ($n^2$ balls in total), we distribute them among $n$ boxes as follows: for each ball, we choose a box at random. If the chosen box already contains a ball of the same colour as the ball we are considering, we throw the current ball away. Otherwise, we put the ball in the box. Show that the probability that a box contains a ball of a given color is
$$1-\left(1-\frac{1}{n}\right)^n$$ The best I can think of is to let 
$$
\begin{align}&\mathrm{A=\{the\ bin\ contains\ a\ ball\ of\ a\ given\ color\}}\\
& \mathrm{A_i\sim Bernoulli}\left(\frac{1}{n}\right)\\
&\mathrm{P(A_i)= \begin{cases}\frac{1}{n}, & \text{if the bin contains a ball of color i}\\1-\frac{1}{n},&\text{else}\end{cases}}\\
&\mathrm{P(A)=1-P(\bar{A})=1-P\left(\bigcap_{i=1}^n A_i=0\right)=1-\prod_{i=1}^n P(A_i=0)}\\
&\mathrm{P(A)=1-(P(A_i=0))^n=1-\left(1-\frac{1}{n}\right)^n}
\end{align}$$ While this does produce the right answer, I am unsure if my reasoning is correct","['probability', 'discrete-mathematics']"
2190093,Deuring lifting theorem,"The following result can be found in Lang's Elliptic functions book (Chapter 13, Theorem 14): Let $A_0$ be an elliptic curve in characteristic $p$, with an endomorphism $\alpha_0$ which is not trivial. Then there exists an elliptic curve $A$ defined over a number field, an endomorphism $\alpha$ of $A$, and a non-degenerate reduction of A at a place $\mathfrak{p}$ lying above $p$, such that $A_0$ is isomorphic to $\overline{A}$, and $\alpha_0$ corresponds to $\overline{\alpha}$ under the isomorphism. In the proof, I don't understand how we get from a curve $A$ with transcendental invariant $j$ over $\mathbb{Q}$ to a curve over a number field. Is that because the curve $A(j_1)$ is defined over a number field? (I don't think it is true.) On the other hand, I wonder if there is a simpler proof for this theorem. I think one can obtain an ""easier"" proof by simply consider the order $L$ in $\text{End}(A_0)$ containing $\alpha_0$ and take the curve $\mathbb{C}/L$. The problem is of course to prove that it is indeed defined over a number field i.e. $g_2(L)$ and $g_3(L)$ are algebraic integers. That seems to be hard. Another question is about the statement of the theorem: It does not mention that $A_0$ being defined over finite field but the proof does assume that. Certainly, I do not think we can lift curves over transcendental extension of $\mathbb{F}_p$ such as $\mathbb{F}(t)$ to number fields. Is there an analogue for general field of characteristic $p$?","['number-theory', 'elliptic-curves', 'algebraic-geometry']"
2190103,Showing that $|Im[e^{-i \phi z}]| = d$?,"The question is taken from Visual Complex Analysis by Needham: My problem is that my work seems to show that $d$ is the real part, not the imaginary part. I know our new point is supposed to have angle $\theta - \phi$ and not $\phi - \theta$, but it's okay since the absolute value of the imaginary part should stay the same. How can I justify switching around the new axes so that I get the correct answer? The reason I think I must label the axes this way is because $\phi - \theta$ is supposed to be in quadrant $1$.","['complex-analysis', 'euclidean-geometry', 'geometry']"
2190135,"Can we use analytic continuation to obtain $\sum_{n=1}^\infty n = b, b\neq -\frac{1}{12}$","Intuitive question It is a popular math fact that the sum definition of the Riemann zeta function:
$$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s} $$
can be extended to the whole complex plane (except one) to obtain $\zeta(-1)=-\frac{1}{12}$. The right hand side for the above equation in $-1$ becomes the sum of the natural numbers so in some sense we have obtained a value for it. My question is: is this value depending on the choice of the Riemann zeta function as the function to be analytically continued, or do we always get $-\frac{1}{12}$? Proper formulation let $(f_n:D\subset \mathbb{C}\rightarrow \mathbb{C})_{n\in \mathbb{N}}$ be a sequence of functions and $a \in \mathbb{C}$ with $\forall n\in \mathbb{N}: f_n(a) = n$ and
$$f(z):=\sum_{n=0}^\infty f_n(z)$$
convergent on a part of the complex plane, such that it can be analytically continued to a part of the plane that contains $a$. Does it then follow that, under this continuation, $f(a)=-\frac{1}{12}$ and why (or can you give a counterexample)? Examples The case of the Riemann zeta function is the case where $\forall n
   \in \mathbb{N}: f_n(s) = \frac{1}{n^s}$ and $a=-1$ The case where $\forall n \in \mathbb{N}: f_n(z) = \frac{n}{z^n}$ and $a=1$ does yield the sum of all natural numbers but it's continuation $\frac{z}{(z-1)^2}$ has a pole at $a$.","['complex-analysis', 'analytic-continuation', 'riemann-zeta']"
2190216,"Proof, without logs/exp that (1+x/n)^n converges","was wondering if any of you would be able to help with this question: Prove that $$\left(1 +\frac{x}{n}\right)^{n}$$ converges as n approaches infinity for $x\in\mathbb{R}$ and $n=1,2,3...$ Now, since this question was given before we learnt the proper definition of exponential functions and logarithms, I assume it requires a proof without these functions. I was able to prove the convergence for $x\geq0$ using the binomial expansion and the fact that $$\binom{n+1}{k}\frac{x^{k}}{(n+1)^{k}}>\binom{n}{k}\frac{x^{k}}{n^{k}}$$ for $x\geq0$ (i.e I proved the sequence to be increasing and was bounded above, and hence convergent).
However, that inequality is the other way round for $x<0$ and the inequalities I used to prove the sequence to be bounded above also relied on the fact that $x\geq0$. How would I go about proving that the sequence is increasing and bounded above (without logs/exponentials) for $x<0$? Would I have to come up with some new inequalities? Thanks","['sequences-and-series', 'convergence-divergence', 'limits']"
2190234,If the derivative of $f:R^m\to R^m$ is isometric then $f$ is isometric,"I can't finish this problem Let $f:R^m\to R^m$ be a $C^1$ function such that for all $x\in R^m$, $f'(x):R^m\to R^m$ is an isometry i.e. $|f'(x)v|=|v|$ for all $v\in R^m$. Prove that $f$ is an isometry, i.e. that $|f(x)-f(y)|=|x-y|$ for all $x,y\in R^m$. Conclude that there is a linear isometry $T:R^m\to R^m$ and $a\in R^m$ such that $f(x)=Tx+a$ for all $x\in R^m$. This is what I've done:
Since $|f'(x)v|=|v|$ for all $x,v$ we have that $|f'(x)|=1$. The mean value inequality then says that $|f(x)-f(y)|\le 1\cdot |x-y|=|x-y|$. Ideally one would like to apply the previous inequality with $f^{-1}$ in place of $f$ but we don't know that $f$ is bijective. I tried to use the inverse function theorem but it only assures the inverse of $f$ when $f$ is restricted to some open sets. So how would one prove that $f$ is bijective?. After that I think i can finish the problem.","['derivatives', 'analysis']"
2190247,Is there a proof of $|Aut(E/F)| \leq [E:F]$ using linear algebra?,"In the text by Dummit and Foote, there is the following proposition: Proposition Let $E$ be the splitting field over $F$ of the polynomial $f(x) \in F[x]$. Then we have 
  \begin{equation*}
|Aut(E/F)| \leq [E:F]
\end{equation*}
  with equality iff $f(x)$ is separable over $F$. The proof of this proposition involves looking at the number of possible ways of extending an isomorphism $\phi: F \to F' $ to an isomorphism $\sigma: E \to E'$ between the splitting field $E$ of $F$ and the splitting field $E'$ of $F'$. I am wondering if there is a proof of this proposition that uses linear algebra. This seems at least plausible to me, since the linear algebra analog of an automorphism of $K$ is just an invertible linear transformation. This suggests writing something like: \begin{equation*}
\Big(\text{number of invertible maps from V to V fixing F}\Big) \leq dim_F(V).
\end{equation*} But there are (at least) two problems with the above statement: The base field (scalar field) $F$ is not necessarily contained in $V$, and it is not clear (to me at least) how to embed $F$ into $V$. There is no linear algebra analog of a transformation ""fixing"" a space.
(Note: I guess one could just say that $T$ fixes a subset $A$ of $T$ if $T$ is the identity on $A$, so maybe this is not really an issue...?) If there is not a way to prove the above proposition using only linear algebra, is there a proof that at least uses a decent amount of linear algebra?","['abstract-algebra', 'galois-theory', 'linear-algebra']"
2190255,Why is $L=\mathbb{Q}(\sqrt[1]{2})\cup\mathbb{Q}(\sqrt[2]{2})\cup\mathbb{Q}(\sqrt[3]{2})\cup\cdots$ a field?,"The title sais it already: Why is $L=\mathbb{Q}(\sqrt[1]{2})\cup\mathbb{Q}(\sqrt[2]{2})\cup\mathbb{Q}(\sqrt[3]{2})\cup\cdots$ a field? The hint provided in my textbook is: $\mathbb{Q}(\sqrt[n]{2})\cup\mathbb{Q}(\sqrt[m]{2})\subset\mathbb{Q}(\sqrt[mn]{2})$, but this doesn't really get me anywhere. Actually, I have no idea what to do whatsoever. Could anyone clarify or give some hint please?","['abstract-algebra', 'field-theory']"
2190258,Fractional part of normally distributed variable,"Let $X$ be a normally distributed variable with mean $0$ and standard deviation $1$. I will consider its fractional part $$\overline{X} = X - \lfloor X \rfloor = X \, \bmod \, 1.$$ I have done some numerical testing and it seems likely that $\overline{X}$ is uniformly distributed on $[0,1].$ To be specific I computed $$\sum_{k=-200}^{200} \Big( \Phi(k+b) - \Phi(k+a) \Big)$$ for a few values of $b \ge a$ in $[0,1]$ and the result is consistently very close to $b-a$. Here is the code in Sage: I first define def Phi(x):
    return (1/2 + erf(x / sqrt(2)) / 2).n() then a few examples of these computations: s = 0
for k in range(-200,200):
    s = s + Phi(k+3/5) - Phi(k + 2/5)
print s.n()
0.199999998998919 and s=0
for k in range(-200,200):
    s = s + Phi(k+4/9) - Phi(k + 2/9)
print s.n()
0.222222221674844 Question: is $\overline{X}$ in fact uniformly distributed? From the examples I've done I am confident that it is but I am not sure how to prove it.","['error-function', 'probability', 'calculus']"
2190313,Solving a differential equation with wronskians,"So I am asked to find a solution to this ODE here and I feel like I am missing something very obvious. I am asked to find the general solution of: $x^2y""-3xy'+4y=\frac{x^2}{ln(x)}, y>1$ So I first tried to find the homogeneous solution which was just a cauchy Euler equation: $x^2y""-3xy'+4y=0$ if I solve that, I get $y_{h}(x)=c_1 x^2 + c_2 x^2 ln(x)$ Then I tried to use variation of parameters to solve the particular solution. I obtain: $W=\begin{bmatrix}
  x^2 & x^2\ln(x) \\
 2x & x+2x\ln(x) \\
\end{bmatrix}$ The wronskian ends up becoming $W=x^3$ so things worked out really nicely. If I try to find the particular solution though, I can't integrate one of the integrals. $Y_p(t)=-y_1\int \frac{y_2g(x)}{W}+y_2\int \frac{y_1g(x)}{W} dx$ $Y_p(t)=-x^2\int x dx +x^2\ln(x)\int \frac{x}{ln(x)} dx$ but the second integral can't be done so either I made a mistake or there is another way to solve this. I can't even use Laplace transforms since I don't have initial conditions so I am a little lost here... Thanks!","['ordinary-differential-equations', 'laplace-transform']"
2190330,L'hopitals rule with limits,"Given the following limit, $$\begin{align}
\lim_{x\to 0}\frac{e^{-1/x^2}-0}{x-0}\\\\
&
\end{align}$$ How do I calculate it? when pluggin in 0 I would get $\frac{0}{0}$","['calculus', 'limits']"
2190339,Curvature and Torsion in terms of Geodesic Curvature,"Let $γ : I → S^2$ be a regular curve in the 2-sphere. Let $\kappa_g$ denote the geodesic curvature . Regarding the curve $γ$ as a space curve $S^2 ⊂ \mathbb R^3$ and assuming it to be Frenet, calculate its curvature $κ$ and torsion $τ$ in terms of $\kappa_g$. So we have $$\kappa_g = \langle T', \gamma \times T\rangle = \langle\gamma'', \gamma \times \gamma'\rangle$$
where the brackets denote the inner product, where $$T = \frac {d\gamma}{dt}, $$ and where the Frenet frame is the 3-dimensional orthonormal basis $(\gamma', \gamma \times \gamma', \gamma)$. The curvature of a space curve is given by $$\kappa = \frac{\lVert \gamma \times \gamma'\rVert}{\lVert\gamma'\rVert^3}$$ The Torsion is given by $$\tau = \frac{\langle\gamma' \times \gamma'',\gamma'''\rangle}{\lVert\gamma' \times \gamma''\rVert^3}$$ So basically the objective is to write $\kappa$ and $\tau$ in terms of $\kappa_g$? I'm not really sure how it's possible to get something like $\lVert\gamma'\rVert^3$ out of the definition of $\kappa_g$. On the other hand it sort of looks like we could obtain the numerator for $\tau$ by just differentiating $\kappa_g$ and noticing that both are of the form of a scalar triple product with the inner product between the two lower order derivatives and the highest order derivative with the numerator of $\kappa_g$ is one degree less than that of the numerator of $\tau$. Can anyone let me know if I'm on the right track or perhaps suggest how I might acquire the entire expression(s) for $\kappa$ and $\tau$ from $\kappa_g$?","['curves', 'differential-geometry', 'curvature', 'geodesic']"
2190360,Statistics uniform distribution commuter bus,"The time, $X$, it takes a commuter bus to complete its route is uniformly distributed between 85 and 109 minutes. $e)$ What is the probability the bus takes less than 90 or more than 95 minutes to complete the route? I have done the following $f(x) = \frac{1}{109-85} = \frac{1}{24}$ In order to find for the probability for more than 95 minutes to complete the route, I did the following for the uniform distribution $P(x > 95) = (109 - 95) * 1/24 = 0.583333$ $P(x < 90) = (90 - 85) * \frac{1}{24} = 0.2083333 \ldots$ Do I just add $0.583333 \ldots + 0.2083333\ldots?$","['means', 'statistics', 'probability', 'standard-deviation']"
2190379,"Orthonormal basis of $L^2(0,2\pi)$","I learned that the functions $e_n = \dfrac{e^{inx}}{\sqrt{2 \pi}}$ are orthonormal basis of $L^2(\mathbb{T})$, the set of square integerable functions on a torus. But then I saw that the same functions are also the orthonormal basis of the space $L^2(0,2\pi)$, the set of square integrable functions that are not necessarily periodic. Why is that the case? Why is it that we can ignore the condition for periodicity?",['functional-analysis']
2190435,"Using complex analysis , how to prove that any holomorphic function $f:\overline{D(0;1)} \to \overline{D(0;1)}$ has a fixed point?","Using complex analysis , how to prove that any holomorphic function $f:\overline{D(0;1)} \to \overline{D(0;1)}$ has a fixed point ? From this answer Suppose $f(z)$ is analytic in the closed unit disc... I can see that if $|f(z)|<1$ on $|z|=1$ then I can prove it easily ; but what if that condition doesn't hold ? I am stuck . Please help . Thanks in advance","['complex-analysis', 'holomorphic-functions']"
2190437,Calculating the location of a robot geometrically,"My team is looking to provide a piece of code that locates a robot on an X/Y grid with ~cm precision. The robot is equipped with a camera/servo combination which is used to uniquely identify columns with known positions which sit outside of the board that the robot can move on. The robot (R) can determine the angles between itself and any post (A, B, C, etc) via computer vision and measurement of the servo value that rotates the camera. It cannot determine the distance from itself to any post, but it knows the location (and therefore distances, angles) between any posts. This is a priori knowledge of the board that is programmed into the robot. For a single triangle formed by ABR, it does not seem to be intuitively possible to locate a robot, because only one angle (R), and one distance (AB) is known. Thinking that we could solve the problem by including more points, we tried including BCR. This seems to intuitively provide enough points to definitely locate a robot, but the math we have done does not point to a single answer. This could be due to real-world assumptions that we have not been able to put in an equation form. For example, the robot never leaves the board, therefore no solutions outside of that box on the grid are valid. How can I calculate the position of robot R, given locations A, B, C, etc? What is the minimum number of columns needed to locate the robot? Do the ""real-world"" assumptions mentioned above, need to be taken into account in order to successfully locate the robot?","['trigonometry', 'geometry']"
2190453,What's the probability of that matrix multiplication can exchange? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question Given two n-order matrices $A,B$,whose elements follow the Gaussian distribution on R.what's the probability that $AB=BA$?","['matrices', 'linear-algebra']"
2190454,Is the definition of z-score correct?,"I'm taking a course in Statistics, and I'm confused by the following wording which popped up on one of the lessons. Does the explanation sound correct? Are there any terms that are imprecise? Q: We can best describe the location of the sample mean in a sampling
distribution in terms of: A: Standard error Explanation: We'll describe the location of the sample mean by calculating how many standard errors it is away from the center of the sampling
distribution. That will give us a z-score for our sample mean.","['means', 'statistics']"
2190471,Function is continuous if and only if preimages of elements of a subbase are open.,"I recently started studying Topology, and functions defined from one topological space to another.
I found on Wikipedia, where I was reading about subbase, that 'continuity of a function need only be checked on a subbase of the range.' That is, if $\mathcal B$ is a subbase for $Y$ , a function $f  : X \to Y$ is continuous if and only if $f^{−1}(U)$ is open in $X$ for each $U \in\mathcal B$ . I tried to prove it by taking an open set in $Y$ and showing that its inverse is also open if $f$ is continuous, after that I studied the structure of $O$ and found that each $O$ is in fact union of finite intersections of elements of $\mathcal B$ , and I got stuck, how to show that the inverse of unions of finite intersections of elements of $\mathcal B$ to be open? May be it's very easy,but it's not striking my head, hope to get a help.
Thank you.","['general-topology', 'proof-writing']"
2190473,Generalizing Jensen's inequality to several variables.,"Let $f\colon D\to\mathbb{R}$ be a continuous function, where
  $D\subseteq\mathbb{R}^n$ is a convex open set. Find a sufficient
  condition on the derivative of $f$ such that for any $x_i\in D$,
  $1\leq i\leq n$, we have $$\frac{\sum_{i=1}^n f(x_i)}{n}\geq f\bigg(\frac{\sum_{i=1}^n x_i}{n}\bigg).$$ I thought up this question myself. I was wondering whether there is a simple test (for example, $\frac{\partial f}{\partial x}\geq0$ and $\frac{\partial f}{\partial y}\geq0$) so that I can use the inequality above.","['real-analysis', 'inequality', 'analysis']"
2190509,Cauchy CDF derivation from standard normal?,"I'm studying Probability, from the book ""Introduction to probability"" by Joseph K. Blitzstein and Jessica Hwang page 294 talks about Cauchy CDF, it says: Let $X$ and $Y \sim N(0,1)$ (Standard Normal) and let $T = \frac{X}{Y}$. The distribution of $T$ is called Cauchy Distribution. The CDF of $T$ is: $$F_T(t) = P(T \le t) = P\Big(\frac{X}{Y} \le t\Big) = P\Big(\frac{X}{|Y|} \le t\Big)$$ since the r.v.s $\frac{X}{Y}$ and $\frac{X}{|Y|}$ are identically distributed by the symmetry of the standard Normal distribution. I have few questions: Random variable has some similarity with function which we can manipulate it for example if I have function in general(like a high school math function) ex. $f(x) = x+2$ and another $g(x) = x+2$ then if I do $\frac{f(x)}{g(x)} =1$ I get $1$. lets talk about the r.v.s $X$ and $Y$, if it is identical shouldn't I get $\frac{X}{Y} = 1$? Why $P(\frac{X}{Y} \le t) = P(\frac{X}{|Y|} \le t)$ ? I know symmetry of standard normal talks about if $Z$ has standard normal distribution then $-Z$ and $Z$ has the same distribution but in this case it is the absolute value of $Y$, what does that mean? When we talk about manipulating r.v.s ex. $Y = X-1$ it is to minus all the support of $X$ by $1$ to get distribution of $Y$ but what about the r.v.s divide by another r.v.s? Do we think of it as a function that already crystallised into a number? Or how we think about it? I really have no clue about what this is about. Please give me detail and step by step answer. I'm a newbie.","['probability', 'probability-distributions']"
2190563,Entropy maximizing distributions on $GL_n(\mathbb{R})$,"$GL_n(\mathbb{R})$ comes equipped with a Haar measure $\mu$, and using it an $f\in L^1(GL_n)$ satisfing $f \geq 0$, and $\int f d\mu = 1 $ is a probability density function for some probability distribution. We can define its entropy $H(f)$ as $\int_{GL_n} log(f(x)) f(x) d \mu(x)$. According to the ""principle of maximum entropy"", the $f$ that maximize $H(f)$ given some constraints $C$, are the best choices of prior distributions. Considering the inclusion $GL_n(R) \to M_n(R)$ as a random variable, or similar, one can compute various 'moments' of the distribution. I'm not sure what conditions $C$ you can impose on $f$ to guarantee that there is a unique entropy maximizer. It seems reasonable to ask for a mean of the identity matrix and a variance some fixed matrix, because then the entropy maximizer might perhaps be some version of the Gaussian distribution. Or, as Qiaochu suggests below, perhaps fixing the expectation of the trace turns out to be interesting. Can someone enlighten me about appropriate conditions $C$ and what the entropy maximizers are?","['probability-theory', 'probability-distributions', 'information-theory', 'entropy', 'lie-groups']"
2190566,"Why is the event $A=[X\leq x]$the same as $ [u(X)\geq u(x)]=A$, for any decreasing bounded invertible function $u$?","In this question , the accepted answer claims that for a random variable $X\geq 0$, the event $A=[X\leq x]$ is the same as $ [u(X)\geq u(x)]$, for any decreasing bounded invertible function $u$ (e.g., $u(X)=\frac{1}{1+tX}$ or $u(X)= e^{-tX}$, $t>0$). I really don't see how this is true. Could anyone give me a hint here?",['probability-theory']
2190609,Is there a function whose all limits at rational points approach infinity? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Is there a function $f\colon\mathbb R \to \mathbb R$, such that its limits at rational points approach infinity?","['real-analysis', 'calculus']"
2190710,Why does this limit exist?,I want to show that $$\lim_{\epsilon \to 0} \int_\mathbb {R} \frac{1}{x^2-(1+i\epsilon)^2} dx$$ converges. I evaluated this integral numerically and it seams like it converges to some value for small $\epsilon$. Any ideas how to show that it converges?,"['complex-analysis', 'real-analysis', 'integration', 'limits']"
2190716,Prove the following limit is $\lim_{n\rightarrow\infty}\frac{1}{n}\left(\frac{(2n)!}{n!}\right)^{\frac1n}=\frac{4}{e}$,I want to prove the following limit $$\lim_{n\rightarrow\infty}\frac{1}{n}\left(\frac{(2n)!}{n!}\right)^{\frac1n}=\frac4e$$ In a previous exercise I found that $\int_1^2\ln x dx=2\ln(2)-1$ which is also equal to $\ln(4/e)$. I'm thinking I could use this result somehow?,"['calculus', 'limits']"
2190724,Show that $\cot(\pi/14)-4\sin(\pi/7)=\sqrt7$,"Show that $\cot(\pi/14)-4\sin(\pi/7)=\sqrt7$. This problem is from G.M. 10/2016 and I can't solve it. I tried with an isosceles triangle with angles $3\pi/7, 3\pi/7$ and $\pi/7$ and I tried to find a relation between the sides of the triangle but I couldn't find anything. I also thought to solve it with complex numbers but again I could't find anything. Any ideas?",['trigonometry']
2190750,Definition of smooth curves in Stein and Shakarchi's Complex Analysis - why nonzero derivative?,"A parametrized curve is a function $z(t)$ which maps a closed interval $[a, b] \subset \mathbb{R}$ to the complex plane. We shall impose regularity conditions on the parametrization which are always verified in the situations that occur in this book. We say that the parametrized curve is smooth if $z'(t)$ exists and is continuous on $[a, b]$ , and $z'(t) \neq 0$ for $t \in[a, b]$ . Above is the definition of smooth parameterized curves given in Stein and Shakarchi's Complex Analysis . Questions : (i) Why do we require $z'(t) \not= 0$ ? I have not seen this condition used in any proofs. (ii) Where is the ""regularity condition"" imposed - I thought this meant $z(t) \in C^{\infty}[a,b]$ (?)","['terminology', 'complex-analysis', 'curves', 'definition']"
2190841,What is orthogonal transformation?,"When $A^{T}A = AA^{T} = I$ , I am told it is an orthogonal transformation $A$ . But don't really get what it means. Hope to hear some explanations. $\begin{bmatrix}\cos\theta & \sin\theta \\ -\sin\theta & \cos\theta\end{bmatrix} \begin{bmatrix}\cos\theta & -\sin\theta \\ \sin\theta & \cos\theta\end{bmatrix} = \begin{bmatrix}1 & 0 \\ 0 & 1\end{bmatrix}$","['matrices', 'linear-algebra']"
2190846,Finding the Automorphism Group of a Finitely Presented Group with Solvable Word Problem,"I'm not sure if this question is more suited to mathoverflow. Is there a systematic way to solve for the automorphism group of a finitely presented group with a solvable word problem? Preferably with software. Here is my particular example: $$G_n = \langle r_1, r_2, \dots , r_n \; \vert \;r_i^{n_i}, r_1 r_2 \dots r_n \rangle \quad \text{for some} \quad \{n_i\} \subset\mathbb N$$ This is a type of hyperbolic reflection group generated by a finite number of rotations. They are index $2$ subgroups of coxeter groups. I've tried using the GAP System for Computational Discrete Algebra to find the automorphism group, but the method AutomorphismGroup doesn't seem to terminate. However, a rewriting system for all such groups can be developed using the kbmag package. I'm actually interested in the outer automorphisms, as these are nontrivial. I expect the rank of $\mathrm{Out}(G_4)$ to be $2$, and I think I have the explicit form of the generators in this case. However, I don't know how to check whether my suspected generators do in fact generate the whole outer automorphism group, and so I seek a way to compute $\mathrm{Out}(G_i)$ for given rotation orders $n_i$.","['algorithms', 'group-theory', 'gap', 'discrete-mathematics']"
2190862,"There is a bounded linear transformation $T$ such that $\|Tx\|\geq b\|x\|$, show that $T$ is $1-1$ mapping.","Let $T$ be a bounded linear transformation from a normed space $X$ onto a normed space $Y$. If there is a positive $b$ such that $\|Tx\|\geq b\|x\|$ for all $x$ in $X$,  show that $T$ is a one-one mapping.","['functional-analysis', 'normed-spaces', 'linear-algebra', 'linear-transformations']"
2190867,"A stick of length $a$ is broken in three parts. Find the probability that the length of each part is less than $b$, where $b>a/3$.","A stick of length $a$ is broken in three parts. Find the probability that the length of each part is less than $b$, where $b>a/3$. A sample space, $\Omega$, is defined as: $$\Omega=\{(x,y): x>0,y>0,a-x-y>0\}$$
$$=\{(x,y): x>0,y>0,x+y<a\}$$ where $x,y,a-x-y$ are lenghts of broken parts. Event $A$: ""The length of every part is less than $b,b>a/3$."" $$A=\{(x,y)\in\Omega\::0<x<b,0<y<b,0<a-x-y<b\}$$
$$=\{(x,y)\in\Omega\::0<x<b,0<y<b,a-b<x+y<a\}$$ Now, what I don't understand is the following: In my book's solution it says that we consider two cases: First case $$0<\frac{a}{3}<b\le \frac{a}{2}$$ In this case, $\Omega$ is a right angled triangle with sides $a$. The problem in this case is how to determine event $A$ (I am given the geometric approach). In my book's solution it says that event $A$ is also a right angled triangle.
How? Shouldn't it be quadrilateral surface? We have that
$$m(A)=\int_{a-2b}^b(b-(-x+a-b))dx$$ How? Second case $$b > \frac{a}{2}$$ Here, $\Omega$ is defined as a square with side $b$, and event $A$ as a hexagonal surface. How? We have that $$m(A)=b^2-\frac{1}{2}(a-b)^2-\frac{1}{2}(2b-c)^2$$ Why do we choose $\frac{a}{2}$ as a bound in both cases?","['probability', 'geometric-probability']"
2190881,"Number of $9-$digit numbers, all digits are different and nonzero and having no consecutive digits in consecutive positions","I am trying to solve a problem:
We are asked to find the number of $9-$digit numbers by using the digits from $1$ to $9$ only once. There is also one more restriction. Consecutive digits should not be positioned side by side. For example, $814953627$ is convenient while $8\mathbf{21}574936$ is not. It seems a hard problem to me. $1$ and $9$ have one consecutive digit while others have two. This makes the problem harder a bit. So I tried to establish a recurrence relation. For $2\leq n\leq 9$, if the number of such numbers is $A_n$, we can use $A_{n-1}$. For each such $(n-1)-$digit numbers, we can find $n-2$ such $n-$digit numbers. Let me give an example, if $n=5$, and we have such a $4-$digit number, $3142$ for instance, we have three position to place digit $5$. Therefore $$A_n = (n-2)A_{n-1} + \cdots$$ Of course this is not the only way to have such an $n-$digit number. We also place the digit $n$ between two consecutive digits. Again if we take $n=5$, and if we have an inconvenient $4-$digit number $4231$, we can place the digit $5$ between $2$ and $3$, and we obtain a convenient $5-$digit number $42531$. However, in this case, we must have only two digits positioned side by side and one of them must not be $n-1$. So, if we say $B_n$ the number of $n-$digit numbers whose digits vary between $1$ and $n$ and it has two and only two consecutive digits in consecutive positions such that consectuive digits are different than $n$, then we have $$A_n = (n-2)A_{n-1} + B_{n-1}.$$ However, we need to have one more recurrence ralation in order to find $B_{n-1}$. I could not find yet. What should I do? Trying to solve by using a completely different method or going over $B_n$? Your helps make me happy for both cases.","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2190897,"If $\sqrt n X_n\xrightarrow{d}N(0,1)$, what can we say about $X_n$?","Suppose that $X_1,X_2,\ldots$ are random variables such that
  $$
\sqrt nX_n\xrightarrow{d} N(0,1)\quad\text{as}\quad n\to\infty.
$$
  What can we say about the convergence of $X_n$ in some sense as $n\to\infty$? Since $\sqrt n\to\infty$, $X_n$ has to go to $0$ in an appropriate sense, right? Can we deduce that $X_n$ goes to zero almost surely? Or does it only have to go to $0$ in probability? For the convergence in distribution, the random variables need not be defined on the same probability space, so I am not sure if almost sure convergence or convergence in probabiltiy is even appropriate in this situation. Suppose that $Y,Y_1,Y_2,\ldots$ are iid random variables with $\operatorname EY=0$ and $\operatorname EY^2=1$. Set $X_n=n^{-1}\sum_{k=1}^nY_k$. Then $\sqrt nX_n\xrightarrow{d}N(0,1)$ and $X_n\to0$ almost surely. Hence, we have an example when $X_n\to0$ almost surely. However, I'm not sure if it is possible to construct an example when $X_n\to0$ only in probability. Any help is much appreciated!","['weak-convergence', 'probability-theory', 'sequences-and-series', 'convergence-divergence']"
2190901,Find the derivative of $\frac{d}{dt} (\int_0^t xf(x)dx)$,"I was going through the solved example 2.d in Sheldon Ross ""A First Course in Probability 8th Edition"" Chapter 5, and i got stuck on a reduction involving calculus differentiation. with regards to specifics of the problem as per the equation below, x and t are non-negative variables, and c, k are constants. f(x) represents probability density function, F(x) represents the cumulative probability density function. $$
ExpectedCost = ct\int_0^t f(x)dx - c\int_0^t xf(x)dx + k\int_t^\infty xf(x)dx -kt\int_t^\infty f(x)dx
$$ The step i am unable to comprehend is the derivative of $ExpectedCost$ with respect to t, which, as per the book, yields: $$
\frac{d}{dt} (ExpectedCost) = ctf(t) + cF(t) - ctf(t) - ktf(t) + ktf(t) - k[1-F(t)]
$$ My own calculations differ from those of the book: Integral#1:
$$
\frac{d}{dt} (\int_0^t f(x)dx) = f(t)
$$ Integral#2:
$$
\frac{d}{dt} (\int_t^\infty f(x)dx) = -f(t)
$$ Integral#3:
$$
\frac{d}{dt} (\int_0^t xf(x)dx) \\
= \frac{d}{dt} (xF(x)|_0^t - \int_0^t F(x)dx) \\
= \frac{d}{dt} (xF(x)|_0^t) - \frac{d}{dt} (\int_0^t F(x)dx) \\
= \frac{d}{dt} (tF(t)) - \frac{d}{dt} (\int_0^t F(x)dx) \\
= F(t) + tf(t) - F(t) \\
= tf(t)
$$ Integral#4:
$$
\frac{d}{dt} (\int_t^\infty xf(x)dx) \\
= \frac{d}{dt} (xF(x)|_t^\infty - \int_t^\infty F(x)dx) \\
= \frac{d}{dt} (xF(x)|_t^\infty) - \frac{d}{dt} (\int_t^\infty F(x)dx) \\
= \frac{d}{dt} (-tF(t)) - \frac{d}{dt} (\int_t^\infty F(x)dx) \\
= -F(t) -tf(t) - (-F(t)) \\
= -tf(t)
$$ As per my calculations, the derivative of the $ExpectedCost$ with respect to t, comes to zero. My guess is that i am going wrong with regards to the calculation of derivatives of Integrals #3 and #4. Please help correct my mistake. Thanks in Advance.","['derivatives', 'integration', 'definite-integrals', 'calculus']"
2190948,Why is this determinant zero ? (block matrix),"I have two non-singular matrices $P_1$ and $P_2$ such that their sum $P_1+P_2$ is also non-singular. The calculations I need to do lead me to the following block matrix: $$\begin{pmatrix} (P_1+P_2)^{-1} & (P_1+P_2)^{-1}-P_2^{-1} \\ (P_1+P_2)^{-1}-P_1^{-1} & (P_1+P_2)^{-1}\end{pmatrix}$$ Its determinant appears to be always null (i tried with random-generated $P_1$ and $P_2$) but I do not find any reason why, even though it is easy to prove it when $P_1$ and $P_2$ are $1\times 1$.
To follow up with this question, can we find a linear combination of these matrix that is zero ? Edit : this weaker version of my problem has been solved. It also solves this stronger version : let's consider the whole problem then. We have $P_1$, $P_2$, ... $P_n$ non-singular such that every sum of these is also non-singular. The block matrix is now $$
\begin{pmatrix}
\Sigma^{-1} & \Sigma^{-1}-A_1 & \dots & \Sigma^{-1}-A_1 \\
\Sigma^{-1}-A_2 & \Sigma^{-1} & \dots & \Sigma^{-1}-A_2 \\
\vdots & \vdots & \ddots & \vdots \\
\Sigma^{-1}-A_n & \Sigma^{-1}-A_n & \dots & \Sigma^{-1}
\end{pmatrix}$$ Where $\Sigma = \displaystyle \sum_{i}P_i$ and $A_k = \displaystyle \left(\sum_{i\neq k}P_i\right)^{-1}$.
Multypling by $(P_1, P_2,\dots,P_n)$ gives zero",['matrices']
2191048,Efficient way of integrating a 2-dimensional Gaussian over a convex polygonal domain,"I am looking for a reference for the calculation of integrals of bivariate normal distributions over (convex) polygons. $$P\{X\in\mathcal{A}\} = 
\int_{\Omega} \frac{1}{\sqrt{(2\pi)^2|\Sigma|}}e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}dx$$ $$\Omega:=\{x\in\mathbb{R}^2\,|\,\,Ax\leq b\}$$ For the case of triangular domains, formulae exist and are used for example in the polyCub R package. The approach can be extended to arbitrary polygons, based on a triangulation of the domain. I came across a paper [1] from 1978 that seemingly provides a more efficient solution, without the need for a triangulation. Here the integral over the complement of the region is calculated, based on a partitioning to external angular regions. For these semi-analytical solutions using special functions $(\operatorname{erf}, \operatorname{erfc})$ are given. I was wondering if a more recent work using such an approach exists? The original document is sometimes barely readable due to the scan quality. [1] A. R. DiDonato, M. P. Jarnagin Jr, and R. K. Hageman, “Computation of the bivariate normal distribution over convex polygons,” DTIC Document, 1978.","['reference-request', 'statistics', 'definite-integrals', 'normal-distribution']"
2191058,Prove that $\sin\frac{\pi}{7}\sin\frac{2\pi}{7}\sin\frac{3\pi}{7}=\frac{\sqrt{7}}{8}$.,"Prove that
  $\sin\frac{\pi}{7}\sin\frac{2\pi}{7}\sin\frac{3\pi}{7}=\frac{\sqrt{7}}{8}$. What I've tried doing :
If $\theta=\frac{\pi}{7}:$
$$
3\theta+4\theta=\pi
$$
This allowed me to prove that :
$$
\tan^2\frac{\pi}{7}+\tan^2\frac{2\pi}{7}+\tan^2\frac{3\pi}{7}=21
\\
\cot^2\frac{\pi}{7}+\cot^2\frac{2\pi}{7}+\cot^2\frac{3\pi}{7}=5
$$
Is my reasoning wrong or is this entirely the wrong way to approach this question ?",['trigonometry']
2191089,What is the mechanism of Eigenvector? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I have studied EigenValues and EigenVectors but still what I can't see is that how EigenVectors become transformed or rotated vectors.","['linear-algebra', 'linear-transformations', 'vector-analysis']"
2191107,"What combinations of ""swaps"" of elements in a list are equivalent?","Define a swap-operation $s_{ij}=s_{ji}$ on an $n$-tuple $a_n=(1,2,\dots,n)$ as interchanging the elements in the $i$th and $j$th positions of the tuple. I would like to find an efficient way to generate all distinct permutations resulting from applying $k<n$ such swaps, i.e., all distinct $S=s_1s_2\cdots s_k$, where the subscripts refers only to the order in which the swaps are applied; any of the swaps $1,\dots,k$ could be any of the possible $s_{ij}$ (but it is perhaps appropriate to exclude the possibility of having two adjacent and identical swaps, since they would just cancel). Example: For $n=3$, represent the tuple as a column vector and the swaps by the three $\left(\binom{n}{2}=3\right)$ possible $3\times 3$ matrices: \begin{align}
s_{12}&=\pmatrix{0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1}\\
s_{13}&=\pmatrix{0 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 0} \\
s_{23}&=\pmatrix{1 & 0 & 0 \\ 0 & 0 & 1 \\ 0 & 1 & 0}
\end{align} Then we can identify the results of applying $k=2$ such swaps: \begin{align}
s_{12}s_{13}a_3^T&=\pmatrix{3 & 1 & 2}^T \\
s_{12}s_{23}a_3^T&=\color{red}{\pmatrix{2 & 3 & 1}^T} \\
s_{13}s_{12}a_3^T&=\color{red}{\pmatrix{2 & 3 & 1}^T} \\
s_{13}s_{23}a_3^T&=\color{blue}{\pmatrix{3 & 1 & 2}^T} \\
s_{23}s_{12}a_3^T&=\color{blue}{\pmatrix{3 & 1 & 2}^T} \\
s_{23}s_{13}a_3^T&=\color{blue}{\pmatrix{3 & 1 & 2}^T} \\
\end{align} Note the duplicates. I would like to avoid calculating these. Could I have known from the start that $\color{red}{s_{12}s_{23}=s_{13}s_{12}}$ and $\color{blue}{s_{13}s_{23}=s_{23}s_{12}=s_{23}s_{13}}$, without actually calculating these? So far, I've checked the result of all permutations of operations (giving the six scenarios in the example above), and then thrown out the duplicates, but my computer quickly chokes. Is there a way to go directly to the unique results for a given $n$ and $k$? In my present problem, $n=9,$ but a generalization would be nice. I'm using Matlab, but pseudo-code or strictly mathematical considerations are both very welcome. Thank you.","['algorithms', 'matlab', 'permutations', 'group-theory', 'discrete-mathematics']"
2191126,Topology of the complement of a countable union of divisors,I have the following situation: let $U\subset\mathbb{P}^n$ ($n\geq2$) be an open subset and let $U'$ the complement of a countably infinite union of divisors in $U$. Is there any way to know the relation between $\pi_1(U')$ and $\pi_1(U)$? For example I was wondering if the induced map $\pi_1(U')\to\pi_1(U)$ was surjective. Notice that here we are working over $\mathbb{C}$ hence a divisor has real codimension $2$. A theorem of Godbillon (cf. Francesco's answer here ) states that we have surjectivity in the case of a unique divisor. How can we pass from this to a countable union? Is there any topological spectral sequence which can handle this question? References are much appreciated. Thank you very much.,"['algebraic-topology', 'fundamental-groups', 'algebraic-geometry']"
2191162,Why can't we use the circumference of a circle to find arc lengths of polar curves?,"To find the area in a polar curve, we use areas of sectors of tiny pie slices to figure out the area, to get
$$A=\int_a^b\frac{1}{2}r^2\,d\theta$$
Why can't we use the circumference of the circle to figure out arc length of a polar curve? I tried and it went something like this:
The arc length of a tiny pie slice is $r\theta$, where theta is in degrees and r is the radius. Adding up all the tiny pie slice arc lengths, we should get
$$\int_a^b r\,d\theta$$
But that is clearly not correct! For example, for $1+cos\theta$, this 'formula' tells us that the arc length is $2\pi$, when the actual arc length is 8. What am I doing wrong? Am I assuming something wrong? Or is it just stupid mistakes?","['polar-coordinates', 'calculus']"
2191222,Number of $5$-digit numbers which are divisible by $11$ and whose digits add up to $43$,"Problem Statement:- Consider the collection of all $5$-digit numbers such that the sum of digits of each number is $43$. A number is selected at random from the collection. Find the probability that the number is divisible by $11$. My Solution:- Let the five-digit numbers be represented by $x_1x_2x_3x_4x_5$. As the digits of these numbers should add up to $43$, we have $$x_1+x_2+x_3+x_4+x_5=43\tag{where $1\le x_i\le9$, $x_i\in\mathbb{N}$}$$ So, the number of such numbers is equal to the coefficient of $x^{43}$ in $\left(\dfrac{1-x^{10}}{1-x}\right)^5=15$ As this is a listable amount of numbers so lets just list them $$99997\\
99979\\
99799\\
97999\\
79999\\
99988\\
99889\\
98899\\
88999\\
99898\\
98989\\
89899\\
98998\\
89989\\
89998$$ Its easy to spot the numbers divisible by 11 which are $97999,\; 99979,\; 98989$ So, the required probability comes out to be $\dfrac{3}{15}=\dfrac{1}{5}$ The number of numbers in this list turned out to be small hence just listing them turned out to be good enough for finding the numbers divisible by $11$, but what if the sum of the digits of the number turns out to be such that the number of numbers satisfying the condition turns out to be too big. In that case, how am I supposed to find the number of numbers which are divisible by $11$ without the help of a computer but just with pen and paper.","['combinatorics', 'elementary-number-theory']"
2191265,Calculating Euler Number limit,"Please, so far I did
$$\lim_{x\to +\infty}\left(\frac{x^2-x+1}{x+2}\right)^{\frac{1}{x-1}},$$ but I can write
$$\frac{x^2-x+1}{x+2}=1+\frac{x^2-2x-1}{x+2}=1+\frac{1}{\frac{x+2}{x^2-2x-1}}.$$
But
$$\lim_{x\to +\infty}\frac{x+2}{x^2-2x-1}=0,$$ so I can not use 
$$e =\lim_{N\to \infty}(1+\frac{1}{N})^N$$","['calculus', 'limits']"
2191320,Prove that $MA\cdot AN+NB\cdot BL+LC\cdot CM<BC^2$.,"I've been trying to understand where to take this math problem... I've tried substituting all of these terms below in the form of $BC$ since it is an equilateral triangle but that just gets messy and I cant figure out what else to try. Triangle $ABC$ is equilateral, $L,M,N$ are points on $BC,CA$ and $AB$ respectively. Prove that $MA\cdot AN+NB\cdot BL+LC\cdot CM < BC^2$.","['inequality', 'geometric-inequalities', 'geometry']"
2191335,A question about how far a well known theorem of Sierpinski can be strengthened,"Let E be a finite dimensional Euclidean space. A well known theorem of Sierpinski states that if C is an infinite compact-i.e. closed and bounded-connected subset of E, then C cannot be the countable union of pairwise disjoint closed subsets of E. I have also seen a theorem of Hausdorff which implies that the same conclusion continues to hold if C is any infinite closed connected subset of E-not necessarily compact-provided C is locally connected. My question is: Does Hausdorff's theorem continue to hold, if one drops the requirement that C should be locally connected?..........Some of the statements I have read in the literature seem to suggest that the answer is ""Yes"" whenever the infinite connected subset C of E is locally compact. This will certainly be the case if E is a finite dimensional Euclidean space and C is a closed subset of E. But I am not really clear about the whole situation.",['general-topology']
2191356,Trigonometric inequality with weird angle,I have this inequality $\log_{\tan x}\sqrt{\sin^2x-\frac{5}{12}}<1$ that I would like to solve. So $\tan x>0$ and $ \tan x\ne1$.  First I try when $\tan x>1$. Then I have $\sqrt{\sin^2x-\frac{5}{12}}<\tan x$ I have to solve the system $\sin^2x-\frac{5}{12}\ge0$ (I can't solve this one ($\frac{5}{12}$ troubles me I souldn't use a calculator or a table to solve this)) $\tan x>0$ $\sin^2x-\frac{5}{12}<\tan^2x$ and this one,"['inequality', 'trigonometry']"
2191359,Why are there nine regular polyhedra?,"Context for question: The study of polyhedra and more generally of polytopes has never been particularly focused on rigor, and many references for results are often either non-existent, or impossible to find. This lead me to try to prove some basic results on polyhedra. To be clear, the definition of polyhedra I use is a set of polygonal faces and edges such that two faces are adjacent to each edge, no two elements coincide and such that no subset of faces and edges forms a valid polyhedron (this excludes compounds). The problem with answering the question: With this in mind, I can now use the common definition of a regular polyhedron as a vertex-transitive polyhedron with congruent, regular faces. However, I ran into a problem when trying to prove that there were only 5 convex and 4 non-convex types (Platonic and Kepler-Poinsot solids): First of all, the common proof for the Platonic solids (the one that uses the fact that you can't have many shapes with many sides around a vertex) assumes too many things. For example, one first needs to prove that the sum of the angles around a vertex is less than $2\pi$, which is false in the general, not-necessarily-convex case. Also, one needs to prove that given a vertex arrangement, there's at most one regular polyhedron that can be made. And even with all of this, the argument can't be generalized to non-convex solids: One can fit perfectly 7 equilateral triangles around a vertex, if you allow them to intersect. So, why are there only 9 regular types of polyhedra? [EDIT #1] Using Arentino's answer, I can immediately characterize the convex cases. If I could prove that the convex hull of any regular solid is regular, I could easily just check for polygons on the vertices of these five solids and check how to connect them to create the other four cases. However, I don't know why should this be the case either, and I have no idea of how to prove it. [EDIT #2] Assuming all ""known"" properties of convex hulls (they are polyhedra for finite sets of points, etc.), I have been able to prove that the convex hulls have to be vertex-transitive (any symmetry of the original polyhedron that takes vertex A to B, will preserve the positions of the vertices as a whole and therefore the convex hull. As a consequence, the vertex figures are all congruent. However, I still need to prove that the faces are all congruent and regular, and I don't know how to do this. (Yet again). [EDIT #3] At last, some useful literature! I found the following book (p. 260) where it describes why every Kepler-Poinsot solid must be a stellation of a regular polyhedron. (Although if someone can prove the thing about convex hills, I'd appreciate it deeply). There's just a tiny problem. I don't understand the proof completely. For example, why should the ""kernel"" of the polyhedron be a convex polyhedron? And even if it is, how did he show it consisted of regular faces?","['polyhedra', '3d', 'euclidean-geometry', 'geometry']"
2191380,Optimal Pricing Strategy,"I have 1 room for rental. I can ask any price. The customers come in sequentially. If the customer has money that is equal to or greater than my price, they will take my room. Otherwise I get nothing. Assume customer's money is exponentially distributed with parameter $\lambda=1$, and they are i.i.d, and there are $n=30$ customers in total. a) Assume your pricing is fixed. what is your optimal price? b) If you can change your pricing every time you want (i.e., you ask customer 1 for 10 dollars, you can ask customer 2 for 5 dollars, etc). What is your optimal price? Attempt: a) For $n$ customers, I will get $p*I_{X_1 >p, OR, X_2>p, OR, X_3>p,......OR,X_n>p}$, where $I$ is the indicator function. Thus, i will have $p*n*exp(-p)$, taking the derivative and set it to 0, I get $p^*=1$. b) For the adjustable price, let $p_i=$ price that you ask for the $i_th$ customer, then the profit is: $p_1P(X_1>p_1) + p_2 P(X_1<p_1  \wedge X_2>p_2) + p_3 P(X_1<p_1  \wedge X_2<p_2  \wedge X3>p_3 +) .... $ $= p_1e^{-p1} + p_2(1-e^{-p_1})(e^{-p_2}) +...$","['probability-theory', 'probability', 'expectation', 'probability-distributions']"
2191453,"Why is it true that $\lim_{n\to\infty} \left(\int_a^b \left|f(x)\right|^ndx\right)^{1/n} = \text{sup}\{\left|f(x)\right| : x \in [a,b]\}$? [duplicate]","This question already has answers here : If $f(x)$ is continuous on $[a,b]$ and $M=\max \; |f(x)|$, is $M=\lim \limits_{n\to\infty} \left(\int_a^b|f(x)|^n\,\mathrm dx\right)^{1/n}$? (2 answers) Closed 7 years ago . Can someone explain the intuition behind this/ what the proof might look for this? If $f$ is a continuous, real-valued function on $[a,b]$, then
\begin{equation}
\lim_{n\to\infty} \left(\int_a^b \left|f(x)\right|^ndx\right)^{1/n} = \text{sup}\{\left|f(x)\right| : x \in [a,b]\}
\end{equation} It seems like it's a way of averaging $\left|f(x)\right|$, similar to how the Lyapunov number is an average of all the slopes of an orbit in a dynamical system.","['real-analysis', 'analysis']"
2191456,Seemingly difficult probabilistic method question,"Hello I was asked the following question and I really am not sure how to show such results. I believe it could maybe be done using the probabilistic method. Consider a graph on $ m$ vertices, for any pair of vertices , we include an edge between $i$ and $j$ with probability $1/2$. This is done independently and for every pair $i,j$. The question is to show that for any two vertices, with large probability they share at least $\frac{m}{4}-\sqrt{m\log m}$ common neighbours. My thoughts: It seems like it may be possible to use Chernoff bounds, for any given vertex, if we let $X_{i}$ denote the random variable of the number of neighbours of some vertex $i$, I believe $$E[X_{i}]=\frac{m-1}{2}=\mu$$ So that could possibly be used in computing a probability using Chernoff bound. However, I don't see how I can incorporate that we are looking for shared common neighbours. Maybe using pigeonhole principle? Maybe it is related to Ramsey theorem and edge colouring? Or maybe their is a whole different approach that would work a lot more efficiently? Any ideas? Thanks","['graph-theory', 'probability', 'discrete-mathematics']"
2191464,What is the number of all skew symmetric bilinear forms on $m$ dimensional space $V$ over $\mathbb{F}_q$ with rank equal to $2r$?,Let $V$ be a vector space of dimension $m$ over the finite field $\mathbb{F}_q.$ Then I want to find the number of all skew symmetric bilinear forms on $V$ with rank equal to $2r$ ($0 \leq 2r \leq m$). I need some help. Thanks in advance.,"['matrices', 'multilinear-algebra', 'bilinear-form', 'linear-algebra', 'vector-spaces']"
2191471,Group of units of direct sum of rings is isomorphic to direct sum of the groups of units,"Let $R_{1}$, $R_{2}$, $\cdots$, $R_{m}$ be rings with identity. I need to prove that the following group isomorphism holds: $U(R_{1} \oplus R_{2} \oplus \cdots \oplus R_{n}) \simeq U(R_{1}) \oplus U(R_{2}) \oplus \cdots \oplus U(R_{n})$. I surmise that induction is going to be necessary here, but I'm having trouble even just getting started to prove it for just the base case, where $n = 2$:  $U(R_{1} \oplus R_{2}) \simeq U(R_{1}) \oplus U(R_{2})$. I have absolutely no idea where to begin, so any kind of point in the right direction would be appreciated. Just be willing to answer lots of follow-up questions, please. Thank you in advance.","['abstract-algebra', 'ring-theory', 'direct-sum', 'group-isomorphism']"
2191485,Must any nth order homogeneous ODE have n solutions?,"I am quite confused about ordinary differential equations and the number of solutions they have. In particular, it seems that an nth order homogeneous differential equation has n solutions, not more or less. I cannot figure out why this would be so. I have read the following two posts: here and here . The first didn't really seem to have any conclusive answers and the second was quite technical for me to understand. Perhaps there is an explanation in easy terms? My current 'understanding' so far is as as follows: The general solution to any homogeneous linear ODE is a linear combination of all possible solutions. In the case of an ODE of form $ay''+by'+cy=0$ where there are two equal roots to the auxillary equation, i.e. $b^2-4ac=0$, then I know the extra solution is $xe^{\lambda x}$ (although I have no idea why someone ever realised that this would work. Is there an underlying reasoning motivating this choice?) Now if I accept this form and plug it in, I can see that indeed $xe^{\lambda x}$ is a solution iff $b^2-4ac=0$. Therefore in the case of two equal roots of the auxillary equation, we necessarily have that two of the solutions are $e^{\lambda x}$ and $xe^{\lambda x}$ so the general solution is their linear combination. And if the two roots of the auxillary equation are not equal, $xe^{\lambda x}$ is not a solution. Of course I have not shown that there are only two solutions (could there be more?), nor have I shown that there have to be at least n solutions for an nth order ODE. I have just demonstrated that for a second order linear homogeneous ODE, $xe^{\lambda x}$ is a solution if there is only one root of the auxillary equatiuon, and it isn't otherwise. I think my dilemma boils down to the following questions which I would be grateful if someone could answer, or indicate where to look for further information: a)Need an nth order homogeneous ODE have n solutions (can it ever have more or less)? b)Need an nth order linear homogeneous ODE have n solutions (can it ever have more or less)? c)Are there any 'special cases'? Thank you in advance. EDIT: I have just thought a bit about 'function spaces' (i'm not sure if this is the right term. I am not too familiar with this but from my vague understanding, I think that n liearly independent solutions will span an n dimensional function space, so if it is the case that there must be n linearly independent solutions then this implies that the solution space of the ODE must span n dimensions? I am not sure why this is the case though, or what differential equations have to do with dimensions...","['ordinary-differential-equations', 'linear-algebra', 'fundamental-solution']"
2191490,General Topology and Basis definition,"In the book ""Introduction to Smooth Manifolds"" by John M. Lee, the author defined general topology and basis as: A topology on a set $X$ is a collection $\mathcal{T}$ of subsets of $X$, called open sets , satisfying: $X$ and $\emptyset$ are open The union of any family of open sets is open The intersection of any finite family of open sets is open A basis for a topology on $X$ is a collection $\mathcal{B}$ of subsets of $X$ such that $X = \cup_{B \in \mathcal{B}} B$ If $B_1, B_2 \in \mathcal{B}$ and $x \in B_1 \cap B_2$, there exists $B_3 \in \mathcal{B}$ such that $x \in B_3 \subset B_1 \cap B_2$ My questions are: In topology definition: Why ""union of any family""? Why not ""union of finite elements of $\mathcal{T}$""? The same with intersection. In basis definition: are those set $B$ open sets? Would it be any different if we consider the basis as a collection of general subset? And does $B_3$ have to be strictly proper subset of $B_1 \cap B_2$?","['general-topology', 'definition']"
2191508,"Discrete math(greatest common divisor,gcd)","True or False
For any positive integer,n (n not equal to 13), gcd (13,n)=1. It might be false if n is a multiple of 13 (e.g. 26) because then the gcd will be 13 instead.But isn't it a precondition that gcd(a,b) means a>b?Thus the statement will be true?","['gcd-and-lcm', 'discrete-mathematics']"
2191511,Tangent Space of the Heisenberg Group,"Let H$_{3}$(R) denote the Heisenberg group of 3 x 3 real matrices. For any A $\in$ H$_{3}$(R) such that A = $\left( \begin{array}{ccc}
1 & a & b \\
0 & 1 & c \\
0 & 0 & 1 \end{array} \right)$ ,  $\exists$ a continuous path A(t), 0 $\leq$ t $\leq$ 1, from I to A given by A(t) = $ \left( \begin{array}{ccc}
1 & a(t) & b(t) \\
0 & 1 & c(t) \\
0 & 0 & 1 \end{array} \right)$ . Let v be the tangent vector of A(t) at identity (t=0), then v= $\frac{d}{dt}$ A(t)|$_{t=o}$. Then shouldn't v = A'(0) = $ \left( \begin{array}{ccc}
1 & \frac {d}{dt}0 & \frac{d}{dt}0 \\
0 & 1 & \frac{d}{dt}0 \\
0 & 0 & 1 \end{array} \right)$ = $ \left( \begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 \end{array} \right)$ ? If this is correct, then is the tangent space of H$_{3}$(R) the standard, orthonormal basis of R$^3$? (Apologies if this is horribly fallacious, I'm new to lie algebra)","['differential-geometry', 'linear-algebra', 'lie-algebras', 'lie-groups']"
2191522,Question About the Logic of my Proof,"Okay, I am working on the following relatively simple problem: Let $f(x) = |x-3| + |x-1|$ for all $x \in \mathbb{R}$. Find all $t$ for which $f(t+2) = f(t)$. So, if $f(t+2)=f(t)$, the is equivalent to $|t+1| = |t-3|$. Thus, if this holds, one can square both sides and arrive at $t=1$. So, this value of $t$ is a necessary condition, but prima facie it isn't the only value. To show sufficiency, could I let $t = 1 + \epsilon$, plug it into the above equation, deduce that $\epsilon = 0$, and conclude that $t=1$ is the only value? Would that go into showing this is the only value?","['algebra-precalculus', 'proof-verification']"
