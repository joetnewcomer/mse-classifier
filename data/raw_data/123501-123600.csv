question_id,title,body,tags
1862541,"Does there exist a subsequence $n_j$ such that $\int_A f_{n_j}(x)\,dx$ converges for each Borel subset $A$ of $[0, 1]$?","Let $\{f_n\}$ be a sequence of measurable real-valued functions on $[0, 1]$ that is uniformly bounded. Does there exist a subsequence $n_j$ such that 
$$\int_A f_{n_j}(x)\,dx$$ 
converges for each Borel subset $A$ of $[0, 1]$?","['real-analysis', 'measure-theory']"
1862551,"Compute $E(X\mid X+Y)$ if $(X,Y)$ is centered normal with known covariance matrix [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question The random variable $(X,Y)$ has a two dimensional normal distribution with mean $(0,0)$ and covariance matrix $\begin{pmatrix}
 4&2 \\ 
 2&2 
\end{pmatrix}$. Find $E(X\mid X+Y)$. I am completely lost with this question.","['probability', 'covariance']"
1862558,"Brownian Motion in Confined space, any results?","I am searching for work regarding Brownian motion in a confined space, like a sphere or a cylinder, where the wall will serve as reflection boundary. I am wondering if it is possible to derive results such as the mean square displacement under such or similar constraint? I have been searching google for a while but did not get specific result. Any suggestion or recommendation will be greatly appreciated! Thanks!","['stochastic-processes', 'brownian-motion', 'random-walk', 'geometry']"
1862568,How to prove that if $E[X^2]$ is finite then $n\Pr[\lvert X\rvert>\varepsilon\sqrt n]\xrightarrow[n\to\infty]{}0$?,"Let $X$ be a random variable with $E[X^2]<\infty$. I want to prove that
$$ n\Pr[\lvert X\rvert>\varepsilon\sqrt n]\xrightarrow[n\to\infty]{}0 \text. $$ I tried to apply Chebyshev's inequality, but it only yields
$$ n\Pr[\lvert X\rvert>\varepsilon\sqrt n] \leq n\frac{E[X^2]}{n\varepsilon^2} = \frac{E[X^2]}{\varepsilon^2} \text. $$
At least that bound doesn't diverge , but on the other hand it doesn't imply anything useful either. Chebyshev's inequality with higher powers $p$ of $X$ would help, but then $E[\lvert X\rvert^p]$ might be infinite. How does one approach this problem?","['probability-theory', 'inequality', 'convergence-divergence']"
1862571,"Combinatorial proof of $\sum_{k=0}^{n}(-1)^{k}\binom{n}{k}(l-k)^n=n!$, using inclusion-exclusion","If $l$ and $n$ are any positive integers, is there a  proof of the identity $$\sum_{k=0}^{n}(-1)^{k}\binom{n}{k}(l-k)^n=n!\;$$ which uses the Inclusion-Exclusion Principle? (If necessary, restrict to the case where $l\ge n$.) This question is closely related to Expressing a factorial as difference of powers: $\sum_{r=0}^{n}\binom{n}{r}(-1)^r(l-r)^n=n!$? and also Proof of the summation $n!=\sum_{k=0}^n \binom{n}{k}(n-k+1)^n(-1)^k$?","['binomial-coefficients', 'combinatorial-proofs', 'inclusion-exclusion', 'combinatorics', 'summation']"
1862578,Elementary proof of $C^\infty_c$ is dense in $L^p (L^q)$ mixed space,"As it well known, $C^\infty_0 (\mathbb{R}^n)$ (the space of infinitely differentiable functions with compact support) is dense in $L^p (\mathbb{R)^n}$ Here I want to consider the same result with mixed norm. The mixed norm space is defined by $$ \Vert f \Vert_{L^p_t L^q_x}:=\left(\int_{\mathbb R} \left[\int_{\mathbb{R}^n} |f(t,x)|^p dx\right]^{\frac{q}{p}}dt\right)^{\frac{1}{p}}.$$ This norm can be viewed as $$ \Vert f \Vert_{L^p_t L^q_x}:=\left(\int_{\mathbb R} \Vert f(t,\cdot) \Vert_{L^q (\mathbb{R^n})}^p dt \right)^{\frac{1}{p}}.$$ So by this point of view, I can verify that the space $L^p_t L^q_x$ is actually $L^p (\mathbb{R}; L^q(\mathbb{R}^n)$ ) space, which is a special case of Bochner space. Then in the theory of Banach-valued function space, $$ f(t) = \sum_{i=1}^n a_i \phi_i (t),$$ where $a_i$ is an element of Banach space $B$ , $\phi_i$ is a characteristic function in $\mathbb{R}$ with finite measure, is dense in $L^p (\mathbb{R};B)$ when $1\leq p <\infty$ . So by taking molification, we see that $C^\infty_0 (\mathbb{R};B)$ is dense in $L^p (\mathbb{R};B)$ . As $C^\infty_0$ is dense in $L^p(\mathbb{R}^n)$ , $C^\infty_0 (\mathbb{R}^{n+1})$ is dense in $L^p_t L^q_x$ . My question is the following: Can I proved it properly? How can prove the fact without using Bochner integral? Thank you in advance.","['real-analysis', 'partial-differential-equations', 'harmonic-analysis', 'proof-verification', 'functional-analysis']"
1862612,"Is $X\simeq [0,1]$?","Suppose that $X$ is a metric continuum irreducible between two points $p$ and $q$. Suppose further that whenever $U$ is a connected open set missing $p$ and $q$, we have $X\setminus U$ has two connected components, one containing $p$ and the other containing $q$. Is $X$ necessarily equal to (homeomorphic to) $[0,1]$? EDIT: I don't have much context to add.  I came up with this question while trying to solve a very different problem. Honestly I have to clue if the answer is yes or no, though if the answer is yes it would be useful to me.","['general-topology', 'compactness', 'connectedness']"
1862625,Solving the quadratic formula to determine stability of a system,"I am trying to solve the $2\times 2$ matrix $$\begin{bmatrix} 0 &1 \\ -k &-b \end{bmatrix}$$ for a relationship between the variables $k$ and $b$ to determine when a system is stable. Stability means that the real component of the eigenvalues are all $0$ or less. I have sought the eigenvalues and have gotten to the quadratic formula here: eigens $= \frac{-b \pm \sqrt{b^2-4k}}{2}$ I know that the eigenvalues must be less than $0$, but I am having trouble with the algebra to get to a clear relationship. Any tips?","['matrices', 'eigenvalues-eigenvectors', 'quadratics']"
1862652,How solve $\int_{0}^{\infty} \dfrac{1-\cos x}{x^{2}} dx$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question What is the value of the following integral? $$\int_{0}^{\infty} \dfrac{1-\cos x}{x^{2}} dx$$","['improper-integrals', 'integration', 'calculus']"
1862654,"Show $A\cap B \neq \varnothing \Rightarrow \operatorname{dist}(A,B) = 0$, and $\operatorname{dist}(A, B) = 0 \not\Rightarrow A\cap B \neq \varnothing$","I have a question Let $d$ be a metric on $X$ , and define the set to set distance $$\operatorname{dist}(A,B) = \inf\{d(x,y): x\in A, y \in B\}$$ where $A,B \subseteq X$ are nonempty sets Show that $A\cap B \neq \varnothing \Rightarrow \operatorname{dist}(A,B) = 0$ , and $\operatorname{dist}(A, B) = 0 \not\Rightarrow A\cap B \neq \varnothing$ First: ( $A\cap B \neq \varnothing \Rightarrow \operatorname{dist}(A,B) = 0$ ) Trivial, since $A \cap B \neq \varnothing \implies \exists z \in A$ and $B$ , so $\operatorname{dist}(A,B) = \inf\{d(z,z)\} = 0$ Second: ( $\operatorname{dist}(A, B) = 0 \not\Rightarrow A\cap B \neq \varnothing$ ) We want to produce $A \cap B = \varnothing$ such that $\operatorname{dist}(A,B) = 0$ .
Is there a metric space where this can happen? I've checked the discrete metric, all the $\ell_p$ metrics. I don't think you can have disjoint sets with their distance zero.","['real-analysis', 'metric-spaces']"
1862666,"Are there infinitely many primes $n$ such that $\mathbb{Z}_n^*$ is generated by $\{ -1,2 \}$?","Let $n$ a prime, and let $\mathbb{Z}_n$ denote the integers modulo $n$. Let $\mathbb{Z}^*_n$ denote the multiplicative group of $\mathbb{Z}_n$ Are there infinitely many $n$ such that $\mathbb{Z}^*_n$ is generated by $\{ -1, 2 \}$? Artin's conjecture on primitive roots implies something even stronger: that there are infinitely many $n$ such that $\mathbb{Z}^*_n$ is generated by $\{ 2 \}$. Although likely to be true (in particular it is implied by the Generalized Riemann Hypothesis), as far as I know this conjecture remains open. I am wondering if it is possible that with generators $\{-1,2 \}$, this is known unconditionally. (One could, of course, ask this for any two generators. For reasons that I'll omit here, I am especially interested in the the generating set $\{-1,2 \}$.)","['number-theory', 'modular-arithmetic', 'primitive-roots']"
1862692,Question about continuity in the box topology,"I have two question regarding the following example in Munkres (1)Why ""if $f^{-1}(B)$ were open it would contain some interval $(-\delta,\delta)$ about 0.
(2)My second question is somewhat broad, but maybe someone can shed some light on it. My intuition with why certain functions are continous comes from metric spaces. But, given a function like the one in the example below how can one see intuitively if it is continuous? Example 2. Consider $\mathbb R^\omega$, the countably infinite product of $\mathbb R$ with itself. Recall that $$\mathbb R^\omega = \prod_{n \in \mathbb Z_+} X_n,$$ where $X_n = \mathbb R$ for each $n$. Let us define a function $f : \mathbb R \to \mathbb R^\omega$ by the equation $$f(t) = (t, t, t, \dotsc)$$; the $n$th coordinate function of $f$ is the function $f_n(t) = t$. Each of the coordinate functions $f_n : \mathbb R \to \mathbb R$ is continuous; therefore, the function $f$ is continuous if $\mathbb R^\omega$ is given the product topology. But $f$ is not continuous if $\mathbb R^\omega$ is given the box topology. Consider, for example, the basis element $$B = (-1, 1) \times (-\frac{1}{2}, \frac{1}{2}) \times (-\frac{1}{3}, \frac{1}{3}) \times \dotsb$$ for the box topology. We assert that $f^{-1}(B)$ is not open in $\mathbb R$. If $f^{-1}(B)$ were open in $\mathbb R$, it would contain some interval $(-\delta, \delta)$ about the point $0$. This would mean that $f((-\delta, \delta)) \subset B$, so that, applying $\pi_n$ to both sides of the inclusion, $$f_n(-\delta, \delta)) = (-\delta, \delta) \subset (-1/n, 1/n)$$ for all $n$, a contradiction.","['product-space', 'general-topology']"
1862747,$\sup_n \int |f_n|^{1 + \gamma}d\mu < \infty$ implies $\{f_n\}$ is uniformly integrable?,"Suppose $\mu$ is a finite measure and for some $\gamma > 0$, we have$$\sup_n \int |f_n|^{1 + \gamma}d\mu < \infty.$$Does it follow that $\{f_n\}$ is uniformly integrable?","['real-analysis', 'calculus', 'integration', 'lebesgue-integral', 'measure-theory']"
1862748,Why minimising the MSE in Variance-Bias tradeoff?,"As I understand the Variance-Bias tradeoff, modifying estimators to minimise bias might increase the variance of the estimator and vice-versa. For the simple case of the biased variance estimator, using $\frac{n}{(n-1)}$ as a correction factor might overcome the bias but the estimator has an un-optimal variance. At several places regarding this, as a more suited goal of supervised learning, correction factors to minimise the Mean Squared Error are used ($\frac{n}{n+1}$ for the sample variance). Why is minimising MSE a better objective (than that of minimising only bias)?","['descriptive-statistics', 'statistics', 'variance']"
1862751,How many egyptian fractions including and above (1/n) are necessary to sum to unity,"Let there be a finite set of positive integers such that: (a) no two members of the set are equal (b) the sum of the inverse of each member of the set is equal to one The smallest set (as defined by its number of members) is simply $[1]$. The next is $[2, 3, 6]$. There are (by my count) six different sets which have four members. However, all of them include the number '$2$'. This is self-evident, as, if they included only numbers greater than $2$, the greatest that four members could sum to is $1/3 + 1/4 + 1/5 + 1/6 = 19/20$. Consequently, there is a way to have a five member set which doesn't use $2$. $[3, 4, 5, 6, 20]$. What is the smallest set which uses neither $2$ nor $3$? It would seem possible to do it with $7$ members, as $1/4 + 1/5 + ... 1/10 = 1.095...$ 
However, I could not find a way to sum to exactly one with $7$ members. The smallest set appears to have $8$ members, such as $[4,5,6,8,10,12,20,40]$. The general question, then, is this. What is the relationship between $n$ (minimal number permitted to be a member of the set) and $m$ (members of the minimal set). 
So far, we have $n=1,m=1$; $n=2,m=3$; $n=3,m=5$; $n=4,m=8$. Can anyone extend this series by considering $n=5$; or solve the general problem? Thanks","['number-theory', 'summation', 'egyptian-fractions']"
1862764,"Variant of dominated convergence theorem, does it follow that $\int f_n \to \int f$?","Suppose $f_n$, $g_n$, $f$ and $g$ are integrable, $f_n \to f$ almost everywhere, $g_n \to g$ almost everywhere, $|f_n| \le g_n$ for each $n$, and $\int g_n \to \int g$. Does it follow that $\int f_n \to \int f$?","['real-analysis', 'integration', 'probability', 'measure-theory', 'lebesgue-integral']"
1862793,"Open interval $(0,1)$ with the usual topology admits a metric space","which of the following is/are true ? $(0,1)$ with the usual topology admits a metric which is  complete . $(0,1)$ with the usual topology admits a metric which is not  complete. $[0,1]$ with the usual topology admits a metric which is not complete. $[0,1]$ with the usual topology admits a metric which is  complete. This question has come at my competetive exam. I think this is a wrong question, because completeness a metric space property not a topological space property.In the offical answer key, answer has given (1) and (4), I want to send my representation. So please check my representation. Thank you Let $X = (0,1)$ and $d$ is a Euclidean  metric on $X$ which induces the usual topology on $X$ and a sequence $\{\frac{1}{n} \}$ is a cauchy sequence in the Euclidean metric , but  not converges in $X$. So $X$ is not complete withbthe usual topology admit a Euclidean metric. On the other hand The map
$$
f:(0,1)\to\mathbb{R}:x\mapsto\tan\pi\left(x-\frac{1}{2}\right)
$$
is a bijection which allows you to define the metric
$$
d(x,y)=|f(x)-f(y)|
$$
which makes $((0,1),d)$ complete. Since $f$ maps intervals to intervals then both topologies are equivalent. So Completeness is not a topological property. So this is irrelivent. I would be thankful, if some one check my representation","['complete-spaces', 'real-analysis', 'proof-verification']"
1862797,Alternate proof of the dominated convergence theorem by applying Fatou's lemma to $2g - |f_n - f|$?,"Here is a proof of the dominated convergence theorem. Theorem. Suppose that $f_n$ are measurable real-valued functions and $f_n(x) \to f(x)$ for each $x$ . Suppose there exists a nonnegative integrable function $g$ such that $|f_n(x)| \le g(x)$ for all $x$ . Then $$\lim_{n \to \infty} \int f_n\,d\mu = \int f\,d\mu.$$ Proof. Since $f_n + g \ge 0$ , by Fatou's lemma, $$\int f + \int g = \int (f + g) \le \liminf_{n \to \infty} \int (f_n + g) = \liminf_{n \to \infty} \int f_n + \int g.$$ Since $g$ is integrable, $$\int f \le \liminf_{n \to \infty} \int f_n.\tag*{$(*)$}$$ Similarly, $g - f_n \ge 0$ , so $$\int g - \int f = \int (g - f) \le \liminf_{n \to \infty} \int (g - f_n) = \int g + \liminf_{n \to \infty} \int (-f_n),$$ and hence $$-\int f \le \liminf_{n \to \infty} \int (-f_n) = -\limsup_{n \to \infty} \int f_n.$$ Therefore $$\int f \ge \limsup_{n \to \infty} \int f_n,$$ which with $(*)$ proves the theorem. $$\tag*{$\square$}$$ My question is as follows. Can we get another proof of the dominated convergence theorem by applying Fatou's lemma to $2g - |f_n - f|$ ?","['real-analysis', 'integration', 'probability', 'measure-theory', 'lebesgue-integral']"
1862809,Statistics: Testing hypothesis,"I'm not sure that I'm understanding this stuff fully so I would appreciate it if someone could check my work. QUESTION
The percentage of children who leave foster care due to adoption is generally accepted to be 15%. A social worker claims that this percent is incorrect. After performing a hypothesis test on his claim using sample data from 2009, he fails to reject the null hypothesis. According to a report by the US department of Health and Human Services, the actual percentage of children who left foster care due to adoption was 20% in 2009. Was an error made? If so, what type? MY ANSWER
Ho = p=15%
Ha = p≠15% Ho is proven to be false, but it says that the service worker doesn't reject it. Since they think the Ho is true when it isn't, this is a type 1 error.",['statistics']
1862829,What is the difference between a polynomial and a function or can they be used interchangebly?,"I have been wondering over this basic question (seems rather trivial at first sight) for a long time: What is the difference between a polynomial and function? My confusion arises form the following thoughts: We use same notions to represent both – $f(x)$ is a polynomial or function The operations are quite similar. When we write $f(a)$ in a polynomial or function $f(x)$ we replace all the $x$ s with $a$ and find value. So, polynomials and functions are quite similar. So, can they be used interchangeably?","['polynomials', 'functions', 'definition']"
1862849,Name for mappings where there is at least one y for every x,"There are names for several properties of mappings from $x$ in $X$ to $y$ in $Y$. I think we say that a mapping from X to Y is (a)... Function : there is at most one $y$ for every $x$ Injective : there is at most one $x$ for every $y$ Surjective : there is at least one $x$ for every $y$ How do we say ""there is at least one $y$ for every $x$""?","['real-analysis', 'functions']"
1862869,H is a subgroup of G and G' is a subgroup of H. Prove H is normal in G.,"Question:
Let G be a group and let G' be the subgroup of G generated by the set $S=\left \{ x^{-1}y^{-1}xy \mid x,y \in G \right \}$ $\space$ Prove that G' is normal in G. Solved $\space$ Prove that G/G' is abelian. Solved $\space$ Prove that if H is a subgroup of G and G' is a subgroup of H, then H is a normal subgroup of G. I cannot even begin to start on this question. Any hint is appreciated.",['group-theory']
1862888,"Suppose X~Y, Prove that P(X) ~ P(Y)","My attempt : I imagined that if two sets are equivalent there would exist $ f:X→Y$ that is bijective. If I conceptually create P(X) and apply the function defined for the first equivalence relation to every set in the power set one gets P(Y). Let $X = \{x_1, x_2 ,  x_3 , ...    \}$, thus $Y = \{f(x_n), \forall \quad x_n \in X, n=1,2,... \}$ Both X and Y will have power sets with $2^n$ elements. If the bijective relation from X to Y is applied to every subset in P(X) so that it is one-to-one and onto, it gives a new set B. Since X~Y, B = P(Y) End of my solution I am not convinced by my efforts, in my self-study in preparation for the fall I have found my own proofs difficult to ""buy"". Specially, my issue is showing that the operation in the function from X to Y once applied to the subsets of X (elements of P(X)) will give P(Y). PS P(.) is the operation for power set incase notation is of concern. Question source : Foundations of Mathematical Analysis, Johnsonbaugh and Pfaffenberger.","['equivalence-relations', 'elementary-set-theory']"
1862893,"Is there a meaning to the notation ""\arg \sup""?","When $f$ is a function on a set $A$, the notation: $\arg\max_{x\in A} f(x)$
denotes the set of elements of $A$ for which $f$ attains its maximum value. This set may be empty, for example, if $f(x)=x$ and $A=(0,1)$, then $f$ has no maximum on $A$, so:
$$\arg\max_{x\in (0,1)} f(x) = \emptyset$$ However, $f$ always has a supremum (that can be $\infty$ if $f$ is unbounded), so apparently we can define an ""argument-supremum"". In this case, this would be:
$$\arg\sup_{x\in (0,1)} f(x) = \{1\}$$ Can this ""arg sup"" operator be defined formally? I thought to define it in the following way: $$\arg\sup_{x\in A} f(x) = \arg \max_{x\in \text{closure}(A)}f(x)$$ Is this definition meaningful? Is it used anywhere in mathematics?","['supremum-and-infimum', 'real-analysis', 'notation', 'definition']"
1862896,Action of $\mathbb{Z}/3\mathbb{Z}$ on $P^{1}$,"I am reading from the book Topics in Galois theory by Serre.
I have the following question , take $G=\mathbb{Z}/3\mathbb{Z}$. The group $G$ acts on $P^1$ by 
$$\sigma x\;=\;1/(1-x)$$
where $\sigma$ is generator of $G$. Am I interpreting this action correctly. I am thinking of it as following, think $P^1$ as extended complex plane and think x as a complex number. I am not able to interpret this action geometrically thinking of $P^1$ as set of lines. If we write $T=x+ \sigma x + \sigma^{2} x$. How $T$ gives a map $Y=P^1\rightarrow P^1/G$.","['algebraic-topology', 'algebraic-curves', 'algebraic-geometry']"
1862918,Prove that $\sum_{k=0}^n \binom{3n-k}{2n}=\binom{3n+1}{n}$,Prove that $$\sum_{k=0}^n \binom{3n-k}{2n}=\binom{3n+1}{n}$$ I've tried multiple things that didn't work. Maybe this would help $$\sum_{k=0}^n \binom{3n-k}{2n}=\sum_{k=0}^n \binom{3n-(n-k)}{2n}=\sum_{k=0}^n \binom{2n+k}{2n}$$,"['combinatorics', 'summation', 'binomial-coefficients']"
1862935,finite polynomials satisfy $|f(x)|\le 2^x$,"This is a problem from TsingHua University math competition for high school students. Prove there exists only finite number of polynomials $f\in \mathbb{Z}[x]$ such that for any $x\in \mathbb{N}$ , $|f(x)|\le 2^x$. My attempts: since $f(x)=o(2^x)$, $f$ can only be bounded when $x$ is small, for example $f(0)=0,1, \ \ f(1)=0,1,2, \cdot \cdot \cdot$. Thus using Lagrange interpolation it concludes that for any given $n\in \mathbb{N}$ the number for such polynomial is finite. But I don't know how to proceed from here. Is my methods wrong or there's a better way? Also, I'd like to know something about the background of this problem. Thanks in advance.","['nonlinear-optimization', 'contest-math', 'real-analysis', 'polynomials']"
1862981,Winding number of a polynomial,"Consider $f(z) = c_n z^n + ... + c_1 z + c_0$, where $c_n\ne 0$. Let $C_R$ be the circle of radius $R$ centred at the origin, oriented counterclockwise. Prove that the winding number of $f\circ C_R =n $ for $R$ sufficiently large. My approach: Parametrize $C_R$ as $\gamma(t) = Re^{it}$. Then
$$\frac{1}{2\pi i}\int_{C_R} \frac{f'(z)}{f(z)}dz=\frac{1}{2\pi i}\int\limits_0^{2\pi} \frac{f'(\gamma(t))\gamma'(t)}{f(\gamma(t))}dt$$
$$=\frac{1}{2\pi }\int\limits_0^{2\pi} \frac{nc_n (Re^{it})^n + ... + c_1 Re^{it}}{c_n (Re^{it})^n+...+c_1Re^{it}+c_0}dt$$ I thought I got stuck here, but now I'm thinking: maybe I should take the limit as $R\to \infty$ of the integral above, take the limit in the integral (since the limit is not in terms of $t$), and then observe that the integrand becomes $ndt$, and so the integral comes to $\frac{2\pi n}{2\pi}=n$?
Would this approach be correct? I think so, because $R$ should go to infinity in order to encompass all possibilities for all zeros of $f(z)$.","['complex-analysis', 'winding-number', 'contour-integration']"
1862995,Why should I learn modern category theory if my interest mainly is structured sets?,"A long time ago I studied mathematics at the University of Stockholm. I had a romantic view of modern algebra and manage to make the first two algebra courses by self studies in order to immediately study homological algebra, Galois theory and such topics. That is not the best way to study. Later as a graduate student I did rather well - until the gaps in my basic knowledge and abilities began to affect too much. Then I stopped focusing on mathematics about 35 years ago. I did self studies in category theory because we were supposed to do that and because it was a good idea. Category theory worked fine with the mathematics evolved at 1950 or so. The universal definitions and duality simplified a lot of mathematics as tensor products and injective/projective modules etc and the functors opened new possibilities. The last 40 years or so the interest in and the development of category theory has exploded and seems nowaday be very abstract but also very consistent. My question is, what modern category theory could be    interesting for a person mainly interested in the mathematics concerning structured sets? The bounty will soon expire and there is 50+ in reputation to earn - aren't there anything to express on this topic?","['category-theory', 'abstract-algebra', 'soft-question', 'big-picture']"
1863006,What is the correct definition of a group?,"What is the correct definition of a group? More precisely the predicate ""being a group""? According to Wikipedia A group is a set, G, together with an operation • (called the group law of G) that... How should one interpret this? $\textbf{Definition A)}\\
\quad \quad G \text{ is a set},\\
\quad \quad +:G\times G\to G \\
\langle G,+\rangle \text{ is a group} :\iff\\
\quad \quad +\text{ is asscociative},\\
\quad \quad \exists 0\in G : \forall x\in G:x+0=0+x=x \text{ and } \exists y:x+y=y+x=0 $ or $\textbf{Definition B)}\\
\quad \quad G \text{ is a set}\\
G \text{ is a group} :\iff\\
\quad \quad \exists +:G\times G\to G:\\
\quad \quad \quad +\text{ is asscociative},\\
\quad \quad \quad \exists 0\in G : \\
\quad \quad \quad \quad\forall x\in G:x+0=0+x=x \text{ and } \exists y:x+y=y+x=0 $ And is there a separate notion of ""$G$ being a group with operation $+$""?","['logic', 'group-theory']"
1863015,Prime Number Theorem and the Riemann Zeta Function,"Let
$$\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}$$
be the Riemann zeta function. The fact that we can analytically extend this to all of $\mathbb{C}$ and can find a zero free region to the left of the line $Re(s)=1$ shows that 
$$\pi(x) := |\{p\leq x: p \mbox{ prime }\}| \sim \frac{x}{\log(x)}.$$
Moreover, improving the zero free region improves the error term on $\pi(x)$ with the Riemann hypothesis giving us the best possible error term. However, there are elementary proofs for this fact about $\pi(x)$ which does not rely on using $\zeta(s)$. My question is, just using the knowledge that
$$\pi(x) = \frac{x}{\log(x)} + ET$$
for some error term I call $ET$, can you show that $\zeta(s)$ can be analytically continued with a zero free region to the left of the line $Re(s)=1$, where this region depends on $ET$. For example, if you assume that $ET = x^{1-\epsilon}$ for some $\epsilon>0$, then can you show that $\zeta(s)$ can be analytically continued to the region $Re(s) > 1-\epsilon$ and that $\zeta(s)$ has no zeros in this region? Any solution or reference would be greatly appreciated.","['number-theory', 'riemann-zeta', 'prime-numbers']"
1863017,The expected distortion of a linear transformation (continued),"Let $A: \mathbb{R}^n \to \mathbb{R}^n$ be a linear transformation. I am interested in the ""average distortion"" caused by the action of $A$ on vectors. Consider the uniform distribution on $\mathbb{S}^{n-1}$, and the random variable $X:\mathbb{S}^{n-1} \to \mathbb{R}$ defined by $X(x)=\|A(x)\|_2$. Question: What is the expectation of $X$? (Is there a closed formula?) Using SVD, the problem reduces to $A$ being a diagonal matrix with non-negative entries. So, the question amounts to calculating $$\int_{\mathbb{S}^{n-1}} \sqrt{\sum_{i=1}^n (\sigma_ix_i)^2} $$ (and dividing by the volume of $\mathbb{S}^{n-1}$). This question is related to these two , which ask about the expected distortion of the square of the norm (which is easier, since no square roots are involved). For the above problems, a successful approach was to use standard normal variables, in order to generate a unit random vector (see here ). However, it does not seem to help in this case.","['matrices', 'probability', 'linear-algebra', 'random-variables']"
1863032,Help understanding convolutions for probability?,"I have been trying to do some problems in probability that use convolutions but there has not been much of an explanation of what a convolution is or the purpose of using a convolution. For example in the following problem: Let X and Y be two independent exponential distributions with mean $1$ . Find the distribution of $\frac{X}{Y}$ . So I define $U=\frac{X}{Y}$ and $V=Y$ then $$f_U(u)=\int_{-\infty}^{\infty}f_{XY}(uv,v)dv=\int_{0}^{\infty}e^{-uv}e^{-v}dv=\frac{1}{u+1}$$ Maybe one could explain a simpler problem: Let X and Y be two random variables with joint density function $f_{XY}$ .
Compute the pdf of $U = Y − X$ .  So I tried the following and maybe its correct I dont know just using formulas $$f_U(u)=\int_{-\infty}^{\infty}f_{XY}(x,u+x)dx=\int_{-\infty}^{\infty}f_{XY}(y-u,y)dy$$ I was given the formula $(f*g)(z)=\int_{-\infty}^{\infty}f(z-y)g(y)dy=\int_{-\infty}^{\infty}f(x)g(z-x)dx$ I do not fully understand what I am supposed to be putting into $f(z-y)g(y)$ part of the integrals specifically for $(z-y)$ .","['probability-theory', 'probability', 'statistics', 'probability-distributions']"
1863035,Difference between Ordering and Order?,"I am confused by the two terms order and ordering . I am learning on Ideals, Varieties and Algorithms by Cox et all. The context is monomial orderings and Gröbner basis on polynomial rings. How are the terms ordering and order different? Are they synonyms?","['terminology', 'algebraic-geometry', 'order-theory']"
1863112,The number of primitive Pythagorean triangles with bounded hypotenuses,"I was reading the ""mathematical constants"" book. At some point, it said that Lehmer proved the following theorem in 1900. $$\lim_{n \rightarrow \infty} \frac{P_h(n)}{n}=\frac{1}{2\pi}$$ $$\lim_{n \rightarrow \infty} \frac{P_p(n)}{n}=\frac{\ln2}{\pi^2}$$ where $P_h(n), P_p(n)$ are the number of primitive Pythagorean triangles whose hypotenuses and perimeter do not exceed $n$ , respectively. Is there any simple proof for those beautiful results?","['analytic-number-theory', 'number-theory', 'pi', 'geometry', 'pythagorean-triples']"
1863129,The relationship between tan(x) and square roots,"Please note: I am working in DEGREES I think the easiest way to illustrate my point is by showing some examples: $ \tan(0^\circ) = \sqrt 0 = 0$ $ \tan(22.5^\circ) = \sqrt 2 -1$ $ 3 \cdot \tan(30 ^\circ) =\sqrt 3$ $ \tan(45 ^\circ) =\sqrt 1 = 1$ $ \tan(60 ^\circ) =\sqrt 3$ $ \tan(75 ^\circ) = 2 + \sqrt 3$ Ok, so there are some nice examples that have whole numbers, but then there are some that are less ""pretty"": $ \tan(54.73561... ^\circ) = \sqrt 2$ $ \tan(65.90515... ^\circ) = \sqrt 5$ ... and so on ... These aren't very impressive, because once can easily generate these irrational numbers in order to get the square root of something by simply using the arctan(x) function. (arctan($\sqrt 2$) = 54.73561... Let's look at this useless equation: $ \tan( \arctan(\sqrt x)) = \sqrt x$ * SHOCKER * So, I was wondering, is there possibly a way to represent this without using arctan($\sqrt x$) by the use of an infinite series - for example: $ \tan(\sum_{n=0}^\infty $ something in terms of x ) = $\sqrt x$ I look forward to any answers or responses I may get :) Kind regards Joshua :) EDIT: An interesting ""discovery"" (not really) I'm putting ""discovery"" in inverted commas because I am fairly certain that I am not the first to find this, but I haven't been able to find it on the internet (that I have searched). \begin{align}
\sqrt{3} & =  \frac{\sum_{n=0}^\infty \frac{(-1)^n (\frac{\pi}{3})^{2n+1}}{(2n+1)!}}{\sum_{n=0}^\infty \frac{(-1)^n (\frac{\pi}{3})^{2n}}{(2n)!}} \\
\end{align} Now notice that $\sqrt3$ = infinite sum (THAT CONTAINS $\frac{\pi}{3}$) (The transcendental number pi divided by 3, which is the number we started with) - I do not mind having $\pi$, $e$ or $\phi$ in the infinite sum, as these are transcendental numbers. However, I would like to avoid non-transcendental numbers such as $\sqrt 2$, etc. Let me simplify a bit more:
The bottom infinite sum converges to 0.5 \begin{align}
\sqrt{3} & =  \frac{\sum_{n=0}^\infty \frac{(-1)^n (\frac{\pi}{3})^{2n+1}}{(2n+1)!}}{0.5} \\
& = 2\sum_{n=0}^\infty \frac{(-1)^n (\frac{\pi}{3})^{2n+1}}{(2n+1)!}
\end{align} Now all you observant people would notice that the equation can be written as $$\frac{\sqrt{3}}{2} = \sum_{n=0}^\infty \frac{(-1)^n (\frac{\pi}{3})^{2n+1}}{(2n+1)!} = sin(60^\circ)
$$ And
\begin{align}
\sqrt{3} & =  \frac{sin(60^\circ)}{cos(60^\circ)} = tan(60^\circ)\\
\end{align} Maybe this helps someone work it out a little bit further :)","['trigonometry', 'sequences-and-series', 'irrational-numbers']"
1863146,Power Series in Two Variables and Radius of Convergence,"Let $\alpha > 0$, $\beta > 0$, and assume that the power series with real coefficients
\begin{equation}
\sum_{n,m = 0}^{\infty} a_{n,m} x^{n} y^{m}
\end{equation}
is absolutely convergent for every real $x, y$ such that $|x| < \alpha$, $|y| < \beta$. Then you can rearrange the terms of the series in ascending powers of $x$ as
\begin{equation}
\sum_{n = 0}^{\infty} f_n(y) x^{n},
\end{equation}
where the function $f_n:(-\beta,\beta) \rightarrow \mathbb{R}$ are analytic functions. For every fixed $y \in (-\beta,\beta)$, let $R(y)$ be tha radius of convergence of the series in $x$
\begin{equation}
\sum_{n = 0}^{\infty} f_n(y) x^{n}.
\end{equation}
Is $R$ a continuous function of $y$?
I guess that, generally speaking, the answer is negative, but I have no counterexample.","['power-series', 'real-analysis', 'sequences-and-series', 'analysis']"
1863151,Proof related to the least squares method,"I've seen this exercise in several statistics text, but how they get to the final formula is something that I don't quite get. How do two squared terms suddenly become a binomial term? I've been trying to figure out how to get to the final formula but I don't get anywhere near. Hope you can help me.","['statistics', 'sequences-and-series', 'least-squares']"
1863176,The relation between axes of 3D rotations,"Let's suppose we have two rotations about two different axes represented by vectors $v_1$ and $v_2$:
$R_1(v_1, \theta_1)$, $R_2(v_2,\theta_2)$. It's relatively easy to prove that composition of these two rotations gives rotation about axis $v_3$ distinct from axes $v_1$ and $v_2$ . Indeed if for example $v_3=v_1$ then $R_1(v_1, \theta_1) R_2(v_2,\theta_2)=R_3(v_1,\theta_3)$ leads to $R_2(v_2,\theta_2)=R_1^T(v_1, \theta_1)R_3(v_1,\theta_3)=R(v_1,\theta_3 -\theta_1)$ what gives $v_1=v_2$. ... Contradiction... We see that composition of two rotations about different axes always generates a new axis of rotation. The problem can be extended for condition of the plane generated by the axes. Question: Is it true that composition of two rotations generates the axis which
  doesn't belong to the plane   which is constructed by the original axes of rotations ? How to prove it ? If the statement is not however true what are conditions for not changing a plane during the composition of rotations $ ^{[1]}$ ? $ ^{[1]}$ It can be observed that even in the case of quite regular rotations the above statement is true Let's take $Rot(z,\dfrac{\pi}{2})Rot(x,\dfrac{\pi}{2})= \begin{bmatrix}
0 & -1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 1 \\
\end{bmatrix} \begin{bmatrix}
1 & 0 & 0 \\
0 & 0 & -1 \\
0 & 1 & 0 \\
\end{bmatrix} = \begin{bmatrix}
0 & 0 & 1 \\
1 & 0 & 0 \\
0 & 1 & 0 \\
\end{bmatrix} = Rot([1,1,1]^T, \dfrac{2}{3}\pi)$ or $Rot(x,  \pi  )Rot(z,  \pi  )= \begin{bmatrix}
1 & 0 & 0 \\
0 & -1 & 0 \\
0 & 0 & -1 \\
\end{bmatrix} \begin{bmatrix}
-1 & 0 & 0 \\
0 & -1 & 0 \\
0 & 0 & 1 \\
\end{bmatrix} = \begin{bmatrix}
-1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & -1 \\
\end{bmatrix} = Rot( y, \pi)$ So I suppose it is generally true but how to prove it ?","['matrices', 'rotations', 'linear-algebra']"
1863178,Represent $\dfrac{\lambda_1^M-\lambda_2^M}{\lambda_1-\lambda_2}$ in terms of $\lambda_1+\lambda_2$ and $\lambda_1\lambda_2$,"I have a problem as follows: Let $\lambda_1, \lambda_2$ are roots of the equation $\lambda^2-a\lambda+b=0.$ It can be proved easily (by induction for example) that the quantity $$\dfrac{\lambda_1^M-\lambda_2^M}{\lambda_1-\lambda_2}$$ is a polynomial $P_M$ in $a,b$. My question is: Can we write down a precise formula for $P_M$?
I found a recursive formula for $P_M$'s which reads $$P_{M+1}=aP_M-bP_{M-1},$$ however it seems to be not enough to answer my question. Any hint or idea is appreciated. Thanks a lot!","['algebra-precalculus', 'polynomials', 'analysis']"
1863179,"How to find number of integral solutions, containing large number of cases?","Number of positive unequal integral solutions of the equation $x+y+z=12$ can be found out knowing the cases it involves: $(1, 2, 9) , (1,3,8), (1,4,7), (1,5,6), (2,3,7), (2,4,6) and (3,4,5)$. Thus, the number of positive integral solutions of the above equation = $7×3! = 42$. Now suppose the equation is like this: $a+b+c+d+e=99$. In this equation if we follow the above followed method then it'll take me decades to find out all the cases. What should be my approach now in order to find out the number of solutions?","['permutations', 'combinatorics', 'binomial-coefficients', 'combinations']"
1863184,Differentiating the binomial coefficient,"I took a lecture in combinatorics this semester and the professor did the following step in a proof: 
He showed that function $f: x \mapsto \binom{x}{r}$ is convex for $x > r - 1$ (in order to use Jensen's inequality on $f$) and did this in the following way: ""By the product-rule we have $$f''(x) = \frac{2}{r!} \sum_{0 \leq i < j \leq r - 1} \prod_{l = 0}^{r - 1} ( x - l) \frac{1}{(x - i ) (x - j)} \geq 0$$ for all $ x > r - 1$."" I am a bit confused on his definition: How would one extend the binomial coefficient to $x \notin \mathbf{N}$? I first thought about piecewise linear interpolation, but then I can't differentiate it. I also thought of plugging in the Gamma-function for the factorials, but I doubt that this is the definition he used here. Can anyone explain to me what's happening here? Thanks!","['derivatives', 'combinatorics', 'real-analysis', 'binomial-coefficients']"
1863192,integrate $\int \frac{x^4-16}{x^3+4x^2+8x}dx$,$$\int \frac{x^4-16}{x^3+4x^2+8x}dx$$ So I first started with be dividing $p(x)$ with $q(x)$ and got: $$\int x-4+\frac{8x^2+32x-16}{x^3+4x^2+8x}dx=\frac{x^2}{2}-4x+\int \frac{8x^2+32x-16}{x^3+4x^2+8x}dx$$ Using partial sum I have received: $$\int \frac{8x^2+32x-16}{x^3+4x^2+8x}dx=8\int -\frac{1}{4x}+\frac{5x}{4(x^2+4x+8)}+\frac{5}{x^2+4x+8} dx=-2ln|x|+8(\frac{5}{4}\int\frac{x}{(x^2+4x+8)} +5\int \frac{1}{x^2+4x+8})=-2ln|x| +10\int\frac{x}{(x^2+4x+8)}dx +40\int \frac{1}{x^2+4x+8}dx$$ How do I continue from here?,"['indefinite-integrals', 'integration']"
1863227,Finding integer solutions to $y^2=x^3-2$,"I have the equation:
$$y^2=x^3-2$$
It seems to be deceivingly simple, yet I simply cannot crack it. It is obviously equivalent to finding a perfect cube that is two more than a perfect square, and a brute force check shows no solutions other than $y=5$ and $x=3$ under 10,000. 
However, I can't prove it. Are there other integer solutions to this equation? If so, how many? If not, can you prove that there aren't? Bonus: What about the more general equation""
$$y^2=x^3-c$$
Where $c$ is a positive integer?","['number-theory', 'elliptic-curves', 'diophantine-equations']"
1863239,"If $f$ is a smooth real valued function on real line such that $f'(0)=1$ and $|f^{(n)} (x)|$ is uniformly bounded by $1$ , then $f(x)=\sin x$?","Let $f : \mathbb R \to \mathbb R$ be a smooth ( infinitely differentiable everywhere ) function such that $f '(0)=1$ and $|f^{(n)} (x)| \le 1 , \forall x \in \mathbb R , \forall n \ge 0$ ( as usual denoting $f^{(0)}(x):=f(x)$) ; then is it true that $f(x)=\sin x , \forall x \in \mathbb R$ ?","['complex-analysis', 'real-analysis', 'calculus', 'harmonic-analysis']"
1863260,Difficult looking summation problem,"$$\sum_{n=1}^{\infty} \omega(n)(x^n - 2x^{2n} + (-x)^n) = \frac{2x^2}{1-x^4} $$
Where $\omega(n)$ is the number of prime factors of $n$ and $\vert x \vert < 1$","['number-theory', 'summation']"
1863266,Prove that $\overline{f(z)}$ is differentiable at $a \in D(0;1)$ if and only if $f'(a)=0$,"Let $f$ be holomorphic in $D(0;1)$ and define $k$ by $k(z)=\overline{f(z)}$. Prove that $k$ is differentiable at $a\in D(0;1)$ if and only if $f'(a)=0$. What I tried was first, assuming $k$ is differentiable and letting $f=u+iv$ we have (first when $h \in \mathbb{R}$) $$k'(z)= \lim_{h \to 0} \frac{u(x+h,y)-u(x,y)}{h} -i\frac{v(x+h,y)-v(x,y)}{h} = u_x -iv_x$$
and when $h=ik, \ k\in \mathbb{R}$ $$k'(z)=\lim_{k \to 0} \frac{u(x,y+k)-u(x,y)}{ik} -\frac{v(x,y+k)-v(x,y)}{h} = \frac{1}{i}u_y -v_y$$ And equating real and imaginary parts, we get that $$u_x=-v_y, \; u_y=v_x$$
Since $f$ is holomorphic, it satisfies the Cauchy-Riemann equations and thus $$u_x=v_y, \; u_y=-v_x$$
so
$$f'(a)=-f'(a)$$
and then $f'(a)=0$. I don't know if this works, so please correct me if I'm wrong. Besides that, I'm stuck in proving the other implication. So far I did $$0=f'(a)=\lim_{h\to 0} \frac{f(a+h)-f(h)}{h}=\overline{\lim_{h\to 0}\frac{f(a+h)-f(h)}{h}}=\lim_{h\to 0}\frac{\overline{f(a+h)} -\overline{f(h)}}{\overline{h}}=\overline{f'(a)}=k'(a)$$ But again, I'm not sure if this is right. Any help will be highly appreciate, and thanks in advance!","['derivatives', 'complex-analysis']"
1863270,Contiuous function on a closed bounded interval is uniformly continuous. Don't understand the proof.,"I'm self studying real analysis from Wade's ""An Introduction to Real Analysis"" and I've come across a proof that I don't understand. I was hoping that some might be able to walk me through it. The theorem is as follows Theorem. Suppose that $I$ is a closed, bounded interval. If $f:\rightarrow\mathbb{R}$ is continuous on $I$, then $f$ is uniformly continuous on $I$. Proof. Suppose to the contrary that $f$ is continuous but not uniformly continuous on $I$. Then there is an $\varepsilon_0>0$ and points $x_n, y_n \in I$ such that $|x_n-y_n|<\frac{1}{n}$ and $$|f(x_n)-f(y_n)|\geq \varepsilon_0\;\;\;\;n\in\mathbb{N}$$ By the Bolzano-Weierstrass Theorem and the Comparison Theorem the sequence $\{x_n\}$ has a subsequence, say $x_{n_k}$, which converges as $k\rightarrow\infty$, to some $x \in I$. Similarly the sequence $\{y_{n_k}\}_{k\in\mathbb{N}}$ has a convergent subsequence say $y_{n_{k_j}}$, which converges as $j\rightarrow \infty$, to some $y \in I$. Since $x_{n_{k_j}} \rightarrow x$ as $j\rightarrow \infty$ and $f$ is continuous it follows from above that $|f(x)-f(y)|\geq \varepsilon_0$; that is $f(x)\neq f(y)$. But $|x_n-y_n|<\frac{1}{n}$ for all $n \in \mathbb{N}$ so the Squeeze Theorem implies $x=y$. Therefore,  $f(x)=f(y)$, a contradiction. Why in this proof do we need to take a sub-subsequence, why wont subsequences suffice? I have seen slightly different proofs of this theorem which use only subsequences and the triangle inequality. If someone could help me I would be most grateful.",['real-analysis']
1863287,Conjectured value of $\int_{0}^{\infty}\left(\frac{x-1}{\ln^2 x}-\frac{1}{\ln x}\right)\frac{\mathrm{d}x}{x^2+1}$,"I was curious whether this integral has a closed form expression : $$\int_{0}^{\infty}\left(\frac{x-1}{\ln^2 x}-\frac{1}{\ln
 x}\right)\frac{\mathrm{d}x}{x^2+1}$$ The integrand has a singularity at $x=1$, but it's removable.  And as $x \to \infty$, the integrand behaves like $\frac{1}{x \ln^{2}x}$. So the integral clearly converges. Although I have not been able to derive its closed form, I think, by reverse symbolic calculators, up to 20 digits it could be $$I=\frac{4G}{\pi}$$ where $G$ is Catalan's constant. Is it true or is it completely fabulous? EDIT. NOTE : For better search to this integral I have renamed the title from Conjectured value of logarithmic definite integral , which is ambiguous and did not say anything, to the current one with integral explicitly written.","['integration', 'definite-integrals']"
1863302,What is $f_!$ in the context of commutative rings?,"Given a morphism of schemes $f:X \to Y$ there is a functor $f_!:Sh(X) \to Sh(Y)$ where
$$
f_!\mathcal{F}(U) = \{ s \in \mathcal{F}(f^{-1}(U)) : f:\text{supp}(s) \to U \text{ is proper} \}
$$
How do I repackage this in the setting of commutative rings? I know that $f_*:\text{Mod}(S) \to \text{Mod}(R)$ is just composition of the $S$-action with the morphism $f:R \to S$, but I'm not sure how to interpret the support and properness in this setting.","['algebraic-geometry', 'commutative-algebra']"
1863305,Area of circle (double integral and cartesian coordinates)?,"I know that the area of a circle, $x^2+y^2=a^2$, in cylindrical coordinates is
$$
\int\limits_{0}^{2\pi} \int\limits_{0}^{a} r \, dr \, d\theta = \pi a^2
$$ But how can find the same result with a double integral and only cartesian coordinates?","['multivariable-calculus', 'integration', 'calculus']"
1863314,When is the universal cover of a Riemannian manifold complete?,"Let $(M,g)$ be a connected Riemannian manifold which admits a universal cover $(\tilde{M}, \tilde{g})$, where $\tilde{g}$ is the Riemannian metric such that the covering is a Riemannian covering. I want to know under what conditions the universal cover $\tilde{M}$ is complete. The reason for this questions is that I want to know under what conditions on $M$ the Hopf-Rinow theorem can be applied to the universal cover. On Wolfram ( http://mathworld.wolfram.com/CompleteRiemannianMetric.html ) it says that if $M$ is compact, its universal cover is complete. Would someone be able to give a proof of this? And what deductions can we make if $M$ is complete (and possibly fulfills some other conditions)? (I'm not really looking for curvature conditions like corollaries of the Bonnet-Myers theorem). Thanks in advance for any help!","['riemannian-geometry', 'complete-spaces', 'covering-spaces', 'smooth-manifolds', 'differential-geometry']"
1863337,"How to integrate $\int \frac{1}{\sin^4 x \cos^4 x}\,dx$?","The integral in question is: $$\int \dfrac{1}{\sin^4 x \cos^4 x} dx$$ I tried using $1 = \sin^2 x + \cos^2 x$, but it takes me nowhere. Another try was converting it into $\sec$ and $\csc$, but some factors of cosec always remained when I substituted $\sec x$ as t. Please give a pointer to where I should proceed. Thank you!","['integration', 'trigonometry', 'trigonometric-integrals']"
1863341,"If $f(x)$ has a vertical asymptote, does $f'(x)$ have one too?","So here is what I understand: If $f(x)$ is increasing/decreasing , then its derivative $f'(x)$ is positive/negative and... If $f(x)$ is increasing/decreasing , then the derivative of $f'(x)$ (which is $f''(x)$) is concave up/concave down So my question is: if a graph has a vertical asymptote, the derivative must also have a vertical asymptote, too, right? Does it also work vice versa ? I feel like there is a trick to it, but I'm not sure. I have a graph from GeoGebra here . The dotted line is the derivative.","['derivatives', 'calculus', 'functions']"
1863342,Why all vector space have a span set?,"I thought about this question, but I don't sure if my proof is correct. In the book, he put this question like a observation of span sets' definition, so I tried proof this. My attempt: Suppose that exists a vector space $V$ such that there isn't a span set $S = \{ v_1, v_2, \ldots, v_n \}$, so exists a $v_{n+1} \in V$ such that $v_{n+1} \neq \sum_{i=1}^{i=n} v_i$, so $S \cup \{ v_{n+1} \}$ can be a span set of $V$, but can be exists $v_{n+2} \in V$ such that $v_{n+2} \neq \sum_{i=1}^{i=n+1},  v_i$, so $S \cup \{ v_{n+1}, v_{n+2} \}$ can be a span set of $V$ and we can be in this cycle infinitely. My doubt is what ensures that doesn't exists infinitely many vectors that can be span by a span set?","['linear-algebra', 'proof-verification']"
1863364,Why isn't the gradient vector of a parametric curve parallel to the tangent vector?,"Consider a parametric curve defined by the equation: $$\mathbf{r}(t) = X(t)\mathbf{\hat{i}} + Y(t)\mathbf{\hat{j}} + Z(t)\mathbf{\hat{k}}$$ Paul's online math notes indicate that the unit tangent vector to such a curve is defined by: $$\mathbf{T}(t) = \frac{\mathbf{r}'(t)}{|\mathbf{r}'(t)|}$$ More importantly, $\mathbf{r}'(t)$ is a tangent vector. Now let's consider a scenario wherein a thin, insulated wire follows the path $\mathbf{r}(t)$ between two arbitrary end points with some boundary conditions applied. The wire will attain some temperature distribution $T=T(x,y,z)=T(t)$. My intuition tells me (and I hope everyone will agree) that the temperature gradient at any point along the wire should be a vector tangent to the wire, i.e.: $$\mathbf{\nabla}T \propto \mathbf{r}'(t)$$ Now I want to confirm my intuition. I'll start with the definition of the gradient vector in Cartesian co-oridinates: $$ \mathbf{\nabla} = \frac{\partial}{\partial x}\mathbf{\hat{i}} + \frac{\partial}{\partial y}\mathbf{\hat{j}} + \frac{\partial}{\partial z}\mathbf{\hat{k}} $$ Using the chain rule I can re-write each of the derivative operators in terms of $t$: \begin{align}
\mathbf{\nabla} &= \frac{\partial t}{\partial x}\frac{\partial}{\partial t}\mathbf{\hat{i}} + \frac{\partial t}{\partial y}\frac{\partial}{\partial t}\mathbf{\hat{j}} + \frac{\partial t}{\partial z}\frac{\partial}{\partial t}\mathbf{\hat{k}} \\
\mathbf{\nabla} &= \left(\frac{\partial t}{\partial x}\mathbf{\hat{i}} + \frac{\partial t}{\partial y}\mathbf{\hat{j}} + \frac{\partial t}{\partial z}\mathbf{\hat{k}}\right) \frac{\partial}{\partial t} \\
\mathbf{\nabla} &= \left(\frac{1}{X'(t)}\mathbf{\hat{i}} + \frac{1}{Y'(t)}\mathbf{\hat{j}} + \frac{1}{Z'(t)}\mathbf{\hat{k}}\right) \frac{\partial}{\partial t}
\end{align} The vector in the above equation should be parallel to $\mathbf{r}'(t)$. I can test this by checking the cross product of these two vectors (should be $\mathbf{0}$ if they are parallel): \begin{align}
\left(\frac{1}{X'(t)}\mathbf{\hat{i}} + \frac{1}{Y'(t)}\mathbf{\hat{j}} + \frac{1}{Z'(t)}\mathbf{\hat{k}}\right) \times \left( X(t)\mathbf{\hat{i}} + Y(t)\mathbf{\hat{j}} + Z(t)\mathbf{\hat{k}} \right) \\
= \left( \frac{Z'}{Y'} - \frac{Y'}{Z'} \right)\mathbf{\hat{i}} + 
\left( \frac{X'}{Z'} - \frac{Z'}{X'} \right)\mathbf{\hat{j}} +
\left( \frac{Y'}{X'} - \frac{X'}{Y'} \right)\mathbf{\hat{k}}
\end{align} So it appears these vectors are parallel only when $X'^2 = Y'^2 = Z'^2$, which seems like a really unlikely restriction. What's wrong here: my intuition, my math, or both? Also please keep in mind what I'm really interested in is the correct transformation of the gradient operator. This question is just the most concise way to explain what I'm struggling with. I realize that similar questions on this topic have been asked previously: characteristic curves tangent and gradient Gradient vector of parametric curve This may seem like a duplicate of one of those, but from what I understand about those questions neither of them address the case where the shape of the domain is confined to a parametric curve , which is the focus here.","['multivariable-calculus', 'parametric', 'vector-analysis']"
1863379,How to complete Vakil's proof that the composition of projective morphisms are projective when the target is quasicompact?,"For this question, a morphism $\pi : X \rightarrow Y$ is projective iff there exists a finite type quasicoherent sheaf $\mathcal{E}$ on $Y$ such that $X$ is isomorphic (as a $Y-$scheme) to a closed subscheme of $\mathbb{P}(\mathcal{E})$. I am interested in finding a way to solve this problem as it is presented in Vakil, and not in solving it using completly different methods (such as can be found in e.g. EGA II $5.5.5$, or Stacks Tag $01W7$, although under the additional assumptions that $Y$ is either quasi-separated or Noetherian). In exercise 17.3.B of Vakil's ""Foundations of Algebraic Geometry"" notes, he asks to show that if $\pi : X\rightarrow Y$ and $\rho : Y \rightarrow Z$ are projective morphisms and $Z$ is quasi-compact, then $\rho \circ \pi$ is also projective. The hint he gives is to show that in the case where $Z$ is affine, if $\mathcal{L}, \mathcal{M}$ are the very ample line bundles on $X,Y$ coming from pulling back the respective $\mathcal{O}(1)$ bundles from the projective bundles $X$ and $Y$ are closed subschemes of, then there is some $m$ such that $\mathcal{L}\otimes \pi^*(\mathcal{M})^{\otimes m}$ is $\rho\circ \pi-$very ample. He then suggests using that $Z$ is quasicompact to cover it by finitely many open affine pieces, but I can't work out how to use this to prove the result. My first instinct would be to glue together the morphisms constructed over each affine piece, or to extend the construction globally, but in this case neither approach works. I can see that covering $Z$ by finitely many affine pieces $U_i$ allows us to find a fixed $m$ such that $\mathcal{L}\otimes \pi^*(\mathcal{M})^{\otimes m}$ is $\rho \circ \pi-$relatively very ample upon restriction to each $(\rho \circ \pi)^{-1}(U_i)$, but I don't understand how to use this to show that it is globally $\rho \circ \pi-$relatively very ample. Vakil does mention several times (and later proves) that with locally Noetherian hypotheses, the property of a line bundle on the source being relatively very ample can be checked affine-locally on the target, which would finish the proof if $Z$ was Noetherian, but this isn't part of the hypothesis of $17.3.B$. My question then, is this: Is it possible to finish this approach to the exercise, perhaps by showing that $\mathcal{L}\otimes \pi^*(\mathcal{M})^{\otimes m}$ is $\rho \circ \pi-$relatively very ample globally given that it is locally? Or is it really the case that you need to either assume that $Z$ is Noetherian, or take a completely different approach to the proof (such as characterising projective morphisms to quasicompact schemes as those that or both quasiprojective and proper)?","['projective-geometry', 'algebraic-geometry', 'projective-schemes']"
1863390,Decompose a matrix into diagonal term and low-rank approximation,"For a matrix $A$ the Singular Values Decomposition allows getting the closest low-rank approximation $$A_K=\sum_i^K\sigma_i \vec{v}_i \vec{u}_i^T$$ so that $\|A-A_k\|_F$ is minimal. I'd like to do the same but allow for an additional diagonal term; that is, for a given square matrix $A$ and an positive integer $K$ find a diagonal matrix $D$ and low-rank approximation  $$A_K=D+\sum_i^K\sigma_i \vec{v}_i \vec{u}_i^T$$ so that like above $\|A-A_k\|_F$ is minimal. The problem originated in the context of correlations matrices. Thus answers which further assume $A$ is symmetric, positive semi-definite are also welcome.","['matrices', 'svd', 'matrix-decomposition']"
1863392,How do I find the derivative of $(1 +1/x)^x $,"I tried one approach but the correction in the book shows me a total different answer. Here's what I did: $(1+ 1/x)^x=xln(1+1/x)$
Thus, now we try to find the derivative of a multiplication: $ u(x)=x$ $(u(x))'=1$ $v(x)=ln(1+1/x)$ $(v(x))'= -1/(x^2) +1/x$ And so: $(uv)'=u'v+uv'$
which gives us: $(uv)'=xln(1 +1/x) +(-1/x^2 -1/x)$ Yet, the correction gives me this as an answer: $ln(1+1/x)-1/(1+x)$",['derivatives']
1863415,The entry-level PhD integral: $\int_0^\infty\frac{\sin 3x\sin 4x\sin5x\cos6x}{x\sin^2 x\cosh x}\ dx$,"I hope you find this integral interesting. Evaluate
  $$\int_0^\infty\frac{\sin\left(\,3x\,\right)\sin\left(\,4x\,\right)
\sin\left(\,5x\,\right)\cos\left(\,6x\,\right)}{x\,\sin^{2}\left(\,x\,\right)\cosh\left(\,x\,\right)}\,\,\mathrm{d}x\tag1$$ This problem is taken from the PhD graduate entry tests in my college. I've tried to use product-to-sum trigonometric identities
$$2\sin 4x\sin 3x=\cos x-\cos 5x$$
and
$$2\cos 6x\sin 5x=\sin 11x-\sin x$$
I got a bunch of the following form 
$$\int_0^\infty\frac{\sin \alpha x\cos \beta x}{x\sin^2 x\cosh x}\ dx\quad\Longrightarrow\quad\int_0^\infty\frac{\sin \gamma x}{x\sin^2 x\cosh x}\ dx\tag2$$
I tried
$$I'(\gamma)=\int_0^\infty\frac{\cos \gamma x}{\sin^2 x\cosh x}\ dx\tag3$$
but the latter form is not easy to evaluate either. Can anyone here help me to evaluate $(1)$? Thanks in advance.","['trigonometry', 'calculus', 'closed-form', 'integration', 'definite-integrals']"
1863425,"I am confused by the statement ""the null space of A is a nontrivial""","Correct me if I'm wrong but if a null space of a matrix A is nontrivial would it be correct to say that it is the opposite of the list of points in the Invertible Matrix Theorem? A is an invertible matrix A is row equivalent to the identity matrix A has n pivot columns The equation has only a trivial solution to ax=0 The columns of A are linearly independent The equation Ax=b has at least one solution for each b in Rn The column of A span Rn maps Rn onto Rn There is a nxn matrix C such that CA is equal to the identity matrix There is an nxn matrix D such that AD is equal to the identity matrix
....",['linear-algebra']
1863428,Derivative of projection's norm squared with respect to a matrix,"Background: Let $M^{n\times k}(\mathbb{R})$ denote the $n\times k$ matrices with real entries. For any smooth function $f: M^{n\times k}(\mathbb{R}) \to \mathbb{R}$, define the derivative $\frac{\partial f}{\partial A}$ by $$\left(\frac{\partial f}{\partial A}\right)_{i,j}:= \frac{\partial f}{\partial a_{ij}},$$ where $a_{i,j}$ is the entry of $A$ at the $i$-th row and $j$-th column. For any smooth curve $c:(-\epsilon,\epsilon)\to M^{n\times k}(\mathbb{R})$ with $c(0) = A, \dot c(0) = v$, $\frac{\partial f}{\partial A}$ satisfies:
$$\frac{d}{dt}|_{t=0}f(c(t)) = \text{trace}\left(v^T \frac{\partial f}{\partial A}\right).$$ Question: Let $f: M^{n\times k}(\mathbb{R}) \to \mathbb{R}$ be defined by $$f(A):= \|(I - A(A^TA)^{-1}A^T) z\|^2,$$
where $z \in \mathbb{R}^n$ is a fixed vector and $\|\cdot\|$ denotes the Euclidean norm.
I would like to compute $\frac{\partial f}{\partial A}$, at least at any $A$ which is full rank . Are there any tricks that can simplify this process, or is the easiest thing simply to compute each $\frac{\partial f}{\partial a_{i,j}}$ by ""brute force""? My attempt at a simpler solution: Let $c:(-\epsilon,\epsilon)\to M^{n\times k}(\mathbb{R})$ be a smooth curve with $c(0) = A, \dot c(0) = v$. I will assume that $A$ is full rank. By the chain and product rules, we have $$\frac{d}{dt}|_{t=0}f(c(t)) = 2 z^T(I-A(A^TA)^{-1}A)\left[-v (A^TA)^{-1}A^T + A(A^TA)^{-1}(v^TA + A^Tv)(A^TA)^{-1}A^T - A(A^TA)^{-1}v^T\right]z, $$ 
where I have used the fact that for any smooth curve $b:(-\epsilon,\epsilon)\to GL(n,\mathbb{R})$, $\frac{d}{dt}|_{t=0}b^{-1}(t) = -b^{-1}(0)\dot b(0) b^{-1}(0)$. To simplify notation, let $A^\dagger:= (A^T A)^{-1} A^T$ denote the Moore-Penrose pseudoinverse of $A$ and let $\Pi_{A_\perp}:= I - AA^\dagger$ be the orthogonal projection onto the orthogonal complement of the range of $A$.
Substitution of this new notation yields:
$$\frac{d}{dt}|_{t=0}f(c(t)) = 2 z^T\Pi_{A_\perp}\left[-v A^\dagger + (A^\dagger)^T(v^TA + A^Tv)A^\dagger - (A^\dagger)^T v^T\right]z. $$
Now, the kernel of $A^\dagger$ is equal to the orthogonal complement to the range of $A$, so the range of $(A^\dagger)^T$ is equal to the range of $A$. It follows that $\Pi_{A_\perp} (A^\dagger)^T = 0$. Thus we now have a simpler expression: $$\frac{d}{dt}|_{t=0}f(c(t)) = -2 z^T\Pi_{A_\perp}v A^\dagger z = -2\text{trace}\left(z^T(A^\dagger)^Tv^T\Pi_{A_\perp}z\right) = -2\text{trace}\left(v^T \Pi_{A_{\perp}}zz^T(A^\dagger)^T\right).$$ Since $v \in M^{n\times k}(\mathbb{R})$ was arbitrary, it follows that $$\frac{\partial f}{\partial A}(A) = -2 \Pi_{A_\perp} zz^T(A^\dagger)^T.$$","['matrices', 'differential-geometry', 'matrix-calculus', 'multivariable-calculus']"
1863446,Sequence of Erdos-Renyi random graphs convergent with probability 1,"Definitions Let $H,G$ be finite simple graphs. Then the density of $H$ in $G$ , denoted $d(H,G)$, is defined as the probability that a randomly chosen $|H|$-tuple of vertices of $G$ induce a graph isomorphic to $H$. Note that $$d(H,G)=\frac{\operatorname{ind}(H,G)}{|G|(|G|-1)\cdots (|G|-|H|+1)},$$ where $\operatorname{ind}(H,G)$ is the number of embeddings of $H$ as induced subgraphs of $G$. A sequence of graphs $(G_n)_{n=1}^\infty$ is convergent if for every finite simple graph $H$, the sequence $d(H,G_n)$ converges as $n\rightarrow\infty$. Question In the following article, http://research.microsoft.com/en-us/um/people/borgs/papers/teststoc.pdf , in Example 5 (Random graphs), the authors assert that the sequence of Erdos-Renyi random graphs $(G(n,p))_{n=1}^\infty$ is convergent with probability $1$ (with $p\in[0,1]$ fixed). They claim that ""it is not hard (using high concentration results)..."". I have some decent knowledge in graph theory, but I am not so comfortable in probability theory, so I haven't succeeded in proving the assertion. My approach What I have tried is the following. Let $H$ be a fixed graph, we denote $G_n=G(n,p)$ for some fixed $p\in[0,1]$. We want to prove that the sequence $d(H,G_n)$ is convergent with probability $1$. It is straightforward to compute the expected value $$\mathbb{E}d(H,G_n)=|\operatorname{Aut}(H)|p^{|E(H)|}(1-p)^{\binom{|H|}{2}-|E(H)|},$$
which is independent of $n$. Now, the idea is to show that the random variable $d(H,G_n)$ is highly concentrated around its expected value (as the authors suggest) -- so that we can use Borel-Cantelli lemma . In particular, if we show that 
$$\operatorname{Pr}[|d(H,G_n)-\mathbb{E}d(H,G_n)|>t_n]\leq q_n,$$
for some sequences $(t_n)_{n=1}^\infty$ and $(q_n)_{n=1}^\infty$ such that $t_n\rightarrow 0$ and $\sum_{n=1}^\infty q_n<\infty$, then we can apply Borel-Cantelli lemma on the sequence of events $E_1,E_2,\ldots$ where $E_n$ is the event $|d(H,G_n)-\mathbb{E}d(H,G_n)|>t_n$ to conclude that with probability $1$, only finitely many $E_n$ occur. This should directly imply that the sequence $d(H,G_n)$ is convergent, right? The missing piece is the proof that the random variable $d(H,G_n)$ is highly concentrated around its expected value. I know about Chernoff bounds and Chebychev inequality, but it seems that some more involved bound is needed here.","['random-graphs', 'graph-theory', 'probability-theory', 'sequences-and-series']"
1863453,"If a coin toss is observed to come up as heads many times, does that affect the probability of the next toss?","A two-sided coin has just been minted with two different sides (heads and tails). It has never been flipped before. Basic understanding of probability suggests that the probability of flipping heads is .5 and tails is .5. Unexpectedly, you flip the coin a very large number of times and it always lands on heads. Is the probability of flipping heads/tails still .5 each? Or has it changed in favor of tails because the probability should tend to .5 heads and .5 tails as you approach an infinite number of trials? I understand that flipping coins is generally a stochastic process, but does that change at all if you see a large number of trials bias to one side?","['stochastic-processes', 'probability']"
1863469,Classifying space of $GL_{n}(\mathbb{F})$?,"I was looking for the classifying space of the general linear group $GL_{n}(\mathbb{F})$ over a field (of characteristic either zero or positive, finite or infinite), but unfortunately I didn't manage to find something. Can you help me please? Also, do you know what's the cohomology ring of that group in the case where the field is finite or infinite?","['algebraic-topology', 'group-cohomology', 'homology-cohomology', 'group-theory']"
1863470,Evaluation of $\lim_{x\to 0} \frac{(1+x)^{1/x}-e+\frac{ex}{2}}{x^2}$ [duplicate],This question already has answers here : The limit of $((1+x)^{1/x} - e+ ex/2)/x^2$ as $x\to 0$ (4 answers) Closed 4 years ago . Evaluate the following limit: $$L=\lim_{x\to 0} \frac{(1+x)^{1/x}-e+\frac{ex}{2}}{x^2}$$ Using $\ln(1+x)=x-x^2/2+x^3/3-\cdots$ I got $(1+x)^{1/x}=e^{1-x/2+x^2/3-\cdots}$ Could some tell me how to proceed further?,"['calculus', 'limits']"
1863504,Square Integrable Martingales and the Unit Process,"Let $X_t$ be a continuous square-integrable martingale. Then it is true (I think, please correct me if I am wrong) that: $$\forall t \in [0,\infty), \quad \int_0^t 1_{[0,t]}(s) dX_s = X_t - X_0$$ So couldn't we use this as a definition of $\int_0^t 1 (s) dX_s$ (where $1$ is the constant function)? I.e. $$\forall t \in [0,\infty), \quad \int_0^t 1(s) dX_s = \int_0^t 1_{[0,t]}(s)dX_s$$ I am confused because the integral on the right is supposed to be a square integrable martingale, but the one on the left is supposed to be just a local martingale, because the integrand on the left is not square-integrable, only locally $L^2-$ bounded, whereas the integrand on the right is square-integrable. Where is my mistake? square-integrable = $L^2$ -bounded : $\mathbb{E}[\int_0^{\infty} |f_s|^2 \mathrm{d}s]< \infty$ locally square-integrable/ $L^2$ -bounded: $\forall t \in [0,\infty) \quad \mathbb{E}[\int_0^t |f_s|^2 \mathrm{d}s] < \infty$ Seemingly we could do the same trick for any locally $L^2-$ bounded process, and we would always get a square integrable martingale for any finite $t$ (just integrate $(f\cdot 1_{[0,t]})(s)$ instead of $f(s)$ ). But Revuz and Yor says that the integrand needs to be square integrable, not just locally square integrable, for the stochastic integral to again be a continuous square-integrable martingale, and that if the integrand is only locally square integrable, then the resulting process is a continuous local martingale, but not a true martingale.","['stochastic-processes', 'probability-theory', 'stochastic-integrals', 'stochastic-analysis', 'stochastic-calculus']"
1863506,How to I solve this summation?,"I am having trouble solving this summation: 
$\displaystyle{\quad\sum_{i = 1}^{n}\,\,\sum_{j = 4}^{i}
\left(\,\, j + 2i\,\right)}$. I've only gotten this far:
$\displaystyle{\quad\sum_{i = 1}^{n}\sum_{j = 4}^{i}2i +
{i\,\left(\, i + 4\,\right) \over 2}\quad}$ and would welcome some help.","['summation', 'discrete-mathematics']"
1863512,Baby/Papa/Mama/Big Rudin,"Recently, I was looking for the reviews of some Analysis books while encountered terms such as Baby/Papa/Mama/Big Rudin. Firstly, I thought that these are the names of a book! But it turned out that these are some nick names used for the books of Walter Rudin . So I was thinking that $1$. What are the corresponding books of these nick names? $2$. Why such nick names are chosen? or What are their origins?","['soft-question', 'analysis']"
1863534,Why does this ring have rank $k!$?,"Let $R$ be any ring free of rank $k$ over $\mathbb{Z}$ having non-zero discriminant. 
Let $R^{\otimes k} = R \otimes_{\mathbb{Z}} \cdots \otimes_{\mathbb{Z}} R$. Then $R^{\otimes k}$ is a ring of rank $k^k$ in which $\mathbb{Z}$ lies naturally as a subring via $n \rightarrow n(1 \otimes  \cdots \otimes 1)$. Denote by $I_R$ the ideal in $R^{\otimes k}$ generated by elements of the form 
$$
x \otimes  \cdots \otimes 1 + 1 \otimes x \cdots \otimes 1 + \cdots
+ 1 \otimes  \cdots \otimes x - \text{Tr} (x)
$$
for $x \in R$. Let 
$$
J_R = \{ r \in R^{\otimes k} :  nr \in I_R \text{ for some } n \in \mathbb{Z} \}.
$$
Then the ring
$$
R^{\otimes k} / J_R
$$
has rank $k!$. I have been trying to work out why this ring has rank $k!$, but I am not quite seeing it yet. I would appreciate any explanation. Thank you very much! PS This is a ring that comes up in ``Higher composition laws III'' by Manjul Bhargava.","['abstract-algebra', 'ring-theory', 'modules', 'tensor-products']"
1863544,Derivation of gradient for non negative matrix factorization,"I am looking at a paper for non-negative matrix factorization and can't seem to figure out the derivation for the gradient. The function is as follows: $f(W,H) = \frac{1}{2}||V-WH ||^2_F$ Where V is fixed. The resulting gradients are: $\nabla_W f(W,H) = (WH-V)H^T $ $\nabla_H f(W,H) = W^T(WH-V) $ I tried looking up rules in various reference manuals but never got anything solid. Even a hint / solid resource would be incredibly helpful.","['matrices', 'multivariable-calculus', 'partial-derivative', 'linear-algebra']"
1863562,Proving $\operatorname{Var}(X) = E[X^2] - (E[X])^2$,"I want to understand something about the derivation of $\text{Var}(X) = E[X^2] - (E[X])^2$ Variance is defined as the expected squared difference between a random variable and the mean (expected value): $\text{Var}(X) = E[(X - \mu)^2]$ Then: $\operatorname{Var}(X) = E[(X - \mu)^2]$ $\operatorname{Var}(X) = E[(X - E[X])^2]$ $\operatorname{Var}(X) = E[(X - E[X])(X - E[X])]$ $\operatorname{Var}(X) = E[X^2 - 2XE[X] + (E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2E[XE[X]] + E[(E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2E[E[X]E[X]] + E[(E[X])^2]$ $\operatorname{Var}(X) = E[X^2] - 2(E[X])^2 + (E[X])^2$ $\operatorname{Var}(X) = E[X^2] - (E[X])^2$ What I don't quite understand is the steps that get us from $E[XE[X]]$ to $E[E[X]E[X]]$ to $(E[X])^2$, also $E[(E[X])^2]$ to $(E[X])^2$. While I'm sure these jumps are intuitive and obvious I would still like to understand how we can (more formally) make these jumps / consider them mathematically equivalent.","['variance', 'probability', 'expected-value', 'proof-explanation']"
1863586,Integrate $\int\frac{x+1}{\sqrt{1-x^2}} \; dx$ without using trigonometric substitution,"I want to solve: $$\int\frac{x+1}{\sqrt{1-x^2}} \; dx$$ I know how to solve this using trigonometric substitution, but how can I solve the integral in an other way ?","['integration', 'trigonometric-integrals', 'calculus']"
1863590,Maximum area of triangle inside a convex polygon,"Prove that within any convex polygon of area $A$, there exists a triangle with area at least $cA$, where $c=\tfrac{3}{8}$. Are there any better constants $c$? I'm not sure how to approach this problem. It is easily proven that such a triangle should have its vertices on the perimeter of the polygon, but I don't know how to proceed from here.","['polyhedra', 'combinatorial-geometry', 'convex-geometry', 'extremal-combinatorics', 'combinatorics']"
1863626,"If $H<G$ is abelian, and $\chi(1)=[G:H]$ for irreducible $\chi$, then $H$ contains a nontrivial normal subgroup?","Suppose $\chi$ is an irreducible character of a finite group $G$, and $H$ is a nontrivial abelian subgroup such that $\chi(1)=[G:H]$. Why does $H$ contain a nontrivial normal subgroup? I understand that
$$
\chi(1)=\chi|_H(1)\leq(\chi|_H,\chi|_G)\leq [G:H](\chi,\chi)=[G:H]=\chi(1)
$$
So I have equality throughout. Since $(\chi|_H,\chi|_H)=[G:H]$, I know that $\chi$ vanishes on $G\setminus H$, so necessarily $\ker\chi$ and $Z(\chi)$ are in $H$ at least. These are normal in $G$, so if they're nontrivial, that would explain it. Since $\ker\chi\subseteq Z(\chi)$, I think it'd make sense to show $Z(\chi)$ is nontrivial. Does this happen to be true, or should I be looking for a different subgroup? For simplicity, I'm working over $\mathbb{C}$.","['finite-groups', 'representation-theory', 'group-theory', 'characters']"
1863655,Multiplicative functions on matrices,"What are some examples of multiplicative functions on matrices? More precisely, I'm looking for $f : M^{n \times n}, M^{n \times n} \to \mathbb R$ with the property $$f(AB) = f(A)f(B)$$ where A, B are $n \times n$ matrices. A particularly well-known example is the determinant, but I'm curious about other examples, and possibly a classification of them.","['matrices', 'linear-algebra']"
1863658,Symbol of differential operator and change of coordinates,"$\DeclareMathOperator{I changed index to upper one}{but edit has to take al least 6 elements}$ Some time ago I posted the question about the change of coordinates in differential operator. Here is the relevant discussion Symbol of differential operator transforms like a cotangent vector The answer which was given to this question explains why we can invariantly define the principial symbol of differential operator. However I would like to understand straightforward what happens with the principial symbol when we introduce new coordinates. Let me recall some formulas for transformation laws for tensors: if $(x^i)$ are old coordinates and $(y^i)$ are new coordinates then we have following formulas for canonical basis in tangent and cotangent spaces (everything takes place over manifold $M$):
$$\frac{\partial}{\partial y^i}=\sum_{k=1}^n \frac{\partial x^k}{\partial y^i} \frac{\partial}{\partial x^k}, \qquad \frac{\partial}{\partial x^i}=\sum_{k=1}^n \frac{\partial y^k}{\partial x^i} \frac{\partial}{\partial y^k},$$
$$dy^i=\sum_{k=1}^n\frac{\partial y^i}{\partial x^k} dx^k, \qquad dx^i=\sum_{k=1}^n\frac{\partial x^i}{\partial y^k} dy^k $$
If we have vector field $X=\sum_{k=1}^nX^k \frac{\partial}{\partial x^k}=\sum_{k=1}^n Y^k \frac{\partial}{\partial y^k}$ and differential one-form $\omega=\sum_{k=1}^n \alpha_k dx^k=\sum_{k=1}^n\beta_k dy^k$ expressed in these two system of coordinates then we have formulas:
$$Y^i=\sum_{k=1}^n\frac{\partial y^i}{\partial x^k}X^k, \qquad X^i=\sum_{k=1}^n\frac{\partial x^i}{\partial y^k}Y^k,$$
$$\beta_i=\sum_{k=1}^n\frac{\partial x^k}{\partial y^i}\alpha_k, \qquad \alpha_i=\sum_{k=1}^n\frac{\partial y^k}{\partial x^i}\beta_k.$$
For general tensors of type $(r,s)$ if we have in two differenet coordinate systems $$t=\sum_{i_1,...,i_r,j_1,...,j_s}t^{i_1,...,i_r}_{j_1,...,j_s}\frac{\partial}{\partial x^{i_1}} \otimes ... \otimes \frac{\partial}{\partial x^{i_r}}\otimes dx^{j_1} \otimes ... \otimes dx^{j_s}=\sum_{i_1,...,i_r,j_1,...,j_s}u^{i_1,...,i_r}_{j_1,...,j_s}\frac{\partial}{\partial y^{i_1}} \otimes ... \otimes \frac{\partial}{\partial y^{i_r}}\otimes dy^{j_1} \otimes ... \otimes dy^{j_s}$$
then we have 
$$\frac{\partial}{\partial y^{i_1}} \otimes ... \otimes \frac{\partial}{\partial y^{i_r}}\otimes dy^{j_1} \otimes ... \otimes dy^{j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial x^{k_1}}{\partial y^{i_1}} ... \frac{\partial x^{k_r}}{\partial y^{i_r}}\frac{\partial y^{j_1}}{\partial x^{l_1}} ... \frac{\partial y^{j_s}}{\partial x^{l_s}}  \frac{\partial}{\partial x^{k_1}} \otimes ... \otimes \frac{\partial}{\partial x^{k_r}}\otimes dx^{l_1} \otimes ... \otimes dx^{l_s},$$ $$\frac{\partial}{\partial x^{i_1}} \otimes ... \otimes \frac{\partial}{\partial x^{i_r}}\otimes dx^{j_1} \otimes ... \otimes dx^{j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial y^{k_1}}{\partial x^{i_1}} ... \frac{\partial y^{k_r}}{\partial x^{i_r}}\frac{\partial x^{j_1}}{\partial y^{l_1}} ... \frac{\partial x^{j_s}}{\partial y^{l_s}}  \frac{\partial}{\partial y^{k_1}} \otimes ... \otimes \frac{\partial}{\partial y^{k_r}}\otimes dy^{l_1} \otimes ... \otimes dy^{l_s}$$and also $$u^{i_1,...,i_r}_{j_1,...,j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial y^{i_1}}{\partial x^{k_1}} ... \frac{\partial y^{i_r}}{\partial x^{k_r}} \frac{\partial x^{l_1}}{\partial y^{j_1}} ... \frac{\partial x^{l_s}}{\partial y^{j_s}}t^{k_1,...,k_r}_{l_1,...,l_s},$$ $$t^{i_1,...,i_r}_{j_1,...,j_s}=\sum_{k_1,...,k_r,l_1,...,l_s}\frac{\partial x^{i_1}}{\partial y^{k_1}} ... \frac{\partial x^{i_r}}{\partial y^{k_r}} \frac{\partial y^{l_1}}{\partial x^{j_1}} ... \frac{\partial y^{l_s}}{\partial x^{j_s}}u^{k_1,...,k_r}_{l_1,...,l_s}.$$ However general differential operator contains higher order differentials for which I haven't seen the appriopriate formulas. For general differential order $m$ operator of the form $D=\sum_{|\alpha| \leq m}a_{\alpha}(x)\frac{\partial^{|\alpha|}}{\partial x_1^{\alpha_1} ... \partial x_n^{\alpha_n}}$ (where $\alpha=(\alpha_1,...,\alpha_n)$ a multiindex and $a_{\alpha}(x)$ are matrices) the principial synmbol is defined as the expression $a(x,\xi)=\sum_{|\alpha|=m}a_{\alpha}(x)\xi_1^{\alpha_1} ... \xi_n^{\alpha_n}$ where $\xi=(\xi_1,...,\xi_n)$ is a vector: what we do, we replace each $\frac{\partial}{\partial x_k}$ by $\xi_k$. So far we have some formal expression $a$ which takes a point $x$ of a manifold and vector $\xi \in \mathbb{R}^n$ and produces some matrix. And here are my questions: What transformation law the function $a$ must obey in order to correctly define a mapping from the cotangent bundle $T^*M$? Or maybe we look for some transformation laws for the variables $\xi_k$? How to show that such transformation law holds? I repeat once again: I already understood how to define symbol globally as a map from cotangent space and that this definition gives exactly the local expression described above-however I would like to understand the reason for such definition which at the moment is pulled out of hat.Concerning the second question I would like to understand whether there are some general formulas for transformation laws for an arbitrary differential operators: as far as I remeber, when I once saw the computations for spherical Laplacian, it was not clear whether such method will work in general arbitrary example.","['derivatives', 'real-analysis', 'tensors', 'change-of-basis', 'differential-geometry']"
1863661,Bound on $c-b$ for $a^n+b^n=c^n$,"Let $a\leq b\leq c$ be positive real numbers and $n$ positive integer with $a^n+b^n=c^n$. Prove that $c-b\leq(\sqrt[n]{2}-1)a$. The desired inequality can be written as $c-b+a\leq \sqrt[n]{2}a$. Raising to the power of $n$, this is $(c-b+a)^n\leq 2a^n$. If it were true that $(c-b+a)^n\leq c^n-b^n+a^n$ we would be done, since the latter is just $2a^n$.","['algebra-precalculus', 'inequality']"
1863686,Restriction of a $C^{\infty}$ vector bundle over a regular submanifold.,"This question is about the content of page 134 of Tu's An Introduction to Manifolds . A $C^{\infty}$ vector bundle or rank r is a triple $(E,M,\pi)$ consisting of manifolds $E$ and $M$ and a surjective smooth map $\pi:E\rightarrow M$ that is locally trivial of rank $r$. More precisely, (i) each fiber $\pi^{-1}(p)$ has the structure of a vector space of dimension $r$, (ii) for each $p\in M$, there are an open neighborhood $U$ of $p$ and a fiber-preserving diffeomorphism $\phi:\pi^{-1}(U)\rightarrow U\times\mathbb{R}^n$ such that for every $q\in U$ the restriction $$\phi\mid_{\pi^{-1}(q)}:\pi^{-1}(q)\rightarrow \{q\}\times\mathbb{R}^r$$ is a vector space isomorphism. My question is: Given any regular submanifold $S\subset M$, is the triple $(\pi^{-1}S,S,\pi\mid_{\pi^{-1}S})$ also a $C^{\infty}$ vector bundle over S? I tried to resolve this issue by checking the conditions (i) and (ii). Condition (i) is obviously satisfied. To prove (ii), I chose an adapted chart $(U,\phi)$ with $p\in U$  (which gives a chart for $S$) and tried showing that the map $$\phi\mid_{\pi^{-1}(U\cap S)}:\pi^{-1}(U\cap S)\rightarrow U\cap S\times\mathbb{R}^r$$
is a fiber-preserving diffeomorphism. But is this map necessarily a diffeomorphism? This is a restriction of a diffeomorphism, and even though it possesses an inverse (using $\phi^{-1}$) which looks like a smooth inverse for $\phi$, we don't know what manifold structures the sets $\pi^{-1}(U\cap S),U\cap S\times\mathbb{R}^r$ have yet, and I'm hesistated to say for sure that those maps are smooth maps, let alone inverse maps to each other. In summary: Do the sets $\pi^{-1}(U\cap S),U\cap S\times\mathbb{R}^r$ have manifold strutures? Canonical ones? Is this true in general? In what sense? : Restriction of a vector bundle is a vector bundle. Thanks in advance.","['algebraic-topology', 'differential-geometry', 'differential-topology']"
1863696,Bounding Geodesic Curvature,"Let $\Sigma$ be a smooth surface, let $p,q \in \Sigma$ and let $n_{p}$ be the normal at $p$. Suppose that $d(p,q) < c$ for some constant $c$. That is $p$ and $q$ are pretty close to each other on $\Sigma$. Consider the plane $h = \operatorname{span}\{n_{p}, \vec{pq}\}$. The intersection $h \cap \Sigma$ defines a curve $\gamma$ from $p$ to $q$. I want to bound the geodesic curvature of $\gamma$. I have a bound on the principal curvatures in a neighborhood of $p$. This allows me to bound the normal curvature of $\gamma$. I want to bound the geodesic curvature of $\gamma$, so that I can bound the total curvature of $\gamma$. Is there a way to leverage the principal curvatures at $p$, the fact that $\gamma$ lies in a plane defined above, and the fact that $p$ and $q$ are close on $\Sigma$ to bound the geodesic curvature $k_{g}$ of $\gamma$?","['differential-geometry', 'differential-topology']"
1863705,"Negating the statement $\exists x \in \Bbb R$ so that $x$ is not an integer, $x > 2016$, and $\lfloor x^2 \rfloor = \lfloor x \rfloor^2$","There exists a real number $x$ so that $x$ is not an integer, $x > 2016$, and $\lfloor x^2 \rfloor = \lfloor x \rfloor^2$. I would like clarification on how to negate this. My idea of negation is for all real numbers $x$, so that $x$ is not an integer, $x>2016$ and  $\lfloor x^2\rfloor = \lfloor x\rfloor ^2$. I'm tempted to say for all $x$ so that $x$ is an integer, $x> 2016$, but $\lfloor x^2 \rfloor \neq \lfloor x\rfloor ^2$.","['predicate-logic', 'logic', 'discrete-mathematics']"
1863706,Show that linear functional $L(f) = \int_0^1 f(x) dx$ is continuous,"Let $(C[0,1], d_1)$ be a metric space of all continuous functions $f:[0,1] \to \mathbb{R}$, $d_1$ is the $L_1$ metric
$$d_1(f,g) = \int\limits_0^1 |f(x) - g(x)| dx$$ Show that linear functional $L(f) = \int\limits_0^1 f(x) dx$ is
  continuous I'm not sure what would be the easiest way to prove this claim, I feel like I am on the right track Proof Attempt: Recall $L$ is continuous if for all convergent sequence $(f_n), f_n
   \to f$ as $n \to \infty \implies L(f_n) \to L(f)$ as $n \to \infty$ Let $(f_n)$ be a convergent sequence in $(C[0,1], d_1)$, we wish to
show that $L(f_n) \to L(f)$ as $n \to \infty$ $f_n \to f$ if $\forall \epsilon >0, \exists N \in \mathbb{N}$, such
that $\forall x \in [0,1], \forall n \geq N, d_1(f_n(x), f(x)) <
   \epsilon$ By definition, $d_1(f_n(x), f(x)) < \epsilon \implies \int\limits_0^1
   |f_n(x) - f(x)| dx < \epsilon$ If $L(f_n) \to L(f)$ as $n \to \infty$ then $|L(f_n) - L(f)| = |\int\limits_0^1 f_n(x) - f(x) dx| < \epsilon$ But $|\int\limits_0^1 f_n(x) - f(x) dx|  \leq \int\limits_0^1 |f_n(x) - f(x)| dx $ by triangle inequality, and $\int\limits_0^1 |f_n(x) - f(x)| dx  < \epsilon$ Therefore,  $L(f_n) \to L(f)$ as $n \to \infty$ Does this look correct?","['real-analysis', 'proof-verification', 'functional-analysis', 'metric-spaces', 'convergence-divergence']"
1863709,Geometric interpretation of linear programming dual,"Is there a geometric interpretation of the linear programming dual in terms of the primal? I feel like without some sort of intuition of it, I don't truly understand it.","['linear-algebra', 'linear-programming', 'duality-theorems']"
1863712,"Let $f$ be a Lebesgue measurable function on $\Bbb{R}$ satisfying some properties, prove $f\equiv 0$ a.e.","Let $f$ be a Lebesgue measurable function on $\Bbb{R}$ satisfying: i) there is $p\in (1,\infty)$ such that $f\in L^p(I)$ for any bounded interval $I$ . ii) there is some $\theta \in (0,1)$ such that: $$\left|\int_I f\ dx\right|^p\leq \theta (\mu(I))^{p-1}\int_I |f|^p\ dx$$ Prove that $f\equiv 0 $ a.e. This is a previous qual question (3, beware: PDF). My thoughts. We assume that there is some $E$ where without loss of generality $f>0$ on $E$ and $\mu(E)>0$ . Using regularity of Lebesgue measure, for all $\epsilon>0$ there is some open $G_{\epsilon}$ with $\mu(G_{\epsilon}\setminus E)<\epsilon$ and $E \subseteq G_{\epsilon}$ . We may decompose $G_{\epsilon}$ as a countable disjoint union $I_k$ . So we must only show that there is a contradiction if $f>0$ on some interval. I tried arguing like this: $$\begin{align*}\left|\int_I f\ dx\right|^p&\leq \theta (\mu(I))^{p-1}\int_I |f|^p\ dx\\ &\leq\theta (\mu(I))^{p-1} \mu(I) \operatorname{essup}(|f|^p)\\&=\theta(\mu(I))^p\operatorname{essup}_I(|f|^p)\end{align*}$$ I feel like there should be a general contradiction here (for example if $I=(0,1)$ and $f=1$ this inequality doesn't hold). Can someone help me? I would like hints only please.","['functional-analysis', 'lp-spaces', 'lebesgue-integral', 'measure-theory']"
1863740,How to approach general solutions to functional equations of multiple variables,"I understand the concept of a function, broadly speaking, but when it comes down to solving general functional equations, I sometimes find it difficult to wrap my head around the problem at hand. For example, if I were asked to solve the functional equation $$f(x+t) - f(x-t) = 4xt,$$ I simply wouldn't know where to start. With my experience in functions, I've learned to determine equations of inverses, the value of f(x) that emerges when one plugs in x values, and how to graph many types of functions, but these solutions of the more general type really get to my head. Any tips on how to approach a problem (and similar problems) like this? Many thanks.","['algebra-precalculus', 'functions']"
1863753,A surprising inequality about a $\limsup$ for any sequence of positive numbers,"Prove the following : Let $\{x_n\}_{n=1}^{\infty}$ be a sequence of positive real numbers. Then $$ \limsup \frac{x_1+x_2+...+x_n+x_{n+1}}{x_n} \geq 4 \ .$$ Note: Yes, $4$ is sharp: $x_n=2^n$ sequence. I have already proved that $$ \liminf   x_n < \infty \implies \limsup \frac{x_1+x_2+...+x_n+x_{n+1}}{x_n} = \infty.$$ So, the interesting case is when $\lim x_n = \infty$ .","['limsup-and-liminf', 'sequences-and-series']"
1863791,homeomorphisms of the real line,"Given a homeomorphism $h$ of the extended real line. Is it true that there exists an extension $\hat h$ of $h$, which is a Mobius transformation of a hyperbolic space $\mathbb{H}$? Any hints are welcome! Thank you in advance!","['complex-analysis', 'hyperbolic-geometry', 'functions']"
1863794,2 times chord length equals supplementary arc length,"This is a problem that has bugged me for a long time. It involves a diameter and a circle with radius 1. I wanted to find the point at which the distance between the point and one end of the diameter was $\frac{1}{2}$ the length of the arc connecting the point to the other end of the diameter. I have used a program to find the angle's approximate measure ($118.014011183903^\circ$), and the arc's approximate length ($2.05973305864452$), but would like to know a mathematical way to solve for either one of these, as each leads to the other.",['geometry']
1863808,Domain of $f(x)=x^{\frac{1}{\log x}}$,"What is the domain of $$f(x)=x^{\frac{1}{\log x}}$$ Since there is logarithm , the domain is $(0 \: \infty)$ But the book answer is $(0 \: \infty)-\{1\}$ but if $x=1$ $$f(x)=1^\infty=1$$ So is it necessary to exclude $1$","['algebra-precalculus', 'functions']"
1863811,Is $X^*$ complete with weak*-topology,"Suppose $X$ is a topological vector space, $X^*$ is its topological dual space. Let the topology of $X^*$ is weak*-topology, Is $X^*$ complete? Suppose $f_s$ is a Cauchy net in $X^*$, it is easy to see that $f=\lim f_s$ exists. We can prove that $f$ is linear, but I couldn't see if it is continuous.",['functional-analysis']
1863836,Define an $\mathbb{N}$ to $\mathbb{N}$ function that is,"Hi I'm preparing for an exam and was going through exercises on functions. I stumbled upon this question and didn't know how to answer it. Give an $\mathbb{N}$ to $\mathbb{N}$ function that
is one-to-one but not onto, Answer:  $f(n)=n+1$ onto but not one-to-one, Answer: $F(n) =\begin{cases} n-1 &\mbox{if } n > 0 \\ 0 & \mbox{if } n= 0\end{cases}$ both one-to-one and onto (but different from $\text{id}_{\mathbb{N}}$), Answer: $F(n) =\begin{cases} n-1 &\mbox{if } n\text{ is odd}\\ n+1 &\mbox{if }n\text{ is even}\end{cases}$ neither one-to-one nor onto. Answer: $F(n) = 42$ When I looked at the answers to try & understand I couldn't figure out why they were correct. Why was 42 chosen as a neither one-to-one or onto function (based on what equation)? And how does $n-1$ or $n+1$ define the domain & codomain which then can determine the type of the function? Thank you very much!","['elementary-set-theory', 'functions', 'discrete-mathematics']"
1863846,Does the series $1-\frac12+\frac12-\frac1{2^2}+\frac13-\frac1{2^3}+\frac14-\frac1{2^4}+\frac15-\frac1{2^5}+\cdots$ converge or diverge?,"$1-\frac{1}{2}+\frac{1}{2}-\frac{1}{2^2}+\frac{1}{3}-\frac{1}{2^3}+\frac{1}{4}-\frac{1}{2^4}+\frac{1}{5}-\frac{1}{2^5}+\cdots$ I've be trying to figure out how to write this series symbolically so I can examine it's limit, but I'm having trouble.  So far the best I've come up with is: $\sum_{n=0}^{\infty}(-1)^n\left(\frac{1}{2^n}-\frac{1}{2^{n+1}}\right)$ But obviously the above does not properly reproduce the series.","['real-analysis', 'convergence-divergence', 'sequences-and-series', 'calculus']"
1863875,Find the average value of the function...,"Find the average value of the function $$F(x) = \int_x^1 \sin(t^2) \, dt$$ on $[0,1]$. I know the average value of a function $f(x)$ on $[a,b]$ is $f_\text{avg}=\dfrac1{b-a} \int_a^b f(x) \, dx$, but I don't know how to apply that to this question... The function loos like the Fresnel integral? But that doesn't quite help me either.","['average', 'integration', 'calculus']"
1863881,Asymptotic distribution of $(\bar{Y}_n - E(|X_1|)) / \bar{X}_n$,"Let $(X_n)$ be i.i.d double exponential random variables, with PDF $\frac1{2a}e^{-|x|/a}$, thus $E(X_n) = 0$, $E(|X_n|) = a$ and $V(X_n)=2a^2$. Consider the sample means $$\bar{X}_n=\frac1n\sum\limits_{i=1}^nX_i\qquad\bar{Y}_n=\frac1n\sum\limits_{i=1}^n|X_i|.$$ One is interested in the asymptotic distribution of $$R_n=\frac{\bar{Y}_n - a}{\bar{X}_n}.$$ I want to use the delta method, but the expectation of $\bar{X}_n$ is $0$, which causes the problem when dividing. Any other idea?","['probability-theory', 'central-limit-theorem']"
1863921,"Real Analysis, Folland Theorem 3.18 Differentiation on Euclidean Space","Background Information: A measurable function $f:\mathbb{R}^n\rightarrow \mathbb{C}$ is called locally integrable (w.r.t Lebesgue measure) if $\int_K |f(x)|dx < \infty$ for every bounded measurable $K\subset \mathbb{R}^n$. We denote the space of locally integrable functions by $L^1_{loc}$. If $f\in L^1_{loc}$, $x\in \mathbb{R}^n$, and $r > 0$, we define $A_r f(x)$ to be the average value of $f$ on $B(r,x)$ (ball of radius $r$ around $x$): $$A_r f(x) = \frac{1}{m(B(r,x))}\int_{B(r,x)} f(y) dy$$ Maximal Theorem  - There is a constant $C > 0$ such that for all $f\in L^1$ and all $\alpha > 0$, $$m(\{x:Hf(x) > \alpha\}) \leq \frac{C}{\alpha}\int |f(x)|dx$$ Question: Theorem 3.18 - If $f\in L^1_{loc}$ then $\lim_{r\rightarrow 0} A_r f(x) = f(x)$ for a.e. $x\in\mathbb{R}^n$ I am trying to understand Folland's proof but I am having some trouble. He first begins by saying that it suffices to show that for $N\in\mathbb{N}$, $A_r f(x)\rightarrow f(x)$ for a.e. with $|x| < N$. Why does $|x| \leq N$? Then he states that but for $|x|\leq N$ an $r\leq 1$ the values $A_r f(x)$ depend on $f(y)$ for $|y|\leq N + 1$. Again why is $|y|\leq N+1$? Then he says by Theorem 2.41 we can find a continuous integrable function $g$
such that $\int |g(y) - f(y)|dy < \epsilon$. Then the rest is not so bad to follow. If there is another way of proving this please let me know otherwise I just need to understand the beginning points and I think I should be able to understand the proof. Second question: As mentioned Folland uses Theorem 2.41 to find a continuous integrable function $g$ such that $\int |g(y) - f(y)|dy < \epsilon$. By contunity of $g$ we have that for $x\in\mathbb{R}^n$ and $\delta > 0$ there exists an $r > 0$ such that $|g(y) - g(x)| < \delta$ whenever $|y - x| < r$, and hence $$|A_r g(x) - g(x)| = \frac{1}{m(B(r,x)}\left|int_{B(r,x)} [g(y) - g(x)] dy \right| < \delta$$ therefore $A_r g(x)\rightarrow g(x)$ as $r\rightarrow 0$ for all $x$, so 
\begin{align*}
\lim_{r\rightarrow 0}\sup|A_rf(x) - f(x)| &= \lim_{r\rightarrow 0}\sup |A_r(f-g)(x) + (A_r g - g)(x) + (g - f)(x)|\\
&\leq H (f-g)(x) + 0 + |f-g|(x)
\end{align*}
Let, $$E_{\alpha} = \{x:\lim_{r\rightarrow 0}\sup |A_r f(x) - f(x)| > \alpha\} \ \ \ F_{\alpha} = \{x: |f - g|(x) > \alpha\}$$ This is where I get confused again. Folland says note that $$E_{\alpha} \subset F_{\alpha/2}\cup \{x: H(f-g)(x) > \alpha/2\}$$ Why does he have $F_{\alpha/2}$ I understand why $E_{\alpha}$ is a subset of these but I don't understand the intuition. Then he says but $$(\alpha/2)m(F_{\alpha/2}) \leq \int_{F_{\alpha/2}} |f(x) - g(x)| dx < \epsilon$$ Is he using the Maximal Theorem there?","['real-analysis', 'measure-theory']"
1863928,About a proof that $\lfloor x^2\rfloor = \lfloor x\rfloor^2$ for unbounded non integer values of $x$,"I am taking a first course in discrete mathematics. The instructor parsed the following question that has the following solution, respectively: Prove the statement: For all positive integers $N$, there exists a real number $x$, so that $x$ is not an integer, $x>N$, and $\lfloor x^2\rfloor = \lfloor x\rfloor^2$. Why is $x= N+ 1/(3N)$ used? I do not understand this statement. Is $1/(3N)$ some axiom of non-integer real numbers? Also, what is the intuition behind squaring both sides at the end of the third line of the solution?","['ceiling-and-floor-functions', 'proof-verification', 'discrete-mathematics']"
1863933,Expectation of Product of Ito Integrals wrt Independent Brownian Motions,"Let $W_1(t)$, $W_2(t)$, $W_3(t)$ be independent Brownian motions and $f$, $g$ smooth functions. I want to know if the following is true:
$$
   \mathbb{E}\left[
      \left(
         \int\limits_0^t f(W_3(s),s) \,dW_1(s)
      \right)
      \left(
         \int\limits_0^t g(W_3(s),s) \,dW_2(s)
      \right)
   \right] = 0
$$
I think it is, because, as an argument from intuition:
$$
\begin{align}
   \mathbb{E}&\left[
      \left(
         \int\limits_0^t  f(W_3(s),s) \,dW_1(s)
      \right)
      \left(
         \int\limits_0^t g(W_3(s),s) \,dW_2(s)
      \right)
   \right]\\ 
&=
\mathbb{E}\left[
      \left(
         \lim_{n\rightarrow\infty}\sum\limits_{i=0}^{n-1} 
                  f(W_3(t_i),t_i) [W_1(t_{i+1})-W_1(t_{i})]
      \right)
      \left(
         \lim_{n\rightarrow\infty}\sum\limits_{j=0}^{n-1} 
                  g(W_3(t_j),t_j) [W_2(t_{j+1})-W_2(t_{j})]
      \right)
   \right]\\
&=
\lim_{n\rightarrow\infty}
\sum\limits_{i=0}^{n-1}
\sum\limits_{j=0}^{n-1}
\mathbb{E}\left[
      f(W_3(t_i),t_i) g(W_3(t_j),t_j)
   \right]
\underbrace{
\mathbb{E}\left[ 
   W_1(t_{i+1})-W_1(t_{i})
\right]
}_0
\underbrace{
\mathbb{E}\left[ 
   W_2(t_{j+1})-W_2(t_{j})
\right]
}_0\\
&=0
\end{align}
$$
since increments of $W$ are Gaussian. But I am not sure if there are some stochastic analysis concepts I am missing. Thanks!","['stochastic-processes', 'probability', 'stochastic-integrals', 'brownian-motion', 'stochastic-calculus']"
1863943,Homology and cohomology of 7-manifold,"I have the following problem: Let $M$ be a connected closed $7$-manifold such that $H_1(M,\mathbb{Z}) = 0$, $H_2(M,\mathbb{Z}) = \mathbb{Z}$, $H_3(M,\mathbb{Z}) = \mathbb{Z}/2$. Compute
  $H_i(M,\mathbb{Z})$ and $H^i(M,\mathbb{Z})$ for all $i$. I know that if $M$ is orientable, using Poincaré duality, the fact that $\chi(M)=0$ and the exact sequence for $H^i(M,\mathbb{Z})$ I can get the result. But, I don't know how to prove that $M$ is orientable. I know that is the case if $M$ does not have $2$-torsion on $\pi_1(M)$, but I don't see why this $2$-torsion should descend to $H_1(M)$.","['homology-cohomology', 'manifolds', 'orientation', 'algebraic-topology', 'differential-geometry']"
1863979,Group of deck transformations acts properly discontinuously,"Let $M$ be a connected (smooth Riemannian) manifold which admits a universal cover $\tilde{M}$. Let $\Gamma$ be the group of deck transformations on $\tilde{M}$. I want to show that $\Gamma$ acts properly discontinuously on $\tilde{M}$. The definition for properly discontinuous that I'm using is as follows: Definition 1: A group $G$ acts properly discontinously on a (smooth) manifold $N$ (it is already enough to require $N$ being a locally compact Hausdorff space) if $G$ acts by homeomorphisms and for any compact set $K \subset N$ the set 
$\{ \gamma \in \Gamma \mid \gamma(K) \cap K \neq \emptyset \}$ is finite. In literature however, one sometimes finds the following definition, which for the sake of distinction, I will call properly discontinuous$^{TypeB}$ (compare Munkres' book on Topology): Definition 2: A group $G$ acts properly discontinuously$^{TypeB}$ on a (smooth) manifold $N$ if it acts by homeomorphisms and for every $x \in N$ there is an open neighborhood $U$ of $x$ in $N$ such that $g(U) \cap U = \emptyset$ for all $g \in G \setminus\{id\}$. It is easy enough to show that the group of deck transformations $\Gamma$ acts properly discontinuously$^{TypeB}$ on $\tilde{M}$ (i.e. using Definition 2). I was unable to prove however, that properly discontinuous$^{TypeB}$ implies properly discontinuous (i.e. Definition 2 implies Definition 1). The proofs I've found are all either rather indirect (i.e. with many intermediate steps) or use methods that I don't understand. Compare for example the treatment here: https://mathoverflow.net/questions/55726/properly-discontinuous-action So, I'm looking for either an immediate proof that properly discontinuous$^{TypeB}$ implies properly discontinuous or a direct proof that $\Gamma$ acts properly discontinuously on $\tilde{M}$ (using Definition 1). Thanks in advance for any help!","['group-actions', 'covering-spaces', 'smooth-manifolds', 'differential-geometry']"
1864047,Why is uniqueness important for PDEs?,"Every text on PDEs I come across will spend alot of time on showing the existence and uniqueness of solutions to a particular PDE. The importance of the existence of a solution to a PDE is obvious, but I can't see why so much time is spent on uniqueness. Why do we care whether a solution is unique or not as long as we know that there is a solution? Is uniqueness just shown for the sake of it, ie. the sake of completeness, or is there some deeper reason why it's considered important to show uniqueness?","['functional-analysis', 'partial-differential-equations']"
