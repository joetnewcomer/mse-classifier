question_id,title,body,tags
1792954,"In general, why is the product topology not equal to the box topology","I am trying to understand a counter-example showing that the box topology and product topology are not equal. Here it is: Let $\tau$ and $\tau'$ be the product and box topologies respectively. Let $X_i = \mathbb{R}\ \forall i$ and let $U_i = (-1,1)\ \forall i$. Then $U:= \prod_{i=1}^{\infty}U_i$ and $U \in \tau'$ but $U \notin \tau$. I don't understand why $U \notin \tau$. Any insight would be appreciated!","['general-topology', 'product-space', 'real-analysis']"
1792955,Unramified algebraic extensions of local fields,"This is a basic question from Neukirch's Algebraic Number Theory , Prop. 7.2: Fix a non-Archimedean local field $K$. Let $L/K$ and $K'/K$ be two extensions inside an algebraic closure $\bar{K}/K$ and let $L'=LK'$. Then one has $$L/K\text{ unramified} \implies L'/K'\text{ unramified}.$$ For an arbitrary extension, Neukirch defines an arbitrary extension $L/K$ to be unramified if $L$ is a union of finite unramified subextensions of $K$. Now at the start of the proof it states that we may assume $L/K$ to be finite . Why is this? This is the only reason I can think of: suppose $L=\bigcup_{i\in I}L_i$ for some collection $L_i$ of finite unramified subextensions of $K$, then the composite $LK'$ is the union $\bigcup_i (L_iK)$. I've tried showing this but I can't do it without also assuming that $L=\bigcup_{i\in I}L_i$ is a directed union. I'd be very grateful for some help.","['number-theory', 'abstract-algebra', 'algebraic-number-theory', 'field-theory']"
1792969,Bayesian Estimation Derivation,"I am trying to understand Bayesian estimation and I come across this line in my lecture notes: θ(Bayesian) = E_θ|x[θ] =  E[π(θ|x)] So it's meant to reader that the Bayesian estimator is the Conditional Expectation of the sample (x's) which equals the expectation of the posterior (3'rd expression). I understand the derivation up to this point but I dont see how the conditional expectation of theta: So the middle expression ""E_θ|x[θ]"" (should look like E underscore θ|x of θ) is: Integral [θ · π(θ|x) dθ] and somehow that equals the expectation of the Posterior i.e. E[π(θ|x)] Please help! I am hoping it is a simple answer cause there is no explanation between these steps.","['probability-theory', 'bayesian', 'statistics', 'estimation', 'probability']"
1792990,Does an abelian subgroup inject into the abelianisation of the whole group? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question If $H <G $ are groups and H is abelian, do we get an injection from H into $G/[G,G] $?","['abelian-groups', 'examples-counterexamples', 'group-theory']"
1793007,How to find the Laurent series expansion of an exp function.,"Question: How to find the Laurent series expansion in powers of z of a) $f(z)= \dfrac{e^{z^2}}{z^3}$ $\text{where} \left| z \right| > 0$ Attempt: I know that the main idea is to rearrange the equation in such a way that you can use standard Tylor series such as: $e^x$ which is given as $\displaystyle \sum \frac{x^n}{n!}$ But how do you do this, and what is the method to tackle L series questions? Edit: After looking at some of the comments, would this method be correct: $f(z)= \dfrac{e^{z^2}}{z^3}$ $f(z)= \dfrac{1}{z^3} e^{z^2}$ $f(z)= \dfrac{1}{z^3} \displaystyle \sum_{n=0}^\infty \frac{(z^2)^n}{n!}$ L.series? $f(z)= \dfrac{1}{z^3} \biggl(1+z^2+\dfrac{z^4}{2!}+\dfrac{z^6}{3!}+...\biggr)$","['laurent-series', 'complex-analysis', 'calculus']"
1793017,Is an abelian subgroup of a finitely generated group finitely generated?,"Let $H <G $ be groups, G finitely generated and H abelian. Is H then finitely generated?",['group-theory']
1793045,"Real Analysis, Folland problem 1.4.20 Outer measures","Exercise 20 - Let $\mu^*$ be an outer measure on $X$, $M^*$ the $\sigma$-algebra of $\mu^*$-measurable sets, $\overline{\mu} = \mu^*|M^*$, and $\mu^+$ the outer measure induced by $\overline{\mu}$ as in (1.12) (with $\overline{\mu}$ and $M^*$ replacing $\mu_0$ and $\mathcal{A}$). a.) If $E\subset X$, we have $\mu^*(E)\leq \mu^+(E)$ with equality iff there exists $A\in M^*$ with $A\supset E$ and $\mu^*(A) = \mu^*(E)$. b.) If $\mu^*$ is induced from a premeasure, then $\mu^* = \mu^+$ (Use exercise 18a found here ) c.) If $X = \{0,1\}$ there exists an outer measure $\mu^*$ on $X$ such that $\mu^* \neq \mu^+$ Attempted proof a.) Let $E\subset X$. Then $$\mu^+(E) = \inf\{\sum_{1}^{\infty}\overline{\mu}(A_j): A_j\in M^*, E\subset \bigcup_{1}^{\infty}\}$$ Then by definition of the infimum there exists a sequence $\{A_j\}\in M^*$ and $E\subset \bigcup_{1}^{\infty}A_j$. Then by monotonocity \begin{align*}
\mu^*(E) &\leq \mu^*\left(\bigcup_{1}^{\infty}A_j\right)\\
&\leq \sum_{1}^{\infty}\mu^*(A_j) \ \text{(subadditivity)} \\
&= \sum_{1}^{\infty}\overline{\mu}(A_j) \ (\text{since} \ \overline{\mu} = \mu^*|M^*)
\end{align*}
It follows that $\mu^*(E)\leq \mu^+(E)$. If there exists an $A\in M^*$ such that $E\subset A$ and $\mu^*(A) = \mu^*(E)$, then $$\mu^+(E)\leq \overline{\mu}(A)$$
This is where I am stuck and my question is that I found a proof online that follows the same procedure but he says $$\mu^+(E)\leq \overline{\mu}(A) + \sum_{2}^{\infty}\overline{\mu}(\emptyset) = \mu^*(A) = \mu^*(E)$$ I don't understand this part if anyone could explain the logic to me. I am going to re-edit my answer to include (b) and (c) once I finish (a) completely. Please avoid just submitting a solution for this problem unless you think it will help me otherwise just answer the question I posed.","['real-analysis', 'measure-theory']"
1793052,Limit of $ \frac1x \int_x ^{2x}e^{-t^2}dt$,"What is the limit of the function $$\lim_{x\to 0} \ \frac1x \int_x ^{2x}e^{-t^2}dt$$
? I tried this problem by using gamma function. 
I couldn't find the integral.","['real-analysis', 'improper-integrals', 'analysis', 'limits']"
1793091,Is the Riemann integral defined with partitions with subintervals of the same length different from the general case?,"When considering Riemann sums we partition the closed interval $[a,b]$ in subintervals that don't necessarily have to have the same length. Then the Riemann integral is defined by taking the supremum of the lengths of the intervals go to zero. My question is, what is gained by not having the intervals in the partition not have the same lenght? Is there is some function that is Riemann integrable in the if the subintervals are of the same lenght, but not otherwise?","['integration', 'riemann-integration']"
1793104,Hilbert polynomial of iterated Veronese embedding,"Let $X=\mathbb{V}(x^2-yz)\subset\mathbb{P}^2$ and consider the Veronese embedding $Y=\mathcal{v}_2(X)\subset\mathbb{P}^5$. Find the Hilbert polynomial, and thus the degree, of $Y$. I know how we can read the degree of a projective variety off from the Hilbert polynomial, but I'm struggling to calculate the polynomial in this case.
I'm pretty sure that we can parametrise $$Y=\big\{[\lambda^2\mu^2,\mu^4,\lambda^4,\lambda\mu^3,\lambda^3\mu,\lambda^2\mu^2]\mid\lambda,\mu\neq0\big\}\cup\big\{[0:1:0:0:0:0],[0:0:1:0:0:0]\big\}.$$
Further, $X=\mathcal{v}_2(\mathbb{P}^1)$ and so $Y=(\mathcal{v}_2\circ\mathcal{v}_2)(\mathbb{P}^1)$, but I've never come across iterated applications of the Veronese embedding before. It looks like $Y\cong\mathcal{v}_4(\mathbb{P}^1)$ by ignoring the first/last coordinate in my parametrisation. But if I carry on naively, I argue as follows (trying to repeat an argument that seems to be commonly used for finding the degree of the Veronese embedding): We can restrict a degree $d$ polynomial on $\mathbb{P}^5$ to $Y$ and write it in terms of $\lambda,\mu$ and it will be a degree $4d$ polynomial.
   Thus $$h_Y(d)=\binom{2+4d}{2}=\frac{(2+4d)(1+4d)}{2}=8d^2+6d+1.$$
   Then the leading term is $8d^2=(16/2!)d^2$, which tells us that $\dim Y=2$ and $\deg Y=16$. This doesn't seem like a correct answer though. I know that the degree depends on the embedding, but this just seems like an unusually large number to get... Edit: Using the answer given to this question I'm pretty sure that the degree of $Y$ is equal to the degree of $\mathcal{v}_4(\mathbb{P}^1)=4^1=4$, which does disagree with my above argument. Edit 2: As another question, is it generally true that $(\mathcal{v}_d\circ\mathcal{v}_e)(X)\cong\mathcal{v}_{d\cdot e}(X)$? If, so, is this isomorphism always 'nice', in the sense that it induces an isomorphism of homogeneous coordinate rings?","['hilbert-polynomial', 'algebraic-geometry']"
1793112,"Is [a, a[ empty?","Is the segment $[a, a[$ equivalent to the point $\{a\}$ or the empty set $\varnothing$? Can one or other be formally proved? I was wondering because in computer science it is the empty set, as the loop for(x = a; x < a; x+=incr) never executes.","['order-theory', 'elementary-set-theory', 'computer-science']"
1793113,Ambiguity in definition of compactness,"I am struggling with the definition of compactness in a topological sense. Below is the definition presented in my lecture notes: A topological space $X$ is compact if every open cover has a finite
  subcover on $X$. Okay, this seems to make sense. But, an example is later presented in the notes: $X$ with the trivial topology $\tau = \{X, \varnothing \}$ is compact. Again, okay, this seems to make sense, as any open cover is finite, if we look at $\tau$. My question is: Does the cover come from the set $X$ or $\tau$? Apologies if my thought process seems unclear!","['general-topology', 'real-analysis', 'compactness', 'definition']"
1793138,Approximate area of overlap of two rotated rectangles,"I need to estimate the overlap ratio of two rectangles, each one with arbitrary size and orientation. I know how to perform the exact computation, using the Sutherland-Hodgman algorithm, which can be optimized for this case. Anyway as I need to use that function intensively and perfect accuracy isn't required (say 10% error can be tolerated), I was wondering if it cannot be evaluated in a faster way. If that helps, one can assume the same aspect ratio for both rectangles, and ratio of the areas not exceeding $4$.","['rectangles', 'geometry']"
1793169,Contraction Banach theorem,"Given the following function: $$g(z)=C*\begin{pmatrix}
         x^2+y^2-2 \\
         x^2-y^2-1 \\
         \end{pmatrix}+z, \; \; \;z=(x,y)\in [0.93,1.52]\times [0.41,1]$$ Prove that $g $ is a contraction for $C=\begin{pmatrix}
         c & c \\
         c & -c \\
         \end{pmatrix}$ I looked at the Jacobian matrix of $g$ which is : $J=C*\begin{pmatrix}
        2x & 2y \\
        2x & -2y \\
        \end{pmatrix}+\begin{pmatrix}
        1 & 0 \\
        0 & 1 \\
        \end{pmatrix}$ However, I didn't find any norm such that $||J||\lt1$ which would prove that $g$ is in fact a contraction. Would appreciate some help.","['multivariable-calculus', 'normed-spaces', 'banach-fixed-point']"
1793203,What is the name of the 3D matrices?,The name of a variable in the $\mathbb{R}$ is called scalar. Multiple scalars form a vector: $\mathbb{R}^n$ Two or more vectors form together a matrix: $\mathbb{R}^{n \times m }$ But what is the name of the 3 dimensional array of elments? ($\mathbb{R}^{n \times m \times k }$),"['matrices', 'linear-algebra', 'vectors']"
1793214,Sum of differentiable functions.,"True/False Question :  suppose that $f+g$ is differentiable at point $x_0$ therefore $f$ and $g$ are differentiable at $x_0$ I think this statement is false and I got a counter example : 
$f(x)=\begin{cases}
1 & \,\,x>0\\
x & \,\,x<0
\end{cases};
  g(x)=\begin{cases}
x\,\, & x-1>0\\
0 & \leq0
\end{cases}$
$(f+g)(x)=\begin{cases}
x\,\, & x>0\\
x\,\, & x<0\\
0 & x=0
\end{cases}\rightarrow\forall x\in\mathbb{R}\,\,\left(f+g\right)(x)=x,
 \left(f+g\right)'(0)=0$ Nor $f$ or $g$ are differentiable at $x_0=0$ but the sum is differentiable. However second True/false question got me very confused, it says : suppose that $f+g$ and $f$ is differentiable at point $x_0$ therefore $g$ are differentiable at $x_0$ and here I got confused, I can not find acounter example however I can not also find a proof","['derivatives', 'calculus', 'limits']"
1793218,Book reference for theory of differential equations (not Coddington's book),"I'm looking for references to study theory of ordinary differential equations. I'm looking for a similar book to Coddington's book, theory of ordinary differential equations but not this one, because this is a little old. I've already taken a course of (applied) differential equations but now I want to delve into the theory. I love Coddington's book but it is quite old. Also I like have more than one reference. Thank you in advance for your time.","['book-recommendation', 'reference-request', 'ordinary-differential-equations']"
1793253,Expected number of rolls for an unfair die to get all possibile values at least once,"Suppose that we have a 6-sided unfair dice, where rolling a 1 is twice as likely as rolling any other number, and the other numbers have the same likelihood. What is the expected number of rolls to get each value at least once? Thus, $$p(1) = 2/7\qquad p(2) = p(3) = \cdots = p(6) = 1/7$$ I understand how to approach this when the probabilities are the same, as it's just the Coupon collector's problem, but throwing in a non-uniform probability distribution throws me off. I know there is a general solution for this problem, but I can't seem to get any intuition as to why it's the case.","['coupon-collector', 'probability', 'probability-distributions']"
1793259,Is there any solution to find a condition for $f(x)=a+bx^n+cx^2-dx>0$ to always hold true?,"Okay, I am interested to know the criteria for a function to always hold $$f(x)=a+bx^n+cx^2-dx>0,$$
if it is given that $a, b, c>0$ and $n\in(-2,2)$ is some real number and $x>0$.  My idea was to find a minima of this function, and at minima $x_m$, the following condition has to be satisfied $$nbx_m^{n-1}+2cx_m-d=0,$$ and the function exhibits minima only when $$n(n-1)x_m^{n-2}>-2c.$$
Now to find a condition when $f(x)>0$ is always satisfied, my idea would be to find $x_m$ from second equation and replace it in the first equation. The problem is second equation is not solvable except for some special values of $n$. So my question is it this the dead end or there is something more that can be done to approach towards the solution? Any inputs would be greatly appreciated.","['derivatives', 'inequality', 'calculus']"
1793296,Why the probability distribution of a uniform random variable is the Lebesgue measure?,"Consider the random variable $X$ defined on the probability space $(\Omega, \mathcal{F}, P)$ distributed as a uniform on $[0,1]$. The probability distribution function of $X$ is defined as a map
$$
p:\mathcal{B}(\mathbb{R})\rightarrow [0,1]
$$
such that, for any $E\in \mathcal{B}(\mathbb{R})$, 
$$
p(E):=\mathbb{P}(X^{-1}(E))
$$
$p$ is a probability measure for $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ and $(\mathbb{R}, \mathcal{B}(\mathbb{R}), p)$ is a probability space. Let $\mu$ be the Lebesgue measure on $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$. Why $p(E)=\mu(E)$ for any $E\subseteq [0,1]$? Is that by definition? My attempt which I think is wrong is that: the probability density function of $X$ is
$$
f(t)=\begin{cases}
1 \text{ if $t$ $\in$ $[0,1]$}\\
0 \text{ otherwise}
\end{cases}
$$
We know that $f$ is the probability density function of $X$ with respect to $\mu$ meaning that
$$
f:=\frac{dp}{d\mu}
$$
Is this somehow related with having $p(E)=\mu(E)$ for any $E\subseteq [0,1]$?","['lebesgue-measure', 'probability-distributions', 'probability', 'measure-theory', 'uniform-distribution']"
1793308,Is there a simple solution to these 2 equations without trying all possible values?,"Now I have two equations and the computation is in a finite field GF( p ), where p is a prime. $x, y$ are unknown, and $a, b$ are known. ($0<y<p-1$, and $0<ax<p-1.$) $\begin{cases} 
 x^y = a, \\
 y^{ax} = b.
 \end{cases} 
$ Is there a simple solution to solve $x$ and $y$ other than trying all their possible combinations (which is $p^2$ tries)? Thanks a lot!","['finite-fields', 'finite-groups', 'logarithms', 'discrete-mathematics', 'exponentiation']"
1793315,"Show that $\sum\limits_{n=1}^{\infty}\frac{x}{1+n^2x^2}$ is not uniformly convergent in $[0,1]$","Show that $\sum\limits_{n=1}^{\infty}\frac{x}{1+n^2x^2}$ is not uniformly convergent in $[0,1]$. I was thinking in the direction of taking the maximum value of each term $\frac{x}{1+n^2x^2}$, which is $\frac{1}{2n}$, and of summing them. That is clearly a divergent series. But then those maximum values don't occur at the same value of $x$ for each term. For the $n$th term the maximum occurs at $x = \frac{1}{n}$. So, how to proceed?","['real-analysis', 'sequences-and-series', 'uniform-convergence']"
1793354,Show that $\left\| \exp(A)-\mathbf{1} \right\| \leq e^{\left\|A\right\|}-1$,"Have been attempting this question, just wondering if my answer looks alright. Question: Given $A \in \Bbb{K}^{n\times n}$ show that $\left\| \exp(A)-\mathbf{1} \right\| \leq e^{\left\|A\right\|}-1$ My proof goes as follows if $\left\| . \right\|$ is the matrix norm with the submultiplicative property $\left\|AB\right\| \leq \left\|A\right\| \left\|B\right\|$ $\left\|\exp(A)-\mathbf{1}\right\| = \left\|\mathbf{1} + A + \frac{1}{2!}A^{2} + \cdots - \mathbf{1} \right\| = \left\|A + \frac{1}{2!}A^{2} + \cdots \right\|$ We know by triangle inequality that $ \left\|A + \frac{1}{2!}A^{2} + \cdots \right\| \leq \left\|A\right\| + \frac{1}{2!} \left\|A\right\|^{2} + \cdots = e^{\left\|A\right\|} -1 $ Hence $\left\|\exp(A)-\mathbf{1}\right\| \leq e^{\left\|A\right\|} -1 $ Does this seem alright? Thanks in advance!","['matrices', 'abstract-algebra', 'analysis']"
1793358,"Show that open interval $(-1,1)$ is isomorphic to $(\mathbb{R},+)$","Define group structure on $G=(-1,1)$ by
$$a*b=\frac{a+b}{1+ab}$$
for any $a,b\in G$. Show that $G$ is isomorphic to $\mathbb{R}$ under addition. I've tried the obvious maps $f:G\rightarrow \mathbb{R}$ such as $f(x)=\tan(\pi x/2)$ or $f(x)=\frac{x}{1-x^2}$ but none of these seem to work. Any help would be appreciated, thanks.","['abelian-groups', 'abstract-algebra', 'real-analysis', 'group-theory']"
1793424,Prove $(x^2y+y^2z+z^2x)\left(\frac{1}{(x+y)^2}+\frac{1}{(y+z)^2} +\frac{1}{(z+x)^2}\right) \geqslant \frac94$,"$x,y,z > 0$ and $x+y+z=3$ , prove $$(x^2y+y^2z+z^2x)\cdot \left(\frac{1}{(x+y)^2}+\frac{1}{(y+z)^2} +\frac{1}{(z+x)^2}\right) \geqslant \frac94.$$ My immediate thought is that this inequality is similar to the famous Iran inequality $$(xy+yz+zx)\cdot \left(\frac{1}{(x+y)^2}+\frac{1}{(y+z)^2} +\frac{1}{(z+x)^2}\right) \geqslant \frac94$$ then if I can prove that $$x^2y+y^2z+z^2x \geqslant xy+yz+zx$$ for positive $x,y,z$ satistifes $x+y+z=3$ then the problem is solved. However, it turns out that $x^2y+y^2z+z^2x$ is neither always greater or lesser than $xy+yz+zx$ , so I get stuck here. I don't like solution involved computer or numerical methods. I will down vote all of answers that showing these methods","['algebra-precalculus', 'inequality']"
1793440,How can I prove this equation holds?,"As the final part of a big proof I got for uni homework: (It is an extra question, may be unsolvable) $$k^n<\sum_{i=0}^n\binom{n}ik^{n-i}(2^i-1)$$ My idea is to develop the right side into an $(x+y)^n$ type thing, but it is not in  a correct form for this. This is said (by my homeworks) to be true for each $n > 2$, and $k \in N+$ How can I prove/develop this equation? Edit: I tried induction, but failed to find a common expression. I tried simplifying into $(x+y)^n$ but failed doing that as well, because $(2^i-1)$ is not a $y^i$ This started from $k^n < (k+2)^n - (k+1)^n$","['combinatorics', 'proof-writing']"
1793463,Convolution: How to construct it for a given function?,"While working on my thesis my advisor handed me an unfinished paper which states the following: First , define the operators
  \begin{align*}
A_i &:= -\operatorname{div}(\sigma_i\nabla) \\
A_e &:= -\operatorname{div}(\sigma_e\nabla) \\
C &:= A_i + A_e \\
G &:\approx C^{-1} \\
R &:= \mathrm{Id} - CG
\end{align*}
  where the $\sigma$'s are tensors for an internal- and an external-""influence/action"". Second , consider the function 
  $$ \xi(t) := R \left[A_i u(t) - C v(t) + \epsilon^{-1}r(t) \right] \quad \text{on} \quad [0,T]\subset \mathbb{R}$$
  and the differential equation
  $$ \dot r (t) = \xi(t) -\epsilon^{-1}r(t) \quad \text{also on} \quad [0,T]\subset \mathbb{R}$$ 
  where $u$, $v$, $r$, and $\xi$ are elements of the Sobolev space
  $$ W^{1,2}\left(0,T,H^1(\Omega),H^1(\Omega)^*\right) := \left\{ \varphi \, \Big| \, \varphi \in L^2\left(0,T,H^1(\Omega)\right),\, \dot\varphi \in L^2\left(0,T,H^1(\Omega)^*\right) \right\}.$$ Thus , we can write
  \begin{equation}
 r(t) = \int_{\tau = 0} ^t \exp\left( -\tfrac{t-\tau}{\epsilon} \right) \xi (\tau)\, d\tau \quad \text{f.a.a} \quad t \in [0,T].\hspace{80pt} (1)
\end{equation}
  Further, using 
  $$
         \delta_t(x) := \begin{cases}
				      + \infty & \text{if } x = t \\
						0 			& \text{otherwise,}
	\end{cases} \quad\quad\quad \int_{-\infty}^{+\infty} \delta_t(x) \, dx = 1 $$
  we can write
  $$ \dot{r} (t) = \big( \xi * \left( \delta _t - \mu \right) \big) (t). $$ I can see that with
$$ \mu (t) := \left\{ \begin{array}{ll}
				     \epsilon^{-1}\exp\left(-\tfrac{t}{\epsilon} \right) & \mbox{for } t \geq 0 \\
					0   & \mbox{otherwise}
	\end{array}\right.$$
$(1)$ is a convolution $$r (t) = (\xi * \mu)(t)=\int_{-\infty}^{+\infty}\xi(\tau)\mu(t-\tau)\,d\tau$$
But, why does $r = \xi * \mu $ ? How is this calculated? or how is such a function $\mu$ constructed? Is there a standard method to express any given function as a convolution? Or a differential equation as a convolution?","['ordinary-differential-equations', 'convolution']"
1793466,Is $\mathbb{Z}_4 \times \mathbb{Z}_ {12} \times \mathbb{Z}_9$ cyclic?,"I find on internet this: $\mathbb{Z}_m \times \mathbb{Z}_n$ is cyclic if and only if $\gcd(m,n)=1$. Then I do the next steps: $\gcd(4,12,9)$ is 1. Then I assume that $\mathbb{Z}_4 \times \mathbb{Z}_{12} \times \mathbb{Z}_9$ is cyclic. I'm trying to find and element $(a,b,c)$, such that $a \in \mathbb{Z}_4,b \in  \mathbb{Z}_{12}$ and $c \in \mathbb{Z}_9 $. $\mathbb{Z}_4$ have two generators: <1>, <3> $\mathbb{Z}_{12}$ have four generators: <1>, <5>, <7>, <11> $\mathbb{Z}_{9}$ have four generators:<1>, <2>, <4>, <5>, <7>, <11> I thought that maybe the generator of $a \in \mathbb{Z}_4,b \in  \mathbb{Z}_{12}$ and $c \in \mathbb{Z}_9 $ would be a combination of the other generators. Im traying to find it but I don't get it. Then I suspect that the group is not cyclic.","['finite-groups', 'group-theory', 'cyclic-groups']"
1793512,Where did I go wrong in finding maximum?,"The question in my book is given as: If $x^2+y^2+z^2=1$ for $x,y,z$ belongs to all real numbers ($x,y,z$ are independent), then find the maximum of $x^3+y^3+z^3-3xyz$. What I tried: As all variables are independent I took the derivative of first equation and I got $x+y+z=0$. Then for maximum of second equation I took the derivative and equated to zero 
$$3x^2+3y^2+3z^2-3(xy+yz+zx)=0$$
and now for maximum
$$xy+yz+zx=1$$
(this is because $x^2+y^2+z^2=1$) We know that $(x+y+z)^3=x^3+y^3+z^3+3[(x+y+z)(xy+yz+zx)]-3xyz$ and here left hand side is zero since $x+y+z=0$ so we get
$x^3+y^3+z^3-3xyz=0$ but this is wrong! I think I made error by taking the derivative of $x^2+y^2+z^2$ but i don't know why it is wrong. Any help will be appreciated!","['derivatives', 'calculus']"
1793515,write down the expression for $\sin (15°)$ using the double angle formula.,"show that $\sin 15^\circ=\frac {\sqrt3 -1}{2\sqrt2}$ using $\cos2A=1-2\sin^2A$
However I got $\sin 15^\circ= \sqrt{\frac {2-\sqrt 3}{4}}$ instead.",['trigonometry']
1793545,Is this limit correctly computed?,"Here is the function: \begin{align*}
u(x,y,z)={}&\int_0^1\frac{\tau}{\sqrt{x^2+y^2+(z-\tau)^2}}\mathrm{d}\tau={} \\
{}={}&\sqrt{x^2+y^2+(z-1)^2}-\sqrt{x^2+y^2+z^2}-{} \\
&{}+z\log\left|\frac{z-1+\sqrt{x^2+y^2+(z-1)^2}}{z+\sqrt{x^2+y^2+z^2}}\right|,
\end{align*} where the last equality holds outside the $z$ axis, whereas on the $z$ axis the expression is just the first two terms, outside $\{0\}\times\{0\}\times[0,1]$, of course. I am now pretty convinced I calculated this correctly, and Wolfram agrees if I take the absolute values out, but since they are in a log when I differentiate they just go away, so it's like confirming in any case. I state this because my Higher Analysis course notes have different signs in various points, and the same goes for this pdf . Now I want to take the limit for $z\to0^+$ along surfaces of the form $(e^{-\frac\alpha{2z}}\cos\theta,e^{-\frac\alpha{2z}}\sin\theta,z)$. This is because I want to test its continuity at the origin. The two square roots converge to 1 and 0 respectively, since both $z$ and $e^{\frac\alpha{2z}}$ go to 0. I'm then left with the log, which I split into a sum of logs -- well yeah a difference since I have a quotient inside it. So here I go: \begin{multline*}
\lim_{z\to0^+}\left[-z\log\left(z-1+\sqrt{e^{-\frac{\alpha}{z}}+(z-1)^2}\right)+z\log\left(z+\sqrt{e^{-\frac{\alpha}{z}}+z^2}\right)\right]={} \\
=\lim_{z\to0^+}z\left[-\log\left(z-1+\sqrt{1+z^2-2z+e^{-\frac{\alpha}{z}}}\right)+\log\left(z+e^{-\frac{\alpha}{2z}}\sqrt{1+\frac{z^2}{e^{-\frac{\alpha}{z}}}}\right)\right]={} \\
\lim_{z\to0^+}z\left[-\log\left(z-1+1+\frac{z^2-2z+e^{-\frac{\alpha}{z}}}{2}+o\left(z^2-2z+e^{-\frac{\alpha}{z}}\right)\right)\right.+{} \\
{}+\left.\log e^{-\frac{\alpha}{2z}}+\log\left(\frac{z}{e^{-\frac{\alpha}{2z}}}+1+\frac{z^2}{2e^{\frac{\alpha}{2z}}}+o\left(\frac{z^2}{e^{-\frac{\alpha}{2z}}}\right)\right)\right]={}
{}=\lim_{z\to0^+}z\left[-\frac{\alpha}{2z}-\log\left(z+\frac{z^2-2z+e^{-\frac{\alpha}{z}}}{2}+o\left(z^2-2z+e^{-\frac{\alpha}{z}}\right)\right)\right.+{} \\
{}+\left.\underbrace{\log\left(\frac{z}{e^{-\frac{\alpha}{2z}}}+1+\frac{z^2}{2e^{\frac{\alpha}{2z}}}+o\left(\frac{z^2}{e^{-\frac{\alpha}{2z}}}\right)\right)}_{\text{Goes to zero since the argument is $1+o(1)$.}}\right]={}
{}=\lim_{z\to0^+}z\left[-\frac{\alpha}{2z}-\log e^{-\frac{\alpha}{z}}-\log\left(\frac{z}{e^{-\frac{\alpha}{z}}}+\frac{z^2-2z+e^{-\frac{\alpha}{z}}}{2e^{-\frac{\alpha}{z}}}+\frac{1}{e^{-\frac{\alpha}{z}}}o\left(z^2-2z+e^{-\frac{\alpha}{z}}\right)\right)\right].
\end{multline*} The first two terms give me a $\frac\alpha2$, and the rest should have a finite limit ($-\log\frac12$). So I would get the limit is $1+\frac\alpha2$. But I have two things giving me doubts: An older version of the notes and the pdf give this limit as $1+\alpha$, and the newer version (linked above) of the notes gives $\alpha$; I'm suspicious about that last small-o with the exponential under it: it does go to zero right? So is this all correct or is there something not quite right about it? Update I just realized that: No, that thing in general doesn't tend to zero, since if we multiply and divide by the small-$o$'s argument it becomes an infinitesimal fraction times $\frac{z^2-2z+e^{-\frac{\alpha}{z}}}{e^{-\frac{\alpha}{z}}}$ which goes to infinity; The small-$o$ in the other logarithm has an infinite as its argument. So I will start over. Now the expansion for the first logarithm is a huge mess, so I calculated a few terms with Wolfram ( 1 and 2 ) and, admitting I didn't mis-sum those messes, it should collapse into $\frac{7}{16}z^5+o(z^5)$, hence: \begin{multline*}
\lim_{z\to0^+}\left[-z\log\left(z-1+\sqrt{1+e^{-\frac{\alpha}{z}}+z^2-2z}\right)+z\log\left(z+\sqrt{e^{-\frac{\alpha}{z}}+z^2}\right)\right]={} \\
{}=\lim_{z\to0^+}z\left[-\log\left(\frac{7}{16}z^5+o(z^5)\right)+\log z+\log\left(1+\sqrt{\frac{e^{-\frac{\alpha}{z}}}{z^2}+1}\right)\right]={} \\
{}=\lim_{z\to0^+}z\left[-\log\frac{7z^5}{16}-\log\left(1+o(1)\right)+\log z+\log\left(1+1+\frac{e^{-\frac{\alpha}{z}}}{2z^2}\right)\right]={} \\
{}=\lim_{z\to0^+}\left[-z\log\frac{7}{16}-5z\log z-z\log(1+o(1))+z\log z+z\log(2+o(1))\right]=0.
\end{multline*} Is this huge mess right now? So my limit is 1 from the square roots plus 0 from the logarithms, thus 1. No $\alpha$. So it seems the whole thing in the notes is completely falling apart, because the proof that $u$ has no limit at the origin is now a non-proof, and even discontinuity with that $u(0,0,0)=2$ claimed by the notes is torn apart by the simple remark that: $$u(0,0,0)=\int_0^1\frac{\tau}{\sqrt{0^2+0^2+(0-\tau)^2}}\mathrm{d}\tau=\int_0^2\frac{\tau}{|\tau|}\mathrm{d}\tau=\int_0^1\operatorname{sgn}\tau\mathrm{d}\tau=\int_0^1\mathrm{d}\tau=1.$$ So am I making any mistake in the above or are the notes full of errors? Extras: computing the ugly integral First of all I will get rid of the $z$ axis so as to always have a strictly positive denominator. It is easy to verify that for $z\in(0,1]$ $u(0,0,z)$ gives a diverging integral. After all, the denominator has a zero in a place ($\tau=z$) where the numerator doesn't, and it's an absolute-value type of zero, so order one, so non-integrable. Let's see the origin. Wait, I've already done it above. So for $z\notin[0,1]$ we proceed as follows: \begin{align*}
u(0,0,z)={}&\int_0^1\frac{\tau}{\sqrt{0^2+0^2+(z-\tau)^2}}\mathrm{d}\tau=\int_0^1\frac{\tau}{|z-\tau|}\mathrm{d}\tau={} \\
{}={}&\begin{cases}
\int_0^1\frac{\tau}{\tau-z} & z<0 \\
-\int_0^1\frac{\tau}{\tau-z} & z>1 \\
\end{cases}=\begin{cases}
\int_0^1\frac{\tau-z}{\tau-z}\mathrm{d}\tau+z\cdot\int_0^1\frac{1}{\tau-z}\mathrm{d}\tau & z<0 \\
-\int_0^1\frac{\tau-z}{\tau-z}\mathrm{d}\tau-z\cdot\int_0^1\frac{1}{\tau-z}\mathrm{d}\tau & z>1
\end{cases}={} \\
{}={}&\begin{cases}
1+z\log|\tau-z|\Big|_0^1 & z<0 \\
-1-z\log|\tau-z|\Big|_0^1 & z>1
\end{cases}=\begin{cases}
1+z\log(1-z)-z\log(-z) & z<0 \\
-1-z\log(z-1)+z\log(z) & z>1 \\
\end{cases}={} \\
{}={}&\begin{cases}
1+z\log(1-\frac1z) & z<0 \\
-1-z\log(1-\frac1z) & z>1 \\
\end{cases}=\operatorname{sgn}(1-z)\cdot\left(1+z\log\left(1-\frac1z\right)\right).
\end{align*} Let us now get out of the $z$ axis: \begin{align*}
u(x,y,z)={}&\int_0^1\frac{\tau}{\sqrt{x^2+y^2+(\tau-z)^2}}\mathrm{d\tau}={} \\
{}={}&\int_0^1\frac{\tau-z}{\sqrt{x^2+y^2+(\tau-z)^2}}+z\cdot\int_0^1\frac{1}{\sqrt{x^2+y^2+(\tau-z)^2}}\mathrm{d}\tau={} \\
{}\underset{\substack{\Big| \\ t=\frac{z-\tau}{\sqrt{x^2+y^2}}}}{=}{\hspace{-.6cm}}&\sqrt{x^2+y^2+(\tau-z)^2}\Big|_0^1-z\cdot\int_{\frac{z}{\sqrt{x^2+y^2}}}^{\frac{z-1}{\sqrt{x^2+y^2}}}\frac{1}{\sqrt{1+t^2}}\frac{1}{\sqrt{x^2+y^2}}\sqrt{x^2+y^2}\mathrm{d}t={} \\
{}={}&\sqrt{x^2+y^2+(z-1)^2}-\sqrt{x^2+y^2+z^2}-z\log(t+\sqrt{1+t^2})\Big|_{\frac{z}{\sqrt{x^2+y^2}}}^{\frac{z-1}{\sqrt{x^2+y^2}}}={} \\
{}={}&\sqrt{x^2+y^2+(z-1)^2}-\sqrt{x^2+y^2+z^2}-{} \\
&{}+z\log\left(\frac{z-1}{\sqrt{x^2+y^2}}+\sqrt{1+\frac{(z-1)^2}{x^2+y^2}}\right)+{} \\
&{}+z\log\left(\frac{z}{\sqrt{x^2+y^2}}+\sqrt{1+\frac{z^2}{x^2+y^2}}\right)={} \\
{}={}&\sqrt{x^2+y^2+(z-1)^2}-\sqrt{x^2+y^2+z^2}-z\log\frac{z-1+\sqrt{x^2+y^2+(z-1)^2}}{z+\sqrt{x^2+y^2+z^2}}.
\end{align*} Interestingly enough, if I substitute $t=\frac{\tau-z}{\sqrt{x^2+y^2}}$ up there, I get the pdf's expression, the notes' expression having an extra term and a wrong log argument, and the limit above is much easier. But do those things actually differ by a constant? Naturally! Here is the difference: \begin{multline*}
\log(\tau-z+\sqrt{x^2+y^2+(\tau-z)^2})-(-\log(z-\tau+\sqrt{x^2+y^2+(z-\tau)^2}))={} \\
{}=\log((\tau-z+\sqrt{x^2+y^2+(\tau-z)^2})(z-\tau+\sqrt{x^2+y^2+(z-\tau)^2})))={} \\
{}=\log(x^2+y^2+(z-\tau)^2-(z-\tau)^2)=\log(x^2+y^2+z^2),
\end{multline*} which is constant in $\tau$!","['calculus', 'limits']"
1793548,"Concave up theorem for $f:A \to\mathbb R, A \subseteq \mathbb R $ - True or false?","I am a 1st year-2nd semester student of the department of Applied Mathematics @ NTUA. Some days ago, I had a really interesting conversation with one of my old school mathematics teacher about a theorem for concave up (or down) functions which is boldly stated in the book of the final grade of high-school, which is also studied for the panhellenic exams. The definition of a concave up function, is stated as : Let $f$ be a continuous function over $D \subseteq \mathbb R $ and also differentiable in the interval of $D$. We say that : The function $f$ is concave up , if the derivative of $f$,$f'$ is strictly increasing in the interval of $D$. According to that definition, the answer to the following question is TRUE : If $f$ is a concave up function over $D \subseteq \mathbb R $ and $1$,$2$ belong in the interval of D, then $f'(1) < f'(2)$. The formal definition for a concave up/convex function $f:X \to \mathbb R$ though, is : 
$ f(tx_1 + (1-t)x_2) \leq tf(x_1) + (1-t)f(x_2)$ $\forall x_1,x_2 \in X, \forall t \in [0,1] $. Now, my question is : Is the book's definition perfectly solid, or is it possible to find a function which is concave up BUT NOT diffentiable ? All I could think off were function that you cannot integrate in the set of standard mathematical equations, but that doesn't mean that by definition they aren't concave up (e.g. $f(x) = \int \int e^{-x^2}dx)$","['real-analysis', 'convex-analysis', 'functions', 'calculus', 'analysis']"
1793591,General Principles of Solving Radical Equations,"What are the general ways to solve radical equations similar to questions like $\sqrt{x+1}+\sqrt{x-1}-\sqrt{x^2 -1}=x$ $\sqrt{3x-1}+\sqrt{5x-3}+\sqrt{x-1}=2\sqrt2$ $\sqrt{\frac{4x+1}{x+3}}-\sqrt{\frac{x-2}{x+3}}=1$ Are there just a few known ways to solve them? How do you know the best way to solve such questions? I have trouble with a lot of square root equations, and when I ask them on this site, I get good answers, but for one question. I was wondering if there were any general principles of solving such questions.","['algebra-precalculus', 'radicals']"
1793596,An always increasing function,"Suppose I wanted a function $f(x)$ such that the following properties are had. $f(x)$ maps $\mathbb{R}\to\mathbb{R}$. $f(a)>f(b)$ if $a>b$. The function may or may not be continuous, but it doesn't have singularities. Is there a special name for this type of function and does it have any special properties?  (properties for all functions that meet the requirements.)","['special-functions', 'functions']"
1793615,On the GCD of two palindromes.,"I had an observation. Which I will discuss below. My question will be Is my observation correct? If so, how can one prove it? Observation: Consider the string of palindromes below: $100...01$ and $111...11$ I observed that: $gcd(100...01,111...11)=1$ if the length of the string is odd while $gcd(100...01,111...11)=11$ if the length of the string is even. Thank you so much for the big help.","['number-theory', 'palindrome', 'combinatorics', 'recreational-mathematics', 'elementary-number-theory']"
1793655,How to prove that $\sum_{n=1}^{\infty} \frac{(\log (n))^2}{n^2}$ converges?,"$$\sum_{n=1}^{\infty} \frac{(\log (n))^2}{n^2}$$ I know that this series converges (proof by Answer Sheet). However I need to prove it using comparison, integration, ratio or other tests. The integration test doesn't seem to help. The ratio test seemed to shed light except that it requires further proofs that $\frac{log(n+1)}{log(n)} < 1$ etc which makes me think this is not the best approach. I considered the fact that $\log(n) < \sqrt{n}$ but this just shows that it is less than a divergent series which doesn't help. Suggestions?","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
1793679,Ideal of 8 general points in $\mathbb{P}^2$,"I am working through chapter 3 of Eisenbud's Geometry of Syzygies. In the first example he makes the claim that the ideal of 8 general points in $\mathbb{P}^2$ is generated by two cubics and a quartic. Q: How can I see that this is the case? I am familiar with Bezout's theorem and the Cayley-Bacharach theorem, but I have never done one of these types of arguments on my own before.","['algebraic-geometry', 'commutative-algebra']"
1793682,Intuitively what is the second directional derivative?,"I'm thinking that the second directional derivative, if both dd's are evaluated in the same direction, will just give you the concavity (the second scalar derivative) in that direction.  Is that right? But what if the second directional derivative is evaluated in a different direction?  As in $D_{\vec v}D_{\vec u} f(\vec x)$ where $\vec v\ne \vec u$.  Then what would this thing mean?  Does it still have to do with concavity?",['multivariable-calculus']
1793701,What is the probability that all $n$ colors are selected in $m$ trials?,"I have a concrete problem, say, there are $n$ different balls ($n$ different colors to distinguish them), each ball will be selected uniformly at random. The way I choose a ball is that I randomly get a ball, and write down its color．Then I put  this ball back to the collection and choose a ball again. It won't stop until I get $m$ recorded colors. Suppose $m \geq n$. How many ways are there such that all $n$ colors were selected? And what is the probability that all $n$ different colors are recorded in the consecutive $m$ selections? My guts tell me there are $n^m$ combinations in total, but my rusty math halts me there.  Thank you in advance.","['combinatorics', 'probability']"
1793713,Question about conditional statements as applied to math?,"I was being bothered by the fact that $p \implies q$ is defined when $p$ is false, so I thought I would try an example in math terms to help me understand it; but I got a stuck: Let's define $p: x > 0$ $q:$ The equation $100 = \sqrt x$ has a solution in $\mathbb{R}$ Consider the statement $$p \implies q$$ $$\begin{array}{|c|c|c|}
\hline
p&q&p\implies q\\ \hline
T&T&T\\
T&F&F\\
F&T&T\\
F&F&T\\\hline
\end{array}$$ Now $(p \implies q) = T$ makes sense when $p$ and $q$ are both true, and this agrees with the truth table. But if we look at the third row of the truth table, we are told that $(p \implies q)$ should be true even if $p=F$ and $q=T$. However, mathematically the statement $$x \le 0 \implies \text{The equation $100 = \sqrt x$ has a solution in }\mathbb{R} $$ is of course false. How do we reconcile this? My only idea is that somehow one of $p, q$ is not a ""real"" statement or that they are not independent from each other, but according to what I've learned so far they are valid.","['logic', 'discrete-mathematics']"
1793736,How to Find Expected Value from a Joint Distribution?,"I am trying to solve the following problem: Let $X$ be a random variable from a contaminated normal distribution.
  That is, let $B ∼\text{Bernoulli}(p).$ Then $X|B = 0 ∼ N(µ, τ^2 )$ and $X|B = 1 ∼ N(µ, σ^2 )$. Calculate $\text{Cov}(X, B)$. Are $X$ and $B$ independent? Here we know $\operatorname{Cov}(X,B)=E(XB)-E(X)E(B)$
Here i found $$E(X)=\mu$$ and $E(B)=p,$.
But how can I find E(XB)? even if i can find $E(XB)$, then how to take decision that $X and B$ are independent or not because $Cov(X,B)=0$ doesn't imply they are independent.","['probability-theory', 'statistics', 'probability-distributions']"
1793794,Application of Combinatorics/Graph Theory to Organic Chemistry?,"Recently, I have been self-teaching graph theory and having an organic chemistry course at school. When I was learning isomer enumeration I found great resemblance between organic molecules and graphs. Every atom can be regarded as a vertex, with carbon vertices of $4$ degree, hydrogen atoms of $1$ degree etc. On the whole they just constitute a loopless yet usually not simple graph! While I am excited about this idea, I am unclear about how to apply graph theory (and some combinatorial techniques) to chemistry. Am I correct? Are there really applications of combinatorics or graph theory to organic chemistry, particularly isomer enumeration? If so how? Are there any books or resources from where I can learn about this amazing idea?","['applications', 'combinatorics', 'graph-theory', 'chemistry']"
1793807,Two Similar Measures on a Probability Space,"Let $(\Omega,\mathscr{F}, P)$ be a probability space and let $Q$ be
  another probability measure on $\mathscr{F}$, and let
  $\mathscr{F}_n=\sigma(Y_1,\ldots,Y_n)$ be a non-decreasing sequence
  of $\sigma$-fields in $\mathscr{F}$, for random variables
  $Y_1,Y_2,\ldots$ on  $(\Omega,\mathscr{F})$. Suppose that the distribution of the random vector
  $(Y_1,\ldots,Y_n)$ has densities $p_n(y_1,\ldots,y_n)$ and
  $q_n(y_1,\ldots,y_n)$, with respect to $n$-dimensional Lebesgue
  measure, under the measures $P$ and $Q$ respectively. Now, suppose the $Y_n$ are independent and identically distributed
  under both $P$ and $Q$. (So, for example, $p_n(y_1,\ldots,y_n)=p(y_1)\cdots p(y_n)$ for density $p$ on the line). If $P[Y_n \in H]\neq Q[Y_n\in H]$ for some $H \in \mathscr{R}^1$ and $Z_n=I_{[Y_n\in H]}$, then what happens to $n^{-1}\sum_{k=1}^n Z_k$ by the strong law of large numbers? I mean, does it converge to $P[Y_1 \in H]$ or to $Q[Y_1 \in H]$? Additionally, if $P$ dominates $Q$ when both are restricted to $\mathscr{F}_n$, can $P$ and $Q$ be mutually singular on $\mathscr{F}$ and how? Thanks and Regards!","['martingales', 'singularity', 'measure-theory']"
1793824,What does $X_j \approx X$ mean when used in this blog post?,"I was trying to learn disjoint union topology and used the following blog : https://drexel28.wordpress.com/2010/04/02/disjoint-union-topology/ The second theorem about disjoint topology says that if  {$\ X_j$} where $\ j$ $\ \varepsilon $$\ J$ be a class of topological spaces such that $\ X_j$$\ \approx$ $\ \mathcal X $ with $\ \psi_j$:$\ X_j$$\ \to$ $\ \mathcal X $ the homeomorphism.Then $\ \coprod$$\ X_j$ has the D.U.T and $\ \tau$ the discrete. What does $\ X_j$$\ \approx$$\ \mathcal X$ mean here ? Also I would like to know the mathematical definition of the word ""class "" and the places where we should use it instead of sets .","['general-topology', 'notation', 'elementary-set-theory']"
1793834,How to compute $(1 \cdot 3 \cdot 5 \cdots 97)^2 \pmod {101}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How to compute $(1 \cdot 3 \cdot 5  \cdots 97)^2 \pmod {101}$ in easiest and fastest way?","['number-theory', 'elementary-number-theory']"
1793848,"For a group of 7 people, find the probability that all of their birthdays do not occur in the winter using the stars and bars counting method","So for a group a 7 people, find the probability that all of their birthdays do not occur in the winter. That is, all of their birthdays occur either in the spring, summer or fall. Assume that the probability of being born in each season is equally likely. So the answer to this one is pretty simple as it is just $\frac{3}{4}^7=0.133$. However, I thought I would try it with a different method. I did it by using the stars and bars counting method. I counted how many ways there are to arrange 7 people into 3 seasons and also how many ways there are to arrange 7 people into 4 seasons. Ie. $$P(no\; birthdays\; in\; the\; winter) = \frac{\binom{7+3-1}{3}}{\binom{7+4-1}{4}}=0.4$$ Why is this not getting the same answer?","['combinatorics', 'probability']"
1793862,"Positive integers $a,b$ satisfying $a^3+a+1=3^b$",How to prove that $a=b=1$ is the only positive integer solution to the following Diophantine equation?$$a^3+a+1=3^b$$,"['number-theory', 'diophantine-equations', 'elementary-number-theory']"
1793871,Sum of real values of $x$ satisfying the equation $(x^2-5x+5)^{x^2+4x-60}=1$,"I have this equation from this paper (Q.63) Find the sum of all real values of $x$ satisfying the equation-$(x^2-5x+5)^{x^2+4x-60}=1$. My attempt- $(x^2-5x+5)^{x^2+4x-60}=(x^2-5x+5)^{(x-6)(x+10)}$ So, $x=6$ and $x=-10$ makes the power $0$ and hence the equation becomes one. So, the sum of the real values of $x$ satisfying the equation is $6+(-10)=-4$. But answer is $+3$. Where have I gone wrong?",['algebra-precalculus']
1793873,Find the number of 4 digit numbers of the form $abcd$ such that $ab+cd$ is even,"Let $n$ denote the number of 4 digit numbers of the form $abcd$ such that $ab+cd$ is even. Find the last digit of $n$. There are two cases. $ab,cd$ is odd. Which means $a,b,c,d \in \text{odd}$. Number of such cases is $5!=120$ $ab,cd$ is even. Atleast one of $\{a,b\}$ and atleast one of $\{c,d\}$ is even. If $a$ is even, $a\in\{2,4,6,8\}$. If $b$ is even $b\in\{0,2,4,6,8\}$. In both cases atleast one of $c,d$ has to be even. Number of ways is $\binom{2}{1}\binom{5}{1}\binom{10}{1}$. If $a$ is even, number of ways is $\binom{4}{1}\binom{10}{1}\cdot\binom{2}{1}\binom{5}{1}\binom{10}{1}$. If $b$ is even, number of ways is $\binom{9}{1}\binom{5}{1}\cdot\binom{2}{1}\binom{5}{1}\binom{10}{1}$. I am getting $0$ as the last digit of $n$. Answer given is $1$.",['combinatorics']
1793901,When is a mapping the proximity operator of some convex function?,"Sorry for cross-posting from MO . It's been a few days and the question hasn't received any attention there. So, is there a characterization of mappings $p : \mathbb R^n \rightarrow \mathbb R^n$ which are proximity operators ( in the sense of Moreau ) of l.s.c (extended) real-valued functions ?
That is, given $p : \mathbb R^n \rightarrow \mathbb R^n$, under what sufficient conditions does there exist an extended-valued l.s.c  convex function $g:\mathbb R^n \rightarrow (-\infty, +\infty]$ such that
$$p(x) \equiv \mathrm{prox}_g(x) := \underset{z \in \mathbb R^n}{\text{argmin }}\frac{1}{2}\|z-x\|_2^2 + g(z) \;?$$ N.B: Of course it's necessary that $p$ be firmly-nonexpansive, and have other classical properties of prox operators. Motivation: In regularization techniques for signal / image processing, one usually proposes to minimize an energy of the form $f(x) + g(x)$, where $x=x^*$ is the image to be recovered from noisy / corrupted measures, $f(x)$ is a data fidelity term and measures the ""fit"" of the model, while $g(x)$ is a regularization term that imposes some structural constraints. For example, one can take $f(x) = \frac{1}{2}\|y-Ax\|_2^2$, under a additve Gaussian-noise assumption, where $y$ is the observed image and $A$ is a sensing linear operator, so that $y \approx Ax + \text{ noise}$, etc., etc. A brilliant idea that has been proposed in Social Sparsity! is to impose the penalty $g$ only implicitly, by instead constructing its proximal operator $p(x)$, i.e by stating the intended shrinkage action of $g$ on the model coefficients $x_j$. For a concrete example, think of a (fictional) world in which we didn't know about the $\ell_1$ norm, but instead decided to invent the Lasso by stating that the prox of the (unknown) $\ell_1$ penalty should shrink the coefficients according to the soft-thresholder $$(p(x))_j = st_{\lambda}(x_j) = sign(x_j)(|x_j| - \lambda)_+,$$ where $\lambda > 0$ is a regularization parameter and $sign(x_j): = -sign(-x_j) = 1$ if $ x_j > 0$ and $0$ else. Note that the above prox would correspond to a penalty $g(x) = \lambda \|x\|_1$, and acts component-wise only because we're assuming (in this example) a separable penalty. The question is then: How to show that $st_{\lambda}$ actually corresponds to the proximal operator of some penalty function. Update I've accepted an answer here , under the original MO post.","['reference-request', 'signal-processing', 'convex-analysis', 'functional-analysis', 'image-processing']"
1793906,"Subset (Comprehension, Separation) Axiom and Definability","I am reading Moshe Machover's book, Set Theory, Logic, and Their Limitations , and on p. 19 he states that if $A\cup B$ is a set, then $A$ and $B$ are too by the Subset Axiom.  But this confuses me.  Clearly, $A$ and $B$ are both subsets of $A\cup B$.  But how do we know that they are definable?  (Similarly, if $A$ is a class of sets, and $\cup A$ is a set, then I take it that $A$ is supposed to be a set by Powerset and Subset.  But my question re-arises here.)  I'm obviously missing something basic.  Thanks, in advance.",['elementary-set-theory']
1793967,Showing that the Hopf fibration is a non-trivial fibre bundle,"I want to show that the Hopf bundle
$$ \mathbb{S}^1 \rightarrow \mathbb{S^3} \rightarrow \mathbb{S}^2$$
is non-trivial as a principal fibre bundle. I have seen hints of several different approaches: Hopfs original approach, using linking numbers, see Hopf fibration and $\pi_3(\mathbb{S}^2)$ . Hopf invariant. Cohomology. I want to keep it simple. My gut says cohomology is my best bet (I am slightly familiar with de Rahm Cohomology). Unfortunately, I am having trouble finding sources that treat this on my level (without a lot of general theory I think I don't need). I have the following books: The Topology of Fibre Bundles , Steenrod. Fibre Bundles , Husemoller. Manifold and Differential Geometry , Jeffry Lee. What is the bare minimum of theory I need to to get to this result? What route would you advise? I am an undergraduate working on a Bsc thesis.","['obstruction-theory', 'fiber-bundles', 'hopf-fibration', 'group-cohomology', 'differential-geometry']"
1793975,Integral conversion to polar coordinates - bounds $\int\limits_0^1 \int\limits_0^1\sqrt{x^2+y^2}\ dxdy$ [duplicate],"This question already has answers here : Evaluating $\int_{0}^{1}\int_{0}^{1}\sqrt{x^{2}+y^{2}}dxdy$ using polar coordinates. (3 answers) Closed 4 years ago . I have an integral $$\int_0^1 \int_0^1\sqrt{x^2+y^2}\ dxdy $$ and its result is $\approx0.765...$ I convert it to polar coordinates and get $$\int_a^b \int_c^dr\ drd\phi $$ But how can I compute $a,b,c,d$ ?","['multivariable-calculus', 'integration', 'polar-coordinates']"
1793985,How to show that any rectangle in ellipse must be oriented parallel to axes?,"A problem which is often given as an exercise for students learning about calculus and finding extrema, is to find maximal possible area of a rectangle inside an ellipse. Such question was asked, for example, here: Find the area of largest rectangle that can be inscribed in an ellipse (A similar problem in three dimensions is also often asked: Dimensions of a box of maximum volume inside an ellipsoid .) The solution usually starts by stating that we the rectangle must be oriented in such way that the sides are parallel to the ellipse, which gives a simple expression for the area. Even though the fact that any rectangle inscribed in an ellipse must be oriented in this way seems intuitively clear, I would like to see an argument showing that this is indeed the case. (I have posted as an answer my attempt using analytic geometry.) Of course, there is one obvious exception. Rectangle inscribed in a circle can be rotated in any direction we want. So we should assume that the semiaxes of the ellipse have different lengths. Here is a picture illustrating the situation (shamelessly stolen from this post ):","['conic-sections', 'rectangles', 'geometry']"
1794001,Bessel's Differential Equation - textbook queries:,"In order to ask this question I must first give some background information as written in my text book: Given Bessel's Differential equation: $$x^2y^{\prime\prime}+xy^{\prime}+(x^2-p^2)y=0$$ or
  $$x(xy^{\prime})^{\prime}+(x^2-p^2)y=0\tag{1}$$ where $p$ is a constant, but not necessarily an integer. We find a generalized power series for $(1)$ by writing only the general terms in the series for $y$ and the derivatives we need in $(1)$, we have
  $$y=\sum_{n=0}^\infty a_nx^{n+s}$$
  $$y^{\prime}=\sum_{n=0}^\infty a_n(n+s)x^{n+s-1}$$
  $$xy^{\prime}=\sum_{n=0}^\infty a_n(n+s)x^{n+s}$$
  $$(xy^{\prime})^{\prime}=\sum_{n=0}^\infty a_n(n+s)^2x^{n+s-1}$$
  $$x(xy^{\prime})^{\prime}=\sum_{n=0}^\infty a_n(n+s)^2x^{n+s}$$
  We now substitute the above into $(1)$ and tabulate the coefficients of powers of $x$: \begin{array}{|c|l:l|}\hline
&  x^s & x^{s+1} & x^{s+2} & \cdots & x^{s+n} \\
\hline
x(xy^{\prime})^{\prime} & s^2a_0 & (1+s)^2a_1 & (2+s)^2a_2 &  & (n+s)^2a_n  \\
x^2y &  &  & a_0 & & a_{n-2}  \\
-p^2y & -p^2a_0 & -p^2a_1 & -p^2a_2 & & -p^2a_n  \\
 \hdashline
 \hline
\end{array} The coefficient of $x^s$ gives the indical equation and the values of $s$:
  $s^2-p^2=0\implies s=\pm p$. The coefficient of $x^{s+1}$ gives $a_1=0$. 
  The coefficient of $x^{s+2}$ gives $a_2$ in terms of $a_0$, etc. But we may as well write the general formula from the last column at this point. We get:$$\left[(n+s)^2-p^2\right]a_n+a_{n-2}=0$$ or $$a_n=-\frac{a_{n-2}}{(n+s)^2-p^2}\tag{2}$$ First we shall find the coefficients for the case $s=p$. From $(2)$ we have $$a_n=-\frac{a_{n-2}}{(n+p)^2-p^2}=-\frac{a_{n-2}}{(n^2+2np)}=-\frac{a_{n-2}}{n(n+2p)}\tag{3}$$ Since $a_1=0$, all odd $a$'s are zero. For even $a$'s it is convenient to replace $n$ by $2n$; then from $(3)$ we have $$a_{2n}=-\frac{a_{2n-2}}{2n(2n+2p)}=-\frac{a_{n-2}}{2^2n(n+p)}\tag{4}$$ The formulas for the coefficients can be simplified by the use of the $\Gamma$ function (Gamma function) notation by recalling that $\Gamma(p+1)=p\Gamma(p)$ for any $p$ so $$\Gamma(p+2)=(p+1)\Gamma(p+1)$$
  $$\Gamma(p+3)=(p+2)\Gamma(p+2)=(p+2)(p+1)\Gamma(p+1)$$
  $$\Gamma(p+4)=(p+3)\Gamma(p+3)=(p+3)(p+2)(p+1)\Gamma(p+1)$$ and so on. Then from $(4)$ we find $$a_2=-\frac{a_0}{2^2(1+p)}=-\frac{a_0\Gamma(1+p)}{2^2\Gamma(2+p)}$$
  $$a_4=-\frac{a_2}{2^3(2+p)}=\frac{a_0}{2!\cdot2^4(1+p)(2+p)}=\frac{a_0\Gamma(1+p)}{2!\cdot2^4\Gamma(3+p)}$$
  $$a_6=-\frac{a_4}{3!\cdot2(3+p)}=-\frac{a_0}{3!\cdot2^6(1+p)(2+p)(3+p)}=-\frac{a_0\Gamma(1+p)}{3!\cdot2^6\Gamma(4+p)}$$ and so on. Then the series solution (for the $s=p$ case) is $$\begin{align}&y=a_0x^p\Gamma(1+p)\left[\frac{1}{0!\cdot\Gamma(1+p)}-\frac{1}{1!\cdot\Gamma(2+p)}\left(\frac{x}{2}\right)^2+\frac{1}{2!\cdot\Gamma(3+p)}\left(\frac{x}{2}\right)^4-\frac{1}{3!\cdot\Gamma(4+p)}\left(\frac{x}{2}\right)^6+\cdots\right] \\&= a_02^p\left(\frac{x}{2}\right)^p\Gamma(1+p)\left[\frac{1}{\Gamma(1)\Gamma(1+p)}-\frac{1}{\Gamma(2)\Gamma(2+p)}\left(\frac{x}{2}\right)^2+\frac{1}{\Gamma(3)\Gamma(3+p)}\left(\frac{x}{2}\right)^4-\frac{1}{\Gamma(4)\Gamma(4+p)}\left(\frac{x}{2}\right)^6+\cdots\right]\end{align}$$ Where we have inserted $\Gamma(1)$ and $\Gamma(2)$ (which are both equal to $1$) in the first $2$ terms and written $x^p=2^p\left(\dfrac{x}{2}\right)^p$ to make the series appear more systematic. If we take $$a_0=\frac{1}{2^p\Gamma(1+p)}=\frac{1}{2^pp!}$$ then $y$ is called the Bessel function of the first kind of order $p$, and written $J_p(x)$ Then $$J_p(x)=\frac{1}{\Gamma(1)\Gamma(1+p)}\left(\frac{x}{2}\right)^p-\frac{1}{\Gamma(2)\Gamma(2+p)}\left(\frac{x}{2}\right)^{2+p}+\frac{1}{\Gamma(3)\Gamma(3+p)}\left(\frac{x}{2}\right)^{4+p}-\frac{1}{\Gamma(4)\Gamma(4+p)}\left(\frac{x}{2}\right)^{6+p}+\cdots$$ or $$\fbox{$J_p(x)=\sum_{n=0}^\infty\frac{(-1)^n}{\Gamma(n+1)\Gamma(n+1+p)}\left(\frac{x}{2}\right)^{2n+p}$}\tag{5}$$ We have found just one of the two solutions of Bessel's equation, that is, the one when $s=p$; we must next find the solution when $s=-p$. It is unnecessary to go through all the details again; we can just replace $p$ by $-p$ in $(5)$. In fact, the solution when $s=-p$ is usually written $J_{-p}(x)$. So from $(5)$ we have $$\fbox{$J_{-p}(x)=\sum_{n=0}^\infty\frac{(-1)^n}{\Gamma(n+1)\Gamma(n+1-p)}\left(\frac{x}{2}\right)^{2n-p}$}\tag{6}$$ I understand all of the above. My question is regarding the following extract: If $p$ is not an integer $J_p(x)$ is a series starting with $x^p$ and $J_{-p}(x)$ is a series starting with $x^{-p}$. Then $J_p(x)$ and $J_{-p}(x)$ are two independent solutions and a linear combination of them is a general solution. 
  $\bbox[#AFF]{\text{But if }p\text{ is}\text{ an integer, then the first few terms in }{J_{-p}(x)}\text{ will be zero, as in the denominator }\,\Gamma(n-p+1)\text{ is }\Gamma \text{ of a negative number, which is infinite.}}$
  $\bbox[#AFA]{\text{You can show that }J_{-p}(x)\text{ starts with the term }x^p\text{ for integer }p\text{ just as } J_{p}(x)\text{ does,}}$$\bbox[yellow]{\text{ and that }J_{-p}(x)=(-1)^pJ_p(x)\text{ for integer }p}$. For the blue highlighted part it says the ""first few terms in $J_{-p}(x)$ will be zero""; But how do they know this? This can only be true by my logic iff $p\gt 2$. Yet we are given no restriction on $p$ other than $p \gt 0$; Why is it only the first few (two) terms that are zero? For the green highlighted part; by my logic $J_{-p}(x)$ always starts with $x^{-p}$ and not $x^p$. What am I missing here? Lastly for the yellow part: I'm sorry but I have simply no idea how to show that $J_{-p}(x)=(-1)^pJ_p(x)$, and much to my annoyance this is the most important part of this post. I have already checked the errata list for this book and I can tell you that none of the above queries of mine are due to book errors. If anyone is able to provide me with some hints/advice on addressing some/all/any of the $3$ queries above I will be most grateful. I have only just started to learn about Bessel's equation, so my knowledge is somewhat limited (apologies). Kindest Regards.","['special-functions', 'recurrence-relations', 'ordinary-differential-equations', 'bessel-functions']"
1794007,Expected number of rolls to get all colors on 6-sided die colored in with 3 colors,"If I have a die that has 3 red sides, 2 blue sides, and 1 green side, how many rolls do I expect until every color has appeared at least once? I have run some tests and I’m getting numbers around 7.31, but clearly I’m looking for a mathematical solution. Thanks in advance.",['probability']
1794012,Minimal Normal Subgroups of an elementary abelian p-group,"Can you explain/prove, why the number of minimal normal subgroups of an elementary abelian $p$ -group of order $p^n$ (for instance of $\mathbb{Z_p}^n$ ), is exactly $(p^n-1)/(p-1)$ ? I know that it seems trivial but i can't see why. It is an exercise from Dixon & Mortimer book ""Permutation Groups"" pg.120.","['abelian-groups', 'normal-subgroups', 'p-groups', 'group-theory']"
1794025,Show that $Z(G) = \cap_{a \in G} C(a)$,Show that $Z(G) = \cap_{a \in G} C(a)$ . Let $a \in Z(G)$ . Then $ax=xa$ for all $x$ in $G$ . In particular we can say that $ax_1=x_1a$ and $ax_2=x_2a$ and $ax_3=x_3a$ and so on ( $x_i$ are elements of $G$ ). This is nothing but intersection of all subgroups of form $C(a)$ . However I doubt my way of doing this question. Please guide me Thanks,"['abstract-algebra', 'self-learning', 'group-theory']"
1794044,Given $f(x) = x + |x|$ for what values of $x$ is $f$ differentiable,"Problem : Given $f(x) = x + |x|$ for what values of $x$ is $f$ differentiable? For the sake of generality, let's assume that it is unknown to us that $|x|$ is not differentiable at $x = 0$ Attempted Solution : Using the definition of differentiability, a function is differentiable over an interval $I$ $\text{iff}$ $$f'(x) = \lim_{h \to 0} \frac{f(x+h)-f(x)}{h}, \ \ \forall x\in I$$ Now implicitly this definition of differentiability requires $$\lim_{h\to 0^+} \frac{f(x+h)-f(x)}{h} = \lim_{h\to 0^-} \frac{f(x+h)-f(x)}{h}$$ Therefore $f$ will be differentiable only when $$\lim_{h\to 0^+} \frac{(x + h + |x+h|)-(x + |x|)}{h} = \lim_{h\to 0^-} \frac{(x - h + |x-h|)-(x + |x|)}{h}$$ But it is unclear what to do next as $x$ is just arbitrary
$$
\begin{equation}
\begin{aligned}
|x+h| &= \begin{cases}x+h & \text{if} & x \geq -h\\ -x-h & \text{if} & x < -h \end{cases} \\
&= \begin{cases}x+h & \text{if} & x \geq 0\\ -x-h & \text{if} & x < 0 \end{cases}
\end{aligned}
\end{equation}$$ A Wrong Solution : We could take the derivative of $f$, (and evaluate the domain of the derivative $f'(x)$ to values for which it is defined), using the rules of differentiation, but we would get a wrong answer. $$f'(x) = \frac{|x| + x}{|x|}$$
$$\implies f'(x) = \begin{cases}
2 & \text{if} & x \geq 0 \\
0 & \text{if} & x < 0
\end{cases}$$ This implies the derivative $f'(0)$ exists, when it does not as per the definition of differentiability. Why is that so? Questions: How can a solution be found using the definition of differentiablity? Why does taking the derivative of $f$, $f'(x)$ and evaluating it's domain, not give the correct values of $x$ for which $f$ is differentiable?","['derivatives', 'real-analysis', 'limits', 'calculus', 'continuity']"
1794065,Partitioning positive integers using digital rivers,"I stumbled on a very simple computer science question from the British Informatics Olympiad for schools and colleges. Embedded in it is a very interesting numbers theory problem. Here is the interesting part: A digital river is a sequence of numbers where the number following n is n plus the sum of its digits. For example, 12345 is followed by 12360, since 1+2+3+4+5 = 15. If the first number of a digital river is k we will call it river k . For example, river 480 is the sequence beginning {480, 492, 507, 519, ...} and river 483 is the sequence beginning {483, 498, 519, ...}. Normal streams and rivers can meet, and the same is true for digital rivers. This happens when two digital rivers share some of the same values. For example: river 480 meets river 483 at 519, meets river 507 at 507, and never meets river 481. Every digital river will eventually meet river 1, river 3 or river 9. Source: http://www.olympiad.org.uk/papers/1999/bio/bio99r1q1.html It is quite easy to show that rivers 1, 3 and 9 cannot meet. However, it appears to be more difficult to prove the remaining part: How to prove that for any n > 0, river n eventually meets river 1, 3 or 9?","['decimal-expansion', 'sequences-and-series', 'elementary-number-theory']"
1794095,Showing 2 Distributions are the Same,"Let $X_1, X_2, \dots$ be i.i.d. exponentially distributed RVs. For $n = 1,2,\dots$ consider: $Y_n := \max(X_1, X_2, \dots, X_n)$ $U_n := \sum_{i=1}^{n}\frac{X_i}{i}$ Show that $Y_n$ and $U_n$ have the same distribution What I've tried: $P(Y_n<y)= P(X_i<y)^n = (1- e^{\lambda y})^n => P(Y_n=y) = n(1- e^{\lambda y})^{n-1}$ But I get stuck with $U_n$ . I tried an MGF, $U_n$ evaluates nicely but then $Y_n$ gets messy. Any thoughts?","['probability', 'probability-distributions']"
1794098,The reason behind the definition of manifold,"I was going thorough the definition of a manifold and needless to say it wasn't something that I could digest at one go.
Then I saw the following Quora link and Qiaochu's illustrative answer . It was great to see the motivation behind the concept of manifold. Then I looked at the definition of manifold that I have at my disposal which is the following: A topological space $M$ is an $n$-dimensional real manifold if there is a family of subsets $U_\alpha$, $\alpha \in A$, of $\mathbb{R}^n$ and a quotient map $f \colon \coprod_\alpha U_\alpha \to M$ such that $f|_{U_\alpha}$ is a homeomorphism onto the image for all $\alpha$. I understand that we are trying to conceptualize about a bigger space which when looked at a very small region looks like something else (a euclidean space) thereby giving a possibly incorrect bigger picture about the shape. Now what was the reason behind introducing disjoint union in this definition. Can someone help me to get in terms with this idea?
I went through this related question and Samuel's brilliant answer to it. Leaving aside the points about Haussdorff and second countable spaces I could draw that homeomorphism is the concept that we use to convey the similarity between two spaces. I can loosely convince myself that the existence of homeomorphism between two spaces means the similarity in the pattern of open sets in the two spaces. (I might not be expressing what I feel about it.) But still then can anyone make it a bit more elaborate as to why we use homeomorphism here? If we divided this bigger surface, let's say earth into smaller circles, then I can see that we wouldn't have gotten the local shape same everywhere, somewhere it would have been a circle and some other points it would have been an area in between four circles or maybe something else. But are these local shapes homeomorphic to $\mathbb{R}^2$? What are other shapes which wouldn't have been homeomorphic to $\mathbb{R}^2$? I guess "" What happens when two spaces are homeomorphic ?"" would be a good way to start the discussion.","['manifolds', 'general-topology']"
1794123,Do men or women have more brothers?,"Do men or women have more brothers? I think women have more as no man can be his own brother. But how one can prove it rigorously? I am going to suggest some reasonable background assumptions: There are a large number of individuals, of whom half are men and half are women. The individuals are partitioned into nonempty families. The distribution of the sizes of the families is deliberately not specified. However, in each family, the sex of each member is independent of the sexes of the other members. I believe these assumptions are roughly correct for the world we actually live in. Even in the absence of any information about point 3, what can one say about relative expectation of the random variables “Number of brothers of individual $I$, given that $I$ is female” and “Number of brothers of individual $I$, given that $I$ is male”? And how can one directly refute the argument that claims that the second expectation should almost certainly be smaller than the first, based on the observation that in any single family, say with two girls and one boy, the girls have at least as many brothers as do the boys, and usually more.","['combinatorics', 'probability']"
1794134,Differential Equations: Solve $(x^2-1){dy\over dx} + 2xy = x$,I managed to get to $$y = {x^2+2C\over 2x^2-2}$$ Not sure if this is right. Help would greatly be appreciated.,"['ordinary-differential-equations', 'calculus']"
1794155,Showing that $\log(n)^{\log(\log(n))} \in \mathcal{O}(n)$,"I want to show that $$\log(n)^{\log(\log(n))} \in \mathcal{O}(n)$$ where $n \in \mathbb{N}_{≥2}$, and $\mathcal{O}$ is the big-O-notation. It seems like a relatively simply statement, but so far, I've had no luck. I first started with the limit $\lim_{n \to \infty} \frac{\log(n)^{\log(\log(n))}}{n}$. In order to show the statement, it would be sufficient to show that this limit is $< \infty$. I searched for any way to simplify the expression, but so far couldn't find any. Sure we can write the limit as $\lim_{n \to \infty} \frac{\log(n)}{n^{\frac{1}{\log(\log(n))}}}$, but that doesn't seem to help either. Next I thought about considering the derivative of $\log(n)^{\log(\log(n))}$. If it's derivative is bounded, then it grows at most linearly, which would also show the statement. Unfortunately though, it's derivative is (according to Wolframalpha) $\frac{2 \log^{\log(\log(n))-1} (n)\log(\log(n))}{n}$ which looks even more complicated than the limit I wanted to examine before, and it is (to me at least) not visible right away why this derivative must be bounded. I also thought about induction arguments. When looking at a graph of the function, I noticed that $\log(n)^{\log(\log(n))}$ gets more and more flat for  higher $n$, so maybe I can use an induction argument by fixing a fitting $c \in \mathbb{R}_{> 0}$ and showing that $\log(n)^{\log(\log(n))} ≤ c n$ for almost all $n \in \mathbb{N}$? The way this exercise was posed to me makes me think that I'm probably thinking way too complicated and that there is a much easier way to show the desired statement, but so far, I haven't found any way that works.","['asymptotics', 'calculus', 'limits']"
1794168,Laplace-Beltrami operator on a circle - Explanation,"I would like to find the spectrum of a circle. I know that the Laplace-Beltrami eigenvalue problem for unit circle is equivalent to the regular Laplacian eigenvalue problem for  the interval of the length $2\pi$ with periodic Boundary conditions. In a sense, the Laplace-Beltrami operator (i.e. $∆ =\frac{1}{\sqrt{G}} \sum_{i,j=1}^n \frac{\partial}{\partial_i} (\sqrt{G} g^{ij} \frac{\partial}{\partial_i})$) on circle can be viewed as a Laplacian of a function depending on the arc length. I am not familiar with the use of the Laplace-Beltrami operator and Helmholtz equation. Some things I know is in the definition of page $1$ of pdf . The first formula of the pdf, the definition of the $Δ$ operator in manifolds in term of local coordinates $x_i$ and the metric $g$ and I'd say that if the manifold is a $1$-manifold homeomorphic to the circle, we can choose the coordinates such that $g$ is constant and $=1$, and it reduces again to the eigenvalue equation $h″=λh$ with $h:ℝ→ℂ$ and  periodic. Is there anyone could solve it in using these tools?","['spectral-theory', 'laplacian', 'ordinary-differential-equations']"
1794175,arccot limit: $\sum_{r=1}^{\infty}\cot ^{-1}(r^2+\frac{3}{4})$,"I have to find the limit of this sum:
$$\sum_{r=1}^{\infty}\cot ^{-1}(r^2+\frac{3}{4})$$ I tried using sandwich theorem , observing: $$\cot ^{-1}(r^3)\leq\cot ^{-1}(r^2+\frac{3}{4})\leq\cot ^{-1}(r^2)$$ Now when I was calculating the limit of left hand expression, I convert it to $\tan^{-1}$, by using:
 $$\tan^{-1}\frac{1}{x} = \cot^{-1}x$$ but couldn't sum up the terms of arctan series. How can I proceed? Is there any better way ?","['summation', 'trigonometry', 'limits']"
1794186,Sketching the graph of $\cos(4\pi t-\pi)$,"I am struggling to sketch the graph of $\cos(4\pi t-\pi), -3<t<3$. Here is what I have tried: $w=4\pi$ $f=2$ $T=0.5$ So the graph will start from $0$, and form two cycles between $0$ and $1$, two cycles between $1$ and $2$, and so on. But I am missing out on the shift of $\pi$ to the right. Could someone please help me visualize and sketch this graph? Thanks","['trigonometry', 'calculus']"
1794197,"How to work with trig functions when dealing with limits tending to a point, without using L'Hôpital's rule","Past Paper Question: For each of the following functions f , determine whether $\lim_{x\to a}f(x)$
exists, and compute the limit if it exists. In each case, justify your answers. a) $f(x)= \dfrac{2\tan^2(x)}{x^2+2x^3}$ $\text{where a = 0}$ b)$f(x)= \dfrac{\sin(\left| x \right|)}{x^2+\sin(\left| x \right|)}$ $\text{where a = 0}$ Attempt: I can't use L'Hôpital's rule, but I know from my graphical calculator that the limits of a) = $6$ and b) = $1$. Not sure how to show this, from past experience I know you have to separate the $\tan(x)$ function into $\cos(x)$ and $\sin(x)$. But apart from that I have no idea.","['real-analysis', 'trigonometry', 'calculus', 'limits']"
1794228,"$\lim_{n \to\infty} E(|S_n|)= \infty$ for $(X_n)_{n \geq 1}$ i.i.d. real RV with Var$(X_1)=1, E(X_1)=0$","Problem: For $(X_n)_{n \geq 1}$ i.i.d. real RV with Var$(X_1)=1$ and $E(X_1)=0$ and $S_n$ denoting the partial sum of the RVs we have $$\lim_{n \to \infty} E(|S_n|)=\infty $$ My Approach: I have managed to show, thanks to the central limit theorem , that $\exists p >0$ such that for large enough $n \in \mathbb{N}$ (i.e. $n \geq n_0$) we have  \begin{align}P (|S_n| \geq \sqrt{n}) \geq p>0, \ \forall n \geq n_0 \tag{*} \end{align} I do want to use * to conclude the statement. My idea was now to use that for a positive RV $X$ we have  $$E(X)= \int_0^\infty P(X \geq x) dx $$
However I am having trouble to connect this with my result (*) because evidently we have $P(|S_n| \geq \sqrt{n}) \geq P(|S_n| \geq n)$ I can write $$E(|S_n|) = \int_0^\infty P (|S_n| \geq x ) dx = \sum_{i=1}^\infty \int_{i-1}^i P(|S_n| \geq x)dx \\ \geq \sum_{i=1}^\infty \int_{i-1}^i P(|S_n| \geq i) dx = \sum_{i=1}^\infty P(|S_n| \geq i ) $$
I assume that I am on the wrong track. Maybe someone could provide me a hint to get me in the right direction again using (*) to conclude the statement in the problem.","['probability-theory', 'probability', 'central-limit-theorem']"
1794231,"Show that if $[Q,P]=it\Bbb{I}$ then the operators are unbounded","In the Hilbert space $\mathcal{H} = L^2(\mathbb{R},dx)$, let 2 symmetrical operators $P$ and $Q$ be given, with the following properties: $D(P) = D(Q) = \mathcal{S}(\mathbb{R})$ $P\mathcal{S}(\mathbb{R}) \subset \mathcal{S}(\mathbb{R})$ $Q\mathcal{S}(\mathbb{R}) \subset \mathcal{S}(\mathbb{R})$ $[Q,P]=it\Bbb{I}$ on $\mathcal{S}(\mathbb{R})$ Where $\mathcal{S}(\mathbb{R})$ is Schwartz space, $t$ is a real constant different from $0$ and $[Q,P] = QP - PQ$. Show that operators cannot be bounded. I've tried to define an operator $C=[Q,P]$ and prove that it's unbounded using sequence $\Phi_n(x)=char_{[n,n+1)}x$,where $char$ is characteristic function. And using the definition for a bounded operator I have the following:
$$||C\Phi_n(x)||=(\int_n^{n+1}|it|^2dx)^{1/2}=t$$
Which means $C$ in bounded. And from this moment I'm not sure in which direction I should move. Or maybe it was wrong from the beginning.","['functional-analysis', 'normed-spaces', 'operator-theory']"
1794261,Estimate the sum of alternating harmonic series between $7/12$ and $47/60$,"How can I prove that: 
$$\frac{7}{12} < \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n} < \frac{47}{60}$$ ? I don't even know how to start solving this...","['inequality', 'sequences-and-series', 'calculus']"
1794291,Calculating the determinant of a matrix using its rank,"Let A, B, C and D be real n×n matrices. If $$\operatorname{rank} \begin{bmatrix}
       \ A & B \\[0.3em]
       \ C & D \\[0.3em]
     \end{bmatrix} = n$$ then show that $$\det \begin{bmatrix}
       \det A & \det B \\[0.3em]
       \det C & \det D \\[0.3em]
     \end{bmatrix} = 0$$","['matrices', 'matrix-rank', 'linear-algebra', 'determinant']"
1794313,"Flip $n$ coins, discard tails, and continue until $k$ heads remain","Consider the following game: $n$ participants have a fair coin each, on a given round, the not already discarded participants flip their coins, those who flip a tail are discarded from the game, the remaining ones continue to play until there are at most $k$ of them left. The question is: what's the distribution of the number of rounds in this game? Bonus question: idem, but the $n$ coins are all unfair, with probabilities $p_1$, $p_2$, $\ldots$, $p_n$. Disclaimer: this is not a homework question, it came up when considering distributed routing protocols with a colleague.","['probability', 'probability-distributions']"
1794316,If $f^{-1}(x)=\frac{1}{f(x)}$ then find $f(1)$,"For $a>1$ we have: $f:[\frac{1}{a},a]\to [\frac{1}{a},a]$ be a bijective function. Suppose $f^{-1}(x)=\frac{1}{f(x)}$ for all $x \in [\frac{1}{a},a]$ then find $f(1)$. Could someone give me slight hint for this question? Also as function is bijective, hence it will be monotonic but can we tell for sure if it will be increasing or decreasing in this particular question?","['inverse', 'calculus', 'functions']"
1794347,When are the limits of roots of a polynomial identical to the roots of the limit of the polynomial?,"I have a univariate polynomial of degree $n$ (where $n$ is larger than $4$). The real-valued coefficients of the polynomial depend on a parameter $\psi$, i.e.
$$p_\psi(x)=a_n(\psi) x^n+a_{n-1}(\psi) x^{n-1}+\ldots+a_1(\psi)x+a_0(\psi).$$
Ideally, I would like to compute the roots of this polynomial, $r_i(\psi)$, $i\in\{1,\ldots,n\}$, and take the limit of $\psi$ to zero
$${\hat r}_i=\lim_{\psi\rightarrow 0} r_i(\psi)$$ However , since the degree of the polynomial is too high, I cannot get a solution in closed form. A feasible alternative would be the following: Compute the roots $r^\ast_j$ of the limit of the polynomial
$$p^\ast(x)=\lim_{\psi\rightarrow 0} p_\psi(x).$$
In my case, the coefficients are such that a) the leading coefficient $a_n(\psi)$ will converge to zero and b) the limiting polynomial $p^\ast(x)$ will factor into low order polynomials. My question is : under which conditions do the two calculations lead to the same answer, i.e. ${\hat r}_i=r^\ast_j$, for the roots that exist in both cases?
Any answers or references would be much appreciated.","['roots', 'polynomials', 'limits']"
1794361,Finding $\lim_{x \to 0}\frac{\sqrt[3]{1+2x}-1}{x}$,"Good morning everyone, first time posting here. For my calculus class, we are asked to find  $$\lim_{x \to 0}\frac{\sqrt[3]{1+2x}-1}{x}$$ We are given the hint that $$a^3-b^3=(a-b)(a^2+ab+b^2)$$ I have tried several step by step online solvers, but they all use derivatives and something called the 'hospital' rule, which we haven't learned yet. So in conclusion, if someone could set me on a path to solving this that uses the hint I included, I'd be very grateful.","['calculus', 'limits']"
1794366,Seating arrangements of 7 boys and 5 girls in a row.,In how many ways can these boys and girls be arranged in a row if between two particular boys A and B there are no boys but exactly 3 girls?,"['permutations', 'combinatorics', 'discrete-mathematics']"
1794386,On an injective ring homomorphism from the ring of continuous functions to the ring of differentiable functions,"Let $\phi : C \to D$ be an injective ring homomorphism such that $\phi(1)=1$, where $1$ denotes the constant function $1$ and $C$, $D$ are the rings of continuous, respectively differentiable functions on $\mathbb{R}$. If $f \in C ,g \in D$ are such that $\phi(f)=g$, and $t_0\in \mathbb R$, is it true that $\phi (f-g(t_0))=g-g(t_0)$ ? This is used on page 944, Problem 11617 . And why if the image of $\phi $ consists of only constant functions, then $\phi$ is not injective ? Please help. Thanks in advance.","['derivatives', 'ring-homomorphism', 'real-analysis', 'continuity', 'ring-theory']"
1794413,"Is $C^\omega([0,1])$ normable? (And about the growth of coefficients of infinitely differentiable functions)","This question arised to me when trying to prove that the space of infinitely differentiable functions defined in a compact space $K\subset\mathbb{C}$ taking values in $\mathbb{C}$, that is $C^\infty(K)$, is a Banach space.
It is well known that $C^n(K)$ (the space of n-times continuously diferentiable functions) is a Banach space with the norm
$$||f||:=||f||_\infty+...+||f^{n)}||_\infty$$
When I try to define an analogous norm for $C^\infty(K)$, I have the problem that I dont know how fast is allowed to grow the sequence
$$(||f^{n)}||_\infty)_n$$
I've read from several sources that $C^\infty(K)$ is a Frechet space so I'm guessing that there is no restriction about the growth of that sequence. Its that true?
Any help would be appreciated. (Update) [$\approx$ Solved] I've read that the space of analytic functions $C^\omega([0,1])$ is not normable (nor $C^\infty([0,1])$ either then), so my question must have a negative answer: If it were true that $||f^{n)}||_\infty\leq M_n$ for some absolute (i.e. holding for every $f\in C^\omega([0,1])$) sequence $(M_n)_n$ of positive numbers, then we could define
$$||f||_\omega:=\sum_{n=0}^\infty2^{-n}\frac{||f^{n)}||_\infty}{M_n}$$
for $f\in C^\omega([0,1])$. It is inmediate to verify that $||\cdot||_\omega$ (would) define a norm over $C^\omega([0,1])$. As this can't happen, there is not such sequence $(M_n)_n$. [I guess that saying that $C^\omega([0,1])$ is not normable means with respect to the topology ""where $f$ and $g$ are close if $f^{n)}$ and $g^{n)}$ are close for every $n\geq0$"". That is, with respect to the topology $\tau$ generated by $\{B(\varepsilon,f)\}_{\varepsilon>0,f\in C^\omega([0,1])}$, where $B(\varepsilon,f)=\{g\in C^\omega([0,1]):||g^{n)}-f^{n)}||_\infty<\varepsilon\ \forall n\geq0\}$] As proving that $C^\omega([0,1])$ is  not normable with respect to $\tau$ is the only remaining question, I've changed the tittle.
Again, any help would be appreciated :)","['functional-analysis', 'banach-spaces']"
1794446,Analytic continuation of power series on the unit whose terms tends to 0,"This problem is from complex analysis. Set $$f(z)=\sum_{n=0}^{\infty}a_nz^n$$ with convergence radius of 1, and $$\lim_{n \to \infty}a_n=0$$ Prove that if $z_0 \in \partial B(0,1)$ is not a singular point of f(z), then $$\sum_{n=0}^{\infty}a_n z_0^n$$ converges. It's easy to see that if $$\lim_{n \to \infty}na_n=0$$, we can quickly solve it because of Tauber's theorem. But now the condition $$\lim_{n \to \infty}a_n=0$$ seems too weak, is it really sufficient enough for the problem?","['complex-analysis', 'singularity', 'analytic-continuation']"
1794459,"What is cardinality of set of all intervals (a,b), where a, b are rational numbers?","We have set $S=\{ (a,b) | a,b \in \mathbb{Q}\}$ And we know that $(a,b)\sim \mathbb{R}$ , so $k((a,b))=c$. And $\mathbb Q \sim \mathbb N$, so $k(\mathbb Q)=\aleph_0$. I don't know how to put all informations together. I was also thinking that $S \subset \mathbb R$ and than we know $k(S) \le k(\mathbb R)=c$.
But how to get other inclusion.","['cardinals', 'elementary-set-theory']"
1794496,Evaluation of $\int_{0}^{1}\frac{\ln x}{x^2-x-1}dx$,"Evaluation of $\displaystyle \int_{0}^{1}\frac{\ln x}{x^2-x-1}dx$ $\bf{My\; Try::}$ Let $\displaystyle I = \int_{0}^{\infty}\frac{\ln x}{x^2-x-1}dx=\int_{0}^{\infty}\frac{\ln(x)}{\left(x-\frac{1}{2}\right)^2-\left(\frac{\sqrt{5}}{2}\right)^2}dx$ Now Put $\displaystyle \left(x-\frac{1}{2}\right)=\frac{\sqrt{5}}{2}\sec \theta\;,$ Then $\displaystyle dx = \frac{\sqrt{5}}{2}\sec \theta \tan \theta$ So $$ I= -\frac{2}{\sqrt{5}}\int_{-\frac{1}{2}}^{\infty}\frac{\ln(\sqrt{5}\sec \theta+1)-\ln(2)}{\tan \theta}\cdot \sec \theta d\theta$$ So $$I = \frac{2}{\sqrt{5}}\int_{-\frac{1}{2}}^{\infty}\frac{\ln(2)+\ln(\cos \theta)-\ln(\sqrt{5}+\cos \theta)}{\sin \theta} d\theta$$ Now How can I solve after that, Help Required, Thanks",['integration']
1794502,$\left(x+\sqrt{x^2+1}\right)\left(y+\sqrt{y^2+1}\right)=1$. Find $(x+y)$.,"We know that $\left(x+\sqrt{x^2+1}\right)\left(y+\sqrt{y^2+1}\right)=1$. Find the expression $(x+y)$. My work so far: $$\left(x+\sqrt{x^2+1}\right)\left(y+\sqrt{y^2+1}\right)=1$$
$$\color{red}{\left(x-\sqrt{x^2+1}\right)\cdot}\left(x+\sqrt{x^2+1}\right)\left(y+\sqrt{y^2+1}\right)=\color{red}{\left(x-\sqrt{x^2+1}\right)\cdot}1$$
$$-\left(y+\sqrt{y^2+1}\right)=\left(x-\sqrt{x^2+1}\right)$$
$$-\color{red}{\left(y-\sqrt{y^2+1}\right)\cdot}\left(y+\sqrt{y^2+1}\right)=\color{red}{\left(y-\sqrt{y^2+1}\right)\cdot}\left(x-\sqrt{x^2+1}\right)$$
$$1=\left(x-\sqrt{x^2+1}\right)\left(y-\sqrt{y^2+1}\right)$$ I need help here.","['algebra-precalculus', 'radicals']"
1794532,Statistics $X_{(1)}$ complete for a Uniform Distribution?,"Someone had asked this earlier, but since it was good practice for my qualifying exam coming up, I figured I would ask and share my work on the problem. The problem is: Suppose $X$ is Unif$(0,\theta)$. Let $T = X_{(1)}$ (minimum order statistic). Is $T$ complete? My initial thought was no since usually lectures show $X_{(n)}$ is, but here was my attempt: I assume that $E[g(T)]=0$ for some function $g$ and want to find if $P(g  =0)=1$. $$P(T \leq t) = 1 - P(T > t) = 1-\left(1-\frac{t}{n} \right)^n$$ So taking derivatives to get the pdf: $$f_T(t) = \left(1-\frac{t}{n}\right)^{n-1}$$ So now working with expectations: $$0=E[g(T)] = \int_0^\theta g(t)\left(1-\frac{t}{n}\right)^{n-1} dt$$ This integral is differentiable, and since the integral is $0$, then the derivative is $0$, so taking the derivative with respect to $\theta$: $$0= g(\theta)\left(1-\frac{\theta}{n}\right)^{n-1}$$ Hence $g(\theta) =0$, so $T$ is a complete statistics. Does this argument work? I basically modeled it after the proof of showing the max order statistic is complete. If $X_{(1)}$ is not complete, where does the proof go wrong?","['uniform-distribution', 'statistics', 'order-statistics']"
1794539,Combinatorial proof of a certain alternating sum of binomial coefficients,The following identity appeared as a question earlier today $$\displaystyle\sum\limits_{k=0}^n (-1)^k\binom{m+1}{k}\binom{m+n-k}{n-k} = \begin{cases} 1\ \text{if}\ n=0 \\ 0\ \text{if}\ n>0 \end{cases}$$ and was given an algebraic solution. Is there a combinatorial proof?,"['binomial-coefficients', 'combinatorial-proofs', 'closed-form', 'combinatorics', 'summation']"
1794625,A question regarding Vitali Covering Covering Lemma,"Let f be an increasing function on the closed, bounded interval [a, b]. Define $$E_{\alpha}=\{ x\in(a,b) | \bar{D}f(x) \geq \ \alpha \}$$
Choose $\alpha^{'} \in (0, \alpha)$. Let $F$ be the
collection of closed, bounded intervals $[c, d]$ contained in $(a, b)$ for which $f (d) - f(c) \geq\alpha^{'}(d - c)$. Since $\bar{D}f(x) > \alpha$ on $E_{\alpha}$, $F$ is a Vitali covering of $E_{\alpha}$. Why is F a Vitali covering of $E_{\alpha}$?","['real-analysis', 'measure-theory']"
1794652,Deleted versus non-deleted limits,"When I read Serge Lang's Undergraduate Analysis(second edition) page 41,  I found the definition of limit he define is so called non-Deleted limits , this results in some conclusion is different from the usual limit( deleted limit), for example, every isolated point $x_0$ has limit, its value is $f(x_0)$. By topology knowledge, we know every isolated point is continuous, we cannot get this result by $\lim_{x\to x_0}f(x)=f(x_0)$, if we define limit as deleted limit. However, if we define limit as non-deleted limit, we can get it. My question: is non-deleted limit better than deleted limit, if yes, why does most textbook do not use it?",['real-analysis']
1794665,Is it bad to call series a generalization of sum?,"In a recent question I asked why series has a name separate from that of sum, and the general answer was that a series does not have the nice properties of sum.
Does this mean it is bad to call series a generalization of sum?","['terminology', 'sequences-and-series']"
1794666,Reference request: Inclusion of smooth maps into continuous maps between smooth manifolds is a weak homotopy equivalence.,"Let $M,N$ be smooth manifolds. It seems to be well known that if the sets $C^0(M,N)$ and $C^\infty(M,N)$ are equipped with the appropriate topologies (I suppose the weak/strong Whitney topology), then the inclusion
$$C^\infty(M,N) \hookrightarrow C^0(M,N)$$
is a weak homotopy equivalence, see e.g. here . However, I don't know of any reference where this is proved explicitly. Can anyone provide a reference that the above inclusion is a weak homotopy equivalence?","['differential-topology', 'homotopy-theory', 'algebraic-topology', 'differential-geometry', 'analysis']"
1794691,Check that $\lim\limits_{n\to\infty}\sum\limits_{i=1}^{n}\left(\frac{i+x}{n}\right)^n=\frac{e^{x+1}}{e-1}$,"Show that
  $$\lim_{n\to\infty}\sum_{i=1}^{n}\left(\frac{i+x}{n}\right)^n=\frac{e^{x+1}}{e-1}$$
  Any hints how I can tackle this problem? Although I checked on a sum calculator that it converges very slowly, this result gives me a reason that the proposed closed form is incorrect. Can anyone verify it? I know that
$$\lim_{n\to\infty}\left(\frac{n+x}{n}\right)^n=e^x$$ The limit to be computed is $$\lim_{n\to\infty}\left(\frac{1+x}{n}\right)^n+\left(\frac{2+x}{n}\right)^n+\left(\frac{3+x}{n}\right)^n+\cdots$$ It looks like the natural number series $$1^n+2^n+3^n+4^n+\cdots$$ But this is the farthest I can go.","['exponential-function', 'limits']"
1794713,Uniform convergence of $\sum_{n=-\infty}^{\infty}\frac{1}{n^2 - z^2}$ on any disc contained in $\mathbb{C}\setminus\mathbb{Z}$,"I'm currently revising some complex analysis, and need to show that the series $$\sum_{n=-\infty}^{\infty}\frac{1}{n^2 - z^2}$$ defines a holomorphic function on $\mathbb{C}\setminus\mathbb{Z}$. The hint that the question gives me is to consider any disc contained in $\mathbb{C}\setminus\mathbb{Z}$ and show that the series converges uniformly there. I can see how to complete the question once I've done this, but it's late, I'm tired, and I can't figure out how to show the series converges uniformly. I've tried the Weierstrass M-Test, but this failed for me on discs where $z$ was close to $n$, for obvious reasons. Any hints would be greatly appreciated.","['complex-analysis', 'uniform-convergence', 'sequences-and-series', 'convergence-divergence']"
1794721,"What's an example of a function in $L^1(0,1)$ but not $L^p(0,1)$ for $p>1$?","What's an example of a function in $L^1(0,1)$ but not $L^p(0,1)$ for $p>1$? I've seen this answer but this is on an infinite domain. I'm interested only in $(0,1)$. I tried playing around with $\int_0^1 \frac{1}{x^a\log^b(x)}dx$ but haven't found success. I was trying to think of some transformation of the given answer to the domain $(0,1)$ but it can get messy. If possible, I would prefer a hint to an outright answer.","['functional-analysis', 'lp-spaces']"
1794724,On the converse of Schur's Lemma,"Let $G$ be a finite group and $F$ a field with $\mathrm{char}(F)=0$ or coprime to $|G|$. Let $V$ be a $FG$-module in a way that every $ FG$-homomorphism $ f : V \to V $ is given by $f(x)= \lambda x $. Then $V$ is irreducible. I already managed to proof this by contradiction, using Maschke's Theorem. We can  write $V$ as $U\oplus W$ and get a $FG$-homomorphism $\pi:U\oplus W \to U\oplus W$, $\pi (u+w)=u$, then $\pi(u+w)=\lambda (u+w)=u $ then either $U$ or $W$ are trivial and thus $V$ is irreducible. My question is if this statements still holds if the characterictic of $F$ divides the order of $G$, since I only used this fact in my proof to use Maschke's theorem.","['representation-theory', 'abstract-algebra', 'group-theory']"
1794726,Rational solutions of $x^3+y^3=9$,"An old alchemist had two sphercial flasks, one with a circunference of $12$ inches and the other one with a circumference of $24$ inches. He desired to transfer their contents into two other spherical flasks whose sizes are different from the first two. What were the circumferences of the two new flasks in rational numbers? After some easy algebraic operations I have arrived at the problem: Find solutions of $ x^3+y^3=9$ with $x$ and $y$ in $\mathbb{Q}$ . Are there any other solutions distinct from the $(2,1)$ and $(1,2)$ ? 
I have tried very much but I haven't made progress in doing this. How can I proceed with that? What's the name of the theme? What can I do?","['number-theory', 'rational-numbers']"
1794744,Finding the value of x at which the tangent to the curve is parallel to the x axis,"I have thoroughly searched up how to attempt this question. However, I am not sure if my answer is correct or if I even attempted the question correctly. Assistance would be greatly appreciated! Calculate the value of x at which the tangent to the curve is parallel
  to the $x$ axis for the curve $y=3x^2+5x-2$ The value I got for $x$ is $0$. How I did it:
the expression for the gradient $\frac{dy}{dx}= 6x+5$ then, $6x+5=0 \Leftrightarrow 6x=-5 \Leftrightarrow x=-0.83$ or if that was wrong I also tried $$6x+5x
\Leftrightarrow6x+5x=0
\Leftrightarrow11x=0
\Leftrightarrow x=0$$
I dont think I did it properly. Any suggestions?",['derivatives']
1794753,Prove $|A| < |B| \leq |C| \implies |A| < |C|$,"I was wondering if I actually have to construct functions here and compose them, or if I can simply argue based on cardinality. Let's say we have injections $f: A \rightarrow B$, $g: B \rightarrow C$. The composition of these injective functions is the injection $g \circ f: A \rightarrow C$ which gives me $|A| \leq |C|$. I have to show this is only an injection; that is prove it is not bijective. Suppose for the sake of contraction that $|A| = |C| \iff A \approx C$. If $|B| \leq |C| \land |A| = |C|$ $\implies |B| \leq |A|$. But our hypothesis gives $|A| < |B|$, which is a contradiction. So $|A| \neq |C|$. So the function cannot be bijective although it is injective.",['elementary-set-theory']
1794755,How many partial derivatives does a multivariate polynomial have?,"Definition: My motivation for this question stems from the following definition: Define the deterministic finite automata generated by the nonconstant* polynomial $f(x_0 , \dots , x_n) \in \mathbb{Z} [x_0 , x_1 , \dots , x_n]$, denoted $\text{DFA}(f)$, to be the $5$-tuple $$\text{DFA}(f) = (\partial f, \Sigma, f, \delta, \equiv0),$$ where $\partial f = \{ \text{all partial derivatives of } f \}$ is the set of states, $\text{alphabet } \Sigma = \Bigg \{ \frac{\partial}{\partial x_0}, \frac{\partial}{\partial x_1}, ... , \frac{\partial}{\partial x_n} \Bigg \},$ $f = f(x_0 , x_1 , \dots , x_n )$ is the unique start state, transition (partial, as in not defined for all possible inputs) function $\delta : \Sigma \times \partial f \longrightarrow \partial f, \bigg( \frac{ \partial}{\partial x_i} , p \bigg) \mapsto \frac{\partial p}{\partial x_i}$, where we only keep those elements $\bigg( \frac{\partial}{\partial x_i} , p \bigg)$ that satisfy either $\frac{\partial p}{\partial x_i} \neq 0$  or $\frac{\partial p }{\partial x_i} = 0 \text{ for all } i$ and $p \not\equiv 0$, $\text{and } \equiv0$, the zero polynomial, is the unique accept state. The cardinality of $\partial f$ is the title of the question.","['polynomials', 'finite-automata', 'partial-derivative', 'order-theory', 'combinatorics']"
1794757,Cohomology Class of a Subvariety,"I'm working on question 7.4 of Chapter III.7 in Hartshorne's Algebraic Geometry. The question is about the cohomology class of a subvariety. The setup is as follows: $X$ is an $n$-dimensional non-singular projective variety over an algebraically closed field $k$. $Y\subset X$ is a non-singular subvariety of codimension $p$. We have the standard map $\Omega_X\otimes \mathcal{O}_Y \rightarrow \Omega_Y$ from which we can deduce a map $\Omega_X^{n-p} \rightarrow \Omega_Y^{n-p}$, and this in turn yields a map on cohomology $H^{n-p}(X, \Omega_X^{n-p}) \rightarrow H^{n-p}(Y,\Omega_Y^{n-p})$. Now $Y$ is $(n-p)$-dimensional so $\Omega_Y^{n-p} = \omega_Y$ and we have the trace map $H^{n-p}(Y,\Omega_Y^{n-p} = \omega_Y) \rightarrow k$. Composing with this trace map we have $\varphi_Y : H^{n-p}(X,\Omega_X^{n-p})\rightarrow k$. Now, since by Serre Duality $H^p(X,\Omega_X^p) \cong H^{n-p}(X, \Omega_X^{n-p})^{\lor}$, $\varphi_Y$ corresponds to an element $\eta(Y) \in H^p(X,\Omega_X^p)$ which we call the cohomology class of $Y$ . Part (a) of the problem asks to show that if $P\in X$ is a closed point, then $t_X(\eta(P)) = 1$, where $t_X$ is the trace map on $\omega_X$. Now, in the case of a point, the map $\Omega_X^{n-p} \rightarrow \Omega_Y^{n-p}$ is simply the map $\mathcal{O}_X \cong \Omega_X^0 \rightarrow \Omega_P^0\cong k_P$ defined by $f \mapsto f(P)$ which, when composed with the trace map on $H^0(P,\omega_P)$, yields $f \mapsto t_P(f(P))$. This map should correspond to an element $\eta(P) \in H^n(X,\Omega_X^n = \omega_X)$ as indicated above. My problem is, I don't know how to get my hands on $\eta(P)$. All I know is that it should exist. Moreover, I thought that $H^n(X, \omega_X) \rightarrow k$ is only a map of $k$-vector spaces. Wouldn't I need some morphism respecting ring structures somewhere in order to detect $1 \in k$ and be able to show that $t_X(\eta(P)) = 1$ here? Hartshorne himself says that, except in the case of curves, we can't really write down explicitly what the trace map is because we don't know. All we know is that it exists.","['schemes', 'algebraic-geometry']"
1794771,Matrices and prime numbers,"Let $ p $ be a prime number and \begin{align} K=\left\{ \begin{pmatrix} a &b \\ 
 c& d \end{pmatrix} \mid a,b,c,d \in \left\{0,1,\ldots,p-1 \right\}, \right. & a+d \equiv 1 \!\!\!\! \pmod p, \\
& ad-bc \equiv 0 \!\!\!\! \pmod p \left.\vphantom{\begin{pmatrix} a &b \\ 
 c& d \end{pmatrix}} \right\}. \end{align}
  Determine $\operatorname{card}(K) $. I have taken some particular cases: $ p=2,3,5 \text{ or } 7 $ and I've deduced that $\operatorname{card}(K)=p(p+1) $, but I can't extend the solution to the general case.","['finite-fields', 'matrices', 'abstract-algebra', 'combinatorics', 'linear-algebra']"
