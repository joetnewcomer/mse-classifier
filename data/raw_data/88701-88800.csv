question_id,title,body,tags
1193057,Showing that $\lim_{x \to 0}\frac{f(x)}{g(x)} = \frac{f'(0)}{g'(0)}$.,"If $f$ and $g$ are differentiable functions with $f(0) = g(0) = 0$ and $g'(0) \neq 0$, show that $\lim_{x \to 0}\frac{f(x)}{g(x)} = \frac{f'(0)}{g'(0)}$. I consider that perhaps: $$
\begin{align}
\\ \lim_{x \to 0}\frac{f(x)}{g(x)} &= \lim_{x \to 0}\frac{f(0+x) - f(0)}{x} \cdot \frac{1}{ \lim_{x \to 0}\frac{g(0+x) - g(0)}{x}} = f'(0) \cdot \frac{1}{g'(0)} = \frac{f'(0)}{g'(0)}
\end{align}
$$ But, it seems like that's maybe not quite right. I'm not certain. Insight?","['calculus', 'proof-verification', 'real-analysis', 'derivatives', 'limits']"
1193076,Product of character values,"From Isaac's character theory book; $3.12$ Let $x\in Irr(G)$ and $g,h\in G$ . Show that $$\chi(g)\chi(h)=\dfrac{\chi(1)}{|G|}\sum_{z\in G}\chi(gh^z)$$ I had thought that it was related to $3.9)$ ; $$K_iK_j=\sum_{v}a_{ijv}K_v$$ where $K_i$ is the sum of the $i$ th conjugacy classes and $$a_{ijv}=\dfrac{|\mathfrak{K_i}||\mathfrak{K_j}|}{|G|}\sum_{\chi\in Irr(G)}\dfrac{\chi(g_i)\chi(g_j)\overline{\chi(g_v)}}{\chi(1)}$$ But by using above equalites, I found that $$\chi(g)\chi(h)=\sum_{\chi\in Irr(G)}\dfrac{\chi(g)\chi(h)}{\chi(1)}$$ . I could not proceed more. Any help would be appreciated.","['representation-theory', 'group-theory', 'characters']"
1193084,Proof of squeeze theorem for functions,"Suppose for all $x$ we know $g(x)\le f(x)\le h(x)$ and $\lim_{x\to c} g(x)=L=\lim_{x\to c} h(x)$. Does the following argument work to conclude that $\lim_{x\to c} f(x)=L$? Let $\epsilon\gt 0$ be given. Then we can find a $\delta_1$ such that if $|x-c|\lt\delta_1$, then $|g(x)-L|\lt\epsilon$ and a $\delta_2$ such that if $|x-c|\lt\delta_2$ then $|h(x)-L|\lt\epsilon$. Let $\delta = min\{\delta_1,\delta_2\}$. Then for all x such that $|x-c|\lt\delta$, it follows that $|g(x)-L|\lt\epsilon$ and $|h(x)-L|\lt\epsilon$. This means that $L-\epsilon\lt g(x)\le h(x)\lt L+\epsilon$. But since $g(x)\le f(x)\le h(x)$,  $L-\epsilon\lt f(x) \lt L+\epsilon$. Hence $\lim_{x\to c}f(x)=L$. This proof is slightly different from others that I've seen, but it doesn't seem to be wrong. Is there anything that I'm missing?",['real-analysis']
1193108,"min(a + b,c) $\leq$ min(a,c) + min(b,c)?","Is the following always true ?  if we have min(a + b,c) $\leq$ min(a,c) + min(b,c) according to the cases I have analyzed it seems to be true but I want to double check. For a $\geq$ 0,b $\geq$ 0, c $\geq$ 0",['algebra-precalculus']
1193120,"Second order partial of $f(x,y)=\frac{xy(x^2-y^2)}{x^2+y^2}$ [duplicate]","This question already has an answer here : partial derivation 2nd order for a function defined by parts (1 answer) Closed 2 years ago . Consider the function $f(x,y)=\dfrac{xy(x^2-y^2)}{x^2+y^2}$ for $(x,y) \neq (0,0)$, $f=0$ otherwise. I have to compute $\dfrac{d^2f}{dydx}(0,0)$. I know that I have to calculate $\frac{df}{dx}$ first.
But that is , $\frac{df}{dx} = \frac{\partial f}{\partial y}\frac{dy}{dx}+\frac{\partial f}{\partial x}$.
When I put it in wolframalpha, it gives me this calculation, and also just $\frac{\partial f}{\partial x}$ as an alternative form. wolframalpha calculation link Why do I just ignore the y'? I don't know what y(x) is, as a function of x. 
y and x are independent functions, no?","['multivariable-calculus', 'partial-derivative']"
1193121,Bernstein's Theorem of Analytic Function Proof,"I'm studying from a textbook and came across an exercise to prove the following, which it calls the Bernstein's Theorem: If $f$ is infinitely differentiable on an interval $I$, and $f^n(x)\ge0$ for all $n\in\mathbb N$ and $x\in I$, then $f$ is analytic on $I$. I'm trying to find more information and/or a proof of it, though most of my search comes up with the Cantor-Bernstein or Schröder-Bernstein theorems, which don't seem to be the same as this. Is anyone more knowledgable of this proof?","['differential', 'real-analysis']"
1193223,Extension Lemma for Smooth maps (Lee vs. Lee),"I've been reading Jeffrey Lee's, Manifolds and Differential Geometry and John Lee's, Introduction to smooth manifolds . In the first book ( here , in page 31), after introducing partition of unity, there's an exercise that says: Exercise 1.74. Show that if a function is smooth on an arbitrary set $S\subset M$ as defined earlier, then it has a smooth extension to an open set that contains $S$. Where he says "" as defined earlier "", I assumed he meant that $M$ was paracompact, but maybe I missed something else. On the sencond book (check here , in page 45) there's the Extension Lemma for Smooth Functions, and it says: Lemma 2.26 (Extension Lemma for Smooth functions). Suppose $M$ is a smooth manifold with or without boundary, $A \subset M$ is a closed subset, and $f:A\to\Bbb R^k$ is a smooth function. For any open subset $U$ containing $A$, there exists a smooth function $\hat f:M\to\Bbb R^k$ such that $\hat f|_A=f$ and $supp(f) \subset U$. And after proving the lemma there is this exercise that made me very confused. Exercise 2.27. Give a counterexample to show that the conclusion of the extension
  lemma can be false if A is not closed. Doesn't exercise 2.27 imply that exercise 1.74 is incorrect? Are those trick questions? Like when you are asked to prove something right but it turns out is not? Or, more likely, did I missed something in Jeffrey Lee's book?","['manifolds', 'differential-geometry']"
1193262,"For a random variable $X$ such that $P(a<X<b)=1$, showing $E(X)E\left(\frac{1}{X}\right) \le\frac{(a+b)^2}{4ab}$","I've worked on the following problem and have a solution (included below), but I would like to know if there are any other solutions to this problem, particularly more elegant solutions that apply well known inequalities that I've overlooked. QUESTION : Suppose we have a random variable s.t. $P(a<X<b) =1$  where $0 < a < X < b$ , $a$ and $b$ both positive constants. Show that $$E(X)E\left(\frac{1}{X}\right) \le \frac{(a+b)^2}{4ab}$$ Hint :  find constant c and d s.t. $\frac{1}{x} \le cx+d$ when $a<x<b$, and argue that then we shall have $E(\frac{1}{X}) \le cE(X)+d$ MY SOLUTION : For a line $cx+d$ that cuts through $\frac{1}{X}$ at the points $x=a$ and $x = b$, it's easy to show that $ c = - \frac{1}{ab} $  and $d = \frac{a+b}{ab} $, $$ E\left(\frac{1}{X}\right) \le - \frac{1}{ab} E(X) + \frac{a+b}{ab} $$ $$ abE\left(\frac{1}{X}\right) + E(X) \le (a+b) $$ and because both sides of the inequality are positive, it follows that: $$ \left(abE\left(\frac{1}{X}\right) + E(X)\right)^2 \le (a+b)^2 $$ $$ (ab)^2E\left(\frac{1}{X}\right)^2 + 2abE\left(\frac{1}{X}\right)E(X) + E(X)^2  \le (a+b)^2 $$ Now, for the LHS, we can see that 
$2abE\left(\frac{1}{X}\right)E(X) \le (ab)^2E\left(\frac{1}{X}\right)^2 + E(X)^2$ because $0 \le (ab)^2E\left(\frac{1}{X}\right)^2 - 2ab\,E\left(\frac{1}{X}\right)E(X) + E(X)^2 = \left(ab\,E\left(\frac{1}{X}\right) - E(X)\right)^2 $ So, $$ 4ab\,E\left(\frac{1}{X}\right)E(X) \le (ab)^2E\left(\frac{1}{X}\right)^2 + 2ab\,E\left(\frac{1}{X}\right)E(X) + E(X)^2  \le (a+b)^2 $$ and therefore: $$ E\left(\frac{1}{X}\right)E(X) \le \frac{(a+b)^2}{4ab} $$  Q.E.D. Thanks for any additional solutions you might be able to provide.  Cheers!","['functional-inequalities', 'inequality', 'probability', 'expectation']"
1193304,Showing a complex analytic function is unbounded,"This was one of the problems on a previous year's Complex Analysis final exam. Assume $f\in \mathcal O (\mathbb H )$, non-constant, and $f(\frac {i}{\sqrt n})=0, \forall n\in \mathbb N$. Prove that $f$ takes unbounded values. What I tried so far: I tried to argue that the point $z=0$ had to be an essential singularity since the function cannot be continued to be holomorphic there (taking the value $0$), for then it would be forced to be identically the $0$ function (which it is assumed not to be). Then i squared the input domain to argue that the essential singularity must take on unbounded values in the upper-half plane somewhere near $z=0$. But, I think my reasoning is wrong because this may not be an isolated singularity at all and may be a point in the branch cut of a holomorphic function or something. I'm wondering if someone can write me up a nice proof and/or explanation about how to tackle this problem, thanks.","['singularity-theory', 'complex-analysis']"
1193331,Graphs of interesting integrals of the form: $\int \sin^a(x^a)\cos^a(x^a)$,"Here are a few graphs of the form:- $$\int \sin^a(x^a)\cos^a(x^a)dx$$
Where $a$ is an even, positive integer. $a = 2$ $a = 4$ $a = 6$ Now, a few graphs of the form:- $$\int \sin^a(x^a)\cos^a(x^a)dx$$
Where $a$ is an odd, positive integer. $a = 1$ (Common) $a = 3$ $a = 5$ $a = 7$ The integrals themselves are hideous.. But the graphs are fun to observe (At least for me), especially for the cases where a is odd. I know that the difference in these graphs (Between odd and even $a$ ) is caused mainly by the powers the sin and cos functions are raised to, rather than the powers of the arguments of these functions. I have 4 questions :- Why does $\int \sin^a(x^a)\cos^a(x^a)dx$ , where $a$ is even, have fewer and fewer oscillations (i.e. the line becomes less wavy) as the value of $a$ increases? (Note: I know that the lines come closer and closer to the x-axis as evidenced by the outputs of the integral on the graph) What is going on when $a$ is odd? Can you explain why that beaker-like structure is formed; specifically, why does it seems to dip around a certain value ,then raise again to oscillate so much and the die out? Some questions regarding an observation of the case $a = 5$: Why does there seem to be a tiny bump just after the '4' on the x-axis? What value could be causing this, and why? And when $a = 7$, why do there seem to be tiny successive bumps beyond 2 and -2? I realize that answers may not exist for all of these questions, because these maybe the intrinsic qualities of the graph of the integral in discussion, but I'm hoping that some people may have insights and explanations for the features of the graphs I've questioned about.... Especially questions 3 and 4. I hope you don't consider the question silly; I'm genuinely interested in knowing the reasons (If they exist) for the above graphs.","['trigonometry', 'calculus', 'integration', 'graphing-functions']"
1193356,Number of unique binary strings containing at least m sequential 1s,"Let $Z\left(n,m\right)$ be the number of unique binary strings of length $m$ containing at least one instance of $n$ consecutive 1's. I am trying to come up with an expression for $Z$, preferably directly calculable though I will accept a recursive solution as well. I have attempted a formulation based on [1] ,
$$ \hat{Z}\left(n,m\right) = \sum_{q=m}^{n}\sum_{i=1}^{\lfloor \frac{q}{m}\rfloor}(-1)^{i+1}\binom{n-q+1}{i}\binom{n-mi}{n-q}\text{,}$$
however I am getting some discrepencies against test cases I worked out by hand. For example, it works for $Z\left(7,6\right)=3$ and $Z\left(7,5\right)=8$, but it does not work for $\left(7,4\right)=16$ (the formulation above gives $20$). N.B. : my definitions of $n$ and $m$ are opposite those of [1]; $q$ is the same. I believe it has something to do with double-counting some string permutations, but I haven't been able to work out what else I have to take out. Update : I found a recursive formulation [2] that gives me the same result as my $\hat{Z}$ above:
$$ \tilde{Z}\left(n,m\right) = 2\tilde{Z}\left(n-1,m\right) + 2^{n-m-1}-\tilde{Z}\left(n-m-1,m\right) $$
Having found this independent formulation, I will have to revisit my counting and see if I've made a mistake somewhere. Bonus points for an answer that works for arbitrary dictionaries, i.e. $W\left(a,n,m\right)$ where $a$ is the number of possible symbols in each position of the string. The original question would be equivalent to $Z\left(n,m\right) = W\left(2,n,m\right)$. [1] G.L., Number of binary strings containing at least n consecutive 1 [2] Gerry Myerson, response to Number of bit strings with 3 consecutive zeros or 4 consecutive 1s",['combinatorics']
1193380,What constitutes an outcome in probability?,"In probability, I often have trouble determining which situations to take as distinct outcomes for calculation. For instance, if we have a die with its faces numbered $1, 2, 2, 3, 3, 6$ and we roll it twice. We get $2$ on the first roll and $3$ on the second. Again rolling it twice we get $2$ and $3$. But the $2$ we got the second time is not the same $2$ as the first one. Its the other $2$ inscribed on the face of the die (the die has two $2$'s). So, for the purpose of calculating the probability that the sum of the two rolls in a die will be a certain number $4$, say, will these two situations constitute distinct outcomes? This is just a simplified, distilled example of a persistent problem I face in probability. Is there any way to think about outcomes that can make this clearer?",['probability']
1193398,Residue Theorem and Homologous to zero,"This is a very basic question and I couldn't find it posted yet but here it goes;
The Residue Theorem states that if $f:G\to \mathbb{C}$ is analytic on $G$- a region and $f$ has isolated singularities $b_1,...,b_k$ and $\gamma$ is homologous to 0, then $$\displaystyle\int_{\gamma}f=2\pi i\sum_1^kn(\gamma;b_s)\mathrm{Res}(f;b_s).$$ 
To my understanding, if $\gamma$ ""wraps"" around an isolated singularity, $b_i$, (say 1 time), then $\gamma$ would not be homologous to 0 since $n(\gamma;b_i)=1$ in this case ($b_i\in \mathbb{C}-G$). I think I need a better picture of the situation in this case. Thank you for your help!","['homotopy-theory', 'complex-analysis']"
1193422,Why hyperreal numbers are built so complicatedly?,I have seen approaches at building hyperreal systems by using complicated notions like ultrafilters and the like. Why not just postulate the existence of infinitesimal element $\varepsilon$ and infinite $\omega=1/\varepsilon$ like we do with complex numbers and build a field system around them?,"['number-systems', 'nonstandard-analysis', 'abstract-algebra']"
1193424,$ \int_{0}^1\frac{1+x^6}{1-x^2+x^4-x^6+x^8}dx$,"How do we compute this integral ?
$$ \int_{0}^1\frac{1+x^6}{1-x^2+x^4-x^6+x^8}dx$$
I have tried partial fraction but it is quite hard to factorize the denominator. Any help is appreciated.","['calculus', 'integration']"
1193432,"Prove that $\{\sin x, \sin 2x, ... , \sin nx\}$ is a linearly independent set","Prove that $\{\sin x, \sin 2x, ... , \sin nx\}$ is linearly independent. The short solution that I do not understand is as follow:
For p and q are positive integer, we have 
$$
\int\limits_{0}^{\pi}\sin{px}\sin{qx} dx=\left\{\begin{array}{l}0\qquad  \textrm{if } \, p\ne q\\
\dfrac{\pi}{2}\qquad \textrm{if }\, p=q\ne0\\
\end{array}
\right.
$$
Applying this result to show that if $\sum\limits_{k=1}^{n}\alpha_k\sin kx=0$ then $\alpha_k=0,\, k=1,\dots,n$ The solution is too short for me too understand. I would be grateful if you could explain this problem more in detail for me.","['fourier-series', 'linear-algebra', 'lp-spaces']"
1193442,Relation between residual spectrum and point spectrum.,"Suppose T is a bounded operator on a Hilbert space. Show that if λ is in the
residual spectrum of T, then $\bar{λ}$ is in the point spectrum of the adjoint. Here is what I think needs to be done.  We know that $\langle Tu,v\rangle = \langle u,T^*v\rangle = \overline{\langle T^*v,u\rangle}$.  Does that help with connecting $\lambda$ with $\overline{\lambda}$?","['spectral-theory', 'hilbert-spaces', 'functional-analysis']"
1193466,Tan inverse summation,$$S=\sum\limits_{i=1}^{4}\tan^{-1} x_i$$ How to simplify this ? I think I will have to use this : but it looks too long a method . Is there a method or symmetrical way which yields the answer quickly ? note : $x_i$ are the roots of a fourth degree polynomial so I know the sum and product of the roots,"['trigonometry', 'summation', 'inverse']"
1193492,If $\sin^{-1}\frac{2a}{1+a^2}-\cos^{-1}\frac{1-b^2}{1+b^2}=\tan^{-1}\frac{2x}{1-x^2}$ then what is value of x?,If $\sin^{-1}\frac{2a}{1+a^2}-\cos^{-1}\frac{1-b^2}{1+b^2}=\tan^{-1}\frac{2x}{1-x^2}$ then what is value of x? Solution $\tan^{-1}x=\tan^{-1}a-\tan^{-1}b=\tan^{-1}\frac{a-b}{1+ab}$ x=$\frac{a-b}{1+ab}$ i have a doubt what is $\tan^{-1}a$ and $\tan^{-1}b$ and how come $\tan^{-1}x=\tan^{-1}a-\tan^{-1}b$?,"['trigonometry', 'inverse']"
1193531,$\sum_{n=1}^{\infty} \frac{n^2}{ n!}$ equals [duplicate],This question already has answers here : Calculate sum of series $\sum \frac{n^2}{n!}$ [duplicate] (3 answers) Closed 9 years ago . $ \sum_{n=1}^{\infty} \frac{n^2}{ n!} $ equals I'm not able to convert in any standard series? Any hints?,"['sequences-and-series', 'exponential-function', 'calculus', 'limits']"
1193575,Number of multisets on $[2m]$ which satisfy certain conditions.,"I am trying to find the number of $n$-element multisets on $[2m]=\left\{1, \ldots, 2m\right\}$ such that $m+1, \ldots, 2m$ appear an even number of times in the $n$-multiset. I have tried several approaches, but the following seems to be the best approach so far... Let $A=\left\{m+1, \ldots, 2m\right\}$ and let $\nu(i)$ be the number of times $i\in [2m]$ appears in the multiset. We're trying to find the number of multisets $\left\{1^{\nu(1)}, 2^{\nu(2)} \ldots, 2m^{\nu(2m)} \right\}$ such that $\sum_{i=1}^{2m}\nu(i)=n$ and $\nu(i)=2j_i$, for some $j_i\in \mathbb{N}$ where $i\in A$. This is equivalent to finding the number of weak compositions of $n$ with $2m$ parts, $\sum_{i=1}^{2m} x_i=n$, such that $x_i=2j_i$ for each $i\in A$. There are two cases: $\textbf{Case 1:}$ $j_i=0$ for all $i\in A$. In this case, $\sum_{i=1}^{2m} x_i=\sum_{i=1}^{m} x_i=n$, which is a weak composition of $n$ into $m$ parts, of which there are $\binom{n+m-1}{m-1}$. $\textbf{Case 1:}$ $j_i=0$ for all $i\in S$, where $S\in \binom{A}{k}$ (i.e., $S\subseteq A$ such that $|S|=k$) and $j_i\geq 1$ for all $i\in A\setminus S$. In this case,
$$\sum_{i=1}^{2m} x_i=\sum_{i=1}^{m} x_i+\sum_{i\in A\setminus S}x_i+\sum_{i\in S}x_i=\sum_{i=1}^{m} x_i+\sum_{i\in A\setminus S}x_i=n$$, which is a weak composition of $n$ with $2m-k$ parts such that $x_i=2j_i$ for all $i\in A\setminus S$. Here is where I hit a brick wall! I don't see a simple way to figure out the number of weak compositions of $n$ with $2m-k$ parts such that $x_i=2j_i$ for all $i\in A\setminus S$. Your help is extremely appreciated!!","['discrete-mathematics', 'number-theory', 'multisets', 'combinatorics']"
1193581,Show that there is a probability such that $P_n$ converges weakly/in distribution as $n \to \infty$.,"Suppose that $P_n$ $n \ge 1$ is a sequence of probabilities concentrated on $[a,b]$. Suppose that one may show for each positive integer $r$ that $\int_{[a,b]}x^rP_n(dx) \to m_r \in R$ as $n \to \infty$. Show that there is a probability $P$ such that $P_n \Rightarrow P$ as $n \to \infty$ and $\int_{[a,b]}x^rP(dx) = m_r$ for each $r \ge 1$. My attempt at a solution: I believe that because we are looking at probabilities on $[a,b]$, we automatically have that the sequence is tight. At which point I would like to apply Prohorov's Theorem, which would implies that the weak closure of the sequence is compact in the weak topology. But I have no idea what to do from here. Edit 1: I have made some progress. So, for a subsequence that converges weakly to $P$, say, $P_{n_k}$, whose existence we are guaranteed by Prohorov's Theorem, that subsequence converges weakly to some $P_k$. Therefore, for all continuous, bounded functions $f$ on $[a,b]$, we have that 
$$\int_{[a,b]} f(x)P_{n_k}(dx) \to \int_{[a,b]}f(x)P_k(dx)$$
I'm thinking that from here we'll want to apply Weierstrass (all continuous, bounded functions can be approximated by polynomials) but I don't quite know how to do it.","['probability-theory', 'weak-convergence', 'probability']"
1193597,Hölder continuity of $\frac1x$,"I have a question. Is the function $f(x)=1/x$ Hölder continuous if $x\in (\varepsilon,+\infty),\ \varepsilon>0$?","['holder-spaces', 'continuity', 'functional-analysis', 'real-analysis']"
1193615,Probability of another 3 integers with same sum and product as the first 3 integers,"Let us suppose $3$ integers are selected at random from a large range, say $$-1000\leq x\leq y\leq z\leq 1000$$ Now, we define the sum and product:
$$\begin{align*}s&=x+y+z \\p&=xyz\end{align*}$$ ($s$ and $p$ will not be equal in most cases, sorry for the confusion) What is the probability that there exists another solution for $(x,y,z)$ that satisfies above 3 equations? (reordering of x, y and z not allowed) My friend gave me this question, and I have no idea where to start. If we limit ourselves to positive integers, is there a unique solution, or not?","['probability-theory', 'algebra-precalculus', 'probability', 'diophantine-equations']"
1193628,"Does every $9 \times 9$ Latin square contain a $3 \times 3$ submatrix containing each symbol in $\{1,2,\ldots,9\}$?","Q : Does every $9 \times 9$ Latin square on the symbol set $\{1,2,\ldots,9\}$ contain a $3 \times 3$ submatrix containing each symbol in $\{1,2,\ldots,9\}$? This one has $1728$ such submatrices, which is as low as I've gotten:
$$
\begin{bmatrix}
6 & 7 & 8 & 9 & 1 & 4 & 2 & 3 & 5 \\
5 & 6 & 1 & 7 & 2 & 8 & 3 & 4 & 9 \\
9 & 1 & 6 & 2 & 4 & 3 & 7 & 5 & 8 \\
4 & 5 & 3 & 6 & 8 & 7 & 1 & 9 & 2 \\
1 & 2 & 4 & 8 & 3 & 5 & 9 & 6 & 7 \\
2 & 3 & 7 & 4 & 9 & 6 & 5 & 8 & 1 \\
8 & 9 & 2 & 3 & 5 & 1 & 6 & 7 & 4 \\
7 & 8 & 5 & 1 & 6 & 9 & 4 & 2 & 3 \\
3 & 4 & 9 & 5 & 7 & 2 & 8 & 1 & 6 \\
\end{bmatrix}$$ It doesn't seem likely that random Latin squares will help much; they average in the thousands of such submatrices.  The one above is the best random Latin square I've found so far (although, I haven't busted a gut doing this; it seems like it won't work anyway). The groups of order $9$ have lots ($C_9$ has $5832$ and $C_3 \times C_3$ has $19440$). This question was motivated by answering this math.SE question which asks if any $9 \times 9$ Latin square can have its rows and columns permuted to give a sudoku square. One way to find an explicit counterexample would be to find a $9 \times 9$ Latin square with no $3 \times 3$ submatrix containing each symbol in $\{1,2,\ldots,9\}$.  But this attempt didn't work since I couldn't find one.  Hence my question.","['latin-square', 'discrete-mathematics', 'combinatorics']"
1193654,Evaluating $\sum\limits_{n=1}^{\infty} \left(\frac{1}{4 n-3}+\frac{1}{4 n-1}-\frac{1}{2 n}\right)$,$$\sum\limits_{n=1}^{\infty} \left(\frac{1}{4 n-3}+\frac{1}{4 n-1}-\frac{1}{2 n}\right) = \;?$$ I have been trying to see if it can be written as sum of two telescope terms but it looks tricky. Any help ?,['sequences-and-series']
1193687,How to evaluate $\int \sqrt{\sin^{-1}(\sqrt{\phi})} d\phi $?,"How do I go about solving the below integral? $$I_1=\int \sqrt{\sin^{-1}(\sqrt{\phi})} d\phi $$ Background: I came across the simpler version of this, which required me to evaluate: $$\int\sin^{-1}(\sqrt{\phi})d\phi$$ I got the solution for this: $$\big[\sin^{-1}(\sqrt{\phi})\big(\phi-\frac{1}{2}\big) + \frac{\sqrt{\phi(1-\phi)}}{2}\big] + C$$ But I still don't see this helping me solve the original question (i.e. $I_1$ ). Note: Wolfram Alpha gives this solution, but I want to know how to arrive at it. Edit: I did a substitution $\phi = \sin^2(\psi)$ to get: $$\int \sqrt{\psi}\sin(2\psi)d\psi$$ Now I'm stuck...","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
1193705,"Compute the covariance of $\xi$ and $\min \{\xi,2\}$, where $\xi$ is exponentially distributed","Let $\xi$ be a random variable exponentially distributed and let $\xi_1=\min \{\xi,2\}$. Calculate $Cov(\xi,\xi_1)$. I know the problem is easy but I just need somebody to check my work. Here's my solution. $$
E(\xi\cdot\xi_1)=\int_0^\infty x\cdot\min(x,2)\cdot\lambda\exp(-\lambda x) \,dx=
\int_0^2x^2\lambda e^{-\lambda x} \,dx+2\int_2^\infty x\lambda e^{-\lambda x} \,dx=\int_0^{2\lambda} \lambda^{-2} t^2e^{-t}\,dt +\frac{2}{\lambda}\int_{2\lambda}^{\infty}te^{-t}\,dt=\frac{-e^{-t}(t^2+2t+2)}{\lambda^2}|_{t=0}^{2\lambda}+\frac{-2(1+t)e^{-t}}{\lambda}|_{t=2\lambda}^{\infty}=\frac{2}{\lambda^2}(1-e^{-2\lambda}(\lambda+1)).
$$
Next
$$
E(\xi_1)=\int_0^{\infty}\min(x,2)\lambda e^{-\lambda x}\,dx=\int_0^2 x\lambda e^{-\lambda x}\,dx+2\int_2^\infty\lambda e^{-\lambda x}\,dx=\lambda^{-1} \int_0^{2 \lambda}te^{-t}\,dt+\int_{2\lambda}^{\infty}2e^{-t}\,dt=\frac{-e^{-t}(1+t)}{\lambda}|_{t=0}^{2\lambda}-2e^{-t}|_{t=2\lambda}^{\infty}=\frac{1-e^{-2\lambda}(1+2\lambda)}{\lambda}+2e^{-2\lambda}=\frac{1-e^{-2\lambda}}{\lambda}.
$$
Hence
$$
Cov(\xi,\xi_1)=E(\xi\cdot\xi_1)-E\xi\cdot E\xi_1=\frac{2}{\lambda^2}(1-e^{-2\lambda}(\lambda+1))-\frac{1-e^{-2\lambda}}{\lambda^2}=\frac{1-e^{-2\lambda}-2\lambda e^{-2\lambda}}{\lambda^2}
$$
Could you please check whether it is correct?","['probability-distributions', 'probability']"
1193722,Proof of relation between maximum element and induced $p$-norm of a matrix,"If true, prove the identity:
$$
||A|| \ge \max\limits_{i,j}|a_{ij}|
$$ $||.||$ is any induced/operator norm. Edit: The identity is true only for operator norm induced by $p$-norm for vectors. I found this property in a presentation of singular values and matrix norms. This property could be useful for me in my work but I am not able to prove it.","['matrices', 'normed-spaces', 'vectors']"
1193723,Why do we define curves on manifolds via the objects $\phi\circ\gamma$?,"Consider the following definition: ($M$ denotes a manifold structure, $U$ are subsets of the manifold and $\phi$ the transition functions) Def :   A smooth curve in $M$ is a map $\gamma: I \rightarrow M,$ where $I \subset \mathbb{R}$ is an open interval, such that for any chart $(U,\phi)$, the map $\phi \circ \gamma : I \rightarrow \mathbb{R}^n$ is smooth. My first question is, why do we define a smooth curve in this way? In particular, why is the map $\phi \circ \gamma$ a good object to consider? The only thing that comes to mind is that now we have a function defined from $\mathbb{R} \rightarrow \mathbb{R}^n$ so differentiation is well defined and thus one may introduce the concept of a tangent vector (as below). Now let $f: M \rightarrow \mathbb{R}$ be a smooth function on $M$ and $\gamma: I \rightarrow M$, smooth curve as before. Then $f \circ \gamma : I \rightarrow \mathbb{R}$ is smooth. Hence we take a derivative to find the rate of change of $f$ along the curve $\gamma$: $$\frac{d}{dt}f(\gamma(t)) = [(f \circ \phi^{-1}) \circ (\phi \circ \gamma)]'(t) = \sum_{i=1}^n \left(\frac{\partial (f \circ \phi^{-1})}{\partial x^i}\right)_{\phi(\gamma(t))} \frac{d}{dt} x^i(\gamma(t))$$ My next question is to simply understand how this equation comes about. I can see it is some application of the chain rule but I am struggling with the precise details of the equation, mostly in how the final equality comes about and the subscript on the  $\partial (f \circ \phi^{-1})/\partial x^i$  term.  Many thanks!","['curves', 'differential-geometry', 'manifolds', 'linear-algebra', 'derivatives']"
1193736,Suppose that $f$ is a differentiable function such that $f(g(x)) = x$ and $f^\prime(x) = 1+ [f(x)]^2$. Show that $g^\prime(x) = \frac{1}{1+x^2}$.,"Suppose that $f$ is a differentiable function such that $f(g(x)) = x$ and $f^\prime(x) = 1 + [f(x)]^2$. Show that $g^\prime(x) = \dfrac{1}{1+x^2}$. $$
f(g(x)) = x \implies f = g^{[-1]}
$$ I have been told: $$
f^{[-1]\prime}(f^\prime(c)) = \dfrac{1}{f^\prime(c)}
$$ However, I have no intuition of this being true, thus I have a weak understanding of it. I feel as though it may somehow be applicable when considering $f$ is the inverse of $g$ and have been defined as they have. I'm not familiar with the formal name of this truth, so knowing that would be a start on being able to find material from which to study it. Edit: The problem only defines $f^\prime(x)$. It doesn't define $f^\prime(g(x))$. The formula which was derived is relative to functions, their inverses, and their respective derivatives. It is not necessarily so that $f′(x) = f′(g(x))$. So, how could it be shown that $g'(x) = \dfrac 1 {f'(g(x))} = \dfrac 1 {1+f(g(x))^2} = \dfrac 1 {1+x^2}$ when we don't know what $f^\prime(g(x))$ or $g^\prime(x)$ is?","['calculus', 'derivatives', 'functions']"
1193740,Centralizers of reflections in parabolic subgroups of Coxeter groups,"Let us consider a (not necessarily finite) Coxeter group $W$ generated by a finite set of involutions $S=\{s_1,...,s_n\}$ subject (as usual) to the relations $(s_is_j)^{m_{i,j}}$ with $m_{i,j}=m_{j,i}$ and  $m_{i,j}=1$ if and only if $i=j$ (if necessary you may also assume that $m_{i,j}<\infty$ for all $i,j$). Let $P\leq W$ be a subgroup generated by all but one of the $s_i$, say wlog $P=\langle s_1,...,s_{n-1}\rangle$. I am interested in the centralizer of $s_n$ in $P$. In particular I would like to know if $C_P(s_n)=C_W(s_n) \cap P=\langle s_i~|~ 1\leq i\leq n-1, m_{i,n}=2\rangle=:Z$ always holds. Obviously this is true if $n=2$ and I believe (though I have not written it down rigorously) I can prove it for Coxeter groups of type $A_n$ by using the standard isomorphism to $S_n$. On the other hand the centralizer of $s_n$ in $W$ is not necessarily a standard parabolic subgroup (look at the dihedral group of order $8$ for example). There are some results on centralizers of reflections in Coxeter groups and on normalizers/centralizers of parabolic subgroups (which is the same in this special case) to be found in the literature but most deal with the centralizer in $W$. In principal it should be possible to obtain the centralizer in $P$ from these results by simply taking the intersection but the results I found so far are not explicit/ simple enough for this to be a feasible solution. Edit: Some thoughts so far: I can show that elements of $C_P(s_n)$ of length $1$ or $2$ already lie in $Z$ (the case $1$ being trivial) and that elements of $C_P(s_n)$ of length $3$ where all three occurring simple reflections are pairwise distinct already belong to $Z$. On the other hand look at $s_1s_2s_1 \in C_P(s_n)$ which centralizes $s_n$ if and only if $s_2$ centralizes $s_1s_ns_1$. I don't see any reason why this should not be the case so I tried constructing a counterexample consisting of $s_1,s_2$ and $s_3$ such that $s_1,s_2$ do not commute and $s_1s_3$ do not commute but $s_2$ and $s_1s_3s_1$ do. Any ideas on how to do that?","['coxeter-groups', 'reference-request', 'group-theory']"
1193746,Calculating $\mathrm{Var} (Z|Z|)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Suppose $Z\sim N(0,1). $ How can I calculate $\mathrm{Var} (Z|Z|)$? I know $\mathrm{Var} (Z|Z|)= \mathrm{E}(Z^4)-\mathrm{E}^2(Z|Z|)$",['statistics']
1193763,Eigenvalues of product matrix,"I have two matrices, both positive definite, real symmetric and one is diagonal. What can I say about lower and upper bound of the eigenvalues of the product matrix in terms the of lower and upper bounds on eigenvalues of those two matrices.",['linear-algebra']
1193772,Why the mean value of a Gaussian process is usually set to zero?,"In most textbooks (e.g. Rasmussen's book on Gaussian Processes for Machine Learning) the mean value of a gaussian process is set to zero. Of course, this does not mean that all the values are expected to be zero since we are looking for the Maximum a Posteriori estimate of these variables, which do not have any more a zero mean. Is there a mathematically robust proof or at least an explanation based on mathematics that the assumption of the zero mean value is not too prohibitive for the a posteriori estimate? To make things a bit more clear, assume that we have the following model where the noise $e$ is uncorrelated with $f(x)$: $y= f(x) +e $, $f(x) \sim \mathcal{N} (m, K)$, $e \sim \mathcal{N} (0, \sigma^2)$. Then the a posteriori (which is actually the MAP estimate) is given by $\mathbb{E} (f | y) = m + K (\sigma^2 I + K)^{-1} (y-m)$ The way I see it, by setting the mean equal to zero we usually reduce the number of hyperparameters that have to be estimated, because most of the times the mean is also unknown, so it has to be parametrized by some hyperparameters and then these hyperparameters have to be estimated by a non-convex optimization routine, thus increasing the computational burden. However, this does not explain mathematically if the assumption that the mean is zero does not restrict too much the a posteriori estimate. Any help would be appreciated!","['statistics', 'statistical-inference', 'random-variables']"
1193786,Computing $\sum_{i=2}^{n-1} 1$ and $\sum_{i=2}^{n-1} i$.,"Could someone explain how I calculate these summations? I'm using upper - lower + 1. a) $\displaystyle\sum_{i=2}^{n-1} 1$ b) $\displaystyle\sum_{i=2}^{n-1} i$ So for (a) I have: 
$$
(n-1) -2 +1)1 = -1n - 1.
$$ For (b) I have:
$$
((n-1) -2 +1)2 = -2n -1.
$$ Are these calculations correct?","['summation', 'algebra-precalculus', 'solution-verification']"
1193794,Why did it take mathematicians so long to discover non-Euclidean geometry?,"Why did it take mathematicians so long to realise that Euclid's fifth postulate is independent of the other 4? Why didn't people like Lagrange notice that a sphere is a model for a non-Euclidean geometry (first 4 axioms satisfied, the fifth not satisfied)? They had ships and cartography long before Gauss and Bolyai were born. Am I misunderstanding something?","['geometry', 'math-history']"
1193797,The Idea behind the Second Partial Derivative Test,"I'm currently learning about local extrema in serveral variables and have come across the second derivative test for classifying critical points of multivariable functions. I have read and understood the test (see link below), however I don't understand the idea behind it. Why is the critical point of a function a minimum if the eigenvalues of the Hessian matrix are all positive? I understand the idea behind the single variable case, however I am confused about the role of eigenvalues in the case of several variables. http://en.wikipedia.org/wiki/Second_partial_derivative_test Any insight into this would be much appreciated. Thanks.","['multivariable-calculus', 'eigenvalues-eigenvectors', 'partial-derivative']"
1193824,Minimize : $\sqrt{(1+{1\over a})(1+{1\over b})}$ subject to $a+b=\lambda$.,"Given positive real variables $a$ and $b$, find the minimum of  $$f(a,b)=\sqrt{\left(1+{1\over a}\right)\left(1+{1\over b}\right)}$$  subject to  $a+b=\lambda$ where $\lambda$ is a constant . [ISI Sample Papers] Method $1$ : Substitute $b=\lambda - a$ and then compute ${\partial \over \partial a }f(a,b)$. But, the calculations get a bit messy. Method $2$ : Actually this is what I want to know. Is there an easier approach using some inequalities like the AM-GM inequality ? I tried this but was not able to got lost in between. Method $3$ : Lagrange multipliers. I have not tried this and kept it as a last option. What is the best way to solve this problem ?","['optimization', 'multivariable-calculus', 'inequality', 'lagrange-multiplier', 'problem-solving']"
1193847,About the uniqueness of a quadric determined by sufficient points,"What is the condition on a set of 14 points for them to uniquely determine a quadric in $\mathbb{P}^4$? Is being in linear general position enough to guarantee uniqueness? If not, what is the alternative condition? In what precise sense of ""general position"" must the points be in general position? What if I know that the quadric is non-singular? If I pick 14 points from the intersection of two non-singular quadrics in $\mathbb{P}^4$, can they be in general position? Thank you.","['algebraic-geometry', 'quadrics']"
1193852,"Existence of continuous bijective function $f:[0,1] \times [0,1] \to [0,1] $ ? Continuous and only injective and continuous and olny surjective?","Does there exist any continuous bijective function $f:[0,1] \times [0,1] \to [0,1] $ , where $[0,1]$ is equipped with usual Euclidean metric of $\mathbb R$ and $[0,1] \times [0,1]$ is equipped with the usual Euclidean metric of $\mathbb R^2$ ? What if we require the continuous  mapping to be only injective or only surjective ?","['metric-spaces', 'continuity', 'functions', 'analysis']"
1193883,Solving system of delay differential equations,"Are there any numerical methods for solving systems of delay differential equations with time-dependent delays?
For example, I have a system: $$\frac{dP_1}{dt}  = f_1(t) P_2(t-\tau(t)) P_3(t)$$ $$\frac{dP_2}{dt}  = f_2(t) P_3(t-\tau(t)) P_1(t)$$ $$\frac{dP_3}{dt}  = f_3(t) P_1(t-\tau(t)) P_2(t)$$ I thought about applying method of steps together with Runge-Kutta method, but it leads to loss of information, because Runge-Kutta method requires values of RHS at $(x+1/2 h)$, where $h$ is a step. So, I'm interested if any other methods except this one exist for solving such systems.
And, if they exist, could you please tell me where I can read about them, because I didn't find useful information.","['ordinary-differential-equations', 'delay-differential-equations', 'reference-request', 'numerical-methods']"
1193904,"Evaluating $\sum_{0\leq k,l \leq n}\binom{n}{k}\binom{k}{l}l(k-l)(n-k)$ algebraically","I'm having problems with the following sum: $$\sum_{0\leq k,l \leq n}\binom{n}{k}\binom{k}{l}l(k-l)(n-k)$$ It's quite easy to think about it combinatorically: We have $n$ balls, we're coloring $k$ of them, then $l$ of these colored balls get sprinkled with gold. Then we're putting a crown on one colored ball, one colored, sprinkled with gold ball and one uncolored ball. It's all kind of funny but it allowed me to come up with, as it turns out, correct evaluation of this sum - first we're crowning 3 balls $\binom{n}{3}$, then we're chosing for each ""crowned"" ball whether it's colored, colored and sprinkled with gold or uncolored ($3!$) and then for the remaining $n-3$ balls we're either coloring them, coloring them and sprinkling with gold or do nothing with them ($3^{n-3}$). So we get: $\sum_{0\leq k,l \leq n}\binom{n}{k}\binom{k}{l}l(k-l)(n-k)=\binom{n}{3}3!3^{n-3}=n(n-1)(n-2)3^{n-3}$ But I have no idea how to get the similair result using only algebraic methods. Any hints?","['summation', 'discrete-mathematics', 'binomial-coefficients']"
1193970,Monotone class theorem vs Dynkin $\pi-\lambda$ theorem,"Monotone class theorem : Let $\mathcal C$ be a class of subset closed under finite
  intersections and containing $\Omega$ (that is, $\mathcal C$ is a
  $\pi$-system). Let $\mathcal B$ be the smallest class containing
  $\mathcal C$ which is closed under increasing limits and by difference
  (that is, $\mathcal B$ is the smallest $\lambda$ system containing $\mathcal C$). Then $\mathcal B =
 \sigma(\mathcal C)$ Dynkin $\pi-\lambda$ theorem If $P$ is a $\pi$ system and $D$ is a $\lambda$ system with $P
 \subseteq D$, then $\sigma(P) \subseteq D$ (Also, I believe that it can concluded that $D$ is a $\sigma$ algebra) It seems to me that they are basically the same thing. Dynking statement is slightly more general but more or less the same. Is it it true or am I misunderstanding something?","['probability-theory', 'monotone-class-theorem', 'measure-theory', 'probability']"
1193973,What is the relation between dx in elementary calculus and dx in differential geometry?,"I've recently started studying differential geometry and was really hoping that in doing so I'd finally have an answer to something that's been bugging me since I first learnt calculus - what is $dx$?! As far as I understand, in differential geometry $dx^{i}$ is a linear functional that maps vectors in a tangent space $T_{p}M$ at a point $p\in M$ on a manifold $M$ to the set of real numbers $\mathbb{R}$, i.e. $$dx^{i} :T_{p}M\rightarrow\mathbb{R}$$ In this sense the differential form $dx^{i}$ maps a vector $v\in T_{p}M$ to its $i^{th}$ coordinate with respect to the coordinate basis $\frac{\partial}{\partial x^{i}}$, i.e. $dx^{i}(v)=v^{i}$. In elementary calculus I was always told when I asked the question ""what is $dx$?"" , that it is an infinitesimal change in the x-coordinate . This has never rested easy with me as e.g. if we have the formula $$ df=\lim_{\Delta x\rightarrow 0}\Delta f = \lim_{\Delta x\rightarrow 0}f'(x)\Delta x $$ then due to the properties of limits this can be expressed as $$\lim_{\Delta x\rightarrow 0}f'(x)\lim_{\Delta x\rightarrow 0}\Delta x$$ and clearly $\lim_{\Delta x\rightarrow 0}\Delta x =0$ which seems inconsistent. So my main question is: what actually is $dx$ and is there any intuitive (perhaps geometric) explanation as to how it relates to an infinitesimal line element?","['differential-forms', 'calculus', 'differential-geometry']"
1193999,$TS^1$ is Diffeomorphic to $S^1\times \mathbf R$.,"I know this is a very basic question. But I am unable to get every detail right. I need to show that $TS^1$ is diffeomorphic to $S^1\times \mathbf R$. (I am using the concept of derivations to define the tangent spaces.) I asked this of my friends and this is what, in essence, I have learned from them: Define $f:TS^1\to S^1\times \mathbf R$ as 
$$f
\left(
p;\ \lambda\left(p_2
\left.\frac{\partial}{\partial x_1}\right|_{p}-p_1\left.\frac{\partial}{\partial x_2}\right|_p
\right)
\right)
=
(p,\ \lambda)
$$
for all $p=(p_1,p_2)\in S^1$ and all $\lambda\in \mathbf R$, and show that this is a diffeomorphism. My problem with this is that: $\left(p_2
\left.\frac{\partial}{\partial x_1}\right|_{p}-p_1\left.\frac{\partial}{\partial x_2}\right|_p
\right)$ is not really a member of $T_pS_1$. It lies in $di_p(T_pS^1)\subseteq T_p\mathbf R^2$, where $i:S^1\to \mathbf R^2$ is the inclusion map. (Reason: The manifold structure of $S_1$ is governed by the fact that $i:S^1\to \mathbf R^2$ is a smooth embedding, and thus, a tangent vector $X_p\in T_p\mathbf R^2$ is in $di_p(T_pS^1)$ if an only if $X_p\xi=0$ for all $\xi\in \mathcal C^\infty(\mathbf R^2)$ with $\xi|S^1\equiv 0$.) Keeping this in mind, I attempted the following: Define $F:T\mathbf R^2\to \mathbf R^2\times \mathbf R^2$ as 
$$
F\left(p,\ a_1
\left.
\frac{\partial}{\partial x_1}
\right|_p+a_2\left.\frac{\partial}{\partial x_2}\right|_p\right)
=
(p,\ a_1, a_2)
$$
for all $p\in \mathbf R^2$ and $a_1, a_2\in \mathbf R$. We note that $F$ is a diffeomorphism. Now define $G:\mathbf R^2\times \mathbf R^2\to \mathbf R^2\times \mathbf R$
as
$G(p, a_1, a_2)=(p, \sqrt{a_1^2+a_2^2})$. We note that $G$ is smooth. Finally, since $i:S^1\to T\mathbf R^2$ is smooth (it is more than that), we have $di:TS^1\to T\mathbf R^2$ is also smooth. Now $G\circ F\circ di: TS^1\to S^1\times \mathbf R$ is thus a smooth map, since composition of smooth maps is smooth. But I am unable to show that this map is the required diffeomorphism. Can somebody help?","['smooth-manifolds', 'differential-geometry']"
1194005,Derivative of $f(x) = (x^2 +1)^3 (2x+5)^2$,"I have function
$$f(x) = (x^2 +1)^3 (2x+5)^2$$ I need to find the derivative. I believe that I need to use the product rule and chain rule. Here's what I did. $$f'(x) = (2x+5)^2[3(x^2+1)^2(2x)] + (x^2+1)^3[2(2x+5)2]
\\ = (2x+5)^2(6x(x^2+1)^2)+4(2x+5)(x^2+1)^3
\\ = 6x(2x+5)^2(x^2+1)^2+4(2x+5)(x^2+1)^3$$ That is what I have. But the problem is, the answer book says that the answer is, $$2(x^2+1)^2(2x+5)(8x^2+15x+2)$$ Since the answer book has been wrong few times, so I checked the answer with a calculator.
The calculator showed the same answer. Then I used another calculator (which showed some steps), showed my answer. The calculator showed, Which answer is correct?? Or are they just equivalent answers??
If I did wrong, what was the problem??
Can it be factorized? How? Thank you","['calculus', 'algebra-precalculus', 'derivatives']"
1194012,"Is $\prod \limits_{i = 1}^{n} [0,1] \subseteq \mathbb R^n$ homeomorphic to the closed unit ball?","Is $\prod \limits_{i = 1}^{n} [0,1] \subseteq \mathbb R^n$ homeomorphic to $\bar B(\theta , 1)$ , the closed ball centered at origin with radius $1$? Can someone please give some reference links to study elementary techniques to deal with homeomorphism and to show two given spaces homeomorphic ?","['general-topology', 'metric-spaces', 'analysis']"
1194018,Is there an intuitve motivation for the wedge product in differential geometry?,"I've recently started studying differential forms and have been looking at differential forms. I'm struggling to understand the motivation for introducing the notion of the wedge product. Does it simply arise when generalising the notion of a "" signed area/volume "" in higher dimensional spaces, or is there a deeper reasoning behind it? If it is just a generalisation of a "" signed area/volume "" in higher dimensional spaces then my understanding is that the ""area"" spanned by two tangent vectors $X,Y$ is given by the wedge product between their associated differential forms. Thus, in one-dimension, if we have a one-form $\omega$ expressed in a local coordinate basis as $\omega =f_{i}(x)dx^{i}$, then $$\omega\wedge\omega = f_{i}(x)f_{j}(x)dx^{i}\wedge dx^{j}$$ and so from this, if X=Y, then the ""area"" spanned by them should be zero and so, $$\omega\wedge\omega (X,X)=0=f_{i}(x)f_{j}(x)dx^{i}(X)\wedge dx^{j}(X)\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\\ \quad\;\;=\frac{1}{2}\left[f_{i}(x)f_{j}(x)dx^{i}(X)\wedge dx^{j}(X)+f_{j}(x)f_{i}(x)dx^{j}(X)\wedge dx^{i}(X)\right]$$ and this implies that $$dx^{i}(X)\wedge dx^{j}(X)=-dx^{j}(X)\wedge dx^{i}(X)$$
I'm unsure whether my understanding here is correct or not?","['exterior-algebra', 'differential-forms', 'differential-geometry']"
1194028,Compass and straightedge contruction of an equilateral triangle inscribed in a given circle with unknown center,"I haven't found a proper solution for this problem, found in Hartshorne's ""Geometry: Euclid and Beyond"": (4.3) Given a circle, but not given its center, construct an inscribed equilateral triangle in as few steps as possible. I managed to construct it in $9$ steps (use of compass or straightedge) but I can't get any lower. Finding circle center takes $5$ of those $9$ uses, and then I need $1$ more to get vertices and $3$ for constructing the triangle.","['geometry', 'geometric-construction']"
1194031,The series $\sum\limits_{n\ge1}n^{-z}$ converges locally normally,"Show that the series $\sum\limits_{n\ge1}n^{-z}$ converges locally normally on the half plane $\{z:\text{Re}(z)>1\}$ $\displaystyle n^{-z}=\frac{1}{n^z}\le\frac{1}{|n^z|}=\frac{1}{n^{\text{Re}(z)}}\le\frac{1}{n^{1+\epsilon}}$ (If $z=x+iy$ with $x>1$ then $\exists\epsilon>0$ s.t. $x>1+\epsilon$) So it converges absolutely and also normally, because then there is always an $r$-neighbourhood for every $z_0\in\{z:\text{Re}(z)>1\}$, such that; $\displaystyle\sum\limits_{n\ge1}||n^{-z}||_{\{z:|z-z_0|\le r\}}=\sum\limits_{n\ge1}\sup\limits_{z\in\{z:|z-z_0|\le r\}}|n^{-z}|=\sum\limits_{n\ge1}\frac{1}{n^{\inf\{\text{Re}(z):z\in\{z:|z-z_0|\le r\}\}}}$ but how can I show formally that $\exists\delta>0:$ $\displaystyle\frac{1}{n^{\inf\{\text{Re}(z):z\in\{z:|z-z_0|\le r\}\}}}\le\frac{1}{n^{1+\delta}}$ Is it enough to say $\{z:|z-z_0|\le r\}\subsetneq\{z:\text{Re}(z)>1\}$ ?","['complex-numbers', 'complex-analysis']"
1194033,Why in Teichmüller-Tukey lemma finiteness is essential?,First we will state a Teichmüller-Tukey Lemma: Let $A$ be a set and $\phi$ be a property defined on all finite subset of $A$. Assume that $B$ is a subset of $A$ such that each finite subset of $B$ have property $\phi$. Then $B$ can be extended to a maximal subset $M$ of $A$ such that each finite subset of $M$ has a property $\phi$. My question is :- In the statement there is condition of finite . In case we have countable why we could not show that its equivalent with the axiom of choice.,"['elementary-set-theory', 'axiom-of-choice']"
1194064,find the limit of this problem,Prove that $\int\limits_1^x e^t/t dt \sim (e^x)/x$ as $x \longrightarrow \infty$. any ideas of how to approach this problem. I can not seem to evaluate the integral either so i am real stuck in this problem,"['calculus', 'limits']"
1194072,Where do summation formulas come from?,"It's a classic problem in an introductory proof course to prove that $\sum_{ i \mathop =1}^ni = \frac{n(n+1)}{2}$ by induction. The problem with induction is that you can't prove what the sum is unless you already have an idea of what it should be. I would like to know what the process is for getting the idea. Wikipedia has plenty of summation formulas listed, and there are surely lots more, but I think I should be able to simplify summations without referring to a table. I don't suppose there's a universal technique for deriving all of them, but it would be good to know at least a few things to try. This question was motivated by an answer involving summation, and while I have no doubt that it's true, I wouldn't know how to get the answer to the particular summation without being told beforehand.","['summation', 'sequences-and-series', 'combinatorics']"
1194085,How does one bound computational error for a finite difference approximation of the second derivative?,"I'm trying to wrap my head around ways to minimize total computational error (defined as a sum of the bounds on the truncation and rounding errors) by taking a differentiable function $f : \mathbb{R} \rightarrow \mathbb{R}$ and a finite difference approximation of its second derivative $$
f''(x) = \frac{f(x + h) - 2f(x) + f(x-h)}{h^2}
$$ I know that, by Taylor's Theorem $$
f(x + h) = f(x) + f'(x)h + f''(x)\frac{h^2}{2} + f'''(\theta)\frac{h^3}{6}
$$ for some $\theta \in [x, x + h]$. How would you determine the value of $h$ for which a bound of the total computational error is minimized?","['error-propagation', 'derivatives', 'numerical-methods']"
1194115,When does function composition commute? [duplicate],"This question already has answers here : When functions commute under composition (3 answers) Closed 9 years ago . I've read that function composition ""generally does not commute."" Not counting compositions involving the identity function, and compositions of a function and its inverse, are there examples of functions on the reals (for example) $f, g$ where $fg = gf$ outside of these cases?",['functions']
1194139,Is there another way to solve this integral?,"My way to solve this integral. I wonder is there another way to solve it as it's very long for me. $$\int_{0}^{\pi}\frac{1-\sin (x)}{\sin (x)+1}dx$$ Let $$u=\tan (\frac{x}{2})$$
$$du=\frac{1}{2}\sec ^2(\frac{x}{2})dx $$ By Weierstrass Substitution $$\sin (x)=\frac{2u}{u^2+1}$$ $$\cos (x)=\frac{1-u^2}{u^2+1}$$ $$dx=\frac{2du}{u^2+1}$$ $$=\int_{0}^{\infty }\frac{2(1-\frac{2u}{u^2+1})}{(u^2+1)(\frac{2u}{u^2+1}+1)}du$$ $$=\int_{0}^{\infty }\frac{2(u-1)^2}{u^4+2u^3+2u^2+2u+1}du $$ $$=2\int_{0}^{\infty }\frac{(u-1)^2}{u^4+2u^3+2u^2+2u+1}du  $$ $$=2\int_{0}^{\infty }\frac{(u-1)^2}{(u+1)^2(u^2+1)}du $$ $$=2\int_{0}^{\infty }(\frac{2}{(u+1)^2}-\frac{1}{u^2+1})du $$ $$=-2\int_{0}^{\infty  }\frac{1}{u^2+1}du+4\int_{0}^{\infty}\frac{1}{(u+1)^2}du $$ $$\lim_{b\rightarrow \infty }\left | (-2\tan^{-1}(u)) \right |_{0}^{b}+4\int_{0}^{\infty}\frac{1}{(u+1)^2}du$$ $$=(\lim_{b\rightarrow \infty}-2\tan^{-1}(b))+4\int_{0}^{\infty}\frac{1}{(u+1)^2}du$$ $$=-\pi+4\int_{0}^{\infty}\frac{1}{(u+1)^2}du$$ Let $$s=u+1$$ $$ds=du$$ $$=-\pi+4\int_{1}^{\infty}\frac{1}{s^2}ds$$ $$=-\pi+\lim_{b\rightarrow \infty}\left | (-\frac{4}{s}) \right |_{1}^{b}$$ $$=-\pi+(\lim_{b\rightarrow \infty} -\frac{4}{b}) +4$$ $$=4-\pi$$ $$\approx 0.85841$$","['definite-integrals', 'calculus', 'integration']"
1194153,When does convergence of function imply convergence of its derivative?,"Let $F_n$ be a sequence of differentiable real valued functions. Suppose that $$\lim_{n \to \infty} F_n(x) = F(x)$$ and that $F(x)$ is differentiable. Under which conditions does that imply $$\lim_{n \to \infty} F'_n(x) = F'(x)$$ ? Do I need some regularity, or maybe that the $F_n$ converges uniformly?","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'uniform-convergence']"
1194239,Maximal abelian subgroup of general linear groups,"Thanks for any help or comments. Is it possible to recognize all maximal abelian subgroups of general linear group on finite field $F$ of order $q$,  $GL_n(F)$.
By maximal abelian I mean if $A$ is maximal abelian and $B$ is abelian such that $A\subseteq B$, then $B=A$.","['finite-groups', 'group-theory']"
1194272,Approximation of $\sqrt{ x + y } - \sqrt{ x - y }$,"I've been struggling to try and find a way to approximate the function: $\sqrt{ x + y } - \sqrt{ x - y }$ I should mention that $y$ is positive and a small number, so that $0<y<<1$. What I'm hoping for is to approximate this in such a way that, we have roughly: $\sqrt{ x + y } - \sqrt{ x - y } \approx (1-y)\sqrt{ x + y }$ There may be some numerical factor in front of this. This could very well be absurd, I'm wondering if this can be done at all. It is crucial that I have this factor $\sqrt{ x + y }$ in the approximation. I've thought about defining a function $\ f(r)=\sqrt{r}$. Then I could write: $f(x+y)-f(x-y)$ = $f(x+y)-f(x+y-2y)$ i've tried taking a Taylor expansion but my result isn't working out. Does anyone have some advice?","['approximation', 'functions']"
1194295,To show that $A_4$ is solvable,"I need to show that $A_4$ is solvable.
From what i know the definition of solvable expects to give some chain of subgroups such that each subgroup in the chain is normal to the one in which it is contained and also the quotient group is abelian. So I tried constructing such a chain but I was not able to","['finite-groups', 'group-theory', 'abstract-algebra', 'representation-theory']"
1194302,Find $\lim \sup A_n$ and $\lim \inf A_n$?,"Question: Let $\Omega = R^2. A_n$ is the interior of a circle with center at $\left\{\frac{(-1)^n}{n},0 \right\} $ at radius 1. 
Find $\lim \sup A_n$ and $\lim \inf A_n$ ? My answer is the following;
Let $\Omega = R^2$ As we know, $\lim\sup A_n =\{W: W\in A_n \ \mathrm{for} \ \mathrm{infinite} \ \mathrm{ n}\}$ $\lim\inf A_n =\{W: W\in A_n \ \mathrm{for} \ \mathrm{finite} \ \mathrm{ n}\}$ In this question, there exists a circle with center  at $\left\{\frac{(-1)^n}{n},0 \right\} $ at radius 1. $X^2 + Y^2 =1 \rightarrow x^2 + y^2 =1 \rightarrow (\cos\theta)^2+(\sin\theta)^2 =1 $ let $n=1$ , there exists a circle with $(-1,0)$ at radius 1. $(x-h)^2 +(y-k)^2  =r^2$ $h=1, k=0, r=1$ $(x+1)^2 +(y-0)^2=1^2$ let n=2, there exists a circle with $(1/2, 0)$ at radius 1 $(x-1/2)^2 +(y-0)^2=1^2$ $n=3 \rightarrow (-1/2, 0)$ radius=1 $n=4 \rightarrow (1/4, 0)$ and so on... $\lim\inf A_n =\{(x,y): x^2+y^2\lt 1\}$ $\lim\sup A_n =\{(x,y): x^2+y^2\le 1\} - \{(0,1), (0,-1)\}$ what i dont understand is a point in  the last gray box. How do we obtain these limsup and liminf? please clearly explain the way to get these limsup and liminf thank you for helping.","['general-topology', 'measure-theory', 'limsup-and-liminf', 'real-analysis', 'analysis']"
1194304,system of equations with $n$ equations and $2^k n$ unknowns,"I have a system of equations with infinitely many solutions. I would like to find a ""nice"" way to write down an explicit solution. Here, $n,k\geq 1$ are integers, we have $x_1,x_2,\dots, x_{2^k n}$ unknowns and $n$ equations which take the following form: $$
\begin{cases}
x_1+x_{n+1}+x_{2n+1}+\cdots + x_{(2^k -1)n+1}=0\\
x_2 + x_{n+2}+x_{2n+2}+\cdots + x_{(2^k -1)n+2}=0\\
\vdots\\
x_{n} + x_{2n}+ x_{3n}+\cdots + x_{2^kn} =0.
\end{cases}
$$ Observe two important things: the variables are never repeated, i.e. they only appear once, so the equations are ""independent"" of each other. Also, the unknowns are ordered vertically, that is, starting from the top left $x_1$ then going down to $x_2,x_3,\dots, x_n$ then up again to the second on the top left $x_{n+1}$ then down again... and so on until we arrive at $x_{2^k n}$. As an example: If $k=2$ and $m=3$ then $$
\begin{cases}
x_1+x_{4}+x_{7}+x_{10}=0\\
x_2 + x_{5}+x_{8}+x_{11}=0\\
x_{3} + x_{6}+ x_{9}+ x_{12} =0.
\end{cases}
$$ By Rouché-Cappelli's theorem since the ranges of the two matrices are equal but less than $2^k m$ we have infinitely many solutions. I aim at writing something like: $$w_1 := x_1, w_2 := x_2,\dots, w_m := x_m$$
and then deriving the rest in terms of the $w_j$. Is there a ""nice"" and ""clean"" well-shaped pattern for doing this? I'll be really thankful for any ideas you might have!","['linear-algebra', 'algebra-precalculus', 'systems-of-equations', 'real-analysis']"
1194313,"A rigorous meaning of ""induced measure""?","In my readings I often come across terms like ""induced measure"" or ""induced Lebesgue measure"". For example: $$\int_{\mathbb{B}^n}u\frac{\partial v}{\partial x_j}\;dx = \int_{\mathbb{S}^{n-1}}uv\frac{x_j}{|x|}\;d\sigma - \int_{\mathbb{B}^n}v\frac{\partial u}{\partial x_j}\;dx$$ where $d\sigma$ denotes the induced Lebesgue measure on the sphere. Unfortunately though, I've never really seen anyone give a rigorous definition to this phrase. Sure, in the above example, we understand how to parametrize the $n$ ball, $\mathbb{B}^n$, and the $n-1$ sphere, $\mathbb{S}^{n-1}$, and so the integrals are easy to compute and not very confusing. Sometimes, however, it appears in the context of a general hypersurface in $\mathbb{R}^n$ (say $\Sigma$, with integrals involving $d\Sigma$), or when integrating over a subset (submanifold) of some higher-dimensional  space. In a completely general setting like this, I am at a little bit of a loss when it comes to understanding  how these separate ""surface"" measures or ""induced"" measures are really defined, when I'm lacking an explicit parametrization. It also doesn't help that traditional vector calculus classes seem to always fall short of doing anything past 3 dimensions. For example, I've never seen a class teach its students how to carry out a (2-D) surface integral in anything except $\mathbb{R}^3$; so they would have no idea how to go about finding the surface area of, say a Clifford Torus in $\mathbb{R}^4$. And in general, I've never seen them address a general technique for integrating over an $n$-dimensional body, embedded in $n<m$-dimensional space. It seems like everything they're taught is in terms of the cross product, which fails to be of any use in $\mathbb{R}^{n>3}$. Now I realize that at least some of the hypersurface examples from calculus, that I've mentioned above, can be addressed using the generalized Stokes' theorem: $\int_{D}\text{d}\omega = \int_{\partial D}\omega$. But it seems to me that when we are getting to the realm of measure theory, higher-level analysis, and Riemannian geometry, the word ""induced"" is probably thrown around for a good reason. Let me clarify what I mean: If we are on a Riemannian manifold $M$, then its metric $g$ defines a volume element for the the manifold, $dV_g = \sqrt{\det g}\;dV$, where $dV$ is the Euclidean measure for your coordinate patch in $\mathbb{R}^n$. If we then consider an immersed submanifold $N\hookrightarrow M$, we have a rigourous definition for the induced metric that $N$ inherits from $M$. If we have a topological space $(X,\tau)$, then it induces a subspace topology on any subset $Y\subset X$, $\tau_Y = \{Y\cap U : U\in\tau\}$. Similarly for any subset $Y\subset X$ of a $\sigma$-algebra $(X,\Sigma)$, we have the sub-$\sigma$-algebra $(Y,\Sigma_Y), \Sigma_Y = \{Y\cap A : A\in\Sigma\}$. In these settings, the word "" induced "" has a very specific meaning, and essentially boils down to the idea of a subset inheriting some sort of property from a larger set it belongs to. So it would make sense that there should be some concrete way of having a measure space induce some kind of measure on a subset of itself. At first glance, since a measure space $(X,\Sigma,\mu)$ can give rise to a sub-$\sigma$-algebra (as mentioned above) then you might want to simply take the restriction of $\mu$ to these subsets in $\Sigma_Y$. But the problem is that any subset $E$, without full dimension, will of course have measure zero, $\mu(E)=0$. So this would make for a lousy way to define integration over this subset. So maybe we only concern ourselves with Riemannian manifolds, and just define the induced measure as the one that arrises from the induced metric of some parent manifold. But this seems limiting for a couple reasons: Integration is now limited to Riemannian manifolds, and no longer over a general measure space. For example, while integration with respect to the counting measure makes sense over $\mathbb{N}$, I can't see any way to interpret this as integration over a Riemannian manifold; and so the question of how the counting measure ""induces"" another measure would be meaningless. If we consider a (smooth) subset $S\subset\mathbb{R}^n$, we can build a measure space on $S$ from scratch, similar to how we build the Lebesgue measure on $\mathbb{R}^n$ in measure theory. My question then is: are we always able to realize integration (with respect to this measure) over $S$ as integration with respect to some induced metric, by considering $S\subset M$, for some manifold $(M,g)$? To me, a measure (and anything that it induces) should be in the spirit of measurable sets, and not be restricted to differential manifolds. The Lebesgue measure $\mu$ in $\mathbb{R}^3$ gives us the volume of the unit ball as $\frac{4}{3}\pi$; shouldn't $\mu$ induce a measure on $\mathbb{S}^2$, to give us $4\pi$ surface area? And whatever method we choose, shouldn't it apply to abstract measures as well, not just Lebesgue measure?","['lebesgue-integral', 'measure-theory', 'lebesgue-measure', 'integration']"
1194337,When is the tensor product of a separable field extension with itself a domain?,"I'm reading Algebraic Geometry and Arithmetic Curves by Qing Liu. On page 92, in the proof of Corollary 3.2.14 d), he states that if $K \otimes_k K$ is a domain, then $K = k$. Here $K$ is a separable (not obviously finite) field extension of $k$. Why is this true? Does it require separability?","['tensor-products', 'algebraic-geometry', 'abstract-algebra', 'field-theory']"
1194339,Can one find a stronger norm on a Banach space?,"Given a Banach space $V$ of infinite dimension with norm $\|\cdot\|_1$, is that possible to find a norm $\|\cdot\|_2$ on $V$ such that the topology induced by $\|\cdot\|_2$ is strictly stronger than that of $\|\cdot\|_1$? I guess the answer is no, but I can only prove that $\|\cdot\|_2$ cannot be complete (simply  by open mapping theorem). Any idea will be appreciated.","['normed-spaces', 'functional-analysis']"
1194364,Matrix of Ones with Diagonal of Integers,"My teacher posed a question to the class today asking us to find the determinant of the following matrix... \begin{bmatrix}
    2 & 1 & 1 & 1 & 1 \\
    1 & 3 & 1 & 1 & 1  \\
    1 & 1 & 4 & 1 & 1 \\
    1& 1 & 1 & 5 & 1 \\
    1&1&1&1&6
\end{bmatrix} using a simple trick that doesn't involve transforming it into reduced row echelon form.  For the life of me I've been unable to figure it out.  Does anyone know the trick, or even which steps I should take to make my teachers supposed method more apparent?","['matrices', 'linear-algebra', 'determinant']"
1194368,If $\int_1^x f(t)^2dt \le \frac{x^3-1}{3}$ then $\int_1^2 f(t)dt \le \frac{3}{2}$,"If $f:[1,2]\to [0, \infty )$ is an Riemann integrable function such that $\int_1^x f(t)^2dt \le \frac{x^3-1}{3} , \forall x \in [1,2]$. Prove that $\int_1^2 f(t)dt \le \frac{3}{2}$ . First, I used Cauchy's inequality: $(x-1) \int_1^x f^2(t)dt \ge \left( \int_1^x f(t)dt \right)^2 $ so $\int_1^x f(t)dt \le \sqrt{\frac{(x^3-1)(x-1)}{3}}$ , so $\int_1^x f(t)dt \le \sqrt{ \frac{7}{3}}$, but $\frac{3}{2} < \sqrt{\frac{7}{3}}$. Another attempt is: From $(f(x)-x)^2 \ge 0, \forall x\in [1,2]$, so $f^2(x)+x^2 \ge 2xf(x), \forall x\in [1,2]$. Integrating this inequality on [1,x] and using the hyphotesis we get that $\frac{x^3-1}{3} \ge \int_1^x tf(t)dt , \forall x\in[1,2]$. Can you help me, please ?! Thank you!",['analysis']
1194386,"In the first countable TVS, if every Cauchy sequence convergence then every Cauchy net convergent","Let $X$ be a topological vector space with the first countable topology(that is, every point has a countable neighborhood basis).If every Cauchy sequence convergence, we want to show that every Cauchy net converges. For every given Cauchy net $\langle x_i\rangle$, I think I can inductively find a subnet $\langle x_{k_n}\rangle$of $\langle x_i\rangle$ which is actually a Cauchy sequence. By assumption, we know $\langle x_{k_n}\rangle$ converges to  a point $x$ in $X$, I need to show $\langle x_i\rangle \rightarrow x$. If $X$ is a metric space, then the argument may be easier since we can apply ""$2\epsilon$ argument"" to $x_i-x_{k_n}+x_{k_n}-x$. But how to do this in a general 1st countable topological vector space? Plus, if $\{U_n\}$ is a countable neighborhood basis at $0$, is $\{U_n+U_n\}$ again a neighborhood basis at $0$?","['general-topology', 'topological-vector-spaces', 'convergence-divergence', 'nets']"
1194403,How to determine if a quintic polynomial is solvable by radicals,"I wish to determine if $f(x)=x^5+x^4+x^3-2x^2-2x+5$ is solvable by radicals over $\mathbb{Q}$ . In other words, I want to know if its Galois group is solvable. I haven't gotten anywhere trying to find the roots explicitly.  Also, the result for polynomials with exactly three real roots doesn't apply here.  How should I approach this problem?","['galois-theory', 'abstract-algebra', 'polynomials']"
1194409,How many permutations of a multiset have a run of length k?,"Background $\newcommand\ms[1]{\mathsf #1}\def\msP{\ms P}\def\msS{\ms S}\def\mfS{\mathfrak S}$Suppose I have $n$ marbles of $c$ colors, where $c≤n$. Let $n_i$ denote the number of marbles of color $i$. Let $\msP=(1^{n_1} 2^{n_2} \dots c^{n_c})$ be the multiset $\small\{\underbrace{1, \dots, 1}_{n_1},\underbrace{2,\dots,2}_{n_2},\dots,\underbrace{c,\dots,c}_{n_c}\}$ in frequency representation . The number of distinct permutations of $\msP$ is given by the multinomial:
$$\left|\mfS_{\msP}\right|=\binom{n}{n_1,n_2,\dots,n_c}=\frac{n!}{n_1!\,n_2!\cdots n_c!}=n! \prod_{i=1}^c \frac1{n_i!}.$$ Question How many permutations of $\msP$ have a run of length k ? Let $r_k(\msS)$ be true if a permutation $\msS$ has a run of length $k$ ($k$ marbles in a row are the same color). For example, if I have 5 marbles (2 green, 2 blue, and 1 yellow), then: If $\msS$ is GBYGB , then $r_1(\msS)$ is true, but $r_2(\msS)$ is false. If $\msS$ is GBBYG or GGBBY , then $r_1(\msS)$ and $r_2(\msS)$ are true, but $r_3(\msS)$ is false. Let the number of permutations of $\msP$ having a run of length $k$ be
  $$N(k; \msP)=\sum\limits_{\msS\in\mfS_\msP}[r_k(\msS)]$$
  where $[x]$ denotes the Iverson bracket. Is there a formula for $N(k; \msP)$? Essentially, I would like to find a generalization of this recurrence for the case $c=2$ ( Bloom 1996 ). What I have done so far I constructed the table below, counting the permutations for configurations of up to $n=7$ marbles by brute force.  The rightmost columns count the permutations having runs of length $2≤k≤n$. Unfortunately, brute force stops being practical around $n\gtrsim 11$ (at $10^8$ permutations; see A005651 ). Here is a closer look at the permutations comprising the five $n=4$ cases. I tried to find patterns along different axes that would lead me to formulas for those specific cases, which I could then generalize, but I haven’t gotten anywhere. I then tried deriving a recurrence relation, also to no avail. My hunch, however, is that there may be a Fibonacci-like recurrence relation involved. Update I have entered Andrew’s solution into Mathematica: Ν[r_, P_] := Multinomial@@P - c[r, P]
c[r_, P_] := CoefficientRules[Π[r, P, t]] /. ({a_} -> b_) :> b a! // Total
Π[r_, P_, t_] := Product[q[r, ni, t], {ni, P}]
a[x_, r_, t_] := a[x, r, t] = Exp[t  (x - x^r)/(1 - x^r)]
q[r_, n_, t_] := q[r, n, t] = SeriesCoefficient[a[x, r, t], {x, 0, n}] The values up to $n=5$ match the tables above: Column@Table[
 Grid@Table[
   Table[Ν[r, partition], {r, 1, Max[partition]}
    ], {partition, IntegerPartitions[marbles]}
   ], {marbles, 1, 5}
 ]

1

1   1
2   

1   1   1
3   2   
6       

1   1   1   1
4   4   2   
6   4       
12  6       
24          

1   1   1   1   1
5   5   4   2   
10  9   3       
20  18  6       
30  18          
60  24          
120 Table of $q_{r,n}(t)$ polynomials $$\newcommand\f[1]{\color{gray}{#1}}
\begin{array}{r|llllll}
r \backslash n & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
1 & 0 & 0 & 0 & 0 & 0 & 0 \\
2 & \f{t} & \frac{t^2}{2}-t & \frac{t^3}{6}-t^2+t & \frac{t^4}{24}-\frac{t^3}{2}+\frac{3 t^2}{2}-t & \frac{t^5}{120}-\frac{t^4}{6}+t^3-2 t^2+t & \frac{t^6}{720}-\frac{t^5}{24}+\frac{5 t^4}{12}-\frac{5t^3}{3}+\frac{5 t^2}{2}-t \\
3 & \f{t} & \f{\frac{t^2}{2}} & \frac{t^3}{6}-t & \frac{t^4}{24}-t^2+t & \frac{t^5}{120}-\frac{t^3}{2}+t^2 & \frac{t^6}{720}-\frac{t^4}{6}+\frac{t^3}{2}+\frac{t^2}{2}-t \\
4 & \f{t} & \f{\frac{t^2}{2}} & \f{\frac{t^3}{6}} & \frac{t^4}{24}-t & \frac{t^5}{120}-t^2+t & \frac{t^6}{720}-\frac{t^3}{2}+t^2 \\
5 & \f{t} & \f{\frac{t^2}{2}} & \f{\frac{t^3}{6}} & \f{\frac{t^4}{24}} & \frac{t^5}{120}-t & \frac{t^6}{720}-t^2+t \\
6 & \f{t} & \f{\frac{t^2}{2}} & \f{\frac{t^3}{6}} & \f{\frac{t^4}{24}} & \f{\frac{t^5}{120}} & \frac{t^6}{720}-t \\
\end{array}
$$ Similar questions I missed in prior searches Find the number of arrangements of $k \mbox{  }1'$s, $k \mbox{  }2'$s, $\cdots, k \mbox{  }n'$s - total $kn$ cards. (answered by Jair Taylor himself) How many arrangements of $\{a,2b,3c,4d, 5e\}$ have no identical consecutive letters? Number of words with a minimal number of repetitions","['permutations', 'recurrence-relations', 'multisets', 'combinatorics-on-words', 'combinatorics']"
1194419,Maximum volume of a box with a lid that can be made out of a square,"Snacks will be provided in a box with a lid (made by removing squares from each corner of a rectangular piece of card and then folding up the sides) You have a piece of cardboard that is 40cm by 40 cm – what dimensions would give the  maximum volume? This is how I attempted it Let the length of the square to be cut off be x cm. V be the Volume in cm3 Volume = L x B x H $$L= 40 – 2x$$
$$B= 40 – 2x$$
$$H = x$$
So Volume $= x(40-2x)(40-2x)$
$$V = 4X^3 – 160x^2 + 1600x$$
Or $V= x^3 – 40x^2 + 400x$
$$V'  = 3x^2 – 80x + 400$$
$$V'' = 6x – 80$$
Solve for turning points by putting $V ' = 0$ $$3x^ 2 – 80x + 400 = 0 $$ $$(3x - 20)(x – 20) = 0$$ $x= 20/3$ and  $x = 20$ For Max Volume, $x = 20$ is a reasonable solution that can be apply  and discard the other root i.e. $x = 20$ 2nd derivative test  $x = 20/3$: $$V'' = 6(20/3) – 80= -20 < 0 $$ it will give Maximum Volume $$V =  (20/3)3 – 40(20/3)2 + 400(20/3)$$ $$V = 1186 \text{cm}^ 3$$ Have I done it right ?","['optimization', 'calculus', 'derivatives', 'polynomials']"
1194425,Proving or Disproving statements using sets,"I just don't seem to get proofs or set theory so hopefully my question makes sense. I'm not sure when I should or shouldn't use an example to prove or disprove a statement? One example question is, if C $\subseteq$ A and D $\subseteq$ B, then C $\cup$ D $\subseteq$ A $\cup$ B. I want start by making set A = $\{1, 2, 3, 4, 5\}$ , B = $\{1, 2, 3, 4, 5, 6\}$ C = $\{1, 2, 3\}$ and D = $\{1,2,3,4\}$ and this would show an example proving this statement. However I think this might be wrong because it only shows one example. So, I tried to think of a counterexample that would show that the statement is false. However I'm not sure if I should then try to prove, If C $\subseteq$ A and D $\subseteq$ B, then C $\cup$ D $\subseteq$ A $\cup$ B false or if I should be proving, If C $\subseteq$ A and D $\subseteq$ B, then C $\cup$ D $\subsetneq$ A $\cup$ B false?? I've also tried using x $\in$ C $\subseteq$ A, then x $\in$ C and x $\in$ A, x $\in$ D 
$\subseteq$ B, then x $\in$ D and x $\in$ B But, I didn't know what to do from there.","['proof-writing', 'discrete-mathematics', 'elementary-set-theory']"
1194451,Calculate the maximum area (maximum value),TX farmer has 100 metres of fencing to use to make a rectangular enclosure for sheep as shown. He will use existing walls for two sides of the enclosure and leave an opening of 2 metres for a gate. a)  Show that the area of the enclosure is given by: $A = 102x – x^2.$ b)  Find the value of x that will give the maximum possible area. c)  Calculate the maximum possible area. How do I assign the two variables for area ? Can anyone assist me in solving this problem?,"['optimization', 'calculus', 'algebra-precalculus', 'derivatives']"
1194465,Covariance of absolute value of variables,"I have some relatively complicated variables I am working with. I need to find the covariance: $\text{cov}(\left|x\right|,\left|y\right|)$, is there a simplification of $\text{cov}(\left|x\right|,\left|y\right|)$ in terms of $\text{cov}(x,y)$?","['statistics', 'probability', 'covariance', 'expectation']"
1194481,Notation of author-defined functions.,"I have seen functions defined various ways, and I'm wondering which form I should use for some functions. I am hoping to learn what it might be read as, interpreted, etc. The most common definition of a function is by far $f(x_0,\ldots,x_n)$, for example, $f(a,b,c)=\frac{a^b-c^a}{abc}$. I assume that this is read as ""(the) $f$ of $a,b, $ and $c$"". I have seen another definition as $R_z$, for example, $C_n$ is the cyclic graph with $n$ vertices. I have interpreted this to refer to some special element of a larger set, as opposed to $f(x)$, which to me connotes a routine of sorts. A symbol is often used to denote some function, for example, $\bigcup_{\{x_i\}_{i\in I }}$, $\mathbb{Z}_n$, and $\sum_{i=0}^{12}i^2-i$. I'm not entirely sure when to use this. The last definition I have seen is $f(x;y)$. I have seen this only in some probability functions, and, with my limited exposure, I interpreted it to mean ""$f$ of $x$ with respect to $y$"" or something similar. My question is this: When should I use each notation? Are there any other ways of denoting a function? I wish to define a large number of functions, and I wonder which cases would require each notation.","['notation', 'functions']"
1194499,Find the derivative of a polylogarithm function,"I was trying to find to which function the next series converges.
$$
\sum_{n=1}^{\infty} \ln(n)z^n
$$
If we take the polylogarithm function $Li_s(z)$ defined as
$$
Li_s(s)=\sum_{n=1}^{\infty} \frac{z^n}{n^s}
$$
Then it is easily seen that
$$
\sum_{n=1}^{\infty} \ln(n)z^n = - \left( \frac{\partial}{\partial s}Li_s(z)\right)_{s=0}
$$ Now, my question is how to calculate $ \frac{\partial}{\partial s}Li_s(z)$, using an integral representation for $Li$, such as
  $$
Li_s(z)=\frac{1}{\Gamma(s)}\int_{0}^{\infty} \frac{zt^{s-1}}{e^t-z} dt
$$ Is there any nice solution to this? All my attempts are unclear about it, especially because of the derivative of $\Gamma(s)$.","['partial-derivative', 'polylogarithm', 'complex-analysis']"
1194500,Do functions that decay at $\pm \infty$ eventually become a constant $0$ function?,"If a function defined on $\mathbb{R}$ decays at $\pm \infty$, does that mean it will have 'died out' before reaching $\pm \infty$ i.e $f=0$ for $x\geq a$ for some $a>0$ and $f=0$ for $x\leq b$ for some $b<0$ as the function can never take on a value at $\pm \infty$","['integration', 'functions']"
1194510,Proof of convergence of a recursive sequence,How do I prove that $x_{n+2}=\frac{1}{2} \cdot (x_n + x_{n+1})$ $x_1=1$ $x_2=2$ is convergent?,"['faq', 'sequences-and-series', 'convergence-divergence', 'calculus']"
1194532,Surfaces in $\mathbb P^3$ not containing any line,"Let $d \geq 4$. I'm interested by know if there is a surface $S$ of degree $d$ in $\mathbb P^3_{\mathbb C}$ such that $S$ does not contains a line. I know 
I have no idea how to do it.",['algebraic-geometry']
1194537,Question on calculating curvature of a surface given implicitly,"I want to find, as an exercise, an expression for the curvature of a surface given by the zero set of a function. I reached a final expression, but when I test it for a sphere I get a non-constant expression. I know I'm doing a step wrong, but I don't know why. Below is what I have. Say we have a good enough $f:\Bbb R^3 \to \Bbb R$. This defines a surface in $\Bbb R^3$ as $$S = \{(x,y,z)\in\Bbb R^3 : f(x,y,z) = 0\}$$ Suppose that $f_z = \frac{\partial f}{\partial z}\neq 0$. Then by the implicit function theorem it's easy enough to see we have a local parametrization of $S$ (in fact, the graph of a function): $$h:\Bbb R^2\to \Bbb R^3 \atop (x,y)\mapsto (x,y,h(x,y))$$
and $h$ satisfies (found using the chain rule on $f(x,y,h(x,y)) = 0$) $$\begin{align}h_x = \frac{-f_x}{f_z} \\ h_y = \frac{-f_y}{f_z}\end{align}$$ This way we have a basis for $T_pS$ (at a point $p$ which is omitted in the expressions) $(1,0,-f_x/f_z), (0,1,-f_y/f_z)$. With the usual notation, the coefficients of the first fundamental form $I$ can be calculated as $$E = 1+(f_x/f_z)^2, F = \frac{f_xf_y}{f_z^2}, G = 1 + (f_y/f_z)^2$$
My problem, it seems, comes with the second fundamental form $II$. For example, my calculation of $h_{xx}$ results in $$h_{xx} = \frac{f_xf_{xz}-f_{xx}f_z}{f_z^2}$$
while on this page they get $$h_{xx} = \frac{2f_xf_zf_{xz}-f_x^2f_{zz}-f_z^2f_{xx}}{f_z^3}$$ so either something is horribly wrong and I've forgotten how to differentiate a quotient, or there's something else in the calculation I'm not including. Note that this is before doing anything with the normal vector, just partial derivatives of the parametrization. Could someone clear this up?","['differential-geometry', 'implicit-differentiation', 'curvature', 'partial-derivative', 'implicit-function-theorem']"
1194549,Schwarz 's lemma and sharp upper bound,"Let $f$ be a holomorphic function on $|z|<1$ with $|f(z)|<1$ for all $|z|<1$. (1) Find necessary and sufficient conditions for equality of $$\frac{|f'(z)|}{1-|f(z)|^2} \leq \frac{1}{1-|z|^2}$$ for all $|z| < 1.$ (2) If $f(\frac{1}{2}) = \frac{1}{3}$, find a sharp upper bound for $|f'(\frac{1}{2})|.$ I know that the inequality is Schwarz-Pick Lemma, and I think that it has something to do with Mobius Transformation (Linear fractional transformation) which I supposed that it will be introduced later in my textbook (Complex Analysis in Spirit of Lipman Bers, second edition). This problem is in chapter 6, and the Mobius should be introduced in chapter 8. So, actually, I do not know much about Mobius Transformation. So I do not have any clear idea for the condition concerning equality of the inequality above. Also, I do not know what is a sharp upper bound. I found the definition on http://en.wikipedia.org/wiki/Upper_and_lower_bounds ,but I do not fully understand what it means, and, according to the question, what I have to do with $|f'(\frac{1}{2})|$","['complex-analysis', 'analysis']"
1194565,How to know if two points are diagonally aligned?,"If I have two points at different X/Y coordinates, I know that: They are vertically aligned if both are at the same X coordinate; They are horizontally aligned if both are at the same Y coordinate. Based on the X/Y coordinates of one in relation to the other I can also tell the distance between them, etc. Now, how can you tell that the points are diagonally aligned by following the same logic?","['geometry', 'coordinate-systems']"
1194582,How to find the vector equation of a plane given the scalar equation? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How would I find the vector equation of the plane: $x + 2y + 7z - 3 = 0$ So far, I found the normal vector: it's $(1, 2, 7)$.","['vector-spaces', 'geometry', 'linear-algebra', '3d']"
1194584,The total number of subarrays,"I want to count the number of subarrays for a vector (not combinations of elements). Ex. A[1,2,3] It has 6 subarrays : {1}, {2}, {3}, {1,2}, {2,3}, {1,2,3} I think that for a vector of N elements the total number of subarrays is N*(N+1)/2 . I am not able to prove it, can someone do it?",['combinatorics']
1194634,The set of convergent points of a sequence of continuous functions is Borel,"Suppose that $f_n$ are continuous.  Prove that $E=\{x\in \mathbb{R}:f_n(x)\text{ is convergent}\}$ is Borel. My first instinct is to take balls around $\lim_{n\to\infty}f_n(x)$, for each $x$ in $E$, and then show that there has to be some ball small enough so that everything inside that ball is a member of $E$. But this would imply not only that $E$ is Borel, but moreover that it is open, so I don't think that can be right.  Can someone show me how to do this?","['measure-theory', 'real-analysis']"
1194666,Application of the chain rule for curves,"Problem : Let $f: \mathbb{R}^3 \to \mathbb{R}$ be a differentiable function such that $$y \frac{\partial f}{\partial x}(x,y,z) -x \frac{\partial f}{\partial y}(x,y,z) + \frac{\partial f}{\partial z}(x,y,z) \geq a>0, \forall(x,y,z) \in \mathbb{R}^3 \tag{*} $$
  Let $\gamma: \mathbb{R}_+ \to \mathbb{R}^3$ a differentiable curve given by $\gamma(t)=(- \cos t, \sin t ,t), \ t \geq 0$ Show for $g(t):=f(\gamma(t))$ that $\lim_{t \to + \infty} g(t) = + \infty$ My approach : My idea was to make use of the fact that $g$ is differentiable and the derivative is given by $$g'(t)=< \nabla f(\gamma(t)), \dot\gamma(t)> $$ because the result will very much look like (*), if I can manage to show that $g'(t)\geq a >0$ it would follow that for all $t\geq 0$ I have that $g$ is strictly monotone increasing, if I then could prove that there exists no upper bound, this would finish the exercise. I have $\dot \gamma(t)=(\sin t, \cos t ,1)$, my next step was to compute $g'(t)$, I obtained that $$g'(t)= \sin t \frac{\partial f( \gamma(t))}{\partial x}+ \cos t \frac{\partial f ( \gamma(t))}{\partial y} + \frac{\partial f(\gamma(t))}{\partial z} $$
Which looks a lot like (*), however not quite, because there is this annoying minus sign missing, which might be due to a typing error in C. Michels Analysis II Exercises. Also I fail to make sense of the partial derivatives above, I left the $x,y,z$ in place in order to establish the connection with (*), however if I naively substitute $x= - \cos t, y = \sin t, z = t$ I get very weird partial derivatives that make no sense at all to me. Is my approach to this exercise (in general) right? Or did I misguide myself into trap because (*) looks so much like the chain rule for curves.","['multivariable-calculus', 'self-learning', 'calculus']"
1194705,Would the powerset of $\mathbb{Z}$ also not denumerable?,"Would the powerset of $\mathbb{Z}$ also be not denumerable?, Since Cantor's theorem says that the $\mathbb{N}$ is denumberable but the powerset of $\mathbb{N}$ is not denumberable because there does not exist a surjective function from $\mathbb{N} \rightarrow$ $P( \mathbb{N} )$ I feel like this should be true for $\mathbb{Z}$ as well am I wrong?","['discrete-mathematics', 'contest-math', 'recreational-mathematics']"
1194761,how do you type sec^2(0) on a calculator?,I press cos^-1 then ^2 then brack (o) but then it comes up with syntax error,"['trigonometry', 'calculator']"
1194762,Mental Primality Testing,"At a trivia night, the following question was posed: ""What is the smallest 5 digit prime?"" Teams (of 4) were given about a minute to write down their answer to the question. Obviously, the answer is googleable, so I'm not asking what the answer to the trivia question is, but rather: how could a team quickly find the answer without previous knowledge of it? If you wanted to try solving the trivia question yourself, don't read any further, as I will start discussing the answer and ruling out other numbers now. My thoughts so far: If you know your slide rules, you expect that prime density is close to $ln(10,000)$ or about 10%. So, a reasonable approach would be to focus on numbers 10,000 through 10,010. Really, what matters is that (I assume) you start at 10,000, factor as many numbers in a row as you can, and then guest the first number you haven't factored. We can rule out a lot with easy divisibility tests, leaving 10001, 10003, 10007, and 10009. Assuming one of your people is fast with division or knows better divisibility rules, 10003 is also eliminated because it has a small divisor (7). This shouldn't require a special technique. We're now left with 3 numbers that reasonable divisibility tests won't handle. It turns out 10,001 is composite, while 10,007 and 10,009 are both prime. But the smaller factor of 10,001 is 73, which is the 21st prime. If the team could do the above steps and then rule out 10,001 by dividing by the first 21 primes (also assuming they know the first 21 primes), they would presumably guess 10,007 thereby being right (though not necessarily confident in their answer). But, let's assume that 21 divisions aren't quite possible. Is there a faster way? Let's say that either a test that quickly determines that 10,001 is likely composite or a test that determines that 10,007 is likely prime is sufficient, since we might be down to some guess work at this point, but bonus points if we can know for sure 10,001 is composite or know for sure 10,007 is prime, and extra bonus points if we do both! There are potentially approaches that don't rely on ruling out 10,001. For example, I had the idea initially that given that 10,001, 10,007, and 10,009 are each hard to divide, maybe it's fairly likely that 10,007 and 10,009 are twin primes, and therefore it is more likely that 10,007 is a prime than 10,001 and so you would guess it anyway. While 10,007 and 10,009 do turn out to be twin primes, I don't actually think that the assertion holds, and this seems more like luck.","['primality-test', 'mental-arithmetic', 'divisibility', 'number-theory']"
1194796,Find a subgroup of $S_{4}$ which is isomorphic to $\mathrm{Aut}(U_{8})$,"The notation I am using is: $S_{4}$: the permutation group of order 4 $\mathrm{Aut}(U_{8})$: the set of all automorphisms on the set $U_{8}$ $U_{8}$: the group of numbers relatively prime to 8 I know that $U_{8} = {{1,3,5,7}}$. Forgive my lack of a proper table, but the ""multiplication table"" for $U_{8}$ is given by: $\begin{bmatrix}
       1*1 & 1*3 & 1*5 & 1*7   \\[0.3em]
       3*1 & 3*3 & 3*5 & 3*7   \\[0.3em]
       5*1 & 5*3 & 5*5 & 5*7   \\[0.3em]
       7*1 & 7*3 & 7*5 & 7*7
     \end{bmatrix} =  \begin{bmatrix}
       1 & 3 & 5 & 7   \\[0.3em]
       3 & 1 & 7 & 5   \\[0.3em]
       5 & 7 & 1 & 3   \\[0.3em]
       7 & 5 & 3 & 1
     \end{bmatrix}$ So I believe I should begin by asking how many elements does $\mathrm{Aut}(U_{8})\ $ have. An element in $\mathrm{Aut}(U_{8})\ $ is an isomorphism from $U_{8}$ to itself. My research led to some discussions of finding the number of generators of the group - however $U_{8}$ is not cyclic so this falls apart for me. Can somebody point me in the right direction? Even just explaining the different possibilities would help me tremendously. Other than the trivial automorphism $\Phi(x)=x\ $ I cannot think of anything. I should also note that $U_{8}$ is isomorphic to the Klein four-group. I'm not sure how this helps me.","['permutations', 'group-theory', 'group-isomorphism']"
1194799,Conditional Expectation of Functions of Random Variables satisfying certain Properties,"Suppose that we have a probability space $(\Omega, \mathcal{F}, P)$. Let $X,Y$ be real-valued random variables defined on this space, and let $\mathcal{H} \subset \mathcal{F}$ be a sub-sigma-algebra. Suppose $X$ is $\mathcal{H}$-measurable (i.e, $X^{-1}(B) \in \mathcal{H}$ for all Borel $B \subset \mathbb{R}$). Also suppose that $Y$ is independent of $\mathcal{H}$ (which implies that $X$ and $Y$ are independent). Then is it true that for any Borel-measurable function $g: \mathbb{R}^2 \to \mathbb{R}$, we have that $\mathbb{E}(g(X,Y)|\mathcal{H})=\mathbb{E}(g(X,Y)|X)$? Observations: It seems to be true for functions of the form $g(x,y)=f(x)h(y)$, because $\mathbb{E}(f(X)h(Y)|\mathcal{H}) = \mathbb{E}(h(Y)) \cdot f(X)=\mathbb{E}(f(X)h(Y)|X)$ by independence of $Y$ to $X$ and $\mathcal{H}$. But I can't seem to prove it for the general case. Maybe we can approximate arbitrary $g$ by functions of this form from below, and then use MCT? Is it possible to show that any measurable $g: \mathbb{R}^2 \to \mathbb{R}$ can be written as the (upward) limit of linear combinations of functions of the form $\chi_{A \times B}$, for Borel $A,B \subset \mathbb{R}$? Because then we can just apply MCT and use the preceding comment, and we're done. (The $\chi_E$ denotes characteristic function of $E$.)","['probability-theory', 'measure-theory']"
1194816,Existence and Uniqueness of ODEs and form of initial conditions,"Is there a technical reason as to why the existence and uniqueness theorem for ODEs of the form $$y'(x) = F(x,y(x))$$ is proved for initial conditions of the form $$y(x_0) = y_0$$ and not for $$y'(x_0) = y'_0$$ I understand that in most physical applications, only initial values of the form $y(x_0) = y_0$ are present. But is there any other reason for such a form of initial condition, or can we prove existence and uniqueness even for the IVP of the form $y'(x_0) = y'_0$ ?",['ordinary-differential-equations']
1194833,liminf inequality in measure spaces,"Let $(X;\mathscr{M},\mu)$ be a measure space and $\{E_j\}_{j=1}^\infty\subset \mathscr{M}$. Show that $$\mu(\liminf E_j)\leq \liminf \mu(E_j)$$
  and, if $\mu\left(\bigcup_{j=1}^\infty E_j\right)<\infty$, that
  $$\mu(\limsup E_j)\geq \limsup \mu(E_j).$$ I'm trying to parse what's going on.  On the left, we're taking the measure of $\liminf E_j$, which is $\cup_{i=1}^\infty\cap_{j=i}^\infty E_i$.  This is the union of the tails... okay. On the right, we've got $\lim_{n\to\infty}\inf\{\mu(E_j):n\leq j\}$.  The smallest $\mu$ for everything after $n$ (or the greatest lower bound, anyway). I can't make any progress, I've been stuck here for quite a while. I just don't know where to make the comparison. Can I get a nudge?","['measure-theory', 'real-analysis', 'limsup-and-liminf']"
1194897,Calculating angle on ellipse,"This is a really basic question, yet I can't remember my old geometry classes nor could I find an answer via google. Given a circle ""tilted"" at angle a to the horizontal plane, and given angle b inside the circle, I want to calculate the vertically projected angle, c , on the horizontal plane. It's obvious that the circle's vertical projection on the plane is an ellipse, and that cos(b) = cos(c) but I still can't work out the formula that gives me c given only the 2 first angles. I'm assuming this can be worked out regardless of the dimensions of the circle, although temporary arbritary dimensions can be used to calculate the solution. Note: As an example, in the above sketchup drawing a = 70 degrees, b = 45 degrees, and (what I want to calculate mathematically) c = 18.8 degrees.","['geometry', 'trigonometry', 'circles']"
1194900,Covering space of surface of infinite genus,"Let $X$ be a surface of infinite genus that is not compact (with edges extending to infinity). How would I show that this is a covering space of the 2-torus $T^{1}\# T^{1}$ via the action of the free product $\mathbb{Z}_{2} \star \mathbb{Z}_{2} = \langle a,b \mid a^{2} = e, b^{2} = e\rangle$ ? I've tried doing something analogous to the case of the simply connected covering space of $RP^{2} \vee RP^{2}$ via even translation and the action of the antipodal map, but can't quite get it to work with this case.","['general-topology', 'covering-spaces', 'algebraic-topology']"
1194906,"What about my proof is ""nonsense""?","I am working on a question from Fraleigh's ""A First Course In Abstract Algebra"": A torsion group is a group all of whose elements have finite order. A
  group is torsion free if the identity element is the only element of
  finite order. A student is asked to prove that if $G$ is a torision
  group, then so is $G/H$ for every normal subgroup $H$ of $G$. The
  student writes: We must show that each element of $G/H$ is of finite order. Let $x \in G/H$ Why does the instructor reading this proof expect to find nonsense
  from here on in the students proof? What should the student have
  written? Complete the proof. So I started thinking and just thought of point 3: We must show that each element of $G/H$ is of finite order. Let $x \in G/H$. Observe that $x \in G$ as $G/H \leq G$, but since $G$ is a torsion group, and $x$ is in $G$, $x$ must have have finite order. Q.E.D. This seems fine to me, but I think I am doing something silly since, the question leads me to believe so.",['abstract-algebra']
1194922,Maps from $D^n$ to $D^n$ with a single inverse set are open.,"Let $D^n$ denote the closed unit ball in $\Bbb R^n$. In multiple sources proving Brown's generalized Schoenflies theorem (including a version in the original paper), the following consequence of Brouwer's invariance of dimension is stated without proof. If $f: D^n \rightarrow D^n$ with only one non-singleton inverse set $f^{-1}(y)$ disjoint from the boundary, then $y$ is in the interior of the image of $f$. I am at a loss as to how to go from invariance of dimension to this. EDIT: I just went through the proof of generalized Schoenflies in Bing's book, and he doesn't makes use of this fact. I'm still interested how one proves this from invariance of dimension (or using similar homological techniques as such).","['general-topology', 'geometric-topology', 'metric-spaces', 'algebraic-topology']"
1194929,Confusion with Lang's proof of Sylow Theorem,"I am currently working through Lang's Algebra.  I am rather confused by what seems to be a trivial point.  In a lemma preceding the proof of the Sylow Theorem (which is essentially Cauchy's Theorem), lemma 6.1, he proves that if a finite abelian group has an exponent $n$ then its order divides some power of $n$.  I am comfortable with this fact.  However, he immediately used this to show that all such groups with order $np$, for $p$ prime, have an element of period $p$.  This seems very much like a non-sequitur to me.  What am I missing?","['finite-groups', 'group-theory', 'abstract-algebra']"
1194935,Working with norms,"I was hoping to get some help with being able to properly work with norms and derivatives so I can actually understand my PDE course. We are currently working on Sobolev spaces. Example, I want to show that: $$-\int_{U} u \Delta u dx \leq C \int_{U}|u||D^2u|dx$$ $u \in C_{c}^{\infty}(U)$ with $U$ bounded. I get to: $$-\int_{U} u \Delta u dx \leq \int_{U} |u||\Delta u|dx$$ I know it is not very far at all, but I am so confused. I am missing some key skills in multivariable calculus. My main question: What is $|D^2u|$? I thought that $D^2u$ was the hessian, and I'm confused about taking the norm. If you have any links that would help me better understand operations with norms and $D^ku$ I would greatly appreciate it. I'm really trying, but its just not clicking. Its really frustrating to be undone by the simpler concepts in an extremely theoretical PDE course.","['multivariable-calculus', 'partial-differential-equations']"
