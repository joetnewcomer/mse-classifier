question_id,title,body,tags
2098492,Question about the inequality in the proof of $\lim_{x\to 4}{\sqrt{x}}=2$ by $\epsilon$ - $\delta$ method?,"What I want to proof is $\lim_{x\to 4}{\sqrt{x}}=2$ The following is from my textbook Finding a $\delta$. Let $\epsilon\gt 0$. We seek a $\delta\gt 0$, s.t. $if\quad 0\lt|x-4|\lt\delta,\quad then\quad|\sqrt{x}-2|\lt\epsilon$ To be able to form $\sqrt{x}$, we need to have $x\ge 0$. To ensure this, we must have $\delta\le 4$. How to derive/translate this statement in inequality?","['inequality', 'limits', 'calculus', 'epsilon-delta', 'proof-explanation']"
2098512,Principal value of $\frac{1}{x^2}$ over $\mathbb{R}$,"If I look at the the integral $$
PV\int_{-\infty}^{\infty}\frac{1}{ax^2+bx+c}\;\mathrm{d}x
$$ under the condition $b^2>4ac$, I can conclude this equals zero. Graphically this makes sense, the divergent positive and negative areas ""cancel"" with each other. If instead $b^2=4ac$ there is no negative area to cancel the divergence of the positive area, so I would think it should be infinite. However, if in my work I take a limit as $b\rightarrow0$ with $a=1$, $c=0$, the integral continues to be zero. Wolfram also gives the result $$
PV\int_{-\infty}^{\infty}\frac{1}{x^2+bx}\;\mathrm{d}x = 0 \;\text{for}\ b\in \mathbb{R}
$$ Notably this includes $b=0$. Symbolically I keep coming to the conclusion that $$
PV\int_{-\infty}^{\infty}\frac{1}{x^2}\;\mathrm{d}x = 0
$$ but geometrically I'm missing something. Other principal values I've seen I can look at a graph and reason some form of area cancelation, among other things, but $\displaystyle\frac{1}{x^2}$ is positive everywhere. I also only get to this result by introducing other constants in the function then having them tend to, or equal $0$, which is different than any other principal values I've done. Is this principal value actually correct? If so, why can $0$ be associated with an integral over a function positive everywhere?","['integration', 'cauchy-principal-value']"
2098567,Why is $\lim_{t\to 1}\frac{t^n-1}{t^m-1}=\frac{n}{m}$,$$\lim_{t\to 1}\frac{t^n-1}{t^m-1}=\lim_{t\to 1}\frac{(t-1)(t^{n-1}+t^{n-2}+...+t+1)}{(t-1)(t^{m-1}+t^{m-2}+...+t+1)}=\frac{n}{m}$$ How do you get $\frac{n}{m}$ in the end?,"['calculus', 'limits']"
2098594,How many one to one functions are there between two sets where the $k$th element of the domain is not mapped to the $k$th element of the codomain?,"Suppose $2$ sets with cardinality $X=5$ and $Y=7$. How many one to one function from $X$ to $Y$ such that $k$th element of $X$ should not align with the $k$ th element of $Y$ ? I think one to one possible are $6\times 5\times 4\times 3\times 2$, but not sure though.","['combinatorics', 'functions']"
2098600,Equivalent definition of orientability,"I came across the following definition of orientability. Let $O$ be the ""$0$-section"" of the exterior n-bundle $\Lambda^nM^*$
  with $M$ being a connected differentiable manifold of dimension $n$.
  It is said that $M$ is orientable if $\Lambda^nM^* \smallsetminus O$
  has two components; an orientation is a choice of one of the two
  components of $\Lambda^nM^* \smallsetminus O$. It is said that $M$ is
  non-orientable if $\Lambda^nM^* \smallsetminus O$ is connected. Now, this seems like a really good definition. But I have a problem understanding how it is equivalent to saying that an orientable manifold $M$ admits a nowhere-vanishing smooth $n$-form . In particular, if the definitions are to be equivalent, the following statement must be true. $$ \Gamma(\Lambda^nM^* \smallsetminus O) = \varnothing \Leftrightarrow \Lambda^nM^* \smallsetminus O \text{ is connected}$$ I don't see why that should be the case. For example, I could take a Möbius band (which can be seen as the $2$-dimensional cotangent bundle over the $1$-dimensional Möbius circle) and start cutting through it without touching the base circle (say a constant $2 cm$. off of it). I would go around twice before completing the section. So I do have a smooth non-vanishing $1$-form here, although I believe it is supposed to be non-orientable by the given definition. Another example could be an exterior $n$-bundle which has the topology of a torus (does that exist?) which clearly admits a smooth section of $\Lambda^nM^* \smallsetminus O$.","['smooth-manifolds', 'differential-geometry']"
2098604,Sigma Algebra of Events for Uncountable Sample Space,"If $\Omega$ is an uncountable sample space, why are we not allowed to take the sigma-algebra of events $\cal{F}$ to be the power set of $\Omega$? The Wikipedia page devoted to Probability spaces states that this power set may be too large so that there may be events for which it is impossible to assign a unique probability measure. (1) Why can't we assign probabilities to all of the events? (2) Can't we just set most of the probabilities to be $0$ and deal with the probabilities that we can assign?","['probability-theory', 'measure-theory']"
2098666,Definitions 4.32 and 4.33 and Theorem 4.34 in Baby Rudin: Are these proofs the limit statements based on these definitions correct?,"Here's Theorem 4.34 in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: Let $f$ and $g$ be defined on $E \subset \mathbb{R}$ . Suppose $$ f(t) \to A, \ \ \ g(t) \to B, \ \mbox{ as } \ t \to x.$$ Then (a) $f(t) \to A^\prime$ implies $A^\prime = A$ . (b) $\left( f+g \right)(t) \to A+B$ . (c) $\left( fg \right)(t) \to AB$ . (d) $\left( f/g \right)(t) \to A/B$ . provided the right members of (b), (c), and (d) are defined. Note that $\infty - \infty$ , $0 \cdot \infty$ , $\infty / \infty$ , $A/0$ are not defined. Now here is Definition 4.33 in Rudin: Let $f$ be a real function defined on $E \subset \mathbb{R}$ . We say that $$ f(t) \to A \ \mbox{ as } \ t \to x,$$ where $A$ and $x$ are in the extended real number system, if for every neighborhood $U$ of $A$ there is a neighborhood $V$ of $x$ such that $V \cap E$ is not empty, and such that $f(t) \in U$ for all $t \in V \cap E$ , $t \neq x$ . And, finally here is Definition 4.32: For any real $c$ , the set of real numbers $x$ such that $x > c$ is called a neighborhood of $+\infty$ and is written $(c, +\infty)$ . Similarly, the set $(-\infty, c)$ is a neighborhood of $-\infty$ . How to prove Theorem 4.34 using Definitions 4.33 and 4.32? My effort: Theorem 4.34(a): If $f(t) \to A$ and $f(t) \to A^\prime$ as $t \to x$ , then, for every neighborhood $U$ of $A$ , we can find a neighborhood $V$ of $x$ such that $V \cap E$ is not empty, and such that $f(t) \in U$ for all $t \in V \cap E$ , $t \neq x$ , and for every neighborhood $U^\prime$ of $A^\prime$ , we can find a neighborhood $V^\prime$ of $x$ such that $V^\prime \cap E$ is not empty, and such that $f(t) \in U^\prime$ for all $t \in V^\prime \cap E$ , $t \neq x$ . Now if $A \neq A^\prime$ , then we can find neighborhoods $U$ and $U^\prime$ of $A$ and $A^\prime$ , respectively, such that $U \cap U^\prime$ is empty. Now $V \cap V^\prime$ is not empty and is a neighborhood of $x$ . What next? Theorem 4.34(b), (c), and (d): If $f(t) \to A$ and $g(t) \to B$ as $t \to x$ , then, for every neighborhood $U$ of $A$ and for every neighborhood $V$ of $B$ , we can find neighborhoods $W_1$ and $W_2$ , respectively, of $x$ such that $W_1 \cap E$ and $W_2 \cap E$ are not empty, and such that $f(t) \in U$ for all $t \in W_1 \cap E$ , $t \neq x$ , and such that $g(t) \in V$ for all $t \in W_2 \cap E$ , $t \neq x$ . What next?","['real-analysis', 'limits', 'calculus', 'analysis']"
2098667,Extinction probabilities of binomial tends to Poisson distribution,"I am stuck on exercise 11.2 From Grimmett's  probability on graphs. Here is a link to the pdf on his website. Consider a branching process whose family-sizes have the binomial distribution bin$(n, \frac{\lambda}{n})$. Show that the extinction probability converges to $\eta(\lambda)$ as $n \rightarrow \infty$, where $\eta(\lambda)$ is the extinction probability of a branching process with family-sizes distributed as $\text{Po}(\lambda)$. To solve this exercise, we use a theorem from his other book, which states that if you have a branching process whose family sizes are $X$ distributed then the extinction probability of this branching process is the smallest non-negative fixed point of the equation $s = G(s)$ where $G$ is the probability generating function $G(s) = \sum_{k = 0}^\infty \mathbb{P}(X = k)s^k$. My next step was computing these probability generating functions for $\text{bin}(n,\lambda)$, these are $G_n(s) = (1+\frac{\lambda( s -1)}{n})^n$. When the family sizes are Poisson distributed with parameter $\lambda$ we get $G(s) = e^{\lambda(s-1)}$. and so clearly $G_n$ converges pointwise to $G$. This however is not enough, as we want to show that the extinction probabilities also converge, so we have $s_n$ extinction probabilities of the $n$-th process, i.e. $s_n$ is the smallest non-negative solution to $s = G_n(s)$, and we want to show that this converges the smallest non-negative solution of $s = G(s)$. I hoped I could use some theorem which states that if you have pointwise convergence then the fixed points also converge, but this is false, see this counterexample . During writing this I thought of an attempt to solve this using Hurwitz theorem, namely, show that the smallest non-negative fixed point of $G(s)$ is smaller than 1, then show that the function $G'$ is complex differentiable with non-zero derrivative, use inverse function theorem, get an open neighbourhood of our fixed point, find sequence of fixed points which converge to the smallest non-negative fixed point $\eta(\lambda)$ of $G$. Here I am stuck trying to show that $s_n$ are the smallest non-negative fixed points of $G_n$. How to proceed?","['generating-functions', 'fixed-point-theorems', 'probability-theory']"
2098715,"How to calculate total number of chords, if radius of circle given and length of chord is given?","Problem is : There is circle of radius 17 cm and there is a point inside the circle such that its distance is 12 cm from center, How many chords can drawn to this point whose length is an integer?
What's the approach? I think infinite, is it right?","['circles', 'spherical-coordinates', 'geometry']"
2098741,Which of the integers cannot be formed with $x^2+y^5$,"So, I was asked by my teacher in school to solve this problem it really had me stumped.The problem is as follows:Given that $x$ and $y$ are integers, which of the following cannot be expressed in the form $x^2+y^5$? $1.)\ 59170$ $2.)\ 59012$ $3.)\ 59121$ $4.)\ 59149$ $5.)\ 59130$ Is it possible for an elegant solution and not tedious trial and error?","['algebra-precalculus', 'elementary-number-theory']"
2098784,What really is the modern definition of Euclidean spaces?,"What is the modern definition of Euclidean spaces ? I read the Wikipedia article about the topic , but I still don't get it. Is a Euclidean space something that satisfies the traditional Euclid's axioms, or Hilbert's axioms? or is it defined to be an inner product space? or is it defined to be a set on which we can somehow define the notion of ""length"" and ""angle""? or is it defined to be an affine space? If a Euclidean space is defined as in case 2 (i.e. as an inner product space), then do we still need Euclid's axioms or Hilbert's axioms? For example, there's a Hilbert's axiom For every two points A, B there exists a line a that contains each of the points A, B. but in terms of inner product space terminology, it can be directly proved by trivial pre-calculus technique, right?","['hilbert-spaces', 'inner-products', 'geometry', 'general-topology', 'linear-algebra']"
2098809,Are these function cases at all equivalent?,"For a programming assignment, I need to map integers to integers based on a factor. By knowing what the input and output should be, I was able to come up with the following function: $g\left(f,c\right)=\begin{cases}
\left\lfloor \left( c-1\right) \div f\right\rfloor +1 & f<1\\
c & f=1\\
\dfrac{c+\mod\left(f-\mod\left(c,f\right),f\right)}{f} & f>1
\end{cases}$ where $f\in\left(0,100\right]$ is the factor  and $c>0$, in this case, stands for coordinate, and is an integer. This appears correct with my initial testing. One thing I noticed, however, is that the $f=1$ case is actually unnecessary. Both the $f<1$ and $f>1$ cases return $c$ when $f$ is 1, so I'm wondering if, somehow, there's only one case instead of two or three, but I'm unable to see it because I'm unused to simplifying equations with the floor or mod functions. Note that while I came up with these as part of a programming assignment, from a coding point of view, the above is sufficient. Simplifying the above function isn't part of the assignment, just my own math geek interest. In case it helps, given a factor and an $x$- or $y$-coordinate within a resized image, the above is supposed to return the $x$- or $y$-coordinate of the original pixel that should be used in the resized image.","['ceiling-and-floor-functions', 'modular-arithmetic', 'functions', 'closed-form']"
2098842,Cardinality of a simple relation,"What is the cardinality of all equivalence relations in $\mathbb{R}$, such that their equivalence classes contain only finite,odd number of elements? My attempt: as relations are subset of $\mathbb{R} \times \mathbb{R}$, so the cardinality is smaller than $2^{\mathbb{R}}$. So we need to prove that the cardinality of those relations is at least $2^{\mathbb{R}}$. One way could be to find an injective function from power set of R to those relations, and thus prove the statement. But I have no idea how to construct such a function. Afterall how should I approach such kind of questions? Are there any heuristics for solving such problems (constructing such functions)?","['relations', 'cardinals', 'elementary-set-theory']"
2098845,"How can the limit of this $F(x,y)$ is $0$ when it is taken along $y=x^2$ or $ x=y^2$?","Find $$\lim_{(x,y) \to (0,0)}\frac{3x^{2}y}{x^{2}+y^{2}}$$ if it
  exists. From my textbook, it said that the limits along the parabolas $$y=x^{2}\text{ and } x=y^{2}$$ also turn out to be 0. I couldn't figure out why, as if we set $$x=y^{2}$$, for example then $$\lim_{(x,y) \to (0,0)}\frac{3x^{4}}{x^{2}+(x^{2})^{2}}$$ $$\lim_{(x,y) \to (0,0)}\frac{3x^{4}}{x^{2}+x^{4}}$$
$$\lim_{(x,y) \to (0,0)}\frac{3}{0+1}$$
then the answer is supposed to be $3$?  right?","['calculus', 'limits']"
2098857,Finding the slope of an hypotenuse of the trigonometic circle,"I've been learning about derivatives and I've learnt that the derivative of a circunference for $x$ is given by $-\frac{x}{y}$ with the formula for the circunference being $y^2+x^2=1$ Knowing this, I have tried to calculate the slope of a line that goes through center of this circle and a point in the circunference. To make things simpler, I decided to use the trigonometic circle. I did the following: Let this line be $f(x)$ and the tangent on the point where $f(x) = 1$ be $g(x)$ I know that $f(x) = mx$ because it goes through through the point $(0,0)$ and so $b=0$ Because the derivative of the circunference is $-\frac{x}{y}$, I know that $g(x) = -\frac{x}{y}x+b = -\frac{x^2}{y}+b$ I think that the tangent is perpendicular to $g(x)$, which means that $g(x)$ is its normal line. I don't know this for sure nor do I know how to prove it, it just looks that way for me so I am going explore that possibility and see what happens. Assuming that $g(x)$ is perpendicular to $f(x)$: If the slope of $g(x)$ is $-\frac{x}{y}$, then the slope of $f(x)$ is $\frac{y}{x}$, and so $f(x) = \frac{y}{x}x = y$, which doesn't really bring me anywhere... I think. Another way of calculating the slope of $f(x)$ would be the traditional way, replacing $x$ and $y$ with $(\cos(\theta);\sin(\theta))$ and so: $$f(x) = mx \Leftrightarrow \sin(\theta) = m\cos(\theta) \Leftrightarrow m = \frac{\sin(\theta)}{\cos(\theta)} \Leftrightarrow m = \tan(\theta)$$ And so $f(x) = \tan(\theta)x$ Another thing that I tried to do was to calculate $b$ for $g(x)$, using the point $(\cos(\theta);\sin(\theta))$: $$g(x) = -\frac{x^2}{y}+b \Leftrightarrow \sin(\theta) = -\frac{\cos^2(\theta)}{\sin(\theta)} \Leftrightarrow \sin(\theta)+\cos(\theta)\cot(\theta) = b \Leftrightarrow b = \csc(\theta)$$ And so $g(x) = -\frac{x^2}{y}+ \csc(\theta)$ EDIT: So, to recap: $$f(x) =  \tan(\theta)x 
\\ f'(x) = \tan(\theta) \\
g(x) = -\frac{x^2}{y}+ \csc(\theta) \\
g'(x) = -\frac{x}{y}$$ Now my questions: Did I do everything correctly? Are $f(x)$ and $g(x)$ perpendicular? Did I prove it above when I got $f(x) = y$? If not, could you show me how to prove whether or not if they are perpendicular? I could never really understand the purpose of $\tan$. Is it the slope of the line that contains the hypotenuse? Feel free to expand on this subject if you want or point out any detail I might have missed.","['derivatives', 'tangent-line', 'trigonometry', 'calculus']"
2098860,Proof that a specific bounded sequence converges? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question $(a_n)$ is a bounded sequence such that $$\lim_{n\to\infty}(a_{2^n}-3a_n)=0$$ Prove that $(a_n)$ converges and determine the limit. I haven't got a clue of what to do here. I've been told I could watch accumulation points of the sequence but honestly I don't understand how I should proceed. Any kind of hint would be really helpful.
Thanks in advance!","['sequences-and-series', 'convergence-divergence', 'limits']"
2098866,Electrical circuit analyses: coil and capacitor in series,"I've a series circuit of a coil and a capacitor, in between those components we've a switch that will close when $t=0$. We can write: $$
\begin{cases}
\text{U}_\text{C}\left(t\right)=-\text{U}_\text{L}\left(t\right)\\
\\
\text{I}_\text{C}\left(t\right)=\text{U}'_\text{C}\left(t\right)\cdot\text{C}\\
\\
\text{U}_\text{L}\left(t\right)=\text{I}'_\text{L}\left(t\right)\cdot\text{L}\\
\\
\text{I}\left(t\right)=\text{I}_\text{C}\left(t\right)=\text{I}_\text{L}\left(t\right)\\
\end{cases}\space\space\space\space\space\therefore\space\space\space\space\space\frac{1}{\text{C}}\cdot\text{I}\left(t\right)=-\text{L}\cdot\text{I}''\left(t\right)\tag1
$$ Using Laplace transform: $$\text{I}\left(\text{s}\right)=\frac{\text{s}\cdot\text{I}\left(0\right)+\text{I}'\left(0\right)}{\frac{1}{\text{C}}+\text{L}\cdot\text{s}}\tag2$$ $$\text{U}_\text{C}\left(\text{s}\right)=\frac{1}{\text{C}\cdot\text{s}}\cdot\left\{\frac{\text{s}\cdot\text{I}\left(0\right)+\text{I}'\left(0\right)}{\frac{1}{\text{C}}+\text{L}\cdot\text{s}}+\text{C}\cdot\text{U}_\text{C}\left(0\right)\right\}\tag3$$ $$\text{U}_\text{L}\left(\text{s}\right)=\text{s}\cdot\text{L}\cdot\frac{\text{s}\cdot\text{I}\left(0\right)+\text{I}'\left(0\right)}{\frac{1}{\text{C}}+\text{L}\cdot\text{s}}-\text{L}\cdot\text{I}\left(0\right)\tag4$$ Well, I know that: $$\text{U}_\text{C}\left(0\right)=200\tag5$$ $$\pi\sqrt{\text{C}\cdot\text{L}}<10\cdot10^{-6}=10^{-5}\space\Longleftrightarrow\space\text{C}\cdot\text{L}<\frac{10^{-10}}{\pi^2}\tag6$$ Question: How can I find the value of $\text{C}$ and $\text{L}$ using the things I know?","['real-analysis', 'laplace-transform', 'physics', 'integration', 'ordinary-differential-equations']"
2098877,Show that $\overline{f(z)}$ is holomorhpic in $D(0;1)$ if and only if $f$ is constant.,"Let $f$ be holomorphic in $D(0;1)$. Show that $\overline{f(z)}$ is holomorhpic in $D(0;1)$ if and only if $f$ is constant. It is clear to me that if $f$ is constant then $\overline{f(z)}$ is holomorphic since the Cauchy-Riemann equations will be satisfied. However, I'm not sure about how to show the other direction. How do I do that?",['complex-analysis']
2098897,Generating Random Orthogonal Matrices,"If I generate a random matrix A with every element sampled from a uniform [0, 1) distribution, and then use the Gram Schmidt procedure to get an orthogonal matrix Q. Will this generate every orthogonal matrix with elements within some interval on the real line? and will it do so with equal probability for each matrix? If not, how could I generate a random orthogonal matrix, preferably using python? Thank you.","['probability', 'linear-algebra']"
2098912,A limit of indeterminate,"$$\lim _{x\to \infty }\frac{\left(e^x+x\right)^{n+1}-e^{\left(n+1\right)x}}{xe^{nx}}\:= \:\:?$$ I tried to get it to a simpler form like this: $$\lim _{x\to \infty }\frac{\left(e^x+x\right)^{n+1}-e^{\left(n+1\right)x}}{xe^{nx}}\:=\:\lim _{x\to \infty }\frac{e^{\left(n+1\right)x}\left(1+\frac{x}{e^x}\right)^{n+1}-e^{\left(n+1\right)x}}{xe^{nx}}=\lim _{x\to \infty }\frac{e^x}{x}\left(\left(1+\frac{x}{e^x}\right)^{n+1}-1\right)$$ Then i noted $\frac{e^x}{x}$ with t which tends to infinity also. Then i applyed the formula for $a^n-b^n$ (I've considered $1$ as $1^\left(n+1\right)$) and i got 1, but the answer is $n+1$. What have i missed ?",['limits']
2098915,Differentiability of an exotic function,"I saw a question on stackexchange earlier today about the function $f(x)=\begin{cases}
1&\text{if }x\in\mathbb{Q}\\
0&\text{otherwise.}
\end{cases}$ It reminded me of an old problem (that I don't think I solved), and I thought it was worth sharing with others. Let
\begin{equation*}
g(x)=\begin{cases}
\frac{1}{q^j}&\text{if }x\in\mathbb{Q}\\
0&\text{otherwise.}
\end{cases}
\end{equation*}
For rational values of $x$, we have $x=\frac{p}{q}$ is in lowest terms. Additionally, $j> 1$. 1) One of the questions that was asked was to show the following: $g$ is differentiable for $x\in\mathbb{R}\setminus\mathbb{Q}$. I don't think this is very difficult; however, I had trouble with the next one: 2) Show that $g$ is $k$-times differentiable for $x\in\mathbb{R}\setminus\mathbb{Q}$ and $k<j$. How do we prove (2)? Is it even true? For the second derivative, we take 
\begin{equation*}
f''(x)=\lim_{h\to 0}\frac{f(x+h)-2f(x)+f(x-h)}{h^2}
\end{equation*} I'm not totally sure how one might extend to higher derivatives, and a quick google search did not yield what I was looking for! I would be happy if there was a proof for $k=2$ in my question.","['derivatives', 'real-analysis', 'calculus']"
2098928,Elementary factors in the Weierstrass Factorization Theorem,"Weierstrass Factorization Theorem allows representing an entire function $f$  (can be considered as an infinite polynomial) as a product involving zeros $\{a_n\}$ of $f$:
$$
f(z)=z^m e^{g(z)}\prod_{n=1}^{\infty} E_{p_n}(\frac{z}{a_n})
$$
In the formula above we substitute a simple expression $\prod_{n}(z-a_n)$ that would be used if the product was finite (fundamental theorem of algebra) by the product of elementary factors:
$$
    E_n(z)=\left\{
                \begin{array}{ll}
                  (1-z), n=0\\
                  (1-z)\exp(\frac{z}{1}+\frac{z^2}{2}+...+\frac{z^n}{n}), x\neq0\\
                \end{array}
              \right.
$$
These elementary factors should ensure that the product converges (terms become close to 1) and that the zeros are at $\{a_n\}$. Question: Could you please explain how the term $\exp(\frac{z}{1}+\frac{z^2}{2}+...+\frac{z^n}{n})$ helps the product to converge? I'm especially confused about the case $z>1$ when $E_n(z)$ seems to grow very fast instead of being close to 1.","['functional-analysis', 'complex-analysis', 'weierstrass-factorization', 'convergence-divergence']"
2098930,solving inhomogenous $2$ x $2$ ODE?,"Let $y'=\begin{pmatrix}1 & 2 \\ 3 & 6\end{pmatrix}y+\begin{pmatrix}x \\ sin(x)\end{pmatrix}$ with $y_0=\begin{pmatrix}0 \\ 0\end{pmatrix}$ Now I want to solve it, but don't know how to continue: $1)$ solve the homogeous ODE $y'=Ay$ $\Rightarrow y_{hom}(x)=e^{0x} \cdot c_1\begin{pmatrix}-2 \\ 1\end{pmatrix}+c_2 \cdot e^{7x}\begin{pmatrix}1 \\ 3\end{pmatrix}=c_1\begin{pmatrix}-2 \\ 1\end{pmatrix}+c_2 \cdot e^{7x}\begin{pmatrix}1 \\ 3\end{pmatrix}$ $2)$ solve particular ODE $y'=Ay+b$ with variation of parameters: $y_{par}=Y_{hom}\cdot c(x)=\frac{1}{7}\begin{pmatrix}e^{7x}+6 & 3(e^{7x}-1)\\2(e^{7x}-1) & 6e^{7x}+1\end{pmatrix}\begin{pmatrix}\dot c_1(x) \\ \dot c_2(x)\end{pmatrix}=\begin{pmatrix}\ x \\ \ sin(x)\end{pmatrix}$ Now I solved for $c_1$ and $c_2$ , but I guess it's wrong because I couldn't solve it without calculator and than I checked it , it was wrong :/ $c_1=\dfrac{\mathrm{e}^{-7x}\left(-1029\sin\left(x\right)+\mathrm{e}^{7x}\left(7350\cos\left(x\right)+1225x^2\right)-147\cos\left(x\right)+\left(2100x-300\right)\mathrm{e}^{14x}\right)}{17150}+C$ $c_2=\dfrac{\mathrm{e}^{-7x}\left(1029\sin\left(x\right)+\mathrm{e}^{7x}\left(1225\cos\left(x\right)-1225x^2\right)+147\cos\left(x\right)+\left(350x-50\right)\mathrm{e}^{14x}\right)}{8575}+C$ Is this way correct or is there another one ?
Thanks in advance",['ordinary-differential-equations']
2098933,Showing quasicompactness is affine-local on the target.,"$\newcommand{\Spec}{\operatorname{Spec}}$Let $\pi:X\to Y$ be a morphism of schemes. I want to show that the property of $\pi$ being quasicompact is affine-local on the target. That is, if $\{U_i\}$ is an affine open cover of $Y$, and $\pi^{-1}(U_i)$ is quasicompact for each $i$, then $\pi$ is quasicompact. I understand that by the Affine Communication Lemma, I just need to show $(1)$ If $\Spec A\subset Y$ is affine open such that $\pi^{-1}(\Spec A)$ is quasicompact, then $f\in A$ implies $\pi^{-1}(\Spec A_f)$ is quasicompact. $(2)$ If $(f_1,\dots,f_n)=A$ and $\pi^{-1}(\Spec A_{f_i})$ is quasicompact for each $i$, then $\pi^{-1}(\Spec A)$ is quasicompact. The latter is obvious enough because $\Spec A=\cup_i\Spec A_{f_i}$, so $$\pi^{-1}(\Spec A)=\cup_{i=1}^n\pi^{-1}(\Spec A_{f_i})$$ which is a finite union of quasicompact sets, hence quasicompact. I'm having more trouble showing $(1)$ holds; if $f\in A$, then $\Spec A_{f_i}$ is open in $\Spec A$, hence open in $Y$, so $\pi^{-1}(\Spec A_{f_i})$ is open in $\pi^{-1}(\Spec A)$, the latter of which is quasicompact, but I don't know how to use this to show $\pi^{-1}(\Spec A_{f_i})$ is quasicompact. It would be true certainly if $\pi^{-1}(\Spec A)$ were Noetherian, but this isn't the case here. Can anybody provide any insight as to what I'm missing to prove $(1)$?","['schemes', 'algebraic-geometry']"
2098941,"Bernoulli numbers, taylor series expansion of tan x","I found the following formula here: Taylor Series of $\tan x$ . Taylor series of $\tan x$ : $$\tan x = \sum_{n\,=\,1}^\infty \frac {(-1)^{n-1}2^{2n} (2^{2n}-1) B_{2n}} {(2n)!} x^{2n - 1} $$ . I do not understand what the Bernoulli number means in this formula. My problems are the following ones: I do not know anything about Bernoulli numbers. I do not know how to expand the Bernoulli number in the formula you see further up. What expansion will be the final result? How did you arrive there? Why did you arrive there? How did you know that you should use the specific Bernoulli-related terms that you used in your answer? What is the purpose of the Bernoulli number in this formula? A great deal of thanks.","['taylor-expansion', 'trigonometry', 'trigonometric-series', 'summation', 'bernoulli-numbers']"
2098989,De Moivre's formula proof step,"($\cos \phi + i\sin \phi)^n = \cos (n \phi) + i\sin (n \phi)$ Saw this in the De Moivre's formula proof and some other calculations involving complex numbers, but I do not understand why the equation is true.","['trigonometry', 'complex-numbers']"
2099006,Lighting Problem,"Can you help me with this problem of combinatorics? There are $12$ lights in a row enumerated from $1$ to $12$. The lights $3$, $7$ and $11$ are switched on and the others are off. One of the lights can be switched on if at least one of its neighbours is switched on and the lights can't be switched off. In how many ways could you switch on all the lights?","['combinatorics', 'discrete-mathematics']"
2099032,how to get number of possible public keys in RSA,"I need to calculate the number of possible public keys. The tuple for the public key is defined as: $Key_{Publ} = (n,a)$ So: 
Let $p:=83$ and $q:=163$ $n= p \cdot q = 83 \cdot 163 = 13529$ $\phi(n) = (p -1 )(q - 1) =(83 - 1)(163 - 1) = 13284$ Question : How is it possible to calculate the number of possible $a$'s in $\gcd(a , \phi(n))$ with $a \in [1, \phi(n)]$ ? 
So I will be able to calculate the possibilities with $n \cdot a$? I have two possible ways to calculate $\phi(n):$
$$\phi(n)=(p-1)(q-1)$$
$$\phi(n)=\prod_{p \in \mathbb P}(p^{v_p(n)-1}(p-1))$$ I appreciate every hint.","['number-theory', 'discrete-mathematics']"
2099036,Is it possible to determine this kind of set just by drawing?,"For instance, let consider $A$ and $B$ two points of the plane. We want to determine the set of points $M$ such that : $\vert \vert \vec{MA}+\vec{MB}\vert \vert=\vert\vert \vec{MA} \vert \vert$. I know that the classical method uses the scalar product and also barycenter but it's an analytic method. I wonder how to see ""what does this set look like"" just by drawing ? If we just look at the expression of the equation we first draw (with vectors) a parallelogram from $M$ and we want that the diagonal ($Md=MA+MB$) has the same length as $MA$. Maybe the $\triangle AMd$ must be isoscele or equilateral. Thanks in advance !","['intuition', 'euclidean-geometry', 'geometry']"
2099043,Complex structures on a real torus,"Given $\omega_1,\omega_2\in\mathbb{C}\setminus\{0\}, \frac{\omega_1}{\omega_2}\notin\mathbb{R}$, define $L(\omega_1,\omega_2)=\{n\omega_1+m\omega_2:n,m\in\mathbb{C}\}$. The torus associated to $L(\omega_1,\omega_2)$ is $T_{\omega_1,\omega_2}=\mathbb{C}/L(\omega_1,\omega_2)$. Now $T_{\omega_1,\omega_2}$ has the natural complex structure: for $x\in T_{\omega_1,\omega_2}$, fix $z\in \mathbb{C}$ such that $\pi(z)=x$, where $\pi:\mathbb{C}\rightarrow T_{\omega_1,\omega_2}$ is the natural quotient map; choose $D$ to be an open sufficiently small disc centered at $z$, and then $(\pi(D), (\pi\restriction_D)^{-1})$ is a chart at $x$; it may be checked that charts of this form are compatible so that we get a complex structure on $T_{\omega_1,\omega_2}$. I wonder whether it is true that any complex structure on an abstract real torus arises in this way? By ""an abstract real torus"" I mean a real 2-dimensional surface of genus one. I guess it is obvious that any such torus is homeomorphic to the topological space $\mathbb{C}/L(\omega_1,\omega_2)$ (with the quotient topology) for some $\omega_1,\omega_2\in\mathbb{C}\setminus\{0\}, \frac{\omega_1}{\omega_2}\notin\mathbb{R}$, but is it obvious that one cannot put a complex structure on $T_{\omega_1,\omega_2}$ apart from the natural one described above?","['complex-geometry', 'algebraic-geometry', 'complex-manifolds', 'smooth-manifolds', 'manifolds']"
2099061,Proper clopen subset of disconnected set,"In Chapman Pugh's Real Analysis the definition of a disconnected set is that it has a proper clopen subset. I was trying to apply that to a simple example but got the following inconsistency: The disconnected set $U=[a,b]\cup[c,d]\subset\mathbb R$ where $a<b<c<d$ should have a proper clopen subset. However, $\mathbb R$ has no clopen proper subsets and any proper subset of $U$ is also a proper subset of $\mathbb R$ which is a contradiction. Where am I wrong in my reasoning? Thanks in advance!","['general-topology', 'real-analysis', 'connectedness']"
2099081,Summation of $\arcsin $ series. [duplicate],"This question already has answers here : Limit with inverse trignometry [closed] (2 answers) Closed 7 years ago . What is $a $ if $$\sum _{n=1} ^{\infty} \arcsin \left(\frac {\sqrt {n}-\sqrt {n-1}}{\sqrt {n (n+1)}}\right) =\frac {\pi }{a} \,?$$ Attempt: What I tried is to convert the series to $\arctan$ and then convert it telescoping series. So in terms of $\arctan $ it becomes $$\arctan \left(\frac {\sqrt {n}-\sqrt {n-1}}{\sqrt {n}+\sqrt {n-1}}\right) $$ but now if I divide by $n$ it simplifies as $n\frac {\pi}4-\sum _1^{\infty} \arctan \left(\frac {\sqrt {n-1}}{\sqrt {n}}\right) $ but as $n$ is tending towards infinity it will lead to infinity which seems wrong. Also note that $a$ is an integer . Thanks!","['summation', 'trigonometry']"
2099088,"Prove that all roots of $z\tan z = k$ lie in $\Bbb R$, where $k$ is a positive, non-zero real number.","The question is that given in the title; Prove that all roots of the equation $z\tan z = k$ lie in $\Bbb R$, where $k$ is a positive non-zero real number. I attempted a somewhat ""brute force"" approach by simply letting $z = a + bi$, with $a, b \in \Bbb R$. Under this assumption, if $a = 0$ (that is, $z$ is purely imaginary), we come to the conclusion that $k$ must be of the form $$-b\tanh b = k.$$ If $b > 0$ then $\tanh b \in (0,1]$ and so $-b\tanh b < 0$. If $b < 0$ then $\tanh b \in [-1, 0)$ since $\tanh$ is odd, and so again, $-b\tanh b < 0$, and so for $k \in \Bbb R_{>0}$, we cannot have purely imaginary $z$. Consider then the case that $z = a + bi$ where $a, b \neq 0$. Then after some manipulation, we end up with $$z\tan z = \frac{\tan a + i\tanh b}{1 - i\tan a \tanh b}.$$ Since both $\tan$ and $\tanh$, with domain restricted to $\Bbb R$, also have codomain $\Bbb R$, this ratio must be complex, since $\tanh b = 0$ iff $b = 0$, which we excluded under assumption, and so $k$ is complex if $z$ is complex. The only remaining possibility is that $z \in \Bbb R$, the result has been proven. I think this is somewhat hand-wavy at best; can anyone give me a more satisfactory/elegant proof of this result?","['complex-analysis', 'trigonometry']"
2099097,Proving that $19\mid 5^{2n+1}+3^{n+2} \cdot 2^{n-1}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How can I prove that $$5^{2n+1}+3^{n+2} \cdot 2^{n-1} $$ can be divided by 19 for any nonnegative n? What modulo should I choose?","['number-theory', 'divisibility', 'elementary-number-theory']"
2099115,Evaluating the integral $\int_0^\infty dke^{-\gamma k}k\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\sin(kr)$,"Consider the telegraph equation within a linear medium: $$\left(\frac{\varepsilon\mu}{c^2}\frac{\partial^2}{\partial t^2}+\mu\sigma\frac{\partial}{\partial t}-\nabla^2\right)\Psi(\vec{r},t)=0$$ with initial conditions $\Psi(\vec{r},0)=f(\vec{r}), \Psi_t(\vec{r},0)=0$. Taking a Fourier Transform with respect to spatial coordinates gives $$\left(\frac{\varepsilon\mu}{c^2}\frac{\partial^2}{\partial t^2}+\mu\sigma\frac{\partial}{\partial t}+k^2\right)\hat{\Psi}(\vec{k},t)=0$$ This is a linear ODE in $t$ with characteristic equation $$\lambda^2+\frac{\sigma c^2}{\varepsilon}\lambda+\frac{c^2k^2}{\varepsilon\mu}=0$$ Thus, assuming that $\frac{c^2k^2}{\varepsilon\mu}>\frac{\sigma^2c^4}{4\varepsilon^2}$ its solutions are given by $$\hat{\Psi}(\vec{k},t)=e^{-\beta t}\left[A(\vec{k})\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)+B(\vec{k})\sin\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\right]$$ for arbitrary functions $A(\vec{k}), B(\vec{k})$ and $\alpha:=\frac{c}{\sqrt{\varepsilon\mu}}, \beta:=\frac{\sigma c^2}{2\varepsilon}$. Plugging in the initial conditions, we have $A(\vec{k})=\hat{f}(\vec{k}), B(\vec{k}) = 0$, thus $$\hat{\Psi}(\vec{k},t)=\hat{f}(\vec{k})e^{-\beta t}\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)$$ To calculate the Inverse Fourier Transform, we calculate the Inverse Fourier Transform of $\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)$ and then apply the Convolution Theorem. \begin{align}
\mathcal{F}^{-1}\left[\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\right]&=\frac{1}{8\pi^3}\int_0^\infty dkk^2\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\int_0^\pi d\theta\sin\theta e^{ikr\cos\theta}\int_0^{2\pi}d\phi\\
&=\frac{1}{4\pi^2}\int_0^\infty dkk^2\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\int_{-1}^1due^{ikru}\\
&=\frac{1}{4\pi^2r}\int_0^\infty dkk^2\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\left[\frac{e^{ikr}-e^{-ikr}}{ik}\right]_{u=-1}^{u=1}\\
&=\frac{1}{2\pi^2r}\int_0^\infty dkk\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\sin(kr)
\end{align} Since this integral does not converge, we insert a regularisation parameter and rewrite it: $$\mathcal{F}^{-1}\left[\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\right]=\frac{1}{2\pi^2r}\lim\limits_{\gamma\rightarrow 0^+}\int_0^\infty dke^{-\gamma k}k\cos\left(\sqrt{\alpha^2k^2-\beta^2}t\right)\sin(kr)$$ This integral converges for all values of $\gamma>0$. It is at this point that I am stuck. I've tried a couple of things - writing out the product using the fact that $\cos(x)\sin(y) = \frac{1}{2}\left[\sin(x+y)-\sin(x-y)\right]$  and then rewriting this as the imaginary part of complex exponentials, using the Residue Theorem, integration by parts - in each case I get stuck because of the square root within the cosine function. Could anybody give me a hint on how to calculate this final integral? Or does there exist no closed form?","['partial-differential-equations', 'integration', 'definite-integrals', 'ordinary-differential-equations', 'fourier-transform']"
2099121,"Show that $f(z)=0$ for all $z$, where $f$ is an analytic function on the closed unit disc with additional conditions.","Let $D$ denote the open ball of unit radius about origin in the complex plane $\Bbb C$ . Let $f$ be a continuous complex-valued function on its closure $D$ which is analytic on $D$ . If $f(e^{it}) = 0$ for $0 < t  <\frac{\pi}{2}$ , show that $f(z) = 0 $ for all $z$ . Here is what I tried: $f$ is analytic on $D$ . If I can find a sequence $(z_n)_n$ in $D$ such that $f(z_n)=0\forall n$ and additionally $(z_n)_n$ has a limit point in $D$ then we are done. I think $f(e^{it}) = 0$ may help finding one sequence but I am not sure. Will you kindly help?",['complex-analysis']
2099189,Amount of 3 x 3 block of binary pixels combinations with rotations/reflections considered identical,"I am considering a $3\times 3$ block of pixels where each pixel can be either $0$ or $1$. How many unique blocks are there if we consider rotations/reflections to be identical? I believe the answer is $76$, but I am really bad at combinatorics. Below is an image of what I believe is the solution set:","['combinatorics', 'rotations', 'reflection']"
2099210,When is the matrix $\text{diag}(\mathbf{x}) + \mathbf{1}$ invertible?,"Given a vector $\mathbf{x} \in \mathbb{R}^N$, let's define: $$\text{diag}(\mathbf{x}) = \begin{pmatrix}
x_1 & 0 & \ldots & 0 \\
0 & x_2 & \ldots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \ldots & x_N
\end{pmatrix}.$$ Moreover, let $$\mathbf{1}= \begin{pmatrix}
1 & 1 & \ldots & 1 \\
1 & 1 & \ldots & 1 \\
\vdots & \vdots & \ddots & \vdots \\
1 & 1 & \ldots & 1
\end{pmatrix}.$$ Here is my question: When is the matrix $\mathbf{M} = \text{diag}(\mathbf{x}) + \mathbf{1}$ invertible? I was able to find some results when $x_1 = x_2 = \ldots = x_N = x$. Indeed, the matrix $M$ is singular when: $x=0$. This is trivial since $\mathbf{M} = \mathbf{1}$... $x=-N$. In this case, if you sum up all the rows (or columns) of the matrix $M$, you get the zero vector. What can I say in the general case when $\text{diag}(\mathbf{x})$ is a generic vector?","['matrices', 'linear-algebra', 'inverse']"
2099294,Deducing this better version of the regularity lemma from the usual one,"Szemeredi's regularity lemma states that for every $\epsilon >0$ there is $M\in \Bbb N$ such that all graphs have an equipartition $\{V_1,...,V_k\}$ for some $k$ satisfying $\frac 1\epsilon \leq k \leq M$ such that at most $\epsilon k^2$ of the pairs $(V_i,V_j)$ are not $\epsilon$-regular. By an equipartition we mean that the sets are as equal as possible, i.e. $||V_i|-|V_j||\leq 1$, and by an $\epsilon$-regular pair $(V_i, V_j)$ we mean that for every $A\subseteq V_i, B\subseteq V_j$ with $|A| \geq \epsilon |V_i|, |B| \geq \epsilon |V_j|$ we have that $|d(V_i,V_j)-d(A,B)|<\epsilon$, where $d(X,Y)$ denotes the density of the bipartite graph on $X,Y$. Deduce from the regularity lemma that we can even require that every $V_i$ will have at most $\epsilon k$ irregular pairs $(V_i,V_j)$, which strengthens the traditional formulation above (in which we only claim that there are at most $\epsilon k^2$ irregular pairs). This fact is referred to as a well-known (and easy) observation right before theorem 2 in this paper . It is claimed  explicitly this holds when we take $M^3$ instead of $M$ in the statement. This is also given as problem 2 here . I'd like to know why this is true.","['graph-theory', 'extremal-graph-theory', 'discrete-mathematics']"
2099305,Are there arbitrarily large sets $S$ of natural integers such that the difference of each pair is their GCD?,"I am interested in sets $S \subseteq \mathbb{N}$ of natural integers with the following property: for any $i, j \in S$, then the greatest common divisor of $i$ and $j$ is the absolute value of their difference, $|i - j|$. Equivalently, this amounts to requiring that the difference $|i-j|$ divides $i$ and $j$. Are there sets $S$ of arbitrarily large cardinality with this property? Examples of such sets $S$ of cardinality up to 9 are given in sequence A213918 of the OEIS, but there is no discussion there about whether arbitrarily large such sets exist. My intended use for this would be to obtain a variant of Van der Waerden's theorem , to show that from an infinite word one can extract arbitrarily large monochromatic arithmetic progressions with the added condition that the common difference of the arithmetic progression divides its first term.","['gcd-and-lcm', 'combinatorics', 'arithmetic-progressions', 'arithmetic']"
2099324,"Show that the extension of $f : S → \mathbb{R}$ to the closure of its domain, $\overline{S}$, is unique","I trying to solve the following question Assume that $f : S → \mathbb{R}$ is a uniformly continuous function
  deﬁned on a subset $S$ of a metric space $M$. 1. Prove that $f$ extends to a uniformly continuous function $f : \overline{S} → \mathbb{R}$. 2. Prove that $\overline{f}$ is the unique continuous extension of $f$ to a function deﬁned on $\overline{S}$. 3. Prove the same things when $\mathbb{R}$ is replaced with a
      complete metric space $N$. For the first question, I show that for some sequence $x_n \in S$ that converges to  $\hat{x} \in \overline{S},$ $\overline{f}(x_n)$ converges to $\overline{f}(\hat{x})$ since uniformly continuous functions take Cauchy sequences to Cauchy sequences and since $\mathbb{R}$ is complete. However, I feel like while this shows that $\overline{f}(x_n)$ converges, it does not fully establish that $\overline{f}(x_n)$ converges to $\overline{f}(\hat{x})$. Is this proof sufficient to show that $f$ extends to a uniformly continuous function $f : \overline{S} → \mathbb{R}$? For number 3, the same proof applies since I used the completeness of $\mathbb{R}$ as the basis for my proof. However, I don't understand how I would show that $\overline{f}$ is the unique extension of $f$. Is it sufficient to say that since all sequences in $S$ must converge to their unique limits in $\overline{S}$, $\overline{f}$ must also be unique?","['real-analysis', 'complete-spaces', 'uniform-continuity', 'metric-spaces', 'sequences-and-series']"
2099342,Why does $\arcsin(-x) = -\arcsin(x)$? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question What is the property that tells us  $\arcsin(-x) = -\arcsin(x)$ ? I've also seen in an exercise that : $\arcsin (\sin(2x)) = 2x ~~$ if $x \in\left[0,\frac{\pi}{4}\right]$ And what about: $\arcsin(\sin(2x)) = \pi - 2x ~~$ if $x \in \left]\frac{\pi}{4},\frac{\pi}{2}\right]$? What justifies these relations?",['trigonometry']
2099366,Do we have $\lim_{n\to \infty }\int X_n dP=\int\lim_{n\to \infty }X_ndP$,"Let $P$ a probability and $X_n$ a random variable that is uniformly bounded, i.e. $\sup_n X_n<\infty $. We suppose $X_n\to X$. Do we have that $$\lim_{n\to \infty }\int_{\Omega } X_n dP=\int_{\Omega } \lim_{n\to \infty }X_n dP\ \ ?$$ To me it's almost bounded convergence theorem, but the bounded convergence theorem that I know is only valid on set of finite measure. So, $\Omega $ may be not bounded, but since $P(\Omega )=1$ maybe it also works. I recall the bounded convergence theorem that I know : If $f_n(x)\to f(x)$ a.e. $(f_n)$ is uniformly bounded and $m(E)$ is finite, then $$\lim_{n\to \infty }\int_E f_n=\int_E f.$$ Here it's a little bit different. But I have the intuition that it's almost the same. Do you have an explanation ?","['probability', 'measure-theory']"
2099382,Getting the usual definition of product topology from an alternative one,"I'm studying the topological product using Schubert's book.
He starts by defining the product topology as follows: DEFINITION. Let $\{X_{\lambda}\}_{\lambda\in\Lambda}$
    be a (non-empty) family of topological spaces. The coarsest topology on the set $X=\underset{\lambda\in\Lambda}{\prod}X_{\lambda}$
   , for which all projections $p_{\lambda}:X\rightarrow X_{\lambda}$
    are continuous, is called the product topology on X. If $X$ is considered as having this topology, then $X$ is called the topological product of the spaces $X_\lambda$. He then states the following theorem: THEOREM: Sets of the form $\prod Q_{\lambda}$, where $Q_{\lambda}$  is open in $X_{\lambda}$ and $Q_{\lambda}=X_{\lambda}$  with a finite number of exceptions, form a basis for the product topology. Which the usual definition of the product topology. I tried to prove this theorem from the given definition. I'm still very shaky in this topic (topology), and I found this proof particularly tricky, so I would like you to check it. My attempt: I know that the coarsest topology on $X$ containing all the sets of a certain family $A$ of subsets of $X$ is the topology generated by $A$ ($A$ thus being a subbasis for this topology). Hence, if we let $A$ be the set of all subsets of $X$ containing all the sets of the form $p_{\lambda}^{-1}(Q_{\lambda})$ (with $Q_\lambda$ an open set of $X_\lambda$), $A$ is a subbasis of the product topology (because all projections $p_{\lambda}:X\rightarrow X_{\lambda}$ are continuous precisely when the sets of the form $p_{\lambda}^{-1}(Q_{\lambda})$ (with $Q_\lambda$ an open set of $X_\lambda$) are open in $X$). I also know that, if $Q_{\mu}$
  is a set of $X=\underset{\lambda\in\Lambda}\prod X_{\lambda}$, then $p_{\mu}^{-1}(Q_{\mu})=X_{1}\times X_{2}\times...\times Q_{\mu}\times...$ Now, the set of all finite intersections of the elements of $A$ is a basis of $X$. The finite intersections of the $p_{\mu}^{-1}(Q_{\mu})=X_{1}\times X_{2}\times...\times Q_{\mu}\times...$ are precisely of the form described in the theorem.","['general-topology', 'proof-verification']"
2099456,What is the prob that the seq obtained is inc (ie. nondecreasing),"Given n distinct numbers, k numbers are picked out, 1 by 1 w/ replacement to get a seq of numbers. What is the prob that this seq is increasing? I know that since non-decreasing seq are allowed, there are in addition n constant seq on top of the strictly increasing probability of C(n,k)/n^k. But I am stuck from here...",['statistics']
2099461,What's the name of the following method for dividing polynomials? It's not long-division nor synthetic division,"I saw this method in some random PDF and am intrigued of the exact method used. I can't find any page of this method on the web because I'm not sure what you'd call this method. Here is the method: For solving
  $$\int \frac{2x^4 + x^3}{x^2 + x - 2} \,\text{d}x$$
  Observe that
  $$\begin{align*}
2x^4 + x^3
&= 2x^2 (x^2+x-2) - x^3+4x^2 \\
&= 2x^2 (x^2+x-2) - x(x^2+x-2) + 5x^2-2x \\
&= 2x^2 (x^2+x-2) - x(x^2+x-2) + 5(x^2+x-2) - 7x+10 \\
&= (2x^2-x+5)(x^2+x-2) - 7x+10
\end{align*}$$
  and then
  $$
\int \frac{2x^4-x^3}{x^2+x-2} \,\text{d}x
= \int (2x^2-x+5)\,\text{d}x
+ \int \frac{-7x+10}{x^2+x-2}\,\text{d}x$$","['integration', 'polynomials']"
2099483,"coercive implies bounded, variational principle","I have a question about the proof of the variational principle, see below. Any help is much appreciated! How does it follow from coercivity that $(x_k)_k$ is bounded? Why is $\alpha_0 > - \infty$? $\,$ Prerequisites Let $(X, || · ||_X )$ a normed real vector space, $\, M \subset X$, $\, F : M \rightarrow \mathbb R.$ $\,$ Theorem. (Eberlein-Šmulyan) Let $X$ be reflexive, $(x_k)_{k \in \mathbb N} \subset X$ bounded. Then there exists $x \in X$ and a subsequence $\Lambda \subset \mathbb N$ with
  $$ x_k \overset{w}{\rightarrow} x \quad (\text{for } \, k → ∞ , \, k \in \Lambda) .$$ $\,$ Definition. The function $F$ ist weakly sequentially lower semi-continuous (w.s.l.s.c.) at $x_0 \in M$, if $\forall \, (x_k)_{k\in \mathbb N} \subset M$ with $x_k \overset{w}{\rightarrow} x_0$ (for $k \rightarrow \infty$) there holds $$F(x_0) ≤ \liminf_{k \rightarrow \infty} F(x_k).$$ $\,$ Definition. $F$ is called coercive on $M$  with respect to $||·||_X$ , if for $x \in M$ $$F(x) \rightarrow \infty, \quad (\text{for} \, ||x||_X \rightarrow \infty).$$ $\,$ Actual question Theorem. (Variational Principle) Let $X$ be reflexive, $M \subset X$ nonempty and weakly sequentially closed, $F : M \rightarrow R$ coercive and w.s.l.s.c.. Then there exists $x_0 \in M$ with
  $$F(x_0) = \inf_{x∈M} F(x).$$ $\,$ Proof. Consider a minimal sequence $(x_k)_{k ∈ \mathbb N} \subset M$ with $$F(x_k)→ \inf_{x \in M} F(x)=:α_0 ≥ −∞, \quad (\text{for } k→∞).$$ Since $F$ is coercive, $(x_k)_{k \in \mathbb N}$ is bounded . (Why?) By Eberlein-Šmulyan's theorem $(x_k)_{k \in \mathbb N}$ has a 
  weakly convergent subsequence $x_k \overset{w}{\rightarrow} x_0$ $($for $k → ∞, k ∈ Λ)$. Since $M$ is weakly sequentially closed, it follows that $x_0 ∈ M$, and
  $$F(x_0) ≤ \liminf_{k→∞, \, k∈Λ} F(x_k) = α_0$$
  since $F$ is w.s.l.s.c., in particular we have $α_0 > −∞.$","['normed-spaces', 'functional-analysis', 'weak-convergence', 'coercive', 'calculus-of-variations']"
2099505,conservation of dot product with parallel transport,"I have a question about the parallel transport of a vector : Why does one say that parallel transport preserves the value of dot product (scalar product) between the transported vector and the tangent vector ? Is it due to the fact that angle between the tangent vector and transported vector is always the same during the operation of transport (which is the definition of parallel transport) ? So If I take 2 different points, the dot product is the same since angle is the same ?? How to demonstrate it or translate this statement from a mathematic point of view ? Thanks for your help UPDATE 1 : Thanks for your quick answer. Unfortunately, I am not an expert in tensor calculus but I know some basics like the definition of covariant derivative of a vector $V$ along a geodesic - like with this notation : $\nabla_{i}V^{j}=\partial_{i}V^{j}+V^{k}\Gamma_{ik}^{j}\quad\quad(1)$ and the absolute derivative : $D\,V^{j}=(\nabla_{i}V^{j})dx^{i}\quad\quad(2)$ Could give me the link between your equation (
$Z \langle X,Y \rangle = \langle \nabla_Z X, Y\rangle + \langle X, \nabla_Z Y\rangle$ ) and the equation (1) or (2). Moreover, you define $Z$ like $$\text{d}\gamma/\text{d}t$$ but after, you only take $\text{d}/\text{d}t$ in : $\frac{d}{dt}\langle X,Y \rangle = \langle \nabla_{\overset{\cdot}{\gamma}} X, Y\rangle + \langle X, \nabla_{\overset{\cdot}{\gamma}} Y\rangle = 0$ You say that $Z$ is a vector field : is it an operator or a vector field ? And what about $\langle X,Y\rangle$ ? Can one write : $\langle X,Y\rangle=g_{ij}X^{i}Y^{j}$ with $g_{ij}$ the metrics ??? Regards UPDATE 2 : I think there is a little error on index for the third term in first factor, this sould be : $\Big(\dfrac{\partial g_{ij}}{\partial x^p} - g_{kj}\Gamma_{pi}^k - g_{ik}\Gamma_{pj}^k\Big)\xi^i\eta^j\mathrm{d}x^p = 0.$ and not $\Big(\dfrac{\partial g_{ij}}{\partial x^p} - g_{kj}\Gamma_{pi}^k - g_{ik}\Gamma_{pi}^k\Big)\xi^i\eta^j\mathrm{d}x^p = 0.$ UPDATE 3 : You say ""Why ?"" above ""equal symbol"" but you don't give the reason : $\mathrm{D}\langle\xi\eta\rangle \stackrel{why?}{=} \mathrm{d}\langle\xi\eta\rangle = \mathrm{d}(g_{ij}\xi^i\eta^j) = 0.$ Could you justify please this expression : $\mathrm{d}(g_{ij}\xi^i\eta^j) = 0$ I know that norm of 2 vectors defined by $\text{d}x^{i}$ and $\text{d}x^{j}$ is constant (I mean indepedently of basis used) because : $\text{d}s^2=g_{ij} \text{d}x^{i}\text{d}x^{j}=\text{length}=\text{constant}$ Is this the same justification with $\xi^i\eta^j$ vectors ?",['differential-geometry']
2099506,Prove that $ a\in Z(G) $,"Let $ (G,\cdot ) $ be a group with $ |G|=2m+1,m\in \mathbb{N} $ and $ a\in G $ so that there exists $ n\in \mathbb{N} $ with $ a^{n}\cdot x=x\cdot a,\forall x\in G\setminus A $, where $ A=\left \{ a^{k}|k\in \mathbb{Z} \right \}. $ Prove that $ a\cdot x=x\cdot a,\forall x\in G. $ Obviously, if $ x\in A $, $ a\cdot x=x\cdot a. $ If $ x\notin A $, the only thing I've found is that $ a^{n}\cdot (x\cdot a^{n-1})^{2m}\cdot x\cdot a^{-1}=e $.","['finite-groups', 'abstract-algebra', 'group-theory']"
2099508,Linear algebra over a non-free f.g. module,"Suppose $M$ is a finitely generated module over a commutative ring $R$. I was thinking about the relation between $\operatorname{End}_R M$ and $M_n(R)$. Suppose I fix a generating set $m_1, \dotsc, m_n \in M$. Not all matrices $(a_{ij}) \in M_n(R)$ represent $R$ linear self-maps of $M$ via 
$$m_i \mapsto \sum_j a_{ij}m_j,$$
because some of them don't respect the relations that may hold between the $m_i$. If a relation holds on $m_i$, the same had better hold for the columns of $a_{ij}$. For example, in $\mathbb{Z}_2 \oplus \mathbb{Z}_3$, with the usual two generators, the matrix 
$$\begin{pmatrix} 0 & 1 \\ 1 & 0\end{pmatrix}$$
does not represent a map of abelian groups. So we need to look at some subalgebra $S <M_n(R)$ which does represent linear self-maps of $M$. Further, the fact that there are relations between the generators means that in general a lot of matrices correspond to the zero transformation. So it seems we should think of $\operatorname{End}_R M$ as a quotient of $S$, by the ideal of matrices that determine the zero transformation. I see no reason why this would be a two-sided ideal in $M_n(R)$, but it will be in $S$. So it seems that when we try to do matrix computations when working with f.g. modules, like when we prove Cayley-Hamilton and so forth, we are looking at $$M_n(R) \hookleftarrow S \twoheadrightarrow S/I \cong \operatorname{End}_R(M)$$ and we work so that we can do some matrix computations inside $S$ that work after we mod out by $I$. (I guess in proving Cayley Hamilton, like here , we're taking the ring to be $R[x]$.) Can anyone offer any more clarifying perspective? I've never seen sources that discuss it like this, so any references are welcome.","['modules', 'reference-request', 'soft-question', 'commutative-algebra', 'linear-algebra']"
2099513,Is there a name for a functionalistic / operations-like approach?,"I find it a lot easier to think about e.g. integration as int(a, b, f(x), x) rather than $\int_{a}^{b}{f(x)}dx$. And even addition seems more intuitive as add(a,b) rather than $a+b$. Is there a term for thinking like that or is this just being weird with notation?","['binary-operations', 'integration', 'functions']"
2099514,Units of p-adic integers,"How to prove that the $p$-adic units can be written as
$$\mathbb{Z}_p^\times \cong \mu_{p-1}\times(1 + p\mathbb{Z}_p) \cong \mathbb{Z}/(p-1)\mathbb{Z}\times\mathbb{Z}_p$$
where $\mu_n$ is the $n$-th roots of unity in $\mathbb{Z}_p$? Here $p>2$ is a prime number. Any hint or link would be helpful. Besides, it looks strange: why the units of $\mathbb{Z}_p$ is isomorphic to some guy which looks bigger than $\mathbb{Z}_p$?","['number-theory', 'algebraic-number-theory', 'p-adic-number-theory']"
2099516,"For independent Gamma random variables $G_1, G_2 \sim \Gamma(n,1)$, is $G_1+G_2$ independent of $G_1-G_2$?","For independent Gamma random variables $G_1, G_2 \sim \Gamma(n,1)$, $\frac{G_1}{G_1+G_2}$ is independent of $G_1+G_2$. Does this imply that $G_1+G_2$ is independent of $G_1-G_2$? Thanks!","['probability-theory', 'probability', 'random-variables']"
2099586,What are the eigenvalues of matrix $uu^T$ where $u$ is a column vector?,"Please let me know if this problem is duplicated and I will remove it ASAP. I see this problem on an interview book. The vector is defined as $u=(u_1,u_2,...,u_n)^T$. Then the eigenvalues of $uu^T$ are given as $\Sigma_{i=1}^n u_i^2$ with multiplicity 1 and 0 with multiplicity $n-1$. I try to start with $det(uu^T-\lambda I)$ and try to show this is exactly ($\lambda-\Sigma_{i=1}^n u_i^2)\lambda^{n-1}=0$ Any help will be appreciated!","['symmetric-matrices', 'linear-algebra']"
2099597,Subgroup of $\mathbb{R}$ that is a nontrivial direct sum of $n$ groups,"Given any integer $n\geq 2$, I need to find a subgroup of $\mathbb{R}$ which is a nontrivial direct sum of $n$ groups. Initially, I was thinking of $\mathbb{Q}$, since it has the nice property of count ability, but them I remembered that every two nontrivial subgroups of $\mathbb{Q}$ has nontrivial intersection. So, I am really at a loss as to how to even start. What $n$ groups comprise the nontrivial direct sum of a subgroup of $\mathbb{R}$? And which subgroup of $\mathbb{R}$? I thank you ahead of time for any help you can give.","['abstract-algebra', 'group-theory']"
2099607,How do I prove that $e^z$ is entire?,"How does one prove that$\frac{\mathrm{d}}{\mathrm{d}z}e^z = e^z$, $\forall z\in\mathbb{C}$? Attempt 1 $$\frac{\mathrm{d}}{\mathrm{d}z}e^z=\lim_{\Delta z\to 0}\frac{e^{z+\Delta z}-e^z}{\Delta z} = \lim_{\Delta z\to 0}e^z\frac{e^{\Delta z}-1}{\Delta z}$$
I assume that $\frac{e^{\Delta z}-1}{\Delta z}\to1$, but since $\Delta z$ isn't necessarily real I don't know how to deal with the limit. Attempt 2 I considered using the Cauchy–Riemann equation and it's relation to differentiation to evaluate $\frac{\mathrm{d}}{\mathrm{d}z}e^z$ by computing the partial derivatives. Let $f(z)=e^z$. $$f_x(z) = \lim_{\Delta x\to0}\frac{e^{x+\Delta x+iy}-e^{x+iy}}{\Delta x} = \lim_{\Delta x\to0}e^{x+iy}\frac{e^{\Delta x}-1}{\Delta x}$$
Since $\Delta x\in\mathbb{R}$ this is essentially just a standard limit from calculus since $e^{x+iy}$ is constant and the fraction is real and tends to $1$. So $f_x(z)=e^z$ and I don't know if it's continuous on all of $\mathbb{C}$ but I'll save that one for later. I cannot assume that $f_y(z)=-if_x(z)$ since I would have to assume that $f$ is entire which I have not proven. So I have to compute $f_y(z)$ like I did with $f_x(z)$.
$$f_y(z)=\lim_{\Delta y\to0}\frac{e^{x+i(y+\Delta y)}-e^{x+iy}}{\Delta y} = \lim_{\Delta y\to0}e^{x+iy}\frac{e^{i\Delta y}-1}{\Delta y}$$
Here I run into a problem again because of $e^{i\Delta y}$ and I don't know how to compute that limit. Eulers formula would possibly make things a bit more simple, it usually does, the reason I didn't want to attempt to apply it is because I have not seen a proof of it that is rigorous that I understand. I have seen the Maclaurin series proof but I am not familiar with complex power series and convergence must be proven. Anyway, this post is getting to be a bit too long for such a simple result, but there you have my attempts. Now please help me. How do I prove this?","['derivatives', 'real-analysis', 'limits', 'exponential-function', 'complex-analysis']"
2099647,Cutting out a circle using circles,"Let $X_0$ be the unit disc, and consider the process of ""cutting out circles"", where to construct $X_n$ you select a uniform random point $x \in X_{n-1}$ , and cut out the largest circle with center $x$ . To illustrate this process, we have the following graphic: where the graphs are respectively showing one sample of $X_1,X_2,X_3,X_{100}$ (the orange parts have been cut out). Can we prove we eventually cut everything out? Formally, is the following true $$\text{lim}_{n \to \infty} \mathbb{E}[\text{Area}(X_n)] = 0$$ where $\mathbb{E}$ denotes we are taking the expectation value. Doing simulations, this seems true, in fact $\mathbb{E}[\text{Area}($ X_n $)]$ seems to decay with some power law, but after 4 years I still don't really know how to prove this :(. The main thing you need to rule out is that $X_n$ doesn't get too skinny too quickly, it seems.","['probability', 'measure-theory', 'geometry', 'recreational-mathematics', 'random-variables']"
2099666,Find a subsequence whose limit exists,"Let $\{a_n\}$ be a sequence of non-zero real numbers. Show that it has a subsequence $\{a_{n_k}\}$ such that $\lim \dfrac{a_{n_{k+1}}}{ {a_{n_k}}}$ exists and belongs to $\{0,1,\infty\}$ . I am finding the above problem false.
If I take $(a_n)_n=(e^{-n})_n$ then any sub-sequence of $a_n$ is $e^{-n_k}$ but $\lim \dfrac{a_{n_{k+1}}}{ {a_{n_k}}}=\dfrac{e^{-n-1}}{e^{-n}}=\dfrac{1}{e}\notin \{0,1,\infty\}$ . Edits :By @Henry's comment I am sure the problem is true.But how should I  find the sub-sequence.Please give some hints.","['real-analysis', 'convergence-divergence', 'sequences-and-series', 'analysis']"
2099671,Find $\int_{0}^{\infty }\frac{\cos x-\cos x^2}{x}\mathrm dx$,"Recently, I met a integration below
\begin{align*}
\int_{0}^{\infty }\frac{\sin x-\sin x^2}{x}\mathrm{d}x&=\int_{0}^{\infty }\frac{\sin x}{x}\mathrm{d}x-\int_{0}^{\infty }\frac{\sin x^{2}}{x}\mathrm{d}x\\
&=\int_{0}^{\infty }\frac{\sin x}{x}\mathrm{d}x-\frac{1}{2}\int_{0}^{\infty }\frac{\sin x}{x}\mathrm{d}x\\
&=\frac{1}{2}\int_{0}^{\infty }\frac{\sin x}{x}\mathrm{d}x=\frac{\pi }{4}
\end{align*}
the same way seems doesn't work in
$$\int_{0}^{\infty }\frac{\cos x-\cos x^2}{x}\mathrm dx$$
but why? Then how to evaluate it? Thx!","['improper-integrals', 'integration', 'definite-integrals']"
2099679,Why can't we remove the sqrt from rms?,"In chemistry, we define the root-mean-square speed as $\sqrt{\bar{u^2}}$ = $\sqrt{\frac{3\text{RT}}{\text{M}}}$ A student asked me why we can't just remove the square root symbol. And aside from ""because this is how we define it"", I didn't actually have a reason. So, I'm hoping someone can shed some light on why the above equation is used and not: $\bar{u^2} = \frac{3\text{RT}}{\text{M}}$ In case it is important, we use this equation to determine the rms speed of a gas. It depends on the temperature (T) and the molecular mass of the gas (M). R is a constant value. I understand we don't just use the average because in a set of gases, they move in a random direction so the average is 0. But, by squaring isn't that issue resolved, without the square root?","['statistics', 'chemistry']"
2099699,Left inverse in $F_{A}$ iff injective proof.,"Let A be a non-empty set and $f : A → A$ be a function. Prove that f has a left inverse in $F_{A}$ if and only if f is injective
(one-to-one). $\leftarrow$ assume f is injective then $\forall x\in A \space \space \space \space \space \space \space \space \space f(x) \in A  $  such that if $f(x)=f(y) $ then $ x=y$ something something $g(f(x)) = x  \space \space \space \space \forall x\in A$ $\rightarrow$ assume f has a left inverse in $F_{A}$ then $\forall x\in A$ $g(f(x)) = x$ something says that x must be one to one? Im really confused by this question First of all f must be a bijection if it is one to one from $ A \to A $ is it not? Can someone help me out with this proof?",['elementary-set-theory']
2099712,Two disjoint convex closed sets that cannot be separated by a closed hyperplane?,"When I was reading ""Functional Analysis"" written by Brezis, I noticed the following counterexample, saying that two disjoint closed convex sets may not be separated by a closed hyperplane. Let $E=l^{1}$ (the space of real, absolutely convergent series) and define 
$$X=\{x=(x_{n})_{n\geq1}\in E:x_{2n}=0 \ \forall n\geq 1\}$$
and 
$$Y=\{y=(y_{n})_{n\geq1}\in E:y_{2n}=\frac {1}{2^{n}}y_{2n-1} \ \forall n\geq 1\}$$
(i) Show that $X$ and $Y$ are closed linear spaces and $\overline{X+Y}=E$. (ii) Let $c=(c_{n})_{n\geq1}\in E$ be defined by $c_{2n}=\frac{1}{2^{n}}$ and $c_{2n-1}=0$ for all $n\geq 1$. Check that $c\notin X+Y$. (iii) Set $Z=X-c$ (then $Y\bigcap Z=\emptyset$). Show that $Y$ and $Z$ cannot be separated by a closed hyperplane. I can prove that (i) and (ii) hold. But I'm stuck in part (iii). How can I prove $Y$ and $Z$ cannot be separated by a closed hyperplane? Thanks!","['general-topology', 'real-analysis', 'functional-analysis']"
2099715,"Difficult definite integration $\int_{-2}^{0}\frac{x^2 + x - 5}{(x-1)^2}e^x\,\mathrm dx$","I found an integral in a contest that seems very difficult to compute. The answer is $-2$, however, I do not know how to arrive at this answer. $$\int_{-2}^{0}\frac{x^2 + x - 5}{(x-1)^2}e^x\,\mathrm dx$$ At first I tried to make the substitution $u = x - 1$, but I did not get anywhere. I also tried to expand the denominator and perform synthetic division, which did not help so much either. Also, I don't think it is possible to do partial fraction decomposition since the degree of the denominator is equal to the degree of the numerator. Attempt with substitution (Moo's help) - Let $u = x - 1$. Then, $du = 1$
$$\begin{align}
I &= \int_{-2}^{0} \frac{x^2 + x - 5}{(x - 1)^2} e^x\,\mathrm dx =\\
&= \int_{-2}^{0} \frac{x^2 + x - 5}{u^2} e^{u+1}\,\mathrm du =\\
&= \int_{-2}^{0} \frac{e^{u+1}(x^2 + x - 5)}{u^2}\,\mathrm du
\end{align}$$ Now, $x = u + 1$, $x^2 = u^2 + 2u + 2$ and therefore
$$I = \int_{-3}^{-1} \frac{e^{u+1}(u^2 + 3u - 2)}{u^2}\mathrm du = e \int_{-3}^{-1} e^{u}\frac{u^2 + 3u - 3}{u^2}\mathrm du$$","['integration', 'definite-integrals', 'calculus']"
2099735,Definition of significant figures,"Normally when we are taught how to add numbers with regards to significant figures, we are told to round the result to the rightmost place of the least precise digit. $3.55 + 4 = 7.55$, for example, would be rounded off to $8$. But for my argument I will be considering the addition of two numbers $9$ and $2$, both of which are significant to the ones digit. Following the usual rule for addition, $9 + 2 = 11$ and now we have two significant figures. However, whenever I think about significant figures I would intuitively think of these two definitions: 1 - Digits to the right of the last significant digit, can be any number
  between 0 and 9. 2 - Any digit that has the possibility of being more than one numerical
  value, is not a significant digit. Using the first definition, we can put $9$ and $2$ in these forms: $9.A$ $2.B$ where $A$ and $B$ are arbitrary digits ranging from $0$ to $9$. Thus, when we add
these two numbers, we would end up with: $$9.A + 2.B$$ $$= 9 + 2 + 0.A + 0.B$$ $$= 11 + 0.A + 0.B$$ Finally when we assign some meaningful values to $A$ and $B$ such as $(A , B) =
(0 , 0)$ or $(A , B) = (9 , 9)$, we can observe something very interesting: For $(A , B) = (0 , 0)$: $$11 + 0.0 + 0.0 = 11$$ For $(A , B) = (9 , 9)$: $$11 + 0.9 + 0.9 = 12.8$$ In the set of all possible numbers that can result from adding $9.A$ and
$2.B$, both of which are significant to the ones digit, the minimum happens
to be $11$ and the maximum happens to be $12.8$ (the set becomes even greater
if we add more uncertain digits to the right of $A$ and $B$, and in that case
the maximum resulting value starts to approach $13$ as you add more and
more 9's to both $9$ and $2$). Lastly, we can see that tens digit is always $1$, and using my second definition of significant digits, we can claim that the tens digit is significant. On the other hand, because ones digit can either be $1$ or $2$, the ones digit is not significant. Thus, using my two definitions of significant figures, we can claim that the addition between $9$ and $2$ results in one significant figure (at the tens place), rather than two significant figures one would get from the usual rule of thumb. So my question is, are my definitions of significant digits correct? If yes, then I can say the general rules of thumb for adding numbers with significant figures is wrong and is being blindly taught and learned in high schools and universities. If not, then can you show me why not and if you have any credible sources.","['statistics', 'experimental-mathematics', 'arithmetic']"
2099740,"""In a party people shake hands with one another""",In a party people shake hands with one another (not necessarily everyone with everyone else). (a) Show that 2 people shake hands the same no. of times. (b) Show that the number of people who shake hands an odd no. of time is even. I find this question to be very tough and I can't find a way to even start answering this. It would be great if I could get a small hint in order for me to at least start it.,"['permutations', 'combinatorics', 'combinations']"
2099771,Continuity of a function (Real Analysis),"In Stochastic process, Bass claim (without proof) the function $f:\mathbb{R} \to \mathbb{R}$ defined by $f(x)=\int_{A} e^{\tfrac{-(y-x)^2}{2t}}dy$ is continuous, where $A$ is a Borel measurable set. He says use dominated convergence theorem, it is clear. But I get confused here. Because, HOW? I tried to use the definition of continuity ($\epsilon-\delta$ argument) to prove it, for instance, $|\int_{A} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$
$ \leq |\int_{A \cap [y \leq M]} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A \cap [y \leq M]} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$ +$|\int_{A \cap [y \geq M]} e^{\tfrac{-(y-x)^{2}}{2t}}dy-\int_{A \cap [y \geq M]} e^{\tfrac{-(y-x_{n})^{2}}{2t}}dy|$ The first term I think we can use the dominated convergent theorem, and the second one use the fact that the integrand is $L^{1}$-integrable, but I can't give a good $\epsilon-\delta$ argument, can someone help? Furthermore, if the $f$ becomes $f(x)=\int_{A} F(y)e^{\tfrac{-(y-x)^2}{2t}}dy$ where $F$ is bounded measurable, will it be continuous still? It is important since it might gives a sufficient condition for Strong Markov Process but the author never mention. Thanks!","['stochastic-processes', 'real-analysis', 'probability']"
2099787,Are homeomorphisms convex-preserving?,"If $A\subset \mathbb R^n$ is a convex subset and $A$ is homeomorphic to a subset $B\subset R^n$, can I also say $B$ is convex? Any counterexamples?","['general-topology', 'real-analysis', 'examples-counterexamples', 'convex-analysis']"
2099793,sum of series $(2^2-1)(6^2-1)+(4^2-1)(8^2-1)+\cdots \cdots +\cdots (100^2-1)(104^2-1)$,"The sum of series $(2^2-1)(6^2-1)+(4^2-1)(8^2-1)+\cdots \cdots +\cdots (100^2-1)(104^2-1)$ Attempt Assume $\displaystyle S = \sum^{50}_{r=1}((2r)^2-1)((2r+4)^2-1) = \sum^{50}_{r=1}(4r^2-1)(4r^2+16r+15)$ $\displaystyle S = \sum^{50}_{r=1}(16r^4+64r^3+56r^2-16r-15)$ could some help me how to solve it, thanks",['sequences-and-series']
2099800,Does $\int_{0}^{\infty}{\cos(10x^2\pi)\sin(6x^2\pi)\over \sinh^2(2x\pi)}\mathrm dx={1\over 16}?$,"How do we prove these two results? $$\int_{0}^{\infty}{\cos(10x^2\pi)\sin(6x^2\pi)\over \sinh^2(2x\pi)}\mathrm dx={1\over 16}\tag1$$ $$\int_{0}^{\infty}{\sin(10x^2\pi)\sin(6x^2\pi)\over \sinh^2(2x\pi)}\mathrm dx={1\over 8\pi}\tag2$$ Try an approach to split out the form $${\cos(10x^2\pi)\sin(6x^2\pi)\over \sinh^2(2x\pi)}\mathrm dx={1\over 4}{\sin(16x^2\pi)-\sin(4x^2\pi)\over 2\sinh(x\pi)\cosh(x\pi)}\tag3$$ $$={1\over 4}{\sin(16x^2\pi)-4\sin(x^2\pi)\cos(x^2\pi)+8\sin^3(x^2\pi)\cos(x^2\pi)\over 2\sinh(x\pi)\cosh(x\pi)}\tag4$$
 Or we could write $(1)$ as $$\int_{0}^{\infty}{({e^{i10x^2\pi}+e^{-i10x^2\pi}})({e^{i6x^2\pi}-e^{-i6x^2\pi}})\over4i \sinh^2(2x\pi)}\mathrm dx\tag5$$ $$\int_{0}^{\infty}{{e^{i16x^2\pi}-e^{-i16x^2\pi}}-({e^{i4x^2\pi}-e^{-i4x^2\pi}})\over4i \sinh^2(2x\pi)}\mathrm dx\tag6$$ $$\int_{0}^{\infty}{\sinh(i16x^2\pi)-\sinh(i4x^2\pi)\over2i \sinh^2(2x\pi)}\mathrm dx\tag7$$ Surely this is not the correct  approach here. I estimated the closed form using wolfram integrator, not sure it is correct.","['integration', 'definite-integrals', 'contour-integration', 'calculus']"
2099844,Characterization of some property for inverse functions,"Let's suppose there are two functions $f:A\longrightarrow B$ and
$g:B\longrightarrow B$, such that: $f(x)=f(g(f(x)))$ and $g(x)=g(f(g(x)))$. I know this should be a trivial question, but what does this mean exactly? Is it possible that this is equivalent to saying that $g$ is an inverse for $f$? Thanks for any kind of help!","['elementary-functions', 'functions']"
2099856,Prove that $6<3^\sqrt3$ implies $3^\sqrt3 < 7$,"Consider the double inequality : $$6<3^\sqrt3 < 7$$
  Using $only$ the elementary properties of exponents and inequalities ( NO calculator, computer,
  table of logarithms, or estimate of √3 may be used), prove that the first inequality implies the
  second. SOURCE : ""Inequalities proposed in Crux Mathematicorum"" (Page Number 14; Question Number 627) I have no idea how to solve this problem. I tried taking logarithms, but that did not help. I strongly suspect that some inequality has to be used. I tried AM-GM on a few set of terms, but that just made it messier. Wolfram Aplha gives the value of ${3^{\sqrt {3}}}$ as $\approx 6.7049918538258$. Can anyone give me a hint on how to solve this problem ?","['algebra-precalculus', 'contest-math', 'inequality']"
2099858,Every linearly independent set can be extended to a basis,Let $E$ be  linear space (infinite dimensional in general). We know by Zorn's lemma that there exists a basis. Now let $S \subset E$ be any linear independent subset. How to prove that it is contained in some basis of $E$? And moreover if $F \subset E$ is subspace then there are linear functional such that $f(F) = 0$ and linear complement to $F$ in $E$. I know how it can be done for finite dimensional spaces but I am always confused when infinite dimension and Zorn's lemma are involved.,"['functional-analysis', 'linear-algebra']"
2099958,Feller - Question on two throws of three dice,"I am stuck at the following question. What is the probability that two throws with three dice each will show the same configuration if (a) the dice are distinguishable (b) they are not. Solution. (a) $P(\text{Two throws of three dice s.t. each show the same configuration})=6^{3}/6^{6}=1/216$. (b)Firstly from the second set of throws, the $3$ dies with the same face value as the first ones can be chosen in $3!=6$ ways. Place $r=3$ dies in $n=6$ cells, such that order does not matter with repetition, can be done in ${{3+6-1}\choose{3}}={8\choose 3}=56$ ${\displaystyle P(\text{Two throws of three indistinguishable dice show the same configuration})=\frac{56\times6}{6^{6}}}$ However, my answer to the second part of the problem is incorrect. Could someone help me think correctly about the problem.","['combinatorics', 'probability']"
2099961,Integrate $\int _0^{\infty }\frac{\sqrt[3]{x}}{x^2+1\:}\:dx$,"So I want to compute $ I = \int _0^{\infty }\frac{\sqrt[3]{x}}{x^2+1\:}\:dx$. First thing I thought of is that integrals from $0$ to $\infty$ usually take a nicer form when we apply the change $x = e^t$, so I did that:
$$
I = \int _{-\infty }^{\infty }\frac{e^{\frac{4}{3}t}}{e^{2t}+1\:}\:dt
$$ Now, I've seen some other integrals with a form like this one. For the other ones, I computed the contour integral of a rectangle of vertex $[-R, R, R+xi, -R+xi]$, choosing $x$ such that the integrand takes opposite values in $[-R, R]$ and $[-R+xi, R+xi]$. If I could choose such an $x$, then I would have succeeded, since I can prove that the lateral integrals go to $0$ as $R\to \infty$, and thus the desired integrals would be equal to half the value of the residues enclosed by the rectangle. But that requires solving the following system:
$$
\begin{cases} 
e^{\frac{4}{3}t} = -e^{\frac{4}{3}(t+xi)} \\ 
e^{2t} = e^{2(t+xi)} 
\end{cases} \implies
\begin{cases} 
\frac{4}{3}xi+i\pi = 2ki\pi \\ 
2xi = 2ki\pi 
\end{cases} \implies
\begin{cases} 
x = \frac{3}{4}(2k+1)\pi \\
x = k\pi
\end{cases}
$$
For $k\in \mathbb{Z}$. But this system does not have a solution! The first equation forces $x$ to be $q\pi$ for some $q\not\in\mathbb{Z}$, contradicting the second equation. From here I am stuck. Can I get a hint? EDIT: I followed @DanielFischer suggestion to use a keyhole contour. Let $C$ be the keyhole contour formed by a big circle $\Gamma_R$ of radii $R$, a small circle $\gamma_\epsilon$ of radii $\epsilon$ and two segments connecting the two circles surrounding the positive axis, separated by a $\delta$ margin. Then we have thanks to the estimation lemma that:
$$
|\int_{\Gamma_R}|\le {\sup}_{z\in{\Gamma_R}}{\frac{\sqrt[3]{z}}{z^2+1\:}}\cdot long(\Gamma_R)\sim \frac{R^{1/3}}{R^2}\cdot 2\pi R \to 0
$$ On the other hand, when $\delta \to 0$:
$$
\int_R^\epsilon\frac{\sqrt[3]{z}}{z^2+1\:} = 
\int_R^\epsilon\frac{e^{\log{z}/3}}{z^2+1\:} = 
\int_R^\epsilon\frac{e^{\frac{\log{|z| + i\arg{z}}}{3}}}{z^2+1\:} = 
-e^{-2\pi i/3}\int_\epsilon^R\frac{e^{\frac{\log{|z| + i\arg{z}+2\pi i}}{3}}}{z^2+1\:} = 
-e^{-2\pi i/3}\int_\epsilon^R
$$ Thus in the limit:
$$
\int_C = \int_\Gamma + \int_\gamma + \int_\epsilon^R + \int_R^\epsilon =
\int_0^\infty -e^{-2\pi i/3}\int_0^\infty =\\
=(1 -e^{-2\pi i/3})\int_0^\infty =
2\pi i (Res(i)+Res(-i))
$$ The residues can be easily calculated as:
$$
Res(i) = \frac{\sqrt[3]{i}}{2i\:}\\
Res(-i) = \frac{\sqrt[3]{-i}}{-2i\:}
$$ Thus $\int_0^\infty = \frac{2\pi i (\frac{\sqrt[3]{i}}{2i\:}+\frac{\sqrt[3]{-i}}{-2i\:})}{(1-e^{-2\pi i/3})} = \frac{π}{2 \sqrt{3}} + \frac{i π}{2}$... which is not real as it should be. Along the way I've also assumed that $\int_{\gamma_\epsilon}\to 0$, which seems like the case but I cannot prove it. Therefore, I ask: How do I prove that $\int_{\gamma_\epsilon}\to 0$? Why is my result wrong? Turns out the minus sign on the exponent was wrong:
$$I = \frac{i \left(e^{\frac{i \pi }{3}}-e^{-\frac{2 i \pi }{3}}
\right) \pi }{1-e^{\frac{2
   i \pi }{3}}} = -2\pi / \sqrt{3}$$ This result is still wrong according to the almighty Wolfram Alpha, but at least it has a similar form! I'll keep debugging.","['complex-analysis', 'improper-integrals', 'contour-integration']"
2099967,A characterization of pure sheaf,"I have started reading the book ""The Geometry of moduli of sheaves"" by Huybrechts and Lehn.
This is a statement in this book at page no.3 the last line. ""$E$ is pure if and only if all associated points of $E$ have the same dimension.""
Definition for associated points of a sheaf is as follows: $Ass(E) = \{x \in X \vert m_x \in AssE_x \}$. Point has always dimension 0 ,So my question is, what does this mean by saying that associated points have same dimension? Does this mean that local rings $O_x$ has the same dimension for all $x$ associated point of $E$ ? Can anyone suggest me a good reference which supports me while studying this book?","['moduli-space', 'coherent-sheaves', 'sheaf-theory', 'algebraic-geometry']"
2100000,Finding a solution with minimal $\ell_2$ norm in linear regression with dependent variables,"I am trying to find a linear regression for the problem: $$\displaystyle\arg\min_w\|y-Xw\|^2 $$ By finding the optimum of the above equation, I get $$\displaystyle X^TXw=X^Ty $$ In the case where $X^TX$ is invertible (i.e. the variables are independent), I can get the unique solution $$\displaystyle w=(X^TX)^{-1}X^T $$ However, when the variables are dependent , there's more than one unique solution. Now, say  I want to find a solution with minimal $l_2$ norm. I can define the new problem as: $$\displaystyle\begin{align}\arg&\min_w\|w\| \\ &s.t. X^TXw=X^Ty
 \end{align}$$ How can I now use SVD decomposition ($X=U\Sigma V^T$) to solve the above optimization problem? Solving with lagrange method: I tried optimizing the equivalent $0.5\|w\|^2$, and got the following Lagrangian: $$ \mathcal{L}(w,\alpha)=0.5\|w\|^2+\alpha(X^Ty-X^TXw) $$ When the gradient w.r.t $w$ is equal to 0, I get: $$w = \alpha X^TX\\
X^Ty=X^TXw $$ But couldn't proceed from here","['linear-regression', 'optimization', 'svd', 'statistics', 'linear-algebra']"
2100060,$L^p$ convergence follows from $L^2$ convergence plus $L^p$ boundedness?,"Suppose $f_n$ is sequence of functions such that $f_n\rightarrow f$ in $L^2(\mathbb{R})$. Also suppose $\|f_n\|_p\leqslant C \|f\|_p$, where constant $C$ is independent of $n$. From this data, can we conclude that $f_n\rightarrow f$ in $L^p(\mathbb{R})$? Assume $1<p<\infty$.","['functional-analysis', 'measure-theory']"
2100062,Solving two Cubic Equation on their Roots.,"Let $x^{3}+ax+10=0$ and $x^{3}+bx^{2}+50=0$ have two roots in common. Let $P$ be the product of these common roots. Find the numerical value of $P^{3}$, not involving $a,b$. My attempts: Let roots of $x^{3}+ax+10=0$ be $\alpha,\beta,\gamma\implies$ 
\begin{align*}
&\alpha+\beta+\gamma =0 \\
&\alpha\beta+\alpha\gamma+\beta\gamma =a \\
&\alpha\beta\gamma = -10
\end{align*} and of $x^{3}+bx^{2}+50=0$ be $\alpha,\beta,\gamma'\implies$
\begin{align*}
&\alpha+\beta+\gamma' =-b \\
&\alpha\beta+\alpha\gamma'+\beta\gamma' =0 \\
&\alpha\beta\gamma' = -50
\end{align*} Few important equations: $\dfrac{\alpha\beta\gamma'}{\alpha\beta\gamma}=\dfrac{-50}{-10}=5$ $\implies \gamma'=5\gamma $ $\gamma-\gamma'=b \because$ Substracting first eq $(\alpha+\beta)(\gamma-\gamma')=a$ Substracting second eq. from above $\alpha+\beta=\dfrac{a}{b} \ \ \because(2),(3)$ squaring gives: $(\alpha+\beta)^{2}=\dfrac{a^{2}}{b^{2}}$ $\alpha\beta\gamma-\alpha\beta\gamma'=40\implies\alpha\beta(\gamma-\gamma')=40\implies\alpha\beta=\dfrac{40}{b}$ Also $(\alpha+\beta+\gamma')^{2} =b^{2}$ $\implies \alpha^2+\beta^2+\gamma'^2=b^2 \implies \alpha^2+\beta^2=b^2-\gamma'^2=b^2-\dfrac{25b^{2}}{16}=\dfrac{-9b^2}{16}\because (2),(1)$ Now, squaring first eq. of first set of eq.$\implies \alpha^2+\beta^2+\gamma^2+2a =0 \implies \alpha^2+\beta^2=\dfrac{-b^2}{16}-2a\because (2),(1)$ Equating this with previous equations, $\implies \alpha^2+\beta^2=\dfrac{-9b^2}{16}=\dfrac{-b^2}{16}-2a\implies a^2=\dfrac{b^4}{16}\rightarrow(7)$ Also, $\alpha^2 +\beta^2 +2\alpha\beta=\dfrac{a^2}{b^2} \because(4)$. And we calculated very thing in terms of $b$, putting all these,$\implies \dfrac{-9b^2}{16} +2\alpha\beta=\dfrac{b^4}{16b^2}\because(7)\implies \dfrac{80}{b}=\dfrac{10b^2}{16}\ \because (5)\implies b^3=128\rightarrow(6)$ Now, $(eq.5)^3\implies (\alpha\beta)^3=\dfrac{64000}{b^3}=\dfrac{64000}{128}=500=P^3\because(6)$ Is this correct, and if, then what are easiest/shortest method besides my GIANT method.","['algebra-precalculus', 'cubics', 'roots', 'polynomials']"
2100066,"Is $\mathbb{R}-\{-2,6\}$ a neighbourhood of $0$?","Is $\mathbb{R}\setminus\{-2,6\}$ a neighbourhood of $0$? When we consider the $\mathbb{R}$ with the Euclidean topology (i.e. the topology induced by the euclidean metric). I wrote that it is since: $0 \in \mathbb{R}\setminus\{-2,6\} \subseteq \mathbb{R}\setminus\{-2,6\}$ and $\mathbb{R}\setminus\{-2,6\}$ is an open set in $\mathbb{R}$ with the Euclidean topology (since it is an open set in $\mathbb{R}$ with the Euclidean metric. Is this correct???",['general-topology']
2100071,Is independence preserved under transformation?,"Is independence preserved under transformation? If not, assume linear/continuous? This problem comes from proving $X_n$ and $s_n^2$ are independent given iid sample from $N(\theta,\sigma^2)$ The argument goes $s_n^2$ is a function of $X_i-\bar{X}$ which is uncorrelated to $\bar{X}$ by Basu's theorem.","['statistics', 'probability']"
2100082,Lemma of Gronwall,"Let $T \in \mathbb R^+\cup \{\infty\}$, $t_o \in [0,T)$, $a,b \in L^\infty(t_0,T)$ and $\lambda \in L^1(T_0,t)$, $\lambda(t) \geq 0$ for almost all $t \in (t_o,T)$. From the inequality $$a(t) \leq b(t) + \int_{t_0}^t\lambda(s)a(s)ds \,\,\,\,\,$$ a.e. in $(t_o,T)$ it follows  $$a(t) \leq b(t) + \int_{t_0}^t e^{\phi(t)-\phi(s)}\lambda(s)b(s) \,ds$$ for almost all $t\in (t_0,T)$ where $\phi(s):=\int_{t_o}^s \lambda(\tau)\,d\tau$. Is there a counterexample for the case that $\lambda$ is negative? And what changes about the implication if $t<t_o$?","['real-analysis', 'integration', 'ordinary-differential-equations', 'inequality']"
2100087,How to evaluate $\lim _{x\to \infty }\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(1/x\right)}$?,"How to evaluate $\lim _{x\to \infty }\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(1/x\right)}$? My Try: $$\lim _{x\to \infty }\left(x^2\sin\left(\frac{1}{x}\right)\ln\left(\frac{x+3}{\sqrt{x^2-5x}}\right)\right) = \lim _{t\to 0 }\left(\frac{1}{t^2}\sin\left(t\right)\ln\left(\frac{\frac{1}{t}+3}{\sqrt{\frac{1}{t^2}-\frac{5}{t}}}\right)\right)$$
Now $\sin(x) \approx x, x \rightarrow 0$ so:
$$\approx \lim _{t\to 0 }\left(\frac{1}{t}ln\left(\frac{\left(3t+1\right)\sqrt{-5t+1}}{1-5t}\right)\right)$$ At this point i used the rule of the de l'Hôpital so:
$$\lim _{t\to 0 }\left(\frac{1}{t}ln\left(\frac{\left(3t+1\right)\sqrt{-5t+1}}{1-5t}\right)\right) = \lim _{t\to 0}\left(\frac{\frac{-15t+11}{2\left(-5t+1\right)\left(3t+1\right)}}{1}\right) = \frac{11}{2}$$
So:
$$\lim _{x\to \infty }\left(\left(\frac{x+3}{\sqrt{x^2-5x}}\right)^{x^2\sin\left(\frac{1}{x}\right)}\right) = \color{red}{e^\frac{11}{2}}$$
Which it is the exact result of the proposed limit. My question is, there is another method, different from mine to get the same result? (Preferably without resorting to de l'Hôpital rule).","['limits-without-lhopital', 'alternative-proof', 'calculus', 'limits']"
2100150,Linear map dense trajectory,"Is there a finite-dimensional $\mathbb{R}$-normed space $V$ with $x_0 \in V$ and linear map $T \colon V \to V$ such that $\{T^nx_0\}_{n=1}^{\infty}$ is dense in $V$? I got this question of Bollobas' Introductory Linear Analysis. My intuition leans towards no, but I can't come up with a convincing argument without assuming things. There is a hint given and it is to first prove the result over a $\mathbb{C}$-normed space.","['functional-analysis', 'dynamical-systems', 'linear-transformations']"
2100183,"The function $f$ and the composite function $fg$ are defined as $f:x→x+2$ , $fg:x→3x-2$. Find the function g.","The function $f$ and the composite function $fg$ are defined as $f:x\mapsto x+2$ , $fg:x\mapsto 3x-2$. Find the function $g$. I just started learning functions and need help with it. Please provide workings so that I understand better, thank you.",['functions']
2100206,Valid to move $x$ to other side of equation in differentials?,"Say you have $dy/dx = x$, is it valid to write $dy/x = dx$?","['derivatives', 'calculus']"
2100238,"For a 3 sets' tennis game, would you bet on it finishing in 2 sets or 3 sets, assuming each player has an equal probability of winning a set?","Obviously the various permutations are:
AA
BB
ABB
BAB
ABA
BAA. 
Nevertheless, I'm still confused because I can reason to myself both ways so any help would be much appreciated.","['permutations', 'statistics', 'probability']"
2100261,"Find all reals $x$,$y$ satisfying the following equation:","Find all positive reals $x,y \in \mathbb{R}^+$ satisfying:
  $$\frac{x^9}{y} + \frac{y^9}{x} = 10-\frac{8}{xy}$$ Since this involves higher exponents I am unable to tackle this problem. Please help me.","['algebra-precalculus', 'real-numbers']"
2100279,Sum of given infinite series: $\frac14+\frac2{4 \cdot 7}+\frac3{4 \cdot 7 \cdot 10}+\frac4{4 \cdot 7 \cdot 10 \cdot 13 }+....$,Find the sum of infinite series $$\frac{1}{4}+\frac{2}{4 \cdot 7}+\frac{3}{4 \cdot 7 \cdot 10}+\frac{4}{4 \cdot 7 \cdot 10 \cdot 13 }+....$$ Generally I do these questions by finding sum of $n$ terms and then putting $ \lim{n \to \infty}$ but here I am not able to find sum of $n$ terms. Could some suggest as how to proceed?,['sequences-and-series']
2100295,How many three digit numbers have all three digits that are different?,How do I solve this? Please explain in detail. I am told the answer is $9\times9\times8$ but I do not understand how that would lead to the solution.,['algebra-precalculus']
2100299,How do telescopic series work in general and in this specific problem?,"$$\sum_{n=1}^\infty\frac{1}{n(n+3)(n+6)}$$
I did the partial fraction decomposition and also plugged in the values.
 I can't understand how the eleminating thing works, for example in cases like this where you don't know what to cancel what am I supposed to do? I'm going to write it in simple math. From the partial fraction decomposition I've got:
S=1/18(1/n -2/(n+3) +1/(n+6)) Then Ive let the limit of the sum go to infinity or how does that go. 1- 1/2 +1/7 $$
     1/2- 2/5 +1/8$$
             1/3-1/3+1/9$$
         .$$
             .$$
         .$$
            1/n-2/(n+3)+1/(n+6)
So I cant find a pattern to cancel some of them and I dont know how that could go.","['telescopic-series', 'sequences-and-series']"
2100321,"Show that $f(x + 1/n) = f(x)$ for some $x$, given $f(0) = f(1)$ [duplicate]","This question already has an answer here : Show that there is $\xi$ s.t. $f(\xi)=f\left(\xi+\frac{1}{n}\right)$ (1 answer) Closed 7 years ago . Let $f: [0,1] \to \mathbb{R}$ be continuous and such that $f(0) = f(1)$. For each $n \in \mathbb{N}$, prove that there exists $x \in [0,1]$ such that $x + 1/n \in [0,1]$ and $f(x + 1/n) = f(x)$. Don't even know where to start.","['real-analysis', 'calculus', 'functions']"
2100434,$\forall x\in\mathbb{R}\setminus\mathbb{Q}:f'(x)=0$. Does it follow that f is constant?,Function $f:\mathbb{R}\rightarrow\mathbb{R}$ is continuous and $\forall x\in\mathbb{R}\setminus\mathbb{Q}:f'(x)=0$. Does it follow that f is constant?,"['derivatives', 'real-analysis', 'functions']"
2100491,Formula for product of polynomial functions,"Let $f:\mathbb Q \rightarrow \mathbb Q$ be a function such that $f(x)=\displaystyle \sum_{i=0}^n a_ix^i$ with $a_i$ being elements of a subset of rational numbers indexed by non-negative integers from interval $[0;n]$. Let $g:\mathbb Q \rightarrow \mathbb Q$ be defined as $g(x)=\displaystyle \sum_{i=0}^m b_ix^i$ with $b_i$ defined analogically to $a_i$, as a subset of $\mathbb Q$ indexed by an interval of natural numbers $[0;m]$. We know that $f(x)g(x)= \big (\displaystyle \sum_{i=0}^n a_ix^i \big ) \big ( \displaystyle \sum_{i=0}^mb_ix^i \big )$. How to prove that $\big (\displaystyle \sum_{i=0}^n a_ix^i \big ) \big ( \displaystyle \sum_{i=0}^mb_ix^i \big )=\displaystyle \sum_{i=0}^{n+m} \big ( \displaystyle \sum_{i=0}^{n+m} a_ib_{n-i} \big)x^i$ - in other words, to achieve the standard formula for polynomial product?","['abstract-algebra', 'polynomials', 'functions', 'rational-numbers']"
2100500,Pair of numbers using pigeon hole principle,"n ∈ N, A ⊆ {1, . . . , 2n}, |A| = n + 1. Show that: a) In A there is a pair of numbers whose sum is equal to 2n + 1. b) In A there is a pair of relatively prime numbers. c) In A there is a pair of numbers, such that one is a multiple of the other. For the first part, I started by making pairs of numbers whose sum equals 2n + 1, which is literally the first number and the last one in the set A, 
{2n + 1, 2n - 1 + 2, 2n - 2 + 3 ...}
I'm not sure how to prove that there exists this pair, when it clearly does. I'm not sure how to go about part b) and c) any hint would be much appreciated.","['pigeonhole-principle', 'elementary-set-theory']"
2100546,Arrangements of balls from a bag,"A bag contains $2$ red, $2$ green, $2$ black, $3$ white, $1$ yellow, $1$ brown and $1$ orange ball. In how many ways the balls be arranged in a row by taking all of them together if balls of same color cannot be placed adjacent? I am aware that $\dfrac{12!}{2!\times 2! \times 2! \times 3!}$ arrangements are possible. But these arrangements contain balls of same colors placed adjacent also. How to solve this problem?","['permutations', 'combinatorics', 'combinations']"
2100567,"Real Analysis Methodologies to show $\gamma =2\int_0^\infty \frac{\cos(x^2)-\cos(x)}{x}\,dx$","In THIS ANSWER , I used straightforward complex analysis to show that $$\gamma =2\int_0^\infty \frac{\cos(x^2)-\cos(x)}{x}\,dx \tag 1$$ where $\gamma =-\int_0^\infty \log(x) e^{-x}\,dx$ is the Euler-Mascheroni Constant . The key in the derivation of $(1)$ was to transform the cosine terms into real exponential ones. To date, I have been unable to use strictly real analysis, without appealing to tabulated results of special functions (e.g., use of the $\text{Cin}(x)$ and $\text{Ci}(x)$ functions), to prove $(1)$. I have tried introducing a parameter and using ""Feynman's Trick to augment the integral into something manageable.  Or somewhat equivalently, rewriting the integral in $(1)$ as a double integral and proceeding by exploiting Fubini-Tonelli. QUESTION:  What are ways to prove $(1)$ without relying on complex analysis and without simply appealing to tabulated relationships of special functions.  For example, stating that the $Ci(x)$ function is defined as $\text{Ci}(x)\equiv -\int_x^\infty\frac{\cos(t)}{t}\,dt=\gamma +\log(x) +\int_0^x \frac{\cos(t)-1}{t}\,dt$ is unsatisfactory unless one proves the latter equality.","['real-analysis', 'euler-mascheroni-constant', 'improper-integrals', 'integration', 'definite-integrals']"
2100584,Cauchy-Schwarz inequality and homogeneous Sobolev space,"Let $f\in \dot{H}^s$ with $s\in (0,1)$ and $g\in \dot{H}^{-s}$, where $\dot{H}^s$ denote the fractional homogeneous Sobolev space $\dot{W}^{p,s}$with $p=2$. Does one have the following Cauchy-Schwarz type inequality?
$$
(f,g)_{L^2}\leq \| f \|_{\dot{H}^s} \| g \|_{\dot{H}^{-s}},
$$
where $(.,.)_{L^2}$ is the $L^2$-inner product and on the right are the seminorms corresponding to the homogeneous spaces (given by the Gagliardo seminorms). I have seen an inequality of this type for fractional Sobolev spaces but without any proof. Does one have a reference (also for the case above)? Thanks for your help!","['functional-analysis', 'inequality', 'sobolev-spaces']"
2100602,Auto Path in Dokapon Kingdom - how do they do it?,"In the video game Dokapon Kingdom ( here's an example video on it ), the objective is to go around saving towns while simultaneously screwing over your friends (who will no longer be your friends). (It's been described as "" Mario Party meets an RPG"".) Prominently featured within that game is the Auto Path function, which determines what spaces are reachable from the current space using a path of length $n$, namely, what the player rolled. Said path can loop multiple times, and can even end up turning around on itself, but it cannot traverse the same edge twice in a row (i.e. no sudden U-turns). Translating the game board to a graph (and its associated adjacency matrix) is very easy, but how does one enforce the no sudden U-turns rule? Using the squared matrix with its diagonal zeroed out doesn't work, as that still allows a U-turn after every other edge taken.","['matrices', 'graph-theory']"
2100637,Find $\lim \limits_{x\to 0}{\sin{42x} \over \sin{6x}-\sin{7x}}$,"I want to find
$$\lim \limits_{x\to 0}{\sin{42x} \over \sin{6x}-\sin{7x}}$$
without resorting to L'Hôpital's rule. Numerically, this computes as $-42$. My idea is to examine two cases: $x>0$ and $x<0$ and use ${\sin{42x} \over \sin{6x}}\to 7$ and ${\sin{42x} \over \sin{7x}}\to 6$. I can't find the appropriate inequalities to use the squeeze theorem, though. Do you have suggestions?","['real-analysis', 'limits-without-lhopital', 'limits']"
2100641,"Proof that $\frac{a}{a+3b+3c}+\frac{b}{b+3a+3c}+\frac{c}{c+3a+3b} \ge \frac{3}{7}$ for all $a,b,c > 0$","So I am trtying to proof that $\frac{a}{a+3b+3c}+\frac{b}{b+3a+3c}+\frac{c}{c+3a+3b} \ge \frac{3}{7}$ for all  $a,b,c > 0$. First I tried with Cauchy–Schwarz inequality but got nowhere. Now I am trying to find a convex function, so I can use jensen's inequality, but I can't come up with one which works.. Has anyone an idea?","['inequality', 'tangent-line-method', 'sum-of-squares-method', 'lagrange-multiplier', 'analysis']"
