question_id,title,body,tags
615930,"If the sum $\frac{1}{7} + \frac{1\cdot 3}{7\cdot 9} + \frac{1\cdot 3\cdot 5}{7\cdot 9\cdot 11} + ...$ to 20 terms is $\frac{m}{n}$, then $n-4m$?","If the sum $\frac{1}{7} + \frac{1\cdot 3}{7\cdot 9} + \frac{1\cdot 3\cdot 5}{7\cdot 9\cdot 11} + ...$ to 20 terms is $\frac{m}{n}$, reduced fraction, then what is $n-4m$? This is a question I dug up from an old JEE Main paper (India). It's very intriguing to me because, although it looks simple, I can't seem to find he sum in this question. The numerator of the nth term of the series seems to be the product of the first n terms of odd numbers.
The denominator is similarly made but the sequence starts from 7.
I have no idea how to find the sum to n terms in this situation. If it were the sum of odd numbers and not the product, I could have done it easily. Please explain to me how you find the product of n terms of a sequence and also the sum to n terms of the given sequence. I have never been introduced to the product of n terms before, If you could give me a proper intuition for it, it would really make my christmas.","['sequences-and-series', 'discrete-mathematics']"
615948,Does every normal number have irrationality measure $2$?,"A normal number is a number whose digit expansion in any base is ""uniform"" in the sense that all finite digit strings occur with the ""statistically expected"" frequency. I read a sentence somewhere which could be understood as implying that every normal number had irrationality measure $2$. Is it known if all normal numbers have irrationality measure (approximation exponent) $2$? Also, are there some non-normal irrational numbers whose irrationality measures are known? Also, are there some non-normal numbers with irrationality measure $2$ known?","['diophantine-approximation', 'normal-number', 'number-theory']"
615990,Uniform Convergence/continuity,"Let $A$ be a compact set of $\mathbb{R}^n$ and $f$ continuous on $A$. Let $F=f_A$, and let $I_0$ be a cube containing $A$. Divide $I_0$ in $2^n$ equal subcubes $I_{1_1},\dots, I_{1_{2^n}}$.On $I_0$ we define $F_0=max f_A$.  We define $A_{k_i}=A\cap cl(I_{k_i})$ and $F_{1} (\mathbf{x})=
\begin{cases}
max f_{A_{1_i}}(x), & \text{if }x\in I_{1_i}\text{ and } A_{1_i}\text{ not empty}\\
0, & \text{ otherwise}
\end{cases}$. Now, we repeat the same division of subcubes in subsubcubes, and so on, and define, for each new division,
$F_{k} (\mathbf{x})=
\begin{cases}
max f_{A_{k_i}}(x), & \text{if }x\in I_{k_i}\text{ and } A_{k_i}\text{ not empty}\\
0, & \text{ otherwise}
\end{cases}$. The exercise asks us to prove that $F_k$ converges uniformly to $f_A$ if and only if $f(\mathbf{x})=\mathbf{0} \ \ \forall \mathbf{x}\in fr(A)$ Exercise 10, section 5.5, Wendell Fleming's Functions of Several Variables. My first doubt is: Shouldn't the $F_k$ be defined in terms of $ cl(I_{k_i})$ instead of just $I_{k_i}$?Because for a given point in $A$, there will be a certain order where that point will belong to $fr(I_{k_i})$, where $F_k(\mathbf{x})=0 $ My second doubt is how do I solve this? I have no clue as to how to tackle this. 
A hint would be just fine. Thanks.",['multivariable-calculus']
615995,Definitions of Sierpinski Carpet and Higher Dimensional Analogues,"We define the Cantor Set as: $Let \mathscr{J} := \{ 0, 2, \ldots , 3^{m-1} -1 \}$ for $m \in \mathbb{N}$, then 
$$C = [0,1] \setminus \bigcup_{m \in \mathbb{N}} \bigcup_{k \in \mathscr{J}} \Big( \frac{3k+1}{3^{m}} , \frac{3k +2}{3^m} \Big)$$ is it proper to define the sierpinski carpet and menger sponge, and their higher dimensional analogues as $C \times C$, $C \times C \times C$, and $\prod_{i \in \mathbb{N}} C_i$ respectively? I cannot seem to find an explicit formula for higher dimensionl analogues on the internet. Additionally, I'd like to know what it would mean to discuss the cantor set iterated a hyperreal number of times. i.e. 
$Let \mathscr{J} := \{ 0, 2, \ldots , 3^{m-1} -1 \}$ for $m \in \mathbb{N}^{*}$, then 
$$C = [0,1] \setminus \bigcup_{m \in \mathbb{N}^{*}} \bigcup_{k \in \mathscr{J}} \Big( \frac{3k+1}{3^{m}} , \frac{3k +2}{3^m} \Big)$$ Any feedback will be greatly appreciated, especially on the second portion of the question.","['measure-theory', 'fractals']"
616007,Why do p-values include the probability of obtaining more extreme values than the test statistic?,"p -value is defined as ""the probability of obtaining a test statistic at least as extreme as the one that was actually observed, assuming that the null hypothesis is true"" . Why are all values more favourable to the alternative hypothesis than the one observed are considered when finding the p -value. Is there some intuitive explanation for this? (From a practical viewpoint, I do realize that in the case of a continuous random variable that the probability of getting some exact value is 0, and so it's impossible to consider the probability associated with the exact value of the test statistic.) The only attempt to answer this question I found was this PDF which equates p-values to Type I error rates. However, the Wikipedia p-value page also states that ""The p-value should not be confused with the Type I error rate [false positive rate] α in the Neyman–Pearson approach."" so I'm not sure how useful of an explanation that is.",['statistics']
616014,$n^{th}$ derivative of a tetration function,"I stumbled upon this very peculiar function last summer, namely: $f(x)=x^{x^{x^{...^{x}}}}$, where there is a number $n$ of $x$'s in the exponent, I tried to find the derivative for the function and I was successful, it turned out not to be the most elegant formula but it worked. (Firstly, I invented a new notation, namely, a function such as $f(x)$ we can write it as the following: $f(x) =x^{\langle x \vert n\rangle}$ where $x$ is the exponent that is getting ""powered"" up $n$ times.) The formula I obtained by pattern matching was: $$f^{\prime}(x)=x^{\langle x \vert n\rangle +\langle x \vert n-1\rangle -1}\left[1+\prod_{i=0}^{n-2}x^{\langle x \vert i\rangle}\cdot \ln(x)^n+\sum_{j=1}^{n-1}\prod_{k=n-1-j}^{n-2}x^{\langle x \vert k\rangle}\cdot \ln(x)^j\right]\tag{$n\geqslant 2$}.$$ I know this looks like a mad mess and I am aware that people like this have done it more elegantely, but now for the question. This is only the first derivative of the function, is there a way, or rather is there a general derivative i.e a $n^{th}$ derivative of this function? Update: December 23th I have tried to approach the problem myself since I asked the question and I have not gotten to a stage to say if it is impossible or possible to do, however I think I am on the right track. At first, I thought of distributing the factor $x^{\langle x \vert n \rangle +\langle x \vert n-1 \rangle -1}$ to all the terms in the parentheses, but I quickly realized I had to deal with at least derivatives of triple products. Now I have come to realize that the easiest way is to differentiate the function just as it is and get a normal product and thus I must use the following formula: $$(f \cdot g)^{(n)}=\sum_{k=0}^{n}{n\choose k}f^{(k)}\cdot g^{(n-k)}$$ where $f =x^{\langle x \vert n \rangle +\langle x \vert n-1 \rangle -1}$ and $g=1+\prod_{i=0}^{n-2}x^{\langle x \vert i\rangle}\cdot \ln(x)^n+\sum_{j=1}^{n-1}\prod_{k=n-1-j}^{n-2}x^{\langle x \vert k\rangle}\cdot \ln(x)^j$. Since $k$ and $n-k$ are arbitrary numbers this leads us to find the general derivative for $f$ and $g$, this is where I am right now. (I do realize that I am trying to find the $n^{th}$ derivative of the first derivative but that is easily fixed later). Please come with suggestions on how to tackle this problem. Update: December 24th I have made progress with the help of Maple 17, namely, I have found a repeating pattern in at least a part of the general derivative, but there is still a part of it I cannot yet explain. Nonetheless, I present to you the part of the general derivative I have found: $$D_x^{\xi}f(x) = x^{\langle x \vert n\rangle +\langle x \vert n-1\rangle -\xi} \Big[(-1)^{\xi}\cdot\xi! +O(x)\Big]$$ I renamed the degree of the derivative as $\xi$ since $n$ is taken for the number of $x$s. The $O(x)$ is the (perhaps) series which I am currently working on finding, I do think I am on the right track though. The approach above with the product rule turned out to be less successful.","['calculus', 'derivatives', 'tetration']"
616025,Joukowski Aerofoil Plot,"I've just had a go at plotting flow around aerofoils and I've come across a problem where I can't spot where I've gone wrong. I've previously worked out that the complex potential flow around a disk with added circulation (to satisfy the stagnation point being on the trailing edge) is given by $$\Omega (z)=U\left(ze^{-i\phi}+\frac{e^{i\phi}}{z}\right)+2iUsin\phi ln(z).$$ To transform the disk into an aerofoil shape, I (think!) I need to apply the Joukowski Mapping to an off-centred disk. I can then find the inverse of this map and substitute this into the previously known flow around a disk and plot the streamlines. Now to do this, I thought to first apply an affine transformation to map the disk to an off-centred disk that passes through the point $\zeta=1$ and encloses $\zeta=-1$ (the two critical points of the Joukowski transform), and then apply the Joukowski map, work out the inverse and substitute into the known flow. So here goes: first I apply the transformation $$w=\alpha z +\beta,$$ such that $\alpha = |1-\beta|$. This maps the disk $|z|\leq 1$ to a disk centred $\beta$, radius $\alpha$. Then applying the Joukowski map $$\zeta=\frac{1}{2}\left(w+\frac{1}{w}\right)=\frac{1}{2}\left(\alpha z +\beta+\frac{1}{\alpha z +\beta}\right),$$ and solving for z, $$z=\frac{\zeta-\beta+\zeta\sqrt{(1-\frac{1}{\zeta^2})}}{\alpha} .$$ Substituting this into the known flow and plotting the imaginary part, if I simply shift the disk along the real axis, I get roughly what I expect (the green line being the dividing streamline): But if I shift the disk upwards, whilst I get the right sort of shape, it's clearly not correct: If anyone could give me a push as to where I've gone wrong it would be appreciated. I can't spot it in the code or the workings at all. Thanks!","['fluid-dynamics', 'complex-analysis']"
616027,How long does a sequence need to be to be guaranteed to have a monotonic subsequence length k?,"The sequence 7, 2, 4, 1, 4, 8 has an increasing subsequence length four (2, 4, 4, 8) and a decreasing subsequence length three (7, 4, 1). It has other monotonic (increasing or decreasing) subsequences too, but none longer than four. How long does a sequence need to be to be guaranteed to have a monotonic subsequence length k?","['ramsey-theory', 'order-theory', 'sequences-and-series', 'combinatorics']"
616033,"Upon multiplying $\cos(20^\circ)\cos(40^\circ)\cos(80^\circ)$ by the sine of a certain angle, it gets reduced. What is that angle?","So if $P = \cos(20^\circ)\cos(40^\circ)\cos(80^\circ)$, I can multiply $P$ by $\sin(X)$ so that the entire expression reduces to something manageable. I then take the simplified product and divide it by $\sin(X)$ and should get the numerical value of $\cos(20^\circ)\cos(40^\circ)\cos(80^\circ)$. However, I can't figure out what angle to use. I know it probably has something to do with the double angle forumlae and proably something to do with the product sum formulae. I tried to reduce $\cos(20^\circ)\cos(40^\circ)\cos(80^\circ)$ to see if I got an answer but no luck. I've looked on the Internet and the answer is there but it's unclear how people figured out which sine angle to multiply it by so if you do provide an answer, it'd be really great if you could mention why you picked the angle you picked. Thanks.",['trigonometry']
616038,Is there an uncountable proper sub-field of $\mathbf{R}$?,Is there an uncountable proper subfield of $\mathbf{R}$?,"['abstract-algebra', 'field-theory']"
616040,Which functions satisfy $ g(x) d^n f(x)/dx^n = x^n/n!$ for all positive $n$?,"Are there any $f(x)$ and $g(x)$ real functions which satisfy $$ g(x) \frac{d^n}{dx^n} f(x)= \frac{x^n}{n!}$$ for all positive $n$? EDIT:
More generally, are there functions which satisfy $$ h(x)\left(g(x) \frac{d}{dx}\right)^n f(x)= \frac{x^n}{n!}$$ for all positive $n$? 
Here $$\left(g(x) \frac{d}{dx}\right)^n = g(x)\frac{d}{dx} \left\{ g(x) \frac{d}{dx} \left[g(x)\frac{d}{dx} \left( \dots f(x)\right)\right]\right\}$$","['differential', 'ordinary-differential-equations', 'calculus']"
616061,Non-trivial nilpotent group has non-trivial center,"A book I'm reading quotes the following result without any explanation: Any non-trivial nilpotent group has a non-trivial center. (The definition of ""nilpotent group"" is as follows: Suppose $G$ is a group, define $G^{(1)}=[G,G]$ to the commutator subgroup, and recurrsively define $G^{(m)}=[G^{(m-1)},G^{(m-1)}]$. A group $G$ is said to be nilpotent if $G^{(m)}=0$ for sufficiently large $m$.) The group in the claim does not have to be finite. I have thought about this claim for a while and it doesn't seem easy. Could you please help me? Thank you very much! [Edit] As pointed out by DonAntonio, the definition of ""nilpotent group"" given here is not correct. The correct definition is that if we define $\gamma^n=[\gamma^{n-1},G]$ then $G$ is nilpotent if and only if $\gamma^n=0$ for sufficiently large $n$. Now the conclusion follows easily. Thank you for your help!","['group-theory', 'abstract-algebra']"
616065,Mixed Distribution Problem,"You design an insurance policy that pays a random amount Payment $= 1000 \cdot A$, where $A$ denotes the age at death. $A$ is assumed to have a continuous uniform distribution on $[50,110]$ (that is, a constant density function). Modify this policy to pay an amount Modified payment = $\begin{cases} 1000 \cdot A\; \text{if} \;A<90\\ 100,000 \;\text{if}\; A \geq 90 \end{cases}$ a) Find $E[X]$ and $\sigma$ of the original payment. b) Find $E[X]$ and $\sigma$ of the modified payment. I know the for the original payment the function jumps from 0-50 (like the step function) but I don't know how to compute $E[X]$ because my thinking for the 1st one was to just do $\dfrac{50}{110}(1000)\cdot 25.5 + \dfrac{60}{110}\cdot 1000 \displaystyle\int_{50}^{110} x$ which will give me my $E[X]$ for part a but that didn't work. So need some help understanding these sorts of problems.","['statistics', 'probability']"
616072,Sequential sums $1+2+\cdots+N$ that are squares [duplicate],"This question already has answers here : General formula to obtain triangular-square numbers (5 answers) Closed 10 years ago . While playing with sums $S_n = 1+\cdots+n$ of integers,
I have just come across  some ""mathematical magic""
I have no explanation and no proof for. Maybe you can give me some comments on this: I had the computer calculating which Sn are squares,
and it came up with the following list: Table row $N$        sum($1+\cdots+N$)   M (square root of sum) r=1     N=1     sum=1       M=1 r=2 N=8         sum=36      M=6 r=3 N=49        sum=1225        M=35 r=4 N=288       sum=41616       M=204 r=5 N=1681  sum=1413721     M=1189 r=6     N=9800  sum=48024900    M=6930 Of course we have $1+\cdots+N = \frac{N(N+1)}{2}$,
but this gives no indication for which N the sum $1+\cdots+N$  is a square. Can you guess how in this table we can calculate the entries in row 2 from the entries in row 1?
Or the entries in row 3 from the entries in row 2? 
Or the entries in row 4 from the entries in row 3? 
Or the entries in row 5 from the entries in row 4? I looked at the above table and made some strange observations: The value of the next M can be easily calculated from the previous entries:
 Take the M from the previous row, multiply by 6 and subtract the M from two rows higher up.
         $M(r) = 6*M(r-1)–M(r-2)$
 How is this possible? The S(r)  we  calculate as $S(r) = M(r)^2$. Note that we do not know whether this newly constructed
 number $S_r$ is in fact of the type $1+\cdots+k$ for some $k$. The value of  the next N can be calculated as 
          N(r) = Floor($M(r)*\sqrt 2$), 
where Floor means “rounding down  to the next lower integer“.
Somewhat surprising, $S(r)$ is the sum $1+\cdots+N(r)$  ! It looks as if outside the entries in the above table there are no other cases.
With other words, the method  $M(r) = 6*M(r-1)–M(r-2)$
seems to generate ALL solutions n where the sum $1+\cdots+n$ is a square. Problems: Is there a proof for any of the three observations? 
Do observations 1 and 2 really work for the infinite number of rows in this table?
Is there an infinite number of rows in the first place? Puzzled, 
Karl","['summation', 'algebra-precalculus', 'diophantine-equations']"
616093,Why every prime (>3) is represented as $6k\pm1$,"Why is every prime (>3) representable as $6k\pm1$? Afterall, by putting values of k, we don't just get primes but also composites. Then why not $2k+1$ or $3k+2$ or $4k+1$ etc. Is it because of probability? Is there a proof for it?",['number-theory']
616103,Asymptotics of probability of Newton-Pepys problem,"In Newton-Pepys problem one is interested in probability $p_n$ of getting at least $n$ sixes in $6 n$ independent throws of regular 6-sided die. The number of sixes $S_m$ obtained in $m$ throws follows a Binomial distribution $\operatorname{Bin}(m,p)$, where $p=\frac{1}{6}$ is the probability of getting a six in a single throw. Thus
$$
     p_n = \Pr\left(S_{6n} \geqslant n\right)
$$
Notice that $\mathsf{E}(S_{6n}) = 6 n p = n$, and variance $\mathbb{Var}(S_{6n}) = \sqrt{5 n/6}$, hence in the large $n$ limit
$$
    \lim_{n \to \infty} p_n = \lim_{n \to \infty} \Pr\left(\frac{S_{6n}-n}{\sqrt{5 n/6} }\geqslant 0\right) \stackrel{\text{CLT}}{=} \Pr(Z \geqslant 0) = \frac{1}{2}
$$
In fact $p_n$ is monotonically decreasing sequence: Q. : How can one find the large $n$ asymptotics of $p_n$?","['dice', 'probability']"
616106,When is the moment of inertia of a smooth plane curve is maximum?,"Given a smooth plane curve $(x(s),y(s))$, parameterized in arc length $s$, of fixed finite length $L$, its moment of inertia about its center of mass (axis perpendicular to the plane) is given as $$MI = \int_0^L ((x(s)-x_{cm})^2 + (y(s)-y_{cm})^2)  ds$$. What I predict from earlier discussions, and almost convinced is that if we fix length $L$, $MI$ is maximum when the curve is a straight line. I lack the faculty of mathematical machinery (I guess calculus of variations) to prove it, hence is my gentle request to help me out in proving it and thoroughly understanding the situation and all the corollaries and nuances. This not just the result I need, but I want to do more with it and hence would like understand all the things that are making this result and even more general ones (only to plane curves though).","['calculus-of-variations', 'plane-curves', 'calculus', 'real-analysis']"
616128,automorphisms of a finite field,"Let $F$ be a finite field of characteristic $p$ over $\mathbb{Z}_p$ with $p^r$ elements. Then I have proved that the map $\phi: x\mapsto x^p$ is a field automorphism of $F$. Moreover, $\phi(x)=x$ if and only if $x\in \mathbb{Z}_p$. I am confused on: (1). Is every field automorphism of $F$ fixing $\mathbb{Z}_p$ can be written in this form? I do not know how to prove: (2). $\phi$ is an invertible linear map on the $\mathbb{Z}_p$-vector space $F$ and determine the minimal polynomial of $\phi$ over $\mathbb{Z}_p$. (3). Let $K$ be a  finite field of characteristic $p$ over $\mathbb{Z}_p$ with $p^t$ elements. Then $K$ is a subfield of $F$ if and only if $t\mid r$. (4). If $t\mid r$, then $\phi^t: x\mapsto x^{p^t}$ is a field automorphism of $F$ such that $\phi^t(x)=x$ if and only if $x\in K$. Moreover, how about the minimal polynomial of $\phi^t$ over $K$?","['finite-fields', 'finite-groups', 'galois-theory', 'group-theory', 'field-theory']"
616144,Constructing a Function to Decrease a Quiz Score with Time,"I wasn't sure which stack exchange site to pose this question to, so I'm asking it here, I hope it's appropriate. I thought it might be because it has to do with math. This game I'm writing for fun is basically a mental math speed quiz game. I'm writing it in javascript and html. What I want to happen is for there to be a score depending on how fast you finished the quiz and how many you got correct. For an incorrect answer, you get 0 points. But for a correct answer, if you took 5 seconds to solve that question, you get more points than if someone took 8 seconds to answer the question. This seems trivial but I was thinking about it and I don't really have a good algorithm or equation for judging a performance based on time. For example: someone answering a question correctly in 5 seconds gets 20 points, someone answering correctly in 10 seconds gets 14 points (not exact figures, just example) Does someone have an idea of this? Thanks","['algebra-precalculus', 'functions']"
616152,Show that $M[x]$ is a Noetherian $A[x]$-module.,"This is a question from Atiyah and Macdonald, Introduction to Commutative Algebra . Problem: Let $M$ be a Noetherian $A$-module. Show that $M[x]$ is a Noetherian $A[x]$-module. Solution: So, I can solve the problem with an extra assumption. That is, if we assume that $M$ is faithful (i.e., $Ann(M)=0$). In this case, it follows that $A$ is necessarily Noetherian as well. Hence, by Hilbert's Basis Theorem, it follows that $A[x]$ is Noetherian as well. It can easily be shown that $M[x]\cong A[x]\bigotimes_A M.$ I can also show that the tensor product of two Noetherian modules is Noetherian, hence the result. I am wondering though, does this result hold without this extra assumption? I guess, I'm not also sure whether the ring $A$ is always necessarily Noetherian if we do not require that our module $M$ be faithful? All I can show is that if $M$ is Noetherian as an $A$-module then $A/Ann(M)$ is necessarily Noetherian as a ring. Thanks!!","['commutative-algebra', 'abstract-algebra']"
616168,The significance of Topologically Equivalence (To A Donut)?,"A friend of mine explained how a coffee mug is topologically equivalent to a donut to me tonight. I have to say the idea is very interesting! However, I don't know topology a lot but I am wondering about the significance of such equivalence. Not to mention that my friend failed to give a satisfying answer. So my question really is: Why is topologically equivalence important? How can such a equivalence help us? Under what circumstances? What problem are we trying to solve? I'd apologize if this is not quite a good question to ask. But I'd appreciate if someone who knows topology well can share some insight in this! Thanks ahead!",['general-topology']
616184,Ways of making polite numbers?,"Given that $n$ is a polite number , meaning that it can be expressed as the sum of two or more consecutive positive integers, how many different ways are there to express $n$ as the sum of at least two consecutive positive integers? Can you prove that the method you describe works?",['number-theory']
616203,Are there infinite many $n\in\mathbb N$ such that $\pi(n)=\sum_{p\leq\sqrt n}p$?,"Are there infinite many $n\in\mathbb N$ such that $$\pi(n)=\sum_{p\leq\sqrt n}p,\tag{1}$$
  where $\pi(n)$ is the Prime-counting_function ? For example, $n=1,4,11,12,29,30,59,60,179,180,389,390,391,392,\dots$ As I know, $\pi(x)\sim \dfrac{x}{\ln x},\sum_{p\leq x}p\sim \dfrac{x^2}{2\ln x}$, hence  $\pi(x)\sim \sum_{p\leq \sqrt x}p$. It seems that 1) it's very often that $\pi(n)>\sum_{p\leq\sqrt n}p$, 2) there are infinite many primes $q$ such that $q>\pi(q^2)-\sum_{p<q}p.$ If we can prove 1) and 2) then we get (1), but I can't prove even one of them. Thanks in advance! Edit: Use the formula given by Balarka Sen, I get 
$$\pi(x)\sim \sum_{p\leq\sqrt x}p = \frac{x}{\ln x}(1+\frac{1+o(1)}{\ln x}),$$ but it's not enough to solve our problem. Edit2: Use the formula given in Dusart's paper and this paper (or this post ), I get 
$$\pi(x)=\frac{x}{\ln x}(1+\frac{1}{\ln x}+\frac{2}{(\ln x)^2}+O(\frac{1}{(\ln x)^3}))\tag 2$$ $$\sum_{p\leq\sqrt x}p =\frac{x}{\ln x}(1+\frac{1}{\ln x}+o(\frac{1}{(\ln x)^2})),\tag 3$$ so 1) is true but 2) is not, and there are only finite many $n$ satisfy $(1)$.","['analytic-number-theory', 'number-theory']"
616296,Limit when denominator = 0,"Can someone explain me why the following is not defined: $$\lim_{x \to 2} \frac{x-3}{(x-2)(x+2)} = \text{not defined in real numbers}$$ But this one is $-\infty$
$$\lim_{x \to 2} \frac{-1}{(x-2)^2} = -\infty$$ Both denominator = 0 but different result.. I don't understand the difference..",['limits']
616331,Area of an equilateral triangle divided by three lines,An equilateral triangle is divided by three straight lines into seven regions whose areas are shown in the image below. Find the area of the triangle. How to solve this problem ?,"['geometry', 'triangles', 'trigonometry']"
616335,"How prove this $F'(x_{0})=f(x_{0})$ if $F(x)=\int_{a}^{x}f(t)dt,x\in[a,b]$","Question: let $f$ be Riemann integrable on $[a,b]$,Assmue that $x_{0}\in [a,b]$,and let $f(x)$ is continuous on point $x=x_{0}$,and define
$$F(x)=\int_{a}^{x}f(t)dt,x\in[a,b]$$ show that
$$F'(x_{0})=f(x_{0})$$ This problem is my friend (He is a teacher) ask me,and I post my answer,maybe have some wrong, since
  $$F'(x_{0})=\lim_{x\to x_{0}}\dfrac{F(x)-F(x_{0})}{x-x_{0}}=\lim_{x\to x_{0}}\dfrac{\int_{x_{0}}^{x}f(t)dt}{x-x_{0}}$$
  and other hand, case1: $x>x_{0}$ we have $$I=\left|\dfrac{\int_{x_{0}}^{x}f(t)dt}{x-x_{0}}-f(x_{0})\right|=\dfrac{\left|\int_{x_{0}}^{x}f(t)dt-f(x_{0})(x-x_{0})\right|}{x-x_{0}}\le\dfrac{\int_{x_{0}}^{x}|f(t)-f(x_{0})|dt}{x-x_{0}}$$
  since
  $f(x)$ is continous on point $x=x_{0}$
  so
  $$I\le\dfrac{\int_{x_{0}}^{x}\varepsilon dt}{x-x_{0}}=\varepsilon$$
  so
  $$F'(x_{0})=f(x_{0})$$ case2:$x<x_{0}$ $$I=\left|\dfrac{\int_{x_{0}}^{x}f(t)dt}{x-x_{0}}-f(x_{0})\right|=\dfrac{\left|\int_{x_{0}}^{x}f(t)dt-f(x_{0})(x-x_{0})\right|}{|x-x_{0}|}\le\dfrac{\int_{x}^{x_{0}}|f(t)-f(x_{0})|dt}{x_{0}-x}$$
  since
  $f(x)$ is continous on point $x=x_{0}$
  so
  $$I\le\dfrac{\int_{x}^{x_{0}}\varepsilon dt}{x_{0}-x}=\varepsilon$$ My question:  someone  have other methods? Thank you  very much!","['limits', 'calculus', 'derivatives', 'analysis']"
616393,Entire function $f(z)$ bounded for $\mathrm{Re}(z)^2 > 1$?,Let $z$ be a complex number and $\mathrm{Re}$ denote the real part. Does there exist a nonconstant entire function $f(z)$ such that $f(z)$ is bounded for  $\mathrm{Re}(z)^2 > 1$ ?,['complex-analysis']
616398,Calculate $f^{(25)}(0)$ for $f(x)=x^2 \sin(x)$,"Calculate $f^{(25)}(0)$ for $f(x)=x^2 \sin(x)$. The answer is too short for me to understand, and the answer is $- 25 \cdot 24 \cdot 8^{23}$",['calculus']
616426,Find $f(x)$ where $ f(x)+f\left(\frac{1-x}x\right)=x$,What function satisfies $ f(x)+f\left(\frac{1-x}x\right)=x$ ?,"['calculus', 'algebra-precalculus', 'functional-equations']"
616450,"How to show $\max\{Y_{1},Y_{2},\cdots,Y_{n}\}$ converges in probability to $\theta$ as $n \to \infty$. [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $Y_{1},Y_{2},\ldots,Y_{n} $ be independent random variables , each uniformly distributed over the interval $(0,\theta)$. Show that $\max\{Y_{1},Y_{2},\ldots,Y_{n}\}$ converges in probability to $\theta$ as $n \to \infty$.","['probability-theory', 'uniform-distribution', 'convergence-divergence', 'uniform-convergence']"
616453,Why is Riemann integration used in complex analysis and not Lebesgue integration?,"In the development of complex analysis you use Riemann integration and not Lebesgue integration to define line integrals. My questions are: Are the theories developed the same? (i.e. does it not matter which integral you use in the development? Since all the functions usually involved are analytic or meromorphic can you use things such as analytic is equivalent to having a power series representation and uniform convergence within the radius of convergence to somehow show that the choice doesn't matter. I feel as if the function involved is analytic and has a finite radius of convergence this should be the case but I'm not so sure about what would happen if the function was meromorphic and/or has an infinite radius of convergence (Am I on the right track?)) If the theories developed are the same, does it become significantly easier to develop the theory with Riemann integration rather than Lebesgue integration. If they are not the same, what are examples to show that show they are different?",['complex-analysis']
616530,General Leibniz rule for triple products,"I have a question regarding the General Leibniz rule which is the rule for the $n^{th}$ derivative of a product and reads: 
$$
(f g)^{(n)}=\sum_{k=0}^{n} {n \choose k} \,f^{(k)} g^{(n-k)}.
$$ 
However, what about if there is a triple product instead of just a product. (i.e. $(f \cdot g \cdot  h)^{(n)}$)? Is there a comprahensive formula for such a derivative? I have yet to find one, but perhaps someone knows it.","['calculus', 'binomial-coefficients', 'derivatives', 'combinatorics']"
616536,How to solve for $x$ in $\sqrt[4]{x+27}+\sqrt[4]{55-x}=4$?,"I'm trying to guess a method for getting the values that work on this irrational equation:
$$\sqrt[4]{x+27}+\sqrt[4]{55-x}=4, x\in\mathbb C$$ After using the formula $a^4+b^4=(a+b)(a^3-a^2b+ab^2+b^3)$ and doing some amplifications, I ended in this phase:
$$p=x+27, r=55-x
\\\sqrt[4]{p^3}+\sqrt[4]{r^3}-\sqrt{p}\sqrt[4]{r}+\sqrt[4]{p}\sqrt{r}=\frac{82}{4}$$
, which clearly is complicated than the initial equation. Also, rising to the power of $4$, it isn't efficient either: you will end up with mixed radicals. Maybe I'm doing something wrong?","['radicals', 'algebra-precalculus', 'problem-solving']"
616564,Sheaf of a complex analytic function,"Let 
$$ F(U) = \left\{ \mbox{ all complex analytic functions } f \mbox{ on } U \mid z \frac{df}{dz}=1 \right\}$$
for any domain $U$ in $\mathbb{C}$. I want to show that: $F$ is a sheaf. The stalk of $F$ at $0$ is empty. The stalk at any other point is non-canonically isomorphic to $\mathbb{C}$. I know that the presheaf of continuous function is a sheaf (as they have the gluing property over open coverings), so also analytic functions (which are $C^\infty$) are sheaf. However, there are two problems is: a function that satisfy $d \frac{df}{dz}=1$ actually is $$\frac{df}{dz} = \frac{1}{z}$$ which is not analytic in 0. Moreover, is not the differential equation $\frac{df}{dz}=\frac{1}{z}$ is unique up to a constant - the family of solution is $f(z) = \ln(z) + c$ with $c \in \mathbb{C}$? Then it follows that $F$ is a sheaf with stalk $$\{f(z) = \ln(z) + c \mid c \in \mathbb{C} \} \cong \mathbb{C}$$
and empty stalk at 0 since there is no analytic function such that $0 \cdot \frac{df}{dt} = 1$. Are my consideration here are correct? Added in edit: We can define $\ln(z)$ as the extension of 
$$ \ln(x) = \sum_{n=1}^{\infty} \frac{(-1)^{n-1}}{n}(x-1)^n $$
to the complex number. Of course one needs to check where it converges and well-defined, and then arise the issue of branch cuts. I am no expert on complex analysis but my intuition says that $\frac{df}{dz}=\frac{1}{z}$ has a family of solutions differ by constants. Is this correct?","['sheaf-theory', 'complex-analysis']"
616577,"Any set with Associativity, Left Identity, Left Inverse, is a Group. - Fraleigh p.49 4.38","I couldn't unravel the 3rd para. in a similar post . Proof that left identity element = right identity element: $\begin{align} \color{#1E90FF}e*e &= \color{darkorange} 
{e} \\
\color{#1E90FF}{a^{-1}*a}*e& =\color{darkorange} 
{a^{-1}*a} \\
\color{purple}{(a^{-1})^{-1}*}\color{#1E90FF}{a^{-1}*a}*e& =\color{purple}{(a^{-1})^{-1}*}\color{darkorange} 
{a^{-1}*a} \\
\color{purple}{[(a^{-1})^{-1}*}\color{#1E90FF}{a^{-1}] *a}*e& =\color{purple}{[(a^{-1})^{-1}*}\color{darkorange} 
{a^{-1}]*a} \\
\color{#1E90FF}{a}*e& = \qquad \qquad \qquad \quad\color{darkorange} 
{a} 
\end{align}$ Proof that left inverse = right inverse, $\begin{align}a^{-1} * a & = e \\
a^{-1} * a \color{#1E90FF}{* a^{-1}} &= e \color{#1E90FF}{* a^{-1}}  \\
a^{-1} * a \color{#1E90FF}{* a^{-1}} &=  \color{#1E90FF}{a^{-1}} \\
\color{magenta}{[(a^{-1})^{-1}*}a^{-1}] * a \color{#1E90FF}{* a^{-1}} &= \color{magenta}{(a^{-1})^{-1}*} \color{#1E90FF}{a^{-1}}
\\
 a \color{#1E90FF}{* a^{-1}} &= e
\end{align}$ How can you prognosticate the tricky algebra here? You must rewrite $e$ as $a*a^{-1}$ and must know what to multiply by. Can someone please make this less prescient? Why does a one-sided definition of a group have to be all left sided or right sided? 
I'm NOT asking about the algebra...I'm asking for the intuition? If one-sided definitions are correct for groups, why not use them instead of the standard two-sided definitions? Reference: Fraleigh, A First Course in Abstract Algebra , p. 49 Question 4.38.","['intuition', 'group-theory', 'abstract-algebra']"
616605,Partial differentials vs normal differential (notation question/clarification only),"In physics, it seems like the use of $\dfrac{dy}{dx}$ and $\dfrac{\partial y}{\partial x}$ are used somewhat interchangeably. My understanding is that, technically $\dfrac{dy}{dx}$ is only appropriate where $y$ only has a single variable (x), but may have many other constants. By contrast $\dfrac{\partial y}{\partial x}$ says $y$ has more than just a single $x$ variable, but for now we're holding those variables as constants and treating the $x$ as the only variable. Essentially, $\dfrac{dy}{dx}$ and $\dfrac{\partial y}{\partial x}$ should give you the same result when applied to $y=x^2+3x-2\theta+\lambda^2 $, except $\dfrac{dy}{dx}$ implies that $\theta$ and $\lambda$ are constants and always will be, while  $\dfrac{\partial y}{\partial x}$ suggests that at least one of $\lambda$ or $\theta$ is a variable. Is this understanding correct, or have I missed something?","['notation', 'ordinary-differential-equations', 'calculus', 'partial-differential-equations']"
616608,Properties of the first eigenvalue of the $p$-Laplace operator,"Let $\Omega\subset\mathbb{R}^n$ be a bounded domain and $p\in (1,\infty)$, $p\neq 2$. Consider the usual Sobolev space $W_0^{1,p}(\Omega)$ and its dual $W^{-1,p'}(\Omega)$, where $1/p+1/p'=1$. Define $\lambda_1>0$ by $$\tag{1}\lambda_1=\inf_{u\in W_0^{1,p}(\Omega)}\frac{\|u\|_{1,p}^p}{\|u\|_p^p}$$ $\lambda_1$ is the first eigenvalue associated with the problem $$-\Delta _p u=\lambda |u|^{p-2}u,\ u\in W_0^{1,p}(\Omega),\tag{2}$$ where the above equation is understood as an equation in $W^{-1,p'}(\Omega)$ and $\Delta_p u=|\nabla u|^{p-2}\nabla u$. As you can see in these notes from Peral, the infimum in $(1)$ is achieved by, let's say, $u_1\in W_0^{1,p}(\Omega)$. Moreover, $u_1$ does not change sign, i.e. we can choose it to be strictly positive in $\Omega$ and if $v$ is another minimum point of $(1)$, we have that $v=\alpha u_1$, $\alpha\in \mathbb{R}$ ($\lambda_1$ is simple). I would like to note that $(1)$ can also be viewed as a problem of minimization on the Banach manifold $$S_p=\{u\in W_0^{1,p}(\Omega):\ \|u\|_p=1\}$$ i.e. $$\lambda_1=\inf_{u\in W_0^{1,p}(\Omega),\ u\in S_p}\|u\|^p_{1,p}\tag{3}$$ We have from the simplicity of $\lambda_1$ that there are two eigenvectors of $(2)$ in $S_p$. Fix one of them and let's call it $u_1$. The tangent space in the point $u_1$ in $S_p$ can be indetified as $$T=T_{u_1}S_p=\left\{v\in W_0^{1,p}:\ \int_\Omega |u_1|^{p-2}u_1 v=0\right\}$$ Let  $T_1=\{v\in T:\ \|v\|_{1,p}=1\}$. Consider the function $F:\mathbb{R}\times T_1\to \mathbb{R}$ defined by $$F(t,v)=\frac{\int_\Omega|\nabla (u_1+tv)|^p}{\int_\Omega|u_1+tv|^p}=\frac{\|u_1+tv\|_{1,p}^p}{\|u_1+tv\|_p^p}=\left\|\frac{u_1+tv}{\|u_1+tv\|_p}\right\|_{1,p}^p$$ I am trying to prove  that there exist $\epsilon>0$ such that for all fixed $v\in T_1$ the function $f(t,v)$ is strictly convex for $t\in (-\epsilon,\epsilon)$. Geometrically, I am taking curves in $S_p$ which starts in $u_1$. If someone has  an idea, maybe some trick inequality or even a counter example, I would be grateful.","['sobolev-spaces', 'partial-differential-equations', 'analysis']"
616619,to find the graphs having vertices with same eccentricity,"I was reading a paper http://www.discuss.wmie.uz.zgora.pl/php/discuss3.php?ip=&url=plik&nIdA=11134&sTyp=HTML&nIdSesji=-1 There is a formula to calculate eccentricity in the section 4. where $E_G(x) = max\{D_G(x, y)|y\in V(G)\}$ and $D_G(x, y)$ is the
minimum length of an x-y walk whose parity differs from that of $d_G(x, y)$. Also Two walks have the same parity if the difference of their lengths is even; otherwise they have opposite parity. I was just looking for those graphs where eccentricity comes out to be the same. One of my attempts made me to think that if we take all graphs as cycles of odd length, then eccentricity of every vertex in the tensor product will be same. Am I right? Are there any other conditions or graphs so that we get the required condition. If not then please help me by giving hints or suggestions. Thanks a lot for helping and giving time. Thanks Note: The reason of taking cycles of odd length is that we can easily find odd and even length walks between any pair of vertices in a graph.","['graph-theory', 'discrete-mathematics', 'tensor-products', 'combinatorics']"
616651,Difference between $R^\infty$ and $R^\omega$,"I know $R^\omega$ is the set of functions from $\omega$ to $R$. I would think $R^\infty$ as the limit of $R^n$, but isn't that $R^\omega$?
The seem to be used differently, but I can't tell exactly how.","['general-topology', 'elementary-set-theory', 'notation']"
616656,A question on a sequence in a Banach algebra [duplicate],"This question already has answers here : An easy question on complex (2 answers) Closed 10 years ago . If $\{u_{k}\}_{k=1}^{\infty}$ is a sequence in an Banach algebra (and more specifically, in the set of all the bounded linear operators of a Banach space $X$). If $$\sum_{k=1}^{\infty}\lambda^{k}u_{k}=0,\quad \text{for every $\lambda\in \mathbb{D}(0, 1/3)$},$$
where the $\mathbb{D}(0, 1/3)~$ denotes an open disc centered at $0$ and radius $1/3$. Then can we conclude that $\boldsymbol{ u_{n}=0}$, for every $\boldsymbol{n}$?","['operator-theory', 'operator-algebras', 'functional-analysis', 'complex-analysis']"
616675,Does random linear transformation keep linear indepedence?,"We have 3 linearly independent vectors $J_1, J_2, J_3 \in \mathbb{C}^3$. We also have a random matrix $A\in\mathbb{C}^{4\times 3}$. Are the vectors $AJ_1, AJ_2, AJ_3 \in \mathbb{C}^4$ linearly independent? In other words, Does the random linear transformation from $\mathbb{C}^3$ to $\mathbb{C}^4$ keep the linear independence almost surely?","['probability-theory', 'linear-algebra']"
616703,"$f$ is a non-constant polynomial, $A $ is a set of measure zero, Is this true that $m(f^{-1}A)=0$, where $m$ stands for the Lebesgue measure.","Let $f$ be a non-constant polynomial, and let $A \subset \mathbb{R}$ be a set of measure zero, Is this true that $m(f^{-1}A)=0$, where $m$ stands for the Lebesgue measure. If $A$ is a countable set, it is easy to see that $Cardinality (f^{-1}A) \leq Cardinality (\mathbb{N} * \mathbb{N})$ and it means that $m(f^{-1}A)=0$. My problem in proving that this is true, is sets like Cantor set, whose measure is zero but is uncountable. Any hints or ideas is appreciated. Thanks !","['measure-theory', 'real-analysis']"
616728,Inverse rule to the L'Hôpital's rule,"If in L'Hôpital's rule we have that: $f,g :(a,b)\to \mathbb{R}$ , there exist $f'(x)$ , $g'(x)$ , and $g'(x)\ne0$ , $$\lim_{x\to a^+} \frac{f(x)}{g(x)} = L,$$ and also $\lim_{x\to a^+} f(x)=\lim_{x\to a^+} g(x) = 0$ , must it be also $$\lim_{x\to a^+}\frac{f'(x)}{g'(x)} = L$$ or not? I think it is wrong in some cases, but I can't find an example.",['real-analysis']
616745,"If $\,\lim_{n\to\infty}f(nx)\,$ exists, for all $x\in\mathbb R$, then so does $\,\lim_{x\to\infty}f(x)\,$","Let $\,f:\mathbb{R}\to\mathbb{R}$. The following limit exists for all $x \in \mathbb{R}$: 
$$\lim_{n\to ∞} f(nx) ,$$ where $n \in \mathbb N$. Is it correct that:
$$\lim_{x\to ∞} f(x) ,$$ 
exists if: a) $f$ any function, b) $f$ continuous on $\mathbb{R}$.","['calculus', 'continuity', 'real-analysis', 'limits']"
616767,Convergence of $\sum\frac{\tan(nz)}{n^2}$ to an analytic function...what if $z\in \mathbb{R}$?,"For which values of $z$ does $$\sum_{n=1}^\infty
 \frac{\tan(nz)}{n^2}$$ converge? For which values of $z$ is the
  limiting function analytic? One can show, as in this answer, that $$\left|\frac{e^{inz}-e^{-inz}}{e^{inz}+e^{-inz}}\right|$$ is bounded as $n\to \infty$, so long as $\text{Im}(z)\neq 0$. But the article above really does not discuss the case $\text{Im}(z)=0$, although it thinks it does. It doesn't deal with the poles at $\frac{(2k+1)\pi}{2}$, which can make some of the terms of the series undefined. If $\text{Im}(z)=0$, obviously the estimate $$\left| 
\frac{e^{inz}-e^{-inz}}{e^{inz}+e^{-inz}} \right|\leq \frac{1+e^{2ny}}{|1-e^{2ny}|} $$ does not work. (Here $y=\text{Im}(z)$.) For $x\in \mathbb{R}$ of the form $j^2\frac{(2k+1)\pi}{2}$, there will be undefined terms. Suppose there are no undefined terms. What can we say then about convergence? And in what way can we describe these singularities of the limiting function, corresponding to $x$ with undefined terms? Perhaps these points are not even isolated...","['trigonometry', 'sequences-and-series', 'complex-analysis']"
616773,Continuity of homotopy from constant function to identity,"According to the definition of homotopy between two maps $f,g : X \to Y$ we need a continuous map $F : X \times [0,1] \to Y$ such that $F(x,0) = f(x)$ and $F(x,1) = g(x)$. Most examples I've seen in the literature however tend to skip over the continuity part of $F$ in examples. So for example take $X$ a convex subset of $\mathbb{R}^n$, fix $x_0 \in X$ and define maps $X \to X$ by $f(x) = x_0$, i.e. $f$ is the constant function and the identity map $\mathrm{id}$. Then for a homotopy between $f$ and $\mathrm{id}$ we clearly want $F(x,t) = tx_0 + (1-t)x$ (obviously could generalise this to any $f$ and $g$). It seems non-trivial to me to prove that $F$ is continuous (the rest of it is straight forward). I can formally solve to get an $F^{-1}$ for this but I'm not sure how that might help. I get
$$ F^{-1}(y) = \left\{ \begin{array}{rl} \{ (x, 1) : x \in X \} \cup \{ (x_0, t) : t \in [0,1) \} & \text{if } y = x_0 \\ \left\{ \left( \frac{y-tx_0}{1-t}, t \right) : t \in [0,1) \right\} & \text{otherwise.} \end{array} \right. $$
but it seems tricky to then apply this to say the open ball about $x_0$ in $X$ say. I also thought maybe trying to break it down into simpler maps but I can't see this either at the moment, for example I can't break it into maps $X \to X$ and $[0,1] \to X$ as then their product would be a map $X \times [0,1] \to X \times X$ which is of course not what I want. Any help appreciated. I have a feeling it's not difficult I just can't see it right now. Steve","['general-topology', 'homotopy-theory', 'algebraic-topology']"
616792,Derivative change sign,"If the function $f:\mathbb{R} \to \mathbb{R}$, $f$ has an extremum at the point $x$, and $f$ is differentiable in some neighborhood of $x$. Is it right that the derivative changes sign when passing through $x?$","['functions', 'calculus', 'real-analysis']"
616797,How should one think about results that depend on AC?,"I just encountered this: ""(Theorem of A. H. Stone) Every metric space is paracompact... Existing proofs of this require the axiom of choice...
  It has been shown that neither ZF theory nor
  ZF theory with the axiom of dependent choice is sufficient"" I understand that it's standard to mention whenever AC is used to prove any results. I also read here on this site that it is due to the fact that undesired stuff like the Banach-Tarski paradox happens when you assume AC. My question is, as a non-set theorist, how should one think about results that depend on the axiom of choice? I'm sorry if this question is too broad but please realize that part of the reason I'm asking it is because I'm not sure what is the real question here... ADDED : There's a great thread on MO on that very question!","['general-topology', 'metric-spaces', 'elementary-set-theory', 'axiom-of-choice']"
616828,A finite field cannot be an ordered field.,"I am reading baby Rudin and it says all ordered fields with supremum property are isomorphic to $\mathbb R$. Since all ordered  finite fields would have supremum property that must mean none exist. Could someone please show me a proof of this? Thank you very much, Regards.","['ordered-fields', 'abstract-algebra', 'field-theory']"
616834,"How many arrays with crossed cells, order of rows/columns irrelevant","I've been struggling with this simple problem for months though as I am a newbie to… well, maths, there's high chance someone more educated than myself may get it right! Let's consider an array or a table or a Ferrers diagram or whatever it's called, $r$ rows by $c$ columns, in which each cell can either be blank or have a cross in it but each column must contain exactly $a$ crosses. For instance, $\begin{array}{|c|c|c|c|c|c|}
\hline ×&×&×&×& &  \\
\hline ×&×& & &×&× \\
\hline  & &×& &×&  \\
\hline  & & &×& &× \\
\hline
\end{array}$ is such an array with $c=6,\ r=4,\ a=2$. Now two arrays are said to be identical ('isomporphic' is probably the right word?) if we can obtain the second one from the first one by changing the order of columns and/or rows of the first one. So, the following array is identical to the one above: $\begin{array}{|c|c|c|c|c|c|}
\hline  & & &×& &× \\
\hline ×&×& & &×&× \\
\hline  &×&×& & &  \\
\hline ×& &×&×&×&  \\
\hline
\end{array}$ but the order of columns is changed to $164325$ and the order of rows to $3241$. Now the question is: how many unidentical (non-isomorphic) arrays are there, such that all the above conditions are satisfied and $c,r,a$ are given? I know the answer for $c=6,r=4,a=2$ is $32$ because I have painstakingly went through every combination but how to do this more effectively?? :) I've been trying to learn enough group theory but it's all about rotating cubes or necklaces and I can't figure out how to translate this simple problem so that its tools can be deployed. Also, I tried to find a recurrence (by slicing away the last row and column) but it seems to be dependent on the actual placement of the crosses so… I'd be glad for any help…","['matrices', 'algebraic-graph-theory', 'group-theory', 'combinatorics']"
616841,Ideals in $B(H)$ are self-adjoint,It is known that every (closed two-sided) ideal in a $C^{*}$-algebra is self-adjoint. The proofs that I've seen involve functional calculus and approximate units. I am wondering whether there is a more direct approach in the particular case of $B(H)$ (for a Hilbert space $H$).,"['operator-theory', 'operator-algebras', 'functional-analysis']"
616861,"Behavior of $f(z)=\int_0^1\mathrm{e}^{\alpha t^2}\sin(tz)\,dt$ when $\alpha <0$","Define $$f(z)=\int_0^1\mathrm{e}^{\alpha t^2}\sin(tz)\,dt,$$ where $\alpha \in
 \mathbb{R}$. If $\alpha >0$ then $f(z)$ has infinitely many real zeros
  and at most a finite number of complex zeros. What if $\alpha <0$? Hint. Integrate by parts. My attempt so far. To get some intuition about the problem, I tried to demonstrate the claim in the question. If $x\in \mathbb{R}$, it seems that $$f(x) = 0 \iff \int_0^1\mathrm{e}^{\alpha t^2 + tx}dt= \int_0^1\mathrm{e}^{\alpha t^2 - tx}dt.$$ I was unable to simplify that condition. I then attempted to integrate by parts blindly, and turn the $\alpha <0$ case into the $\alpha>0$ case, and use the claim. $$\int_0^1 \mathrm{e}^{\alpha t^2}\sin(tz)\,dt = -\frac1z \mathrm{e}^\alpha \cos(z) + \frac1z + \frac1z \int_0^1 \cos(tz)\,\mathrm{e}^{\alpha t^2}2\alpha t \, dt.$$ And there I got stuck. Any ideas?","['roots', 'integration', 'definite-integrals', 'complex-integration', 'complex-analysis']"
616885,Limits of square root [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question $$\lim_{x\to\infty}\left(\sqrt{x+\sqrt{x+\sqrt{x + \sqrt x} }}-\sqrt x\right) $$ (original screenshot) Compute the limit
Can you please help me out with this limit problem","['radicals', 'arithmetic', 'limits', 'analysis']"
616889,Worst-case number of transpositions needed to generate a permutation,"For a permutation on $n$ elements, what is the worst-case minimal number of transpositions that need to be multiplied to give the permutation? The transpositions do not need to be adjacent.",['combinatorics']
616898,How do I solve $\sin^2 x=\cos x$?,"I'm trying to solve a trigonometric equation, but I'm a bit stuck. The equation is this: $\sin^2 x = \cos x$ So far what I've done looks like this: $\sin^2 x - \cos x = 0$ $ (1 - \cos^2 x) - \cos x = 0$ $-\cos^2 x - \cos x + 1 = 0$ But from there I don't know how to factor it to get onwards to evaluating $x$ for separate cosine terms. Have I gone wrong somewhere, or am I simply not seeing the proper way to factor this?",['trigonometry']
616905,Is $U = \left\{A \in \mathbb{M}^ {n \times n}(\mathbb{R} ): \ker{A} \cap \text{Im}A = \{\vec{0}\} \right\}$ a vector space?,"I recently tried to prove or reject the conjecture that the set of matrices $$U = \left\{A \in \mathbb{M}^ {n \times n}(\mathbb{R} ): \ker{A} \cap \text{Im}A = \{\vec{0}\} \right\}$$ is a linear subspace of $\mathbb{M}^{n \times n}(\mathbb{R})$. I didn't find it hard to prove that the set is multiplicative: Assume that $A \in U$. We know that $\ker{0}\cap \text{Im}0 = \vec{0}$. So in the case that $\lambda=0$ we are done. Suppose that $\lambda \neq 0$. It follows easily that $\ker{A}=\ker{\lambda A}$ and that $\text{Im}A = \text{Im}{\lambda A}$. I thought additivity was the hardest part. I don't have a good intition when it comes to "" adding"" linear maps. Can you help me with this?","['matrices', 'linear-algebra']"
616914,discrete math identity set question,"Let $S=\{a,b\}$ be a two-element set. How many functions $f:S\rightarrow S$ have  the property $f \circ f$ is the identity function? one or two or three? This is my university discrete math question, however, i am really out of thought for this one.
I understand the identity function is that we give $f(x) = x$ and $g(x) = x$, but for $f \circ f$, the only thing i can thought is $f(x) \times f(x)$, am i right? thanks for Tim's correction, the $f \circ f$ stands for $f(f(x))$ not $f(x) \times f(x)$","['elementary-set-theory', 'functions']"
616922,"With hypotheses of Schwarz's lemma, estimate the radius around zero where $f$ must be one-to-one","Suppose $f(z)$ is analytic in the open unit disc and $|f(z)|<1$ there.
  Suppose further that $f(0) =0$ and $f'(0) = a \neq 0$. Show that there
  is a disc of positive radius $|z|<\rho$ such that for $z_1$ and $z_2$
  in the disc, $$f(z_1)=f(z_2) \Longrightarrow z_1=z_2.\tag{1}$$ Find an
  estimate for $\rho$. Try to make the estimate as sharp as you can. Hint: $$f(z_2)-f(z_1) = \int_{z_1}^{z_2}f'(z)dz = a(z_2-z_1)+ \dotsb .$$ My answer so far: I can show (1) in a neighborhood of zero as follows: $z=0$ is an isolated zero of $f$ by the isolated zero theorem (note $f$ is non-constant since $f'(0)\neq 0$). Therefore there is a closed neighborhood $\overline{B_{\rho}(0)}$ of zero such that $f\neq 0$ on the punctured disc $\overline{B_{\rho}(0)} \setminus \{0\}$. Let $M = \max_{z\in \partial{B_{\rho}(0)}}|f(z)|$. Now for $w\in B_{M}(0)$, we have that $|f(z)-0|> |w-0|$ for $z\in \partial B_\rho(0)$, so $f(z)-0$ and $f(z)-0 + (w-0)=f(z)-w$ have the same number of zeros in $\overline{B_{\rho}(0)}$, meaning that $f$ is one-to-one there. For the estimate, I'm having more trouble. I know by Schwarz's theorem that $|f(z)|<|z|$ in the disc, and $a<1$, unless $f(z)=\lambda z$ for $\lambda \in S^1$, in which case both are equalities. But how can I use this? If I try to use the hint, I get (I think) $$f(z_2)-f(z_1) = a(z_2-z_1)+ \frac12 f''(0)(z_2^2 - z_1^2) + \dotsb$$ but I'm not sure what to do with this.",['complex-analysis']
616950,Motivation of Weierstrass-approximation Theorem?,"Weierstrass Theorem (Classical): If $f$ is a continuous real or complex function on $[a,b]$ , there exists a sequence of polynomials $P_n$ such thay $\lim_{n\to \infty} P_n(x)=f(x)$ . The proof i know (using Berstein Polynomials) is easy but really artificial. I don't see any motivation and how and where ideas come in. What are motivations for this proof? And is weierstrass' original proof not constructive?",['real-analysis']
616961,Separatedness of a scheme of finite type over a field,"Let $k$ be a field.
Let $\bar k$ be an algebraic closure of $k$.
Let $X$ be a $k$-scheme of finite type.
Suppose $X\times_k \bar k$ is separated over $\bar k$.
Is $X$ separated over $k$?
If yes, how do you prove it?",['algebraic-geometry']
616981,Relation between the braid group and the mapping class group of the plane,"According to the following link , page 248, the braid group modulo its center is isomorphic to the mapping class group of the $N$-times punctured plane, i.e. $B_N/Z(B_N)\cong M_N(\mathcal(R)^2)$. Could anybody explain to me, how it is related to the mapping class group of the punctured $2$-sphere, please?","['low-dimensional-topology', 'general-topology', 'algebraic-topology', 'knot-theory', 'homotopy-theory']"
616986,Has SGA 4½ been typeset in TeX?,"The title says it all. I've CW'd the question since I'm answering it, as this seemed like the best way to get the news out.","['arithmetic-geometry', 'algebraic-geometry', 'reference-request', 'etale-cohomology']"
616995,Reference help - Linear Algebra and Calculus,"I went through some of the questions asking for reference help but they're not the same (definitely similar though). Maybe i missed something but here goes- I know there are Gilbert Strang videos, textbooks and other sources that are similar to learn Linear Algebra but what i want to know is - are there any concise (preferably freely available) text books to review the concepts? I say review because I've taken up both Linear Algebra and Calculus 6-7 years ago and they are rusty. I need to review these for grad school and I'm short of time to re-learn everything from scratch. I need to brush up the basics for example, Linear Algebra - Vectors, and solving linear equations Spaces Matrices (Rank, Row/Column operations) Determinants Eigen values and Eigen vectors. Calculus Limits (and some pre-calculus) solving differential equations (ODEs and PDEs et al) basic integral calculus What I'm looking for is review sources and primers that maybe some of you have found really useful. Edit - Some very helpful links, thank you all. I also found PatrickJMT.com for very basic stuff to solve a few problems and help remember high school learning. And some wandering soul might appreciate this link as well - Additional Resources","['linear-algebra', 'calculus', 'ordinary-differential-equations']"
617009,Finding the derivative of $x\uparrow\uparrow n$ [duplicate],"This question already has answers here : $n^{th}$ derivative of a tetration function (6 answers) Closed 5 years ago . I am trying to find a general derivative for the function: $f(x)=x^{x^{x^{...^{x}}}}$however to do that I must find $f^{\prime }$ and $f^{\prime \prime}$...etc. I am now trying to write down a general expression for $f^{\prime \prime}$ and I have stumble opon the series in the picture below, I wonder, do anyone have an idea of what sort of expantion it migth be ? I have tried breaking it down into three different sums, but I wasn't very successful! EDIT So since this post has gotten some attention and the title has been change I will tell you what I am on about, although I already have a post just for the question in the title from before. I am as I said earlier trying to find a general derivative for the function $f(x)=x^{x^{x^{...^{x}}}}$ where $n$ is an arbitrary number, natural number and greater or equal to 2. I have already made success when I tried to find the first derivative, and I have also found some interesting pattern emerge when the derivatives as well as n incresses. But my question here was if anyone knew what this expation might be or look similar to be, since I have yet to be lernt series etc. I did not know that the question needed such background since it's straight a forward question.","['sequences-and-series', 'power-series', 'calculus', 'derivatives']"
617029,Prove that $||\sum_{n=0}^{+\infty}{x_n}||\le\sum_{n=0}^{+\infty}||{x_n}||$ when series $\sum_{n=0}^{+\infty}{x_n}$ are absolutely converge?,"I think it should be proved that: Since $$||\sum_{n=0}^{N}{x_n}||\le\sum_{n=0}^{N}||{x_n}||$$ so $$\lim_{N\to+\infty}||\sum_{n=0}^{N}{x_n}||\le\lim_{N\to+\infty}\sum_{n=0}^{N}||{x_n}||$$
so $$||\sum_{n=0}^{+\infty}{x_n}||\le\sum_{n=0}^{+\infty}||{x_n}||$$ 
is it right ??","['convergence-divergence', 'sequences-and-series', 'limits']"
617030,Real roots of the equation $1+\sum_{r=1}^{7}\frac{x^{r}}{r} = 0$,The number of real roots of the equation $\displaystyle 1+\frac{x}{1}+\frac{x^2}{2}+\frac{x^3}{3}+\frac{x^4}{4}+\frac{x^5}{5}+\frac{x^6}{6}+\frac{x^7}{7} = 0$ $\bf{My\; Try}::$ Let $\displaystyle f(x) = 1+\frac{x}{1}+\frac{x^2}{2}+\frac{x^3}{3}+\frac{x^4}{4}+\frac{x^5}{5}+\frac{x^6}{6}+\frac{x^7}{7}$ Now $\displaystyle f^{'}(x) = 1+x+x^2+x^3+x^4+x^5+x^6$ and $\displaystyle f^{''}(x) = 1+2x+3x^2+4x^3+5x^4+6x^5$ $\displaystyle f^{'''}(x) = 0+2+6x+12x^2+20x^3+30x^4 = 2\left(1+3x+6x^2+10x^3+15x^4\right)$ Now I did not understand how can i solve it Help Required Thanks,['algebra-precalculus']
617032,calculation of $\int_{0}^{1}\tan^{-1}(1-x+x^2)dx$,"Compute the definite integral
  $$
\int_{0}^{1}\tan^{-1}(1-x+x^2)\,dx
$$ Failed Attempt: Let $1-x+x^2=t$. Then $$
\begin{align}
(2x-1)\,dx &= dt\\
dx &= \frac{1}{(2x-1)}dt
\end{align}
$$ Changing the limits of integration, we get $$\int_{1}^{1}\tan^{-1}(t)\cdot \frac{1}{(2x-1)}dt = \int_{1}^{1}\tan^{-1}(t)\cdot f(t)dt = 0
$$ where $f(t)=\frac{1}{(2x-1)}$. Is it true that $\int_{a}^{a}f(x)dx = 0$? If not, then where have I made a mistake in my attempted solution?","['trigonometry', 'calculus']"
617040,Why is a Borel algebra a $\sigma$-algebra?,"My book defines a Borel algebra $\mathcal{B}^n$ as the $\sigma$-algebra generated by the open sets of $\mathbb{R}^n$. In order to be a $\sigma$-algebra: If $A$ is a set in a $\sigma$-algebra, so is its complement $A^c$. Suppose $X$ is an open set in $\mathcal{B}^n$, then $X^c$ is closed. But wouldn't $X^c \notin \mathcal{B}^n$ because it is closed? Is it possible to get closed sets from open ones with the properties of a $\sigma$-algebra?",['measure-theory']
617049,Reason for Continuous Spectrum of Laplacian,"For the circle $S^1$, it is well-known that the Laplace-Beltrami operator $\Delta=\text{ div grad}$ has a discrete spectrum consisting of the eigenvalues $n^2,n\in \mathbb{Z}$, as can be seen from the eigenfunction basis $\{\exp(in\theta)\}$. This is not quite the case in $\mathbb{R}$; the spectrum of $\Delta$ there is $[0,\infty)$. This is because there is a family of ""step"" eigenfunctions that vary continuously and give out all the eigenvalues we need. But I was wondering, is there a more geometric reason (perhaps related to the properties of $\Delta$) as to why the spectrum is continuous in this case?","['spectral-theory', 'differential-geometry']"
617071,Finding the volume of two intersecting cylinders at arbitrary angles,"Suppose we know the length, radius, position and orientation of two cylinders. Is there a general formula to calculate the volume of space shared by the intersection of the cylinders?",['geometry']
617073,absolute convergence of $\sum _{n=1}^{\infty} a_n$ imply?,"Question is : If $\sum _{n=1}^{\infty} a_n$ is absolutely convergent  then which of the following is not true? $\sum_{m=n}^{\infty}a_m\rightarrow 0$ as $n\rightarrow \infty$ $\sum_{n=1}^{\infty}a_n\sin n$ is convergent. $\sum_{n=1}^{\infty}e^{a_n}$ is divergent. $\sum_{n=1}^{\infty}a_n^2$ is divergent. First thing I would like to concentrate on is third option (as it is easy :P).... absolutely convergence of $\sum _{n=1}^{\infty} a_n$ imply $a_n\rightarrow 0$ i.e., $e^{a_n}\rightarrow 1$ i.e.,$\sum_{n=1}^{\infty}e^{a_n}$ is divergent. I guess second option is most probably true.. It is for sure absolute convergence as $|a_n\sin n|\leq |a_n|$ for all $n$....  I could not give concrete argument for convergence. I guess fourth option is false... absolutely convergence of $\sum _{n=1}^{\infty} a_n$ imply $a_n\rightarrow 0$ i.e., after certain stage $|a_n|<1$ i.e., $|a_n^2|<|a_n|$ So, we would have convergence of $\sum_{n=1}^{\infty}a_n^2$. I do not understand what is actual point of first option... Could some one confirm if this justification for second/third/fourth options is sufficient and help me to understand what first option is... Thank you.","['sequences-and-series', 'real-analysis']"
617075,A group presentation for $\mathbb{Z}_2\times \mathbb{Z}_2$,"I know that the only groups of order 4 are $\mathbb{Z}_2\times \mathbb{Z}_2$ and $\mathbb{Z}_4$ up to isomorphisms.
And I also know that the group presentation of $\mathbb{Z}_4$ is $\left ( a:a^4=1 \right )$. Naturally, I thought the group presentation of $\mathbb{Z}_2\times \mathbb{Z}_2$ is $\left ( a,b:a^2=1,b^2=1 \right )$.
But I'm not sure this presentation really indicates  $\mathbb{Z}_2\times \mathbb{Z}_2$. For example, if $A=\begin{pmatrix}
\sqrt{2} &1 \\ 
-1 &-\sqrt{2} 
\end{pmatrix}, B=\begin{pmatrix}
\sqrt{3} &1 \\
-2 &-\sqrt{3}
\end{pmatrix}\in \left ( M(2, \mathbb{R}), \cdot  \right )$, then a group $\left ( A,B \right )$ has a presentation $\left ( A,B:A^2=E,B^2=E \right )$ but $AB\neq BA$ and thus this group is not isomorphic to $\mathbb{Z}_2\times \mathbb{Z}_2$. Where did I misunderstand?","['group-presentation', 'free-groups', 'group-theory', 'abstract-algebra']"
617087,How to find the greatest number among 3 integer numbers?,Can anyone explain to me where & how can I use this equation. I was told to make a program that reads 3 integer numbers and prints the greatest one using the following formula. But how? $$\operatorname{Major} AB = \frac{a+b+abs(a-b)}{2}$$,['algebra-precalculus']
617097,Why did Hartshorne bother on schemes in his textbook when he worked only over an algebraically closed field?,"In his textbook Algebraic Geometry , he wrote in p. 58: Now that we have seen a litle bit of what algebraic geometry is about,
  we should discuss the degree of generality in which to develop the foundations of the subject.
  In this chapter we have worked over an an algebraically closed field, because that is the simlest case.
  But there are good reasons for allowing fields which are not algebraically closed. However, in Chapter 4 and 5 treating curves and surfaces, which are the ""meat"" of algebraic geometry, he worked only over an algebraically closed field.
Hence my title question.",['algebraic-geometry']
617100,Weird matrix identity,"I stumbled upon a weird equality that I can't seem to explain: For a $N\times N$ (symmetric) matrix $\mathbf{X}$ that satisfies the eigenvalue problem $$\mathbf{X} \mathbf{v}_k = \lambda_k \mathbf{v}_k$$ and a $N\times1$ matrix $\mathbf{u}$ that is split in 2 (elements in the first half are equal to 1, equal to -1 for the second half), i.e. $$\mathbf{u}^T := \frac{1}{\sqrt{N}}\bigl[\underbrace{1 ...\ 1}_{\times N/2}\ \underbrace{-1\ ....-1}_{\times N/2}\bigr]$$ the following (apparantly) holds $$ \mathbf{u}^T(z \mathbf{I} - \mathbf{X})^{-1} \mathbf{u} = \sum_{k=1}^N \frac{(\mathbf{u}^T \mathbf{v}_k)^2}{z-\lambda_k}.$$ $z$ is complex but vanishingly close to the real axis. I'm guessing it has something to do with the resolvent $$ (z \mathbf{I} - \mathbf{X})^{-1} \equiv \sum_{k=0}^\infty \frac{\mathbf{X}^k}{z^{k+1}}$$ but I can't figure it...","['matrices', 'eigenvalues-eigenvectors']"
617103,Does this integral have a closed form?,"I was working with this problem in an exam: Given $\lambda\in(-1,1)\subset\Bbb R$, find 
$$f
   (\lambda)=\int_{0}^{\pi}\ln\left(1+\lambda \cos x\right)\mathrm{d}x
$$ My try: put $\delta\in (0,1)$ such that $\lambda\in(-\delta,\delta)$. Using the power series of $\ln(1+x)$ and uniform convergence to take $\sum_{n=0}^\infty$ outside $\int_{0}^{\pi}$, finally, I got this: $$f(\lambda)=-\sum_{k=1}^\infty{(2k-1)!!\over (2k)!!}{\lambda^{2k-1}\over 2k}$$ But I still wonder if there is a closed form for $f(\lambda)?$ And is my solution above right or wrong?","['definite-integrals', 'calculus', 'integration']"
617153,Unable to understand this profit loss problem,"I got this question from here . A man sold $250$ chairs and had a gain equal to selling price of $50$ chairs. His profit percent is? The answer says it will be $25\%$ of profit.
But, how? It should  be $20\%$ . My solution is $\dfrac{50}{250}\times 100 = 20\%$ . Can't understand the solution from the website. Please help.",['algebra-precalculus']
617167,Finding complex power series with interesting boundary behavior,"I need to find one (or more) interesting complex power series to give to my students for their analysis exam. Ideally, this would be a power series that has interesting behavior at the boundary, i.e. does not converge everywhere/nowhere, but only at select points. To check this, they have at their disposal Abel's criterion, Dirichlet's criterion and Weierstrass' M-test. The classic examples (that they've seen) are of course the ones with coefficients $1, \frac{1}{n}$, and $\frac{1}{n^2}$. Others seem hard to find.","['power-series', 'complex-analysis', 'real-analysis', 'analysis']"
617169,Complexification of a real Hilbert space,"The following is problem 1.7 in chapter 1 of Conway's A Course in Functional Analysis. Let $H$ be a Hilbert space over $\Bbb R$ and show that there is a Hilbert space $K$ over $\Bbb C$ and a map $U: H \to K$ such that a) $U$ is linear b) $(Uh_1,Uh_2)=(h_1,h_2)$ for all $h_1,h_2 \in H$ c) for any $k\in K$ there are unique $h_1,h_2\in H$ such that $k=Uh_1+iUh_2.$ For this exercise I put K:= $\{ h_1+ih_2 ; h_1,h_2\in H\}$ and define inner product on K such that $(k,k'):= (h_1,h_1')+(h_2,h_2') +i(h_2,h_1')-i(h_1,h_2')$ . Now define $U(h)=h$ for all $h \in H$ and extend $U$ linearly. With these, I can not show that $K$ is complete. Please help me.",['functional-analysis']
617178,Volume of the largest rectangular parallelepiped inscribed in an ellipsoid,Show that the volume of the largest rectangular parallelepiped that can be inscribed in the ellipsoid $$\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}=1$$ is $\dfrac{8abc}{3\sqrt3}$. I proceeded by assuming that the volume is $xyz$ and used a Lagrange multiplier to start with $$xyz+\lambda \left(\frac{x^2}{a^2}+\frac{y^2}{b^2}+\frac{z^2}{c^2}-1\right)$$ I proceeded further to arrive at $\frac{abc}{3\sqrt3}$. Somehow I seemed to be have missed $8$. Can someone please tell me where I did go wrong?,"['optimization', 'multivariable-calculus', 'volume', 'lagrange-multiplier']"
617189,"""clopen"" terminology: acceptable?","I like the term ""clopen"" (a set which is both open and closed in a topological space), though an instructor of mine hated it when I used it recently. (Approximately, ""never, ever use that again."") Is this common? Was the term introduced relatively recently, so perhaps age has something to do with it, or is this a random occurrence? Really, are there enough people who dislike or don't know ""clopen"" that I should switch to the barely longer ""closed and open""?","['general-topology', 'terminology']"
617199,Any two groups of three elements are isomorphic - Fraleigh p. 47 4.25(b),"The answer has no details. Hence maybe the answer is supposed to be quick. But I can't see it? Hence I took two groups. Call them $G_1 = \{a, b, c\}, G_2 = \{d, e, f\}$. Then because every group has an identity, I know $G_1, G_2$ has one each. Hence WLOG pick $c$ as the identity in $G_1$. I want to match letters so pick $e$  as the identity in $G_2$.
Now we have $G_1 = \{a, b, \color{magenta}{c}\}, G_2 = \{d, \color{magenta}{e}, f\}$. I know every group has an inverse. But how do I apply this to $G_1, G_2$ to simplify them? And to prove $G_1, G_2$ are isomorphic, how do I envisage and envision what the isomorphism is? Update Dec. 25, 2013 (1). Answer from B.S. Why does $ab = b$ fail? 
$\begin{align} ab & = b \\ & = bc \end{align}$. What now? (2.) Do I have to do all the algebra work for $G_1$ for $G_2$? Is there some smart answer? Update Jan. 8, 2014 (1.) I'm confounded by drhab's comment on Dec. 30 2013. Is drhab saying: Even if the domain's identity is the $\color{green}{third}$ letter $\color{magenta}{c}$  but the codomain's identity is the second letter $\color{magenta}{e}$, $d^{\huge{\color{green}{3}}} = e$ anyways? Hence I should've chosen the $\color{green}{third}$  letter in the codomain as the identity too? What else is drhab saying about this? (2.) I don't understand drhab's comment on Dec. 28 2013. Why refer to commutativity? It's not a group axiom? And what are the binary operations? Update: I didn't realize this before, but by dint of Martin Sleziak's comment, this question is just a sepcial case of Fraleigh p. 63 Theorem 6.10 = Pinter p. 109-111 Theorem 11.1.","['finite-groups', 'group-theory']"
617202,"Metric Space, Normed Space, and Inner Product space hierarcy","I'm having trouble understanding the intuition of the hierarchy of metric space, normed space, and inner product space. What additional structure do I gain at every level? I'm going to list my understanding, I hope others can either fill in more detail or verify that my understanding is correct. Ok: A metric space gives me a notion of distance A normed space introduces a metric to a VS. So it buys me a notion of vector magnitude. An inner product space enforces a particular norm. This norm, by virtue of being an inner product space, is also a linear functional. I can explicitly leverage my notion of magnitude with my linear functional to build a description of my VS (e.g. compute basis vectors, compute dimension, etc.). I had no way to do this before. Essentially, I have some generic dot product. is this right?","['metric-spaces', 'functional-analysis']"
617221,How to find the radius of convergence?,The function is $\dfrac {z-z^3}{\sin {\pi z}} $. How to find the radius of convergence in $ z=0 $?,"['power-series', 'convergence-divergence', 'sequences-and-series', 'analysis', 'complex-analysis']"
617253,"Terminology for functions with $F(a,a,\dots,a) = a$","Is there a commonly used terminology for functions $F : \mathbb{R}^n \rightarrow \mathbb{R}$ such that if $x \in \mathbb{R}^n$ and $x_i = a$ for all $i\in \{1,\dots, n\}$, $F(x) = a$ ?","['terminology', 'functions']"
617255,Number made from the first digits of $2^n$,"Consider the number c made from the first digits of $2^n$ . To be more precise, the $n$ -th decimal digit of $c$ is the first digit of $2^n$ . The first digits from $c$ are : $0.24813612512481361251248136125124813612512481371251249137125124913712512491371361
24913713612491371361$ At first sight, the number appears to be rational because apparent patterns appear
showing periods. In fact, the continued fraction of $c$ has very large convergents.
I calculated the first $20 000$ digits from $c$ with PARI and found a convergent with
amazing $5817$ digits! The terms afterwards are totally normal. This leads to the
conjecture that $c$ is transcendental. Has anyone an idea how this can be proven ? A similar situation is observed in champernowne's constant constant $0.12345678910111213...$ I read in the internet that this number also has extreme convergents without
having obvious periods. Does anyone know why the large convergents occur ?","['transcendental-numbers', 'continued-fractions', 'number-theory']"
617260,Uniform integrability (show an equivalence),"Let $(\Omega,\mathcal{A},\mu)$ be a measurable space and $\mathcal{F}$ a set of measurable  functions. Show: If $\mu(\Omega)<\infty$, $\mathcal{F}$ is uniformly integrable exactly then, when for any $\varepsilon > 0$ there exists a constant $a_{\varepsilon}>0$ so that 
    $$
\sup_{f\in\mathcal{F}}\int 1_{\lvert f\rvert\geq a_{\varepsilon}}\lvert f\rvert\, d\mu<\varepsilon.
$$ Hello! For the direction ""$\Leftarrow$"" my idea is to use Uniform integrability of a set of measurable functions (show an equivalence) , because: Consider any $\varepsilon > 0$ and any $f\in\mathcal{F}$, then 
$$
(\lvert f\rvert - a_{\varepsilon})^+\leq 1_{\lvert f\rvert\geq a_{\varepsilon}}\lvert f\rvert
$$
and so
$$
\int (\lvert f\rvert-a_{\varepsilon})^+\, d\mu\leq\int 1_{\lvert f\rvert\geq a_{\varepsilon}}\lvert f\rvert\, d\mu\leq\sup_{f\in\mathcal{F}}\int 1_{\lvert f\rvert\geq a_{\varepsilon}}\lvert f\rvert\, d\mu<\varepsilon,
$$
and therefore 
$$
\sup_{f\in\mathcal{F}}\int (\lvert f\rvert-a_{\varepsilon})^+\, d\mu<\varepsilon
$$
which means (relating to the given link), that $\mathcal{F}$ is uniformly integrable, because $a_{\varepsilon}$ is the required non-negative, integrable function. For the other direction my idea is the following: Let $\mathcal{F}$ be uniformly integrable. Consider any $\varepsilon >0$. Then it exists a non-negative, integrable function $h$ so that
$$
\sup_{f\in\mathcal{F}}\int 1_{\lvert f\rvert\geq h}\lvert f\rvert\, d\mu<\varepsilon/2.
$$
Now choose $a_{\varepsilon}$, so that
$$
\int 1_{h\geq a_{\varepsilon}}h\, d\mu<\varepsilon/2.
$$
To my opinion it is
$$
1_{\lvert f\rvert\geq a_{\varepsilon}}\lvert f\rvert\leq 1_{\lvert f\rvert\geq h}\lvert f\rvert+1_{h\geq a_{\varepsilon}}h,
$$
so it is
$$
\int 1_{\lvert f\rvert\geq a_{\varepsilon}}\lvert f\rvert\, d\mu\leq\int 1_{\lvert f\rvert\geq h}\lvert f\rvert\, d\mu+\int 1_{h\geq a_{\varepsilon}}h\, d\mu\\\leq \sup_{f\in\mathcal{F}}\int 1_{\lvert f\rvert\geq h}\lvert f\rvert\, d\mu+\int 1_{h\geq a_{\varepsilon}}h\, d\mu<\varepsilon/2 + \varepsilon/2=\varepsilon.
$$ But where do I have to use that $\mu(\Omega)<\infty$? To my opinion it is necessary for the direction ""$\Leftarrow$"", because $a_{\varepsilon}$ is only integrable if $\mu(\Omega)<\infty$, because then
$$
\int\lvert a_{\varepsilon}\rvert\, d\mu=a_{\varepsilon}\mu(\Omega)<\infty.
$$
Are there more points in the proof, where I need $\mu(\Omega)<\infty$? By the way: What do you think about my proof? Sincerely yours, math12","['uniform-integrability', 'measure-theory', 'solution-verification']"
617269,"Confusion about $E(B(t)^2)$, $E(B(t)^3)$ and $E(e^{\sigma B(t)})$ where $(B(t))$ is a Brownian motion","This is about expectations of brownian motion and how they are connected to normal distribution. I know that $B(t)$ is normal with mean $t$ and variance $t$ and that $E(B(t))=0$ if $(B(t))$ is a standard brownian motion since $B(t)$ has mean $0$ and variance $t$), but why is $E(B(t)^2)=t$? Another example is why is $E(\exp(\sigma B(t)))=\exp(\sigma^2t/2)$, for $\sigma >0 $? So, what would be $E(B(t)^3)$, for example? Or, if you have another useful example to help me understand that would be great.","['probability-theory', 'normal-distribution', 'brownian-motion']"
617274,An exercise about p-solvable,"I'm dealing with a problem about p-solvable in Isaac's finite group theory book. Question is the following: ""Let $G$ be $p-$solvable and $P \in Sy{l_p}\left( G \right)$ and $K \le G$ such that $p$ doesn't divide $\left| K \right|$. Suppose that $P \le {N_G}\left( K \right)$. Show that $K \le {O_{p'}}\left( G \right)$."" There is a hint.
Hint: Firstly, consider the case ${O_{p'}}\left( G \right) = 1$. For general case, consider the quotient group $G$/${O_{p'}}\left( G \right) $. I hope some of you can answer me.","['finite-groups', 'group-theory']"
617275,Conjugate convex functions property,"$E$ is normed vector space.Let $f\in E^*$ in a bounded linear functional from $E$ to $C$ and fix $x\in E$. We have $$\forall y\in E;\ \ \ \    f(y-x)\leq \frac{1}{2}\|y\|^2-\frac{1}{2}\|x\|^2$$
 And I have proven $f(x)=\|x\|^2$ and $\|x\|\leq \|f\|$. Prove that $\|f\|=\|x\|$.","['convex-analysis', 'operator-theory', 'real-analysis', 'analysis', 'functional-analysis']"
617288,Action on G via Automorphism,"Here is an exercise from Isaacs, Finite Group Theory, $4D.1$: Let $A$ act on $G$ via automorphism, and assume that $N \trianglelefteq G$ admits $A$ and that $N \geq C_G(N)$. Assume that $(|A|,|N|)=1$. If $A$ acts trivially on $N$, show that its action on $G$ is trivial. Hint: Show that $[G,A]\leq N$ and consider $C_\Gamma(N)$ where $\Gamma=G\rtimes A$ I couldn't get the way how i can use the hint","['finite-groups', 'group-theory']"
617292,"How to show that $\mathcal{O}(1)$ is generated by the global sections $x_1, \ldots, x_n$?","On page 150 of Algebraic Geometry by Hartshorne, line 4 of paragraph 2, it is said that $\mathcal{O}(1)$ is generated by the global sections $x_1, \ldots, x_n$. How to show that $\mathcal{O}(1)$ is generated by the global sections $x_1, \ldots, x_n$? By definition, $\mathcal{O}(1) = \widetilde{S(1)}$, $S=k[x_0, \ldots, x_n]$. Let $U_i=\{(x_0, \ldots, x_n): x_i \neq 0\}$ be the open covering of $\mathbb{P}^{n}_k$. Then $\mathcal{O}(1)(U_i)$ is the set of functions $s: U_i \to \sqcup_{p \in U_i} S(1)_{p}$ such that $s(p) \in S(1)_p$ and $s$ satisfies some properties. I think that $S(1)_n = S_{n+1}$. Therefore $S(1)_0 = S_1 = \sum_{i=0}^{n} k x_i$. But how to show that $\mathcal{O}(1)$ is generated by the global sections $x_1, \ldots, x_n$? Thank you very much.",['algebraic-geometry']
617297,Prove that $|\sin n|+|\sin (n+1)| > 2\sin(1/2)$ for all $n\in \mathbb N$,"Show that
  $$|\sin{(n)}|+|\sin{(n+1)}|>2\sin{\dfrac{1}{2}},n \ge 1,n\in \mathbb N$$ My try: let
$$F(n)=|\sin{(n)}|+|\sin{(n+1)}|$$
then
$$F(n+\pi)=|\sin{(n+\pi)}|+|\sin{(n+\pi+1)}|=|\sin{(n)}|+|\sin{(n+1)}|=F(n)$$
and
$$F(\pi-n)=|\sin{(\pi-n)}|+|\sin{(\pi-n+1)}|=|\sin{n}|+|\sin{(n-1)}|\neq F(n)$$
so we must prove when $n\in (0,\pi)$,
have 
$$F(n)>2\sin{\dfrac{1}{2}}$$
when
$n\in (0,\pi-1)$,then
$$F(n)=\sin{n}+\sin{(n+1)}=\sin{n}(1+\cos{1})+\sin{1}\cos{n}$$
and
$n\in(\pi-1,\pi)$,then
$$F(n)=\sin{n}-\sin{(n+1)}$$
How prove it this two case have $F(n)>2\sin{\dfrac{1}{2}}$? Thank you and I know this well know inequality
$$|\sin{x}|+|\sin{(x+1)}|+|\sin{(x-1)}|\ge 2\sin{1},x\in \mathbb R$$","['inequality', 'trigonometry', 'calculus', 'algebra-precalculus']"
617301,The problem of the most visited point.,"Represent the set $R_{n\times n}=\{1,2,\ldots, n\}\times\{1,2,\ldots, n\} $ as a rectangle of $n$ by $n$ points as in the figures below for example. How to calculate the number of circuits that visit a chosen point in this rectangle? What is the most visited point on this rectangle? Making the question more precise we fix the settings below. A circuitc $c$ in rectangle $R_{n\times n}$ is defined as a sequence of distinct points $x_{i_1j_1}, x_{i_2j_2},x_{i_2j_2},\ldots, x_{i_{m-1}j_{m-1}}$ and a point $x_{i_{m}j_{m}}=x_{i_{1}j_{1}}$  in $R_{n\times n}$ such that $|i_{k}-i_{k+1}|+|j_{k}-j_{k+1}|=1$ for $k=1,\ldots, m-1$. A circuit $c=\{x_{i_1j_1}, x_{i_2j_2},x_{i_2j_2},\ldots, x_{i_{m-1}j_{m-1}},x_{i_{m}j_{m}}\}$ visit a point $x_{ij}$ if $x_{ij}\in c$. Let $N_n(x_{ij})$ the total circuits in $R_{n\times n}$ who visit the point $x_{ij}$ . Question. How to calculate the value of $N_n(x_{ij})$? If we draw a circuit randomly 
   which  point $x_{ij}$ has the highest probability to be visited? Calculations case $n = 1,2,3$ are trivial. I'm trying to calculate the number $N_n(x_{ij})$ by a recursive procedure which reduces the calculation for the case $n$ to $n-1$. But I think the use of this recursion depends on some well-crafted trick that escaped my attempts.","['recursion', 'probability-theory', 'percolation', 'probability', 'combinatorics']"
617305,How to solve $(f'(x+1)+f'(x-1))f(x)-(f(x+1)+f(x-1))f'(x)=0$,$$(f'(x+1)+f'(x-1))f(x)-(f(x+1)+f(x-1))f'(x)=0$$ I don't have any ideas about the solution of this problem. How can I solve this differential equation?,"['ordinary-differential-equations', 'functional-equations']"
617319,Selection of $b_n$ in Limit Comparison Test for checking convergence of a series,I wonder what the correct criterion for selection of $b_n$ in Limit Comparison Test for checking convergence of a series. Any hint to online material will be highly appreciated. The selection of $b_n$ in first series is easy but in other three is tricky. Is there any universal criterion for selection of $b_n$? Thanks in advance for your help. $\sum_{1}^{\infty}\frac{\sqrt{n}}{1+n}$ then $b_{n}=\frac{\sqrt{n}}{n}=\frac{1}{\sqrt{n}}$ $\sum_{1}^{\infty}\frac{\ln n}{n}$ then $b_{n}=\frac{1}{n}$ $\sum_{1}^{\infty}\sin(\frac{\pi}{n})$ then $b_{n}=\frac{\pi}{n}$ $\sum_{1}^{\infty}\frac{\ln\left(n+1\right)}{n^{2}}$ then $b_{n}=\frac{1}{n^{\frac{3}{2}}}$,"['convergence-divergence', 'limits']"
617321,Graph with sharply 1-transitive automorphism group,"What finite Graphs $G$ have the property that for all $v,w\in G$, there is exactly one automorphism $\phi$ of $G$ with $\phi(v)=w$? Of course, each of the three graphs with one or two vertices have this property, but are there any other examples?","['graph-theory', 'group-theory', 'group-actions', 'combinatorics']"
617325,Is every Lie group the automorphism group of a riemannian manifold?,"Given a finite-dimensional Lie Group $G$, is there always a Riemannian manifold $M$, such that $G$ is the group of isometries of $M$?","['lie-groups', 'riemannian-geometry', 'group-theory']"
617329,"How to prove $f'(\xi)=a$ ,if $ f(0)=0,f(a)=a,f'(x_{0})=0$?","let $a\in (0,1)$,and $f(x)$ is continuous on $[0,a]$, and is 
differentiable on $(0,a)$, and $x_{0}\in (0,a)$,such $f'(x_{0})=0$,and 
such
$$f(0)=0, f(a)=a$$
show that
there exsit $\xi\in(0,a)$,such
$$f'(\xi)=a$$ My try: I want to put
$$F(x)=f(x)-ax$$
since
$$F(0)=f(0)-0=0$$
so
if we find another point $c\in(0,a)$ such that $F(c)=f(c)-ac$ then we can use Rolle theorem to prove it. Now How to prove there exist $c\in(0,a)$,such that $f(c)=ac$ maybe this method is not useful,Thank you.",['analysis']
617332,Question about matrices whose row and column sums are zero,"I am interested in $n \times n$ matrices over some field $K$ all whose rows and all whose columns sum to zero. First question: do these matrices have a name? Pending an answer I will call these ""null-matrices"". Second (main) question: Given $n$, are there subsets $J \subset \{1, \ldots n\} \times \{1, \ldots, n\}$ of indices such that 
$$\sum_{(i, j) \in J} a_{i,j} = 0$$
for every null-matrix $(a_{ij})_{i, j = 1 \ldots n}$? More visually: can you take a red pencil and put red circles around some entries in a an (still empty) matrix so that in whichever way someone fills up the matrix with elements of $K$ to obtain a null-matrix, the sum of the red-circled entries will always add up to zero? Obviously the answer is yes, just take $J$ to be a disjoint union of rows or a disjoint union of columns. So my question is: are there examples of set $J$ that are not of this form? In general (i.e. without specifying the field over which we consider the matrix) I expect the answer to be no (but please prove me wrong) - however for some special combinations of $n$ and char($K$) the answer might be yes. In particular, for $n = 2$, char($K$) $=2$, the diagonal (i.e. $J = \{(1, 1), (2,2)\}$) is an example of the type of set I'm looking for. Are there more examples like this?","['matrices', 'positive-characteristic', 'combinatorics']"
