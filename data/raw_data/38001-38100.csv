question_id,title,body,tags
369754,Notation Clarification of Koch Curve,"I am having trouble making sense of the notation used to describe the Koch Curve in the book Getting Aquanted with Fractals . The link will take you to a preview of the book which describes the notation. I am looking at section $1.1.2$ titled The Koch Curve . At each iteration of $f$ applied to $A_{(k)}$, what does $A_{j_1,\ldots.j_k}$ mean? Specifically, what does $A_{j_1, j_2}$ mean in light of $A_{(2)}$? How does this describe the curve? I think a great answer would be to walk through the first few iterations of the Koch Curve explaining what the $A_{j_1, j_2, \ldots, j_k}$ mean. All help is greatly appreciated!","['notation', 'fractals', 'analysis']"
369763,Snapped quadrilateral is never concave?,"Is there a proof or disproof that the quadrilateral resulting from snapping each corner of an arbitrary rectangle to the nearest point on a regular square grid is never concave? Arbitrary, note e.g. any orientation.",['geometry']
369792,What is the rationale for the factor of $4$ in the Conics parabola equation?,"The Conics form of a parabola equation is $4p(y-k)=(x-h)^2$ where $(h,k)$ is the vertex of the parabola and $p$ is the distance from the vertex to the focus. (Which is also the same distance from the vertex to the directrix).  My question is where does this factor of $4$ come from?","['conic-sections', 'algebraic-geometry', 'algebra-precalculus']"
369793,Relation between factor graph and conditional probability distribution,"First, I'm from computer science. I don't know how to say this problem in a mathematical way. So please bear with me. The question Let say I have a factor graph illustrated in the figure. The variables are $w,t,a$. The domain for $w,t,a$ is $\{0,1\},\{0,1,2\}$ and $\{0,1,2\}$ respectively. For the factors $h,g$, I know how to assign functions to them. For $h$, it can take a probability density function: $Pr(0) = 0.7, Pr(1)=0.3$. For $g$, it can be $Pr(0) = 0.2,Pr(1) = 0.3, Pr(2) = 0.5$. (Correct me if these assignments are wrong) Then, I don't know how to assign a function to the factor $f$. Is it the conditional probability distribution function $p(t|w,a)$ ? 
If this is the case, do I need to define these three functions $p(t=0|w,a),p(t=1|w,a),p(t=2|w,a)$ given all possible values of $w$ and $a$ ? The setting The real world setting is the following: A user $w$ needs to label a data item $t$ to its correct value. The values which a data item $t$ can take are $0,1,2$. The value of the user can be $0,1$ - 0 means unreliable and 1 means reliable. $a$ is the label that the user have assigned to the data item. Therefore, I think $a$ is an observed variable and it can only take one value. From the factor graph and these values, I want to find the reliability of the user and the probability of correctness for each value of the data item. Please enlighten me. Thanks.","['probability-theory', 'machine-learning', 'random-variables']"
369806,Constant Rank theorem for domain with nonempty boundary,"Problem 4-3 in J.M. Lee's introductory text about smooth manifolds, asks to formulate and prove a version of the constant rank theorem for a map of constant rank whose domain is a smooth manifold with boundary. That is, show that, If $F:M\rightarrow N$ is smooth, $N$ with empty boundary, $F$ of constant rank $r$, then, for every point $p$ in $M$, $F$ has a local representation of the form $\tilde{F}(x)=(x_1, ...,x_r,0,...,0)$ Lee gives a hint: After extending $F$ (the interesting case is when $p\in\partial M$), follow the proof of the regular constant rank theorem,  until you have to make use of the constant rank hypothesis. The problem may be that the extension has higher rank. Lee's hint is to modify the map so that it has constant rank. I don't see how to do this. (If it's a silly question, I'm sorry, I haven't slept in over 24hs.)","['manifolds', 'differential-geometry']"
369812,Is this incidence variety in $\mathbb{P}^2 \times \mathbb{P}^2$ isomorphic to a variety in $\mathbb{P}^1 \times \mathbb{P}^1$?,"I have an incidence variety $X = \{(p,\ell) \in C \times D^* : p \in \ell\} \subset \mathbb{P}^2 \times \mathbb{P}^2$, where $C = Z(f) \subset \mathbb{P}^2$ and $D^* = Z(g^*) \subset \mathbb{P}^2$ are two conics ($D^*$ is the dual conic of the conic $D = Z(g)$). From Hartshorne exercise I.3.1(c) I know that every conic is isomorphic to $\mathbb{P}^1$. Can I use this to write $X$ as a variety in $\mathbb{P}^1 \times \mathbb{P}^1$? If so, what equations would define this variety? Thanks in advance.",['algebraic-geometry']
369839,What is the difference between integrals and contour integrals?,I understand integrals but what are contour integrals?,"['complex-analysis', 'contour-integration']"
369845,Question about derivative,"I need to check whether I've done it correctly To find whether a point is maximum of function $f(x)$, we have to checked whether $f''(x)>0, f''(x)=0$ or $f''(x)<0?$ To find the inflection point of the function, we have to find, $f''(x)=0, f'(x)=0,$ $f(x)=0.$ When choose the value of $\sqrt{(64,3)},$ $X_o$ has the value: $64, 0,3$ or $X_o>64.$ My answers are the following. $1. f''(x)<0$ $2. f''(x)=0$ $3. X_o = 64.$",['derivatives']
369846,Integer solutions of $x^3+y^3=z^2$,"Is there any integer solution other than $(x,y,z)=(1,2,3)$ for $x^3+y^3=z^2$?",['number-theory']
369859,Cardinality of the borel measurable functions?,"Using Lebesgue measurable set which is uncountable, one can show that the cardinality of the set of all Lebesgue measurable functions is $2^\mathbb{R}$ I know that Borel $\sigma$-algebra on $\mathbb{R}$ is of cardinality $\mathbb{R}$ (even if I haven't read proof). Then how can I show that the cardinality of the set of all borel measurable functions is $\mathbb{R}$?","['descriptive-set-theory', 'real-analysis']"
369862,Group of order 100: 1 or 3 subgroups of order 50?,"Show that every group of order 100 has a subgroup of order 50. Show also that the
  number of subgroups of order 50 is either 1 or 3. For the first part I did the following: As $|G|=100=2^2 5^2$ we can deduce from Sylow's Theorems that $G$ has a normal subgroup $N$ of order 25 (normal because there is only one). There is also a subgroup $H$ of order 2 (as 2 divides 100). Since $N$ is normal there holds $NH=HN$. So $NH$ is in fact a subgroup, which has order 50. But I am puzzled as to why there are either 1 or 3 such subgroups.","['sylow-theory', 'group-theory']"
369870,Hopf's theorem on CMC surfaces,"I got stuck reading the proof of the following theorem: Theorem (Heinz Hopf) Let $X: S^2\to \mathbb R^3$ be a constant mean curvature immersion. Then $X(S^2)$ is a round sphere. Proof: Let $g_{S^3}$ denote the round metric on $S^2$ (such that the area is $4\pi$). By the uniformization theorem there exists a map $\phi: S^2 \to S^2$ such that $(X\circ \phi)^\ast g_{\mathbb R^3}$ is conformal to $g_{S^2}$. Hence we may assume that $X$ is a conformal map $(S^2, g_{S^2}) \to (\mathbb R^3, g_{\mathbb R^3})$. Let $\pi: (\mathbb R^2, g_{\mathbb R^2})\to (S^2\setminus \{pt\}, g_{S^2})$ be stereographic projection. Let $Y = X\circ \pi$. Then $Y$ is a conformal immersion from $\mathbb R^2$ to $\mathbb R^3$. If $\nu = \nu^\alpha e_\alpha$ denotes the unit normal vector field along this immersion, then $\Delta \nu^\alpha + |h|^2 \nu^\alpha = 0$, where $\Delta = \frac{\partial^2}{\partial u^2} + \frac{\partial^2}{\partial v^2}$ is the usual Laplacian and where $|h|^2$ is the length of the second fundamental form tensor along the immersion. Edit: Here is the remainder of the proof (from memory). In particular, this shows that $\Delta \nu$ is parallel to $\nu$. Identifying $\mathbb R^2\cong \mathbb C$ and using complex notation ${\partial_z} = \frac 12 \left(\frac{\partial }{\partial u} - i\frac{\partial}{\partial v}\right)$, $\overline{\partial_z} = \frac 12 \left(\frac{\partial }{\partial u} + i\frac{\partial}{\partial v}\right)$, we have $\Delta \nu = 4 \partial_z\overline{\partial_z}\nu$. Note that $\partial_z\nu \perp \nu$, whence $\partial_z\nu \perp \Delta \nu$. It follows that 
$$\overline{\partial_z} (\partial_z\nu)^2 = 2 \partial_z \nu \cdot \partial_z\overline{\partial_z}\nu = \frac 12 \partial_z \nu \cdot \Delta \nu = 0.$$
This implies that the complex-valued function $z\mapsto (\partial_z\nu)^2$ is holomorphic. Here $$(\partial_z \nu )^2 = (\partial_u\nu - i \partial_v \nu)^2 = (|\partial_u\nu|^2 - |\partial_v\nu|^2) - 2i \partial_u \nu \cdot \partial_v\nu.$$ It now follows from the conformal invariance of the Dirichlet energy $E(u) = \int_M |\nabla u|^2 \, \mathrm{dvol_g}$ that $\int_{\mathbb R^2} |(\partial_z \nu)^2| \, < \infty$. Indeed, the Dirichlet energy of $\nu$ over $\mathbb R^2$ (with respect to the Euclidean metric), bounds $\int_{\mathbb R^2} |(\partial_z \nu)^2|$. Now $\nu$ can be pulled-back to a vector field on the sphere via stereographic projection (which is conformal), and the Dirichlet energy can be calculated there (with respect to the round metric). But the pull-back of $\nu$ extends to a smooth vector field on all of $S^2$, and $S^2$ is compact. Therefore its Dirichlet energy must be finite. It follows from $\int_{\mathbb R^2}|(\partial_z \nu)^2|<\infty$, that the (holomorphic) function $(\partial_z\nu)^2$ is identically $0$. This is equivalent to $|\partial_u \nu| = |\partial_v\nu|$ and $\partial_u \nu \cdot \partial_v \nu = 0$. Write $\partial_u \nu = h^u_u \partial_u Y + h^v_u \partial_v Y$, $\partial_v \nu = h^u_v \partial_u Y + h_v^v\partial_v Y$. It follows from the conformality of $Y$ together with the above, that $h^u_v H = h^u_v (h^u_u + h^v_v) = 0$, $|h^u_u| = |h^v_v|$. This is only possible if $h^u_u = h^v_v = H/2$ and $h^u_v = 0$. But then $\partial_u \nu = H/2 \partial_u Y$ and $\partial_v \nu = H/2\partial_v Y$, imply that $Y = c + 2/H \nu$ for some constant vector $c$. This shows that $Y$, and by continuity also $X$, map into a sphere. $X$ is onto, because it is open (being an immersion) and closed (being continuous, mapping from a compact set). I don't see how to show that $\Delta \nu^\alpha + |h|^2\nu^\alpha = 0$? Thanks for your help! Any ideas are welcome.","['riemann-surfaces', 'riemannian-geometry', 'conformal-geometry', 'differential-geometry']"
369880,General questions about Parametric equations,"My textbook doesn't explain this very well, so what I want to know is: What is the purpose of parametric equations? What is a parameter? What is the advantage of these equations over a function y=f(x)? What do they essentially enable you to do? I find this topic to be impenetrable so a thorough explanation in simple terms would be very much appreciated. Thank you.","['parametric', 'algebra-precalculus']"
369890,Please tell me what I am doing wrong for this multivariable Calculus Problem,"Suppose $F =(2x−4y)i +(x+3y)j$. Use Stokes' Theorem to make the following circulation calculations: (a) Find the circulation of $F$ around the circle $C$ of radius $10$ centered at the origin in the $xy$-plane, oriented clockwise as viewed from the positive $z$-axis. Circulation = $\int_CF\cdot dr$ Here is my work: Please tell me the correct answer and what I am doing wrong: $$
\begin{align*}
\int_C F\cdot dr&= \int\int_S \text{curl} F · dS & \text{by Stokes' Theorem} \\
&= \int\int\langle 0, 0, 5\rangle \cdot \langle 0, 0, 1\rangle~dA & \text{since the circle lies on }z = 0 \\
&= 5 * (\text{Area of }C) \\
&= 5 * 100π \\
&= 500π.
\end{align*}
$$",['multivariable-calculus']
369931,Show that $(1-\frac{1}{n})^{\sum_{i=1}^n X_i}$ is an unbiased estimator of $\tau(\theta)=e^{-\lambda}$,"Let $S=\sum_{i=1}^n X_i$ than show that $T(X_1,\ldots,X_n)= \left(1-\frac{1}{n}\right)^{\sum_{i=1}^n X_i}$ is an unbiased estimator of $\tau(\theta)=e^{-\lambda}$ where $X_1,\ldots,X_n$ are IID from POI($\lambda$) with $n>1$.","['statistics', 'statistical-inference']"
369932,"$G$ fin ab group, acts faithfully, transitively on $X$, then $|X|=|G|$","Let $G$ be a finite abelian group. Suppose that $G$ acts faithfully and transitively on a set $X$. Show that $|X|=|G|$. Deduce that the action is equivalent to the action of $G$ on itself by left translation. Because $G$ acts transitively on $X$, the Orbit-Stabilizer Theorem tells us $|G|=|X|\cdot|H_x|$, where $H_x$ is a point stabiliser for $x\in X$. Now let $y\in X$ be fixed and choose any $x\in X$, then $\exists g\in G$ such that $gx=y$ (because of transitivity). Let $h\in H_y$, then $gx=y$ implies $hgx=hy=y=gx$, and because $G$ is abelian: $ghx=gx\Rightarrow hx=x$. So $h\in H_x$ for any $x\in X$. But $\bigcap_{x\in X} H_x =\{e\}$ since $G$ acts faithfully. So $H_x=\{e\}$ for every $x\in X$, and $|G|=|X|\cdot|H_x|$ gives the result. But how does one deduce that the action is equivalent to the action of $G$ on itself by left translation?","['finite-groups', 'group-theory', 'abelian-groups']"
369949,"Evaluate $\int_{-\infty}^\infty x\cdot\exp(-x^2+ix)\,dx$ using complex analysis.","It is easy to evaluate $\int_{-\infty}^\infty x\cdot\exp(-x^2+ix)\,dx$ without using complex analysis, i.e., $\int_{-\infty}^\infty x\cdot\exp(-x^2+ix)\,dx=\exp(-\frac{1}{4})\int_{-\infty}^\infty x\cdot\exp(-(x-\frac{1}{2}i)^2)\,dx$ and then use substitution to get the answer $\exp(-\frac{1}{4})\frac{i}{2}\sqrt{\pi}$. If we want to evaluate it using complex analysis, I know we need to construct a contour so that I can apply Cauchy integral formula (since there is no pole here so that we cannot use Residue theorem). However, I cannot find a contour and the functions to integrate on the complex plane so that the contour follows the part of the complex plane that describes the real-valued integral. Any suggestion or hint will be highly appreciated.","['integration', 'complex-analysis']"
369951,"Sequence of matrices, equivalent conditions","I am trying to prove that: Let $B$ be a square matrix. The following conditions are equivalent: $\lim\limits_{k\rightarrow\infty}B^k = 0$ $\lim\limits_{k\rightarrow\infty}B^kv = 0$ for every vector $v$ $\rho(B)<1$ $\|B\| < 1$ for at least one subordinate matrix norm $\|\cdot\|$ The matrix $(I-B)$ is invertible and $$(I-B)^{-1}\ =\ \lim_{k\rightarrow\infty}(I + B + \ldots + B^k).$$ The matrix $(I-B)$ is invertible and all the eigenvalues of the matrix $(I+2(B-I)^{-1})$ have negative real part. There exists a positive definite Hermitian matrix $H$ such that the (Hermitian) matrix $(H-B^*HB)$ is positive definite. Given any matrix norm $\|\cdot\|$ , there exists an integer $l$ such that $\|B^l\| < 1$ . I already proved almost all, the only proof that I need is (whatever) $\Rightarrow (7)$ ,
but I really don't know how do it. Please, somebody help me. Thanks in advance.","['matrices', 'linear-algebra', 'sequences-and-series']"
369958,"I need to find the value of $a,b \in \mathbb R$ such that the given limit is true","I am given that $\lim_{x \to \infty} \sqrt[3]{8x^3+ax^2}-bx=1$ need to find the value of $a,b \in \mathbb R$ such  that the given limit is true. I was able to work the whole thing out, but I have a question about one step in my work. There is a lot of rough work because I simplify by using the rule of the difference of cubes, so here is a condensed part of my work:
$$\begin{align} \lim_{x \to \infty} \sqrt[3]{8x^3+ax^2}-bx &=\lim_{x \to \infty} \frac{8x^3+ax^2-b^3x^3}{(\sqrt[3]{8x^3+ax^2})^2+bx\sqrt[3]{8x^3+ax^2}+b^2x^2} \\&= \lim_{x \to \infty} \frac{8+a\frac{1}{x}-b^3}{\frac{1}{x^3}(\sqrt[3]{8x^3+ax^2})^2+b\frac{1}{x^2}\sqrt[3]{8x^3+ax^2}+b^2\frac{1}{x}} \\&=\frac{\lim_{x \to \infty}8+\lim_{x \to \infty}a\frac{1}{x}-\lim_{x \to \infty}b^3}{\lim_{x \to \infty}\frac{1}{x^3}(\sqrt[3]{8x^3+ax^2})^2+\lim_{x \to \infty}b\frac{1}{x^2}\sqrt[3]{8x^3+ax^2}+\lim_{x \to \infty}b^2\frac{1}{x}} \\&= \frac{8-b^3}{0+0+0} \\&= \frac{8-b^3}{0}\end{align}$$ Thus $8-n^3$ must also equal $0$ which implies that $b=2$. (This is the part I am unsure about. Is what I said true? If $b=2$ then this would give me an indeterminate form, but other than that I'm not sure if what I said holds, and if it does hold why does it hold?) Regardless of my uncertainty, I went on and using this assumption I found that $a=12$ in a similar manner, and when I check $\lim_{x \to \infty} \sqrt[3]{8x^3+12x^2}-2x$ it does equal $1$ . Any help as to why/why not my assumption is correct? 
Thanks in advance! (If anyone wants me to post the method as to how i got 12 for $a$, let me know and then I'll type it up).","['real-analysis', 'limits']"
369971,"""Tricky"" wording on Congruence Modulo Question?","I'm asked for all possible values, but I can only see one. The question on my practice exam reads: Consider the equivalence class [3] for the equivalence relation ""congruence modulo $7$"" on $\Bbb Z$. Suppose that $S = {1, 2, ..., N}$, where $N$ is a positive integer. Find all possible values of $N$ so that $[3] \cap S$ contains exactly $10$ elements. As I see it, $S$ must be $\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\}$, so all possible values of $N$ are $12$? $3$ and $10$ and members of $[3]$, but $13$ is not, so any higher values would have more than $10$ elements.","['modular-arithmetic', 'equivalence-relations', 'discrete-mathematics', 'elementary-set-theory']"
369981,Looking for help understanding the Möbius Inversion Formula,"I was recently told that the Möbius Inversion Formula can be applied to the Chebyshev Function. Let $\vartheta(x)$,$\psi(x)$ be the first and second Chebyshev functions so that: $$\vartheta(x) = \sum_{p\le{x}}\log p$$ $$\psi(x) = \sum_{n=1}^{\infty}\vartheta(\sqrt[n]{x})$$ Then applying the Möbius Inversion Formula , we get: $$\vartheta(x) = \sum_{k=1}^{\infty}\mu(k)\psi(\sqrt[k]{x}) = \psi(x) - \psi(\sqrt{x}) -\psi(\sqrt[3]{x}) -\psi(\sqrt[5]{x}) + \psi(\sqrt[6]{x}) + \ldots$$ As I understand it, Möbius Inversion Formula can only be applied to functions of the following form: $$g(n) = \sum_{d\,\mid \,n}f(d)$$ With the inversion being of the form: $$f(n)=\sum_{d\,\mid\, n}\mu(d)g(n/d)$$ So, I'm not clear how the inversion formula can be applied to the Chebyshev functions. If someone could help me to understand why the inversion formula can be applied in this situation, that will really help. Thanks, -Larry","['chebyshev-function', 'mobius-inversion', 'number-theory']"
369990,Two martingales whose distributions agree for each time have the same overall distribution,"Let $\{X_n\}$ and $\{Y_n\}$ be two martingales. Suppose that for each fixed $n \in \mathbb Z_+$, $X_n$ and $Y_n$ have the same distribution. Must it hold that the random sequences $\{X_n\}$ and $\{Y_n\}$ have the same distribution? At first glance this appears to be false, and I tried constructing a counterexample using various combinations of random walks and expectations of a fixed random variable with respect to an increasing collection of $\sigma$-algebras. However, I was not successful. Does anyone have a a counterexample (or a proof that the answer to my question is affirmative)?","['probability-theory', 'stochastic-processes', 'martingales']"
370002,Existence of a unique solution with given initial value problems.,"Directions: Find an interval centered about $x = 0$ for which the given initial-value problem has a unique solution. $$(x - 2)y'' + 3y = x$$ Initial values:  $y(0) = 0,\,\,y'(0) = 1 $. My answer was $(-\infty, 1) \cup (3, \infty)$. The books answer was $(-\infty < x < 2)$. I determined my answer because I thought as long as $a_{2}(x)$(the coefficient of the highest order derivative) $= 0$ is not true. Maybe it's because I'm not really sure what ""centered around $x = 0$"" means. But can someone explain to me why the books answer is correct and mine is incorrect.",['ordinary-differential-equations']
370004,"If $a$ and $b$ commute and $\text{gcd}\left(\text{ord}(a),\text{ord}(b)\right)=1$, then $\text{ord}(ab)=\text{ord}(a)\text{ord}(b)$.","Prove if $\operatorname{ord}(a)=m$ , $\operatorname{ord}(b)=n$ , and $\operatorname{gcd}(m,n)=1$ , then $\operatorname{ord}(ab)=mn$ . I was reading this and was thinking how this proof would look like. I tried to do it and am not sure if this is correct. Here is what I did: If $a$ and $b$ commute then $(ab)^{mn} = a^{mn} * b^{mn} = (a^m)^n * (b^n)^m = 1 * 1 = 1.$ So $ord(ab) | mn$ . Now, take $k = \operatorname{ord}(ab) = m^\prime * n^\prime$ where m' is relatively prime with $n$ and $n'$ is relatively prime with $m$ . By the result above $m' | m$ and $n' | n$ . Now we have $((ab)^k)^{m/m'} = 1$ since $(ab)^k=1$ . But on the other hand, by the commutativity: $$((ab)^k)^(m/m') =$$ $$((ab)^(m' * n'))^(m/m') =$$ $$ a^{n'm} * b^{n'm} = $$ $$(a^m)^{n'} * b^{n'm'}=$$ $$b^{n'm'} = 1$$ This implies that $n' * m'$ is divisible by $n$ . But $m'$ is relatively prime with $n$ , so we must have $n' = n.$ By symmetry, $m' = m$ . So $ord(ab) = mn$ . Just to say this again, I want to prove if $a$ and $b$ commute and $m$ and $n$ are relatively prime then $$ord(ab)=mn.$$ The comments are vague. I guess this must be the answer then and there probably is not another way to do this.","['group-theory', 'abstract-algebra', 'number-theory']"
370012,Lagrangian subspaces,"Let $\Lambda_{n}$ be the set of all Lagrangian subspaces of $C^{n}$, and $P\in \Lambda_{n}$. Put $U_{P} = \{Q\in \Lambda_{n} : Q\cap (iP)=0\}$. There is an assertion that the set $U_{P}$ is homeomorphic to the real vector space of all symmetric endomorphisms of $P$. And then in the proof of it there is a fact that the subspaces $Q$ that intersect $iP$ only at $0$ are the graphs of the linear maps $\phi : P\to iP$. This is what I don't understand, any explanation or reference where I can find it would be helpful.","['symplectic-geometry', 'differential-geometry']"
370019,"Revisited: How is $\phi:{\cal{L}}(V,W)\rightarrow M_{m\times n}(F)$ an isomophism of vector spaces?","I'm told in lecture that if $V,W$ are vector spaces over $F$ and ${\cal{L}}(V,W)$ is the vector space of all linear maps $V\rightarrow W$ and ${\scr{B}}$ and ${\scr{C}}$ are bases for $V$ and $W$ respectively, then $\phi:{\cal{L}}(V,W)\rightarrow M_{m\times n}(F)$ defined by $\phi(T)=[T]^{\scr{C}}_{\scr{B}}$ is an isomorphism of vector spaces, where $T \in {\cal{L}}(V,W)$ and $[T]^{\scr{C}}_{\scr{B}}\in M_{m\times n}(F)$. Now, I'm trying to understand how this theorem completes the proof for the following theorem: Let $\{v_1,\dots,v_n\}$ be linearly independent set in a finite dimensional vector space $V$ and let $w_1,\dots,w_n$ be arbitrary vectors in a vector space $W$, then there is a linear map $T:V\rightarrow W$ such that $T(v_1)=w_1, T(v_2)=w_2, \dots$, or simply $T(v_i)=w_i$ for all $i=1,2,\dots,n$. My professor concludes at the end of the proof for the second theorem that ""[b]y theorem, such [a] $T$ exists and is unique."" Any help? Furthermore, how does the below outline conclude such a theorem? Let ${\scr{B}}=\{v_1,\dots,v_n\}$ be a basis for $V$ and ${\scr{C}}=\{u_1,\dots,u_m\}$ a basis for $W$. Then \begin{eqnarray}
w_1 & = & a_{11}u_1+a_{21}u_2+\cdots+a_{m1}u_m & = & T(v_1)\\
w_1 & = & a_{12}u_1+a_{22}u_2+\cdots+a_{m2}u_m & = & T(v_2)\\
\vdots &&&&\vdots\\
w_n & = & a_{1n}u_1+a_{2n}u_2+\cdots+a_{mn}u_m & = & T(v_n),
\end{eqnarray} which can be rewritten as \begin{eqnarray}
\begin{pmatrix}
u_1&\cdots&u_m
\end{pmatrix}
\begin{pmatrix}
a_{11}&\cdots&a_{1n}\\
\vdots&\ddots&\vdots\\
a_{m1}&\cdots&a_{mn}
\end{pmatrix}=
\begin{pmatrix}
T(v_1)\\ \vdots \\ T(v_n)
\end{pmatrix},
\end{eqnarray} thus such a $T$ exists. Does this really suffice to prove?","['vector-spaces', 'matrices', 'linear-algebra', 'abstract-algebra']"
370023,How to prove a sequence of a function converges uniformly?,"For $n \in \mathbb{N}$ , define the formula, $$f_n(x)= \frac{x}{2n^2x^2+8},\quad x \in [0,1].$$ Prove that the sequence $f_n$ converges uniformly on $[0,1]$ , as $n \to \infty$ . I know that the definition says $f_n$ converges uniformly to $f$ if given $\forall \epsilon \gt 0$ , $\forall n \geq N$ , such that $|f_n(x) - f(x)| \lt \epsilon, \forall n \geq N$ and $\forall x \in [0,1].$ I looked first at the pointwise convergence and found that $$\lim_{n \rightarrow \infty} \frac{x}{2n^2x^2+8} = 0, \forall x \in [0,1].$$ So how do I use this to choose an $n \geq N$ such that $|f_n(x) - f(x)| \lt \epsilon$ ? Right now, I have ""proof: Let $\epsilon > 0, \exists N \in \mathbb{N}$ such that, n $\geq N \Rightarrow \frac{1}{2n^2+8} \lt \epsilon$ , by $|f_n(x) - 0| = |\frac{x}{2n^2x^2+8}| \leq |\frac{x^2}{2n^2x^2+8}| \leq \frac{1}{2n^2x^2+8} \;\;\;\; \forall x \in [0,1].$ Since $\lim_{n \rightarrow \infty} \frac{x}{2n^2x^2+8} = 0, \forall x \in [0,1]$ , $f_n(x)$ will converge uniformly to $0$ on $[0,1]$ ."" Is this correct? Am I missing something? Is something not correct? I'm unsure about my choice of $N$ . Please & thanks!","['uniform-convergence', 'real-analysis']"
370025,"If $\phi(\alpha)$ is prime in $\mathbb{Z}$, show that $\alpha$ is prime in $\mathbb{Z}[i]$ [duplicate]","This question already has answers here : Is it true that $a+bi$ is prime in $\mathbb{Z}[i]$ if and only if $a^2+b^2$ is prime in $\mathbb{Z}$? [closed] (3 answers) Closed 11 years ago . If $\alpha=a+bi$ is a Gaussian integer, let $\phi(\alpha)=a^2+b^2$. If $\phi(\alpha)$ is prime in $\mathbb{Z}$, show that $\alpha$ is prime in $\mathbb{Z}[i]$. I use the idea that if $a^2+b^2=p$ where $p$ is prime number, then $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$. Hence, $(a+bi)$ is a maximal ideal since $\mathbb{Z}_p$ is a field. So, $(a+bi)$ is a prime ideal and hence $a+bi$ is a prime element. Is this proof works? EDIT: $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$ is proved in my class so I think I can straight away use it here. By the way, in the proof of $\mathbb{Z}[i]/(a+bi) \cong \mathbb{Z}_p$, my lecturer said that $a^2+b^2=p$ implies $\gcd(a,b)=1$. I can't figure out the proof of this. I start with contradiction, i.e. $d=\gcd(a,b)>1$. Then $d(\frac{a^2}{d}+\frac{b^2}{d})=p \implies d |p \implies d=p \implies a^2+b^2=\gcd(a,b)$, contradiction. Is this proof work ?",['abstract-algebra']
370036,Find $f(i)$ for an entire function satisfying given conditions.,"Let $f$ be an entire function satisfying $|f''(z) - 3|\geq 0.001$ for all $z\in \mathbb{C}$, $f(0)=0$, $f(1) = 2$, and $f(-1) = 4.$ Find $f(i)$. I'm not entirely sure how to go about this... If we try a polynomial of degree 2, $f(z) = az^2 + bz + c$, where $a,b,c$ are constants, then the above constraints on $f$ force $c = 0$, $a = 3$, and $b = -1$. In this case we find that $f(i) = -3 - i$. Does the condition $|f''(z) - 3|\geq 0.001$ force $f$ to be a polynomial of degree 2?",['complex-analysis']
370056,Maps circles onto ellipses,"Show that the mapping $w=z+\frac1z$ maps circles $|z|=p(p\ne 1)$ onto
  ellipses $$\frac{u^2}{(p+\frac1p)^2}+\frac{v^2}{(p-\frac1p)^2}=1.$$ I can parametrize the circle by $z(t)=pe^{it}, \ 0 \leq t\leq 2\pi$. Then, $w(t)=pe^{it}+\frac{1}{pe^{it}},$ but then how can I show that this does map circles onto ellipses?",['complex-analysis']
370125,Why isn't $\lim \limits_{x\to\infty}\left(1+\frac{1}{x}\right)^{x}$ equal to $1$?,"Given $\lim \limits_{x\to\infty}(1+\frac{1}{x})^{x}$, why can't you reduce it to $\lim \limits_{x\to\infty}(1+0)^{x}$, making the result ""$1$""?  Obviously, it's wrong, as the true value is $e$.  Is it because the $\frac{1}{x}$ is still something even though it's really small?  Then why is $$\lim_{x\to\infty}\left(\frac{1}{x}\right) = 0\text{?}$$ What is the proper way of calculating the limit in this case?","['exponential-function', 'limits']"
370140,Bipartite graph: how many closed walk with given properties,"Let be $G=(U,V,E)$ a bipartite graph where $U$ has $K$ possible vertices and $V$ has $N$ possible vertices. We focus on closed walks of length $2L$. Such walks can be described by the sequence of vertices $(u_1,v_1,u_2,v_2,\ldots,u_L,v_L,u_1)$. The $(2k-1)$th edge is given by $\{ u_k,v_k \}$ and the $2k$th edge is given by $\{v_k,u_{k+1}\}$, for $1\leq k\leq L-1$, the last two edges are $\{u_L,v_L\}$, $\{v_L,u_1\}$. The following two properties have to be satisfied: ( P1 ) $u_k\neq u_{k+1}$ for $1\leq k\leq L-1$ and $u_L\neq u_1$; ( P2 ) each edge is traversed an even number of times. The question is: how many closed walks satisfying ( P1 ) and ( P2 ) have $\ell$ distinct edges? Example : $U = \{1,2,3\}$, $V=\{4,5\}$. The walk $(1,4,2,5,2,4,1)$ does not satisfy ( P1 ) since it comes back to $2$ after $5$, while for instance $(1,4,2,4,1)$ is ok. I can solve the problem when $N=1$, since in that case ( P2 ) is automatically satisfied (the graph is bipartite but in this very particular case $V$ has only one vertex so...) while I do not know how to start when $N>1$. Do you have some hint? P.S. I have an algorithm that compute (brute force) the answer given $K$, $N$, $L$. I report here four cases with random choices of $K$, $N$, $L$ for some check, I hope they can be useful: when $K=7$, $N=3$, $L=3$, then $(1134,630)$ are the number of closed walks with $\ell=2,3$ distinct edges; when $K=7$, $N=1$, $L=4$, then $(294,1260,840)$ with $\ell=2,3,4$ distinct edges; when $K=7$, $N=2$, $L=4$, then $(2100,4200,2772)$ with $\ell=2,3,4$ distinct edges; when $K=7$, $N=3$, $L=4$, then $(6930,8820,5796)$ with $\ell=2,3,4$ distinct edges. Update (combinatorial form) : I think that I can rephrase the problem in the following combinatorial form. Let a closed walk be represented by the set of his edges: 
\begin{equation}\mathcal{G}=\{ \{u_1,v_1\},\{v_1,u_2\},\{u_2,v_2\},\ldots,\{u_L,v_L\},\{v_L,u_1\} \}.\end{equation}
This is a set properly specified by fixing $(u_1,\ldots,u_L)$ and $(v_1,\ldots,v_L)$, where $1 \leq u_k \leq K$ and $1 \leq v_k \leq N$. Elements are actually sets of the form $\{u_i,v_j\}$. Suppose there are $\ell$ distinct elements in this set. For ( P2 ), one has:
\begin{equation} 2L = 2n_1 + \cdots + 2n_\ell,\end{equation}
where $2n_i$ is the number of times that the $i$th set appears. This number is necessarily even, and $L=n_1+\cdots+n_\ell$. There is a number of ways to obtain this sum and this is given by a standard formula in combinatorics. How many $\mathcal{G}$ satisfying ( P1 ) are there? In other words, how many times $\mathcal{G}$ has $\ell$ distinct elements, each appearing an even number of times, satisfying ( P1 )?","['graph-theory', 'combinatorics']"
370145,Concept of integration to differential form,"How to integrate differential form actually. As far as I know, a differential form is a multilinear function mapping from a vector space to a real number. Let's take $\int_c fdx+gdy$ as an example. It is integrating a differential $1$-form while I don't quite get the meaning of the integral process. Shouldn't the function act on something, like the tangent vector in the tangent space? For instance $dx^i(e_p^i)=1$ however when we are doing integration, we won't add a tangent vector next to $dx$, why?","['differential-forms', 'integration', 'real-analysis', 'analysis']"
370150,Use the Residue Theorem to evaluate the integral:,"$$\int_{0}^{∞} \frac{\sqrt{x}}{x^2+2x+5} dx$$ I'm thinking of using the ""keyhole"" contour, but I'm not sure how to proceed from there. Please help! Thanks!","['residue-calculus', 'integration', 'complex-analysis', 'contour-integration']"
370151,"If $f:\mathbb{R}\to\mathbb{R}$ is continuous and $f(x)\neq x$ for all $x$, must it be true that $f(f(x))\neq x$ for all $x$?",Let $f: \Bbb R → \Bbb R$ be a continuous function such that $f(x)=x$ has no real solution  . Then is it true that $f(f(x))=x$ also has no real solution ?,"['general-topology', 'continuity', 'real-analysis', 'functional-equations']"
370178,"If $A\cup B=B$, does it follows that $A \subseteq B$?",We know that $A \subseteq B \Rightarrow A \cup B = B$. Is the theorem valid in the other direction $\Leftarrow$? I thought of it to be intuitive that the $\Leftarrow$ direction should be valid too. Is it?,['elementary-set-theory']
370188,Empty intersection and empty union,"If $A_\alpha$ are subsets of a set $S$ then $\bigcup_{\alpha \in I}A_\alpha$ = ""all $x \in S$ so that $x$ is in at least one $A_\alpha$"" $\bigcap_{\alpha \in I} A_\alpha$ = ""all $x \in S$ so that $x$ is in all $A_\alpha$"" It is the convention that $\bigcup_{\alpha \in \emptyset}A_\alpha = \emptyset$ and $\bigcap_{\alpha \in \emptyset} A_\alpha = S$. But if $x$ is in $\bigcap_{\alpha \in \emptyset} A_\alpha = S$ then $x$ is in all $A_\alpha$ with $\alpha \in \emptyset$ and therefore $x$ is certainly in at least one $A_\alpha$ with $\alpha  \in \emptyset$. But then $x \in \bigcup_{\alpha \in I}A_\alpha$. Can someone help me and tell me what is wrong with this? Thank you.",['elementary-set-theory']
370248,Interpretation for the Functional Determinant,"Let $S:V \rightarrow V$ be a linear operator on the function space $V$. It is possible to define a functional determinant for $S$ via the zeta function regularization process. In specific we define first the associated $\zeta$-function $\zeta_S(z):=\text{Tr}(S^{-z})$ for $\Re(z)>>0$, then we extend $\zeta_S(z)$ by analytic continuation, and finally we define the functional determinant by $\det(S):=\text{exp}(-\zeta_s'(0))$. The details of the definition are rather clear, but I'm puzzled about the meaning of the construction. Question What does the functional determinant tell us about the operator $S$? To be more specific, what can we say about $S$ if $\det(S)=0$?",['functional-analysis']
370250,Convergence of $c_j = \sum_{k=1}^nx_k\cos(2\pi\frac{k-1}{n})j$,"S. Kim, K, Umeno, and A. Hasegawa, Corrections of the NIST Statistical Test Suite for Randomness (available at http://arxiv.org/pdf/nlin/0401040.pdf ) mention page 8-9 that: $c_j = \sum_{k=1}^nx_k\cos(2\pi\frac{k-1}{n})j$ converges to the normal distribution with mean $0$ and variance $n/2$ for $x_k$ random and $x_k =\pm 1$. What is a proof for this?","['statistics', 'convergence-divergence']"
370268,Martingale equality,"The question is to prove 
$$P\{\sup_{t\geq 0}M_{t}>x\mid \mathcal{F}_{0}\}=\min\left\{1,\frac{M_{0}}{x}\right\},$$
where $M$ is a positive continuous martingale which converges to 0 almost surely as t tends to infinity.
I'd like to use the optional sampling theorem in order to prove this. I therefore introduce the stopping time $$\tau=\inf\{t\geq 0\mid M_{t}\geq x\}$$ As $M$ is a martingale we also have that the stopped process is a martingale
$$M_{0}=\mathbb{E}[M_{0}\mid\mathcal{F}_{0}]=\mathbb{E}[M_{\tau}\mid\mathcal{F}_{0}]$$
$$=\mathbb{E}[M_{\tau}\mathbb{1}_{\{\tau<\infty\}}\mid\mathcal{F}_{0}]+\mathbb{E}[M_{\tau}\mathbb{1}_{\{\tau=\infty\}}\mid\mathcal{F}_{0}]$$
$$=\mathbb{E}[M_{\tau}\mathbb{1}_{\{\tau<\infty\}}\mid\mathcal{F}_{0}]$$
$$=x\mathbb{P}(\sup_{t}M_{t}\geq x \mid\mathcal{F}_{0})=x\mathbb{P}(\sup_{t}M_{t}> x \mid\mathcal{F}_{0})+x\mathbb{P}(\sup_{t}M_{t}= x \mid\mathcal{F}_{0})$$ Here is where I get stuck. I'd like to prove that $\mathbb{P}(\sup_{t}M_{t}= x \mid\mathcal{F}_{0})$ is equal to $0$.
Is there anyone that could help me prove this or correct me if i'm approaching this in the wrong manner?","['probability-theory', 'stochastic-processes', 'martingales']"
370317,Does an absolutely integrable function tend to $0$ as its argument tends to infinity?,"Suppose that $f:[0,\infty)\rightarrow\mathbb{R}$ is continuous. Is it true that $$\int_{0}^\infty|f(t)|dt<\infty\Rightarrow \lim_{t\rightarrow\infty}f(t)=0?$$ If so can you provide a proof, otherwise a counter example. Thank you.","['measure-theory', 'calculus', 'real-analysis']"
370320,Why is an intersection product $X.C=0$?,"Here is the situation: $S$ is a nonsingular complex projective surface, and $C=X\cup_AY\subset S$ is a uninodal curve of compact type: it is obtained by glueing two nonsingular curves $X,Y\subset S$ at a single node $A$. [If this helps (or is needed), I obtained $C$ as the special fiber of a family of smooth curves $\pi:S\to B$, where $B=\textrm{Spec }\mathbb C[[t]]$ and the generic fiber $S_\eta$ is a nonsingular curve.] Question . Why is $X.C=0$? If $X$ was a fiber of $\pi$ as well, we would be done. But it isn't. Moreover, the assertion $X.C=0$ looks strange to me, because (please, correct me here because I feel like I am dramatically wrong)
it means that $X$ is linearly equivalent to $X+Y$. But $X-(X+Y)=-Y$ is not equivalent to $0$! Moreover, how should I interpret the fact that $X.X=-A$? (This follows by the claim because $0=X.C=X.(X+Y)=X.X+X.Y=X.X+A$). Thank you.","['intersection-theory', 'algebraic-geometry']"
370331,Classification of flat complex line bundles,"I'm having a contradiction with two different classifications of flat complex line bundles over a manifold $X$.  Suppose for simplicity that $H^2(X;\mathbb Z) = 0 = H^1(X;\mathbb C)$.  Then the only complex line bundle is the trivial one and (thinking in terms of connection 1-forms) isomorphism classes of line bundles with connection become just one-forms on $X$ modulo gauge transformations $\Omega^1(X;\mathbb C) \ni \theta \mapsto \theta^g:=\theta + g^{-1} dg$ where $g: X \to \mathbb C^\times$.  If $f: X \to \mathbb C$ is arbitrary and $g = e^f$ then $\theta^g = \theta + df$ is cohomologous to $\theta$.  Since $H^1(X;\mathbb C) = 0$ any 1-forms are cohomologous so there is just one equivalence class of flat connections. On the other hand, the Riemann-Hilbert correspondence says that there is a 1-to-1 correspondence between iso classes of flat line bundles with flat connection and representations of $\pi_1(X)$ on $\mathbb C$.  But in the situation above $\pi_1(X)$ can be something like $\mathbb Z/n\mathbb Z$, which has more than one rep on $\mathbb C$. What am I missing?  Is the equivalence of flat bundles under Riemann-Hilbert stronger than gauge equivalence?","['vector-bundles', 'algebraic-topology', 'differential-geometry']"
370400,How to solve the ODE: $\frac{d^2y}{dx^2}=y\big(\frac{dy}{dx}\big)^2$,I am trying to solve the non-linear ODE  $ \frac{d^2y}{dx^2}=y\big(\frac{dy}{dx}\big)^2$ and I would appreciate some suggestions on how to approach this equation. This is actually part of a more complex PDE which I managed to separate but I am puzzled when it comes to solve the above non-linear problem. Thank you.,['ordinary-differential-equations']
370402,Series $\sum \frac{\sin(n)}{n} \cdot \left(1+\cdots +\frac{1}{n}\right)$ convergence question,"I want to test the convergence of the series.  $$ \sum_{n=1}^{\infty} \frac{\sin(n)}{n} \cdot \left(1+\frac{1}{2} + \cdots + \frac{1}{n}\right)$$ My guess is this should diverge, and the below I provide the details Note that $\displaystyle 1+\frac{1}{2} + \cdots + \frac{1}{n} \geq 1 +\frac{1}{2} + \frac{1}{4} + \cdots + \frac{1}{2^{n-1}} = 2 \cdot \left(1-\frac{1}{2^{n}}\right)$ So from above I conclude that $$\sum_{n=1}^{\infty} \frac{\sin(n)}{n} \cdot \left(1+\frac{1}{2}+\cdots + \frac{1}{n}\right) \geq  2 \cdot \sum_{n=1}^{\infty} \frac{\sin(n)}{n} - \cdot \underbrace{\sum_{n=1}^{\infty} \frac{\sin(n)}{n \cdot 2^{n}}}_{A}$$ Now $A$ converges and I think $\displaystyle \sum \frac{\sin(n)}{n}$ diverges hence my given series should diverge. Am I correct in my reasoning?","['sequences-and-series', 'real-analysis']"
370416,Normed vector spaces and Banach spaces,"Let $X$ be a Banach space with norm $||.||$ and let $S$ be a non-empty subset in $X$. Let $F_b(S,X)$ be the vector space of $F(S,X)$ of all functions $f:S \rightarrow X$ such that $\{||f(s)||:s \in S\}$ is bounded and consider the norm $||.||_b$ as $F(S,X)$ given by
$$||f||_b = \sup \{ ||f(s)|| : s \in S\}.$$ I have to show that $F_b(S,X)$ is a Banach space. Meaning that I have to show that it is a complete metric space. If I let $d(f,g)=||f-g||_b$, I can show that it is a metric space. However, I'm not able to prove that every Cauchy sequence in $F_b(S,X)$ would converge to some element in $F_b(S,X)$.","['normed-spaces', 'functional-analysis', 'banach-spaces']"
370418,Representing $\prod_{k=2}^{\infty}\left(1+\frac{1}{k^{2}-1}\right)$ as an Euler's product.,"The above formula corresponds to the following identity $$
2=\prod_{k=2}^{\infty}\left(1+\frac{1}{k^{2}-1}\right)
$$ I wonder if this can be represented as an Euler's product. Could anyone find such a representation? Thanks.","['euler-product', 'elementary-number-theory', 'infinite-product', 'number-theory']"
370421,How do I solve the DE $y''+6y'+8y = 2t+e^t$?,"The differential equation I am trying to solve is 
$$
\dfrac{d^2y}{dt^2} + 6\dfrac{dy}{dt} + 8y = 2t +e^t
$$
I know how to start off. I have done the $s^2 + 6s + 8 = 0$ to get $s = -4$ and $s = -2$ and have the 
$$
y_p(t) = k_1e^{-4t} + k_2e^{-2t}
$$ What I am having a problem with is gettting $y_h(t)$ which will be dependent on the $2t + e^t$. I know that the solution will be in the form $c_1 + c_2t + c_3e^t$, I am just not sure how to solve for those constants
Thank you very much for any help you can give me.",['ordinary-differential-equations']
370425,Integer solutions of $n^3 = p^2 - p - 1$,"Find all integer solutions of the equation, $n^3 = p^2 - p - 1$,  where p is prime.","['prime-numbers', 'diophantine-equations', 'number-theory']"
370439,In how many ways can five letters be posted in 4 boxes?,"Question : In how many ways can 5 letters be posted in 4 boxes? Answer 1: We take a letter. It can be posted in any of the 4 boxes. Similarly, next letter can be posted in 4 ways, and so on. Total number = $4^5$. Answer 2: Among the total number of positions of 5 letters and 3 dividers (between 4 boxes), positions of 3 dividers can selected in $\binom{8}{3}$ ways. Which one is correct (I think the first one)? Why is the other one wrong and how does it differ from the right answer in logical/combinatorial  perspective?",['combinatorics']
370484,Functional form of a series of a product of Bessels,"This question arises from my answer to an inverse Laplace transform question.  The result I got took the form $$ f(t)= e^{-r_0 t/2} H(t-a) \left [ J_0\left(\frac{1}{2} a r_0\right) I_0\left(\frac{1}{2} r_0 t\right) \\+ 2 \sum_{k=1}^{\infty} J_{2 k}\left(\frac{1}{2} a r_0\right) I_{2 k}\left(\frac{1}{2} r_0 t\right)\right ]  $$ where $H$ is the Heaviside step function: $$H(x) = \begin{cases} \\ 1 & x > 0\\ 0 & x < 0\end{cases}$$ This result in turned derived from the following integral: $$\frac{1}{\pi} e^{-r_0 t/2} \int_0^{\pi} d\theta \: \cos{\left(\frac{1}{2} a r_0 \sin{\theta}\right)} e^{(r_0 t/2) \cos{\theta}}$$ Now, I suspect  that, if I could evaluate that sum in closed form, it would take the form $$S\left(\sqrt{t^2-a^2}\right)$$ but, I stress, this is only a suspicion at  this point.  My question is two-fold: 1) is anyone aware of a closed form expression for that sum, and 2) even if not, is there a way to prove or disprove that the sum has the above functional form?","['special-functions', 'sequences-and-series', 'laplace-transform', 'calculus']"
370488,Can a space have both a conditional and an unconditional basis?,"Does there exist a Banach space $X$ which admits both a conditional and an unconditional Schauder Basis? If so, can one find an example in the collection of $\ell^p$ spaces? My thoughts so far: I've been able to convince myself that this is not possible in $\ell^2$, but of course this is a very special case. The standard basis in $\ell^p$ is an example of an unconditional basis. So the second qeustion boils down to whether there is also a conditional one. Also, given the type of question, I think I should mention right away that, no, this is not homework. Thanks in advance.","['schauder-basis', 'functional-analysis', 'banach-spaces']"
370490,"Let $\mathbb{F}$ be a field and $R=\mathbb{F}[x]$, the polynomial ring over $\mathbb{F}$. Is the ideal $(x^2-1)$ maximal in $R$?","Let $\mathbb{F}$ be a field and $R=\mathbb{F}[x]$, the polynomial ring over $\mathbb{F}$. Is the ideal $(x^2-1)$ maximal in $R$? Does the answer depend upon $\mathbb{F}$? I think of this isomorphism $\mathbb{F}[x]/(x^2-1) \cong \mathbb{F}[i]$ where $\mathbb{F}[i]=\lbrace a+bi:a,b \in \mathbb{F} \rbrace$. Since $\mathbb{F}[i]$ is a field (which I am not quite sure about it), $(x^2-1)$ is maximal. Can anyone explain to me whether $\mathbb{F}[i]$ is a field or not.",['abstract-algebra']
370518,"Evaluating $\int_{\mathbb{R}}\frac{\exp(-x^2)}{1+x^2}\,\mathrm{d}x$","I would like to evaluate in a closed form the integral 
$$\int_{\mathbb{R}}\frac{\exp(-x^2)}{1+x^2}\,\mathrm{d}x$$ I tried various methods : integration by parts some changes of variables ($y=x^2$, $x=\tan$) residue calculus (but the factor $\exp(-x^2)$ forbid to send the contour to infinity) developping $\exp(-x^2)$ or $\frac{1}{1+x^2} $ in power series (but in both cases one cannot exchange sum and integral) Does anyone knows if this integral is known, or how to evaluate it ?
At least I would like to find an exact expression. The reason for me to believe that a closed form exists is that this integral arose in a problem of probability where I expect - if I haven't made any mistake previously - a very simple expression.","['definite-integrals', 'integration']"
370520,Inverse of a differentiable function equal to its derivative then f is analytic,"I've found a nice problem concerning analytic functions. Here it is: Let $f: (0, \infty) \rightarrow \mathbb{R}$ be a  function differentiable on $(0, \infty)$ and such that $f^{-1} = f'$. Prove that $f$ is analytic on $(0, \infty)$. I'm not sure if it's relevant, but I know that $f$ cannot be a bijection :) Could you help me?","['derivatives', 'real-analysis', 'analyticity']"
370545,Is there any standard notation for specifying dimension of a matrix after the matrix symbol?,"I want to explicitly specify dimension of matrices in some expressions, something like $$\boldsymbol{A}_{m \times n} \boldsymbol{B}_{n \times m} = \boldsymbol{C}_{m \times m} \, .$$ Is there any more or less standard notation for this? While this notation is generally unambiguous, I think it become ambiguous, for example, in the following case. Suppose that I have some column or row vector which is conjugate transpose of correspondingly row or column vector. If I write it in the following way 
$$\boldsymbol{A}_{n \times 1}^{\dagger} \, ,$$
we can have 2 different interpretations: matrix $\boldsymbol{A}_{n \times 1}$ is $n \times 1$ column vector and by
$\boldsymbol{A}_{n \times 1}^{\dagger}$ I'm referring to its
conjugate transpose which is $1 \times n$ row vector; matrix $\boldsymbol{A}_{n \times 1}^{\dagger}$ itself is $n \times 1$ column vector which is conjugate transpose of $1 \times n$ row vector $\boldsymbol{A}$.","['notation', 'matrices']"
370553,Linear Independence Game,"Suppose you have a set $X$ of vectors in $\mathbb{F}_2^n$, with $|X| \ge n+1$, and consider the following game. On their turn, each player (2 player game) chooses from $X$ one vector and sets it aside in their pile $P_i$ (we also remove this vector from $X$). If at the end of their turn, there exists $m$ vectors in $P_i$ ($m \le n$) that are linearly dependent, then player $i$ loses. I was wondering if there has been any work on matrix/nim games such as these, and any papers or suggestions would helpful. Edit: I am only interested in the case where $X$ results in no draws. A game I am particularly interested is the following. Let $X$ contain only the vectors with everything $0$ except for $2$ positions that have $1$'s ($n \choose 2$ of them). Now play the following game above, and set $m=3$. Note I am also interested if there is a way to convert, or embed such a game into an impartial game (So Sprague-Grundy applies).","['game-theory', 'combinatorial-game-theory', 'linear-algebra', 'combinatorial-geometry', 'combinatorics']"
370560,Asymptotics for infinite sum with erf,"I'm interested in approximating the infinite sum
$$
\sum_{i=1}^\infty Z\left(\frac{\alpha i\pm1}{\beta}\right)
$$ where $\alpha,\beta$ are constant and
$$
Z(a\pm b)=\frac{1}{2\pi}\int_{a-b}^{a+b}e^{-x^2/2}dx=\frac{\operatorname{erf}(a+b)-\operatorname{erf}(a-b)}{2}
$$
is the standard normal distribution. Any useful asymptotics?","['statistics', 'asymptotics', 'special-functions']"
370566,Factoring $e^{-x}tx^{t-1}-e^{-x}x^t$,"I have a very simple factoring question; I'm doing a calculus problem in which part of the question requires me to factor a derivative. The derivative in question is $e^{-x}tx^{t-1}-e^{-x}x^t$ (the derivative of $\frac{x^t}{e^x})$. I have no problem with finding the derivative, and once the derivative is factored I can easily solve the problem, but I embarrassingly can't figure out how to factor the derivative by hand into the form $-e^{-x}x^{t-1}(x-t)$. I suspect my problem is that I'm running on rote muscle memory of factoring polynomials. I would appreciate a quick walk-through of the hand computations.","['factoring', 'algebra-precalculus']"
370571,closed and open set - set $S$ is open if and only if its complement is closed?,"Let set $S$ be a set of real numbers. A point $p∈S$ is set to be interior point of $S$ provided that there exist a $δ>0$ such that $(p-δ,p+δ)⊆S$. The set $S$ is said to be an open set if every element of $S$ is an interior point. How can I prove that Set $S$ is open if and only if its complement is closed.",['real-analysis']
370581,Why is $|x-8| \le 1$ equivalent to $-1 \le x-8 \le 1$?,My book presents the following: $$7 \le x \le 9 $$ so $$ -1 \le x - 8 \le 1 $$ and $$ |x-8| \le 1$$ I usually get confused with the way that taking the absolute value of an expression works. Could anybody explain why the inequalities above are equivalent? I understand how the first and the second one are equivalent but not how the third one is equivalent to the second one.,"['inequality', 'absolute-value', 'algebra-precalculus']"
370621,Cantor set is boundary of regular open set,"Does there exist a regular open set $U$ in $[0,1]$, such that Cantor set is the boundary of $U$?","['general-topology', 'metric-spaces']"
370636,Simplify: $X \cap (Z-X)$,"I'm a little confused as to what's the correct answer to this question - Yeah i'm a noob at math currently. I have to simplify the following using the laws of set theory: X(intersect)(Z-X); Sorry for using text instead of proper notation. Just to clarify that is: X union the product of Y-Z; This is where i'm a little stuck The result of this is an empty set. However, i've been asked to simplify it not necessarily answer the question. Would the answer to simplifying this be: (X (union) Z) Complement I don't know why but i'm unsure about that being correct. As I said, I'm a noob at math currently. Thanks in advance",['elementary-set-theory']
370662,Infinite Geometric Series Formula Derivation,"We know that the formula for computing a geometric series is: $$\sum_{i=1}^{\infty}{a_0r^{i-1}} = \frac{a_0}{1-r}$$ Out of curiosity, I would like ask: Is there any ways the formula can be derived other than the following two ways? Method 1 (The way I found on my own): $$\sum_{i=1}^{\infty}{a_0r^{i-1}} \equiv S$$ $$S = a_0r^0+a_0r^1+a_0r^2+\cdots$$ $$S = r\left(a_0r^{-1} + a_0r^{0} + a_0r^1+\cdots\right)$$ $$S = r\left(a_0r^{-1} + S\right)$$ $$S = a_0 + rS$$ $$(1-r)S = a_0$$ $$S = \frac{a_0}{(1-r)}$$ Note that for this to work, you must first confirm this: $$\lim_{n\to\infty} a_n = 0$$ Method 2 (The way I found on the web): $$\sum_{i=1}^{n}{a_0r^{i-1}} \equiv S_n$$ $$S_n = a_0r^0+a_0r^1+a_0r^2+\cdots + a_0 r^{n-2} + a_0 r^{n-1}$$ $$rS_n = r\left(a_0r^0+a_0r^1+a_0r^2+\cdots + a_0 r^{n-2} + a_0 r^{n-1}\right)$$ $$rS_n = a_0r^1 + a_0r^2 + a_0r^3 + \cdots + a_0 r^{n-1} + a_0 r^{n}$$ $$S_n-rS_n = a_0r^0 - a_0r^n$$ $$(1-r)S_n = a_0 - a_0 r^n$$ $$S_n = \frac{a_0(1 - r^n)}{1-r}$$ Given: $$\left|r\right| < 1,$$ $$\lim_{n\to \infty} S_n = \lim_{n\to \infty}\frac{a_0(1 - r^n)}{1-r} = \frac{a_0}{1-r}$$ I personally prefer Method 1 because it is faster and more intuitive, as we don't have to multiply by $r$ . Method 1 for formula of partial sums: $$\sum_{i=1}^{n}{a_0r^{i-1}} \equiv S_n$$ $$S_n = a_0r^0+a_0r^1+a_0r^2+\cdots+a_0r^{n-2}+a_0r^{n-1}$$ $$S_n = r\left(a_0r^{-1} + a_0r^{0} + a_0r^1+\cdots+a_0r^{n-3}+a_0r^{n-2}\right)$$ $$S_n = r\left(a_0r^{-1} + S_n - a_0r^{n-1}\right)$$ $$S_n = a_0 + rS_n - a_0r^{n}$$ $$(1-r)S_n = a_0 - a_0r^n$$ $$S_n = \frac{a_0(1 - r^n)}{(1-r)}$$","['sequences-and-series', 'calculus']"
370689,How can I use prime factorization to find a cube root?,"This is based on a lesson at Khan Academy that I didn't understand. In the lesson, the instructor uses the number 512 as an example and the entire prime factorization consists of three groups of three 2s.  However, not every number has such a nice prime factorization and I don't understand how to use prime factorization to determine a cube root. For example, if the number is 1000, I know the cube root is 10, but how do I get there using prime factorization. The prime factorization of 1000 is 2 * 2 * 2 * 5 * 5 * 5.  Since it's six prime numbers, I can't get 3 equal groups of the same number like I could with 512.  In another forum someone said to use three groups of the smallest factor, but three 2s doesn't get me 10. What am I missing?","['factoring', 'arithmetic', 'algebra-precalculus']"
370700,Prove that $H=0$ or $H=\mathbb{Q}$,"Let $H$ be a subgroup of the additive group of rational numbers with the property that $\dfrac{1}{x} \in H$ for every non-zero element $x$ of $H$. Prove that $H=0$ or $H=\mathbb{Q}$ Let $x \in \mathbb{Q}$. Then $x=\dfrac{a}{b},a,b\in \mathbb{Z},b \neq 0$. Then $\dfrac{1}{x}=\dfrac{b}{a}$. Then I stuck here. Actually I don understand what the set $H$ is. Does it mean $H= \lbrace x \in \mathbb{Q}:\dfrac{1}{x} \in H\,\, \forall x \in H \rbrace$? If this is the case, then what should I do to show that $x$ is an element of $H$ ?",['abstract-algebra']
370711,Evaluate $\int_0^{2\pi} \frac{d\theta}{(1-a\cos(\theta)+a^2)}$,"Evaluate $\displaystyle \int_0^{2\pi} \frac{d\theta}{(1-a\cos(\theta)+a^2)}$ Super general. I get to a step: $\displaystyle \frac{2}{i}$ multiplied by Path integral $\displaystyle \frac{z}{[(2-a)z^2 + 2(a^2  z) + a]}.$
No idea if I'm on the right track. Maybe distribute the $i$? Wondering if I can get some help.",['complex-analysis']
370721,Research topics in combinatorics,"I am a new user here, so forgive me if I am doing anything improperly. I am currently a masters student in mathematics. I am very interested in combinatorics, and I was thinking about writing my master's thesis about some topic in combinatorics. I have talked to some of the professors at my university, and they are having a slightly difficult time coming up with good research topics for me to look at. So I am just wondering, are there any accessible (to a masters student) topics in combinatorics/graph theory/etc that you know of?",['combinatorics']
370731,Groups with 20 Sylow subgroups,"Is there a reasonably easy proof that a finite group with exactly $20$ Sylow $p$-subgroups has PSL$(2,19)$ or PGL$(2,19)$ as a quotient group? What if we weaken this to merely: “a group of order $760$ has a normal Sylow 19-subgroup”? One can see this How to show there are no simple groups of order 760 using Sylow's theorem for some motivation. My motivation is merely to turn this into a more positive statement, but the arguments for 760 are getting pretty complicated (one can easily show a group of order 760 either (1) has a normal subgroup of index 2, (2) a normal subgroup of size 2 and a normal subgroup of index 19, or (3) a normal subgroup of size 19; however, every group in fact lands in case (3) through a convoluted theoretical argument or a quick check of computer databases).","['sylow-theory', 'finite-groups', 'group-theory']"
370734,"The analytic and the algebraic ""small disc""","I would like to understand the relation between an analytic object (the so called ""small disc"") and an algebraic one (the spectrum of a DVR). The framework is that of one-parameter families of complex curves $X\to S$. Analysis : $S_0=\{z\in \mathbb C:|z|<\epsilon\}$. Algebra : $S_1=\textrm{Spec }\mathbb C[[t]]$. I understand (better: I accept!) that, under some GAGA equivalence of categories, the arrow $X\to S$ can be thought of as either a holomorphic map in the category of complex manifolds, or as a morphism of complex algebraic varieties. But why is $S_1$ the ""translation"" of $S_0$? I figure $S_1$ as a two point space where the unique closed point is $(t)$ and $\eta=(0)$ is the generic point. When I look at $S_0$, I can guess that the origin $0\in S_0$ plays the role of $(t)\in S_1$. Can anyone tell me how I should interpret $S_0$ and $S_1$ in terms of each other? (I am sorry because I know this is a vague question.) The main difficulty is to deal with the fact that there are only two points in $S_1$ (so a family $X\to S_1$ consists of two curves), while there are infinitely many points in $S_0$.
But I understand that $\eta$, being an open point, plays the role of a neighborhood of $(t)$ exactly as every open neighborhood of the origin in $S_0$. Thanks in advance.",['algebraic-geometry']
370758,Multivariable Calculus Integral Proof,"This problem is being very difficult for me to solve, I need help. Consider $F:\mathbb{R}^2\rightarrow\mathbb{R}$ of class $C^1$, suppose that the level curves of $F$ are closed and that $\nabla F$ is never $0$ for $x\neq0$.
Consider the region $D$ between the curves $F=a$ and $F=b$. For each $r$ in $[a,b]$, let $c_r$ be the curve $F=r$. Let $f:D\rightarrow\mathbb{R}$ continuous. I have to show that $$\int_Df=\int_a^b\bigg(\int_{c_r}\frac{f}{|\nabla F|}\bigg)dr$$ Usually when I ask something here I show my attempts or my observations, but in this case I couldn't even start doing this! Thank you very much for helping!","['multivariable-calculus', 'vector-analysis']"
370817,Commuting in matrix exponential [duplicate],"This question already has answers here : Operator Exponential $e^A e^B = e^{A+B}$ (2 answers) Closed 3 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Let $A$ , and $B$ be commuting $n\times n$ matrices, i.e., $A B = B A$ . Let $$ \exp(A) := \sum_{i=0}^\infty\frac{1}{i!} A^i $$ Show that $\exp(A+B) = \exp(A) \exp(B)$ .","['matrices', 'exponential-function', 'matrix-exponential', 'analysis']"
370824,Finite Abelian groups: $G \times H \cong G\times K$ then $H\cong K$,"Let $G,H,$ and $K$ be finite abelian groups. If $G \times H \cong G\times K$ then $H\cong K$. I am trying to use the fundamental theorem for abelian groups to solve this, it is clear intuitively that I can decompose $G \times H$ and $G \times K$ and then cancel out the factors of $G$ but I have no clue on writing this rigorously, or if my method is right. Edit: Can I say that $H \cong \Bbb{Z}_{p^i} \times \ldots \times \Bbb{Z}_{p^n}$ and $K \cong \Bbb{Z}_{p^q} \times \ldots \times \Bbb{Z}_{p^k}$ and since $G \times H \cong G\times K$ then $G\times  \Bbb{Z}_{p^i} \times \ldots \times \Bbb{Z}_{p^n} \cong G \times \Bbb{Z}_{p^q} \times \ldots \times \Bbb{Z}_{p^k}$ , but the representation is unique hence $\Bbb{Z}_{p^i} \times \ldots \times \Bbb{Z}_{p^n} \cong \Bbb{Z}_{p^q} \times \ldots \times \Bbb{Z}_{p^k}$ that is $H \cong K$?","['finite-groups', 'group-theory', 'abstract-algebra', 'abelian-groups']"
370826,proof of $p'(x)^2 \geq p(x)p''(x) \text { for all x } \in \Bbb{R}$,"$p(x)$ is non-constant polynomial with only real roots. If $x = a_i$ is a root of $p(x)$,  we are done. Assume then $x$ is not a root. Product of differentiation: $$p\prime(x) = \sum\limits_{k=1}^n\frac{p(x)}{x-a_k}$$ that is $$\frac{p\prime(x)}{p(x)} = \sum\limits_{k=1}^n\frac{1}{x-a_k}$$ now by differentiating it again, we get: $$\frac{p\prime\prime(x)p(x)-p\prime(x)^2}{p(x)^2} = -\sum\limits_{k=1}^n\frac{1}{(x-a_k)^2} $$ I understand, why after second differentiation we get left side, but I can't figure out, how we got the right side ($-\sum\limits_{k=1}^n\frac{1}{(x-a_k)^2} $). Can you please provide me some tips? Thanks ... and to complete the proof, by second differentiation we see, that $-\sum\limits_{k=1}^n\frac{1}{(x-a_k)^2} < 0$, so also: $$\frac{p\prime\prime(x)p(x)-p\prime(x)^2}{p(x)^2} < 0$$
$$p\prime\prime(x)p(x)-p\prime(x)^2 < 0$$
$$p\prime\prime(x)p(x) < p\prime(x)^2 $$
...done :)","['proof-writing', 'derivatives', 'polynomials']"
370828,Number of perfect squares less than N?,What is the process used to find the number of perfect squares less than or equal to N?,"['elementary-number-theory', 'algebra-precalculus']"
370834,Why generalize the Euclidean metric?,"It is well known that the Euclidean metric can be generalized to $\Bbb R^n$ by $\sqrt{(x_1-x'_1)^2+\cdots + (x_n-x'_n)^2}$, and that under this generalization it is still a metric and satisfies various other properties of the two and three dimensional cases. But other than as a mathematical curiosity, why do this? Does this metric appear naturally in any mathematical problems or fields of study? Or is the only reason to generalize because we can?","['geometry', 'metric-spaces', 'soft-question']"
370851,Lie bracket in local coordinates.,"$\bf 14.9.$ Lie bracket in local coordinates Consider the two vector fields $X,Y$ on $\mathbb{R}^n$: $$X=\sum a^i\dfrac\partial{\partial x^i},\qquad Y=\sum b^j\dfrac\partial{\partial x^j},$$ where $a^i(x),b^j(x)$ are $C^\infty$ functions on $\mathbb R^n$. Since $[X,Y]$ is also a $C^\infty$ vector field on $\mathbb R^n.$ $$[X,Y]=\sum c^k\dfrac\partial{\partial x^k}$$ for some $C^\infty$ functions $c^k.$ Find the formula for $c^k$ in terms of $a^i$ and $b^j$. Can you help for solving this.I have an manıfold exam and ı am working but ı have a problem about lie bracket. And ı am putting what ı did..","['general-topology', 'manifolds', 'calculus', 'differential-geometry']"
370860,Moment Generating Function Supremum,"I'm studying probability, and am having trouble with the following: Let $X$ be a uniform R.V. on $[0,1]$. Compute the moment generating function $M(t)$ of $X$. Compute $I(y) = \sup_{t \in \mathbb{R}}\{ty - \ln M(t)\}$. Computing the moment generating function is easy enough; it's $M(t) = \begin{cases} \frac{1}{t}(e^t-1) &t\neq 0 \\ 1 &t=0 \end{cases}.$ However, I don't see how to compute $I(y)$. 
I can see it is $$\sup_{t \in \mathbb{R}}\{ty - \ln M(t)\} = \sup_{t \in \mathbb{R}}\{\ln \left( e^{ty}/ M(t) \right) \}.$$
For $y \geq 1$, this seems to approach infinity as $t \to \infty$. For $y < 0$, the value goes to infinity as $t \to -\infty$. For $y \in [0,1)$, the value goes to $-\infty$ as $t \to \infty$ and as $t \to -\infty$. The desired supremum is attained when the argument $te^{ty}/{(e^t-1)}$ achieves its maximum. Its derivative is zero when 
$$ M(t) = \frac{e^t-1}{t} = \frac{e^t}{yt+1}. $$ This doesn't seem to lead anywhere though. Is there some nifty probability trick to this? I think there must be a way to use the fact that $M$ is moment generating function, but I'm not seeing it...","['probability-theory', 'measure-theory']"
370883,Pullback of a reduced closed subscheme along an étale morphism,Let $X$ any $Y$ be reduced schemes of finite type over a field and $W\subseteq Y$ a closed reduced subscheme. What is an example of such $X$ and $Y$ and $W$ and of a morphism $f:X\to Y$ such that the closed subscheme $X\times_Y W\subseteq X$ is not reduced? Is there such an example for $f:X\to Y$ étale?,['algebraic-geometry']
370893,Arnold's Trivium problem 51,"Calculate $$ f(k) = \int_{-\infty}^{+\infty} e^{ikx}\frac{1 - e^x}{1+e^x}dx.$$ As far as I know, this is not a function but rather the Fourier transform in tempered distributions. 1) What is a rigorous proof of Arnold's problem ? 2) How people usually use and manipulate Fourier Transform of tempered distributions ? Edit : Thx a lot to joriki and sos440 for two very nice and rigorous proofs. To summarize, joriki 's idea is to get a regular integral by derivation and then using the Rediues Theorem ; while sos440 is removing the 'constant' term that makes the integral diverge and treat it seperatly. If anyone has another different method, I'd be glad.","['complex-integration', 'fourier-transform', 'integration']"
370907,"Continuous on rationals, discontinuous on irrationals","Let $f: R \rightarrow R$. Show that the set of points of continuity of
  $f$ is a $G_{\delta}$ set. Explain why it follows from this that there
  is no function that is continuous on the rationals and discontinuous
  on the irrationals. Solution: I can prove the second part, although independently of the first. In words: No function can be continuous only on a countable dense set of $R$, such as $Q$. If the set, $X$, of continuity points were countable, then we could choose a nested sequence of intervals around points of $X$ where the variation in $f$ goes to 0, that eventually avoids all points of $X$. But the common point of the intervals would be a continuity point, contradiction. How can I relate this to the first part?","['measure-theory', 'functional-analysis', 'real-analysis']"
370909,Accounting for changing radius of a paper roll to always unroll the same amount of paper,"So I'm building a Post-Turing Machine that's running a 5-state busy beaver. It has a 300ft roll of receipt paper at each end simulating an infinite tape. Hypothetically the tape is divided into 'cells.'  So the machine writes or erases a 1 on the tape under the writing head, then the tape shifts either 2"" to the right or 2"" to the left. I have a stepper motor (Nema 17) at each end hooked to each roll. Finally, my question: As you can imagine turning both motors a given number of steps will initially will move the tape evenly 2"", however now one roll has 2"" more and the other, 2"" less. Not such a big difference now but as it goes on one roll could have 500ft and the other 100ft, making the one with 500ft have a much larger radius, therefore turning the motor the same amount will release much more tape...Does anyone know a way to calculate these changing ratios so the motors will always work together in letting out/winding 2"" of tape? (by the way, programed in a counter variable, so ""leftMotor = 3600 and rightMotor=3600"" if it does a move right then leftMotor=3602 and rightMotor=3598)","['geometry', 'algebra-precalculus', 'algorithms']"
370920,"If $A^2$ is invertible, then $A$ is also invertible?","True or False: If $A^2$ is invertible, then $A$ is also invertible. ($A$ is a matrix here.) The answer is true. I was trying to come up with an example that makes this false. But I couldn't. Could anybody help me prove this?","['matrices', 'linear-algebra', 'inverse']"
370928,Vector Bundle Doubt..,"Well I have a doubt about a rank $k$ vector bundle. My definition of vector bundle is: A rank $k$ vector bundle is a triple $(\pi, E, M)$ where $E$ and $M$ are smooth manifolds and $\pi:E\rightarrow M$ is a smooth submersion, which satisfies: (i) for every $p\in M$ the fiber $F_p=\pi^{-1}(p)$ is a $k$-vector space. (ii) given $p\in M$ there is an open set $U\subseteq M$ containing $p$ and a diffeomorphism $\phi:\pi^{-1}(U)\rightarrow U\times \mathbb R^k$ such that $\textrm{pr}_1\circ \phi=\pi$. (iii) For every $q\in U$ the map $\phi_q:E_q\rightarrow \mathbb R^k$, $e\mapsto (\textrm{pr}_2\circ \phi)(e)$, is a linear isomorphism.. My doubt is: If I have $\pi^{-1}(U)=E$ and $U=M$ in $(ii)$ and I consider $\phi^{-1}:M\times \mathbb R^k\rightarrow E$ can I say $\phi^{-1}(p, \cdot)=\phi_p^{-1}$?","['manifolds', 'vector-bundles', 'differential-geometry']"
370936,Every subnet of $(x_d)_{d\in D}$ has a subnet which converges to $a$. Does $(x_d)_{d\in D}$ converge to $a$?,"Let $(X,\mathcal T)$ be a topological space and $(x_d)_{d\in (D,\le)}$ be a net in it and let $a\in X$.
Every subnet of $(x_d)_{d\in D}$ has a subnet which converges to $a$. Does $(x_d)_{d\in D}$ converge to $a$? In fact, $a$ is a cluster point of every subnet as defined in this wikipedia page .","['general-topology', 'nets']"
370959,Basic Question about linearity of expectation,"I am going through some introductory notes on probability here http://www.stat.berkeley.edu/~aldous/134/gravner.pdf In Chapter 8, page 89, there is a problem where you get a bag containing 10 Black, 7 red and 5 white balls. What i find surprising is that E[X] where X denotes the number of red balls you get after 5 draws in the following cases (i) with replacement
(ii) w/o replacement is the same. I mean its clear that in both cases $E[X] = \sum_{i=1}^{i=5}E[I_i]$ where $I_i$ is an indicator variable which is $1$ if the $i^{th}$ ball you get is red. And in case(i) the claim that $E[X] = 5*7/22$ is believable as $P(I_i = 1) = 7/22$ is true for each of the draws. But in case(ii) I am unable to understand why $E[I_i] = 7/22$ for all the $5$ draws. I mean since $I_i$'s are indicator rv's, $E[I_i] = P(I_i = 1)$ and i can see that this quantity is $7/22$ only for the first draw. I do not understand why all $E[I_i]'s$ are the same as the author claims. This is making me terribly confused. Please help. Also, I would request if you can shed some more light on the problem. As in, please provide some commentary which kind of makes this result intuitive, easier to digest (and not surprising). That is, I would like to really understand why this result is true at a deeper level. Hope the question is clear. Edit : Removed one statement as I had not done calculations as per one of the comment below. The calculations confirm that $Pr(I_j = 1) = 7/22$ for all $0 \leq j \leq 5$. I want to understand this better. I mean, calculations is one thing -- but why are all the numbers coming out to be the same?","['probability-theory', 'intuition', 'probability']"
370979,"Given one inequality, prove second inequality","I'm stuck on this homework problem. Can someone please give me a hint? Given $2a^2+3ab+4ac<0$. Is the following expression zero, negative or
  positive?  $$9b^2-32ac$$ Thanks.","['inequality', 'algebra-precalculus']"
370981,In Pursuit of a Broader Understanding of Complicated Binomial Coefficient Sums,"$$\sum_{k=0}^{n}\binom{n}{k}\frac{k!}{(n+k+1)!}$$ The above identity was posted once before by me, however, all results were obtained numerically exploring the identity rather than understanding it combinatorially or performing explicit manipulations on it algebraically.  I was hoping by posting again I might be able to entice someone a bit more capable than myself to consider again whether there might be a good combinatorial interpretation for this after all, and whether there are some general guidelines for both arriving at these interpretations, and choosing the proper algebraic manipulations where necessary to see them.","['summation', 'binomial-coefficients', 'combinatorics']"
370993,Derivative of Function with Exponentials,I would like to know the derivatives of the following function: $ y = x^e*e^x$ At first sight it looks like the product rule should be used and so one would get $e*x^{e-1}*e^x+x^e*e^x$. Is this correct?,['derivatives']
371006,Equation with Logarithm: $\log_x3+\log_x12 = 2$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Given is the equation: $$\log_x3+\log_x12 = 2$$ How do I solve it? My idea was to use the formula $\log_a(b) = \frac{\ln b}{\ln a}$ but that does not seem to help here.","['logarithms', 'algebra-precalculus']"
371021,*-homomorphisms $M_m(\mathbb{C})\rightarrow M_n(\mathbb{C})$,"I've heard that every *-homomorphism $\phi:M_m(\mathbb{C})\rightarrow M_n(\mathbb{C})$ is unitarily equivalent to some *-homomorphism of the form
$A\in M_m(\mathbb{C})\mapsto\left(\oplus_{k}A\right)\oplus0_{n-km}\in M_n(\mathbb{C})$ for some $k$, that is, the matrix $A$ is copied $k$ times in the diagonal as below:
$$A\in M_m(\mathbb{C})\mapsto\left[\begin{array}{}
A\\
&\ddots\\
&&A\\
&&&0_{n-km}
\end{array}\right]\in M_n(\mathbb{C})$$ Do someone have a (maybe not so) simple proof of this fact?","['matrices', 'linear-algebra', 'functional-analysis', 'abstract-algebra']"
371026,Showing a bijection with a contraction,"I have the function $F(x) = x + f(x)$ where $f(x)$ is a contraction: $|f(x)-f(y)| \leq \alpha|x-y|$ for some $0 < \alpha < 1$ and all $x, y \in \mathbb{R}$ I want to show that $F$ is a bijection: Proof of injection: By contradiction suppose $F$ is not injective then $F(x_1) = F(x_2)$ but $x_1 \neq x_2$. \begin{align*}
    x_1 + f(x_1) &= x_2+f(x_2) \\
    |x_1 - x_2| &= |f(x_2) - f(x_1)| \\
\end{align*}
But we have that $|f(x_1)-f(x_2)| \leq \alpha|x-y|$ as $x_1 \neq x_2, |x_1 - x_2| \neq 0 \implies |f(x_1)-f(x_2)| \neq 0$ as $0<\alpha < 1$ then $|f(x_1)-f(x_2)| < |x-y|$ Thus we have a contradiction. Proof of surjection : Let $y\in\mathbb{R}$. We must show that there exists $x$ such that $F(x)=y$. Let $y = F(x)$
\begin{align}
y = x + f(x)\\
\iff x = y - f(x)
\end{align} We must show that for any $y$ and $f(x)$ we can find an $x$. I am not quite sure how to proceed from here. I think I need to use some properties of $f$ being a contraction, which will tell me that I can find this $x$ for all $f(x)$. Also, is my injective proof correct?","['discrete-mathematics', 'functions']"
371035,Open map and topology,"If $ f:\mathbb{R} \to \mathbb{R}$,  $f(x)= x^3+3x^2+ax+3$, for what $a$ is $f$ an open map? I was thinking the following: It suffices to show $f$ maps basic open set (interval) to an open set in $\mathbb{R}$. Since $f$ is a continuous map because it is a polynomial, $f$ should map an open interval into a connected subset of $\mathbb{R}$ which is of the form of an interval. But what are the other conditions needed to make sure it is an open map?",['general-topology']
371044,Restrictions of null/meager ideal,"Let I denote the null/meager ideal on reals. Is it consistent that for any pair of non null/meager sets A and B, there is a null/meager preserving bijection between A and B? In particular, is this true in the model obtained by adding $\omega_2$ Cohen/random reals over a model of CH?","['general-topology', 'set-theory', 'measure-theory', 'descriptive-set-theory']"
371059,How Does One Find A Basis For The Orthogonal Complement of W given W?,"I've been doing some work in Linear Algebra for my course at school. I just want to be clear about how to find the orthogonal complement of a subspace. The basis for the subspace, W , is shown below, composed of 3 vectors:$$W = \begin{Bmatrix}\begin{bmatrix}1\\2\\3\\4 \end{bmatrix} \begin{bmatrix}-3\\4\\2\\6\end{bmatrix} \begin{bmatrix}2\\-2\\3\\5\end{bmatrix}\end{Bmatrix}$$ I would like to know if one simply sets $W*W^T$ $=0$ and takes the columns of the resulting matrix as the basis of the orthogonal complement of W , provided that row reduction has been performed to make sure the remaining columns are linearly independent. Please note that I have created an arbitrary set of vectors above that are not orthogonal, and so if they need to be for $W*W^T$ $=0$ please point that out. Thank you.","['vector-spaces', 'matrices', 'linear-algebra']"
371075,All the compact covering spaces of torus.,"I know the covering spaces of the of a torus $T^2$ are homeomorphic to $T^2,S^1\times\mathbb{R},\mathbb{R}^2$. I am interested in finding all of the covers with covering space $T^2$. The subgroups of $\pi_1(T^2)=\mathbb{Z}\times\mathbb{Z}$ with covering space $T^2$ are of the form $\langle (a,b),(c,d)\rangle\cong\mathbb{Z}\times\mathbb{Z}$. The cover for $n\mathbb{Z}\times m\mathbb{Z}$ is $p:T^2\rightarrow T^2, p(x,y)=(x^n,x^m)$. How can I generalize this to arbitrary 2 dimensional subgroups.","['general-topology', 'covering-spaces', 'algebraic-topology', 'group-theory']"
371096,"Proof that if $H \triangleleft G$ and $G/H$ is abelian, then $G' \le H$","I'd like some input on one part of my attempted proof for the following result.  The other part I feel good about. ""If $H \le G$ is any subgroup, show that $G' \le H$ if and only if $H \triangleleft G$ and $G/H$ is abelian."" $\Leftarrow$ Let $\pi:G \to G/H$ be the canonical homomorphism and let $aH=\pi(a), bH=\pi(b) \in G/H$.  Then since $G/H$ is abelian, $[\pi(a),\pi(b)]=1=\pi([a,b])$, which implies that $[a,b] \in H$ for all $a,b \in G$, so $G' \le H$. ($[\cdot\,,\cdot]$ denotes the commutator, and $G'$ the derived subgroup of $G$, to be clear) The only thing that makes me a little uneasy is choosing elements $aH$ and $bH$ in $G/H$ like I did, since there could be more than one element representing them in $G$, but I think it still works. Thanks.","['group-theory', 'proof-verification']"
371103,Question on compactification,"I was studying for quals and had trouble with this question. Any help would be great, thanks. A two-point compactifcation of a Hausdorff space $X$ is a compact Hausdorff space
$Y$ such that $X$ is a dense subspace of $Y$, and $Y \setminus X$ consists of exactly two points.
Prove that no two-point compactification of the Euclidean plane $\mathbb{R}^2$
exists.","['general-topology', 'compactness']"
371118,Fourth Order Nonlinear ODE,"I was looking at an ode $w^{(4)} + w^3 = 0$ with initial conditions $[w'''(0),w''(0),w'(0),w(0)]=[1,0,0,0]$. I can see via maple that there is a blowup around 3.7. I was wondering if there was a way to show there is a blowup without using a computer, or if someone could direct me to some material on how to prove blowups. I'm having trouble finding literature on it. Thanks so much for your consideration.",['ordinary-differential-equations']
371125,Prove that $x^{12}-x^9+x^4-x+1>0$ for all $x\in \mathbb{R}$,"Prove that the expression $x^{12}-x^9+x^4-x+1>0\; \forall x\in \mathbb{R}$ My try:: Using Interval method:: $\bullet \; $If $x\leq 0$, Then $x^{12}-x^9+x^4-x+1>0$ $\bullet \; $If $0<x\leq 1$, Then $x^{12}+x^4.(1-x^5)+(1-x)>0$ $\bullet \; $If $x>1$, Then $x^9.(x^3-1)+x(x^3-1)+1>0$ So the expression $x^{12}-x^9+x^4-x+1>0\; \forall x\in \mathbb{R}$ My question is How can I solve Using $A.M\geq G.M$ method. or How can I complete the square so that the expression is $>0$ Thanks","['inequality', 'algebra-precalculus', 'polynomials']"
