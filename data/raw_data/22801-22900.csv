question_id,title,body,tags
195642,"Why is positivity of first entry sufficient for a matrix in $\mathrm{SO}(1,3)$ to be in $\mathrm{SO}^{+}(1,3)$?","This is a result physics books tell all the time, that the branch of proper Lorentz transformations with positive first entry forms the identity component of Lorentz group. In mathematical language, for all $\Lambda\in\mathrm{SO}(1,3)$ and $(\Lambda)_{00} \geq 0$ (indices: 0,1,2,3), we have $\Lambda\in\mathrm{SO}^{+}(1,3)$. The converse is also true. But why? $(\Lambda)_{00} \geq 0$ is a very weak condition, and I have tried for hours but cannot even prove such $\Lambda$'s is closed under multiplication. Could anyone give me a hint? In addition, is this result generalizable to arbitrary $\mathrm{SO}(1,n)$?","['general-relativity', 'lie-groups', 'group-theory']"
195646,If a sequence satisfies $\lim\limits_{n\to\infty}|a_{n+1} - a_n|=0$ then the set of its limit points is connected,Prove that if a sequence satisfies $\lim\limits_{n\to\infty}|a_{n+1} - a_n|=0$ then the set of its limit points is connected. My professor once mentioned a proposition likewise but I cannot find the exact version of it. Can anyone help?,"['general-topology', 'sequences-and-series']"
195648,$\sigma$ algebra of collection of random variables,"Im doing a course on measure theory and I'm stuck on one of the exercises. Take $\{Y_{\gamma}:\gamma \in C\}$ as an arbitrary collection of random variables and $\{X_{n}: n \in N\}$ to be a countable collection of random variables I now want to show that $$\sigma \{Y_{\gamma} : \gamma \in C\}=\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}$$ So i need to show that both $\sigma \{Y_{\gamma} : \gamma \in C\}\subset\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}$ and $\sigma\{Y^{-1}_{\gamma}(B): \gamma \in C, B \in Borel\}\subset\sigma \{Y_{\gamma} : \gamma \in C\}$ hold. I know that for a single random variable X you have $\sigma(X)=\{X^{-1}(B): B \in Borel\}$. How do I expand this for the collection of random variables? I then also have to show that if $Fn=\sigma\{X_{1},...,X_{n}\}$ and $A=\cup_{n=1}^{\infty}F_{n}$ then $$\sigma(A)=\sigma\{X_{n}: n \in N\}$$ Can anyone help me with this?","['measure-theory', 'random-variables']"
195656,Bypassing a series of stochastic stoplights,"In order for me to drive home, I need to sequentially bypass $(S_1, S_2, ..., S_N)$ stoplights that behave stochastically.  Each stoplight, $S_i$ has some individual probability $r_i$ of being red, and an associated probability, $g_i$, per minute of time of turning from red to green. What is the probability density function for the number of minutes I spend waiting at the $N$ stoplights on my way home? Update 2: The first update is incorrect since the $T$ variable $T$ is a mix of a discrete and continuous measures (as Sasha noted), to generate our distribution for $T$, and assuming all lights are the same, we need to compute the weighted sum: Distribution for $x = T = \sum^N_{j=1} Pr[j$ lights are red upon approach$] * Erlang[j, g]$ Here, Pr[$j$ lights are red upon approach] is just the probability of $j$ successes in $N$ trials, where the probability of success is $r$. In the case where all the lights are unique, we perform the same sort of weighted sum with the hypoexponential distribution, where we have to account for all possible subsets of the lights, with unique $g_i$, being red. Update 1 (see update 2 first, this is incorrect!) : from Raskolnikov and Sasha's comments, I'm supposing that the following is the case: If we allow all the spotlights, $S_i$ to be the same, following from (http://en.wikipedia.org/wiki/Erlang_distribution), we have an Erlang (or Gamma) distribution where $k = N$ and the rate parameter is $\lambda = \frac{g}{r}$.  This gives us a mean waiting time at all the red lights, $x = T$ minutes, of $\frac{k}{\lambda} = \frac{N}{(\frac{g}{r})}$ and the following PDF for $x = T$: $\frac{\lambda^k x^{k-1} e^{-\lambda x}}{(k-1)!}$ = $\frac{(\frac{g}{r})^N T^{N-1} e^{-(\frac{g}{r}) T}}{(N-1)!}$ Now if all of the stoplights are not the same, following from (http://en.wikipedia.org/wiki/Hypoexponential_distribution), we have a hypoexponential distribution where $k = N$ and the rate parameters are $(\lambda_1, \lambda_2, ..., \lambda_N) = ((\frac{g_1}{r_1}), (\frac{g_2}{r_2}), ..., (\frac{g_N}{r_N}))$.  This gives us a mean waiting time at all of the red lights, $x = T$ minutes, of $\sum^{k}_{i=1} \frac{1}{\lambda_i} = \sum^{N}_{i=1} \frac{1}{(\frac{g_i}{r_i})}$.  I'm having trouble, however, understanding how to correctly calculate the PDF for the hypoexponential distribution. Is the above correct? (answer: no, but the means are correct)","['stochastic-processes', 'probability']"
195659,When is the image of a null set also null?,"It is easy to prove that if $A \subset \mathbb{R}$ is null (has measure zero) and $f: \mathbb{R} \rightarrow \mathbb{R}$ is Lipschitz then $f(A)$ is null. You can generalize this to $\mathbb{R}^n$ without difficulty. Given a function $f: X \rightarrow Y$ between measure spaces, what are the minimal conditions (or additional structure) needed on $X$, $Y$ and $f$ for the image of a null set to be null? Any generalization (containing the above as a special case) is appreciated. Apparently if $X$ and $Y$ are $\sigma$-compact metric spaces with the $d$-dimensional Hausdorff measure and $f$ is locally Lipschitz then the result holds. Can we be more general? I would like to see something without a metric.","['general-topology', 'measure-theory', 'analysis']"
195660,Uniform boundedness imply uniform convergence?,"If ${f_n}$ is a uniformly bounded sequence of holomorphic functions in $\Omega$ such that ${f_n(z)}$ converges for every $z \in \Omega$, is the convergence is uniform on every compact subset of $\Omega$? I'm trying to prove using Dominated Convergence Theorem with Cauchy's Integral Formula. For any compact $K \subset \Omega$, let $\gamma = \partial K$. Then for any $z \in K$, by the CIF,
$$|f_n(z) - f_m(z)| \leq \frac{1}{2\pi i}\int_{\gamma}\left|\frac{f_n(w)-f_m(w)}{w-z}\right|\:dz.$$ Now since we are talking in compact sets, $|f_n(z)| \leq B \in L^1$, so by applying Dominated Convergence Theorem, and by taking the limit as $m \to \infty$,
$$|f_n(z)-f(z)| \leq \frac{1}{2\pi i}\int_{\gamma}\left|\frac{f_n(w)-f(w)}{w-z}\right|\:dz.$$ But by the pointwise convergence, I am trying to claim that RHS can be made sufficiently small for large enough $n$. Am I on the right track?",['complex-analysis']
195690,Canonical form of conic section,"I have $x^2+2xy-2y^2+x-4y=0$ and I have to find its canonical form, but I'm a little confused.. I'd like to understand very well what I have to do.. Can you help me, please?
Thanks!","['algebraic-geometry', 'conic-sections']"
195726,"Spivak's Calculus (Chapter 5, Problem 41): Proof that $\lim_{x \to a} x^2 = a^2$","In Chapter 5, Problem 41, Spivak provides an alternative way to prove that $$\lim_{x \rightarrow a} x^2 = a^2\,\,,\,\,a > 0$$ Given $\,\epsilon > 0\,$ let $$\delta = \min\left\{\sqrt{a^2 + \epsilon} - a, a - \sqrt{a^2 - \epsilon}\right\}$$ Then $$|x - a| < \delta\Longrightarrow \sqrt{a^2 - \epsilon} < x < \sqrt{a^2 + \epsilon}\Longrightarrow a^2 - \epsilon < x^2 < a^2 + \epsilon\,\,,\, |x^2 - a^2| < \epsilon$$ Then he goes on to claim that this proof is fallacious. But wherein lies the fallacy?","['epsilon-delta', 'calculus', 'continuity', 'real-analysis', 'limits']"
195734,"Keep the value of an 8-sided die roll, or gamble by taking a 12-sided die roll. What's the best strategy?","Consider a dice game in which you try to obtain the largest number ( e.g. you win a prize based on the final dice roll). You roll an 8-sided die, with numbers 1–8 on the sides. You may either keep the value you rolled, or choose to roll a 12-sided die, with numbers 1–12 on the sides. What's the best strategy for choosing what to do in step #2? I know the 8-sided die has expected payoff of 4.5, and the 12-sided die has expected payoff of 6.5. So I think relying on the 12-sided die is better — but how do I show the probability of this?","['dice', 'probability']"
195747,Evaluation of probability related integral,"I have encountered the following integral in my research which does not give-in to my attempts:
$$
\int_\mathbb{R} x \left( \frac{1}{\sigma_1} \phi\left(\frac{x}{\sigma_1}\right) \Phi\left(\frac{x-\mu}{\sigma_2}\right) + \frac{1}{\sigma_2} \phi\left(\frac{x-\mu}{\sigma_2}\right) \Phi\left(\frac{x}{\sigma_1}\right) \right) dx
$$
where $\phi(x)$ denote probability density function and $\Phi(x)$ a cumulative density function of the standard normal distribution. $\sigma_1$ and $\sigma_2$ are positive, and $\mu$ is real. I would appreciate hints on how to evaluate it. Thank you!","['probability', 'integration']"
195765,Does Bayesian probability have a different interpretation of a random variable?,Bayesian probability interprets the meaning of the probability of a random variable as some degree of belief.  But does this result in any difference in the interpretation of a random variable itself?,"['bayesian', 'probability']"
195767,An analytic function with a simple pole,"Let $f(z)$ be analytic in the disk $|z|<R \ \ \ (R>1)$ except for a simple pole at a point $z_0$, $|z_0|=1$. Consider the expansion $f(z)=a_0+a_1 z+ \cdots$, and show that $$\lim_{n \to \infty} \frac {a_n} {a_{n+1}}=z_0$$ All my attempts failed. I wanted to use the Laurent series at $z_0$ but the problem needs expansion at $0$.",['complex-analysis']
195785,"Limit of the difference quotient of $f(x) = \frac{2}{x^2}$, as $x\rightarrow x_0$","Could someone please show me how to derive the limit of the difference quotient of $f(x) = \frac{2}{x^2}$, as $x\rightarrow x_0$ The difference quotient is just the expression: $(f(x+h)-f(x))/h$ So, it's easy to get an expression for this, but a little tricky to eliminate the 'h' from the denominator.. Would appreciate it if someone can show me how.","['calculus', 'derivatives', 'limits']"
195799,How to solve a set of cosine equations?,"suppose I have an equations of the following with two unknowns $A$ and $\theta$ $A\sin(x+\theta)=D$ I have two points $(E,F) (G,H)$ how do I go about solving this equation analytically. I can solve this equation by using least squares where I just plugin a few numbers and solve it iteratively. I was thinking about using trig identities and breaking it down to $A\sin(x)\cos(\theta)+Acos(x)\sin(\theta)=D$ But I am kind of stuck at that point. Using derivative to solve the equation doesn't help since the form of the equation is still $\cos(x+\theta)$",['trigonometry']
195803,$(1-t)^{-d}= \Sigma_{k=0}^\infty {d+k-1 \choose d-1} t^k$?,"I'm trying to see why the equation $(1-t)^{-d}=   \Sigma_{k=0}^\infty {d+k-1 \choose d-1} t^k$ holds in the power series ring $\mathbb{Z}[[t]]$. I assume it's a counting argument about the number of ways to pick $k$ objects from $d$ barrels but I can't really see it. Any help would be greatly appreciated.  This formula is used on page 117 of Atiyah Macdonald, btw. Thanks!","['ring-theory', 'polynomials', 'abstract-algebra', 'combinatorics']"
195805,Average of random variable - can't find its value!,"I have $P(t) = 1-(1-R^{-t})^N$ which is the probability that I need more than t operations in my algorithm, t is a random variable then, I can assign a probability to it. Why is it that the sum of probabilities of t $P(t=0)+P(t=1)+P(t=2)+...$ is the average value for that variable? I mean: the formula for the average value of a random variable is: $E[X]=\sum\limits_{i=1}^\infty{x_i p_i}$ but since my random variable is ""I need more than t elements"", which is its value $p_i$? ( http://en.wikipedia.org/wiki/Expected_value#Discrete_random_variable.2C_countable_case )","['probability-theory', 'probability', 'random-variables']"
195806,When does the summation of a quotient equal the quotient of summations?,"That is, under what conditions would $$
\sum_{i = 1}^n \frac{a_i}{b_i}= \frac{\sum_{i = 1}^n a_i}{\sum_{i = 1}^n b_i} 
$$ be true?  What about for infinite summations, i.e. when $n \rightarrow \infty$?","['sequences-and-series', 'algebra-precalculus']"
195817,Subset of a function,"Suppose we have a function  $f:X \rightarrow Y$. Now, consider the function $g:X'\rightarrow Y$ where $X'\subset X$. I'd like to say the $g$ is a ""subset"" of $f$ ; is there a correct term for describing $g$ w.r.t $f$? NB : 
Also, $g(x) = f(x)$ for $x \in X'$","['notation', 'terminology', 'elementary-set-theory', 'functions']"
195848,homeomorphism question relating to the topological 3-sphere,"I have a question concerning an exercises from a text call Topology and Groupoid authored by Ronald Brown The question is as follows: Let $E^2 = \{(x, y) \in \mathbb R^2 : x^2 + y^2 \leq 1\}$. The space $S^1 \times E^2$ is called the solid torus.
Prove that the 3-sphere
$S^3 = \{(x_1, x_2, x_3 , x_4) \in \mathbb R^4 : (x_1)^2+(x_2)^2+(x_3)^2+(x_4)^2 = 1\}$
is the union of two spaces each homeomorphic to a solid torus and with intersection
homeomorphic to a torus [Consider the subspaces of $S^3$ given by $(x_1)^2 + (x_2)^2 \leq (x_3)^2 + (x_4)^2$ and by $(x_1)^2 + (x_2)^2 \geq (x_3)^2 + (x_4)^2$] I am not certain I understand the hint from the square bracket in geometric terms. From what I understand of how the 3-sphere can be constructed, one takes two 2-spheres and superimposes the boundary of one on top of the other and then glues both boundaries together. The two 2-sphere can be represented as $S^3_+ = \{(x_1, x_2, x_3 , x_4) \in\mathbb R^4 : (x_1)^2+(x_2)^2+(x_3)^2 = 1, (x_4)^2 \geq 0\}$ and $S^3_- = \{(x_1, x_2, x_3 , x_4) \in\mathbb R^4 : (x_1)^2+(x_2)^2+(x_3)^2 = 1, (x_4)^2 \leq 0\}$ Is the question asking me to show that both $S^3_+$ and $S^3_-$ are individually homeomorphic to the solid torus and $S^3_+ \cap S^3$ is homeomorphic to the torus? If so how does the hint become relevant? Thanks in advance",['general-topology']
195852,Can the Identity Map be a repeated composition one other function?,"Consider the mapping $f:x\to\frac{1}{x}, (x\ne0)$. It is trivial to see that $f(f(x))=x$. My question is whether or not there exists a continuous map $g$ such that $g(g(g(x)))\equiv g^{3}(x)=x$? Furthermore, is there a way to find out if there is such a function that $g^{p}(x)=x$ for a prime $p$? Edit: I realise I was a little unclear - I meant to specify that it was apart from the identity map. The other 'condition' I wanted to impose isn't very precise; I was hoping for a function that didn't seem defined for the purpose. However, the ones that are work perfectly well and they certainly answer the question.","['functions', 'real-analysis', 'function-and-relation-composition']"
195884,Multivariate Hypergeometric Distribution/Urn Problem,"I am having a difficulty with the following multivariate hypergeometric distribution problem. The setting is as usual, an urn contains a total of $M$ balls of $K$ unique colors, with $N_1$ balls of color 1, $N_2$ balls of color 2, ..., $N_K$ balls of color $K$ s.t. $N_1+N_2...+N_K = M$. What is the probability that in a sample of size $n$ (without replacement), the ball drawn last has a color not sampled before. For simplicity, we can assume that $N_1=N_2=...=N_K=N$, i.e. $M=KN$. I have been trying to look at particular cases with $K=2$ and $K=3$ (2 or 3 colors) with different values of sample size, $n$, hoping I could generalize the formulas for arbitrary $K$ and $n$. Thus, for example, for $K=2$ and any value of $n$, I showed that the probability in question could be found by $K \cdot \frac{{N_1 \choose n-1}{N_2 \choose 1}}{n {M \choose n}}$. For $K=3$, we may have two different cases: a) only 2 out of the available three colors are sampled (with $n-1$ balls of the same color and 1 ball of a second color). The desired probability is then $K(K-1)\frac{{N_1 \choose 2}{N_2 \choose 0}{N_3 \choose 1}}{n {M \choose 3}}$. And case b) all three colors are sampled (1 ball of each), then the desired probability is $K(K-1) \frac{{N_1 \choose 1}{N_2 \choose 1}{N_3 \choose 1}}{n{M \choose 3}}$ and the final answer is the sum of (a) and (b). Does this logic seem reasonable ? Obviously by increasing the values of $k$ and $n$ the number of cases to keep track of will increase too but it seems that each new case may be simplified into (or represented by) a previously worked out scenario. In short, it seems that I may eventually be able to find some recursive relation but after some tedious work. Any ideas would be greatly appreciated. More specifically - is this a good route to go? If yes, are there any shortcuts that I can take ? Is there a completely different approach that I can try ?
Thanks, in advance,
Tamar","['probability-distributions', 'probability', 'combinatorics']"
195893,"How can I determine the shape of a graph with $x^2$, $x$, and $y^2$ terms?","I'm working through a multivariable calculus course. I'm ~5 years removed from my most recent calculus course, and ~10 years removed from my most recent trigonometry course. While I'm understanding the new material pretty easily, I keep tripping up on material that I'm (understandably) expected to already know. One review exercise is: Draw the level curve for $f(x, y) = \frac{x}{x^2 + y^2}$ at values $c = -2, 0, 4$. For $c = 0$, this is trivial ($x = 0, y \ne 0$). I'm having a bit more trouble with the other values. I can look in the back of the book and see that the shapes are two circles. But what signs am I looking for to tell me this? I can simplify the equation of the level curve to something like this: $$c = \frac{x}{x^2 + y^2}$$
$$c(x^2 + y^2) = x$$
$$cx^2 - x + cy^2 = 0$$
$$cy^2 = -cx^2 + x$$
$$y^2 = -x^2 + \frac{x}{c}$$
$$y = \pm \sqrt{-x^2 + \frac{x}{c}}$$ For $x \ne 0, c \ne 0$. I also recall that equations like this describe a ellipse: $$a(x - x_0)^2 + b(y - y_0)^2 = r^2$$ I assume there is a similar form that accounts for the possibility of an $x$ term. But I'm not sure how to go about determining this form. This problem isn't assigned as homework, but I'm marking it as homework anyway, because it relates to a class that I'm taking.","['geometry', 'graphing-functions']"
195911,Calculation of the Covariance of Gaussian Mixtures,"I have a Gaussian mixture model, given by: $$
X \sim \sum_{i = 1}^M \alpha_i N_p(\mu_i, C_i)
$$ such that $\sum_{i=1}^M\alpha_i =1 $ .
Is there a way I can compute the overall covariance matrix if $x$ ? I would like to say "" $X$ has a covariance matrix given by $C$ "".","['normal-distribution', 'probability-distributions', 'probability']"
195918,Calculating Average Case Complexity,"I am trying to find the average case complexity of a sequential search. I know that the value is calculated as follows: Probability of the last element is $\frac{1}{2}$
Probability of the next to last is $\frac{1}{4}$
Probability of any other elements is $\frac{1}{4n-8}$ I can assume the I have a list of n $\geq$ 3. How Would I go about solving this?","['discrete-mathematics', 'proof-writing', 'algorithms']"
195919,"In a continuous-time Markov process, is the waiting time between jumps a function of the current state?","Two books construct Markov processes from Q-matrices using waiting times and jump chains but differ in whether the waiting times depend on the current state. Can the two be reconciled? Klenke claims that to every Q-matrix $q$ corresponds a unique Markov process that is differentiable at time $t=0$ and such that $q$ is its derivative there (Theorem 17.25). According to him, this unique process can be constructed by combining a (discrete time) Markov chain representing ""jumps"" between states, and a Poisson process representing the time lapse between jumps (a.k.a. the waiting time). According to this model, the waiting time $\sim \exp(\lambda)$, where $\lambda$ is a function of $Q$, and therefore unaffected by the current state. Norris too constructs a Markov process from a Q-matrix (section 2.6). His construction is similar to Klenke's except that $\lambda$ is a function not only of $Q$, but of the state active at the beginning of the waiting time. Can the two constructions be reconciled? What am i missing here? Is one of the authors wrong or idiosyncratic in his definition of a Markov process? Klenke Theorem 17.25 Let $q$ be an $E\times E$ matrix ($E$ being a countable set) such that $q(x,y)\geq0$ for all $x,y\in E$ with $x\neq y$. Assume that the following hold i) $q(x,y)\geq0$ for all $x,y\in E$, ii) $q(x,x)=-\sum_{y\neq x}q(x,y)$ iii) $\sup_{x\in E}|q(x,x)|<\infty$ Then $Q$ is the $Q$-matrix of a unique Markov process $X$. Proof [Abridged] Let $I$ be the unit matrix on $E$. Define
$$p(x,y)=\frac{1}{\lambda}q(x,y)+I(x,y)\space\space\mathrm{for\, }x,y\in E$$ Then $p$ is a stochastic matrix and $q=\lambda(p-I)$. Let $\left((Y_n)_{n\in\mathbb{N}_0}, (\mathrm{P}_x^Y)_{x\in E}\right)$ be a discrete Markov chain with transition matrix $p$ and let $\left((T_t)_{t\geq0}, (\mathrm{P}_n^T)_{n\in \mathbb{N}_0}\right)$ be a Poisson process with rate $\lambda$. Let $X_t:=Y_{T_t}$ and $\mathrm{P}_x=\mathrm{P}_x^Y\otimes\mathrm{P}_0^T$. The $\mathfrak{X}:=\left((X_t)_{t\geq0}, (\mathrm{P}_x)_{x\in E}\right)$ is [...] the required Markov process. [...] $\square$ Norris A minimal right-continuous process $(X_t)_{t\geq0}$ on $I$ is a Markov chain with initial distribution $\lambda$ and generator matrix $Q$ if its jump chain $(Y_n)_{n\geq0}$ is discrete-time Markov($\lambda$, $\Pi$) and if for each $n\geq1$, conditional on $Y_0, \dots, Y_{n-1}$, its holding times $S_1, \dots, S_n$ are independent exponential random variables of parameters $q(Y_0), \dots, q(Y_{n-1})$ respectively. We say $(X_t)_{t\geq0}$ is Markov($\lambda$, $Q$) for short. We can construct such a process as follows: let $(Y_n)_{n\geq0}$ be discrete-time Markov($\lambda$, $\Pi$) and let $T_1,T_2,\dots $ be independent exponential random variables of parameter $1$, independent of $(Y_n)_{n\geq0}$. Set $S_n=T_n/q(Y_{n-1})$, $J_n=S_1+\cdots+S_n$ and
$$X_t=\begin{cases}Y_n &\mathrm{if\, }J_n\leq t<J_{n+1}\mathrm{\, for\, some\, }n\\ \infty &\mathrm{otherwise}\end{cases}$$ Then $(X_t)_{t\geq0}$ has the required properties.","['probability-theory', 'stochastic-processes', 'markov-process']"
195920,Prove a formula is corect,I am trying to figure out this discrete math problem. I am not sure how to do it or even how to really start it. The problem is as follows: Consider values of $\frac{\sum_{i=1}^n i^2}{\sum_{i=1}^n i}$ for several small values of n. What formula will express $\sum_{i=1}^n i^2$ in terms of $n$. Prove this is a correct formula.,['discrete-mathematics']
195932,Automorphism group of the quaternion group,"Let $Q_8$ be the quaternion group. How do we determine the automorphism group ${\rm Aut}(Q_8)$ of $Q_8$ algebraically? I searched for this problem on internet. I found some geometric proofs that ${\rm Aut}(Q_8)$ is isomorphic to the rotation group of a cube, hence it is isomorphic to the symmetric group $S_4$ . I would like to know an algebraic proof that ${\rm Aut}(Q_8)$ is isomorphic to $S_4$ .","['quaternions', 'automorphism-group', 'finite-groups', 'group-theory']"
195948,"A, B, C and D, and we are trying to find the probability that exactly one event occurs.","Truthfully, this is a homework problem. I've come across a solution, but I'm really trying to figure out how this works, hopefully at an intuitive level. We have four events, A, B, C and D, and we are trying to find the probability that exactly one event occurs. I've seen the ""Inclusion exclusion principle"", and that would help if I had to find the probability of A or B or C or D. I feel this should be trivial, probability is my weakest math, which is why I'm taking it, but this particular problem is giving me a lot of trouble. Any help would be greatly appreciated.",['probability']
195951,What exactly is going on when we're finding a limit?,"I understand that there are point discontinuities in certain functions, and that there are sometimes values that these functions approach from both sides of the discontinuity. Then the limit exists, and it's a useful thing to know. Assuming that's right, I still have a problem with this process of finding limits. Is the point to muck about with the function algebraically until there isn't a discontinuity - and that's it? So far in my classes it just seems like we play around until there are no zero divisors and then poof it's all working. It just seems a little fishy. What should I read about to gain a deeper appreciation for what's going on?","['calculus', 'limits']"
195981,Where should I start to determine the limit of a multivariate function?,"The textbook I'm using only contains examples for very simple functions, like $$\lim_{(x,y) \rightarrow (0, 1)}{x^2 + y^2 + 2}$$ In this case, I can just break up the function into its composite parts: $$\lim_{(x, y) \rightarrow (0, 1)}{x^2} + \lim_{(x, y) \rightarrow (0, 1)}{y^2} + \lim_{(x, y) \rightarrow (0, 1)}{2} = 0 + 1 + 2 = 3$$ For more complex functions, it has some examples for how to verify a given limit. But none for how to compute it in the first place. Suppose I am given something like one of the following problems: $$\lim_{(x,y) \rightarrow (0,0)} \frac{e^{xy} - 1}{y}$$
$$\lim_{(x,y) \rightarrow (0,0)} \frac{\cos {(xy)} - 1}{x^2y^2}$$
$$\lim_{(x,y) \rightarrow (0,0)} \frac{xy}{x^2 + y^2 + 2}$$ How do I begin if I want to compute the limit? What is the general approach?","['multivariable-calculus', 'limits']"
196007,Analysis problem with volume,"I'm looking for a complete answer to this problem. Let $U,V\subset\mathbb{R}^d$ be open sets and $\Phi:U\rightarrow V$ be a homeomorphism. Suppose $\Phi$ is differentiable in $x_0$ and that $\det D\Phi(x_0)=0$. Let $\{C_n\}$ be a sequence of open(or closed) cubes in $U$ such that $x_0$ is inside the cubes and with its sides going to $0$ when $n\rightarrow\infty$. Denoting the $d$-dimension volume of a set by $\operatorname{Vol}(.)$, show that
$$\lim_{n\rightarrow\infty}\frac{\operatorname{Vol}(\Phi(C_n))}{\operatorname{Vol}(C_n)}=0$$ I know that $\Phi$ cant be a diffeomorphism in $x_0$, but a have know idea how to use this, or how to do anything different.
Thanks for helping.","['real-analysis', 'analysis']"
196024,Can someone explain the ABC conjecture to me?,"I am an undergrad and I know that the conjecture may have been proven recently. But in reading about it, I am entirely confused as to what it means and why it is important. I was hoping some of you kind people could help me. I know there are several formulations of the conjecture. Wolfram says: for any infinitesimal $\epsilon > 0$, there exists a constant $C_\epsilon$ such that for any three relatively prime integers $a$, $b$, $c$ satisfying $a+b=c$ the inequality $$\max (|a|, |b|, |c|) \leq C_{\epsilon}\displaystyle\prod_{p|abc} p^{1+\epsilon}$$
holds, where $p|abc$ indicates that the product is over primes $p$ which divide the product $abc$. Then Wikipedia says: For a positive integer $n$, the radical of $n$, denoted $\text{rad}(n)$, is the product of the distinct prime factors of $n$. If $a$, $b$, and $c$ are coprime positive integers such that $a + b = c$, it turns out that ""usually"" $c < \text{rad}(abc)$. The abc conjecture deals with the exceptions. Specifically, it states that for every $\epsilon>0$ there exist only finitely many triples $(a,b,c)$ of positive coprime integers with $a + b = c$ such that $$c>\text{rad}(abc)^{1+\epsilon}$$ An equivalent formulation states that for any $\epsilon > 0$, there exists a constant $K$ such that, for all triples of coprime positive integers $(a, b, c)$ satisfying $a + b = c$, the inequality $$c<K\cdot\text{rad}(abc)^{1+\epsilon}$$ holds. A third formulation of the conjecture involves the quality $q(a, b, c)$ of the triple $(a, b, c)$, defined by: $$q(a,b,c)=\frac{\log(c)}{\log(\text{rad}(abc)}$$ I am particularly interested in the first definition, but any help with any of it would be greatly appreciated.","['open-problem', 'number-theory']"
196028,Using LDCT to show a function is continuous and differentiable,"We have the following test prep question, for a measure theory course: $\forall s\geq 0$, define $$F(s)=\int_0^\infty \frac{\sin(x)}{x}e^{-sx}\ dx.$$ a) Show that, for $s>0$, $F$ is differentiable and find explicitly its derivative. b) Keeping in mind that $$F(s)=\int_0^\pi \frac{\sin(x)}{x}e^{-sx}\ \ dx\ +\int_\pi^\infty \frac{\sin(x)}{x}e^{-sx}\ dx,$$ and conveniently doing integration by parts on the second integral on the right hand side of the previous equation, show that $F(s)$ is continuous at $s=0$.  Calculate $F(s)\ (s\geq 0)$. Since it's a measure theory course, I'm thinking there are methods involving the things you typically learn in these courses, and I think Lebesgue's Dominated Convergence Theorem will play a role, because I was looking at books by Bartle and Apostol, and they both have similar exercises or theorems, and both use LDCT. Also, I suppose these proofs regarding continuity or differentiability could be done with standard calculus stuff (like $\epsilon$'s and $\delta$'s or the actual definition of a derivative), but I want to avoid these methods and focus on what I should be learning from the class. I think I have part (a), or at least a good idea, based on the Bartle book.  If I let $f(x,s)=\frac{\sin(x)}{x}e^{-sx}$, I just need to find an integrable function $g$ such that $\big|\frac{\partial f}{\partial s}\big|\leq g(x)$ (after showing that partial does exist, of course :) ). And then, $$\frac d{ds}F(s)=\int _{\mathbb{R}^+}\frac{\partial f}{\partial s}\ dx.$$ Please correct me if I'm mistaken, or missing something. Now, for part (b) I'm a little stumped.  In the Apostol book, the case $s>0$ is done explicitly, but I read through it and it didn't help me.  Looking at the Bartle book, I get the idea of defining $f_n=(x,s_n)$, where $s_n=\frac1{n+1}$ or some such sequence that goes to zero.  Then, somehow, maybe, LDCT kicks in (but I guess I'd have to find a function what would dominate these $f_n$).  I also don't really see the point in dividing the integral into the two parts up there, so I must be missing something.","['measure-theory', 'continuity', 'integration', 'derivatives']"
196032,Proving $\bigcup A - \bigcup B \subset \bigcup(A-B)$,I need to prove: $\bigcup\limits_{i} A - \bigcup\limits_j B \subset \bigcup\limits_j (A-B)$ $\bigcap\limits_{i} A - \bigcap\limits_j B \subset \bigcup\limits_j (A-B)$ So when can the equality hold? Appreciate your help.,['elementary-set-theory']
196038,"Example that a measurable function $f$ on $[1,\infty )$ can be integrable when $\sum _{n=1}^{\infty }\int_{n}^{n+1}f$ diverges.","I am seeking help in my attempt to formulate a proof to disprove the following. For a measurable function $f$ on $[1,\infty )$ which is bounded on bounded sets, define $a_n= \int_{n}^{n+1}f$ for each natural number $n$. Is it true that $f$ is integrable over $[1,\infty )$ if and only if the series $\sum _{n=1}^{\infty }a_{n}$ converges ? I strongly suspect this to be false and could prove that if the series converged absolutely then $f$ is integrable over $[1,\infty )$ but i am unsure how to extend this to answer the question based on conditional convergence of the series. Any help would be much appreciated.","['measure-theory', 'sequences-and-series', 'integration', 'real-analysis']"
196040,Intersection of distinct maximal subgroups in a finite simple group,Suppose $G$ is a finite simple group in which every proper subgroup is abelian. If $M$ and $N$ are distinct maximal subgroups of $G$ show that $M \cap N = 1$. My plan for this problem is to use abelianess of proper subgroups of $G$ to produce a map out of $G$ with kernel $M \cap N$. I am not sure if I am on the right track.,"['group-theory', 'abstract-algebra']"
196043,Sigma Algebras generated by two classes of subsets,"If $A_1$ and $A_2$ are two collection of subsets in $\Omega$  (Sample Space), I need to prove that 
$$\sigma(A_1) \subseteq \sigma(A_2).$$  I understand that there exist minimal unique $\sigma$-algebras generated by $A_1$ & $A_2$ respectively. However, I am not sure what needs to be demonstrated mathematically, in order to prove the subset status. I tried to construct an example for this.
Let A1={1,2} , A2={1,2,3} , Ω={1,2,3,4} Then, σ(A1)={∅,Ω,{1,2},{3,4}} σ(A2)={∅,Ω,{1,2,3},{4}} How can I proceed beyond this. I am confused as how to interpret the subsets as opposed to elements. Appreciate your comments. Thank you.",['measure-theory']
196048,Application of Trigonometry,"My question is-
From an aeroplane vertically over a straight road,the angles of depression of two consecutive kilometer-stones on the same side are 45 degrees and 60 degrees.Find the height of the aeroplane from the road. Any solution to solve this question would be greatly appreciated.",['trigonometry']
196067,how to calculate the exact value of $\tan \frac{\pi}{10}$,"I have an extra homework: to calculate the exact value of $ \tan \frac{\pi}{10}$ . 
From WolframAlpha calculator I know that it's $\sqrt{1-\frac{2}{\sqrt{5}}} $, but i have no idea how to calculate that. Thank you in advance,
Greg",['trigonometry']
196068,Relationship between two random variables?,"What is the relationship between a random variable obeying the subexponential distribution defined here and a random variable $X$ satisfying $P\left(\left|X\right|>t\right)\le\alpha e^{-\beta t}$ for all $t>0$ and some $\alpha,\beta>0$ ? Thanks a lot for any helpful answers.","['statistics', 'measure-theory', 'probability-theory', 'probability-distributions', 'probability']"
196083,Continuation of strictly monotone functions on $\mathbb{R}$,"While studying the properties of ordinal utility functions, I came across the following question. Given a strictly increasing function $f : D \rightarrow \mathbb{R}$, where $D$ is an arbitrary non-empty subset of $ \mathbb{R} $, can one always find a strictly increasing function $g : \mathbb{R} \rightarrow \mathbb{R}$ that is defined everywhere on $\mathbb{R}$ and is equal to $f$ everywhere in the set $D$? I feel that the answer should be positive, however, there might be some counterexample I'm unaware of.","['elementary-set-theory', 'functions', 'order-theory']"
196095,Compute the limit of $\sum\limits_{k=1}^{n} \left(\frac{k}{n^2}\right)^{1+k/n^2}$ when $n\to\infty$,"Compute the limit
  $$\lim_{n\to\infty} \sum_{k=1}^{n} \left(\frac{k}{n^2}\right)^{\frac{k}{n^2} + 1}$$ At a first look, I only thought of Riemann sums, but I don't see how I may apply it. What else could I do? I need some hints, suggestions.","['sequences-and-series', 'real-analysis', 'limits']"
196096,If $A \in M_2(\mathbb R)$ non identical with $A^3=I $ then $\text{tr}(A)=-1$,"Let $A \in M_2(\mathbb R)$ a $2\times 2$ matrix with real coefficient, such that $A \ne I$ and
  $$
A^3=I
$$
  Then $\text{tr}(A)=-1$. What if we consider $M_n(\mathbb R)$? Is the statement still true? I didn't manage to solve it, but I have a question: can we say $A$ is non singular? Indeed, 
$$
A^3=I \Rightarrow AA^2=A^2A=I\Leftrightarrow A^{-1} = A^2.
$$ Is it right? How can we prove the statement?",['matrices']
196100,How to prove if function is increasing,"Need to prove that function $$P(n,k)=\binom{n}{k}= \frac{n!}{k!(n-k)!}$$ is increasing when $\displaystyle k\leq\frac{n}{2}$. Is this inductive maths topic?","['induction', 'combinatorics']"
196153,Trig question I don't really understand,"$4\cos^2 \left( x +  \dfrac{1}{4}\pi \right)$ = 3 My final answer: $ x = \frac{11}{12}\pi+k\pi $ and $x =  \frac{7}{12}\pi + k\pi $ In the correction model it is $x = \frac{7}{12}\pi + k\pi $ and $x = -\frac{1}{12}\pi+k\pi$ (and $x = -\frac{1}{12}\pi+k\pi$ equals $x = 1\frac{11}{12}\pi+k\pi$ and not $ x = \frac{11}{12}\pi+k\pi $ I reposted this because the answers on the original question didn't suffice. Also, reposting  on this forum is just like bumping your old post up right? If not, I'm sorry, I don't want to spam, but from previous times I learned that reposting only bumps up the original post..","['trigonometry', 'algebra-precalculus']"
196155,Strategies to denest nested radicals $\sqrt{a+b\sqrt{c}}$,"I have recently read some passage about nested radicals, I'm deeply impressed by them. Simple nested radicals $\sqrt{2+\sqrt{2}}$,$\sqrt{3-2\sqrt{2}}$ which the later can be denested into $1-\sqrt{2}$. This may be able to see through easily, but how can we denest such a complicated one $\sqrt{61-24\sqrt{5}}(=4-3\sqrt{5})$? And Is there any ways to judge if a radical in $\sqrt{a+b\sqrt{c}}$ form can be denested? Mr. Srinivasa Ramanujan even suggested some CRAZY nested radicals such as:
$$\sqrt[3]{\sqrt{2}-1},\sqrt{\sqrt[3]{28}-\sqrt[3]{27}},\sqrt{\sqrt[3]{5}-\sqrt[3]{4}},
\sqrt[3]{\cos{\frac{2\pi}{7}}}+\sqrt[3]{\cos{\frac{4\pi}{7}}}+\sqrt[3]{\cos{\frac{8\pi}{7}}},\sqrt[6]{7\sqrt[3]{20}-19},...$$
Amazing, these all can be denested. I believe there must be some strategies to denest them, but I don't know how. I'm a just a beginner, can anyone give me some ideas? Thank you.","['radicals', 'nested-radicals', 'algebra-precalculus', 'proof-writing']"
196156,Finding $\sum\limits_{n=1}^{9999} \frac{1}{(\sqrt{n+1}+\sqrt{n})(\sqrt[4]{n}+\sqrt[4]{n+1})} $,How we can find $$\sum_{n=1}^{9999}  \frac{1}{(\sqrt{n+1}+\sqrt{n})(\sqrt[4]{n}+\sqrt[4]{n+1})}   $$,"['summation', 'algebra-precalculus']"
196161,Show that the Topologies of $\mathbb{R}_l$ and $\mathbb{R}_K$ are not comparable.,"Here, $\mathbb{R}_l$ is the lower limit topology on $\mathbb{R}$ and $\mathbb{R}_K$ is the K-topology on $\mathbb{R}$. I understand the proof that these topologies are strictly finer than $\mathbb{R}$, but I am at a loss to begin how to show they aren't comparable. This is from Munkres book.",['general-topology']
196170,Is an elementary family of sets always an algebra of sets?,"Definition 1: An algebra of sets on a non-empty set $X$ is a non-empty collection $\cal{A}$ of subsets of $X$ that is closed under taking complements and finite unions. Definition 2: An elementary family of sets on a non-empty set $X$ is a collection $\cal{E}$ of subsets of $X$ such that (i) $\emptyset \in \cal{E}$ , (ii) $\cal{E}$ is closed under finite intersection, (iii) if $E \in \cal{E}$ , then $E^c$ is a finite disjoint union of members of $\cal{E}$ . Proposition: If $\cal{E}$ is an elementary family of sets, then the collection $\cal{A}$ of finite disjoint unions of members of $\cal{E}$ is an algebra of sets. Proof: It's easy to show that if $A,B \in \cal{E}$ , then $A \setminus B \in \cal{A}$ (just write $A \setminus B = A \cap B^c$ and apply property (iii) to $B^c$ ). Using this observation, we write $A \cup B = (A \setminus B) \sqcup B$ , and conclude that $A \cup B \in \cal{A}$ , as well, for any $A,B \in \cal{E}$ . The rest of the proof follows by induction. Question: Is every elementary family of sets in fact an algebra of sets? Look at the proof: we make an observation there that if $A,B \in \cal{E}$ , then $A \cup B \in \cal{A}$ . But $\emptyset \in \cal{E}$ , so we may as well say that if $A \in \cal{E}$ , then $A = A \cup \emptyset \in \cal{A}$ . Reference: Folland, Real Analysis , pp. 23-24.",['measure-theory']
196171,Pf. of weak lower semicontinuity for convex Lagrangians,"This question is about the proof of Theorem 1 in Chapter 8 of Evans' PDE book (p. 468 in the 2nd edition). Let $u,u_k\in\mathrm{W}^{1,q}(U)$ for all $k\in\mathbb{N}$, $U\subset\mathbb{R}^n$ be open, bounded, $L$ smooth, $1<q<\infty$ and 
$$G_\epsilon=E_\epsilon\cap F_\epsilon$$ where $E_\epsilon$ measurable s.t. $|U-E_\epsilon|\le \epsilon$ and
$$F_\epsilon=\left\{x\in U\,|\,|u(x)|+|Du(x)|\le\frac{1}{\epsilon}\right\}.$$
If $$u_k\rightarrow u\;\;\text{uniformly in}\;\;E_\epsilon$$
why does the limit
$$ \lim_{k\rightarrow\infty}\int_{G_\epsilon} L(Du,u_k,x) dx = \int_{G_\epsilon}L(Du,u,x)dx, $$
hold? I suppose this is the reason why $F_\epsilon$ is defined as it is, but I don't see the exact connection.
I would appreciate if somebody could look it up and help me out :-).","['multivariable-calculus', 'calculus-of-variations', 'partial-differential-equations']"
196175,"What does it mean mathematically to set some of the integration constants in the general solution to a linear differential equation, equal to zero?","I'm trying to calculate the position of a particle in a quadrapole magnet depending on the entry position $x_0$ and the combined (constant) physical parameters $k$. 
Given an equation $$x(t) =\frac{(\frac{x''(t)}{k})''}{k},$$ solving via assuming that $x(t) = e^{\lambda t}$ et,c... I arrive at the general solution $$x(t) = c_1\cos(\sqrt{k}\cdot t)+c_2\sin(\sqrt{k}\cdot t)+c_3e^{-\sqrt{k}\cdot t}+c_4e^{\sqrt{k}\cdot t}$$ with $c_1,c_2,c_3,c_4$ arbitrary constants. What would it mean mathematically if I were to set say $c_1,c_2,c_3 = 0$, assuming I don't have other constraints (in my example I would have additional $x(0) = x_0$, but as far as I can see that doesn't forbid it). Given that they are arbitrary, I can't see a problem with it. Of course, if you have additional starting conditions, you have to set the constants accordingly, but in my example $c_4 = x_0$ seems to do the job and leaves me with a much simpler solution. So why would I ever NOT eliminate every unnecessary term?","['ordinary-differential-equations', 'calculus', 'integration', 'physics']"
196195,Topology of matrices,"1.Consider the set of all $n×n$ matrices with real entries as the space $\mathbb R^{n^2}$ .
Which of the following sets are compact? (a) The set of all orthogonal matrices. (b) The set of all matrices with determinant equal to unity. (c) The set of all invertible matrices. 2.In the set of all $n×n$ matrices with real entries, considered as the space $\mathbb R^{n^2}$ , which of the following sets are connected? (a) The set of all orthogonal matrices. (b) The set of all matrices with trace equal to unity. (c) The set of all symmetric and positive definite matrices. FOR 1 (a) may be true as determinant mapping is continuous and it maps to the compact set{1,-1} but it is only a necessary condition.and (c) is not true as determinant mapping is continuous and it maps to a non compact set.do not know about (b).but i think it is not true. FOR2 (a) is not correct.do not know about (b) & (c)","['general-topology', 'matrices', 'compactness', 'connectedness']"
196197,Finding solutions for a linear system of equations,"Got the following problem where I can't find a way to solve: Knowing $\begin{pmatrix}5\\ 3\\ 6\end{pmatrix}$ is the unique solution for the system  $Ax=\begin{pmatrix}2\\1\\1\end{pmatrix}$, with $A \in \mathbb{R}^{3\times3}$ and $B=\begin{pmatrix}
1 & 2 & 1 & 2 \\ 
1 & 0 & 4 & -1 \\ 
1 & 3 & -3 & 6
\end{pmatrix}$ Find all solutions for $ABx=\begin{pmatrix}2\\1\\1\end{pmatrix}$ What I've tried: The problem says that $Ax=b$ got unique solution, so I've tried by getting rid of $A$ by using the inverse matrix but it doesn't work sice I don't know $A$. Since the constant matrix is $\begin{pmatrix}2\\1\\1\end{pmatrix}$ for both systems, I've tried $ABx = Ax$ but that also doesn't work for me. Thanks in advance for your help and sorry for my bad English. Lucas",['linear-algebra']
196199,Rectangular spacing algorithm?,"Thank God, there is a math section to this site, I'm going insane I have a problem I know how to solve by trial and error but I'm trying to figure out the 'smart' way to do it so I can make it into a macro using auto-hotkey and never have to guess and check again. I think what I need is an algorithm to do the following, Here's the problem: For any large rectangle, place the least amount of smaller rectangles inside the large rectangle with as equal spacing as possible, the smaller rectangles will all be $A$ units wide and $B$ units long. Here's the parameters: Smaller rectangles can only have a maximum area of $250$ units.
Smaller rectangle can't be more than $20$ units in any direction.
Smaller rectangle can't be less than $10$ units in any direction.
Smaller rectangles may overlap. Here's how I manually solve it, takes a while and is messy: I divide the big rectangle area by the smaller rectangle area. This gives me the minimum amount of rectangles possible, assuming no minimum or maximum sizing limitations. In some cases, the minimum or maximum sizing limitations of the smaller rectangles means I will have to use a few more rectangles. If I had a $5 \text{unit}\times  200.01 \text{unit}$ big rectangle, for example, I would have to use $11$ small rectangles to fill the big rectangle (the $0.01$ makes me have to add another rectangle by itself), since I can't make the small rectangles longer than $20$ units according to the parameters. For most of these problems, the best way to figure out the best solution is to find the ratio of the sides of the big rectangle (a $200 \times 400$ rectangle would have a ratio $1:2$), and scale that down to the smaller rectangles. However, I have to be careful not to have a ratio that exceeds the size limits imposed on the smaller rectangles ($10$ minimum, $20$ maximum). Thanks for any help. It seems a lot simpler to me than how it looks on paper, but I still can't wrap my head around how to put it into an algorithm or solve it neatly in the quirky situations where you're not using nice clean numbers.","['geometry', 'algorithms']"
196202,prove that the entire function f is a polynomial.,"Suppose that $f$ is an entire function, and that in every power series $f(z)=\sum_{n=0}^{\infty} c_{n}(z-a)^n$
at least one coefficient is 0. Prove that $f$ is a polnomial. Hint: $n!c_{n}=f^{(n)}(a)$ Actually, this is a Rudin's book's exercise. I tried Cauchy inequality, and Liouville's theorem ( for $g(z)=\sum_{n=m}^{\infty} c_{n}(z-a)^n$ is bounded) but failed. I really want to solve that, but I don't have any idea. I need your help.","['power-series', 'complex-analysis', 'polynomials']"
196203,An indecomposable $\mathbf{Z}$-module whose injective hull is not indecomposable,"I'd like to find an indecomposable $\mathbf{Z}$-module whose injective hull is not indecomposable, and I'm running out of ideas: The only indecomposable $\mathbf{Z}$-modules I know are $\mathbf{Z}$, $\mathbf{Q}$ (which is the injective hull of $\mathbf{Z}$), $\mathbf{Z}/p^n\mathbf{Z}$, $\mathbf{Z}(p^\infty)$ (which is the injective hull of $\mathbf{Z}/p^n\mathbf{Z}$). All of these have indecomposable injective hulls, so I don't really know what to do. Does someone have an idea?","['abstract-algebra', 'abelian-groups']"
196207,Drawing sine and cosine waves,"I like mathematics and pretty much every mathematical subject, but if there is one thing I thoroughly dislike, it is drawing (functions, waves, diagrams, etc.) We have this important trig test coming up and I need to master the drawing of sine and cosine waves. Can you guys give me an action plan of how to draw (co)sine waves? Like what to do first, second and so on. I missed a month of school because of my pneumonia so I really need all the help I can get (outside of school).","['trigonometry', 'algebra-precalculus']"
196217,Finding if the limit does not exist,"I just want to know, in calculating limits, when I do direct substitution, and it gives 3/0 instead of 0/0, does it mean for sure that the limit does not exist?","['calculus', 'limits']"
197235,Some examples in C* algebras and Banach * algebras,"I would like an example of the following things. A Banach * algebra that is not a C* algebra for which there exists a positive linear functional (it takes $x^*x$ to numbers $ \geq 0$) that is not norm continuous. (Apparently if a Banach * algebra so much as even has a bounded approximate identity, then all positive linear functionals are continuous.  Does anybody have a proof of this?) An example of a Banach algebra with an unbounded approximate identity A couple of examples of some C* algebras and nonC* algebra Banach * algebras that admit nice representations into $B(H)$ other than those given by the GNS construction. An example of a Hilbert space $H$ and a C* subalgebra $A$ of operators on $H$ for which there exists a vector $v \in H$ such that $\overline{Av}$ does not contain $v$.  See here where I proved that if $v$ belongs to the usual family from Zorn's Lemma that decomposes $H$ into cyclic pieces, then $v$ cannot be an example for 4.  But maybe other $v$s can serve as an example? Decomposition of representations Partial answers are also much appreciated, and I caution that I am not asserting that examples to all 4 of these things exist.  If not, I'd like to see a proof why not.  But most of them should probably exist because I got the impression that they do from for example a textbook making a point of saying ""bounded approximate identity"" vs. ""approximate identity.""","['banach-algebras', 'examples-counterexamples', 'operator-algebras', 'von-neumann-algebras', 'functional-analysis']"
197254,"What are the odds a graph generated ""randomly"" represents a function?","I'm creating an activity for my class that teaches the vertical and horizontal line tests and for the life of me I can't figure out the probabilities involved. Here's the exercise: Draw 5 pairs of cards from a standard deck. Each pair defines a point in the plane: the first card is the x-coordinate of a point and the second card is the y-coordinate (Jacks = 11, Queens = 12, Kings = 13). Red cards are positive and black cards are negative. Plot the 5 points, shuffle the cards, repeat the process to get a total of 10 points. Question: What are the odds your graph passes the vertical line test? This isn't the question the students will be answering, they are just calculating the experimental probabilities by polling the class. I thought it would be cool to show them the theoretical odds so we could discuss how close we are, but so far I've only been able to find simple, easy-to-understand wrong answers. I imagine it's pretty likely I've just forgotten some combinatorics and this is actually pretty easy to figure out. (Update: About 34% is the most sensible answer I've gotten so far.)","['probability', 'functions', 'combinatorics']"
197279,A question about The Implicit Function Theorem,"here is a problem im trying to solve for a few days, and Im not getting sucess. Let $f:\mathbb{R}^2\rightarrow\mathbb{R}$ such that $f\in C^1$ and $F(x,y,z)=f(y/x,z/x)$. Consider a level surface $S$ defined by $F(x,y,z)=0$ and $(x_0,y_0,z_0)\in S$. What are the conditions, in a neighborhood of $(x_0,y_0,z_0)$, that we can write $S$ in the form $z=g(x,y)$ ?
Also, show that at this conditions, its true that
$$x\frac{\partial g}{\partial x}(x,y)+y\frac{\partial g}{\partial y}(x,y)=g(x,y)$$ Well, here is what I've done:
To use the Implicit Function Theorem I choose $F(x_0,y_0,z_0)=0$ and I have to show that $\frac{\partial F}{\partial z}(x_0,y_0,z_0)\neq 0$. 
$$\frac{\partial F}{\partial z}(x_0,y_0,z_0)=\textrm{lim}_{t\rightarrow 0}\frac{F(x_0,y_0,z_0+t)-F(x_0,y_0,z_0)}{t}=\textrm{lim}_{t\rightarrow 0}\frac{F(x_0,y_0,z_0+t)}{t}=\textrm{lim}_{t\rightarrow 0}\frac{f(y_0/x_0,(z_0+t)/x_0)}{t}\neq 0$$ Here I tried something that I dont know if is right, and even if is right, i couldnt conclude the right answer from this.
$$\textrm{lim}_{t\rightarrow 0}\frac{f(y_0/x_0,(z_0+t)/x_0)}{t}=\textrm{lim}_{t\rightarrow 0}\frac{f(y_0/x_0,(z_0/x_0)+(t/x_0))}{t}=\frac{1}{x_0}\frac{\partial f}{\partial y}(y_0/x_0,z_0/x_0)$$
I did this variable change $u=t/x_0$ with $u\rightarrow 0$ and calculate the limit. But Im really not sure about it and I didnt found the last equality they are asking. Thank you everyone one more time.","['real-analysis', 'analysis']"
197285,$|f(x)-f(y)|\geq k|x-y|$.Then $f$ is bijective and its inverse is continuous.,"My exercise says:
Let $f:\mathbb{R} \rightarrow \mathbb{R}$ a continuous function e suppose that exists $k$ such that: $$|f(x)-f(y)|\geq k|x-y|$$ Then $f$ is bijective and  its inverse is continuous. Well, there's a Theorem , Invariance of domain, that says ""If $U$ is an open subset of $\mathbb {R^n}$ and $f : U \rightarrow\mathbb{R}$ is an injective continuous map, then $V = f(U)$ is open and $f$ is a homeomorphism between $U$ and $V$"". But I'm not knowing how to proceed...need a clue...Thanks for attention!!!","['continuity', 'analysis']"
197295,What is the geodesic equation on $\mathbb{S}^{n}$?,"Suppose $\gamma: \mathbb{R}\rightarrow \mathbb{S}^{n}$ is a smooth curve. Let $\gamma(t)=(x^{1}(t)...x^{n+1}(t))$. Let $\mathbb{D}^{n}$ be embedded into $\mathbb{R}^{n+1}$ by viewing $\mathbb{R}^{n+1}$ as $\mathbb{R}^{n}\times \mathbb{R}$ and introduce coordinate embedding $$f: y\rightarrow \langle y, (1-|y^{2}|)^{1/2}\rangle$$ of the ball of radius 1 in $\mathbb{R}^{n}$ into $\mathbb{S}^{n}$. The round metric on $T\mathbb{S}^{n}$ identify $$\langle (x,v), (x,w)\rangle=\langle v, w\rangle$$ with $x\in \mathbb{S}^{n},v,w\in T\mathbb{S}_{x}$. Now in order to find a geodesic on $\mathbb{S}^{n}$ I need to find the Christoffel symbols $\Gamma^{i}_{jk}$. And to find Christoffel symbols I need to find the pull-back metric (from $\mathbb{D}^{n}\rightarrow \mathbb{S}^{n}$). Taubes now assert that we have $$g_{ij}=\delta_{ij}+y_{i}y_{j}(1-|y|^{2})^{1/2}$$ I am wondering why this is true. The pull-back metric for map between manifolds $\psi:M\rightarrow N$ and vector bundle $E\rightarrow N$ with a given fibre-wise metric is defined by $\langle (p,v), (p,w)\rangle=v\cdot w,p\in M, v,w\in E$. So in our case we are working with $\mathbb{D}^{n}\rightarrow \mathbb{S}^{n}$, with the bundle $T\mathbb{S}^{n}\rightarrow \mathbb{S}^{n}$ (endowed with round metric) pulled back. By definition of metric we would be expecting $g_{ij}(x)=\langle \partial y_{i},\partial y_{j}\rangle, \partial y_{i},\partial y_{j}\in T\mathbb{S}^{n}_{x}$. Now since $x=(y,(1-y^{2})^{1/2})$, by definition above we can pull it back to $f^{*}T\mathbb{S}^{n}_{x}$. But the evaluation seems to be the same and I could not understand how he get his formula. Since the sphere case is the simplest possible, I feel I need to ask for help. I also thought about differentiating directly. Then we would have $g_{ij}=\delta_{ij}+y_{i}y_{j}(1-|y|^{2})^{-1}$. This still does not match Taube's formula and I do not know what is wrong.",['differential-geometry']
197299,Expected value of maximum of two random variables from uniform distribution,"If I have two variables $X$ and $Y$ which randomly take on values uniformly from the range $[a,b]$ (all values equally probable), what is the expected value for $\max(X,Y)$?",['probability']
197312,When should I grab a bag of money?,"100 small bags of coins are placed in a large cauldron. The 99 of these bags that contain pennies have the same size. The single small bag of quarters is twice the size of a single bag of pennies. The probability of grabbing each bag is proportional to its size. 100 people get to each randomly grab a bag from this cauldron. If I want to grab the bag of quarters, when I should I grab a bag? For instance, should I do it first? Second? Last? My current hunch is that it does not matter. After all, the bags are randomly distributed, so this scenario should be no different from someone just randomly distributing all the bags at the same time. Is this reasoning sound?",['probability']
197316,Rigorous proof of the Taylor expansions of sin $x$ and cos $x$ revisited,"I asked this question a while ago.
I exchanged comments with a member(mixedmath) about the rigorous proofs that $\lim_{x\rightarrow 0} \frac{\sin x}{x} = 1$ and the addition formula for $\sin x$. He referred to the wikipedia article .
However, I'm not sure if the proofs using pictures are rigorous enough.
The proofs take it for granted that what an angle(measured by radian) is.
IMO, a straightforward and yet rigorous definition of an angle is that as an arc length of the unit circle. This definition involves the limit or the sup of suitable sums of lengths of line segments.
I don't see how this definition incorporates into the proofs.
Simply put, are the proofs of the wikipedia article rigorous?","['trigonometry', 'calculus', 'algebra-precalculus']"
197317,"What does $Tor^{R}_n(M,N)$ represent?","Let $R$ be a commutative ring and $M$ and $N$ be $R$-modules (I am not sure if one really needs commutativity in the following). It is well-known that $Ext_{R}^n(M,N)$ for $n>1$ parametrizes $n$-extension of $N$ by $M$, i.e. exact sequences 
$$
0\rightarrow M\rightarrow C_{1}\rightarrow \dots \rightarrow C_{n}\rightarrow N\rightarrow 0
$$
mod certain equivalent relations. Another way to see $Ext_{R}^n(M,N)$ is via derived category; it can be seen as a hom space in $D(R-mod)$
$$
Ext_{R}^n(M,N)=Hom_{D(R-mod)}(M,N[n]). 
$$ I now want to understand what $Tor^{R}_n(M,N)$ represent. How should one understand $Tor^{R}_n(M,N)$ intuitively?","['derived-functors', 'homological-algebra', 'algebraic-geometry']"
197328,Epsilon-Delta Proof for $x^n$ tends to 0,"What is the epsilon proof that $x^n \rightarrow 0$ as $n \rightarrow \infty$ provided $|x| < 1 $? I only know it's true because I know the geometric series converges, which implies its terms must tend to 0, but never seen an epsilon proof of this simple fact.",['real-analysis']
197331,How do I prove that in every commuting family there is a common eigenvector?,"The proof given by my textbook is highly non-satisfying. The author adopted some magic-like ""reductio ad absurdum"" and the proof (although is correct) didn't reveal the nature of this problem. I made my own effort into it and tried a different approach. Yet I can't finish it. Let $\mathscr{F}$ be a commuting family in $M_n(\mathbb{C}^n)$, and $A\in\mathscr{F}$, then $A$ has $n$ eigenvalues. We pick one, say $\lambda$. Let $x$ be one of its eigenvector. We can easily prove that, if $A$ has no other eigenvector with eigenvalue $\lambda$ that linearly independent with $x$, which means that $\{cx|c\in\mathbb{C}\}$ are the only vectors satisfying $Ax=\lambda x$, then $x$ is a common eigenvector. Because $\forall B\in\mathscr{F}$ and $\forall y\in \{cx|c\in\mathbb{C}\}$, $$A(Bx)=ABx=BAx=B(Ax)=B(\lambda x)=\lambda (Bx)$$, so that $Bx$ has to be in $\{cx|c\in\mathbb{C}\}$, that is, $Bx=c_0x$ for some $c_0\in\mathbb{C}$, which means $x$ is a eigenvector of $B$ too. But what if there are vectors satisfying $Ax=\lambda x$ that's not in  $\{cx|c\in\mathbb{C}\}$? Well, then we should have a set of linearly independent eigenvectors $\{x_1,x_2,...,x_k\}$, that $\{c_1x_1+c_2x_2+...+c_kx_k|c_i\in\mathbb{C}\}$ are the only vectors satisfying $Ax=\lambda x$. Now, I have a reasonable hypothesis that there exists some $x=c_1x_1+c_2x_2+...+c_kx_k$, that can be proven to be a common eigenvector of $\mathscr{F}$. I've tried some approaches to prove it but all failed. Do you guys believe it's true? And if it is true then how do I prove it?",['matrices']
197332,Evaluation map of sheaves $f^{*}(f_{*}\mathcal{F})\rightarrow\mathcal{F}$.,"Let $f:X\rightarrow Y$ be a projective morphism of algebraic varieties and $\mathcal{F}$ be a coherent sheaf on $X$. Then some people say that there is a canonical evaluation map 
$$
f^{*}(f_{*}\mathcal{F})\rightarrow\mathcal{F}, 
$$
which I don't quite understand the definition. I do understand both pushforward $f_{*}$ and pullback $f^{*}$ of sheaves, but how does one define ""evaluation"" map above?","['sheaf-theory', 'algebraic-geometry', 'coherent-sheaves']"
197345,how to prove the addition of transfinite cardinal numbers?,"How do you prove the following transfinite cardinal addition?: $ \alpha + \beta = \max(\alpha,\beta)$? And as the consequence, $\alpha + \alpha = \alpha$ where $\alpha$ and $\beta$ are transfinite cardinal numbers?","['cardinals', 'elementary-set-theory']"
197389,Proving properties of a sequence,"I just received my first assignment for a mathematical proofs course I am taking this year. We just began the course, and we have so far only covered examples of proofs (how to prove if-then statements in different ways) and the mathematical principle of induction. Here is the question I am having difficulty with: ""Define a sequence $a_n, n \ge 0,$ inductively by $a_0 = 2,$ and for all $n \ge 0, a_{n+1} = \sqrt{a_n + 1}.$ a) Prove that for every $n \ge 0, a_n > \frac{1+\sqrt{5}}{2}.$ b) Prove that for every $n \ge 0, a_n > a_{n+1}.$ (You may use the fact that the polynomial $x^2 - x - 1 < 0$ if and only if $\frac{1-\sqrt{5}}{2} < x < \frac{1+\sqrt{5}}{2}.$ What would be the best proof technique for these questions? Should I prove both using induction, or is there a simpler/better way?",['discrete-mathematics']
197392,Summation of a finite series involving permutations.,"$$\large \sum_{i = 2}^{25}P(i,2)$$
$P$ stands for ""permutations"".","['permutations', 'sequences-and-series']"
197393,Why does $\tan^{-1}(1)+\tan^{-1}(2)+\tan^{-1}(3)=\pi$?,"Playing around on wolframalpha shows $\tan^{-1}(1)+\tan^{-1}(2)+\tan^{-1}(3)=\pi$. I know $\tan^{-1}(1)=\pi/4$, but how could you compute that $\tan^{-1}(2)+\tan^{-1}(3)=\frac{3}{4}\pi$ to get this result?",['trigonometry']
197400,"If $\sum a_n$ converges, then $\sum \sqrt{a_na_{n+1}}$ converges","Prove that if the positve term series $\sum^{\infty}_{n=1}a_n$ is convergent, also $\sum^{\infty}_{n=1}\sqrt{a_na_{n+1}}$ is convergent. Prove that if the positive term series $\sum^{\infty}_{n=1}a_n$ and $\sum^{\infty}_{n=1}b_n$ are convergent, also $\sum^{\infty}_{n=1}a_nb_n$ is convergent. I've tried to solve it using comparison test, but no results.","['convergence-divergence', 'sequences-and-series']"
197408,"If $f$ has graph satisfying $|y|=|x^2-x^3|$, at how many points must it be differentiable?","I'm trying to do problem 2 here . Let $f(x)$ be a function defined for all real $x$ such that the coordinates of each point of its graph satisfy $|y|=|x^2-x^3|$ . The total number of points at which $f(x)$ must be differentiable is (A) none (B) $1$ (C) $2$ (D) $3$ (E) infinite The correct answer is B, but I'm completely stumped as to why that is. Is there an explanation for this answer?","['calculus', 'derivatives']"
197425,What does $\upharpoonright$ in $G(F\upharpoonright\alpha)$ mean?,"More formally, we can state the Transfinite Recursion Theorem as follows.  Given a class function $G\colon V\to V$, there exists a unique transfinite sequence $F\colon\mathrm{Ord}\to V$ (where $\mathrm{Ord}$ is the class of all ordinals) such that $F(\alpha) = G(F\upharpoonright\alpha)$ for all ordinals $\alpha$. (Wikipedia, transfinite induction) First question is, what does $\upharpoonright$ mean? Also, what exactly is $F$ in this usage? $F$ seems to be some form of function, but it says its transfinite sequence...","['notation', 'transfinite-recursion', 'ordinals', 'elementary-set-theory']"
197431,Construction of cut-off function,"I want to know the example of cut-off function. $\phi \in C^2 ([0,\infty))$ satisfies the followings : (1) $\phi(x) =1$ on $[0,r]$ (2) $\phi(x) =0$ on $ x > 2r$ (3) $- C r^{-1} \phi^{1/2}(x) \leq \phi ' (x) \leq 0$ on $r \leq x \leq 2r $ (4) $| \phi '' (x) | \leq C r^{-2}$ on $r \leq x \leq 2r$ Is there an explicit example about cut-off function ? Thank you in advance.",['differential-geometry']
197450,"If $\int_0^\infty f\text{d}x$ exists, does $\lim_{x\to\infty}f(x)=0$?","Are there examples of functions $f$ such that $\int_0^\infty f\text{d}x$ exists, but $\lim_{x\to\infty}f(x)\neq 0$? I curious because I know for infinite series, if $a_n\not\to 0$, then $\sum a_n$ diverges. I'm wondering if there is something similar for improper integrals.",['calculus']
197455,$\mathbb{R}$ represented using an infinite union of finite sets containing reals?,"If $S_1$, $S_2$, $\dots$ are sets of real numbers and if $\bigcup_{j=1}^{\infty}{S_j} = \mathbb{R}$ then one of the sets $S_j$ must have infinitely many elements. I believe at least one of the $S_j$ must be an infinite set, but I can't work out a proof. What's the trick I'm missing?",['elementary-set-theory']
197461,A proof problem from a first time real analysis course,"Given a continuous function $g:[a,b]\to\Bbb R$,
if there exists a number $K>0$ s.t. for all $x\in[a,b]$, $|g(x)| \le K \int_a^x |g|$, prove $g(x)=0$ for all $x\in[a,b]$. And I tried to derive some contradiction around $\inf g^{-1}(\Bbb R-\{0\})$ assuming $g\ne 0$, under given hypothesis, but I wasn't succesful.","['inequality', 'integration', 'real-analysis']"
197492,Why would the axiom of choice be needed if ordinals are well-ordered without AC?,"Will ordinals be well-ordered without AC? This seems to be obviously true, as they are by definition well-ordered. Why would we then need the axiom of choice. We can just form a bijection function to ordinals, allowing all sets to be well-ordered.","['ordinals', 'elementary-set-theory', 'axiom-of-choice']"
197496,series involving Catalan and Zeta,"I ran across another challenging and interesting series, and I am wondering if someone could shed some light on how to evaluate it. $$ \sum_{n=1}^{\infty}\sum_{k=1}^{\infty}\frac{1}{(n^{2}+k^{2})^{2}}=\zeta(2)\sum_{n=1}^{\infty}\frac{(-1)^{n-1}}{(2n-1)^{2}}-\zeta(4)$$ This has turned out to be rather challenging. At first glance, I thought it may be somewhere along the lines of the famous $$ \sum_{n=1}^{\infty}\frac{1}{n^{2}+k^{2}}=\frac{\pi}{2k}\coth(\pi k)-\frac{1}{2k^{2}}$$ that is often seen in Complex Analysis. So, I ran the first sum through Maple and it gave me: $$ \sum_{n=1}^{\infty} \sum_{k=1}^{\infty}\frac{1}{(n^{2}+k^{2})^{2}}=\frac{{\pi}^{2}}{4}\sum_{n=1}^{\infty}\frac{\coth^2(\pi n)}{n^{2}}+\frac{\pi}{4}\sum_{n=1}^{\infty}\frac{\coth(\pi n)}{n^{3}}-\frac{{\pi}^{2}}{4}\sum_{n=1}^{\infty}\frac{1}{n^{2}}-\frac{1}{2}\sum_{n=1}^{\infty}\frac{1}{n^{4}}$$ Of course, two of these are the very familiar $\zeta(2), \;\ \zeta(4)$.  I managed to evaluate $\displaystyle \sum_{n=1}^{\infty}\frac{\coth(\pi n)}{n^{3}}=\frac{7{\pi}^{3}}{180}$ using Complex Analysis. The one that has given me the fit is $\displaystyle\sum_{n=1}^{\infty}\frac{\coth^{2}(\pi n)}{n^{2}}$. This evaluates to $\displaystyle\frac{2}{3}K+\frac{19{\pi}^{2}}{180}$.  But, how?. I tried a Complex Analysis method, but had trouble finding the residues at $ni$, which are the zeroes of $\sinh^{2}(\pi n)$ . Anyone have any good ideas on how to evaluate the original sum at the top or even just this 'coth-squared' one?. Complex analysis or other wise.  I thought maybe a clever use of Fourier would work, but maybe not.",['sequences-and-series']
197505,Is $0.23571113171923293137\dots$ transcendental?,"Is the following number transcendental?
$$0.23571113171923293137\dots$$(Obtained by writing prime numbers consecutively from left to right, in the decimal expansion)","['transcendental-numbers', 'number-theory']"
197521,Balanced but not convex?,"In a topological vector space $X$, a subset $S$ is convex if \begin{equation}tS+(1-t)S\subset S\end{equation} for all $t\in (0,1)$. $S$ is balanced if \begin{equation}\alpha S\subset S\end{equation} for all $|\alpha|\le 1$. So if $S$ is balanced then $0\in S$, $S$ is uniform in all directions and $S$ contains the line segment connecting 0 to another point in $S$. Due to the last condition it seems to me that balanced sets are convex. However I cannot prove this, and there are also evidence suggesting the opposite. I wonder whether there is an example of a set that is balanced but not convex. Thanks!","['general-topology', 'topological-vector-spaces', 'convex-analysis', 'functional-analysis']"
197522,How to prove that $\lim_{n \to \infty} n x^{n} = 0 $ when $0<x<1$?,"Intuitively it's easy, but hard to prove by the epsilon-delta method: $$ \lim_{n \to \infty} n x^{n} = 0$$","['calculus', 'limits']"
197537,Can a non-compact manifold have infinite-dimensional cohomology?,"For compact manifolds, Hodge Theory tells us that (de Rham) cohomology is finite dimensional. What about non-compact manifolds? That is: Can non-compact manifolds have infinite dimensional cohomology? If the answer is yes, is there an example for which this is easy to see?","['homology-cohomology', 'differential-geometry', 'hodge-theory']"
197553,Topology from interiors of closed sets?,"Assume you've got an arbitrary topological space $X$. Now let $I$ be the set of the interiors of all closed subsets of $X$. And now assume you give me $I$, but don't tell me what $X$ is. Can I reconstruct the topology from $I$ alone? If it is not always possible, does there exist any commonly assumed additional feature of topological spaces so that if I restrict $X$ to topological spaces with that feature, the reconstruction is possible? Note that while all members of $I$ are open by construction, generally not all open sets of $X$ will be in $I$. For example on $\mathbb R$, the set $(-1,0)\cup(0,1)$ is open, but not the interior of a closed set.",['general-topology']
197567,Metric in riemannian Manifold,"Let $(M,g)$ be a riemannian Manifold, we can use the metric $g$ to obtain a metric $d_g:M\times M\to \mathbb{R}$. I ask for a kind of converse, we can start with a metric $d:M\times M\to \mathbb{R}$ and ask when we can recover a metric $g$ such that $d=d_g$. What obstructions need to be required on $d$ so the answer is positive, at least necessary?","['metric-spaces', 'differential-geometry']"
197569,Differential Equations with Deviating Argument,"Is there literature available on solving differential equations of the type
$$f(x,y(x),y(\kappa x),y'(x))=0,$$
where $\kappa$ is a given constant? I know about the book Introduction to the Theory and Application of Differential Equations with Deviating Arguments by L.E. El'sgol'ts and S.B. Norkin from the year 1973 [1], but I wonder if there are more recently published books available as well. Specifically, I would be interested in solving for example
$$u(2t)-2u'(t)u(t)=0$$ 
without guesswork. [1] Introduction to the Theory and Application of Differential Equations with Deviating Arguments, L.E. El'sgol'ts and S.B. Norkin, Mathematics in Science and Engineering, Volume 105, Academic Press, New York, 1973","['ordinary-differential-equations', 'real-analysis', 'analysis']"
197595,How to show that that $\sum_{n=1}^{\infty}\left( \frac{1}{3n-1} + \frac{1}{3n-2}- \frac{2}{3n}\right)= \ln\left(3\right)$?,"$$
\mbox{How to show that that}\qquad
\sum_{n = 1}^{\infty}\left({1 \over 3n - 1} + {1 \over 3n - 2} - {2 \over 3n}\right)
=
\ln\left(3\right)\ {\large ?}
$$
$$
\mbox{or}\quad
1 + \frac{1}{2} -\frac{2}{3} + \frac{1}{4} + \frac{1}{5} - \frac{2}{6} +\frac{1}{7} + \frac{1}{8} - \frac{2}{9} \cdots
=
\ln\left(3\right)
$$","['sequences-and-series', 'limits']"
197596,Frechet derivative,"I want to find the Fréchet derivative of the following functional:
$$
\begin{align}
F : C[-1,1] &\rightarrow \mathbb{R}\\
x &\mapsto x(0)\int_0^1 \sin\ x(t) \, dt.
\end{align}
$$
How can I do it?","['functional-analysis', 'derivatives']"
197602,"Asymptotic analysis of the integral $\int_0^1 \exp\{n (t+\log t) + \sqrt{n} wt\}\,dt$","The integral I'm trying to study is $$
F(n) = \int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}wt\right\}\,dt,
\tag{1}
$$ where $w$ is a fixed complex number with $\Re(w) < 0$ and $\Im(w) > 0$.  As I'll indicate below, I ""expect"" an asymptotic expression of the form $$
F(n) \sim A e^{n+\sqrt{n}w} n^{-1}.
$$ My first attempt at estimating $(1)$ was to try to address the problem of the oscillatory integrand.  I set out to mimic the method of steepest descent and deform the contour of integration so that the imaginary part of the argument $f(n,t) = n(t+\log t)+\sqrt{n}wt$ was constant. The image below shows where $\Re(f(n,t)) = \text{const.}$ (thick lines), where $\Im(f(n,t)) = \text{const.}$ (thin lines), and the interval $(0,1)$ (red line).  The parameter $n$ has been fixed at $10$. By Cauchy's theorem I can deform the contour $(0,1)$ to the contour $C_n$, on which $$
\Im(f(n,t)) = \sqrt{n}\Im(w),
$$ shown in red below. Thus I have $$
\begin{align}
F(n) &= \int_{C_n} \exp\left\{n(t+\log t)+\sqrt{n}wt\right\}\,dt \\
     &= \int_{C_n} \exp\left\{\Re\left(n(t+\log t)+\sqrt{n}wt\right) + \sqrt{n}\Im(w)\right\}\,dt \\
     &= e^{\sqrt{n}\Im(w)} \int_{C_n} \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt,
\end{align}
$$ so that at least now I'm dealing with a real integral.  However, I don't know where to go from here.  It's clear that $C_n \to (0,1)$ as $n \to \infty$, so I think the last integral above could be asymptotic to $$
\int_0^1 \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt = \int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}\Re(w)t\right\}\,dt,
\tag{2}
$$ but I don't know how to bound the ""error"" $$
\int_{E_n} \exp\left\{n(\Re(t)+\log |t|)+\sqrt{n}\Re(wt)\right\}\,dt,
$$ where $E_n$ is the closed loop $C_n \cup -(0,1)$, shown below. If this error is sufficiently small, I could see if I could apply the general ideas of the standard Laplace method to the real integral $(2)$, though it's not of the usual form.  My guess would be that $$
\int_0^1 \exp\left\{n(t+\log t)+\sqrt{n}\Re(w)t\right\}\,dt \sim A e^{n+\sqrt{n}\Re(w)} n^{-1}
$$ since the largest contribution to the integral comes from a neighborhood of $t=1$. Any help would be greatly appreciated.","['asymptotics', 'integration', 'complex-analysis']"
197614,locally self-similar topologies,"Call a topology ""locally self-similar"" if it has a basis in which each open set is homeomorphic to the entire space.  What topologies have this property? So far, I have the following list: Any set with the indiscrete topology (the whole space is the unique neighborhood of any point). The real numbers. The rational numbers (as a subspace of the real numbers). Probably the Cantor set or something similar (I'm not sure whether the endpoints look locally like the other points). Probably the Sierpinski carpet and lots of similar spaces. Probably the irrational numbers. Any finite product of spaces with this property. Anything else?  Is it possible to classify these spaces in any interesting way?",['general-topology']
197631,Determining partial derivatives and cross products for bicubic interpolation using function values only?,"I'm trying to implement a bicubic interpolation algorithm. In order to calculate the interpolated values, I need to calculate sixteen coefficients used in the calculation process - and that's where I'm stumped. So far I've tried to use the calculation methods for univariate functions as explained by Paul Bourke in his article on interpolation methods, calculating the coefficients for each vertical coordinate individually, using this data to determine the function values at the selected Y coordinate, using those values to calculate the coefficients for the given slice of the function and calculate the function value for the given X coordinate. This technically works, but does not give the same results as expected. Using the first coefficient calculation method described by Bourke, the image is closer overall but includes visible artifacts: Using Catmull-Rom splines (as described by Bourke), image is smoother but differs far more from the example I'm trying to recreate): ""A Review  of Some Image Pixel Interpolation Algorithms"" by Don Lancaster and the Wikipedia article on bicubic interpolation show decidedly different results using same data values. Both describe what (I assume) should be the correct way of calculating the coefficients - the final formula itself is pretty clear, but relies on determining several partial derivatives and cross products. It has been several years since I had calculus and while I understand what a partial derivative is, I no longer remember how to actually calculate it from given function values. I'm completely clueless as to the cross products - the subject might not have been actually covered during the calculus and linear algebra courses I took. I'd appreciate advice as to how I should proceed to properly determine those values.","['interpolation', 'cross-product', 'derivatives', 'algorithms']"
197636,"Problem understanding “and”,“or” and importance of “()” in set theory","I was reading the distributive law of sets (I keep coming back to basic maths when needed, forget it after some time, then come back again. Like I'm in loop): $A\cup(B \cap C)=(A\cup B)\cap(A\cup C)$ The proof (which I'm assuming everyone knows) has a transaction between lines which baffled me , which are: $x \in A$ or ($x\in B$ and $x\in C$) ($x\in A$ or $x\in B$) and ($x\in A$ or $x \in C$) in the second line, did they just applied distributive law? (in the proof of distributive law itself Oo) or Did they simple assumed ""and"" = ""+"" etc like following: $2 X (A + B) \equiv (2XA) + (2XB)$ Another question will be : ($x\in A$ or $x\in B$) or $x\in C\implies x\in A$ or ($x\in B$ or $x\in C$) I can just open the brackets?",['elementary-set-theory']
197641,what is the solution of this ODE,How to solve the following differential equation $$\frac{dy}{dx} + \frac{5y}{6x} = \frac{5x^4}{y^4}$$ subject to the condition $y(1) = 1$.,['ordinary-differential-equations']
197642,Does the complex conjugate of an integral equal the integral of the conjugate?,"Let $f$ be a complex valued function of a complex variable. Does
$$
\overline{\int f(z) dz} = \int \overline{f(z)}dz \text{ ?}
$$ If $f$ is a function of a real variable, the answer is yes as
$$
\int f(t) dt = \int \text{Re}(f(t))dt + i\text{Im}(f(t))dt.
$$ If $f$ is a complex valued function of a complex variable and belong to $L^2$, the answer is also yes as $L^2$ is a Hilbert space and, by conjugate symmetry of the inner product,
$$
 \overline{\langle f,g\rangle}=\langle g,f\rangle
$$
where $g(z)=1$ is the identity function. Apart from these two cases, is it otherwise true? Is it true in $L^1$?",['complex-analysis']
197656,Proving the trigonometric identity,Please help me in proving the following idenity: $$8\cdot \cos 40^\circ\cdot \cos 20^\circ \cdot \cos 10^\circ = \cot 10^\circ$$,['trigonometry']
197672,Locally closed subset equivalence proof using $\bar{L}\cap V = L \cap V$,"From 'Treatise on Analysis (vol 2)': (12.2.3) Let $L$ be a subset of a topological space $E$.  Then the following properties are equivalent:
(a)  For each $x\in L$ there exists a neighborhood $V$ of $x$ in $E$ such that $L\cap V$ is closed in $V$; (b)  $L$ is an open subset of the subspace $\bar{L}$ (the closure of $L$ in $E$); (c) $L$ is the intersection of an open subset and a closed subset of $E$. The book proves this with b $\Rightarrow$ c, c $\Rightarrow$ a, a $\Rightarrow$ b.  The last one however (a to b) is what I'm stuck on.  I am following their approach exactly for this particular proposition. Their proof for a $\Rightarrow$ b goes: For each $x \in L$, we have $V \cap L = V \cap \bar{L}$, because $V \cap L$ is closed in $V$; this shows that in the subspace $\bar{L}$ the point $x$ is an interior point of $L$, and therefore $L$ is open in $\bar{L}$. So the part I'm stuck on is showing that $\bar{L} \cap V = L \cap V$.  I wasn't sure whether the closure in that expression was w.r.t. subspace $V$ or the space $E$.  But assuming either leaves me stuck. Hints are more welcome, so that some work is left for me to learn from. Grazie.",['general-topology']
