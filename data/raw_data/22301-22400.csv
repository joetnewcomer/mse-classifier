question_id,title,body,tags
190762,"Dyck Paths, Catalan Numbers, and Trapezoidal Parallelogram Polyominoes","I've been trying to find the number of Dyck paths $P$ of length $2n$ such that $\forall (x,y) \in P, |x-y| \le k$ for some fixed constant $k$.  These are the Dyck paths that are bounded by the lines $y=x$, $y=x-k$, $y=0$, and $x=n$.  This is also the number of trapezoidal parallelogram polyominoes. If we let $P(n,k)$ be the number of paths, it is easy to prove that  $C_n \ge P(n,k) \ge (C_k)^{n/k}$, where the first equality is tight if $n\le k$ and the final equality is tight only for $k=1$. This question may be too general, but does anyone know of a closed form for the function $P(n,k)$ ?  Or at least have a clue about how to continue towards one?","['catalan-numbers', 'number-theory', 'combinatorics']"
190767,Shasha's safecracking problem,"Suppose you want to open a safe with 10 switches. For each switch there're 3 settings, say, 1,2,3. There're 2 key switches. The safe is unlocked once you set the key pair correctly, but you can't distingush the key ones from the others. The question is, how many tries do you need to be sure to open the safe, and how should you choose the combinations (an althorithm)?  (For example, if the safe has only 2 switches instead of 10, you need $3\times3=9$ tries) Will the number of tries grow less than linearly as the number of switches increases? Could there be a formula for a general problem of $n$ switches, $m$ settings and $k$ keys?","['puzzle', 'combinatorics']"
190773,Proof of $\frac{d}{dx}e^x = e^x$,"I'm working through the proof of $\frac{d}{dx}e^x = e^x$, and trying to understand it, but my mind has gotten stuck at the last step. Starting with the definition of a derivative, we can formulate it like so: $$\frac{d}{dx} e^x = \lim_{h \to 0} \frac{e^{x+h}-e^x}{h}$$ After some algebra, we arrive at: $$\frac{d}{dx} e^x = e^x \lim_{h \to 0} \frac{e^h-1}{h}$$ As $h\to0$, the expression approaches $\frac{0}{0}$, which makes it indeterminate. And, this is where my understanding ends. I've tried looking at wikipedia and other descriptions of the proof , but couldn't understand those explanations. It has usually been something along the lines of, ""plot $\frac{e^x - 1}{x}$ and see the function's behavior at $0$,"" which ends up approaching $1$, which can substitute the limit to give the result of the derivative: $$\frac{d}{dx} e^x = e^x \cdot 1 = e^x$$ I vaguely understand the concept of indeterminate forms, and why it is difficult to know what is happening with the function. But is there a better explanation of how the result of $1$ is obtained?","['calculus', 'limits']"
190779,Show that $X$ is independent of $\mathcal{G}$ given $E(X|\mathcal{G})$,"Given that $\mathcal{G}$ is a sub-sigma field. $Z=\mathbb E(X|\mathcal{G})$, how can we show that $X$ is independent of $\mathcal{G}$ given $Z$? I am struggling about the interpretation of this result. By definition, we only need to show that given $A\in \sigma(X)$, $B\in \mathcal{G}$ that $\mathbb P(AB|\sigma(Z))=\mathbb P(A|\sigma(Z))\mathbb P(B|\sigma(Z))$ , but I don't know how to deal with it then..","['probability-theory', 'probability']"
190792,Cartier divisors and non-reduced points,"Let X be a non-projective non-reduced scheme and let D be an effective Cartier divisor on X. Why is D disjoint from $Ass(\mathcal{O}_X)$? In other words, why can't reduced points lie in the support of any effectice Cartier divisor? The question comes from trying to understand Kleimann's example of a non-projective, non-reduced scheme for which there is not a bijective correspondence between Cartier divisors and line bundles. Thanks in advance for any insight.",['algebraic-geometry']
190794,Find whether or not an inverse exists algebraically,"Is there an algebraic(without graphs) way to determine the existence of a function's inverse without using calculus? I'm an undergrad engineer and can obviously solve this using basic calculus, but I'm having trouble finding a way to explain how to do this using only 11th grade math (explaining it to my sister).","['inverse', 'algebra-precalculus', 'functions']"
190806,Show $\lim_{x\to0}\frac{\Gamma(x)}{\psi(x)}=-1$,"How to show that
$$
\lim_{x\to0}\frac{\Gamma(x)}{\psi(x)}=-1
$$
where $\psi(x)$ is the digamma function.","['special-functions', 'limits']"
190817,Prove: Every compact metric space is separable,How to prove that Every compact metric space is separable$?$ Thanks in advance!!,"['general-topology', 'metric-spaces', 'compactness']"
190823,Where can I find a comprehensive guides to linear algebra and calculus?,"I'm a software engineer with a keen interest in all sorts of artificial intelligence and machine learning applications, and also quantum computing. Both areas require quite a bit of linear algebra and calculus, and I'm afraid mine is quite rusty. I'm looking for a good source on either or both. I'm not exactly a stranger to them, I'm familiar with the basics (functions, basic matrix operations, and a bit of single variable calculus I can remember from high school), but I'm more of a logic & set theory guy. Does anybody know of a good source that covers more than the basics, but isn't too technical? (I'm not a dedicated mathematician) Much appreciated :)","['linear-algebra', 'calculus', 'reference-request']"
190829,What's the right way to make a change of variables under another integral?,"Here's something that has me a little perplexed. I'm missing some step in making a change of variables under a multiple integral, where the new variable depends on more than one of the original ones. I can not think of a simplified example that demonstrates the problem, so I'll just list the actual integral I'm trying to do: $$\int_0^1\mathrm{d}\xi'\frac{1 + \xi'^2}{(1 - \xi')_+}\Biggl(\iint_{\mathbb{R}^2}\frac{\mathrm{d}^2\vec{t}_\perp} {(2\pi)^2}\exp\biggl[-\frac{t_\perp^2Q_s^2}{4}\biggr]\frac{e^{i\xi'\vec{k}_\perp\cdot\vec{t}_\perp}}{t_\perp^2} - \frac{1}{(2\pi)^2}\iint_{\mathbb{R}^2}\mathrm{d}^2\vec{r}'_\perp\frac{e^{-i\vec{k}_\perp\cdot \vec{r}'_\perp}}{r'^2_\perp}\Biggr)$$ Each of the two integrals over $\mathbb{R}^2$ is individually divergent because of a singularity at 0. But when I take the difference, the divergences will cancel out (perhaps only in some limiting sense, but that's really what I'm after). Accordingly, the way I tried to do this is to change variables in the second (inner) integral from $\vec{r}'_\perp$ to $-\xi'\vec{t}_\perp$ so that I could then subtract the integrands. I compute the Jacobian as $$\mathrm{d}\xi'\mathrm{d}^2\vec{r}'
 = \begin{vmatrix}\frac{\partial\xi'}{\partial\xi'} & \frac{\partial\xi'}{\partial t_x} & \frac{\partial\xi'}{\partial t_y} \\ \frac{\partial r'_x}{\partial\xi'} & \frac{\partial r'_x}{\partial t_x} & \frac{\partial r'_x}{\partial t_y} \\ \frac{\partial r'_y}{\partial\xi'} & \frac{\partial r'_y}{\partial t_x} & \frac{\partial r'_y}{\partial t_y}\end{vmatrix}\mathrm{d}\xi'\mathrm{d}^2\vec{t}
 = \begin{vmatrix}1 & 0 & 0 \\ -t_x & -\xi' & 0 \\ -t_y & 0 & -\xi'\end{vmatrix}\mathrm{d}\xi'\mathrm{d}^2\vec{t}
 = \xi'^2\mathrm{d}\xi'\mathrm{d}^2\vec{t}$$ I notice that by making this change of variables, I change the second term from something independent of $\xi'$ to something dependent on $\xi'$. But leaving that possible issue aside for now... I get $$\begin{gather}\int_0^1\mathrm{d}\xi'\frac{1 + \xi'^2}{(1 - \xi')_+}\Biggl(\iint_{\mathbb{R}^2}\frac{\mathrm{d}^2\vec{t}_\perp}{(2\pi)^2}\exp\biggl[-\frac{t_\perp^2Q_s^2}{4}\biggr]\frac{e^{i\xi'\vec{k}_\perp\cdot\vec{t}_\perp}}{t_\perp^2} - \frac{1}{(2\pi)^2}\iint_{\mathbb{R}^2}\mathrm{d}^2\vec{t}'_\perp\frac{e^{i\xi'\vec{k}_\perp\cdot \vec{t}'_\perp}}{t'^2_\perp}\Biggr)\\
=\int_0^1\mathrm{d}\xi'\frac{1 + \xi'^2}{(1 - \xi')_+}\iint_{\mathbb{R}^2}\frac{\mathrm{d}^2\vec{t}_\perp}{(2\pi)^2}\biggl(\exp\biggl[-\frac{t_\perp^2Q_s^2}{4}\biggr] - 1\biggr)\frac{e^{i\xi'\vec{k}_\perp\cdot\vec{t}_\perp}}{t_\perp^2}\end{gather}$$ I can express the inner integral in polar coordinates as $$\begin{gather}&\int_0^1\mathrm{d}\xi'\frac{1 + \xi'^2}{(1 - \xi')_+}\int_0^{2\pi}\mathrm{d}\theta_t\int_0^\infty\frac{\mathrm{d}t_\perp\,t_\perp}{(2\pi)^2}\biggl(\exp\biggl[-\frac{t_\perp^2Q_s^2}{4}\biggr] - 1\biggr)\frac{e^{i\xi' k_\perp t_\perp\cos\theta_t}}{t_\perp^2}\\
&=\int_0^1\mathrm{d}\xi'\frac{1 + \xi'^2}{(1 - \xi')_+}\int_0^\infty\frac{\mathrm{d}t_\perp}{2\pi t_\perp}\biggl(\exp\biggl[-\frac{t_\perp^2Q_s^2}{4}\biggr] - 1\biggr)J_0(\xi' k_\perp t_\perp)\\
&=-\int_0^1\mathrm{d}\xi'\frac{1 + \xi'^2}{(1 - \xi')_+}\frac{1}{4\pi}\Gamma\biggl(0, \frac{k^2 \xi'^2}{Q_s^2}\biggr)
\end{gather}$$ (the last equality comes from Mathematica, I haven't gotten to show it myself). But the true result is supposed to be $$-\int_0^1\mathrm{d}\xi'\frac{1 + \xi'^2}{(1 - \xi')_+}\frac{1}{4\pi}\biggl[\Gamma\biggl(0, \frac{k^2 \xi'^2}{Q_s^2}\biggr) {\color{red}{+ \ln\xi'^2}}\biggr]$$ I can't figure out where in this procedure that extra logarithm (in red) is supposed to come in. I guess it's supposed to be something in the change of variables that does it, but given that I've computed the Jacobian determinant and also the new region of integration (still $\mathbb{R}^2$), I don't know what else there would be. And I would very much like to know how I can avoid getting caught by this issue in the future.","['multivariable-calculus', 'integration']"
190835,Compute this limit of series: $\lim_{n\rightarrow \infty} \frac{1}{n^{3}}\sum_{k=1}^{n-1}k^2 $,"Compute this limit of series: $\displaystyle \lim_{n\rightarrow \infty} \frac{1}{n^{3}}\sum_{k=1}^{n-1}k^2 $ I used the definition of the definite integral $\displaystyle \int_{a}^{b}f(x)dx=\lim_{n\rightarrow \infty} S_{n}$ where $\displaystyle f(x)=x^2$, $\displaystyle [a,b]=[0,1]$; since the function is continuous in $\displaystyle [0, 1]$ then it is certainly integrated. $\displaystyle \int_{0}^{1}x^2dx=\lim_{n\rightarrow \infty} \sum_{k=1}^{n-1}\frac{1}{n}\ \left(\frac{k}{n}\right)^2=\lim_{n\rightarrow \infty} \frac{1}{n^3}\sum_{k=1}^{n-1}k^2$ We have: $\displaystyle\int_{0}^{1}x^2dx=\frac{1}{3}$ then $\displaystyle \lim_{n\rightarrow \infty} \frac{1}{n^{3}}\sum_{k=1}^{n-1}k^2 =\frac{1}{3}$ Any suggestions, please? This limit can be solved in other ways? Thanks.","['sequences-and-series', 'limits']"
190837,Prove that the baker map $B(x)$ is chaotic.,"I would like to show that $B(x)= 2x$ if $\ 0\leq x\leq 1/2$ $B(x)=2x-1$ if $\ 1/2 \leq x \leq 1$ is chaotic on [0,1]. I used the symbolic dynamics; any suggestions please? I briefly recall some definitions from ""An Introduction to Chaotic Dynamical System"" of R. L. Devaney: Let V be a set. $f: V \rightarrow V$ is said to be chaotic on V if 1) $f$ has sensitive dependence on initial condition, i.e. there exists $\delta>0$ such that, for any $x\in V$ and any neighborhood $N$ of $x$, there exists $y\in N$ and $n\geq 0$ such that $|f^{n}(x)-f^{n}(y)|>\delta$. 2) $f$ is topologically transitive, i.e. for any pair of open sets $J,I\subset V$ there exists $k>0$ such that $f^{k}(J)\cap I\neq 0$. 3) periodic points are dense in V. Now, let $f:A\rightarrow A$ and $g:B\rightarrow B$ be two maps. $f$ and $g$ are said to be topologically conjugate it there exists a homeomorphism $h:A\rightarrow B$ such that, $h\circ f=g \circ h$. Mappings which are topologically conjugate are completely equivalent in terms of their dynamics.","['general-topology', 'dynamical-systems']"
190843,Determinant of matrices along a line between two given matrices,"The question, with no simplifications or motivation: Let $A$ and $B$ be square matrices of the same size (with real or complex coefficients). What is the most reasonable formula one can find for the determinant $$\det((1-t)A + tB)$$ as a function of $t \in [0,1]$? If no reasonable formula exists, what can we say about these determinants? So we're taking a line between two matrices $A$ and $B$, and computing the determinant along this line. When $A$ and $B$ are diagonal, say $$A = \operatorname{diag}(a_1,\ldots,a_n), B = \operatorname{diag}(b_1,\ldots,b_n),$$ then we can compute this directly:
$$\begin{aligned}
\det((1-t)A + tB) &= \det \operatorname{diag}((1-t)a_1 + tb_1, \ldots, (1-t)a_n + tb_n) \\
&= \prod_{j=1}^n ((1-t)a_j + tb_j).
\end{aligned}$$
I'm not sure if this can be further simplified, but I'm sure someone can push things at least a tiny bit further than I have. I'm most curious about the case where $A = I$ and each $(1-t)A + tB$ is assumed to be invertible. Here's what I know in this case: writing
$$D(t) = \det((1-t)I - tB),$$
we can compute that
$$ \dot{D}(t) = D(t) c(t)$$
where
$$c(t) := \operatorname{trace}(((1-t)I + tB)^{-1}(B-I))$$
(a warning: I am not 100% sure this formula holds). Thus we can write
$$D(t) = \exp\left(\int_0^t c(\tau) \; d\tau\right)$$
since $D(0) = 1$.
I have no idea how to deal with the function $c(\tau)$ though. Any tips?","['linear-algebra', 'determinant']"
190844,Finding $E(\bar{X^2}|\bar{X})$ [duplicate],"This question already has an answer here : Closed 11 years ago . Possible Duplicate: Finding $E\Bigl(\overline{Y^2}\Bigm|\overline{Y\vphantom{Y^2}}\Bigr)$ by Basu's theorem? Suppose $X_1,\ldots,X_n$ are a random sample of $N(\theta,1)$. if $\bar{X^2}=\displaystyle\frac{1}{n}\sum_{i=1}^n X_i^2$, how can I find $E(\bar{X^2}|\bar{X})$?",['statistics']
190856,Nilpotent matrix over a division algebra,"Suppose I have an $n\times n$ nilpotent matrix $A$. If the entries are from any field, then I can show that all eigenvalues are zero and the trace is zero. Indeed, if we consider the algebraic closure of the field then the Jordan normal form $J$ of $A$ must be nilpotent, so all its eigenvalues are zero, which is of course in the original field itself. Also $\operatorname{tr}(J)$ is zero, and using the fact that $\operatorname{tr}(AB)=\operatorname{tr}(BA)$, it follows that $A$ (which is similar to $J$) must also have zero trace. But now I want to consider the case where the entries of $A$ are from a finite dimensional associative division algebra $D$ over a field $K$. If $K$ is algebraically closed then we are back in the case above since the only finite dimensional division algebra over an algebraically closed field is the field itself. But I'm having some difficulty with the case where $K$ is not necessarily algebraically closed - are the above still true? For simplicity let's assume that $K$ has characteristic $0$ but is not necessarily algebraically closed. The proof above (for a field) does not seem applicable in this case - at least I can't convince myself of it. I can't use the idea of algebraic closure, so I do not know if there exists any eigenvalues in $D$. Also, since commutativity does not in general hold in $D$, I do not know if the trace is invariant under a change of basis. The difficulty seems to be that I don't know what results continue to hold for a division algebra. Any ideas of a good way to think about this?","['linear-algebra', 'abstract-algebra', 'division-algebras']"
190866,What is the cardinality of the set of functions having finite image?,"If we are given two infinite sets $X$ and $Y$ we can consider the set $S$ of all functions from $X$ to $Y$, which has cardinality $|Y|^{|X|}$. Also, we can consider the set $F$ of all functions from $X$ to $Y$ having finite image. Is it true that $|F|=|Y|\cdot 2^{|X|}$? If not, what is the cardinality of $F$?","['cardinals', 'elementary-set-theory']"
190869,What is the probability that $XYZ$ is divisible by $5$?,"A solution of $X + Y + Z = 20$ in non-negative integers is chosen at random. What is the probability that $XYZ$ is divisible by $5$? Edit:
This happens to be an exam question. So I can't use calculators or computers and have to get the answer in less than 20 minutes while showing systematic workings. I appreciate the answers below, but can someone instruct me on solving the question given the mentioned constraints?",['probability']
190877,Matrix factorization,"I'd like to factorize matrices as follows: $$ \left(\begin{array}{cc}X_1&X_2\\X_3&X_4\end{array}\right) = \left(\begin{array}{cc}D_1&D_2\\D_3&D_4\end{array}\right)\left(\begin{array}{cc}P_1&\\&P_2\end{array}\right)\left(\begin{array}{cc}D_5&D_6\\D_7&D_8\end{array}\right) $$ provided such a factorization exists. The left-hand side is known and the right-hand side isn't. The $X_i$ are full $2^t\times 2^t$ ($t\ge 1$), the other blocks have same dimension with the $D_i$ being diagonal and the $P_i$ full. ( edit : the previous notations I used for the diagonal blocks $D_i$ might have been unclear, these blocks are not necessarily scalar multiples of the identity) Assuming a simple case where the diagonal matrices are invertible, the above problem amounts to solving the following nonlinear system of matrix equations (I use the same notations to simplify notations but the matrices are not the same as the previous one. The reason for this is to keep notations simple esp. given that what matters here is the structure of the blocks.) $$ \left\{ \begin{array}{lcl} X_1 &=& P_1 + P_2 \\ X_2 &=& P_1 D_1 + P_2 D_2\\ X_3 &=& D_3 P_1 + D_4 P_2\\ X_4 &=& D_3 P_1 D_1 + D_4 P_2 D_2\end{array} \right. $$ I've been looking for a way to solve this system but so far without much success. One thing I tried is to fix $D_1$ and $D_2$ (say), obtain the corresponding $P_1$ and $P_2$ with the first two equations and then find the best $D_3$ and $D_4$ in the Frobenius sense using the last two equations. Then start the other way around using $D_3$ and $D_4$. However this does not seem to converge (looks like projections on non-convex sets.). Also, given that there is $4n^2$ ($n:=2^t)$ equations with $2n^2+4n$ unknowns, maybe that this system can be further simplified. Any insight is most welcome, thanks! Edit: any result or idea on the potential infeasibility of finding an efficient/elegant way of solving this is also welcome. I've also been looking into the simplest case of this problem where each block is exactly $2\times 2$. In order not to use notations which would make this question even more confusing that it already is, I'll just use bullets to denote potentially non-zero entries since what really matters here is structure. $$ \left(\begin{array}{cc}  \left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)   & \left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)\\\left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)&\left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)\end{array}\right) 
= 
\left(\begin{array}{cc}\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)&\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)\\
\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)&\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)\end{array}\right)
\left(\begin{array}{cc}  \left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right) &\\&\left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)\end{array}\right)
\left(\begin{array}{cc}\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)&\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)\\
\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)&\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)\end{array}\right) $$ (lots of bullets...) when applying a perfect shuffle on this (aka bit-reversal) on this system, we get an equivalent system with the following form: $$ \left(\begin{array}{cc}  \left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)   & \left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)\\\left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)&\left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)\end{array}\right) 
= 
\left(\begin{array}{cc}  \left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right) &\\&\left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)\end{array}\right)
\left(\begin{array}{cc}\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)&\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)\\
\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)&\left(\begin{array}{cc}\bullet&\\&\bullet\end{array}\right)\end{array}\right)
\left(\begin{array}{cc}  \left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right) &\\&\left(\begin{array}{cc}\bullet&\bullet\\\bullet&\bullet\end{array}\right)\end{array}\right)
$$ which maybe can be considered in the context of simultaneous diagonalization of matrices? If solving this particular system can be done, I'm hoping it could give hints for the more general case. Thanks!","['matrix-decomposition', 'matrices', 'linear-algebra']"
190887,$p$-Sylow in quotient groups,Prove that if $P$ is a $p$-Sylow subgroup of $G$ and $N \triangleleft\> G$ then: $ PN/N $ is a $p$-Sylow subgroup of $G/N$ $P \cap N $ is a $p$-Sylow subgroup of $N$,"['finite-groups', 'group-theory']"
190895,Some question on Hilbert polynomial,"Let $S=k[X_1,\cdots,X_n]$ and $\{f_1,\cdots f_q\}$ be a $S$-regular sequence with ${\rm deg}(f_i)=a_i$. What is Hilbert polynomial of $S/ \langle f_1,\cdots,f_q\rangle$?","['commutative-algebra', 'algebraic-geometry']"
190904,A limitation related to multinomial distribution.,"recently I have a problem about the multinomial distribution. Here, for positive integer $n$, $$
t_{n}=\sum_{i=1}^{n}a^{i}\sum_{i_{1},\ldots i_{n}}\left(\begin{array}{c}
i\\
i_{1},\ldots i_{n}
\end{array}\right)p_{1}^{i_{1}}\ldots p_{n}^{i_{n}} 
$$
where $a\in\left(0,1\right)$. But the second summation has two conditions:
$$
\begin{cases}
i_{1}+i_{2}+\cdots+i_{n}=i\\
i_{1}+2i_{2}+\cdots+ni_{n}=n
\end{cases}
$$ In this case, can you obtain an easier expression for $t_n$. Actually, what I need is this: I know $\sum_{i=1}^{\infty}p_{i}=1$, and $\lim_{n\rightarrow\infty}\frac{p_{n+1}}{p_{n}}=c\in\left(0,1\right)$. Under these conditions, I need to get the limit of $t_{n}$  ratio, i.e., $\lim_{n\rightarrow\infty}\frac{t_{n+1}}{t_{n}}$. From the above expression, can I get the expression of $\lim_{n\rightarrow\infty}\frac{t_{n+1}}{t_{n}}$? Thank you in advance.","['probability-distributions', 'calculus', 'limits']"
190914,Do circles divide the plane into more regions than lines?,"In this post it is mentioned that $n$ straight lines can divide the plane into a maximum number of $(n^{2}+n+2)/2$ different regions. What happens if we use circles instead of lines? That is, what is the maximum number of regions into which n circles can divide the plane? After some exploration it seems to me that in order to get maximum division the circles must intersect pairwise, with no two of them tangent, none of them being inside another and no three of them concurrent (That is no three intersecting at a point). The answer seems to me to be affirmative, as the number I obtain is $n^{2}-n+2$ different regions. Is that correct?","['geometry', 'circles', 'combinatorics']"
190918,Compact operators and completely continuous operators,"A compact operator between Banach spaces is an operator that maps bounded sets into relatively compact sets, while a completely continuous operator maps all weakly convergent sequences into convergent sequences. Compact operators are always completely continuous, but completely continuous operators may be non-compact: the identity operator in the Schur space ${\rm l}_1$ is an example. In reflexive spaces, completely continuous operators are compact, so the two classes of operators are the same. Here are my questions: If the classes of compact operators and completely continuous operators are the same, what can we say about the space? Must it be reflexive? What can we say about the spectrum of completely continuous operators?","['operator-theory', 'compact-operators', 'functional-analysis', 'banach-spaces']"
190941,"What does ""$\cdots$"" mean in $\frac{n(n-1)(n-2)\cdots(n-r+2)}{(r-1)!}a^{n-r+1}b^{r-1}$?","In the formula, $$\frac{n(n-1)(n-2)\cdots(n-r+2)}{(r-1)!}a^{n-r+1}b^{r-1}$$ what does the ""$\cdots$"" mean?","['notation', 'algebra-precalculus']"
190950,Two solutions for $x$,"I am trying to solve this. I already got the answer but my doubt is if I am doing it right. There are two solutions for $x$ in the equation, to 2 decimal places.
  What is the value of the greater of the two solutions? $$a|x+b|+c = 0$$
          $a = 10$, $b = 4$ and $c = -46$ my solution's as follows: Step 1, Substitute the values: $$10|x+4|-46 = 0$$ Step 2, solve: $$10|x+4| = 46$$ $$|x+4| = +4.6$$ or $$|x+4| = -4.6$$ Hence $x$ can be  $x = 0.60$ or $x = -8.60$. is that the correct way of doing it?","['absolute-value', 'algebra-precalculus']"
190963,Delta Function as The Probability Distribution Function.,"When a random variable $X$ has only one possible outcome $x_0$, the probability density function at $X=x_0$ is infinite, while the probability density at other locations is zero. Then the p.d.f is exactly a delta function $\Pr(X=x) = \delta(x=x_0)$. However, when I tried to calculate the entropy of the random variable, the problem arises. How can I calculate the integral $\int_{-\infty}^{+\infty}{\delta(x-x_0)\log\delta(x-x_0) \, dx}$?",['probability']
190966,Evaluating $ \lim\limits_{n\to\infty} \sum_{k=1}^{n^2} \frac{n}{n^2+k^2} $,How would you evaluate the following series? $$\lim_{n\to\infty} \sum_{k=1}^{n^2} \frac{n}{n^2+k^2} $$ Thanks.,"['sequences-and-series', 'limits']"
190974,Recurrence equation similar to a geometric progression,"I have the following recurrence relation:
$$T(i) = \sqrt{T(i-1) \left(T(i+1) + k\right)},$$
with $k \geq 0$, a fixed constant. I know that when $k=0$, we have:
$$T(i) = \sqrt{T(i-1) T(i+1)},$$
which solution is $T(i) = e^{ai+b}$ (geometric progression), but I do not know if there is a solution for the general case. If there is no closed-form solution to it, as it seems to be the case, is there an easy way to compute $T(i),\;1 < i < n$ given $T(1) = A$ and $T(n) = B$ ? More generally, is there a systematic, elegant way to (numerically) compute recurrences when the initial conditions are not ""contiguous"" ?","['recurrence-relations', 'sequences-and-series']"
190982,"Prove Ramsey Number R(3,5)=14","I'm having problem proving the ramsey number of R(3,5) = 14. Below is my proof. Proof . Let $v_0$ be a vertex from a $k_{14}$ vertices. The vertices incident to $v_0$ are $v_1, v_2, \cdots , v_{13}$ with edges coloured with either red or blue. By Pigeonhole principle, there are at least $7$ ($kn+1=13,6\cdot 2+1=13,6+1=7$) edges coloured with either blue or red. Assume it to be coloured with blue. And let these be edges $\{(v_0,v_1),(v_0,v_2),\cdots , (v_0,v_7)\}$. If any of the edges between $v_1,v_2,\cdots , v_7$ is coloured with blue then we have a 3-blue clique, if none of them, then we have a 7-red clique. $\blacksquare$ Now, I'm confused. I get R(3,7) in my proof not R(3,5). Any suggestion?","['ramsey-theory', 'combinatorics']"
191006,Number of countable subsets of $\mathbb{R}$,"More generally, if a set $S$ has cardinality $\mathfrak{m}$, how many of its subsets have cardinality $\mathfrak{n}$? Clearly there are at least $2^\mathfrak{n}$ such subsets. I don't see how many more though. Thanks","['cardinals', 'elementary-set-theory']"
191007,Minimizing a function over two variables,"Given two natural numbers $i$ and $p$ such that $0 < i \leqslant 2^p$, let
$$
\psi(p,i) := p - \alpha + 1 - \frac{1}{2^p}\left((2^p+i)\lg(2^p+i) - i\lg i - i + \alpha - \frac{2^p}{i+1} -
    \frac{i}{2^p+1}\right),
$$
where $\alpha \simeq 1.264499$ and $\lg n$ is the binary logarithm of $n$ . I am looking for $\min_{p,i}\psi(p,i)$. It seems that $\min_{i}\psi(p,i) = \psi(p,2^p)$ or $\psi(p,2^p-1)$. Anyway, I can then minimize over $p$. We have
$$
\frac{\partial\psi}{\partial i}(p,i) = - \frac{1}{(i+1)^2} -
\frac{1}{2^p}\left(\lg(2^p+i) - \lg i - \frac{1}{2^p+1} - 1\right).
$$
(The derivative with respect to $p$ is much worse.) Also
$$
\lim_{i \rightarrow 0^{+}}\frac{\partial\psi}{\partial i}(p,i) = -\infty,\quad
\text{and}\quad
\left.\frac{\partial\psi}{\partial i}(p,i)\right|_{i=2^p} \!\!= \frac{1}{2^p(2^p+1)^2} > 0.
$$
The derivative is strictly increasing (the second derivative is positive). How can I prove that the root of $\partial\psi/\partial i = 0$ is between $i=2^p-1$ and $i=2^p$? And which of these values is the minimum?","['functions', 'inequality', 'real-analysis', 'optimization']"
191008,A curious limit for $-\frac{\pi}{2}$,"How to prove this ?
$$-\frac\pi2 = \lim_{x\to\infty}\sum_{n=1}^{\infty}(-1)^n \frac{x^{2n-1}}{(2n)! \ln 2n}$$","['pi', 'calculus']"
191014,How do I evaluate $\int \limits_{-\infty}^{a} e^{−t^2}dt$?,"I know that $$I \equiv \int \limits_{-\infty}^\infty e^{−t^2} \, dt=\sqrt{\pi},\text{ and }\int \limits_{-\infty}^0 e^{−t^2} \, dt=\frac{\sqrt{\pi}}{2}.$$ However, I don't understand if (or how) I can find a similar solution for $\int \limits_{-\infty}^{a}e^{−t^2}dt, a \neq 0$, given that the error function actually does not yield closed form solutions. Any help is greatly appreciated!","['normal-distribution', 'integration']"
191059,Two parallel lines and distance between three points on them.,"I'm solving one hard problem in my homework textbook (it is from the list of hardest problems in the end of book with stars). I reduced it to very simple question which I can prove by two, but very complicated and long ways (using Heron formula and some long algebra operations). It must be easy and simple (I hope) solution to this question, which i can't see. Question is : We have two parallel lines $(l_1,l_2)$ and the distance between this lines $|DE|=n$ an integer(see pic.), $n \in \mathbb{N}$. Let points $A$,$B \in l_1$ and $|AB|=|DE|=n$. Let point $C \in l_2$ and $|AC|=k,|BC|=m$. Prove that there are no exist such point $C$  that $k$ and $m$  both integer. (If $k,n \in \mathbb{N}$, then $m \notin \mathbb{N}$ or if $m,n \in \mathbb{N}$, then $k \notin \mathbb{N}$). I can prove it (like i said before it is very long analysis of equation which we can obtain using formulas for area), I'm looking for simple and short solution. Thanks. In my proof I use equation $$
4n^4=(n+k+m)(k+m -n)(n+k-m)(n-(k-m)), \ \text{if } x=k+m, y=k-m  \Rightarrow
$$ $$
5n^4-(x^2+y^2) n^2 +x^2 y^2=0.
$$",['geometry']
191076,The first cohomology of group,"I would like to ask if G is a group of order $p^4 (p\neq 2)$ as form $C_{p^3}\rtimes C_p$ (a semidirect product of cyclic group of order $p^3$ by a group of order $p$). Then can we obtain the first co-homology $H^1(C_p,C_{p^3} )$?
Is there any upper bound on the order of $H^1(C_p, C_{p^3})$? yours,","['homology-cohomology', 'group-cohomology', 'finite-groups', 'group-theory']"
191077,Evaluate $\int\frac{dx}{\sin(x+a)\sin(x+b)}$ [duplicate],"This question already has answers here : Evaluate $\int\frac{1}{\sin(x-a)\sin(x-b)}\,dx$ (4 answers) Closed 7 years ago . Please help me evaluate:
$$
\int\frac{dx}{\sin(x+a)\sin(x+b)}
$$","['calculus', 'integration']"
191082,visualization of the method of steepest descent,"I am trying to understand the method of steepest descent (complex integral).
I looked in some complex analysis books and also on Wikipedia, but I still don't understand
the methodology of approximating such integrals nor the name of this method.
Could someone give me a step by step example and a way to visualize it?",['integration']
191104,Ways to Choose Three Adjacent Elements from a Set,"In essence, how many unique ways can I choose a subset of N people such that there exist 3 people in the subset who are adjacent in the original set. e.g. N = 4
Lets label the people {1,2,3,4}
I can choose {1,2,3} , {2,3,4} , { 1,2,3,4} making a total of 3 ways. Here I assume that {1,2,3} = {3,2,1} etc. are the same Is there any general formula I can derive for calculating this?",['combinatorics']
191110,How to prove that the space of convergent sequences is complete?,"Let $X=\mathrm{Conv}(\mathbf R)$, the collection of all convergent sequences in $\mathbf{R}$. Is the normed space $(X,\|\cdot\|_\infty)$ complete?","['functional-analysis', 'banach-spaces']"
191118,Calculation of bessel function versus matlab solution,"I am looking to calculate the Bessel function of the first kind $J_o(\beta)$.  I am using the formula (referenced from wikipedia) to accomplish this. $$J_\alpha (\beta) = \sum_{m=0}^{\infty}\frac{(-1)^m}{m!\Gamma(m+\alpha +1)} \left(\frac{\beta}{2}\right)^{2m+\alpha}$$ I am also aware of that MATLAB has a function which can calculate the solution as well.  The function call is $besselj(nu,Z)$.  However, what I am finding is that there is a discrepancy between what my $for$ loop calculates and what MATLAB outputs. Does anyone see why this might be happening?  I have included my code for reference: loop_var = 100;
beta = 0.120;
alpha = 0;

sum = 0;
amp = 0;

[matl,ierr]  =besselj(alpha,beta)

for m=0:loop_var
    amp=amp+((-1)^m)/(factorial(m)*gamma(m+alpha+1))*(beta/2)^(2*m+alpha);
end
amp Thanks for all comments and suggestions. EDIT: Thanks to Fabian and Ed for catching that error. I suppose as a ""followup"" question, the wikipedia formula and that MATLAB function seem to only match for ""small"" values of $\beta$.  After $\beta$ is great than approximately 10, there is some error between the two values.  Does anyone then know how the Matlab number is obtained?","['matlab', 'special-functions', 'functions', 'transcendental-equations']"
191124,Generating function for characters of representations,"One example of such a generating function that I know how to derive is for $SU(2)$, $\frac{1}{(1-tx)(1-\frac{t}{x})}$. The coefficient of $t^n$ in the above function is the character in the $n+1$ dimensional representation of $SU(2)$ for elements conjugate to the element ""x"" . Similarly I have seen that for $SU(3)$ the function is, 
$$\frac{1-t_1 t_2}{(1-t_1Y_2)(1-t_1 \frac{Y_2}{Y_1})(1-t_2Y_2)(1-\frac{t_1}{Y_2})(1-\frac{t_2}{Y_1})(1-t_2 \frac{Y_1}{Y_2})}$$ The coefficient of $t_1^a t_2^b$ in the above function gives the character of the element in the conjugacy class of $Y_1^{T_3}Y_2^{T_8}$ of $SU(3)$ in the irreducible representation whose highest weight is $(a,b)$. I would like to know of the proof of the above. I would like to know of any general method of computing these functions (..like I have seen such a function in literature for $O(5)$ but again I don't know the derivation..)","['lie-algebras', 'representation-theory', 'abstract-algebra', 'lie-groups', 'group-theory']"
191129,Find the least interger m such that $S_n$ is embedd into $GL_m(F)$,"let $S_n$ be the permutation group on n letters, we know that there exists an injective group homomorphism from $S_n$ to $GL_m(F)$, where $F$ denotes a field, if $m=n$, so my question is: For a fixed n, what is the least possible nonzero integer of m, such that $S_n$ can be embeded into $GL_m(F)$?",['group-theory']
191148,"What is the largest determinant you can get by filling in 0,1 or 2 into a 4-by-4 matrix?","For example $$\left| \begin{array}{ccc}
2 & 0 & 0 & 2 \\
2 & 0 & 2 & 0 \\
0 & 2 & 1 & 2 \\
2 & 2 & 0 & 0 \end{array} \right|=40$$ Can it get bigger than that? And what's your approach?",['matrices']
191165,Proving an equality involving compositions of an integer,"Let's consider various representations of a natural number $n \geq 4$ as a sum of positive integers, in which the order of summands is important (i.e. compositions).  The task is to prove the number $3$ appears altogether $n2^{n-5}$ times in all of them. I know there're $2^{n-1}$ compositions of $n$. However, I have no clue as to how to count only those involving the number(s) $3$. I can't think of any sensible generating function for this. Maybe there's a nice combinatorial interpretation of the given formula, which I can't figure out? Could anyone lend me a hand with handling this problem?","['discrete-mathematics', 'combinatorics']"
191177,Computing the volume of a region on the unit $n$-sphere,"I would like to compute the surface volume of a region on the unit $n-1$-sphere: $$\sum_{i=1}^n x_i^2  = 1,$$ bounded by an ellipsoid $$\sum_{i=1}^n a_ix_i^2 \leq a_2,$$ where $1=a_1 < a_2 < \dots < a_n$. A couple nice properties are that The region is symmetric across each axis, so I need only worry about computing the volume in one orthant and then multiply by $2^n$, and the limits of integration are somewhat easy to compute. My approach so far has been to use Cartesian coordinates ($n$-spherical seemed a bit too daunting with all the powers of sines): $$\int_0^{\ell_2} dx_2 \int_0^{\ell_3(x_2)} dx_3 \dots \int_0^{\ell_n(x_2,\dots,x_{n-1})} \frac{dx_n}{\sqrt{(1-x_2^2-\dots - x_n^2)}},$$ where $\ell_2 = 1$, $\ell_3(x_2) = \sqrt{\frac{(a_2-a_1) - (a_2-a_1)x_2^2}{a_3-a_1}}$, $\ell_4(x_2, x_3) = \sqrt{\frac{(a_2-a_1) - (a_2-a_1)x_2^2 - (a_3-a_1)x_3^2}{a_4-a_1}}$, and so on, so $\ell_i(x_2, \dots, x_{i-1}) = \sqrt{\frac{1}{a_i-a_1}\left((a_2-a_1) - \sum_{j=2}^{i-1}(a_j-a_1)x_j^2\right)}$. The problem for me is that as soon as I compute the most internal integral, I get a rather nasty formula involving arcsin: $$\sin^{-1}\left(\sqrt{\frac{(a_2-a_1) - \sum_{j=2}^{n-1}(a_j-a_1)x_j^2}{(a_n-a_1)(1-\sum_{j=2}^{n-1}x_j^2)}}\right)$$ Since this is the innermost formula, I don't even know where to go from here. Playing tricks with the trig doesn't seem to help either. My questions are: Is there a better way to attack this? Is it even possible to get a solution in terms of the $a_i$? Is there an approximation to the value of the integral that I can work out in terms of the $a_i$ (perhaps with $O()$-notation)? I should also note that $n$ could easily be extremely large (on the order of thousands or millions), so I'd need a very general way to attack this problem.","['geometry', 'integration', 'multivariable-calculus']"
191198,Quadratic residues and representations of integers by a binary quadratic form,"Let $F = ax^2 + bxy + cy^2$ be a binary quadratic form over $\mathbb{Z}$.
We say $D = b^2 - 4ac$ is the discriminant of $F$.
Let $m$ be an integer.
If $m = ax^2 + bxy + cy^2$ has a solution in $\mathbb{Z}^2$, we say $m$ is represented by $F$.
If $m = ax^2 + bxy + cy^2$ has a solution $(s, t)$ such that gcd$(s, t) = 1$,
we say $m$ is properly represented by $F$. My question Is there any other proof of the following theorem other than the Gauss's original proof?
Since this theorem is important, I think having different proofs is meaningful. It would be also nice if some one would post a modern form of the Gauss's proof, since not everybody can have an easy access to the book. Theorem(Gauss: Disquisitiones Arithmeticae, art.154) Let $ax^2 + bxy + cy^2$ be a binary quadratic form over $\mathbb{Z}$.
Let $D$ be its discriminant.
Let $m$ be an integer.
Suppose $m$ is properly represented by $ax^2 + bxy + cy^2$.
Then $D$ is a quadratic residue modulo $4m$. EDIT The Gauss's DA is notorious for its difficult read. This was even so for his contemporaries.
Dirichlet devoted a lot of time to simplify DA.
There is a legend that Dirichlet always carried DA in his travels.
Gauss's proof often uses a ""magic"" equation which seems to come out of nowhere.
One of the reasons is that, as he wrote, he could not afford elaborate proofs due to lack of enough available pages for an economical reason.
So I think it would be nice if there is a more natural proof.",['number-theory']
191203,Help understanding $e^{it}=\cos t+i\sin t$ by way of matrices and vector fields,"I was brushing up on my complex arithmetic in preparation for a class in ODE's this semester and I found myself looking at Exercise 2.7.5 in Introduction to Complex Analysis for Engineers by Michael Alder, which reads The exponential function is a procedure for turning vector fields into flows; if you take the vector field which is given by$$V\begin{bmatrix}
x \\
y
\end{bmatrix}=\begin{bmatrix}
0 & -1\\
1 & 0
\end{bmatrix}\begin{bmatrix}
x \\
y
\end{bmatrix}$$
  you call the matrix $A$ and then the flow is given as $e^{tA}$. [...] Draw a picture of the vector field. Identify the matrix as a complex number. Deduce that $e^{it}=\cos t+i\sin t$ is little more than the observation that exponentiation is about solving ODE's by Euler's method taken to the limit. I would like very much to understand this very well. I've actually done most of it and perhaps the problem is that I haven't actually taken the ODE's class yet, but I've read ahead enough to understand most of what's being said. I drew the vector field (by hand) and got some lovely circley looking things. When he says, ""identify the matrix as a complex number,"" I understand that he is referring to the fact that in the book he defines a complex number $a+bi$ to be the matrix $$\begin{bmatrix}
a & -b\\
b & a
\end{bmatrix}$$and so $A$ is $i$. I also managed to do the exponentiation $e^{tA}$ and got $$\begin{bmatrix}
\cos t & -\sin t\\
\sin t & \cos t
\end{bmatrix}$$ Which is, of course, the complex number $\cos t + i\sin t$. So so far so good, I've shown that $e^{it}=\cos t + i\sin t$. I'm just having problems understanding the last little bit, and maybe that's cause I haven't taken the ODE's class yet, but I see that there are tangent lines to radiuses of circles somewhere in there since the vector field makes tangent lines to circles around the origin and $e^{At}$ ends up being the rotation matrix with angle $t$, so we have some notion of a radius rotating around the origin somewhere? How does this relate to Euler's method for solving ODE's? Is the idea that there is an ODE which produces that vector field as a direction field, and $e^{it}$ gives solutions? I get a little bit lost at this point, maybe someone can help me finish putting the pieces together.","['matrices', 'complex-numbers', 'ordinary-differential-equations']"
191207,Can the Sum Rule for derivatives be extended to infinite series?,"I wrote an answer here , which I'm not sure works. The sum rule for differentiation of two functions says that $D(u+v) = D(u) + D(v)$ where $D$ indicates the derivative, and $u$ and $v$ two functions.  The sum rule can get extended to any finite set of functions.  Since numbers can get regarded as functions, this implies that for any finite series $S=a + b + \dots+z$ we can evaluate $D(S).$  Can we extend the sum rule to differentiation of convergent infinite series?  Divergent infinite series?  Why or why not?","['calculus', 'derivatives']"
191210,is the smallest $\sigma$-algebra containing all compact sets the Borel $\sigma$-algebra,"Let $R$ be the smallest $\sigma$-algebra containing all compact sets in $\mathbb R^n$.
I know that based on definition the minimal $\sigma$-algebra containing the closed (or open) sets is the Borel $\sigma$-algebra. But how can I prove that $R$ is actually the Borel $\sigma$-algebra?","['measure-theory', 'compactness', 'real-analysis']"
191221,Quadratic residue character determined by a binary quadratic form,"Let $F = ax^2 + bxy + cy^2$ be a binary quadratic form over $\mathbb{Z}$.
We say $D = b^2 - 4ac$ is the discriminant of $F$.
Let $m$ be an integer.
If $m = ax^2 + bxy + cy^2$ has a solution in $\mathbb{Z}^2$, we say $m$ is represented by $F$. My question Is there any other proof of the following theorem other than the Gauss's original proof?
Since this theorem is important, I think having different proofs would be nice. It would be also nice if some one would post a modern form of the Gauss's proof, because not everybody can have an easy access to the book. Theorem(Gauss: Disquisitiones Arithmeticae, art.229) Let $F = ax^2 + bxy + cy^2$ be a binary quadratic form of discriminant $D$.
Suppose $D$ is not a square integer.
Let $p$ be an odd prime divisor of $D$.
Let $m$ and $k$ be integers which are not divisible by $p$.
Suppose $m$ and $k$ are represented by $F$.
Then $\left(\frac{m}{p}\right) = \left(\frac{k}{p}\right)$. Remark The above result and this question suggest that the repesentations of integers by an integral binary quadratic form might have a connection with the quadratic reciprocity law.",['number-theory']
191222,A matrix inequality,If $A=(a_{ij})$ is a real positive definite symmetric matrix of order $n$.  How to show $(n-1)\prod_{i=1}^na_{ii}+\det A\ge \sum_{i=1}^na_{ii}\det A(i)$? $A(i)$ means the submatrix of $A$ by deleting the $i$th row and $i$th column.,"['matrices', 'linear-algebra']"
191231,conditional probability that both answers are correct given that at least one is correct,"I came across this question whiles doing conditional probability and need a vivid explanation. A person answers each of two multiple choice questions at random. if there are four possible choices on each of the question, what is the conditional probability that both answers are correct given that at least one is correct","['statistics', 'probability']"
191259,Points lying on more than one irreducible component,"Let $X$ be a scheme over a field $k$.  Let $X = X_1 \cup \cdots \cup X_n$ be its decomposition into irreducible components.  If a point $x \in X$ lies in more than one component, is it necessarily singular? Why?","['commutative-algebra', 'algebraic-geometry']"
191261,Prove $\lim_{x\to\infty}x^{\ln(x)} = \infty$,"I am trying to prove $$\lim_{x\to\infty}x^{\ln(x)} = \infty$$ I am going to break this into two methods: one my professor mentioned and my method (which is where the question lies - skip ahead if you must!). Note that this is not homework, but simply an exercise my professor decided to do during notes the other day. The problem is taken from Stewart 7e Calculus (#70a in section 6.3 if you want to bust out your (e)-book). Method 1: Recall $\ln(e^x) = x, e^{\ln(x)} = x$. Thus we can write the original limit as
$$\lim_{x\to\infty}\left(e^{\ln(x)}\right)^{\ln(x)} = \lim_{x\to\infty}e^{\left(\ln (x)\right)^2}$$ He then let $u = \ln(x)$. As $x\to\infty$, then $u=\ln(x) \to\infty$. As $u\to\infty, v = u^2 \to\infty$. Also, as $v\to\infty, e^v \to\infty$. So, as $x\to\infty, e^{\left(\ln (x)\right)^2} \to\infty$. Thus it is sufficient to say $$\lim_{x\to\infty}x^{\ln(x)} = \infty \ \ \ \ \ \ \ \mathrm{Q.E.D.}$$ Method 2 (my attempt): Let $t = \ln x$. As $x\to\infty, t\to\infty$ because the $\ln$ function is strictly increasing. $$\lim_{x\to\infty}x^{\ln(x)}  \equiv \lim_{t\to\infty}x^t \tag{1}$$ Does the last statement of line (1) make sense mathematically though since the limit is with the variable $t$, yet the argument contains an $x$ still? Since line (1) may not be formally correct, I decided to try to write $x$ in terms of $t$. Recall that I made the substitution $t = \ln x \implies e^t = e^{\ln x} = x$. Thus I rewrote the limit as $$\lim_{t\to\infty}\left(e^t\right)^t$$ which diverges to $\infty$ for sufficiently large values of $t$. As an added bonus, are there any other 'simple' proofs for this limit?","['calculus', 'limits']"
191262,Probability / statistics calculation,"Lets say I have a series of 100 digits forming a number. 15 of those digits are always the same at the same place, 85 of those digits are randomly 1 to 5. I generate 10000 numbers this way. What would be the average lowest uniqueness of a random number compared to each other number where you start at 100% uniqueness and go -1% for each number that is the same on the same place. additional info with what I mean by average lowest uniqueness By lowest average uniqueness I mean, what would be the average uniqueness of all numbers compared to the one they have the most in common with. Kinda hard to explain example I generate 10.000 numbers with way, what would their average uniqueness be of those 10.000 numbers compared to the one they have to most in common with. So I take one number 1, find out it has the most in common with with number 7, being X% unique, now I do this for all numbers and then make an average of all those x% unique I get Real life application The real life application and reason why I ask is this. I write a 100 word text, and for each word I can find synonyms for I give them. for example : This is a {very,extremely} {difficult,complicated,hard} {question,equation}. Now when I generate 10000 texts based on this (with software) where it will each time take one of the options between brackets and put them online. Now google will try to see how unique my text is based on all the text that is online. I want for example to have my text be at least 60% unique compared to any text found online (only my text will really be a factor in this, seeing as I'm writing a 100 word text) I want to get an idea how many synonyms and text length I need to aim for given I want at least 60% uniqueness and I want to generate 5000, 10000 or even 20000 text. If I can get an idea how its calculated or what the value is for my example I can about guess how long and how many synonyms ill have to aim for in case I need 1000 5000 or even 20000 text generated.","['statistics', 'probability']"
191263,How can I explain this integer partitions function recursion?,"How to explain how this algorithm works? I need to write an article about this but I can't explain why this recursion works fine. It defines the number of partitions of a given integer function p(sum,largest):
    if largest==0: return 0
    if sum==0: return 1
    if sum<0: return 0
    return p(sum, largest-1) + p(sum-largest, largest) (call: p(n,n)) Thank you very much.","['recursion', 'algorithms', 'number-theory']"
191268,Absolutely continuous functions,"This might probably be classed as a soft question. But I would be very interested to know the motivation behind the definition of an absolutely continuous function.
To state ""A real valued function $ f $ on $ [a,b] $ is absolutely continuous on said interval if $\forall $$\epsilon >0 \ $, $\exists\delta>0\ $  such that 
$$
\sum^n_{k=1}|f(b_k) -f(a_k)|< \epsilon $$ for every $n$ disjoint subintervals $ \ (a_k,b_k) $ of $ \ [a,b] $, $k=1,\ldots,n$, such that
$ \sum^n_{k=1}|b_k -a_k|< \delta $.
Why the use of the disjoint sub-intervals? What purpose do they serve? Somehow the definition didn't seem natural to me. What I mean is just as the notion of uniform continuity is motivated by the definition of continuity itself or as the concept of compactness serves to generalise the notion of finiteness, how can one look at Absolute Continuity in this respect?",['real-analysis']
191273,Maximum total distance between points on a sphere,"What is the configuration (set of locations) of $n$ points on the surface of a sphere such that the sum of distances is maximum for $n=1,2,3,...$? The sum of distances is measured by summing the lengths of every straight line (through the sphere) connecting every possible combination of $2$ points. 
All the points are on a single sphere of radius $R$. Here's a visualization: Acknowledgements: Based on this Physics S.E. question. Image from StackOverflow .","['optimization', 'geometry']"
191296,"Universal property of free module, ""converse""","Let $F$ be a free $R$-module with a basis $B$. We know that $B$ satisfies the following property: For any $R$-module $M$ and any $g:B\rightarrow M$, there exists a unique $R$-map $\varphi:F\rightarrow M$ that extends $g$. Now suppose that $F$ is any $R$-module and $B$ is any subset of $F$. If $B$ satisfies the above property, is $B$ a basis of $F$? I think this is true for vector spaces. If $B$ doesn't span $F$ then there is no unique extension of $g$, and if $B$ is linearly dependent then the extension might not exist at all. But I'm having trouble extending my reasoning to modules, due to the lack of division and the presence of torsion elements.","['modules', 'abstract-algebra']"
191299,Solving a multiple choice question paper,"Firstly, I am not sure whether this is a mathematical problem. Please inform me in case it is not.
My question is as follows I have a online game with 14 questions. It's a kind of treasure hunt. Each question has 4 choices. The correct answer choices are unevenly distributed.
Choices B & C constitute 5 answers each and choice A & D constitute 2 answers each. Imagine a man without any knowledge about the quiz subject, what would be the best way to clear the quiz to go to the next level?
Once the user submits the answers, the system gives him reference links for questions he answered wrongly. But they will not be numbered and he will not know which references are for which question. The references will be in order and the user has unlimited attempts to crack the paper.
The user has to get 10 answers correct to crack the quiz. What is the best approach to follow to go to next level. 
The problem is a practical problem and I am not sure under which topic of mathematics this falls under.",['probability']
191307,Perimeter of an ellipse,How can I calculate the perimeter of an ellipse? What is the general method of finding out the perimeter of any closed curve?,['geometry']
191317,"Is $\langle a,b \mid a^2b^2=1 \rangle$ a semidirect product of $\mathbb{Z}^2$ and $\mathbb{Z}_2$?","All is in the title: Is $\langle a,b \mid a^2b^2=1 \rangle$ a semidirect product of  $\mathbb{Z}^2$ and $\mathbb{Z}_2$? I think it is the case, but I don't know how to prove it.","['group-theory', 'group-presentation']"
191321,What about without replacement,Cards are drawn at random and with replacement from an ordinary deck of 52 cards until a spade appears. what is the probability that at least 4 draws are necessary. Is this idea correct. The probability of picking a all non spades on 1 consecutive draw with replacement is 1/4.  2 consecutive is $(1/2)^2$  and 3 consecutive draw is $ (3/4)^3$. So $ 1 - (3/4)^3$ is the final answer. Is it okay to reason that way? What about without replacement?,"['statistics', 'probability']"
191340,What is the definition of a group entirely in first-order predicate logic?,"I've seen the definition of a group in many different books given as follows: A group is a nonempty set $G$ and a binary operation $*$, denoted by $(G,*)$ that satisfies the following properties: For every $a$, $b$, and $c$ in $G$, $(a*b)*c=a*(b*c)$; There exists $e$ in $G$ such that for every $a$ in $G$, $a*e=a$; For every $a$ in $G$, there exists $b$ in $G$ such that $a*b=e$. I would just like to clean this up and put it in predicate logic properly.  I have not seen this done in any book.  When I try to do this myself, I feel like I'm opening Pandora's box!  Here is how I have reasoned about this important definition: Let $G$ be any nonempty set and form the set containing $G$ as the only element, $\{G\}$.  Now let $*$ be set of all functions from $G\times G$ to $G$, so $*=\{\text{all functions } G\times G\rightarrow G\}$.  Next, we take the Cartesian product of $\{G\} \times * = \{ (G,*_1), (G,*_2), (G,*_3),\dots\}$.  So, basically we have set of ordered pairs where each ordered pair consists of a set and a function.  It seems that we are interested in whether or not each ordered pair satisfies the above properties.  Actually, it seems that for a particular ordered pair $(G, *_n)$ to be a group, it would only be dependent upon how the function is defined.  Depending on the cardinality of $G$, there are many functions from $G\times G\rightarrow G$, and we know that not all of these would be groups, nevertheless, it seems that $(G,*)$ is group if $*$ satisfies the above properties. So, I've tried to formulate the law of associativity using only ordered pairs.  Here is what I have come up with: For every $a$, $b$, $c$, $x$, $y$, $z$ in $G$ ($*$ is associative iff [$((a,b),x)$ in $*$ and $((x,c),y)$ in $*$ iff
$((b,c),z)$ in $*$ and $((a,z),y)$ in $*$]) I know this looks ugly, but since $*$ is really just a set of ordered pairs where the first coordinate is also an ordered pair, I tried to translate
For every $a$, $b$, $c$ in $G$, $(a*b)*c=a*(b*c)$ strictly into a statement with ordered pairs. Anyway, I'm not sure about this formulation.  For example, when we want to test if a relation $R$, on $S\times S$ is symmetric, we say for every $a$, $b$ in $S$, $R$ is symmetric iff $(a,b)$ in $R$ implies $(b,a)$ in R.  The difference is technically $*$ is a relation on $(G\times G)\times G$ and to test for associativity I said for every $a$, $b$, $c$, $x$, $y$, $z$ in $G$.  Can I do this since for symmetry, $R$ was a relation on $S\times S$  where the two sets are equal.  On $(G\times G)\times G$ the two sets are not equal, so I don't know if this is correct. Besides the issue with associativity, I'm not sure how to formulate the last two rules of groups in predicate logic and also I think we should include something about closure, perhaps. I just want to have one long statement in predicate logic that correctly gives the definition of a group incorporating everything in the English version given above. Any help would be appreciated.  Thanks.","['logic', 'group-theory', 'abstract-algebra']"
191351,Prove $H$ is normal subgroup,"I try to prove it, but I can't. Please tell it true or false? Let a group $G=G_1\times G_2$, i.e. $G$ is direct product of $G_1$ and $G_2$. If $H$ is normal subgroup of $G$, then $H$ will be direct product of $H_1$ and
$H_2$, for $H_1$, $H_2$ are normal subgroup $G_1$ and $G_2$, isn't it?",['group-theory']
191361,conjugate closed group,"Let H is a normal subgroup of G. For any $x\in H$, $x^H=\{h^{-1}xh:h\in H\}$ . A normal subgroup H of a group G is said to be conjugate closed , if $x^G=x^H$  for $x\in H$. A group G is said to be conjugate closed if every normal subgroup of G is conjugate closed . Prove that: A direct product of conjugate closed groups is conjugate closed group. i.e.:  If $G_1$ and $G_2$ is conjugate closed group, $G=G_1\times G_2$ is conjugate closed group! Of course, we have $x^H\subset x^G$, so what $x^G\subset x^H$? I try to prove it, but i can't. Please help me!",['group-theory']
191379,Limit (without series expansion and l'Hôpital's rule),"$$\lim_{x \to \infty}\ln{\frac{x+\sqrt{x^2+1}}{x+\sqrt{x^2-1}}}\cdot \left(\ln{\frac{x+1}{x-1}}\right)^{-2}=\frac{1}{8}$$ Any suggestion to find this limit without series expansion and l'Hôpital's rule? Thanks and regards. Note:
WolframAlpha confirms that the result is $\frac{1}{8}$.","['limits-without-lhopital', 'calculus', 'logarithms', 'radicals', 'limits']"
191387,True statements for a continuous function,"Let $f\colon \mathbb R\rightarrow \mathbb R$ be a continuous function. Define $G = \{(x, f(x)) : x \in \mathbb R\} \subseteq  \mathbb R^2$.
Pick out the true statements: a. $G$ is closed in $\mathbb R^2$. b. $G$ is open in $\mathbb R^2$. c. $G$ is connected in $\mathbb R^2$. I think c is correct since $f$ is continuous but no idea about a and b.","['general-topology', 'functions', 'continuity', 'real-analysis']"
191395,Correspondence between rotation representations,"I was wondering if there is a bijection between unit quaternions and other rotation representations such as vector of rotation, Euler angles or rotation matrices. It seems to me this is not the case but I cannot find a theoretical arguments to prove this point. Thanks.","['geometry', 'quaternions', 'rotations']"
191407,Function $f:\mathbb R^+\rightarrow \mathbb R^+$ that is eventually greater than $x^{x^{x^{...^{x^x}}}}$,"For each $n$, define $f_n:\mathbb R^+\rightarrow \mathbb R^+$ by 
$f_n(x) = \underbrace{x^{x^{x^{...^{x^x}}}}}_n$ I want to find a function $f:\mathbb R^+\rightarrow \mathbb R^+$ such that for any given $n$, $f$ is eventually greater than $f_n$. Here $\mathbb R^+$ means the non-negative reals.",['functions']
191429,Is a function globally Lipschitz continuous and $\mathcal{C}^1$ if and only if it is $\mathcal{C}^1$ and its total derivative is bounded?,"Is $f:\mathbb{R}^n\rightarrow\mathbb{R}^n$ globally Lipschitz continuous, i.e. there exists an $L>0$ such that $\frac{|f(x)-f(y)|}{|x-y|}\leq L$ for all $x,y\in\mathbb{R}^n$, and $\mathcal{C}^1$ if and only if $f$ is $\mathcal{C}^1$ and its total derivative is bounded? Based on intuition alone, I'm strongly inclined to believe that the answer is yes. However I'm having trouble coming up with a proof (probably because my grasp of multivariable calculus is far from great). Could someone give one if the statement is true, or provide a counter example if it is false? Thanks.","['multivariable-calculus', 'real-analysis']"
191446,"""Efficient version"" of Cayley's Theorem in Group Theory","I'm considering finite groups only.
Cayley's theorem says the a group $G$ is isomorphic to a subgroup of $S_{|G|}$.
I think it's interesting to ask for smaller values of $n$ for which $G$ is a subgroup of $S_n$. Obviously, it's not always possible to do better than Cayley's theorem. But sometimes it is possible (for example, $\mathbb{Z}_6$ as a subgroup of $S_5$). So I'm asking: Given a finite group $G$, is there an algorithmic way to find or approximate the minimal $n$ for which $G$ is isomorphic to a subgroup of $S_n$? If the answer to $(1)$ is not known, is it known for specific classes of groups? In particular, for finite abelian groups, is it true that for a prime $p$, the minimal $n$ for $\mathbb{Z}_{p^{t_1}} \times \mathbb{Z}_{p^{t_2}}$ is $p^{t_1}+p^{t_2}$ (I can prove that is is true for different primes $p_1$ and $p_2$, but have problems when it's the same prime in both factors). Thanks!","['permutations', 'group-theory']"
191453,How to show that the modulus of $\frac{z-w}{1-\bar{z}w}$ is always $1$?,Let's suppose that $|z|<1$ and $|w|=1$. Show that the modulus of $\displaystyle \frac{z-w}{1-\bar{z}w}$ is always $1$. Some hint.,['complex-analysis']
191461,Locally integrable functions,"Formulation: Let $v\in L^1_\text{loc}(\mathbb{R}^3)$ and $f \in H^1(\mathbb{R}^3)$ such that 
\begin{equation}
  \int f^2 v_+ = \int f^2 v_- = +\infty.
\end{equation}
Here, $v_- = \max(0,-f)$, $v_+ = \max(0,f)$, i.e., the negative and
positive parts of $v=v_+ - v_-$, respectively. Question: Does $g\in H^1(\mathbb{R}^3)$ exist, such that 
\begin{equation}
  \int g^2 v_+ < \infty, \quad \int g^2 v_- = +\infty \quad ?
\end{equation} Some thoughts: Let $S_\pm$ be the supports of $v_\pm$, respectively. One can easily find $g\in L^2$ such that the last equation holds, simply multiply $f$ with the characteristic function of $S_-$. The intuitive approach is then by some smoothing of this function by a mollifier, or using a bump function to force the support of $g$ away from $S_+$. However, the supports of $S_\pm$ can be quite complicated: for example, fat Cantor-like sets. Thus, a bump function technique or a mollifier may ""accidentally"" fill out any of $S_\pm$. My motivation: The problem comes from my original research on the mathematical foundations of Density Functional Theory (DFT) in physics and chemistry. Here, $f^2$ is proportional to the probability density of finding an electron at a space point, and $v$ is the potential energy field of the environmentn. $\int f^2 v$ is the total potential energy for the system's state. The original $f$ gives a meaningless ""$\infty-\infty$"" result, but for certain reasons, we are out of the woods if there is some $other$ density $g$ with the prescribed property. Edit: Removed claim that $S_\pm$ must be unbounded. This does not follow from the stated assumptions.","['functional-analysis', 'analysis']"
191467,Sum of Cauchy sequences is Cauchy in an Abelian Topological Group,"Let $G$ be a topological abelian group and suppose $0$ has a countable
fundamental system of neighborhoods. Let $(x_n),(y_n)$ be Cauchy sequences
of $G$. Why is it true that $(x_n+y_n)$ is a Cauchy sequence? I tried to generalize the case of real sequences: my problem is that if
$U$ is a neighborhood of $0$, then i would need to use something like
$\frac{1}{2} U$, but obviously this does not make sense. I also looked at this relevant question Sum of Cauchy Sequences Cauchy? however it was not very helpful, since it refers to metric topological groups. Thanks.","['general-topology', 'topological-groups', 'abstract-algebra']"
191499,Inequality involving eigenvalues and trace of an operator with its adjoint,"I have come across a problem which I can't properly solve: Let $\tau$ be a linear operator on $\mathbb{C}^n$ and let $\lambda_{1},...,\lambda_{n}$ be the eigenvalues of $\tau$, each one written a number of times equal to its algebraic multiplicity. I should show that: $\sum_{i}|\lambda_{i}|^2\leq tr(\tau^*\tau)$ Also, one should show that the equality holds iff $\tau$ is normal. First I felt that this might use singular values, but I have no success with this. My idea then was that Cauchy-Schwarz may be useful. (I work with matrices, this is clearly not a restriction to the problem.) So I defined the inner-product $\langle A,B\rangle=tr(B^*A)$, which I know to be acceptable. Elementary operations on Cauchy-Schwarz inequality $|\langle A,A^*\rangle|^2$$\leq \langle A,A\rangle\langle A^*,A^*\rangle$ then give that 
$|\sum_{i}\lambda_{i}^2|^2$$\leq (tr(A^*A))^2$
(I may be mistaken). This is not what I want. In the question ''equality holds iff $\tau$ is normal'', one way (right to left) is easy. I highly appreciate any suggestion!","['linear-algebra', 'inequality']"
191504,"Questions about analytic functions, and zeros.","I'm studying Silverman's complex analysis but this book seems a lot slack. I have a question in page273: Suppose $f(z)$ is a nonconstant analytic at $z_0$ with $f(z_0)$=0. Then, by the
  corollary to Theorem 8.13, there exists a neighborhood of $z_0$ that
  contains no other zeros of $f(z)$. Thus we may express $f(z)$ as
  $f(z)=(z-z_0)^k F(z)$ ($k$ a positive integer), where $F(z)$ is
  analytic at $z_0$ with no zeros in the neighborhood or on its boundary
  $C$. I can't understand the last sentence(bold fonts). How can we know there is a factor $(z-z_0)^k$ and even more $F(z)$ is analytic? I also have Ahlfors' book so you can give me references in Silverman or Ahlfors.",['complex-analysis']
191505,Eigenvalues of $A^T A$,"I have a real, positive-definite, symmetric matrix $M$, calculated from a matrix $A$ which is known: $M = A^\top A$ Given the nature of $M$, is there any specialised (read: fast code and/or simple code) way to find the largest eigenvalue of $M$?  It's years since I did linear algebra, so I'm a bit rusty.  I've had a look in Numerical Recipes, Wikipedia and the Matrix cookbook. I found the following in the Matrix cookbook and got excited too early: For a symmetric, positive-definite matrix $A$: $eig\left(A A^\top\right) = eig\left(A^\top A\right) = eig\left(A\right) \cdot eig\left(A\right)$ Of course, it is $M$ that is positive-definite and symmetric, not $A$.  $A$ isn't even square.  M will probably be 1024x1024 or larger.  The size of $M$ (i.e. width of $A$) can be constrained by the algorithm if needed, i.e. I don't mind if your suggestions require that it be a multiple of 4 or a power of 2. [Edit:]
I'm mainly looking for something that I can code natively (taking advantage of SSE/AVX where possible), although your MATLAB/Octave suggestions will definitely be useful to aid my understanding of the algorithms!","['matrices', 'eigenvalues-eigenvectors']"
191508,Calculate the sum of the first N terms of the sequence,"$a_n=a_{n-1}\displaystyle \frac{n+1}{n}$ if $n > 1$ $a_n=1$ if $n=1$ I'm not too sure where to start here. This is part of a review for a class and I can't really seem to remember what we're reviewing. The first 5 values are... $a_1 = 1,a_2=1.5,a_3=2,a_4=2.5,a_5=3$ Sums of these to each point.... $a_1=1, a_2=2.5, a_3=4.5, a_4=7, a_5=10$ It doesn't seem like it should be too tricky to figure out how to get a formula for a sum of the first N terms, since each term seems to just increase by 0.5 every team, I just haven't done this for a while and am a little rusty. Any pointers would be greatly appreciated!",['sequences-and-series']
191516,How to evaluate $ \int_{-\infty}^\infty {e^{ax} \over 1 +e^x } \; dx $ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Possibility to simplify $\sum\limits_{k =  - \infty }^\infty  {\frac{{{{\left( { - 1} \right)}^k}}}{{a + k}} = \frac{\pi }{{\sin \pi a}}} $ Given that $0 < a < 1$ how to evaluate by the method of residues
$$ \int_{-\infty}^\infty {e^{ax} \over 1 +e^x } \; dx $$",['complex-analysis']
191518,Random walking and the expected value,"I was asked this question at an interview, and I didn't know how to solve it. Was curious if anyone could help me. Lets say we have a square, with vertex's 1234. I can randomly walk to each neighbouring vertex with equal probability. My goal is to start at '1', and get back to '1'. How many average walks will I take before I return back to 1?","['probability-theory', 'geometric-probability', 'random-walk', 'expectation']"
191532,Why can't a neighborhood be a finite set?,"Rudin defines a neighborhood as follows: Let $X$ be a metric space endowed with a distance function $d$. A neighborhood of a point $p \in X$ is a set $N_r(p)$ consisting of all $q \in X$ such that $d(p,q) < r$ for some $r > 0$. He later proves two facts: every neighborhood is an open set, and every finite set is closed. But it would seem to me that a neighborhood as defined above could be finite. For example, let $X = \{1,2,3\}$ with $d(x,y) = |x-y|$ be a metric space . Consider the neighborhood around $p = 2$ of radius $0.5$, i.e.: the set of all points $q$ in $X$ such that $d(q,p)<0.5$. But the neighborhood is simply $\{2\}$. Therefore, the neighborhood is a finite set, and therefore closed. But every neighborhood is open. This is a contradiction. So my understanding of a neighborhood is broken somehow. It has further implications: if we define $E = \{2\}$, then the $0.5$-radius neighborhood is $\{2\}$, which is a subset of $E$, which means that $2$ is an interior point of $E$. Since $2$ is the only point in $E$, all points in $E$ are interior points, and $E$ is open. But $E$ is finite, and therefore closed. I'm probably missing something obvious. Can anyone spot my mistake?","['general-topology', 'real-analysis']"
191548,Combinatorial proof of $\sum_{k=0}^{n} \binom{n+k-1}{k} = \binom{2n}{n}$ [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: Combinatorial proof for two identities is there a combinatorial proof of equation below? (parallel summation for binomials):
$$\sum_{k=0}^{n} \binom{n+k-1}{k} = \binom{2n}{n}$$ It seems like it's easy to prove combinatorically, yet I cannot find proper proof...",['combinatorics']
191556,Solution to a Matrix equation,"Is there a general solution to the following matrix equation. $A - BAB^T = C$ where B is known but can be any non-symmetric square matrix, C is known and invertible, all are n by n matrices. Is there a solution to A? or we need to use numerical methods?","['matrices', 'linear-algebra']"
191559,How to Calculate inverse of GCD?,"How to Calculate inverse of GCD ?
for example if we have GCD(a,b) = 7 
how do we determine the values of a,b .
note : a,b have given bound and the given result of the GCD is always a prime. am actually trying to solve this problem and reversing GCD is the first Idea that came to my mind since a,b limit are <$10^7$",['number-theory']
191563,Combinatorial proof of an equation,"I was wondering if there is a combinatorial proof of this equation?
$$\sum_{k=0}^{n}k \binom{n+k-1}{k} =n \binom{2n}{n+1}$$",['combinatorics']
191607,Summation Of Product Of Fibonacci Numbers,"Im trying to find out a general term for the following summation of products of fibonacci numbers:-- $$\sum_{k=4}^{n+1} F_{k}F_{n+5-k}\; , n \geq 3$$ I tried using Binet's equation but I am getting stuck at a certain point. So, I would be very glad if someone could post an answer to my question with a detailed explanation. Here are the first few values of the summation for different values of n :-- n = 3 , ans = 9 n = 4 , ans = 30 n = 5 , ans = 73 n = 6 , ans = 158 Note : I have used the usual fibonacci notation. i.e $$
F_0=0,\;F_1=1,\;F_2=1,\;F_3=2,\;...etc
$$ EDIT After reading the comments for this question I tried solving it to form a recurrence relation and this is what i ended up with :-- $$  
\begin{align*}
G(n)&=\sum_{k=4}^{n+1} F_kF_{n+5-k}\; , n \geq 3\\
G(n)-G(n-1)&=\sum_{k=4}^{n+1} F_kF_{n+5-k}-\sum_{k=4}^{n} F_kF_{n+4-k}\\
&=F_{n+1}F_{4}+\sum_{k=4}^{n}F_kF_{n+3-k}\\
&=F_{n+1}F_{4}+F_{n}F_{3}+\sum_{k=4}^{n-1}F_kF_{n+3-k}\\
\\
&=F_{n+1}F_{4}+F_{n}F_{3}+G(n-2)\\
\\
G(n)&=G(n-1)+G(n-2)+F_{n+1}F_{4}+F_{n}F_{3}\\
\\
\end{align*}
$$ Is this correct ? And how do I reduce it further ?","['fibonacci-numbers', 'recurrence-relations', 'sequences-and-series']"
191611,Is this differential equation separable??,"Just a quick question... I have the equation: $$\frac{dw}{dy} w^{-2}=0$$ Is this separable? i.e. can I go : $$\begin{align}
\frac{dw}{dy} w^{-2}&=0 \\[8pt]
(w^{-2}) \,dw&=(0)\,dy \tag{*} \\[8pt]
-w^{-1}&=A
\end{align}$$
and thus
$$w = B$$ with $A,B$ being arbitrary constants with $B \not= 0$ Is this ok? The only thing I'm wondering about is the starred line... can I separate the equation like that with only a zero on the RHS?",['ordinary-differential-equations']
191630,Expressing $\operatorname{Pic}^0(X)$ as a cokernel,"Let $X$ be a Kähler manifold. This answer on MO quotes the exact sequence
$$0 \to H^1(X, \mathbb{Z}) \to H^{0,1}(X) \to \operatorname{Pic}^0(X) \to 0$$
where $H^{0,1}(X) = H^1(X, \mathscr{O}_X)$ (I think). Question: Is there an analogous exact sequence when $X$ is a smooth projective variety over an arbitrary field?  If so, where can I find a derivation of this result?","['algebraic-geometry', 'reference-request', 'kahler-manifolds']"
191632,Abstract manifolds or do we need an ambient space?,"I'm currently studying on J.Lee's ""Introduction to smooth manifolds"", but several other sources I consulted present the same line of thought. The most natural description of the $n$-dimensional sphere $S^n$ follows from imagining the sphere sitting in $\mathbb{R}^{n+1}$, as the locus of points $x=(x^1,\dots,x^{n+1})$ such that $(x^1)^2+\dots+(x^{n+1})^2=1$. It is then possible to introduce (for example) the stereographic projection of the points of the sphere and to construct the homeomorphism $\sigma: S^n \setminus \{N\} \mapsto \mathbb{R}^n$. Writing the analogous map $\tilde{\sigma}: S^n \setminus \{S\} \mapsto \mathbb{R}^n$, I get an atlas for $S^n$ and I can prove that it is indeed a smooth manifold. What puzzles me is that the coordinates of the ambient space have been used to describe the homeomorphisms, while it is always said that manifolds exist in their own right, without the need of embedding them in a bigger space (and I'm aware - thanks to this past discussion - of the difficulties and limitations of the ""embed everything""-approach). 
But then I don't know how to describe smooth charts, i.e. how to specify the point of the manifold that gets a certain coordinate representation under the homeomorphism. Moreover, when studying the differential geometry of curves and surfaces in $\mathbb{R}^3$, I used to parametrize the object with functions from $\mathbb{R}$ or $\mathbb{R}^2$. This looks as defining the homeomorphisms of my local charts in the opposite direction, but always imagining the curve/surface living in $\mathbb{R}^3$. So, the questions are: Speaking about $S^n$, is there an ""intrinsic"" way to associate its points with those of $\mathbb{R}^n$ to build the local charts? How to proceed with a generic manifold? [Wild guess: As long as I consider surfaces and their higher dimensional generalizations, it is useful and perhaps unavoidable working with their parametrization; what I'm looking for comes out when I study stranger spaces.] Thanks in advance! Update : Just this little edit to clarify that I'm most interested in answers to my second question about ""the philosophy"" of building coordinate charts, which has not been addressed yet. About my wild guess: as I learn from Hagen's answer, the term ""unavoidable"" is wrong.",['differential-geometry']
191638,Lebesgue Integration fundamental questions,"My question involves the definition of the Lebesgue integral. Most colloquial definitions I've read follow (2), in that f*(t) is the ""length"" of one of the horizontal rectangles and dt is the height. But, I've also seen definitions follow (1), which appear fundamentally different. Why are they presented differently? Also, are the two forms somehow equivalent to each other? Is there a good way to visualize why they are equivalent? Why are they presented differently? My next question is the notation in (3). This notation is said to be the Lebesgue integral in its ""standard"" form. My interpretation of this integral is that it is integrated over E, which is the domain of the function f. This seems more akin to Riemann integration where the domain is partitioned rather than the range (in this case if the measure space is (E,X,μ) and f : E->R, where R is the reals). Shouldn't it be summed over R instead? also how should dμ be interpreted? If you look at (4) it makes sense. The integral is integrated over the domain of f, E. Then, the function is evaluated at x ϵ E. μ(dx) also makes sense, as dx is some segment of E, which is an element of the sigma space X. The μ(dx) is then the measure of this element of the sigma space. But, as I mentioned before, this seems to just be Riemann integration. In summation, which (1) or (2) better describes Lebesgue integration and why are these different approaches use to describe Lebesgue integration; how should the notation in (3) be interpreted. Thanks.","['lebesgue-integral', 'calculus', 'integration']"
191639,"Evaluating $\int_0^\infty\frac{\sin(x)}{x^2+1}\, dx$","I have seen $$\int_0^\infty \frac{\cos(x)}{x^2+1} \, dx=\frac{\pi}{2e}$$ evaluated in various ways. It's rather popular when studying CA. But, what about $$\int_0^\infty \frac{\sin(x)}{x^2+1} \, dx\,\,?$$ This appears to be trickier and more challenging. I found that it has a closed form of 
$$\cosh(1)\operatorname{Shi}(1)-\sinh(1)\text{Chi(1)}\,\,,\,\operatorname{Shi}(1)=\int_0^1 \frac{\sinh(x)}{x}dx\,\,,\,\, \text{Chi(1)}=\gamma+\int_0^1 \frac{\cosh(x)-1}{x} \, dx$$ which are the hyperbolic sine and cosine integrals, respectively. It's an odd function, so 
$$\int_{-\infty}^\infty \frac{\sin(x)}{x^2+1} \, dx=0$$ But, does anyone know how the former case can be done? Thanks a bunch.","['improper-integrals', 'calculus', 'integration']"
191640,Atoms in a tail $\sigma$-algebra as $\liminf C_n$,"Trying to solve exercise 1.1.18 in D.W. Stroock, Probability Theory, I somehow don't see how to get the hint in that exercise. Given a set $\Omega$, a tail $\sigma$-algebra $\tau$ generated by $\sigma$-algebras $\cal F_n$, where each $\cal F_n$ is again generated by a set $A_n$, that is ${\cal F}_n = \{\emptyset, \Omega, A_n, \Omega \setminus A_n\}$. The sets $A_n$ are independent. An atom $C\in \tau$ is a non-empty set which has no non-empty subset in $\tau$: If $\emptyset \neq B \subset C$ and $B\in \tau$, then $B=C$. Now, if $C$ is an atom in $\tau$ then it can be written as a $\liminf$, more precisely: $C$ is an atom only if one can write 
$$
C = \liminf_n C_n = \bigcup_n \bigcap_{k\geq n} C_k \quad \mbox{ where } C_n \in \{A_n, \Omega\setminus A_n\}
$$ Is that implication simple? I simply don't see it. Thanks for any help.","['probability-theory', 'measure-theory']"
191643,Maps from sets of measure zero to sets of measure zero [duplicate],"This question already has answers here : Closed 11 years ago . Possible Duplicate: If $E$ has measure zero, then does $E^2$ have measure zero? I'm trying to find a proof for the following question: Suppose $A\subset\mathbb{R}$ is a set of measure zero.  Show that the set $A^2=\{x^2 \in \mathbb{R} \,|\, x \in A\}$ is also a set of measure zero. I feel like this is a very easy proof and I am just missing something.  I don't think stating ""the map $f:A\to A^2$ also maps the collection of intervals covering $A$ to a collection of intervals covering $A^2$"" is complete.  I don't believe this qualifies as a Lipschitz function, since the derivative of the function $f$ is unbounded on $\mathbb{R}$.  Please help, is there something I am missing here?","['measure-theory', 'real-analysis']"
191646,$\mathbb{R}^\mathbb{R}$ is not normal,"Does anyone know how to prove that $\mathbb{R}^\mathbb{R}$ (with the product topology) does not fulfill the $T_4$ axiom? It would be sufficient to have an uncountable subset $A \subseteq \mathbb{R}^\mathbb{R}$ which is closed and discrete as subspace (because this is impossible for any separable $T_4$-space), but I do not know if such a subspace exists.",['general-topology']
191661,Homeomorphism that maps a closed set to an open set?,"In my Real Analysis class I got a bit frisky and broke out a homeomorphism in a problem to show that a set was closed (that is, I had a closed set, and I made a homeomorphism between it and the set in question to show that the set in question was closed). My reason for doing this was simple:
A homeomorphism maps closed sets to closed sets. My instructor made a note saying that this is not true in general. He says homeomorphisms do not in general map closed sets to closed sets. Everything I have ever read about homeomorphisms contradicts this. But maybe I'm wrong, so if someone on here could provide a counterexample (that is, a homeomorphism mapping a closed set to an open set), I would certainly appreciate it.",['general-topology']
191667,Dimension of a tensor product of affine rings,"The dimension of a ring is defined as the length of a longest prime chain as usual. Let $A,B$ be affine rings over a field $k$.
Then $$\dim A\otimes_k B = \dim A + \dim B.$$
How can we prove or disprove this?","['commutative-algebra', 'algebraic-geometry']"
191688,What are my chances of winning this card game,"I shuffle a standard deck and guess that I will pick an ace at my first draw. If it is indeed an ace, I win the game immediately and stop. If it is not an ace, I will claim that the next card drawn from the deck (now only 51 cards remaining) is a 2. If it is a 2, I win the game and stop. If not, I will go on: I will go though all ranks this way and if I guess the 13th card drawn incorrectly (i.e., it was not a King), then I lose the game. I simulated this game and I got a winning probability of around .65, but now I want to solve for it mathematically. I think the exact way is too complicated (the probability that I get the fifth card right will depend on how many of it have already been drawn beforehand). So, I am satisfied with an approximate way to solve for it.","['probability', 'combinatorics']"
191689,Is $f^{(0)}:=f$ a valid assumption for a proof involving derivatives on induction?,"My motivation for this was proving the general Cauchy-Integral formula (in complex analysis) for an arbitrary derivative.  Every book I read shows at least the first derivative using a $\delta-\epsilon$ argument, but we already did this technique/style when showing the proof for $f(z_0)=\int_\Gamma \frac{f(z)}{(z-z_0)}dz$. So my question is a general one (i.e. I mention the C-Int formula only as my motivation), and I'm curious if (in the general case), we may (when convenient) consider the ""zeroth derivative"" (the function) as a base case for induction on a derivative.... obviously, the general formula for any such problem wasn't probably ""seen"" by looking at only that base case (I'm certain that the historical derivation for the general formula required the first three derivatives since the third derivative is the first time $n!≠n:n≠0$.  None the less, I'm wondering if ""zero derivative"" is a valid assumption for such a proof or just a ""definition"".",['analysis']
191690,When is the product of $n$ subgroups a subgroup?,"Let $G$ be any group. It's a well-known result that if $H, K$ are subgroups of $G$, then $HK$ is a subgroup itself if and only if $HK = KH$. Now, I've always wondered about a generalization of this result, something along the lines of: Theorem : If $H_1, \ldots, H_n$ are subgroups of $G$, then $H_1H_2\dots{H_n}$ is a subgroup if and only if ($\star$) holds, where $(\star)$ is some condition on $H_1, \ldots, H_n$, preferably related to how the smaller products $H_{m_1}\ldots{}H_{m_k}$, for $k < n$, behave. Question 1 : Is there such a theorem? I do know, and its easy to prove, that if $H_iH_j = H_jH_i$ for every $i, j$, then the big product is a group, but this is not satisfying since it's far from necessary (just take one of the groups to be $G$, and you need no commutativity at all). Also, I've been told that there is no really satisfactory answer; if that is indeed the case, then my question would be why ? In particular: Question 2 : Are there really problematic counterexamples where you can see that the behavior of the smaller products has nothing to do with the big product, so that no such a theorem can ever exist? I would appreciate even an answer for the particular case $n = 3$. Thanks.","['group-theory', 'abstract-algebra']"
