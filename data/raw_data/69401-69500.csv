question_id,title,body,tags
841028,What good is the Commutator product?,"In geometric algebra, the commutator product is defined as $A \times B = \frac 1 2 (AB - BA)$. From linear algebra, I remember that the commutator of matrices is $[A, B] = AB - BA$ and the commutator of linear functions is likewise $[f,g]=fg-gf$.  Looking at my notes I see that skew transformations are closed under this operation.  But why is that important? Why do we need this product/ operation?  Can I use it to prove some cool theorems or is it useful in performing some algorithms?  What is the point of the commutator?","['geometric-algebras', 'linear-algebra']"
841080,Does the series $\sum_{n=1}^\infty\frac{\sin n}{\ln n+\cos n}$ converge?,"$$\sum_{n=1}^\infty\frac{\sin n}{\ln n+\cos n}$$
My guess is ""yes"", but I can't prove it.","['sequences-and-series', 'real-analysis']"
841093,Can you derive a formula for the semiprime counting function from the prime number theorem?,"E.g., there are $4$ semiprimes less than or equal to $10$ $(4, 6, 9, 10)$ or $2$ squarefree semiprimes ($6$ and $10$). It's ok if it's off for small numbers but gets more accurate as $n \to \infty$.","['semiprimes', 'number-theory']"
841096,uniform convergence of a functional sequence,"Is this sequence of functions 
$$f_n(x)=n^3x(1-x)^n$$ 
converges uniformly for $x\in[0,1]$. I need some help on this.","['sequences-and-series', 'real-analysis', 'analysis']"
841114,Probability Puzzle: Mutating Loaded Die,"Take an (initially) fair six-sided die (i.e. $P(x)=\frac{1}{6}$ for $x=1,…,6$) and roll it repeatedly. After each roll, the die becomes loaded for the next roll depending on the number $y$ that was just rolled according to the following system: $$P(y)=\frac{1}{y}$$
$$P(x)=\frac{1 - P(y)}{5} \text{, for } x \ne y$$ i.e. the probability that you roll that number again in the next roll is $\frac{1}{y}$ and the remaining numbers are of equal probability. What is the probability that you roll a $6$ on your $n$th roll? NB: This is not a homework or contest question, just an idea I had on a boring bus ride. Bonus points for calculating the probability of rolling the number $x$ on the $n$th roll.","['dice', 'puzzle', 'probability']"
841126,"Convergence in $L^p$ plus bounded gradient implies that the limit belongs to $W^{1,p}$?","I have a question with this problem I have found in the latest edition of the book Functional analysis, Sobolev Spaces author Haim Brezis pag 264 Remark 4 Let $(u_n) \subset W^{1,p} $ such that $u_n \longrightarrow u$ in $L^p$ and $(\nabla u_n)$ is bounded in $(L^p)^N$ to conclude that $u \in W^{1,p} $. I appreciate any help beforehand.","['sobolev-spaces', 'functional-analysis', 'lp-spaces']"
841141,Is there a closed form expression for the sum of all the proper divisors of an integer?,"I have already found a summation formula here: https://math.stackexchange.com/a/22723 , and also a very interesting recursive formula here: https://math.stackexchange.com/a/22744 . Any ideas on how to reduce either of these to a closed form expression would be greatly appreciated. Edit: Essentially, I want a finite expression using elementary functions that gives the sum of the proper divisors of an integer n in terms of n (and not the prime decomposition).","['closed-form', 'divisor-sum', 'summation', 'number-theory']"
841163,Expected value of the function of a random variable,"I am studying Probability and Monte Carlo methods, and it feels that the more I study the less I truly understand the theory. I guess I just confuse myself now. So the expected value of a random variable X is: $E[X] = \int x_i p(x_i)\:dx$ where X is is random variable and p(x) is the pdf of X. This sort of makes sense to me especially of you think in terms of discrete random variable. If an outcome is more likely to be drawn than others, then the pdf for this outcome $x_i$ accounts for this.I have a problem when this apply to a function. So we have: $E[f(x)] = \int f(x_i) p(x_i) \: dx$ My understanding here is that f can be any sort of function we like. $x_i$ is a possible value from the random variable X and $p(x_i)$ is the probability distribution. Because $x_i$ is random $f(x_i)$ is random. So f(x) is a function of the random variable X. Now what I don't understand with this: doesn't the result of the expected value E[f(x)] depends on the choice of the pdf? For example of you have a simple function such as f(x) = x (imagine the integration domain is [0,1]), if you choose a uniform pdf or a gaussian distribution, wouldn't the result of E[f(x)] be different? I am sure I am just mixing in my mind ""simple"" concepts. I am probably not thinking this problem the right way. If anybody could straighten that up for me, it would be great. EDIT Thank you for your answers. So it seems my question wasn't clear enough and complete. From the answer you gave me, I understand that: X is distributed according to a give distribution (in other words, X and its PDF are interdependent). therefore indeed changing X, implies that the distribution has changed as well and yes, E[f(X)] is likely to be different for different Xs. I think my confusion comes partly from the fact this PDF plays a role in the computation of the Monte Carlo integral and particular the general form in which the integrand is divided by the PDF: $E[f(X)] \approx { 1 \over N } \sum_{i=0}^{N-1} { f(x_i) \over p(x_i) }.$ where $x_i$ is a sequence of random numbers drawn from a random variable X with distribution p(X). We are trying to approximate: $F = \int f(x)\:dx.$ We know the result of this MC integral converges in probability to the expected value E[f(X)]. So according to the three points I listed above, wouldn't changing X and its PDF give a different result for E[f(x)] when MC integration is used? When you measure the area ""under"" (a way of interpreting what an integral is) the curve, that area is constant. So if we get a different E[f(x)] for something that should always be the same, what I am missing? In other words, in a lot of books $E[f(X)] = \int f(X) p(X) \: dx$ is presented as ""the formula"" to calculate the expected value of f. This seems like misleading to me. Should it be more accurate to say ""the expected value of f given the particular random variable X with PDF p(X)""? , knowing that if we change X we will get a different E[f(X)].","['probability-theory', 'integration', 'random-variables']"
842176,How to integrate: $\int_{0}^{\infty}e^{tx}(x^2e^{-x})/2dx$,"I'm working on a few moment generating function problems and I came across: $f(x)=(x^2e^{-x})/2$ for $x>0$, and zero otherwise. Find the mean. The mean is the same as the expected value. If we find the moment generating function, $M_x(t)$, of $f(x)$ then we can take the first derivative of $M_x(t)$ at $t=0$. This will give us the mean. To find the $M_x(t)$ we take $$\int_{-\infty}^{\infty}e^{tx}f(x)dx$$ $$\int_{0}^{\infty}e^{tx}(x^2e^{-x})/2dx$$ I wrote this as: $$\frac12\int_{0}^{\infty}x^{2}e^{x(t-1)}dx$$ I'm a bit rusty on integration and if someone could help point me in the right direction as to how to tackle this guy I would greatly appreciate it!","['moment-generating-functions', 'calculus', 'probability', 'integration']"
842200,Why all composite numbers have this property?,"Define $f(n)=\sum\limits_{A \in S} f_{1}(n,A),\ n>2,\ n \in  \mathbb{Z}$, where $S$ is the power set of $\{\frac{1}{2},\cdots ,\frac{1}{n-1}\}$. Define $\ f_1(n,\varnothing)=1,\ f_{1}(n,A)=(-1)^{\#A-2n\Sigma(A)}$, where $\#A$ is the size of the set $A$ and $\Sigma(A)$ is the sum of the elements of A. Let's take $n = 5$, for example:
$$
\begin{align*} 
S = \{\\
& \varnothing,\\
&  \{\frac{1}{2}\},\  \{\frac{1}{3}\},\  \{\frac{1}{4}\},\\ 
&  \{\frac{1}{2},\frac{1}{3}\},\   \{\frac{1}{2},\frac{1}{4}\},\  \{\frac{1}{3},\frac{1}{4}\},\\
&  \{\frac{1}{2},\frac{1}{3},\frac{1}{4}\}\\
\}
\end{align*}
$$
$f(5)=1+(-1)^{1-2 \cdot 5 \cdot (\frac{1}{2})}+ \cdots +(-1)^{2-2 \cdot 5 \cdot (\frac{1}{2}+\frac{1}{3})} + \cdots + (-1)^{3-2 \cdot 5 \cdot (\frac{1}{2}+\frac{1}{3}+\frac{1}{4})}=4.7320508075688767+1.2679491924311326i$ My question is: Why for every composite number $n$ is the real part of $f(n)$ approximately $0$, while prime numbers do not have this property?  Examples:
$$
\begin{align*} 
f(4) & = 1.887379141862766e-15-1.1102230246251565e-15i\\
f(22) & = -8.325340417059124e-12-7.568612403474617e-1i
\end{align*}
$$ Source: http://mymathforum.com/number-theory/43341-prime-prime.html P.S. Python code for $f(n),f_{1}(n,A)$: import itertools

def f_1(n,A):
    return (-1) ** (len(A) - 2 * n * (sum(A)))
def f(n):
    l = [itertools.combinations([1/x for x in range(2,n)], x) for x in range(1,n-1)]
    return round(sum([f_1(n,y) for x in l for y in x]).real) + 1

print(f(4))

# Output: 0","['number-theory', 'elementary-number-theory', 'prime-numbers', 'complex-numbers', 'complex-analysis']"
842216,Saddle Points on Matrices,"Let $n$, $m$ be positive integers. Suppose that $A$ is a $2$ x $n$ or an $m$ x $2$ matrix and that it has a saddle point. Show that among the saddle points of $A$ there exists at least one which can be reached by using dominance relations. My knowledge: A saddle point in a matrix is an entry which is the minimum in its row and maximum in its column. I also know that for dominance relations the $i^{th}$ row dominates the $j^{th}$ row if all the entries in the $i^{th}$ row are $\geq$ the corresponding entries in the $j^{th}$ row. The the $i^{th}$ column dominates the $j^{th}$ column if all the entries in the $i^{th}$ column are $\leq$ the corresponding entries in the $j^{th}$ column. I was teaching myself about dominance relations and saddle points after a friend of mine started discussing it with me and how it relates to games.  I learned how to do saddle points and would like to see a proof of this question to expand my knowledge.","['matrices', 'game-theory', 'proof-writing', 'combinatorial-game-theory']"
842294,How to find out the period of fractional part of x,"I came across this solved example in a book, it says -
 Find the period of the function : $f(x)=\sin(4\pi x)+\{3x\}$, where $\{x\}$ denotes the fractional part of $x$. Now I know that if $f(x)$ is periodic with period $T$, then $f(ax+b)$ is periodic with period $\dfrac{T}{|a|}$. So, period of $\sin(4\pi x)$ is $\dfrac{2 \pi}{4 \pi} = \dfrac{1}{2}$. The book says the period of $\{3x\} = 1/3$. Please explain it to me how to find out the period of a fractional part ?","['fractional-part', 'functions', 'periodic-functions']"
842300,Rigorous Book on Stochastic Calculus,"I have already taken a couse in Stochastic Calculus.
Due to time constraints on many ocassions we had to skip some formalities among the proofs.
I'm trying now to fill the gaps left, and I have been searching for a book to do so. My problem is that I haven't found many good references. I'm intersted in a book (or books) with rigorous treatment of: Brownian Motion (Wiener Process, Wiener Measure and construction) Martingale Theory (Discrete and Continuous, but specially the transition from Discrete to Continuous Time) Stochastic Calculus (Ito Integration) SDE I have already explored some books such as Karatsas but have found them very dry and almost encyclopedia like, which is something I don't like from books. Any references (online notes or books) are appreciated. I'm kind of trying to overcome the thought that this subject (Stochastic Calculus) is filled with dry formalities. I'm trying to find a treatment which balances intuition and formality but without feeling dry and devoid of motivation. By the way I have a good base on measure theory so no problem with it as a prequisite. Thanks in advance","['martingales', 'stochastic-analysis', 'probability-theory', 'stochastic-calculus', 'probability']"
842305,Question about line of curvature,"If $\alpha$ is a planar geodesic on surface $M$, show that $\alpha$ is a line of curvature. My try: $\alpha$ planar imply torsion=0, and binomial vector is constant. Since $0=\kappa_g=\kappa_\alpha B\cdot U$, ($U$ is normal vector of $M$), so B perpendicular to $U$.  Here's where I stuck. Please help",['differential-geometry']
842306,Prove $n(A-B)=n(A)-n(A \cap B)$,Prove that: $n(A-B)=n(A)-n(A \cap B)$ This is an example from my book in which first step is like this:$$n(A)=n(A-B)+n(A \cap B) $$ But  how did they get it.,"['self-learning', 'elementary-set-theory']"
842311,Derivative function went wrong,"I am trying to take the derivative of this function but I am facing some difficulties. $$f(x)= e^{\ln(e^{7x^2+11})}$$ My answer was : $7e^{(7(x^2))}*14x$
 I cancelled the $\ln$ with the $e$ first, then I downgrade the $7$ and keep the $\exp$. as it is, after that I took the derivative of the $7x^2$ and the result was the one on top.","['calculus', 'derivatives']"
842365,A field is finite if and only if its multiplicative group is finitely generated.,"Show that a field $\mathbb{F}$ is finite if and only if its multiplicative group $\mathbb{F}^{\times}$ is finitely generated. The "" $\Rightarrow$ "" implication is obvious, but how to prove the otherwise?","['finite-fields', 'finitely-generated', 'abstract-algebra', 'field-theory']"
842395,Evaluate $\int \frac {x^2}{\sqrt{\arctan x}} dx$,Is there any closed form expression of $$\int \dfrac {x^2}{\sqrt{\arctan x}} dx?$$,['integration']
842401,"Showing that for $s,t\in\mathbb{Q}$, we have $(s+t)^*= s^* + t^*$.","I'm working through the problems of Elementary Analysis Theory of Calculus, and for some reason, this question didn't make the solutions in the back of the book. I did a thorough search on Stack Exchange and could not find a similar problem.  I was wondering if anyone could help me verify my proof.  Some background: $$s,t \in \Bbb Q, \quad s^∗ = \{r \in \Bbb Q : r < s\}$$ is a Dedekind cut where $s$ is in $\Bbb Q$.  So, it is a rational Dedekind cut. $t^*$ is defined similarly. $$(s+t)^* = \{r ∈ \Bbb Q : r < s + t\}$$ $$s^* + t^* = \{r1 + r2 : r_1 \in s^* \text{ and} r_2 ∈ t^*\}$$ So, to show that $s^* + t^*$ is a subset of $(s+t)^*$ is quite easy.  To show $(s+t)^* \subseteq s^* + t^*$ was quite difficult for me.  But, I think I have it now.  Here goes. Suppose $x ∈ (s+t)^*$.  Then, $x ∈ \Bbb Q$ and $x < s + t$.  By the density of $\Bbb Q$, there is an $m$ in $\Bbb Q$ such that $x < m < s + t$.  Let $\varepsilon = m - x$.  So, $x < x + \varepsilon < s + t$.  So, $x + \varepsilon - s < t$. Define $x$ as follows: $$x = (s-ϵ) + (t - (t - x + (s-\varepsilon))). $$ Clearly, $s-\varepsilon < s$.  Since $s-\varepsilon ∈ \Bbb Q, s-\varepsilon ∈ s^*$ .  Likewise, $$(t - (t - x + (s-\varepsilon))) = x - s + \varepsilon < t.$$  Since $(t - (t - x + (s-\varepsilon))) ∈ \Bbb Q$ and $(t - (t - x + (s-\varepsilon))) < t, (t - (t - x + (s-\varepsilon))) ∈ t^*$. Hence, $x = r_1 + r_2$ such that $r_1 ∈ s^*$ and $r_2 ∈ t^*$.  Thus, $x ∈ s^* + t^*$ and $(s+t)^* \subseteq s^* + t^*$ Is this proof valid?","['proof-verification', 'elementary-set-theory', 'real-analysis']"
842402,How do you integrate the reciprocal of square root of cosine?,I encountered this integral in physics and got stuck. $$\int_{0}^{\Large\frac{\pi}{2}} \dfrac{d\theta}{\sqrt{\cos \theta}}.$$,"['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
842403,What are the $n$th roots of the identity function?,"What are all the functions $f:\mathbb{R}\rightarrow \mathbb{R}$ such that $f^n=I$ where $f^n$ denotes the composition $f\circ f\circ f\dots \circ f$ of $f$ with itself $n$ times, and $I:\mathbb{R}\rightarrow \mathbb{R}$ is the identity function? Is there a neat description of such functions? (There seems to be infinitely many of them, for each $n>1$.) It is easy to see that such a $f$ has to be bijective. Is there a better answer if $f$ is assumed to be continuous?","['general-topology', 'real-analysis', 'analysis']"
842409,Set theory to define natural number [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question I am now studying set theory, but I am so curious about it. 1.Why we need to define number rather than treat it as something naturally exist? 2.Do we need to define point or line in Euclidean geometry by set theory? If so, how to define it?",['elementary-set-theory']
842444,"Let $A,B,C$ be sets, and $B \cap C=\emptyset$. Show $|A^{B \cup C}|=|A^B \times A^C|$","Let $A,B,C$ be sets, and $B \cap C=\emptyset$. Show $|A^{B \cup C}|=|A^B \times A^C|$ by defining a bijection $f:A^{B \cup C} \rightarrow A^B \times A^C$. Any hints on this one? Thank you!",['elementary-set-theory']
842451,Are all Sylow 2-subgroups in $S_4$ isomorphic to $D_4$?,"I was assigned to show that every Sylow 2-subgroups in $S_4$ is isomorphic to $D_4$. So I figured, since $|S_4|=24=2^3\cdot 3$, every Sylow 2-subgroup has either the form: $\langle (a_{1}a_{2}),(a_{3}a_{4}a_{5}a_{6})\rangle$ or: $\langle(a_{1}a_{2})(a_{3}a_{4}),(a_{5}a_{6}a_{7}a_{8})\rangle$ (where $a_{i}\in\left\{ 1234 \right\}$ all distinct in a permutation). To my big surprise, I found out that it is not true that for every choice of $\sigma=(a_1a_2)$ and $\tau=(a_3a_4a_5a_6)$, the group $\langle\sigma, \tau\rangle$ forms a Sylow 2-subgroup... For example, $\langle(12),(1234)\rangle=\langle(23),(1234)\rangle=S_4$, where, on the other hand, $\langle(13),(1234)\rangle$ does form a subgroup of $S_4$, isomorphic to $D_4$ (it is of order 8 and all relations hold). First of all, I am curious about why does it matter which $\sigma$ do I choose (does it also matter which $\tau$ do I choose?), does it have anything to do with the reflection symmetry? because when looking at a square with vertices numbered 1,2,3,4: there's a big difference between $(12)$ and $(13)$, and between $(12)(34)$ and $(13)(24)$ Does it have anything to do with that? This leads me to my second, less important question: considering all the above, how can I wisely choose $\sigma$ and $\tau$? or do I have to try all possible $\sigma$'s and $\tau$'s?","['sylow-theory', 'permutations', 'group-theory', 'abstract-algebra']"
842468,Random $0-1$ matrices,"I'm working my way through the Oxford notes in Probabilistic Combinatorics and came across this question in one of the question sheets; I'd like to stress that this is not my homework: I'm simply working through the notes for my own pleasure. For $n, r ∈ \mathbb{N}$, $1 < r < n$, let $z(r, n)$ be the largest possible number of $0$ entries in an $n × n$ matrix which has no $r × r$ submatrix whose entries are all $0$. (Here a submatrix is obtained by selecting any $r$ rows and any $r$ columns; the rows/columns need not be consecutive.) Consider a random matrix in which each entry is $0$ with probability $p$ and $1$ with
probability $1−p$, independently. Deduce that $z(r, n) > pn^{2}-p^{r^{2}}n^{2r}.$ My solution: Let $[n]_{2}$ denote the set of all $n \times n$ matrices, with only $0-1$ entries. For each $\sigma \in [n]_{2}$ let the random variable $X(\sigma)$ denote the number of $0$ entries in $\sigma$ and the random variable $Y(\sigma)$ denote the number of $r \times r$ submatrices filled with entirely with $0$'s. It follows that $\mathbb{E}(X)=pn^{{2}}$ and $\mathbb{E}(Y)=\binom{n}{r}^{2}p^{r^{2}}<n^{2r}p^{r^{2}}$. Further more consider the random variable $X-Y$ for which $\mathbb{E}(X-Y)>pn^{2}-n^{2r}p^{r^{2}}$. It follows that there exists a $\sigma \in [n]_{2}$ such that $X(\sigma)-Y(\sigma)>pn^{2}-n^{2r}p^{r^{2}}$. Given such a $\sigma$ construct $\sigma' \in [n]_{2}$ as follows. For each of the all $0$, $r \times r$ sub matrices of $\sigma$ remove at random a single $0$ from each to ensure $\sigma'$ has no $r \times r$ such sub-matrices. We have removed at most $\binom{n}{r}^{2}<n^{2r}$ such zero's and so we can conclude that $\sigma'$ has at least $pn^{2}-p^{r^{2}}n^{2r}$ zeros thus we can conclude that $z(n,r)>pn^{2}-p^{r^{2}}n^{2r}$. I'd appreciate any comments on the validity of the proof.","['probability-theory', 'probability', 'combinatorics']"
842480,How can the circular function $\tan(\theta)$ be both a length and a ratio of lengths?,"The circular function $\tan(\theta)$ is defined as $\tan (\theta)=\frac{\sin (\theta)}{\cos (\theta)}$ . If we look at this in the context of the Unit Circle: From this picture it can be seen that $\tan(\theta)$ is the $y$ -coordinate of the $Q(1,y_1)$ , the point on the terminal side of $\theta$ that lies on the vertical line $x=1$ . So like $\sin(\theta)$ and $\cos(\theta)$ it signifies a length on the Unit Circle. My question is: How can $\tan(\theta)$ be a length if it is a ratio of two lengths? The ratio of two lengths is dimensionless, so how does $\tan(\theta)$ signify a length? EDIT: I guess this goes for $\sin(\theta)$ and $\cos(\theta)$ as well; as they are ratios of two lengths. EDIT 2: mislabeled sine and cosine on the unit circle","['trigonometry', 'algebra-precalculus']"
842481,Roots of $x \cos{x}-1$ and $\cos{x}-x^{-1}$,"To finding the roots of  $x \cos{x}-1=0$ we can write the equation as
$$
f(x)=x \cos{x}-1=0 \to x \cos{x}=1 \to \cos{x}=\frac{1}{x} \to \cos{x}-\frac{1}{x}=u(x)-v(x)=g(x)=0
$$
The roots of $f(x)$ are exactly the same roots of $g(x)$. But $f(x)\ne g(x)$. How can it be correct? Edit: My question is: Can we always simplify the equation (changing $f(x)=0$ to $u(x)-v(x)=0$) to finding the roots? Edit 2: The main problem is that it is much easier to finding the roots graphically by writing $f(x)$ as difference between two functions $u(x)-v(x)$. Then the roots of $f(x)$ are the intersections of the two functions $u(x)$ and $v(x)$. Edit 3: The problem is NOT where the two functions $f(x)$ and $g(x)=u(x)-v(x)$ obtained from $f(x)$ by adding or multiplying in the right and left of $f(x)=0$ are defined. The problem is are the roots of $f(x)$ equal to the roots of $g(x)$ or intersections of the two functions $u(x)$ and $v(x)$? Are there counterexamples in which the the roots of $g(x)=u(x)-v(x)$ are not equal to original function $f(x)$? Edit 4: Can we eliminate $x/x$ from $(x \cos{x})/x=1/x$ to obtain $\cos{x}- (1/x)=0$ ? I think I shouldn't do that. But in my textbook the author does that.","['calculus', 'roots', 'functions']"
842491,Questions about solutions of $x'=f(x^2)$,"Let $f:\mathbb{R} \rightarrow \mathbb{R}$, class $C^1$ and consider $x'=f(x^2)$ Can all solutions be strictly decreasing? Is every solution either constant or strictly monotonic? I don't know how to answer those questions. How to use the fact that $f$ is $C^1$? Could you help?",['ordinary-differential-equations']
842500,Showing that $ϕ(x)=x^n$ is a homomorphism from $G\to Z(G)$,"Let $G$ be a group with $|G:Z(G)|=n$ then $\phi(x)=x^n$ is a homomorphism from $G$ to $Z(G)$. I guess it has a proof using transfer theory, I wonder whether it has an elemantary proof or not. Thanks.","['transfer-theory', 'finite-groups', 'group-theory', 'abstract-algebra']"
842546,Evaluate the limit $\lim_{x\rightarrow 0}\left[ \frac{\ln(\cos x)}{x\sqrt{1+x}-x} \right]$,"Evaluate the limit: $$\lim_{x\rightarrow 0}\left[ \frac{\ln(\cos x)}{x\sqrt{1+x}-x} \right]$$ I actually was able to find the limit is $-1$ after applying L'Hôpital's rule twice. I wonder if that was the intention of this exercise or there's an ""easier"" way. Thanks.","['calculus', 'real-analysis', 'limits']"
842604,"Given every horse's probability of winning a race, what is the probability that a specific horse will finish 2nd and 3rd?","This question is a follow-on from this question . I am trying to determine the probability of each horse finishing 2nd and each horse finishing 3rd. I have developed code to calculate the probabilities by implementing the formulas provided in the above mentioned question. Each horse is represented by a 'horseData' object containing variables such as the horse id (a unique number to identify the horse), the probability of winning (Pw), the probability of finishing 2nd (P2nd), the probability of finishing third (P3rd) among other variables. All of the HorseData objects are contained in a List called hdList. The following code implements the formula:
$$
P(i,2)= \sum_{i \neq x} (P_x . \frac {P_i}{(1 - P_x)  })
$$ // Calc 2nd place for each horse
for (HorseData hdi : hdList) {
    for (HorseData hdx : hdList) {
        if (hdi.id != hdx.id) {
            term = hdx.Pw * hdi.Pw / (1 - hdx.Pw);
            hd.addToP2nd(term);
        }
    }
} This calculates the probability of finishing 2nd for each horse. The sum of these probabilities adds to one. All good so far. The following code implements the formula: $$
P(i,3)= \sum_{i \neq x \neq y}( P_x . P_{y2nd} .\frac {P_i}{(1 - P_x - P_{y2nd})  })
$$ // Calc prob 3rd place for each horse
for (HorseData hdi : hdList) {
    for (HorseData hdx : hdList) {
        if (hdi.id != hdx.id) {
            for (HorseData hdy : hdList) {
                if ((hdx.id != hdy.id) & (hdi.id != hdy.id)) {
                    term = hdx.Pw * hdy.P2nd * hdi.Pw / (1 - hdx.Pw - hdy.P2nd);
                    hd.addToP3rd(term);
                }
            }
        }
    }
} This calculates the probability of finishing 3rd for each horse. However the sum of these probabilities does not add to one. For testing, I have a 5 horse race, with the Pw = 0.2 for all horses. The code to calculate P2nd returns 0.2 for each horse, however the code to calculate P3rd returns 0.16 for each horse (whereas I think it should be 0.2). Any assistance in reviewing the formulas and the code implementation would be appreciated.","['statistics', 'probability', 'conditional-probability']"
842648,Approximate $d\sqrt{x}$ or $d\log(x)$ by a function of the form $a/(1 + bx^c)$,"I have some functions of $x$, in the form of $d\sqrt{x}$ or $d\log(x)$ where d is known. I would like to rewrite (approximate is fine) them in the form $\dfrac{a}{1 + bx^c}$, where a, b and c are arbitrary. We are talking about dollars here so x goes from 0 to less than 100,000. No need to worry about limiting behaviours. I think one way to do this is to write out the Taylor series expansion on both sides, and then try to match coefficients, but that doesn't look so easy. Another way is pick 3 x's , say x = 100, 4000 and 80000, and try to solve for a, b, c at those points, but it seems there is no solution. Are there better ways to approach this problem? Thanks!","['approximation', 'functions']"
842713,Question about the local maxima of a funciton,"Assume $f(x_1,x_2,\dots,x_n)$ is a smooth, continuos, differentiable function, and let we want to check if $(x'_1,x'_2,\dots,x'_n)$ is the local maxima or not. Assume the first order condition is satisfied i.e. $\nabla f(x'_1,x'_2,\dots,x'_n)=0$, however the corresponding Hessian matrix $\nabla \nabla f(x'_1,x'_2,\dots,x'_n)$ is negative semi-definite and all higher order derivatives are $\boldsymbol{0}$ matrix. In this case, can we say $x'_1,x'_2,\dots,x'_n$ is a local maxima of function $f$?","['functions', 'calculus', 'real-analysis']"
842749,Ahlfors Complex Integration,This  is  my  opinion  on the  question.  Is  true  or  not? If  not  what  is  the  useful solution?  Which  way  is  more  useful?,['complex-analysis']
842764,Proving $\limsup\frac 1 {a_n}=\frac 1 {\liminf a_n}$ and $\limsup a_n\cdot \limsup \frac 1 {a_n} \ge 1$,"Let $a_n$ be a sequence such that $\forall n\in \mathbb n: 0<a\le a_n\le b <\infty.$ Prove: $\displaystyle\limsup_{n\to\infty}\frac 1 {a_n}=\frac 1 {\displaystyle\liminf_{n\to\infty}a_n}$ $\displaystyle\limsup_{n\to\infty}a_n\cdot \limsup_{n\to\infty}\frac 1 {a_n} \ge 1$ and there's an equality iff $a_n$ is converging. Suppose there are two subsequences: $a_{n_l}, \ a_{n_k}$ such that $\lim a_{n_k} = k, \ \lim a_{n_l}=l$ and suppose $l\le k$, so $\lim \frac 1 {a_{n_k}}=\frac 1 k , \ \lim \frac 1 {a_{n_l}}=\frac 1 l$ so clearly: $\frac 1 k\le \frac 1 l\le l\le k$ so it's easy to see once the largest limit (supermum) is 'inverted' it has to become the smallest limit (infimum). I realize this doesn't show equality, I don't know how to do the other way and I'm not even sure if what I did is good. If $a_n$ converges, suppose to $L$ as its limit then we have: $L\cdot \frac 1 L=1$. If it does not converge then $a_n$ may tend to infinity or won't have a limit. From 1 we can change it to $\displaystyle\limsup_{n\to\infty}a_n\cdot \frac 1 {\displaystyle\liminf_{n\to\infty}a_n} \ge 1$ and from BW, every sequence has a converging subsequence, and since for converging subsequences: $\liminf a_n\le \limsup a_n$ we have $\frac {\limsup a_n} {\liminf a_n}=\limsup a_n\cdot \limsup\frac 1 {a_n} \ge 1$. This should probably be in absolute value since one of those subsequnce limits can be negative, but it isn't in absolute value in the question.","['inequality', 'sequences-and-series', 'calculus', 'limsup-and-liminf', 'proof-verification']"
842767,A game on a graph,"Alice and Bob play a game on a complete graph ${G}$ with $2014$ vertices. They take moves in turn with Alice beginning. At each move Alice directs one undirected edge of $G$. At each move Bob chooses a positive integer number $m,\: 1\leq   m \leq 1000$ and after that directs $m$ undirected edges of $G$. The game ends when all edges are directed. If there is some directed cycle in $G$ Alice wins. Determine whether Alice has a winning strategy. This problem is from the Turkey JBMO TST 2014. Could someone help? I have not gone anywhere with it. Thanks a lot.","['contest-math', 'directed-graphs', 'combinatorial-game-theory', 'graph-theory', 'combinatorics']"
842771,${n \choose r}=\frac {n!}{r!(n-r)!}$ without using the permutation approach.,"I had an idea that would be to first prove Pascal's Rule, $${n \choose r} = {n-1 \choose r-1} + {n-1 \choose r},$$ which can be proved combinatorically whether one particular element (among the $n$) is chosen or not. Now we use the obvious identity  ${n \choose 1}=n$ and also that ${n \choose 2}=\sum_{i=1}^{n-1} i=\frac {n(n-1)}{2}$, both of which can be proved combinatorically and argue by induction, first on $r$ and then on $n$. But this is a very lengthy process and I think not a good solution. Is there any shorter and better method to do this.","['alternative-proof', 'induction', 'binomial-coefficients', 'combinatorics']"
842796,Advice for self-studying Inequalities and Calculus,"I'm interested in self-studying the following books over the next year or so: Spivak's Calculus (I'm already in Ch. 5 and it is very slow going) The Cauchy-Schwarz Master Class by J. Michael Steele Analytic Inequalities by Nicholas Kazarinoff My goal in studying these books is to gain a deeper understanding of calculus, basic real analysis, and manipulations of the standard inequalities, with the ultimate goal of understanding derivations, approximations, and inequalities in probability and statistics (Stirling's approximation, Wallis product, Gamma Function, Normal Distribution, Limit Theorems etc).  One of the things I realized when I first started studying Spivak's Calculus is that I have had very little experience in solving challenging problems.  I have never had any issues with doing 'Exercises' in the standard engineering style calculus text books, but I am often at a loss of ideas when I do problems in Spivak. My questions are the following: Before progressing through Spivak, should I go through a book like Art and Craft of Problem Solving by Paul Zeitz? I guess the point of doing this would be to beef up my problem-solving skills. I should note that I am not very excited about working through the Art and Craft of Problem Solving because a lot of it seems geared toward solving Olympiad geometry problems.  I've never had a solid geometry course, so at this point I feel like it might just be a waste of time trying to learn plane geometry. Should I relearn high school mathematics? To be perfectly honest, I feel robbed by my entire education and I'm very disappointed by my lack of foresight up to this point. I've always used easy textbooks(not my choice) in my college calculus, Linear algebra, and ODE and PDE classes and believed 'good grades' were enough. Or, should I just keep a copy of Polya's Heuristics on hand while I patiently work through Spivak? I'm just looking for a bit of advise on the wisest way to proceed. Thanx.","['inequality', 'calculus', 'soft-question', 'advice', 'problem-solving']"
842801,Topology: Opens vs Neighborhoods,"Disclaimer: This thread is meant informative and therefore written in Q&A style. The problems are highlighted in bold face. The axiomatization of topology can be done in various ways all of them having their own advantage. Here I would like to investigate two of them specifically. There's the one by open sets usually given:
$$\bullet \#I<\infty:\quad A_i\in\mathcal{T}\implies \bigcap_{i\in I}A\in\mathcal{T}\\
\bullet \#I\leq\infty:\quad A_i\in\mathcal{T}\implies\bigcup_{i\in I}A_i\in\mathcal{T}$$
and the one by neighborhoods introduced by Felix Hausdorff:
$$\bullet A\subseteq B:\quad A\in\mathcal{N}(x)\implies B\in\mathcal{N}(x)\\
\bullet A,B\in\mathcal{N}(x)\implies A\cap B\in\mathcal{N}(x)\\
\bullet \forall x\in X:\quad\mathcal{N}(x)\neq\{\}\\
\bullet A\in\mathcal{N}(x)\implies x\in A\\
\bullet A\in\mathcal{N}(x)\implies\exists C_0\in\mathcal{N}:\quad A\in\mathcal{N}(c)\text{ for all }c\in C_0(x)$$ Prove that any family of open sets give rise to a neighborhood system via: $$A\in\mathcal{N_T}(x):\iff\exists U_0\in\mathcal{T}:\quad x\in U_0\subseteq A\quad$$ and that any neighborhood system gives rise to a family of open sets via: $$A\in\mathcal{T_N}:\iff\forall a\in A:\quad A\in\mathcal{N}(a)$$ Moreover prove that their equivalent in the sense: $$\mathcal{T}\mapsto\mathcal{N_T}\mapsto\mathcal{T}\text{ and }\mathcal{N}\mapsto\mathcal{T_N}\mapsto\mathcal{N}$$
(Note that both must be checked in order to ensure injectivity and surjectivity.) So we can switch back and forth between both descriptions for topology. Here are two situations where this is exploited: a. The interior is defined via neighborhoods:
$$A^\circ:=\{z:A\in\mathcal{N}(z)\}$$
It is contained and open (see Topology: Interior ):
$$A^\circ\subseteq A\text{ and }A^\circ\in\mathcal{N}(z)\text{ for all }z\in A^\circ$$
Therefore neighborhoods have nonempty interior:
$$A^\circ=\bigcup_{A\supseteq U\in\mathcal{T}}U$$
b. Continuity is defined via neighborhoods:
$$N\in\mathcal{N}(f(x))\implies f^{-1}N\in\mathcal{N}(x)$$
Thus in locally convex spaces topology is entailed fully in any point:
$$N\in\mathcal{N}(x)\iff N+a\in\mathcal{N}(x+a)$$ So while open sets reflect general aspects of topology correlations between space itself and topology become lucid via neighborhoods.","['general-topology', 'axioms', 'continuity', 'definition']"
842803,How to find the missing number?,"A teacher intended to give a typist a list of nine integers that form a group under multiplication modulo 91. But one of the nine integers was inadvertently left out, so that the list appeared as $1,9,16,22,53,74,79,81.$ Which integer was left out?","['modular-arithmetic', 'algebra-precalculus']"
842807,Show that: $\frac{D_n}{\langle a\rangle}\simeq\mathbb{Z_2}$,"Show that: $$\frac{D_n}{\langle a\rangle}\simeq\mathbb{Z_2}$$
where $D_n$ is dihedral group and $a$ is generator of order $n$.","['finite-groups', 'group-theory', 'abstract-algebra']"
842823,Quotient of a locally compact space,I am looking for an example of a quotient of a locally compact space that isn't locally compact. Is there a not too complicated example ?,"['general-topology', 'quotient-spaces', 'examples-counterexamples']"
842828,Q: $\lim_{n\to \infty}\left(1 + \frac{1}{n}\right)^{n} = e$,"I am having difficulty with the proof $$\lim_{n\to \infty}\left(1 + \frac{1}{n}\right)^{n} = e$$ in Rudin's Principles of Mathematics. In particular, the last few steps.  The proof is as follows: Theorem. $\lim_{n\to\infty} \left(1 + \frac1n \right)^n = e.$ Proof. Let $$s_n = \sum_{k=0}^{n} \frac{1}{k!}, \qquad t_n = \left(1 + \frac1n \right)^n.$$ By the binomial theorem, $$t_n = 1 + 1 + \frac1{2!}\left( 1 - \frac1n \right) + \frac1{3!}\left(1 - \frac1n \right)\left(1 - \frac2n \right) + \dots \\ + \frac1{n!}\left(1 - \frac1n \right)\left(1 - \frac2n \right)\dots\left(1-\frac{n-1}{n}\right).$$ Hence $t_n \leq s_n$, so that $$\limsup_{n\to\infty} t_n \leq e, 
\tag{14}$$ by Theorem 3.19. Next, if $n \geq m$, $$t_n \geq 1 + 1 + \frac1{2!}\left(1-\frac1n\right) + \dots + \frac1{m!}\left(1-\frac1n\right)\dots\left(1-\frac{m-1}{n}\right).$$ Let $n\to\infty$, keeping $m$ fixed. We get $$\liminf_{n\to\infty} t_n \geq 1 + 1 + \frac1{2!} + \dots + \frac1{m!},$$ so that $$s_m \leq \liminf_{n\to\infty} t_n.$$ Letting $m\to\infty$, we finally get $$e \leq \liminf_{n\to\infty} t_n. \tag{15}$$ The theorem follows from (14) and (15). (original image) My question: What allows us to say that $$\lim_{n\to \infty}\text{inf } t_{n} \geq s_{m}?$$ I see that $\lim_{n\to \infty}t_{n} \geq s_{m}$ (if it exists, I suppose otherwise it's vacuously true...), but why the $\liminf$?  The text does similar steps in other proofs without explanation, so I am not sure if I am misunderstanding something obvious...","['real-analysis', 'analysis']"
842838,Möbius transformation: proving the image of the unit circle is a line,"Problem 1) Find the Möbius transformation which maps the points $0,i,-i$ to $0,1,\infty$ respectively. 2) Prove that the image of the circle centered at $0$, of radius $1$ is the line $\{Re(z)\}=1$. In $1)$ I didn't have problems, the homographic transformation $T(z)$ which satisfies the conditions given is $T(z)=\dfrac{2z}{z+i}$. I don't know how to solve $(2)$. If I denote the circle by $C$, I want to show that $T(C)=\{Re(z)=1\}$. I've tried to prove the two inclusions of these sets but I couldn't, I would appreciate some help.","['complex-numbers', 'complex-analysis']"
842846,Finite Subgroups of $GL_2(\mathbb Q)$,"I want to prove that the only finite subgroups of $GL_2(\mathbb Q)$ are $C_1, C_2, C_3, C_4, C_6, V_4, D_6, D_8,$ and $D_{12}$. First, we determine all possible finite orders of elements. Now, an element of order $n$ will have a minimal polynomial that divides $x^n-1$, so its (complex) roots will be distinct, and so the matrix will be diagonalizable over $\mathbb C$. This implies that both eigenvalues are $n$th roots of unity, and that at least one is primitive, and so the minimal polynomial will be the $n$th cyclotomic polynomial. But since the minimal polynomial can only have degree $1$ or $2$, since we're dealing with $2\times 2$ matrices, the only possible orders are those $n$ for which $\phi(n)=1$ or $2$, so the only possible orders are $1, 2, 3, 4$, and $6$.  Thus, if $G$ is a finite subgroup of $GL_2(\mathbb Q)$, then $|G|=2^a3^b$. Now, since $G$ contains a Sylow-$3$ of order $3^b$, and any $3$-group contains subgroups of every possible order, once we show that $C_3\times C_3$ is not a subgroup of $GL_2(\mathbb Q)$, then we can conclude that $b=0$ or $1$, since we already saw that $C_9$ cannot be a subgroup. WLOG, let $g=\begin{bmatrix} 0&-1\\1&-1\end{bmatrix}$, which is the Rational Canonical Form for the minimal polynomial $x^2+x+1$, and so has order $3$. We seek to show that there is no matrix $h$ such that $h$ has order $3$, commutes with $g$, and isn't a power of $g$. So assume $h=\begin{bmatrix} a&b\\c&d\end{bmatrix}$. Then $gh=\begin{bmatrix} -c&-d\\a-c&b-d\end{bmatrix}$ and $hg=\begin{bmatrix} b&-(a+b)\\d&-(c+d)\end{bmatrix}$. Equating these, we get that $c=-b, d=a+b$, so $h=\begin{bmatrix} a&b\\-b&a+b\end{bmatrix}$. For $h$ to have order $3$, the trace must be $-1$, and the determinant must be $1$, just like in the Rational Canonical Form, so $2a+b=1$, and $a^2+ab+b^2=1$. The solutions are $a=-1, b=1$ and $a=0, b=-1$. The latter gives $h=g$ and the former gives $h=g^2$, and so there can be no subgroup isomorphic to $C_3\times C_3$, and thus $9$ does not divide the order of the group. Now, the next step would be to restrict the exponent of $2$, but I'm not quite sure how to do this. One part of the problem tells me to show that the only noncyclic abelian subgroup is $V_4$, the Klein-$4$ group. So if we let $g=\begin{bmatrix} 0&1\\1&0\end{bmatrix}$ be the RCF of $x+1$, then the only order $2$ matrices that commute with it are $-g$ and $-g^2=-I$, which form a Klein-$4$ group. This means that $C_2^3$ is not a subgroup. Also, if we get $g=\begin{bmatrix} 0&-1\\1&0\end{bmatrix}$ be the RCF of $x^2+1$, then the only order $2$ element that commutes with it is $-I=g^2$, so there is also no subgroup isomorphic to $C_4\times C_2$. In a previous exercise, I showed that $Q_8$ is not a subgroup of $GL_2(\mathbb R)$, and thus isn't a subgroup over $\mathbb Q$ either. But this doesn't seem to prevent subgroups of order $16$, since $D_8$ is in fact a subgroup. Checking all $14$ groups of order $16$, it seems that all of them have an order $8$ subgroup besides $D_8$, but is there a cleaner way to rule out groups of order $16$ without classifying them, since I'm apparently supposed to conclude that the order of $G$ divides $24=2^3\cdot 3$ from the fact that the Klein-$4$ group is the only noncyclic abelian subgroup. So now, if I assume as known that $24$ divides the order of $G$, then the possible orders for $G$ are $1, 2, 3, 4, 6, 8, 12$, and $24$. I can find $C_1, C_2, C_3, C_4, C_6, V_4, D_6, D_8,$ and $D_{12}$. This takes care of all the orders except $12$ and $24$. I can show that $C_{12}$ and $C_{6}\times C_2$ are not subgroups, but I'm not sure how to rule out the nonabelian groups of order 12, $A_4$ and $C_3\rtimes C_4$, or the groups of order $24$. So in summary, I'm a bit stuck in ruling out the nonabelian groups of order $12, 16,$ and $24$. Is there a more elegant way to do this than to look at the classifications of these groups and find subgroups which I have already shown to be impossible?","['linear-algebra', 'group-theory']"
842851,$M \oplus M \simeq N \oplus N$ then $M \simeq N.$,Let $M$ and $N$ be finitely generated $R$-modules where $R$ principal domain. Show that if $M \oplus M \simeq N \oplus N$ then $M \simeq N.$,"['modules', 'principal-ideal-domains', 'abstract-algebra']"
842870,Zabreiko's Lemma,"Lemma (Zabreiko, 1969) Let $X$ be a Banach space and let $p: X \to [0,\infty)$ be a seminorm. If for all absolutely convergent series $\sum_{n=1}^\infty x_n$ in $X$ we have 
  $$
p\left(\sum_{n=1}^\infty x_n\right) \leq \sum_{n=1}^\infty p(x_n) \in [0,\infty]
$$
  then $p$ is continuous. I must find this lemma's proof.","['reference-request', 'functional-analysis']"
842889,Flux Integral - where did I go wrong?,"S is the graph $z=25-(x^2+y^2)$ over the disk $x^2+y^2\leq 9$ and $\varphi = z^2dx\wedge dy$. Find $\int_S \varphi$. According to the book the answer is $3843\pi$, but the answer I got is different. What I did: First define $k(x,y)=(x,y,25-(x^2+y^2))$ then $k_x=(1,0,-2x)$ and $k_y=(0,1,-2y)$. Now, I have that $\varphi (k_x,k_y)=(25-(x^2+y^2))^2dx\wedge dy (k_x,k_y)=(25-(x^2+y^2))^2$. I ought to find $\int_S\varphi$ which will be given by $$\int_S\varphi=\int_0^3\int_0^{\sqrt{9-y^2}}625-50(x^2+y^2)+(x^2+y^2)^2dxdy$$. To make it easier, I changed to polar coordinates: $x=r\cos\phi,y=r\sin\psi$. Then I have $$\int_S\varphi = \int_0^{\color{red}{2\pi}}\int_0^3625r-50r^3+r^5drd\phi\\=\int_0^{\color{red}{2\pi}}\left(\frac{625}{2}(3)^2-\frac{50}{4}(3)^4+\frac{1}{6}(3)^6\right)d\phi\\=\int_0^{\color{red}{2\pi}}\left(\frac{5625}{2}-\frac{4050}{4}+\frac{726}{6}\right)d\varphi\\=\int_0^{\color{red}{2\pi}} 1921\; d\phi\\=3842\pi.$$ Looks like I have missed something, maybe my change to polar coordinates is wrong or there's another mistake that I cannot see. Update:Fixed the limits of integration","['definite-integrals', 'multivariable-calculus', 'differential-forms', 'integration']"
842898,Is $\det(AB) =\det(BA)$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Let $A, B$ be square matrices. I am having trouble proving if $$ \det(AB) = \det(BA) $$ is right or wrong. Can you please point me to the right direction?","['matrices', 'linear-algebra', 'determinant']"
842899,Solution verfication and two small cardinality questions,"I'm studying to my final exam due to tomorrow, and I encountered several small problems. Determine the cardinality of the following sets: 1). $A$ is the set of all injective functions from $\{1,2,3\}$ to $\mathbb R$. My solution: $1$ can be sent to everything in $\mathbb R$. Lets assume it was sent to $\{a\}$. So $2$ can be sent to $\mathbb R \setminus \{a\} \sim \mathbb R$. Lets assume it was sent to $\{b\}$. $3$ can be sent to $\mathbb R \setminus \{a, b\} \sim \mathbb R$. So overall there are $|\mathbb R \times \mathbb R \times \mathbb R|=\aleph$ such functions. 2). I wasn't sure how to solve this. $B$ is the set of all surjective functions from  $\mathbb R$ onto $\{1,2,3\}$. 3)> I tried continuing, but also got stuck on this one: $C= \{f \in B: $ for every $x,y \in \mathbb R| x \leq y \rightarrow f(x)\leq f(y) \}$ Thanks in advance for any hints or assistance of any sort!","['elementary-set-theory', 'solution-verification']"
842912,Number of way to invite my friends over for dinner on 5 nights,"Okay so here's the full problem followed what I'm thinking: Problem : How many successive ways are there to invite one of four different friends over for dinner on five successive night s.t no friend is invite more than three times? Now here's the though process I'm going down: We proceed by cases, adding up the cases at the end Case 1 : 1 friend for 3 nights, 1 friend for 2 nights Let's denote the friends as $f_i$ where $1\leq i\leq 4$. If $f_1$ eats dinner at the house for 3 nights, that leaves either $f_2$ for two nights, or $f_3$ or $f_4$. Thus, there are 3 arrangements if $f_1$ eats dinner 3 nights. It follows similarly if we consider $f_2$ for the spot of 3 nights, or $f_3$ or $f_4$. Thus, there are $$12{5 \choose 3}{2 \choose 2}$$
  arrangements possible. Case 2 : 1 friend for 3 nights, 1 friend for 1 night, 1 friend for 1 night If $f_1$ eats dinner at the house 3 nights, we have $f_2$ one night, $f_3$ one night. Or we have $f_2$ one night, $f_4$ one night. Or we have $f_3$ one night, $f_4$ one night. Thus, with $f_1$ on 3 nights, we have 3 ways to choose. The subcases of $f_2-f_4$ follow similiarly, so we have $$12{5 \choose 3}{2 \choose 1}{1 \choose 1}$$ Am I on the right track or does there need to be some revision?",['combinatorics']
842913,$|f(x)|\leq \sqrt{\frac{\pi}{3}\int_0^\pi f'^2}$,"Let $f\in C^1([0,\pi],\mathbb R)$ such that $\displaystyle\int_0^\pi f(t) dt=0$ Prove that $\forall x\in [0,\pi],\displaystyle|f(x)|\leq \sqrt{\frac{\pi}{3}\int_0^\pi f'^2(t)dt}$ Failed natural attempt $\int_0^\pi f(t) dt=0$ tells us that there is some $\beta\in [0,1]$ such that $f(\beta)=0$ Using the fundamental theorem of calculus and Cauchy-Schwarz inequality, $\displaystyle |f(x)|=|f(x)-f(\beta)|\leq\int_x^\beta |f'(t)|dt\leq \int_0^\pi |f'(t)|dt \leq \sqrt{\pi}  \sqrt{\int_0^\pi f'^2}$ It is not sharp enough. This might have something to do with Fourier series.","['inequality', 'real-analysis', 'integral-inequality']"
842915,A Modern Alternative to Euclidean Geometry,"First of all, I want to master Geometry, I have knowledge on high school geometry and I was thinking of learning Euclidean Geometry. I bought a copy of Euclid's Elements, it is very interesting, however, it does have a fairly different method compared to the modern approach in teaching geometry. Can I ask if it is required in our modern mathematics to learn Euclid's Elements? Or is learning Euclid's elements just for intellectual exercise? Are there any modern textbook on Euclidean Geometry or plane geometry? I have no problem with the formal mathematical approach using Axioms and Postulates, I enjoy having a first exposure to them, actually. In the future, I want to read Principia Mathematica by Isaac Newton, is it a must to learn Euclid's Elements to learn it? Or Descartes's Geometry is the basis of it? Or maybe there is a modern geometrical approach to explain it?","['geometry', 'euclidean-geometry']"
842926,Does this function change signs infinitely often?,"$$f(n) = \sum_{i = 1}^n (-1)^{\omega(i)}$$ where $\omega(n)$ counts how many distinct prime factors $n$ has. I don't see any sign changes past $n = 49$, but I've only computed it up to $n = 1{,}000$.",['number-theory']
842937,Show that $\lim _{r \to 0} \|T_rf−f\|_{L_p} =0.$,"I am having a hard time with the following real analysis qual problem.  Any help would be awesome. Suppose that $f \in L^p(\mathbb{R})$ , where $1\leq p< + \infty$ . Let $T_r(f)(t)=f(t−r)$ . Show that $\lim_{r \to 0} \|T_rf−f\|_{L_p} =0$ , that is $$ \lim_{r\to 0} \left( \int_{\mathbb R} |f(t-r) - f(t)|^p \mathrm d t\right)^{1/p} =0.$$","['measure-theory', 'real-analysis', 'lebesgue-integral', 'lebesgue-measure', 'lp-spaces']"
842942,When can we switch the limit and the integral?,"$\Omega$ is a domain in the complex plane and $F(z,t)$ is a continuous function on $\Omega\times I$ where $I=[0,1]$ is the unit interval in $\mathbb{R}$. Suppose further that $F(z,t)$ is analytic in $z$ on $\Omega$ for each fixed $\in I$. Prove that $$g(z)=\int_0^1 F(z,t) dt$$ Is analytic on $\Omega$. What can be said if $F(z,t)$ is only assume to be analytic on $z\in\Omega$ For all rational values of $t$ (when held fixed in $I$)? Prove:    $$\lim_{h\rightarrow0} \frac{g(z+h)-g(z)}{h}=\lim_{h\rightarrow 0} \int _0^1 \frac{F(z+h,t)-F(z,t)}{h}$$ Here I want to switch the integral but I do not know which theorem can I use? Edit 1 Another approach,
Using Morera's theorem,
$\int_{\gamma}\int_0^1F(z,t)dtdz=0$ for any closed curve $\gamma$. Since $F(z,t)$ is uniformly continuous, we can switch the integral and get the result.
Is this right? Can we switch the integral? Edit 2 Second part: Let $t\in [0,1]$ and let $\{t_n\}$ be a sequence in $\mathbb{Q}$ such that $t_n\rightarrow t$ uniformly. $lim_{n\rightarrow\infty}F(z,t_n)=F(z,t)$ uniformly since $F$ is uniformly continuous in $t\in[0,1]$ Then we have: 
$\lim_{n\rightarrow \infty} \int_{\gamma}\int_0^1F(z,t_n)dtdz=\int_{\gamma}\int_0^1lim_{n\rightarrow\infty}F(z,t_n)dtdz=\int_{\gamma}\int_0^1F(z,t)dtdz=0$ by first part.",['complex-analysis']
842944,How is Russell’s Paradox equal to the universal set?,"How is Russell’s Paradox, which is defined as the collection
$$
\{ x \mid x \notin x \},
$$
equal to the universal set $ \{ x \mid x = x \} $? Do we assume that if $ x = x $, then $ x \notin x $? My question is specifically what is written at the end of Page 21 of this document . Thanks for any help!",['elementary-set-theory']
842949,How to solve the non-linear differential equation $y''=x-y^2$?,"$y''(x)=x-y^2(x)$ I'm particularly interested in solutions when $x>0$. I've performed asymptotic analysis and reached the conclusion that solutions must behave as $\pm\sqrt{x}$ when $x\rightarrow \infty$ but I don't know what to do next. I've also tried looking for a solution of the form $y(x)=y_p(x)\pm\sqrt{x}$, but I got to an even more difficult differential equation for $y_p(x)$ I can also deduce the obvious thing that $y''>0$ when $x>y^2$ and $y''<0$ when $x<y^2$, so there are like three regions. My guess is that there will be solutions which tend to the parabola $y=\sqrt{x}$ in every region, but I'm really stuck. Any insights would be very appreciated. EDIT:
When I say ''solve'', I mean that I want a feel on how possible solutions behave (e.g., are there any oscillating solutions?, if I have a solution of an IVP where $y^2(x_0)>x_0$, what will that solution do?...) Also, I would be thrilled if there were solutions expressable as elementary functions. Now that i think about it, a better phrasing than ''solve this ODE'' would be ''study [the behaviour of solutions of] this differential equation''","['asymptotics', 'ordinary-differential-equations']"
842958,A set is compact if and only if every continuous function is bounded on the set? [duplicate],"This question already has answers here : $K\subseteq \mathbb{R}^n$ is a compact space iff every continuous function in $K$ is bounded. (4 answers) Closed 10 years ago . I was asked to prove the following statement: Let $K \subseteq R^n$ . show that $K$ is compact (meaning closed and bounded) if and only if every continuous function is bounded on $K$ . What I did: Suppose $K$ is not bounded, and so, it is not compact. Then the function $\sum |x_i|$ is a continuous unbounded function on $K$ . Via contrapositive, this shows that if every function is bounded, then $K$ is also bounded. What I need help with: Assume $K$ is not closed. I need to find a continuous and unbounded function on $K$ . that will prove that if every continuous function is bounded on $K$ , then $K$ is compact. after that, i still need to show that if $K$ is compact then every continuous function $f: K \to \mathbb R$ is bounded. Would someone point me in the right direction? Clarification: it's not homework. I am preparing for an exam.","['general-topology', 'multivariable-calculus', 'calculus', 'compactness']"
842960,"if $X_i$ are iid standard normal distributed, what is the limiting distribution of $\sum X^4 / (\sum X^2)^2$?","If $X_i$, $i=1,\ldots,n$ are iid standard normal distributed, what is the limiting distribution of $S_n=\sum X^4 / (\sum X^2)^2$? After finding the moments and since $Cov(X^4, X^2)=0$, I have the bivariate normal $\sqrt{n} (\frac{1}{n}\sum X^4-\mu_1)\rightarrow N(0,\sigma_1^2)$
$\sqrt{n} (\frac{1}{n}\sum X^2 - \mu_2)\rightarrow N(0,\sigma_2^2)$
with $Cov(X^2,Cov^4)=0$ (not sure how to type latex matrices) and using multivariate delta method $h(x,y)=\frac{x}{y^2}$, I get $\sqrt{n}(nS_n-\frac{\mu_1}{\mu_2^2})\rightarrow N(0,\nabla h^T\sigma \nabla h)$. My question is - is this the right form for finding the limiting distribution of $S_n$? I thought the form should be $\sqrt{n}(S_n-\mu)\rightarrow N(0,\sigma^2)$, but here I have an 'extra' $n$ as the coefficient of $S_n$).","['statistics', 'normal-distribution', 'central-limit-theorem']"
842978,"Proving $\frac2\pi x \le \sin x \le x$ for $x\in [0,\frac {\pi} 2]$","Prove $\frac2\pi x \le \sin x \le x$ for $x\in [0,\frac {\pi} 2]$. I tried to do this in two ways, I'm not sure about CMVT and I have a problem with the other way. Using Cauchy's MVT: RHS: 
$\sin x \le x \implies \frac {\sin x}{x}\le 1$ 
So define: 
$f(x)=\sin x, \ g(x)=x$ then from CMVT: 
$\dfrac {f(\frac {\pi} 2)}{g(\frac {\pi} 2)}=\dfrac {f'(c)} {g'(c)}=\cos c$ 
and from the fact that $c$ is between $0$ and $\pi/2 \implies \cos c \le 1$. LHS: In the same manner but here I run into some trouble:
$\frac2\pi x \le \sin x\implies \frac {2x}{\pi\sin x}\le 1$
So: 
$\dfrac {f(\frac {\pi} 2)}{g(\frac {\pi} 2)}=\dfrac {f'(c)} {g'(c)}\implies\frac {1}{\sin {\frac {\pi}{2}}}=\frac {2}{\pi \cos c}$
 Here actually 
$\frac {1}{\sin {\frac {\pi}{2}}}=1$ so it's also $\le 1$ Is it correct to use CMVT like this ? The other way: We want to show: $f(x)=\sin x - x < 0$ and $g(x)=\frac {2x}{\pi}-sinx <0 $ by deriving both it's easy to show that the inequality stands for $f$ but for $g$ it isn't so obvious that $g'(x)=\frac {2}{\pi}-\cos x$ is negative. In fact for $x=\frac {\pi} 2$ it's positive. Please help figure this out. This is the same The sine inequality $\frac2\pi x \le \sin x \le x$ for $0<x<\frac\pi2$ but all the answers there are partial or hints and I want to avoid convexity. Note: I can't use integrals.","['inequality', 'calculus', 'proof-verification']"
842985,Proof by induction that $\sum_{i=1}^{n} \frac{2^i}{i} \leq n!+1$ for $n\ge 3$,"Prove that $\forall n, n\geq 3$,
  $$
\sum_{i=1}^{n} \frac{2^i}{i} \leq n!+1
$$ By induction, I have that: For $n=3$: $\displaystyle\sum_{i=1}^{3} \frac{2^i}{i} = 20/3 \leq 3!+1=7$ Suppose that the proposition is true for $n=k$. Then, for $n=k+1$ $$
\sum_{i=1}^{k+1} \frac{2^i}{i}=\sum_{i=1}^{n} \frac{2^i}{i}+\frac{2^{k+1}}{k+1} \leq k!+1+\frac{2^{k+1}}{k+1}=\frac{(k+1)!}{k+1}+1+ \frac{2^{k+1}}{k+1}
$$ But I'm stuck here, I should get $\leq (k+1)!+1$",['discrete-mathematics']
842989,The completeness assumption in Prokhorov's theorem,"Originally, I encountered this question on Terence Tao's blog , where the following exercise is presented: Exercise 23 (Implications and equivalences) Let $X_n, X$ be random variables taking values in a $\sigma$compact metric space $R$. [...] (ii) Show that if $X_n$ converges in distribution to $X$, then $X_n$ has a tight sequence of distributions. (iii) Show that if $X_n$ converges in probability to $X$, then $X_n$ converges in distribution to $X$. (Hint: first show tightness, then use the fact that on compact sets, continuous functions are uniformly continuous.) Whats struck me as odd was that $R$ is merely assumed to be $\sigma$-compact, i.e. no completeness-assumption on $R$ is made (as the example $\Bbb{Q}$ shows, there are $\sigma$-compact spaces that are neither locally compact, nor complete). This makes it rather hard to construct new compact subsets (from old ones). Indeed, the proofs of the above statement (ii) that I found (see e.g. https://www.math.leidenuniv.nl/~vangaans/jancol1.pdf Theorem 5.2) use the fact that $$
K := \bigcap_j \bigcup_{i=1}^{k_j} \overline{B}(a_i, 1/j)
$$
is a compact set if $R$ is complete , because it is closed and totally bounded. Nevertheless, Wikipedia ( http://en.wikipedia.org/wiki/Prokhorov%27s_theorem ) does also not assume that the metric space in question is complete, there the only requirement is separability. Note that we need to produce compact subsets of $R$, because for tightness (see below), we have to show that for $\varepsilon > 0$ there is $K \subset R$ compact such that $\Bbb{P}(X_n \in K) \geq 1-\varepsilon$ holds for all $n$ sufficiently large. In summary , my question is if the two statements as in the exercise above are correct even without further completeness assumptions on $R$. Hints/proofs/counterexamples would be highly appreciated. For convenience of the reader, I repeat the necessary definitions below: Definition 10 (Modes of convergence) Let $R = (R,d)$ be a $\sigma$-compact metric space (with the Borel $\sigma$-algebra), and let $X_n$ be a sequence of random variables taking values in $R$. Let $X$ be another random variable taking values in $R$. [...] $X_n$ converges in probability to $X$ if, for every $\epsilon > 0$, one has
  $$\liminf_{n \rightarrow \infty} {\bf P}( d(X_n,X) \leq \epsilon ) = 1$$
  [...] $X_n$ converges in distribution to $X$ if, for every bounded continuous function $F: R \rightarrow {\bf R}$, one has $$\lim_{n \rightarrow\infty} \mathop{\bf E} F(X_n) = \mathop{\bf E} F(X)$$ $X_n$ has a tight sequence of distributions if, for every $\epsilon > 0$, there exists a compact subset $K$ of $R$ such that $\mathop{\bf P}( X_n \in K ) \geq 1 - \epsilon$ for all sufficiently large $n$.","['probability-theory', 'measure-theory', 'metric-spaces']"
842990,Need help with simple system of differential equations,"thanks to your help I advanced in computing differential equations, but now I encountered another problem I need help with - this time it is a system of differential equations: $$x_1'=-x_2$$ 
  $$x_2'=x_1$$ I know that the answer should contain trigonometric functions, (sine and cosine) but I have no idea how to start. I tried to divide first equation/second equation and I got something like: $$\frac{x_1'}{x_2'}=-\frac{x2}{x1}$$ Then I rewrited x1' as $$\frac{dx1}{dt}$$ and did the same with x2. I got rid of dt this way and got a:
$$x_1dx_1=-x_2dx_2$$
Which lead me to result:
$$x_1=\sqrt(const-x_1^2)$$
After inserting x1 to the $$x_2'=x_1$$ equation I got some results, but neither of them contains sine or cosine. Could you point me what am I doing wrong?","['trigonometry', 'ordinary-differential-equations', 'systems-of-equations']"
842996,Number Theory Reading List,What are the essential number theory texts that every serious student of number theory should read?,"['book-recommendation', 'soft-question', 'number-theory']"
843014,Showing a recursive sequence isn't bounded $a_{n+1}=a_n+\frac 1 {a_n}$,"Show the sequence isn't bounded: $a_1=1$, $a_{n+1}=a_n+\frac 1 {a_n}$. Proof by contradiction: Let $M>0$ such that $\forall n: |a_n|< M$. Let $\epsilon >0 $ and for some $n=N, \epsilon: a_N=M-\epsilon<M $ pluging that in the recursion: $a_{N+1}=M-\epsilon+\frac 1 {M-\epsilon}>M>M-\epsilon$. Contradiction. I wondered if I could suppose about the boundary that $\forall n: |a_n|\le M$ ? The proof would basically be the same only I could drop the epsilon.","['sequences-and-series', 'proof-verification', 'real-analysis']"
843018,"Find polynomials f(x),g(x) and h(x),if they exist,such that for all x... Putnam Problem","Find polynomials $f(x), g(x)$, and $h(x)$, if they exist, such that for all $x$, $\mid f(x)\mid-\mid g(x) \mid+h(x)=  
\begin{cases}  
-1, & \text{if}~x<-1 \\  
3x+2, & \text{if}~-1\leq x\leq 0 \\  
-2x+2, & \text{if}~x>0\\
\end{cases}$ This is a problem from Putnam Competition 1999, and I could not even approach the problem. I have seen one solution, where they say, it seems that $-1,0$ are crucial points, so one can assume $F(x)=a|x+1|+b|x|+cx+d$ , now, there are quite a few things I do not understand here, why should the sum need to be linear, second, why should we consider this?. Another version of solution uses this: if $r(x)$ and $s(x)$ are any two functions, then $\max\{r,s\}=\dfrac{r+s+|r-s|}{2}$. Though this seems to be correct for a few case tests, how can I prove this to be true, if not proof then at least understand the intuition behind it. Please help, but please do not bombard a solution with so advanced theories that I cannot grasp the concept. Thank you.","['algebra-precalculus', 'functions']"
843031,What is that curve that appears when I use $\ln$ on Pascal's triangle?,"I made a little program that generates Pascal triangles as images : I first tried it associating to each pixel a color whose intensity was proportional to the number in the Pascal triangle The colors being 0-255, i used the following function to convert value to colors: $$f(x)=\frac{x-m}{M-m}255$$
where $x$ is the value in the Pascal triangle, $M$ is the max value in the triangle, and $m$ in the min value in the triangle.
 : size 50*50 : The axis are like in this picture : However, as you can see, most of the picture is black due to the numbers being really distant (great distance between highs and lows) Therefore, i thought it would be good to use a logarithmic scale : $$f(x)=\frac{\ln(1+x-m)}{\ln(1+M-m)}255$$ Which gives me : size 50*50 : That's way better. Yet, something was bugging me : as I increased the number of rows, I noticed that some curve was being drawn : size 50*50 : size 100*100 : size 150*150 : I can't try really high numbers, as my computer isn't good enough, nor is the software I use. Is there something behind that 'curve' ? If so, what curve would it be ? Could someone provide explanation why I get such results ? Thank you. Progress We're looking at the level curves of $\ln\binom{N-y}{x},N\in\mathbb{N}^*$ By Stirling, as @TedShifrin remarked,  $\ln(n!)\sim n\ln(n)$ therefore $\ln\binom{N-y}{x}\sim y\ln(N-y)-x\ln(x)-(N-y-x)\ln(N-y-x)$ and seem to give us nice curves (cf his answer). Is there an equation y=f(x) for those curves ?","['algebra-precalculus', 'combinatorics']"
843046,Locally Vs Globally Lipschitz Confusion,Is there any difference in a function being locally Lipschitz on $\mathbb{R^n}$ and being globally Lipschitz?,"['ordinary-differential-equations', 'continuity']"
843054,Ramanujan Class Invariant $G_{125}$ and $ G_{5}$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question How to calculate the Ramanujan Class Invariant $G_{125}$ and $G_{5}$?","['special-functions', 'number-theory']"
843081,Prove $A = (A \setminus B) \cup (A \cap B)$,"Prove $A = (A \setminus B) \cup (A \cap B)$ Logically, this is clearly true. I can explain why: start with $A$, remove all elements in $B$ and then add in any elements in both $A$ and $B$, which restores you back to $A$. That's an explanation, but AFAIK, it's not a proof in the formal proof sense. I submitted a proof by a truth table which considers the four possible scenarios where an element is in/not in $A$/$B$. My professor asked me to redo the proof without a truth table. My question is what mechanisms and strategies can I use to prove this in a acceptable formal proof sense?","['proof-writing', 'elementary-set-theory']"
843091,Approximate value of a slowly-converging sum of $\sum|\sin n|^n/n$,"In this question on
Math.SE there appears
this sum:
$$ S = \sum_{n\geq1}s_n, \qquad s_n = \frac{|\sin n|^n}{n}, $$
which converges very slowly. What methods would you suggest for
evaluating it numerically? What I managed to do is unsatisfactory. Pick a bound $M$, and
approximate the remainder of the sum over $n\geq M$ using
$$ \frac{|\sin n|^n}{n} \approx \frac1\pi\int_0^\pi \frac{|\sin
  t|^n}{n}\,dt = T_n, $$
then write
$$S_M = \sum_{1\leq n<M}s_n + \sum_{n\geq M}T_n. $$
The infinite sum over $T_n$ has a closed form in terms of generalized
hypergeometric functions. I tried Shanks and Cohen-Villegas-Zagier convergence acceleration
techniques (in mpmath) applied to $S_{10^6k}$ and $S_{10^7k}$, $1\leq k\leq10$, but
they didn't work well, giving values about $10^{-3}$ away from each
other ($2.151$).  When I tried to fit
$$ S_M = S_\infty + b M^\alpha, $$
for $M=\{1,2,3\}\times 10^7$, I got $\alpha=-\frac12$ and
$$ S_\infty = 2.1509. $$ This is only five digits with $10^7$ terms. Is there a better method? EDIT The values for $S_{10^6\{1\ldots10\}}$ are: Z6 = [2.1503320981264467, 2.1504796881940735, 2.150563926321965,
      2.150601535111673, 2.1506361337302553, 2.1506605927579456,
      2.15067535745342, 2.150691134235195, 2.1507008825140925,
      2.1507120293097395] The values for $S_{10^7\{1\ldots10\}}$ are: Z7 = [2.1507120293097395, 2.1507656995403974, 2.1507894767527613,
      2.1508036508488018, 2.1508133237402696, 2.150820463977797,
      2.1508260133696635, 2.1508304866069095, 2.150834191855564,
      2.1508373250787898] The values for $S_{1+10^8\{1\ldots10\}}$ are: Z8 = [2.1508373250785855, 2.1508542694443973, 2.1508618019128343,
      2.150866279387301, 2.150869344143939, 2.1508715999897547,
      2.150873358367117, 2.1508747716998142, 2.1508759457833806,
      2.1508769361805817] The main reason I say that convergence acceleration seems to fail is that it gives somewhat different results (error $\sim 10^{-3}$) for $Z_6$ and $Z_7$. The simple model above gives the same result (to five digits), but introducing the next asymptotic term and trying to fit $S_\infty+b_1 M^{-1/2}+b_2 M^{-3/2}$ makes the two series agree slightly less, not more. EDIT When fitting $S_\infty+b M^{-1/2}$ with least squares one thing to note is that the estimate for $Z_7$ lies two estimated standard errors from the estimate for $Z_6$, so I'm not sure how accurate it is. The better value, estimated from $Z_7$ seems to be $2.150895272(1)$, but this might be inaccurate. EDIT The sum $\sum_{n\geq m}T_n$ behaves as $m^{-1/2}$ as $m\to\infty$, and is given by
$$ \frac{\Gamma(m)}{\pi 2^m}\left(\frac{2}{\Gamma(1+\frac m2)^2}F\left( \begin{array}{c} 1,\frac{1+m}{2},\frac m2\\1+\frac m2,1+\frac m2 \end{array}\right) + \frac{m}{\Gamma(\frac{3+m}{2})^2}F\left(\begin{array}{c} 1,\frac{1+m}{2},1+\frac m2\\ \frac{3+m}{2},\frac{3+m}{2}\end{array} \right) \right). $$","['approximation', 'closed-form', 'sequences-and-series', 'numerical-methods']"
843107,Local minimum of $f(x) = 4x + \frac{9\pi^2}{x} + \sin x$,"What's the minimum value of the function $$f(x) = 4x + \frac{9\pi^2}{x} + \sin x$$ for $0 < x < +\infty$? The answer should be $12\pi - 1$, but I get stuck with the expression involving both $\cos x$ and $x^2$ in the derivative. Taking the derivative, we have: $$f'(x) = 4 - \frac{9\pi^2}{x^2} + \cos x.$$ In order to find the local extrema of the function, we set $f'(x) = 0$. Therefore, \begin{align}
4 - \frac{9\pi^2}{x^2} + \cos x &= 0 \\
4x^2 - 9\pi^2 + x^2 \cos x &= 0 \\
x^2 (4 + \cos x) &= 9\pi^2.
\end{align} However, I'm not sure what to do from here or if, indeed, I'm doing it right at all. Any help would be appreciated.","['optimization', 'trigonometry', 'calculus', 'derivatives']"
843108,Why are $L^p$-spaces so ubiquitous?,"It always baffled me why $L^p$-spaces are the spaces of choice in almost any area (sometimes with some added regularity (Sobolev/Besov/...)). I understand that the exponent allows for convenient algebraic manipulations, but is there more behind it than mathematical convenience? What bugs me about $L^p$-spaces is that they don't build a scale (of inclusions) but still only allow for one parameter, so by making a choice of exponent you make a choice about two (to my current knowledge) unrelated properties of your function, a) its behavior at singularities (which get milder with high exponent) and b) its tail behavior (which gets less nice with high exponent). How can it still be a good idea to ask ""does this operator map $L^p$ to $L^p$"" rather than ""what does this operator do with singularities and what does it do with tails""? Of course answers to the latter will be harder to formulate and prove, but is that all?","['functional-analysis', 'sobolev-spaces', 'partial-differential-equations', 'soft-question', 'lp-spaces']"
843120,Swapping signs in analysis proofs,"Under what minimal conditions are the following interchange of operations valid (including a question of existence, if not given explicitly)? \begin{align*} \lim \int f_n&=\int \lim f_n \\ \lim_{x\to a} \lim_{y \to b} f(x,y)&=\lim_{y\to b}\lim_{x \to a} f(x,y) \\ \frac{d}{dx}\lim f_n&=\lim \frac{d}{dx}f_n \\ \lim_{x \to c} \int f(x,y)dy&=\int \lim_{x \to c} f(x,y)dy \\ \frac{d}{dx} \int f(x,t) dt &= \int \frac{d}{dx} f(x,t)dt \end{align*} This is probably my weakest area in analysis. The only loose idea I have in my head for a general program surrounds uniform convergence, but I wouldn't even know how to apply that notion to, e.g. the fourth question. I have books, like Royden, Rudin, etc., that provide a laundry list of conditions, but I generally need visualization and intuitive rationale for theorems - and I just don't see it here. I once had the advice to always think of these in basic terms, like sequences and series, but even then, it's hard to picture what's going on geometrically. I have similar issues with $l_p$ vs $L_p$ spaces - norms for $l_p$ are easy to visualize, but norms for $L_p$ have no geometric meaning for me. Thanks for helping me get over this hump - I know this is an important area for understanding analysis deeply. I cannot remember the tag for non-specific questions and would appreciate anyone adding that tag if she or he knows.",['analysis']
843137,How to solve for $x \times x = y$ when I know $y$?,"I'm trying to figure out a problem for a program I'm writing.  I am calculating color values, and they get premultiplied by the alpha.  I want to figure out what the alpha was before hand and divide the color by that. I have the new premultiplied alpha (let's say alpha is $.25$ or $25\%$) $\alpha = .25 * .25$; $\alpha = .0625$ Given this information, I want to figure out $.25$ from $.0625$ $.0625 = x \times x$ My math is super bad/rusty.  Any help would be great!",['algebra-precalculus']
843162,"How to prove ""a group $G$ of order $72$ can't be a simple group""?","By using Sylow theorem, I can prove that $G$ has either $1$ Sylow $3$-subgroup or $4$ Sylow $3$-subgroup, but I don't know how to continue the proof.","['group-theory', 'abstract-algebra']"
843173,Path-connected and locally connected space that is not locally path-connected,"I'm trying to classify the various topological concepts about connectedness. According to 3 assertions ((Locally) path-connectedness implies (locally) connectedness. Connectedness together with locally path-connectedness implies path-connectedness.), we can draw this diagram: +--------------------------+
|Connected                 |
|             1      +-----+----------------------------+
|                    |  3  |           Locally connected|
|   +----------------+-----+     6                      |
|   |Path-connected  |  4  |                            |
|   |                +-----+------------------------+   |
|   |    2           |  5  |  Locally path-connected|   |
+---+----------------+-----+                        |   |
                  8  |           7                  |   |
                     +------------------------------+---| So, I want to find examples of all these 8 categories, but I can't find an example for 4. The topologist's sine curve The comb space The ordered square See below The real line The disjoint union of two spaces of the 3rd type $[0,1] \cup [2,3]$ The rationals Actually there is an answer that gives an example of type 4, but there isn't any explanation. Can anyone please explain it (why it is not locally path-connected, to be specific) or give another example? (Unlike Connected, locally connected, path-connected but not locally path-connected subspace of the plane the example need not be within $\mathbb R^2$ .)","['examples-counterexamples', 'general-topology', 'connectedness', 'locally-connected', 'path-connected']"
843202,"Evaluate $\int \sqrt{1-x^2}\,dx$","I have a question to calculate the indefinite integral:
$$\int \sqrt{1-x^2} dx $$
using trigonometric substitution. Using the substitution $ u=\sin x $   and $du =\cos x\,dx $, the integral becomes:
$$\int \sqrt{\cos^2 u} \, \cos u \,du = \int \|{\cos u}\| \cos u\, du $$ Q: (part a) At what point (if at all) is it safe to say that this is the equivalent of ?
$$\int \cos^2 u\, du = \int \frac {1 + \cos 2u} {2} du$$ (this is easy to solve, btw). In lectures, it was made abundantly clear that over certain intervals (eg $ 0 \le u \le \pi/2$) that $cos u$ is +ve and is safe to do so, but in the indefinite form, the same argument cannot be made (eg $ \pi/2 \le u \le n\pi$). Q: (part b) Is it safe to declare it ok due to the nature of the original integral, which, using a sqrt() must return a +ve number? It could then be argued that it was the substitution which artificially added a -ve aspect... Any suggestions on how to proceed? PS: This is a 1st year calculus course and am revising for exams ;)","['calculus', 'integration', 'indefinite-integrals']"
843212,How to show that no. of elements $x$ of group $G$ such that $x^3=e$ is odd?,"Let G be a finite group G. Then How can I show that no. of elements $x$ of group $G$ such that $x^3=e$ is odd ?
I read this question in an Algebra book. Since $e^3=e$, e must be one of those elements. But how to find for non trivial elements ?","['group-theory', 'abstract-algebra']"
843223,When does injectivity imply surjectivity?,"I'm aware of the existence of this question: Surjectivity implies injectivity However, the question is regarding a finite set $S$. I was wondering, though: What happens when $S$ is an infinite set? Zhen Lin addresses this cases in his answer, by saying that it ceases to be necessarily true, for example $f:\mathbb{N}\rightarrow \mathbb{N}$ defined by $x \mapsto x+1$ is injective but not surjective. My question is: what happens if $S = \mathbb{R}$? Constructing a counterexample for $S=\mathbb{N}$ seems simple enough, but I'm struggling to find a function $f:\mathbb{R}\rightarrow \mathbb{R}$ that's injective but not surjective. Does such a function even exist? If so, how to construct it? And perhaps a more general question (maybe too broad): For which infinite sets $S$ there is a function $f:S\rightarrow S$ such that $f$ is injective but not surjective?","['soft-question', 'elementary-set-theory', 'functions']"
843251,Examples of Infinite Simple Groups,"I would like a list of infinite simple groups. I am only aware of $A_\infty$. Any example is welcome, but I'm particularly interested in examples of infinite fields and values of $n$ such that $PSL_n(F)$ is simple. References about this topic, or any example, are also appreciated.","['infinite-groups', 'simple-groups', 'big-list', 'reference-request', 'group-theory']"
843276,Proving $x+\sin x-2\ln{(1+x)}\geqslant0$,"Question: Let $x>-1$ , show that $$x+\sin x-2\ln{(1+x)}\geqslant 0.$$ This is true. See http://www.wolframalpha.com/input/?i=x%2Bsinx-2ln%281%2Bx%29 My try: For $$f(x)=x+\sin x-2\ln{(1+x)},\\
f'(x)=1+\cos{x}-\dfrac{2}{1+x}=\dfrac{x-1}{1+x}+\cos{x}=0\Longrightarrow\cos{x}=\dfrac{1-x}{1+x}.$$ So $$\sin x=\pm\sqrt{1-{\cos^2{x}}}=\pm \dfrac{2\sqrt{x}}{1+x}$$ If $\sin x=+\dfrac{2\sqrt{x}}{1+x}$ , I can prove it. But if $\sin x=-\dfrac{2\sqrt{x}}{1+x}$ , I cannot. See also http://www.wolframalpha.com/input/?i=%28x-1%29%2F%28x%2B1%29%2Bcosx This inequality seems nice, but it is not easy to prove. Thank you.","['logarithms', 'inequality', 'real-analysis', 'maxima-minima']"
843326,if $\lim_{n\to\infty}(4a_{n+2}-4a_{n+1}+a_{n})=2014$ prove the $\lim_{n\to\infty}a_{n}$ is exist and find the value,"Let sequence $\{a_{n}\}$ such 
$$\lim_{n\to\infty}(4a_{n+2}-4a_{n+1}+a_{n})=2014$$ show that
$$\lim_{n\to \infty}a_{n}$$ exist and find the limit value. Now I use an ugly method to solve this.
I use this follow lemma:
if $$\lim_{n\to\infty}(a_{n+1}-\lambda a_{n})=a
\Longleftrightarrow \lim_{n\to\infty}a_{n}=a,|\lambda|<1$$ I know this lemma proof is ugly, maybe anyone here has a simple method. Thank you.","['limits', 'analysis']"
843327,Quick question about solutions of $y'-y+y^8=0$,"I have one small question about solving $y'-y+y^8=0$ but I don't know where. Here's what I do: Let $u(x) = y(x)^{1-8} = y^{-7}$, then $y=u^{- \frac{1}{7}}$ $\frac{du}{dx} = -7 y^{-8} \frac{dy}{dx} = -7 u^{\frac{8}{7}} (u^{-\frac{1}{7}} - u^{-\frac{8}{7}})= -7u+7$ $u=Ce^{-7x}+1, \ \ C>0$ $y=(Ce^{-7x}+1)^{- \frac{1}{7}}$ And here's where I have doubts. Wolfram says that the solutions of this equation are $\frac{?}{\sqrt[7]{C + e^{7x}}}$ Where $? = e^x, \ \sqrt[7]{-1} \cdot e^x, \ (- 1 )^{2/7} e^x, ..., (- 1 )^{6/7} e^x$. My question is, should I include the $n$-th roots of $1$ in my solutions or is not always necessary?",['ordinary-differential-equations']
843360,Prove that $(kn)!$ is divisible by $(k!)^n$ [duplicate],"This question already has answers here : The product of $n$ consecutive integers is divisible by $n$ factorial (7 answers) Closed 11 months ago . Suppose $k,n$ are integers $\ge1$ . Show that $(kn)!$ is divisible by $(k!)^n$ I have simplified the problem and now, I need to prove that the product of any $k$ consecutive integers is divisible by $k!$ . However I am stuck there.","['divisibility', 'number-theory']"
843401,An exponential martingale [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let $H_{t}$ be a bounded continuous and $\textbf{F}^{B}_{t}$ an adapted process. $B$ Brownian motion. Show that $M_{t}= \exp\left(-\int^{t}_{0}H_{s}dB_{s} -\frac{1}{2}\int^{t}_{0}H^{2}_{s}ds\right)$ is a martingale. Find $M_{t}$ quadratic variation and $\left\langle M,B\right\rangle_{t}$ Some help would be appreciated.","['probability-theory', 'stochastic-processes', 'stochastic-integrals', 'martingales']"
843409,Diferential equation solution satisfying $y(0) = \pi$,"I have the following question from a past exam: Show that the differential equation $\frac{dy}{dx} = \cfrac{e^x + x}{\sin y + 2}$ has a solution satisfying $y(0) = \pi$ What I have done: $$\int (\sin y + 2) \; \mathrm{d}y = \int (e^x + x) \; \mathrm{d}x$$
$$-\cos y + 2y = e^x + \frac{x^2}2 + C$$ Sub in $y = \pi, x = 0$ $$-\cos {\pi} + 2\pi = e^0 + 0 + C$$
$$1+2\pi - 1 = C, C = 2\pi$$ $$-\cos y + 2y = e^x + \frac{x^2}2 + 2\pi$$ Now I am not sure what this question actually wants me to do. Any ideas how I can 'show that the differential equation has a solution satisfying$\dots$'? Note: I am apparently meant to solve it implicitly using an 'appropriate' theorem. Perhaps there is a real-analysis way of solving this?(This was for an Analysis past exam, and I seem to have solved it using only calculus)","['ordinary-differential-equations', 'calculus']"
843412,"Explicit description for $G=\langle a,b,c\mid[a,b]=b\,,\,[b,c]=c\,,\,[c,a]=a\rangle$","I am trying to give an explicit description of the group $$G=\langle a,b,c\mid[a,b]=b\,,\,[b,c]=c\,,\,[c,a]=a\rangle\,.$$
Generalizing to fewer generators, one ends up with the trivial group, i.e.
$$G_0=\langle\,\rangle\cong G_1=\langle a\mid [a,a]=a\rangle\cong G_2=\langle a,b\mid[a,b]=b\,,\,[b,a]=a\rangle\cong 1\,.$$
But I don't see a reason, why this should hold for $G=G_3$ or $G_n$, $n\in\mathbb{N}$. Edit : I am sorry, I thought the symbols were standard. $[a,b]$ is defined as $aba^{-1}b^{-1}$. This makes it a little less trivial.","['group-theory', 'group-presentation']"
843418,Proposed proof of set theoretic result,"I am tasked with proving the following:
$$ (A - B)\cap (B-A) = \varnothing $$ My Attempt: Suppose there exist a $x \in (A - B)\cap (B-A) $ then:
 \begin{align*}
    x \in (A - B)\cap (B-A) &\iff (x \in A \land x \notin B) \land  (x \in B \land x \notin  A) \\
    &\iff  x \in A \land ( x\notin B \land  x  \in B) \land x \notin A \\
    &\iff  x \in A \land ( x\in B \land  x  \notin B) \land x \notin A \\
    &\iff  (x  \in A  \land x \notin A) \land ( x\in B \land  x  \notin B)\\
    &\iff  x \in (A-A) \cap (B-B)
  \end{align*} Since $B-B = \varnothing $ and $A-A = \varnothing$ then $x \in  \varnothing $. An contradiction Is this attempt  correct? Can it be improved in anyway?","['proof-writing', 'elementary-set-theory', 'proof-verification']"
843443,How find this limit $I=\lim_{n\to\infty}n^a\left(\int_{0}^{\pi/2}\sin{(nx)}\cos^n{x}dx\right)=b$,"If the constant $a,b\neq 0$ such 
$$
I=\lim_{n \to \infty}\left[%
n^{a}\int_{0}^{\pi/2}\sin\left(nx\right)\cos^{n}\left(x\right)\,{\rm d}x
\right] = b
$$ find $a,b$ My idea: since
$$\sin{(nx)}=\dfrac{e^{inx}-e^{-inx}}{2i}$$
$$\cos{x}=\dfrac{1}{2}(e^{ix}+e^{-ix})$$
so
$$(e^{ix}+e^{-ix})^n=\sum_{k=0}^{n}\binom{n}{k}e^{i(n-k)x}e^{-ikx}$$
so
$$\sin{(nx)}\cos^n{x}=\dfrac{1}{2i}\cdot\dfrac{1}{2^n}(e^{inx}-e^{-inx})(e^{ix}+e^{-ix})^n=\dfrac{1}{2^{n+1}\cdot i}\sum_{k=0}^{n}\left(\binom{n}{k}(e^{i(2n-2k)x}-e^{-2ikx}\right)$$
then I can't.Thank you","['integration', 'limits']"
843468,Integration by change the variable,"Let, $\int_{-1}^1\sqrt{1+e^x}\operatorname{dx}$ . Write as an integral of a rational function and compute it. Suggest : change the variable in order to eliminate the square root. My work was: Let $u^2=1+e^x$ , so $u=\sqrt{1+e^x}$ . One also have $e^x=u^2-1$ . Then one got $\operatorname{du}=\frac{e^x}{2\sqrt{1+e^x}}\operatorname{dx}$ and so $\operatorname{dx}=\frac{2\sqrt{1+e^x}}{e^x}\operatorname{du}$ . Now substituting: $$\int_{-1}^1\sqrt{1+e^x}\operatorname{dx}=\int_{-1}^1 \sqrt{u^2}\frac{2\sqrt{1+e^x}}{e^x}\operatorname{du}=\int_{-1}^1u\frac{2\sqrt{u^2}}{u^2-1}\operatorname{du}=$$ $$=2\int_{-1}^1\frac{u^2}{u^2-1}\operatorname{du}=2\int_{-1}^11+\frac{1}{u^2-1}\operatorname{du}=$$ $$=2\int_{-1}^11 \operatorname{du}+2\int_{-1}^1\frac{1}{u^2-1}\operatorname{du}$$ Is this thought right? And what is the second integral? Is not the $\arctan$ ! Thanks","['indefinite-integrals', 'calculus', 'integration', 'proof-verification']"
843481,Prove that $A$ is diagonalizable iff $\mbox{tr} A\neq 0$,"Prove that $A$ is diagonalizable if and only if $\mbox{tr} A\neq 0$. $A$ is an $n\times n$ matrix over $\mathbb{C}$, and $\mbox{rk} A=1$. If $p(t)$ is the characteristic polynomial of $A$, I know that $a(n-1)\neq0$ because $\mbox{tr} A = (-1)^{n+1}a(n-1).$
I also know that $\dim\ker(A-0\cdot I)=\dim\ker A=n-\mbox{rk} A=n-1$ (so the geometric multiplicity of $t=0$ as an eigenvalue is $n-1$).
Though I don't know how to continue from here (on both directions). Any suggestions?
Thanks","['trace', 'linear-algebra', 'diagonalization']"
843492,What is a predual of the Banach space of compact operators on $\ell^2$?,I am wondering if the space $K(\ell^2)$ of compact operators on $\ell^2$ can have a predual. Thank you in advance for your help.,"['operator-theory', 'compact-operators', 'functional-analysis']"
843548,Blow-ups in Projective Space,"This is in regards to a question (no solutions or comments thus far :-() I asked earlier in regards to the blow-up of an elliptic curve: Question Let $f(x,y)=y^2-4x^3+ax+b$, where $(x,y)\in\mathbb C^2$. As described here , I need to consider the projective space $\mathbb{CP^2}$ to find the base point. Letting $x=X/Z$ and $y=Y/Z$, the homogeneous polynomial is $F(X,Y,Z)=Z^3\left(\frac{Y^2}{Z^2}-4\frac{X^3}{Z^3}+a\frac{X}{Z}+b\right)$. That is, $$F(X,Y,Z)=Y^2Z-4X^3+aXZ^2+bZ^3.$$Solving $F(X,Y,0)=0$ yields the base point$[0,1,0]$. I want to resolve this base point through blow-ups (I believe that there is a total of 9 blow-ups). I have no idea how to perform blow-ups in projective space. Any help (hints, books, etc.) to get me started will be appreciated. Thanks,
Jay.","['projective-space', 'blowup', 'algebraic-geometry', 'projective-geometry', 'reference-request']"
843553,integration by parts of trig functions,"Can anyone help me with this integral? $\int{x^3 \sin(x^4) dx}$ I set $u=x^3$, and I let $v=-\cos(x^4)$, so that $\frac{dv}{dx}=\sin(x^4)$ I tried using integration by parts, but, whenever I come to the term where I have to integrate  $\frac{du}{dx}(v)$, I get $(\ldots) + \int{3x^2 \cos(x^4) dx}$, which means I'll have to use integration by parts again, and it'll be a never-ending spiral. (I could be wrong.)","['trigonometry', 'calculus', 'integration']"
843576,Finding all the values of $\theta$ for which $\tan(\theta)=\sqrt3$; problem with understanding.,"My textbook has a section where it says a possible way that $\tan(\theta)$ can be thought of is: For acute angles $\theta$, $\tan(\theta)$ is the $y$-coordinate of the point on the terminal side of $\theta$ which lies on the vertical line $x=1$, which is tangent to the Unit Circle. It also provides an illustration which I particularly like as it provides me with some intuition as to where the tangent function is in relation with sine and cosine on the Unit Circle: Bearing this in mind I am then asked to find all the possible angles which satisfy the following equation: $\tan(\theta)=\sqrt3$. I know from memory that $\tan(\theta)=\sqrt3$ for one of the common angles $60^\circ$ or $\frac{\pi}{3}$ radians. All other solutions in quadrant I must be coterminal with this angle so I state simply: $\theta=\frac{\pi}{3}+2\pi k$ where $k$ is an integer. However the answer states another solution is to be found in the third quadrant that is given by $\theta=\frac{4\pi}{3}+2\pi k$ for integers $k$. And as $\tan(\theta)$ is periodic every $\pi$ radians a simplified formula for all solutions is given by: $\theta=\frac{\pi}{3}+\pi k$ for integers $k$. My confusion arises from the above diagram. According to this diagram: It is not possible for $\theta$ to be a quadrant III angle, as the terminal side of $\theta$ will never intersect the vertical line $x=1$, as illustrated by this rudimentary picture below: Furthermore it is not possible for $\tan\theta=\sqrt 3$ in the third quadrant where $\theta=\frac{4\pi}{3}$ as the terminal side of the angle will not be able to intersect $y=\sqrt 3$. What have I misunderstood? 
How is it possible to retain the intuition from this diagram and apply it to angles that are greater than $\frac{\pi}{2}$ radians? Any answers should be written with the knowledge that I am a precalculus student.
Thanks.","['trigonometry', 'algebra-precalculus', 'circles', 'functions']"
843595,How can I calculate the derivative of a Catmull-Rom spline with nonuniform parameterization?,"Allow me to preface this by saying I am not a trained mathematician in any sense, so it's entirely possible I'm missing something rather fundamental. That said, I'm trying to take the derivative of a centripetal or chordal Catmull-Rom spline . Using the uniform equation calculating the tangents for the control points as well as the derivative is very simple. But when you want to make a spline with nonuniform $t$ values, you have to go through this: Arrows indicate that you multiply by the coefficient and add to the adjacent to form the next coefficient up in the pyramid. When you get up to $C$ you have your coordinate on the curve. $P$ values are your control points and $t$ values are calculated with the following: If I'm just plugging values into $t$ then I can get the curve coordinates, but I need the derivative to do some other calculations. I tried to expand the entire thing manually and take the derivative at $t_1$ and $t_2$ , but it was a mess, and I think I did it completely wrong, so I ask here. Looking at the answer here , this person claims to have done it and got these very simple formulas, but the only methodology listed is ""mathematica."" How can I get a usable, general derivative? Is it necessary to choose an alpha value beforehand, or can it be done easily without choosing a parameterization type? Images in this question were borrowed from an answer here .","['recursive-algorithms', 'spline', 'derivatives', 'numerical-methods']"
843618,An interesting series to test convergence,"I have another series in mind, today it is 
$$\sum^\infty_{n=10}\sin\left(\frac{1}{n^3}+\frac{\cos(n)}{n^2}\right)$$
I have tried to investigate the argument:
it is basically $\frac{1+n\cos(n)}{n^3}$ or we could say that $1/n^3$ converges, $1/n^2$ also and $\cos(n)$ have bounded partial sums, so the argument should converge. However, we are not talking about a sum of sines. I tried also dividing the sum into two sums using summation rule for sine:
$\sin(...)=\sin(1/n^3)\cos(\cos(n)/n^2)+\sin(\cos(n)/n^2)\cos(1/n^3)$, however, $\cos(1/n^3)$ does not converge, so it is not bounded and I am afraid that $\sin(\cos(n)/n^2)$ is not bounded either.","['convergence-divergence', 'sequences-and-series']"
843660,"Square root of Chi-square distribution tends to $N(0,1)$","The question requires to show that $\sqrt{2\chi^2_n}-\sqrt{2n}$ converges in distribution to $N(0,1)$ as $n \rightarrow \infty$, which I dont know how to proceed. The question also has a first part asking to show $\frac{\chi^2_n-n}{\sqrt{2n}}$ converges in distribution to $N(0,1)$, and it's straightforward by CLT. I am thinking if there is any connection between the two parts, however still have no idea. Can anyone help me ? Thanks in advance.","['statistics', 'probability-distributions', 'probability-theory']"
