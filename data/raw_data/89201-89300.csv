question_id,title,body,tags
1193575,Number of multisets on $[2m]$ which satisfy certain conditions.,"I am trying to find the number of $n$-element multisets on $[2m]=\left\{1, \ldots, 2m\right\}$ such that $m+1, \ldots, 2m$ appear an even number of times in the $n$-multiset. I have tried several approaches, but the following seems to be the best approach so far... Let $A=\left\{m+1, \ldots, 2m\right\}$ and let $\nu(i)$ be the number of times $i\in [2m]$ appears in the multiset. We're trying to find the number of multisets $\left\{1^{\nu(1)}, 2^{\nu(2)} \ldots, 2m^{\nu(2m)} \right\}$ such that $\sum_{i=1}^{2m}\nu(i)=n$ and $\nu(i)=2j_i$, for some $j_i\in \mathbb{N}$ where $i\in A$. This is equivalent to finding the number of weak compositions of $n$ with $2m$ parts, $\sum_{i=1}^{2m} x_i=n$, such that $x_i=2j_i$ for each $i\in A$. There are two cases: $\textbf{Case 1:}$ $j_i=0$ for all $i\in A$. In this case, $\sum_{i=1}^{2m} x_i=\sum_{i=1}^{m} x_i=n$, which is a weak composition of $n$ into $m$ parts, of which there are $\binom{n+m-1}{m-1}$. $\textbf{Case 1:}$ $j_i=0$ for all $i\in S$, where $S\in \binom{A}{k}$ (i.e., $S\subseteq A$ such that $|S|=k$) and $j_i\geq 1$ for all $i\in A\setminus S$. In this case,
$$\sum_{i=1}^{2m} x_i=\sum_{i=1}^{m} x_i+\sum_{i\in A\setminus S}x_i+\sum_{i\in S}x_i=\sum_{i=1}^{m} x_i+\sum_{i\in A\setminus S}x_i=n$$, which is a weak composition of $n$ with $2m-k$ parts such that $x_i=2j_i$ for all $i\in A\setminus S$. Here is where I hit a brick wall! I don't see a simple way to figure out the number of weak compositions of $n$ with $2m-k$ parts such that $x_i=2j_i$ for all $i\in A\setminus S$. Your help is extremely appreciated!!","['multisets', 'discrete-mathematics', 'number-theory', 'combinatorics']"
1193581,Show that there is a probability such that $P_n$ converges weakly/in distribution as $n \to \infty$.,"Suppose that $P_n$ $n \ge 1$ is a sequence of probabilities concentrated on $[a,b]$. Suppose that one may show for each positive integer $r$ that $\int_{[a,b]}x^rP_n(dx) \to m_r \in R$ as $n \to \infty$. Show that there is a probability $P$ such that $P_n \Rightarrow P$ as $n \to \infty$ and $\int_{[a,b]}x^rP(dx) = m_r$ for each $r \ge 1$. My attempt at a solution: I believe that because we are looking at probabilities on $[a,b]$, we automatically have that the sequence is tight. At which point I would like to apply Prohorov's Theorem, which would implies that the weak closure of the sequence is compact in the weak topology. But I have no idea what to do from here. Edit 1: I have made some progress. So, for a subsequence that converges weakly to $P$, say, $P_{n_k}$, whose existence we are guaranteed by Prohorov's Theorem, that subsequence converges weakly to some $P_k$. Therefore, for all continuous, bounded functions $f$ on $[a,b]$, we have that 
$$\int_{[a,b]} f(x)P_{n_k}(dx) \to \int_{[a,b]}f(x)P_k(dx)$$
I'm thinking that from here we'll want to apply Weierstrass (all continuous, bounded functions can be approximated by polynomials) but I don't quite know how to do it.","['probability-theory', 'probability', 'weak-convergence']"
1193597,Hölder continuity of $\frac1x$,"I have a question. Is the function $f(x)=1/x$ Hölder continuous if $x\in (\varepsilon,+\infty),\ \varepsilon>0$?","['holder-spaces', 'continuity', 'real-analysis', 'functional-analysis']"
1193615,Probability of another 3 integers with same sum and product as the first 3 integers,"Let us suppose $3$ integers are selected at random from a large range, say $$-1000\leq x\leq y\leq z\leq 1000$$ Now, we define the sum and product:
$$\begin{align*}s&=x+y+z \\p&=xyz\end{align*}$$ ($s$ and $p$ will not be equal in most cases, sorry for the confusion) What is the probability that there exists another solution for $(x,y,z)$ that satisfies above 3 equations? (reordering of x, y and z not allowed) My friend gave me this question, and I have no idea where to start. If we limit ourselves to positive integers, is there a unique solution, or not?","['probability-theory', 'probability', 'diophantine-equations', 'algebra-precalculus']"
1193628,"Does every $9 \times 9$ Latin square contain a $3 \times 3$ submatrix containing each symbol in $\{1,2,\ldots,9\}$?","Q : Does every $9 \times 9$ Latin square on the symbol set $\{1,2,\ldots,9\}$ contain a $3 \times 3$ submatrix containing each symbol in $\{1,2,\ldots,9\}$? This one has $1728$ such submatrices, which is as low as I've gotten:
$$
\begin{bmatrix}
6 & 7 & 8 & 9 & 1 & 4 & 2 & 3 & 5 \\
5 & 6 & 1 & 7 & 2 & 8 & 3 & 4 & 9 \\
9 & 1 & 6 & 2 & 4 & 3 & 7 & 5 & 8 \\
4 & 5 & 3 & 6 & 8 & 7 & 1 & 9 & 2 \\
1 & 2 & 4 & 8 & 3 & 5 & 9 & 6 & 7 \\
2 & 3 & 7 & 4 & 9 & 6 & 5 & 8 & 1 \\
8 & 9 & 2 & 3 & 5 & 1 & 6 & 7 & 4 \\
7 & 8 & 5 & 1 & 6 & 9 & 4 & 2 & 3 \\
3 & 4 & 9 & 5 & 7 & 2 & 8 & 1 & 6 \\
\end{bmatrix}$$ It doesn't seem likely that random Latin squares will help much; they average in the thousands of such submatrices.  The one above is the best random Latin square I've found so far (although, I haven't busted a gut doing this; it seems like it won't work anyway). The groups of order $9$ have lots ($C_9$ has $5832$ and $C_3 \times C_3$ has $19440$). This question was motivated by answering this math.SE question which asks if any $9 \times 9$ Latin square can have its rows and columns permuted to give a sudoku square. One way to find an explicit counterexample would be to find a $9 \times 9$ Latin square with no $3 \times 3$ submatrix containing each symbol in $\{1,2,\ldots,9\}$.  But this attempt didn't work since I couldn't find one.  Hence my question.","['discrete-mathematics', 'latin-square', 'combinatorics']"
1193654,Evaluating $\sum\limits_{n=1}^{\infty} \left(\frac{1}{4 n-3}+\frac{1}{4 n-1}-\frac{1}{2 n}\right)$,$$\sum\limits_{n=1}^{\infty} \left(\frac{1}{4 n-3}+\frac{1}{4 n-1}-\frac{1}{2 n}\right) = \;?$$ I have been trying to see if it can be written as sum of two telescope terms but it looks tricky. Any help ?,['sequences-and-series']
1193687,How to evaluate $\int \sqrt{\sin^{-1}(\sqrt{\phi})} d\phi $?,"How do I go about solving the below integral? $$I_1=\int \sqrt{\sin^{-1}(\sqrt{\phi})} d\phi $$ Background: I came across the simpler version of this, which required me to evaluate: $$\int\sin^{-1}(\sqrt{\phi})d\phi$$ I got the solution for this: $$\big[\sin^{-1}(\sqrt{\phi})\big(\phi-\frac{1}{2}\big) + \frac{\sqrt{\phi(1-\phi)}}{2}\big] + C$$ But I still don't see this helping me solve the original question (i.e. $I_1$ ). Note: Wolfram Alpha gives this solution, but I want to know how to arrive at it. Edit: I did a substitution $\phi = \sin^2(\psi)$ to get: $$\int \sqrt{\psi}\sin(2\psi)d\psi$$ Now I'm stuck...","['trigonometry', 'calculus', 'indefinite-integrals', 'integration']"
1193705,"Compute the covariance of $\xi$ and $\min \{\xi,2\}$, where $\xi$ is exponentially distributed","Let $\xi$ be a random variable exponentially distributed and let $\xi_1=\min \{\xi,2\}$. Calculate $Cov(\xi,\xi_1)$. I know the problem is easy but I just need somebody to check my work. Here's my solution. $$
E(\xi\cdot\xi_1)=\int_0^\infty x\cdot\min(x,2)\cdot\lambda\exp(-\lambda x) \,dx=
\int_0^2x^2\lambda e^{-\lambda x} \,dx+2\int_2^\infty x\lambda e^{-\lambda x} \,dx=\int_0^{2\lambda} \lambda^{-2} t^2e^{-t}\,dt +\frac{2}{\lambda}\int_{2\lambda}^{\infty}te^{-t}\,dt=\frac{-e^{-t}(t^2+2t+2)}{\lambda^2}|_{t=0}^{2\lambda}+\frac{-2(1+t)e^{-t}}{\lambda}|_{t=2\lambda}^{\infty}=\frac{2}{\lambda^2}(1-e^{-2\lambda}(\lambda+1)).
$$
Next
$$
E(\xi_1)=\int_0^{\infty}\min(x,2)\lambda e^{-\lambda x}\,dx=\int_0^2 x\lambda e^{-\lambda x}\,dx+2\int_2^\infty\lambda e^{-\lambda x}\,dx=\lambda^{-1} \int_0^{2 \lambda}te^{-t}\,dt+\int_{2\lambda}^{\infty}2e^{-t}\,dt=\frac{-e^{-t}(1+t)}{\lambda}|_{t=0}^{2\lambda}-2e^{-t}|_{t=2\lambda}^{\infty}=\frac{1-e^{-2\lambda}(1+2\lambda)}{\lambda}+2e^{-2\lambda}=\frac{1-e^{-2\lambda}}{\lambda}.
$$
Hence
$$
Cov(\xi,\xi_1)=E(\xi\cdot\xi_1)-E\xi\cdot E\xi_1=\frac{2}{\lambda^2}(1-e^{-2\lambda}(\lambda+1))-\frac{1-e^{-2\lambda}}{\lambda^2}=\frac{1-e^{-2\lambda}-2\lambda e^{-2\lambda}}{\lambda^2}
$$
Could you please check whether it is correct?","['probability', 'probability-distributions']"
1193722,Proof of relation between maximum element and induced $p$-norm of a matrix,"If true, prove the identity:
$$
||A|| \ge \max\limits_{i,j}|a_{ij}|
$$ $||.||$ is any induced/operator norm. Edit: The identity is true only for operator norm induced by $p$-norm for vectors. I found this property in a presentation of singular values and matrix norms. This property could be useful for me in my work but I am not able to prove it.","['normed-spaces', 'vectors', 'matrices']"
1193723,Why do we define curves on manifolds via the objects $\phi\circ\gamma$?,"Consider the following definition: ($M$ denotes a manifold structure, $U$ are subsets of the manifold and $\phi$ the transition functions) Def :   A smooth curve in $M$ is a map $\gamma: I \rightarrow M,$ where $I \subset \mathbb{R}$ is an open interval, such that for any chart $(U,\phi)$, the map $\phi \circ \gamma : I \rightarrow \mathbb{R}^n$ is smooth. My first question is, why do we define a smooth curve in this way? In particular, why is the map $\phi \circ \gamma$ a good object to consider? The only thing that comes to mind is that now we have a function defined from $\mathbb{R} \rightarrow \mathbb{R}^n$ so differentiation is well defined and thus one may introduce the concept of a tangent vector (as below). Now let $f: M \rightarrow \mathbb{R}$ be a smooth function on $M$ and $\gamma: I \rightarrow M$, smooth curve as before. Then $f \circ \gamma : I \rightarrow \mathbb{R}$ is smooth. Hence we take a derivative to find the rate of change of $f$ along the curve $\gamma$: $$\frac{d}{dt}f(\gamma(t)) = [(f \circ \phi^{-1}) \circ (\phi \circ \gamma)]'(t) = \sum_{i=1}^n \left(\frac{\partial (f \circ \phi^{-1})}{\partial x^i}\right)_{\phi(\gamma(t))} \frac{d}{dt} x^i(\gamma(t))$$ My next question is to simply understand how this equation comes about. I can see it is some application of the chain rule but I am struggling with the precise details of the equation, mostly in how the final equality comes about and the subscript on the  $\partial (f \circ \phi^{-1})/\partial x^i$  term.  Many thanks!","['curves', 'manifolds', 'differential-geometry', 'linear-algebra', 'derivatives']"
1193736,Suppose that $f$ is a differentiable function such that $f(g(x)) = x$ and $f^\prime(x) = 1+ [f(x)]^2$. Show that $g^\prime(x) = \frac{1}{1+x^2}$.,"Suppose that $f$ is a differentiable function such that $f(g(x)) = x$ and $f^\prime(x) = 1 + [f(x)]^2$. Show that $g^\prime(x) = \dfrac{1}{1+x^2}$. $$
f(g(x)) = x \implies f = g^{[-1]}
$$ I have been told: $$
f^{[-1]\prime}(f^\prime(c)) = \dfrac{1}{f^\prime(c)}
$$ However, I have no intuition of this being true, thus I have a weak understanding of it. I feel as though it may somehow be applicable when considering $f$ is the inverse of $g$ and have been defined as they have. I'm not familiar with the formal name of this truth, so knowing that would be a start on being able to find material from which to study it. Edit: The problem only defines $f^\prime(x)$. It doesn't define $f^\prime(g(x))$. The formula which was derived is relative to functions, their inverses, and their respective derivatives. It is not necessarily so that $f′(x) = f′(g(x))$. So, how could it be shown that $g'(x) = \dfrac 1 {f'(g(x))} = \dfrac 1 {1+f(g(x))^2} = \dfrac 1 {1+x^2}$ when we don't know what $f^\prime(g(x))$ or $g^\prime(x)$ is?","['derivatives', 'calculus', 'functions']"
1193740,Centralizers of reflections in parabolic subgroups of Coxeter groups,"Let us consider a (not necessarily finite) Coxeter group $W$ generated by a finite set of involutions $S=\{s_1,...,s_n\}$ subject (as usual) to the relations $(s_is_j)^{m_{i,j}}$ with $m_{i,j}=m_{j,i}$ and  $m_{i,j}=1$ if and only if $i=j$ (if necessary you may also assume that $m_{i,j}<\infty$ for all $i,j$). Let $P\leq W$ be a subgroup generated by all but one of the $s_i$, say wlog $P=\langle s_1,...,s_{n-1}\rangle$. I am interested in the centralizer of $s_n$ in $P$. In particular I would like to know if $C_P(s_n)=C_W(s_n) \cap P=\langle s_i~|~ 1\leq i\leq n-1, m_{i,n}=2\rangle=:Z$ always holds. Obviously this is true if $n=2$ and I believe (though I have not written it down rigorously) I can prove it for Coxeter groups of type $A_n$ by using the standard isomorphism to $S_n$. On the other hand the centralizer of $s_n$ in $W$ is not necessarily a standard parabolic subgroup (look at the dihedral group of order $8$ for example). There are some results on centralizers of reflections in Coxeter groups and on normalizers/centralizers of parabolic subgroups (which is the same in this special case) to be found in the literature but most deal with the centralizer in $W$. In principal it should be possible to obtain the centralizer in $P$ from these results by simply taking the intersection but the results I found so far are not explicit/ simple enough for this to be a feasible solution. Edit: Some thoughts so far: I can show that elements of $C_P(s_n)$ of length $1$ or $2$ already lie in $Z$ (the case $1$ being trivial) and that elements of $C_P(s_n)$ of length $3$ where all three occurring simple reflections are pairwise distinct already belong to $Z$. On the other hand look at $s_1s_2s_1 \in C_P(s_n)$ which centralizes $s_n$ if and only if $s_2$ centralizes $s_1s_ns_1$. I don't see any reason why this should not be the case so I tried constructing a counterexample consisting of $s_1,s_2$ and $s_3$ such that $s_1,s_2$ do not commute and $s_1s_3$ do not commute but $s_2$ and $s_1s_3s_1$ do. Any ideas on how to do that?","['group-theory', 'coxeter-groups', 'reference-request']"
1193746,Calculating $\mathrm{Var} (Z|Z|)$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Suppose $Z\sim N(0,1). $ How can I calculate $\mathrm{Var} (Z|Z|)$? I know $\mathrm{Var} (Z|Z|)= \mathrm{E}(Z^4)-\mathrm{E}^2(Z|Z|)$",['statistics']
1193763,Eigenvalues of product matrix,"I have two matrices, both positive definite, real symmetric and one is diagonal. What can I say about lower and upper bound of the eigenvalues of the product matrix in terms the of lower and upper bounds on eigenvalues of those two matrices.",['linear-algebra']
1193772,Why the mean value of a Gaussian process is usually set to zero?,"In most textbooks (e.g. Rasmussen's book on Gaussian Processes for Machine Learning) the mean value of a gaussian process is set to zero. Of course, this does not mean that all the values are expected to be zero since we are looking for the Maximum a Posteriori estimate of these variables, which do not have any more a zero mean. Is there a mathematically robust proof or at least an explanation based on mathematics that the assumption of the zero mean value is not too prohibitive for the a posteriori estimate? To make things a bit more clear, assume that we have the following model where the noise $e$ is uncorrelated with $f(x)$: $y= f(x) +e $, $f(x) \sim \mathcal{N} (m, K)$, $e \sim \mathcal{N} (0, \sigma^2)$. Then the a posteriori (which is actually the MAP estimate) is given by $\mathbb{E} (f | y) = m + K (\sigma^2 I + K)^{-1} (y-m)$ The way I see it, by setting the mean equal to zero we usually reduce the number of hyperparameters that have to be estimated, because most of the times the mean is also unknown, so it has to be parametrized by some hyperparameters and then these hyperparameters have to be estimated by a non-convex optimization routine, thus increasing the computational burden. However, this does not explain mathematically if the assumption that the mean is zero does not restrict too much the a posteriori estimate. Any help would be appreciated!","['statistics', 'random-variables', 'statistical-inference']"
1193786,Computing $\sum_{i=2}^{n-1} 1$ and $\sum_{i=2}^{n-1} i$.,"Could someone explain how I calculate these summations? I'm using upper - lower + 1. a) $\displaystyle\sum_{i=2}^{n-1} 1$ b) $\displaystyle\sum_{i=2}^{n-1} i$ So for (a) I have: 
$$
(n-1) -2 +1)1 = -1n - 1.
$$ For (b) I have:
$$
((n-1) -2 +1)2 = -2n -1.
$$ Are these calculations correct?","['summation', 'solution-verification', 'algebra-precalculus']"
1193794,Why did it take mathematicians so long to discover non-Euclidean geometry?,"Why did it take mathematicians so long to realise that Euclid's fifth postulate is independent of the other 4? Why didn't people like Lagrange notice that a sphere is a model for a non-Euclidean geometry (first 4 axioms satisfied, the fifth not satisfied)? They had ships and cartography long before Gauss and Bolyai were born. Am I misunderstanding something?","['math-history', 'geometry']"
1193797,The Idea behind the Second Partial Derivative Test,"I'm currently learning about local extrema in serveral variables and have come across the second derivative test for classifying critical points of multivariable functions. I have read and understood the test (see link below), however I don't understand the idea behind it. Why is the critical point of a function a minimum if the eigenvalues of the Hessian matrix are all positive? I understand the idea behind the single variable case, however I am confused about the role of eigenvalues in the case of several variables. http://en.wikipedia.org/wiki/Second_partial_derivative_test Any insight into this would be much appreciated. Thanks.","['partial-derivative', 'eigenvalues-eigenvectors', 'multivariable-calculus']"
1193824,Minimize : $\sqrt{(1+{1\over a})(1+{1\over b})}$ subject to $a+b=\lambda$.,"Given positive real variables $a$ and $b$, find the minimum of  $$f(a,b)=\sqrt{\left(1+{1\over a}\right)\left(1+{1\over b}\right)}$$  subject to  $a+b=\lambda$ where $\lambda$ is a constant . [ISI Sample Papers] Method $1$ : Substitute $b=\lambda - a$ and then compute ${\partial \over \partial a }f(a,b)$. But, the calculations get a bit messy. Method $2$ : Actually this is what I want to know. Is there an easier approach using some inequalities like the AM-GM inequality ? I tried this but was not able to got lost in between. Method $3$ : Lagrange multipliers. I have not tried this and kept it as a last option. What is the best way to solve this problem ?","['problem-solving', 'multivariable-calculus', 'optimization', 'lagrange-multiplier', 'inequality']"
1193847,About the uniqueness of a quadric determined by sufficient points,"What is the condition on a set of 14 points for them to uniquely determine a quadric in $\mathbb{P}^4$? Is being in linear general position enough to guarantee uniqueness? If not, what is the alternative condition? In what precise sense of ""general position"" must the points be in general position? What if I know that the quadric is non-singular? If I pick 14 points from the intersection of two non-singular quadrics in $\mathbb{P}^4$, can they be in general position? Thank you.","['algebraic-geometry', 'quadrics']"
1193852,"Existence of continuous bijective function $f:[0,1] \times [0,1] \to [0,1] $ ? Continuous and only injective and continuous and olny surjective?","Does there exist any continuous bijective function $f:[0,1] \times [0,1] \to [0,1] $ , where $[0,1]$ is equipped with usual Euclidean metric of $\mathbb R$ and $[0,1] \times [0,1]$ is equipped with the usual Euclidean metric of $\mathbb R^2$ ? What if we require the continuous  mapping to be only injective or only surjective ?","['analysis', 'metric-spaces', 'continuity', 'functions']"
1193883,Solving system of delay differential equations,"Are there any numerical methods for solving systems of delay differential equations with time-dependent delays?
For example, I have a system: $$\frac{dP_1}{dt}  = f_1(t) P_2(t-\tau(t)) P_3(t)$$ $$\frac{dP_2}{dt}  = f_2(t) P_3(t-\tau(t)) P_1(t)$$ $$\frac{dP_3}{dt}  = f_3(t) P_1(t-\tau(t)) P_2(t)$$ I thought about applying method of steps together with Runge-Kutta method, but it leads to loss of information, because Runge-Kutta method requires values of RHS at $(x+1/2 h)$, where $h$ is a step. So, I'm interested if any other methods except this one exist for solving such systems.
And, if they exist, could you please tell me where I can read about them, because I didn't find useful information.","['reference-request', 'numerical-methods', 'ordinary-differential-equations', 'delay-differential-equations']"
1193904,"Evaluating $\sum_{0\leq k,l \leq n}\binom{n}{k}\binom{k}{l}l(k-l)(n-k)$ algebraically","I'm having problems with the following sum: $$\sum_{0\leq k,l \leq n}\binom{n}{k}\binom{k}{l}l(k-l)(n-k)$$ It's quite easy to think about it combinatorically: We have $n$ balls, we're coloring $k$ of them, then $l$ of these colored balls get sprinkled with gold. Then we're putting a crown on one colored ball, one colored, sprinkled with gold ball and one uncolored ball. It's all kind of funny but it allowed me to come up with, as it turns out, correct evaluation of this sum - first we're crowning 3 balls $\binom{n}{3}$, then we're chosing for each ""crowned"" ball whether it's colored, colored and sprinkled with gold or uncolored ($3!$) and then for the remaining $n-3$ balls we're either coloring them, coloring them and sprinkling with gold or do nothing with them ($3^{n-3}$). So we get: $\sum_{0\leq k,l \leq n}\binom{n}{k}\binom{k}{l}l(k-l)(n-k)=\binom{n}{3}3!3^{n-3}=n(n-1)(n-2)3^{n-3}$ But I have no idea how to get the similair result using only algebraic methods. Any hints?","['summation', 'binomial-coefficients', 'discrete-mathematics']"
1193970,Monotone class theorem vs Dynkin $\pi-\lambda$ theorem,"Monotone class theorem : Let $\mathcal C$ be a class of subset closed under finite
  intersections and containing $\Omega$ (that is, $\mathcal C$ is a
  $\pi$-system). Let $\mathcal B$ be the smallest class containing
  $\mathcal C$ which is closed under increasing limits and by difference
  (that is, $\mathcal B$ is the smallest $\lambda$ system containing $\mathcal C$). Then $\mathcal B =
 \sigma(\mathcal C)$ Dynkin $\pi-\lambda$ theorem If $P$ is a $\pi$ system and $D$ is a $\lambda$ system with $P
 \subseteq D$, then $\sigma(P) \subseteq D$ (Also, I believe that it can concluded that $D$ is a $\sigma$ algebra) It seems to me that they are basically the same thing. Dynking statement is slightly more general but more or less the same. Is it it true or am I misunderstanding something?","['probability-theory', 'probability', 'monotone-class-theorem', 'measure-theory']"
1193973,What is the relation between dx in elementary calculus and dx in differential geometry?,"I've recently started studying differential geometry and was really hoping that in doing so I'd finally have an answer to something that's been bugging me since I first learnt calculus - what is $dx$?! As far as I understand, in differential geometry $dx^{i}$ is a linear functional that maps vectors in a tangent space $T_{p}M$ at a point $p\in M$ on a manifold $M$ to the set of real numbers $\mathbb{R}$, i.e. $$dx^{i} :T_{p}M\rightarrow\mathbb{R}$$ In this sense the differential form $dx^{i}$ maps a vector $v\in T_{p}M$ to its $i^{th}$ coordinate with respect to the coordinate basis $\frac{\partial}{\partial x^{i}}$, i.e. $dx^{i}(v)=v^{i}$. In elementary calculus I was always told when I asked the question ""what is $dx$?"" , that it is an infinitesimal change in the x-coordinate . This has never rested easy with me as e.g. if we have the formula $$ df=\lim_{\Delta x\rightarrow 0}\Delta f = \lim_{\Delta x\rightarrow 0}f'(x)\Delta x $$ then due to the properties of limits this can be expressed as $$\lim_{\Delta x\rightarrow 0}f'(x)\lim_{\Delta x\rightarrow 0}\Delta x$$ and clearly $\lim_{\Delta x\rightarrow 0}\Delta x =0$ which seems inconsistent. So my main question is: what actually is $dx$ and is there any intuitive (perhaps geometric) explanation as to how it relates to an infinitesimal line element?","['differential-geometry', 'calculus', 'differential-forms']"
1193999,$TS^1$ is Diffeomorphic to $S^1\times \mathbf R$.,"I know this is a very basic question. But I am unable to get every detail right. I need to show that $TS^1$ is diffeomorphic to $S^1\times \mathbf R$. (I am using the concept of derivations to define the tangent spaces.) I asked this of my friends and this is what, in essence, I have learned from them: Define $f:TS^1\to S^1\times \mathbf R$ as 
$$f
\left(
p;\ \lambda\left(p_2
\left.\frac{\partial}{\partial x_1}\right|_{p}-p_1\left.\frac{\partial}{\partial x_2}\right|_p
\right)
\right)
=
(p,\ \lambda)
$$
for all $p=(p_1,p_2)\in S^1$ and all $\lambda\in \mathbf R$, and show that this is a diffeomorphism. My problem with this is that: $\left(p_2
\left.\frac{\partial}{\partial x_1}\right|_{p}-p_1\left.\frac{\partial}{\partial x_2}\right|_p
\right)$ is not really a member of $T_pS_1$. It lies in $di_p(T_pS^1)\subseteq T_p\mathbf R^2$, where $i:S^1\to \mathbf R^2$ is the inclusion map. (Reason: The manifold structure of $S_1$ is governed by the fact that $i:S^1\to \mathbf R^2$ is a smooth embedding, and thus, a tangent vector $X_p\in T_p\mathbf R^2$ is in $di_p(T_pS^1)$ if an only if $X_p\xi=0$ for all $\xi\in \mathcal C^\infty(\mathbf R^2)$ with $\xi|S^1\equiv 0$.) Keeping this in mind, I attempted the following: Define $F:T\mathbf R^2\to \mathbf R^2\times \mathbf R^2$ as 
$$
F\left(p,\ a_1
\left.
\frac{\partial}{\partial x_1}
\right|_p+a_2\left.\frac{\partial}{\partial x_2}\right|_p\right)
=
(p,\ a_1, a_2)
$$
for all $p\in \mathbf R^2$ and $a_1, a_2\in \mathbf R$. We note that $F$ is a diffeomorphism. Now define $G:\mathbf R^2\times \mathbf R^2\to \mathbf R^2\times \mathbf R$
as
$G(p, a_1, a_2)=(p, \sqrt{a_1^2+a_2^2})$. We note that $G$ is smooth. Finally, since $i:S^1\to T\mathbf R^2$ is smooth (it is more than that), we have $di:TS^1\to T\mathbf R^2$ is also smooth. Now $G\circ F\circ di: TS^1\to S^1\times \mathbf R$ is thus a smooth map, since composition of smooth maps is smooth. But I am unable to show that this map is the required diffeomorphism. Can somebody help?","['differential-geometry', 'smooth-manifolds']"
1194005,Derivative of $f(x) = (x^2 +1)^3 (2x+5)^2$,"I have function
$$f(x) = (x^2 +1)^3 (2x+5)^2$$ I need to find the derivative. I believe that I need to use the product rule and chain rule. Here's what I did. $$f'(x) = (2x+5)^2[3(x^2+1)^2(2x)] + (x^2+1)^3[2(2x+5)2]
\\ = (2x+5)^2(6x(x^2+1)^2)+4(2x+5)(x^2+1)^3
\\ = 6x(2x+5)^2(x^2+1)^2+4(2x+5)(x^2+1)^3$$ That is what I have. But the problem is, the answer book says that the answer is, $$2(x^2+1)^2(2x+5)(8x^2+15x+2)$$ Since the answer book has been wrong few times, so I checked the answer with a calculator.
The calculator showed the same answer. Then I used another calculator (which showed some steps), showed my answer. The calculator showed, Which answer is correct?? Or are they just equivalent answers??
If I did wrong, what was the problem??
Can it be factorized? How? Thank you","['calculus', 'algebra-precalculus', 'derivatives']"
1194012,"Is $\prod \limits_{i = 1}^{n} [0,1] \subseteq \mathbb R^n$ homeomorphic to the closed unit ball?","Is $\prod \limits_{i = 1}^{n} [0,1] \subseteq \mathbb R^n$ homeomorphic to $\bar B(\theta , 1)$ , the closed ball centered at origin with radius $1$? Can someone please give some reference links to study elementary techniques to deal with homeomorphism and to show two given spaces homeomorphic ?","['analysis', 'metric-spaces', 'general-topology']"
1194018,Is there an intuitve motivation for the wedge product in differential geometry?,"I've recently started studying differential forms and have been looking at differential forms. I'm struggling to understand the motivation for introducing the notion of the wedge product. Does it simply arise when generalising the notion of a "" signed area/volume "" in higher dimensional spaces, or is there a deeper reasoning behind it? If it is just a generalisation of a "" signed area/volume "" in higher dimensional spaces then my understanding is that the ""area"" spanned by two tangent vectors $X,Y$ is given by the wedge product between their associated differential forms. Thus, in one-dimension, if we have a one-form $\omega$ expressed in a local coordinate basis as $\omega =f_{i}(x)dx^{i}$, then $$\omega\wedge\omega = f_{i}(x)f_{j}(x)dx^{i}\wedge dx^{j}$$ and so from this, if X=Y, then the ""area"" spanned by them should be zero and so, $$\omega\wedge\omega (X,X)=0=f_{i}(x)f_{j}(x)dx^{i}(X)\wedge dx^{j}(X)\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\\ \quad\;\;=\frac{1}{2}\left[f_{i}(x)f_{j}(x)dx^{i}(X)\wedge dx^{j}(X)+f_{j}(x)f_{i}(x)dx^{j}(X)\wedge dx^{i}(X)\right]$$ and this implies that $$dx^{i}(X)\wedge dx^{j}(X)=-dx^{j}(X)\wedge dx^{i}(X)$$
I'm unsure whether my understanding here is correct or not?","['differential-geometry', 'differential-forms', 'exterior-algebra']"
1194028,Compass and straightedge contruction of an equilateral triangle inscribed in a given circle with unknown center,"I haven't found a proper solution for this problem, found in Hartshorne's ""Geometry: Euclid and Beyond"": (4.3) Given a circle, but not given its center, construct an inscribed equilateral triangle in as few steps as possible. I managed to construct it in $9$ steps (use of compass or straightedge) but I can't get any lower. Finding circle center takes $5$ of those $9$ uses, and then I need $1$ more to get vertices and $3$ for constructing the triangle.","['geometric-construction', 'geometry']"
1194031,The series $\sum\limits_{n\ge1}n^{-z}$ converges locally normally,"Show that the series $\sum\limits_{n\ge1}n^{-z}$ converges locally normally on the half plane $\{z:\text{Re}(z)>1\}$ $\displaystyle n^{-z}=\frac{1}{n^z}\le\frac{1}{|n^z|}=\frac{1}{n^{\text{Re}(z)}}\le\frac{1}{n^{1+\epsilon}}$ (If $z=x+iy$ with $x>1$ then $\exists\epsilon>0$ s.t. $x>1+\epsilon$) So it converges absolutely and also normally, because then there is always an $r$-neighbourhood for every $z_0\in\{z:\text{Re}(z)>1\}$, such that; $\displaystyle\sum\limits_{n\ge1}||n^{-z}||_{\{z:|z-z_0|\le r\}}=\sum\limits_{n\ge1}\sup\limits_{z\in\{z:|z-z_0|\le r\}}|n^{-z}|=\sum\limits_{n\ge1}\frac{1}{n^{\inf\{\text{Re}(z):z\in\{z:|z-z_0|\le r\}\}}}$ but how can I show formally that $\exists\delta>0:$ $\displaystyle\frac{1}{n^{\inf\{\text{Re}(z):z\in\{z:|z-z_0|\le r\}\}}}\le\frac{1}{n^{1+\delta}}$ Is it enough to say $\{z:|z-z_0|\le r\}\subsetneq\{z:\text{Re}(z)>1\}$ ?","['complex-analysis', 'complex-numbers']"
1194033,Why in Teichmüller-Tukey lemma finiteness is essential?,First we will state a Teichmüller-Tukey Lemma: Let $A$ be a set and $\phi$ be a property defined on all finite subset of $A$. Assume that $B$ is a subset of $A$ such that each finite subset of $B$ have property $\phi$. Then $B$ can be extended to a maximal subset $M$ of $A$ such that each finite subset of $M$ has a property $\phi$. My question is :- In the statement there is condition of finite . In case we have countable why we could not show that its equivalent with the axiom of choice.,"['elementary-set-theory', 'axiom-of-choice']"
1194064,find the limit of this problem,Prove that $\int\limits_1^x e^t/t dt \sim (e^x)/x$ as $x \longrightarrow \infty$. any ideas of how to approach this problem. I can not seem to evaluate the integral either so i am real stuck in this problem,"['calculus', 'limits']"
1194072,Where do summation formulas come from?,"It's a classic problem in an introductory proof course to prove that $\sum_{ i \mathop =1}^ni = \frac{n(n+1)}{2}$ by induction. The problem with induction is that you can't prove what the sum is unless you already have an idea of what it should be. I would like to know what the process is for getting the idea. Wikipedia has plenty of summation formulas listed, and there are surely lots more, but I think I should be able to simplify summations without referring to a table. I don't suppose there's a universal technique for deriving all of them, but it would be good to know at least a few things to try. This question was motivated by an answer involving summation, and while I have no doubt that it's true, I wouldn't know how to get the answer to the particular summation without being told beforehand.","['summation', 'sequences-and-series', 'combinatorics']"
1194085,How does one bound computational error for a finite difference approximation of the second derivative?,"I'm trying to wrap my head around ways to minimize total computational error (defined as a sum of the bounds on the truncation and rounding errors) by taking a differentiable function $f : \mathbb{R} \rightarrow \mathbb{R}$ and a finite difference approximation of its second derivative $$
f''(x) = \frac{f(x + h) - 2f(x) + f(x-h)}{h^2}
$$ I know that, by Taylor's Theorem $$
f(x + h) = f(x) + f'(x)h + f''(x)\frac{h^2}{2} + f'''(\theta)\frac{h^3}{6}
$$ for some $\theta \in [x, x + h]$. How would you determine the value of $h$ for which a bound of the total computational error is minimized?","['error-propagation', 'numerical-methods', 'derivatives']"
1194115,When does function composition commute? [duplicate],"This question already has answers here : When functions commute under composition (3 answers) Closed 9 years ago . I've read that function composition ""generally does not commute."" Not counting compositions involving the identity function, and compositions of a function and its inverse, are there examples of functions on the reals (for example) $f, g$ where $fg = gf$ outside of these cases?",['functions']
1194139,Is there another way to solve this integral?,"My way to solve this integral. I wonder is there another way to solve it as it's very long for me. $$\int_{0}^{\pi}\frac{1-\sin (x)}{\sin (x)+1}dx$$ Let $$u=\tan (\frac{x}{2})$$
$$du=\frac{1}{2}\sec ^2(\frac{x}{2})dx $$ By Weierstrass Substitution $$\sin (x)=\frac{2u}{u^2+1}$$ $$\cos (x)=\frac{1-u^2}{u^2+1}$$ $$dx=\frac{2du}{u^2+1}$$ $$=\int_{0}^{\infty }\frac{2(1-\frac{2u}{u^2+1})}{(u^2+1)(\frac{2u}{u^2+1}+1)}du$$ $$=\int_{0}^{\infty }\frac{2(u-1)^2}{u^4+2u^3+2u^2+2u+1}du $$ $$=2\int_{0}^{\infty }\frac{(u-1)^2}{u^4+2u^3+2u^2+2u+1}du  $$ $$=2\int_{0}^{\infty }\frac{(u-1)^2}{(u+1)^2(u^2+1)}du $$ $$=2\int_{0}^{\infty }(\frac{2}{(u+1)^2}-\frac{1}{u^2+1})du $$ $$=-2\int_{0}^{\infty  }\frac{1}{u^2+1}du+4\int_{0}^{\infty}\frac{1}{(u+1)^2}du $$ $$\lim_{b\rightarrow \infty }\left | (-2\tan^{-1}(u)) \right |_{0}^{b}+4\int_{0}^{\infty}\frac{1}{(u+1)^2}du$$ $$=(\lim_{b\rightarrow \infty}-2\tan^{-1}(b))+4\int_{0}^{\infty}\frac{1}{(u+1)^2}du$$ $$=-\pi+4\int_{0}^{\infty}\frac{1}{(u+1)^2}du$$ Let $$s=u+1$$ $$ds=du$$ $$=-\pi+4\int_{1}^{\infty}\frac{1}{s^2}ds$$ $$=-\pi+\lim_{b\rightarrow \infty}\left | (-\frac{4}{s}) \right |_{1}^{b}$$ $$=-\pi+(\lim_{b\rightarrow \infty} -\frac{4}{b}) +4$$ $$=4-\pi$$ $$\approx 0.85841$$","['calculus', 'definite-integrals', 'integration']"
1194153,When does convergence of function imply convergence of its derivative?,"Let $F_n$ be a sequence of differentiable real valued functions. Suppose that $$\lim_{n \to \infty} F_n(x) = F(x)$$ and that $F(x)$ is differentiable. Under which conditions does that imply $$\lim_{n \to \infty} F'_n(x) = F'(x)$$ ? Do I need some regularity, or maybe that the $F_n$ converges uniformly?","['calculus', 'real-analysis', 'sequences-and-series', 'uniform-convergence', 'convergence-divergence']"
1194239,Maximal abelian subgroup of general linear groups,"Thanks for any help or comments. Is it possible to recognize all maximal abelian subgroups of general linear group on finite field $F$ of order $q$,  $GL_n(F)$.
By maximal abelian I mean if $A$ is maximal abelian and $B$ is abelian such that $A\subseteq B$, then $B=A$.","['group-theory', 'finite-groups']"
1194272,Approximation of $\sqrt{ x + y } - \sqrt{ x - y }$,"I've been struggling to try and find a way to approximate the function: $\sqrt{ x + y } - \sqrt{ x - y }$ I should mention that $y$ is positive and a small number, so that $0<y<<1$. What I'm hoping for is to approximate this in such a way that, we have roughly: $\sqrt{ x + y } - \sqrt{ x - y } \approx (1-y)\sqrt{ x + y }$ There may be some numerical factor in front of this. This could very well be absurd, I'm wondering if this can be done at all. It is crucial that I have this factor $\sqrt{ x + y }$ in the approximation. I've thought about defining a function $\ f(r)=\sqrt{r}$. Then I could write: $f(x+y)-f(x-y)$ = $f(x+y)-f(x+y-2y)$ i've tried taking a Taylor expansion but my result isn't working out. Does anyone have some advice?","['approximation', 'functions']"
1194295,To show that $A_4$ is solvable,"I need to show that $A_4$ is solvable.
From what i know the definition of solvable expects to give some chain of subgroups such that each subgroup in the chain is normal to the one in which it is contained and also the quotient group is abelian. So I tried constructing such a chain but I was not able to","['representation-theory', 'abstract-algebra', 'group-theory', 'finite-groups']"
1194302,Find $\lim \sup A_n$ and $\lim \inf A_n$?,"Question: Let $\Omega = R^2. A_n$ is the interior of a circle with center at $\left\{\frac{(-1)^n}{n},0 \right\} $ at radius 1. 
Find $\lim \sup A_n$ and $\lim \inf A_n$ ? My answer is the following;
Let $\Omega = R^2$ As we know, $\lim\sup A_n =\{W: W\in A_n \ \mathrm{for} \ \mathrm{infinite} \ \mathrm{ n}\}$ $\lim\inf A_n =\{W: W\in A_n \ \mathrm{for} \ \mathrm{finite} \ \mathrm{ n}\}$ In this question, there exists a circle with center  at $\left\{\frac{(-1)^n}{n},0 \right\} $ at radius 1. $X^2 + Y^2 =1 \rightarrow x^2 + y^2 =1 \rightarrow (\cos\theta)^2+(\sin\theta)^2 =1 $ let $n=1$ , there exists a circle with $(-1,0)$ at radius 1. $(x-h)^2 +(y-k)^2  =r^2$ $h=1, k=0, r=1$ $(x+1)^2 +(y-0)^2=1^2$ let n=2, there exists a circle with $(1/2, 0)$ at radius 1 $(x-1/2)^2 +(y-0)^2=1^2$ $n=3 \rightarrow (-1/2, 0)$ radius=1 $n=4 \rightarrow (1/4, 0)$ and so on... $\lim\inf A_n =\{(x,y): x^2+y^2\lt 1\}$ $\lim\sup A_n =\{(x,y): x^2+y^2\le 1\} - \{(0,1), (0,-1)\}$ what i dont understand is a point in  the last gray box. How do we obtain these limsup and liminf? please clearly explain the way to get these limsup and liminf thank you for helping.","['measure-theory', 'real-analysis', 'general-topology', 'analysis', 'limsup-and-liminf']"
1194304,system of equations with $n$ equations and $2^k n$ unknowns,"I have a system of equations with infinitely many solutions. I would like to find a ""nice"" way to write down an explicit solution. Here, $n,k\geq 1$ are integers, we have $x_1,x_2,\dots, x_{2^k n}$ unknowns and $n$ equations which take the following form: $$
\begin{cases}
x_1+x_{n+1}+x_{2n+1}+\cdots + x_{(2^k -1)n+1}=0\\
x_2 + x_{n+2}+x_{2n+2}+\cdots + x_{(2^k -1)n+2}=0\\
\vdots\\
x_{n} + x_{2n}+ x_{3n}+\cdots + x_{2^kn} =0.
\end{cases}
$$ Observe two important things: the variables are never repeated, i.e. they only appear once, so the equations are ""independent"" of each other. Also, the unknowns are ordered vertically, that is, starting from the top left $x_1$ then going down to $x_2,x_3,\dots, x_n$ then up again to the second on the top left $x_{n+1}$ then down again... and so on until we arrive at $x_{2^k n}$. As an example: If $k=2$ and $m=3$ then $$
\begin{cases}
x_1+x_{4}+x_{7}+x_{10}=0\\
x_2 + x_{5}+x_{8}+x_{11}=0\\
x_{3} + x_{6}+ x_{9}+ x_{12} =0.
\end{cases}
$$ By Rouché-Cappelli's theorem since the ranges of the two matrices are equal but less than $2^k m$ we have infinitely many solutions. I aim at writing something like: $$w_1 := x_1, w_2 := x_2,\dots, w_m := x_m$$
and then deriving the rest in terms of the $w_j$. Is there a ""nice"" and ""clean"" well-shaped pattern for doing this? I'll be really thankful for any ideas you might have!","['systems-of-equations', 'linear-algebra', 'real-analysis', 'algebra-precalculus']"
1194313,"A rigorous meaning of ""induced measure""?","In my readings I often come across terms like ""induced measure"" or ""induced Lebesgue measure"". For example: $$\int_{\mathbb{B}^n}u\frac{\partial v}{\partial x_j}\;dx = \int_{\mathbb{S}^{n-1}}uv\frac{x_j}{|x|}\;d\sigma - \int_{\mathbb{B}^n}v\frac{\partial u}{\partial x_j}\;dx$$ where $d\sigma$ denotes the induced Lebesgue measure on the sphere. Unfortunately though, I've never really seen anyone give a rigorous definition to this phrase. Sure, in the above example, we understand how to parametrize the $n$ ball, $\mathbb{B}^n$, and the $n-1$ sphere, $\mathbb{S}^{n-1}$, and so the integrals are easy to compute and not very confusing. Sometimes, however, it appears in the context of a general hypersurface in $\mathbb{R}^n$ (say $\Sigma$, with integrals involving $d\Sigma$), or when integrating over a subset (submanifold) of some higher-dimensional  space. In a completely general setting like this, I am at a little bit of a loss when it comes to understanding  how these separate ""surface"" measures or ""induced"" measures are really defined, when I'm lacking an explicit parametrization. It also doesn't help that traditional vector calculus classes seem to always fall short of doing anything past 3 dimensions. For example, I've never seen a class teach its students how to carry out a (2-D) surface integral in anything except $\mathbb{R}^3$; so they would have no idea how to go about finding the surface area of, say a Clifford Torus in $\mathbb{R}^4$. And in general, I've never seen them address a general technique for integrating over an $n$-dimensional body, embedded in $n<m$-dimensional space. It seems like everything they're taught is in terms of the cross product, which fails to be of any use in $\mathbb{R}^{n>3}$. Now I realize that at least some of the hypersurface examples from calculus, that I've mentioned above, can be addressed using the generalized Stokes' theorem: $\int_{D}\text{d}\omega = \int_{\partial D}\omega$. But it seems to me that when we are getting to the realm of measure theory, higher-level analysis, and Riemannian geometry, the word ""induced"" is probably thrown around for a good reason. Let me clarify what I mean: If we are on a Riemannian manifold $M$, then its metric $g$ defines a volume element for the the manifold, $dV_g = \sqrt{\det g}\;dV$, where $dV$ is the Euclidean measure for your coordinate patch in $\mathbb{R}^n$. If we then consider an immersed submanifold $N\hookrightarrow M$, we have a rigourous definition for the induced metric that $N$ inherits from $M$. If we have a topological space $(X,\tau)$, then it induces a subspace topology on any subset $Y\subset X$, $\tau_Y = \{Y\cap U : U\in\tau\}$. Similarly for any subset $Y\subset X$ of a $\sigma$-algebra $(X,\Sigma)$, we have the sub-$\sigma$-algebra $(Y,\Sigma_Y), \Sigma_Y = \{Y\cap A : A\in\Sigma\}$. In these settings, the word "" induced "" has a very specific meaning, and essentially boils down to the idea of a subset inheriting some sort of property from a larger set it belongs to. So it would make sense that there should be some concrete way of having a measure space induce some kind of measure on a subset of itself. At first glance, since a measure space $(X,\Sigma,\mu)$ can give rise to a sub-$\sigma$-algebra (as mentioned above) then you might want to simply take the restriction of $\mu$ to these subsets in $\Sigma_Y$. But the problem is that any subset $E$, without full dimension, will of course have measure zero, $\mu(E)=0$. So this would make for a lousy way to define integration over this subset. So maybe we only concern ourselves with Riemannian manifolds, and just define the induced measure as the one that arrises from the induced metric of some parent manifold. But this seems limiting for a couple reasons: Integration is now limited to Riemannian manifolds, and no longer over a general measure space. For example, while integration with respect to the counting measure makes sense over $\mathbb{N}$, I can't see any way to interpret this as integration over a Riemannian manifold; and so the question of how the counting measure ""induces"" another measure would be meaningless. If we consider a (smooth) subset $S\subset\mathbb{R}^n$, we can build a measure space on $S$ from scratch, similar to how we build the Lebesgue measure on $\mathbb{R}^n$ in measure theory. My question then is: are we always able to realize integration (with respect to this measure) over $S$ as integration with respect to some induced metric, by considering $S\subset M$, for some manifold $(M,g)$? To me, a measure (and anything that it induces) should be in the spirit of measurable sets, and not be restricted to differential manifolds. The Lebesgue measure $\mu$ in $\mathbb{R}^3$ gives us the volume of the unit ball as $\frac{4}{3}\pi$; shouldn't $\mu$ induce a measure on $\mathbb{S}^2$, to give us $4\pi$ surface area? And whatever method we choose, shouldn't it apply to abstract measures as well, not just Lebesgue measure?","['lebesgue-integral', 'lebesgue-measure', 'measure-theory', 'integration']"
1194337,When is the tensor product of a separable field extension with itself a domain?,"I'm reading Algebraic Geometry and Arithmetic Curves by Qing Liu. On page 92, in the proof of Corollary 3.2.14 d), he states that if $K \otimes_k K$ is a domain, then $K = k$. Here $K$ is a separable (not obviously finite) field extension of $k$. Why is this true? Does it require separability?","['abstract-algebra', 'algebraic-geometry', 'tensor-products', 'field-theory']"
1194339,Can one find a stronger norm on a Banach space?,"Given a Banach space $V$ of infinite dimension with norm $\|\cdot\|_1$, is that possible to find a norm $\|\cdot\|_2$ on $V$ such that the topology induced by $\|\cdot\|_2$ is strictly stronger than that of $\|\cdot\|_1$? I guess the answer is no, but I can only prove that $\|\cdot\|_2$ cannot be complete (simply  by open mapping theorem). Any idea will be appreciated.","['functional-analysis', 'normed-spaces']"
1194364,Matrix of Ones with Diagonal of Integers,"My teacher posed a question to the class today asking us to find the determinant of the following matrix... \begin{bmatrix}
    2 & 1 & 1 & 1 & 1 \\
    1 & 3 & 1 & 1 & 1  \\
    1 & 1 & 4 & 1 & 1 \\
    1& 1 & 1 & 5 & 1 \\
    1&1&1&1&6
\end{bmatrix} using a simple trick that doesn't involve transforming it into reduced row echelon form.  For the life of me I've been unable to figure it out.  Does anyone know the trick, or even which steps I should take to make my teachers supposed method more apparent?","['determinant', 'linear-algebra', 'matrices']"
1194368,If $\int_1^x f(t)^2dt \le \frac{x^3-1}{3}$ then $\int_1^2 f(t)dt \le \frac{3}{2}$,"If $f:[1,2]\to [0, \infty )$ is an Riemann integrable function such that $\int_1^x f(t)^2dt \le \frac{x^3-1}{3} , \forall x \in [1,2]$. Prove that $\int_1^2 f(t)dt \le \frac{3}{2}$ . First, I used Cauchy's inequality: $(x-1) \int_1^x f^2(t)dt \ge \left( \int_1^x f(t)dt \right)^2 $ so $\int_1^x f(t)dt \le \sqrt{\frac{(x^3-1)(x-1)}{3}}$ , so $\int_1^x f(t)dt \le \sqrt{ \frac{7}{3}}$, but $\frac{3}{2} < \sqrt{\frac{7}{3}}$. Another attempt is: From $(f(x)-x)^2 \ge 0, \forall x\in [1,2]$, so $f^2(x)+x^2 \ge 2xf(x), \forall x\in [1,2]$. Integrating this inequality on [1,x] and using the hyphotesis we get that $\frac{x^3-1}{3} \ge \int_1^x tf(t)dt , \forall x\in[1,2]$. Can you help me, please ?! Thank you!",['analysis']
1194386,"In the first countable TVS, if every Cauchy sequence convergence then every Cauchy net convergent","Let $X$ be a topological vector space with the first countable topology(that is, every point has a countable neighborhood basis).If every Cauchy sequence convergence, we want to show that every Cauchy net converges. For every given Cauchy net $\langle x_i\rangle$, I think I can inductively find a subnet $\langle x_{k_n}\rangle$of $\langle x_i\rangle$ which is actually a Cauchy sequence. By assumption, we know $\langle x_{k_n}\rangle$ converges to  a point $x$ in $X$, I need to show $\langle x_i\rangle \rightarrow x$. If $X$ is a metric space, then the argument may be easier since we can apply ""$2\epsilon$ argument"" to $x_i-x_{k_n}+x_{k_n}-x$. But how to do this in a general 1st countable topological vector space? Plus, if $\{U_n\}$ is a countable neighborhood basis at $0$, is $\{U_n+U_n\}$ again a neighborhood basis at $0$?","['nets', 'convergence-divergence', 'general-topology', 'topological-vector-spaces']"
1194403,How to determine if a quintic polynomial is solvable by radicals,"I wish to determine if $f(x)=x^5+x^4+x^3-2x^2-2x+5$ is solvable by radicals over $\mathbb{Q}$ . In other words, I want to know if its Galois group is solvable. I haven't gotten anywhere trying to find the roots explicitly.  Also, the result for polynomials with exactly three real roots doesn't apply here.  How should I approach this problem?","['abstract-algebra', 'polynomials', 'galois-theory']"
1194409,How many permutations of a multiset have a run of length k?,"Background $\newcommand\ms[1]{\mathsf #1}\def\msP{\ms P}\def\msS{\ms S}\def\mfS{\mathfrak S}$Suppose I have $n$ marbles of $c$ colors, where $c≤n$. Let $n_i$ denote the number of marbles of color $i$. Let $\msP=(1^{n_1} 2^{n_2} \dots c^{n_c})$ be the multiset $\small\{\underbrace{1, \dots, 1}_{n_1},\underbrace{2,\dots,2}_{n_2},\dots,\underbrace{c,\dots,c}_{n_c}\}$ in frequency representation . The number of distinct permutations of $\msP$ is given by the multinomial:
$$\left|\mfS_{\msP}\right|=\binom{n}{n_1,n_2,\dots,n_c}=\frac{n!}{n_1!\,n_2!\cdots n_c!}=n! \prod_{i=1}^c \frac1{n_i!}.$$ Question How many permutations of $\msP$ have a run of length k ? Let $r_k(\msS)$ be true if a permutation $\msS$ has a run of length $k$ ($k$ marbles in a row are the same color). For example, if I have 5 marbles (2 green, 2 blue, and 1 yellow), then: If $\msS$ is GBYGB , then $r_1(\msS)$ is true, but $r_2(\msS)$ is false. If $\msS$ is GBBYG or GGBBY , then $r_1(\msS)$ and $r_2(\msS)$ are true, but $r_3(\msS)$ is false. Let the number of permutations of $\msP$ having a run of length $k$ be
  $$N(k; \msP)=\sum\limits_{\msS\in\mfS_\msP}[r_k(\msS)]$$
  where $[x]$ denotes the Iverson bracket. Is there a formula for $N(k; \msP)$? Essentially, I would like to find a generalization of this recurrence for the case $c=2$ ( Bloom 1996 ). What I have done so far I constructed the table below, counting the permutations for configurations of up to $n=7$ marbles by brute force.  The rightmost columns count the permutations having runs of length $2≤k≤n$. Unfortunately, brute force stops being practical around $n\gtrsim 11$ (at $10^8$ permutations; see A005651 ). Here is a closer look at the permutations comprising the five $n=4$ cases. I tried to find patterns along different axes that would lead me to formulas for those specific cases, which I could then generalize, but I haven’t gotten anywhere. I then tried deriving a recurrence relation, also to no avail. My hunch, however, is that there may be a Fibonacci-like recurrence relation involved. Update I have entered Andrew’s solution into Mathematica: Ν[r_, P_] := Multinomial@@P - c[r, P]
c[r_, P_] := CoefficientRules[Π[r, P, t]] /. ({a_} -> b_) :> b a! // Total
Π[r_, P_, t_] := Product[q[r, ni, t], {ni, P}]
a[x_, r_, t_] := a[x, r, t] = Exp[t  (x - x^r)/(1 - x^r)]
q[r_, n_, t_] := q[r, n, t] = SeriesCoefficient[a[x, r, t], {x, 0, n}] The values up to $n=5$ match the tables above: Column@Table[
 Grid@Table[
   Table[Ν[r, partition], {r, 1, Max[partition]}
    ], {partition, IntegerPartitions[marbles]}
   ], {marbles, 1, 5}
 ]

1

1   1
2   

1   1   1
3   2   
6       

1   1   1   1
4   4   2   
6   4       
12  6       
24          

1   1   1   1   1
5   5   4   2   
10  9   3       
20  18  6       
30  18          
60  24          
120 Table of $q_{r,n}(t)$ polynomials $$\newcommand\f[1]{\color{gray}{#1}}
\begin{array}{r|llllll}
r \backslash n & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
1 & 0 & 0 & 0 & 0 & 0 & 0 \\
2 & \f{t} & \frac{t^2}{2}-t & \frac{t^3}{6}-t^2+t & \frac{t^4}{24}-\frac{t^3}{2}+\frac{3 t^2}{2}-t & \frac{t^5}{120}-\frac{t^4}{6}+t^3-2 t^2+t & \frac{t^6}{720}-\frac{t^5}{24}+\frac{5 t^4}{12}-\frac{5t^3}{3}+\frac{5 t^2}{2}-t \\
3 & \f{t} & \f{\frac{t^2}{2}} & \frac{t^3}{6}-t & \frac{t^4}{24}-t^2+t & \frac{t^5}{120}-\frac{t^3}{2}+t^2 & \frac{t^6}{720}-\frac{t^4}{6}+\frac{t^3}{2}+\frac{t^2}{2}-t \\
4 & \f{t} & \f{\frac{t^2}{2}} & \f{\frac{t^3}{6}} & \frac{t^4}{24}-t & \frac{t^5}{120}-t^2+t & \frac{t^6}{720}-\frac{t^3}{2}+t^2 \\
5 & \f{t} & \f{\frac{t^2}{2}} & \f{\frac{t^3}{6}} & \f{\frac{t^4}{24}} & \frac{t^5}{120}-t & \frac{t^6}{720}-t^2+t \\
6 & \f{t} & \f{\frac{t^2}{2}} & \f{\frac{t^3}{6}} & \f{\frac{t^4}{24}} & \f{\frac{t^5}{120}} & \frac{t^6}{720}-t \\
\end{array}
$$ Similar questions I missed in prior searches Find the number of arrangements of $k \mbox{  }1'$s, $k \mbox{  }2'$s, $\cdots, k \mbox{  }n'$s - total $kn$ cards. (answered by Jair Taylor himself) How many arrangements of $\{a,2b,3c,4d, 5e\}$ have no identical consecutive letters? Number of words with a minimal number of repetitions","['combinatorics-on-words', 'permutations', 'recurrence-relations', 'combinatorics', 'multisets']"
1194419,Maximum volume of a box with a lid that can be made out of a square,"Snacks will be provided in a box with a lid (made by removing squares from each corner of a rectangular piece of card and then folding up the sides) You have a piece of cardboard that is 40cm by 40 cm – what dimensions would give the  maximum volume? This is how I attempted it Let the length of the square to be cut off be x cm. V be the Volume in cm3 Volume = L x B x H $$L= 40 – 2x$$
$$B= 40 – 2x$$
$$H = x$$
So Volume $= x(40-2x)(40-2x)$
$$V = 4X^3 – 160x^2 + 1600x$$
Or $V= x^3 – 40x^2 + 400x$
$$V'  = 3x^2 – 80x + 400$$
$$V'' = 6x – 80$$
Solve for turning points by putting $V ' = 0$ $$3x^ 2 – 80x + 400 = 0 $$ $$(3x - 20)(x – 20) = 0$$ $x= 20/3$ and  $x = 20$ For Max Volume, $x = 20$ is a reasonable solution that can be apply  and discard the other root i.e. $x = 20$ 2nd derivative test  $x = 20/3$: $$V'' = 6(20/3) – 80= -20 < 0 $$ it will give Maximum Volume $$V =  (20/3)3 – 40(20/3)2 + 400(20/3)$$ $$V = 1186 \text{cm}^ 3$$ Have I done it right ?","['optimization', 'polynomials', 'calculus', 'derivatives']"
1194425,Proving or Disproving statements using sets,"I just don't seem to get proofs or set theory so hopefully my question makes sense. I'm not sure when I should or shouldn't use an example to prove or disprove a statement? One example question is, if C $\subseteq$ A and D $\subseteq$ B, then C $\cup$ D $\subseteq$ A $\cup$ B. I want start by making set A = $\{1, 2, 3, 4, 5\}$ , B = $\{1, 2, 3, 4, 5, 6\}$ C = $\{1, 2, 3\}$ and D = $\{1,2,3,4\}$ and this would show an example proving this statement. However I think this might be wrong because it only shows one example. So, I tried to think of a counterexample that would show that the statement is false. However I'm not sure if I should then try to prove, If C $\subseteq$ A and D $\subseteq$ B, then C $\cup$ D $\subseteq$ A $\cup$ B false or if I should be proving, If C $\subseteq$ A and D $\subseteq$ B, then C $\cup$ D $\subsetneq$ A $\cup$ B false?? I've also tried using x $\in$ C $\subseteq$ A, then x $\in$ C and x $\in$ A, x $\in$ D 
$\subseteq$ B, then x $\in$ D and x $\in$ B But, I didn't know what to do from there.","['elementary-set-theory', 'discrete-mathematics', 'proof-writing']"
1194451,Calculate the maximum area (maximum value),TX farmer has 100 metres of fencing to use to make a rectangular enclosure for sheep as shown. He will use existing walls for two sides of the enclosure and leave an opening of 2 metres for a gate. a)  Show that the area of the enclosure is given by: $A = 102x – x^2.$ b)  Find the value of x that will give the maximum possible area. c)  Calculate the maximum possible area. How do I assign the two variables for area ? Can anyone assist me in solving this problem?,"['optimization', 'calculus', 'algebra-precalculus', 'derivatives']"
1194465,Covariance of absolute value of variables,"I have some relatively complicated variables I am working with. I need to find the covariance: $\text{cov}(\left|x\right|,\left|y\right|)$, is there a simplification of $\text{cov}(\left|x\right|,\left|y\right|)$ in terms of $\text{cov}(x,y)$?","['covariance', 'probability', 'statistics', 'expectation']"
1194481,Notation of author-defined functions.,"I have seen functions defined various ways, and I'm wondering which form I should use for some functions. I am hoping to learn what it might be read as, interpreted, etc. The most common definition of a function is by far $f(x_0,\ldots,x_n)$, for example, $f(a,b,c)=\frac{a^b-c^a}{abc}$. I assume that this is read as ""(the) $f$ of $a,b, $ and $c$"". I have seen another definition as $R_z$, for example, $C_n$ is the cyclic graph with $n$ vertices. I have interpreted this to refer to some special element of a larger set, as opposed to $f(x)$, which to me connotes a routine of sorts. A symbol is often used to denote some function, for example, $\bigcup_{\{x_i\}_{i\in I }}$, $\mathbb{Z}_n$, and $\sum_{i=0}^{12}i^2-i$. I'm not entirely sure when to use this. The last definition I have seen is $f(x;y)$. I have seen this only in some probability functions, and, with my limited exposure, I interpreted it to mean ""$f$ of $x$ with respect to $y$"" or something similar. My question is this: When should I use each notation? Are there any other ways of denoting a function? I wish to define a large number of functions, and I wonder which cases would require each notation.","['notation', 'functions']"
1194499,Find the derivative of a polylogarithm function,"I was trying to find to which function the next series converges.
$$
\sum_{n=1}^{\infty} \ln(n)z^n
$$
If we take the polylogarithm function $Li_s(z)$ defined as
$$
Li_s(s)=\sum_{n=1}^{\infty} \frac{z^n}{n^s}
$$
Then it is easily seen that
$$
\sum_{n=1}^{\infty} \ln(n)z^n = - \left( \frac{\partial}{\partial s}Li_s(z)\right)_{s=0}
$$ Now, my question is how to calculate $ \frac{\partial}{\partial s}Li_s(z)$, using an integral representation for $Li$, such as
  $$
Li_s(z)=\frac{1}{\Gamma(s)}\int_{0}^{\infty} \frac{zt^{s-1}}{e^t-z} dt
$$ Is there any nice solution to this? All my attempts are unclear about it, especially because of the derivative of $\Gamma(s)$.","['partial-derivative', 'complex-analysis', 'polylogarithm']"
1194500,Do functions that decay at $\pm \infty$ eventually become a constant $0$ function?,"If a function defined on $\mathbb{R}$ decays at $\pm \infty$, does that mean it will have 'died out' before reaching $\pm \infty$ i.e $f=0$ for $x\geq a$ for some $a>0$ and $f=0$ for $x\leq b$ for some $b<0$ as the function can never take on a value at $\pm \infty$","['functions', 'integration']"
1194510,Proof of convergence of a recursive sequence,How do I prove that $x_{n+2}=\frac{1}{2} \cdot (x_n + x_{n+1})$ $x_1=1$ $x_2=2$ is convergent?,"['sequences-and-series', 'faq', 'calculus', 'convergence-divergence']"
1194532,Surfaces in $\mathbb P^3$ not containing any line,"Let $d \geq 4$. I'm interested by know if there is a surface $S$ of degree $d$ in $\mathbb P^3_{\mathbb C}$ such that $S$ does not contains a line. I know 
I have no idea how to do it.",['algebraic-geometry']
1194537,Question on calculating curvature of a surface given implicitly,"I want to find, as an exercise, an expression for the curvature of a surface given by the zero set of a function. I reached a final expression, but when I test it for a sphere I get a non-constant expression. I know I'm doing a step wrong, but I don't know why. Below is what I have. Say we have a good enough $f:\Bbb R^3 \to \Bbb R$. This defines a surface in $\Bbb R^3$ as $$S = \{(x,y,z)\in\Bbb R^3 : f(x,y,z) = 0\}$$ Suppose that $f_z = \frac{\partial f}{\partial z}\neq 0$. Then by the implicit function theorem it's easy enough to see we have a local parametrization of $S$ (in fact, the graph of a function): $$h:\Bbb R^2\to \Bbb R^3 \atop (x,y)\mapsto (x,y,h(x,y))$$
and $h$ satisfies (found using the chain rule on $f(x,y,h(x,y)) = 0$) $$\begin{align}h_x = \frac{-f_x}{f_z} \\ h_y = \frac{-f_y}{f_z}\end{align}$$ This way we have a basis for $T_pS$ (at a point $p$ which is omitted in the expressions) $(1,0,-f_x/f_z), (0,1,-f_y/f_z)$. With the usual notation, the coefficients of the first fundamental form $I$ can be calculated as $$E = 1+(f_x/f_z)^2, F = \frac{f_xf_y}{f_z^2}, G = 1 + (f_y/f_z)^2$$
My problem, it seems, comes with the second fundamental form $II$. For example, my calculation of $h_{xx}$ results in $$h_{xx} = \frac{f_xf_{xz}-f_{xx}f_z}{f_z^2}$$
while on this page they get $$h_{xx} = \frac{2f_xf_zf_{xz}-f_x^2f_{zz}-f_z^2f_{xx}}{f_z^3}$$ so either something is horribly wrong and I've forgotten how to differentiate a quotient, or there's something else in the calculation I'm not including. Note that this is before doing anything with the normal vector, just partial derivatives of the parametrization. Could someone clear this up?","['implicit-function-theorem', 'curvature', 'partial-derivative', 'implicit-differentiation', 'differential-geometry']"
1194549,Schwarz 's lemma and sharp upper bound,"Let $f$ be a holomorphic function on $|z|<1$ with $|f(z)|<1$ for all $|z|<1$. (1) Find necessary and sufficient conditions for equality of $$\frac{|f'(z)|}{1-|f(z)|^2} \leq \frac{1}{1-|z|^2}$$ for all $|z| < 1.$ (2) If $f(\frac{1}{2}) = \frac{1}{3}$, find a sharp upper bound for $|f'(\frac{1}{2})|.$ I know that the inequality is Schwarz-Pick Lemma, and I think that it has something to do with Mobius Transformation (Linear fractional transformation) which I supposed that it will be introduced later in my textbook (Complex Analysis in Spirit of Lipman Bers, second edition). This problem is in chapter 6, and the Mobius should be introduced in chapter 8. So, actually, I do not know much about Mobius Transformation. So I do not have any clear idea for the condition concerning equality of the inequality above. Also, I do not know what is a sharp upper bound. I found the definition on http://en.wikipedia.org/wiki/Upper_and_lower_bounds ,but I do not fully understand what it means, and, according to the question, what I have to do with $|f'(\frac{1}{2})|$","['analysis', 'complex-analysis']"
1194565,How to know if two points are diagonally aligned?,"If I have two points at different X/Y coordinates, I know that: They are vertically aligned if both are at the same X coordinate; They are horizontally aligned if both are at the same Y coordinate. Based on the X/Y coordinates of one in relation to the other I can also tell the distance between them, etc. Now, how can you tell that the points are diagonally aligned by following the same logic?","['geometry', 'coordinate-systems']"
1194582,How to find the vector equation of a plane given the scalar equation? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question How would I find the vector equation of the plane: $x + 2y + 7z - 3 = 0$ So far, I found the normal vector: it's $(1, 2, 7)$.","['3d', 'geometry', 'linear-algebra', 'vector-spaces']"
1194584,The total number of subarrays,"I want to count the number of subarrays for a vector (not combinations of elements). Ex. A[1,2,3] It has 6 subarrays : {1}, {2}, {3}, {1,2}, {2,3}, {1,2,3} I think that for a vector of N elements the total number of subarrays is N*(N+1)/2 . I am not able to prove it, can someone do it?",['combinatorics']
1194634,The set of convergent points of a sequence of continuous functions is Borel,"Suppose that $f_n$ are continuous.  Prove that $E=\{x\in \mathbb{R}:f_n(x)\text{ is convergent}\}$ is Borel. My first instinct is to take balls around $\lim_{n\to\infty}f_n(x)$, for each $x$ in $E$, and then show that there has to be some ball small enough so that everything inside that ball is a member of $E$. But this would imply not only that $E$ is Borel, but moreover that it is open, so I don't think that can be right.  Can someone show me how to do this?","['real-analysis', 'measure-theory']"
1194666,Application of the chain rule for curves,"Problem : Let $f: \mathbb{R}^3 \to \mathbb{R}$ be a differentiable function such that $$y \frac{\partial f}{\partial x}(x,y,z) -x \frac{\partial f}{\partial y}(x,y,z) + \frac{\partial f}{\partial z}(x,y,z) \geq a>0, \forall(x,y,z) \in \mathbb{R}^3 \tag{*} $$
  Let $\gamma: \mathbb{R}_+ \to \mathbb{R}^3$ a differentiable curve given by $\gamma(t)=(- \cos t, \sin t ,t), \ t \geq 0$ Show for $g(t):=f(\gamma(t))$ that $\lim_{t \to + \infty} g(t) = + \infty$ My approach : My idea was to make use of the fact that $g$ is differentiable and the derivative is given by $$g'(t)=< \nabla f(\gamma(t)), \dot\gamma(t)> $$ because the result will very much look like (*), if I can manage to show that $g'(t)\geq a >0$ it would follow that for all $t\geq 0$ I have that $g$ is strictly monotone increasing, if I then could prove that there exists no upper bound, this would finish the exercise. I have $\dot \gamma(t)=(\sin t, \cos t ,1)$, my next step was to compute $g'(t)$, I obtained that $$g'(t)= \sin t \frac{\partial f( \gamma(t))}{\partial x}+ \cos t \frac{\partial f ( \gamma(t))}{\partial y} + \frac{\partial f(\gamma(t))}{\partial z} $$
Which looks a lot like (*), however not quite, because there is this annoying minus sign missing, which might be due to a typing error in C. Michels Analysis II Exercises. Also I fail to make sense of the partial derivatives above, I left the $x,y,z$ in place in order to establish the connection with (*), however if I naively substitute $x= - \cos t, y = \sin t, z = t$ I get very weird partial derivatives that make no sense at all to me. Is my approach to this exercise (in general) right? Or did I misguide myself into trap because (*) looks so much like the chain rule for curves.","['self-learning', 'calculus', 'multivariable-calculus']"
1194705,Would the powerset of $\mathbb{Z}$ also not denumerable?,"Would the powerset of $\mathbb{Z}$ also be not denumerable?, Since Cantor's theorem says that the $\mathbb{N}$ is denumberable but the powerset of $\mathbb{N}$ is not denumberable because there does not exist a surjective function from $\mathbb{N} \rightarrow$ $P( \mathbb{N} )$ I feel like this should be true for $\mathbb{Z}$ as well am I wrong?","['contest-math', 'recreational-mathematics', 'discrete-mathematics']"
1194761,how do you type sec^2(0) on a calculator?,I press cos^-1 then ^2 then brack (o) but then it comes up with syntax error,"['calculator', 'trigonometry']"
1194762,Mental Primality Testing,"At a trivia night, the following question was posed: ""What is the smallest 5 digit prime?"" Teams (of 4) were given about a minute to write down their answer to the question. Obviously, the answer is googleable, so I'm not asking what the answer to the trivia question is, but rather: how could a team quickly find the answer without previous knowledge of it? If you wanted to try solving the trivia question yourself, don't read any further, as I will start discussing the answer and ruling out other numbers now. My thoughts so far: If you know your slide rules, you expect that prime density is close to $ln(10,000)$ or about 10%. So, a reasonable approach would be to focus on numbers 10,000 through 10,010. Really, what matters is that (I assume) you start at 10,000, factor as many numbers in a row as you can, and then guest the first number you haven't factored. We can rule out a lot with easy divisibility tests, leaving 10001, 10003, 10007, and 10009. Assuming one of your people is fast with division or knows better divisibility rules, 10003 is also eliminated because it has a small divisor (7). This shouldn't require a special technique. We're now left with 3 numbers that reasonable divisibility tests won't handle. It turns out 10,001 is composite, while 10,007 and 10,009 are both prime. But the smaller factor of 10,001 is 73, which is the 21st prime. If the team could do the above steps and then rule out 10,001 by dividing by the first 21 primes (also assuming they know the first 21 primes), they would presumably guess 10,007 thereby being right (though not necessarily confident in their answer). But, let's assume that 21 divisions aren't quite possible. Is there a faster way? Let's say that either a test that quickly determines that 10,001 is likely composite or a test that determines that 10,007 is likely prime is sufficient, since we might be down to some guess work at this point, but bonus points if we can know for sure 10,001 is composite or know for sure 10,007 is prime, and extra bonus points if we do both! There are potentially approaches that don't rely on ruling out 10,001. For example, I had the idea initially that given that 10,001, 10,007, and 10,009 are each hard to divide, maybe it's fairly likely that 10,007 and 10,009 are twin primes, and therefore it is more likely that 10,007 is a prime than 10,001 and so you would guess it anyway. While 10,007 and 10,009 do turn out to be twin primes, I don't actually think that the assertion holds, and this seems more like luck.","['primality-test', 'number-theory', 'divisibility', 'mental-arithmetic']"
1194796,Find a subgroup of $S_{4}$ which is isomorphic to $\mathrm{Aut}(U_{8})$,"The notation I am using is: $S_{4}$: the permutation group of order 4 $\mathrm{Aut}(U_{8})$: the set of all automorphisms on the set $U_{8}$ $U_{8}$: the group of numbers relatively prime to 8 I know that $U_{8} = {{1,3,5,7}}$. Forgive my lack of a proper table, but the ""multiplication table"" for $U_{8}$ is given by: $\begin{bmatrix}
       1*1 & 1*3 & 1*5 & 1*7   \\[0.3em]
       3*1 & 3*3 & 3*5 & 3*7   \\[0.3em]
       5*1 & 5*3 & 5*5 & 5*7   \\[0.3em]
       7*1 & 7*3 & 7*5 & 7*7
     \end{bmatrix} =  \begin{bmatrix}
       1 & 3 & 5 & 7   \\[0.3em]
       3 & 1 & 7 & 5   \\[0.3em]
       5 & 7 & 1 & 3   \\[0.3em]
       7 & 5 & 3 & 1
     \end{bmatrix}$ So I believe I should begin by asking how many elements does $\mathrm{Aut}(U_{8})\ $ have. An element in $\mathrm{Aut}(U_{8})\ $ is an isomorphism from $U_{8}$ to itself. My research led to some discussions of finding the number of generators of the group - however $U_{8}$ is not cyclic so this falls apart for me. Can somebody point me in the right direction? Even just explaining the different possibilities would help me tremendously. Other than the trivial automorphism $\Phi(x)=x\ $ I cannot think of anything. I should also note that $U_{8}$ is isomorphic to the Klein four-group. I'm not sure how this helps me.","['group-theory', 'group-isomorphism', 'permutations']"
1194799,Conditional Expectation of Functions of Random Variables satisfying certain Properties,"Suppose that we have a probability space $(\Omega, \mathcal{F}, P)$. Let $X,Y$ be real-valued random variables defined on this space, and let $\mathcal{H} \subset \mathcal{F}$ be a sub-sigma-algebra. Suppose $X$ is $\mathcal{H}$-measurable (i.e, $X^{-1}(B) \in \mathcal{H}$ for all Borel $B \subset \mathbb{R}$). Also suppose that $Y$ is independent of $\mathcal{H}$ (which implies that $X$ and $Y$ are independent). Then is it true that for any Borel-measurable function $g: \mathbb{R}^2 \to \mathbb{R}$, we have that $\mathbb{E}(g(X,Y)|\mathcal{H})=\mathbb{E}(g(X,Y)|X)$? Observations: It seems to be true for functions of the form $g(x,y)=f(x)h(y)$, because $\mathbb{E}(f(X)h(Y)|\mathcal{H}) = \mathbb{E}(h(Y)) \cdot f(X)=\mathbb{E}(f(X)h(Y)|X)$ by independence of $Y$ to $X$ and $\mathcal{H}$. But I can't seem to prove it for the general case. Maybe we can approximate arbitrary $g$ by functions of this form from below, and then use MCT? Is it possible to show that any measurable $g: \mathbb{R}^2 \to \mathbb{R}$ can be written as the (upward) limit of linear combinations of functions of the form $\chi_{A \times B}$, for Borel $A,B \subset \mathbb{R}$? Because then we can just apply MCT and use the preceding comment, and we're done. (The $\chi_E$ denotes characteristic function of $E$.)","['probability-theory', 'measure-theory']"
1194816,Existence and Uniqueness of ODEs and form of initial conditions,"Is there a technical reason as to why the existence and uniqueness theorem for ODEs of the form $$y'(x) = F(x,y(x))$$ is proved for initial conditions of the form $$y(x_0) = y_0$$ and not for $$y'(x_0) = y'_0$$ I understand that in most physical applications, only initial values of the form $y(x_0) = y_0$ are present. But is there any other reason for such a form of initial condition, or can we prove existence and uniqueness even for the IVP of the form $y'(x_0) = y'_0$ ?",['ordinary-differential-equations']
1194833,liminf inequality in measure spaces,"Let $(X;\mathscr{M},\mu)$ be a measure space and $\{E_j\}_{j=1}^\infty\subset \mathscr{M}$. Show that $$\mu(\liminf E_j)\leq \liminf \mu(E_j)$$
  and, if $\mu\left(\bigcup_{j=1}^\infty E_j\right)<\infty$, that
  $$\mu(\limsup E_j)\geq \limsup \mu(E_j).$$ I'm trying to parse what's going on.  On the left, we're taking the measure of $\liminf E_j$, which is $\cup_{i=1}^\infty\cap_{j=i}^\infty E_i$.  This is the union of the tails... okay. On the right, we've got $\lim_{n\to\infty}\inf\{\mu(E_j):n\leq j\}$.  The smallest $\mu$ for everything after $n$ (or the greatest lower bound, anyway). I can't make any progress, I've been stuck here for quite a while. I just don't know where to make the comparison. Can I get a nudge?","['real-analysis', 'limsup-and-liminf', 'measure-theory']"
1194897,Calculating angle on ellipse,"This is a really basic question, yet I can't remember my old geometry classes nor could I find an answer via google. Given a circle ""tilted"" at angle a to the horizontal plane, and given angle b inside the circle, I want to calculate the vertically projected angle, c , on the horizontal plane. It's obvious that the circle's vertical projection on the plane is an ellipse, and that cos(b) = cos(c) but I still can't work out the formula that gives me c given only the 2 first angles. I'm assuming this can be worked out regardless of the dimensions of the circle, although temporary arbritary dimensions can be used to calculate the solution. Note: As an example, in the above sketchup drawing a = 70 degrees, b = 45 degrees, and (what I want to calculate mathematically) c = 18.8 degrees.","['geometry', 'circles', 'trigonometry']"
1194900,Covering space of surface of infinite genus,"Let $X$ be a surface of infinite genus that is not compact (with edges extending to infinity). How would I show that this is a covering space of the 2-torus $T^{1}\# T^{1}$ via the action of the free product $\mathbb{Z}_{2} \star \mathbb{Z}_{2} = \langle a,b \mid a^{2} = e, b^{2} = e\rangle$ ? I've tried doing something analogous to the case of the simply connected covering space of $RP^{2} \vee RP^{2}$ via even translation and the action of the antipodal map, but can't quite get it to work with this case.","['covering-spaces', 'algebraic-topology', 'general-topology']"
1194906,"What about my proof is ""nonsense""?","I am working on a question from Fraleigh's ""A First Course In Abstract Algebra"": A torsion group is a group all of whose elements have finite order. A
  group is torsion free if the identity element is the only element of
  finite order. A student is asked to prove that if $G$ is a torision
  group, then so is $G/H$ for every normal subgroup $H$ of $G$. The
  student writes: We must show that each element of $G/H$ is of finite order. Let $x \in G/H$ Why does the instructor reading this proof expect to find nonsense
  from here on in the students proof? What should the student have
  written? Complete the proof. So I started thinking and just thought of point 3: We must show that each element of $G/H$ is of finite order. Let $x \in G/H$. Observe that $x \in G$ as $G/H \leq G$, but since $G$ is a torsion group, and $x$ is in $G$, $x$ must have have finite order. Q.E.D. This seems fine to me, but I think I am doing something silly since, the question leads me to believe so.",['abstract-algebra']
1194922,Maps from $D^n$ to $D^n$ with a single inverse set are open.,"Let $D^n$ denote the closed unit ball in $\Bbb R^n$. In multiple sources proving Brown's generalized Schoenflies theorem (including a version in the original paper), the following consequence of Brouwer's invariance of dimension is stated without proof. If $f: D^n \rightarrow D^n$ with only one non-singleton inverse set $f^{-1}(y)$ disjoint from the boundary, then $y$ is in the interior of the image of $f$. I am at a loss as to how to go from invariance of dimension to this. EDIT: I just went through the proof of generalized Schoenflies in Bing's book, and he doesn't makes use of this fact. I'm still interested how one proves this from invariance of dimension (or using similar homological techniques as such).","['metric-spaces', 'algebraic-topology', 'general-topology', 'geometric-topology']"
1194929,Confusion with Lang's proof of Sylow Theorem,"I am currently working through Lang's Algebra.  I am rather confused by what seems to be a trivial point.  In a lemma preceding the proof of the Sylow Theorem (which is essentially Cauchy's Theorem), lemma 6.1, he proves that if a finite abelian group has an exponent $n$ then its order divides some power of $n$.  I am comfortable with this fact.  However, he immediately used this to show that all such groups with order $np$, for $p$ prime, have an element of period $p$.  This seems very much like a non-sequitur to me.  What am I missing?","['abstract-algebra', 'group-theory', 'finite-groups']"
1194935,Working with norms,"I was hoping to get some help with being able to properly work with norms and derivatives so I can actually understand my PDE course. We are currently working on Sobolev spaces. Example, I want to show that: $$-\int_{U} u \Delta u dx \leq C \int_{U}|u||D^2u|dx$$ $u \in C_{c}^{\infty}(U)$ with $U$ bounded. I get to: $$-\int_{U} u \Delta u dx \leq \int_{U} |u||\Delta u|dx$$ I know it is not very far at all, but I am so confused. I am missing some key skills in multivariable calculus. My main question: What is $|D^2u|$? I thought that $D^2u$ was the hessian, and I'm confused about taking the norm. If you have any links that would help me better understand operations with norms and $D^ku$ I would greatly appreciate it. I'm really trying, but its just not clicking. Its really frustrating to be undone by the simpler concepts in an extremely theoretical PDE course.","['multivariable-calculus', 'partial-differential-equations']"
1194942,Question about definition of the Lebesgue integral of a non-negative function,"I am reading Royden's Real Analysis to learn about Lebesgue integration. Royden first shows that a bounded function on a set of finite measure is Lebesgue integrable if and only if it is measurable. Then, he goes on to define the integral of a non-negative measurable function $f$ on a measurable set $E$ as: $\int_E f = \sup\limits_{h \leq f} \int_E h$, where $h$ is a bounded measruable function which vanishes outside a set of finite measure What I am wondering about this definition is why we need a non-negative function $f$ to be measurable in the first place. Wouldn't the same definition be well defined even if $f$ is not measurable? In the case of the integral of a bounded function $f$ on a finite measure, all we assume is the boundedness of $f$, and the measurability of $f$ turns out to be the equivalent characterization of the Lebesgue integrability of $f$.","['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
1194948,Why General Leibniz rule and Newton's Binomial are so similar?,"The binomial expansion: $$(x+y)^{n} = \sum_{k=0}^{n} \binom{n}{k} x^k y^{n-k}$$ The General Leibniz rule (used as a generalization of the product rule for derivatives): $$(fg)^{(n)} = \sum_{k=0}^{n} \binom{n}{k} f^{(k)} g^{(n-k)}$$ Both formulas can be obtained simply by induction; Newton's binomial also has a combinatorial proof (here's the relevant wikipedia page) .
It's striking how these formulas are similar; is there a possible connection between them?
I was thinking that maybe the General Leibniz rule could be obtained using a combinatorial argument as well (hence the binomial coefficients)...","['induction', 'combinatorics', 'binomial-coefficients', 'intuition', 'derivatives']"
1194950,How to set up normal approximation for binomial,"In a particular school, 25% of first grade students do not enjoy reading. 22% of second graders do not enjoy reading. 
A random sample is taken of 100 first grade students, and another independent sample of 100 second graders is taken. Part 1:
Use normal approximation to find the probability that less than 30 first grade students in the sample do not enjoy reading. Part 2: 
Use normal approximation to find the probability that 5 more second graders than first graders in the samples do not enjoy reading. For part 1, after doing the 0.5 correction, I got
$$ O \  follows \  N(25, 18.75) $$
$$ P(O \le 29.5) = 0.851 $$ Is that right?
And for part 2, I'm not exactly sure how to set it up. Thanks!","['normal-distribution', 'probability', 'binomial-distribution']"
1194979,When variable substituitions are allowed in Taylor's Polynomials and when they aren't?,"Let $f:[-a,a] \rightarrow \mathbb{R}$ be a function assuming derivatives up to the $n$-th order in the open interval $(-a,a)$. The Taylor polynomial of $f$ around $0$ is: $$P_{n}(x) = \sum_{k=0}^{n} \frac{f^{(k)}(0)}{k!}x^k$$ For example, if $f(t)=e^t$, then: $$P_{n}(t) = 1 + t + \frac{t^2}{2} + \frac{t^3}{3!} + ... + \frac{t^n}{n!}$$ It's possible to substitute $t \rightarrow -x^2$ to get: $$P_{n}(-x^2) = 1 - x^2 + \frac{x^4}{2} - \frac{x^6}{3!} + ... + (-1)^n \frac{x^{2n}}{n!}$$ And the primitive of this polynomial could be used to approximate $\int e^{-x^2}dx$ However, if we had $g(x) = e^{\sin x}$, the third order Taylor polynomial would be $$P_{3}(\sin x) = 1 + x + \frac{x^2}{2}$$ (Note: the third derivative calculated in $0$ is equal to $0$) And obviously, replacing $t$ by $\sin x$ wouldn't work here. It may sound a silly question, but when I got to this result I started asking what's formally a substitution and when it's possible to change variables and when it's not.","['power-series', 'sequences-and-series', 'calculus']"
1195032,Find the values of m and n(Trigononetry in series),"$$\sin ^6(1)+\sin ^6(2)+... ...+\sin ^6(89)=\frac{m}{n}$$ Find $\frac{m}{n}$ in its simplest form , and hence find both values. (All angles are in degree) I've no idea how to start to solve this questions. Need some guidance for it. Thanks in advance.","['sequences-and-series', 'calculus', 'trigonometry']"
1195033,Calculate Wronksian of Second Order Differential Equation,"Use variation of parameters to find a particular solution to: $\frac{d^{2}y}{dx^{x}} + 2 \frac{dy}{dx} + y = \frac{1}{x^{4}e^{4}}.$ There are no solutions given so finding a wronskian that way is nil.
But since it is still in the order $p(x)y'' + q(x)y' + r(x)y = g(x)$ I think there is still a way to calculate a Wronskian. I have not worked with second order differential equations before and some hints/tips/help would be appreciated.",['ordinary-differential-equations']
1195047,Do Carmo :Show a line of curvature C is a plane curve if osculating plane makes a constant angle,"Here's the full problem: Assume that the osculating plane of a line of curvature $C \subset S$, which is nowhere tangent to an asymptotic direction, makes a constant angle with the tangent plane of $S$ along $C$. Prove that $C$ is a plane curve. My attempt: Let $\alpha : I \to S$ be some regular parametrization of $C$. Then the binormal vector $b(s)$ determines the osculating plane of $\alpha$, and the tangent plane to $S$ is determined by the normal vector $N$. Thus the stipulation is that $$b(s) \cdot N(s) = const$$ or $$ b'(s) \cdot N(s) + b(s) \cdot N'(s) = 0$$ Since $C$ is a line of curvature we have $N'(s) = \lambda(s) \alpha'(s)$ and so $b(s) \cdot N'(s) = 0$. Then we are left with $$\tau(s) n(s) \cdot N(s) = 0 $$ If I can show that $n(s) \cdot N(s) \neq 0$ then I have my result, since this means $\tau(s) = 0$. But I don't think this should be true in general, which means I've messed up somewhere. Any help would be greatly appreciated!",['differential-geometry']
1195095,Determine the Winding Numbers of the Chinese Unicom Symbol,"I'm practicing with Winding Numbers , and encountered an interesting example. You might be familiar with this liantong symbol, the logo of China Unicom: Suppose we make this into a fully closed and connected curve, and try to determine the Winding Numbers of the various points in the symbol. For instance: Find the winding numbers of the closed curve shown below at $z_1,z_2,z_3,z_4,z_5$ It seems to me that for each $z$, the winding number $W(z)$ is: $W(z_1)=0$ (since it is outside the curve) $W(z_2)=1$ (since it falls to the left of the curve in one loop) $W(z_3)=-2$ (since it falls to the right of the curve in two loops) $W(z_4)=0$ (since it falls to the right and to the left of the curve twice each, cancelling out) $W(z_5)=-1$ (since it falls to the right of the curve in one loop) Would you agree with these winding numbers (and given reasoning)? Thank you for your help!","['plane-curves', 'complex-analysis', 'winding-number']"
1195098,Delta function equation difficulty,1) Can we solve if we have two delta functions with $a=b$? Can we solve this? If not why? $$\int\delta (x−a)\delta(a−x)dx$$ 2) Can we solve this $$\int f(x)\delta (x)dx$$ ...where $f(x)=1/x$ i.e. $f(x)$ is infinite at $x=0$ and also delta function is infinite at $x=0$. We can have many such similar $f(x)$ which may face same difficulty.,['functions']
1195114,Measurable functions on product space,"Let $(\Omega, \mathcal{H}), (E, \mathcal{E})$ and $(F,\mathcal{F})$ be measurable spaces. Let $(E \times F, \mathcal{E} \otimes \mathcal{F})$ be a product space. Define the following three functions: $X:(\Omega,\mathcal{H}) \rightarrow (E,\mathcal{E})$ $Y: (\Omega, \mathcal{H} \rightarrow (F,\mathcal{F})$ $Z = (X,Y): (\Omega, \mathcal{H}) \rightarrow (E \times F, \mathcal{E} \otimes \mathcal{F})$ Now, I am trying to show that the following:
$X:(\Omega,\mathcal{H}) \rightarrow (E,\mathcal{E})$ and $Y:(\Omega, \mathcal{H}) \rightarrow (F,\mathcal{F})$ are measurable $\Leftrightarrow (X,Y): (\Omega,\mathcal{H}) \rightarrow (E \times F, \mathcal{E} \otimes \mathcal{F})$ is measurable. Here is my current work: $(\Rightarrow):$ Since X and Y are both measurable, we have
\begin{align*}
Z^{-1}(E \times F) &= \{w \in \Omega: Z(w) \in E \times F\}\\
&= \{w \in \Omega:(X(w),Y(w)) \in E \times F\}\\
&= \{w \in \Omega: X(w) \in E\text{ and }Y(w) \in F\}\\
&= \{w \in \Omega: X(w) \in E \} \cap \{w \in \Omega: Y(w) \in F\}\\
&= X^{-1}(E) \cap Y^{-1}(F),
\end{align*}
so the function $Z(w)$ is measurable for any $w \in \Omega$. $(\Leftarrow):$ On this part I'm stuck so I just wrote out my assumptions and what I want to show: We assume $Z(w)$ is measurable, so we have $Z^{-1}(A) \in \mathcal{H}$ for all $A \in \mathcal{E} \times \mathcal{F}.$ We need to show that X and Y are measurable, i.e. $X^{-1}(A) \in \Omega$ for all $B \in \mathcal{E}$ and $Y^{-1}(C) \in \Omega$ for all $C \in \mathcal{F}.$ How can I finish the rest of this proof? Unfortunately, I couldn't find anything like  of this in my book (Probability and Stochastics by Cinlar)","['products', 'measure-theory']"
1195127,Remark 4.31 in Baby Rudin: How to verify these points?,"Let $a$ and $b$ be two real numbers such that $a < b$, let $E$ be any countable subset of the open interval $(a,b)$, and let the elements of $E$ be arranged in a sequence 
$$x_1, x_2, x_3, \ldots.$$
Now let $\{c_n\}$ be any sequence of positive real numbers such that the series $\sum c_n$ converges. Now define the function $f \colon (a,b) \to \mathbb{R}$ as follows: 
$$f(x) \colon= \sum_{x_n < x} c_n \ \ \ \ \text{ for all } x \in (a,b).$$ Then Rudin states that
(a) the function $f$ is monotonically increasing on $(a,b)$; if $a < x < y < b$, then $$f(y) = \sum_{x_n < y} c_n  \geq \sum_{x_n < x} c_n = f(x)$$ because if any $c_n < x$, then that particular $c_n$ is obviously less than $y$ also. 
(b) $f$ is discontinuous at every point of $E$; in fact, 
$$ f(x_n + ) - f(x_n - ) = c_n.$$ How does this hold? How to show this rigorously using the $\epsilon$-$\delta$ approach?
(c) $f$ is continuous at every other point of $(a,b)$. How to show this using the rigorous approach? Moreover, $f(x-) = f(x) = f(x+)$ at all points of $(a,b)$.","['analysis', 'continuity', 'calculus', 'real-analysis']"
1195179,"The interval $[0,1]$ is not the disjoint countable union of closed intervals.","The following proof was suggested: suppose [0,1] was the disjoint countable union of closed intervals. Write the intervals as $[a_n,b_n]$. Start by showing the set of endpoints $a_n, b_n$ is closed. At first I thought this was obvious since it seems like the complement is just the union of $(a_n,b_n)$ which is open but then I thought the complement was the infinite intersection of $(0,a_n) \cup (a_n,b_n) \cup (b_n,1)$ which is not necessarily open any more. This comes from Taylor's proof in Is $[0,1]$ a countable disjoint union of closed sets?","['real-analysis', 'general-topology']"
1195192,Every finite group is the Galois group of a field extension,How can I show that every finite group is the Galois group of an extension $K/F$ where $F$ is itself a finite extension of $\mathbb Q$? I know  the following: Every finite group is contained in $S_p$ for a large enough prime $p$. Every irreducible polynomial in $\mathbb Q[x]$ of degree $p$ having exactly $p-2$ real roots has a Galois group $S_p$ over $\mathbb Q$. For any $n$ there is an irreducible polynomial in $\mathbb Q[x]$ of degree $n$ having exactly $n-2$ real roots. Does this have something to do with the inverse Galois problem?,"['abstract-algebra', 'field-theory', 'galois-theory', 'finite-groups']"
1195195,When the endomorphism ring of an abelian group is generated by automorphisms?,"Given an abelian group $M$. First I'd like to know if $\text{End}(M)$ is generated by $\text{Aut}(M)$ (as ring, or equivalently, as additive group). Second I'd like to know if it doesn't hold generally, then what condition will guarantee it. I guess it holds at least when $M/\text{Tor}(M)$ is a free abelian group. And under this constraint, it suffices to consider abelian $p$-groups and free groups. I succeeded to prove that it always holds for free abelian groups of finite rank. But I cannot prove the case of abelian $p$-groups and general free abelian groups.","['abstract-algebra', 'abelian-groups', 'ring-theory']"
1195216,Which way to calculate this probability is correct?,"There is an urn that contains $N$ balls. Each ball might be either white or blue. I dont know how many white balls are in the urn, but my prior is that a ball is blue with probability $b$. Someone iterates through the blue balls and, for each ball independently, they either show it to me, with probability $p$, or they don't. What is the probability that I am shown $v$ balls? Solution 1:
$Pr=\sum\limits_{i=0}^{N}{N\choose i}b^{i}(1-b)^{N-i}{i\choose v}p^{v}(1-p)^{i-v}.$ Solution 2:
$Pr={N \choose v}(bp)^v(1-bp)^{N-v}.$ I wish the second one is correct, but it must be wrong. Why?",['probability']
1195238,Epsilon-Delta Proof of Divergence of $S_n = (-1)^n*n$,"I am self-learning Analysis (reading Spivak's Calculus) but I found this problem in Ross' Elementary Analysis that I found interesting. However, I am having some difficulty proving the statement. It is: Show that the following sequence does not converge, $$ S_n = (-1)^n*n $$. I am attempting a proof via contradiction; ie: assume $ \exists $ a limit L $ \mid \forall \epsilon > 0, \exists $ N $ \in \mathbb{N} \mid n > $ N$ \implies |S_n - L| < \epsilon. \\ \implies |(-1)^nn - L| < \epsilon. $ Now i am stuck here because i am unsure which epsilon to choose and what to work towards in order to obtain my contradiction. Am I required to show that for all L $ \in \mathbb{R}$ that there is an $ \epsilon > 0 $ such that for any $ N > 0 $ there is an $ n > N $ such that $ |S_n - L| \ge \epsilon $? Any help is appreciated.","['analysis', 'epsilon-delta']"
1195243,Trigonometric equation; finding all solutions,I'm having a hard time with trigonometric equations. I need to find all solutions to the following equation: $$4\sin^2 θ=3$$ Any help will be appreciated.,['trigonometry']
1195250,For any sequence from Frechet spaces there exists a sequence that takes it to zero,"I am trying to prove following for Frechet spaces($X$): Show that any sequence $(x_n) \subset X$ there exists a sequence $(\lambda_n)$ with $\lambda_n \neq 0$, $\lambda_n \downarrow 0$ such that $\lambda_n x_n \to 0$ in $X$. But I don't really know how to start. I think need to show after $\exists N$ such that for $n>N$ $\lambda _n x_n$ is in a small neighborhood, but how to do this for any sequence from $X$. Or maybe there is a different way. Any help is appreciated.","['real-analysis', 'functional-analysis']"
1195285,Various evaluations of the series $\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)^3}$ [duplicate],"This question already has answers here : Sum : $\sum_{n=0}^\infty \frac{(-1)^n}{(2n+1)^3}$ (7 answers) Closed 4 years ago . I recently ran into this series:
$$\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)^3}$$ Of course this is just a special case of the Beta Dirichlet Function , for $s=3$. I had given the following solution:
$$\begin{aligned} 
1-\frac{1}{3^3}+\frac{1}{5^3}-\cdots &=\sum_{n=0}^{\infty}\frac{(-1)^n}{\left ( 2n+1 \right )^3} \\  
 &\overset{(*)}{=} \left ( 1+\frac{1}{5^3}+\frac{1}{9^3}+\cdots \right )-\left ( \frac{1}{3^3}+\frac{1}{7^3}+\frac{1}{11^3}+\cdots \right )\\  
 &=\sum_{n=0}^{\infty}\frac{1}{\left ( 4n+1 \right )^3} \; -\sum_{n=0}^{\infty}\frac{1}{\left ( 4n+3 \right )^3} \\  
 &= -\frac{1}{2\cdot 4^3}\psi^{(2)}\left ( \frac{1}{4} \right )+\frac{1}{2\cdot 4^3}\psi^{(2)}\left ( \frac{3}{4} \right )=\frac{1}{2\cdot 4^3}\left [ \psi^{(2)}\left ( 1-\frac{1}{4} \right )-\psi^{(2)}\left ( \frac{1}{4} \right ) \right ]\\ 
 &=\frac{1}{2\cdot 4^3}\left [ 2\pi^3 \cot \frac{\pi}{4} \csc^2 \frac{\pi}{4}  \right ] \\ 
 &=\frac{\pi^3 \cot \frac{\pi}{4}\csc^2 \frac{\pi}{4}}{4^3}=\frac{\pi^3}{32} 
\end{aligned}$$ where I used polygamma identities and made use of the absolute convergence of the series at $(*)$ in order to re-arrange the terms. Any other approach using Fourier Series, or contour integration around a square, if that is possible?","['sequences-and-series', 'calculus', 'polygamma', 'special-functions']"
1195286,"Show that there exists $a\in[0,1]$ such that $\frac{f''(a)}{f(a)}>0$","I would appreciate if somebody could help me with the following problem: Given that : (1) $f(x)$ is a twice differential function and $f''(x)$ is continuous on $\mathbb{R},$ (2) $\frac{f(1)}{f(0)}=\frac{f'(1)}{f'(0)}>0,$ and, (3) $f(x)f'(x)\neq 0. \; (0\leq x\leq 1).$ Show that: there exists $a\in[0,1]$ such that $$\frac{f''(a)}{f(a)}>0$$ I tried to consider MVT .But not getting the result!","['derivatives', 'real-analysis', 'functions']"
