question_id,title,body,tags
929411,"Question about the construction of lebesgue measure of $(0,1]$ (or: the Borel sigma algebra is generated by the half open intervals)","I am reading the book ""Probability with Martingales"" In this book, the author constructs lebesgue measure on (0,1] as follows. Let $F =$ the collection of subsets of $(0,1]$ which can be written as a finite union of $(a_i,b_i]$ Then, he claims that the $B((0,1]) = $ the sigma algebra generated by $F$. What makes me confused is that: Isn't $B((0,1])$ the sigma algebra generated by the open subsets of $(0,1]$? Then, why is it that any open set of $(0,1]$ is a member of the sigma algebra generated by F?
How do I know this? Conversely, why is it that an element of the sigma algebra generated by $F$, such as $(0,1/2]$ is a member of $B((0,1])$? Any clarification please?","['probability-theory', 'measure-theory']"
929414,first chern class of cotangent bundle,"If $X$ is a smooth variety, how do we see that $c_1(T_X^*)$ is the canonical divisor? I can see this for the projective space: if $X=\mathbb{P}^n$, then the Euler exact sequence 
$$
0\to O\to O(1)^{n+1}\to T_X\to 0
$$ gives $c_1(T_X)=(n+1)[H]$, and we know $\omega_X=O(-n-1)$. But how do we prove this in general?",['algebraic-geometry']
929415,What is global differential geometry?,"What is the difference between local and global differential geometry? I cannot find their (exact) definitions. There are some other terms in geometry like ""rigid"" (e.g. that structure is more rigid that the other one) which it seems they don't care to define. I think  I vaguely know what they mean but want to be sure.","['soft-question', 'big-picture', 'differential-geometry']"
929434,Derivative of spectral norm of symmetric matrix,"I want to calculate the derivative of the spectral norm of a symmetric square matrix $W$: $$
\frac{\partial}{\partial w_{ij}} \|W\|_2 
$$ How should I go about this?","['matrices', 'matrix-calculus', 'linear-algebra', 'spectral-norm', 'derivatives']"
929437,What does this quotient group $\frac{C^*}{R^+}$ represent?,"If $C^*$ and $R^+$ denote the multiplicative group of non zero complex numbers and the subgroup of positive reals, then what does the quotient group $\frac{C^*}{R^+}$ mean?",['group-theory']
929450,Doubts on Differentiation in $\mathbb{R}^p$,"I am currently reading R.G Bartle's ""Elements of Real Analysis"" for a one semester course in Advanced Real Analysis. In the chapter on Differentiation in $\mathbb{R}^p$, I am confused regarding the terminologies and the notations used. I list the basic doubts : $1$. What do you mean when you say derivative of $f:A\subseteq\mathbb{R}^p\to\mathbb{R}^q$ is a linear map L from $\mathbb{R}^p\to \mathbb{R}^q $ ? $2.$ What does the notation $Df(c)(u)$ mean ? $3$. What do you mean when you say partial derivative of f with respect to an arbitratry vector $u\in \mathbb{R}^p $ ? $4.$ Given $f(x) = \begin{cases}
\dfrac{xy^2}{x^2+y^2}, &\text{if }(x,y)\ne(0,0) \\
0, &\text{if }(x,y)=(0,0).
\end{cases}$ How is $D_{(a,b)}f(0,0)=\dfrac{ab^2}{a^2+b^2},(a,b)\ne(0,0 )?$ I need help in understanding these.  Thanks","['multivariable-calculus', 'real-analysis']"
929462,Why Riemannian metrics have to be smooth?,Why do Riemannian metrics have to be smooth? Can you give an example of a smooth curve with a none smooth metric and show me what possibly will go wrong if our metric is not smooth?,"['soft-question', 'riemannian-geometry', 'differential-geometry']"
929513,Topology vs Borel sigma-algebra on a set $X$,"What is the difference between: ($X$: a set) Topology (open set system) on $X$ Borel sigma-algebra on $X$ Both are a set of open subsets. Both include $X$ and empty set. Both are closed under union and intersection. They look like the same thing, right? Or  2. is the smallest sigma-algebra containing 1.?","['general-topology', 'measure-theory']"
929528,Additive but not $\sigma$-additive function,"Give an example of a measure space $(\Omega, \mathit{F})$ and a function $\mu$ on $\mathit{F}$ that is additive but not $\sigma$ -additive, i.e. $\mu(\cup A_i)= \sum\mu(A_i)$ for a finite collection of disjoint $A_i$ but not for some infinite collections. I know a measure function defined on $\sigma$ -algebra is $\sigma$ -additive, but I struggle finding a function that would not be additive for infinite collections. Can someone give me an example and show me why?","['probability-theory', 'measure-theory', 'real-analysis']"
929551,"If $f$ is continuous on $[a,b)$ and differentiable on $(a,b)$ such that $\lim_{x\to b^{-}}f(x)=\infty$, Then $f'$ is not bounded above in $(a,b)$.","I got this problem: Let $f$ be a continuous function on the interval $[a,b)$ and differentiable on the interval $(a,b)$, Prove that if $\lim_{x\to b^{-}}f(x)=\infty$, Then $f'$ is not bounded above in $(a,b)$. I tried some ways but none led me to a solution. Any help will be appreciated.","['calculus', 'derivatives', 'real-analysis', 'limits']"
929603,"The math behind generating Dungeons & Dragons ability scores: roll 4d6, toss lowest","D&D 5th ed. gives the following instructions for determining your “ability scores.” Roll four 6-sided dice and record the total of the highest three dice If I repeat the “roll-toss-and-total” 6 times (generating a set of 6 totals), what is the probability that my resulting set will contain 4 or more totals ≥ 10 and 3 or more totals ≥ 12 and 2 or more totals ≥ 15? Note that this problem contains and statements. I already figured out the probabilities the totals of these rolls. (3: 1/1296;  4: 1/324;  5: 5/648;  6: 7/432;  7: 19/648;  8: 31/648;  9: 91/1296;  10: 61/648;  11: 37/324;  12: 167/1296;  13: 43/324;  14: 10/81;  15: 131/1296;  16: 47/648;  17: 1/24;  18: 7/432) I can’t remember how to use these probabilities to ask more than basic questions. :-/","['dice', 'probability']"
929626,Is algebra over a set also algebra over a field?,"During my studies I have come across two different notions of the term ""algebra"", namely algebra over a set and algebra over a field ( the field its vector space always being Euclidean space in my case). While both of those concepts use the same term, I can't seem to find any relation between them, e.g. one being a sub-case of the other. Is there any such relation? Is there a reason why they are called the same?","['terminology', 'elementary-set-theory', 'abstract-algebra']"
929630,Relative countable weak$^{\ast}$ compactness and sequences,"I am finding serious difficulties in understanding some things about relative countable compactness and the use of sequences in proving it by my functional analysis text, Kolmogorov-Fomin's. For example, here in corollary 2 , it says that a subset of the space $E^{\ast}$ conjugate to a separable Banach space $E$ is bounded if it is relatively countably compact (as in definition 5 here ) in the weak$^{\ast}$ topology as a consequence of theorem 2' here . I would like to understand why, if $M$ is not bounded, it cannot be relatively countably compact, but from theorem 2' I only get that, if $\{f_n\}_n$ is not bounded, then it is not weakly$^{\ast}$ convergent: how can that prove that any infinite subset of $M$ has an accumulation point? My book, without giving a proof and treating it as trivial, might appear to treat countable compactness in the weak$^{\ast}$ topology as equivalent to the fact that any sequence has a a weak$^{\ast}$-convergent subsequence, but, if it is true, I am too stupid to see it as trivial, though I am not sure that it is true... If $M$ were a subset of a metric space I would know that $x$ would be an accumulation point of $M$ if and only if it were the limit of an eventually non-constant sequence of points belonging to $M$, but $E^{\ast}$ with the weak$^{\ast}$ topology is not a metric space (though a sphere centred in 0 is metrisable, but, if we do not a priori know that a subset $M$ is bounded...). I also think, thanks to what, and to who has written what, I read here , that if $E$ is a separable Banach space then every relatively weak$^{\ast}$-compact subset of $E^{\ast}$ is relatively sequentially weak$^{\ast}$-compact ( definition as here ), but here we only have countable weak$^{\ast}$-compactness... Does relative countable weak$^{\ast}$-compactness implies relative sequential weak$^{\ast}$-compactness? If it does, I see that if $M$ is not bounded, and infinite, we can chose from it a sequence $\{f_n\}$ (even such that $\forall i\ne j\quad f_i\ne f_j$, if we desire so) such that $\|f_n\|\to+\infty$, which, by theorem 2' , will not have any convergent subsequence. Then, if relative countable weak$^{\ast}$-compactness implied relative sequential weak$^{\ast}$-compactness, $M$ would not be countabye weak$^{\ast}$-compact, so that the ""only if part"" of corollary 2 , which is what causes some problems to me, would be proven. But I am far from being conviced that such implication is true... I uncountably thank you for any help! ;-)","['topological-vector-spaces', 'functional-analysis', 'banach-spaces']"
929632,Consecutive composite numbers,"When I took basic number-theory course there was this exercise to find 2000 consecutive numbers. And of course it's well known that the trick to take numbers of the form 
$$
(n+1)!+m, \quad 2 \leq m \leq n+1
$$
does the trick with $n=2000$. But these numbers are really huge which makes me think of the following question. Is there a better way to construct consecutive composite numbers? With better I mean that is there a way to find smaller consecutive composites for each $n$? Or even the smallest? Example: Smallest 3 consecutive composites are clearly $8,9,10$ but the formula gives us the numbers $26, 27, 28$ and even $14,15,16$ would be smaller. So I'm asking a way to find these smaller/smallest consecutive composites.",['number-theory']
929645,Discrete set of zeroes of polynomials must be finite?,"Let  $F:\mathbb C^n\to\mathbb C^n$ be a polynomial mapping (i.e. $n$ polynomials in $n$ variables). Suppose that $Z = \left\{z \in \mathbb C^n : F(z) = 0\right\}$ is a discrete set (all points are isolated). I think $Z$ must be finite. How to prove this? Also, is it true that a sufficient condition for $Z$ to be discrete is that $\det \left(\frac {\partial F_i}{\partial z_j}(z)\right) \ne 0$ for all $z \in Z$? I think this is true by the complex version of the Implicit Function Theorem (for instance, Proposition 1.1.11 in Complex Geometry - An Introduction by D. Huybrechts).","['algebraic-geometry', 'several-complex-variables', 'complex-analysis', 'polynomials']"
929669,Integration of product of functions(Special form),"Sir, I have been doing a proof related to one research topic. But after a long effort, I got ended up in a messy integration equation. Could you give me some suggestions to solve this equations? (Any method like substitutions etc are welcome). Kind of stucked my work because of this. I am giving you the integration equation as follows NB :: ""*"" notation also implies multiplication. Means $a \times b = ab=a*b$ Given Data in the question $   \lambda(t)  =   \left(\sqrt{\left( \frac{t}{2}A- a   \right )^2+\left(   \frac{t }{2}B- b   \right )^2+\left( \frac{t }{2}C- c    \right )^2} \right) \\= \sqrt{ \frac{t^2}{4}(A^2+B^2+C^2)-(Aa+Bb+Cc)t+(a^2+b^2+c^2)  }  \tag 1$ We here imply only positive square root. A,B,C,a,b and c are constants we cant alter the values. Only t is a variable here. 2.   $\phi(t)_0=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}A- a  \right)   \tag2$
                     $\phi(t)_1=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}B- b  \right)     \tag3$
  $\phi(t)_2=  \frac{sin \left(  \frac{t}{2}\lambda(t) \right)}{ \lambda(t)}*\left( \frac{t }{2}C- c  \right)     \tag2$ We have two  sets of questions. SET 1 is the original problem. I have added SET 2 as supplementary  because solving this will lead to the solution of SET 1. Any solution to either set 1 or set 2 is welcome. Main issue I face here is the difficulty to take out square root from sin . Note that A,B,C,a,b,c can have any real values. It is not necessary that the $\frac{t^2}{4}(A^2+B^2+C^2)-(Aa+Bb+Cc)t+(a^2+b^2+c^2) $ has equal roots Question SET 1 Is there anyway to solve $  \int \phi(t)_0 cos \left( \frac{t}{2}\lambda(t)\right) \ dt\tag 5$? Is there anyway to solve $  \int \phi(t)_0 \phi(t)_1 \ dt \tag 6$ ? Is there anyway to solve $  \int \phi(t)_1 \phi(t)_2 \ dt \tag 7$  ? SET 2 Is there anyway to solve $\displaystyle \int t^2\frac{\sin^2\left(t \sqrt{ at^2+bt+c}\right) }{   at^2+bt+c}  \operatorname{d}t \tag8$? Is there anyway to solve $\displaystyle \int t\frac{\sin^2\left(t \sqrt{ at^2+bt+c}\right) }{   at^2+bt+c } \operatorname{d}t \tag8$? Is there anyway to solve $\displaystyle \int t^2\frac{\sin \left(2\times t\sqrt{ at^2+bt+c}\right) }{   at^2+bt+c } \operatorname dt \tag8$? Is there anyway to solve $\displaystyle  \int t \frac{\sin \left(2\times t\sqrt{ at^2+bt+c}\right) }{ \sqrt{ at^2+bt+c}} \operatorname dt \tag8$? Some attempts currently I am trying Thinking about the possiblity of exponent expression of sin x and cos x  as here Thinking about the possibility of  product form results of sin xcos x  as here Thinking about substitution method by utilizing property $ax^2+bx+c =a \left(x+ \frac{b}{2a}\right)^2-\frac{b^2-4ac}{4a}$  as done here NB : So far I couldnot solve it. Main issue here is the square root inside trigonometric terms. It is difficult to convert it in to a solvable propblem Thanks for taking time to read my doubt. Hope nice suggestions and discussions","['calculus', 'integration', 'indefinite-integrals']"
929674,Which of the following groups are isomorphic (TIFR 2014)?,Which of the following groups are isomorphic? (a) $\mathbb{R}$ and $\mathbb{C}$ (b) $\mathbb{R}^*$ and $\mathbb{C}^*$ (c) $S_3\times \mathbb{Z}_4$ and $S_4$ (d) $\mathbb{Z}_2\times \mathbb{Z}_2$ and $\mathbb{Z}_4$ Here option (d) is not correct because one is not cyclic and other one is cyclic. Also $\mathbb{R}$ and $\mathbb{C}$ are vector space isomorphic (over the field $\mathbb{Q}$). But i cannot conclude correct answer help me!,"['group-theory', 'abstract-algebra']"
929690,Can any two disjoint nonempty convex sets in a vector space be separated by a hyperplane?,"Let $V$ be a normed vector space over $\mathbb{R}$, and let $A$ and $B$ be two disjoint nonempty convex subsets of $V$.
A geometric form of Hahn-Banach Theorem states that $A$ and $B$ can be separated by a closed hyperplane (i.e. there is $f \in V^\ast$ and $\alpha \in \mathbb{R}$ such that $f(a) \le \alpha, \forall a \in A$ and $\alpha \le f(b), \forall b \in B$) if either $A$ or $B$ is open, or $A$ is closed and $B$ is compact. (This statement is not in the full generality.) There are examples of two disjoint nonempty convex sets which cannot be separated by a closed hyperplane.(These convex sets don't satisfy the condition of the previous statement.) My question is: If the separating hyperplane need not be closed, can any pair of disjoint nonempty convex sets be separated by a hyperplane? More precisely, for any vector space $V$ over $\mathbb{R}$ and two disjoint nonempty convex subsets $A$ and $B$ of $V$, does there exist a linear functional $f:V\to\mathbb{R}$ and a real number $\alpha\in\mathbb{R}$ such that $f(a) \le \alpha, \forall a \in A$ and $\alpha \le f(b), \forall b \in B$? This question doesn't involve any topological concepts. For the finite dimensional case, it is known that the separation is possible. What would happen if the underlying space is infinite dimensional?","['convex-geometry', 'linear-algebra', 'functional-analysis']"
929719,Partition of a Matrix,"In Linear Algebra, we have been taught that the partition of a matrix $A$ consists of matrices,or blocks. In other words, its elements are matrices. This same, partitioned matrix, however is said to be equal to the original matrix. But their elements are different, as one contains scalars and the other matrices. Please help me understand.","['matrices', 'linear-algebra', 'block-matrices']"
929723,Using an identity to simplify the sum,So I ran into this problem today. It asks me to use an identity to simplify the sum. $$\sum_{j=7}^{27}\ln\left(\frac{j+1}{j}\right)$$ I have no idea where to start. I don't know any identity that fits this formation. Thanks.,"['logarithms', 'summation', 'algebra-precalculus']"
929735,(non)equivalence of definition of non-atomic measure for finitely additive measure,"For a measure space $(X, \mathscr{B} ,\mu )$here're two definitions of non-atomic measure: Definition1: For each $A \in \mathscr{B}$, $\mu(A)> 0$, there exists $ B \subset A$ such that $0 < \mu(B) < \mu(A)$. Definition2: For each $A \in \mathscr{B}$, $\mu(A)> 0$, for each $r \in (0,1)$ there exists $ B \subset A$ such that $\mu(B) = r\mu(A)$ The equivalence of two definitions for countably additive measure relies crucially on countable additivity to establish that $\sup_{A \in \mathscr B}\{\mu(A) \mid \mu(A) \leq \mu(X \setminus A)\}$ can be attained by some $A$. I think two definitions are probably not equivalent for finitely additive measure? Is there an example?",['measure-theory']
929738,"Is it true that $L^2$ is compactly embedded in $(W^{1,2}_{0})^{\ast}$?","Is it true that $L^{2}(\mathbb R^{n})$ is compactly embedded in $(W^{1,2}_{0}(\mathbb R^{n}))^{\ast}$ ? If so, how can I prove it? Context I've just started to study Functional Analysis. I tried to read some articles about embeddings in Sobolev spaces, but all I can find are the standard inequalities (like Sobolev inequality etc).","['sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
929755,equivalence relation,"I have the sets $X = \{0,1,2,3,4,5,6,7,8,9\}$ and $Y = \{0,2,4,6,8,9\} $
.In $\mathcal P(X)$ I define the equivalence relation such that $A\mathrel RB$ iff $A - Y = B - Y$. How many equivalence classes are there?or, cardinal of the quotient set $ \mathcal{P} (X)/R$? I know the cardinal value of the set $\mathcal{P} (X)/R$ is $16$ but I do not know how to get to this result.",['elementary-set-theory']
929788,Is the principal value of Argument differentiable at every nonnegative nonzero number?,"How do i show that argument is continuous at points except its branch cut? I posted a question to ask whether the principal value of Argument $Arg:\mathbb{C}\setminus \{0\}\rightarrow (-\pi,\pi]$ is continuous at every nonnegative nonzero number. Then, vladimirm answered my question so now I'm checking his argument. However, I'm not sure that whether the function $Arg$ is differentiable at every nonnegative nonzero number. Is it differentiable? Then how do i prove it?","['continuity', 'complex-analysis']"
929794,Triplet prime reciprocal series,"Does any body know if the series of reciprocals of triplet primes of form $p, p+2, p+6$ or $p, p+4, p+6$ converges or diverges? Could this be used as a proof of infinity of twin primes?",['number-theory']
929832,Simple differentiation from first principles problem,"I know this is really basic, but how do I differentiate this equation from first principles to find $\frac{dy}{dx}$: $$
y = \frac{1}{x}
$$ I tried this: $$\begin{align}
f'(x) = \frac{dy}{dx} & = \lim_{\delta x\to 0} \left[ \frac{f(x + \delta x) - f(x)}{\delta x} \right] \\
& = \lim_{\delta x\to 0} \left[ \frac{(x+\delta x)^{-1} - x^{-1}}{\delta x} \right] \\
& = \lim_{\delta x\to 0} \left[ \frac{1}{\delta x(x + \delta x )} - \frac{1}{x(\delta x)} \right] \\
& = \lim_{\delta x\to 0} \left[ \frac{1}{x(\delta x)} + \frac{1}{(\delta x)^2} - \frac{1}{x(\delta x)} \right] \\
& = 1
\end{align}$$ which is obviously wrong, since $f'(x) = - \frac{1}{x^2}$. Where am I going wrong?","['calculus', 'derivatives']"
929882,"What is wrong with my algorithm for finding how many positive integers are divisible by a number d in range [x,y]?","I have been solving basic counting problems from Kenneth Rosen's Discrete Mathematics textbook (6th edition) .  These come from section 5-1 (the basics of counting), pages 344 - 347. This question is not specifically about finding an answer to a problem or being given the correct equation, but whether my reasoning is sound.  Therefore I would find it hard to argue this is a duplicate of seemingly similar questions like this one or this one . The problems I have been dealing with come of the form How many positive integers in range [x,y] are divisible by d? All additional questions are based on the composition of the information learned in these, e.g. how many positive integers in range [x,y] are divisible by d or e? To answer the simple question I wrote this ""equation/algorithm,"" which takes as input an inclusive range of positive integers $[x,y]$ and a positive integer $d$, and returns $n$, the total number of positive integers in range $[x,y]$ which are divisible by $d$. (1) $n = \left \lfloor{\frac{y}{d}}\right \rfloor - \left \lfloor{\frac{x}{d}}\right \rfloor$ The idea is that in order to count how many positive integers are divisible by $d$ from $[1,m]$, we simply calculate $\left \lfloor{\frac{m}{d}}\right \rfloor$, because every $dth$ positive integer must be divisible by $d$.  However, this does not work when given a range $[x,y]$ where $x \not= 1$ or when $x > 1$.  So we need to subtract the extra integers we counted, which is $\left \lfloor{\frac{x}{d}}\right \rfloor$, i.e. the number of positive integers divisible by $d$ from $[1,x]$. For a sanity check, I also wrote a brute force algorithm that does a linear search over every positive integer in the range $[x,y]$ and counts it if $x \text{ mod } d == 0$.  It also can list out the integers it picked, in case I am feeling really paranoid. With (1) I've been getting the correct answers except on this problem/input: How many positive integers between 100 and 999 inclusive are odd? My solution was to calculate how many are even, and subtract this from the total number of positive integers in range $[100,999]$.  To find the evens I simply use the algorithm in (1): $\left \lfloor{\frac{999}{2}}\right \rfloor - \left \lfloor{\frac{100}{2}}\right \rfloor = 499 - 50 = 449$ But this answer is wrong, since there actually $450$ even numbers in range $[100,999]$ by the brute force algorithm.  (1) is somehow counting off by 1.  My question is, why is (1) failing for this input of $(2, [100,999])$ but so far it's worked on every other input?  What do I need to do to fix (1) so it produces the correct answer for this case?  Perhaps I'm actually over counting because $x$ should actually be $x - 1$? (1') $n = \left \lfloor{\frac{y}{d}}\right \rfloor - \left \lfloor{\frac{x - 1}{d}}\right \rfloor$ (1') returns the correct answer for this specific input now, but I am not sure if it will break my other solutions.","['discrete-mathematics', 'divisibility']"
929924,"If $A^n = I$, $n$ odd, $A$ a square integer matrix, does $A = I$?","Edit: Crap, even my hypothesis was wrong. If you put $A = \left[ \begin{array}{cc} 1&-1\\3&-2 \end{array} \right]$, then $A^3 = I$ but no eigenvalue is $1$. (What's true is that all eigenvalues are $n$th roots of unity.) I ask this because I believe it might resolve a trickier problem I'm working on in a simple way. Obviously this is false if $n$ is even, but I have no counterexample if $n$ is odd. Indeed, if $x$ is an eigenvector of $A$, $$A^nx = \lambda^nx = Ix = x \implies \lambda = 1 $$ so $\lambda = 1$ is the only eigenvalue of the matrix. This says $\operatorname{trace}(A) = n$ and $p(\lambda) = (1 - \lambda)^n$. (Trivially, $\det(A) = 1$ from the multiplicativity of the determinant.) (Incidentally, I am aware that there is a subtlety here in assuming a real eigenvector exists, since the rotation-by-$90^{\circ}$ matrix satisfies $A^4 = I$ and has none; but it seems that the condition that $A^n = I$ for odd $n$ may take care of this problem.) How can we prove this, in a fairly simple way? (If the proof is complicated, I'm still game, but it's probably not the intended solution to my original problem.)","['matrices', 'linear-algebra', 'determinant']"
929958,What is the derivative of a Radial Basis Interpolation function?,"A radial basis interpolation function is described as: $
f(\textbf{x})=\sum_{k=1}^N c_k \phi(\lVert \textbf{x}-\textbf{x}_k \rVert_2), \ \textbf{x}\in\mathbb{R}^s
$ where $\textbf{x}_k$ are the $N$ scattered points and $c_k$ are the coefficients of the function obtained by solving the linear system: $
\begin{bmatrix}
f(\textbf{x}_1) \\ f(\textbf{x}_2) \\ \vdots \\ f(\textbf{x}_N) 
\end{bmatrix}
=
\begin{bmatrix}
\varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_1\rVert} - \frac{1}{\lVert\textbf{x}_{1}\rVert} \right\rvert\right)  &  \varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_1\rVert} - \frac{1}{\lVert\textbf{x}_{2}\rVert} \right\rvert\right)  & \ldots & \varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_1\rVert} - \frac{1}{\lVert\textbf{x}_{N}\rVert} \right\rvert\right)   \\ 
\varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_2\rVert} - \frac{1}{\lVert\textbf{x}_{1}\rVert} \right\rvert\right)  & \varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_2\rVert} - \frac{1}{\lVert\textbf{x}_{2}\rVert} \right\rvert\right) & \ldots & \varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_2\rVert} - \frac{1}{\lVert\textbf{x}_{N}\rVert} \right\rvert\right)  \\
\vdots & \vdots & \ddots & \vdots \\
\varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_N\rVert} - \frac{1}{\lVert\textbf{x}_{1}\rVert} \right\rvert\right)  & \varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_N\rVert} - \frac{1}{\lVert\textbf{x}_{2}\rVert} \right\rvert\right)  & \ldots & \varphi\left(\left\lvert \frac{1}{\lVert\textbf{x}_N\rVert} - \frac{1}{\lVert\textbf{x}_{N}\rVert} \right\rvert\right)  \\
\end{bmatrix}
\begin{bmatrix}
c_1 \\ c2 \\ \vdots \\ c_N
\end{bmatrix}
$ The radial basis function $\phi$ can be a Gaussian, an inverse multiquadric, etc. For a Gaussian, we get: $
\phi(x) = e^{-(\epsilon x)^2}
$ for some free parameter $\epsilon$ How do you find the derivative of the function and is it well-defined on all values or do we get into zero-denominator situations? for example, what is $\frac{df(x)}{dy}$ if $\textbf{x}\in\mathbb{R}^2$?","['interpolation', 'partial-derivative', 'derivatives']"
929963,Show: $\max_{|z|=R} \operatorname{Re}\left(z\frac{f'(z)}{f(z)}\right) \geq N $,"Let $f$ be a holomorphic function defined in a neighbourhood of $\overline{D(0,R)}$ which has no zero on $\partial D(0,R).$ Let $N$ be number of zeros of $f$ in $D(0,R).$ Show: $\max_{|z|=R} \operatorname{Re}\left(z\dfrac{f^{\prime}(z)}{f(z)}\right) \geq N \ $ My attempt: $\begin{align}\int_{|z|=R}\operatorname{Re}\left(z\dfrac{f^{\prime}(z)}{f(z)} \right) dz+ i\int_{|z|=R}\operatorname{Im}\left(z\dfrac{f^{\prime}(z)}{f(z)} \right)dz\end{align}=2\pi i \sum^{n}_{i=1}\alpha_{i} a_i,$ where $a_i$ is zero of $f$ and $\alpha_i$ is the corresponding multiplicity and $\alpha_1+...+\alpha_n = N.$ Could anyone advise me on how to proceed from here? Thank you.",['complex-analysis']
929969,Fundamental group of two tori with a circle ($S^1✕${$x_0$}) identified,"Compute the fundamental group of the space obtained from two tori $S^1✕S^1$ by identifying a circle $S^1✕$ { $x_0$ } in one torus with the corresponding circle $S^1✕$ { $x_0$ } in the other. Using van Kampen's theorem, I can fairly quickly show that if $T_1$ is one torus and $T_2$ is the other, then the group has to be isomorphic to $((π_1(T_1) ∗ π_1(T_2)))/N ≅ (\mathbb{Z} ✕ \mathbb{Z})∗ (\mathbb{Z} ✕ \mathbb{Z})/N$ , where N is generated by elements of the form $i_{12}(w)i_{21}(w)^{-1}$ , w is in $\pi_1(S^1✕$ { $x_0$ } $) ≅ \mathbb{Z}$ and $i_{12}$ , $i_{21}$ are the maps from $\pi_1(S^1✕$ { $x_0$ } $)$ to $π_1(T_1)$ , $π_1(T_2)$ respectively determined by inclusion. My problem is, as it seems to always be with van Kampen-related problems, figuring out what the elements of N look like. My attempt to do this in a pure-algebra way, as far as I can tell, failed me: I tried examining the case where w represents a loop that goes n (some integer) times around the circle, but then it seems like $i_{12}(w)$ "" $=$ "" $(n, 0)$ in $T_1$ and $i_{21}(w)$ "" $=$ "" $(n, 0)$ in $T_2$ , which says to me that $i_{12}(w)i_{21}(w)^{-1} $ "" $=$ "" $ (n, 0) + (-n, 0) = 0$ . The notation here isn't right, since $(n, 0)$ in $T_1$ is not the same as $(n, 0)$ in $T_2$ and their addition (composition?) shouldn't be written quite that way, hence my quotes around the equals signs, but certainly no loop in $S^1✕$ { $x_0$ } is going to magically include anything but the 0 loop in either torus's second component, right? But this doesn't seem right to me, since if a, b are the generators of the circles in $T_1$ and d, e are the generators of the circles in $T_2$ , and c is the constant path then the identification of the circle should make, say, $a = d$ , so for example $(a, b)*(d, e)$ $ = (a^2,b)*(c, e)$ $ = (c, b)*(d^2,e)$ . This doesn't match with what I just worked out N might be, but I also can't figure out what N should look like to make this equivalence make sense. My attempt to understand this geometrically has gone even worse. What I know for sure is that the resulting figure isn't the ""2-torus"", 2 tori glued together at a disc. What I don't know for sure is whether this identification should actually create the hypertorus $S^1✕S^1✕S^1$ or something completely different.","['general-topology', 'algebraic-topology']"
929973,Why aren't exact differential equations considered PDE?,"Exact differential equations come from finding the total differential from some multivariable function. In the exact differential equation $M\mathrm{d}x+N\mathrm{d}y=0$ M and N are considered to be partial derivatives of some potential function... So why aren't exact differential equations considered PDEs? After all, you're finding the potential function given it's partial derivatives... Thanks.",['ordinary-differential-equations']
930000,Calculating a harmonic conjugate,"Is the following reasoning correct? Determine a harmonic conjugate to the function \begin{equation} f(x,y)=2y^{3}-6x^{2}y+4x^{2}-7xy-4y^{2}+3x+4y-4 \end{equation} We first of all check if $f(x,y)$ is indeed a harmonic function. This amounts to show $f(x,y)$ satisfy the two-dimensional Laplace equation \begin{equation}
\frac{\partial^{2 }f}{\partial x^{2}}+\frac{\partial^{2} f}{\partial y^{2}}=0 \tag{1}
\end{equation} We have $\frac{\partial^{2}f}{\partial x^{2}}=8-12y$ and $\frac{\partial^{2} f}{\partial y^{2}}=12y-8$ . Thus, (1) is fulfilled, and so $f(x,y)$ is harmonic. Next, we seek to determine a harmonic conjugate to the given function. Let $u(x,y)=2y^{3}-6x^{2}y+4x^{2}-7xy-4y^{2}+3x+4y-4$ . \begin{equation*}
u_{x}=v_{y} \iff -12xy+8x-7y+3=v_{y}
\end{equation*} Integrate with respect to $y$ \begin{equation}
v=-6xy^{2}+8xy-\frac{7}{2}y^{2}+3y+h(x) \tag{2}
\end{equation} where $h(x)$ is a function of $x$ alone. To determine this, we use the second Cauchy-Riemann equation $v_{x}=-u_{y}$ \begin{align*}
-u_{y}=v_{x} &\iff 6x^{2}+7x-6y^{2}+8y-4=h'(x)-6y^{2}+8y \\
&\iff h'(x)=6x^{2}+7x-4
\end{align*} Integrating with respect to $x$ we have \begin{equation}
h(x)=2x^{3}+\frac{7}{2}x^{2}-4x+C
\end{equation} where $C$ is an arbitrary constant. Therefore, if we let $C=0$ , then one harmonic conjugate of $u$ is given as: \begin{equation}
v=2x^{3}+\frac{7}{2}x^{2}-6xy^{2}+8xy-4x-\frac{7}{2}y^{2}+3y
\end{equation}","['harmonic-functions', 'self-learning', 'complex-analysis']"
930009,Counting the Number of Points in an Algebraic Variety,"How can we count the number of points in $$S = \{(x,y) \in \mathbb{Z_m}^2: x^2+ky^2 = c\}$$ where $k,c$ are some positive integers?","['algebraic-geometry', 'combinatorial-number-theory', 'number-theory']"
930011,Closed-forms for several tough integrals,"These integrals came up in the process of finding solution to Vladimir Reshetnikov's problem . I wonder if there are closed-forms for the following integrals:
\begin{array}{1,1}
&[\text{1}] &\quad\int_0^1\frac{\operatorname{Li}_3(ax)}{1+2x}\ dx\\[12pt]
&[\text{2}] &\quad\int_0^1\frac{\operatorname{Li}_2(ax)\ln x}{1+2x}\ dx\\[12pt]
&[\text{3}] &\quad\int_0^1\frac{\ln(1-ax)\ln^2 x}{1+2x}\ dx
\end{array}
I have tried many substitutions, integration by parts, or differentiation under integral sign method, but without success so far. I do not need a complete or rigorous answer and your answer can be only Mathematica 's or Maple 's output since I don't have those software packages in my computer or links of related papers. I'd be grateful for any help you are able to provide.","['improper-integrals', 'closed-form', 'calculus', 'integration', 'definite-integrals']"
930017,$\tan \left(\sec ^{-1}(x)\right)$,"$$\tan \left(\sec ^{-1}(x)\right)$$ I know that sec(?)=$\frac{x}{1}$ and that sec=hyp/adj, therefore I conclude that hyp=x and adj=1 and that op=$\sqrt{x^2-1}$ Since Tan = opp/adj I thought the answer was the same as op. However I do not understand how this is done? cause my conclusion is wrong! The answer provided is this:","['trigonometry', 'calculus']"
930023,The Freyd-Mitchell Embedding Theorem and projective (injective) objects,"Given a small abelian category $\mathcal{A}$, the Freyd-Mitchell Embedding Theorem gives me a fully faithful exact functor $F:\mathcal{A}\rightarrow R$-$\mathsf{Mod}$, for some unital ring $R$, so that, in particular, $\mathcal{A}$ is equivalent to a full subcategory of $R$-$\mathsf{Mod}$. Wikipedia states However, projective and injective objects in $\mathcal{A}$ do not necessarily correspond to projective and injective $R$-modules. Given that the definition of projective objects is entirely categorical in nature, how could it be that the notions of projective in each category do not correspond to each other in equivalent categories?  Is this because the projective objects in a full subcategory of $R\mathsf{Mod}$ are sometimes different than the projective objects in all of $R$-$\mathsf{Mod}$? (Of course, you can everywhere replace ""projective"" with ""injective"" in the above.)","['abstract-algebra', 'homological-algebra', 'category-theory', 'modules', 'abelian-categories']"
930031,Every finite dimensional representation of an algebra has an irreducible sub representation,"Let $V$ be a nonzero finite dimensional representation, i.e we have a homomorphism $\rho\colon A\rightarrow \text{End}_k(V)$, of an algebra $A$. I have to show that there is an irreducible sub representation. This is how wanted to do that: Let $v\in V$ and look at $W=\text{span}\{\rho(a)(v)\colon a\in A\}$. This is a lineair subspace of $V$ and by construction it is a sub representation. But it is not irreducible yet. I thought I should continue this process, so take again another vector in $W$ and consider the same construction of a sub representation. I don't understand how I should continue this or if this is going to help me solve this problem. I should also use somewhere the finiteness of the representation as it does not hold for infinite dimensional representations. I need help. Thanks.",['abstract-algebra']
930043,Second order ODE $y''+p(t)y'+q(t)y=0$,"Let consider ordinary differential equation of the form $$t^2y''+3ty'+y=0$$ This is equivalent to $$y''+\frac{3}{t}y'+\frac{1}{t^2}y = 0$$
which looks better. But how does one find the solutions here? I guessed one of them is $y(t)=\frac{1}{t}$, but guessing shouldn't be the method here. I feel as though I needed a smart substitution. Any hints?",['ordinary-differential-equations']
930065,Set containing all rings!,Does there exist a set containing all rings ? Possible idea :I think such set is not possible.If S is a set containing all rings i think we can again define a structure on S to make it Ring and that is a contradiction because S cannot contain itself.,"['ring-theory', 'elementary-set-theory', 'abstract-algebra']"
930069,Finding $\int_{0}^{1} \frac{\log(1+x)}{1+x^2} {\rm d}x$ by differentiating under the integral sign.,"I've tried to find this integral by the method already outlined in the title. I decided to let $$ \displaystyle  I(\alpha) = \int_{0}^{1} \dfrac{\log(1+\alpha x)}{1+x^2} \text{ d}x. $$
From this integral, I differentiated the equality with respect to $\alpha$ and performed a partial fraction decomposition on the resulting integral. $$\begin{aligned} I'(\alpha) \ \ & = \int_{0}^{1} \dfrac{\partial}{\partial \alpha} \left( \dfrac{\log(1+\alpha x)}{1+x^2} \right) \text{ d}x \\ & = \int_{0}^{1} \dfrac{x}{(1+\alpha x)(1+x^2)} \text{ d}x \\ & = \dfrac{-\alpha}{1+\alpha^2} \int_{0}^{1} \dfrac{1}{1+\alpha x} \text{ d}x + \dfrac{1}{1+\alpha^2} \int_{0}^{1} \dfrac{x+\alpha}{1+x^2} \text{ d}x \\ & = \dfrac{-1}{1+\alpha^2} \log \left| 1+\alpha x\right| \Big|_{\ x=0}^{\ x=1} + \dfrac{1}{2(1+\alpha^2)} \log \left( 1+x^2 \right) \Big|_{\ x=0}^{\ x=1} + \dfrac{\alpha}{1+\alpha^2} \arctan x \Big|_{\ x=0}^{\ x=1} \\ & = \dfrac{-\log \left| 1 + \alpha \right|}{1+\alpha^2} + \dfrac{\log(2)}{2(1+\alpha^2)} + \dfrac{\alpha \pi}{4(1+\alpha^2)} \end{aligned} $$ Integrating this equality with respect to $\alpha$, I get something along the lines of. $$\begin{aligned} I(\alpha) \ \ & = - \int \dfrac{-\log \left| 1 + \alpha \right|}{1+\alpha^2} \text{ d}\alpha + \dfrac{\log(2)}{2} \arctan \alpha + \dfrac{\pi}{8} \log(1+\alpha^2) + \mathcal{C} \end{aligned}$$ Where $\mathcal{C}$ is a constant of integration to be found. Now from here on in, I'm unsure of how to perform integration by parts on the integral in the final line, with $u=\log|1+\alpha|$ so that I can finish the integral off. Any help would be greatly appreciated!","['integration', 'logarithms', 'trigonometry', 'partial-derivative', 'derivatives']"
930095,Infinitely many $n \in \mathbb{N}$ such that $\mu(n) + \mu(n+1) = 0 $.,"I try to show that there are infinitely many numbers $n \in \mathbb{N}$ such that $\mu(n) + \mu(n+1) = 0 $. What I did We write $\mathcal{P}$ for the set of prime numbers. 
We need to show that one of the following sets is infinite:
$$
A \quad = \quad 
\{ n \ : \ \exists p,q \in \mathcal{P}, \ p^2|n \ \text{ and }  \ q^2 | (n+1) \   \}
$$
$$
B \quad = \quad
\{ n \ : \ \omega(p)=-\omega(q) \text{ and $p,q$ are square free} \}
$$ There are no upper bounds for the sets 
$\mu^{-1}(\{ -1\}), \ \mu^{-1}(\{ 0\}), \ \mu^{-1}(\{ 1\})$. I find it very hard to say something about $n+1$, given that we have the factorisation of $n$. All I know is that $p | n  \ \Rightarrow \ p \nmid n+1$. Could you give me a hint to show that either $A$ or $B$ is infinite? Please don't give a full answer. Attempt to use the hint I got I understand that we can choose $x$ as big as we need. Obviously, $x^p$ as divided be some square prime. Here I try to show that $x^p +1 $ is not squarefree.  We know that $x+1 \ | \ x^p+1$, and
$p \ | \ x+1$ so $p \ | \  x^p+1$. Now we need to show that $$
p  \ | \  \frac{x^p+1}{x+1}
$$
We have in $\mathbb{F}_p$ that
$$
\frac{x^p+1}{x+1} \ = \ \frac{(x+1-1)^p+1}{x+1} 
\ = \ \frac{(x+1)^p + (-1)^p + 1}{x+1} = (x+1)^{p-1} \ = \ 0
$$
as required.",['number-theory']
930103,A smooth function $f:S^1\times S^1\to \mathbb R$ must have more than two critical points.,"I am trying to show that a smooth function $f:S^1\times S^1\to \mathbb  R$ must have more than two critical points. Since $f$ attains maximum and minimum, it must have at least two critical points. How would one show that they can't be two? If one considers the gradient vector field $\nabla f$ then by the Poincare Hopf index theorem its index is equal to the Euler characteristic of the torus, i.e. it is $0$. Therefore $\nabla f$ has an even number of zeros. This question has been posted here but it hasn't been answered.",['differential-geometry']
930111,Show that there exists an uncountable family of sets,"Show that there exists an uncountable family of uncountable sets $(X_t)_{t\in T}$ such that for any $t_1,t_2\in T$, $t_1\ne t_2$ the set $X_{t_1}\cap X_{t_2}$ consists of only one element, but for any three pairwise different $t_1,t_2,t_3 \in T$ it is $X_{t_1}\cap X_{t_2} \cap X_{t_3} = \emptyset$ Any idea how to tackle it?",['elementary-set-theory']
930151,How to Solve $ \int \frac{dx}{x^3-1} $,"I am having quite a difficult time integrating $$
\int  \frac{\mathrm{d}x}{x^3-1}
$$ My first approach was to apply a partial fraction decomposition $$
\int \frac{\mathrm{d}x}{x^3-1} = \int \frac{\mathrm{d}x}{(x-1)(x^2+x+1)} = \frac{1}{3} \int \frac{\mathrm{d}x}{x-1} - \frac{1}{3} \int \frac{x+2}{x^2+x+1}\mathrm{d}x$$ The first term is simple enough to integrate but I can't figure out the second.  I've tried each of the integration tricks in my arsenal, integration of parts gives a more complex equation, a trigonometric substitution doesn't seem to get me anywhere, and lastly I'm not sure what to do with a u-substitution since if $ u = x^2+x+1 $ then $ \mathrm{d}u = (2x+1)\mathrm{d}x \neq (x+2)\mathrm{d}x $.  And further breaking up the formula further doesn't seem to eliminate these problems. My last effort was to get a solution from Wolfram and try to reverse engineer it by taking the derivative $$
\frac{\mathrm{d}}{\mathrm{d}x} \left( - \frac{1}{6} \ln (x^2+x+1) + \frac{1}{3} \ln (1-x) - \frac{\sqrt{3}}{3} \tan ^{ - 1} \left( \frac{2x+1}{\sqrt{3}} \right) \right)
$$ from which I got $$
\frac{1}{3(1-x)} - \frac{1}{2(x^2 + x + 1)} - \frac{2x+1}{6x^2 + 6x + 6}
$$ However I can't seem to figure out the method or motivation for the fraction decomposition. I'm I missing something really obvious or am I missing a tool of integration?  Thank you very much for your help! From the first answer suggesting completing the square I believe I was able to figure the rest out. One then gets a difference of squares and can then use a trigonometric substitution where $$ x + \frac{1}{2} = \frac{\sqrt{3}}{2} \tan \theta $$ the answer I got is $$
\frac{1}{3} \ln |x-1| - \frac{1}{6} \ln(x^2+x+1) - \frac{\sqrt{3}}{3} \tan ^{ - 1} \left( \frac{2x+1}{\sqrt{3}} \right) + C
$$ My last confusion is the discrepancy in the solutions. Wolfram's second term seems to be undefined over $ (1, \infty) $, whereas I believe that $$
\int  \frac{\mathrm{d}x}{x^3-1}
$$ should be defined over that interval.","['calculus', 'integration', 'indefinite-integrals']"
930157,A topological space is extremally disconnected iff every two disjoint open sets have disjoint closures,"Show that for any topological space $X$ the following are equivalent: $X$ is extremally disconnected Every two disjoint open sets in $X$ have disjoint closures. My attempt at a solution Assume every two disjoint open sets in $X$ have disjoint closures.
Let A open in $X$, $A$ and $X \setminus \overline{A} $  disjoint open set
$\overline{A} \cap (\overline{X \setminus \overline{A}} )= \emptyset$, $(\overline{X \setminus \overline{A}} ) \subset X \setminus \overline{A}$,
which implies that $X \setminus \overline{A}$ is closed in $X$. Thus $\overline{A}$ is open in $X$. So we obtain $X$ is extremally disconnected. Otherwise Let $X$ is extremally disconnected. Then the closure of every open set is open.
 So $X$ is completely separated. Let $A$, $B$ two disjoint open sets.  Then there exist a continuous function $g:X \rightarrow [0,1]$ such that  $g(A)=0$, $g(B)=1$ How can I continue?","['general-topology', 'connectedness']"
930186,Why is this function a really good asymptotic for $\exp(x)\sqrt{x}$,"$$f(x)=\sum_{n=0}^{\infty} a_n x^n\;\;\;\;\; a_n = \frac{1}{\Gamma(n+0.5)}$$ Why is this entire function a really good asymptotic for $\exp(x)\sqrt{x}$, where for large positive numbers, $f(x)\exp(-x) \approx \sqrt{x}$? As |x| gets larger, the error term is asymptotically $f(x)-\exp(x)\sqrt{x} \approx \frac{1}{x\cdot\Gamma(-0.5)}$, and the error term for $f(x)\exp(-x) - \sqrt{x} \approx \frac{\exp(-x)}{x\cdot \Gamma(-0.5)}$.  If we treat $f(x)$ as an infinite Laurent series, than it does not converge. I stumbled upon the result, using numerical approximations, so I can't really explain the equation for the $a_n$ coefficients, other than it appears to be the numerical limit of a pseudo Cauchy integral for the $a_n$ coefficients as the circle for the Cauchy integral path gets larger.  I suspect the formula has been seen before, and can be generated by some other technique.   By definition, for any entire function $f(x)$, we have for any value of real r:
$$a_n = \oint x^{-n} f(x) = \int_{-\pi}^{\pi} \frac{1}{2\pi} (re^{-ix})^{-n} f(re^{ix}) )\; \mathrm{d}x\;\;$$ 
The conjecture is that this is an equivalent definition for $a_n$, where $f(x) \mapsto \exp(x)\sqrt{x}$ and $x \mapsto re^{ix}$.
$$a_n =\lim_{r\to\infty} \int_{-\pi}^{\pi} \frac{1}{2\pi} (re^{-ix})^{-n}\exp(re^{ix})\sqrt{re^{ix}})\; \mathrm{d}x = \frac{1}{\Gamma(n+0.5)}   $$","['logarithms', 'exponential-function', 'asymptotics', 'gamma-function', 'complex-analysis']"
930205,Space of oriented lines in $\mathbb{R}^{n+1}$ as symplectic quotient.,"I've been working out a nice example of symplectic reduction, and have come to a solution only after quite a lot of effort. So I was wondering if anyone knew a more straightforward route to the answer. This example is about the space of oriented lines in $\mathbb{R}^{n+1}$. Start by considering the symplectic manifold $(\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}, dp_{i} \wedge dq_{i})$, where $(q_{i},p_{i})$ are the coordinates on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$. We let $\mathbb{R}$ act on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ as follows:
\begin{equation}
t \ast (q,p) = (q+tp, p).
\end{equation}
This action is evidently symplectic. Then define the following moment map 
\begin{equation}
\mu : \mathbb{R}^{n+1} \times \mathbb{R}^{n+1} \to \mathbb{R}, \ \ \ \ (q,p) \mapsto \frac{1}{2}(|p|^2 - 1).
\end{equation}
The symplectic quotient is the space $(\mu^{-1}(0)/\mathbb{R}, \omega_{r})$, where $\omega_{r}$ is the reduced symplectic form, which is the unique symplectic form on the quotient $\mu^{-1}(0)/\mathbb{R}$, satisfying
\begin{equation}
\pi^{*}(\omega_{r}) = \iota^{*}(dp_{i} \wedge dq_{i}),
\end{equation}
where $\pi : \mu^{-1}(0) \to \mu^{-1}(0)/\mathbb{R}$ is the orbit projection map, and $\iota : \mu^{-1}(0) \to \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ is the inclusion. We have the following interpretation of the resulting space:
If we restrict to $|p| = 1$, then $p$ specifies a direction in $\mathbb{R}^{n+1}$. The coordinate $q$ specifies a point in $\mathbb{R}^{n+1}$. Therefore, the pair $(q,p)$ singles out the line passing through $q$ in the direction of $p$. Hence $\mu^{-1}(0)$ consists of all the directed lines in $n+1$ dimensional space. However, there is a degeneracy: pairs $(q,p)$, where the $q$ lie along the same line, all pick out the same oriented line. In fact, our action of $\mathbb{R}$ is a symmetry of this interpretation because all points $t \ast (q,p)$ correspond to the same line; each orbit corresponds to a single line. Therefore $\mu^{-1}(0)/\mathbb{R}$ is the space of oriented lines. Now we want to describe the geometry of this space, and to do so we should pick a representative from each orbit. The natural choice for each line is to pick the closest point to the origin. Given a line specified by $(q,p)$, this point is $(q - (q \cdot p)p, p)$. Note that $(q - (q \cdot p)p) \cdot p = 0$. The two coordinates of this representative are orthogonal.
So if we define $N$ to be the following embedded submanifold of $ \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$:
\begin{equation}
N = \{ (q,p) \in  \mathbb{R}^{n+1} \times \mathbb{R}^{n+1} \ | \ |p| = 1, \ q \cdot p = 0\},
\end{equation}
then we can describe the orbit projection map $\pi$ as the smooth submersion
\begin{equation}
\pi : \mu^{-1}(0) \to N, \ \ (q,p) \mapsto (q - (q \cdot p)p, p).
\end{equation} Now note that the image $N$ is nothing but the tangent bundle of the n-sphere $TS^n$, and that this is isomorphic to the cotangent bundle of the n-sphere $T^{*}S^{n}$. I want to show that in fact, $N$ is symplectomorphic to $T^{*}S^{n}$ with the canonical symplectic structure ( http://en.wikipedia.org/wiki/Cotangent_bundle#Symplectic_form ). This is where I'm a little less sure about how to proceed. My idea is as follows: We can use the standard Euclidean metric $g$ on the ambient space $\mathbb{R}^{n+1}$ to induce a metric on the sphere $S^n$. This induces a vector bundle isomorphism between the tangent and cotangent bundles of $S^n$ which covers the identity on $S^n$
\begin{equation}
\hat{g} : TS^n \to T^{*}S^n, \ \ v_{s} \mapsto g_{s}(v_{s}, -).
\end{equation} 
Note that this means that if $\Pi : TS^n \to S^n$ and $\tilde{\Pi} : T^{*}S^n \to S^n$ are the projection maps, then $\tilde{\Pi} \circ \hat{g} = \Pi$. I want to now pull back the canonical symplectic structure on $T^{*}S^n$ with $\hat{g}$ and compare it to the reduced symplectic form $\omega_{r}$. If they turn out to agree, then this proves that $\hat{g}$ is a symplectomorphism between $\mu^{-1}(0)/\mathbb{R}$ and $T^{*}S^n$. Now note that the canonical symplectic structure is the (negative of the) differential of the tautological one form $\alpha \in \Omega^{1}(T^{*}S^n)$, which is defined as follows:
\begin{equation}
\xi_{s} \in T^{*}_{s}S^n, \ \ \alpha(\xi_{s}) = d\tilde{\Pi}^{*}_{\xi_{s}}(\xi_{s}) \in T^{*}_{\xi_{s}}(T^{*}S^n).
\end{equation}
So we pull this back instead, since we can always take the differential later on. Now $\hat{g}^{*}(\alpha) \in \Omega^{1}(TS^n)$ and at a point $v_{s} \in T_{s}S^n$ we have
\begin{equation}
\hat{g}^{*}(\alpha)_{v_{s}} = \alpha_{\hat{g}(v_{s})} \circ d\hat{g}_{v_{s}} = \hat{g}(v_{s}) \circ d(\tilde{\Pi} \circ \hat{g})_{v_{s}} = \hat{g}(v_{s}) \circ d\Pi_{v_{s}} = v_{s} \cdot (d\Pi_{v_{s}}(-)),
\end{equation}
where the last term means taking a dot product in euclidean space. Now how does this act on specific vectors: Take coordinates $(u_{i})$ for $S^n$ around a point $s$. This gives local frame $\frac{\partial}{\partial u_{i}}$ for the tangent bundle. And this in turn gives coordinates $(u_{i}, v_{i})$ for the tangent bundle. That is to say $(u_{i}, v_{i}) \mapsto v_{i}\frac{\partial}{\partial u_{i}}|_{u}$. Now take a vector $(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}})$ at a point $(u,v)$. Then 
\begin{equation}
\hat{g}^{*}(\alpha)_{(u,v)}(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}}) = v_{u} \cdot d\Pi_{(u,v)}(t_{i} \frac{\partial}{\partial u_{i}} + l_{i} \frac{\partial}{\partial v_{i}}) = v_{u} \cdot t_{u}.
\end{equation}
In other words, if we note that $T_{(u,v)}(TS^n) \cong T_{u}S^n \times \mathbb{R}^{n}$, then $\hat{g}^{*}(\alpha)_{(u,v)}(t,l) = v \cdot t$. Now we also have the standard 1-form on $\mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$ which is given by $q_{i} dp_{i}$. We can pull this back to $TS^n = N$ using the inclusion $i : N \to \mathbb{R}^{n+1} \times \mathbb{R}^{n+1}$. Since $T_{(q,p)}N \cong \mathbb{R}^{n} \times T_{p}S^{n} \subseteq \mathbb{R}^{n+1}_{q} \times \mathbb{R}^{n+1}_{p}$, for $(l,t) \in T_{(q,p)}N$ we have $i^{*}(q \cdot dp)_{(q,p)}(l,t) = q \cdot dp_{(q,p)} (l + t) = q \cdot dp_{(q,p)}(t) = q \cdot t$. Therefore, $\hat{g}^{*}(\alpha) = i^{*}(q \cdot dp)$ since they have the same effect on vectors. Therefore $\pi^{*}(\hat{g}^{*}(\alpha)) = \pi^{*} i^* (q \cdot dp) = (i \circ \pi)^* (q \cdot dp)$. We wish to compare this with $\iota^{*}(q \cdot dp)$. We do this using coordinates on $\mu^{-1}(0) = \mathbb{R}^{n+1} \times S^n$. We choose coordinates $(q,u) \in \mathbb{R}^{n+1} \times \mathbb{B}^n$, with coordinate map $\phi^{\pm} : \mathbb{R}^{n+1} \times \mathbb{B}^n \to \mu^{-1}(0), \ \ (q,u) \mapsto (q,u,\pm\sqrt{1-|u|^2})$. We also write $q = (\overrightarrow{q}, q_{n+1})$, where $\overrightarrow{q}$ denotes the first $n$ coordinates. In these coordinates then we see that
\begin{equation}
\iota^{*}(q \cdot dp) = \overrightarrow{q} \cdot du \pm q_{n+1}d\sqrt{1-|u|^2} = \overrightarrow{q} \cdot du - (\pm 1)\frac{q_{n+1} u \cdot du}{\sqrt{1-|u|^2}}.
\end{equation}
And that (after some cancellation of terms)
\begin{equation}
\pi^{*}(\hat{g}^{*}(\alpha)) = (i \circ \pi)^* (q \cdot dp) = \overrightarrow{q} \cdot du - (\pm 1)\frac{q_{n+1} u \cdot du}{\sqrt{1-|u|^2}}.
\end{equation}
Therefore we have shown that $\iota^{*}(q \cdot dp) = \pi^{*} (\hat{g}^{*}(\alpha))$. Taking the differential of both sides and multiplying by $-1$ gives
\begin{equation}
\iota^{*}(dp_{i} \wedge dq_{i}) = \pi^{*} (\hat{g}^{*}(-d\alpha)),
\end{equation}
where $-d\alpha$ is the canonical symplectic form on $T^{*}S^n$. And so $\omega_{r} = \hat{g}^{*}(-d\alpha)$, showing that $\hat{g} : (N,\omega_{r}) \to (T^{*}S^n, -d\alpha)$ is a symplectomorphism. The way I exhibit the symplectomorphism uses a lot of extra stuff like the tautological 1-form, and the ambient euclidean metric. I'm wondering if there is a more direct way to see the symplectomorphism. Thanks","['riemannian-geometry', 'symplectic-geometry', 'differential-geometry']"
930242,Quadratic formula with complex coefficients,"Let $a,b$ and $c$ be complex numbers. I'm trying to prove that this version of the usual quadratic formula: $$z=\frac{-b+(b^2-4ac)^{\frac{1}{2}}} {2a}$$ solves the quadratic equation $$az^2+bz+c=0$$ This seemed fairly easy to do, but I came across some doubts. This is what I've done so far, please correct me if I made a mistake anywhere: $$az^2+bz+c=0$$ $$z^2+\frac b a z+\frac c a=0$$ $$(z+\frac b {2a})^ 2=\frac {b^2} {4a^2} -\frac c a$$ Now, if we were working with real numbers, I would just take square root on both sides of the equation and that would be all. The problem is, the complex function $w^{\frac 1 2}$ is multivaluated. I don't quite know how to work around it without reducing the image set in order to work with an injective function. Please, if somebody know how to finish this proof, I would really appreciate it. PS: I apologize in advance for the misspelling/structure mistakes of this post.","['complex-numbers', 'complex-analysis', 'analysis']"
930249,proving that if $f(x)$ odd then $f(0)=0$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Need to prove that if $f(x)$ is an odd function that defined in the point: $x=0$, So $f(0)=0$. I know that odd function is: $f(-x)=-f(x)$ And that $f(x)=0$ is an odd function but dont know how to prove. Thanks.",['functions']
930265,What is FOIL and how is it done?,"My Algebra teacher was explaining to the class about creating a trinomial using FOIL. What is it, and how is it done?",['algebra-precalculus']
930274,How to draw Congressional districts to mirror the Popular Vote,"Let me preface this by saying that I'm not sure whether this is fundamentally a mathematical question or not, but I think it is. In the United States, the House of Representatives is elected roughly as follows.  The country is divided into 435 contiguous congressional districts, drawn in such a way that each district contains approximately the same number of people.  And the people in each district elect one person to represent them in the House of Representatives. Suppose for simplicity that there are only two political parties, the Democrats and the Republicans.  Now an often-criticized fact about congressional elections is that there is a divergence between the House Popular Vote, the percentage of people all across the country who voted for one party over the other in the Congressional election, and the party control of the House of Representatives, i.e. the percentage of members of the House who belong to each party.  This is sometimes due to gerrymandering, or the intentional drawing of districts to benefit one party or the other, but it's often just due to how the districts are naturally drawn.  To take an extreme example, if people voted for Republicans 1 - 0 in 434 out of 435 districts, and they voted 500-66 for Democrats in the last district, then Republicans would win the House of Representatives 434-1, even though the popular vote would be tied 500-500. Now people often just point to this divergence as a symptom of some other problems that we need to fix, and they propose redrawing district maps to fix those more fundamental problems.  But my question is, what if you made minimizing the divergence your criteria?  That is to say, given only the requirements that the number of districts must stay at 435, that districts must contain equal numbers of people, and that they must be contiguous regions, what is the mathematically optimal way to draw districts such that the the divergence between party control percentages and national popular vote percentages is minimized? Note that I'm not asking for what the actual optimal districts are for the United States would be, I'm just asking what mathematical methods would allow you to solve this general type of problem?  I assume in practice you would just do a numerical simulation where you try lots of different possible district maps until you found one that approximately optimal, but just at an intuitive level, what sort of district drawing scheme would be at least close to optimal?","['general-topology', 'graph-theory', 'statistics', 'applications']"
930277,Differential Equation Word Problem involving y=Ce^(xk) (y=y'),"""The rate of change of y is proportional to y. Write and solve the differential equation that models the verbal statement."" This part of the problem is easy. My work is such: $y'=ky$ $\frac{dy}{dx} = ky$ $dy = ky dx$ $\frac{dy}{y} = k dx$ Then by integrating, I get: $y = e^{kx + c}$, where $c$ is some constant Which can also be written as: $y = e^{kx} e^c$ $y = ce^{kx}$ The next part is rather confusing though: ""Use this statement to find the value of y when x=10, if it satisfies when x=0, y=2, and when x=4, y=8"" How can you find a particular solution of this differential equation when you are missing information about c, k, and y? If it helps, I just started Calculus 2. Thank you for your time in advance.","['differential', 'ordinary-differential-equations', 'calculus']"
930303,Recovering pmf from characteristic function,"I'm having some trouble trying to recover the probability mass function of a discrete random variable from its characteristic function. I have seen that some continuous cases, you can recognize that the characteristic function is the inverse Fourier transform of the density function, so you can apply the Fourier transform again. The formula in that case is
$$f(x) = \frac{1}{2\pi} \int_\mathbb{R} e^{-itx} \phi(t) \mathop{dt}.$$ However, in the discrete case, this integral does not make sense, as it is
$$\frac{1}{2\pi} \int_\mathbb{R} e^{-itx} \sum_{n=1}^N P(X=x_n) e^{itx_n} \mathop{dt}
= \frac{1}{2\pi} \sum_{n=1}^N P(X=x_n)\int_{\mathbb{R}}e^{it(x_n-x)} \mathop{dt},$$
which is not integrable. I thought about using an integral over an interval instead, but it is not possible to get the right period since the $x_n$ are arbitrary real numbers. How do you recover the pmf from the characteristic function?","['probability-theory', 'characteristic-functions']"
930304,Showing that a matrix is invertible and finding its inverse,"I'm incredibly rusty at linear algebra, and in preparation for my course I've been doing some review questions. I've been staring at this one for a half hour and still don't know how to approach it: ""Let A be a square matrix such that $A^3 = 0$. Show that the matrix $I + A + 2A^2$ is invertible and find its inverse."" I'm pretty sure I need to find a relationship between $A^3$ and $I + A + 2A^2$, but I'm not sure how. A matrix is invertible if the determinant is nonzero, and I know how to find the inverse of a matrix, but since this is a more theoretical question I'm not entirely certain how to approach it. Any hints would be much-appreciated :)","['matrices', 'linear-algebra', 'inverse']"
930326,Prove/disprove $n! = O(2^n)$ via mathematical induction,"My computer science professor has us tasked with proving or disproving the statement $n! = O(2^n)$ . We are then supposed to say if it's always true, always false, or non-conclusive (true in some cases but false in other cases). So I believe that the statement $n! = O(2^n)$ is non-conclusive for the sole reason that it isn't true until $n\geq4$ . I'm having a hard time proving the inductive step of my mathematical induction. Below is what I have so far, could someone help me out figure the induction step? Problem $\boldsymbol 1$ (c) Is the statement True, False, or non-conclusive? Non-conclusive meaning true in some cases but false in other cases. Question. $C(n) =n!$ implies that $C(n) =O(2^n)$ $\longleftarrow$ Prove or disprove Given: $2^n \leq n!$ For $n=1$ , we have $2^1 \leq 1! \implies 2\leq1$ which is FALSE. For $n=2$ , we have $2^2 \leq 2! \implies 4\leq2$ which is FALSE. For $n=3$ , we have $2^3 \leq 3! \implies 8\leq6$ which is FALSE. For $n=4$ , we have $2^4 \leq 4! \implies 16\leq24$ which is TRUE. From pluging in some values we see that $n!$ seems to grow faster than $2^n$ . Let's try and prove that through mathematical induction. Let us suppose the following property $P(n)$ defined thusly: $$2^n \leq n! \quad \text{for all integers } n \geq 4.$$ Mathematical Induction Proof: Step $1$ . Prove the Basis step, we must show $P(4)$ is true. $$P(n) =2^n \leq n! \longrightarrow 2^4 \leq 4! \implies 16 \leq 24,$$ which is true. Step $2$ . Prove the inductive step, now suppose this works for any integer $k$ , $k \leq 4$ such that $$2^k \leq k! \longleftarrow \text{inductive hypothesis}$$ Now to complete mathematical induction proof, we must show that the following is true for $P(k+1)$ : \begin{align}
2^{k+1} &\leq (k+1)! \\
(2^k)(2) &\leq (k+1)(k!)
\end{align}","['induction', 'discrete-mathematics']"
930333,Notation on partial deriviatives,"If I need to find $$\frac{\partial ^{2}g}{\partial u \partial v}$$ Then do I want to perform $$ \frac{\partial} { \partial v}\ \big( \frac{\partial g}{\partial u} \big) $$ 
or 
$$ \frac{\partial g} {\partial u} * \frac{\partial g}{\partial v} $$ I'm thinking the first one, but I just want to check my intuition. edit: Notation Blunder *facepalm *","['notation', 'multivariable-calculus']"
930338,Summation of series $\sum_{k=0}^\infty 2^k/\binom{2k+1}{k}$,"How to find the sum of this series? 
$$\sum_{k=0}^{\infty}\cfrac{{2}^{k}}{\binom{2k+1}{k}}$$ It seems very easy. But I still can not work it out, can anyone help?","['summation', 'sequences-and-series', 'combinations']"
930340,"Linear Algebra - four ""true or false"" questions about matrices and linear systems","I'm reviewing for my linear algebra course, and have four ""true or false"" questions that I'm struggling to prove. I've included my approach to the solutions in brackets below them: 1) If $A^2 = B^2$, then A = B or A = -B, where A and B are nxn matrices (Not sure how to approach this one at all) 2) Every 3x3 skew symmetric matrix is singular (Pretty sure I have this one correct: Because this is a skew symmetric matrix, $\det(A) = \det(A^T) = \det(-A) = (-1)^n\det(A)$, and when n is odd $\det(A) = -\det(A)$, so $2\det(A) = 0$ and therefore $\det(A) = 0$. As such, the answer is ""False"" because it is only singular when n is odd) 3) Any system of n linear equations in n variables has at most n solutions (A system can have infinitely many solutions if the determinant is zero, right? I just don't know how to prove it) 4) For a square matrix A, A is invertible if and only if $AA^T$ is (Not sure how to approach this one, either)","['matrices', 'linear-algebra', 'systems-of-equations', 'determinant']"
930352,"Suppose $(s_n)$ converges and that $s_n \geq a$ for all but finitely many terms, show $\lim s_n \geq a$","I've got a few questions about the problem. Prob :Suppose $(s_n)$ converges and that $s_n \geq a$ for all but finitely many terms, show $\lim s_n \geq a$ The solution here breaks this problem up into two parts. Q1. I don't understand why is it necessary to consider the finitely many terms that $s_k < a?$ Doesn't the condition that $s_n \geq a$ for all, but finitely many terms and $(s_n)$ being convergent imply that $$\forall \epsilon > 0, \exists N_0 \in \mathbb{N} \implies \forall n > N_0 \implies |s_n - s| <\epsilon$$ So that all the terms after $N_0$ are going to be close to $s$ and therefore $$a < s+\epsilon$$ So why do we need to show the existence of $N > \max \{ M, N_0 \}$ when the definition says there is going to be an $N'$ that gives us convergence? Q2. Also what is wrong with the following ""proof""? Proof Since $(s_n)$ converges, $$\lim s_n \geq \lim a = a.$$ Ii want to say the proof is wrong because $s_n \geq a$ is not true for every $n$, if it is true for all $n$ then it may be correct? But I thought limits only care about what happens in the long term, so I am not entirely sure what is really the mistake... EDIT : I was just going to say (very roughly) $s_n \to s \implies \forall \epsilon >0, \exists N_1 \ni \forall n > N_1 s_n < s + \epsilon.$ Now for the rest of the $s_k < 1$ (where $k > N_1$), choose a new $N > \max \{ \max_{k}, N_1 \}$ so that $a \geq s_n < s + \epsilon.$ This is true for all $\epsilon >0$, so take $\epsilon = 0$","['inequality', 'calculus', 'real-analysis', 'limits']"
930388,How to solve limits?,"The above limit was solved by making a seemingly arbitrary substitution. The previous limit was solved by making a linear substitution $y=mx$ . Which again seemed a bit out of the blue. For another question, my book somehow came to the conclusion that the limit exists and that we should be trying to prove this (again, no explanation was given as to why they were trying to prove the limit existed this time). They then somehow came to the conclusion that a polar coordinate substitution might help along with the Squeeze theorem. When given a limit, my book keeps using all these different methods from all these different areas of math- most of which are very non-obvious. So my question(s) boils down to: a) When given a limit, what's a good way to get ""a hunch"" if the limit exists or not? I don't want to waste 15 minutes trying to prove a limit that doesn't exist. b) If I believe the limit exists, what's a good way to approach the problem and generate ideas on how to prove it? c) If I believe the limit doesn't exist, what's a good way to approach the problem and generate ideas on how to prove it? These questions obviously don't have deterministic answers that always work, I'm just looking for something to get past the initial ""What the hell do I do?!?!"". Most of the math I've done so far has been pretty mechanical (keep trying methods from your toolbox until one finally works), so these limits are pretty intimating.","['multivariable-calculus', 'limits']"
930389,Prove that $\max\{|x_i|: 1 \leq i \leq n\} \leq \|\vec{x}\| \leq \sum_{i=1}^{n} |x_i|$,"If $\|\vec{x}\|$ denotes the Euclidean Norm of $\vec{x} \in R^n$, show that 
$$
\max\left\{|x_i|: 1 \leq i \leq n\right\} \leq \|\vec{x}\| \leq \sum_{i=1}^{n} |x_i|
$$","['geometry', 'euclidean-geometry']"
930400,Product $\sigma$ algebra,"Consider $\mathbb{R}$ with the $\sigma$-algebra of Borel sets, and $\mathbb{R}^\mathbb{R}$ with the product $\sigma$-algebra(see p.22 of 'Real Analysis - Gerald B. Folland'). Does $[0,1]^\mathbb{R} \subset \mathbb{R}^\mathbb{R}$ belong to the product  $\sigma$-algebra?",['measure-theory']
930402,Why does $y = x\sin(\frac{180}{x})$ approach $\pi$?,"A few days ago I was playing on my scientific calculator and I ran over an interesting little equation: $180\sin(1)$ is extremely close to $\pi$. At first I thought it was a coincidence, but then I tried $360\sin\left(\frac{1}{2}\right)$ and it was closer to pi. So then I tried out $90\sin(2)$ and it was farther from $\pi$. So I came up with the equation $y = 180x\sin\left(\frac{1}{x}\right)$, which I then simplified to $y = x\sin\left(\frac{180}{x}\right)$. Although it approaches $\pi$ slower (180 times slower), it is easier to understand what was going on on the desmos graphing calculator. It seems the larger the $x$ value, the closer it gets to $\pi$. I would like to know why exactly this happens. EDIT: (Sine is in degrees not radians, just for clarification)","['pi', 'trigonometry', 'limits']"
930406,Limit of $\frac{\sin(\theta)}{\theta}$ in degrees,"What does $\lim \limits_{\theta\to0}\dfrac{\sin(\theta)}{\theta}$ equal when $\theta$ is expressed in degrees? I know that theta in degrees is $\frac{\pi}{180}$ theta radians, but I don't get the final answer of $0.01745$.","['calculus', 'limits']"
930436,A result on sequences: $x_n\to x$ implies $\frac{x_1+\dots+x_n}n\to x$ without using Stolz-Cesaro [duplicate],"This question already has answers here : On Cesàro convergence: If $x_n \to x$ then $z_n = \frac{x_1 + \dots +x_n}{n} \to x$ (3 answers) Closed 7 years ago . If $x_n \to x$, how might we prove $$\lim_{n \to \infty} \frac{\sum_{i=1}^{n} x_i}{n} = x$$ Of course, one has $\limsup x_n = \liminf x_n = x$, and thus, using the Stolz-Cesaro theorem: $$\liminf x_n \le \liminf \frac{\sum_{i=1}^{n} x_i}{n} \le \limsup \frac{\sum_{i=1}^{n} x_i}{n} \le \limsup x_n$$ which shreds this easily. However, I'm wondering whether one could do this without the Stolz-Cesaro theorem. Also, apparently the converse of this statement is not true. If we take $x_n = 0,\, n$ even, and $x_n =1,\, n$ odd, this suffices, correct? As the second expression tends to $1/2$, while the first has no limit?","['cesaro-summable', 'sequences-and-series']"
930456,Differential Equation for brownian bridge?,"For the brownian motion, we know that probability density of the particle's position at time $ t $, $ \rho(x,t) $ satisfies the diffusion equation pde: $ \partial_t \rho = d \; \partial_x^2 \rho $. Is there some similar statement for the brownian bridge, something of the form: the probability density of the particle's position $\rho $ satisfies $ L \rho = 0 $ for some differential operator $L $ with the boundary conditions $ \rho(x,0) = \rho(x,1) = \delta(x) $?","['statistics', 'soft-question', 'probability-distributions', 'partial-differential-equations']"
930457,"Computing an indefinite integral: $\int \frac{2n!\sin x + x^n }{e^x + \sin x + \cos x + P_n (x)}\, dx $","Let $\displaystyle 
P_n (x) = 1 + \frac{x}{1!} + \frac{x^2 }{2!} + \cdots + \frac{x^n }{n!}
\
$ and $$
I(x) = \int \frac{2n!\sin x + x^n }{e^x  + \sin x + \cos x + P_n (x)}\, dx
$$ (where $\
n \to \infty 
\
$). This problem is REALLY frustrating to me at the moment, it's 6 AM here and I've been trying to sort it out since 4:30 AM. First of all, I don't get the use of the $P_n(x)$ notation,  isn't that just $e^x$ ?
Anyhow...None of my approaches yielded any useful results, so I'm reaching out to you. Can someone suggest anything, at all ? It would be much appreciated, thanks a lot! EDIT : I managed to solve part of it, I'm now stuck with $
I(x) = n!(x - \log [2e^x  + \sin (x) + \cos (x)] + \int {\frac{{x^n }}{{e^x  + \sin x + \cos x + P_n (x)}}} dx
$. Can't really figure out if this is much better, but that's all I could get up until this point.","['closed-form', 'calculus', 'integration', 'indefinite-integrals', 'real-analysis']"
930497,Proving $\lim_{n \rightarrow \infty} \frac{\sum_{r=1}^{n} r^a}{n^{a+1}}=\frac{1}{a+1}$ [duplicate],"This question already has answers here : What is the result of $ \lim_{n \to \infty} \frac{ \sum^n_{i=1} i^k}{n^{k+1}},\ k \in \mathbb{R} $ and why? (4 answers) Closed 9 years ago . How do we prove that $$\lim_{n \rightarrow \infty} \dfrac{\displaystyle\sum_{r=1}^{n} r^a}{n^{a+1}}=\frac{1}{a+1}$$? This type of terms appear in problems on limits, but I am unable to prove this. Please help me out.","['summation', 'limits']"
930512,"high order DE :$y''''+y'''=1-x^2\,e^{-x}$","I am doing some exercise and I got to this question:
SOLVE:  $ y''''+y'''=1-x^2e^{-x}$,
the associated homegeneous eqation  solution is simple to calculate
that is,
$y_h=c_1+c_2x+c_3x^2+c_4e^{-x}$
However, when it comes to particular solution ,it is really trivial and hard.
can anyone teach me how to solve the problem in the easiet way?that is ,solve the problem as quick as possible",['ordinary-differential-equations']
930550,Theorem 1.20 (b) in Baby Rudin: Can the proof of the theorem be improved?,"I'm reading Principles of Mathematical Analysis , third edition, and am at Theorem 1.20(b), which is as follows: If $x \in \mathbb{R}$ , $y \in \mathbb{R}$ , and $x < y$ , then there exists a $p \in \mathbb{Q}$ such that $x< p < y$ . Now here is the proof given by Rudin: Since $x<y$ , we have $y-x > 0$ , and Theorem 1.20(a) furnishes a positive integer $n$ such that $$n(y-x) > 1.$$ Apply Theorem 1.20(a) again to obtain positive integers $m_1$ and $m_2$ such that $m_1 > nx$ and $m_2 > -nx$ . Then $$-m_2 < nx < m_1. $$ Hence there is an integer $m$ (with $-m_2 \leq m \leq m_1$ )  such that $$ m-1 \leq nx < m.$$ If we combine these inequalities, we obtain $$nx < m \leq 1+nx < ny.$$ Since $n > 0$ , it follows that $$ x < \frac{m}{n} < y.$$ This proves Theorem 1.20(b) with $p = \frac{m}{n}$ . Now I have the following questions: (1) In the above proof, can we not dispense with the integers $m_1$ and $m_2$ ? (2)  How do we know that the integer $m$ satisfies the inequalities $-m_2 \leq m \leq m_1$ ? (3) As Rudin has not mentioned the well-ordering principle, how do we obtain the inequalities $ m-1 \leq nx < m$ ? (4) Is this proof sound enough logically even without using the well-ordering principle?","['solution-verification', 'proof-writing', 'real-analysis', 'analysis']"
930562,Goursat's Lemma proof,"There is a problem in Lang's book that I don't quite understand how to proceed. It is problem #5, pg 75. I  have already shown that the subgroups N and N' can be identified as normal in G, G'. But I don't know how to show that the image of H in G/N $\times$ G'/N' is the graph of an isomorphism. Problem statement: Let $G, G'$ be groups, and let $H$ be a subgroup of $G \times G'$ such that the two projections $p_1 : H \to G$ and $p_2 : H \to G'$ are surjective. Let $N$ be the kernel of $p_2$ and $N'$ be the kernel of $p_1$ . One can identify $N$ as a normal subgroup of $G$ , and $N'$ as a normal subgroup of $G'$ . Then the image of $H$ in $G/N \times G'/N'$ is the graph of an isomorphism $
G/N \approx G'/N'
$ .",['abstract-algebra']
930619,Question about integrating differential forms,"Maybe it's stupid question, by why: $$\int_S Fdx\wedge dy=\int_S Fdxdy$$ And is calculating a surface integral $$\int_S Fdx\wedge dy+Gdy \wedge dz+H dz\wedge dx=\int_S Fdxdy+\int_SGdydz + \int_SHdzdx$$ equivalent to calculating it as $$\int_S Fdx\wedge dy+Hdy \wedge dz+H dz\wedge dx=\int_A(G(T(s,t)),H(T(s,t)),F(T(s,t)))\cdot \vec{n} dA$$ Where $\vec{n}$ is a vector normal to surface $S$ and $T:A\rightarrow S$ is its parametrization. (where the second integrals are common double integral). I think it is equivalent knowing how components of normal vector looks like and that in the first integral we use change of variables theorem (also calculating jacobians).","['differential', 'differential-forms', 'integration', 'differential-geometry']"
930646,"Find the limit points of the set $\{ \frac{1}{n} +\frac{1}{m} \mid n , m = 1,2,3,\dots \}$","I need to find limit points of the set $\{  \frac{1}{n} +\frac{1}{m} \mid n, m = 1,2,3,\dots \}$. My try : If both $m$ and $n$ tend to very large values say $\infty$ then the value of $\{ \frac{1}{n} +\frac{1}{m} \}$ tends to $0$, and if only one of $m$ or $n$ tends to very large values, then the set $\{ \frac{1}{n} \mid n=1,2,3,\dots\} $ acts as limit points. So is it true that a set of limit points is $\{0\}$ $\cup$  $\{\frac{1}{k} \mid k=1,2,3,\dots \}$? How should I write this proof rigorously?",['real-analysis']
930666,How many roots have a complex number with irrational exponent?,"If a rational exponent on a complex number $z^q$ is the representation of a finite number of roots, then if the exponent is irrational this mean that there are infinite countable roots? If this is the case... the cardinality of the number of roots is the same for any irrational exponent? Thanks in advance. NOTE: there are different questions about irrational exponents but no one answer what Im searching so please dont mark this as repeated.","['complex-numbers', 'calculus', 'analysis']"
930684,Integrate $\int\frac{\cos^2x}{1+\tan x}dx$,"Integrate $$I=\int\frac{\cos^2x}{1+\tan x}dx$$ $$I=\int\frac{\cos^3xdx}{\cos x+\sin x}=\int\frac{\cos^3x(\cos x-\sin x)dx}{\cos^2x-\sin^2x}=\int\frac{\cos^4xdx}{1-2\sin^2x}-\int\frac{\cos^3x\sin xdx}{2\cos^2x-1}$$
Let $t=\sin x,u=\cos x,dt=\cos xdx,du=-\sin xdx$
$$I=\underbrace{\int\frac{-u^4du}{(2u^2-1)\sqrt{1-u^2}}}_{I_1}+\underbrace{\int\frac{u^3du}{2u^2-1}}_{I_2}$$
I have found(using long division): $$I_2=\frac{u^2}2+\frac18\ln|2u^2-1|+c=\frac12\cos^2x+\frac18\ln|\cos2x|$$
I have converted $I_1$ into this:
$$I_1=\frac12\left(\int(-2)\sqrt{1-u^2}du+\int\frac{du}{\sqrt{1-u^2}}\right)+\frac14\underbrace{\int\frac{du}{(2u^2-1)\sqrt{1-u^2}}}_{I_3}$$
Now I have took $v=1/u$ in $I_3$ so that $du=-(1/v^2)dv$:
$$I_3=\int\frac{vdv}{(v^2-2)\sqrt{v^2-1}}$$
Now I took $w^2=v^2-1$ or $wdw=vdv$ to get:
$$I_3=\int\frac{dw}{w^2-1}=\frac12\ln\left|\frac{w-1}{w+1}\right|$$
I have not yet formulated the entire thing; Is this correct? This is very long, do you have any ""shorter"" method?",['integration']
930695,Supremum of sum of two sequences: $\sup (x_n+y_n) \le \sup x_n + \sup y_n$ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Prove that $\sup\{x_n+y_n\}\leq \sup\{x_n\}+\sup\{y_n\}$, if both sups are finite. Furthermore, prove that $\limsup\{x_n+y_n\}\leq \limsup\{x_n\}+\limsup\{y_n\}$ if both limsups are finite.","['inequality', 'real-analysis', 'supremum-and-infimum']"
930708,Comparing the size of square roots,"How to compare the size of following numbers without using the calculator ? $a=\sqrt{2}+\sqrt{6}+\sqrt{7},$ $b=\sqrt{3}+\sqrt{4}+\sqrt{8},$ $c=\sqrt{5}+\sqrt{5}+\sqrt{5}$",['algebra-precalculus']
930715,Is any homeomorphism from Riemann sphere to Riemann sphere Mobius transformation?,"Let $\hat{\mathbb{C}}$ be the Riemann sphere. Let $f:\hat{\mathbb{C}}\rightarrow \hat{\mathbb{C}}$ be a homeomorphism. Then, is $f$ a Mobius transformation?",['complex-analysis']
930729,When can an infinite abelian group be embedded in the multiplicative group of a field?,"This question comes from this question by user72870. That question would easily be answered if we know the cyclicity of the group in question, but, as the OP appears to be trying to prove that the group is cyclic by embedding it into the multiplicative group of a field, we cannot work under the cyclic hypothesis. So I loosed the condition and only assumed that it is abelian, but I could not find an appropriate field to embed it: finite fields are definitely out of options in reason of orders, and the ideal field must contain some sort of ""cyclic algebras"" for this embedding to happen. The obstacle that I emcountered is that, in the decomposition of an abelian group into cyclic ones, the orders of different summands might not be relatively prime, so that the approach to embed an anelian group into the multiplicative group of a field by embedding respectfully its cyclic factors does not work. Edit: Thanks to the reminder of @user72870, I realised that it is impossible to embed a finite abelian group into the multiplicative group of a field, unless the group is cyclic...I don't know what I was thinking at that moment, trying to embed a general abelian group into the multiplicative group of a field. Hence I change the question to embedding a general infinite group into the multiplicative group of a (infinite, of course) field. Any help or hint will be greatly appreciated; thanks in advance.","['group-theory', 'field-theory']"
930734,Real life math to explore/solve [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 8 years ago . Improve this question What are some examples of mathematics application in the real life that is interesting to explore about? And not too complicated but not too easy, something that exist around us. I'm interested in doing something related to integration, trigonometry and statistics. I currently taking an IB diploma (Maths HL course) so my knowledge on those topics is not really wide. Thus, I'm searching for real - life problem that up to my level to explore/solve? Thanks in advance","['statistics', 'trigonometry', 'integration']"
930776,"The closed form of $\lim_{x\to\frac{4}{3}}\frac{\partial}{\partial x}\left[\,_2{\rm{F}}_1\left(\frac{1}{3},1;x;-1\right)\right]$","Do you think the following limit might have a closed form? Some hints or clues? $$\lim_{x\to\frac{4}{3}}\frac{\partial}{\partial x}\left[\,_2{\rm{F}}_1\left(\frac{1}{3},1;x;-1\right)\right]$$","['calculus', 'real-analysis', 'hypergeometric-function', 'derivatives', 'limits']"
930778,Show that $\lim_{n\to\infty}\frac{a^n}{n!}=0$ and that $\sqrt[n]{n!}$ diverges.,"Let $a\in\mathbb{R}$. Show that
    $$
\lim_{n\to\infty}\frac{a^n}{n!}=0.
$$
    Then use this result to prove that $(b_n)_{n\in\mathbb{N}}$ with
    $$
b_n:=\sqrt[n]{n!}
$$
    diverges. Okay, I think that's not too bad. I write
$$
\frac{a^n}{n!}=\frac{a}{n}\cdot\frac{a}{n-1}\cdot\frac{a}{n-2}\cdot\ldots\cdot a
$$
and because all the factors converges to 0 resp. to $a$ (i.e. the limits exist) I can write
$$
\lim_{n\to\infty}\frac{a^n}{n!}=\lim_{n\to\infty}\frac{a}{n}\cdot\lim_{n\to\infty}\frac{a}{n-1}\cdot\ldots\cdot\lim_{n\to\infty}a=0\cdot 0\cdot\ldots\cdot a=0.
$$ Let $a_n:=\frac{a^n}{n!}$ and $a=1$ then
$$
b_n=\frac{1}{\sqrt[n]{a_n}}.
$$
Because (as shown above) $a_n\to 0$ it follows that $\sqrt[n]{a_n}\to 0$, because 
$$
\lvert\sqrt[n]{a_n}\rvert\leqslant\lvert a_n\rvert\to 0\implies\lvert\sqrt[n]{a_n}\rvert\to 0
$$ and therefore $b_n\to\infty$. I think that's all . Am I right?","['sequences-and-series', 'proof-verification', 'real-analysis', 'analysis']"
930780,Is a differentiable function always continuous?,"Continuous Functions are not Always Differentiable. But can we safely say that if a function f(x) is differentiable within range $(a,b)$ then it is continuous in the interval $[a,b]$ . If so , what is the logic behind it ?",['calculus']
930847,which surfaces have (for a large area) a constant negative curvature?,"There is no surface in $ R^3 $ that can represent the complete hyperbolic plane (Hilberts theorem) so we always have to do with a surface that is not completely equivalent, has a cusp somewhere, but in most publications on hyperbolic geometry, it is almost given that the tracioid (tractrix rotated about its asymptope) is a surface that has a constant negative curvature, and in many publications ""tracioid"" and ""pseudosphere"" are used interchangable. But I am wondering are there other surfaces that have a constant negative curvature? I did some searching and did find: In Klein's ""Vorlesungen uber Nicht-Euclidische Geometrie"" (1928) $4, page 286, figure 218 - 220, Klein gives three surfaces for hyperbolic surfaces: one that looks like an hill one that looks like an single sheet hyperboloid and then the well known tracioid Unfortunedly Klein doesn't give the equations of these surfaces. In Sommerville ""The elements of non euclidean geometry"" it says (Dover edition page 167) Furtunedly we do not require to take the imaginary circle a the type of surfaces of constant negative curvature. There are different forms of such surfaces, even of revolution, but the simplest is the surface called pseudosphere, which is formed by revolving a tractrix about its asymptope. Again a hint that other surfaces exist but no equations In https://math.stackexchange.com/a/666101/88985 there is a link to http://www.dm.unibo.it/~arcozzi/beltrami_sent1.pdf and this publication says at page 6 Gauss published his Theorema egregium in 1827 and it was already clear that, if figures could be moved isometrically, cuvature had to be constant. Minding observed that the converse was true in the 30's, and he found various surfaces of constant negative curvature in Euclidean space, the tractroid among them. sadly there is no reference to the publication of Minding. So i am stuck: What are those other surfaces of a constant negative curvature? and what are their equations?","['hyperbolic-geometry', 'differential-geometry']"
930848,Why does the empty set have a cardinality of zero?,"Consider the following sets: $$ A = \{1, 2, \{1,2\}, \emptyset \} $$ $$ B = \emptyset $$ My book says that $|A| = 4$ and $|B| = 0$. Why is $\emptyset$ considered an element if it's a subset, but not when it's on its own?",['elementary-set-theory']
930849,In what sense is a function on a circle the same as a $2 \pi$ periodic function on $\mathbb{R}$?,"I was reading the appendix of Elias M Stein's Fourier Analysis and before proving the approximation lemma the author mentions the following Recall that a function on a circle is the same as a $2 \pi$ periodic function on $\mathbb{R}$
Could someone explain me what this exactly means and how are the functions are the same?","['functions', 'circles', 'real-analysis', 'periodic-functions']"
930854,What is the importance of Jacobian Conjecture and any progress on it?,"What is the importance of Jacobian Conjecture?Are there any important central problem with the conjecture as precondition?
 and any progress on it?","['algebraic-geometry', 'reference-request', 'analysis']"
930876,a covering map is open?,"$E,B$ are topological spaces and let's say that $p:E\to B$ is a covering map. Is $p$ open? i tried to show it as follows: let $U$ be an open set in $E$ , and now for every $x\in U$ , $p(x)\in B$ . $p$ is a covering map so there is a open neighborhood of $p(x)$ , call it $V$ that is evenly coverd by $p$ . e.g there is a partition of $p^{-1}(V)$ of open disjoint subsets $\{V_\alpha\}$ that covers $E$ . and $p|_{V_\alpha}$ is homeomorphism between $V_\alpha$ and $V$ . so for some $\alpha$ , $x\in V_\alpha$ . so $V_\alpha \bigcap U$ is an open neighborhood of $x$ and $V_\alpha \bigcap U\subset V_\alpha$ and it is open in $V_\alpha$ , and since $p|_{V_\alpha}$ is homeomorphism between $V_\alpha$ and $V$ we get that $p(V_\alpha \bigcap U)$ is an open neighborhood of $p(x)$ and it is a subset of $p(U)$ .
then $p(U)$ is open. is it right?","['general-topology', 'covering-spaces', 'open-map', 'solution-verification']"
930931,Explanation of how probability density functions transform under the change of variable,"I've just read about probability density function from this article . In that article, there is some wired concept that I can't understand, please see the section named ""Dependent variables and change of variables"". In that section, there is an equation appeared with short comment about it, ""This follows from the fact that the probability contained in a differential area must be invariant under change of variables. That is, (and the equation appeared)"" I can't understand what that equation means and the sentence ""the probability contained in a differential area must be invariant under change of variable"", especially the ""invariant under change of variable"". Why the probability must be invariant under change of variable? and what is the change of variable? Could anybody give me some insight to understand that equation?","['probability-theory', 'probability-distributions', 'intuition']"
930998,"If the set of values , for which a function has positive derivative , is dense then is the function increasing?","Let $f:\mathbb R \to \mathbb R$ be a differentiable function such that $A:=${ $x \in \mathbb R :f'(x)>0$ } is dense  in $\mathbb R$ , then is it true that $f$ is an increasing function ? What  happens if $f'$ is also continuous  ?","['functions', 'derivatives', 'real-analysis']"
931013,What is the rule behind this derivative?,"$$\dfrac{\rm d}{{\rm d}t}\big(\sin^2(t)\big)=\sin(2t).$$ I don't understand what is the rule behind this derivation. I had tried to first rerivate sin() and then to derivate the square function, but apparently that's the wrong way.","['calculus', 'derivatives']"
931038,Second order equation. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question (i)Show that the ODE $$y''+[b'(x)/b(x)]y'-[a^2/b^2(x)]
y=0$$ has a pair of linearly independant solutions that are reciprocals, where $a$ is a constant and $b(x)$ is a function of x. Find them in terms of $a$ and $b(x)$. (ii)If the ODE $$y''+p(x)y'+2y=0$$ has solutions $y$ and $y^2$, find $y$ and find $p(x)$. Find both the possibilities.",['ordinary-differential-equations']
931042,Jacobi vs. Gauss-Seidel: convergence,"I know that for tridiagonal matrices the two iterative methods for linear system solving, the Gauss-Seidel method and the Jacobi one, either both converge or neither converges, and the Gauss-Seidel method converges twice as fast as the Jacobi one. Are there theorems relating the convergence speeds of these two methods when the system's matrix is not tridiagonal?","['numerical-linear-algebra', 'linear-algebra']"
931090,Decomposition of shear matrix into rotation & scaling,"How can I decompose the affine transformation: $$ \begin{bmatrix}1&\text{shear}_x\\\text{shear}_y&1\end{bmatrix}$$ into rotation and scaling primitives? $$ \begin{bmatrix}\cos\theta&-\sin\theta\\\sin\theta&\cos\theta\end{bmatrix}$$
\begin{bmatrix}\text{scale}_x&0\\0&\text{scale}_y\end{bmatrix}","['affine-geometry', 'linear-algebra']"
931111,Trivialising cover for étale morphisms,"Let $f:Y \to X$ be a finite étale morphism of smooth and proper schemes over a field $k$ (not necessarily separable closed). Is there a geometrically connected étale cover $\{U_i\}$ of $X$ which trivializes $Y$ , i.e. $Y \times_k U_i$ is the disjoint union of copies of $U_i$ ? EDIT: it seems that, for general $k$ , the above is not necessarily true. I have a couple of follow-up questions: If $k = k^{sep}$ , is there a positive answer to my original question? Is there a connected étale cover $\{U_i\}$ of $X$ which  trivializes $Y$ , for a general $k$ ?","['arithmetic-geometry', 'algebraic-geometry', 'schemes']"
931117,Prove that the power set of an $n$-element set contains $2^n$ elements,"Theorem. Let $X$ denote an arbitrary set such that $|X|=n$ . Then $|\mathcal P(X)|=2^n$ . Proof. The proof is by induction on the numbers of elements of $X$ . For the base case, suppose $|X|=0$ . Clearly, $X=\emptyset$ . But the empty set is the only subset of itself, so $|\mathcal P(X)|=1=2^0$ . Now, the induction step. Suppose $|X|=n$ ; by the induction hypothesis, we know that $|\mathcal P(X)|=2^n$ . Let $Y$ be a set with $n+1$ elements, namely $Y=X\cup\{a\}$ . There are two kinds of subsets of $Y$ : those that include $a$ and those that don't. The first are exactly the subsets of $X$ , and there are $2^n$ of them. The latter are sets of the form $Z\cup\{a\}$ , where $Z\in\mathcal P(X)$ ; since there are $2^n$ possible choices for $Z$ , there must be exactly $2^n$ subsets of $Y$ of which $a$ is an element. Therefore $|\mathcal P(Y)|=2^n+2^n=2^{n+1}$ . $\square$ Image that replaced text. From the above explanation, I don't understand why the set that contains $\{a\}$ will contain $2^{|n|}$ elements when it should clearly be $2^{|1|}$ . The construction of a new set $S$ is the union of the old set with cardinality $n$ and a new element $\{a\}$ , therefore the set that does not contain $\{a\}$ still has cardinality $n$ and the set that contains $\{a\}$ is just $\{a\}$ , one element. Can someone please elucidate?","['induction', 'elementary-set-theory']"
931133,Find a series solution to $(x^2-2)y''+6xy'+4y=0$.,"Find a series solution to $(x^2-2)y''+6xy'+4y=0$. A. Find the recurrence relation to $a_n$: My answer is $a_{n+2}=a_n\cdot \frac{n+4}{2(n+2)}$  which is correct. B. Using A , write two independent solutions to the ODE. So, for the odd n's:
$$a_3=\frac{1}{2} \frac{5}{3}a_1 \\
a_5=\frac{1}{2}\frac{7}{5}a_3=\frac{1}{2}^2\frac{7}{3}a_1 \\
a_7=\frac{1}{2}\frac{9}{7}a_5=(\frac{1}{2})^3\cdot \frac{9}{3}a_1$$
So that if I iterate right, the $2m+1$'th term is $$a_{2m+1}=(\frac{1}{2})^{m+1}\cdot (m+5)\cdot \frac{a_1}{3}$$ 
Which means the a solution is $$y_1(x)=\sum_{m=0}^\infty (\frac{1}{2})^{m+1}\cdot (m+5)\cdot \frac{a_1}{3}x^{2m+1}$$But, the answer in the textbook is slightly different: 
$$y(x)=\sum_{m=0}^\infty \frac{2m+3}{2^m}x^{2m+1}$$
Same with even terms: I came up with $$y_2(x)=\sum_{m=0}^\infty \frac{m+2}{2^{m+1}}x^{2m}$$
and the solution I have is
$$y(x)=\sum_{n=0}^\infty \frac{m+1}{2^m}x^{2m}$$
So what's is wrong in my solution? C. Find the Solution to the ODE when $y(0)=1, \ y'(0)=0$ as a series solution around $x=0$.
So how do I know that $a_0=1, \ a_1=0$ and not vise versa?","['power-series', 'ordinary-differential-equations']"
931155,What is the domain of this multivariable function?,"Let $h(x,y,z) = (z^2 -xz + zy -xy)^{1/4}$. What is the domain on this function? I know that
\begin{align*}
z^2 -xz + zy -xy \geq 0 \\
\implies z(x+y) -x(z+y) \geq 0 \\
\implies (z-x)(z+y) \geq 0
\end{align*} So is $D(h) = \{ (x,y,z) \in \mathbb{R}^3 | (z-x)(z+y) \geq 0 \}$ sufficient? Also how can this be described in words? Is it just a pair of intersecting planes?",['multivariable-calculus']
931193,Show that the solution of an initial value problem is always less than a given constant,My try is that $$\frac{dy}{dt} =(y-3)e^{\cos ty}$$ $$\frac{dy}{y-3}= e^{\cos ty}dt$$ $$\ln (y-3)=-\frac{e^{\cos ty}}{\sin ty} +c$$ my steps is correct or I made mistakes ? please help to solve this problem,"['inequality', 'ordinary-differential-equations', 'calculus']"
