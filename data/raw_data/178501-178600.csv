question_id,title,body,tags
3231271,A sufficient and necessary condition for a special linear operator to be compact,"Suppose $X$ is Banach and $T\in B(X)$ (i.e. $T$ is a linear and continuous map and $T:X \to X$ ). Also, suppose $\exists c > 0$ , s.t. $\|Tx\| \ge c\|x\|, \forall x\in X$ . Prove $T$ is a compact operator if and only if $X$ is finite dimensional. "" $X$ is finite dimensional $\implies$ $T$ is compact"" is easy to show. To prove the other side, at first, I made a mistake, thinking $X$ is reflexive. Then this work can be easily done by the fact that any sequence of a reflexive linear space has a weakly convergent subsequence and $T$ is completely continuous (since $T$ is compact). But this is not the situation. So how to prove "" $T$ is compact $\implies X$ is finite dimensional""?","['compact-operators', 'functional-analysis', 'weak-convergence']"
3231364,PDE as a system of ODEs,It has been said that a PDE is like an infinite dimensional system of ODEs. How can one see this by a clear example? Can any PDE be transformed into an infinite dimensional system of ODEs?,"['dynamical-systems', 'systems-of-equations', 'ordinary-differential-equations', 'partial-differential-equations']"
3231389,Showing that $\lim_{n \rightarrow \infty}\left(1+\frac{1}{n}+\frac{1}{n^2}\right)^n = e$,"$\lim_{n \rightarrow \infty}\left(1+\frac{1}{n}+\frac{1}{n^2}\right)^n = e$ I got this limit while solving another problem. Usually limits that look like this can be easily handled by factoring expressions, but this limit has addition inside the parenthesis which confuses me. How can this limit be solved? No l'Hopitals, thank you :)","['limits-without-lhopital', 'limits', 'exponential-function']"
3231433,"Choosing $r$ things from a set containing $l$ things of one kind, $m$ things of a different kind, $n$ things of a third kind,...","Here is a statement from a textbook that I'm referring to: From a set containing $l$ things of one kind, $m$ things of a different kind, $n$ things of a third kind and so on, the number of ways of choosing $r$ things out of this set of objects is the coefficient of $x^r$ in the expansion of $$(1+x+x^2+x^3+...+x^l)(1+x+x^2+x^3+...+x^m)(1+x+x^2+x^3+...+x^n).$$ Can someone please explain the intuition behind this? How can it be derived?","['combinatorics', 'generating-functions']"
3231451,"Prove $a^x> x^a$ for all $x>c$, for some real $c$. $(a>1)$","To prove $a^x> x^a$ for all $x>c$ , for some real $c$ . ( $a>1$ ). Proof Attempt: We first try to prove that $\lim_{x \to \infty}\frac{a^x}{x^a}=\infty$ . Both of the functions in the numerator and the denominator goes to $\infty$ as $x\to\infty$ . So, L'Hospital's rule is applicable. We get $\lim_{x \to \infty}\frac{a^x \log (a)}{ax^{a-1}}$ . We repeat the operation $\lceil a \rceil = p$ times. We get $\lim_{x \to \infty}\frac{a^x(\ln (a))^{p} x^{p-a}}{a(a-1)(a-2)...(a-(p-1))} =\infty$ A function $f(x)$ is said to diverge to positive infinity, if $\forall G>0$ , $\exists k>0$ such that $f(x)>G$ , $\forall x>k$ . We fix $G=1$ here. By the very definition, we can find a $k>0$ , such that $\frac{a^x}{x^a}>1$ , $\forall x>k$ , i.e. $a^x> x^a, \forall x>k$ . Is this method valid?","['proof-verification', 'real-analysis', 'calculus', 'limits', 'derivatives']"
3231469,Differentiability of $G_k(w)$,"Suppose that $f$ is holomorphic in a neighborhood of $z_0$ , and that all complex derivatives of $f$ up to order $m-1$ at $z_0$ vanish, namely, $f^{(j)}(z_0)=0$ for all $j=0,...,m-1$ , but that $f^{(m)}(z_0)\ne 0$ . (a)Prove that there exist $\epsilon>0$ and $\delta>0$ such that, for every $k\in\mathbb N$ , the equation $$ G_k(w)=\frac{1}{2\pi i}\int_{|\zeta-z_0|=\epsilon}\frac{\zeta^k f'(\zeta)}{f(\zeta)-w}d\zeta $$ defines a holomorphic function of $w$ in the set $$ D_\delta(f(z_0))=\{ 
w\in\mathbb C:|w-f(z_0)|<\delta \}.$$ (b) Prove that, in the context of (a), if $w\in D_\delta(f(z_0))$ then the equation $f(z)-w=0$ has $m$ roots (counted with multiplicity), $z_1,...,z_m,$ inside $|z-z_0|<\epsilon$ , and that $$G_k(w)=\sum_{j=1}^m z_j^k.$$ My attempt: (a) Suppose $w\in D_\delta(f(z_0))$ , then \begin{align}
\frac{G_k(w+\Delta w)-G_k(w)}{\Delta w}&=\frac{1}{2\pi i}\int_{|\zeta-z_0|=\epsilon}\frac{\zeta^k f'(\zeta)}{(f(\zeta)-w-\Delta w)(f(\zeta)-w)}d\zeta
\end{align} I was about to show that the modulus of integrand is bounded by an integrable function so that I can apply the dominated convergence theorem. However, I cannot find such a function... Edit: We know that if $\gamma$ is a Jordan curve, $\varphi(\zeta)$ is continuous on $\gamma$ , then the function $$ F(z)=\frac{1}{2\pi i}\int_\gamma\frac{\varphi (\zeta)}{\zeta-z}d\zeta $$ is analytic on each region of $\overline{\mathbb C}\setminus\gamma$ . The proof of differentiability of $F(z)$ depends on the non-vanishment of $\zeta-z$ on $\overline{\mathbb C}\setminus\gamma$ which clearly is not the case in this problem. So we have to use different techniques.",['complex-analysis']
3231505,Variance of the range for the exponential distribution,"If $n$ random variables are independently distributed with an exponential distribution $f_X(x) =\lambda e^{-\lambda x} (x\geq 0)$ , the range $R_n = \max(X_1,\cdots,X_n) - \min(X_1,\cdots,X_n)$ has the following expectation: $\mbox{E}[R_n] = \frac{1}{\lambda}\Big(1+\frac{1}{2}+\frac{1}{3}+\cdots + \frac{1}{n-1}\Big)$ . This result is well known, see here for some context. However, I could not find a formula for the variance, in the literature. So I decided to do the computations myself and came up with a spectacular formula. I am wondering if the following  formula for the variance is original: $\mbox{Var}[R_n]= \frac{1}{\lambda^2}\Big(1+\frac{1}{2^2}+\frac{1}{3^2}+\cdots + \frac{1}{(n-1)^2}\Big)$ . As a result, the limit as $n\rightarrow\infty$ is $\pi^2/(6\lambda^2)$ . I have a hard time believing that this is a new result. Could someone provide a reference? I plan on including it in an upcoming article. This result is pretty deep, though not that hard to prove. It is almost like the range, for the exponential distribution, is made up of a weighted sum of independent exponential variables with same parameter $\lambda$ , each new one added into the sum contributing with a weight equal to $1/k, k=1, 2$ and so on.","['statistics', 'probability-distributions', 'exponential-distribution', 'order-statistics', 'probability']"
3231522,Spectral measure of a finite graph,"Let $A$ be the adjacency operator of connected, locally finite graph $G = (V,E)$ ( $A$ seen as an operator on $\ell^2(V)$ ). Then we have the spectral representation $$ A = \int_{\sigma(A)} t \mu(dt)$$ where $\mu$ is a resolution of the identity. For $u, v \in V$ , let $e_u$ be the vector in $\ell^2(V)$ whose $u$ -entry is $1$ and all other entries are $0$ . Define the spectral measures by $$\mu_{u,v}(dt) = \langle \mu(dt) e_u, e_v \rangle.$$ In this case, $\mu_{u,u}$ is the unique probability measure on $\mathbb{R}$ such that for all integers $k \geq 1$ , $$ \int_{\sigma(A)} t^k \mu_{u,u}(dt) = \langle A^k e_u, e_u \rangle.$$ Question: if $|V|$ is finite, then $A$ is a symmetric matrix (and self-adjoint), and the spectrum is discrete. If $(v_1, \ldots, v_n)$ is an orthonormal basis of eigenvectors associated to the eigenvalues $(\lambda_1, \ldots, \lambda_n)$ , how can one show from the definition that $$\mu_{u,u} = \sum_{k=1}^n \langle v_k, e_u \rangle^2 \delta_{\lambda_k},$$ or I think equivalently that $$\mu = \frac{1}{n} \sum_{i=1}^n \delta_{\lambda_i},$$ especially if one should be able to recover $A$ from $\mu$ ?","['integration', 'measure-theory', 'spectral-graph-theory', 'graph-theory', 'functional-analysis']"
3231536,Find the Minimum Value of $x^2+y^2$,"Given: $x+y=2\sin{a}-\cos{b}\\
xy=2\cos{a}+\sin{b}$ Find the minimum value of $x^2+y^2$ . Attempt: $\begin{aligned}
x^2+y^2&=(x+y)^2-2xy\\
&=(2\sin{a}-\cos{b})^2-2(2\cos{a}+\sin{b})\\
&=4\sin^2{a}-4\sin{a}\cos{b}+\cos^2{b}-4\cos{a}-2\sin{b}
\end{aligned}$ $\begin{aligned}
f_{a}(a,b)&=0\\
8\sin{a}\cos{a}-4\cos{a}\cos{b}+4\sin{a}&=0\\
\cos{a}\cos{b}&=2\sin{a}\sin{b}+\sin{a}\\
\end{aligned}$ $\begin{aligned}
f_{b}(a,b)&=0\\
4\sin{a}\sin{b}-2\sin{b}\cos{b}-2\cos{b}&=0\\
2\sin{a}\sin{b}&=\sin{b}\cos{b}+\cos{b}\\
\end{aligned}$ Tried to plot it on a graph, the answer should be -6.","['trigonometry', 'derivatives']"
3231543,"If $S_n$ is Binomial $(n,p)$ then $\mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-np}$.","I was reading this post , and I have to admit that I was quite confused. The question was : If $S_n$ is a Binomial r.v. with parameter $(n,p)$ s.t. $n$ large, $p$ very small and $np$ not to big (for instance $np\leq 10$ ), then $$\mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-np}.$$ What I completely agree is (using notation of the link I put) if $(B_m)$ is a sequence of $Binomial(m,p_m)$ where $\lim_{m\to \infty }mp_m=\lambda $ , then $$\lim_{m\to \infty }\mathbb P(B_m=k)=\frac{\lambda ^k}{k!}e^{-\lambda }.$$ I can prove it without any problem. Now, if $np\leq 10$ , $n$ big and $p$ small, I'm indeed confuse with $\mathbb P(S_n=k)\approx \frac{(np)^k}{k!}e^{-(np)}$ . Atempts Let $n\in\mathbb N$ large and $p$ small s.t. $np\leq 10$ . I set $\lambda =np$ . Then, define the sequence $p_m=\frac{\lambda }{m}$ , i.e. $mp_m=\lambda $ for all $m$ . So now, $\mathbb E[S_n]=\mathbb E[B_m]$ for all $m$ and if $p_m$ is very small, then $p_m\approx p$ and thus $$\text{Var}(S_n)=np(1-p)=mp_m(1-p)\underset{(*)}{\approx} mp_m(1-p_m)=\text{Var}(B_m).$$ Therefore, if $m$ is big enough, then $B_m$ and $S_n$ are Binomial distributed with same expectation and very close variance. Q1) Does this implies that $$\mathbb P(S_n=k)\approx \mathbb P(B_m=k) \ \ ?$$ i.e. that a Binomial is uniquely determined by its variance and expectation ? Q2) In what the fact that $np\leq 10$ is relevant ? I hope my question is clear, and if not, please let me know.",['probability']
3231558,$ \lim_{x\to \frac{1}{{\sqrt 2}^+}} \frac{\cos ^{-1} \left( 2x\sqrt{1-x^2}\right)}{x-\frac{1}{\sqrt{2}}}$,"$\displaystyle \lim_{x\to {1\over \sqrt{2}^+}} \dfrac{\cos ^{-1} \left( 2x\sqrt{1-x^2}\right)}{x-\dfrac{1}{\sqrt{2}}}$ I have tried substituting $x$ for $\sin \theta$ , doing the calculations and ended up with - $2√2$ . But the solution provided was $2√2$ . Then I tried this question again, but this time used $\cos \theta$ instead of $\sin \theta$ and the answer did match. I don't understand why $x$ as $\sin \theta$ doesn't give the correct result. I have checked all my steps but couldn't find any flaw with $\sin \theta$ as substitution. Can anyone tell me whether $\sin \theta $ a wrong substitution for this question or not?",['limits']
3231566,Can a matrix $A$ commute with $e^B$ without commuting with $B$?,"As in the title. Is it possible that $[A,B]\neq0$ , but $[A,e^B]=0$ ? I tried expanding the exponential and using $[A,B^n]=\sum_k {n\choose k} B^{n-k}[A,B]B^k $ but this doesn't seem to give any insight. I'm inclined to think the answer is yes, because a sum of terms being $0$ is a weaker requirement than each term being $0$ , but I was wondering if there's a clearer way to see it. EDIT: in light of lisyarus' answer, what if the matrices in question are hermitian and have real eigenvalues?","['matrices', 'matrix-exponential', 'linear-algebra']"
3231585,"$\{a_n\}$ be a sequence such that $ a_{n+1}^2-2a_na_{n+1}-a_n=0$, then $\sum_1^{\infty}\frac{a_n}{3^n}$ lies in...","Let $\{a_n\}$ be a sequence of positive real numbers such that $a_1 =1,\ \  a_{n+1}^2-2a_na_{n+1}-a_n=0, \ \ \forall n\geq 1$ . Then the sum of the series $\sum_1^{\infty}\frac{a_n}{3^n}$ lies in... (A) $(1,2]$ , (B) $(2,3]$ , (C) $(3,4]$ , (D) $(4,5]$ . Solution attempt: Firstly, we figure out what $\frac{a_{n+1}}{a_n}$ is going to look like. We get, from the recursive formula, $\frac{a_{n+1}}{a_n}=1+\sqrt{1+\frac{1}{a_n^2}}$ (remembering the fact that $a_n>0$ , the other root is rejected). We know that, if $\lim_{n \to \infty}\frac{a_{n+1}}{a_n}>1$ , then $\lim a_n \to \infty$ . Further, $(a_{n+1}-a_n)= \sqrt{a_n(a_n+1)}>0$ . (Again, the other root is rejected due to the same reason). Hence, $(a_n)$ increases monotonically. Therefore, the largest value of $\frac{a_{n+1}}{a_n}$ is approximately $1+\sqrt{1+\frac{1}{1}} \approx 2.15$ Now, the sum can be approximated as $\displaystyle\frac{\frac{1}{3}}{1-\frac{2.15}{3}} \approx 1.3$ (In actuality, $\mathbb{sum}< 1.3$ ). So, option $(A)$ is the correct answer. Is the procedure correct? I have been noticing a handful of this type of questions (based on approximations) lately, and the goal is to find out where the sum / the limit of the sequence might lie. Is there any ""definitive"" approach that exploits the recursive formula and gives us the value, or does the approach varies from problem to problem?","['approximation', 'proof-verification', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
3231634,"$\sin(\theta) + \sin(5\theta) = \sin(3\theta)$ . Find number of solutions and the solutions for this equation in $[0,\pi]$","I tried to solve the equation by doing this- $$2\sin(\frac{\theta+5\theta}{2})\cos(\frac{\theta-5\theta}{2})=\sin(3\theta)\\
  2\sin(3\theta)\cos(2\theta) = \sin(3θ)\\
  \cos(2θ) = \frac{1}{2}\\
  1-2\sin^2(θ) = \frac{1}{2}\\
\sin^2(θ) = (\frac{1}{2})^2\\
∴ θ = nπ ± α\\
Answer = \frac{π}{6},\frac{5π}{6} $$ But in the solution there are 6 solutions and in step 3 instead of dividing $\sin(3θ)$ by $\sin(3θ)$ they have taken it as common and made "" $\sin(3θ)(2\cos(2θ)-1)$ """,['trigonometry']
3231701,"$a$ and $b$ are solutions of $ \frac{1}{x^{2} - 10x-29} + \frac{1}{x^{2} - 10x-45} - \frac{2}{x^{2} - 10x-69} = 0 $, $a+b=?$","$a$ and $b$ are solutions of $$ \frac{1}{x^{2} - 10x-29} + \frac{1}{x^{2} - 10x-45} - \frac{2}{x^{2} - 10x-69} = 0 $$ What is $a+b=?$ $$ $$ Are there better approaches than the one below? Solution: By letting $x^{2} - 10x = y$ , then we have $$ \frac{1}{y-29} + \frac{1}{y-45} - \frac{2}{y-69} = 0, \:\: y \notin \{ 29,45,69 \} $$ and $$ (y-45)(y-69) + (y-29)(y-69) - 2(y-29)(y -45) = 0 $$ $$ (y- 69)(y-37) = (y-29)(y-45) $$ $$ y^{2} - 106 y + 69 \cdot 37 = y^{2}-74y + 29 \cdot 45 $$ $$ -32y = 3 (29 \cdot 15 - 23 \cdot 37) = -1248 $$ $$  y = x^{2} - 10x = 39$$ Here are the roots: $$ x^{2} -10x - 39 = 0 \implies (x-13)(x+3) = 0$$ So the answer is $a + b = 13 - 3 = 10$","['contest-math', 'algebra-precalculus', 'polynomials']"
3231714,Is a vector of independent Brownian motions a multivariate Brownian motion?,"Given a filtered probability space $(\Omega, \mathcal{F}, \mathcal{F}_{t\geq 0}, P)$ : If $B_1, B_2, \dots, B_m $ are all real $\mathcal{F}_t$ Brownian motions, jointly independent. Is the resulting vector $B = (B_1, B_2, \dots, B_m )$ an $\mathcal{F}_t$ $m$ -dimensional Brownian motion or just a natural one? To me it seems that I can't conclude that $B_t - B_s$ is independent of $\mathcal{F}_s$ even though all components are. In fact $P(\{B_{1,t}-B_{1,s} \in \Lambda_1\}, \dots,\{B_{m,t}-B_{m,s} \in \Lambda_m\}, A)$ for $\Lambda_i$ a borel set, and $A \in \mathcal{F}_s$ can't be factorized, because all events are only pairwise independent with $A$ . Am I missing something or am I correct? To summarise, if $X$ and $Y$ are independent, and also pairwise independent of a sigma-algebra $\mathcal{D}$ , I need that $\sigma(X,Y)$ independent of $\mathcal{D}$ to factorize the probabilities. Or in other words a random vector whose components are independent of a sigma algebra is not necessarily independent itself.","['stochastic-processes', 'measure-theory', 'brownian-motion', 'stochastic-calculus']"
3231776,Integer points on parabola,"I'm intrested in studying integer points on quadratic equations: $$Q(x,y)=ax^2+bxy+cy^2+dx+ey+f=0, \quad (a,b,c,d,e,f\in\mathbb{Z}).$$ Using Lagrange method it is possible to reduce it in a Pell equation $$X^2-DY^2=N,$$ with $$
X=(b^2-4ac)y+E, \quad Y=2ax+by+d,\quad N=E^2-F(b^2-4ac),
$$ easy to solve algorithmically if $Q(x,y)$ is not a parabola $(\Delta=b^2-4ac\neq 0)$ . How can I determine integer points on a quadratic equation with $\Delta =0$ ?","['number-theory', 'algebraic-geometry']"
3231815,"If $Y \sim \operatorname{Gamma}(a+1, 1), U_0 \sim \operatorname{Unif}(0, 1), U = U_0^\frac1a$, why $YU \sim \operatorname{Gamma} (a, 1)$?","Given random variables like below: $Y \sim \operatorname{Gamma}(a + 1, 1)$ $U_0 \sim \operatorname{Unif}(0,1)$ $U = U_0^\frac1a$ If $Y$ and $U_0$ is independent, How can I proof $X=YU \sim \operatorname{Gamma}(a, 1)$ ? I tried to solve this problem with theorem $f_{U,V}(u,v) = f_{X,Y}(h_1(u,v), h_2(u,v))|J|$ But I'm confusing what should be preimage.","['statistics', 'probability-distributions']"
3231910,Showing that $\sqrt{5} \in \mathbb{Q}(\sqrt[p]{2} + \sqrt{5})$,"I am attempting to show that $\sqrt{5} \in \mathbb{Q}(\sqrt[p]{2} + \sqrt{5})$ , where $p > 2$ is prime. I have already shown that $[\mathbb{Q}(\sqrt[p]{2}, \sqrt{5}) : \mathbb{Q}] = 2p$ . If needs be, I can understand that this might constitute proving that $\mathbb{Q}(\sqrt[p]{2} + \sqrt{5}) = \mathbb{Q}(\sqrt[p]{2}, \sqrt{5})$ , which I know intuitively but am unsure how to prove. In that regard, I am aware of questions such as this and this , but all answers provided either do not seem to generalize easily to cases where not both of the roots are square. are beyond the scope of my current course. Any help towards a (preferably low-level) proof of either the inclusion of $\sqrt{5}$ or the equality of $\mathbb{Q}(\sqrt[p]{2} + \sqrt{5})$ and $\mathbb{Q}(\sqrt[p]{2}, \sqrt{5})$ is much appreciated.","['field-theory', 'ring-theory', 'abstract-algebra', 'extension-field']"
3231983,Proof verification for $(A-B)-C = (A-C)-(B-C)$,"Let $A$ , $B$ , and $C$ be sets.
Prove that $(A-B)-C=(A-C)-(B-C)$ . I attempted to prove this with the following. I am very new to proof writing, and I feel I may have glossed over something or have done something just completely invalid. Any assistance with revisions or a superior method would be greatly appreciated. Suppose $x \in (A-B)-C$ . This would mean $x \in A$ , $x \notin B$ , $x \notin C$ . The statements $x \in A$ and $x \notin C$ could be written as $(A-C)$ . The statements $x \notin B$ and $x \notin C$ could be written as $-(B-C)$ . Together these statements could be written as $(A-C)-(B-C)$ . This shows that $(A-B)-C \subseteq (A-C)-(B-C)$ . Suppose $x \in (A-C)-(B-C)$ . This would mean that $x \in A$ , $x \notin B$ , $x \notin C$ . The statements $x \in A$ and $x \notin B$ could be written as $(A-B)$ . In addition $x \notin C$ , this combined with the earlier statement that $(A-B)$ would result in $(A-B)-C$ . This shows that $(A-C)-(B-C) \subseteq (A-B)-C$ . Concluding the proof that $(A-B)-C = (A-C)-(B-C)$ .","['elementary-set-theory', 'proof-verification']"
3231997,Fundamental vector field and moment map for action on mathematical pendulum.,"I am trying to compute the moment map , for an action. As I understand it if I have a configuration space which is given by a manifold $M$ and an action $\rho_g \colon M \to M$ , it induces an action on the phase space $(\rho_{g^{-1}})^* : T^*M \to T^*M$ , $(\rho_{g^{-1}})^* : (q,p) \mapsto (gq, (\rho_{g^{-1}})^*(p))$ . Then we can compute the fundamental vector field . Let $X\in \mathfrak{g}=T_eG$ be the an element of the Lie algebra, we then have $X^\#_{(q,p)}=\frac{d}{dt}_{\vert_{t=0}} \rho_{exp(tX)^{-1}}^*(q,p)$ . I was trying do do an example to understand how it works. The mathematical pendulum with coordinate $(\phi,\theta)$ , and the action (with $G=S^1$ ) $\rho_g : S^2 \to S^2$ , $\rho_{\theta}:(\phi_0,\theta_0) \mapsto (\phi_0,\theta_0+\theta)$ . But in practice, I am confused as to how exactly calculat $(\rho_{-\theta})^*$ and $X^\#_{(q,p)}$ .","['vector-fields', 'moment-map', 'group-actions', 'lie-groups', 'differential-geometry']"
3232027,"Does there exist a function $f_{\Box,\Box}(\Box)$ making the formula $a + (b \oplus c) = (f_{b,c}(a)+b) \oplus (f_{c,b}(a)+c)$ true?","Let $a$ and $b$ denote the resistances of two resistors. If they're put in series, the total resistance is $a+b$ . If they're put in parallel, the total resistance is $$a \oplus b := \frac{1}{\frac{1}{a}+\frac{1}{b}} = \frac{ab}{a+b}.$$ I suspect there's a formula describing how $+$ ""distributes over"" $\oplus$ . It should be of the form $$a + (b \oplus c) = (f_{b,c}(a)+b) \oplus (f_{c,b}(a)+c)$$ for an appropriate choice of $f$ . I haven't been able to find an $f$ that works, however. Question. Does there exist an $f$ making the above formula true? If not, why not? Remark. Unpacking the definitions, we're looking for a function $f$ such that $$(ab+ac+bc)(f_{b,c}(a)+b + f_{c,b}(a)+c)$$ and $$(b+c)(f_{b,c}(a)+b) (f_{c,b}(a)+c)$$ are equal.","['functional-equations', 'algebra-precalculus', 'rational-functions', 'real-analysis']"
3232057,Finding $\lim\limits_{n \to \infty }n\int_{0}^{1}\frac{x^{n}}{1+x+x^{n}}dx$,"$$\lim_{n \to \infty }n\int_{0}^{1}\frac{x^{n}}{1+x+x^{n}}dx$$ I factorize $x^n$ then I tried with $u=1+x^{1-n}$ but I didn't get too far. Also I tried to get something from $0<x<1$ . I know that if $x$ is from $(0,1)$ then $x^n$ tends to $0$ as $n \to \infty$ .","['limits', 'calculus']"
3232065,Axiom of Choice in General Topology,"I ask this question after having searched a bit the web and not having found much about the role of Axiom of Choice and General Topology. I am trying to answer: where does the axiom of choice enters General Topology? Would it be possible to track its impact on the subject and explicit its most profound consequences? What would General Topology look without it? Being only in my undergarduate studies I couldn't find a satisfactory answer. 
The fact is: I studied proofs involving AOC, in its equivalent formulation of Zorn's Lemma, both in Algebra (mainly about rings ideals and, most famously, the existence of a Hammel Basis for a vector space) and in  Analysis (extension theorems of linear maps, most importantly: the Hahn Banach theorem). In a hypothetical ""foundational hierarchy"" of Mathematics I would naively place General Topology somehow in the middle between Logic/Algebra and Analysis (I am obviously strongly stereotyping the concept! Don't misunderstand me) and so I would expect AOC to have a grip also in this field. Coming to what I know about General Topoloogy, it seems to me one AOC enters ""only"" in coverings and their properties (paracompactness, types of refinements...) which in turn found all the theorems about metrizability, metrics spaces and so on (gauges, uniform spaces, completeness). But I mean, one should expet this: we are somehow going in the direction of Analysis. There is much gneral topology beyond these topics. I hope you can help me, maybe also through articles/books.","['axiom-of-choice', 'general-topology', 'soft-question']"
3232098,Why can we consider this subsequence in $L^p$?,"I am trying to understand a step in the following proof of completeness of $L^p$ in Stein-Shakarchi's Functional Analysis . (See the proof on page 5 of the link or at the end of this post.) At the beginning of the proof, it is said that Let $\{f_n\}_{n=1}^\infty$ be a Cauchy sequence in $L^p$ , and consider a subsequence $\{f_{n_k}\}_{k=1}^\infty$ of $\{f_n\}_{n=1}^\infty$ with the following property $\|f_{n_{k+1}}-f_{n_k}\|\le 2^{-k}$ for all $k\geq 1$ . Question: Why can the sequence be considered as it is? On a YouTube video , it explains about a similar subsequence. I still don't understand why for $n,m>n_k$ $\Vert f_{n}-f_{m}\Vert_p\implies \Vert f_{n_k}-f_{n_{k+1}}\Vert_p$ , thus an increasing subsequence. Why is it justified to make $n$ to depend on $k$ , $n_k$ ?","['measure-theory', 'lp-spaces', 'functional-analysis', 'real-analysis']"
3232120,A riddle involving series.,"Father has left to his children several identical gold coins. According to his will, the oldest child receives one coin and one-seventh of the remaining coins, the next child receives two coins and one-seventh of remaining coins, the third child receives three coins and one-seventh of the remaining coins, and so on through the youngest child. If every child inherits an integer number of coins then find the number of children and gold coins. I tried to write $x_k$ as some function of $k$ (where $x_k$ is the number of coins taken by the $k_{th}$ child) but failed. All I could write is $x_k= k + \frac{1}{7}(n-k- S_{k-1})$ where $S_k$ denotes the sum of first $k$ terms then $S_k=\frac{n}{7} + \frac{6}{7}(S_{k-1} +k)$ but I cannot proceed further, please help.",['sequences-and-series']
3232124,$2\pi i\beta = \int\limits_{|z|=r} \frac{dz}{f(z)-z}$,"Let $\beta \in \mathbb{C^{*}}$ and $f(z) = z+ z^{k+1} - \beta z^{2k+1}$ . Show if if r is small enough then $$2\pi i\beta = \int\limits_{|z|=r} \frac{dz}{f(z)-z}$$ This is my input: I have to resolve it using residues aplications, so $$ \int\limits_{|z|=r} \frac{dz}{f(z)-z} =  \int\limits_{|z|=r} \frac{dz}{z+ z^{k+1} - \beta z^{2k+1}-z} = \int\limits_{|z|=r} \frac{dz}{ z^{k+1} - \beta z^{2k+1}} = \int\limits_{|z|=r} \frac{dz}{z^{k+1}(1-\beta z^{k})} $$ My question is, I have a lot of methods to resolve integrals by residues, in this case, I think I have to resolve it on unit disk for $z = e^{i \theta}$ I have to calculate his residue, but what are the singularities of $f(z)$ and what is the best method to resolve the exercise? Can you help me, please?","['complex-analysis', 'contour-integration', 'residue-calculus', 'complex-integration']"
3232149,Convergence of harmonic functions in $L^1$ implies uniform convergence on compact sets,"Resorting to an analog of what's done here , I'm trying to prove the following statement: Let $u_m: \mathbb{R}^n \to \mathbb{R}$ be a sequence of harmonic
   functions and suppose there exists a continuous function $u:
 \mathbb{R}^n \to \mathbb{R}$ such that $u_m$ converges to $u$ in $L^1$ in any compact subset, i.e., for every limited $A\subset
 \mathbb{R}^n$ , we have $$ \int_A \left\vert u_m(x) -
 u(x)\right\vert~dx \to 0, $$ as $m\to \infty$ . Show such convergence is uniform in compact sets. My attempt: Let $\Omega \subset \mathbb{R}^n$ be an open set and $(u_m)_{m \in \mathbb{N}} \subset C^{\infty}(\Omega)$ . If $\Omega$ is open, then $\Omega^c = \mathbb{R}^n \setminus\Omega$ is closed, so we may take $r = \frac{1}{2}dist(A, \Omega^c)$ and define $V = \cup_{x_0 \in A} B(x_0, r)$ such that $\tilde{A} = \overline{V}$ , where $B(x_0, r)$ denotes the ball of center $x_0$ and radius $r$ . At this point, I want to say there exists $n \in \mathbb{N}$ such that $\forall x_0 \in A$ , with $r$ as defined above, so that we may apply the mean value-property to $u_m(x_0) - u(x_0)$ in the following manner: $$
|u_m(x_0) - u(x_0)| \leq \frac{1}{|B(x_0, r)|} \int_{B(x_0, r)} |u_m(y) - u(y)| ~dy \leq \int_{\tilde{A}} |u_m(y) - u(y)| ~dy \to 0,
$$ as $m \to \infty$ , by the $L^1$ convergence hypothesis. Since $y \in \tilde{A}$ is arbitrary on the RHS of the last inequality, we'd conclude the convergence is uniform and the proof would be finished. However, the given function $u$ is not harmonic, only continuous, so we're not able to apply the mean-value theorem the way I described and follow on accordingly with the proof above. Is there any way to correct this? If not, then how may I prove such uniform convergence?","['partial-differential-equations', 'harmonic-functions', 'uniform-convergence', 'real-analysis']"
3232158,A nasty indefinite integral $ \int \frac{1}{x(x+1)(x+2)(x+3)(x+4) ... (x+m)} dx $,"Below is a problem from the book ""Calculus and Analytic Geometry"" by Thomas Finney. I am hoping somebody can check my work. I consider it to be a particular hard problem.
Thanks, Bob Problem: We dare you to evaluate this integral. $$ \int \frac{1}{x(x+1)(x+2)(x+3)(x+4) ... (x+m)} \,\, dx $$ Answer: To evaluate this integral, we will consider some special cases. For $m = 0$ we have: \begin{align*}
 \int \frac{1}{x} \,\, dx &= \ln|x| + C \\
\end{align*} Now for $m = 1$ we have the following integral: $$ \int \frac{1}{x(x+1)} \,\, dx $$ \begin{align*}
\frac{1}{x(x+1)} &= \frac{A}{x} + \frac{B}{x+1} \\
1 &= A(x+1) + B(x) \\
\end{align*} At $x = 0$ we have $1 = A(0+1)$ which yields $A = 1$ . \begin{align*}
A + B &=  0 \\
1 + B &= 0 \\
B &= -1 \\
\frac{1}{x(x+1)} &= \frac{1}{x} - \frac{1}{x+1}  \\
\int \frac{1}{x(x+1)} \,\, dx &=  \ln|x| -  \ln|x+1| + C \\
\end{align*} Now for $m = 2$ we have the following integral: $$ \int \frac{1}{x(x+1)(x+2)} \,\, dx $$ \begin{align*}
\frac{1}{x(x+1)(x+2)} &= \frac{A}{x} + \frac{B}{x+1} + \frac{C}{x+2} \\
1 &= A(x+1)(x+2) + B(x)(x+2) + C(x)(x+1) \\
\end{align*} At $x = 0$ we have $1 = A(0+1)(0+2)$ which yields $A = \frac{1}{2}$ . At $x = -1$ we have $1 = B(-1)(-1+2) = -B$ which yields $B = -1$ . At $x = -2$ we have $1 = C(-2)(-2+1) = 2C$ which yields $C = \frac{1}{2}$ . \begin{align*}
\frac{1}{x(x+1)(x+2)} &= \frac{ \frac{1}{2}}{x} - \frac{1}{x+1} + \frac{ \frac{1}{2}}{x+2} \\
\int \frac{1}{x(x+1)(x+2)} \,\, dx &= \frac{1}{2} \ln{|x|} - \ln{|x+1|} + \frac{1}{2} \ln{|x+2|} + C \\
\end{align*} Now for $m = 3$ we have the following integral: $$ \int \frac{1}{x(x+1)(x+2)(x+3)} \,\, dx $$ \begin{align*}
\frac{1}{x(x+1)(x+2)(x+3)} &= \frac{A}{x} + \frac{B}{x+1} + \frac{C}{x+2} + \frac{D}{x+3} \\
1 &= A(x+1)(x+2)(x+3) + B(x)(x+2)(x+3) + \\
 & C(x)(x+1)(x+3) + D(x)(x+1)(x+2) \\
\end{align*} At $x = 0$ we have $1 = A(0+1)(0+2)(0+3) = 6A$ which yields $A = 1/6$ . At $x = -1$ we have $1 = B(-1)(-1+2)(-1+3) = -2B$ which yields $B = -1/2$ . At $x = -2$ we have $1 = C(-2)(-2+1)(-2+3) = 2C$ which yields $C = 1/2$ . At $x = -3$ we have $1 = D(-3)(-3+1)(-3+2) = -6D$ which yields $D = -1/6$ . Hence, we have the following solution: $$ \int \frac{1}{x(x+1)(x+2)(x+3)} \,\, dx =
\frac{1}{6}\ln{|x|} - \frac{1}{2}\ln{|x+1|} + \frac{1}{2}\ln{|x+2|} - \frac{1}{6}\ln{|x+3|} + C $$ Now for $m = 4$ we have the following integral: $$ \int \frac{1}{x(x+1)(x+2)(x+3)(x+4)} \,\, dx $$ \begin{align*}
\frac{1}{x(x+1)(x+2)(x+3)(x+4)} &= \frac{A}{x} + \frac{B}{x+1} + \frac{C}{x+2} + \frac{D}{x+3} + \frac{E}{x+4} \\
1 &= A(x+1)(x+2)(x+3)(x+4) \\
  &+ B(x)(x+2)(x+3)(x+4) \\
  &+ C(x)(x+1)(x+3)(x+4) \\
  &+ D(x)(x+1)(x+2)(x+4)  \\
  &+ E(x)(x+1)(x+2)(x+3) \\
\end{align*} At $x = 0$ we have $1 = A(0+1)(0+2)(0+3)(0+4) = 24A$ which yields $A = 1/24$ . At $x = -1$ we have $1 = B(-1)(-1+2)(-1+3)(-1+4) = -6B$ which yields $B=-1/6$ . At $x = -2$ we have $1 = C(-2)(-2+1)(-2+3)(-2+4) = 4C$ which yields $C = 1/4$ . At $x = -3$ we have $1 = D(-3)(-3+1)(-3+2)(-3+4) = -6D$ which yields $D=-1/6$ . At $x = -4$ we have $1 = E(-4)(-4+1)(-4+2)(-4+3) = 24E$ which yields $E=1/24$ . Hence we have the solution: Now for $m = 4$ we have the following integral: $$
\int \frac{1}{x(x+1)(x+2)(x+3)(x+4)} \,\, dx
 = \frac{\ln{|x|} - 4\ln{|x+1|} + 6\ln{|x+2|} - 4\ln{|x+3|} + \ln{|x+4|}}{24} + C $$ Now let's consider the general case. \begin{align*}
\frac{1}{x(x+1) \cdots (x+m)} \,\, &= \frac{C_0}{x} + \frac{C_1}{x+1} \cdots + \frac{C_m}{x+m} \\ 
\end{align*} \begin{align*}
1 &= {C_0}(x+1)(x+2) \cdots (x+m) \\
  &+ {C_1}(x)(x+2) \cdots (x+m) \\
  &+ {C_2}(x)(x+1)(x+3)(x+4) \cdots (x+m) \\
  &+ \cdots \\
  &+ C_m(x)(x+1)(x+2) \cdots (x+m-1) \\
\end{align*} Now let's consider the first term. We set $x = 0$ and we get: \begin{align*}
1 &= {C_0}(0+1)(0+2) \cdots (x+m) = m! C_0 \\
C_0 &= \frac{1}{m!}
\end{align*} Now let's consider the $C_2$ term. We set $x = 2$ and $m > 4$ . We get: \begin{align*}
1 &= C_2(-2)(-2+1)(-2+3)(-2+4)(-2 + 5) \cdots (-2 + m) \\
1 &= C_2 (2)(1)(2)(3)(4) \cdots (m-2) \\
1 &= 2(m-2)! C_2 \\
C_2 &= \frac{1}{2(m-2)!} = \frac{m(m-1)}{2(m!)} \\
C_2 &= \frac{ \binom {m}{2} } {m!} \\
\end{align*} Now let's consider the last term. We set $x = -m$ and we get: \begin{align*}
1 &= C_m(-m)(-m+1)(-m+2) \cdots (x+m -1) \\
C_m &= \frac{(-1)^{m}}{m!} \\
\end{align*} Now let's consider one of the middle terms. We set $x = -k$ where $0 <= k <= m$ and we get: \begin{align*}
1 &= C_k(-k)(-k+1)(-k+2) \cdots (-1) (1)(2) \cdots (-k + m - 1) \\ 
1 &=  {-1}^k C_k(k-1)(k-2) \cdots  (1)(2) \cdots (-k + m - 1) \\
C_k &= \frac{ 1 }{ {(-1)}^k C_k(k-1)(k-2) \cdots  (1)(2) \cdots (-k + m - 1)  } \\
C_k &= \frac{ k! }{ {(-1)}^k C_k(k-1)(k-2) \cdots  (1)m!  } \\
C_k &= \frac{ \binom {m}{k} }{ {(-1)}^k m!  } \\
\end{align*} Hence the answer is: $$ \sum_{k=0}^{k=m} \left( \frac{ \binom {m}{k} }{ {(-1)}^k m!  }\right) 
\ln{|x+k|} + C $$","['integration', 'calculus', 'solution-verification']"
3232160,Show that there is no vector field with transitive orbit on $\mathbb{R}^{2}$,"I need to show that there is no vector field with transitive orbit on $\mathbb{R}^{2}$ . Let $X:\mathbb{R}^{2}\rightarrow\mathbb{R}^{2}$ a $C^{k}, k\geq 1$ , vector field in $\mathbb{R}^{2}$ .
The integral curves of $X$ are the solutions $\phi_{p}(t)$ of the system $x'=X(x)$ through the point $p\in\mathbb{R}^{2}$ defined on its maximal interval $I_{p}$ The orbits of $X$ are the sets $\gamma_{p}=\{\phi_{p}(t):t\in I_{p}\}$ . A transitive orbit of $X$ is a dense orbit of $X$ , i.e., $\bar{\gamma_{p}}=\mathbb{R}^{2}$ . Is there some theorem that I can use to solve my question? I tried to suppose that $X$ has dense orbit and get a contradiction, but I didn't got anything.","['vector-fields', 'ordinary-differential-equations']"
3232218,The behaviour of functions nested under themselves outwith their domains,"This question follows from some interesting observations on a sum of reciprocals . Instead of summing them however, we will place each fraction to make a continued fraction. Some visualisations on Desmos on nested functions have led to the following observations/questions. In particular, we will focus on nests that exhibit cycles, and hence a closed form for the functions in consideration can be deduced. Some issues arising from this will also be discussed. Let us firstly start with the function $$f(x)=\frac1{1+\frac x{1+\frac x{1+\cdots}}}\implies \frac1{f(x)}=1+xf(x)\implies f(x)=\frac{-1+\sqrt{1+4x}}{2x}$$ where we take the positive root as $f(x)>0$ for $x>0$ . The domain is $x\in\left[-\frac14,\infty\right)\setminus\{0\}$ , meaning that the closed form does not represent the values when $x<0$ . This is shown in the following plot; in red is $f$ represented as a nest, in green is $f$ in its closed form, and in blue is a function of the form $\tan(x^{1/k}\ln x)$ , which is alike to $f$ for negative $x$ when reflected across the $y$ -axis. It is natural to think that solving $f(-x)=\frac1{1-\frac x{1-\frac x{\cdots}}}$ for itself suffices to tackle the problem, but note that this still brings up a rational function of a similar form. Similarly, consider the function $$g(x)=\frac1{x-\frac1{x-\cdots}}=\frac1{x-g(x)}\implies g(x)=\frac{x\pm\sqrt{x^2-4}}2$$ where the domain now is $|x|\in[2,\infty)$ . A simple inspection of the nest of $g$ (in here ) reveals that there is much more to its behaviour outwith the domain. The function $g(x)$ is much 'denser' at $\pm2$ and displays more regular features after it. Question Is there a way to model the behaviour of such nested functions, for values that the domains of their closed forms do not cover?","['functions', 'closed-form', 'real-analysis']"
3232248,What does it mean for something to be strictly less than $\epsilon$ for an arbitrary $\epsilon$?,"Perhaps a trivial question, but something I never completely understood.  If we have shown that $a-b < \epsilon$ for all $\epsilon > 0$ , then does that imply that $a-b \le 0$ ? I""m interested in it in the context of this question: Proving that $ f: [a,b] \to \Bbb{R} $ is Riemann-integrable using an $ \epsilon $-$ \delta $ definition. and in page 172 of these notes: http://alpha.math.uga.edu/~pete/2400full.pdf","['epsilon-delta', 'calculus', 'real-analysis']"
3232250,Why is this integration method not valid?,Let $$I=\int \frac{\sin x}{\cos x + \sin x}\ dx \tag{1}$$ Now let $$u=\frac{\pi}{2} - x \tag{2}$$ so $$I=\int \frac{\sin (\frac{\pi}{2} - u)}{\cos (\frac{\pi}{2} - u)+\sin (\frac{\pi}{2} - u)}\ du \tag{3}$$ $$=\int\frac{-\cos u}{\sin u + \cos u} \ du \tag{4}$$ $$= \int\frac{-\cos  x}{\sin x + \cos x} \ dx \tag{5}$$ and hence $$2I=\int\frac{\sin x - \cos x}{\sin x + \cos x} \ dx \tag{6}$$ $$=-\ln\ |\sin x + \cos x| + c \tag{7}$$ $\implies I=-\frac{1}{2}\ln|\sin x + \cos x| + c \tag{8}$ But the actual answer is $$I= \frac{1}{2}x -\frac{1}{2}\ln|\sin x + \cos x| + c \tag{9}$$ according to Wolfram Alpha and supported by a different method. Why does my method not yield the correct result?,"['integration', 'substitution']"
3232333,Prove $\iiint_V\frac{1}{\sqrt{(x-a)^2+(y-b)^2+(z-c)^2}}dV$ is constant inside a ball,"I have been struggling with this problem for a while: Let $V$ be the volume: $$V=\{(x,y,z)| R_1^2\leq x^2+y^2+z^2\leq R_2^2\}$$ Such that $0<R_1 <R_2$ . We will define a new function $\phi(a,b,c)$ , which is defined for every $(a,b,c)\notin V$ : $$\phi(a,b,c)=\iiint_V\frac{1}{\sqrt{(x-a)^2+(y-b)^2+(z-c)^2}}dxdydz$$ Our task is to prove that $\phi(a,b,c)$ is constant inside the ball $B((0,0,0),R_1)$ . I tried to change the variables using spherical coordinates: $$x=r\cos\varphi\sin\theta$$ $$y=r\sin\varphi\sin\theta$$ $$z=r\cos\theta$$ $$r\in[R_1,R_2], \theta \in[0,\pi] ,\varphi \in[0,2\pi]$$ And then solve the integral, proving it is constant when $r<R_1$ , but the integral was a bit hard to solve. I assume there's an easier way - but I couldn't think of one. Thanks! P.S. - Yes, I noticed the Physics here - electric potential inside a ball! But unforunately this is not the course - I have to be rigorous.",['multivariable-calculus']
3232403,If two medians are congruent... is the triangle isosceles in a Hilbert plane?,"If $ABC$ is a triangle for which two medians are congruent... is it true that the triangle $ABC$ is isosceles in a general Hilbert plane? I am having a little bit of trouble trying to prove this, if it is true. Here is my try, in a Hilbert Plane with the parallelism axiom: First, let $CD,\,BE$ be the medians of the sides $AC$ and $AB$ , respectively. Let $M$ be the point where these medians cut (that exists, as an easy application of Pasch's axiom). By hypothesis, $AD=BD$ , $AE=CE$ , and $BE=CD$ (hence $AB=2AD=2BD,\,AC=2AE=2CE)$ . Assuming the parallelism axiom , we have by Thales theorem (VI 2), that, since: $$\frac{AB}{AD}=\frac{AC}{AE}$$ $DE$ is parallel to $BC$ , and the triangles $ADE$ and $ABC$ are similar. In particular, $BC=2DE$ . Applying (I29) twice, we can conclude that the triangles $BCM$ and $EDM$ have all the same angles, so by (VI 4), we conclude that these are similar triangles. But then: $$\frac{BC}{ED}=\frac{CM}{DM}$$ And the left hand side equals $2$ , so we conclude that $CM=2DM$ , or in other words, $-$ since $CD=CM+MD\,-$ , that $CD=\frac{3}{2}CM$ . On the other hand, we also have that: $$\frac{BC}{ED}=\frac{BM}{EM}$$ And since the left hand side is equal to $2$ , we also obtain that $BM=2EM$ , or simply, that $BE=\frac{3}{2}BM$ But by hypothesis, $BE=\frac{3}{2}BM=\frac{3}{2}CM=CD$ , therefore $BM=CM$ . Applying (I6) to the isosceles triangle $MBC$ we conclude that $\angle MBC=\angle MCB$ . And then: $$\begin{cases}
  \ BE=CD\,\text{ (by hypothesis)} \\
  \ \angle EBC=\angle DCB\,\text{ (since we just proved that }\angle MBC=\angle MCB) \\
  \ CB=BC\,\text{ (C2)} \\
\end{cases}$$ So by (C6) we conclude that the triangles $EBC$ and $DCB$ are congruent. In particular, $CE=BD$ . Since $AB=2BD$ and $AC=2CE$ , we conclude that $AB=AC$ , and then the triangle $ABC$ is isosceles This proof relied heavily in the theory of similar triangles that can only be developed assuming the parallelism axiom. However, can this be proved in a more general context, avoiding the use of the parallelism axiom, or any of its consequences? Can there be a non-euclidean model of the Hilbert plane in which this statement is false?. Any comments about this will be appreciated.","['euclidean-geometry', 'noneuclidean-geometry', 'axioms', 'geometry', 'axiomatic-geometry']"
3232426,Finding the derivative of $ g(x) = tan(3x) $ using the definition,"I was asked to find the derivative of $tan(3x)$ using the limit definition I am bit stuck at the steps, can anyone please explain ? Thank you so much , would be a great help !","['limits', 'derivatives']"
3232479,"If $\int_a^bg(x)dx=0$, show that $\int_a^bf(x)g(x)dx=0.$","Let $g(x)\ge0$ . If $\int_a^bg(x)dx=0$ , show that $\int_a^bf(x)g(x)dx=0,$ where $f$ is any integrable function. If simeone is allowed to use the Mean Value thorem for integrals, the proof is at hand. But for that $f$ must be continuous! Any suggestion?","['integration', 'calculus', 'riemann-integration', 'real-analysis']"
3232485,Construct a rank-3 matroid using rank-2 flat,"Let $E$ be a finite set with size bigger or equal to 3. Let $L$ be a collection of subsets of $E$ such that: $2 \leq |A| < |E|$ for any $A \in L$ $|A \cap B| \leq 1$ for any $A, B \in L$ Now show that there exists a unique simple rank-3 matroid $M$ on $E$ such that $L$ is exactly the collection of all rank-2 flat. Also, describe the set of basis of $M$ in terms of $L$ . I have difficulty in finding those independent sets and also do not know how to define a rank function such that all elements in $L$ has rank 2. I can come up with an example like $U_{3, 4}$ . In $U_{3, 4}$ , $L$ is just all the set with size 2 and it is unique up to isomorphism. At least now I know that there is a matroid that can be built up in this way but fail to prove the more general theorem. Any responses will be appreciated. Update_1: Hinted by Joshua, I consider the characterization of flats of a matroid but used the definition from here . This time I have trouble proving the third axiom and also do not know how to make these flats have rank 2.","['projective-geometry', 'matroids', 'combinatorics', 'discrete-mathematics', 'elementary-set-theory']"
3232500,"Build up a matroid using a ""rank-like"" function","It is not hard to show that given a matroid ( $E, L$ ) and a defined rank function, $L$ is exactly those subsets whose rank is equal to the size. The following question is about how to build up a matroid using a function that has exactly the same 3 properties as a rank function has. Let $E$ be a finite set and $f$ a function from $\mathscr P(E)$ to $\mathbb{Z}$ such that: $f(\emptyset) = 0$ Whenever $X \subseteq Y$ , $f(X) \leq f(Y)$ For any $X, Y$ , $f(X)+f(Y) \geq f(X \cup Y)+f(X \cap Y)$ The question is: Show that the following set: { $A \subseteq E \;|\; f(B) \geq |B| \hspace{.1cm} \forall \hspace{.1cm} B \subseteq A$ } is the independent set of a matroid on $E$ . I mainly have difficulty in prove the exchange property. One of my attempts is to prove by contradiction. If I assume $X$ and $Y$ are both in $L$ and $|X| = |Y| + 1$ , assume $Y \cup {x} \notin L$ for any $x \in X$ . Then fix an $x \in X$ \ $Y$ and assume $Y_1 \subseteq Y$ satisfy $f(Y_1) < |Y_1|$ . Say $Y_1 = A_1 \cup {x}$ where $A_1 \in L$ . Then I can only conclude that: $f(A_1) + f({x}) \geq |Y_1| > f(Y_1)$ I do not know how to proceed then.","['elementary-set-theory', 'matroids', 'combinatorics', 'discrete-mathematics']"
3232510,Every surjective isometry on a Hilbert space is indeed a unitary operator,"I have a little bit confused on unitary operators and surjective isometries on a Hilbert space. I think it is quite clear that A operator is unitary if and only if it is a surjective isometry . However, according to the first line of the 2nd page of https://link.springer.com/article/10.1007/BF02761592 (or first paragraph of the 2nd page of https://core.ac.uk/download/pdf/82282502.pdf ), there are more surjective isometries on a Hilbert space onto itself than unitary operators. Is it a contradiction or did I misunderstand something?","['operator-algebras', 'metric-spaces', 'hilbert-spaces', 'functional-analysis', 'isometry']"
3232511,Chain rule in derivatives,"Well, I have to derive this function: $$f(x)=\sin(2x \sqrt[3]{x+1} )$$ I want to use the chain rule, and I want to use it like this;
I will call: $$T=x+1$$ $$Q=2x. \sqrt[3]{t} $$ $$f=\sin (Q)$$ So then I have: $$\cfrac{df}{dx} = \cfrac{df}{dQ} . \cfrac{dQ}{dT} . \cfrac{dT}{dx} . $$ And now I just have to derive. For example, $$\cfrac{df}{dQ} = \cos (Q) $$ and then I put $$2x. \sqrt[3]{t} $$ instead of Q, and so on. But what should I do when I want to do $ \cfrac{dQ}{dT} $ ? Because I have a product, and I know that I have to use the product rule and it would be $$Q'=2x'.\sqrt[3]{t}+2x.(\sqrt[3]{t})'$$ but what shall I do when deriving that X in $(2x)'$ ? Because the derivative is $ \cfrac{dQ}{dT} $ , not $ \cfrac{dQ}{dx} $ I know that I could avoid putting names to these ""sub-functions"", but this way is easier to me, so, please, don't teach me any other method.
Thanks!","['calculus', 'derivatives', 'chain-rule']"
3232521,Shortest distance between two rectangles in 2D,"Given the center points and dimensions of two rectangles and the angles $\theta_1$ and $\theta_2$ , how to calculate the shortest distance between two rectangles ( $d$ )? $\theta$ is the angle that the length of rectangle makes with $X$ axis on a $2D$ plane.","['euclidean-geometry', 'rectangles', 'geometry']"
3232525,What's the probability that the teacher teaches her class?,"Hi, thanks for reading! I really need help with this question. I'll post all my progress below - I tried really hard being as thorough as possible, but if I don't meet the guidelines for how a homework question should be asked, please tell me and I'll edit my question! Progress so far: Here is what I'm thinking. Let $P(A)$ be the probability that the professor teaches the class. Let $P(B)$ be the probability that the weather is bad Let $P(S)$ be the probability that an individual student shows up, for any student. Let $P(G)=P(B^C)=(1-P(B))$ be the probability that the weather is good. The weather being good is the complement of the weather being bad. Let $p_b$ be the probability that the student shows up given that the weather is bad. Let $p_g$ be the probability that the student shows up given that the weather is bad. The probability that the weather was bad and a student shows up would be $(p_{b})P(B)$ The probability that the weather was bad and a student shows up would be $(p_g)(1-p(B))$ Let $n$ be the number of students in the class. Let $k$ be the minimum number of students for the teacher to teach. For a student, the probability that they show up on any given day is equal to the probability that they show up and the weather was bad or they show up and weather was good. Since the weather being good and the weather being bad are disjoint events, that means the probability that a student shows up on any given day is the sum of the two probabilities. $P(S)=P(S \cap B)+P(S \cap B^C) = p_{b}P(B) + p_{g}(1-P(B))$ Let's say we want to calculate the total probability that $j$ students show up. Then, we would need to calculate the number of ways that $j$ students CAN show up, which would be $n\choose{j}$ , and multiply it by the probability of one of the specific outcomes where $j$ out of the $n$ students showed up, which would be: $(p_{b}P(B) + p_{g}(1-P(B)))^j *(1-p_{b}P(B) - p_{g}(1-P(B)))^{n-j}$ So, the total probability that $j$ of the $n$ students show up is: $${n \choose j} (p_{b}P(B) + p_{g}(1-P(B)))^j *(1-p_{b}P(B) - p_{g}(1-P(B)))^{n-j}$$ Okay. Almost done. The professor will teach if at least $k$ of the $n$ students show up. That means she'll teach if $k$ of them show up, or $k+1$ of them show up...etc...up to if all $n$ of them show up. Each of the events: $1$ student shows up, $2$ students show up, $3$ students show up...etc...are disjoint. So, the total probability one or the other or the other or the other or....etc....of them happening is the sum of their individual probabilities. Therefore, the probability of the teacher teaching would be given by the probability that $k$ students show up + the probability that $k+1$ students show up plus the probability that $k+2$ students show up plus.....plus the probability that all $n$ students show up. $$P(A) = \sum_{j=k}^{n} {n \choose j} (p_{b}P(B) + p_{g}(1-P(B)))^j *(1-p_{b}P(B) - p_{g}(1-P(B)))^{n-j}$$ WHEW. That was a lot of writing! If you've followed me so far, thank you so much. However, that answer is wrong! Here's the correct answer: Now, the correct answer makes sense to me. However, so does mine...I can't see where I went wrong. I thought perhaps we were both saying the same thing, but writing it differently. But then I tested it out in Wolfram Alpha, and alas, the two equations give different answers. $n=10, \: k=3, \: p_b=0.4, \: p_g = 0.7, \: P(B)=0.8, \: (1-P(B))=0.2$","['combinatorics', 'probability']"
3232531,Finding the equivalence classes of the relation R,"Find the equivalence classes of the relation R = {(0, 0),(1, 1),(1, 2),(2, 2),(2, 1),(3, 3),(3, 4),(4, 3),(4, 4)} on the set A = {0, 1, 2, 3, 4}. How do i solve this question. I'm attempting to teach myself at the moment so any help will be appreciated. As far as i'm aware the equivalence class of a is the set of all elements x in A, such that x is related to a by r.","['equivalence-relations', 'discrete-mathematics']"
3232557,A question about the proof of Theorem 5.21 in Van der Vaar(1998),"If we know that $\hat\theta_n\overset{p}\to\theta_0$ , how does the following equation \begin{equation}
\sqrt{n}V_{\theta_0}\cdot(\theta_0-\hat\theta_n)+\sqrt{n}o_p(|\hat\theta_n-\theta_0|)=G_n\psi_{\theta_0}+o_p(1)\qquad\qquad(1)
\end{equation} become $$\sqrt{n}V_{\theta_0}\cdot(\hat\theta_n-\theta_0)=-G_n\psi_{\theta_0}+o_p(1)?\qquad\qquad(2)$$ This is part of proof for Theorem 5.21 on page 52-53 in Van der Vaar(1998).  I wonder how can the term $\sqrt{n}o_p(|\hat\theta_n-\theta_0|)$ in equation (1) be omitted. The author also provide an inequality between these two equations. That is, $$\sqrt{n}|\hat\theta_n-\theta_0|\le|V_{\theta_0}^{-1}|\sqrt{n}|V_{\theta_0}(\hat\theta_n-\theta_0)|=O_p(1)+o_p(\sqrt{n}|\hat\theta_n-\theta_0|)\qquad\quad (3)$$ He also writes, ""This implies that $\hat\theta_n$ is $\sqrt{n}$ -consistent: The left side is bounded in probability. Inserting this
in equation (1), we obtain equation (2).""","['statistics', 'probability-distributions', 'convergence-divergence', 'probability-theory', 'probability']"
3232595,QR decomposition with lower triangular matrix using Householder reflection,"Problem Find householder matrices $H_1,H_2,\cdots,H_n$ such that $$
H_n\cdots H_1 A = L
$$ where $A$ : $n \times n$ matrix and $L$ : $n \times n$ lower triangular matrix . Try By defining $v_k:= [\cdots, sgn(x_k) |x_k|, \cdots]$ and $H_k := I - 2v_kv_k^T/v_k^Tv_k$ , we can make $$
H_n\cdots H_1 A = U
$$ where $U$ : $n \times n$ upper triangular matrix But I'm currently stuck at how to define $v_k$ to make RHS lower triangular.","['numerical-linear-algebra', 'linear-algebra', 'matrix-decomposition']"
3232602,Proof verification: At most countably many local maxima,"I'd appreciate a second pair of eyes on a proof. I want to prove that a function $f:\mathbb{R}\to\mathbb{R}$ can have at most countably many strict local maxima. The question has been asked elsewhere on Stack Exchange, but my question is about the validity of the following argument, which isn't discussed. Assume for contradiction that $f$ has uncountably many strict local maxima. For each $n\in\mathbb{N}$ , define $$E_n=\Big\{x\in \mathbb{R}: f(x)>f(y) \hspace{2mm}\text{for all $y$ such that $0<|x-y|<\frac{1}{n}$} \Big\}.$$ For example, if $x\in E_3$ , then $x$ provides a strict local maximum on at least an open interval of radius $\frac{1}{3}$ . If each $E_n$ was at most countable, then $\bigcup^{\infty}_{n=1}E_n$ would be countable as well, contrary to assumption. Hence, some set, say $E_{n_0}$ , is uncountable. Being uncountable, the set $E_{n_0}$ has a limit point, $\xi$ . But now this gives a contradiction. Let $\{x_k\}_{k=1}^{\infty}$ be a sequence in $E_{n_0}$ converging to $\xi$ . Let $x_i$ and $x_j$ be terms satisfying $|x_i-\xi|<\frac{1}{2n_0}$ and $|x_j-\xi|<\frac{1}{2n_0}$ . Then $|x_i-x_j|<\frac{1}{n_0}$ by the triangle inequality. Since $f(x_i)$ is a strict local maximum on an interval about $x_i$ of radius $\frac{1}{n_0}$ , we have $f(x_i)>f(x_j)$ . But for the same reason we must have $f(x_j)>f(x_i)$ , which is a contradiction. Thanks in advance for your feedback.","['proof-verification', 'real-analysis']"
3232614,Compactness when mapping into a higher $L^p$ space and then back,"Question: Let $q>p \ge 1$ and let $T:L^p[0,1] \to L^q[0,1]$ be a bounded linear operator. Let $i: L^q[0,1] \to L^p[0,1]$ be the inclusion map (which is bounded). Is the composition $i\circ T$ necessarily a compact operator on $L^p$ ? We can assume $p\in (1,\infty)$ if the uniform convexity of the underlying space helps in some way, though the boundary cases might be interesting themselves. Context: This was inspired by this question , where the accepted answer covers the case $q=\infty$ (in that case the composition is indeed always compact). I've been at it for a couple days trying to prove and also to disprove it. It might be trivial with a silly oversight on my part (because I don't know too many explicit examples of bounded operators from $L_p \to L_q$ ), but on the other hand it could be inherently nontrivial as well, and I was hoping to learn some new funfact about the geometry of Banach spaces in case of the latter. Ideas: To prove that it is compact, here are a couple of ideas that I played around with. One suggestion is to somehow translate the problem to a statement about $\ell^p$ spaces and then apply Pitt's theorem . Unfortunately there seems to be no clear way to do this, for example any attempt at using a Fourier transform (which boundedly sends $L^p \to \ell^{\frac{p}{p-1}}$ and $\ell^p \to L^{\frac{p}{p-1}}$ for $1< p < 2$ ) will somehow ""go the wrong way."" A second idea is to try to find a Banach space $X$ which has the Dunford-Pettis property (e.g. a $L^1(\mu)$ or $C(K)$ space) and which nests in between $L^p$ and $L^q$ , i.e., $L^q \subset X \subset L^p$ . This would easily show compactness of $i\circ T$ , but finding such $X$ seems not too easy. A third idea is to try to mimic the proof of Pitt's theorem adapted to this $L^p$ context. Basically suppose $i\circ T$ was not compact. Then we can find $f_n \in L^p$ with $\|f_n\|_p=1$ and $f_n \to 0$ weakly, and also $\|Tf_n\|_p \ge \delta>0$ . Then (after perhaps passing to a subsequence) one may try to show that $T$ is bounded below on the closed linear span of the $f_n$ , which would imply that the image of $T$ contains a closed infinite-dimensional subspace of $L^p$ . And I'm farily certain that such a subspace cannot be contained in $L^q$ (never mind: this turns out to be false, see answer below). But formalizing these ideas might take some work. A fourth idea is to try to use type-cotype considerations which I don't know much about, but have been powerful in the context of classifying $L_p$ spaces up to isomorphism. On the other hand, here are some ideas for potential counterexamples if it turns out to be false. For one idea let us identify $L^p[0,1] \simeq L^p(\Bbb R)$ and consider the Fourier transform $\mathcal F:L^p(\Bbb R) \to L^{\frac{p}{p-1}}(\Bbb R)$ , where $p<2$ . I've shown that $\mathcal F$ is not a compact operator. Hence there is at least a noncompact operator from $L^p[0,1] \to L^{\frac{p}{p-1}}[0,1]$ for $p<2$ (which brings up another question of what if we restrict attention to $q>p^*$ , then can we say that $T$ itself is compact?... but perhaps that's for another day). However, the difficult thing is to show that it remains noncompact when we compose it with the inclusion map, and I think that it actually becomes false. I played around with the Hermite functions $\psi_n$ which orthonormally diagonalize $\mathcal F$ on $L^2(\Bbb R)$ , and I was able to compute that $\|\psi_n\|_{L^p(\Bbb R)} \sim_n C_p n^{\frac1{3p}-\frac16}$ , so while these converge weakly to $0$ in $L^2(\Bbb R)$ they fail to do so in $L^p(\Bbb R)$ for $p<2$ , hence they are useless for us. A second idea is to use some of the abstract mappings mentioned in this MO thread and the subsequent comments . Actually this might all be trivial from some proposition in Albiac-Kalton but I can't access the book at the moment.","['banach-spaces', 'fourier-analysis', 'real-analysis', 'lp-spaces', 'functional-analysis']"
3232645,Inverse Laplace transform of $F(s)=\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}}$ using complex integration,"I want to find the inverse Laplace transform of $$F(s)=\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}}$$ I tried to use the Bromwich integral $$f(t)=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\frac{1}{s\sqrt{s+b\sqrt{as}\tanh{(\sqrt{as})}}}e^{st}\,ds$$ My progress so far has been stunted by the fact that we have a branch point at s=0. The contour may be like this. But I don't know how to perform the integration. Any help is appreciated.","['complex-analysis', 'contour-integration', 'laplace-transform']"
3232654,Is the matrix $\sum_{g \in G} a_g \rho(g)$ normal and what further properties does it have?,"Let $\rho$ be the regular representation of $G$ . $S \subset G$ a generating set, $|g| := |g|_S=$ word length with respect to $S$ . Then I construct such a matrix, where we have some ordering $g_i$ of the group $G$ : $$ a_{i,j} = \frac{1}{1+|g_i g_j^{-1}|}$$ This is a group matrix as defined by Dedekind and Frobenius. Let $H_G:= \sum_{g \in G} \frac{1}{|g|+1}$ be the harmonic number associated to $S$ and $G$ . Here are my conjectures concerning this matrix some of which I can prove: $H_G = |A|$ , where $|A|$ denotes the spectral norm of $A$ [proved with Perron Frobenus theorem] (If 1. is true, then by definition of $A$ we must have that $1/H_G A = 1/|A| A $ is a doubly stochastic matrix [that $\frac{1}{H_G}A_G$ is doubly stochastic and positive is clear from definition, so this is also proved] $A = \sum_{g \in G} \frac{1}{1+|g|} \rho(g)$ is the Birkhoff-Neunmann decomposition induced by the doubly stochastic matrix [ proved, by comment of darijgrinberg] Using 3. I can prove that $A$ is a normal matrix $A$ is non-singular. [that is unclear to me, but numerics suggest that's true] If we regard 3. as the definition of $A$ then I am able to show that $A$ is normal: It basically boils down to $\rho(g)^T = \rho(g)^{-1}$ as $\rho$ is a permutation matrix and hence orthogonal and that: $$\sum_{g,h \in G} \rho(g^{-1} h) = \sum_{g,h \in G} \rho(g h^{-1})$$ However I am a bit unsure about the last step. For the 1. part:
I think of using the Perron Frobenius theorem on the positive and doubly stochastic matrix $$\frac{A}{H_G}$$ I can prove that $$A \cdot 1 = H_G \cdot 1$$ where $1$ is the vector consisting of all $1$ -s. For the 5. part: By a therorem (page 12) of Frobenius, we have: $$\det(X_{gh^{-1}}) = \prod_{ \rho \text{ irred }}\det(\sum_{g \in G} X_g \rho(g))^{\deg(\rho)}$$ Hence for 5. it remains to show that if $\psi$ is an irreducible representation then: $$0 \neq \det(\sum_{g \in G} \frac{1}{1+|g|} \psi(g))$$ Maybe this could be proved with Fourier Analysis of finite groups? Any help for proving 1-5 is highly appreciated. Thanks for your help! Related: https://mathoverflow.net/questions/330359/what-properties-characterize-the-function-lx-x-expx-logx","['spectral-norm', 'representation-theory', 'finite-groups', 'markov-chains', 'matrices']"
3232737,Finding range of $a$ in exponential inequality,"If $a4^{\tan x}+a4^{-\tan x}-2=0$ has a real solution, where $0\leq x\leq \pi,x\neq \frac{\pi}{2},$ then interval of $a$ is Thoughts on that problem: Via the arithmetic-geometric inequality (AM-GM), we have $$4^{\tan x}+4^{-\tan x}\geq 2\implies\frac{2}{a}\geq 2\implies a<1$$ But this is not right Help me to solve it please","['algebra-precalculus', 'trigonometry']"
3232770,"For $(a + b + c + d)^{10}$, how many terms have coefficients that aren't divisible by $5$?","$(a + b + c + d)^{10}$ how many terms have coefficients that aren't divisible by $5$ ? I know that each of the following $a^{10}, b^{10}, c^{10}, d^{10} $ , their coefficient is 1, which isn't divisible by 5.
I also know that the sum of all the coefficients is : $a=b=c=d=1$ , $(1+1+1+1)^{10} = 4^{10} = 1,048,576$ so if I subtract the coefficients I found so far, I'll still have 1,048,572, which still isn't divisible by 5, which means there's at least 1 more coefficient that's not divisible by 5. got stuck here. probably not even thinking in the right direction. please help :)","['binomial-theorem', 'combinatorics', 'discrete-mathematics']"
3232799,Nonvanishing vector field on an odd sphere,"This is an exercise I am somewhat confused about. Here $X$ looks like a vector field on $\mathbb{R}^{2n}$ , not $S^{2n-1}$ . Then how should I interpret $X$ to make it a vector field on the sphere? Could anyone please explain?","['manifolds', 'vector-fields', 'differential-geometry']"
3232813,How prove this identity wih the sum equal to other sum,"Question: Given $l\in \mathbb{N^+}$ . $a_1,\cdots,a_l,b_1,\cdots,b_l$ are real numbers. $a_0=b_0=a_{l+1}=b_{l+1}=0$ .Define $$g(m,l)=-\dfrac{\displaystyle\prod _{r=0} ^{l}{(a_m-a_r+b_{r+1}-b_m)}}{\displaystyle\prod _{r=1,r\ne m} ^{l}{(a_m-a_r+b_r-b_m)}}$$ Prove: $$\sum_{m=1}^{l}{g(m,l)}=\sum_{t=1}^{l}{(a_t-a_{t-1})b_t}$$ For example,for $l=1$ , $g(1,1)=-\frac{a_1(-b_1)}{1}=(a_1-a_0)b_1$ Another example:for $l=2$ , $$g(1,2)+g(2,2)=-\frac{a_1(b_2-b_1)(a_1-a_2-b_1)}{a_1-a_2+b_2-b_1}+\frac{b_2(a_2-a_1)(a_2+b_1-b_2)}{a_2-a_1+b_1-b_2}$$ $$=\frac{(a_2-a_1+b_1-b_2)(a_1 b_1+a_2 b_2-a_1 b_2)}{a_2-a_1+b_1-b_2}=\sum_{t=1}^{2}{(a_t-a_{t-1})b_t}$$ But How to prove general case,Maybe use Lagrange interpolation formula?",['calculus']
3232894,Matrix representation of Fractional Linear Transformation and the Identity Matrix?,"For $x \in \mathbb{R}$ , define the fractional linear transformation of $x$ as $f(x)$ where: $$f(x) = \frac{ax + b}{cx+d}$$ Then $f(x)$ has a matrix representation in $\mathbb{R}^2$ of $F$ where: $$F = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$$ Then the function $g(x)= \dfrac{1}{1-x}$ has the matrix representation of: $$G = \begin{pmatrix} 0 & 1 \\ -1 & 1 \end{pmatrix}$$ Observe that $g(g(g(x)))=x$ . Then why isn't $G^3=I$ ? In fact: $$G^3 = \begin{pmatrix} -1 & 0 \\ 0 & -1 \end{pmatrix} = -I$$ How does that make sense where $g^3(x)=x$ and not $-x$ ? Shouldn't the vector $$ v=\begin{pmatrix} x \\ y \end{pmatrix}$$ get mapped back to itself after 3 iterations of multiplying by $G$ ? What am I missing?","['matrices', 'linear-algebra', 'linear-transformations']"
3232979,Is there a point $H$ such that $\frac{AH \cdot DM}{HD^2} = \frac{BH \cdot EN}{HE^2} = \frac{CH \cdot FP}{HF^2}$?,"$H$ is a point in non-isoceles triangle $\triangle ABC$ . The intersections of $AH$ and $BC$ , $BH$ and $CA$ , $CH$ and $AB$ are respectively $D$ , $E$ , $F$ . $AD$ , $BE$ and $CF$ cuts $(A, B, C)$ respectively at $M$ , $N$ and $P$ . Is there a point $H$ such that the following equality is satisfied? $$\large \frac{AH \cdot DM}{HD^2} = \frac{BH \cdot EN}{HE^2} = \frac{CH \cdot FP}{HF^2}$$ If there is not, prove why. If there is, illustrate how to put down point $H$ . Of course, point $H$ should be one of the triangle centres identified in the Encyclopedia of Triangle Centers . But I don't which one it is.","['euclidean-geometry', 'triangles', 'circles', 'geometry']"
3233029,Decomposing a symmetric matrix as a sum of nilpotent matrices,"Assume that a real-valued symmetric matrix $M$ with trace zero can be written as $$
M = A + A^T,
$$ with $A^2=0$ . Given that $M$ is known, how (if possible) can $A$ be found? The diagonal elements of $A$ are just half those of $M$ , that is $$
A_{ii}=M_{ii}/2.
$$ But for the non diagonal ones, considering only the decomposition above, the number of unknowns is the double of the number of equations: $$
M_{ij}=A_{ij}+A_{ji},
$$ with $i\neq j$ , implying that is not possible to get an unique solution. Using the nilpotency property of $A$ , nonlinear equations such as $M^2=AA^T+A^TA$ or $A^TMA=0$ can be generated, but I can't see how using these nonlinear relations can lead to an unique solution.","['matrices', 'nilpotence', 'nonlinear-system', 'linear-algebra']"
3233046,show this $ t_{n+p^{2p}-1} \equiv t_n \pmod{p} $ with hard problem,"We define the Fibonacci sequence $\{F_n\}_{n\ge0}$ by $F_0=0$ , $F_1=1$ , and for $n\ge2$ , $F_n=F_{n-1}+F_{n-2}$ ; we define the Stirling number of the second kind $S(n,k)$ as the number of ways to partition a set of $n\ge1$ distinguishable elements into $k\ge1$ indistinguishable nonempty subsets.
        For every positive integer $n$ , let $$t_n = \sum_{k=1}^{n} S(n,k) F_k$$ Let $p\ge7$ be a prime. Prove that $$ t_{n+p^{2p}-1} \equiv t_n \pmod{p} $$ for all $n\ge1$ . some My try: first note that the following identity holds: $\sum_{n \ge 0}S(n, k)x^n = x^k\prod_{r = 1}^k\frac{1}{1-rx}$ . So $$T(x) = \sum_{n \ge 0}t_nx^n = \sum_{n \ge 0} \sum_{k \ge 0}S(n,k) F_k x^n = \sum_{k \ge 0} \sum_{n \ge 0}S(n,k) F_k x^n = \sum_{k \ge 0} F_kx^k \prod_{r = 1}^k\frac{1}{1-rx} $$ Then I can't,Thanks",['number-theory']
3233141,Why is the sum of two independent geometrically distributed RVs not geometrically distributed again?,"Let X = Geo(1/4) and Y = Geo(1/4) (both independent) and let Z = X + Y. Why is X + Y not Geo(0.5) for example and how could I, as an example, calculate P(Z = 3)?","['statistics', 'probability-distributions', 'probability']"
3233234,Prove that a NxN grid can be colored using n colors such that each color appear once each row and column,"Just like a simpler Sudoku game, given n, show that nxn grid can be colored using n colors so that each color appears once for each row/column. I see that each row/column forms a complete graph so that we need at least n colors for each row/column. But I'm stuck at bringing those together and show that n is also the maximum color needed to color the grid. Any hint? Thanks! EDIT: I forgot to add 1 more constraint that I would need to prove also for the case that k (k less than n) row is already given. I think in that case the shifting answer would not be correct right?","['graph-theory', 'discrete-mathematics']"
3233243,"Quotient of two integrals $\frac{\int_0^\pi x^3\ln(\sin x)\,dx}{\int_0^\pi x^2\ln(\sqrt{2}(\sin x))\,dx}$","Calculate $$\frac{\int_0^\pi x^3\ln(\sin x)\,dx}{\int_0^\pi x^2\ln(\sqrt{2}(\sin x))\,dx}$$ In this problem, I'm unable to understand how to start. I tried applying integration by parts but I couldn't solve it. I also tried the various properties of definite integration but they were of no use.
Maybe applying integration by parts (or DI method) successively may work but it leads to a form of $\frac{\infty}{\infty}$ .","['integration', 'definite-integrals']"
3233291,More on the integral $\int_0^1\int_0^1\int_0^1\int_0^1\frac{1}{(1+x) (1+y) (1+z)(1+w) (1+ x y z w)} \ dx \ dy \ dz \ dw$,"In this post , the OP asks about the integral, $$I = \int_0^1\int_0^1\int_0^1\int_0^1\frac{1}{(1+x) (1+y) (1+z)(1+w) (1+ x y z w)} \ dx \ dy \ dz \ dw$$ I. User DavidH gave a beautiful (albeit long) answer in terms of the Nielsen generalized polylogarithm , $$S_{n,p}(z) = \frac{(-1)^{n+p-1}}{(n-1)!\,p!}\int_0^1\frac{(\ln t)^{n-1}\big(\ln(1-z\,t)\big)^p}{t}dt$$ namely, $$I = \tfrac32 S_{2,2}(-1)+\tfrac{11}{8} S_{1,3}(1)-S_{1,3}(-1) + \tfrac32 S_{3,1}(-1) \approx 0.223076$$ with the last addend tweaked by yours truly. A session with Mathematica shows that these explicitly are, $$S_{3,1}(-1) = -\tfrac78\zeta(4) \\ S_{1,3}(1) = \zeta(4) \\ S_{2,2}(-1) = 2S_{1,3}(-1)-\tfrac18\zeta(4)$$ and, $$S_{1,3}(-1) = \tfrac18\ln^3(2)\,\rm{Li}_1\big(\tfrac12\big)+\tfrac12\ln^2(2)\,\rm{Li}_2\big(\tfrac12\big)+\ln(2)\,\rm{Li}_3\big(\tfrac12\big)+\rm{Li}_4\big(\tfrac12\big)-\zeta(4)$$ Since $S_{1,3}(-1)$ and $S_{2,2}(-1)$ have a linear relation, then the integral can be simplified as, $$\color{blue}{I = 2S_{1,3}(-1)+\tfrac14\zeta(4)}$$ Note that $\rm{Li}_n\big(\tfrac12\big)$ for $n=1,2,3$ have closed-forms. II. User nospoon gave an equal but alternative form as, $$I=\tfrac52\ln(2)\zeta(3)-\tfrac{11}{576}\pi^4-\tfrac1{2}\ln^2(2)\zeta(2)+\tfrac1{16}\ln^4(2)+\tfrac32\rm{Li}_4\big(\tfrac12\big)-A+\tfrac12B\\ \approx 0.223076$$ where $$A = \int_0^1\frac{\rm{Li}_3(x)}{1+x}dx$$ $$B= \int_0^1\frac{\ln(1-x^2)\,\rm{Li}_2\big(\tfrac{1-x}2\big)}{x}dx$$ III. Question After guessing on various candidate variables, is it true that the closed-forms of $A$ and $B$ are, $$A = -4S_{2,2}(-1)+6S_{1,3}(-1) +\ln(2)\zeta(3) = 0.339545\dots$$ $$B = -\tfrac12S_{2,2}(-1)-2S_{1,3}(-1)-\tfrac38\ln(2)\zeta(3)+\tfrac14\ln^2(2)\zeta(2) = -0.1112606\dots$$","['integration', 'definite-integrals', 'special-functions', 'multivariable-calculus', 'polylogarithm']"
3233396,Closed-forms for the integral $\int_0^1\frac{\operatorname{Li}_n(x)}{1+x}dx$?,"( This is related to this question .) Define the integral, $$I_n = \int_0^1\frac{\operatorname{Li}_n(x)}{1+x}dx$$ with polylogarithm $\operatorname{Li}_n(x)$ . Given the Nielsen generalized polylogarithm $S_{n,p}(z)$ , $$S_{n,p}(z) = \frac{(-1)^{n+p-1}}{(n-1)!\,p!}\int_0^1\frac{(\ln t)^{n-1}\big(\ln(1-z\,t)\big)^p}{t}dt$$ Then it seems, $$I_1 = -S_{1,1}(-1)-\tfrac12\ln(2)\ln(2)$$ $$I_2 = -5S_{1,2}(-1)+\ln(2)\,\zeta(2)\quad$$ $$\quad\qquad I_3 = -2S_{1,3}(-1)+\ln(2)\,\zeta(3)-\tfrac12\zeta(4)$$ where $S_{1,1}(-1) = -\tfrac12\zeta(2)$ , and $S_{1,2}(-1) = \tfrac18\zeta(3)$ and $S_{1,3}(-1)$ has a more complicated closed-form given in the linked post. Q: What is $I_4$ and $I_5$ ? In general, can $I_n$ be expressed by the Nielsen generalized polylogarithm? P.S. Note that $\operatorname{Li}_n(z), \ln(z), \zeta(z)$ are just special cases of this function.","['integration', 'definite-integrals', 'special-functions', 'polylogarithm', 'closed-form']"
3233400,integration of a gaussian with $x^2$,"I need to integrate $$\int_{-\infty}^{\infty} x^2 e^{-ax^2} \qquad \text{where } a\in R$$ The book does the following: I don't understand what's happening. I tried solving the integral using integration by parts and this is what I got $$
\begin{align}
\int_{-\infty}^{\infty} x^2 e^{-ax^2} &= x^2\sqrt{\frac{\pi}{a}} - \int_{-\infty}^{\infty} \sqrt{\frac{\pi}{a}} 2x dx  && \text{as we are told } \int_{-\infty}^{\infty}dx e^{-ax^2}= \sqrt{\frac{\pi}{a}}\\
&=x^2\sqrt{\frac{\pi}{a}} - 2\sqrt{\frac{\pi}{a}}\frac{x^2}{2} && \text{as } \int xdx = \frac{x^2}{2} \\
&= 0
\end{align}
$$ What am I doing wrong? Actually, I might have found a way of solving this $$
\begin{align}
\int_{-\infty}^{\infty} x^2 e^{-ax^2} dx &= \int_{-\infty}^{\infty} x\cdot x e^{-ax^2} dx \\
&= - \frac{1}{2a} \int_{-\infty}^{\infty}  x(-2ax)e^{-ax^2} dx \\
&= -\frac{1}{2a}\left(\left[e^{-ax^2}\right]_{-\infty}^{\infty} - \int_{-\infty}^{\infty} e^{-ax2} dx\right) \\
&= -\frac{1}{2a}\left(0 - \sqrt{\frac{\pi}{a}}\right) \\
&= \frac{1}{2a}\sqrt{\frac{\pi}{a}}
\end{align}
$$","['integration', 'definite-integrals', 'improper-integrals', 'multivariable-calculus', 'calculus']"
3233411,Is every compact solvmanifold the quotient of a simply connected solvable Lie group by a discrete subgroup?,"Recall that a manifold is called a nilmanifold if it is a homogeneous space for a connected nilpotent Lie group. Mal'cev showed that every compact nilmanifold is diffeomorphic to the quotient of a simply connected nilpotent Lie group by a discrete subgroup acting cocompactly. A manifold is called a solvmanifold if it is a homogeneous space for a connected solvable Lie group. Every nilpotent group is solvable, so every nilmanifold is a solvmanifold. Is there an anologue of Mal'cev's result for solvmanifolds? That is, Is every compact solvmanifold diffeomorphic to the quotient of a simply connected solvable Lie group by a discrete subgroup acting cocompactly?","['solvable-groups', 'smooth-manifolds', 'lie-groups', 'differential-geometry']"
3233415,Find Jordan Decomposition of $\left(\begin{smallmatrix} 4 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 3 \end{smallmatrix}\right)$ over $\mathbb{F}_5$,"Find the Jordan decomposition of $$
A := \begin{pmatrix} 4 & 0 & 1 \\ 0 & 1 & 0 \\ 1 & 0 & 3 \end{pmatrix}
\in M_3(\mathbb{F}_5),
$$ where $\mathbb{F}_5$ is the field modulo 5. What I've done so far The characteristic polynomial is \begin{equation}
P_A(t) = (4 - t)(1-t)(3-t) - (1-t)
= -t^3 + 8t^2-18t+1
\equiv 4t^3 + 3t^2 + 2t + 1 \mod5.
\end{equation} Therefore, $\lambda = 1$ is a zero of $P_A$ , since $4+3+2+1 = 10 \equiv 0 \mod 5$ .
By polynomial division one obtains $$
P_A(t)
= (t + 4)(4t^2 + 2t + 4)
= (t + 4)(t + 4) (4t + 1)
\equiv 4 (t + 4)^3
$$ Therefore $\lambda = 1$ is the only eigenvalue of $A$ .
To find the eigenspace we calculate the kernel of $A + 4 E_3$ and obtain $$
\text{span}\left( \begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix}, \begin{pmatrix} 1 \\ 1 \\ 2 \end{pmatrix} \right)
$$ Since $(A + 4 E_3)^2 = 0$ , the kernel of $(A + 4 E_3)^2$ is the whole space.
Now, I choose $v := (1, 0, 0) \in \text{ker}(A + 4 E_3)^2$ such that $v \not\in \text{ker}(A + 4 E_3)$ .
We calculate $(A + 4E)v = (3, 0, 1)$ and then $$
(A + 4E)
\begin{pmatrix} 3 \\ 0 \\ 1\end{pmatrix}
= \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix},
$$ but the zero vector can't be a basis vector of our Jordan decomposition. Have I made a mistake in my calculations?","['jordan-normal-form', 'finite-fields', 'linear-algebra']"
3233429,Find confidence levels from given intervals,"A set of $40$ data items, produces a confidence interval for the population mean of $94.93<\mu<105.07$ . If $\sum x^2 = 424 375$ , find the confidence level. So the idea of confidence intervals is still rather new to me and one that isn't fully clear in my mind, would someone be able to give me some hints about solving this and explain what they are doing to solve it. I get that the confidence interval is given by $$\bar{x}-z\frac{\sigma}{\sqrt{n}}<\mu<\bar{x}+z\frac{\sigma}{\sqrt{n}}$$ and that $z=\Phi^{-1}(c)$ where $c$ is the confidence level, however this is as far as my knowledge goes.","['statistics', 'confidence-interval', 'normal-distribution']"
3233454,Expectation of Gaussian r.v. conditioned on positive r.v.s with positive covariances is positive,"Suppose that $(X_1,\dotsc,X_K)^T \sim \mathcal{N}(0, \Sigma)$ , with $\mathrm{cov}(X_i, X_j) > 0$ for all $i,j$ . Prove that $$ \mathbb{E}[X_K  1\{ X_1> 0, \dotsc, X_{K-1}> 0 \} ] > 0$$ where $1\{ A \}$ is the indicator function of $A$ .","['conditional-probability', 'probability-distributions', 'normal-distribution', 'probability-theory', 'probability']"
3233456,Why is the KL divergence the number of bits required to represent the error of an estimator?,"I am familiar with several interpretations of the KL divergence, last week I heard of a new one, mentioned in a lecture on probabilistic graphical models. It was stated kind of offhandedly, so I hope I'm getting the gist, but I seem to remember something like ""The KL divergence between a distribution $\mathcal{D}$ and an empirical distribution $\mathcal{D}_{emp}$ based on a sample $\mathcal{X}\sim\mathcal{D}$ is the number of bits required to represent the error of a MLE which is based on $\mathcal{X}$ "" (I know this sounds weird, MLE for what parameter? Maybe for any parameter? I'm honestly not sure) Is anyone familiar with such a result?","['statistical-inference', 'statistics', 'information-theory']"
3233500,Can one characterize the set of all $A\subseteq\mathbb{R}$ satisfying $2\cdot A\cdot A\subseteq A$ and $A\cdot(\mathbb{R}\backslash A)\subseteq A$?,"This question is a spin-off of this question . When trying to solve that question, we came up with the idea of construction functions using sets $A\subseteq \mathbb{R}$ having the properties that $2xy\in A$ for all $x,y \in A$ and $xy\in A$ for all $x\in A$ and $y\in\mathbb{R}\backslash A$ . How would one characterize the set of such sets $A$ ? I would literally have no idea where to start, although the problem can be formulated so easily. I know that the sets $A=\varnothing$ , $A=\{0\}$ , and $A=\mathbb{R}$ qualify, but are these the only ones? Any ideas/suggestions? Thanks!","['elementary-set-theory', 'real-analysis']"
3233552,Intuitive reason why a simple symmetric random walk is recurrent on $\Bbb Z^2$ and transient on $\Bbb Z^3$.,"Polya proved the following very well-known Theorem: A simple random walk on $\Bbb Z^D$ is recurrent if and only if it is symmetric and $D<3$ . Dropping simplicity (i.e. allowing jumps to non-neighboring states) leaves this result essentially unaltered, as long as the distribution of the increments is not too heavy-tailed (compare e.g. Theorems 5.4.8, 5.4.9, 5.4.14 in the book by Rick Durrett ). I am familiar with common proofs of these results, and of course I am able to see why they work for which dimensions. However, the point of this question is that I'd like to understand these results better on a purely intuitive level . In view of the law of large numbers (which is very intuitive in itself), it is clear that asymmetry ruins any chance of recurrence. Furthermore, adding dimensions provides more possibilities for the random walker to ""get lost"", as the probability of walking in ""the right direction"" decreases. This makes it very plausible that, in the symmetric case, for some $D_0\in\Bbb N \cup \{\infty\}$ we have recurrence in all dimensions $1\le D< D_0$ and transience for all $D\ge D_0$ . It just so happens that this is true and that $D_0=3$ . But why? Why not lower or greater? What's so special about two- or three-dimensional space? Is there any geometric reason that makes this more graspable? I'd be very grateful for any helpful answer!","['stochastic-processes', 'random-walk', 'probability-theory', 'markov-chains']"
3233561,Prove The Derivative Rules in the Ring of Polynomials. How to show Leibniz's rule?,"Let $R$ be a commutative ring with unity element 1. Let $f(x)\in R[x]$ and define its derivative as $f'(x)=r_1 +2(r_2)x+...+n(r_n)x^{n-1}$ . Prove that $(f+g)'(x)=f'(x)+g'(x)$ and that $(fg)'(x)=f'(x)g(x)+f(x)g'(x)$ So im pretty sure I worked out the addition, but am struggling with the multiplication. Let $f(x),g(x)\in R[x]$ with $f(x)=r_0+r_1x+r_2x^2+...+r_nx^n$ and $g(x)=s_0+s_1x+s_2x^2+...+s_nx^n$ $$(f+g)'(x)=((r_0+s_0)+(r_1+s_1)x+...+(r_n+s_n)x^n)'(x)$$ $$=((r_1+s_1)+2(r_2+s_2)x+...n(r_n+s_n)^{n-1}$$ $$=((r_1+s_1)+(2r_2+2s_2)x+...+(nr_n+nr_n)x^{n-1}$$ $$=f'(x)+g'(x)$$ For the multiplication, this is what I've got so far... $$(fg)'(x)=((r_0s_0)+(r_0s_1+r_1s_0)x+...+(m_j)x^n)$$ where $$m_j=\sum_{i+k=j}^n r_is_k$$ for $j=0,1,2,...$ , $$(fg)'(x)=((r_0s_1+r_1s_0)+2(r_0s_2+r_1s_1+r_2s_0)x+...+n(m_j)x^{n-1}$$ $$=((r_0s_1+r_1s_0)+(2r_0s_2+2r_1s_1+2r_2s_0)x+...+nm_jx^{n-1}$$ This is where I lose it, if I'm even correct up to this point...","['ring-theory', 'abstract-algebra', 'derivatives', 'polynomials']"
3233585,algebraic de Rham cohomology of normal crossing singularities,"For a variety $X/k$ the standard way of defining de Rham cohomology $H^i_{\mathrm{dR}}(X)$ is as the hypercohomology $\mathbb{H}^i(\Omega^{\bullet}_{X/k})$ of the de Rham complex, and this requires $X$ to be smooth. Hartshorne has extended the definition of $H^i_{\mathrm{dR}}$ to singular varieties, but using techniques that are too complicated for me. So I would appreciate if someone could help me to find out if the two definitions agree in certain circumstances. Does the naive definition agree with actual de Rham cohomology: $1)$ when $X$ has normal crossing singularities? $2)$ when $X$ is a curve with normal crossing singularities? $3)$ when $X$ is a union of $\mathbb{P}^1$ with transverse intersection? If these are not true, do we at least have agreement of the Hodge filtration $H^p(\Omega^q_{X/k})$ ? I'm happy to restrict to projective varieties. Thanks.","['algebraic-geometry', 'singularity-theory', 'sheaf-cohomology', 'de-rham-cohomology']"
3233626,"For prime quadratic integer $\pi$, $x \equiv 1$ (mod $\pi$), Show $x^2 \equiv1$ (mod $\pi^2$) and $x^3 \equiv 1$ (mod $\pi^3$) is not always true.","I was working through one of the problems given to me on my problem set for a number theory class and I would like some help in an attempt to learn. Could someone help me with the following question? Show by counterexample, that if $\pi$ is a prime quadratic integer, and $x \equiv 1 \pmod \pi$ , it does not necessarily follow that $x^2 \equiv 1 \pmod {\pi^2}$ or that $x^3 \equiv 1 \pmod {\pi^3}$ . In this case, for the field $\mathbb{Q}(\sqrt{d})$ , which is the set of all numbers of the form $a + b(\sqrt{d})$ where $a$ and $b$ are rational numbers, and $d$ is an integer that is not a perfect square, a quadratic integer are the subset of these numbers that can be written as the roots of polynomials of the form $x^2 + mx + n = 0$ where $m$ and $n$ are integers. I'd really appreciate the help! Thanks! We are given that quadratic integers in $\mathbb{Q}(\sqrt{-3})$ are of the form $a + b\sqrt{-3}$ where $a$ and $b$ are rational numbers. I asked my teacher and got the hint that I need to reduce this equation modulo $\lambda^3$ but I'm still confused about how to continue. Could anyone please help? Thanks!","['number-theory', 'quadratic-integer-rings', 'ring-theory']"
3233690,Question about Etale Sheaves,"Let consider the one point field scheme $Spec(K)$ and denote by $G:=\text{Gal}(\overline{K}/K)$ the corresponding Galois group. We consider by $\mathbf{Sh}\big(\text{Spec }k)_{\text{et}}$ the category of etale sheaves on $Spec(k)$ . Then there is a wll known theorem that the exist a cetegory equivalence $$
\mathbf{Sh}\big(\text{Spec }K)_{\text{et}}
\cong\{\text{discrete abelian group with continuous }G_K\text{-action}\} $$ given explicitely by $$\mathcal F \mapsto \varinjlim_{K'/K\text{ finite separable extension}}
\mathcal F(\text{Spec }K') $$ with inverse $$\big(\text{Spec }k'\mapsto M^{\text{Gal}(\overline K/K')}\big) \leftarrow M
$$ My question is how $G_K$ acts explicitely on $\varinjlim_{K'/K\text{ finite separable extension}}
\mathcal F(\text{Spec }K')$ ? So in other words if we take a separable field extension $K \subset K'$ what does $G_K$ with $\mathcal F(\text{Spec }K')$ ?","['algebraic-geometry', 'sheaf-theory']"
3233696,"Deriving MLE of $\theta$ in $\text{Exp}(\theta,\theta)$ distribution [duplicate]","This question already has an answer here : Maximum likelihood estimator is sample mean or minimum ordered statistic? (1 answer) Closed 4 years ago . Suppose $X_1,X_2,\ldots,X_n$ are i.i.d variables having a two-parameter exponential distribution with common location and scale parameter $\theta$ : $$f_{\theta}(x)=\frac{1}{\theta}e^{-(x-\theta)/\theta}\mathbf1_{x>\theta}\quad,\,\theta>0$$ I am wondering if it is possible to derive a maximum likelihood estimator (MLE) of $\theta$ . The likelihood function given the sample $x_1,\ldots,x_n$ is $$L(\theta)=\frac{1}{\theta^n}e^{-n(\bar x-\theta)/\theta}\mathbf1_{x_{(1)}>\theta}\quad,\,\theta>0$$ , where $\bar x=\frac{1}{n}\sum\limits_{i=1}^n x_i$ and $x_{(1)}=\min\limits_{1\le i\le n} x_i$ . Since $L(\theta)$ is not differentiable at $\theta=x_{(1)}$ , I cannot apply the second-derivative test here. Even if I could say that $L(\theta)$ is increasing and/or decreasing in $\theta$ under the constraint $\theta<x_{(1)}$ , I am not sure what choice of $\theta$ maximises $L(\theta)$ . Differentiation is not valid as I understand. I think it is safe to assume $x_{(1)}<\bar x$ , so the constraint is actually $\theta<x_{(1)}<\bar x$ . If MLE is unique, then it is likely to be a function of the sufficient statistic $(\overline X,X_{(1)})$ . However I don't see how to derive it in this particular model. Any suggestion would be great.","['statistics', 'probability-distributions', 'exponential-distribution', 'maximum-likelihood', 'optimization']"
3233700,Let $X$ be $\mathbb{C}$ with the following topology: A subset $F$ of $X$ is closed $\iff$ $F$ is the set of zero(s) of a polynomial. Connected?,"Let $X$ be $\mathbb{C}$ with the following topology: A subset $F$ of $X$ is closed $\iff$ $F$ is the set of zero(s) of a polynomial. Is $X$ Compact? Connected? $X$ is indeed Compact. If $\{U_\alpha\}$ is an open cover of $X$ , then the complement of each one is finite. Thus we can take one to cover all but a finitely many points of $X$ , and then choose a finite number of elements of the cover to achieve a finite cover. As for it being connected... A space $X$ is connected $\iff$ there is no continuous onto map $f: X \rightarrow \{0,1\}$ where $\{0,1\}$ has the discrete topology. I think there does not exist such a continuous map... To have the inverse image of both $0$ and $1$ be open would mean that both of their preimages have finite complements, which is not possible. $\therefore X$ is connected.","['general-topology', 'proof-verification']"
3233758,Mathematical induction proof $n^4-1$ is divisible by $16$ for all odd integers $n$,"I'm stuck towards the end of proving this, here's my attempt: $P(3) = 80/16 = 5$ , True $P(k) = k^4-1$ $P(k+1)= (k+1)^4-1$ Expanded $= k^4+4k^3+6k^2+4k+1-1$ This is where I am stuck at. Sorry for the sloppy formatting im still reading how to  properly write formulas on this site. Thanks in advance for your help!","['induction', 'discrete-mathematics']"
3233762,"Why are singular values of ""complex"" matrices always real and non-negative?","I've already read the following related questions on math.SE: Why can't singular values be complex numbers? Clarification on the SVD of a complex matrix Why are singular values always non-negative? Convention on non-negative singular values? The conclusion they seem to agree on is the following: For $A \in \mathbb{R}^{m\times n} $ , its singular values are real non-negative . I do not see, however, how can this be the case for $A \in \mathbb{C}^{m\times n}$ , even though in most answers, people say it is the same as for real matrices. Usual argument for singular values of $A  \in \mathbb{R}^{m\times n} $ being real non-negative: The SVD of $A$ is: $$
A = U S V^T
$$ We have $$
B = A^T A = V S^T U^T U S V^T = V S^T S V^T
$$ where $S^T S$ is diagonal with elements $\sigma_i^2$ , where $\sigma_i$ are the singular values of $A$ .
Now, $\sigma_i^2$ are real-nonegative because they can be seen as the eigenvalues $\lambda_i=\sigma_i^2$ of the symmetric, positive-definite, matrix $B = V \Lambda V^T$ (i.e., $\Lambda = S^T S$ ). Using $\lambda_i=\sigma_i^2 \ge 0$ to solve for $\sigma_i$ , we find that: $\sigma_i$ is real because if it were complex, then the only way $\sigma_i^2$ would be real is if $\sigma_i$ is real or pure imaginary. However, in the latter case we get $\sigma_i^2$ negative, which contradicts $\sigma_i^2 \ge 0$ . $\sigma_i$ is the square-root of $\lambda_i$ , which can be positive or negative. By convention, however, we take the positive square-root. Hence, $$
\sigma_i \text{ are real-nonnegative themselves.}
$$ A try for a similar argument for singular values of $A  \in \mathbb{C}^{m\times n} $ : The SVD of $A$ is: $$
A = U S V^H
$$ We have $$
B = A^H A = V S^H U^H U S V^H = V S^H S V^H
$$ where $S^H S$ is diagonal with elements $|\sigma_i|^2$ , where $\sigma_i$ are the singular values of $A$ .
Now, $|\sigma_i|^2$ are real-nonnegative because of the modulus square, and they can also be seen as the eigenvalues $\lambda_i=|\sigma_i|^2$ of the Hermitian, positive-definite, matrix $B = V \Lambda V^H$ (i.e., $\Lambda = S^H S$ ). Using $\lambda_i=|\sigma_i|^2 \ge 0$ , how can one solve for $\sigma_i$ and prove it is real-nonnegative ? Particularly, what prevents $\sigma_i$ from being complex?","['svd', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'matrix-decomposition']"
3233778,How to solve this complex indefinite integral? In a contour,"I have to solve this indefinite integral $$\int_{0}^{\pi} \frac{\cos(4\theta)}{1+\cos^2(\theta)}\, d\theta$$ I changed $\cos(4\theta)$ for $\frac{e^{4i\theta}+e^{-4i\theta}}{2}$ on the unit disk, but my teacher told me that this shouldn't be done. What should I do?","['complex-analysis', 'analysis']"
3233821,Why is $y$ separated into two intervals?,"So, here's a question and a solution to part b). I do not understand why they make $y^{1/2}$ belong to interval $[0,1)$ and then separately to the interval $[1,3)$ .","['statistics', 'probability-distributions', 'probability', 'random-variables']"
3233827,About two events being mutually exclusive and independent give that one of the event's probability is zero.,"I'm studying statistics and probability using an introductory textbook and it had this question: 108.The events “Other” and “Up for reelection in November 2016” are ________

a. mutually exclusive.

b. independent.

c. both mutually exclusive and independent.

d. neither mutually exclusive nor independent. The answer key says that the correct answer is letter a , but shouldn't it be letter c as the P(""Other"" $\cap$ ""Up for reelection in November 2016"") = 0 meaning that the two events are mutually exclusive and that the P(""Other""|""Up for reelection in November 2016"") = P(Other), therefore also being independent?","['statistics', 'probability']"
3233841,Prove that $\sqrt{5521}-1$ is an irrational number,"I'm stuck on a textbook problem where I'm asked to prove that $\sqrt{5521} − 1$ is an irrational number by contradiction and prime factorization. I tried following steps the teacher did in her class $10 + $$\sqrt{5}$ , and I made it to the end of the first steps but I couldn't get past that as I didn't know what to do after ending up with $5521b^2 = a^2$ . For her example, she did four cases for when the remainder is $1$ , $2$ , $3$ , and $4$ but I don't understand where she is getting these values from. My guess is she did every number up to but not including $5$ , but the number I'm given is $5521$ and that seems like an excessive number of cases, which makes me believe that I'm not doing this right. I don't even know if the steps she did on her slides would also apply to any irrational number, specifically the one I'm asked to solve. Any help or push in the right direction would be appreciated.","['irrational-numbers', 'discrete-mathematics']"
3233862,Graph with the condition that every vertex is connected to at least n other vertices.,"Problem: (Adrian Tang) $G$ is a graph with $2n+1$ vertices. In $G$ , for every set $S$ of at most $n$ vertices, there is one vertex outside of $S$ that is adjacent to every vertex in $S$ . Prove that at least one vertex is adjacent to every other vertex. My approach: assume for contradiction that the vertex of highest degree doesn't have degree $2n$ . There is something about its neighbourhood that arouses a contradiction that there is a vertex with a higher degree.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3233900,Next Term Of Strange Sequence,"I tutored a 10th grader and I was asked this puzzle and I had spent nearly an hour with it and got “no where”. Any one can crack it? Please let me know. Thank you. Question: Find the $14$ th term of the sequence: $$ \frac{1}{2},  \frac{3}{7}, \frac{1}{3}, \frac{5}{19}, \frac{3}{14}, .... $$ .",['algebra-precalculus']
3233946,Proof of $\Gamma(1-z) \Gamma (z) = \frac{\pi}{\sin \pi z}$,"In the proof of the above result from the book by Stein and Shakarchi, they have used the substitution $vt = u$ where $t>0$ to get $$\Gamma (1-z) = \int_{0}^{\infty} e^{-u} u^{-z} du = t\int_{0}^{\infty} e^{-vt} (vt)^{-z} dv.$$ Well, up to this part it was okay. But I am not understanding the following mixing of integrals: $$ \begin{align} \Gamma (1-z) \Gamma (z) & = \int_{0}^{\infty} e^{-t} t^{z-1} \Gamma (1-z) dt \\
&= \int_{0}^{\infty} e^{-t} t^{z-1} \left(t \int_{0}^{\infty} e^{-vt}(vt)^{-z}dv \right) dt  \\ &=\int_{0}^{\infty} \int_{0}^{\infty} e^{-t(1+v)}v^{-z} dvdt. \end{align}$$ I want to understand how the introduced variable $t$ is taken to be the same with the dummy variable $t$ while mixing the integrals.","['complex-analysis', 'proof-verification', 'gamma-function']"
3233952,How to calculate weighted average of hourly sales in a day,"I have hourly sales data & want to aggregate it to a day level. Out of $24$ hours, we are classifying $6$ hrs as peak hours and $18$ hrs as non-peak. Assume peak hr sales for a day as: $X_1, X_2,..., X_6$ Non-peak hr sales for a day as: $Y_1, Y_2,..., Y_{18}$ How can we take a weighted average of peak hr and non-peak hrs to get the data to a day level?","['average', 'descriptive-statistics', 'statistics', 'means']"
3233963,More on the log sine integral $\int_0^{\pi }\theta ^{3}\log^{3}\left ( 2\sin\frac{\theta }{2} \right )\mathrm{d}\theta$,"I. In this post , the OP asks about the particular log sine integral, $$\mathrm{Ls}_{7}^{\left ( 3 \right )} =-\int_{0}^{\pi }\theta ^{3}\log^{3}\left ( 2\sin\frac{\theta }{2} \right )\,\mathrm{d}\theta $$ and gives the monster evaluation, $$\small{\begin{align*}
-\mathrm{Ls}_{7}^{\left ( 3 \right )}\left ( \pi  \right)&=\frac{9}{35}\log^72+\frac{4}{5}\pi ^{2} \log^52+9\zeta \left ( 3 \right )\log^42-\frac{31}{30}\pi ^{4}\log^32\\
&-\left [ 72\mathrm{Li}_5\left ( \frac{1}{2} \right )-\frac{9}{8}\zeta \left ( 5 \right )-\frac{51}{4}\pi ^{2}\zeta \left ( 3 \right ) \right ]\log^22\\
&+\left [ 72\,\color{red}{\mathrm{Li}_{5,1}}\left ( \frac{1}{2} \right )-216\mathrm{Li}_6\left ( \frac{1}{2} \right )+36\pi ^{2}\mathrm{Li}_4\left ( \frac{1}{2} \right ) \right ]\log2+72\,\color{red}{\mathrm{Li}_{6,1}}\left ( \frac{1}{2} \right )\\
&-216\mathrm{Li}_7\left ( \frac{1}{2} \right )+36\pi ^{2}\mathrm{Li}_5\left ( \frac{1}{2} \right )-\frac{1161}{32}\zeta \left ( 7 \right )-\frac{375}{32}\pi ^{2}\zeta \left ( 5 \right )+\frac{1}{10}\pi ^{4}\zeta \left ( 3 \right )
\end{align*}}$$ where I had to use small fonts to make it fit better. Update : Based on Przemo's answer , I just realized the multiple polylogarithm $\mathrm{Li}_{m,1}(z)$ is just a Nielsen generalized polylogarithm $S_{n,p}(z)$ in disguise, $$\color{red}{\mathrm{Li}_{m ,1}}\left ( z \right )=\sum_{k=1}^{\infty }\frac{z^{k}}{k^{m}}\sum_{j=1}^{k-1}\frac{1}{j} = S_{m-1,\,2}(z)$$ discussed below. II. The Nielsen generalized polylogarithm , $$S_{n,p}(z) = \frac{(-1)^{n+p-1}}{(n-1)!\,p!}\int_0^1\frac{(\ln t)^{n-1}\big(\ln(1-z\,t)\big)^p}{t}dt$$ Given $\color{blue}{z=-1}$ , for brevity let $S_{n,p}(-1) = S_{n,p}$ . Then I found the integral can be evaluated using only 6 $S_{n,p}$ with small coefficients, $$\frac1{18}\int_0^{\pi}x^3\ln^3\left(2\sin\tfrac{x}2\right)dx \\
\large{\color{blue}{=-10 S_{5,2}+14S_{4,3}-8S_{3,4}+\tfrac{\pi^2}6\Big(4S_{3,2}-9S_{2,3}+6S_{1,4}\Big)\\} =\, 0.3341049\dots}$$ However, since there is a linear relation between these six as, $$1260 S_{5,2}-1506 S_{4,3} + 1004 S_{3,4} -\tfrac{\pi^2}6\Big(157S_{3,2}-279S_{2,3}+558S_{1,4}\Big) = 0$$ then the number of terms can be reduced to $5$ . The last piece of the puzzle is to express these as polylogarithms. Note that, $$32S_{3,2}(-1) = 16\zeta(2)\zeta(3)-29\zeta(5)$$ $$32S_{2,3}(-1) = 16\zeta(2)\zeta(3)-31\zeta(5)+64S_{1,4}(-1)$$ $$30S_{1,4}(-1) = -a^5-5a^3\rm{Li}_2(\tfrac12)-15a^2\rm{Li}_3(\tfrac12) -30a\, \rm{Li}_4(\tfrac12)-30\rm{Li}_5(\tfrac12)+30\zeta(5)$$ where $a=\ln 2$ , and, $$128S_{5,2}(-1) = 64\zeta(2)\zeta(5)+112\zeta(3)\zeta(4)-251\zeta(7)$$ I've been trying to do so also for $S_{3,4}(-1)$ and $S_{4,3}(-1)$ but to no avail. The best I could do was, $$128S_{3,4}(-1)-192S_{4,3}(-1)=-64\zeta(2)\zeta(5)-160\zeta(3)\zeta(4)+315\zeta(7)$$ III. Question: For $z=-1$ , can we express $S_{3,4}(-1)$ and $S_{4,3}(-1)$ in terms of polylogarithms $\rm{Li}_m(x)$ ? In general, can we do so for all $S_{n,p}(-1)$ ? P.S. I know it can be done when $n = 1$ .","['integration', 'calculus', 'polylogarithm', 'closed-form', 'zeta-functions']"
3233967,Probability of nth draw being same value,"Disclaimer at the beginning: this does relate to a homework problem, but is not the actual homework problem itself. Consider a series of numbers, $1, 2,...,n$ . We select one value at a time at random from this sequence (with replacement) until we select a value that has already been selected before. Let $D_n$ be the draw on which we select a value that has been selected before. $D_n$ clearly only takes on values from $2$ to $n+1$ . Now, the homework problem asks us to show that (but this is not what I'm asking about): $$\lim_{n \to \infty}P\{\frac{D_n}{\sqrt{n}}>x\}=e^{\frac{-x^2}{2}}$$ However, what I'm curious to know about is the probability $P\{D_n=t\}$ . In my calculation, there are $n^{n+1}$ possible ways of making $n+1$ draws of n values. And, there are $$n(n-1)(n-2)...(n-t+1)\binom{n-1}{1}(n^{n-t+1})=\frac{n!(n-1)(n^{n-t+1})}{(n-t+1)!}$$ ways of having exactly two values in t draws be equal. So, then the $P\{D_n=t\}$ : $$P\{D_n=t\}=\frac{n!(n-1)(n^{n-t+1})}{(n-t+1)!}*\frac{1}{n^{n+1}}$$ $$=\frac{n!(n-1)(n^{-t})}{(n-t+1)!}$$ However, I know this must be wrong because as $n \to \infty$ , this is (according to Mathematica), unbounded. Where am I going wrong?","['permutations', 'statistics']"
3234043,Confidence interval of $\mu_1 - \mu_2$ of two samples,"We have two samples where both is $N(\mu_i, \sigma_i)$ , we assume that $\sigma_1 = \sigma_2$ . From the two samples we get the follow numbers: $n_1 = 4, \bar{x} = 1007.25, s_1=143.66$ and $n_2 = 4, \bar{x}=817.25, s_2=73.627$ Calculate the lower limit of a confidence interval for $\mu_1 - \mu_2$ where the confidence level is 95%. What I've done: I calculated $s$ to be: $s=114,1471$ . Then I use t-distribution: $\mu_1 - \mu_2 - \frac{s\cdot \lambda_{\frac{\alpha}{2}}(f)}{\sqrt{n}}$ which gives: $1007.25 - 817.75 - \frac{s\cdot \lambda_{0.025}(6)}{\sqrt{8}} = 90.123$ which apparently is wrong. What am I doing wrong here? The thing I feel most uncertain about here is what $f$ and $n$ is supposed to be when using two samples like this.","['statistics', 'confidence-interval']"
3234052,Confusion about topology on CW complex: weak or final?,"The topology of the CW complex is defined to be the weak topology : given the sequence of inclusions of the skeleta $X_0 \subseteq X_1 \subseteq_ \cdots$ a subset $A \subseteq X = \cup X_i$ is open iff $A \cap X_i$ is open for all $i$ . Nlab says this is equivalent to the colimit of the inclusions, and so the weak topology is the same as the final topology: ""W = “weak topology”: Since a CW-complex is a colimit in Top over its
  cells, and as such equipped with the final topology of the cell
  inclusion maps..."" (Remark 1.1, https://ncatlab.org/nlab/show/CW+complex ) Following the link there to ""final topology"" it then says the weak topology means the same as initial topology and the final topology is synonymous with the strong topology , i.e., the opposite of the weak topology...
So which is correct, the weak or the strong? It seems that it cannot be both.","['general-topology', 'cw-complexes', 'algebraic-topology']"
3234053,"How to prove $\frac{\partial}{\partial x^r} (x^r) = 1$ where $(U, (x^1, ..., x^n))$ is a local chart of a smooth manifold.","Let $M$ be a  smooth manifold. I am getting lost in the notations. Could someone please explain me how to prove $\frac{\partial}{\partial x^r} (x^r) = 1$ where $(U, \phi = (x^1, ..., x^n))$ is a local chart of $M$ ? Also I would appreciate if someone one can tell me what I should think of $\frac{\partial}{\partial x^r}$ as intuitively?","['intuition', 'smooth-manifolds', 'differential-geometry']"
3234058,Range of rational expression having algebraic terms,"Find the range of $\displaystyle f(x) = \frac{x^2+x-1}{x^2-x+2}$ subjected to $-1 \leq x\leq 1$ . Plan \begin{align} y = \frac{x^2+x-1}{x^2-x+2}&\implies yx^2-yx+2y=x^2+x-1\\&\implies(y-1)x^2-(y+1)x+(2y+1)=0.\end{align} For $y=1$ , we have $x=3/2$ . For $y\neq 1$ , $$(y+1)^2-4(y-1)(2y+1)\geq 0$$ $$y^2+2y+1-4(2y^2-y-1)\geq 0$$ $$7y^2-6y-5\leq 0$$ $$y\in \bigg[\frac{3-2\sqrt{21}}{7},\frac{3+2\sqrt{21}}{7}\bigg]$$ But the solution is $\displaystyle \bigg[\frac{3-2\sqrt{21}}{7},\frac{1}{2}\bigg]\cup \{1\}$ . Help me please.","['calculus', 'functions', 'quadratics']"
3234126,Double centralizer of derived subgroup,"Let $G$ be (finite) matabelian group; define $W(G):=C_G(C_G(G'))$ ; $G'$ is derived subgroup of $G$ . If $\mathcal{F}$ is the collection of all maximal abelian normal subgroups of $G$ which contain $G'$ , then for any $A\in\mathcal{F}$ , it is easy to show that $C_G(A)=A$ . Since $G'\le A$ , so $C_G(G')\ge C_G(A)=A$ , so $C_G(C_G(G'))\le C_G(A)=A$ for all $A\in\mathcal{F}$ ; hence $$W(G)=C_G(C_G(G'))\le \bigcap_{A\in\mathcal{F}} A. $$ Q.1 Is there non-nilpotent metabelian group where $W(G)$ is proper subgroup of intersection of all maximal abelian normal subgroups in $G$ ? Q.2 In metabelian groups $G$ , what properties about $W(G)$ are known? Is there special name to this subgroup? In the case of nilpotent groups, one can easily obtain example of this nature: take a $p$ -group $H$ in which $H'$ is proper in $Z(H)$ . Then $W(H)=Z(H)$ ; so to push $W(H)$ properly in intersection of all maximal abelian normal subgroups, we may look for a $p$ -group in which maximal abelian normal subgroup is unique. I think, the construction of such $p$ -group is not difficult; however, I was unable to find an example of non-nilpotent group. Edit (after comment by Holt): I think, question (1) is not meaningful with following computation: Let $G$ be (finite) metabelian; let $A_1,\ldots, A_l$ be all the maximal abelian normal subgroups containing $G'$ . (So, $G/A_i$ is abelian, and it can be seen that $C_G(A_i)=A_i$ .) Suppose $g\in C_G(G')$ . Note that $G'$ is abelian (since $G$ is metabelian). Then $\langle g,G'\rangle$ is  abelian normal subgroup of $G$ (since it contains $G'$ ), so $\langle g,G'\rangle\subseteq A_i$ for some $i$ , hence $g\in A_i$ for some $i$ . This means, $C_G(G')\subseteq \cup_i A_i$ . Then taking centralizer in $G$ , we get $C_G(C_G(G'))\supseteq \cap_i C_G(A_i)=\cap_i A_i$ . Thus $W(G)\supseteq \cap A_i$ . The reverse inclusion is shown before Q.1. Thus, for finite metabelian equality holds in equation before Q.1. (I hope this is correct. Comments will be helpful.)","['group-theory', 'finite-groups']"
3234133,Self-similar solution of the momentum equation,"I have used the steam functions $u = \psi_{y}$ and $v = -\psi_{x}$ to transform the momentum equations to the following form $$\rho\left(\psi_{y}\psi_{xy} - \psi_{x}\psi_{yy}\right)=-p_{x}+\mu\left(\psi_{xxy}+\psi_{yyy} \right) $$ $$\rho\left(-\psi_{y}\psi_{xx} + \psi_{x}\psi_{xy}\right)=-p_{y}+\mu\left(\psi_{xxx}+\psi_{xyy} \right) $$ I eliminated the pressure term via cross-differentiation and have obtained the final form of the equation to be as follows $$\rho\left(\psi_{y}\left(\psi_{xyy}+\psi_{xxx} \right) - \psi_{x}\left(\psi_{yyy}+\psi_{xxy} \right) \right) = \mu\left(\psi_{xxxx} +\psi_{yyyy} + 2\psi_{xxyy} \right)\tag{1}, $$ which can be rewritten with $\nabla = \left<\partial_{x},\partial_{y} \right>$ as follows $$\rho\left(\psi_{y}\nabla^{2}\psi_{x} - \psi_{x}\nabla^{2}\psi_{y} \right) = \mu\nabla^{4}\psi$$ Now, this is a leading edge problem of a fluid flowing over a flat plate with viscous forces dominating. The self-similar variable was found to be $$\eta = \frac{y}{x}\tag{2},$$ and the self-similar stream function has the following form $$f(\eta) = \frac{\psi}{Ux}.\tag{3} $$ Substituting $(2)$ and $(3)$ into $(1)$ transforms the PDE to an ODE a follows $$\left(1+\eta^{2}\right)^{2}f_{\eta\eta\eta\eta}+8\eta\left(1+\eta^{2}\right)f_{\eta\eta\eta} + 4\left(1+3\eta^{2}\right)f_{\eta\eta} + Re\left[2\eta ff_{\eta}+\left(1+\eta^{2}\right)\left(ff_{\eta\eta\eta} + f_{\eta}f_{\eta\eta}\right)\right]=0,\tag{4}$$ where $Re=\frac{\rho Ux}{\mu}$ Could someone please show me how this transformation is done.
I tried proceeding via the chain rule and was able to compute all the derivatives but failed to obtain the final form as shown in $(4)$ . Any help is appreciated.","['fluid-dynamics', 'ordinary-differential-equations', 'partial-differential-equations']"
3234144,How to compute the MLE of the zero truncated poisson?,"$$P(X = x ) =  
\frac{\theta ^ x e^{- \theta} }{x ! \left ( 1 - e^{- \theta} \right )},\ x=1,2,\cdots,\ 0<\theta<\infty$$ Then the likelihood of $(x_1,\cdots,x_n)$ is $$\mathcal L(\theta \mid \boldsymbol y) = \prod_{i=1}^n \frac{e^{-\theta}}{1-e^{-\theta}} \frac{\theta^{x_i}}{x_i!} \propto (e^{\theta} - 1)^{-n} \theta^{n \bar x}$$ so the log-likelihood is $$\ell(\theta \mid \boldsymbol x) = -n \log(e^{\theta} - 1) + n\bar x \log \theta$$ and its derivative with respect to θ is $$\frac{\partial \ell}{\partial \theta} = \frac{e^\theta}{1-e^{\theta}} + \frac{\bar x}{\theta}$$ but I don't know how to compute $\partial \ell/\partial\theta = 0$ , since this does not have a closed form expression. Is there anyone can give me an idea?","['statistics', 'poisson-distribution', 'maximum-likelihood']"
3234157,Expected maximum number of unpaired socks,"Like all combinatoric problems, this one is probably equivalent to another, well-known one, but I haven't managed to find such an equivalent problem (and OEIS didn't help), so I offer this one as being possibly new and possibly interesting. Problem statement I have $2N$ socks in a laundry basket, and I am hanging them on the hot pipes to dry. To make life easier later, I want to hang them in pairs. Since it is dark where the pipes are, I adopt the following algorithm: Take a sock at random from the basket. If it matches one that is already on my arm, hang them both on the pipes: the one in my hand and the matching one taken from my arm. If it does not match one that is already on my arm, hang it on my arm with the others. Do this $2N$ times. The question is: How long does my arm have to be? Clearly, the minimum length is $1$ , for instance if the socks come out in the order $AABBCC$ . Equally clearly, the maximum length is $N$ , for instance if the socks come out as $ABCABC$ . But what is the likeliest length? Or the average length? Or what sort of distribution do the required lengths have? It turns out to be easiest to parameterise the results not by $2N$ , the number of socks, but by $2N-1$ , which I will call $M$ . The first few results (Notation: $n!!$ is the semifactorial, the factorial including only odd numbers; thus $7!!=7\times 5\times 3\times 1$ ). In each case I provide the frequency for each possible arm length, starting with a length of 1. I use frequencies rather than probabilities because they are easier to type, but you can get the probabilities by dividing by $M!!$ . $$
\begin{array}{c|rrrrr}
M \\
\hline
1 & 1 \\
3 & 1 & 2 \\
5 & 1 & 8 & 6 \\
7 & 1 & 30 & 50 & 24 \\
9 & 1 & 148 & 340 & 336 & 120 \\
\end{array}
$$ It would be good to know (for example) if these frequencies tend to some sort of known distribution as $M\to\infty$ , just as the binomial coefficients do. But, as I said at the beginning, this may just be a re-encoding of a known combinatorial problem, carrying a lot of previously worked out results along with it. I thought, for instance, of the lengths of random walks in $N$ dimensions with only one step forward and one step back being allowed in each dimension – but that looked too complicated to give any straightforward direction to follow. Background: methods In case it is interesting or helpful, I obtained the results above by means of a two-dimensional generating function, in which the coefficient of $y^n$ identified the arm length needed and the coefficient of $x^n$ identified how many socks had been retrieved at the [first] time that this length was reached. Calling the resulting generating function $A_M(x,y)$ , the recurrence I used was: $$A_M=MxyA_{M-2}+x^2(x-y)\frac\partial{\partial x}A_{M-2}+(1-x^2)xy$$ which is based on sound first principles and matches the results of manual calculation up to $M=5$ . Having found a polynomial, I substitute $x=1$ and the numbers in the table above are then the coefficients of the powers of $y$ . But, mathematics being close to comedy, all this elaboration may be an unnecessarily complicated way to get to a result too trivial to be found even in OEIS. Is it?","['combinatorics', 'generating-functions']"
3234229,How to calculate the derivative of $\int_0^x \left(\frac{1}{t}-[\frac{1}{t}]\right)dt$ at $x=0$?,"Let $F(x):=\int_0^x \left(\frac{1}{t}-[\frac{1}{t}]\right)dt$ ,where $[\frac{1}{t}]$ is the largest integer no more than $\frac{1}{t}$ .Prove $F'(0)=\frac{1}{2}$ . I have tried in this way: \begin{equation}
\begin{aligned}
\lim_{n\to\infty}nF\left(\frac{1}{n}\right)&=\lim_{n\to\infty}n\sum_{k=n}^\infty\int_\frac{1}{k+1}^\frac{1}{k}\left(\frac{1}{t}-\left[\frac{1}{t}\right]\right)dt\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty\int_\frac{1}{k+1}^\frac{1}{k}\left(\frac{1}{t}-k\right) dt\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty \left(\ln(1+\frac{1}{k})-\frac{1}{k+1}\right)\\&=\lim_{n\to\infty}n\sum_{k=n}^\infty \left(\frac{1}{k}-\frac{1}{k+1}\right)\\&=1.
\end{aligned}
\end{equation} Please give me some ideas,thank you!","['calculus', 'analysis']"
3234360,What is the geometric intuition of $n/p$?,"(volume for ball): Let B $_{r}^{p}(0):=\{x\in\mathbb R^n; \|x\|_p\leq r\}$ . Then the volume of B $_{r}^{p}(0)$ is \begin{align}
{\rm V}_r^{p}=2^n\cdot\frac{\left\{\Gamma(\frac{1}{p}+1)\right\}^n}{\Gamma\left(\frac{n}{p}+1\right)}\cdot r^n. \quad\text{(calculation of multi-integral)}
\end{align} (Sobolev embedding): Sobolev space $W^{k,p}(n)(1\leq p<\infty)\rightarrow \frac{n}{p}-k:=i$ . If $0<i$ , then $W^{k,p}\hookrightarrow W^{\ell,q}$ , where $\frac{n}{q}-\ell=i, k>\ell$ . If $0>i$ , then $W^{k,p}\hookrightarrow C^{r,\alpha}$ , where $-(r+\alpha)=i, 0<\alpha\leq1$ . Notice that there is a well-marked factor \begin{align}
\frac{n}{p}=\frac{\text{dimension of space}}{\text{norm index of space}}.\end{align} What is the significance or geometric intuition of $\frac{n}{p}$ , which I think is essential and fundamental? (Maybe I think too much, thanks!)",['analysis']
3234403,Convergence of Feller processes implies convergence of the resolvent operators of their generators,"Let $E$ be a locally compact separable metric space $(T_n(t))_{t\ge0}$ and $(T(t))_{t\ge0}$ be strongly continuous contraction semigroups on $C_0(E)$ with generator $(\mathcal D(A_n),A_n)$ and $(\mathcal D(A),A)$ , respectively, for $n\in\mathbb N$ $(\Omega,\mathcal A,\operatorname P)$ be a probability space $(X^n_t)_{t\ge0}$ and $(X_t)_{t\ge0}$ be $E$ -valued càdlàg processes on $(\Omega,\mathcal A,\operatorname P)$ with $$\operatorname E\left[f(X^n_t)\mid(X^n_r)_{r\le s}\right]=(T_n(t-s)f)(X^n_s)\;\;\;\text{almost surely}\tag1$$ and $$\operatorname E\left[f(X_t)\mid(X_r)_{r\le s}\right]=(T(t-s)f)(X_s)\;\;\;\text{almost surely}\tag2$$ for all $f\in C_0(E)$ and $t\ge s\ge0$ Suppose we know that $X^n\xrightarrow{n\to\infty}X$ weakly (wrt the Skorohod topology) whenever $X^n_0\xrightarrow{n\to\infty}X_0$ . Let $f\in C_0(E)$ , $\lambda>0$ , $(x_n)_{n\in\mathbb N}\subseteq E$ and $x\in E$ with $x_n\xrightarrow{n\to\infty}x$ . Are we able to conclude that $$(R_\lambda(A_n)f)(x_n)\xrightarrow{n\to\infty}(R_\lambda(A)f)(x),\tag3$$ where $R_\lambda(A_n)$ and $R_\lambda(A)$ denote the resolvent operator of $A_n$ and $A$ , respectively, with respect to the regular value $\lambda$ . From general operator theory, we know that $$R_\lambda(A_n)f=\int_0^\infty e^{-\lambda t}T_n(t)f\:{\rm d}t\tag4$$ and $$R_\lambda(A)f=\int_0^\infty e^{-\lambda t}T(t)f\:{\rm d}t.\tag5$$ From $(1)$ and $(2)$ we conclude that $$R_\lambda(A)f=\operatorname E\left[\int_0^\infty e^{-\lambda t}f(X^n_t)\:{\rm d}t\mid X^n_0=\;\cdot\;\right]\;\;\;(X^n_0)_\ast\operatorname P\text{-almost surely}\tag6$$ and $$R_\lambda(A)f=\operatorname E\left[\int_0^\infty e^{-\lambda t}f(X_t)\:{\rm d}t\mid X_0=\;\cdot\;\right]\;\;\;(X_0)_\ast\operatorname P\text{-almost surely}.\tag7$$ We may note that $$g:D([0,\infty),E)\to\mathbb R\;,\;\;\;y\mapsto\int_0^\infty e^{-\lambda t}f(y(t))\:{\rm d}t$$ is bounded and continuous (where $D([0,\infty),E)$ denotes the space of càdlàg functions from $[0,\infty)$ to $E$ equipped with the Skorohod topology). Let $\delta$ denote the Dirac kernel on $(E,\mathcal B(E))$ , we may note that $$\delta_{x_n}\xrightarrow{n\to\infty}\delta_x\tag8$$ weakly. By $(8)$ and boundedness and continuity of $g$ , we easily see that if $(X^n_0)_\ast\operatorname P=\delta_{x_n}$ and $(X_0)_\ast\operatorname P=\delta_x$ , then $(3)$ holds true. However, what if $X^n$ and $X$ have arbitrary initial distributions? Can we reduce the problem somehow to the former case?","['weak-convergence', 'operator-theory', 'markov-process', 'functional-analysis', 'probability-theory']"
