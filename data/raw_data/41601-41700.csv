question_id,title,body,tags
411098,How to denote the set of binary relations of which a particular ordered pair is a member?,"Given a universe $U$ and two subsets $S$ and $T$ (also, both members of $U$), what is the name given to denote the set of all binary relations in $U$ where the ordered pair $(S,T)$ is a member? The concept I'm trying to describe is similar to $Hom(S,T)$ in a category of sets, but where as $Hom(S,T)$ is a category of all morphisms from $S$ to $T$, the concept I am targeting is: (1) limited in scope to sets; and (2) looking for all the morphisms for which $(S,T)$ are associated instead of for the morphisms from $S$ to $T$.","['relation-algebra', 'elementary-set-theory', 'abstract-algebra', 'relations', 'category-theory']"
411104,Help finding eigenvectors?,"The given matrix is: $$
\begin{pmatrix}3 & 1 & 6 \\ 2 & 1 & 0 \\ -1 & 0 & -3\end{pmatrix}\qquad
$$ I got the characteristic polynomial of $$x^3 - x^2 - 5x - 3 = 0$$ which factors down to $$(x+1)^2 * (x-3) = 0$$ I see that it  has eigenvalues of -1 and 3. I know I'm almost there, I plugged in the eigenvalues to $A-\lambda I$ but completely forgot how to find the eigenvectors after this. When $\lambda$ = 3, I got: $$\begin{pmatrix}0 & 1 & 6 \\ 2 & -2 & 0 \\ -1 & 0 & 0\end{pmatrix} \begin{pmatrix}x
_1 \\ x_2 \\ x_3\end{pmatrix}=0\qquad$$ and when $\lambda$ = -1, I got: $$\begin{pmatrix}4 & 1 & 6 \\ 2 & 0 & 0 \\ -1 & 0 & 4\end{pmatrix}\begin{pmatrix}x
_1 \\ x_2 \\ x_3\end{pmatrix}=0\qquad$$ Where do I go from here? Row-reduce the $3x3$ matrices to solve?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
411119,Does there exist such a closed subspace of normed linear space,"let $(X,|| || )$ be a norm linear space. And $M$ be a closed subspace of norm linear space .does there exist a closed subspace $N$ such that $X=M \oplus N $ . I know such an subspace $N$ exist .but i am not conform about such an $N$ is closed or not .","['normed-spaces', 'functional-analysis', 'banach-spaces']"
411140,"solving linear system ""by inspection""?","A text question is asking to solve some linear systems by inspection . My interpretation of ""by inspection"" is ""by looking"". For a linear system like $$
\begin{cases}
3x + 4y = 28\\
3x + 4y = 83
\end{cases}
$$ you could say that by inspection there is no solution because ""two (of the same) numbers can't have different sums."" or given the system $$
\begin{cases}
y = 3x + 5\\
y = 2x + 5
\end{cases}
$$ you could say that by inspection, the solution is (0, 5) because both lines have the same y-intercept but different slopes. But the exercises given in my text don't seem (to me) to lend themselves to solution by inspection (hence my question here). The four systems are: $$
\begin{cases}
x + y = 6\\
2x + y = 8
\end{cases}
$$ $$
\begin{cases}
x - y = 1\\
5x + 2y = 5
\end{cases}
$$ $$
\begin{cases}
x + y = 8\\
2x + y = -11
\end{cases}
$$ $$
\begin{cases}
2x + y = 13\\
x + 2y = 7
\end{cases}
$$ For each one, it seems that at the very least some mental calculation is required — which goes beyond the concept of ""by inspection"" in my opinion. Or does it? Or is there something else I'm missing? Thank you.","['linear-algebra', 'terminology']"
411141,Covariance of sums of random variables,"I need some help understanding an excercise. Let $X_1, X_2, X_3 \sim N(-2,3).$ (right here there is an ambiguity about the second parameter: is it $\sigma$ or $\sigma^2$ ?) First they calculate the variance $$\sigma^2\left(\sum_{i=1}^3 i  X_i\right) = \sum_{i=1}^3 i^2 \sigma^2 X_i = 14 \cdot 9 = 126$$ So far I think I understand. This result implies that $\sigma = 3$ . Am I correct? Then they give the following line without any explanation: $$\operatorname{cov}\left(\sum_{i=1}^3 i  X_i, \sum_{i=1}^3 X_i\right) = \sum_{i=1}^3 i \cdot \sigma^2 X_i = 54$$ Can you explain what happens here? How did they derive $\sum_{i=1}^3 i \cdot \sigma^2 X_i $?","['statistics', 'probability']"
411143,Singular value decomposition of positive definite matrix,"Let $A$ be a positive definite matrix, and let $A = U \Sigma V^*$ be its singular value decomposition (SVD). Show that $U=V$ . What I have done: $A$ is Hermitian, so $A$ is unitarily diagonalizable, say, $A=WDW^*$ where $D$ consists of the eigenvalues (decreasing order). Also $D=\Sigma$ since $A$ is positive definite. From $A^2=AA^*=UD^2U^*$ , and similarly I have $A^2=UD^2U^*=VD^2V^*=WD^2W^*$ so the column vectors of $U,V,W$ corresponds to same eigenvalues of $A^2$ . And I'm now stuck. How could I proceed?","['positive-definite', 'matrices', 'linear-algebra', 'svd']"
411145,"Maximum likelihood estimation of $a,b$ for a uniform distribution on $[a,b]$","I'm supposed to calculate the MLE's for $a$ and $b$ from a random sample of $(X_1,...,X_n)$ drawn from a uniform distribution on $[a,b]$. But the likelihood function, $\mathcal{L}(a,b)=\frac{1}{(b-a)^n}$ is constant, how do I find a maximum? Would appreciate tips on how to proceed!","['statistics', 'maximum-likelihood', 'uniform-distribution', 'parameter-estimation']"
411164,Is every vector space basis for $\mathbb{R}$ over the field $\mathbb{Q}$ a nonmeasurable set?,"The existence of subsets of the real line which are not Lebesgue measurable can be argued using the Axiom of Choice. For example, define an equivalence relation on $[0, 1]$ by $a \thicksim b$ if and only if $a - b \in \mathbb{Q}$ and let $S \subset [0, 1]$ contain exactly one representative from each class; $S$ is not Lebesgue measurable. Now, the Axiom of Choice also gives us that every vector space has a basis, and in particular $\mathbb{R}$ has a basis over the field $\mathbb{Q}$. Can a similar (but assumedly much more involved) argument show that every such basis is a nonmeasurable set?","['vector-spaces', 'hamel-basis', 'measure-theory', 'axiom-of-choice']"
411175,The differentiability of distance function,"Let $M$ be a submanifold of $\mathbb R^n$, then is there an open set $\Omega$ in $\mathbb R^n$ such that function $d(x,M)$ (distance function) is smooth on $\Omega$?",['differential-geometry']
411178,"""Center"" of a spherical triangle","I have a very deficient background in geometry, so I come across questions like these and I'm not sure how to verify my intuition. Consider three points in $\mathbb{R}^3$, given by position vectors, lying on a sphere centered at the origin. These define both a spherical triangle and a plane. Is the sum of the position vectors normal to the plane? I think this is true but I can't figure out how the details go. Also, it seems like projecting the triangle onto the plane should put the sum of the vectors in some sort of center for the triangle, would that be the circumcenter? Thank you in advance!","['geometry', 'spherical-geometry']"
411187,"Prove that the circle $S^1$ is not the boundary of any compact manifold with boundary in $\mathbb R^2-{(0,0)}$","Suppose it were, then define a 1-form $w:=\frac{1}{x^2+y^2}(-y\,\mathrm dx+x\,\mathrm dy)$. Firstly , I try to evaluate $\int_{S^1}w$ by two ways . Firstly, let $F\colon[0,2 \pi]\to S^1$ defined by $F(\theta)=(\sin\theta, \cos\theta)$, then $\int_{S^1}w=\int_{[0,2\pi]} F^{\ast}w=\int_{[0,2\pi]}(-\cos^2\theta \,\mathrm d\theta+\sin^2\theta \,\mathrm d\theta)=-2\pi$. Then I want to evaluate $\int_{S^1}w$ by using Stoke's theorem (This uses the assupmtion that $S^1$ is the boundary of some compact manifold with boundary in $\mathbb R^2-{(0,0)}$). If the result of this integral is different from $-2\pi$, then I can conclude the assumption is false, thus proving the result. However, I don't know how to evaluate by using Stoke, I am stuck with how to change the 1-form into 0-form and evaluate it. Thanks for any help!","['multivariable-calculus', 'differential-geometry', 'manifolds', 'analysis', 'complex-analysis']"
411191,Pointwise but not Uniformly Convergent,"The Question: Prove that the sequence of functions $f_n(x)=\frac{x^2+nx}{n}$ converges pointwise on $\mathbb{R}$, but does not converge uniformly on $\mathbb{R}$. My Work: Prove Pointwise: First, $\lim\limits_{n\to\infty} \frac{x^2+nx}{n}=\lim\limits_{n\to\infty} \frac{x^2}{n}+x=x$. My Problem: I am not sure where this fails to be uniformly convergent. Any help is appreciated. 
Thanks","['convergence-divergence', 'real-analysis', 'uniform-convergence']"
411196,How to prove that operator is not compact in $L_2 (\mathbb{R})$,I have the operator $(Af)(x) = \int _{\mathbb{R}} e^{{-(x-t)^2}/2} f(t) dt$. It seems to me that it isn't compact and I'm looking for some general <=> criterion for integral operators to be compact on $L_2 (\mathbb{R})$.,"['operator-theory', 'functional-analysis', 'convolution']"
411212,Limit of product of $\sin \frac{k}{n}$,"Could you help me how to find the limit of $$\left(\sin \frac{1}{n} \cdot \sin \frac{2}{n} \cdots \sin 1\right)^{\frac{1}{n}}?$$ I know that $$\ln \left((\sin \frac{1}{n} \cdot \sin \frac{2}{n} \cdots \sin 1)^{\frac{1}{n}} \right)=\frac{1}{n} \sum_{k=1}^n \ln \left( \sin(\frac{k}{n})\right)$$ and $$\lim _{n \rightarrow \infty}  \frac{1}{n} \sum_{k=1}^n \ln \left( \sin(\frac{k}{n})\right) = \int_0^1 \ln(\sin(x)) \, dx \text{ (Riemann integral)}$$ but I am not sure what to do next, I mean, how do I get back to $$\lim_{n \rightarrow \infty} (\sin \frac{1}{n} \cdot \sin \frac{2}{n} \cdots \sin 1)^{\frac{1}{n}}?$$ Could you help me with that?","['sequences-and-series', 'integration', 'limits']"
411224,How to evaluate double integrals over a region?,"Evaluate the double integral $\iint_D(1/x)dA$, where D is the region bounded by the circles $x^2+y^2=1$ and $x^2+y^2=2x$ Alright so first I converted to polar coordinates: $$ x^2 + y^2 = 1 \ \Rightarrow \ r = 1 \ \ , \ \
x^2 + y^2 = 2x \ \Rightarrow \ r^2 = 2r \cos θ \ \Rightarrow \ r = 2 \cos θ \ .  $$ Points of intersection:
$ 2 \cos θ = 1 \ \Rightarrow \ θ = ±π/3 \ , $ $ 2 \cos θ > 1 $ for θ in (-π/3, π/3). So, $$ \int \int_D \ (1/x) \ \ dA
 \ \ = \ \ \int_{-π/3}^{π/3} \ \int_1^{2 \cos θ} \ \frac{1}{r \cos θ} \ \ r dr \  dθ  $$ $$ = \ \ \int_{-π/3}^{π/3} \ \int_1^{2 \cos θ} \ \sec θ \ \ dr \  dθ \ \ 
= \ \ \int_{-π/3}^{π/3} \ (2 \cos θ - 1) \sec θ \ \ dθ $$ $$ = \ \ 2 \ \int_0^{π/3} \ (2 - \sec θ) \ \ dθ \ \ , $$ (since the integrand is even) $$ = \ \ 2 \ (2 θ \ - \ \ln |\sec θ + \tan θ| \ ) \vert_0^{π/3} \ \ = \ \ \frac{4π}{3} \ - \ 2 \ln(2 + √3) \ \ .  $$ I'm not sure this is right. Could someone look over it?",['multivariable-calculus']
411225,Cardinal number of eventually constant rational sequences,"If $D_n=\{\langle d_k\rangle\in \mathbb{Q}^\mathbb{N}: (\exists q\in \mathbb{Q})(\forall k\geq n) \,d_k=q\}$, what is the cardinal number of $D_n$? Is it $|D_n|=|\mathbb{Q}^\mathbb{N}|=|\mathbb{Q}|^{|\mathbb{N}|}=\aleph_0^{\aleph _0}=\aleph _0$?",['elementary-set-theory']
411228,How to describe the one point compactification of a space,"In my Topology course we defined the one point compactification of a Hausdorff space $\left(X,\tau\right) $ to be a compact Hausdorff space $\left(Y,\tau^{'}\right)
 $ such that $X\subseteq Y$, $\tau\subseteq\tau^{'}$ and $\left|Y\backslash X\right|=1
$. More specifically one such construction is given by taking $Y=X\cup\left\{ \infty\right\}$ and defining: $$\tau^{'}=\tau\cup\left\{ U\subseteq Y\;|\;\infty\in U\:\wedge\; Y\backslash U\;\mbox{is compact}\right\}$$ That is all nice and well but it gives me no clue whatsoever as to how to find a ""nice representation"" to the one point compactification of a given space. In particular I need to describe an embedding in $\mathbb{R}^{n}$ of the one point compactifications of each of the following: $\left[0,1\right]$ $\left(0,1\right)$ $\mathbb{N}$ Help would be greatly appreciated. EDIT: I just noticed there was another section to the question about the compactification of $X=\left(0,1\right)\times\left\{ 0,1\right\}$. Since this is all in the subspace topology of $\mathbb{R}^{2}$ which is metric I find it more convenient to use the ""heuristic"" of trying to answer the questions ""what are the sequences in $X$ that don't converge in $X$ and how to add one point to the space so all those sequences would converge to it"". In the case of $\left(0,1\right)$ the answer was folding the line segement into a circle. In this case since I essentially have two parallel ""line segments"" in $\mathbb{R}^{2}$ it would seem the nicest way to achieve what I want would be to fold them both into an $8$ shape but I can't really see what sort of mapping would do that for me... EDIT 2: I tried tackling the problem in another way, instead of trying to fold $\left(0,1\right)\times\left\{ 0\right\}$ upwards and $\left(0,1\right)\times\left\{ 1\right\}$ downwards to form two ellipses with one point in common I decided to copy $\left(0,1\right)\times\left\{ 0\right\}$ and $\left(0,1\right)\times\left\{ 1\right\}$ into two circles with one point $\left(0,0\right)$ in common, I did this using the following mapping: $$f\left(x,y\right)=\begin{cases}
\left(\sin\left(2\pi x\right),\cos\left(2\pi x\right)-1\right) & \left(x,y\right)\in\left(0,1\right)\times\left\{ 0\right\} \\
\left(\sin\left(2\pi x\right),1-\cos\left(2\pi x\right)\right) & \left(x,y\right)\in\left(0,1\right)\times\left\{ 1\right\} 
\end{cases}$$
If I'm not mistaken this should be a homeomorphism between $X$ and the union of two circles of radius 1, one centered at $\left(0,-1\right)$ and one at $\left(0,1\right)$  minus the point $\left(0,0\right)$. Then the one point compactification of said union would be obtained by adding the point $\left(0,0\right)$ (the union of the circles is closed as the union of two closed sets and is also bounded and thus compact by Heine-Borel theorem). This compactification would be in turn homeomorphic to the compactification of $X$. Could someone confirm if this train of thought indeed arrives at its intended destination?","['general-topology', 'compactness']"
411238,Non-integer bases and irrationality,"I read somewhere: When it comes to properties like prime, irrational, rational,
  divisible by 2, etc., nothing changes when you change base. But I'm not sure about the rational/irrational one. If you use non-integer bases, even integer numbers can become ugly expressions (See 3 in base 2.5 in Wolfram ) The point is: is that number irrational, or it just has a lot of repeating decimals?
Either way, how could you prove it?","['number-systems', 'irrational-numbers', 'number-theory']"
411249,What is a parallel line?,"We are learning vectors in class and I have a question about parallel lines and coincident lines. According to wikipedia a parallel line is: Two lines in a plane that do not intersect or touch at a point are called parallel lines. But another reference says Side by side and having the same distance continuously between them. According to the above definition, you can have two parallel lines with a distance of zero but this contradicts the first definition. So which is it? EDIT: If it is the second definition then you can have two lines that are coincident and parallel right?","['geometry', 'algebra-precalculus']"
411256,can the following sum be simplified,"For $n \ge 3$, define
$$f(n) = \sum_{k=3}^n {n \choose k}{k-1 \choose 2}.$$ Is there a closed form expression for $f$?","['summation', 'combinatorics']"
411261,Find volume using double integrals?,"Question: Use double integral to find the volume of the solid enclosed by the spheres $x^2+y^2+z^2=1$ and $x^2+y^2+(z-1)^2=1$ Alright so I tried to doing this by myself and I'm not sure if this is right. Could someone check over my work? Curve of intersection:
\begin{align*}
x^2 + y^2 + z^2 &= x^2 + y^2 + (z - 1)^2\\
\implies z^2 &= z^2 - 2z + 1\\
\implies z &= 1/2.
\end{align*} So, the curve of intersection is $x^2 + y^2 = 3/4$ with $z = 1/2$.
By symmetry, it suffices to double the volume between $z = 1/2$ and $z = 1$. $x^2 + y^2 + (z-1)^2 = 1$ is above $x^2 + y^2 + z^2 = 1$ when $z > 1/2$. Solving for (positive) $z$ yields
$z = \sqrt{1 - x^2 - y^2}$ and $z = 1 + \sqrt{1 - x^2 - y^2}$. Hence, the volume equals
\begin{align*}
V &= 2  \iint \left[(1 + \sqrt{1 - x^2 - y^2}) - \sqrt{1 - x^2 - y^2}\right]\, dA\\ \\
&= 2 \int_0^{2\pi}\!\int_0^{\sqrt{3/4}}\!r\,dr \,d\theta, \qquad\textrm{via polar coordinates}\\ \\
&= 2 \int_0^{2\pi} \!\left[(1/2)r^2\right]_{r = 0}^{\sqrt{3/4}}\, d\theta\\ \\
&= \int_0^{2\pi}\!3/4\,d\theta\\ \\
&= 3\pi/2.
\end{align*}",['multivariable-calculus']
411280,Given $\Sigma a_n$ diverges show that $\Sigma \frac{a_n}{1+a_n}$ diverges. [duplicate],"This question already has answers here : Positive series problem: $\sum\limits_{n\geq1}a_n=+\infty$ implies $\sum_{n\geq1}\frac{a_n}{1+a_n}=+\infty$ (7 answers) Closed 8 years ago . Intuitively speaking, I first thought that if the series $\Sigma a_n$ is divergent then $$\lim_{n \to \infty} a_n \ne 0$$ therefore it was clear that $\Sigma \frac{a_n}{1+a_n} $ would be divergent, but when I thought about it there are cases where the limit of the sequence does approach to $0$ and yet diverge, like the harmonic series. Then I tried to go with since the sequence diverges, the series is not Cauchy (I
m not even 100% sure if this is true but I tried) $$|\sum_{i = m}^{n} a_n| \gt \epsilon$$ and derive the other series to not be Cauchy as well, only to not being able to reach. I appreciate all the help.","['sequences-and-series', 'cauchy-sequences', 'analysis']"
411286,Definition of Zariski Topology,"Could someone explain to me, what is Zariski Topology? Under what condition a topology can be called Zariski Topology? Between the set $$V(E)=\{P \in \mathrm{Spec}(R)|E \subseteq P\}$$ and $$D(r)=\{P \in \mathrm{Spec}(R) | r \notin P \},$$ which one of them is Zariski Topology? Thank you.",['algebraic-geometry']
411289,Is $\lim_{n \to \infty} \sqrt[n]{\frac{1}{n!}} = 0$? [duplicate],"This question already has answers here : $\lim\limits_{n \to{+}\infty}{\sqrt[n]{n!}}$ is infinite (12 answers) Closed 11 years ago . When I was trying to solve a problem to find the radius of convergence of the power series $$\sum \frac{2^nz^n}{n!}$$ I fully understand that the ratio test works well in this one and the radius of convergence is $\infty$. However, knowing that the root test gives a better span of the ratio test and it is necessary to prove it, I wanted to be able to find the radius of convergence using the ratio test. Thus obtaining the following $$\begin{align}
\lim_{n \to \infty} \sqrt[n]{\frac{2^nz^n}{n!}} & = |2z|\lim_{n \to \infty} \sqrt[n]{\frac{1}{n!}} \\
\\
& = 0\\
\\
& \lt 1 \\
\\
& \Rightarrow R = \infty
\end{align}$$ must be true. So, I was thinking that $\lim_{n \to \infty} \sqrt[n]{\frac{1}{n!}}$ must be equal to 0. Is there a direct proof of this ? I just want to be a bit more algebraically savvy.","['limits', 'sequences-and-series', 'real-analysis', 'analysis']"
411302,Sum of alternating sign squares of integers stuck with proof by induction,"Note that
$$
A(1):1=1\\A(2):1-4=-(1+2)\\A(3):1-4+9=1+2+3\\A(4):1-4+9-16=-(1+2+3+4)
$$
Let us set up the $A(k)$:
$$
A(k)=1-4+9-…+(-1)^{k+1}k^2=(-1)^{k+1}(1+2+…+k)
$$
Setting up $A(k+1)$:
$$
A(k+1)=1-4+9-…+(-1)^{k+1+1}(k+1)^2=(-1)^{k+1+1}(1+2+…+k+(k+1))
$$
Knowing that:
$$
1+2+…+n=\frac{n(n+1)}{2}
$$
We simplify right hand sides of $A(k)$ and $A(k+1)$:
$$
A(k)=(-1)^{k+1}(1+2+…+k)=(-1)^{k+1}\frac{k(k+1)}{2}\\A(k+1)=(-1)^{k+1+1}(1+2+…+k+(k+1))=(-1)^{k+1+1}\frac{(k+1)(k+2)}{2}
$$
Then I am trying to show that right hand side of $A(k+1)$ is equal to $A(k) + (-1)^{k+1+1}(k+1)^2$, but it does not work for me. That is what I am getting:
$$
A(k+1)=(-1)^{k+1+1}\frac{(k+1)(k+2)}{2}=(-1)^{k+1+1}\frac{k^2+2k+k+2}{2}=(-1)^{k+1+1}(\frac{k(k+1)}{2}+(k+1))=(-1)A(k)+(-1)^{k+1+1}(k+1)=-(A(k)+(-1)^{k+1}(k+1))
$$ What am I doing wrong?
How to prove $A(k)$ by induction?","['induction', 'sequences-and-series']"
411313,Realizing groups as symmetry groups,"We're supposed to think of (non-Abelian) groups as groups of symmetries of some object. Sometimes it isn't obvious what this object is. For example, the fundamental group of a topological space acts by symmetries on the universal cover. Does anyone have any examples of (non-Abelian) groups which aren't defined as the group of symmetries of something but turn out to be the group of symmetries of some non-obvious thing? Edit: In response to Qiaochu's comment I have edited the question appropriately.","['big-picture', 'big-list', 'group-actions', 'symmetry', 'group-theory']"
411316,General Integral Formula,"I know how to find the integral below, but I would like to know if there is any clever or general formula for the integral, since my method involves simple polynomial division... $\int \frac{1}{1+\sqrt[n]x}dx$ Thanks.",['integration']
411324,"Is thi set of vectors, $\{(2, 1), (3, 2), (1, 2)\}$, is linearly dependent or independent?","Given a set of vectors 
S = $\left\{
\begin{bmatrix} 2 \\ 1 \end{bmatrix},
\begin{bmatrix} 3 \\ 2 \end{bmatrix},
\begin{bmatrix} 1 \\ 2 \end{bmatrix}
\right\}
 $ Find out if the vectors are linearly dependent or independent I know that for a set of vectors to be linearly dependent, they must satisfy the below equation: $$c_1v_1 + c_2v_2 ... c_nv_n = \mathbf 0 $$ such that not all $c_i$ are zero. So, I decided to apply Gauss Elimination and I got the following equation: $
c_1\begin{bmatrix} 2 \\ 1 \end{bmatrix} + c_2 \begin{bmatrix} 3 \\ 2 \end{bmatrix} + c_3 \begin{bmatrix} 1 \\2 \end{bmatrix} = \begin{bmatrix} 0 \\ 0\end{bmatrix}
$ And, needless to say, I get an under-determined system of equations below: $$2c_1 + 3c_2 + c3 = 0$$
$$c_1 + 2c_2 + 2c_3 = 0$$ And after solving, I get this:
$$c_1 = 4c_3$$
$$c_2 = -3c_3$$ So, $c_3$ is the free variable. Assuming $c_3$ is non zero, the vectors are linearly dependent. If it is zero, vectors are linearly dependent. How can it be that a free variable decides whether vectors are linearly dependent or not ? Shouldn't it a 100% yes or no answer that does not fluctuate depending on values of constants?","['matrices', 'linear-algebra']"
411339,Ideal of smooth function on a manifold vanishing at a point,"I'm trying to prove the following lemma: let $M$ be a smooth manifold and consider the algebra $C^{\infty}(M)$ of smooth functions $f\colon M \to \mathbb{R}$. Given $x_0 \in M$, consider the ideals
$$\mathfrak{m}_{x_0} := \{f\in C^{\infty}(M) : f(x_0)=0\},$$
$$\mathfrak{I}_{x_0} := \{f\in C^{\infty}(M) : f(x_0)=0, df(x_0)=0\}.$$
Then $\mathfrak{I}_{x_0} = \mathfrak{m}^2_{x_0}$, i.e. any function $f$ vanishing at $x_0$ together with its derivatives can be written as
$$f=\sum_kg_kh_k, \quad g_k, h_k \in \mathfrak{m}_{x_0}.$$
I have no idea about how to prove the inclusion $\mathfrak{I}_{x_0} \subseteq \mathfrak{m}^2_{x_0}$.","['manifolds', 'differential-geometry']"
411348,How to prove this inequality for determinant of Hermitian block matrix?,"I am given an Hermitian positive definite matrix $$D=\left(\begin{matrix}A&\overline{C}^T\\C&B\end{matrix}\right)$$
$A$ and $B$ are square matrices. The task is to prove the following inequalities: $\det(D)\leq\det(A)\det(B)\\\det(D)\leq\prod_{i=1}^{n}(d_{ii})$ All I can see is that $A,B$ are also Hermitian, and that determinant is equal to product of eigenvalues for $D, A, B$ since they are Hermitian, and those are positive since matrix is positive definite, and I have no further idea. Maybe you could give an advice or kind of hint. Thanks in advance!","['inequality', 'hermitian-matrices', 'matrices', 'block-matrices', 'determinant']"
411356,Who was the first to prove $\lim_{x \to 0} \frac{\sin{x}}{x}=1 $?,Who was the first to prove $\lim_{x \to 0}\frac{\sin{x}}{x}=1$?,"['math-history', 'calculus', 'real-analysis', 'limits']"
411362,Find $f^{(1001)}(0)$,"I am to find the value in 0 of 1001th derivative of the function $$f(x) = \frac{1}{2+3x^2}$$ How should I approach this kind of problem? I tried something like : $$\frac{1}{2+3x^2} = \frac{1}{2}\cdot\frac{1}{1-(-\frac{3}{2}x^2)}= \frac{1}{2}\sum_{n=0}^{\infty}\left(\frac{3x^2}{2}\right)^n$$ and compare whats next to $x^{1001}$ in this sum and in MacLaurin series but damn, we've got only even powers of x here. How should I do that?","['calculus', 'derivatives', 'taylor-expansion']"
411363,Dividing factorials is always integer,Is there a simple way to show that $$n!\over r!(n-r)!$$ is always an integer?,"['factorial', 'algebra-precalculus', 'binomial-coefficients']"
411380,Prove there is a unique continuous function satisfying this integral equation,"This is a question from an old real analysis qual: Prove that there is a unique continuous function $f:[0,1] \to \mathbb{R}$ such that $$f(x) = \cos x + \int_0^x f(y)e^{-y}dy$$
for $x \in [0,1]$ I haven't seen any problems like this before and I'm not really sure where to start.","['integral-equations', 'real-analysis']"
411398,"How to integrate $\int_{-\infty}^{+\infty} e^{-x^2}\cos x \, dx$ [duplicate]","This question already has answers here : Gaussian-like integral : $\int_0^{\infty} e^{-x^2} \cos( a x) \ \mathrm{d}x$ (7 answers) Closed 8 years ago . Can you help me with this? $$\int_{-\infty}^{+\infty} e^{-x^2}\cos x \, dx$$",['calculus']
411406,"Prove that if $s_n ≤ b$ for all but finitely many $n$, then $\lim s_n ≤ b$.","The question asks me to prove  that if $s_n ≤ b$ for all but finitely many $n$, then $\lim s_n ≤ b$ where $(s_n)$ be a sequence that converges.
. 
Here is how I did it but im not sure if its entirely correct. I used proof by contradiction. Suppose $\lim s_n>b$ and $s_n \leq b$ for all but finitely many $n$. Let $S=\lim s_n$. By definition we have for every $n>N$ which implies $|s_n-s|<\epsilon$. Let $\epsilon= b-2s+s_n$.
Now we get $s_n-s<\epsilon=b-2s+s_n$ which simplifies to $s<b=\lim s_n<b$ which is a contradiction.",['analysis']
411414,Surface integration over section of paraboloid below a plane,"Let S be the finite portion of the surface $z = 4x^2 + y^2$ cut off by the plane 
$z = 8x + 4y - 4$.
Evaluate the surface integral $(x, y, 3z)\,dS$ over the region $S$ where the normal to $S$ points upwards. I can do this using the divergence theorem, but I don't know what the limits would be for the surface integral. If I parametrise the surface as $r=(\frac{1}{2}r\cos t, r\sin t, r^2)$, then $0\leq t < 2\pi$. But if I substitute the parametrised coordinates into the plane equation then I get $r^2 \leq 4r\cos t + 4r\sin t - 4$. Is this right?",['multivariable-calculus']
411421,Example of something easier to count with $q$-analog?,"Are there any known examples of combinatorial objects that become easier to count by considering some kind of $q$-analog? It seems to me that it might be impossible for the problem of computing the $q$-analog directly to be (strictly) easier than enumerating the objects themselves, as we should be able to just replace $q$ everywhere with 1. However, I'd also be interested in any enumerative problems in which $q$-analogs give us some additional insight.","['q-analogs', 'combinatorics']"
411424,Why 7 points on a twisted cubic is enough to fix a quadratic?,"From Joe Harris, Algebraic Geometry, Page 10. Show that if seven points $p_{1},\cdots,p_{7}$ on a twisted cubic curve, then the common zero locus of the quadratic polynomials vanishing at the $p_{i}$ is the twisted cubic. I am looking for a hint to solve this problem (and the more general case of rational normal curves). I know $p_{i}$ must be in general position, such that any four of them span $\mathbb{P}^{3}$. But this alone does not give an answer immediately. Here is an argument based on Harris' argument on page 7. Consider $p_{1},p_{2},p_{3}$. It must span a hypersurface of dimension 2 in $\mathbb{P}^{3}$. And similarly is $p_{4},p_{5},p_{6}$. If $p_{7}$ lies on all quadratic polynomial passing through them, then $p_{7}$ has to lie on the intersection of two hypersurfaces - therefore must be lying on at least one hyperplane spanned by the above 2 sets. So we can write $p_{7}$ to be the linear combination of $p_{1},p_{2},p_{3}$ without loss of generality. But this contradicts the fact that they lying on general position (such that $p_{1},p_{2},p_{3},p_{7}$ span $\mathbb{P}^{7}$). So $p_{7}$ must not lie on all quadratic polynomials passing through them. Since we know every quadratic in $\mathbb{P}^{3}$ is determined by $4+6-1=9$ coefficients, two quadratics pass through the same 6 points should give us 3 dimension ""wiggle room"" left. But then I am lost as what to proceed.",['algebraic-geometry']
411432,Incomplete beta function in MATLAB,"Mathematica is capable of evaluating the incomplete beta function $$ \mathrm{Beta}[z,a,b] = \int_0^z u^{a-1}\left(1-u\right)^{b-1}\,du $$ even when the argument $z$ is negative.  MATLAB's function betainc(z,a,b) , however, only allows $z\in[0,1]$.  Do there exist any work-arounds for this (analytical tricks, or better MATLAB functions)?","['matlab', 'special-functions', 'integration']"
411434,An example of a space which fails to be compactly generated,"Does anyone know of an example of a topological space which is not compactly generated? I am using the definition in May's book ""A Concise Course in Algebraic Topology."" The definition is that a space $X$ is compactly generated if for any continuous map $g:K\to X$ from a compact Hausdorff space $K$, we have $g(K)$ is closed in $X$ (i.e. $X$ is ""weak Hausdorff"") and for any subset $A$ of $X$, $A$ is closed if an only if for any map $g:K\to X$, the preimage $g^{-1}(A)$ is closed in $K$ (i.e. $X$ is a ""$k$-space""). Of course, any compactly generated space is at least $T_1$, as compact Hausdorff spaces are $T_1$, so I am really interested in an example which has $T_1$-separation (or even better, one which is Hausdorff) but which fails to be a $k$-space.","['general-topology', 'examples-counterexamples']"
411442,Bounds on Young Tableau Element locations,"I'm having trouble finding some elementary results on the following. Let $Y$ be a standard Young Tableau of shape $\lambda=(\lambda_1,\lambda_2,\ldots,\lambda_n)$ with $N:=\sum_{i=1}^n\lambda_i$. My question is, for a given element $k$, what can be said about the location of $k$ in terms of bounds on its $(i,j)$ coordinates in the tableau?  For example, 1 must be at $(1,1)$, 2 can be at $(2,1)$ or $(1,2)$, 3 can be at $(2,1),(3,1),(1,2),(1,3)$ and so on. What I'm looking for is some crude statement of the form: $k$ lies in the region bounded by intervals $[(i_1,j_1),(i_1,j_1')],\ldots,[(i_n,j_n),(i_n,j_n')]$ where the intervals are defined between the two bracketed coordinates. References would be highly appreciated!","['representation-theory', 'young-tableaux', 'integer-partitions', 'reference-request', 'combinatorics']"
411447,$f: \mathbb{Z}\rightarrow\mathbb{Z}$ and $f(x)= x^2-1$. Is $f$ one-to-one? onto?,"Define $f: \mathbb{Z}\rightarrow\mathbb{Z}$ by $f(x)= x^2-1$. Then $f$ is a one to one function. I think it is false because if you put $3$, then $9-1=8$ which you can get it by $2\times 4$ and $1\times 8$. Could you tell me if I'm wrong or right? thanks sincerely","['discrete-mathematics', 'functions']"
411449,The relationship between fisher information and EM algorithm?,"I wonder what is the relationship between fisher information and EM algorithm?
When I read papers about EM algorithm, people sometimes discussed about fisher information, and there are algorithms which would combine fisher scoring method and EM algorithm together. However, I couldn't find materials clearly illustrate how fisher information is related to EM algorithm and what role it is playing ? Could anyone help me understand if there is any connection? Thanks.","['statistics', 'linear-algebra', 'optimization', 'algorithms']"
411450,Let A and B be $n \times n$ real matrices with same minimal polynomial.,"Let $A$ and $B$ be $n \times n$ real matrices with same minimal polynomial. Then (i) $A$ is similar to $B$. (ii) $A-B$ is singular. (iii) $A$ is diagonalizable if $B$ is so. (iv) $A$ and $B$ commute. I think only (iii) is the correct option, similar matrcies have same characteristics polynomial but the converse may not be true, $\begin{pmatrix}1&0\\0&0\end{pmatrix}\times \begin{pmatrix}0&1\\0&1\end{pmatrix}\ne \begin{pmatrix}0&1\\0&1\end{pmatrix}\times \begin{pmatrix}1&0\\0&0\end{pmatrix}$ though they have same minpoly $x(x-1)$ the same two matrices works as a counter example for (ii), am I right ?","['matrices', 'ring-theory', 'linear-algebra', 'abstract-algebra']"
411459,Ring homomorphisms $\mathbb{R} \to \mathbb{R}$.,"I got this question in a homework: Determine all ring homomorphisms from $\mathbb{R} \to \mathbb{R}$. Also prove that the only ring automorphism of $\mathbb{R}$ is the identity. I know that $\mathbb{R}$ is a field, so the only ideals are $\mathbb{R}$ and $\{0\}$. Therefore the homomorphisms must be the identity and the function $f(x)=0$ where $x \in \mathbb{R}$. But how do I prove these are the only two homomorphisms? Also, I was told to use the fact that $\mathbb{Q}$ is dense in $\mathbb{R}$, how can I use this hint?","['ring-theory', 'abstract-algebra']"
411467,Solving the 'easy' differential equation $(1 - \phi^2)\phi'' + \phi(\phi')^2 =0$.,I need to solve the following: $$(1 - \phi^2)\phi'' + \phi(\phi')^2 =0.$$ Is there any standard method I can use?,['ordinary-differential-equations']
411468,Finding the completion of a coordinate ring,"Consider $A=\mathbb C[x,y]/(y^2-x(x+1))$, and consider the $\mathfrak m$-adic completion, where $\mathfrak m =(x,y)$. I want to show that this completion is isomorphic to $\mathbb C[[u,v]]/(uv)$, where the double brackets denote a ring of formal power series. I think I've figured out the trick, but I'm unable to complete the argument. I believe the completion of $A$ is just $\mathbb C[[x,y]]/(y^2-x^2(x+1))$. The ""trick"" is to note that we can factor the generator of the ideal in the power series ring as $(y-x\sqrt{x+1})(y+x\sqrt{x+1})$, because we can expand the square roots into power series. Consider the map $\mathbb C[[u,v]]\rightarrow \mathbb C[[x,y]]$ with $$\phi(u)=y+x\sqrt{x+1}$$ $$\phi(v)=y-x\sqrt{x+1}.$$ If we can show this is surjective, we can compose it with the quotient map to $\mathbb C[[x,y]]/(y^2-x^2(x+1))$. If we then show the kernel is $(uv)$, we are done by the standard ring isomorphism theorem. So my two questions are: How do we show surjectivity? And how do we compute the kernel after we compose with the quotient map? Instead of computing the kernel, we could note the map descends to a map on $\mathbb C[[u,v]]/(uv)$ to $\mathbb C[[x,y]]/(y^2-x^2(x+1))$ and show this is injective (possibly by finding an inverse?), but I don't see how to do this. For surjectivity, we just need to show that $y$ and $x$ are in the image. We can get $y$ by $(u+v)/2$, but getting $x$ is going to require a power series that I don't see how to compute. I realize this has some geometric interpretation, but I'm looking for purely algebraic and elementary answers, as I'm new to this material. Thanks.","['commutative-algebra', 'ring-theory', 'algebraic-geometry', 'elliptic-curves']"
411477,A new constant?,"I was experimenting in Wolfram Alpha the answer to the equation $\int_0^k x^x dx=1$ And I got about 1.19... But, What is this number k (and could you calculate it to more decimal places?) And is it constructed out of $\pi$ , $e$ , $\gamma$ , etc, or is it a whole new number?","['integration', 'constants']"
411485,Prove by induction that $1^3 + 2^3 + 3^3 + .....+ n^3= \frac{n^2(n+1)^2}{4}$ for all $n\geq1$. [duplicate],"This question already has answers here : Proving $1^3+ 2^3 + \cdots + n^3 = \left(\frac{n(n+1)}{2}\right)^2$ using induction (16 answers) Closed 10 years ago . Use mathematical induction to prove that $1^3 + 2^3 + 3^3 + .....+ n^3= \frac{n^2(n+1)^2}{4}$ for all $n\geq1$. Can anyone explain? Because I have no clue where to begin. I mean, I can show that $1^3+ 2^3 +...+ (k+1)^3=\frac{(k+1)^2(k+2)^2}{4}$, but then I don't know where to go. I need further explanation to prove it. thank you so much for help Sincerely","['induction', 'summation', 'discrete-mathematics']"
411486,Understanding the singular value decomposition (SVD),"Please, would someone be so kind and explain what exactly happens when Singular Value Decomposition is applied on a matrix? What are singular values, left singular, and right singular vectors? I know they are matrices of specific form, I know how to calculate it but I cannot understand their meaning. I have recently been sort of catching up with Linear Algebra and matrix operations. I came across some techniques of matrix decomposition, particularly Singular Value Decomposition and I must admit I am having problem to understand the meaning of SVD. I read a bit about eigenvalues and eigenvectors only because I was interested in PCA and I came across diagonalizing a covariance matrix which determines its eigenvectors and eigenvalues (to be variances) towards those eigenvectors. I finally understood it but SVD gives me really hard time. thanks","['matrix-decomposition', 'matrices', 'linear-algebra', 'svd']"
411492,Inverse of a block matrix with singular diagonal blocks,"I have a special case where $$X=\left(\begin{array}{cc}
A & B\\
C & 0
\end{array}\right)$$ and: $X$ is non-singular $A \in \Bbb R^{n \times n}$ is singular $B \in \Bbb R^{n \times m}$ is full column rank $C\in \Bbb R^{m \times n}$ is full row rank $D \ = 0_{m\times m}$ How do you calculate $X^{-1}$ in this case? For example, $$X=\begin{pmatrix}0&1\\1&0\end{pmatrix}$$","['matrices', 'linear-algebra', 'inverse', 'block-matrices']"
411534,Prove $T$ has at most two distinct eigenvalues,"The question is from Axler's Linear Algebra text. The $\mathcal{L}(V)$ stands for the space of linear operators on the vector space $V$. Suppose that V is a complex vector space with dim $V=n$ and $T \in \mathcal{L}(V)$ is such that
    $$\text{null} \ T^{n-2} \neq \text{null} \ T^{n-1} 
$$
    Prove that $T$ has at most two distinct eigenvalues. I fist thought of solving this by contradiction. That is, I thought, suppose there were three distinct eigenvalues. Then, there would be an equation like 
$$(x-\lambda_1I)^{d_1}(x-\lambda_2I)^{d_2}(x-\lambda_3I)^{d_3}
$$
where the $d_i$'s are positive integers that sum to dim $V$. Call this polynomial $q(x)$ the characteristic poly. Thus, by Cayley's theorem,
$$q(T)=(T-\lambda_1I)^{d_1}(T-\lambda_2I)^{d_2}(T-\lambda_3I)^{d_3}=0
$$
Then multiplying out and setting dim $V = d_1+d_2+d_3 = n$, I could then get a poly with the various powers of $T$ (this is a little tricky to write down). In particular, I wanted to see the powers $n-2$ and $n-1$. I thought, ok, so now, rewrite the poly in terms of each of these and using the fact that $\text{null} \ T^{n-2} \neq \text{null} \ T^{n-1}$ you get some vector $v \in V$ such that,
$$T^{n-1}v = (\text{poly}_1)v = 0
$$ 
but 
$$T^{n-2}v = (\text{poly}_2)v = k \neq 0
$$
I can think of some interesting things about $(\text{poly})_1$ and $(\text{poly})_2$, in particular, each has the monic term $T^n$. At this point, I'm not sure any of this helped. Well, anyways, I'm sure someone has a much better approach! Thanks in advance to anyone who read this.","['vector-spaces', 'linear-algebra', 'eigenvalues-eigenvectors']"
411536,Ramification group fixing an unramified extension,"For a Galois extension of local fields $L/K$ with Galois group $G$, define the ramification groups $G_i$ by $$G_i = \{ \sigma \in G : \nu_{L}(\sigma(x) - x) \geq i+1 \text{ } \forall x \in \mathcal{O}_L\}.$$  Here $\nu_{L}$ is the valuation on $L$ such that $\nu_L(\pi_L) = 1$, where $\pi_L$ is a uniformizer of $L$. We would like to show that $G_0$ is the subgroup of $G$ fixing $K^{ur}$, where $K^{ur}$ is the maximal unramified extension of $K$ contained in $L$. Here is what we have so far. We know that $\mathcal{O}_L$ = $\mathcal{O}_{K^{ur}}[\pi_L]$. Furthermore,  elements in $\mathcal{O}_{K^{ur}}$ look like $$\sum_{i \geq 0} a_i \pi_{K^{ur}}^i,$$ where the $a_i$ are units in $\mathcal{O}_{K^{ur}}$. Since $K^{ur}/K$ is unramified, then $\pi_{K^{ur}} = u \cdot \pi_{K}$ for some unit $u$ in $\mathcal{O}_{K^{ur}}$. If we knew that elements in $G_0$ fixed the units in $K^{ur}$, then we could conclude that elements in $G_0$ fixed all sums of the above form in $O_{k^{ur}}$. Any tips or a full solution would be greatly appreciated. We are just beginning to learn about local fields and are having trouble filling in the details for many of the statements offered without detailed justification, such as this one, in  the notes we are reading.","['p-adic-number-theory', 'ring-theory', 'abstract-algebra', 'galois-theory', 'field-theory']"
411545,Eigenvalues of a block matrix,"For $X=\left(\begin{array}{cc} A & B\\ C & 0\end{array}\right)$ , how are eigenvalues of $X$ related to the eigenvalues of $A$ ?","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors', 'block-matrices']"
411562,Exercise of series in a Banach Space,"A vector basis of a vector space $E$ is a family $(a_{\lambda})_{\lambda\in L}$ such that any element of $E$ can be written in a unique way as a linear combination of a finite number of $a_{\lambda}$, this implies in particular that the $a_\lambda$ are linearly independent. Let $(a_n)$ be a sequence of linearly independent elements in a Banach space $E$. Define 
inductively a sequence $(t_n)$ of positive real numbers in the following way: if $d_n$ is the distance of the point $t_n a_n$ to the subspace $V_{n-1}$ generated by $a_1,...., a_{n-1}$ (note that $d_n>0$), take $t_{n+1}$ such that $|t_{n+1}|\cdot ||a_{n+1}|| < \frac{d_{n}}{3}$. Show that the series $\displaystyle{\sum_{n=1}^{\infty}t_n a_n}$ is absolutely convergent, and that its sum $x$ does not belong to any of the subspaces $V_n$.","['normed-spaces', 'functional-analysis', 'banach-spaces']"
411581,Can a sequence of a function with a single variable be thought about as a function with two variables?,"Long title, but first off is it logically ok to think of $\{f_n(x)\}$ as $f(n,x)$ where $n$ is restricted to a natural number? Second, would this at all be useful? Thus far in my study of sequences of functions you deal strictly with convergence (similar to sequences in general) - either pointwise or universal convergence. It seems interesting to me because then we can consider some function of two variables as converging to a function with one. It seems as though this would be useful... So it's as if we could have the definition of convergence be: $$
\forall \; \epsilon > 0 \\
\exists \; N \in \mathbb{N} : \lvert f(n,x) - f(x) \rvert < \epsilon
$$ and then could this possibly be extrapolated out to an $n$ with any domain one wishes? EDIT: as Andre reminded me, sequences can be thought of as functions, i.e. $$
a : \mathbb{N} \to \mathbb{R}
$$ however it seems to be then that this becomes the concatenation of functions, i.e. $$
g : \mathbb{R} \to \mathbb{R}\quad
f : \{ \mathbb{R} , \mathbb{N} \} \to \mathbb{R}
$$ and $f_n (x) = f(g(x),n)$ again, would this be an ok way of thinking about sequences of functions, is it useful, and could this be extrapolated so that we can view any $n$ variable function as the concatenation of $n$ functions, and the variables dont need to have any specific domain?","['functions', 'sequences-and-series', 'real-analysis', 'analysis']"
411587,Does this integral have a closed form: $\int_0^1 \frac{x^{\beta-1}}{1-x}\log\frac{1-y x^\delta}{1-y}\mathrm dx$?,"Consider the following integral:
$$G(\beta,\delta,y) = \int_0^1 \frac{x^{\beta-1}}{1-x}\log\frac{1-y x^\delta}{1-y}\mathrm dx,$$
with $\delta>0$, $\Re\beta>0$, $y\neq1$. Does it have a closed form in terms of standard special functions? If not, what is its asymptotic behaviour near the point $y=1$? Is there a closed-form expansion of the type
$$ G(\beta,\delta,y) = \frac{G_0(\beta,\delta)}{1-y} + G_1(\beta,\delta) + o(1), \qquad (y\to1-)$$
or something like it? Is there a closed form if $\frac{1}{\delta}$ is a positive integer? Does anything useful happen if $y$ is a root of unity? Context. I encountered this integral while trying to answer this question and also this question , but could not reduce the integral to a simpler form, except for the very specific values of $\beta=\frac14$ and $\delta=\frac14$. When $\delta=\frac14$, a substitution $x=y^4$ leads to an integral with logarithmic terms and the fraction $\frac{1}{1-y^4}$ that can be expanded in partial fractions, and the individual terms can be integrated rather more easily, so $G(\frac14,\frac14,y)$ can be expressed in terms of logs and polylogs. Numerically, I find the singular behaviour to be $\propto(\log(1-y))^2$.","['special-functions', 'sequences-and-series', 'integration', 'definite-integrals']"
411590,Can a tetrahedron lying completely inside another tetrahedron have a larger sum of edge lengths?,Find 2 tetrahedrons $ABCD$ and $EFGH$ such that $EFGH$ lies completely inside $ABCD$. The sum of edge lengths of $EFGH$ is strictly greater than the sum of edge lengths of $ABCD$. I am completely stumped on this. Seems very counter intuitive to begin. I now have doubts if a solution exists or not. Source : Here,"['geometry', 'puzzle', 'polyhedra', 'euclidean-geometry']"
411592,How to calculate this area?,"Calculate the area of $$S:=\lbrace (x,y,z)\in\mathbb{R}^3: y^2+(z-x^2)^2=x^2-1\rbrace$$ Anyone have an idea? I tried using cylindrical coordinates, but nothing. Well, I have something, but I'm not really sure... Ok: We have the surface $$y^2+(z-x^2)^2=x^2-1 \Rightarrow (z-x^2)^2=x^2-1-y^2$$ 
$$\Rightarrow z-x^2=\sqrt{x^2-1-y^2} \Rightarrow z(x,y) =  \sqrt{x^2-1-y^2}+x^2$$ Now we put some reestriction on z. We have two cases: $$S^{-} = \lbrace C \cap \lbrace z<x^2\rbrace \rbrace$$
$$S^{+} = \lbrace C \cap \lbrace z>x^2\rbrace \rbrace$$ Let's work on $S^{+}$. Using the polar parametrization $x=rcos(\theta)$ e $y=rsin(\theta)$ we have: $$z(\theta, r) = \sqrt{r^2cos(2\theta)-1}+r^2cos^2 (\theta)$$
Where we have 2 restrictions: $r>1$ and $r^2cos(\theta)>1$ (looking the root). So we can calculate the integration limits. And we have the vector: $$\gamma(\theta, r) = (rcos(\theta), rsin(\theta), z(\theta, t))$$
So we only need use the area equation $$\int \int \left| \frac{\partial\gamma}{\partial \theta}\times \frac{\partial\gamma}{\partial r}\right|d\theta dr$$",['multivariable-calculus']
411593,"Solve $2\tan (x)\cos (x)=\tan (x)$, algebraically where $0 \leq x < 2\pi$","please help me correct if anything is wrong.. or even if i'am right Solve $\quad 2\tan x\cos x=\tan x,$ algebraically where $0≤x<2π$ $$2\tan(x) \cos (x) - \tan (x) = 0$$ $$\tan (x)(2\cos (x) - 1) = 0$$ $$\text{So, either}\;\;\tan (x) = 0 \Longrightarrow x \in \{0, π,  2π\} $$ $$\text{Or}\;\;2\cos(x)-1 = 0, \cos (x) = 1/2 \implies x \in \{-π/3, π/3\}$$ $$\text{Solutions}\;\;: x \in \{0, \pi/3, -\pi/3, \pi, 2\pi\}$$ 2) Solve $2\sin^2(x)-\sin(x)-1=0$ where $0≤x<2π$ $$2\sin^2(x)-\sin(x)-1=0$$ $$\iff(2\sin(x)+1)(\sin(x)-1) = 0$$ Thus, either $\;2\sin(x) +1 = 0 \iff \sin x = -1/2 \implies x = -π/6, x = 7π/6$ or $\;\sin(x)-1 = 0 \iff \sin x = 1 \implies  x = π/2$ $$\text{Solutions}\;\;x\in \{-π/6,  π/2, 7π/6\}$$","['trigonometry', 'calculus']"
411600,Toric Varieties: gluing of affine varieties (blow-up example),"Let $\Delta$ be a fan, consisting of cones $\sigma_0=conv(e_1,e_1+e_2)$ and $\sigma_2=conv(e_1+e_2,e_2)$ and $\tau=\sigma_0\cap\sigma_1=conv(e_1+e_2)$. The dual cones are $\sigma_0^\vee= conv(e_2,e_1\!-\!e_2)$ and $\sigma_1^\vee= conv(e_2\!-\!e_1,e_1)$ and $\tau^\vee= conv(e_2\!-\!e_1,e_1\!-\!e_2,e_1,e_2)= conv(e_2\!-\!e_1,e_1\!-\!e_2,e_1)= conv(e_2\!-\!e_1,e_1\!-\!e_2,e_2)$. The corresponding semigroup algebras are $S_{\sigma_0}= \mathbb{C}[\mathbf{x}^{e_2},\mathbf{x}^{e_1\!-\!e_2}] =\mathbb{C}[y,xy^{-1}]$ and $S_{\sigma_1}= \mathbb{C}[\mathbf{x}^{e_2\!-\!e_1},\mathbf{x}^{e_1}]= \mathbb{C}[x^{-1}y,x]$ and $S_\tau= \mathbb{C}[\mathbf{x}^{e_2\!-\!e_1}, \mathbf{x}^{e_1\!-\!e_2}, \mathbf{x}^{e_1},\mathbf{x}^{e_2}]$ $=$ $\mathbb{C}[x^{-1}y,y^{-1}x,x,y]$ $=$ $\mathbb{C}[x^{-1}y,y^{-1}x,x]= \mathbb{C}[x^{-1}y,y^{-1}x,y]$ inside $\mathbb{C}[x^{\pm1},y^{\pm1}]$. The three associated affine schemes $U_{\sigma_0}, U_{\sigma_1}, U_\tau$ are their spectrums. The homomorphism of $\mathbb{C}$-algebras $\beta_0\!: \mathbb{C}[X,Y]\rightarrow\mathbb{C}[x/y,y]$ that sends $X\!\mapsto\!x/y,Y\!\mapsto\!y$ is an isomorphism. The homomorphism of $\mathbb{C}$-algebras $\beta_1\!: \mathbb{C}[X,Y]\rightarrow\mathbb{C}[x,y/x]$ that sends $X\!\mapsto\!x,Y\!\mapsto\!y/x$ is an isomorphism. Thus $U_{\sigma_0}\!=\!\mathbb{C}^2\!=\!U_{\sigma_1}$ via $\overset{\beta_0^\ast}{\longleftarrow}\!\ldots\!\overset{\beta_1^\ast}{\longrightarrow}$. Furthermore, $\mathbb{C}[X,x]_X\!=\!\mathbb{C}[X,x,X^{-1}]\!\cong\!\mathbb{C}[x/y,x,y/x] \!=\! \mathbb{C}[x/y,y,y/x]\!\cong\!\mathbb{C}[Y^{-1}\!,y,Y]\!=\!\mathbb{C}[y,Y]_Y$, so $\mathbb{C}^\ast\!\!\times\!\mathbb{C} \!=\!U_\tau\!=\! \mathbb{C}\!\times\!\mathbb{C}^\ast$ and $X\!=\!Y^{-1}$. We have inclusions $\sigma_0\!\hookleftarrow\!\tau\!\hookrightarrow\!\sigma_1$, hence inclusions $\sigma_0^\vee\!\hookrightarrow\!\tau^\vee\!\hookleftarrow\!\sigma_1^\vee$, thus morphisms $\mathbb{C}[\sigma_0^\vee]\!\overset{\iota_0}{\hookrightarrow}\!\mathbb{C}[\tau^\vee]\!\overset{\iota_1}{\hookleftarrow}\!\mathbb{C}[\sigma_1^\vee]$, hence morphisms $Spec\,\mathbb{C}[\sigma_0^\vee]\!\overset{\iota_0^\ast}{\leftarrow}\!Spec\,\mathbb{C}[\tau^\vee]\!\overset{\iota_1^\ast}{\rightarrow}\!Spec\,\mathbb{C}[\sigma_1^\vee]$. Our morphisms $\mathbb{C}[x/y,y]\!\overset{\iota_0}{\hookrightarrow}\!\mathbb{C}[x/y,x,y/x]\!=\!\mathbb{C}[x/y,y,y/x]\!\overset{\iota_1}{\hookleftarrow}\!\mathbb{C}[x,y/x]$ send $(x/y,y)\!\rightarrow\!(x/y,y\!=\!x\frac{y}{x})$ and $(y\frac{x}{y}\!=\!x,y/x)\!\leftarrow\!(x,y/x)$, i.e. morphisms $\mathbb{C}[X,Y]\!\overset{\iota_0}{\hookrightarrow}\!\mathbb{C}[X,x,X^{-1}]\!=\!\mathbb{C}[Y^{-1},y,Y]\!\overset{\iota_1}{\hookleftarrow}\!\mathbb{C}[X,Y]$ send $(X,Y)\!\rightarrow\!(X,x/X)$ and $(y/Y,Y)\!\leftarrow\!(X,Y)$. On ideals, they map $\langle X\!-\!u,Y\!-\!v\rangle \!\overset{\iota_0}{\rightarrow}\! \langle X\!-\!u,x/X\!-\!v\rangle \!=\! \langle X\!-\!u,x\!-\!vX\rangle$ and $\langle y\!-\!uY,Y\!-\!v\rangle \!=\! \langle y/Y\!-\!u,Y\!-\!v\rangle\!\overset{\iota_0}{\leftarrow}\!\langle X\!-\!u,Y\!-\!v\rangle$, so preimage morphisms $\mathbb{C}^2\!\overset{\iota_0^\ast}{\leftarrow}\!\mathbb{C}^\ast\!\!\times\!\mathbb{C}\!=\!\mathbb{C}\!\times\!\mathbb{C}^\ast\!\overset{\iota_1^\ast}{\rightarrow}\!\mathbb{C}^2$ send $\langle X\!-\!u,Y\!-\!???\rangle\!\leftarrow\!\langle X\!-\!u,x\!-\!v\rangle$ and $\langle y\!-\!u,Y\!-\!v\rangle\!\rightarrow\!\langle X\!-\!???,Y\!-\!v\rangle$, i.e. $(u,???)\!\leftarrow\!(u,v)$ and $(u,v)\!\rightarrow\!(???,v)$. Question 1: Is everything so far correct? Question 2: The usual identification is that $Max\,\mathbb{C}[x,y]=\{\langle x\!-\!u,y\!-\!v\rangle;\, u,v\!\in\!\mathbb{C}\}\equiv\mathbb{C}^2$. However, in the literature, $Spec\,\mathbb{C}[x,y]$ is identified with $\mathbb{C}^2$ (I'm not sure this is the right thing to do). I would like to glue together $U_{\sigma_0}$ and $U_{\sigma_1}$ via $U_\tau$ to obtain a scheme. How can I obtain a gluing isomorphism? The problem is that for $\iota_0,\iota_1$, the preimage of a maximal ideal is not a maximal ideal. How does this gluing morphism map points $\mathbb{C}^\ast\!\!\times\!\mathbb{C}\rightarrow\mathbb{C}\!\times\!\mathbb{C}^\ast$? I'd like to see that is sends $(u,v)\mapsto(uv,u^{-1})$. Are we gluing two copies of $\mathbb{C}^2$ along $\mathbb{C}\!\times\!\mathbb{C}^\ast$ or along $\mathbb{C}^\ast\!\times\!\mathbb{C}^\ast$? How are $\mathbb{C}^\ast\!\!\times\!\mathbb{C}$ and $\mathbb{C}\!\times\!\mathbb{C}^\ast$ via $\iota_0^\ast$ and $\iota_1^\ast$ embedded in $\mathbb{C}^2$?","['toric-geometry', 'algebraic-geometry', 'schemes', 'abstract-algebra', 'simplicial-stuff']"
411601,Green's theorem and flux,"Given the vector field $\vec{F}(x,y) = (x^2+y^2)^{-1}\begin{bmatrix} x \\ y \end{bmatrix}$, calculate the flux of $\vec{F}$ across the circle $C$ of radius $a$ centered at the origin (with positive orientation). It is my understanding that Green's theorem for flux and divergence says
$$
\int\limits_C \Phi_{\vec{F}} = \int\limits_C P\,dy - Q\,dx = \iint\limits_R\nabla\cdot\vec{F}\,dA
$$
if $\vec{F} = \begin{bmatrix} P & Q \end{bmatrix}$ (omitting other hypotheses of course). Note that $R$ is the region bounded by the curve $C$. For our $\vec{F}$, we have $\nabla\cdot\vec{F} = 0$. So shouldn't the flux of $\vec{F}$ through $C$ be zero? Everytime I try to compute it, I obtain zero. However, it appears that I am supposed to be getting $2\pi$. Can someone help me to understand where I am going wrong?",['multivariable-calculus']
411610,Subspace topology and discrete space,Does there exist $A \subseteq \mathbb{R}^{2}$ with usual topology and $A$ not enumerable such that $\tau_{A}$ the subspace topology in $A$ it is a discrete space?,['general-topology']
411612,Compute $\int_{0}^{1}\left[\frac{2}{x}\right]-2\left[\frac{1}{x}\right]dx$,"The question is to find $$\int_{0}^{1}\left(\left[\dfrac{2}{x}\right]-2\left[\dfrac{1}{x}\right]\right)dx,$$ where $[x]$ is the largest integer no greater than $x$ , such as $[2.1]=2, \;[2.7]=2,\; [-0.1]=-1.$ Is there any nice method to solve this integral,Thank you everyone. Some of my thoughts: I have if $a\in(0,1]$ , then $$\int_{0}^{1}\left[\dfrac{a}{x}\right]-a\left[\dfrac{1}{x}\right]dx=a\ln{a}.$$ What about $a>1$ , $$\int_{0}^{1}\left[\dfrac{a}{x}\right]-a\left[\dfrac{1}{x}\right]dx=?$$ and $$\int_{0}^{1}\left(\left[\dfrac{2}{x}\right]-2\left[\dfrac{1}{x}\right]\right)^{2}dx=?$$ becasue I have $$\int_{0}^{1}\left(\dfrac{1}{x}-\left[\dfrac{1}{x}\right]\right)^2=-1-\gamma+\ln{(2\pi)}$$",['integration']
411620,least squares: verify simple derivative,"What is the derivative of $||Y-X\beta||_2$ w.r.t $X$? I have $(Y-X\beta)^T(Y-X \beta) = Y^TY-Y^TX \beta-\beta^TX^TY+\beta^TX^TX\beta$ which gives the derivative as $-Y\beta^T -Y\beta^T +2X\beta\beta^T$ Is this correct? If not, what is the correct result?","['multivariable-calculus', 'calculus', 'matrices', 'partial-derivative', 'derivatives']"
411626,"Is a real number the limit of a Cauchy sequence, the sequence itself, a shrinking closed interval of rational numbers, or what?","I've been studying a collection of analysis books (one of them Bishop's Constructive version) and contemplating the reals. Correct me if I'm wrong, but I feel that I have seen the Cauchy sequence itself in some places and its limit in other places described as the real number. I do understand that nested closed intervals have a point as the limit of their countably infinite intersection. I can visualize an arbitrarily small interval of rationals, any of which has an equal claim (its seem to me, at least until other considerations are brought in) to being an ""approximation"" of this point. Unless we know the limit point (via the geometric series, for instance), what are we approximating if not a yet better approximation of a yet better approximation? (Maybe the ""approximation"" terminology works better for cuts.) I suppose I'm asking not only for the clarification of the dominant convention but also for ""real talk"" about the mathematical imagining of real numbers.",['real-analysis']
411631,derivative of exponential of matrix trace,"What is the derivative of $\sum_{ij}e^{-d_{ij}^2(X)}=\sum_{ij}e^{-\operatorname{tr}(X^TC_{ij}X)}$, w.r.t $X$ where $C_{ij}$ is a constant matrix and $d_{ij}^2(X)$ denotes the squared Euclidean distance between the rows $i,j$ of $X$. All the entries here are real","['multivariable-calculus', 'calculus', 'real-analysis', 'analysis', 'derivatives']"
411650,Extending and inducing irreducible representations,"I sense this may be a simple question, but it is one I haven't been able to find an answer for, possibly due to the use of different terminology. Referring to this question: Faithful irreducible representations of cyclic and dihedral groups over finite fields What exactly does it mean to extend a representation? Secondly, how do you induce representations from representations of degree greater than one? (I've only seen this done for the one dimensional case). To make things simple, let's consider the representations of $D_8$ (the symmetries of a square, the order of which is 8) over $\mathbb{F}_7$. We have a normal subgroup generated by $z=(1 2 3 4)$ which is isomorphic to $C_4$ which has an irreducible representation of degree two over $\mathbb{F}_7$ that takes $z$ to the matrix \begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} According to the answer to the linked question, this representation somehow extends to $D_8$. How? Also, how would you show it inducing a representation of degree 4? Please let me know if anything I've said above is incorrect and thank you in advance for your help.","['finite-fields', 'finite-groups', 'group-theory', 'representation-theory']"
411658,Is there a contradiction is this exercise?,"The following exercise was a resolution to this problem Let $\displaystyle\frac{2x+5}{(x-3)(x-7)}=\frac{A}{(x-7)}+\frac{B}{(x-3)}\space  \forall \space x \in \mathbb{R}$. Find the values for $A$ and $B$ The propose resolution was: In order to isolate $A$ on the right side, multiply all the equation by $x-7$ $\displaystyle\frac{(2x+5)(x-7)}{(x-3)(x-7)}=\frac{A(x-7)}{(x-7)}+\frac{B(x-7)}{(x-3)}$ Now is my doubt. The resolution suggests that $x-7$ cancel out. $\displaystyle\frac{(2x+5)}{(x-3)}=A+\frac{B(x-7)}{(x-3)}$ But, $x-7$ can be equal zero. In this situation, is allowed to perform this operation? One can say ""for every $x\neq7$"", but on the next step the resolution says ""for $x=7$ we have"". $\displaystyle\frac{(14+5)}{(7-3)}=A+\frac{B(0)}{(7-3)} \Leftrightarrow A=\frac{19}{4}$ I think there is a contradiction is this resolution.",['algebra-precalculus']
411667,Solving elementary row operations,"So I am faced with the following:
$$
\begin{align}
x_1 + 4x_2 - 2x_3 +8x_4 &=12\\
x_2 - 7x_3 +2x_4 &=-4\\
5x_3 -x_4 &=7\\
x_3 +3x_4 &=-5
\end{align}$$ How should I approach this problem? In other words, what is the next elementary row operation that I should attempt in order to solve it? I know how to do with 3 equations by using the augmented method but this got me a little confused.","['matrices', 'linear-algebra']"
411668,Is there a (real) number which gives a rational number both when multiplied by $\pi$ and when multiplied by $e$?,"Besides $0$ of course. What about addition and exponentiation? I would think there's no such number, but I'm not sure if I could prove it.","['irrational-numbers', 'number-theory']"
411676,Limit with roots,"I have to evaluate the following limit: $$ \lim_{x\to 1}\dfrac{\sqrt{x+1}+\sqrt{x^2-1}-\sqrt{x^3+1}}{\sqrt{x-1}+\sqrt{x^2+1}-\sqrt{x^4+1}} . $$ I rationalized both the numerator and the denominator two times, and still got nowhere. Also I tried change of variable and it didn't work. Any help is grateful. Thanks.",['calculus']
411690,rectangularizing the square,"There is a square that I want to divide to n people, such that each person gets a rectangular piece with an equal area. An obvious option is to cut 1-by-n rectangles of size n-by-1, but the people don't want such rectangles, they say they are too skinny. They want to get R-balanced rectangles , which are defined as axis-aligned rectangles whose width-height ratio is between $R$ and $1/R$ (where $R \geq 1$ ). What is the minimum R for which I can guarantee that, for every n, there is a division of a square to n equal-area R-balanced rectangles? Some notes and sub-questions: A 1-balanced rectangle is just a square. So, for $R=1$ , a division is possible only when n is a square number. For $R=2$ , I managed to find a division for $n=1, 2, 4, 5, 6, 7, 8, 9$ , but I haven't found a division for $n=3$ , and also haven't managed to prove that it is impossible. What do you think? What are all the numbers $n$ for which there is a division of a square into $n$ 2-balanced rectangles? Obviously all square and double-square numbers are included, but there are other numbers, such as 5, 6 and 7. For $R=3$ , I haven't found a counter-example, but also couldn't prove that for every n it is possible to find a division to 3-balanced rectangle. What do you think? (Note that Erich's packing center contains a nice summary of packing rectangles in a square, but it is limited to identical rectangles. I allow different rectangles, as long as they are the same area, and with an R-balanced width-height ratio).","['geometry', 'rectangles', 'packing-problem']"
411696,How find the $\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}(-1)^{m+n}\frac{1}{n(m+2n)}$,"find the value
$$\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}(-1)^{m+n}\dfrac{1}{n(m+2n)}$$ I think this is good problem,Thank you everyone I find 
$$\int_{0}^{1}\dfrac{\ln{(1+x^2)}}{1+x}dx=\sum_{n=1}^{\infty}\sum_{m=1}^{\infty}(-1)^{m+n}\dfrac{1}{n(m+2n)}$$","['summation', 'sequences-and-series']"
411709,Proving that the medians of a triangle are concurrent,"I was wondering how to prove Euclid's theorem: The medians of a triangle are concurrent. My work so far: First of all my interpretation of the theorem is that if a line segment is drawn from each of the 3 side's medians to the vertex opposite to it, they intersect at one point. Since a triangle has three sides and each side must have a median, I figure that at least 2 of them have to intersect as the lines can't be parallel. May anyone explain further? Thank you!",['geometry']
411716,Degree of splitting field extensions,"The problem states: Let $f (x) = x^3+px+q$ be an irreducible cubic polynomial with rational coefficients
  and let $K$ be the splitting field of $ f(x) $ over $\mathbb{Q}$. Prove that $ [K : \mathbb{Q}] = 3 $ if and only if $ -4p^3 - 27q^2 $ is a square in $\mathbb{Q}$. Here is how far I've come on the problem. Since $f$ is cubic and the degree of the extension is $3$, then non of the roots are in $\mathbb{Q}$ hence they are in $K$. Now, I am having trouble connecting this piece of information with the given value being a square in $\mathbb{Q}$. Thanks in advance.","['galois-theory', 'abstract-algebra', 'field-theory']"
411723,Surface area of a sphere patch cut out by a regular tetrahedron,"Description: consider a regular tetrahedron (with height 1), construct a sphere centering at one of the tetrahedron's vertex, with radius 1 also. Then what's the surface area of the sphere's portion that gets cut out by the tetrahedron? Following are links to some illustrations I made using Mathematica. $\hskip 1.3in$ $$\text{a side view}$$ $\hskip 1.3in$ $$\text{a bottom view: you are viewing the unknown area directly}$$",['geometry']
411732,Differentiation of $\operatorname{tr}(A^TB)$ if $A$ is symmetric,"May be an easy question but I am quite confused. Differentiation of $\operatorname{tr}(A^TB)$ with respect to $A$ is $B$ and $\operatorname{tr}(AB)$ is $B^T$. What if $A^T = A$, that is $A$ symmetric, is the differentiation $B$ or $B^T$?",['multivariable-calculus']
411735,What can we say about a locally compact Hausdorff space whose every open subset is sigma compact?,What can we say about a locally compact Hausdorff space whose every open subset is sigma compact? Can we say that it is metrizable or second countable? thanks,"['general-topology', 'compactness']"
411755,This tower of fields is being ridiculous,"Suppose $K\subseteq F\subseteq L$ as fields. Then it is a fact that $[L:K]=[L:F][F:K]$. No other hypotheses are needed (I'm looking at you, Hungerford V.1.2). Now obviously $[\mathbf{C}:\mathbf{R}]=2$. But consider the fact that the algebraic closure of $\mathbf{R}(t)$ has cardinality $2^{\aleph_0}$---this implies that $\overline{\mathbf{R}(t)}\cong\mathbf{C}$, so in particular we can embed $\mathbf{R}(t)$ into $\mathbf{C}$. If we embed $\mathbf{R}$ into $\mathbf{R}(t)$ in the natural way, we get
$$\mathbf{R}\subset\mathbf{R}(t)\subset\mathbf{C}.$$ So our good fact at the beginning would have us believe $$2=[\mathbf{C}:\mathbf{R}(t)][\mathbf{R}(t):\mathbf{R}].$$ What is the meaning of this? Either these two degrees really are both finite or (more likely) I've made a huge mistake. Perhaps it would all be clear if I were more precise about ""embedding"" $\mathbf{R}(t)$ in $\mathbf{C}$.","['fake-proofs', 'extension-field', 'abstract-algebra', 'field-theory']"
411783,How does this strange phenomena happen in quotient of groups ?,"in my question , here , i learned a strange fact from the comments which was a surprise for me on the answer of landsacpe  ! and this surprise it : if $G$ is a group , $H$ and $K$ are two normal subgroups of $G$ such that  $H$ is isomorphic to K then 
it is NOT necessary true that $G/H$ is isomorphic to $G/K$ . i always thought that two isomorphic groups have the same algebraic structure and so we can deal with them as the same things , we can use them respectively in fact ! but an example from the member Landscape broke down this thought so , why does this happens in quotients groups ? why two groups have the same isomorophism type leads to different  groups under quotients ? also , in which case , two isomorophism groups may leads to different things ? and in which case there is no matter to deal with them as the same thing ? till the moment , i think this phenomena may happens ONLY on infinite groups not finite groups "" it may not happen also in infinite generated groups i think ! "" any clarification plz ?","['finite-groups', 'group-theory', 'abstract-algebra']"
411813,Jordan form and an invertible $P$ for $A =\left( \begin{smallmatrix} 1&1&1 \\ 0 & 2 & 2 \\ 0 & 0 & 2 \end{smallmatrix}\right)$,"$A = \begin{pmatrix} 1&1&1 \\ 0 & 2 & 2 \\ 0 & 0 & 2 \end{pmatrix}$, find the jordan form and the invertible $P$ such that: $A = P J P^{-1}$. Now I found the characteristic polynomial and minimal polynomials:
$P_A(x) = (x-1)(x-2)^2 = m_A(x)$. And from the minimal polynomial I found out that the maximal block size for the eigenvalue $1$ is $1$ so we have one block of size $1$ for that eigenvalue. And in the same way that the maximal jordan block size for eigenvalue $2$ is $2$ and I calculated $N=A-2I$ and figured that there is only one block of size $2$ for eigenvalue $2$. And so I found the Jordan Form: $$J_A = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 2 & 1 \\ 0 & 0 & 2 \end{pmatrix}$$ Now what I am having trouble with is finding $P$. I know that $Ker(N) = Ker(N-2I) = (1,1,0$ and $Ker(Z) = Ker(A-I) = (1,0,0)$ But how do I exactly calculate the spans to know the basis for the Jordan form if I have two eigenvalues? This is an algorithm that I was not taught! Any help will be appreciated","['jordan-normal-form', 'matrices', 'linear-algebra']"
411817,Rudin: Problem Chp3.11 and need advice.,"I am working on the following problems and I have a couple of questions. Suppose $a_n>0, s_n = \sum_{i = 1}^{n}$ and $\Sigma a_n$ diverges. RTP (a)  $\Sigma \frac{a_n}{1+a_n}$ diverges. (b) By showing $$\sum_{i=1}^{k} \left[ \frac{a_{N+i}}{s_{N+i}} \right] \ge 1 - \frac{s_N}{s_{N+k}}$$ prove that $\sum \frac{a_n}{s_n}$ diverges. (c) By showing  $$\frac{a_n}{s_n^2} \le \frac{1}{s_{n-1}}-\frac{1}{s_n}$$ and deduce that $\sum \frac{a_n}{s_n^2}$ converges. (d) What can be said about $$\Sigma \frac{a_n}{n a_n +1} \text{ and } \Sigma \frac{a_n}{a+n^2a_n}$$ I understand (a). But I am generally very iffy with proving these kind of problems because I usually get stuck with showing some inequalities being true. 1), How are the rest of the problem solved ? 2), Is there a general way to solve most of these inequalities ? Especially with those that have summations ? 3), Are these problem considered easy ? I am teaching myself analysis and it's such a struggle for me.","['inequality', 'sequences-and-series', 'advice', 'analysis']"
411845,An intuitive approach to the Jordan Normal form,"I want to understand the meaning behind the Jordan Normal form, as I think this is crucial for a mathematician. As far as I understand this, the idea is to get the closest representation of an arbitrary endomorphism towards the diagonal form. As diagonalization is only possible if there are sufficient eigenvectors, we try to get a representation of the endomorphism with respect to its generalized eigenspaces, as their sum always gives us the whole space. Therefore bringing an endomorphism to its Jordan normal form is always possible. How often an eigenvalue appears on the diagonal in the JNF is determined by its algebraic multiplicity.  The number of blocks is determined by its geometric multiplicity. Here I am not sure whether I've got the idea right. I mean, I have trouble interpreting this statement. What is the meaning behind a Jordan normal block and why is the number of these blocks equal to the number of linearly independent eigenvectors? I do not want to see a rigorous proof, but maybe someone could answer for me the following sub-questions. (a) Why do we have to start a new block for each new linearly independent eigenvector that we can find? (b) Why do we not have one block for each generalized eigenspace? (c) What is the intuition behind the fact that the Jordan blocks that contain  at least $k+1$ entries of the eigenvalue $\lambda$ are determined by the following? $$\dim(\ker(A-\lambda I)^{k+1}) - \dim(\ker(A-\lambda I)^k)$$","['jordan-normal-form', 'matrices', 'linear-algebra', 'intuition']"
411868,A difficult integral $\int_0^\infty \mathrm{d}t\frac{1}{t}\frac{1}{t-s-\mathrm{i}\epsilon}\frac{1}{X}\ln\frac{1-X}{1+X} $,"Can anyone give any hints on how to rewrite this in terms of dilogarithms? $$
\int_{0}^{\infty}{{\rm d}t \over t}\,{1 \over t - s - {\rm i}\epsilon}\,
{1 \over \,\sqrt{\, 1 - a/t\,}\,}\,
\ln\left(1 - \,\sqrt{\,1 - a/t\,}\, \over 1 + \,\sqrt{\, 1 - a/t\,}\,\right)\,,
$$
with $\epsilon$ small. It looks horrible and I really don't know how to proceed, I have tried many variable substitutions, separate $t$ and $t - s$ via partial fractions etc...nothing seems to work. Any help is appreciated. EDIT: So I have split the integral up in the following way, can someone comment my logic and mistakes: Since $1-a/t$ is negative for $t<a$ we let 
$$ (1-a/t)^{1/2} = \mathrm{i}\sqrt{a/t-1}$$ in this interval, in the rest of the integration range it the usual square root. Then one can write the integral as $$ I = \int_0^a \mathrm{d}t\frac{1}{t}\frac{1}{t-s-\mathrm{i}\epsilon}\frac{1}{\mathrm{i}\sqrt{a/t-1}} \ln\frac{1-\mathrm{i}\sqrt{a/t-1}}{1+\mathrm{i}\sqrt{a/t-1}}\\[3mm]+\int_a^\infty \mathrm{d}t\frac{1}{t}\frac{1}{t-s-\mathrm{i}\epsilon}\frac{1}{\sqrt{1-a/t}} \ln\frac{1-\sqrt{1-a/t}}{1+\sqrt{1-a/t}}$$
Now substituting $u=1-a/t$ and $u=a/t-1$ we get 
$$I=-\mathrm{i}\int_0^\infty\mathrm{d}u\frac{1}{\sqrt{u}}\frac{1}{a-s(1+u)-\mathrm{i}\epsilon}\ln\frac{1-\sqrt{u}}{1+\sqrt{u}}\\[3mm]+\int_0^1\mathrm{d}u\frac{1}{\sqrt{u}}\frac{1}{a-s(1-u)-\mathrm{i}\epsilon}\ln\frac{1-\sqrt{u}}{1+\sqrt{u}}$$
Now there is an obvious substitution $u=v^2$ but I how would I treat the first log since the stuff inside its parenthesis becomes negative for $u>1$ and I rather not mess with absolute value bars (e.g. in $\log z = \log|z|+\mathrm{i}\arg z$). Is there any other way from here on?","['improper-integrals', 'integration']"
411873,Learning Roadmap for Borel - Weil - Bott Theorem,"Next semester I may study a course where the ultimate goal is to get to the Borel - Weil - Bott (BWB)  Theorem , if not at least try to understand it in the case that we have $G = \text{SL}_n$. I have studied some representation theory of Lie groups from Brian Hall's book Lie groups, Lie algebras and Representations . I am ok with highest weight theory for $\mathfrak{sl}_n$ and I have also studied some  Schur - Weyl duality and classification of irreps of $\mathfrak{sl}_n$ from Fulton and Harris. My question is: What would a learning roadmap for understanding the BWB Theorem be? I was told by the lecturer we would probably start out by looking at line bundles over $\Bbb{P}^1$.  Now I don't mind if there is no single reference/book to read linearly  that I have to look into. Though, I don't know how one would build up one's background to get to the theorem. 
I don't  mind if I have to learn things like sheaf cohomology and the like on the way. If it helps, I have also studied differential geometry and am familiar with the material in chapters 1-5,7,8,11,14,16 of Lee's Smooth Manifolds, second edition.","['lie-groups', 'algebraic-geometry', 'representation-theory', 'reference-request']"
411898,The notion of a curve in the context of line integrals,"For brevity I'm making the following assumption: I'm only talking
about regular curves on $\left[a,b\right]$ with values in $\mathbb{R}^{n}$,
and line integrals of scalar fields. [Since there are a lot of questions at the end and you have to dig through the text below to make sense of them, I'm willing to offer 150 bounty points for a complete and thorough answer by a knowledgeable person in either differential geometry or vector analysis (or related fields) of all the questions . There are three common ways to define curves: Here they are defined as mappings $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$. Here a curve is used as a subset $C$ of $\mathbb{R}^{n}$ that's the image
of a (regular) $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$- which clearly doesn't work with the concept from 1. (although Wikipedia
has linked to that - has no one spotted this so far ?) Here curves are equivalence classes of mappings $\left[a,b\right]\rightarrow\mathbb{R}^{n}$
(which are equivalent if they are obtained from reparametrisations
of eachother). Now these definitions relate in different ways to the concept of a
line integral over scalar field $f$ along $\gamma$. If I take 1. as my definition, I can define 
$$
\int_{\gamma}fd s:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t
$$
without mathematical problems, but I have the ""psychological""
problem that I would like my line integral to not be dependent on
all the information $\gamma$ contains (since, for example, different
reparametrisations of $\gamma$ give me the same $\int_{\gamma}f$)
- of course I can show that this holds in a separate theorem, but
this just seems ugly). If I take 2. as my definition, I can define 
$$
\int_{C}fds:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t
$$
where $\gamma$ is any parametrisation $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$
that has image $C$. This has mathematical problems: There are (regular)
curves that have the same image , but aren't equivalent, so have different
lengths. For example 
$$
t\mapsto\left(\begin{array}{c}
\cos t\\
\sin t
\end{array}\right)\ \text{and}\ t\mapsto\left(\begin{array}{c}
\cos2t\\
\sin2t
\end{array}\right)
$$
where $t\in\left[0,2\pi\right]$. So $\int_{C}f s$ isn't well
defined since it depends on the choice of the parametrisation of $C$.
But from a ""psychological"" perspective I like this the most,
since it only has a geometric content (since $C\subseteq\mathbb{R}^{n})$
and not a dynamic one (I don't know anything about the ""speed""
with which $C$ is traced) and my personal view is, that line integral
(or arc lengths, since I could have discussed this issue in the same
matter with arc lengths instead of line integrals) should be purely
geometrical. If I take 3. as my definition, I can define 
$$
\int_{\hat{\gamma}}fd s:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t
$$
where $\hat{\gamma}$ is the equivalance class of $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$.
This seems to me to be a compromise between 1. and 2.: The line integral
is (from the start) independent of reparametrisations - but it isn't
purely geometric, as the definitions from 2. But other weird issues arise in this case: Since a curve is a set of mappings (which makes up the equivalence class) I loose a comfortable way of speaking about curves by the following subtle point: I can't say anymore that a smooth curve is also a continuous curve, since for example the equivalence class of the identity on $[0,1]$ (taken as a curve in $\mathbb{R}$), viewed as a smooth curve (i.e. as the set $\{f\mid f:[0,1] \rightarrow \mathbb{R} \text{ is smooth and can be reparametrised to be the identity}\}$) does not contain $$t\mapsto\begin{cases}
2t, & 0\leq t\leq\frac{1}{2}\\
1, & \frac{1}{2}<t\leq1
\end{cases}$$which is is in the equivalence class of the identity, viewed as a continuous curve (i.e. as the set $\{f\mid f:[0,1] \rightarrow \mathbb{R} \text{ is continuous and can be reparametrised to be the identity}\}$) . Questions: A. Is there a standart definition of what a curve (and thus a line
integral) is ? If there isn't a definition that's valid for the whole
of mathematics, is the definition at least separately standarised
in subfields (like differential geometric, vector analysis etc.) ? B. Is my view that line integrals and arc lengths should only depend
on a purely geometric object of a curve ""correct"" ? (You may
understand what you wish by ""correct"".) C. Could I perhaps save the definition of $\int_{C}f ds$ from 2.,
by modifying its definition so that it says 
$$
\int_{C}fds:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t
$$only for those $\gamma$ that are injective on $\left(a,b\right)$ ? (In this case I would need a proposition, that for every $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$ there exists an injective $\gamma':\left[a,b\right]\rightarrow\mathbb{R}^{n}$, such that $\gamma$ and $\gamma'$ have the same image. Does such a proposition exist ?) Would I exclude important physical phenomena by this alternative definition of 2.? D. I've know that there also a fourth definition if a curve, namely
as a topological space locally homeomorphic to a line. How does this
definition reduce to each of the three definitions above (as Wikipedia
says at the beginning of the article http://en.wikipedia.org/wiki/Curve about curves) and how do I define a line integral (or arc length)
by this definition ? Note: I've already read this in case you wanted to direct me there.","['multivariable-calculus', 'integration', 'differential-geometry', 'vector-analysis', 'analysis']"
411930,"Injection $f:[0,1]\to [0,1]{\bf\big\backslash}\left\{ 1/n : n\in \mathbb{N}^*\right\}$ with $f(0)=0$ and $f$ continuous at $0$?","Does there exist a function $f:[0,1]\to [0,1]\setminus\left\{\frac 1n, n\in \mathbb{N}^*\right\}$ so that $f$ is 1-1, $f(0)=0$ and $f$ continuous at $0$? Does it have a closed form? I know that as $[0,1], [0,1]\setminus\left\{\frac 1n, n\in \mathbb{N}^*\right\}$ have the same cardinality $\mathfrak{c}$, at least one bijection between them exists. By swaping $0,x$ ($x$ is the unique number for which $f(x)=0$) I can obtain $f(0)=0$. But what about continuity at $0$?","['functions', 'continuity', 'real-analysis']"
411986,An inequality for symmetric matrices: $ \mbox{trace}(XY)\leq \lambda(X)^T\lambda(Y) $.,"Let the vector of eigenvalues of a $n\times n$ matrix $U$
is denoted by 
$$
\lambda(U)=\big(\lambda_1(U),\lambda_2(U),\ldots,\lambda_i(U),\ldots\lambda_{n-1}(U),\lambda_n(U)\big)^T.
$$
where the eigenvalues are ordered as $\lambda_1(U)\leq\lambda_2(U)\leq\ldots\leq\lambda_i(U)\leq\ldots\lambda_{n-1}(U)\leq\lambda_n(U)$. I would like to prove ( or get a counterexample) the following inequality for symmetric matrices $X$ and $Y$ 
$$
\mbox{trace}(XY)\leq \lambda(X)^T\lambda(Y).
$$
Thanks in advance.","['trace', 'matrices', 'linear-algebra', 'inequality']"
412003,Probability of consecutive dice rolls,"This is probably quite a simple question but here I go.. Suppose you are going to roll a six-sided (fair) die N times, what is the probability that you will get at least one set of three consecutive numbers in a row? Hopefully that's clear enough but as an example, in nine rolls you may get: 1, 4, 2, 6, 4, 4, 4, 4, 3 With the 4s making two sets of consecutive rolls. Thanks!","['dice', 'probability']"
412011,Lebesgue integral over a collection of sets,"Let $E$ and $\langle E_n \rangle$ be measurable sets in $\mathbb{R}$. Suppose that $f$ is Lebesgue integrable over $E$. If $E_n\subset E$ for all $n$ and $\displaystyle \lim_{n\to \infty} m(E_n)=m(E)<+\infty$, show that 
$\displaystyle \lim_{n\to \infty} \int_{E_n} f(x)\ dx= \int_E f(x)\ dx.$ The theorems at my disposal are pretty much any theorem from the first 4 chapters of Royden 3rd Edition. The technique I tried involved creating an increasing sequence of sets (call them $D_k$) from the $E_n$'s via unions, then create a sequence of functions $f_k=f \chi_{D_k}$ however that will only converge if $\bigcup D_k=E$ which I am not sure it will. Can anyone give me any pointers to help with this method?  Or if I'm on the wrong track help steer me on the correct track.","['lebesgue-integral', 'measure-theory', 'real-analysis']"
412048,"Find the legs of isosceles triangle, given only the base","Is it possible to find the legs of isosceles triangle, given only the base length? I think that the info is insufficient. Am I right?","['geometry', 'triangles']"
412052,prove this $\int_{0}^{2}f^2(x)dx\le\int_{0}^{2}f'^2(x)dx$,"let $f\in C^1[0,2]$,and such $\int_{0}^{2}f(x)dx=0,f(0)=f(2)$, show that
$$\int_{0}^{2}f^2(x)dx\le\int_{0}^{2}f'^2(x)dx$$ I think we must use $Cauchy$ inequality my idea:I have see this 
let $f(x)\in C^1([a,b],R)$,and $f(a)=f(b)=0$,show that：$$\displaystyle\int_{a}^{b}f^2(x)dx\le\dfrac{(b-a)^2}{8}\displaystyle\int_{a}^{b}[f'(x)]^2dx$$
pf：
$$|f(x)|=|f(x)-f(a)|\le\sqrt{x-a}\left(\displaystyle\int_{a}^{x}[f'(t)]^2dt\right)^{\frac{1}{2}}$$
then $$f^2(x)\le(x-a)\displaystyle\int_{a}^{x}[f'(t)]^2dt\le(x-a)\displaystyle\int_{a}^{b}[f'(t)]^2dt$$
so we can $a$to $b$ we have;
$$\displaystyle\int_{a}^{b}f^2(x)dx\le\displaystyle\int_{a}^{b}\left[(x-a)\displaystyle\int_{a}^{b}[f'(t)]^2dt\right]dx=\dfrac{(b-a)^2}{2}\displaystyle\int_{a}^{b}[f'(x)]^2dx$$
then we use $\dfrac{a+b}{2}$to $b$,then we 
$$\displaystyle\int_{a}^{\frac{a+b}{2}}f^2(x)dx\le\dfrac{(b-a)^2}{8}\displaystyle\int_{a}^{\frac{a+b}{2}}[f'(x)]^2dx$$
other hand ，for any $x\in[\frac{a+b}{2},b],f(x)=-\displaystyle\int_{x}^{b}f'(t)dt$, so
$$f^2(x)=\left(\displaystyle\int_{x}^{b}f'(x)dx\right)^2\le(b-x)\displaystyle\int_{x}^{b}[f'(t)]^2dt$$
we can $\dfrac{a+b}{2}$to $b$ have :
\begin{align}
&\displaystyle\int_{\frac{a+b}{2}}^{b}f^2(x)dx\le\displaystyle\int_{\frac{a+b}{2}}^{b}(b-x)\left(\displaystyle\int_{a}^{b}[f'(t)]^2dt\right)dx\le
\displaystyle\int_{\frac{a+b}{2}}^{b}(b-x)dx\left(\displaystyle\int_{\frac{a+b}{2}}^{b}[f'(t)]^2dt\right)dx\\
&=\left(\displaystyle\int_{\frac{a+b}{2}}^{b}(b-x)dx\right)\left(\displaystyle\int_{\frac{a+b}{2}}^{b}[f'(x)]^2dx\right)\\
&=\dfrac{(b-a)^2}{8}\displaystyle\int_{\frac{a+b}{2}}^{b}[f'(x)]^2dx
\end{align}
then 
$$\displaystyle\int_{a}^{b}f^2(x)dx\le\dfrac{(b-a)^2}{8}\displaystyle\int_{a}^{b}[f'(x)]^2dx$$ let $b=2,a=0$,then we have
$$2\int_{0}^{2}f^2(x)dx\le\int_{0}^{2}f'^2(x)dx$$","['integral-inequality', 'integration', 'analysis']"
412057,Characterisation of linearly separable points of a hypercube,"Essentially, linearly separable points are just those corners that can be cut off with just one slice as marked out by a hyperplane. E.g. for a cube, the following 4 points (red) are not linearly separable - no single cut by a plane (tilted at whatever angle) across the cube can slice off exactly these 4 points: So this begs the question: given $n$ points on an $m$-dimensional hypercube, how can I tell if these $n$ points are linearly separable?","['geometry', 'convex-analysis', 'graph-theory', 'combinatorial-geometry', 'decision-problems']"
412069,$\frac{1}{x-a} + \frac{1}{x-b} + \frac{1}{x-c} = 0 $ has precisely two real roots,"Prove that given $ a < b < c $ this equation:  $$\frac{1}{x-a} + \frac{1}{x-b} + \frac{1}{x-c} = 0 $$ has precisely 2 real roots. I understand there are 3 point of discontinuities, but I have no idea how to prove this. Can you give me a hint? Thanks in advance.",['calculus']
412078,Examples of 2-dimensional foliations of a 4-sphere.,"This is a follow up to The 4-sphere does not admit dimension 2 foliations , where I asked about the existence of nonsingular foliations of a 4-sphere. Since that question determined there are no such foliations, I am now looking for examples of any 2-dimensional foliations of the 4-sphere. The simplier the better; for instance the 3-sphere has a foliation coming from the Hopf map which one can explicitly describe with coordinates. I have been struggling to find something similar for the 4-sphere case and haven't had any luck. Does anyone know of any?","['foliations', 'examples-counterexamples', 'differential-geometry']"
412082,Preordering on a set,I am given a definition which states that a 'preodering on a set is a relation that is reflexive and transitive.' Show that a relation $\leq$ defined on $\mathbb{C}$ by $z_1 \leq z_2$ iff $|z_1| = |z_2|$ is a preodering on $\mathbb{C}$. I must be missing something here because clearly for any $z \in \mathbb{C}$ we have $|z| = |z|$ and if $z_1 \leq z_2$ and $z_2 \leq z_3$ then that implies that $|z_1| = |z_2| = |z_3|$ which means that $z_1 \leq z_3$.  I must be reading the question wrong surely.  What am I missing?,"['relations', 'elementary-set-theory']"
412083,Computing the cube under a different modulus,"Given a natural number $n$, we want to find another natural number $m$ coprime to $n$, such that on input $y=x^3 \pmod n$ for any $x \in \mathbb{Z}_n^* \cap \mathbb{Z}_m^*$, we must be able to compute $x^3 \pmod m$. Note that it might be computationally infeasible to first compute the cubic root of $y$ modulo $n$. Therefore, the algorithm should cleverly pick $m$ in such a way it can later compute $x^3 \pmod m$.","['algorithms', 'number-theory']"
412085,Integrate: $\int \frac{dx}{x \sqrt{(x+a) ^2- b^2}}$,"How to evaluate
$$\int \frac{dx}{x \sqrt{(x+a) ^2- b^2}}$$
I tried trigonometric substitution $x + a = b \sec \theta$ and I encountered
$$\int \frac{\tan \theta}{ (b - a \cos \theta) \sqrt{\tan^2 \theta}}d\theta$$
how to handle this term $\displaystyle \frac{\tan \theta}{|\tan \theta|}$?","['calculus', 'integration', 'indefinite-integrals']"
