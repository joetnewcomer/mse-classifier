question_id,title,body,tags
1581126,Is there standard terminology to describe the not-quite-a-limit behavior of ${\tan( \log x) \over x}$ as $x$ approaches infinity?,"Suppose I want to describe the long term behavior of ${\tan(\log x) \over x}$ as x increases towards positive real infinity. Now, $$\lim_{x \rightarrow \infty}{\tan(\log x) \over x}$$ obviously doesn't exist.  So it would be wrong to say its limit is 0. But in some very slightly looser sense, the term obviously approaches 0 aside from the very occasional vertical asymptote.  If you were to pick a point at ""random"" far, far down the number line (I'm being very imprecise here, I know), it would be an $\epsilon$ from 0 with a probability approaching 1 as the random range you were pulling from got larger.  Various summability methods would also make this fact clear. Is there either standard terminology for getting this idea across, or standard notation for expressing it?","['real-analysis', 'limits', 'asymptotics', 'calculus', 'terminology']"
1581146,What is the logical idea of self orthogonality?,"I know how to calculate the orthogonal trajectory of a given family of curves. And it is said in my text book that if the orthogonal trajectory of a curve is itself, then we say that the family of curves is self orthogonal. As an example, orthogonal trajectory of parabola $$y^2=4a\left(x+a\right)$$  Is the same function. But how this is possible? Orhogonal trajectory cut every member of given family normally. I cannot get an idea of self orthogonality. I tried to graph the above equation with suitable $a$ . But I cannot agree with the fact that the same function is its orthogonal trajectory. I try an algebraic approach. If $m$ is the slope of such function at a point $x$ , then $\frac{-1}{m}$ is also its slope at $x$ . This gives, $$m^2=-1\\  
\implies {m=i}$$
thus, the slope I get is a complex value for such functions. But I cannot agree with it. Where is my mistake? Can anyone help me?","['orthogonality', 'ordinary-differential-equations']"
1581161,What is the angle $\widehat{BAC}$?,"Let the triangle $ABC$ and the angle $\widehat{ BAC}<90^\circ$ Let the perpendicular to $AB$ passing by the point $C$ and the perpendicular to $AC$ passing by $B$ intersect the circumscribed circle  of $ABC$ on $D$ and $E$ respectively . 
We suppose that $DE=BC$ What is the angle $\widehat{BAC}$ I tried using law of sines in triangle
Also , let O be center of circle so OD=OE=r","['euclidean-geometry', 'geometry']"
1581188,Expected value for the number of tries to draw the black ball from the bag,"We have a bag with $4$ white balls and $1$ black ball. We are drawing balls without replacement. Find expected value for the number of tries to  draw the black ball from the bag. Progress. The probability to draw a black ball from first trial is $1/5$. The problem is how to find the probability to draw black ball from $2$nd, $3$rd, $ \ldots, 5$th trial. When I know all this probabilities I can find expected value as $1\cdot(1/5) + 2 p_2 + \dots + 5 p_5$.","['balls-in-bins', 'probability']"
1581202,Why is this the equation of the tangent plane?,"I want to find the equation of the tangent plane of the surface patch $\sigma (r, \theta)=(r\cosh \theta , r\sinh \theta , r^2)$ at the point $(1,0,1)$. I have done the following: The point $(1,0,1)$ corresponds to $\sigma (1,0)$. We have that $$\sigma_r=(\cosh \theta , \sinh \theta , 2r) \rightarrow \sigma_r(1,0)=(1,0,2) \\ \sigma_{\theta}=(r \sinh \theta , r \cosh \theta , 0) \rightarrow \sigma_{\theta}(1,0)=(0,1,0)$$ $$\sigma_r (1,0) \times \sigma_{\theta} (1,0)=(-2,0,1)$$ The equation of the tangent plane is given by the formula $$(-2, 0, 1) \cdot (x-1, y-0, z-1)=0 \\ \Rightarrow -2x+z+1=0$$ $$$$ In the solution of the book, the answer is $-2x - 2y + z =0$. Where is the mistake at my calculations?","['plane-curves', 'differential-geometry', 'surfaces']"
1581228,Trying to express a polynomial as $(z-\text{root}_1)(z-\text{root}_2)$,"I'm probably making some stupid mistake, but here's my problem: I have the polynomial $0.5z^2+9iz-0.5$, the roots I calculated are $a=-9i-4\sqrt5i,\;\;\;b=-9i+4\sqrt5i$. I tried to express the polynomial as $(z-a)(z-b)$, and I plugged some numbers to check if it works - but it seems like I always get double the result, what am I doing wrong? (Results were calculated with a calculator)",['complex-analysis']
1581230,$\lim_{x\to 0}\frac{\sin 3x+A\sin 2x+B\sin x}{x^5}$ without series expansion or L Hospital rule,"If $$f(x)=\frac{\sin 3x+A\sin 2x+B\sin x}{x^5},$$ $x\neq 0$, is continuous at $x=0$, then find $A,B$ and $f(0)$. Do not use series expansion or L Hospital's rule. As $f(x)$ is continuous at $x=0$,therefore its limit at $x=0$ should equal to its value. Note that this question is to be solved without series expansion or L Hospital's rule, I tried to find the limit $\lim_{x\to 0}\frac{\sin 3x+A\sin 2x+B\sin x}{x^5}$ $\lim_{x\to 0}\frac{\sin 3x+A\sin 2x+B\sin x}{x^5}=\lim_{x\to 0}\frac{3\sin x-4\sin^3x+2A\sin x\cos x+B\sin x}{x^5}=\lim_{x\to 0}\frac{3-4\sin^2x+2A\cos x+B}{x^4}\times\frac{\sin x}{x}$ $=\lim_{x\to 0}\frac{3-4\sin^2x+2A\cos x+B}{x^4}$ As the denominator is zero,so numerator has to be zero,in order the limit to be finite. So, $3+2A+B=0. (1)$ I tried but I could not get the second equation between $A$ and $B$. I am stuck here. How do I continue?","['limits-without-lhopital', 'calculus', 'limits']"
1581250,Intuition behind subspace $\sigma$-Algebra,"Let $(X,\Sigma)$ be a measurable space and $D \subseteq X$. The subspace $\sigma$-Algebra of subsets of $D$, $$Ïƒ_D = \{E \cap D : E \in \Sigma\}$$
What is the intuition behind this definition? What is it trying to say?",['measure-theory']
1581257,How to construct Markov kernels into a product measurable space?,"Let $(A,\mathcal E_A)$, $(B,\mathcal E_B)$, $(C,\mathcal E_C)$ be
measurable spaces. Let $f$ be a Markov kernel from $(A,\mathcal
E_A)$ to $(B,\mathcal E_B)$. Let $g$ be a Markov kernel from
$(A,\mathcal E_A)$ to $(C,\mathcal E_C)$. Let $h_a$ be the unique
measure on $(B\times C,\mathcal E_B\otimes\mathcal E_C)$ such
that
$$h_a(E_B\times E_C) = f(a,E_B)\cdot g(a,E_C)$$
for all $E_B\in\mathcal E_B$, $E_C\in\mathcal E_C$. If we write $h(a,E)=h_a(E)$, then is $h$ a Markov kernel from $(A,\mathcal E_A)$ to $(B\times C,\mathcal E_B\otimes\mathcal E_C)$? In
particular, is the map $a\mapsto h_a(E)$ a real-valued measurable function for all
$E\in\mathcal B\otimes\mathcal C$?","['probability-theory', 'measure-theory', 'product-measure']"
1581271,Pointwise A.E. Convergence of Convolution,"The following is a prelim question, which I can't seem to show under the hypotheses given. Problem . Let $f$ and $g$ be bounded measurable functions on $\mathbb{R}^{n}$. Assume that $g$ is integrable and satisfies $\int g=0$. Define $g_{k}(x):=k^{n}g(kx)$ for $k\in\mathbb{N}$. Show that $f\ast g_{k}\rightarrow 0$ pointwise almost everywhere, as $k\rightarrow\infty$. It's easy to show that $(f \ast g_{k})(x)\rightarrow 0$ for every point of continuity of $f$. Moreover, if $g$ satisfies some decay at $\infty$ condition like $O(|x|^{-n-\delta})$, for some $\delta>0$. Then we can show that $(f\ast g_{k})(x)\rightarrow 0$ for a.e. $x$ (in fact, every point in the Lebesgue set of $f$). Indeed, sSince $f$ is locally integrable, we have by the Lebesgue differentiation theorem that for a.e. $x\in \mathbb{R}^{n}$,
    $$\lim_{r\rightarrow 0}r^{n}\int_{|y|\leq r}|f(x-y)-f(x)|dy=0$$
Using the hypothesis $\int g=0$, we have
\begin{align*}
\left|(f\ast g_{k})(x)\right|&=\left|k^{n}\int_{\mathbb{R}^{n}}[f(x-y)-f(x)]g(ky)dy\right|\\
	&\leq k^{n}\int_{|y|\leq 1/k}|f(x-y)-f(x)||g(ky)|dy+k^{n}\int_{|y|>1/k}|f(x-y)-f(x)||g(ky)|dy\\
	&\leq\|g\|_{L^{\infty}}k^{n}\int_{|y|\leq 1/k}|f(x-y)-f(x)|dy+k^{n}\int_{|y|>1/k}|f(x-y)-f(x)||g(ky)|dy\\
\end{align*}
We estimate the second term by
\begin{align*}
&\lesssim\sum_{j=0}^{\infty}k^{n}\int_{2^{j}k^{-1}<|y|\leq 2^{j+1}k^{-1}}|f(x-y)-f(x)||ky|^{-n-\delta}dy\\
&\leq \sum_{j=0}^{\infty}2^{-j(n+\delta)}k^{n}\int_{|y|\leq 2^{j+1}k^{-1}}|f(x-y)-f(x)|dy\\
&=\sum_{j=0}^{\infty}2^{-j(n+\delta)}2^{(j+1)n}(2^{-j-1}k)^{n}\int_{|y|\leq 2^{j+1}k^{-1}}|f(x-y)-f(x)|dy\\
&\lesssim\sum_{j=0}^{\infty}2^{-j\delta}(2^{-j-1}k)^{n}\int_{|y|\leq 2^{j+1}k^{-1}}|f(x-y)-f(x)|dy
\end{align*}
The rest of the proof follows by using the $L^{\infty}$ bound for $f$ and the summability of the resulting series to reduce to a finite sum, then appealing to Lebesgue differentiation.","['real-analysis', 'lebesgue-integral', 'measure-theory']"
1581283,What is the discriminant of a degree $n$ polynomial?,In my high school algebra class the teacher (who is me) says that the discriminant of a quadratic polynomial $ax^2 + bx + c$ is $b^2 - 4ac$. I have read in the Wikipedia article that the discriminant of a polynomial is the product of the squares of the differences of its roots.  This does not seem to be consistent with the above.  If I subtract the roots of a quadratic and then square the result I get $\frac{(b^2 - 4ac)}{a^2}$.,"['algebra-precalculus', 'abstract-algebra']"
1581289,Need help understanding central limit theorem,"I am very confused about CLT and have searched on the internet but found nothing that solved my confusion. How can I solve a problem like this with CLT? Let $Y =\operatorname{Pois}(n)$.  Using Normal approximation, aka the CLT, give an
estimate of the probability $$p\Big[|Y-n| \geq 2\sqrt{n}\Big].$$","['statistics', 'central-limit-theorem']"
1581304,"How is this called? (""Syncing sequences"")","I recently needed something like the following: Let $(a_0, a_1, \dots, a_m)$ and $(b_0, b_1, \dots, b_n)$ be two
finite sequences of integers, not necessarily of the same length,
with the same beginning and end (i.e. $a_0 = b_0$ and $a_m =
b_n$) and both with the property that the difference between two
successive sequence elements is always $1$ or $-1$, i.e. $|a_k -
a_{k+1}| = 1$ for $k=0,\dots,m-1$ and the same for the other
sequence.  Furthermore, let each sequence only have elements
between the beginning and the end.  To be more precise, we demand
$$\min(a_0,a_m) < a_k < \max(a_0,a_m)$$ for $k=1,\dots,m-1$ and
the same for the other sequence. It is then always possible to construct a finite sequence
  $$ ((\alpha_0,\beta_0), (\alpha_1,\beta_1), \dots, (\alpha_r,\beta_r)) $$
of pairs of indices such that the following conditions hold: $0 \leq \alpha_k \leq m$ for $k=0,\dots,r$ $0 \leq \beta_k \leq n$ for $k=0,\dots,r$ $(\alpha_0,\beta_0) = (0,0)$ $(\alpha_r,\beta_r) = (m,n)$ $|\alpha_k - \alpha_{k+1}| = 1$ for $k=0,\dots,r-1$ $|\beta_k - \beta_{k+1}| = 1$ for $k=0,\dots,r-1$ $a_{\alpha_k} = b_{\beta_k}$ for $k=0,\dots,r$ (This is easier to visualize than to write down.  See for example here .) I was able to prove this and to also code a recursive algorithm for this. My question now is: This must surely be something that people have done before.  But how is it called?  I was unable to find a name for this.  I don't even know how to tag this question correctly...","['terminology', 'sequences-and-series', 'discrete-mathematics']"
1581331,Can a function be analytic and satisfy $f\left(\frac 1 n\right) =\frac{1}{\log{n}}.$?,"Let $\Omega = \{z\in\mathbb{C}:\,|z|<2\}$. Prove or disprove that there exists an analytic function $f:\Omega\rightarrow\mathbb{C}$ such that for $n\geq2$:
$$f\left(\frac 1 n\right) =\frac{1}{\log{n}}.$$ Usually this question would fall under the uniqueness theorem for analytic functions; an example where the uniqueness theorem works is in disproving the existence of an analytic $f$ satisfying $$f\left(\frac 1 n\right) =\frac{(-1)^n}{n^2}.$$ But in the case of the $\log$, I think the issue of existence is more ""substantial"". Is it true that if such $f$ were to exist, then $f(z) = -\frac{1}{\log z}$? And if so, what is the main reason this function cannot be analytic in $\Omega$? Thanks in Advance!","['complex-analysis', 'complex-numbers']"
1581335,Differentiable function satisfying $f(x+a) = bf(x)$ for all $x$,"This is an exercise from Apostol Calculus , (Exercise 10 on page 269). What can you conclude about a function which has derivative everywhere and satisfies an equation of the form
  $$ f(x+a) = bf(x) $$
  for all $x$, where $a$ and $b$ are positive constants? The answer in the back of the book suggests that we should conclude $f(x) = b^{x/a} g(x)$ where $g(x)$ is a periodic function with period $a$.  I'm not sure how to arrive at this. One initial step is to say, by induction,
$$ f(x+a) = bf(x) \implies f(x+na) = b^n f(x)$$
for all $x$.  I'm not sure what to do with this though.  I'm also not clear how to use the differentiability of $f$.  (If I write down the limit definition of the derivative then I end up with a term $f(x+h)$, but I cannot use the functional equation on that since the functional equation is for a fixed constant $a$.)","['calculus', 'functional-equations']"
1581344,A continuous function on $S^1$- unit circle .,"$$S^1=\{z\in \mathbb C : |z|=1\}$$  be the unit circle. Then which of the following  is false $?$ Any continuous function  from $S^1$ to $\mathbb R$ is A. bounded B. uniformly continuous. C. has image containing a non empty open subset of $\mathbb R.$ D. has a point $z\in S^1$  such that  $f(z)=f(-z)$ Since $S^1$ is compact any continuous function would be bounded  or  uniformly  continuous so  $A$  and $B$  are  correct. For $C$, the  constant  function  does not have any open interval in its image. Thus, $C$ is the false statement. That leaves $D$ to be correct. How can I prove the existence of a point $z$ having properties  like  said  in $D$?","['complex-analysis', 'general-topology']"
1581347,Can I define cotangent as $\cot x=\cos x/\sin x$?,"Since $\tan x=\sin x/\cos x$ and $\cot x=1/\tan x$, can we redefine cotangent as $\cot x =\cos x/\sin x$? if we use this definition, we can find this value $\cot \pi/2= 0$. What are the advantages of the second definition?",['trigonometry']
1581381,If $B(x+y)-B(x)-B(y)\in\mathbb Z$ can we add an integer function to $B$ to make it additive?,"Given a function $B:\mathbb R\to\mathbb R$ satisfying $B(x+y)-B(x)-B(y)\in\mathbb Z$ for all real numbers $x$ and $y$ , is there a function $Z:\mathbb R\to\mathbb Z$ such that $B+Z$ is an additive function? In other words, is there a function $A:\mathbb R\to\mathbb R$ satisfying $A(x+y)=A(x)+A(y)$ for all real numbers $x$ and $y$ , such that $A(x)-B(x)\in\mathbb Z$ for every real number $x$ ? My motivation: I was thinking about real solutions of the d'Alembert functional equation, $f(x+y)+f(x-y)=2f(x)f(y)$ , without assuming continuity. There was a case where I could show that for some real function $B$ , $f(x)=\cos\big(2\pi B(x)\big)$ and $\cos\Big(2\pi\big(B(x+y)-B(x)-B(y)\big)\Big)=1$ so for every $x$ and $y$ we have $B(x+y)-B(x)-B(y)\in\mathbb Z$ . I was wondering if there's an additive function $A$ such that $A(x)-B(x)\in\mathbb Z$ for every $x$ . In that case, I could show that the solution is of the form $f(x)=\cos(2\pi A(x))$ where $A$ is additive. It's easy to verify that every function of this form is indeed a solution to the functional equation. (In other cases I could show that $f$ is the constant zero function or is of the form $f(x)=\cosh\big(A(x)\big)$ for some additive function $A$ . But they're not related to my question here.) My attempt: I defined $n(x,y)=B(x+y)-B(x)-B(y)$ . So $n(x,y)=n(y,x)$ and $n(x,0)=-B(0)$ . Without loss of generality, we can assume that $B(0)=0$ (otherwise we can subtract $B(0)$ from $B(x)$ and continue). Because $x+(y+z)=(x+y)+z$ , therefore I could conclude that $n(x,y+z)+n(y,z)=n(x+y,z)+n(x,y)$ . But this doesn't seem to help much.","['algebra-precalculus', 'functions', 'functional-equations']"
1581388,Equality of Two functions,"Let $f,g : B \to C$ be any two functions. Suppose that $f \circ h = g \circ h$ for every function $h: A \to B$. Prove that $f = g$. This is a problem form Pinter's Set Theory. I am trying to solve it but got no clue. Somebody help me please.","['real-analysis', 'elementary-set-theory']"
1581415,Proving $(A\times C)\cup(B\times D)\subseteq(A\cup B)\times(C\cup D)$,"I have been trying to prove the following for a while now, but I can't get to the solution: $$(A\times C)\cup(B\times D)\subseteq(A\cup B)\times(C\cup D)$$ Can anyone help me?",['elementary-set-theory']
1581420,Conservative Covector Fields are Exact,"$\newcommand{\R}{\mathbf R}$
I am trying to understand the proof of the following: Theorem. Let $M$ be a smooth manifold and $\omega$ be a smooth covector field on $M$. Then $\omega$ is conservative iff it is exact. The fact that exactness implies conservativeness is clear.
The other direction is more interesting. I am following the proof given in Lee's Introduction to Smooth Manifolds (Theorem 11.42). Proof. Assume $M$ is connected and $\omega$ is conservative. We need to show that $\omega$ is exact. For two points $p$ and $q$ in $M$, we write $\int_p^q \omega$ to denote the line integral $\int_\gamma \omega$, where $\gamma$ is any piecewise smooth curve starting at $p$ and ending at $q$.
This notation is unambiguous because of the conservativeness of $\omega$.
It is easy to guess a candidate $f:M\to \R$ such that $df=\omega$.
Fix $p_0\in M$ and define $f:M\to \R$ (just a set map as of now, no smoothness claimed yet), as
$$f(q)=\int_{p_0}^q\omega$$
for all $q\in M$. Main Question. To show that  $f$ defined above is smooth. For me it is enough to understand why $f$ is smooth at $p_0$.
We may further assume, by passing to a smooth chart, that $M=\R^n$ and $p_0=\mathbf 0$. So the main question is revised to: Revised Main Question. Take $M=\R^n$ and $p_0=\mathbf 0$. To show that $f$ defined above is smooth at $p_0$. The rest of the proof now goes like this: Let $\epsilon>0$. Fix $j$, and let $\gamma:[-\epsilon, \epsilon]\to\R^n$ be defined as $\gamma(t)=(0, \ldots, 0, t, 0, \ldots, 0)$, where $t$ is in the $j$-th place.
Let $p_1=\gamma(-\epsilon)$, and define $\tilde f:\R^n\to \R$ as
$$\tilde f(q)=\int_{p_1}^q\omega$$
It is clear that the difference $f-\tilde f$ is a constant.
So it is enough to show that $\tilde f$ is smooth.
Now we have:
$$\tilde f\circ \gamma(t)=\int_{-\epsilon}^t\omega_j(\gamma(s))ds$$
where $\omega_j$ is given by $\omega=\omega_1dx^1+\cdots +\omega_ndx^n$.
By fundamental theorem of calculus this shows that $\tilde f\circ \gamma$ is smooth and we get
$\frac{\partial \tilde f}{\partial x_j}(p_0)=\omega_j(p_0)$. What I do not Understand. But I do not see how does this prove that $\tilde f$ is smooth. It only shows that the partial derivative exists. What am I missing?","['differential-forms', 'smooth-manifolds', 'differential-geometry', 'line-integrals']"
1581440,Number of ways to put $k$ balls in $n$ boxes,"Compute the number of ways to spread $k$ identical balls over $n$ different cells (where $k \geq n$) with the condition that every cell will have at least one ball. So if $k=n$ then, we have only one option, because they're identical. otherwise, it was k! options. If $k>n$ then, we will put one ball to every cell and will have left with $k-n$ identical balls. then it is easy. Spreading k-n balls to n different cells without any conditions is $C(k-n + n - 1, k-n - 1)$. What do you guys think?",['discrete-mathematics']
1581460,Tate curve and cusps,"I know this is a naive question, but what is the relation between the Tate curve and cusps on a modular curve? Naive googling seems to suggest that level structures on the Tate curve (up to isomorphism) are in correspondence with the cusps of a modular curve. However, more googling says that the fibers over the cusps are n-gons ( https://mathoverflow.net/questions/51147/what-objects-do-the-cusps-of-modular-curve-classify ). Suppose we are working over a fixed field. Then, the special fiber of the Tate curve is a nodal curve or 1-gon. Then, where do the n-gons come from for n bigger than 1? If I take formal completions at the cusps of a modular curve, how are the fibers related to the Tate curve?","['algebraic-geometry', 'number-theory', 'arithmetic-geometry', 'elliptic-curves', 'modular-forms']"
1581490,Simpler proof of an integral representation of Bessel function of the first kind $J_n(x)$,"While doing research in electrical engineering, I derived the following integral representation of the Bessel function of the first kind: $$J_n(x)=\frac{e^{in\pi/2}}{2\pi}\int_0^{2\pi}e^{i(n\tau-x\cos\tau)}\mathrm{d}\tau\tag{1}$$ My derivation, which I include below, is long and ugly.  I am wondering if there is a more elegant proof of (1) using basic facts about other integral representations of the Bessel function, trig identities, and, perhaps, clever integration techniques.  The integral representation for Bessel function (found on wikipedia page ) that looks similar to mine is: $$J_n(x)=\frac{1}{2\pi}\int_{-\pi}^{\pi}e^{i(n\tau-x\sin\tau)}\mathrm{d}\tau. \tag{2}$$ Gradshteyn and Ryzhik (G&R) give the same expression in a slightly different form as formula 8.411.1 in the 7th edition.  However, I failed to convert (2) into (1) using simple substitution.  Does anyone have any other ideas? My LONG proof of (1) First, I use Euler's formula to break the integrand in (1) into in-phase and quadrature components, and apply the angle sum identities : $$\begin{align}e^{i(n\tau-x\cos\tau)}&=\cos(n\tau-x\cos\tau)+i\sin(n\tau-x\cos\tau)\\
&=\cos(n\tau)\cos(x\cos\tau)\tag{a}\\
&\phantom{=}+\sin(n\tau)\sin(x\cos\tau)\tag{b}\\
&\phantom{=}+i\sin(n\tau)\cos(x\cos\tau)\tag{c}\\
&\phantom{=}-i\cos(n\tau)\sin(x\cos\tau)\tag{d}
\end{align}$$ Now let's integrate (a)-(d) in turn.  First, for (a), note that: $$\begin{align}\int_{\pi}^{2\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\cos(n(\tau+\pi))\cos(x\cos(\tau+\pi))\mathrm{d}\tau\\
&=(-1)^n\int_0^{\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\tag{a1},
\end{align}$$
where (a1) is due to the negation of the cosine (and sine) from the shift by odd multiples of $\pi$, or, formally, $\cos(\theta+n\pi)=(-1)^n\cos\theta$. By formula 3.715.18 in G&R 7th ed: $$\int_0^{\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=\pi\cos\left(\frac{n\pi}{2}\right)J_n(x).$$ Thus, $$\begin{align}\int_0^{2\pi}\cos(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=(1+(-1)^n)\pi\cos\left(\frac{n\pi}{2}\right)J_n(x)\\
&=2\pi\cos\left(\frac{n\pi}{2}\right)J_n(x),\tag{a2}
\end{align}$$
where (a2) is because when $n$ is odd, $\cos\left(\frac{n\pi}{2}\right)=0$, making the double-multiplication by zero in this case unnecessary. Now let's integrate (b). First consider odd $n$: $$\int_0^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=2\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau,$$
because $\sin(n(\tau+\pi))\sin(x\cos(\tau+\pi))=\sin(n\tau)\sin(x\cos\tau)$ due to the negation of the sine (and cosine) from the shift by odd multiples of $\pi$, or, formally, $\sin(\theta+n\pi)=(-1)^n\sin\theta$ and the fact that $\sin(-\theta)=-\sin\theta$. Furthermore, $$\begin{align}\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau+\int_{\pi/2}^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\
&=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\
&\phantom{=}+\int_0^{\pi/2}\sin(n(\pi-\tau))\sin(x\cos(\pi-\tau))\mathrm{d}\tau\tag{b1}\\
&=\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi/2}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=0\tag{b2},
\end{align}$$
where (b1) is due to the substitution of $\tau=\pi-\tau'$ (the prime is dropped after substitution is made) and (b2) is since $\sin(n\pi-\theta)=\sin(\theta)$ for odd $n$ and $\cos(\pi-\theta)=-\cos(\theta)$. Now let's integrate (b) with even $n$:
$$\begin{align}\int_0^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau+\int_{\pi}^{2\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\
&=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\\
&\phantom{=}+\int_0^{\pi}\sin(n(2\pi-\tau))\sin(x\cos(2\pi-\tau))\mathrm{d}\tau\tag{b3}\\
&=\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi}\sin(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=0\tag{b4},
\end{align}$$
where (b3) is due to the substitution of $\tau=2\pi-\tau'$ (again, the prime is dropped after substitution is made) and (b4) is since $\sin(2n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for an integer $n$ and $\cos(2\pi-\theta)=\cos(\theta)$. Now let's integrate (c). Consider odd $n$ (let's omit the imaginary unit):
$$\begin{align}\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau+\int_{\pi}^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\
&=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\
&\phantom{=}+\int_0^{\pi}\sin(n(2\pi-\tau))\cos(x\cos(2\pi-\tau))\mathrm{d}\tau\tag{c1}\\
&=\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=0,\tag{c2}\\
\end{align}$$
where (c1) is due to the substitution of $\tau=2\pi-\tau'$ (the prime is dropped after substitution is made) and (c2) is since $\sin(2n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for integer $n$ and $\cos(2\pi-\theta)=\cos(\theta)$. Now integrate (c) with even $n$ (again, let's omit the imaginary unit):
$$\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=2\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau,$$
because $\sin(n(\tau+\pi))\cos(x\cos(\tau+\pi))=\sin(n\tau)\sin(x\cos\tau)$ due to $\sin(\theta+n\pi)=\sin\theta$ for even $n$, and $\cos(-\theta)=\cos\theta$. Furthermore, $$\begin{align}\int_0^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau+\int_{\pi/2}^{\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\
&=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau\\
&\phantom{=}+\int_0^{\pi/2}\sin(n(\pi-\tau))\cos(x\cos(\pi-\tau))\mathrm{d}\tau\tag{c3}\\
&=\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau-\int_0^{\pi/2}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau=0\tag{c4},
\end{align}$$
where (c3) is due to the substitution of $\tau=\pi-\tau'$ (the prime is dropped after substitution is made) and (c4) is since $\sin(n\pi-\theta)=\sin(-\theta)=-\sin(\theta)$ for even $n$ and $\cos(-\theta)=\cos(\theta)$. Finally, we integrate (d), omitting the negative imaginary unit for now. First, note that 
$$\begin{align}\int_{\pi}^{2\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau&=\int_0^{\pi}\cos(n(\tau+\pi))\sin(x\cos(\tau+\pi))\mathrm{d}\tau\\
&=(-1)^{n+1}\int_0^{\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau\tag{d1},
\end{align}$$
where (d1) is due to the negation of the cosine (and sine) from the shift by odd multiples of $\pi$, or, formally, $\cos(\theta+n\pi)=(-1)^n\cos\theta$ and by the fact that $\sin(-\theta)=-\sin\theta$. By formula 3.715.13 in G&R 7th ed: $$\int_0^{\pi}\cos(n\tau)\sin(x\cos\tau)\mathrm{d}\tau=\pi\sin\left(\frac{n\pi}{2}\right)J_n(x).$$ Thus, $$\begin{align}\int_0^{2\pi}\sin(n\tau)\cos(x\cos\tau)\mathrm{d}\tau&=(1+(-1)^{n+1})\pi\sin\left(\frac{n\pi}{2}\right)J_n(x)\\
&=2\pi\sin\left(\frac{n\pi}{2}\right)J_n(x),\tag{d2}
\end{align}$$
where (d2) is because when $n$ is even, $\sin\left(\frac{n\pi}{2}\right)=0$, making the double-multiplication by zero in this case unnecessary. Combining all the terms, using Euler's formula, and solving for $J_n(x)$, we arrive at (1).  Surely there is a better way...","['special-functions', 'integration', 'definite-integrals', 'bessel-functions']"
1581514,Equivalent definitions of locally convex topological vector space,"This Wikipedia article gives two equivalent definitions of locally convex space (l.c.s). I don't see clearly the equivalence and I'd like to make it crystal clear. Definition 1 Let $(V,\tau)$ be a TVS. It is called a l.c.s. if the origin has  a local base of convex balanced absorbing sets. Definitions 2 Let $(V,\tau)$ be a TVS. It is called a l.c.s. if $\tau$ is generated by a family of seminorms on $V$. Suppose $(V,\tau)$ satisfies Definition 1. Let $\mathcal{B}$ be a local base at $0$ such that for every $C\in\mathcal{B}$, $C$ is convex, balanced and absorbing. A known result shows that the Minkowski functional $\mu_C$ is a seminorm on $V$ for $C\in\mathcal{B}$. Question 1: Why can we conclude that $\tau$ is generated by $\{\mu_C\}_{C\in\mathcal{B}}$ so that Definition 1 implies Definition 2? Suppose $(V,\tau)$ satisfies Definition 2 and $\tau$ is generated by a family of seminorms $\{p_\alpha\}_{\alpha\in A}$. For every finite subset $F\subset A$ and $r>0$, define
$$
S_{F,r}=\bigcap_{\alpha\in F}\{x\in V:p_\alpha(x)<r\}.
$$ Question 2: Why $\{S_{F,r}\}$ form a base of convex balanced absorbing sets at the origin? Let $\tau'$ be the topology generated by $\{\mu_C\}$ in Question 1. I don't know at all why $\tau=\tau'$. For Question 2, I can show that the sets $S_{F,r}$ form a convex and balanced base at $0$. Why is each $S_{F,r}$ absorbing and are the two definitions of absorbing sets in this question the same here?","['functional-analysis', 'general-topology', 'locally-convex-spaces', 'topological-vector-spaces']"
1581544,Location of roots of degree six complex polynomial,"I want to prove that $z^6 +192 z + 640 =0$ has one root in the first and fourth quadrants and two roots in the second and third quadrants. How can I do this? I have tried some ideas like using Vieta's formulas, but still no result.",['complex-analysis']
1581583,Union an intersection of sets,I have that $F\subset E~$ where $F=\cup_{i\in I} V_i~$ and $~V_i=U_i\cap F$ and $U_i\subset E$ Why $$E= (E\setminus F)\cup (\cup_{i\in I} U_i)$$ Thank you.,['elementary-set-theory']
1581644,Solving by limit definition,"To show that $\displaystyle\lim_{(x,y)->(0,0)} \dfrac{5x^2y}{x^2+y^2}=0$
I tried to do this by the limit definition by pluging 0 to l in lim(x,y)->(Xo,Yo) | f(x,y)-l |. Then i got stucked where i couldnt put delta  to get an inequility. Can some one lemme know how to get this inequility?","['multivariable-calculus', 'limits']"
1581658,On what sets can we define a group operation?,"A question came up into mind. Prove that for every nonempty set $X$ an operation can be suggested such that $X$ would be a group with that operation. For example, it is obvious for finite and countable sets: $(\mathbb{Z}_n,+), (\mathbb{Q}, +)$. Also, it can be done for all sets of form $X=2^L$, as $(X, \Delta)$, which is symmetric difference on subsets of $L$. So is seems that the question is reduced to (1) sets which are high in hierarchy of cardinals (not of form $2^L$) and (2) sets which do not exist assuming continuum hypothesis (between $\mathbb{R}$ and $2^\mathbb{R}$ for instance). Axiom of choice is given. Or maybe intuition is wrong and for some sets it cannot be done, then a proof of existance of such or a single example would be nice. Thank you in advance.",['group-theory']
1581669,Integral $\int_0^1\arctan(x)\arctan\left(x\sqrt3\right)\ln(x)dx$,"I need to evaluate this integral:
$$\int_0^1\arctan(x)\arctan\left(x\sqrt3\right)\ln(x)dx$$
Apparently, Maple and Mathematica cannot do anything with it, but I saw similar integrals to be evaluated in terms of polylogarithms (unfortunately, I have not yet mastered them enough to do it myself). Could anybody please help me with it?","['logarithms', 'trigonometry', 'calculus', 'integration', 'definite-integrals']"
1581687,Can you give me a concrete example of a sphere being defined without reference to an ambient space?,"The strength of topology seems to lie in the ability to consider geometric objects without having to deal with something as obnoxious as an ambient space. However, despite reading many books and articles on the subject, I am unable to think of a simple concrete example regarding the subject; every embedding of a sphere that I devise always references R^3.","['general-topology', 'geometry']"
1581693,Asymptotics for a series of products,"I am trying to solve the following problem: Define the following functions for $x>0$:
  $$f_n(x):=\prod_{k=0}^{n}\frac{1}{x+k}$$ Show that the function
  $$f(x):=\sum_{n=0}^{+\infty}f_n(x)$$
  is well defined for $x>0$. Calculate its value in $1$. Study the function $f(x)$ and give asymptotic estimates for $x \to 0^+$ and $x\to +\infty$. Prove that the following equivalence holds:
  $$f(x)=e \sum_{n=0}^{+\infty}\frac{(-1)^n}{(x+n)n!}$$ I am having a hard time proving the equality in the third point. What I have done for now: $\textbf{Part 1}$ Using the ratio test,
$$\lim_{n\to +\infty}\frac{\prod_{k=0}^{n+1}\frac{1}{x+k}}{\prod_{k=0}^{n}\frac{1}{x+k}}=\lim_{n\to +\infty}\frac{1}{x+n+1}=0$$
 the series converges for $x>0$. The value of the function in $1$ is $$f(1)=\sum_{n=0}^{+\infty}\prod_{k=0}^{n}\frac{1}{k+1}=\sum_{n=0}^{+\infty}\frac{1}{(n+1)!}=e-1$$ $\textbf{Part 2}$ First of all, $f$ is positive for every $x>0$. Its monotonicity is immediate: if $x_2>x_1$, $$\begin{align} \quad \qquad \frac{1}{x_2+k}<\frac{1}{x_1+k} \end{align} \\
  \implies f(x_2)=\sum_{n=0}^{+\infty}\prod_{k=0}^{n}\frac{1}{x_2+k}\leq\sum_{n=0}^{+\infty}\prod_{k=0}^{n}\frac{1}{x_1+k}=f(x_1)$$ The general term of the series $f$ must be zero, because it converges; hence in an interval $[M,+\infty)$ with $M>0$ $$||f_n(x) ||_{\infty}=\prod_{k=0}^{n}\frac{1}{M+k}$$
$$\implies \sum_{n=0}^{+\infty}||f_n(x)|| \text{  is convergent}$$ so the series is uniformly convergent on every interval of the type $[M,+\infty)$. $f$ is asymptotic to $\frac 1x$ for $x\to +\infty$: in fact $$\lim_{x\to \infty}\frac{f(x)}{\frac{1}{x}}= \lim_{x\to \infty}  x\left (\frac{1}{x}+ \sum_{n=1}^{+\infty}\prod_{k=0}^{n}\frac{1}{x+k}\right )= 1 $$ because the series converges in a neighbourhood of $+\infty$. In a neighbourhood of $0$, the function acts similarly: we can notice that $$\lim_{x\to 0^+}\frac{f(x)}{\frac{1}{x}}=\lim_{x\to 0^+} x\sum_{n=0}^{+\infty}\prod_{k=0}^{n}\frac{1}{x+k}=\lim_{x \to 0^+} x\left (\frac{1}{x}+ \sum_{n=1}^{+\infty}\prod_{k=0}^{n}\frac{1}{x+k}\right )=  \lim_{x\to 0^+}  1 + \sum_{n=1}^{+\infty}\prod_{k=1}^{n}\frac{1}{x+k}$$ but $\sum_{n=1}^{+\infty}\prod_{k=1}^{n}\frac{1}{x+k}$ converges in $x=0$ and is continuous, so the limit is $$\lim_{x\to 0^+}\frac{f(x)}{\frac{1}{x}} = 1+  \sum_{n=1}^{+\infty}\prod_{k=1}^{n}\frac{1}{k}=e$$ hence $f \sim \frac{e}{x}$ Monotonicity and limits of this function imply that $f$ is a bijection of $(0,+\infty)$ in itself. $\textbf{Part 3}$ I have tried to manipulate the sums: writing a single fraction instead of the product does not seem to work: it leads to $$\sum_{n=0}^{+\infty}\prod_{k=0}^{n}\frac{1}{x+k}=\frac{1}{x}+\frac{1}{x}\frac{1}{x(x+1)}+\dots=\lim_{n\to +\infty}\frac{\sum_{h=0}^{n}\prod_{k=0}^h(x+k)}{\prod_{k=0}^{n}(x+k)}$$ It does not seem very familiar, even dividing it by $e=\sum_{n=0}^{+\infty}\frac{1}{n!}=f(1)$ Another idea that came to mind was to use the Cauchy product series and the Cauchy series product on the RHS : it leads to $$\sum_{i=0}^{+\infty}\frac{1}{i!}\sum_{j=0}^{+\infty}\frac{(-1)^j}{(x+j)j!}=\sum_{k=0}^{+\infty}\sum_{l=0}^{k}\frac{(-1)^{k-l}}{(x+k-l)l!(k-l)!}$$ Things seem as complicated as before. Integrating or derivating $f(x)$ term by term would require to know a general form for the integral/derivative of $f_n(x)=\prod_{k=0}^{n}\frac{1}{x+k}$: it does not appear impossible to find it, but I think it would not be of great practical use; moreover, the series does not converge uniformly on  the whole interval $(0,+\infty)$. The same goes for the series on the RHS . Working backwards, I thought of finding its integral/series on the interval $[M,+\infty)$ : I obtained $$\int \left (e\sum_{n=0}^{+\infty}\frac{(-1)^n}{(x+n)n!} \right ) dx =e\sum_{n=0}^{+\infty} \int \frac{(-1)^n}{(x+n)n!}  dx=e\sum_{n=0}^{+\infty}  \frac{(-1)^n}{n!}\log(x+n)+C $$ I can't get far from here, and I am not even sure if what I have done is correct. Question : Are the two first parts correct? What could be a good way of proving the equality in the third part?","['real-analysis', 'infinite-product', 'asymptotics', 'sequences-and-series']"
1581725,Induced scheme structure on an irreducible component?,"Suppose that $X$ is a non-reduced scheme of finite type over a field, with multiple irreducible components $X_1,\ldots,X_n$, possibly intersecting each other.  Is there a natural scheme structure on each $X_i$?  I don't want the reduced induced structure: for example, if $X$ is generically non-reduced on $X_i$, I want my induced structure on $X_i$ to be non-reduced. I am not sure if I should expect to have embedded points at $X_i \cap X$ or not.  Possibly there is not a canonical choice for this structure.",['algebraic-geometry']
1581728,What does it mean for a function to be Riemann integrable?,"I need to come up with a precise mathematical definition of what a Riemann integrable function is. I know what the Riemann integral is but when I look for definitions all I find are proofs of how to prove that a function is Riemann integrable. I need help creating a definition of what it means for a function to be Riemann integrable that does not include any notation, just a couple of mathematical sentences that defines Riemann integrals.","['real-analysis', 'riemann-integration']"
1581730,"Is there any error in my solution : If $\sum^n_{r=1} r^4=I(n), $ then $\sum^n_{r=1}(2r-1)^4$ is equal to ..","Problem : If $\sum^n_{r=1} r^4=I(n), $ then $\sum^n_{r=1}(2r-1)^4$ is equal to (a)  $I(2n)-16I(n)$ (b) $I(3n)-2I(n)$ (c) $I(2n)-I(n)$ (d) $I(2n)+I(n)$ Please suggest if there is some error in the following solution of mine will be of great help. Sol : $\sum^n_{r=1} r^4=I(n),  $ $ I(2n) = 1^4+2^4+3^4 + \cdots +(2n-1)^4 +(2n)^4$ $ = 1^4 +3^4 +\cdots (2n-1)^4 + 2^4 (1^4 +2^4 + \cdots n^4)$ $ I(2n) = \sum^n_{r=1} (2r-1)^4 +16 I(n),$","['algebra-precalculus', 'summation', 'solution-verification']"
1581745,Estimation of the n-th derivative of a complex function using Cauchy integral formula.,"I encountered this problem from ""Classical complex analysis"" by L.S. Hahn and B. Epstein, p.133. ""Let $f(z)$ be analytic in the unit disc $D$ and suppose that $$\left|f(z)\right| \leq \dfrac{1}{1-|z|}$$ for all $z \in D$. Show that $$\left|f^{(n)}(0)\right| \leq (n+1)!e.$$ The hint is to use the Cauchy integral formula with a path of integration suitably chosen for each $n$."" My attempt is: By the hypothesis, we have $|f(0)| \leq 1$ . Now let $r \in (0;1)$ and consider the circle $C(0,r)$. By the Cauchy integral formula and taking modulus of both sides, we have
$$|f^{(n)}(0)| = \left|\dfrac{n!}{2\pi i} \oint_{C(0,r)} \dfrac{f(z)}{z^{n+1}}\,dz \right| \leq \dfrac{n!}{2\pi } \oint_{C(0,r)} \left|\dfrac{f(z)}{z^{n+1}} \right|\,\left|dz\right|= \dfrac{n!}{(1-r)r^n}.$$
Now we have to choose $r$ (depend on $n$) so that $$\dfrac{1}{(1-r)r^n} \leq (n+1)e$$ and I got stuck at this step. I tried to remove the power $n$ of $r$ in the denumerator by using Bernoulli inequality, $$r^n = (1+(r-1))^n \geq 1+n(r-1)$$ and made the number $e$ appear by using the estimation $$1-r \geq e^{-2r}$$ but still couldn't work things out. Do you have any idea to find $r$ (depend on $n$)? Any help would be highly appreciated. Thanks in advance!","['cauchy-integral-formula', 'complex-analysis']"
1581751,"Show that this limit is positive,","I want to show that, for $\alpha = \frac{1}{2}$, $$\lim_{x \to 0} \sum_{n=1}^{\infty}\frac{x}{(1+nx^2)n^{\alpha}}>0$$ Any ideas are welcome. (In a previous question , I considered the case for $\alpha > \frac{1}{2}$, from which we were able to derive a uniform upper bound and use Weierstrass M-test and Dominated Convergence Theorem to establish the continuity of the series and evaluate the limit as $x \to 0$) Thanks,","['real-analysis', 'uniform-convergence', 'limits', 'convergence-divergence', 'sequences-and-series']"
1581784,Is a function that maps every compact set to a compact set continuous?,"A continuous function maps a compact set to a compact set. Is the converse of this true? That is, is a function that maps every compact set to a compact set necessarily continuous?","['general-topology', 'real-analysis']"
1581785,What does the false infinite sum of a series mean?,"For any geometric series with |$r$| < 1 , I know that $$\sum_{k=1}^{âˆž} ar^{k-1} =\frac{a}{1-r}$$ But if |$r$| > 1 and you try to use the formula, you'll get a weird answer. For instance: $$4+8+16+32+64+128+... =\sum_{k=1}^{âˆž} (4)2^{k-1}= \frac{4}{1-2} = -4$$ That answer obviously doesn't make sense; the series diverges. So what does -4 mean? Where did it come from, and how is it related to the series? It must be significant somehow.","['fake-proofs', 'summation', 'sequences-and-series']"
1581811,How to Prove the Chain Rule for Limits Using a $\varepsilon$-$\delta$ Argument?,I came across the chain rule for limits the other day and it interested me quite a bit and surprisingly I couldn't find the proof on the internet anywhere. From what I understand the chain rule for limits states that if: $$ \lim_{x\to c} g(x)=M$$ and $$\lim_{x\to M} f(x)=L$$ then$$\lim_{x\to c} \ f(g(x))=L$$ 1.Under what conditions does this hold true? 2.What is the epsilon-delta proof for the rule?,"['alternative-proof', 'limits', 'proof-verification', 'calculus', 'epsilon-delta']"
1581820,Find an element of largest order in the symmetric group $S_{10}$.,"Find an element of largest order in the symmetric group $S_{10}$. I know that given any element in $S_{10}$ there is a cycle decomposition and the order of it is the lcm of lengths of the cycles. So, we have to maximize $n_1.n_2....n_k$ so that $gcd(n_i, n_j)=1$ for $i\neq j$ and $n_1+n_2+...+n_k=10$. Moreover, $(n_1.n_2....n_k)|10!$. So, $n_1,...n_k$ must be a combination of some numbers of the set $\{1,2,...,10\}$. So how do I find that combination rigorously? Do I need to write all possibilities and decide?(I think there are many). Intuitively, I think the solution must be $2\times 3\times 5=30$. But how?","['group-theory', 'symmetric-groups']"
1581828,Relations in Group Presentation,"In an introduction to abstract algebra, I was recently introduced to the idea of presenting a group - minimally, a group is just a set of generators along with a set of relations amongst the generators. I believe that I have, at least, a rather basic understanding of this idea. On the other hand, I don't quite understand when one knows that they have a sufficient amount of relations to uniquely characterize the group at hand. For example, a common example for generators and relations is the Dihedral group $ D_n = \{ \rho, \tau : \;\rho^n = 1, \tau^2 =1, \tau\rho\tau^{-1}=\rho^{-1} \}$. Clearly there are two generators here: a rotation $ \rho $ by an angle $ 2\pi/n$ and a reflection $ \tau $. What I don't understand is exactly how one knows that these three relations as listed are sufficient to characterize the group. When listing the relations, I see that each of these properties are true, but how does one know that they cannot stop with just $ \rho^n = 1$ and $ \tau^2= 1 $, the most basic properties of $D_n$? A small bit of clarification here would be greatly appreciated as I feel as though I am missing something obvious.","['abstract-algebra', 'group-presentation']"
1581835,Irreducible polynomials over $\mathbb Q$ and $\mathbb Z $,"When I read "" Contemporary Abstract Algebra "" by Joseph gallian, under the topic irreducible polynomials, his first example is the 
polynomial $$2x^2+4=0$$ is reducible over $\mathbb  Z$ but irreducible over
$ \mathbb Q$. I dont know how is this possible? Since it is of degree 2, we can see the roots of the polynomial, where it lies? if it lies in $\mathbb Z$ then it would lie in $ \mathbb Q$, then how can it be reducible over $\mathbb Z$ when the roots are complex numbers? pls explain","['irreducible-polynomials', 'abstract-algebra', 'ring-theory', 'polynomials']"
1581868,An infinitely powered expression [duplicate],"This question already has answers here : Are these solutions of $2 = x^{x^{x^{\:\cdot^{\:\cdot^{\:\cdot}}}}}$ correct? (4 answers) Closed 8 years ago . Here's an expression I am struggling to evaluate:
$$\LARGE
  {\sqrt{2}^{\sqrt{2}^{\sqrt{2}^{\:\cdot^{\:\cdot^{\:\cdot}}}}}}
$$ The value turns out be $2$, but I don't understand how do we get it. Can anyone give the solution? EDIT: The original problem is as follows: If $y(x)= { x }^{ { x }^{ { x }^{ { x }^{.  } } } }$, then evaluate $y(\sqrt { 2 })$.","['algebra-precalculus', 'calculus']"
1581872,Is there any popular name for this theorem in the standard literature?,"Let $X$ be a normed space. Then $X$ is a Banach space if and only if the absolute convergence of any series in $X$ implies the conditional convergence of that series. Is there any name given to the above result in the standard literature on the normed space theory? And, is there any name given to the property of absolute convergence of a series implying conditional convergence? How do we prove this theorem? My effort: Suppose that $X$ is a Banach space. Let $\sum_n x_n$ be an absolutely convergent series in $X$. Then the sequence $(\alpha_n)_{n\in \mathbb{N}}$, where 
$$\alpha_n \colon= \Vert x_1 \Vert + \cdots + \Vert x_n \Vert \ \mbox{ for all } \ n \in \mathbb{N},$$
is a Cauchy sequence in $\mathbb{R}$. Thus, given a real number $\epsilon>0$, we can find a natural number $N$ such that 
$$\vert \alpha_m - \alpha_n \vert < \epsilon \ \mbox{ for all } \ m, n \in \mathbb{N} \ \mbox{ such that } \ m > N \ \mbox{ and } \ n > N. $$
Now let $m, n \in \mathbb{N}$ such that $n > m > N$. Then 
$$
\begin{align}
\left\Vert \sum_{k=1}^n x_k - \sum_{k=1}^m x_k\right\Vert 
&= \left\Vert \sum_{k=m+1}^n x_k \right\Vert \\ 
&\leq \sum_{k=m+1}^n \Vert x_k \Vert \\ 
&= \alpha_n - \alpha_m \\
&= \vert \alpha_n - \alpha_m \vert \\
&< \epsilon.
\end{align}
$$
Thus the sequence $\left(\sum_{k=1}^n x_k \right)_{n\in\mathbb{N}}$ of partial sums of the series $\sum_n x_n$ is Cauchy and hence convergent. Conversely, suppose that the absolute convergence of any series in $X$ implies convergence of that series. Suppose that $(x_n)$ is a Cauchy sequence in $X$. We need to show that this sequence converges in $X$. How to?","['real-analysis', 'normed-spaces', 'functional-analysis', 'absolute-convergence', 'analysis']"
1581896,Formula for all possible sums of a binary sequence,"Suppose I have a sequence, where for each element I can choose one out of two numbers. I would like to find a compact formula to write all the possible sums of all the possible sequences. For example, suppose I have $\langle(1,2), (3,4) \rangle$ The possible sequences are $\langle 1, 3 \rangle$, $\langle 1, 4 \rangle$, $\langle 2, 3\rangle$, $\langle 2, 4\rangle$ and therefore all the possible sums are $4, 5, 5, 6$ respectively.","['combinatorics', 'np-complete']"
1581922,"If $f(x.y)=f(x).f(y)$ for all $x,y$ and $f(x)$ is continuous at $x=1$,then show that $f(x)$ is continuous for all x except at $x=0$.Given $f(1)\neq 0$","If $f(x.y)=f(x).f(y)$ for all $x,y$ and $f(x)$ is continuous at $x=1$,then show that $f(x)$ is continuous for all x except at $x=0$.Given $f(1)\neq 0$ In the functional equation $f(x.y)=f(x).f(y)$,put $x=1,y=1$ $f(1)=f(1).f(1)\Rightarrow f(1)=1$ because $f(1)\neq 0$ As $f(x)$ is continuous at $x=1$,so $\lim_{x\to 1}=f(1)=1$ Now take any number $x_0\neq 0$ Put $x=x_0$ in the equation $f(x.y)=f(x).f(y)$ $\lim_{x\to1}f(x_0.x)=f(x_0).f(x)=f(x_0)\lim_{x\to1}f(x)=f(x_0).1=f(x_0)$ So i proved $\lim_{x\to1}f(x_0.x)=f(x_0)$ Therefore $f(x)$ is continuous at all non zero numbers. But i do not know how to prove that $f(x)$ is not continuous at $x=0.$Please help me.Thanks.","['continuity', 'limits']"
1581964,Construction of new ellipse,"Using a pencil, the thread was pulled on the ellipse. Then the pencil started to rotate around the ellipse. How to prove that the new geometric figure which the pencil drew is also an ellipse (with the same foci as the first ellipse)?","['analytic-geometry', 'conic-sections', 'geometry']"
1581967,Is $\int_{M_{n}(\mathbb{R})} e^{-A^{2}}d\mu$ a convergent integral?(2),"We  identify $M_{n}(\mathbb{R})$ with $\mathbb{R}^{n^{2}}$ We put $\int_{M_{n}(\mathbb{R})} e^{-A^{2}}d\mu=\lim_{r\to \infty}  \int_{D_{r}} e^{-A^{2}}$  where the later is  counted as a Riemann integral not Lebesgue integral. Here $D_{r}$  is the disc of radius $r$ with respect to the Euclidean  norm of $\mathbb{R}^{n^{2}}$. Is the above integral a convergent improper integral? What about if we consider $D_{r}$  with respect to the matrix norm? The following post shows that this integral is not convergent in the Lebesgue sense. It also shows that if it is Riemann convergent, then the value of integral is  an scalar matrix. Is $\int_{M_{n}(\mathbb{R})} e^{-A^{2}}d\mu$ a convergent integral?","['real-analysis', 'matrices', 'gaussian-integral', 'integration', 'improper-integrals']"
1581968,Olympiad problem on the prime numbers,"Let $P={2,3,5,7,11,...}$ denote the set of all prime numbers less than ${ 2 }^{ 100}$ . Prove that $\sum _{ p\in P }^{  }{ \frac { 1 }{ p }  } < 8$ . I don't understand how to progress in the problem. Any help would appreciated. Thank you.",['number-theory']
1581969,"A Lie group that has an immersion in $\mathrm{GL}(n,\Bbb R)$ but no embedding?","Question: Is there a Lie group $G$ that admits a smooth immersion
  $$i:G\longrightarrow\mathrm{GL}(n,\Bbb R)$$
  for some $n\in\Bbb N$, but no smooth embedding
  $$j:G\longrightarrow\mathrm{GL}(m,\Bbb R)$$
  for any $m\in\Bbb N$? (Here, $i$ and $j$ are also required to be group homomorphisms.) The usual example of a Lie group which is immersed but not embedded is the group $\Bbb R$ with the immersion
$$i:\Bbb R\longrightarrow\mathrm{GL}(2,\Bbb C),\quad t\longmapsto\begin{pmatrix}e^{it} & 0 \\ 0 & e^{i\alpha t}\end{pmatrix}$$
for $\alpha$ irrational. The so-called dense curve on the torus . However, here $\Bbb R$ do embed in $\mathrm{GL}(n,\Bbb R)$, but just in a different way:
$$j:\Bbb R\longrightarrow \mathrm{GL}(2,\Bbb R),\quad t\longmapsto\begin{pmatrix}1 & t \\ 0 & 1\end{pmatrix}.$$ There are also well-known groups that have no injective homomorphism into $\mathrm{GL}(n,\Bbb R)$, but then they do not immerse either.","['smooth-manifolds', 'group-theory', 'representation-theory', 'differential-geometry', 'lie-groups']"
1581985,"Automorphisms of the affine semilinear group $A\Gamma L(1,2^{n})$","In this question, it is mentionned that the group of automorphisms of the semilinear group $A\Gamma L(1,2^{n})$ is the group itself. Do you have a short proof of this fact?","['finite-groups', 'finite-fields', 'semidirect-product', 'group-theory']"
1581987,"How to see that if the following integral is finite, the second moment is finite as well?","How to see that if for some random variable $X$
$$\int_0^\infty\sqrt{P(|X|> t)}dt<\infty,$$
then $E|X|^2<\infty$. To show this I have a hint that
$$E|X|^2\leq 2\int_0^\infty P(|X|\geq u)udu \leq 2\int_0^\infty\sqrt{P(|X|> t)}dt\|X\|_2.$$ The first statement follows, since
$$E|X|^2 = \int_\Omega|X(\omega)|^2dP(\omega) = \int_\Omega\int_0^{|X(\omega)|^2}dtdP(\omega) = \int_0^\infty\int_\Omega\mathbf{1}_{\{\omega:\;|X(\omega)|^2>t\}}dP(\omega)dt = \int_0^\infty P(|X|>\sqrt{t})dt=2\int_0^\infty P(|X|>u)udu.$$ I fail to see the second inequality.",['probability-theory']
1582038,Prove that exists such $i$ that $\frac{x_i}{y_i}\geqslant\frac{X}{Y}$,"Let $\sum_{i=1}^n x_i \geqslant X$ and $\sum_{i=1}^n y_i \leqslant Y$ and $X, Y > 0$. Prove that exists such $i$ that $\frac{x_i}{y_i}\geqslant\frac{X}{Y}$. I think that it could be proved using one of the following ways: pigeonhole principle, induction, by contradiction. But I got stuck. For example when we try to show it by contradiction we can write that for all $i$ (if $\sum_{i=1}^n y_i$ is positive) $$\frac{x_i}{y_i} < \frac{X}{Y}$$
$$\sum_{k=1}^n y_k\frac{x_i}{y_i} \leqslant Y\frac{x_i}{y_i} < X \leqslant \sum_{j=1}^n x_j $$
$$\sum_{k=1}^n y_k\frac{x_i}{y_i} < \sum_{j=1}^n x_j $$
$$\frac{x_i}{y_i} < \frac{\sum_{j=1}^n x_j}{\sum_{k=1}^n y_k}$$
But I don't know how it can be useful. Do you have some hints?","['inequality', 'discrete-mathematics']"
1582039,"Let $X$ an infinite $T_1$ space, then exist some subspace homeomorphic to $(\Bbb N,\tau)$ where $\tau$ is discrete or cofinite","My attempt to prove the statement of the title: if $X$ is infinite and $T_1$ with topology $\tau_1$ then any basis for $X$ is infinite too. If $X$ is $T_1$ then for any $x, y\in X$ with $x\ne y$ exists some open sets $U$ and $V$ such that $x\in U \land y\notin U$ and $x\notin V \land y\in V$. $\color{red}{(1)}$ If you extend this analysis for a finite subset $F\subset X$ you can create a collection $\mathcal{U}$ of open sets where $\forall x_i,x_j\in F,\ i\ne j,\ \exists U_i\in\mathcal{U}:\ (x_i\in U_i)\land (x_j\notin U_i)$. Then $F\bigcap(\bigcap_{i=0}^{n} U_i)=\varnothing$ and $\mathcal {U}=\{U_i\}$ but $\bigcap_{i=0}^{n} U_i\in\tau_1$ due the definition of topology (and remember $F$ is finite). Then: If exists some countable infinite collection of disjoint open sets for the basis of $X$ then if we take some point belonging to any of these disjoint basic open sets then the resulting subspace is obviously homeomorphic to $\Bbb N$ with the discrete topology. If doesnt exist an infinite collection of disjoint basic open sets we have that exist an infinite collection of non-disjoint open sets. If we take infinite countable points each one belonging to a different but non-disjoint open set and cause the space is $T_1$ we have that for every open set at most a finite number of points ($F$ in the expression $\color{red}{(1)}$) not belong to them cause the statement on $\color{red}{(1)}$, so the subspace is homeomorphic to $\Bbb N$-cofinite. Question: I feel my proof correct but not enough clear, maybe you can point how to clear it or if it lacks something? The expression on $\color{red}{(1)}$ is enough understandable? Thank you in advance. EDITION: the expression $\color{red}{(1)}$ is very hard to write it correctly to me by now, so Im going to describe in words: you can extend the definition of $T_1$-space not only to some $x,y\in X$ if not to $x_1,x_2,x_3,...,x_n\in X$. If you make all considerations then exist some $U_i$ for every $x_i$ where $x_i\in U_i$ but the others points does not belong to $U_i$. These collection of $U_i$ I call $\mathcal{U}$. The intersection of every $U_i$ belongs to $\tau_1$ because is a finite intersection of open sets, and no one $x_i$ belongs to this intersection, obviously, and these $x_i$ are finite. This is what I wanted express on $\color{red}{(1)}$, sorry for the inconvenience :S","['general-topology', 'proof-writing', 'proof-verification']"
1582055,Limit of a periodic function,"I stumbled upon this question in my course, and I am out of ideas. Let $f$ be a periodic function $$f(x)=f(x+l), \qquad l>0$$ Prove that if it is not constant, then $\lim_{x\to 0}f\left(\frac1x\right)$ does not exist. I don't understand why it's true, let alone how to prove it.","['real-analysis', 'periodic-functions', 'calculus', 'limits']"
1582061,Finding the radius of a circle inside of a triangle,"What is the measure of the radius of the circle inscribed in a triangle whose sides measure $8$, $15$ and $17$ units? I can easily  understand that it is a  right angle triangle  because of the given edges.  but I don't find any  easy formula to find the radius of the circle.",['geometry']
1582062,I would like to calculate $\lim_{x \to \frac{\pi}{6}} \frac{2 \sin^2{x}+\sin{x}-1}{2 \sin^2{x}-3 \sin{x}+1}$,"I want to calculate the following limit: $$\lim_{x \to \frac{\pi}{6}} \frac{2 \sin^2{x}+\sin{x}-1}{2 \sin^2{x}-3 \sin{x}+1}$$
or prove that it does not exist. Now I know the result is $-3$, but I am having trouble getting to it. Any ideas would be greatly appreciated.","['real-analysis', 'calculus', 'limits']"
1582106,I want to calculate the limit of: $\lim_{x \to 0} \left(\frac{2^x+8^x}{2} \right)^\frac{1}{x} $,"I want to calculate the limit of: $$\lim_{x \to 0} \left(\frac{2^x+8^x}{2} \right)^\frac{1}{x} $$
or prove that it does not exist. Now I know the result is $4$, but I am having trouble getting to it. Any ideas would be greatly appreciated.","['real-analysis', 'limits']"
1582122,Basic algebra (composite functions),"The question is $h(x)=\frac{(1+x)}{(1-x)}$
find $h(1-x)$ I understand how to solve the question, it's: $1+\frac{(1+x)}{(1-x)}$ What I can't seem to understand is why the denominator $1-(1-x)$ equals $x$ and not $-x$ I'm guessing that it's because the $-$ cancels out, but since it's not multiplication (e.g $-2(1-3)=-2+6$) why does it still cancel out? Why can't it be answered as $1-1-x=-x$?","['algebra-precalculus', 'function-and-relation-composition']"
1582132,The chart-problem; problem solving,"In how many ways can we construct a $6\times 6$ chart with only $1$ and $-1$ such that in every row and column, the product is always positive?","['combinatorics', 'problem-solving']"
1582147,A locally finite Borel measure on a locally and $\sigma$ compact metric space is a Radon measure,"Let $X$ be a locally compact metric space which is $\sigma$-compact, and let $\mu$ is an unsigned Borel measure which is finite on every compact set. Show that $\mu$ is a Radon measure. I know that every unsigned Borel measure on a compact metric space which is $\sigma$-compact is a Radon measure. From the assumption, we only need to verify outer regularity and inner regularity. Inner regularity is easier, since we can write $X$ as a countable union and compacts sets $K_n$, and a closed set in each $K_n$ is also a closed set in $X$. I have difficulty verifying outer regularity, open set in $K_n$ may not be open in $X$.",['real-analysis']
1582155,Find an unbound sequence in which $a_{n+1}$ - $a_n$ converges to zero,"Find an unbound monotonic increasing sequence in which $a_{n+1}$ - $a_n$ converges to zero. I've been thinking about this one for a while. found it in an exam from seven years ago.
I don't know if the answer is hidden in some rule we've learned or are we just expected to be creative.","['convergence-divergence', 'sequences-and-series', 'calculus']"
1582201,Show that $f(z)$ can be extended to all of $\mathbb{C}$ as an entire function.,"Let $f(z)$ be analytic in the unit disc $D$. Suppose there is a constant $M$ such that $$\left|f^{(n)}(0)\right| \leq M^n$$ for all n sufficiently large. Show that $f(z)$ can be extended to all of $\mathbb{C}$ as an entire function. My idea is to construct a function $g(z)$ whose restriction to $D$ is $f(z)$, and prove that its Taylor series has infinite radius of convergence, which means it is an entire function. But I do not know how to do that. Do you have any idea? Any help would be highly appreciated! Thank you in advance!",['complex-analysis']
1582219,Show that the root of $x^{1/3}=1-x$ lies between $0$ and $1$ using the intermediate value theorem,"I am currently doing a problem that asks me to use the intermediate value theorem to show that $x^{1/3}=1-x$ lies between $0$ and $1$. I want to start by evaluating the function at $0$ and $1$, but it seems the function is undefined because if you plug in $1$, you get $1=0$. This doesn't seem right. Is my interpretation correct? The problem comes from Stewart's Calculus section 2.5, q 48.",['algebra-precalculus']
1582259,$\lim_ {n \to \infty} f_n$ is $\Sigma$-measurable,"Let $(X,\Sigma)$ be a measurable space and let $\{f_n\}_{n \in \mathbb{N}}$ be a sequence of $\Sigma$-measurable  real valued functions with domains included in $X$. What does it mean to say ""domains included in $X$""? Why is this significant? We define a function $\lim\limits_{n \to \infty} f_n$ by writing $$\lim\limits_{n \to \infty} (f_n)(x) = \lim\limits_{n \to \infty} f_n (x)$$ for $x \in \cup_{n \in \mathbb{N}} \cap_{m \geq n} \text{dom } f_m$ for which the limit exists in $\mathbb{R}$. Then $\lim\limits_{n \to \infty} f_n$  is $\Sigma$-measurable. What does $x \in \cup_{n \in \mathbb{N}} \cap_{m \geq n}\text{dom } f_m$ mean? How can it be interpreted?",['measure-theory']
1582294,Intuition behind tail events?,"I am studying now Probability Theory and when I came to Kolmogorov's law 0-1 I met with tail events. Despite, formal definition it is little hard to understand the intuition of tail events. I am asking a favour for those who are more deep in probability theory to explain tail events and may this question can be useful also for the others. Thanks in advance.",['probability-theory']
1582313,Intuition for Kuratowski-MrÃ³wka characterization of compactness,"Fact. A space $X$ is compact iff for every space $Y$, the projection $X\times Y\rightarrow Y$ is a closed map. The finite subcover definition of compactness seems reasonably intuitive: finite covers mean it can't be too ""spread out"". This fits in with the characterization by nets, which are just there because sequences may have too few points to measure problems. I have no intuition whatsoever for this characterization. How should one visualize it, why should one expect it, etc?","['intuition', 'general-topology', 'compactness']"
1582342,Geometric intuition behind locality of morphisms of locally ringed spaces,"Let $(X,\mathcal O_X)$ be a locally ringed space. The examples I have in mind are sheaves of continuous/$C^k$/smooth/etc. functions over a suitable topological space. The direction $f^\sharp:\mathcal O_Y\rightarrow f_\ast\mathcal O_X$ of a morphism $(X,\mathcal O_X)\rightarrow (Y,\mathcal O_Y)$ is clear to me, but I am struggling to understand the geometric significance of respecting the maximal ideals. I don't know commutative algebra so excuse the question if it's a well discussed triviality. First, let's switch from $f^\sharp:\mathcal O_Y\rightarrow f_\ast\mathcal O_X$ to $f^\flat:f^\ast\mathcal O_Y\rightarrow \mathcal O_X$. Now we can look at a map between the stalks at $x\in X$:
$$\mathcal O_{Y,f(x)}\rightarrow \mathcal O_{X,x}$$
The maximal ideal $\mathfrak m_{f(x)}\vartriangleleft \mathcal O_{Y,f(x)}$ is comprised of the nonzero germs at $f(x)$. These are just the locally non-invertible functions at $f(x)$. To map $\mathfrak m_{f(x)}$ into $\mathfrak m_x$ is to say we do not accidentally invert any nonunits in $\mathcal O_{Y,f(x)}$. This sounds like a good thing at the formal level, but what are some interesting geometric examples in which not being a local homomorphism has unpleasant consequences?","['algebraic-geometry', 'commutative-algebra']"
1582348,"Simple example of ""Maximum A Posteriori""","I've been immersing myself into Bayesian statistics in school and I'm having a very difficult time grasping argmax and maximum a posteriori .  A quick explanation of this can be found: https://www.cs.utah.edu/~suyash/Dissertation_html/node8.html Basically theta is a set of parameters and x is the data, P of theta given x (posterior) equals P of x given theta (likelihood term) multiplied by P of theta (prior term) and all of that divided by P of x (to normalize).  Not sure exactly how dividing by P(x) normalizes this but thats not my main question. Then, you maximize the posterior with argmax I believe your maximizing the set of parameters to get the most likely posterior ... Can someone please give a simple example of this so I can visualize what is happening?","['probability-theory', 'bayesian', 'maximum-likelihood', 'statistics', 'probability']"
1582370,Solution to $xe^{e^x}$,"The problem $xe^{e^x}=e$ came up another day and I wondered if it were solvable. My attempt was the following substitution,$$x=W(u)$$$$W(u)e^{e^{W(u)}}=e$$Where I used a Lambert W identity to get $$W(u)e^{\frac u{W(u)}}=e$$And attempted to solve. I got this far:$$-\frac1{W(u)}e^{-\frac u{W(u)}}=-\frac1e$$However, I couldn't continue.  Its so darn close... but alas, its not quite there. So I've come to you guys for help, well knowing that most of you will say ""no solution"" of closed form, but that's ok.  I will even accept answers that attempt to continue or start from the beginning to try out a different path for the solution. I also considered the following: If you could get into a form where adding/subtracting/multiplying/dividing/whatever will cancel a part of the equation with a previous form, then that'll be great e.g.$$f(u)W(u)=g(u)$$$$xf(u)=W(u)$$Divide the two and you get $$\frac{W(u)}x=\frac{g(u)}{W(u)}$$$$W^2(u)=xg(u)$$Noting that you can switch around with substitutions as long as you are consistent with your substitutions. I also realize that in the beginning, I could have used the substitution $x=-W(x)$ to flip the resulting fraction to put the $W$ on top and repeat the Lambert identity process, only to create$$-W(u)[\frac{u}{W(u)}]^{1/u}=e$$ Which is still not solvable!","['special-functions', 'lambert-w', 'exponential-function', 'functions']"
1582384,Prove that $e>2$ geometrically.,"Q: Prove that $e>2$ geometrically. Attempt: I only know one formal definition of $e$ that is $\lim_\limits{n\to\infty} (1+\frac{1}{n})^n=e$. I could somehow understand that this is somehow related to rotation in the complex plane.
$$e^{i\theta}=\cos \theta + i \sin \theta$$
Hence we have $$e^{i\pi}=-1$$
But how can I bring out the value of $e$ when I am showing this rotation in a geometrical figure? Any hints are appreciated. EDIT: As per the comments, I am making a small addition to the question which will not affect the existing answers. It is that, as a definition of $e$, one can use any definition which does not use the fact $2<e<3$.","['contest-math', 'exponential-function', 'geometry']"
1582388,I would like to calculate $\lim_ {n \to \infty} {\frac{n+\lfloor \sqrt{n} \rfloor^2}{n-\lfloor \sqrt{n} \rfloor}}$,"I would like to calculate the following limit: $$\lim_ {n \to \infty} {\frac{n+\lfloor \sqrt{n} \rfloor^2}{n-\lfloor \sqrt{n} \rfloor}}$$
where $\lfloor x \rfloor$ is floor of $x$ and $x âˆˆ R$. Now I know the result is $2$, but I am having trouble getting to it. Any ideas would be greatly appreciated.","['real-analysis', 'ceiling-and-floor-functions', 'calculus', 'limits']"
1582392,Find $f(c)$ given the graph of $f'(x)$,"I am given a graph of the derivative of some function and asked to find $f(c)$.
I can't explain it well without the graph, so here is the image of the problem: First of all, should't the point labeled on the graph as $(3,2)$ be $(2,3)$?
Second, wouldn't $f(6)$ be the integral from $0$ to $6$ of the graph?
If so, then I have the area of the square $(3*2)$ plus the first triangle $(3)$ minus the third triangle $(1)$, giving me an answer of $8$. Is this incorrect?  Why do I need to know that $f(0)=7$?","['calculus', 'functions']"
1582408,"If $d(f\omega)=0$, then $\omega \wedge d(\omega)=0$","Here's the question: Suppose that $\omega$ is a $k$-form on an open set $U$ of $\mathbb{R}^n$ and $f:U \to \mathbb{R}$ is a $C^\infty$ function such that $f(x) \neq 0$, for all $x \in U$, and $d(f\omega)=0$. Prove that $\omega \wedge d(\omega)=0$ My attempts so far: Differentiate the product $f\omega$, and take the wedge product with $\omega$: $$d(f\omega)=df\wedge\omega + f d\omega=0$$
$$\Rightarrow \omega \wedge df\wedge\omega + f \omega \wedge d\omega=0$$ I see 2 cases: If $k$ is odd: then the product $\omega \wedge \omega$ must be zero, since if the commutation formula is used: $$\omega \wedge \omega = (-1)^{k^2} \omega \wedge \omega = - \omega \wedge \omega$$ Then, commutating $df$ above with $\omega$ (with a sign that comes out, no problem) and dividing by $f$, which is valid since $f$ is never zero, yields the result. If $k$ is even: I don't really see how to extend the above argument. I'm worried I might have to toss it away and try with another tool. Or maybe I'm missing something very fundamental in here. Any suggestion or solution is welcome. Thanks!","['differential-forms', 'differential-geometry']"
1582477,"Why do we need ""span"" in linear algebra?","In my linear algebra course in university we started learning about span and I was curious what is it good for? and if someone know, how does it relate to 3D graphics? Thank you.","['linear-algebra', 'span']"
1582491,Recurrence for expected length of Gaussian vector,"Let $g_k \sim N(0, I_{k \times k})$ be a a standard $k$-dimensional Gaussian vector. Denote by $\|g\|$ the $2$-norm of $g$. By explicit integration, it is not hard to see that
$$
\mathbb E \|g_k\| = \frac{\sqrt 2 \Gamma\left(\frac{k+1}{2}\right)}{\Gamma\left(\frac k 2\right)}\,,
$$
where $\Gamma$ is the Gamma function. In particular, the above expression implies
\begin{equation*}
\mathbb E \|g_k\|\mathbb E\|g_{k+1}\| = k\,.
\end{equation*} This formula gives a nice recurrence for the expected length of a standard Gaussian. The recurrence is so nice that I'd like to see a slick proof of this fact, if one exists. Question : Is there an elegant proof of the recurrence $\mathbb E \|g_k\|\mathbb E\|g_{k+1}\| = k$, one that involves no explicit integration?","['recurrence-relations', 'expectation', 'probability', 'normal-distribution']"
1582500,Reference for low-dimensional topology,"I have read topology and algebraic topology by Munkres and I want to start low-dimensional topology.
What is a good reference for starting low-dimensional topology?","['low-dimensional-topology', 'reference-request', 'general-topology', 'book-recommendation']"
1582501,Show that $P(T \le n + N \mid \mathscr F_n) > \epsilon$ where T is a stopping time,"Given random variables $Y_1, Y_2, \ldots \stackrel{iid}{\sim} P(Y_i = 1) = p = 1 - q = 1 - P(Y_i = -1)$ where $p > q$ in a filtered probability space $(\Omega, \mathscr F, \{\mathscr F_n\}_{n \in \mathbb N}, \mathbb P)$ where $\mathscr F_n = \mathscr F_n^Y$, define $X = (X_n)_{n \ge 0}$ where $X_n = a + \sum_{i=1}^{n} Y_i$ where $0 < a$. It can be shown that the stochastic process $M = (M_n)_{n \ge 0}$ where $M_n = X_n - n(p-q)$ is a $(\{\mathscr F_n\}_{n \in \mathbb N}, \mathbb P)$-martingale. Let $b > a$ be a positive integer and $T:= \inf\{n: X_n = 0 \ or \ X_n = b\}$. It can be shown that $T$ is a $\{\mathscr F_n\}_{n \in \mathbb N}$-stopping time . Show that $\exists N \in \mathbb N, \epsilon > 0$ s.t. $\forall n \in \mathbb N$, $$P(T \le n + N \mid \mathscr F_n) > \epsilon \ a.s.$$ What I tried: By using induction on n, we have for the base case: Suppose $P(T \le N) > \epsilon$. Show that $P(T \le N+1 | \mathscr F_1) > \epsilon$. I tried considering $P(T \le N+1 | \mathscr F_1)$ and then hopefully I could use the assumption somewhere: $$P(T \le N+1 | \mathscr F_1) = E[1_{T \le N+1} | \mathscr F_1]$$ $$= E[1_{T \le N} 1_{T = N+1} | \mathscr F_1]$$ $$= E[E[1_{T \le N} 1_{T = N+1} | \mathscr F_N] | \mathscr F_1]$$ $$= E[1_{T \le N} E[ 1_{T = N+1} | \mathscr F_N] | \mathscr F_1]$$ Now what is $E[ 1_{T = N+1} | \mathscr F_N]$ exactly? Well, up to time N we have already hit $X_n = b$, or we haven't. If we have, then $E[ 1_{T = N+1} | \mathscr F_N] = 0$. Otherwise, $E[ 1_{T = N+1} | \mathscr F_N] = p1_{X_{N} = b-1}$. Continuing: $$= E[1_{T \le N} p1_{X_{N} = b-1} | \mathscr F_1]$$ $$= pE[1_{T \le N} 1_{X_{N} = b-1} | \mathscr F_1]$$ $$= pE[1_{T \le N-1} 1_{X_{N} = b-1} | \mathscr F_1]$$ Similarly, I got $$= p^2 E[1_{T \le N-2} 1_{X_{N-1} = b-2} | \mathscr F_1]$$ $$= p^2 E[1_{T \le N-2} E[1_{X_{N-1} = b-2} | \mathscr F_{n-2}] | \mathscr F_1]$$ However, I'm not quite sure that $$E[1_{X_{N-1} = b-2} | \mathscr F_{n-2}] = p1_{X_{N-2} = b-3}$$ I think we have that $$E[1_{X_{N-1} = b-2} | \mathscr F_{n-2}] = p1_{X_{N-2} = b-3} + q1_{X_{N-2} = b-1}$$ Um, am I on the right track? Did I make a mistake somewhere?","['stochastic-processes', 'random-walk', 'probability-theory', 'stopping-times', 'martingales']"
1582506,"Understanding proof by algebraic geometry, Fermat's last theorem for polynomials when $n = 3$.","This is a followup to my question here . See here . The question is as follows. How do we see that there do not exist nonconstant, relatively prime, polynomials $a(t)$ , $b(t)$ , and $c(t) \in \mathbb{C}[t]$ such that $$a(t)^3 + b(t)^3 = c(t)^3?$$ There is the following answer, the ""better motivated proof where you see that $\mathbb{CP}^1$ can't map holomorphically to a genus $1$ curve."" Let $a(t)$ , $b(t)$ , $c(t)$ have degree $n_1$ , $n_2$ , $n_3$ , respectively, and $n = \text{max}(n_1, n_2, n_3)$ . Then we can define $A(u, v)$ , $B(u, v)$ , $C(u, v)$ as homogeneous polynomials of degree $n$ such that $$A(u, 1) = a(u),\text{ }B(u, 1) = b(u),\text{ }C(u, 1) = c(u).$$ Then, by construction, $$A(u, v)^3 + B(u, v)^3 = C(u, v)^3.$$ Let $$E = \{(x, y, z) \in \mathbb{P}^2 : x^3 + y^3 = z^3\}.$$ $E$ is a smooth curve of genus $1$ , i.e. an elliptic curve. Now, define a map $$\varphi: \mathbb{P}^1 \to E,\text{ }(u, v) \mapsto (A(u, v), B(u, v), C(u, v)).$$ This map is well-defined since $A(u, v)$ , $B(u, v)$ , $C(u, v)$ are homogeneous polynomials of the same degree which do not vanish simultaneously. Moreover, this map is nonconstant and proper since its source is projective. As the image of a proper map is closed and it is not a point, and $E$ is an irreducible $1$ -dimensional variety follows that $\varphi$ is a surjective morphism. $E$ is a topologically a torus, i..e it has genus $1$ and there is a one up to scaling differential form $\tau$ on it. This will imply that its pullback $\varphi^*\tau$ is a differential form on $\mathbb{P}^1$ , which is impossible since it has genus $0$ . In more formal terms, a surjective map $\mathbb{P}^1 \to E$ gives rise to the injection $H^0(E, \Omega^1) \to H^0(\mathbb{P}^1, \Omega^1)$ . But this is absurd, since the former is a vector space of dimension $1$ and the latter is a vector space of dimension $0$ . Perhaps you might want to say something about why the pullback of a non-zero holomorphic differential is non-zero. $X$ and $Y$ are Riemann surfaces and $f: X \to Y$ holomorphic differential form looks like $g(z)\,dz$ , where $g$ is a holomorphic function. Then its pullback is locally given by $g(f(z))\,df$ . It is obviously nonzero as long as $f$ is nonconstant. Unfortunately, I do not know any algebraic geometry and do not really understand what is going on. Can anyone summarize/explain the motivation/explain what is going on/explain the key steps/help me understand the proof? Thanks.","['intuition', 'algebraic-geometry', 'abstract-algebra', 'number-theory', 'elliptic-curves']"
1582515,smooth functions are dense in the space of bounded continuous functions - why? [duplicate],"This question already has an answer here : Is it possible to write any bounded continuous function as a uniform limit of smooth functions (1 answer) Closed 8 years ago . Let $C_b $ be the space of real valued bounded continuous functions that are defined on $\mathbb {R} $. Let  $S $ be the subset of smooth functions in  $C_b $. My probability theory book states the following without proof: $S $ is dense in $C_b$ Why is this true? The book does not mention it but I guess that  $C_b $ is equipped with the norm  $||\,\,||_{\infty}$ Thank you a lot.","['functional-analysis', 'analysis']"
1582536,I would like to prove the following series: $\sum_{n=1}^\infty {\frac{\sin{\frac{\pi}{n}}}{n}}\cdot(x-2)^n $ is convergent,"I would like to prove the following series: $$\sum_{n=1}^\infty {\frac{\sin{\frac{\pi}{n}}}{n}}\cdot(x-2)^n $$ is convergent (absolutely?) or divergent.
Now I know that it converges for: $|{x-2}|<1$, but I am having trouble proving it. Any ideas would be greatly appreciated.","['sequences-and-series', 'convergence-divergence', 'discrete-mathematics']"
1582557,Prove: $\lim\limits_{n\to\infty}\frac{1}{n}\sum\limits_{k=1}^{n}\sqrt{1+\frac{k}{n}}=\frac{2}{3}(2\sqrt{2}-1)$,Prove: $\lim\limits_{n\to\infty}\frac{1}{n}\sum\limits_{k=1}^{n}\sqrt{1+\frac{k}{n}}=\frac{2}{3}(2\sqrt{2}-1)$ What method to use in order to find the closed form of summation $\sum\limits_{k=1}^{n}\sqrt{1+\frac{k}{n}}$?,"['summation', 'calculus', 'limits']"
1582558,Understanding the random variable definition of Markov chains,"Update This question is answered in section 3.2 of these notes . As a probability novice, I'm struggling to completely understand the definition of a Markov chain as a sequence of random variables. For simplicity, consider discrete-time, homogeneous Markov chains with finite state spaces $S$ which we take to be $\{1, \dots, n\}$.  I understand the following definition of a Markov chain in this context: A Markov chain is a pair $(S,P)$ where $P = (P_{ij})$ is a transition matrix . Given this definition, one can generate a trajectory of the Markov chain consisting of an infinite sequence $s_0, s_1, \dots$ of elements of $S$ by initializing in a state $s_0$ and evolving forward according to the transition probabilities $(P_{ij})$. So far so good -- this is all quite intuitive. However, suppose instead that one considers a Markov chain as a sequence $X_0, X_1, \dots$ of random variables with values in $S$ having the Markov property -- is there a standard mapping between these definitions? In particular, since each $X_k$ is a random variable whose domain is some sample space $\Omega$; $$
  X_k:\Omega\to S,
$$ and since the transition probabilities are usually described as conditional probabilities; $$
  P_{ij} = \mathbf P(X_k = i\mid X_{k-1}=j),
$$ or the transpose of this depending on you conventions, presumably there is a sample space $\Omega$ and a probability measure $\mathbf P$ sitting somewhere ? One guess would be that $\Omega$ can be taken to be the set of all sequences $s_0, s_1, \dots$ of elements of $S$, the random variable $X_k$ maps any such sequence to its $k^\mathrm{th}$ element, $$
  X_k(s_0, s_1, \dots) = s_k,
$$ and $\mathbf P$ is any probability measure on the set of subsets of $\Omega$ that satisfies the Markov property. Is this description of (one direction of) the correspondence between these Markov chain definitions correct and/or standard ?","['stochastic-processes', 'markov-chains', 'probability']"
1582567,Proof that trace of 'hat' matrix in linear regression is rank of X,"I understand that the trace of the projection matrix (also known as the ""hat"" matrix) X*Inv(X'X)*X' in linear regression is equal to the rank of X.  How can we prove that from first principles, i.e. without simply asserting that the trace of a projection matrix always equals its rank? I am aware of the post Proving: ""The trace of an idempotent matrix equals the rank of the matrix"" , but need an integrated proof.","['matrices', 'statistics', 'linear-regression', 'linear-algebra']"
1582569,"Find all possible functions, $F(r)$, harmonic in $2$ and $3$ dimensions,","Sources: this is an old advanced calculus exam question, which I think is asking for harmonic functions. The problem statement is: Suppose $F(r)$ is a smooth function of $r$ for $r>0$ . Define $\Phi(x) = F(|x|)$ with $x = (x_1, ...,x_d) \in \mathbb{R}^d$ and $|x| = (\large \sum_i^dx_i^2)^{\frac{1}{2}}$.For $d=2$ and $d=3$, find all possible functions $F(r)$ so that
  $$\sum_{i=1}^d (\frac {\partial}{\partial x_i})^2\Phi(x) = 0.$$ Any hints or comments are welcome. So, it appears that this problem statement is just a tricky way  of asking to find all functions $\Phi$ such that $$\Phi_{x_1x_1} + \Phi_{x_2x_2} = 0 $$ and $$\Phi_{x_1x_1} + \Phi_{x_2x_2} + \Phi_{x_3x_3} = 0$$ I.e., we are looking for all functions that are harmonic.  But what is weird about this question is that it doesn't really specify a domain in which we are to find these harmonic functions.  Unless the domain is simply understood to be for all $| x| \ne 0$. Thanks,","['functional-analysis', 'real-analysis', 'harmonic-functions', 'calculus']"
1582594,Evaluating the Definite Integral $\int_{0}^{1}\frac{2 \sin \pi x \cos \pi x}{1+x^2}dx$,"How can I find this integral
  $$I=\int_{0}^{1}\frac{2 \sin \pi x \cos \pi x}{1+x^2}dx$$ Any trick that could compute the definite integral is acceptable. However, it will be more challenging to find a primitive. Any hint or help is appreciated. My Work I just wrote the integral as $$I=\int_{0}^{1}\frac{\sin 2 \pi x}{1+x^2}dx$$ Then, I decided to introduce $$J(\alpha)=\int_{0}^{1}\frac{\sin \alpha x}{1+x^2}dx$$ and solve a more general problem. Hence, we would have $I=J(2\pi)$ as a special result. But I don't know how to go further. I tried integration by parts and substitutions but to no avail!","['integration', 'definite-integrals', 'calculus']"
1582608,Conformally mapping an ellipse into the unit circle,"I'm currently studying for a complex analysis final and I don't think I've really developed the intuition for conformal mappings yet. I'm attempting a problem from Ahlfors: map the outside of the ellipse $(x/a)^2+(y/b)^2=1$ onto $|w|<1$ with preservation of symmetries. I believe I should use the inverse of the Joukowski transformation at some point (as it maps ellipses to circles) to get a circle of radius $R$ and then rescale. However, I run into trouble when I try to find an $R$ that will work. Any thoughts?","['complex-analysis', 'conformal-geometry', 'analysis']"
1582652,"Grassmannian, symmetric, idempotent matrices of trace $n$?","How do I see that $G_n(\mathbb{R}^m)$ is diffeomorphic to the smooth manifold consisting of all $m \times m$ symmetric, idempotent matrices of trace $n$?","['differential-topology', 'matrices', 'manifolds', 'general-topology', 'differential-geometry']"
1582662,Classification of Finite Topologies,"Does there exist a classification of finite topologies? I define a finite topology as a finite Set $T$ of Sets which respects the following properties: $\forall a,b \in T:  a \cap b \in T$, $\forall a,b \in T: a \cup b \in T$, $ \emptyset \in T$, $\exists S\in T\ |\ \forall a \in T , a \subseteq S$. This seems like a natural thing to do in the vein of classifying finite groups, so i'm curious what current research in this area looks like.","['universal-algebra', 'abstract-algebra', 'general-topology']"
1582672,Smoothest function which passes through given points?,"I am trying to interpolate/extrapolate on the basis of a known collection of (finitely many) points. I'm wondering if there is a way to formalize this intuitive notion: find a 'smoothest' function which passes through each of the points. Of course in general the function would not have a nice form. The idea is similar to that of BÃ©zier curves (and would be closer still, if I used a parametric curve rather than a function) and essentially opposite to the Lagrange interpolating polynomial, where fitting more than a few points usually produces wild oscillations. Any idea how to make an idea like this work?","['real-analysis', 'extrapolation', 'interpolation', 'complex-analysis', 'bezier-curve']"
1582684,Compute $z^3 = |z|$,"Compute $z^3 = |z|$ $z = 0$ is a solution when $z$ is not zero, I get to $z^2 = z'$ , how do I continue from here?","['algebra-precalculus', 'complex-numbers']"
1582721,Invertible ideals are finitely generated.,"Let $R$ be an integral domain and let $I,J \subseteq R$ be ideals. Suppose $IJ=(a)$ for some $a \in R$. We wish to show that $I$ and $J$ are finitely generated. Since $a \in IJ$ we know $a$ can be written as the finite sum of products of the form $xy$, where $x \in I$ and $y \in J$. I want to show that $I$ is generated by these particular $x$'s (and analogously $J$ is generated by these particular $y$'s). But I'm having some trouble & I'm ready for a bigger hint.","['abstract-algebra', 'integral-domain', 'ideals']"
1582760,Morphisms! Time to set the record straight,"In my limited mathematical reading, I often come across authors that declare functions as isomorphisms, homomorphisms, or homeomorphisms (or any other variety of morphism).  Although I've found definitions of these terms in resources like Wikipedia and Wolfram MathWorld, I still am not able to completely and concretely understand them and their differences . I assume all these morphisms are related but differentiated by certain properties (an isomorphism has an inverse? a homeomorphism is an isomorphism constrained to topology?) but I don't know exactly what those properties are. Could someone provide a picture of all types of defined morphisms and how they relate (I'm thinking possibly they fit into a hierarchy?).  Further, providing examples of what is a particular morphism and what is not that same morphism (for example, ""f is an endomorphism but not a homeomorphism because..."") would be very helpful.  Further, how do these morphisms relate to topology and category theory? Thanks!","['category-theory', 'abstract-algebra', 'functions']"
1582780,What is the probability that $x^4-y^4$ is divisible by 5?,"Two numbers $x$ and $y$ are chosen at random without replacement from the set $\{1,2,3...,5n\}$. What is the probability that $x^4-y^4$ is divisible by $5$? I divided the numbers into groups of 5 $(1,2,3,4,5),(6,7,8,9,10),...$.The probability in the first group would itself be the answer.But how to find that?","['combinatorics', 'probability', 'elementary-number-theory']"
1582781,Finding conditional probability distribution (X|Y) from (Y|X),"$(Y,X)$ has a joint distribution where the marginal of $X$ is a standard normal and $Y|X \sim U \left[|X|-\frac{1}{2},|X|+\frac{1}{2}\right] $ where $U[a,b] $ means uniform in the interval [a,b]. How can I find the distribution of $X$ given $Y$ and conditional expectation function $E(X|Y)$? I tried to multiply p.d.f. of $Y|X$ and $X$ to find joint distribution first, but support of $Y|X $ confused me. Thanks in advance :)","['uniform-distribution', 'statistics', 'conditional-expectation', 'normal-distribution']"
1582803,Signal processing and algebraic geometry,"Signal processing is a pretty huge branch of what I would (maybe wrongly) call electrical engineering. I have heard here and there whispers of interesting connections between signal processing - in particular sampling theory - and algebraic geometry. I am not interested in ""local"" applications to solve specific problems. Instead, I'm looking for something like a general approach to signal processing and sampling theory which intrinsically uses notions of algebraic geometry. Kind of like the approach to number theory via algebraic geometry. I am very interested to read how these two fields relate to each other and would be grateful for references.","['signal-processing', 'reference-request', 'sampling', 'algebraic-geometry']"
1582826,Prove that the limit of $\sqrt{n+1}-\sqrt{n}$ is zero,"How would I go about proving that $\lim_{n\to\infty}\sqrt{n+1}-\sqrt{n}=0$? I have tried to use Squeeze theorem but have not been able to come up with bounds that converge to zero. Additionally, I don't think that converting to polar is possible here.","['radicals', 'limits']"
1582834,Integration involving Inner Product,"Suppose $f: {\bf R}^n \to {\bf R}^n $be a continuous function such that $\int_{{\bf R}^n} \vert f(x) \vert \, dx < \infty$. Let $ A \in GL_n({\bf R})$. Show that $$ \int_{{\bf R}^n} f(Ax) e^{i\langle y,x\rangle} \, dx = \int_{{\bf R}^n} f(x) e^{i\langle (A^{-1})^ty,x\rangle} \frac {dx}{\vert \det(A)\vert }.$$ Here,$<x,y>$ denote standard inner product on $\bf R^n$.Clearly using $Ax=t$ in the L.H.S. gives the R.H.S expression except $\vert \det(A)\vert ^{-1}$. I guess this $\vert \det(A)\vert^ {-1} $ is Jacobian of Matrix of change of variable but unable to verify this. Please help.","['matrices', 'integration', 'multivariable-calculus', 'inner-products']"
1582847,"For a subgroup $H$ of a group $G$, how many cosets are there?","According to my lecture notes, for a subgroup $H$ of a group $G$, the (right) cosets of $H$ in $G$ are all the sets given by
$$
Hx = \{hx: h \in H\}
$$
Where $x \in G$. This implies that the number of cosets would be given by $[G : H]= |G|$. However, Lagrange's Theorem states that $[G:H]=\frac{|G|}{|H|}$. Why is this the case?","['finite-groups', 'group-actions', 'group-theory']"
