question_id,title,body,tags
2559880,Determinant of hermitian matrix,"Let $M=A+iB$ be a complex $n \times n$ Hermitian matrix. First of all we know that $$(\det M)^2=\det \begin{pmatrix} A & -B \\ B & A \end{pmatrix}.$$ Also $\det \begin{pmatrix} A & -B \\ B & A \end{pmatrix}$ is a polynomial in $n^2$ variables of degree $2n$. Is it true that $\det M$ is a polynomial, say D, of degree $n$ in this $n^2$ variables such that $D^2(M)=\det \begin{pmatrix} A & -B \\ B & A \end{pmatrix}$? The explicit calculations for $n=1,2,3$ suggest so, yet I can't find the information if this is true neither proof this.","['matrices', 'linear-algebra', 'determinant']"
2559883,A probability concentration inequality,"Suppose $\mathbb{E}(X)=0 , \text{Var}(X)=1$ and $|X|\leq M$ on $\Omega$. Prove that $$P(|X|\geq t)\geq \frac{1-t^2}{M^2-t^2} \quad\forall\,0<t<1.$$ How I can prove , I attempted to use Markov's inequality but this does not hold. Please help me to prove this, thanks in advance.","['inequality', 'concentration-of-measure', 'probability-theory', 'statistics', 'probability']"
2559901,Probability that leading Eigenvalue is real,"What is the probability that the leading Eigenvalue (largest real part) of a large i.i.d Gaussian (real) random matrix is real? To what will this probability converge in the limit of large size? Update: my numerical experiments find that the fraction of leading eigenvalues that are real drops with size but appears to saturate somewhere around 0.3. I calculated this for matrices up to N=8000, albeit for only 80 realizations each.","['matrices', 'eigenvalues-eigenvectors', 'random-matrices', 'linear-algebra']"
2559915,Decompose matrix A into its symmetric and skew-symmetric parts,"I have this square matrix: $$A=\begin{pmatrix}0&-14\\14&0\end{pmatrix}$$ and I want to find its symmetric and skew-symmetric parts but I am confuse because it is already a skew symmetric matrix, and when finding the symmetric part I get a zero matrix. Is that possible?","['matrices', 'transpose']"
2559997,How to finish calculating of $\int_0^{\infty}\frac{\mathrm{d}z}{z^6+1}$?,"I have $$\int_0^{\infty}\frac{\mathrm{d}z}{z^6+1}.$$ I am a bit confused about the residue result in my calculus, but what I've done: $$\frac12\int_{-\infty}^{\infty}\frac{\mathrm{d}z}{z^6+1}=2\pi\mathrm{i}\left(\sum_{j=1}^n\textrm{Res}_j\right),$$ and therefore $z=\sqrt[6]{-1}$ . I figured out 3 roots that are in the contour: \begin{align*}
\varphi_1&=\frac{\sqrt3}2+\frac{\mathrm{i}}2,\\
\varphi_2&=-\frac12+\mathrm{i},\\
\varphi_3&=-\frac{\sqrt3}2+\frac{\mathrm{i}}2.
\end{align*} To find the residues, I used the formula for the fraction: $$\textrm{Res}_{z = a}=\frac{\xi(a)}{\psi'(a)},$$ so therefore $$F(z) =\frac1{6z^5}\Bigg\lvert_{z= \varphi_1..\varphi_3}$$ and after that, \begin{align*}
\textrm{Res}_1&=\frac1{6\left(\frac{\sqrt3}2+\frac{\mathrm{i}}2\right)^5},\\
\textrm{Res}_2&=\frac1{-6\left(\frac12-i\right)^5},\\
\textrm{Res}_3&=\frac1{-6\left(\frac{\sqrt3}2-\frac{\mathrm{i}}2\right)^5},
\end{align*} but the imaginary component just did not dissapear in the final answer, so maybe I am doing something wrong? because I know that when we do real integration with residues, we should get rid of the imaginary component in the final answer.","['complex-analysis', 'improper-integrals', 'residue-calculus', 'complex-integration']"
2560000,"Existence and uniqueness of solution of : $y'(x) = (x-y(x))^{4/5}, \space y(3)=3$","Study the Existence and Uniqueness of the IVP :
  $$y'(x) = (x-y(x))^{4/5}, \space y(3)=3$$ Regarding existence, I'd first assume $f$ the function such : $$f(x,y)=(x-y)^{4/5}$$ We observe that $f(x,y)$ is not continuous in $
\mathbb R^2$ since we need $x-y\geq0$. Letting $D$ be a domain such : $$D=\{(x,y)\in \mathbb R^2: |x-3| \leq ε_1, \space |y-3|\leq ε_2 \}$$ we can say that there exists $ε_1,ε_2 \in \mathbb R$ such that $f$ is continuous in $D$, which means that the IVP has a solution in $D$. Question : Is the above statement correct ? Shall I go into more details explaining why $f$ can be continuous in such a domain ? Finally, regarding uniqueness, I know that showing that $f(x,y)=(x-y)^{4/5}$ is a Lipschitz function is enough. : $$|f(x,y_2) -f(x,y_1)|=|(x-y_2)^{4/5}-(x-y_1)^{4/5}|$$ The function $g(y)=(x-y)^{4/5}$ is continuous in the interval $[y_1,y_2]$ with $y_1,y_2 \in D_f$ and $g$ is also differentiable in $(y_1,y_2)$ , which means that we can apply the Mean Value Theorem and yield : $$g'(ξ)=\frac{g(y_2)-g(y_1)}{y_2-y_1}\Rightarrow \bigg|\frac{4}{5(x-ξ)^{1/5}}\bigg||y_2-y_1|=|(x-y_2)^{4/5}-(x-y_1)^{4/5}|$$ Here, we can see that there isn't a bound for the expression $\bigg|\frac{4}{5(x-ξ)^{1/5}}\bigg|$, thus meaning that the solution is not unique .","['lipschitz-functions', 'ordinary-differential-equations', 'dynamical-systems', 'initial-value-problems']"
2560013,Differentiate the squared dot product,"I am new to Mathematics stack exchange community and has no experience in asking question so please bear with me. I am watching deep learning course from Coursera and encounter a question during the video.
$$\left|\frac d{d\vec x}(\vec x\cdot\vec x)^2\right|=?$$
$$\vec x=\begin{bmatrix}x_1\\x_2\end{bmatrix}=\begin{bmatrix}3\\4\end{bmatrix}$$
I am not sure how to perform dot product on 2 vectors since they are 2x1 and 2x1 dimension. Please guide me! Thanks Note:
After some try and error, I got the answer, but I don't understand the solution.","['derivatives', 'linear-algebra', 'vectors']"
2560108,How many dimensions will a derivative of a 1-D vector by a 2-D matrix have?,"As the title above, I find it hard to imagine or illustrate. It is a question from Coursera and the answer is 3. I do not get it why the answer is 3?","['matrices', 'vectors', 'derivatives']"
2560128,Associativity in forming Disjoint Unions,"Let $X'$ be a set and let $\{X_{\alpha}\}_{\alpha \in A}$ be an indexed collection of sets. We can form the disjoint union $$\bigsqcup_{\alpha \in A} X_{\alpha} = \left\{(x, \alpha) \ | \ \alpha \in A \ \text{and } \ x \in X_{\alpha}\right\}.$$ Now my question is what does $X' \sqcup \left(\bigsqcup_{\alpha \in A} X_{\alpha}\right)$ equal (as a set?), because based on the definition of the disjoint union I see two approaches to form the disjoint union of the above. Approch 1 Set $X_1 = X'$ and $X_2 = \bigsqcup_{\alpha \in A} X_{\alpha}$, and let the indexing set $I = \{1, 2\}$. Then $$\bigsqcup_{i \in I} X_i = X' \sqcup \left(\bigsqcup_{\alpha \in A} X_{\alpha}\right) = \left\{(x, i) \ | \ i\in I \ \text{and } \ x \in X_{i}\right\}$$ Now let $\phi_i : X_i \to \bigsqcup_{i \in I}X_{i}$ be the canonical embedding defined by $\phi_i(x) = (x, i)$. Now pick $p \in X_2 = \bigsqcup_{\alpha \in A} X_{\alpha}$, then we have $p = (q, \alpha)$ for some $q \in X_{\alpha}$ and $\alpha \in A$. Then $\phi_2(p) = ((q, \alpha), 2)$ and for $p \in X_1 = X'$ we have $\phi_1(p) = (p, 1)$. This doesn't seem desirable and I think it defeats the purpose or the point of having the disjoint union, but it seems to be logically correct (I think) based on the the definition of a disjoint union  above. Approach 2 On the other hand we can extend the indexing set $A$ by setting $X^{'} = X_{\beta}$ and setting a new indexing set to be $A' = A \cup \{\beta\}$ and then we'd have $$X' \sqcup \left(\bigsqcup_{\alpha \in A} X_{\alpha}\right) = \bigsqcup_{\alpha \in A'} X_{\alpha} = \left\{(x, \alpha) \ | \ \alpha \in A' \ \text{and } \ x \in X_{\alpha}\right\}$$ Again let  $\phi_{\alpha} : X_{\alpha} \to \bigsqcup_{\alpha \in A'}X_{\alpha}$ be the canonical embedding defined by $\phi_{\alpha}(x) = (x, \alpha)$. But now when we pick $q \in X_{\alpha}$ for some fixed $\alpha \in A'$ we have $\phi_{\alpha}(q) = (q, \alpha)$ and for $p \in X_\beta$ we have $\phi_{\beta}(p) = (p, \beta)$. This seems to be desirable for the disjoint union because we only have an ordered pair, instead of a $3$-tuple above, but I don't think that it is logically sound. Which of the approaches above is correct? Also I think that the main reason for the discrepency is that I have probably failed to take assosciativity into account for approach $2$ above, for example I'm assuming approach $2$ holds if we have $$X' \sqcup \bigsqcup_{\alpha \in A} X_{\alpha}$$ So with regards to assosciativity, does it hold that for sets, $X, Y, Z$ we have $X \sqcup (Y \sqcup Z) \neq (X \sqcup Y) \sqcup  Z$? That may possibly explain the issue I'm having. Also it should be noted that sometimes authors use the brackets $( \cdot )$ not for assosciativity but to enclose a complicated expression for a set so my pedantic issues above may not even be relevant.",['elementary-set-theory']
2560143,how to find probalility that a student misses at least one test if he/she is absent twice?,The probability that a teacher will give an unannounced test during any class is $\dfrac15$ . If a student is absent twice then probability that he/she misses at least one test is $\\ \hspace{5cm}$ a) $\dfrac23\ \quad $ b) $\dfrac45\ \quad$ c) $\dfrac7{25}\ \quad $ d) $\dfrac9{25}\ $ My attempt: Probability of attending first test & missing $2$ nd test $=\dfrac45\times\dfrac15=\dfrac4{25}$ Probability of missing first test & attending $2$ nd test $=\dfrac15\times\dfrac45=\dfrac4{25}$ Probability of missing both the tests $=\dfrac15\times\dfrac15=\dfrac1{25}$ Total probability of missing at least one test $=\dfrac4{25}+\dfrac4{25}+\dfrac1{25}=\dfrac9{25}$ Can somebody please help me if I am wrong? Thanks.,['probability']
2560162,Change of basis for linear transformation - Linear algebra,"So I'm having a lot of difficulties with change of basis. Watched tons of tutorials on youtube but they only seem to confuse me more. Let $T: \mathbb{R^2} \to \mathbb{R^2}$ be defined by $T(a,b) = (a +
 2b, 3a - b)$ . Let $\mathcal{B} = \{(1,1),(1,0)\}$ and $\mathcal{C} =
> \{(4,7),(4,8)\}$ . Find $[T]_\mathcal{B}$ and $[T]_\mathcal{C}$ and
show that $[T]_\mathcal{C} = Q^{-1} \cdot [T]_\mathcal{B}\cdot Q$ for
some invertible matrix $Q$ . So I've done some thinking, and the matrix $Q$ might be the matrix that goes from basis $c$ to $b$ ? and then if I invert that one I get matrix $Q^{-1}$ ? I just have 0 idea where to start to problem from, like what's the first matrix that I have to work with? Do I start with the basic basis in $R^2$ that is $\{(1,0),(0,1)\}$ and apply the transformation to it?","['change-of-basis', 'linear-algebra', 'linear-transformations']"
2560163,If $B$ is a subset of a Banach space is it true that if $\operatorname{span} B$ is closed then $\operatorname{span} B$ is finite dimensional,"Let $V$ be a separable Banach space Let $B \subset V$ be a linearly independent, closed and bounded subset of $V$ I would like to know if is it true that
$$
\operatorname{span} B
\text{ is closed }
\Longrightarrow 
\operatorname{span} B
\text
{ is finite dimensional}
$$ thanks","['functional-analysis', 'banach-spaces']"
2560168,"Can we 2-colour elements of a finite group so that for some element $g$ of even order, $x$ and $gx$ have different colours?","The question:
If $G$ is a finite group and $g \in G$ is an element of even order. Then can we colour the elements of $G$ with two colours in such a way that $x$ and $gx$ have different colours for each $x \in G$? I wanted to verify this solution of mine. First, $x \sim y$ if $x = g^my$ for some $ m \in \mathbb{Z}$ then this defines an equivalence relation on $G$. $x \sim x$ if we take $m = 0$. If $x \sim y$, then we have $y = g^mx$ for some $m \in \mathbb{Z}$. Then, $x = g^{-m}y$, so $y \sim x$. If $x \sim y$ and $y \sim z$, then $y = g^mx$ and $z = g^ny$ for some $m, n \in \mathbb{Z}$. That is, $z = g^{m+n}x$, so $x \sim z$. $G$ is partitioned into $g$-orbits, so to speak. Let the order of $g$ be $2n$. In each orbit, say we colour $x$ red, $gx$ blue, $g^2x$ red, ... , $g^{2n-1}x$ blue, $g^{2n}x = x$ red we have coloured the elements of $G$ as required.","['group-theory', 'proof-verification']"
2560171,Let $f:\mathbb R \to \mathbb R$ be continuous. Then which of the following statements implies that $f(0)=0$?,"Let $f:\mathbb R \to \mathbb R$ be continuous. Then which of the
  following statements implies that $f(0)=0$? (A)$\lim_{n \to \infty}\int_{0}^{1}f(x)^n dx=0.$ (B)$\lim_{n \to \infty}\int_{0}^{1}f(x/n) dx=0.$ (C)$\lim_{n \to \infty}\int_{0}^{1}f(nx) dx=0.$ (D) None of the above. (A)Suppose $f(x)=1-x, \int_{0}^{1}(1-x)^n dx=-\frac{1}{n+1},$ which converges to zero. I tried to find the counter example for the (B) and (C). I couldn't find. please help me.","['real-analysis', 'integration', 'limits']"
2560188,Cardinality of $\Bbb N^{k}$,"How can i determine the cardinality of $\Bbb N^{k}$ for $k \in \Bbb N$ ? I know that $\Bbb{N} \times \Bbb{N}$ is of cardinality $\aleph_o$, is there any valid induction for $k\in \Bbb{N}$?","['cardinals', 'discrete-mathematics']"
2560241,The possible number of elements in a convex set,"Let $(X,\|\cdot \|)$ be a normed space over $\mathbb{K}$ ($\mathbb{R}$ or $\mathbb{C}$), and let $M\subseteq X$ be a subspace. Let $\phi\in \mathcal L(M,\mathbb{K})$, and let $A$ be the set of all bounded linear functionals $f$ such that $f|_M=\phi$ and $\|f\|=\|\phi\|$. What is the possible number of elements in $A$? Hint: Show that $A$ is a non-empty convex set, and use it to determine the possible number. What I did : First, I have proven that $A$ is a non-empty convex set. I am not sure how to determine the possible number. Pick $f_1,f_2\in A$ and let $\alpha\in [0,1]$, and write $f_3=\alpha f_1+(1-\alpha) f_2$.  If $f_1=f_2$, then $f_3=f_1$ is the only map in $A$, ie. it is unique, so $A$ must be finite if each element in $A$ are equal to some other. If $f_1\neq f_2$, then $f_3=\alpha f_1+(1-\alpha) f_2$ belongs to $A$ and it is not unique. There are infinitely many such maps, so $A$ is infinite, if at least one of the elements in $A$ is not equal to the rest. If my reason is correct, is there a better/rigorious way to formulate?","['functional-analysis', 'elementary-set-theory']"
2560259,Arranging the letters of this word so that no two vowels are together,"Arrange the letters(every arrangement must contain all letters of the word) of the word ' BENGALI ', so that no two vowels are together. What my cute little brain could find out: Let me first arrange the vowels... __ E __ A __ I__ where the underscores contain the consonants. Now, clearly, there will be 
$^{3}P_3$ arrangements. So my brain tells me to find the ans for the E A I one and then multiply it by $^{3}P_3$ Now my brain thinks for a minute and then says: ""Hey! There are $4$ underscores and how many consonants do you have? Its $4$ Is it not a modified stars and bars problem?"" I thought for a moment, and agreed with my brain. Then it said: ""Find all integer solutions to the equation based on the following conditions: $x_1+x_2+x_3+x_4=4$, where $x_1,x_4≥0$ and $x_2,x_3≥1$"" And the answer to this is $\binom{2 + 4 - 1}{2} = \binom{2 + 4 - 1}{4 - 1}$( just some honesty! ) ""But wait! There are $^{4}P_4$ ways of arranging the consonants. So multiply this by $^{4}P_4$"" And finally by $^{3}P_3$ So my final answer is $$\binom{2 + 4 - 1}{2}\times^{4}P_4 \times^{3}P_3$$
Am I correct? If yes, is there any better or more efficient way? If yes, would you show that?","['permutations', 'combinatorics', 'combinations', 'discrete-mathematics']"
2560271,"$(Ax)(t)= \int_{0}^{1} \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} x(s) ds$ for $A : L_2[0,1] \to L_2[0,1] $ is compact.","The question is as follows: Show that the linear operator $(Ax)(t)= \int_{0}^{1} \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} x(s) ds$ for $A : L_2[0,1] \to L_2[0,1] $ is compact. $\textbf{An idea:}$ For to prove that $A$ is compact, it is enough to show that its kernel $k(t,s) = \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} $ is continuous and is in $L_2[0,1] \times L_2[0,1]$, i.e we have to show that $\int_{0}^{1} \int_{0}^{1} \left| \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} \right|^2 ds dt \leq +\infty $. For to show this, we have
\begin{align} \int_{0}^{1} \int_{0}^{1} \left| \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} \right|^2 ds dt &\leq  \int_{0}^{1} \int_{0}^{1}  \frac{1}{\mid t-s \mid^{\frac{2}{3}}}   ds dt \\& =  \int_{0}^{1} \left( \int_{0}^{t} \frac{1}{( t-s )^{\frac{2}{3}}} + \int_{t}^{1} \frac{1}{(  s-t )^{\frac{2}{3}}} ds \right) dt \\&= \int_{0}^{1}  \left( -3(t-s)^{frac{1}{3}}\mid_{0}^{t} + 3(s-t)^{frac{1}{3}}\mid_{t}^{1} \right) dt \\& = \int_{0}^{1} \left( -3 t^{\frac{1}{3}} + 3(1 -t)^{\frac{1}{3}} \right) dt \\&= -\frac{9}{4} t^{\frac{4}{3}}\mid_{0}^{1} -  \frac{9}{4} (1-t)^{\frac{4}{3}}\mid_{0}^{1} = -  \frac{9}{4} +  \frac{9}{4} =0 < +\infty \end{align}
This proves the claim. Please let me know if I am wrong or if we need to show something else for to ensure that the mentioned integral operator is compact? Thanks!","['functional-analysis', 'real-analysis', 'operator-theory']"
2560326,What is the method to show exactly one positive root of a Cubic equation?,"I have $a x^3 + b x^2 + c x + d =0$ and $a>0 , d<0$ $a, b, c, d$ is the function of all parameters.   I'm looking for an analytic solution of this cubic equation. How to prove that is cubic equation has exactly one positive root?","['algebra-precalculus', 'real-analysis', 'number-theory', 'elementary-number-theory']"
2560368,Why do we lose geometric intuition regarding a scheme due to nilpotent elements?,"I have quite often read that the functor of points allows us to recover some geometric intuition for a scheme which was lost due to the presence of nilpotent elements in the structure sheaf. I know this question is somewhat vague, but, regardless, what exactly is it about the nilpotent elements which don't allow us to view a scheme as a collection of points and how does the functor of points approach resolve this issue?",['algebraic-geometry']
2560413,Heights and circumcircle,In a triangle $ABC$ the heights $BB'$ and $CC'$ intersect the circumcircle of $ABC$ at $E$ and $F$. Prove that $\displaystyle B'C'=\frac{EF}{2}$. The circle of diameter $BC$ passes through $B'$ and $C'$ since $BB'C=CC'B=90^{\circ}$. $EFC=\frac{\stackrel{\frown}{EC}}{2}=B'BC=CC'B$ then the lines $B'C'$ and $EF$ are parallel. They are also parallel to the tangent at $A$. How to continue?,"['circles', 'geometric-transformation', 'euclidean-geometry', 'geometry']"
2560418,Entire functions such that $\frac{f(z+1)-f(z-1)}{2}=f'(z)$,"Consider the equation
$$\frac{f(z+1)-f(z-1)}{2}=f'(z)\tag{*}.$$
Any polynomial of degree $\leq 2$ satisfies $(*)$ for all $z$.  My question is: If $f:\mathbb{C}\to\mathbb{C}$ is holomorphic and satisfies $(*)$ for all $z$, must $f$ be a polynomial of degree $\leq 2$? I would also be interested in answers to weakened versions of the question, for instance where $f$ is only holomorphic on a strip $\{z:-c<\operatorname{Im}z<c\}$, or where $f$ is allowed to have isolated singularities. Here are some things I know about this question so far.  If we instead consider smooth functions $f:\mathbb{R}\to\mathbb{R}$, then there are lots more solutions to $(*)$ besides polynomials of degree $\leq 2$ (see Functions $f$ such that $f(x+1)-f(x-1)=2f'(x)$. ). On the other hand, if $f$ is a polynomial which satisfies $(*)$, it must have degree $\leq 2$.  Indeed, if $f$ satisfies $(*)$, so does $f'$ (by differentiating the equation), so if a polynomial of degree $>2$ satisfied $(*)$, we could repeatedly differentiate to get a cubic.  Subtracting the quadratic part (since $(*)$ is linear), we would conclude that $f(z)=z^3$ satisfies $(*)$, which is false. You could attempt to build solutions to $(*)$ using Taylor series.  Specifically, suppose $f(z)=\sum a_n z^n$ and let $g(z)=f'(z)-\frac{f(z+1)-f(z-1)}{2}$.  To verify that $f$ satisifies $(*)$, it suffices to check that $g^{(n)}(0)=0$ for all $n\in\mathbb{N}$.  This can be written as an infinite list of (infinitary) linear conditions on the $a_n$.  For instance, the condition that $g(0)=0$ says that $$\sum_{n=1}^\infty a_{2n+1}=0$$ and the condition that $g'(0)=0$ says that $$\sum_{n=2}^\infty2na_{2n}=0.$$  In general, the equations for even derivatives involve only the $a_n$ for $n$ odd and the equations for odd derivatives involve only the $a_n$ for $n$ even, so you can consider odd $n$ and even $n$ separately.  You could try to inductively construct the $a_n$ to make all these equations true one at a time.  For instance, you might start by defining $a_3=1$ and $a_5=-1$, and then define $a_7$ and $a_9$ so that $g(0)=0$ remains true but $g''(0)=0$ becomes true.  Then you could try to define $a_{11}$, $a_{13}$, and $a_{15}$ so that $g(0)=0$ and $g''(0)=0$ remain true and $g''''(0)=0$ becomes true.  However, this has convergence issues: I don't know how to prove that such a construction will make the series $\sum_{n=1}^\infty a_{2n+1}$ actually converge (all the construction gives is that infinitely many of the partial sums are $0$), let alone that the $a_n$ shrink fast enough so that $\sum a_nz^n$ is entire.","['complex-analysis', 'ordinary-differential-equations', 'functional-equations']"
2560471,Why is $\mathbb{A}^{1}_{\mathbb{C}} \to \mathbb{A}^{1}_{\mathbb{R}}$ etale?,"Consider the morphism $\mathbb{A}^{1}_{\mathbb{C}} \to \mathbb{A}^{1}_{\mathbb{R}}$ induced by the inclusion $\mathbb{R}[T] \to \mathbb{C}[T]$. I'm having trouble proving that this is etale. The definition of etale that I'm working with is flat and unramified. Really, I would like input on why for each $x \in \mathbb{A}^{1}_{\mathbb{C}}$, we have $$m_{f(x)}\mathcal{O}_{\mathbb{A}^{1}_{\mathbb{C}}, x} = m_{x}.$$ Every element in $\mathbb{A}^{1}_{\mathbb{C}}$ is either the zero ideal (and then $\mathcal{O}_{\mathbb{A}^{1}_{\mathbb{R}}, (0)} = \mathbb{R}(T)$, in which case the desired conclusion is obvious) or it's of the form $(T-z)$. So the stalks at these points are the localizations $\mathcal{O}_{\mathbb{A}^{1}_{\mathbb{C}}, (T-z)} = \mathbb{C}[T]_{(T-z)}$, and the maximal ideals are $(T-z)\mathcal{O}_{\mathbb{A}^{1}_{\mathbb{C}}, (T-z)}$, but is there a nice description of this localization (or do we even need one)? And how do we obtain the above relation? In particular, what is the form of f((T-z))? Finally, we know what the elements (and thus of the maximal ideals in the stalks) look like in $\mathbb{A}^{1}_{\mathbb{R}}$. They are either 0, of the form $(T-a)$ of of the form $(aT^2 + cT + d)$ for some irreducible degree 2 polynomial. Obviously, for this to be true, $f((T-z))$ must be degree 1, but I don't see how to show this.","['algebraic-geometry', 'commutative-algebra']"
2560473,Transformation mapping vector to a gradient is diffeomorphism,"$f:U\to \mathbf{R}$ is $C^2$, $U$ is open subset of $\mathbf{R}^n$, for every $u\in U$ $D^2f(u)$ is positive definite. How do I show that the map $x\mapsto \nabla f(x)$ is a diffeomorphism?","['multivariable-calculus', 'real-analysis']"
2560488,Evaluate $\iint_{D}e^\frac{x+y}{x-y}$ on the region $D$ using a change of variables,"Evaluate $\displaystyle\iint_{D}e^\dfrac{x+y}{x-y}$ on the region $D$ using a change of variables Here is the region: The region is bounded by the following: $y=x-2, y=x-1, x=0, y=0$. A sub that is obvious is let $u=y-x$, then $-2\leq u\leq -1$. Now I have to make one more sub that takes care of the $x=0, y=0$, so I made the sub, let $v=\frac{y}{y-x}$. Then if $x=0\to v=1$, and if $y=0\to v=0$. Therefore $0\leq v\leq 1$. Before I calculate the Jacobian, I notice that I cannot write $e^\frac{x+y}{x-y}$ in terms of $u,v$. The closest I can get is $e^\frac{x+y}{-u}$, but the $x+y$ is still left? Have I made an incorrect sub?","['multivariable-calculus', 'change-of-variable', 'integration', 'calculus']"
2560526,Inverse Laplace Transform of an exponential function 3,"How to find inverse Laplace transform of the following function? $$ U(x,s)=\exp\left(P-\frac{\sqrt{P^2+4Ps}}{2}x\right) $$ I obtained this equation by solving a PDE using Laplace Transform, now I have to take the inverse Laplace of this to obtain the actual solution to the PDE. I am looking for any hint or calculations, kindly suggest any efficient method with some steps.","['laplace-transform', 'calculus', 'complex-analysis', 'contour-integration', 'inverse']"
2560570,Do Fibonacci numbers form a complete residue system in every modulus?,"I want to show that:
$$\forall x,m\ \exists n:x\equiv_mF_n$$ I assume that one can prove this by the pigeonhole principle, but I couldn't manage to find a series of $m+1$ numbers that each want to occupy a different number.","['number-theory', 'fibonacci-numbers']"
2560588,Prove that $\|P_h\|\geq\int_{-1}^{1}|h(t)|dt$ using Tietze extension theorem,"For each $h\in C([-1,1])$, define the linear functional $P_h:C([-1,1])\to \mathbb{R}$ by
$$
P_h(f)=\int_{-1}^{1}f(t)h(t)dt,\qquad f\in C([-1,1]).
$$
Here is the Banach space $C([-1,1]):=\{f:[-1,1]\to \mathbb{R}:f\textrm{ continuous}\}$, endowed with $\| f\|_\infty=\sup_{t\in [-1,1]}|f(t)|$ for $f\in C([-1,1])$. Problem : Prove that $\| P_h\|=\int_{-1}^{1}|h(t)|\,dt$. First, we have
$$
|P_h(f)|\leq \int_{-1}^{1}|f(t)h(t)|dt\leq \int_{-1}^{1}|h(t)|dt \|f\|_\infty\implies \|P_h\|\leq \int_{-1}^{1}|h(t)|dt
$$
To prove the other inequality, I got the hint as follows: For each $\delta>0$, let $A_\delta=\{t\in [-1,1]:|h(t)|\geq \delta\}$. Define $f_0$ suitably on $A_\delta$ and use Tietze extension theorem. Tietze extension theorem : 
   If $K$ is a compact Hausdorff space and $K_0$ is a closed subset of
   $K$ then for each $f_0\in C(K_0)$ there exists $f\in C(K)$ such that
  $f|_{K_0}=f$ and $\|f\|_\infty = \|f_0\|_\infty$. Do you have an idea which map $f_0$ should look like defined on $A_\delta$? Edit : I asked a comrade about this, and he got the hit from our lecturer. He said about putting $f_0(t)=\frac{h(t)}{|h(t)|}$. This is well-defined on $A_\delta$. Then, he claimed something like
$$
\| P_h(f_0)\|=\left | \int_{-1}^{-1}f_0(t)h(t) dt \right |\geq \int_{A_\delta}\frac{h(t)}{|h(t)|}h(t)dt=\int_{A_\delta}\frac{|h(t)|^2}{|h(t)|}dt=\int_{-1}^{-1}|h(t)|dt.
$$
I really doubt about this claim because it doesn't look right. Is there a way fix it? I guess I want something like 
$$
\|P_h\|\|f\|_\infty=\|P_h\|\|f_0\|_\infty\geq \| P_h(f_0)\|\geq \|f\|_\infty \int_{-1}^{-1}|h(t)|dt
$$
for some $f\in C([-1,1])$ by Tietze extention theorem.",['functional-analysis']
2560623,Proof that a continuous monotone function is a.e differentiable,In S&S there is the proof that a monotone function is a.e differentiable. It says it is enough to prove 2 properties I understand why we need to prove both properties but I am confused as to why we can consider -F(-x) and how they get the final inequality. Isn't $D_- < D_+$ trivially since the function is monotonic? If this is true then why do we need to consider -F(-x) to get that inequality?,"['derivatives', 'lebesgue-integral']"
2560629,Degree of a divisor on surfaces,"I'm reading surfaces from ALgebraic Geometry of Robin Hartshorne. On chapter $5$ page $357$ there is an affirmation: ""A divisor on a surface is a sum of curves, so (in the absence of a projective embedding) it does not make sense to talk about the degree of a divisor, as in the case of curves."" Why is that? The degree would be the formal sum of the coefficients of the divisor, so those numbers will only exist if there is a projective embedding? Thanks for any suggestion","['algebraic-curves', 'algebraic-geometry']"
2560633,Why is $\frac{dx}{dy} \neq \frac{1}{\frac{dy}{dx}}$?,"Suppose I have a function $y=\sqrt{x}$. Then $\frac{dy}{dx}=\frac{\sqrt{x}}{2}$.
Now if I rewrite the function in terms of y then it becomes $x=y^2$ and $\frac{dx}{dy}=2y$. Clearly $\frac{dx}{dy} \neq \frac{1}{\frac{dy}{dx}}$, but why is that the case? I'm confused because we have frequently used $\frac{dx}{dy}= \frac{1}{\frac{dy}{dx}}$ in rate of change questions, and I've never been taught that that's not the case.","['derivatives', 'calculus']"
2560653,Proof of the equation of the fundamental matrix in absorbing Markov chains,"The standard or canonical form of the transition matrix of an absorbing Markov chain is $$P = \begin{bmatrix}I & 0 \\ R & Q \end{bmatrix}$$ and the fundamental matrix is calculated as $$F=(I - Q)^{-1}$$ such that $FR$ spells out the probability of eventually landing on each absorbing states from different transient states. At the same time, $F$ provides the expected number of steps required. What is the proof that $F$ and $FR$ include this information?","['stochastic-processes', 'markov-chains', 'probability']"
2560666,"Prove that the shortest side of one triangle is the longest side of another, given 3 pairs of points.",I have received this question and am having great difficulties. I don't even know how to try to solve it. It goes like this: 6 points are given in a room. These points are pairwise differently distant from each over. However no 3 points may lie on a straight line. Observe all triangles whose corners are the aforementioned points. Now prove that there is always one triangle whose shortest side is the longest side of another triangle.,"['combinatorial-geometry', 'ramsey-theory', 'triangles', 'geometry', 'contest-math']"
2560700,Why does the sup norm make the results of approximation theory independent from the unknown distribution of the input data?,"I was reading the paper "" Why and When Can Deep – but Not Shallow – Networks Avoid the Curse of Dimensionality: a Review "" and I was trying to understand the following statement in section 3.1: On the other hand, our main results on compositionality require the
  sup norm in order to be independent from the unknown distribution of
  the inputa data. This is important for machine learning. my questions are: what does it mean that the sup norm $\| f \|_{\infty} = \sup_{x \in X} |f(x)|$ make the results of the respective paper independent of the input distribution? additionally, why does the sup norm $\| f \|_{\infty} = \sup_{x \in X} |f(x)|$ make the results of the respective paper independent of the input distribution? Why is that important for machine learning? I don't know the answers, maybe because of my lack of experience in functional analysis and approximation theory but my guesses what the answer might be are: I think what it means is that since the paper is concerned with proving bounds on the smallest distance between a target function and a space of functions (space of Neural Networks) denoted by the degree of approximation $dist(f,V_N) = \inf_{P \in V_N} \|f - P \|_{\infty}$, then what I assume it claims is that upper bounds on this quantity are independent (not a function of) the probability distribution of the input space $X$ where $f:X \to Y$. Does it matter because it means it applies to any distribution of $X$? I guess the reason I find this confusing is that I don't particularly see an issue with it dependent on the data distribution. I think what matters more is that the bound on the degree of approximation is not vacuous.i i.e. that its not infinity. If it is infinity for some distribution then the results are useless. However, I don't see why independence on the distribution would matter, I'd assume that boundedness or compactness rather than distribution is what matters (since its what makes things not explode). I don't understand why the sup norm make things not explode. The reason things should not explode should be due to boundedness or compactness, not anything to do with the sup norm. I guess obviously the sup norm implies things don't explode if its bounded, but that happens because of a apriori boundedness/compactness assumption, not due to the sup norm, right? I guess its important for machine learning because they care things hold for any probability/data distribution. But as I've said before, I don't understand how talking about data distribution matters. In my opinion it doesn't matter, since thats not what makes things explode, what matters is the boundedness/compactness of $X$, $f(x)$ and $Y$ Is this on the right track? Or am I misunderstanding the paper a lot?","['real-analysis', 'functional-analysis', 'machine-learning', 'approximation-theory', 'neural-networks']"
2560744,The probability of forming Mississippi by choosing random letters from Mississippi,"I'm having difficulty with the following problem: You choose a letter at random from the word Mississippi eleven times
  without replacement. What is the probability that you can form the
  word Mississippi with the eleven chosen letters? Hint : it may be
  helpful to number the eleven letters as $1, 2, . . . , 11$. This is how I approached it: the number of possible outcomes is $11!$, since we're taking one word at a time without replacement, so there are $11$ choices for the first letter, $10$ choices for the second letter and so on. Now, as to the number of 'success' outcomes, I noticed that there are $4$ s's to choose from, $4$ i's, $1$ M and $2$ p's. So, in order to form the word Mississippi, we have for the first letter $1$ option, $4$ for the second and third letters, $3$ for the fourth (since we've already used one ""s"") and so on, which amounts to a total of $4^2*3^2*2^3=1152$ different ways of doing so. However, my answer does not match the one provided in my book (Henk Tijn's Understanding Probability 3rd edition). What am I doing wrong? Thanks very much in advance.",['probability']
2560784,Why is the following operator invertible,"Suppose that $T : X \rightarrow X$ is an isometry between two Banach spaces. Then if $|\lambda| < 1$, then $T^{-1} - \frac{1}{\lambda}I_X$ is invertible. Can someone explain this step as it is critical step in one of my proofs.","['functional-analysis', 'linear-algebra']"
2560807,Trying to factor $x^4-3$ over $\Bbb{F}_p$ with $p\equiv 3\mod{4}$,"So I am trying to show that $f(x) = x^4-3$ will factor over $\Bbb{F}_p$ when $p\equiv 3\mod 4$, with $p\neq 3$. Specifically, I am trying to show that $f$ will factor into irreducibles such that there is at least one factor of degree 2. My Work So Far So if I assume that it can be factored, we would have
$$ x^4-3 = (x^2+ax+b)(x^2-ax+d) = x^4 + (b+d-a^2)x^2 + a(d-b)x + bd.$$
Because we want the linear term to be 0, we need either $a=0$ or $d-b = 0$. Now if $a=0$ we get that $b=-d$, so $-b^2 = -3$. That is, $3$ is a square. If $d-b = 0$, then we would have $b^2 = -3$, so $-3$ is a square. Because $-1$ is not a square when $p\equiv 3\mod{4}$, we know that one of $-3$ or $3$ must be a square, but not both, so $a=0$ or $d=b$, but not both. If $a=0$, that is $3$ is a square, then we have $f(x) = (x^2 +b)(x^2-b)$. Then one of $b$ or $-b$ is a square, but not the other, so $f$ will factor into two linear terms and a quadratic. So this case works. The trouble I am having is with the second case. If $d=b$, then we have 
$$ f(x) = (x^2 + ax + b)(x^2 -ax +b)$$ with $2b = a^2$. This is where I get stuck. How do I know that such an $a$ can exist? Edit: If there is a better approach to solving this, that would be great to know as well. I haven't been taught any of the relevant number theory to solve this, so I'm kind of out of my element here.","['abstract-algebra', 'polynomials', 'algebraic-number-theory']"
2560861,"Finding the range of $\cos t\sqrt{2-\cos^2 3t}$ via ""elementary"" (ie, pre-calculus) methods","I was wondering, what would be a precalculus level solution to the following question: What is the range of the function $x(t)=\cos t\sqrt{2-\cos^2 3t} \ $, for $\ t\in[0,2\pi)$ ? Please note that I am stressing "" precalculus level "". I know very well how to do this using the usual first-second derivative criteria for stationary points of a single variable, real valued function. However, my main motivation for the question is my attempt to explain it to precalculus-level students. (Their exposition to calculus is limited to the notions of limits, continuity and the intermediate value theorem for continuous functions. There have been no derivatives in the picture so far.) Thanks in advance! P.S.: Note, that the corresponding problem would appear far easier for the $\sin t\sqrt{2-\cos^2 3t}$, $t\in[0,2\pi)$ function: the range can be easily found to be $[-\sqrt{2},\sqrt{2}]$ by appealing to the intermediate value theorem for continuous functions and taking into account that the factors $\sin t$ and $\sqrt{2-\cos^2 3t}$ acquire their extreme values for the same value of the parameter $t$. However, this is not the case for $\cos t\sqrt{2-\cos^2 3t}$.","['algebra-precalculus', 'trigonometry', 'calculus', 'functions']"
2560888,"Does localization in commutative algebra really ""localize"" our study of a variety?","Since the lemmas and theorems of algebraic geometry are beyond my knowledge and mathematical maturity at this point, I have struggled to somehow intuitively/visually grasp its basic concepts from the well-written book An Invitation to Algebraic Geometry by Karen E. Smith, et al and my best friends, Wikipedia and the MSE community. Generally speaking, when something ends to the suffix -ization, it suggests the performance of an action. So, my question is: Is the localization of a commutative ring at a prime ideal (or other multiplicative sets) in some sense a way of looking at the things locally ? I already have some thoughts on this that I would like to share them with you. Also, a discussion with @rschwieb on this question provoked my curiosity. So, Hilbert's Nullstellensatz gives an algebro-geometric dictionary to think about varieties. In particular, when we work over an algebraically closed field, solutions of polynomial equations define geometric varieties that correspond to radical ideals in the polynomial ring over the field. This dictionary reverses the order of subset inclusion, translating bigger varieties to smaller radical ideals and vice-versa. A maximal ideal which is in some sense the biggest radical ideal becomes the smallest variety, a point. This dictionary also translates unions of varieties to intersections of their radical ideals. Therefore, a prime ideal is a radical ideal that its variety is in some sense indecomposable. Krull's dimension becomes a number that's supposedly the maximum dimension of these indecomposable sub-varieties as expected. Now, when we localize a commutative ring by a multiplicative set, we get a ring that has only one maximal ideal. In particular, when we do this with the complement of a prime ideal $P$ as a multiplicative set, it feels like we are crushing every point of the variety outside of the indecomposable component corresponding to $P$ to a single point, which is the maximal ideal of the localized polynomial ring. It seems like the big picture works. So, I am looking for more evidence about this. Maybe a few elementary explanations and well-versed related proofs. I am looking for more intuition. What results in algebraic geometry, in particular about localization, can be thought of as examples along this line of thought? Are the things I have said correct? Why is the localization of $\mathbb{Z}$ equal to $\mathbb{Q}$? Any pictorial explanation? Also, any more information regarding other concepts explained with this algebro-geometric language is welcome. At the end, if moderators found my question suitable for Math Overflow, please do move my question to Math Overflow if you think I can get better explanations and answers there.","['intuition', 'algebraic-geometry', 'commutative-algebra']"
2560890,Why does $\mu(E) = \int_E f d \mu$ define a measure?,"I'm trying to understand why defining a set function $\mu$ by setting $\mu(E) = \int_E f d \mu$ defines a measure, where $f$ is some integrable function. I know that if $E_1, E_2$ are disjoint, then $\int_{E_1 \cup E_2} f d \mu = \int_{E_1} f d \mu + \int_{E_2} f d \mu$, and that we can extend this to a finite union of pairwise disjoint sets. But how do we get $\sigma$-additvity from this? Do we need to use the monotone convergence theorem or something?","['lebesgue-integral', 'measure-theory']"
2560895,Does Weak Convergence in Joint Imply Weak Convergence in Marginal and Conditional distributions?,"Apologize for the confusing title. Assume there is a sequence of two random variables $x_n,y_n$ and two random variables $x_0,y_0$ s.t. $$(x_n,y_n)\overset{d}{\to}(x_0,y_0)$$ and that both $x_n,y_n$ and $x_0,y_0$ have continuous joint/marginal/conditional p.d.f., does the following also hold? $$x_n\overset{d}{\to}x_0$$
and for any fixed $a\in\mathcal{Y}$, 
$$(x_n|y_n=a)\overset{d}{\to}(x_0|y_0=a)$$ If the above is not always true, then when will the above holds?","['probability-theory', 'asymptotics']"
2560915,"Find number of binary operations on given set $S=\{a_{1},a_{2},...,a_{n}\}$","Let $S=\{a_{1},a_{2},...,a_{n}\}$ (i)Find number of binary relations $(*)$ on $S$ which are commutative. (ii)Find number of binary relations on $S$ such that $a_{i}*a_{j}\neq a_{i}*a_{k},\forall j\neq k.$ (iii)Let $a_{1},a_{2},...,a_{n}$ be the distinct real numbers,then find total number of binary relations on $S$ such that $a_{i}*a_{j}\leq a_{i}*a_{j+1}\forall i,j$ My Attempt : (i)Total number of pairs $(a_{i}*a_{j})$ possible are $\binom{n}{2}+n$ i.e.$\frac{n^2+n}{2}$. Each pair has $n$ choices. So number of binary relations should be $n^{\left(\frac{n^2+n}{2}\right)}$. But how many of these will be commutative. (ii)Now, $(a_{i}*a_{1})$ has $n$ choices so  $(a_{i}*a_{2})$ has $(n-1)$ choices and ....so on. So $(a_{i}*a_{j})$ has $n!$ choices. So for all $i$ required number of binary relations should be $(n!)^n$ (iii)How to define $*$ if $\leq$ is to be invoked.","['relations', 'elementary-set-theory']"
2560932,The rank of Jacobian matrix at a point of affine variety is independent of choice of generators,"This is a statement made in Hartshorne Chpt 1, Sec 5. Let $Y\subset A^n$ be an affine variety. Let $\{f_i\}$ be a set of generators of ideal $I(Y)\subset k[x_1,\dots, x_n]$. Let $p\in Y$. Define $r=\mathrm{rk}(\frac{\partial f_i}{\partial x_j}|_p)$. Then $p$ is smooth iff $r=n-\dim(Y)$. Q: How does one see this definition of rank is independent of the choice of generators? I guess he did not mention tangent space is isomorphic to $m_p/m^2_p$ at this part and I cannot use this intrinsic definition.","['algebraic-geometry', 'commutative-algebra']"
2560933,"If $X/M$ is a normed space with the induced seminorm, is $M$ closed?","Let $X$ be a normed space. If $M$ is a subspace, then $X/M$ has a known seminorm: $\left\|{x+M}\right\|=\inf\{\left\|{x+y}\right\|:y\in M\}$ It is easy to show that if $M$ is closed then $\left\|{}\right\|$ is a norm in $X/M$ (the only class with ""seminorm"" zero is the trivial class). My question is: if $\left\|{}\right\|$ is a norm in $X/M$, can we prove $M$ must be closed? I couldn't prove it so far. Is there a counterexample?",['functional-analysis']
2560942,Is there a connection between compactness and the Hilbert basis theorem?,"I was just talking with a few friends and we noticed something interesting. Namely, a straightforward corollary of the Hilbert Basis Theorem is: If $R$ is noetherian and $V \subset R^n$ is defined as the zero set of some (possibly infinite) collection $\{f_\alpha\}$ of polynomials in $R[x_1,\ldots,x_n]$, then $V$ is the zero set of some finite set of polynomials. This had a striking resemblance to the definition of compactness: A topological space $X$ is compact if every cover by a collection of open sets $\{U_\alpha \} $ has a finite subcollection. My question is: is there a deeper significance to this similarity? Is ""noetherian"" some sort of analog of compactness?","['general-topology', 'algebraic-geometry', 'commutative-algebra']"
2560968,Is the set of all possible binary strings countable?,"Determine whether the given sets are countable or uncountable. Justify your answers either with bijections or using results/methods. The set of all possible binary strings. Note a binary string is a sequence of 0s and 1s. If a binary string consists only of 0s and 1s, then is it even possible to find a bijection for it?",['elementary-set-theory']
2560990,Do non-convex platonic solids exist?,"Consider a solid with the following properties - It is composed of congruent, regular polygons. At each vertex, the same number of edges and faces meet. This is the same as the requirement for the Platonic solids, but the solid need not be convex. Of course, the five Platonic solids will satisfy these conditions, but are there any others? EDIT: consider the topological proof given in the Wikipedia article on Platonic solids - https://en.wikipedia.org/wiki/Platonic_solid If we require the Euler characteristic to be 1 instead of 2 (as in the proof) we get - $$\frac{1}{p} + \frac{1}{q} = \frac{1}{2} + \frac{1}{2E}$$ This still keeps open the possibility (using the same argument as for the Platonic solids given in that proof) of five such solids with Euler characteristic 1 (so they won't be convex). Question is, do these solids exist?","['platonic-solids', 'geometry']"
2561006,Product of Baire spaces,"Hi¡ I have troubles with the next exercise. I'm so stuck. Any hint? Let $X$ and $Y$ be a Baire spaces. Prove that if $X\times Y$ is of second category in itself, then, $X\times Y$ is a Baire space. I have some ideas, but, really I don't know how can I conclude. First, I thought in the definition. I take $\{ U_n\}_{n\in\mathbb{N}}$ a family of open and dense sets in $X\times Y$. Because $X\times Y$ is of second category in itself, we can conclude that $\displaystyle\bigcap_{n\in\mathbb{N}}U_n\neq\emptyset$. We need to prove now that $\displaystyle\bigcap_{n\in\mathbb{N}}U_n$ is a dense set in $X\times Y$. By contradiction, if we take a non empty open set $V$ of $X\times U$ such that $V\cap\left( \displaystyle\bigcap_{n\in\mathbb{N}}U_n\right)=\emptyset$, then, take a basic open $A\times B\subseteq V$. In this way, $(A\times B)\cap\left( \displaystyle\bigcap_{n\in\mathbb{N}}U_n\right)=\emptyset$. I think that $\Pi_{X}\left[ \displaystyle\bigcap_{n\in\mathbb{N}}U_n\right]$ (projection over $X$) is a dense set in $X$ and $\Pi_{Y}\left[ \displaystyle\bigcap_{n\in\mathbb{N}}U_n\right]$ (projection over $Y$) is a dense set in $Y$. In this way we obtain the desired contradiction because both pojections intersects $A$ and $B$ and then, $\displaystyle\bigcap_{n\in\mathbb{N}}U_n$ intersects $V$. But I don't know how can I prove the density of the projections (is it true?)
The other way is prove that every open set of $X\times Y$ is of second category in $X\times Y$. Again, by contradiction. Suposse that there exist $V$ open set in $X\times Y$ such that $V$ is of firts category in $X\times Y$, then, $V=\displaystyle\bigcup_{n\in\mathbb{N}}C_n$ with every $C_n$ a nowhere dense set. I think then that the projection of $V$ over $X$ is again a first category set, but this will be a contradiction (clearly, if it is true). 
Any hint? I really appreciate any help you can provide me.","['general-topology', 'baire-category']"
2561009,Cardinality of the set of multiple-representation decimals,"The set of real numbers in the open interval $(0,1)$ which have more
  than one decimal expansion is (A) Empty (B)non-empty but finite (C)Countably infinite (D)uncountable I know that, $$\frac{1}{10}=.10000...=.0999999...$$
              $$\frac{1}{10}=.010000...=.099999...$$
              $$ \frac{1}{100}=.0010000...=.0099999...$$ $$...$$ $$\frac{1}{10^n}$$ has also the two binary representation. I think answer is (C). Am I correct? How do I prove it rigorously. Please help me. When I was doing the above question, this question came in to mind. I have question that The set of real numbers in the open interval
  $(0,1)$ which have more than one binary expansion is (A) Empty (B)non-empty but finite (C)Countably infinite (D)uncountable I think the elements of the form $\frac{1}{2^n}$ has two binary expansion in $(0,1)$ . but I couldn't give the rigorous proof. Please help me.","['decimal-expansion', 'real-analysis', 'binary', 'real-numbers', 'elementary-set-theory']"
2561014,$P(X<Y)$ where X and Y are exponential with means $2$ and $1$,"Given that $X$ and $Y$ are independent variables and that $X$ is exponential with a mean of $2$ and $Y$ is exponential with a mean of $1$. Find $P(X<Y)$? From the information it can be concluded that $X \sim \operatorname{Exp}(\frac{1}{2})$ and $Y \sim \operatorname{Exp}(1)$ Hence, $f(x,y) = \frac{1}{2}e^{-\frac{1}{2}x} e^{-y} $ Therefore, $P(X<Y) = \int_{0}^{\infty} \int_{0}^{y} \frac{1}{2}e^{-\frac{1}{2}x} e^{-y} \,\,dx dy = \frac{1}{3}$ Is this the correct way to solve this problem?","['statistics', 'probability']"
2561029,A combinatorial proof of the identity: $\sum_{k=1}^n k \binom{n}{k}^2 = {n}\binom{2n-1}{n-1}$?,"Give a combinatorial proof of the identity: $$\sum_{k=1}^n k \binom{n}{k}^2 = {n}\binom{2n-1}{n-1}$$ I am not exactly sure where to start. Since $\binom{n}{k}^2 = \binom{n}{k}\binom{n}{k}$, thus, above equation says that we are choosing k elements out of n elements and we are doing it twice where k starts from 0 and goes all the way to n and we add all of them up. However, about the right side, I have no idea what to say and how it fits in this situation. Any help will be grately appreciated.","['combinations', 'combinatorial-proofs', 'permutations', 'combinatorics', 'summation']"
2561032,isomorphic quotient groups but non-isomorphic groups,I am studying for an upcoming exam and was given the following problem as practice: Can it happen that $G_1$ is not isomorphic to $G_2$ yet have isomorphic normal subgroups $N_1 < G_1$ and $N_2 < G_2$ and isomorphic quotient groups $G_1/N_1$ and $G_2/N_2$? I think it must be that $G_1$ is isomorphic to $G_2$ but I cannot for the life of me show this. One situation might be that the order of $G_1$ and $G_2$ are not the same then the order of $G_1/N_1$ is not the same as $G_2/N_2$ but if $|G_1|=|G_2|$ it seems like its possible for them to not be isomorphic yet display the above properties.,"['normal-subgroups', 'group-theory', 'group-isomorphism', 'quotient-group']"
2561085,Is there a function $f:{\mathbb N}\to{\mathbb N}$ that is neither injective nor surjective? [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question Is there a function $f:{\mathbb N}\to{\mathbb N}$ that is neither injective nor surjective ? I came up with $n\mapsto\sin n$ as not all outputs are mapped and some inputs have the same output, but then I realized $\sin n$ doesn't produce a natural number. I have to map the natural numbers to the natural numbers. I also came up with other ones but they always seem to be total and injective or total and subjective.","['elementary-set-theory', 'functions']"
2561109,Acceptance Sampling: Probability that the owner will return a shipment of fruits,"A grocery shop receives a monthly shipment of $1000$ fruits. The owner knows that usually $1 \%$ of the fruits are damaged when they arrive. To estimate the number of damaged ones, he takes a sample of $50$ fruits. If $2$ or more fruits in the sample are damaged then he returns the package. Approximate the probability that the owner will return a shipment. The way I've tried solving is: $1 - \binom{50}{0}(0.99)^{50}(0.01)^{0} - \binom{50}{1}(0.99)^{49}(0.01)^{1} = 0.089$ Is this correct? They ask for an approximation so that's why I'm confused.","['statistics', 'probability']"
2561146,How do I evaluate $\sum_{a=1}^{\infty}\sum_{b=1}^{\infty}\frac{ab}{(a+b)!}$,$$\sum_{a=1}^{\infty}\sum_{b=1}^{\infty}\frac{ab}{(a+b)!}$$ I'm not really comfortable with more than 1 sigma's and that's why this question is confusing me. I don't think it's possible to reduce the number of variables to 1 here. The answer is $\frac{2}{3}e$,"['summation', 'sequences-and-series']"
2561150,An example of set which is not Souslin set,"DEFINITION Let $X$ be a topological space. A set $B \subseteq X$ is called Souslin set if there is a family of closed sets $\{F_s|s \in \mathbb{N}^{<\mathbb{N}} \}$ in $X$ such that $$B=\bigcup_{\sigma \in \mathbb{N^N}} \bigcap_{n=1}^{\infty} F_{\sigma\upharpoonright n}$$ Question I know that a countable intersection of closed sets or countable union of closed sets is Souslin set. I want to find an example of set which is not Souslin set. First, I assume that $A=[0,1) \subseteq \mathbb{R}$ is not Souslin set, but $A$ is $F_\sigma.$ Then, my assumption is not true. How to construct a set which is not Souslin set? Any hint would be appreciated. Thank you very much.","['descriptive-set-theory', 'general-topology']"
2561159,Trigonometry problem solving in diagram,"A is a point on the $x$ axis and B is a point on the $y$ axis such that $(5,3)$ lies on the straight line passing through A and B . Given that OP is perpendicular to AB and $\angle BAO = \theta $ , Show that OP = $3 \ cos \theta + 5 \sin \theta $ My attempt , $\sin \theta = \frac{OP}{OA} $ $OP =  OA \sin \theta$ OA = $ 5 + ? $ The '?' is what I marked on the diagram as well. I'm not sure how do I get that .",['trigonometry']
2561166,Two equivalent norms on $\mathcal{L}(E)^n$,"Let $E$ be a complex Hilbert space, and $\mathcal{L}(E)$ be the algebra of all bounded linear operators on $E$. For ${\bf A}:=(A_1,...,A_n) \in \mathcal{L}(E)^n$ we recall the definitions of the following two norms on $\mathcal{L}(E)^n$:
$$\|{\bf A}\|=\displaystyle\sup_{\|x\|=1}\bigg(\displaystyle\sum_{k=1}^n\|A_kx\|^2\bigg)^{\frac{1}{2}},$$ and
 $$\omega_e({\bf A})=\displaystyle\sup_{\|x\|=1}\bigg(\displaystyle\sum_{k=1}^n|\langle A_kx\;|\;x\rangle|^2\bigg)^{1/2}.$$ It's not difficult to prove that $\omega_e({\bf A}) \leq \|{\bf A}\|$. Are $\|\cdot\|$ and $\omega_e(\cdot)$ two equivalent norms on $\mathcal{L}(E)^n\,?$ If the answer is true, I hope to find $\alpha$ such that
  $$\alpha \|{\bf A}\|\leq \omega_e({\bf A}) \leq \|{\bf A}\|.$$
  Note that if $n=1$, it is well known that
  $$\displaystyle\frac{1}{2}\|A\|\leq \omega(A)\leq\|A\|.$$ And you for you help.","['functional-analysis', 'hilbert-spaces']"
2561169,When $y(t) = \lambda x(t) - \int_{-1}^{1} (ts^2 + t^2 s^3 + t^3 s) x(s) ds$ has a solution?,"The question is as follows: Estabilish conditions for the integral equation
$$y(t) = \lambda x(t) - \int_{-1}^{1} (ts^2 + t^2 s^3 + t^3 s) x(s) ds$$
to have a solution. $\textbf{Definitions and efforts:}$ Actually I do not know what to do! It's my first of this kind and I am trying to learn! I just know that it is an integral equation which is said is Fredholm equation because the integration limits $a$ and $b$ are constants. Can someone please let me know how can we attack to this problem and what are techniques? Thanks!","['functional-analysis', 'real-analysis', 'integral-equations']"
2561196,Proving the presence of one real root,"""Show that the following equation has exactly one real root: $3x+2\cos x+5=0$"" So I think the way to approach this problem is to use a combination of the intermediate value theorem and the mean value theorem. But since we are not given a specific interval, I'm not entirely sure what values of $f(a)$ and $f(b)$ to choose. Am I suppose to choose $f(0)$ and $f(1)$ and see that $0$ lies in between them. If so, how exactly can we proceed with the mean value theorem after using the intermediate value theorem. Do we have to check for continuity and the number $c$, or is there some other way? Any help?","['derivatives', 'limits', 'roots', 'trigonometry', 'calculus']"
2561201,$a=\frac{3b}{b-3}$ Find all values of $b$ where $a$ is a positive integer.,"Here is the problem: $$ a = \frac{3 b}{b-3} $$
$a$ and $b$ are positive integers. You have to find all the possible values of $b$ where $a$ is a positive integer. Once all the values of $b$ has been found, you have to prove that they are the only possible values of $b$. What I've attempted I've found 2 values for a and b: (4, 12) and (6, 6). I got this mostly by luck, which is not what I'm aiming for. I've also wrote a code which confirmed that these were the only combinations up to $b=100,000$, however I would like a mathematical method to solve these kind of questions. Since $a$ is an integer, this implies that $3b$ is divisible by $b-3$. I wrote expressed this as $3 b = (b-3)\cdot m$, where $m$ is a natural number. I tried use this to prove that the values I found above were the only values possible, however to no avail. Could someone please explain how to approach and solve problems like this (where you have to find all possible values and prove that they are the only possible values)? Thank you for your time.","['algebra-precalculus', 'proof-writing', 'problem-solving']"
2561232,Spivak or Apostol to prepare for learning Baby Rudin on my own?,"I wish to learn real analysis on my own using the first 7 chapters from Baby Rudin. My goal is to have a good math background so as to study from PhD-level books in economics and finance on my own (e.g, stochastic calculus in finance, optimization, etc.). As an economics student, I find this kind of learning really challenging, so I appreciate it very much if you could give me some good suggestions/tips. I have the following:
1) Apostol's single-variable calculus book without solutions manual
2) Spivak's single-variable calculus book + solutions manual
3) Time constraints and a rusty knowledlege of calculus (single-variable/multivariable calculus/LA) If I have roughly 1-2 years ahead, I have to work full-time, and I have to choose only one of these 2 books, then which calculus book is better for self-study and for preparing for the first 7 chapters from Baby Rudin? Thanks much","['real-analysis', 'calculus']"
2561273,"How many permutations are there for the letters in the word ""meеt""?","Which would be correct: $$P_4=4!=24 \quad \text{or} \quad \frac{4!}{1!2!1!}=12?$$ I don't know if Meеt and Meеt with exchanging the two $e$'s are different or not?
If the answer is the latter, why would it be different from the permutations of the word Meat with an $a$, which should be $24$ permutations I believe? Thanks.","['permutations', 'combinatorics']"
2561302,Classifying finitely generated modules over complex quotient polynomial ring,"Please help demystify the classification of finite modules over PIDs for me. I want to decompose a finitely generated module over a PID into its elementary divisors or its invariant factors (see Dummit & Foote, Theorems 12.5 and 12.6 if you're not familiar). Here's an example from Artin: Classify finitely generated modules over the ring $\mathbb{C}[\epsilon]$ where $\epsilon^2 = 0$. How does one start this process in the above simple case? I understand much of the proofs in the text, but can't seem to work out a simple example like this one. I see the same textbook problem here: Classify finitely generated modules over the ring $\mathbb{C}[\epsilon]$ where $\epsilon^2=0$ But don't believe they've completed the step of decomposing into its elementary divisors or invariant factors. Can someone help with this particular step?","['abstract-algebra', 'modules', 'principal-ideal-domains']"
2561353,"Set of functions from empty set to $\{0,1\}$","How does the set of all functions $\{f \,|\, f: \emptyset \to \{0,1\}\}$ look like? Is it empty or does it contain infinitely many functions? Does the definition $f: \emptyset \to \{0,1\}$ make sense at all? I was wondering because we know that the two sets $\{0,1\}^X$ and $\mathcal{P}(X)$ have the same cardinality. But this is only true if $X$ is non-empty, right?","['elementary-set-theory', 'functions']"
2561363,"Between any two continuous functions $f>g$, can we find a real-analytic function?","I asked myself a question which I thought was interesting, but I'm not sure how to approach it. The Question The question is, given two continuous functions $f,g:\mathbb{R}\rightarrow\mathbb{R}$ such that $f > g$, is there a real analytic function $h$ between $f$ and $g$ (so that $f > h > g$)? An easier version of the question can be asked over closed intervals.
Given two continuous functions $f,g:[a,b]\rightarrow\mathbb{R}$ such that $f > g$, is there a real analytic function $h$ between $f$ and $g$? In this case, the answer is yes, and the result is actually stronger than expected.
Essentially, this is an application of the Weierstrass Approximation Theorem. By the extreme value theorem, the function $H(x) = (f(x) - g(x))/2$ has a   minimum $M > 0$. You can define $k(x) = (f(x) + g(x))/2$ and then apply the Weierstrass Approximation Theorem to get a polynomial $p:[a,b]\rightarrow\mathbb{R}$ such that $\lVert p - k\rVert < M$.
  Then $p$ is a polynomial such that $p(x)\in (k(x) - M, k(x) + M)\subseteq (g(x), f(x))$ for all $x\in[a,b]$. However, you run into issues when the domain is the real line.
Here are some thoughts I had so far. For I am aware that there is a generalized Stone-Weierstrass Theorem on locally compact Hausdorff spaces $X$ concerning functions in $C_{0}(X)$.
There are two issues though.
The first is that our continuous functions $f,g$ don't necessarily tend to zero as $x\rightarrow\pm\infty$.
The second is that the difference $f(x) - g(x)$ is allowed to get arbitrarily small as $x\rightarrow\pm\infty$. The first issue isn't major to me, because I think I have a way to evade it.
For all intents and purposes, we can assume that $f,g$ tend to zero if it suits our needs. The second issue, though, seems to be fatal, and it seems like there is no way to modify the Stone-Weierstrass Theorem appropriately. This makes me think I need a completely different approach. Against If I want to make a counterexample, maybe I can use pathological functions like the Weierstrass function $w:\mathbb{R}\rightarrow\mathbb{R}$.
I'm thinking that if we take $f(x) = w(x) + e^{-x^{2}}$ and $g(x) = w(x)$, we can force any intermediate function $h$ to become ""more and more detailed"" as it gets sandwiched closer and closer between $f,g$ for large $x$.
Then this function might become ""too detailed"" to be analytic, but I have no rigorous way to express this idea. Even worse, I'm having doubts that this would go anywhere because there is always ""wiggle room"" between $f$ and $g$, so maybe we can fit an analytic function between them after all. Are there any suggestions on how to make progress on this question?","['real-analysis', 'power-series', 'analysis']"
2561435,Simply connected noncompact complete 2-dimensional submanifold of $\mathbb{R}^3$,Can a simply connected noncompact complete 2-dimensional submanifold of $\mathbb{R}^3$ (endowed with the metric induced by the flat metric of $\mathbb{R}^3$ ) be conformally equivalent to the hyperbolic plane? From the uniformization theorem I know that it must be conformmally equivalent either to the euclidean plane or to the hyperbolic plane. But can I exclude the second case?,"['conformal-geometry', 'riemannian-geometry', 'differential-geometry']"
2561455,"If I am 80% sure, is there an 80% chance that I'm right? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 6 years ago . Improve this question A friend of mine said this, and I couldn't argue why I thought it was wrong. Obviously, in some circumstances it is valid, say if you flip a coin, and I say I'm 50% sure it lands on heads. In a discussion about whether sending a ""dick pic"" was illegal, he said: I'm 99.3% sure, so there's only a 0.7% chance that I'm wrong. Now, if we assume that it is illegal, I would agree, but isn't there a 50% chance that there is a 99.3% chance that he is wrong? Could someone explain to me if and how this is wrong?",['probability']
2561484,From prime to prime by squaring the digits,"I took prime $131$, squared digits of it and wrote them in natural order as they appear, from left to right, and obtained $191$, then I obtained $1811$ by the same procedure, and then $16411$ and then $1361611$, and $131,191,1811,16411$ are primes and $1361611$ is not. To illustrate how to arrive at the next number in sequence from previous one, take, for example, $16411$. We have: $1^2=1$ and $6^2=36$ and $4^2=16$ and $1^2=1$ and $1^2=1$ so we obtain $1361611$ from $16411$. Can we generate in this way as large a number of different (to avoid loops like one that starts with $11$) primes as we want? Or there is/are some law/laws that do not allow that?","['number-theory', 'recreational-mathematics', 'prime-numbers']"
2561544,If $\sum\limits_{n=1}^\infty a_n $converges does it imply that $\sum\limits_{n=1}^\infty \dfrac {a_n^{1/4}}{n^{4/5}}$ is convergent?,"Let $\sum_{n=1}^\infty a_n$ be a convergent series of positive terms, then is it true that $$\sum_{n=1}^\infty \dfrac {a_n^{1/4}}{n^{4/5}}$$ is convergent ? I tried comparing with $\sum a_n$ , but without any progress. Please help with any hint.","['real-analysis', 'sequences-and-series', 'calculus', 'convergence-divergence', 'analysis']"
2561569,"If two matrices have the same determinant, are they similar? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I am wondering if we have two square matrices $A$ and $B$ and if $\det A = \det B$, then does an invertible matrix $P$ exist with 
$$A = P^{-1} B P$$","['matrices', 'determinant']"
2561593,Condition for two cubic equations to have two common roots,The equations $x^3-x^2+bx+c=0$ and $x^3+cx^2+bx-d=0$ have two common roots.The question is to show that $b^2=d$ I couldn't get how to approach this problem.Any help would be appreciated. thanks,"['algebra-precalculus', 'quadratics']"
2561646,Spivak Calculus on Manifolds - Problem 3-18,"$\textbf{3.18}$ If $f: A \longrightarrow \mathbb{R}$ is non-negative and $\int_A f = 0$, show that $\{ x \in A : f(x) \neq 0 \}$ has measure $0$. Hint: prove that $\left\{ x \in A : f(x) > \frac{1}{n} \right\}$ has content $0$. I know that the set $\{ x \in A : f(x) \neq 0 \}$ has measure $0$. Hint: prove that $\{ x ; f(x) > \frac{1}{n} \}$ has content $0$ for each $n$, then the same set has measure $0$ and observing that $$\{ x \in A : f(x) \neq 0 \} = \bigcup_{i = 1}^{\infty} \left\{ x \in A : f(x) > \frac{1}{n} \right\}$$ i.e, $\{ x \in A : f(x) \neq 0 \}$ is a countable union of set with measure $0$, then $\{ x \in A : f(x) \neq 0 \}$ has measure $0$, therefore is sufficient prove the hint. I think to prove the hint I need to use the fact that a function $f: A \longrightarrow \mathbb{R}$ is discontinuous in $x \in A$ if and only if $o(f,x) > 0$ (theorem $1-10$ of Spivak's book) and use the fact that $f$ is integrable if and only if $B := \left\{ x \in A : f \  \text{is not continuous at} \ x \right\}$ has measure $0$ (theorem $3-8$ of Spivak's book). I'm trying relate that $f(x) > \frac{1}{n}$ with $o(f,x) > \frac{1}{n}$, but I don't know how to do this. I would like to receive a hint about how to do this. Thanks in advance! $\textbf{P.S.:}$ 1) $A \subset \mathbb{R}^n$ is a rectangle; 2) A set with content $0$ is an set $A$ such that for every $\varepsilon > 0$, we can find a finite cover $\{ U_1, \cdots, U_n \}$ of $A$ by closed rectangles such that $\sum_{i = 1}^{i = n} v(U_i) < \varepsilon$, where $v(U_i)$ is the volume of $U_i$. 3) The oscillation of $f$ at $x$ is defined by $o(f,x) := \lim_{\delta \rightarrow 0} \left[ \sup f \left( B(x, \delta \right) - \inf f \left( B(x, \delta) \right) \right]$.","['multivariable-calculus', 'integration', 'calculus']"
2561676,Set of values of $x$,"If the inequality
  $$(1-a^2)x^2+(2a-3)x+1<0$$
  is true for all values of $a$ then the set of values of $x$ is? I took two cases (the parabola opens upwards and the parabola opens downwards). For the first case the value of $x$ is all real except the interval containing roots. For the second case the value of $x$ is the interval containing the roots. I couldn't proceed with this as I couldn't eliminate $a$. Any ideas? Thanks","['algebra-precalculus', 'inequality']"
2561678,"A compact, Hausdorff and connected topology on $\mathbb {N}$","I am studying Topology for the first time and I am attempting to solve the following homework problem. Given an example of a topology on $\mathbb {N}$ such that it makes it a compact and Hausdorff space. Can this topology also be connected? My solution so far: Let $(\mathbb{N},\tau)$ and $(\mathbb{N}$$\cup\left\{ \infty\right\} ,\tau')$
be two topological spaces. The topology $\tau$ is the subspace topology
inherited from the usual topology in $\mathbb{R}$ and $\tau'$ is
the topology of the Aleksandrov compactification of $\mathbb{N}$. Consider the map 
\begin{array}{cccc}
f: & (\mathbb{N}\cup\left\{ \infty\right\} ,\tau^{'}) & \rightarrow & (\mathbb{N},\tau^{*})\\
 & \infty & \mapsto & 0\\
 & n & \mapsto & n+1
\end{array} I claim that the final topology induced by $f$ is Hausdorff and compact. $\tau$ is the discrete topology since every singleton is open. $\tau'=\tau\cup\{(\mathbb{N}\setminus C)\cup\{\infty\}\mid C\text{ is compact in }\mathbb{N}\}$.
The compact sets of $\mathbb{N}$ are finite sets because the compacts
sets of a discrete topology must be finite (the proof being clear).
Therefore, 
$$
\tau'=\tau\cup\left\{ (\mathbb{N}\setminus\{n,\dots,k\})\cup\{\infty\}\right\} 
$$ The final topology induced by $f$ is the finest topology that makes
$f$ continuous, i.e. $U\in\tau^{*}\iff f^{-1}(U)\in\tau'$ and it
follows that 
$$
\tau^{*}=\left\{ \left\{ n\right\} \mid n\in\mathbb{N}\setminus\left\{ 0\right\} \right\} \cup\left\{ \mathbb{N}\setminus\left\{ n,\dots,k\right\} \mid n>0\right\} 
$$ It's easy to see that $(\mathbb{N},\tau^{*})$ is compact since for
any cover of $\mathbb{N}$ there is a finite subcover of the form
$\mathbb{N}\setminus\left\{ n,\dots,k\right\} \cup\left\{ n,\dots,k\right\} $.
I could also reason that the image of a compact space is compact but
one gains more insight in this fashion. Let's check that $(\mathbb{N},\tau^{*})$ is still Hausdorff. Let
$x,y\in\mathbb{N}$ such that $x\neq y$. There are two cases to be
considered. If $x,y\neq0$ then pick the following open sets $U=\left\{ x\right\} $
and $V=\left\{ y\right\} $. Now suppose, without loss of generality that $x\neq0$. Then choose
the opens sets $U=\left\{ x\right\} $ and $V=\mathbb{N}\setminus\{x\}$.
In either case $U\cap V=\emptyset$ and $U,V\in\tau^{*}$proving that
it is indeed Hausdorff. Clearly this topological space isn't connected. Given any subspace
$U\subset\mathbb{N}$ which is not a singleton or $\emptyset$ (these
are always trivially connected) it is always possible to find $V_{1},V_{2}\in\tau^{*}$
such that $V_{1}\cap V_{2}=\emptyset$ and $V_{1}\cup V_{2}=U$. Again,
let's consider two different cases. If $0\notin U$ then $U$ is a discrete space which is trivially disconnected. If $0\in U$ then simply set $V_{1}=U\setminus\left\{ 0\right\} $
and $V_{2}=\mathbb{N}\setminus\left\{ n,\dots,k\right\} $ such that
$\left\{ n,\dots,k\right\} \notin V_{1}$. This proves that this space is actually totally disconnected. Questions : I feel that this is always true, i.e. given any compact and Hausdorff topology on $\mathbb{N}$ it is always the case that it can't be connected. My argument would go like this: since the Aleksandrov compactification is unique up to homeomorphism then every topology that I could give for $\mathbb{N}$ would give rise to a homeomorphic topological space. Clearly I could have defined $f$ in another way but the topology would be the ""same"" (up to homeomorphism). I found this exercise in a book and the hint they gave was: think of Baire category theorem. But I honestly can't see the connection. I know that a compact and Hausdorff space is a Baire space but what follows from here...?",['general-topology']
2561701,Bound on the norm of a matrix power,"Suppose we have the square matrix $A$ and we know that its spectral radius $\rho(A)$ is less than $1$, therefore matrix $A$ is stable. How can we prove that $\exists \gamma \in(0,1)$ and $\exists M >0$ such that 
$$\|A^k\|\leq M\gamma^k, \:\:\:\: \forall k\geq0$$
What I tried so far is $\|A^k\|=\|A\dots A\|\leq\|A\|\dots \|A\| =\|A\|^k$ so taking $\gamma=\|A\|$ I should be close to the above inequality, but I am not sure it is correct.","['matrices', 'normed-spaces', 'stability-theory']"
2561715,Differentiation of $\sum_{n=0}^{\infty}\frac{1}{(n+1)3^n}x^{n+1}$,Let $$f(x)=\sum_{n=0}^{\infty}\frac{1}{(n+1)3^n}x^{n+1}=x+\frac{x^2}{6}+\frac{x^3}{27}+\frac{x^4}{108}+\cdots$$ The question asked me to use the knowledge of series to compute $f'(2)$. How should I solve? Wouldn't be just differentiate each term and substitute $2$?,"['derivatives', 'sequences-and-series', 'calculus']"
2561744,Calculating perihelia using Maple,"I have the differential equation DE:=$\frac{d^2}{d\phi^2}(\frac{1}{r(\phi)})+\frac{1}{r(\phi)}=1+\frac{3}{64r(\phi)^2}$, with initial conditions ICS:=$r(0)=\frac{2}{3}, (r)'(0)=0$. Solving for $r(\phi)$ and plotting the orbit with polar coordinates sol:=dsolve({DE,ICs},numeric,output=listprocedure); 
r_sol:=rhs(sol[2]);
polarplot(r_sol(phi),phi=0..10*Pi; I observe an orbit about the origin that has precessing perihelion.  I want to calculate, using Maple, how much the perhelion precesses by per revolution. How do I find the value of $\phi$ for each of the perihelia?","['maple', 'ordinary-differential-equations', 'polar-coordinates', 'general-relativity']"
2561793,"Prove: $\int_\gamma \bar z \, dz=2i\operatorname{Area}(G)$","Let $G$ be a bounded, open and connected set and $\gamma$ be its boundary. Prove that if $\gamma$ is a closed, smooth curve, then:  $$\int_\gamma \bar z \, dz = 2i \operatorname{Area}(G)$$ What I have done so far: I proved that the statment is correct when $G$ is a triangle, and then when the boundary of $G$ is a polygonal chain. Now for the general case, I thought about approximating $\gamma$ with polygonal chains somehow, but I'm pretty stuck. Is my thinking correct? Any ideas how to move forward?","['complex-analysis', 'contour-integration']"
2561857,How do you solve the following PDE $\nabla_x y(x) \cdot y(x) = f(x)$?,"How do you solve PDEs of the form  $\nabla_x y(x) \cdot y(x) = f(x)$? Here, $y:\mathbb{R}^m \rightarrow \mathbb{R}$, $\nabla_x y(x)$ is the gradient of $y(x)$ w.r.t $x$ and $f:\mathbb{R}^m \rightarrow \mathbb{R}^m$ is a continuous function.","['ordinary-differential-equations', 'partial-differential-equations']"
2561878,"Show that if $X\sim\text{Pois}(\theta)$, then $I(\theta;X) = 1/\theta$.","The Fisher information matrix $I(\theta;X)$ about $\theta$ based on $X$ is defined as the matrix with elements $$I_{i,j}(\theta;X) = \operatorname{Cov}_\theta\bigg(\frac{\partial}{\partial \theta_i}\log f_X(X\mid\theta), \frac{\partial}{\partial\theta_i}\log f_X(X\mid \theta) \bigg).$$ Exercise: Let $X\sim \text{Pois}(\theta)$. Show that $I(\theta;X) = 1/\theta$. What I've tried: If I'm not mistaken then $\dfrac{\partial}{\partial \theta_i} \log f_X(X \mid \theta) = \dfrac{x_i}{\theta} + \log e$. The Fisher information matrix (a $1\times 1$ matrix in this example) would be given by $\operatorname{Cov}_\theta\left(\dfrac{x_i} \theta + \log e, \dfrac{x_i} \theta + \log e\right)$. We know that $\operatorname{Cov}_\theta\left(\dfrac{x_i} \theta + \log e, \dfrac{x_i}{\theta} + \log e\right) = \operatorname{Var}_\theta\left(\dfrac{x_i}\theta + \log e\right) = \operatorname{Var}_\theta \left(\dfrac{x_i}{\theta}\right) = x_i^2 \operatorname{Var}_\theta \left(\dfrac 1 \theta \right).$ Obviously I'm doing something wrong as the $x_i^2$ before the variance is a problem. Besides that, I'm not sure if I can calculate $\operatorname{Var}_\theta\left(\dfrac 1 
 \theta \right)$. Question: How do I show that $I(\theta;X) = 1/\theta$? Thanks in advance!","['statistical-inference', 'probability-theory', 'probability-distributions', 'statistics', 'probability']"
2561888,You meet two arbitrary children of a married couple the odds are $50\%$ that they both have blue eyes. How many children does the family have?,I'm stuck on the following riddle: you meet two arbitrary children of a married couple the odds are $50\%$ that they both have blue eyes. How many children does the family (the married couple) have? The possible answers are: A: $3$ B: $4$ C: $5$,"['puzzle', 'recreational-mathematics', 'probability']"
2561924,Any insight on the half reciprocal Fibonacci sequence?,"Define $R_n=R_{n-1}+\frac{1}{R_{n-2}} $ with $R_0=R_1=1$ Define $K_n=\frac{1}{K_{n-1}}+K_{n-2} $ with $K_0=K_1=1$ These are all limits I've found using Python but no basis of proof for these limits and was wondering if anyone has experience with these. $$\lim_{n\to\infty} \frac{R_{2n}^2}{K_{2n}^2}=\pi\tag{1}$$ $$\lim_{n\to\infty}\frac{R_{2n+1}^2}{K_{2n+1}^2}=\frac{4}{\pi}\tag{2}$$ $$\lim_{n\to\infty}\frac{R_{dn}}{R_{n}}=\sqrt{d}\tag{3}$$ For odd n, and even d $$\lim_{n\to\infty}\frac{K_{dn}}{K_{n}}=\frac{2\sqrt{d}}{\pi}\tag{4}$$ Else $$\lim_{n\to\infty}\frac{K_{dn}}{K_{n}}=\sqrt{d}\tag{5}$$ and $$\lim_{n\to\infty}(K_{2n+1}^2-K_{2n-1}^2)=\pi; \;\; \lim_{n\to\infty}(R_{n+1}^2-R_{n}^2)=2\tag{6}$$ And I did the math a long time ago and lost my methods but I ended up getting the formula $$R_{an}\approx F(R_n,a)=\frac{R_n^2\sqrt{a}+\sqrt{aR_n^4+2R_n^2(a-2)+a}}{2R_n}\tag{7}$$ and substituting R_n=1 you get the approximating (although weak) formula $$R_n\approx\frac{\sqrt{n}}{2}+\sqrt{n-1}\tag{8}$$ I suppose my questions would be is there a better approximation formula? What happens when we generalize to ($R_0=a, R_1=b$) or ($K_0=a, K_1=b$)
Is there a good approximation formula for $K_n$, and why does the sequence relations above converge to $\pi$","['approximation-theory', 'recreational-mathematics', 'sequences-and-series']"
2561960,Prime and primary ideals in $\mathbb{Z}[\sqrt{5}]$,"Let $R=\mathbb{Z}[\sqrt{5}]$. The ideal $(2, 1-\sqrt{5})$ is prime in $R$, right (as $R/(2, 1-\sqrt{5})=\mathbb{F}_2$)? 1. Is then $(2^n, 1-\sqrt{5})$ primary for some $n\geq2$? 2. Are $(2)$ and $(3)$ prime ideals and $(2^n)$ and $(3^k)$ primary ideals in $R$? I was thinking that at least $(2^n)$ should be primary as the zero divisors of $R/(2^n)$ are $2, 1+\sqrt{5}, 1-\sqrt{5}$, i.e. nilpotent...
Or are there some problems as $-4=(1+\sqrt{5})(1-\sqrt{5})$...","['abstract-algebra', 'ideals', 'algebraic-number-theory', 'commutative-algebra']"
2561962,"For which $u$ does the derivative $f'(u,0)$ of $f(x,y)=x^3/(x^2+y^2)$ exist?","Let $f: \mathbb{R}^2\to \mathbb{R}$ be defined by setting $$f(x,y)=\begin{cases}\frac{x^3}{x^2+y^2} & (x,y)\neq (0,0)\\0 & (x,y)=(0,0)\end{cases}$$ (a) For which vectors $u\ne 0$ does $f'(0; u)$ exist? Evaluate it when it
exists. (b) Do $D_1f$ and $D_2f$ exist at $0$? (c) Is $f$ differentiable at $0$? (d) Is $f$ continuous at $0$? I have thought a lot about this problem: For (a), be $u\neq 0, u:=(h,k)$, so $\lim_{t\to 0}\frac{f(0+tu)-f(0,0)}{t}=\lim_{t\to 0}\frac{f(th,tk)}{t}=\lim_{t\to 0}\frac{(th)^3}{(th)^2+(tk)^2}\frac{1}{t}=\frac{h^3}{h^2+k^2}$, then $f'(0,u)$ exists for all $u\neq 0$. For (b), $\lim_{t\to 0}\frac{f(0+te_1)-f(0)}{t}=\lim_{t\to 0}\frac{f(t,0)}{t}=\lim_{t\to 0}\frac{t^3}{t^3}=\lim_{t\to 0}1=1$ so $D_1f(0,0)=1$ and $\lim_{t\to 0}\frac{f(0+te_2)-f(0)}{t}=\lim_{t\to 0}0=0$ so $D_2f(0,0)=0$ I am having problems solving (c) and (d), could someone help me please? Thank you very much.","['real-analysis', 'calculus', 'multivariable-calculus', 'analysis', 'vector-analysis']"
2561963,A confusion regarding the concept of principal divisor,"Let $M$ be a complex manifold. Then a Weil-divisor $D$ on $M$ is given by the formal sum $\sum_{V\in\nu}{\eta}_{V}.V$, where $\nu$ is a locally finite collection of irreducible analytic hypersurfaces in $M$ and ${\eta}_{V}\in\mathbb{Z}$ for each $V\in\nu$. Now, consider a meromorphic function $f$ on $M$. For each irreducible analytic hypersurface $V\subset M$ one can define an integer $ord_{V}(f)$ called the order of $f$ along $V$. Lastly, one defines a Weil -divisor corresponds to $f$ as $(f)=\sum_{V} ord_{V}(f).V$, where $V$ runs over all irreducible analytic hypersurfaces in $M$ [See Griffiths-Harris ""Principles of Algebraic Geometry"", page 130-131 for details]. Clearly, this collection is not locally finite. So, to conclude that $(f)$ is a Weil-divisor one needs to show $\{V:ord_{V}(f)\neq 0\}$ is locally finite. But I am quite unsure how to establish this. Any help is appreciated.","['divisors-algebraic-geometry', 'complex-geometry', 'algebraic-geometry']"
2561997,Local Form of Covariant Derivative Induced from a Connection one-form,"Let $P\rightarrow M$ be a Principal G-Bundle with $E=P\times_\rho V$ the associated vector bundle with $\rho$ a representation of $G$ on $GL(V)$. Also let $\omega$ be a connection one-form on $P$ i.e. $\omega\in\Omega(P; Lie(G))$. We have for some local trivialisation $\phi:P\rightarrow U\times G$, $
(\phi^{-1})^*\omega=g^{-1}a_Ug+ g^{-1}dg
$ with $a_U$ a lie algebra valued one form on $U$, and open set of $M$. Let $\nabla$ be the covariant derivative induced by the connection $\omega$. If we have a local trivivialisation $\psi:E\rightarrow U\times V$. with a section $s\in\Omega^{0}(M; E)$. I am wondering how we derive the formula $\psi(\nabla s)=(x, ds_U+\rho_*(a_u)s)$ in the local trivialisation. Please just comment if something is unclear. I have seen this formula in multiple sources and can't find a derivation. Appreciate any help that is given.","['fiber-bundles', 'principal-bundles', 'differential-geometry', 'vector-bundles', 'connections']"
2562055,"Show $A \in \cal F$ exists, such that $\mathbb P(A)=1$ and $\mathbb Q(A)=0$.","Let $\mathbb P$ and $\mathbb Q $ different probability measures on $(\Omega, \cal F)$ and $T:\Omega \to \Omega$ a measurable function, which is $\mathbb P$ and $\mathbb Q$ ergodic. Show $A \in \cal F$ exists, such that $\mathbb P(A)=1$ and $\mathbb Q(A)=0$. Since $T$  is $\mathbb P$ and $\mathbb Q$ ergodic $\forall A \in \cal F$ with $A=T^{-1}(A)$, $\mathbb P(A) \in \{0,1\}$ and $\mathbb Q(A) \in \{0,1\}$.
Furthermore I know since T is ergodic $\lim_{n\to\infty}\frac 1n \sum_{k=0}^{n-1}\mathbb P(A \cap T^{-k}(B))=\mathbb P(A)\mathbb P(B)$. 
I was wondering if I can use this lemma here. It exists some $ B \in \cal F$ such that $P (B) \ne Q (B)$. And I considered $A$ to be T-invariant, but still I can not lead this in the right direction..
Some help is highly appreciated!","['probability-theory', 'ergodic-theory', 'measure-theory']"
2562153,Evaluate $\int_0^\infty \left(\frac{x}{\sinh x}\right)^3dx$,"I need to evaluate $$\int_0^\infty \left(\frac{x}{\sinh x}\right)^3dx$$ I know that I need to use the residue theorem to solve it, but I don't understand how to choose contour properly. Thank you for any help!","['complex-analysis', 'improper-integrals', 'integration']"
2562196,Entire function doesn't cut real axis.,"Let be $ f : \mathbb{C} \rightarrow \mathbb{C} $ a entire function. If it verifies that $ f(\mathbb{C}) \cap \mathbb{R} = \emptyset $ then we cand deduce that $ f $ is constant* (see below to proof), but my question is, the same statement is true if $ f( \mathbb{C} ) \cap [0, \infty) = \emptyset $? And generally, if $ f(\mathbb{C}) \cap [a,b] = \emptyset $ then $ f $ must be constant? I have test some entire functions for the case $ [0, \infty) $ like $ \sin(z) $ and $ \cos(z) $ but I haven't found a conterexpample. I haven't found any similar way to proced like in the case $ f(\mathbb{C}) \cap \mathbb{R} $. *Proof: From $ f( \mathbb{C}) \cap \mathbb{R} = \emptyset $ we deduce that $ \Im(f(z)) > 0 \ \forall z \in \mathbb{C} \ $ or $ \ \Im(f(z)) < 0 \ \forall z \in \mathbb{C} $, because $ f $ is continuous and then $ f( \mathbb{C} ) $ must be a connected subset of $ \mathbb{C} $. Now we consider the compositions $ e^{if} = e^{-v + iu} $ and $ e^{-if} = e^{v - iu} $ where $ f = u + iv $. This functions must be also entire, and we have
$$
| e^{if} |=
|e^{-v + iu}| =
e^{-v}
\ \ \mbox{ and } \ \
| e^{-if} |=
|e^{v - iu}| =
e^{v}
$$
So, if $ v(z) = \Im(f(z)) > 0 \ \forall z \in \mathbb{C} $, the first equality gives that $ |e^{if(z)}| \leq 1 $. In the same way, if $ v(z) = \Im(f(z)) < 0 $, the second equality gives that $ |e^{-if(z)}| \leq 1 $. As $ e^{if} $ and $ e^{-if} $ are entire bounded functions, they must be constant. So we deduce $ f $ is a constant function.","['complex-analysis', 'entire-functions']"
2562201,Find group with distinct Sylow $p$-subgroups that share a normalizer,"Here a question I thought of, but can't find an answer to Find two distinct Sylow $p$-subgroups (of a given $p$) $H_1$ and $H_2$ of $G$ such that $N_G(H_1) = N_G(H_2)$. I don't know if it's actually possible, so I should qualify the question with If no such pair exists, show why. Well, the easiest case would be if $H_1$ and $H_2$ were normal, however this would imply that $n_p = 1$. Hence, we'd only have one Sylow $p$-subgroup. My intuition says that such a pair does exist, however. Of course, it's merely intuition...","['abstract-algebra', 'group-theory', 'sylow-theory']"
2562226,ODE: complex constants in the solution (basic understanding),"The solution to oscillatory equations of motion can be solved using complex number terms, so it would look something like: $y(t)=c_1e^{iat}+c_2e^{-iat} \tag{1}$ which is then rearranged applying Euler's identity: $y(t)=(c_1+c_2)\cos(at)+i(c_1-c_2)\sin(at) \tag{2}$ where next, you can get rid of the complex part by redefining: $c_2'=i(c_1-c_2) \tag{3}$ I've done this many times now, but I find the last step is somewhat strange. I know that the integration constants are supposed to be arbitrary constants, and I know that you can solve these ODE's without even using complex numbers. But doesn't equation (3) assume, that the newly defined $c_2'\in \mathbb{C}$ ?","['ordinary-differential-equations', 'complex-numbers']"
2562233,"Does there exist a continuous surjection from $\Bbb R^3-S^2$ to $\Bbb R^2-\{(0,0)\}$?","Prove or disprove : There exists a continuous surjection from $\mathbb{R}^3- S^2$ to $\mathbb{R}^2-\{(0,0)\}$ (here $S^2\subset
\mathbb{R}^3$ denotes the unit sphere defined by the equation
  $x^2+y^2+z^2=1$),. This question had appeared in TIFR GS-2018 exam for PhD admissions. How should I think about such a map?","['continuity', 'contest-math', 'general-topology', 'proof-writing']"
2562253,Relation between function and Laplacian in Riemannain manifold,"Let $f$ and $k$ be two real valued function on the Riemannian manifold $(M,g)$ such that for each $p\in M$, 
$$k(p)\geq \frac{\partial f}{\partial x_i}|_p.$$ Then wthat is the relation between Laplacian $\Delta f$ and $k$? I have tried as follows Since $grad(f)=g^{ij}\frac{\partial f}{\partial x_j}\partial _i$, hence $grad(f)|p\leq k(p)g^{ij}\partial _i|p$. Then putting the value of $grad(f)$ in Laplacian we get $$\Delta(f)(p)=g_p(\nabla_j k(p)g^{ij}\partial _i,\partial_j).$$ After that I can not go further. Please anyone help me. Thank you","['riemannian-geometry', 'differential-geometry', 'analysis']"
2562261,Prove that $f$ is constant if $f(x)=f(x^2-x+1)$,"Let $f:[0,1] \to \mathbb{R}$ be a function which is continuous at $x_0=1$ and which satisfies$$f(x)=f(x^2-x+1), \: \forall \: x\in [0,1]$$
  Prove that $f$ is constant. My idea is to get as much as possible from the initial equation, eventually getting a chain like $f(x)=...=f(\text{something})$, that $\text{something}$ getting to $1$ eventually, independently of $x$. This way we could apply the continuity at $1$, thus proving the claim. With these in mind, I made the substitution $x \to 1-x$ and got $$f(1-x)=f(x^2-x+1)=f(x), \: \forall \: x \in [0,1]$$ which means that it's enough to prove that $f$ is constant on $[0,\frac{1}{2}]$ and also gives $$f(x)=f(1-x)=f(x^2-x+1)=f(x-x^2), \: \forall \: x \in [0,1]$$
From here, everything eventually came back to one of those $4$ terms above and I got stuck...","['continuity', 'real-analysis', 'calculus', 'functional-equations']"
2562283,Evaluating $\sum_{k=0}^\infty \left(\frac{1}{5k+1} - \frac{1}{5k+2} - \frac{1}{5k+3} + \frac{1}{5k+4} \right)$,"I saw this problem somewhere recently and I was having some difficulty getting started on it. The problem is twofold. The first is to evaluate: $$\sum_{k=0}^\infty \left(\frac{1}{5k+1} - \frac{1}{5k+2} - \frac{1}{5k+3} + \frac{1}{5k+4} \right)$$ and once this is done, to explain what this has to do with the construction of a pentagon (maybe some other polygon?) using a compass and straight edge. In terms of evaluating the series, I tried writing each $n$ as $m \cdot 2^k$ and evaluating the summation there since $2^k$ will alternate between + and - mod 5. However, this leads to a divergent series and I think this is not a valid thing to do since the original series is not absolutely convergent so we can't rearrange terms like that.","['real-analysis', 'geometric-construction', 'sequences-and-series']"
2562290,The parabola $x^2=12y$ rolls without slipping around the parabola $x^2=-12y$,The parabola $x^2=12y$ rolls without slipping around the parabola $x^2=-12y$ then find the locus of focus of rolling parabola and also find the locus of vertex of rolling parabola,"['conic-sections', 'geometry']"
2562354,"What is $\lim\limits_{k\to\infty}\frac{a_{k+1}}{a_{k}}$, where $a_k$ is the $k$th ""generalized"" fibonacci number?","The following sequence is given: \begin{align*}
a_1,a_2,..., a_n=1\\
a_{m}=\sum_{k=1}^{n}a_{m-k},m>n
\end{align*} What is $\lim\limits_{k\to\infty}\frac{a_{k+1}}{a_{k}}$ ? Or how fast is the value of this expression growing with respect to $n$ ? E.g. for $n=2$ it is $\frac{1+\sqrt{5}}{2}$ , but is there a more general expression for any $n$ ? Thank you","['fibonacci-numbers', 'sequences-and-series', 'limits']"
2562408,Proving the equality of two outer measures in a special case,"I would like some help with this question from Bartle's ""The Elements of Integration and Lebesgue Measure"": (Here $\mu^{\star}(A) = \text{inf} \{ \sum\limits_{j=1}^{\infty} \mu(E_i): E_i \in \Omega, A \subseteq \bigcup\limits_{j=1}^{\infty} E_i\}$.) 9.N Let $X$ be a set, $\Omega$ an algebra of subsets of $X$, and $\mu$ a measure on $\Omega$. If $B$ is an arbitrary subset of $X$, let $\mu'(B)$ be defined to be
  $$\mu'(B) = \text{inf} \{\mu(B): B \subseteq A \in \Omega \}$$ 
  Show that $\mu'(E) = \mu(E)$ for all $E$ in $\Omega$ and that $\mu^{\star}(B) \leq \mu'(B)$. Moreover, $\mu^{\star} = \mu'$ in case $X$ is the countable union of sets with finite $\mu$-measure. Is $\mu'$ countably additive in the sense of 9.5(e)? I don't know how to prove the equality mentioned in the ""Moreover (...)"" part. I keep thinking of this ""counter-example"", and I don't know what is wrong with it: $X = \mathbb{R}$ and $\mu$ is the usual length function, and $B = \bigcup\limits_{n=1}^\infty (n, n+\frac{1}{2^{n}}]$, and then $\mu^{\star}(B) = 1$ but every finite union of intervals that contains $B$ would have to have some interval of the form $(a,\infty)$, in which case $\mu'(B) = \infty$. I've searched the internet but couldn't find anything related. I'd appreciate any help.","['lebesgue-measure', 'measure-theory']"
2562413,Quick doubt on an application of the chain rule,"In Perloff's Microeconomics With Calculus 3rd edition, on page 63, one proceeds to the differentiation of the following equation with respect to $\tau$:
$$D(p(\tau))=S(p(\tau)-\tau)$$
And the result is: $$\frac{\text{d}D}{\text{d}p}\frac{\text{dp}}{\text{d}\tau}=\frac{\text{d}S}{\text{d}p}\frac{\text{d}(p(\tau)-\tau)}{\text{d}\tau}=\frac{\text{d}S}{\text{d}p}(\frac{\text{d}p}{\text{d}\tau}-1)$$
My doubt is: why is the third member of the equation equal to the one in the middle? I really can't see how to go from one to another. Besides, according to the chain rule, shouldn't the derivative of $S(p(\tau)-\tau)$ with respect to $\tau$ be $\frac{\text{d}S}{\text{d}(p(\tau)-\tau)}\frac{\text{d}(p(\tau)-\tau)}{\text{d}\tau}$? Any help will be much appreciated. Thanks very much in advance.","['derivatives', 'implicit-differentiation', 'calculus']"
