question_id,title,body,tags
3253630,"Every finite group is finitely presented, but how to do this effectively?","Aluffi II.8.3 suggests proving that every finite group can be finitely presented. Clearly, we could just present a group via its whole underlying set as the set over which we construct the free group, and $\{ g_i g_j = g_k | \forall g_i, g_j \in G \}$ as the relations, so the proof is easy. But the question I have is slightly different: is it possible to do this more effectively (with less relations listed explicitly) for an arbitrary group? For instance, $S_3$ is represented as $(\{ x, y \} \mid x^2, y^3, xyxy)$ earlier in the book, which lists far less relations than the whole multiplication table for $S_3$ .","['combinatorial-group-theory', 'group-theory']"
3253665,Polynomials with $f(\sin x) = f(\cos x)$,"Find all polynomials in $f \in \mathbb{R}[x]$ such that $f(\sin x) = f(\cos x)$ for all $x\in \mathbb{R}$ . The best idea I tried was comparing coefficients of $f(t)$ and $f(\sqrt{1-t^2})$ but it's still quite messy. Update: Finding all $f$ with $f(t^2) = f(1-t^2)$ would be enough, by Sufficient and essential condition for polynomials $P$ and $Q$ to satisfy $P(\sin x)= Q(\cos x)$","['algebra-precalculus', 'polynomials']"
3253687,Is $\frac{\mathrm d}{\mathrm dx}$ an operation?,"What exactly is an operation? I understand that multiplication and addition are operations, but what about the derivative ( $\frac{\mathrm d}{\mathrm dx}$ ). Can an operation be a relation of expressions, or just of numbers?",['abstract-algebra']
3253709,Find $ \int_{0}^{\infty} e^{ix} \sin(x) \frac{e^{-3x}}{x} dx$,"The second contribution in the Born approximation for the Yukawa potential in scattering theory leads to the following integral (for some given ratio of parameters): \begin{align}
\int_{0}^{\infty} e^{ix} \sin(x) \frac{e^{-3x}}{x} dx
\end{align} The solution is said to be (wolframalpha) $\tan^{-1}(\frac{3}{10} + \frac{i}{10})$ . How is this derived? Is there a way to evaluate the numerical value of the integral (e.g. via the residue theorem?) Derivation of the integral: Starting point was an integral equation for the wave function of the scattering problem described by the Schroedinger equation: \begin{align}
\phi_{\vec{k}}(\vec{r}) = \frac{1}{(2\pi)^{\frac{3}{2}}} e^{i \vec{k} \cdot \vec{r}} - \frac{m}{2\pi \hbar^2} \int^{}_{} d^3 r' \frac{e^{ik|\vec{r} -\vec{r}'|}}{|\vec{r} - \vec{r}'|} V(\vec{r}')
     \phi_{\vec{k}}(\vec{r}')
\end{align} Simply inserting plane waves in the RHS leads to what is called the Born approximation: \begin{align}
\phi_{\vec{k}}(\vec{r}) = \frac{1}{(2\pi)^{\frac{3}{2}}} e^{i \vec{k} \cdot \vec{r}} - \frac{m}{2\pi \hbar^2} \int^{}_{} d^3 r' \frac{e^{ik|\vec{r} -\vec{r}'|}}{|\vec{r} - \vec{r}'|} V(\vec{r}')
      \bigg(\frac{1}{(2\pi)^{\frac{3}{2}}}e^{i \vec{k} \vec{r}'} \bigg)
\end{align} In class, we derived the following expression for the scattering amplitude, and furthermore used the Born approximation to show that it is the fourier transformed of the potential. \begin{align}
  f_{\vec{k}} (\theta, \phi) = - \frac{\sqrt{2\pi}m}{ \hbar^2} \int^{}_{} d^3 r' e^{-i \vec{k}'(k,
    \theta, \phi) \vec{r}'} V(\vec{r}') \phi_{\vec{k}}(\vec{r}') \approx -\frac{m}{2\pi \hbar^2} 
    \int^{}_{} d^3 r' e^{+i(\vec{k} - \vec{k}'(k,\theta, \phi)) \vec{r}'} V(\vec{r}')
\end{align} In the lecture notes a formula is given to evaluate when the Born approximation is good. It starts from the above formula, assumes a symmetric potential with respect to rotation, goes over to spherical coordinates and most importantly assumes $\vec{r} =0$ for a potential centered at 0. The last assumption is justified as the influence of the potential should be the highest at this choice.
This leads to the criterium \begin{align}
\frac{2m}{\hbar^2 k} \bigg|\int^{\infty}_{0} dr' e^{ikr'} V(r') \sin(kr')\bigg| \ll 1
\end{align} The Yukawa potential reads $V(r) = A \frac{e^{-\lambda r}}{r}$ . The task was to numerically (I am just curious for an analytical perspective) evaluate for which $A$ the Born approximation is good with $\frac{k}{\lambda} = 3$ . The substitution $x = kr'$ leads to my initial question.","['integration', 'complex-analysis', 'mathematical-physics', 'physics']"
3253774,I want to know what was the motivation/intuition behind weierstrass function?,I know that it came as an example of a function that is continuous everywhere but differentiable nowhere.But how did the idea of such an unusual construction came?,"['continuity', 'derivatives', 'intuition', 'real-analysis']"
3253793,Conditional expectation of Brownian motion's first hitting time,"Let $T_x$ be the first hitting time of $x$ . Let $B_t$ be a Brownian motion started at $x\in [0,R]$ . Show that $$E[T_R \mid T_R < T_0]=\frac{R^2-x^2}{3}.$$ By using the fact that $B_t^2 - t$ is a martingale and stopping time theorem, $E(T_R) = R^2-x^2$ but I am not sure how to find $E[T_R \mid T_R < T_0]$ . Thanks and appreciate a hint.","['conditional-expectation', 'stochastic-processes', 'stopping-times', 'brownian-motion', 'probability-theory']"
3253903,Derivative of log of multivariate Normal respect to Matrix?,I am wondering how to calculate the gradient of a multivariate Normal respect to L where $\Sigma=LL^{T}$ . I know what would be the derivative respect to $\Sigma$ and I can use chain rule to get the derivative respect to L but since $\Sigma$ is a matrix and L is matrix then derivative of a matrix respect to matrix is 4D tensor. Therefore I am wondering can anyone help to find the derivative of log|L| $-(x-z)L^{-1}L^{-T}(x-z)^{T}$ respect to L. The first term involving the determinant is a standard calculation but I am stuck  in the second term.,"['normal-distribution', 'matrices', 'calculus', 'vector-analysis', 'derivatives']"
3254006,Evaluate $\lim_{n\to \infty}n\int_2^e{(\ln x)^n}dx$,$$\lim_{n\to \infty}n\int_2^e{(\ln x)^n}dx$$ Any idea on how to approach this problem with elementary methods? The answer should be $e$ . I proved with the mean value theorem for definite integrals that $$\lim_{n\to \infty}\int_2^e{(\ln x)^n}dx=0$$ And I tried $\ln x=t$ but to no use.,"['limits', 'calculus', 'limits-without-lhopital']"
3254038,Maximise the Product,"I have an array consisting of positive and negative integers .
For the array i have to maximize the  quantity $$\left| a_{i}-a_{j} \right| \left|i-j \right|$$ where $a_{i}$ is the $i_{th}  $ element in the array . The indexing of array is done starting with $ 1$ . What kind of approach should be applied to solve such problems .?","['abstract-algebra', 'discrete-mathematics', 'real-analysis']"
3254041,Two powerful alternating sums $\sum_{n=1}^\infty\frac{(-1)^nH_nH_n^{(2)}}{n^2}$ and $\sum_{n=1}^\infty\frac{(-1)^nH_n^3}{n^2}$,"where $H_n$ is the harmonic number and can be defined as: $H_n=1+\frac12+\frac13+...+\frac1n$ $H_n^{(2)}=1+\frac1{2^2}+\frac1{3^2}+...+\frac1{n^2}$ these two sums are already solved by Cornel using summation manipulation and can be also found in his newly released book "" (almost) impossible integrals, sums and series "". I was able to evaluate them using integration and some harmonic identities. \begin{align}
\sum_{n=1}^\infty\frac{(-1)^nH_nH_n^{(2)}}{n^2}&=4\operatorname{Li}_5\left(\frac12\right)+4\ln2\operatorname{Li}_4\left(\frac12\right)-\frac23\ln^32\zeta(2)+\frac74\ln^22\zeta(3)\\&\quad-\frac{15}{16}\zeta(2)\zeta(3)-\frac{23}8\zeta(5)+\frac2{15}\ln^52
\end{align} \begin{align}
\sum_{n=1}^\infty\frac{(-1)^nH_n^3}{n^2}&=-6\operatorname{Li}_5\left(\frac12\right)-6\ln2\operatorname{Li}_4\left(\frac12\right)+\ln^32\zeta(2)-\frac{21}{8}\ln^22\zeta(3)\\&\quad+\frac{27}{16}\zeta(2)\zeta(3)+\frac94\zeta(5)-\frac15\ln^52
\end{align} The point of posting these two sums is to use them as a reference in our solutions if needed.","['integration', 'real-analysis', 'harmonic-numbers', 'polylogarithm', 'sequences-and-series']"
3254063,Why is row $n = 2^x$ in Pascal's triangle have all even numbers except the $1$'s?,"In row $n = 2^x$ , $x$ being a positive integer, in the Pascal's triangle, all entries except the two $1$ 's in extreme left and right are even. I tried to prove but I couldn't. Here is my try:- Every entry is of the form $\frac{(2^x)!}{(k!)([2^x]-k)!}$ I counted the no.of 2's in the prime factorisation of $(2^x)!$ in the following way:- No.of multiples of $2 = \frac{2^x}2 = 2^{x-1}$ No.of multiples of $4 = \frac{2^x}{2^2}= 2^{x-2}$ Similarily upto no.of multiples of $2^x = 1$ . So total no.of 2's in prime factorisation is $$
2^{x-1} + 2^{x-2} + \cdots + 2 + 1 = 2^x-1
$$ But I cannot prove that the no.of 2's in the denominator of each entry will be less than $2^{x-1}$ . Can I get some hints/help? Thank you.",['combinatorics']
3254083,Matrix derivative of structured matrix (with constraint),"Let $$c (A,B) := \log | ABA' + I - \mbox{diag}(ABA')|$$ where matrix $A$ is not necessarily square, matrix $B$ is symmetric, and $I$ is the identity matrix. How to obtain the derivatives $\frac{dc}{dA}$ and $\frac{dc}{dB}$ ?","['matrix-calculus', 'determinant', 'derivatives']"
3254097,Alternative proofs Matrix Determinant Lemma,"Well as many of you know wiki has a beautiful proof for the Matrix Determinant Lemma Wiki's Proof But: How the hell is one supposed to get there on his own? There is no way that when a professor would ask you to proof the lemma in your let's say 4th semester, you will come up with the idea for that proof. So my question is: Are there alternative methods to show the Lemma which are more intuitiv or let's say realistic to come up with?","['determinant', 'matrices', 'matrix-calculus', 'linear-algebra', 'numerical-methods']"
3254157,Vector Khintchine Inequality,"Suppose that $X_1,\ldots,X_n$ are fixed vectors in $\mathbb{R}^{d}$ and $\epsilon_1,\ldots,\epsilon_n$ are Rademacher random variables.  Is it the case that there are constants $A_p,B_p$ so that $$
A_{p}\sqrt{\sum_{i=1}^{n}||X_{i}||_r^{2}}\le \left(\mathbb{E}||\sum_{i=1}^{N}\epsilon_{i}X_{i}||_r^p\right)^{1/p}\le B_{p}\sqrt{\sum_{i=1}^{n}||X_{i}||_r^{2}}
$$ I want a version of the Khintchine inequality that works for $\mathbb{R}^{d}$ equipped with the $r$ norm instead of $\mathbb{C}$ with $|\cdot|$ .  If $r$ has to be $2$ , that's fine.","['probability-theory', 'probability']"
3254262,Intersection of two curves only in two points.,"Is it always true that for any given curve and for any two points on that given curve (no matter how close these points are), it is possible to construct some curve that intersect that given curve only at those two points (with the below constrictions)  ? Constrictions: 1- The other curve ( the constructed curve ) should not be a straight line in a neighborhood of the two points . 2- The two curves should be continuous in a neighborhood of the two points. 3- The two curves should be differentiable in a neighborhood of the two points. As an example take the parabola $ y =  x^2 $ and for a given $ε>0$ , let ( $x$ , $x^2$ ) and ( $x+ε$ , $(x+ε)^2$ ) be two points on the parabola $ y =  x^2 $ . My question is : is it possible to find a curve that passes through only those two points for any given $ε>0$ ? And how to construct such curve ? If this is always possible please provide an explanation. 
And if not (please provide a counter example) how about removing constraint 3 dose that make it possible ? Edit: If the question is too broad, then It would be helpful to provide a specific example for the case of a parabola.","['curves', 'algebraic-geometry', 'differential-geometry', 'real-analysis']"
3254265,Geodesics of Helicoid,"I'm working on the geodesics of a helicoid $S$ parametrised by $X(u,v) = \left( u \cos(v) , u \sin(v) , v \right)$ , with $\alpha(t) = \left( u(t) , v(t) \right) : I \subset \mathbb{R} \to S$ a unit speed curve on $S$ , i.e. parametrised by arc length. Thus far I have \begin{align}
X_u &= \frac{\mathrm{d}X(u,v)}{\mathrm{d}u} = \left( \cos(v) , \sin(v) , 0 \right) \\
X_v &= \frac{\mathrm{d}X(u,v)}{\mathrm{d}v} = \left( -u\sin(v) , u\cos(v) , 1 \right)
\end{align} Giving the coefficients of the first fundamental form $E = X_u \cdot X_u = 1$ , $F = X_u \cdot X_v = 0$ , and $G = X_v \cdot X_v = u^2 +1$ , such that \begin{align}
\mathrm{d}s^2 &= E \mathrm{d}u^2 + 2F \mathrm{d}u \mathrm{d}v + G \mathrm{d}v^2 \\
&= \mathrm{d}u^2 + \left(u^2 +1 \right)\mathrm{d}v^2 .
\end{align} Here, as $\alpha$ has unit speed, I have reasoned that $\mathrm{d}s^2/\mathrm{d}t^2 = 1$ implying that $1 = \left( u'(t) \right)^2 + \left( u^2+1 \right) \left( v'(t) \right)^2$ ; is this correct reasoning? By computing the derivatives $E_u = E_v = F_u = F_v = G_v = 0$ and $G_u = 2u$ , we can compute the Christoffel symbols \begin{align}
\Gamma_{11}^1 = \Gamma_{11}^2 = \Gamma_{12}^1 = \Gamma_{22}^2 = 0; \\
\Gamma_{12}^2 = \frac{u}{u^2+1}; \qquad \Gamma_{22}^1 = -u.
\end{align} It is given that $\alpha$ is a geodesic on $S$ , which is equivalent to the satisfaction of the following system: \begin{align}
u'' + \Gamma_{11}^1 \left( u'(t) \right)^2 + 2 \Gamma_{12}^1 u'(t) v'(t) + \Gamma_{22}^1 \left( v'(t) \right)^2 &= 0 \\
v'' + \Gamma_{11}^2 \left( u'(t) \right)^2 + 2 \Gamma_{12}^2 u'(t) v'(t) + \Gamma_{22}^2 \left( v'(t) \right)^2 &= 0 \\
\implies u'' - u \left( v'(t) \right)^2 &= 0 \\
v'' + 2 \frac{u}{u^2+1} u'(t) v'(t) &= 0 
\end{align} The last equation yields by integration $v' = \Theta/ \left( u^2 +1 \right)$ , where $\Theta$ is an integration constant. If $\Theta = 0$ then $v'\equiv 0$ and subsequently $v = $ constant, i.e. it is a necessary condition that $u' \ne 0$ for $v = $ constant and $u = u(s)$ to be a geodesic. Is this correct? Furthermore, if $\Theta =1$ then $v' = 1/\left(u^2 +1 \right)$ , such that \begin{align}
\mathrm{d}v^2 \left( u^2 +1 \right)^2 &= \mathrm{d}s^2 \\
&= \mathrm{d}u^2 + \left( u^2 + 1 \right) \mathrm{d}v^2 \\
\implies \mathrm{d}v^2 \left( u^4 + u^2 \right) &= \mathrm{d}u^2 \\
\implies \mathrm{d}v &= \frac{\mathrm{d}u}{u \sqrt{u^2 +1 }} \\
\implies v(s) &= \text{constant} \pm \int \; \frac{\mathrm{d}u}{u \sqrt{u^2 +1 }} \\
&= \text{constant} \pm \ln\left| \csc(s) + \cot(s) \right|
\end{align} The above equation is the geodesic for $\Theta = 1$ , in terms of $u$ or explicitly in terms of arc length $s$ ; is this correct? I am feeling like a noob with geodesics so any and all help is appreciated. Also, if you would like to extend to explain something that you find interesting about this then I would really like to hear from you - the more interested I am the easier it is to learn!","['geodesic', 'differential-geometry']"
3254269,Tricky surface integral of vector field,"The following problem comes from a vector calculus exam. Let $$ S = \left\{ (x,y,z) \in \mathbb{R}: z = e^{1 - (x^2 + y^2)^2}, z > 1 \right\} $$ be an embedded surface with the orientation corresponding to the positive $\bf{OZ}$ direction, and let $$\mathbf F:\mathbb{R}^3\to \mathbb{R}^3; (x,y,z)\mapsto (x e^{y^2}, 2ye^{x^2}, 5-3z) $$ be a vector field. Calculate $\bf F$ 's flux through the surface $S$ , $$\iint_S \langle \mathbf{F}\cdot d\mathbf{S}\rangle$$ I am yet to find an effective way to solve it. So far, I have encountered  solutions in terms of the likes of error functions or $$\int e^{x^2}dx$$ which is far from what one would expect at that level. Most of our attempts have been by using cylindrical coordinates and both Stokes's and Gauss's divergence theorems, but these awkward terms keep coming back. For those who might have a go at it, let me give you the vector $n$ normal to the surface $$n= (-r^4 \cos\theta e^{1-r^4}, r^4\sin \theta e^{1-r^4}, r)$$ with the surface's cylindrical coordinates $(x,y,z) = (r\cos\theta, r\sin\theta, e^{1-r^4})$ . Source Here is the original question in Spanish.","['integration', 'vector-fields', 'surface-integrals', 'multivariable-calculus', 'vector-analysis']"
3254277,Intuitive reason on how predictable processes are defined,"In discrete-time, we say that a process X defined in $\left(\Omega, \mathscr{F}, \lbrace\mathscr{F}_n\rbrace, \mathbb{P}\right)$ given by X $ = \lbrace X_n, n \in \mathbb{N}\rbrace$ is predictable if $ \forall n \in \mathbb{N}, X_n$ is $\mathscr{F}_{n-1}$ -measurable. An intuitive meaning of this is that, one can predict the value of $X$ at time $n$ despite only having the information at time $n-1$ . However, as defined by Revuz and Yor, for continuous time, a process $X$ is predictable if the map $\left(\omega, t\right) \to X_t(\omega)$ is measurable with respect to the $\sigma$ -field generated by the space of adapted processes which are left continuous on $\left(0,\infty\right)$ . Can someone enlighten me on the similarity of the two definitions? And how would the ""predictability"" of $X$ be intuitive from the definition in continuous time (similar to the intuitive meaning in discrete-time)?","['stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3254301,Mobius transformations from intersection of circles to two straight lines,"My textbook is pretty useless on Mobius transformations, and I just wanted to check this reasoning was correct! I want to find a Mobius mapping from the region $$\{z:|z-1|\lt\sqrt{2}, |z+1|\lt \sqrt{2}\}$$ to the region $$\{z:\frac{3\pi}{4}\lt argz \lt \frac{5\pi}{4}\}$$ I know that the two circles in the first region intersect at $i$ and $-i$ so I consider a Mobius transformation $z \mapsto \frac{z+i}{z-i}$ which takes $-i$ to $0$ and $i$ to $\infty$ . I then tested two points, one on the left circline that bounds the two circles' intersections (namely $1-\sqrt{2}$ ) and one on the right circline that bounds the two circle's intersections (namely $-1+\sqrt{2}$ ). From here I see that $1-\sqrt{2}$ goes to $-\frac{\sqrt{2}}{2}-\frac{\sqrt{2}}{2}i$ ,so onto the half line $y=x$ for $y,x\lt 0$ . And similarly, $-1+\sqrt{2}$ gets mapped to the line $x=-y$ for $x \lt 0$ and $y\gt 0$ . These two boundaries seem to bound precisely the region we want. Thus I think this mapping, $z \mapsto \frac{z+i}{z-i}$ is a Mobius mapping from the first region to the second. Is this correct?","['complex-analysis', 'conformal-geometry', 'mobius-transformation']"
3254331,Prove that $\int_0^\infty\left(\arctan \frac1x\right)^2 \mathrm d x = \pi\ln 2$,"Prove $$\int_0^\infty\left(\arctan \frac1x\right)^2 \mathrm d x = \pi\ln 2$$ Out of boredom, I decided to play with some integrals and Inverse Symbolic Calculator and accidentally found this to my surprise $$\int_0^\infty\Big(\arctan \frac1x\Big)^2 \mathrm d x = \pi\ln 2 \quad (\text{conjectural}) \,\,\, {\tag{1}} $$ Here is Wolfram Alpha computation which shows (1) to be true to 50 digits. Is (1) true and how to prove it? I can calculate $$\int_0^\infty\arctan \frac{1}{x^2}\mathrm d x = \frac{\pi}{\sqrt2}$$ easily by expanding $\arctan$ into Maclaurin series. But how to proceed with $\arctan^2$ ?","['integration', 'conjectures', 'improper-integrals', 'calculus', 'experimental-mathematics']"
3254339,Why does the universal enveloping algebra not have zero-divisors?,"Let $\mathfrak{g}$ be a finite-dimensional Lie algebra, and denote by $U(\mathfrak{g})$ its universal enveloping algebra. It appears to be a consequence of the Poincaré-Birkhoff-Witt Theorem that $U(\mathfrak{g})$ has no zero-divisors. All sources I look at consider this to be either obvious or an easy exercise. But to be honest I'm baffled by this problem. Attempt 1: Take a basis $e_1,\ldots,e_n$ of $\mathfrak{g}$ , so that $U(\mathfrak{g})$ is generated by all terms of the form $e_1^{k_1} \cdots e_n^{k_n}$ . Take two elements $x$ and $y$ in $U(\mathfrak{g})$ , and suppose $x y = 0$ . Our goal is to show that $x$ or $y$ is trivial. Thanks to Poincaré-Birkhoff-Witt, $x$ and $y$ are a finitely sum of the form $$x = \sum_{k_1,\ldots,k_n} a_{k_1\cdots k_n} e_1^{k_1} \cdots e_n^{k_n}$$ and $$y = \sum_{k_1,\ldots,k_n} b_{k_1 \cdots k_n} e_1^{k_1} \cdots e_n^{k_n}$$ We can then expand the product $xy$ , and for each product of the form $$e_1^{k_1} \cdots e_n^{k_n} e_1^{k'_1} \cdots e_n^{k'_n}$$ we can use the rule $e_i e_j + e_j e_i = [e_i,e_j]$ finitely many times to find an expression of it with respect to the basis that PBW gives us. Working all this out, the expression for $xy$ entirely gets out of hand, and it is not at all clear that it won't vanish for non-trivial $x$ and $y$ . Attempt 2: It is often hinted that you should use the associated graded ring of $U(\mathfrak{g})$ in some way. Many times it is stated that, as a consequence of PBW, this graded ring is a polynomial ring, and that therefore there aren't zero divisors. Both logical steps elude me, and I have no idea how to proceed in this direction.","['ring-theory', 'abstract-algebra', 'linear-algebra', 'lie-algebras']"
3254349,"Prove $F(x, y) = (f(x))^{g(y)}$ is integrable over $A = [0, 1] \times [0, 1].$","I'm writing to ask for your help in the last step to finish the following question: Let $f, g: [0, 1] \to \mathbb{R}$ be integrables functions with $f(x) \geq m > 0,$ for all $x \in [0, 1]$ . Prove that $F(x, y) = (f(x))^{g(y)}$ is integrable over $A = [0, 1] \times [0, 1].$ My attempt: First, note that: $F(x, y) = (f(x))^{g(y)} = \exp(g(y)\cdot \ln(f(x)))$ . Then since $f([0, 1]) \subset [m, +\infty)$ and the logarithm is Lipschitz on $[m, +\infty)$ , so $\ln \circ f$ is integrable over $[0, 1]$ . Second, Defining $\phi : [0, 1] \times [0, 1] \to \mathbb{R}$ such that $\phi(x, y) = g(y)\cdot\ln(f(x))$ , it is possible to prove that $\phi$ is integrable due to the fact that $g$ and $\ln \circ f$ are. Finally, since $F = \exp \circ \phi,$ what is needed to finish the proof is to be show that $\exp \circ \phi$ is also integrable. But here is where I met my Waterloo. Any kind of help would be really appreciated. Thanks in advance.","['multivariable-calculus', 'real-analysis']"
3254382,Solve Riddle With Algebra,"There is a riddle and I believe it can be solved by algebra - please assist A boy has as many sisters as brothers, but each sister has only half as many sisters as brothers. How many brothers and sisters are there in the family Here is algebra, but I am stuck $b=brother$ $s=sister$ $t=total$ boy has as many brothers as sisters $b + b + s = t$ each sister has only half as many sisters as brothers $s + s + b = t$ $s + \frac{1}{b} + b = t$ Hence $b + b + s = s + \frac{1}{b} + b$ $2b + s = s + \frac{3b}{2}$ $2b = \frac{3b}{2}$ $4b = 3b$ Please assist.","['word-problem', 'algebra-precalculus', 'puzzle']"
3254388,Uniqueness of Rank of Free Group via Abstract Nonsense,"It is a well known result that given two isomorphic free groups, their freely generating sets have the same cardinality, which is then called the rank of a free group. I am well aware of the usual proof that the rank of a free group is well defined, by abelianization and (if this is not reduced far enough for you) tensoring with $\mathbb{Q}$ to obtain a vector space. However I was wondering, whether there is a more abstract way to prove this result relying solely on the free functor satisfying some categorical properties. Taking the perspective of category theory one might be tempted to rephrase this fact as follows: The free functor $F: \underline{Set} \rightarrow \underline{\smash{Grp}}$ creates isomorphisms, in the sense that given an isomorphism $\phi: F(G) \rightarrow F(H)$ there is a morphism $f:G \rightarrow H$ with $F(f) = \phi$ and $f$ is an isomorphism. EDIT : I was rightfully corrected that it is wrong that any isomorphism between free groups is in the range of the free functor. Nevertheless my question about reflecting the property of being isomorphic is still open. I think I managed to show that the free functor reflects isomorphisms , ie. if $F(f)$ is an isomorphism, so is $f$ . I showed that the free functor is faithful and thus reflects monos and epis. But as monos and epis in $\underline{Set}$ and $\underline{\smash{Grp}}$ split, it also reflects isos. Now the problem is just, whether each isomorphism between free groups is in the range of the free functor. Clearly the free functor is not full (take $\mathbb{Z} \rightarrow F_2, 1 \mapsto ab$ ). However I could not think of a similiar counterexample which also is an isomorphism. So my question is: Is my reformulation correct and if so, is there a categorical proof, ie. does the free functor satisfy some categorical criterion which makes it create isomorphisms? Thank you all for your time!","['group-theory', 'category-theory']"
3254409,"Prove $\liminf \left(\frac{n!}{(n-k)! n^k}\right) = 1,\ k =$ constant.",I had this as an assumption in my textbook (in the section Poisson approximation to Binomial distribution ) but couldn't prove it.,"['permutations', 'poisson-distribution', 'binomial-distribution', 'limits', 'probability-theory']"
3254421,Multipliers and corners of $C^*$-algebras,"Let $A$ and $B$ be $C^*$ -algebras. Suppose that there exists a projection $p$ in $\mathcal{M}(B)$ , the multiplier algebra of $B$ , such that $A=pBp$ . That is, $A$ is a corner of $B$ . Question: Is it true that the corner $p(\mathcal{M}(B))p$ contains the multiplier algebra of $A$ (which we view as a subalgebra of $B$ )? In other words, does every multiplier of the corner come from the corner of the multiplier algebra?","['c-star-algebras', 'operator-theory', 'functional-analysis', 'operator-algebras']"
3254430,How to shrink a circle to a point that is not its center,"Let's say we have a circle $C$ with a fixed radius $R$ on $\mathbb{R}^2$ . An obvious parametrization to the circle would be: $$C(t)=(R\cos(t),R\sin(t)) \\ t\in[0,2\pi]$$ I'm interested in shrinking the circle to a point. If we look at the limit where $R\to0$ , it would be easy to see that the circle would shrink to the point $(0,0)$ . However, I'm trying to shrink the circle to another point. Let's say, for example, that $R=2$ , and I want the circle to shrink to the point $P=(1,1)$ . In order to do that, I have to make sure that through the process, the point $P$ would always be inside the area; For that reason, I must have another parametrization of the circle (one that would also help me to take a proper limit). Problem is I have no idea how to do that. I tried to draw a segment from the point $P$ to some generic point on the circle (and named it $r$ ), and then tried to parametrize the circle using $r$ , but it was an algebraic challenge. So I'd be very glad if you could help me with that. Also, if you thought of an easier solution - I would be glad to hear it too! Thanks! In short : Given the point $(x_0,y_0)$ , find a parametrization $C(R,r,t)$ of a circle centered at $(0,0)$ with radius $R\geq\sqrt{x_0^2+y_0^2}$ , such that $t\in[a,b]$ for some $a,b\in\mathbb{R}$ , $r$ is fixed and is dependent on $R$ (which is constant), and: $$\lim_{r\to0} C(R,r,t)=(x_0,y_0)$$ When $(x_0,y_0)$ is a point inside the circle, throughout the shrinking process.","['curves', 'differential-geometry']"
3254431,pi approximation with Newton's method to an arbitrary rate of convergence,"If $a_1$ to $a_3$ is the solution of this linear system of equations $$\left(\begin{array}{rrr|r}
-1&2&-3& -1\\
1&-8&27&0 \\
-1 & 32 & -243 & 0
\end{array}\right)$$ then $f_3(x) = a_1\sin(x)+ a_2 \sin(2x) + a_3 \sin(3x)$ defines a function with $f_3(\pi) = 0$ and the convergence rate of Newton's methods should locally be of 6th order since $f_3'(\pi) = -1$ and the 2nd to 6th derivatives vanish at $\pi$ (That's how the system of equations is constructed). As far as I know from my class on numerical methods, this is sufficient for the rate of convergence. Similarly, one can extend the defining system of equations above to construct functions which imply an arbitrary rate of convergence for Newton's method by computing coefficients $a_1$ to $a_k$ with $f_k(\pi) = 0$ , $f_k'(\pi) = -1$ and $f_k^{(i)}(\pi) = 0$ for $2 \leq i \leq 2k$ . The convergence rate of Newton's method is therfore of the order $2k$ . Numerical calculations in Matlab confirm these results. By plotting the functions $f_k$ one can observe that the function seems to converge pointwise to $g(x) = \pi -x $ for $x \in (0, 2\pi)$ . If this is true, how can one prove this? I'm not familiar with functions definied by solutions of linear systems of equations and have never seen something like this before. I tried to use the Taylor expansion of $|f_k(x)| = |\frac{1}{(2k+1)!} \cdot f^{(2k+1)}(\xi)| \gtrapprox a_k\frac{k^{2k+1}}{(2k+1)!} (x-\pi)^{2k+1}$ . But $\frac{k^{2k+1}}{(2k+1)!}$ diverges when $k$ approches $\infty$ , so I either need an estimation of $a_k$ or another approach to show pointwise convergence. Is there any material about functions defined by linear system of equations or closely related topics (preferably undergraduate level)? Did anyone, by chance, have a smiliar idea to this and/or is there any further material available on this topic? Is it connected to the Fourier series? Another question I asked myself when I discovered these functions was if it is connected to the Fourier series of $\pi-x$ (extended periodically beyond $[0, 2\pi]$ ) because it is a linear combination of sine functions with integer factors in the argument. I remember that if there exits a uniformly convergent series of the form $\sum_{k= -\infty}^\infty c_k e^{ikx}$ it must be the Fourier series. We can write $f_k = \sum_{i= 0}^k a_{ki}\sin(ix)$ , so there can't be any coefficients $a_{\infty i}$ such that the sum defined by $f_\infty$ converges uniformly to $\pi-x$ because that would imply the uniform convergence of the Fourier Series of $\pi-x$ , which it does not, if I remember correctly. Can one define something like $a_{\infty i}$ in a reasonable way? And if so, are they the Fourier coefficients?I have no idea how to start here. I have found some results about infinite systems of linear equations but nothing directly applicable to my problem. Thanks in advance for any answers.","['numerical-methods', 'matrix-equations', 'linear-algebra']"
3254492,Can all groups be thought of as the symmetries of a geometrical object?,"It is often said that we can think of groups as the symmetries of some mathematical object. Usual examples involve geometrical objects, for instance we can think of $\mathbb{S}_3$ as the collection of all reflections and rotation symmetries of an equilateral triangle, similarly we can think of $D_8$ as the symmetry group of a square. Cayley's Theorem along with the fact that the symmetry group of a regular $n$ -simplex is isomorphic to $\mathbb{S}_{n+1}$ allows us to think of any finite group as a subset of the symmetry group of some geometrical object. Which brings me to the following questions: Can every finite group be represented as the collection of all symmetries of a geometrical object? That is, are all finite groups isomorphic to some Symmetry group? Can such a result (the representation of groups as distance-preserving transformations of some geometrical object) be extended to infinite groups? If so, how? Thanks in advance (:","['geometry', 'abstract-algebra', 'group-theory', 'symmetry', 'soft-question']"
3254523,Why Q-matrix often set to $C^TC$ in Algebraic Riccati Equations?,I wonder why many books say that the Q-matrix in the Algebraic Riccati Equations: $$A^T X + X A - X B R^{-1} B^T X + Q = 0 $$ or $$X = A^T X A -(A^T X B)(R + B^T X B)^{-1}(B^T X A) + Q$$ Is often set to $Q = C^TC$ when finding the steady state kalman gain matrix $K$ in the kalman filter state update: $$\hat x(k+1) = \hat x(k) + K(y(k) - C\hat x(k))$$ Or finding the optimal control law: $$u = r - Lx(k+1)$$ Why $Q = C^TC$ ? I think that is great that it can be at least one answer for the $Q$ matrix instead of saying that the $Q$ matrix should be greater than $0$ . But what results will I get if I always say that $Q=C^TC$ ?,"['optimal-control', 'control-theory', 'matrices', 'linear-control', 'matrix-equations']"
3254532,Conclude $X^n_t\to X_t$ weakly from knowing that $X^n_0\to X_0$ weakly and convergence of the corresponding generators,"Let $E$ be a locally compact separable metric space $(T(t))_{t\ge0}$ be a strongly continuous contraction semigroup on $C_0(E)$ with generator $(\mathcal D(A),A)$ $(T_n(t))_{t\ge0}$ be a uniformly continuous contraction semigroup on $B(E)$ (bounded Borel measurable functions $E\to\mathbb R$ equipped with the supremum norm) for $n\in\mathbb N$ $(\Omega,\mathcal A,\operatorname P)$ be a probability space $(X_t)_{t\ge0}$ be an $E$ -valued càdlàg process on $(\Omega,\mathcal A,\operatorname P)$ with $$\operatorname E\left[f(X_t)\mid(X_r)_{r\le s}\right]=(T(t-s)f)(X_s)\;\;\;\text{almost surely}\tag1$$ for all $f\in C_0(E)$ and $t\ge s\ge0$ $(X^n_t)_{t\ge0}$ be an $E$ -valued càdlàg process on $(\Omega,\mathcal A,\operatorname P)$ with $$\operatorname E\left[f(X^n_t)\mid(X^n_r)_{r\le s}\right]=(T_n(t-s)f)(X_s)\;\;\;\text{almost surely}\tag2$$ for all $f\in C_b(E)$ and $t\ge s\ge 0$ Assume $$X^n_0\xrightarrow{n\to\infty}X_0\tag3$$ weakly and that for all $f\in\mathcal D(A)$ and $t\ge0$ , there is a $(B_n)_{n\in\mathbb N}\subseteq\mathcal B(E)$ and a $(f_n)_{n\in\mathbb N}\subseteq B(E)$ with $$\operatorname P\left[\forall s\in[0,t]:X^n_s\in B_n\right]\xrightarrow{n\to\infty}1\tag4,$$ $$\sup_{n\in\mathbb N}\left\|f_n\right\|_\infty<\infty\tag5$$ and $$\left\|f_n-f\right\|_{B_n}+\left\|A_nf_n-Af\right\|_{B_n}\xrightarrow{n\to\infty}0\tag6$$ (where $\left\|g\right\|_{B_n}:=\sup_{x\in B_n}|g(x)|$ ). Fix $f\in\mathcal D(A)$ and $t\ge 0$ . Are we able to conclude $\operatorname E\left[f(X^n_t)\right]\xrightarrow{n\to\infty}\operatorname E\left[f(X_t)\right]$ ? My attempt is to write $$\operatorname E\left[f(X^n_t)\right]=\operatorname E\left[(T_n(t)f)(X^n_0)\right]=\operatorname E\left[f(X^n_0)\right]+\operatorname E\left[\int_0^t(A_nf)(X^n_r)\:{\rm d}r\right]\tag7$$ and analogously $$\operatorname E\left[f(X_t)\right]=\operatorname E\left[(T(t)f)(X_0)\right]=\operatorname E\left[f(X_0)\right]+\operatorname E\left[\int_0^t(Af)(X_r)\:{\rm d}r\right]\tag8.$$ With $(7)$ and $(8)$ , we obtain $$\left|\operatorname E\left[f(X^n_t)\right]-\operatorname E\left[f(X_t)\right]\right|\le\left|\operatorname E\left[f(X^n_0)\right]-\operatorname E\left[f(X_0)\right]\right|+\operatorname E\left[\int_0^t\left|(A_nf)(X^n_r)-(Af)(X_r)\right|\:{\rm d}r\right]\tag9,$$ but I'm unable to proceed from here. EDIT : On the other hand, the claim would follow from $$\operatorname E\left[f(X^n_t)-(T(t)f)(X^n_0)\right]\xrightarrow{n\to\infty}0.\tag{10}$$ We know that there are $B_n$ and $f_n$ as above. Let $U^n:=f_n(X^n)$ and $V^n:=(A_nf_n)(X^n)$ . Then we may somehow use that $U^n-\int_0^{\;\cdot\;}V^n_s\:{\rm d}s$ is a martingale. Maybe we need to stop this martingale at $$\tau_n:=\inf\left\{t>0:\left(\int_0^t\left|(A_nf_n)(X^n_s)\right|^2\:{\rm d}s\right)^2>\sqrt t(\left\|Af\right\|_\infty+1)\right\},$$ noting that $\operatorname P\left[\tau_n\le t\right]\xrightarrow{n\to\infty}0$ . The idea is that we may insert this martingale in $(10)$ and somehow show the convergence. Remark : There is a superior result in section 8 of chapter 4 in the book of Ethier and Kurtz, but I would like to find a direct proof in this special situation.","['weak-convergence', 'operator-theory', 'markov-process', 'semigroup-of-operators', 'probability-theory']"
3254535,"Intuition: $]0,\infty[: \{x \mapsto \arctan{(nx)}: n \in \mathbb N\}$","Let $X=]0,\infty[: \{x \mapsto \arctan{(nx)}: n \in \mathbb N \}$ so $f_{n}: ]0,\infty[ \to \mathbb R, x \mapsto \arctan{(nx)}$ for all $n \in \mathbb N$ There is a statement, saying (w.r.t. $d_{\infty}$ ): $1.$ $(f_{n})_{n}$ is equicontinuous $2.$ $(f_{n})_{n}$ is not uniformly equicontinuous $3.$ each function $f_{n}$ is uniformly continuous. The difference between $1.$ and $2.$ is clear but I do not understand why $(f_{n})_{n}$ is equicontinuous because with every increasing $n$ my slope close to $0$ increases, so my chosen $\delta$ will need to get smaller and smaller. And surely if $1.$ and $3.$ are true our sequence $(f_{n})_{n}$ necessarily has to be uniformly equicontinuous. Why is this not the case, any explanations are greatly appreciated.","['continuity', 'convergence-divergence', 'functional-analysis']"
3254540,"Proving $\int_0^{\pi/4}\sin^n(x)\,dx>\frac{1}{2^{n/2}(n+2)}$","I want to prove: $$\int_0^{\pi/4}\sin^n(x)\,dx>\frac{1}{2^{n/2}(n+2)}$$ This came up when I was working on this question that only asked for elementary calculus solution. Some trivial lower bounds such as: $$ \sin(x)\geq\frac{2\sqrt{2}}{\pi}x$$ or even a slightly stronger one: $$\sin(x)\geq \dfrac{3}{\pi}x\cdot 1_{[0,\pi/6]}+\left(\frac{6(\sqrt{2}-1)}{\pi}x+\dfrac{3-2\sqrt{2}}{2}\right)\cdot 1_{[\pi/6, \pi/4]}$$ were not tight enough to prove the assertion. Ideally, one could find the asymptotic expansion of: $$n2^{n/2}\int_0^{\pi/4}\sin^n(x)\,dx$$ which can be seen to be converging to $1.$","['calculus', 'trigonometry', 'real-analysis']"
3254553,Interesting inequality $\frac{x^{m+1}+1}{x^m+1} \ge \sqrt[2m+1]{\frac{1+x^{2m+1}}{2}}$,Prove that $$\frac{x^{m+1}+1}{x^m+1} \ge \sqrt[k]{\frac{1+x^k}{2}}$$ for all real $x \ge 1$ and for all positive integers $m$ and $k \le 2m+1$ . My work. If $k \le 2m+1$ then $$\sqrt[k]{\frac{1+x^k}{2}}\le \sqrt[2m+1]{\frac{1+x^{2m+1}}{2}}.$$ I need prove that for all real $x \ge 1$ and for all positive integers $m$ the inequality $$\frac{x^{m+1}+1}{x^m+1} \ge \sqrt[2m+1]{\frac{1+x^{2m+1}}{2}}$$ holds.,"['inequality', 'real-analysis']"
3254555,"If $K$ is compact, prove that $K$ has a minimum and maximum.","Let $X$ be a nonempty totally ordered set which doesn't have a minimum or maximum and let $T$ be order topology on $X$ . Let $ K \subset X $ be a nonempty subset of $X$ . If $K$ is compact, prove that $K$ has a minimum and maximum. I tried by contradiciton. Suppose that $K$ has no maximum. Then $  <- \infty, k> k \in K$ is an open cover of $K$ which has no finite subcover. So K cannit be compact. Is this correct?",['general-topology']
3254580,Solving a Non linear ODE,"Can the following differential equation be solved analytically by some method $$ 
 v(v’’’ + 3v’’ +52v’ + 50v) + 4(v’’’ + 3 v’’ + 52v’ + 100v) = 0,\\
v(0) = v’(0) = v’’(0) = 1.
$$ The solutions to each linear DE in the parenthesis is known. On observation one can see that for the first DE the roots of characterstic equation are $-1, -1\pm7i$ . And the roots to the other are $-2,-0.5\pm i\sqrt{49.75}$ . I have tried solving it numerically on matlab and the solution looks like a sinusoidal wave squeezed between 2 exponentially decaying functions. And the solution decays to zero. Presently, I am trying if functions of the following form might be able to fit into the solution $$
v(x) = \alpha - \sqrt{\alpha^2 + (a_1 e^{-x}+ a_2e^{-2x})+(b_1e^{-x}+b_2e^{-2x})(A\cos\delta x + B\sin\delta x)}
$$",['ordinary-differential-equations']
3254634,"What does a topology do, and what makes a particular topology the 'right' one?","From Wikipedia : The same set can have different topologies. For instance, the real line, the complex plane, and the Cantor set can be thought of as the same set with different topologies. [Aside: Taken literally, this claim is either subjective (hinging on the interpretation of ""can be thought of as"") or false. I would appreciate it if someone could clarify what this is meant to say.] From so many sources that it's a cliche: The Euclidean topology is the natural topology for $\Bbb{R}^n$ ... Naturally, sets such as $\Bbb{N}$ and $\Bbb{Z}$ [which are not dense / nowhere dense] suggest the discrete topology... Both of these sentiments seem common enough, and suggest to me that particular topologies are implicitly descriptive of particular sets and vice-versa. Yet, there seems to be no grounds for "" $X$ topology 'naturally' describes $Y$ "", save for $X$ and $Y$ being nominally related (in the same manner as ""ocean"" and ""giant tube worm""). In fact, it seems to me that the choice of topology is fundamentally arbitrary. In a discipline that prides itself on rigor, I find this, along with the casual acceptance of very loose explanations as to why a particular topology is 'natural' or 'obvious', slightly disturbing. All of this has led me to two very important question: What precisely does a topology do - that is, given a particular topology, what can you infer about the structure (i.e. 'shape'), of a space with that topology (aside from the obvious 'this is open/closed', 'this is continuous', etc)? What, if anything, makes a specific topology the right one for a given context - that is, given an arbitrary set, and perhaps some additional information, which topology best describes that set, and why? Ideally, when presented any problem I want to be able to answer the question ""which topology should I use for this""? Note: I am aware of a what a metric topology is and how it is used, I am not asking for an explanation of metric topologies, I want to know why the selection of any particular topology is reasonable in the first place. Seeing as how a metric is just one of any number of characteristics which can be assigned to a set arbitrarily, I would like to know why any one characteristic should be selected to define the 'natural' topology on a set. Edit: Clarification I did not expect this question to get as much of a response as it did, but after reading the comments, I think some clarification is in order. 'Arbitrary' means subject to individual choice, nothing more, nothing less. Because the topology assigned to a set is independent (up to inclusion) of that set, the choice of topology is indeed 'arbitrary'. That being said, I can understand why the Euclidean Topology in $\Bbb{R}^n$ (particularly considered as a vector space) would seem 'natural' - it follows what we would expect from our intuition. It is tempting to say that this intuition is 'natural' or even 'universal' - an element of human nature rather than a product of a particular construct - however, if cultural anthropology has taught me one thing, it is that nothing is universal (except for homicidal endocannibalism taboos). The intuition behind a particular understanding of 'space' is something learned - it is not known from birth, nor is it present in all people. More generally, topology is not an implicitly spatial thing. Outside of analysis and geometric topology, a topology is just a kind of set. My Take Away From what I can piece together from the answers, a topology first and foremost is a means of labeling particular subsets of a set - namely those subsets possessing a desired property. The significance of the labelling depends on what information we are interested in, not the characteristics of the set itself. In the case of metric topology, what we are interested in is 'space', and the open sets of a metric topology effectively captures the idea of 'sets that take up space'. In other cases, such as Furstenberg's proof that there are infinitely many primes (addressed in J.G.'s answer) or algebraic geometry (addressed in Moishe Kohan's answer) we are interested in different things - like 'sets which are infinite', or 'sets containing the zeros of polynomials'.","['general-topology', 'big-picture']"
3254644,Evaluating $\int\limits_a^b x (b-x)^{n-1} (x-a)^{k-n} dx$,"I have an integral: $$\int\limits_a^b x (b-x)^{n-1} (x-a)^{k-n} \, dx$$ Where $0 \leq a \leq b$ are fixed/known reals and $1 \leq n \leq k$ are fixed/known integers. At first I thought binomial theorem but I think that requires the variables to have absolute value under $1$ . How can I tackle this?","['integration', 'calculus', 'binomial-theorem', 'definite-integrals']"
3254676,How to integrate $\frac{1}{(x+1)(x+2)^2(x+3)^3}$?,I tried to solve it with partial fraction decomposition but the expression becomes way too difficult to solve. I could only solve three of six(A-F) expressions of the partial fraction expansion.,"['integration', 'calculus']"
3254688,Eigenvalues of the Jacobian matrix of a quadratic change of variables,"Consider the set of coordinates $x_i$ and $y_i$ for $i = \pm 1, \pm 2 \dots \pm N$ and $N \geq 2$ .
Consider the change of coordinates from $\mathbf{x}$ to $\mathbf{y}$ defined by $$
y_i(\mathbf{x}) = c_i + x_i \sum_{j \neq i} c_j x_{-j} \tag{1}
$$ where the $c_i$ are any strictly positive real numbers constrained by $\sum_{i} c_i = K$ for a constant $K$ . Let $\mathbf{J}(\mathbf{x}) = \partial \mathbf{y}/\partial \mathbf{x}$ be the Jacobian matrix of the transformation. Let $\mathbf{1}$ be a vector of length $2N$ consisting of all $1$ 's. Conjecture 1: The constant $K$ is an eigenvalue of $\mathbf{J}(\mathbf{1})$ . Conjecture 2: Assuming Conjecture $1$ is true, any vector $\mathbf{v}$ satisfying $\mathbf{J}(\mathbf{1}) \mathbf{v} = K \mathbf{v}$ has the property that $v_{j} + v_{-j} = 0$ , where $v_{\ell}$ is the entry of $\mathbf{v}$ corresponding to coordinate $x_\ell$ . I've verified both conjectures by explicit (computer-assisted) calculation for $N = 2, 3, 4$ . One observation is that Eq. $(1)$ can be written as \begin{align}
y_i &= c_i + x_i \sum_{j} c_j x_{-j} - c_i x_{i} x_{-i} \\ 
 &= c_i + \alpha x_i - c_i x_{i} x_{-i}
\end{align} where $\alpha$ is a constant that doesn't depend on $i$ . In particular, swapping $i \to -i$ shows that $y_i$ and $y_{-i}$ both (sort of) only depend on $x_i$ and $x_{-i}$ which is suggestive of Conjecture $2$ . It really seems like there should be a simple reason for the conjectures but I can't see it.","['matrices', 'jacobian', 'nonlinear-system', 'eigenvalues-eigenvectors']"
3254708,Are there infinitely many primes that are 1 more a square-free number? [duplicate],"This question already has answers here : How to prove that $p-1$ is squarefree infinitely often? (2 answers) Closed 3 years ago . Other words, are there infinitely many primes $p$ such that $p-1$ is square-free. This seems likely to be true, but I can't seem to give an easy argument why. This set of primes and all primes 1 more an integer with a square divisor make up the set of primes, so at least one of these is infinite. I looked at this question for enlightenment but to no avail : Infinitely many primes $p$ such that $\frac{p-1}{2}$ is a product of two primes as 2 could be included in this product.","['number-theory', 'elementary-number-theory', 'sieve-theory']"
3254724,"If $\int_0^1f^k(x)\;dx\le M$, then $m(\{x\in[0,1]:f(x)>1\})=0$.","I am having trouble with the following problem from a past analysis qualifying exam: Let $f(x)$ be a non-negative measurable function defined on $[0,1]$ . Suppose there exists a constant $M$ such that $$\int_0^1f^k(x)\;dx\le M$$ for all $k\ge1$ . Prove that $m(\{x\in[0,1]:f(x)>1\})=0$ . (Note that $m$ here stands for the Lebesgue measure) I can't seem to figure out how this bound on the integral helps me. Just following my nose, let $E=\{x\in[0,1]:f(x)>1\}$ . Then $$m(E)=\int\chi_E(x)\;dx<\int f(x)\chi_E(x)\;dx\le\int f^k(x)\chi_E(x)\;dx$$ $$\le\int_0^1 f^k(x)\;dx\le M.$$ Clearly this is not the way to go since I'd like to show that $m(E)=0$ . Any help would be very much appreciated.","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis', 'measurable-functions']"
3254738,What is the number of connected graphs with $n$ vertices of max. degree up to $P$? Leaving $F(x) = x + x^2 + 2x^3 + 6x^4 + 21x^5 + ...$,"It is known that F(x) is the generating function of the counting sequence of connected simple graphs with N vertices is given by: $F(x) = x + x^2 + 2x^3 + 6x^4 + 21x^5 + 112x^6 + ...$ where the total number of connected graphs of $n$ vertices is obtained by the coefficient corresponding to $x^n$ . The question here is : How to find the series (or formula) to get the counting of connected simple graphs with $n$ vertices of maximum degree up to $P$ ? (generalizing with at least $1$ vertice with maximum degree equal to $P$ ) For example, for $n = 5$ with $P=3$ , we have $8$ connected graphs with at least $1$ vertice with maximum degree equal to $3$ , and for $n = 5$ with $P=4$ , we have $11$ connected graphs with at least $1$ vertice with maximum degree equal to $4$ , as shown the degree distribution in the illustration below: Follows a table of the count of the first groups of graphs according to the number of vertices and the maximum degree: My question in brief is to determine the number of connected graphs with max. degree $P$ for a given number of Nodes $n$ . OBS: Do not get confused! the question does not include Disconnected Graphs, Digraphs, Labeled Graphs, number of cubic or quartic graphs! Anyone know a solution to this intriguing problem? help me! Note: F(x) is the generating function of the counting sequence of connected structures, then the corresponding generating function G(x) of the counting sequence of all structures is given by: $$G(x) = exp \sum_{k>=1} F(x^k)/k = \sum_{i=0} b_i x^k$$ Applying a variant of the Mobius inversion to equation above, it is possible to
express F(x) in terms of G(x): $$F(x) = exp \sum_{k>=1} [\mu(x)/k]log G(x^k) = \sum_{i=0} a_i x^k$$ Where $\mu$ stands for the Mobius function. Let $a_n$ be the number of connected graphs on $n$ vertices and $b_n$ the number of all graphs on $n$ vertices. Then: $F(x) = x + x^2 + 2x^3 + 6x^4 + 21x^5 + 112x^6 + 853x^7 + ...$ and $G(x) = 1 + x + 2x^2 + 4x^3 + 11x^4 + 34x^5 + 156x^6 + ...$ I saw this on ""Counting Disconnected Structures: Chemical Trees, Fullerenes, I-graphs"" on the link: https://hrcak.srce.hr/file/4232 but I did not understand how I can use it in favor of my problem. An observation: If $T(n)$ represents the total of connected graphs of $n$ nodes and $D_p(n)$ represents the total of connected sub-graphs group with max. degree $P$ , and knowing that $P_{max} = (n-1)$ , we can write: $$ T(n) = D_1(n) + D_2(n) + D_3(n) + ... + D_{n-1}(n)$$ For $n>2$ , we know that $D_1(n) = 0$ and $D_2(n) = 2$ , so we have to: $$T(n) = 2 + D_3(n) + ... + D_{n-1}(n)$$ Note also that $D_{n-1}$ is obtained by the coefficient of $x^{n-1}$ of $G(x)$ . But how to calculate $D_p(n)$ ? OBS: Another way to attack the problem I posted on the link About counting the number of graphs by the maximum Degree $D$.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3254743,Basic notions about derivatives,"First of all, I'm a beginner in calculus and this problem came out to be tricky for me. Denote $\dot{x}=\frac{dx}{dt}$ for any function $x(t)$ of time $t$ . Consider the equality $$\dot{y}=c \frac{\dot{x}}{x},$$ where $y=:y(t)$ and $x=:x(t)$ . My first question is: it holds that $$\frac{d\dot{y}}{d\dot{x}}=c/x$$ or should I take into account that $\dot{y}=f(\dot{x},x)$ and $\dot{x}=g(x)$ ? Moreover, I would like to know how to treat the second derivative $$\frac{d^2\dot{y}}{d\dot{x}^2}.$$ Finally, for some function $h$ , is it correct that $\frac{dh(x)}{d\dot{x}}=\frac{dh}{dx}\frac{dx}{d\dot{x}}$ , provided that $\frac{d\dot{x}}{dx}=\frac{d\dot{x}}{dt}\frac{dt}{dx}=\frac{\ddot{x}}{\dot{x}}$ exists? Thanks in advance!","['self-learning', 'derivatives']"
3254745,How come the $\epsilon-\delta$ definition of continuity is preferred over the sequential definition of continuity?,"I've personally found things are a lot easier to prove using the sequences rather than the $\epsilon-\delta$ method. I do understand the $\epsilon-\delta$ is more intuitive, but it's quite difficult to prove a function is continuous on $x_0 \in D$ since it implies finding a function that takes $\epsilon$ and $x_0$ as arguments and outputs some $\delta>0$ , or at least proving such a function exists. This issue is even more prevalent when proving a function is uniformly continuous. On all of my homework problems involving uniform continuity, I always tried to use the $\epsilon-\delta$ definition, yet I always failed. When searching for the solution, the proofs are quite confusing and complex. I would then switch to the sequence definition and would succeed in solving the problem quickly. My professor says that the mathematics community nonetheless refers the $\epsilon-\delta$ definition, so I am curious why when it's a more difficult path. Here are the definitions. For a function $f:D \rightarrow \mathbb{R}$ , Continuity : $f$ is continuous at $x_0 \in D$ if for any sequence $(x_n)$ in $D$ where $\lim_{n \rightarrow \infty} x_n=x_0$ , it follows $\lim_{n \rightarrow \infty} f(x_n)=f(x_0)$ . Uniform continuity: $f$ is uniformly continuous if for any sequences $(u_n),(v_n)$ in $D$ where $\lim_{n \rightarrow \infty} (u_n-v_n)=0$ , it follows $\lim_{n \rightarrow \infty}(f(u_n)-f(v_n))=0$ . An instance of this is proving the function $f:[0,1) \rightarrow \infty$ where $f(x)=\frac{1}{1-x}$ is not uniformly continuous. I found it very difficult to prove this using the $\epsilon-\delta$ definition, and the proofs I found online were quite confusing and there's definitely no way I would've come across them by myself. The sequential definition however was very simple. I simply used the sequences $u_n=1-\frac{1}{n^2}$ and $v_n=1-\frac{1}{n}$ . The differences of the sequences converge to 0, and the differences of the image of the sequences diverge to $\infty$ . $0 \not = \infty$ and therefore $f$ is not uniformly continuous. Another example is showing that any continuous function whose domain is a closed interval is uniformly continuous. There's no way I could come up with a way to prove this using the $\epsilon-\delta$ definition, but I definitely could using the sequence definition. I may be wrong, but I believe I read once that for some metric spaces, continuity and sequential continuity are not equivalent. I don't know much about that matter though, but would love to learn about it.","['continuity', 'uniform-continuity', 'real-analysis']"
3254774,Polar decomposition of a general matrix,"How can I calculate the polar decomposition for a general matrix? For example for this simple one: $$
    \begin{pmatrix}
    a & -b  \\
    b & a  \\
    \end{pmatrix}
$$ I know how to calculate it for a matrix with numbers, via eigenvalues, eigenvectors. I have been searching for the answer on the internet for a while but I don't fully understand it.","['linear-algebra', 'matrix-decomposition']"
3254778,"Why compare $s_n:=\sum_{k=1}^n\frac{1}{k}$ to $\int_{1}^{n+1}\frac{1}{x}dx$, instead of $\int_1^{n}\frac1{x}dx$, when proving divergence of $s_n$?","I've seen an example in which the limit of the sequence $s_n = \sum_{k=1}^n \frac{1}{k}$ is proved to be divergent because: $$s_n \geq \int_{1}^{n+1}\frac{1}{x} dx$$ and $\log(n+1)=+\infty$ as $n\to +\infty$ . I'm confused about the following: Why $n+1$ instead of $n$ ? I've been trying to think but found no (convincent) reason for it, I guess it would work with $n$ too. I guess I got confused because in the previous example, he proved that $s_n=\sum_{k=1}^{n}\frac{1}{k^2}$ is convergent because: $$s_n\leq 1+\int_1^{n}\frac{1}{x^2}dx$$",['sequences-and-series']
3254789,Is $2\pi B \coth{\frac{\pi B}{2\sqrt{A^2 - B^2}}}$ a valid lower bound for the circumference of an ellipse?,"Suppose there is an ellipse with a semi-major axis length of $A$ and a semi-minor axis length of $B$ . The task is to prove or disprove that the circumference of the ellipse in question is greater than $$2\pi B \coth{\frac{\pi B}{2\sqrt{A^2 - B^2}}}$$ This is a problem that I received from a friend, and so far I have tried to compare it to the integral expression for the circumference of an ellipse and use Jenson's inequality to find another lower bound to compare the above expression to. This leading me to no avail, I thought I would pose the problem here to see if there is a better approach.","['conic-sections', 'geometry', 'hyperbolic-functions']"
3254842,Curvature and torsion of a spherical curve,"I'm trying to show that if $\alpha$ is a regular curve parametrized by arc lenght whose range lies on the unit sphere centered at the origin, then $\kappa (s) = \sqrt{1+j^2}$ and $\tau (s) = \dfrac{j'(s)}{1+j^2(s)}$ where $j(s)=\det[\alpha (s), \alpha '(s), \alpha ''(s)]$ . Any ideas?","['spheres', 'arc-length', 'curvature', 'differential-geometry']"
3254895,"Let $f(x)$ be twice differentiable function, with $f(x) = x$ has $3$ roots","Let $f(x)$ is twice differentiable increasing  function everywhere such that $f(x) = x$ has $3$ distinct root $\alpha ,\beta$ and $\gamma$ $(\alpha  < \beta  < \gamma )$ . Let $h(x) = \underset{n\to \infty }{\mathop{\lim }}\,\underset{n\,\,\,times}{\mathop{(f(f(...(f(x))))}}\,$ . (1)    If $f’’(x) > 0$ $\forall \,x\,\in \,(-\infty ,\beta )$ , $f”(x) < 0$ $ \forall x\,\in \,(\beta ,\infty ]\,$ and $f''(\beta )=0,\,$ then find $h(x)$ (2)    If $f(x)\ge x\,\forall \,x\,\in \,(-\infty ,\alpha ]\,\cup \,[\gamma ,\infty )$ and $f(x)\le x\,\forall \,x\,\in \,[\beta ,\gamma ]\,$ then find $h(x)$ I tried with a fucntion $k(x) = f(x)-x$ , such that $k(\beta)$ is $0$ .
But how to do further.","['functions', 'derivatives']"
3254910,What is the definition of a set?,"From what I have been told, everything in mathematics has a definition and everything is based on the rules of logic. For example, whether or not $0^0$ is $1$ is a simple matter of definition . My question is what the definition of a set is? I have noticed that many other definitions start with a set and then something. A group is a set with an operation, an equivalence relation is a set, a function can be considered a set , even the natural numbers can be defined as sets of other sets containing the empty set. I understand that there is a whole area of mathematics (and philosophy?) that deals with set theory . I have looked at a book about this and I understand next to nothing. From what little I can get, it seems a sets are ""anything"" that satisfies the axioms of set theory. It isn't enough to just say that a set is any collection of elements because of various paradoxes. So is it, for example, a right definition to say that a set is anything that satisfies the ZFC list of axioms?","['foundations', 'algebra-precalculus', 'definition', 'set-theory']"
3254931,Circular Permutations. Difference between clockwise and anti-clockwise permutations.,"Please tell me the total number of permutations possible of the beads in a necklace where all the beads are distinct. The necklace consists of n distinct beads. Answer as per me: the answer is $(n-1)!\:$ , as the clockwise and anti-clockwise arrangements are different. Answer given in various online courses: The clockwise arrangement of the necklace shown is B1-B2-B3-B4. Since the necklace can be flipped, the total permutations = (n-1)!/2. Reason: After flipping the necklace, the anti-clockwise arrangement is the same again i.e. B1-B2-B3-B4.
The link to these online courses are: 1) https://www.askiitians.com/iit-jee-algebra/permutations-and-combinations/circular-permutations.aspx 2) https://www.youtube.com/watch?v=6BoAwmUlfqs > The 2nd link is a video lecture in the language of Hindi. Start this video from 13:05 minutes, so as to avoid the unnecessary things. Can you tell me which one is correct with an appropriate explanation.","['permutations', 'combinatorics', 'contest-math']"
3255016,Find the limit $\lim _{n \to \infty}(n!)^{{\frac{1}{n^2}}}$ [duplicate],This question already has answers here : Using the squeeze theorem to determine a limit $\lim_{n\to\infty} (n!)^{\frac{1}{n^2}}$ (2 answers) Closed 5 years ago . Find the limit $$\lim _{n \to \infty}(n!)^{{\frac{1}{n^2}}}$$ I have tried it using Stirling's approximation and then using L'Hospital's Rule and get answer $1$ Is there any other easy method to find this limit ? Any hint. Thanks in advance.,"['analysis', 'real-analysis', 'calculus', 'sequences-and-series', 'limits']"
3255069,The fundamental group of the gluing of two genus $g$ $3$-dimensional handlebodies,"I was given the problem above, and I'd appreciate some help. I think I have a general direction, but I'm not entirely sure if what I'm doing is true, so it'd be great if someone could tell me if what I'm doing is generally alright and maybe point me in a more concrete direction if necessary. So I start off by computing the fundamental group of the genus $g$ handlebody. I do so by taking the handlebody and making it thinner and thinner, until its basically as thick as a line. This is a deformational retract, and therefore not supposed to affect the fundamental group. I'm then left with g copies of $S^1$ which all intersect at a point, and so by the Seifert-Van-Kampen theorem, the fundamental group is the free group generated by $g$ elements. Now, I want to see what happens when I glue two handlebodies along the boundary. This is where things get tricky for me. I want to use Seifert-Van-Kampen once again, but not entirely sure that I'm doing it correctly. Since I glue the to handlebodies along the boundary, the intersection of the two handlebodies is now a sufrace of genus $g$ , who's fundamental group I can once again calculate using Seifert-Van-Kampen - $$\pi=\langle a_1,b_1,...,a_g,b_g| \prod _{i=1}^{g} [a_i,b_i]=1 \rangle$$ So I think that the fundamental group I'm looking for should be the free product of the two original fundamental groups of the handlebodies ( $F_1, F_2$ ), under quotient with respect to the fundamental group of the surface with genus $g$ : $$\pi'=(F_1*F_2)/\pi$$ Does this make sense? Or is there something I'm missing along the way? Moreover, I'm wondering if there's a simpler/clearer way to express the group $\pi'$ . Thanks in advance.","['group-theory', 'fundamental-groups', 'manifolds', 'general-topology', 'algebraic-topology']"
3255091,Probability of Random Item Selection,"In a 15-piece batch there are 5 black balls and the 10 remaining balls are white. 3 balls are selected randomly. The batch is discarded if among the chosen ones at least one selected ball is white. What is the probability of this? I assume the random selection is based upon no replacements, as 3 balls are taken at one go. Formula: $P(X=x) = C(n,x) p^x (1–p)^{n-x}$ The probability of selecting a white ball is given by $\tfrac{10}{15}$ , hence $\tfrac{2}{3}$ should be white. But how about the probability distribution for at least one single white ball selected out of 3? Thanks to @lulu: $1 - (\tfrac{5}{15} * \tfrac{4}{14} * \tfrac{3}{13}$ ) or just $1 - \binom 53 \Big / \binom {15}3$","['statistics', 'probability']"
3255112,"What does the word ""letters"" mean in Bourbaki text?","On Bourbaki's ""Theory of Sets"", page 16, it says "" $\int_0^1 f(x) dx$ represents an assembly in which the letter $x$ and the letter $d$ do not appear; and the assemblies represented by $\mathbb{Z}$ , $\mathbb{N}$ do not contain any letters."" This confuses me since it said before letters are those Roman letters, since those $x$ are not replaced by other assemblies, why we don't account them as letters? Thank you!",['elementary-set-theory']
3255184,"Is $C_{c}^{\infty}[a,b]$ a complete metric space?","Is the space of smooth functions with compact support in an interval $[a,b] \subset \mathbb{R}$ , with the metric $\rho(\varphi_{1},\varphi_{2})= \sum_{n=0}^{\infty}2^{-n}\frac{\left \| \varphi_{1} - \varphi_{2} \right \|_{n}}{1 + \left \| \varphi_{1} - \varphi_{2} \right \|_{n}}$ where $\left \| \varphi\right \|_{n} = \sum_{j=0}^{n}\sup_{x \in [a,b]}|\varphi^{(j)}(x)|$ complete?","['general-topology', 'smooth-functions', 'functional-analysis', 'metric-spaces']"
3255197,Why does $ b \ge 0 $ in Gronwall Lemma?,"I'm reading about Gronwall Lemma, formulated this way: Let $a \in \mathbb{R}$ , $b\ge 0$ , $T>0$ . If $ u: [0, T) \to \mathbb{R} $ continuous and for $ t \in (0, T) $ $$ u(t) \le a + b\int^t_0u(s)ds $$ then for $ t \in (0,T) $ $$ u(t) \le ae^{bt}. $$ I can see that $a$ is any real number, so why $b$ has to be greater (or equal) than zero? Are there some counterexamples for this lemma with $b<0$ ?",['ordinary-differential-equations']
3255198,Matrix Equation $B^3+C^3=\begin{pmatrix}-1 & 1\\ 0 & -2\end{pmatrix}$,"How can I solve in $\mathcal{M}_{2}(\mathbb{Z})$ the equation $$B^3+C^3=\begin{pmatrix}-1 & 1\\ 0 & -2\end{pmatrix}?$$ I try to use $$X^2-Tr(X)X+det X\cdot I_2=0_2$$ but there are $B$ and $C$ , I don't still obtain anything. thanks.","['matrices', 'matrix-equations', 'linear-algebra']"
3255200,Proof that $\sum_{k=1}^n(-1)^k(k-1)!{n \brace k} = 0$ in use combinatoric interpretation,"Proof that $$\\\sum_{k=1}^n(-1)^k(k-1)!{n \brace k} = 0\\$$ where $n > 1$ .
I know how it can be done with standard algebraic methods: Solution $$
\begin{align*}
  \sum^n_{k=1}(-1)^k(k-1)!{n \brace k}
  &=\sum^n_{k=1}(-1)^k(k-1)!\left(k{n-1 \brace k} +
   {n-1 \brace k-1}\right) = \\
  &=\sum^n_{k=1}(-1)^k k!{n-1 \brace k} +
   \sum^n_{k=1}(-1)^k (k-1)!{n-1 \brace k-1}
\end{align*}
$$ We can describe both sums: $$
\begin{align*}
  &=&&- 1!{n-1 \brace 1}
   + 2!{n-1 \brace 2}
   - 3!{n-1 \brace 3}
   + \dots
   + (-1)^{n-1}(n-1)!{n-1 \brace n-1}
   + (-1)^{n}n!{n-1 \brace n} + \\
  &&&- 0!{n-1 \brace 0}
   + 1!{n-1 \brace 1}
   - 2!{n-1 \brace 2}
   - \dots
   + (-1)^{n-1}(n-2)!{n-1 \brace n-2}
   + (-1)^{n}(n-1)!{n-1 \brace n-1}\\
\end{align*}
$$ We see that elements of both sums reduce so we can write that as: $$
  = -0!{n-1 \brace 0} + (-1)^{n} \cdot n! \cdot {n-1 \brace n}
  = 1 \cdot [n-1 = 0] + (-1)^{n} \cdot n! \cdot 0 = 0 + 0 = 0
   $$ But I am really interested in combinatoric proof. I know that I should find bijection between even and odd elements, but I don't know how it can be done.","['combinatorics', 'stirling-numbers']"
3255277,How can I know the number of solutions of the following congruence $x ^ {10} \equiv 1 \pmod {2016}$?,"How can I know the number of solutions of the following congruence $x ^ {10} \equiv 1 \pmod {2016}$ ? My professor quick answer was: $$\mathbb{Z_{2016}^*} \cong \mathbb{Z_{32}^*} \times \mathbb{Z_{9}^*} \times \mathbb{Z_{7}^*} \cong (C_{8} \times C_{2}) \times C_{6} \times C_{6} \cong (C_{8} \times C_{2}) \times (C_{2} \times C_{3}) \times (C_{2} \times C_{3})  $$ Where $\mathbb{Z^*}$ is the group of units and $C_{n}$ is the cyclic group of order n. My question related to this part is why he did not use $C_{16}$ or $C_{4} \times C_{4}$ instead of $C_{8} \times C_{2}$ , could anyone explain this for me please? Then My professor added: ""then the number of solutions of the given congruence is $|C_{2} \times C_{2} \times C_{2} \times 1 \times  C_{2} \times 1 | = 2^4 =16$ "" I understand part of this part, he neglected the $C_{3}$ group as it will not contain elements of order 2 (which I do not know why? could anyone explain this for me please?). Also, he took one $C_{2}$ group of $C_{8}$ (which I do not understand why? as far as I know $\mathbb{Z_{mn}} \cong \mathbb{Z_{n}} \times \mathbb{Z_{m}}$ iff gcd(m,n) = 1, and gcd(4,2) $\neq$ 1) Could anyone elaborate these parts for me please? Note: I have asked my professor but he answered these question in a very fast way so that I could not follow him. The steps my professor do before answering this number of solutions question are: He used the Euler-Phi function to find $\phi (2016) = 576 $ then he used Euler's theorem, then he noticed that $gcd(10, 576) = 2$ , so he ended up with the congruence $$x ^ {2} \equiv 1 \pmod {2016}$$ , and he said hence the order of of $x$ is either 1 or 2, but the identity element is the only element of order 1, so our $x$ has order 2, this is why we were searching for $C_{2}$ in the above isomorphisms. But my question is: does not $C_{16}, C_{8}, C_{4}$ or $C_{3}$ contains elements of order 2? Thanks!","['number-theory', 'congruence-relations', 'modular-arithmetic', 'elementary-number-theory']"
3255290,When does $v_0\wedge\dots\wedge v_{k-1}=0$ when working over a ring that's not a field?,"Let $M$ be a module over a commutative ring $R$ , and let $v_0,\dots,v_{k-1}$ be elements of $M$ . If $R$ is a field then $v_0\wedge\dots\wedge v_{k-1}$ is equal to $0$ if and only if $v_0,\dots,v_{k-1}$ are linearly dependent. But if $R$ isn't a field then this needn't be true. For example if we view $\frac{\mathbb{Z}}{2\mathbb{Z}}$ as a $\mathbb Z$ -module then $1\in\frac{\mathbb{Z}}{2\mathbb{Z}}$ is linearly dependent on its own, because $2.1=0$ , but it doesn't get sent to $0$ in $\Lambda^1\left(\frac{\mathbb{Z}}{2\mathbb{Z}}\right)$ . Is there a nice characterisation of which lists of vectors do get sent to $0$ ?","['modules', 'ring-theory', 'abstract-algebra', 'linear-algebra', 'exterior-algebra']"
3255319,Arborescence of a graph,"Let $G=(V,E)$ be a directed graph with $n(\geq 2)$ vertices, including a special vertex $r$ . Each edge $e \in E$ has a strictly positive edge weight $w(e)$ . An arborescence in $G$ rooted at $r$ is a subgraph $H$ of $G$ in which every vertex $u \in V \backslash \{r\}$ has a directed path to the special vertex $r$ . The weight of an arborescence $H$ is the sum of the weights of the edges in $H$ . Let $H^*$ be a minimum arborescence rooted at $r$ , and $w^*$ the weight of $H^*$ . Which of the following is $NOT$ always true? $A)w^* \geq \sum_{u \in V \backslash \{r\}} \min_{(u,v) \in E} w((u,v))$ $B)w^* \geq \sum_{u \in V \backslash \{r\}} \min_{(v,u) \in E} w((v,u))$ $C)H^*$ has exactly $n-1$ edges $D)H^*$ is acyclic $E)w^*$ is less than the weight of the minimum weight directed Hamiltonian cycle in $G$ , when $G$ has a directed Hamiltonian cycle I tried like this
Here it is saying a graph given G and it has a special vertex r Now, H is subgraph of graph G and every vertex of H which has a directed edge to r Now I thought G is a graph like this ​ Now as $H$ is any subgraph of $G$ , So, A) and B) false , there is always a subgraph which contains minimum weight of the graph C) false because $H$ may not contain exactly $n-1$ edges. E) False , because H and G can be both same graph (i.e. improper subgraph) One case definitely there , where it is false Now D) H is cyclic or not totally depend on ur designing of graph So, it is not always true (See in the above diagram, if H=G, then It contains a cycle)","['graph-theory', 'directed-graphs', 'discrete-mathematics']"
3255329,Interesting matrix construction question,"We are told that an $n \times n$ matrix $P$ satisfies $P^3=P$ . Can we construct such a matrix $P$ ? Of course, we see that $-1,0,1$ are its only eigenvalues and, thus, a diagonal matrix with diagonal elements $0,1,-1$ would do. However, if I were told that the given matrix should not have $0,1,-1$ as its diagonal elements, then what would be the way out?","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'matrix-equations', 'matrix-decomposition']"
3255361,Volume of a sphere using cartesian coordinates,"I'm preparing my calculus exam and I'm in doubt about how to generally compute triple integrals. I know that the cartesian equation of a sphere is $B_R=\{(x, y, z)|x^2+y^2+z^2=R^2\}$ ,
so (if I didn't want to use spherical coordinates, wich I'm aware is the best way and I already did that)
it's volume would just be $\iiint_S \mathrm{d}x\mathrm{d}y\mathrm{d}z$ ,
but what would the extremes be? I know $-R \leq z \leq R$ and $-\sqrt{R^2-y^2-z^2} \leq x \leq\sqrt{R^2-y^2-z^2} $ ,
but what are the extremes for $y$ ?
I can't describe it in terms of $x$ , so I have $$\text{Vol}(B_R) = \int_{-R}^{R} \int_?^?\int_{-\sqrt{R^2-y^2-z^2}}^\sqrt{R^2-y^2-z^2} \mathrm{d}x\mathrm{d}y\mathrm{d}z.$$ What should be there instead of the '?'","['integration', 'multivariable-calculus', 'volume']"
3255422,"Prob. 5, Sec. 6.2, in Bartle & Sherbert's INTRO TO REAL ANALYSIS, 4th ed: How to show this function is strictly decreasing using derivative","Here is Prob. 5, Sec. 6.2, in the book Introduction To Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition: Let $a > b > 0$ and let $n \in \mathbb{N}$ satisfy $n \geq 2$ . Prove that $a^{1/n} - b^{1/n} < (a-b)^{1/n}$ . [ Hint: Show that $f(x) \colon= x^{1/n} - (x-1)^{1/n}$ is decreasing for $x \geq 1$ , and evaluate $f$ at $1$ and $a/b$ .] My Attempt: We find that for $x > 1$ , $$
\begin{align}
 f^\prime(x) &= \frac{1}{n}x^{\frac{1}{n} - 1} - \frac{1}{n}(x-1)^{\frac{1}{n} - 1} \\
&= \frac{1}{n} \left( \frac{x^{1/n}}{x} - \frac{(x-1)^{1/n}}{x-1} \right) \\
&= \frac{1}{nx(x-1)} \left( x^{1/n}(x-1) - x(x-1)^{1/n} \right) \\
&= \frac{x^{1/n}(x-1)^{1/n}}{nx(x-1)} \left( (x-1) - x \right) \\
&= -\frac{1}{nx^{1-\frac{1}{n}} (x-1)^{1-\frac{1}{n}} }. 
\end{align}
$$ PS (based on the answer by @auscrypt): We find that for $x > 1$ , $$
\begin{align}
 f^\prime(x) &= \frac{1}{n}x^{\frac{1}{n} - 1} - \frac{1}{n}(x-1)^{\frac{1}{n} - 1} \\
&= \frac{1}{n} \left( \frac{x^{1/n}}{x} - \frac{(x-1)^{1/n}}{x-1} \right) \\
&= \frac{1}{nx(x-1)} \left( x^{1/n}(x-1) - x(x-1)^{1/n} \right) \\
&= \frac{x^{1/n}(x-1)^{1/n}}{nx(x-1)} \left( (x-1)^{1-1/n} - x^{1-1/n} \right) \\
&< 0. 
\end{align}
$$ because $1-1/n$ is positive for every $n \in \mathbb{N}$ such that $n \geq 2$ and because $0 < x-1< x$ , which implies that $$ 0 < (x-1)^{1-1/n} < x^{1-1/n},$$ and hence $$ (x-1)^{1-1/n} - x^{1-1/n} < 0.$$ Thus $f^\prime(x) < 0$ for all $x > 1$ . Therefore the function $f$ is strictly decreasing on the interval $[1, +\infty)$ . That is, for any $x > 1$ we have $f(x) < f(1)$ . Now if $a > b > 0$ , then $a/b > 1$ , and so we have $$ f(a/b) < f(1),$$ that is, $$ \left(\frac{a}{b}\right)^{\frac{1}{n}} - \left(\frac{a}{b} - 1\right)^{\frac{1}{n}} < 1,$$ which amounts to $$ \frac{a^{1/n} - (a-b)^{1/n} }{ b^{1/n} } < 1, $$ which implies $$ a^{1/n} - (a-b)^{1/n} < b^{1/n},$$ and hence $$ a^{1/n} - b^{1/n} < (a-b)^{1/n}, $$ as required. Are there any issues with this proof?","['proof-verification', 'real-analysis', 'calculus', 'inequality', 'derivatives']"
3255436,"variance of number of isolated vertices in random graph $G(n,p)$","Suppose we have random graph $G(n,p)$ from a uniform distribution with $n$ vertices and independently, each edge present with probability $p$ . Calculating it's expected number of isolated vertices proves quite easy, chance of single vertex to be isolated is equal to $(1-p)^{n-1}$ , then using linearity of probability, expected number of isolated vertices is equal to $n\times(1-p)^{n-1}$ . However, I am tasked to calculate the variance of this number, or at least decent approximation of it, without any idea how to proceed.","['random-graphs', 'probability-theory']"
3255452,Can a differentiable function be real valued at infinite points and complex valued at some other intervals,"Can a differentiable function (in real part) be real valued at an interval (infinite points) and complex valued at some other intervals?
For example Exp[it] is real valued at countable points and complex valued at other uncountable points. I am trying to understand if a a differentiable function can have both real valued and complex valued intervals (on real axis).","['complex-analysis', 'functions']"
3255546,"Simplifying $\sum_{cyc}\tan^{-1}\left(\sqrt{\frac{x(x+y+z)}{yz}}\right)$. I get $0$, but the answer is $\pi$.","So the question is $$  \tan^{-1}\left(\sqrt{\frac{x(x+y+z)}{yz}}\right)+\tan^{-1}\left(\sqrt{\frac{y(x+y+z)}{xz}}\right)+\tan^{-1}\left(\sqrt{\frac{z(x+y+z)}{yx}}\right) =\ ? $$ So my take on the question is to rewrite it as $$  \tan^{-1}\left(x\sqrt{\frac{(x+y+z)}{xyz}}\right)+\tan^{-1}\left(y\sqrt{\frac{(x+y+z)}{xyz}}\right)+\tan^{-1}\left(z\sqrt{\frac{(x+y+z)}{yzx}}\right) $$ Then say $$\frac{x+y+z}{yzx}= a^2.$$ We get $$ \tan^{-1}\left( \frac{a((x+y+z)-a^2xyz)}{1-a^2(xy+yz+zx)}\right)$$ And since $ (x+y+z) = a^2xyz $ , this is just equal to $\tan^{-1}(0)= 0 $ but the answer given is $\pi.$","['trigonometry', 'inverse-function']"
3255547,Derivative of a double integral over a variable circular region,"Calculate the following derivative $$\frac{d}{dt}\iint_{D_t}F(x,y,t) \, \mathrm d x \mathrm d y$$ where $$D_t = \lbrace (x,y) \mid (x-t)^2+(y-t)^2\leq r^2 \rbrace$$ I've read here $^1$ that the answer to the above question is in the form of: \begin{align}\frac{d}{dt}\iint_{D_t}F(x,y,t)dxdy &=\int_{\partial D_t} F(udy-vdx) + \iint_{D_t}\frac{\partial F}{\partial t}dx dy \\
&=\iint_{D_t}\left[\text{div}(F\mathbf{v})+\frac{\partial F}{\partial t}\right]dx dy\end{align} which is a generalization of Leibniz integral rule. I don't know how I can calculate $\mathbf{v}$ and $\mathbf{n}$ or $u$ and $v$ in my problem. The paper states that $\mathbf{v}$ with components $u$ and $v$ is the velocity and $\mathbf{n}$ is the normal vector. Also, I would be grateful if someone could introduce some other references on the derivative of such double integrals to me. $^1$ : Harley Flanders, Differentiation under the integral sign , Am. Math. Mon. 80, 615-627 (1973). ZBL0266.26010 . The following reference was very handy for me: J. Haslinger and R. Mäkinen, Introduction to shape optimization: theory, approximation, and computation , Society for Industrial and Applied Mathematics (2003).","['integration', 'reference-request', 'multivariable-calculus', 'derivatives', 'leibniz-integral-rule']"
3255556,Extension of bounded linear operator in Hilbert Spaces,"Let $H=(H,(\cdot,\cdot))$ be a Hilbert space and $G\subset H$ equiped with a norm of $H$ . Let $F=(F,||\cdot||_{F})$ a Banach space and $S:G \longrightarrow F$ a bounded linear operador. Prove that, there exists a bounded linear operator $T: H \longrightarrow F$ such that it extends $S$ and $||T||_{\mathcal{L}(H,F)}=||S||_{\mathcal{L}(G,F)}$ . I have already been able to prove that such $ T $ exists by taking $ T = \tilde{S} \circ P_\bar {G}$ , where $ \tilde{S}: \bar{G} \longrightarrow F $ is the extension of $ S $ (Theorem 2.7.11, Kreyszig) and $ P_\bar{G} : H \longrightarrow \bar{G} $ is the projection on the closed convex $ \bar{G} $ . I could not prove that $||T||_{\mathcal{L}(H,F)}=||S||_{\mathcal{L}(G,F)}$ .","['banach-spaces', 'inner-products', 'operator-theory', 'hilbert-spaces', 'functional-analysis']"
3255557,Derivative of double integral,"I am trying to find out what the derivative $\frac{\mathrm d}{\mathrm dx}f(x)$ of the function $$f(x)=\int_0^{x^2}\left(\int_{a-x}^{a+x}\sin(a^2+b^2-x^2)\,\mathrm db\right)\mathrm da$$ is. Using the Leibniz rule twice, I get $$f'(x)=-2x\int_0^{x^2}\left(\int_{a-x}^{a+x}\cos(a^2+b^2-x^2)\,\mathrm db\right)\mathrm da+2\int_0^{x^2}\cos(2a^2)\sin(2ax)\,\mathrm da+2x\int_{x^2-x}^{x^2+x}\sin(x^4-x^2+b^2)\,\mathrm db.$$ This does not look like it had an analytic expression. Are there maybe some symmetries I did not see, or is there a better approach than the Leibniz rule to solve this?","['integration', 'analysis', 'real-analysis', 'calculus', 'derivatives']"
3255569,What are the implications when matrix's lowest eigenvalue is equal to 0?,I have a task to solve where only eigenvalues are given and I need to calculate a matrix condition number. The formula for it requires division by the lowest eigenvalue (which is zero). In such case the condition number cannot be calculated. Can equation system be solved if the lowest matrix eigenvalue is 0?,"['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3255573,Infinite sets: $A$ is infinite iff there is a bijection between $A$ and $A \cup \{b\}$,"I've been struggling to understand the proof of the following theorem given in a book. Let $A$ be a set and $b \notin A$ . Then $A$ is infinite iff there is a
  bijection between $A$ and $A \cup \{b\}$ . Proof: Since $A$ is infinite, it must be nonempty, i.e. $A=\{a_0,a_1,a_2,...\}$ . A bijection $f: (A \cup \{b\}) \rightarrow A$ can be defined by: $f(b):=a_0$ $f(a_n):=a_{n+1}$ , for $n \in \mathbb{N}$ $f(a):=a$ , for $a\in (A\setminus \{b, a_0,a_1,... \})$ . q.e.d. In the last line, I don't understand why the set $A\setminus \{b, a_0,a_1,... \}$ is nonempty. (It is literally the set formed by taking all the elements of $A$ away from $A$ .)",['elementary-set-theory']
3255578,"Schwartz space, Gaussian measures and integration over paths","I'm studying the Wiener measure motivated by the path integral in quantum mechanics. For that I'm using the book by Glimm & Jaffe ""Quantum Physics: a Functional Integral Point of View"" that deals with it from that perspective. Now, I'm having a problem in understanding a part of the book, that I think might be just a notation problem. The notations I'm used to For me $\mathscr{S}(\mathbb{R}^d)$ , the space of Schwartz functions, is the space of smooth functions $f : \mathbb{R}^d\to \mathbb{R}$ with the property that: $$\sup_{x\in \mathbb{R}^d}x^\alpha D^\beta f(x)<\infty,\quad \alpha,\beta \ \text{multi-indices}.$$ Similarly, for me $\mathscr{S}'(\mathbb{R}^d)$ means the space of continuous linear functionals on $\mathscr{S}(\mathbb{R}^d)$ . I know then that we have: $$\mathscr{S}(\mathbb{R}^d)\subset \mathscr{S}'(\mathbb{R}^d),$$ so that $\mathscr{S}'(\mathbb{R}^d)$ can be seen as an enlargement of $\mathscr{S}(\mathbb{R}^d)$ .The key point is: in what I'm used to a Schwartz distribution is a linear functional acting on $f : \mathbb{R^d}\to \mathbb{R}$ maps which can be seen as a more general class of such maps . What Glimm and Jaffe seem to do My issue is that Glimm & Jaffe talks many times about constructing gaussian measures (and in particular the Wiener measure) on the space of Schwartz distributions. In particular, since $\mathscr{S}(\mathbb{R}^d)\subset \mathscr{S}'(\mathbb{R}^d)$ this measure allows to integrate over functions $f : \mathbb{R}^d\to \mathbb{R}$ . These are not paths by any means. Let me make my issue crystal clear: my issue is not on working with the dual. This seems a standard thing to do to deal with singular objects. Furthermore, later on one could see how to restrict the measure to the original space. My issue is that the original space here is a space of functions $f : \mathbb{R}^d\to \mathbb{R}$ while paths must be functions $f: [a,b]\to \mathbb{R}^d$ . So I ask: how the Schwartz space relates to paths in Glimm & Jaffe treatment? How one integration over paths (Wiener measure) can be related with an integration over real-valued functions? Is it perhaps another Schwartz space of functions, whose elements are indeed paths, and hence another Schwartz distribution space, whose elements are linear functionals on paths?","['wiener-measure', 'measure-theory', 'definition', 'functional-analysis']"
3255686,Why is this method incorrect?,"A man is to be executed at random time between 00:00 and 01:00. The
  firing squad's accuracy decreases linearly, so that at 00:00 they
  shoot perfectly, at 00:30 miss half the time, and at 01:00 miss
  always. Also, with probability 1/2, a blank round of shots will be
  used. Given that the man survived, what is the probability that he faced a
  live round? At first I drew a diagram with time on x-axis, a horizontal line at $y=1/2$ with ""blind round"" above it and ""live round"" below. Then I divided that lower region with a diagonal to represent the falling accuracy, and got the answer $\frac{1}{4} / (\frac{1}{4}+\frac{1}{2}) = \frac{1}{3}$ which a simulation seems to confirm. I'm not sure why the following method gives an incorrect answer: at time $\theta$ , $P_\theta (\text{survived})=\theta/2 + 1/2$ and $P_\theta(\text{live rounds and survived}) = \theta/2$ . Therefore $P_\theta(\text{live rounds | survived}) = \frac{\theta}{\theta+1}$ . Now integrate to get $\int_0^1 P_\theta d\theta = \int_0^1 \frac{d\theta . \theta}{\theta+1} = 1-\log 2 \approx 0.3069$ .","['probability-distributions', 'probability']"
3255687,"If compact embedding $H^1_0(\Omega) \hookrightarrow H^{-1}(\Omega)$ is not surjective, how can $H^{-1}(\Omega)$ be the dual of $H^1_0(\Omega)$?","Let $\Omega$ be bounded with Lipschitz boundary. By Rellich compactness, $\iota: H^1_0(\Omega) \hookrightarrow L^2(\Omega)$ is compact embedding. It is also dense. By Riesz representation, $L^2(\Omega) \overset{\sim}{\longrightarrow}(L^2(\Omega))^*$ , so $L^2(\Omega)$ is identified with its dual. By Hahn-Banach, the dual map $\iota^*: (L^2(\Omega))^* \hookrightarrow (H^1_0(\Omega))^* = H^{-1}(\Omega)$ is dense compact embedding. Thus, $\kappa: H^1_0(\Omega) \hookrightarrow H^{-1}(\Omega)$ is dense compact embedding. It is that the compact map in infinite dimensional space can not be surjective. Here is my confusion: $H^{-1}(\Omega)$ is dual of $H^1_0(\Omega)$ . Thus, there must be an isometric isomorphism that maps every $x \in H^1_0(\Omega)$ to a dual $x^* \in H^{-1}(\Omega)$ . So, the embedding $\kappa$ of $H^1_0(\Omega)$ to its dual should be surjective. Then, how can $H^1_0(\Omega)$ is compactly embedded to its dual?","['dual-spaces', 'sobolev-spaces', 'functional-analysis', 'compact-operators']"
3255711,$\sum_{n=1}^\infty\frac{H_n}{n}\left(\zeta(2)-H_{2n}^{(2)}\right)$,"This problem was proposed by Cornel and he showed that $$S=\sum_{n=1}^\infty\frac{H_n}{n}\left(\zeta(2)-H_{2n}^{(2)}\right)=\frac13\ln^42-\frac12\ln^22\zeta(2)+\frac72\ln2\zeta(3)-\frac{21}4\zeta(4)+8\operatorname{Li}_4\left(\frac12\right)$$ here is my approach. we know that $\quad\zeta(2)-H_{2n}^{(2)}=\psi^{(1)}(2n+1)=-\displaystyle\int_0^1\frac{x^{2n}\ln x}{1-x}\ dx$ then $$S=-\int_0^1\frac{\ln x}{1-x}\sum_{n=1}^\infty\frac{x^{2n}H_n}{n}\ dx=-\int_0^1\frac{\ln x}{1-x}\left(\frac12\ln^2(1-x^2)+\operatorname{Li}_2(x^2)\right)\ dx$$ and by applying IBP , we get $$S=-2\int_0^1\frac{\operatorname{Li}_2(1-x)\ln(1-x^2)}{x(1-x^2)}\ dx$$ I applied the dilogarithmic identity $\quad\operatorname{Li}_2(1-x)=\zeta(2)-\ln x\ln(1-x)-\operatorname{Li}_2(x)$ but it was not that helpful. any idea?","['integration', 'real-analysis', 'harmonic-numbers', 'polylogarithm', 'sequences-and-series']"
3255734,"How to Move the Intercepts of $x^y=y^x$ to (1, 1)","In the equation, $x^y=y^x$ , which I have modified to $(gx)^{y}=(gy)^{x}$ , what would $g$ have to be to make the $f(x)=x$ function to intercept with the hyperbolic function at the point $(1,1)$ ? $gx^y=gy^x$ where $g=1$ "">","['functions', 'graphing-functions']"
3255760,"$a_k = \sum\limits_{i=1}^{k-1}a_i \left(\frac{1}{k-i}-\frac{1}{k-i+1}\right)$ and $a_1 = 1$, prove the series is decreasing?","If the series { $a_n$ } is defined recursively in the following way: $a_1 = 1$ , $a_k = \sum\limits_{i=1}^{k-1}a_i\cdot\left(\frac{1}{k-i}-\frac{1}{k-i+1}\right)$ for $k=2,\cdots, n$ , how can I prove that $a_k$ is decreasing?","['monotone-functions', 'discrete-mathematics', 'sequences-and-series']"
3255786,"How many ways can 15 people be divided into 3 classes of 5, if there are 3 blond people....","How many ways can 15 people be divided into 3 classes of 5, if there are 3 blond people and each class needs to have 1 blond person? My attempt at the question: First, the 3 blond people are excluded from the 15, leaving us with 12. 
To divide the 12 people into 3 groups of 5, where each group has 1 person already, we must do: 12C4 * 8C4 * 4C4 Now, this is where I get a little confused. I think that, because the groups are ""distinct"", due to the presence of 1 blond person in each group, there's no need to divide by 3!, despite the groups being of equal size. Is this logic correct? As a spin-off question, if all the blond people have to be in 1 class, then we'll have to do 12C2 (to choose the other 3 people for that class) * 10C5 * 5C5 divided by 2!, as the other two classes aren't distinct. Is this correct? I don't have solutions to these questions so I cannot determine if it's right or wrong. Any advice will be much appreciated.","['permutations', 'combinations', 'combinatorics']"
3255812,Putnam Combinatorics/Set Theory Question,"This is a problem from the 1985 Putnam Exam: Determine, with proof, the number of ordered triples $(A_1, A_2, A_3)$ of sets with (i) $A_1 \cup A_2 \cup A_3 = \{1,2,3,4,5,6,7,8,9,10\},$ and (ii) $A_1 \cap A_2 \cap A_3 = \emptyset.$ Express your answer in the form $2^a3^b5^c7^d$ with $a,b,c,d$ being nonnegative integers. My Proof: The first condition says that each integer between $1$ and $10$ inclusive appears in at least one of the three sets. The second condition states that no integer between $1$ and $10$ inclusive appears in all three of the sets at the same time. These conditions lead to six possible placements of each of the integer $1$ through $10.$ Namely $n \in A_1$ and $n \notin A_2$ and $n \notin A_3$ $n \notin A_1$ and $n \in A_2$ and $n \notin A_3$ $n \notin A_1$ and $n \notin A_2$ and $n \in A_3$ $n \in A_1$ and $n \in A_2$ and $n \notin A_3$ $n \in A_1$ and $n \notin A_2$ and $n \in A_3$ $n \notin A_1$ and $n \in A_2$ and $n \in A_3$ where the first three cases arise from n being in only one of the sets, the last three arise from n being in two, and n is any integer between $1$ and $10$ inclusive. We must choose one of these conditions for each integer $1$ through $10$ to make sure that each number appears in the union. This leads to $6^{10}$ possibilities. Writing this in the desired form, we get $2^{10}3^{10}5^07^0$ . I have tested different combinations and the results all seem to satisfy the conditions, but my concern is that this seems to be too simple, and I'm concerned that I'm missing something. Please let me know if I am, but with HINTS ONLY please. And if I am not missing anything, please let me know if this constitutes a rigorous proof, or if there is an alternate way to approach this problem. Thanks","['contest-math', 'combinatorics']"
3255851,"""Factoring Behavior"" of a cubic polynomial mod $p$","Given an irreducible polynomial $f(x)$ with integer coefficients, I want to characterize all the primes $p$ based on how $f(x)$ factors $\mod p$ . For quadratic polynomials, it follows directly from the Law of Quadratic Reciprocity. Specifically, if $f(x)$ has discriminant $D$ , then $f(x)$ splits completely $\mod p$ ( $p>2$ ) precisely when $D$ is a square $\mod p$ and remains irreducible otherwise. I want to generalize this as much as I can for the case where $f(x)$ is a cubic polynomial. Specifically, I want to determine for which primes, $f$ splits, remains irreducible, or factors as a product of a linear and quadratic polynomial. Any hints, full or partial solutions, or references to papers or textbooks with ideas that could help me would be greatly appreciated! Here's what I've done so far: Let $f(x)$ be an irreducible cubic polynomial with integer coefficients. Let $\alpha, \beta, \gamma$ be the roots and $D = (\alpha-\beta)^2(\beta-\gamma)^2(\alpha-\gamma)^2$ its discriminant. Let $p$ be a prime. For simplicity, I'm assuming $p>3$ and that $p \nmid D$ . Let $K/\mathbb{Q}$ be its splitting field and $G$ its Galois group. Let $K_p/\mathbb{F}_p$ be the splitting field of $f$ over the finite field with $p$ elements. Case 1: $D = d^2$ for some integer $d$ . In this case, $G$ is cyclic of order 3. This implies that $\beta$ and $\gamma$ can be written as polynomials in $\alpha$ , so we have either $f$ splits completely $\mod p$ , or $f$ remains irreducible. I'm conjecturing that $K \subset \mathbb{Q}(\zeta_d)$ ( $\zeta_d$ is a primitive $d$ -th root of unity) and from there I can obtain congruence conditions for which the polynomial splits. I imagine that this can be proven easily using Class Field Theory, but I'm still in the process of learning it. My main idea so far has been to use Gaussian periods corresponding to index 3 subgroups of $(\mathbb{Z}/d\mathbb{Z})^\times$ . It worked for all the explicit examples I've checked, but I have no idea how to prove it works in general. Case 2: $D$ is not a square. If $\left(\frac{D}{p}\right) = -1$ , then I'm able to show that $f$ has exactly one root in $\mathbb{F}_p$ as then $\mathbb{F}_p(\sqrt{D})$ is a quadratic subextension of $K_p$ , which implies $K_p$ is itself a quadratic extension. I have no idea how to show the converse statement or if it is even true. If $\left(\frac{D}{p}\right) = 1$ , things get a lot more complicated and this where I'm having the most trouble. In the case $f(x) = x^3 - 2$ , we have that $D = -3\cdot6^2$ . Thus, $$\left(\frac{D}{p}\right) = \left(\frac{-3\cdot6^2}{p}\right) = \left(\frac{-3}{p}\right) = 1 \iff p \equiv 1\mod 3.$$ In this case, I know that there exists integers $A,B$ such that $p = A^2 + 3B^2$ and that $f$ splits $\mod p$ iff $3 | B$ . These congruence conditions were derived from the Law of Cubic Reciprocity, which heavily relies on the Eisenstein integers and $p = A^2 + 3B^2$ being possible because the Eisenstein integers are a UFD. Back to the general case, my first guess has been to write $$kp = A^2 - DB^2$$ for some appropriate $k$ , and then hopefully be able to derive some congruence conditions for $A$ and $B$ . I imagine that this might involve deriving some kind of analogue for Cubic Reciprocity, but the ring of integers of $\mathbb{Q}(\sqrt{D})$ would replace the Eisenstein integers. My next idea (which might be more fruitful), is to use modular (or automorphic) forms. Admittedly, I don't know much about them, just a few basic facts like how they form a finite dimensional $\mathbb{C}$ -vector space etc. If I try this, my approach would be to first try to use modular forms (after learning more about them) to try solving the case $f(x) = x^3 - 2$ , replacing $x^2 + 3y^2$ with $$\theta = \sum_{i,j \in \mathbb{Z}} q^{x^2+3y^2}$$ and see if this sheds any light on the general problem. I've heard tidbits from people much smarter than me that makes me think this could maybe work out, but I'm mostly in the dark here. If you have any input on what would be the best approach, or if you're thinking, ""From what you've written, it doesn't seem like you know enough math. You should probably know X,Y, and Z before you can even hope to solve this,"" let me know!
I'd be glad to hear any solution, even if it goes way over my head! I've been trying to solve this problem for over a year now, and I feel as if I've made no significant progress. It's VERY disheartening.","['number-theory', 'abstract-algebra']"
3255853,Determine the probability,"Joe, who owns a grocery store, has ordered tins of chickpeas and lentils. When unpacking the tins, he finds that one box contains 10 tins that have lost their labels. The tins are identical but after looking through his invoices, he has determined that 7 of the tins contain chickpeas and 3 contain lentils. Joe decides to take them home since he is unable to sell them without a label. He will open one tin each day and use whatever it contains. Determine the probability that he opens at least one tin of each over the next 3 nights.",['probability']
3255917,Summation Involving Product Of Two Identical Polynomials.,"Recently I stuck, to a problem. However I rarely think that there is some proper formula for this problem, but here I am in search of algorithm's or theorem that relate to this problem or can solve this problem. We have three integers  positive integers $a, b, n$ and we need to compute this summation: $$\sum\limits_{k = 1}^n{(k^a - {(k - 1)}^a)(k^b - {(k - 1)}^b)}$$ It looks simple, if we try to solve it using computer, but real problem lies in it's constraints: $$n < 10^{12}$$ $$a < 10^4$$ $$b < 10^4$$ Clearly, we cannot iterate from $k = 1$ to $k = n$ , thus we need to think of an algorithm that solve it in constant time
or in complexity in terms of $a$ and $b$ One can easily find relation like this $\sum\limits_{k = 1}^n{(k^a - {(k - 1)}^a)} = n^a$ but the problem has product of two such terms. So, Please give me some suggestion to solve this problem.","['summation-method', 'calculus', 'combinatorics', 'algorithms', 'sequences-and-series']"
3256007,"ODE: $\dot{x}=f(t)x^2,x(0)=1$ solution on $\mathbb{R}\Leftrightarrow\int_{0}^{t}f(s)ds<1\forall t\in\mathbb{R}$","Let $f:\mathbb{R}\rightarrow\mathbb{R}$ a continuous function and $\phi$ a solution on its maximal interval of existence for the initial value problem $$
\dot{x}=f(t)x^2\hspace{0.3cm},\hspace{0.3cm}x(0)=1
$$ Show that the solution exists on $\mathbb{R}$ iff $$
\int_{0}^{t}f(s)ds<1\hspace{0.3cm}\forall t\in\mathbb{R}
$$ So what I think would be the right way to start is to note that $\dfrac{\dot{x}}{x^2}=-\dfrac{d}{dt}\dfrac{1}{x}$ however that only works when $x\neq 0$ so I'm not quite sure about how to proceed.","['proof-writing', 'ordinary-differential-equations', 'real-analysis']"
3256024,What is a mathematical solution to this problem? (Project Euler #106),"I've already asked this question before, but then I realized that wording was, unfortunately, quite confusing. The statement of the problem is following: Let $S(A)$ represent the sum of elements in set A of size n. We shall call it a special sum set if for any two non-empty disjoint subsets, $B$ and $C$ , the following properties are true: $1.$ $S(B) ≠ S(C$ ); that is, sums of subsets cannot be equal. $2.$ If B contains more elements than $C$ then $S(B) > S(C)$ . For this problem we shall assume that a given set contains n strictly increasing elements and it already satisfies the second rule. Surprisingly, out of the 25 possible subset pairs that can be obtained from a set for which $n = 4$ , only 1 of these pairs need to be tested for equality (first rule). Similarly, when $n = 7$ , only 70 out of the $966$ subset pairs need to be tested. For $n = 12$ , how many of the $261625$ subset pairs that can be obtained need to be tested for equality? Problem statement specifies that, if size of subset $B$ doesn't equal to the size of the subset $C$ , then theirs sums will not be equal by default. So when testing set $A$ for the equality, we only consider subsets with the same size. The main question is, for arbitrary set $A$ with size $n$ which satisfies conditions specified in the problem, how many pairs of subsets with the same size are needed to be tested?
I couldn't have come up with purely mathematical solution myself, so I checked answers provided by the users in the discussion thread.
A lot of them mentioned so called ""grid method"", for example, one of the posts: First, some observations. If elements of the set are assigned in ascending order to subset $B$ , subset $C$ , or discarded, and every element of $B$ can be paired with an element of $C$ that was selected later, then B's sum will be smaller than $C$ 's, and the comparison will not be necessary. If you imagine a walk on a grid from upper left to lower right, where selecting an element for subset $B$ is like walking East, and selecting an element for subset $C$ is like walking South, and selecting an element for neither subset is effectively the same as selecting it for both (East, then South), then a walk that crosses the diagonal from north to south (with this direction being the first diagonal crossing) corresponds exactly to a subset pair that must be compared. And one more Clearly we only need to test equal size groups $(k)$ . If we select $2k$ elements, we only need to test some partition of that into $2k$ -size groups if there is an $m$ -smallest number in the group with the smallest element that is bigger than the $m$ -smallest number in the other group. This can be modeled as a path across a $k×k$ grid that crosses the diagonal , so we can use Catalan numbers $C_k$ (which count paths that don't cross the diagonal) and half the total number of paths across the grid to get the number of diagonal-crossing paths (half = given start direction).Then the selection of the initial $2k$ set is a binomial coefficient, and sum across values of $k$ . Can some explain what is this ""grid"" they are referring to? And how do you solve the problem using this method?","['combinations', 'combinatorics']"
3256153,"Prob. 16 (c), Sec. 6.2, in Bartle & Sherbert's INTRO TO REAL ANALYSIS, 4th ed: If $f^\prime(x)\to b$ as $x \to \infty$, then $f(x)/x \to b$. How?","Here is Prob. 16, Sec. 6.1, in the book Introduction To Real Analysis by Robert G. Bartle & Donald R. Sherbert, 4th edition: Let $f \colon [0, \infty) \to \mathbb{R}$ be differentiable on $(0, \infty)$ and assume that $f^\prime(x) \to b$ as $x \to \infty$ . (a) Show that for any $h > 0$ , we have $\lim_{x \to \infty} \big( f(x+h) - f(x) \big)/h = b$ . (b) Show that if $f(x) \to a $ as $x \to \infty$ , then $b = 0$ . (c) Show that $\lim_{x \to \infty} \big( f(x)/x \big) = b$ . Here is Definition 4.3.10 in Bartle & Sherbert, 4th edition: Let $A \subseteq \mathbb{R}$ and let $f \colon A \to \mathbb{R}$ . Suppose that $(a, \infty) \subseteq A$ for some $a \in \mathbb{R}$ . We say that $L \in \mathbb{R}$ is a limit of $f$ as $x \to \infty$ , and write $$ \lim_{x \to \infty} f = L \qquad \mbox{ or } \qquad \lim_{x \to \infty} f(x) = L, $$ if given any $\varepsilon > 0$ there exists $K = K(\varepsilon) > a$ such that for any $x > K$ , then $\lvert f(x) - L \rvert < \varepsilon$ . I think I'm clear on Parts (a) and (b). How to do Part (c)? Here is my attempt at Part (c): As $f^\prime$ is defined for all $x$ in $(0, \infty)$ and as $f^\prime(x) \to b$ as $x \to \infty$ , so given any $\varepsilon > 0$ we can find a $K \colon= K(\varepsilon/3) > 0$ such that for any $x > K$ , we have $$ \left\lvert f^\prime(x) - b \right\rvert < \frac{\varepsilon}{3}. \tag{0}$$ In particular, for $\varepsilon = 1$ , there exists a real number $K_0 \colon= K(1) > 0$ such that for any $x > K_0$ , we have $$ \left\lvert f^\prime(x) - b \right\rvert < 1.$$ So for any $x > K_0$ , we also have $$ \left\lvert f^\prime(x) \right\rvert \leq \left\lvert f^\prime(x) - b \right\rvert + \lvert b \rvert < 1 + \lvert b \rvert, $$ and thus $$ \left\lvert f^\prime(x) \right\rvert < 1 + \lvert b \rvert \tag{1} $$ for any real number $x > K_0$ . Now let $M$ be any real number such that $$ M > \max \left\{ \ K, K_0  \ \right\}. \tag{2}$$ Let us take $x$ to be any real number such that $$x >  \max\left\{ \ M, \frac{3 \big( \lvert f(M) \rvert + 1 \big) }{\varepsilon }, \frac{3 M \big( \lvert b \rvert + 1 \big)}{  \varepsilon } \ \right\}. \tag{3}. $$ Then as $f$ is continuous on the closed interval $[ M, x]$ and differentiable on the open interval $( M, x)$ , so there exists a real number $c_x \in (M, x)$ such that $$ f(x) - f(M) = (x-M) f^\prime \left( c_x \right),  $$ and then $$ f(x) = f(M) + (x-M) f^\prime \left( c_x \right),  $$ which implies that $$
\begin{align}
& \ \ \  \left\lvert \frac{f(x)}{x} - b \right\rvert \\ 
&=  \left\lvert \frac{ f(M) + (x-M) f^\prime \left( c_x \right) }{x} - b \right\rvert \\
&= \left\lvert f^\prime \left( c_x \right) - b + \frac{f(M)}{x} - \frac{M f^\prime\left(c_x\right)}{x} \right\rvert \\
&\leq \left\lvert f^\prime \left( c_x \right) - b \right\rvert +  \frac{ \left\lvert f(M) \right\rvert }{x}  + \frac{ M \left\lvert f^\prime\left(c_x\right) \right\rvert }{x} \\
& \ \ \ \mbox{ [ Note that our choice of $K$, $K_0$, and $M$ in (0), (1), and (2) above, respectively, implies that $x > 0$ also. ] } \\
&< \frac{\varepsilon}{3} + \frac{ \left\lvert f(M) \right\rvert }{x}  + \frac{M}{x} \left( \lvert b \rvert + 1 \right) \\ 
& \ \ \  \mbox{ [ using (2), and then (0) and (1) above ] } \\ 
& < \frac{\varepsilon}{3} + \frac{\lvert f(M)\rvert \varepsilon}{3 \big( \lvert f(M) \rvert + 1 \big) } + \frac{\varepsilon}{3 \left( \lvert b \rvert + 1 \right) } \left( \lvert b \rvert + 1 \right) \\
& \qquad \qquad \mbox{ [ using (3) above ] }\\
&\leq \frac{\varepsilon}{3} + \frac{ \varepsilon }{ 3 } + \frac{\varepsilon }{3} \\
&= \varepsilon.
\end{align}
$$ Let us put $$ M^* \colon= \max\left\{ \ M, \frac{3 \big( \lvert f(M) \rvert + 1 \big) }{\varepsilon }, \frac{3 M \big( \lvert b \rvert + 1 \big)}{  \varepsilon } \ \right\}. \tag{4}. $$ Thus we have shown that, for any given real number $\varepsilon > 0$ , there exists a real number $M^* > 0$ such that $$ \left\lvert \frac{f(x)}{x} - b \right\rvert < \varepsilon $$ for every real number $x > M^*$ . Therefore $$ \lim_{x \to \infty} \frac{f(x)}{x} = b, $$ as required. Is this proof correct? If so, is it rigorous and clear enough too? Or, are there any problems in it?","['analysis', 'real-analysis', 'solution-verification', 'limits', 'derivatives']"
3256166,Geodesics on the helicoid,"The problem is as follows: Suppose that a geodesic $\alpha$ is intersecting a ruling of the
  helicoid S given by $$x(u,v) = (u \cos(v),u \sin(v), v) $$ at a point $p$ .
  The angle at $p$ between the ruling and $\alpha$ is $\theta \in (0,
 \pi/2)$ . Furthermore, $p$ does not lie on the z axis and we call the
  relative distance $\delta > 0$ . (a) Show that $\delta > \cot(\theta)$ (b) Show that if $\delta < \cot(\theta)$ , then $\delta$ does not
  intersect the $z$ -axis (c) Find the geodesics for $\delta = \cot(\theta )$ I'm struggling with figuring out how to start on this. I don't understand how can I express the angle $\theta$ and the distance $\delta$ . If you could help me explain that, I think I would be able to continue on my own. Any help appreciated! P.S.: This question is slightly connected to Geodesics of Helicoid , the results obtained there might be useful in this problem as well.","['surfaces', 'geodesic', 'geometry', 'differential-geometry']"
3256229,Integral $\int_0^\infty\frac{\exp(i\alpha\cos u)-J_0(\alpha)}{1+\beta u}\mathrm{d}u$,"I was studying the motion of a particle in a certain magnetic field and one of the quantities that arose was given by the titular integral $$
F(\alpha,\beta)=\int_0^\infty\frac{\exp(i\alpha\cos u)-J_0(\alpha)}{1+\beta u}\mathrm{d}u
$$ Here $\alpha\in\mathbb{R}$ , $\beta>0$ and $J_0$ is a Bessel function. The integral does exist. I found the following theorem in a book on real analysis: Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be continuous on $[a,b]$ while $g:\mathbb{R}\rightarrow\mathbb{R}$ is nonnegative, decreasing and continuously differentiable on $[a,b]$ . Then $\exists\xi\in[a,b]$ : $$
\int_a^bf(x)g(x)\mathrm{d}x=g(a)\int_a^\xi f(x)\mathrm{d}x
$$ Taking into account the fact that $\exp(i\alpha\cos u)-J_0(\alpha)$ is periodic with period $2\pi$ and that its integral over one period is $0$ , we can apply the above theorem seperately to the real and imaginary parts of the original integral to find that for all $a,b>0$ : $$
\left\vert\int_a^b\frac{\exp(i\alpha\cos u)-J_0(\alpha)}{1+\beta u}\mathrm{d}u\right\vert<\frac{6\pi}{1+\beta a}
$$ This implies convergence. However, I can't find any way to express $F$ in terms of other functions, be it ordinary or special. This wouldn't be too much of a problem if the  integrand weren't oscillatory, making numerical evaluation difficult. Therefore, my question is twofold: is there a closed form for $F$ , perhaps in terms of special functions, if not, are there at least any efficient methods for numerical computation of $F$ ?","['integration', 'definite-integrals', 'special-functions', 'analysis', 'numerical-methods']"
3256241,Prove that $\sum_{n=1}^{\infty}\log \cos \left (\frac{1}{n}\right )$ converges absolutely.,Prove that $$\sum_{n=1}^{\infty}\log \cos \left (\frac{1}{n}\right )$$ converges absolutely. The answer here suggests to use the Limit Comparison Test but it works for $a_n \geq 0$ while $\ln(\cos (1/n))<0$ . Also the limit given in the answer is $-\frac{1}{2}$ while the test gives results for positive limit values only. That post is $6$ years old so I didn't leave this as a comment.,"['limits', 'trigonometry', 'summation', 'sequences-and-series']"
3256243,"Relation between total variation and KS distance between measures on $[0,1]^d$","Let $P$ and $Q$ be two probability measures on the space $[0,1]^d$ , $d \in \{1, 2, \ldots \}$ , endowed with the $L_\infty$ norm and the corresponding Borel $\sigma$ -field, $\mathcal{B}$ . Let $$F_P(\mathbf{u})=P([\mathbf{0},\mathbf{u}]), \, \quad F_Q(\mathbf{u})=Q([\mathbf{0},\mathbf{u}]),$$ denote the distribution functions associated to $P$ and $Q$ , respectively. Then, we have that $$
d_{KS}(F_P,F_Q):=\sup_{\mathbf{u}\in[0,1]^d}
|F_P(\mathbf{u})-F_Q(\mathbf{u})| \leq \sup_{B \in \mathcal{B}}|P(B)-Q(B)|=:d_{TV}(P,Q).
$$ My question is the following: assume $F_P$ and $F_Q$ are Lipschitz continuous, then does (some form of) converse inequality also hold true? I was reasoning in this way: since $P$ and $Q$ are regular, for every $B \in \mathcal{B}$ and $\epsilon>0$ there exist closed sets $C_{B,\epsilon}^{(P)},C_{B,\epsilon}^{(Q)}$ and open sets $O_{B,\epsilon}^{(P)},O_{B,\epsilon}^{(Q)}$ such that $O_{B,\epsilon}^{(\bullet)} \subset B \subset C_{B,\epsilon}^{(\bullet)}$ and $$
P(C_{B,\epsilon}^{(P)}\setminus O_{B,\epsilon}^{(P)})\leq \epsilon, \quad
Q(C_{B,\epsilon}^{(Q)}\setminus O_{B,\epsilon}^{(Q)})\leq \epsilon.
$$ Whence, $
|P(B)-Q(B)| \leq 2 \epsilon + |P(O_{B,\epsilon}^{(P)})-Q(O_{B,\epsilon}^{(Q)})|.
$ Yet, from now on it is not clear how to proceed. Maybe cover
each open set with uniform metric-balls $\{B_1^\bullet,\ldots,B_{m_\bullet}^\bullet\}$ of radius $\delta$ ? Herein , we could maybe exploit the covering number inequality $m_\bullet \leq (3d/\delta)^d$ . Observe that each ball is of the form $$
B_i^\bullet=\times_{j=1}^d(u_{i,j}^\bullet-\delta,u_{i,j}^\bullet+\delta),
$$ where $\mathbf{u}_i^\bullet=(u_{i,1}^\bullet, \ldots, u_{i,d}^\bullet) \in [0,1]^d.
$ In particular, by absolute continuity, we could choose $\delta$ such that $$
|F_P(\mathbf{u}_i^Q+\delta \mathbf{1})-F_Q(\mathbf{u}_i^Q-\delta \mathbf{1})|\leq \epsilon',
\quad |F_Q(\mathbf{u}_i^P+\delta \mathbf{1})-F_P(\mathbf{u}_i^P-\delta \mathbf{1})|\leq \epsilon'
$$ for some arbitrarily small $\epsilon'>0$ . But still it is not evident to me that this could lead to a suitable upperbound encompassing $d_{KS}(F_p,F_Q)$ . Do you have any clue?","['probability-distributions', 'metric-spaces', 'real-analysis', 'total-variation', 'probability']"
3256244,Measure upon which pointwise convergence of averaging operator fails in $L^1$,"If $\mu$ is a doubling Radon measure on $\mathbf{R}^n$ , it is well known that for any locally integrable function $f$ , the values $$ (A_\delta f)(x) = \frac{1}{\mu(B(x,\delta))} \int_{B(x,\delta)} f(t) d\mu(t)  $$ converges pointwise $\mu$ almost everywhere to $f(x)$ . Are there any simple examples of non doubling absolutely continuous measures $\mu$ where this phenomenon fails to occur?","['harmonic-analysis', 'measure-theory', 'geometric-measure-theory']"
3256268,"Calculate $\iiint_\omega (x+y+z)^2\,dxdydz$.","Problem : Calculate $$\displaystyle\iiint_\Omega (x+y+z)^2\,dxdydz,$$ where $\Omega$ is the domain bounded by the sphere $x^2+y^2+z^2\le 3a^2$ and the paraboloid $x^2+y^2\le 2az$ , where $z\ge 0$ . Progress : So, by sketching the domain, one can see that the domain includes a part from sphere and a part from the paraboloid, so we need to calculate the integral on two seperate part, then add the to get the result. To calculate the integral in the sphere part, I've tried using spherical coordinate. Using spherical coordinate, I made the following substitution: $$\begin{cases} x = r\sin\theta\cos\varphi\\ y = r\sin\theta\sin\varphi\\ z = r\cos\theta \end{cases}$$ with $0\le \varphi\le 2\pi$ , $0\le\theta\le\alpha$ , where $\alpha =\arccos\left(\dfrac{1}{\sqrt{3}}\right)$ (one can get the bound for angle $\theta$ by working out the intersection of the paraboloid and the sphere) and $\dfrac{a}{\cos\theta}\le r\le\dfrac{a\sqrt 2}{\sin\theta}$ . Now, the expression $(x+y+z)^2$ become $$r^2(1+\sin^2\theta\sin 2\varphi + \sin 2\theta+\sin\varphi+\sin 2\theta\cos\varphi).$$ Now, we multiply the Jacobian determinant and the original integral become $$\int^{2\pi}_0d\varphi\int^\alpha_0d\theta\int^\tfrac{a\sqrt 2}{\sin\theta}_\tfrac{a}{\cos\theta}r^4\sin^2\theta(1+\sin^2\theta\sin 2\varphi + \sin 2\theta+\sin\varphi+\sin 2\theta\cos\varphi)dr.$$ As you can see, this one is tedious and almost impossible to calculate it. Do you have any idea to solve this problem?","['integration', 'multivariable-calculus', 'calculus', 'multiple-integral']"
3256272,Laurent series for $ f(z) = \frac{1} {(z-1)(z-2)} $ around $ z_{0} =0$ and $|z| <1$.,Find the Laurent series for $ f(z) = \frac{1} {(z-1)(z-2)} $ around $ z_{0} =0$ and $|z| <1$ . I tried by writing $\frac{1} {(z-1)(z-2)}$ as $ \frac{1} {z-2} - \frac{1} {z-1} $ but how do I find the laurent series for $ \frac{1} {z-2}$ where $|z|<1$ ? I can only find it for $|z|<2$ .,['complex-analysis']
3256326,"If something is not false, is it true?","For proving vacuous truths for empty sets, Halmos in his Naive Set Theory mentions that To prove that something is true about the empty set, prove that it cannot be false. But now consider Russell's paradox where $A$ is the set of all sets not contained in it. $A \notin A$ being false there doesn't imply that $A\in A$ . So how does Halmos' method work?","['elementary-set-theory', 'logic']"
3256333,The distribution of $X_i-X_{(1)}$,"If $X_1,...,X_n$ be a random sample from $Exp(1)$ and $X_{(1)}$ is the smallest exponential order statistic, how can I get the distribution of $X_i-X_{(1)}$ ?","['exponential-distribution', 'statistics', 'probability-theory', 'order-statistics']"
3256355,Cohomology of toric Calabi-Yau manifolds in $d=4$,"Let $X$ be a toric Calabi-Yau manifold, of complex dimension $d=4$ .
What do we know about its cohomology?
In particular, if we know $H^{1,1}(X)$ (say we know its dimension and pick a basis), can we say something about $H^{2,2}(X)$ and $H^{3,3}(X)$ ? Clarification: let $\mathbb C^{N+4}$ with coordinates $z_a$ , and $U(1)^N$ action $z_a \to e^{\sqrt{-1} \alpha_i Q^i_a} z_a$ for some matrix of integers $Q$ satisfying $\sum_{a=1}^{N+4} Q^i_a = 0$ for all $i=1,\ldots,N$ ,
and moment maps $$ \mu_i = \sum_a Q^i_a |z_a|^2 - r_i : \mathbb C^{N+4} \to \mathbb R$$ for real numbers $r_i$ .
Then $X= \mu^{-1}(r) / U(1)^N$ .","['symplectic-geometry', 'complex-geometry', 'algebraic-geometry', 'homology-cohomology', 'differential-geometry']"
3256465,Solve $x^2y^2 - 4x^2y + y^3 + 4x^2 - 3y^2 + 1 = 0$ over the integers.,"Solve $$x^2y^2 - 4x^2y + y^3 + 4x^2 - 3y^2 + 1 = 0$$ over the integers. You can probably guess by now... This problem is adapted from a recent competition. If there are any other solutions, please post them below. I have provided one if you want to check out.","['divisibility', 'elementary-number-theory', 'diophantine-equations', 'polynomials', 'discrete-mathematics']"
3256487,Prove that a kernel operator has no eigenvalues,"Good evening! I'm just popping here for a quick question. I'm just starting to work on kernel operators, from $L^2(\mathbb{R}_+)$ to itself, ie: $f \mapsto \left(x \mapsto \displaystyle\int_{\mathbb{R}_+} K(x,y)f(y)dy\right)$ , with $K$ a function from $\mathbb{R}^2$ to $\mathbb{R}$ . In the case where $K$ can be written as a finite sum of functions of $x$ and $y$ (ie $K(x,y) = \displaystyle\sum\limits_{i} u_i(x)v_i(y)$ , with $u_i$ and $v_i$ real functions), it is fairly easy to find eigenvalues and eigenfunctions (or prove there are none). But what if $K$ cannot be written as such? For example, I'm faced with the case $K(x,y) = \dfrac{1}{x+y}$ . What to do then? I know this operator has no eigenfunctions, but I'm trying to prove it. I've been looking for solutions in books on the subject, mostly A Hilbert space problem book by Paul Helmos, but the closest I could find to it was the proof that a Volterra operator had no eigenfunctions. So if anyone would have any idea where I could find resources on how to prove that.. maybe a book, or an article. I'd be grateful :) Thanks, have a nice day.","['operator-theory', 'spectral-theory', 'functional-analysis']"
