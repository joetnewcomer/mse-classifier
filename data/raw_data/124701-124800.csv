question_id,title,body,tags
1886666,Why Fibonacci-Jacobsthal sequences divert into positive and negative values in the complex plane?,"The Fibonacci numbers closed-form expression is as follows: $$F_n = \frac{\varphi^n-(1-\varphi)^n}{\sqrt{5}}$$ where $\varphi = \frac{1+\sqrt{5}}{2}$ is the golden ratio . I wanted to review what happens when instead of $\sqrt{5}$ another root is used, in a kind of generalization of the Fibonacci numbers , so I have defined the following generic expression ($E1$): $$F_n = \frac{\varphi^n-(1-\varphi)^n}{\sqrt{r}}$$ where $\varphi = \frac{1+\sqrt{r}}{2}$ is a manipulated ""golden ratio-equivalent"". So what happens when we use instead of $\sqrt{5}$ another positive root, $\sqrt{r}$? Basically the observation is that when $r = 1+4k, k \in \Bbb N$ (including $k=0$), the elements of the Fibonacci sequences are always integers following the definition. $$F_n = F_{n-2} \cdot k + F_{n-1}$$ being the starting elements $F_0 = 0, F_1=1$ If $r \not =1+4k$, for instance $r=6$, then when using $\sqrt{6}$ at expression ($E1$) the elements of the Fibonacci sequence are not integers. When $k=0$ the Fibonacci sequence is $\{0,1,1,1,1,1...\}$. Always $1$ except $F_0=0$. When $k=1$ so $r=1+4 \cdot 1=5$, then we are using $\sqrt{5}$, providing the classic Fibonacci sequence $\{0,1,1,2,3,5...\}$.: $$F_n = F_{n-2} \cdot (k) + F_{n-1} = F_{n-2} \cdot (1) + F_{n-1} = F_{n-2} + F_{n-1}$$ When $k=2$, to my suprise, we obtain the Jacobsthal sequence : $$F_n = F_{n-2} \cdot (k) + F_{n-1} = F_{n-2} \cdot 2 + F_{n-1}$$ So it seems that the manipulation of the root at expression ($E1$) provides a generalization of the Jacobsthal sequence as follows: $$F_n = F_{n-2} \cdot (k) + F_{n-1}$$ The interesting point (and the questions at the end are related to this) is: What happens if instead of using positive roots to obtain generic Fibonacci-Jacobsthal sequences, we use negative roots? By defining the expression of $r$ as follows: $$r = 1-4k, k>0  \in \Bbb N$$ The result is quite interesting. The expression ($E1$) turns into this: $$F_n = \frac{\varphi^n-(1-\varphi)^n}{(\sqrt{\mid r \mid})i}$$ Where $\varphi = \frac{1+(\sqrt{\mid r \mid})i}{2}$ is the golden ratio-equivalent for the complex plane. The observation in this case is that $F_n$ diverts into positive and negative values (thus, $\Bbb Z$), so the Fibonacci-Jacobsthal sequences are not pure increasing positive sequences when the root applied to ($E1$) is negative, but diverting sequences containing positive and negative numbers. The following image shows both the behavior of positive roots (classic Fibonnaci-Jacobsthal) and negative roots applied into ($E1$) as explained above. The graph represents in the positive $x$ axis the Fibonacci sequences generated for a positive $\sqrt{x}$ root, showing the first $100$ elements of each sequence in the $y$ axis. For instance at $x=0.5$ , the shown $y$ points are the first $100$ elements of the Fibonacci sequence obtained for $\sqrt{0.5}$ applied to ($E1$). As you can see $x=1$ is an special case because for that case $\forall n \gt 1 \in \Bbb N, F_n=1$, except $F_0=0$. That is the reason why all the points seem to ""converge"" to $x=1, y=1$. The classic Fibonacci sequence is located at $x=5$ which is the use of the root $\sqrt{5}$ at ($E1$). It is out of 
the scale of the graph at the right side in the positive $x$ axis. But in the other hand, when we use negative roots ($x \lt 0$), so we use $\sqrt{x} = \sqrt{\mid x \mid \cdot (-1)} =  (\sqrt{\mid x \mid }) \cdot \sqrt{(-1)} =(\sqrt{ \mid x \mid })i$ applied to ($E1$), then the Fibonacci-Jacobsthal sequences obtained divert into positive and negative values. In the graph, the $x$ values under $x \lt 0$ represent the negative roots $(\sqrt{\mid x \mid })i$ applied into ($E1$) and the $y$ values are the Fibonacci sequences obtained for each value of $x$. It can be seen the the sequences are not strictly positive increasing sequences: they have negative and positive (complex) terms. There is a very interesting value in the complex plane, when $k=1, r = 1-4k = -3$, this is represented in the graph at $x=-3$, which shows the use of the root $(\sqrt{\mid -3 \mid })i$ into ($E1$). As it can be seen, again the sequences seem to ""converge"", but in this case into three points: $y=1$,$y=0$,and $y=-1$. The sequences associated with the values $x \lt -3$ start to grow up quickly, so the scale does not let to see us a whole view of the evolution of the sequences. Below there is a graph showing what happens after $x=-3$ in a short interval: This is the Python code to make the graphs, please use it freely as you wish: def fcgrm():
    from math import sqrt
    import matplotlib.pyplot as plt
    import matplotlib as mpl
    from numpy import real, imag, arange, float

    # Plotting setup
    arraydim = 4000000
    xrange = arange(arraydim,dtype=float)       
    yrange = arange(arraydim,dtype=float)       
    ax = plt.gca()
    ax.set_axis_bgcolor((0, 0, 0))
    figure = plt.gcf()
    figure.set_size_inches(18, 16)

    complexi = 0+1j
    test_limit = 100
    pos=0

    for SQRTSEL in range(-30000,-0):
        if SQRTSEL == 0:
            continue
        if SQRTSEL<0:
            GRM = (1+((sqrt((SQRTSEL*(-1))/10000))*complexi))/2
        else:
            GRM = (1+(sqrt(SQRTSEL/10000)))/2

        for n in range(0,test_limit):
            if SQRTSEL<0:
                new_i_val = (((GRM)**n)-((1-GRM)**n))/sqrt((SQRTSEL*(-1))/10000)
            else:
                new_i_val = (((GRM)**n)-((1-GRM)**n))/sqrt(SQRTSEL/10000)

            varx = new_i_val.real
            vary = new_i_val.imag

            if SQRTSEL<0:
                varx = SQRTSEL/10000
                xrange[pos]=varx
                yrange[pos]=vary
            else:
                vary = SQRTSEL/10000
                xrange[pos]=vary
                yrange[pos]=varx

            pos = pos + 1

            if pos==arraydim:
                newxrange = arange(pos,dtype=float)     
                newyrange = arange(pos,dtype=float)     
                for i in range(0,pos):
                    newxrange[i]=xrange[i]
                    newyrange[i]=yrange[i]
                plt.plot(newxrange,newyrange,""w,"")
                pos=0           

    newxrange = arange(pos,dtype=float)
    newyrange = arange(pos,dtype=float)     
    for i in range(0,pos):
        newxrange[i]=xrange[i]
        newyrange[i]=yrange[i]
    plt.plot(newxrange,newyrange,""w,"")
    xrange = arange(arraydim)       
    yrange = arange(arraydim)

    pos=0   
    order = 1           

    plt.show()

fcgrm() I would like to ask the following questions: Are my calculations correct regarding the behavior of ($E1$) or did I miss something? Why are the sequences diverting into positive and negative values? Heuristically I can understand that it really happens, but not the reason. The Fibonacci series according to the manipulations of ($E1$) divert into positive and negative values. But what is the mechanism that makes this happen in the complex plane? Is it due to the complex division applied into ($E1$)? I think that the equivalent to what is happening in the real plane at $x=1$ is happening in the complex plane at $x=-3$. If we see the graph of the Fibonacci sequences as a whole, as in the first graph shown above, they have a ""mirrored"" behavior, meaning that the sequences seem to ""converge"" to some specific points of the positive and negative $x$ axis, and then the sequences start to grow up quickly after that point when $x \to -\infty$ and $x \to \infty$ respectively, and it seems that there is continuity between the elements of each sequence, except at $x=0$ where $E1 \to \infty$. Are the points $(1,1)$, $(-3,-1)$, $(-3,0)$ and $(-3,1)$ some kind of attractor? Thank you!","['fibonacci-numbers', 'sequences-and-series', 'complex-numbers']"
1886693,Expected position of a random walk with a biased coin directly after two consecutive heads are observed,"Suppose a coin is tossed repeatedly and independently, and the probability of observing a heads on any toss is 0.6. Now suppose that a one-dimensional simple random walk $\{\sigma_1,\sigma_2,\cdots\}$ is designed based on the coin tossing. For $i=1,2,\cdots,$ a coin is tossed and $$ 
\sigma_i = 
\left\{
\begin{array}{ll}
      1, & \text{if a head is observed} \\
      -1, & \text{if a tails is observed} \\
\end{array} 
\right. 
$$ The random walk starts at the origin. Compute the expected position of the random walk when a string of 2 consecutive heads is observed for the first time. That is compute $$ E\left(\sum_{i=1}^T \sigma_i\right) $$ where $\{T=i \in \mathbb{N}: \text{A string of 2 consecutive heads is observed for the first time after toss i}\} $. So I figured I should first compute T, the expected number of flips to get two consecutive heads. Basically, I did this by conditioning as shown below: $$E(T) = (1+E(T))\frac{2}{5}+(2+E(T)\frac{3}{5}\frac{2}{5}+2\frac{3}{5}\frac{3}{5}$$ Solving for E(T) I then get E(T) = $\frac{40}{9}$. Thus, I'm assuming when I calculate $ E\left(\sum_{i=1}^T \sigma_i\right) $, have T=5 since it is the next natural number. Now even with this assumption I am stuck on what to do next. I guess I could just brute force it by writing out the terms of the sum from the standard expectation formula, but I think there might be an easier way. Any insight would be appreciated.","['stochastic-processes', 'probability-theory', 'markov-chains', 'stopping-times', 'probability']"
1886713,Finding P(X<Y) of 2 random variables that are gamma distributed,"X ~ Gamma ($r_1$ = 3, $\lambda_1$ = 2) Y ~ Gamma ($r_2$ = 5, $\lambda_2$ = 7) Find P( X > Y ) To find this, I know that I can double integrate the joint distribution of X and Y but I wanted to know a more intuitive approach to this problem. I was suggested to think of this probability as a binomial distribution where T ~ Bin( n = $r_1$ + $r_2$ - 1 = 7, p = $\left(\frac{\lambda_2}{\lambda_1 + \lambda_2}\right)$) I would like to have this explained please.","['gamma-distribution', 'statistics', 'random-variables']"
1886718,Dif. Eq. General solution is sum of homogeneous and particular solutions,Why is the general solution to ordinary first order differential equations a sum of homogeneous(Setting the inhomogeneous term to 0) and particular(satisfies the differential equation but not necessarily the initial conditions) solutions? $x=x_{h}+x_{p}$ I have tried finding a proof on the Internet but without a result. Can someone give me a not too complicated mathematical proof(If possible) to why this relation is valid? Thank you!,['ordinary-differential-equations']
1886775,Solve the equation $\tan(2x) = 1+\tan(x)$,"I am trying to solve the equation $$\tan(2x) = 1+\tan(x).$$ I have tried putting $u = tan(x),$ and $tan(2x) = \frac{2u}{1-u^2}$ so that $-u^3 + u^2 + 3u = 1,$ but I can't find any roots that would help me. I have also tried using all the trigonometric identities I could think of but that hasn't helped me either, so I have a feeling that I should ""see"" something that I am failing to see. Any advice? Edit: I should find all real solutions.",['trigonometry']
1886801,Show that the one point compactification of $\mathbb{Q}$ is not Hausdorff,"https://en.wikipedia.org/wiki/Alexandroff_extension Definition: one point compactification Let $X$ be any topological space, and let   $ \infty$  be any object
  which is not already an element of $X$. Put $ X^{*}=X\cup \{\infty
 \}$, and topologize $X^*    $ by taking as open sets all the open
  subsets $U$ of $X$ together with all subsets $V$ which contain $\infty
 $  and such that $X\setminus V$ is closed and compact Show that the one point compactification of $\mathbb{Q}$ which is $\mathbb{Q}^*$ is Not Hausdorff. What to do? What... My Attempt: Suppose to the contrary $\mathbb{Q}^*$ is Hausdorff, then we take two points $x$, $\infty \in \mathbb{Q}^*$, $x \neq \infty$, and produce disjoint open sets $U,V$ such that $x \in U$ and $\infty \in V$ By definition, we know that $\mathbb{Q} \backslash V$ is a closed and compact space such that $x \in U \subseteq \mathbb{Q} \backslash V$ We wish to produce a contradiction such that $\mathbb{Q} \backslash V$ is not closed, or not compact. But we know that $\mathbb{Q} \backslash V$ has to be closed since $V$ is open, therefore we need to show $\mathbb{Q} \backslash V$ is not compact. Let $\mathcal{U}$ be an open cover of $\mathbb{Q} \backslash V$. Since  $\mathbb{Q} \backslash V$ is claimed to be compact, then $\mathcal{U}$ has a finite subcover $\{U_i|i \in F\}$, $F$ is finite in  $\mathbb{Q} \backslash V$. Then for all $x \in \mathbb{Q}\backslash V$, $\exists i \in F$ s.t. $x \in U_i$ (...Ugh everything seems fine...) Can someone provide me with some help as to how to go on with this proof? Thanks a bunch.","['compactification', 'proof-verification', 'proof-writing', 'compactness', 'general-topology']"
1886830,Show that $\mathbb{Q}$ is not locally compact with a characterization of local compactness,"I know this question has been asked to death, but I wish to prove that $\mathbb{Q}$ is not locally compact with a use of a lemma I have not seen used in the other proofs. Lem : Given $(X, \mathfrak{T})$ Hausdorff, then it is locally compact iff
  every point is contained in an open set with compact closure My attempt: Since $\mathbb{Q}$ is a subspace of $\mathbb{R}$, therefore $\mathbb{Q}$ is Hausdorff given that Hausdorffness is arbitrarily hereditary. To show that $\mathbb{Q}$ is not locally compact, we wish to produce a point $x \in \mathbb{Q}$ that is contained in an open set without a compact closure. Let $U = (a,b) \subset \mathbb{R}$. Then $U \cap \mathbb{Q}$ is an open set in the subspace topology. Pick $x \in U \cap \mathbb{Q}$, then $x \in U \cap \mathbb{Q} \subseteq \overline {U \cap \mathbb{Q}}$. (Alarm bells: $\overline {A \cap B}$ might not be equal to $\overline A \cap \overline B$) Now we need to show that $ \overline {U \cap \mathbb{Q}}$ is not compact...however intuitively this set feels like $[a,b] \subset \mathbb{R}$... What! Does anyone see how to resolve this? Thanks so much Also there is another answer using a much simpler characterization Why Q is not locally compact, connected, or path connected? Can we see that the lemma I am using and the one given https://math.stackexchange.com/a/650270/174904 is equivalent?","['proof-verification', 'proof-writing', 'rational-numbers', 'compactness', 'general-topology']"
1886831,Greatest possible cardinality of a set of numbers less than 1000 such that the sums avoid powers of 2,"Let $S = \{1, 2, \dotsc, 1000\}$, $T$ is a subset of $S$. For any $a, b\in T$ (can be the same), $a + b$ is not a power of $2$. Find the greatest possible value of $|T|$. Notice that if $a+a=2^N=2a$, then $a$ must be a power of $2$ as well. Namely $2^{N-1}$. Hence we can't include any power of 2 in the set of $T$ as $a$ and $b$ could be the same. That leaves us for $T=\{1,3,5,6,...,513,514,...,1000\}$. Now notice that if $1+b=2^N$, then $b=2^N-1$, which means every number such that it is one less than a power of $2$ can't be included inside, or $1$ could not be inside. Similar for $3, 5, 6, \dotsc$ as a number with $1, 3, 5, \dotsc$ less than a power of $2$ is much more than a single number $1, 3, 5$ etc. Hence I think it would be more clever to exclude the single number $1, 3, 5, \dotsc$ (I don't know if it's right). From here on I'm stuck and I have no idea.","['combinatorics', 'arithmetic']"
1886864,Writing Complex Numbers as a Vector in $\mathbb{R^2}$,"Generally speaking is it mathematically correct to write a complex number $z = x +  iy \in \mathbb{C}$, as a vector in $\mathbb{R}^2$? $$z=\begin{bmatrix}
x\\
y
\end{bmatrix} \quad \text{with } x,y \in \mathbb{R}$$ With row 1 being the $Re(z)$ and row 2 being $Im(z)$, i.e. 
$$Re: \mathbb R^2 \to \mathbb R, \begin{bmatrix}
x\\
y
\end{bmatrix}\mapsto x \quad \text{and} \quad Im: \mathbb R^2 \to \mathbb R, \begin{bmatrix}
x\\
y
\end{bmatrix}\mapsto y$$","['complex-numbers', 'real-numbers', 'complex-analysis', 'vectors', 'vector-spaces']"
1886890,What is the exact difficulty in defining a point in Euclidean geometry?,"In Euclidean geometry texts, it is always mentioned that point is undefined, it can only be described. Consider the following definition: ""A point is a mathematical object with no shape and size."" I do not understand what is the problem with this definition. Please give the detailed reasons. Thanks in advance!","['definition', 'euclidean-geometry', 'philosophy', 'geometry']"
1886901,How many $5$-digit numbers can be made from digits in the number $75226522$?,"I'm having troubles with this one: How many $5$-digit numbers can be made from digits in the number $75226522$ ? So there is: one seven, one six, two fives, and four twos in that number. So I guess I need to use combination with repetition but I'm having trouble with understanding this. I know how many $8$-digit numbers there are: $$ \frac{8!}{4!2!}$$ But I'm clueless in $5$-digit case",['combinatorics']
1886926,Homeomorphism in product and box topology,"Given sequences $(a_1,a_2,...)$ and $(b_1,b_2,...)$ of real numbers with $a_i\gt0$
for all $i$ Define $h:\Bbb R^\omega\to\Bbb R^\omega$ by the equation $h((x_1,x_2,...))=(a_1x_1+b_1,a_2x_2+b_2,...)$ Now if $\Bbb R^\omega$ is given by the product topology the it is fairly east to show that $h$ is a homeomorphism I am testing whether $h$ is homeomorphic if $\Bbb R^\omega$ is given in box topology My Try: Given fuction can be broken down into 2 functions $h_1$ and $h_2$ defined as $h_1((x_1,x_2,...))=(a_1x_1,a_2x_2,...)$ $h_2((x_1,x_2,...))=(x_1+b_1,x_2+b_2,...)$ Now the original function $h$ is a composition of these functions i.e. $h=h_2\circ h_1$ Clearly both $h_1$ and $h_2$ are one-one and onto. Now we show $h_1$ is continuous. Consider the coordinate maps $h_{1_i}:\Bbb R\to \Bbb R$ for each $i\in \Bbb Z^+$
defined by $h_{1_i}(x)=a_ix$ Its clear that $h_{1_i}$ is continuous for each $i$ Now for each $i$ consider the open set $V_i$ then $h_{1_i}^{-1}(V_i)$ is open $\prod_{i=1}^{\infty}V_i$ is a typical basis element for box topology Also $h_1^{-1}(\prod_{i=1}^{\infty}V_i)=\prod_{i=1}^{\infty}h_{1_i}^{-1}(V_i)$ where the RHS is a basis element of box-topology hence it is open Therefore $h_1$ is continuous, Similarly continuity can be established for $h_1^{-1},h_2,h_2^{-1}$ Thus $h_1,h_2$ are homoemorphic and hence their composition namely $h$ is also homeomorphic. Have I gone wrong somewhere? In the question they have taken $a_i>0$ for all $i$. If $a_i=0 $ then there will be a problem in the inverse map. But what if $a_i<0$, I guess even in this case the the above solution (if at all it is correct) must hold. So can we relax the condition on $a_i$'s to just being nonzero?","['general-topology', 'proof-verification']"
1887036,Claim: $a$ has $90 \% $ primes less than $n$ If $n!= 2^s \times a \times b $ and $\lfloor{\frac{a}{b}}\rfloor = 2^{s-2}$,"Description: We can write, $n!= 2^s  \times a \times b \cdots (1)$ where $gcd(a,b)=1$ and $2^{s+1} \nmid  n!$  . It is given that, $\lfloor{\frac{a}{b}}\rfloor = 2^{s-2}$. Claim: If $n!= 2^s  \times a \times b $ and  $\lfloor{\frac{a}{b}}\rfloor = 2^{s-2}$, then $a$ has $90 \% $ primes less than $n$ as factor. Proof: Here,  $\nu_ p(n)$ denotes the p-adic valuation of $n$ and $s_p(n)$  denotes the sum of the standard base-p digits of $n$, so,
$\nu _{p}(n!)={\frac {n-s_{p}(n)}{p-1}}$  ($\textit{Legendre's formula}$). For $p = 2 $, we obtain $\nu _{2}(n!)= n-s_{2}(n)$, where $s_{2}(n) $ is the number of $1$'s in the binary representation of $n$. The number of primes less than $n$ is denoted by $\pi(n)$. By $\textit{Prime  Number Theorem}$, $\pi(n)\approx  \frac{n}{\log n}$. Since,  $\lfloor{\frac{a}{b}}\rfloor = 2^{s-2} $ $\implies \log_2(a )-\log_2(b)= \log_2 (2)^{s-2}$ [ignoring a quantity $<1$ on R.H.S] $ \implies  \log_2(a )-\log_2(b )=n- s_2(n)-2$ $ \implies  \sum_{p \mid a}\log_2( p ^{\nu _{p}(n!)})-\sum_{q \mid b}\log_2( q ^{\nu _{q}(n!)})=n- s_2(n)-2 \dots (2)$ Equation $(2)$ implies that, $\sum_{p \mid a}\log_2( p ^{\nu _{p}(n!)})-\sum_{q \mid b}\log_2( q ^{\nu _{q}(n!)}) >0  \cdots  (3)$ Now, we consider the smallest prime factor, $p_0$ of $a$ and the biggest prime factor$q_0$ of $b$. Note, $a$ has $i$ distinct prime factors,  $b$ has $j$ prime factors and $ i+j = \pi(n)-1\approx \frac{n}{\log n}-1$.  Since, $\sum_{p \mid a}\log_2( p ^{\nu _{p}(n!)}) < (\log_2(p_0 ^{\nu _{p_0}(n!)}) ) \times i$ 
and, $\sum_{q \mid b}\log_2( q ^{\nu _{q}(n!)}) >(\log_2( q_0^{\nu _{q_0}(n!)}) ) \times j$  (See 1 , Theorem 3.9 on page 7), so- $(\log_2( p_0 ^{\nu _{p_0}(n!)}) ) \times i-(\log_2(q_0^{\nu _{q_0}(n!)}) ) \times j>\sum_{p \mid a}\log_2( p ^{\nu _{p}(n!)})-\sum_{q \mid b}\log_2(q ^{\nu _{q}(n!)})  \cdots (4) $ $\implies (\log_2(p_0 ^{\nu _{p_0}(n!)}) ) \times i-(\log_2( q_0 ^{\nu _{q_0}(n!)}) ) \times j>0$ $\implies i \times \log_2( p_0 ^{\nu _{p_0}(n!)}) > j \times \log_2( q_0 ^{\nu _{q_0}(n!)} )$ $\implies i > j  \times \frac{ \log_2( q_0 ^{\nu _{q_0}(n!)}) }{\log_2( p_0 ^{\nu _{p_0}(n!)}) }$ Let, $T=\frac{ \log_2( q_0 ^{\nu _{q_0}(n!)}) }{\log_2(p_0 ^{\nu _{p_0}(n!)}) }$. $\therefore i > (\pi(n)-1-i)  \times T$ $\implies i > T \times (\pi(n) -1)- T \times i \implies i> \frac{T}{(1+T)} \times (\pi(n) -1)\cdots (5)$ If $  \frac{T}{(1+T)}  \approx 0.9$ so,  $i> 0.9 \times (\pi(n)-1)$. Query: Is the above proof  correct? Please, let me know if anything is inconsistent. Reference : Diophantine equations involving arithmetic functions of factorials , Daniel M. Baczkowski,  A Thesis for  Master’s of Arts, Miami University.","['proof-verification', 'number-theory', 'combinatorics', 'prime-numbers', 'elementary-number-theory']"
1887055,Measure theory and Probability Theory on generalizations of topological spaces,"Given a set $X$ and a topology $\tau$ on $X$ the definition of the Borel $\sigma$-algebra $B(X)$ makes use of the availability of open sets in the topological space $(X, \tau)$: it is the $\sigma$-algebra generated by the open sets. There are many ways to generalize the notion of a topology, e.g. (i) preclosure spaces (with a closure operator that is not necessarily idempotent) or equivalently (i') neighborhood system spaces (a neighborhood of a point need not contain an ""open neighborhood"") and more generally (ii) filter or net convergence spaces (satisfying some convergence axioms). The notion of convergence spaces is strong enough to be able to speak of continuity of maps (defined by preservation of convergence). If $X$ is a convergence space then one can form the set $C(X)$ of continuous real-valued functions $f : X \to \mathbb{R}$ (where $\mathbb{R}$ is equipped with the convergence structure coming from its usual topology). In this way, one can at least relate such spaces to measure theory by creating the Baire $\sigma$-algebra $Ba(X)$ on $X$ generated by $C(X)$. Questions: Are there other ways to connect such generalized topological structures to measure theory and probability theory on such spaces that are of interest in practice? I especially may think here of applications in functional analysis where Beattie and Butzmann argue that convergence structures are more convenient than topologies in such a context. As a standard example, the notion of almost everywhere convergence (of sequences, nets or filters) is not topological. Are there some practical applications in working with such Baire $\sigma$-algebras in non-topological preclosure or convergence spaces? Even for topological space, the Baire $\sigma$-algebra and the Borel $\sigma$-algebra need not coincide. (I think they do coincide if $\tau$ is perfectly normal). Is the following only a trivial idea or does it lead to interesting properties: To any convergence space one can assign a topological space (the reflection of the convergence space, see ncatlab ) and thus speak of a ""Borel"" $\sigma$-algebra for a convergence space. I also understand that measure theory on general topological spaces can be rather boring. Only for special topological spaces like Polish spaces or Radon spaces we may have interesting measure-theoretic results. So maybe there is also an interesting class of non-topological convergence spaces with interesting measure-theoretic theorems generalizing those for Radon spaces.","['functional-analysis', 'category-theory', 'probability-theory', 'measure-theory']"
1887057,Another definition of a Holder norm,"$\def\R{\mathbb{R}}$ Consider a space $C^{1,\beta}$ of all continuous differentiable functions $f\colon\R\to\R$ such that their derivative $f'$ is Holder continuous with exponent $\beta$. A standard way to define a norm on this space is to put $$
\|f\|_{1,\beta}:=\sup_{x\in\R} |f(x)|+\sup_{x\in\R} |f'(x)|+\sup_{x\neq y}\frac{|f'(x)-f'(y)|}{|x-y|^\beta}.
$$ My question is why do we need here the middle  term $\sup_{x\in\R} |f'(x)|$? If we just put
$$
\|f\|:=\sup_{x\in\R} |f(x)|+\sup_{x\neq y}\frac{|f'(x)-f'(y)|}{|x-y|^\beta}.
$$
would this be a norm? Would the space equipped with this norm be a Banach space? Would this norm be equivalent to the standard norm $\|\cdot\|_{1,\beta}$? Thanks!","['functional-analysis', 'normed-spaces', 'real-analysis', 'holder-spaces']"
1887095,Sum of $n$ terms and infinite terms of series,"The sum of $n$ terms of the series $$\frac{1}{2}+\frac{1}{2!}\left(\frac{1}{2}\right)^2+\frac{1\cdot 3}{3!}\left(\frac{1}{2}\right)^3+\frac{1\cdot 3 \cdot 5}{4!}\left(\frac{1}{2}\right)^4+\frac{1\cdot 3 \cdot 5 \cdot 7}{5!}\left(\frac{1}{2}\right)^5+....$$ And also calculate sum of $\infty$ terms. $\bf{My\; Try::}$ We can write above series as $$ 1\underbrace{-\frac{1}{2}+\frac{1}{2!}\left(\frac{1}{2}\right)^2+\frac{1\cdot 3}{3!}\left(\frac{1}{2}\right)^3+\frac{1\cdot 3 \cdot 5}{4!}\left(\frac{1}{2}\right)^4+\frac{1\cdot 3 \cdot 5 \cdot 7}{5!}\left(\frac{1}{2}\right)^5+....}_{S_{n}}$$ So here $$\bf{r^{th}}\; terms \; of \; above\; series (T_{r}) = \frac{1\cdot 3 \cdot 5\cdot \cdot \cdot \cdot (2r-3)}{r!}\cdot \frac{1}{2^r}$$ So $$T_{r} = \frac{1}{3}\left[\frac{1\cdot 3 \cdot 5\cdot \cdot \cdot \cdot  (2r-5)}{(r-1)!}\cdot \frac{1}{2^{r-1}}-\frac{1\cdot 3 \cdot 5\cdot \cdot \cdot \cdot (2r-3)}{r!}\cdot \frac{1}{2^r}\right]$$ So $$S_{n} = \sum^{n}_{r=1}T_{r} = \frac{1}{3}\sum^{n}_{r=1}\left[\frac{1\cdot 3 \cdot 5\cdot \cdot \cdot \cdot  (2r-5)}{(r-1)!}\cdot \frac{1}{2^{r-1}}-\frac{1\cdot 3 \cdot 5\cdot \cdot \cdot \cdot (2r-3)}{r!}\cdot \frac{1}{2^r}\right]$$ So $$S_{n} = \frac{1}{3}\left[-3-\frac{1\cdot 3 \cdot 5\cdot \cdot \cdot \cdot (2n-3)}{n!}\cdot \frac{1}{2^n}\right] = -1+\frac{1}{3}\frac{1\cdot 3 \cdot 5\cdot \cdot \cdot \cdot (2n-3)}{n!}\cdot \frac{1}{2^n}$$ So our Sum is $$=\frac{1}{3}\frac{1\cdot 3 \cdot 5\cdot \cdot \cdot \cdot (2n-3)}{n!}\cdot \frac{1}{2^n}$$ Is my process is right or not, If not the how can i calculate it, Thanks",['sequences-and-series']
1887096,Approximation the sum $\sum\limits_{n=0}^\infty (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}}$,"I would like to find lower and upper bounds on the following sum \begin{align}
\sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}}
\end{align}
where $c,a>0$ and $k>1$. Note that if we could approximate this sum with an integral then 
\begin{align}
\sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} \approx \int _{n=0}^\infty (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} dn=  -\frac{2 a}{k} e^{-\frac{(c+n)^k}{2*a}} |_0^\infty=\frac{2 a}{k} e^{-\frac{c^k}{2*a}}
\end{align} then one might guess that the bounds are 
\begin{align}
\frac{2 a}{k} e^{-\frac{c^k}{2*a}}+c_1 \le\sum_{n=0}^\infty  (c+n)^{k-1} e^{-\frac{(c+n)^k}{2*a}} \le \frac{2 a}{k} e^{-\frac{c^k}{2*a}}+c_2
\end{align} My question is how can this be done or is there a better method  to give lower and upper bounds? I also know that there are bounds of the form
\begin{align}
\int_0^\infty f(x) dx \le \sum_{n=0}^\infty f(n) \le f(0) + \int_0^\infty f(x) dx
\end{align} but they only hold if $f(x)$ is monotone decreasing which is not the case here. Thanks.","['real-analysis', 'sequences-and-series', 'calculus', 'approximation']"
1887103,Heights and sides form two triangles,"Given an acute triangle, consider the three sides and the three heights. Show that using these six segments, it is possible to form two triangles. For three segments with length $a,b,c$ to form a triangle, we need $a+b>c,b+c>a,c+a>b$. The heights of the triagle are $2A/a,2A/b,2A/c$, where $A=\sqrt{s(s-a)(s-b)(s-c)}$ is the area of the triangle and $s=(a+b+c)/2$. If $a\geq b\geq c$, then $2A/a\leq 2A/b\leq 2A/c$. To check the triangle condition is equivalent to checking $2A/a+2A/b>c$ for instance, but this looks rather involved. Is there a way to get around it?","['euclidean-geometry', 'geometry']"
1887114,Finding closest point to some arbitrary 3D coordinate,"I have a cloud of points (hundreds of them) in 3D space. Now I need to find the closest point to my chosen coordinate somewhere in that space. Is there any algorithm that is more efficient than simply iterating over all the points, calculating distance to my arbitrary coordinate and choosing that with lowest value?","['algorithms', 'optimization', 'geometry']"
1887144,Question on $\Pi_{n=1}^\infty\left(1-\frac{x^a}{\pi^an^a}\right)$ and the Riemann Zeta function,"Question on what is $$\Pi_{n=1}^\infty\left(1-\frac{x^a}{\pi^an^a}\right)$$ I deduced that for any $a=2,4,6,\dots$, the above product is simplify-able into a product of sines, $$\Pi_{n=1}^\infty\left(1-\frac{x^2}{\pi^2n^2}\right)=\frac{\sin(x)}x$$ $$\Pi_{n=1}^\infty\left(1-\frac{x^4}{\pi^2n^2}\right)=\frac{\sin(x)\sin(xi)}{x^2}$$ And trying to put this into a general form, I got $$f(x):=\frac{\sin(x)}{x}$$ $$\implies f(x)=f(-x)$$ $$f(x)f(ix)=\Pi_{n=1}^\infty\left(1-\frac{x^4}{\pi^4n^4}\right)=\sqrt{f(xe^{\frac{\pi i}{2}})f(xe^{\pi i})f(xe^{\frac{3\pi i}{2}})f(xe^{2\pi i})}$$ Using $(a+b)(a-b)=a^2-b^2$, we can get something along the lines of $$\Pi_{n=1}^\infty\left(1-\frac{x^{2^a}}{\pi^{2^a}n^{2^a}}\right)=\sqrt{f(xe^{\frac{1\pi i}{2^a}})f(xe^{\frac{2\pi i}{2^a}})\dots f(xe^{\frac{2^a\pi i}{2^a}})}=\Pi_{n=1}^{2^a}\sqrt{f(xe^{\frac{n\pi i}{2^a}})}$$ $$\implies\Pi_{n=1}^\infty\left(1-\frac{x^a}{\pi^an^a}\right)=\Pi_{n=1}^a\sqrt{f(xe^{\frac{n\pi i}a})}$$ I was wondering if this is correct and if it were possible to... take the Taylor Series of the RHS?  Specifically for $a=3$, as this would result in relations to the Riemann Zeta function.","['algebra-precalculus', 'riemann-zeta', 'trigonometry', 'infinite-product']"
1887190,Find $a^{2013} + b^{2013} + c^{2013}$,"Problem Statement Let $f(x) = x^3 + ax^2 + bx + c$ and $g(x) = x^3 + bx^2 + cx + a$ where $a,b,c$ are integers with $c\not=0$ Suppose that the following conditions hold: $f(1)=0$ the roots of $g(x)=0$ are the squares of the roots of $f(x)=0$ $$\text{Find the value of} \: \: a^{2013} + b^{2013} + c^{2013}$$ My attempt Let $f(x) = (x-p)(x-q)(x-r) \: \:$ and $g(x) = (x - p^2)(x-q^2)(x-r^2)$ Expanding we get $$f(x) = x^3 - (p + q + r)x^2 + (pq + pr + qr)x - pqr$$ $$g(x) = x^3 - (p^2 + q^2 + r^2)x^2 + (p^2q^2 + p^2r^2 + r^2q^2)x - p^2q^2r^2$$ And so we have $$a = -(p+q+r) = -p^2q^2r^2$$
$$b = pq + pr + qr = p^2 + q^2 + r^2$$
$$c = -pqr = p^2q^2 + p^2r^2 + r^2q^2$$ Then we get the following relations $$a = -c^2$$ $$b = a^2 - 2b \implies 3b = a^2 \implies b = \frac{c^4}{3}$$ From $f(1) = 0$ we have $a + b + c = -1 \implies \dfrac{c^4}{3} + c - c^2 = -1$ However, upon graphing this function, I saw that there are no integer solutions for $c$. Have I done something wrong? Edit For future readers, my approach can simplified alot if you replace $r$ with $1$ since $f(1) = g(1) = 0$","['algebra-precalculus', 'polynomials', 'functions']"
1887213,On the embedding of a Sobolev space on a unbounded domain,"I have a question about a Sobolev space. Let $D \subset \mathbb{R}^d$ be a connected open subset with smooth boundary. When $D$ is bounded, Relich's theorem states that $W^{1,2}(D)$ (Sobolev space on $D$ with Neumann boundary condition) is compactly embedded in $L^2(D)$. But I am interested in the case $D$ is unbouned. Question When $D=\{(x,y) \in \mathbb{R}^2: y>0 \}$, can we show that $W^{1,2}(D)$ is compactly embedded in $L^2(D)$ or $W^{1,2}_{0}(D)$ is compactly embedded in $L^2(D)$ ? ($W_{0}^{1,2}(D)$ is the Sobolev space on $D$ with Dirichlet boundary condition) If you know related research, please let me know.","['functional-analysis', 'sobolev-spaces']"
1887301,The Weierstrass map between a torus and an elliptic curve is biholomorphic,"Let $\Lambda$ be a lattice in $\mathbb C$. We can build by this lattice the Weierstrass $\wp$-function in the following manner:
$$
\wp(z) = \frac{1}{z^2}+\sum\limits_{l\notin\Lambda\setminus\{0\}}\left(  \frac{1}{(z-l)^2} - \frac{1}{l^2}\right)
$$
It can be shown that this function satisfies the following differential equation: $$
\wp'(z)^2 = 4\wp(z)^3 - 60G_4\wp(z) - 140 G_6
$$
This function gives us a map frop $\mathbb C/\Lambda$ to the elliptic curve $y^2 = 4x^3 - 60G_4 x - 140G_6$ in such a way:
$$
z \mapsto [\wp(z):\wp'(z):1]
$$ My question is: why this map is biholomorphic?","['complex-analysis', 'elliptic-curves']"
1887324,Topology of the space $\mathcal{D}(\Omega)$ of test functions,"Let $\Omega$ be a nonempty open subset of $\mathbb{R}^n$, and $\mathcal{D}(\Omega)$ the set of test functions (infinitely differentiable functions $f:\Omega \rightarrow \mathbb{C}$ with compact support contained in $\Omega$). For every compact $K \subseteq \Omega$, let $\mathcal{D}_K$ be the locally convex topological vector space of infinitely differentiable function $f:\Omega \rightarrow \mathbb{C}$ whose support lies in $K$, with the topology $\tau_K$ induced by the system of norms ($N=0,1,2,\dots$):
\begin{equation}
\left| \left| f \right| \right|_{N} = \max \{ \left| D^{\alpha}f(x) \right| : x \in \Omega, | \alpha | =0,1,\dots, N \},
\end{equation}
where $\alpha=(\alpha_1,\dots,\alpha_n)$ is a multi-index and $|\alpha|=\alpha_1 + \dots + \alpha_n$. The usual topology of $\mathcal{D}(\Omega)$ is defined as the strongest topology among all those topologies on $\mathcal{D}(\Omega)$ that (i) make $\mathcal{D}(\Omega)$ a locally convex topological vector space and such that (ii) the inclusion $i_K: \mathcal{D}_K \hookrightarrow \mathcal{D}(\Omega)$ is continuous for every compact $K \subseteq \Omega$. In the language of Bourbaki, $\tau$ is called the ""locally convex final topology"" of the family of topologies $(\tau_K)$ of the spaces $(\mathcal{D}_K)$ with respect to family of linear maps $(i_K)$. I have two questions. (Q1) Can we find a set $V \subseteq \mathcal{D}(\Omega)$, such that $V \cap \mathcal{D}_K \in \tau_K$ for all compact $K \subseteq \Omega$, but $V \notin \tau$? (Q2) Can we find $V \subseteq \mathcal{D}(\Omega)$, with $0 \in V$, such that $V \cap \mathcal{D}_K \in \tau_K$ for all compact $K \subseteq \Omega$, and there is no $W \subseteq V$, with $0 \in W \in \tau$? Clearly a positive answer to (Q2) implies that also (Q1) has a positive answer.
Note that (Q1) is equivalent to ask whether $\tau$ coincides or not with the final topology $\tau'$ on $\mathcal{D}(\Omega)$ with respect to the family of inclusions $i_K: \mathcal{D}_K \hookrightarrow \mathcal{D}(\Omega)$, where $K$ is any compact subset of $\Omega$. So we have $\tau \subseteq \tau'$ and (Q1) can maybe be given a positive indirect answer, by proving that $\tau$ and $\tau'$ do not share the same properties.
To give a positive answer to (Q2) seems to be more difficult.","['functional-analysis', 'general-topology', 'distribution-theory', 'topological-vector-spaces']"
1887326,Second order differential equation by linear algebra,"I am trying to solve the following differential equations $\frac {du}{dt} = Au$ and $\frac {d^2u}{dt^2} = Au$ with 
$$
A = 
        \begin{bmatrix}
        -2 & 1 & 0 \\
        1 & -2 & 1 \\
        0 & 1 & -2 \\
        \end{bmatrix},
$$ $u(0) = (0, 2 \sqrt 2, 0)$ and $\frac{du}{dt}(0) = 0$ by linear algebra. I get the complete solution for the first equation and get stuck on the second one. The textbook (""Introduction to Linear Algebra"" by Strang) offers the following solution: $\frac {d^2u}{dt^2} = Au$ has the same eigenvectors  x.  But  now the eigenvalues  $\lambda$ lead to oscillations $e^{i\omega t}x$ and $e^{-i\omega t}x$.  The  frequencies  come  from $\omega^2 = -\lambda$. Then it proceeds to plug $e^{i\omega t}x$ into the second order equation to show the last equation holds. My question is: Is there a specific method for solving this kind of second order equation relying on $e^{i\omega t}x$? Or am I missing something and there actually is a way to deduce $e^{i\omega t}x$ from what is asked? Needles to say, at this point in the material, specific methods for solving the second equation have not been covered.","['ordinary-differential-equations', 'linear-algebra']"
1887338,Christoffel Symbols of Bi-invariant Metric on $SO(3)$,"I'd like to calculate directly the Christoffel symbols for $SO(3)$. Let us suppose I have the metric on $SO(3)$ given by 
$$g(X,Y)=1/2 [\operatorname{tr}(X^tY)].$$
I'm aware of Milnor paper and I know I can get the Christoffel symbol of a bi-invariant metric of a generic Lie Group through Koszul formula, but in this case is there a way to find the Christoffel Symbols o the connection forms directly? Taking the standard basis $E_1,E_2,E_3$ of $\text{so}(3)$ where $[E_1,E_2]=E_3$, $[E_2,E_3]=E_1$ and $[E_3,E_1]=E_2$, if I'm not mistaking $g_{ij}$ at the identity is the identity matrix... so where do I go from there? I'm getting quite confused...","['riemannian-geometry', 'differential-geometry', 'lie-algebras', 'lie-groups']"
1887350,What is a generic (genetic/geometric) map? (In the study of manifolds),"At 29:30 in his lecture on Youtube , Mikhail Gromov talks about how one only gets a manifold from the zero set of the equation $f(0)=0$ if the map $f$ is ""generic"" (or genetic or geometric -- I mostly but not entirely understand his accent). It is a dirty word, because it is extremely convenient, but you don't know what you get -- but on the other hand this is the major mechanism generating manifolds, by genericity(?) He then goes on to discuss how this concept raises foundational issues, saying at 31:37 that if we do not allow such functions to exist then the continuum hypothesis is true,  and that if we do allow such functions to exist, then the continuum hypothesis is false. What concept is he referring to? It sounds extremely important. The best I could find is generic point which sounds vaguely similar. That or perhaps he is mistranslating a Russian term and means regular point ? Because I am aware of how one can use the implicit function theorem to take the inverse images of a regular point and create manifolds. Also he talks in between about singularities being ""rare"" but coming with additional structure when they do occur, which sounds like Morse theory to me. He also talks about a result from Riemannian geometry which holds at least for dimensions 1-7 and was proved in part by Jim Simons.","['riemannian-geometry', 'differential-topology', 'algebraic-geometry', 'morse-theory', 'manifolds']"
1887362,Increasing derivatives of recursively defined polynomials,"Consider recursively defined polynomials $f_0(x) = x$ and $f_{n+1}(x) = f_n(x) - f_n'(x) x (1-x)$. These polynomials have some special properties, for example $f_n(0) = 0$, $f_n(1) = 1$, and all $n+1$ roots of $f_n$ are in $[0,1)$. 
Let $x_n$ denote the largest root of $f_n$. Then $f_n(x_n) = 0$ and $f_n'(x_n)>0$. Moreover, $x_n > x_{n-1}$ for all $n$. I want to prove the following claim: $f_{n}'(x_{n+1}) > f_{n-1}'(x_{n+1})$ for all $n \geq 2$. Note that the claim does not hold for arbitrary $x$. The derivatives are polynomials themselves, by Gauss-Lucas theorem all their roots are in $[0,x_n)$ and there are many points where $f_{n}'(x) < 0 < f_{n-1}'(x)$. However, I am quite sure that at $x \geq x_{n+1}$, the derivatives are ordered: $f_1'(x) < \dots < f_n'(x)$. Some of the first polynomials are: $f_1(x) = x^2$, $f_1'(x) = 2x$, $x_1 = 0$ $f_2(x) = 2x^3 - x^2$, $f_2'(x) = 6 x^2 -2x$, $x_2 = \frac{1}{2}$ $f_3(x) = 6 x^4 - 6x^3 + x^2$, $f_3'(x) = 24x^3-18x^2+ 2x$, $x_3 \approx 0.7887$ $f_4(x) = 24 x^5 - 36 x^4 + 14 x^3 -x^2$, $f_4'(x) =120x^4-144x^3 +42x^2 -2x$, $x_4 \approx 0.9082$ Therefore $f_2'(x)-f_1'(x) = 6x^2-4x \geq 0$ for all $x \geq \frac{2}{3}$. Note that, $x_2 < \frac{2}{3} < x_3$. For $f_3'(x) - f_2'(x) = 24 x^3-24 x^2 + 4 x \geq 0$ for all $x \geq 0.7887$. Here it turns out that at $x_3$ the inequality holds as an equality (coincidence perhaps?), but of course then for $x_4 > x_3$ it holds as a strict inequality.","['recurrence-relations', 'real-analysis', 'polynomials', 'roots']"
1887376,Showing a function is differentiable on $\mathbb{R}^+$,"Question : Let $f \ge 0$ be an integrable function on $\mathbb{R}$. Define $g(t) := \displaystyle \int_\mathbb{R} \cos(tx)\ f(x) \; dx$ for $t \ge 0$. Show $g$ is twice-differentiable $\iff \displaystyle \int_\mathbb{R} x^2 f(x) \; dx <\infty$. Solution : $(\Rightarrow)$ Suppose $g$ is twice-differentiable so that $| g''(0)|<\infty$. Then,
\begin{align*}
|g''(0)| &= \left\vert \lim \limits_{h \to 0} \dfrac{g(h) -2g(0) +g(-h)}{h^2} \right\vert \\
&= \lim \limits_{h \to 0}\left\vert \dfrac{g(h) -2g(0) +g(-h)}{h^2} \right\vert \\
&= \lim \limits_{h \to 0} \int_\mathbb{R} \left\vert \dfrac{ \cos(hx) -2 + \cos(-hx)}{h^2} f(x) \right\vert \; dx  \quad (^* \text{Wrong, see edit}^*)\\
&=  \lim \limits_{h \to 0} \int_\mathbb{R} \left\vert \dfrac{2( \cos(hx) -1) }{h^2}  \right\vert f(x) \; dx \\
&\ge   \int_\mathbb{R} \liminf \limits_{h \to 0} \left\vert \dfrac{2( \cos(hx) -1) }{h^2} \right\vert  f(x) \; dx \quad \text{(Fatou)} 
\\ &= \int_\mathbb{R} x^2f(x) \; dx.
\end{align*} $(\Leftarrow) $ This is where I am sort of stuck. I am doing a standard technique of showing a partial derivative is bounded so I can push the derivative inside the integral using LDCT ( Will moving differentiation from inside, to outside an integral, change the result? ) First, note that $g(t)$ is integrable since 
$$
\left\vert \int_\mathbb{R} \cos(tx) f(x) \; dx \right\vert \le \|f\|_{L^1(\mathbb{R})}<\infty
$$ Also, $\left\vert \frac{\partial^2 }{\partial t^2} \cos(tx) f(x) \right\vert = |x^2 \cos(tx) f(x)| \le |x^2 f(x)|,$ which is integrable by assumption. So $g''$ exists, assuming $g'$ does. But I can't show $g'$ exists because $\left\vert \frac{\partial }{\partial t} \cos(tx) f(x) \right\vert = |x\sin(tx) f(x)| $, which is $\le$ both  $|xf(x)|$ and $|x^2 t f(x)|$, neither of which seem to help . . . If I attack with $g'(t) = \lim \limits_{h \to 0} \dfrac{g(t+h)-g(t)}{h}
 =  \lim \limits_{h \to 0} \displaystyle \int_\mathbb{R} \dfrac{\cos(x(t+h)) - \cos(xt)}{h}f(x) \; dx$, I can't make progress either. Thanks for the help. EDIT: Let me fix the $\Rightarrow$ direction. Basically all I need to do is note that $2 - 2 \cos(hx) \ge 0$, so I can still apply Fatou.
\begin{align*}
-g''(0) &=  \lim \limits_{h \to 0} -\dfrac{g(h) -2g(0) +g(-h)}{h^2}  \\
&= \lim \limits_{h \to 0} \int_\mathbb{R}  \dfrac{ -\cos(hx) +2 - \cos(-hx)}{h^2} f(x)  \; dx  \\
&=  \lim \limits_{h \to 0} \int_\mathbb{R}  \dfrac{2( 1-\cos(hx)) }{h^2}  f(x) \; dx \\
&\ge   \int_\mathbb{R} \liminf \limits_{h \to 0}  \dfrac{2(1-\cos(hx)) }{h^2}  f(x) \; dx \quad \text{(Fatou)} 
\\ &= \int_\mathbb{R} x^2f(x) \; dx.
\end{align*}","['real-analysis', 'measure-theory']"
1887409,On convergence of $\cos(2\pi \alpha n!)$,"Let $x\in \mathbb R$ Prove that there exists some $\alpha_x$ such that the sequence $\cos(2\pi \alpha_x n!)$ converges to $\cos(x)$ I've been stumped with this problem for a while. I've been looking for some $\alpha$ such that $$\forall n, 2\pi \alpha n! = x + 2\pi k_n + \epsilon_n$$ where $k_n$ is an integer and $\epsilon_n$ a sequence that goes to $0$ . Can someone help me build the $\alpha$ ?","['trigonometry', 'sequences-and-series']"
1887417,Complexification of a self-adjoint operator is self-adjoint on the complexified space,"In ""Linear algebra done right"" 9.b.4 : Suppose $V$ is a real inner product space and $T \in \mathcal{L}(V)$ is self-adjoint. Show that $T_\mathbb{C}$ is a self-adjoint operator on the inner product space $V_\mathbb{C}$. My way to do it is as follow: Since $T$ is self-adjoint under real inner product vector space, by real spectral theorem, there exists an orthonormal basis $\mathcal{B}$ such that $\mathcal{M}(T,\mathcal{B},\mathcal{B})$ is diagonal matrix and all $\lambda_i \in \mathbb{R}$ are on the diagonal. W.r.t the same basis $\mathcal{B}$, $\mathcal{M}(T_\mathbb{C},\mathcal{B},\mathcal{B})$ is the same as $\mathcal{M} (T,\mathcal{B},\mathcal{B})$, and because $\lambda_i$ are all real, we have $\mathcal{M}(T_\mathbb{C}^*,\mathcal{B},\mathcal{B})$=$(\overline{\mathcal{M}(T_\mathbb{C},\mathcal{B},\mathcal{B})})^t$=$\mathcal{M}(T_\mathbb{C},\mathcal{B},\mathcal{B})$, which implies $T_\mathbb{C}$ is self-adjoint. Can someone tell me is there anything wrong in this proof?",['linear-algebra']
1887442,Derivative of a function is same the function,"Lets extend to nth order derivative  functions and not merely second order derivative functions. The 4th order(say) derivative of the following functions is same the function itself $$
\begin{aligned}
f(x)&=e^{x}\\
f(x)&=0\\
f(x)&=\sin x\\
f(x)&=\cos x
\end{aligned}
$$
I was curious to know whether there are there any more such unique functions ?","['derivatives', 'calculus']"
1887464,$A+tB \ge 0 $ for small $t \Rightarrow A+B \ge 0$?,"$\newcommand{\psym}{\operatorname{P}_{\ge 0}}$
Let $\psym$ be the set of symmetric positive semidefinite (real) matrices. Let $A \in \psym$ be on the boundary of $\psym$, i.e $\det A=0$ and let $B$ be a symmetric matrix such that $A+tB \in \psym$ for $t >0$ small enough. Is it true that $A+B \in \psym$? Why I think this might be true: The intution is that if we are on the boundary of $\psym$, and we have some small perturbation which keeps us inside the space, than this perturbation must be in the ""inward"" direction from the boundary into the interior of the space. Thus, taking a larger step $(t >>0)$ in this direction will also keep us in the space. Proof for the case when $A,B$ commute: If $A,B$ commute, then they are simultaneously diagonalisable by an orthogonal matrix, i.e there exists $V \in O_n$ such that: $$V^TAV=\Sigma_A,V^TBV=\Sigma_B , $$ so (remember $t>0$) $$A+tB \ge 0 \Rightarrow V^T(A+tB) V=\Sigma_A+t\Sigma_B \ge 0\Rightarrow  \Sigma_A+\Sigma_B \ge 0 \Rightarrow $$ $$ V (\Sigma_A+\Sigma_B) V^T=A+B \ge 0 $$ as required.","['matrices', 'positive-definite', 'linear-algebra']"
1887476,What exactly is a derivative?,"In calculus courses, we learn the classical derivative: $$f'(x)=\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$$ And the directional derivative: $$D_{\mathbf{v}}{f}(\mathbf{x}) = \lim_{h \rightarrow 0}{\frac{f(\mathbf{x} + h\mathbf{v}) - f(\mathbf{x})}{h}}$$ In which the partial derivative is just a slight variation of the previous one. But some days ago, I've read Stopple's Primer of Analytic Number Theory , I've read something about the difference operator: $$\Delta f(x)=f(x+1)-f(x)$$ Which at least for me, seems quite sems quite familiar with the previous examples. The only difference is that this is not really a limiting process - another one that lacks the limiting process but is also called a derivative is the arithmetic derivative . But there are other examples in which there is a limiting process, in non-newtonian calculus, for example, we have the geometric derivative : $$f^{*}(x) = \lim_{h \to 0}{ \left({f(x+h)\over{f(x)}}\right)^{1\over{h}} }$$ And the bigeometric derivative: $$f^{*}(x) = \lim_{h \to 0}{ \left({f((1+h)x)\over{f(x)}}\right)^{1\over{h}} } =  \lim_{k \to 1}{ \left({f(kx)\over{f(x)}}\right)^{1\over{\ln(k)}} }$$ And in this site , the authors argue that: ""There are infinitely many non-Newtonian calculi. Like the classical calculus, each of them possesses, among other things: a derivative, an integral, a natural average, a special class of functions having a constant derivative, and two Fundamental Theorems which reveal that the derivative and integral are 'inversely' related."" I remember from my calculus classes that the classical derivative is a comparison of a certain function with the slope of a straight line. It seems to my limited knowledge that these other derivatives are also comparisons with some other geometrical figures, perhaps? From this book : During the Renaissance many scholars, including Galileo, discussed the following problem: Two estimates, $10$ and $1000$ , are proposed as the value of a horse. Which estimate, if any, deviates more from the true value of $100$ ? The scholars who maintained that the deviations should be measures by the differences concludes that the estimate of $10$ was closer to the actual value. However, Galileo eventual maintained that the deviations should be measured by ratios, and he concluded that the two estimates deviated equally from the true value. Other examples are also Fréchet's derivatives and Gâteaux derivatives which I'm not exactly sure of what they are. As you can see further in the book, this yields the previously mentioned geometric derivative . So, assuming there is a class of kinds of derivatives, what binds them all? How can I look at anything and decide if it's a derivative or not? I presume that if something is a derivative, then it must have - just as the authors of the mentioned website said - an integral, a natural average, a special class of functions having a constant derivative, and two Fundamental Theorems which reveal that the derivative and integral are 'inversely' related. So, given any expresion, is it a derivative if I can come up with all these items? This seems a faint answer to me, I'd like to see if there is a better one.",['analysis']
1887514,Must there be a sequence $(\epsilon_n)$ of signs such that $\sum\epsilon_nx_n$ and $\sum\epsilon_ny_n$ are both convergent?,"Let $(x_n)$ and $(y_n)$ be real sequences. (i) Suppose $x_n \rightarrow 0$ as $n \rightarrow \infty.$ Show that
  there is a sequence $(\epsilon_n)$ of signs (i.e., $\epsilon_n \in
 \{−1, +1\}$ for all $n$) such that $\sum \epsilon_nx_n$ is convergent. (ii) Suppose $x_n \rightarrow 0$ and $y_n \rightarrow 0.$ Must there
  be a sequence $(\epsilon_n)$ of signs such that $\sum\epsilon_nx_n$
  and $\sum\epsilon_ny_n$ are both convergent? I'm struggling to come up with formal proofs, for (i) I've seen that we simply pick a limit and and then as soon as our sum passes the limit we set $\epsilon_n=-1$ until we pass it again and so on, oscillating about the limit but as $x_n \rightarrow 0$ we converge to it. for (ii) I don't think there must be such a sequence of $\epsilon_n$ but I can't construct a proof or counter example. So I would ask for a solution to (ii) and possibly a better way of constructing answers/tackling these problems in general. Thank you","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
1887568,Chord Length Distribution in Two-Dimensional Disk(s),"Let $A\in\mathbb{R}^2$ be a disk of radius $R$, let $(x_1,y_1)\in A$ and $(x_2,y_2)\in A$ be points chosen randomly from a uniform distribution and let $\delta$ denote the distance between the two points. There is a distance ditribution $\Delta(\delta)$ such that $\int_a^b\Delta(\delta)d\delta$ is the probability that $a<\delta<b$. I was able to come up with the following definition of $\Delta$: The probability of any choosing two points is equal, thus the probability can be expressed as the intgral of all sets of points separated by distance $\delta$ divided by the integral of all pairs of points: $$\Delta(\delta)=\frac{\int_{(x_1,y_1),(x_2,y_2)\in A,\ \sqrt{(x_2-x_1)^2+(y_2-y_1)^2}=\delta}dV}{\int_{(x_1,y_1),(x_2,y_2)\in A}dV}$$ where $dV$ is a volume differential of appropriate dimension. The denominator is simply the square of the area of A. $$\Delta(\delta)=\frac{\int\int_{(x_1,y_1)\in A}\int_{(x_2,y_2)\in A,\ \sqrt{(x_2-x_1)^2+(y_2-y_1)^2}=\delta}dV}{\pi^2R^4}$$ The domain of the second integral is the union of A and a circle of radius $\delta$ centered at $(x_2,y_2)$. $$\Delta(\delta)=\frac{\int\int_{(x_1,y_1)\in A}\int_{\theta_{min}}^{\theta_{max}}\delta\ d\theta\ dy_1\ dx_1}{\pi^2R^4}$$ This can be simplified by switching to polar coordinates, and using the Law of Cosines to find $\theta_{min}$ and $\theta_{max}$. $$\Delta(\delta)=\frac{4\delta}{\pi R^4}\int_0^Rr\ \arccos\frac{r^2+\delta^2-R^2}{2r\delta}dr$$ This is as much as I have been able to simplify the expression. I'n not sure if the remaining integral has a closed form, but it seems as if it should. $$$$ A slightly more complicated variation involves disjoint disks $A_1$ and $A_2$ with radii $R_1$ and $R_2$ separated by center-to-center distance $D$, and the distribution of distances between one point randomly selected from $A_1$ and another randomly selected from $A_2$. All I could get out was this mess of an integral: $$\Delta(\delta)=2\delta\int_0^{2\pi}\int_0^{R_1}r\sqrt{r^2+D^2-2rD\ \cos\ \theta}\ \arccos\frac{\delta^2+r^2+D^2-R_2^2-2rD\ \cos\ \theta}{2\delta\sqrt{r^2+D^2-2rD\ \cos\ \theta}}dr\ d\theta$$ Any input would be appreciated.","['statistics', 'integration', 'geometry']"
1887574,Spivak Problem 18-31 (b),"Problem Description: 
Evaluate the following limit: 
$\displaystyle\lim_{x \to \infty }{e^{-x^2}\int_{x}^{x+\frac{1}{x}} e^{t^2}dt}$. The solution books uses L'Hopital's rule, and does as follows: $\displaystyle\lim_{x \to \infty }\frac{\displaystyle\int_{x}^{x+\frac{1}{x}} e^{t^2}dt}{e^{x^2}}$
$=\displaystyle\lim_{x \to \infty }\frac{e^{{(x+\frac{1}{x})}^2} - e^{x^2}}{2xe^{x^2}}$. My concern is that shouldn't it be 
$\displaystyle\lim_{x \to \infty }\frac{\displaystyle\int_{x}^{x+\frac{1}{x}} e^{t^2}dt}{e^{x^2}}$
$=\displaystyle\lim_{x \to \infty }\frac{e^{(x+\frac{1}{x})^2)}(1- \frac{1}{x^2}) - e^{x^2}}{2xe^{x^2}}$.","['derivatives', 'calculus', 'limits']"
1887583,"Show that, for all $n > 1: \frac{1}{n + 1} < \log(1 + \frac1n) < \frac1n.$ [duplicate]","This question already has answers here : Showing $\frac{x}{1+x}<\log(1+x)<x$ for all $x>0$ using the mean value theorem [duplicate] (5 answers) Closed 6 years ago . I'm learning calculus, specifically derivatives and applications of MVT, and need help with the following exercice: Show that, for all $n > 1$ $$\frac{1}{n + 1} < \log(1 + \frac1n) < \frac1n.$$ I tried to follow the below steps in order to prove the RHS inequality: Proving that $f < g$ on $I$ from $a$ to $b$: Step $1$. Prove that $f' < g'$ on $\operatorname{Int}(I)$. Step $2$. Show that $f(a) \leq g(a)$ or that $f(a^+) \leq g(a^+)$ Following the above steps, let $f(x) = \log(1 + \frac1x)$ and $g(x) = \frac1x$, for all $x > 1$. One has $$f'(x) =  -\frac{1}{x^2 + x} \quad \text{and} \quad g'(x) = -\frac{1}{x^2}.$$ We note that, for every $x > 1$, $f'(x) > g'(x)$. Moreover, $f(1^+) = \log(2) < 1 = g(1^+).$ My problem is that I got the wrong inequality sign in Step $1$ . Looking at the solution in my textbook, the author suggests using the MVT but I don't know how to apply it in this case.","['derivatives', 'inequality', 'calculus', 'logarithms']"
1887601,How would you show that the series $\sum_{n=1}^\infty \frac{(2n)!}{4^n (n!)^2}$ diverges?,"How would you show that the series $$\sum_{n=1}^\infty \frac{(2n)!}{4^n (n!)^2}$$ diverges? Wolfram Alpha says it diverges ""by comparison"", but I'd like to know to what you would compare it? I've tried some basic things to no avail: The ratio test is inconclusive, comparing with something ""smaller"" which I know diverges is proving difficult. If possible, I'd like to show this without using anything fancy (such as Stirling's approximation). Can you do this with a ""basic"" comparison?","['divergent-series', 'sequences-and-series', 'calculus']"
1887632,"Why is $\lim_{x\to 1}\sqrt{1-x}\sum_{n=0}^\infty x^{n^2}=\sqrt{\pi}/2\,\,$? [duplicate]","This question already has answers here : Compute the limit of $\sqrt{1-a}\sum\limits_{n=0}^{+\infty} a^{n^2}$ when $a\to1^-$ (2 answers) Closed 7 years ago . It is well-known that $\sum_{n=0}^\infty x^n=1/(1-x)$. However, it seems difficult to find $\sum_{n=0}^\infty x^{n^2}$. A natural problem is study its behavior around $1$. A problem states that
$$\lim_{x\to 1}\sqrt{1-x}\sum_{n=0}^\infty x^{n^2}=\sqrt{\pi}/2.$$ How can we prove this? Abel summation formula? Any others? I have no idea.","['sequences-and-series', 'calculus', 'limits']"
1887642,How can I geometrically understand the fundamental group of the 1-skeleton of the unit cube?,"Consider the unit cube $I^3$. I'm aware that the 1-skeleton consists of all the edges of the cube and that the fundamental group is $\mathbb{Z} \star \mathbb{Z} \star \mathbb{Z}$, but I'm trying to understand how the cube deforms into the wedge sum of three circles.","['algebraic-topology', 'group-theory', 'fundamental-groups']"
1887646,Differential of flow related to gradient Ricci soliton on $S^2$,"I'm confused by a claim made in Brendle's Ricci Flow and the Sphere Theorem on page 37. Let $(S^2,g)$ be a gradient Ricci soliton with soliton function $f:S^2\to\Bbb R$. Since the sphere is $2$-dimensional, we have 
$$\nabla^2f=(\rho-\tfrac{1}{2}s)g,$$
where $\nabla$ is the LC connection, $s$ is the scalar curvature, and $\rho$ is a constant. Let $J$ be an almost complex structure compatible with $g$, i.e. $(x,y)\mapsto g(x,Jy)$ is a symplectic form, $g(Jx,Jy)=g(x,y)$, and $\nabla J=0$. Letting $\xi$ be the gradient of $f$ wrt. $g$, we have that $J\xi$ is a Killing field and its flow $\varphi_t$ is a one-parameter group of isometries. Let $p\in S^2$ be a critical point of $f$ and let $a=\rho-\tfrac{1}{2}s(p)$, so that 
$$\tag{1}(\nabla^2 f)_p(v,v)=a|v|^2.$$ The author claims this implies $$\tag{2}(\mathrm d\varphi_t)_p(v)=\cos(at)v+\sin(at)Jv,$$
for all $t\in\Bbb R$ and $v\in T_pS^2$, which I am having a very hard time seeing. Since $p$ is a critical point $J\xi_p=0$, and $\varphi_t(p)=p$. We also have $g(v,Jv)=\omega(v,v)=0$, i.e. $v\bot Jv$ and are thus linearly independent. So we may write $$(\mathrm d\varphi_t)_pv=\alpha(t)v+\beta(t)Jv,$$
for smooth functions $\alpha,\beta:\Bbb R\to\Bbb R$. Furthermore, since $\varphi_t$ is an isometry, we have 
\begin{align*}g(v,v)&=g((\mathrm d\varphi_t)_p(v),(\mathrm d\varphi_t)_p(v))\\
&=g(\alpha v+\beta Jv,\alpha v+\beta Jv)\\
&=\alpha^2 g(v,v)+2\alpha\beta g(v,Jv)+\beta^2g(Jv,Jv)\\
&=(\alpha^2+\beta^2)g(v,v)\implies \alpha^2(t)+\beta^2(t)=1.\end{align*} Clearly $\alpha(0)=1$ and $\beta(0)=0$. To get sine and cosine, it seems like one should derive the ODEs $\alpha''=-a^2\alpha$ and $\beta''=-a^2\beta$ with the correct initial values from $(1)$, but I don't know how to do that. Taking the derivative of $\alpha^2+\beta^2=1$ gives $\alpha\alpha'+\beta\beta'=0$, whence $\alpha'(0)=0$. Let $c(t)=\alpha(t)v+\beta(t)Jv$. Then $t\mapsto g(c(t),c(t))$ is a constant function, so $g(c',c)=0$. This fixes $c'=-k\beta v+k\alpha Jv$, where $k$ is a constant. Thus $
\alpha'=-k\beta$ and $\beta'=k\alpha$. Thus $\beta'(0)=k$ and we get $c''=-k^2c$. Together with the initial values, this gives $c(t)=\cos(kt)v+\sin(kt)Jv$. How does one see that $a=k$? It's not clear to me from this why $\alpha,\beta$ should be the same for all vectors, either. Assuming $(\mathrm d\varphi_t)_p(w)=\gamma(t)w+\delta(t)Jw$ and computing $g(v,w)$ gives a horrible mess. How does one obtain $(2)$?","['riemannian-geometry', 'differential-geometry']"
1887675,Any Implications of Fermat's Last Theorem? [duplicate],"This question already has answers here : Fermat's Last Theorem: implications (there is no new proof) (3 answers) Closed 7 years ago . In our discourse FLT is Fermat's Last Theorem.
I am unaware of any theorems or conjectures that begin assuming FLT is true, or otherwise use FLT as a starting point or tool. The small amount of literature review I've done on this question reveals nothing. My question is: Where can I find a work requiring FLT, or some useful implication of FLT? Even an implication of a polynomial inequality, that may not be FLT, may be a good answer to this question, as I'll likely try to use it to find something regarding FLT. The following is not acceptable as an answer to this question: $$ (a^{x_{1}}_{1} + b^{x_{1}}_{1} - c^{x_{1}}_{1}) \ldots (a^{x_{n}}_{n} + b^{x_{n}}_{n} - c^{x_{n}}_{n}) \not= 0 : x_{i} > 2 $$ and it's expansions imply (something trivial) Another acceptable answer to this question would be a proof requiring FLT to be false . Thanks and please let me know if I can ask this question in a way more fitting math.se (new user).","['number-theory', 'proof-writing', 'diophantine-equations', 'alternative-proof']"
1887680,Can 4 lines intersect in 2 points?,"Four lines can intersect in at most $\frac{4^{2}-4}{2} = 6$ points. And in fact you can find an example of lines intersecting in 0, 1, 3, 4, 5 and 6 points. All but 2. Obviously there isn't any way how four lines can intersect in two points. But how to prove it?","['recreational-mathematics', 'geometry']"
1887711,Definition of a slope of a straight line [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I am learning about the straight line and its slope was defined as ""rise over run"". Why not ""run over rise""? Was ""rise over run"" chosen arbitrarily or it was derived based on some physical relationship? Thanks in advance","['analytic-geometry', 'algebra-precalculus', 'definition', 'slope', 'graphing-functions']"
1887724,Probability that only one of the two husbands and only one of the two wives is retired.,"The members of a wine tasting club are married couples. For any married couples in the club, the probability that ""husband is retired "" $= 0.7$ , ""wife is retired"" $= 0.4$ , the probability that ""the husband retires given his wife retires"" $=0.8$ . Two married couples are chosen at random. Find the probability that only one of the two husbands and only one of the two wives is retired. My work: $P$ (Both of them are retired) = $0.32  $ $P$ (Only the husband is retired) = $0.38  $ $P$ (Only the wife is retired) = $0.08  $ $P$ (Only one of them is retired) = $0.46  $ So $P$ (Only one of two husbands and only one of the two wives is retired) = $$2 \times 0.38 \times 0.08 = 0.0608$$ But the answer says $0.2016$ . Why is it so?   I tried $P$ (Only one of them retired) $^2$ but this equals $0.2116$ and does not make sense since it also accounts for having both husbands retired or wives retired from two couples -- not one each. Many thanks in advance!","['statistics', 'probability']"
1887739,Categories which are dually equivalent to themselves.,"I'm new to category theory and I'm struggling to get an intuition for very basic concepts. Assuming the notation that we characterize dual equivalence for categories $A$ and $B$ by an equivalence functor ( $\Leftrightarrow$ full, faithful, isomorphism-dense/essentially surjective) between $A^{\text{op}}$ and $B$ . General questions: 1.a. Is there some deeper meaning to the property of a category to be dually equivalent to itself? I.e. has the sub-conglomerate of these categories in $\bf Cat$ important properties? 1.b. In what respect does dual equivalence of a category to itself generalize self-duality? Examples: 2.a. Are there some instructive examples for categories which are dually equivalent to themselves? Only the category of finite dimensional vector spaces and categories which are groupoids(even dually isomorphic to themselves) come to my mind (e.g. category of relations $\bf Rel$ , sets as objects, relations as morphisms). Counterexamples: So far it seems to me, that the categories of sets $\bf Set$ (and of finite sets $\bf FinSet$ ), topological spaces $\bf Top$ , magmas $\bf Mag$ , Semigroups $\bf Sem$ , sets structured with relations ${\bf Rel}_n {\bf Set}$ (sets with $n$ -relations as objects and maps perserving these as morphisms) are not dually equivalent to themselves since they have initial/terminal objects which aren't zero objects. 3.a. Why is the category of $\mathbb{k}$ -vector spaces ${\bf Vec}_{\mathbb{k}}$ not dually equivalent to itself? I would argue: Assume an equivalence functor $F: {\bf Vec}_{\mathbb{k}} \rightarrow {\bf Vec}_{\mathbb{k}}^{\text{op}}$ , $\aleph_0$ -dim. $V_0$ and $\aleph_1$ -dim. $V_1$ as ${\bf Vec}_{\mathbb{k}}$ -objects. To be full/faithful $F$ has to map infinite-dim. vectorspaces within their isomorphism-classes, i.e. $V_i\cong F(V_i)$ . But since equivalences preserve/reflect mono/epimorphisms I get a contradiction by duality: $\emptyset=\operatorname{epi}_{{\bf Vec}_{\mathbb{k}}}(V_0,V_1)\cong \operatorname{epi}_{{\bf Vec}_{\mathbb{k}}^{\text{op}}}(F(V_0),F(V_1))=\operatorname{mono}_{{\bf Vec}_{\mathbb{k}}}(F(V_1),F(V_0))\neq \emptyset$ . I would like to argue similarly for the category of groups $\bf Grp$ , but I have no idea about the general cardinality of hom-sets in $\bf Grp$ , so... 3.b. Why is the category of groups $\bf Grp$ not dually equivalent to itself? 3.c. What about the categories of monoids $\bf Mon$ ? 3.d. Are there more instructive counterexamples?","['category-theory', 'abstract-algebra', 'self-learning']"
1887759,What is the maximum number of quadrants in $n$ dimensional space that a $k$ dimensional hyperplane can pass through?,"Assume that the hyperplane passes through the origin i.e. it is the span of some $k$ linearly independent vectors in $n$-space. For example, for $n,k = 2,1,$ we have a line in the 2d plane passing through the origin, so the answer is 2. For $n,k=3,2$, it is 6. In fact, I have proven that $F(n,n-1)=F(n-1,n-2)+2^{n-1}$. This follows by considering the $(n-1)$-subspace for which one of the coordinates is 0. The intersection of this subspace with the hyperplane is an $n-2$ dimensional hyperplane which passes through the origin and $F(n-1,n-2)$ quadrants of the subspace. For each quadrant, the original hyperplane will at maximum pass through two corresponding quadrants of the $n$-space. And for each quadrant it does not pass through, the original can pass through at most one quadrant. The recurrence follows. But I am unable to extend this proof to general $k$, or even $n-2$. Any help is appreciated.","['linear-algebra', 'geometry']"
1887781,"$f$ entire but not polynomial then $\lim_{n\to\infty}\sup \{|z|:p_n(z)=0\}\to\infty$, where $p_n$ is $n-th$ Taylor series of $f$","Let $f(z)=\sum_{k=0}^{\infty}a_kz^k$ be entire and not a polynomial. Let $p_n(z)=\sum_{k=0}^n a_kz^k$ be its $n-th$ Taylor polynomial centered at $0$, and let $r_n=\sup \{|z|:p_n(z)=0\}$. Show that $\lim_{n\to\infty}r_n=\infty$ My thought: $\lim_{n\to\infty}p_n(z)=\lim_{n\to\infty}(z-a_1)(z-a_2)...(z-a_n)=f(z)$, then if $\lim_{n\to\infty}r_n\neq 0$, then this means the zeros of $f$ is bounded by a compact set, then ${z: f(z)=0}$ has a limit point in $\mathbb{C}$, so $f\equiv 0$, which is contradiction with $f$ is polynomial. I feel something is wrong in my proof above, but I can not tell what exactly is not right. Could someone kindly help me with this? Thank you so much!","['complex-analysis', 'analysis']"
1887793,Why use neighborhood to define boundary? Not open ball?,"One way to define a boundary point of set S is that ""every neighborhood of it contains at least one point of S and at least one point outside S"". I wonder if it's OK to replace ""neighborhood of it"" by ""open ball centered at it""? What's the difference? A further question is why introduce the concept ""neighborhood"" in the first place? Its role seems very similar to open balls.",['analysis']
1887794,Number of odd binomial coefficients is a power of $2$,"Prove that for any positive integer $n$, the number of odd integers among the binomial coefficients $\binom{n}{k}$ $(0 \leq k \leq n)$ is a power of $2$. I am thinking of trying to prove that the number of odd binomial coefficients is equal to 2 to the power of the number of $1$s in the binary form of $n$. How should I go about proving this?",['number-theory']
1887854,Constructive proof that countably infinite-dimensional normed vector space is incomplete,"I'm familiar with the standard proof that there exists no $\mathbb{N}$-dimensional Banach space based on Baire: Let $\{ v_{K} : k \in \mathbb{N} \}$ be a normalized basis for $V$, and let $W_{\ell} = \mathbb{R} v_{1} + \cdots + \mathbb{R} v_{\ell}$. Then $V = \cup_{\ell \in \mathbb{N}} W_{\ell}$. Moreover, $W_{\ell}$ is closed, so $X_{\ell} = V \setminus W_{\ell}$ is open. Also, $X_{\ell}$ is dense. To show it's dense, let $v = \sum _{k = 1}^{m} r_{k} v_{k} \in V$, where $r_{m} \neq 0$. If $m > \ell$, then $v \in V \setminus W_{\ell}$. If not, let $\epsilon > 0$; then $v + \frac{\epsilon}{2} v_{\ell + 1} \in X_{\ell} \cap N(v, \epsilon)$. Baire tells us that $\cap_{\ell \in \mathbb{N}} X_{\ell}$ is dense, but it is in fact empty, a contradiction. My question is: Can the argument be made constructively? Do we need BCT to show there exists no $\mathbb{N}$-dimensional Banach space? Can we instead make a diagonalization argument, i.e. construct a Cauchy sequence that doesn't converge in $\operatorname{span} \{ v_{k} : k \in \mathbb{N} \}$? Perhaps further, is the result dependent on BCT? That is, does the result imply BCT? Thanks in advance.","['constructive-mathematics', 'banach-spaces', 'linear-algebra']"
1887892,Evaluate $\int_\frac12 ^2 \frac1x\tan(x-\frac1x)dx $ [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question $$\int\limits_\frac{1}{2} ^2 \frac{1}{x}\tan\left(x-\frac{1}{x}\right)\mathrm{d}x$$ I have tried substitution and by parts and it seems failed at all. Can anyone give me some hints?",['integration']
1887906,Is a limit point in a sequential space the limit of some sequence?,"I am following this Wikipedia entry .
Let $X$ be a topological space and $S \subseteq X$ an arbitrary subset.
A point $x \in X$ is a limit point of $S$ if every neighborhood $U$ of $x$ contains a point of $S$ different from $x$ (that is $U \cap S \setminus \{ x \} \neq \emptyset$) or equivalently $x \in \textrm{cl}(S \setminus \{ x \})$. Wikipedia states that: Alternatively, if the space $X$ is sequential, we may say that $x \in X$ is a limit point of $S$ if and only if there is an $\omega$-sequence of points in $S \setminus \{ x \}$ whose limit is $x$; hence, $x$ is called a limit point. Is this statement true? It is clearly true for first-countable spaces $X$: take a countable neighborhood base $U_n \subseteq X$ of $x$ and a point $x_n \in U_n \cap S \setminus \{ x \}$. Then we have the desired convergent sequence $x_n \to x$. More generally, the statement is true for Fréchet-Urysohn spaces $X$ since then the closure $\textrm{cl}$ equals the sequential closure $\textrm{scl}$, i.e. $\textrm{cl}(S \setminus \{ x \}) = \textrm{scl}(S \setminus \{ x \})$ implying that for the limit point $x$ of $S$ there is the desired sequence $x_n \in S \setminus \{ x \}$ with $x_n \to x$. If $X$ is merely sequential (i.e. a set is closed iff it is sequentially closed) then from $S \setminus \{ x \}$ being not closed we can only deduce that $S \setminus \{ x \}$ is not sequentially closed implying that there is a sequence $x_n \in S \setminus \{ x \}$ converging to some point $y \not\in S \setminus \{ x \}$. But $y$ needs not be equal to the given point $x$.",['general-topology']
1887911,Maximizing $|f'(0)|$ of an analytic function with $f(1/2)=0$.,"Let f be an analytic function from the unit disk D to the unit disk D. Assume that $f(1/2)=0$, prove $|f'(0)| \leq 25/32$. I am currently stucked with this problem. I have tried adding some conformal self-map g of the unit disk so that $fg(0)=0$ to apply Schwarz lemma,but this only gives upper bound for $|f'(1/2)|$. Is there any other approach for this problem?","['complex-analysis', 'inequality', 'optimization']"
1887945,Are telescoping sums related to the fundamental theorem of calculus?,"I just noticed that
$$\sum_{i=1}^n (a_i - a_{i-1})=a_n-a_0$$
and
$$\int_a^b f'(x)\mathrm{d}x=f(b)-f(a)$$
look really similar.
We can consider $a_i-a_{i-1}$ a discrete analog to the derivative of continuous functions. Is there anything deep between those equations?","['algebra-precalculus', 'calculus']"
1887991,Meaning of $^*$ after a set?,"I'm reading this Wolfram page about Disjoint Unions. It shows sets $A$ and $B$ with $^*$ after them. This operator converts each element to an ordered pair and assigns $0$ or $1$ to $b$ of the ordered pair $(a,b)$. I've not encountered this before. I Googled and found Kleene Star and free monoids but it didn't seem to match this operator, although I didn't understand the information at all! Is there anything more to read about this $^*$ operator, or is it just some local, convenient notation on the Wolfram page?","['notation', 'elementary-set-theory']"
1888049,Use of differential equations for modeling population which is a discrete variable,"Population dynamics is often modeled using ODE. For example one common model is logistic growth model: $$\frac {dx}{dt} = kx\left(1-\frac{x}{C}\right)$$ where $x$ is population size, $k$ is rate constant for growth, $C$ is carrying capacity. But population is a discrete variable. It is not continuous. It always takes whole numbers. You can have a population of 3000 fishes, but not 3001.2 fishes. Then how can one use population as a dependent variable in a differential equation? Integration of the ODE, given above, will give me a function to calculate size of population, $x_t$, at time $t$, when size of the population at $t = 0$, was $x_0$. We can specify a whole number for $x_0$. But, $x_t$ can be a real number with fraction. But a population size is always a whole number. How does one tackle this anomaly?","['biology', 'ordinary-differential-equations', 'mathematical-modeling']"
1888053,What does the symbol $\sqsubset$ mean? Is it the same as $\subset$? [duplicate],"This question already has answers here : Does $\sqsubset$ have any special meaning? (2 answers) Closed 7 years ago . I have tried looking for this symbol but I found the definition for latter only. Hence, I have this doubt if these two are same. If not, can anyone please let me know the difference? Thanks a lot.","['notation', 'elementary-set-theory']"
1888061,How can I find all solutions to differential equation?,"How one can find all functions $f$ that there exists $f'$ satisfying $(f(x))^2+(f'(x))^2=1$? I just found solutions $f(x)=1,-1,\sin x$.",['ordinary-differential-equations']
1888126,Seeing $PSL_2(\mathbb{C}) \cong SO_3(\mathbb{C})$,"How can I see the isomorphism between projective special linear group (order 2) and the special orthogonal group (order 3)? I know only this setting $PSL_2(\mathbb{C}) = SL_2(\mathbb{C})/Z(SL_2(\mathbb{C})$, but it has not helped me a lot.","['matrices', 'group-isomorphism', 'exceptional-isomorphisms', 'group-theory', 'lie-groups']"
1888236,$.99999...=1$: What is the proof that we can multiply an infinite series by something to shift it?,"I wanted to prove to myself that $.9999... = 1$ so I wanted to show that: $N = 9/10 + 9/100 + 9/1000 + 9/100000 + ...$ or more formally, $N = 9S$ where $S = \sum_{k=1}^{\infty} \frac{1}{10^k}$ Then multplying by $10$ I get $10S = \sum_{k=1}^{\infty} \frac{1}{10^{k-1}} = \sum_{k=0}^{\infty} \frac{1}{10^{k}}$ Subtracting I get $10S - S = \sum_{k=0}^{\infty} \frac{1}{10^k} -  \sum_{k=1}^{\infty} \frac{1}{10^{k}} = \frac{1}{10^0} = 1$ So if $9S = 1$, then $S = 1/9$, and $N = 9S = 1$, proof completed. Is this proof correct? What is it exactly that allows me to multiply an infinite series by $10$ and have it be a valid transformation? To my ""ignorant intuition"" this seems like taking something infinite and making it $10$ times infinity, which I don't know what that really means. What is it that allows me to shift indexes like I did to move $k$ down from $1$ to $0$? Similar to question 2 above. We shift and yet do not have to touch or manipulate the upper bound of infinity at all. I know that ""infinity minus one"" is sort of a weird notion but I don't understand what it means or why we can default it back to infinity, whereas in any other context when we change bounds we change them on both lower and upper.","['power-series', 'infinity', 'sequences-and-series', 'proof-explanation']"
1888243,Prove that real numbers and irrational numbers are numerically equivalent. [duplicate],"This question already has answers here : Is there a simple, constructive, 1-1 mapping between the reals and the irrationals? (7 answers) Let $A$ be any uncountable set, and let $B$ be a countable subset of $A$. Prove that the cardinality of $A = A - B $ (4 answers) Closed 7 years ago . How do I prove that set A and set A/C are numerically equivalent,where A is uncountable set and C is countably finite subset of A. This can be further used to show that real numbers and irrational numbers are numerically equivalent. I am aware of the fact that,what are uncountable and countably infinite sets and also the meaning of numerically equivalent.I am not able to create the required bijection.",['elementary-set-theory']
1888244,How does uncertainty of dataset propagates through numerical integration?,"In the following text, uncertainty refers to standard deviation. I have 500 time series which I use in a few equations and get averages and uncertainties. Through calculations for each time series, I end up with a data set with 500 values of the position z, the resistance $R(z)$, the absolute and the relative uncertainty:
$$  z \,,  R( z )  \,, \pm \Delta R(z) \,, \pm \frac{\Delta R(z)}{ R(z) }$$ What I want is to calculate the permeation $P$ through the following formula:
$$ P=\frac{1}{\int_{z_{min}}^{z_{max}}R(z)dz} $$ therefore, I need to numerically integrate these 500 values. This is easy with a trapezoidal but the question is what happens to the uncertainty? How does it propagate through the integral? Essentially I want to report the average $ \left( P \pm \Delta P \right) \, [units]$","['numerical-methods', 'integration', 'error-propagation']"
1888314,Notion of a normal operator,"I understand that a normal operator is an operator such that $$
AA^\dagger = A^\dagger A
$$
where $\dagger$ is the conjugate transpose. However, what is the most intuitive way to ""characterise"" this? For example, $SO(3)$ is the group of rotations in $\mathbb R^3$ A unitary matrix is one that represents an isometry A hermitian matrix is a generalization of symmetric, and is the ""nicest"" (diagonalizable, real eigenvalues, etc) of all matrices over $\mathbb C$ I was hoping for some sort of intuitive explanation of why I would care about normal matrices over $\mathbb C$ (maybe other reasons than the spectral theorem? Something more fundamental / geometric perhaps)","['functional-analysis', 'representation-theory', 'linear-algebra']"
1888336,Which of the following facts are true of a sequence satisfying $\lim a_n^{\frac{1}{n}}=1$?,"Let $a_n$ be a sequence of non-negative numbers such that $$\lim a_n^{\frac{1}{n}}=1$$ Which of the following are correct? $\sum a_n$ converges $\sum a_nx^n$ converges uniformly on $[-\frac{1}{2},\frac{1}{2}]$ $\sum a_nx^n$ converges uniformly on $[-1,1]$ $\lim \sup\frac{a_{n+1}}{a_n}=1$ My effort : 1.false ,consider $a_n=n$ 2.true,The radius of convergence of  a power series $\frac{1}{R}=\lim a_n^{\frac{1}{n}}=1\implies R=1$ .Hence the series converges uniformly for compact sets inside $|x|<1$ .Hence the series converges uniformly in $|x|\leq 0.5$ 3.false ,putting $x=1$ the same as in case 1. 4.I am unable to prove this fact.How to solve this .","['sequences-and-series', 'convergence-divergence']"
1888337,"If $f,g$ are continuous and $g$ is $1$-periodic, $\int_0^1 f(x)g(nx)dx \xrightarrow[n\to\infty]{} \int_0^1 f \int_0^1 g$ [duplicate]","This question already has answers here : integral involving a periodic function (3 answers) Closed 6 years ago . Let $f,g\in C(\mathbb{R},\mathbb{R})$ where $g(x+1)=g(x) \; \forall x\in \mathbb{R}$. Prove that
\begin{equation} \lim_{n\rightarrow\infty} \int_0^1 f(x)g(nx)dx=\int_0^1f(x)dx \int_0^1g(x)dx . \end{equation}","['periodic-functions', 'limits', 'continuity', 'integration', 'lebesgue-integral']"
1888375,Uniformly convergence of $f_{n+1}(x)= \int^x_0 f_n(t)dt$,"Let $f_0$ be integrable function on $[0,a]$ and a sequence of functions $f_{n+1}(x)= \int^x_0 f_n(t)dt$. 
   Show that $f_n$ is uniformly convergent on $[0,a]$ to $0$. I get so far is if $\int_0^xf_0(t)dt =x_0 $ so $\int_0^xx_0dt=xx_0 $ and $f_n(x)=x^nx_0  $ so  $f_n(x) \to 0$ for $x\in[0,1) $ but I don't know if it uniformly and what happen for $a>1$ ? Thanks ahead.","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
1888473,Calculating Fibonacci numbers [duplicate],This question already has answers here : How are we able to calculate specific numbers in the Fibonacci Sequence? (8 answers) Closed 7 years ago . In my book they calculated the $28$th Fibonacci number and said $F_{28} = 3 \times 13 \times 19 \times 281 = 317811$. This made me wonder if there was an easier way to find the $28$th Fibonacci number than by doing it by hand.,"['number-theory', 'fibonacci-numbers']"
1888503,Solution of $ydx-xdy+3x^2y^2e^{x^2}dx=0$,Find the solution of given differential equation: $$ydx-xdy+3x^2y^2e^{x^2}dx=0$$ I am not able to solve this because of $e^{x^2}$. Could someone help me with this one?,"['ordinary-differential-equations', 'calculus']"
1888504,Square as union of two disjoint connected sets containing opposite corners,"Question: Given the unit square $[0,1] \times [0,1]$ Write it as the union of two disjoint connected sets $A, B$, $A$ must
  contain $(0,0),(1,1)$, $B$ must contain $(0,1), (1,0)$ Not sure if this can actually be done. I went for the obvious solution: Let $A = \{(x,x) | x \in [0,1]\}$, $B = ([0,1] \times [0,1]) \backslash A$. Then $A,B$ contains the desired points. $A$ is connected because it is homeomorphic to $[0,1]$, a connected space. What about the connectedness of $B$? Well, obviously it is not connected. What other possibility could there be?","['general-topology', 'connectedness', 'proof-verification', 'problem-solving']"
1888514,"If y=y(x) and $\frac{2+sin(x)}{y+1}\frac{dy}{dx}=-cosx,y(0)=1$, then find $y(\frac{\pi}{2})$.","Question: If y=y(x) and $\frac{2+sin(x)}{y+1}\frac{dy}{dx}=-cosx,y(0)=1$, then find $y(\frac{\pi}{2})$. My attempt:- $$\frac{2+sin(x)}{y+1}\frac{dy}{dx}=-cosx$$
$$\frac{dy}{1+y}=-\frac{cos(x)}{2+sin(x)}dx$$
Integrating both sides
$$\int\frac{dy}{1+y}=-\int\frac{cos(x)}{2+sin(x)}dx$$
$$log(1+y)=-log(2+sin(x))+C$$
$$log(1+y)=log(\frac{1}{2+sin(x)})+C$$
Antilog on both sides
$$1+y=\frac{1}{2+sin(x)}+C$$
$$y=\frac{-1-sin(x)}{2+sin(x)}+C$$
Now it is given that $y(0)=1$
So $$y(0)=1=\frac{-1-sin(0)}{2+sin(0)}+C$$
$$1=\frac{-1}{2}+C$$
$$C=\frac{3}{2}$$
$$y(\frac{\pi}{2})=\frac{-1-sin(\frac{\pi}{2})}{2+sin(\frac{\pi}{2})}+C$$
$$y(\frac{\pi}{2})=\frac{-2}{3}+\frac{3}{2}$$
$$y(\frac{\pi}{2})=\frac{5}{6}$$ But the answer happens to be $\frac{1}{3}$.",['ordinary-differential-equations']
1888516,"Finding the value of ${_2F_1}\left(\frac12,\frac12;\ 1;\ 1/9\right)$","I need help finding the value of
$${_2F_1}\left(\frac12,\frac12;\ 1;\ \frac{1}{9} \right)\tag1$$ Not in terms of elliptic functions. I've tried many methods on this and have reduced it down to many forms, none of which have provided any help to me, however I think they may be of some use here. We have the identity
$${_2F_1}\left(a,1-a;1;\ z\right)= P_{-a}(1-2z)$$
Which leads to $(1)$ being equal to 
$$\frac{2 \operatorname{K}({1/9})}{\pi}^*$$ Where $\operatorname{K}(x)$ is the Complete Elliptic Integral of the First Kind . This is technically a closed form, but I would prefer to find a closed form not in terms of elliptic integrals - since elliptic integrals can be expressed in the form ${_2F_1}\left(\frac12,\frac12;\ 1;\ x^2\right)$ this closed form feels awful circular. It also seems to be equal to
$${_2F_1}\left(\frac14,\frac34;\ 1;\ 9/25 \right)\frac{3}{\sqrt{10}}$$ and many other equivalent but seemingly useless forms that can be computed using (1) (2) I've gotten tantalizingly close but haven't been able to crack it. What is the closed form for this hypergeometric function, if there is one? *Also, this is probably a very stupid question, but on both Wolfram Mathworld and Wikipedia they claim ${_2F_1}\left(\frac12,\frac12;\ 1;\ k^2\right)=\operatorname{K}(k)$ which means $(1)$ should be equal to $\operatorname{K}(1/3)$ but Wolfram Alpha and Mathematica both seem to say ${_2F_1}\left(\frac12,\frac12;\ 1;\ k\right)=\operatorname{K}(k)$","['special-functions', 'hypergeometric-function', 'calculus', 'closed-form']"
1888529,Connection between the Kalman filter and the multivariate normal distribution,"Consider at dynamic linear model where $$ \theta_{1} \sim N(\mu_{1}, W_{1}), $$ $$ \theta_{i}=G\theta_{i-1} + w_{i}, w_{i}\sim N(0,W), $$ $$ Y_{i} = F\theta_{i} + v_{i}, v_{i}\sim N(0,V) $$ and $ \theta_{1}, w_{i}, v_{i} $ all independent random vectors. Let $ \theta_{0:t} : = (\theta_{t}, \theta_{t-1},\ldots, \theta_{0}) $ and $ Y_{1:t}:= (Y_{t},Y_{t-1},\ldots, Y_{1})$. A generel result from multivariate normal distribution is as follows: Suppose $ Y|X=x \sim N(Ax,V)$ and $ X \sim N(\mu, \Sigma) $. Then $ Y\sim(A\mu, A\Sigma A^{T} + V) $. Question 1: How do I see, that the joint density of $ (\theta_{0:t}, Y_{1:t}) $ is Gaussian? From the definitions above, we have $Y_{t}|\theta_{t}$ is normal and $\theta_{t}|\theta_{t-1}$ is normal. From the general result the joint densities of $(Y_{t},\theta_{t})$ and $(\theta_t, \theta_{t-1})$ is also normal. In fact, since a dynamic linear model is also a state space model, it can be shown (and I have) that $$p(\theta_{0:t}, y_{1:t}) = p(\theta_0)\prod_{j=1}^{t}p(y_j | \theta_j)p(\theta_j  | \theta_{j-1}).$$ But I can not complete the puzzle; i.e why is $ (\theta_{0:t}, Y_{1:t}) $ is Gaussian? Question 2: Assume we know  $$ \theta_{n-1}\mid Y_{1:n-1} = y_{1:n-1} \sim N(\hat \theta_{n-1}, \Sigma_{n-1}).$$ Now, how do I apply the generel result stated above, to see that $$ \theta_{n}\mid Y_{1:n-1} = y_{1:n-1} \sim N(G\hat \theta_{n-1}, G\Sigma_{n-1}G^{T} + W).$$ Of course we have $E[\theta_n | Y_{1:n-1}] = G\hat \theta_{n-1}$ and $Var[\theta_n | Y_{1:n-1}] = G\Sigma_{n-1}G^{T} + W$. But I am not sure why $\theta_{n}\mid Y_{1:n-1}$ is normally distributed. My guess is, that I can apply the result about linear combinations of Gaussians is again Gaussian.","['kalman-filter', 'probability', 'normal-distribution']"
1888532,What's condition of cubic polynomial to represent an ellipse-like closed curve?,"I know the condition for quadratic polynomial to be an ellipse-like closed convex curve is $$ b^2-4ac < 0, $$ where $f(x,y) = ax^2+bxy+cy^2+dx+ey+f = 0.$ Then what's the same condition for cubic polynomial such as following? \begin{equation}
f(x,y) = a_1x^3+a_2x^2y+a_3xy^2+a_4y^3+ a_5x^2+\\a_6xy+a_7y^2+a_8x+a_9y +a_{10} = 0
\end{equation} I was guessing the condition might be that determinant of $f''(x,y)$ matrix be less than 0, but as element of $f''(x,y)$ are involving terms of $x$ and $y$, I don't think my guess is correct. Any hint would be appreciated. Added some background below for your convenience. I was estimating egg-shape curve with cubic polynomial. And sometimes, the estimation is good. And in some cases, it's bad although the two datasets are similar. This led to my question. UPDATE Thanks to people's effort on this question, I was able to clear my mind and decided to impose conditions from the original model (distorted quadratic curve if not rotated) I was trying to estimate. Now, I am using constrained cubic polynomial.","['convex-analysis', 'algebraic-geometry']"
1888539,Hartshorne 3.8.1,"I am stuck on the following exercise in Hartshorne (Chapter III, 8.1): $\hspace{3mm} $ ""Let $f:X \to Y$ be a continuous map of topological spaces. Let $\mathcal{F}$ be a sheaf of abelian groups on $X$ and assume that $R^if_*(\mathcal{F})=0$ for all $i>0.$ Show that there are natural isomorphisms, for each $i \geq 0,$ $$H^i(X,\mathcal{F}) = H^i(Y, f_*\mathcal{F}).""$$ Idea: It seems like Hartshorne would like me to take an injective resolution of $\mathcal{F},$ apply $f_*,$ and argue that this gives me an injective resolution of $f_*\mathcal{F}.$ The vanishing of $R^if_*\mathcal{F}$ ensures that $f_*$ is an exact functor and hence the cohomology groups will agree. The only problem is that I don't see why $f_*$ preserves ""invectiveness"" of my resolution.","['sheaf-theory', 'algebraic-geometry']"
1888575,Line bundle on a product,"Let X and T be projective varieties, with $H^1(\mathcal{O}_X)=0$. Take L a line bundle on the product. Prove that for any two points $t,t'$ of T, the pullbacks $L_t, L_{t'}$ to $X\times t, X\times t'$ are isomorphic line bundles on X. I am completely stuck and I don't even undeerstand how to use  the hypothesis in cohomology. If someone posts an hint I can try to elaborate.","['projective-schemes', 'algebraic-geometry']"
1888604,Can every prime (greater than $5$) be expressed in the form $30m+n$?,"Let
$$
T = \{ 1, 7 , 11 , 13 , 17 , 19 , 23, 29 \}
$$ Can every prime $p > 5$ be expressed in the form $30m+n$, where $m\geq 0$ and $$n is a element of set $T$? For example 
Prime number $37$ is expressed as $30\times 1+7$ where $7$ is a element of set. I did check untill $1000$ to find counterexample for this statement. But i can't find it. If it is true, please help me to prove it.","['number-theory', 'prime-numbers']"
1888608,"With two subgroups of a group $G$, does one being a subset of the other imply being a subgroup of it?","Let $(G,\ast,e)$ be a group, and $(H,\ast,e)$ and $(K,\ast,e)$ be subgroups of $G$. If $K\subseteq H$, is $K \leq H$ ? With the subgroup test, it seems trivial, but I just want to make sure I'm not making some stupid mistake, as I'm using this for another proof that's causing me to question everything.","['abstract-algebra', 'group-theory']"
1888613,Are the geodesics of $SO(n)$ rotation in a plane?,"In what follows, I use "" rotation "" in a sense more closely mirroring that of everyday usage -- specifically I mean a smooth path between two elements of $SO(n)$ (since in everyday usage a rotation means progressing through all intermediate states between the initial and final states (see for example pp. 52-53 of Stillwell's Naive Lie Theory , which inspired this question, in part). Without loss of generality, let the smooth path begin at $Id \in SO(n)$ and end at some arbitrary $C \in SO(n)$ -- this is because, given any smooth path $A \to B$ , we can get a path $Id \to A^{-1} B$ by taking the left action of $A^{-1}$ which is a homeomorphism (and even a diffeomorphism, I think). Question: Do the geodesics of $SO(n)$ correspond to our ""intuitive sense"" of rotations in $\mathbb{R}^3$ , i.e. the original position and the final position being separated by rotation through a single plane, as opposed to the possibility of having to compose multiple rotations occurring in multiple planes? Remember that I am only concerned with the geodesic path between two elements of $SO(n)$ here, the fact that the path is a geodesic meaning to imply that it is in some sense the ""natural"" path of intermediate states to rotate through in order to arrive at one position from another. It would make some sense if this were the case, because then any such path would be an embedding of part of $SO(2)$ (the unit circle) into $SO(n)$ , and $SO(2)$ is one-dimensional, thus an embedding of a compact subset of it into $SO(n)$ could conceivably be a path. I am not quite sure how to phrase this question in a rigorous manner, although I have tried -- please let me know if anything is still unclear so that I can correct and improve the clarity of the question.","['geodesic', 'differential-geometry', 'lie-groups']"
1888635,Calculating the infinite sum of one over the odd numbers squared: $\sum_{i \ge 0} \frac{1}{(2i+1)^2}$,"Can someone tell me how to calculate the following infinite sum?
$$
(1/1^2)+(1/3^2)+(1/5^2)+(1/7^2)+(1/9^2)+(1/11^2)+ \cdots
$$ Don't give me the answer. Can you tell me if this is a geometric series?",['sequences-and-series']
1888653,Developing Intuition for the Monster Group,"Here is my context. I recently finished my undergraduate studies and am moving on to graduate work. I have learned up to and including the Sylow theorems, group actions, and conjugacy classes. Over two summers, I tried to read Conway's Sphere Packings, Lattices and Groups, as well as Wilson's Finite Simple Groups; however, I did not get far in either as my prerequisite knowledge seemed lacking. So far, I've learned how to construct the extended Golay Code from the hexacode (using the MOG), and the Leech Lattice from the extended Golay Code. Parker's Loop is a little beyond my understanding as well as the Golay Cocode. My goal is it learn enough to have a relatively modern understanding of the monster group even if it takes me several years or longer. Currently, I am lost on how to pursue this goal. I do not know which books to read and in what order. I am looking for a step by step guide (or a way to learn how to best make my own) in terms of books to read (preferably in an ascending order of difficulty and relevance to the monster group). Any tips and warnings from those who have a modern understanding would be helpful as well. Thanks for the help.","['intuition', 'finite-groups', 'reference-request', 'simple-groups', 'group-theory']"
1888658,Probability that a player wins a card guessing game,"$ \textbf{Question:} $ A card game consists of $ n $ cards $ (n \ge 1), $ one of which is a special card. The cards are shuffled randomly and then turned over one at a time. At any time, a player must guess whether the current card is the special card before it is revealed. The player wins when he correctly guesses the special card. What is the probability that the player wins the game? I approach this problem by letting $ E $ be the event that the current card is a special card and $ F $ be the event that the player will guess the current card is the special card, so finding the probability that the player wins the game means finding the probability that both $ E $ and $ F $ occur. Now I have $ \displaystyle P(EF) = P(E)P(F|E) $ with $ \displaystyle P(E) = \frac{1}{n}, $ but I don't know how to compute $ P(F|E). $ It seems reasonable (to me) that $ P(F|E) = 1 $ since once the player knows apriori that the current card is the special card, he will just make the guess. Suppose that the problem provides an extra information that at any time, the probability that the player guesses the current card is the special card is $ 30\% $ (meaning $ P(F) = 0.3), $ will that change the value of $ P(F|E) $ from $ 1 $ to $ 0.3? $",['probability']
1888669,What is the difference between an algebraic and a complex analytic variety?,"I have some simple questions about scheme theory which are not clear in my mind : $1)$ What is the difference between a scheme $X$ or, a $ \mathrm{Spec} \mathbb{Z} $ - scheme : $ X $, and a $ Y $ - scheme $ X $ or a scheme $ X $ over a scheme $ Y $ ? Who's big and general ?. $ 2) $ What is the difference between a scheme $ X $ and a scheme which takes the form : $ X(L) = \mathrm{Hom}_k ( k[T_1 , \dots , T_n ] / ( P_1 , \dots , P_r ) , L ) $
$ \simeq \{ (x_1 , \dots , x_n ) \in L^n \ \mathrm{t.q.} \ P_1 (x_1 , \dots , x_n ) = ... = P_r ( x_1 , \dots , x_n ) = 0 \} $ 
? Who's big and general ? $ L $ is an extension of the base field $ k $. $ 3) $ If $ X $ is an integral scheme of finite type, over $\mathbb{Q}$, then $ X(\mathbb{Q} ) $ is a $ \mathbb{Q} $ - scheme, and $ X( \mathbb{C} ) = X $, right ? why are $ X(\mathbb{Q}) $ an algberaic variety and $ X(\mathbb{C} ) $ a complex analytic variety ? When $ X $ is more general than an integral scheme of finite type over $\mathbb{Q}$, what is the difference between $ X $ and $ X( \mathbb{C} ) $ ? In other words, How can we construct, or what is the nature of a point $ x \in X \backslash X( \mathbb{C} ) $ ? Thanks in advance for your answers and for your patience.  :-)","['schemes', 'algebraic-geometry']"
1888684,"Is $[0,1]^2$ with the dictionary order topology separable? First countable?","I have question about order square $I^2_0$ which is $[0,1]\times[0,1]$ with dictionary order 
this is what I know about it: compact Hausdorff, hence normal and regular as well. and also it is Lindelof. Therefore, it is not second countable, and metrizable (the  argument is not difficult) just by playing by theorems. However, I want to whether or not it is separable. I do it by way of contradiction. suppose it is separable we know that each open subspace of separable is separable. let $Y$ be a space of $X$ and $Y=(0,1)\times(0,1)$ it is open. For each $x\in{Y}$ there exist $U_x={x}\times(0,1)$. It makes the subspace $Y$ not separable. my question is Is my argument about separable correct? 
 and also how about first countable?","['general-topology', 'order-topology', 'proof-verification']"
1888714,Why is the area of a circle not $2 \pi R^2$?,"Let $$ C=\{(x,y,z)\mid x^2+y^2=1,  0 \le z \le 1\} $$ Counter-calculus, my intuition says that the area of a circle with radius $r$ should be $2 \pi \cdot R^2$, because I think that if all radii segments are to be raised perpendicularly to the perimeter of the unit circle (at plane $xy$), then the area is preserved. I know I am wrong but I don't (qualitatively) understand why (note I never learnt measure theory).","['circles', 'geometry']"
1888725,"Transforming one list of numbers into another by a sequence of ""moves""","Given two unordered lists of integers, both of length $n$, named $X$ and $Y$, how would one find the minimum number of moves required to transform the elements of $X$ into the elements of $Y$ ? Ordering doesn't matter in the sense that the modified version of $X$ has to be a permutation of $Y$. A move consists of picking elements from the $X$ list at indexes $i,j$ where $i \neq j$ and incrementing $x_j$ by $1$ while decrementing $x_i$ by $1$. I've checked out a similar problem that was meant to find a minimal number of moves done in order to equalize an array, but that doesn't feel helpful here. Any ideas?","['algorithms', 'optimization', 'discrete-mathematics']"
1888727,Triangles on a Torus,"This is a really basic question, which draws as its source two of the pictures from the Wikipedia article about Gaussian curvature . If it is true that the sum of the angles of a triangle on a surface of negative Gaussian curvature is less than 180 degrees (as it says on Wikipedia), and that the sum of the angles of a triangle on a surface of positive Gaussian curvature is more than 180 degrees (which I believe is the case for a sphere, I think the sum is 270 degrees), then: Since the inside of a torus supposedly has negative Gaussian curvature, and the outside supposedly has positive Gaussian curvature, does a triangle inscribed on the inside of a torus have a sum of angles less than 180 degrees while a triangle inscribed on the outside of a torus have a sum of angles greater than 180 degrees? By ""inside"" I mean ""closer to the donut hole"" and by ""outside"" I mean ""away from the donut hole"". Thus an ""ant walking on a torus"" could tell precisely when it arrived ""at the highest point"" of the torus (the circle on the torus where every point has zero Gaussian curvature which divides the above two mentioned regions of positive and negative curvature) when the triangles it is drawing on the ground have a sum of angles of precisely 180 degrees? Also does this mean that the torus essentially has both elliptic and hyperbolic geometries, depending on which side the ant is walking on? I was thinking about this question because I was trying to think of examples of closed surfaces which have negative Gaussian curvature over an extended region, because it is not possible for the surface to be closed and have negative curvature everywhere and be embeddable in $\mathbb{R}^3$ , see: existence of closed surface having only negative Gaussian curvature. https://mathoverflow.net/questions/111101/surfaces-in-mathbb-r3-with-negative-curvature-bounded-away-from-zero https://mathoverflow.net/questions/32597/compact-surfaces-of-negative-curvature","['differential-geometry', 'soft-question']"
1888729,How is that $S^1$ is not contractible?,"It is stated in Wikipedia (and other pages too) that the spheres $S^n$ are all not contractible. Take $n=1$. Would anyone explain to me why $$S^1\times [0,1]\to S^1$$$$(e^{2\pi i t},s)\mapsto e^{2\pi i ts}$$is not an homotopy between the identity and a point?",['general-topology']
1888732,A question about substitute equivalent form into limit: $\lim_{x\to \infty} \sqrt{x^2+x+1}-\sqrt{x^2+3x+1} = -1$,"When I had the calculus class about the limit, one of my classmate felt confused about this limit: $$\lim_{x\to \infty} \sqrt{x^2+x+1}-\sqrt{x^2+3x+1} = -1$$ What he thought that since $x^2 > x$ and $x^2 > 3x$ when $x \to \infty$ so the first square root must be $x$ and same for the second. Hence, the limit must be $0$ . It is obviously problematic. And what I thought is that make prefect square under the limit, though I know the right solution is to rationalize the numerator. After perfect-squaring, $$\lim_{x\to \infty} \sqrt{\left(x+\frac{1}{2}\right)^2+\frac{3}{4}}-\sqrt{\left(x+\frac{3}{2}\right)^2-\frac{5}{4}}$$ I assert that since there is a perfect square and a square root. As $x \to \infty$ , the constant does not matter. So $$\lim_{x\to \infty} \sqrt{\left(x+\frac{1}{2}\right)^2+\frac{3}{4}}-\sqrt{\left(x+\frac{3}{2}\right)^2-\frac{5}{4}}= \lim_{x\to \infty} \sqrt{\left(x+\frac{1}{2}\right)^2}-\sqrt{\left(x+\frac{3}{2}\right)^2}\\ = \frac{1}{2}-\frac{3}{2} = -1 $$ But when I conquer this limit: this post . Here is my argument: $\sqrt{ax^2+bx+c} =O(\sqrt a(x+\frac{b}{2a}))$ when $x \to \infty$ $$\lim_{x\to\infty}\frac{\sqrt{x^2-2x+3}+\sqrt{4x^2+5x-6}}{x+\sqrt{x^2-1}} =\frac{x-1+2(x+5/4)}{x+x}  = \frac{3}{2}$$ Very concise get this answer but it gets downvoted. I do not know what is wrong with my strategy. But in general case: for instance this problem about cubic root my strategy seems to work really efficient: $$\lim_{x\to \infty} \sqrt[3]{x^3+6x^2+9x+1}-\sqrt[3]{x^3+5x^2+x+1}$$ My solution is: $$\lim_{x\to \infty} \sqrt[3]{x^3+bx^2+cx+d} = \lim_{x\to \infty} \sqrt[3]{\left(x+\frac{b}{3}\right)^3}$$ So the limit becomes: $$\lim_{x\to \infty} \sqrt[3]{(x+2)^3+O(x)}-\sqrt[3]{\left(x+\frac{5}{3}\right)^3 + O(x)} =\lim_{x\to \infty}  (x+2) -\left(x+\frac{5}{3}\right) = \frac{1}{3} $$ This result gets verified by wolframalpha . To put all into a nutshell, what is wrong with my solution to these three problem. Is there any counterexample to this substitution. Any help, you will be appreciated.","['radicals', 'calculus', 'limits']"
1888773,What is $\sqrt{-4}\sqrt{-9}$? [duplicate],"This question already has answers here : Why $\sqrt{-1 \cdot {-1}} \neq \sqrt{-1}^2$? (14 answers) Closed 4 years ago . I assumed that since $a^c \cdot b^c = (ab)^{c}$, then something like $\sqrt{-4} \cdot \sqrt{-9}$ would be $\sqrt{-4 \cdot -9} = \sqrt{36} = \pm 6$ but according to Wolfram Alpha, it's $-6$?","['algebra-precalculus', 'complex-numbers']"
1888786,"Why every positive integer can be written as addition of 1 triangle number, 1 square number, and 1 pentagonal number","I find this interesting conjecture, maybe I'm not the first to state this conjecture. I have tested this conjecture to $100.000$ first positive integers (then my friend at Brainden forum tested it to 1 trillion), but test result is not the prove.
Anybody can provide the prove or disprove this conjecture ? the conjecture is : Every positive integer can be written as addition of 1 triangle number, 1 square number, and 1 pentagonal number note : Triangle numbers are generated by the formula, $T_{n} = \frac{1}{2} n(n+1)$.
The first ten triangle numbers are:
0, 1, 3, 6, 10, 15, 21, 28, 36, 45, ... Square numbers are generated by the formula, $S_{n}=n^{2}$.
The first ten square numbers are:
0, 1, 4, 9, 16, 25, 36, 49, 64, 81,... Pentagonal numbers are generated by the formula, $P_{n}=\frac{1}{2}n(3n-1)$.
The first ten pentagonal numbers are:
0, 1, 5, 12, 22, 35, 51, 70, 92, 117,... 10 first positive integer which follow the conjecture : Numbers    =     Triangle + Square + Pentagon 1    =    0    +    0    +    1 2    =    0    +    1    +    1 3    =    1    +    1    +    1 4    =    0    +    4    +    0 5    =    0    +    0    +    5 6    =    0    +    1    +    5 7    =    1    +    1    +    5 8    =    3    +    0    +    5 9    =    0    +    4    +    5 10    =    0    +    9    +    1","['number-theory', 'square-numbers']"
1888807,Why is the value of $\frac{\sin\theta}{\sin\sin\theta}$ close to the number of degrees in a radian?,"Why is $\cfrac{\sin\theta}{\sin\sin\theta}$ very close to 1 radian $(57.2958°)$? I tested this out for $\theta=1^{\circ}$ and $\theta=45^{\circ}$ and various other angles, but I always seem to get about the same answer.",['trigonometry']
1888809,Does proving that a property holds for every set with $n$ elements implies it holds positive integers,"If we prove by using PMI that some predicate $P(\mathbf{X})$ is true for every set $\mathbf{X}$ with $n$ elements, for each $n\in \mathbb{Z}^{+}$, can we say that $P(\mathbf{X})$ holds for $\mathbb{Z}^{+}$? Or are we limited to ensure it is true only if $\mathbf{X}$ is finite? Thanks in advance!","['induction', 'logic', 'elementary-set-theory']"
1888843,Is the graph of the Conway base 13 function connected?,"IVT Property: If $a<b$ and $y$ is between $f(a)$ and $f(b)$, then there exists $c\in(a,b)$ such that $f(c)=y$. Theorem. Let $f:\mathbb R \to \mathbb R$ be a function with the IVT Property. If the set of discontinuities of $f$ is first category in $\mathbb R$, then the graph of $f$ is connected. This is an old Theorem. I assume there must be a counterexample if we leave out the first category assumption, though I don't know of any (help!). There are functions which are discontinuous everywhere and still have connected graphs. F.B. Jones showed that the graph of a function satisfying $f(x)+f(y)=f(x+y)$ for all $x$ and $y$ can be connected, even if the function is discontinuous everywhere. So now I come to Conway's example . It has the IVT property in a rather extreme way: it takes every value on every interval. It is discontinuous everywhere. Is the graph connected?","['general-topology', 'real-analysis']"
1888859,Definite integral and limit $\lim_{n \rightarrow \infty} (n((n+1)I_{n}-\frac{\pi}{4})$,Given $I_{n} = \int_{0}^{1} x^{n} \arctan(x)dx $ Calculate: $\lim_{n \rightarrow \infty} (n((n+1)I_{n}-\frac{\pi}{4})$,"['limits', 'definite-integrals', 'calculus', 'analysis']"
1888868,"Stirling formula, O-Notation","In lecture we proof that
:  $ \sqrt{2 \pi n} (\frac{n}{e})^n< n! \le \sqrt{2 \pi n} (\frac{n}{e})^n e^{\frac{1}{12n}}$ But how we came form this to the formula $n!= \sqrt{2 \pi n} (\frac{n}{e})^n (1+ O(1/n)) $ with $0< O(1/n) \le \frac{1}{12n}$ I can rewirte the second formula as that  $\lim\sup_{n\rightarrow \infty}| \frac{\frac{n!}{\sqrt{2 \pi n}*(\frac{n}{e})^n} -1}{1/n}|$ exists, what means that $\frac{\frac{n!}{\sqrt{2 \pi n}*(\frac{n}{e})^n} -1}{1/n}$ is bounded. When i use the first formula i get $0=\frac{1-1}{n} \le \frac{\frac{n!}{\sqrt{2 \pi n}*(\frac{n}{e})^n} -1}{1/n} \le \frac{1}{12}*\frac{(e^{\frac{1}{12n}}-1)}{1/12 n}$ I know $\lim_{n\rightarrow \infty} \frac{1}{12}*\frac{(e^{\frac{1}{12n}}-1)}{1/12 n}= \frac{1}{12}*1=\frac{1}{12}$ so the right side is bounded and so the limessuperior exists. I need to show that $ \frac{n!}{\sqrt{2 \pi n} (\frac{n}{e})^n} -1 \le \frac{1}{12n}$, that means $ \frac{\frac{n!}{\sqrt{2 \pi n} (\frac{n}{e})^n} -1}{\frac{1}{n}} \le \frac{1}{12}$. But this formula i only get for $n$ big enough and not for all n?","['stirling-numbers', 'probability', 'discrete-mathematics']"
1888889,Continuous self-maps on $\mathbb{Q}$,"1) Are $\mathbb{Q}$ and $\mathbb{Q}\setminus\{0\}$ homeomorphic? 2) If $S\subseteq \mathbb{Q}$ is a non-empty subset, is there a continuous surjection $f:\mathbb{Q}\to S$?",['general-topology']
1888892,Total number of combinations for boxes that can hold a maximum of 2 objects.,"Consider an $N$ balls than can be placed in $n$ number of boxes. Where: $n > N/2$ Suppose each boxes can only hold a maximum of two balls, what is the formula for finding the total number of combinations if each balls are considered distinguishable?","['combinatorics', 'statistics', 'probability']"
1888910,Trying to find an explicit sum of an infinite series: $\sum_{n=1}^{\infty} \frac{ (-1)^n }{(2n+1) 3^n }$,"I have the following series $$\sum_{n=1}^{\infty}\frac{(-1)^n }{(2n+1)3^n}$$ I am trying to find an explicit sum. I know this looks like $\arctan x = \sum_{n=0}^{\infty} \frac{ (-1)^n x^{2n+1}}{2n+1} $. I do the following $$ \sum_{n=1}^{\infty} \frac{ (-1)^n }{(2n+1) 3^n } = \sum_{n=0}^{\infty} \frac{ (-1)^n }{(2n+1) 3^n } - 1 =\sqrt{3} \sum_{n=1}^{\infty} \frac{ (-1)^n \sqrt{1/3}^{2n+1}}{(2n+1) } - 1$$ Since $(1/3)^n = (\sqrt{1/3})^2n = \sqrt{3} (\sqrt{1/3})^{2n+1}$. Thus, the sum is 
$$ \sqrt{3} \sum_{n=1}^{\infty} \frac{ (-1)^n \sqrt{1/3}^{2n+1}}{(2n+1)  } - 1 = \sqrt{3} \arctan(1/\sqrt{3}) = 1 = \boxed{\frac{ \sqrt{3} \pi }{6} - 1 }$$ Is this a correct solution? Do you guys a differenti method?","['sequences-and-series', 'calculus', 'closed-form']"
