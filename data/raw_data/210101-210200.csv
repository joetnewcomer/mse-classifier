question_id,title,body,tags
4221980,Would you ‘buy’ a prediction from Prof. Gott?,"As a young man Mr Gott visits Berlin in 1969. He’s surprised that he cannot cross into
East Berlin since there is a wall separating the two halves of the city. He’s told that the wall was erected
8 years previously. He reasons that : The wall will have a finite lifespan; his ignorance means that he
arrives uniformly at random at some time in the lifespan of the wall. Since only 5% of the time one would
arrive in the first or last 2.5% of the lifespan of the wall he asserts that with 95% confidence the wall will
survive between 8/0.975 ≈ 8.2 and 8/0.025 = 320 years. In 1989 the now Professor Gott is pleased to find
that his prediction was correct and promotes his prediction method in elite journals. This ‘delta-t’ method
is widely adopted and used to form predictions in a range of scenarios about which researchers are ‘totally
ignorant’. Would you ‘buy’ a prediction from Prof. Gott? Explain carefully your reasoning. My answer to this question is no, I would not buy a prediction from Prof. Gott as his ""confidence interval"" is very large and hence it was not too accurate. But how exactly would one go about explaining this more rigourously?","['statistics', 'probability']"
4221986,General solution of $\sin(x) = -1/2$,"I have a doubt with regards to the general solution of $\sin(\theta) = -1/2$ . I know that the principal solutions are $\frac{7\pi}{6}$ and $\frac{11\pi}{6}$ . So my main question is: Should the general solution be $n\pi$ + $(-1)^{n}$$\frac{7\pi}{6}$ or $n\pi$ + $(-1)^{n}$$\frac{11\pi}{6}$ ? Apparently, WolframAlpha uses $\frac{7\pi}{6}$ for the general solution. My apologies to you if you found this question a bit silly. I appreciate your time and effort.",['trigonometry']
4222005,Are $\mathbb{R}P^3$ and $T^1S^2$ isometric?,"It is well-known that 3-dimensional real projective space $\mathbb{R}P^3$ is diffeomorphic to $T^1S^2$ , the unit tangent bundle of the 2-sphere. However, I could not find any reference to whether these spaces are also isometric as Riemannian manifolds, where $\mathbb{R}P^3$ is given its canonical metric of constant curvature 1 (coming from its double cover by $S^3$ ), and $T^1 S^2$ is given the Sasaki metric. I feel like this should be true, but I am not sure.
Can anyone help? Any reference would be appreciated.","['differential-geometry', 'riemannian-geometry', 'reference-request', 'tangent-bundle', 'projective-space']"
4222030,What are the units of an inverse matrix?,"As the title suggests. For example if I have a matrix $A = \begin{pmatrix}
 a & b\\ 
 c& d 
\end{pmatrix}$ and all elements consist of variables with units $kg$ and then I take the inverse of the matrix is the resulting units simply $kg^{-1}$ ? How can this be the case if not all matrices have inverses? Somewhat related to my other question about unit quantities in other matrix equations.","['unit-of-measure', 'applications', 'matrices', 'linear-algebra', 'inverse']"
4222038,Differential equation with derivatives on both sides,"I was doing some differential equations while following lessons online and was just wondering if what I found written there is correct. Given differential equation: $y''=xy'+y'+1$ we're trying to make both left and right side derivatives of some functions like: $f'(x)=g'(x) \implies f(x)=g(x)+c$ .
What my tutor did is: $(y')'=(xy)'+1$ $(y')'=(xy+x)'$ $y'=xy+x+c_1$ etc. I am curious if this is wrong or I haven't understood this so far. If $y=y(x)$ then $(xy)'$ should be $(xy)'=y+xy'$ , right? How do you get from $(xy)'$ following: $xy'+y'$ ?",['ordinary-differential-equations']
4222061,Area of Cyclic Quadrilateral,"Let $ABCD$ be a quadrilateral inscribed in a circle with diameter $AC$ , and let $E$ be the foot of perpendicular from $D$ onto $AB$ . If $AD=DC$ and the area of quadrilateral $ABCD$ is $24$ , find $DE$ . Here's what I did:
Assuming the radius of the circle to be $r$ , $AD=DC=a$ , $AB=b$ and $BC=c$ , I found out that: • $a^2=2r^2$ , and $b^2+ c^2 = 4r^2$ ,  using $Pythagoras$ •Next $ $ $[ABCD]= \frac {a²}{2} + \frac {bc}{2} $ . Substituting the values, I got $b+c=4\sqrt6$ . •Finally, we have $$[ABCD] = \frac {(b+c)(b+c)(2a+b-c)(2a+c-b)}{16}  \\... using \  Brahmagupta \ Formula$$ Substituting values, I got $bc=24$ $\Rightarrow$ $ b=c=2\sqrt6$ . I am stuck here. What should I do next?
Thanks.","['quadrilateral', 'area', 'geometry']"
4222081,How do I evaluate this limit that seems to be indeterminate?,"I've been trying to evaluate the below limit, which Mathematica claims is equals to $1$ . $$\underset{n\to \infty }{\text{lim}}\frac{\frac{1}{2} (n+1) \sin \left(\frac{2 \pi }{n+1}\right)-\pi }{\frac{1}{2} n \sin \left(\frac{2 \pi }{n}\right)-\pi }$$ However, my attempts, of which I attempted using L'Hopital's rule, always end with the indeterminate form of $\frac{0}{0}$ , because taking the limit to infinity of both the non- $\pi$ sections of the numerator and denominators gives $\pi$ . Is Mathematica correct, and if so, what is the solution?",['limits']
4222107,Proving that the range of two functions is disjoint and the union of the ranges is the entire set of natural numbers.,"Define, where $x$ and $y$ are non-negative integers: $f(x,y)=x^2 + 2x(y + 1) + y^2 + y + 1$ $g(x,y)=x^2 + 2x(y + 1) + y^2 + 3y + 2$ Prove that the range of $f(x,y)$ is disjoint from the range of $g(x,y)$ and that the union of the ranges is the entire set of natural numbers. What I have attempted so far:
To prove that the ranges are disjoint, I tried to find when $f(x,y)=g(x,y)$ . This only occurs when $y=-\frac{1}{2}$ , which is not a non-negative integer. However, I don't think it proves the ranges are disjoint, as it only shows there isn't an ordered pair which gives the same value for both functions, not that the two functions never output the same value. For the second part of the problem (and possibly the first part) re-writing both formulas using some clever factorisation might reveal something. For example, $f(x,y)=(x+y+1)^2-y$ and $g(x,y)=(x+y+1)^2+y+1$ . However, I am not quite sure how to utilise this. Any hints for either part of the problem?","['algebra-precalculus', 'functions']"
4222108,Solve in $\mathbf{N}$ the equation $9x^2+p=y^2$,"In these days, I have been trying to solve this problem: Let $p \in \mathbf{N}$ a positive large integer ( $> 10^9$ ). Find all $x, y \in\mathbf{N}$ such that: $$9x^2+p=y^2$$ The first approach that I have tried is the following. We know that: $$(t+n)^2-t^2=t^2+2\cdot t \cdot n +n^2-t^2=2\cdot t \cdot n +n^2$$ Also, we can build every possible square $w_n$ greater than $p$ in this way: $$w_n=\left\lfloor\sqrt{p}\right\rfloor^2+2\cdot \left\lfloor\sqrt{p}\right\rfloor \cdot n +n^2 = \left(n+\left\lfloor\sqrt{p}\right\rfloor^2\right)^2$$ For example, let $p=5$ . Follows that: $w_1=\left(1+\left\lfloor\sqrt{5}\right\rfloor^2\right)^2=9$ , $w_2=\left(2+\left\lfloor\sqrt{5}\right\rfloor^2\right)^2=16$ and so on. Now, using this idea and applying to the first equation: $$9x^2=\left(n+\left\lfloor\sqrt{p}\right\rfloor^2\right)^2-p$$ I am not allowed to apply Pell's equation because $9=3^2$ and calcultaing $\Delta$ in $x$ doesn't help anymore. Another approach is based on Pell's equation. I thought to express $9x^2=8x^2+x^2$ and then: $$8x^2+x^2+p=y^2\leftrightarrow 8x^2+p=y^2-x^2\leftrightarrow (y^2-x^2)-8x^2=p \leftrightarrow u^2-8x^2=p$$ But then, in order to generate all the solutions, I have to guess the first one (or one of them) that is pretty complicated for big $p$ . So, how can we do that? Are there any other solutions? Thanks.","['ceiling-and-floor-functions', 'number-theory', 'elementary-number-theory', 'square-numbers', 'pell-type-equations']"
4222134,Determining probability of 'thirteen orphans' hand in riichi mahjong,"For anyone not familiar with how riichi mahjong is played, it uses 34 unique tiles with 4 duplicates of each tile, adding up to 136 in total. There are numbers 1 to 9 in 3 different suits, as well as two types of special honor tiles: winds, which have 4 unique tiles - east, west, south and north, and dragons, which have 3 unique tiles - red, green, and white dragon. This is what they look like: Players discard and draw from this deck and try to build their hand which contains 13 tiles along with 1 tile they have drawn. Can one determine the likelihood of getting a mahjong hand mathematically without using programs to simulate the hands? For instance, such as the thirteen orphans: Discarding and other players can be ignored, I just want to know the the likelihood of it happening from just drawing tiles from the deck. The criteria are as follows: The hand must contain a 1 and a 9 from all 3 numbered suits All four wind tiles All three dragon tiles One duplicate of any wind or dragon tile to complete the hand Calculating the odds of something like the nine gates is fairly straightforward as there is only one suit to choose from which leaves us with something like $\frac{{4 \choose n_1} . . . {4 \choose n_9}}{34 \choose 13}$ where $n_j$ is the amount of duplicates of a tile and $j$ is the number of the number of the tile ( $n_1$ for the first tile, all the way up to $n_9$ ). However, I cannot figure out what to do when honor tiles get involved.","['permutations', 'combinatorics', 'combinatorial-game-theory', 'game-theory', 'probability']"
4222221,Asymptotic equivalence while considering series convergence,"I am given the series $$\sum_{n=1}^{\infty}\frac{n^{n-1}}{\left ( 2n^2+n+1 \right )^{\left (n+\frac{1}{2} \right )}}.$$ Does this series converge? Solution states that comparison test should be used, though it is not stated which one. The one which looks the most promising to me is the one that says that if for two sequences $a_n \sim b_n$ then $\sum_{n=1}^\infty a_n$ is equiconvergent to $\sum_{n=1}^\infty b_n$ . This requires me to find the sequence $b_n$ . So I went ahead, done some gymnastics and found $b_n = \left(\frac{1}{2n} \right)^n$ , meaning that my original series would be convergent. I am wondering is this valid, that is whether I found $b_n$ correctly, or not. They never really explained the process of finding $b_n$ so I am not sure which ""transformation"" am I allowed to do. I hope that someone can confirm my solution, if it is correct, or if it is not, provide an answer that would use one of the comparison tests to determine the convergence of this series. I have not tried other methods, since the comparing sequences is an expected way to solve it, but I think that this could also be done using the root test. For completeness, here is my work for finding $b_n$ . The reasoning I used is that I can remove terms of lower exponents everywhere, and that would still preserve asymptotic equivalence. Again, I am not sure if this is true, as it was never explained properly during the course. I just believe that that is how the process works. I also graphed both series in Desmos and it seemed that they started meeting at some point along the x axis and then continuing to converge towards $0$ together. Anyways, this is what I did: $$a_n = \frac{n^{n-1}}{\left ( 2n^2+n+1 \right )^{\left (n+\frac{1}{n} \right )}} \sim \frac{n^{n}}{\left ( 2n^2+n+1 \right )^n} \sim \frac{n^{n}}{( 2n^2)^n} \sim \frac{n^{n}}{ 2^n n^{2n}} \sim \frac{1}{ 2^n n^n} \sim \frac{1}{(2n)^n} = b_n. $$ Maybe this solution is correct. I would still very much appreciate if someone could write an answer explaining in what ways I can manipulate the original series in order to preserve the  relation of asymptotic equivalence. I have no idea if what I did is right, or why is it right if it is, or why it would not be if it is not.","['calculus', 'convergence-divergence', 'asymptotics', 'sequences-and-series']"
4222224,Can Mercer's theorem fail without positivity?,"Let $X = [0,1]$ and $K: X \times X \to \mathbb C$ continuous and self-adjoint, meaning that $K(y, x) = \overline {K(x,y)}
$ . It defines a compact, even Hilbert-Schimdt, self-adjoint convolution operator $T_K$ on $L^2(X)$ . Call the eigenvalues $(\lambda_n)_{n \geq 1}$ and orthonormal eigenfunctions $(f_n)_{n \geq 1}$ . Mercer's theorem ( Wikipedia ) says that when $T_K$ is positive (meaning all $\lambda_n \geq 0$ ), the series $$\sum_{n \geq 1} \lambda_n f_n(x) \overline {f_n(y)}$$ converges uniformly on $X \times X$ (necessarily to $K(x, y)$ , which is the $L^2$ -limit). If have not found any reference that discusses whether the condition that $T_K$ is positive, is necessary. Can the theorem fail if $T_K$ is not positive? For a counterexample I don't mind replacing $[0, 1]$ by some other compact Riemannian manifold $X$ with boundary.","['trace', 'functional-analysis', 'reproducing-kernel-hilbert-spaces']"
4222228,Spacetime as an algebraic surface over $\mathbb{C}$,"First of all I would like to say that I know little about physics so I am very likely to talk nonsense in what follows. If I am not wrong, spacetime can be defined as a $4$ -dimensional differentiable manifold $X$ together with a pseudo-Riemannian metric. Hence, one can study the curvature of $X$ , geodesics on $X$ , the singularities of the metric, etc.  Moreover, all these concepts have a physical interpretation. On the other hand, a $2$ -dimensional $\mathbb{C}$ -scheme with some extra hypothesis induces a complex analytic space that gives rise to a $4$ -dimensional variety over $\mathbb{R}$ . Taking this into account, it could make sense to define spacetime as a complex algebraic surface $Y$ with some good properties and one could study the most common aspects of this type of surfaces - namely, the singularities of $Y$ , some Čech cohomology groups of $Y$ , the holomorphic Euler characteristic of $Y$ , the self-intersection of the canonical class of $Y$ (if defined), etc. Hopefully, these concepts could also have a physical interpretation. Maybe there is an obvious reason for this not to be worth studied, but I have not been able to find any information about it on the internet. So, my questions are: Could considering spacetime as an algebraic surface over $\mathbb{C}$ be of any help? Has someone considered spacetime as an algebraic surface over $\mathbb{C}$ ?","['riemannian-geometry', 'algebraic-geometry', 'general-relativity', 'schemes', 'differential-geometry']"
4222272,How do I choose the three pairs of points for a moebius transform?,"I somehow don't really understand how to choose the points for a moebius transform. I know that a moebius transform maps circles and lines to circles and lines and that it is a conformal(biholomorphic) map. Why do we always choose the three points on the boundary of the corresponding domain? When we for example want to construct a moebius transform from the open unit disk to the upper half plane, then we choose three points on the boundary of the unit disk which we want to map to the boundary of the upper half plane which is the real axis. Why is it necessary that all these points are on the corresponding boundary? How are the points exactly mapped to each other? It seems that one cannot just map the 3 points in any order to the image points. I have read that one has to keep the orientation in mind. What is meant by that? Do I have also to keep something in mind when I am mapping the 3 image and pre-image points to $0,1,\infty$ ? How are only 3 point-pairs with information on orientation enough to specify the mapping For me this seems unintuitive. I could just change the target domain a little bit so that the boundary points I chose still lie on the boundary of the domain. Wouldn't I get the exact same moebius transform although my target domain is different now?","['complex-analysis', 'mobius-transformation']"
4222287,"Regularity of an ODE: series Ansatz, analytic and numerical solutions","Suppose I have an ODE that can be written as $$ E(y'(x),y(x),x)=0 $$ Suppose also that this equation has a closed-form solution for $y(x)$ , that is $$y(x) =y(x,C)$$ for an integration constant $C$ . If I know from ""physical arguments"" that this function ought to be even (say because it is defined on a 3-sphere where x is the third hyper-spherical coordinate), I might get the idea of substituting in a sort of power series ansatz $$ y(x)= \sum_{i=-1}^{m} y_i x^i$$ where $m$ is some truncation number. This yield an identically vanishing polynomial, from the coefficients of which I might verify that indeed, only the even components of $y_i$ are non-zero. My first problem is, and this already tells me that the integration constant $C$ in the analytic solution has to take a specific value (zero in my case), if its series expansion around $x=0$ coincides with the $y_i$ coefficients calculated from the polynomial. Is this because a regularity (even power-series) at $x=0$ acts a sort of boundary condition, hence determining the integration constant? My second problem is, that even though on paper this function should be regular at the $x=0$ origin, in numerical solutions there IS a singularity there. How can this be, if $y_{-1}=0$ ? Should the numeric solution not go as $$ y_\text{numeric} \propto y_{0}+y_{2} x^2+\mathcal{O}(x^4)   \;\;\;?$$","['power-series', 'calculus', 'ordinary-differential-equations']"
4222311,Points on the hypotenuse of a right-angled triangle,"Points $K$ and $L$ are chosen on the hypotenuse $AB$ of triangle $ABC$ $(\measuredangle ACB=90^\circ)$ such that $AK=KL=LB$ . Find the angles of $\triangle ABC$ if $CK=\sqrt2CL$ . As you can see on the drawing, $CL=x$ and $CK=\sqrt2x$ . I don't know how to approach the problem at all. Since $\measuredangle ACB=90^\circ$ , it will be enough to find the measure of only one of the acute angles. If $\measuredangle ACK=\varphi_1$ and $\measuredangle BCL=\varphi_2$ , I have tried to apply the law of sines in triangle $KCL$ , but it seemed useless at the end. Thank you! I would be grateful if I could see a solution without using coordinate geometry.","['euclidean-geometry', 'triangles', 'geometry', 'ratio']"
4222336,Finding the center of mass of a hollow hemisphere,"Let there be hollow hemisphere (there is no solid bottom) with radius $r$ . Find the center of mass of the hollow hemisphere, assuming the mass distribution is uniform. My attempt: Let there be a hollow hemisphere centered at $(0,0,0)$ with the bottom plane of the hemisphere resting on the $x-z$ plane. Let it's total mass be M. By symmetry the center of mass of the hemisphere must lie on the $y$ axis. Now let us divide the hemisphere into thin rings, starting from the bottom. Let $dA$ be the area of a thin ring, where is the center of mass is the ring's center. Also, let $dM$ be the mass of the ring. From the diagram it is clear that: $$x^2+r^2=R^2$$ $$dA=2\pi r\cdot dx \implies dA = 2\pi\cdot \sqrt{R^2-x^2}\cdot dx$$ Hence, $dM=\frac{M}{2\pi R^2} \cdot dA=\frac{M}{R^2} \cdot \sqrt{R^2-x^2} \cdot dx$ $$y_{com}=\frac{1}{M} \cdot \int dm \cdot x=\frac{1}{R^2}\int_0^Rx \cdot \sqrt{R^2-x^2} \cdot dx $$ Evaluating this gives $y_{com} = R/3$ , which is proven wrong by a quick google search. The method shown here uses an angle subtended by a small surface area on a ring, which after computation does give the correct answer of $R/2$ . My question is, which step am I doing wrong? Why is the answer coming one way but not the other? I did the same thing with a cone, and the same thing happened, if I approximated a hollow cone as a series of thin hollow cylinders on top of each other, I get the incorrect answer, but with the angle approach, it gives the correct answer. When is an approximation considered ""good enough"" mathematically? I would really appreciate an explanation.","['calculus', 'trigonometry']"
4222361,What is the value of the $CH$ segment in the figure below?,"For reference: In the figure, $ABCDE$ is a regular pentagon with $BD = BK, AB = BT ~and ~TK = 2\sqrt5$ . Calculate $CH$ (If possible by geometry instead of trigonometry) My progress: $Draw KD \rightarrow \triangle DBK(isosceles)\\
Draw TAB \rightarrow \triangle BTA(isosceles)\\
a_i = \frac{180(5-2)}{5} = 108^\circ\\
\angle A EH= 360 -2(108)-2(90)=54^\circ$ but I can't finish... i I made the figure of peterwhy",['geometry']
4222381,Finding the square root of a radical expression,"I have this (not necessarily optimum) method for finding the value of sin $15^{\circ}$ .
(Meant to be an application of Angle Bisector Theorem). In a equilateral triangle with side length 1, draw the altitude to get two $30^{\circ}-60^{\circ}-90^{\circ}$ triangles
Then, in one of the $30^{\circ}-60^{\circ}-90^{\circ}$ triangles, draw the angle bisector again to get a $15^{\circ}-90^{\circ}-75^{\circ}$ triangle. Apply the Angle bisector theorem to find that the side opposite $15$ degrees is $\dfrac{(2\sqrt{3}-3)}{2}$ .
Combine with height $\dfrac {\sqrt{3}}{2}$ to get the hypotenuse squared as $6 \sqrt{3}$ , which then has as its square root $\dfrac {(3-\sqrt{3})}{\sqrt{2}}$ . Apply sin = opp/hyp to get the usual formula for $\sin 15^{\circ}$ . I got $\sqrt{6-3\sqrt {3}}$ as $\dfrac{(3-\sqrt{3})}{\sqrt{2}}$ through trial and error.
Is there a systematic way of finding it?","['trigonometry', 'radicals']"
4222384,Find all primes $p$ and $r$ such that $ pr+1+r^3=p^2 $,"I tried some small values, and I found that $p=7$ and $r=3$ was a solution.
I ve also find a way to factorise the equation: $$ p(p-r)=(r+1)(r^2-r+1)$$ Since  we know that $ p > r+1 $ then $$p| (r^2\color{blue}{-}r+1) $$ That's all what i've found , thank you in advance fo your precious help !","['number-theory', 'prime-numbers']"
4222409,"Finding $a+b+c+d$, where $ab+c+d=15$, $bc+d+a=24$, $cd+a+b=42$, $da+b+c=13$","Let $a,b,c,d \in \mathbb{R}$ . Consider the following constraints: \begin{cases} ab+c+d=15 \\ bc+d+a=24 \\ cd+a+b=42 \\da+b+c=13 \end{cases} Calculate the value of $a+b+c+d$ . It is easy to use the Gröbner basis to get the value: \begin{cases}
10849-4501 d+380d^2,-39409+2320c+3420d,-20+29b-9d,1801+2320 a-380 d\}
\end{cases} so the value of $a+b+c+d$ is $\frac{169}{10}$ . What I am curious about is how to use high schools mathematics to get an answer without too much complicated mathematical calculations ?","['contest-math', 'systems-of-equations', 'groebner-basis', 'polynomials', 'algebra-precalculus']"
4222411,Why can’t a non-constant polynomial have a constant interval?,"Given a polynomial that is not constant, of course, it doesn’t contain a constant interval. But how can we prove it? Since the polynomial is differentiable over R, I came up with a solution that uses Lagrange mean value theorem n times and reduces the nth derivative to a constant. Since the leading term is not zero, there can not be a zero in the nth derivative, and that contradicts the mean value theorem. Therefore, the polynomial must not contain a constant interval. However, I do realize that this solution is a bit complicated,  so is there a simpler solution(possibly elementary) that can prove this?","['calculus', 'polynomials', 'real-analysis']"
4222440,A fair dice is to be rolled $n$ times. Find the probability of not getting three consecutive sixes.,"A fair dice is to be rolled $n$ times. Find the probability of not getting three consecutive sixes. (Here $12664665$ or $12346522$ is a valid result while $12666555$ or $66664256$ isn't.) The problem is inspired from this problem . I think the problem can be solved by case working. But I am not interested in that kind of solution. Rather I am interested in a solution that uses recurrence relations like this solution of the original problem. I've thought of a way to solve the problem which is not complete: The main concern of solving the problem is to find the number of ways to arrange the numbers $1$ to $6$ such that no three sixes are consecutive. Now, we change all the digits which are not $6$ into $0$ . For example, if we get $1266564$ , we will change this as $0066060$ . Let $S_n$ be the number of such valid results that contain $0$ and $6$ only.   ​
Now, if the first rolled dice gets a $0$ then there are $n-1$ rolls still left. But any of the results will be similar to one of the configurations of $S_{n-1}$ . If the first rolled dice gets a $6$ and the second rolled dice gets a $0$ , then using the same logic above we get that there $S_{n-2}$ ways of getting a valid result. If the first rolled dice gets a $6$ and the second rolled dice gets a $6$ , then the third rolled dice will get a $0$ for the result to be valid. So, there will be $S_{n-3}$ ways of getting the result. Hence, we get a recurrence relation that is: $S_n=S_{n-1}+S_{n-2}+S_{n-3}$ . Now, my idea was to change all $0$ s into $1,2,3,4$ or $5$ . But I think that's not possible or that will be too complicated as there will be too many cases. So, I need a solution to the problem that uses recurrence relations.","['contest-math', 'combinatorics', 'recurrence-relations', 'probability']"
4222503,The pure subgroups of a divisible abelian group are just the direct summands.,"This is Exercise 4.3.3 of Robinson's ""A Course in the Theory of Groups (Second Edition)"" . According to Approach0 , it is new to MSE. (NB: I have left out the modules tag for a reason: the tools available here are entirely group theoretic.) The Details: Since definitions vary, on page 15, ibid. , paraphrased, it states that A subgroup $N$ of $G$ is normal in $G$ if one of the following equivalent statements is satisfied: (i) $xN=Nx$ for all $x\in G$ . (ii) $x^{-1}Nx=N$ for all $x\in G$ . (iii) $x^{-1}nx\in N$ for all $x\in G, n\in N$ . On page 94, ibid. , An element $g$ of an abelian group $G$ is said to be divisible in $G$ by a positive integer $m$ if $g=mg_1$ for some $g_1$ in $G$ . [. . .] An abelian group $G$ is said to be divisible of each element is divisible by every positive integer. On page 106, ibid. , A subgroup $H$ of an abelian group $G$ is called pure if $$nG\cap H=nH$$ for all integers $n\ge 0$ ; in words, $H$ is pure if every element of $H$ that is divisible by $n$ in $G$ is divisible by $n$ in $H$ . The Question: The pure subgroups of a divisible abelian group are just the direct summands. Thoughts: This exercise feels as if it would follow from the relevant definitions rather easily, but I've got nowhere so far. At the risk of repeating myself, here's how I start . . . Let $H\le G$ be a pure subgroup of a divisible abelian group $G$ . Then, for every integer $n\ge 0$ , we have $$nG\cap H=nH$$ and for each $g\in G$ and each integer $m\ge 0$ , there exists a $g_1\in G$ such that $g=mg_1$ . Observation: Using notation as above, we have for each such $m\in \Bbb Z$ , $$mG\cap H=mH$$ What do I do next? Since $G$ is abelian, each of its subgroups is normal, so $H\unlhd G$ . I need to show that there exists a $K\unlhd G$ such that $H\cap K=\{e\}$ and $G=HK=\{ hk\in G\mid h\in H, k\in K\}$ ; that is, $G=H\oplus K$ . The question is trivial if $H$ is trivial or $H=G$ . I think I could answer this question myself if I had enough time; as such, a good hint is preferred over a full answer. Please help :)","['divisible-groups', 'direct-product', 'group-theory', 'abelian-groups']"
4222589,On $\mathrm{\sum\limits_{x=1}^\infty Ci(x)}$.,"I have held out on asking this question as it seems a bit simple, but I have also asked some similar summation questions. This brought about the idea of adding it to the collection. The problem uses properties of the Cosine Integral function with related functions . Here is a related question: Prove $$\sum_{n=1}^\infty \text{Ci}(\pi n)=\frac{\ln(2)-\gamma}{2}$$ Also see the hypergeometric definitions . The expression with the Confluent-U hypergeometric function looks like some type of sum transform. Note that Wolfram Research defines Ci(x) and related functions with an additional logarithm term which will be ignored. Without this term, the Wolfram version just has an extra imaginary part, but the sums will all be over the real part of the summand: $$\mathrm{Ci(1)+Ci(2)+Ci(3)…=\sum_{x=1}^\infty Ci(x)= \sum_{x=1}^\infty Chi(ix)= \sum_{x=1}^\infty\frac{Ei(-ix)+Ei(ix)}{2}=-\sum_{x=1}^\infty\frac{Γ(0,ix)+Γ(0,-ix)}{2}=\sum_{x=1}^\infty G_{2,3}^{1,2}\left(_{1,0,0}^{\ \ 1,1} \big|x\right)=\sum_{x=1}^\infty (Ei(ix)-i Si(x))=-\sum_{x=1}^\infty e^x U(1,1,-x)=\sum_{x=1}^\infty x\,_2F_1(1,1,2,2,x)=\sum_{x=1}^\infty \sum_{y=1}^\infty \frac{x^y}{yy!}=-\sum_{x=1}^\infty\sum_{y=1}^\infty\sum_{z=1}^y\frac{e^x(-x)^y}{zy!}=ln\prod_{x=1}^\infty e^{Ci(x)}=0.630…}$$ The Abel-Plana formula seems to work, so here is the constant using it. Note that you can split the integral: $$\mathrm{\sum_{x=0}^\infty Ci(x+1)= sin(1)-\frac{Ci(1)}{2}+\frac i2\int_0^\infty [Ci(1+ix)-Ci(1-ix))][coth(\pi x)-1]dx}$$ What is a way to evaluate the summation in Exact form ? Even though there is no explicit $(-1)^x$ , this sum converges by the Alternating Series test as it is decreasing with a limit to 0 of the summand which is just Ci(x) on $\text x\ge 1$ . Please correct me and give me feedback! Note: See this question on Evaluation of $\sum\limits_{n=0}^\infty \left(\operatorname{Si}(n)-\frac{\pi}{2}\right)$ ? and On $\mathrm{\sum\limits_{n=0}^\infty \left(C(n)-\frac{\sqrt\pi}{2\sqrt2}\right)+ \sum\limits_{n=0}^\infty \left(S(n)-\frac{\sqrt\pi}{2\sqrt2}\right)}$ Jus for fun, here is another nice identity with credit from @ComplexYetTrivial and @Metamorphy. This will use the principal branch for simplicity. Also, please remember the Pi-Product notation . This works for $x>0$ and for $x=\frac{1}{2\pi}$ , the formula works for all $b\ne 0$ . It includes the Harmonic numbers and an indicator function of natural numbers: $$\mathrm{\prod_{n=1}^\infty b^{Ci(2\pi n x)}= b^{\sum\limits_{n=1}^\infty Ci(2\pi n x)}=b^{-\frac γ2}\sqrt{\frac{b^{H_{\lceil x\rceil}}b^{\frac{I_{\Bbb N}(x)}{2\lceil x\rceil}}}{\sqrt[\lceil x\rceil]{b} b^{ln(x)}}}\mathop\implies ^{x=\frac{y}{2\pi}} \prod_{n=1}^\infty b^{Ci(n y)}= b^{-\frac {γ+ln(2)+ln(\pi)}2}\sqrt{\frac{b^{H_{\left\lceil \frac{y}{2\pi}\right\rceil}}b^{\frac{I_{\Bbb N}\left(\frac {y}{2\pi}\right)}{2 \left\lceil \frac{y}{2\pi}\right\rceil}}}{\sqrt[\left\lceil \frac{y}{2\pi}\right\rceil]{b} b^{ln y}}}}$$ Another fascinating special case is the following. You can derive similar ones like it yourself if you like, so I will only post one. I will also expand it using Euler’s formula . Note I will use the principal branch only: $$\mathrm{log_{-1}\prod_1^\infty (-1)^{Ci(x)}=\sum_1^\infty Ci(x)\implies \prod_1^\infty (-1)^{Ci(x)} =(-1)^{\sum_1^\infty Ci(x)}=(-1)^\frac{ln(2\pi)-γ}{2}=i^{ln(2\pi)-γ}=i^{-γ}(2\pi)^\frac{i\pi}{2}=cos\left(\frac{\pi(γ-ln(2\pi))}{2}\right)+i\,sin \left(\frac{\pi(γ-ln(2\pi))}{2}\right)=-\sqrt{\frac{1+cos(\pi(γ-ln(2\pi))}{2}}+ \sqrt{\frac{1-cos(\pi(γ-ln(2\pi))}{2}} =-0.39810115624278019936718245779... +
0.91734152277009760782638804362... i}$$","['special-functions', 'trigonometric-series', 'calculus', 'sequences-and-series', 'constants']"
4222619,Let $\mathcal{F_1}$ and $\mathcal{F_2}$ be two $\sigma-$algebras of subsets of $\Omega$. Write the definition of $\mathcal{F_1} \cap \mathcal{F_2}$:,"Let $\mathcal{F_1}$ and $\mathcal{F_2}$ be two $\sigma-$ algebras of subsets of $\Omega$ . Write the definition of $\mathcal{F_1} \cap \mathcal{F_2}$ , and show that $\mathcal{F_1} \cap \mathcal{F_2}$ is a $\sigma-$ algebra. Definition: $\mathcal{F_1} \cap \mathcal{F_2}=\{A\subset \Omega | A\in \mathcal{F_1}\: \text{and}\: A\in \mathcal{F_2}\}$ Since $\mathcal{F_1}$ and $\mathcal{F_2}$ are two $\sigma-$ algebras, then $\Omega \in \mathcal{F_1}$ and $\Omega \in \mathcal{F_2}$ , by definition $\Omega \in \mathcal{F_1} \cap \mathcal{F_2}$ . Let $A \in \mathcal{F_1} \cap \mathcal{F_2}$ , then $A\in\mathcal{F_1}$ and $A\in\mathcal{F_2}$ . Since $\mathcal{F_1}$ and $\mathcal{F_2}$ are $\sigma-$ algebras, then $A^c\in\mathcal{F_1}$ and $A^c\in\mathcal{F_2}$ , i.e. $A^c\in\mathcal{F_1 \cap F_2}$ . Let $A_1, A_2,\ldots \in \mathcal{F_1 \cap F_2}$ , then $\bigcup\limits_{i=1}^{\infty} A_{i}\in \mathcal{F_1}$ and $\bigcup\limits_{i=1}^{\infty} A_{i}\in \mathcal{F_2}$ , i.e. $\bigcup\limits_{i=1}^{\infty} A_{i}\in \mathcal{F_1\cap F_2}$ . Therefore, $\mathcal{F_1\cap F_2}$ is a $\sigma-$ algebra. Is this okay?","['probability-theory', 'probability']"
4222624,Third Chern class of an ideal sheaf of a curve on a quadric hypersurface.,"Let $X$ be a quadric hypersurface in $\mathbb P^4$ and let $Z\subset X$ be a algebraic subset of pure dimension $1$ on $X$ . Consider $Z$ smooth. I want to find the $c_3(I_{Z/X})$ . I want somebody to help me verify if the calculations below are OK, also I need some help, hind or reference when $Z$ is singular. Take the Euler characteristic of the following short exact sequence \begin{equation}
0\rightarrow I_{Z/X}\rightarrow \mathcal O_X\rightarrow \mathcal O_{Z/X}\rightarrow 0
\end{equation} we have $\chi(I_{Z/X})=1-\chi(\mathcal O_{Z/X})=g$ , where $g$ is the arithmetic genus of $Z$ . By the Hirzebruch-Riemann-Roch theorem \begin{align}
\chi(I_{Z/X})&=\deg\left[Ch(I_{Z/X})\cdot td(TX)\right]_3\\
             &=\deg\left[(1+c_1+\frac{1}{2}(c_1^2-2c_2)+\frac{1}{6}(c_1^3-3c_1c_2+3c_3))\cdot (1+\frac{1}{2}c_1^{'}+\frac{1}{12}((c_1^{'})^2+c_2^{'})+\frac{1}{24}(c_1^{'}c_2^{'}))\right]_3
\end{align} where $[\ ]_3$ is the term of degree 3, $c_i=c_i(I_{Z/X})$ and $c_i^{'}=c_i(TX)$ for $i=1,2,3$ . By the other hand $c_1=0$ , $c_2=[Z]$ (the fundamental cycle of $Z$ ), $c_1^{'}=3H$ , $c_2^{'}=4H^2$ and $H=c_1(\mathcal O_X(1))$ . So \begin{align}
\chi(I_{Z/X})&=\deg\left[(1-[Z]+\frac{1}{2}c_3)\cdot (1+\frac{3}{2}H+\frac{13}{12}H^2+\frac{1}{2}H^3)\right]_3\\
    g &=\deg\left(\frac{1}{2}H^3+\frac{1}{2}c_3-\frac{3}{2}[Z]\cdot H\right).
\end{align} finally, we have the identity $$ (g-1)H^3-3[Z]\cdot H =c_3$$","['algebraic-geometry', 'characteristic-classes']"
4222662,Proof of $\operatorname{Aut}(C_q)\cong C_{q-1}$ by group action?,"Let $G$ and $H$ be groups, and $\varphi\colon G\to\operatorname{Aut}(H)$ a homomorphism. Then, further than all the results valid for a general group action on a set, the following additional one holds: $$\operatorname{Fix}(g):=\{h\in H\mid \varphi_g(h)=h\}\le H \tag 1$$ For finite $G$ and $H$ , the condition $(1)$ brings new opportunities, as now $\left|\operatorname{Fix}(g)\right|$ divides $|H|$ ; as an example, for $p, q$ distinct primes such that $p\nmid q-1$ , one can prove from here that there are no nontrivial homomorphisms $\phi\colon C_p\to\operatorname{Aut}(C_q)$ , by no means knowing anything on the structure of $\operatorname{Aut}(C_q)$ . If, in addition, $\varphi$ is injective , then this setting may lead to some other result: for instance, for $q$ prime and $H=C_q$ , I was able to prove via $(1)$ that $|G|$ divides $q-1$ , again by no means knowing anything on the structure of $\operatorname{Aut}(C_q)$$^\dagger$ . Question . One step ahead in this escalation, if $\varphi$ is an isomorphism , I expect this setting to lead to further group action conditions (involving stabilizers, fixed points subgroups, orbits, etc.), potentially useful in getting the structure (isomorphism class) of $\operatorname{Aut}(H)$ , for some known $H$ . In particular, as entry test of this approach, I'm aiming to retrieve in this way the known result $\operatorname{Aut}(C_q)\cong C_{q-1}$ . Edit (2021-11-5). The integer $|G|-k$ is the number of $g\in G$ such that $\left|\operatorname{Fix}(g)\right|=q$ , namely the number of $g\in G$ such that $\varphi_g(h)=h$ for every $h\in C_q$ , namely the number of $g\in G$ such that $\varphi_g=\operatorname{Id}_{C_q}$ , whence: $$|G|-k=\left|\operatorname{ker}\varphi\right| \tag{1bis}$$ If $\varphi$ is injective, then $\left|\operatorname{ker}\varphi\right|=1$ and $(1\text{bis})$ yields: $k=|G|-1$ . But $k$ is the number of $g\in G$ such that $\left|\operatorname{Fix}(g)\right|=1$ , namely the number of $g\in G$ such that $\varphi_g(h)=h\Longrightarrow h=1$ . Therefore, every nontrivial $g\in G$ is sent to an automorphism of $C_q$ which moves all the nontrivial elements of $C_q$ . If, in addition, $G\cong\operatorname{Aut}(C_q)$ , then every $\psi\in\operatorname{Aut}(C_q)\setminus\{\operatorname{Id}_{C_q}\}$ moves all the nontrivial elements of $C_q$ . So, $C_q$ has at most $q-1$ automorphisms, all but one (the identity) of which move all the nontrivial elements of $C_q$ . Suppose we have proved that there are precisely $q-1$ automorphisms: would the fact that $q-2$ of them move all the nontrivial elements of $C_q$ imply that some of them (automorphisms) must have order $q-1$ ? Edit (2021-11-8). By the previous edit, every $\psi\in\operatorname{Aut}(C_q)\setminus\{\operatorname{Id}_{C_q}\}$ is of the form: \begin{alignat}{1}
&\psi(1)=1 \\
&\psi(a^i)=a^{\sigma(i)} \\
\end{alignat} where $\sigma\in S_{q-1}$ has cycle type $(r_1,\dots,r_N)$ ( $r_1\le\dots\le r_N$ ), for some $N\ge 1$ , with: $r_i\ge 2$ , for every $i=1,\dots,N$ $\sum_{i=1}^Nr_i=q-1$ Note that, if a cycle $(i_1\dots i_s)$ which composes $\sigma$ is such that $\sum_{j=1}^si_j\not\equiv 0\pmod q$ , then: \begin{alignat}{1}
\psi(a^{i_1}\dots a^{i_s}) &= \psi(a^{i_1+\dots+i_s\pmod q}) \\
&= a^{\sigma(i_1+\dots+i_s\pmod q)} \\
\end{alignat} and: \begin{alignat}{1}
\psi(a^{i_1})\dots\psi(a^{i_s}) &= a^{\sigma(i_1)}\dots a^{\sigma(i_s)} \\
&= a^{\sigma(i_1)+\dots+\sigma(i_s)\pmod q} \\
\end{alignat} whence: \begin{alignat}{1}
a^{\sigma(i_1+\dots+i_s\pmod q)} &= a^{\sigma(i_1)+\dots+\sigma(i_s)\pmod q}  \\
\end{alignat} and finally (being the $a^i$ 's distinct and by definition of cycle): \begin{alignat}{1}
\sigma(i_1+\dots+i_s\pmod q) &= \sigma(i_1)+\dots+\sigma(i_s)\pmod q  \\
&= i_1+\dots+i_s\pmod q  \\
\end{alignat} which is a contradiction, because $\sigma$ doesn't fix any element of $\{1,\dots,q-1\}$ . Therefore, every cycle $(i_1\dots i_s)$ which composes $\sigma$ must fulfil the condition: $$\sum_{j=1}^si_j\equiv 0\pmod q\tag{1ter}$$ Maybe , the condition $(1\text{ter})$ , which is fulfilled in particular by the $(q-1)$ -cycles, limits the possibilities enough that, for some of the nontrivial automorphisms $\psi_1,\dots,\psi_{q-2}$ , the corresponding $\sigma$ must be a $(q-1)$ -cycle? Edit (2021-11-29). By taking as known that $^{\dagger\dagger}$ $\operatorname{Aut}(C_q)\cong (\Bbb Z/q\Bbb Z)^\times$ , we can take advantage of $G$ being a finite abelian group, and use the framework in the previous Edit to prove, e.g. , that $\operatorname{Aut}(C_7)$ (and then $(\Bbb Z/7\Bbb Z)^\times$ ) is cyclic. In fact, the order of every element divides the maximal order among the elements in $G$ . By contradiction, let's assume that such maximal order is $3$ . Then, all the nontrivial elements must have order $3$ . But then, the only nontrivial permutations fulfilling the constraints in the previous Edit are: $\sigma_1=(124)(356)$ , $\sigma_2=(142)(356)$ , $\sigma_3=(124)(365)$ , $\sigma_4=(142)(365)$ , namely too few to build up the whole $\operatorname{Aut}(C_7)$ . Likewise, let's assume that such maximal order is $2$ . Then, all the nontrivial elements must have order $2$ . But then, the only nontrivial permutation fulfilling the constraints in the previous Edit is $\sigma_1=(16)(25)(34)$ , definitely too few to build up the whole $\operatorname{Aut}(C_7)$ . Therefore, $\operatorname{Aut}(C_7)$ (or, equivalently, $(\Bbb Z/7\Bbb Z)^\times$ ) must have an element of (maximal) order $6$ . Maybe this kind of argument can be generalized to every $q$ ? $^\dagger$ Every automorphism of $C_q$ is a permutation of its $q-1$ nontrivial elements; therefore, $\operatorname{Aut}(C_q)\cong K\le S_{q-1}$ and hence $\left|\operatorname{Aut}(C_q)\right|$ divides $(q-1)!$ . For an embedding $\varphi\colon G\hookrightarrow\operatorname{Aut}(C_q)$ , $|G|$ divides $\left|\operatorname{Aut}(C_q)\right|$ and $\operatorname{Fix}(g):=\{h\in C_q\mid \varphi_g(h)=h\}$ is a subgroup of $C_q$ . But $C_q$ has no nontrivial subgroups; therefore: \begin{alignat}{1}
\sum_{g\in G}\left|\operatorname{Fix}(g)\right| &= k+(|G|-k)q \\
&= |G|q-k(q-1) \\
\tag 2
\end{alignat} for some $k$ , $0\le k\le |G|$ . By Burnside's Lemma, $|G|$ divides the LHS of $(2)$ , and hence $|G|$ divides $k(q-1)$ either. The case $k=|G|$ corresponds to a transitive action, whence $q\mid |G|$ : contradiction, because $|G| \mid\left|\operatorname{Aut}(C_q)\right|$ and $\left|\operatorname{Aut}(C_q)\right|\mid(q-1)!$ , but $q\nmid (q-1)!$ . Therefore, $k<|G|$ and then necessarily $|G|\mid q-1$ . $^{\dagger\dagger}$ After all, here the focus is to prove the cyclicity of $\operatorname{Aut}(C_q)$ , and the standard result $\operatorname{Aut}(C_q)\cong U_q$ can be then assumed as known - see e.g. Herstein's Topics in Algebra , 2nd Edition, Example 2.8.1, page 69.","['automorphism-group', 'group-theory', 'group-actions']"
4222706,Prove that ${2p\choose p}\equiv 2\pmod {p^2}.$,"Prove that ${2p\choose p}\equiv 2\pmod {p^2}.$ My progress: Consider any $S={(x,y),~~1\le x\le p,~~1\le y\le 2}.$ Note that $|S|=2p.$ Now consider $A\subseteq S$ such that $|A|=p.$ So there are a total of ${2p}\choose{p}$ possible value of $A.$ Then let $A=\{(a_1,b_1),......,(a_p,b_p)\}.$ Define $$f(A)=\{(a_2,b_2),.............(a_p,b_p),(a_1,b_1)\}$$ .
.
. $$f^{p-1}(A)=\{(a_p,b_p),\dots ,(a_{p-1},b_{p-1})\}$$ Now, define a new binary relation $R$ such $f^{m}(A)Rf^l(A)$ when $$b_{m+1}=b_{l+1},~~b_{m+2}=b_{l+2},~~\dots$$ Note that this is possible only when $b_i=c$ a constant where $c=1$ or $2.$ For the rest ${{2p}\choose{p}}-2$ sets, the orbit size is $p.$ Hence we get $p\mid{{2p}\choose{p}}-2.$ I want to go with the same essence, but I don't know how to get $p^2.$ Any hints?","['elementary-number-theory', 'binomial-coefficients', 'combinatorics', 'modular-arithmetic']"
4222723,Can every tree with total length $2$ be covered by a semi-disc of radius $1$?,"Can every tree with total length $2$ be covered by a semi-disc of radius $1$ ? If the tree is actually a curve, or the convex hull of the tree is a triangle, I know this is correct after some attempts. But for the general case, I have no idea.","['combinatorial-geometry', 'combinatorics', 'geometry']"
4222733,"Maximizing $x_1+x_2+\cdots+x_{10}$, where each $x_i$ lies between $-1$ and $1$, and $x_1^3+x_2^3+\cdots+x_{10}^3=0$","Let $x_1, x_2, \ldots, x_{10}$ be ten quantities each lying between $-1$ and $1$ , and the sum of cubes of these ten quantities is zero. Find the maximum value of $x_1+x_2+\cdots+x_{10}$ . I have tried substituting $x_1=\sin(y_1)$ , $x_2=\sin(y_2)$ , and so on,  and then used the identity for $\sin 3x$ to simplify the cubes leading to $$x_1 + x_2 + \cdots x_{10} = \frac13 (\sin 3y_1 + \sin 3y_2 +\cdots + \sin 3y_{10})$$ Now is the statement $$\frac13 (\sin 3y_1 + \sin 3y_2 +\cdots + \sin 3y_{10}) \leq \frac{10}{3}$$ right? Is the answer $10/3$ ? How do I maximise $$\frac13 (\sin 3y_1 + \sin 3y_2 +\cdots + \sin 3y_{10})$$ under the constraints?",['trigonometry']
4222735,Embedded Ricci Flow,"Consider a submanifold $\mathcal{M}$ that is embedded in a higher dimensional manifold $\mathcal{N}$ . Now if I infinitesimally perturb the submanifold as $$g_{\alpha\beta}\rightarrow g_{\alpha\beta}+\varepsilon R_{\alpha\beta}+\mathcal{O}(\varepsilon^2)$$ then a) Is there an embedding of the new manifold in $\mathcal{N}$ ? If yes, is the embedding also infiitesimally perturbed from the original one? (Of course an embedding may not be unique, I mean is there one embedding that is infinitesimally close?) b) If the answer to 'a' is affirmative, can I describe the embedding flow solely in terms of the extrinsic curvature? I have shown that except for manifolds with constant curvature ( $R_{\alpha\beta}=Cg_{\alpha\beta}$ ), the Ricci flow is different from the 'curve shortening flow' and therefore do not know where the animations of the ricci flow come from!","['manifolds', 'submanifold', 'ricci-flow', 'differential-geometry']"
4222752,Integer minimizers of sum of squares given sum constraint,"""Given positive integers $k,n$ and nonnegative integers $x_1,x_2,...,x_n$ satisfying $x_1 + x_2 + \dots+ x_n = k$ , is it true that $x_1^2+x_2^2+\dots+x_n^2$ is minimized if and only if $|x_i-x_j|\leq1$ for all $i,j$ ?"" Hello. I am reading one paper where I am not sure how to deal with this part.
So basically, we want to distribute $k$ identical objects into $n$ identical boxes, and minimize the sum of squares of the numbers of objects in the boxes. So I denote the number of objects by $x_i$ and formulate the problem above. It is claimed that when the distribution is as even as possible,  then the sum of squares of $x_i$ 's is minimized. This does look intuitively true (or does it?), but I am not sure how to prove this if it is true. This feels like a constrained integer least square problem but I never studied it. What I tried is to use AM-QM inequality to have a bound by first changing the above absolute value into $(x_i - x_j)^2\leq 1$ and then expanding this and summing all over the pairs, but I only get a lower bound $\frac{k^2}{n}$ and an upper bound $\frac{k^2}{n} + \frac{n-1}{2}$ . Perhaps pigeonhole then can be used to find some pairs of $i,j$ with $|x_i - x_j|\geq2$ for some pair, but I am still stuck. Trying to be exact, the most even distribution must be like $k = (q+1)r+q(n-r)$ where $q,r$ are the quotient,remainder in the division algorithm. I could not proceed any further. In general, I think instead of finding the exact minimum, we only need to show that if $|x_i - x_j|\geq 2$ , then the sum is greater than when we use the most even distribution. This way the two directions of the statement are handled simultaneously. Any suggestion is appreciated. Thanks!","['discrete-optimization', 'optimization', 'combinatorics', 'discrete-mathematics']"
4222797,Calculating $\int_0^\infty \frac{1}{(x^2+1)^n}dx$,"I am trying to determine a closed form expression of the integral $I_n := \int_0^\infty \frac{1}{(x^2+1)^n}dx$ , where $n \in \mathbb{N}$ . I'd like to use residue calculus to solve this problem. I have come up with the following: Let $f_n(x) := \frac{1}{(x^2+1)^n}$ . Since $f_n$ is an even function, we have $$
2I_n = \int_\mathbb{R}\frac{1}{(x^2+1)^n}dx.
$$ Next, consider the function $f_n$ with a complex argument $z \in \mathbb{C}$ . This gives us $$
f_n(z) = \frac{1}{(z^2+1)^n} = \frac{1}{(z+i)^n(z-i)^n}.
$$ Let $r>0$ , $t \in [0,\pi]$ and define the contour $\Gamma := [-r,r] \cup \gamma_r$ , i.e. $\Gamma$ consists of the straight line from $-r$ to $r$ along the real axis, and then the half circle $\gamma_r$ (counterclockwise, with radius $r$ ) from $r$ to $-r$ , i.e. $\gamma_r(t) := re^{it}$ . Then, by the residue theorem: $$
\oint_\Gamma f_n(z)\,dz = \int_{-r}^rf_n(z)\,dz + \int_{\gamma_r}f_n(z)\,dz = 2\pi i \text{Res}(f_n,i),
$$ since $i$ lies within the contour $\Gamma$ . We see that $\lim_{r\to\infty}\int_{\gamma_r}f_n(z)\,dz = 0$ , since \begin{align}
\left|\int_{\gamma_r}f_n(z)\,dz\right| &= \left| \int_0^\pi f_n(\gamma_r(t))\gamma_r'(t)\,dt \right|\\
&= \left| \int_0^\pi \frac{rie^{it}}{(r^2e^{2it}+1)^n}dt \right|\\
&\leq r \int_0^\pi \frac{1}{|r^2e^{2it}+1|^n}dt\\
&\leq r \int_0^\pi \frac{1}{|r^2-1|^n}dt = \frac{\pi r}{|r^2-1|^n} \xrightarrow{\;r \to \infty\;} 0.
\end{align} Hence, we get that $$
2I_n = \lim_{r\to\infty}\oint_\Gamma f_n(z)\,dz = 2\pi i \text{Res}(f_n,i) \implies I_n = \pi i \text{Res}(f_n,i).
$$ Now, we calculate $\text{Res}(f_n,i)$ . Since $i$ is a pole of order $n$ of $f_n$ , we can write $$
\text{Res}(f_n,i) = \frac{1}{(n-1)!}\lim_{z\to i} \frac{\partial^{n-1}}{\partial z^{n-1}}[(z-i)^nf_n(z)] = \frac{1}{(n-1)!}\lim_{z\to i} \frac{\partial^{n-1}}{\partial z^{n-1}} \left[ \frac{1}{(z+i)^n} \right].
$$ Then, we see that \begin{align}
\frac{\partial^{n-1}}{\partial z^{n-1}} \left[ \frac{1}{(z+i)^n} \right] &= n(n+1)(n+2)\cdots(2n-3)(2n-2)\frac{p(n-1)}{(z+i)^{2n-1}} \qquad\qquad (*)
\end{align} where $p$ denotes the ""parity-function"" defined by $$
p : \mathbb{N} \to \{-1,1\}, \qquad n \mapsto 
\begin{cases}
1 & n \text{ even}\\
-1 & n \text{ odd}
\end{cases}.
$$ Then, we get \begin{align}
\frac{1}{(n-1)!}n(n+1)(n+2)\cdots(2n-3)(2n-2)\frac{p(n-1)}{(z+i)^{2n-1}}
=\frac{(2n-2)!}{((n-1)!)^2}\frac{z+i}{(z+i)^{2n}}p(n-1),
\end{align} and finally, by letting $z \to i$ , we obtain $$
\text{Res}(f_n,i) = \frac{(2n-2)!}{((n-1)!)^2}\frac{2i}{(2i)^{2n}}p(n-1) = -\frac{(2n-2)!}{((n-1)!)^2}\frac{2i}{4^n},
$$ where the last equality follows from comparing the signs of $p(n-1)$ and $(2i)^{2n} = (-4)^n$ for different $n \in \mathbb{N}$ . Since $I_n = \pi i \text{Res}(f_n,i)$ , we get $$
I_n = \frac{(2n-2)!}{((n-1)!)^2}\frac{2\pi}{4^n}.
$$ My questions are: Is this formula for $I_n$ correct? Are there any flaws in my proof? I'm not sure that equation $(*)$ is correct. I simply calculated the derivative for $n=1,2, 3$ and then loosely used an inductive argument for the general case. Is there a mistake here?","['complex-analysis', 'contour-integration', 'solution-verification', 'residue-calculus', 'complex-integration']"
4222848,Variance of a Probability density function,"I'm trying to find the variance of the following random variable with density function $$f(x)=\begin{cases}
\frac{3}{2}x(1+x),& \text{ $|x|\leq1$ }  \\ 
 0& \text{  }  o. w
\end{cases}$$ First, we find $\displaystyle E(x)=\frac{3}{2} \int_{-1}^{1}x^2(1+x)dx=1$ and $E(x^2)= \displaystyle \frac{3}{2} \int_{-1}^{1}x^3(1+x)dx= \frac{3}{5}.$ Now, variance of the random variable $x$ is defined  by $V(x)=E(x^2)-(E(x))^2= \frac{3}{5}-1\Rightarrow \frac{-2}{5}<0$ . But, variance can't be negative. Where did I made a mistake?","['probability-distributions', 'probability', 'random-variables']"
4222872,differential inequality with $f$ and $f'$,"Let $f$ be a continuously differentiable function such that for all real numbers $x$ : $$(f(x))^2+(1+f'(x))^2 \leq  1 .$$ How do you prove that $f = 0$ ? I managed to prove that $f$ was bounded between $-1$ and $1$ , $f'$ between $-2$ and $0$ and therefore that $f$ was decreasing and I was trying to integrate the inequality but i'm stuck now .","['inequality', 'derivatives', 'ordinary-differential-equations', 'real-analysis']"
4222909,"A generalization of Elon Musk's favorite interview question (Going 1km South, 1km West, then 1km North returns to the starting position).","This question concerns a generalization of the following problem (allegedly, in the early days of Tesla and SpaceX, Elon Musk would ask the following question to possible future employees): Assume that you are standing on the surface of the Earth and that Earth's surface is perfectly spherical. Find the set of points such that walking $1~\mathrm{km}$ South, $1~\mathrm{km}$ West then $1~\mathrm{km}$ North brings you back to the same position. In case you would like to try and solve this puzzle yourself, I hide the solution below: There are infinitely many points which satisfy this condition. The obvious solution is the North pole. The other set of solutions are the set of points $1~\mathrm{km}$ North of the circles of circumference $1/n~\mathrm{km}$ around the South pole for all $n\in \mathbb{N}$ . If my explanation is unclear, see for instance this YouTube video . I would like to generalize this problem further: Assume that you are standing on the surface of the Earth and that Earth's surface is perfectly spherical. Find the set of points such that walking $x~\mathrm{km}$ at a bearing of $\alpha^{\circ}$ , $y~\mathrm{km}$ at a bearing of $\beta^{\circ}$ then $z~\mathrm{km}$ at a bearing of $\gamma^{\circ}$ brings you back to the same position. The main focus of this question is to obtain this locus. So far I know the following: Suppose you start from the surface of the Earth of radius $R$ at latitude/longitude $(\varphi_1,\lambda_1)$ and walk a ( rhumb line , not geodesic) distance $d$ at a constant bearing $\theta$ . Then it can be shown that the latitude $\varphi_2$ and longitude $\lambda_2$ after walking this distance is (normalize to $\varphi_{1,2}\in [-\pi/2,\pi/2]$ and $\lambda_{1,2}\in [-\pi,\pi)$ if necessary) $$\varphi_2=\varphi_1+\frac{d}{R}\cos(\theta),$$ $$\lambda_2=\lambda_1+\frac{d}{R}\cdot \frac{\sin(\theta)}{q},$$ where $$q:=\begin{cases} \frac{\varphi_2-\varphi_1}{\ln(\tan(\varphi_2/2+\pi/4)/\tan(\varphi_1/2+\pi/4))},&\mathrm{if}~\theta\not\in \{\pi/2,3\pi/2\}, \\ \cos(\varphi_1),&\mathrm{otherwise}. \end{cases}$$ Hence, we are asking for fixed points of the function $f_{z,\gamma}\circ f_{y,\beta}\circ f_{x,\alpha}$ where $f_{d,\theta}$ is defined as $$f_{d,\theta}(\varphi_1,\lambda_1)=(\varphi_2,\lambda_2)$$ where $\varphi_2$ and $\lambda_2$ are as above. The problem is that I do not think it is easy to solve for the fixed points. I also thought about solving such an equation numerically. However, since we are generally dealing with infinitely many solutions (I am not sure if there are special cases with finitely many points), it will be quite difficult to use a root finding method (e.g. Newton-Raphson). Hence, my question is: Given any $x,y,z,\alpha,\beta$ and $\gamma$ is there any way to compute the set of solutions either analytically (an approximate locus is also acceptable) or via some computational methods? UPDATE: Recently I had the idea of using Mathematica to find the locus. Here I define a function RhumbSeqDiff , which computes the norm of the differences between the initial and final latitudes and longitudes after walking the given distances (to test if the program works, I use the parameters in the simplified problem). R = 6371;
x = 1;
y = 1;
z = 1;
alpha = 180;
beta = 270;
gamma = 0;
Rhumb[Phi1_, Lambda1_, Theta_, d_] :=
  ({Phi1Rad = Phi1*(Pi/180);
    Lambda1Rad = Lambda1*(Pi/180);
    ThetaRad = Theta*(Pi/180);
    Phi2Rad = Phi1Rad + (d/R)*Cos[ThetaRad];
    DeltaPsi = 
     Log[Tan[(Phi2Rad/2) + (Pi/4)]/Tan[(Phi1Rad/2) + (Pi/4)]];
    q = If[Theta == 90 || Theta == 270, 
      Cos[Phi1Rad], (Phi2Rad - Phi1Rad)/DeltaPsi];
    DeltaLambda = (d/R)*(Sin[ThetaRad]/q);
    Lambda2Rad = Lambda1Rad + DeltaLambda;
    Phi2Deg = Phi2Rad*(180/Pi),
    Lambda2Deg = Mod[Lambda2Rad*(180/Pi) + 540, 360] - 180});
RhumbSeq[Phi1_, Lambda1_] := 
  Rhumb[Part[
    Rhumb[Part[Rhumb[Phi1, Lambda1, alpha, x], 1], 
     Part[Rhumb[Phi1, Lambda1, alpha, x], 2], beta, y], 1], 
   Part[Rhumb[Part[Rhumb[Phi1, Lambda1, alpha, x], 1], 
     Part[Rhumb[Phi1, Lambda1, alpha, x], 2], beta, y], 2], gamma, z];
RhumbSeqDiff[Phi1_, Lambda1_] := 
  Norm[RhumbSeq[Phi1, Lambda1] - {Phi1, Lambda1}]; I decided to see if the function would work if we select the solutions on the South Pole. Using some simple trigonometry, one finds that the latitudes of these solutions (in degrees) are $${\varphi_n}^{\circ}=-\frac{180}{\pi}\arccos\left(\frac{1}{2\pi R n}\right)+\frac{360}{2 \pi R},\quad \forall n\in \mathbb{N}.$$ I tested if RhumbSeqDiff[-(180/Pi)*ArcCos[1/(2*R*Pi)] + 360/(2*R*Pi), lambda] would return $0$ for any lambda , which is what happened - as expected. However, when I try to plot the function I get some weird results. For instance, if I plot the function along the $n=1$ solution using Plot[RhumbSeqDiff[-(180/Pi)*ArcCos[1/(2*R*Pi)] + 360/(2*R*Pi), x], {x, -180, 180}] , I get dependence on $\lambda$ and the function is nonzero everywhere: My idea was that I could use ContourPlot or RegionPlot to find the locus (such as ContourPlot[RhumbSeqDiff[y,x]==0, {x, -180, 180},{y, -90, 90}] ), but with this bug I am unable to do so. Perhaps this problem is rectifiable?","['mathematica', 'numerical-methods', 'geometry', 'spherical-geometry']"
4222913,How do I determine the expected duration of the walk until absorption at either boundary?,"Consider a random walk $S_n=S_0+\sum^b_{i=1}X_i$ with i.i.d steps $X_i$ taking value $4$ and $-7$ with probabilities $\frac{7}{11}$ and $\frac{4}{11}$ respectively. I would like to find a constant $\gamma$ such that $Y_n=S^2_n-\gamma n$ is a martingale, and hence to determine the expected duration of the walk until absorption at either boundary. My attempt: To impose the martingale condition on $Y_n$ , one has to evaluate $$E[Y_{n+1}|\mathcal{F}_{n}]=E[(S_n+X_{n+1})^2-\gamma(n+1)|\mathcal{F}_n]=S^2_n+E[X^2]-\gamma(n+1)\Leftrightarrow \\E[X^2]-\gamma=0$$ We have that $$E[X^2]=16\left(\frac{7}{11}\right)+49\left(\frac{4}{11}\right)=10.18+17.81\approx28$$ So, $\gamma=28$ Is this correct? How do I determine the expected duration of the walk until absorption at either boundary?","['expected-value', 'martingales', 'probability-theory', 'probability']"
4222998,How do we know if a function has an elementary inverse?,"There are certain elementary functions where the inverse (or the branches of the inverse in a non-injective function, or the inverse over its range for a non-surjective function) is non-elementary. For example, the function $$y=xe^x$$ does not have an inverse that is elementary. Instead we call its inverse the Lambert W function . Another example is, in general, $$y=ax^5+bx^4+cx^3+dx^2+ex+f$$ because an inverse function would imply $$ax^5+bx^4+cx^3+dx^2+ex+f-y=0$$ has an elementary solution, which contradicts the unsolvability of the quintic in general. However, in general, given a function $f(x)$ , how will I determine if the function has an elementary inverse/inverses? (note: an elementary function is a function that can be represented as the finite sum, product and composition of rational functions, radicals, $\exp$ , $\ln$ and trigonometric functions)","['inverse-function', 'elementary-functions', 'functions', 'closed-form', 'algebra-precalculus']"
4223073,Prove that a prime $p\equiv 1 \pmod 8$ can be written in the form $x^2+2y^2.$,"Prove that a prime $p\equiv 1\pmod 8$ can be written in the form $x^2+2y^2.$ I referred to Show every prime $p\equiv 1,3$ (mod 8) can be written as $p=x^2+2y^2$ But it didn't give the solution I require. We are supposed to use break up the numbers $\{1, 2, . . . , p − 1\}$ into
sets of the form $\{x, \bar{x}, -x, -\bar{x}, ix, −ix, i\bar{x}, −i\bar{x}\}$ , where $i^2 \equiv −1
\pmod p$ . Then analyze how many elements these sets have. Here $\bar{x}$ mean the inverse of $x\pmod p$ So we have $\{1, 2, . . . , p − 1\}.$ I didn't get how to incorporate $i.$ So here's the analysis for $\{x, \bar{x}, -x, -\bar{x}\}.$ If $x\equiv \bar{x}\pmod p\implies x^2\equiv 1\pmod p\implies x\equiv 1,p-1.$ This gives ${1,p-1}$ If $x\equiv -{x}\pmod p\implies 2x\equiv 0\pmod p.$ Not possible. If $x\equiv -\bar{x}\pmod p\implies x^2\equiv -1\pmod p.$ Which is possible only when $p\equiv 1\pmod 4.$ And this will give only $x,-\bar{x}$ to be different. That is $-x\equiv \bar{x}\pmod p.$ Now these break elements of $\{1, 2, . . . , p − 1\}$ into groups of $4$ or $2$ ( of ${1,p-1}$ and sometimes ${x,-\bar{x}}$ ) Now, I did the same thing with $\{ix, −ix, i\bar{x}, −i\bar{x}\}.$ If $ix\equiv i\bar{x}\pmod p\implies x^2\equiv 1\pmod p\implies x\equiv 1,p-1.$ If $ix\equiv -{x}i\pmod p\implies 2x\equiv 0\pmod p.$ Not possible. If $ix\equiv -\bar{x}i\pmod p\implies x^2\equiv -1\pmod p.$ This will give us only $x,-\bar{x}$ to be different. Any hints?","['number-theory', 'elementary-number-theory']"
4223123,Rotation around the diameter in Riemann sphere,"Consider Riemann sphere And consider the following projection : The plane $\zeta =0 $ here is the complex plane, and consider the following map: Each point (except the north pole) of the sphere, being mapped to $ \left(\xi,\eta,\zeta\right)\to\left(\frac{\xi}{1-\zeta},\frac{\eta}{1-\zeta},0\right) $ And conversly, the point on the sphere that is being mapped to $(x,y,0) $ given by $$ \left(\frac{x}{x^{2}+y^{2}+1},\frac{y}{x^{2}+y^{2}+1},\frac{x^{2}+y^{2}}{x^{2}+y^{2}+1}\right)\to\left(x,y,0\right) $$ Now, I want to show that the function $ \frac{1}{z},z\in\mathbb{C} $ is represented on the sphere by a $ 180^{\circ} $ rotation about the diameter with endpoints $ \left(-\frac{1}{2},0,\frac{1}{2}\right),\left(\frac{1}{2},0,\frac{1}{2}\right) $ What I have done : I proved that given a point $ z $ which is the image of a point $ \left(\xi,\eta,\zeta\right) $ on the sphere, the point which is mapped to $\frac{1}{z} $ on the sphere, is the point $ \left(\xi,-\eta,1-\zeta\right) $ . So all thre's left to do is to prove that given a point on the sphere $ \left(\xi,\eta,\zeta\right) $ , its rotation about the diameter that I mentioned by $180^{\circ} $ is indeed $ \left(\xi,-\eta,1-\zeta\right) $ . I dont know how to express the rotation since its in 3 dimensions and Im not familier with this. So I'd really apreciate any help. Thanks in advance.","['complex-analysis', 'stereographic-projections', 'riemann-sphere']"
4223144,Strong Law of Large Numbers without assuming $\Bbb{E} X^2 < \infty$,"According to various sources ( Wikipedia , Tao's blog ), the strong law of large numbers-- Let $X$ be a r.v. with expectation $\mu := \Bbb{E}X$ . Then if $X_1, X_2, X_3, ...$ are an iid sequence of copies of $X$ , then $$\Bbb{P}( \lim_{n \to \infty} \overline{X_n} = \mu ) = 1,$$ where $\overline{X_n} = (X_1 + ... + X_n)/n$ is the sample average. does not require the common assumption $\operatorname{Var}(X) < \infty$ ( and still holds true if $\mu = +\infty$ ). Most proofs of the strong law that I've seen in some way rely on finite moments, a particularly common one being $\Bbb{E}X^4 < \infty$ . But sources including the aforementioned Tao's blog frequently mention the complexity involved in proving the strong law without such assumptions, and the proofs I've come across seem a little abstruse. Working from the starting point that SLLN holds for bounded r.v.'s, I came up with the following argument that SLLN holds for generic nonnegative r.v.'s without any assumptions on second moments, but I'm not 100% confident about the interchange of summation and limit towards the end, and I'd appreciate some feedback on whether or not this approach works [or can be modified to work]: Proof attempt: Let $X \geq 0$ be a nonnegative r.v. with finite expectation $\mu = \Bbb{E}X < \infty$ . ( WLOG the underlying sample space, on $X$ and all its iid copies, is $\Omega = [0, 1]$ , the probability measure $\Bbb{P}$ is just Lebesgue measure, and the events are the Lebesgue measurable sets. ) We can write $X = \sum_{k = 1}^\infty A_k$ , where $A_i := X 𝟙_{\{i-1 < X \leq i\}}$ for $i = 1, 2, 3, ...$ Clearly each of the $A_i, i \geq 1$ , are bounded above by $i$ , so they all have finite means as well. Let $\mu_i := \Bbb{E} A_i$ , then $\sum_i \mu_i = \mu$ by linearity of expectation. We take our sequence $\{X_n \}_{n \geq 1}$ of iid copies of $X$ , and we get sequences $\{(A_i)_n \}$ of iid copies of $A_i$ for each $i \geq 1$ , so that $X_n = \sum_i (A_i)_n$ . and also for the sample means, $\overline{X_n} = \sum_i \overline{(A_i)}_n$ . Since $A_i$ is bounded, we are guaranteed that for each $i$ , the event $$E_i := \{ \omega: \lim_n \overline{(A_i)}_n(\omega) = \mu_i \}$$ has $\Bbb{P}(E_i) = 1$ , by our assumption that SLLN holds for bounded r.v.'s. If $$E := \cap_i E_i = \{ \omega: \lim_n \overline{(A_i)}_n( \omega ) = \mu_i, \text{ for all } i \geq 1 \},$$ then $\Bbb{P}(E) = 1$ because $E$ is a countable intersection of events with probability $1$ . Now from here, we would like to be able to interchange limit and sum: \begin{align*}
\lim_n \overline{X_n} &= \lim_n \sum_i \overline{(A_i)_n} \\
 &= \sum_i ( \lim_n \overline{(A_i)_n} ) \\
 &= \sum_i \mu_i \\
 &= \mu \text{ on all of } E, \
\end{align*} but it's not clear that any of the typical conditions (monotone convergence, dominated convergence) which allow us to interchange limits and sums hold here. So we choose $\epsilon > 0$ and appeal to Egorov's theorem to construct, for each $n \geq 1$ , a subset $F_n \subset E$ with $\Bbb{P}(F_n) > 1 - \epsilon/2^n$ , so that $$\sum_i \overline{(A_i)_n} \to \overline{X_n} \text{ uniformly on } F_n.$$ Let $F := \cap_n F_n$ , then $\Bbb{P}(F) > 1 - \sum_{n \geq 1} \epsilon/2^n = 1 - \epsilon$ and $\sum_i \overline{(A_i)_n} \to \overline{X_n}$ uniformly on $F$ for all $n \geq 1$ . So on $F$ , we are justified in interchanging the sum and the limit: $$\lim_n \overline{X_n}(\omega) = \sum_{i \geq 1} \lim_n \overline{(A_i)_n}(\omega) = \sum_{i \geq 1} \mu_i = \mu, \forall \omega \in F,$$ which implies $\Bbb{P}(\lim_n \overline{X_n}(\omega) = \mu) \geq \Bbb{P}(F) > 1 - \epsilon$ for every $\epsilon > 0$ . Therefore $\Bbb{P}(\lim_n \overline{X_n}(\omega) = \mu) = 1$ . $\blacksquare$ Does this work? Was uniform convergence applied correctly in the final stages?","['measure-theory', 'probability-limit-theorems', 'solution-verification', 'uniform-convergence', 'law-of-large-numbers']"
4223163,Prove that if $\sum_k k^2 |a_k|^2 < \infty$ then $\sum_k |a_k| < \infty$. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question During class, the professor made the following statement, but did not prove it. If $\sum_{k=1}^\infty k^2 |a_k|^2 < \infty$ then $\sum_{k=1}^\infty |a_k| < \infty$ . How does one prove that this is indeed true? Here is what I'm stuck on. So since  the first series converges,
I get that $k^2|a_k| \to 0$ , hence, $|a_k|^2 < \frac{1}{k^2}$ for a $k$ sufficiently large. Now, what I'd like to do it to claim that $$|a_k| \leq \frac{1}{k^{1+\varepsilon}}$$ Therefore, I'd get that my series would be dominated by $$\sum |a_k|\leq \sum \frac{1}{k^{1+\varepsilon}} <\infty$$ I have some issues with this approach, first the claim that $|a_k| < \frac{1}{k}$ does not seem quite right, and I'm also not sure I could claim that $|a_k| \leq \frac{1}{k^{1+\varepsilon}}$ . Sorry if this question seems easy, perhaps the very simple solution is simply going over my head.","['convergence-divergence', 'sequences-and-series']"
4223165,Random variable $X$ is symmetric iff $\mathbb{E}\left(X / \left(1 + r^2X^2\right)\right) = 0$ for any $r \in \mathbb{R}$.,"Can you prove/disprove the following claim? Let $X$ be a random variable, which takes values in $\mathbb{R}$ . Assume that $\mathbb{E}\left(X / \left(1 + r^2X^2\right)\right)$ is defined and finite for any $r \in \mathbb{R}$ . The density of $X$ is symmetric about $0$ iff $$\mathbb{E}\left(\frac{X}{1 + r^2X^2}\right) = 0$$ for any $r \in \mathbb{R}$ . A couple of observations: If $X$ is symmetric about $0$ then the expectation is $0$ for any $r \in \mathbb{R}$ because $x/(1+r^2x^2)$ is an odd function. If the expectation condition was instead that $\mathbb{E}(g(X)) = 0$ for any odd function $g$ then it would be clear that $X$ must be symmetric, since we could just choose functions of the form $$g_s(x) = \begin{cases}
-1 & \text{if } x \in (-s - \epsilon, -s),\\
1 & \text{if } x \in (s, s + \epsilon),\\
0 & \text{otherwise}
\end{cases}$$ for any $s > 0$ and arbitrarily small $\epsilon$ 's and just check that the density of $X$ is symmetric. Context: I was watching a conference talk about e-values (more info about e-values here) and the speaker claimed (unless I misunderstood) that the following hypotheses are equivalent: $$X \textrm{ is symmetric},$$ and $$\mathbb{E}\left(1 + \frac{rX}{1 + r^2X^2}\right) \leq 1$$ for any $r \in \mathbb{R}$ . The speaker said that the claim can be shown but I couldn't find the proof in any of his citations.","['statistics', 'probability-distributions', 'probability']"
4223169,Topological spaces with isomorphic categories of open subsets,"Given two topological spaces $X$ and $Y$ , let $\text{Op}(X)$ (resp. $\text{Op}(Y)$ ) be the category of open subsets of $X$ (resp. $Y$ ). If the two categories $\text{Op}(X)$ and $\text{Op}(Y)$ are isomorphic, under what conditions can we say that $X$ and $Y$ are also isomorphic? What kind of information of $X$ can we learn from $\text{Op}(X)$ ? More importantly, what if $X$ is a quasi-projective variety (Zarski topology)?","['general-topology', 'algebraic-geometry', 'category-theory']"
4223193,"Show that $\langle x,x\rangle > 0$ if $x \neq0$","Let $x=(x_1,x_2)$ and $ y=(y_1,y_2)$ be vectors in the vector space $C^2$ over $C$ and define $\langle \cdot,\cdot\rangle : C^2 \times C^2 \rightarrow C$ by $ \langle x,y\rangle =3x_1 \overline{y_1}+(1+i)x_1 \overline{y_2}+(1-i)x_2 \overline{y_1}+x_2 \overline{y_2} $ Show that $\langle x,x\rangle > 0$ if $x \neq0$ . So what I have so far is: $\begin{aligned} \langle x,x\rangle &= 3x_1 \overline{x_1}+(1+i)x_1 \overline{x_2}+(1-i)x_2 \overline{x_1}+x_2 \overline{x_2} \\
&= 3|x_1|^2 + |x_2|^2 +x_1 \overline x_2 + ix_1\overline x_2 - ix_2 \overline x_1 +x_2 \overline x_1 \\
&=3|x_1|^2 + |x_2|^2 + (1+i)(x_1 \overline x_2 - i\overline x_1 x_2)
\end{aligned}$ Now $3|x_1|^2 + |x_2|^2 >0$ if $x \neq0$ , but I don't know how to show that $(1+i)(x_1 \overline x_2 - i\overline x_1 x_2) >0$ as well. Any guidance would be appreciated. Thank you.","['inner-products', 'linear-algebra']"
4223230,"Is there any way to refer to a function $f$, without defining $f$? [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 years ago . Improve this question If I have to refer to a function $f$ without defining it explicitly, what should I write? Or is there no notation I can use but explicitly defining $f$ ?","['notation', 'functions']"
4223249,Having difficult time understanding the solution to this probability problem,"So, the task says: there are 12 passengers and 4 wagons, what is probability that 3 passengers entered every wagon? this is the answer $\frac{\binom{12}{3}\binom{9}{3}\binom{6}{3}\binom{3}{3}}{4^{12}}$ but why instead of $4^{12}$ it doesn't go $12^{4}$ ? I understand that for first wagon we chose 3 out of 12 passenger and hence $\binom{12}{3}$ and so on, but should the same logic be applied for the denominator, shouldn't it be, for the first vagon we can chose 12 passener, for the second the same, and so on? Thank you!","['combinatorics', 'probability']"
4223348,Show that $ \sum_{z\in\mathbb{P}^{1}\left(\mathbb{C}\right)}\text{ord}_{z}\left(f\right)=0$,"$ \mathbb{P}^{1}\left(\mathbb{C}\right) :=\mathbb{C}\cup{\infty} $ (There are  some different definitions, the one that I know is the stereographic projection and defining the image of the north pole under the projection as $\infty $ in $ \mathbb{C} $ . Define also $ \text{ord}_{z=a}\left(f\right) $ as the following: if $ f $ has a zero of multiplicity $m\geq1 $ at $ a $ , then $ \text{ord}_{z=a}\left(f\right)= m $ . if $ a $ is a pole of multiplicity $m\geq 1 $ for $ f $ , then $ \text{ord}_{z=a}\left(f\right) = -m $ if $ f $ defined well\has a removable singularity at $ a $ and $f(a) \neq 0 $ then $ \text{ord}_{z=a}\left(f\right) =0 $ . Prove that the following sum has finitely many nonzero terms and that $ \sum_{z\in\mathbb{P}^{1}\left(\mathbb{C}\right)}\text{ord}_{z}\left(f\right)=0 $ Where we define $ \text{ord}_{z=\infty}\left(f\right)=\text{ord}_{\omega=0}\left(g\right) $ Where $ g $ is the nonzero meromorphic function defined by $ g\left(\omega\right):=f\left(\frac{1}{\omega}\right) $ . Im have absolutely no intuition for the proof, I cant even understand why it is correct. For example what about the function $ \frac{1}{z}+\frac{1}{z-1} $ ? It has a pole of order $ 1 $ in $0 $ and in $ 1 $ so that together it summed to $-2 $ , and the order at $\infty $ is the order of $ z+\frac{z}{1-z} $ at $0 $ , which is $1$ . So it seems like the sum is not $0 $ . Any help would be appreciated.",['complex-analysis']
4223396,Let $A = (a_{ij})$ be an an $n \times n$ matrix such that $\max\lvert a_{ij} \rvert < \cfrac{1}{n}$. Show that $I-A$ is invertible,"Just wondering if the following solution I had works: (Note here im using the norm $\lVert A\rVert_{1} = \max_{1\leq j \leq n} \sum_{i=1}^n \rvert a_{ij} \lvert$ ) Suppose BWOC that $I-A$ is not-invertible. Then, $I-A$ has a non-trivial kernel $\implies$ $1$ is an eigenvalue of $A \implies \exists \mathbf{v} \neq 0$ such that $A\mathbf{v} = \mathbf{v}$ . Now since $\lVert A\mathbf{v} \rVert_1 \leq \lVert A \rVert_1 \lVert \mathbf{v} \rVert_1$ (proved in previous part of the question) we have $\lVert \mathbf{v} \rVert_1 \leq \lVert A \rVert_1 \lVert \mathbf{v} \rVert_1 \implies \lVert A \rVert_1 \geq 1$ . But, (using definition of norm above and that $\max\lvert a_{ij} \rvert < \cfrac{1}{n}$ ) $\lVert A \rVert_1 < n\cfrac{1}{n} = 1$ . Contradiction.","['matrices', 'normed-spaces', 'linear-algebra']"
4223426,A simple general expression for a definite integral,"Let $$I_k = \int_0^{\frac{\pi}{2}} \sin x \cos^{2k} x \sqrt{1 + \sin x} \, dx,$$ where $k = 0,1,2,\ldots$ . I wish to find a simple general expression for $I_k$ in terms of $k$ . Simple here is the operative word. Making a tangent half-angle substitution of $t = \tan \frac{x}{2}$ produces $$I_k = 4\int_0^1 \frac{t(1 + t)^{2k + 1} (1 - t)^{2k}}{(1 + t^2)^{2k + \frac{5}{2}}} \, dt.$$ Trying to guess its general form one notices: \begin{align*}
k = 0 : \quad I_0 &= 4\int_0^1 \frac{t(1 + t)}{(1 + t^2)^{\frac{5}{2}}} \, dt = 4 \left [\frac{(t - 1)(t^2 + t + 1)}{3(t^2 + 1)^{\frac{3}{2}}} \right ]_0^1 = \frac{4}{3}\\
k = 1 : \quad I_1 &= 4\int_0^1 \frac{t(1 + t)^3(1 - t)^2}{(1 + t^2)^{\frac{9}{2}}} \, dt = 4 \left [\frac{(t - 1)^3(11t^4 + 33t^3 + 52t^2 + 33t + 11)}{105(t^2 + 1)^{\frac{7}{2}}} \right ]_0^1 = \frac{44}{105}\\
k = 2 : \quad I_2 &= 4 \int_0^1 \frac{t(1 + t)^5(1 - t)^4}{(1 + t^2)^{\frac{13}{2}}} \, dt = 4\left [\frac{(1 - t)^5(211t^6 + 1055t^5 + 2593 t^4 + 3370t^2 + 1055t + 211)}{3465(t^2 + 1)^{\frac{11}{2}}} \right ]_0^1 = \frac{844}{3465}
\end{align*} So it appears $$I_k = 4 \left [\frac{(t - 1)^{2k + 1}p_k(t)}{a_k(t^2 + 1)^{2k + \frac{3}{2}}} \right ]_0^1,$$ where $a_k$ is a positive integer and $p_k(t)$ is a symmetric polynomial of degree $(2k + 2)$ . But what is $a_k$ and $p_k(t)$ ? Alternatively, a closed-form expression in terms of the hypergeometric function can be found. It is $$I_k = \frac{2}{3\sqrt{2}} {}_2 F_1 \left (\frac{3}{2},-2k;\frac{5}{2};1 \right ) + \frac{1}{2^{2k + \frac{3}{2}}(2k+1)} {}_2F_1 \left (2k + 1,2k + \frac{5}{2};2k + 2; \frac{1}{2} \right ),$$ but this is hardly simple since ultimately $I_k$ is just a positive rational number. Perhaps this expression can be simplified in some way. So my question is, can a simple expression for $I_k$ be found?","['integration', 'definite-integrals', 'closed-form', 'hypergeometric-function']"
4223458,What would you call an equation that determines the maximum value of a regression line on a bell-shaped scatterplot?,"Please forgive the vagueness of my question, it has been a while since I have done this sort of math and I'm simply looking for the correct type of wording to further research this problem. Given that I have a data set that produces a scatter plot in bell-shaped curve similar to this image: My goal is to create a curve that fits this scatter plot as shown above, and then calculate the maximum value at the peak of the curve. For example, what is the expected value on the x-axis that is most likely to correlate with the highest value on the y-axis. I'm assuming that this will also provide some degree of statistical significance and also require a software such as R. It has been a decade since I have done this type of math and the vocabulary I need to look this up and refresh myself on these concepts is escaping me. Any insight would be appreciated.",['statistics']
4223573,Interversion of limit and summation of double-indexed sequence [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Assume we have a sequence $(a_{m,n}) \in [0,1]^{\mathbb{N}\times \mathbb{N}}$ such that $a_{m,n} \rightarrow a_n\in [0,1]$ when $m \rightarrow \infty$ . Are there any known conditions under which $\sum_{n=0}^{\infty} a_{m,n} \rightarrow \sum_{n=0}^{\infty} a_n$ when $m \rightarrow \infty$ ? Assume it is known that both series converge.","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
4223576,Finding the anti-derivative of $ \frac{e^{-c y^2 }}{y\sqrt{y^2-1}}$,"I am trying to evaluate the integral \begin{align}
\frac{1}{2\sqrt{2}\pi}\int_{0^{-}}^{t} ds \ \frac{e^{-x^2/2S^2(t,s) }}{\Sigma(s) S(t,s)}
\end{align} where $S(t, s) = 2D(t-s)+\frac{\Sigma(s)}{2}$ and $\Sigma(s)= \sigma^2+2Ds$ . I found a rather neat change of variable by taking $\xi=S^{-1}(t,s)$ so that \begin{align}
\Sigma(s)&=\sqrt{2} \ \xi^{-1}\sqrt{\xi^2\Sigma^2(t)-1}\\
2D(t-s)&=2 \ \xi^{-2}-\Sigma^2(t)\\
ds&=\frac{2}{D\xi^3}\ d\xi
\end{align} Applying this to the integral gives the result \begin{align}
\frac{1}{2 \pi D}\int_{\sqrt{2}/\Sigma (2 t)}^{\sqrt{2}/\Sigma (t)} d{\xi} \ \frac{e^{-x^2 \ \xi^2/2 }}{\xi\sqrt{\Sigma^2(t)\xi^2-1}}=\frac{1}{2 \pi D}{\int_{\xi_L}^{\xi_H} d{\xi} \frac{e^{-x^2 \ \xi^2/2 }}{\xi\sqrt{\Sigma^2(t)\xi^2-1}}}.
\end{align} and at last applying the change of variable $y=\Sigma(t)\xi$ gives \begin{align}
\frac{1}{2 \pi D}{\int_{\xi_L}^{\xi_H} d{\xi} \frac{e^{-x^2 \ \xi^2/2 }}{\xi\sqrt{\Sigma^2(t)\xi^2-1}}} = \frac{1}{2 \pi D}{\int_{\sqrt{2}\Sigma(t)/\Sigma(2t)}^{\sqrt{2}} d{y} \frac{e^{-(x^2/2\Sigma^2(t)) y^2 }}{y\sqrt{y^2-1}}} =\frac{1}{2 \pi D}\color{blue}{\int_{a}^{b} d{y} \frac{e^{-c y^2 }}{y\sqrt{y^2-1}}}
\end{align} Above calculation indeed check out numerically. It seems the integral in blue could have an anti-derivative. However, no luck just yet!  Someone who knows a way forward? Many thanks in advance!","['integration', 'calculus', 'definite-integrals', 'gaussian-integral']"
4223579,Can a positive definite second order elliptic operator over an unbounded domain give rise to a compact semigroup?,"Let $A$ denote some positive definite second order elliptic operator which is defined over $L^2(\Omega)$ with domain $D(A) = H^{2m}(\Omega) \cap H^{m}_{0}(\Omega)$ . Here $\Omega$ is a bounded domain in $R^m$ . Assume that the coefficient functions of $A$ are nice enough, then it can be shown that the semigroup generated by $A$ is compact. Now what if $\Omega$ is $[0, \infty)$ ? Is it possible that $A$ can still generate compact semigroup, if replacing the function spaces in the bounded case by some weighted function spaces? If so, are there any references please?","['operator-theory', 'compact-operators', 'functional-analysis', 'partial-differential-equations']"
4223609,Square differential forms in cohomology,"Let $X$ be a differentiable manifold (connected, compact, orientiable) of dimension $4n$ . Consider on $X$ a closed $2n$ -form $\omega$ , with associated cohomology class $[\omega] \in H^{2n}(X,\mathbb{R})$ . The integral of its square is some real number, $$
\int_X \omega \wedge \omega \in \mathbb{R} \,,
$$ which may be negative, positive, or zero. In general, the integrand $\omega \wedge \omega$ need not have the same sign everywhere as the result of the integral. However, the integral $\int_X \omega \wedge \omega$ is a function only of the cohomology class $[\omega]$ , while $\omega \wedge \omega$ depends on the choice of representative $\omega \in [\omega]$ . So my question is: Is it possible to find a cohomologically equivalent $\omega' \in [\omega]$ such that everywhere $\mathrm{sgn}\big(\omega' \wedge \omega'\big) = \mathrm{sgn}\big(\int_X \omega \wedge \omega\big)$ ? In the case that the answer is negative, I wonder if one can give criteria under which it holds. A negative answer was given to a related question here . However, that answer crucially relied on the existence of the Massey triple product, which vanishes in the present case, so it doesn't seem possible to make a similar argument here.","['homology-cohomology', 'de-rham-cohomology', 'differential-forms', 'differential-geometry']"
4223615,Evaluating $\frac12+\frac14+\frac18+\frac1{10}+\frac1{20}+\frac1{22}+\frac1{44}+\frac1{46}+\frac1{92}+\cdots$,How can I find the value of this series? $$\dfrac{1}{2} + \dfrac{1}{4} + \dfrac{1}{8} + \dfrac{1}{10} + \dfrac{1}{20} + \dfrac{1}{22} + \dfrac{1}{44} + \dfrac{1}{46} + \dfrac{1}{92}+\cdots$$ The pattern is that the denominator increases by $2$ first and then it gets multiplied by $2$ . I converted this series to this form: $$\dfrac{1}{2} + 3\left(\dfrac{1}{8} + \dfrac{1}{20} + \dfrac{1}{44} + \dfrac{1}{92}+\dots\right)$$ In this version the denominator is multiplied by $2$ and added 4. I have found out that how to find the $n$ -th value in the denominator and it is $2^{n+1} \cdot 3  - 4$ . How can I find the exact value of this series?,['sequences-and-series']
4223710,"$\frac{dx}{dt} = x-xy,\quad \frac{dy}{dt} = -y+xy.$ Find the range of values of $\ x\ $ and $\ y\ $ for which both variables are increasing.","$$\frac{dx}{dt} = x-xy,\quad \frac{dy}{dt} = -y+xy.$$ Find the range of values of $\ x\ $ and $\ y\ $ for which both
variables are increasing. Here, increasing means the derivative is $\ >0.$ My attempt: $x-xy>0,\quad -y+xy>0 \implies x>y.$ We also have: $\ x(1-y)>0\ \implies \text{either}\ (\ x>0\ \text{and}\ y<1\ )\quad \text{or}\ (\ x<0\ \text{and}\ y>1\ ).$ and $y(-1+x)>0\implies\ (\ y>0\ \text{and}\ x>1\ )\quad \text{or}\ (\ y<0\ \text{and}\ x<1\ ),$ But now I don't know where to go from here without getting confused. We can also say that $\ x(-1+x)>y(-1+x)>0,\ $ assuming that $\ ( \ y>0\ $ and $\ x>1),\ $ or $\ ( \ y<0\ $ and $\ x<1).$ and try to make sense of the quadratic inequality in $x,$ but the different cases make this a headache. Note that this is a difficult A Level problem, so should be solvable quite quickly. I'm confident that I'm missing something straightforward.","['derivatives', 'problem-solving', 'ordinary-differential-equations']"
4223712,Number of cute permutations,"A permutation of the numbers $1,2,3,\dots,n$ is called cute if there is exactly one number that is greater than its position. For example, $1,4,3,2$ is a cute permutation (when $n=4$ ) because only the number $4$ is greater than its position. How many cute permutations there for a fixed $n$ ? The problem is from a local math contest. Here is my attempt in solving the problem: I've noticed that if $p_1,p_2,\dots,p_n$ is a cute permutation where $p_k>k$ then for all $i\neq k$ , we have $p_i\leq i$ . But I don't think this is helpful in finding the number of cute permutations. I also tried for small values of $n$ by listing all the possible permutations. For $n=2$ , it's easy to see that there is only one such permutation. For $n=3$ , I found $4$ permutations. For $n=4$ , I found $10$ permutations. From here it seems to me that the the number of cute permutations is $\binom 22+\binom 32+\dots+\binom n2$ . But I couldn't find a way to show that. So, how to solve the problem? And what happens if we call a permutation less cute if there are exactly two numbers that are greater than its position? Can we solve in general?","['contest-math', 'proof-writing', 'combinatorics']"
4223715,How to shorten this rational function?,"Determine a value for the constant b so that we can shorten the expression for the function $f\left(x\right)=\frac{2x^2+bx-30}{x+3}$ . Shorten the expression. Here is the step by step solution we got: The zero point for the denominator $x+3$ is $x=-3$ The function $f$ is defined when $x\ne-3$ We can shorten the expression only if the denominator and numerator have a common factor. The numerator has the factor $x+3$ only if $-3$ is the zero point in the numerator. We determine the constant b: The numerators value is zero for the variable value $-3$ . $2\cdot\left(-3\right)^2+b\cdot\left(-3\right)-30=0$ $b=-4$ Now I don't understand why x is replaced with $-3$ above. What is the reason behind it, why can't it be for example be $-4$ ? edit: need an easy explanation, I'm not too good at math.","['calculus', 'functions', 'rational-functions', 'algebra-precalculus', 'derivatives']"
4223732,Exercise 9.3.H in Ravi Vakil’s Foundations of Algebraic Geometry.,"I am following the hint given in Exercise 9.3.H of Ravi Vakil’s notes. It can be found on page 261, here . The exercise states: any finitely presented morphism $\pi:X\to\operatorname{Spec} B$ is a pullback of a finite type morphism $\pi’:X’\to\operatorname{Spec} \mathbb{Z}[x_1,\cdots,x_N]$ for some integer $N$ . It is easy when $X$ is affine, but I am stuck considering more general cases. Any hints or comments would be appreciated. Thank you very much!",['algebraic-geometry']
4223741,Solution verification for limit problem $\lim\limits_{x\to 0}\dfrac{\sin(4x)\tan^2(3x)+6x^2}{2x^2+\sin(3x)\cos(2x)}.$,"Find the value of $$\lim\limits_{x\to 0}\dfrac{\sin(4x)\tan^2(3x)+6x^2}{2x^2+\sin(3x)\cos(2x)}.$$ I try as below. \begin{align}
\lim\limits_{x\to 0}\dfrac{\sin(4x)\tan^2(3x)+6x^2}{2x^2+\sin(3x)\cos(2x)}&=\lim\limits_{x\to 0}\dfrac{6x^2\left(\dfrac{\sin(4x)\tan^2(3x)}{6x^2}+1\right)}{2x^2\left(1+\dfrac{\sin(3x)\cos(2x)}{2x^2}\right)}\\
&=3\lim\limits_{x\to 0}\dfrac{\left(\dfrac{\sin(4x)}{4x}\cdot\left(\dfrac{\tan(3x)}{3x}\right)^2 6x+1\right)}{\left(1+\dfrac{\dfrac{1}{2}\left(\sin(5x)+\sin(x)\right)}{2x^2}\right)}\\
&=3\lim\limits_{x\to 0}\dfrac{\left(\dfrac{\sin(4x)}{4x}\cdot\left(\dfrac{\tan(3x)}{3x}\right)^2 6x+1\right)}{\left(1+\dfrac{\sin(5x)}{4x^2}+\dfrac{\sin(x)}{4x^2}\right)}\\
&=3\lim\limits_{x\to 0}\dfrac{\left(\dfrac{\sin(4x)}{4x}\cdot\left(\dfrac{\tan(3x)}{3x}\right)^2 6x+1\right)}{\dfrac{1}{x}\left(x+\dfrac{5}{4}\dfrac{\sin(5x)}{5x}+\dfrac{1}{4}\dfrac{\sin(x)}{x}\right)}\\
&=3\lim\limits_{x\to 0}\dfrac{\left(\dfrac{\sin(4x)}{4x}\cdot\left(\dfrac{\tan(3x)}{3x}\right)^2 6x^2+x\right)}{\left(x+\dfrac{5}{4}\dfrac{\sin(5x)}{5x}+\dfrac{1}{4}\dfrac{\sin(x)}{x}\right)}\\
&=3\dfrac{\left(\lim\limits_{x\to 0}\dfrac{\sin(4x)}{4x}\left(\lim\limits_{x\to 0}\dfrac{\tan(3x)}{3x}\right)^2 \lim\limits_{x\to 0} 6x^2+\lim\limits_{x\to 0} x\right)}{\left(\lim\limits_{x\to 0} x+\dfrac{5}{4}\lim\limits_{x\to 0} \dfrac{\sin(5x)}{5x}+\dfrac{1}{4}\lim\limits_{x\to 0} \dfrac{\sin(x)}{x}\right)}\\
&=3\cdot\dfrac{1\cdot 1^2\cdot 0+0}{0+\dfrac{5}{4}+\dfrac{1}{4}}\\
&=0.
\end{align} I'm not sure with my answer. Does my answer correct?","['limits', 'trigonometry', 'solution-verification']"
4223799,Existence of zero for sequence of functions for which the limit function has a zero,"Let $f_n \colon \mathbb R^d \to \mathbb R^d$ be a sequence of smooth functions and let $f \colon \mathbb R^d \to \mathbb R^d$ be its limit such that $\lim_{n \to \infty} f_n(x) = f(x)$ for all $x \in \mathbb R^d$ , which is also smooth. I assume that there exists $x_0 \in \mathbb R^d$ such that $f(x_0) = 0$ and $\det J_f(x_0) \neq 0$ , where $J_f$ denotes the Jacobian matrix of the function $f$ . I would like to prove (by also adding other assumptions if necessary) or disprove that there exists $N > 0$ such that for all $n > N$ there exists $x_n \in \mathbb R^d$ (not necessarily unique) which satisfies $f_n(x_n) = 0$ and $\lim_{n \to \infty} x_n = x_0$ . In the one-dimensional case ( $d = 1$ ) I proved that the result holds. However, for higher dimensions $d > 1$ this seems either non-trivial or false.","['analysis', 'real-analysis']"
4223803,What is $\det (W^T A W)$ for $W$ not square?,"I am sure the answer to this question is out there, but I cannot find it, maybe because I don't know the correct torm for 'matrix multiplication from left and right'. Consider a matrix $W \in \mathbb{R}^{m \times n}$ and a square matrix $A \in \mathbb{R}^{m \times m}$ . What can we say about the determinant $$\det (W^TAW)?$$ In the case that $W$ is also square, since the determinant then commutes, we have $$\det (W^TAW) = \det (A WW^T) = \det (A) \det (WW^T) = \det(A) \det(W^TW).$$ Do we have a similar result when $W$ is not square? We can not expect the two last equalities on the left generally hold, since one of $\det (WW^T)$ and $ \det(W^TW)$ will be equal to $0$ , but maybe it holds for the respective one that might have full rank? Edit: Maybe this works indeed, using singular value decomposition: Let $W = U \Sigma V$ and assume $W$ has full rank, and assume that $m<n$ , such that $U$ is an orthogonal $m\times m$ matrix, $V$ is an orthogonal $n \times n$ matrix, and $\Sigma \in \mathbb{R}^{m\times n}$ is of the form $\begin{pmatrix}D & 0\end{pmatrix}$ with $D$ diagonal. Then $$\det (W^T AW) = \det (V^T \Sigma^T U^T A U \Sigma V) = \det ( \Sigma^T U^T A U \Sigma VV^T) = \det ( \Sigma^T U^T A U\Sigma)$$ Bot now if we denote $U^TAU=B$ , then $$\Sigma^T B \Sigma = \begin{pmatrix}D \\ 0\end{pmatrix} B \begin{pmatrix}D & 0\end{pmatrix} = DBD $$ . But then $$\det(\Sigma^T U^T A U\Sigma) = \det (\Sigma^TB\Sigma) = \det (\Sigma^T\Sigma B) = \det(D^2) \det(B) = \det(D^2) \det(U^TAU) = \det(D^2) \det(A) =\det(WW^T)\det(A).$$ Is this correct? second edit : the 'solution' above must contain an error, since we obviously have that the determinant is zero in the case that $m<n$ ...","['matrices', 'determinant', 'linear-algebra']"
4223817,How to evaluate $\int_{-\infty}^{\infty}e^{x-n\sinh^2 x}\ dx$,This is what I tried: $$\sum_{k=0}^{\infty}\int_{-\infty}^{\infty}\dfrac{(x-n\sinh^2 x)^k}{k!}\ dx$$ $$\sum_{k=0}^{\infty}\frac1{k!}\int_{-\infty}^{\infty}\sum_{r=0}^{k}\binom{k}{r}x^r(-n\sinh^2 x)^{k-r}\ dx$$ After this I have no idea how to proceed,"['integration', 'calculus', 'definite-integrals']"
4223880,Show that $\Gamma^{(n)}(z) = \int_0^\infty t^{z-1}(\log(t))^ne^{-t}dt$,"So, I need to show that the n-th derivative of Gamma function is equal to: \begin{equation}
\Gamma^{(n)}(z) = \int_0^\infty t^{z-1}(\log(t))^ne^{-t}dt
\end{equation} I already know that: \begin{equation}
\Gamma(z) = \lim_{n \to \infty}\int_0^n t^{z-1}(1-\frac{t}{n})^n dt = \lim_{n \to \infty} \gamma_n(z)
\end{equation} I also see that: \begin{equation}
\gamma_n'(z_0) = \lim_{z \to z_0} \int_0^n (1-\frac{t}{n})^n \cdot \frac{t^{z-1} - t^{z_0-1}}{z - z_0} dt
\end{equation} Now, if I could show that \begin{equation}
\frac{t^{z_n-1} - t^{z_0-1}}{z_n - z_0} \to t^{z_0 - 1}\log(t)\textrm{ uniformly, as } n \to \infty  \; (z_n \to z_0) \; \; \; \; \; \;(1)
\end{equation} then I would be able to pull the limit to the inside of the integral and get: \begin{equation}
\gamma_n'(z_0) = \int_0^n t^{z-1}\log(t)(1-\frac{t}{n})^n dt
\end{equation} From which I see how I can get $\Gamma'(z_0) = \int_0^\infty t^{z-1}\log(t)e^{-t}dt$ . However, I don't know how to prove $(1)$ . Could someone please help me?","['gamma-function', 'calculus', 'derivatives', 'real-analysis']"
4223924,"Finding a Solution to a Log-Linear System of Equations, or Showing Existence of Such a Solution","I'm trying to find the solution ( $x^*_1, y^*_1, x^*_2, y^*_2$ ) to the following system of equations: $$
gx_1=\lambda\left(\log \frac{x_2}{1-x_2}-\log \frac{x_2 + y_2}{2-x_2-y_2}\right)\\
by_1=\lambda\left(\log \frac{y_2}{1-y_2}-\log \frac{x_2 + y_2}{2-x_2-y_2}\right)\\
bx_2=\lambda\left(\log \frac{x_1}{1-x_1}-\log \frac{x_1 + y_1}{2-x_1-y_1}\right)\\
gy_2=\lambda\left(\log \frac{y_1}{1-y_1}-\log \frac{x_1 + y_1}{2-x_1-y_1}\right)\\
$$ Here, $g>0>b$ and $\lambda>0$ . I suspect that this cannot be done analytically, but would love to be corrected. If it can't be done analytically, I'd also like to prove that such a solution must exist. I'd really appreciate any help, or any possible direction in how to attempt this.","['algebra-precalculus', 'systems-of-equations', 'fixed-point-theorems', 'real-analysis']"
4223928,Linear PDE in n+1 dimension given t=0 condition,"Given the following PDE: $$\frac{\partial}{\partial t} f(x,y,t) = x \frac{\partial f}{\partial y} - y \frac{\partial f}{\partial x}$$ And initial condition: $$f(x,y,0) = g(x,y) = x^2+y^2$$ How do we determine $f$ for all time? My thinking is as follows: the initial function (paraboloid) is being modified by a certain vector field defined by the RHS of the equation, and it determines the shape of the function for $t > 0$ So suppose we have a vector field $v(x,y) = (-y,x)$ then the vector field $v$ represents the movement of the function through time. And the local flow of any particle starting at $(x, y)$ is $p(t) = (-yt + x, xt+y)$ . So in this case $p$ represents a curve in $R^2$ going through time, starting at $(x,y)$ and being moved by the said vector field. So the solution of the PDE is obtained by composing $g$ with $p$ , that is: $$f(x,y,t) = g(p(t)) = (-yt+x)^2 + (xt+y)^2 = (x^2+y^2)(t^2+1)$$ So at first glance it does satisfy the initial condition, but it does not satisfy the main PDE itself. $$\frac{\partial f}{\partial t} = 2t(x^2+y^2)$$ But $$\frac{\partial f}{\partial x} = 2x(t^2+1)$$ $$\frac{\partial f}{\partial y} = 2y(t^2+1)$$ So the RHS of the equation is zero What did I do wrong here?","['initial-value-problems', 'partial-differential-equations', 'differential-geometry']"
4223937,How to come up with formula to get minimum sell price to profit on commodity exchange,"I'm stuck trying to come up with an equation that will calculate the minimum sale price of a commodity (such as Bitcoin) in order to at least break even. That in it of itself is no problem, sell for same price it was purchased for at the minimum. The issue I'm running into is, based on my several searches, one variable is dependent on another variable. To be specific, if I purchase something for $100, with .5% of the purchase being a fee, how do I figure out what my sale price of that same quantity will need to be in order to break even? If I'm thinking about this correctly, my independent variable is sale price, while the dependent variable is the sale fee. I've tried different things, but I can't seem to get the result I'm looking for. I'll use the following variables: a =  purchase price
b =  purchase fee (constant, 0.5% or 0.005)
c =  sale price
d =  sale fee (constant, 0.5% or 0.005) The first equation I come up with, and with the help of online formula solver to simplify: $$c = (a * (1 + b)) / (1 + d).$$ But the fee is not supposed to be additive, this comes out of the purchase and sale prices $$(c - (c * .005)) - (a - (a * .005)).$$ But I don't even know what c is. So if I use the online formula solver to solve for c, I get: $$ c = a.$$ I can trial and error in a spreadsheet until I get my profit to show $0.00 so I know what my minimum sale price is. But trying to convert that into a C# program is proving to test my limited knowledge in math. Can anybody point me in the right direction on how to logic this out to the point I can program it?","['functions', 'graphing-functions']"
4223952,Calculate $ \intop_{0}^{\infty}\frac{1}{x^{6}+x^{3}+1}dx $ (Using line integral) (complex analysis),"I want to calculate the integral $$ \intop_{0}^{\infty}\frac{1}{x^{6}+x^{3}+1}dx $$ using a line integral $\varGamma $ which is the boundary of an arc of a circle of radius $ R $ and $ 0\leq Arg(z) \leq 2\pi/3 $ Such a path $\gamma $ is sort of a slice of pizza. Now I'm gonna denote this path $ \gamma $ and decompose it into 3 parts. One part - the part that lies on the real axis, given by $ x, R\leq x \leq 0 $ . Second part - the arc of the circle which we'll parametrize $ Re^{i\theta},\thinspace\thinspace\thinspace0\leq\theta\leq\frac{2\pi}{3} $ And the last part, a ray from the origin with phase $2\pi/3 $ and length R (the radius of this pizza slice), which we'll parametrize $ xe^{i\frac{2\pi}{3}}\thinspace\thinspace\thinspace0\leq x\leq R $ So we get $$ \intop_{\gamma}\frac{1}{z^{6}+z^{3}+1}dz=\intop_{0}^{R}\frac{1}{x^{6}+x^{3}+1}dx-\intop_{0}^{R}\frac{e^{i\frac{2\pi}{3}}}{x^{6}+x^{3}+1}dx+\intop_{0}^{\frac{2\pi}{3}}\frac{Rie^{i\theta}}{R^{6}e^{6i\theta}+R^{3}e^{3i\theta}+1}d\theta $$ And notice that $$ \intop_{0}^{\frac{2\pi}{3}}\frac{Rie^{i\theta}}{R^{6}e^{6i\theta}+R^{3}e^{3i\theta}+1}d\theta \to 0 $$ When $ R \to \infty $ . Also, by the Residue theorem of Cauchy, we get $$ \intop_{\gamma}\frac{1}{z^{6}+z^{3}+1}dz=2\pi i\text{Res}\left(\frac{1}{z^{6}+z^{3}+1};z_{k}\right) $$ So when $ R \to \infty $ , the line integral would be the summation of all the poles of the integrand inside $\gamma$ , that is, all the poles with the argument between $ 0 $ and $2\pi/3$ . Now I have checked, and found that the poles of $f $ which satisfies this conditions are $ e^{i\frac{2\pi}{9}},e^{i\frac{4\pi}{9}} $ So that $$ 2\pi i\left(\text{Res}\left(\frac{1}{z^{6}+z^{3}+1};e^{i\frac{2\pi}{9}}\right)+\text{Res}\left(\frac{1}{z^{6}+z^{3}+1};e^{i\frac{4\pi}{9}}\right)\right)=\left(1-i\frac{2\pi}{3}\right)\intop_{0}^{\infty}\frac{1}{x^{6}+x^{3}+1}dx $$ Now, for a function which has a simple pole at $z_k$ we can write the function as $ \frac{A\left(z\right)}{B\left(z\right)} $ where $B$ has a zero at the pole and $ A $ does not have a zero. And the residue is given by $$\lim_{z\to z_{k}}\left(z-z_{k}\right)\frac{A\left(z\right)}{B\left(z\right)}=\frac{A\left(z\right)}{B'\left(z\right)} $$ evaluated at $z_{k}$ So in order to find the residue of my poles, I found the derivative of the denominator and let z= the pole. So finally I got after all the calculations that the integral should be $$ \left(\frac{1}{6e^{i\frac{10}{9}\pi}+3e^{i\frac{4}{9}\pi}+1}+\frac{1}{6e^{i\frac{20}{9}\pi}+3e^{i\frac{4}{9}\pi}+1}\right)2\pi i\frac{1}{1-e^{i\frac{2}{3}\pi}} $$ Which is not real (I checked, unfortunately) What am I missing? what went wrong? Thanks in advance.",['complex-analysis']
4223956,Does anything special happen when you replace the direct product in the definition for a wreath product with a central product?,"In group theory there is a special type of product called the wreath product and is defined as follows: Let $A$ and $H$ be groups, with the group $H$ acting on the set $\Omega$ . We define $K$ to be the direct product: $$K = \prod_{\omega \in \Omega} A_{\omega}$$ the duplicates, $A_{\omega}$ of the group $A$ being indexed by elements of the set $\Omega$ . What happens when we change the direct product in this definition with a central product? Does that change anything? If the answer is yes, then does this type of product have a name?","['direct-product', 'group-theory', 'definition', 'wreath-product']"
4223994,Is there any quick way to classify a group from list of abelian groups?,"I'm trying to solve the following problem Classify group of order $720$ which has exactly $14$ elements of order $6$ By using fundamental theorem of abelian groups, I found following $10$ abelian groups of order $720$ . $\mathbb{Z}_{16}\times\mathbb{Z}_5\times\mathbb{Z}_3\times\mathbb{Z}_3$ . $\mathbb{Z}_{16}\times\mathbb{Z}_5\times\mathbb{Z}_9$ . $\mathbb{Z}_4\times\mathbb{Z}_4\times\mathbb{Z}_5\times\mathbb{Z}_3\times\mathbb{Z}_3$ . $\mathbb{Z}_4\times\mathbb{Z}_4\times\mathbb{Z}_5\times\mathbb{Z}_9$ . $\mathbb{Z}_2\times\mathbb{Z}_8\times\mathbb{Z}_5\times\mathbb{Z}_3\times\mathbb{Z}_3$ . $\mathbb{Z}_2\times\mathbb{Z}_8\times\mathbb{Z}_5\times\mathbb{Z}_9$ . $\mathbb{Z}_2\times\mathbb{Z}_2\times\mathbb{Z}_4 \times\mathbb{Z}_5\times\mathbb{Z}_3\times\mathbb{Z}_3$ . $\mathbb{Z}_2\times\mathbb{Z}_2\times\mathbb{Z}_4 \times\mathbb{Z}_5\times\mathbb{Z}_9$ . $\mathbb{Z}_2\times\mathbb{Z}_2\times\mathbb{Z}_2\times\mathbb{Z}_2 \times\mathbb{Z}_5\times\mathbb{Z}_3\times\mathbb{Z}_3$ . $\mathbb{Z}_2\times\mathbb{Z}_2\times\mathbb{Z}_2\times\mathbb{Z}_2 \times\mathbb{Z}_5\times\mathbb{Z}_9$ . How to classify the one asked in question? What is the smartest way to do this? Do we have to count the number of elements in each group individually?","['group-theory', 'abstract-algebra', 'abelian-groups']"
4224015,Question 4A.9 of Finite group theory by Martin Isaacs,"Let $G = NA$ , where $N \lhd G$ and $ A \subseteq G$ , and let $M$ be the final term in the series $$N \supset [N, A] \supset [N, A, A] \supset [N, A, A, A] \supset \cdots \supset M,$$ where $[A, B, C] =[ [A, B], C]$ . Show that $A \lhd\lhd G$ iff $M \subseteq A$ . Note that $A \lhd\lhd G$ means $A$ is subnormal in $G.$ $\Rightarrow$ part: Suppose $A \lhd\lhd G$ , then there exists a chain of subgroup $A_1$ , $A_2$ $ \cdots$ such that $ A \lhd A_1 \lhd A_2 \lhd \cdots \lhd A_n \lhd G$ . Consider $ G \supset [G, A_n] \supset \cdots \supset [G, A_n, \cdots A_2] \supset [G, \cdots A_2, A_1] \supset [G, \cdots A_2, A_1, A]$ . Easy induction shows that $[G, A_n, \cdots A_i] \subseteq A_i$ and $[G, A_n, \cdots A_i] \supset [N, A, A, \cdots, A]$ there are $n-i+1$ A's in the second expression. Therefore $A \supset M$ . $\Leftarrow$ part: Suppose $M \subseteq A$ . I have a strong intuition that $A = AM \lhd \cdots \lhd A[N, A, A] \lhd A[N, A] \lhd AN = G$ . But I don't know how to show my conjecture formally. Please help.","['group-theory', 'abstract-algebra', 'finite-groups']"
4224024,Rigorous proof for a ray intersecting the boundary in a convex compact set in exactly one point.,"As above mentioned, I am searching for a rigourous proof of this statement:
Let $C\subseteq\mathbb{R}^2$ with $0\in \operatorname{int}(C)$ be a compact convex set, then for every $v\in\mathbb{R}^2$ there is a unique $\lambda_v>0$ with $\lambda_v v \in\partial C$ . Every proof, I have seen so far ignores something or draws only a picture. Intuitively for me there are $2$ cases, which must be contradicted. The first one is, that two isolated points on the ray must intersect $\partial C$ , the second case is, that the ray is laying on the boundary, cutting $\partial C$ uncountable many times. Perhaps Iam missing something, but all proofs make assumptions I don't understand or say, the proof is trivial.","['convex-hulls', 'topological-vector-spaces', 'geometry', 'geometric-topology', 'general-topology']"
4224061,"A challenging integral $ -\int_0^1 \frac{\ln(1-x)}{1+x} \operatorname{Li}_2(x) \, \mathrm{d}x $","I'm interested in evaluating the following integral $ \DeclareMathOperator{\Li}{Li}$ $$ \mathcal{A} = -\int_0^1 \frac{\ln(1-x)}{1+x} \Li_2(x) \, \mathrm{d}x $$ My most successful attempt thus far went like this: First, converting the dilogarithm to its integral form yields $$ \mathcal{A} = \int_0^1 \int_0^1 \frac{\ln(1-x) \ln(1-xt) }{t(1+x)} \, \mathrm{d}t \, \mathrm{d}x $$ Interchanging the bounds of integration yields $$ \mathcal{A} = \int_0^1 \int_0^1 \frac{\ln(1-x) \ln(1-xt) }{t(1+x)} \, \mathrm{d}x \,\mathrm{d}t $$ For the inner integral, we have $$ \mathfrak{J}(t) = \int_0^1 \frac{ \ln(1-x)\ln(1-xt) }{(1+x)} \, \mathrm{d}x $$ Differentiating under the integral with respect to $t$ and then applying partial fractions yields $$ \mathfrak{J}'(t) = \frac{1}{1+t} \int_{0}^{1} \frac{\ln(1-x) }{tx-1} \, \mathrm{d}x +\frac{1}{1+t} \int_0^1 \frac{\ln(1-x)}{1+x} \, \mathrm{d}x $$ This evaluates (not) very nicely to $$ \mathfrak{J}'(t) = \frac{1}{t(1+t) } \Li_2\left(\frac{t}{1-t} \right) +\frac{1}{1+t} \left( \frac{\ln^2(2)}{2} -\frac{\pi^2}{12} \right) $$ This means that our original integral is equivalent to solving $$ \mathcal{A} = \int_0^1 \int_0^t \frac{1}{at(1+a)} \Li_2 \left(\frac{a}{1-a} \right) \, \mathrm{d}a \, \mathrm{d}t + \left(\frac{\ln^2(2)}{2}-\frac{\pi^2}{12} \right) \int_0^1 \int_0^t \frac{1}{t(1+a)} \, \mathrm{d}a \, \mathrm{d}t $$ The second part of the integral above is trivial, what's giving me trouble is the first part. Any help whatsoever is much appreciated!","['integration', 'calculus', 'definite-integrals']"
4224149,Finding the correlation between the maximum and minimum of two uniform random variables,"Suppose $X_1, X_2 \stackrel{\mathrm{iid}}{\sim}$ Uniform $(-1, 2)$ . I am interested in finding Corr $(Y, Z)$ , where $Y = \min\{X_1, X_2\}$ and $Z = \max\{X_1, X_2\}$ . Now, I can solve the problem following the traditional methods i.e. by first finding the respective probability density functions and so on. However, this process is very long and tedious. After a bit of searching online, I came across this post , where the question is very similar to mine but I am more interested in the answer, which gives the following three ""short-cuts"" for $X_1, X_2 \stackrel{\mathrm{iid}}{\sim}$ Uniform $(0, 1)$ and $Y$ and $Z$ defined as above: $\mathbb{E}[Y] + \mathbb{E}[Z] = 1$ Var $(Y)$ = Var $(Z)$ $\mathbb{E}[YZ] = \frac 1 4$ I am unable to see how these relationships are true. Moreover, do such relationships hold in general (possibly just simply requiring to change the values on the RHS of 1 and 3 accordingly) or are they only true for standard iid uniform random variables? Any intuitive explanations will be greatly appreciated! :)","['correlation', 'probability-distributions', 'uniform-distribution', 'probability']"
4224152,"Suppose $A_1 \subseteq A_2 \subseteq A_3 \subseteq\cdots,\,\,$ and suppose $\bigcup \limits_{n\in \mathbb{Z}^+} A_n = \mathbb{Z}^+$.","Suppose $A_1 \subseteq A_2 \subseteq A_3 \subseteq\cdots,\,\,$ and suppose $\bigcup \limits_{n\in \mathbb{Z}^+} A_n = \mathbb{Z}^+$ . Suppose also that for every infinite set B $\subseteq \mathbb{Z}^+$ , there is some positive integer $n$ such that B $\cap A_n$ is infinite. Prove that for some $n$ , $A_n = \mathbb{Z}^+.$ I’m trying a contradiction argument.  So assume that for all n, $A_n \neq \mathbb{Z}^+$ . Then for every +ive integer i there is some $a_i \in \mathbb{Z}^+$ such that $a_i \notin A_i$ . So from the givens, for any infinite B we can find j such that $A_j \cap B$ Is infinite but does not contain some $a_j$ . I don’t know where to go from here.  Maybe I need to think of a specific set to use for B, or perhaps a different approach entirely is required.  Any help would be greatly appreciated.",['elementary-set-theory']
4224154,Checking answer here to confirm if it's question mistake or mine: $\lim_{x \rightarrow 0} \frac{\tan (x - x)}{\sin (x-x)}$ = indetermined? why wrong?,"I encountered a questions with asking to evaluate: $\lim_{x \rightarrow 0} \frac{\tan (x - x)}{\sin (x-x)}$ , and gives multiple choice options $-2, 0, 1, 2$ but doesn't have indetermined... If I used trig identities, I'd get $\frac{1}{\cos (x-x)}$ by converting tan to $\frac {\sin}{\cos}$ so the best guess is 1, but that's still wrong. Please can someone tell me where my gap is? I'm learning l'Hopital rule if that helps, but even applying that gives $\frac{0}{0} = \text{indetermined}.$ Could the question be wrong..?","['integration', 'limits', 'calculus', 'derivatives']"
4224188,What does $\mathrm{Spec}(\mathbb{Z})\times_{\mathrm{Spec}(\mathbb{F}_{1})}\mathrm{Spec}(\mathbb{Z})$ look like?,"See also: What does $\mathrm{Spét}(H\mathbb{Z})\times_{\mathrm{Spét}(\mathbb{S})}\mathrm{Spét}(H\mathbb{Z})$ look like? . $\newcommand{\F}{\mathbb{F}}\newcommand{\N}{\mathbb{N}}\newcommand{\Z}{\mathbb{Z}}$ One of the most mysterious objects in mathematics is the elusive ""field with one element"", and coming with it is the arithmetic curve $\mathrm{Spec}(\mathbb{Z})\times_{\mathrm{Spec}(\mathbb{F}_{1})}\mathrm{Spec}(\mathbb{Z})\cong\mathrm{Spec}(\mathbb{Z}\otimes_{\mathbb{F}_{1}}\mathbb{Z})$ . I want to know what such a thing would look like, and hence am trying to work it out in one particular model for geometry over $\mathbb{F}_1$ , that of binoids . Here are some definitions (for the question, it suffices to know 1–3 only). A binoid is a commutative monoid $M$ together with an absorbing element $0$ . An ideal of $M$ is a subset $I$ such that $0\in I$ . If $a\in I$ and $r\in M$ , then $ra\in I$ . An ideal $I$ of $M$ is prime if it is proper and whenever $ab\in I$ then $a\in I$ or $b\in I$ . The spectrum $\mathrm{Spec}(M)$ of a binoid $M$ is the set of all prime ideals of $M$ . The Zariski topology on $\mathrm{Spec}(M)$ is the topology generated by the collection $\{D(I)\}$ with $D(I)=\mathrm{Spec}(M)\setminus V(I)$ , where $$V(I)=\{\mathfrak{p}\in\mathrm{Spec}(M):I\subset\mathfrak{p}\}.$$ A distinguished open of $\mathrm{Spec}(M)$ is a set of the form $D_f=D(\{f\})$ for some $f\in A$ . These form a basis for the Zariski topology on $\mathrm{Spec}(M)$ . A binoidal space is a pair $(X,\mathcal{O}_X)$ with $X$ a topological space and $\mathcal{O}_X$ a sheaf of binoids on $X$ . An affine binoid scheme is a binoidal space of the form $(\mathrm{Spec}(M),\mathcal{O}_{M})$ , where $\mathcal{O}_{M}$ is defined on the distinguished opens by $$\mathcal{O}_{M}(D_f)=M_f.$$ For example, every ring $R$ has an associated binoid, given by forgetting the addition of $R$ . We have also a tensor product of binoids , and the tensor product $\mathbb{N}\otimes_{\mathbb{F}_{1}}\mathbb{N}$ is isomorphic to a countable direct sum of the multiplicative monoid of positive natural numbers, $(\mathbb{N}\setminus\{0\},\cdot,1)$ , adjoined with an absorbing element $\{0\}$ . It looks like this: The binoid $\Z\otimes_{\F_{1}}\Z\cong(\Z\setminus\{0\},\cdot)^{\oplus{\N}}\sqcup\{0\}$ is pictured in the same way, we just add negative numbers. What I'd like to ask is: What are the $\mathrm{Spec}$ 's of the main objects involved here, including $\mathrm{Spec}(\mathbb{N})$ and $\mathrm{Spec}(\mathbb{Z})$ (where $\mathbb{N}=(\mathbb{N},\cdot,1)$ and similarly for $\mathbb{Z}$ ), and, above all, \begin{align*}
\mathrm{Spec}(\mathbb{N})\times_{\mathrm{Spec}(\mathbb{F}_{1})}\mathrm{Spec}(\mathbb{N}) &\cong \mathrm{Spec}(\mathbb{N}\otimes_{\mathbb{F}_{1}}\mathbb{N}),\\
\mathrm{Spec}(\mathbb{Z})\times_{\mathrm{Spec}(\mathbb{F}_{1})}\mathrm{Spec}(\mathbb{Z}) &\cong \mathrm{Spec}(\mathbb{Z}\otimes_{\mathbb{F}_{1}}\mathbb{Z}),
\end{align*} the sets of prime ideals of the binoids $\N\otimes_{\F_{1}}\N\cong(\N\setminus\{0\},\cdot)^{\oplus{\N}}\sqcup\{0\}$ and $\Z\otimes_{\F_{1}}\Z\cong(\Z\setminus\{0\},\cdot)^{\oplus{\N}}\sqcup\{0\}$ ?","['monoid', 'algebraic-geometry', 'abstract-algebra', 'semigroups']"
4224190,Are affine semiring schemes equivalent to semirings?,"One of the generalizations of algebraic geometry is provided by the theory of semiring schemes, cf. Lorscheid 2012 . The theory follows the same set up of scheme theory, but we use semirings instead of rings. Given a semiring $R$ , we have a semiringed space $\mathrm{Spec}(R)$ , defined by mimicking the usual definition for rings. This gives a functor $\mathrm{Spec}$ from the opposite of the category semirings to that of affine semiring schemes. Conversely, there's also a global sections functor $\Gamma:\mathrm{AffSemiSch}^\circ\to\mathrm{Semiring}$ sending a semiringed space $(X,\mathcal{O}_X)$ to $\Gamma(X,\mathcal{O}_X)$ . Does the pair $(\mathrm{Spec},\Gamma)$ give as in ordinary algebraic geometry a contravariant equivalence of categories $\mathrm{Semiring}\cong\mathrm{AffSemiSch}^\circ$ ?","['semiring', 'algebraic-geometry', 'abstract-algebra']"
4224191,The spectrum of a semiring,"One of the generalizations of algebraic geometry is provided by the theory of semiring schemes, viz. Lorscheid 2012 . The theory follows the same set up of scheme theory, but we use semirings instead of rings, also known as rings without additive inverses; examples of which are the natural numbers $\mathbb{N}$ or the tropical semiring $\mathbb{T}$ . An ideal of a semiring $R$ is a set $I\subset R$ which 1) is closed under addition 2) contains $0$ , and 3) is such that $IA=I$ . Moreover, $I$ is prime if whenever $ab\in I$ , then $a\in I$ or $b\in I$ , and we write $\mathrm{Spec}(R)$ for the set of prime ideals of $R$ . What are $\mathrm{Spec}(\mathbb{N})$ and $\mathrm{Spec}(\mathbb{T})$ ? Do we have other nice examples of prime spectra of semirings?","['semiring', 'algebraic-geometry', 'abstract-algebra']"
4224234,definite integral $\int_0^1 \frac {1-x}{(1+x^3)\ln x}dx=\frac{-1}{2}\ln 3$,"Problem: Prove that: $$\int_0^1 \frac {1-x}{(1+x^3)\ln x}dx=\frac{-1}{2}\ln 3.$$ My attempt: I am able to prove: $$\int_0^1 \frac {1-x}{(1+x^3)\ln x}dx=\int_1^\infty \frac {1-x}{(1+x^3)\ln x}dx.$$ I don't know if this relation is useful or not. By the way, it seems it's impossible to integrate the function directly. So, I am looking for an equation derived from integration by parts or other similar tricks but I can't go further. Any help would be highly appreciated. P.S: This problem was proposed by ""Jalil Ghaderi"" from Iran.","['integration', 'indefinite-integrals', 'definite-integrals']"
4224241,Finding all $a$ such that $f(x)=\sin2x-8(a+1)\sin x+(4a^2+8a-14)x$ is increasing and has no critical points,"Find the set of all values of the parameter $a$ for which the function, $$f(x)=\sin\left(2x\right)-8\left(a+1\right)\sin\left(x\right)+\left(4a^2+8a-14\right)x$$ increases for all $x\in\Bbb{R}$ and has no critical points for all $x\in\Bbb{R}$ . Obviously, the first thing I did was to find the derivative of this function and simplify it a bit and I got: $$f'(x)=4\left(\;\cos^2x-2\left(a+1\right)\cos x+\left(a^2+2a-4\right)\;\right)$$ But now how do I proceed further, had it been a simple quadratic in $x$ . I would've calculated $D<0$ but this is a quadratic in $\cos x$ . Can I do the same here? Why or why not? How should I go ahead? Not just this, there are many instances where the quadratic is not in x, but in expressions like $e^{x}$ . Is there any general approach to solving these quadratics for things like no solutions etc-","['contest-math', 'inequality', 'derivatives', 'trigonometry', 'quadratics']"
4224332,Conditions for Ramanujan's Master Theorem,"I would like to apply Ramanujan's Master Theorem (RMT) to formally justify some integrals that I have been using. The source for the proof of the RMT that I have is Hardy's book on Ramanujan's work. The formal statement of the RMT can be found in https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.704.4327&rep=rep1&type=pdf as Theorem 3.2. In Hardy's book, he says that the growth condition on $\varphi$ (and in particular the requirement $A < \pi$ ) is 'natural', but insufficient in many practical applications, where apparently $A=\pi$ is the best bound available. In almost all practical applications I have seen, the formal statement of the RMT is more or less ignored and it is applied 'blindly' to derive a bunch of interesting integrals. How can one generically check that the growth condition on $\varphi$ is satisfied? Is there a simpler condition which implies this kind of growth? Specifically, I am interested in proving entry 3.252-10 in Gradsteyn & Rhyzik: http://fisica.ciens.ucv.ve/~svincenz/TISPISGIMR.pdf If I expand the function $$f(x) = \frac{1}{(1+2x\cos t +x^2)^{\alpha_2}}; \quad (\alpha_2 >0)  $$ in terms of Gegenbauer polynomials and 'blindly' apply the RMT, I get the correct answer (after some trivial manipulations and using the generalized definition of Gegenbauer polynomials in terms of ${}_2F_1$ , which can also be found in the above link). To meet the conditions of the RMT, I would need to prove that the function $$ \phi(s) = C^{\alpha_2}_{s}(\cos t) $$ satisfies said growth condition as a function of $s$ , where $0 < t < \pi$ . I don't know how to approach this. Edit: for completeness' sake, the growth condition reads: for some $0<\delta<1$ and $s=v+iw$ in the half-plane $v \geq -\delta$ we have $$|\phi(v+iw)| \leq C \exp(Pv + A|w|)$$ for some $P$ and $A<\pi$ . Any help is appreciated!","['complex-analysis', 'mellin-transform', 'definite-integrals', 'asymptotics']"
4224351,How to use inequalities to solve for multivariable limits?,"I am searching for a  methodological description on how to select the correct functions over several inequalities to find and prove that a function has a limit. I quote an example Find the limit of the given function: \begin{equation}
\lim_{(x,y)\longrightarrow(0,0)}\frac{x^2y}{x^2+y^2}
\end{equation} The solution, in terms of inequalities , is: \begin{equation}
\bigg|\frac{x^2y}{x^2+y^2}\bigg|\leqslant|y|\leqslant\sqrt{x^2+y^2}
\end{equation} where $\sqrt{x^2+y^2}$ approaches $0$ as $(x,y)\longrightarrow(0,0)$ . First of all, where does the author of this solution get those functions between the intervals, in the solution? What rationale does he use, when he constructs these functions? Apparently , there are many different functions that have limits that reach zero, so is this selection purely intuitive, and a subjective choice? If so, what is the objective method behind this? Thanks","['limits', 'multivariable-calculus']"
4224367,Graph of negative exponential function,"Is it possible to graph a function $Y = (-2)^x$ where $x \geq 1$ It is written in my text that exponential functions are only defined for positive bases, but why not negative bases having restriction on domain ( $x$ ) of function  which would not give minus sign under square root. I am new to this stuff so please help me even if it looks silly.","['functions', 'exponential-function']"
4224382,Hartshorne Exercise I.5.13: subset of nonnormal points is proper and closed,"I'm trying to solve the following exercise, Exercise I.5.13 from Hartshorne's Algebraic Geometry: Here's my attempt: I've been able to show that the set of nonnormal points is a subset of a proper closed subset as follows. By intersecting with an affine open, we may assume that the variety in consideration, say $Y$ , is an affine variety. Let $A(Y)$ coordinate ring of $Y$ , $\overline{A(Y)}$ its closure in $K(Y)$ , the field of fractions of $A(Y)$ . By Finiteness of Integral Closure, we obtain that $\overline{A(Y)}$ is generated by some finite number of $f_i/g_i\in K(Y)$ (for $i\in \{1,\ldots, n\}$ ), over $A(Y)$ as an $A(Y)$ -module. Since localization preserves integral closure, $\overline{A(Y)}_{g_1\ldots g_n}$ is integrally closed. But it's easy to see that $\overline{A(Y)}_{g_1\ldots g_n}\cong A(Y)_{g_1\ldots g_n}$ , as subrings of $K(Y)$ . Thus, the distinguished open set $D(g_1\ldots g_n)\cap Y$ with coordinate ring isomorphic to $A(Y)_{g_1\ldots g_n}$ is normal, by Exercise I.3.17 (d), which states that an affine variety is normal if and only if its coordinate ring is integrally closed. However, I seem to be unable to prove that the set of nonnormal points is closed too. I would be really grateful if someone could provide a hint on how to finish the proof. Thank you.","['algebraic-geometry', 'commutative-algebra']"
4224397,Inequality regarding simple graphs with no $4$-cycles,"I've been recently reading on Graph Theory , which is one of those areas I always felt lazy to approach when I trained for mathematical Olympiads. As it turns out, this is one of the fields that do show up later on really frecuently :( Anyhow, I was reading the article Firke, F. A., Kosek, P. M., Nash, E. D., & Williford, J. (2013). Extremal graphs without 4-cycles. Journal of Combinatorial Theory, Series B, 103(3), 327-336. on bounds regarding graphs without $4$ -cycles — as the title suggests — and had some questions on one of its earlier statements. Lemma 1. Let $q$ be a natural number greater than $2$ and let $G$ be a $C_4$ -free graph on $q^2 + q$ vertices with at least $E_0$ edges. Then the maximum degree of a vertex in $G$ is at most $q + 2$ . Proof . Let $v$ be a vertex of $G$ of maximum degree $d$ , and suppose that $d \geqslant q + 3$ . Let $e$ be the number of edges of $G , e \geqslant \frac12 q(q + 1)^2 − q$ . We proceed by bounding the number of $2$ -paths in $G$ which have no endpoints in $\Gamma (v)$ [where $\Gamma(v)$ represents the set of vertices in the neighborhood of $v$ ]. This gives us: $$\binom{n-d}{2}\geqslant \sum _{v\neq u}\binom{d(v)-1}{2}$$ [where, I believe, $n$ represents the number of vertices in $G$ .] Question 1. What's the meaning of » $2$ -paths«? And, what are the authors counting in the inequality? $\binom{n-d}{2}$ stands for the number of possible connections between two vertices of the set $G\setminus \Gamma (v) $ , right? But, what does $\sum _{v\neq u}\binom{d(v)-1}{2}$ represent? Shouldn't it be $\sum _{u\neq v}\binom{d(u)-1}{2}$ ? From what they derive through Jensen, I would say that they are considering the degrees of elements in $G\setminus \{v\}$ , but still don't understand what they are counting... Later on, in the proof of the Lemma 1, the authors introduce some inequalities which I am struggling to follow, since they are stated without proof: However, we also have: $$\begin{align*}(q + &1)(2e − 2n − d + 2) − (n − 1)(n − d − 1)\\ &\geqslant (q^2 −2)d−q^3 −2q^2 +q+1\\
&\geqslant (q^2 −2)(q+3)−q^3 −3q^2 +1\geqslant q^2 −q−5\end{align*}$$ (...)
We also have the inequality: $$\begin{align*}(2e−n−d+1)−(q+1)(n−d)&\geqslant −q^2 −3q+1+qd\\& \geqslant −q^2 −3q+1+q(q+3)=1>0\end{align*}$$ Could you please give a hint regarding the proof of these inequalities? Thanks in advance!","['graph-theory', 'inequality', 'combinatorics']"
4224450,Evaluating $\lim_{x\to 0}\frac{1-\cos(x^2)}{x^3(4^x-1)}$,"I need to calculate $$\lim_{x\rightarrow 0}\frac{1-\cos(x^2)}{x^3(4^x-1)}$$ and the options are:
(a) $\frac 12 \ln 2\quad$ (b) $\ln 2\quad$ (c) $\ln 4\quad$ (d) $1 - \frac 12 \ln \left( \frac{e^2}{4}\right)$ . The answers would are given to be $b$ and $d$ I tried to solve it in the following manner: \begin{align}\lim_{x\rightarrow 0}\frac{1-\cos(x^2)}{x^3(4^x-1)} &=\lim_{x\rightarrow 0}(\frac{2\sin^2(\frac{x^2}{2})}{x^4}\cdot\frac{x}{4^x-1})\\
&=\lim_{x\rightarrow 0}(\frac{2\sin^2(\frac{x^2}{2})}{(\frac{x^2}{2})^2\cdot 4}\cdot\frac{x}{4^x-1})\\
&=\lim_{x\rightarrow 0}(\frac{1}{2}\frac{\sin^2(\frac{x^2}{2})}{(\frac{x^2}{2})^2})\lim_{x\rightarrow 0}(\frac{x}{4^x-1})\\
&=\frac{1}{2}\frac{1}{\ln(4)}\\
&=\frac{1}{4}\log_2(e).
\end{align} Is my solution correct? Or am I missing something?","['limits', 'calculus', 'limits-without-lhopital', 'trigonometry']"
4224457,Lambda calculus - church encoding and lists,"I'm reading a book on the $\lambda$ -calculus and I'm stuck on a list of representations. While practising different lambda calculus tasks I've stumbled upon an interesting issue. Given two terms I would like to understand what list is represented by those - or what is the actual process of transforming those. I have two terms defined: $F_n$ and $F'_n$ for each natural number $n \in \mathbb{N} $ is defined as following: $n$ is either a number or a Church encoding, $m$ and $c$ are variables. $F'_0 = m$ $F'_n = c n F'_{n-1}$ for $n > 0$ $F_n =\lambda c. \lambda m.F'_n $ The question is what kind of list does the term $F_n$ represent? Expanding a bit on the question as the context was marked as insufficient. Understanding how different lists are represented in lambda calculus is an important part of a learning process, moreover, I haven't found any great sources on how in the general process given terms into a specific list type. The provided answer nicely highlights the process of transitioning a term into an actual list representation.","['definition', 'discrete-mathematics', 'lambda-calculus', 'induction', 'computer-science']"
4224464,Minimize the variance of distances between 2 points for planar region of given area,"Given a region $S$ in the Euclidean plane, let $X$ and $Y$ be random points in $S$ , independent and uniformly distributed. If the area of $S$ is given (let's say it is 1), what is the shape of $S$ that minimizes the variance of distances, $$
\operatorname{Var}(d(X,Y)),
$$ where $d$ is the Euclidean distance? My guts says is a ball (in 2D). But I don't know how to prove it. A more simple question is what shape will minimize the expectation of $d(X,Y)$ . This time again I think its a ball, but I have some more sense. Not a proof, but a direction, is that in any shape that is not a ball, there is a point that we can get closer to the center of mass of the group - hence decreasing the average distance from the rest of the points.","['general-topology', 'probability-distributions', 'geometric-probability', 'topological-groups']"
4224499,What about the rank of this matrix?,Problem: Suppose $0<r<n$ . Suppose $A:\mathbb{R} \to \mathcal{M}_2(\mathbb{R})$ is $\mathcal{C}^1$ . Suppose that he rank of $A(t)$ il less or equal $r$ for all $t \in \mathbb{R}$ . What be said about the rank of $A'(0)$ ? Attempt: I tried using the fact that $rank(A)=k$ if and only $k$ is the maximum size of an invertible minor $B$ . I would like to say that $rank(A'(0)) \leq r$ but I am not sure if it is true. Of course $rank(A'(0))$ could be $r$ because we can define $A(t)$ as the diagonal matrix with the first $r$ elements equal to $t$ and anywhere else equal to $0$ .,"['matrices', 'matrix-rank', 'linear-algebra']"
4224547,Probability of Rain Question,"This is the question: Most mornings, Victor checks the weather report before deciding whether to carry an umbrella.
If the forecast is “rain,” the probability of actually having rain that day is 80%. On the other
hand, if the forecast is “no rain,” the probability of it actually raining is equal to 10%. During
fall and winter the forecast is “rain” 70% of the time and during summer and spring it is 20%. (a) One day, Victor missed the forecast and it rained. What is the probability that the forecast
was “rain” if it was during the winter? What is the probability that the forecast was “rain”
if it was during the summer? ==================================================================================== I've figured out the numerator for both winter and summer but I'm having issues coming up with the denominator. Any help is appreciated. So far I have:
Let A be the event that the forecast was rain.
Let B be the event that it rained.
Let p be the probability that the forecast says rain.
So, P(A|B) = P(B|A)P(A)","['statistics', 'conditional-probability', 'conditional-expectation', 'problem-solving', 'probability']"
4224570,Algebra in Geometric Proof of Quadratic Reciprocity,"I am trying to understand the proof of quadratic reciprocity form the George Andrews textbook on number theory (this proof follows geometry and Eisenstein's thinking). I understand what is happening conceptually, but the finer points of inequality algebra are not obvious to me. We are given sets $\mu_1=\{q,2q,\cdots,\frac{1}{2}(p-1)q\}$ and $\mu_2=\{p,2p,\cdots,\frac{1}{2}(q-1)p\}$ , with $\mu_1$ representing the negative least residues mod $p$ and $\mu_2$ representing the negative least residues mod $q$ . Ultimately the proof shows $\mu_1+\mu_2$ is odd if and only if $p\equiv q\equiv3\pmod{4}$ . The author illustrates this by considering a hexagon $H$ with vertices $ABCDEF$ that lies within a rectangle $AGDJ$ (drawn in Quadrant $I$ ) that is bounded by $x=p/2$ and $y=q/2$ . The attached picture provides additional information about the components of the rectangle. For a point $(x,y)$ to lie in $H$ , it must satisfy, $0<x<p/2$ , $0<y<q/2$ , $y<\frac{q}{p}x+\frac{1}{2}$ , and $y>\frac{q}{p}x-\frac{q}{2p}$ . The next step remarks that if $(m,n)$ is some lattice point in $H$ , then so is $(\frac{p+1}{2}-m,\frac{q+1}{2}-n)$ , where these two points are $equal$ . This is verified by substituting ""these coordinates"" into the four inequalities above. I'm not sure what is meant by ""these coordinates."" I assumed it meant $(m,n)$ , so this is what I tried. $\frac{q}{p}x-\frac{q}{2p}<y<\frac{q}{p}x+\frac{1}{2}\Rightarrow \frac{q}{p}m-\frac{q}{2p}<n<\frac{q}{p}m+\frac{1}{2} \Rightarrow qm-\frac{q}{2}<py<qm+\frac{p}{2}$ $\Rightarrow 2qm-q<2py<2qx+p$ . Any assistance would be appreciated.","['elementary-number-theory', 'algebra-precalculus', 'geometry']"
4224576,Hatcher 3.3.21: What is a cone?,"I'm trying to solve exercise 3.3.21 from Hatcher's Algebraic Topology , and I'm a bit stuck on not quite understanding what he means by cone and cone point : For a space $X$ , let $X^{+}$ be the one-point compactification. If the added point, denoted $\infty$ , has a neighbourhood in $X^{+}$ that is a cone with $\infty$ the cone point, show that the evident map $H^{n}_c (X;G) \rightarrow H^n (X^{+}, \infty; G)$ is an isomorphism for all $n$ . [Question: Does this result hold when $X=\mathbb{Z} \times \mathbb{R}$ ?] Okay, so, I would infer from the question that in the one-point compactification of $\mathbb{Z} \times \mathbb{R}$ , $\infty$ has no such neighbourhood that is a cone. Thing is though, why not? My naive assumption was that by a cone shaped neighbourhood, Hatcher was simply meaning that there existed some space $Y$ such that if the neighbourhood in question was $N_{\infty}$ , then $CY$ is homeomorphic to $N_{\infty}$ and if the homeomorphism is denoted $\phi$ and $p$ is the ""tip of the cone"", then $\phi(p) = \infty$ . But then it would appear to me that in the one-point compactification of $\mathbb{Z} \times \mathbb{R}$ there definitely exists a cone-shaped neighbourhood of $\infty$ , specifically, one that is homeomorphic to the cone of $\mathbb{Z}$ . Am I doing something seriously wrong here? If so where? How am I to interpret what Hatcher has written?","['general-topology', 'homology-cohomology', 'algebraic-topology']"
4224588,Minimum EigenValue,"From Rayleigh Equation, we know for symmetric $n\times n$ matrix $A$ $$\min_{x\in \mathbb{R}^n\setminus \{0\}}\frac{x^TAx}{x^Tx} = \lambda_{\min}(A)$$ My question is does the same equation hold for the following scenario $$\inf_{x\in \mathbb{S}^{n-1}\setminus\{x^*\}}\frac{(x-x^*)^TA(x-x^*)}{(x-x^*)^T(x-x^*)} = \lambda_{\min}(A)$$ where $\mathbb{S}^{n-1}$ is the unit sphere in $n$ dimensions and $x^*$ is a fixed element in $\mathbb{S}^{n-1}$ . Further, it seems that the minimum can be achieved if $x^*$ is orthogonal to the eigenvector corresponding to the minimum eigen value. Can this also be proved formally/","['matrices', 'convex-optimization', 'linear-algebra', 'real-analysis']"
4224600,Prove the random variable is bounded,Let $g_n$ be given by $$g_n=\prod_{i=1}^n \left(1+\frac{X_i}{\sqrt{i}}\right)$$ where $X_i$ 's are independent random variables with $P(X_i=1)=P(X_i=-1)=0.5$ .Then is it true that $P(g_n \rightarrow \infty)=0$ .If yes how can I show it? My attempt:I think I have to use Borel Cantelli lemma but I am not sure how.,"['probability-theory', 'probability']"
4224602,Graph problem on cycles,"Given a simple graph $G(V,E)$ with 2020 vertices such that $\deg(v)\geqslant 45$ for every vertex $v\in V(G)$ . Show that one can find a $4$ -cycle in $G$ . I've managed to prove the statement for $n^2$ vertices, all of them with degree $\geqslant n+1$ with a simple Pigeonhole argument counting the number nice edge-pairs (i.e. pairs of edges that share a vertex). One should arrive at $$\binom{n^2}{2}<n^2\cdot \binom{n+1}{2}$$ which is the desired contradiction. However, the argument fails for $2020$ and $\deg\geqslant 45$ . I also tried to apply the idea displayed here (first page) which leads to the inequality $$n(n-1)\geqslant \sum_{u\in V}\deg(u)\cdot (\deg(u)-1)\implies 2020\cdot 2019\geqslant 2020\cdot 45\cdot 44 $$ But this is true and leads, therefore, to no contradiction. Any ideas/hints?","['graph-theory', 'combinatorics']"
4224703,Chance letter a next to b in circle with whole alphabet such that no vowels next to each other,"Here's a question from a book on probability I'm working through: If the $26$ letters of the alphabet are written down in a ring so that no two vowels come together, what is the chance that a is next to b ? Here's what I did. Let's fix a . Since b can be immediately to the left or right of a , there's $2$ choices for b . Without loss of generality let's say we have ab , and so we have $4$ vowels remaining and $20$ consonants remaining. With the condition that no $2$ vowels come together: We want to find the number of possible places where we can place a vowel, which is in between consonants. With the $20$ consonants, there's $19$ possible ""gaps"" between, plus the $2$ on the end, for a total of $21$ . However, because our b already occupies one of them, we have to subtract $1$ , getting us $20$ . So out of these $20$ places we're choosing $4$ , so there's $\binom{20}{4}$ ways to place our $4$ vowels among the $20$ consonants subject to the condition no $2$ vowels come together. There's $4!$ ways to order the remaining vowels and $20!$ ways to order the remaining consonants. So our numerator is $${{2 \binom{20}{4} 20!4!}}$$ Now let's calculate the denominator. Fix a again. This time we have $21$ consonants and $4$ vowels remaining, but only the $20$ possible ""gaps"" between the consonants to places our $4$ vowels (there's no $2$ at the end this time around), so our numerator is $$\binom{20}{4}21!4!$$ Therefore the chance that a is next to b is $${2\over{21}}$$ However, the answer in the back of my book (which is known to be wrong in many places in the answers in the back section) is ${1\over{10}}$ . So who's correct? And if I'm wrong, where did I specifically go wrong?","['combinatorics-on-words', 'combinatorics', 'probability']"
4224720,Prove function $g$ has a continuous expansion $f$ on $\mathbb{R}^2 \rightarrow \mathbb{R}$,"I'm trying to expand the function $$g(x,y) = \arctan \left(\frac{1-xy}{x^2+y^2}\right)$$ to some function $f \colon \mathbb R^2 \rightarrow \mathbb R$ . We know already it's continuous on $\mathbb R^2 \backslash \{(0,0)\}$ , so to find a proper candidate for the value $f(0,0)$ , we can check any approaching limit. For example $$\lim_{x\to 0} f(x, 0)= \lim_{x\to 0} \arctan \frac{1}{x^2} = \frac{\pi}{2}$$ So if $f$ is continuous in $(0,0)$ , the value has to be equal to $\frac{\pi}{2}$ . The problem I'm having is how to now prove if $f$ actually is continuous. So for $\forall \epsilon > 0$ , there has to $\exists \delta > 0$ , so that $|(x,y) - (0,0)| < \delta \implies |f(x,y) - f(0,0)| < \epsilon$ .
When I try to look at $$\left| \arctan \frac{1-xy}{x^2+y^2} - \frac{\pi}{2}\right|$$ I then kind of become stuck, trying to see what the value is less as. I hope my question is somewhat clear. I'm just searching for the next step in proving continuity if anybody can offer some help. Thank you all in advance. :)","['continuity', 'trigonometry', 'analysis', 'real-analysis']"
