question_id,title,body,tags
172766,Calculating equidistant points around an ellipse arc,"As an extension to this question on equiangular fisheye distortion, how can I calculate equidistant points around an ellipse (or 1/4 segment of) given it's aspect ratio? When it's circular, I can use a simple angle increment around the central point, but as the aspect ratio gets smaller, the length of the arc gets shorter and the angles are no longer equidistant.","['trigonometry', 'plane-curves', 'conic-sections']"
172771,Are there an infinite set of sets that only have one element in common with each other?,"In a card game called Dobble , there are 55 cards, each containing 8 symbols. For each group of two cards, there is only one symbol in common. (The goal of the game being to spot it faster than the other players, which is not the point of my question). If I translate that to  mathematical language, I would say that: $S = [S_1, S_2, ..., S_{55}]$. $S_n = [n_1, n_2, ..., n_8]$. For $S_n, S_m \in S$ there is one and only one $n_a = m_b$ My double (dobble) question is: Are there a finite or infinite number of sets and elements that allows such a property? I know there is one more with 30 sets containing 6 elements each (because of Dobble Kids, a lighter version of the game). How can I calculate the number of sets, the number of elements in the sets, how many different elements there are in all the sets and which elements go in which sets? Is there a formula or is it simply a step-by-step try and fail method? EDIT I realise that having sets like {1, 2, 3, 4}, {1, 5, 6, 7}, {1, 8, 9, 10}, ... answers the question (with 1 being the only element in common in each set). There is one more restriction: Each element used in the sets must appear the same number of times (for example, in 7 given sets). In the game, there are 50 symbols altogether. (55 cards, 8 symbols per card, 50 symbols altogether). I have figured out a simple example with 4 sets of 3 elements (6 elements overall):
$$S_1 = [1, 2, 3], S_2 = [1, 4, 5], S_3 = [2, 5, 6], S_4 = [3, 4, 6]$$ Each element is present twice.","['recreational-mathematics', 'elementary-set-theory']"
172797,"Using the substitution $p=x+y$, find the general solution of $dy/dx=(3x+3y+4)/(x+y+1)$.","Using the substitution $p=x+y$, find the general solution of $$\frac{dy}{dx}=(3x+3y+4)/(x+y+1)$$
Here are my steps: Since $p=x+y$, $$\frac{3x+3y+4}{x+y+1}=\frac{3p+4}{p+1}=\frac{1}{p+1}+3$$ Therefore, integrate both sides 
$$y=\ln(p+1)+3p+c$$ $$y=\ln(x+y+1)+3(x+y)+c$$ But the answer in my book is $$x+y-\frac{1}{4}\ln(4x+4y+5)=4x+c$$
Is that correct?","['ordinary-differential-equations', 'calculus']"
172804,Transition Kernel of a Markov Chain,"Supposing $X_t$ is a Markov Process, can the transition kernel be defined by
$$K_t(x,A):= P(X_{t+1} \in A | X_t = x)?$$ Assume that $X_t : \Omega \to \mathbb{R}^n$. The issue is that under the normal definition of conditional probability, r.h.s is defined as $$P(X_{t+1} \in A | X_t = x) =\frac{P( (X_{t+1} \in A) \cap (X_t = x))}{P(X_t = x)}$$ and the denominator is zero for most random variables. Even 
if this is assumed to be $E[I_A(X_{t+1}) | \sigma(X_t = x)]$, the conditional
expectation can take arbitrary values on the set $\{X_t =x\}$ if $P(X_t = x) =0$. Another definition I could gather from the web is that $K_t(x,A)$ is called a 
transition kernel if $$K_t(X_t(\omega),A) := E[I_A(X_{t+1})|X_t](\omega)~\forall
\omega \in \Omega.$$ 
Also, $K_t(x,\cdot)$ should be a probability measure so that the conditional 
expectations should be regular (if I am not wrong). The book (page 18) I am reading uses the first definition given above. Thanks for the help.","['probability-theory', 'stochastic-processes', 'markov-process']"
172806,Moving to a conformal metric,"Given a generic 2-dimensional metric
$$
   ds^2=E(x,y)dx^2+2F(x,y)dxdy+G(x,y)dy^2
$$
what is the change of coordinates that move it into the conformal form
$$
   ds^2=e^{\phi(\xi,\zeta)}(d\xi^2+d\zeta^2)
$$
being $\xi=\xi(x,y)$ and $\zeta=\zeta(x,y)$? Is it generally known? Also a good reference will fit the bill. Thanks beforehand.","['riemannian-geometry', 'conformal-geometry', 'reference-request', 'differential-geometry']"
172808,Finding a bijective function from integer to words,"I need to find a function to enumerate the ordered list of sequential words based on a charset. Let me give you an example. If the charset is ""abc"", the function to be found ""f"" should compute the following: f(0) =    a
f(1) =    b
f(2) =    c
f(3) =   aa
f(4) =   ab
f(5) =   ac
f(6) =   ba
f(7) =   bb
f(8) =   bb
f(9) =   ca
f(10) =  cb
f(11) =  cc
f(12) = aaa
... It is important to note that ""aaa"" is different from ""aa"" or ""aaaa"". This is why I found it difficult to represent abc as a number system to the base 3. I am looking for an explicit definition of f(n) to compute f for an arbitrary n without enumerating recursively.","['number-systems', 'elementary-set-theory', 'functions', 'combinatorics']"
172810,"Convergence of sequence in $C^{k, \alpha}$ composed with $C^\infty$ function","Is it true that if a sequence $u_n \to u$ in $C^{k, \alpha}$ norm, and if you have a function $f \in C^\infty$, then $f(u_n) \to f(u)$ in $C^{k,  \alpha}$? I think so, since this is true for ordinary $C^k$ space so the ""norm part"" of the $C^{k, \alpha}$ norm converges, but I am not sure how to show that the seminorm part of the $C^{k, \alpha}$ norm converges. And I guess if this works for Hölder space, it'll work for parabolic Hölder space too.
Parabolic Hölder space is defined as follows.
The seminorm is defined
$$[u]_{\alpha} = \sup_{(x,t), (y,s) \in Q} \frac{|u(x,t) - u(y,s)|}{(|x-y|^2 + |t-s|)^{\frac{\alpha}{2}}},$$ and norm on the parabolic Hölder space $C^{k, \alpha}$ is defined
$$\lVert{u}\rVert_{\widetilde{C}^{k, \alpha}(\overline{Q})} = \sum_{i+2j \leq k} \lVert{\frac{\partial^{i+j}u}{\partial x^i \partial t^j}}\rVert_{C(\overline{Q})} + \sum_{i+2j = k} \bigg[\frac{\partial^{i+j}u}{\partial x^i \partial t^j}\bigg]_\alpha.$$","['holder-spaces', 'convergence-divergence', 'functional-analysis', 'analysis']"
172815,Continuous Random Variable with constant moments?,"I would like to know if there exists a measure $\rho$ on the positive real line such that its moments $\int_0^{\infty} x^j d\rho(x)$ are equal to a constant (for example equal to one) for all $j=0,\dots,n,\dots$ (or for $j\leq n$ for any $n$). 
In other words, if there exists a density function (equal to zero on the negative real part) such that its characteristic function is $e^{it}$.","['measure-theory', 'fourier-analysis', 'probability']"
172816,Integral-Summation inequality.,"The following question was in an entrance exam: Show that, if $n\gt0$ , then: $$\int_{{\rm e}^{1/n}}^{\infty}{\frac{\ln{x}}{x^{n+1}}\:dx}=\frac{2}{n^2{\rm e}}$$ You are allowed to assume $\lim_{x\to\infty}{\frac{\ln{x}}{x}}=0$ . Hence explain why, if $1\lt a\lt b$ , then: $$\int_{b}^{\infty}{\frac{\ln{x}}{x^{n+1}}\:dx}\lt\int_{a}^{\infty}{\frac{\ln{x}}{x^{n+1}}\:dx}$$ Deduce that: $$\sum_{n=1}^{N}{\frac{1}{n^{2}}}<\frac{\rm e}{2}\int_{{\rm e}^{1/N}}^{\infty}{\left(\frac{1-x^{-N}}{x^{2}-x}\right)\ln{x}\:dx},$$ Where $N\in\mathbb{N}:N\gt1$ . The first part I believe I integrate by parts, such that: $$\int{\frac{\ln{x}}{x^{n+1}}\:dx}=\frac{1}{n}\int{x^{-n-1}\:dx}-\frac{x^{-n}\ln{x}}{n}$$ Clearly $\int{x^{-n-1}\:dx}=-\frac{x^{-n}}{n}$ , so we have: $$\int_{{\rm e}^{1/n}}^{\infty}{\frac{\ln{x}}{x^{n+1}}\:dx}=\left.\frac{x^{-n}(n\ln{x}+1)}{n^{2}}\right|_{{\rm e}^{1/n}}^{\infty}=\frac{{\rm e}^{-\frac{n}{n}}(\frac{n}{n}+1)}{n^{2}}-0=\frac{2}{n^{2}{\rm e}}$$ As required. To prove the next inequality, all that is required is to demonstrate that $\left.\frac{\ln{x}}{x^{n+1}}\right|_{x=1}\geq0$ , $\lim_{x\to\infty}{\frac{\ln{x}}{x^{n+1}}}\geq0$ , and $\left(\frac{\ln{x}}{x^{n+1}}\right)'\neq0$ , $\forall x\in[1,\infty)$ and $\forall n\gt0$ . The first inequality is verified simply by observing that $\ln{1}=0$ , therefore $\frac{\ln{1}}{1^{n+1}}=0$ , $\forall n$ .The second inequality can be written as: $$\lim_{x\to\infty}{\left(\frac{1}{x^{n}}\frac{\ln{x}}{x}\right)},$$ And as we know $\lim_{x\to\infty}{\frac{\ln{x}}{x}}=0$ , and $\lim_{x\to\infty}{\frac{1}{x^{n}}}=0$ , the second inequality must also be true. To verify the second inequality we simply differentiate using the quotient rule and look for critical points: $$\frac{d}{dx}{\left(\frac{\ln{x}}{x^{n+1}}\right)}=\frac{x^{n}-(n+1)x^{n}\ln{x}}{x^{2n+2}}=\frac{1-(n+1)\ln{x}}{x^{n+2}}$$ As $\ln{x}$ is a monotonically increasing function, and at $x=1$ , $\ln{x}=0$ , we can show that $\forall n\gt 0$ , and $x\gt1$ , $\left(\frac{\ln{x}}{x^{n+1}}\right)\leq 0$ , therefore, the function is positive for all values of $x\gt 0$ , which means by the fundamental theorem of calculus that if $1\lt a\lt b$ , then $\forall n\gt0$ : $$\int_{b}^{\infty}{\frac{\ln{x}}{x^{n+1}}\:dx}<\int_{a}^{\infty}{\frac{\ln{x}}{x^{n+1}}\:dx}$$ As required. However, I am stuck for the final part of the question. My first thought was that as $\frac{1}{n^{2}}$ is monotonically decreasing, $\forall n\gt0$ ; any integral performed over the region $(0,\infty)$ will have a positive error term, therefore, we can replace the summation with $\int_{1}^{N}{\frac{1}{n^2}\:dn}=\left.-\frac{1}{n}\right|_{1}^{N}=-\frac{1}{N}+1$ . I am not sure how to perform the second integral, however. Thanks in advance!","['inequality', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
172823,"Proving $\left\lfloor \frac{x}{ab} \right\rfloor = \left\lfloor \frac{\left\lfloor \frac{x}{a} \right\rfloor}{b} \right\rfloor$ for $a,b>1$","I'm trying to prove rigorously the following: $$\left\lfloor \frac{x}{ab} \right\rfloor = \left\lfloor \frac{\left\lfloor \frac{x}{a} \right\rfloor}{b} \right\rfloor$$ for integers $a,b \geq 1$ and real $x$ . So far I haven't gotten far. It's enough to prove this instead: $$\left\lfloor \frac{z}{c} \right\rfloor = \left\lfloor \frac{\lfloor z \rfloor}{c} \right\rfloor$$ for integers $c \geq 1$ and real $z$ since we can just put $z=\lfloor x/a \rfloor$ and $c=b$ .","['ceiling-and-floor-functions', 'algebra-precalculus', 'number-theory']"
172837,A counterexample in topology,"Semi-local simple connectedness is a property that arises in Algebraic Topology in the study of covering spaces, namely, it is a necessary condition for the existence of the universal cover of a topological space X. It means that every point $x \in X$ has a neighborhood $N$ such that every loop in $N$ is nullhomotopic in $X$ (not necessarily through a homotopy of loops in $N$ ). The way I see it, the prefix ""semi-"" is refers more to ""simply connected"" than to ""locally"", since if such $N$ exists, all other neighborhoods of $x$ inside $N$ also have the property, so each point has a fundamental system of (open) neighborhoods for which the property holds ( EDIT see Qiaochu's comment). Instead it isn't true that a semi-local simply connected space is locally simply connected (i.e each point has a fundamental system of open, simply connected neighborhoods): take the space $$ X = \frac{H \times I}{ \sim } $$ where $H$ is the "" Hawaiian earring "", or infinite earring (which is an example of non semi-locally simply connected space) and $\sim$ is the equivalence that identifies $H \times \{0\}$ to one point. However I was interested in finding another type of counterexample. Consider the topological property (call it $*$ ) consisting in the existence, for all $x \in X$ , of a simply connected, not necessarily open, neighborhood of $x$ . We have $$ \text{semi-local simple connectedness} \Leftarrow * \Leftarrow \text{local simple connectedness} \wedge \text{simple connectedness} $$ I am wondering if $$ \text{semi-local simple connectedness} \Rightarrow * $$ holds. Intuitively it shouldn't, but I'm having trouble finding a counterexample. For example, the space $X$ described above won't work because it is simply connected (even contractible). It seems to me that, if a counterexample does exist, it must have local pathologies (to ensure that a certain point $x$ doesn't have a simply connected neighborhood), and globally the space should allow loops close to $x$ to be nullhomotopic, but in such a way that every neighborhood $N$ of $x$ contains a small enough loop that will not contract in $N$ . EDIT Also, I am looking for a counterexample which is a locally path connected space (a previous answer showed a counterexample without this property.. but @answerer it was interesting anyway, you shouldn't have deleted it!) But perhaps I'm wrong, and the two assertions are equivalent, or maybe I am missing something very simple. If anybody has any ideas please share, thank you!","['general-topology', 'examples-counterexamples', 'algebraic-topology']"
172839,pseudo numbers and surreal numbers,"A surreal number $\{x_L\|x_R\} \in No$ is a number when for all $\xi\in x_L$ and all $\eta \in x_R$ we have $\eta > \xi$. All the things $\{x_L\|x_R\}$ which are not of that form are called ""pseudo-numbers"" and usually ignored (except in certain game-theoretic applications). Questions: Is it possible (in an algebraic, analytic or topological sense) to make sense of these pseudo-numbers ? Can one obtain a ""filling of the gaps"" of $No$ by extending $No$ with pseudo-numbers ? Is there research in which the pseudo numbers are studied ? When you study $\mathbb{A}^{1,an}_{No}$ as the set of (bounded, non-archimedean) seminorms on $No[T]]$, is there a connection between pseudonumbers and the set $\mathbb{A}^{1,an}_{No} - No$, also known as the ""hyperbolic space"" $\mathbb{H}^{1,an}_{No}$ among those who a acquainted with the Berkovich terminology ?","['set-theory', 'general-topology', 'combinatorial-game-theory', 'abstract-algebra', 'number-systems']"
172841,"Explain why $E(X) = \int_0^\infty (1-F_X (t)) \, dt$ for every nonnegative random variable $X$","Let $X$ be a non-negative random variable and $F_{X}$ the corresponding CDF. Show,
  $$E(X) = \int_0^\infty (1-F_X (t)) \, dt$$
  when $X$ has : a) a discrete distribution, b) a continuous distribution. I assumed that for the case of a continuous distribution, since $F_X (t) = \mathbb{P}(X\leq t)$, then $1-F_X (t) = 1- \mathbb{P}(X\leq t) = \mathbb{P}(X>  t)$. Although how useful integrating that is, I really have no idea.","['probability-theory', 'expected-value', 'probability', 'faq']"
172848,Proving an elementary integral inequality (in early Dirichlet space material),"I'm reading up on Dirichlet spaces using this document here and, on page two, am stumped by a particular integral inequality. If this is trivial and/or I'm missing something blatant, I apologize. First we define, for any analytic function $f$ defined on the unit disk $\mathbb{D}$, the quantity
$$
D(f) = \frac{1}{\pi} \int_{\mathbb{D}} | f' |^2 dA =  \frac{1}{\pi} \int_{\mathbb{D}} | f' |^2 dxdy
$$
(The Dirichlet space is the set of all functions $f$ as before such that $D(f)<\infty$.
$D(f)$ is only a semi-norm, as $D(c)=0$ for any constant $c$.)
Next we define, for any $\zeta \in \partial \mathbb{D}$, the quantity
$$
L(f,\zeta) = \int_0^1 |f'(r \zeta)|dr
$$
The author now says If $D(f)<\infty$ we can apply the Cauchy-Schwarz inequality to show that
  $$
\int_0^{\pi} L(f,e^{i\theta} ) d\theta \leq c D(f) < \infty
$$
  and so $L(f,e^{i\theta})<\infty$ for almost all $\theta$. This is what I can not show. Attempt: The C-S inequality reads
$$
\left| \int h(x) \overline{g(x)} dx \right|^2 \leq \int |h(x)|^2dx \int |g(x)|^2dx 
$$
and applies because, by above, all functions in the Dirichlet space are square integrable. 
We are trying to show
$$
\int_0^{\pi} \int_0^1 |f'(r e^{i\theta})|dr d\theta \leq c \frac{1}{\pi} \int_{\mathbb{D}} | f' |^2 dxdy
$$
which, when we transfer to polars, gives
$$
\int_0^{2\pi} \int_0^1 |f'(r e^{i\theta})|dr d\theta \leq A 
\int_0^{2\pi} \int_0^1 |f'(re^{i\theta})|^2rdrd\theta
$$
So I defined $h(r) = |f'(r e^{i\theta})| \sqrt{r}$ to match C-S with what we have on the right, and then attempted so pick $g$ so that the left hand sides would match, too. This gives $g(r) = r^{-1/2}$. Subbing all this in we get
$$
\left| \int_0^1 |f'(r e^{i\theta})| \sqrt{r} \frac{1}{\sqrt{r}}  dx \right|^2 \leq
 \int_0^1 |f'(r e^{i\theta})|^2  rdr \int_0^1 |r^{-1/2}|^2dx 
$$
$$
\left| \int_0^1 |f'(r e^{i\theta})| dx \right|^2 \leq
 \int_0^1 |f'(r e^{i\theta})|^2  rdr \int_0^1 r^{-1}dr 
$$
When we integrate over $\theta$ we kind of get what we're looking for (the square shouldn't matter as everything on the right above is finite and all we're trying to show is that the left is finite). The problem is the term
$$
\int_0^1 r^{-1}dr = + \infty
$$
Any thoughts? Apologies again if this is silly.","['integration', 'complex-analysis']"
172852,Legendre Equation,"From Apostol's Calculus, Vol. II, Section 6.21 #3: The Legendre equation can be written in the form
  $$\left[(x^2 -1)y'\right]'-\alpha(\alpha+1)y=0\,,$$
  where $\alpha\in\mathbb R$. If $a, b, c$ are constants with $a>b$ and $4c+1>0$, show that a differential equation of the type
  $$\left[(x-a)(x-b)y'\right]'-cy=0$$
  can be transformed to a Legendre equation by a change of variable of the form $x=At+B$ where $A>0$. Determine $A$ and $B$ interms of $a$ and $b$. It is easy to determine $A=\frac {a-b} 2$, and $B=\frac {a+b} 2$ (which agrees with the answer provided by the book), and we can find that this yields the equation
$$\left[(A^2t^2-A^2)y'\right]'-cy=0\implies\left[(t^2-1)y'\right]'-\frac c {A^2} y =0$$
So to finish the proof that this can be considered as a Legendre equation, we must show that $\exists \alpha\in \mathbb R$ such that $\alpha(\alpha+1)=\frac c {A^2}$, however in solving this we find that $\alpha = \frac 1 2 \left(-1 \pm \sqrt{1+4\frac c {A^2}}\right)$. The condition $4c+1>0$ is not enough to guarantee that $\alpha\in\mathbb R$. For instance, we could take $a=\frac 1 4$, $b=0$, and $c=-\frac 1 8$. Did I make a mistake, or should the condition instead be $16c + (a-b)^2>0$?","['ordinary-differential-equations', 'calculus']"
172873,Subgroups between $S_n$ and $S_{n+1}$,"Lets look at $S_n$ as subgroup of $S_{n+1}$. 
How many subgroups $H$, $S_{n} \subseteq H \subseteq S_{n+1}$ there are ?","['permutations', 'group-theory']"
172877,Proof of Hilbert's Nullstellensatz,"I'm working through my notes and I'm stuck in the middle of the proof of Hilbert's Nullstellensatz. (Hilbert's Nullstellensatz) Let $k$ be an algebraically closed field. Let $J$ be an ideal in $k[x_1, \dots , x_n]$. Let $V(J)$ denote the set of $x$ in $k$ such that all $f$ in $J$ vanish on them. Let $U \subset k^n$ and let $I(U)$ denote the set of $f$ in $k[x_1, \dots , x_n]$ that vanish on $U$. Then 
$$ r(J) = I(V(J))$$
where $r$ denotes the radical of $J$. Let me go through the proof as far as I understand it: $\subset$: Easy. Let $p \in r(J)$. Then $p^k \in J$ which means $p(x)^k = 0$ for all $x$ in $V(J)$. Hence $p(x) = 0$  for $x$ in $V(J)$ hence $p \in I(V(J))$. $\supset$: Assume $f \notin r(J)$. Then for all $k>0$, $f^k \notin J$. We know that there exists a prime ideal $p$ such that $J \subset p$ and $f^k \notin p$ for all $k>0$. To see this we use the same argument used in the proof of proposition 1.8. on page 5 in Atiyah-MacDonald: Let $\Sigma$ be the set of all ideals that do not contain any power of $f$. We order $\Sigma$ by inclusion and use Zorn's lemma to get a maximal element $p$. We claim $p$ is prime. Assume neither $x \notin p$ nor $y \notin p$ (then we want to show $xy \notin p$). Then $p + (x), p + (y)$ are ideals properly containing $p$ hence neither of them is in $\Sigma$ hence $f^n \in p + (x)$ and $f^m \in p + (y)$. Now $f^{n+m} \in (p + (x)) (p + (y)) = p^2 + (x)\cdot p + (y)\cdot p + (xy) \subset p + (xy)$ so $p + (xy) \notin \Sigma$. Hence $p$ is properly contained in $p + (xy)$ hence $xy$ cannot lie in $p$. So we have $p$ is a prime ideal containing $J$. Now consider the map
$$ k[x_1, \dots, x_n] \xrightarrow{\pi_1} k[x_1, \dots, x_n]/p \xrightarrow{i} (k[x_1, \dots, x_n]/p) [\overline{f}^{-1}] =: B([\overline{f}^{-1}]) \xrightarrow{\pi_2}  B[\overline{f}^{-1}] /m$$ where $\overline{f}$ denotes $\pi_1 (f)$ and $m$ is some maximal ideal in $B[\overline{f}^{-1}]$. We may assume $f \neq 0$ so that $\overline{f} \neq \overline{0}$. $\overline{f}^{-1}$ is an element of the field of fractions of $B$ so we may adjoin it to $B$ to get a new ring. Since we only adjoined one element and otherwise only took quotients, the thing coming out on the RHS is a finitely generated $k$-algebra (because $ k[x_1, \dots, x_n]$ is). Now by theorem 5.24 in Atiyah-MacDonald we know that $k \cong B[\overline{f}^{-1}] /m$. The proof now finishes as follows:
""Let $t_1, \dots, t_n$ denote the images of $x_1 , \dots, x_n$ under this composite ring homomorphism. (*)By construction, $g \in J \implies g \in p \implies g(t_1, \dots, t_n) = 0 \implies (t_1 , \dots, t_n ) \in V(J)$. (**)On the other hand, $f(t_1 , \dots, t_n )$ is precisely the image of $f$ in $B[\overline{f}^{-1}] /m$, which is a unit. $\implies f(t_1 , \dots, t_n ) \neq 0 \implies f \notin I(V(J))$."" Question 1: What is the line (*) showing? I think we want to show $f \notin I(V(J))$, where does this come in here? Question 2: Why is $f(t_1 , \dots, t_n )$ a unit? Thank you for your help.","['commutative-algebra', 'abstract-algebra']"
172887,How to solve the $C^\alpha$ Poisson equation on closed Riemannian manifolds?,"To be specific, suppose $M$ is a closed oriented manifold, $g$ is a Riemannian metric of $M$. 
Let $\Delta_g$ be the Laplace-Beltrami operator w.r.t. $g$. Prove : Suppose $f\in C^\alpha(M)$ satisfies $\int_M f\, dVol_g=0$, then there exists a function $u\in C^{2,\alpha}(M)$ such that $\Delta_g u=f$ in $M$, and $u$ is unique up to plus a constant, here $0<\alpha<1$. My attempt is that, firstly use $D(u):=\int_M(\frac{1}{2} |\nabla u|^2+fu)dVol_g$ is a convex functional with a lower bound on $W_0^{1,2}(M)$ to show that there exists a weak solution $u\in W^{1,2}(M)$, next use the $L^2$-regularity theory to show that $u\in W^{2,2}(M)$, but I don't know how to improve the regularity of $u$ further. (Actually, I can use the method to prove that if $f$ is $C^\infty$, then $u$ is also $C^\infty$, but I cannot extend this result to $C^\alpha$ case.) Another attempt is Schauder estimate. However, in Gilbarg and Trudinger's book they assume that $u\in C^{2,\alpha}(M)$ already to get some interior derivative norm bound of $u$, while I don't know how to establish $u\in C^{2,\alpha}(M)$. They give a continuity method to ensure that, but it seems their discussion works for domains in Euclidean space, not for manifolds. Therefore, I want to split the question into coordinate charts, but I failed, because I don't know how to use the condition $\int_M f\, dVol_g=0$ and how to give boundary conditions in every coordinate charts. Since I'm a novice in PDE, my presentation of the problem might have some errors. Please correct them by comments or answers. Also, any comments or answers are welcome. Thanks for your help.","['riemannian-geometry', 'partial-differential-equations', 'differential-geometry']"
172894,Question about integral closures and localizations,"Suppose $A$ is an integral domain with integral closure $\overline{A}$ (inside its fraction field), $\mathfrak{q}$ is a prime ideal of $A$, and $\mathfrak{P}_1,\ldots,\mathfrak{P}_k$ are the prime ideals of $\overline{A}$ lying over $\mathfrak{q}$. Show that $\overline{A_\mathfrak{q}} = \bigcap\overline{A}_\mathfrak{P_i}$ (note that the LHS is the integral closure of a localization, whereas the RHS is the intersection of localizations of integral closures of $A$). If it would help, I suppose we could assume that $A$ has dimension 1, so that $\overline{A}$ is Dedekind, though I don't think that assumption is required. (Geometrically, we're comparing the integral closure of a local ring at a singular point Q of some variety with the intersection of local rings at points in the normalization mapping to Q). Thanks.","['commutative-algebra', 'algebraic-geometry']"
172896,"Set of maximal chains in $\langle\mathcal{P}(\mathbb{N}),\subseteq\rangle$","Let $S$ be the set of all maximal chains in the poset $\langle$ $\mathcal{P}$ $($ $\mathbb{N}$ $),$ $\subseteq$ $\rangle$ partitioned into equivalence classes by their order types . 
How many different order types are there? Can you give me some insight into the structure of $S$ when quasi-ordered by embedding of order types? What is the supremum of ordinals that can be embedded into this quasi-order?","['ordinals', 'elementary-set-theory', 'order-theory']"
172901,Calculating the minimum of $\cos x \sin y$,"I am about to start university in October, to study computer science, and have been asked by my university to complete a number of problem sheets.  I have become stuck on the following question, and therefore would appreciate any help possible. The numbers $x$ and $y$ are subject to the constraints $x+y=\pi$. Find the values of $x$ and $y$ for which $\cos x\sin y$ takes its minimum value. Using this question as a starting point towards a solution, I have the following steps attempted so far. \begin{align*}
\Lambda(x, y, \lambda)&=\cos x\sin y+\lambda(x+y-\pi)\\
\frac{\partial\Lambda}{\partial x}&=-\sin x\sin y+\lambda=0\\
\frac{\partial\Lambda}{\partial y}&=\cos x\cos y+\lambda=0\\
\frac{\partial\Lambda}{\partial\lambda}&=x+y-\pi=0\\
x&=\cos^{-1}\left(\frac{\lambda}{\sin y}\right)\\
y&=\cos^{-1}\left(\frac{-\lambda}{\cos x}\right)\\
\cos^{-1}\left(\frac{\lambda}{\sin y}\right)+\cos^{-1}\left(\frac{-\lambda}{\cos x}\right)&=\pi\\
\end{align*} Unfortunately, such maths is way beyond my abilities, as I have only studied A-Level Maths and Further Maths, and I am working from the first answer in the referenced question and the Wikipedia articles on Lagrange Multipliers and Partial Derivatives .
I'm unsure of the correct tags to apply, so any help there would also be wonderful. Edit: After receiving a number of hints, this is part of my solution, however, I'm not sure on how to properly phrase the last bit of the question with respect to properly solving the inequality or expressing values for $y$.
\begin{align*}
\sin x\cos y&=\sin x\cos(\pi-x)\\
&=-\sin x\cos x\\
&=\sin x\cos x\\
&=\frac12\sin2x\\
\frac{\mathrm{d}}{\mathrm{d}x}\left(\frac12\sin2x\right)&=\cos2x\\
\cos2x&=0\Rightarrow x=\frac12\left(n\pi-\frac\pi2\right),n\in\mathbb{Z}\\
\frac{\mathrm{d}}{\mathrm{d}x}\cos2x&=-2\sin2x\\
-2\sin2x>0&\Rightarrow\sin2x<0\\
\end{align*}",['multivariable-calculus']
172909,proving convergence for a sequence defined recursively,"The sequence $\left \{ a_{n} \right \}$ is defined by the following recurrence relation:
$$a_{0}=1$$ and $$a_{n}=1+\frac{1}{1+a_{n-1}}$$ for all $n\geq 1$ Part 1)- Prove that $a_{n}\geq 1$ for all $n\geq 0$
Part2)- Prove that the sequence $\left \{ a_{n} \right \}$ converges to some real number $x$, and then calculate $x$ For the first part, I could prove it using induction.
For the second part: The problem is how to prove that this sequence is convergent. Once the convergence is proved, then from the recurrence relation we can deduce that $x=\sqrt{2}$. In order to prove it is convergent, I tried to see how this sequence converges to $x$. I calculated the terms $a_{0}$, $a_{1}$, $a_{2}$, $a_{3}$, $a_{4}$. I can see that the sequence is neither decreasing nor increasing, so the monotone convergence theorem cannot be applied. I can see that the distance between two consecutive terms is getting smaller and smaller, so I tried to prove that this sequence is contractive. $\left | a_{n+1} -a_{n}\right |=\frac{1}{\left | 1-a_{n} \right |\left | 1+a_{n} \right |}\left | a_{n}-a_{n-1} \right |$, and obviously, $\frac{1}{\left | 1+a_{n} \right |}\leq \frac{1}{2}$. I need to prove that $\frac{1}{\left | 1-a_{n} \right |}\leq \alpha $ where $0< \frac{\alpha }{2}< 1$, and hence the sequence is contractive and therefore it is convergent. If you have any idea how to prove $\frac{1}{\left | 1-a_{n} \right |}\leq \alpha $ or any other idea please share...","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'analysis']"
172910,Probability density function of a complex-valued random variable,"I'm trying to understand the concept of complex-valued random variables, but I'm struggling. If you consider two real-valued random variables $U$ and $V$ with values $u$ and $v$ and the joint random variable $UV$ with values $(u,v)$ then under the following transformation of random variable $UV$ to random variable $ZW$
$$z=u+iv$$
$$w=u$$
the probability density function of $ZW$ is (Jacobian determinant =1)
$$p_{ZW}(z,w)=p_{UV}(z-iw,w)$$
and the marginal probability density function $p_{Z}(z)$ is then given by
$$p_{Z}(z)=\int_{-\infty}^{\infty}{p_{UV}(z-iw,w)}dw$$
Is this the probability density function of complex-valued random variable $Z$?","['statistics', 'probability']"
172917,proving existence of a sequence such that the limit exists?,"Can anyone prove the existence of a sequence $(n_{k})_{k\in \mathbb{N}}$ of distinct positive integers such that the limit: $\lim_{k\rightarrow \infty }\sin(n_{k})$ exists in $\mathbb{R}$ I can definitely construct a sequence $(n_{k})_{k\in \mathbb{N}}$ such that $\frac{1}{2}\leq \sin(n_{k})\leq 1$, but this doesn't imply that this sequence is convergent. Any suggestions?","['sequences-and-series', 'convergence-divergence', 'calculus', 'real-analysis', 'analysis']"
172919,Which of the following are compact sets?,"Which of the following are compact sets? $\{\operatorname{trace}(A): A  \text{ is real orthogonal}\}$ $\{A\in M_n(\mathbb{R}):\text{ eigenvalues $|\lambda|\le 2$}\}$ Well, orthogonal matrices are compact, but the trace of them may be any $x\in\mathbb{R}$, so I guess 1 is non compact. Let $x$ be an eigenvector corresponding to the eigenvalue $\lambda$; then $Ax=\lambda x$, then $\|Ax\|= |\lambda|\cdot\|x\|\le \|A\|\cdot\|x\|$ so $\|A\|\ge 2$ so $2$ is also non compact as unbounded?","['general-topology', 'matrices', 'compactness']"
172964,Is R with $j_d$ topology totally disconnected?,"Let consider the topological space $R_j=(\mathbb{R},j_r)$ where $j_r$ is generated by right side open intervals, i.e $[a,b)$ for $a,b \in \mathbb{R}$; note that this topology includes the euclidean topology. $R_j$ is not a connected space, because given $x \in \mathbb{R}$ we have that $(-\infty,x)$ and $[x,+\infty)$ provide a disconnection or $R_j$. Given the arbitrariness in choosing $x$, is it possible that $R_j$ is totally disconnected? Let consider a certain $y:x<y<+\infty$; I can progressively reduce the open interval containing $x$ $$[x...)...)...)...)...y)$$ so that the connected component which contains $x$ is (strictly) included in $[x,x+\varepsilon)\;\forall\varepsilon>0.$ if we suppose there is a certain limit in this reduction, then we would have to accept that $[x-\varepsilon /2,x+\varepsilon /2)$ is a connected component, which is a contradiction with the beginning of this discussion. What can we conclude, from this?",['general-topology']
172966,"What are the differences between class, set, family, and collection?","In school, I have always seen sets. I was watching a video the other day about functors, and they started talking about a set being a collection, but not vice-versa. I also heard people talking about classes. What is their relation? Some background would be nice. It has to do with something called Russell's paradox, but I don't know what that is. I think that the difference between a family and a set is that the former is a function and the latter is a set. Is this right?","['terminology', 'elementary-set-theory', 'paradoxes', 'definition']"
173017,I want inductively prove that $f^{(n)}(0)=0$ for all n.,"Define a function $f(x)$ such that: \begin{cases}
\exp(-1/x^2), & \text{if } x>0, \\
0, & \text{if } x\leqslant 0. \\
\end{cases} I want to inductively prove that $f^{(n)}(0)=0$ for all $n \geqslant 0$. Any suggestions, please?","['induction', 'calculus', 'derivatives']"
173020,A problem on Fourier transforms and orthogonality,"Let $f$ be a square integrable function, strictly positive almost everywhere. Consider the family of functions $f_a=f(x+a)$, where $a$ is any real number. I want to prove that if a function is orthogonal to all this family then it must be zero. The hint I was given is to use Fourier transform, that is to show that $(g,e^{ika}\hat f)=0$ implies that $g=0$. But from here I am not sure how to go on... I see that $(g,e^{ika}\hat f)$ is proportional to the inverse Fourier transform of $g^{*}\hat f$ and therefore $g^{*}\hat f$ is zero almost everywhere, but can I say that $\hat f$ is also positive, since it is the Fourier transform of a positive function?","['hilbert-spaces', 'fourier-analysis', 'functional-analysis']"
173021,Is the coordinate ring of SL2 a UFD?,"Is the ring $K[a,b,c,d]/(ad-bc-1)$ a unique factorization domain ? I think this is a regular ring , so all of its localizations are UFDs by the Auslander–Buchsbaum theorem . However, I know there are Dedekind domains (which are regular; every local ring is a PID, so definitely  UFD) that are not UFDs, so being a regular ring need not imply the ring is a UFD. With the non-UFD Dedekind domains (at least the number rings), I can usually spot a non-unique factorization, but I don't see any here in this higher dimensional example.","['commutative-algebra', 'ring-theory', 'unique-factorization-domains', 'abstract-algebra']"
173026,Matrices whose Linear Combinations are All Singular,"I'd like to know if the following problem of elementary linear algebra is already solved / solvable. For two (singular) $n\times n$ matrices $P$ and $Q$, if $\det(\lambda P+\mu Q)=0$ for any $\lambda,\mu\in\mathbb{R}$, what are conditions on $P$ and $Q$?",['linear-algebra']
173049,"Any finitely generated subgroup of $(\mathbb{Q},+)$ is cyclic.","$\fbox{1}$ Prove that any finitely generated subgroup of $(\mathbb{Q},+)$ is cyclic. $\fbox{2}$ Prove that $\mathbb{Q}$ is not isomorphic to $\mathbb{Q}\times \mathbb{Q}$ . Any hints would be appreciated.","['finitely-generated', 'group-theory', 'abelian-groups']"
173053,How to show unitary decomposition is continuous,"It is a well-known fact that, for $A \in GL(n,\mathbb{C})$ with polar decomposition $A=U_AP_A$ for $U_A$ unitary and $P_A$ positive definite and Hermitian, the map $GL(n,\mathbb{C}) \rightarrow U(n)$ by $A \mapsto U_A$ is a homotopy equivalence. This is a fact I have seen many times. However, I have recently realized that I have no idea how to prove this map is continuous. It's pretty clear that since $U_A=A P_A^{-1}=A (\sqrt{A^*A})^{-1}$, where * denotes the conjugate transpose, all one needs to prove is continuity for the matrix square root map which sends a positive-definite matrix to its principal square root since continuity for multiplication and inverses are well-known and continuity for * is obvious. Can anyone provide a good proof for continuity of the matrix square-root map on the space of positive definite matrices? Of course if you can prove $A \mapsto U_A$ is continuous without that fact, that would also be a fine answer.","['linear-algebra', 'continuity']"
173061,"Sequence Limit: $\lim\limits_{n \rightarrow \infty}{n\,x^n}$","If $-1<x<1$ show that $\lim\limits_{n \to \infty}{n\,x^n} = 0$. I don't have idea. I only prove that $n\,x^n$ is decreasing.","['sequences-and-series', 'limits']"
173068,Find a continuous solution of the initial-value problem,"This question is from DE book by Braun(Pg no 10, Q no 17), Find a continuous solution of the initial-value problem $y'+y= g(t), y(0)= 0$ where $g(t)=\begin{cases}2, &0 \leq t\leq 1, \\0, &t > 1\end{cases} $ since the intial condition is given at (0,0), therefore we consider $g(t)=2$ and so solving $y'+y=2$ gives integrating factor $\mu(t)=Ce^t \Rightarrow y=2+Ce^{-t} \Rightarrow C=-2 \Rightarrow y=2(1-e^{-t})$, the answer given in the text it this $y(t) = \begin{cases} 2(1-e^{-t}), &0\leq t\leq 1\\ 2(e-1)e^{-t},  &t > 1 \end{cases} $ even if we consider $g(t)=0$ we get $\ln|y|=-t+C$ and we cannot proceed further since there is no initial condition, $y(1)=?$ my question is how to solve for $y$ at $t>1$ and also, do we find left and right limit at $t=1$ to prove that the answer is a continuous function?",['ordinary-differential-equations']
173070,Showing that the closure of the closure of a set is its closure,"I have the feeling I'm missing something obvious, but here it goes... I'm trying to prove that for a subset $A$ of a topological space $X$, $\overline{\overline{A}}=\overline{A}$.  The inclusion $\overline{\overline{A}} \subseteq \overline{A}$ I can do, but I'm not seeing the other direction. Say we let $x \in \overline{A}$.  Then every open set $O$ containing $x$ contains a point of $A$.  Now if $x \in \overline{\overline{A}}$, then every open set containing $x$ contains a point of $\overline{A}$ distinct from $x$.  My problem is: couldn't $\{x,a\}$ potentially be an open set containing $x$ and containing a point of $A$, but containing no other point in $\overline{A}$? (Also, does anyone know a trick to make \bar{\bar{A}} look right?  The second bar is skewed to the left and doesn't look very good.)",['general-topology']
173073,Why are compact operators 'small'?,"I have been hearing different people saying this in different contexts for quite some time but I still don't quite get it. I know that compact operators map bounded sets to totally bounded ones, that the perturbation of a compact operator does not change the index, and that the calkin algebra is an indispensable tool in the study of operators in the sense that 'essentially something' becomes a useful notion. But I still suspect why they are 'small'. Now Connes says they are like 'infinitesimals' in commutative function theory, which makes me even more confused. So I guess I just post this question here and hopefully I can hear some quite good explanations about the reasoning behind this intuition. Thanks!","['operator-theory', 'operator-algebras', 'banach-algebras', 'functional-analysis']"
173093,Homeomorphisms of X form a topological group,"So I'm just learning about the compact-open topology and am trying to show that for a compact, Hausdorff space ,$X$, the group of homeomorphisms of $X$, $H(X)$, is a topological group with the compact open topology.  This topology has a subbasis of sets $\{f\in H(X):f(C)\subseteq V\}=S(C,V)$ for compact $C$, open $V$.  This is my first attempt at getting to know this topology, so I'd appreciate some help with the part of a proof I have so far, possibly a better way to go about proving this, and any other help understanding this topology. First, let $c:H(X)\times H(X)\rightarrow H(X)$ be composition.  For $f,g\in H(X)$, let $S(C,V)$ be a subbasis set with $f\circ g\in S(C,V)$.  So $f(g(C)\subseteq V$ which means $f\in S(g(C),V)$ and $g\in S(C,f^{-1}(V)$.  The product of these open sets works since if $h_1(C)\subseteq f^{-1}(V)$ and $h_2(g(C))\subseteq V$, then $h_2\circ h_1(C)\subseteq V$. Then let $i:H(X)\rightarrow H(X)$ be inversion.  Take a subbasis set $O=\{g:g(C)\subseteq U\}$ and consider $i^{-1}(O)=\{g^{-1}:g(C)\subseteq U\}$.  If $h^{-1}\in i^{-1}(O)$, then one thing we have is that $h(C)\subset U$, but I'm not totally sure what to do with this.  This part seems like it should be easier, but I am just not seeing it. Thanks.","['general-topology', 'topological-groups']"
173099,"Find all solutions, other than $2$ for $12x^3-23x^2-3x+2=0$","Find all solutions, other than $2$ for $12x^3-23x^2-3x+2=0$ I started off by taking out an $x$ and got $$x(12x^2-23x-3)+2=0$$ I do not know if this is the correct first step, if it is, then am I able to use the quadratic formula or complete the square to get the answers. Can anyone give me general hints. Please do not solve this for me in anyway. Just give me hints.",['algebra-precalculus']
173106,"Solve $\, \mathrm dy/\, \mathrm dx = e^{x^2}$","I want to solve $$\frac{\, \mathrm dy}{\, \mathrm dx}=e^{x^{2}}.$$ i using variable separable method to solve this but after some stage i stuck with the integration of $\int e^{x^{2}}\, \mathrm dx$ . i dont know what is the integration of $\int e^{x^{2}}\, \mathrm  dx$ .  Please help me out!",['ordinary-differential-equations']
173113,Relationship between prime factorizations of $n$ and $n+1$?,"Are there any theorems that give us any information about the prime factorization of some integer $n+1$, if we already know the factorization of $n$? Recalling Euclid's famous proof for the infinity of the set of prime numbers, I guess we know that if $n = p_1 p_2 p_3$, then $n+1$ cannot have $p_1$, $p_2$, or $p_3$ as factors. But is there any way we could use the information about $n$'s factorization to determine something more precise about the factorization of $n+1$?","['prime-numbers', 'number-theory']"
173133,What can be the possible value of $a+b+c$ in the following case?,"What can be the possible value of $a+b+c$ in the following case? $$a^{2}-bc=3$$ 
$$b^{2}-ca=4$$
$$c^{2}-ab=5$$ $0, 1, -1$ or $1/2$? After doing $II-I$, $III-I$ and $III-II$, I got, 
$$(a+b+c)(b-a)=1$$
$$(a+b+c)(c-a)=2$$
$$(a+b+c)(c-b)=1$$ I'm unable to solve further, please help.",['algebra-precalculus']
173156,Are a square matrix's columns and rows either both(separately) linearly independent or both(separately) linearly dependent?,"Prove or disprove: Given a square matrix $A$,the columns of $A$ are linearly independent iff. the rows of $A$ are linearly independent.","['matrices', 'linear-algebra']"
173170,"To express $f(x,z)=\sum \limits_{n=0}^\infty \frac{e^{-\alpha n^2 x+\beta n z}}{n!}$ as known functions","$\alpha,\beta >0$
$$f(x,z)=\sum \limits_{n=0}^\infty \frac{e^{-\alpha n^2 x+\beta n z}}{n!}$$ $$\frac{\partial{f(x,z)}}{\partial z}=\beta \sum \limits_{n=1}^\infty \frac{e^{-\alpha n^2 x+\beta n z}}{(n-1)!}$$ $$\frac{\partial{f(x,z)}}{\partial z}|_{z=2 \frac{ \alpha}{\beta} x+ z_1}=\beta \sum \limits_{n=1}^\infty \frac{e^{-\alpha n^2 x+\beta n (2 \frac{ \alpha}{\beta} x+  z_1)}}{(n-1)!}$$ $$\frac{\partial{f(x,z)}}{\partial z}|_{z=2 \frac{ \alpha}{\beta} x+ z_1}=\beta e^{\alpha x+ \beta z_1} \sum \limits_{n=1}^\infty \frac{e^{-\alpha (n-1)^2 x+\beta (n-1) z_1}}{(n-1)!}$$ $$\frac{\partial{f(x,z)}}{\partial z}|_{z=2 \frac{ \alpha}{\beta} x+ z_1}=\beta e^{\alpha x+ \beta z_1} \sum \limits_{n=0}^\infty \frac{e^{-\alpha n^2 x+\beta n z_1}}{n!}$$ $$\frac{\partial{f(x,z)}}{\partial z}|_{z=2 \frac{ \alpha}{\beta} x+ z_1}=\beta e^{\alpha x+ \beta z_1} f(x,z_1)$$ I do not know how to solve this kind  differential equations. Do you know how to solve that? Can we express the function as known functions such as Jacobi Theta Functions etc? Also  could you please share your knowledge about the function if you know it. Thanks a lot for answers EDIT: Another property is: $$-\alpha\frac{\partial^2{f(x,z)}}{\partial z^2}=\beta^2 \frac{\partial{f(x,z)}}{\partial x} $$","['special-functions', 'ordinary-differential-equations', 'sequences-and-series', 'partial-differential-equations']"
173189,"For what value of k, $x^{2} + 2(k-1)x + k+5$ has at least one positive root?","For what value of k,  $x^{2} + 2(k-1)x + k+5$ has at least one positive root? Approach: Case I : Only $1$ positive root, this implies $0$ lies between the roots, so $$f(0)<0$$ and $$D > 0$$ Case II: Both roots positive. It implies $0$ lies behind both the roots. So, $$f(0)>0$$
$$D≥0$$
Also, abscissa of vertex $> 0  $ I did the calculation and found the intersection but its not correct. Please help. Thanks.","['quadratics', 'algebra-precalculus', 'roots']"
173209,Conditions for the equivalence of $\mathbf A^T \mathbf A \mathbf x = \mathbf A^T \mathbf b$ and $\mathbf A \mathbf x = \mathbf b$,"I have an application where I have to minimize a cost function of the form: $J(\mathbf x) = \| \mathbf A \mathbf x - \mathbf b \|^2 \quad (1)$ By calculating the gradient, I derived that I have to solve the system of equations: $\mathbf A^T \mathbf A \mathbf x = \mathbf A^T \mathbf b \quad (2)$ Now my question is, when can I solve the following system instead? $\mathbf A \mathbf x = \mathbf b \quad (3)$ From my point of view, this depends on $\mathbf A$ to be invertible. In my application $\mathbf A$ is a square matrix of the form $\mathbf A = \mathbf I - \mathbf W$ where $\mathbf I$ is the identity matrix and $\mathbf W$ is a square matrix with zeros on the main diagonal and small values on a few secondary diagonals. The values of $\mathbf W$ are arbitrary but normalized, so that each row of $\mathbf W$ sums to 1. However, some lines of $\mathbf W$ can also be zero. For example $\mathbf A$ may look like this: $\mathbf A = \pmatrix{
1 & -0.2 & 0 & 0 & -0.3 & -0.2 & -0.3 & 0 & 0 \cr
-0.1 & 1 & -0.2 & 0 & 0 & -0.4 & -0.2 & -0.1 & 0 \cr
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \cr
0 & 0 & -0.2 & 1 & -0.1 & 0 & 0 & -0.6 & -0.1 \cr
-0.2 & 0 & 0 & -0.2 & 1 & -0.5 & 0 & 0 & -0.1 \cr
-0.4 & -0.3 & 0 & 0 & -0.1 & 1 & -0.2 & 0 & 0 \cr
-0.1 & -0.1 & -0.1 & 0 & 0 & -0.6 & 1 & -0.1 & 0 \cr
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \cr
0 & 0 & -0.2 & -0.4 & -0.1 & 0 & 0 & -0.3 & 1 \cr
}$ Have I argued correctly? Then how can I show that $\mathbf A$ is invertible? Or is there any other argument for solving (3) instead of (2)? I tried to solve both systems (2) and (3) with MATLAB and the Intel MKL, but surprisingly only (3) gave me the expected result. I would expect that it also works with (2). Maybe a numerical problem?","['numerical-linear-algebra', 'linear-algebra']"
173228,On certain decomposition of unitary symmetric matrices,"It is well known that a symmetric matrix over field $\Bbb F$ is congruent to a diagonal matrix, i.e., there exists some A s.t. $A^TUA=D$ with $U$ symmetric and $D$ diagonal. If $\Bbb F=\Bbb C$ then we can make $D=I$. Recently I learned that if $U$ is unitary that we can do one step further by requiring $A$ to be unitary too. A similar result holds for unitary skew matrices. But I fail to figure out a proof myself. Can anyone provide a proof of this or at least help me to locate some references? Many thanks!","['linear-algebra', 'reference-request']"
173237,Is this definition missing some assumptions?,"In his ""Calculus on manifolds"" Spivak first defines $n$-dimensional (Riemann-) integral over rectancles, then over Jordan measurable subsets of rectangles and finally extends it to open sets using partitions of unity. It's this final part I'm having some problems with. He defines a partition of unity for a set $A\subset \mathbb{R}^n$ to be family $\Phi$ of $C^{\infty}$ functions satisfying the following three axioms: $0\leq\phi(x)\leq 1$ $\forall \phi\in\Phi$ $\forall x\in A$ For every $x\in A$ there exists an open set $V$ s.t. only finitely many $\phi\in\Phi$ are nonzero in $V$ $\sum_{\phi\in\Phi} \phi(x)=1$ $\forall x\in A$ Moreover, $\Phi$ is subordinate to an open cover $\mathcal{O}$ of $A$ if for each $\phi\in\Phi$ we can find an open set $U\in\mathcal{O}$ s.t. $\phi=0$ outside some closed set contained in $U$. Suppose now that $A$ is open and we have an open cover $\mathcal{O}$ for $A$ s.t. $U\subseteq A$ for each $U\in\mathcal{O}$. We shall call such a cover admissible . Let $f:A\to R$ be locally bounded (i.e. every point has a neighbourhood $V$ s.t. $f$ bounded in $V$) and continuous almost everywhere (i.e. the set of discontinuties has measure $0$). Furthermore let $\Phi$ be a countable partition of unity for $A$ subordinate to $\mathcal{O}$. We say that $f$ is integrable over $A$ if $\sum_{\phi\in\Phi} \int_A \phi |f|$ converges. Spivak asserts that the integrals $\int_A \phi|f|$ all exist but I don't see why because we have thus far only defined integrals over bounded sets. Obviously we could assume that the open cover is composed of bounded sets or maybe instead that the functions $\phi$ have compact support but neither appears to be assumed in the book. So do we need some extra assumptions here or am I missing something?","['multivariable-calculus', 'integration']"
173238,Evaluating the product $\prod\limits_{k=1}^{n}\cos\left(\frac{k\pi}{n}\right)$,"Recently, I ran across a product that seems interesting. Does anyone know how to get to the closed form: $$\prod_{k=1}^{n}\cos\left(\frac{k\pi}{n}\right)=-\frac{\sin(\frac{n\pi}{2})}{2^{n-1}}$$ I tried using the identity $\cos(x)=\frac{\sin(2x)}{2\sin(x)}$ in order to make it ""telescope"" in some fashion, but to no avail. But, then again, I may very well have overlooked something. This gives the correct solution if $n$ is odd, but of course evaluates to $0$ if $n$ is even. So, I tried taking that into account, but must have approached it wrong. How can this be shown? Thanks everyone.","['trigonometry', 'sequences-and-series', 'products']"
173239,Spectrum of $R[x]$,"The spectrum of $\Bbb Z[x]$ is well known : a prime ideal of $\Bbb Z[x]$ is or $(Q, p)$, with $Q \in \Bbb Z[x]$ zero or irreducible modulo $p$, and $p$ prime or zero. If I'm not mistaken, we have a similar result for $R[x]$, when $R$ is a domain with finite Krull dimension : under this hypothesis, a prime ideal of $R[x]$ is  $(Q) + \mathfrak p$, with $\mathfrak p$ a prime ideal of $R$ and $Q$ zero of irreducible modulo $\mathfrak p$. Some years ago I saw a paper dealing with this question of the spectrum of $R[x]$ in great details, but I'm unable to find it again. Could you help me ?","['commutative-algebra', 'algebraic-geometry', 'reference-request']"
173270,Finding the divisor of an unknown,"I am trying to solve this problem A number when divided by a divisor leaves a remainder of 24. When twice the original number is divided by the same divisor, the remainder is 11. What is the value of the divisor? I have established two relations here but dont know how to proceed , any suggestions would be appreciated . $x= dq + 24  $ where d=divisor $2x= dk + 11 $ where d=divisor","['elementary-number-theory', 'algebra-precalculus']"
173315,Different notions of q-numbers,"It seems that most of the literature dealing with q-analogs defines q-numbers according to
$$[n]_q\equiv \frac{q^n-1}{q-1}.$$
Even Mathematica uses this definition: with the built-in function QGamma you obtain QGamma[n+1,q] / QGamma[n,q] = (q^n-1) / (q-1) However, in some books and papers you find that the authors use a different notion of q-numbers, namely
$$[n]_q\equiv \frac{q^n-q^{-n}}{q-q^{-1}}.$$
To me it seems that this alternative definition is exclusively used in the context of physics dealing with quantum groups. Now my questions: What is the notion/motivation for the latter definition? Somehow, it seems to be more relevant in (physical) applications. Are these two approaches equivalent? If so, to what extent? On the technical side: The QGamma function can be defined in terms of QPochhammer functions (see e.g. http://en.wikipedia.org/wiki/Q-gamma_function ). If I wanted to define a QGamma function such that
$$\frac{\Gamma_q(n+1)}{\Gamma_q(n)} = \frac{q^n-q^{-n}}{q-q^{-1}}$$
what would be the (modified) definition of the respective QPochhammer functions? Thanks in advance to everyone considering my questions! P.S.: I'd also appreciate, if anyone can suggest some good literature on this topic in general.","['special-functions', 'hopf-algebras', 'q-analogs', 'quantum-groups', 'combinatorics']"
173331,Moment generating function for the uniform distribution,"Attempting to calculate the moment generating function for the uniform distrobution I run into ah non-convergent integral. Building of the definition of the Moment Generating Function $
M(t) = E[ e^{tx}] = \left\{ \begin{array}{l l}
\sum\limits_x e^{tx} p(x) &\text{if $X$ is discrete with mass function $p( x)$}\\
\int\limits_{-\infty}^\infty e^{tx} f( x) dx &\text{if $X$ is continuous with density $f( x)$}
\end{array}\right.
$ and the definition of the Uniform Distribution $
f( x) = \left\{ \begin{array}{l l}
\frac{ 1}{ b - a} & a < x < b\\
0 & otherwise
\end{array} \right.
$ I end up with a non-converging integral $\begin{array}{l l}
M( t) &= \int\limits_{-\infty}^\infty e^{tx} f(x) dx\\
&= \int\limits_{-\infty}^\infty e^{tx} \frac{ 1}{ b - a} dx\\
&= \left. e^{tx} \frac{ 1}{ t(b - a)} \right|_{-\infty}^{\infty}\\
&= \infty
\end{array}$ I should find $M(t) = \frac{ e^{tb} - e^{ta}}{ t(b - a)}$, what am I missing here?",['probability-theory']
173333,Maximum area of a triangle in a square,"For a given square, consider 3 points on the perimeter to form a triangle. How to prove that: The maximum area of triangle is half the square's. The maximum area of triangle occurs if and only if the chosen points are vertexes of the square.","['optimization', 'geometry']"
173336,What surfaces in $\mathbb R^3$ are such that every planar section (with more than 1 point) has nontrivial symmetry?,"In $\mathbb R^3$ , the intersection of a plane and a sphere (e.g. $x^2 + y^2 + z^2 = 1$) is either empty, a single point, or a circle.  All isometries of those circles are realized by isometries of the full sphere. In contrast, every plane intersects a cone (e.g. $x^2 + y^2 - z^2 = 0$) in a conic section which has reflection symmetries along one, two, or more axes.  The one reflection is realized by an isometry of the cone, but the second, in general, is not. What surfaces in $\mathbb R^3$ , or general subsets of $\mathbb R^3$ , are such that all non-empty planar intersections are either 1 point or have nontrivial symmetry?  When are those symmetries not extensible to a symmetry of the full surface?","['algebraic-geometry', 'algebra-precalculus', 'surfaces']"
173337,"Difference between population, sample and sample value.","I was going through a book and reached a point where the author is comparing a Population, Sample and Sample Values. I don't seem to understand the difference at all. (Caps are Random Variables, small font are values/data points) What is the role of Random Variables here? What does the numbering in X imply? ($X_i \forall i\in \{1,2,3,\cdots,n\}$) What does the vertical line from $X_1$ to $x_1$ suggest?",['probability']
173344,What exactly is a Haar measure,"I've come across at least 3 definitions, for example: Taken from here where $\Gamma$ is a topological group. Apparently, this definition doesn't require the Haar measure to be finite on compact sets. Or from Wikipedia :
""... In this article, the $\sigma$-algebra generated by all compact subsets of $G$ is called the Borel algebra....""
Then $\mu$ defined on this sigma algebra is a Haar measure if it's outer and inner regular, finite on compact sets and translation invariant. So I gather the important property of a Haar measure is that it's translation invariant. Question 1: What I don't gather is, what do I get if I define it on the Borel sigma algebra as opposed to defining it on the sigma algebra generated by compact sets (as they do on Wikipedia)? Question 2: Can I put additional assumptions on $G$ so that I can drop the requirement that $\mu$ has to be finite on compact sets? Question 3: As you can guess from my questions I'm poking around in the dark trying to find out how to define a Haar measure suitably. Here suitably means, I want to use it to define an inner product so I can have Fourier series. Are there several ways to do this which lead to different spaces? By this I mean, if I define it on the Borel sigma algebra, can I do Fourier series for a different set of functions than when I have a measure on the sigma algebra generated by compact sets? Or what about dropping regularity? Or dropping finiteness on compact sets? Thanks.","['measure-theory', 'fourier-analysis', 'functional-analysis']"
173370,Compute the trigonometric integrals,"How would you compute the following integrals? $$ I_{n} = \int_0^\pi \frac{1-\cos nx}{1- \cos x} dx  $$
$$ J_{n,m} = \int_0^\pi \frac{x^m(1-\cos nx)}{1- \cos x} dx  $$ For instance, i noticed that the first integral is convergent for any value of $n$ since $\lim_{x\to0} \frac{1- \cos nx}{1 - \cos x}= n^2$. This fact may also be extended to the second integral, as well.","['definite-integrals', 'calculus', 'real-analysis']"
173379,"Find center, radius and a tangent to $x^2+y^2+6x-4y+3=0$","For the circle  $x^2+y^2+6x-4y+3=0$ find a) The center and radius b) The equation of the tangent line at the point $(-2,5)$ Now, I solved a) and got the equation
$$(x+3)^2+(y-2)^2=10$$ with center $=(-3,2)$ and radius $=\sqrt{10}$ Now, I've never learned about the tangent of a circle, but I think that it's a line that touches the outer end of a circle. But I'm not 100% on that. So if anyone can help me out with this, that would be very beneficial. And please do not solve this for me.","['algebra-precalculus', 'circles']"
173385,Connected nice topological spaces that are transitive but not 2-transitive under homeomorphisms,"I was thinking about a question on here earlier, and came up with this question. [Added Hausdorff note, below.] It is easy to see that the group of self-homeomorphisms of the real line acts $2$-transitively on the space, but not $3$-transitively. Likewise, it is clear that, for example, $\mathbb R\setminus \{0\}$ is a space on which the group of self-homemorphisms is $1$-transitive but not $2$-transitive. If you take the real line with the open sets of the form $(-\infty,a)$ for some $a$, then I guess this gives you an example, but that space is not Hausdorff. I can't seem to think of an example of a connected Hausdorff space where the self-homeomorphisms are $1$-transitive but not $2$-transitive.",['general-topology']
173387,Calculating maximum of function,"I want to determine the value of a constant $a > 0$ which causes the highest possible value of $f(x) = ax(1-x-a)$. I have tried deriving the function to find a relation between $x$ and $a$ when $f'(x) = 0$, and found $x = \frac{1-a}{2}$. I then insert it into the original function: $f(a) = \frac{3a - 6a^2 - 5a^3}{8}$ I derived it to $f'(a) = \frac{-15a^2 + 12a - 3}{8}$ I thought deriving the function and equaling it to $0$ would lead to finding a maximum, but I can't find it. I can't go beyond $-15a^2 + 12a = 3$. Where am I going wrong?","['optimization', 'calculus', 'functions']"
173402,Necessary and sufficient conditions for a matrix to be a valid correlation matrix.,"It's not too hard to see that any correlation matrix must have certain properties, such as all entries in the range -1 to 1, symmetric, positive semi-definite (excluding pathological cases like singular matrices for the moment). But I'm wondering about the other direction. If I write down some matrix that is positive semi-definite, is symmetric, has 1's along the main diagonal, and all entries are between -1 and 1, does this guarantee that there exists a set of random variables giving rise to that correlation matrix? If the answer is easy to see, a helpful hint about how to define the set of random variables that would give rise to a given matrix would be appreciated.","['matrices', 'correlation', 'linear-algebra', 'probability']"
173403,A circle is tangent to the $y$-axis at $y=3$ and has one $x$-intercept at $x=1$. Find the other $x$-intercept,"A circle is tangent to the $y$-axis at $y=3$ and has one $x$-intercept at $x=1$. Find the other $x$-intercept Like previously mentioned, I'm not all too familiar with circles. So, I plotted the two points and I do not know the next step. I would guess to find the slope which is $-\dfrac{3}{1}$. But that doesn't seem right. I'm just taking a shot in the dark. If someone can tell me what to do next, or at least how to find the center that would be helpful. Please do not give me the answer.","['algebra-precalculus', 'circles']"
173420,What is a Neighborhood?,"Which of these definitions is more commonly used, and in which contexts? Fix a point $x\in (X, \tau)$. Then a neighborhood around a point $x$ is: a set $N\ni x$ and $N\in \tau$ a set $N$ with $x\in \text{int}(N)$ If we are working in a space $(X, \tau)$ that is locally (path) connected: a set $N$ that is (path) connected and open a set $N$ that is simply (path) connected and open Specifically, I am interested in the terminology that would be used in the study of PDEs such as in the book by Gilbarg and Trudinger. Thanks!","['general-topology', 'convention', 'terminology', 'partial-differential-equations']"
173424,Intersection of Simply-Connected Sets,"Let $U,V$ be two simply connected subsets of a topological space. Prove or disprove:
$U \cap V$ is simply connected.",['general-topology']
173441,"Book suggestion for linear algebra ""2""","I am almost finishing Gilbert Strang's book ""An introduction to linear algebra"" (plus video lectures at MIT OCW). First and foremost, I would like to suggest this course for everyone. It has been incredibly illuminating. I would like to continue studying linear algebra, with particular focus on different properties of matrices and the transition to more general linear spaces (I am a physicist so Hilbert spaces and etc. are of particular interest). Does anyone have a a good recommendation of books/resources/etc.?","['linear-algebra', 'reference-request', 'soft-question']"
173447,Proving $\sum\limits_{l=1}^n \sum\limits _{k=1}^{n-1}\tan \frac {lk\pi }{2n+1}\tan \frac {l(k+1)\pi }{2n+1}=0$,"Prove that $$\sum _{l=1}^{n}\sum _{k=1}^{n-1}\tan \frac {lk\pi } {2n+1}\tan \frac {l( k+1) \pi } {2n+1}=0$$ It is very easy to prove this identity for each fixed $n$ . For example let $n = 6$; writing out all terms in a $5 \times 6$ matrix, we obtain: $\begin{matrix} 
\tan \dfrac {\pi } {13}\tan \dfrac {2\pi } {13}
 & 
\tan \dfrac {2\pi } {13}\tan \dfrac {3\pi } {13}
&
\tan \dfrac {3\pi } {13}\tan \dfrac {4\pi } {13}
&
\tan \dfrac {4\pi } {13}\tan \dfrac {5\pi } {13}
&
\tan \dfrac {5\pi } {13}\tan \dfrac {6\pi } {13}
 \\ 
\tan \dfrac {2\pi } {13}\tan \dfrac {4\pi } {13}
 &
 \tan \dfrac {4\pi } {13}\tan \dfrac {6\pi } {13}
&
\tan \dfrac {6\pi } {13}\tan \dfrac {8\pi } {13}
&
\tan \dfrac {8\pi } {13}\tan \dfrac {10\pi } {13}
&
\tan \dfrac {10\pi } {13}\tan \dfrac {12\pi } {13}
\\
\tan \dfrac {3\pi } {13}\tan \dfrac {6\pi } {13}
&
\tan \dfrac {6\pi } {13}\tan \dfrac {9\pi } {13}
&
\tan \dfrac {9\pi } {13}\tan \dfrac {12\pi } {13}
&
\tan \dfrac {12\pi } {13}\tan \dfrac {15\pi } {13}
&
\tan \dfrac {15\pi } {13}\tan \dfrac {18\pi } {13}
\\
\tan \dfrac {4\pi } {13}\tan \dfrac {8\pi } {13}
&
\tan \dfrac {8\pi } {13}\tan \dfrac {12\pi } {13}
&
\tan \dfrac {12\pi } {13}\tan \dfrac {16\pi } {13}
&
\tan \dfrac {16\pi } {13}\tan \dfrac {20\pi } {13}
&
\tan \dfrac {20\pi } {13}\tan \dfrac {24\pi } {13}
\\
\tan \dfrac {5\pi } {13}\tan \dfrac {10\pi } {13}
&
\tan \dfrac {10\pi } {13}\tan \dfrac {15\pi } {13}
&
\tan \dfrac {15\pi } {13}\tan \dfrac {20\pi } {13}
&
\tan \dfrac {20\pi } {13}\tan \dfrac {25\pi } {13}
&
\tan \dfrac {25\pi } {13}\tan \dfrac {30\pi } {13}
\\
\tan \dfrac {6\pi } {13}\tan \dfrac {12\pi } {13}
&
\tan \dfrac {12\pi } {13}\tan \dfrac {18\pi } {13}
&
\tan \dfrac {18\pi } {13}\tan \dfrac {24\pi } {13}
&
\tan \dfrac {24\pi } {13}\tan \dfrac {30\pi } {13}
&
\tan \dfrac {30\pi } {13}\tan \dfrac {36\pi } {13}
 \end{matrix}$ one can notice then, that the first column vanish the fourth one : $\tan \dfrac {\pi } {13}\tan \dfrac {2\pi } {13}=-\tan \dfrac {12\pi } {13}\tan \dfrac {15\pi } {13}$ $\tan \dfrac {2\pi } {13}\tan \dfrac {4\pi } {13}=-\tan \dfrac {24\pi } {13}\tan \dfrac {30\pi } {13}$ $\tan \dfrac {3\pi } {13}\tan \dfrac {6\pi } {13}=-\tan \dfrac {16\pi } {13}\tan \dfrac {20\pi } {13}$ $\tan \dfrac {4\pi } {13}\tan \dfrac {8\pi } {13}=-\tan \dfrac {4\pi } {13}\tan \dfrac {5\pi } {13}$ $\tan \dfrac {5\pi } {13}\tan \dfrac {10\pi } {13}=-\tan \dfrac {8\pi } {13}\tan \dfrac {10\pi } {13}$ $\tan \dfrac {6\pi } {13}\tan \dfrac {12\pi } {13}=-\tan \dfrac {20\pi } {13}\tan \dfrac {25\pi } {13}$ and the third column vanish the fifth one : $\tan \dfrac {3\pi } {13}\tan \dfrac {4\pi } {13}=-\tan \dfrac {30\pi } {13}\tan \dfrac {36\pi } {13}$ $\tan \dfrac {6\pi } {13}\tan \dfrac {8\pi } {13}=-\tan \dfrac {5\pi } {13}\tan \dfrac {6\pi } {13}$ $\tan \dfrac {9\pi } {13}\tan \dfrac {12\pi } {13}=-\tan \dfrac {25\pi } {13}\tan \dfrac {30\pi } {13}$ $\tan \dfrac {12\pi } {13}\tan \dfrac {16\pi } {13}=-\tan \dfrac {10\pi } {13}\tan \dfrac {12\pi } {13}$ $\tan \dfrac {15\pi } {13}\tan \dfrac {20\pi } {13}=-\tan \dfrac {20\pi } {13}\tan \dfrac {24\pi } {13}$ $\tan \dfrac {18\pi } {13}\tan \dfrac {24\pi } {13}=-\tan \dfrac {15\pi } {13}\tan \dfrac {18\pi } {13}$ while the second column is self-vanishing: $\tan \dfrac {2\pi } {13}\tan \dfrac {3\pi } {13}=-\tan \dfrac {10\pi } {13}\tan \dfrac {15\pi } {13}$ $\tan \dfrac {4\pi } {13}\tan \dfrac {6\pi } {13}=-\tan \dfrac {6\pi } {13}\tan \dfrac {9\pi } {13}$ $\tan \dfrac {8\pi } {13}\tan \dfrac {12\pi } {13}=-\tan \dfrac {12\pi } {13}\tan \dfrac {18\pi } {13}$ . So the equality occurs.
But how to generalize the proof?","['trigonometry', 'sequences-and-series']"
173470,Simple group of order $660$ is isomorphic to a subgroup of $A_{12}$,Prove that the simple group of order $660$ is isomorphic to a subgroup of the alternating group of degree $12$. I have managed to show that it must be isomorphic to a subgroup of $S_{12}$ (through a group action on the set of Sylow $11$-subgroups). Any suggestions are appreciated!,"['group-theory', 'abstract-algebra', 'simple-groups']"
173492,The minimum value of $(\frac{1}{x}-1)(\frac{1}{y}-1)(\frac{1}{z}-1)$ if $x+y+z=1$,"$x, y, z$ are three distinct positive reals such that $x+y+z=1$, then the minimum possible value of $(\frac{1}{x}-1) (\frac{1}{y}-1) (\frac{1}{z}-1)$ is ? The options are: $1,4,8$ or $16$ Approach: $$\begin{align*}
\left(\frac{1}{x} -1\right)\left(\frac{1}{y}-1\right)\left(\frac{1}{z}-1\right)&=\frac{(1-x)(1-y)(1-z)}{xyz}\\
&=\frac{1-(x+y+z)+(xy+yz+zx)-xyz}{xyz}\\
&=\frac{1-1+(xy+yz+zx)-xyz}{xyz}\\
&=\frac{xy+yz+zx}{xyz} - 1
\end{align*}$$ Now by applying $AM≥HM$, I got the least value of $(xy+yz+zx)/xyz$ as $9$, so I got final answer as $8$. Is it correct?","['optimization', 'algebra-precalculus']"
173498,Simple Double Summation,"I've seen how nesting works with a simple $(i+j)$ but this problem below is tripping me up. It's either because of the multipliers or because they each start at zero but I get 60, and the answer I believe is 78. Not sure where I'm missing the last 18. $$\sum_{i=0}^2\sum_{j=0}^3(2i+3j)$$ For the inner sum, I come up with $18$ $((0+0) + (0+3) + (0+6) + (0+9))$ I plug that into the outer sum $((0+18) + (2+18) + (4+18))$ What am I doing wrong? This discrete math book is horribly short in it's explanation (it only speaks of double sums in product form) and it throws curve balls right off the bat. It doesn't do much to build confidence in the material. Thanks for the help and the place to vent!","['solution-verification', 'summation', 'algebra-precalculus', 'discrete-mathematics']"
173508,Solving for coefficients on a Laurent series,"I am having an issue with the following complex analysis problem. I am suppose to 
find the coefficients of $z^{-1}$, $z^{-2}$ and $z^{-3}$ in the  Laurent series for 
$\displaystyle \frac{1}{\sin z}$ around $z_0 = 0$ which is valid for $2\pi < |z| < 3\pi$. One way I thought of doing it was to say 
$$ \frac{1}{\sin z} = \frac{1}{(z - 2\pi)(z - 3\pi)}\frac{(z - 2\pi)(z - 3\pi)}{\sin z} $$ Let $H(z) = \displaystyle \frac{(z - 2\pi)(z - 3\pi)}{\sin z} $.
Then we have 
$$ \frac{1}{\sin z} = H(z)\left[ \frac{A}{z - 2\pi} - \frac{B}{z - 3\pi} \right]
	= H(z)\left[ \sum_{k = 0}^\infty \frac{A(2\pi)^k}{z^{k + 1}} 
		+ \sum_{k = 0}^\infty \frac{Bz^k}{(3\pi)^{k + 1}} \right]. $$
This seems to get me part of the way of where i need to go, but leaves me having
to find a series that works for $H(z)$. I was going to continue in this way, but I though
that perhaps it was giving me an entire series, and the problem seems to be suggesting
to only solve for 3 of the coefficients. Another way to solve for the coefficients is 
$\displaystyle a_k = \frac{1}{2\pi i} \int_\gamma \frac{f(w)}{(w - z_0)^{k + 1}} dw$, where $\gamma$ is a
circle, of say radius $R$, that is in the annulus. I tried to do this just for $a_{-1}$ and I got the following
$$ \int_0^{2\pi} \frac{Rie^{it}}{\sin(Re^{it})} dt = \int_{u(0)}^{u(2\pi)} \frac{1}{\sin(u)} du $$
where $u = Re^{it}$, so $u(0) = R$ and $u(2\pi) = R$. Thus I'm integrating from 
$R$ to $R$, so $a_{-1} = 0$. However the $u$ substitution seems like something went wrong. I am not even sure if I can
actually do a $u$ substitution like that, but I can't see how to solve the integral any other way. I am not sure what direction to go with this problem, and it seems like I am making it a lot
harder than it is suppose to be. Can anyone give me some direction on it? Should I be attempting to solve the integrals, or do something like I was at the beginning?",['complex-analysis']
173521,Examples of stable curves $g\geq 2$?,"I'd like to get my hands on some simple examples of families of stable curves.  Ideally these would come in the form of a projective curve $C$ over a 1 dimensional base $B$, say $B = \mathbb{A}^1$.  The generic fiber would be smooth and the special fiber would be nodal. For genus 0 there is the nice example of the closure in $\mathbb{P}^2_{\mathbb{A}^1}$ of Spec $k[x,y,t]/(xy - t)$ where $t$ is the coordinate on $\mathbb{A}^1$. For genus 1 there is the closure in $\mathbb{P}^2_{\mathbb{A}^1}$ of Spec $k[x,y,t]/(y^2 = x(x-t)(x+1))$. I know for genus $2$ you can't expect to have an example in $\mathbb{P}^2_{\mathbb{A}^1}$ but what about something in $\mathbb{P}^3_{\mathbb{A}^1}$? Whenever $g = (d-1)(d-2)/2$ I would think you can get an example in $\mathbb{P}^2_{\mathbb{A}^1}$, is there anyway to control the number of nodes you get in the special fiber?","['plane-curves', 'algebraic-geometry', 'algebraic-curves']"
173527,Partial Derivative Question,"I am given with the function: $ f(x,y) = \frac{y\ln(1+x^2 + ay^2) } {x^2 + 2y^2} $ when $ (x,y)\neq (0,0)$, and $f(0,0)=0$ . There is another given data; $ f_y (0,0) = 2 $ . 
What is the value of $a$ ? I've tried computing the limit $  \frac{f(0,h)- f(0,0)}{h} $ , but it seems like it's always zero, contradicting the fact that $f_y(0,0)=2 $ ! Can someone help me understand my mistake? Thanks !",['multivariable-calculus']
173533,Is periodic extension of Lipschitz function Lipschitz?,"Let $f: [0,T] \rightarrow \mathbb{R}$, where $T>0$, be a Lipschitz with constant $K$ and $f(0)=f(T)$. 
Let us define $g(x)=f(x)$ for $x \in [0,T]$ and $g(x+T)=g(x)$ for $x \in \mathbb{R}$. Does $g$ satisfies $$|g(x)-g(y)| \leq K |x-y|$$ for $x,y \in \mathbb{R}$? It is clear that we may assume that $x<y$. When $|x-y| \geq T$ then there are $n,m\in N$ such that  $x-mT, y-nT\in [0,T]$ and $|g(x)-g(y)|=|f(x-mT)-f(y-nT)| \leq K \cdot T \leq K|x-y|$.
When $|x-y|<T$ and, for some integer $n$, is $x,y \in [nT, (n+1)T]$ we have $|g(x)-g(y)|=|f(x-nT)-f(y-nT)|\leq K |x-y|$. It remains the case when  $|x-y| <T$ and, for some integer $n$, is  $x\in [nT,(n+1)T]$,  $y\in [(n+1)T, (n+2)T]$.",['analysis']
173535,continuous function from $D\setminus \{0\}$ to subset of $\mathbb{R}$,"a) is not true as $\mathbb{Z}$ is not dense in $\mathbb{R}$. b) is not correct as inverse image of a closed set is going to be open set. c) is not true as $f(D\setminus\{0\})$=is not a connected set. Is my logics are correct against a,b,c? Please help.",['general-topology']
173556,Limit of sets and the interchange of limit and integral,"Suppose I have a collection of subsets, $\{ A_i \}_{i \ge 1}$, all of which are subsets of some set $S$. Suppose I have a measure on subsets of $S$: a non-negative function $f$ of the form $f(A)=\sum_{a \in A} g(a)$ where $g$ in non-negative. $f$ can attain infinity, but $g$ can't. If $f(A_i)$ is monotone increasing, what is the relationship between $\lim f(A_i)$ and $f(\limsup A_i), f(\liminf A_i)$? What about the case where $\lim A_i$ exists?","['measure-theory', 'real-analysis']"
173560,Adjoint of the infinitesimal generator of a stochastic process,"I need help seeing that 
$$
\mathcal{L}^* g = -\frac{\partial (bg)}{\partial x} + \frac{1}{2}\frac{\partial^2(\sigma^2g)}{\partial x^2}
$$
is the adjoint operator of
$$
\mathcal{L} = b\frac{\partial f}{\partial x} + \frac{1}{2}\sigma\frac{\partial ^2 f}{\partial x^2}
$$
in the $L^2$ sense $\langle \mathcal{L}f,g\rangle = \langle f,\mathcal{L}^*g\rangle$, where $b(x)$ and $\sigma(x)$ are some suitable functions.
Doing the computations I arrive to 
$$
\eqalign{
\langle \mathcal{L}f,g\rangle &= \int_{\mathbb{R}} \left(b\frac{\partial f}{\partial x} + \frac{1}{2}\sigma\frac{\partial ^2 f}{\partial x^2}\right)g dx
= \cdots\text{by parts x2} \cr 
&= \int_{\mathbb{R}}f\left(-\frac{\partial (bg)}{\partial x} + \frac{1}{2}\frac{\partial^2(\sigma^2g)}{\partial x^2}\right)dx + 
 \left[ bfg + \frac{1}{2}\sigma^2g\frac{\partial f}{\partial x} - \frac{1}{2}\frac{\partial(\sigma^2g)}{\partial x^2}f\right]_{-\infty}^{+\infty}\ .
}
$$
So basically I need help understanding in what circumstances
$$
\left[ bfg + \frac{1}{2}\sigma^2g\frac{\partial f}{\partial x} - \frac{1}{2}\frac{\partial(\sigma^2g)}{\partial x^2}f\right]_{-\infty}^{+\infty} = 0
$$
so that $\mathcal{L}^*$ is the adjoint of $\mathcal{L}$. (Reference Robert V.Kohn ch1 pg 14 .)","['operator-theory', 'calculus', 'functional-analysis', 'partial-differential-equations']"
173562,Factorise the determinant $\det\Bigl(\begin{smallmatrix} a^3+a^2 & a & 1 \\ b^3+b^2 & b & 1 \\ c^3+c^2 & c &1\end{smallmatrix}\Bigr)$,Factorise the determinant $\det\begin{pmatrix} a^3+a^2 & a & 1 \\ b^3+b^2 & b & 1 \\ c^3+c^2 & c &1\end{pmatrix}$. My textbook only provides two simple examples. Really have no idea how to do this type of questions..,"['linear-algebra', 'determinant']"
173565,Group of order $60$,"[NBHM_2006_PhD screening test_Algebra] Let $G$ be a group of order $60$, pick out the true statements: a. $G$ is abelian b. $G$ has a subgroup of order $30$. c. $G$ has subgroups of order $2$, $3$, and $5$. d. $G$ has subgroups of order $6$, $10$, and $15$. My Attempt: a is false because $A_5$ is an non abelian group of order $60$. For  b,c,d I have no idea.if $G$ was abelian then $c$ is correct by cauchy theorem .","['group-theory', 'abstract-algebra']"
173571,"Compute integral $\int_{-6}^6 \! \frac{(4e^{2x} + 2)^2}{e^{2x}} \, \mathrm{d} x$","I want to solve $\int_{-6}^6 \! \frac{(4e^{2x} + 2)^2}{e^{2x}} \, \mathrm{d} x$ but I get the wrong results: $$
\int_{-6}^6 \! \frac{(4e^{2x} + 2)^2}{e^{2x}} \, \mathrm{d} x = 
\int_{-6}^6 \! \frac{16e^{4x} + 16e^{2x} + 4}{e^{2x}} \, \mathrm{d} x
$$ $$
= \left[ \frac{(4e^{4x} + 8e^{2x} + 4x)2}{e^{2x}} \right]_{-6}^6 =
\left[ \frac{8e^{4x} + 16e^{2x} + 8x}{e^{2x}} \right]_{-6}^6
$$ $$
= (\frac{8e^{24} + 16e^{12} + 48}{e^{12}}) - (\frac{8e^{-24} + 16e^{-12} - 48}{e^{-12}})
$$ $$
= e^{-12}(8e^{24} + 16e^{12} + 48) - e^{12}(8e^{-24} + 16e^{-12} - 48)
$$ $$
= 8e^{12} + 16 + 48e^{-12} - (8e^{-12} + 16 - 48e^{12})
$$ $$
= 8e^{12} + 16 + 48e^{-12} - 8e^{-12} - 16 + 48e^{12})
$$ $$
= 56e^{12} + 56e^{-12}
$$ Where am I going wrong?","['definite-integrals', 'calculus', 'integration']"
173582,How to prove the function $y = \sin x$ is not a closed function? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I came across a question: Suppose that $f(x) = \sin x$ is a function from $\mathbb R$ to $[-1,1]$. How do I prove the function $f(x) = \sin x$ is not a closed function? By ""closed function"", I mean a function such that the image of any closed set is closed.","['general-topology', 'closed-map', 'functions']"
173590,Sufficient condition for convergence of a real sequence [duplicate],"This question already has answers here : Every subsequence of $x_n$ has a further subsequence which converges to $x$. Then the sequence $x_n$ converges to $x$. (4 answers) Closed 6 years ago . Let $(x_n)$ be a sequence of real numbers. Prove that if there exists $x$ such that every subsequence $(x_{n_k})$ of $(x_n)$ has a convergent (sub-)subsequence $(x_{n_{k_l}})$ to $x$, then the original sequence $(x_n)$ itself converges to $x$ . Thanks for any help.","['convergence-divergence', 'sequences-and-series', 'real-analysis', 'limits']"
173594,Uniform boundedness principle statement,"Consider the uniform boundedness principle: UBP . Let $E$ and $F$ be two Banach spaces and let $(T_i)_{i \in I}$ be a family (not necessarily countable) of continuous linear operators from $E$ into $F$. Assume that $\sup_{i \in I} \|T_ix \| < \infty$ for all $x \in E$. Then $\sup_{i \in I} \|T_i\|_{\mathcal{L}(E,F)} < \infty$. I don't understand the statement of the UBP. The assumption tells us that, fixed an element $u$, we surely find a $\|T_ku\|< \infty$ (in particular, for that fixed $u$ each other $T$ is limited in $u$ too). The conclusion tells us that the sup over the $i$'s of the set
$$
\biggl\{ \sup_{\|x\|\leq 1} \|Tx\| \biggr\}
$$ 
is limited . But isn't that clear from the assumption? I mean, if each $T$ is bounded, a fortiori the conclusion must hold... please explain me where I am wrong.","['operator-theory', 'functional-analysis', 'banach-spaces']"
173601,A number of SVD components; understanding the relation,"Related to my work is the concept of Singular Value Decomposition (SVD). Namely, given some matrix $B\in\mathbb{R}^{n\times m}$, $n\geq m$, SVD can be written as
$$B=U\Sigma V^T,$$
where $U\in\mathbb{R}^{n\times n}$ ($n$ left-singular vectors), $\Sigma \in\mathbb{R}^{n\times m}$ (matrix with $m$ singular values on its diagonal), and $V\in\mathbb{R}^{m\times m}$ ($m$ right-singular vectors). So, how I see it, given that there are $m$ singular values, only right-singular vectors and $m$ first left-singular vectors have the asociated singular value? To which singular value do the rest of left-singular vectors correspond to? In case one complements $\Sigma$ to contain zero singular values such that $\Sigma\in\mathbb{R}^{n\times n}$, then $V^T$ needs also to be complemented to be a $V^T\in\mathbb{R}^{n\times m}$ matrix. But, that would imply that a vector of all zeros is also a right-singular vector. Could someone clarify this? Furthermore, suppose that the rank of matrix $B$ is $c$, $c<m\leq n$. Does this imply that $B$ has only $d$ left- and right-singular vectors?","['matrices', 'linear-algebra']"
173603,closed-form expressions for product of 3n+k where k = 1 or 2,"There are some easy products that can be written in closed form in terms of factorials: $ 2 \times 4  \times 6 \times ... 2n = n! \times 2^n$ $ 1 \times 3  \times 5 \times ... (2n-1) = {{(2n)!} \over  {n! \times 2^n}}$ $ 3 \times 6  \times 9 \times ... 3n = n! \times 3^n$ But what about these? $ f_2(n) = 2 \times 5 \times 8 \times ... (3n+2)$ $ f_1(n) = 1 \times 4 \times 7 \times ... (3n+1)$ Wolfram Alpha gives some expressions for partial products in terms of gamma functions, but is there any way to use factorials instead?","['factorial', 'sequences-and-series', 'products']"
173627,Nullstellensatz for polynomials generating the same hypersurface,"Let $X$ be an affine variety and $f,g\in \mathcal{O}(X)$ such that $\lbrace f=0\rbrace = \lbrace g= 0\rbrace$. How does it follow by the Nullstellensatz that $f^n = g^m$ for some $m,n\in \mathbb{N}$? This is claimed in a proof, but I don't see the reason. If it is not true in general, are there additional conditions under which the statement is true? Many thanks in advance!","['commutative-algebra', 'algebraic-geometry']"
173628,Number of Points on the Jacobian of a Hyperelliptic Curve,Consider a genus 2 hyperelliptic curve $X$ over a finite field $\mathbb{F}_{p^{k}}$ for $k \leq 4$. Let $J$ be the Jacobian of $X$. Is there a relation between the zeta function of $X/\mathbb{F}_{p^{k}}$ and $\#J(\mathbb{F}_{p^{k}})$?,"['algebraic-geometry', 'algebraic-curves']"
173636,Putnam Problem: Partitioning integers with generating functions,"We were given the following A-1 problem from the 2003 Putnam Competition: Let $n$ be a fixed positive integer. How many ways are there to write $n$ as a sum of positive integers, $$ n= a_1+a_2+ \cdots + a_k$$
With $k$ an arbitrary positive integer, and $a_1 \le a_2 \le \cdots \le a_k \le a_1+1$. For example, with $n=4$ there are 4 ways: 2, 2+2, 1+1+2, 1+1+1+1. I managed to do this by induction, showing that there are always $n$ ways to partition an integer in such a way. In my combinatorics class however, we always solved integer partitioning problems with generating functions and I have been unable to construct one for this problem. I was wondering if the math.stackexchange community could help me out with this and at least give me a nudge in the right direction. Thanks","['integer-partitions', 'generating-functions', 'contest-math', 'combinatorics']"
173639,Properties for a matrix being invariant under rotation?,"Consider a 2D case. 
Let $R$ be a rotation matrix with angle $\theta$
$$R = \begin{bmatrix}
\cos\theta & -\sin\theta\\
\sin\theta & \cos\theta
\end{bmatrix}.$$ Is it possible for a matrix $A$ to satisfy the following identity for any $\theta$
$$A = R A R^T?$$",['linear-algebra']
173670,"A transform function from $(−∞,∞)$ to $(0,1)$?","I want to convert an integral from $(0, 1)$ range to $(-\infty, \infty)$ range by change of variable. What is the best transform function to do this - one that is simple, monotonic with $f(-\infty)=0$ and $f(\infty)=1$? Thanks.","['calculus', 'functions']"
173687,Stalk of a pushforward sheaf in algebraic geometry,"Excuse me if this is a naive question. Let $f : X \to Y$ be a morphism of varieties over a field $k$ and $\mathcal{F}$ a quasi-coherent sheaf on $X$. I know that for general sheaves on spaces not much can be said about the stalk $(f_*\mathcal{F})_y$ at $y \in Y$ (let's just talk about closed points), but does anything nice happen in this situation? If $f$ is proper then the completion of the stalk is described by the formal function theorem, but I'm interested in the honest stalk. Suppose, for instance, that $X = \text{Spec } A$ is affine (so $\mathcal{F} = \widetilde{M}$ for some $A$-module $M$) and that the scheme-theoretic fiber of $f$ over the closed point $y \in Y$ is reduced. Write this fiber as a union of irreducible components $Z_1 \cup \cdots \cup Z_r$ corresponding to prime ideals $\mathfrak{p}_1,\cdots,\mathfrak{p}_r \subset A$, so there is an associated semi-local ring $S^{-1}A$ with $S = A \setminus (\mathfrak{p}_1 \cup \cdots \cup \mathfrak{p}_r)$. Hopefully here $(f_*\mathcal{F})_y$ is just $S^{-1}M$ regarded as an $\mathcal{O}_{Y,y}$-module via the natural map $\mathcal{O}_{Y,y} \to S^{-1}A$. Does this make sense? Is something like this true when $X$ is not affine and/or the fiber is nonreduced? Edit: As Georges's answer shows, this cannot possibly be true in general. I wonder if there is still hope when $f$ is proper? My example in the comments below (the squaring map $\mathbb{A}^1 \to \mathbb{A}^1$ with $\mathcal{F} = \mathcal{O}$ and $y = 1$) is actually consistent with my guess above: $(f_*\mathcal{F})_y$ is the localization of $k[t]$ at $k[t^2] \setminus (t^2-1)k[t^2]$. It is not hard to see that this coincides with the localization at $k[t] \setminus ((t-1) \cup (t+1))$, i.e. the semilocal ring at $\{ \pm 1 \}$.","['quasicoherent-sheaves', 'algebraic-geometry']"
173694,$e^x(\ln x-c) =\sum \limits_{k=0}^\infty \frac{ x^{k} \Gamma'(k+1)}{ (k!)^2}$ Is  it correct result?,"$e^x=\sum \limits_{k=0}^\infty \frac{x^k}{k!}$ We can write $e^x=\sum \limits_{k=0}^\infty \frac{x^k}{ \Gamma(k+1)}$ Where $\Gamma(x)$ is Gamma function $\Gamma(k+1)=k\Gamma(k)$ $\frac{\Gamma(k+1)}{\Gamma(k)}=k$ $\frac{\Gamma(1)}{\Gamma(0)}=0$ $\frac{1}{\Gamma(0)}=0$ $\frac{\Gamma(-1+1)}{\Gamma(-1)}=\frac{\Gamma(0)}{\Gamma(-1)}=-1$ $\frac{1}{\Gamma(-1)}=\frac{-1}{\Gamma(0)}=-1.\frac{1}{\Gamma(0)}=0$ If we continue in that way, we get result for  $m $ is non-positive integer, $\frac{1}{\Gamma(m)}=0$ Thus we can write $e^x=\sum \limits_{k=-\infty}^\infty \frac{x^k}{ \Gamma(k+1)}$ Then we extended $e^x$ for n is integer 
(Equation 1): $$e^x=\sum \limits_{k=-\infty}^\infty \frac{x^{k+n}}{ \Gamma(k+n+1)}$$ $n \in Z $ {...,-2,-1,0,1,2,...} It is possible to extend the defination to  $z \in C$. $f(x)=\sum \limits_{k=-\infty}^\infty \frac{x^{k+z}}{ \Gamma(k+1+z)}$ $$\frac{d(f(x))}{dx}=\frac{d}{dx}(\sum \limits_{k=-\infty}^\infty \frac{x^{k+z}}{ \Gamma(k+1+z)})= \sum \limits_{k=-\infty}^\infty (k+z)\frac{x^{k+z-1}}{ (k+z)\Gamma(k+z)}= \sum \limits_{k=-\infty}^\infty \frac{x^{k+z-1}}{ \Gamma(k+z)}=\sum \limits_{k=-\infty}^\infty \frac{x^{k+z}}{ \Gamma(k+1+z)}=f(x)$$ $$\frac{d(f(x))}{dx}=f(x)$$ $$f(x)=c(z)e^x$$ $c(z)e^x=\sum \limits_{k=-\infty}^\infty \frac{x^{k+z}}{ \Gamma(k+1+z)}$
According to Equation 1,  $c(z) = 1$ for $z \in Z$ but  I noticed I need to  find what is $c(z)$  for $z \in C$. (Thanks to Norbert for his contribution) After that we can find the result: $$\frac{\partial(c(z)e^x)}{\partial z}=\sum \limits_{k=-\infty}^\infty \frac{\partial}{\partial z}(\frac{x^{k+z}}{ \Gamma(k+1+z)})$$ $$c'(z)e^x=\sum \limits_{k=-\infty}^\infty \frac{\partial}{\partial z}(\frac{x^{k+z}}{ \Gamma(k+1+z)})$$ $$c'(z)e^x=\sum \limits_{k=-\infty}^\infty (\frac{\ln x . x^{k+z}}{ \Gamma(k+1+z)})-\sum \limits_{k=-\infty}^\infty (\Gamma'(k+1+z)\frac{ x^{k+z}}{ \Gamma^2(k+1+z)})$$ $$c'(z)e^x=\ln x \sum \limits_{k=-\infty}^\infty (\frac{ x^{k+z}}{ \Gamma(k+1+z)})-\sum \limits_{k=-\infty}^\infty (\Gamma'(k+1+z)\frac{ x^{k+z}}{ \Gamma^2(k+1+z)})$$ $$e^x(c(z)\ln x-c'(z)) =\sum \limits_{k=-\infty}^\infty (\frac{ x^{k+z} \Gamma'(k+1+z)}{ \Gamma^2(k+1+z)})$$ If we take $z=0$, we get an interesting result. $$e^x(c(0)\ln x -c'(0)) =\sum \limits_{k=0}^\infty \frac{ x^{k} \Gamma'(k+1)}{ (k!)^2}$$ $c(0)=1$ according to Equation 1 Thus $$e^x(\ln x -c'(0)) =\sum \limits_{k=0}^\infty \frac{ x^{k} \Gamma'(k+1)}{ (k!)^2}$$
I do not know what $c'(0) is$. Acoording to Norbert's answer. $c'(0) \approx -0.596347$ I have not seen that result in other place. Is it known result?Please let me know if my results are correct or not. Can we extend all such functions that include $\Gamma(x)$ in  denominator? Thanks for advice","['special-functions', 'sequences-and-series']"
173702,Projective and injective modules; direct sums and products,"I need two counterexamples. First, a direct sum of $R$-modules is projective iff each one is projective.
 But I need an example to show that, “an arbitrary direct product of projective modules need not be a projective module.” If I let $R= \mathbb Z$  then $\mathbb Z$ is a projective $R$-module, but the direct product $\mathbb Z \times \mathbb Z \times \cdots$ is not free, hence it is not a projective module. We have a theorem which says that every free module over a ring $R$ is projective. Am I correct? Second, a direct product of $R$-modules is injective iff each one is injective 
but I need an example to show that the direct sum of injective modules need not be injective.","['modules', 'abstract-algebra']"
173708,an integer sum of products of tangents,"This question arose from my initial attempts at answering this question . I later found a way to transform the desired sum into a sum of squares of tangents, but before I did, I found numerically that apparently $$
\sum_{l=1}^n\tan\frac{jl\pi}{2n+1}\tan\frac{kl\pi}{2n+1}=m_{jkn}(2n+1)
$$ with integer factors $m_{jkn}$, for which I haven't been able to find an explanation. If $j$ or $k$ is coprime to $2n+1$, we can sum over $jl$ or $kl$ instead, so most cases (in particular all for $2n+1$ prime) can be reduced to the case $j=1$. Here are the numerically determined factors $m_{1kn}$ for $n\le18$ (with $n$ increasing downward and $k$ increasing to the right): $$
\begin{array}{r|rr}
&1&2&3&4&5&6&7&8&9&10&11&12&13&14&15&16&17&18\\\hline1&1\\
2&2&0\\
3&3&-1&1\\
4&4&0&1&0\\
5&5&-1&1&1&1\\
6&6&0&2&-2&0&0\\
7&7&-1&2&-1&1&0&1\\
8&8&0&2&0&2&2&2&0\\
9&9&-1&3&1&1&-3&1&-1&1\\
10&10&0&3&-2&2&-1&1&0&1&0\\
11&11&-1&3&-1&1&-1&1&3&-1&1&1\\
12&12&0&4&0&2&0&0&-4&0&0&0&0\\
13&13&-1&4&1&3&0&1&-1&1&1&3&0&1\\
14&14&0&4&-2&2&2&2&0&2&4&0&0&2&0\\
15&15&-1&5&-1&3&-3&3&-1&3&-5&1&1&1&-1&1\\
16&16&0&5&0&2&-1&2&0&1&-2&1&1&-2&-2&1&0\\
17&17&-1&5&1&3&-1&2&-1&1&-1&1&5&1&0&1&1&1\\
18&18&0&6&-2&4&0&2&0&2&-2&2&-6&0&0&4&2&0&0\\
\end{array}
$$ (See also the table in this answer to the other question, which shows the case $j=k+1$; in that case the rows of the table sum to $0$ because of the identity that's the subject of the other question.) The values $m_{11n}=n$ reflect the sum of squares of tangents that I determined in my answer to the other question. I have no explanation for the remaining values. I've tried using the product formula for the tangent; multiplying by a third tangent to use the triple tangent product formula; and finding a polynomial whose roots are the products being summed; but none of that worked out. This vaguely reminds me of character theory; the values $\tan\frac{kl\pi}{2n+1}$ for fixed $k$ are like characters, and their dot products are integer multiples of the ""group order"" $2n+1$; though if they were characters the dot products couldn't be negative. I'd appreciate any insight into this phenomenon, and of course ideally a way to calculate the $m_{jkn}$. [ Update: ] I've verified the periodicities that Brian observed in comments up to $n=250$: $$m_{1,k,n+k} = m_{1kn}+[k \text{ odd}]\;,$$ $$m_{1,k+4d+2,k+4d+2+d}=m_{1,k,k+d}\;,$$ where the bracket is the Iverson bracket .","['trigonometry', 'sequences-and-series']"
173716,Independent events and Dependent events,"I have a question regarding these strikingly similar problems with contradicting solutions. This is somewhat long, so prepare Probblem 1 Consider a bag of ten coins, nine are fair, but one is weighted with both sides heads. You randomly select a coin and toss it five times. Let $2s$ denote the event of selecting the weighted coin (that is the 2-sided coin) and $N$ be the even you select a regular coin and $5H$ be the event of getting five heads in a row. What is a) $P(5H | 2s)$ b) $P(5H | N)$ c) $P(5H)$ d) $P(2s | 5H)$ Solution 1 a) Simply 1 b) $\frac{1}{2^5}$ c) $\frac{1}{2^5}\frac{9}{10}+ \frac{1}{10} = \frac{41}{320}$ d) $P(2s|5H) = \dfrac{P(5H|2s)P(2s)}{P(5H)} = \frac{32}{41}$ From the Solution 1 , it seems that $P(2s|5H) \neq P(2s)P(5H)$ That is the event of picking out the weighted coin affects the probability of getting 5H. Here is part of my question, isn't there also some tiny probability of getting 5H from picking the normal one as well? Doesn't make sense why the events of picking the coin and getting 5H is dependent . Read on the next question Problem 2 A diagnostic test for an eye disease is 88% accurate of the time and 2.4% of the population actually has the disease. Let $ED$ be the event of having the eye disease and $p$ be the event of testing positive. Find the probability that a) the patient tests positive b) the patient has the disease and tests positive Solution 2 Here is a tree diagram a) $0.02122 + 0.011712 = 0.13824$ b) $P(ED | p) = \dfrac{P(\text{ED and p})}{P(p)} =\frac{0.02122}{0.13824 }= 0.1535$ From Solution 2 , it looks like $P(\text{ED and  p}) = P(\text{ED})P(p)$ which means that having the eye disease and testing positive are independent events? After trying out the same formula from Problem 1 , it also seems that $$P(\text{ED | p}) = \dfrac{P(\text{ED and  p})}{P(p)} = \dfrac{P(\text{p | ED})P(ED)}{P(p)} =  0.1535$$ Also, when the question asks ""the patient has the disease and tests positive"", how do I know that it is $P(ED | p)$ and not $P(p | ED)$? I am very confused in general with this. Could anyone clarify for me? Thanks",['probability']
173725,A free group on the non-empty set $X$ is solvable iff $|X| =1$,"Let $X$ be a non-empty set. Prove that $F_X$, the free group on $X$ is solvable if and only if $|X| = 1$. We can see that if $|X| = 1$, then $F_X$ is abelian, and hence solvable. However, the other direction stumps me. Any suggestions?","['free-groups', 'group-theory', 'abstract-algebra']"
173730,Elements of $\mathbb{F}_p$ having cube roots in $\mathbb{F}_p$ [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Let $p$ be a prime number, and let $\mathbb{F}_p$ be the field with $p$ elements. How many elements of $\mathbb{F}_p$ have cube roots in $\mathbb{F}_p$? I had this question on an exam and after reviewing I am still not sure. Any help would be appreciated.","['finite-fields', 'elementary-number-theory', 'number-theory']"
173737,Two questions from Dixmier's book on Von Neumann algebras,"It seems something is going wrong with the preview I linked in some of my previous questions, so I will just type out the question.  I am having trouble with Dixmier's proof of Corollary 5 on p. 46.  That one states ""Let $A$ be a Von Neumann Algebra, and $m$ a two-sided ideal of A, and $\bar m$ its weak closure.  For each $T \in (\bar m)^+$ there exists an increasing [net] $F \subset m^+$ such that $T$ is the supremum of $F$.""  He then proves it as follows: ""Let $(T_i)_{i \in I}$ be a maximal family of non-zero operators of $m^+$ such that $\sum_{i \in J} T_i \leq T$ for every finite subset $J$ of $I$.  The operators $\sum_{i \in J} T_i \leq T$ form an increasing [net in $m^+$] whose supremum $S$ is an element of $(\bar m )^+$ majorized by $T$.  Let $R=T-S \in (\bar m)^+$.  As $A \in m$ converges weakly to the greatest projection $E$ of $\bar m$, $R^{1/2}AR^{1/2}$ converges weakly to $R^{1/2}ER^{1/2}=R$; hence if $R \neq 0$, we have $R^{1/2}AR^{1/2}\neq 0$ for some $A \in m$, hence for some $A \in m^+$, such that $0 \leq A \leq I$.  But we then have $R^{1/2}AR^{1/2}\leq R$, $R^{1/2}AR^{1/2} \in m^+$ and this contradicts the maximality of the family $(T_i)_{i \in I}$.  Hence $R=0$."" Everything here is fine in my book until he speaks at the very end as if the $R^{1/2}AR^{1/2}$ he furnishes is not redundant with any of the $T_i$.  That is where I don't understand why this proof works. Another question I have is on the first page of Chapter 4.  Let $A$ be a *-algebra of operators on $H$.  He says that all positive linear functionals on $A$ $\phi$ (not necessarily norm continuous) turn out to be norm continuous, with norm $\phi(I)$  He argues for this using the following string of inequalities.  I disagree with the second inequality: $|\phi(T)|^2 \leq \phi(I)\phi(T^*T) \leq \phi(I)^2 ||T^*T||=\phi(I)^2||T||^2$. Can you explain why the second inequality holds?","['operator-algebras', 'von-neumann-algebras', 'operator-theory', 'analysis']"
173745,Separability of a product metric space,"I am trying to prove the following: 'If $(X_1,d_1)$ and $(X_2,d_2)$ are separable metric spaces (that is, they have a countable dense subset), then the product metric space $X_1 \times X_2$ is separable.'  It seems pretty straightforward, but I would really appreciate it if someone could verify that my proof works. Since $(X_1,d_1)$ and $(X_2,d_2)$ are separable, they each contain a countable dense subspace, say $D_1 \subset X_1$ and $D_2 \subset X_2$.  We will show that $D_1 \times D_2 \subset X_1 \times X_2$ is dense and countable.  First, $D_1 \times D_2$ is countable since both $D_1$ and $D_2$ are. Now let $x=(x_1,x_2) \in X_1 \times X_2$ and let $d$ be the product metric on $X_1 \times X_2$ (given by $d(x,y)=(\displaystyle\sum_{i=1}^2 d_i(x_i,y_i)^2)^{1/2}$).  We will show that every open ball $B_d(x,\varepsilon)$ containing $x=(x_1,x_2)$ also contains a distinct point of $D_1 \times D_2$.  Let $a_1 \in B_{d_1}(x_1,\frac{\sqrt{2}}{2}\varepsilon)\cap D_1$ and let $a_2 \in B_{d_2}(x_2,\frac{\sqrt{2}}{2}\varepsilon)\cap D_2$ (such points exist because $D_1$ and $D_2$ are dense in $X_1$ and $X_2$, respectively.)  Letting $a=(a_1,a_2)$, we then have $d(x,a)=(\displaystyle\sum_{i=1}^2 d_i(x_i,a_i)^2)^{1/2})=(d_1(x_1,a_1)^2 + d_2(x_2,a_2)^2)^{1/2} < ((\frac{\sqrt{2}}{2}\varepsilon)^2 + (\frac{\sqrt{2}}{2}\varepsilon)^2)^{1/2}=\varepsilon$, so we have that $a \in B_d(x,\varepsilon)$, so $D_1 \times D_2$ is dense in $X_1 \times X_2$.  Then since $D_1 \times D_2 \subset X_1 \times X_2$ is a countable dense subspace of $X_1 \times X_2$, we have that $X_1 \times X_2$ is separable. I can see how this would easily generalize to finite products, but does it also extend to countable products?","['general-topology', 'separable-spaces', 'metric-spaces', 'product-space']"
173746,morphism from a local ring of a scheme to the scheme,"Let $X$ be a scheme, and $x \in X.$ Let $U=\text{Spec}(A)$ be an open affine subset containing $x,$ then we have the natural morphism $\mathcal{O}_X(U) \to \mathcal{O}_{X,x}$ inducing a morphism $ \text{Spec} \;\mathcal{O}_{X,x} \to U$ and by composing it with the open immersion $U \hookrightarrow X$ we get a morphism $f: \text{Spec} \;\mathcal{O}_{X,x} \to X.$ Why this definition does not depend on the choice of $U?$ and What is the image of $f?$","['algebraic-geometry', 'schemes']"
