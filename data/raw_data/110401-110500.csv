question_id,title,body,tags
1591040,One-parameter subgroups and Lie bracket,"Suppose that $G$ is a Lie group. It is easy to prove that given $X \in Lie(G)$ there exists a unique one-parameter subgroup $\phi_X : \mathbb{R} \to G$ such that $\dot{\phi}(0)=X$. My question is: given $X,Y \in Lie(G)$, is it possible to describe the one-parameter subgroup $\phi_{[X,Y]}$ in function of $\phi_X$ and $\phi_Y$?","['differential-geometry', 'lie-algebras', 'lie-groups']"
1591042,Computing tangent space,"Let
$$Sl_2(\mathbb{R})=\{M\in\mathcal{M}\mid\det M=1\}$$
after showing that this is a 3-smooth manifold, I have been told to compute the tangent space to this manifold at the point
$$p=\left(\begin{matrix}1&1\\0&1\end{matrix}\right)$$
I am not sure what to do here, I don't know what does it mean to ""compute the tangent space"", it's a 3 dimensional real vector space so it's $\mathbb{R}^3$, but I don't think this is what I have to do.","['smooth-manifolds', 'differential-geometry']"
1591064,"What is the ""module of twisted global sections""?","Let $X$ be a projective variety. Suppose we have computed the graded modules corresponding to $\Omega_{\mathbb P^n}$ (the cotangent sheaf) and $\mathcal O_X$. One way to get a representation for $\Omega_{\mathbb P^n} \otimes \mathcal O_X$ is to tensor the two corresponding modules. In section 3 of the paper ""Projective Geometry and Homological Algebra"" by Eisenbud, contained in this freely available book , the author objects, saying The result would represent the right sheaf, but would not be the
  module of twisted global sections of $\Omega_{\mathbb P^n}\otimes
 \mathcal O_X$ (the unique module of depth two representing the sheaf). I have never seen this terminology before. What is the ""module of twisted global sections,"" and what is the connection with depth? I suppose it is the module in the definition at the top of page 106 in Hartshorne (the ""graded $S$-module associated to $\mathcal F$"") but I have no idea how depth is relevant here. After that passage, Eisenbud uses the Euler exact sequence to compute a description for  $\Omega_{\mathbb P^n}$, and remarks that since this method produces a module with depth at least 2, we have found the module of twisted global sections. Again, I wonder about this depth statement.","['schemes', 'reference-request', 'projective-schemes', 'algebraic-geometry']"
1591066,Density In The Theorem/Proof of The Stone-Weierstrass Theorem,"Yet again, I have a question that I could use some help with. Note that almost everything can be found in C. Pugh's, Real Mathematical Analysis (soft-cover, 2nd Edition, ISBN: 978-1-4419-2941-9); furthermore, although it is a book-preview, what I'm about to refer to as well as question can (hopefully, as it did for me) be found here . My question concerns the very beginning of the proof of the Stone-Weierstrass Theorem in Pugh's book (proof of Theorem 19, PG. 224 in the actual book, or PG. 235 in the book-preview link above). The theorem from the text is restated below. Stone-Weierstrass Theorem: If $M$ is a compact metric space, and $\mathcal{A}$ is a function algebra in $C^{0}M$ that vanishes nowhere and separates points, then $\mathcal{A}$ is dense in $C^{0}M$ . As far as the definitions of a function algebra, the function algebra vanishing at a point $p\in M$ , as well as the function algebra separating points in $M$ , please see the link above (they are available in the preview for me, but I omitted them for the sake of saving space - I will gladly state them if need be). Moreover, for some compact metric space $M$ , $C^{0}M$ is shorthand notation for the set $C^{0}\big(M,\mathbb{R}\big)=\big\{ \phi~|~\phi:M\rightarrow\mathbb{R},~\phi\text{ is continuous on }M\big\}$ , i.e., $C^{0}M$ is the set of continuous, real-valued functions on the compact metric space $M$ . Now for my question. In the very beginning of Pugh's proof of the theorem above, we assume $\mathcal{A}\subset C^{0}M$ is a function algebra that vanishes nowhere and separates points (clearly),  Then, we show $\mathcal{A}$ is dense in $C^{0}M$ , to which the proof asserts that this can be shown by proving for any $F\in C^{0}M$ and any $\varepsilon>0$ , there exists a $G\in\mathcal{A}$ such that for all $x\in M$ we have $F(x)-\varepsilon<G(x)<F(x)+\varepsilon$ (equivalently, $\big|G(x)-F(x)\big|=\big|F(x)-G(x)\big|<\varepsilon$ ). Now, earlier in the book -- which isn't part of the book-preview for me, unfortunately (if it helps, the definition is on PG. 98 in Pugh's text) -- Pugh defines density of a set which is restated below (I added the ambient topological space part for reference purposes). Definition: Let $M$ be a metric (or topological) space. If $S\subset M$ and $\overline{S}=M$ , then $S$ is dense in $M$ . I've been trying to connect the statement at the beginning of the Stone-Weierstrass proof with this definition above. In other words, in the proof of the Stone-Weierstrass Theorem in Pugh's text, we need to show that $\overline{\mathcal{A}}=C^{0}M$ , correct? Furthermore, how does this translate to, or how do we connect this definition with, for any $F\in C^{0}M$ and any $\varepsilon>0$ , there exists a $G\in\mathcal{A}$ such that for all $x\in M$ we have $F(x)-\varepsilon<G(x)<F(x)+\varepsilon$ ? First I started working with the fact that (where this can be shown) $\lim\mathcal{A}=\overline{\mathcal{A}}$ where $\lim\mathcal{A}$ is the limit set of the function algebra $\mathcal{A}$ (i.e., the set of limit points of $\mathcal{A}$ ). Then, I recalled the example that $\mathbb{Q}$ is dense in $\mathbb{R}$ being equivalent to saying that for any pair of distinct real numbers $p<r\in\mathbb{R}$ , there exists a rational number $q\in\mathbb{Q}$ such that $p<q<r$ . I'm thinking that I'm on the right track by going from the example that $\mathbb{Q}$ is dense in $\mathbb{R}$ ; and the connection I'm trying to make is possibly similar to showing that $\mathbb{Q}$ is dense in $\mathbb{R}$ is equivalent to saying that for some $q\in\mathbb{Q}$ , $p<q<r$ whenever $p<r\in\mathbb{R}$ ...just in a more abstract scene? In sum, any help with making this connection will be greatly appreciated. I apologize that this is a bit lengthy but I wanted to be precise. As a personal remark, check out the proof, as it is pretty neat - especially how he finds a functions that supersolves the expression $F(x)-\varepsilon<G(x)<F(x)+\varepsilon$ .","['real-analysis', 'functional-analysis', 'approximation-theory', 'metric-spaces', 'analysis']"
1591069,A Scalar times the Zero Vector,"I'm reading Linear Algebra Done Right by Sheldon Axler and the proof given in the book is the same as the one in the answer provided for this question . I tried to solve this before looking at the solution and the way I did it was: Theorem: $a \cdot \vec0 = \vec 0 $ for every $a \in \mathbb F$ Proof $\ $Let $a \in \mathbb F$, then \begin{align}a \cdot \vec0    
&= a \cdot \langle 0_1,0_2, \ldots ,0_n\rangle \tag{Def. of a vector}\\
&= \langle a \cdot0_1,a \cdot0_2, \ldots ,a \cdot0_n \rangle \tag{Def. of Scalar Multiplication} \\
&= \langle 0_1,0_2,...,0_n \rangle \\
&= \vec 0
\end{align} Hence,  $a \cdot \vec0 = \vec 0 $ , desired result. Is there anything wrong with this proof? For example, I didn't explain why $a \cdot 0_j = 0$, do I have to do so? Also doesn't this proof provide more insight in terms of using basic definitions rather than just vector algebra?* Is there a way to proof this result besides this and the one given in the link?","['alternative-proof', 'linear-algebra', 'proof-verification', 'vector-spaces']"
1591071,prove\disprove if $f\circ g$ is invertible then $g\circ f$ is invertible,"The question is to prove\disprove that if $f\circ g$ is invertible then $g\circ f$ is invertible. $f:A\to B$, $g:B\to A$. (f,g are functions) I tried to prove it but always got stuck, so I began wondering it's a disapproval. To disprove I chose g as injective and non-surjective function, while f chosen to be surjective and non-injective. Thus, I get $f\circ g$ as invertible, however $g\circ f$ isn't a function and thus can't be invertible (as a disproof). Is it correct what I did here? would appreciate your notes.","['functions', 'proof-verification', 'proof-writing', 'logic', 'elementary-set-theory']"
1591081,Topological space in which the principal filters are the only filters that converge,"Let $(X, \mathcal{T})$ be a topological space in which only the principal filters converge. Show that $\mathcal{T}$ is the discrete topology. It is similar to one of my previous questions (link: Topological space in which every filter in which every filter converges to every point ), but it needs a different approach that I can't (yet) come up with. Definitions used (for the sake of consistency): A filter is a nonempty set $\mathcal{F}$ for which the following properties hold: $\mathcal{F}$ does not contain the empty set; for every  $F \in \mathcal{F}$ such that $F \subset G, G \in \mathcal{F}$ holds; for every $F \in \mathcal{F}$ and $G \in \mathcal{F} $ also $F \cap G \in \mathcal{F}$. A principal filter generated by a set $A \subset X$ is the set$\{F \subset X \vert A \subset F\}$. A filter $\mathcal{F}$ converges to $x \in X$ iff the neighbourhood filter of $x$ is contained in $\mathcal{F}$ or, equivalently, for every $V$ in the neighbourhood filter of $x$, there exists an element $F \in \mathcal{F}$ such that $F \subset V$. A subset $V \subset X$ is called a neighbourhood of $x$ if there exists an open set $T \in \mathcal{T}$ such that $x \in T \subset V$. The neighbourhood filter of $x$ is the set of all neighbourhoods of $x$.","['general-topology', 'convergence-divergence', 'filters']"
1591083,"If $Y$ is an irreducible subset of $X$, then its closure $\overline{Y}$ in $X$ is also irreducible.","From Hartshorne: If $Y$ is an irreducible subset of $X$, then its closure $\overline{Y}$ in $X$ is also irreducible. By irreducible they mean that $Y$ cannot be written $Y_1 \cup Y_2$ for two proper subsets $Y_i$ of $Y$ that are closed in the subspace topology of $Y$. My attempt Suppose that $\overline{Y} = Y_1 \cup Y_2$, both $Y_1, Y_2$ closed in $\overline
{Y}$.  Since the closed subsets of $\overline{Y}$ are precisely the closed subsets of $X$ intersected with $\overline{Y}$, we have that $Y_i = \overline{Y} \cap Y_i'$ for some closed $Y_i'$ in $X$.  In other words, each $Y_i$ is closed in the whole space $X$ as well as in $\overline{Y}$. By a previous statement, If $U \subset Y$ is an open subset, then when $Y$ is irreducible, $U$ is both irreducible (in $U$) and dense (in $Y$). So we have that $U_i = \overline{Y} \setminus Y_i$ is irreducible in itself and dense in $\overline{Y}$, meaning $\overline{U}_i = \overline{Y} \setminus \text{Int} (Y_i) = \overline{Y}$. Where to next?","['general-topology', 'algebraic-geometry']"
1591085,Convergence of sequence of ratio of consecutive terms.,"I would like to prove that the following sequence of ratios $(x_n)$ where $x_n = c_n/c_{n-1}$ converges to a finite limit $L$: $$\lim_{n\to\infty} x_n = \lim_{n\to\infty}\frac{c_n}{c_{n-1}} = L$$ Where $c_n$ is defined by the recurrence relation:
$c_n = c_{n-1} + \lfloor c_{n-4}/2 \rfloor$ for $n \geq 4$, with initial conditions $c_0=3, c_1=4, c_2=5, c_3=6$. I feel there should be a similar approach to proving limit of consecutive Fibonacci numbers converges, which I think might require me to solve the recurrence, but the floor function doesn't help. Some observations, verification by computer software has led me to predict that the limit tends towards $L = 1.25372495821...$, which appears to be very close to a solution to the equation: $$x^4 - x^3 - \frac{1}{2}=0$$ This would be the characteristic equation to the recurrence relation $\alpha_n = \alpha_{n-1} + \alpha_{n-4}/2$, which is very similar to the way how $c_n$ is defined. Any ideas? I exhausted most of the standard undergraduate analysis techniques for proving sequences converge, no luck though.","['recurrence-relations', 'sequences-and-series', 'limits']"
1591087,Generalization of Tonelli's Theorem for Series,"Let $A, B$ be sets and $x_{n,m}$ $n \in A, m \in B$ be a doubly infinite sequence of extended non-negative reals indexed by A and B.  Show that $\sum_{(n,m) \in A \times B} (x_{n,m})$ = $\sum_{n \in A} \sum_{m \in B} (x_{n,m})$ = $\sum_{m \in B} \sum_{n \in A} (x_{n,m})$ I started this proof but have one step I am not sure of.  To start, we can observe that if A or B is uncountable then either: a) at least one of the sums is $\infty$, so we are done; or b) the number of non-zero elements is at most countable, which puts us in the case of countable sets. Here's the step I am unsure of:  If A and B are both countable, they can each be mapped to the positive integers, so instead of indexing $x_{n,m}$ by $A \times B$ we can consider them to be indexed by the positive integers. Then this is just Tonelli's Theorem in its original form and we invoke it to complete the proof. I like this approach which avoids repeating all the work to prove Tonelli's theorem directly, but I'm unsure if it is correct.  I am concerned that by mapping A and B into the integers, we are imposing an ordering on the $x_{n,m}$ without knowing that we can reorder them and still get the same sum. Then again, A and B were not ordered to begin with, so we are perhaps assuming that the ordering does not matter?  Tonelli's theorem itself seems to say that the ordering does not matter if all the terms are positive. Can anyone enlighten me?","['measure-theory', 'real-analysis', 'sequences-and-series']"
1591089,Combinatorial identity $i{n \choose i } =n {n-1 \choose i - 1}$,"In the first course of probability by sheldon ross on page 155 at the bottom.
It is the proof for the expectation of Binomial distribution. It uses the identity: $$i{n \choose i } =n {n-1 \choose i - 1}$$ Since learning combinatorics, I have been trying to think of this intuitively. So is there an intuitive proof for this identity, rather than just using brute force?","['combinatorics', 'probability']"
1591105,Baby Rudin exercise 1.6: Is this the proof Rudin expects?,"$\bf Exercise\, 1.6$ Fix $b>1.$ Prove that if $m,n,p,q$ are integers, $n>0,q>0$ and $r=m/n=p/q$, then $$
(b^m)^{1/n}=(b^p)^{1/q}.
$$ I'm not really sure what I can assume and what  I can't assume, I think that all I need is $(x^y)^z=x^{yz}$ for integers $y,z$, but I'm not sure how to prove this (I don't even know what the expected definition of exponentiation is!). Attempt $$
\begin{align}
\left((b^m)^{1/n}\right)^n&=b^m\quad \text{By Theorem 1.21 (I think).}\\
\left((b^m)^{1/n}\right)^{nq}&=b^{mq}\quad \text{Here I use $(x^y)^z=x^{yz}$.}\\
\left((b^m)^{1/n}\right)^{nq}&=b^{np}\quad \text{As $mq=np$.}\\
\left((b^m)^{1/n}\right)^{qn}&=b^{pn}\quad 
\end{align}
$$ Then, taking $n$-th and then $q$-th roots, we get our desired result (I think this is possible, again, by theorem $1.21$, but I'm not sure). Could someone check my proof and tell me which facts about exponentiation we are allowed to assume and use for these kind of proofs?","['real-analysis', 'analysis', 'proof-verification']"
1591120,Homotopy cardinality of the category of categories,"The category of finite sets has homotopy cardinality $e$ , because
$$
|{\bf FinSet}|=\sum_{n=0}^{\infty}\frac{1}{\left|\operatorname{Aut}\ [n]\right|}=\sum_{n=0}^{\infty}\frac{1}{n!}.
$$ What is the homotopy cardinality of ${\bf FinCat}$, the category of finite categories? Sets are $0$-categories. According to the periodic table of categories , we have
$$
 |{\bf FinCat_{-2}}|=1,\qquad |{\bf FinCat_{-1}}|=2,\qquad |{\bf FinCat_{0}}|=e.
$$
Is there a reason to expect this to be an increasing sequence?","['category-theory', 'combinatorics', 'homotopy-theory']"
1591123,Examples where $H\ne \mathrm{Aut}(E/E^H)$,"If $E/F$ is a field extension, and $H$ is a subgroup of $\mathrm{Aut}(E/F)$, it is quite trivial to see that $H\subset \mathrm{Aut}(E/E^H)$. Since the theorem only shows the inclusion relationship, I think there must be a lot of examples where $\subset$ is actually $\subsetneq$. But due to lack of knowledge I can't come up with one. Could you help me with this? Best regards.","['galois-theory', 'examples-counterexamples', 'abstract-algebra', 'extension-field', 'field-theory']"
1591126,Number of ways to color n objects with 3 colors if colors must be used once,"I am aware this combinatoric problem (which I got from Discrete Mathematics Elementary and Beyond ) has been answered on here before, but from what I can tell the solution I have come up with is different than the answers on other posts but I am not sure so I would like to see where my thought process is wrong. My solution was originally: $$3!\cdot3^{n-3}$$ My rationale was: The first one has the option of 3 colors. Second, two, and the third, one. Each one after that can have any 3 colors since we've met our initial requirements. The below 'diagram' shows how many options each object has for colors. -----  -----  -----  -----  -----  -----
| 3 |  | 2 |  | 1 |  | 3 |  | 3 |  | 3 |
-----  -----  -----  -----  -----  -----  .... To me this makes sense for the answer, similarly to string combination problems. However it appears that my answer yields numbers different to the correct answer people arrive at using the Inclusion-Exclusion principal formula. Could someone explain how this is yields the wrong answer? I am assuming I am not accounting for all cases in some way. I am seeing the following as a correct answer in the case of distinctly labeled answers $$3^n - (2^n)\cdot{{3}\choose{2}} + 1^n\cdot{{3}\choose{1}}$$ Which for this specific problem reduces to: $$3^n - 2^n\cdot3 + 3$$","['combinations', 'combinatorics', 'coloring', 'discrete-mathematics']"
1591136,Lights Out variant: what matrix to use when whole row+column gets flipped?,"I've done my research and found a few similar questions here and on other sites, but none of them have what I'm looking for. Lights out is a simple game that has interesting math-based solutions (info here ). Using the typical rules in a 5x5 board, clicking anywhere in the grid causes the clicked spot and its 4 immediate neighbours to get flipped.  But I want to implement a solution where the entire row and column get flipped. For example, in this board 0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0
0 0 0 0 0 Clicking on the point at coordinate (4, 4) will result in 0 0 0 1 0
0 0 0 1 0
0 0 0 1 0
1 1 1 1 1 
0 0 0 1 0 Given a 5x5 board, I know how to solve it using Gaussian elimination when using the standard rules.  I read this short pdf that explained the linear algebra theory very well and showed how a solution can be obtained by solving Ax = b , where b is the column-vector of the current board and A is the following 25x25 matrix C I 0 0 0    where    I = identity(5) and C = 1 1 0 0 0
I C I 0 0                                     1 1 1 0 0
0 I C I 0                                     0 1 1 1 0 
0 0 I C I                                     0 0 1 1 1
0 0 0 I C                                     0 0 0 1 1 I figured out how to do Gaussian elimination in modulus 2 in order to solve the matrix equation and was able to solve 5x5 boards. I also found out that by just changing the C matrix slightly, I can easily use the same code to solve 3x3. I'm pretty sure that in order to solve the variant that I want (entire row+column gets flipped), all I need to do is figure out the C matrix.  But I tried sitting down with pencil and paper for a while and do something similar to what the PDF I linked to was doing, but I couldn't figure it out. Does anyone know how to derive the matrix required for this?","['matrices', 'linear-algebra']"
1591141,Solve the equation $27 \sin(x) \cdot \cos^2(x) \cdot \tan^3(x) \cdot \cot^4(x) \cdot \sec^5(x) \cdot \csc^6(x) = 256$.,Solve the equation $27 \sin(x) \cdot \cos^2(x) \cdot \tan^3(x) \cdot \cot^4(x) \cdot \sec^5(x) \cdot \csc^6(x) = 256$. I was hoping some things would cancel out when I expanded this but nothing. I think using inequalities will help.,['trigonometry']
1591144,Closed form for an integral involving the incomplete Gamma function?,"Let $\alpha>1$ , $K>1$ and $n \in \mathbb{N}^+$ . What is a closed form solution to a tough integral? $$I(\alpha,K,n)=-\int_{-\infty }^{\infty } \frac{2 i e^{-i K u} (K u-i) \Bigl[\alpha \, (-i u)^{\alpha } \,\Gamma (-\alpha ,-i u)\Bigr]^n}{u^2} \, du,$$ where $\Gamma(.,.)$ is the incomplete Gamma function: $\Gamma (a,z)=\int _z^{\infty }d t\, t^{a-1} e^{-t}$ . I tried all manner of substitutions and various combinations of integration by parts.","['calculus', 'complex-analysis', 'integration', 'fourier-transform', 'gamma-function']"
1591148,"If $f,g$ integrable then $f(x-y)g(y)$ integrable for almost every $x$","I am trying to prove that for two integrable functions $f,g: \mathbb{R}^n \rightarrow \mathbb{R}$ the function $y \mapsto f(x-y)g(y)$ is integrable for almost every $x$. By using the holder inequality I reduced this to showing that if a function is integrable then also its square is integrable but after browsing a bit I found this so I guess this leads nowhere. Any hints are welcomed.","['real-analysis', 'integration', 'measure-theory']"
1591149,Evaluate$ \iint_S\frac{x+y+z}{(x^2+y^2+z^2)^{3/2}}ds$,"Evaluate $\displaystyle \iint_S\frac{x+y+z}{(x^2+y^2+z^2)^{3/2}}ds$ where $S$ is the unit disk centered at $(1,1,1)$ and lies on the plane $x+y+z=3$. So my inegral becomes $\displaystyle \iint_S\frac{3}{(x^2+y^2+z^2)^{3/2}}ds$. Now I change the coordinate system as $X=x-1,Y=y-1,Z=z-1$ in order to shift the center to $(0,0,0)$. Then, I have $\displaystyle \iint_S\frac{3}{((X+1)^2+(Y+1)^2+(Z+1)^2)^{3/2}} \, ds$. And then I was going to change this to $(r,\theta)$ system since now $(X+1)^2+(Y+1)^2+(Z+1)^2=r^2$. Is this correct? I mean doesn't that coordinate change does anything to $ds$?","['multivariable-calculus', 'integration', 'geometry']"
1591155,"Integral $\int_0^{1/2}\arcsin x\cdot\ln^3x\,dx$","It's a follow-up to my previous question .
Can we find an anti-derivative
$$\int\arcsin x\cdot\ln^3x\,dx$$
or, at least, evaluate the definite integral
$$\int_0^{1/2}\arcsin x\cdot\ln^3x\,dx$$
in a closed form (ideally, as a combination of elementary functions and polylogarithms)?","['logarithms', 'calculus', 'integration', 'definite-integrals', 'polylogarithm']"
1591161,Is the kth central moment less than the kth raw moment for even k?,"If $X$ is a real-valued random variable, then the $k$th raw moment is $\mathbb{E}[X^k]$, while the $k$th central moment is $\mathbb{E}[(X-\mathbb{E}[X])^k]$.  If $k$ is even, is the $k$th central moment always bounded above the $k$th raw moment? When $k = 2$, then $\mathbb{E}[(X-\mathbb{E}[X])^2] = \mathbb{E}[X^2]-\mathbb{E}[X]^2$, and because $\mathbb{E}[X]^2$ is always positive, it follows that this is less than or equal to $\mathbb{E}[X^2]$.  But I'm having trouble extending this to larger moments.","['inequality', 'probability', 'expectation']"
1591185,Is my proof of the uniqueness of $0$ non-circular?,"Please try to avoid jumping directly the proof, the text before it is crucial to my question as well. I had a proof of this here , but I have come to realize that the proof is circular since I implied the result in all $3$ lemmas. I also believe that the one liner given in a comment to that question ($e_1=e_1+e_2=e_2$) also relies on some assumptions which were not given in the text. So allow me to write exactly what is given, exactly as written from the text (Apostol's ""Mathematical Analysis""): Definition of addition and multiplication: Along with the set R of real numbers we assume the existence of two operations, called addition and multiplication , such that for every pair of real numbers $x$ and $y$ the sum $x+y$ and the product $xy$ are real numbers satisfying the following axioms. (In the axioms that appeat below, $x, y, z$ represent arbitrary real numbers unless something is said to the contrary) Axiom 1: Commutative Laws $x+y=y+x$, $xy=yx$ Axiom 2: Associative Laws $x+(y+z)=(x+y)+z$, $x(yz)=(xy)z$ Axiom 3: Distributive Law $x(y+z)=xy+yz$ Axiom 4: Given any two real numbers $x$ and $y$, there exists a real number $z$ such that $x+z=y$. This $z$ is denoted by $y-x$; the number $x-x$ is denoted by $0$ (it can be proved that $0$ is independent of $x$.) We write $-x$ for $0-x$ and call $-x$ the negative of $x$. Please Note: I will denote the number $x-x$ as $0_x$ and $y-y$ as $0_y$. 
We are not given $x + 0 = x$ or $x + (-x) = 0$ in the general sense (which would imply a piece of information that is not given in the text about $0$). What I mean by that is that we are given that $x + (x-x)=x$, but we are not given that $x+(y-y)=x$. And we are given $x + ((x-x)-x) = x-x$, but we are not given $x + ((y-y)-x) = x-x$. The only piece of information we have about $0$ is that it is the symbol which denotes $x-x$, the number which when added to $x$ results in $x$. Before I start the actual proof, I want to make another note; the way I understand it, the ""uniqueness of $0$"" can have at least $2$ different meanings: $1)$ The number $0_x$ that satisfies $x + 0_x = x$ is unique $2)$ The number $0_x$ is the same as $0_y$ I believe the first meaning of uniqueness follows from the definition of $z$ in axiom $4$, as the wording in axiom $4$ seems to imply that $z$ in axiom $4$ is unique (please let me know if I am correct/incorrect here). Also, were are not given $y-x=y+(-x)$; $y-x$ is just a symbol for the number $z$ in axiom $4$. So now I am trying to prove the second meaning of uniqueness (this proof is similar to the one in the linked question, only hopefully witouth circular assumptions): Lemma: If $x+z=y+z$, then $x=y$ Let $x=y$ Add $z$ to both sides $x+z=y+z$. Therefore, if $x+z=y+z$, then $x=y$ I think the proof of this lemma is correct only if we assume that addition is an operation which maps two real numbers to one unique real number. Is this a fair assumption to make from the definition of addition given above? Is there a way to prove this lemma without this assumption? Proof that $0_x=0_y$ So just a refresher on the definition, $0_x=x-x$ and $0_y=y-y$ $x + 0_x = x$ $y + 0_y = y$ By axiom $4$, we are guaranteed that there exists a (unique?) $z$ such that $x + z = y$, so we will replace $y$ by $x + z$. $x +z + 0_y = x+z$ By associative and commutative laws, $(x + 0_y)+z = (x)+z$ By the lemma, $(x + 0_y) = (x)$ but $(x + 0_x) = (x)$ And if meaning number $1$ of uniqueness given above is true, then $0_x = 0_y$","['real-analysis', 'axioms', 'analysis', 'proof-verification']"
1591203,A mathematical fallacy concerning the integrability of a function and cancellation,"I am reading the Florida Mu Alpha Theta Sponsors Guide . Page 43 is a list of clarifications and disputes commonly made, and their resolutions. One of their clarifications is this: A function which is not integrable on an interval A is not integrable on any interval B, where B contains A. I.e. no “the negative signs cancel” arguments. What is this argument they're referring to?","['improper-integrals', 'real-analysis', 'integration']"
1591214,Prove that $\sin^{2n+4}(x)+\cos^{2n+4}(x) \leq \frac{\sin^2(2x)}{2^{n+1}} + \cos^2(2x)$.,"Let $n$ be a nonnegative integer and $x$ a real number. Prove that $\sin^{2n+4}(x)+\cos^{2n+4}(x) \leq \dfrac{\sin^2(2x)}{2^{n+1}} + \cos^2(2x)$. Should I use the $\sin^2(x)$ and $\cos^2(x)$ properties to solve this? Seeing as how we have the $2n+4$ in the exponent, we should be able to get $$\sin^{2n+4}(x)+\cos^{2n+4}(x) = \sin^{2n+2}(x)\sin^{2}(x)+\cos^{2n+2}(x)\cos^2(x).$$ Then I get stuck","['inequality', 'trigonometry']"
1591215,Approximating one random variable by a function of other random variables,"Suppose $(X,Y)$ is a continuous bivariate random variable and we want to approximate $Y$ by a function of $X$ ,that means we seek a function say $h(x)$ whose outcomes are the minimum expected squared distance from the outcome of $Y$ , in other words we want to minimize
$$\mathbb{E}[(Y-h(X))^2] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(y-h(x))^2 f(x,y)dxdy$$
My question is ,how can we mathematically prove that the optimal choice of approximating function is the regression function i.e $h(x)= E(Y|x)$ ?","['statistics', 'conditional-expectation', 'expectation']"
1591220,"$\frac{1}{\sin 8^\circ}+\frac{1}{\sin 16^\circ}+....+\frac{1}{\sin 4096^\circ}+\frac{1}{\sin 8192^\circ}=\frac{1}{\sin \alpha}$,find $\alpha$","Let $\frac{1}{\sin 8^\circ}+\frac{1}{\sin 16^\circ}+\frac{1}{\sin 32^\circ}+....+\frac{1}{\sin 4096^\circ}+\frac{1}{\sin 8192^\circ}=\frac{1}{\sin \alpha}$ where $\alpha\in(0,90^\circ)$,then find $\alpha$(in degree.) $\frac{1}{\sin 8^\circ}+\frac{1}{\sin 16^\circ}+\frac{1}{\sin 32^\circ}+....+\frac{1}{\sin 4096^\circ}+\frac{1}{\sin 8192^\circ}=\frac{1}{\sin \alpha}$ $\frac{2\cos8^\circ}{\sin 16^\circ}+\frac{2\cos16^\circ}{\sin 32^\circ}+\frac{2\cos32^\circ}{\sin 64^\circ}+....+\frac{2\cos4096^\circ}{\sin 8192^\circ}+\frac{1}{\sin 8192^\circ}=\frac{1}{\sin \alpha}$ $\frac{2^2\cos8^\circ\cos16^\circ}{\sin 32^\circ}+\frac{2^2\cos16^\circ\cos32^\circ}{\sin 64^\circ}+\frac{2^2\cos32^\circ\cos64^\circ}{\sin 128^\circ}+....+\frac{2\cos4096^\circ}{\sin 8192^\circ}+\frac{1}{\sin 8192^\circ}=\frac{1}{\sin \alpha}$ In this way this series is getting complicated at each stage,is there any way to simplify it?Please help me.Thanks.",['trigonometry']
1591223,Group Theory : What is $Ha \ne Hb$?,"As a beginner of Group Theory, I got stuck with the following question: Suppose that $H$ is a subgroup of $G$ such that whenever $Ha \ne Hb \space ,$ then $aH \ne bH$ . $(a,b \in G)$ Prove that $gHg^{-1} \subset H \space\space\forall g\in G$ . My first doubt is what is exactly implied by $Ha \ne Hb$ in the above question? Does it mean $$ whenever \space ha\ne hb , ah\ne bh \space \forall\space h\in H $$ $$OR$$ $$whenever \space h_1a\ne h_2b , ah_1\ne bh_2 \space \forall \space h_1,h_2 \in H \space ?$$ I dont know whether this is a very silly doubt or not ; please help me clarify. Secondly , it will be very helpful if you give me a hint how to proceed with this problem. Thank you in advance.. If this question is a repetition please give a link , but do not down-vote. I am very low in reputation.","['normal-subgroups', 'group-theory']"
1591250,Separable Differential Equation (Check Answer),"Question: Determine all differentiable functions in the form $y$ = $f(x)$ which have the properties: $f'(x)$ = $(f(x))^3$ and $f(0)=2$ What I have done I set up the differential equation as such $$ \frac{dy}{dx} = y^3 $$ $$ \int y^{-3} dy = \int dx$$ $$ {-1\over 2y^2} = x + c $$ $$ {1\over 2y^2} = -x-c $$ At $y = 2 , x = 0 , c = -\frac{1}{8}$ $$ {1\over 2y^2} = {1\over 8} - x$$ $$ 2y^2 = {8\over {1-8x}} $$ $$ y^2  = {4\over {1-8x}} $$ $$ y = ±\sqrt{4\over {1-8x}} $$ Is this correct? Are there any limits of x or y to consider?","['integration', 'ordinary-differential-equations', 'calculus']"
1591273,Proving a trigonometric inequality,"I've been having difficulty with the following, Prove that, $[\sin^{n+1}(x)]^{2}+[\cos^{n+1}(x)]^{2} \geq (\frac12)^{n}$ where $x$ is real and $n$ is a non-negative integer. I've tried an inductive approach but have struggled with the inductive step.","['inequality', 'trigonometry']"
1591274,Curious combinatorial summation,"Let $\gamma$ denote a grid walk from the upper left corner $(1,k)$ to the lower right corner $(\ell,1)$ of the $k\times\ell$ rectangle $\{1,..,k\}\times\{1,..,\ell\}$.  There are $\binom{k+\ell-2}{k-1}$ such paths.  Denote
$$
X_\gamma = \prod_{(i,j)\in\gamma} \frac{1}{i+j-1}\,.
$$ Claim: $$\sum_\gamma X_\gamma = \frac{1}{(k+\ell-1)(k-1)!(\ell-1)!}\,.
$$ Equivalently, and more elegantly, for a random path $\gamma$, we have: $\ \Bbb E[X_\gamma] = 1/(k+\ell-1)!$ Example: $k=2$, $\ell=3$. There are $3=\binom{3}{1}$ paths $\,\gamma_1:  (1,2) \to (1,1) \to (2,1) \to (3,1)$, $\,\gamma_2:  (1,2) \to (2,2) \to (2,1) \to (3,1)$, $\,\gamma_3:  (1,2) \to (2,2) \to (3,2) \to (3,1)$. Then:
$$
X_1 = \frac{1}{2\cdot 1\cdot 2\cdot 3} \ , \ X_2 = \frac{1}{2\cdot 3\cdot 2\cdot 3} \ , \ X_3 = \frac{1}{2\cdot 3\cdot 4\cdot 3} \ ,  
$$
$$X_1+X_2+X_3 = \frac{1}{12}+\frac{1}{36}+\frac{1}{72} = \frac{1}{8} = \frac{1}{4\cdot 1!\cdot 2!}\,.
$$ Question: Is there a simple proof of this combinatorial summation?  If it's known, does anyone have a reference? P.S.  I can in fact prove the claim but the proof is incredibly involved for such a simple looking result.","['combinatorics', 'binomial-coefficients', 'discrete-mathematics']"
1591281,Closed form solutions to Abel equation,"Consider a (somewhat simplified) Abel equation of the first kind for $\alpha$: $\left[\alpha(x)\right]^2 \left[1-f(x)\alpha(x)\right] + \alpha'(x) = 0$, for some smooth function $f$. Is it known what conditions on $f$ are necessary (and sufficient) to ensure a closed form solution? One particular case I am interested in is $f(x) = \lambda x^3$ for some $\lambda \in \mathbb{R}$; is there any hope of getting a closed form in this case? What other cases have been studied?",['ordinary-differential-equations']
1591307,How to prove that $\frac{(12!)!}{12!^{11!}}$ is integer? [duplicate],This question already has answers here : Proving that $\frac{(k!)!}{k!^{(k-1)!}}$ is an integer (3 answers) Closed 2 years ago . So far I have used that a combination is an integer so $\frac{n!}{m!(n-m)!}$ is integer. Now let $n=mb$ so $\frac{mb!}{m!(mb-m)!}$. What is left is to prove that $\frac{(mb)!}{m!^b}$ is integer so that i can apply $m=12$ and $b =11!$ How to do that?,"['combinations', 'combinatorics', 'discrete-mathematics']"
1591311,$n$ distinguishable items into $b$ distinguishable bins (there's more to elaborate...),"I've been thinking about this problem which I think is interesting, but can't solve it. There are $n$ distinguishable items, and $b$ distinguishable bins. Each bin has to include at least one item. But, once some set of items are placed in a bin, they become indistinguishable. How many ways are there to place the items into the bins? (1) The condition that each bin has to include at least one item can be resolved by simply tweaking the problem a bit: suppose there are $n-b$ items, and proceed. So this is not a big hurdle. (Or, it can be, depending on how we handle the second condition below.) (2) The second condition that the items in a bin are indistinguishable is a bit tricky. Suppose we have 3 items, and 2 bins. The items are numbered as 1, 2 and 3. The bins are denoted as A and B. The second condition says that, we have to consider the following as identical: A - 1, B - 2, 3. vs. A - 1, B - 3, 2. However, we have to consider the following as distinct: A - 1, B - 2, 3 vs. A - 2, 3, B - 1. How can I compute the total number of ways to place the items into the bins? Thanks.","['combinatorics', 'discrete-mathematics']"
1591313,Uniform convergence of $\sum_{n=0}^{\infty} \frac{\int_{\sin nx}^{\sin(n+1)x}\sin t^2dt \int_{nx}^{\infty}\frac{dt}{\sqrt{t^4+1}}}{1+n^3x^2}$,"I am preparing for the exam. Please help me to solve the following problem: Given a series $$\sum_{n=0}^{\infty} \frac{\int_{\sin nx}^{\sin(n+1)x}\sin t^2dt \int_{nx}^{\infty}\frac{dt}{\sqrt{t^4+1}}}{1+n^3x^2}$$ determine, if it is uniformly convergent on 1) $(0, \infty)$ ? 2) $(0, c)$, where $c < \infty$ ? Thanks a lot for your help!","['uniform-convergence', 'convergence-divergence', 'sequences-and-series', 'calculus']"
1591320,Is every measure finitely additive?,"The answer is yes because for disjoint $A_i, i=1,2,...n$ $\mu(A_1\cup A_2 \cup ... \cup A_n) = \mu(A_1\cup A_2 \cup ... \cup A_n \cup \emptyset \cup \emptyset \cup ...) = \sum_{i=1}^{n} \mu(A_i) + \sum_{i=n+1}^{\infty} \mu(\emptyset) = \sum_{i=1}^{n} \mu(A_i)$ Correct?","['real-analysis', 'measure-theory']"
1591370,What is tangent to a curve or function?,"When I read my textbooks or even type ""what is a tangent?"" on google, I have always got an answer similar to these lines:
""A straight line or plane that touches a curve or curved surface at a point, but if extended does not cross it at that point.""
Now when I am thinking about graph of $\sin x$ or $\cos x$, it is very hard for me to believe this definition because if we draw a line touching any point on such curves then either it will cut at some point or touch at (infinitely) many points. So therefore it is very hard for me to believe this concept (or definitions). Please correct me if I am wrong at any point suggest a better definition in good mathematical framework. Image in support of question","['self-learning', 'functions', 'graphing-functions']"
1591384,Canonical Bundle Isomorphism $T_v(E)\cong \pi^* E$,"Given a smooth vector bundle $\pi:E\to M$, the vertical bundle $T_v(E)$ is by definition $\ker T\pi$, which is a subbundle of $T(E)$. It is asserted in this answer that there is a canonical isomorphism $$T_v(E)\cong \pi^* E.$$ Georges Elencwajg writes the following: Recalling  that for a finite-dimensional vector space  $V$ (seen as a
  manifold) we have for each $a\in V$ a canonical isomorphism $T_a(V)=V$
  we obtain the canonical isomorphism $T_v(E)=\pi^*(E)$ I am still unable to see how one obtains the claimed isomorphism and would be thankful for elucidation.","['vector-bundles', 'differential-geometry', 'differential-topology']"
1591386,How are the elements of a dihedral group usually defined?,"While searching online, I've come across two ways to define the elements of the dihedral group. Both ways are internally consistent and are fine as far as I can tell, but they are mutually exclusive, so I was wondering which of the two ways is more standard or commonly used. The two ways are as follows: Way 1. Elements are defined as transformations against a fixed set of axes. In this way of defining the elements, each element of $D_n$ is either a reflectional symmetry or a rotational symmetry of the polygon being considered. In an $n$ -gon, there are $n$ reflectional symmetries and $n$ rotational symmetries. The reflectional symmetries are described as follows: An $n$ -gon has $n$ axes of symmetry. For each axis of symmetry in the $n$ -gon there is an element in the dihedral group that reflects the $n$ -gon along that axis. It is important to note that these axes stay fixed, even after the n-gon itself undergoes a rotational symmetry. Similarly, there are $n$ rotational symmetries in the $n$ -gon being discussed, and each of these rotations is a member of $D_n$ . It is important to note that here, the rotations are always in the same direction, even if the shape undergoes reflectional symmetry. So, for example, an element $r$ that rotates a square $90^{\circ}$ clockwise will always rotate the square $90^{\circ}$ clockwise, even after the square is reflected. Way 2. Elements are defined as permutations of vertices. The second way of defining the elements of $D_n$ is that each element is defined as a permutation of vertices of the $n$ -gon. (It should be noted that there are in total $n!$ permutations of vertices, yet only $2n$ elements in $D_n$ ; this discrepancy is explained by the fact that a permutation must also preserve the structure of the $n$ -gon in order to be included in $D_n$ .) Like all permutations on a finite set, these permutations can be written out as cycles such as $(1234)$ , where $1$ , $2$ , $3$ , and $4$ are the names of vertices of a square, for example. Way 2 is actually distinct from Way 1, both geometrically and algebraically (as far as I can tell). There are still $n$ rotations and $n$ reflections, but unlike in Way 1 where the transformations are defined in terms of a fixed ""background"" which doesn't move as the $n$ -gon undergoes rotation or reflection, the transformations in Way 2 are now defined in terms of  the vertices of the $n$ -gon, which DO move as the $n$ -gon undergoes rotation or reflection. What this means is that in Way 2, the transformations change depending on the current orientation of the $n$ -gon. For example, consider the rotation of a square. In Way 1, we can let $r$ be the element that rotates the square $90^{\circ}$ clockwise. The direction of rotation ( $90^{\circ}$ clockwise or, equivalently, $270{\circ}$ counterclockwise) never changes, even after the square is reflected across one of its axes of symmetry. On the other hand, the roughly corresponding rotation in Way 2 would be something like the cycle $(1234)$ . Unlike $r$ , which always rotates the square $90^{\circ}$ clockwise, $(1234)$ may rotate the square $90^{\circ}$ either clockwise or counterclockwise, depending on whether the square has been reflected or not. Similarly, the axes of reflection in Way 2 move along with the square, while those of Way 1 remain fixed. The fact that the two ways are non-equivalent can also be verified algebraically (I think...). No isomorphism exists between the two Ways (at least as far as I can tell; I tried constructing an isomorphism by making a bijection between the elements as defined in Way 1 with the elements as defined in Way 2, matching the rotations and reflections in Way 1 with the corresponding ones in Way 2, but the bijection did not satisfy the criterion that $f(a)f(b) = f(ab)$ for all $a$ , $b$ in Way 1. The problem arose when $a$ was a rotation and $b$ was a reflection. However, if there actually is an isomorphism that I overlooked, please correct me.) My main question is: Which of these two ways is standard, or used more often by working mathematicians? Are both acceptable? It seems to me that Way 2 is just nicer all-around, mainly because all of the elements are permutations and can thus be written as cycles, which are easy to work with algebraically (by Cayley's Theorem, Way 1 is isomorphic to some group of permutations anyway, but then it seems like kind of a hassle finding a way to write it as cycles and whatnot.) If there are some benefits to Way 1, then I would like to learn about those too. Thanks in advance for those who bothered to read through all this!","['dihedral-groups', 'group-theory']"
1591430,Denominator in rational gcd of integer polynomials,"A recent question tells us that even if two polynomials $f,g\in \mathbb Z[X]$ have no common factor as polynomials, their values at integer points may have common factors. That question gives this example:
$$
f=x^3-x^2+3x-1,
\qquad
g=x^3+2,
\qquad
\gcd(f(27),g(27))=31
$$ The explanation I've given for this example is that even though $\gcd(f,g)=1$ in $\mathbb{Z}[x]$, we cannot always write $1=uf+vg$ with $u,v \in \mathbb{Z}[x]$ (because $\mathbb{Z}[x]$ is not a PID). But we can write $1=uf+vg$, if we allow $u,v \in \mathbb{Q}[x]$. In the example above, we get
$$
1 = \dfrac1{31} (-6 x^2-7 x-3)f(x)+\dfrac1{31}(6 x^2+x+14)g(x)
$$ Now, clearing denominators, we get
$d = uf+vg$ with $u,v \in \mathbb{Z}[x]$ and $d \in \mathbb{Z}$. Is there a name for $d$ in terms of $f$ and $g$? Can we compute $d$ without performing the entire  extended Euclidean algorithm in $\mathbb{Q}[x]$? When $d>1$, is it always true that some values of $f$ and $g$ (at the same point) are not coprime? It seemed that $d$ is the resultant of $f$ and $g$, but perhaps not .","['gcd-and-lcm', 'abstract-algebra', 'polynomials', 'elementary-number-theory']"
1591441,Finding $f(x)$ from the functional equation $f(x+2y)=f(x)+f(2y)+e^{x+2y}(x+2y)-xe^x-2ye^{2y}+4xy$ [duplicate],"This question already has answers here : Finding $f$ from the functional equation $f(x+y)=f(x) + f(y) + e^{x+y}(x+y)-xe^x-ye^y+2xy$ (2 answers) Closed 8 years ago . This sum really looks scary to me. No idea how to begin. I just figured out that $f(0)$ is $0$ . What's next? Let $f:\mathbb R \to \mathbb R$ , such that $f'(0)=1$ and $$f(x+2y)=f(x)+f(2y)+e^{x+2y}(x+2y)-xe^x-2ye^{2y}+4xy$$ for all real $x$ and $y$ . Find $f(x)$ . P.S. Please don't use very high level maths.","['calculus', 'functions']"
1591454,Why is L the derivative of L? I have a very vague understanding about the very step needed to show $dL=L$.,"I have a bits-and-pieces understanding on how to solve this problem and just a very rough intuition of the path to solve the problem but very much struggling to get to show $dL=L$. This is part of a question if Do Carmo's book that reads as follows: Prove that if $L:R^3\to R^3$ is a linear map and $S\subset R^3$ is a regular surface invariant under $L$, i.e., $L(S)\subset S$, then the restriction $L|S$ is a differentiable map and $$dL_p(w)=L(w), \text{ }p\in S, w\in T_p(S).$$ I could show that the restriction $L|S$ is a differentiable map but I am struggling to show that $dL_p(w)=L(w)$. So let's try this: Let $p$ be a point on the surface $S$, $x:U\subset \mathbb R^2\rightarrow S$ be a parametrization s.t. $x(0)=p$ and $y:V\subset \mathbb R^2\rightarrow S$ be another parametrization s.t. $L(p)=y(0)$. Let $f(u,v)=y^{-1}\circ L \circ x(u,v)$. By using chain rule, we get $df_0=d(y^{-1})_{L(p)}\circ dL \circ dx_0$. My question is: 1. What the map does is $\mathbb R^2 \underset{dx}{\longrightarrow} T_pS \underset{dL}{\longrightarrow} T_{L(p)}S\underset{dy^{-1}}{\longrightarrow} \mathbb R^2$. From here, how can we conclude that $dL=L$? I have seen some similar problems from some other sources, but I am still very much struggling to connect all the dots, everything for me is still bits and pieces. Helps are greatly appreciated! Hopefully after making those points clear I can finish the problem by myself. Thanks.",['differential-geometry']
1591461,Swapping the $i$th largest card between $2$ hands of cards,"Introduction to ""game"" There are $2$ players and $2n$ cards, labelled $1, 1, 2, 2, 3, 3, 4, 4, \dots, n, n$. ($2$ of each card from $1$ to $n$) Firstly, the $2n$ players are each given $n$ cards randomly. More specifically, a random ordering of the $2n$ cards is achieved and the first player gets the first $n$ cards, the second player gets the other $n$ cards. We can assume each player can see all the cards. On every turn, each player will sort his hand of cards. Label the cards in the hands $a_1, a_2, a_3,\dots, a_n, b_1, b_2, b_3,\dots, b_n$. The players find a pair of cards $a_i\neq b_i$. Then they exchange the cards $a_i$ and $b_i$. After which, the turn ends. Clearly if $a_i=b_i$ for all $i$, then $a_i=b_i=i$, and the ""game"" terminates. Example Let $n=4$. We call the $2$ players $A, B$. At the start of the game, they receive: $A: 1, 1, 2, 2$ $B: 3, 3, 4, 4$ Turn 1: They decide to swap the first card. $A: \color{red}{3}, 1, 2, 2$ $B: \color{red}{1}, 3, 4, 4$ Before the second turn starts, they sort their cards. $A: 1, 2, 2, 3$ $B: 1, 3, 4, 4$ Turn 2: This time, they decide to swap the third card. They cannot swap the first card as the numbers on the first card are the same. $A: 1, 2, \color{red}{4}, 3$ $B: 1, 3, \color{red}{2}, 4$ They sort their cards. $A: 1, 2, 3, 4$ $B: 1, 2, 3, 4$ The ""game"" ends as the players both have $1, 2, 3, 4$. This game ends in $2$ turns. Questions about this ""game"" Will it terminate? (The answer is yes, and an idea of a bound based on the monovariant will be added as a self-answer.) In how many moves (at most) does it take for a $2n$ card game to terminate? What arrangements will cause it to take such a long time to terminate? Assuming that the players pick the next card to exchange randomly (among all the possible moves, choose a valid move, each valid move with equal probability), what is the expected number of moves for the game to terminate? Ideas about the question: As suggested by hardmath: If we constrain the players to take the lowest card that works or the highest card that works, the game will definitely end in at most $n-1$ turns. Both cases are symmetrical, so we work on highest. Base case: if $n=1$, no moves have to be done. Otherwise, $n>1$. We now proceed on the inductive step. Suppose the highest cards of the players are different. If they are the same, we delete them, reducing to the $n-1$ case, which can be done in at most $n-2$ moves. Otherwise, one player has both the highest card. When the move is done, a copy of the highest card is given to the other player. Now, both players have the highest card, and it can be deleted. In total, there are $1+(n-2)=n-1$ moves for this. From this, we can obtain that on average, the game ends in $O(n^2)$ turns, as it takes (on average) $O(n)$ turns for the highest card to be swapped. Code (for reference): I ran a Monte Carlo simulation of random games. A simulation of $1000$ games of $1000$ cards gave an average number of swaps of $1310.703$. C++ code for reference: #include <cstdio>
#include <algorithm>
#include <cmath>
using namespace std;
int N;
int K;
int maxCounter = 0;
int sumCounter = 0;
int counter;
int arr[999999];
/** Results:
(X cards, 10^6 rounds)
1 -> 0 0
2 -> 1 0.334546 (guess: 1/3)
3 -> 2 0.733746
4 -> 3 1.180559
5 -> 5 1.667006 (guess: 5/3)
6 -> 6 2.179321
7 -> 8 2.721661
8 -> 9 3.283566
9 -> 10 3.867299
10 -> 12 4.471352
Other things I tried: (cards, rounds)
100 1000 -> 143 84.411
200 1000 -> 307 197.332
300 1000 -> 503 319.691
500 1000 -> 960 580.373
1000 1000 -> 1910 1310.703
**/
int main(void) {
    srand(23);
    printf(""Number of cards: "");
    scanf(""%d"", &N);
    for (int i=0;i<N;i++) {
        arr[i] = arr[i+N] = i;
    }
    printf(""Number of rounds: "");
    scanf(""%d"", &K);
    for (int j=0;j<K;j++) {
        random_shuffle(arr, arr+2*N);
        counter = 0;
        while (counter>=0) {
            sort(arr, arr+N);
            sort(arr+N, arr+2*N);
            int pass = 1;
            for (int i=0;i<N;i++) {
                if (arr[i] != arr[i+N]) {
                    pass = 0;
                    break;
                }
            }
            if (pass) break;
            counter++;
            int theMove = rand()%N;
            while (arr[theMove] == arr[theMove+N]) theMove = rand()%N;
            int temp = arr[theMove];
            arr[theMove] = arr[theMove+N];
            arr[theMove+N] = temp;
        }
        //printf(""%d "", counter);
        maxCounter = max(maxCounter, counter);
        sumCounter += counter;
        if (j%(K/100) == 0) printf(""Done: %d\n"", j);
    }
    printf(""Maximum: %d\nAverage: %lf\n"", maxCounter, sumCounter/(double)K);
    return 0;
} Results of the code: The average number of moves appear to grow faster than $O(n)$.","['combinatorics', 'expectation', 'probability']"
1591464,Show that the union of two sets of the same cardinality has again the same cardinality.,"Greetings great wise ones. Continuing my set-theoretic adventures, I have again stumbled upon a problem and need guidance. The original problem goes like this:
Let $k_0 = \aleph_0$ and for any $n > 0$, $k_{n+1} = 2^{k_n}$ (These are Beth numbers basically).
I need to show that $k_n + k_n = k_n$ for any $n$. So what I'm trying to do so far, is conjure up a bijection $f : A \rightarrow A \cup B$ where $A$ and $B$ are two disjoint sets whose cardinality is $k_n$. An injection from $A$ to $A \cup B$ is easy, the tricky part is other way around, but I am not sure how to go around doing that. Trying to find some help in a bunch of set theory books I have, I found that I could prove the aforementioned equality by first proving that $k_n * k_n = k_n$ (in that $k_n + k_n = (1 + 1)k_n = 2k_n = k_n$), but that problem is pretty much the same as what I'm having trouble with. That book discussed cardinals in general though and not ones of the form I gave, so maybe I'm not using the definition of those $k_n$s to my advantage. Can someone please give me a hint/direction?","['cardinals', 'elementary-set-theory']"
1591469,Solve the functional equation $f(xy)=e^{xy-x-y} \big( e^yf(x)+e^xf(y) \big)$,"If $f: \Bbb R ^+ \to  \Bbb R$ satisfies $$f(xy)=e^{xy-x-y} \big( e^yf(x)+e^xf(y) \big)$$ for all $x, y \ge 0$ and if $f'(1)=e$, determine $f(x)$. I'm a beginner. Can someone give me some hints for this sum? I'm getting $f(1)=0$. Is that right?","['algebra-precalculus', 'calculus', 'functions']"
1591472,Geometric solution of quintic equations,There are many method of geometric solution of quadratic equations (for example Carlyle Circle ). Does there exist similar method  for the quintic equation?,"['roots', 'polynomials', 'geometry']"
1591491,Find equation of plane given plane point,"So I am given one plane point $M(5,2,0)$, also two points which are not plane points: $P(6,1,-1)$ distance to plane $1$, also point $Q(0,5,4)$ distance to plane $3$. How find equation of plane with the information given?","['algebra-precalculus', 'solid-geometry', 'linear-algebra', 'geometry']"
1591526,Two (equivalent ?) norms on Hilbert space,"Let $H$ be a vector space equipped with two inner products $\langle \cdot,\cdot\rangle_1, \ \langle \cdot,\cdot\rangle_2$, s.th. $(H,\langle \cdot,\cdot\rangle_j)$ is a Hilbert space for $j=1,2$. Suppose that $R_1$ and $R_2$ are linear operators on $H$, which are bounded w.r.t. $\|\cdot\|_1$ and $\|\cdot\|_2$,respectively. Moreover, let us assume that $R_1$ is injective and for any $x,y\in H \ \langle R_1x,y\rangle_1=\langle R_2x,y\rangle_2$. Is it true that norms $\|\cdot\|_1$ and $\|\cdot\|_2$ are equivalent ?","['functional-analysis', 'normed-spaces', 'hilbert-spaces']"
1591529,Generating probability distribution function from continuous data,"We have a continuous function $F(x,y)$ defined on a bounded domain $(x, y) \in [0, L_x] \times [0, L_y]$ . Suppose the function $F$ (the explicit form is irrelevant here) is defined such that $F(x,y)$ always lies between, say, 0 and 1. By varying $x$ and $y$ continuously over the finite region, we obtain a set of corresponding (continuous) values for $F$ . Now, I would like to find the PDF of the values assumed by $F$ itself. In other words, what I am looking for is the probability $P\, [F = \zeta;\,\, 0 \le \zeta \le 1]$ as a function of $\zeta$ . This answer suggests a numerical prescription for such a situation as follows: Way of generate a PDF from discrete / continuous data: Find a continuous equation that models the collected data, let say normal distribution equation Calculate the parameters required in the equation from the collected data.For example, parameters for normal distribution equation are mean and standard deviation. Calculate them from collected data Based on the parameters, plot the equation with continuous x-value --> that is called PDF However, I was wondering if there is a method to obtain the PDF analytically, given that we know the exact functional form of $F$ . I would greatly appreciate any help in this regard. Many thanks!","['statistics', 'probability', 'probability-distributions']"
1591534,"For numerical integration, is it true that higher degree of precision gives better accuracy always?","In case of numerical integration, is it true that higher degree of precision always gives better accuracy? Justify your answer. I know the definition of degree of precision. For Trapezoidal and Simpson's 1/3 rule they are 1 and 3 respectively. Simpson's 1/3 gives better accuracy than Trapezoidal rule. Then whether the above statement is true always. If not, why? If yes, then why we learn Trapezoidal/ Simpson rule? Why we shall not establish/go for higher and higher DOP from generalized Newton-Cote's rule or other general quadrature formula
.","['numerical-methods', 'integration']"
1591545,How can I solve this triangular linear system?,"I am trying to create a model for simulating the dynamics of a rope by treating it like several connected pendulums. The goal is to solve the following system for $\vec\alpha$, which is a vector of all the angular accelerations $\alpha$ of all the rope segments. The system is: $$C\vec\alpha = S\vec\omega - \frac{g}{L}\vec s$$ Where $\vec\alpha$ is the vector of unknowns, $\vec\omega$ is a vector of known angular velocities and $\frac{g}{L}$ is a constant. $C$ and $S$ are $m \times m$ matrices and $\vec s$ is a vector. They're defined as follows: $$ C = \begin{pmatrix}
1& 0& 0& \cdots& 0\\
\cos(\theta_1-\theta_2)& 1& 0& \cdots& 0\\
\cos(\theta_1-\theta_3)& \cos(\theta_2-\theta_3)& 1& \cdots& 0\\
\vdots& \vdots& \vdots& \ddots& \vdots&\\
\cos(\theta_1-\theta_m)& \cos(\theta_2-\theta_m)& cos(\theta_3-\theta_m)& \cdots& 1
\end{pmatrix}$$ $S$ is the same as $C$, except every instance of $\cos$ is replaced with $\sin$. $$ \vec s =
\begin{pmatrix}
\sin(\theta_1)\\
\sin(\theta_2)\\
\vdots\\
\sin(\theta_m)\\
\end{pmatrix}$$ Additionally, $\theta_n$ is a known angle for all integers $n$ in $[1,m]$. The objective is to solve the given linear system for $\vec\alpha$. The obvious way to do so is to left-multiply by the inverse of $C$. Am I right in assuming this would yield the following? $$ \vec \alpha = C^{-1}S\vec\omega-\frac{g}{L}C^{-1}S$$ I'm quite confident this is correct, but if it breaks some rule of matrix multiplication I've overlooked please tell me. Either way, I would like help with finding the inverse of $C$. Additionally, if possible, I would like help finding $C^{-1}S$ and $C^{-1}\vec s$. Any help is appreciated.","['matrices', 'matrix-equations', 'trigonometry', 'linear-algebra']"
1591548,basis of neighborhoods of zero in Schwartz Space,"I have the following question: In $S(\mathbb{R}^n)$, and for $\alpha, \beta\in \mathbb{N}^n $, we defined
  \begin{align}
ρ_{\alpha,\beta}(\phi) = \sup_{x\in\mathbb{R}^n}|x^{\alpha}D^{\beta}\phi(x)|.
\end{align}
  We defined a distance as follows: we take a bijection $\sigma: \mathbb{N}\mapsto \mathbb{N}^n\times \mathbb{N}^n$, and set
  \begin{align}
d(\phi,\varphi) = \sum_n 2^{-n}\frac{ρ_{\sigma(n)}(\phi-\varphi)}{1 + ρ_{\sigma(n)}(\phi − \varphi)}
\end{align}
  This distance induces a topology in $S(\mathbb{R}^n)$. Starting from these definitions, prove that the family of sets
  \begin{align}
N_{\epsilon, l, m} = \Big\lbrace \phi\in S\mid \sum_{|\alpha|\leq l, |\beta|\leq m}p_{\alpha, \beta}(\phi)<\epsilon\Big\rbrace
\end{align}
  defines a basis of neighborhoods of $0 \in S$. I know that what we have to do is to assume that we have a open set $U$ in $S(\mathbb{R}^n)$ containing zero, that is, for every $x\in U$ there exists a disc \begin{align}
B_{r,x}=\lbrace \phi\in S\mid d(x,\phi)<r\rbrace 
\end{align}
such that $x\in B_{r,x}\subseteq U$. Then we have to look if there exist some $N_{\epsilon,l,m}$ that defines a basis for $U$. Thats the point I get lost... I appreciate any help :)","['real-analysis', 'schwartz-space', 'functional-analysis', 'general-topology', 'metric-spaces']"
1591558,Nonconstant polynomials do not generate maximal ideals in $\mathbb Z[x]$,"Let $f$ be a nonconstant element of ring $\mathbb Z[x]$. Prove that $\langle f \rangle$ is not maximal in $\mathbb Z[x]$. Let us assume $\langle f \rangle$ is maximal. Then $\mathbb Z[x] / \langle f \rangle$ would be a field. Let $a \in \mathbb{Z}$. Then $a + \langle f \rangle$ is a nonzero element of this field, hence a unit. Let $g + \langle f \rangle$ be its inverse. Then $a g - 1 \in \langle f \rangle$, hence $ag(x)-1 = f(x)h(x)$ for some $h \in Z[x]$, hence $ag(0) + f(0)h(0) = 1$, thus $(a,f(0))=1$ for all $a \in \Bbb Z$, contradiction, hence the proof. Is my argument correct? Is there any other method?","['polynomials', 'abstract-algebra', 'proof-verification', 'maximal-and-prime-ideals', 'ring-theory']"
1591561,preservation of extreme points under linear transformation,"Suppose $\{e_1,...,e_N\}$ is the set of all extreme points of a compact convex subset $X\subset\mathbb R^n$.   $L: \mathbb R^n\to \mathbb R^m$ is a linear transformation. $L$ is surjective but is not injective. Let $Y= L(X)$. Would it hold that for every  $1\leq i\leq N$,   $L(e_i)$ must be an extreme point of  $Y$? Is there any   characterization on $L$ such that this property holds? Thanks.","['real-analysis', 'linear-algebra', 'linear-transformations', 'convex-analysis']"
1591571,"Which quantity is greater, $\frac{x^2}{y+\frac1y}$ or $\frac{y^2}{x+\frac1x}$?","$x \gt y$, $ xy \neq 0$ A= $ x^2\over {y+{1\over y}}$ B= $ y^2\over {x+{1\over x}}$ Options: 1) Quantity A is greater. 2) Quantity B is greater. 3) The two quantities are equal. 4) The relationship cannot be determined from the given information. By taking $x=2, y=1 $, I get $A\gt B$ , Thus options 2 and 3 are eliminated. By taking$ x=2, y=-1$ , I get $B\gt A$ , Thus option 1 is eliminated. So answer is option 4. But I am not satisfied with this solution by taking particular values of $x$ and $y$. Is there any other method to deal with this question? What should be proper tag for this?
I think it should be comparision but that is not available in tag list.So please edit it.","['algebra-precalculus', 'inequality', 'calculus']"
1591583,What does it mean to say that a vector is 'coordinate invariant'?,"In my lecture notes, it says that a vector is 'coordinate invariant' if it's properties do not depend on the choice of basis used to represent them. I understand that the basis of a vector space is a set of linearly independent vectors which span the vector space, but I'm struggling to interpret the given definition of coordinate invariance. If anyone could clear this up for me, perhaps with an example, that would be greatly appreciated.","['vector-spaces', 'calculus', 'multivariable-calculus', 'vectors', 'definition']"
1591586,"How to show that the Banach space $\left(C[a,b],\lVert.\rVert_{\scriptsize C[a,b]}\right)$ is not Hilbert space?","I want to show that  the Banach space $\left(C[a,b],\lVert.\rVert_{\scriptsize C[a,b]}\right)$ is not a Hilbert space. So I should show that it is not an inner product space. Most likely, The Parallelogram Equality does not work for some two elements of this space but I could not find these two elements. Thanks for your helps.","['functional-analysis', 'normed-spaces', 'hilbert-spaces', 'inner-products']"
1591620,Calculating a (Forward Measure) Martingale,"Above is my question. I am, unfortunately, stuck on part (a)! Below are my workings. I've just spotted a typo -- at one point, an ""$\exp$"" is missing, but it's fairly obviously supposed to be there. The only thing I can really think of is to apply Bayes' formula, but this really doesn't give me something that nice. I mean, there is a little bit of cancellation: the it with the typo cancels, but nothing else. Any advice would be most appreciated! As always, I'd only like assistance with the first part please! If you've seen my questions before, then you'll have seen some remark to this effect about wanting to learn maths not just be told answers, etc -- you know the drill. Sorry for not LaTeXing it -- didn't really fancy it as it would have likely taken ages! =P","['bayes-theorem', 'probability-theory', 'conditional-expectation', 'martingales']"
1591623,Why do I need absolute convergence to prove $\cos z=\frac{e^{iz}+e^{-iz}}{2}$?,"I'm reading Conway's Complex Analysis book and on page 38 he said we can manipulate the power series because they are absolute convergent: Let's see: Conway defines $$\cos z=1-z^2/2+z^4/24-\ldots$$ So, we know $$e^{iz}=1+iz-\frac{z^2}{2}-\frac{z^3i}{6}+\frac{z^4}{24}+\frac{z^5i}{120}\ldots$$
$$e^{-iz}=1-iz-\frac{z^2}{2}+\frac{z^3i}{6}+\frac{z^4}{24}-\frac{z^5i}{120}+\ldots$$ Now, lets call $e^{iz}=\lim_{n\to \infty}s_n=\lim_{n\to \infty}(a_1+a_2+\ldots+a_n)$ and $e^{-iz}=\lim_{n\to \infty}s_n'=\lim_{n\to \infty}(b_1+b_2+\ldots+b_n)$. Then, we have $$\cos z=\lim_{n\to \infty}(1/2(a_1+b_1)+1/2(a_2+b_2)+\ldots1/2(a_n+b_n))=\lim_{n\to \infty}(((1/2)a_1+(1/2)a_2+\ldots+(1/2)a_n))+((1/2)b_1+(1/2)b_2+\ldots+(1/2)b_n)))=1/2\lim_{n\to \infty}(a_1+a_2+\ldots+a_n)+1/2\lim_{n\to \infty}(b_1+b_2+\ldots+b_n)=(1/2)e^{iz}+(1/2)e^{-iz}=\frac{e^{iz}+e^{-iz}}{2}$$ I think I didn't use the fact the series $e^{iz}$ and $e^{-iz}$ are absolute convergent. Where am I wrong? what am I missing? EDIT Note that I'm using commutativity only in the finite case: $$\lim\sum_{k=1}^n(a_k+b_k)=\lim((\sum_{k=1}^n a_k)+(\sum_{k=1}^n b_k))=\lim(s_n+s_n')=\lim s_n+\lim s_n'$$. I need help Thanks!","['complex-analysis', 'real-analysis']"
1591636,"Prove if $A$ is hermitian and $A^m=I$, then $A^2=I$","Prove If $A_{n\times n}$ is hermitian over $\mathbb C$ and $A^m=I, m\in \mathbb N$, then $A^2=I$ In other words, we need to show that $A$ is unitary, since its hermitian $A=A^*$, then $A^2=A^*A=AA^*=I$. I don't know how to tackle this though, maybe somehow use that the polynomial $x^m-1$ annihilate $A$ and both it and $x^2-1$ and have a common root?","['matrices', 'linear-algebra']"
1591697,"Why zero is a multiple of every integer, but not a divisor of zero?","All positive and negative numbers including zero are called integers. So in the form $a=bq$, since $0 = 0ㆍq$ is true for any integer $q$, $0$ can have $0$ as a divisor of itself as well as a multiple of itself by the definition expressed by $a=bq$. But why it's said ""We cannot divide by $0$"" ? It's understood as ""$0$ cannot be a divisor"" to me. ""Definition: An integer a is called a multiple of an integer $b$ if $a=bq$ for some integer $q$. In this case we also say that b is a divisor of $a$ , and we use the notation $b | a$ . . . On the other hand, for any integer $a$, we have $0 = aㆍ0$ and thus $0$ is a multiple of any integer."" Source: Abstract Algebra: Third Edition, John A. Beachy, William D. Blair, p.4. ""Rule Division by $0$ is undefined. Any expression with a divisor of $0$ is undefined. We cannot divide by $0$"" Source: Prealgebra: A Text/Workbook, Charles McKeague, p.61. ""Observe that division by the integer $0$ is not defined, since for $n≠0$ there is no integer $x$ such that $0ㆍx=n$ and since for $n =0$ every integer $x$ satisfies $0ㆍx=0$"" Source: Introduction to Mathematical Proofs, Second Edition, Charles Roberts, p.99. [Now I understand my question more after reading number theory chapter of a book] $0=d\cdot 0 $ Thus, 0 is a multiple of every integer except 0.","['abstract-algebra', 'elementary-number-theory']"
1591701,How does Restricted Boltzmann Machine (RBM) try to model the distribution of data?,"An RBM is a non-directed graphical model that defines the distribution over some input vector X. I know it's going to model the distribution of that those vectors in my training data X using a layer of binary hidden units, but i don't understand if it's an unsupervised method, then what kind of information about the labeling of the data gives us the distribution? I would appreciate if someone could give a brief intuitive explanation about this.","['machine-learning', 'statistics', 'neural-networks']"
1591734,Why the octahedral axiom?,"My question is about the octahedral axiom (OA) in the definition of a triangulated category . For what I can understand so far (cf. Huybrechts, Fourier-Mukai in algebraic gometry , Definition 1.32), this axiom wants to roughly generalise the ""double quotient"" situation in the category of abelian groups, i.e. if $A\subset B\subset C$ are abelian groups then $C/B\cong(C/A)/(B/A)$. I would like to know why people think that this axiom is superfluous. I reported the ""double quotient"" situation because one may say that if it wants to generalise a situation which is natural in the non-generalised case, then one would expect this situation to be natural too. But it seems to me that this argument is too weak and probably there are better arguments... Moreover, is it true that everyone is convinced about that? As a motivation to this question I would like to say that: $1)$ last summer a paper by Maciocia appeared in which he proved the OA is a consequence of the previous ones. But unfortunately there was an error which is still not fixed. $2)$ In the Huybrechts book, I have cited before, he doesn't state the OA because he ""will never use it explicitely and only once implicitely"". $3)$ I am very curious about that. Thank you all! P.S.: I have tried to find something in the literature or in StackExchange as well but I was apparently unable. Sorry if it is a duplicate.","['category-theory', 'triangulated-categories', 'algebraic-geometry']"
1591751,Dual space of exterior power and exterior power of dual space,"Let $V$ be a finite-dimensional vector space. Is there an isomorphism between $\Lambda^k(V^\ast)$ and $\left(\Lambda^k(V)\right)^\ast$? I was able to prove this with the additional requirement of an inner product on $V$ (and thus subsequently on $\Lambda^k(V)$) via 
$$
\require{AMScd}
\begin{CD}
\left(\Lambda^k(V)\right)^\ast @>\mathcal{J}^{-1}>> \Lambda^k(V) @>\Lambda^kJ>> \Lambda^k(V^\ast)  
\end{CD}
$$
where $J: V \to V^\ast$ and $\mathcal{J}: \Lambda^k(V) \to \left(\Lambda^k(V)\right)^\ast$ are the isomorphisms given by the Riesz representation theorem and $\Lambda^kJ$ is the map given by $v_1\wedge \cdots \wedge v_k \mapsto J(v_1) \wedge \cdots \wedge J(v_k)$. Is there another way to identify these two spaces without the requirement of an inner product on $V$? I read Qiaochu Yuan's comment to his answer on a similar question but did not really understand it I fear. 
Thank you very much.","['exterior-algebra', 'linear-algebra', 'multilinear-algebra']"
1591766,Weak Limit of Measures Mutually Singular wrt Lebesgue Measure,"I'm stuck on the following qual problem: Let $\{h_{n}\}$ be a sequence of positive continuous functions on the unit cube $Q$ in $\mathbb{R}^{d}$ satisfying the following conditions: $\lim_{n\rightarrow\infty}h_{n}(x)=0$ $m$-a.e. ($m$ denotes the Lebesgue measure on $Q$) $\int_{Q}h_{n}dx=1$ $\forall n$ $\lim_{n\rightarrow\infty}\int_{Q}fh_{n}dx=\int_{Q}fd\mu$ for every continuous function $f$ on $Q$. Prove that $\mu\perp m$ or give a counterexample. My intuition suggests to me that $\mu\perp m$ since $h_{n}\rightarrow 0$ a.e. and therefore must become very large on sets of small Lebesgue measure; however, I'm struggling to prove my guess. My thought was to write the $\int_{Q}fd\mu=\int_{Q}fh dx+\int_{Q}fd\nu$, where $hdx+\nu=\mu$ is the Lebesgue decomposition of $\mu$ and then show that $h=0$ $m$-a.e, or equivalently $\int_{Q}fhdx=0$ for every continuous $f$. But I have been unable to do this. Any suggestions?","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
1591782,Subset of $\ell^2$ is precompact,"Suppose we have a sequence of $a_i$ with some restrictions on it. Which restrictions must be to make set $$A= \left\{(x_i) \in \ell_2 \mid \sum\limits_{i\geqslant1} |a_i x_i|^2 \leqslant 1 \right\} $$
precompact in $\ell_2$? I have spent a lot of time on solving that task, but I still have got no idea which restrictions I have to choose","['functional-analysis', 'lp-spaces', 'compactness', 'hilbert-spaces']"
1591828,Proving that the group of all roots of unity in a number field is finite cyclic,"I would be very grateful if someone would check my solution to the following problem. Let $K$ be a number field (i.e. a finite field extension of $\mathbb{Q}$). Let $G$ be the group of all roots of unity in $K.$ Claim. $G$ is a finite cyclic group. Here is my attempt at a solution: By definition $[K:\mathbb{Q}]$ is finite and this clearly implies that $G$ is finite. To show that $G$ is cyclic, we proceed by supposing otherwise. Let $g \in G$ be an element of maximal order, say $m.$ Since $G$ is not cyclic, there exists some $h \in G\setminus\langle g \rangle.$ Let $s$ be the order of $h.$ Then $s$ does not divide $m,$ otherwise $h^m=1$ and so $h \in \langle g \rangle$ (because $\{1,g,\ldots,g^{m-1}\}$ is the complete set of $m$th roots of unity in $K$). Therefore the order of $gh$ is equal to lcm$(m,s)$ and this is greater than $m.$ This is a contradiction!","['abstract-algebra', 'algebraic-number-theory', 'group-theory', 'proof-verification']"
1591830,Solving $\lim_{x\to+\infty}(\sin\sqrt{x+1}-\sin\sqrt{x})$ [duplicate],"This question already has answers here : Limit $\lim_{x \to \infty}{\sin{\sqrt{x+1}}-\sin{\sqrt{x}}}$ (4 answers) Closed 8 years ago . Do you have any tips on how to solve the limit in the title? Whatever I think of doesn't lead to the solution. I tried using: $\sin{x}-\sin{y}=2\cos{\frac{x+y}{2}}\sin{\frac{x-y}{2}}$ and I got:
$$\lim_{x\to+\infty}\bigg(2\cos{\frac{\sqrt{x+1}+\sqrt{x}}{2}}\sin{\frac{\sqrt{x+1}-\sqrt{x}}{2}}\bigg)=$$
$$\lim_{x\to+\infty}\bigg(2\cos{\frac{\sqrt{x+1}+\sqrt{x}}{2}\frac{\sqrt{x+1}-\sqrt{x}}{\sqrt{x+1}-\sqrt{x}}}\sin{\frac{\sqrt{x+1}-\sqrt{x}}{2}}\bigg)=$$
$$\lim_{x\to+\infty}\bigg(2\cos{\frac{1}{2(\sqrt{x+1}-\sqrt{x})}}\sin{\frac{\sqrt{x+1}-\sqrt{x}}{2}}\bigg)$$
but, as you can see, this leads me to $\infty-\infty$ in $\cos$ term. How can I get rid of that?","['trigonometry', 'limits']"
1591841,Which options are true for $f(z)=\frac{1}{z}$,"Consider $f(z)=\frac{1}{z}$ on the annulus $A= \{z\in \Bbb{C} | \frac{1}{2}<|z|<2\}$. Which of the following are true? There is a sequence $\{p_n(z)\}$ of polynomials that approximate $f(z)$ uniformly on compact subsets of $A$. There is a sequence $\{r_n(z)\}$ of rational functions, whose poles are contained in $\Bbb{C}\setminus A$ and which approximates $f(z)$ uniformly on compact subsets of $A$. No sequence $\{p_n(z)\}$ of polynomials approximate $f(z)$ uniformly on compact subsets of $A$. No sequence $\{r_n(z)\}$ of rational functions whose poles are contained in $\Bbb{C}\setminus A$ approximate $f(z)$ uniformly on compact subsets of $A$. I think options 2 and 3 are correct, 2 follows from Runge's theorem, but I don't know how to prove 3.",['complex-analysis']
1591845,How can I count solutions to $x_1 + \ldots + x_n = N$?,"I am interested in how many non-negative integer solutions there are to: $$x_1 + \ldots + x_N = B$$ where at least $K$ of the variables $x_1, \ldots , x_N \geq C$ For example when:
$B = 5, N = 3, K = 2, C = 2$ I want to count the solutions to: $$x_1 + x_2 + x_3 = 5$$ where at least $2$ of the variables are $\geq 2$. I found the total number of candidate solutions using the $\binom{B+N-1}{B} = 21$ However, only $9$ of them have two variables $\geq 2$. \begin{align*}
    2+0+3& =5\\
    2+1+2& =5\\
    3+0+2& =5\\
    1+2+2& =5\\
    3+2+0& =5\\
    0+2+3& =5\\
    0+3+2& =5\\
    2+3+0& =5\\
    2+2+1& =5
\end{align*} I feel there is a connection to the Associated Stirling numbers of the second kind. But I can't place it :( EDIT: Here is my code for enumerating them all to count the number of ways of select B elements from a set of N (uniformly with replacement), such that you have at least C copies of K elements - also shows the output for this question I'm asking here as it's the core piece. Obviously can't be run for very large values of the parameters - that's why I'm here :) Code is here Here is another example for B = 6, N = 3, C = 2 and K = 2 there are 16 solutions: \begin{align*}
0+2+4& = 6\\
0+3+3& = 6\\
0+4+2& = 6\\
1+2+3& = 6\\
1+3+2& = 6\\
2+0+4& = 6\\
2+1+3& = 6\\
2+2+2& = 6\\
2+3+1& = 6\\
2+4+0& = 6\\
3+0+3& = 6\\
3+1+2& = 6\\
3+2+1& = 6\\
3+3+0& = 6\\
4+0+2& = 6\\
4+2+0& = 6\\
\end{align*} There are a number of different and correct solutions below. I don't know which to accept.",['combinatorics']
1591853,"Is it true that $ \lim_{h \to 0} \frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0, y_0)?$","let $f: \mathbb{R}^2 \to \mathbb{C}$ be a continuous function. Let $(x_0,y_0) \in \mathbb{R}^2$ be a point in $\mathbb{R}^2$ such that both partial derivatives $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ exist at $(x_0,y_0)$ . Is is true that $$ \lim_{h \to 0} \frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0, y_0)?$$ I believe that this statement is true if we know that $f$ is $C^1$ in a neighborhood of $(x_0, y_0)$ , for then the mean value theorem tells us that $$\frac{f(x_0 + h, y_0 + h) - f(x_0 + h, y_0)}{h} = \frac{\partial f}{\partial y}(x_0+ h, \tilde{y}) $$ for some $\tilde{y}$ between $y_0$ and $y_0 + h$ , and this will converge to $\frac{\partial f}{\partial y}(x_0, y_0)$ as $h \to 0$ . But if $f$ is not $C^1$ then we don't have as much to work with. It seems that it may not be true in this case and we need to find a counterexample. Hints or solutions are greatly appreciated.","['derivatives', 'real-analysis', 'partial-derivative']"
1591869,Prove that $|f|\leq 1$ whenever $|x|\leq 1$.,"Let $f :\mathbb{R}^2\rightarrow \mathbb{R}^2 $ be everywhere differentiable such that the Jacobian is not singular at any point in $\mathbb{R}^2$. Assume $|f|\leq 1$ whenever $|x|=1$. Prove that $|f|\leq 1$ whenever $|x|\leq 1$. I think this is straight forward if we apply maximum modulus principle. But how may I prove it without using it? I tried to use Implicit function theorem by defining $g:\mathbb{R}^2\rightarrow \mathbb{R}$ by $g(x)=|f(x)|^2$, but no success. At least a hint is appreciated.","['multivariable-calculus', 'real-analysis', 'maximum-principle', 'implicit-function-theorem']"
1591882,What is the pointwise limit of the following function:,"What is the pointwise limit of:
$$f_n(x) = \begin{cases} n-n^2x & if &  0\leq x \leq\frac{1}{n} 
           \\0 & if & \frac{1}{n} \leq x \leq 1
     \end{cases} $$","['limits', 'calculus', 'analysis']"
1591903,Solving $\lim \limits _{x \to \infty} (\sqrt[n]{(x+a_1) (x+a_2) \dots (x+a_n)}-x)$ [duplicate],"This question already has answers here : How to find $\lim_{n \rightarrow +\infty } \left(\sqrt[m]{\prod_{i=1}^{m}(n+{a}_{i})}-n\right)$? (3 answers) Closed 8 years ago . $$\lim \limits _{x \to \infty}\bigg(\sqrt[n]{(x+a_1) (x+a_2) \dots (x+a_n)}-x\bigg)$$
We can see the limit is of type $\infty-\infty$. I don't see anything I could do here. I can only see the geometric mean which is the $n$-th root term. Can I do anything with it? Any tips on solving this?","['calculus', 'limits']"
1591906,What are the units of Z[x]? [duplicate],"This question already has answers here : Characterizing units in polynomial rings (3 answers) Closed 5 years ago . Where $\mathbb{Z}[x]$ is the ring of polynomials in $x$ with integer coefficients. The book I am studying says the unity of this ring is $f(x) = 1$ so then if some $p \in \mathbb{Z}[x]$ is a unit, this then must mean that $p^{-1} \in \mathbb{Z}[x]$, where $p \cdot p^{-1} = 1$, correct? Obviously then $f(x) = 1$ and $f(x) = -1$ are units, and I have seen elsewhere on the internet that people claim these are the only units of $\mathbb{Z}[x]$, but aren't simple one-term polynomials also units? That is, $\forall k \in \mathbb{Z}, f(x) = x^k$ is a unit because $(f(x) = x^k)^{-1} \Longleftrightarrow f(x) = x^{-k}$ and $x^k \cdot x^{-k} = 1$, no?","['ring-theory', 'polynomials', 'group-theory']"
1591911,Inverse Laplace transform of $\tan^{−1}\left(\frac{1}{s}\right)$,"I'm studying Laplace transformations, but I don't understand where $-\frac{1}{t}$ comes from. And what is the relationship between the corollary and the example?","['ordinary-differential-equations', 'linear-algebra', 'laplace-transform']"
1591918,"Is a function necessarily measurable, given that all of its level sets are measurable?","Let $f: \mathbb{R}^n \rightarrow \mathbb{R}$ be a function such that the set $$T_{\alpha} \equiv \{ x \in \mathbb{R}^n : f(x) = \alpha\}$$ is measurable $\forall \alpha \in \mathbb{R}$. Is $f$ measurable? Here's the proof I've sketched, but I'd like to know whether I'm on the right way or not. Since $T_\alpha$ is measurable $\forall \alpha \in \mathbb{R}$, the set $$T^{+}_{\beta} \equiv \mathbb{R}/\bigcup_{\alpha = \beta}^{+\infty}T_{\alpha} = \{x \in \mathbb{R} : f(x) < \beta\}$$ is also measurable $\forall \beta \in \mathbb{R}$, therefore $f$ is measurable.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1591937,Why are the quaternions not an algebra over the complex numbers?,I just began to study about algebras over rings and quickly came across the fact that the quaternions are not an algebra over the complex numbers. I would prefer an answer as elementary as possible.,"['abstract-algebra', 'ring-theory']"
1591947,Relatively hyperbolic groups,"A group $G$ is relatively hyperbolic relative to a collection of subgroups $\mathcal{G}$ , if $G$ admits an
action on a connected graph, $K$ , with the following properties: (1) $K$ is hyperbolic, and each edge of $K$ is contained in only finitely
many circuits of length $n$ for any given integer, $n$ , (2) there are finitely many $G$ -orbits of edges, and each edge stabiliser
is finite, (3) the elements of $\mathcal{G}$ are precisely the infinite vertex stabilisers of $K$ ,
and (4) every element of $\mathcal{G}$ is finitely generated. This is taken from Bowditch . There are other equivalent definitions, and an inequivalent definition (though groups satisfying the latter are now usually called weakly relatively hyperbolic ). I have two questions about relatively hyperbolic groups . They sound elementary, but I haven't seen an explicit answer in, for example, papers by Farb or Bowditch. Is a free product of finitely many relatively hyperbolic groups itself relatively hyperbolic (relative to the collection of given parabolic subgroups)? If $G$ is hyperbolic relative to non-trivial subgroups $H_1,\ldots,H_n$ , and each $H_i$ is a subgroup of $H_i'$ , is $G$ hyperbolic relative to $H_1',\ldots H_n'$ ? (Assuming that $H_i'\cap H_j'$ is trivial for $i\neq j$ .)","['group-theory', 'geometric-group-theory']"
1591966,Why is $\infty$ a ramification point of a hyperelliptic curve when the defining equation has odd degree?,"We can work over $\mathbb{C}$ for simplicity. Let $X$ be defined by the equation $y^2 = h(x)$ where $h(x)$ has odd degree and distinct roots. Let $\pi: X \to \mathbb{P}^1$ be the ramified double covering. Just to make sure, the roots of $h(x)$ are ramification points because if $y = 0$, then we get each root having multiplicity two, correct? But this argument doesn't really shed light on why there is another ramification point outside of the roots when $h$ has odd degree. Which point in $X$ maps to the point at $\infty$, and why is it a ramification point? Why isn't this a ramification point when $h(x)$ has even degree? Edit: I would like an explanation without using the Riemann-Hurwitz formula since the text I am reading counts the ramification points to compute the genus of the curve.",['algebraic-geometry']
1591973,Circle Packing in an Elastic Container,"A (somewhat) common problem in geometry and optimization deals with how to most efficiently pack $n$ rigid disks inside a given container of some fixed size and shape (e.g. a circular container, a rectangular container, etc). I'm curious whether any work has been done on the question of circle packing in a container with an elastic boundary, the shape of which is allowed to vary. It seems to me that, if we allow a collection of circles to be enclosed in an elastic container, the most efficient packing should be the packing that minimized the stretching of the elastic - i.e. its perimeter. The question, then, can be stated: Given a collection of $n$ unit disks, find a placement of the disks and a closed piecewise smooth curve such that None of the disks overlap Every disk is enclosed by the curve The length of the curve is minimized Obviously, this is a very difficult problem, so I don't expect any solutions below. However, I'd be grateful for any references on existing work on this question (if any exist).","['packing-problem', 'optimization', 'geometry']"
1591975,Radon measure determined by the intersection of half lines in the plane,"Consider a vector $r$ in the euclidian plane $\mathbb R^2$ and two unit vectors $u,v\in\mathbb U$ ($\mathbb U$ is the unit circle). Let $s>0$ be a real number. I am looking for an expression of the following distribution on $\mathbb R^2\times\mathbb R^+\times\mathbb U\times\mathbb U$
$$\mu(r,s,u,v)=\int_0^s \delta^{(2)}(r-tu+(s-t)v)\mathrm dt\tag1$$
where $\delta^{(2)}$ is a 2-dimensional Dirac distribution, which is defined by $\delta^{(2)}((x,y))=\delta(x)\delta(y)$.
I exclude the cases $u=v$ and $u=-v$. Here is what I have done so far. It's detailed and hence rather long... I have considered the following problem : there are two points $A$ and $B$
from where start two half lines with unit vectors $u$ and $v$ (see the figure below) and such that $\overrightarrow{AB}=r$. The half-lines can cross, but under a condition that is to be determined.
A point on the half-line $(A,u)$ is of the form $A+xu$ with $x\geq0$. Similarly a point on $(B,v)$ is of the form $B+yv$, with $y\geq0$. The intersection is given by the equation $A+xu=B+yv$, $$xu=r+yv\tag2.$$
If we write (2) as $r-xu+yv=0$, we see that problem (1) is related to the intersection equation (2) with the extra condition $x+y=s$. As the vectors $u$ and $v$ are not colinear, it is possible to solve (2) by taking the scalar products with both $u$ and $v$ :
$$\left\{\begin{array}{ccccc}
x&=&r\cdot u&+&y\,u\cdot v\\
x\,u\cdot v&=&r\cdot v&+&y \end{array}\right.$$
We get
$$x=\frac{r\cdot u-(r\cdot v)(u\cdot v)}{1-(u\cdot v)^2}\qquad 
y=\frac{r\cdot v-(r\cdot u)(u\cdot v)}{1-(u\cdot v)^2}.\tag3$$
and we conclude that the half-lines intersect if $r\cdot u\geq(r\cdot v)(u\cdot v)$ and $r\cdot v\geq(r\cdot u)(u\cdot v)$. If these conditions are
not fulfilled, the integral (1) vanishes. Supposing these conditions are satisfied, we can see that we have to impose
$x+y=s$ which can simplified into
$$r\cdot u+r\cdot v-(1+u\cdot v)s=0.\tag4$$ 
Interestingly the conditions $x\geq0$ and $y\geq0$ expressed with (3) and  combined with the condition (4) give $s-r\cdot u\geq0$ and $s-r\cdot v\geq 0$. From there I am not so sure: I have tried to write $\mu$ as 
$$\mu(r,s,u,v)=f(r,s,u,v)\delta\big(r\cdot u+r\cdot v-(1+u\cdot v)s\big)\Theta(s-r\cdot u)\Theta(s-r\cdot v)\tag5$$
where $f$ is a regular function ($\Theta$ is the Heaviside step function).
I have integrated this expression with respect to $v$
and obtained
$$\int\mu(r,s,u,v)\mathrm dv=2f(r,s,u,v_1)\frac{\Theta(s-|r|)}{\sqrt{r^2-(r\cdot u)^2}}$$ where $v_1$ is such that $(r-su)\cdot v_1=s-r\cdot u$. I have also integrated (1) with respect to $v$ and got
$$\int\mu(r,s,u,v)\mathrm dv=\frac{\Theta(s-|r|)}{s-r\cdot u}.$$
I am wondering if I can
deduce $f(r,s,u,v)$ from these computations. Can anyone (who went throught all of this) give me a little hint ? Thanks.","['dirac-delta', 'lebesgue-integral', 'measure-theory']"
1591983,Weakly convergence but not strongly - properties of limsup and liminf,"Let $X$ be a Banach space and suppose we have a sequence $\{x_n\}$  which is convergent weakly but not strongly. Define 
$y_n:=\sum\limits_{k=1}^{n}x_k$. What we can say about $\limsup\limits_{n\to\infty} \|y_n\|^{\frac{1}{n}}$ and $\liminf\limits_{n\to\infty}\|y_n\|^{\frac{1}{n}}$ ?","['functional-analysis', 'limsup-and-liminf', 'banach-spaces', 'weak-convergence']"
1591995,Inequivalent Hilbert norms on given vector space,"Suppose we have a vector space $X$. Let $\|\cdot\|_1$ and $\|\cdot\|_2$ be two different complete norms on $X$ s.th. $X$ equipped with $\|\cdot\|_j, \ j\in\{1,2\}$ is a Hilbert space. Are there simple examples of such norms, which are inequivalent ? This question arises from this discussion.","['functional-analysis', 'hilbert-spaces']"
1592019,Proving the limit,"I have to prove that:$$\lim_\limits{x\to\infty}\bigg(\frac{n}{\frac{1}{x+a_1}+\frac{1}{x+a_2}+\cdots+\frac{1}{x+a_n}}-x\bigg)=\frac{a_1+a_2+\cdots+a_n}{n}$$
The way I started doing this is:
$$=\lim_\limits{x\to\infty}\left(\frac{n}{\frac{(x+a_1)(x+a_2)\cdots(x+a_n)\sum_{i=1}^{n}\big(\frac{1}{x+a_i}\big)}{(x+a_1)(x+a_2)\cdots(x+a_n)}}-x\right)$$
Then I combine $x$ with the rest, but that leads me nowhere. Any tips on how to do this? Taylor expansion cannot be used.",['limits']
1592046,How can the zero ring be an initial object in the category of schemes?,"The spectrum of the zero ring is the empty set, right?  Prime ideals of a ring must be proper ideals.  So a morphism to a scheme $(X, \mathcal O_X)$ from the affine scheme corresponding to $0$ would include on the underlying spaces a continuous function $f$ from the empty set to $X$.  But there is no such function $f$.  So it seems like there wouldn't be any morphisms whatsoever from the affine scheme of the zero ring to the given scheme.",['algebraic-geometry']
1592062,Is This a Proof of Multiplication On The Parabola?,"I am a high school student who is beginning to look at proofs and I was wondering if this could be considered a proof for a property of multiplication of points on a parabola. I've seen this result before online but I haven't seen a formal proof of it using this method. This is my first time attempting a proof on my own so any advice would be appreciated. Theorem: Given the function $f(x) = x^{2}$, the line which passes through points A and B which lie on the graph of $f$ has the $y$-intercept $-(A_{x}B_{x})$ if $A_{x} < B_{x}$ first it is clear that: $$f(A_{x}) = A_{y} = A_x^{2} \quad \& \quad  f(B_{x}) = B_{y} = B_x^{2}$$ The slope of the line joining A & B will be: $$m = \frac{B_{x}^{2}-A_{x}^{2}}{B_{x}-A_{x}}$$ The numerator is a difference of squares; thus the whole expression can be simplified to: $$m = B_{x}+A_{x}$$ Then choose one point (A or B) and sub this value into the equation of a line and solve for b: $$A_{x}^{2} = (B_{x}+A_{x})A_{x}+b$$
$$-(A_{x}B_{x}) = b$$ and since $A_{x}$ will always be negative if non-zero and $B_{x}$ will always be positive if non-zero ; this is equivalent to saying $-A_{x}B_{x}$ QED.","['algebra-precalculus', 'proof-verification', 'quadratics']"
1592065,Volume Integral of this set,"I'm not sure about this exercise. Be: $$E=\left\{(x,y,z) \in \mathbb{R^3} : x\geq 0, y\geq 0, 0\leq z\leq \frac{1}{\sqrt{x^2+y^2}}-1\right\}$$ Find: $$\int_{E} z\, \max\{x,y\}\: dx \, dy \, dz$$ My idea is that since $x,y\geq 0$, one of the two variables will be greater than the other in a section of the quadrant divided by the bisector and vice versa. For example, let's suppose that $x\geq y$, the  section of the volume would be something like:
$$\left\{(x,y,z)\in \mathbb{R^3}  : 0\leq x\leq \infty, 0\leq y\leq x,0\leq z\leq \frac{1}{\sqrt{x^2+y^2}}-1\right\}$$
The volume of this would be:
$$\int_0^\infty\int_0^x\int_0^{\frac{1}{\sqrt{x^2+y^2}}-1} zx\: dz\, dy\, dx$$ 
Then the volume of $E$ would be this volume plus the volume of the case where $y\geq x$, does this look correct to you?","['multivariable-calculus', 'integration', 'volume', 'calculus']"
1592140,When the product of dice rolls yields a square,"Succinct Question: Suppose you roll a fair six-sided die $n$ times. What is the probability that the product of the rolls is a square? Context: I used this as one question in a course for elementary school teachers when $n=2$ , and thought the generalization might be a good follow-up question for secondary school math teachers. But I encountered quite a bit of difficulty in tackling it, and I am wondering if there is a neater solution than what I have already seen, and to what deeper phemonena it connects. Known: Since the six sides of a die are $1, 2, 3, 2^2, 5,$ and $2\cdot3$ , the product of the rolls is always of the form $2^{A}3^{B}5^{C}$ , and the question is now transformed into the probability that $A, B, C$ are all even. The actual ""probability"" component is mostly for ease of phrasing; its only contribution is a $6^n$ in the denominator, and my true question is of a more combinatorial nature: namely, In how many ways can the product of $n$ rolls yield a square? One approach that I have seen involves first creating an $8 \times 8$ matrix corresponding to the eight cases around the parity of $A, B, C$ ; one can then take the dot product of each roll with this matrix, and hope to spot a pattern. In this way, one may discover the formula: $$\frac{6^n + 4^n + 3\cdot2^n}{8}$$ and the ""probability"" version is simply this formula with another $6^n$ multiplied in the denominator. As for proving this: Some guesswork around linear combinations of the numerator yields a formula for each of the eight cases concerning $A,B,C$ parity, and one can then prove all eight of them by induction. And so I ""know"" the answer in the sense that I have all eight of the formulae (and the particular one listed above is correct) but they were not found in a particularly organized fashion. My Actual Question: What is a systematic way to deduce the formula, given above, for the number of ways the product of $n$ rolls yields a square, and to what deeper phenomena does this connect?","['number-theory', 'markov-chains', 'generating-functions', 'combinatorics', 'linear-algebra']"
1592163,Valuations coming from Prime Divisors,"I'm trying to understand where the valuation defined by a prime divisor on an integral, Noetherian separated scheme regular in codimension 1 comes from. In particular, I'm looking at this example: $X = \text{Spec}( \mathbb{C}[x,y,z,w]/(xw-yz))$ and $D= V(x,y)$, the prime divisor corresponding to $x=0$ and $y=0$. There are two descriptions I've seen of this valuation: one is that $D$ has a generic point $\eta$ (which corresponds here to the minimal prime  $(x,y)$ here in $D$). Then the valuation $v_D$ is the valuation on $\mathcal{O}_{X,\eta}$, a DVR. So in this case $\mathcal{O}_{X,\eta}= \left(\frac{\mathbb{C}[x,y,z,w]}{(x,y)}\right)\bigg|_{(x,y)} \cong \mathbb{C}[z,w]|_0 = \mathbb{C}(z,w)$. This is a field then with maximal ideal $0$  - so the valuation of $z$ and $w$ are 0 are units and the valuation of $x$ and $y$ are undefined (as they are 0). Is this right? However, I saw another description which had us consider $U$ open for which $D \cap U \neq \emptyset$. Then we apparently would have $D \cap U = \text{Spec} (\mathbb{C}[x,y,z,w]/(xw-yz) / P)$ for some prime ideal $P$ and then we have that $\mathbb{C}[x,y,z,w]/(xw-yz) / P$  localised (at 0?) gives us a DVR with a valuation on it. This I find even more confusing. Could somebody clarify if my calculation above is correct? Could you also explain the second description please?","['schemes', 'algebraic-geometry']"
1592198,What is the intersection of these two cylinders?,"$$0\le x^2 + z^2 \le 1$$ $$0 \le y^2 + z^2 \le 1$$ I want to compute the volume of the intersection. Sketching it out on paper is sort of nice: I see cross-sections that are disks, the first cylinder, the y-coordinate is free to vary, and for the second cylinder, the x-coordinate is free to vary. The intersection, I would guess, seems to be something spherical. So how can I pin down the actual set of points? Well, one thing I thought of was to try to manipulate both inequalities to make use of the equation of a sphere, so I try looking at these inequalities instead: $$y^2\le x^2 + y^2 + z^2 \le 1 +y^2$$ $$x^2 \le x^2 +y^2 + z^2 \le 1+x^2$$ Am I heading in the right direction?  Where can I go from here? Thanks,","['real-analysis', 'volume', 'calculus', 'multivariable-calculus', 'integration']"
1592247,Understanding purpose of dual vector space,"I am a beginner in differential geometry and have questions/confusion about dual vector space. I took a look at this and this questions. But both did not resolve my question. We have standard definition of a dual vector space as: Let $G,H$ are real vector spaces, we define vector space of all linear
   maps $ f : G \rightarrow H$. Dual space $G^*$ is defined as $G^*: G
 \rightarrow \mathbb R$ Sometimes notation $HOM(G,H)$ is used to indicate vector space of all linear maps. Does this have to do with homomorphism? Can someone comment what is role of homomorphism here? When $G,H$ are both real vector spaces, why can't we say dual space $G^*$ is   $G^*: G \rightarrow H$? I did not understand the purpose of defining another vector space mapping from original vector space to space of real numbers. I can guess, one such purpose is for non Cartesian coordinate systems. We have a vector as $ \overline{ a} = a_{i}e^i = a^je_j$. Here $e^i,e_j$ are dual basis vectors. Is this the purpose for dual vector space? I appreciate any inputs and thanks in advance!","['abstract-algebra', 'differential-geometry', 'linear-algebra']"
1592249,What is $\mathbb R^{\mathbb R}$ as a vector space?,"In Sheldon Axler's Linear Algebra Done Right third edition the following is given as an example of a subspace: The set of differentiable real-valued functions on $\mathbb R$ is a subspace of $\mathbb R^{\mathbb R}$ I'm looking for an intuitive explanation of the statement? Letting $S$ be the set of all differentiable real-valued functions, in order for the statement to be true, $S$ must be a subset of $\mathbb R^{\mathbb R}$(a subspace needs to be a subset). - How can $S \subset \mathbb R^{\mathbb R}$ when $S$ is a set containing functions and  $\mathbb R^{\mathbb R}$ is a set containing real numbers? - What are the elements in $\mathbb R^{\mathbb R}$? How can we think of $  \mathbb R^{\mathbb R}$ as a tuple?","['linear-algebra', 'vector-spaces']"
1592273,Rather weird integral,"I've reached a pretty weird integral
$$\int_0^{5} \frac{\ln(y)}{(y+3)\sqrt{y}} dy,$$
And I'm having some difficulties starting from the
$u$-substitution method. I had the intuition that
I may take $\sqrt{y} = u$ and thus $\frac{1}{2\sqrt{y}}dy = du.$
However, this method seems to get tangled with the issues related
to the natural log in the numerator. I felt that I could start on
integration by parts, but then I thought that there may be a cleaner
method with partial fractions. Could someone give me some suggestions
on either method in this problem?","['integration', 'calculus']"
1592283,Algebra 2 - Find Domain and Range of Function and Its Inverse,"$f(x)=-x^2+1$ For some reason, the inverse $f^{-1}$ gives me a domain equal to 1 or less than with a range of all real #'s. But the domain of the original function f(x) can only be negative. As squaring the x will only give positive numbers coupled with a negative sign on the outside making them negative. Is there a discrepancy with the book here?","['algebra-precalculus', 'functions', 'inverse']"
1592295,How to test a collection of samples are sampled with replacement or not?,"A box is full of balls with $m$ different colors, and for each color, there are $n$ balls. So the total number of balls is $m*n$. Note that $m$ is unknown, $n$ is already known, and balls can only be distinguished by the color. Now, if one draws $N$ samples from the box with replacement or without replacement, how can I know whether the sample is drawn with replacement or not? any hypothesis test to tackle it? Thanks! To make the question clearer: What I am concerned is that how to measure the degree that the current samples are drawn with replacement. It might be a function $f$, which takes the samples $\{x\}$, $m$, and $n$ as inputs. If $f(\{x\}, n, m) = 1$, then the sampling process is sampling with replacement; If $f(\{x\}, n, m) = 0$ , then the sampling process is sampling without replacement. Other values between 0 and 1 describe the likelihood that the sampling process is with replacement.","['statistics', 'sampling', 'hypothesis-testing', 'statistical-inference']"
1592296,"Show that this integral converges,","Show that $$\int_1^{\infty}\int_1^{\infty}\cdots\int_1^{\infty} \frac{{\rm d}x_1\cdots {\rm d}x_n}{x_1^{\alpha_1} + \ldots + x_n^{\alpha_n}} < \infty$$ if $\frac{1}{\alpha_1} + \ldots + \frac{1}{\alpha_n} < 1 $ I'm guessing that, to make use of the inequality assumption given in the problem statement, I should look to make a change of variables. Any ideas are welcome. Thanks!","['real-analysis', 'calculus', 'multivariable-calculus', 'integration', 'convergence-divergence']"
1592297,finiteness of the number of conics on a hypersurface,"In an exercise of ""Rational & Nearly Rational Varieties"", I want to show a certain hypersurface contains only finite number of conics passing through a point. The hypersurface $X$ and the point $x$ are given by
$X: x_0^n-x_1x_2\cdots x_n$, $x=(1:1:\cdots:1)$. My first attempt is to parametrize the conics as follows.
$(x:y)\mapsto (a_0x^2+b_0xy+y^2:a_1x^2+b_1xy+y^2:\cdots:a_nx^2+b_nxy+y^2)$ However, after that, naive dimension counting does not give an answer, because even when the number of restrictions are bigger than the dimension of variables, they might not intersect properly. Could anyone give me a hint to attack this problem correctly?","['algebraic-geometry', 'birational-geometry']"
1592316,Expected number of steps to finish all the cookies,"Please help on this question: Steve has 256 cookies. Each cookie has a label that is a distinct subset of $\{1,2,3,4,5,6,7,8\}$. At each step, Steve chooses a cookie randomly and eats it as well as all othe cookies whose label is a subset of the chosen one. What is the expected number of steps Steve takes before finishing all the cookies? All I could find was that he should anyway eat the root cookie with the $\{1,2,3,4,5,6,7,8\}$ to finish the game. But the probability to choose it depends on what kind of cookies he has chosen before he grabs the final one, and I have no idea how to tackle it. Thanks. I tried to see what happens for a much simplified case. If Steve has 4 cookies that are subsets of {$1,2$}, the possible cases are: \begin{align}
&\emptyset\rightarrow\{1\}\rightarrow\{2\}\rightarrow\{1,2\}&=4\times\frac14\times\frac13\times\frac12\\
&\emptyset\rightarrow\{2\}\rightarrow\{1\}\rightarrow\{1,2\}&=4\times\frac14\times\frac13\times\frac12\\
&\emptyset\rightarrow\{1\}\rightarrow\{1,2\}&=3\times\frac14\times\frac13\times\frac12\\
&\emptyset\rightarrow\{2\}\rightarrow\{1,2\}&=3\times\frac14\times\frac13\times\frac12\\
&\emptyset\rightarrow\{1,2\}&=2\times\frac14\times\frac13\\
&\{1\}\rightarrow\{2\}\rightarrow\{1,2\}&=3\times\frac14\times\frac12\\
&\{1\}\rightarrow\{1,2\}&=2\times\frac14\times\frac12\\
&\{2\}\rightarrow\{1\}\rightarrow\{1,2\}&=3\times\frac14\times\frac12\\
&\{2\}\rightarrow\{1,2\}&=2\times\frac14\times\frac12\\
&\{1,2\}&=1\times\frac14\\
\end{align} that sums up to $\cfrac94$.",['probability']
1592338,Hom / tensor adjunction for $O_X$ modules?,"Does the hom-tensor adjunction hold for $O_X$ modules also? With sheaf hom and sheaf tensor product, the statement would consist of a natural transformation $Hom_O (M \otimes_O N, K)\cong_{nat} Hom_O(M, Hom_O(N, K))$, $O = O_X$ is the structure sheaf and $M,N,K$ are sheaves of $O_X$ modules. If true I think I can check this by hand, by describing sheaves in terms of compatible germs, defining this adjunction on the germs and checking that they glue together. It is easier in the quasi-coherent sheaves on a scheme case because then one can just work in an affine cover and the distinguished base. I am little bit concerned that one might need a finite presentation hypothesis somewhere, in order for $Hom$ to localize well. ($Hom_{R[S^{-1}]}(M[S^{-1}], N[S^{-1}]) \cong Hom_R(M,N)[S^{-1}]$ needs $M$ finitely presented.)","['category-theory', 'algebraic-geometry', 'commutative-algebra']"
