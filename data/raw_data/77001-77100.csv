question_id,title,body,tags
974928,What is $\{v_0:(\lnot(v_0=v_0))\}$?,"I'm going through this set of notes to try to learn a bit more about set theory, because, while I've often encountered papers that use concepts from set theory, I've never actually studied it. I'm reading over the section on classes, and there are two examples, which are supposedly well known: $\{v_0:(v_0=v_0)\}$ and $\{v_0:(\lnot(v_0=v_0))\}$. The first one seems like it contains everything that is equal to itself, but I'm not entirely sure what the second one is. Is it just the empty set, or some empty class that's similar to the empty set, but is a class instead of a set?",['elementary-set-theory']
974936,There exists x on closed interval such that f(x)=x,"If $f$ is a continuous function on a closed interval, how can I show that there exists some $x$ on $f$ that $f(x)=x$? I know it will require the Intermediate Value Theorem. Initially I thought of letting $g(x)=f(x)-x$, and showing that there exists $x$ such that $g(x)=0$ implying $f(x)=x$, but don't have any information about $f$ on either end of the interval.","['fixed-point-theorems', 'continuity', 'real-analysis']"
974960,"If $x=t^2\sin3t$ and $y=t^2\cos3t$, find $\frac{dy}{dx}$ in terms of $t$","If $x=t^2\sin3t$ and $y=t^2\cos3t$, find $\frac{dy}{dx}$ in terms of $t$. This is how I tried solving it: $$
\frac{dx}{dt} = 2t\sin3t + 3t^2\cos3t \\
\frac{dy}{dt} = 2t\cos3t - 3t^2\sin3t \\
\frac{dy}{dx} = \frac{2t\cos3t - 3t^2\sin3t}{2t\sin3t + 3t^2\cos3t} 
$$ But the answer listed is: $$
\frac{2-3t\tan3t}{2\tan3t+3t}
$$ Is my answer incorrect, or can I simplify it even more?","['trigonometry', 'parametric', 'calculus']"
974972,Intiutive argument that $\exp' = \exp$,"Is there any intuitive argument or visual ""proof"" that $\exp' = \exp$? Suppose you have defined the Euler number $\mathrm{e}$ as limit of the sequence $(a_n)$ where $a_n = \left (1 + \frac{1}{n} \right)^n \quad \forall n > 0$, and that the $\exp(x)$ is introduced as $\mathrm{e}^x$. The use of the power series of $\exp$ should be avoided.","['education', 'exponential-function', 'derivatives', 'analysis']"
974973,Continuous function with continuous one-sided derivative,"Simple example of the absolute value function $x \mapsto |x|$ on $\mathbb{R}$ shows that it is possible for a continuous function to posses both the right-hand and the left-hand side derivatives and still not being differentiable on $\mathbb{R}$. I was wondering if it is possible to assume something about one of the one-hand side derivatives to obtain differentiability. The obvious came to my mind: Is it true that if a continuous function $f \in C(\mathbb{R})$ has left-hand-side derivative $f_{-}^{'}$ that is continuous on $\mathbb{R}$, then the function $f$ is differentiable?","['continuity', 'derivatives', 'real-analysis']"
974989,Do these limits commute?,"Given a sequence of functions $f_{n,m}:\mathbb{R}^{n} \to \mathbb{R}$, suppose that $$\displaystyle\lim_{m} f_{n,m}(x)$$ exists almost everywhere (for any fixed n) and also suppose that $$\displaystyle\lim_{n} f_{n,m}$$ exists in norm $L^p$(for any fixed $m$). I would like to know if the iterative limit commute, that is, if $$\displaystyle\lim_{n}\lim_{m} f_{n,m}(x) = \displaystyle\lim_{m}\lim_{n} f_{n,m}(x)$$ almost everywhere (where the limit in the index $n$ is again understood as a $L^p$ limit and the limit in the index $m$ is understood as a limit almost everywhere). If not, which are the sufficient conditions for this to happen? Thanks in advance.","['normed-spaces', 'real-analysis', 'analysis', 'lp-spaces', 'limits']"
974998,Regarding functions from R² to R: continuity and differentiability,"Let $f : U \rightarrow \mathbb{R}$ where $U \subseteq \mathbb{R}^2$ is an open set and $P \in U$. I am almost sure the following statements are correct, but please confirm: The only requirement for $f$ to have a tangent plane at $P$ is: $\exists \  \nabla f(P)$ (in other words, both $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ exist at $P$. Edit: the partial derivatives must be continuous! If the tangent plane exists, still not necessarily the function is continuous at $P$. The statement 2 is reverse order: if the function is continuous at $P$, still not necessarily the tangent plane exists. If the function happen to be continuous at $P$, still not necessarily the function is differentiable at $P$. And now, assuming those are correct, my main question comes: If $f$ is continuous at $P$, and $f$ has a tangent plane at $P$, is it possible that $f$ still is not differentiable? I might have misunderstood what my teacher said, but it seems that the answer is yes! If you agree, can you provide at least one example? Thank you! EDIT (Six months later): This question awarded me the Tumbleweed badge and even after six months there hasn't been any answers, comments or even votes! Today something made me remember of this question. Fortunately, I already made some progress: I was able to confirm the statements 1, 3 and 4. I couldn't confirm statement 2 yet, and my main question also still stands (I put it in italic above). Thanks for any help. EDIT 2 (May 28): Thanks for the attention. I have felt the need to quote James Stewart in his definition of tangent plane: Suppose f has continuous partial derivatives. An equation of the tangent plane to the surface $z = f(x, y)$ at the point $P(x_0, y_0, z_0)$ is
  $$z - z_0 = f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0)$$ Therefore, Stewart needs only continuous partial derivatives to define the tangent plane. This shows that I was wrong about my statement 1 . I have edited it now, adding the ""must be continuous"" requirement. This doesn't change any of my other thoughts though (yet). I would like to emphasize that I am considering any weird function you could come up with, not just real life functions and such. In this question I am looking for properties that will formally apply in any case. If anyone disagrees that statements 1, 3 and 4 are true please comment for further discussion (maybe I did miss something!). Now I'll try to give an example of what makes me believe in statement 2: Please correct me if I'm wrong! Take this weird function: $$ f(x, y)=\begin{cases}
    0, & \text{if $x = 0$ or $y = 0$}.\\
\\
    1, & \text{otherwise}.
  \end{cases} $$ Hopefully, if I'm not mistaken, this function is an example that shows that my second statement is true. (please let me know if I'm mistaken). Assuming everything is fine by now, don't forget of my main question: If $f$ is continuous at $P$, and $f$ has a tangent plane at $P$, is it possible that $f$ still is not differentiable?","['differential', 'multivariable-calculus', 'continuity', 'partial-derivative']"
975034,Evaluating limit of $0/0$ form,"I am given a quadric equation such that $ax^2 + bx +c=0$ whose roots are $\alpha$ and $\beta$ then what would be value $$\lim\limits_{x \to \alpha} \frac{1-\cos( ax^2 + bx +c) }{(x-\alpha)^2}$$
Now since $x$ is tending to root of input in $\cos$ so my limits become $0/0$ form so I applied L'Hospital Rule hence my limit becomes $$\lim\limits_{x \to \alpha} \frac{\sin( ax^2 + bx +c).2ax +b }{2(x-\alpha)}$$ now since $\alpha$ and $\beta$ are roots hence my expression can be written as $$\lim\limits_{x \to \alpha} \frac{ (x-\beta ) \sin( (x-\alpha)(x-\beta))(2ax +b)}{2(x-\alpha) (x-\beta ) }$$ now it becomes of form $\frac{\sin x}{x}$ when $x$ approaches $0$  so finally I reach $$\lim\limits_{x \to \alpha} \frac{(2ax +b)(x-\beta )}{2}$$ which finally becomes   $$ \frac{(2a\alpha +b)(\alpha-\beta )}{2}$$
But my answer does not matches , what did I do wrong?",['limits']
975062,Curvature of curve not parametrized by arclength,"If I have a curve that is not parametrized by arclength, is the curvature still $||\gamma''(t)||$? I am not so sure about this, cause then we don't know that $\gamma'' \perp \gamma'$ holds, so the concept of curvature might not be transferable to this situation. So is this only defined for curves with constant speed?","['curves', 'differential-geometry', 'curvature', 'real-analysis', 'analysis']"
975069,The inverse of AR structure correlation matrix / Kac-Murdock-Szegő matrix,"I want to find the inverse of the following matrix: $$ R_{k-1} = 
   \begin{pmatrix}
    1 &\rho &\rho^2 & \dots &\rho^{k-2} \\
    \rho &1 &\rho   & \dots  &\rho^{k-3} \\
    \rho^2 &\rho &1 & \dots&\rho^{k-4} \\
    \vdots &\vdots &\vdots &\ddots &\vdots\\ 
    \rho^{k-2} & \rho^{k-3} & \rho^{k-4} & \dots & 1\end{pmatrix}$$ Let $A_{i,j}$ be the $i,j$ minor of $R_{k-1}$ . By considering the pattern of the above matrix and its symmetrical properties, we can conclude that: $\det(A_{11})  = \det(A_{k-1,k-1})= |R_{k-2}|$ $\det(A_{i,j}) = \det((A_{j,i})^T)$ $\det(A_{i,j}) = 0$ for $|i-j|\le2$ which means that the inverse of $R_{k-1}$ is a tridiagonal symmetric matrix. I've tried to find the inverse using the fact I've described above and using $A^{-1}A=A A^{-1}=I$ . But I couldn't find it, since there are more variables than equations. Did i miss something?
or may be is there any other easier way to find the inverse?","['matrices', 'linear-algebra', 'inverse', 'correlation', 'toeplitz-matrices']"
975134,Solving recurrence -varying coefficient,"How can one find a closed form for the following recurrence?
$$r_n=a\cdot r_{n-1}+b\cdot (n-1)\cdot r_{n-2}\tag 1$$ (where $a,b,A_0,A_1$ are constants and $r_0=A_0,r_1=A_1$) If the $(n-1)$ was not present, this could easily be solved using a characteristic equation.  However, with the varying coefficient, the process is not so simple.","['recurrence-relations', 'calculus', 'discrete-mathematics', 'recursive-algorithms', 'finite-differences']"
975156,Triangle similarity question,I've been trying to solve this question for like 40 mins straight and can't seem to get anywhere. I tried drawing a parallel to |KM| from C to |AB| but that didn't seem to help. I just can't see a way to get to |MN|.,"['geometry', 'triangles']"
975210,Can anyone explain why this equation using the fundamental theorem of calculus works?,"\begin{align}
        \left| f(b)-f(a)\right|&=\left| \int_a^b \frac{df}{dx} dx\right|\\ \ \\
        &\leq\left| \int_a^b \left|\frac{df}{dx}\right|\ dx\right|.
\end{align} I do not understand why the second line is greater or equal than the top equation. Can anyone explain please?","['ordinary-differential-equations', 'calculus']"
975243,Geodesic completeness of a Lie group,"Let $G$ be a Lie group and $\rho$ some left(right, bi)-invariant Riemannian metric on $G$. Is it possible to say for which $\rho$ an underlying manifold $G$ is geodesically complete (maybe for every such $\rho$)?","['lie-groups', 'differential-geometry', 'geodesic']"
975257,"If $\sum_{n=1}^\infty \frac{1}{a_n}$ converges, must $\sum_{n=1}^\infty \frac{n}{a_1 + \dots + a_n}$ converge?","Suppose $\sum_{n=1}^\infty \frac{1}{a_n} = A$ is summable, with $a_n > 0,$ $n = 1,2,3,\cdots.$ How can we prove that $\sum_{n=1}^\infty \frac{n}{a_1 + \dots + a_n}$ is also summable? This question came from a problem-solving seminar, but I'm quite stuck without a push in the right direction. I tried a few things, including Cauchy-Schwarz (which says $\sum_{n=1}^\infty \frac{n}{a_1 + \dots + a_n} < \sum_{n=1}^\infty \frac{A}{n}$) and also the idea of assuming the latter series diverges and attempting to deduce the divergence of the former series from that, using facts such as $\sum a_n = \infty \implies \sum \frac{a_n}{a_1 + \cdots + a_n} = \infty$. Nothing has worked so far.","['means', 'convergence-divergence', 'contest-math', 'analysis']"
975267,Doubt on understanding continuity .,"Just preparing for my multivariable-calculus exam and wanted to clear these things: I've come across many questions of sort below , especially 2-dimensional regions , and wanted to understand the Idea behind them.... Prove the continuity of $f(x,y)$ on $\mathbb R^2$where, $$f(x,y) = \begin{cases} \text{some fn./value is given} & \text{, if x,y in region1 } \\ \text{some other fn./value is given} & \text{, if x,y in region2} \end{cases}$$ Here ,region $1$ and region $2$ consist of all those points $(x,y)$ satisfying respective inequalities in $x$ and $y$... to clearly understand my above statements consider example:  $$f(x,y)=
\begin{cases}  e^{-\text(\frac{1}{|x-y|})} & \text{if $x\neq y$} \\ 0 & \text{if $x=y$} \end{cases} $$ Now if I've to prove continuity on $\mathbb R^2$ : STEP 1 : I should pick up any $(x_0,y_0)$ in $\mathbb R^2$ where continuity can be proved, STEP 2 : Now what I've to show that limit of $f(x,y)$ where $(x,y)$ are in region $1$ must be equal to limit of $f$ at $(x_0,y_0)$. similarly ,show the above for region $2$. Am I correct with this procedure.....","['multivariable-calculus', 'continuity']"
975312,Limit of a sequence defined by recursive relation : $ a_n = \sqrt{a_{n-1}a_{n-2}}$,"We're given a sequence defined by the recursive relation: $$a_n = \sqrt{a_{n-1}a_{n-2}}$$ $a_1$ and $a_2$ are positive constants.
We have to show the following: The sequences $\{ b_n \} = \{ a_{2n-1} \}$ and $\{ c_n \} = \{ a_{2n} \} $ are monotonic, and if one is increasing, the other is decreasing. The limit of the sequence $\{ a_n \} $ is $ \left(a_1a_2^2\right)^{\frac13} $ Now, I have proved the first part. Besides that, I have also proved a few other things: If $a_1 > a_2$, then: a. $ \{ b_n \} $ decreases, and $ \{ c_n \} $ increases. b. $ c_n < b_n $ If $a_1 < a_2$, we just flip $\{ b_n \}$ and $\{c_n\}$ Besides, I have also shown that both the sequences : $\{b_n\}$ and $\{ c_n\}$ have the same limit. What I don't know, is how to evaluate the limit.","['recurrence-relations', 'sequences-and-series', 'limits']"
975342,Nested recurrence sequence with interesting properties,"This is my first post here, thanks for stopping by. The question as written below comes from the book 'A Concise Introduction To Pure Mathematics'. I've included my working (this isn't a homework problem) and points I am interested in - particularly, the thought process that you had in dealing with this problem. Critic Ivor Smallbrain has been keeping a careful account of the number of chocolate bars he has eaten during film screenings over his career. For each positive integer $n$ he denotes by $a_n$ the total number of bars he consumed during the first n films. One evening, during a screening of the Christmas epic It's a Wonderful Proof , he notices that the sequence $a_1 , a_2 , ...$ obeys the following rules for all $ n => 1$: $a_{n+1} > a_n $ $a_{a_n} = 3n$ Also $a_1 > 0$ (a) Find $a_1$ . ( Hint : Let $x=a_1$. Then what is $a_x$?) (b) Find $a_2 , a_3 , ... , a_8 , a_9$ (c) Find $a_{100}$ (d) Investigate the sequence $a_1 , a_2 , ...$ further. (a) Well, we would be good to make use of the hint, so that $a_x = a_{a_1} = 3$
by the second property. Now, let us say that x is greater than or equal to four. As the sequence is strictly increasing, the terms before $a_x$ are strictly decreasing, thus we would run out of terms if this were the case. Hence x must be less than 4, so x is 1,2 or 3, remembering that the first term of the sequence is at least one. Well, suppose that x is 1. Then we get $a_1 = a_x = a_{a_1} = 3$, an absurdity. So, we investigate if x is 3. Then $a_3 = a_x = a_{a_1} = 3$ Yet we recall x is $a_1$ and the sequence is strictly increasing, so this is an absurdity. (b) Knowing that $a_1 = 2$ we note $3 = a_{a_1} = a_2$ by the second property. Similarly, $6=a_{a_2}=a_3$ so $9 = a_{a_3} = a_6$. Now, we are looking for $a_5$ and $a_4$, but this is made easy by the first property; the sequence is increasing, and the third term is 6, the sixth term is 9. Hence the fourth is 7 and the fifth 8. So, to sum; $a_1$ = 2
$a_2$ = 3
$a_3$ = 6
$a_4$ = 7
$a_5$ = 8
$a_6$ = 9 To finish, note the seventh term is obtained from the fourth, to be 12,the eighth from the fifth, to be 15, and the ninth from the sixth, to be 18. (c) - (d) - Parts I am stuck on. Well, it sounds like if you could answer (d) with an explicit formula then obtaining the answer for (c) would be fine - you just plug in n = 100. However, I am struggling to find how you can 'skip' finding numbers. From the working above it appears to me that I need to find all terms before the hundredth. I am asking for your help in not merely a method, but in illumination - please explain to me why you are doing this or that and so forth - I am hoping to learn something here, and if you can answer this, then whatever you say will be something I and all people can learn from so do not hold back - say anything.",['sequences-and-series']
975369,Linear functionals and dual bases,How do I tackle this question? I am a little hazy on linear functionals and integral signs.,"['linear-algebra', 'integration', 'functions', 'polynomials']"
975392,If $f(x)+\frac{f'(x)}{x}\to0$ then $f(x)\to0$,I honestly have no idea how to solve this one. Can we use the mean value theorem? $$\lim_{x\to \infty}\left(f(x)+\frac{f'(x)}{x}\right)=0 \implies \lim_{x\to \infty}f(x)=0$$,"['real-analysis', 'limits']"
975435,Cardinality of the set of irrational numbers which is connected subset of rational numbers,"Let X be a connected subset of real numbers. If every elements of X is irrational then what is the cardinality of X?
We know cardinality of irrational numbers is same as the cardinality of real numbers,which is denoted by 'a'. But I don't know what will be the change of cardinality for imposing the connectedness condition..Is it same of different?","['connectedness', 'elementary-set-theory']"
975469,Can $f:\Bbb{N}\rightarrow\Bbb{N}$ return an empty set?,I have a function $f:\Bbb{N}\rightarrow\Bbb{N}$. An empty set is not a member of $\Bbb{N}$. Can $f$ still return an empty set for some arguments $x\in\Bbb{N}$?,['elementary-set-theory']
975526,When can I leave the absolute value from Chebyshev's inequality?,"I have a positive random variable whose distribution is unknown, but its mean is $10$. I have to find an estimation of its variance, given that $Pr(X\ge9$)=0.9980 I thought of Chebyshev's inequality: $Pr(|X-10|\geq -1)\leq\frac{D^2X}{1}=0.9980$ But can I leave the absolute value?","['probability', 'random-variables']"
975573,Hartshorne II prop 6.6,"I'm having a really hard time understanding the proof of this proposition.  $X$ is a noetherian integral separated scheme that is regular in codimension 1.  We consider $X\times \mathbb{A}^1$ and the projection $\pi$ onto $X$. First, Hartshorne says there are two types of codimension 1 points of $X\times \mathbb{A}^1$, type 1 being those which map to a codimension 1 point of $X$ through $\pi$ and type 2 being those which map to the generic point.  I'm not clear on why these are the only types.  I believe that when $Y$ is a subscheme of $X$ that $\pi^{-1}(Y)=Y\times \mathbb{A}^1$ and is a subscheme of $X\times \mathbb{A}^1$.  Is it true that the codimension of $\pi^{-1}(Y)$ is less than or equal to the codimension of $Y$?  Is this what Hartshorne is implicitly using?  I think if this is true we would also get a 1-1 correspondence between type 1 prime divisors of $X\times \mathbb{A}^1$ and prime divisors of $X$. Next, if we have that the function field of  $X$ is $K$, then we have the function field of $X\times \mathbb{A}^1$ is $K(t)$.  I guess Hartshorne is saying that if $f\in K$ then $(f)_X=(f)_{X\times \mathbb{A}^1}$ where on the r.h.s we view $f\in K(t)$.  I am confused about why this is true.  I guess I need to understand how to compare the image of $f$ in the local rings at generic points of $X\times \mathbb{A}^1$ with those of $X$.",['algebraic-geometry']
975587,"When $a\to \infty$, $\sqrt{a^2+4}$ behaves as $a+\frac{2}{a}$?","What does it mean that $\,\,f(a)=\sqrt{a^2+4}\,\,$ behaves as $\,a+\dfrac{2}{a},\,$
as $a\to \infty$? How can this be justified? Thanks.","['calculus', 'limits', 'asymptotics', 'radicals', 'taylor-expansion']"
975617,Evaluate $\int(x^{91}+x^{327})\cos(x)\mathrm{d}x \quad .$,"Evaluate  $$\int\left(x^{91}+x^{327}\right)\cos(x)\mathrm{d}x \quad .$$ It's my first time to face integration like that. I just need a clue to start because I tried, but it's not working Thanks in advance","['integration', 'indefinite-integrals']"
975626,Solve quadric equation system,"How to solve this analytically(not a numerical solution)? For given real and symmetric matrices
$A_1,A_2,A_3,A_4\in\mathbb{R}^{4\times4}$
find
$0\neq x\in\mathbb{R}^4$ $$x^TA_1x=0$$
$$x^TA_2x=0$$
$$x^TA_3x=0$$
$$x^TA_4x=0$$ Example: Solve the system: \begin{align}
a^2+b^2+c &=3.95 \\
ab+bc+c^2 &=4.57 \\
ac+b &=2.63 \\ 
\end{align}
Denoting:
\begin{equation}
x = \begin{bmatrix}a & b & c & 1\end{bmatrix}^T
\end{equation} Then the matrices, $A_k$ can be build from the equations, for example to form $A_1$, we rewrite the first equation in matrix form  $x^TB_1x=0$ where:
\begin{equation}
B_1 = \begin{bmatrix} 1&0&0&0\\0&1&0&0\\0&0&0&1\\0&0&0&-3.95\\  \end{bmatrix}
\end{equation} Then, since from $x^TB_1x=0$ transpose leads to $x^TB_1^Tx=0$, the sum is: $x^T(B_1+B_1^T)x=0$
denoting the matrix as $A_1=(B_1+B_1^T)$, it is symmetric and  $x^TA_1x=0$","['matrices', 'numerical-linear-algebra', 'calculus', 'numerical-methods']"
975675,"Given $\alpha$, can we always find $\beta$ such that both $\sin(\alpha+\beta)$ and $\sin(\alpha-\beta)$ are rational?","Given $\alpha$, can we always find $\beta$ such that both $\sin(\alpha+\beta)$ and $\sin(\alpha-\beta)$ are rational?","['trigonometry', 'rational-numbers']"
975676,"Is $[a, a)$ equal to $\{a\}$ or $\varnothing$?","Let us define the set $[a,b) = \{ x \in \mathbb{R}: a\le x <b\}$ Is $[a, a)$ equal to $\{a\}$ or $\varnothing$?","['real-numbers', 'elementary-set-theory']"
975682,Irreducibility of holomorphic functions in a neighborhood of a point,"Let $D \subset \mathbb C^n$ be a domain and let $f \in \mathscr O(D)$, $f \not\equiv 0$ be a holomorphic function. Define 
$$ 
   V_f = \bigl\{ z \in D : f(z) = 0 \bigr\}.
$$
Let $p \in V_f$. Suppose that $f$ is irreducible in the ring of germs $\mathscr O_p$. Is it true that there exists a neighborhood $U$ of point $p$ such that $f$ is irreducible in $\mathscr O_q$ for all $q \in V_f \cap U$? Maybe I should use somehow the property that if two functions in $\mathscr O_p$ are relatively prime then they will be relatively prime in $\mathscr O_q$ for $q$ close to $p$? Update. If $f$ is reducible in $\mathscr O_q$ then $f = f_1 f_2$ in a neighborhood of $q$ with $f_1(q)=f_2(q)=0$. This implies that $f(q)=0$ and $\frac{\partial f(q)}{\partial z_k}=0$, $k=1$, $\dots$, $n$. If at point $p$ some $\frac{\partial f(p)}{\partial z_k} \neq 0$ then the statement is true. Update 2. Suppose that $f$ divides all $\frac{\partial f}{\partial z_k}$ in $\mathscr O_p$ so that we have
$$
   \frac{\partial f}{\partial z_k} = fh_k, \quad k =1,\ldots,n,
$$
in a neighborhood of $p$ with holomorhic $h_k$, $h_k(0) = 0$. Differentiating these equalities we obtain
$$
   \frac{\partial^2 f}{\partial z_k \partial z_l} = \frac{\partial f}{\partial z_l} h_k + f \frac{\partial h_k}{\partial z_l},
$$
this implies $\frac{\partial^2 f(p)}{\partial z_k z_l} = 0$ for all $k$, $l$. We can continue this process showing that all derivatives of $f$ at $p$ are equal to zero so that $f \equiv 0$. The only remaining case when the statement may be false is when all $\frac{\partial f}{\partial z_k}(p)=0$ and $f$ doesn't divide some $\frac{\partial f}{\partial z_k}$ in $\mathscr O_p$.","['complex-geometry', 'algebraic-geometry', 'complex-analysis', 'germs']"
975686,Classification of pde,"I got stuck on the following problem: Determine the subsets of $\mathbb{R}^2$ where the pde $$u_{xx}+2xu_xu_{xy}+yu_{yy}+yu_x=1$$ is elliptic, hyperbolic and parabolic respectively. Now, at first I thought this to be an exceedingly simple task, all we need to do is look at the determinant of $$\begin{pmatrix}1 & xu_x \\xu_x & y\end{pmatrix}.$$ If it is positive, we are elliptic, if it's negative, we are hyperbolic, if it's $0$, we are parabolic. So far, so good. However, what kind of ruined the notion that this was going to be oh so easy was the fact that suddenly I was left with the differential inequalitiy $$y> (xu_x)^2$$
with symmetric versions for $=,<$. Duh. Now, think positively, at least one does get the trivial case that for $y<0$ we are hyperbolic. And for $(x,y)=(0,0)$ we are parabolic. Also, for $x=0,y>0$ we are elliptic. Only about half of the real numbers left, yay. So in the following we could assume that $y\geq0$, you never know, it might help. In order to try and solve this, I figured I could at least try to do something for the parabolic case:
$$\frac{y}{x^2}=u_x^2 \quad\Leftrightarrow \\ \frac{\sqrt{y}}{|x|}=|u_x|$$ and now I cannot even say anything definitive about the integral because, well, we have $|u_x|$ instead of $u_x$. Also, even if I could integrate, if I had $\sqrt{y}\ln|x|+c=|u(x,y)|$, I still would have no idea for which sets $(x,y)\in\mathbb{R}^2$ this is true. Same goes for the inequalities, if not worse, which goes to say I've basically not made any progress with this. One other thing I've tried is to at least look at the case $x\neq 0,y=0$, where if $u_x\neq0$ we are also trivially hyperbolic, but inserting that into the original pde doesn't seem to give me any kind of contradiction ($u_{xx}$ does, unfortunately, not need to be $0$, too - also, we do not (well, at least, I don't) know anything about it's sign, since it only appears in our inequality quadratically). Also note that it is explicitly stated that it is not necessary to solve the original pde. In case this is even possible; I'm fairly new to this subject. Hence I assume that I have simply been unable to find anything resembling a ""correct"" approach, and would be quite thankful for anyone shedding light on what to do here.","['ordinary-differential-equations', 'partial-differential-equations']"
975695,When will the support of a non-effective Cartier divisor be pure of codimension 1?,"Let $X$ be a scheme and $D \in Div(X)$ a non-effective Cartier divisor. I am curious as to when $\text{Supp } D$ is pure of codimension 1, i.e all irreducible components are of codimension 1. So, three concrete questions that I have been having are the following: If $X$ is assumed to be integral, what is an example of a scheme $X$ and a non-effective Cartier divisor that is not supported purely in codimension $1$? If $X$ is normal, can we still find non-effective Cartier divisors that are not supported purely in codimension $1$? Lastly, if $X$ is not only normal, but actually regular, does this imply that the support is purely in codimension $1$?",['algebraic-geometry']
975705,Why the space S1 and S1/Z_2 is topologically identical?,"I am a physicist studying liquid crystals. My research is bit related to topology but I don't have much knowledge of it. Recently I read from a the book Soft matter physics: An introduction that topologically, $S^1$ and $S^1/Z_2$ is topologically identical. The book doesn't give explain to this statement and I have some problem of understanding. Is the space of $S^1/Z_2$ a semi-circle? If so why it is identical to $S^1$? Is $S^1/Z_N$ also topologically identical to $S^1$? Can anyone give me some hints? References are also warmly welcome.","['general-topology', 'algebraic-topology', 'homotopy-theory', 'group-theory']"
975722,"If $0 \to M \to N \to S \to 0$ splits, then $N \cong M \oplus S$","I am trying to show that if we have the left splitting short exact sequence of $R$ -modules $$
  0
  \longrightarrow M
  \xrightarrow{\enspace f \enspace} N
  \xrightarrow{\enspace g \enspace} S
  \rightarrow 0 \,,
$$ then there exists an isomorphism of $R$ -modules $\phi \colon N \to M \oplus S$ . I know that there is $\psi \colon N \to M$ such that $\psi \circ f = \mathrm{Id}_M$ , and we have the epimorphism $g \colon N \to S$ , so maybe the morphism $\beta \colon N \to M \oplus S$ defined as $\beta(n) = (\psi(n), g(n))$ could work ( $\beta$ would be $\phi^{-1}$ ). It is easy to show that $\beta$ is a module morphism. I am having some difficulty to prove it is injective and surjective, I would appreciate some help, maybe I’ve chosen the wrong morphism.","['modules', 'abstract-algebra', 'exact-sequence']"
975736,Triangular Factorials,"I came across a statement online and have been looking for a proof : It states that 1, 6 and 120 are the only numbers which are both triangular and factorials. Is there any way I can prove this? This claim looks too 'big' and I've tried to prove it but I couldn't. Can anyone help me to prove this?","['diophantine-equations', 'number-theory']"
975746,Existence of partial derivative,"I know how to compute partial derivatives of functions with more than one variable. But how can i assert that the partial derivatives of a given function exist at a point without computing it? Consider the following functions for example: $f(x,y)=xy(x^2-y^2)/(x^2+y^2)$ and $f(0,0)=0$ How do I show that the first partial derivative of $f(x,y)$ exists at $0$? Thanks for you help in advance!","['multivariable-calculus', 'partial-derivative', 'derivatives', 'real-analysis']"
975759,Are differentiation and integration continuous functions?,"Is differentiation a continuous function from $C^1[a,b] \to C[a,b]$? I think it is but I can't prove it... Would it be possible to prove it using theory about closed sets in $C[a,b]$ and their preimage? My problem here would be to check all closed sets and the closeness of their preimage so I'm feeling I'm on the wrong track! Also : is integration a continuous function from $C[a,b] \to C[a,b]$? Somehow I feel it's not... Then it would be enough to show that some closed subset of $C[a,b]$ has a non-closed preimage? Wouldn't it? But which one? I'm not sure this isn't all misleading... Can you help me? Thanks a lot! PS: I'm considering the sup metric on $C[a,b]$!","['functional-analysis', 'continuity', 'integration', 'derivatives']"
975770,Reference request: Galois descent,What is a classic (perhaps even original) reference for Galois descent? I know that it can be seen as a special case of faithfully flat descent (for which FGA and SGA I is the usual reference) and that it can also be proven directly in a very elementary way. It is also presented in many new textbooks. But I would like to have a very old (and still useful) reference.,"['galois-theory', 'algebraic-geometry', 'reference-request']"
975773,Let X be a discrete random variable,"Let X be a discrete random variable. If $E[X]=-3$, then $E[(3+5X)^2]=$ I understand that to find the expected value the formula would be $E[aX+b] = aE[X]+b$ 
so it would be 3+5(-3). My problem is that I do not know what to do with the square. Where would I put it in the formula. I tried squaring my answer, but it was wrong. What is the formula in an expected value that is squared?","['statistics', 'probability']"
975799,Proving Multivairble Limit Exists [duplicate],"This question already has answers here : Is there a step by step checklist to check if a multivariable limit exists and find its value? (2 answers) Closed 9 years ago . How do you deal with multivariable limits? We'll use the example $f: \mathbb R ^2 \rightarrow \mathbb R$ $$\lim _{(x,y) \rightarrow (0,0)}\frac{\sqrt{|xy|}}{\sqrt{x^2 + y^2}}$$ The limit doesn't exist, if $x=y$ we have the value $1/\sqrt{2}$ and if $y = x^3$ we get $0$. How would we prove it with the $\epsilon - \delta$ proof? Do we even need to prove it through the definition, or does it suffice to show that approaching the point by different paths leads to different answers? Given that there are an infinite amount of paths in which to approach our point, how would you prove that the limit did actually exist? Take for example $f(x,y) = xy$, where we'll take the limit $$\lim _{(x,y)\rightarrow (1,2)} f(x,y) = 2 $$ This is obvious because the function is continuous at our point of interest, but how do you prove it directly from the definition? The same tricks we used when dealing with a single variable won't apply here due to the fact that we're dealing with a point, rather than a single number.","['multivariable-calculus', 'limits']"
975810,Whitney sum of smooth vector bundles,"I was reading through Lee's smooth manifolds book, in his chapter on vector bundles. Upon reading about smooth vector bundles and its definition, I was wondering if the whitney sum of two smooth vector bundles would be smooth, i.e. $p \colon E \oplus E' \to M $ where $\alpha \colon E \to M$ and $\beta \colon F \to M$ are smooth vector bundles? How would one verify this, how is the direct sum of two smooth manifolds defined?","['general-topology', 'manifolds', 'differential-topology']"
975820,The question regrading to density argument in analysis.,"I know the density argument in $L^p$ space, in Sobolev spaces, and even in BV are really sweet in many many cases. However, some times author just work on nice functions and comment by ""the rest can be easily done by density""... Like I said, some times it is easy, but some times it is really not clear! Here I list some problems I encountered before in which I do not find out why density argument can so easily worked out. This one regrading to weak convergence in $BV$ space. It is an argument in Evans & Gariepy's book, page 175, theorem 3. In that theorem they were trying to prove a sequence of radon measure $\mu_k\to \mu$ weakly. In the prove, they only test against $\phi\in C_c^1(R^n;R^n)$, and hence they can employ integration by parts in $BV$ functions. However, to my knowledge, to prove a radon measure convergence weakly, we really need to test against all continuous function. So here I assume they use density argument. Now given any $\phi\in C_c(R^n;R^n)$, of course we can find a sequence $\phi_m\in C_c^\infty$ and $\phi_m\to \phi$ uniformly. Hence, the question would be, why we can interchange the limit such that
$$\lim_{m\to\infty}\lim_{k\to\infty}\int \phi_m d\mu_k =\lim_{k\to\infty}\lim_{m\to\infty}\int \phi_m d\mu_k  \,\,??$$
given that we already proved that 
$$\lim_{k\to\infty}\int \phi_m d\mu_k =\int \phi_m d\mu $$
for all $\phi_m\in C_c^\infty$. Another similar question regrading to density is here , in which I have a sequence $u_n$ bounded in $H^1$ norm and I want to prove $u_n\to 0$ weakly in $H^1$. It is quick to show that $u_n\to 0$ weakly in $L^2$ but hard to work out $\partial_i u_n\to 0$. The comment in that post nicely suggest by using density argument so that we could test $\partial_i u_n$ with a $C^\infty$ function and hence by integration by parts we could use that fact $u_n\to 0$ weak to conclude. However, now I face the similar situation: for an sequence $g_m\in C_c^\infty$, I have $g_m\to g$ strongly in $L^2$ and I have
$$\lim_{n\to\infty} \int_\Omega \partial_i u_n g_m\,dx= 0 $$
Next I need to push $m\to\infty$ and I have
$$\lim_{m\to\infty}\lim_{n\to\infty} \int_\Omega \partial_i u_n g_m\,dx= 0 $$ for sure. However, why could I interchange the limit here? i.e., why
$$\lim_{m\to\infty}\lim_{n\to\infty} \int_\Omega \partial_i u_n g_m\,dx= \lim_{n\to\infty}\lim_{m\to\infty} \int_\Omega \partial_i u_n g_m\,dx $$ Also, I post another question regrading to how to interchange limit, but I gave a too nice condition there ... Please help, and if possible, please work out the details of how to interchange the limit. THx!!!!","['sobolev-spaces', 'real-analysis', 'bounded-variation', 'functional-analysis', 'limits']"
975824,Expected Total Number,"To determine whether or not they have a certain disease, 160 people are to have their blood tested. However, rather than testing each individual separately, it has been decided first to group the people in groups of 10. The blood samples of the 10 people in each group will be pooled and analyzed together. If the test is negative. one test will suffice for the 10 people (we are assuming that the pooled test will be positive if and only if at least one person in the pool has the disease); whereas, if the test is positive each of the 10 people will also be individually tested and, in all, 11 tests will be made on this group. Assume the probability that a person has the disease is 0.04 for all people, independently of each other. I know the expected number of tests necessary for each group is $$11-10*(.96)^{10}$$ I just need help computing the expected total number of tests necessary for the entire population of 160 people.","['statistics', 'probability']"
975858,"How many natural numbers less than 1,000,000,000 are multiples of 5 or 7?","I used the Inclusion-Exclusion Principle and I got $200,000,000$ (multiples of $5$ less than $10^9$, obtained by $10^9 / 5$) + $124,857,142$ ( multiples of $7$ less than $10^9$, obtained by $10^9 / 7$ and round it down) - $28,571,428$ ( multiples of both $5$ and $7$ that are less than $10^9$, obtained by $10^9 / 35$ because only multiples of $35$ is multiple of both $5$ and $7$ ) since the rule says $|A ∪ B| = |A| + |B| - |A ∩ B|$. So my equation is: $200,000,000 + 124,857,142 - 28,571,428 = 314,285,714 $, which is a rather big number so I think I might have done something wrong. Is my reasoning correct? Please help. Thank you!",['discrete-mathematics']
975910,Exact result of a series using Euler-Maclaurin expansion.,"This is a variant of Exercise 64 in Chapter 9 of concrete mathematics. Prove the following identity
\begin{equation}
\sum_{n = -\infty}^{\infty}' \frac{1 - \cos( 2\pi n k )}{n^2 }  = 2 \pi^2 ( k - k^2 ) \qquad k \in [0,1]
\end{equation}
I came across it in a different context and was surprised that it is exact. Let's use Euler-Maclaurin expansion to convert the sum into an integral. Take $f(x) = \frac{1 - \cos( 2\pi x k )}{x^2 } $
\begin{equation}
\sum_{n = -N+1}^{N}' f(n) = \int_{-N}^{N} f(x) dx - f(0) + \sum_{k=1}^{p} \frac{B_k}{k!}f^{(k-1)}(x)\Big|^N_{-N} + R_p 
\end{equation}
The first two terms are already the exact result, 
\begin{equation}
\int_{-\infty}^{\infty} f(x) dx = 2\pi k \int_{-\infty}^{\infty} \frac{1- \cos x}{x^2}dx = 2\pi^2 k \qquad f(0) = 2\pi^2 k^2 
\end{equation}
so one needs to prove the end point corrections(terms with $B_k$ in it) as well as the reminder terms are zero. At any order $p$, there are only finite number of end point correction terms which goes at most like $\mathcal{O}(\frac{1}{N^2})$, so they vanish when taking the $N\rightarrow \infty$ limit. But I don't know how to show the reminder term is zero(as $N\rightarrow \infty$),
\begin{equation}
R_p(N)  = (-1)^p \int_{-N}^{N} \frac{1}{p!} B_p( x - \lfloor x \rfloor ) f^{(p)}(x) dx 
\end{equation}
Maybe there are other methods to prove the identity, but I personally would appreciate the proof using Euler Maclaurin, since I'm going to use it for another series, and the reminder term has
\begin{equation}
f(x) = \frac{g(x) - g(0) }{ x^2} - \frac{g'(0)}{x}
\end{equation}
where $g(x ) = g(x + N)$ is a periodic function. So you can also go ahead and prove the general $g(x)$ case. Thanks. Edit :
The general case can also be worked out by robjohn 's method by summing over each individual the Fourier components. Though a direct proof of the vanishing Euler-Maclaurin reminder term is still absent, robjohn's method solved my problem.","['calculus', 'euler-maclaurin', 'real-analysis', 'numerical-methods', 'bernoulli-numbers']"
975917,Differential-geometry textbook with solved problems,I'm looking for a textbook in differential geometry which inside has exercises with (at least) final answers. Since it's my first course in differential geometry it doesn't have to cover material (we finished the course with gauss-bonnet theorem)but rather to have hard-leveled problems. What book would you recommend to me ?,"['soft-question', 'reference-request', 'differential-geometry']"
975924,Why can I not combine integrals this way?,"Evaluating the triple integral $\int^1_0 \int^{1-z}_0 \int^{1-y-z}_0 \text{dxdydz}$, I get $\frac 16$. Evaluating the triple integral $\int^1_0 \int^1_0 \int^1_0 \text{dxdydz}$, I get $1$. So I subtract them like: $$\int^1_0 \int^1_0 \int^1_0 \text{dxdydz} - \int^1_0 \int^{1-z}_0 \int^{1-y-z}_0 \text{dxdydz} = \int^1_0 \left(\int^1_0 \int^1_0 \text{dxdy} + \int^0_{1-z} \int^0_{1-y-z} \text{dxdy} \right)\text{dz}= \int^1_0 \int^1_{1-z} \int^1_{1-y-z} \text{dxdydz}$$ and I get $\frac 23$, not $1-\frac 16 = \frac 56$.  So I must be combining the integrals wrong.  Why can't I do it this way?","['multivariable-calculus', 'integration']"
975953,The limit of a solution of the logistic equation as time tends to infinity,"$$ \frac{dP}{dt} = 3P(4 - P),\quad P(0) = 2.$$ What value does $P$ approach as $t$ gets large, ie. as $t \to\infty$. How do I solve this?
Is the idea to this question to first rearrange the equation so that there is a constant on the Right Hand Side, then you can integrate both sides with respect to $dt$? Thanks","['ordinary-differential-equations', 'calculus', 'limits']"
976006,Sum of roots of an equation $\sqrt{x-1}+\sqrt{2x-1}=x$,"Find the sum of the roots of the equation $\sqrt{x-1}+\sqrt{2x-1}=x$ My attempt: Squaring the equation: $(x-1)+(2x-1) +2\sqrt{(x-1)(2x-1)}=x^2$ $\implies x^2-3x+2=2\sqrt{(x-1)(2x-1)} $ $\implies (x-1)(x-2)=2\sqrt{(x-1)(2x-1)} $ $\implies (x-2)=2\sqrt{\displaystyle \frac{(2x-1)}{(x-1)}} $ Squaring, $(x^2-4x+4)(x-1)=8x-4$ $\implies x^2(x-5)=0$. So, the sum of roots should be five. The given answer is 6. Could anyone look at my attempt to find where I went wrong. Thanks.",['algebra-precalculus']
976034,What are some good examples of (non-quasicoherent) sheaves not satisfying the conclusion of Hartshorne Lemma II.5.3?,"Hartshorne, Algebraic Geometry , Lemma II.5.3 reads (roughly): Let $X = \operatorname{Spec} A$, let $f \in A$, and let $\mathscr{F}$ be a quasicoherent sheaf on $X$. (a) If $s \in \Gamma(X, \mathscr{F})$ with $s|_{D(f)} = 0$ then $f^n s = 0$ for $n \gg 0$. (b) If $s \in \Gamma(D(f), \mathscr{F})$ then $f^n s$ extends to all of $X$ for $n \gg 0$. The proof essentially amounts to clearing denominators. I'm trying to get a good picture of exactly what this is ruling out, but I don't have a great mental picture of a (obviously non-quasicoherent) sheaf where (a) and (b) don't hold.  Are there any good examples to think of?",['algebraic-geometry']
976049,Positive values of $x$ that satisfy the inequality $\frac{1}{x}-\frac{1}{x-1}>\frac{1}{x-2}$,"Determine the set of positive values of $x$ that satisfy the inequality $$\frac{1}{x}-\frac{1}{x-1}>\frac{1}{x-2}.$$ My attempt:
\begin{align}
\frac{-1}{x(x-1)} & >\frac{1}{(x-2)} \\[0.1in]
\frac{1}{x(1-x)} & >\frac{1}{(x-2)} \\[0.1in]
 x(1-x) & <(x-2)
\end{align} If I put $0.25$ in the original inequality, it works, but not in the last one. What mistake did I make? Please advise.","['inequality', 'algebra-precalculus']"
976094,Infinite Series -: $\psi(s)=\psi(0)+\psi_1(0)s+\psi_2(0)\frac{s^2}{2!}+\psi_3(0)\frac{s^3}{3!}+.+.+ $.,"We have a given converging series using derivatives and matrices(Analogue to Taylor's series) $\psi(s)_{3 \times 3}=\psi(0)+\psi_1(0)s+\psi_2(0)\frac{s^2}{2!}+\psi_3(0)\frac{s^3}{3!}+..+.. \tag 1$. (Note the notional convention used here $\frac{\mathrm{d}^2 \psi(s) }{\mathrm{d} s^2}=\psi_2(s),\frac{\mathrm{d}^p \psi(s) }{\mathrm{d} s^p}=\psi_p(s) $) Given data and Observation in the question It is given that $ \psi_2(s)=(A+Bs)\psi_1(s)\tag 2$ where A,B are constant $3 \times 3$ skew symmetric matrices with determinant $0$ 
$$A=\left( \begin{array}{ccc} 
   0 & -c_0 & b_0 \\
   c_0 & 0 & -a_0 \\
  -b_0 & a_0 & 0 \\
   \end{array} \right).$$ $$B=\left( \begin{array}{ccc} 
   0 & -c_1 & b_1 \\
   c_1 & 0 & -a_1\\
  -b_1 & a_1 & 0 \\
   \end{array} \right).$$
Note : All entries of the matrices $A$, $B$ are constants,can't be altered $\psi_1(0)$ has determinant $1$ and  orthogonal. No information about the same property on other derivatives. $\psi_1(0),\psi(0)$, are given Question Can we re write equation (1) as $\psi(s)_{3 \times 3}=\tau(s)_{3 \times 3} \psi_1(0)+\psi(0) \tag 3$? Can we re write  $\psi(s)_{3 \times 3}$  in a finite Closed form by summing all the terms? NB :: Means what could be the finite function $\tau(s)$ which is defined with out any derivatives of $\psi(s)$. Implies you can write $\tau(s)$ using $A,B,s$ as per your convenience . Please check my attempts to solve it as answers below. If you have different idea you can write new one ATTEMPT #1#Answer When you look at the relationship  $ \psi_2(s)=(A+Bs)\psi_1(s) $ we can make recursion out of it $\psi(0)_n=A\psi(0)_{n-1}+(n-2)B \hspace{.2cm}\psi(0)_{n-2}\tag 4$ For simplicity let me write $y_n=\psi(0)_n,C_1=A,C_2=B$,because we are going to make recursion on n. All s based variables are now become constant $y_n =
\left\{
	\begin{array}{ll}
		 \psi_1(0)  & \mbox{if } n = 1 \\
		 C_1\psi_1(0)& \mbox{if }n=2\\
        C_1y_{n-1}+(n-2)C_2 y_{n-2} & \mbox{if }n> 2\\
	\end{array}
\right.\tag 5$ Question 1 Find out the solution of recursion in equation (5). The solution may  contain initial terms $y_1,y_2$(as most of the recursion solution), then substitute for  each $y_n$. Then you can take out $y_1$ as mentioned in the question.You may need to solve the infinite series after taking out $y_1$. I am trying to solve it. Till not yet successful. Expecting suggestions Question 2 Multiply by $x^n$ ,then take summation $\sum_{n=1}^{\infty}y_nx^{n}= xC_1\sum_{n=2}^{\infty}y_{n-1}x^{n-1}+x^2C_2\sum_{n=3}^{\infty} (n-2)y_{n-2}x^{n-2} \tag 6  $ $\sum_{n=1}^{\infty}y_nx^n= xC_1\sum_{n=1}^{\infty}y_{n}x^{n}+x^2C_2\sum_{n=1}^{\infty}  n y_{n}x^{n} \tag 7  $ $\sum_{n=1}^{\infty}y_nx^n= xC_1\sum_{n=1}^{\infty}y_{n}x^{n}+x^3C_2\sum_{n=1}^{\infty}  n y_{n}x^{n-1} \tag 8  $ Assume $F(x)_{3 \times 3}=\sum_{n=1}^{\infty}y_nx^n$ then we get an ODE $ F(x)=xC_1F(x)+x^3C_2F'(x)\tag 9$ Solving $F(x)$ will give solution of question number 2.More precisely $F(1)$. But the issue is I couldnt not find a solution. Expecting suggestions to solve it","['sequences-and-series', 'calculus', 'matrices', 'derivatives', 'taylor-expansion']"
976138,"calculating partial derivatives at $(0,0)$","Let $f:\mathbb R^2 \to \mathbb R$ given by := $$f(x,y) = \begin{cases} 0 & \text{, if xy=0  } \\ 1 & \text{, if xy $\neq$ 0} \end{cases}$$ I've to show that $\partial_1 f(0,0)=0=\partial_2 f(0,0)$. Also show that $f$ is not continuous at $0$.. I don't know how to calculate partial derivatives in this case.please if anyone can explain it to me...",['multivariable-calculus']
976166,Progressively Measurable for Right Continuous Adapted Processes,"Any adapted and right continuous process $X_t$ is progressively measurable. For the above statement, I found proof in several books. They all have similar argument as follows. For a given $t > 0$ and $n \in \mathbb N$, define the following funciton sequence 
$$
X_n(s) := X \left( \frac{(k+1)t}{2^n} \right), \ \ \mathrm{if} \ \frac{kt}{2^n} <s\leq \frac{(k+1)t}{2^n}.
$$
It is clear that $X_n$ is left continuous . My question is why use left continuous functions to approximate right continuous function, please? Or maybe it does not matter? At the beginning, I thought it is typo. However, all proof I read defines $X_n$ to be left-continuous. Thank you!.","['stochastic-processes', 'stochastic-analysis', 'self-learning', 'probability-theory', 'analysis']"
976187,Counting Number of Possibilities using Inclusion-Exclusion,"I have been tasked with answering the following combinatorics problem for a homework assignment: Consider the set of all six digit numbers that don’t begin with 0. How many of these
have at least one 0, at least one 1, and at least one 2? The professor hinted that we use inclusion-exclusion to solve it, but I am not really seeing to accomplish this. I have tried writing down some patterns and then finding rearrangements of them within the rules, but I am not arriving at the correct answer of 59790 (I wrote a program to count the size of the set). Given that this is homework I would prefer some guidance and not a full solution. Thanks!","['statistics', 'inclusion-exclusion', 'combinatorics']"
976199,Evaluating the double limit $\lim_{m \to \infty} \lim_{n \to \infty} \cos^{2m}(n! \pi x)$,"I have to find out the following limit $$\lim_{m\to\infty}\lim_{n\to\infty}[\cos(n!πx)^{2m}]$$ for $x$ rational and irrational. for $x$ rational $x$ can be written as $\frac{p}{q}$ and as $n!$ will have $q$ as its factor the limit should be equal to 1.
the second part of irrational is giving me problems. I first thought that limit should be zero as absolute value of cosine term is less than 1 and power it to infinity you should get $0$. But then I realised that it was wrong. I brought the limit down to this form. $$e^{-\sin^2(n!πx)m}$$ after this I find the question quite ambiguous as they have just said $x$ is irrational. If I take $x$ as $\frac{1}{n!π\sqrt{m}}$ I get the limit as $\frac{1}{e}$ but if I take  $x$ as $\frac{2}{n!π\sqrt{m}}$ I get the limit as $\frac{1}{e^4}$. please help me and tell me where have I gone wrong?","['calculus', 'limits']"
976200,Surface area of a sphere limits,"If I am finding the surface area of a sphere in spherical coordinates my intergral would be like this: $$\int^{\pi}_0 \int^{2\pi}_0 R^2 \sin (\theta) d\phi d\theta =4\pi R^2$$
But if I do the following: $$\int^{\pi}_0 \int^{2\pi}_0 R^2 \sin (\theta) d\theta d\phi =0$$ What makes the answers different? In both cases I am integrating over the same total area! What does the last integral represent?","['geometry', 'calculus', 'surfaces']"
976232,how to solve $a\sin x+b\cos x$ [duplicate],"This question already has answers here : Solving trigonometric equations of the form $a\sin x + b\cos x = c$ (7 answers) Closed 4 years ago . Let's solve: $\sqrt{3}\sin x - \cos x=2$ The left hand side may be expressed as $R\sin(x+ \phi)$ We know that $R=\sqrt{3+1}=2$ We also know that $\tan \phi= \frac{-1}{\sqrt{3}}$ The solution to $\tan \phi=\frac{-1}{\sqrt{3}}$ has many solutions, for example, -30, 150, 330 degrees etc. Which of these solutions do we accept? Or is it irrelevant which we will accept? Which of these solutions are acceptable? Thanks!",['trigonometry']
976241,Show that the Sorgenfrey line does not have a countable basis.,"I am trying to understand this proof from Munkres' book which shows that the Sorgenfrey line does not have a countable basis. His proof is: Let $\beta$ be a basis for $\mathbb{R}_l$. Choose for each $x$ an element $B_x \in \beta$ such that $x \in B_x \subset [x, x+1)$. If $y$ is not equal to $x$ then $B_y \neq B_x$ since inf($B_x$) = $x$ and $y$ = inf($B_y$). Therefore $\beta$ must be uncountable. I am new to topology so I am probably just missing a simple point but I do not see why $\beta$ must be uncountable according to this argument. I agree that $B_y \neq B_x$ but isn't it possible that $y \in B_x$ (and thus the set $B_y$ is not needed as part of the basis)? Thanks in advance for your help.","['general-topology', 'second-countable', 'sorgenfrey-line']"
976267,Prove that y>2x+1 is open?,"The answer is inserted but what I'm looking for is a heavy breakdown on this. My professor tried to explain to me a harder version but I don't understand it. Solution: What my prof does for the problems he has gone over is he first draws out a disk contained in S. Then he finds another point within the disk, moving it some small increment less than the radius of the disk. He tries to find a radius that will work for any point in S to show that it's open. In this case, he would do something like this ... (as a proof sketch) Let $z=(x,y) \in S$ with open disc of radius $\delta$, $D_r(z)$. If we take another point in the disc around z, say $z_0$, we would have $z_0 = (x+\alpha,y+\beta)$ for $|\alpha|<\delta$ and $|\beta|<\delta$. Then $y+\beta > 2(x+\alpha)+1$ $y+\beta > 2x + 2\alpha+1$ $y-2x-1>2\alpha-\beta$ Then he would probably do triangle inequality stuff here to get a value to get the radius $\delta$. I am not looking for alternative solutions (such as the use of inverses which we haven't covered). Can somebody please really really break this down for me and justify everything? I would really appreciate it, I've tried so hard to learn it but I just don't get it! Thank you.",['general-topology']
976276,Vanishing of Taylor series coefficient [duplicate],"This question already has an answer here : A question regarding power series expansion of an entire function [duplicate] (1 answer) Closed 8 years ago . I am solving previous year question paper some competitive exam. Give me some hint to solve the following problem. Let $f$ be an entire function. Suppose for each $a \in \mathbb{R} $ there exists at least one coefficient $c_n$ in $f(z) = \sum_{n=0}^{\infty} c_n (z-a)^n$ which is zero. Then, a) $f^{(n)}(0) = 0$ for infinitely many $n \ge 0$ b) $f^{(2n)}(0)=0$ $ \forall n \ge 0$ c) $f^{(2n+1)}(0)=0$  $ \forall n \ge 0$ d) $f^{(n)}(0) = 0$ for all sufficiently large n. Thanks in advance.","['power-series', 'complex-analysis']"
976290,Consider the family of lines $a(3x+4y+6)+b(x+y+2)=0$ Find the equation.......,"Question : Consider the family of lines $a(3x+4y+6)+b(x+y+2)=0$ Find the equation of the line of family situated at the greatest distance from the point P (2,3) Solution : The given equation can be written as $(3x+4y+6)+\lambda (x+y+2)=0$ 
$\Rightarrow x(3+\lambda)+y(4+\lambda)+6+2\lambda =0....(1)$ Distance of point P(2,3) from the above line (1) is given by D= $\frac{|2(3+\lambda)+3(4+\lambda)+6+2\lambda|}{\sqrt{(3+\lambda)^2+(4+\lambda)^2}}$ $\Rightarrow D = \frac{(24+7\lambda)^2}{(3+\lambda)^2+(4+\lambda)^2}$ Now how to maximize the aboved distance please suggest. Thanks","['optimization', 'geometry', 'coordinate-systems']"
976292,Definition of homogeneous ideal,"I'm a little confused about the definition of a homogeneous ideal. I have the following two definitions: An ideal $I\subset k[X_{0}, \dots, X_{n}]$ is homogeneous if $I$ is
generated by (finitely many) homogeneous polynomials. An ideal $I\subset k[X_{0}, \dots, X_{n}]$ is homogeneous if $I$ can 
be generated by homogeneous polynomials. So does a homogeneous ideal have to be an ideal generated only by finitely many homogeneous polynomials or do we allow the infinite case? I know that every ideal can be generated by finitely many when $k$ is a field, but an ideal, which we have generated by an infinite number of homogeneous polynomial, is not necessarily generated by a finite number of homogeneous polynomials.. right? To clarify my last sentence: I had an exercise where $I\subset k[x_{1}, \dots, x_{n} ]$ is an ideal and $I^{h}$ was the ideal generated by $\lbrace f^{h};f\in I \rbrace$ where $f^{h}$ is the homogenization of $f$ i.e. it is a homogeneous polynomial. The exercise was to show that $I^{h}$ is a homogeneous ideal. From the second definition above, this is ""obvious"" a homogeneous ideal (since it is generated by homogeneous polynomials). But from the first definition we actually have to show that it can be generated by a finite number of homogeneous polynomials. The solution I was given, was not a trivial solution.",['algebraic-geometry']
976323,I have a question about infinite partially ordered sets.,"If I have an infinite partially ordered set $P$ where every chain has finite order and I take some maximal element $x_1$ (which must exists because our chains are finite) and then I take a maximal element $x_2\in P-{x_1}$ is it true that $\{x_1,x_2\}$ is an anti chain? I don't think it is but I am not quite sure to find a counterexample. What I think is true, but not quite sure how to prove it.    $\downarrow$ If I take some element $x_1\in P$ and then consider its maximal chain $T_1$ and consider the maximal element $t_1\in T_1$ and then take some $x_2\in P-T_1$ and consider its maximal chain $T_2$ with maximal element $t_2$ and continue this, then $\{t_1,t_2,t_3...\}$ is an anti chain. Is any of this true?","['elementary-set-theory', 'order-theory']"
976329,Measure theory convention that $\infty \cdot 0 = 0$,"In the preface of Terry Tao's notes on measure theory he states that in the extended real number setting we adopt the convention that $\infty \cdot 0 = 0 \cdot \infty = 0.$ He explains that it's a useful convention which makes it natural to define integration from below (e.g. integrals as supremums of nonnegative simple functions). He seems to be saying, ""Let's define it this way, because it makes our lives simpler."" Is more justification not needed? This 'fact' helped me during my midterm today in showing that $\mu(E \times \mathbb{R})=0$ for any measure-zero set $E$, but I felt sleazy using it. Any thoughts (philosophical or otherwise) on why or how we can do this and still have self respect as mathematicians?","['measure-theory', 'real-analysis']"
976330,On Neumann-series of matrices,"Let $A \in \mathbb{R}^{n \times n}$ and we denote with $\rho(A)$ the spectral radius of $A$ and with $I_n \in \mathbb{R}^{n \times n}$ the identitiy matrix . Applying Carl Neumann's result on matrices we know that if $\rho(A)<1$ then $(I-A)^{-1}$ matrix exists and
$$(I_n-A)^{-1}=\sum_{k=0}^{\infty} A^k.$$ Is it true backwards? So if $(I-A)^{-1}$ matrix exists and $(I_n-A)^{-1}=\sum_{k=0}^{\infty} A^k$, then $$\rho(A)<1?$$ If it is how could we prove it? If not: give a counter-example with a positive $A$ matrix if it's possible.","['matrices', 'linear-algebra', 'sequences-and-series']"
976334,How to show the following definition gives Wiener measure,"On the first page of Ustunel's lecture notes, he defines the Wiener measure in the following way: Let $W = C_0([0,1]), \omega \in W, t\in [0,1]$, define $W_t(\omega) = \omega(t)$. If we denote by $\mathcal{B}_t = \sigma\{W_s; s\leq t\}$, then there is one and only one measure $\mu$ on $W$ such that 1) $\mu \{W_0(\omega) = 0\} = 1$ 2) $\forall f \in C_b^{\infty}$, the stochastic process 
$$(t, \omega ) \mapsto f(W_t(\omega)) - \dfrac{1}{2}\int_0^tf''(W_s(\omega))ds$$ is a $(\mathcal{B}_t, \mu)$-martingale. $\mu$ is called the Wiener measure I am more familiar with the definition which supposes that we have already a Brownian motion $B_t$ available and then define 
$$\nu\left(\{\omega: \omega_{t_1} \in A_1, \cdots, \omega_{t_n} \in A_ n\}\right) = P(B_{t_1} \in A_1, \cdots, B_{t_n} \in A_ n)$$ My question is why $\mu$ and $\nu$ are the same? Of couree if we begin with $\nu$ and use Its's formula, we can see the two conditions defning $\mu$ are verified. But if we begin with the definition of $\mu$, how can we verify the condition defining $\nu$? In addition, in Ustunel's notes, he first presented his definition of Wiener measure then introduced stochastic integral. So I am wondering if there is a way to begin with the definition of $\mu$, then to show $\mu$ satisfies the condition defining $\nu$ without using stochastic integral. Of course I will still appreciate it if you help me show $\mu \implies \nu$ using stochastic integral. Thank you!","['wiener-measure', 'martingales', 'measure-theory', 'probability-theory', 'brownian-motion']"
976359,Why is Division harder than Multiplication?,Both conceptually and computationally it feels easier to see that: $ 6 \cdot 3.7 = 22.2$ than it is to see that $ 22.2 \div 6 = 3.7 $. Thoughts about the roots of this asymmetry? An analogous question might be asked of anti-differentiation and differentiation...,"['arithmetic', 'mental-arithmetic', 'algebra-precalculus']"
976369,Borel algebra on the postive real line,"I´m considering the borel sigma algebra on the positive real line, $ \mathcal{B} (\mathbb{R}_+ ) $ and  I would like to show that intervals given by $\{ [0,t] : t \in  \mathbb{R}_+ \}$ satisfy that $ \sigma ( \{ [0,t] : t \in  \mathbb{R}_+ \} ) = \mathcal{B} (\mathbb{R}_+ ) $ is there a simple (obvious) way to proof this claim?",['measure-theory']
976415,Convergence of infinite product of prime reciprocals?,"Where p n is the n th prime number, does the infinite product
$$\prod_{n=1}^{\infty}\left(1-\frac{1}{p_n}\right)$$
converge to a nonzero value? (Any help would be much appreciated!)","['convergence-divergence', 'infinite-product', 'number-theory', 'prime-numbers', 'limits']"
976426,Special values of the classical normalized Eisenstein series,I am looking for a comprehensive list of some known special values of the classical normalized Eisenstein series $E_4(\tau)$ and $E_6(\tau)$. Does anyone know where I can find a table of some known explicit values of $E_4(\tau)$ and $E_6(\tau)$?,"['modular-forms', 'sequences-and-series', 'reference-request']"
976462,A 1400 years old approximation to the sine function by Mahabhaskariya of Bhaskara I,"The approximation $$\sin(x) \simeq \frac{16 (\pi -x) x}{5 \pi ^2-4 (\pi -x) x}\qquad (0\leq x\leq\pi)$$ was proposed by Mahabhaskariya of Bhaskara I, a seventh-century Indian mathematician. I wondered how much this could be improved using our computers and so I tried (very immodestly) to see if we could do better using $$\sin(x) \simeq \frac{a (\pi -x) x}{5 \pi ^2-b (\pi -x) x}$$ I so computed $$\Phi(a,b)=\int_0^{\pi} \left(\sin (x)-\frac{a (\pi -x) x}{5 \pi ^2-b (\pi -x)x}\right)^2 dx$$ the analytical expression of which not being added to the post. Settings the derivatives equal to $0$ and solving for $a$ and $b$, I arrived to $a=15.9815,b=4.03344$ so close to the original approximation ! What is interesting is to compare the values of $\Phi$ : $2.98 \times 10^{-6}$ only decreased to $2.17 \times 10^{-6}$. Then, no improvement and loss of attractive coefficients. Now, since this is a matter of etiquette on this site, I ask a simple question: with all the tools and machines we have in our hands, could any of our community propose something as simple (or almost) for basic trigonometric functions ? In the discussions, I mentioned one I made (it is probable that I reinvented the wheel) in the same spirit $$\cos(x) \simeq\frac{\pi ^2-4x^2}{\pi ^2+x^2}\qquad (-\frac \pi 2 \leq x\leq\frac \pi 2)$$  which is amazing too !","['trigonometry', 'approximation', 'math-history']"
976498,checking whether functions satisfy Inverse Function Theorem.,"I've my exam tomorrow and this question is expected  to come but donot know how to solve... Here's the INVERSE FUNCTION THEOREM stated in my notes: It says: Let $E\subseteq \mathbb R^n$ be open  and $f:E\to \mathbb R^n$ be a $C^1$ map. Suppose that for some $a\in E$,the linear map $f'(a)$ is invertible, and $b=f(a)$.Then there are open set $U$ and $V$ in $\mathbb R^n$ ,s.t. $a\in U,b\in V$ and $f|_U$ is $1-1$ and onto V,that is $f(U)=V$ If g is inverse of $f|_U$ ,so $g:V\to U$ and $g(f(x))=x$ for all $x\in U$,then $g\in C^1(V,U)$ I had to check whether following satisfy the above hypothesis of inverse function theorem on $D$: $1.)$ $g(x)=x+c$ , $D=\mathbb R^n$ , $2.)$ $g(s,t)=(s+2)e_2+(s-t)e_2$ , $D=\mathbb R^2$ , $3.)$ $g(s,t)=(s^2-t^2)e_2+(st)e_2$ , $D=\mathbb R^2$ \ ${(0,0)}$. I think that $1.)$ satisfies all hypothesis as it has a inverse.... 
I don't know how to solve these questions...any hint...","['multivariable-calculus', 'inverse', 'calculus', 'analysis']"
976504,"Finding the fourth roots of $\,5(\cos(3)+i\sin(3)).$","Find the four fourth roots of $\,5(\cos(3)+i\sin(3)).$ I tried to convert to polar form so I could set up an equation like $\,x^4=5e^{i3},\,$ but I am unsure to continue.","['trigonometry', 'complex-numbers']"
976536,"Number of possible permutations of n1 1's, n2 2's, n3 3's, n4 4's such that no two adjacent elements are same?","Given $n_1 $ number of  $1 $'s,  $n_2 $ number of  $2 $'s,  $n_3 $ number of  $3 $'s,  $n_4 $ number of  $4 $'s. form a sequence using all these numbers such that two adjacent numbers should not be same. I have tries lot of things but nothing worked. can somebody tell me how to solve this problem?","['permutations', 'sequences-and-series', 'combinatorics']"
976546,$\mathbb Z^n$ as a quotient of $\mathbb Z^m$,"It is quite obvious that if $n\le m$, the group $\mathbb Z^n$ can be obtained as a quotient of $\mathbb Z^m$. But is the converse statement also true? That is, if $\mathbb Z^n$ is a quotient of $\mathbb Z^m$, is $n\le m$? In that case, is there an easy proof?",['group-theory']
976550,Fundamental limit in two variables,"Can I write that  $$\lim_{(x,y)\to(0,0)}\frac{\sin(x^2+y^2)}{x^2+y^2}=\lim_{u\to0}\frac{\sin(u)}{u}$$
and, hence, that $\lim_{(x,y)\to(0,0)}\frac{\sin(x^2+y^2)}{x^2+y^2}=1$? If so, why can I do it?","['multivariable-calculus', 'calculus', 'continuity', 'limits']"
976551,"Evaluate $\int_0^{2 \pi} \sin \theta \cos^2 \theta \,d\theta$","The problem is to integrate $$\int_0^{2 \pi} \sin \theta \cos^2 \theta \,d\theta.$$
What I have tried is substituting $t := \cos \theta$, but the new limits of integration are equal to each other. How do I resolve this?","['calculus', 'integration', 'definite-integrals', 'trigonometry', 'trigonometric-integrals']"
976591,Hermitian and self-adjoint operators on infinite-dimensional Hilbert spaces,"I am a physicist and I am trying to get a grasp on the following terms from functional analysis: As I understand, an operator is Hermitian if it is symmetric and bounded (domains of A and A* don't need to be equal in this case.) An operator is selfadjoint if it is symmetric and the domains of A and A* are equal, D(A) = D(A*), so A = A*. My question is, is the boundedness here an artefact of the finiteness of the Hilbert space? I.e., in the finite Hilbert spaces we can 'safely' work with the Hermitian operators, but in the infinite Hilbert spaces we lose the notion of boundedness, so we need to start to work with self-adjoint operators? Or, if I am completely wrong here, what is the difference between the self-adjoint and Hermitian operator, in the context of finite vs. infinite Hilbert space?","['hilbert-spaces', 'functional-analysis']"
976595,How do you calculate randomness?,"Suppose I receive a list of 1 million coinflips, and I want to know how likely it is that the list was randomly generated. My first thought would be to count the number of heads and tails, which should be evenly distributed (around 500.000). But suppose the distribution looks normal, its still possible the list contains patterns or repititions. For example, the first half of the list may be the heads, and the last half the tails. In real random data, that would be highly unlikely. So how do you calculate the 'randomness' of this list?","['statistics', 'random']"
976608,"Prove $\int_{0}^{\pi/2} x\csc^2(x)\arctan \left(\alpha \tan x\right)\, dx = \frac{\pi}{2}\left[\ln\frac{(1+\alpha)^{1+\alpha}}{\alpha^\alpha}\right]$","When I showed to my brother how I proved \begin{equation}
\int_{0}^{\!\Large \frac{\pi}{2}} \ln \left(x^{2} + \ln^2\cos x\right) \, \mathrm{d}x=\pi\ln\ln2
\end{equation} using the following theorem by Mr. Olivier Oloa \begin{equation}{\large\int_{0}^{\!\Large \frac{\pi}{2}}} \frac{\cos \left( s \arctan \left(-\frac{x}{\ln \cos x}\right)\right)}{(x^2+\ln^2\! \cos x)^{\Large\frac{s}{2}}}\, \mathrm{d}x = \frac{\pi}{2}\frac{1}{\ln^{\Large s}\!2}\qquad,\;\text{for }-1<s<1.\end{equation} He showed me the following interesting formula \begin{equation}
\int_{0}^{\!\Large \frac{\pi}{2}} x\csc^2(x)\arctan \left(\alpha \tan x\right)\, \mathrm{d}x
=\frac{\pi}{2}\,
\ln\left(\left[1 + \alpha\right]^{1 + \alpha}
\over \alpha^\alpha\right)\,,\qquad
\mbox{for}\ \alpha > 0\tag{✪}.
\end{equation} I tried several values of $\alpha$ to check its validity ( since he always messes around with me ) and the numerical results match the output of Mathematica $9$ . The problem is how to prove this formula since he didn't tell me ( as always ). I tried Feynman's integration trick and I arrived to the following result: \begin{equation}\partial_\alpha\int_{0}^{\!\Large \frac{\pi}{2}} x\csc^2(x)\arctan \left(\alpha \tan x\right)\, \mathrm{d}x = \int_{0}^{\!\Large \frac{\pi}{2}} \frac{x\cot x}{\cos^2x+\alpha^2 \sin^2 x}\, \mathrm{d}x\end{equation} but I am having difficulty to crack the very last integral. Could anyone here please help me to prove the formula $(✪)$ preferably with elementary ways (high school methods)? Any help would be greatly appreciated. Thank you.","['closed-form', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
976625,Is Linear Algebra the foundation of Applied Mathematics?,"I've lately taken an interest in foundations of my field. While there are many important areas that contribute to Applied Mathematics (differential equations, probability & statistics, numerical methods, combinatorics), it seems that Linear Algebra is an essential ingredient in most Applied Mathematics projects. If one had to take only one course after the general calculus sequence, it seems like advanced Linear Algebra would be the choice, hands-down. As examples: In statistical applications, you often rely on solutions falling (at least approximately) in the space of Normal distributions, which is a linear space defined over the reals. The differential operator is a linear operator, so you can represent systems of differential equations using linear algebra. Numerical methods typically linearize a problem and then iterate to converge to a solution. Is this just an artifact of my experiences, or is Linear Algebra really the foundational framework/theory of applied mathematics?","['applications', 'linear-algebra', 'soft-question']"
976658,How to calculate $\lim_{x \rightarrow \infty} (4x\arctan(x)-2\pi x)$,"How to calculate $$\lim_{x \rightarrow \infty} (4x\arctan(x)-2\pi x)$$ ? I checked Wolframalpha and the answer is -4, shall I use some kinda standard limit? I dont get anywhere.","['calculus', 'limits']"
976665,"Show that $\, 0 \leq \left \lfloor{\frac{2a}{b}}\right \rfloor - 2 \left \lfloor{\frac{a}{b}}\right \rfloor \leq 1 $","How can I prove that, for $a,b \in \mathbb{Z}$ we have $$ 0 \leq \left \lfloor{\frac{2a}{b}}\right \rfloor - 2  \left \lfloor{\frac{a}{b}}\right \rfloor \leq 1 \, ? $$ Here, $\left \lfloor\,\right \rfloor$ is the floor function.  I tried the following: say that $\frac{2a}{b} = x$, and $ \left \lfloor{\frac{2a}{b}}\right \rfloor = m$, with $0 \leq x - m \leq 1$. I tried the same for $ 2 \left \lfloor{\frac{2a}{b}}\right \rfloor $, and then combining the two inequalities. It did not seem to help, though.","['inequality', 'fractions', 'algebra-precalculus', 'ceiling-and-floor-functions']"
976688,Murder at Hilbert's Hotel! A study of the testimony of infinitely many suspects.,"I'm sorry if this is a duplicate in any way. I doubt it's an original question. Due to my ignorance, it's difficult for me to search for appropriate things. Motivation. This question is inspired by Exercise 1.2.16 of these logic notes by S. G. Simpson. Here is a shortened version of that exercise for convenience. Brown, Jones, and Smith are suspected of a crime. They testify as follows: Brown: Jones is guilty and Smith is innocent. Jones: If Brown is guilty then so is Smith. Smith: I’m innocent, but at least one of the others is guilty. a) Are the three testimonies consistent? b) The testimony of one of the suspects follows from that of another. Which from which? c) Assuming everybody is innocent, who committed perjury? d) Assuming all testimony is true, who is innocent and who is guilty? e) Assuming that the innocent told the truth and the guilty told lies,
who is innocent and who is guilty? I like to challenge friends and family with similar problems. It's fun to make up scenarios and the solutions are fairly easy to those familiar with basic mathematical logic. I can vary the testimonies, the number of suspects, the questions about the testimonies, etc. ; it's good stuff. Lately, though, I've wondered what it would mean to have (at least countably) infinitely many suspects . To make the problem tractable the testimonies would need some sort of defining rule and the questions ought to address appropriate groups of suspects . The Question. With this in mind, here's my scenario. On the morning of the first night at Hilbert's hotel , when all the rooms were taken, the receptionist was found dead at his desk; it looked extremely suspicious. Was he murdered? The police interviewed all the tenants and staff, and concluded that the staff couldn't possibly have been involved in the death. However, the tenants had some interesting testimonies which amounted to the following. $[\dots ]$ Okay, so I've given this some thought and I suspect that the original set up is at least similar to letting $$\begin{align}
\text{Brown}&\mapsto [1]_3:=\{n\in\mathbb{N}\mid n\cong 1\pmod{3}\}, \\ 
\text{Jones}&\mapsto [2]_3, \\
\text{Smith}&\mapsto [3]_3,
\end{align}$$ where each number $n$ represents the tenant in Room $n$ , then changing the testimonies accordingly . (I'll leave that as an exercise for the reader (ha!): this is too long already.) Immediately, I'm reminded of the notion of presentations and freeness . The above smells like a presentation (or perhaps some kind of homomorphism ). I suppose my main bunch of questions here are: What is this thing? What's a better, more formal way of describing the mathematics behind this scenario? What similar things have been done before? The reason why I included the (number-theory) tag is that I'm curious now as to what number theoretic problems, if any, can be phrased this way . (Does that make any sense?) Thoughts and Clarification. This is based on the comments. It's more about the maps between the infinite and finite cases. A thorough answer would include a mathematical description of what the infinite case is, a mathematical description of how the infinite case relates to finite cases , details on what similar things have been done before, and perhaps a number-theoretic problem phrased using the above. One has to take into account negations in the infinite case in such a way that the structure of the given finite case is preserved . I suspect that they're just different models of the same theory , where the infinite case is in some sense ""free""; that maps like the one given above are somehow related to the notion of a presentation ; and that at least some trivial Number Theory problems can be stated this way. :)","['logic', 'model-theory', 'number-theory']"
976739,On clarifying the relationship between distribution functions in measure theory and probability theory,"I recently found myself confusing concepts from measure theory and probability theory, so I'd like to get an idea for what I'm misunderstanding. This definition is what started it all: A sequence $\{X_{n}\}$ of random variables converges in distribution to $X$ if $$\lim_{n \to \infty} F_{n}(x) = F(x)$$ for every number $x \in \mathbb{R}$ at which $F$ is continuous. Concerns: 1) Recalling that random variables are really just measurable functions, am I to understand that each distinct measurable function is associated with a unique Distribution Function by which its probability content is evaluated? I was always under the impression that we use the Lebesgue measure (and its corresponding Distribution Function) to calculate the probability of random variables we encounter in general (except in abstract spaces). Is this just flat out wrong? 2) I also know that for any increasing, right-continuous function $F: \mathbb{R} \to \mathbb{R}$, there is a unique Borel measure $\mu_{F}$ such that $\mu_{F}((a,b]) = F(b) - F(a)$ for all $a,b$. Conversely, given a Borel measure on $\mathbb{R}$ that is finite and bounded on all Borel sets, we can uniquely associate it with a real-valued, right-continuous and increasing function. Okay, so by Littlewood's principles, we know that measurable functions are nearly continuous. So this could justify associating each random variable $X_{n}$ with a unique Distribution Function $F_{n}$. But random variables (i.e., measurable functions) don't have to be increasing, so that adds to my confusion. Short Summary: 1) To calculate the probability of a generic real-valued random variable, do we just use the CDF associated with Lebesgue measure, or does the random variable have its own CDF? 2) If we can associate a CDF to a general random variable, how is this done is the function is not increasing?","['probability-theory', 'measure-theory', 'probability']"
976749,Show that a polynomial $P(x)$ has $r$ as a double root if and only if $P'(r)=0$ and $P(r)=0$,"Assuming that $r$ is a double root. Then $$P(x)=(x-r)^2\cdot k(x).$$ We also have the derivative: $$P'(x) = 2(x-r)k(x) + (x-r)^2k'(x).$$ Hence, $$P(r) = (r-r^2)k(r)=0$$ and $$P'(r) = 2(r-r)k(r) + (r-r)^2k'(r) = 0.$$ What I cannot show is the converse, that is, assuming that $r$ is a root of $P(x)$ ($P(r)=0$) and $P'(x)$ ($P'(r)=0$); how can we prove that $r$ is a double root of $P(x)$?","['calculus', 'roots', 'polynomials']"
976750,"Functions in $L^p(\mathbb{R}^n)$, are tempered distributions.","How to prove that functions in $L^p(\mathbb{R}^n),1 \leq p \leq \infty$, are tempered distributions.","['functional-analysis', 'lp-spaces']"
976755,Analogous of Markov's inequality for the lower bound,"Consider a positive random variable $X$ and call $E[X]$ its expectation.
For any positive $a \in \mathbb{R}$, an upper bound for the probability of $P(X>a)$ is provided by the Markov's Inequality,
$$
P(X>a) \leq \frac{E[X]}{a},
$$
Is there an analogous lower bound that is based only on the knowledge of the expectation?","['inequality', 'random', 'probability-theory', 'probability-distributions', 'probability']"
976762,Whats the connection between Turing machine and First order logic?,"Today in my Computing class i came across the theorem which states that., If language $L$ and $\Sigma^*\setminus L$ are recursively enumerable then L is recursive (total turing machine). Which looks very similar to the Δ elemantary class which has the property that if a model $M$ and its complement are Δ elementary class then $M$ is elementary. So i am curious as to how do some of the elementary and Δ elementary classes relate to recursively enumerable and recursive languages? For example: Connected graphs are not elementary class. How does that problem translate to turing machine? (As i can write a halting program to find whether a graph is connected or not). EDIT: Seems like decidability of First-order theories has got lot to do with the recursive-enumerability of the Language (Godel's theorem). I instinctively feel that there is some more relation to Δ elementary and recursively enumerable  languages and i still dont completely get it. Or does a elementary class decide the 'decidability' of the theory?","['computability', 'turing-machines', 'discrete-mathematics', 'first-order-logic']"
976768,Question definition: If I take any three vectors...,"I am currently studying linear algebra and one of the things I am having trouble with concerns understanding the questions being asked to me. The following question I am having trouble defining. The following question is in R2 space. If I take any three vectors, u, v, w in the plane, will there always
  be two different combinations that produce... (and the question
  continues, I understand the rest of the question) What I don't understand is the ""If I take any three vectors, u, v, w in the plane"". Does this mean I can take for example u, u and u (effectively three u vectors, as it states: any three vectors and figure out different combinations with them etc.). Or perhaps u, u and v? Or does it mean u, v, w specifically. I know this might seem like a stupid question.",['linear-algebra']
976777,An asymptotic expression of sum of powers of binomial coefficients.,"Let $k$ be a fixed positive number and $n$ an integer increasing to infinity. Then  $$\sum_{\nu =0}^n \binom{n}{\nu}^k \sim \frac{2^{kn}}{\sqrt{k}} \left( \frac{2}{\pi n} \right)^{\frac{k-1}{2}}.$$  This is from Polya's Problems and Theorems in Analysis , Vol. 1, Part II, Problem 40. The proof provided in the book is too simple. It says details can be found in Jordan's Cours d'Analyse , Vol.2, 3rd Ed, pp. 218-221. However, I cannot find this edition online, and what's worse, there is not any English translations. Can anyone give a proof in detail?","['asymptotics', 'binomial-coefficients', 'analysis']"
976778,How do I prove that finitely generated group with $g^2=1$ is finite?,"Let $G$ be a finitely generated group. Assume for all $g\in G, g^2=e$. Then, how do I show that $G$ is actually finite? I don't know where to start..",['abstract-algebra']
976811,To find the extreme values of function,"can anyone just help me with the below stated problem: Show that: $1.)$ $\text{sin}(x)+\text{sin}(y)+\text{sin}(x+y)$ , $x,y\in [0,\pi/2]$ has a global maximum $3\sqrt3/2$ at $(\pi/3,\pi/3)$ and global minimum at $(0,0)$ . $2.)$ $f(x,yz)=xyz(1-x-y-z)$ has a maximum at $(1/4,1/4,1/4).$ $3.)$ $f(x,yz)=(x+z)^2+(y+z)^2+xyz$ has no extrema. $4.)$ maximum value of $\text{cos}~a+\text{cos}~b+\text{cos}~c$ where $a,b,c$ are angle of triangle.... I could just have an idea of solving $4.)$ by taking $c=\pi-(a+b)$ and then maximizing the function: $\text{cos}~a+\text{cos}~b+\text{cos}~(a+b)$ where $a,b\lt \pi$ and then take $\partial_af(a,b)=0$ and $\partial_b{f(a,b)}=0$ .... any hint of how to solve the rest of them...... Please help...","['multivariable-calculus', 'calculus', 'partial-derivative']"
976813,"Half-Fourier transform, relation to Delta function","so the Fourier transform of the Kronecker Delta function is (up to sign conventions / normalisation) $$\int_{-\infty}^\infty dt\; e^{i t \omega} = \delta(\omega).$$ Can one say anything about the half-Fourier transform $$\int_0^\infty dt\; e^{i t \omega}$$ and its relation to the Kronecker Delta function? Specifically, I have come across the relation $$\int_0^\infty dt\; \textrm{Re}[e^{i t \omega}]  \;\;\Big(=\int_0^\infty dt \cos( t \omega)\Big) \;\;= \delta (\omega),$$ but cannot seem to prove this. Any ideas?","['fourier-analysis', 'integration', 'dirac-delta', 'complex-integration', 'complex-analysis']"
976843,"If $\lim_{n\rightarrow\infty} f(n+1) - f(n) = L$, prove that $\lim_{n\rightarrow\infty} f(n)/n = L$","Here's the problem in full. I've stared at it for hours and can't get anywhere, so a hint would be nice. Suppose that $f:\mathbb N\rightarrow\mathbb R$. If $$\lim_{n\rightarrow\infty}f(n+1)-f(n) = L$$ prove that $\lim_{n\rightarrow\infty}f(n)/n$ exists and equals $L$. This problem is marked with the word ""Cauchy"", so I'm guessing Cauchy sequences or something related to them will be necessary, but I can't figure out what. Edit: It appears as if the Stolz-Cesaro Theorem makes this quite easy. Unfortunately though, we have not discussed this, so I won't be able to use this.",['limits']
976862,"Prove $1.43 < \int_0^1 e^{x^2}\,\mathrm{d}x < \frac{e+1}{2}$","Prove $$1.43<\int_0^1 e^{x^2}\,\mathrm{d}x<\frac{e+1}{2}$$ What I did: As I have no idea how to approach the left inequality I work with $$\int_0^1 e^{x^2} \mathrm{d}x<\frac{e+1}{2} \iff \int_0^1 e^{x^2} \mathrm{d}x<\int_0^1 \frac12 (e+x)\mathrm{d}x \iff e^{x^2}<\frac12(e+x) \iff x^2<\log (e+x)-\log 2$$ I don't know how to proceed.","['inequality', 'calculus', 'integral-inequality']"
976865,Can the measure of zeroes of a harmonic function be positive?,"Let $u$ be a non-constant harmonic function of two variables defined, say, in the unit disk (or on the half plane for example). It is known that $u$ can vanish on some lines, as it discussed in here . But can $u$ vanish on a set of positive measure ?","['harmonic-functions', 'roots', 'complex-analysis']"
976866,Prove that $A=B$ according to the conditions involving relative complements,"Prove that if the relative complement of $A$ with respect to a set $E$ is equal to the relative complement of $B$ with respect to a set $E$, then $A=B$.",['elementary-set-theory']
976869,trouble solving the integral of $\cos(x^2)$,"No, I really mean the integral of $\cos(x^2)$, not $[\cos(x)]^2$. Can the chain rule be applied here?","['trigonometry', 'calculus', 'integration']"
