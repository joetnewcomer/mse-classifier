question_id,title,body,tags
1831743,The standard deviation is more stable than the mean?,"In an introduction to the subject of hypothesis testing, a book on probability and statistics for engineering students has a statement asserting that ""the standard deviation is more stable than the mean' (paraphrased). The context is paraphrased as follows: A machine packs packages of powered sugar. If the machine works properly, then the weight of each package is normally distributed with a mean 0.5kg and a standard deviation 0.015kg. One day, a worker randomly selected 9 bags of powered sugar packed by the machine, with the following weights: 0.497kg, 0.506kg, 0.518kg, 0.524kg, 0.498kg, 0.511kg, 0.520kg, 0.515kg, 0.512kg Use this to decide whether the machine was working properly. In order the derive a solution, the books does the following (still paraphrased): Let the random variable $X$ denote the weight of a package of powered sugar on this particular day, and let $\mu$ and $\sigma$ denote the mean and the standard deviation of $X$ respectively. Experience suggests that the standard deviation is more stable than the mean. So we may suppose that $\sigma=0.015$ . Thus $X\sim \mathcal{N}(\mu, 0.015^2)$ , with $\mu$ unknown. With this in mind, we propose two hypotheses: $$H_0: \mu = 0.5, \qquad H_1: \mu\neq 0.5.$$ We want to use the data available to decide which one to accept. The book then proceeds to introduce the statistic $$ \frac{\bar{X}-\mu}{\sigma/\sqrt{n}}$$ to do the hypothesis testing. The questionable assumption about the standard deviation being equal to 0.015 aside, I want to know whether it is true that 'experience suggests that the standard deviation is more stable than the mean'. And if this is true, do we have a theoretical explanation? I was thinking that perhaps we could interpret it this way: Denote the weight of a package produced by the machine when it is working properly by the random variable $Y$ , then $Y\sim \mathcal{N}(\lambda, \theta^2)$ , for some $\lambda$ and $\theta>0$ . Then taking all possible factors into account, maybe we could view the weight of a package produced by the machine in each possible state (broken or not) as a new variable $Y_i\sim \mathcal{N}(\lambda, \theta^2)$ , with all the $Y_i$ independent and indentically distributed. Then the statement is saying that for an $n$ large enough $$ D(\bar{Y}) \geq D(S), \tag{1}$$ where $\bar{Y}$ is the sample mean $\bar{Y}=\frac{1}{n}\sum_{i=1}^n Y_i$ , and $S$ is the sample standard deviation, with $S^2=\frac{1}{n-1}\sum_{i=1}^n (Y_i-\bar{Y})^2$ . But it is not very difficult to see that Inequality $(1)$ is not always true. Failing to find any reference about this statement, I ask for your help!","['means', 'normal-distribution', 'standard-deviation', 'statistics', 'probability']"
1831755,What will happen if evolve metric under Ricci flow on general manifold? [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question Because the scalar curvature under Ricci flow evolve by
$$
\partial_t R=\Delta R+ 2|Ric|^2
$$
I treat it as heat equation with heat source . So, no matter the heat source is very hot or not ,  the scalar curvature will be positive everywhere on manifold ,if $\int _M R_{t=0}dV >0$. But this condition don't means the curvature is positive in everywhere at beginning .  And not all manifold can be placed metric with positive curvature. So, on such manifold, the Ricci flow will evolve the manifold to unconnected parts if we suitably cut and mend  the singularity. At last the different parts will evolve to manifold with  non-negative curvature. So, in fact ,Ricci flow can be used as a way to cut manifold to non-negative  curvature  parts.  And in the process, the manifold only can be placed metric with negative curvature will be decomposed (if there is such manifold) . So There is a way of  classification manifold contained in Ricci flow. But as I know , there are only preliminary work of classify 4-manifold. I just happen to think of this ,and my base is weak . So I don't know whether right this idea. Maybe , this is not a precise question , but I really curious about it .","['riemannian-geometry', 'ricci-flow', 'curvature', 'soft-question', 'differential-geometry']"
1831788,Functional equation $P(X)=P(1-X)$ for polynomials,"I have encountered the following problem : Find all polynomials $P$ such as $P(X)=P(1-X)$ on $\mathbb{C}$ and then $\mathbb{R}$. I have found that on $\mathbb{C}$ such polynomials have an even degree. Because for each $a$ root, $1-a$ must be a root too. I struggle to find whether we can do something with polynomials of degree $2$ on $\mathbb{R}$. I was also wondering if we could find a general solution for $P(X)=P(aX+b)$ with $a$ and $b$ complexe for $P$ defined either on $\mathbb{R}$ or $\mathbb{C}$.","['polynomials', 'functional-equations', 'reflection', 'algebra-precalculus', 'symmetry']"
1831791,What is $\mbox{Tr}^2(A)-\mbox{Tr}(A^2)$ in terms of the eigenvalues of $A$?,"I am looking for a way to relate the terms of the characteristic polynomial of a $3 \times 3$ matrix to its eigenvalues. The definition I start with (taken from Wolfram MathWorld ) is $\\P_{3}(A)=x^{3} + \mbox{Tr}(A)x^{2} + (\mbox{Tr}^{2}(A) - \mbox{Tr}(A^{2}))x^1 +(\mbox{Tr}^{3}(A) + 2 \mbox{Tr} (A^{3}) -3 \mbox{Tr} (A) \mbox{Tr}(A^{2}))x^0$ Which can also be written as $\\P_{3}(A)=x^{3} + \mbox{Tr}(A)x^{2} + (\mbox{Tr}^{2}(A) - \mbox{Tr}(A^{2}))x^1 + \det(A)x^0$, which again can be rewritten using the properties of eigenvalues as $\\P_{3}(A)=x^{3} + x^{2} \sum_{i=1}^{i=3} \lambda_{i} + x^1(\mbox{Tr}^{2}(A) - \mbox{Tr}(A^{2})) + x^0 \prod_{i=1}^{i=3} \lambda_{i}$ . I am wondering is there a way to relate the term in $x$ also to the eigenvalues in a similar way that can be done in with the terms in $x^{2}$ and $x^{0}$? Thanks!","['matrices', 'eigenvalues-eigenvectors', 'polynomials']"
1831871,Show that $tE(1/X;X>t)\to0$ when $t\to0+$,"Let $X\geqslant 0$ be a random variable，then $$\lim_{t\rightarrow 0+}{ \,\,t\int_{\left [ X> t \right ]} \frac{1}{X} \, {\mathrm{d}\mathbb{P}} }=0$$ I have no idea of how to prove it.","['probability-theory', 'integration']"
1831908,Find the sum of angles without trigonometry?,I have found the sum it's $180$ but using right triangle and sine theorem.,"['puzzle', 'euclidean-geometry', 'geometry']"
1831975,Isometry map on a compact metric space,"Let $X$ be a compact metric space and $f : X\rightarrow X$ such that $d (x,y)\le d (f(x),f(y))$ for all $x,y\in X$. Prove that $f$ is an isometry. I am getting stuck on this question. Can any one help me ?","['general-topology', 'real-analysis', 'functional-analysis']"
1831986,"Differentiation under the integral sign, where the partial derivative of the integrand is not bounded by a Lebesgue integrable function.","Let $K(t)=\int_1^\infty u(t,x)\ \mathrm{d}x$, where $$u(t,x)=\frac{\cos{tx}}{x^2}\mathbb{1}_{[1,\infty)}(x).$$
I need to show that, for $t>0$, $$\frac{dK}{dt}(t)=\frac{1}{t}\left(K(t)-\cos{t}\right).$$
I have shown that $\int_1^\infty \frac{\partial}{\partial t}u(t,x)\ \mathrm{d}x$ is equal to the right-hand side of the above, but I cannot use the standard theorem for differentiation under the integral sign to establish that $$\int_1^\infty \frac{\partial}{\partial t}u(t,x)\ \mathrm{d}x=\frac{dK}{dt}(t),$$ since $$\frac{\partial}{\partial t}u(t,x)=\frac{-\sin{tx}}{x}$$ is not bounded above by a Lebesgue integral function. How do I therefore show that the equality still works?","['derivatives', 'integration', 'lebesgue-integral']"
1831988,How to prove that $A$ is positive semi-definite if all principal minors are non-negative?,"Let $A\in\mathbb C^{n\times n}$ be a Hermitian matrix such that all its principal minors are non-negative (i.e. for $B=\left(a_{l_il_j}\right)_{1≤i,j≤k}$ with $1≤l_1<...<l_k≤n$ we have $\det(B)≥0$). Then how to show that $A$ is positive semi-definite? I thought maybe we could use induction since the condition is also satisfied for every submatrix, but I couldn't find an easy way. Can prove it elegantly?","['matrices', 'positive-semidefinite', 'linear-algebra']"
1832060,Diophantine relations using an equation with polynomials of degree at most 4,"I'm completely stuck at exercise 5.8.5 of Mathematical Logic , Chiswell & Hodges: Here are the mentioned definition and theorem: I'm stuck because I failed to use the hint given in the exercise. I can't figure out how to use such a property of functions on a relation (a function is a relation but the opposite isn't true).  Also, I couldn't even figure out how this can be true for the following diophantine relation: ""$x_1+x_2$ is a power of $5$"".  The equation $\phi(x_1,x_2,y)$ for such a relation is $x_1+x_2=y^5$. Could you please help me?","['diophantine-equations', 'logic', 'elementary-set-theory']"
1832077,Finding integers $x$ and $y$ such that $633x + 255y = 6$,"The first bit of the question asks to find the gcd of $633$ and $255$ which I did and found that it's $3$. However, the next bit asks this: Find integers $x$ and $y$ such that $633x + 255y = 6$, or explain why none exist. At first I thought that the integers do exist because $3$ divides $6$ but I'm not sure if this is the right approach to this question. Would be great if anyone could clear this up for me, thanks.","['euclidean-algorithm', 'discrete-mathematics']"
1832106,Sectional curvature of 2-manifold,"This is problem7, chapter 5 of  Do Carmo's Riemannian geometry. Let $M$ be a Riemannian two manifold, $p\in M$ , $exp_p$ is a diffeomorphism on a neighbourhood of origin $V\in T_pM$. Let $S_r(0)\subset V$ be a circle of radius $r$ centered at the origin, and let $L_r$ be the length of the curve $exp_p(S_r)$ in $M$. Prove that the sectional curvature at $p\in M$ is $$K(p)=\lim_{r\to 0}\frac{3}{\pi}\frac {2\pi r-L_r}{r^3}$$ from a previous exercise we already have $$\lim_{r\to 0}\frac{\sqrt{g_{22}}_{rr}}{\sqrt{g_{22}}}=-K(p)$$ where $g_{22}=\big|{\frac{\partial f}{\partial \theta}}\big|^2,  f(r,\theta)=exp_p rv(\theta), v $  the unit circle. I try to use $\frac{\partial f}{\partial \theta}=(dexp_p)_{rv}rv'(\theta)$ , but this is not the case where Gauss lemma is applicable. Also, I cannot figure out where $L_r$ come up. Any suggetion will be apprecaited .","['riemannian-geometry', 'differential-geometry', 'curvature']"
1832109,Exact same solutions implies same row-reduced echelon form?,"In Hoffman and Kunze they have two exercises where they ask to show that if two homogeneous linear systems have the exact same solutions then they have the same row-reduced echelon form. They first ask to prove it in the case of $2\times 2$ (Exercise 1.2.6) and then they ask to prove it in the case $2\times 3$ ( Exercise 1.4.10 ).  I am able to prove it in both of these special cases, but as far as I can tell Hoffman and Kunze never tell us whether or not this is true in general. So that's my question, is this true in general?  And if not, can anybody provide a counter-example?  Thank you!","['matrices', 'linear-algebra', 'linear-transformations']"
1832110,Area of a circle on sphere,"On a (flat) Euclidean plane, the area of a circle with a radius $r$ can be described by the function $A(r) = \pi r^2.$ But how can one describe the area of the same circle on a spherical manifold? Assuming that the radius of the sphere is an Euclidean distance of $d,$ how would $A(x)$ look? I'm assuming this can be found using calculus and/or trigonometric functions, but I'm not exactly sure how to do it.","['circles', 'spheres', 'spherical-geometry', 'geometry']"
1832169,"A binary operation, closed over the reals, that is associative, but not commutative","I am aware that matrix multiplication as well as function composition is associative, but not commutative, but are there any other binary operations, specifically that are closed over the reals, that holds this property? And can you give a specific example?","['examples-counterexamples', 'abstract-algebra', 'functions', 'group-theory', 'associativity']"
1832171,"If a finite group has only 1D irreducible representations, is it abelian? [duplicate]","This question already has an answer here : If every irreducible representation of a finite group has dimension $1$, why must the group be abelian? (1 answer) Closed 8 years ago . I know abelian groups have only 1D representations. Is the converse proposition true? i.e. If a finite group has only 1D irreducible representations, is it abelian?","['representation-theory', 'group-theory']"
1832177,Sigmoid function with fixed bounds and variable steepness [partially solved],"(see edits below with attempts made in the meanwhile after posting the question) Problem I need to modify a sigmoid function for an AI application, but cannot figure out the correct math. Given a variable $x \in [0,1]$ , a function $f(x)$ should satisfy the following requirements (pardon the math-noobiness of my expression): a) the values of $f(x)$ should be costrained to $[0,1]$ b) when $x=0$ then $f(x)=0$ , and when $x=1$ then $f(x)=1$ c) $f(x)$ should follow a sigmoid or ""S-curve"" shape within these bounds, with some variable changing the ""steepness"" of the curve. I used a different function earlier, corresponding to (0), illustrated below on the left: (0) $f(x) = x^{(z+0.5)^{-b}}$ , where $b=2$ with $z \in [0,1]$ controlling the curve What is a function that would satisfy these requirements, i.e. do the same thing as equation (0) but with an S-curve $?_{(I\hspace{1mm} hope\hspace{1mm} this\hspace{1mm} makes\hspace{1mm} at\hspace{1mm} least\hspace{1mm} some \hspace{1mm}mathematical\hspace{1mm} sense...)}$ Attempt 1 I tried to accomplish something similar with a logistic function (by varying the $x_0$ value; cf. equation (1) and the right side plot above) (1) $f(x) = \dfrac{1}{1 + e^{-b(x-(1-x_0))}}$ , where $b=10$ , $x_0 \in [0,1]$ ...so that $x_0 = 0.5$ yields some central or average curve (like the linear growth line on the leftmost plot), and values around it rise or lower the steepness. Shortcoming: the ""ends"" of the curve where $x=\{0,1\}$ won't reach the required values of 0 and 1 respectively. I don't want to force it arbitrarily with an if-else , it should come naturally from the properties of an equation (and as such form nice curves). Attempt 2 This sort of does the trick, now the ends smootly reach 0 and 1 for all values of $x_0$ : (2) $f(x) = \Bigg(\bigg( \dfrac{1}{1 + e^{-b(x-(1-x_0))}}\bigg)x\Bigg)^{1-x} $ Only problem, the effect is not ""symmetrical"", when comparing high and low values. Observe the values for $f(x)$ with $x_0 = [0,1]$ ; $b=10$ (left side plot below). The curve steepness varies more among lower $x_0$ values (yellow,red) than amoing higher values (pink); also, changing $x_0$ also has noticably more effect in lower values of $x$ than its higher values. Attempt 3 Ok maybe if-elsing the hell out of those extreme values is not such a bad idea. (3) $f(x) = \Bigg(\bigg( \dfrac{1}{1 + e^{-b(x-(1-x_0))}}\bigg)g(x)\Bigg)^{1-h(x)} $ where $g(x) = \left\{\begin{array}{ll}1 & x>0\\0 & otherwise\end{array}\right.$ and $h(x) = \left\{\begin{array}{ll}1 & x==0\\0 & otherwise\end{array}\right.$ The right side plot above illustrates the result: the ends are still nicely 0 and 1, and now the curves above and below $x_0=0.5$ are symmetrical, but there are noticable ""jumps"" on $x=0.1$ and $x=0.9$ if $x_0$ is in its either extremes. Still not good. So far all my attempts are all so-so, each lacking in some respect. A better solution would thus still be very welcome.","['curves', 'calculus', 'functions']"
1832257,"For an orthogonal matrix $Q$, why does $QQ^T = I$? [duplicate]","This question already has answers here : Why is inverse of orthogonal matrix is its transpose? (5 answers) Why, if a matrix $Q$ is orthogonal, then $Q^T Q = I$? [duplicate] (6 answers) Closed 2 years ago . In my linear algebra text (Strang), an orthogonal matrix is defined to be a square matrix whose columns are orthonormal. In other words, an orthogonal matrix is a matrix $Q = [q_1 \cdots q_n]$ where each $q_i$ is a unit column vector of length $n$ with
$$q_i^Tq_j = \begin{cases} 0 & \text{ when }i \neq j \\ 1 & \text{ when } i = j \end{cases}.$$ My book says that an orthogonal matrix $Q$ has the properties $Q^TQ = I$ and $QQ^T = I$, from which it follows that $Q^T = Q^{-1}$. I can see how (1) follows from orthonormal columns, but I don't see why (2) is necessarily true. Can anyone provide some insight?","['orthonormal', 'matrices', 'orthogonality', 'orthogonal-matrices', 'linear-algebra']"
1832276,Example 4.5-3 in Kryeszig's Functional Analysis: What is the relation between the matrix of a linear operator and that of its adjoint?,"Let $X$ and $Y$ be finite-dimensional normed spaces, either both real or both complex, and let $T \colon X \longrightarrow Y$ be a linear operator. (Then by Theorem 2.7-8 in Kreyszig $T$ is bounded since its domain is finite-dimensional). Let $X^\prime$ denote the dual space of $X$ (i.e. the normed space of all the bounded linear functionals with domain $X$ ); since $X$ is finite-dimensional, $X^\prime$ consists of all the linear functionals with domain $X$ , again by Theorem 2.7-8 in Kreyszig. And, the same applies to $Y^\prime$ . Then the adjoint operator $T^\times \colon Y^\prime \longrightarrow X^\prime$ of $T$ is also a bounded linear operator that is defined as follows: Let $g \in Y^\prime$ . Then $T^\times (g) = f \in X^\prime$ , where $f$ is defined by $$f(x) = g\big( T(x) \big) \mbox{ for all } x \in X.$$ This operator $T^\times$ is linear and bounded with $$ \left\lVert T^\times \right\rVert = \lVert T \rVert.$$ Now let $E = \left( e_1, \ldots, e_n \right)$ be an ordered basis for $X$ , and let $B = \left( b_1, \ldots, b_m \right)$ be an ordered basis for $Y$ . Let $A = \left[ \alpha_{ij} \right]_{m \times n}$ be the matrix of $T$ with respect to the ordered bases $E$ and $B$ . Let $E^\prime$ and $B^\prime$ denote the dual ordered bases of $E$ and $B$ , respectively. Let $A^\times$ be the matrix of $T^\times$ with respect to the dual bases $B^\prime$ and $E^\prime$ . What is the relation between the matrices $A$ and $A^\times$ ? By definition, the dual basis $E^\prime$ of $X^\prime$ corresponding to the ordered basis $E$ for $X$ is the ordered $n$ -tuple $\left( f_1, \ldots, f_n \right)$ of linear functionals  with domain $X$ such that, for each $j = 1, \ldots, n$ and for each $k = 1, \ldots, n$ ,  we have $$ 
f_j \left( e_k \right) = \begin{cases} 1 & \mbox{ if }  j = k; \\ 0 & \mbox{ if }  j \neq k.\end{cases} 
$$ And, similarly the dual basis $B^\prime$ of $B$ is the ordered $m$ -tuple $\left( g_1, \ldots, g_m \right)$ of linear functionals  with domain $Y$ such that, for each $r = 1, \ldots, m$ and for each $s = 1, \ldots, n$ ,  we have $$f_r \left( e_s \right) = \begin{cases} 1  & \mbox{ if }  r = s; \\ 0 & \mbox{ if }  r \neq s.\end{cases} $$ Here is a Math Stack Exchange of mine which contains the relevant terminology and notation.","['real-analysis', 'operator-theory', 'adjoint-operators', 'functional-analysis', 'analysis']"
1832284,Picking pairs of socks from a drawer.,"There are $n$ socks in a drawer, of $m$ different colours. Initially, the probability of picking a sock of colour $c_i$ at random is $\mathbb{P}(c_i) \cdot 2r$ socks are picked at random, without replacement. What is the probability, $\mathbb{P}(pairs)$, that $r$ pairs of socks are picked? (i.e. all socks are paired) If $r = 1$ (2 socks are chosen): $\mathbb{P}(pairs)$ = $\mathbb{P}$(2 are $c_1$ or 2 are $c_2$ or ... or 2 are $c_m$) ~ $\sum_{k}^{m} {\left[\mathbb{P}(c_k)\right]^2}$ How can this be generalized for r?","['combinatorics', 'probability']"
1832325,"Given $S \in B(Y^{*}, X^{*})$, does there exist $T\in B(X,Y)$ such that $S=T^{*}$?","Let $X, Y$ be Banach spaces, $S \in B(Y^{*}, X^{*})$. Does such operator $T \in B(X, Y)$ exist so that $T^{*}=S$? I suppose that the answer should be - no. Are there any hints that might help in constructing a counterexample? Any help would be much appreciated.","['functional-analysis', 'banach-spaces', 'operator-theory']"
1832332,How to determine the existence of all subsets of a set?,"Given The definition of subset ; The axiom of power set: for any set $S$, there exists a set $\wp$ such that $X \in \wp$ if and only if $X\subseteq S$ we know what a subset is and what a power set contains . In a simple case where a set $A$ is supposed to exist, with $A=\{a, b, c\}$, we know what is and what is not a subset of $A$: $\{a\}, \{b\}, \{c\}, \{a, b\}, \{a,c\}, \emptyset$ and $A$ are subsets of $A$ and anything different is not. $\wp(A)=\big\{\{a\}, \{b\}, \{c\}, \{a, b\}, \{b,c\}, \{a,c\}, \{a, b, c\}, \emptyset\big\}$. However the mere definition of something (and consequently it's recognition as such) does not guarantee its existence. $\emptyset$ and $A$ seem like the only subsets whose existence is immediate. In other words, I know what a power set contains, but how do I know that the things it contains exist in the first place? Because such a well-defined and existent set such as $\wp(A)$ should not contain nonexistent elements, to prove the existence of its elements is important. It seems that two alternatives arise: Being a member of $\wp(A)$ automatically makes this thing to exist; or There should be an alternative to prove the existence of all subsets of $A$ without the axiom of power set.",['elementary-set-theory']
1832338,"Find the almost sure limit of $X_n/n$, where each random variable $X_n$ has a Poisson distribution with parameter $n$",$X_{n}$ independent and $X_n \sim \mathcal{P}(n) $  meaning that $X_{n}$ has Poisson distributions with parameter $n$. What is the $\lim\limits_{n\to \infty} \frac{X_{n}}{n}$ almost surely ? I think we can write $X(n) \sim X(1)+X(1)+\cdots+X(1)$ where the sum is taken on independent identical distribution then use the law of large number. But I am not sure that is it correct or not. Can anyone give me some hints? Thank you in advance!,"['probability-theory', 'poisson-distribution', 'probability-distributions']"
1832344,What does it take for a smooth homeomorphism to be a diffeomorphism?,"I have an open subset $A$ of $\mathbb{R}^k$ and a subset $B$ of $\mathbb{R}^n$, $n>k$, that are homeomorphic and $f:A\longrightarrow B$ is a smooth homeomorphism between two sets. I'm wondering if you know any results as to what additional properties of $f$ (other than its inverse being smooth) would ensure that it is a diffeomorphism. Such result would be in the spirit of ""a continuous bijection is a homeomorphism if and only if it is open (closed)"" which lets one prove a function is a homeomorphism without directly proving that its inverse is continuous. My end goal is to prove that my concrete function $f$ has its Jacobi determinant positive everywhere on $A$ or at least that Jacobian is zero only at isolated points. So if you know any results that would let me reason about the set on which the Jacobian vanishes using the facts (smooth homeomorphism) that I stated, I would very much appreciate it.","['derivatives', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
1832370,Derivative of exponent,Looking to solve : $$ \frac{d}{dx}[2^{0.5x}]$$ The multiplication and X value in the exponent is confusing me. Help? Thanks!,"['derivatives', 'calculus', 'exponentiation']"
1832381,Prove that if $p$ is a prime number then $\binom{p-1}{k}\equiv (-1)^k\pmod{p}$,"Prove that if $p$ is a prime number then $\binom{p-1}{k}\equiv (-1)^k\pmod{p}$. What can be said about $\binom{p+1}{k} \pmod{p}$? I thought about expanding $\dbinom{p-1}{k} = \dfrac{(p-1)!}{k!(p-1-k)!}$, but I don't see how that helps. Is there an easier way?",['number-theory']
1832407,How many possible functions?,"Take $f:\{1,2,3,4,5,6,7\}$ to $\{0,1,2,3,4\}$ How many such functions satisfy the cardinality of the pre-image of the set $\{3\}$ is equal to $3$. I thought it would be $35$, i.e :$7\choose{3}$ however my book is getting $8960$, could someone explain where this extra factor of $256$ is coming from?","['combinatorics', 'functions', 'discrete-mathematics']"
1832409,logical equivalence statements in discrete math,"Construct another English form sentence, which is logically equivalent to that which was given. ""Susan goes to school or Susan does not talk on the phone or Susan does not go to school.""",['discrete-mathematics']
1832456,What exactly does a rotation preserve?,"I understand a rotation should preserve length and angle and hence the dot product. Since anything that preserves the dot product is a linear transformation, then a rotation can be represented by a matrix. Let's only consider real matrices . However, there is something else that a rotation preserves and I am here to ask what it is. A linear transformation that preserves length must be orthogonal, however, an orthogonal matrix is a rotation if its determinant is $1$. That means a rotation is a special case of orthogonal matrix. So what makes a rotation special from orthogonal matrices? What else does a rotation preserve in addition to length and angle ? Anyone can provide a prove that a matrix is a rotation iff it is an orthogonal matrix with determinant $1$? Thank you!","['matrices', 'orthogonal-matrices', 'linear-algebra']"
1832501,The divergent sum of alternating factorials,"So I came across this exposition of a paper by Euler 1 where Euler is trying to sum the divergent sum: $$s = 1 - 1 + 2! - 3! + 4! \dots = \sum_{k\geq 0}(-1)^k k!.$$ There are a couple of questions at the end. However, I would like to go through some exposition first: This sum is certainly divergent but this of course does not stop Euler. He goes through various manipulations and always ends up at the same value of $s \sim 0.5963$ . Briefly, the various methods are as follows: Let $s = \sum_{k\geq 1}(-1)^ka_k$ with $a_k > 0$ . He defines: $$b_l = \sum_{0\leq k\leq l}(-1)^{l-k}\binom{l}{k}a_{k+1}$$ and then shows that: $$s = \sum_{l\geq 1}\frac{b_l}{2^l}.$$ We can apply this to our $s$ repeatedly and find an approximate value. It is mentioned that he finds diverging series for $1/A$ and $\log A$ and using similar methods finds the same approximate value. He also manages to find continued fraction expansions for $A$ and $1/A$ and approximates them to the same value. Finally, the linked paper goes through the following fascination derivation. Define: $$s(x) = \sum_{k\geq 0}(-1)^kk!x^{k+1}.$$ Then: $$\frac{ds}{dx} = \frac{x-s}{x^2}$$ and Euler solves this differential equation to get the integral representation: $$s(x) = e^{1/x}\int_0^x\frac{e^{-1/t}}{t}dt$$ and evaluating at $x=1$ ends up with the same approximation. Questions: There are a few obvious questions here. There seems to be a strong internal consistency to this series. Why? Usually, I would suspect that there is some analytic continuation lurking in the background. Is this true? Second, what is the exact value that we are approximating? Third, is there any book/article with more on divergent series like these. This is all incredibly fascinating and I would love to learn more. The article references Hardy's ""Divergent Series"" 2 , is this still the best book to go to? 1 Sandifer, C. Edward , How Euler did it, The MAA Tercentenary Euler Celebration 3. Washington, DC: Mathematical Association of America (MAA) (ISBN 978-0-88385-563-8/hbk). xiv, 235 p. (2007). ZBL1141.01009 . Link on Euler Archive 2 Hardy, G. H. , Divergent series, Oxford: At the Clarendon Press (Geoffrey Cumberlege) XIV, 396 S. (1949). ZBL0032.05801 . Link on Internet Archive","['complex-analysis', 'factorial', 'divergent-series', 'sequences-and-series']"
1832565,minimum distance of a linear codes [duplicate],"This question already has answers here : Efficient computation of the minimum distance of a binary linear code (2 answers) Closed 1 year ago . My question is about computing the minimum distance (weight)  of a linear code. Assume that we have the generating matrix of the code. Then we can easily compute the weights of each row and of course the minimum weight among the set of all rows gives us an upper bound for the minimum weight. My question is, are there any techniques to improve this bound? Also is it possible to find a lower bound for that? Any references will be appreciated.","['combinations', 'coding-theory', 'reference-request', 'algorithms', 'discrete-mathematics']"
1832582,"Find the probability that a word with 15 letters (selected from P,T,I,N) does not contain TINT","If a word with 15 letters is formed at random using the letters P, T, I, N, find the probability that it does not contain the sequence TINT. (I just made up this problem.)","['inclusion-exclusion', 'combinatorics', 'probability', 'discrete-mathematics']"
1832605,Complement of a simply connected set is simply connected,"I saw the following surprising statement in Wikipedia : When $D\subseteq\Bbb C$ is a simply connected compact set, then its complement $E=D^c$ is a simply connected domain in the Riemann sphere that contains $\infty$, ... This property sounds like something specific to $S^2$. Is it true that the complement of a compact simply connected subset of $S^n$ is simply connected? Is this true if $D$ is not necessarily compact/closed? How do you prove this? A related question (which may need to be moved elsewhere): is there a subset $D\subseteq S^2$ such that there are no nontrivial paths in either $D$ or $D^c$?","['complex-analysis', 'general-topology', 'connectedness']"
1832611,Compute $\frac{d^ny}{dx^n}$ if $y = \frac{7}{1-x}$,"I am wondering what is $\frac{d^n}{dx^n}$ if $y = \frac{7}{1-x}$ Basically, I understand that this asks for a formula to calculate any derivative of f(x) (correct me if I'm wrong). Is that related to Talylor's theory? How do I end up with such a formula? Thanks!","['derivatives', 'taylor-expansion', 'calculus']"
1832614,Lindeberg CLT application,"Let $X_1,X_2,\dots$ be a sequence of independent Random Variables with
$$\mathbb{P}(X_k = -1) = \mathbb{P}(X_k = 1) = \frac{1 - 2^k}{2}$$
$$\mathbb{P}(X_k = 2^k) = \mathbb{P}(X_k = -2^k) = \frac{1}{2^{k+1}} $$ How can I show the CLT holds? Tried to verify Lindeberg's Condition without success.",['probability-theory']
1832624,How to derive through a convolution?,"Let $f(t) = \alpha e^{-\beta t}$, where $\alpha, \beta$ are constants Let $g(t) = y(t)$ Then the resulting convolution $f\ast g$ is: $$f \ast g = \int_0^t \alpha  e^{-\beta (t-\tau)} y(\tau) d\tau$$ Does anyone know how one would take the derivative of this
expression? In general, are there rules for taking derivative of $f \ast g$, for
some given $f,g$? Idea: using fundamental theorem of calculus, treat the integrand as a
  single function $h(t)$ $$\int_0^t \alpha  e^{-\beta (t-\tau)} y(\tau) d\tau = \int_0^t
 h(\tau) d\tau$$","['derivatives', 'laplace-transform', 'convolution', 'calculus', 'integration']"
1832659,How much area in a unit square is not covered by $k$ disjoint disks of maximal area centered at random points within the square?,"1 . Paint a $1\times 1$ square in blue. 2 . Take $k$ points randomly and uniformly from the square. 3 . Paint $k$ disks centered at each point in red. The radius of the disk centered at point $p$ is $d/2$ , where $d$ is the distance from $p$ to its closest point. What is the expected remaining blue area? Related question: How much area in a unit square is not covered by $k$ disks of area $1/k$ centered at random points within the square?","['expectation', 'probability']"
1832686,Probability: Are disjoint events independent? [duplicate],"This question already has answers here : Independence of disjoint events with strictly positive probability (2 answers) Closed 8 years ago . I just read that disjoint events, A, B, if, $\mathbb{P}(AB) = 0$ are independent. This really frustrates me. My teacher stated otherwise - $\mathbb{P}(AB) = 0 \iff A \cap B = \emptyset \implies \mathbb{P}(AB) = 0 \ne \mathbb{P}(A)\mathbb{P}(B)$ because $\mathbb{P}(A)$ and $\mathbb{P}(B)$ are not empty (does the latter come from the definition of independent events?). Could somebody clear this for me?",['probability']
1832691,How to define $f(0)$ when $f$ is a function in $L^2$?,"Any function $f$ in $L^2$ is a actually an equivalence class and has properties that only hold ""almost everywhere."" But it would be convenient to speak of the value of $f$ at certain points like $f(0)$. Is there a meaningful way of defining this?",['functional-analysis']
1832712,Understanding the flat (uniform) Dirichlet distribution density over a simplex,"This should be really straightforward from the formula, but somehow I'm having trouble understanding the density of a Dirichlet distribution with $\alpha = [1, 1, ... 1] \in R^k$, which is a uniform distribution over the $k-1$ dimensional simplex. For example, $Dir(x;[1,1,1])$ is the same as a uniform distribution over the triangle with vertices $[0,0,1], [0,1,0]$, and $[0,0,1]$ (see pic below). Since there's 1 unit of probability mass uniformly spread over the triangle, I thought the density should simply be $1/Area(triangle)=2/\sqrt(3)$; but the formula is giving me $Dir(x;[1,1,1])=2$. How come?","['probability', 'calculus', 'probability-distributions']"
1832751,Radon Nikodym Thm: extending to $\sigma$-finite case,"I am reading Bartle's ""Elements of Integration"". Radon-Nikodym Thm : Let $\lambda,\mu$ be $\sigma$-finite measures on a measurable space $(X,\textbf{X})$ and say $\lambda \ll \mu$.  Then $\exists$ unique $\mu$-a.e. measurable $f:X \to \bar{\mathbb{R}}_{\geq 0}$ (that's my notation for the nonnegative extended reals) s.t. $\lambda(E)= \int_E f \, d \mu$, $\forall E \in \textbf{X}$. From his pf, I'm comfortable with the case where $\lambda,\mu$ are finite (both existence and uniqueness). Here is how Bartle generalizes to the $\sigma$-finite case. Let $X_1 \subseteq X_2 \subseteq\cdots$ be s.t. $X= \bigcup_{n=1}^\infty X_n$, each $\lambda(X_n),\mu(X_n)< \infty$. $\exists$ fns $h_n: X \to \bar{\mathbb{R}}_{\geq 0}$ s.t. $h_n(x)=0$ for $x \notin X_n$ and $$\lambda(E)= \int_E h_n d \mu, \forall E \subseteq X_n \text{ measurable} \tag1$$ If $n \leq m$, then $X_n \subseteq X_m$ and $\int_E h_n d \mu = \int_E h_m d \mu$, $\forall E \in \textbf{X}$.  So $h_n 1_{X_n}= h_m 1_{X_n}$ $\mu$-a.e. Put $f_n:=\sup \{ h_1,\ldots,h_n\}$, so $(f_n)$ is a monotone seq.  Put $f:= \lim_{n \to \infty} f_n$.  Then $\lambda(E \cap X_n)= \int_E f_n \, d \mu$, so $\lambda(E)= \int_E f \, d \mu$, $\forall E \in \textbf{X}$, by the Monotone Conv Thm. Here are my questions regarding the proof: a) (2nd bullet point) I can see $\lambda_n (E):= \lambda(E \cap X_n)$ and $\mu_n (E):= \mu(E \cap X_n)$ are finite measures s.t. $\lambda_n \ll \mu_n$.  Thus, $\exists$ fns $h_n$ s.t. $\lambda(E)= \int_E h_n d \mu_n$, $\forall E \subseteq X_n$ measurable.  But why can we replace $\mu_n$ with $\mu$ to get (1)?  This seems intuitive but how do I make a rigorous argument?  Perhaps my attempt to define $\lambda_n, \mu_n$ was not helpful but it was the only way I could think of to use the result for finite measures. b) (4th bullet pt) Why does he define $f_n$ at all?  Why not just use $h_n$ in place of $f_n$?  It seems the $(h_n)$ are already an incr seq: for instance, $h_1=h_2$ $\mu$-a.e. on $X_1$ but $h_1=0$ on $X_1^c$ (while we know $h_2 \geq$0) so $h_1 \leq h_2$ $\mu$-a.e. I appreciate any help as I am new to measure theory and trying to understand how arguments are made.","['real-analysis', 'measure-theory']"
1832793,When is $\sum_{i=1}^n a_i^{-2}=1$?,For which natural numbers $n$ do there exist $n$ natural numbers $a_i\ (1\le i\le n)$ such that $\displaystyle\sum_{i=1}^n a_i^{-2}=1$? I didn't see an easy way of solving this. There is a solution for $n=1$ since we just take $a_i = 1$ and a solution for $n=4$ if we take $a_i = 2$. How do we find all possible values of $n$?,['number-theory']
1832812,Prove that $M = \mathbb Z^+$,"Let $M$ be a nonempty subset of $\mathbb Z^+$ such that for every element $x$ in $M,$ the numbers $4x$ and $\lfloor \sqrt x \rfloor$ also belong to $M.$ Prove that $M = \mathbb Z^+$. Suppose $a \in M$. Then so are $4ak$ and $\lfloor \sqrt{4ak} \rfloor$ for every positive integer multiple of $k$. Also we could take a multiple of $4$, then do the square root and floor it etc. in many different combinations. How do we prove that $M$ is all of $\mathbb{Z}^+$?","['number-theory', 'elementary-number-theory']"
1832836,"A linear map $S:Y^*\to X^*$ is weak$^*$ continuous if and only if $S=T^*$ for some $T\in B(X,Y)$","As the title says, the question is how to prove Let $X,Y$ be normed spaces. A linear map $S:Y^*\to X^*$ is weak $^*$ continuous if and only if $S=T^*$ for some $T\in B(X,Y)$","['functional-analysis', 'normed-spaces', 'operator-theory']"
1832867,"How to represent ""not an empty set""?","I'm writing a academic paper and need to represent ""A is not the empty set"". What is usual way for professional mathematicians? My idea is: $|A| > 0$ However, using the emptyset $\emptyset$ might be more intuitive: $A\ != \emptyset$ But, I know ""!="" is not permissible in math community (only in programmers). Update Sorry, I fixed the second equation:
$|A|\ != \emptyset \rightarrow A\ != \emptyset$","['article-writing', 'notation', 'elementary-set-theory']"
1832937,"How can I calculate $ \lim_{h\to 0} \frac{1}{h}\int_{2}^{2+h} F(x)\,dx$?","Let, say, $F(x) = \sin(x^2)$ which is continuous, therefore there exists a
 $c \in [2,2+h]$ such that $$ F(c) = \frac{1}{h}\int_{2}^{2+h} F(x)\,dx.$$ I'm trying to calculate the limit when $h$ goes to zero, which is supposed to be $\sin(2)$ but I don't see it. Could you  explain how to calculate the limit?","['integration', 'definite-integrals', 'calculus']"
1832941,Properties of the power set of $A$,"Let $A$ be any set . Let $\wp(A)$ be the power set of $A$. Then which of the following are true 1) $\wp(A) = \emptyset$ for some $A$ 2) $\wp(A) $ is a finite set for  some $A$ 3) $\wp(A)$ is a countable set for some $A$. 4) $\wp(A)$ is uncountable for some set $A$ for 1) take $A= \emptyset$, then $\wp(A) = \emptyset$. for 2) take $A$ is a finite set, then $\wp(A)$ is a finite set. for 3) If $A$ is finite then  $\wp(A)$ is a finite set, if $A$ is infinite , then $\wp(A)$ is uncountable set. I think this is false. for 4) Take $A = \mathbb N$, then $\wp(A)$ is uncountable. This is an exam problem . I would be thankful if someone check my problem, if feel any error then correct.","['cardinals', 'elementary-set-theory', 'proof-verification']"
1832973,How to find range of $\frac{\sqrt{1+2x^2}}{1+x^2}$?,How to find range of $$\frac{\sqrt{1+2x^2}}{1+x^2}$$ ? I tried put it equal to $y$ and squaring but I'm getting $4$th degree equation.,"['algebra-precalculus', 'functions']"
1832991,"Given sets A and B such that A ⊆ B, write down A ∪ B in a simplified form.","Here's how I did it: Let A = {1,2,3}
Let B = {1,2,3,4,5} Since A ∪ B, everything in A would also be in B thus the simplified form would be B? If it's wrong, please let me know how to go about this, thanks.",['discrete-mathematics']
1833028,"If $g$ is Riemann-integrable in a closed interval and $f$ is a increasing function in a closed interval, is $g\circ f$ Riemann-integrable?","If $g$ is Riemann-integrable in a closed interval and $f$ is a increasing function in a closed interval, is $g\circ f$ Riemann-integrable? To clarify: the problem stated that the composition is well defined. I think that the statement of the question is true but Im having trouble to write/concrete a proof. I know that a monotone function defined in a closed interval is Riemann-integrable by a previous result. And I know that the reverse statement ($g$ being monotone and $f$ integrable) is not true in general. After thinking some moment my idea for the proof is to show that $g\circ f$ have, at most, countable discontinuities. To do this I was thinking how to show some kind of order-correspondence between the points of the domain of a monotone function and it image. Can you help me? I get stuck and it is very possible that Im wrong in my assumption about that the statement is true. Some hint will be appreciated. EDIT: I get a new idea, design a partition of $f$ that take any possible discontinuity into a closed interval of known length, and after see what happen in the composition with this closed intervals with discontinuities, and by the other hand see what happen with the parts of continuous mapping. After reading this answer I get the idea to provide a proof for the validity of the statement. First I will characterize the different kind of images of closed intervals that a monotonic function can create. For an increasing function we have that $x<y$ implies that $f(x)\le f(y)$, and that at most a monotone function can have a countable number of discontinuities in any closed interval. No discontinuities on the image: if the image of $f([x_1,x_2])$ is continuous then it can be at most of three types: A constant function $f([x_1,x_2])=\{a\}$. Then $(g\circ f)([x_1,x_2])=g(\{a\})=\{c\}$, then the function $(g\circ f)$ is constant in $[x_1,x_2]$ so is Riemann-integrable A strictly increasing function i.e. $f([x_1,x_2])=[a,b]$. Then $(g\circ f)([x_1,x_2])=g([a,b])=[c,d]$. If $g$ is Riemann integrable in $[a,b]$ then exists a sequence of partitions $(P_n)$ such that $$\lim_{n\to\infty}U(g,P_n)-L(g,P_n)=0$$ Then because $f$ is bijective in $[a,b]$ then for every $P_n$ exists a partition $P'_n$ in $[x_1,x_2]$ such that $$\lim_{n\to\infty}U(g\circ f,P'_n)-L(g\circ f,P'_n)=0$$ so $g\circ f$ is Riemann-integrable in $[x_1,x_2]$ A mix of both previous cases. Then the interval $[x_1,x_2]$ can be partitioned on types of subintervals discussed previously (constant and strictly monotonic images), so $g\circ f$ is Riemann-integrable here too. Discontinuity in the image : a jump discontinuity in $[x_1,x_2]$ is mapped into two types of the previously discussed intervals with the difference that can be the case that in the image exists an interval with an open boundary of the kind $[a,b)$ or $(a,b]$. But cause $f$ and $g$ are Riemann integrable in closed intervals this mean that they are bounded, and if $g$ is integrable in any subinterval $[a-\varepsilon,b]$ then is integrable in $(a,b]$ (this is known by a previous proof). My question: it is this proof correct? It lacks something essential? Can you help me to write it better? Thank you in advance. EDIT 2: as the user @ParamanandSingh pointed in the comments it is possible that the discontinuities cannot be isolated, one by one, inside some interval. So I will search further for a correct proof of the statement.","['real-analysis', 'integration', 'proof-writing', 'proof-verification']"
1833056,Solution to the differential equation $xy''+y'+xy=0$,"Show that the differential equation
  $$xy''+y'+xy=0$$
  admits a solution of the form 
  $$\varphi(x)=\int_0^1f(t)\cos(xt)dt$$
  for some function $f(t)$. Since
$$\varphi'(x)=\frac{d}{dx}\int_0^1f(t)\cos(xt)dt
=\int_0^1\frac{\partial}{\partial x}f(t)\cos(xt)dt
=-\int_0^1t f(t)\sin(xt)dt$$
and 
$$\varphi''(x)=-\frac{d}{dx}\int_0^1t f(t)\sin(xt)dt
=-\int_0^1\frac{\partial}{\partial x}t f(t)\sin(xt)dt
=-\int_0^1t^2 f(t)\cos(xt)dt$$
it must be satisfied 
$$\int_0^1f(t)\left[-xt^2\cos(xt)-t\sin(xt)+x\cos(xt)\right]dt=0.$$
I don't know how to proceed from this point. I've tried to use integration by parts to simplify the expressions for $\varphi'$ and $\varphi''$ but became even worse.",['ordinary-differential-equations']
1833068,"What does the word ""norm"" stands for in linear algebra?","I know that ""norm"" is the formal name for length, but where did this name came from? or from what language is came from? Thank you in advance.","['terminology', 'linear-algebra']"
1833102,Expected Number of flips for alternating Heads/Tails 10 times,"What is the expected number of flips needed to flip a coin 10 times and have the outcome be alternating heads/tails (starting with heads, then tails, then heads etc...). I wrote a c++ program and it gives me 2,730. Is this correct and how would you do this mathematically?",['statistics']
1833130,Are there more types of critical points beyond maxima/minima/saddle points for higher dimensions?,"I had a course on single variable calculus and at that point, we had minima and maxima. Now on several variables calculus, there is maxima, minima and saddle points. Certain books of several variables calculus  point only those three types of critical points but there is actually no guarantee that these are the only ones - other types could be more advanced and/or irrelevant for the study of calculus, perhaps? So are there more kinds of critical points for higher dimensional calculus? Supposing there are only these three, how can I know for sure that there are only these three? Supposing that there are more than three, how can I know that there are more than three?","['multivariable-calculus', 'analysis']"
1833134,"Which number is greater, $11^{11}$ or $9^{12}$?",Which number is greater than $11^{11}$ or $9^{12}$ ? My work so far: $11^{11}=285311670611>9^{12}=282429536481$ . But to verify the validity of equality should be in the range of easily verifiable calculations.,"['inequality', 'number-comparison', 'algebra-precalculus', 'arithmetic', 'exponentiation']"
1833147,Is $\lim\limits_{x\to x_0}f'(x)=f'(x_0)$?,"Let $f$ be a function defined in the open interval $(a,b)$ and let $x_0\in(a,b)$. Suppose in addition that $f'(x)$ exists for all $x_0\neq x\in(a,b)$. Is the following statement true: If $\lim\limits_{x\to x_0}f'(x)$ exists, then $f'(x_0)$ exists and $\lim\limits_{x\to x_0}f'(x)=f'(x_0)$. Thanks!",['calculus']
1833168,Statements about derivatives and integrals [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question My professor gave me one example. It's given one intervall  $I=\left [ a,b \right ]\subset \mathbb{R}$ and one function $f:I\mapsto \mathbb{R}$. There is also given 8 statements about derivatives and integrals, so here we go: A: f is Riemann integrable. B: For all $c\in I$ applies that $\lim_{x\mapsto c}f(x)=f(c)$. C: For all $c\in I$ applies that $f(x)= \sum_{k=0}^{\infty}a_kx^k$. D: $f$ is for I five times continuously differentiable. E: $f$ is continues for I. F: $f(x)=\int_{a}^{x}g(s)ds$ with one continuous function $g:\left [ a,b \right ] \mapsto \mathbb{R}$. G: $f$ is bounded. H: $f$ is for $I$ continuously differentiable. I had to sort by strength. Answer is: $C \implies D  \implies H \Leftrightarrow F\implies E \Leftrightarrow B \implies A\implies G$ Can somone explain my why is like this? I understand why everystatment is true, but I don't understand how to sort them by strength. I only understand why $ D  \implies H$ and that's it. Can someone explain me this?","['derivatives', 'integration']"
1833176,Why can't a set of four vectors in $\mathbb{R}^3$ be linearly independent?,"Why can't a set of four vectors in $\mathbb{R}^3$  be linearly independent? I know that if the determinant of the vectors together is not $0$ then the vectors are linearly independent. But this is not relevant to this case of a non square matrix. Is the answer ""because there can only ever be 3 pivots when reduced"" a good answer?","['linear-algebra', 'vector-spaces']"
1833212,Counter-clockwise angle between edges,"I have a couple of connected lines (or rather edges) in the form of coordinates, that is for each edge a starting point $(x_s,y_s)$ and end point $(x_e,y_e)$. and I want to know a specific angle between them. Here is a drawing to illustrate which angles I want: The blue arrows are (in this case 4) edges. The orange-like pieces of a circle are supposed to show the desired angles. That is, I want the counter-clockwise angle of the respective second edge to the respective first edge. How do I do that?","['angle', 'geometry']"
1833223,What's the equation for a line segment?,"I already know that the standard equation for a line is $y=mx+b$, but what if I want the line to have specific endpoints and not go on forever? For example, the equation for a line beginning at $(3, 1)$ and ending at $(7, 2)$. Can you help me? What's the standard equation for this?","['linear-algebra', 'geometry']"
1833322,A well-order on a uncountable set,"I can't find an example of a well-order on an uncountable set. Is possible to prove that exists with the Axiom of Choice? How can I give a pratical construction? I try to define a well-order on Cantor Set, but I'm not able to do.","['order-theory', 'elementary-set-theory']"
1833351,Minimum number of steps to reduce a number to zero.,"I am trying to solve a problem which is described below: Given a number $n$ , reduce it to $0$ in a minimum number of steps using the $2$ operations below: $n$ can be changed to $\max (a,b)$ , where $n=a\cdot b$ ( $a$ and $b$ can't be $1$ or $n$ and they have not specified anything about the factors). $n$ can be decremented by $1$ .
The minimum number of steps has to be reported. My strategy to solve this is as follows: Continue till $n$ is reduced to $0$ : If $n$ is not a prime number then find a factor of $n$ starting from $\sqrt{n}$ to $0$ . Divide $n$ with this factor, this new value is the reduced $n$ . If $n$ is a prime number then decrement it by $1$ . But this strategy fails for many inputs like $214567$ . Where am I going wrong? Any help is appreciated.",['number-theory']
1833369,Determine matrix of linear map,Linear map is given through: $\phi\begin{pmatrix} 3 \\ -2 \end{pmatrix} =\begin{pmatrix} -3 \\ -14 \end{pmatrix} $ $\phi\begin{pmatrix} 3 \\ 0 \end{pmatrix} =\begin{pmatrix} -9 \\ -6 \end{pmatrix}$ Determine matrix $A$ linear map. Here I have solution but I dont understand how to get it. $A=\begin{pmatrix} -3 & -3 \\ -2 & 4 \end{pmatrix}  $,"['matrices', 'linear-algebra', 'calculus']"
1833376,Is there a nonabelian topological group operation on the reals?,"Inspired by A binary operation, closed over the reals, that is associative, but not commutative . That question asks for a noncommutative semigroup operation on $\Bbb R$, for which right projection is a continuous solution. If you ask for inverses as well, that is, a nonabelian group operation, then you can use bijection tricks from any other nonabelian group of cardinality $\frak c$, for example the group $M_2(\Bbb R)$ of $2\times 2$ real matrices. But this will not usually give a continuous group operation on $\Bbb R$ because the bijection is usually exotic. To ""upper bound"" the properties needed, according to @PseudoNeo , if we require that the group operation be not just continuous but $C_1$, then it is necessarily of the form $x\ast y=\phi^{−1}(\phi(x)+\phi(y))$ for some $C_1$ diffeomorphism $\phi$, which is manifestly abelian. (Anyone have a reference for this result?) My question lies between these extremes: Is there a nonabelian topological group operation on the reals? That is, a group operation $\ast$ such that $\ast:\Bbb R\times\Bbb R\to\Bbb R$ is continuous and so is ${}^{-1}:\Bbb R\to\Bbb R$.","['general-topology', 'real-analysis', 'group-theory']"
1833380,Find the highest power of $4$ in $82! + 83!$,"I'am only getting $4^{13}$ as answer, but the correct answer is $40$.
What am I missing?","['number-theory', 'elementary-number-theory']"
1833407,Does $\int_0^2\frac{1}{\ln(x)}dx$ converge?,"Given the following integral: $$ \int_0^2 \frac{1}{\ln(x)} dx $$ Does it converge? Iv'e gone this far:
$$ \int_0^2 \frac{1}{\ln(x)} dx = \int_0^1 \frac{1}{\ln(x)} dx + \int_1^2 \frac{1}{\ln(x)} dx $$ Now I'm having trouble calculating each. I can only tell that: $ \int \frac{1}{\ln(x)} dx \gt \int\frac1x dx $","['integration', 'convergence-divergence', 'calculus']"
1833434,Constructing an $L^2$ space on the unit ring $\mathcal{S^1}$,"Revised Question: Starting with $L^2[0,2\pi]$, does the canonical map $$[0,2\pi)\ni\theta\mapsto e^{i\theta}\in\mathcal{S^1}$$(with functions going across in the obvious way) turn $L^2[\mathcal{S^1}]$ into a bona fide Hilbert space? In particular, does the difference in topology between $[0,2\pi]$ and ${S^1}$ have any nasty implications? Original Question: Is the Hilbert Space of $L^2$ functions on $[0,2\pi]$ with $f(0)=f(2\pi)$ equivalent to a Hilbert Space of $L^2$ functions defined on the unit ring $\mathcal{S^1}$? Can I even construct the latter? The reason I ask is that I'm uncertain whether the difference in the measure and topologies between $[0,2\pi]$ and $\mathcal{S^1}$ 'bubbles' its way up into functional analytic results. Note : The boundary condition given is shorthand for: ""The set of equivalence classes of Lebesgue square measurable functions (modulo sets of measure zero) containing a continuous member satisfying the given boundary condition"".","['functional-analysis', 'general-topology', 'lp-spaces', 'hilbert-spaces']"
1833453,"Does there exist a surjective function from $(0,1)$ to $[0,1]$?","Can I say that cardinality of $(0,1)$ is less than the cardinality $[0,1]$ ?","['real-analysis', 'elementary-set-theory']"
1833491,Find number of integral solutions of a*b*c*d = 600,The number of ordered solutions comes out to be 800. I need to find the number of distinct solutions but I'm stuck at calculating the possible combinations. Any ideas on how to proceed further?,"['number-theory', 'combinatorics', 'elementary-number-theory']"
1833506,The group $\mathrm{Diff}(F)$ and transition functions of a fibre bundle.,"Let $M$ and $F$ be differentiable manifolds, and let $F\to E\to M$ be a differentiable fibre bundle over $M$. A trivialising cover $\{(U_i,\phi_i)\,|\,i\in I\}$ of $M$ determines a set $\{t_{ij}:U_{ij}\to\mathrm{Diff}(F)\,|\,i,h\in I\}$ of transition functions satisfying the Čech cocycle conditions. In [Nakahra, Geometry, Topology and Physics, 2003], it is assumed that these transition functions actually take values in some Lie group $G$, and it is simply mentioned that the transition functions are smooth maps. I was pondering: Why are they actually smooth? If one considers the general case that the transition functions take values in $\mathrm{Diff}(F)$, are these functions still smooth? Is this even well-defined, i.e. is $\mathrm{Diff}(F)$ always a manifold? Any help is much appreciated.","['smooth-manifolds', 'differential-geometry', 'differential-topology', 'lie-groups']"
1833508,Intersection of infinite sets is infinite?,"I know that if $C \subseteq [0,1]$ is uncountable, then there exists $a \in (0,1)$ such that $C \cap [a,1]$ is uncountable. Is it still true for any infinite sets? That is, if $C \subseteq [0,1]$ is infinite, does there exist an $a \in (0,1)$ such that $C \cap [a,1]$ is infinite?",['real-analysis']
1833526,induction proof over graphs,"I have a question about how to apply induction proofs over a graph. Let's see for example if I have the following theorem: Proof by induction that if T has n vertices then it has n-1 edges. So what I do is the following, I start with my base case, for example: a=2 v1-----v2 This graph is a tree with two vertices and on edge so the base case holds. Induction step: Let's assume that we have a graph T which is a tree with n vertices and n-1 edges (Induction Hypothesis)
Now I take a new vertex that is not connected to the tree that I will call it v'. If I add this v' to T then I will have to connect it with any vertex that is on T by an edge to form the new graph T'. By IH hypothesis T has n vertices and n-1 edges, and by adding this new vertex I will end up with n+1 vertices and n edges. As we see the addition of this new vertex v' with its correspondent edge will not form a cycle, so T' will also be a tree. Is it my induction proof fine? and if its not, then how it will be a sound induction proof? Thanks","['induction', 'discrete-mathematics']"
1833557,The largest root of a recursively defined polynomial,"Suppose that for all $x \in \mathbb{R}$, $f_1(x)=x^2$ and for all $k \in \mathbb{N}$,
$$
  f_{k+1}(x) = f_k(x) - f_k'(x) x (1-x).
$$
Let $\underline{x}_k$ denote the largest root of $f_k(x)=0$. I want to prove the following conjectures: $0=\underline{x}_1 < \underline{x}_2 < \underline{x}_3 < \dots < 1$. $\lim_{n \to \infty} \underline{x}_n = 1$. $f_k'(\underline{x}_k) \geq 0$ for all $k$. These conjectures are the missing part of a larger proof and it seems to hold for any $f_k$ that I can compute by hand or numerically. The first few polynomials: $f_1(x)=x^2$, so that $\underline{x}_1=0$ and $f_1'(\underline{x}_1) = 0$ $f_2(x)=x^2 (2x-1)$, so that $\underline{x}_2=\frac{1}{2} \in (\underline{x}_1,1)$ and $f_2'(1/2)=1/2>0$ $f_3(x)=x^2 (6x^2-6x+1)$, so that $\underline{x}_3 = \frac{1}{2} + \frac{1}{2 \sqrt{3}} \approx 0.7887 \in (\underline{x}_2,1)$ and $f_3'(\underline{x}_3) \approx 2.1547>0$ $f_4(x)=x^2 (2x-1) (12 x^2-12 x+1)$, so that $\underline{x}_4=\frac{1}{2}+\frac{1}{\sqrt{6}} \approx 0.9082 \in (\underline{x}_3,1)$ and $f_4'(\underline{x}_4) \approx 6.5993 > 0$ The polynomials $f_k$ have many properties that should help. For example it is easy to show that $f_k(1)=1$ for all $k$ and $f_k(x) > 1$ for all $x>1$ for all $k$. Therefore all real roots must be strictly below $1$.","['recursion', 'polynomials', 'calculus']"
1833588,Inequality with a rational polynomial,"Let $$P(x)=x^{n-1}+a_{n-2}\,x^{n-2}+a_{n-3}\,x^{n-3}+\cdots+a_0\in\mathbb{Q}[x]$$ be a monic rational polynomial of degree $n-1$. I want to show that, for every set of $n$ distinct integers $\{x_1,x_2,\cdots,x_n\}$, there exists $i\in\{1,2,\cdots,n\}$ such that 
$$\big|P(x_i)\big|\ge\frac{(n-1)!}{2^{n-1}}\,.$$ I don't know how approach this problem. Note that the degree is $n-1$ yet there are $n$ integers.","['number-theory', 'inequality', 'polynomials']"
1833613,How exactly is the St Petersburg Paradox giving bounded payoff in average-of-N-trials?,"I understand why the expected value of the St Petersburg Paradox is algebraically infinite, but intuition tells me that in practice any given round of the game will not go on multiplying the pot for an infinite number of steps, so I am attempting a more nuanced analysis. I wrote a computer program to measure the actual payoff in practice. In pseudocode, the linked algorithm is basically for each trial
    pot = 2
    if (coin toss is tails)
        end this trial with no winnings
    while (coin toss is heads)
        pot <-- pot x 2
    winnings <-- pot
end trial loop
print winnings / number of trials Here are the raw results TRIALS      AVERAGE PAYOFF (one column per run of the program)
10          2.6     6.8     3.8     2.4     0.6     3.2
100         14.02   6.44    9.8     5.5     5.54    6.3
1000        7.494   9.516   9.254   4.162   4.676   4.36
10000       6.864   7.362   217.462 11.3302 5.722   13.2424
100000      19.248  9.78776 14.4392 15.9848 14.1321 14.9646
1000000     26.0934 10.4752 13.1372 15.6501 10.6382 9.93312
10000000    12.3089 12.9838 11.7851 17.3922 12.9416 27.9271
100000000   23.467  14.6506 15.1155 16.2025 12.4644 15.5596
1000000000  18.4466 13.9933 16.7371 14.888  15.5726 Let's assume the random number generator is behaving as documented and there is no bias in the program. Note that the numbers involved are well within the limits of numerical stability for a FPU. Apart from one outlier, where apparently sufficiently many trials in the 10,000 case were lengthy enough to move the average, the average payoff seems to be less than 30. This result is remarkably consistent. Now, the analytical response to this would be ""a long trial is exponentially unlikely to happen but produces an exponentially increasing payoff if you wait long enough until you see it "". However, unless you play the game an infinite number of times , you will not see an infinite payoff in practice. My next observation is that as the number of trials increases the average payoff over all trials seems to stabilise at around 15. (If you stick to taking an average of, say, 10 trials, then you soon start to see larger average payoffs as you re-run the program, dropping off exponentially as you would expect). What I'm getting at is that, from an economic and decision-theoretic point of view, it appears to be demonstrably irrational to put down more than about $15,000,000,000 to play the game 1,000,000,000 times. Intuitively we could say that, in the long run, one expects that most games are short and this constrains the average payoff in practice; the algebraic limit doesn't matter because we never actually get there. How can we quantify this notion? How can we derive this apparently stable practical-limit-of-the-average-over-many-trials, which seems to be about 15?","['game-theory', 'statistics', 'decision-theory', 'probability']"
1833651,"Is there a ""balanced knapsacks"" problem with a known result?","You're going on a trip with some friends and want to share the load of the camping gear as evenly as possible. Each of you is equally strong, and each of your knapsacks is identical. Can the fairest distribution of the load be obtained without trying the brute-force approach of every possible combination? More formally, given: $n$ knapsacks of equal weight capacity $c$ a set $S$ of packages of arbitrary weights $\{w_1, w_2, ..., w_k\}$ with $\forall i : w_i \leq c, \sum_{i} w_i \leq nc$, all of which are to be put into the knapsacks then we want to minimize the difference between the weight of the heaviest knapsack and the weight of the lightest knapsack. Does this problem have a name and a known strategy for minimizing the stated difference? It seems NP-hard, at least.",['combinatorics']
1833667,Proof that $A \cap B$ and $A \setminus B$ are disjoint.,"I am trying to prove that $A \cap B$ and $A \setminus B$ are disjoint. Here is what I've done so far. Is there anything that's wrong in my proof, and is there anything that can make it better? Proof: $A \cap B$ and $A \setminus B$ are disjoint if $(A \cap B) \cap (A \setminus B) = \emptyset$. First, let $x \in (A \cap B) \cap (A \setminus B)$. Then $x \in (A \cap B)$ and $x \in (A \setminus B)$. Then this means $x \in A$ and $x \in B$, and $x \in A$ and $x \notin B$. Thus, these two sets must be disjoint and therefore $x \in \emptyset$. Hence, $(A \cap B) \cap (A \setminus B) \subseteq \emptyset$. Conversely, since the empty set is always a subset of any nonempty set, $\emptyset \subseteq (A \cap B) \cap (A \setminus B)$. Therefore $(A \cap B) \cap (A \setminus B) = \emptyset$.","['elementary-set-theory', 'proof-verification']"
1833678,Why is $\lim\limits_{n\to\infty} (1 + \frac{1}{2n})^n = e^{\frac{1}{2}}$,In my textbook it is stated that this is obvious: $\lim\limits_{n\to\infty} (1 + \frac{1}{2n})^n = e^{\frac{1}{2}}$. However I feel stupid for not understanding why? What am I missing?,"['eulers-number-e', 'exponential-function', 'limits']"
1833688,Non constant analytic function from $\{z\in\mathbb{C}:z\neq 0\}$ to $\{z\in\mathbb{C}:|z|>1\}.$,"Does there is non constant analytic function from  $\{z\in\mathbb{C}:z\neq 0\}$ to $\{z\in\mathbb{C}:|z|>1\}?$ According to me there is no such  non constant analytic function because if there is any such function say $f,$ then $f$ can have  either a pole or essential singularity at $z=0$. In the case of pole Picard's theorem of meromoprphic function will work and in the case of essential singularity we know that image of  any neighbourhood of essential singularity  is dense in $\mathbb{C}$, so in both of the cases we get a contradiction. So no such non constant analytic function. Am i right? Please suggest me. Thanks.",['complex-analysis']
1833722,Why the space of complex measures is Banach?,"I've read the proof from here: Space of Complex Measures is Banach (proof?) and understood the part that proves that constructed limit is complex measure. But the first part is a bit unclear for me. I don't see why $$\|\mu-\mu_n\| \le \liminf\limits_{m\to\infty} \|\mu_m-\mu_n\|$$
Could anyone help me with that?","['functional-analysis', 'measure-theory']"
1833724,Find the value of $(a+b-c)/(a+b+c)$,"Given $$2a^2 +17b^2 + 8c^2 -6ab -20bc =0 \\ abc \neq 0.$$ 
  Find the value of $(a+b-c)/(a+b+c)$. I tried factorizing the equation, but still can't find a solution","['algebra-precalculus', 'polynomials']"
1833734,Why can I remove discontinuities by modifying function,Given for example $$\lim_{x\to 2} \frac{x^{2} + x - 6}{x - 2}.$$ The limit cannot be computed in that form of the function. But WHY am I able to modify the expression so as to define the limit as $x$ approaches $2$? What is happening? Please ELI$5$ how that is valid math.,"['continuity', 'limits']"
1833776,How to determine which of the following transformations are linear transformations?,"Determine which of the following transformations are linear transformations A. The transformation $T_1$ defined by $T_1(x_1,x_2,x_3)=(x_1,0,x_3)$ B. The transformation $T_2$ defined by $T_2(x_1,x_2)=(2x_1−3x_2,x_1+4,5x_2)$ . C. The transformation $T_3$ defined by $T_3(x_1,x_2,x3)=(x_1,x_2,−x_3)$ D. The transformation $T_4$ defined by $T_4(x_1,x_2,x3)=(1,x_2,x_3)$ E. The transformation $T_5$ defined by $T_5(x_1,x_2)=(4x_1−2x_2,3|x_2|)$ . I believe that it could be A and E. How can I determine this? If someone could show me one I could figure out the rest.","['linear-algebra', 'linear-transformations']"
1833797,$(AB=BA\wedge A^*Bx=0)\implies BA^*x=0$?,"Let $X^*$ mean the conjugate transpose of matrix $X.$ I am given two matrices $A,B$ and a vector $x$ such that $AB=BA$ and $A^*Bx=0.$ Does $BA^*x=0$ then? It may look out of context, but such a property would help me with proving ellipticity of some differential operator. Unfortunately I am not handy with matrix algebra. If the answer is no, would such additional assumptions like those below help?
$$A^*B^*x=0\hspace{10pt}ABx=0\hspace{10pt}B^*A=0$$","['matrices', 'linear-algebra']"
1833802,Is exponential map locally a diffeomorphism w.r.t. base point?,"Let $M$ be a riemannian manifold and $\exp_p: T_pM \rightarrow M$ the exponential map at $p \in M$. At each point $p\in M$, $\exp_p$ can be restricted to a neighborhood $V$ of $0\in T_pM$ so that $\exp_p|_V$ is a diffeomorphism. Let $U\subset M$ denote image of $V$ under this map. Choosing an orthonormal basis $\{E_i\}$ for $T_p M$ and using the isomorphism $E: \mathbb R^n \rightarrow T_pM$, where $E(x^1, \dots, x^n)= x^iE_i$, gives normal coordinates $(U, \phi)$, where 
$$
\phi := E^{-1} \circ \exp^{-1}_p: U \rightarrow \mathbb R^n
$$ My question is: can we fix some $z\in \mathbb R^n$ (small enough) and take some small neighborhood $\widetilde{U}$ of $p$ so that the function $\widetilde \phi$, defined as
$$
\widetilde{\phi}_z (p) := \exp_p ( E(z))
$$
is a diffeomorphism when restricted to  $\widetilde{U}$? (In the definition of $\widetilde \phi$, the isomorphism $E$ will also vary with $p$.)","['riemannian-geometry', 'differential-geometry']"
1833826,Finding a recurrence for number of paths in a certain tree,"I have a graph which looks like this: The question is to find a recurrence for $a_n$ - the number of paths of length $n$ that start in vertex $A$. How do you tackle these kind of problems? There is obviously something I need to notice, but what is it?","['combinatorics', 'graph-theory', 'recurrence-relations', 'discrete-mathematics']"
1833828,"Show finite complement topology is, in fact, a topology","My attempt to prove the following is below: Let X be an infinite set. Show that $\mathscr{T}_1=\{U \subseteq X : U = \emptyset $ or $ X\setminus U $ is finite $ \}$ My book calls this set the "" finite complement topology "" I just want to know if this proof is correct. (I intuitively understand why its a topology, but I'm not sure if I'm showing it properly) Using the definition of topology: $\mathscr{T}$ is a topology on X if and only if the following are true: (i) X and Ø are elements of $\mathscr{T}$. (ii) $\mathscr{T}$ is closed under finite intersections. (iii) $\mathscr{T}$ is closed under arbitrary unions. Let:$V_k \subseteq X$ be any finite set. (ie: $V_1, V_2...$ are all finite sets) So Then, $U_k = X \setminus V_k$, would be the subsets of $\mathscr{T}$. Now to verify the definition. (i) X and Ø are elements of $\mathscr{T}$. Ø is given in the definition of $\mathscr{T}_1$. Also, the empty set is considered finite, with cardinality zero. Thus $X$ is in $\mathscr{T}_1$ because its complement is finite. (ii) $\mathscr{T}$ is closed under finite intersections. $U_k \cap U_j = X \setminus (V_k \cup V_j) $, due to De Morgan's law. Since the Union of two finite sets is also finite, this set is still in $\mathscr{T}_1$. Or Symbolically (using bars || for cardinality): If $|V_k \cup V_j| < |\mathbb{N}|  $, then $(U_k \cap U_j) \in \mathscr{T}_1$. This reasoning can be extended to any finite amount of intersections. (iii) $\mathscr{T}$ is closed under arbitrary unions. $U_k \cup U_j = X \setminus (V_k \cap V_j) $, due to De Morgan's law.Since the Intersection of two finite sets is also finite, this set is still in $\mathscr{T}$. Or Symbolically: If $|V_k \cap V_j| < |\mathbb{N}|  $, then $(U_k \cup U_j) \in \mathscr{T}_1$. This reasoning can be extended to any finite amount of Unions. Now let's consider the infinite case: $V_k \cap ... \cap V_j$ will only contain points that are in EVERY set being intersected. So if $V_k \cap ... $ was infinite, that would imply the every $V_k$ being intersected is also infinite, but $V_k$ is specifically defined as being finite. Thus even with infinite Unions, $\mathscr{T}_1$ is still closed.","['general-topology', 'proof-verification']"
1833830,Does the image of positive measure set under homeomorphism also have positive measure?,"Say I have a homeomorphism $f:A\longrightarrow B$ between open subsets $A$ and $B$ of $\mathbb{R}^n$. If $S\subset A$ has positive Lebesgue measure, does $f(S)$ also have positive measure? If so, do you know a reference to this result?","['lebesgue-measure', 'measure-theory']"
1833841,Compare $\mathbb{E}[XY]\mathbb{E}[XY]$ with $\mathbb{E}[X]\mathbb{E}[XY^2]$,$\newcommand{\E}{\mathbb{E}}$So this was a question asked to me in an interview where $X$ and $Y$ are two random variables and I was asked to compare the $\E[XY]\E[XY]$ with $\E[X]\E[XY^2]$ . The interviewer didn't give any more details. I am not exactly sure what he wanted.,"['probability-theory', 'probability', 'expectation']"
1833867,Visualization of surface area of a sphere,"I help mentor some really young, bright kids in mathematics. We were looking at geometric properties of various shapes, and one of the kids noted that the surface area of a sphere $S = 4\pi r^2$ contains the equation for the area of a circle $A = \pi r^2$. She was a bit confused why the factor of $4$ was mysteriously there. I told her I'd get back to her. I know how to prove the formula using calculus, but I spent a long time trying to find an elementary way of doing it. Does anyone know of a way of proving the first equation using almost no advanced mathematics$^1$? This seems unlikely, so as a separate question, does anyone know of a good visualization to show the relation between $S$ and $A$? The naive approach of taking four circles and showing you can ""place them"" on a sphere is clearly wrong (you can't just place four circles on a sphere), but I'm not sure what the alternative is. $^1$These kids have a working knowledge of variable manipulation, basic geometry, and I guess combinatorics?","['alternative-proof', 'education', 'geometry']"
1833891,Combinatorial proof for a non obvious binomial identity,I think I got some serious problem with those combinatorial proofs. Why would the following be true ($1\leq r\leq k\leq n$): $$\sum_\limits{j=r}^{n+r-k}\binom{j-1}{r-1}\binom{n-j}{k-r} = \binom{n}{k}?$$ It doesn't make sense to me. We could choose $r$-th element of our set and choose from lesser and greater elements but this is not what this formula gives.,"['combinatorics', 'combinatorial-proofs', 'discrete-mathematics']"
1833894,Definitions of inner and outer regular measures,"The definitions can be found here . I am trying to figure out why it's defined specifically this way. More precisely- Why compact sets are used to define inner regularity while open sets are used for outer regularity? I thought that maybe it has something to do with the facts that the union of open sets is open and that (in a Hausdorff space) the intersection of compact sets is compact, but I dont see how these matter.
Another thought I had is that maybe the motive comes from Riesz–Markov–Kakutani representation theorem.",['measure-theory']
1833915,"""Barred"" Tensor Indices in Complex Manifolds","I'm having an embarrassingly hard time straightening out how to work with the ""barred"" indices that show up in tensors on complex manifolds.  For example, the Kahler form $\omega = \frac{i}{2}g_{i \bar{j}}dz^{i} \wedge d\bar{z}^{\bar{j}}$.  Is it correct to say that these barred indices only serve to denote an index that is contracted with either a $d\bar{z}$ or $\partial/\partial \bar{z}$ in some general tensor?  In other words, we could I think equivalently write the above Kahler form as $\omega = \frac{i}{2}g_{i j}dz^{i} \wedge d\bar{z}^{j}$, correct?  I suppose this barred notation is simply convenient when writing things out in coordinates, so we can read off the holomorphic and anti-holomorphic components. The precise problem in which this tripped me up, is arguing that the $g_{i \bar{j}}$ coming from the above Kahler form is actually a Hermitian matrix in local coordinates.  Clearly, without the barred notation, we would say a matrix is Hermitian if its entries satisfy $g_{ij}=(g_{ji})^{*}$.  Can someone perhaps help me reason through how the barred indices are affected by this complex conjugation?  I know the Kahler form is real, so it should equal its complex conjugate, but even for a non-real form there is a way to conjugate components, and the Hermitian condition I think is something extra.  I'd very much appreciate a little nudging here!","['complex-geometry', 'differential-geometry']"
1833916,Find the value of $ [1/ 3] + [2/ 3] + [4/3] + [8/3] +\cdots+ [2^{100} / 3]$,Assume that [x] is the floor function. I am not able to find any patterns in the numbers obtained. Any suggestions? $$[1/ 3] + [2/ 3] + [4/3] + [8/3] +\cdots+ [2^{100} / 3]$$,"['algebra-precalculus', 'functions']"
1833917,"If GCD $(a_1,\ldots, a_n)=1$ then there's a matrix in $SL_n(\mathbb{Z})$ with first row $(a_1,\ldots, a_n)$","Let $n \geq 2$ . Let $a_1, a_2, \ldots, a_n$ be $n$ integers such that $\gcd\left(a_1, a_2, \ldots, a_n\right) = 1$ . Prove that there exists a matrix in $\operatorname{SL}_n\left(\mathbb{Z}\right)$ whose first row is $\left(a_1, a_2, \ldots, a_n\right)$ . Since the gcd of the integers $a_1,\ldots, a_n$ is $1$ , there exists weights $x_i \in \mathbb{Z}$ such that $a_1x_1+\cdots+ a_nx_n=1$ .
My two ideas are (a) to brute force construct an $n\times n$ matrix with first row $a_1,\ldots ,a_n$ and to construct the remaining rows such that the determinant is $\sum a_ix_i=1$ or (b) to use induction. (a) (Constructive) This is tedious since once I find a way to construct the remaining $n-1$ rows to ensure that $a_1x_1$ appears in the determinant, I am not sure how to modify these $n-1$ rows to ensure  that only the terms $a_ix_i$ appear in the cofactor expansion. If such a matrix exists, I'd like to see it. (ii) (Non-constructive) If I proceed by induction then the base case $n=2$ is settled since I can choose the 2nd row to be $-x_2, x_1$ so that the determinant is $a_1x_1-a_2(-x_2)=1$ . However, I'm not sure how to use the inductive hypothesis to show that if I can construct such an $n\times n$ -matrix then I can construct an $\left(n+1\right) \times \left(n+1\right)$ -matrix with the desired property. In particular, if the gcd $(a_1,\ldots ,a_{n+1})$ is $1$ , it is not necesarry that the gcd of any $n$ of these terms is $1$ , so induction may not even apply here. How can I construct such a matrix or prove that one exists (without necessarily constructing it)?","['matrices', 'gcd-and-lcm', 'determinant']"
1833959,"A common term for $a_n=\begin{cases} 2a_{n-1} & \text{if } n\ \text{ is even, }\\ 2a_{n-1}+1 & \text{if } n\ \text{ is odd. } \end{cases}$","When I was answering a question here, I found a sequence as a recursive one as given below. $a_1=1$, and for $n>1$, $$a_n=\begin{cases}
2a_{n-1} & \text{if } n\ \text{ is even, }\\
2a_{n-1}+1 & \text{if } n\ \text{ is odd. }
\end{cases}$$ I need to find a common term for this sequence. For example, for the sequence $a_1=2$ and $a_n=2a_{n-1}$, for $n>1$, the common term is $a_n=2^n$. I appreciate any answer or hint in advance.","['sequences-and-series', 'calculus']"
1834010,Find Polynomial of order 10 for $f(x)=sin(x)$ near x=0,My work so far : I presume the answer should look more like a summation? Thanks!,"['derivatives', 'taylor-expansion', 'calculus']"
1834024,Seeking closed form for infinite sum $\sum \limits_{ n=1 }^{ \infty }{ \frac { { \left(n! \right) }^{ 2 } }{ { n }^{ 3 }(2n)! } }$,"$\displaystyle \sum _{ n=1 }^{ \infty  }{ \frac { { \left(n! \right) }^{ 2 } }{ { n }^{ 3 }(2n)! }  }$ is approximately $.5229461921333351$ but I've been assured that there is a closed form for this infinite series that involves the TriGamma and  Zeta functions but it is not unique. I found one candidate result which is:
$$ \frac{ \pi \sqrt{3}}{72} \Big[3 \psi_{1} \left(\frac{1}{3} \right) - \psi_{1} \left(\frac{5}{6} \right) \Big]- \frac{4}{3} \zeta(3) $$ My friend (tormentor) has challenged me to find other such expressions. I know how to transform the look of such expressions if the Gamma function is involved by using functional equations like $\Gamma(x) = \Gamma(1+x)/x$ so I suspect he knows a similar result for the PolyGamma functions. I just can not find the information.  By trial and error, I did find that $3 \psi_{1}(1)=\psi_{1}(1/2)$","['special-functions', 'factorial', 'sequences-and-series', 'closed-form']"
1834025,How can I solve $y^4 = 5 \pmod{11\times19}$ with legendre?,"Solve $y^4 = 5 \pmod{11\times19}$ I'm trying to let $y^2=A$ then $A^2=5 \pmod{11\times19}$. And solve this problem then $A= 104,-104,28,-28 \pmod{11\times19}$ Then should I solve this problem for all this four $A$ ? I want to solve this easily with Legendre. (I think I can use this thing that $(\frac{100}{14})=1$ and $(\frac{104}{19})=1$ , $(\frac{28}{11})=-1$, $(\frac{14}{11})= 1$.) All fractions are translated as Legendre symbol.",['number-theory']
1834047,Convergence in $\mathbb{Q}$,"How will I prove that a sequence in $\mathbb{Q}$ which is bounded below and decreasing is Cauchy, without using the knowledge of reals?","['real-analysis', 'sequences-and-series']"
