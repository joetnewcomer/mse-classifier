question_id,title,body,tags
1151099,Is the set of real numbers a group under the operation of multiplication?,"Question: Is the set of real numbers a group under the operation of multiplication? My professor answered it by saying: No. There is no identity element (1*0=0). However, isn't the identity element 1, did he mean to say there is no inverse because the number 0 does not have an inverse. Or did my professor try to mean something else? Or maybe I'm just mis-understanding what he wrote.",['abstract-algebra']
1151101,How many blocks in this set differ from the original in one exactly one way?,"This is an example problem that I worked out but I'm not sure if it's correct since we weren't given an answer key. The full problem reads: Dustin has a set of blocks. Each of these blocks is made of either wood or plastic and comes in one of three sizes (small, medium, large), five colors (red, white, blue, yellow, green) and six shapes (triangular, square, rectangular, hexagonal, octagonal, circular). A. How many blocks does Dustin have if he has a full set, that is one of each possible type. My answer = 2 types * 3 sizes * 5 colors * 6 shapes = 180 B. (This is the answer I'm not so sure of) How many of the blocks in this set differ from the small red wooden square block in exactly one way ? My answer = small red (plastic) square = 1 choice (medium, large) red wooden square = 2 choices small (white, blue, yellow, green) wooden square = 4 choices small red wooden (triangular, rectangular, hexagonal, octagonal, circular) = 5 choices so, 1 + 2 + 4 + 5 = 12 blocks that differ in exactly one way","['discrete-mathematics', 'combinatorics']"
1151112,Definition of measurability,"The alternative definition of measurability is: A subset $E \subset \mathbb{R}^n$ is measurable if for every $\epsilon > 0$ there is a closed set $F \subset E$ such that $m^*(E\setminus F)<\epsilon$. I am asked to show that this is equivalent to the usual definition of measurability: A subset $E \subset \mathbb{R}^n$ is measurable if for every $\epsilon > 0$ there is an open set $O \supset E$ such that $m^*(O \setminus E)<\epsilon$. My approach is: If $E$ is measurable, then $E^c$ is measurable. So for all $\epsilon > 0$, there exists a closed $F \subset E^c$ such that $m^*(E^c-F)<\epsilon$. Let $O=F^c$ Since $F$ is closed, $O=F^c$ is open. If $F \subset E^c$, then $O=F^c \supset E$. Finally, $E^c-F=F^c-(E^c)^c=F^c-E=O-E$, which implies $m^*(O-E)=m^*(E^c-F)<\epsilon$. Other direction: Suppose for all $\epsilon > 0$ there exists an open $O \supset E^c$ such that $m^*(O-E)<\epsilon$. This means $E$ is measurable, which in turn means $E^c$ is measurable. So there exists an open $O \supset E^c$ such that $m^*(O-E^c)<\epsilon$. Let $F=O^c$. If $O$ is open, then $F=O^c$ is closed. If $O \supset E^c$, then $F=O^c \subset E$. Finally, $$O-E^c=(E^c)^c-O^c=E-O^c=E-F,$$ which means $m^*(E-F)=m^*(O-E^c)<\epsilon$.",['measure-theory']
1151118,When can an edge subset of a graph be extended to become an element of its cycle space?,"Let $F$ be a set of edges in a graph $G$.
Show that $F$ extends to an element of the cycle space of $G$ iff $F$ contains no odd cut. The context for this exercise is the following: Let $G = (V,E)$ be a simple graph (i.e., a graph without parallel edges or loops). We can understand the power set $2^E$ (with the symmetric difference $\dotplus$ as addition) as vector space $\mathcal E(G)$ over $\mathbb F_2$. Many authors write also $GF(2)$ for $\mathbb F_2$. If $C$ is a cycle subgraph of $G$, then the edge set of $C$ is called a circuit. The vector subspace of $2^E$ generated by all circuits is called the cycle space $\mathcal C(G)$ of $G$. The above exercise asks when an arbitrary set of edges $F$ of $G$ can be extended to an element of $\mathcal C(G)$. We can understand an element $W \in \mathcal E(G)$ as indicator map $W: E \to \mathbb F_2$ and define a bilinearform $\left\langle F, F'\right\rangle := \sum_{e \in E} F(e) \cdot F'(e) \in \mathbb F_2$ for $F, F' \in \mathcal E(G)$. So $\left\langle F, F'\right\rangle = 0$ iff $F$ and $F'$ have an even number of edges of $G$ in common.
In general we have $\left\langle F, F'\right\rangle = 0$ if $F$ is any circuit and $F'$ is any cut of $G$. I have the following suggestion for one of the two implications of the exercise (but I have no idea for the other implication). Let $\emptyset\not= F \subseteq E(G)$ be a set of edges that extends to an element $C\in\mathcal C(G)$, i.e., $F \subseteq C$.
Suppose $F$ contains an odd cut $D$, i.e., $D \subseteq F \subseteq C$. Consider the following facts: $D \cap (C\setminus F) = \emptyset$ and $C\setminus F = C \dotplus F$ and $C = F \cup (C\setminus F) = F \dotplus (C\setminus F) = F \dotplus (C \dotplus F)$. Since $C$ is a circuit and $D$ is a cut, it follows $0 = \left\langle C,D\right\rangle = \left\langle F \dotplus (C\setminus F),D\right\rangle = \left\langle F,D\right\rangle + \left\langle C\setminus F,D\right\rangle = 1 + 0 = 1$ which is a contradiction. There is also a dual version of the exercise above (which could be of use): 
Let $F$ be a set of edges in a simple graph $G$.
Show that $F$ extends to an element of the cut space $\mathcal C^*(G)$ of $G$ iff $F$ contains no odd circuit. 
For this equivalence I have a complete solution, but not for the original one.","['graph-theory', 'algebraic-graph-theory', 'combinatorics']"
1151148,A convex subset of a Banach space is closed if and only if it is weakly closed,"I'm looking for a proof that given $(X\textbf{ } \|\cdot\|)$ normed space, $M \subset X$ convex set, $M$ is weakly closed if and only if it's strongly closed as well.","['general-topology', 'normed-spaces', 'convergence-divergence', 'functional-analysis']"
1151202,Show that $S$ and $2^{S}$ are not equinumerous. (Not bijective?),"I have tried to look for a problem the same as mine, but I have not been too lucky, or if I did I had trouble applying that solution to my problem. Any help would be appreciated. I know how to solve this problem, but I'm afraid it would someone ""cheap"" because it is just a fact I found. Let $S$ be any set.  Let $2^{S} =\{f\mid f\colon S\to\{0,1\}\}$. Then $S$ and $2^{S}$ are not equinumerous. Now, I believe the ""cheap"" way I found out how to do this is to use the fact that the there is a bijection between $2^{S}$ and $\mathcal{P}(S)$, but there is no bijection between a set and it's power set. I was given a hint to assume there is a bijection $f\colon S\to2^{S}$, and to copy the method used in Cantor's Theorem. I went through this theorem a few weeks ago. Also, I just looked at in my text and on Proofwiki, but I am still having trouble. Edit: I forgot to mention I am just taking an introductory logic class. The only thing we have done with Cantor's Theorem is prove that the powerset of integers is non enumerable.","['elementary-set-theory', 'functions']"
1151217,"Linear independence of $\sqrt{2}$, $\sqrt[3]{2}$, $\sqrt[4]{2}, \dots$ over the rationals","I was trying to prove that $\sqrt{2}, \sqrt[3]{2}, ... $ are linearly independent over the rationals using elementary knowledge of rational numbers. But I could not come up with any proof using simple arguments. 
How to prove that the set $$\{\sqrt[n]{2}\; :\; n=2,3,4,...\}$$ is linearly independent over the field $\mathbb{Q}$ ?","['radicals', 'linear-algebra']"
1151244,Trigonometric inequalities: when to reverse sign,"I have the inequality 
$$\cos^{-1}{x^2 \over 2x-1} \ge {\pi\over 2}  $$
Now, by multiplying both sides by cos, I get.
$$ {x^2 \over 2x-1} \ge 0$$
However, I SHOULD be getting 
$$ -1\le {x^2\over2x-1} \le 0$$
And this raises three questions Where does that $-1$ come from? Why were the signs reversed, and how do I know when to do it? Where do I go from here?","['inequality', 'trigonometry', 'algebra-precalculus']"
1151275,Covariance of Two Dependent Variables,"So I'm looking at the following: $\operatorname{Cov}(X, X^2)$ where $X$ is the standard normal.  So I know that $E[X] = 0$ and we have: $$\operatorname{Cov}(X, X^2) = E(X \cdot X^2) - E[X] \cdot E[X^2] = E[X^3] - 0 \cdot E[X^2] = E[X^3]$$ From googling around, apparently this $= 0$, but I'm not sure why. Any clarification here? Thanks,
Mariogs","['statistics', 'probability']"
1151291,What exactly is a natural map,"I have numerous questions on my abstract homework asking me to define ""the natural map"", though i don't see reference to it in my textbook. Let X and Y be sets and let C be the set {f : {1,2}→ X ∪Y|f(1) ∈ X and f(2) ∈ Y} (1) Deﬁne the natural map Γ: C → X × Y (2) Deﬁne the map $Γ^{−1}$: X ×Y → C . I don't understand what is being asked of me. Also: For a set S deﬁne the natural isomorphism Char: P(S) →F(S,{0,1}). For A ⊆ S denote the function Char(A) by χA. (2) Deﬁne Char−1: F(S,0,1) →P(S) I know that an isomorphism is a function that perserves structure between two structurally-the-same algebraic thingies. Can someone give me an intuitive definition of what all this natural stuff is about?",['abstract-algebra']
1151309,Function that sends every Lebesgue measureable sets to a lebesgue measurable set. Then it sends measure zero sets to measure zero sets.,I want to prove: If $f: \mathbb R \to \mathbb R $ is a function that send every Lebesgue measureable sets to Lebesgue measurable sets then it send measure zero sets to measure zero. I do not know how to start to think. Can someone help me. Thanks,"['measure-theory', 'lebesgue-measure', 'real-analysis']"
1151328,"How to show that this estimator is unbiased, and find its variance","Suppose I'm trying to estimate $\mathbb{E}[\phi(X)]$ where $X$ is an $N(0,\sigma^2)$ r.v. by using the estimator $$\theta = \frac{1}{n \sigma} \sum_{i=1}^n \exp(-Y_i^2(1/2\sigma^2 - 1/2))\phi(Y_i)$$ where $Y_i$ are i.i.d $N(0,1)$ r.v.'s and $\phi$ is s.t. $\phi(X)$ has finite mean and variance. How do I show that this is unbiased? I've currently tried manipulating the thing inside the sum to try and get something that resembles a normal pdf which integrates to 1, but there's a couple of things missing that means this doesn't work. Hints much appreciated","['statistics', 'probability', 'probability-theory']"
1151335,What is Direct Sum Decomposition,Suppose that $V$ is a finite dimension inner product space and $W$ is a subspace of $V$. Then we know that $V = W \oplus W^{\perp}$. What is this $\oplus$ operator? Is it equivalent to union $\bigcup$ or intersection $\bigcap$?,"['direct-sum', 'linear-algebra']"
1151347,Series : Every rearrangement converges $\implies$ absolutely convergent,"I know that for a (complex) series : If the series converge absolutely, then every rearrangement also converges and converge to the same limit. But how to prove the converse : If every rearrangement of a (complex) series converge to the same limit, then the series itself also converge absolutely. That is to prove : Let $\sum z_i$ be a complex series. If every rearrangement of $\sum z_i$ converge to the same limit, then $\sum z_i$ converges absolutely.","['complex-analysis', 'sequences-and-series', 'real-analysis']"
1151403,Am I correct in thinking that $A = B \cup C = B \cup D \not\implies C = D$?,"One of my textbooks has a problem of this form: If $A = B \cup C = B \cup D$, can we conclude that $C = D$? Am I correct in thinking that it's almost trivial because I can't just ""cancel"" the $B$ show that $C \neq D$? I'm thinking along the lines of $A = B \cup C = B \cup D \not\implies C = D$ because (for example), $C = \varnothing$ and $D \subseteq B, D \neq \varnothing$ still satisfies the equation, but $C \neq D$.",['elementary-set-theory']
1151406,Random walk with finite expected stopping time,"Let's say each $X_i$ is a simple random variable taking on values 1 or -1 with probability $1/2$ each. Then $S_n = \sum_{i=1}^{n} X_i$ is a random walk. Set $T = \min \{n\in\mathbb{N} \, : \, S_n = 1\}$. One can show that $E[T] = \infty$. Can we choose the $X_i$ instead in such a way that $E[T] < \infty$? They don't necessarily have to be identically distributed, but I would be interested to see if we can do it with the restriction that each $X_i$ takes on two possible values, each with probability $1/2$.","['probability-theory', 'random-walk', 'probability']"
1151421,"Lie algebras of GL(n,R) and differentials","This question comes from a proof in John Lee's Introduction to Smooth Manifolds , page 194. I am questioning a line in the proof of the following proposition: The composition of the maps $\text{Lie}(GL(n,\mathbb{R}))\rightarrow T_{I}(GL(n,\mathbb{R}))\rightarrow\mathfrak{gl}(n,\mathbb{R})$ gives a Lie algebra isomorphism between $\text{Lie}(GL(n,\mathbb{R}))$ and the matrix algebra $\mathfrak{gl}(n,\mathbb{R})$ He uses the standard coordinates, $X^i_j$, on $GL(n,\mathbb{R})\subset \mathfrak{gl}(n,\mathbb{R})$. As I understand it, these $n^2$ coordinate functions take $A\in GL(n,\mathbb{R})$ to the $ij$-th entry of the matrix representation of $A$. He writes any $A=(A^i_j)\in \mathfrak{gl}(n,\mathbb{R})$ determines a left-invariant vector field $A^l\in \mathfrak{g}$, given by $A^L|_X=(dL_X)_I (A)=(dL_X)_I\left(A^i_j\frac{\partial}{\partial X^i_j}\bigg|_I\right)$. This is fine. It is his next few lines which confuse me. He says Since $L_X$ is the restriction to $GL(n,\mathbb{R})$ of the linear map $A\mapsto XA$ on $\mathfrak{gl}(n,\mathbb{R})$, its differential is represented in coordinates by exactly the same linear map. In other words, the left-invariant vector field $A^L$ determined by $A$ is the one whose value at $X\in GL(n,\mathbb{R})$ is $
\begin{align}A^L|_X=X^i_j A^j_k \frac{\partial}{\partial X^i_k}\bigg|_X\end{align}$. I understand the fact that the matrix representation of the differential of a linear map is just the matrix representation of the linear map itself. And I do believe this is essentially what is going on here. The reason I am confused, is because I feel he is using two different meanings for the same notation $X^{\alpha}_{\beta}$. As I understand it, the $X^i_k$ in the $\partial/\partial X^i_k$ are the global coordinates defined on $GL(n,\mathbb{R})$. Whereas, I feel that the $X^i_j$ in the coefficient of each basis vector is the $ij$-th entry of the matrix representation of $X$. Wouldn't it be more appropriate to write, $A^L|_Y = (dL_y)_I(A)=Y^i_jA^j_k\frac{\partial}{\partial X^I_k}\bigg|_Y$, where $Y^i_j$ is the $ij$-th entry of the matrix representation of $Y\in GL(n,\mathbb{R})$? I don't know if I am being stupid or pedantic. Probably both. But if someone is able to clear this up for me it would be much appreciated! Thanks.","['manifolds', 'vector-space-isomorphism', 'lie-groups', 'differential-geometry']"
1151435,"If $f: \mathbb{R} \rightarrow \mathbb{R}$ is a differentiable function, $f(0)=0$ and $f' = f^2$, then $f = 0$.","If $f: \mathbb{R} \rightarrow \mathbb{R}$ is a differentiable function, $f(0)=0$ and $f' = f^2$, then $f = 0$. Any help?",['real-analysis']
1151457,"How do you square $\sin θ\,$? [duplicate]","This question already has answers here : Ambiguity of notation: $\sin(x)^2$ [duplicate] (3 answers) Closed 9 years ago . Is $(\sinθ)^2=\sin^2θ$ or $(\sinθ)^2=\sin(θ^2)$ or $(\sinθ)^2=\sin^2(θ^2)$ Can you explain your answer, regards Tom. Also, does your answer work for $\cos$ and $\tan$?",['trigonometry']
1151465,"What is the size of $\{(x_1,\ldots,x_n)\in\mathbb{R}^n:x_1+\cdots+x_n<a\text{, and }x_i>0\}$? [duplicate]","This question already has answers here : Volume of $T_n=\{x_i\ge0:x_1+\cdots+x_n\le1\}$ (4 answers) Closed 8 years ago . Is there an easy way to compute the size (Lebesgue measure) of the set
$$S_n(a):=\{(x_1,\ldots,x_n)\in\mathbb{R}^n:x_1+\cdots+x_n<a\text{, and }x_i>0\}.$$
Using integration I computed that
$$m(S_n(a))=\frac{a^n}{n!}.$$
But the computation is tedious, and I was wondering if there are more concise/direct ways of proving it. Computation: $$
\begin{align}
m(S_n(a)) &= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-1}}dx_n\cdots dx_1 \\
&= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-2}}(a-x_1-\cdots-x_{n-1})dx_{n-1}\cdots dx_1 \\
&= \int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-3}}\frac{-1}{2}(a-x_1-\cdots-x_{n-1})^2\big|_0^{a-x_1-\cdots-x_{n-2}}dx_{n-2}\cdots dx_1\\
&=\int_0^a\int_0^{a-x_1}\cdots\int_0^{a-x_1-\cdots-x_{n-3}}\frac{1}{2}(a-x_1-\cdots-x_{n-2})^2dx_{n-2}\cdots dx_1\\
\end{align}
$$
and so on...","['calculus', 'measure-theory', 'simplex', 'volume', 'real-analysis']"
1151476,"If $I$ is a homogeneous ideal of $A$ contained in $A_+$, then $\sqrt{I} = \bigcap\limits_{I\subset P\in\text{Proj }A} P$?","EDIT: This is from an exercise of Vakil's Foundations of Algebraic Geometry . 4.5.H: Suppose $I$ is any homogeneous ideal of $S$ contained in $S_+$, and if $f$ is a homogeneous element of positive degree, show that $f$ vanishes on $V(I)$, i.e. $V(I)\subset V(f)$ iff $f^n\in I$ for some $n$. The definition of $V(I)$ is the set of all homogeneous prime ideals containing $I$ but not $S_+$. My thoughts: Now one direct is clear. I want to show the reverse. I think it translates to the following:
$$\sqrt{I} = \bigcap_{I\subset P\in\text{Spec }A} P = \bigcap_{I\subset P\in\text{Proj }A} P.$$
But this seems to be false? How should I go about then?","['commutative-algebra', 'graded-rings', 'algebraic-geometry', 'abstract-algebra']"
1151480,Prove that $a^2 + b^2 \geq 8$ if $ x^4 + ax^3 + 2x^2 + bx + 1 = 0 $ has at least one real root.,"If it is known that the equation
$$ x^4 + ax^3 + 2x^2 + bx + 1 = 0 $$
has a (real) root, prove the inequality
$$ a^2 + b^2 \geq 8. $$ I am stuck on this problem, though, it is a very easy problem for my math teacher . Anyway, I can't figure out.","['inequality', 'roots', 'calculus', 'algebra-precalculus', 'polynomials']"
1151491,Under what conditions is $AA^T$ invertible?,"Given a matrix $A$ with dimensions $m \times n$, is $B=AA^T$ invertible if and only if the rows of $A$ are linearly independent? So far, I've tried writing A as row vectors, $$A = \begin{bmatrix}v_1\\ v_2\\ \vdots \\ v_m\end{bmatrix}$$ where $B_{i,j} = (v_i v_j) $ The Wikipedia page on the Gram Determinant suggests that the condition I stated above is necessary and sufficient, but does not provide a proof.",['matrices']
1151521,How to calculate sin(65) without a calculator.,"I know about the sum and difference formula but I can't think of two values which will be able to use for sin(65). Therefore, I come to the question: How to calculate sin(65) without a calculator.",['trigonometry']
1151569,How to calculate the derivative of log det matrix?,"How to calculate the derivative with respect to $X$ of:
$$
\log \mathrm{det}\, X
$$
here $X$ is a positive definite matrix, and det is the determinant of a matrix. How to calculate this? Thanks! I know it's a classical problem, but I can't find some clear material from the Internet. So some good reference is also very helpful! The hardness for me to understand is that the domain of $X$ is confined to be $S^n$. Therefore, for each symmetric matrix $X$, a specific $n(n+1)/2$-dimension vector would represent it. But the result is $X^{-1}$ (if I remember it right), a matrix form with $n^2$ elements. How to interpret the matrix form result?","['matrices', 'matrix-calculus']"
1151614,how to compute this limits given these conditions.,"if $f(1)=1$ and $f'(x)=\frac{1}{x^2+[f(x)]^2}$ then compute $\lim\limits_{x\to+\infty}f(x)$ i tried to write it was
$$\frac{dy}{dx}=\frac{1}{x^2+y^2}\\
(x^2+y^2)\frac{dy}{dx}=1\\
(x^2+y^2)dy=dx$$
by the help
$$\begin{align}
f(x)&\le1+\int_1^x\frac{dt}{1+t^2}\\
&\le1+\arctan t\bigg|_1^x\\
&\le1+\arctan x-\arctan 1\\
&\le1+\arctan x-\frac{\pi}{4}
\end{align}$$
so
$$\begin{align}
\lim\limits_{x\to+\infty}f(x)&\le\lim\limits_{x\to+\infty}1+\arctan x-\frac{\pi}{4}\\
&\le1+\frac{\pi}{2}-\frac{\pi}{4}\\
&\le1+\frac{\pi}{4}=\frac{4+\pi}{4}
\end{align}$$","['ordinary-differential-equations', 'special-functions', 'real-analysis', 'limits']"
1151626,Canonical isomorphism from $I_p/I_p^2$ to cotangent space,"Sorry if the title is confusing, I don't know if the terminology is standard. For my homework this week I have to prove the following: Let $M$ be a smooth manifold and let $p \in M$. Let $I_p$ denote the set of smooth functions $f:M \to \mathbb{R}$ such that $f(p)=0$. Let $I_p^2$ denote the set of sums $\sum_{i=1}^k f_ig_i$ where $k$ is a nonnegative integer and $f_i,g_i \in I_p$. Show that the quotient vector space $I_p/I_p^2$ is canonically isomorphic to the cotangent space $T_p^*M$. I found the map $f \mapsto \phi_f$, where $\phi_f(v)=vf$ for $v \in T_pM$, and I've proved every part except injectivity. I've tried finding a basis for $I_p/I_p^2$ to show that it has the same dimension as $T_pM$, and I've tried showing that if $f=g \bmod I_p^2$ then there exist derivations taking $f$ and $g$ to different numbers, and I've tried showing that for any smooth function vanishing at $p$ and not in $I_p^2$ there is a derivation taking it to a nonzero number. I tried working in coordinates but that didn't seem to help. Does anyone have any hints? Thanks!","['smooth-manifolds', 'differential-geometry']"
1151671,"About the ""mixed"" form of Gauss and Fresnel integrals","How to integrate the ""mixed"" form of Gauss and Fresnel integrals as following? $$\int_{-\infty}^{+\infty} {e^{-x^2-ia(x+b)^2} dx} $$ where $a \in R, b \in R$. [EDIT] As Claude Leibovici pointed out, by completing the square in the exponent as following: $$-x^2-ia(x+b)^2 = -(1+ia)x^2 -i(2ab)x -i(ab^2) \\
  = -(1+ia) (x + \frac{iab}{1+ia})^2 + c$$ where $c = -i(ab^2) - \frac{a^2b^2}{1+ia}$, the above integral is reduced to: $$e^c \int_{-\infty - id}^{+\infty - id} {e^{-(1+ia) y^2} dy}$$ where $d = \frac{ab^2}{1 + a^2}$. This integral is equal to: $$I_0 \equiv e^c \int_{-\infty}^{+\infty} {e^{-(1+ia) y^2} dy}$$. This is justified by the integration over the following contour to be equal to zero: $$y \in (-\infty, +\infty) \cup (+\infty, +\infty -id) \cup
(+\infty -id, -\infty -id) \cup (-\infty -id, -\infty)$$ The complex Gauss integral $I_0$ is still in the form of ""mixed"" real Gauss and Fresnel integrals. The question is how to derive and justify that the result can be written as $e^c\sqrt{\frac{\pi}{1+ia}}$?","['integration', 'complex-analysis', 'contour-integration']"
1151712,How to prove P(A ∩ B ∩ C) = P(A|B ∩ C)P(B|C)P(C)?,"How to prove P(A∩B∩C) = P(A|B∩C)P(B|C)P(C)? I've tried to approach this a couple times, but always end up getting stuck :( Any help is appreciated! :)",['statistics']
1151723,Domain and Range for composite function,"Given the function $f(x) = x^2$ with the domain $[0, \infty)$ and
  $g(x) = \sin(x)$ with domain $(- \infty, \infty)$. What are the domain
  and range of $f(g(x))$ and $(g(f(x))$? I start the problem by finding both $f(g(x))$ and $g(f(x))$. It appears that: $g(f(x)) = \sin(x^2)$ and $f(g(x)) = (\sin(x))^2$ First, I consider the composition function $f(g(x))$: We know that $Dom(g)$ is given by $(- \infty, \infty)$, and the $Ran(g)$ is $ [-1,1].$ We also know that $Dom(f)$ is given by $[0,\infty)$, and $Ran(f) = [0,\infty)$. I realize that $Ran(g)$ is not a subset of $Dom(f)$. So, this does not exist (?) For the second one, I realize that $Ran(f) \subset Dom(g),$ hence, the domain for $g(f(x)) = [0,\infty)$. Since $\sin(x)$ oscillates, then the range for $g(f(x)) = [-1,1]$. Am i right? Thank you in advance.","['calculus', 'algebra-precalculus', 'functions', 'function-and-relation-composition']"
1151744,Is this proof of Schur's lemma (for a densely defined closed operator) mistaken? How to fix it?,"I'm trying to understand a version of Schur's lemma for a densely defined closed operator.  It is on page 17 of the book Nonabelian Harmonic Analysis by Howe and Tan. The confusing parts are underlined in red. First of all, since the image of $P_U|_{\Gamma (T)}$ is the domain of $T$ , which is a dense subspace of $U$ , it seems like the image of $U_1$ should be $U$ , not just $(\ker T)^\perp$ .  Secondly, what does $\Gamma(T) \cap V =\{0\}$ have to do with T being closed?  This should be a consequence of the fact that $T$ is a function. So it seems like what actually needs to be shown is that $U_1$ carries $(\ker P_V)^\perp$ isometrically onto $(\ker T)^\perp$ . $U_1$ looks like an isometry, so that's okay.  Also, $P_U|_{\Gamma(T)}$ clearly carries $\ker P_V|_{\Gamma(T)}$ onto $\ker T$ , so if $P_1:=   (P_U|_{\Gamma(T)}^\ast \circ P_U|_{\Gamma(T)})^{1/2}$ preserved $\ker P_V$ maybe I would be in business, but it's only evident to me that $P_U|_{\Gamma(T)}^\ast \circ P_U|_{\Gamma(T)}$ does so.","['representation-theory', 'functional-analysis', 'analysis']"
1151759,How do I intuitively understand what this linear transformation matrix is?,$\begin{bmatrix}0 & 1 \\ -1 & 0 \end{bmatrix}$ I know how to get the product when given another matrix. But how do I know what this matrix is doing simply by looking at it?,['linear-algebra']
1151787,The topological product of path-connected spaces is path-connected $\Rightarrow\sf AC$?,"There is a very natural proof that the product of path-connected spaces is path-connected: Let $X=\prod_{i\in I}X_i$ be a product of path-connected spaces $X_i$. Given $(x_i)_{i\in I},(y_i)_{i\in I}\in X$, by assumption for each $i$ there is a path $\gamma_i$ from $x_i$ to $y_i$. Then the function $\gamma(t)=(\gamma_i(t))_{i\in I}$ is a path from $(x_i)_{i\in I}$ to $(y_i)_{i\in I}$. This proof uses the (full) axiom of choice in the selection of the $\gamma_i$'s. Now what I would like to know is whether, as with Tychonoff's theorem, you can recover AC from this statement.","['general-topology', 'set-theory', 'axiom-of-choice']"
1151792,(ZF) Existence of injection and surjection,"I'm trying to prove the following statement related to the Zermelo–Fraenkel set theory, which looks rather basic yet I'm still unable to solve it. Problem: Let $A$ be a nonempty well-ordered set. Prove that for every set $B$ the following two statements are equivalent: There exists an injective function from $A$ to $B$. There exists surjective function from $B$ to $A$. Any comments, ideas and suggestions would be very much welcome. As usual, thank you in advance! EDIT: Here is the a modification of the original: Let $A$ be a nonempty well-ordered set. Prove that for every set $B$ such that there exists an injective function from $A$ to $B$ then there exists surjective function from $B$ to $A$ and vice versa.",['elementary-set-theory']
1151795,Outer measure of product of sets,"If  $A\subseteq R^n$ and $B\subseteq R^m$, such that $A \times B\subseteq R^{n+m}$
Prove that  $μ^{*}_{n+m}(A\times B)\leq μ^*_n(A)μ^*_m(B)$, where $μ^*_q$ is the outer measure of  $ \mathbb{R}^q $. My attempt $A⊆⋃_iA_i,B⊆⋃_jB_j $, and since  $A \times B \subseteq ⋃_{i,j}A_iB_j$
I have the inequality (because of the outer measure monotocity) that states $m^*_{n+m}(A \times B) \leq m^*_{n+m}(⋃_{i,j}A_iB_j)  $
But I don't think that is going to take me somewhere. Thanks!","['measure-theory', 'inequality']"
1151803,"If $f_k \to f$ a.e. and the $L^p$ norms converge, then $f_k \to f$ in $L^p$","Let $1\leq p < \infty$ . Suppose that $\{f_k, f\} \subset L^p$ (the domain here does not necessarily have to be finite), $f_k \to f$ almost everywhere, and $\|f_k\|_{L^p} \to \|f\|_{L^p}$ . Why is it the case that $$\|f_k - f\|_{L^p} \to 0?$$ A statement in the other direction (i.e. $\|f_k - f\|_{L^p} \to 0 \Rightarrow \|f_k\|_{L^p} \to \|f\|_{L^p}$ ) follows pretty easily and is the one that I've seen most of the time. I'm not how to show the result above though.","['functional-analysis', 'convergence-divergence', 'measure-theory', 'real-analysis', 'lp-spaces']"
1151817,Integrate $ \int_{0}^{\frac{\pi}{4}}\tan^{-1}\left(\frac{\sqrt{2}\cos3 \phi}{\left(2\cos 2 \phi+ 3\right)\sqrt{\cos 2 \phi}}\right)d\phi$,"Evaluate the integral: $$\displaystyle \int_{0}^{\frac{\pi}{4}}\tan^{-1}\left(\frac{\sqrt{2}\cos3 \phi}{\left(2\cos 2 \phi+ 3\right)\sqrt{\cos 2 \phi}}\right)d\phi$$ I have no clue on how to attack it.
The only thing I noticed is that there exists a symmetry around $\pi/8$, meaning that from $\pi/8$ to $\pi/4$ is the negative of zero to $\pi/4$. But, there exists a root of the integrand at $\pi/6$ and the limit of the integrand at $\pi/4$ is $-\infty$. Conjecture: The integral is $0$ for the reason of symmetry I mentioned above. However I cannot prove that. I would appreciate your help.","['improper-integrals', 'calculus', 'integration']"
1151897,How to find Green's function using Fourier-Bessel expansion,"The Green's function satisfies the non homogeneous Bessel equation can be written as
$xg''+g'+\left(k^2x-\frac{m^2}{x}\right)g=-\delta(x-\xi)$
where $m\geq0$ and an integer. The boundary conditions are
$\lim_{x\to 0}|g\left(x|\xi\right)|<\infty$, and $g\left(L|\xi\right)=0$. The Fourier-Bessel series representation of $g$ can be written as $g\left(x|\xi\right)=\sum_{n=1}^{\infty}G_n\left(\xi\right)J_m(k_{nm}x)$. Where $k_{nm}$ is the $n^{th}$ root of $J_m\left(k_{nm}x\right)$. Now if we substitute the second equation into the first one with the Fourier-Bessel representation of $\delta(x-\xi)$ then the $G_n(\xi)$ is expressed as $\left(k^2-k_{nm}^2\right)G_n(\xi)=-\frac{2k_{nm}^2J_m(k_{nm}\xi)}{L^2\left[J_{m+1}\left(k_{nm}L\right)\right]^2}$ How the last result is obtained after substitution? Please help to find it out.","['greens-function', 'ordinary-differential-equations', 'bessel-functions']"
1151914,How to derive this formula: $\int_a^bf(c-x)dx = \int_{c-b}^{c-a}f(x)dx$?,"I'm stuck in this exercise: $$\int_a^bf(c-x)dx = \int_{c-b}^{c-a}f(x)dx$$ My attempt is this: $$$$
\begin{align*}
\int_a^bf(c-x)dx
&= - \int_{-a}^{-b}f(x-c)dx\\
&= \int_{-b}^{-a}f(x-c)dx
\end{align*}
$$$$ But at this point I'm not sure what to do. To my understanding if one wants to integrate $f(x-c)$, which is shifted to the right, it would be the same as integrating $f(x)$ with the interval of integration shifted to the left: $$= \int_{-b-c}^{-a-c}f(x)dx$$ But that does not seem to be the right answer.","['definite-integrals', 'calculus', 'integration']"
1151955,A Theorem On Compact Connected Metric Spaces by Stadje,"I recently came across a surprising theorem, due to Wolfgang Stadje, a special case of which states that: Let $(X,d)$ be a compact connected metric space. Then there exists a unique real number $c$ such that for any positive integer $n$, and for any $x_1,\ldots,x_n\in X$, there exists $x\in X$ such that $$c=\frac{1}{n}\sum_{i=1}^n d(x,x_i)$$ The original proof of the general statement can be found here. This proof is unaccessible to me.
Since this proof was published in 1981, it is possible that simpler proofs have been found in subsequent years, especially for the special case mentioned above. I haven't been able to find any other proof on the internet though. Does anybody know a more accessible proof of the result mentioned above?","['general-topology', 'trigonometry', 'reference-request', 'alternative-proof', 'metric-spaces']"
1151962,"Looking for examples of an uncountable proper subgroup of $(\mathbb R,+)$ without using the concept of Hamel basis of $\mathbb R$ over $\mathbb Q$","Please give some examples of an uncountable proper subgroup of $(\mathbb R,+)$ that does not depend on Hamel basis of $\mathbb R$ over $\mathbb Q$ . Using Hamel basis this is easy as we can find an injective endomorphism $f$ on $(\mathbb R,+)$ which is not a surjection , so $f(\mathbb R) (\ne \mathbb R)$ which has the same cardinaltiy as $\mathbb R$ , is a subgroup  of $(\mathbb R,+)$ , but I don't want to use the concept of Hamel basis , Please help","['real-numbers', 'group-theory']"
1151974,Proving $11! + 1$ is prime,"Prove that: $$11! + 1$$ is a prime number.   Without computing the number (or factorial). Obviously, from Wilson's theorem, a number $n$ is prime if, $$(n-1)! + 1 \equiv 0 \pmod{n}$$ Since $n = 11! + 1 \in \mathbb{N}$, it is prime iff $$(11!)! + 1 \equiv 0 \pmod{11! + 1}$$ I have a problem here, how do I use Wilson's theorem with factorials? For a beginning, Multiples of 11: $$11, 22$$ $11! = 11*10*9...2*1 = 22*10!$ Next, $$(11!)! = (22*10!)! $$ I need help at this point..","['factorial', 'modular-arithmetic', 'elementary-number-theory', 'number-theory']"
1152984,Prove $717$ is not prime using Wilson's Theorem,"Prove that $717$ is not prime using Wilson's Theorem. Assume $717$ is prime then: $$716! \equiv -1 \pmod{717}$$ $$ 716 \cdot 715! \equiv -1 \mod{717}$$ $$ 716 \equiv -1 \pmod{717}$$ $$715! = 715 \cdot 714! \equiv -2 \cdot 714 \pmod{717}$$ Still, I dont feel I have enough to get a contradiction? Help?","['modular-arithmetic', 'elementary-number-theory', 'number-theory']"
1152991,Converse to Chinese Remainder Theorem,"So as seen on this question Converse of the Chinese Remainder Theorem , we know that if $(n,m) \neq 1$, then $\mathbb{Z} /mn \mathbb{Z} \ncong \mathbb{Z}/n\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z}$, because the right hand side does not have an element of order $nm$. But take a more general setting. Let $R$ be a commutative ring, and let $A,B$ be ideals in $R$. $A$ and $B$ are said to be comaximal if $A+B=R$. If $A, B$ are comaximal, then we have: $R/AB \cong R/A \times R/B$. In this setup, is the converse true? If we have $A, B$ ideals in $R$ such that $R/AB \cong R/A \times R/B$, do we always have that $A$ and $B$ are comaximal?","['ring-theory', 'chinese-remainder-theorem', 'abstract-algebra', 'commutative-algebra', 'ideals']"
1153068,"Proving $\sum_{n =1,3,5..}^{\infty }\frac{4k \ \sin^2\left(\frac{n}{k}\right)}{n^2}=\pi$","Proving $$\sum_{n =1,3,5..}^{\infty }\frac{4k  \sin^2\left(\frac{n}{k}\right)}{n^2}=\pi$$
  Where $k$ any number greater than $0$ I tried to prove it by using the Fourier series  but I couldnt find any form likes the above formula . Any helps. Thanks","['fourier-analysis', 'sequences-and-series']"
1153083,Integral $\int_0^\infty\sin{(x^4)} dx$,"Can anyone help with how to evaluate the following integral
$$
\int_0^\infty\sin{(x^4)} dx
$$
I know that I need to use the fact that $\int_0^\infty e^{-x^4}dx=\Gamma\left(\dfrac{5}{4}\right)$ and I know that I have to use Eulers formula and contour integration but I am really lost on how to start the problem.","['definite-integrals', 'calculus', 'integration', 'complex-analysis']"
1153107,Integral involving the error function of log(x),"Looking for a closed form for the integral $$\int_0^{\infty } e^{-\left(\frac{a-\log (x)}{b}\right)^2} \left(\frac{1}{2} \text{erf}\left(\frac{a-\log (x)}{b}\right)+\frac{1}{2}\right) \, \mathrm{d}x,$$
where erf is the error function $erf (z)=\frac{2}{\sqrt{\pi }}\int _0^ze^{-t^2}\mathrm{d}t.$ I've tried all manner of tricks, to no avail.","['calculus', 'special-functions', 'definite-integrals', 'real-analysis', 'error-function']"
1153131,Deriving an expression for $\cos^4 x + \sin^4 x$,"Derive the identity $\cos^4 x + \sin^4 x=\frac{1}{4} \cos (4x) +\frac{3}{4}$ I know $e^{i4x}=\cos (4x) + i \sin (4x)=(\cos x +i \sin x)^4$. Then I use the binomial theorem to expand this fourth power, and comparing real and imaginary parts, I conclude that $\cos^4 x + \sin^4 x = \cos (4x) + 6 \cos^2 (x) \sin^2 (x)$. So now I need to show that $\cos (4x) + 6 \cos^2 (x) \sin^2 (x)=\frac{1}{4} \cos (4x) +\frac{3}{4}$, which has stumped me.","['trigonometry', 'complex-numbers', 'complex-analysis']"
1153161,Every section of a measurable set is measurable? (in the product sigma-algebra),"I'm studying measure theory, and I came across a theorem that says that, given two $\sigma$-finite measure spaces $\left(X,\mathcal M,\mu\right)$ and $\left(Y,\mathcal N,\nu\right)$, and a set $E\in \mathcal M\otimes\mathcal N$, the function $x\mapsto \nu\left(E_x\right)$ is measurable. The definition of the product-$\sigma$-algebra $\mathcal M\otimes\mathcal N$ is the $\sigma$-algebra generated by the rectangles $A\times B$ with $A\in\mathcal M$ and $B\in\mathcal N$. Also, the $x$-section $E_x$ is defined as $E_x=\left\{y\in Y:\left(x,y\right)\in E\right\}$. My problem is that I can't even convince myself that, given $E\in\mathcal M\otimes \mathcal N$, the sections $E_x$ are in $\mathcal N$ for all $x$. It looks like it has something to do with unitary sets being measurable (which shouldn't be necessary, I think), but I can't prove it even assuming that $\left\{x\right\}\in\mathcal M$ for all $x$.","['product-space', 'measure-theory']"
1153190,Complete the character table of group of order $21$,"You are given the incomplete character table of a group $G$ with order $21$ which has $5$ conjugacy classes, $C_1,\dots,C_5$, which have sizes $1,7,7,3,3$. $$ \begin{array}{|c|c|c|c|c|}
\hline
& C_1 & C_2 & C_3 & C_4 & C_5 \\ \hline
 &  & & & & \\ \hline
 &  &  && &  \\ \hline
\chi_2 & 1 & \zeta_3 & \zeta_3^2 & 1 & 1 \\ \hline
 &  &  & & &  \\ \hline
\chi_4 & 3 & 0 & 0 & \zeta_7+\zeta_7^2+\zeta_7^4 & \zeta_7^{-1}+\zeta_7^{-2}+\zeta_7^{-4} \\ \hline 
\end{array}
$$ Complete the character table. Im guessing that $\chi_0$ has to be the trivial representation so we get that $$ \begin{array}{|c|c|c|c|c|}
\hline
& C_1 & C_2 & C_3 & C_4 & C_5 \\ \hline
 \chi_0 & 1 &1 & 1& 1&1 \\ \hline
 & 1 &  && &  \\ \hline
\chi_2 & 1 & \zeta_3 & \zeta_3^2 & 1 & 1 \\ \hline
 & 3 &  & & &  \\ \hline
\chi_4 & 3 & 0 & 0 & \zeta_7+\zeta_7^2+\zeta_7^4 & \zeta_7^{-1}+\zeta_7^{-2}+\zeta_7^{-4} \\ \hline 
\end{array}
$$ and as $21=1+1+1+9+9$. Im sure you have to obtain something from the fact we have 3rd and 7th roots of unity which correspond to the sizes of the conjugacy classes but I cannot see what I am meant to glimmer from this. Hints only please.","['representation-theory', 'group-theory', 'characters']"
1153199,Prove polynomial has at least $n-1$ distinc real roots,Let $W(x)$ be a polynomial with $n$ distinct real roots. Prove for any $k \in \mathbb{R}$ polynomial $P(x)=k\cdot W(x) + W'(x)$ has at least $n-1$ distinct real roots. I know how to show it for $k=0$ then it follow from roll theorem but show it for $k \neq 0$ ?,"['calculus', 'derivatives']"
1153223,Has this subset-sum game been studied?,"Consider the following game: two players, Yolanda (who always goes first) and Zachary, take turns selecting (not yet chosen) numbers between $1$ and $9$.  The first player who can make three of their selected numbers sum to $15$ wins.  This is well-known to be isomorphic to Tic-Tac-Toe (and so in particular, the game is a draw with best play) by mapping numbers to their locations in the $3\times 3$ magic square:
$$
\begin{array}{c|c|c}
8 & 1 & 6 \\
\hline
3 & 5 & 7 \\
\hline
4 & 9 & 2 \\
\end{array}
$$
Thus, for instance, Yolanda can ensure at least a draw by choosing $5$; and if Zachary replies with some other odd number (say, $7$) then she can win — in this particular instance, by choosing $6$ (forcing Zachary to 'block' with $4$) and then picking $1$ (winning next turn with either $\{1,6,8\}$ or $\{1,5,9\}$).  Of course, if Zachary responds to Yolanda's first move of $5$ with any of the even numbers (i.e., the corner squares) then he can draw. On the other hand, the analogous game where the players choose numbers between $1$ and $10$ (still trying to find a subset of three numbers which sum to $15$) becomes a first-player win: Yolanda can start by choosing $2$, and then choose either $3$ or $5$ based on Zachary's first move.  For instance, if Zachary replies by picking $5$, then Yolanda picks $3$; now Zachary has to pick $10$ to keep her from winning immediately, and Yolanda can choose $4$, winning next move with one of $\{3,4,8\}$ or $\{2,4,9\}$. What I'm wondering is if the generalized version of this game has been studied at all: let two players alternate choosing numbers from $\{1\ldots m\}$ with the goal being to select a subset of size $d$ summing to $N$.  Then there are a lot of natural questions that can be asked: (a) Is there a characterization (even partial) of which particular values $(d,m,N)$ lead to a win for the first player? (b) More particularly: is the game monotonic in $m$?  That is, if the $(d,m_0,N)$ game is a first-player win, is $(d,m,N)$ a first-player win for all $m\geq m_0$?  The usual strategy-stealing arguments show that the game must be either a draw or a first-player win with perfect play (since having an extra number in your 'bin' is never a down side), but at least at first glance it's not clear that a winning strategy on $\{1\ldots m\}$ can't be invalidated back to a draw by the existence of additional counter options when $m$ increases. (c) Is it even the case that for every $d\gt2$ there are some $m$ and $N$ with the $(d,m,N)$ game a first-player win?  (A trivial pairing argument shows that this can never be true for $d=2$.)  It seems like there may be Ramsey arguments here, but I haven't proved it yet. I've skimmed my various CGT references and haven't found anything about this game so far; any pointers would be greatly appreciated.","['combinatorial-game-theory', 'reference-request', 'combinatorics']"
1153260,Question in relation to completing the square,"In description of ""completing the square"" at http://www.purplemath.com/modules/sqrquad.htm the following is given : I'm having difficulty understanding the third part of the transformation. Where is
$ -\frac{1}{4}$ derived from $-\frac{1}{2}$ ? Why is $ -\frac {1}{4}$ squared to obtain $ \frac {1}{16}$ ?",['algebra-precalculus']
1153270,Cannonical evaluation map,"Let $C$ be a curve over $\mathbb{C}$, and $E$ be a vector bundle on $C$ such
that $H^0 (C, E) \neq 0$. Everyone talks of the evaluation map 
$H^0 (C, E)\otimes O_C\longrightarrow E$. What is this map exactly? It is generally described as $s\longrightarrow s_x$ that is restricting a global section to it's stalk. But what is the sheaf level map? Is it given by $H^0 (C, E)\otimes O_C(U)\longrightarrow E(U)$, sending $s\otimes t\mapsto t.s|_U$? Or does it mean taking as many copies of $O_C$ as there are global sections? I saw somewhere that if this map is surjective then $E$ is generated by global sections. How is that? Any help will be appreciated! Thanks!","['algebraic-geometry', 'vector-bundles']"
1153278,Graph theory application of homology,"I am struggling with the idea of local homology groups and would like to see an example of how to go about finding them in general. I'm thinking of the most trivial case to apply the theory of local homology to try and understand how it can be applied to more complex topological spaces. In the most trivial case, if I view a graph as a 1 dimensional delta complex, and take each vertex as a point $x \in X$, then defining the local homology as $H_n(X, X $ \ $ \{x\})$, how would I find the local homology of a graph as $x$ varies in $X$? Thanks in advance for the help","['applications', 'general-topology', 'homology-cohomology', 'algebraic-topology', 'graph-theory']"
1153299,"If $A,B$ are square matrices and $A^2=A,B^2=B,AB=BA$, then calculate $\det (A-B)$","If $A,B$ are square matrices and $A^2=A,B^2=B,AB=BA$, then calculate $\det (A-B)$. My solution: consider $(A-B)^3=A^3-3A^2B+3AB^2-B^3=A^3-B^3=A-B$, then $\det(A-B)=0\vee 1\vee -1$ The result of the book is the same as mine, but their solution is different. They begin: ""Since $A^2=A$ and $B^2=B$, $A$ and $B$ are diagonalizable; moreover, since $AB=BA$, then  there exists a invertible matrix $P$ such that $P^{-1}AP$ and $P^{-1}BP$ are diagonal matrices."" The statement has two parts, and I don't understand both. So I really need a specific explanation for those two parts. Thanks in advance.","['matrices', 'linear-algebra', 'diagonalization', 'determinant']"
1153358,Expected value of money left from a coin flipping game,"Say we were to play a game. We started off with \$100 and kept flipping a fair coin. If it turned out heads, we won \$1, else our money got inverted. For example, if on the first flip we got heads, then we'd have \$101. And if we got tails, we'd have \$0.01. What is the expected value of the money we have after N flips? One way to think about it is to use recursion, i.e. to find the recursive relation between f(n) and f(n-1), where f(n) is the expected money after n flips. Without too much effort we can find:
$$f(n) = \frac{1}{2}(f(n-1)+1) + \frac{1}{2f(n-1)}$$
However, if we use this relation, we'll have our money go down exponentially fast, which goes against common sense. For example, if we use the above relation, starting off with \$100, after 7 flips, we'll have around \$1. But a simple computer simulation shows it should be slightly above \$18. Can anyone help shed some light on this problem?","['markov-chains', 'recurrence-relations', 'probability']"
1153391,Derivative of a definite integral: $F(t) = \int_0^t \sqrt{1-x^8} dx$,"I'm preparing for my Calculus 1 exam and I've stumbled across the following exercise, which I am not able to solve. Any help will be appreciated. a) Find the domain and the derivative of the following function: $\displaystyle  F(t) = \int \limits_0^t \sqrt{1-x^8} dx $ . b) Find first three nonzero terms of the Maclaurin sequence that is equal to F(t).","['calculus', 'integration', 'definite-integrals', 'functions', 'derivatives']"
1153393,Does there exist a continuous and differentiable function which isn't smooth?,"As I understand, a smooth function is continuously differentiable. But if I have a function which is continuous AND differentiable, I cannot automatically say that it is smooth. For it has to be so for all its differentials. So I wonder, what function would be continuous and differentiable, but not continuously differentiable ? I cannot find the answer myself, as I do not clearly understand the difference between continuous AND differentiable, and continuously differentiable.... Context:
I ask this because of an arc length contest. The function has to be continuous and differentiable on [0,1]. But does this automatically mean that I may always use the formula for an arc length, which has the condition that the function is smooth... (or, in another book, that it has a continuous derivative)?","['calculus', 'examples-counterexamples', 'functions', 'continuity', 'derivatives']"
1153433,Function after d in integral,"How do you interpret this? $$\int[y-f(x, c)] \text{d}g(x,y)$$ I only saw things such as $\text{d}x\text{d}y$? But here a function ($g$) is after $\text{d}$. c is a constant.","['multivariable-calculus', 'calculus', 'integration', 'analysis']"
1153445,Find Formulas for $M^{n}$ of Matrix $M$,"Find formulas for the entries of $M^n$, where $n$ is a positive integer. $M$ is the following matrix:
$$
\begin{bmatrix}
4 & -2 \\
4 & 10
\end{bmatrix}
$$
So if $M=PDP^{-1}$ then it follows $M^n=PD^nP^{-1}$ where $P$ is made of the eigenvectors and $D$ is the diagonal of our eigenvalues (both of which were found starting with a char. polynomial). My results:
$$
D =
\begin{bmatrix}
8 & 0 \\
0 & 6
\end{bmatrix}
\qquad
P^{-1} =
\begin{bmatrix}
2 & 2 \\
-2 & -1
\end{bmatrix}
\qquad
P =
\begin{bmatrix}
-1/2 & -1 \\
1 & 1
\end{bmatrix}
$$
So I believe (unless I'm completely on the wrong track here) that I've found $M^n$, but I'm unsure now how to get this in an acceptable $2 \times 2$ matrix for $M^n$.","['matrices', 'linear-algebra']"
1153448,Express a Line as a Circle with infinite radius,"I have see a few proofs that, in some systems, a circle with infinite radius is a straight line. A nice example of this is stereographic projection in the complex plane. I have also see simple proofs where people make a circle converge to a vertical line. However this is slightly unsatisfying to me because division by zero is used. Would it be possible to have a circle converge to a non vertical line say: $$1)~~~~~~y = x$$. The equation for this should be: $$
2)~~~~~~~\lim\limits_{r \to \infty} [ (x - r/\sqrt{2})^2 + (y + r/\sqrt{2})^2 = r^2 ]
$$ I am having trouble solving this on my own. So my question is does equation 2 actually converge to equation 1 as $r \to \infty$? Or for that matter is this the right approach for trying to define the line $y = x$ as a circle with infinite radius?","['geometry', 'circles']"
1153458,"Expectation, variance and indicator variables","If we have three events $A_i$ with $i=1,2,3$ with probability $\frac{1}{5}, \frac{1}{4}, \frac{1}{3}$ respectively. Let $X$ be the number of these events that occur. Trying to write down a formula for $X$ in terms of indicators in order to find the expectation of $X$. Afterwards trying to find $\operatorname{Var}(X)$ if each event is disjoint (case 1), each event is independent (case 2), and $A_{1} \subseteq A_{2} \subseteq A_{3} $(case 3). Any suggestions of how to tackle this problem?","['probability', 'expectation']"
1153460,Proof of a fixed point theorem on the disk,"There is a very nice fixed point theorem which I'd have liked to give to my students : Let $n$, $m$ be two integers larger or equal to one. Let $B_n$ be the open unit ball in $\mathbb{R}^n$, and let $h$ be an homeomorphism of $B_n$ such that $h^m = id$. Then $h$ has a fixed point. However, it seems that there is no proof of this general result which does not involve material far beyond their current reach. I was trying to design a simpler proof in dimension $2$, with nothing more evolved that Brouwer's fixed point theorem, invariance of domain, and perhaps (some avatar of) Jordan's curve theorem. I was thinking along these lines : Take a large enough closed ball $C$ in $B_2$. Then $K := \bigcup_{k=0}^{m-1} h^k (C)$ is connected. Show that complementary of $K$ has one connected component $\Omega$ which borders the disk. Take $K' := \Omega^c$. Show that $K'$ is a $h$-invariant simply connected compact. Use a version of Brouwer's fixed point theorem. However, I have a hard time finding a suitable version of Brouwer's fixed point theorem. I could try to use Jordan-Schoenflies' theorem to conjugate the action of $h$ on $K'$ with the action of some homeomorphism of the closed unit disk, but then, I don't know much about the boundary of $K'$ (well, it is made of pieces of simple loops, but gluing them together seems messy). Is there a nice and relatively elementary (but maybe completely different) way of proving the result I want ? If there isn't, how can I frame the argument above and where can I find suitable versions of Brouwer or Jordan's theorems to make things as painless as possible ?","['general-topology', 'fixed-point-theorems']"
1153466,Find the range of the following function,Find the range of the following function: $$f(x)=\frac{x-1}{x^2-5x-6}$$ I know how to find the domain only Please provide an explanation. EDIT: Another question: find the range of $$f(x)=\frac{1}{(1-x)(5-x)}$$ How would we do that?,"['calculus', 'algebra-precalculus', 'functions']"
1153475,If a derivative $f^\prime$ is of bounded variation then prove that $f^\prime$ is continuous.,"I am having trouble with the following problem: Let $f:[a,b]\to \mathbb R$ be  differentiable on $[a,b]$ and $f^\prime$ is of bounded variation on $[a,b]$. Prove that $f^\prime$ is continuous on $[a,b]$. My guess is affirmative. I know that $f^\prime$ can be expressed as difference of two monotonic functions $f^\prime=g-h$ on $[a,b]$. Since $f^\prime$  satisfies intermediate value property (i.e. for any $\lambda$ such that $f^\prime(x)<\lambda<f^\prime(y)$ then there exists a $t$ in $[a,b]$ between $x$ and $y$ such that $f^\prime(t)=\lambda$). From this I am attempting to show that since $f^\prime=g-h$ and both of $g$ and $h$ are monotone, then $f^\prime$ will be continuous. But I do not make it. I have seen a nearly similar type of questions in the MSE but I find hard to address it. Let me know whether my guess is right and if so how to proceed further. Thanks for your attention.","['bounded-variation', 'real-analysis']"
1153487,Any hint for this measure theory problem from Halmos?,"I was reading Halmos book 'Measure Theory' and I'm really stuck with this one. Could anyone please give me a hint? Let $A\in\mathbb{R}$ be a Lebesgue measurable set and $D$ a dense subset of $A$. 
If $\mu(A\,\triangle\, A+d) = 0\;\;\forall d\in D$ where $\triangle$ denotes symmetric difference and $A+d$ is the set resulting of adding $d$ to each $a\in A$, 
it must be that $\mu(A) = 0$ or $\mu(A^c) = 0$. I've tried thinking of A as an open interval and then using properties of Lebesgue measure, also tried to apply Lebesgue Density Theorem, with no success.","['measure-theory', 'lebesgue-measure', 'real-analysis']"
1153499,Show $\ln2 = \sum_\limits{n=1}^\infty\frac1{n2^n}$,"Problem: Show that $$\ln2 = \sum_\limits{n=1}^\infty\frac1{n2^n}.$$ My progress: The problem before this one had me find the Taylor series for $\ln(1-x)$ which was $$-\sum\limits_{n=1}^\infty \frac{x^n}n$$ so I figured I'd use $x=-1$ and plug that into the Taylor series. However, there was a side note stating that the Taylor series I found is only valid for $x\in(-1, 1)$. And in any case, my calculation isn't going anywhere, since I end up with the series $1-\frac12+\frac13-\frac14\cdots$ Question 1: How can I use this to solve the problem stated initially, and in the title? Question 2: I can see why $x$ is restricted to be less than 1, to prevent taking the log of zero or a negative. Why is it not valid for x greater than 1?","['sequences-and-series', 'calculus', 'taylor-expansion']"
1153521,Are there restrictions I have forgotten for Integration by Trigonometric Substitution or am I making some other mistake?,"I have been playing around with some integration problems I had previously solved correctly.  I attempted an approach that was a bit different on one in particular, and I am getting what seems to be a slightly incorrect answer.  The original problems is: $$
\int \frac{x+2}{\sqrt{4-x^2}}\,dx \\[30pt]
$$ I previously solved the problem by splitting it up as:
$$
\int \frac{x}{\sqrt{4-x^2}}\,dx + 2\int \frac{1}{\sqrt{4-x^2}}\,dx \\[30pt]
$$ I ultimately found the correct answer to be: $$
2\cdot\sin^{-1}\Big(\frac{x}{2}\Big)-\sqrt{4-x^2}+C \\[30pt]
$$ What I tried next was to solve the problem using trigonometric substitution without splitting it up.  My work is as follows: $$
\int \frac {x+2}{\sqrt{4-x^2}}\,dx = \int \frac {x+2}{\sqrt{4(1-\frac{1}{4}x^2)}}\,dx = \frac{1}{2}\int\frac{x+2}{\sqrt{1-\frac{1}{4}x^2}}\,dx \\[30pt]
$$ Here I begin the trigonometric substitution with:
$$
\frac{1}{2}x=\sin(\theta)\implies x=2\cdot \sin(\theta); dx=2\cdot \cos(\theta)\,d\theta \\[30pt]
$$ Thus my work continues as follows: $$
\frac{1}{2}\int\frac{x+2}{\sqrt{1-\frac{1}{4}x^2}}\,dx = \frac{1}{2}\int\frac{(2\cdot\sin(\theta)+2)}{\sqrt{1-\sin^2(\theta)}}\cdot(2\cdot \cos(\theta))\,d\theta = \\[30pt] \frac{1}{2}\int\frac{(2\cdot\sin(\theta)+2)}{\sqrt{\cos^2(\theta)}}\cdot(2\cdot \cos(\theta))\,d\theta = \frac{1}{2}\int\frac{(2\cdot\sin(\theta)+2)}{\cos(\theta)}\cdot(2\cdot \cos(\theta))\,d\theta = \\[30pt] \int (2\cdot\sin(\theta)+2)\,d\theta = 2\int (\sin(\theta)+1)\,d\theta = 2(\theta-\cos(\theta))+C = \\[30pt] 2\theta - 2\cos(\theta)+C \\[30pt]
$$ Now solving for $\theta$ I get $\theta = \sin^{-1}\big(\frac{x}{2}\big)$ and solving with a right triangle I find that $\cos(\theta) = \sqrt{4-x^2} \\[30pt]$. Thus -- substituting back in for x -- the final answer would seem to be: $$
2\cdot \sin^{-1}\Big( \frac{x}{2}\Big)-2\sqrt{4-x^2}+C \\[30pt]
$$ But:
$$
2\cdot \sin^{-1}\Big( \frac{x}{2}\Big)-2\sqrt{4-x^2}+C \neq 2\cdot\sin^{-1}\Big(\frac{x}{2}\Big)-\sqrt{4-x^2}+C \\[30pt]
$$ So what am I missing?  Is there a rule necessitating that problems like this be split up before using trigonometric substitution?  Have I made an error somewhere in my calculations/algebra?","['trigonometry', 'calculus', 'integration', 'indefinite-integrals']"
1153528,Difference between homotopy equivalence and homeomorphism - dimensionality,"(The most voted answer to) This question shows spaces of the same dimension can be homotopy equivalent but no homeomorphic. On the other hand ""difference in dimension"" is still a nice way to tell apart homotopies from homeomorphisms. I'm not quite sure how to formulate my question precisely, but here goes: What is the essence of the idea behind the counterexample in the first
  answer
  to the linked question? (Please don't just say $\mathsf{Y}$ is a deformation
  retract of $\mathsf{X}$.) More generally, what kind of ""topological differences"" can homotopy
  equivalences ignore except dimension? Update: In light of Stefan Hamcke's comment ""I think most, if not all local properties can be ignored by homotopy equivalences"", I think this is the statement I should try and understand. Thus, I am asking for as-detailed-as-possible (yet formal) explanations of this sentence. Furthermore, since homotopy equivalences ignore local properties, how do plain homotopies behave with them? I'm guessing the same is no longer true, but why?","['general-topology', 'homotopy-theory']"
1153537,How to compute the trace of an exponential and diagonal matrix?,"I would like to understand how to compute the trace of an exponential and diagonal matrix. For instance, what is:
$$
\mathrm{Tr}\left[ \exp \begin{pmatrix} 5 & 0 \\ 0 & 8 \end{pmatrix}  \right] = \; ?
$$
I've tried to Google it, but couldn't find anything that answers this question.","['matrices', 'linear-algebra']"
1153572,$\lim_{n \to \infty} {\mathbb E}X_n$ for a coin flipping payoff problem,"Suppose we have a fair coin and we start with a base amount of money $X_0 = C \in {\mathbb N}$, and each time we flip the coin we have $X_{n+1} = X_n + 1$ if the flip is heads, otherwise $X_{n+1} = 1/X_n$ if tails. Can we compute $\lim_{n \to \infty} {\mathbb E}X_n$? It seems like the limit should exist and be finite. However coming up with a formula or recurrence relation for ${\mathbb E}X_n$ seems pretty daunting after some thought. However maybe the limit can be found and proved without that explicit formula? If the limit cannot be computed explicitly, can it be related to some other limit, and/or bounded with some good bounds, and/or proved for example to be irrational?",['probability']
1153576,Addition of two Binomial Distribution,"What is the distribution of the variable $X$ given $$ X = Y + Z, $$where $Y \sim $ Binomial($n$, $P_Y$) and $Z\sim$ Binomial($n$, $P_Z$)? For the special case, when $P_Y = P_Z = P$, I think that X~Binomial($2n$, $P$) is correct. If $P_A ≠ P_B$, the distribution might eventually just be Binomial$\left(2n, \frac{P_A + P_B}{2}\right)$ but I can't prove it. If the problem is more complicated than I expect and we can't derive the whole distribution, can we tell something about the mean and the variance of $X$?","['probability-theory', 'probability-distributions', 'probability', 'random-variables']"
1153578,"If $f$ is entire, $\forall x \in \mathbb{R} \hspace{2 mm}\exists n \in \mathbb{N}: f^{(n)}(x)=0 $ then $f$ is polynomial.","This was a question on a complex analysis exam: If $f:\mathbb{C} \rightarrow \mathbb{C}$ is entire, and $\forall x \in \mathbb{R} \hspace{2 mm}\exists n \in \mathbb{N}: f^{(n)}(x)=0 $ prove that $f$ is polynomial. Solution: Let $A_n= \{ x \in \mathbb{R}: f^{(n)}(x)=0\} $. Τhen each $A_n$ is closed and $\bigcup A_n = \mathbb{R} $, so by the Baire category theorem there must be a $k \in \mathbb{N} $ such that $ A_k $ has non-empty interior. That means there is an interval $(a, b) \subseteq A_k $. So $f^{(k)}(x)=0$ for $x \in (a,b)$. Since $f$ is entire so is $f^{(k)}$, therefore $f^{(κ)}\equiv 0$, so $f^{(n)} \equiv 0$ for $ n \ge k$ which means that $f$ a polynomial. Is the above proof correct? Is there a way to avoid using Baire theorem?","['proof-verification', 'complex-analysis']"
1153620,"Prove that for $f:A \to [0,\infty)$ if $\sum\limits_{a\in\mathbb A} f(a) < \infty$ then $\{a \in A\mid f(a) \neq0\}$ is at most countable.","Prove that for $$f:A \to [0,\infty)$$ if $$\sum\limits_{a\in\mathbb A} f(a) < \infty$$
 then $\{a \in A\mid f(a) \neq0\}$ is at most countable. I tried but i didn't conclude to anything.Any ideas for prove this?","['general-topology', 'fourier-analysis', 'elementary-set-theory']"
1153622,Finding points on the parabola at which normal line passes through it,"Hello guys I need help with the problem: Find the points on the parabola $y = x^2 - 4x + 3$ at which normal line passes through $(2, 0)$. What I did: I first took a derivative of the equation which equals to $2x - 4$. Then I have the equation $y - y_1 = (2x - 4)(x - x_1)$. $y$ is $2$ and $x$ is $0$ here. But I'm not sure how to find $y_1$ and $x_1$ here. I'm thinking that when I get the final equation, I can plug in $(2, 0)$ and get the points. Am I approaching this problem correctly? It seems like a simple problem, but it confuses me","['calculus', 'derivatives']"
1153653,"Find the domain of this function in the x,y,z graph","Find the domain of this function in set notation: $f(x,y)=\dfrac{\sqrt{x^2+y^2+4}}v$ $v=y-x$ Could I say that $x^2+y^2+4 \geq 0$ and $y-x \geq 0$ and based off those statements put that into set notation? and get: $D= \{(x,y)|x^2+y^2+4 \neq 0$ and $y-x \neq 0\}$","['multivariable-calculus', 'functions']"
1153655,Newton's method vs. gradient descent with exact line search,"tl;dr: When is gradient descent with exact line search preferred over Newton's method? I simply don't understand why exact line search is ever useful, and here's my reasoning. Let's say I have a function $f$ that I want to minimize. Gradient descent performs the updates: $$\vec{x} \gets \vec{x} - t \vec{\nabla}f(\vec{x})$$ The optimal step size $t$ must satisfy: $$\frac{d}{d t} f(\vec{x} - t\vec{h}) = 0$$ To solve this, I approximate $f$ with its Taylor polynomial: $$f(\vec{x} - t\vec{h}) \approx f(\vec{x}) - t\vec{h}^\top \vec{\nabla}f(\vec{x}) + \frac{t^2}{2}\vec{h}^\top \vec{\nabla}^2f(\vec{x})\ \vec{h} + \ldots$$ ...and then differentiate it with respect to $t$ and set it equal to $0$ : $$\frac{d}{d t} f(\vec{x} - t\vec{h}) \approx -\vec{h}^\top \vec{\nabla}f(\vec{x}) + t\vec{h}^\top \vec{\nabla}^2f(\vec{x})\ \vec{h} = 0$$ $$t = \frac{\vec{h}^\top \vec{\nabla}f(\vec{x})}{\vec{h}^\top \vec{\nabla}^2f(\vec{x})\ \vec{h}}$$ Since $\vec{h} = \vec{\nabla} f(\vec{x})$ , we have: $$t = \frac{\vec{\nabla}f(\vec{x})^\top \vec{\nabla}f(\vec{x})}{\vec{\nabla}f(\vec{x})^\top \vec{\nabla}^2f(\vec{x})\ \vec{\nabla}f(\vec{x})}$$ This is great, except that we can see that computing $t$ requires the Hessian $\vec{\nabla}^2f$ (expensive)! But if I could really compute the Hessian, then wouldn't I be using Newton's method instead? Why would I ever choose to do exact line search?","['optimization', 'convex-optimization', 'newton-raphson', 'derivatives']"
1153662,No Natural Group Structure on Conjugacy Classes,"Is it possible to show that there is no natural group structure on conjugacy classes in a group? Alternatively, for a path connected space $ X $, the set $ [S^1,X] $ of free (unpointed) homotopy classes of loops in $ X $ is in bijection with the set of conjugacy classes of $ \pi_1(X) $. Is it possible to show that this has no natural group structure?","['algebraic-topology', 'group-theory']"
1153689,What is the relationship between functional analysis and topology,"Could someone explain to me using examples and in layman's terms in which ways topology is related to functional analysis? After taking an UG course in point-set topology it felt like I had a taste of functional analysis; it seemed familiar and easy while I learnt it. If I could get some guidance referring to concrete mathematical examples, that would be helpful.","['general-topology', 'functional-analysis']"
1153708,Closer form for $\int_0^\infty\frac{(\arctan{x})^2\log^2({1+x^2})}{x^2}dx$,"I Would like to know the value of this integral. $$\int_0^\infty\frac{(\arctan{x})^2\log^2({1+x^2})}{x^2}dx$$
 I think
$$I=\frac{a}{b}(\pi^3\ln2)+\frac{c}{d}(\pi\ln^32)+\frac{e}{f}(\pi\ln^22)+\frac{g}{h}(\pi\ln2)+\frac{i}{j}(\pi^3)+\frac{k}{m}\zeta({3})??$$
Where a,b,c,d...are integers
Thanks.","['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
1153717,What is this property called for a function? $f(f(x))=f(x)$,"I am looking for a name for the following types of functions. Suppose that for function f , we have:
$$f(x)=y_x$$ and $$f(f(x))=y_x$$
Is there any name for this property?","['terminology', 'functions', 'function-and-relation-composition']"
1153775,How to determine cardinality of an infinite set using Aleph numbers?,"So I was reading a little bit about cardinal infinities, and I thought it was pretty interesting. However I wanted to know a little bit more about how to use them. For example, how would I determine the cardinality of the set of all real numbers? The one thing I know is that if it is countably infinite, then the cardinality is $\aleph_0$, and if it is uncountably infinite, then the cardinality is $\aleph_n$ ($n>0$). I understand the difference between countable infinity and uncountable infinity, so therefore the difference between between $\aleph_0$ and every other $\aleph$ number. But the problem is that I don't know the difference between any of the uncountable ones. What is the difference between $\aleph_2$ and $\aleph_3$? And how can I determine which $\aleph$ number is the cardinality given any uncountably infinite set?","['cardinals', 'elementary-set-theory']"
1153787,Why is the inverse of a sum of matrices not the sum of their inverses?,"Suppose $A + B$ is invertible, then is it true that $(A + B)^{-1} = A^{-1} + B^{-1}$? I know the answer is no, but don't get why.","['matrices', 'linear-algebra', 'inverse']"
1153810,What is the limit ${{\lim }_{x\to\infty}}x^\epsilon$ for an infinitesimal $\epsilon$?,"What is the limit $${{\lim }_{x\to\infty}}x^\epsilon$$ for an infinitesimal $\epsilon$? Does it give zero or infinity? Note that I'm considering the infinitesimals described in http://en.wikipedia.org/wiki/Smooth_infinitesimal_analysis EDIT: Since I was asked to show some of my own thoughts on the subject, I'd like to contribute the following: $$\lim_{x\to\infty} x^\epsilon = \lim_{x\to\infty} \exp(\log (x^\epsilon))= \lim_{x\to\infty} \exp(\epsilon\log(x))\\= \lim_{x\to\infty}(1+\epsilon\log(x))= \lim_{x\to\infty}(1+\epsilon)=1+\epsilon$$ Where we used a series expansion of $\exp(y)$ and the properties of infinitesimals $\epsilon^2=0$ and $a\epsilon=\epsilon$ for any number $a$. However, I am not sure if this is some sort of cheating my way around the limit at hand or not. Help would be appreciated!","['infinitesimals', 'limits']"
1153852,How to approach learning differentiation?,"I currently in my first semester of Single Variable Calculus. I did reasonably well in Algebra (A), Trigonometry (B+), and Pre-Calculus (B+). However, I'm having some difficulty learning to differentiate more complex functions. I remember formulas reasonably well, so I remember the various rules of differentiation: the power rule, the rule for finding derivatives of a sum/difference or constant multiple of a function, as well as the product, and quotient rules. I'm having more difficulty with the chain rule, though - I understand the basic formula: $$
\frac{df}{dx} = \frac{df}{du}\frac{du}{dx}
$$ But in practice, such as when trying to differentiate a complex function (like the one below), which involves using some or all of the differentiation rules in combination, I get bogged down in applying the rules correctly: i.e. in breaking the complex function into its constituent parts and applying the appropriate differentiation rules to them, in the context of the chain rule. $$
f(x) = \frac{3x^7+x^4\sqrt{2x^5+15x^\frac{4}{3}-23x+9}}{6x^2-4}
$$ With problems like this one (especially any differentiation problem that involves use of the quotient rule, and especially any problem requiring the use of a combination of the product, quotient, and/or chain rules), I have a lot of trouble keeping all the small, constituent functions straight and then combining the values of their derivatives correctly to arrive at the correct answer. Surely, I can't be the first person to have this trouble. So, my question is: is there any intuition, technique, or approach, aside from ""practice, practice, practice"" (which I am doing) that might help me here? I've tried using the Wolfram Alpha Calculus course assistant app to show me the differentiation steps when I get stuck, but it can be a bit hard to follow, for me. Sometimes it seems to use notation that is different from the notation my instructor uses in class.","['calculus', 'derivatives']"
1153876,Proving a ring in which $r^n=r$ for all $r$ is commutative.,Let $R$ be a ring with identity such that there is a positive integer $n\geq 2$ for which $r^n=r$ for all $r\in R$ . Prove $R$ is commutative. I had proven before that If $n=2$ it is commutative as follows: $r+s=(r+s)^2=r^2+rs+sr+r^2=r+rs+sr+s\implies 0=rs+sr\implies sr=-rs$ On the other hand $-r=(-1)r=(-1)^2r=r$ . So $sr=-rs=rs$ as desired. I seem to be stumped even with $n=3$ .,"['ring-theory', 'abstract-algebra']"
1153878,What is the gradient of a gradient?,"I'm a student, trying to re-derive a result found in a paper by calculating the following in spherical coordinates: $$\mathbf{I}+ \frac{\nabla\nabla}{\mathrm{constant}},$$ where $\mathbf{I}$ is a $3\times 3$ identity matrix. The paper that I've seen writes the result as \begin{bmatrix}
0 & 0 & 0\\ 
\cos(\Theta)\cos(\Phi) & \cos(\Theta)\sin(\Phi) & -\sin(\Theta)\\ 
-\sin(\Phi) & \cos(\Theta) & 0
\end{bmatrix} How do they get that? What is the gradient of a gradient in spherical coordinates? Is it a Hessian? Please see equations 11 and 13 of the following paper: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.369.921&rep=rep1&type=pdf","['multivariable-calculus', 'vector-analysis', 'vector-fields']"
1153889,Characterization of Extended Lucky Numbers,"The Lucky Numbers is a sieve where one starts out with the positive integers: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... and then eliminate every 2nd number: 1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 ... Since the next element to ""survive"" is 3, then eliminate every third element in the list: 1 3 7 9 13 15 19 21 25 27 31 33 37 39 43 ... and so on (the next step is removing every 7th element). The final numbers that are not removed are so called the ""lucky numbers."" I have an extension of these numbers: when we eliminate every $i$th number, do the same process $i$ times. For example, with our original list: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... we remove every 2nd number 2 times: 1 3 5 7 9 11 13 15 17 19 21 23 25 27 29 31 33 35 37 39 41 43 ... (1st time)
1 5 9 13 17 21 25 29 33 37 41 ... (2nd time) and so on (the next step involves removing every 5th element 5 times). Is there a characterization to the ""surviving"" numbers?","['elementary-number-theory', 'number-theory']"
1153910,Introduction to differential equations for pure mathematicians,"Is there a good reference for learning about differential equations for people who are mainly interested in the theoretical tools (especially in differential geometry/topology) that use them?  I learned very little about differential equations in undergrad (besides basic calculation techniques), but they seem to pop up frequently in things like Ricci flow and invariants coming from counting solutions to equations. I don't know how much material it would be, but if someone who knows a lot about their applications knows some reference for material about differential equations that they think any pure mathematician should know, I'd be interested in what that is.","['ordinary-differential-equations', 'reference-request', 'differential-geometry']"
1153920,$P \lor Q$ is Logically Equivalent to $P \land Q$?,"For some reason I somehow came up with the logical equivalence of $(P \land Q) \equiv (P \lor Q)$ and I was hoping someone could point out the error in my reasoning, as I can't seem to find out where I went wrong. I utilized various logical equivalences and this came out to be the answer. Below was my process: $(P \land Q) \equiv \lnot(P \to \lnot Q)$ $\lnot(P \to \lnot Q) \equiv \lnot P \to Q$ (Double Negation) $\lnot P \to Q \equiv P \lor Q$ I've been using Discrete Mathematics and Its Applications by Kenneth Rosen and according to the table of logical equivalences (pgs 24-25 if anyone has the 6th edition), everything seems to check out, but I already know $P \land Q$ and $P \lor Q$ aren't logically equivalent. But why is this happening? Please pardon my ignorance, I'm just terribly new at Discrete Structures.","['logic', 'discrete-mathematics']"
1153933,When do two matrices have the same exponential?,"Let $A$ and $B$ be $n\times n$ hermitean matrices.
When do we have $e^{iA}=e^{iB}$ ?
Can we somehow classify those pairs of matrices that have the same exponential? Here are some observations that I made: If $A$ and $B$ commute, then the condition is satisfied if and only if the spectrum of $A-B$ is contained in $2\pi\mathbb Z$ . (Both directions can fail if $A$ and $B$ don't commute, as the following two points show.) The condition $e^{iA}=e^{iB}$ can also be satisfied if $A$ and $B$ do not commute.
Take, for example, $A=2\pi\begin{pmatrix}1&0\\0&-1\end{pmatrix}$ and $B=2\pi\begin{pmatrix}0&1\\1&0\end{pmatrix}$ .
They do not commute but $e^{iA}=e^{iB}=I$ .
The spectrum of their difference is not in $2\pi\mathbb Z$ . If $A=\sqrt2\pi\begin{pmatrix}1&0\\0&-1\end{pmatrix}$ and $B=\sqrt2\pi\begin{pmatrix}0&1\\1&0\end{pmatrix}$ , then the eigenvalues of $A-B$ are $\pm2\pi$ but $e^{iA}\neq e^{iB}$ . The exponential map is not a homomorphism so finding the kernel is not enough; cf. the Baker–Campbell–Hausdorff formula . Having the same exponential is an equivalence relation.","['matrices', 'lie-algebras', 'lie-groups']"
1153949,"if $a,b$ are nilpotent elements of a commutative ring $R$, show that $a+b$ is also nilpotent","if $a,b$ are nilpotent elements of a commutative ring $R$, show $a+b$ is also nilpotent So then $a^n=0, b^m = 0, n,m \in \mathbb{Z}^+$ I know this is solvable using the binomial theorem but I would much rather solve it another way if possible. The answer using the binomial theorem isn't making the most sense at the present moment.",['abstract-algebra']
1153969,Find the unique solution to the IVP,"Find the unique solution to the IVP $t^3y'' + e^ty' + t^4y = 0$ $y(1) = 0$
$y'(1) = 0$ Any help would be great..I am lost on how to do this problem.. at first I was going to try to divide by $t^4$ but now I'm not sure.","['ordinary-differential-equations', 'calculus']"
1154005,"How can I write fun, cool, and challenging integration problems?","I just asked this question on another site but with only a handful of somewhat helpful responses. I just made the following integral problem which I think is very cool and nice, but I don't know how to solve it. (I found it by taking the derivative which is what you see here.) $\int \left(\frac{x^2-2}{x^3+6x} \right)^2 dx$. (I won't tell you the answer.) Once I had obtained this nice looking derivative and turned it into a nice looking integration problem I wanted to make more such problems, but the functions I was deriving didn't really seem to have challenging nor interesting derivatives. How can I come up with some fun integration problems (definite or indefinite)? I should also mention that my knowledge of calculus does not include complex analysis such as the Residues things or the contour theorems, only basic Calc 2 level stuff (eg. taylor series, integration by parts, integration tables from my physics textbook as I don't know where my calculus one is.)",['integration']
1154022,"How to show a relation is/isn't reflexive, transitive, or symmetric","I was tasked with this: Define a relation on Z by setting x R y if xy is even. (a) Give a counterexample to show that R is not reflexive. How do I go about proving this? Do I express this in terms of predicate logic or something and use laws and rules and the like to prove this? I think I have an idea of what I need to do, though I don't think I have a correct understanding. I would start by saying assume xy is odd. Then, by definition of odd, xy = 2k + 1, where k is any integer. From here on, I'm stuck. I know reflexivity involves something like x R x but I don't know how to apply that to this problem. Any help is appreciated, especially before 8am Eastern 2/18/15 when this homework is due.","['relations', 'equivalence-relations', 'discrete-mathematics']"
1154054,"a problem in Stein's book 'Real analysis', relate to continuum hypothesis.","The question is from chapter 2, problem 5 in Stein's book 'Real analysis': There is an ordering $≺$ of $\mathbb R$ with the property that for each $y\in\mathbb R$ the set $\{x\in\mathbb R : x ≺ y\}$ is at most countable.
  The existence of this ordering depends on the continuum hypothesis, which
  asserts: whenever $S$ is an infinite subset of $\mathbb R$, then either $S$ is countable, or $S$ has
  the cardinality of $\mathbb R$ (that is, can be mapped bijectively to $\mathbb R$.) [Hint: Let $≺$ denote a well-ordering of $\mathbb R$, and define the set $X$ by $X = \{y \in
\mathbb R \mid \{x \mid x ≺ y\} \text{ is not countable}\}$. If $X$ is empty we are done. Otherwise,
  consider the smallest element $y \in X$, and use the continuum hypothesis.] I cannot figure out how this hint will work?","['order-theory', 'elementary-set-theory', 'axioms', 'real-numbers', 'real-analysis']"
1154062,What is the angle of a line that is tangent to a circle and passes through an arbitrary point?,"I made this illustration to clarify the question: How would I find the angle of this line relative to the bottom line? If the boxes have length x instead of 1, what is the generic solution?","['geometry', 'trigonometry', 'circles']"
1154074,Closed 1-forms on Simply Connected Manifold,"Is it true that closed 1-forms on a simply connected differentiable manifold are exact. If so, could you explain why? Thanks very much","['differential-forms', 'differential-geometry']"
1154099,Determinant of a coherent sheaf over a smooth projective variety,"We know a coherent sheaf $E$ over a smooth projective variety $X$ admits a finite locally free resolution. 
$0\longrightarrow E_n\longrightarrow E_{n-1}\longrightarrow\cdots\longrightarrow E_0\longrightarrow E\longrightarrow 0$. So we define the determinant of $E$ to be $\textrm{det}(E)=\otimes\textrm{det}({E}_i)^{(-1)^i}$, this is a line bundle. My doubt is as follows : How do we know that this is independent of the choice of locally free resolution? Any clarification or reference would really help. Thanks in advance!","['homological-algebra', 'algebraic-geometry']"
