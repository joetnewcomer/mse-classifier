question_id,title,body,tags
3859708,"Show for any matrix $A$ with positive determinant, there is a continuous path in $GL_+(n,R)$ from $A$ to the identity.","Can someone please help me prove the following? Prove $GL_+(n,R)$ is path connected. That is, show that for any matrix $A$ with positive determinant, there is a continuous path in $GL_+(n,R)$ from $A$ to the identity. $\textbf{My idea:}$ Start with diagonal matrices, then upper/lower-triangular matrices, then arbitrary matrices.","['path-connected', 'smooth-manifolds', 'linear-algebra', 'manifolds', 'differential-geometry']"
3859723,Reason for repeated root while solving tangent and curve.,"I was solving a question from a book which is stated as: Let a tangent be drawn to $y=x^4-16x^2$ at $x = 1$ . I need to find all point of intersection between curve and the tangent. I started by finding equation of tangent. Using slope point form , equation of tangent: $y=-28x+13$ . Now equating $y$ of the line in the curve, I get a biquadratic equation in $x$ , which is: $x^4-16x^2+28x-13=0$ Now the solution in the book states that $x=1$ is a repeated root of the above equation,  since it satisfies both curve and the tangent. I don't understand this, by this logic won't we get a repeated root in every time when we solve equation of tangent and curve since the point of tangency satisfies both curve and tangent? Can anybody provide a better reason why do I get a repeated root?","['tangent-line', 'derivatives', 'roots']"
3859728,combinatorial proof that $\sum_{i=0}^n {n+i\choose i}\frac{1}{2^i} = 2^n$ [duplicate],"This question already has answers here : How to show $\sum_{k=0}^{n}\binom{n+k}{k}\frac{1}{2^k}=2^{n}$ (16 answers) Closed 3 years ago . Give a combinatorial proof that $\displaystyle\sum_{i=0}^n {n+i\choose i}\frac{1}{2^i} = 2^n$ . I'm not sure if Pascal's identity is useful here. Or perhaps there is a way involving binary strings? $2^n$ is the number of binary strings of length $n$ , so if there was some way to decompose these strings into disjoint sets $B_i$ with cardinality ${n+i\choose i}\frac{1}{2^i}$ , a proof using that method might work. ${n+i\choose i}$ is the number of binary strings of length $n+i$ with exactly $i$ ones, since one can choose $i$ of the $n+i$ positions to be ones in ${n+i\choose i}$ ways and make the rest zeroes in one way. Then we divide by the number of binary strings of length $i$ , though I'm not sure how to deduce the combinatorial significance of this. I'm most likely thinking of this the wrong way.","['elementary-set-theory', 'summation', 'combinatorics', 'combinatorial-proofs']"
3859763,Find all the triangles in a dissection of a decagon,"On page $97$ of Robin Wilson's ""Four Colors Suffice"", the following puzzle appears: [P]rove that, if all the angular points of a regular decagon are joined, and all the sides and diagonals produced indefinitely, the number of triangles so formed will be $10,000$ . It is stated that the puzzle, due to one James Maurice Wilson, is intended to ""require ingenuity rather than knowledge"" for it solution.  I haven't solved the problem, but I think I can proved that $10,000$ is too big. We have $5$ lines extending the diagonals, and $10$ lines extending the sides.  There are $5$ points ( $2$ red, $2$ gray, and $1$ white) on each of the former. There are $8$ points on each of the latter ( $2$ each colored green, red, blue, and gray.) There is $1$ white point, and $10$ points of each of the other four colors.  At most there is one triangle for every set of $3$ non-collinear points: $$\binom{41}3-10\binom83-5\binom53=10,050$$ Each green point is adjacent to red points, which are in turn adjacent to a common blue point.  The four points are the vertices of a kite-like figure, but if we choose any $3$ of them, there is no triangle, because the diagonals of the kite don't appear.  This eliminates $10\binom43=40$ triangles. Similarly, each of the red points is adjacent to two blue points and a gray point, forming a kite with one diagonal.  Two of the $4$ choices of $3$ these of these $4$ give a triangle, but the $2$ choices including both blue points do not.  This eliminates another $20$ triangles, so we're already below $10,000$ , and there are many other choices of $3$ non-collinear points that don't work either. Is the stated answer incorrect, or am I missing something?","['puzzle', 'combinatorics', 'geometry']"
3859767,How do I find the minimum and maximum of a multivariable function given two constraints?,"Find the minimum and maximum of $f(x, y, z) = y + 4z$ subject to two constraints, $3x + z = 5$ and $x^2 + y^2 = 1$ . Having a hard time figuring out how to do this problem. I think I'm doing it right but I can't seem to get the correct answer in exact terms. Here's what I got so far (the labels are respectively up and down is left to right so $g(x,y,z)=3x+z=5$ : $$f_x = g_xλ + h_x\delta$$ $$f_y = g_yλ + h_y\delta$$ $$f_z = g_zλ + h_z\delta$$ $$0 = (3)λ + (2x)\delta$$ $$1 = (0)λ + (2y)\delta$$ $$4 = (1)λ + (0)\delta$$ After doing the calculations I get $λ = 4$ . Now I solve for $x$ and $y$ by plugging in that value into the equations. I get: $$x=-\frac{6}{\delta}$$ $$y=\frac{1}{2\delta}$$ Then I plug it into $f(x,y,z)$ and get: $$\frac{6}{\delta}^2+\frac{1}{2\delta}^2=1$$ $$\delta = \frac{\sqrt{(145)}}{2}$$ So solving for $x$ and $y$ again: $$x=-\frac{-12}{\sqrt{145}}$$ $$y=\frac{1}{\sqrt{145}}$$ Then I solve for $z$ by using $g(x,y,z)$ : $$-\frac{-12}{\sqrt{145}}*3+z=5$$ $$z=5+\frac{36\sqrt{145}}{145}$$ So then my point is: $$(\frac{12}{\sqrt{145}},\frac{1}{\sqrt{145}},5+\frac{36\sqrt{145}}{145})$$ I plug this into $f(x,y,z)$ : $$f(x,y,z)=\frac{1}{\sqrt{145}}+4\left(5-\frac{36\sqrt{145}}{145}\right)$$ and get: $$f(x,y,z)=\sqrt{145}+20$$ And so I use the opposite point to get the other value (each value multiplied by -1): $$f(x,y,z)=-\frac{1}{\sqrt{145}}+4\left(5-\frac{36\sqrt{145}}{145}\right)$$ $$f(x,y,z)=-\sqrt{145}+20\quad $$ So my final answers are: $$maximum = \sqrt{145}+20\quad$$ $$minimum = -\sqrt{145}+20\quad$$ Yet they're both wrong. I have no clue what's happening. I've checked my calculations a lot of times. I must be missing steps somewhere. I don't know how to solve this problem. If you just want to provide a final answer that'll at least help me back track. Thank you.","['lagrange-multiplier', 'multivariable-calculus', 'calculus', 'partial-derivative', 'derivatives']"
3859768,Lie algebra $\mathfrak{sl}_2 \mathbb{C}$ has only these two real forms $\mathfrak{sl}_2 \mathbb{R}$ and $\mathfrak{su}_2$?,"A Lie algebra is a vector space $\mathfrak{g}$ over some field $F$ together with a binary operation $$\mathfrak{g}\times\mathfrak{g}\to\mathfrak{g}$$ called the Lie bracket satisfying the following axioms: Bilinearity, Alternativity, Jacobi identity, Anticommutativity. (Correct me if I am wrong)* If the Lie algebra over the field $F$ is a complex number, we have a complex Lie algebra. If the Lie algebra over the field $F$ is a real number, we have a real Lie algebra. Given a complex Lie algebra $\mathfrak g$ , a real Lie algebra $\mathfrak{g}_0$ is said to be a  real form of $\mathfrak g$ if the complexification $$\mathfrak{g}_0 \otimes_{\mathbb{R}} \mathbb{C} \simeq \mathfrak{g}$$ is isomorphic to $\mathfrak{g}$ . A real form need not be unique; for example, $$\mathfrak{sl}_2 \mathbb{C}$$ has two real forms $$\mathfrak{sl}_2 \mathbb{R}$$ and $$\mathfrak{su}_2.$$ **My question is that: how do we show $\mathfrak{sl}_2 \mathbb{C}$ has these and only these two real forms $\mathfrak{sl}_2 \mathbb{R}$ and $\mathfrak{su}_2$ ? ** Can you also explain the operation $\otimes_{\mathbb{R}}$ ?","['lie-algebras', 'representation-theory', 'abstract-algebra', 'lie-groups', 'differential-geometry']"
3859787,Spectral theory and Taylor expansion in quantum mechanics for unbounded operators,"I am reading spectral theory and quantum mechanics. We know that for an unbounded self-adjoint operator $A$ , operator-valued functions such as $\exp(iAt)$ , $t\in\mathbb{R}$ can be defined using spectral theorems. It seems to me that there does not exist a Taylor expansion for the exponentiation here i.e. we cannot write \begin{equation}
 \exp(iAt) = \sum_n \frac{(iAt)^n}{n!}.
\end{equation} However, in quantum mechanics, people always consider the case of Taylor expanding to obtain a perturbation theory. How is perturbation theory consistent with the spectral theory? Take, for example, the following simple (1+1)D Schrodinger Hamiltonian: \begin{equation}
H = \frac{\hat{p}^2}{2m} + V(x) =: H_0 + V,
\end{equation} where $\hat{p} = - i \hbar \partial_x$ and some (unbounded) potential $V(x)$ . How could we justify the expansion of an $U$ -matrix: \begin{equation}
 U(t) := \exp(i H_0 t /\hbar )\exp(-i H t / \hbar) \to \sum_n \frac{(iVt/\hbar)^n}{n!}, 
\end{equation} in general?","['quantum-mechanics', 'spectral-theory', 'functional-analysis']"
3859844,Why this inequality is correct,"Let $0<x_1\leq\dots\leq x_m<1$ , I denote $$a=\sum_{i=1}^mx_i,\qquad b=\sum_{i=1}^m\frac{1}{x_i},\qquad c=\sum_{i=1}^m\frac{x_i}{1-x_i}.$$ Im trying to prove that $$(b-m)(c+1-\frac{c}{a})\geq m(m-1).$$ I did prove it for the case of $a\geq 1$ using the Cauchy-Schwartz inequality. I implement a simulation in Python to construct a counterexample but in vain.","['rearrangement-inequality', 'multivariable-calculus', 'summation', 'inequality']"
3859918,Prove that there exist $\mu>0$ and $\delta>0$ s.t. $|f(x)-f(y)|\geq \mu |x-y|$,"Assume that $\Omega$ is an open set in $R^m$ , $f \in C^1(\Omega,R^m)$ , $a\in \Omega$ . If $\det f'(a) \neq 0$ , prove that there exist $\mu>0$ and $\delta>0$ s.t. for all $x,y \in B_{\delta}(a)$ , $|f(x)-f(y)|\geq \mu |x-y|$ . I can solve the situation when $m=1$ . W.L.O.G. assume that $f'(a)>0$ , then for $\epsilon = f'(a)/2$ , there exists $\delta>0$ s.t. $\forall \xi \in B_{\delta}(a)$ we have $|f'(\xi)-f'(a)|<\epsilon$ , hence $f'(\xi)>-\epsilon+f'(a)>0$ . then by Lagrange's theorem, for all $x,y\in B_{\delta}(a)$ , there exists $\xi =x+\theta(y-x)$ where $\theta \in [0,1]$ s.t. $|f(y)-f(x)|=|f'(\xi)(y-x)| \geq |-\epsilon+f'(a)|\cdot |y-x|$ . Hence $\mu=-\epsilon+f'(a)$ and $\delta$ would meet our requirement. But I have no idea how to deal with a higher dimensional space. Any help would be appreciated.","['continuity', 'multivariable-calculus', 'derivatives']"
3859945,"The set $F$ of all functions $f:\Bbb{N}\to \{0,1\}$ that are ""eventually zero"" is countable","Prove or disprove the set $F$ of all functions $f:\Bbb{N}\to \{0,1\}$ that are ''eventually zero'' is countable. For each $n\in \Bbb{N}$ , let $F_n = \{f: \Bbb{N}\to\{0, 1\}:f(i) = 0 \forall i > n\}$ . Then it is easy to see that $F_n$ is finite.
How to prove rigorously? function $f$ is eventually zero means $f(n)=0$ $\forall$ $n\geq N$ , $N\in \Bbb{N}$ . Define  a map $\psi: \Bbb{N} \to \{0,1\}^\Bbb{N}$ such that $\psi(i)=\{f(i):i\in\{0,2,...,n-1\}$ $\psi(i)=\{0:i\notin\{0,2,...,n-1\}$ . Does this map work?
Any help will be appreciated.",['elementary-set-theory']
3859978,$n$-fold convolution of a CDF with itself,"Problem: Suppose that $X_1,X_2,\dots$ are i.i.d. nonnegative integer-valued random variables with common CDF $F(x)$ . Assume that $F(0)<1$ and let $F^{(n)}$ denote th $n$ -fold
convolution of $F$ . (This is the convolution of $n$ copies of $F$ .) Show that $\displaystyle\sum_{n=1}^\infty F^{(n)}(x)$ is finite for all $x\geq0.$ We want to find random variables $Y_i$ which depend on $x$ such that $E\lbrack Y_i\rbrack=F^{(n)}(x)$ and then show that the sum of $Y_i$ 's is also a random variable with finite expectation. The issue we are having is that we are not sure that our understanding of the $n$ -fold convolution of $F$ with itself is correct. We think that $$F^{(n)}(x)=\int_{0}^{x}\cdots\int_{0}^{x}F(x-x_1-\cdots-x_n)F(x_1)F(x_2)\cdots F(x_n)\,dx_1\cdots dx_n.$$ From this, we think that the $Y_i$ 's should be $$Y_i(x_1)=\int_{0}^{x}\cdots\int_{0}^{x}F(x-x_1-\cdots-x_n)F(x_1)F(x_2)\cdots F(x_n)\,dx_2\cdots dx_n.$$ Could anyone help us clearing the smoke out in this problem? Thank you for your time and feedback.","['convolution', 'probability-distributions', 'probability-theory', 'probability']"
3860002,"Prove that if $f$ is differentiable at $c$ (i.e., $\lim_{x\to c} {f(x)-f(c)\over x-c}$ exists), then $f'(c) = \lim_{h\to 0}{f(c+h)-f(c)\over h}.$","Prove that if $f$ is differentiable at $c$ , then $f'(c) = \lim_{h\to 0}{f(c+h)-f(c)\over h}$ . I did this: If f is differentiable at $c$ , then it's continuous at $c$ , which implies, $\lim_{x\to c}$ $f(x)=f(c)$ if only if $\lim_{h\to 0}$ $f(c+h)-f(c)=0$ . Then dividing by $h$ , $$\lim_{h\to 0}{f(c+h)-f(c)\over h}=f'(c).$$ I don't know if this is correct, I feel it's kind of arbitrary. Edit: The definition of derivative is as follows-
If $f$ is differentiable at a point a then the following limit exists: $\lim_{x\to a} {f(x)-f(a)\over x-a}$ .","['calculus', 'derivatives', 'real-analysis']"
3860015,"Book recommendation for convergence (Almost Surely, probability, distribution) concepts in statistics.",I want to study the convergence concepts in statistics.   I am mainly interested in topics like Convergence in Probability Convergence in Distribution Almost Surely convergence I can't seem to find any good textbook or material that covers all the three topics in detail. Any recommendations on what books or what material may be helpful? Thanks!,"['statistics', 'probability-theory', 'book-recommendation', 'reference-request']"
3860073,"Does $L_1$ Convergence imply almost everywhere convergence for the Set of all increasing functions on $[0,1]$ to $[0,1]$?","We know that $L_1$ convergence does not imply convergence a.e. in general. However, consider the following set $$S=\{f:[0,1] \rightarrow [0,1]\mid f(x)\geq f(y) \quad \forall x\geq y\}.$$ Take any  sequence $\{f_n\}_1^\infty\subset S$ that is converging to $f$ with respect to $L_1$ norm.  Is it possible that convergence in $L_1$ implies pointwise a.e.  convergence in this case? I just couldn't  find an example to show this is not true.","['measure-theory', 'functional-analysis', 'real-analysis']"
3860103,Prime factoring $2^{22} + 1$ the sneaky way?,"As the title suggests, how to prime factorize $2^{22} + 1$ without any excessively long computation? There has got to be some trick here. I know that the expression can be factored as $$(2^2 + 1)(2^{20} - 2^{18} + 2^{16} - 2^{14} + \ldots - 2^2 + 1).$$ But not sure where to go from here.","['number-theory', 'factoring', 'elementary-number-theory']"
3860116,Inequality sign change with logarithm,"Why does the inequality sign change when applying a logarithm on both sides, with the base less than $1$ ? I came across the following math which I solved if 2 ways, $$
\left(\frac{1}{2}\right)^n < \frac{1}{4}\\
n\log\left(\frac{1}{2}\right)< \log\left(\frac{1}{4}\right)\\
-0.301n < -0.602 \\
n > 2
$$ The second method is, $$
\left(\frac{1}{2}\right)^n < \frac{1}{4}\\
n\log_\left(\frac{1}{2}\right) \left(\frac{1}{2}\right)< \log_\left(\frac{1}{2}\right) \left(\frac{1}{4}\right)\\
n < 2 \\
$$ Now I know the first one is the correct answer, but what I don't understand why the second method failed to give the correct inequality. Could someone please explain? Another general question would be, if instead of values they were variable, meaning instead if $\frac{1}{2}$ it was A , and instead of $\frac{1}{4}$ it was B , how would I attempt to solve it since, with the first method, I wouldn't know if $log\left(A\right)$ was negative or positive.","['algebra-precalculus', 'logarithms', 'inequality']"
3860121,How to construct line bundles of degree $g-1$ on smooth projective curve with no global section?,"Let $C$ be a smooth projective curve of genus $g$ , we know that for a general line bundle $\mathcal{L}$ of degree $g-1$ , $\mathcal{L}$ has no global sections, i.e. $\text{H}^0(C, \mathcal{L})=0$ . My question is that, in some particular case, for example, $C$ is a plane algebraic curve and I know the defining equation of $C$ , How can I explicitly find such a line bundle $\mathcal{L}$ ? By explicitly I mean to find points on $C$ and write down the divisor form of $\mathcal{L}$ . Or if I pick a divisor of $C$ randomly, for example, divisors of the form $D=p_1+\cdots + p_g-q$ , do I have a criterion to determine whether $\text{H}^0(C, \mathcal{O}_C(D))=0$ ?",['algebraic-geometry']
3860138,Evaluating $\sum _{k=1}^{\infty }\frac{H_k}{4^k\left(2k+1\right)}\binom{2k}{k}$.,"My attempt. $$\sum _{k=1}^{\infty }\frac{H_k}{4^k\left(2k+1\right)}\binom{2k}{k}$$ $$=\frac{1}{2}\sum _{k=1}^{\infty }\frac{H_k}{k\:4^k}\binom{2k}{k}-\frac{1}{2}\sum _{k=1}^{\infty }\frac{H_k}{k\:4^k\left(2k+1\right)}\binom{2k}{k}$$ The first sum can be evaluated easily if one uses the central binomial coefficient generating function , the closed form is $2\zeta \left(2\right)$ . For the remaining sum consider the $\arcsin$ series expansion. $$\sum _{k=0}^{\infty }\frac{x^{2k+1}}{4^k\left(2k+1\right)}\binom{2k}{k}=\arcsin \left(x\right)$$ $$\sum _{k=1}^{\infty }\frac{x^k}{4^k\left(2k+1\right)}\binom{2k}{k}=\frac{\arcsin \left(\sqrt{x}\right)}{\sqrt{x}}-1$$ $$-\sum _{k=1}^{\infty }\frac{1}{4^k\left(2k+1\right)}\binom{2k}{k}\int _0^1x^{k-1}\ln \left(1-x\right)\:dx=-\int _0^1\frac{\arcsin \left(\sqrt{x}\right)\ln \left(1-x\right)}{x\sqrt{x}}\:dx$$ $$+\int _0^1\frac{\ln \left(1-x\right)}{x}\:dx$$ $$\sum _{k=1}^{\infty }\frac{H_k}{k\:4^k\left(2k+1\right)}\binom{2k}{k}=-2\int _0^1\frac{\arcsin \left(x\right)\ln \left(1-x^2\right)}{x^2}\:dx-\zeta \left(2\right)$$ But I got stuck with: $$\int _0^1\frac{\arcsin \left(x\right)\ln \left(1-x^2\right)}{x^2}\:dx$$ Anything I try yields more complicated stuff, is there a way to calculate the main sum or the second one (or the integral) elegantly\in a simple manner?","['integration', 'definite-integrals', 'real-analysis', 'harmonic-numbers', 'sequences-and-series']"
3860202,"Prove that if $(G,\#)$ is a finite group and subset $A$, $|A|>|G|/2$ then any element of $G$ can be written as a combination of two elements of $A$.","Prove that if $(G,\#)$ is a finite group and subset $A$ , $|A| > |G|/2$ then any element of $G$ can be written as a combination of two elements of $A$ . Note that $A$ is not necessarily a subgroup.
If $|G|=n$ then $|A| > ⌊n/2⌋$ .
I know that at least (for $|A| = ⌊n/2⌋+1$ ) $A$ 's gonna have the identity element or an element with its inverse.","['group-theory', 'abstract-algebra', 'finite-groups']"
3860206,"Let $f(x)$ be a polynomial satisfying $\lim_{x\to \infty} \frac {x^4 f(x)}{x^8+1} =3$, $f(2)=5$, $f(3)=10$,$f(-1)=2$,$f(-6)=37$. Find $f(0)$","It’s clear that $f(x)$ is a 4th degree polynomial. If $f(x)=ax^4+bx^3+cx^2+dx+e$ , then $a=3$ From the rest of the given data, I can form four linear equations, which should give me the value of $a,b,c,d$ , but that’s far too tedious and time consuming, and I don’t think the question is meant to be solved that way. Is there any alternative method?","['limits', 'polynomials']"
3860250,How can I convolve $\mathrm{e}^{-\mid t \mid }$ by $\mathrm{e}^{-t^2}$,"I have to solve the following differential equation using Fourier Transform: $$ -f''(t) +f(t) = \mathrm{e}^{-t^2} $$ I will use the following convention for the Fourier Transform formula and the inversion formula : $$ F(\xi)=\int_{R}{f(t)\mathrm{e}^{-2i\pi\xi t}dt}  $$ $$ f(-t) = \int_{R}{F(\xi)\mathrm{e}^{-2i\pi\xi t}d\xi} $$ This is what I have: $$ -(2i\pi\xi)^2F(\xi) + F(\xi) = \mathscr{F}[\mathrm{e}^{-t^2}] \\
 F(\xi) = \frac{1}{1 + 4\pi^2 \xi^2} \mathscr{F}[\mathrm{e}^{-t^2}]$$ I noticed that $ \frac{1}{1 - 4\pi^2 \xi^2}$ is the Fourier transform of $\frac{1}{2}\mathrm{e}^{-\mid t \mid} $ . $$ f(-t) = \frac{1}{2}\mathrm{e}^{- \mid x \mid} *\mathrm{e}^{-x^2}\\
 f(-t) = \frac{1}{2}\int_{-\infty}^{+\infty}{\mathrm{e}^{-\mid t-x \mid}\mathrm{e}^{-x^2} dx}\\
 f(-t) = \frac{1}{2}\int_{-\infty}^{+\infty}{\mathrm{e}^{-x^2 -\mid t-x \mid} dx} \\
 f(t) = \frac{1}{2} \int_{-\infty}^{+\infty}{\mathrm{e}^{-x^2 -\mid -t-x \mid}dx} \\
 f(t) = \frac{1}{2} \int_{-\infty}^{+\infty}{\mathrm{e}^{-x^2 -(t+x)} dx} \\
 f(t) = \frac{1}{2} \mathrm{e}^{-t} \int_{-\infty}^{+\infty}{ \mathrm{e}^{-x^2 -x} dx}$$ I'm stuck here because I don't know how to integrate this function. Any tips to do it ?","['fourier-analysis', 'ordinary-differential-equations']"
3860258,"Given matrices $A$ and $B$, prove that $A^{n}-B^{n}=\frac{1}{2}(7^{n}-5^{n})(A-B)$","$$\text{Given}$$ $$A=\begin{pmatrix} 2 & 5 \\  -3 & 10 \end{pmatrix}$$ $$\text{and}$$ $$B=\begin{pmatrix} 3 & -2 \\  4 & 9 \end{pmatrix}$$ $$\text{prove that}$$ $$A^{n}-B^{n}=\frac{1}{2}(7^{n}-5^{n})(A-B) \  \forall n \in \mathbb{N}$$ The first thing that I tried was to look for a pattern for $A^n$ and $B^{n}$ , but, as I expected, I haven't been able to find any. Then I tried induction, and I think that I found a correct solution, but it is a very tedious one. Here's what I did: $$\text{Base case:}$$ $$p(1):A-B=\frac{1}{2}(7-5)(A-B) - true$$ $$\text{suppose true}$$ $$p(k): A^{k}-B^{k}=\frac{1}{2}(7^{k}-5^{k})(A-B)$$ $$\text{then we need to prove}$$ $$p(k+1): A^{k+1}-B^{k+1}=\frac{1}{2}(7^{k+1}-5^{k+1})(A-B)$$ Then I multiplied the equation from $p(k)$ by $B^k$ , and I subtracted it from the $p(k+1)$ equation to get rid of the $B^k$ . My idea was to try and isolate $A^k$ , and then prove by induction that the formula is, indeed correct, which would finish the proof. But as I said, this is a very tedious solution, and if someone could help me find a more intuitive and straight-forward one, I would appreciate that very much. Thanks!","['matrices', 'algebra-precalculus', 'matrix-equations']"
3860327,Shooting method on non-linear third ordered differential equation with boundary conditions.,"I know that how to apply the shooting method on first and second ordered non linear ordinary differential equations. I want to apply this method on third ordered case. I need the standard references for this problem. For example $f^{'''}+ff^{''}-f^{'2}=0$ with boundary condition $f(0)=0,\, f^{'}(0)=1,\,f^{'}(\infty)=0.$","['numerical-methods', 'ordinary-differential-equations']"
3860435,Can continued fraction of $\pi$ tile the plane?,"By continued fraction, I mean a simple (canonical) continued fraction. By ""tile the plane"": I actually am interested in infinite sequences of tillable rectangles. Continued fraction of $e$ can tile the plane Continued fraction of Euler's number $e=2.7182\dots$ is nice and regular $$[e]=[e_0;e_1,e_2,\dots]=[2;1,2,1,1,4,1,1,6,1,1,8,1,1,10\dots],$$ which is $[2; 1, 2,\dots]$ followed by blocks of three terms $[1,1,2k]$ for $k\ge 2$ . If we take a sequence of integer sided rectangles $r_0,r_1,r_2,\dots$ such that area of $r_i$ is equal to $e_i$ , can we tile the ""plane"" ? - where by ""plane"" , I mean ""one of the four quadrants"" . We start in the origin $(0,0)$ and WLOG look at the quadrant $(x\ge 0,y\le 0)$ . That is, we start at the top left corner, and continue our way down-and-right. Then, to tile the ""plane"" (given quadrant), we can continue following pattern indefinitely: That is, first observe $i=7$ where $r_0,r_1,\dots,r_i$ tile a $a_i\times b_i = 3\times 4$ rectangle. After this, every $6$ th value of $i$ works by adding $[1,4k,1,1,4k+2,1]$ area rectangles, extending the sides of the tiled rectangle $a_i,b_i$ by $2$ (i.e. $|a_i-b_i|=1$ is maintained). The above image uses the first $31$ terms $r_0,\dots,r_{30}$ . This was easy to find because the continued fraction of $e$ is nice and regular. Can continued fraction of $\pi$ tile the plane? Continued fraction of $\pi=3.1415\dots$ does not appear to have any obvious patterns $$\pi=[\pi_0;\pi_1,\pi_2,\dots]=[3; 7, 15, 1, 292, 1, 1, 1, 2, 1, 3, 1, 14, 2,\dots].$$ Notice that right off the bat, some larger values like $292=4\times 73$ start to appear. Can we solve the same problem for $\pi$ as we did for $e$ above, and do it ""regularly"" ? That is, Given $c\ge 0$ , do there exist infinitely many $i$ such that integer sided rectangles $r_0,r_1,\dots,r_i$ with areas $\pi_0,\pi_1,\dots,\pi_i$ , can tile a $a_i$ by $b_i$ rectangle, $|a_i-b_i|\le c$ , for some $a_i,b_i$ ? In the example of $e$ , we see that $c=1$ works. How small of a value of $c$ can we find, that works for $\pi$ ? Can we even find any $c$ value that works? There is some information about Pi Continued Fraction on mathworld , but I do not know if we can say enough about the terms of the continued fraction to draw conclusions about this problem. Can we somehow utilize the known upper bounds on the irrationality measure of $\pi$ , or any other known properties of this irrational transcendental number? If there is no hope in solving the problem, can we do any better if the "" integer sided "" rectangles condition is relaxed to "" rational sided "", or removed (i.e. a side can be a real number) ? Remark This question was inspired when I was trying to think of new visual representations of (approximations of) irrational numbers. If I haven't made any mistakes, then, for example, the following $81\times 8$ rectangle is tiled by integer rectangles of areas $\pi_0,\dots,\pi_{49}$ : As a bonus, the image was also made to have the following property: If you read the areas of rectangles in the image by starting in the upper left corner (red $1\times3$ rectangle) and continue visiting adjacent unvisited rectangles in the order of $8$ colors $\color{red}{R}\color{orange}{O}\color{yellow}{Y}\color{green}{G}\color{cyan}{C}\color{blue}{B}\color{purple}{P}\color{magenta}{M}$ (while preferring to visit the smaller area first if multiple choices are available), you can extract first $50$ terms of the continued fraction of $\pi$ . (If you have impaired color vision, you can use a tool like imagecolorpicker.com .) That is, the above image represents (encodes) about first $56$ decimal digits of $\pi$ . Thought: If we generalize this from rectangles to polyominoes (and use something like the color rule above to guide the decoding of the image), we can get creative with our images.","['number-theory', 'geometry', 'recreational-mathematics', 'continued-fractions', 'tiling']"
3860436,Recurrence formula of the MacMahon $q$-analog of the Catalan numbers,"Catalan number is defined by $C_{n}=\frac{1}{n+1}\binom{2n}{n}.$ Two natural $q$ -analogs of Catalan numbers are (see Carlitz and Scoville, A note on weighted sequences, Fibonacci Quarterly, 13 (1975), 303-306) $C_n(q)=\frac{1}{[n+1]_q}{2n\brack n}_q.$ $C_{n+1}(q)=\sum\limits_{k=0}^{n}q^kC_k(q)C_{n-k}(q).$ However definitions (1) and (2) are not equivalent. Is there any known recurrence relation like (2) in the literature that  (1) satisfies?","['catalan-numbers', 'combinatorial-proofs', 'q-analogs', 'combinatorics', 'sequences-and-series']"
3860463,Absolute value in trigonometric inequality $\left|\sin (2x)\right|\le \frac{\sqrt 2}2$,"I know how to solve trigonometric equations and inequalities but I don't understand how to solve trigonometric inequalities with absolute value. I find all the solution of the following inequality $$\left|\sin (2x)\right|\le \frac{\sqrt 2}2$$ but I don't know what is the final solution. I find $$( \frac{180}{8}, 3(\frac{180}{8}), 5(\frac{180}{8}), 7(\frac{180}{8}))$$ because I have to take $x$ that are between $[0,180]$ . But I don't know what to do from here.","['trigonometry', 'absolute-value']"
3860474,"Finding the equations of all lines tangent to the circle $x^2+y^2=2y$ and passing through $(0, 4)$","I can't figure out this question: Find the equations of all lines that are tangent to the circle $x^2 + y^2 = 2y$ and pass through the point $(0, 4)$ . Hint: The line $y = mx + 4$ is tangent to the circle if it intersects
the circle at only one point. Things I've tried: I've tried things from making a right angled triangle where $4$ is the hypotenuse, $\sqrt{2y}$ being $a^2$ or $b^2$ and try to solve for distance that way, then after trying to get the distance from $(0,4)$ to the unknown point of the tangent on the circle which I will call $(x,y)$ which yielded no results I've also tried to equate the gradients $m_1 m_2 = -1$ but after graphing this circle out I believe the center was not $(0,0)$ as the equation $x^2 + y^2 = 2y$ implied (even if it was $(0,0)$ I still can't figure it out). My graph of how the question might work","['algebra-precalculus', 'circles', 'geometry']"
3860489,show that the limits does not exist (multivariable),"So my professor give me this problem Show that the limit does not exist $$\lim_{(x,y) \to (0,0)} \frac {xy^3\cos x}{2x^2+y^6}$$ So what I ended up doing is approach $(0,0)$ along the $x$ -axis $$\lim_{x \to 0} \frac {0}{2x^2} = 0$$ and approach $(0,0)$ along the $y$ -axis $$\lim_{y \to 0} \frac {0}{y^6} = 0.$$ Then I approach the $(0,0)$ along $y = x$ axis $$\lim_{x \to 0} \frac {x^2\cos x}{2+x^4} = 0$$ And so I thought the limit does exist, but my professor insists that the limit does not exist. Did I do something wrong ? Thank you. *sorry i wrote the wrong problem","['limits', 'multivariable-calculus']"
3860559,Generalized Vandermonde-Matrix,"Let $z_1, \ldots, z_n \in \mathbb{C}\setminus\left\lbrace 0 \right\rbrace$ be distinct complex numbers, $\lambda_1 < \lambda_2 < \ldots < \lambda_n$ positive integers and define $$A = \left( z_i^{\lambda_k}\right)_{i,j = 1,\ldots, n} = 
\begin{pmatrix}
z_1^{\lambda_1} & z_1^{\lambda_2} & \cdots & z_1^{\lambda_n} \\
z_2^{\lambda_1} & z_2^{\lambda_2} & \cdots & z_2^{\lambda_n} \\
\vdots  & \vdots  & \ddots & \vdots  \\
z_n^{\lambda_1} & z_n^{\lambda_2} & \cdots & z_n^{\lambda_n} 
\end{pmatrix}.$$ Is it true that $A$ is invertible? I found this related question but it deals with finite fields where in my case the underlying field is the complex plane. If $\lambda_k = k -1 $ for $k = 1, \ldots, n$ , then $A$ is the well-known Vandermonde-Matrix, so in this case the answer is positive. I have tried to calculate the determinant of $A$ analogously to how it's done if $A$ is the Vandermonde-Matrix but without success. Does anyone have a reference or a proof which answers this question? Thanks in advance...","['matrices', 'determinant', 'complex-numbers']"
3860593,MacLaurin Series of $\tan(x)$,"I am trying to answer the following: Compute the MacLaurin series of $\tan(x)$ . I know this one is: $$\tan x=\sum_{n=1}^{\infty}\frac{(-1)^{n-1}2^{2n}(2^{2n}-1)B_{2n}x^{2n-1}}{(2n)!}$$ And I know how to derive this formula. Indeed I simply express $\tan$ as a linear combination of $\cot(x)$ and $\cot(2x)$ , for which we know the explicit formula $$\cot(x)=\sum_{n=0}^\infty \frac{(-1)^n2^{2n}B_{2n}x^{2n-1}}{(2n)!}$$ This formula is derived by writing $\cot$ in its exponential form and doing some algebra. I know how to derive these formulas, but I do not understand what makes it the MacLaurin series for $\tan(x)$ . Why couldn't they be any Taylor series centered somewhere else? And what even makes them a Taylor series, I only see it as a power series... Thank you for you responses and help!","['power-series', 'trigonometry', 'taylor-expansion']"
3860606,Variation of metric,"I am looking at the derivation of the Einstein field equations as the Euler-Lagrange equations of the Hilbert functional.
To do this one starts with a variation $$ g(t) = g+th $$ of the metric, where $h$ is a symmetric 2-covariant tensor.
For small $t$ , $g(t)$ will be invertible (if we interpret it as a matrix), so it makes sense to consider the components $g(t)^{ij}$ of the inverse. We have $$ 0 = \frac{d}{dt}\Big|_0 (g(t)_{ij} \, g(t)^{jk}) = h_{ij} g^{jk} + g_{ij}h^{jk} \quad\Rightarrow \quad h^{lk} = - g^{il} g^{jk} h_{ij}. $$ My question: What exactly do the coefficients $h^{lk}$ represent? I always thought that if one has a, say, 1-covariant tensor $A = A_i dx^i$ , then $A^i$ denote the components of the 1-contravariant tensor $A^\#$ (cf. musical isomorphisms ), given by $A^i = g^{ij}A_j$ . But in the formula for $h^{lk}$ above we also have a minus sign in front, so as far as I can see the coefficients $h^{lk}$ are not obtained by raising the indices of $h_{lk}$ . That being said, the metric is not really fixed in this case so the musical isomorphisms aren't either, which may be the source of confusion for me.","['tensors', 'euler-lagrange-equation', 'riemannian-geometry', 'differential-geometry']"
3860635,Find an invariant quantity,"All the vertices, except one (say $v$ ) of a $12$ -gon are marked $+1,$ and $v$ is marked $-1.$ At each step, we can choose $3$ adjacent vertices and change their signs. Is it possible to have every vertex marked $+1$ except for one adjacent to $v?$ I have tried to prove that it is impossible by searching invariant, and also tried to prove that it is possible, but didn’t succeed.","['contest-math', 'combinatorics']"
3860704,Sharply $k$-transitive actions on spheres,"A nice fact from complex analysis is that the mobius group acts sharply 3-transitively on the Riemann sphere. I am wondering if other sharply k-transitive (continuous) actions are known on any $S^n$ , and if it's possible to classify them (perhaps up to conjugation by a homeomorphism of the sphere). If $k=1$ , I believe this is the same as asking which spheres have a lie group structure, which just gives possibilities with $S^1$ and $S^3$ , but besides actions these and the mobius group example, I know no others fulfilling my criteria. edit: I believe real mobius transformations act sharply 3-transitively on the circle (real line with point at infinity) just like in the complex case, and I read here that there are not infinite sharply k-transitive groups for $k \ge 4$","['riemann-sphere', 'group-theory', 'group-actions', 'topological-groups']"
3860722,Writing Zeta Function In Terms Of The J-Function,"I am reading through John Derbyshire's ""Prime Obsession"" and am struggling to understand his argument for why $\frac{1}{s} \log{\zeta(s)}=\int_{0}^{\infty} J(x)x^{-s-1}dx$ where $J(x)$ is defined as $\pi(x)+\frac{1}{2}\pi(\sqrt{x})+\frac{1}{3}\pi(\sqrt[3]{x})+\frac{1}{4}\pi(\sqrt[4]{x})+\frac{1}{5}\pi(\sqrt[5]{x})+...$ Here is what I am getting so far: I know $\zeta(s)={ \prod_{p} \left(1-p^{-s}\right)^{-1}}$ . Taking the logarithm, $\log\left(\zeta(s)\right)=-\log(1-\frac{1}{2^s})-\log(1-\frac{1}{3^s})-\log(1-\frac{1}{5^s})+...$ Recall $S=\sum_{k=0}^{n-1}a\cdot r^k=\frac{1}{1-r}$ whenever $a=1$ and $r\in(-1,1)$ . Taking the integral, we have $\int{\frac{1}{1-r}}=\int{1+r+r^2+r^3+...}$ , and $-\log(1-r)=r+\frac{r^2}{2}+\frac{r^3}{3}+\frac{r^4}{4}+...$ . Then since $0 < \lvert \frac{1}{p^s} \rvert<1$ , we can write each term in Euler's product formula as an infinite sum. For example, $-\log(1-\frac{1}{2^s})=\frac{1}{2^s}+\left(\frac{1}{2}\cdot\left(\frac{1}{2^s}\right)^2\right)+\left(\frac{1}{3}\cdot\left(\frac{1}{2^s}\right)^3\right)+\left(\frac{1}{4}\cdot\left(\frac{1}{2^s}\right)^4\right)\dots$ Any term in this infinite sum of infinite sums can be written as an integral. For example, $\left(\frac{1}{3}\cdot\left(\frac{1}{2^s}\right)^3\right)=\frac{1}{3}\times\frac{1}{2^{3s}}=\frac{1}{3}\cdot{s}\cdot \int_{2^3}^{\infty}x^{-s-1}\: dx$ since $\int_{2^3}^{\infty} x^{-s-1}dx=\left(\frac{1}{s}\cdot\frac{-1}{x^s}\right)\biggr\rvert_{8}^{\infty}=\left(0\right)-\left(\frac{1}{s}\cdot\frac{-1}{8^s}\right)=\frac{1}{s}\times\frac{1}{8^s}$ which is precisely $\frac{s}{3}$ multiples of $\frac{1}{3}\times\frac{1}{2^{3s}}$ . This is where I am not following. Derbyshire says that this specific term forms a ""strip"" under the J-Function. Even though the J-Function is a step function, if you think of the integral as area under the curve, the example in the previous step should not be rectangular. Another point that I don't understand is why $\int_{0}^{\infty} J(x)x^{-s-1}dx=\left[\int_{2}^{\infty} \left(\frac{1}{1}\cdot x^{-s-1} dx\right)+\int_{2^2}^{\infty} \left(\frac{1}{2}\cdot x^{-s-1} dx\right)+\int_{2^3}^{\infty} \left(\frac{1}{3}\cdot x^{-s-1} dx\right)+...\right]+\left[\int_{3}^{\infty} \left(\frac{1}{1}\cdot x^{-s-1} dx\right)+\int_{3^2}^{\infty} \left(\frac{1}{2}\cdot x^{-s-1} dx\right)+\int_{3^3}^{\infty} \left(\frac{1}{3}\cdot x^{-s-1} dx\right)+...\right]+\left[\int_{5}^{\infty} \left(\frac{1}{1}\cdot x^{-s-1} dx\right)+\int_{5^2}^{\infty} \left(\frac{1}{2}\cdot x^{-s-1} dx\right)+\int_{5^3}^{\infty} \left(\frac{1}{3}\cdot x^{-s-1} dx\right)+...\right]+...$ . Any insights into this problem?","['riemann-zeta', 'number-theory', 'real-analysis']"
3860736,"What is the meaning of a monomorphism in $S/X$ being ""fiberwise""?","Notation : $S$ :the category of abstract sets; $S/X$ : the slice category of $S$ over a set $X$ ; $A_x$ : the fiber of a set $A$ over an element $x$ of the codomain of a function $A\rightarrow X$ . My question is the following: If $\alpha:f\rightarrow g$ is a monomorphism in $S/X$ , what does it mean for it to be ""fiberwise""? The question appears as exercise 2.43 in ""Sets for Mathematics"" by F.W. Lawvere and R. Rosebrugh and I have included it below for convenience's sake: An important case of slice categories (see Exercise 1.30(e)) is the category of X-indexed families of abstract sets $S/X$ . Recall that in $S/X$ objects are mappings with codomain $X$ and arrows are commutative triangles. The name “family” arises as follows: For any object $f:A\rightarrow X$ of $S/X$ and any element $x:1\rightarrow X$ the inverse image of $x$ along $f$ is a part of A denoted $A_x$ and is called the “fiber of $A$ over x”, A is the “sum” of the family of all its fibers. This is a very simple example of a variable set. Show that the category $S/X$ has binary sums that are computed “fiberwise”. Show that monomorphisms in $S/X$ are also “fiberwise” and
have characteristic morphisms taking values in the object $\Omega$ of $S/X$ ,
which has each fiber equal to $2$ . I understand that a monomorphism in $S/X$ precisely corresponds to an injective function that respects the fiber-structure induced on the domain by morphisms into $X$ . Further more, if $f:A'\rightarrow X$ and $g:A''\rightarrow X$ then given any element $x\in X$ , $$\alpha A'_x \subseteq A''_x$$ This implies that in order to specify a monomorphism in $S/X$ , it involves for each fiber $A'_x$ , choosing a 'part' of the fiber $A''_x$ . Is that a correct interpretation of the adjective ""fiberwise""?","['elementary-set-theory', 'slice-category', 'category-theory', 'terminology']"
3860744,Constants and superposition principle in PDEs,"Given this partial differential equation: $$ x \frac{\partial u}{\partial x} -\frac 12 y\frac { \partial u}{\partial y} = 0$$ I would like to first find the general solution and then apply the boundary condition: $u(1,y) = 1+ \sin y$ . I have used a separation of variables technique, and have gotten two ODE's : $$\frac 1X dX = \frac \lambda x dx$$ and $$\frac 1Y dY = \frac{2\lambda}y dy $$ So one solution will be: $u(x,y) = Cx^\lambda y^{2 \lambda} $ . I am confused when using the superposition which states that I can sum up all the solutions because lambda can take any value (even a complex number). I don't understand if this means I have to sum over lambda like so: $$u(x,y) = \sum C_{\lambda} x^\lambda y^{2\lambda } $$ or integrate because lambda is a technically a continuous variable: $$u(x,y) = \int_{-\infty}^{+\infty} C_{\lambda} x^\lambda y^{2\lambda } d \lambda$$ I feel like using the sum would be easier to solve the boundary condition problem as I could equate the summand to the summand in the Taylor series for $1+ \sin x $ . If the integral is the right way to proceed, how do I go about evaluating this integral, and how will I be able to solve the BCP from there?
Any help would be great.","['boundary-value-problem', 'ordinary-differential-equations', 'partial-differential-equations']"
3860759,Given $T = 75e^{-2t} $ then find $t$ as a function of $f(T)$,"First off, I'm sorry if some terms are wrong because I speak Spanish and I don't know how to translate them to English properly. I'm studying computation, and I have this problem from an integral calculus course, more specifically functions. Given $T = f(t) = 75e^{-2t}$ , find $f^{-1} (t)$ . Can anybody help me to understand how to solve this problem? Thanks in advance.","['algebra-precalculus', 'functions', 'logarithms']"
3860787,Is every plane in $\mathbb{R}^4$ a line in $\mathbb{C}^2$?,"Every complex line, that is, one-dimensional complex affine space, in $\mathbb{C}^2$ is a real plane in $\mathbb{R}^4$ . Is the converse true? That is, is every real plane in $\mathbb{R}^4$ a complex line in $\mathbb{C}^2$ ?","['almost-complex', 'linear-algebra', 'vector-spaces']"
3860913,Laplace equation with initial conditions,"So I have Laplace equation: $$ u_{xx}+u_{yy}= 0 $$ and initial conditions $$ u(0,y)=0, \;\: u_x(0,y)=y  $$ And I have to solve it. My solution: If we assume that the solution is of the form: $$ u(x,y)=X(x)Y(y) $$ Then follows: $$ u(0,y)=X(0)Y(y)=0; \:\; u_x(0,y)=X'(0)Y(y)=y.$$ Furthermore: $$ u_{xx}(x,y)=X''(x)Y(y); \:\; u_{yy}(x,y)=X(x)Y''(y) $$ From that, we get: $$ \begin{aligned}&\;u_{xx}+u_{yy}=X''(x)Y(y)+X(x)Y''(y)=0 \\ \\\Leftrightarrow& \; X''(x)Y(y)=-X(x)Y''(y)  \\\\
 \Leftrightarrow& \; -\frac{X(x)}{X''(x)}=\frac{Y(y)}{Y''(y)}  \end{aligned}$$ My problem: Every time I try to go further I get: $X(0)=0$ , which then implies, that $X'(0)=0$ , which furthermore is in contradiction with $X'(0)Y(y)=y$ This is a part where I didn't know where to go further, everything I try to insert doesn't end well and I am not sure, whether my approach was good at all. I would appreciate any kind of help!","['elliptic-equations', 'harmonic-functions', 'ordinary-differential-equations', 'partial-differential-equations']"
3860915,Probability of probability with certainty?,"Let $x$ be a uniformly distributed variable across the interval [0, 0.1], inclusive, where x represents the probability of a particular event occurring during a trial. If $528174$ trials occur, and in each of these trials the event does not occur, what is the smallest real $y$ so that that $x < y$ with at least $95%$ certainty?","['statistics', 'probability-theory', 'probability']"
3860966,Why Luzin's theorem can not be changed from $|\mathbb{R} \backslash B| < \epsilon$ to $|\mathbb{R} \backslash B| = 0$,"I am looking to prove the following however I am struggling. Any help would be appreciated. Thanks in advance. We let $G$ be an open set so that $\mathbb{Q} \subseteq G$ and $|G| < 1$ , and let $f : \mathbb{R} \rightarrow \mathbb{R}$ be given by $f = \chi_G$ . I am wanting to show that there is no Borel set $B$ with $|\mathbb{R} \backslash B| = 0$ so that $f|B$ is continuous.","['measure-theory', 'lebesgue-integral', 'outer-measure', 'real-analysis']"
3861001,counterexamples for preserves equalizer if and only if preserves pullback,"Assume $\mathcal{C}$ and $\mathcal{D}$ are two categories where finite products exist, then I have proved that if a functor $F: \mathcal{C}\rightarrow \mathcal{D}$ preserves finite products, then we have $F$ preserves equalizer if and only if $F$ preserves pullback diagram. Then I want to ask if this holds without the condition that $F$ preserves finite products. If the answer is no, I want to know the counterexamples for the “if” part and the ""only if "" part respectively. Thanks!","['algebraic-geometry', 'functors', 'category-theory']"
3861011,Let $n=p^mr$ where $p$ is prime and $r\in\mathbb{Z_{>1}}$ such that $p\nmid r$. If $G$ is a simple group of order $n$ then $p^m\mid(r-1)!$,"Question: Let $n=p^mr$ where $p$ is prime and $r\in\mathbb{Z^{>1}}$ such that $p\nmid r$ .  If $G$ is a simple group of order $n$ then $p^m\mid(r-1)!$ . My Ideas: I feel like this should be a rather straightforward argument but I keep getting tripped up.  Since $G$ is simple, the only normal subgroups of $G$ are $\langle1\rangle$ and $G$ . So, we have a homomorphism $\phi:G\rightarrow S_n$ , where $n=1$ or $n=p^mr$ . Since $G$ is simple, $\ker\phi=\langle1\rangle$ .  If $n=1$ , then we would violate the assumption that $r\in\mathbb{Z}_{>1}$ .  .....and I am sort of stuck from here... maybe this isn't the best way to go about it?  Any help is greatly appreciated!  Thank you","['simple-groups', 'group-theory', 'abstract-algebra']"
3861020,"Proof Verification: Bartle's ""Elements of Integration"" - Exercise 4.S","I had to solve this question for a group assignment, and my group is suspicious of my proof for this exercise. Can anyone help me confirm if this proof is correct? Bartle's Elements of Integration - Exercise 4.S: Let $f: X \to \mathbb{R}\cup\{-\infty, \infty\} = \overline{\mathbb{R}}$ be a non-negative measurable function, where $X$ is a measure space, such that $\int f d \mu < \infty$ . Then, for every $\varepsilon > 0$ , there exists a measurable set $E$ , with $\mu(E) < \infty$ , such that $\int f d \mu \leq \int_E f d \mu + \varepsilon$ . So here is my proof: Let $\varepsilon > 0$ . Then there is a simple function $\varphi$ such that $\int \varphi d \mu > \int f d \mu - \varepsilon$ and $\phi(x) \leq f(x)$ for each $x \in X$ (this follows from Bartle's definition of the integral). Let $\{a_1, \dots, a_n\}$ be the set of the distinct positive values $\varphi$ attains, and $E_i = \varphi^{-1}(a_i)$ . Then we can write $\varphi = \sum_{i=1}^{n}a_i \chi_{E_i}$ - where $\chi_A$ is the characteristic function of $A$ . For each $E_i$ , $\mu(E_i) < \infty$ , because $a_i \mu(E_i) \leq \int \phi d \mu \leq \int f d \mu < \infty $ , and $a_i \neq 0$ . Then $E = E_1 \cup \cdots \cup E_n$ is such that $\mu(E) < \infty$ and $\varphi \chi_E = \varphi$ . From this, we have that $\varphi(x) = \varphi(x) \chi_E(x) \leq f(x) \chi_E(x)$ . Thus: $$\int_Efd \mu = \int f \chi_E d \mu \geq \int \varphi d \mu > \int f d \mu - \varepsilon$$ And from this follows that $\int f d \mu < \int_E f d \mu + \varepsilon$ . Is this proof correct?","['measure-theory', 'solution-verification', 'lebesgue-integral']"
3861089,Least prime factor of $n$ is less than the least prime factor of $2^n-1$,"Let $O(n)$ be the least prime factor of $n$ and $O(1):=1$ . Prove that $O(n) < O(2^n-1)$ . In particular, $p<O(2^p-1)$ with a prime number $p$ . I tried it so much but failed. We can see that it is trivial if $n$ is even. The inequality also implies that the number of primes is infinite.","['number-theory', 'prime-factorization', 'prime-numbers']"
3861203,Using strong induction vs strong induction with a recurrence. How both differ,"How would I go about solving a strong induction problem with a recurrence? Does it still follow setting up a base case, inductive hypothesis and inductive step? For ex. how would I go about solving the following problem? Use strong induction to prove that $C(n)=2^n+3$ is a solution to the recurrence $C(0)=4$ , $C(1)=5$ , and $C(n)=3\cdot C(n-1)-2\cdot C(n-2)$ for all $n\in\mathbb{Z+}$ , $n>1$ . Thank you very much for the help. My work so far: Base case: For n=2 $C(2) = 3C(2-1)-2C(2-2)$ $C(2) = 3C(1) - 2C(0)$ Using the given C(0) =4 and C(1) =5 $C(2) = 7$ $C(2) = 2^2 + 3 = 7$ For the induction hypothesis: Assume $C(n)  2^n +3$ $n = 0, 1 ... k$ Induction Step: Prove for n = k+1 $C(k+1) = 3C(k+1-1) -2C(k+1-2)$ ....","['induction', 'discrete-mathematics']"
3861228,"Sum of integrals of $|g_i|<\infty$ implies $g_i$ converges to $0$, and there exists a set whose complement is zero","Problem : Suppose $(X, \mathcal{S}, \mu)$ is a measure space and $g_{1}, g_{2}, \ldots$ are $\mathcal{S}$ -measurable functions from $X$ to $\mathbf{R}$ such that $\sum_{j=1}^{\infty} \int\left|g_{j}\right| d \mu<\infty .$ Prove that there exists $D \in \mathcal{S}$ such that $\mu(X \backslash D)=0$ and $\lim _{k \rightarrow \infty} g_{k}(x)=0$ for every $x \in D$ Attempt : I know that if $g_j$ did not converge to zero, the sum of the integrals would be infinity, but how could I show this rigorously? As for the part involving the subset $D$ , I am a bit unsure how to approach this problem.","['measure-theory', 'lebesgue-integral', 'real-analysis']"
3861291,Limiting behavior of coins on a finite graph with flips activated by a full neighborhood,"Let $G = (V,E)$ be a finite graph, and as particular concrete examples, consider the case of a path or cycle graph. Say a configuration on $G$ is a function $f: V \to \{0, 1\}$ , which we can think of as coins located at each vertex, facing either tails or heads, respectively. Denote the configuration of $G$ at timestep $n$ by $f_n$ . The evolution from timestep $n$ to $n+1$ is given by the following rule: if all neighbors of a vertex $v$ are facing heads, then the coin at vertex $v$ is flipped (i.e., 50% chance of heads, 50% chance of tails) and $f_{n+1}(v)$ is set to be the result of this flip. For all other vertices $v$ , $f_{n+1}(v) = f_n (v)$ . Note that if at any point in the evolution, we have two adjacent vertices $v$ and $w$ such that $f(v) = f(w) = 0$ , then these two vertices will remain at tails forever. Thus, if $I_n$ denotes the proportion of vertices that are ""inactivated"" in this fashion at time $n$ , then $I_{n+1} \ge I_n$ for all $n$ and thus $L = \lim_{n\to\infty} I_n$ exists. Can we say anything explicit about the distribution of $L$ ? For the particular case of the path graph $P_k$ with $k$ vertices, when initializing all vertices as heads, numerical experiments suggest that $L$ is typically very close to about 0.34, irrespective of the length $k$ . The limiting configuration consists of islands of that perpetually flicker between 01110 and 01010, and stable blocks of the form 0110, 010, and 00. However, I haven't been able to calculate anything precise about the incidences of each of these block types. Any help would be very appreciated!","['graph-theory', 'probability-theory']"
3861304,Prove $∃x(∀y(\text{$5x+4y$ is even}))$,"I’m trying to solve this question but I’m not sure if I’m going correctly. I know it’s false, so I tried to prove it defining which is odd (2k + 1) and which is even (2k) . Then I started working on the numbers, considering x and y as even, which would result in an odd result. Am I on the right the path?","['elementary-number-theory', 'discrete-mathematics', 'quantifiers']"
3861311,Number of solutions of $\ln(|a-x|)=x$,"I don't want to duplicate this question: which is too similar to post it again but could you explain to me, how do we determine the number of root in the interval, using the derivative? I have tried substitution with: $$ y=a-x\\x=a-y~~for~x>0\\x=y-a~~for~x<0\\x>0\\f(y)=\ln(y)+y-a\\f'(y)=\frac{1}{y}+1\\f'(y)=0~~~y=-1\\\\f'(y)>0~~~y<-1\\\\f'(y)<0~~~y>-1\\min=0$$ Then I substitute: $$\ f(-1)=a+1$$ Thus $f(-1)=0$ for $a=1$ . Similarly I construct the answers for $x<0$ . However, how to determine the number of roots for every interval of a?","['derivatives', 'real-analysis']"
3861317,Optimal Strategy for Dice-10000 (Dice Game),"There exists a dice game known as Dice-10000 , with alternative names such as Dix Mille or 6-Dice The rules are simple, with each player taking turns rolling dice in order to achieve certain combinations to score points to reach the titular 10,000 points. Exact combinations can vary greatly, but here is an example ruleset: scoring table found on site linked earlier With each successive roll, dice are taken away until a roll is achieved which fail to score anything, in which case all points are lost for the temporary round, and play passes to the next player. A player may choose to stop rolling dice at any time and add their temporary points to their point total towards 10000. What would be a method of determining the optimal strategy for Dice-10000?
Moreover, what would be the optimal strategy for Dice-10000?","['game-theory', 'probability-theory', 'probability']"
3861372,"$A$ is nilpotent, then $I+\lambda A$ is invertible for any $\lambda \in \mathbb{R}$","I need help in this problem Let $A$ is a square real matrix such that $A^{n}=0$ for some positive integer $n .$ Such a matrix is called nilpotent. Show that if $A$ is nilpotent, then $I+\lambda A$ is invertible for any $\lambda \in \mathbb{R}$ I know that for $\lambda = 1$ it is true by $$\left(A+I\right)\left(I-A+A^2-...+(-1)^n A^{n-1}\right) = I +(-1)^{n-1} A^n = I$$ Thus proving that $A+I$ is invertible for any nilpotent $A$ . But I don't know if this is true for any $\lambda$ .","['matrices', 'nilpotence', 'linear-algebra', 'inverse']"
3861412,Is a minimal Gröbner Basis a minimal system of generators?,"I'm studying Gröbner Bases and I'm trying to show that every finitely generated graded module $M$ over $k[x_1,\ldots,x_n]$ has a minimal graded free resolution of length $l \leq n$ . (According to Exercise $5$ of Chapter 6 $\S$ 3 in Cox, Little & O'sheas $\textit{Using Algebraic Geometry 2nd ed.}$ pp. 272). The (graded) Hilbert Syzygy Theorem ensures that every such module has a (graded) free resolution of length $l \leq n$ . Theorem (Graded Hilbert Syzygy Theorem). Let $R = k[x_1,\ldots, x_n]$ . Then every finitely generated graded $R$ -module has a finite graded resolution of length at most $n$ . The proof is based on Schreyer's Theorem, which basically says that some relations $s_{ij}$ arising from the $S$ -vectors of the elements of a Gröbner basis $G = \{ g_1, \ldots, g_s\}$ form a Gröbner basis of the Syzygy module $Syz(G)$ . Like this, one can construct a (graded) free resolution $$ 0 \hookrightarrow F_l \xrightarrow{\phi_l} F_{l-1} \xrightarrow{\phi_{l-1}} \ldots \xrightarrow{\phi_{2}} F_1 \xrightarrow{\phi_{1}} F_0 \xrightarrow{} M \rightarrow 0, $$ by expanding the resolution with free modules $F_i$ and the surjective homomorphism $\phi_i: F_i \rightarrow F_{i-1}$ that takes the canonical basis elements of $F_i$ to the mentioned Gröbner bases elements of $ker (\phi_{i-1}) = Syz(G_{i-2}) \subset F_{i-1}$ . (This procedure will terminate after at most $n$ steps due to a result that says that each step, the leading terms of the Gröbner basis of $ Syz(G_{i-2})$ will contain at least one variable $x_i$ less.) Lemma. Let $G$ be a Gröbner basis for a submodule $M \subset R^t$ w.r.t. to an arbitrary monomial order, and arrange the elements of $G$ to form an ordered s-tuple $G = (g_1,\ldots,g_s)$ so that whenever $LT(g_i)$ and $LT(g_j)$ contain the same standard basis vector $e_k$ and $i < j$ , then $LM(g_i)/e_k >_{lex} LM(g_j)/e_k$ , where $>_{lex}$ is the $lex$ -order on $R$ with $x_1 >\ldots > x_n$ . If the variables $x_1,\ldots,x_m $ do not appear in the leading-terms of $G$ , then $x_1,\ldots,x_{m+1}$ do not appear in the leading terms of the $s_{ij} \in Syz(G)$ w.r.t. to the order $>_{G}$ induced by $G$ . $\textbf{The Problem:}$ The resolution constructed in this proof is generally not minimal i.e $\phi_i$ does not take the canonical basis elements of $F_i$ to a minimal system of generators of $ Im (\phi_i) =Syz(G_{i-2})$ . (Since it takes it to a Gröbner basis.) In the book, it says that one can construct a minimal resolution by always taking a minimal system of generators of $ker(\phi_{i-1})$ and then take the usual surjective homomorphism $\phi_i$ from the free module $F_i$ to this minimal set of generators . This principle should now be used to modify the proof above and show that a minimal free resolution of length $\leq n$ exists. $\textbf{My Question:} $ The proof (of the non-minimal case) above is based on Schreyer's theorem and constructing the resolution with Gröbner bases at each step.  To construct a minimal resolution I would need minimal systems of generators at each step. Are minimal (or reduced) Gröbner bases actually minimal system of generators such that this construction still works? If not, how would I need to use this to construct a minimal resolution of length $\leq n$ ? (Edit: A minimal Gröbner basis $G$ of $M$ is defined to be a Gröbner basis such that its leading terms are a minimal set of generators of the leading terms of $M$ .)","['groebner-basis', 'modules', 'algebraic-geometry', 'graded-modules', 'commutative-algebra']"
3861431,Question in a trigonometric equation.,"I tried it a lot but am not able to get this.Pls help in how should I think when solving this type of question and which side is better to try to simplify first (LHS or RHS).Please share the solution in that way. $$
\frac{1-\sin A}{1+\sin A} = 1 + 2 \tan A \left(\tan A - \sec A \right)
$$ One of the ways I tried but am not understand that how to simplify it in such a way that you get the RHS?",['trigonometry']
3861513,What is the probability that the coriander and basil are on the same side of the parsley?,"Jack has seven unlabelled seeds for different herbs (coriander, basil, parsley,
sage, thyme, oregano and mint). He plants the seeds in one row. What
is the probability that the coriander and basil are on the same side of the
parsley? I have looked at this and I'm wondering if the probabilities are the same based on the reasoning given?",['probability']
3861621,every eigenvalue of $T$ has only one corresponding eigenvector up to a scalar multiplication,"For a linear transformation $T$ on a vector space $V$ of dimension $n .$ Suppose it is given that for some vector $\mathbf{v},$ the vectors $\mathbf{v}, T(\mathbf{v}), T^{2}(\mathbf{v}), \ldots, T^{n-1}(\mathbf{v})$ are linearly independent, then is it true that every eigenvalue of $T$ has only one corresponding eigenvector up to a scalar multiplication.","['linear-algebra', 'linear-transformations', 'eigenvalues-eigenvectors']"
3861757,"The given matrix has three linearly independent eigenvectors, then $x+y=0$.","The question asked is  :: If the matrix $$
A=\left(\begin{array}{lll}
0 & 0 & 1 \\
x & 1 & y \\
1 & 0 & 0
\end{array}\right)
$$ has three linearly independent eigenvectors, then show that $x+y=0$ . solving for eigenvalues from the characteristic polynomial: $$\left|\begin{matrix}
0-\lambda & 0 & 1 \\
x & 1-\lambda & y \\
1 & 0 & 0-\lambda
\end{matrix}\right| =-λ^3+λ^2+λ-1$$ $$=-(λ-1)*(λ^2-1)=-(λ-1)*(λ-1)=-(λ-1)^2*(λ+1)$$ So eigenvalues are $λ_1=1$ and $λ_2=-1$ , Independent of the values of $x$ and $y$ . Now solving for eigenvectors I got $\left(\begin{matrix}
0 \\
1 \\
0
\end{matrix}\right)$ and $\left(\begin{matrix}
-1 \\
\frac{x-y}{2} \\
1
\end{matrix}\right)$ From here how to show that if there are three linearly independent eigenvectors, then show that $x+y=0$ .","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
3861839,Calculate the integral $\int_0^1 \sum_{r_n \leq x} 2^{-n} dx$,"Let $(r_n)_{n=1}^\infty$ be an enumeration of all rational numbers in interval $(0,1)$ . I want to calculate the integral $$ \int_0^1 f(x) dx = \int_0^1 \sum_{r_n \leq  x}\frac{1}{2^n}dx =  \int_0^1\sum_{n=1}^{\infty}\frac{1}{2^n}\chi_{(r_n  \leq x)}dx$$ I'm aware that both $2^{-n}$ and $\chi_{(r_n  \leq x)}$ are measurable, so $2^{-n} \chi_{(r_n <x)}$ is measurable aswell. Since both of them are bounded above on the interval $[0,1]$ , we can use Lebesgue's DCT. So my idea is that \begin{align}
\int_0^1\sum_{n=1}^{\infty}\frac{1}{2^n}\chi_{(r_n \leq x)}dx =& \int_0^1 \lim_{N \rightarrow \infty} \sum_{n=1}^{N}\frac{1}{2^n}\chi_{(r_n \leq x)}dx\\
&= \lim_{N \rightarrow \infty} \int_0^1 \sum_{n=1}^{N}\frac{1}{2^n}\chi_{(r_n \leq  x)}dx\\
&= \lim_{N \rightarrow \infty} \sum_{n=1}^{N} \int_0^1\frac{1}{2^n}\chi_{(r_n \leq  x)}dx\\
&= \lim_{N \rightarrow \infty} \sum_{n=1}^{N}\frac{1}{2^n} \int_0^1\chi_{(r_n \leq  x)}dx\\
\end{align} But I dont know how to compute the last integral. Appriciating all help I can get. Thank in advance. Edit : I accidently had [0,1] on first row when it should have been (0,1). Edit2 : I came up with the perhaps-solution that $$ \int_0^1\chi_{(r_n \leq x)}dx = \int_{r_n}^1dx = 1-r_n$$ since the integral depend on how the $r_n$ are chosen, but I'm not sure if this is correct... Edit3 : Realized I had written < when correct was $\leq$ .","['integration', 'measure-theory']"
3861840,How many groups of pentagonal flower bouquets can be formed?,"A florist has three types of flowers: tulips, roses, and daisies. There are 4 tulips, 5 roses, and 6 daisies. These 15 flowers are to be arranged into three bouquets of 5 flowers each. Assume that the order of the three bouquets is irrelevant, flowers of the same type are indistinguishable. How many groups of pentagonal bouquets can the florist bundle? Attempt Let us denote tulips, roses, and daisies with T, R, and D, respectively. If we form all 15-letter strings and add dashes after every five letters, we can obtain all possible groups of bouquets. For instance, one possibility would be $$\mathrm{TRRTR-TRDDD-DDTRD}.\tag{ex. 1}$$ There are $\dfrac{15!}{4!\ 5!\ 6!}$ such strings. While, of course, all groups of bouquets can be obtained this way, we are overcounting. For strings, $\mathrm{TRDDD-TRRTR-DDTRD}$ is different from the example above, yet it makes no difference for the group of bouquets since order was assumed to be irrelevant. It might be tempting to divide the number of strings by $3!$ but this would also be incorrect. As an example, $\mathrm{TDDDT-TDDDT-RRRRR}\tag{ex. 2}$ is a valid group of three bouquets that should instead be divided by $\dfrac{3!}{2!} = 3$ . So, one way to proceed is to divide all groups of bouquets into two non-intersecting classes. First those for which all groups of three bouquets are pairwise different, and then those with exactly two matching bouquets out of three. Note that forming groups with three identical bouquets is impossible because 4 tulips cannot be shared equally among three bouquets. Once partitioned in this manner, we may divide the first kind of partition with $3!$ , and the second with $3$ . However, such partitioning seems overly tedious, and is further complicated by the following aspect. We still have to consider that whenever there are at least two different kinds of flowers in a single bouquet, there is a further overcounting with the string-approach. Namely, e.g., the bouquets $$\mathrm{TRDDD\equiv DTRDD\equiv DDTRD\equiv DDDTR\equiv RDDDT}\tag{ex. 3}$$ are all equivalent since they can be transformed into one another by a rotation in space. (So a division with $5$ might additionally be in order for such bouquets). The 'further complication' is then the fact that groups of bouquets which initially seem to warrant division by $3!$ , actually require division with $3$ , as is the case for our first example. Indeed, by ex. 3 we have $\mathrm{TRDDD\equiv DDTRD}$ and so $$\mathrm{TRRTR-TRDDD-DDTRD\equiv TRRTR-TRDDD-TRDDD}$$ which should by divided by $3$ . Clarification from comments : bouquets which can be transformed into one another by reflection are not equivalent, and should be counted as different bouquets. Question The above discussion seems to lead into various subcases where mistakes could be easy to make, and is tedious to generalise. Is there cleaner approach? Regardless, an answer which carefully carries the above scheme to completion has value, too. For the record, the answer I obtain with the above method is $898$ . Edit: I have now also ""confirmed"" the answer $898$ with an independent Python program. Trying to find partitions of the multiset $\{\mathrm{T}:4, \mathrm{N}:5, \mathrm{D}:6\}$ into classes of size five is something that I admittedly have not thought much about, but on the face of it would lead to undercounting, since, for instance, the multiset $\{\mathrm{D, D, R, R, T}\}$ would not differentiate between non-equivalent bouquets $\mathrm{DDRRT}$ and $\mathrm{DTDRR}$ . (This question is from the context of introductory combinatorics without recurrences, generating functions and so on).","['set-partition', 'multisets', 'combinatorics', 'discrete-mathematics']"
3861903,Finding area ratios in triangle cut by circle,"This is another one of those problems that was a brain teaser, and I am curious about how to do this in a more elegant way. Given: I want to find the ratio of the blue area to the red one. Initially I had thought the way to do it was use the equation of a circle $x^{2}+y^{2} = 16$ (since we know the radius) and see where it intersects the line $y=\frac{3}{4}x+3$ (I know I could place the point A at the origin too, but I thought dispensing with the coordinates of the center of the circle would be simpler). Anyhow, the idea I had was to subtract the area under the triangle from the circle first, and then do he same with the whole triangle by just subtracting integrals with the limits at the intersection points. So, for the blue area, I would first find where point D is: $$x^2 +y^2 =16 \text{ and substituting } y = \frac{3}{4}x+3$$ $$(\frac{3}{4}x+3)^{2} + x^2 = 16 \rightarrow \frac{9}{16}x^{2}+\frac{9}{2}x+9+x^2=16$$ $$\frac{25}{16}x^{2} + \frac{9}{2}x +9 = 16 \rightarrow \frac{25}{16}x^{2} + \frac{9}{2}x -7 = 0$$ Which is a perfectly good quadratic and we can solve that and I get an intersection point of $(1.12,3.84)$ . Then I can integrate my circle within those limits, subtracting the triangle underneath (which would be described by the linear equation) $$\int_{-4}^{1.12}(16-x^2)^{1/2}dx-\int_{-4}^{1.12}\frac{3}{4}x+3dx $$ That first integral is ugly, and I have to say I am not sure how to approach it because I don't know the angle to the point D to set the limits for the trig substitution that I ordinarily might try. More to the point, what was bothering me was that there has to be a more elegant method for this. I suspect there is some geometric rule or procedure that I am missing here; I tried, for example, dropping a line segment OD which makes for an isosceles triangle AOD and then I could use the relevant formulas for the area of a circle segment. But here again I don't know the angle involved. I could certainly find the angles by, for example, making a line segment OD and knowing that the angle A is $\sin^{-1}(0.6)$ because the triangle is a 3-4-5. That angle would get me both angles AOD and COD, and I could use trig functions to derive the lengths of various triangle sides, which would enable me to find the areas I want. But there was something inelegant about these solutions as well, though if that's the way to do it then that's the way to do it. In any case I am curious what other folks came up with.","['integration', 'trigonometry', 'area', 'geometry']"
3861997,a coupling probability problem and random walk game,"There are 3 players and one dealer in a casino. The dealer chooses a player randomly( $p_1=\frac{1}{3}$ ). The chosen player tosses a coin( $p_2=\frac{1}{2}$ ). If the coin lands head, the chosen player will get 3 dollar, the dealer and the other two players will lose 1 dollar each. If the coin lands tail, the chosen player will lose 3 dollar, the dealer and the other two players will get 1 dollar each. This game repeats $n$ times. Let $x_{1n},x_{2n},x_{3n}$ be the total net profit(or loss) of players and let $y_n$ be the total net profit(or loss) of the dealer. Let $g(n)=prob(y_n>max(x_{in}) )$ For example, $g(1)=0, g(3)=\frac{1}{36}$ . Prove: $g(n)$ is increasing as odd number $n$ goes $n+2$ comments: By intuition, by central limit theorem, It seems that $x_i$ will goes $0$ more deeply than $y_i$ . However, the coupling structure makes this problem not easy.","['random-walk', 'probability-distributions', 'coupling', 'order-statistics', 'probability']"
3862031,Does the well ordering principle really implies mathematical induction?,"Under the Peano Axioms, I want to prove that if the Axiom of Induction is substituted with the well-ordering principle (every non-empty subset of $
\mathbb N$ has a minimum element), everything will be fine. That means I should prove that they are equivalent, as the proof can be found in various textbooks. However, I found a problem when proving that the well-ordering principle implies mathematical induction. The proof follows: Let $P(0)$ be true and $P(n)\implies P(n^+)$ . Suppose $A=\{x\in\mathbb N:P(x)\text{ is false.}\}$ is non-empty, then let $m$ be its least element. Since $P(0)$ is true, $m\neq 0$ . Therefore, there must be some $n$ such that $m=n^+$ . By definition of $m$ , $P(n)$ is true, but this implies $P(n^+)=P(m)$ is true, a contradiction. The statement in bold seems to be correct, but the Peano Axioms do not include it (every natural number is either 0 or a successor of a natural number). In fact, it's usually proven via mathematical induction, which we cannot use in the proof above. Question: How can this flaw be fixed, or they (AI and WOP) are simply not equivalent? Note: I found a paper claiming that they are not equivalent and most textbooks get it wrong. But I haven't read it. Link: https://link.springer.com/article/10.1007/s00283-019-09898-4","['peano-axioms', 'induction', 'natural-numbers', 'discrete-mathematics']"
3862053,"Let $X$ be a nonempty subset of a group $G$. If $X^2=X$ and $X$ is finite, then $X\le G$; a proof explanation.","This is a proof-explanation question concerning the proof of Theorem 3.18(ii) of Rose's ""A Course on Group Theory"" . The closest thing I could find via Approach0 is this , which does not answer my question. The Theorem: Paraphrased: Let $X$ be a nonempty subset of a group $G$ . If $X^2=X$ and $X$ is finite, then $X\le G$ . (Here $X^2=\{ab\mid a,b\in X\}$ .) The Problem Step in the Proof: Let $x\in X$ . Then $xX\subseteq X^2=X$ . Since $X$ is a finite set and $\;\color{red}{{\rm clearly }\; \lvert xX\rvert=\lvert X\rvert}$ , it follows that $xX=X$ . I don't understand why $$\lvert xX\rvert=\lvert X\rvert.$$ The rest of the proof is alright. I'll include it here for clarity and completeness. Therefore $x\in xX$ and so $x=xe$ for some $e\in X$ . But then, in $G$ , $1=x^{-1}x=e\in X$ . Now $1\in xX$ and so $1=xy$ for some $y\in X$ . Then, in $G$ , $x^{-1}=y\in X$ . Since also $X^2\subseteq X$ , this shows that $X\le G$ . Thoughts: Is the problem step a consequence of $xX\subseteq X^2=X$ by definition of $X^2$ , since $$xX=\{xs\mid s\in X\}?$$ How do I get the reverse inclusion? Plus, they need not be the same set, since that's what the sentence uses $\lvert xX\rvert=\lvert X\rvert$ to conclude. An idea I have is to establish a bijection between $xX$ and $X$ . This is more difficult than it looks at first, though, since, at this stage, at least a priori , it could be that $x^{-1}\notin X$ . Please help :)","['proof-explanation', 'group-theory']"
3862200,Double Integral with absolute value.,"I'm trying to get $$\int_0^2\int_0^{\sqrt{2x}}y^2|x-y|dydx.$$ I'm struggling with that absolute value. I'm not sure how to ""divide"" the integral into two. I know that $$|x-y|=\begin{cases} x-y &\text{ if }x\geq y, \\
y-x &\text{ if }x\leq y.\end{cases}$$ My problem is I have that $y=\sqrt{2x}$ in the top integral extreme.","['multivariable-calculus', 'multiple-integral', 'absolute-value']"
3862206,"Do elements $x^2$ and $y$ commute in group $G = \langle x,y \mid x^4, y^{10}, xyx^{-1}y^{-3} \rangle?$","Do elements $x^2$ and $y$ commute in group $$ G =\langle x,y \mid x^4, y^{10}, xyx^{-1}y^{-3} \rangle?$$ Here's what I could get $$\begin{align}
x^2y& = xxy\\
& = xy^3x \\
&= xyy^2x\\
& = y^3xy^2x \\
&= y^3xyyx \\
& = y^6xyx \\
&= y^9x^2.
\end{align}$$ Then $yx^2y = x^2$ . Now let's assume that $x^2y = yx^2$ , then $yx^2y = y^2x^2$ and I get that $y^2 = 1$ .  I think that $y^2 = 1$ is bad in this group. And that's where I am stuck. So what can I do next to prove that it is impossible?","['combinatorial-group-theory', 'group-presentation', 'group-theory']"
3862237,Let $\exists N\in\mathbb{R}:\forall x>N:A(x)$ for a statement $A(x)$. Do I need to define $x$ to be in $\mathbb{R}$ or is this already given by $x>N$?,"Let $\exists N \in\mathbb{R}:\forall x>N:A(x)$ for some statement $A(x)$ . Do I need to define $x$ to be in $\mathbb{R}$ or is this
already given by the fact that $x>N$ ?","['quantifiers', 'propositional-calculus', 'logic', 'discrete-mathematics']"
3862296,"Salvaging $A-B$ and $A+B$ invertible imply $A,B$ invertible, for $A,B\in \mathbb{C}^{n\times n}$","Recently, a professor posed the following question on a midterm: If $A,B\in \mathbb{C}^{n\times n}$ and $A-B$ , $A+B$ are invertible, prove that $A,B$ are invertible. The question was meant to be, 'prove or disprove', as taking $A=\begin{bmatrix}0 & 1 \\ 0 & 0\end{bmatrix}$ and $B=A^T$ provides a counterexample. But I'm left wondering if we could add some condition to make the statement true, maybe with information about the Gershgorin discs or the spectrum of the matrix? In short, my question is: is there a condition $\mathcal{C}$ such that if $A-B$ and $A+B$ are invertible and satisfy $\mathcal{C}$ , then $A$ and $B$ are invertible as well?","['gershgorin-sets', 'eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'inverse']"
3862352,What is a good category of tame topological spaces?,"While the definition of a topological space nicely encapsulates the notion of points being close to each other, it doesn't seem to be a good notion of space. It has quite some problems: Every definition comes with many different variations: There is a zoo of separation axioms . There are at least four versions of connectivity . There are many distinct notions of manifolds and other spaces patched up local models (like CW-complexes ). Often the definitions don't even seem to be standardized (see for example my question on closed neighborhood deformation retracts or find the ""right"" definition of locally compact space ). Those variations are necessary, as there are many pathological counterexamples (like for example the topologist's sine curve , the Warsaw circle or the Hawaiian earring in the context of connectivity). There are many unintuitive results (there are space filling curves , injective continuous maps are not embeddings, quotient maps are not open etc.). global $\not\Rightarrow$ local. (I find it confusing at best that being path connected does not imply being locally path connected...) The category $\mathsf{Top}$ is not cartesian closed. Phrased differently, the sets of maps between spaces do not carry a canonical topology in such a way that composition is continuous. (I am unsure about the set of maps having a topology being intuitive, but it is a very useful tool to have, especially when doing homotopy theory) Arguably it is good to have such a general setting many subjects in mathematics can build upon. What bothers me is that, as soon as one wants to do something geometric / homotopical, one has to restrict to certain topological spaces, dealing with a lot of additional assumptions to avoid those pathological exceptions. Moreover often the topological notions are not really the right ones, when working in a non-topological context (a scheme seldomly is hausdorff, it may be separated though, borrowing but not using topological intuition). So my question is What is a good category of tame topological spaces, in the sense that it is complete, (at least finitely) cocomplete and cartesian (or maybe monoidal) closed contains the prime examples of spaces like metric spaces, smooth manifolds, CW-complexes, polyhedra makes standard notions coincide (as much as possible) + avoids pathological counterexamples has a direct axiomatization (no ""Hausdorff spaces, which admit a neighborhood of locally compact opens with connected fibers thingy..."") I am aware of the possibility that this question may not have a satisfying answer. The fact that genius minds like Grothendieck noted ""The foundations of topology are inadequate is manifest in the form of false problems [..., which] include the existence of wild phenomena (space-filling curves, etc.) that add complications which are not essential"" ( On Grothendieck's Tame Topology, p.3 ) but not come up with a groundbreaking solution (I don't understand o-minimal structures yet, but they do not really look satisfying) leads me to think that the question might not even have one. However I feel like asking this question nonetheless will lead to insights of one kind or another... As always: thank you for your time and considerations. PS: The question feels vague, but I don't really know what to specify further. So any suggestions for making it more precise are very welcome...","['general-topology', 'foundations', 'geometry', 'algebraic-topology']"
3862440,Intuition for why a group can fail to have an automorphism sending a particular element to its inverse.,"It is known that there are groups $G$ containing an element $g$ which is not mapped to $g^{-1}$ by an automorphism of $G$ , but I find this counterintuitive; when I visualize the symmetries of some object in $\mathbb{R}^2$ or $\mathbb{R}^3$ , it seems evident to me that doing a rotation one way vs its inverse are performing the same ""role"" in the group, and hence should be mapped to each other by an automorphism. I'm also aware that every (finite) group can be viewed as the symmetries of some object in $\mathbb{R^n}$ Is there an example (ideally geometric) where my intuition can accept that this can happen? Doing a computation in some semi-direct product isn't satisfying to me.","['automorphism-group', 'group-theory', 'intuition']"
3863460,"Is there a universal property for homogeneous maps $ \phi(ax,ay) = a^k\phi(x,y) $?","Let $E,F$ and $G$ be vector spaces over the field $\Gamma$ and let $\phi:E\times F \to G$ be homogeneous map of degree $k \in \mathbb N$ , i.e., $$
\phi(ax,ay) = a^k\phi(x,y), \qquad \forall x \in E, y \in F a \in \Gamma
$$ Is there universal property for such maps ? i.e., is there a pair $(\odot,H)$ where $\odot$ is a homogeneous map of degree $k$ on $E\times F$ into $H$ (a vector space) such that for every homogeneous map (degree $k$ ) $\phi$ there is a linear $f$ such that $f\circ \odot = \phi$ ? My attempt: Let $C(E\times F)$ be the free vector space over the $E\times F$ and let the $N$ be the subspace generated by all elements of the form $$
(ax,ay) - a^k(x,y)
$$ Now consider the canonical projection $\pi:C(E\times F) \to C(E\times F)/N$ ,  then define the linear map $h:C(E\times F) \to G$ such that $h((x,y)) = \phi(x,y)$ . It can be shown that $N \subset \ker h$ . Then by the universal property of quotient maps there is a unique linear map $f:C(E\times F)/N \to G$ such that $f \circ \pi = h$ . If the restriction of $\pi$ to $E\times F$ is denoted $\odot$ , then this a homogeneous map of degree $k$ , and it follows that $f\circ\odot=\phi$ , and if $C(E\times F)/N$ is denoted $H$ then we have the pair $(\odot,H)$ . Please comment!, I would like to know whether there is any mistake, or if something like this universal property of homogeneous maps does exist at all. Thanks in advance! Added I have the following two comments on this construction: I . This construction can be carried out for homogeneous maps $\phi:V_1\times\cdots\times V_n \to W$ provided the subspace $N$ of $C(V_1\times\cdots\times V_n)$ is modified accordingly, i.e., to be generated by all elements of the form $(av_1,\cdots,av_n)-a^k(v_1,\cdots,v_n)$ II . The basis of $H$ for the case of one Vector space $n=1$ with finite dimension $d > 1$ and over $\mathbb R$ or $\mathbb C$ , is uncountably infinite. Since such maps are determined by their action on all lines through the origin. To see this, take a basis in $V$ , then each direction is determined by $d-1$ numbers, and there is uncountably infinite directions to determine the action of $\phi$ on them. In contrast to ( $p$ -)linear maps on $V$ into $V$ (for example), which requires only $d^{(p)}\cdot d$ numbers to determine a ( $p$ -) linear map, (finite dimensional tensor product space.)","['universal-property', 'abstract-algebra', 'solution-verification', 'quotient-spaces']"
3863476,Finding a lower bound for a fractional part,"I am interested in developing an accurate estimate for the following function: $$
F(A) = \frac{1}{2}+ \frac{1}{\pi}\sum_{t=1}^{\infty}\frac{\sin(A t)}{t};
$$ here $A=4\pi (3/2)^n$ , $n\in\mathbb{N}$ . I am aware that $F(A)\ge 0$ ; I am looking for a tight lower bound that is positive for $A$ (or $n$ ). The sum is convergent by Dirichlet's Test; it is just a matter of obtaining a careful lower bound. This is part of a larger calculation: I want to show that eventually $E(A)\cdot F(A)>4$ , where $E(A)$ is positive and exponential. The case where the series is positive is easy since $E(A)\to\infty$ and if the series is non-negative, $F(A)>1/2$ . I'm a bit stuck on the case where the sum is negative. Using Maclaurin series and trig identities, we have $$
F(A)=\frac{1}{2} + \frac{i (\log(1 - e^{i A}) - \log(1-e^{-i A}))}{2\pi}
$$ $$=\frac{1}{2}+\frac{1}{\pi}\arctan(\cot(\pi A))$$ $$=1-\{A\}$$ I have tried to use the periodicity of the numerator, since $A=2\pi r, r=R/T\in \mathbb{Q}$ to write $F$ as a double sum. Let $S_v=\sum_{t=1}^T \frac{\sin(A t)}{t+v\cdot T}$ : then we have \begin{align}F(A) = \frac{1}{2}+\frac{1}{\pi} \left (\sum_{t=1}^T\frac{\sin(A t)}{t}+\sum_{t=T+1}^{2T}\frac{\sin(A t)}{t}+\sum_{t=2T+1}^{3T}\frac{\sin(A t)}{t}+\cdots \right )\\
= \frac{1}{2} +\frac{1}{\pi} \left (\sum_{t=1}^T\frac{\sin(A t)}{t}+\sum_{t=1}^{T}\frac{\sin(A t)}{t+T}+\sum_{t=1}^{T}\frac{\sin(A t)}{t+2T}+\cdots \right )\\
=\frac{1}{2}+\frac{1}{\pi}\sum_{v=0}^{\infty} \left (\sum_{t=1}^{T}\frac{\sin(A t)}{t+v\cdot T} \right ) = \frac{1}{2}+\frac{1}{\pi}\sum_{v=0}^{\infty}S_v. \end{align} I believe the $S_v$ alternate in sign and have decreasing magnitudes. One approach might be developing a careful bound for $S_0$ and showing $|S_0|>>|S_1|>>|S_2|>>\cdots$ to provide a lower bound. Any help is appreciated.","['trigonometric-series', 'number-theory', 'convergence-divergence', 'asymptotics']"
3863481,A Transformation of a cross-shaped grid filled with 1s (Proof of impossibility?),Consider a cross-shaped grid of size 7 as it shows on the figure (compared to one of size 3). Each cell contains a 1. Le'ts define a transformation $\pi$ of the grid as follows: take any 3 sized sub-cross of the grid and multiply all the cells inside by $-1$ . How many $\pi$ transformations are required to transform a cross-shaped grid of size 2017 that contains a 1 in each cell into a grid that contains $-1$ in every cell? Any ideas on how to proceed? I was trying to solve the particular case for 7 but even for that I found it quite hard.,"['contest-math', 'geometric-transformation', 'combinatorics']"
3863504,"How to show that the sequence $\int_{0}^{\infty} \frac{e^{-nx}}{\sqrt{x}} \,dx$ converges to $0$?","I need to show that for any $\epsilon>0$ exist a $N \in \mathbb{N}$ s.t $n \geq N\in \mathbb{N}$$ \implies$ $\left|\int_{0}^{\infty} \frac{e^{-nx}}{\sqrt{x}} \,dx \right|<\epsilon$ . I know that: \begin{align*}
\left|\int_{0}^{\infty} \frac{e^{-nx}}{\sqrt{x}} \,dx \right|\leq \int_{0}^{\infty} \left| \frac{e^{-nx}}{\sqrt{x}} \right| \,dx=\int_{0}^{\infty} \frac{e^{-nx}}{\sqrt{x}} \,dx
\end{align*} But i can't find a function $g(x,n)$ such that: \begin{align*}
\int_{0}^{\infty} \frac{e^{-nx}}{\sqrt{x}} \,dx \leq \int_{0}^{\infty} g(x,n) \,dx
\end{align*} I apreciate your help.","['limits', 'improper-integrals']"
3863506,Why don't we just use the outer measure?,Why do we care so much to restrict to a $\sigma$ -algebra of sets on which the outer measure is countably additive? When is countable sub -additivity not enough? Does it pose a problem when defining the Lebesgue integral?,"['integration', 'measure-theory']"
3863508,"Closed form $\int_{0}^{\frac{\pi}{2}}\int_{0}^{\frac{\pi}{2}}\int_{0}^{\frac{\pi}{2}}\sin(xyz)\,dx\,dy\,dz$","This is part of an assignment from a multivariable calculus course. We've only just defined triple integrals and we're not using special functions or anything like that, so I'm pretty sure this was a mistake. Still, I'm interested to see if there exists some nice closed form. The only progress I've managed to get is $$\int_{0}^{\frac{\pi}{2}}\int_{0}^{\frac{\pi}{2}}\int_{0}^{\frac{\pi}{2}}\sin(xyz)\,dx\,dy\,dz=\int_{0}^{\frac{\pi}{2}}\dfrac{1}{z}\left(\ln\left(\dfrac{\pi^2}{4}z\right)-\text{Ci}\left(\dfrac{\pi^2}{4}z\right)+\gamma\right)dz\,,$$ where $\text{Ci}(x)$ is the cosine integral, but nothing else. Any ideas?","['multivariable-calculus', 'multiple-integral', 'definite-integrals', 'closed-form']"
3863517,An interesting puzzle in an otherwise boring game,"I recently had the displeasure of playing the Xbox 360 game Tower Bloxx Deluxe. You've played a version of it if not it itself; you build towers by dropping floors on top of the increasingly swaying tower you've already built. That's not interesting. What is interesting is the game's city building. It gives you a grid of plots on which you build towers for people to live in and maximize your population. There are 5 tiers of tower, each taller thus more populous than the last. The trick is that a tier 2 tower needs to have a tier 1 tower adjacent to it before it can be built. A tier 3 tower needs a tier 1 tower and a tier 2 tower adjacent to it before it can be built. Eventually, a tier 5 tower needs to have all the lower tiers adjacent to it before it can be built. Higher tier towers do not satisfy requirements for the lower tiers. Once a tower is built, these restrictions no longer apply, so you can bulldoze everything around a tower and it will still stand. Reworking this as a math puzzle, consider an n by m matrix M of 1's. Each iteration, you may replace one value in M with a counting number s if every counting number less than s is accounted for in the cells adjacent to it (The game only allows orthogonal adjacency, but allowing diagonal could be interesting too). What is the maximum sum of the values in M? What is the minimum number of iterations required to reach that value? What about expanding this to a graph instead of a matrix? It's fairly obvious that no 5's can ever be next to each other, and that any final grid must have a 1 in it somewhere. I whipped up some Python code to brute force the problem, and it found that the optimal matrices of their sizes, up to symmetry, are $$\begin{vmatrix} 1 \end{vmatrix},
\begin{vmatrix} 2 & 1 \end{vmatrix}, 
\begin{vmatrix} 2 & 3 \\ 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 2 & 3 \\ 3 & 4 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 4 & 3 \\ 4 & 2 & 4 \\ 3 & 4 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 3 & 4 & 1 \\ 3 & 4 & 2 & 3 \end{vmatrix},
\begin{vmatrix} 2 & 4 & 3 & 2 \\ 4 & 1 & 5 & 4 \\ 3 & 4 & 2 & 3 \end{vmatrix},
\begin{vmatrix} 2 & 3 & 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 3 & 4 & 3 & 2 \\ 3 & 4 & 2 & 4 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 2 & 3 & 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 4 & 1 & 4 & 3 & 2 \\ 3 & 3 & 4 & 2 & 4 & 3 \end{vmatrix},
\begin{vmatrix} 2 & 3 & 2 & 3 & 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 2 & 3 & 2 & 3 & 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 3 & 2 & 3 & 2 & 3 & 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 2 & 3 & 2 & 3 & 2 & 3 & 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 3 & 2 & 3 & 2 & 3 & 2 & 3 & 2 & 3 & 1 \end{vmatrix},
\begin{vmatrix} 2 & 2 & 3 & 2 & 3 & 2 & 3 & 2 & 3 & 2 & 3 & 1 \end{vmatrix}$$ Matrices of area greater than 12 cause even my fairly beefy computer to run out of memory. I'm surprised that a 5 only appears for the first time in a 4x3. The nx1's also follow a clear pattern. I'm struggling to make any headway beyond this. What can you all come up with? If anyone else wants to use it, here's the code I wrote (meant to be fast to write, not necessarily easily readable, sorry): from queue import SimpleQueue as Q


def modification(grid, row, col, val):
    return grid[:row] + (grid[row][:col] + (val,) + grid[row][col + 1:],) + grid[row + 1:]
    
    
def maximize(w, h, p):
    q = Q()
    s = set()
    q.put(tuple((0,) * w for i in range(h)))
    return _maximize(q, s, p)
    
    
def matsum(grid):
    return sum(sum(row) for row in grid)
    

def _maximize(q, s, p):
    G = ((0,),)
    r = -1
    while not q.empty():
        r = (r + 1) % p
        if r == 0:
            print(""Queue length: "" + str(q.qsize()) +
                  ""\tSeen grids: "" + str(len(s)) + "" ""*15, end='\r')
        g = q.get()
        s.add(g)
        if matsum(g) > matsum(G):
            G = g
        w = len(g[0])
        h = len(g)
        for x in range(w):
            for y in range(h):
                # try setting it to 0
                m = modification(g, y, x, 0)
                if m not in s:
                    q.put(m)
                for v in range(1, 5):
                    if ((x > 0 and g[y][x - 1] == v - 1)
                            or (y > 0 and g[y - 1][x] == v - 1)
                            or (x < w - 1 and g[y][x + 1] == v - 1)
                            or (y < h - 1 and g[y + 1][x] == v - 1)):
                        m = modification(g, y, x, v)
                        if m not in s:
                            s.add(m)
                            q.put(m)
                    else:
                        break
    print(""Queue length: "" + str(q.qsize()) +
          ""\tSeen grids: "" + str(len(s)) + "" ""*15)
    return G
    
    
 for i in range(1, 13):
    for j in range(1, i+1):
        if i*j < 13:
            print(str(i) + ""x"" + str(j) + ':')
            print(maximize(i, j, 5000)) The following code has been slightly modified to prioritize higher-sum matrices at the cost of performance. The result is that it will find high-sum matrices quickly, but for sizes larger than say 4x3, it will take a prohibitively long time to finish and output the actual highest sum matrix (though it will eventually finish). import heapq


def modification(grid, row, col, val):
    return grid[:row] + (grid[row][:col] + (val,) + grid[row][col + 1:],) + grid[row + 1:]


def maximize(w, h, p):
    q = []
    s = set()
    heapq.heappush(q, (-w*h, tuple((1,) * w for i in range(h))))
    return _maximize(q, s, p)


def matsum(grid):
    return sum(sum(row) for row in grid)


def _maximize(q, s, p):
    G = ((0,),)
    sG = matsum(G)
    r = -1
    while len(q) != 0:
        r = (r + 1) % p
        if r == 0:
            print(""len(q)="" + str(len(q)) +
                  "" len(s)="" + str(len(s)) +
                  "" G="" + str(G) + 
                  "" matsum(G)="" + str(sG)+"" ""*10, end='\r')
        sg, g = heapq.heappop(q)
        s.add(g)
        if -sg > sG:
            sG, G = -sg, g
        w = len(g[0])
        h = len(g)
        for x in range(w):
            for y in range(h):
                # try setting it to 1
                m = modification(g, y, x, 1)
                if m not in s:
                    heapq.heappush(q, (-matsum(m), m))
                    s.add(m)
                for v in range(2, 6):
                    if ((x > 0 and g[y][x - 1] == v - 1)
                            or (y > 0 and g[y - 1][x] == v - 1)
                            or (x < w - 1 and g[y][x + 1] == v - 1)
                            or (y < h - 1 and g[y + 1][x] == v - 1)):
                        m = modification(g, y, x, v)
                        if m not in s:
                            s.add(m)
                            heapq.heappush(q, (-matsum(m), m))
                    else:
                        break
    print(""len(q)="" + str(len(q)) +
                  "" len(s)="" + str(len(s)) +
                  "" G="" + str(G) + 
                  "" matsum(G)="" + str(sG)+"" ""*10)
    return G


print(maximize(3, 3, 1000)) # to prove it works
#print(maximize(4, 4, 10000))","['matrices', 'optimization', 'puzzle']"
3863538,Criteria for the convergence of $E(g(X))$,"Let $X$ be a non-negative random variable, and g a non-negative, strictly increasing, differentiable function. I want to show that $E(g(X)) < \infty \iff \sum^{\infty}_{n=1}g'(n)P(X>x)<\infty$ . I know that $E(g(X)) = g(0) + \int^{\infty}_{0}g'(x)P(X>x)dx$ , and I got $\sum^{\infty}_{n=1}\inf_{x \in [n,n-1)}g'(x)P(X>n) \leq E(g(x))-g(0) \leq \sum^{\infty}_{n=1}\sup_{x \in [n,n-1)}g'(x)P(X>n-1)$ How do I proceed?","['expected-value', 'convergence-divergence', 'probability-theory']"
3863552,Probability after rolling 4 dice,"Q. (the probability that the total after rolling 4 fair dice is 21) > (the probability that
the total after rolling 4 fair dice is 22) A. Explanation: All ordered outcomes are equally likely here. So for example with two
dice, obtaining a total of 9 is more likely than obtaining a total of 10 since there are
two ways to get a 5 and a 4, and only one way to get two 5’s. To get a 21, the outcome
must be a permutation of (6, 6, 6, 3) (4 possibilities), (6, 5, 5, 5) (4 possibilities), or
(6, 6, 5, 4) (4!/2 = 12 possibilities). To get a 22, the outcome must be a permutation
of (6, 6, 6, 4) (4 possibilities), or (6, 6, 5, 5) (4!/22 = 6 possibilities). So getting a 21
is more likely; in fact, it is exactly twice as likely as getting a 22. What I have understood so far is that after rolling 4 fair dice you can get 22 in the following ways - 6,6,6,4 - $4C_1$ - 4 6,6,5,5 - $4C_2$ - 6 So the total ways in which you can get 22 is 10, where you can get 21 in the following ways - 6,6,6,3 - $4C_1$ - 4 6,6,5,4 - $4C_2$ - 6 6,5,5,5 - $4C_1$ - 4
and hence the total ways in which you can choose is 14. Am I doing something wrong here?
Can someone please help me understand the answer (A.) a bit better? Thanks in advance.","['dice', 'combinatorics', 'probability']"
3863648,Convergence Rate of Sample Variance,"Question: Given $X_1,X_2,...$ as an sequence of iid distributed random variables with $E(X_i)=0 $ and $V(X_i)=σ^2$ and the fourth order moment $E(X_i^4)<\infty$ . Show that: $\sqrt{n}(S_n^2-\sigma^2)\xrightarrow{d}N(0,E[(X_i^2-\sigma^2)^2])$ , where $S_n^2$ is the sample variance. I am sure that we have to employ the fact that $S^2_n\xrightarrow{p} \sigma^2$ together with the Central Limit Theorem. But I still can not figure out the exact proof of this problem.","['statistics', 'probability-limit-theorems', 'central-limit-theorem', 'law-of-large-numbers', 'probability-theory']"
3863710,How to Compute the answer to the following limit problems?,"According to the answers in my book e = 4 and b = -2, I am unsure about e, but for b I would have assumed it to be -1. Can someone explain to me why the answers are what they are?","['limits', 'calculus']"
3863796,"Showing that $\frac{\|f(x)\|}{\|x\|}=0, \text{ as $x \to 0$}$","Let $f : \Bbb R^2 \to \Bbb R^2$ be differentiable at $x=0.$ Show that $$\frac{\|f(x)\|}{\|x\|}=0, \text{ as $x \to 0$}$$ if and only if $f(0) = 0$ and $Df(0) = 0.$ Using the definition $f(x)-f(a) = Df(a)(x-a)+\|x-a\|\varepsilon(x-a)$ I get that $$f(x)-0=0+\|x-0\|\varepsilon(x-0) \Rightarrow f(x) = \|x\|\varepsilon(x).$$ Dividing by $\|x\|$ I have that $\frac{f(x)}{\|x\|}=\varepsilon(x)$ . Now doesn't $\varepsilon(x) \to 0$ by definition? Thus $\frac{f(x)}{\|x\|} \to 0$ ?","['multivariable-calculus', 'real-analysis']"
3863905,Weighted sum of diagonal values is dominated by the sum of the singular values,"Let $A$ be a $2 \times 2$ real matrix with $\det A \ge 0$ , and let $\sigma_1 \le \sigma_2$ be its singular values. Let $0 \le x_1 \le x_2$ . How to prove that $x_1 A_{11} +x_2A_{22} \le x_1 \sigma_1+x_2 \sigma_2$ ? I have a proof, but it uses Riemannian geometry. I am looking for a more elementary proof. Equivalent formulation: Set $K=\{ A \in M_2 \, | \, \det A \ge 0 \, \, \text{ and the singular values of } A \, \text{are } \sigma_1,\sigma_2 \}$ . Then $$\max_{A \in K} x_1 A_{11} +x_2A_{22}=x_1 \sigma_1+x_2 \sigma_2.$$ It suffices to prove that the maximum is obtained at a diagonal matrix; for a diagonal matrix with nonnegative entries $A=\operatorname{diag}(\sigma_{\alpha(i)})$ , the claim reduces to the rearrangement inequality $\sum_i x_i\sigma_{\alpha(i)} \le \sum_i x_i\sigma_i$ , where $\alpha \in S_2$ is a permutation.(for dimension $2$ this can be verified directly by hand.) I guess this should be well-known. Is there any reference in the literature?
Is it true for $n \times n$ matrices? If $x_1=x_2$ , then this reduces to $\text{tr}(A) \le \sigma_1+\sigma_2$ which is a classic easy result.","['svd', 'multivariable-calculus', 'matrix-calculus', 'optimization', 'inequality']"
3863922,Proof of Levy's Characterization Theorem,"Levy's Characterization theorem states that if $M$ is a continuous local martingale such that $M_0=0$ and the process $M_t^2-t$ is a continuous local martingale, then $M$ is a Brownian motion. A standard approach (Karatzas&Shreve, page 157) to prove the above is to show that \begin{equation}
\tag{1}
E[e^{iu(M_t-M_s)}|\mathcal{F}_s]=e^{-u^2(t-s)/2}
\end{equation} and to do so we take $A\in\mathcal{F}_s$ and applying Ito formula to $1_{A}\exp(iux)$ taking expectation and solving an ODE gives us, $$
\tag{2}
E[1_{A}e^{iu(M_t-M_s)}]=P(A)e^{-u^2(t-s)/2}.
$$ My question is which equation (1) or (2) tells us independence of increments? And how does (2) implies (1)?","['stochastic-processes', 'probability-theory', 'probability', 'stochastic-calculus']"
3863995,"If $X \times X \simeq \mathbb{R}^{2}$, then $X \simeq \mathbb{R}$?","I came across this question few years ago, but I have not yet reached a satisfactory answer. If a product of a topological space $X$ with itself is homeomorphic to the real plane $\mathbb{R}^{2}$ , must $X$ be homeomorphic to the real line $\mathbb{R}$ ? Here I am not assuming a priori that $X$ is a manifold.","['manifolds', 'general-topology', 'products']"
3864015,How to state and prove a certain result from modular arithmetic in algebraic terms?,"Consider the group generated by the two functions $x\mapsto \frac 1x$ and $x\mapsto -1-x$ . It is isomorphic to $S_3$ and contains the following elements: $$G=\left\{x,\frac 1x, -1-x,-\frac{1}{1+x},-\frac{x}{1+x},-\frac{1+x}{x}\right\}$$ And define the equivalence relation $$a\sim b\iff\exists g\in G, g(a)=b$$ The integers mod $p$ for a prime are partitioned into: $0,-1$ for which some inverses are undefined; The two solutions of $x^2+x+1\equiv 0$ if they exist; A set of equivalence classes with 6 elements each; The equivalence class $1,-2,-2^{-1}$ . This is laborious but straightforward to do with standard modular arithmetic, but I wanted a (hopefully more illuminating) proof in algebraic terms. The thing about partitioning into disjoint sets of equal size reminded me of the proof of Cayley's theorem but I wasn't able to adapt it. Likewise I tried to state it as some claim about a homomorphism $G\rightarrow\mathbb{Z}/p\mathbb{Z}$ without luck. I'm asking because here the site math pages used this result without proof.","['group-theory', 'modular-arithmetic']"
3864109,Can we rely on Confidence Intervals?,"Suppose the mean is in (7.6,8.4) with 95% confidence. I understand that this means 95% of the confidence intervals from different samples will contain the population mean. But, what is the significance of this particular interval on its own . Since I am sure that 95% of sampling intervals will contain the mean can I be somewhat certain that this interval is one of them? If not, how is this interval useful at all to me? In other words, how sure can I be that mean is in (7.6,8.4) and if I can't be sure then what's the use of this?","['statistics', 'confidence-interval', 'means', 'intuition', 'probability']"
3864113,Manifolds are Borel sets,"Consider $M\subseteq \mathbb{R}^n$ , an (embedded) $C^{k\geq 1}$ manifold. Is $M$ Borel? I think yes but I got stuck at proving this. For some context, I was checking that integrals over manifolds with respect to Hausdorff measures make sense. My try: Graphs of continuous functions are Borel: let $U$ be open and $f:U \rightarrow \mathbb{R}^q$ be continuous. Let $\phi(x)=(x,f(x))$ , a continuous function. We can write $U=\bigcup_n K_n$ for some compact sets $K_n \subseteq U$ and therefore $\text{graf}f=\phi(U)=\bigcup_n\phi(K_n)$ , so that the graph of $f$ is the countable union of compact (hence Borel) sets. A manifold is ""countably locally"" the graph of a $C^k$ function: by this I mean that $M$ is the countable union of the graphs of some $C^k$ functions. Here I am stuck. I know that $M$ is locally a graph, but I cannot get the countability property. I was thinking of using the density of rationals in the real numbers but I'm not sure if this is the way to go, also beacause I'm not sure that second countability of $M$ is guaranteed with my definition of manifold (see below). Do you have any hint on how to get through point 2, provided my claim is correct? $M\subseteq \mathbb{R}^n$ is an embedded $C^{k\geq 1}$ $m-$ manifold if for every $p$ in $M$ there exists $U\subseteq \mathbb{R}^m$ open and $\phi:U\rightarrow M$ of class $C^{k}$ such that: $\phi(U)$ is a neighbourhood of $p$ , open in $M$ $\phi$ is a homeomorphism onto its image $d\phi$ is everywhere injective","['measure-theory', 'differential-geometry', 'real-analysis']"
3864187,Does idempotent completion commute with direct sum completion?,"Definitions: For a pre-additive category $\mathcal{C}$ I denote its idempotent completion by $\overline{\mathcal{C}}^p$ . The objects of $\overline{\mathcal{C}}^p$ are pairs $(X,p)$ , where $X \in \mathcal{C}$ and $p$ is an idempotent on $X$ . A morphism $f:(X,p) \to (Y,q)$ is a morphism $f:x \to Y$ of $\mathcal{C}$ such that $fp = f$ and $qf=f$ . The embedding $\mathcal{C} \to \overline{\mathcal{C}}^p$ , $X \mapsto (X,1_X)$ satisfies the (weak) universal property of a completion. Similarly, the direct sum completion $\overline{\mathcal{C}}^{\oplus}$ has as objects finite lists of objects of $\mathcal{C}$ . A morphism $f: (X_1,\ldots, X_n) \to (Y_1, \ldots, Y_m)$ is a matrix $(f_{ij})$ of morphisms $f_{ij}:X_i \to X_j$ . It is the universal additive category containing $\mathcal{C}$ (via the embedding $X \mapsto (X,1_X)$ ). Question: Is there always a canonical equivalence $\overline{\mathcal{C}}^{p \oplus} \simeq \overline{\mathcal{C}}^{\oplus p}$ . If not, is there a simple counterexample? Additional info: The statement is equivalent to $\overline{\mathcal{C}}^{\oplus}$ being idempotent complete for any idempotent complete category $\mathcal{C}$ and $\overline{\mathcal{C}}^{p}$ being additive for any additive category $\mathcal{C}$ . The latter is straightforward, giving rise to the embedding $$
\overline{\mathcal{C}}^{p\oplus} \to \overline{\mathcal{C}}^{\oplus p} \\
((X_1, p_1),\ldots, (X_n, p_n)) \mapsto ((X_1,\ldots, X_n),(p_1 \oplus \ldots \oplus p_n))
$$ where the direct sums of morphisms is taking block matrices. (""A direct sum of subobjects is a subobject of the direct sum."") But I can't see how the other direction would follow in general. Possible counter example: For a non semi-simple algebra $A$ let $\mathcal{A}$ be the 1-object subcategory of $A-\operatorname{Mod}$ that only contains the regular representation. Then $\overline{\mathcal{A}}^{\oplus p}$ is $\operatorname{proj}(A)$ but what is $\overline{\mathcal{A}}^{p\oplus}$ ? If $A$ is semi-simple then every $A$ -module is projective so this is not a counter example in that case. Origin of the question: It is claimed in passing in this paper on page 6 at the end of the first paragraph. So probably I'm just blind for not seeing it. Any help is appreciated.","['abstract-algebra', 'category-theory', 'additive-categories']"
3864270,Differential equation's domain?,"I'm confused a little bit. I have a differential equation: $yy'\sqrt{(1-x^2)/(1-2y^2)}+1=0$ . I just looked at it and solved it without problems, it didn't look like a big deal. It's a nonlinear nonhomogeneous first order differential equation, right? You can separate variables here, so I did it. But when I checked the answer on Wolfram, the answer was different. CAS wxMaxima produced another solution. And then I remembered perhaps I should do something with the domain, or something with the expression I've divided by. I've never really understood those things, because my differential equations course was a chaotic one, no one ever really explained it decently. Oh, so, okay, my question. What I should do about the domain and range of the equation? It looks like $(1-x^2)/(1-2y^2)$ has to be greater than or equal to zero, because it is in the square root. So, numerator and denominator should both be greater than or equal to $0$ OR less than or equal to $0$ . Oh, and denominator shouldn't be equal to zero? But how I suppose to solve the dif.equation correctly?
I did this. At first I solve the equation when $x \in [-1,1]$ and $y \in [-\frac{\sqrt{2}}{2}, \frac{\sqrt{2}}{2}]$ , I got the answer $\arcsin x - \frac{\sqrt{1-2y^2}}{2}=C$ . Then I took the case when $x \in [-\infty,-1] \cup [1, +\infty]$ and $y \in [-\infty, -\frac{\sqrt{2}}{2}] \cup [\frac{\sqrt{2}}{2}, +\infty]$ . The solution I got was $\frac{\sqrt{2y^2-1}}{2}+\ln{|\sqrt{x^2-1}+x|}=C$ I did it like that, but I don't really think it's a good solution. Perhaps solutions overlap each other and still not sure if it's a correct method to do this. Oh, and Wolfram gave me this answer: $\frac{1}{2}\sqrt{2y^2-1}=\frac{1}{2}\log(-\frac{x}{\sqrt{x^2-1}}+1)-\frac{1}{2}\log(\frac{x}{\sqrt{x^2-1}}+1)+C$ . CAS wxMaxima gave me this result: $\frac{2\sqrt{x^2-1}\log(2\sqrt{x^2-1}+2x)\sqrt{\frac{x^2-1}{2y^2-1}}+x^2+1}{2\sqrt{x^2-1}\sqrt{\frac{x^2-1}{2y^2-1}}}=C$ I know that you can simplify the answer of Wolfram and wxMaxima, but why they didn't simplify it? There must be reasons.. So, I don't know why these solutions are differently written, which one of them is the most accurate, how to solve exactly correctly, what should I do about the DE domain (not only this equation's, but also every other time, with different DE) and was my solution good? And sorry for my ignorance, I'm  really messed up :D I believe there's some small detail I don't understand at all..","['calculus', 'ordinary-differential-equations']"
3864306,"$C^n$-manifold, which is not a $C^{n+1}$-manifold","Question: Given an integer $n \in \mathbb{N}$ , then what is an example of a $C^n$ -manifold which is not a $C^{n+1}$ -manifold? Minor question: I know everything in theory, but I can not do it in practice. For instance, how can I check that the graph of the function $f\colon \mathbb R^2 \to \mathbb R^3$ , $f(x,y)=(\sin x,e^y\cos x, xy)$ , is a differentiable manifold. Please do not use theorems, if it is possible. I want to see the whole procedure for at least one time. Any link and simple references are welcome. I know the definition of a differentiable (or ~smooth or ~ $C^{\infty}$ ) manifold, which is a Hausdorff, second countable topological space, with a differentiable atlas on it. If an atlas was given, then I feel comfortable with the definition of transition maps, and diffeomorphism (invertible smooth functions, with the smooth inverse), etc. But I can not realize what is the Atlas in that example? Even if it was given to me, I don't have any idea how can I check all the infinitely many transition maps and diffeomorphism in practice.","['manifolds', 'smooth-manifolds', 'differential-geometry']"
3864337,Freidlin-Wentzell theory: clarification of a theorem,"I am studying Freidlin and Wentzell large deviation theory from their 2012 book ""Random perturbations of dynamical systems"" and I have a problem in justifying two steps of the proof of theorem 1.3. The theorem states Theorem We assume that there exists a continuous function $\bar{b}(t, x), t > 0,x \in \mathbb{R}^{r}$ such that for any $δ > 0, T > 0, x ∈ R^r$ we have \begin{equation}
\label{eqn: hp1}
\lim_{\epsilon \to 0} \mathbb{P} \Big( \Big| \int_{t_0}^{t_0+T}b(\epsilon,t,x,\omega)dt - \int_{t_0}^{t_0+T} \bar{b}(t,x)dt \Big| > \delta \Big) = 0
\end{equation} uniformly in $t_0 \ge 0$ . Then the equation \begin{equation}
\label{eqn: hp2}
\dot{\bar{x}}_t=\bar{b}(t,\bar{x}_t), \qquad \bar{x}_0=x
\end{equation} has a unique solution and \begin{equation}
\lim_{\epsilon \to 0} \mathbb{P} \big( \max_{0 \le t \le T}|X_{t}^{\epsilon}-\bar{x}_t| > \delta \big) =0
\end{equation} for every $T>0$ and $\delta>0$ . Proof Since the function $\bar{b}(t,x)$ is continuous, by the mean value theorem we have $
\int_{t}^{t+\Delta}\bar{b}(s,x) ds =\bar{b}(t,x)\Delta+o(\Delta), \qquad \Delta \to 0
$ Taking into account the first hypothesis, we get \begin{equation}
\begin{split}
|\bar{b}(t,x)-\bar{b}(t,y)| &= \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} \bar{b}(s,x)ds - \int_{t}^{t+\Delta} \bar{b}(s,y)ds \Big| + \frac{o(\Delta)}{\Delta}\\
& \le  \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} b(\epsilon,s,x,\omega)ds - \int_{t}^{t+\Delta} b(\epsilon,s,y,\omega)ds \Big| \\
& + \frac{o(\Delta)}{\Delta} +\delta_{\epsilon} \\
& \le K|x-y|+\frac{o(\Delta)}{\Delta} +\delta_{\epsilon}
\end{split}
\end{equation} where $\delta_{\epsilon}=\delta_{\epsilon}(t,\omega) \to 0$ in probability as $\epsilon \to 0$ . And from this follows the Lipschitz condition on $\bar{b}$ and so the existence and uniqueness. Here I don't understand how to get $\delta_{\epsilon}$ , which I don't even know how it is defined. I tried in this way: from the hypotesis I remark that $-\delta \le  \int_{t_0}^{t_0+T}b(\epsilon,t,x,\omega)dt - \int_{t_0}^{t_0+T} \bar{b}(t,x)dt \le \delta$ and so, after adding and subtracting both $\int_{t}^{t+\Delta}b(\epsilon,t,x,\omega)dt$ and $\int_{t}^{t+\Delta}b(\epsilon,t,y,\omega)dt$ and use the remark above and I obtain \begin{equation}
\begin{split}
|\bar{b}(t,x)-\bar{b}(t,y)| &= \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} \bar{b}(s,x)ds - \int_{t}^{t+\Delta} \bar{b}(s,y)ds \Big| + \frac{o(\Delta)}{\Delta}\\
& \le  \frac{1}{\Delta} \Big| \int_{t}^{t+\Delta} b(\epsilon,s,x,\omega)ds - \int_{t}^{t+\Delta} b(\epsilon,s,y,\omega)ds \Big| \\
& + \frac{o(\Delta)}{\Delta} +\frac{2}{\Delta}\delta \\
& \le K|x-y|+\frac{o(\Delta)}{\Delta} +\delta_{\epsilon}
\end{split}
\end{equation} where $\delta_{\epsilon}=\frac{2}{\Delta}\delta$ . But it doesn't seem right since it is not random and so how can I say that it converges in probability as the quantity of the authors? The other doubt is some steps after this. I have the estimate that follows: \begin{equation}
\begin{split}
& \int_{0}^{t} [b(\epsilon,s,\bar{x}_s,\omega)-\bar{b}(s,\bar{x}_s)]ds \\
&= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_s,\omega)-\bar{b}(s,\bar{x}_s)]ds \\
&= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_{kt/n},\omega)-\bar{b}(s,\bar{x}_{kt/n})]ds \\
&+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_s,\omega)-b(\epsilon,s,\bar{x}_{kt/n},\omega)]ds \\
&+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [\bar{b}(s,\bar{x}_{kt/n},)-\bar{b}(s,\bar{x}_s)]ds \\
&= \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} [b(\epsilon,s,\bar{x}_{kt/n},\omega)-\bar{b}(s,\bar{x}_{kt/n})]ds + \rho_{n,t}^{\epsilon}
\end{split}
\end{equation} where they say that $|\rho_{n,t}^{\epsilon}| \le C/n$ with $C=C(T,K)$ . I tried in this way but I'm stuck and don't know how to go on \begin{equation}
\begin{split}
|\rho_{n,t}^{\epsilon}| &\le \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} |b(\epsilon,s,\bar{x}_s,\omega)-b(\epsilon,s,\bar{x}_{kt/n},\omega)|ds \\
&+ \sum_{k=0}^{n-1} \int_{kt/n}^{(k+1)t/n} |\bar{b}(s,\bar{x}_{kt/n},)-\bar{b}(s,\bar{x}_s|ds \\
& \le 2K \sum_{k=0}^{n-1}\int_{kt/n}^{(k+1)t/n}|\bar{x}_s - \bar{x}_{kt/n}|ds
\end{split}
\end{equation} Now I don't know how to procede: how can I get the same result as in the book? Questions is what I did at the beginning correct? If not, how do I change it? how do I go on in the second part?
Thanks to anyone who will have the patience to read and answer.","['large-deviation-theory', 'probability-theory', 'probability', 'estimation']"
3864357,Visualizing the meaning of a complex determinant,"Context: A common visualization of the meaning of a (real) determinant is the area (or volume, in higher dimensions) enclosed by the image of basis vectors under matrix transformation: Question: But what if the matrix and determinant in question are complex valued?  How do we visualize the meaning of the determinant of these cases? Example: For example, the determinant of a unitary matrix $U$ satisfies $$
\det(U) = e^{i\phi}
$$ for some $\phi$ .  Is there a way to visualize what the complex determinant of $U$ is, in this case?","['matrices', 'visualization', 'determinant']"
3864361,Order of $\phi: g^i \mapsto g^{mi}$,"Let $G = \langle g \rangle$ be a cyclic group of order $n$ . Suppose $m$ is an integer such that $\gcd(m, n) = 1$ . Define $\phi: G \to G, g^i \mapsto g^{mi}$ . Then $\phi$ is (I think) an automorphism. What can we say about the order of $\phi$ ? My attempt: Note that $\phi^x(g^i) = g^{m^x i}$ . The exponentiation $m^x$ brings to mind Euler's Theorem, which is applicable in this case since $m, n$ are coprime: $m^{\Phi(n)} \equiv 1 \bmod n$ , where $\Phi$ is Euler's totient function. So $\phi^{\Phi(n)} \equiv I$ , where $I$ is the identity function, and $\Phi(n)$ is a candidate for the order of $\phi$ . However, trying out some simple examples shows that we can have a number $x$ less than $\Phi(n)$ such that $\phi^x \equiv I$ , so at least in some cases $\Phi(n)$ isn't the order of $\phi$ . I'm not sure what else to try now. Any suggestions/corrections would be appreciated.","['group-homomorphism', 'modular-arithmetic', 'cyclic-groups', 'finite-groups', 'group-theory']"
3864408,Is $A\cap B$ the same as $A\cup B-(A-B)-(B-A)$?,Is $A\cap B$ the same as $A\cup B-(A-B)-(B-A)$ ? I know that $A\cap B$ is equivalent to $A-(A-B)$ but I got to the first answer on my own and I want to know if it is correct.,['elementary-set-theory']
3864409,How to define a function that has these specific properties,"Suppose $x = (x_1,x_2,\dots,x_K) \in \mathbb{Z}^K_{\geq 0}$ . For $x,y \in \mathbb{Z}^K_{\geq 0}$ , we write $x \succ y$ or $y \prec x$ if $x \neq y$ and \begin{align*}
		x_{i(x,y)} > y_{i(x,y)},\quad \text{	where } \quad  i(x,y) := \max\{ i: x_i \neq y_i\}.
	\end{align*} That is, for any two vectors $x$ and $y$ that are not equal, we let $i(x,y)$ be the last position on which they differ and say that $x \succ y$ if the coordinate of $x$ at $i(x,y)$ is larger than the corresponding coordinate of $y$ . We write $x \succeq y$ if either $x = y$ or $x \succ y$ , and similarly for $x \preceq y$ . This is a total order. For example, if $x = (7,2,1,0,0)$ and $y = (6,3,1,0,0)$ then $y \succ x$ because they are equal on the last three positions and the next position that they differ is the second coordinate, since 3>2 we conclude that $y \succ x$ . Now, let $mx(x) = max\{k: x_k > 0\}$ , we are interested in defining a function $f: \mathbb{Z}^K_{\geq 0} \rightarrow [0,K+1)$ that has the following properties: $f(0,0,\ldots,0) = 0$ $mx(x) \leq f(x) < mx(x)+1$ (Note that when one of the coordinates of x is 1 and the rest are 0, then $f(x)= mx(x)$ , for example let $x = (0,1,0,0,0)$ , then $f(x)=mx(x)=2$ ) $f(.)$ is strictly increasing on $\mathbb{Z}^K_{\geq 0}$ wrt. the total-ordering defined above The effect of adding a positive value to coordinate $k$ should be smaller than adding the same value to coordinate $k+1,....,K$ , having all the other values fixed, sth like convexity property but I'm not sure if the exact definition of convexity applies here.
For example suppose $K=5$ , $f(0,3,0,0,0) - f(0,2,0,0,0) \leq f(0,0,3,0,0) - f(0,0,2,0,0)$ I could define a function that has the first three properties, but not the fourth one:
For any $x \in \mathbb{Z}^K_{\geq 0}$ ,  let $g_{k}(x) = \prod_{i=k}^{K} (1+i)^{-x_i}$ for $k=2,\dots,K$ and $g_{K+1}(x) = 1$ . \begin{align}
	f(x) := \sum_{k=2}^{K+1} k g_k(x) \big(1 - k^{-x_{k-1}}\big).
\end{align} $f(0,3,0,0,0) - f(0,2,0,0,0) = 2.888889 - 2.666667 = 0.222222$ but $f(0,0,3,0,0) - f(0,0,2,0,0) = 3.9375 - 3.75 = 0.1875$ How to define $f(.)$ so that it follows all the 4 properties?","['order-theory', 'multivariable-calculus', 'functions']"
3864457,Solving a line integral,"A vector field $\overrightarrow{E}=7x^2\hat{e}_x +3y\hat{e}_y-2xz\hat{e}_z$ Evaluate the line integral I $=\int_{c} \overrightarrow{E}\bullet d\overrightarrow{I}$ where the contour C is the straight line from the point (0,0,0) to (1,2,0) I was wondering if we are allowed to split the intergral up, so for example $I= \int_{0}^{1} 7x^2 dx + \int_{0}^{2} 3yzdx$ So do the line integral from (0,0,0) to (1,0,0) in the first integral then (1,0,0) to (1,2,0). or is there an easier method.","['vector-fields', 'multivariable-calculus', 'line-integrals']"
3864590,"How can we prove that there are no other integers with $\phi(n)=2$ besides 3,4,6? [duplicate]","This question already has answers here : For which natural numbers are $\phi(n)=2$? (3 answers) Closed 3 years ago . Where $\phi(n)$ is Euler's phi function that counts the number of relatively prime integers less than or equal to n. I've been able to compute that 3,4,6 all have only 2 relatively prime integers less than or equal to them, however I'm unsure how to prove that there are indeed no others. While I am certain that this is the case, how can this be proved rigorously?","['number-theory', 'totient-function', 'elementary-number-theory', 'prime-numbers']"
3864592,Gradient in Spherical coordinates,"I'm trying to derive the gradient vector in spherical polar coordinates: $$\nabla = \left( \frac{\partial}{\partial x}, \frac{\partial}{\partial y},\frac{\partial}{\partial z} \right)$$ The method I am trying to use is different from most papers/videos I found and I don't understand why it doesn't work. I am able to get expressions for the cartesian differentials: $dx, dy, dz$ . First, I am just trying to find $\frac{\partial}{\partial x}$ in spherical coordinates. I have: $$dx= \cos \theta \sin \phi dr + r \cos \theta \cos \phi d \theta + r \sin \theta \sin \phi d \phi$$ This sounds strange but my first intuition was to say that: $$\frac{\partial}{\partial x} = \frac{ \partial }{ \cos \theta \sin \phi dr + r \cos \theta \cos \phi d \theta + r \sin \theta \sin \phi d \phi} $$ Which doesn't seem to make any sense now :(. If my logic is wrong, could someone explain to me why?","['coordinate-systems', 'multivariable-calculus', 'spherical-coordinates', 'vector-analysis', 'partial-derivative']"
3864631,Why the maximal interval of existence isn't always $\mathbb{R}$,"We know from the Picard-Lindelof Theorem that given an IVP with $f(x)\in C(E)$ where $E$ is an open subset of $\mathbb{R}^n$ then we have a local solution define in some interval $]t_0-\alpha,t_0+\alpha[$ . Now suppose we want the maximal interval of existence , I am interest in figuring out what are the factors that stop us from this maximal interval being $\mathbb{R}$ . One thing I think could happen is that when we try to apply the Picard Lindelof again to a point in $]t_o-\alpha,t_0+\alpha[$ we obtain a new interval but the point is that this sum of lenghts of the intervals could be converging, and so we could not get to the whole space of $\mathbb{R}$ ? Is there anything more that can stop us from getting a solution defined in the whole line ? We need to have control over the values of $x(t)$ but I think the picard-Lindelof theorem gives us that $x(t)$ is in $E$ for all $t$ in the interval given by picard lindelof. I guess a problem could be that if we try to use picard-lindelof in $t_0-\alpha$ we need to check that $x(t_0-\alpha)$ is defined and so this could become a problem too. Also I have seen both version where the interval where the solution is defined is closed and sometimes I have seen it open so I guess I am confused about that too, I can see why they could equivalent but I don't understand why we jut don't fix one. Is there anthing I am missing or missunderstanding? Thanks in advance.",['ordinary-differential-equations']
3864658,Can you subtract a line from an area?,"I'm trying to find the probability of C, and I learned the probability is the area by the uniform law. The thing is I get a line from C. Did I find the wrong area or is there a way to subtract a line from the area?","['statistics', 'probability']"
