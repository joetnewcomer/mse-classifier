question_id,title,body,tags
3206659,How to analyze $\sup_{x>0}|e^xf(x)| < \infty$ and $\sup_{n\in\mathbb{N}} |f^{(n)}(0)|< \infty$?,"Suppose that $$f(x)=1+\sum_{n=1}^\infty a_n \frac{x^n}{n!}\ \ \forall \ x\in \mathbb{R}$$ where $\sup_{x>0}\left|e^xf(x)\right| < \infty$ and $\sup_{n\in\mathbb{N}} |a_n|< \infty$ . Prove that $a_n = (-1)^n$ , $\forall n\in \mathbb{N}$ It seems amazing to me. What we need to prove is $f(x)=e^{-x}$ . It seems insufficient to prove this strong conclusion, but actually it is true and all the ""counterexamples"" I found were wrong. My attempt Put $g(x)=e^x f(x)$ . $$\left|g^{(n)}(0)\right|=\left|\sum_{k=0}^n \binom{n}{k} f^{(k)}(0)\right|\le 2^n\sup_{n\in\mathbb{N}} |a_n|  $$ Put $h(x)=g(\frac{x}{2})$ . Thus $$h^{(n)}(0)=\frac{1}{2^n}g(0) \le \sup_{n\in\mathbb{N}} |a_n|$$ which implies that $$h(x)=1+\sum_{n=1}^\infty b_n \frac{x^n}{n!}\ \ \forall \ x\in \mathbb{R}$$ where $$|b_n|\le \sup_{n\in\mathbb{N}} |a_n| \ \ \forall \ n\in\mathbb{N} 
\,\,\,\,\,\& \,\,\,\,\,  \sup_{x>0}\left|h(x)\right| < \infty $$ And hence if $b_k<0$ , then there exists $l>k$ such that $b_l>0$ . I want to yield a contradiction by supposing this, but I failed. Any hints or other new ideas? Thanks in advance! (I heard that this problem can be solved by complex analysis. This is the reason why I attach the complex-analysis tag.)","['complex-analysis', 'power-series', 'real-analysis']"
3206701,Evaluate $\int _0^{\infty }\frac{x^6}{\left(x^4+a^4\right)^2}dx$,"The function $$f\left(z\right)=\frac{z^6}{\left(z^4+a^4\right)^2}$$ Has the following poles of order 2: $$ z(k)=a \exp\left( \frac{\left(2k+1\right)}4 i\pi \right)$$ $f$ is even, therefore: $$\int _0^{+\infty }\frac{x^6}{\left(x^4+a^4\right)^2}dx =\frac{1}{2}\int _{-\infty }^{+\infty \:}\frac{x^6}{\left(x^4+a^4\right)^2}dx$$ $$\int _0^{+\infty }\frac{x^6}{\left(x^4+a^4\right)^2}dx=i\pi \sum _k\:Res\left(f,\:z\left(k\right)\right)$$ $$Res\left(f,\:z\left(k\right)\right)=\lim _{z\to z\left(k\right)}\left(\frac{1}{\left(2-1\right)!}\left(\frac{d}{dz}\right)^{2-1}\frac{z^6\left(z-z\left(k\right)\right)^2}{\left(z^4+a^4\right)^2}\right)$$ $$z^4+a^4=z^4-z_k^4\implies\dfrac{z^6(z-z_k)^2}{(z^4+a^4)^2}=\dfrac{z^6}{(z^3+z_k z^2+z_k^2 z+z_k^3)^2}$$ $$Res\left(f,\:z_k\right)=\lim _{z\to \:z_k}\left(\frac{d}{dz}\left(\frac{z^6}{\left(z^3+z_kz^2+z_k^2z+z_k^3\right)^2}\right)\right)$$ $$Res\left(f,\:z_k\right)=\frac{2z_kz^5\left(z^2+2z_kz+3z_k^2\right)}{\left(z^3+z_kz^2+z_k^2z+z_k^3\right)^3}=\frac{2z_k^6\cdot 6z_k^2}{\left(4z_k^3\right)^3}$$ $$Res\left(f,\:z_k\right)=\frac{12z_k^8}{64z_k^9}=\frac{3}{16z_k}$$ $$\int _0^{+\infty }\frac{x^6}{\left(x^4+a^4\right)^2}dx=\frac{3i\pi }{16a}\sum _{k=0}^n\:e^{-\frac{\left(2k+1\right)}{4}i\pi }$$ We consider only the residues within the upper half plane, that is to say those corresponding to $k=0$ and $k=1$ . $$\int _0^{+\infty \:}\frac{x^6}{\left(x^4+a^4\right)^2}dx=\frac{3i\pi \:}{16a}\left(e^{-\frac{i\pi }{4}\:\:}+e^{-\frac{3i\pi \:}{4}\:\:}\right)$$ $$\int _0^{+\infty \:}\frac{x^6}{\left(x^4+a^4\right)^2}dx=\frac{3i\pi \:}{16a}\left(\frac{\sqrt{2}}{2}\:-i\frac{\sqrt{2}}{2}-\frac{\sqrt{2}}{2}-i\frac{\sqrt{2}}{2}\right)$$ $$\int _0^{+\infty \:}\frac{x^6}{\left(x^4+a^4\right)^2}dx=\frac{3\pi \sqrt{2}\:}{16a}$$","['integration', 'complex-analysis', 'rational-functions']"
3206737,UMVUE of $P(X_1 \ge t)$ for a two-parameter exponential distribution,"I'm attempting to find $(a)$ The UMVUE of $\lambda$ when $\theta$ is known. $(b)$ The UMVUE of $\theta$ when $\lambda$ is known. $(c)$ The UMVUE of $P(X_1 \ge t)$ for a fixed $t > \theta$ when $\lambda$ is known. I'm new to the concept of UMVUE and attempting to self-learn it through a mathematical statistics textbook. I would appreciate some feedback for $(a)$ and $(b)$ in terms of their correctness and some help with $(c)$ . I found a sufficient statistic $T = (X_{(1)}, \sum\limits_{i = 1 }^n {X_i })$ For $(a)$ , when $θ$ is known, $\sum\limits_{i = 1 }^n {X_i }$ is a sufficient and complete statistic for $λ$ . $E(\sum\limits_{i = 1 }^n {X_i }) = n(\lambda + \theta)$ Therefore $T_1 = \frac{\sum\limits_{i = 1 }^n {X_i }}{n} - \theta = \bar X - \theta$ is the UMVUE of $\lambda$ . For $(b)$ , when $\lambda$ is known, $X_{(1)}$ is sufficient and complete for $\theta$ . $E(X_{(1)}) = \lambda + \theta$ . Therefore $T_2 = X_{(1)} - \lambda$ is the UMVUE of $\theta$ . For $(c)$ , I'm not completely sure how to go about doing this but I'm assuming that the UMVUE would be $P(X_1 \ge t\mid T)$ and that it would be 1 when $t<X_{(1)}$ but I'm unsure how to deal with the other case and whether this is indeed correct.","['statistical-inference', 'statistics', 'probability-distributions', 'parameter-estimation', 'exponential-distribution']"
3206774,Possible eigenvalues of matrix $C = A(B^TA)^{-1}B^T$,"We also have the conditions that $A$ and $B$ are rectangular matrices such that $B^TA$ is square and invertible. Thus, we can assume that $A$ and $B$ have dimensions $p \times n$ and hence $B^TA$ has dimensions $n \times n$ . So, what I have done so far is that since $$C \times C = A(B^TA)^{-1}B^TA(B^TA)^{-1}B^T = A(B^TA)^{-1}B^T = C$$ we have $$ C^2 = C$$ So, by the fact that eigenvalues are roots of the characteristic polynomial, possible eigenvalues can be $0$ or $1$ . But isn't there a problem for the eigenvalue $0$ as if $Cx = 0$ for some non-zero vector $x$ then multiplying $B^T$ from the left (this can be done as $C$ has dimensions $p \times p$ and $B^T$ has dimensions $n \times p$ ) gives $B^TCx = 0$ which means $$B^TA(B^TA)^{-1}B^Tx = 0 \implies B^TAy = 0$$ for some non-zero $y$ , so this is contradicting that $B^TA$ is invertible. So does this mean that only possible eigenvalue is $1$ ? Or is it possible that $y$ can be a zero vector so I can't conclude anything about that? Edit : I think that $y$ can be the zero vector because in that case, we just need $B^Tx$ to be zero as $B^TA$ is invertible. $B^Tx = 0$ is possible for a non-zero $x$ , isn't it?","['matrices', 'proof-verification', 'linear-algebra', 'eigenvalues-eigenvectors']"
3206838,"The number of 5-digit numbers of the form abcde where a,b,c,d,e belong to ${0,1,2,...9}$ and $b = a + c$, $d = c + e $ are?","The number of 5-digit numbers of the form abcde where a,b,c,d,e belong to ${0,1,2,...9}$ and $b = a + c$ , $d = c + e $ are? I tried to reason out that out of the 5 digits we need to choose only $3$ , that is $a,c$ , and $e$ , while $b$ and $d$ will become fixed on the basis of those. Now, we also need to satisfy $a + c ≤ 9$ and $c + e ≤ 9$ . Solving the former equation gives us some pairs of $a$ and $c$ . But, this fixes c, I cannot do the same thing with the latter equation. It just seems like a intertwined puzzle I can't get hold of from any end. I may also add the solution given to this problem: I don't understand what they are trying to do here exactly.",['combinatorics']
3206851,Summing a multiplicative function,"$f(n)$ is a multiplicative function, meaning $f(m\cdot n)=f(m)\cdot f(n)$ . I want to evaluate the sum: $$(1)\qquad\sum_{k=1}^{n}f(m\cdot k)$$ over a fixed $m$ . Because $f$ is multiplicative, I can rewrite the sum as: $$(2)\qquad\sum_{k=1}^{n}f(m)\cdot f(k)$$ And because $m$ is fixed, I thought this sum is equal to: $$(3)\qquad f(m)\cdot \sum_{k=1}^{n} f(k)$$ But it's not, as simple paper & pencil check shows. I can easily evaluate the sum $\sum_{k=1}^{n} f(k)$ , so I tried to rewrite $(2)$ in terms of it. For example, suppose $f(n)$ is Euler's totient function, $\varphi(n)$ , known as the amount of numbers $<n$ that are comprime to $n$ . Suppose $m=4$ and I want to evaluate the sum up to $k=3$ , that is $\sum_{k=1}^{3}\varphi(4\cdot k)$ . The true sum would be written as $(1)$ & $(2)$ respectively as: $$\varphi(4)+\varphi(8)+\varphi(12) = \varphi(4)\cdot \varphi(1)+\varphi(4)\cdot \varphi(2)+\varphi(4)\cdot \varphi(3) = 10$$ In my wrong approach, the sum would be: $$\varphi(m)\cdot \sum_{k=1}^{n} \varphi(k)=\varphi(4)\cdot \biggl(\varphi(1)+\varphi(2)+\varphi(3)\biggl)= 2\cdot \space (1+1+2)=8$$ which is different than the original sum. I've noticed this is also true if $f(n)$ is the sum of divisors function too $\sigma_1(n)$ , and other multiplicative functions as well. My question is how can I rewrite $(2)$ in terms of $\sum_{k=1}^{n} f(k)$ or perhaps in another way too, and why is my approach wrong? Thanks.","['multiplicative-function', 'elementary-number-theory', 'functions']"
3206913,Geometry - Proving a common centroid.,"Triangle PQR is drawn. Through it's vertices are lines drawn which are
parallel to the opposite sides of the triangle. The new triangle formed
is ABC. Prove that these two triangles have a common centroid. I started by letting $M$ be the median of $[PQ]$ , and then prove that bisector of $[BC]$ from $A$ occurs at $R$ while $M$ is collinear to $[AP]$ . Firstly, I'm not sure whether or not this will suffice in proving they share a common centroid, and secondly I'm not sure where to start with the proof as setting up similar triangles from the parallel lines identity has lead to nothing.","['euclidean-geometry', 'vectors', 'geometry', 'geometric-transformation']"
3207021,Does the zero set of a real-analytic function in several variables form a subvariety?,"This is probably a very naive question: I am trying to understand if the zero-set of a real-analytic function in several variables can be ""wilder"" than the zero-set of a polynomial in several variables: Let $f:\mathbb{R}^n \to \mathbb{R}$ ( $n>1$ ) be a real-analytic function which is not identically zero, and set $Z=f^{-1}(0)$ . Can $Z$ always be realized as the zero set of a polynomial? (or a system of polynomial s )? I think that an equivalent ways to phrase this question are: 1. Is $Z$ Zariski closed? or 2. Does $Z$ form an algebraic subvariety of positive codimension in $\mathbb{R}^n$ ? However, I know almost nothing on algebraic geometry, so I am not sure about this.","['real-analysis', 'zariski-topology', 'algebraic-geometry', 'polynomials', 'analytic-functions']"
3207025,"Gradient of $f(W)=\sum_{j \neq {t}} \left[ \max\left(0, [ W x ]_j - \left[ W x \right]_{t} + \delta \right) \right] + \lambda \left\| W \right\|_F^2$","How to find the gradient of the following function \begin{align}
f(W) := \sum_{j \neq {t}} \left[ \max\left(0, [ W x ]_j - \left[ W x \right]_{t} + \delta \right) \right] + \lambda \left\| W \right\|_F^2 \ ,
\end{align} w.r.t. $W \in \mathbb{R}^{m \times n}$ matrix, where $x \in \mathbb{R}^n$ and $\delta, \lambda$ are known variables. The $j$ th element of a vector $y \in \mathbb{R}^n$ is denoted as $[y]_j$ .","['multivariable-calculus', 'matrix-calculus']"
3207039,[True/False]The polynomial $x^4+7x^3−13x^2+11x$ has exactly one real root.,"[True/False]The polynomial $x^4+7x^3−13x^2+11x$ has exactly one real
  root. I want to solve it without drawing the graph. Here is my idea. Note that $f(1)=1+7-13+11=6>0$ and $f(-1)=1-7-13-11=-30<0$ So we have at least one real root. Now since degree is $4$ we have $4$ roots but rest three can not be complex as they occur in pairs, so we must have another real root. So the statement is False Am I right? Thanks for reading and all the help.","['functions', 'real-analysis']"
3207060,"How to solve this volume by revolution about the y-axis, $y=2 \cos(x)$","The first step I took was to solve for $x$ . $y=2\cos(x) => x=\arccos(\frac{y}{2})$ Then I found the y values of the function and intersections between the graph and the axis $(0,2)$ and $(\frac{π}{2},0)$ I then integrated, $\int_0^2 π \cdot [\arccos(\frac{y}{2})]^2 \;dy$ and I solved this using the formula $\int \arccos(x) = x \cdot \arccos(x)-\sqrt{1-x^2}$ and from that I got a final answer of 7.28. 
However, my textbook has the answer as 7.17.
Can someone explain to me why I am close but still wrong?","['integration', 'trigonometry']"
3207094,The Hausdorff dimension of the zero set of a real analytic function,"Let $n>1$ , and let $f:\mathbb{R}^n \to \mathbb{R}$ be a real-analytic function which is not identically zero. Does $\dim_{\mathcal H}(f^{-1}(0)) \le n-1$ ? here $\dim_{\mathcal H}$ refers to the Hausdorff dimension. (I have read this claim in a paper, but there was no reference). I know that $f^{-1}(0)$ has Lebesgue measure zero. If this is false, is it true then that $\dim_{\mathcal H}(f^{-1}(0)) < n$ ? Any reference would be appreciated.","['dimension-theory-analysis', 'geometric-measure-theory', 'reference-request', 'real-analysis', 'analytic-functions']"
3207124,Sufficient conditions for vanishing module of Kähler differentials,"It is a standard fact that the module of Kähler differentials $\Omega_L$ of a finite separable extension of a field $k$ is equal to 0. 
I also know that for a ring B and a finite extension $k \rightarrow B$ a sufficient condition for the module of differentials to vanish is that $B$ is a finite product of separable extensions of $k$ . Question .
Is it possible to lift this result to more general extensions $A\rightarrow B$ where $A$ and $B$ are both rings? Of course with some additional hypothesis on the rings and on the extension.","['etale-cohomology', 'separable-extension', 'ring-theory', 'algebraic-geometry', 'commutative-algebra']"
3207129,Why is the bottom limit of the conditional probability $x$ in Bayesian Statistics?,"I am learning bayesian statistics and was stuck when trying to understand the following example: Romeo and Juliet start dating, but Juliet will be late on any date by a random amount X, uniformly distributed over the interval [0, $\theta$ ]. The parameter $\theta$ is unknown and is modelled as the value of a random variable $\Theta$ , uniformly distributed between zero and one hour. Assuming that Juliet was late by an amount $x$ on their first date, how should Romeo use this information to update the distribution of $\Theta$ ? The sample solution is as follows: $f_\Theta(\theta)$ = 1 if $0 \leq \theta \leq 1$ , 0 otherwise $f_{X|\Theta}(x|\theta) = \frac{1}{\theta}$ if $0 \leq x \leq \theta$ , 0 otherwise The posterior pdf is: $$
f_{\Theta|X} = \frac{f_{\Theta}(\theta)f_{X|\Theta}(x|\theta)}{\int_0^1{f_\Theta(\theta')f_{X|\Theta}(x|\theta')d\theta'}}
$$ The following step is where I have a problem: $$
\frac{1/\theta}{\int_x^1{1/\theta'}d\theta'}
$$ How did the limits for the integeral go from (0, 1) to (x, 1). I cannot find the justification for this step or why the limits is changing. Thank you for your help.","['statistical-inference', 'statistics', 'bayesian', 'probability']"
3207133,Maximum area of triangle inscribed in an ellipse,"If a triangle is inscribed in an ellipse $\frac{x^2}{25}+\frac{y^2}{16}=1$ , Find the Maximum area of Triangle My try: Let $A(5\cos p, 4\sin p)$ , $B(5\cos q, 4\sin q)$ and $C(5\cos r, 4\sin r)$ be vertices of the triangle Its area is: $$\Delta=0.5 \times\begin{vmatrix}
5\cos p &4 \sin p  &1 \\ 
 5 \cos q& 4 \sin q &1 \\ 
5 \cos r &4 \sin r  & 1
\end{vmatrix}=10\begin{vmatrix}
\cos p & \sin p &1 \\ 
\cos q & \sin q &1 \\ 
 \cos r&\sin r  & 1
\end{vmatrix}$$ $$\Delta=40\sin\left(\frac{p-q}{2}\right)\sin\left(\frac{q-r}{2}\right)\sin\left(\frac{r-p}{2}\right)$$ EDIT: According to the mind blowing hint given by Mohammad Zuhair khan: $p \gt q \gt r$ $$p=q+m$$ $$q=r+n$$ where $m,n \gt 0$ So we have $$p-q=m$$ $$q-r=n$$ $$r-p=-(m+n)$$ Then $$\Delta=40 \sin\left(\frac{m}{2}\right)\sin\left(\frac{n}{2}\right)
\sin\left(\frac{m+n}{2}\right)$$ Ignoring the negative sign, since its is Area Now $$\Delta(m,n)=10(\sin m+\sin n-\sin(m+n))$$ Using Partial differentiation for optimization we have: $$\frac{\partial \Delta}{\partial m}=0$$ $$\cos m=\cos(m+n)$$ $$m=2\pi-m-n$$ $$2m+n=2\pi$$ Like wise by symmetry: $$2n+m=2\pi$$ So $$m=n=\frac{2\pi}{3}$$ Hence $$\Delta_{max}=10(\frac{\sqrt{3}}{2}+\frac{\sqrt{3}}{2}
+\frac{\sqrt{3}}{2})=15\sqrt{3}$$ But how to know using partial differentiation Maximum occurs? Can any one give me a link when does partial differentiation applicable for optimization problems?","['analytic-geometry', 'conic-sections', 'maxima-minima', 'triangles', 'trigonometry']"
3207177,Prove that for every integer $n\geq 0$ it follows that $24 | (5^{2n})-1$,"Prove that for every integer $n\geq 0$ it follows that $24 | (5^{2n})-1$ Clearly, we have $24 | (5^{2n})=25^n$ . How can I prove this question, can you help? Thanks...","['elementary-set-theory', 'elementary-number-theory']"
3207232,Minimum distance between independent points drawn from the normal distribution,"Let $x_1,\ldots,x_N$ be $N$ samples drawn independently from the normal distribution $\mathcal{N}(0,1)$ . Let $\Delta_{ij} = | x_i - x_j |$ be the distance between the $i$ -th and the $j$ -th sample. Let $M_N = \min_{ij} \Delta_{ij}$ be the minimal distance (nearest neighbor distance) between all pairs of points. Is the distribution of $M_N$ easy to compute? I am particularly interested in making a statement of the form "" $P(M_N \ge \mu) \ge 1 - \epsilon$ "", computing the limit $\mu$ for a given $\epsilon$ . The bound does not need to be tight, but it should not be catastrophically off.
I am considering the non asymptotic case, $N$ will be between 1 and 10000, $\epsilon$ will be small (of the order of $10^{-6}$ to $10^{-12}$ ) -- which seems to hinder Monte Carlo computations. (I have seen plenty of posts on MathOverflow and the Mathematics Stack Exchange about samples from the uniform distribution -- but nothing about normal variables.)","['geometry', 'probability']"
3207240,Compute this following integral without Fourier series : $\int_0^{\pi/4}x\ln(\tan x)dx$,"Compute the following integration without harmonic series or Fourier series : $I=\displaystyle\int_0^{\frac{π}{4}}x\ln(\tan x)dx$ Wolfram alpha give $I=\frac{7\zeta(3)-4πC}{16}$ Where $C$ : Catalan's constant My try : put : $y=\tan x$ then $dx=\frac{dy}{1+y^2}$ Then : $I=\displaystyle\int_0^{1}\frac{\arctan x\ln x}{1+x^2}dx$ Then define : $I(a,b)=\displaystyle \int_0^{1}\frac{\arctan (ax)\ln x}{1+x^2}dx$ Then : $\frac{dI(a,b)}{da}=\displaystyle\int_0^{1}\frac{x\ln x}{(1+a^{2}x^{2})(1+x^2)}dx$ Use partial fraction $\frac{dI(a,b)}{da}$ $=\displaystyle\int_0^{1}\frac{a^{2}x\ln x}{(1+a^{2}x^{2})(a^{2}-1)}dx$ $-\displaystyle\int_0^{1}\frac{x\ln x}{(1+a^{2}x^{2})(a^{2}-1)}dx$ But I don't know how I complete Please give me ideas to approach it .","['integration', 'definite-integrals', 'polylogarithm', 'closed-form', 'catalans-constant']"
3207244,Inverse of $1-g-g^{-1}$ in group ring $\mathbb{Z}[G]$ for $o(g)=5$.,"I'm trying to prove that if $G$ is a group and $g\in G$ is an element of order $5$ then $x=1-g-g^{-1}$ is an unit element in the group ring $\mathbb{Z}[G]$ . I'm trying to find an explicit inverse  by computing $xg^r$ for $r=1,2,3,4$ and trying to add them in a good way to get $1$ . But so far I can't find a good ""combination"". Any hints on how to compute an inverse for this element?. [EDIT] I found a solution for this but it is probably the hardest way. I'm trying to find an inverse of the form $a+bg+cg^2+dg^3+eg^4$ , so i take the equation $x(a+bg+cg^2+dg^3+eg^4)=1$ and it becomes a linear algebra problem. I found by solving the $5\times 5$ integer linear system that $a=1,b=-1,c=0,d=-1,e=0$ is a solution, i.e., $x(1-g-g^4)=1$ . 
I think there should be other ways to approach these kind of exercises.","['ring-theory', 'abstract-algebra']"
3207257,Summing the totient function $\sum_{k=1}^n \varphi(k)$,"I explored some computer science/number theory challenges sites for fun, and they presented the following problem, exactly as follows: Let $$P(n) = \sum_{k=1}^n \varphi(k)$$ Find $P(10^{16})$ I searched for quite a while about this and tried different approaches: Using the formula for $$\varphi(n)= n \cdot \prod_{i=1}^k \frac{p_i-1}{p_i}$$ I tried to calculate each $\varphi(n)$ in range, but this becomes very inefficient for large $n$ . I could get as far as $10^7$ with this approach. Beyond this it just gets too slow. I tried a different one, more direct. Wikipedia and Wolfram Alpha suggest similiar formulas for directly calculating $P(n)$ : $$P(n) = \sum_{k=1}^n \varphi(k)= \frac12 \cdot \biggl (1+ \sum_{k=1}^n\mu (k)\cdot \lfloor {\frac nk} \rfloor^2\biggl)$$ This formula seemed a lot more promising. I tried it and managed to get alot further than $10^7$ but still far from the target. With pre-calculating a sieve of the Moebius function, I could get to a bit less than $10^9$ . My memory was insufficient, and couldn't compute anymore values in a sieve. And even if I could, it still takes a long time and is very far from $10^{16}$ . Here is part of the code that I used for my 2nd approach written in Java: public static BigInteger PhiSummatoryFunction (long limit)
{
    BigInteger sum = BigInteger.ZERO;
    int [] m = MoebiusSieve(limit);
    for (int i=1;i<m.length;i++)
        sum=sum.add(BigInteger.valueOf((long) (m[i]*Math.floor(limit/i)*Math.floor(limit/i))));
    return sum.add(BigInteger.ONE).divide(BigInteger.ONE.add(BigInteger.ONE));
} Where MoebiusSieve is a function that computes the Moebius function values up to a certain limit in a sieve, using an eratosthenes-like method. After understanding and implementing the recursive method suggested in a link provided in the comments: $$P(n) = \frac {n(n+1)}{2} - \sum_{i=2}^\sqrt n P(\lfloor \frac ni \rfloor) - \sum_{j=1}^\sqrt n P(j) \cdot (\lfloor \frac nj \rfloor - \lfloor \frac n{j+1} \rfloor)$$ I can compute values up to $P(10^{11})$ , and with maximum memory allocation, pre-computing as many $\varphi(n)$ as possible and consequently all $P(n)$ that I can for memoization, I can compute $P(10^{12})$ in just over 20 minutes. A major improvement but still a little far from $P(10^{16})$ . It's ok if the computation takes a bit longer, but I fear $P(10^{16})$ would take exponentially longer time, judging by the ""jump"" in computation time between $P(10^{11})$ and $P(10^{12})$ . My memory allows me to ""save"" up to $350,000,000 \space φ(n)$ values OR up to $700,000,000 \space μ(k)$ values. Perhaps there is a way to perform the summation using μ(k) values rather than φ(n)?. All my computations suggest and show that my recursion is the prominent time consumer. This is obvious, but I am sure it takes longer than it should, as pointed out by qwr . So I am posting below the recursion code, with some documentation. It seems to me that this is the right way to do this computation, but my implementation is not optimal. public static BigInteger phiR (long limit, long [] s) // limit is 10^t, s is the sieve of precomputed values of `P(n)`. Can store maximum 350,000,000 values
{                                                                                                                                               
    if (limit<s.length)                                 
        return BigInteger.valueOf(s[(int) limit]);
    BigInteger sum = BigInteger.valueOf(limit).multiply(BigInteger.valueOf(limit).add(BigInteger.ONE)).divide(BigInteger.valueOf(2)); // this corresponds to the n'th triangular number
    BigInteger midsum1=BigInteger.ZERO;
    BigInteger midsum2=BigInteger.ZERO;
    for (long m=2;m*m<=limit;m++) // computing the first sum, first for changing floor(limit/m) values
        midsum1=midsum1.add(phiR((long) Math.floor(limit/m),s));
    for (long d=1;d*d<=limit;d++) // computing the second sum
        if ((double)d!=Math.floor(limit/d))
            midsum2=midsum2.add(BigInteger.valueOf((long) (Math.floor(limit/d)-Math.floor(limit/(d+1)))).multiply(phiR(d,s)));
    sum=sum.subtract(midsum1).subtract(midsum2);
    return sum;
} I was suggested to use dictinaries by qwr , in addition to the array, for big values of $n$ , but I don't know anything about it. Can another improvement be made to make the time frame a day or so?","['number-theory', 'functions', 'computer-science']"
3207292,The limit of $((1+x)^{1/x}-e)/x\;$ as $\;x$ tends to $ 0$ [duplicate],"This question already has answers here : Limit as $x\to 0$ of $\frac{(1+x)^{1/x}-e}{x}$ (6 answers) Closed 4 years ago . So, I have to solve the limit problem using a derivative. The problem is as follows: $$\lim_{x\to0}\frac{(1+x)^{1/x}-e}{x}$$ I really don't know what to do. Can someone help?","['limits', 'derivatives', 'exponential-function']"
3207333,$F$-related Vector fields and surjective submersion,"I want to show this fact: Let $M, N$ be two manifolds, $\pi : M \to N$ a surjective submersion
  and $X$ a vector field over $M$ . If $d \pi_q(X_q) = d \pi_p(X_p)$ whenever $\pi(p) = \pi(q)$ then there exists a unique vector field $Y$ over $N$ such that $Y_{\pi(p)} = d \pi_{p}(X_p)$ for every $p \in M$ . I don't know where to start. I could define $Y : N \to TN$ such that $Y_p = d \pi_q (X_q)$ where $q$ is an element of $\pi^{-1}(p)$ , but that seems to be too... ugly and not much rigorous, even if it's the right path I can't see how $Y$ can be smooth. Since $\pi$ is a submersion I tried to use its normal local form but following this road is even worse: I can't even see how to build properly $Y$ .
Can you give me a hint please? Thanks. English is not my mother tongue, please excuse any errors on my part.","['vector-fields', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
3207375,How to solve this $3<x^2-4<x+1$,"Solve for, x $$3<x^2-4<x+1 $$ Attempt: $$7<x^2<x+5 $$ This is difficult. Solving this equation $$3x-3<6$$ it is easy. $$3x<9$$ $$x<3$$","['algebra-precalculus', 'inequality']"
3207435,Let $A$ be an $n*n$ matrix such that $A^3=A^2+A-I$. If $A$ Is diagonalizable Show that $A=A^{-1}$,"Let $A$ be an $n*n$ matrix such that $A^3=A^2+A-I$ . Show that $A$ is invertible Suppose in $A$ is diagonalizable. Show that $A=A^{-1}$ For the first part I managed to do it by a rearrangement, $$I=A^{2}+A-A^{3}=A(A+I-A^2)$$ Thus $A+I-A^2$ is the right inverse and simillarly we have $A+I-A^2$ as the left inverse. Hence $A$ is invertible. But for part 2. What I was able to do is: $A^{-1}=A+I-A^2=A+(PDP^{-1})(PDP^{-1})^{-1}-PD^{2}P^{-1}$ . But here after I don't see how should I proceed.","['matrices', 'diagonalization', 'inverse']"
3207441,"Let $X,Y,X_1,X_2,\ldots$ be i.i.d. and $\phi(x,y)$ a test function. Does $\frac{1}{N^2}\sum_{i,j}\phi(X_i,X_j)\to\mathbb E\phi(X,Y)$ a.s.?","Suppose we are given a distribution $\mu$ on $\mathbb R^d$ , and a smooth function $\phi:\mathbb R^d\times\mathbb R^d\to\mathbb R$ with compact support. Let $X_i$ be i.i.d. random variables with distribution $\mu$ . Then is it the case that $$
\frac{1}{N^2}\sum_{i,j=1}^N\phi(X_i,X_j)\to\int_{\mathbb R^d\times\mathbb R^d}\!\phi(x,y)\,\mathrm d\mu(x)\,\mathrm d\mu(y)?
$$ For single-variable $\phi$ , this is just the strong law of large numbers, but I don't quite see how to prove it here.","['probability-theory', 'probability']"
3207452,Finding solution to linear equations using integrating factors,"Here's a couple of problems: $$2xy' + y = 2 \sqrt{x}$$ so according to my book, I should get it into this form: so let's divide by 2x: $$y' + \frac{1}{2x} * y = \frac{2x^{\frac{1}{2}}}{2x} = x^{\frac{-1}{2}}$$ So is the integrating factor = $$I(x) = e^{\int \frac{1}{2x}} = e^{\frac{1}{2} ln(2x)}$$ A bit stuck from here. How does that integral reduce? EDIT going further: $$I(x) = \sqrt{2x}$$ so multiplying both sides: $$\sqrt{2x} \frac{dy}{dx} + \frac{1}{\sqrt{2x}} y = \sqrt{2x}x^{\frac{-1}{2}} = \sqrt{2}$$ $$(\sqrt{2x}y)' = \sqrt{2}$$ $$\sqrt{2x}y = \sqrt{2}x + c$$ $$y = \frac{\sqrt{2}x + c}{\sqrt{2x}} = x^{\frac{1}{2}} + \frac{c}{\sqrt{2x}}$$ When plugging this back in... It's not equal. Did I do something wrong? $$xy' + y = \sqrt{x}$$ divide by x: $$\frac{dy}{dx} + \frac{1}{x}y = x^{\frac{-1}{2}}$$ so the integrating factor is: $e^{\int \frac{1}{x}dx} = x$ $$x * \frac{dy}{dx} + y = x^{\frac{1}{2}}$$ $$(xy)' = x^{\frac{1}{2}}$$ $$xy = \frac{2}{3} x^{\frac{3}{2}}$$ $$y = \frac{2}{3} x^{\frac{1}{2}}$$ Is that right?",['ordinary-differential-equations']
3207471,Representation of the elements of the dual space of the product of topological vector spaces,"Assume $(X_i,\mathcal{T}_i)$ , $i \in I$ is a family of topological vector spaces and $X:=\prod\limits_{i\in I} X_i$ with the product topology $\mathcal{T}$ .
Let $\pi_i: X \rightarrow X_i$ be the canonical projections and $\iota_i: X_i \rightarrow X$ the canonical embeddings. I want to prove that for all elements of the topological dual space $f \in (X,\mathcal{T})'$ there are finitely many indices $i_1,...,i_m \in I$ and $f_{i_1},...,f_{i_m} \in (X_i,\mathcal{T}_i)'$ with $f=\sum\limits_{j=1}^m f_{i_j} \circ \pi_{i_j}$ . My idea so far was to define $f_i:=f\circ \iota_i$ which is linear and continuous and then to show that the set $Y:=\{(x_i)_{i\in I}:x_i=0 
~\text{for almost all}~ i \in I\}$ is dense in the set $X$ . Then I only need to show the the equality for the element in $Y$ . $\forall y \in Y: y = \sum\limits_{i\in I} (\iota_{i} \circ \pi_{i})(y)$ This sum is finite because there are only finitely many components which are not zero, therefore I can write the following: $\forall y \in Y: f(y) = \sum\limits_{i\in I} f((\iota_{i}(\pi_{i}(y))) = \sum\limits_{i\in I} (f_i \circ \pi_{i})(y)))$ Can someone please help me how to get the indices $i_1,...,i_m$ and reduce the sum I have got so far to the expression which I need?","['topological-vector-spaces', 'analysis', 'functional-analysis', 'dual-spaces', 'general-topology']"
3207506,"Existence of non decreasing sequence of continuous functions aproximating $f$ in $L_p(0,\infty)$","I know that the continuous functions $f:(0,\infty) \rightarrow R $ are dense in $L_p(0,\infty)$ , with respect to the norm $|| \space||_p$ . Therefore, if $f\in L_p(0,\infty)$ then there exists a sequence of continous functions $\{f_n\}$ in $L_p$ such that $f_n \rightarrow f$ . I'm wondering if there exists a sequence that does this, but also is non-decreasing, meaning $f_{n+1}\geq f_n$ pointwise por each $n$ . I believe this to be true, but I haven't been able to prove it. So, is this true? If it is, I would appreciete any tips on how to prove it. Thanks!",['measure-theory']
3207513,"Prove that for any integer $a$, $9\nmid(a^2-3)$.","I'd like to know if my proof is a valid way of proving this and additionally if there is a better way of going about this? I'm relatively new to discrete mathematics so any critique would be very helpful for me to improve my style and general way of going about these proofs. Proof: Suppose not. That is, suppose $a\in\mathbb{Z}$ and $9\mid(a^2-3)$ . By definition of divisibility, $a^2-3=9p$ for some $p\in\mathbb{Z}$ . By the quotient-remainder theorem, $a$ can be written in one of the forms $$3q\text{ or }3q+1\text{ or }3q+2$$ for some $q\in\mathbb{Z}$ . Case 1 ( $a=3q$ for some $q\in\mathbb{Z}$ ): Since $a=3q$ , $$a^2-3=(3q)^2-3=9q^2-3=9p\Rightarrow9(q^2-p)=3\Rightarrow3(q^2-p)=1\text{.}$$ $q^2-p\in\mathbb{Z}\because\mathbb{Z}$ is closed under addition and multiplication but $q^2-p=1/3\notin\mathbb{Z}\Rightarrow$ a contradiction. Case 2 ( $a=3q+1$ for some $q\in\mathbb{Z}$ ): Since $a=3q+1$ , $$a^2-3=(3q+1)^2-3=9q^2+6q-2=9p\Rightarrow3(3q^2+2q-3p)=2\text{.}$$ $3q^2+2q-3p\in\mathbb{Z}\because\mathbb{Z}$ is closed under addition and multiplication but $3q^2+2q-3p=2/3\notin\mathbb{Z}\Rightarrow$ a contradiction. Case 3 ( $a=3q+2$ for some $q\in\mathbb{Z}$ ): Since $a=3q+2$ , $$a^2-3=(3q+2)^2-3=9q^2+12q+1=9p\Rightarrow3(3q^2+4q-3p)=-1\text{.}$$ $3q^2+4q-3p\in\mathbb{Z}\because\mathbb{Z}$ is closed under addition and multiplication but $3q^2+4q-3p=-1/3\notin\mathbb{Z}\Rightarrow$ a contradiction. $$\tag*{$\blacksquare$}$$","['divisibility', 'elementary-number-theory', 'proof-verification', 'integers', 'discrete-mathematics']"
3207517,"for $p>0$, when does this integration:$\int_0^{\infty} x^pe^{-x^8\sin^2x}dx$ converge?","for $p>0$ ，find the value range of $p$ , which makes this integration: $\displaystyle\int_0^{\infty} x^pe^{-x^8\sin^2x}dx$ converge. I tried to divide $(0,\infty)$ into $(n\pi,(n+1)\pi)$ , but i met difficulty estimating $\displaystyle\int_0^{\pi} (x+n \pi)^pe^{-(x+n \pi)^8\sin^2x}dx$ My teacher says it is $O(n^{p-4})$ , but i think it is wrong.","['integration', 'convergence-divergence', 'improper-integrals']"
3207545,Find an explicit formula for the recurrence relation $a_n = 5_{an−1} + 6_{an−2}$ with initial conditions $a_1$ = 5 and $a_2$ = 11.,So here is what I did $a_n = 5_{an−1} + 6_{an−2}$ $a_n - 5_{an−1} - 6_{an−2} = 0$ which becomes $t^2 -5t -6$ $(t+1)(t-6)$ $t = -1$ and $t= 6$ then we have $a_n = $$-1^nB + 6^nD$ and so using $a_1 = 5 \ and \ a_2 = 11$ $5 = $$ -1B + 6D$ $11= $$ 1B + 36D$ $16 = $$ 42D$ so D = $  \frac 8{21}$ and following the same process B = $  \frac {35}{16}$ $a_n = $$-1^n $$  \frac {35}{16}$ + $6^n$$  \frac 8{21}$ Is this correct? It worked out so not nicely number wise I wasn't sure.,"['proof-verification', 'recurrence-relations', 'discrete-mathematics']"
3207563,Maximum of function of three variables on the unit cube,"I am looking to prove that the function $$f(x,y,z) = \frac{x(1-x)y(1-y)z(1-z)}{1 - (1-xy)z}$$ attains it's maximum at a point within the unit cube $[0,1] \times [0,1] \times [0,1]$ and NOT on the boundary. Wolfram Alpha confirms that the max is attained not on the boundary, but actually within the cube. I have been able to show that there is a local maximum which gives this value inside the cube, but I can't see how to show that the values at the boundary don't go to infinity. For example, if we approach the vertex $(x,y,z) = (0,0,1)$ we get $0$ over $0$ . How do I know that the function doesn't go to infinity as we tend to this vertex? Many thanks in advance.","['limits', 'calculus', 'real-analysis']"
3207569,Krull Topology on Galois Groups (two equivalent(?) definitions).,"I'm starting to study Infinite Galois Theory and its relation with Profinite Groups, but I'm having troubles with basic definitions. Definition 1. Let $K/F$ a Galois extension. Write $$\mathcal{F} = \{L \mid L \text{ is a subfield of }K\text{ s.t. } L/F\text{ is a finite Galois extension}\}.$$ We define a topology in $\mathrm{Gak}(K/F)$ by taking as a base of open neighborhoods of $1$ the family of subgroups $$\mathcal{N} = \{\mathrm{Gal}(K/L) \mid L \in \mathcal{F}\}.$$ Definition 2. The Krull Topology on $\mathrm{Gal}(K/F)$ is defined as follows: A subset $X$ of $\mathrm{Gal}(K/F)$ is open if is empty or $X = \bigcup_{i}g_{i}N_{i}$ for some $g_{i} \in G$ and $N_{i} \in \mathcal{N}$ . We can show that, according to definition 2, the basis of Krull Topology is $$\{gN \mid g \in G, N \in \mathcal{N}\},$$ but I just can see that taking $g = 1$ , the definition 2 becomes the definition 1. Questions: How can I see that 1 and 2 defines the same topology? Maybe it's a stupid question, but Why defining the open neighborhoods of $1$ it's enough to generate a topology? I can see why the definition 2 works. Unfortunately, my book uses the definition 1. Thus, I would like to understand why that definition works and is equivalent to the second. Thank you for any help!","['galois-theory', 'group-theory', 'abstract-algebra', 'profinite-groups']"
3207589,How to prove that the following matrices in $M_p(\Bbb F_p)$ is similar,"How to prove that the following matrices in $M_p(\Bbb F_p)$ is similar: Consider two matrices $$(a_{ij})=
    \begin{pmatrix}
    1 & 1 & 0 & \cdots & 0 & 0 \\
    0 & 1 & 1 & \cdots & 0 & 0\\
    0 & 0 & 1 & \cdots & 0 & 0\\
    \vdots & \vdots & \vdots& \ddots  & \vdots &\vdots\\
    0 & 0 & 0 &  \cdots &  1 & 1\\
    0 & 0 & 0 &  \cdots &  0 & 1\\
    \end{pmatrix}$$ and $$(b_{ij})=
    \begin{pmatrix}
    0 & 0 & 0 & \cdots & 0 & 1 \\
    1 & 0 & 0 & \cdots & 0 & 0\\
    0 & 1 & 0 & \cdots & 0 & 0\\
    \vdots & \vdots & \vdots& \vdots  & \vdots &\vdots\\
    0 & 0 & 0 &  \cdots &  1 & 0\\
    \end{pmatrix}$$ I can observe that the characteristic polynomial of $(a_{ij})$ =minimal polynomial of $(a_{ij})$ = $(x-1)^p$ and the characteristic polynomial of $(b_{ij})=x^p-1=(x-1)^p$ Now how do I argue from here that the minimal polynomial of $b_{ij}$ is also $(x-1)^p$ ?","['jordan-normal-form', 'modules', 'matrices', 'minimal-polynomials', 'linear-algebra']"
3207625,"Is $x \mapsto d(x, A)$ a quotient map?","Consider a metric space $(X, d)$ and a nonempty closed set $A \subset X$ .
Is the map $d_A : X \to \mathbb{R}, x \mapsto d(x, A)$ a quotient map
when restricted to its image? Note $d(x, A) = \inf\{ d(x, a) : a \in A \}$ . If this is not true, can a counterexample exist in $\mathbb{R}^2$ ? Some partial results follow. If $X$ is compact, then $d_{A}$ is closed. This follows 
since, more generally, continuous maps from compact spaces to Hausdorff spaces are closed. If $X$ has the Heine-Borel property and $A$ is compact then $d_A$ is closed. For $B \subset X$ closed and $y \in \overline{d_A(B)}$ there exist $x_n \in B$ such that $d_{A}(x_n) \to y$ . Exercise 27.2b of Munkres 2ed states that since $A$ is compact, $d(x, A) = d(x, a)$ for some $a \in A$ . So there exist $a_n \in A$ such that $d(x_n, a_n) \to y$ . Since $A$ is compact there exists a subsequence $a_{i_n}$ of $a_n$ such that $a_{i_n} \to a$ . Then $d(x_{i_n}, a) \le d(x_{i_n}, a_{i_n}) + d(a_{i_n}, a)$ for all $n$ , and
the right-hand side of this inequality is eventually less than $y + 1$ . So $x_{i_n}$ is eventually contained in a closed bounded closed set, and by the Heine-Borel property there is a subsequence $x_{j_n}$ of $x_{i_n}$ such that $x_{j_n} \to x$ . Since $B$ is closed, $x \in B$ . Then continuity and the Hausdorff property imply $d_{A}(x) = y$ , implying $y \in d_{A}(B)$ . So the claim follows. In the general case, is $d_A$ always a closed map when $A$ is compact? $d_A$ is not generally a closed map, even when $A$ is closed. Consider the case where $X = \mathbb{R}^2$ and $A$ is the $x$ -axis. Then $d_A$ maps the graph of the exponential
function to $(0, \infty)$ .","['general-topology', 'metric-spaces']"
3207638,Green theorem intuition,What I have a hard time understanding is the connection between line integrals of vector fields and Greens theorem. It was explained that taking lines integrals of parametrized curves is to be interpreted as the work done over the curve. However what Greens theorem provides is that we could write this in-terms of a double integral of the area. Bounded by a closed curve. What are we then calculating? Is it still the work over a closed curve?,"['greens-theorem', 'multivariable-calculus']"
3207739,"$a_n=(1-\frac{1}{n})a_{n-1}+\frac{1}{n}a_{n-2}$, $\lim_{n\to \infty}a_n$ is","Given $a_1,a_2,n\in \mathbb N$ $$a_n=(1-\frac{1}{n})a_{n-1}+\frac{1}{n}a_{n-2}$$ Then $\lim_{n\to \infty}a_n$ is (A) $2(a_2-a_1)+a_1e^{-1}$ (B) $2(a_1-a_2)e^{-1}+a_2$ (C) $2(a_1-a_2)e^{-1}+a_1$ (D) $2(a_2-a_1)e^{-1}+a_1$ My attempt, $a_1,a_2\in \mathbb N$ $$a_3=(1-\frac{1}{3})a_{2}+\frac{1}{3}a_{1}$$ $$a_4=(1-\frac{1}{4})a_{3}+\frac{1}{4}a_{2}$$ $$=(1-\frac{1}{4})((1-\frac{1}{3})a_{2}+\frac{1}{3}a_{1})+\frac{1}{4}a_{2}$$ $$=(1-\frac{1}{4})(1-\frac{1}{3})a_{2}+(1-\frac{1}{4})\frac{1}{3}a_{1}$$ $$a_5=(1-\frac{1}{5})a_{4}+\frac{1}{5}a_{3}$$ $$=(1-\frac{1}{5})((1-\frac{1}{4})(1-\frac{1}{3})a_{2}+(1-\frac{1}{4})\frac{1}{3}a_{1})+\frac{1}{5}((1-\frac{1}{3})a_{2}+\frac{1}{3}a_{1})$$ But I am not able to conclude from here, I couldn't able to generalise anything from here.","['sequences-and-series', 'real-analysis']"
3207744,Using strong induction to prove divisibility statements,"I need to prove that for $n \in \mathbb{N}$ odd, $a,b \in \mathbb{Z}$ , $a \neq b$ , $a+b \ | \ a^n + b^n$ . Does this require strong induction on $n$ ? $$p(n) = \{ n\in \mathbb{N} : a +b \ | \ a^{2n-1} + b^{2n-1} \}$$ The base case ( $n=1$ ) checks out. I'd then have to try to prove that if $p(k)$ is true for $k <n+1$ , $p(n+1)$ . $$ a +b \ | \ a^{2n-1} + b^{2n-1} \iff a +b \ | \ (a^{2n-1} + b^{2n-1})(a^2 + b^2) = a^{2n+1} + b^{2n+1} + (a^2b^2)(a^{2n-3} + b^{2n-3})$$ Since by assumption $ a +b \ | \ a^{2n-3} + b^{2n-3}$ , we have that $ a +b \ | \ a^{2n+1} + b^{2n+1}$ . Is this reasoning correct?","['elementary-number-theory', 'induction', 'divisibility', 'discrete-mathematics']"
3207870,Are there generalised rules for generating heuristics from data?,"Heuristics seems to be more of an art than a science, like a gut-feel supported by data; I might be wrong. Are there algorithms for mathematically generating heuristics from data, like pruning a Bayesian network? Things like the Reichenbach Common Cause principle comes to mind. Is there a branch of mathematics that is specifically applicable here? Maybe a generalised way of expressing discrete data as a function in the way a Taylor series estimates a sine wave? I'll do the reading I just need some pointers. Any help will be appreciated.","['statistical-inference', 'statistics', 'probability-distributions']"
3207884,Probability of ⁿC₇ being divisible by 12,"Let n be a natural number, then, 1.) Probability that ⁿC₇ is divisible by 7.
This one I could solve by observing a pattern in by writing 7 consecutive digits, I observed that for every 7 consecutive natural numbers starting from 7, there was only 1 value of n which made ⁿC₇ divisible by 7. Hence, the required probability was 1/7. Edit 1: I realised that I did a mistake while calculating and got the answer by mistake, but the answer given in the book  is 1/7 . Edit 2: as pointed out in the comments, that for the condition doesn't hold true for any n<49, I did some rigorous calculation and found that all natural numbers from 
49≤n<98 , only 7 satisfy the given condition . I found the same for the next 49 numbers. Can this be generalised to all natural numbers? This gives the probability 7/49 , = 1/7. 2.) Probability that ⁿC₇ is divisible by 12.
I tried this the same way I did the above question but couldn't see any simple pattern for 12. Is there a general, more elegant way to solve these kind of problems?","['elementary-number-theory', 'divisibility', 'probability']"
3207930,Population vs Sampling Frame vs Sample,"Could someone please explain how the sampling frame is different from population and sample? I understand that the population is all the sampling unit that match our criteria for the study. And the sample is those select few who participate in the study. Now, the different answers I have gone through suggests that the sampling frame is from where you draw your sample. But don't we draw our sample from the population? And if the sampling frame defines the criteria for sampling, then how that criterion is different from the criteria we laid down to define our population. Hope I am clear with the question!!
Thanks in advance!!","['statistics', 'sampling']"
3207950,Number of lattice points inside a circle,"The number of lattice points inside the circle $x^2+y^2=a^2$ can not be Options $(a)\; 202\;\;\; (b)\; 203\;\;\; (c)\; 204\;\;\; (d)\; 205$ Try: i have an idea of number of integer points on the circle $x^2+y^2=a^2$ Let $x,y\in\{4n,4n+1,4n+2,4n+3\}$ But no idea how to find number of integer points inside the circle. Could some help me to solve it , Thanks","['integer-lattices', 'combinatorics']"
3207958,Why do connected oriented manifolds have compactly supported forms with integral one but with support contained in a given open proper subset?,"My book is From Calculus to Cohomology by Ib Madsen and Jørgen Tornehave. It seems to be claimed In the proof of Lemma 10.17 : For every proper open subset $W$ of $\mathbb R^n$ , there is an $\omega \in \Omega_c^{n}(\mathbb R^n)$ , namely the "" $\omega_1$ "" in the proof, where $\int_{\mathbb R^n} \omega = 1$ and $\text{supp} \ \omega \subseteq W$ . In the proof of Theorem 11.9 : For a compact connected oriented smooth n-manifold $M$ and for every open subset $U$ of $M$ , there is an $\omega \in \Omega_c^{n}(M) = \Omega^{n}(M)$ , where $\int_M \omega = 1$ and $\text{supp} \ \omega \subseteq U$ (I don't believe this is dependent on the particular $U$ from Lemma 11.8 ). Question : Why? Please try to answer using the tools in the book such as Theorem 10.13 (or Corollary 10.14) , Lemma 10.15 , the last sentence of this or Lemma 10.3(ii) . I think I'm missing something obvious about how such $\omega$ exists because the authors state it so naturally. Is the fact of the existence of such $\omega$ actually not obvious to the reader at this point in the text? For non-obvious facts, I think authors would usually say something like ""First/next, observe that (insert fact), the proof of which is left to the reader/to the exercises"". Here are my thoughts (assuming I understand right): I think (2) follows from Theorem 10.13 (or Corollary 10.14) . I get $\tau \in \Omega_c^{n}(M)$ , where $\int_{M} \tau = 1$ and $\text{supp} \ \tau \subseteq M$ . Choose $\omega$ to be the zero extension of $\tau|_{U}$ to $\tilde{\tau|_{U}} = \tau|_{U}1_{U} + 0 \ 1_{U^c}$ . Similarly, (1) would follow from Lemma 10.15 : I get $\tau \in \Omega_c^{n}(\mathbb R^n)$ , $\int_{\mathbb R^n} \tau = 1$ , $\text{supp} \ \tau \subseteq \mathbb R^n$ , and then $\omega = \tilde{\tau|_{W}} = \tau|_{W}1_{W} + 0 \ 1_{W^c}$ . For (2), instead of applying Theorem 10.13 to $M$ , I'll apply Theorem 10.13 to $U$ , where the proof of Theorem 11.9 says we may actually be assume $U$ to be connected. We get $\gamma \in \Omega_c^n(U)$ , where $\int_{U} \gamma = 1$ and $\text{supp} \ \gamma \subseteq U$ . Let $\psi = \gamma|_{\text{supp} \gamma}$ , the restriction of $\gamma$ to its support. Denote the zero extensions of $\gamma$ and $\psi$ as $\tilde{\gamma} = \gamma 1_{U} + 0 \ 1_{M \setminus U}$ and $\tilde{\psi} = \psi 1_{\text{supp} \gamma} + 0 \ 1_{M \setminus \text{supp} \gamma}$ . Observe $\tilde{\psi} = \tilde{\gamma}$ (like here ), and both are smooth by the last sentence of this . Choose $\omega = \tilde{\psi} = \tilde{\gamma}$ : As $\omega = \tilde{\psi}$ , $\omega$ will satisfy $\text{supp} \ \omega \subseteq U$ . As $\omega = \tilde{\gamma}$ , $\omega$ will satisfy $\int_{M} \omega = 1$ because $\int_{M} \tilde{\gamma} = \int_{U} \gamma$ by Lemma 10.3(ii) . But with this method, how do we argue similarly for (1), where the proof of Lemma 10.17 does not say that we may assume $W$ is connected?","['integration', 'geometry', 'calculus', 'general-topology', 'differential-geometry']"
3208008,Computing intersection of infinite sets.,"Need help in vetting my answers for the question #6 in CRM series book by MAA: Exploratory Examples for Real Analysis, By Joanne E. Snow, Kirk E. Weller. Consider the following two collections of sets: $$\{I_n = [0,\frac1n] \ : n \in \mathbb{N} \}$$ $$\{J_n = (0,\frac1n) \ : n \in \mathbb{N} \}$$ (a) Compute $\bigcap_{n=1}^{\infty} I_n$ . (b) Compute $\bigcap_{n=1}^{\infty} J_n$ . (c) Can you explain the differences in the two answers using any of the terms introduced in this lab ( in chapter #1 )? (a) $I_1 = [0,1], I_2 = [0,\frac12], I_3 = [0,\frac13], I_4 = [0,\frac14], \cdots, I_{\infty} = [0,0] = 0$ $\bigcap_{n=1}^{\infty} I_n = [0,1]\cap[0,\frac12]\cap[0,\frac13]\cap[0,\frac14]\cdots \cap 0$ There need be found intersection of real points in all the given intervals, leading to finally single point $0$ , which is the same as $I_{\infty}$ . (b) $J_1 = (0,1), J_2 = (0,\frac12), J_3 = (0,\frac13), J_4 = (0,\frac14), \cdots, J_{\infty} = (0,0)=\emptyset$ The last set is empty set ( $\emptyset$ ), as . $\bigcap_{n=1}^{\infty} J_n = (0,1)\cap(0,\frac12)\cap(0,\frac13)\cap(0,\frac14)\cdots \cap \emptyset $ $\bigcap_{n=1}^{\infty} J_n = \emptyset $ In all non-null sets, the boundary of the intervals are not included. The intersection of the sets is null set, as there is nothing in common of any set with $\emptyset$ . (c) Unable to find any term in chapter 1 of the book, that describes something related to empty set intersection with other sets leading to null set again. The chapter describes supremum, maximum, Upper bound, infimum, minimum, Lower bound. This can be checked by the google-book link for the same. Doubt: 1. Am I correct about taking the interval $I_\infty$ , that represents a single point? 2. Similarly, about $J_\infty$ , which is empty set.","['elementary-set-theory', 'proof-verification', 'real-analysis']"
3208064,Is intersection of zero set of any family of holomorphic functions an analytic set?,"Let $\{f_{\alpha}\}_{\alpha\in \mathcal{I}}$ be a family of holomorphic functions on the unit ball $\mathbb{B}^{n}$ in $\mathbb{C}^{n}$ . Let $$
U:=\{z\in \mathbb{B}^{n}: f_{\alpha}(z)=0,\forall \alpha\in\mathcal{I}\}.
$$ Can we always conclude that $U$ is an analytic subset in $\mathbb{B}^{n}$ ? That is, for any $a\in \mathbb{B}^{n}$ , there exist a neighbourhood $B(a,\varepsilon)\subset \mathbb{B}^{n}$ of $a$ , and a finite family of holomorphic functions $g_{1},...,g_{m}$ on $B(a,\varepsilon)$ such that $$
B(a,\varepsilon)\cap U=\{z\in B(a,\varepsilon): g_{1}(z)=...=g_{m}(z)=0\}.
$$ I think in general this is not the case. We may need to impose some structure on our family. However, I am not sure at the moment. Thanks so much for any suggestion.","['complex-analysis', 'algebraic-geometry', 'several-complex-variables']"
3208098,"Why does the set $\{1,3,5,7... ; 2,4,6,8...\}$ qualify as well-ordered? How to explain this notation?","The set  {odd natural numbers greater than 0  }U {even natural numbers} that is, the set $\bigcup \{ \{1,3,5,7...\}, \{2,4,6,8...\}  \}$ also strangely written $\{1,3,5,7... ; 2,4,6,8...\}$ . is often given as an example of a well-ordered set ( a set such that for all subset there is a first element). I have some problems with this example. (1) First, which relation orders this set? Could this relation be defined explicitly ? Is this relation somewhat analogous to lexigraphic order? So I don't understand how this set can be an ordered set. (2) Second, I don't understand how it is well -ordered. In order to be well ordered, every subset should have a first element. But apparently, the set $\{7,2\}$ is a subset of my set. What is the first element of $\{7,2\}$ ?","['elementary-set-theory', 'elementary-number-theory', 'order-theory']"
3208106,The group algebra is not semisimple if characteristic divides group order.,"I'm studying a proof that if a prime $p$ has $p\mid |G|$ and $k$ is a field of characteristic $p$ , then the group algebra $kG$ is not semisimple. My issue is that there is an assertion in the first line that I don't understand - given this assertion, I am fine with the rest of the proof. The proof goes like this: If $kG$ were semisimple, the trivial module $k$ would appear exactly once as a summand in a decomposition of $kG$ into simple $kG$ modules. This must be something special about the group algebra, because e.g. $k\oplus k$ doesn't satisfy this and is semisimple, but I don't know where this comes from. By the Artin-Wedderburn theorem, any composition series of $kG$ has exactly one factor isomorphic to $k$ . The augmentation ideal $\Sigma$ (the kernel of the augmentation map sending each group element to 1) has $kG/\Sigma\cong k$ . $\sigma=\sum_{g\in G}g$ lies in the augmentation ideal since $k$ is of characteristic $p$ . So, $k\sigma$ is a submodule of $kG$ contained in the augmentation ideal. Refining $kG\supset \Sigma \supset k\sigma\supset 0$ to a composition series will give at least two factors isomorphic to the trivial module, a contradiction. I understand how, assuming (1), the proof works, and I'm sure I'm missing something blatantly obvious. Why is (1) true?","['positive-characteristic', 'abstract-algebra', 'representation-theory', 'modules']"
3208109,Spivak's Calculus on Manifolds problem 2-15(c),"2-15. Regard an $n \times n $ matrix as a point in the $n$ -fold product $\Bbb{R^n} \times \cdots\times \Bbb{R^n}$ by considering each row as a
   member of $\Bbb{R^n}$ . (a) Prove that $det: \Bbb{R^n} \times \cdots \times \Bbb{R^n} \to
\Bbb{R}$ is differentiable and $
 D(\mathrm{det})(a_1,\ldots,a_n)(x_1,\ldots,x_n)=\sum_{n=i}^{n} \mathrm{det} \begin{bmatrix} 
a_1 \\ \vdots \\ x_i\\ \vdots\\ a_n \end{bmatrix}$ (b) if $a_{ij}: \Bbb{R} \to \Bbb{R} $ are differentiable and $f(t)=det(a_{ij}(t))$ , show that $f'(t)= \sum_{j=1}^{n} det
\begin{bmatrix}  a_{11}(t),\ldots, a_{1n}(t)\\ \vdots\\ a_{j1}'(t),\ldots,
a_{jn}'(t)\\ \vdots \\ a_{n1}(t),\ldots, a_{nn}(t) \end{bmatrix}$ (c) if $\mathrm{det} (a_{ij}(t)) \neq 0$ for all $t$ and $b_1,...,b_n: \Bbb{R}
\to \Bbb{R}$ are differentiable, let $s_1,\ldots,s_n: \Bbb{R}
 \to \Bbb{R}$ be the functions such that $s_1(t),\ldots,s_n(t)$ are the solutions of the equations $\sum_{j=1}^{n}
 a_{ij}(t)s_j(t)=b_i(t)$ $i=1,\ldots,n$ . show that $s_i$ is differentiable and find $s_i'(t)$ . Problem 2-40 asks to redo problem 2-15(c) using the implicit function theorem. 2-12 theorem (implicit function theorem). Suppose $ f: \Bbb{R^n}
\times \Bbb{R^m} \to \Bbb{R^m} $ is continuously
  differentiable in an open set containing $(a,b)$ and $f(a,b) =0$ . Let  be the $m \times m$ matrix. $$(D_{n+j}f^i(a,b))~, \quad 1 \leq i,~j \leq m~.$$ If $\mathrm{det} M \neq 0$ , there is an open set $A \subset R^n$ containing $a$ and an open set $B$ subset $R^m$ containing $b$ , with the following
  property: for each $x \in A$ there is a unique $g(x)$ in $B$ such that $f(x,g(x)) =0$ . the function $g$ is differentiable. Call $i^{th}$ row of $(a_{ji}(t))$ as $R_i(t)$ . Let me define $g(t)= 
\begin{bmatrix} 
s_1(t) \\
s_2 (t)\\
\vdots   \\
s_n(t) 
\end{bmatrix}$ . thus $R_i(t)g(t)=b_i(t)$ . If I define $f:\Bbb{R^n} \times \Bbb{R^n} \to \Bbb{R^n}$ such that $f(R_i(t),g(t)) = R_i(t)g(t)=b_i(t)$ , the first difficulty I face is that the theorem will provide $g(t)$ is differentiable only if $b_i(t)=0$ , which may not be true. To overcome this difficulty, how should I define $f$ so that the theorem will provide me that $g(t)$ is differentiable?","['multivariable-calculus', 'real-analysis']"
3208161,Separability and the Nagata-Smirnov Metrisation Theorem,"Definitions: Let $X$ denote a topological space throughout. If all singleton subsets of $X$ are closed, then we call $X$ Fréchet . If, given any closed subset $C \subset X$ and any point $x \in X - C$ , there exist disjoint neighbourhoods of $x$ and $C$ , then we call $X$ quasiregular. If $X$ is both Fréchet and quasiregular, then we call $X$ regular . (To--hopefully--avoid confusion, I forgo the use of the $T_n$ notation for separation properties entirely, and use the conventions of Clark's notes on general topology in this PDF . A collection $\mathcal{A}$ of subsets of $X$ is said to be locally finite if, for every point $x \in X$ , there exists some neighbourhood of $x$ which intersects only finitely-many elements of $\mathcal{A}$ . If we can write a collection $\mathcal{B}$ of subsets of $X$ as a countable union $\bigcup_{n \in \mathbb{N}} \mathcal{A}_n$ , where each $\mathcal{A}_n$ is locally finite, then the collection $\mathcal{B}$ is said to be $\sigma$ -locally finite . My question: I am confused about the proof of one direction of the Nagata-Smirnov metrisation theorem given as Lemma 4.20 in Kelley, which for completeness I attach to this post as an image. In the above terminology, the statement of this lemma is A regular space whose topology is generated by a $\sigma$ -locally finite basis is metrisable. As I understand it, his approach is to make use of the $\sigma$ -locally finite basis to define a countable collection $\{ d_{(n,m)} \}_{(n,m) \in \mathbb{N}^2}$ of continuous functions $X \to \mathbb{R}$ , and then show that this collection distinguishes points from closed subsets of $X$ . This allows us to deduce that the evaluation map $x \mapsto \left( d_{(n,m)}(x) \right)_{(n,m) \in \mathbb{N}^2}$ embeds $X$ as a subspace of the metrisable space $\prod_{(n,m) \in \mathbb{N}^2} \mathbb{R}$ , which in turn tells us that $X$ is itself metrisable. (Morally, this seems basically identical to the standard proof of the same direction of Urysohn's metrisation theorem, modulo the technical details of defining the countable collection of functions $X \to \mathbb{R}$ in the first place.) Now, there exist metrisable spaces which fail to be separable (or, equivalently, fail to be second countable); for instance, the discrete topology on any uncountable underlying set. What I don't understand is why Lemma 4.20 does not imply that all metrisable spaces are separable when we combine it with the reverse implication. Explicitly, if we assume that the topology of any metrisable space is generated by some $\sigma$ -locally finite basis, then my understanding of Lemma 4.20 tells us that we can embed such spaces in the countable product $\prod_{n \in \mathbb{N}} \mathbb{R}$ . As a product of countably-many second countable spaces, $\prod_{n \in \mathbb{N}} \mathbb{R}$ is second countable; since second countability is inherited by subspaces, this seems to imply the (false) result that all metrisable spaces are second countable. Where is my understanding going wrong? $T_1$ , I use ""Fréchet""."" />","['metrizability', 'general-topology', 'separable-spaces', 'separation-axioms']"
3208166,Simple question on parallel transport in dually flat manifolds,"I just started studying Information Geometry and its applications by Amari . Right in the first chapter, the author talks about parallel transport in Dually flat manifolds. Just some quick notation: 
In the first chapter, the author introduces the definition of Manifold $M$ and one of the many coordinate systems on the manifold, say, $\theta$ .
The length of the curve from $\boldsymbol {\theta}$ to $\boldsymbol{ \theta + d\theta}$ is given by $$
d s^{2}=2 D_{\psi}[\theta : \theta+d \theta]=\sum g_{i j} d \theta^{i} d \theta^{j}
$$ A tangent vector can be expressed as $$
d \boldsymbol{\theta}=\sum d \theta^{i} \boldsymbol{e}_{i}
$$ where $
\left\{\boldsymbol{e}_{i}\right\}
$ , $i \in \{1,.. ,n\}$ are the basis of the tangent space of M at point $\boldsymbol \theta$ . Similarly, the author introduces a dual affine coordinate system whose corresponding basis is $\left\{e^{* i}\right\}$ . Therefore,we can write $$
d \boldsymbol \theta^{*}=\sum d \theta_{i}^{*} e^{* i}
$$ Now, one can also write the length of the small line vector as $$
d s^{2}=\langle d \boldsymbol{\theta}, d \boldsymbol{\theta}\rangle= g_{i j} d \theta^{i} d \theta^{j}
$$ , which is rewritten as $$
d s^{2}=\left\langle d \theta^{i} e_{i}, d \theta^{j} e_{j}\right\rangle=\left\langle e_{i}, e_{j}\right\rangle d \theta^{i} d \theta^{j}
$$ Hence, it is clear that $$
g_{i j}(\boldsymbol{\theta})=\left\langle\boldsymbol{e}_{i}, \boldsymbol{e}_{j}\right\rangle
$$ Similarly, for the dual affine coordinate system $\boldsymbol \theta^*$ , we have $$
g^{* i j}(\boldsymbol \theta^*)=\left\langle e^{* i}, e^{* j}\right\rangle
$$ If $\bf G$ is the Jacobian of the transformation from $\boldsymbol \theta$ to $\boldsymbol \theta^*$ , then we can write $$
\begin{array}{l}{d \boldsymbol{\theta}^{*}=\mathbf{G} d \boldsymbol{\theta}, \quad d \boldsymbol{\theta}=\mathbf{G}^{-1} d \boldsymbol{\theta}^{*}} \\ {d \theta_{i}^{*}=g_{i j} d \theta^{j}, \quad d \theta^{j}=g^{* j i} d \theta_{i}^{*}}\end{array}
$$ Actual doubt: If a tangent vector $\mathbf{A} = A^i\mathbf{e_i} $ is transported
  from a point $\boldsymbol{\theta}$ to $\boldsymbol{\theta^{'}}$ , the
  components $A^i$ remain the same because $\mathbf{e_i}$ is same
  everywhere in a dually flat manifold. However, in the later
  paragraphs, it is stated that the length of the vector is not constant
  even in this dually flat manifold. If the components and basis remain
  the same, shouldn't it be the case where even the length of the vector
  is also the same when moved from one point to another point? Also, why is dual parallel transport any different parallel transport?
  After all, they are just two different coordinate systems. Because, it
  is given that the manifold is dually flat, so both the coordinate
  systems remain the same across all the points. So, why does the
  parallel transport makes the vector invariant under the original basis
  but the same parallel transport changes the vector in the dual basis? 
  Any intuitive explanations, illustrations or examples on how this
  happens? P.S: Relevant page from the book.","['information-geometry', 'manifolds', 'riemannian-geometry', 'differential-geometry']"
3208182,"Let $(X,\mathscr T)$ be a metrizable space such that every metric that generates $\mathscr T$ is bounded. Prove that $X$ is compact. [duplicate]","This question already has an answer here : A separable locally compact metric space is compact iff all of its homeomorphic metric spaces are bounded (1 answer) Closed 5 years ago . Let $(X,\mathscr T)$ be a metrizable space such that every metric that
  generates $\mathscr T$ is bounded. Prove that $X$ is compact. My attempt:-
 We know that $(X,\mathscr T)$ is metrizable. So there is a metric on $x$ such that collection of all open sets with respect to the metric is the $\mathscr T$ . Let $\{d_\alpha\}_{\alpha \in \Lambda}$ be the collection of metric that generates $\mathscr T$ . We know that $\forall \alpha \in \Lambda, (X,d_\alpha)$ is bounded. Suppose on contrary $X$ is not compact. So $(X,d_\alpha)$ is not sequantially compact. So, there is a $\{x_n\}$ be a sequence in $X$ such that none of its subsequence converges. How do I make contradiction with our assumption?","['general-topology', 'metric-spaces', 'compactness']"
3208224,Measurability of closed opeartor,"Given separable Banach spaces $(E, \Vert \cdot \Vert_E)$ and $(F, \Vert \cdot \Vert_F)$ . The Banach space $E$ is endowed with sigma algebra $\mathcal{F}$ which is generated by the open set of it. Similarly, let $\mathcal{G}$ be the sigma algebra of space $F$ . Say $$A: D(A) \to F$$ is a closed operator where $D(A)$ is a subspace of $E $ and we assume $D(A) \in \mathcal{F}. $ My question is that is the map $$A: (D(A), \mathcal{F}|_{D(A)}) \to (F, \mathcal{G})$$ necessarily measurable?  I know that when $D(A)$ is closed this is true, since via closed graph theorem, $A$ is in fact continuous. But in general, I don't know how to prove it.","['measurable-functions', 'functional-analysis']"
3208231,Can we divide $\mathbb{R}^2$ into two path connected parts such that each part is not simply-connected?,"Can we divide $\mathbb{R}^2$ into two connected parts such that each part is not simply-connected? My attempt Put $A= \{ (0,0) \} $ and $B$ is the punctured plane. Since that $S^1$ is a deformation retract of the punctured plane, $B$ is not simply-connected. Thus we can find a division of $\mathbb{R}^2$ such that one part is simply-connected but the other is not. But how to deal with the problem above which requires that each part is not simply-connected? It seems to be related to contractible and holes. But I don't know how to convert these ideas into precise mathematical language. Any hints? Thanks in advance! Added: As pointed out in the comment, the counterexample exists. Now I want to ask another question Can we divide $\mathbb{R}^2$ into two path connected parts such that each part is not simply connected?","['general-topology', 'algebraic-topology']"
3208266,Inverse image ideal sheaf and pullback of ideal sheaf,"Assume that we are given a morphism $m: X\to Y$ of varieties and that $I\subset O_Y$ is an ideal sheaf defining some subscheme $T\subset Y$ . Then we have two objects on $X$ associated to $I$ . The one is $m^{-1}I\cdot O_X$ , the other is $m^*I=m^{-1}I\otimes O_X$ . From the inclusion $i: I\to O_Y$ we get $m^*i: m^*I\to m^*O_Y=O_X$ and I found the statement that $m^{-1}I\cdot O_X=(m^*i)(m^*I)$ . Now there are some questions occurring to me. Relation between the subscheme defined by $T$ and those defined by $m^{-1}I\cdot O_X.$ Let me denote the subscheme of $X$ defined by $m^{-1}I\cdot O_X$ by $S$ . Now, if $I_T=\langle f_1,\dots,f_n\rangle$ , is $I_S=\langle m^*f_1,\dots, m^*f_n\rangle$ ? It seems that this should rather be $m^*I_T$ but how does $m^{-1}I\cdot O_X$ then look like? Why is $m^*I$ not necessarily a subsheaf of $O_X$ ? I know the short answer is that it is because of non-exactness of the tensor product but its hard for me to find an explicit example. This maybe has to do with me not understanding the previous question to well, i.e. not understanding how $m^{-1}I\cdot O_X$ looks like. If $m^{-1}T=S$ , does $m^{-1}I_T\cdot O_X=I_S$ follow? By $I_S$ I mean the ideal sheaf defining $S$ and by $I_T$ I mean the ideal sheaf defining $T=m^{-1}S$ . Since it is an ideal sheaf, the preimage of the ideal defining $T$ would then be the ideal defining $T$ and it looks like this should then give the statement on the ideal sheaves but I am unable to write down a proof.","['algebraic-geometry', 'abstract-algebra', 'sheaf-theory']"
3208273,Is the set of elementary functions which do not have elementary integrals bigger than set of elementary functions which have elementary integrals?,It increasingly seems to me that the functions that have elementary integrals are quite rare in comparison to the ones that don't have them. Even raising an elementary function to a different power may result in it not having an elementary integral . Ex. $\sqrt{\arctan (x)}$ Also many seemingly simple functions do not have elementary integrals. Ex. $\frac {\sin (x)}{x}$ or $ \sin \left( \frac{1}{x} \right) $ So my question is that can we write a formal proof to prove/disprove that the set of elementary functions which do not have elementary integrals is bigger than set of elementary functions which have elementary integrals?,"['integration', 'calculus', 'conjectures', 'elementary-set-theory']"
3208277,Universality of uniform: plugging a random variable into its CDF?,"Consider the universality theorem of the uniform distribution. One way to formulate it is the following: Let $F:\mathbb{R}\rightarrow [0,1]$ be a right continuous, increasing function. Then, if $X\sim F$ (ie. $X$ is a random variable that has CDF $F$ ) then $F(X)\sim Uniform(0,1)$ . While I can prove it, I am confused about the concept of plugging $X$ (a random variable) into its CDF. $X$ is a random variable, that is, X is a mapping from the sample space $S$ to $\mathbb{R}$ (considering 1-dimensional scenario). $X\sim F$ means $F(t)=P(X\le t)$ where "" $X\le t$ "" is an event, "" $X\le t$ "" $=\{s\in S: X(s)\le t\}$ . The domain of $F$ is $\mathbb{R}$ . How could we even imagine the concept of $F(X)$ ? $X$ is a function, coming from the space of functions, not the domain of $F$ . And what would $F(X)$ even be, $P(X\le X)$ ? What event is "" $X\le X$ ""? This is so weird and confusing.","['probability-distributions', 'uniform-distribution', 'probability-theory', 'probability']"
3208307,Proof that if graph has $\frac{(n-1)(n-2)}{2} + 2$ edged then contains hamiltonian cycle,"Proof that if graph has $\frac{(n-1)(n-2)}{2} + 2$ edged then contains hamiltonian cycle I think that it is good to use there induction: Let check base of induction. For $ n= 3 $ I have $$ |E| = \frac{2\cdot1}{2}+2 = 3  \text{ and }n \text{ vertices }$$ so this is just triangle and triangle contains hamiltonian cycle. Assume that $$ \text{if graph with |V| = n has }\frac{(n-1)(n-2)}{2} + 2 \text{ edges then contains hamiltonian cycle } $$ Proof that $$ \text{if graph with |V| = n+1 has }\frac{n(n-1)}{2} + 2 \text{ edgesthen contains hamiltonian cycle } $$ In this step I checked how many edges I have added: $$\frac{1}{2} (n-1) n-\frac{1}{2} (n-2) (n-1) = n-1 $$ Now I should show that if I add $n-1$ edges in any way to my first graph, it will have hamiltonian cycle, but there I have stucked","['graph-theory', 'discrete-mathematics', 'hamiltonian-path']"
3208314,is $y=e^{\ln(x)}$ a function???,Is $y=e^{\ln(x)}$ a function? I am not sure whether this is a function because it should be equal to $y=x$ but $x$ cannot be zero so I am confused  as to wether this is a function or not,['functions']
3208347,How can we prove that $\lim_{n\to \infty}\frac{|\cos(1^2)|+|\cos (2^2)|+\cdots+|\cos (n^2)|}{n}=\frac{2}{\pi}$,"How can we prove that $\lim\limits_{n\to \infty}\frac{|\cos(1^2)|+|\cos (2^2)|+\cdots+|\cos (n^2)|}{n}=\frac{2}{\pi}$ ? I have tried to use Stolz's formula,but unfortunately, it failed,since $$\lim_{n\to \infty}\frac{|\cos ((n+1)^2)|}{(n+1)-n}$$ is not exists.
The problem is too difficult for me to work it out.","['limits', 'sequences-and-series']"
3208362,Partial summation to prove the limit of the series is 0,"Hi I was given the following problem. Let $a_{n}>0$ increasing monotonically to $\infty$ as $ n\to\infty$ and $\sum_{n=1}^{\infty}\frac{y_{n}}{a_{n}}$ is convergent. Use summation by parts to prove that $\lim_{n\to\infty}\frac{1}{a_{n}}\sum_{i=1}^{n}y_{i}=0$ My approach was let $Y_{n} = \sum_{i=1}^{n}y_{i}$ $$ \sum_{k=q}^{p} \frac{y_{k}}{a_{k}} = \sum_{k=q}^{p}Y_{k}(\frac{1}{a_{k}}-\frac{1}{a_{k+1}}) + \frac{Y_{p}}{a_{p+1}}-\frac{Y_{q-1}}{a_{q}} $$ since the sum of $\frac{y_{k}}{a_{k}} $ converges, the RHS can be bounded from above by $\epsilon > 0$ for q,p large enough as the partial sums $\sum^{n}_{k=1}\frac{y_{k}}{a_{k}} $ form a Cacuhy sequence. But how does one reach the conclusion that $\frac{Y_{k}}{a_{k}} \to 0$ or is the approach wrong?","['convergence-divergence', 'analysis', 'sequences-and-series']"
3208418,Showing $X$ is standard normal when $X$ has the same distribution as $\frac{X_1+X_2}{\sqrt{2}}$,"$X, X_1, X_2$ are i.i.d random variables with $\mathbb{E}[X] = 0$ and $\mathbb{E}[X^2] = 1$ . Suppose $X$ has the same distribution as $\frac{X_1+X_2}{\sqrt{2}}$ . I need to show that $X$ is standard Normal. A given hint is to establish a recurrence type relation. So far, I have the following: Formulate $X_i = \frac{X_j+X_k}{\sqrt{2}},$ for some $1 \leq j,k \leq i-1$ Then, the sequence $\{X_n\}$ will be i.i.d. Step 1 is necessary to preserve the identical distribution. By Central Limit Theorem, $\frac{S_n}{\sqrt{n}} =\frac{\sum_i^nX_i}{\sqrt{n}} \to \mathcal{N}(0,1)$ as $n \to \infty$ . Need to construct the sequence $\{X_n\}$ such that $\lim_{n\to \infty} \frac{S_n}{\sqrt{n}} = \frac{X_1+X_2}{\sqrt{2}}$ (or I think any $X_j$ would be good too, since they have identical distribution). Here is where I am stuck. I have tried constructing many sequences but none of them have worked so far! Any help would be deeply appreciated! Much thanks in advance.","['central-limit-theorem', 'probability-distributions', 'normal-distribution', 'convergence-divergence', 'probability-theory']"
3208435,Burgers' equation - Integrate discontinuity over rectangle,"I am studying conservation laws and hyperbolic systems, particularly, Burgers' equation and shocks, and have a doubt at page 40 of the book Numerical Methods for Conservation Laws by R.J. LeVeque (Birkäuser, 1992). I could not understand the following calculation: If a discontinuity is present, then integrating $(u^2)_t + (\frac{2}{3}u^3)_x$ over an infinitesimal rectangle as in Figure 3.12 gives $$\int_{x_1}^{x_2}u^2(x,t)\, dx \bigg|^{t_2}_{t_1} + \int_{t_1}^{t_2}\dfrac{2}{3}u^3(x,t)\, dt \bigg|^{x_2}_{x_1} = s_1\Delta t(u_l^2-u_r^2)+\dfrac{2}{3}\Delta t (u_r^3-u_l^3)+O(\Delta t^2)$$ where We took an infinitesimal rectangle over a shock and have $s_1=\tfrac{1}{2}(u_l+u_r)$ . Here, $u_l$ is the solution of $u(x,0)$ at left of $x=0$ and $u_r$ is the value at right (Riemann problem). $O(\Delta t^2)$ means some quantity depending of $\Delta t^2$ ( $<C\Delta t^2$ for some $C>0$ , is it right?), but I could not understand the calculation very well.
Can somebody explain this?","['integration', 'hyperbolic-equations', 'entropy', 'partial-differential-equations']"
3208470,Proving that any two sets of lines that cover the plane have the same cardinality,"Lets say that a set of lines of the real plane covers the plane if, for every element $\langle x,y\rangle\in\mathbb{R}^2$ , there exists a line $l$ of the set that passes through $\langle x,y\rangle$ . Its obvious that the set of all lines of the plane, denoted by $\mathscr{L}$ , has this property, and it can be identified with the real projective plane $\mathbb{P}_{\mathbb{R}}^2$ minus a point, say $(1:0:0)$ . It is clear then that the cardinality of the set $\mathscr{L}$ is the same as the cardinality of $\mathbb{P}_{\mathbb{R}}^2$ , but, how can we prove rigorously that every subset of $\mathscr{L}$ that covers the plane is actually equipotent with $\mathscr{L}$ ? We know, for instance, that any line in $\mathbb{P}_{\mathbb{R}}^2$ that doesn't pass through the distinguished point $(1:0:0)$ , is a pincel of lines on the plane, and therefore, any line of $\mathbb{P}_{\mathbb{R}}^2$ that does not pass through $(1:0:0)$ can be identified with a set of lines that cover the plane . I think this observation must be useful for the proof, but I don't know how to exploit this fact. The thing is that any line of $\mathbb{P}_{\mathbb{R}}^2$ has the cardinality of $\mathbb{P}_{\mathbb{R}}^2$ , and a pencil is one of the simplest subsets of $\mathscr{L}$ that cover the plane, because for every point $\langle x,y\rangle$ of the plane, there is only one line that passes through $\langle x,y\rangle$ . ""Intuitively"", any subset of $\mathscr{L}$ that covers the plane must have a cardinal larger or equal to that of the pencil, because for a point $\langle x,y\rangle$ there might be more than one line that passes through it. Since any pencil of lines through a point and the set $\mathscr{L}$ have the cardinality of $\mathbb{P}_{\mathbb{R}}^2$ , from the previous commentary we should conclude that any two subsets of lines that cover the plane should have the same cardinality. Hope someone helps me make a rigorous proof out of this intuitive and weak argumentation. Thanks in advance for your time. EDIT : just posted a full, complete answer to this question on the comments, after thinking a lot about this question. I hope that it is correct, and if not, I would really like to hear about your suggestions and comments.","['elementary-set-theory', 'cardinals', 'linear-algebra', 'projective-geometry']"
3208526,"Let $S={1, 2, 3, 4, ....., 2070}$ find the number of subsets of $S$ whose sum of elements in $S$ is divisible by 9","Let $S={1, 2, 3, 4, ....., 2070}$ find the number of subsets of $S$ whose sum of elements in $S$ is divisible by 9 In the expression $$f(x)=(1+x)(1+x^2)......(1+x^{2070})$$ Terms of the form $x^{9k}$ will be the subsets divisible by 9. I am not able to proceed from here.",['combinatorics']
3208536,Advantages of Riesz theorem over Caratheodory Extension theorem,"I apologize in advance if this question seems vague. I'm self studying Real and Complex Analysis by W. Rudin and I've been reading the proof of Riesz theorem in the second chapter which is then used in the construction of the Lebesgue measure. In an analysis class I took a few years ago in undergrad we used another approach and used the Caratheodory extension theorem. I may be biased but I find the second approach much more intuitive in the immediate applications, specifically in the construction of the Lebesgue measure. My question is then the following: Are there measures that are more easily defined (or that can only be defined) using Riesz theorem? That is, is there any significant difference in the two approaches?","['measure-theory', 'examples-counterexamples']"
3208537,"Independent or dependent events, drawing cards without replacement","Firstly, i want to sorry for asking the question that has been answered. This is because i don't have enough reputation so that i can ask the people who gave the answer. The question that has been answered: Independent events, drawing cards without replacement. Question: Two cards are chosen from a pack of cards without replacement. Are the following events independent? (i)the first card is a heart, (ii)the second card is a picture card. After reading this, i still can not understand why these 2 events are independent. I can prove these 2 are independent: $A$ : First card is a heart. $B$ : Second card is a picture card. \begin{align}
    P(A) &= \frac{13}{52} \\ 
    P(B) &= \frac{12}{52}
\end{align} If we assume that these two events are independent then : \begin{align}
    P(A \cap B) &= P(A).P(B) = \frac{13.12}{52^2} = \frac{3}{52}
\end{align} We also have: \begin{split}
    P(A \cap B) &= P(\text{first card is a heart card with picture }\cap B) \\
&\quad+  P(f\text{first card is a heart card not picture }\cap B)\\ 
&=\frac{3}{52}\cdot \frac{11}{51} \; + \frac{10}{52}\cdot\frac{12}{51} = \frac{3}{52}
\end{split} So that: \begin{align}
P(A \cap B) &= P(A)\cdot P(B)\;\;\textit{is true}
\end{align} This proves that these two events are independent. The reason here is that i think that when we pick the first card is a heart then we have two cases : 1) If we pick the first card, it is a heart picture card. So the number of picture cards and total cards in the pack of cards decreases. 2) If we pick the first card, it is a heart but not a picture card. So the number of total cards in the pack of cards decreases. I think on both cases these 2 events are dependent because after the event $A$ happens, it affects to the probability of the event $B$ . After thinking a lot i still can not figure out why they are independent. Thanks a lot for reading and helping me !",['probability']
3208541,Meaning of parallel transport on latitude of a sphere,"There are many good answers - 1 , 2 on how a vector changes its angle when 'parallel transported' along a latitude in a sphere. Most of the explanations use this logic - the cone is tangent to your spherical circle everywhere, parallel transport in the cone agrees with parallel transport in the sphere But I unable to understand how parallel transport looks like on the sphere. I think that it is not the following picture because the angle remains same after rotation: This page gives the following animation but I cannot understand why it is called 'parallel' transport? Note: I am not looking for the math behind parallel transport on spheres such as covariant derivatives, etc. Rather I am looking for an intuitive understanding of 'what is meant by parallel transport on a sphere.' Any helpful analogy or illustration is much appreciated. For e.g.: In this illustration of 'parallel transport', it is very easy to see what is happening: If one moves from point A to N holding a javelin always pointing towards the north , and from point N to B javelin is still held parallel to its position at N , then angle of javelin is different from directly moving from A to B with the javelin pointing north .","['riemannian-geometry', 'differential-geometry']"
3208560,Are all Galois extensions simple?,"I have been looking at Galois extensions and Galois groups and have been wondering if all Galois extensions are simple. I don't think this is true. For example with $\mathbb{Q}(\sqrt{2}, \sqrt{3}) = \mathbb{Q}(\sqrt{2} + \sqrt{3})$ would be a simple extension of $\mathbb{Q}$ . With something like $\mathbb{Q}(i,\sqrt{3})$ over $\mathbb{Q}$ this is Galois, but I don't think it is simple. Is that correct? My initial guess was that $\mathbb{Q}(i,\sqrt{3}) = \mathbb{Q}(i\sqrt{3})$ , but I think the right side is just a subfield.","['galois-theory', 'galois-extensions', 'abstract-algebra']"
3208572,"An urn contains 5 red, 2 blue, and 9 green balls. Six balls are drawn.","Q: An urn contains 5 red, 2 blue, and 9 green balls. Six balls are drawn. Assuming the drawing is WITH replacement, what is the probability of getting 1 red, 2 blue, and 3 green balls? This is an exam question I got wrong. My answer was: $\frac{{5 \choose 1}{2 \choose 2}{9 \choose 3}}{{16 \choose 6}} $ I checked other questions, such as this one , and they approached it the same way. What am I missing?","['combinatorics', 'probability']"
3208640,"Show that the function $u(x,y) =e^{x^2−y^2}\cos(2xy )$is harmonic. Find the harmonic conjugate v of u, up to addition of a constant.","Show that the function $u(x,y) =e^{(x^2−y^2)}\cos(2xy)$ is harmonic. Find the harmonic conjugate of u, up to the addition of a constant. 
My question is how do you integrate this function? My approach:
To show that $u(x,y)$ is harmonic it will need continuous 2nd order partial derivatives and that $\frac{d^2u}{dx^2}+\frac{d^2u}{dy^2}=0$ .
Therefore: $\frac{du}{dx}=-2y\sin (2xy)e^{(x^2-y^2)}+2x\cos (2xy)e^{(x^2-y^2)}$ and $\frac{d^2u}{dx^2}=-4ye^{(x^2-y^2)}(x\sin (2xy)+y\cos (2xy))+4e^{(x^2-y^2)}x(-y\sin (2xy)+x\cos (2xy))+2\cos (2xy)e^{(x^2-y^2)}$ $\frac{du}{dy}=e^{(x^2-y^2)}y\cos (2xy)-2xe^{(x^2-y^2)}\sin (2xy)$ $\frac{d^2u}{dy^2}=4ye^{(x^2-y^2)}(y\cos (2xy)+2x\sin (2xy))-4e^{(x^2-y^2)}x^2\cos (2xy)-2e^{(x^2-y^2)}\cos (2xy)$ Hence $\frac{d^2u}{dx^2}+\frac{d^2u}{dy^2}=0$ Now to find $v(x,y)$ so v is harmonic to u if the Cauchy Riemann equations are continuous and hold you can see that they are continuous, thus: $\frac{du}{dx}=\frac{dv}{dy}=-2y\sin (2xy)e^{(x^2-y^2)}+2x\cos (2xy)e^{(x^2-y^2)}$ To find v we integrate $∫$$-2y\sin (2xy)e^{(x^2-y^2)}+2x\cos (2xy)e^{(x^2-y^2)}dy$ which brings me to my question, how do you integrate this function?","['integration', 'cauchy-riemann-equations', 'harmonic-analysis', 'complex-analysis', 'functions']"
3208650,Number of paths on $\mathbb Z^d$,"Given two points $x,y \in \mathbb Z^d$ I am curious whether there is a formula for the number of paths $P(x,y,n)$ of length $n$ (=number of steps) between $x$ and $y.$ Although an explicit expression would be nice, I am particularly curious to know if there exist sharp upper bounds on the scaling of $P(x,y,n)$ as a function of $n$ . In particular, is it polynomial, exponential, factorial etc.? So to be precise, the paths are allowed to be self-intersecting (and you can go back and forth,yes) and can move horizontically and vertically. Please let me know if you have any questions.","['calculus', 'combinatorics', 'discrete-mathematics']"
3208706,Solving Thiele's differential equation.,"Consider Thiele's differential equation for $t\in[0,\infty)$ (all the other functions are continuous on $[0,\infty)$ , too.) $$
\begin{align}
V'(t)&=\Big(\phi(t)+\lambda(t)\Big)V(t)+\pi(t)-\lambda(t)A(t)\\
V(0)&=0
\end{align}
$$ I am reading a proof about the unique solution being $$V(t)=\int_0^t \big(\pi(s)-\lambda(s)A(s)\big)\exp\Big(\int_s^t \big(\phi(u)+\lambda(u)\big)du\Big)ds$$ So the first thing happening in the proof is that the author solves the equation $$V'(t)=\big(\phi(t)+\lambda(t)\big)V(t)$$ and finding the solution by variation of the constant afterwards. The last equation is equivalent to $$\frac{V'(t)}{V(t)}=\big(\phi(t)+\lambda(t)\big)$$ and therefore $$\int_0^t\frac{V'(s)}{V(s)}ds=\int_0^t \big(\phi(s)+\lambda(s)\big)ds$$ Now he states something I do not understand: $$\log V(t)=\int_0^t \big(\phi(s)+\lambda(s)\big)ds + c$$ In my opinion, using that $\log' V(t)= \frac{V'(t)}{V(t)}$ , it should be $$\log V(t) -\log V(0)=\int_0^t \big(\phi(s)+\lambda(s)\big)ds,$$ which seems to be not well defined, since $V(0)=0$ . Is this some sort of method to solve this equation or is this just wrong? What is the procedure here? Thanks in advance for any help!","['ordinary-differential-equations', 'real-analysis']"
3208715,Is induction neccessary for proving that every injective mapping of a finite set into itself is a mapping onto itself?,"Upon reviewing the basic theorem that the number of elements in a fixed finite set is unique, I tried to determine what part of this proposition is in need of proof.  It seems axiomatic.  Nonetheless, BBFSK have a very long-winded, and seemingly convoluted discussion of this, and related ideas. When I attempted to produce my own argument in support of the above proposition, the part which I am not able to state purely in the terminology of mappings (bijection, injection, etc) is that an injection of a finite set into itself is a mapping onto itself.  The proof BBFSK give uses induction.  After thinking about it for a while, that was the only approach I could come up with. Is there a rigorous proof of the proposition that every injective mapping of a finite set into itself is a mapping of the set onto itself which does not involve induction?","['elementary-set-theory', 'elementary-number-theory', 'induction', 'alternative-proof']"
3208719,why the curvature of a spiral in its origin is not infinity?,"It can be shown that the curvature of a spiral $\bf{r}(\rm t)=t(\cos t, \sin t)$ is given by \begin{eqnarray}
    \kappa(t) = \frac{t^2 + 2}{(\sqrt{1+ t^2})^3}
\end{eqnarray} Given that the radius at $t=0$ is $0$ , I would think that the curvature is
infinity. Still $\lim_{t \to 0} \kappa(t) = 2$ .","['calculus', 'differential-geometry']"
3208726,Structure Group of a Principal G Bundle is G,"Definition 1: A principal $G$ -bundle is a fiber bundle $F \to P \xrightarrow{\pi} X$ together with a right action of $G$ on $P$ such that: (i) $G$ acts freely and transitively on fibers. (ii) $G$ preserves fibers. I am trying to show that the structure group of a principal $G$ -Bundle is $G$ , following wikipedia's definition of a structure group of a fiber bundle .  What I have come up with is the following: Suppose $(U_i,φ_i)$ , $(U_j,φ_j)$ are local trivilizations, then since $φ_i \vert_{π^{-1}(q)} : π^{-1}(q) \to \{q\}\times F  $ (similarly for $j$ ) we should have for $x \in U_i \cap U_j $ , $ξ \in F$ $$φ_i φ^{-1}_j (x,ξ)=(x,ξ') $$ Now $(x,ξ')$ corresponds to an element $p \in π^{-1} (x)$ by $φ^{-1}_j$ and $(x,ξ)$ to an element $p' \in  π^{-1} (x)$ . But we have a transitive right action of G on P, so that we can find a $g \in G$ s.t. $p'=pg$ . Thus, for each $x \in U_i \cap U_j $ we can define a left action on $F$ that takes $ξ$ το $ξ'$ : $$φ_i φ^{-1}_j (x,ξ)=(x,ξ')=(x', t_{ij}(x)ξ) $$ and now $t_{ij}(x)=g \in G$ (the $g$ which acting on $p$ gives $p'$ ) acts on $F$ , so that $G$ is the structure group of our principal $G$ bundle. Is this reasoning correct/complete? Have I missed something? I haven't managed to find anything in the literature proving that  given Definition 1 we can show that the structure group is $G$ and I was wondering if what I came up with is the way it's supposed to be done. EDIT Seeing this question Equivalence of Definitions of Principal G
-bundle it seems to me from Defition 3, since existence of G-equivariant cover is equivalent to having a structure group G, that the structure group being G is part of the definition and thus does not follow from it? I have to say I am generally confused by the definition(s), does it contain both actions on P and on the fiber, or do we define one action and the other follows?","['principal-bundles', 'differential-topology', 'fiber-bundles', 'differential-geometry']"
3208741,"If $V$ is a vector space then $(V,+)$ is a characteristically simple abelian group","(From Rotman, ""Introduction to the Theory of Groups"" )
I am not really sure where to start with this one. I know that characteristically simple groups can be expressed as internal direct products of pairwise isomorphic, finite simple groups. And that we can find a basis for any subspace, $U$ of $V$ that can be extended to a subspace $W$ for the whole space so that $V=U\oplus W$ . But I'm not sure how to translate between the language of groups and the language of vector spaces in this proof. Surely we can't just use $(U,+)$ and $(W,+)$ as direct factors, as they may not be isomorphic!","['abelian-groups', 'group-theory', 'linear-algebra', 'vector-spaces']"
3208818,"Abstract proof that $\lvert H^2(G,A)\rvert$ counts group extensions.","$\DeclareMathOperator{\Hom}{Hom}$ $\DeclareMathOperator{\im}{im}$ $\DeclareMathOperator{\id}{id}$ $\DeclareMathOperator{\ext}{Ext}$ $\newcommand{\Z}{\mathbb{Z}}$ Let $G$ be a group, let $A$ be a $G$ -module, and let $P_3\to P_2\to P_1\to P_0\to\Z\to0$ be the start of a projective resolution of the $G$ -module $\mathbb{Z}$ . Consider the cohomology group $$H^2(G,A)=\frac{\ker(\Hom_{\Z G}(P_2,A)\to\Hom_{\Z G}(P_3,A))}{\im(\Hom_{\Z G}(P_1,A)\to\Hom_{\Z G}(P_2,A))}.$$ It can be shown that $\lvert H^2(G,A)\rvert$ counts the number of equivalence classes of group extensions $0\to A\to E\to G\to0$ .
The only proof that I know of this result involves choosing a specific projective resolution (namely, the bar resolution). Is there a proof of this result that does not require choosing a specific projective resolution? For context, $\lvert\ext_R^n(M,N)\rvert$ counts the number of equivalence classes of extensions $0\to N\to X_n\to\ldots\to X_1\to M\to0$ . The proof of this result is fairly abstract and does not require picking a specific projective resolution of $M$ or a specific injective resolution of $N$ . Also, I am aware that we actually have isomorphisms in both of these results but I am more interested in the existence of an explicit bijection. Here is one approach for constructing an element of $H^2(G,A)$ from an extension $0\to A\to E\to G\to0$ : Treat $A$ as an $E$ -module and consider the transgression map $H^1(A,A)^{E/A}\to H^2(E/A,A^A)$ .
Rewriting this gives a homomorphism $\Hom(A,A)^G\to H^2(G,A)$ .
The image of $\id_A$ under this map will be an element of $H^2(G,A)$ . To make this work, this map would need to be a bijection from equivalence classes of group extensions and elements of $H^2(G,A)$ . Another approach that I considered was to work directly with the arbitrary projective resolution (similar to the proof of the Yoneda Ext result).
Suppose that we are given a group extension $0\to A\to E\to G\to0$ .
We want to construct an element of $\ker(\Hom_{\Z G}(P_2,A)\to\Hom_{\Z G}(P_3,A))$ .
Equivalently, we want to construct a $\Z G$ -module homomorphism $P_2/\im(P_3\to P_2)\to A$ .
However, $\im(P_3\to P_2)=\ker(P_2\to P_1)$ and $P_2/\ker(P_2\to P_1)\cong\im(P_2\to P_1)=\ker(P_1\to P_0)$ .
Thus, we want to construct a $\Z G$ -module homomorphism $f\colon\ker(P_1\to P_0)\to A$ .
Furthermore, if we unwind some more definitions, we see that we only need to construct $f$ up to the restriction of a $\Z G$ -module homomorphism $P_1\to A$ . Unfortunately, the only information we have about $A$ is the short exact sequence $0\to A\to E\to G\to0$ which makes it hard to define a $\Z G$ -module homomorphism to $A$ .","['homological-algebra', 'group-extensions', 'group-rings', 'group-cohomology', 'group-theory']"
3208838,The role of eigenvalue multiplicity in bifurcations,"Consider $\dot x =f(x)$ where $x\in\mathbb{R}^n$ and $f:\mathbb{R}^n\to\mathbb{R}^n$ is smooth enough. I am studying Fold and Hopf bifurcations in such ordinary differential equations. We know that a bifurcation happens when we break the hyperbolicity of the Jacobian matrix $\frac{\partial f}{\partial x}$ . Now, if we break the hyperbolicity via one (or several) zero eigenvalue(s), Fold bifurcation takes place. Moreover, if we we break the hyperbolicity via one (or several) pair(s) of pure imaginary eigenvalue, Hopf takes place. I was wondering if there is any relationship between the algebraic/geometric multiplicty of these eigenvalues and the bifurcations (e.g., their stability, type, etc.)? Any comment or response is greatly appreciated!","['differential-geometry', 'ordinary-differential-equations', 'bifurcation', 'control-theory', 'dynamical-systems']"
3208844,Probability of list having a pair of unchanged consecutive elements once ordered,"I've been grading exams for most of the day. Once I finished grading, I started entering the grades into my gradebook -- one by one, from top to bottom on the stack. About halfway through, I entered one students grade and the next student on the stack was also the next person alphabetically in the gradebook. What is the probability of this happening with $n$ students, all of whom have unique names? Equivalent question: For a random permutation $\left(a_1,a_2,\ldots,a_n\right)$ of the list $\left(1,2,\ldots,n\right)$ , what is the probability that there exists at least one entry $k$ of the permutation that is followed immediately by $k+1$ (that is, $k = a_i$ and $k+1 = a_{i+1}$ for some $i \in \left\{1,2,\ldots,n\right\}$ ) ? For small $n$ , it's not hard to exhaustively calculate the probability. But my combinatorics skills are rusty, and I don't think I can easily calculate this for my 30 students.","['permutations', 'combinatorics', 'probability']"
3208939,Transpose of product of matrices [duplicate],This question already has answers here : How to prove $(AB)^T=B^T A^T$ (5 answers) Closed 5 years ago . How do you prove the following fact about the transpose of a product of matrices? Also can you give some intuition as to why it is so. $(AB)^T = B^TA^T$,['linear-algebra']
3208971,Why irreducible manifolds are prime?,"In wikipedia there is a proof for 3-manifolds that I don't understand. It says that if $M$ is an irreducible manifold and we express $M=N_1\sharp N_2$ , then $M$ is obtained by removing a ball each from $N_1$ and $N_2$ and then gluing the resulting spheres together. These united spheres form a 2-sphere in $M$ , and the fact that $M$ is irreducible means that this sphere must bound a ball. Undoing the gluing operation (how?), either $N_1$ ir $N_2$ is obtained by gluing that ball to the previously removed ball on their borders. I understand until here. Now, it says: 
This operation though simply gives a 3-sphere. That means that one of the two factors was in fact a trivial 3-sphere. But why gluing a 2-sphere to one of the factors gives a 3-sphere? I can't understand this part. Thanks for the help!","['manifolds', 'general-topology']"
3209005,Which subfields of the Galois group of $x^4+8x^2+8x+4$ are Galois and find the splitting field polynomial,"This question is an exercise in Dummit and Foote: 1)I want to find the Galois group of $f(x)=x^4+8x^2+8x+4$ . 2)Which subfields of the splitting field of $x^4+8x^2+8x+4$ are Galois over $\Bbb Q$ ? 3) For the subfields which are Galois over $\Bbb Q$ , find the polynomial $f(x) \in \Bbb Q[x]$ for which they are the splitting field over $\Bbb Q$ . My attempt: I have calculated that $f(x)$ is irreducible moreover, the resolvent cubic $h(x)=x^3-16x^2+48x+64$ is irreducible. Again the discriminant $315392$ is not a square so the Galois group has to $S_4$ . So part 1) is done. Now, the subfields of the Galois group of $x^4+8x^2+8x+4$ which are Galois correspond to the fixed field of a normal subgroup of $S_4$ which are $K_4$ and $A_4$ . So in some sense part 2) is solved. If I want to answer this question as a field $Fix(K_4)=\Bbb Q(a_1,\cdots,a_n)$ and $Fix(A_4)=\Bbb Q(b_1,\cdots,b_r)$ then what will be $a_i$ and $b_j$ . I am not getting any clue for part 3). Please help.","['field-theory', 'galois-theory', 'abstract-algebra', 'symmetric-groups', 'galois-extensions']"
3209007,Find the normalizer of a cyclic subgroup of $S_7$,"Let $P\subset S_7$ be a cyclic subgroup of order $7$ . Show that the normalizer $N$ of $P$ has order $42$ , and find a pair of cycles generating $N$ . My attempt First note that the cyclic subgroup is a Sylow-7 subgroup of $S_7$ . Let the number of Sylow-7 subgroups in $S_7$ be denoted $n_7$ . The Sylow-7 subgroups all intersect trivially and are all cyclic, so every nonidentity element in a Sylow-7 subgroup is of order $7$ and the number of elements in $S_7$ with order $7$ is equal to $n_7$ times $6$ . The elements of order $7$ in $S_7$ are the 7-cycles. And there are $7!/7$ of them. Therefore, $n_7 = 5!$ . Now, to show that $|N|=42$ , use the identity: $n_7 = |S_7 : N| = |S_7|/|N|$ . My question First, I can't see why $N$ is generated by a pair of cycles. Also, I am having trouble writing out explicitly the generators of $N$ . Any help would be greatly appreciated.","['permutations', 'group-theory', 'normal-subgroups', 'cyclic-groups']"
3209084,Using Euler's Formula to prove $e^{i\theta}e^{i\alpha}=e^{i(\theta+ \alpha)}$,"I have a homework question thats been puzzling me. It says: Using Euler's Formula, prove the product property of the complex exponential: $$e^{i\theta}e^{i\alpha}=e^{i(\theta+ \alpha)}$$ Besides knowing Euler's formula, I have no idea where to start so any help is appreciated. :)","['algebra-precalculus', 'trigonometry']"
3209120,Show that $L^nv\rightarrow 0$.,"Let $V$ be a finite-dimensional normed vector space. Let $L:V\rightarrow V$ be a linear operator and let $v\in V$ . Assume that there is a sequence $\{n_i\}_{i=1}^\infty\subset\mathbb{Z}$ such that $L^{n_i}v\rightarrow 0$ . Show that $L^nv\rightarrow 0$ as $n\rightarrow \infty$ . My try: If $v$ is an eigenvector of $L$ , then we have $$
0=\lim L^{n_i}v=\lim \lambda^{n_i}v
$$ which implies that $|\lambda|<1$ . Then we have $$
\lim L^nv=\lim \lambda^nv=0.
$$ How to prove when $v$ is not eigenvector?",['linear-algebra']
3209139,Closure and interior of a connected set $A$,"Let $\overline{A}$ be the closure of $A$ , and $A^{\circ}$ be the interior of $A$ . We assume that $A$ be connected. 1. Is $\overline{A}$ connected? My answer is yes. Because, if $\overline{A}$ is not connected, we can write $$\overline{A}=B\cup C$$ such that $B,C$ are separated. i.e., no limit point of $B$ is in $C$ and vice versa. Also, both $B,C$ are clopen in $\overline{A}$ . And note that $B,C$ are non-empty. WLOG, suppose $A\subset B$ . Since $$\overline{A}=A\cup A'$$ where $A'$ is the set of all limit points of $A$ , $C$ must contain a limit point $l$ of $A$ . But then, since $C$ is open, $C$ is a neighborhood of $l$ that doesn't intersect $A$ ; which makes $l$ not a limit point of $A$ . A contradiction. So $A\not\subset B$ and by the same process, $A\not \subset C$ . Hence $$A=(A\cap B)\cup(A\cap C)$$ separated by two non-empty clopen (in $A$ ) sets, thus $A$ is not connected. So we have the contrapositive statement "" $\overline{A}$ not connected $\implies$ $A$ not connected"", which proves "" $A$ connected $\implies$ $\overline{A}$ connected"". 2. Is $A^{\circ}$ connected? My answer is no. Consider $$A=\{(x,y)\in \mathbb{R}^2:x^2+y^2\leq 1\}\cup\{(x,y)\in\mathbb{R}^2:(x-2)^2+y^2\leq 1\}$$ two circles tangent to each other at $(1,0)$ . Clearly this $A$ is connected. Then the interior would be $$A^{\circ}=\{(x,y)\in \mathbb{R}^2:x^2+y^2< 1\}\cup\{(x,y)\in\mathbb{R}^2:(x-2)^2+y^2< 1\}$$ a union of two disjoint open sets. Which is separated. Thus in some cases $A^{\circ}$ is not connected even if $A$ is connected. Does this argument make correct proof?","['general-topology', 'proof-verification']"
3209151,"Gradient and Hessian of $f(x,y) := a^T \left( x \odot \left[ \exp\left( \mu \ (y \ \oslash \ x) \right) - 1 \right] \right)$, wr.t. $x$ and $y$","How to find the Gradient and Hessian of \begin{align}
f(x,y) := a^T \left( x \odot \left[ \exp\left( \mu \  (y \ \oslash \ x)  \right) - 1 \right] \right) \ ,
\end{align} where $a, x, y \in \mathbb{R}^n$ , all-ones vector $1 \in \mathbb{R}^n$ , and $\mu  \in \mathbb{R}$ ? Also, $\odot$ and $\oslash$ means elementwise multiplication and division, respectively.","['multivariable-calculus', 'matrix-calculus']"
3209154,"If $x = 2$ is a root of $\det\left[\begin{smallmatrix}x&-6&-1\\2&-3x&x-3\\-3&2x&x+2\end{smallmatrix}\right]=0$, find other two roots","If $x = 2$ is a root of equation $$ \begin{vmatrix}
x & -6 & -1 \\
2 & -3x & x-3\\
-3 & 2x & x+2 
\end{vmatrix} = 0 $$ Then find the other two roots. I solved it and got a cubic equation, and then I divided it by $(x-2)$ to get the other two roots. But this is a long method to do. Please help me with some shorter approach to this question.","['matrices', 'matrix-equations', 'determinant']"
3209191,Green's theorem over an annulus,"I need help with this problem: Verify Green's Theorem in the plane where $S$ is the annulus $\{(x,y)\in\mathbb{R^2}|a^2\leq x^2+y^2\leq b^2\}$ and $F(x,y)=\left(\frac{-y}{\sqrt{x^2+y^2}},\frac{x}{\sqrt{x^2+y^2}}\right)$ $F(x,y)=\left(\frac{-y}{x^2+y^2},\frac{x}{x^2+y^2}\right)$ $F(x,y)=\left(\frac{x}{x^2+y^2},\frac{y}{x^2+y^2}\right)$ I was able to compute the line integral $\int_{\partial S^+} F\cdot d\mathbf{r}$ , but I'm having problems with the double integral $\iint_S\left(\frac{\partial F_2}{\partial x}-\frac{\partial F_1}{\partial y}\right)dA$ . My problem is that I don't know which limist should I use. I know that I could use polar coordinates, but this problem is from a chapter before change of variables, so I think I'm not supposed to solve it like that. I just need help with getting the limits of integration right, since I think it is easy to compute the double integral after that.","['integration', 'greens-theorem', 'multivariable-calculus', 'vector-analysis']"
3209279,Is it true that $3^n = 2^{O(n)}$?,I know that the two main rules are dropping low order terms and dropping constant factors. For example: $50n = O(n)$ $5n^2 + 3n + 45 = O(n^2)$ But in a textbook I found the question: Is it true that $3^n = 2^{O(n)}$ ? The answer is true but I do not understand why it is not $3^{O(n)}$ . I know you cannot just drop the base completely but why is $3$ changed to $2$ ?,"['combinatorics', 'asymptotics']"
3209301,The identity theorem at the boundary (complex analysis),"Let $\mathbb{D}^2$ be the closed unit disk, and let $f:\mathbb{D}^2 \to \mathbb{C}$ be a smooth map, which is holomorphic on the open unit disk $\text{int}(\mathbb{D}^2)$ . Suppose that there exists a sequence $z_ n \in \text{int}(\mathbb{D}^2)$ , $z_n \to z_0 \in \partial \mathbb{D}^2$ such that $f(z_n)=0$ . Is $f$ identically zero on $ \mathbb{D}^2$ ? The usual formulation of the identity theorem is for open connected domains; it states that a holomorphic function whose zero set has an accumulation point (inside the open domain) is identically zero. Note that I assumed that $f$ is smooth on the closed disk. (In a sense it is ""holomorphic"" at the boundary too, as the condition of being conformal is a closed one). Edit: If $f$ could be extend $f$ holomorphically to an open neighbourhood of $\mathbb D^2$ , then the answer would be positive, by the usual identity theorem (as the accumulation point would now be in the interior of the new extended domain). I am not sure if such an extension is always possible. There are certainly continuous examples that cannot be extended: e.g. $ f(z) = \sum_{n=1}^\infty \frac{z^{n!}}{n!}$ . (See here for details). However, I don't know any smooth example which cannot be extended.","['smooth-functions', 'real-analysis', 'complex-analysis', 'differential-topology', 'analytic-functions']"
3209323,"If $z=e^{\frac{2\pi i}m}$, then $\sum_{k=1}^mz^k=0$ ($m\neq1$)","Suppose $z=e^{\frac{2\pi i}m}$ for $m\in\mathbb N$ and $m\neq1$ .
Is the following equality hold? $$\sum_{k=1}^mz^k=0\tag{1}$$ $(1)$ seems trivial geometrically ;
it says that the sum of all vectors with equal magnitudes and uniform angle differences should be zero. If $m$ is even ( $m=2l$ ), then $$z^l=e^{i\pi}=-1$$ and $$z^k+z^{k+l}=z^k(1+z^l)=0$$ for every $k=1,2,\cdots,l$ .
So $(1)$ holds. If $m$ is odd, then $(1)$ seems nontrivial.
For $m=3$ , the question becomes straightforward. If $m=5$ , it is quite sophisticated but solvable by using elementary mathematics ; Let $\theta=\frac25\pi$ .
Then $(1)$ is equivalent to $(2)$ and $(3)$ where $$\sum_{k=1}^5\cos k\theta=0\tag{2}$$ and $$\sum_{k=1}^5\sin k\theta=0\tag{3}$$ $(3)$ is trivial from $\sin(2\pi-\phi)=-\sin\phi$ .
For $(2)$ , we can use $\cos(2\pi-\phi)=\cos\phi$ and compute as follows \begin{align*}
\sum_{k=1}^5\cos k\theta
&=\cos\theta+(2\cos^2\theta-1)+(2\cos^2\theta-1)+\cos\theta+1\\
&=4\cos^2\theta+2\cos\theta-1
\tag{4}
\end{align*} On the other hand, (denote $s=\sin\frac\pi{10}$ and $c=\cos\frac\pi{10}$ ) $$2sc=\sin\frac\pi5=\cos\left(\frac\pi2-\frac\pi5\right)=\cos\frac{3\pi}{10}=4c^3-3c$$ Dividing both sides by $c(\neq0)$ yields \begin{gather*}
2s=4c^2-3\\
4s^2+2s-1=0\tag{5}
\end{gather*} Since $s=\cos\theta$ , the last expression of $(4)$ becomes zero, and this proves $(2)$ . So $(1)$ holds for every even $m$ and $m=3,5$ .
But what if $m$ is an odd number grater than $5$ ?.
Is there a general way to explain $(1)$ ? And if it is the case, can I conclude $(2)$ and $(3)$ , $m$ in place of $5$ ?
i.e. do $$\sum_{k=1}^m\cos\frac{2\pi k}m=0\tag{2*}$$ and $$\sum_{k=1}^m\sin\frac{2\pi k}m=0\tag{3*}$$ hold for every $m\in\mathbb N\setminus\{1\}$ ?","['complex-analysis', 'trigonometry']"
3209345,On the Taylor coefficients of $\arcsin^3$,"The Maclaurin series of $\arcsin^2$ and $\arcsin^4$ are fairly well-known, $$ \arcsin^2(x) = \sum_{n\geq 1}\frac{(2x)^{2n}}{2n^2\binom{2n}{n}},\qquad \arcsin^4(x)=3\sum_{n\geq 1}\frac{H_{n-1}^{(2)}(2x)^{2n}}{2n^2\binom{2n}{n}} $$ but in order to deal with some logarithmic integrals I need the Maclaurin series of $\arcsin^3(x)$ . Mr. Wolfram states this is a result of Ramanujan, but I have not been able to find it in his notebooks, so I would like some help. Any derivation from scratch is clearly just as welcome.","['power-series', 'trigonometry', 'sequences-and-series']"
3209354,Using Venn diagram to find HCF and LCM,"Find the HCF and LCM of 40 and 60, we write them as prime factors $40=2^3\times 5$ and $60=2^2\times 3 \times 5$ LCM(40 and 60) $=2^3\times 3\times5=120$ HCF(40 and 60) $=4\times5=20$ How do I find the HCF and LCM of 40 and 60 using a Venn diagram method?","['elementary-set-theory', 'elementary-number-theory', 'least-common-multiple']"
3209387,"If $g(x,y)$ measurable, why $g$ can be boundedly approximate by functions of the form $\sum_{k=1}^n f_k(x)h_k(y)$?","Let $g=g(x,y)$ measurable. 1) What does mean "" $g$ can be boundedly approximate by the sequence $g_n$ "" ? What is this ""boundedly"" ? 2) Why $g$ can be boundedly approximate by functions of the form $\sum_{k=1}^n f_k(x)h_k(y)$ ? I didn't find such a result in Real-analysis of Stein and Shakarchi, neither on wikipedia. Is it a classical result ? Here the context were I found it : It's in the book Stochastic Differential Equation of Oksendal (See red arrow).","['measure-theory', 'stochastic-differential-equations', 'stochastic-calculus', 'real-analysis']"
3209432,Why do the derivations of $\ln(\frac{a}{b})$ and $\ln(a) - \ln(b)$ yield different results,"So I was doing some exercises and I noticed that for one example which was of the form $$\ln( \frac{a}{b} )$$ (with a and b being some term with x), that I was getting a different result for taking the derivation when using the logarithmic rule $$\ln( \frac{a}{b} ) = \ln(a) - \ln(b)$$ before deriving  versus applying chain and quotient rules right away. I tried this with some other examples of that form too and I always ended up getting different results, but I have no idea what would cause this to happen. One of the examples I tried would be $$\ln( \frac{4+x}{4-x} )$$ which yields $$\frac{-8+8x}{(4+x)^3}$$ when applying chain and quotient rules right away and $$\frac{8}{16-x^2}$$ when using $$\ln( \frac{a}{b} ) = \ln(a) - \ln(b)$$ before deriving. Would really appreciate some help, thanks in advance.","['derivatives', 'analysis', 'logarithms']"
3209434,"Measure spaces proof $A,B \in\mathcal{B}$ and $\mu (A\Delta B) = 0$, then $\mu (A) = \mu (B)$ .","Let $(X, \mathcal{B}, \mu)$ be a measure space and let $A\Delta B = (A$ \ $B) \cup (B$ \ $A)$ . Show that If $A,B ∈\mathcal{B}$ and $\mu(A\Delta B) = 0$ , then $\mu(A) = \mu(B)$ .",['measure-theory']
3209473,The universal cover of $S^1 \times S^2$,"I'm trying to prove that the universal cover of $S^1 \times S^2$ is $\mathbb{R}^3 \setminus \{0\}$ . I know that the universal cover of $S^1$ is $\mathbb{R}$ and the universal cover of $S^2$ is $S^2 $ . But I don't know how I can use this for prove it.
Thanks for the help!","['manifolds', 'general-topology']"
3209502,Proving that $a!b!$ divides $\left(a + b \right)!$ using group theory,"I was wondering whether this argument proves that $a!b!$ divides $\left(a + b \right)!$ , and whether one could make it more rigorous. Let $S_{a+b}$ be the symmetry group of $\{1, 2, \ldots , a+b\}$ . Describe a subgroup of $S_{a+b}$ isomorphic to $S_a\times S_b$ as the set of permutations that permute $\{1,\ldots,a\}$ amongst themselves, and $\{a+1,\ldots,a+b\}$ amongst themselves. Then, by Lagrange's Theorem, $|S_a\times S_b|=|S_a||S_b| = a!b!$ divides $|S_{a+b}|=(a+b)!$ .","['group-theory', 'proof-verification', 'divisibility', 'group-isomorphism']"
3209512,What is the name of this hexagon/pentagon polyhedron?,"What is the name of this convex polyhedron? $(V,E,F)=(14,36,24)$ . The top and bottom vertices are degree- $6$ , spanning
hexagons, which are zigzag connected in the band between the
two hexagons. The faces are approximate isosceles triangles
in this physical model.","['polyhedra', 'geometry', 'terminology']"
