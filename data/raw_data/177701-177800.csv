question_id,title,body,tags
3209521,Minimizing $\left ( \sin^2(x) + \frac{1}{\sin^2(x)} \right )^2 + \left ( \cos^2(x) + \frac{1}{\cos^2(x)} \right )^2$,"While solving a problem I came across this task, minimizing \begin{align}
\left ( \sin^2(x) + \frac{1}{\sin^2(x)} \right )^2 + \left ( \cos^2(x) + \frac{1}{\cos^2(x)} \right )^2.
\end{align} One can easily do it with calculus to show that the minimum value is $12.5$ .
I tried to do it using trigonometric identities and fundamental inequalities (like AM-GM, Cauchy-Schwarz, etc.) but failed. Can someone help me to do it using trig identities and inequalities?","['maxima-minima', 'trigonometry']"
3209524,"What is a standard name for a ""relation"" as a subset of $X\times \mathcal P(X)$ rather than of $X\times X$","(Binary) relations on $X$ are formalized as subsets of $X\times X$ . But there are also times when a ""relation"" is a subset of $X\times \mathcal P(X)$ . For example, in topology, we may say that $x$ is in the closure of $X$ , and consider this as a relation, and write $x<X$ . Is there a standard name for such a point-to-set ""relation""?","['elementary-set-theory', 'relations', 'terminology']"
3209525,Angle created by a parallel transport along a smooth closed curve,"This answer uses the fact if you parallel transport a vector around a small smooth closed curve $C$ , the angle through which it turns is $2\pi - \int_C \kappa_g(s)\,ds$ . I don't see it immediately. I tried to use Gauss-Bonnet but it didn't work. A small proof will be very welcome.","['surfaces', 'riemannian-geometry', 'differential-geometry']"
3209537,Does $SO(n)$ lie in any $(n^2-1)$-dimensional subspace of $\mathbf R^{n^2}$?,"The matrix group $SO(n)$ can be treated as a submanifold of $\mathbf R^{n^2}$ . Does it lie in any $(n^2-1)$ -dimensional subspace of $\mathbf R^{n^2}$ ? For $n=2$ the answer is yes because $SO(2)$ lies in the span of the identity matrix and $\begin{pmatrix}
0 & 1\\ 
-1 & 0
\end{pmatrix}$ . How about for $n>2$ ? Thanks.","['matrices', 'linear-algebra', 'lie-groups', 'differential-geometry']"
3209543,"If $ y= x^{n-1}\log(x)$ , then prove that $D^n y $ is $ \frac{(N-1)!}{x}$","$ y= x^{n-1} \log(x)$ , then prove that $D^n y $ is $  \frac{(N-1)!}{x}$ ""> I don't understand this notation of "" $D^n$ "".I searched it on internet and didn't got any useful information ( What is the operator ""capital D"" and how can the chain rule be used in this way ) Please tell me what this notation stands for so that I can solve this question.","['multivariable-calculus', 'calculus']"
3209613,Why does this procedure terminate? Or are there any numbers for which it doesn't?,"I don't really have good formal education in theoretical mathematics, so please don't be upset if this is obvious question, but on the other hand I don't believe I am the first one to think of such problem. So let p,q be Natural numbers q != 0 (we will be thinking of them as a dividend and divisor of a fraction) and procedure looks more or less like that: f(p,q): 
if (gcd(p,q) > 1) return f(p/gcd(p,q), q/gcd(p,q))
if (p/q > 1/3) then return f(p+1, q+4)
if (p/q < 1/3) then return f(p+1, q+1)
if (p/q == 1/3) then return WIN so the case that it should end in some infinite number of steps is intuitive - when we are larger than 1/3 we step towards 1/4 and if we are smaller we step towards 1. Running simple script given result that for all pairs of numbers (up to 5 of decimal digits in size) it ends at some time, so my question is ""Can anyone prove that this procedure finishes after some finite number of steps and not loops infinitely for any numbers p and q as described?""","['fractions', 'number-theory', 'computability']"
3209643,Each cell of a $100 × 100$ table is painted either black or white and all the cells adjacent to the border of the table are black.,"Each cell of a $100 × 100$ table is painted either black or white and all the cells adjacent to the border of the table are black. Can we color the rest of a table so that every $2 × 2$ square there are cells of both colours? This problem is related to Prove there exists $2\times 2$ checkerboard-colored square in a $100\times 100$ table colored black and white. When I was solving related problem I tryed to draw such $n\times n$ table for $n\in\{3,4,5,6\}$ . For 3 and 5 (and any odd number) we can just do concentric rings. I could'n draw it for $n=4$ and also for $n=6$ . So is such a coloring even possible for $n=100$ or any even $n$ ?","['combinatorics', 'discrete-mathematics']"
3209652,Vector proof of shortest distance from a point to a line: flaw in my reasoning.,"Let $E$ an euclidean plane, $P$ a point in $E$ , and $d$ a straight line in $E$ with a fixed point $A$ and a direction vector $\vec{V}$ , so that any other point $X \in d$ can be described through a real parameter $t$ by $$\vec{AX}=t\vec{V}$$ . Consequently, we can write $$\vec{PX}=\vec{PA}+t\vec{V} \,\,\,\,\,\,\,\,\,\,\,\,\    [1]$$ In this mathexchange question, I have a problem with a proof to show the shortest distance from $P$ to $d$ . In fact, I am able to calculate it by minimizing the quantity $$||\vec{PX}||^2$$ seen as a function of $t$ . That expression is purely scalar so it's easy to avoid mistake when minimizing it through differentiation. But just out of curiosity I tried to get to the same result by minimizing $\vec{PX}$ instead of its square, and I have a problem: I can show the shortest distance is perpendicular, but I get the magnitude wrong. Here is the reasoning: First I write $\vec{PX}=|\vec{PX}|.e_{\vec{PX}}$ , where $e$ is the unit vector along the direction of $\vec{PX}$ . Minimizing equation $[1]$ with respect to $t$ means two things: 1/ First I must differentiate both sides of $[1]$ : $$(\partial_t|\vec{PX}|).e_{\vec{PX}}+|\vec{PX}|.(\partial_te_{\vec{PX}})=0+\vec{V}\,\,\,\,\,[2]$$ 2/ Now I impose the minimization condition on the distance: this means that the object $\partial_t|\vec{PX}|=0$ , so the only part that survives in the expression $[2]$ is $$|\vec{PX}|.(\partial_te_{\vec{PX}})=\vec{V}\,\,\,\,\,[3]$$ Now there is a reasoning of vector calculus that tells us that the differential of a unit vector is perpendicular to it. The LHS of $[3]$ tells us that $\partial_te_{\vec{PX}}$ is perpendiculat to $\vec{PX}$ but the RHS of $[3]$ tells us that this perpendicular object is also parallel to $\vec{V}$ . Hence the shortest distance $|\vec{PX}|$ is perpendicular to the straight line $d$ . But then I get stuck and I don't see how to get the magnitude of that distance. At first I would want to write $$|\vec{PX}|=\frac{|\vec{V}|}{|\partial_te_{\vec{PX}}|} \,\,\,\,\,\, [4]$$ I do not see how to calculate the actual magnitude of $|\vec{PX}|$ from there. In fact, I suspect there is a mistake somewhere, because the direction vector $\vec{V}$ can be arbitrarily small or large, while $\vec{PX}$ is fixed by the geometry. I am probably missing something very silly. I have explained the problem the most clearly I can, any insight would be appreciated. Thanks.","['analytic-geometry', 'vectors', 'geometry', 'multivariable-calculus', 'optimization']"
3209660,Show that ${{2m} \choose {m}} \leq \frac{2^{2m}}{\sqrt{2m}}$.,The question is as it is in the title: Show that $${{2m} \choose {m}} \leq \frac{2^{2m}}{\sqrt{2m}}$$ for all $m \in \mathbb{N}$ . I've had various attempts at this question but it never seems to lead anywhere fruitful. The hint we have been given is in the question is Consider the square of the product $$ \frac{(2m)!}{2^{2m}(m!)^2} = \frac{3 \times 5 \times 7 \times \dots \times (2m-1)}{2 \times 4 \times 6 \times \dots \times (2m)}. $$ From the hint it's not too hard to spot where one would go next - the LHS of the original question is disguised as some cheeky factorials - however induction keeps on failing for me and I'm struggling to see a more direct argument. Any light shed on this problem would be appreciated. I feel like I'm missing something obvious. Thanks in advance.,"['inequality', 'binomial-coefficients', 'combinatorics']"
3209689,Cohomology of quadric in $\mathbb{C}^4$ at infinity,"How to prove that the singular cohomology of $X=V(xy-zw)\setminus 0 \subset \mathbb{C}^4$ is $$H^*(X,\mathbb{Z})=\{\mathbb{Z},0,\mathbb{Z},\mathbb{Z},0,\mathbb{Z}\}?$$ Preferably, I would like to know whether the stronger result $$X \simeq S^2 \times S^3$$ holds?","['algebraic-geometry', 'homology-cohomology', 'algebraic-topology']"
3209702,Discrete-time LQR and solutions via LMI,"Having a infinite horizon discrete-time LQR problem $J^* = \min_u \ \sum_{k=0}^{\infty} x^\top_k Q x_k +u^\top_kRu_k$ subject to $x_{k+1}= Ax_k+Bu_k, \quad x(0)=x_0$ . With some algebra manipulations, and setting $J^*=x_kPx_k$ , with $P=P^\top\succ 0$ the following LMI is obtained: $J^* = \begin{bmatrix}
u_k\\x_k
\end{bmatrix}^\top \begin{bmatrix}
B^\top PB+R & B^\top PA\\A^\top PB & A^\top PA +Q
\end{bmatrix} \begin{bmatrix}
u_k\\x_k
\end{bmatrix} \prec 0$ Taking the Schur complement, the resulting state feedback controller $u_k=Kx_k$ is $K = -(R+B^\top PB)^{-1}B^\top PA$ where P is the solution of the Riccati equation $P = Q + A^\top PA - A^\top PB(R+B^\top PB)^{-1}B^\top PA$ I implemented an example in Matlab and compared the solutions obtained using the command dlqr and the LMI solved with Yalmip, but the values of the obtained (P,K) are not the same. the code is: A=[1.1 -0.3; 1 0];
B=[1;0];
Q=eye(2,2);
R=1;

%% inf horizon
[K,S,e] = dlqr(A,B,Q,R)

%% LMI solver:
P = sdpvar(2,2);
F1 = [A'*P*A + Q,A'*P*B; B'*P*A, R+B'*P*B ];
F = [P>=0, F1<=0];
optimize (F,P);
Pfeasible=value(P);
Kfeasible = -inv(R+B'*Pfeasible*B)*B'*Pfeasible*A Do you have an idea why? is it due to the solver?","['schur-complement', 'linear-matrix-inequality', 'convex-optimization', 'matrices', 'matrix-equations']"
3209716,Critical points and immersion map,"I was dealing with the following problem from differential geometry yesterday. Let $ x_1, \ldots, x_4 $ be points in general position in $ \mathbb{R} ^3 $ (that is they don't lie in a plane). Let $ q_1, \ldots, q_4 \in \mathbb{R} $ be electric charges placed at these points. The potential function of the resulting electric field is given by $$ V_q= \frac{q_1}{r_1} + \ldots + \frac{q_4}{r_4} $$ where $ r_i=|x-x_i| $ . The critical points of $ V_q $ are called equilibrum points of the electric field and an equilibrum point is non-degenerate if the critical point is. Prove that for almost all $ q $ the equilibrum points of $ V_q $ are non-degenerate and finite in number. Show that the map $ \mathbb{R}^3 - \{ x_1,\ldots , x_4 \} \rightarrow \mathbb{R}^4 $ with coordinates $ r_1, \ldots, r_4 $ is an immersion."" So far I was able to find the critical points and for showing that the given map is an immersion on the second part I was considering to find the rank of derivative and check if it is equal to the dimension of $ \mathbb{R}^3 - \{ x_1, \ldots, x_4 \} $ but not sure if this is the right approach or if there is some easier way to show it is an immersion. Any help would be appreciated.",['differential-geometry']
3209744,Two wins in a lottery. Good chance or just luck? [duplicate],"This question already has answers here : If I double my lottery tickets, do I double my chances of winning? [duplicate] (2 answers) Closed last year . I've a probability question.
""I bought a lottery ticket where just wins and blanks are possible. I don't know about the chance to win. 
With the first lottery ticket i won.
Know it could be just luck or the chance to win is ""good"".
I took a second ticket and won again. Was this now just luck again or can i say with a specific guarantee, the chance to win is ""good"" (whatever ""good"" means.) Any approaches welcome.
Thanks for your help and interest
Max","['random', 'lotteries', 'probability']"
3209762,Are surjective functions a pointless concept? [duplicate],"This question already has answers here : What is the purpose of a function being surjective? (6 answers) Closed 4 years ago . What is the point of the concept of surjective or onto functions if you can just restrict the co-domain of your function to its image? Injectivity or 1-to-1ness is actually the defining property of bijections (sometimes called 1-to-1 correspondences), while all the question of surjectivity does is derail the argument into checking whether the image equals the co-domain. Am I wrong in thinking this? What am I missing? Only situation where this concept could be marginally useful that I could think of would be some function for which it is easier to find an element of the co-domain for which no pre-image exists than to actually find the image itself.","['elementary-set-theory', 'functions', 'notation']"
3209824,Does Distributivity Imply Power Associativity?,"Say we have an algebra $(A, +, \cdot)$ , where $(A, +)$ is an Abelian Group. All we know about $\cdot$ is that it is both left and right distributive over addition. So, $\forall a,b,c \in A, a \cdot (b+c) = (a \cdot b) + (a \cdot c)$ and $(b+c) \cdot a = (b \cdot a) + (c \cdot a)$ . We can't assume $ \cdot $ is associative, commutative, or anything else besides distributive. Do we know whether multiplication is power associative or not? That is, for all $a$ , powers of $a$ are associative (e.g $a \cdot (a \cdot a) = (a \cdot a) \cdot a$ ). If so, what would the proof look like? If not, is there a counterexample? I attempted this myself, but I couldn't find any hints of a proof, so I tried to produce a counterexample, similarly with no luck.","['nonassociative-algebras', 'abstract-algebra']"
3209847,Eliminate $\theta$ from $\lambda\cos2\theta=\cos(\theta + \alpha) \space$ and $\space \space\lambda \sin2\theta=2\sin(\theta + \alpha)$,"Eliminate $\theta$ from $\lambda \cos2\theta=\cos(\theta + \alpha)$ and $\lambda\sin2\theta=2\sin(\theta + \alpha)$ My approach: Dividing the RHS and LHS of both equations by $\lambda$ , then squaring and adding them, we get, $$\frac{\cos^2(\theta+\alpha)}{\lambda^2}+\frac{4\sin^2(\theta+\alpha)}{\lambda^2}=\cos^22\theta + \sin^22\theta=1$$ $$\Rightarrow \sin^2(\theta+\alpha)=\frac{\lambda^2-1}{3}$$ I am unable to proceed.",['trigonometry']
3209888,Cochran's Theorem,"I am preparing a work on Cochran's theorem and I had two questions : First question : Is there a link between these two statements and to what extent? Would it be redundant to prove each of them separately ? Theorem $1$ (Cochran, algebraic) : Let $E$ be a euclidean space of dimension $n$ and $ u_1, ..., u_p $ be symmetric endomorphisms on E . Suppose that : $(i)$ $\text{rk}(u_1)  +\  ... \ + \text{rk}(u_p) = n$ . $(ii)$ $q_1(x) + \ ... \ + q_p (x) = \langle x,x \rangle\ $ where $q_k(x) =  \langle u_k(x),x\rangle$ . Then $E = \bigoplus\limits_{1\le i \le p}^{\perp}\text{Im}(u_i)$ . Besides, for all $i\in \{1,...,p\}$ , $u_i$ is an orthogonal projector on its image. Theorem $2$ (Cochran, probabilistic) : Let $X \sim \mathcal{N}_d (0, I_d) $ be a gaussian vector and $ \bigoplus \limits_{1\le i \le p}^{\perp} E_i = \mathbb{R}^d $ with $\dim(E_i)= d_i$ for all $i\in \{1,...,p\}$ . Then the orthogonal projections $\pi_{E_1} (X), ..., \pi_{E_p} (X) $ are independent gaussian vectors. Besides, for all $i \in \{1,...,p\}$ : $\Vert \pi_{E_i}(X)\Vert^2 \sim \chi^2(d_i)$ . Second question : Does anyone know of an application of these theorems, other than the statistical gaussian linear model tests ? Specifically is there a purely algebraic application to theorem $1$ ? Thanks in advance.","['statistics', 'bilinear-form', 'linear-algebra', 'probability-theory', 'quadratic-forms']"
3209891,"If $h$ is twice differentiable, then $|h|$ is twice differentiable except on a countable set","Let $h:\mathbb R\to\mathbb R$ be differentiable. It can be shown that $$N:=\left\{a\in\mathbb R:h(a)=0\text{ and }h'(a)\ne0\right\}$$ is countable and $|h|$ is differentiable on $\mathbb R\setminus N$ with $$|h|'(a)=\begin{cases}\displaystyle\frac{h(a)}{\left|h(a)\right|}h'(a)&\text{, if }h(a)\ne0\\0&\text{, if }h'(a)=0\end{cases}\tag1$$ for all $a\in\mathbb R$ . Assuming $h$ is twice differentiable, can we show a similar statement for the second derivative of $|h|$ , i.e. that there is a countable $N'\subseteq\mathbb R$ such that $|h|$ is twice differentiable on $\mathbb R\setminus N'$ ? EDIT : It would be enough for me, if $N'$ can be shown to have Lebesgue measure $0$ (as opposed to being even countable). Moreover, if necessary, feel free to assume that $h''$ is continuous. EDIT 2 : We already know that $|h|$ is differentiable at $a$ with $$|h|'(a)=\operatorname{sgn}(h(a))h'(a)\tag5$$ for all $a\in\left\{h\ne0\right\}\cup\left\{h'=0\right\}$ . Now, since $h$ is continuous, $\operatorname{sgn}h$ is differentiable at $a$ with $$(\operatorname{sgn}h)'(a)=0\tag6$$ for all $a\in\left\{h\ne0\right\}\cup\left\{h=0\right\}^\circ$ (see: Can we show differentiability of $\operatorname{sgn}h$ on a larger set than $\left\{h\ne0\right\}$? ). Thus, by the chain rule, $|h|$ is twice differentiable at $a$ with $$|h|''(a)=\operatorname{sgn}(h(a))h''(a)\tag7$$ for all $a\in\left\{h\ne0\right\}\cup\left\{h=0\right\}^\circ\cap\left\{h'=0\right\}$ . The complement of the latter set is $$N_0:=\left\{h=0\right\}\cap\left(\mathbb R\setminus\left\{h=0\right\}^\circ\cup\left\{h'\ne0\right\}\right)=\partial\left\{h=0\right\}\cup N.$$ However, since $\partial\left\{h=0\right\}$ doesn't need to have Lebesgue measure $0$ (please correct me if I'm wrong), we cannot conclude. (Please take note of my related question: if $h$ is twice differentiable, what is the largest set on which $|h|$ is twice differentiable? .)","['calculus', 'derivatives', 'absolute-value', 'real-analysis']"
3209931,"If $g(x)f'(x) = f(x)g'(x)$ show there is some $c$ in $\mathbb{R}$ such that $f(x)=cg(x) \forall x$ in $\mathbb{R}$. (Fitzpatrick 4.3, 15)","I am working through an exercise in the Fitzpatrick Advanced Calculus book for some practice, section 4.3 exercise 15: Let $g:\mathbb{R}\rightarrow\mathbb{R}$ and $f:\mathbb{R}\rightarrow\mathbb{R}$ be differentiable and suppose $g(x)f'(x) = f(x)g'(x)$ for all $x$ . If $g(x) \ne 0$ show there is some $c$ in $\mathbb{R}$ such that $f(x)=cg(x)$ for all $x$ in $\mathbb{R}$ . Attempt Let $h(x)=g(x)f(x)$ , so $h'(x)=f'(x)g(x)+g'(x)f(x)$ . Then  by hypothesis, $h'(x)=f'(x)g(x)+g'(x)f(x)=2f'(x)g(x)=2g'(x)f(x)$ . So $\frac{2}{2}=\frac{f'(x)}{g'(x)}=\frac{f(x)}{g(x)}$ . Now obviously we are trying to show that $\frac{f(x)}{g(x)}=\frac{f'(x)}{g'(x)}=c$ .  So by setting $c=2/2 = 1$ it seems like we have proven the desired result. Is this correct? Seems too simple.","['calculus', 'derivatives', 'real-analysis']"
3209975,Is there a palindrome prime $p>3$ that is also palindrome in base $\ 5\ $?,"A prime $\ p\ $ is called palindrome, if the digits in reverse order give the same prime. For bases $\ b=2,3,4\ $ , there are large examples of palindrome primes that are also palindrome in base $b$ , but for $\ b=5\ $ , I know only the trivial primes $\ p=2\ $ and $\ p=3\ $ . Is there a palindrome prime $\ p>3\ $ that is also palindrome in base $\ 5\ $ ? With this routine : ? z=5;for(a=1,10^10,u=digits(a);if(gcd(u[1],10)==1,for(b=0,9,n=a*10+b;forstep(k=l
ength(u),1,-1,n=n*10+u[k]);if(isprime(n)==1,v=digits(n,z);if(Vecrev(v)==v,print(
n)))))) we can check whether a solution with $\ 21\ $ digits or less exists. Brute force easily reveals that no prime below $\ 11\ $ does the job, so we can assume that the number of digits is odd and start with $\ 101\ $ . The program generates the palindromes and checks whether there is a solution. I ran the program with limit $\ 10^8\ $ with no result, so a solution must have more than $\ 17\ $ digits.","['number-theory', 'elementary-number-theory', 'palindrome', 'recreational-mathematics', 'prime-numbers']"
3209980,Are groups completely determined by their representations?,"Recently, I became interested in representation theory, and I found out a natural philosophical (vague) question:  are groups completely determined by their representations? To be specific, I want to know answers about following questions: (1) For any (discrete) group $G$ and a field $k$ , let $\text{Rep}_{G,k}$ be the category of representations of $G$ over $k$ . If $\text{Rep}_{G,k}$ and $\text{Rep}_{G',k}$ are equivalent for all $k$ , does this implies $G\simeq G'$ ? How about finite dimensional representation? (2) What happens if '(discrete) group' changed to other kinds of groups (and representation also changed by appropriate alternatives), such as continuous representations of topological groups, or smooth representations of Lie groups? Since (1) and (2) are just my formulations of the original question, please let me know if there exist other better-formulated specific questions related to the original question. Also, if you know related theorems (or conjectures), even if they do not exactly focus on (1) and (2), please tell me. Thanks in advance.","['group-theory', 'representation-theory']"
3209990,A difficult functional series (still unsolved),"The problem is to prove if the following functional series converges or not and in the affirmative case to find its sum $$\qquad\qquad\ \sin^2(\pi x) \sum_{k=1}^\infty\frac{1}{k^2\sin^2(\frac{\pi x}{k})}=\sum_{k=1}^\infty  \frac{\sin^2(\pi x)}{k^2\sin^2(\frac{\pi x}{k})}\qquad\ \text{with}\quad x,k\in\Bbb N-\{0\}$$ The denominator of the series, upon which the summation variable acts, can be rewritten in many ways, as follows, none of which have seemed to be useful to solve the problem: $$\frac{1}{k^2\sin^2(\frac{\pi x}{k})}=\frac{1}{(\pi x)^2\operatorname{sinc}^2(\frac{\pi x}{k})}=\frac{\csc^2(\frac{\pi x}{k})}{k^2}=\frac{1+\cot^2(\frac{\pi x}{k})}{k^2}=\frac{2}{k^2(1-\cos(\frac{2\pi x}{k}))}=\frac{1}{2k^2(1+\cos(\frac{\pi x}{k}))}+\frac{1}{2k^2(1-\cos(\frac{\pi x}{k}))}$$ where $$ \csc(x)=\frac{1}{\sin(x)}\quad\text{and}\quad \operatorname{sinc}(x)=\frac{\sin(x)}{x}$$ Also $$\frac{1}{k^2\sin^2(\frac{\pi x}{k})}=\frac{1}{\pi^2}\sum_{m=-\infty}^\infty  \frac{1}{(x-mk)^2}=\frac{1}{\pi^2}\sum_{m=-\infty}^\infty  \frac{1}{(x+mk)^2}$$ since $$\frac{1}{\sin^2(x)}=\csc^2(x)=\sum_{m=-\infty}^\infty\frac{1}{(x-m\pi)^2}=\sum_{m=-\infty}^\infty\frac{1}{(x+m\pi)^2}$$ Maybe it should be worth noting that the series considered resembles in some way the so called Flint Hills Series (that, differently from the one considered, is a numerical series: http://mathworld.wolfram.com/FlintHillsSeries.html ) for which, unto this day, it is not known whether it converges or not. Note: It is obvious that the result is always $0$ , and hence trivial, if the function is evaluated before performing the sum, but this is not what is intended in this case. In fact, for example, the value resulting for $x=10$ after that the summation of $$\sum_{k=1}^N  \frac{\sin^2(\pi x)}{k^2\sin^2(\frac{\pi x}{k})}\qquad\ \text{with}\quad x,k,N\in\Bbb N-\{0\}$$ has been performed up to $N\geqslant x=10$ is, and will always be (meaning that it stands for $N \to \infty$ ), $4$ . Summarizing, it can be easily verified (for convenience with a software like Maple, for example) that $$\forall\alpha\in\Bbb N-\{0\}\qquad\lim_{x\to\alpha}\Biggl(\sum_{k=1}^{N\geqslant \alpha}  \frac{\sin^2(\pi x)}{k^2\sin^2(\frac{\pi x}{k})}\Biggr)=\beta\neq0\qquad\ \text{with}\quad \beta\in\Bbb N-\{0\}$$ where, clearly, this is one of those cases in which the operation of limit and summation cannot be interchanged.
Another example, but that can be carried out by hand: $$\lim_{x\to 2}\Biggl(\sum_{k=1}^2\frac{\sin^2(\pi x)}{k^2\sin^2(\frac{\pi x}{k})}\Biggr)=\lim_{x\to 2}\Biggl(1+\frac{\sin^2(\pi x)}{2(1-\cos(\pi x))}\Biggr)=2\neq0$$ So, from the calculations of the partial sums up to an arbitrary extent is evident that, numerically, the summation converge (pointwise?); the problem is to see if it is possible to find, first, an analytical closed form for the summation.","['complex-analysis', 'trigonometric-series', 'sequences-and-series']"
3210018,"The ""semi-symmetric"" algebra of a vector space","If $V$ is a vector space over a field $K$ then the symmetric algebra $S(V)$ is defined as the tensor algebra $T(V)$ factorized by the two-sided ideal generated by $x\otimes y-y\otimes x$ , with $x,y\in V$ . The homogeneous component of degree $n$ of $S(V)$ is $S^n(V)=T^n(V)/I_n$ , where $I_n$ is the subspace of $T^n(V)$ generated by $x_1\otimes\cdots\otimes x_n-x_{\sigma (1)}\otimes\cdots\otimes x_{\sigma (n)}$ , where $x_1,\ldots,x_n\in V$ and $\sigma\in S_n$ . What I'm interested are the spaces $S'^n(V):=T^n(V)/I'_n$ , where $I'_n$ is generated only by expressions $x_1\otimes\cdots\otimes x_n-x_{\sigma (1)}\otimes\cdots\otimes x_{\sigma (n)}$ with $\sigma\in A_n$ . Alternatively, we may regard $S'^n(V)$ as the homogeneous component of degree $n$ of the algebra $S'(V)=T(V)/I'$ , where $I'$ is the two-sided ideal of $T(V)$ generated by $x\otimes y\otimes z-y\otimes z\otimes x$ , with $x,y,z\in V$ . (It is because $A_n$ is generated by the cyclic permutations $(i,i+1,i+2)$ with $1\leq i\leq n-2$ .) We may call $S'(V)$ the ""semi-symmetric algebra of $V$ "". My question is, is this object already known? Maybe it was introduced by somebody else under other name or other notation. I need it in a paper I'm writing and, if possible, I'd rather quote the definition and the properties of $S'^n(V)$ than write them myself.","['tensor-products', 'abstract-algebra', 'vector-spaces', 'reference-request']"
3210035,"Jordan-Brouwer separation theorem for topological manifolds: is it simple to prove the existance of the notion of ""inside""?","I'm familiar with a general Jordan-Brouwer Separation theorem for a compact connected smooth manifold of codimension $1$ in $\mathbb{R}^N$ ( i.e. not just hyperspheres ). My ultimate goal is to better understand how the analog (in a proper sense) of this theorem carries over to topological manifolds. This, however, seems to be a very deep result that requires very sophisticated machinery (for a non-expert in graduate-level algebraic topology and differential geometry etc..) with very steep entry barrier. While I gather more knowledge on the subject (that might take many months), I hope to make a smaller (immediate progress) in this general direction, with the help of those two questions: The primary question: Is there a simpler definition/notion of the ""inside"" and ""outside"" of $\mathbb{R}^n \setminus Y$ , for topological compact connected
  codimension-1 manifold $Y\subset \mathbb{R}^N$ (with the topology
  induced by the Euclidian metric)? Secondary question: Let $X\subset \mathbb{R}^N$ be compact, connected smooth manifold of codimension- $1$ (a hypersurface). So it has an easy notion of ""inside"" and ""outside""
  (see in the elaboration below). Map $X$ by a (non-smooth)
  homeomorphism $h:\mathbb{R}^N \to \mathbb{R}^N$ : (a) Does the image $Y= h(X)$ have a simple definition of the ""inside""? (b) if the answer to (a) is negative, what are some of the mild conditions that need to be imposed on $h$ so that its image does have a simple definition of ""inside""? Any comments, references or intuition why those are still hard questions (or not) $-$ especially anything that helps better understanding the big picture $-$ are welcome. Elaborations Here is a quote of Jordan-Brouwer Separation theorem from lecture notes : Theorem 20.1 [Jordan- Brouwer Separation theorem]: Let $X$ be compact, connected (smooth) manifold of codimension- $1$ in $\mathbb{R}^N$ (hypersurface). The complement of $X$ in $\mathbb{R}^N$ consists of two connected open sets, the ""outside"" $D_0$ and the
  ""inside"" $D_1$ . Moreover, $\overline{D}_1$ is compact manifold with
  boundary $X =\partial \overline{D}_1$ . The ""inside"" is, roughly, all points in $\mathbb{R}^N\setminus X$ (the complement of $X$ in $\mathbb{R}^N$ ) for which if we send a ray [ in general position ] from this point[ $^*$ ] and then counts the number of the intersections of this ray with $X$ , we have an odd number of intersections then the point is in the ""inside"" (conversely, if we have even number of cuts the point is in the ""outside""). With the above in mind, my primary question is: suppose I have $Y$ ,  compact connected topological manifold. So I lose the notion of transversality etc. Is there still a (relatively) simple notion of the ""inside"" and ""outside"" of $\mathbb{R}^n \setminus Y$ , if yes how those are defined? Or is this already a ""deep question"" that requires to dive into algebraic topology and etc... Possible duplicates I've searched extensively to find an explanation on StackExchange or other sources: by looking up ""inside topological manifold"", ""separation theorem for topological manifolds"", ""Simple Alexander duality for non-spheres"" etc... but I failed to piece together any answer to my question. I find a lot of sources ( here , here , here , here , here , here , the closest to my question is this one ) concerned with smooth manifolds or non-smooth cases but concerned only with hyperspheres, or concerned about topology of the compliments (e.g. if it is simply connected, the counter-example of Alexander horned sphere, Alexander duality is stated in terms of hyperspheres, and here I would like to consider not just hyperspheres but compact, connected codimension- $1$ manifold)), or it is stated in a way that (with my current knowledge) is too cryptic to decipher (like here ). I hope the way I'm trying to attack this question is simpler and I can make some progress. [ $^*$ ] A ray is going in a general direction so the ray cuts the manifold $X$ transversally , such rays are dense so we can always find one.","['general-topology', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
3210167,Comparing the Markov and Chebyshev's inequalities,"This question was given to me as a review for an upcoming exam. Let X be a positive random variable with mean 3 and variance $\frac{1}{4}$ . Use Chebyshev's and Markov's inequalities to obtain the probability that $X \geq 6$ . Also give an example of such an X My work thus far: Chebyshev's $P(|X-\overline{x}| \geq a) \leq \frac{\sigma^{2}}{a^2} $ $P(X -3 \geq6-3) \leq \frac{\frac{1}{4}}{3^2} = \frac{1}{36}$ Markov's $P(X \gt a) \leq \frac{E[X]}{a}$ $P(X \gt 6) \leq \frac{3}{6}= \frac{1}{2}$ I feel as though I've made an error somewhere, could someone help me figure out where?","['statistics', 'probability']"
3210180,Find $\sum_{k=1}^{2n} k {2n\choose k}^2 (-1)^{k+1}$. [duplicate],"This question already has answers here : Simplify the sum $ \sum_{i=0}^{k}(-1)^i i \binom{n}{i} \binom{n}{k-i}$ (3 answers) Closed 5 years ago . I need to find $$S = {2n\choose 1}^2 -2 {2n\choose 2}^2 + ... - 2n{2n\choose 2n}^2= \sum_{k=1}^{2n} k {2n\choose k}^2 (-1)^{k+1}$$ , given $$\sum_{k=1}^{2n} k {2n\choose k} x^{k-1} = 2n(1+ x)^{2n -1}$$ Using $$-(1-x)^{2n} + 1 = \sum_{k=1}^{2n} {2n \choose k} (-1)^{k+1} x^k$$ , $$(1- (1-x)^{2n}) (2n (1+x)^{2n-1}) = \sum_{k=1}^{4n}x^k\sum_{r=0}^k {2n\choose r} (-1)^{r+1} (k - r) {2n \choose k-r}$$ LHS = $2n ( (1+x)^{2n - 1} -  (1-x)(1-x^2)^{2n-1}) = 2n((1+x)^{2n - 1} -  (1-x^2)^{2n-1} + x(1-x^2)^{2n -1})$ So coefficient of $x^{2n}$ on the LHS is $-2n{2n - 1\choose n} (-1)^n = -n{2n \choose n} (-1)^n$ Coefficient of $x^{2n}$ on the RHS, $$2n \sum_{r=0}^{2n} {2n\choose r}^2 (-1)^{r+1} - S = - 2n{2n \choose n}(-1)^n - S$$ Equating the coefficient of both sides gives $$S = -n{2n \choose n} (-1)^n$$ . I would like to know different methods for doing this and similar problems as the method I used is cumbersome and prone to miscalculation.","['binomial-coefficients', 'combinatorics', 'binomial-theorem']"
3210190,Does the binomial CDF decrease with the number of trials?,"When we fix the probability of success, does the binomial CDF decrease with the number of trials? I thought so, but I cannot prove it. It would be appreciated if someone could let me know whether it is true and if so, how to prove it. Thanks!","['statistics', 'probability']"
3210195,$\int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz$ Cauchy principal value,"$$\int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz$$ I started by defining the following contour: rectangular contour It is easy to show that the integrals along the 2 vertical sides of the rectangle go to $0$ as $R\Rightarrow\infty$ by applying the triangle inequality for integrals. Note that we must have $0<p<1$ for this to work. For the integral along the top side of the rectangle we define $z=x+\pi i$ so the integral becomes: $$\int_{R}^{-R} \frac{e^{p(x+\pi i)}}{e^{x+\pi i}-1}dx$$ Using some basic algebra and taking the limit as $R\Rightarrow\infty$ this simplifies to: $${e^{p \pi i}}\int_{-\infty}^{\infty} \frac{e^{px}}{e^{x}+1}dx$$ This integral has a known solution and plugging this solution in yields: $${e^{p \pi i}} {\frac{\pi}{\sin{p \pi}}}$$ Now we need to tackle the integral over the semi-circle and to do so we define: $z=\epsilon e^{i \theta}$ so $dz=i \epsilon e^{i \theta} d\theta$ and $-\pi \leq \theta \leq 0$ The integral becomes: $$\int_{- \pi}^{0} \frac{e^{p \epsilon e^{i \theta}}}{e^{\epsilon e^{i \theta}}-1} i \epsilon e^{i \theta}d\theta$$ Taking the limit as $\epsilon \Rightarrow 0$ using l'Hopital's rule we get: $$\int_{- \pi}^{0} \frac{e^{p \epsilon e^{i \theta}}}{e^{\epsilon e^{i \theta}}-1} i \epsilon e^{i \theta}d\theta = i \pi$$ Putting everything together and using the fact that the closed contour integral is zero since there are no singularities inside the contour yields. I let WolframAlpha do the simplification: $$\int_{-\infty}^\infty \frac{e^{pz}}{e^z-1}dz = -\pi \cot{(p \pi)} -2 \pi i$$ In my opinion this seems weird because the integrand is real for all inputs of z except $0$ . I expected the cauchy principal value, which this integral actually is because it blows up at $0$ , to be real valued as well. Unfortunately my calculations show that this integral is complex valued. Could someone please tell me if I did something wrong or not.
I found an article which also has this integral covered but I believe there is a mistake in their calculation of the integral along the semi-circle (they forgot a minus sign), which if corrected results in the same answer I got. link: article covering the integral . Any help is greatly appreciated! PS: I am 17 years old so this is my first post on this forum, if there are any (informal) rules which I am not aware of please let me know as well!","['improper-integrals', 'definite-integrals', 'complex-analysis', 'contour-integration', 'cauchy-principal-value']"
3210201,Is there some sort of classification of all minimal non-cyclic groups?,"Does there exist some sort of classification of all minimal non-cyclic groups (non-cyclic groups, such that all their proper subgroups are cyclic) I know the following classes of such groups: 1) $C_p × C_p$ , where $p$ is a prime 2) $Q_8$ 3) $\langle a,b | a^p = b^{q^m} = 1, b^{−1}ab = a^{r}\rangle$ , where $p$ and $q$ are distinct primes and $r ≡ 1 \pmod q$ , $r^q ≡1 \pmod p$ . (These three classes completely cover the case, when our group is finite: Classification of finite minimal non-cyclic group ) 4) $C_{p^{\infty}}$ , where $p$ is a prime 5) $(\{ \frac{n}{p^m}| m, n \in \mathbb{Z} \}, +)$ , where $p$ is a prime (These two classes completely cover the case, when our group is infinite abelian: Does there exist an infinite non-abelian group such that all of its proper subgroups become cyclic? ) 6)Infinite non-abelian groups, such that all their nontrivial proper subgroups are isomorphic to $C_{p}$ for a fixed prime $p$ (Tarski monster groups) 7)Infinite non-abelian groups, such that all their nontrivial proper subgroups are isomorphic to $C_{\infty}$ ( Does there exist an infinite non-abelian group, such that all its nontrivial proper subgroups are isomorphic to $C_\infty$? ). However, I do not know, whether there exists anything, that does not fall into these classes. I only know, that if such groups exist, they have to be infinite non-abelian.","['group-theory', 'abstract-algebra', 'infinite-groups', 'cyclic-groups']"
3210202,"Sobolev embedding when $p=n$: $W^{1,p}(\mathbb{R}^{n}) \hookrightarrow L^{q}(\mathbb{R}^{n})$ for $q: p \leqslant q < \infty$","In class, aside from the standard Gagliardo-Nirenberg-Sobolev and Morrey inequalities, my professor also covered the case when $p=n$ . In particular, if $p=n$ , then $W^{1,p}(\mathbb{R}^{n}) \hookrightarrow L^{q}(\mathbb{R}^{n})$ for all $q$ such that $p \leqslant q < \infty$ . We did not prove this case in class. I can see that this would be true trivially whenever $q=p$ : $||u||_{L^{p}} \leqslant ||u||_{W^{1,p}}$ . If it was true for $q=\infty$ , then I could interpolate to immediately get the result for $p < q < \infty$ . But I know it's definitely not true when $q=\infty$ (consider $\log\log(1+|x|^{-1})$ , which is in $W^{1,n}(B(0,1))$ but not $L^{\infty}(B(0,1))$ ). Can anyone provide some guidance on this for me? At least if $u \in C_{c}^{\infty}(\mathbb{R}^{n})$ and $u\neq 0$ , if I define $u_{\lambda}(x) = u(\lambda x)$ and assume that the inequality $||u_{\lambda}||_{L^{q}} \leqslant C||u_{\lambda}||_{W^{1,n}}$ holds, I cannot get a contradiction anymore as in the case when $1 \leqslant p < n$ , where the contradiction is that $u=0$ a.e. by sending $\lambda$ to either $0$ or $\infty$ . Edit: I found that the proof is actually done by Brezis (Corollary 9.11). I may transcribe the answer later if I have time.","['sobolev-spaces', 'functional-analysis']"
3210211,Maximize area of a quadrilateral given three sides,"What is the maximum possible area that a quadrilateral can have, if the lengths of three of its sides are given as 3, 4 and 5, while the fourth side can have arbitrary length? (Thinking of it as three fence segments arranged around a straight wall such that the area becomes maximal) My approach: Since for given lengths a cyclic quadrilateral will have maximum area, I started out from here. According to Heron’s theorem the squared area of a cyclic quadrilateral equals $A^2 = (s-5)(s-4)(s-3)(s-2x)$ with $s = (5+4+3+2x)/2$ equaling half of the circumference and $x$ half of the unknown side. Rearrangement leads to $A^2=(3+x)(2+x)(1+x)(6-x)$ . Setting the x-derivative to zero yields the maximum area $A = 20.495$ with $x = 4.0279$ (and the missing side $2x = 8.0558$ ). 
Is this correct? Is the maximal quadrilateral at all cyclic as I assumed?
And If yes, isn’t there a more elegant and intuitive geometric solution?","['quadrilateral', 'optimization', 'area', 'geometry']"
3210219,The permutation is given. For how many functions $f:\Bbb{N_{10}} \rightarrow \Bbb{N_{10}}$ are $f(\pi(i))=\pi(f(i))$?,"The permutation $\pi\in S_{10}$ is given by the table: \begin{array}{|c|c|c|c|c|c|c|c|c|c|}
\hline
i & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ \hline
\pi & 9 & 7 & 10 & 4 & 8 & 1 & 2 & 5 & 6 & 3\\ \hline
\end{array} For how many functions $f:\Bbb{N_{10}} \rightarrow \Bbb{N_{10}}$ are $f(\pi(i))=\pi(f(i))$ , where $i \in \Bbb{N_{10}}$ ? Hi, this is a question from a old exam in my course. I know that the answer is $1372$ functions, however I can't follow the explanation that is given. Thus I come to this place and hope that someone can give an answer and an explanation that is easy to follow and understand. Thanks!","['functions', 'discrete-mathematics', 'permutation-cycles']"
3210220,Prove that there is no group $G$ s.t. $\operatorname{Aut}(G)=\mathbb{Q}$,Prove that there is no group $G$ s.t. $\operatorname{Aut}(G)=\mathbb{Q}$ I get the feeling that we should proceed by contradiction. So let $G$ be a group s.t. $\operatorname{Aut}(G)=\mathbb{Q}$ . Then we can identify elements of $\mathbb{Q}$ with automorphisms of $G$ ... and identities such as $\frac{1}{2}*2(g)=1(g)=g$ Can somebody help me find a contradiction?,"['group-theory', 'abstract-algebra']"
3210255,"Number of one to one functions from the set {1, 2, . . . , n} to {1, 2, . . . , n} so that f(x) = x for some x and f(x) $\neq$ x for all the other x?","What is the number of one-to-one functions f from the set {1, 2, . . .
  , n} to the setm {1, 2, . . . , n} so that f(x) = x for some x and
  f(x) $\neq$ x for all the other x? Alright so the fact that f(x) = x for some x and f(x) $\neq$ x for all the other x is throwing me off. Here is my attempt, starting with one to one functions for f(x) $\neq$ x. If we take $A_{i}$ to be a set of one-to one functions so f(x) = x (complement) $A_{1} \cup A_{2} \cup A_{3} ....  \cup A_{n}$ is the set of one to functions so f(x)= x some x | $A_{i}$ | is (n-1)! | $A_{i} \cap A_{j} $ | is (n-2)! | $A_{i} \cap A_{j} \cap A_{k}$ | is (n-3)! thus | $A_{i} \cap A_{j} \cap A_{k} ... \cap \ A_{n}$ |  = (n-n)! Now since the total number of one to one functions is n! $n!$ - $ n \choose 1$ (n-1)! + $n \choose 2$ (n-2)! - $n \choose 3$ (n-3)! + … + $(-1)^{n+1}$ ${n \choose n}^{(n-n)!}$ is the number of functions for which f(x) $\neq$ x, but I'm not sure how to factor in f(x) =x for some x into this solution.. would I just add $ n \choose 1$ (n-1)! + $n \choose 2$ (n-2)! - $n \choose 3$ (n-3)! + … + $(-1)^{n+1}$ ${n \choose n}^{(n-n)!}$ If i do that I'm just left with n! though right?","['inclusion-exclusion', 'discrete-mathematics', 'computer-science']"
3210327,"If $A^{2016} = I_n$, show that $A^{576} - A^{288} + I_n$ is invertible, and calculate it's inverse in terms of $A$.","Let $A$ be a real valued $n \times n$ matrix,where $n \geq 2$ , such that $A^{2016} =I_n.$ Show that the matrix $B = A^{576} - A^{288} + I_n$ is invertible, and calculate it's inverse in terms of $A$ . Well, I was able to prove that matrix is invertible, however it is a bit long-winded. Call $p(x) = x^{576} - x^{288} + 1$ . The eigenvalues of $B$ are of the form $p(\lambda)$ , where $\lambda \in Spec A \subset U_{2018},$ the 2018th roots of unity. We want to show that $B$ can't have a zero eigenvalue; That is, no $2018$ th root of unity is a root of $p(x)$ . Since $p(x) = \left( x^{288} - e^\frac{2\pi}{5} \right) \left( x^{288} - e^\frac{8\pi}{5} \right)$ , it's enough to show that there is no k such that $$2016\left(\frac{2\pi}{5\cdot288}+\frac{2k\pi}{288}\right) = 2l\pi$$ or $$2016\left(\frac{8\pi}{5\cdot288}+\frac{2k\pi}{288}\right) = 2l\pi,$$ where $l$ is another integer.
This follows from the fact that $5$ does not divide $2016$ . However, I have no idea how to find $B$ in terms of $A$ . I think that there is a way to show that $B$ is invertible which also gives an expression for $B$ , but I can't figure that out. Any ideas?","['matrices', 'roots-of-unity']"
3210374,Limit superior of iid Poisson random variables,"Im trying to undestand the proof of the next: Suppose $X_n$ are iid Poisson random variable with rate $\lambda>0.$ Prove that $$\displaystyle\limsup\frac{X_n\log(\log n)}{\log(n)}=1\space a.s.$$ The proof given is following: We have $P(X\geq n)\leq e^{\lambda}P(X=n).$ Let $a_n$ be the integer part of ${\delta \log n \over \log\log n}$ for a $\delta >0$ . Then $$P(X=a_n)={e^{-\lambda}\lambda^{a_n}\over a_n!}=e^{-\lambda}e^{a_n \log \lambda}e^{-\sum_{j=1}^{a_n}\log j}=e^{-a_n\log a_n (1+o(1))}=n^{-\delta +o(1)}$$ Then, $\sum_{n=1}^{\infty} P(X_n\geq a_n)<\infty$ or $=\infty$ depending upon $\delta >1$ or $\delta<1$ . Borel-Cantelli lemma finishes the proof. I'm stuck in this: $$e^{-\lambda}e^{a_n \log \lambda}e^{-\sum_{j=1}^{a_n}\log j}=e^{-a_n\log a_n (1+o(1))}=n^{-\delta +o(1)}.$$ I don't get such expressions; I have understood that little o-notation means a quotient between two functions have zero limit but I don't know how this was used here to get such expressions. Any kind of help is thanked in advanced.",['probability-theory']
3210477,Is $\ell^1$ complete with this norm?,"For $x \in \ell^1$ we set $\Vert x\Vert = \sup\limits_{N \in \mathbb{N}}|\sum\limits_{n=1}^{N}x_n|$ . One can easily see that this is a norm on $\ell^1$ . I was wondering if this space is now complete. I tried finding an absolutely convergent series that does not converge, but I did not find anything.","['functional-analysis', 'absolute-convergence', 'sequences-and-series']"
3210532,Prove that $inf(S_1)=sup(S_2)$,"$f:I \to \Bbb R$ , $I=[0,1]$ continuous and differentiable on $(0,1)$ s.t $f(0)<0<f(1)$ and $f'(x)\neq 0$ $\forall x \in (0,1)$ . Let $S_1=\{x \in I | f(x) >0\}$ and $S_2=\{x \in I | f(x) <0\}$ . Prove that $inf(S_1)=sup(S_2)$ . My attempt: If $\exists x\in I$ s.t $f(x)<f(0)$ then $\exists c\in I$ s.t $f(c)=f(0)$ contradiction by Rolle's thm. So $f'(0)>0$ Claim: $f'(x)>0$ , $\forall x \in (0,1)$ Suppose not then $\exists x_1\in I$ s.t $f'(x_1)<0$ . Consider, $d=inf\{x\in I|f'(x)<0\}$ If we can prove that $d \neq 0$ then $\exists a,b\in (d-\epsilon,d+\epsilon)\subseteq [0,1]$ s.t $f(a)=f(b)$ contradiction by Rolle's thm. So, $f'(x)>0$ , $\forall x \in (0,1)$ $\Rightarrow inf(S_1)=sup(S_2)$ . Done. My question is: How can we prove that $d \neq 0$ ?","['analysis', 'real-analysis', 'continuity', 'calculus', 'derivatives']"
3210672,Is the set of non invertible matrices simply connected? What are their homotopy and homology groups?,"It is fairly easy to see that the set of non invertible matrices is path connected. Are they simply connected? If not what is their fundamental group? What are their homotopy and homology groups. I'm looking for the answer to any of these questions. Any examples for particular (non 0 or 1) dimensions are welcome as well, as well as for real or complex coefficients.
(Sorry about the phrasing, it is currently 3:30 am and I will edit the question in the morning)","['linear-algebra', 'algebraic-topology']"
3210680,Do you know any research on finding closed forms of recursively-defined sequences?,"I am dealing with a non standard progression and I had a hard time finding the general term $U_n = f(n)$ from the recursive definition: $U_{n+1} = b.a^{n+1} + a.U_{n}$ I would like to know if there exists any research in this domain. If so what are the keywords I can use to find the papers? When I search, I always end up finding the geometric and the arithmetic progressions.","['reference-request', 'recurrence-relations', 'sequences-and-series']"
3210683,Why does deep learning work despite the surprising behavior of probability distributions in high dimensions?,"This question is meant to be very specific. How/why is deep learning successful at learning a classification function/hyperplane given the challenges of probability distributions and distance metrics in high dimensional spaces. Deep learning or Deep Neural Networks are a big area of research and activity in machine learning right now and for the past few years. These models are constructed for a large number of layers of latent variables. In a simple convolutional neural network for image classification, or object detection, it is easy to have a million or more parameters. Now there are more than a few references that discuss how in high dimensions, probability distributions behave in very odd ways and distance metrics on those probability distributions also behave in odd ways. Without getting into the details, in high dimension everything is essentially far apart, so the probability density mass becomes more diffuse over its support. Further if you follow the sphere-packing literature, there are very odd phenomena which occur such as most of the volume of a high-dimensional hyper-sphere is on its skin or surface--as opposed to its center. In supervised deep learning, the loss function will govern the learning process. This loss function is usually based upon a distance metric that compares two high-dimensional distributions. So the common loss functions are metrics like cross entropy between two distributions or the KL-Divergence between two distributions. The idea is to understand the distance between the probability of a point on the candidate distribution versus the actual distribution. So I am just trying to understand why deep learning works so well if the high-dimensionality of the data should create such odd behavior in the associated loss functions/metrics. I mean if the probability distributions become so diffuse as dimensionality increases, then the distributions should become less informative as there are more and more ways to obtain the same probability. Some articles or posts I have read suggest that the usual 'manifold assumption' is at work where the high-dimensional data lives on some lower-dimensional manifold. I can understand that idea. But then by that logic the curse of dimensionality should never create a problem for any statistical method on high-dimensional data--since all high-dimensional data is intrinsically low-dimensional. So what I am looking for is a bit more precision in the analysis. How does this manifold assumption--if that is indeed the answer--operate at each level of the network to make it not fall victim to the usual curses of dimensionality. It might be that I am just looking at the problem from the wrong angle--and this is what I wanted to validate. So if I am looking at an image segmentation problem and I have 512x512 image, then I am classifying each pixel with a class label, that means I am assigning about 262,000 labels. Now am I really assigning the labels over a 262,000 dimensional space, or a higher-dimensional space because I am not including the parameters from the lower layers of the network. Or am I just classifying over say a 2 or 5 dimensional space--based upon the possible class label values. Or do neural networks operate like dynamic programming problems where solving the value for each node in the network together will generate some optimal solution overall?","['machine-learning', 'statistics', 'neural-networks', 'probability']"
3210711,Connection between relationships of the form $\|f \|_p \leq \|g\|_p$,"Let us define the $L^p$ norm of a function $f:\mathbb{R} \to \mathbb{R}$ as $$
\|f\|_p:= \left(\int \lvert f \rvert^p\right)^{1/p}.
$$ Let us label the following statement by $S\left(p\right)$ : $$
\|f\|_p \leq \|g\|_p.
$$ My Question: Suppose $p>q>0$ . Then, does there exist any interrelationship between $S\left(p\right)$ and $S\left(q\right)$ ? To be precise, does one implies the other? I think neither implies the other, yet I cannot find a concrete counterexample (I was working with $p=2$ and $q=1$ ). Also, I was wondering if such implication holds if we assume stronger assumptions on $f$ and $g$ . Any help will be much appreciated. Thank you.","['normed-spaces', 'analysis', 'real-analysis', 'functions', 'inequality']"
3210761,How can I visualise the fundamental group of the projective plane?,"The real projective plane $\mathbb{RP}^2$ has fundamental group $C_2$ . We can understand this via the universal covering mapping $S^2 \to \mathbb{RP}^2$ which identifies antipodal points: the contractible loops in $\mathbb{RP}^2$ lift to loops on $S^2$ , while non-contractible loops lift to paths which connect a point with its antipodal point (and 'simultaneously' connects that antipodal point with the point, on the other side of the sphere). We can visualize this, and via this the group operation on $\pi_1(\mathbb{RP}^2)$ . Although this visualization is somewhat satisfying, it still intuitively bothers me that you can have a circle wrapped around something that you can't untie, but then doing the wrapping again does allow you to untie it. Certainly it seems that it cannot happen for subsets of $\mathbb R^3$ (or can it?), but since $\mathbb{RP}^2$ embeds into $\mathbb R^4$ , it does happen in Euclidean space. Since $\mathbb{RP}^2$ has low dimension, and thus seems relatively amenable to visualization, my question is: How can I visualise the fundamental group of $\mathbb{RP}^2$ (or another space with a fundamental group with torsion) in such a way that I can geometrically understand how torsion in a fundamental group works?","['general-topology', 'fundamental-groups', 'algebraic-topology']"
3210805,Help solving a tricky matrix PDE coupled system,"I am trying to a solve a matrix equation of the form $$\begin{equation}\label{jacobi_cond}
\frac{\partial \mathbf{P} (x_3)}{\partial x_3} = \mathbf{H}(x_3) \mathbf{P}(x_3).
\end{equation}$$ where $$\frac{\partial}{\partial x_3}\begin{bmatrix} \chi_1(x_3) & \chi_2(x_3) \\ \chi_3(x_3) & \chi_4(x_3) \end{bmatrix} =\begin{bmatrix} \Delta_1(x_3) & \Delta_2(x_3)  \\ \Delta_3(x_3)  & \Delta_4(x_3) \end{bmatrix}  \begin{bmatrix} \chi_1(x_3) & \chi_2(x_3) \\ \chi_3(x_3) & \chi_4(x_3) \end{bmatrix}$$ with initial condition $$\mathbf{P}(x_3=0) = \mathbf{I}$$ the identity matrix. The $\chi(x_3)$ entries have real and imaginary parts. The $\Delta(x_3)$ functions are nontrivial. I should note also that $\text{Tr}[\mathbf{H}(x_3)] \neq 0.$ I am trying to get a handle on the determinant of the matrix $\mathbf{P}(x_3).$ $\textbf{So far I have tried}$ using Jacobi's formula . This is easy to implement if $\text{Tr}[{\mathbf{H}(x_3)}] = 0,$ meaning the initial condition becomes the determinant, however in my case it does not hold. I have also tried solving this numerically, but the determinant blows up rapidly. So I am really stuck at this. I would really appreciate any ideas or discussion. Thanks.","['calculus', 'matrix-equations', 'ordinary-differential-equations', 'partial-differential-equations']"
3210811,What might be the definition of a positively oriented chart in From Calculus to Cohomology?,"My book is From Calculus to Cohomology by Ib Madsen and Jørgen Tornehave. I recently finished most of An Introduction to Manifolds by Loring W. Tu, so based on the preface of From Calculus to Cohomology, I started at Chapter 8. I don't believe I've missed anything since charts are first introduced in Chapter 8. Question : What's a positively oriented chart, first mentioned in Proposition 10.2 , please? Some context : I think this is relevant in answering my other question: Why is there a form with compact support on a connected oriented manifold with integral one but with support contained in a given open proper subset? I think I have to prove either the chart $(U, g: U \to g(U) = U')$ or some restriction $(W, g|_W:W \to g(W))$ , $W$ open in $U$ , is a ""positively oriented chart"" or at least an ""oriented chart"" in order to apply Proposition 10.2 My guesses : The definition of ""oriented chart"" in the book (see also previous definitions of orientation ) is meant to be ""positively oriented chart"" with ""negatively oriented chart"" to be for orientation-reversing. I mean that 1.1. a chart $(U,h:U \to U')$ is an oriented chart if and only if it is a member of an oriented atlas of an oriented smooth $n$ -dimensional manifold, and we sometimes omit $U$ and $U'$ and call $h$ , the coordinate map, an oriented chart (instead of something like ""oriented map"") 1.2 An oriented chart $(U,h:U \to U')$ , or just $h$ , is positively oriented if and only if $h:U \to U'$ is an orientation-preserving diffeomorphism if and only if $\det(D_q(h)) > 0$ if and only if $D_qh: T_qU = T_qM \to T_{h(q)}U' = T_{h(q)} \mathbb R^n$ is an orientation-preserving diffeomorphism of manifolds  (See here and here ) if and only if $D_qh: T_qU = T_qM \to T_{h(q)}U' = T_{h(q)} \mathbb R^n$ is an orientation-preserving vector space isomorphism of tangent spaces In Proposition 10.2 , what is meant by ""positively oriented chart"" is simply ""oriented chart"" if we go with the convention that ""oriented charts"" are ""positively oriented charts"", as originally in the book. I also tried looking up other books: An Introduction to Manifolds by Loring W. Tu: Based on Section 21.5 and Subsection 23.4 , I believe the definition for integration is for a chart in an ""oriented atlas"" of $M$ , where an ""oriented atlas"" is defined one where overlapping charts have positive Jacobian determinant. Thus, ""oriented atlas"" in An Introduction to Manifolds seems to be the same as ""positive atlas"" in From Calculus to Cohomology. Manifolds, Tensor Analysis, and Applications by Ralph Abraham, Jerrold E. Marsden, Tudor Ratiu : It seems a coordinate chart is defined as positively oriented if the coordinate chart's coordinate map has all its differentials to be orientation preserving ( as in vector spaces or as in manifolds, if we still have such equivalence of the 2 notions of orientation preserving ). If this is what is meant, then to clarify, do we, once again, have a notion, namely the notion of positively oriented chart, that is actually rooted in some prerequisite algebra notion ? I'm not sure this is (exactly) what Madsen and Tornehave mean because there is a difference in definition for manifolds. Update : Based on the proof of Theorem 11.9 , which relies on Lemma 11.8 , I think this might be the definition or at least equivalent to, implied by or implies the definition. Introduction to Smooth Manifolds by John M. Lee: It seems the definition is that for an oriented smooth $n$ -manifold $M$ with or without boundary, for a coordinate chart $(U,\varphi) = (U,x^1,...,x^n)$ in the differentiable structure of $M$ (see Tu Subsection 5.3 ), where $x^i=r^i \circ \varphi$ , where $r^1, ..., r^n$ are the standard coordinates on $\mathbb R^n$ , $(U,\varphi)$ is said to be positively oriented if the frame $\{\frac{\partial}{\partial x^1}, ..., \frac{\partial}{\partial x^n}\}$ is positively oriented. I think there's no explicit concept of ""manifold with boundary"" or ""frame"" in From Calculus to Cohomology by Ib Madsen and Jørgen Tornehave so far, and so if we were to adopt this definition, ""if the frame $\{\frac{\partial}{\partial x^1}, ..., \frac{\partial}{\partial x^n}\}$ is positively oriented"" would be translated to ""if each element of the set $\{\frac{\partial}{\partial x^1}|_p, ..., \frac{\partial}{\partial x^n}|_p\}_{p \in M}$ is positively oriented"". Since each element is a basis of the tangent space $T_pM$ , based on Tu Subsection 21.3 (Tu says it was in Subsection 12.5, but I'm not sure that was explicit unless Subsection 12.5 was understood in the context of Proposition 8.9 ), and this is indeed defined after Definition 9.8","['vector-spaces', 'multivariable-calculus', 'linear-algebra', 'general-topology', 'differential-geometry']"
3210839,The exponential generating function for the central binomial coefficients,"I am having difficulty proving the following result \begin{align}
\sum_{n=0}^{\infty} \binom{2n}{n} \frac{x^{n}}{n!} = e^{2x} \ I_{0} (2x) \text{,}
\end{align} where \begin{align}
I_{0}(y) = \sum_{n=0}^{\infty} \frac{\Big( \frac{y}{2} \Big)^{2n}}{n! \ n!}
\end{align} is a modified Bessel function of the first kind with zero order. I approached it using \begin{align}
e^{2x} \ I_{0} (2x) = \bigg( \sum_{n=0}^{\infty} \frac{(2x)^{n}}{n!}\bigg) \ \bigg( \sum_{k=0}^{\infty} \frac{ x^{2k}}{k! \ k!} \bigg) \text{,}
\end{align} but I have had no luck.","['combinatorics', 'sequences-and-series']"
3210841,"If $X$ is an infinite set and $N$ is a countable set, then what is the cardinality of $X \times N$? [duplicate]","This question already has answers here : Cardinality of cartesian product of an infinite set with N (2 answers) Cardinality of cartesian product of infinite set with countable set (1 answer) Let $X$ be infinite. Then $X$ and $X\times\Bbb N$ are equinumerous Closed 5 years ago . If $X$ is countable, then the cartesian product is countable. However, what about general cases? The googling suggests that the answer is the cardinality of $X$ . But why? Could anyone please provide me with the proof?","['elementary-set-theory', 'cardinals']"
3210849,Possible wrong answer to Spivak calculus chapter on graphs of functions,"In problem #17-v of Spivak's Calculus (3rd edition, chapter 4) the reader is asked to draw the graph of the function $f(x)= [1/x]$ , where $[\ldotp]$ is the greatest integer function. I did the problem and then checked the answer, but the answer provided in the manual seems to be wrong. I have attached a link to the image of the answer provided in the manual: https://i.sstatic.net/b3prm.jpg . Is the answer wrong?","['calculus', 'functions', 'graphing-functions']"
3210851,Existence of global vector fields on a smooth manifold,"According to my book, if $M$ is a smooth manifold the global smooth vector fields form an infinite-dimensional Lie algebra. However, how do we know of the existence of even one vector field and then how do we know the number of them is infinite?","['vector-fields', 'lie-algebras', 'smooth-manifolds', 'differential-geometry']"
3210982,Show identity for Stable distributions,"let $X_1,X_2,X$ be i.i.d (idenpendant, identically distributed) with stable probability density function $l_\alpha(x)$ . For $\forall A>0,B>0$ find $C$ such that $AX_1 + BX_2 \overset{d}{=}CX \qquad (1)$ where $\overset{d}{=}$ means equal in distribution. $\textrm{My Idea}$ : In the lecture we showed that the characteristic function $\hat{l}_\alpha$ is given by $\hat{l}_\alpha(k) = <e^{ikx}>:= \int_{-\infty}^\infty e^{ikx}l_\alpha(x)dx=e^{-\sigma^\alpha|k|^\alpha} \quad \sigma>0$ . Using this result i get the following relation: $(1) \quad \Rightarrow \quad  <e^{i(AX_1 +BX_2)k}>=<e^{ikAX_1}><e^{ikBX_2}>=<e^{ikCX}>$ which should be equivalent to $e^{-\sigma^\alpha|k|^\alpha A^\alpha}  e^{-\sigma^\alpha|k|^\alpha B^\alpha} = e^{-\sigma^\alpha|k|^\alpha C^\alpha} \Rightarrow A+B=C$ Is this the correct solution?","['statistics', 'probability-distributions']"
3210999,Minimum value of $\sqrt{x^2+25}+\sqrt{y^2+16}$ if $x+y=12$,"If $x,y\in\mathbb R^+$ , $x+y=12$ , what is the minimum value of $\sqrt{x^2+25}+\sqrt{y^2+16}$ ? I got the question from a mathematical olympiad competition (of China) for secondary 2 student, so I don't expect an ""analysis"" answer. The answer should be $15$ , when $x=\frac{20}{3}$ and $ y=\frac{16}{3}$ (just answer, no solution :< ). I try to use AM-GM inequality, but I couldn't manage to get the answer. $$\sqrt{x^2+25}+\sqrt{y^2+16}=\sqrt{x^2+25}+\sqrt{(x-12)^2+16}=\sqrt{x^2+25}+\sqrt{x^2-24x+160}$$ Can this help? I also tried to plot the graph, see here . Any help would be appreciated. Thx!",['algebra-precalculus']
3211043,"Does there exist a function $f(x)$, which is “parallel” to $e^x$ and has a finite “norm”?","Does there exist a function $f: \mathbb{R} \rightarrow \mathbb{R}$ such that $$
\lim_{M \rightarrow +\infty}\frac{\int_{-M}^{M}f(x)e^xdx}{\Big(\int_{-M}^{M}(f(x))^2dx\int_{-M}^{M}(e^x)^2dx\Big)^{1/2}}=1
$$ but also the limit $$
\lim_{M \rightarrow +\infty} \int_{-M}^{M} (f(x))^2 dx 
$$ exists and finite? I suppose the answer is no, but I don’t know how to prove it. Motivation. I think of the first limit as of some generalization of the cosine between two vectors (as it is somehow similar to a dot product of two vectors divided by their norms). So the first limit says that functions $f(x)$ and $e^x$ are parallel in some sense (although not in the common sense as there is a limit before the whole fraction). The second limit says that that we are looking for a function $f(x)$ with a finite $L_2$ -norm (again, not exactly the norm, but maybe its principal value ). Functions $f(x) = ae^x$ with $a \in \mathbb{R}_+$ satisfy the first condition (as they are parallel to $e^x$ ), but do not satisfy the second (as their “norm” is infinite). I wonder if there exists such $f(x)$ which satisfies both.","['calculus', 'functional-analysis']"
3211058,Decomposing interval in $\mathbb{R^n}$,"The book I am using states the following result with the respective demonstration: Let $ \Omega \subset \mathbb{R}^n$ be open set and $E \Subset \Omega$ ( Compact embedding ). Show that for all $\epsilon > 0$ exist $I_n$ , $n=1,2,3...$ open interval such that $I_n \subset \Omega$ for all $n \in \mathbb{N}$ , $E \subset \bigcup _{n \in \mathbb{N}} I_n$ and $$\sum_{n \in \mathbb{N}} \text{Vol}(I_n) < m^*(E)+ \epsilon.
$$ Proof :  Take $\epsilon >0$ exist $I'_n$ , $n=1,2,3...$ such that $E \subset \bigcup _{n \in \mathbb{N}} I'_n$ and $$
\sum_{n \in \mathbb{N}} \text{Vol}(I'_n) < m^*(E)+ \frac{\epsilon}{2}$$ (this goes straight from the definition of external measure by the infimum of volumes). For each $n$ we decompose: $$\overline{I'_n}= J_{n,1} \cup J_{n,2} \cup...\cup J_{n,k_n}$$ where each $J_{n,k}$ is compact set and $$\text{Vol}(I'_n)= \text{Vol}(J_{n,1})+...+\text{Vol}(J_{n,k_n}), \text{   diam}(J_{n,k})< \frac{1}{2} d(E,\mathbb{R}^n- \Omega)$$ ... How do I build or show the existence of these $J_{n,k_n}?$","['general-topology', 'measure-theory', 'real-analysis']"
3211084,How to compute the derivative of $\frac{\partial\mathbf{a}_k }{\partial{X}_{ij}}$ when $X = A^TB$,"Assume I have $$ X = A^TB $$ where $X \in R^{m \times n}, A \in R^{r \times m}, A \in R^{r \times n}$ . Let's define $A = [\mathbf{a}_1, ..., \mathbf{a}_m]$ where $\mathbf{a}_k $ is the $k$ -th column of matrix $A$ . How to compute the following derivative? $$\frac{\partial\mathbf{a}_k }{\partial{X}_{ij}}$$","['partial-derivative', 'derivatives', 'matrix-calculus', 'linear-algebra']"
3211109,Is the free product of $\mathbb{Z}$ with $C_2$ virtually torsion-free?,"I  was thinking about the question Is a HNN extension of a virtually torsion-free group virtually torsion-free? and I started wondering whether or not $G = \mathbb{Z}\times C_2$ was a counterexample to the question. In the process, I came across the following question: Is $\mathbb{Z}* C_2=\left< t,x|x^2=1 \right>$ virtually torsion-free? A group is said to be virtually torsion-free if it has a finite index subgroup which does not contain elements of finite order. I suspect that the answer is no because words of the form $t^nxt^{-n}$ all have order two within $\mathbb{Z}*C_2$ . If $\mathbb{Z}*C_2$ has a finite index torsion-free subgroup $T$ then the cosets $t^nxt^{-n}T$ cannot all be distinct.",['group-theory']
3211114,The parking problem riddle,"Assume a street of 300 meters, that you can park your car alongside the pavement. Assume that there is a big parking problem in the area. Assume that the pavement is continuous, without interruptions, and that you can park alongside all of it. Assume that the length of a car is 3 meters long. Assume, for simplicity, that cars can park without space between them (bumper to bumper). Assume, that when a car comes to the street if chooses an equally random parking space (please try to express this randomness) from the free spaces left. Therefore, it may ""ruin"" parking places for other cars. Please try to determine what is the expectancy of cars the can park alongside the street.","['random', 'probability']"
3211133,"Does a connection satisfying $(\nabla_X g)(Y,Z)-(\nabla_Y g)(X,Z)=0$ have a special name or satisfy a special property?","Let $\nabla$ be a flat torsion-free connection on a smooth manifold. Let $g$ be a metric on $M$ ( $\nabla$ may not be the Levi-Civita connection of $g$ ). Suppose that $$
(\nabla_X g)(Y,Z)-(\nabla_Y g)(X,Z)=0.
$$ Does $\nabla$ receive a special name? Or does it imply $\nabla$ is related with the Levi-Civita connection or any other thing stronger than the above relation itself? Maybe the existence of some coordinates, I don't know. I ask this because in Dombrowski's paper On the geometry of the Tangent Bundle , it is proved that the presymplectic form defined as $$\omega(X,Y)=g_S(X,JY),$$ where $J$ is the canonical complex form on $TM$ defined using the split induceb by $\nabla$ and $g_S$ denotes the Sasaki metric defined in terms of the same split and the metric $g$ , is closed whenever $\nabla$ is the Levi-Civita connection. However, the computation for the general case shows that the $d\omega$ is proportional to the above factors when evaluated on some vector fields. But I'm sure the $\omega$ is closed. In fact, I would say, under certain conditions, it is the pullback of the canonical 2-form on $T^*M$ along $g$ . But I don't know exactly what conditions are necessary and if they are related to my expression above. P.S. It would be useful also to recieve some suggestions of references to be able to read about this. Addendum 1. I typed the question on the phone. Let me describe in detail Dombrowski's construction now I have a computer avaible. It is well known every linear connection on $M$ defines an split on $TTM$ into vertical and horizontal subbundles. Each of them is isomorphic to $TM$ and for every vector field $Z\in\Gamma(TTM)$ there are vector fields $X,Y\in\Gamma(TM)$ such that $Z=X^h+Y^v$ , where the superscripts v and h denote the verticla and the horizontal litf, respectively. Hence, every tensor on $TM$ is completely characterised once we know how it acts on horizontal and vertical vector fields. Now, Dombroski defines a complex tructure $J:TTM\rightarrow TTM$ as $$JX^h, X^v, \qquad JX^v= - X^h. $$ He proves $J$ is integrable if and only if $\nabla$ is flat and torsion-free. But in the third appendix we goes beyon. The aim is to prove $TM$ is a Kähler. For that he considers a Riemannian metric $g$ on $M$ (again the flat and torsion-free connection $\nabla$ may not be the Levi-civita connection for $g$ ) and define the Sasaki metric $$
g_S(X^h,Y^h)=g_S(X^v,Y^v)= \pi_{TM}\circ g(X,Y), \qquad g_S(X^h,Y^v)=g_S(X^v,Y^h)=0
$$ (Notice I compose on the right and I denote the differential of a map $f$ as $Tf$ ). It is not difficult to see that $J$ leaves $g_S$ invariant. Hence $\omega(X,Y)=g_S(X,JY)$ is 2-form. Finally, he particularise for the case when $\nabla$ is the Levi-Civita connection for $g$ . In this case he proves $\omega$ is locally and non-locally an exact 2-form. But the computation can be done for a non-metric connection. In that case one finds the relation I have written above. Addendum 2. I claim under certain conditions, $\omega$ is the pullback along $g$ of the canonical 2-form defined on $T^*M$ . For that, let me write firstly the pullback of the canonical 1-form: $$
g^*\theta(Z)|_{p,X}= g_p(X,(T\pi)_{(p,X)}Z), \qquad Z\in T_{(p,X)}TM.
$$ In coordinates $g^*\theta$ reads simply as $y_ig_{ij}d\tilde{x}_j$ . If I compute the diferential I get $$
d(g^*\theta)= -g_{ij}d\tilde{x}_i\wedge dy_j -y_i\frac{\partial g_{ij}}{\partial x_k} d\tilde{x}_i\wedge d\tilde{x}_k,
$$ while $\omega$ reads in coordinates as $-g_{ij}d\tilde{x}_i\wedge dy_j$ (or the opposite, I'm not 100% sure about the sign). Since the connection has not been used, it is logic to expect $dg^*\theta$ cannot match always with the above $\omega$ . However, there are certain conditions under it should. What are they? Is it related to the relations I am asking for?","['connections', 'symplectic-geometry', 'kahler-manifolds', 'differential-geometry']"
3211156,Wasserstein distance between $X$ and $X+N$,"Is there a way to calculate the Wasserstein distance (or any other distance) between the distribution of a random variable $X \in \mathbb{R}^d$ and the distribution of $X+N$ where $N \sim \mathcal{N}(0,\sigma^2\mathbb{I}_d)$ is small perturbation along the dimensions ?","['statistics', 'probability-distributions', 'signal-processing', 'probability-theory', 'random-variables']"
3211158,How to solve Poisson's equation on compact Riemann surfaces of genus greater than one?,"$M$ is a compact Riemann surface, $f\in C^{\infty}(M)$ . I want to find the solution of $\Delta \varphi=f$ . When $M=T^2=\mathbb{R}^2/2\pi \mathbb{Z}^2$ , I can use Fourier series on $\mathbb{R}^2$ to solve this equation. When $M$ are compact Riemann surfaces of genus greater than one, how to solve it? By the uniformization theorem, compact Riemann surfaces of genus greater than one have simply connected universal covering surface given by the unit disk $D$ (poincare metric).
 And $M=D/\Gamma$ , $\Gamma$ is a Fuchsian group of Mobius transformations. So maybe I can solve possion's equation on the Poincare disk?","['riemann-surfaces', 'riemannian-geometry', 'hyperbolic-geometry', 'partial-differential-equations', 'differential-geometry']"
3211174,$\int f^2$ and $\int f''^2$ is convergent then so is $\int f'^2$,"$f$ is second order differentiable in $[0,+\infty)$ . And $\int_0^\infty f^2$ and $\int_0^\infty f''^2$ is convergent. Prove that $\int_0^\infty f'^2$ is convergent. I can prove the case that $f$ and $f''$ is monotonic. In this case $f \rightarrow 0$ and $f'' \rightarrow 0$ when $x \rightarrow +\infty$ . Therefore $$\int f'^2 \mathrm{d}x = \int f' \mathrm{d}f = f'f|_0^\infty - \int ff''\mathrm{d}x$$ and $$\int ff'' \le (\int f^2 )^{\frac{1}{2}} (\int f''^2)^{\frac{1}{2}}$$ in convergent, so is $\int f'^2$ . But I don't know how to do in the general case.","['inequality', 'analysis']"
3211258,"$p^2-p+1=P^3$ prove how many $p$, $P$ pairs are there",Determine  with a proof all prime numbers $p$ such that $p^2-p+1$ is a cube of a prime number. $19^2-19+1=7^3$ But is it the only $p$ ? How should I prove it?,"['number-theory', 'elementary-number-theory']"
3211282,"Prove that points O, P, Q are collinear","Let $\triangle ABC$ be an acute triangle, with $O$ as its circumcenter. $H$ is the foot of the perpendicular from $A$ to the line $BC$ , and points $P$ and $Q$ are the feet of the perpendiculars from $H$ to the lines $AB$ and $AC$ , respectively. Given that, $$AH^2=2\cdot AO^2$$ prove that the points $O,P,Q$ are collinear.",['geometry']
3211285,Existence of directional derivative,"For a two variable function, does the existence of continuous partial derivatives of order 1 with respect to $x$ and $y$ at a point $(x,y)$ imply the existence of the directional derivative in any direction at the point $(x,y)$ ?","['partial-derivative', 'multivariable-calculus', 'real-analysis']"
3211298,"Asymptotic frequency of $[0,\,1,\,1]$ in the Thue–Morse sequence","Let $t_n$ be the Thue–Morse sequence : $$[\color{blue}{0,\,1,\,1,\,0,}\,\color{red}{1,\,0,\,0,\,1,}\,\color{blue}{1,\,0,\,0,\,1,}\,\color{red}{0,\,1,\,1,\,0,}\,...].\tag1$$ See this question for a  definition and formula for $t_n$ . Let's split the sequence into non-overlapping runs of length $3$ : $$[\underline{[\color{blue}{0,\,1,\,1}]},\,[\color{blue}{0,}\,\color{red}{1,\,0}],\,[\color{red}{0,\,1,}\,\color{blue}1],\,[\color{blue}{0,\,0,\,1}],\,\underline{[\color{red}{0,\,1,\,1}]},\,...].\tag2$$ There are $6$ different sorts or runs in this sequence: all possible combinations of $0$ and $1$ except $[0,\,0,\,0]$ and $[1,\,1,\,1]$ — the Thue–Morse sequence is cube-free. What is the asymptotic frequency of the $\underline{[0,\,1,\,1]}$ run? Empirically, it seems to be around $\style{color:#bbbbbb;text-decoration:line-through}{1/5}\,1/6$ , but the convergence is quite slow and erratic.","['conjectures', 'number-theory', 'asymptotics', 'combinatorics', 'sequences-and-series']"
3211307,How to prove this rank inequality? [duplicate],"This question already has an answer here : Matrix problem similar to Problem 3, SEEMOUS 2019 (1 answer) Closed 4 years ago . Let $n\geq2$ and $A,B\in M_{n}(\mathbb{C})$ such that $B^2=B$ . Prove that $$\mbox{ rank }(AB-BA)\leq\mbox{ rank }(AB+BA).$$ If $B$ is zero or the identity matrix, we are done. But $B$ will always be diagonalisable. From this, how we can proceed?","['matrix-rank', 'idempotents', 'matrices', 'linear-algebra', 'inequality']"
3211312,Probability is unique?,"In many problems of probability the requirement is : Find the probability of (something). But a probability is a positive numeric function s.t: Axiom 1. $P(E)=1$ ,where $E$ is sample space. Axiom 2. Let $A_1,A_2,\ldots$ be a countable (possibly countably infinite) sequence of pairwise disjoint events. then: $$ P\left(\bigcup_n A_n\right)= \sum_n P(A_n)$$ But there are many functions, satisfying these axioms, so what does it mean to find the probability of some event? Or is the probability somehow unique?",['probability']
3211340,"Bijection between ""circularly nonconsecutive"" permutations and permutations with one fixed point","A permutation $\pi$ of $[n]:=\{1,2,\dots,n\}$ is called circularly nonconsecutive (CNC) if $\pi_{i+1}-\pi_i\neq 1$ for all $i=1,2,\dots,n-1$ , and furthermore $\pi_1-\pi_n\ne 1$ . In other words, $i+1$ does not occur immediately after $i$ , for any $i\in \{1,2,\dots,n-1\}$ , where we consider the first entry of the permutation as occurring immediately after the last in a circular fashion. There are $3$ CNC permutations of $[3]$ : $(1,3,2)$ , and its two rotations, $(3,2,1)$ and $(2,1,3)$ . In general, all $n$ rotations of a CNC permutation are also CNC. It can be shown that the number of CNC permutations is equal to the number of permutations with exactly one fixed point. You can count both of these quantities with an inclusion exclusion argument and find the the resulting expressions are coincidentally the same, both equal to $$n!\sum_{k=0}^{n-1}\frac{(-1)^k}{k!}$$ Can you give a bijection between CNC permutations of $[n]$ and permutations of $[n]$ with one fixed point? Equivalently, permutations with one fixed point can be partitioned into $n$ equal classes based on which point is fixed, just like CNC permutations can be partitioned into circular rotation classes. So it would be equivalent to find a bijection between CNC permutations for which $\pi_n=n$ and permutations where the only fixed point is $\pi_n=n$ . The latter is obviously in bijection with derangements of $[n-1]$ .","['permutations', 'inclusion-exclusion', 'combinatorics', 'combinatorial-proofs']"
3211341,Holder conditional inequality,"we consider, on a probability space $(\Omega,\mathcal{A},P)$ , two random variable $X$ and $Y$ and let $\mathcal{H} \subset \mathcal{A}$ be a $\sigma$ -algebra. Let $p,q>1$ such that $\frac{1}{p}+\frac{1}{q}=1.$ Prove : $$E[|XY||\mathcal{H}] \leq (E[|X|^p|\mathcal{H}])^{1/p}(E[|Y|^q|\mathcal{H}])^{1/q}$$ I tried to use the Holder inequality for integral, I mean if we have : $$\forall B \in \mathcal{H},\int_B|XY|dP \leq \int_B(E[|X|^p|\mathcal{H}])^{1/p}(E[|Y|^q|\mathcal{H}])^{1/q}dP$$ then the problem is solved. So I am stuck in proving the integral inequality.","['conditional-expectation', 'holder-inequality', 'probability-theory']"
3211425,"Proving $C_{0} + C_1x +\cdots+ C_{n}x^{n} = 0$ has at least one real root in $(0,1)$ [duplicate]","This question already has answers here : Prove existence of a real root. (1 answer) Prove that the equation: $c_0+c_1x+\ldots+c_nx^n=0$ has a real solution between 0 and 1. [duplicate] (2 answers) Closed 5 years ago . If $$C_{0} + \frac{C_1}{2} + \cdots+ \frac{C_{n-1}}{n} + \frac{C_{n}}{n+1} = 0\,,$$ prove that $$C_{0} + C_{1}x + \cdots+ C_{n-1}x^{n-1} + C_{n}x^{n} = 0$$ has at least one real root between $0$ and $1$ . I know how to prove the result by using the mean value theorem, but I am not understanding how the result from the mean value theorem allows us to conclude the final result. What I am asking is how does the existence of an $x \in (0,1)$ such that $f'(x) = 0$ mean that there exists a real root between $(0,1)$ ? All I can conclude from that is that there is an $x \in (0,1)$ such that the slope is the same as a secant line from the endpoints.","['calculus', 'derivatives', 'real-analysis']"
3211427,Finding the conditional PDF of the conditional expectation,"I will quickly summarize the general definition of conditional expectation. Let $(\Omega, \mathcal{A}, P)$ a measure space, $X: \Omega \to \mathbb{R}$ a random variable and $\mathcal{G}$ a sigma algebra such that $\mathcal{G} \subset \mathcal{A}$ . By Radon-Nikodyn theorem, we guarantee the existence of the conditional expectation $E(X|\mathcal{G})$ defined as the unique random variable satisfying the following properties: $E(X|\mathcal{G})$ is $\mathcal{G}$ -measurable; $\int_G E(X|\mathcal{G})dP = \int_G X dP$ , $\quad\forall G\in \mathcal{G}$ . If $G = \Omega$ , we conclude $E[X] = E[ E(X|\mathcal{G})]$ . But I would like to discuss in a little detail these expectations, especially when we use their respective densities (pdf) to express the expectation. We know that $$E[X] = \int x f_X(x) dx$$ . Suposse $X$ and $Y$ two random variables. Considere $\sigma(X)$ and $\sigma(Y)$ the respective $\sigma$ -algebra generated by $X$ and $Y$ . The notation is well knowk: $E(X | Y) = E(X | \sigma(Y))$ . By definition, we know that $E(X | Y)$ is $\sigma(Y)$ -measurable. I have two questions: (1) How can I argument that $E(X | Y)$ is a random variable obtained as a certain function of the $Y$ random variable? (2)  How do I prove that to calculate $E(X | Y = y)$ , I have to use the conditional pdf $f_{X|Y}(x|Y = y)$ ? In other words. $E(X | Y = y) = \int x f_{X|Y}(x|Y = y)dx$ ?","['conditional-expectation', 'measure-theory', 'probability-theory']"
3211463,How to solve $\int^1_{-1} \frac{\sin(x)}{1+x^2}dx$?,"I have to solve $$\int^1_{-1} \frac{\sin(x)}{1+x^2}\,dx$$ I am a Calculus 1 student, and I am having difficulty because I can't think of anything that I could make into a substitute which would cancel much. I think this may be a difficult problem to solve without using techniques that are beyond a college Calculus 1 level of skill, but please try, or I may have a hard time understanding what you mean. Here is some of what I've tried: $u=1+x^2$ $du = 2xdx$ $\frac{du}{2x} = dx$ $$\int^1_{-1}\frac{1}{u} \cdot \sin(x) \cdot \frac{1}{2x} \cdot du$$ I have tried plugging this into Symbolab.com, but it wont even give me a hint what $u$ should be.","['integration', 'calculus', 'definite-integrals', 'substitution']"
3211467,Why eigenvectors with the highest eigenvalues maximize the variance in PCA?,"I'm learning Principal Component Analysis (PCA) and came to know that eigenvectors of the covariance matrix of the data are the principal components, which maximizes the variance of the projected data. I understand the intuition behind why we need the variance of projected data as large as possible. From this answer, I don't understand the following line: The unit vector $u$ which maximizes variance $u^TΣu$ is nothing but the eigenvector with the largest eigenvalue. I know how the variance of projected data points is $u^TΣu$ from this answer. But I don't understand why this will be maxed when $u$ is selected as eigenvectors of $u^TΣu$ with the highest eigenvalues? Intuitively I see eigenvectors as the vectors which stay fixed in their direction under the given linear transformation (values may scale, which are known as eigenvalues). Source: This answer. and this video. I can't relate why vectors with a fixed direction under given linear transformation give the highest variance? Any intuitive explanation will help! Thanks.","['principal-component-analysis', 'eigenvalues-eigenvectors', 'machine-learning', 'linear-algebra', 'linear-transformations']"
3211502,Graph coloring and directed edges,"Proof that graph $G$ is $k$ colored if and only if we can indicate his edges acyclic such that new directed graph doesn't contain  path with $k$ edges I want to say something about my approach but this is one of these task where I have spent hours and didn't get nothing. I suspect that in "" $ \implies $ "" we can show some strategy to build  such graph. For example I have colors $$ c_1,c_2,c_3,
...,c_k $$ such that $$ c_1 < c_2 < ...<c_k $$ and use it for strategy. I tried for example choosing in each step smallest possible color but it is not good algorithm","['graph-theory', 'coloring', 'discrete-mathematics']"
3211510,Construct $\varphi (z)$ such that $\int_{|z|=1} \frac{\varphi (z)}{z-w} dz =0$,"I have this problem to complex analysis. Construct $\varphi (z)$ a continuous function nonzero in $S^{1}$ such that $$\int_{|z|=1} \frac{\varphi (z)}{z-w} dz =0$$ for $|w|<1$ . I have the idea to take $\varphi (z) = (z-w)f(z)$ with $f(z)$ analytic function that is nonzero in $S^{1}$ and use Cauchy theorem for integral, but I am not sure that this is correct. Note: English is not my first language so I am sorry if I did any mistake.","['complex-analysis', 'contour-integration']"
3211519,Is there a name for the set defined by the Minkowski sum of circles in orthogonal planes?,"Recently, I started thinking about the set of points defined by the Minkowski sum of 1D circles in orthogonal planes. The reason for this is to extend the well known result that 1D linear/harmonic oscillators are equivalent to uniform circular motions in the 2D plane, projected onto a line. Generalizing this, it is possible to think of n -dimensional harmonic oscillators as projections of the sum of uniform motions on n circles in n orthogonal planes in an ( n +1)-dimensional Euclidean space with a common vertical axis. To illustrate this construction in the n =2 case, I have created an animated GIF showing two unit circles centered at the origin in the x-z and y-z planes: In this animation, the view rotates to show the same trajectory from two different viewpoints. The second view visually shows the linear projection onto the gray plane. Purple square shows the sum of the projections of the red and blue balls onto this ( x-y ) plane. (There is a random phase shift between the red and blue balls.) More images and animations of this type are posted on my Twitter feed . The alignment of the gray ball and the purple square in the projection view visually indicates that 2D linear oscillator motions (purple square) are indistinguishable from projected motions on the 3D surface (gray ball). This is an instance of the property that sums of linear projections of vectors are equivalent to linear projections of sums of  vectors, by linearity of the projection operator. This particular instance of this simple property may be relevant due to the importance of linear/harmonic oscillators in mathematical physics. By extension, n -dimensional oscillators can be thought of as projections of sums of uniform motions on n circles on n orthogonal planes in ( n +1) dimensions. Although unit circles and identical velocities for the uniform circular motions are shown in this animation, the example could easily be generalized to circles with arbitrary radii and points moving with arbitrary fixed velocities. My questions are: Does the set of points defined by the Minkowski sum of this type of
arrangement of n circles in ( n +1)-dimensions have a name? If so, are there any references or discussions about its properties
and potential relevance to physics? For the sake of clarity, below is some Matlab code to compute a cloud of 3D points representing a finite sample of points in this set, using uniform samples of the two circles: function circle = circle_sum( Npoint )

if nargin < 1 || isempty( Npoint ) 
  Npoint = 4 * 1e3 ; % default number of points per circle
end

circle.x = zeros( Npoint, 3 ) ;
circle.y = zeros( Npoint, 3 ) ;

for kt = 1 : Npoint % generate the 3D coordinates of two 1D circles in orthogonal planes

  tk    = 2 * pi * (kt - 1) / Npoint ; % circle position parameter
  costk = cos( tk ) ; % projection onto the x-y plane
  sintk = sin( tk ) ; % vertical coordinates

  circle.x( kt, : ) = [ costk 0 sintk ] ; % point on circle in the x-z plane 
  circle.y( kt, : ) = [ 0 costk sintk ] ; % point on circle in the y-z plane 

end

circle.sum = zeros( Npoint, Npoint, 3 ) ;

for ks = 1 : Npoint  % points on the Minkowski sum of the circles
  for kt = 1 : Npoint
    circle.sum( kt, ks, : ) = circle.x( ks, : ) + circle.y( kt, : ) ;
  end
end Also, here is some Matlab code to plot this surface from its parametric form: syms s t
x = cos(s) ; y = cos(t) ; z = sin(s) + sin(t) ;
fsurf(x, y, z, [0 2*pi 0 2*pi])
axis square
xlim([-2 2]), ylim([-2 2])
camlight
figSize = 480 ;
az = -35 ;
el = 15 ;
view( az, el ) ;
set( gcf, 'position', [10 10 figSize figSize] )
set( gca, 'xtick', [], 'ytick', [], 'ztick', [] ) Resulting image:","['harmonic-analysis', 'vectors', 'geometry', 'mathematical-physics']"
3211526,Cardinality of certain subsets in vector spaces over finite fields,Assume that you have an $n$ -dimensional vector space over a finite field (therefore the number of elements in the vector space is finite.) and $F$ is a subset of this vector space which contains $m$ elements. Let's $A$ is a subset of this vector space when the intersection of $A+A$ and $F$ is empty. The question is this: What is a non trivial lower bound for the cardinality of $A$ ? Thank you.,"['abstract-algebra', 'linear-algebra', 'extremal-combinatorics', 'combinatorics']"
3211530,Invariant Polynomials under Rotations,"Consider a real polynomial $P(x, y)$ in two variables. It is called invariant with respect to the rotation by an angle $\alpha$ if $$
P (x \cos(\alpha) − y \sin(\alpha), x \sin(\alpha) + y \cos(\alpha)) = P (x, y)
$$ for all real $x$ and $y$ . 
How do we find the dimension of the real vector space formed by all polynomials in 
two variables of total degree not greater than $d$ invariant with respect to the 
rotation by $2\pi/n$ ?","['vector-spaces', 'linear-algebra', 'combinatorics', 'group-actions', 'rotations']"
3211533,Prove that the transitive closure of a relation is transitive without using recursion,"In Kunen's book Set Theory (from 2013) the transitive closure of a relation $R$ on $A$ is defined as $$
 R^* = \{ (x,y) \in A^2 : \text{there is an $R$-path from $x$ to $y$} \}
$$ where an $R$ -path from $x$ to $y$ simply is a function $s : n+1 \to A$ for some $n \in \omega$ such that $s(0) = x$ and $s(n) = y$ and $s(i) \,R\, s(i+1)$ for all $i < n$ .
This is Definition I.9.4 in the book. Now it is claimed in Lemma I.9.5 that $R^*$ is transitive, the proof being that this is ""easily seen by combining paths"". However, I cannot figure out how to combine two paths without appealing to the validity of recursive definitions for $\omega$ . The way it is presented in the book somehow suggests that this should be possible.
Indeed, the goal of the chapter really seems to be to prove the recursion principle for well-founded sets without having to prove recursion for $\omega$ first. Is there a way to combine paths without having to use recursion that I am overlooking? I would also appreciate if someone could point me to another proof of the principle of well-founded recursion where it is not assumed to already know recursion for $\omega$ .","['elementary-set-theory', 'relations']"
3211538,A multi variable function that satisfies 3 conditions,"Let $f(x,y)$ be multi variable function that is defined when $\frac{x}{2}<y <x $ , and I want to know if there is such a function that satisfies : 1 ) $f(x-1,y) > f(x,y)$ 2 ) $f(x-1,y-\ln x) > f(x,y)(1-\frac{1}{x})$ 3 ) $|f(x,y) - \ln x| < \frac{1}{\sqrt{x}}$ when $|y- x| < 3\ln x$ , this condition can be loosened to say $\frac{1}{x^{\frac{1}{3}}}$ or more (but for a fixed constant power). I think such function do not exist, I just don't have a proof. Please give a proof that such function does not exist or an example for such a function Edit : I am interested as $x \to \infty$ how the function behave, also i am assuming that $f(x-1,y),f(x-1,y-\ln x),f(x,y)$ are all defined. For example the function $f(x,y) = \ln (x) +1-\frac{x}{y}$ does satisfy the conditions $1,3$ but does not satisfy $2$ .",['real-analysis']
3211539,Existence of absolutely continuous measure,"Does there exists a finite measure $\mu$ on the $\sigma-$ algebra of Lebesgue measurable subsets of $\mathbb{R}$ such that $\mu << m$ and $m <<\mu$ , where $m$ is the Lebesgue measure? My attempt is to use the Radon-Nikodym theorem to arrive at a contradiction but I am stuck. Any help will be appreciated.","['measure-theory', 'real-analysis']"
3211549,How to evaluate $\underset{x \to 1}{\lim} \frac{x^{2019} - x^{1875}}{x-1}$.,"I know how to evaluate $\underset{x \to 1}{\lim} \frac{x^{2019} - 1}{x-1}$ using the definition of the derivative and the power rule. If $f(x) = x^{2019}$ , then $$\lim_{x \to 1} \frac{x^{2019} - 1}{x-1} = \lim_{x \to 1} \frac{x^{2019} - 1^{2019}}{x-1} = f'(1) = 2019(1)^{2018} = 2019.$$ I assume the problem from the title is similar since the answer is $144$ according to Wolfram Alpha, but I can't wrap my head around it. Edit: I want to know how to do this with the definition of the derivative, not L'Hospital's.","['limits', 'calculus', 'derivatives']"
3211605,How to prove that $\sum\limits_{n=1}\frac{\sin^2n}n$ is divergent,How to prove that $\sum\limits_{n=1}\frac{\sin^2n}n$ does not converge without using the series expansion and with the following tests only or a combination of them (comparison or limit comparison test ),"['sequences-and-series', 'real-analysis']"
3211621,What dose the oplus operator do in set theory,"I'm having some trouble understand oplus in set theory, I couldn't find a simple explanation or example.
So lets say you have $A=\{a,b,c,d\}$ and $B=\{a,c,e,g,i\}$ What would be $A \oplus B$ ? What does the operator do simply?","['elementary-set-theory', 'notation']"
3211629,"If $\nabla f(x,y) \cdot (x,y) = f(x,y)$, then $f$ is first degree homogeneous","Given $f$ differentiable in $\mathbb{R}^2 \setminus \{(0,0)\}$ . We're asked to prove that if $\nabla f(x,y)  \cdot (x,y) = f(x,y)$ for all $\mathbb{R}^2$ , then $f$ is an homogeneous function, i.e. $f(t(x,y))=tf(x,y)$ for $t>0$ and $(x,y) \neq (0,0)$ . My prof. explained that proving the consequent amounts to proving that $$g(t) = \frac{f(tx_0, ty_0)}{t}, t>0,$$ is a constant function, which in turn amounts to showing that its derivative is 0 everywhere. But how do we justify that $g(t) = f(x_0,y_0)$ ?","['multivariable-calculus', 'derivatives', 'homogeneous-equation']"
3211739,"If $f: A \rightarrow B$ and $g: B \rightarrow C$, is $(g \circ f)^{-1}(C) = f^{-1}(B)$?","Let $f: A \rightarrow B$ and $g: B \rightarrow C$ . I have a question that is asking me to come up with and prove some theorems about the images and inverse images of sets under $g \circ f$ . This is a theorem and proof that I have so far (sorry, I'm not great at writing proofs): Theorem: Suppose $f: A \rightarrow B$ and $g: B \rightarrow C$ . Then $(g \circ f)^{-1}(C) = f^{-1}(B)$ . $(\subseteq)$ Suppose $x \in (g \circ f)^{-1}(C)$ . This implies that $x \in A$ . Since $x \in A$ and $f: A \rightarrow B$ is a function, then $f(x) \in B$ . Thus, since $x \in A$ and $f(x) \in B$ , it follows that $x \in f^{-1}(B)$ . $(\supseteq)$ Suppose $x \in f^{-1}(B)$ . This implies that $x \in A$ and $f(x) \in B$ . Since $f(x) \in B$ and $g: B \rightarrow C$ is a function, then $g(f(x)) \in C$ . Thus, since $x \in A$ and $g(f(x))=(g \circ f)(x) \in C$ , it follows that $x \in (g \circ f)^{-1}(C)$ . Is this a valid theorem and proof, or is this not always true? I'm having trouble trying to come up with a counterexample.","['elementary-set-theory', 'functions', 'proof-verification']"
3211794,"Stalks, Germs and Localisation","I've been trying to prove the following proposition: Let $(X,\mathcal{O}_X)$ be a quasi-compact ringed space which is locally isomorphic to an affine variety over an algebraically closed field $k$ . Let $x\in X$ and $U\subseteq X$ be an affine open set of $X$ with $x\in U$ . Then for $A=\Gamma(U,\mathcal{O}_X)$ with maximal ideal $m=\{f\in A\mid f(x)=0\}$ , we have $A_m\cong\mathcal{O}_{X,x}$ , the stalk of $\mathcal{O}_X$ at $x$ . I've can prove the case where $U$ is irreducible: We have $A_m=\{\frac{f}{g}\mid f,g\in\Gamma(U,\mathcal{O}_X),g(x)\neq0\}$ . Let $\varphi:A_m\to\mathcal{O}_{X,x}$ send $\frac{f}{g}$ to the germ $(D(g),\frac{f}{g})$ . To show that $\varphi$ is surjective, take any $(H,h)\in\mathcal{O}_{X,x}$ , where $H\subseteq X$ is open, $x\in H$ and $h\in\Gamma(H,\mathcal{O}_X)$ . We have $H\cap U=\cup_{i=1}^nD(g_i)$ for some $g_i\in\Gamma(U,\mathcal{O}_X)$ , with $h\mid_{D(g_i)}=\frac{f_i}{g_i}\mid_{D(g_i)}$ for some $f_i\in\Gamma(U,\mathcal{O}_X)$ . Then $(H,h)=(D(g_1),\frac{f_1}{g_1})=\varphi(\frac{f_1}{g_1})$ since $h$ and $\frac{f_1}{g_1}$ agree on $\cap_{i=1}^nD(g_i)$ , which is non-empty since $U$ is irreducible. For injectivity, if we have $\varphi(\frac{f_1}{g_1})=\varphi(\frac{f_2}{g_2})$ , then we know that $\frac{f_1}{g_1}$ and $\frac{f_2}{g_2}$ agree on some non-empty open $W\subseteq D(g_1)\cap D(g_2)$ . Then $W\subseteq V(f_1g_2-f_2g_1)$ , so by the irreducibility of $U$ we have that $f_1g_2=f_2g_1$ on all of $U$ , so $\frac{f_1}{g_1}=\frac{f_2}{g_2}$ in $A_m$ . However this argument makes heavy use of the irreducibility of $U$ , and I can't seem to generalise it to the case where $U$ might not be irreducible.","['affine-varieties', 'ring-theory', 'algebraic-geometry', 'germs', 'sheaf-theory']"
3211798,Proving $(n+1)$th differential is $0$ given lower differentials are $0$,"Following is a question I am stuck in. Let $f : \Bbb R \to \Bbb R$ be an infinitely differentiable function and suppose that for some $n ≥ 1$ , $$f(1) = f(0) = f^{(1)}(0) = f^{(2)}(0) = · · · = f^{(n)}(0) = 0$$ Prove that there exists $x \in (0, 1)$ such that $f^{(n+1)}(x) = 0$ . It is a past question of an entrance exam. I thought to use Rolle's Theorem, but this requires information about $f^{(n)} (1)$ that I am unable to get. Only information about behaviour at $1$ I have is $f(1)=0$","['calculus', 'real-analysis']"
3211859,Simple closed curves have the same trace if and only if they are equivalent,"I'm very stuck on Exercise 1.35 (4) in Kristopher Tapp's Differential Geometry of Curves and Surfaces which reads: Show that two parametrized simple closed curves have the same trace if and only if they are equivalent (that is, one is a reparametrization of the other). Note that this text defines curves to be smooth and closed curves to be regular. Further, it is meant to only have the prerequisites of multivariable calculus, linear algebra, and real analysis (not necessarily including multivariable content), does not introduce the idea of a diffeomorphism until talking about surfaces, and does not define the derivative of a curve as a linear function between tangent spaces (but rather as another curve, differeniated componentwise). I am looking for a solution that reflects this. The ""if"" direction is clear from the definitions, but I'm stuck on the ""only if"". I've tried doing it directly by supposing two simple closed curves $\boldsymbol\gamma: [a, b] \to \mathbb R^n$ and $\boldsymbol\beta: [c, d] \to \mathbb R^n$ have the same trace and constructing a bijection $\phi: [a, b] \to [c, d]$ such that $\boldsymbol\gamma = \boldsymbol\beta \circ \phi$ , but I get stuck trying to show that $\phi$ is smooth, let alone that its derivative is never zero and that its derivatives all match at $a$ and $b$ . Update: I've been reviewing the differential geometry exercises I was working on when I wrote this problem and made some progress, but I'm still not quite sure how to put everything together. Here's what I have so far. Let $\boldsymbol\gamma: [a, b] \to \mathbb R^n, \boldsymbol\beta: [c, d] \to \mathbb R^n$ be two parametrized simple closed curves with the same trace $\Gamma$ and components $\boldsymbol\gamma(t) = (\gamma_1(t), \ldots, \gamma_n(t)), \boldsymbol\beta(t) = (\beta_1(t), \ldots, \beta_n(t))$ , and assume without loss of generality that $\boldsymbol\gamma(a) = \boldsymbol\beta(c)$ . For every $s \in [c, d]$ , there is a $k(s) \in \{1, \ldots, n\}$ such that $\beta_{k(s)}'(s) \neq 0$ , and hence there are neighbourhoods $U_s$ of $s$ in $[c, d]$ and $V_s$ of $\beta_{k(s)}(s)$ in $\mathbb R$ such that $\beta_{k(s)}$ has a smooth local inverse $\psi_s: V_s \to U_s$ . I then want to define $\phi(t) = \psi_s(\gamma_{k(s)}(t))$ , where $\boldsymbol\beta(s) = \boldsymbol\gamma(t)$ , but I'm getting caught up in writing out the details showing that this is well-defined (and I'm not sure it is well-defined for $t \in \{a, b\}$ ). Once I have that, it is clear that (a) $\phi$ is smooth, (b) $\phi$ has nonzero derivative, and (c) all derivatives of $\phi$ match at $a$ and $b$ .","['curves', 'parametrization', 'differential-geometry']"
3211893,"Tao Analysis I, exercise 5.2.2.","I have proved the following statement and would like to know if my proof seems correct. Let ε > 0. Show that if $(a_n)$ and $(b_n)$ are eventually
ε-close, then $(a_n)$ is bounded iff $(b_n)$ is bounded. see this snapshot from the text itself Proof:
Since $a_n$ and $b_n$ are ε-close, we know that for all $ε > 0$ there exists a natural number $N$ , such that $$|a_n - b_n| \le ε,$$ $$ n\ge N $$ Since $b_n$ is bounded, $|b_n|<=M_1$ for some natural number $M_1$ .
Set $ε = 1$ . Then there exist a natural number $N$ such that $$|a_n - b_n| \le 1,$$ $$ n\ge N $$ Applying the reverse triangle inequality: $$ |a_n| - |b_n| \le |a_n - b_n| \le 1$$ thus: $$ |a_n| \le 1 + |b_n| $$ For $ n < N $ , $ (a_n)$ is a sequence of finite elements and thus bounded (it is assumed this fact does not need to be proved), say by the natural number $M_2$ . For $ n \ge N, |a_n| \le  1 + M_1$ (since $b_n$ is bounded). Set $M_3 =  max(M_2, 1 + M_1)$ . Then for all $n$ , $|a_n| \le M_3$ . Thus $(a_n)$ is bounded, and the proof is completed.","['proof-verification', 'real-analysis']"
3211894,What can be said about $(\varepsilon-x)y=y'(-x+y^2-2x^2)$ solutions?,"There was an unanswered question 4 years ago. OP asked for a solution of ODE $(\varepsilon-x)y=y'(-x+y^2-2x^2)$ The comment to the original question proposes an implicit solution, $2\log y + 2\epsilon\log(x + 2 x\epsilon - y^2) - (1+2\epsilon)\log(\epsilon + 2 x\epsilon - y^2) = C$ Could you explain to me how this solution can be obtained? Are there singular solutions? If there are any orthogonal families that can be described explicitly, I would like to know about them. If it can be reduced to some special function differential equation, that would be also great! I tried to find an integration factor, but it exists only for $\varepsilon = -\frac{1}{4}$ Here is a graph of solution $\pm \sqrt{\pm \frac{\sqrt{2cx^2+cx+1}}{c}-\frac{1}{c}}$ for $c = -1$ It's not separable, homogeneous, solvable for $x$ or $y$ or Lagrangian, so I'm stuck.","['implicit-differentiation', 'ordinary-differential-equations']"
3211897,"Drawing all chords between six points on a circle, prove that only one triangle is formed in the circle's interior.","Motivating problem: https://artofproblemsolving.com/wiki/index.php/2010_AMC_10A_Problems/Problem_22 If we draw a triangle in the interior of a circle, it is straightforward to show that the triangle can be constructed by the intersection of chords drawn between 6 points on the circle. This can be done by extending each side of the triangle until it intersects with the circle. I am unable to prove that if we start with six points on the circle, and draw chords between all points, that only one triangle is formed in the circle's interior. I've listed some related questions below but I don't think these questions are quite what I'm looking for. Related questions: How many triangles are formed by $n$ chords of a circle? Number of triangles formed by all chords between $n$ points on a circle Chords on a Circle",['geometry']
3211916,Efficiently compute $f'(a)f'(b)f'(c)$ for the roots of a cubic polynomial,"Let $a,b, c$ be the zeroes of $f(x) = x^3+3x^2-7x+1$ . Find $f'(a)f'(b)f'(c)$ . My idea involved substituting in $a,b,c$ into $f'(x)$ then using Vieta's but that would take far too long of a time, especially since I'm training for competitions. What would be a great way to solve this within a time limit?","['calculus', 'functions', 'roots', 'algebra-precalculus']"
3212002,Example of no non-constant meromorphic functions,"This is a basic question but I have found it annoyingly hard to find an answer (which means its incredibly trivial or non-trivial!) Are there examples of compact complex manifolds (of dimension at least 2) which do not admit any global, non-constant, meromorphic functions? Of course this question can be phrased in a number of ways. For one, is there an example of a compact complex manifold which does not admit a rational map into a projective space? Equivalently, is there an example of a compact complex manifold which does not admit a linear system with a base locus of at least codimension 2?","['complex-geometry', 'algebraic-geometry', 'differential-geometry']"
3212012,Find the limit without using Lhopital,this question came out on my analysis exam: Evaluate $$\lim_{x\to 0}\left(\frac{5^{x^2}+7^{x^2}}{5^x+7^x}\right)^{\frac{1}{x}} $$ I did it using L'hopital rule but is there another way to do this?,"['calculus', 'limits-without-lhopital', 'analysis']"
3212037,Volume of Viviani’s Window,"I’m taking Real Analysis and I have an assignment to do on calculating the volume of Viviani’s window or dome. I have to solve this for the sphere $$x^2+y^2+z^2=4$$ and the cylinder $$(x-1)^2+y^2=1$$ Here's a visual representation of the problem: Here's a figure obtained from the intersection of the 2 figures. (I need to find the volume of that figure.) The image shows a curve which does not have a volume but to understand what volume the problem is asking I imagine as if on the inside it is filled with some material My problem is that all I have seen on the Internet about this problem involves multivariable calculus, parametrization, polar coordinates, etc. I have not seen any of these yet, so I have to do this problem with integrals in only one variable. The formulas we have seen in class about the applications of the Riemann Integral are the following: Arc length L of a curve $$L= \int_{a}^{b} \sqrt{1+(f’(x))^2} dx$$ Volume $$V_1=\int_{a}^{b} \pi (f(x)^2 dx$$ $$V_2=\int_{a}^{b} A(x)dx$$ A(x) is the area of a section of the figure Lateral area $$\int_{a}^{b}2\pi f(x) \sqrt{1+f’(x)}dx$$ I thought on expressing the sphere equation and the cylinder equation in terms of the same variable and integrating. The reason behind this was that Viviani’s dome is composed of the points that belong to the cylinder and sphere at the same time, but this reasoning has failed and I don’t know why. Any help is very much appreciated and I’m sorry for my broken English. EDIT This is all I have for now. Need help for A(x). I don’t know how to treat x as a parameter inside the integral and at the bounds of the integral. EDIT 2 @Ertxiem I finally solved the integral and got the final answer: $$\frac{16}{9}(3\pi-4)$$ I still have a few questions though: When you said: “ You can start by thinking about the base .” what did you really meant by the base? I can’t really see what the base of a figure like that would be, since it’s a curve-like figure, how would you visualize that? If you meant the base of the figure, then I understand that studying it is necessary in order to compute the volume but at what point that computation was used? What is exactly b(x) and why is it important? Regarding the height, A(x) is the integral of a function, which is the height taking x as a parameter and y as a variable but, the graph of the function is in the first quadrant, so, doesn’t this mean that we are actually integrating height/2? Conclusion: Find the base, find the height, find the area of a section by integrating the previous results, find the volume by integrating the area of a section. Please point out any flaws, errors. Any suggestions for a better explaining, understanding of the problem are welcome. Thanks!","['integration', 'definite-integrals', 'geometry', 'real-analysis', 'calculus']"
3212043,Drawing Arrows on a Cubical,"Suppose that an arrow is drawn on each edge of a cube, giving each edge a direction, in such a way that every vertex of the cube has at least one arrow coming out of it and at least one arrow going into it. Prove there exists a face of the cube such that the directions of the four boundary edges of that face go in a cycle. So a cube has 6 faces, 8 vertices, and 12 edges, and there will be 12 arrows in total. each vertex has three edges with one in and two out or one out and two in. WLOG, we can assume one vertex for one in and two out and then we go to the adjacent vertices. Is there  an easier way to do this than just exhaust all possibilities by going through all vertices?","['graph-theory', 'discrete-mathematics']"
3212064,"Evaluate $\lim_{a\rightarrow \infty }\frac{1}{a}\int_{0}^{a}\sin(x)\sin(x^2)\,dx$","Calculate $$I=\lim_{a\rightarrow \infty }\frac{1}{a}\int_{0}^{a}\sin(x)\cdot \sin(x^2)\,dx$$ I tried to use the fact that $\lim_{x\rightarrow \infty }\frac{1}{x}\int_{0}^{x}(f(t))\,dt=\frac{1}{T}\int_{0}^{T}f(t)\,dt$ where $T$ is period of the function. So in my case $T=2\pi$ , right? So I have $$I=\lim_{a\rightarrow \infty }\frac{1}{2\pi}\int_{0}^{2\pi}\sin(x)\sin(x^2)\,dx=\lim_{a\rightarrow \infty }\frac{1}{\pi}\int_{0}^{\pi}\sin(x)\sin(x^2)\,dx$$ Now I noted $x=\pi-t$ so $$I=\lim_{a\rightarrow \infty }\frac{1}{\pi}\int_{0}^{\pi}\sin(\pi-t)\sin((\pi-t)^2)\,dt=\lim_{a\rightarrow \infty }\frac{1}{\pi}\int_{0}^{\pi}\sin(t)\sin((\pi-t)^2)\,dt$$ How to continue? Is my method correct?","['integration', 'limits', 'calculus']"
3212065,Combinatorial proof that chromatic polynomial of $n$-cycle is $(x-1)^n+(-1)^n(x-1)$.,How we can proof that chromatic polynomial of cycle $C_n$ is $$ w(x) =(x-1)^n+(-1)^n(x-1) $$ I saw algebraic proof but I am really interested in combinatoric proof of this fact We choose random element (without lost of generality) and give him one of $x$ colour. $$ w(x) = x \cdot ... $$ Now we choose color for right neighbour on $(x-1)$ ways. And again for next right neighbour we choose in $(x-1)$ ways next color. We repeat that as long as we don't meet first vertex. So $$ w(x) = x(x-1)^n \neq (x-1)^n+(-1)^n(x-1) $$,"['graph-theory', 'coloring', 'combinatorial-proofs', 'discrete-mathematics']"
3212082,The Automorphism Group of Free Quandles?,"The following definitions are quoted from this article : My question is, do we know anything description the automorphism group of free quandles with relative smaller number of generating set $S$ ? For example, for each $2\leq |S|\leq 4$ , is $\mathrm{Aut}(FQ(S))$ isomorphic to any familiar group?","['automorphism-group', 'group-theory', 'abstract-algebra']"
3212102,Definition of conditional probability and a problem.,"The Problem: An urn contains 3 red and 4 black balls and another contains 4 red and 5 black. A random ball is chosen from the first urn and is inserted into the second urn. After this a random ball is chosen from the second urn. Consider the events: $A$ : ""first ball is red"", $B$ : ""second ball is red"". Find the Probability $P_A(B)$ where "" $P_A(B)$ "" means the probability that $B$ happens if $A$ has happened (i.e. the conditional probability of $B$ given $A$ ). This is a simple problem right? Why I'm confused: But I'm confused. We work in the probability space $(\Omega,\Sigma,P)$ (in this case $\Sigma=\mathcal P(\Omega)$ ), and $P$ is a probability that means is a function which respect kolmogorov axioms. $P_A(B)=1/2$ (because if $A$ happened then in the second urn we will have 5 red balls and 5 black balls) My question: Here is my question: If $P_A(B)=\frac{P(A \cap B)}{P(A)}$ by definition (and $P $ is a function, we don't know what function just this function respect Kolmogorov axioms). How we came to the conclusion $P_A(B)=1/2$ ? Using $$\frac{\text{Number of Favorable Outcomes}}{\text{Total Number of Possible Outcomes}}?$$ This doesn't make sense for me. $P$ is fixed from the beginning, then we must find $P_A(B)$ using definition to be rigorous. I need a rigourous proof.",['probability']
