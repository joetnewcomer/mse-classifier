question_id,title,body,tags
663154,A condition implying that a holomorphic function is the identity map,"Let $\Omega$ be an open, connected and bounded subset of $\mathbb{C}$ , and $\varphi : \Omega \rightarrow \Omega$ a holomorphic function. If there exists a $z_{0} \in \Omega$ , such that $$
\varphi(z_0) = z_{0}\quad\text{and}\quad\varphi'(z_0) = 1,
$$ then prove that $\varphi$ is the identity function, 
i.e. $\varphi(z)=z$ , for all $z\in\Omega$ . Any hints?","['fixed-point-theorems', 'holomorphic-functions', 'analysis', 'analyticity', 'complex-analysis']"
663159,"Calculating variance of estimated intercept parameter, $\hat\beta_0$","I have the following sample : $$
\begin{array}{c|lr}
X&80&100&120&140&160&180&200&220&240&260\\
\hline
Y & 70 &65&90&95&110&115&120&140&155&150 \\
\end{array}
$$ Now i have to calculate $\mathbb V(\hat\beta_0)=\sigma^2[\frac{1}{n}+\frac{\bar X^2}{\sum(X_i-\bar X)^2}]$ here, X is independent  and Y response variable. $\beta_0$ intercept parameter $\sigma^2$ population variance But i have my sample data. How can i calculate $\sigma^2$ ?","['statistics', 'regression']"
663163,Cubic surface and birational equivalence,"Following Shafarevich ""Algebraic Geometry II"", I found this example. Let $X_3\subset\mathbb{P}^3$ a smooth cubic surface. To prove that $X_3$ is rational he claims that there is a birational map $\phi: X_3\dashrightarrow \mathbb{P}^2$ given by $\phi(x)=\mathit{l}_x\cdot L$, where $L=\mathbb{P}^2\subset\mathbb{P}^3$ and $\mathit{l}_x$ is a line through the point $x\in X_3$ that intersects two fixed skew lines on $X_3$, $m$ and $m^\prime$. I don't see why this map is birational and why the point $\mathit{l}_x$ should intersect two skew lines on $X_3$. Could someone elaborate a bit? I think i don't know very well the geometry of a cubic.","['birational-geometry', 'algebraic-geometry', 'surfaces']"
663164,$F$ entire with $\lim_{k \rightarrow \infty} F(z + N_{k}) = h(z)$ for every $h$ entire,"Universal Entire Functions. Prove that there exists an entire function with the following ""universal"" property: Given any entire function $h$, there is an increasing sequence  $\{ N_{k}\}_{k=1}^{\infty}$ of positive integers such that $$\lim_{k \rightarrow \infty} F(z + N_{k}) = h(z)$$ Is Runge approximation theorem implicated ?","['entire-functions', 'sequences-and-series', 'complex-analysis', 'limits']"
663171,Probability - sum of two dependent binomial variable,"If $X \sim B(n, p)$ and $Y \sim B(m, p)$ are dependent binomial variables with the same probability $p$, and same number of elements $N$, does that make $X + Y$ a binomial variable as well? If so with what parameters?",['probability']
663182,How prove $\measuredangle CDE=2\measuredangle ABE$,"In rectangular  $ABCD$,and $E\in AC$,such
$$BE=\sqrt{2}\cdot AE$$
show that
$$\measuredangle CDE=2\measuredangle ABE$$ My try: let $$AB=a,AD=b,\dfrac{AE}{AC}=k,$$
then
$$AE=k\sqrt{a^2+b^2},BE=k\sqrt{2(a^2+b^2)}$$
I know have this nice relsut
$$AE^2+EC^2=BE^2+ED^2$$
then
$$ED^2=k^2\cdot AC^2+(1-k)^2\cdot AC^2-2k^2\cdot AC^2=(1-2k)AC^2$$
so
$$\cos{\measuredangle EBD}=\dfrac{AB^2+BE^2-AE^2}{2AB\cdot BE}=\dfrac{a^2+k^2(a^2+b^2)}{2a\cdot k\sqrt{2(a^2+b^2)}}$$
$$\cos{\measuredangle CDE}=\dfrac{DC^2+DE^2-EC^2}{2 DC\cdot DE}=\dfrac{a^2+(1-2k)(a^2+b^2)-(1-k)^2(a^2+b^2)}{2\sqrt{(1-2k)(a^2+b^2)}a}=\dfrac{a^2-k^2(a^2+b^2)}{2\sqrt{(1-2k)(a^2+b^2)}a}$$ we will prove 
$$2\cos^2{\measuredangle ABE}-1=\cos{\measuredangle CDE}$$
$$\Longleftrightarrow 2\dfrac{((k^2+1)a^2+b^2)^2}{8a^2k^2(a^2+b^2)}-1=\dfrac{a^2-k^2(a^2+b^2)}{2\sqrt{(1-2k)(a^2+b^2)}a}$$ But I can't Thank you for you",['geometry']
663204,How to know difference between sum of numbers?,"If all the $6$ are replaced by $9$, then the algebraic sum of all the numbers from $$1 to $100$ (both inclusive) varies by? Question - What is the difference between algebraic sum of numbers(with $6$ and when $6$ is replaced by $9$)? Answer - Answer is $330$ I can do it manually but in exam time is limited and it take time to add these numbers, So I want to know that how can I solve it quickly and what if the range is big like $1$ to $1000$ how to solve it quickly?",['algebra-precalculus']
663230,"$\int_{0}^{\infty} f(x) \,dx$ exists. Then $\lim_{x\rightarrow \infty} f(x) $ must exist and is $0$. A rigorous proof?","Let $f: \mathbb R \rightarrow \mathbb R $ be a continuous function such that $\int_{0}^{\infty} \,f(x) dx$ exists. Then Prove that incase (i) $f$ is a non negative function, then $\lim_{x\rightarrow \infty} f(x) $ must exist and is $0$. (ii) $f$ is a positive differentiable function , $\lim_{x\rightarrow \infty} f'(x) $ must exist and is $0$ $Attempt$: For the first part, i don't have a rigorous proof except for the fact that the given condition can be visualised geometrically. Since, the definite integral is actually calculating the area beneath the non negative function, the only way the given limit can exist when limit of f(x) itself tends to 0 at infinity. Please give me a direction so that i can make this proof rigorous enough. For the second part, i took an example. We know that ( leaving out the finite integration parts from $0$ to $1$ ..) $\int_{1}^{\infty} e^{-x^2} dx \leq \int_{1}^{\infty} e^{-x} dx$ and the latter converges.  But the derivative of $e^{-x^2} = (-2x)e^{-x^2}$ whose integration does not exist when x $\in~[1,\infty)$ as it's a monotonic function after a finite $x$. Any help in providing rigor to the above proof will be very helpful Thanks","['improper-integrals', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
663231,Does homeomorphic to itself imply the same topology?,"I know homeomorphim is an equivalence relation, which means a topological space will be homeomorphic to itself. However, does the converse hold? In other words, is it possible that a set with two different topologies can still be self-homeomorphic? Thank you.",['general-topology']
663251,automorphism of fields,"let  we consider $GF(p^n)$ as a vector space over $GF(p)$, $p$ is prime. Also we want to have an invertible linear map on $GF(p^n)$, (automorphism of $GF(p^n)$). on the other hand we know that A field automorphism is a bijective ring homomorphism from a field to itself. I want to know what are the differences between these two automorphism? Can we consider them the same?","['vector-spaces', 'finite-fields', 'finite-groups', 'group-theory']"
663264,Strong Induction Base Case,Is a base case needed ? In response to many questions on this subject I offer the clarification below.,"['induction', 'elementary-set-theory']"
663295,holomorphic function with bounded real part on punctured neighborhood $\dot{D}_{\epsilon}(z_0)$,"I've seen here that a holomorphic function with bounded imaginary part on a punctured neighborhood of $0$ has a removable singularity at $0$. I just wanted to know if this result could be also extended to get this: Let $\epsilon >0$, $z_0 \in \mathbb{C}$ and $f$ be holomorphic on a punctured neighborhood $\dot{D_{\epsilon}}(z_0)$. Futhermore it holds for all $z \in \dot{D_{\epsilon}}(z_0)$ that $Re(f(z))< K \in \mathbb{R}$ This implies that $z_0$ is a removable singularity of $f$ $(|f(z)|$ is bounded ?$)$. If the answer is yes I'm searching for a proof Thanks for help !",['complex-analysis']
663297,Reducibility of a Hilbert scheme in projective space,"My question concerns the computation of the Hilbert scheme $\mathsf{Hilb}_{3}^{2x+1}$, which parametrizes all curves of degree $2$ and genus $0$ in $\mathbb{P}^{3}_{k}$, with $k$ algebraically closed. I would like to prove that $\mathsf{hilb}_{3}^{2x+1}$ is reduced. To do that, I proceed in the following way: (1) I want to show that $\text{dim}(\mathsf{Hilb}^{2x+1}_{3})=8$; (2) I want to show that $\text{dim}\ \text{T}_{p}(\mathsf{Hilb}^{2x+1}_{3})=8$, for any closed point $p\in \mathsf{Hilb}^{2x+1}_{3}$. I cannot seem to be able to compute part (1) . I thought about simply counting the parameters of the generic quadric in $\mathbb{P}^{3}$, but it clearly doesn't work. With part (2) I made a little progress. I found on ""Curves in Projective Space"", Joe Harris, Les Presses de L'université de Montréal, 1982, the following equivalence $\qquad \qquad \qquad \qquad \qquad$ $h^{0}(C,\mathcal{N}_{C/\mathbb{P}^{3}})=h^{0}(C,\mathcal{O}(1)\oplus \mathcal{O}(2))=3+5$ I thought this could be traced back to some split exact sequence, but I don't seem to be able to find which one. I also don't understand why $h^{0}(C,\mathcal{O}(1))=3$ and $h^{0}(C,\mathcal{O}(2))=5$.","['algebraic-geometry', 'schemes', 'projective-schemes']"
663314,Analogue of Lebesgue differentiation theorem in Orlicz spaces,"It is well known that $$\lim\limits_{r\rightarrow 0}\dfrac{\|f\chi_{B(x,r)}\|_{L_{p}(\mathbb{R}^{n})}}{\|\chi_{B(x,r)}\|_{L_{p}(\mathbb{R}^{n})}}=|f(x)|$$ for almost all $x\in\mathbb{R}^{n}$. Here $\chi_{B(x,r)}$ denotes the characteristic function of the open ball $B(x,r)$. I wonder whether there is an analogue of this property in Orlicz spaces, that is, $$\lim\limits_{r\rightarrow0}\dfrac{\|f\chi_{B(x,r)}\|_{L_{\Phi}(\mathbb{R}^{n})}}{\|\chi_{B(x,r)}\|_{L_{\Phi}(\mathbb{R}^{n})}}=|f(x)| \tag{$\ast$}$$ for almost all $x\in\mathbb{R}^{n}$ ? Where $\Phi:[0,\infty)\to [0,\infty)$ is an increasing, continuous, convex function with $\Phi(0)=0$ and
$$
\|f\|_{L_{\Phi}(\mathbb{R}^{n})}:=\inf\{\lambda>0:\int_{\mathbb{R}^{n}}\Phi\left(\frac{|f(x)|}{\lambda}\right)dx\leq 1\}.
$$
It is a generalization of the $L_p$ norm. Indeed, if we take $\Phi(t)=t^p,\,1\leq p< \infty$ we get $\|f\|_{L_{\Phi}}=\|f\|_{L_{p}}$. I think we should define a maximal function such that
$$
M^{\Phi}f(x)=\sup_{r>0}\dfrac{\|f\chi_{B(x,r)}\|_{L_{\Phi}(\mathbb{R}^{n})}}{\|\chi_{B(x,r)}\|_{L_{\Phi}(\mathbb{R}^{n})}}
$$
and obtain a weak type inequality for this operator. As an application of this we get the desired equation. Unfortunately, I couldn't do any of these operations.","['measure-theory', 'functional-analysis', 'orlicz-spaces', 'analysis']"
663351,What does the $-\log[P(X)]$ term mean in the calculation of entropy?,"The entropy (self information) of a discrete random variable X is calculated as: $$
H(x)=E(-\log[P(X)])
$$ What does the $-\log[P(X)]$ mean? It seems to be something like """" the self information of each possible outcome of the random variable X "". And why do we use log function to calculate it? ADD 1 Well, below is my reasoning: The root motivation is to quantify/measure the uncertainty contained in a random variable. Intuitively , people tend to agree that there's some connection between uncertainty and probability . And still intuitively , people shall agree that: the more probability an outcome has, the less uncertainty it has. thus , the less probability an outcome has, the more uncertainty it has. So, I think if we want to measure the uncertainty for an outcome of a random variable, the measure function should satisfy: the value of uncertainty measure should be positive ( human instinct when counting ) the value of this measure for the uncertainty of an outcome should be monotonic decreasing function of the probability of that outcome. for outcomes of independent experiments, the uncertainty should be additive. That is for P(A)*P(B), the total uncertainty should be the sum of A's and B's. ( This is kind of instinctive, too. ) Then I come to the choice of -log[p(i)] as the measure of uncertainty of each possible outcome , or self-information of each outcome. Then I treat the entropy as the weighted average of the self-information of all possible outcomes. I just read the book < Information Theory, Inference and Learning Algorithms > by MacKay. The author indeed gives a similar explanation to mine. And he name it the information content of each outcome . It is not difficult to see that entropy better describes a random variable than the information content . And it is coincidental that the formula we intuitively found to measure the average information content of a random variable has a similar form to the one of entropy in thermodynamics . Thus comes the name information entropy ... BTW I want to quote some words from Einstein... ""It is not so important where one settles down. The best thing is to
follow your instincts without too much reflection."" --Einstein to Max Born, March 3, 1920. AEA 8-146 ADD 2 Following my above reasoning, I tried to derive the calculation of entropy for a continuous random variable Y in a similar way. But I was blocked . Details below. Let Y's p.d.f be: $$f(y)$$ Then, if we strictly follow my previous reasoning, then we should pick up a small interval of I , and the probability of Y within interval I is given by: $$P(y\ within\ I)=\int_If(y)dy$$ Then the measure of uncertainty for Y to fall in interval I should be: $$m(y\ within\ I) = -log\int_If(y)dy$$ Then, to get the entropy, we should get the expectation/average of this measure m , which is essentially: $$E[m(y\ within\ I)]$$ and it can be expanded as below: $$
\int{P(y\ within\ I)*m(y\ within\ I)}dI
=\int{(\int_I{f(y)dy}*{(-log\int_If(y)dy)})dI}
$$ I found myself stuck here because the interval I is not strictly defined. Then I find from here the authoritative definition of entropy of continuous random variable: $$
H(Y)=-\int{f(y)log[f(y)]dy}
$$ The p.d.f. $f(y)$ can certainly be $> 1$ , so the $H(Y)$ can be negative , while in discrete scenario, the $H(X)$ is always non-negative . I cannot explain the why this in-consistence is happening. For now, I can only consider it as a philosophical difficulty regarding continuity and discreteness . Some of my personal feeling (can be safely ignored): In the discrete scenario, the concrete countable outcome provide the foothold for us to carry out our calculation. But in the continuous
scenario, there's no such ready-made foothold (unless we can somehow
make one). Without such foothold, it feels like we just keep falling
into the endless hollowness of mind. Anyone could shed some light? ADD 3 - 4:23 PM 2/21/2022 We created mathematics to quantify the world. And here in probability we even try to quantify our mentality, while our mentality created mathematics in the first place. It's like an endless recursive fall. And it's really hard for one to settle down ...","['probability-theory', 'information-theory', 'probability']"
663391,Bareiss Algorithm,"I need to find the row Echelon form of a large, (sparse,) integer matrix. It seems that the Bareiss algorithm is a prime candidate, but I can't find any resources beyond the Wikipedia page that provide a simple explanation of the algorithm. Are there any resources/recommended books that I should look into?","['matrices', 'linear-algebra']"
663418,How is this disjunctive form found through propositional algebra,"I'm learning about disjunctive normal form and the algebra of propositions.  The text is Discrete Mathematics with Graph Theory, 3rd Edition by Goodaire and Parmenter (it wasn't highly recommended on Amazon but it is what BSU has chosen). In the examples is this implication, $p \rightarrow (q \wedge r)$ which they use to demonstrate how to show in disjunctive normal form using both truth tables and algebra.  I'm lost on the algebra.  Please help me understand where it's coming from. $
\begin{align}
[p\rightarrow (q\wedge r)] 
&\Leftrightarrow [(\neg p) \vee (q \wedge r)] \\
&\Leftrightarrow [((\neg p)\wedge q)\vee ((\neg p)\wedge (\neg q)) \vee (q \wedge r)] \\
&\Leftrightarrow [((\neg p)\wedge q \wedge r) \vee ((\neg p)\wedge q \wedge (\neg r)) \vee  \\
& \hspace{20pt}((\neg p )\wedge (\neg q) \wedge r) \vee ((\neg p) \wedge (\neg q) \wedge (\neg r)) \vee \\
& \hspace{20pt} (p \wedge q \wedge r) \vee ((\neg p)\wedge q \wedge r)] \\
&\Leftrightarrow [((\neg p)\wedge q \wedge r) \vee ((\neg p)\wedge q \wedge (\neg r)) \vee \\ & \hspace{15pt}((\neg p )\wedge (\neg q) \wedge r) \vee ((\neg p) \wedge (\neg q) \wedge (\neg r)) \vee (p \wedge q \wedge r)]
\end{align}
$ I'm fine up to the first logical equivalance.  However, on the second, I'm lost.  I'm not sure which one of the properties they've discussed was used in this algebra.  Is a distributive property being used?","['logic', 'propositional-calculus', 'discrete-mathematics']"
663442,Show that $\left\{A\subset\Omega: A~\text{ is countable or }A^C\text{ is countable}\right\}$ is a $\sigma$-algebra,"Let $\Omega$ a set and
    $$
C=\left\{A\subset\Omega: A~\text{ is countable or }A^C\text{ is countable}\right\}.
$$
    Show that $C$ is a $\sigma$-algebra and that
    $$
\sigma(\left\{\left\{ x\right\}: x\in\Omega\right\})=C.
$$ Hello! First I have to show that $C$ is a $\sigma$-algebra. Here are my results; I have some problems to finish the proof. (1) If $\Omega$ is countable, then $\Omega\in C$. If $\Omega$ is not countable, then $\Omega^C=\emptyset$ is. So in any case $\Omega\in C$. (2) Consider $A\in C$. If $A$ is countable, then $A^C$ is in $C$, because $(A^C)^C=A$ is countable then. If $A$ is not countable, it has to be by definition $A^C$ countable (otherwise $A$ could not be in $C$), so $A^C$ in $C$. (3) Consider $A_1,A_2,\ldots\in C$. First case: All $A_i, i=1,2,\ldots$ are countable. Then $\bigcup_{i\geq 1}A_i$ is countable as countable union of countable sets. So $\bigcup_{i\geq 1}A_i\in C$. Second case: All $A_i, i=1,2,\ldots$ are not countable. Then all $A_i^C, i=1,2,\ldots$ are countable and for any $i\in\left\{1,2,.\ldots\right\}$ it is
$$
\left(\bigcup_{i\geq 1}A_i\right)^C=\bigcap_{i\geq 1}A_i^C\subset A_i^C
$$
which means that $\bigcap_{i\geq 1}A_i^C$ is countable. So it follows that $\bigcup_{i\geq 1}A_i$ is in $C$, because its complement is countable. Now what is with the third case, that some $A_i$ are countable and others not? Do not know how to handle it. Overmore, I have problems to show $\supset$ of the identity that is to show. The other implikation $\subset$ follows, because $C$ is a $\sigma$-algebra (which I have not completely shown) and $\left\{\left\{ x\right\}: x\in\Omega\right\}\subset C$. So would you please help me to finish point (3) (case 3) and the implication $\supset$?","['measure-theory', 'elementary-set-theory']"
663487,Not sure about the derivative of the integral,"Call me stupid, but I would like to know whether my understanding is okay: $$\frac{d}{dx}\left(\int_0^x f(s)ds\right)=\frac{d}{dx}F(x)=f(x)$$",['calculus']
663517,Sufficient Statistic Basics,"If I know the value of a sufficient statistic, but not the sample that generated it, am I right to suspect that the conditional distribution of any other statistic given the sufficient statistic will not depend on the parameter of interest? Formally speaking: Let $\theta$ be the parameter of interest. $T(x)$ is the known sufficient statistic. Now, for any other statistic $\tilde{T}(x)$, we (would; conjecturing) have: $$
f_{\tilde{T}\mid T}(\tilde{t}\mathbb\mid\theta,t)=f_{\tilde{T}\mid T}(\tilde{t}\mid t)
$$ Thanks in advance. EDIT: just to add to my line of thought. I am thinking of the new statistic as equivalent to the sample points, since they differ just by a function. So if the if I have a sufficient statistic for the distribution, it will automatically be sufficient to any other statistic.","['statistics', 'statistical-inference']"
663518,Idempotents in a ring without unity (rng) and no zero divisors.,"Question: Given a ring without unity and with no zero-divisors, is it possible that there are idempotents other than zero? Def: $a$ is idempotent if $a^2 = a$. Originally the problem was to show that $1$ and $0$ are the only idempotents in a ring with unity and no zero-divisors, but I wonder what happens if we remove the unity condition. I am trying to find a ring with idempotents not equal to $0$ or $1$. So far my biggest struggle has been coming up with examples of rings with the given properties. Does anyone have any hints? How should I attack this problem?","['ring-theory', 'rngs', 'abstract-algebra', 'idempotents']"
663520,"Laplace transform of $g_n(t)=\begin{cases}\frac{(1-e^{-t})^n}{t^n}&:t>0,\\0&:t\le0.\end{cases}$","Find Laplace transform for this function "" $g$ "" $$g_n(t)=\begin{cases}\frac{(1-e^{-t})^n}{t^n}&:t>0,\\0&:t\le0.\end{cases}$$ Then  Take advantage of it to calculate the following integration "" $I$ "" $$I_n=\int_0^\infty\frac{(1-e^{-t})^n}{t^n}\,dt,n\geq2$$","['laplace-transform', 'fourier-analysis', 'integration', 'complex-analysis']"
663537,Is Thomas' Corkscrew completely regular? (from Counterexamples in Topology),"In Example 94 of Counterexamples in Topology . In the example itself, it is written that the space is completely regular. But in the appendix at the end of the book, it is written that the space is regular but not completely regular. Which one is correct? Thank you! 94. Thomas' Corkscrew Let $X = \bigcup_{i=0}^\infty L_i$ be the union of
  lines in the plane where $L_0 =
\{ (x,0) \mid x \in (0,1) \}$, and for $i \geq 1$,
  $L_i = \{ ( x , \frac{1}{i} \mid x \in [0,1) \}$. If $i > 0$,
  each point of $L_i$ except for $(0,\frac{1}{i})$
  is open; basis neighborhoods of
  $(0,\frac{1}{i})$ are subsets of $L_i$ with
  finite complements. Similarly,
  the sets $U_i(x,0) = \{ (x,0) \} \cup
\{ (x,\frac{1}{n}) \mid n > i \}$ form a basis for the points in $L_0$. Every basis neighborhood of $X$ is closed as well as open, so $X$ is
  zero dimensional and therefore regular since it is clearly T 1 . $X$ is also completely regular since if $C$ is a closed set and $p \notin C$, ...","['general-topology', 'examples-counterexamples']"
663539,Numerical computation of the $n^{\mathrm {th}}$ derivative of a multivariate function,"From a multivariate function $f$, depending on $n\geq 1$ variables, which can be computed numerically, but which does not admit simple analytic expression, I would like to approximate numerically the quantity:
$$ \frac{\partial^n f}{\partial x_1...\partial x_n}(x_1,...,x_n)$$
using, e.g., finite differences. Intuitively, using finite differences, I would proceed like this:
Let ($e_1,...,e_n$) be the canonical base of $\mathbb{R}^n$, and let $h\in\mathbb{R}_+^*$ be a small number. If $n = 1$ (univariate function); I would compute:
$$ \frac{\partial f}{\partial x_1}(x) \approx \frac{f(x + h e_1) - f(x - h e_1)}{2h}$$
Now, if $n = 2$ (multivariate function with 2 variables), I would compute:
$$ \frac{\partial^2 f}{\partial x_1\partial x_2}(x) \approx \frac{(f(x + h e_1 + h e_2) - f(x + h e_1 - h e_2)) - (f(x - h e_1 + h e_2) - f(x - h e_1 - h e_2))}{(2h)^2}$$
and so on for larger $n$. My problem is that this approximation involves $2^n$ terms, which is cumbersome for large $n$. Is anyone aware of a procedure / reference to obtain a good approximation without computing as much as $2^n$ evaluations of $f$ , or is this hopeless ?","['finite-differences', 'derivatives', 'numerical-methods']"
663544,Finding the Integer part of $\sum_{k=2} ^{9999}\frac{1}{\sqrt k}$,"Question from Model Question Paper for B.Math/B.Stat: Page 28, Question 27 by Indian Statistical Institute Q. Assume the following inequalities for positive k: $$\frac{1}{2\sqrt{k+1}}< \sqrt{k+1}-\sqrt k<\frac{1}{2\sqrt k}$$ The Integer part of: 
$$\sum_{k=2} ^{9999}\frac{1}{\sqrt k}$$ equals: A. $198$ B. $197$ C. $196$ D. $195$ My approach: $$S=\sum_{k=2} ^{9999}\frac{1}{\sqrt k}$$
$$S=\frac{1}{\sqrt 2}+\frac{1}{\sqrt 3}+ \cdots + \frac{1}{\sqrt{9999}}$$
$$S=2\left(\frac{1}{2\sqrt 2}+\frac{1}{2\sqrt 3}+ \cdots + \frac{1}{2\sqrt{9999}}\right)$$
$$S\approx 2\left((\sqrt 2- \sqrt 1) + (\sqrt3- \sqrt2)+\cdots +(\sqrt{9999}-\sqrt{9998})\right)$$
$$[S]\approx2(\sqrt{9999}-\sqrt1)$$
$$[S]\approx 2(98)$$
$$[S]=196$$ I know my method is not an efficient one.
Also I don't know if the answer is correct. Any help will be appreciated.","['linear-algebra', 'real-analysis', 'limits']"
663563,integral from zero to zero,it seems obvious that this integral is zero and so is the limit but what theorem we are using here? I see it's connected to Riemann sums with an interval=zero Right ? The function $\mathrm{f}$ is continuous. $$\lim_{x \to 0}\int_0^x\mathrm{f}(x)\ \mathrm{d}x= \ ?$$,"['continuity', 'integration']"
663578,"How is a ""computer variable"" defined mathematically?","Variables used in maths formulae are not the same that those of computing programs. Maths variables can be bound to a given value only once, and then keep that value. On the other hand, a programming variable is ""mutable"". It is like a box with a name, to which we can change its value over time. How can  a mutable programming variable be mathematically defined?",['abstract-algebra']
663586,"Two sequences are subsequences of one another, one converges. Are they the same?","Let $a_n$ converge to a. Let $b_n$ be a subsequence of $a_n$ and $a_n$ be a subsequence of $b_n$. Are they the same? I've tried showing they are by contradiction, the Bolzano-Weierstrass theorem seems relevant but I can't see where. I can't see any counter example but there seems to be some pattern to why examples fail but I can't see it. Removing the restriction of $a_n$ converging seems to allow for counter examples which all seem to alternate, if I could prove that they all alternate then it would be done as alternating series don't converge. Hints would be most welcome!","['convergence-divergence', 'sequences-and-series', 'real-analysis']"
663588,Prove that a group where $a^2=e$ for all $a$ is commutative [duplicate],"This question already has answers here : Prove that if $g^2=e$ for all $g$ in $G$ then $G$ is Abelian. (15 answers) Closed 10 years ago . Defining a group $(G,*)$ where $a^2=e$ with $e$ denoting the identity class.... I am to prove that this group is commutative. To begin doing that, I want to understand what exactly the power of 2 means in this context. Is the function in the group a power or something?",['abstract-algebra']
663600,Estimate length of confidence interval,"From Hogg & Tanis, 8th ed., p. 291: Let $X_1, X_1, \dots X_n$ by a random sample of size $n$ from the normal distribution $N(\mu, \sigma^2)$. Calculate the expected length of a 95% confidence interval for $\mu$, assuming that $n = 5$ and variance is (a) known, (b) unknown. For (a), I let $L = 2z_{\alpha / 2}(\sigma / \sqrt{n})$.  Since everything is constant, $E[L] = L$; just plug in all the numbers and out comes an expression in terms of $\sigma$. For (b), though, I'm not as sure.  I let $L = 2t_{\alpha / 2}(n - 1)\cdot(S / \sqrt{n}) = 2t_{0.025}(4)\cdot(S / \sqrt{5})$. Then $E[L] = \frac{5.552}{\sqrt{5}}E[S]$. By an earlier result (to which a hint for this question refers), $$E[S] = \frac{\sigma}{\sqrt{n-1}}\cdot\frac{\sqrt{2}\Gamma(n/2)}{\Gamma((n-1)/2)}$$ Plugging in all the relevant values, I get $$E[L] = \frac{4.164\sqrt{\pi}}{\sqrt{10}}\sigma$$ which looks a bit like the previous result.  The result for (a) makes sense to me because $\sigma$ is known; plug in $\sigma$ and out comes the length of the interval.  For (b), though, $\sigma$ is unknown.  So — if this is correct — how would that form of $E[L]$ be at all informative?  Can anyone offer any intuition on what's going on here?","['statistics', 'intuition']"
663610,$A(X\times Y)\cong A(X)\otimes A(Y)$,"I'm looking to understand a previous post. It was a while ago so I thought I would repost. Here is the post Tensor product of 2 coordinate rings . My questions come from the Dylan's answer. I was able to show that the map was well defined and onto. I'm stuck on the injection. If $\{f_{i}\}$ and $\{g_{j}\}$ generate $K[V]$ and $K[W]$ as a k-algebra shouldn't there be elements of this form $f_{i}^{2}\otimes g_{j}$ as well when we try to generate $k[V]\otimes k[W]$. If $\{f_{i}\}$ and $\{g_{j}\}$ generate $k[V]$ and $k[W]$ as vector spaces, then I can see why we do without the products. But we won't get a finite generating set for $k[V]$ as a vector space. Any ideas would be very much appreciated. Thanks","['algebraic-geometry', 'abstract-algebra']"
663633,Prove that $\left\lfloor \lfloor x/2\rfloor/2 \right\rfloor=\lfloor x/4\rfloor$ for all $x$. [duplicate],"This question already has answers here : Prove that $\lfloor\lfloor x/2 \rfloor / 2 \rfloor = \lfloor x/4 \rfloor$ (4 answers) Closed 10 years ago . This I approached the problem. I let $x = n + e$ where $n$ is an integer and $e$ is a decimal less than $1$ but not less than $0$. I substituted that into the equation to get $\left\lfloor \lfloor (n+e)/2\rfloor/2 \right\rfloor = \lfloor (n+e) / 4 \rfloor $ Then I will try for 4 cases. 
case 1: $0 \le x < 1/4$ case 2: $1/4 \le x < 1/2$ case 3: $1/2 \le x < 3/4$ case 4: $3/4 \le x < 1$ Am I allowed to pull the n out of $\left\lfloor \lfloor (n+e)/2\rfloor \right\rfloor$? If I can then i can simply plug in the cases into $e$, which will give me $0=0$ for all $4$ cases. Is that correct?","['fractional-part', 'algebra-precalculus', 'discrete-mathematics']"
663665,Is $(V_1\otimes\cdots\otimes V_k)^\ast \simeq V_1^\ast\otimes \cdots \otimes V_k^\ast$ true for infinite dimensional spaces?,"Suppose $V_1,\dots,V_k$ are vector spaces of finite dimension. Then I could prove easily that $(V_1\otimes\cdots\otimes V_k)^\ast\simeq V_1^\ast\otimes\cdots\otimes V_k^\ast$. My proof was like that: first of all, I've shown that if for each $i$ we have $W_i$ another vector space such that $V_i\simeq W_i$ then $V_1\otimes\cdots\otimes V_k \simeq W_1\otimes\cdots\otimes W_k$. Then, since I'm supposing each $V_i$ finite dimensional, each $V_i\simeq V_i^\ast$ and also, we have $V_1\otimes\cdots\otimes V_k$ also finite dimensional, so that $$(V_1\otimes\cdots\otimes V_k)^\ast \simeq V_1\otimes\cdots\otimes V_k\simeq V_1^\ast\otimes \cdots \otimes V_k^\ast$$ and so it is proved. Now, if the spaces are not finite dimensional this proof cannot be used. In that case, the property still holds? Is it possible to prove for infinite dimensional spaces? I've tried to prove it directly, constructing an isomorphism. I've picked first the mapping $\psi : V_1^\ast\times\cdots\times V_k^\ast \to \mathcal{L}(V_1,\dots,V_k;\mathbb{K})$ given by $$\psi(f_1,\dots,f_k)(v_1,\dots,v_k) = f_1(v_1)\cdots f_k(v_k)$$ this map is multilinear and hence by the universal property there corresponds a unique linear mapping $\phi : V_1^\ast\otimes \cdots \otimes V_k^\ast \to \mathcal{L}(V_1,\dots,V_k;\mathbb{K})$ such that: $$\phi(f_1\otimes\cdots\otimes f_k)(v_1,\dots,v_k) = f_1(v_1)\cdots f_k(v_k)$$ To show that this $\phi$ is isomorphis I would need to find an inverse, but I didn't have any idea. Is it possible to complete this proof? Thanks very much in advance.","['linear-algebra', 'multilinear-algebra']"
663678,Counting simple quadrilaterals in a rectangular lattice.,I've been trying to make an algorithm to find the number of all possible simple quadrilaterals in a N*M lattice. I already have a brute force solution but since this is a Project Euler problem I believe it should be possible to solve much faster than I'm doing and so I'm taking a math approach instead. I haven't figured out much unfortunately. I tried to go about this using binomial coefficients and failed. Now I'm trying to use Pick's theorem which pretty much ensures we are dealing with simple polygons but I am not sure how to handle overlapping quads. The reason I'm posting therefore is to see if there is any other math approach I can take. I don't want any solutions just clues on the math part since I am not that educated on these math subjects. Edit: I took a completely different approach so this has no need for me anymore. I am leaving it open for others.,"['project-euler', 'euclidean-geometry', 'group-theory', 'combinatorics']"
663697,"Set theory. Is $\varnothing \in \{1,2,3\}$ true?","Let $A = \{1, 2, 3\}$. Is the following expression true then? $\varnothing \in A$. I'm having issue understanding if the empty set is an element of $A$. Would love a brief explanation of why it is or isn't. Thanks a lot.",['elementary-set-theory']
663713,Irrational distance between a certain point and every other point with rational coordinates,"Let $A \subset \mathbb R^n $, be a Lebesgue measurable set of positive measure. Show that in $A$ there is a point such that if you consider distances from it to every point in $R^n$ whose coordinates are rational, these distances are irrational.","['measure-theory', 'lebesgue-measure']"
663716,"Inverse of function, containing a fraction","This is basic, I know, but I cannot seem to come up with the right answer. Find the inverse of the function:
$$f(x)= \frac3{x+1}$$ My steps:
1. Convert f(x) to y
$$y = \frac3{x+1}$$ Switch places of x and y
$$x= \frac3{y+1}$$ Try to solve for y. So I multiply the denominator by x to get rid of it
$$x(y+1) = 3$$ After multiplying, I'm left with
$$xy + x = 3$$ Which then converts to
$$2xy = 3$$ Then I get rid of 2x on the left, placing it on the right
$$y = 3 - 2x$$ Now I convert y to the inverse function
$$f^{-1}(x) = 3 - 2x$$ My answer is obviously wrong. The correct answer is:
$$f^{-1}(x) = \frac{3-x}{x}$$ Where did I mess up? Thanks!","['inverse', 'algebra-precalculus', 'functions']"
663739,Unitary Operator bounded?,"Please read all before giving an answer... Suppose you're given a densely defined not necessarily bounded operator: $\overline{\mathcal{D}(T)}=\mathcal{H}$ Moreover, assume it is injective: $\mathcal{N}(T)=\{0\}$ Now, imagine it has the property: $T^*Tx=x,x\in\mathcal{D}(T^*T)$ My point is now, it might happen that: $\mathcal{D}(T^*)=\{0\}$ So in this case the above equation seems trivially true as: $\mathcal{D}(T^*T)=\mathcal{N}(T)=\{0\}$ It is not clear to me wether this situation in particular can occur, but is it possible that sth. seemingly similar can happen, so that the above property does not apply preservation of the scalar product? ...clearly, such an operator must be unbounded otherwise one could extend the domain to all of the Hilbert Space, the adjoint would then be defined everywhere as well and in return the property above would imply preservation of the scalar oroduct by construction...","['adjoint-operators', 'functional-analysis']"
663744,find $P\{P\{0\}\}$. $P$ represents the power set.,"I'm assuming that I'm trying to find the power set of a power set? I start from the inner power set, $P\{0\}$. $P\{0\}= \{ 0, \{0\} \}$. Now I do $P\{ 0, \{0\} \}$ which is $\{ 0, \{0\}, \{\{0\}\} \}$. 0 is the empty set. Is this correct? So I'm taking it that P{0}={0, {0}, {0, {0}} }","['discrete-mathematics', 'elementary-set-theory']"
663761,Does first isomorphism theorem hold in the category of normed linear spaces?,"Consider the category of normed linear spaces over $\mathbb{C}$ with bounded linear maps as morphisms. If $M\subset X$ is a subspace, then the quotient space $X/M$ has a map $\|x+M\|: = \inf_{y\in M}\|x-y\|_X$, which is a norm iff $M$ is closed in $X$ under the topology induced by the norm of $X$. Let $f:L\to M$ be bounded linear map between two normed linear spaces, it is easy to check that $\ker f$ is indeed closed, thus $L/\ker f$ is a normed linear space itself. Is it true that
$$L/\ker f\cong f(L)$$
i.e. there exist invertible bounded linear map whose inverse is also bounded? I checked that the canonical vector space isomorphism $L/\ker f \to f(L)$ is indeed bounded, but I have trouble showing that the inverse is bounded, or equivalently, continuous. In other words, I want to show that 
$$\forall \epsilon>0. \exists \delta>0. \|f(l)-f(m)\|<\delta \Longrightarrow \|(l+\ker f)-(m+\ker f)\|<\epsilon$$
Is it true or is there a counterexample? If the statement is true, then what about the stronger statement: If $f:L\to M$ is an ismorphism of linear spaces that is bounded, then $f^{-1}$ is also bounded.","['category-theory', 'linear-algebra', 'abstract-algebra']"
663764,What is a limit point,"Wikipedia seems to describe the topic with extreme complexity for me. In mathematics, a limit point of a set $S$ in a topological space $X$ is a
  point $x$ (which is in $X$, but not necessarily in $S$) that can be
  ""approximated"" by points of $S$ in the sense that every neighbourhood of
  $x$ with respect to the topology on $X$ also contains a point of $S$ other
  than $x$ itself. Note that $x$ does not have to be an element of $S$. I don't understand the relationship between $S$ and $X$ and what it means for $x$ to be a limit point.","['general-topology', 'real-analysis', 'analysis']"
663799,"Is it possible to be ""too good"" at Spider Solitaire?","There was a similar question here: Losing at Spider Solitaire However, what I'm asking is different. The game has a rule that it would not deal the next ten cards, unless there is already a card in everyone of the ten slots. What I'm asking is whether it is theoretically possible that at any time, except the last deal, there might be a situation with less then 10 cards on the table? To me it feels like it should be possible, but it never happened to me, and I couldn't find any mention of it happening to anyone else...","['card-games', 'probability', 'combinatorics']"
663834,Is the convolution of a function $f(x)$ and a polynomial $p(x)$ always a polynomial?,"After reading the following question: How do I prove a convolution is a polynomial? I want to ask if that is always the expected result, that is to say, does the following holds? A convolution of a function $f(x)$ and a polynomial $p(x)$ will always
  result in a polynomial Is that true? If so, how to prove that? if not, can you give a counterexample? If the answer depends on the properties of $f(x)$, continuity, differentiability, or anything else, please describe the required properties. For example, I've easily proved that if $f(x)$ is like:
$$f(x)=u(x)\,\mathrm{e}^{-x}\,q(x)$$
where $u(x)$ is the unit step function and $q(x)$ is any polynomial, then the convolution of $f(x)$ with $p(x)$ will be a polynomial with the same degree of $p(x)$.","['definite-integrals', 'polynomials', 'convolution', 'analysis']"
663837,"For a system of PDEs, how many equations are needed generally for the system to have unique solution?","For an algebraic system of equations or a system of ordinary differential equations the following rule holds:(right?) the total number of unknown variables must be equal to the number of equations (and also the same number of boundary conditions are needed, but that's not my question) Is it generally correct for a system of PDEs too? I asked this specific question on physics.SE, where one of the users presented the following example in comments saing that it is not the case for a system of PDEs :
$$\partial_x f=0 \,\,\,\,\,\partial_y f=0  \,\,\,\,\text{(two equations)}$$
$$\to f(x,y)=0 \,\,\,\text{(unique solution)}$$
(I've seen this question (without answer), which asks about number of needed boundary conditions; my question is about the number of independent equations needed)","['partial-differential-equations', 'systems-of-equations', 'real-analysis']"
663875,Proof that every number can be represented as the sum of two squares and a pronic,"Does anyone know of a proof that every positive integer can be represented as $a^2+b^2+ c^2 + c$ where $a$,$b$ and $c$ are nonnegative integers? I believe that Goldbach asserted this, along with other ways of representing any number, but I can't find a proof.",['number-theory']
663886,Deriving statistical distributions from games,"The normal distribution can be derived from basic principles and calculus The Normal Distribution: A derivation from basic principles .  Are there other distributions that can be derived like this from naturally occurring processes like those found in simple games? Like any sort of familiar games specifically such as backgammon, billiards, cards, checkers, or chess to name a few.","['stochastic-processes', 'game-theory', 'calculus', 'statistics', 'probability-distributions']"
663905,Smooth paths and homotopies,"In applications of the fundamental group(oid) to smooth manifolds it is sometimes useful to have paths which are smooth, rather than merely continuous. For example, if we consider the local system of solutions of some linear partial differential equation, we can pull it back along a path, where it can be viewed as the solutions of an ordinary differential equation. The ""nicer"" the path is, the ""nicer"" will be the coefficients of the resulting ordinary differential equation. It seems impossible to simply define this issue away by only allowing smooth paths in the first place, since a concatenation of smooth paths need not be smooth. Another possible problem: if we want to also restrict to smooth homotopies, we have to figure out what this means at the corners of the square. Here's a couple of specific questions, since the previous paragraphs are so vague. Does every homotopy class of paths have a smooth representative? If two smooth paths are homotopic, can the homotopy be chosen to be smooth? How does one deal with the corners of the square? I imagine that the answers to these questions are written down somewhere.","['ordinary-differential-equations', 'reference-request', 'fundamental-groups']"
663915,Basis with small $\ell_{\infty}$ norm for Subspace,"At a high level, I'm interested in finding an orthonormal basis for a $d$-dimensional subspace $U \subset \mathbb{R}^n$ with small entry-wise $\ell_{\infty}$ norm. In particular, suppose $v_1, \ldots, v_d$ are the orthonormal basis vectors for $U$.
Let me also write $x_i = (v_{1i}, \ldots, v_{di})^\intercal \in \mathbb{R}^d$ for $i \in \{1, \ldots, n\}$ (i.e. $x_i$ is the $i$th row of the matrix with basis vectors as columns).
Then I would like to prove that: $
\max_i ||x_i||^2 \le \sum_{j=1}^d ||v_j||_{\infty}^2 \le \max_i ||x_i||^2 O(\textrm{polylog(d)})
$ The first inequality is true regardless of the choice of basis. The second inequality is not true for all orthonormal bases. So can one construct an orthonormal basis $\{v_i\}$ for $U$ such that the above inequality holds?","['matrices', 'linear-algebra']"
663919,Proving that $\sigma_7(n) = \sigma_3(n) + 120 \sum_{m=1}^{n-1} \sigma_3(m)\sigma_3(n-m)$ without using modular forms?,"This problem appears as a (starred!) exercise in D. Zagier's notes on modular forms. I have to admit that I have no idea how to do it. Here,  $\sigma_k(n) =\sum_{d\mid n} d^k$, as usual. This identity is traditionally obtained by using the fact that the space $M_8(\text{SL}_2(\mathbf Z))$ of modular forms of weight $8$ and level $1$ is $1$-dimensional, and contains both $E_4^2$ and $E_8$ ($E_k$ the Eisenstein series of weight $k$). Using this, it's a piece of cake (simply a matter of comparing coefficients). Without using modular forms, though, I am stumped.","['divisor-sum', 'elementary-number-theory', 'modular-forms', 'number-theory']"
663920,Geometric Interpretation of Laplace's Equation,"Let $f: \mathbb{C} \rightarrow \mathbb{C}$ be analytic.  In the natural way, let $f = u + vi$ for $u,v : \mathbb{C} \rightarrow  \mathbb{R}$.  Let $z \in \mathbb{C}$. Suppose that $u$ and $v$ satisfy Laplace's equation at $z$ (which they do since $f$ is analytic) so that $$
\Delta u = \frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = 0
$$ and $$
\Delta v = \frac{\partial^2 v}{\partial x^2} + \frac{\partial^2 v}{\partial y^2} = 0
$$ Question 1: Does this mean that the real and complex parts of $f''(z)$ are equal to each other in magnitude? EDIT: This is why I think that the Laplace Equations holding for $u$ and $v$ implies that $f''(z)$ has real and complex components which are equal in magnitude to each other. Since $f$ is analytic, we have that the Cauchy-Riemann Equations hold for $u$ and $v$.  In particular, we have that $$
\frac{\partial u}{\partial x} = \frac{\partial v }{\partial y}
$$ and $$
\frac{\partial v}{\partial x} = - \frac{\partial u}{\partial y}
$$ This then means that $f'(z) = \frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x} = \frac{\partial u}{\partial x} - i \frac{\partial u}{\partial y}$. Then $\color{red}{f''(z) = \frac{\partial^2 u}{\partial x^2} - i \frac{\partial^2 u}{\partial y^2}}$. Yet since $\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = 0$ via Laplace, we have that $f''(z)$ satisfies that its real and complex parts are equal in magnitude to each other. Is this correct? Question 2: If no to the above answer, what is a geometric interpretation of this statement?","['harmonic-functions', 'complex-analysis', 'analysis']"
663929,In how many ways can one distribute ten distinct pizzas among four students with exactly two students getting nothing?,"In how many ways can one distribute ten distinct pizzas among four students with exactly two students getting nothing? How many ways have at least two students getting nothing? For the first part I tried to solve it as $$x1+x2 = 10 \text{, } xi \ge 1$$
Which would give
$$ x1+x2 = 8, \text{ } xi  \ge0$$ Then I computed
$$9\choose 8$$ multiplied by 6. Why is this wrong?
I seen the answer and they are doing something alone the lines of $$
(2^{10} - 2) * 6$$ This relationship is not clear to me, can anyone explain?","['discrete-mathematics', 'inclusion-exclusion', 'combinations', 'probability', 'combinatorics']"
663934,Show that the sequence $\Omega^0\Bbb{R}^2\ \longrightarrow\ \Omega^1\Bbb{R}^2\ \longrightarrow\ \Omega^2\Bbb{R}^2$ is exact.,"I have been posed the following question, which I am unable to answer: Let $a_1,a_2\in\mathcal{C}^{\infty}(\Bbb{R}^2,\Bbb{R})$ be infinitely differentiable functions such that $\frac{\partial a_1}{\partial x_2}=\frac{\partial a_2}{\partial x_1}$, and define
  $$f(x,y):=x_1\cdot\int_0^1a_1(tx_1,tx_2)\ dt+x_2\cdot\int_0^1a_2(tx_1,tx_2)\ dt.$$
  Show that $\tfrac{\partial f}{\partial x_i}=a_i$ for $i\in\{1,2\}$. Unfortunately I lack even the most basic knowledge of calculus. Here's my attempt at a solution: First by linearity of differentiation and second by the product rule and then cleaning up we find
\begin{align*}
\frac{\partial f}{\partial x_1}(x_1,x_2)
&=\frac{\partial}{\partial x_1}\left(x_1\cdot\int_0^1a_1(tx_1,tx_2)\ dt\right)+\frac{\partial}{\partial x_1}\left(x_2\cdot\int_0^1a_2(tx_1,tx_2)\ dt\right)\\
&=x_1\cdot\frac{\partial}{\partial x_1}\left(\int_0^1a_1(tx_1,tx_2)\ dt\right)+\int_0^1a_1(tx_1,tx_2)\ dt\cdot\frac{\partial x_1}{\partial x_1}\\
&\hspace{10pt}+x_2\cdot\frac{\partial}{\partial x_1}\left(\int_0^1a_2(tx_1,tx_2)\ dt\right)+\int_0^1a_2(tx_1,tx_2)\ dt\cdot\frac{\partial x_2}{\partial x_1}\\
&=\int_0^1a_1(tx_1,tx_2)\ dt+x_1\cdot\frac{\partial}{\partial x_1}\int_0^1a_1(tx_1,tx_2)\ dt+x_2\cdot\frac{\partial}{\partial x_1}\int_0^1a_2(tx_1,tx_2)\ dt.
\end{align*}
Now changing the order of integration and differentiation, which is allowed for whatever reason, and subsequently applying the chain rule and substituting $\frac{\partial a_1}{\partial x_2}=\frac{\partial a_2}{\partial x_1}$ we find that
\begin{align*}
\frac{\partial f}{\partial x_1}(x_1,x_2)
&=\int_0^1a_1(tx_1,tx_2)\ dt+x_1\cdot\int_0^1\frac{\partial a_1(tx_1,tx_2)}{\partial x_1}\ dt+x_2\cdot\int_0^1\frac{\partial a_2(tx_1,tx_2)}{\partial x_1}\ dt\\
&=\int_0^1a_1(tx_1,tx_2)\ dt+x_1\cdot\int_0^1\frac{\partial a_1}{\partial x_1}(tx_1,tx_2)\cdot t\ dt+x_2\cdot\int_0^1\frac{\partial a_2}{\partial x_1}(tx_1,tx_2)\cdot t\ dt\\
&=\int_0^1a_1(tx_1,tx_2)\ dt+x_1\cdot\int_0^1\frac{\partial a_1}{\partial x_1}(tx_1,tx_2)\cdot t\ dt+x_2\cdot\int_0^1\frac{\partial a_1}{\partial x_2}(tx_1,tx_2)\cdot t\ dt.
\end{align*}
These integrals look good for integration by parts with respect to $t$ and $\tfrac{\partial a_i}{\partial x_1}(tx_1,tx_2)$, which yields
\begin{align*}
\frac{\partial f}{\partial x_1}(x_1,x_2)
&=\int_0^1a_1(tx_1,tx_2)\ dt+x_1\cdot\left(\left[t\cdot\int\frac{\partial a_1}{\partial x_1}(tx_1,tx_2)\ dt\right]_0^1-\int_0^1\int\frac{\partial a_1}{\partial x_1}(tx_1,tx_2)\ dt\ dt\right)\\
&\hspace{10pt}+x_2\cdot\left(\left[t\cdot\int\frac{\partial a_2}{\partial x_1}(tx_1,tx_2)\ dt\right]_0^1-\int_0^1\int\frac{\partial a_2}{\partial x_1}(tx_1,tx_2)\ dt\ dt\right).\\
\end{align*}
This is where my bright ideas end; I've juggled the terms around a bit but I see no way of evaluating any of these expressions. Any help would be much appreciated.","['multivariable-calculus', 'integration', 'vector-analysis', 'partial-derivative', 'exact-sequence']"
663980,Does closed immersion induce surjection of global section,"Let $X$ be a projective scheme and $Y \subset X$ be a projective subscheme. Assume $X, Y$ are connected. Denote by $i:Y \hookrightarrow X$ the closed immersion. Is it always true that the induced morphism $H^0(\mathcal{O}_X) \to H^0(i_*\mathcal{O}_Y)$ surjective?","['algebraic-geometry', 'sheaf-cohomology']"
664036,How am I counting the possibilities incorrectly in this combinatorics problem?,"I've been working through some problems in Statistical Inference Second Edition (George Casella, Roger L. Berger), one of which is this already discussed problem . While the answer given makes sense, I'm having trouble understanding why the same probability can't be arrived at by calculating possible $\mathit{unordered}$ outcomes of calls mapped to days. Question restated: ""My telephone rings 12 times each week, the calls being randomly distributed among the 7 days. What is the probability that I get a least one call each day?"" While I am not interested in the answer, as it is already given, I am interested in why the following alternative approach doesn't work. What am I incorrect in assuming? Number of possible ways the 12 indistinguishable calls could be arranged among 7 days: $$\text{unordered with replacement} \Rightarrow \binom{7 + 12 - 1}{12} = \binom{18}{12}$$ To find the number of ways 12 calls could be spread among 7 days with at least one call per day, we first assign 1 call to each day. Next, the 5 remaining calls must be placed in some combination among the 7 days. $$\text{again, unordered with replacement} \Rightarrow \binom{7 + 5 - 1}{5} = \binom{11}{5}$$ My thinking was then, having determined the total number of call-day combinations, as well as the total number of combinations with at least one call per day, the probability that each day had one call was trivially $\dots$ $$P(\text{one call per day}) = \frac{\binom{11}{5}}{\binom{18}{12}} = \frac{11}{442} \not\approx 0.2285$$ Where am I going wrong?","['probability', 'combinatorics']"
664084,The dimension of the real continuous functions as a vector space over $\mathbb{R}$ is not countable?,"This question is out of curiosity. I first attempted a web crawl for this answer but was befuddled when Google didn't turn up the result after a couple of tries. If anyone has a reference, I'd be appreciative. The ultimate thing I want to know is whether or not $C(\mathbb{R},\mathbb{R})$ has countably-infinite dimension over $\mathbb{R}$. However, I have an inkling that $C([a,b],\mathbb{R})$ itself does not have countably-infinite dimension. I attempted to show that if $\{f_n\}_{n=1}^\infty$ is a purported basis for $C([a,b])$ then $\sum_{n=1}^\infty 2^{-n}f_n$ is not in their span, but I quickly found out that I don't know how quickly any of these $f_n$ increase. I would like a constructive proof if one can be given; however, I would begrudgingly accept an existence proof. I don't mind if you feel the need to add a metric or topologize the space in any way.","['general-topology', 'functional-analysis', 'real-analysis', 'analysis']"
664088,Coercivity of bilinear form,"I want to show that there is a unique solution for 
$$-u''=f$$
with boundary condition
$$-u'(0)+u(0)=u'(1)=0$$
so I define bilinear form
$$a(v,w) = \int\limits_0^1 {v'} w'dx + v(0)w(0)$$
so I should show that this bilinear form is coercive.
then I should show that
$$a(v,v)\ge\alpha \|v\|^2_1$$","['bilinear-form', 'functional-analysis', 'partial-differential-equations']"
664092,Proving that $a$ is eigenvalue of $p(T)$ iff $a=p(\lambda)$ for eigenvalue $\lambda$ of $T$,"The solution is below, I just do not understand why if: $p(T)-aI$ is not injective, then $T-\lambda_jI$ is not injective for some j either. Also, what does repeatedly applying T to both sides accomplish? Thanks!",['linear-algebra']
664099,$L$-functions of elliptic curves over $\mathbb{Q}$,"How to find out the $P_{v}(E/\mathbb{Q},X)$ theoretically given below in the definition of $L$-functions for elliptic curves over $\mathbb{Q}$ $?$ Please cite some references for the same. For an elliptic curve $E$ over a number field $\mathbb{Q}$, the $L$-function $L(E/\mathbb{Q},s)$ is given by the Euler product $$ L(E/\mathbb{Q},s)=\prod_{v}L_{v}(E/\mathbb{Q},s)=\prod_{v}P_{v}(E/\mathbb{Q},v^{-s})^{-1},  $$ where $v$ runs over primes of $\mathbb{Q}$ and the polynomials $ P_v(E/\mathbb{Q},T) $ depending on the reduction type of $E$ over $ \mathbb{Q}_{p} $ are given explicitly by: $$    P_{v}(E/\mathbb{Q},X) =
                 \begin{cases}
              1-a_{v}X+vX^{2}, & \text{good reduction} \\
              1-X,       & \text{split multiplicative reduction} \\
              1+X,       & \text{non-split multiplicative reduction} \\
              1,      & \text{additive reduction} 
                 \end{cases}
 $$ where $ a_{v}= v+1- \mid\widetilde{E}(\mathbb{F}_{v})\mid$ and $\sim$ is reduction of $E$ at $v$.","['l-functions', 'elliptic-curves', 'number-theory']"
664113,count the ways to fill a $4\times n$ board with dominoes,"After solving this problem from SPOJ (count the ways to fill a 4xn board with 2x1 dominoes) I found a different solution while searching on internet. This solution uses the recurrence relation $f(n) = f(n-1)+5f(n-2)+f(n-3)-f(n-4)$ where $f(n)$ denotes the number of ways to fill the $4\times n$ board with $2 \times 1$ dominoes. I don't fully understand how someone gets that kind of relation (I don't know almost anything of combinatorics or recurrence relations) but I think I understand something. The $f(n-1)$ term comes from observing that there is an unique way to fill the last column and the $5f(n-2)$ term comes from observing there are 5 different ways to fill the last two columns. But i don't get where the terms $f(n-3)-f(n-4)$ come from. So I have two questions, the first one is where these terms come from and second I'd like to ask you for a reference to learn combinatorics and recurrence relations. May you help me? Thanks in advance. -edit- For my solution I used a binary number to represent what configurations of the i-th column was valid. For example 1001 represent that rows 1 and 4 are blocked in the i-th row because in the (i-1)th there is an horizontal domino in that positions. I calculated all the valid transitions such binary numbers could go to (I did this by hand for all the binary numbers from 0000 to 1111). Then I got a function which I programmed using dynamic programming and a technique called bitmask to represent the binary numbers as integers. The function is: $f(i,mask) = \begin{cases} 0 &\mbox{if } i = n, mask \neq 0 \\
1 & \mbox{if } i = n, mask = 0. \\
\sum f(i+1,mask') &\mbox{else} \end{cases}$ Where mask' is taken from the set of all valid masks from where mask could transition to, also i=n means the first column outside the board as I considered 0-indexing. The code for that is here (this is not actually mine, it's from a mate but it's the exactly same idea).",['combinatorics']
664117,Field Extensions and their dimensions,There is a powerful theorem with respect to a field $F$ extensions and their dimensions. $F<E<K \ \Rightarrow [K:F] = [K:E][E:F] $ This is analogous to the famous Lagrange's theorem with respect to groups. Is there any relationship between these two theorems.,"['category-theory', 'group-theory', 'abstract-algebra', 'field-theory']"
664133,"Discrete Math, Difference between $\mathbb Z$ and $\mathbb R$ notation","This may sounds stupid, but in the text book, they ask me a question that is something like this Define $f:\mathbb{R} \to \mathbb{R}$ by $f(x)= 3x + 2$ and $h: \mathbb{Z} \to \mathbb{Z}$ by $h(n) = 3n+2$. a) Is f surjective? Prove or give a counter example
b) Is h surjective? Prove or give a counter example I am not sure what is the difference between the notation of these two. I mean I know $\mathbb{R}$ means Real number and $\mathbb{Z}$ means integers. But aren't they just the same answer? Thanks",['discrete-mathematics']
664138,How Prove that $f$ is unique,"Assume that there exsits a smooth positive function $f$ on $(0,1)$ satisfying the differential equation
$$-f''-\dfrac{f'}{r}+\dfrac{f}{r^2}=f(1-f^2)$$
together with with boundary conditions $f(0)=0$ and $f(1)=1$. Prove that $f$ is
unique. the book give follow solution:Let $f_{1}$ and $f_{2}$ be two positive functions
  satisfying the hypotheses. Dividing the differential equation by $f$ and subtracting
  the corresponding equations, we obtain 
  $$-f''_{1}-\dfrac{f'_{1}}{r}+\dfrac{f_{1}}{r^2}=f_{1}(1-f^2_{1})$$
  $$-f''_{2}-\dfrac{f'_{2}}{r}+\dfrac{f_{2}}{r^2}=f_{2}(1-f^2_{2})$$
  $$\Longrightarrow -\dfrac{f''_{1}}{f_{1}}+\dfrac{f''_{2}}{f_{2}}-\dfrac{1}{r}\left(\dfrac{f'_{1}}{f_{1}}-\dfrac{f'_{2}}{f_{2}}\right)=-(f^2_{1}-f^2_{2})\tag 1$$ Multiplying the above equality by $r(f^2_{1}-f^2_{2})$ and integrating over $(0,1)$ yields
$$\int_{0}^{1}\left(f'_{1}-\dfrac{f_{2}}{f_{1}}f'_{2}\right)^2rdr+\int_{0}^{1}\left(f'_{2}-\dfrac{f_{1}}{f_{2}}f'_{1}\right)^2rdr=-\int_{0}^{1}(f^2_{1}-f^2_{2})^2rdr\tag2$$
Therefore $f_{1}=f_{2}$ My Question: $(1)\Longrightarrow (2)$,I can't understand How get it? Thank you because when $(1)$ multiplying $r(f^2_{1}-f^2_{2})$ and integrating over $(0,1)$ then
$$\int_{0}^{1}(f^2_{1}-f^2_{2})\left(-\dfrac{f''_{1}}{f_{1}}+\dfrac{f''_{2}}{f_{2}}\right)rdr-\int_{0}^{1}(f^2_{1}-f^2_{2})\left((\dfrac{f'_{1}}{f_{1}}-\dfrac{f'_{2}}{f_{2}}\right)dr=-\int_{0}^{1}(f^2_{1}-f^2_{2})^2rdr$$
so we only prove this
$$\int_{0}^{1}(f^2_{1}-f^2_{2})\left(-\dfrac{f''_{1}}{f_{1}}+\dfrac{f''_{2}}{f_{2}}\right)rdr-\int_{0}^{1}(f^2_{1}-f^2_{2})\left((\dfrac{f'_{1}}{f_{1}}-\dfrac{f'_{2}}{f_{2}}\right)dr=\int_{0}^{1}\left(f'_{1}-\dfrac{f_{2}}{f_{1}}f'_{2}\right)^2rdr+\int_{0}^{1}\left(f'_{2}-\dfrac{f_{1}}{f_{2}}f'_{1}\right)^2rdr$$ maybe use integration by parts ? But I can't.Thank you",['ordinary-differential-equations']
664152,Open sets are $\mu*$-measurable in a metric space with a given condition,"I have a homework problem that I'm very stuck on.  The problem statement is as follows: ""Suppose that $X$ is a metric space, and that for any sets $E,F \subseteq X$, if dist$(E,F) > 0$ then $\mu^*(E \cup F) = \mu^*(E) + \mu^*(F)$.  Prove that every open set is a splitting set.  (Recall that the distance between subsets $E$ and $F$ of a metric space is defined to be dist$(E,F) = \inf \{ d(x,y) : x \in E, y \in F \}$.)"" Our professor defines a ""splitting set"" as follows: Let $\mu^*$ be an outer measure on a nonempty set $X$.  A set $A \subseteq X$ is called a splitting set if, for all $E \subseteq X$, $\mu^*(E) = \mu^*(E \cap A) + \mu^*(E \cap A^c)$, where $A^c = X \backslash A$.  (This is what Folland's Real Analysis calls a $\mu^*$-measurable set.) Here are a couple of my (failed) attempts: My first try was to let $U$ be an arbitrary open set in $X$, let $G \subseteq X$ be arbitrary, and define $E = G \cap U$, $F = G \cap U^c$.  If I could somehow show that dist$(E,F) > 0$ in this case, then the result would follow, but in general, this is not true (take $\mathbb{R}$ with the standard metric, let $G = [0,1]$, $U = (-1/2,1/2)$). My next attempt was by contradiction: suppose there is an open set $U$ such that $U$ is not a splitting set.  Then there is some $E \subseteq X$ such that $\mu^*(E) \neq \mu^*(E \cap U) + \mu^*(E \cap U^c)$...  and by monotonicity this means that $\mu^*(E) < \mu^*(E \cap U) + \mu^*(E \cap U^c)$.  But then I only have one set to work with, and with the assumptions, I need two sets $E,F$ to work with in order to get anywhere. I also tried exploring what I could do with closed sets, since if dist$(E,F) > 0$,  then the closures of $E$ and $F$ respectively are disjoint.  But I'm still stuck.  Any hints would be appreciated!!!  Thanks in advance.","['measure-theory', 'metric-spaces', 'real-analysis']"
664162,Purely combinatorial proof and simplification of identity involving factorials and summations,"While trying to decompose factorials into summations, I came up with the following identity
$$(n+2)! = 2^{n+1} + \sum\limits_{k=0}^{n-1}\sum\limits_{i=0}^{n-1-k}\sum\limits_{S \subseteq [2,\ldots,n+1-i]\text{ where }|S|=k}^{}2^{i+1}\prod\limits_{t \in S}^{}t$$ I'm looking for a purely combinatorial proof of the identity and a way to get rid of the product term (if possible) without using extremely large number of summations. This is the way I derived the identity (for some background): The identity can be shown by defining some function $f(i,j)$ as follows $$f(i,j)=\sum\limits_{S \subseteq [2,\ldots,i+1] \text{ where }|S|=j}^{}\prod\limits_{t \in S}^{}t$$
(assume $f(i,0)=1$) and noticing that $(n+2)! = f(n+1,n+1)$ follows the following recurrence $$f(n+1,n+1)=2(f(n,0)+f(n,1)+f(n,2)+\cdots+f(n,n))$$ obtained from Vieta's formulas i.e. an expansion of $g(x)=(2+x)(3+x)(4+x)\cdots(n+1+x)$ Then applying this recurrence on $f(i,i)$ recurrently in the above recurrence we get $$f(n+1,n+1)=2^{n+1} + \sum\limits_{k=0}^{n-1}\sum\limits_{i=0}^{n-1-k}2^{i+1}f(n-i,k)$$ and substituting $f(n-i,k)$ yields the desired identity. Also, note that by fiddling with the recurrence in a different way (making it telescope), one can show that $$(n+2)!=2\sum\limits_{k=0}^{n-1}\sum\limits_{i=0}^{n-1-k}f(n-i,k) + \sum\limits_{j=0}^{n+1}j!$$ But I don't immediately see how this will be helpful.","['factorial', 'recurrence-relations', 'combinatorics']"
664193,Sum of infinitely many i.i.d. random variables is infinite with probability 1,"How do I solve this? I'm really confused. If $X_1,X_2,\ldots$ are non-negative independently and identically distributed random variables with $P(X_i>0)>0$, show that $\displaystyle P\left(\sum_{i=1}^\infty X_i=\infty\right)=1$.","['probability-theory', 'law-of-large-numbers', 'measure-theory']"
664199,"Maximal gaps in prime factorizations (""wheel factorization"")","A wheel factorization is when you remove all the multiples of primes (up to a prime number P) from the product of all primes up to and including P. Examples: For P=5, you remove all the multiples of 2,3 and 5 from 1 to 2x3x5=30 You are then left with the set {1, 7, 11, 13, 17, 19, 23, 29} For P=7, you would remove all the multiples of 2,3,5,7 from 1 to 2x3x5x7=210 You are then left with the set {1, 11, 13, 17, ......... 199, 209} etc. (Just for the record, I am aware this does NOT generate a set of prime numbers, e.g. 209 = 11x19) My question is, for a certain P, what is the maximum gap / difference between successive elements of the set and how do I go about proving it? When P=3 with the set {1, 5}, the maximum gap is 4 When P=5 with the set {1, 7, 11, 13, 17, 19, 23, 29}, the maximum gap is 6 When P=7 with the set {1, 11, 13, 17, .... 199, 209}, the maximum gap is 10 When P=11, the maximum gap is 14 I am currently putting together a program to calculate maximum gaps for higher values of P. Once I am confident of a pattern, how could I go about proving this (maximum gaps)? I have no idea where to even begin! Thanks.",['number-theory']
664206,Matrix $A=B+C$ with $B$ symmetric and $C$ antisymmetric,"I am stumped on a question and am looking for some guidance on how to get it done. The problem gives you: $x_1 = \begin{bmatrix}9&-4&-2 \\-9&6&-3 \\10&-3&9\end{bmatrix}$ $x_1 = x_2 + x_3$. $x_2$ is a symmetric matrix and $x_3$ is an antisymmetric matrix. That is that part that confuses me. The only thing Ive gotten is that the $x_2$ has the $9,6,9$ on the diagonal and $x_3$ has $0$ for its diagonal. Can anyone help me down the right path. Thanks","['matrices', 'symmetry', 'linear-algebra']"
664212,Finding the derivative of a definite integral,"$$
G(x)=\int_1^{x^2}(x-t)\sin^2(t)dt 
$$ Find $
G'(x)
$ given $G(x)$. Normally I can solve these types of problems, but I'm thrown off by the two variables present, both $x$ and $t$ under the integral.","['calculus', 'integration', 'derivatives']"
664213,What is the probability that a randomly selected positive integer between 1 and 100 (inclusive) is square-free?,"What is the probability that a randomly selected positive integer between $1$ and $100$ (inclusive) is square-free (i.e., has no square factor; for instance $15 = 3 \cdot 5$ is square-free, but $90$ is not, since it has a factor of $3^2$). I have no idea how to solve this problem. Any help on how to proceed?",['probability']
664224,"$\forall x \in \mathbb{R}$, there exits $\delta$ such that $(x-\delta,x+\delta) \cap A$ is countable. Prove that $A$ is countable.","As stated in the title. At the first glance I think the approach can be constructing an injection from $A$ to $\mathbb Q$, since obviously $\mathbb Q$ is a set that satisfies such condition. However I have no idea on how to get such injection. Any hints would be appreciated.",['real-analysis']
664249,Bijective function proof in $R\times R$ and $Z\times N$,"How can I verify if these functions are bijective? $ f_4:\Bbb{R^2} \rightarrow \Bbb{R^2}, \ (x,\ y)\mapsto (x+y,\ x-y)$ $ f_5:\Bbb{Z} \times \Bbb{N^*} \rightarrow \Bbb Q, \ (p,\ q)\mapsto p + \cfrac{1}{q} \ $ I'm stuck, so any tip will be helpful Thanks in advance","['discrete-mathematics', 'elementary-set-theory', 'functions']"
664293,Would the transformation of a differential equation obey the same algebra?,"I've found that the algebra of this differential equation $$\frac{d^2y}{dz^2}-(3z^2+\gamma)\frac{dy}{dz}+(cz+\alpha)y=0$$ is in $sl(2)$ because it is possible to use the generators of the $sl(2)$ group
$$J^+ =z\frac{d}{dz}-2jz, \quad J^0=z\frac{d}{dz}-j, \quad J^-=\frac{d}{dz}$$ to recover the aforementioned differential equation, if write it as the following combination I get the operator (note:$j$ represents the spin of a particle, and $\gamma, c$ and $\alpha$ $\in \mathbb{R}$): $$a_{--}J^-J^- + b_{-}J^-+b_{+}J^+ = a_{--}\frac{d^2}{dz^2}+(b_{+}z^2+b_-)\frac{d}{dz}-b_+jz$$ where $a_{--},b_+, b_- \in \mathbb{R}$. I was wondering if I made a transformation of the original differential equation say, $y(z) = h(z)$  would be true to say that this differential equation also follows this algebra as well??","['ordinary-differential-equations', 'lie-algebras', 'group-theory', 'lie-groups', 'functional-analysis']"
664298,"How to find the integral $\int_{0}^{\infty}\exp(- (ax+b/x))\,dx$?","How do I find 
$$\large\int_{0}^{\infty}e^{-\left(ax+\frac{b}{x}\right)}dx$$
where $a$ and $b$ are positive numbers? This is not a homework question. I will be quite happy if somebody can come up with a sort of bound, like an upper bound or a lower bound of integrand.","['improper-integrals', 'closed-form', 'calculus', 'definite-integrals', 'real-analysis']"
664311,discrete math- picking points inside an equilateral,"Suppose 5 points are chosen at random inside an equilateral triangle with sides of length 1. Show that there is at least one pair of these points that are separated by a distance of at most 1/2. I can't figure this out, this applies to pigeon hole principle I believe but I dont get how this problem can be approached",['discrete-mathematics']
664319,Number-Theoretic Coin Puzzle,"There are three piles of coins. You are allowed to move coins from one pile to another, but only if the number of coins in the destination pile is doubled. For example, if the first pile has 6 coins and the second pile has 4 coins, then you may move 4 coins from the first pile to the second pile — no more or less. Prove that by repeating moves of this sort, it is possible to empty one of the piles. Despite my best efforts, I have been unable to find a general solution strategy. Any pointers would be much appreciated. Background: A special case of the puzzle appeared in The Moscow Puzzles: 359 Mathematical Recreations . Starting with piles $(11,7,6)$, can you move coins (as specified above) so that you have piles $(8,8,8)$? Yes, $(11,7,6)\to(4,14,6)\to(4,8,12)\to(8,8,8)$ works.","['number-theory', 'puzzle', 'elementary-number-theory', 'additive-combinatorics', 'combinatorics']"
664349,"If $G$ is a finite group where every non-identity element is generator of $G$, what is the order of $G$?","If $G$ is a finite group where every non-identity element is generator of $G$, what is the order of $G$? I know that the order of $G$ must be prime, but I'm not sure how to go about proving this from the problem statement. Any hints on where to start?","['group-theory', 'abstract-algebra']"
664350,Centralizer of involutions in simple groups.,"I need some information about centralizer of involutions in finite simple groups of lie type. Actually I want to know if $G$ is a simple group of lie type over a finite field, How many conjugacy classes of involution does it have? If there are more than one, what is their sizes? I would be grateful, if someone answers these question or introduce a good reference.","['finite-groups', 'group-theory', 'simple-groups']"
664397,Every element of a finite abelian group with square free order equivalence,"I'm currently having some trouble with this problem: Given $G$ a finite abelian group, prove the following are equivalent: $1.$ Given any subgroup $H$, there exists a subgroup $K$ such that $HK = G$ and $H \cap K = \{e\}$ $2.$ Every element of $G$ has square-free order I'm working on the $1 \to 2$ direction, but I'm not sure what I should do.  I first assumed that $1$ was true and assumed that there was a $x$ with order $p^2$ with the expectation that the case $p^kn$ would follow.  Clearly $<x>$ is a subgroup of $G$ so there exists such a $K$, and $<x>$ is isomorphic to $C_{p^2}$.  I showed that $C_{p^2}$ did not have the 1st property, and I know that $<x> \times K \cong C_{p^2} \times K \cong G$ However, I get stuck here.  Since $K$ is a finite abelian group, it can be decomposed into a product of cyclic groups, all of prime order.  If I could show that $|K|$ and $p^2$ (or $p^kn$) were relatively prime, I would be done, but I don't know if this is true. We have the Chinese Remainder Theorem, decompositions of finite abelian groups (both cyclic and p-groups), and uniqueness.","['finite-groups', 'group-theory', 'abstract-algebra']"
664451,"Prove if $A \in Mat_{n,n}(\mathbb F)$ is both symmetric and skew-symmetric then $A=0$","Prove if $A \in Mat_{n,n}(\mathbb F)$ is both symmetric and skew-symmetric then $A=0$ I know $A^T = A = -A \Rightarrow A = -A \Rightarrow A_{i,j} = -A_{i,j}$. Since $\mathbb F$ is a field we have $2A_{i,j} = 0 \Rightarrow 2 = 0 \lor A_{i,j} = 0$. However how can I verify $A_{i,j} = 0$ ? Suppose $\mathbb F = \{[0],[1]\}$. Then $2 = 0$, so I cannot conclude $A_{i,j} = 0$ ?",['linear-algebra']
664471,Representing localization as a direct limit,"Let $A$ be a commutative ring with identity, $S\subset A$ a multiplicatively closed subset and $1\in S$. Does the equation 
$$S^{-1}A=\varinjlim_{s\in S}A_s$$
make sense? Here $A_s$ is the localization of $A$ at $s$. Note that to make sure the above equation make sense, we need to give a partial order to $S$ and make it to become a direct system.","['homological-algebra', 'commutative-algebra', 'algebraic-geometry', 'abstract-algebra']"
664472,"Prove that integral is a Gaussian random variable, compute its mean and variance","I have to prove that $X_t=\int_0^t W_s ds$ is a Gaussian random variable. I need also to compute it's mean and variance. My attempt: Let $W_t$ be a simple adapted process
$$W_t=\xi_0\mathbf{1}_0(t)+\sum_{i=0}^{n-1} \xi_i \mathbf{1}_{(t_i,t_{i+1}]}(t)$$
where $0=t_0<t_1<\dots<t_n=T$ and $\xi_i$ are measurable with respect to $F_{t_i}$ and $E[\xi_i^2]<\infty$ Then the integral of this process with respect to time is given by
$$\int_0^T W_sds=\sum_{i=0}^{n-1} \xi_i (t_{i+1}-t_i)$$
If I can prove that this integral is Gaussian, I will prove that $X_t$ is Gaussian, since a limit of Gaussian processes is Gaussian. Any help?","['stochastic-processes', 'stochastic-integrals', 'probability-theory', 'stochastic-calculus', 'probability-distributions']"
664478,integral $\int_{0}^{\infty}\frac{\cos(\pi x^{2})}{1+2\cosh(\frac{2\pi}{\sqrt{3}}x)}dx=\frac{\sqrt{2}-\sqrt{6}+2}{8}$,"Here is a seemingly challenging integral some may try their hand at. $$
\int_{0}^{\infty}
{\cos\left(\pi x^{2}\right)\over
1 + 2\cosh\left(\,2\,\pi\,x\,/\,\sqrt{\,3\,}\,\right)}\,{\rm d}x
={\,\sqrt{\,2\,}\, - \,\sqrt{\,6\,}\, + 2\, \over 8}
$$ It appears to be rather tough. I think maybe it is one of Ramanujans. But, some of the clever individuals on SE may come up with a method (Ron, robjohn, etc. ) :) Maybe residues will work, so I wasn't sure rather or not to tag it under contour integration.  Of course, I am not nearly as adept at it as many here at SE, so perhaps some one has an approach....residues or otherwise.","['improper-integrals', 'integration', 'definite-integrals', 'complex-analysis', 'contour-integration']"
664525,Is there a surface in Euclidean space that admits elliptic geometry?,"As I understand, on a pseudosphere , a surface of constant negative curvature, we can realize a part of the hyperbolic plane (but not the entire plane due to Hilbert's 1901 theorem) and use this for example to prove that hyperbolic geometry is just as consistent as Euclidean geometry. But how does this compare to elliptic two-dimensional geometry? Naturally, we can consider a sphere, which is a surface of constant positive curvature, but a sphere only admits spherical geometry and not elliptic geometry if we consider Euclid's postulates (for example there is not always a unique shortest line between two points). How can we then use the sphere to show that elliptic geometry is as consistent as Euclidean geometry? Does there exist some other surface which we can use to do so? Can someone clarify this for me?","['hyperbolic-geometry', 'geometry']"
664545,How to prove $X^*\times Y^*$ is a isometric isomorphism of $(X\times Y)^*$,"$X,Y$ are Banach (real) spaces. Consider the following Banach space:
$$
X \times Y = \{(u,v)\,:\,u\in X,v\in Y\}, \qquad \|(u,v)\|=\|u\|_X+\|v\|_Y
$$
And $X^*\times Y^*=\{(f,g)\,:f\in X^*, y\in Y^*\}$ with this properties:
$$
(f,g)+(f',g')=(f+f',g+g'),\qquad\lambda(f,g)=(\lambda f,\lambda g)\quad\lambda\in\mathbb{R}
$$
$$
\|(f,g)\|_*=\max\{\|f\|_{X^*},\|g\|_{Y^*}\}
$$
During the first part of the exercise I proved that $(X^*\times Y^*,\|\cdot\|_*)$ is Banach. Now I have to prove that the application $J: X^*\times Y^*\rightarrow(X\times Y)^*$ is an isometric isomorphism. With:
$$
J((f,g))(u,v)=f(u)+g(v)
$$
But i'm a bit confused...
In order to show that $J$ is an isometry I have to prove that:
$$
\|J(f,g)\|=\|f+g\|=\|(f,g)\|_*
$$
But I don't know how to consider $\|J(f,g)\|$ even considering the definition:
$$
\|J(f,g)\|=\sup_{\|(u,v)\|=1} |J(f,g)(u,v)|
$$
And in order to prove that $J$ is isometric should I prove that exists $J^{-1}$? (I hope I wrote it correctly!)","['functional-analysis', 'banach-spaces']"
664552,"Prove that a mapping $f:[-1,1]^2\to\mathbb R^2$ with certain properties has the value $(0,0)$.","The mapping $f:[-1,1]^2\to\mathbb R^2$ is known to be continuous. Also the image of the upper edge of the rectangle is contained in the upper half-plane, the left edge's image is contained in the left half-plane, and so on for the bottom and right edge. Formally speaking this means: If $f_1,f_2:[-1,1]^2\to\mathbb R$ are defined to be the components of $f$, i. e. $$f(x,y)=(f_1(x,y),f_2(x,y))\,,$$ then the following conditions hold for each $x\in[-1,1]$ it holds $f_2(x,1)>0$, for each $y\in[-1,1]$ it holds $f_1(-1,y)<0$, for each $x\in[-1,1]$ it holds $f_2(x,-1)<0$ and for each $y\in[-1,1]$ it holds $f_1(1,y)>0$. Under these assumptions prove that there exist $x_0,y_0\in[-1,1]$ such that $f(x_0,y_0)=(0,0)$. This appears to be obvious intuitively, but I'm looking for a formal and rigorous proof.","['multivariable-calculus', 'roots', 'algebraic-topology', 'continuity', 'real-analysis']"
664554,"Can this quick way of showing that $K[X,Y]/(Y-X^2)\cong K[X]$ be turned into a valid argument?","I've been trying to show that $$
K[X,Y]/(Y-X^2)\cong K[X]
$$ where $K$ is a field, $K[X]$ and $K[X,Y]$ are the obvious polynomial rings over the indeterminates $X$ and $Y$ and $(Y-X^2)$ is the ideal generated by the polynomial $Y-X^2$.  Though I'm sure there's a fairly easy way to find an explicit isomorphism between the two rings, the following argument jumped out at me: If we substitute in a value for $X$ - $x$, say, then the ideal $(Y-x^2)$ is a maximal ideal of $K[Y]$.  So the quotient $K[Y]/(Y-x^2)$ is a field; in fact, the homomorphism $K[Y]\to K:P(Y)\mapsto P(x^2)$ and is clearly surjective, so the quotient is isomorphic to $K$. I'd like to be able to deduce from this that $K[X,Y]/(Y-X^2)\cong F[X]$, but I can't see a nice way to do it.  I know that the 'substitution' maps $P(X,Y)\mapsto P(x,Y)$ are homomorphisms, but I can't see a nice way of pulling all these homomorphisms back to the polynomial ring in two variables. Or maybe I'm completely wrong and there is no way to turn this into a valid argument.  Can anyone help me?","['ring-theory', 'algebraic-geometry', 'abstract-algebra', 'polynomials']"
664583,"Prove $(x+y)^a\leq x^a+y^a$ if $0<a\leq1$ and $x,y\geq0$ [duplicate]","This question already has answers here : Prove that $(p+q)^m \leq p^m+q^m$ (2 answers) Closed 9 years ago . Prove $(x+y)^a\leq x^a+y^a$ if $0<a\leq1$ and $x,y\geq0$ I need to prove this step for a bigger question. It should be quite basic but I just have no idea...","['functions', 'inequality', 'real-analysis']"
664594,Why $\{\mathbf{0}\}$ has dimension zero?,According to C.H. Edwards' Advanced Calculus of Several Variables : The dimension of the subspace $V$ is defined to be the minimal number of vectors required to generate $V$ (pp. 4). Then why does $\{\mathbf{0}\}$ have dimension zero instead of one? Shouldn't it be true that only the empty set has dimension zero?,['linear-algebra']
664619,"Roll a die, pick that many balls from an urn","An urn has $5$ white and $10$ black balls. A die is rolled, and that many balls is drawn from the >urn. What is the probability that all the balls drawn are white? My thinking is that each die roll $(d)$ has probability $\frac{1}{6}$. The probability to get only white balls from your draw is $$\frac{C(5, d)}{C(15, d)}$$. Then you add up all the probabilities. I come up with $\frac{5}{66}$, but have no way of knowing if I'm right. Is this the way to go about it? I tried multiplying the probabilities tied to each die roll and came up with an extremely small chance, so that seems wrong to me.","['dice', 'probability']"
664648,What does $dx$ mean in differential form?,"This question relates to this post . From what I know in calculus and standard analysis, strictly speaking, there is no meaning of $dx$. It only makes sense when combining with another $d$, e.g. $df/dx$ as derivative or integration, e.g. $\int f(x) dx$. The $dx$ in derivative or integration has a definite meaning inside the definition of derivative or integration, respectively. However, in differential form, it is given as $\omega = \frac{ \omega_{\mu_1,\cdots, \mu_r}}{r!} dx^{\mu_1} \wedge\cdots\wedge dx^{\mu_r} $ where $dx$ appears explicitly. What does $dx$ mean in differential form? Physicist usually say it is infinitesimal. However, infinitesimal does not mean anything in standard analysis, or I am completely mistaken?","['calculus', 'differential-geometry']"
664657,Prove $y = x$ is continuous,For every $\epsilon > 0$ there exists a $\delta > 0$ such that $|x - c| < \delta$ implies $|f(x) - f(c)| < \epsilon$. Start with $|f(x) - f(c)| < \epsilon$ which gives $|x - c| < \epsilon$. We also know $|x - c| < \delta$ but how can we connect $\epsilon$ and $\delta$?,['analysis']
664668,How to buy a car optimally in this case?,"X has a car. Its value is unknown yet, but between 0 and 1000, uniformly distributed You offer a price to buy the car. If price < value, you can’t buy. If price >= value, you can buy, give the price of money to X. (for example, if value is 200, and you offer 300, you can buy, but you must give 300 to X) If your buy is successful, Y will pay you the money of 1.5 * value to buy this car himself. (for example, if value is 200, you offer 300, you can buy, give 300 to X, and then Y pays you 1.5*200 = 300, and he takes the car) I think first of all, I need to define the optimal case, which is at the end I earn more money than the price I offered. Assume value is 200. If I offer too low price, nothing will happen, not make much sense If I offer 300, buy the car and then sell the car to Y for 300, in the end, I still have 300, unchanged and makes not much sense. If I offer 250, then I will earn 50 in the end, this makes sense. If I offer 400, then I actually loose 100, this is even worse. What should I do? Update Here is my thinking. Let m be the price I am going to offer and v be the value of the car. What I want is after all things (including I don't buy the car successfully), the money in my hand is still at least m . There are three cases: 1. I can't buy the car, i.e., v > m Because 0 <= v <= 1000 , the probability of v > m is (1000-m)/1000 . 2. I buy the car and I get less than m in the end, i.e., m > 1.5v The probability is m/1500 3. I buy the car and I get more than m in the end, i.e., 1.5v >= m >= v The probability is 1 - (1000-m)/1000 - m/1500 = m/3000 . I wish to have case 1 and case 3, so (1000-m)/1000 + m/3000 > m/1500 . solve this I get 0 <= m <= 791 . As long as I offer a price between 0 and 791, I have bigger possibility to get extra money. (image if I play this for 10000 times)",['probability']
664671,Prove that a number all of whose digits are either $6$ or $0$ cannot be a perfect square [duplicate],This question already has answers here : Proving that a natural number made entirely of 6's and 0's is not a square. (3 answers) Closed 10 years ago . Let $m$ be a number all of whose digits are either $6$ or $0$. Prove that '$m$' cannot be a perfect square.,['number-theory']
664702,Existence theorem for antiderivatives by Weierstrass approximation theorem,Is there a way of proving the existence of antiderivatives (of continuous functions on a compact subset of the real line) without using tools of integration? This is an exercise in: http://www.math.nus.edu.sg/~matngtb/Calculus/MA3110/Chapter%2010%20Weierstrass%20Approximation.pdf last page. Apparently one should somehow be able to use the Weierstrass theorem. A related question is now of course: can we prove the fundamental theorem of calculus using Weierstrass' theorem?,"['calculus', 'integration', 'real-analysis']"
664703,Counting measure $\sigma$-finite / not $\sigma$-finite for different sets,"Let $\zeta\colon\mathcal{P}(\Omega)\to [0,\infty]$ be the counting measure. Show that for $\Omega:=\mathbb{R}$ it is not $\sigma$-finite but for $\Omega:=\mathbb{N}$. Hello and good afternoon! Here are my tries: (1) Consider $\Omega:=\mathbb{N}$. Define $A_n:=\left\{1,\ldots,n\right\}, n\geq 2$. Then $A_n\in\mathcal{P}(\mathbb{N}), A_n\nearrow\mathbb{N}$ and $\zeta(A_n)=n<\infty$ for $n\geq 1$. So the measure $\zeta$ is $\sigma$-finite. (2) Now $\Omega:=\mathbb{R}$. First of all it is $\zeta(\mathbb{R})=\infty$ because the counting
 measure of all sets that are not finite, is $\infty$. Assume there are $A_i\in\mathcal{P}(\mathbb{R}), i\geq 1, A_i\nearrow \mathbb{R}$ and $\zeta(A_i)<\infty, i\geq 1$. Then for $A:=\bigcup_{i\geq 1}A_i$ it is because of the $\sigma$-additivity of $\zeta$ and the subtractivity
$$
\zeta(A)=A_1\uplus\biguplus_{k\geq 2}(A_k\setminus A_{k-1})=\zeta(A_1)+\sum_{k\geq 2}\zeta(A_k\setminus A_{k-1})=\zeta(A_1)+\sum_{k\geq 2}\zeta(A_k)-\zeta(A_{k-1})=\zeta(A_{\infty})<\infty,
$$
so because of the continuity of the measure it is 
$$
\zeta(A_i)\nearrow\zeta(A)<\infty.
$$
On the other hand it is $\zeta(A_i)\nearrow\zeta(\mathbb{R})=\infty$. So $\mathbb{R}\neq A$. Contradiction: It was assumed that $A_i\nearrow\mathbb{R}$, i.e. $A_i\nearrow A=\mathbb{R}$. So there do not exist $A_i\in\mathcal{P}(\mathbb{R}), i\geq 1$ with $A_i\nearrow\mathbb{R}$ and $\zeta(A_i)<\infty$, i.e. $\zeta$ is not $\sigma$-finite for $\Omega:=\mathbb{R}$. Maybe you can say me, if I am right. Miro","['measure-theory', 'proof-verification']"
664704,Let $A\subset\mathbb{R}$ a measurable and bounded set. Show that exists for each $0<\alpha<1$ an interval $I$ such that $m(A\cap I)/m(I)>\alpha$.,"Let $A\subset\mathbb{R}$ a measurable where $0<m(A)<\infty$. Show that exists for each $0<\alpha<1$ an interval $I$ such that 
$$
\frac{m(A\cap I)}{m(I)}>\alpha.
$$ MY ATTEMPT : Following a hint a give that: Let $\varepsilon>0$, exists $G$, a open set such that $m(A)\leq m(G)<m(A)+\varepsilon$. As $G$ is open, we can write as the disjoint sum of open intervals $\dot{\bigcup}_n I_n = G$.So,
$$
m(A)\leq m(G)=m\left(\sum \dot{\bigcup_n} I_n \right)\leq \sum m\left(I_n \right)<m(A)+\varepsilon
$$
Suppose that $\varepsilon=(\alpha^{-1}-1)m(A)$: $$
m(A)+\varepsilon=m(A)+m(A)(\alpha^{-1}-1)=m(A)(1+\alpha^{-1}-1)=m(A)\alpha^{-1}
$$
and
$$
\alpha\sum m(I_n)<m(A)=\sum m(A\cap I_n)
$$
$$
\Rightarrow \alpha<\frac{\sum m(A\cap I_n)}{\sum m(I_n)} 
$$ But I have a insecurity with that: (1) I can write that: $m(A)=\sum m(A\cap I_n)$? (2) How to get the result with this: $$
\alpha<\frac{\sum m(A\cap I_n)}{\sum m(I_n)} 
$$","['measure-theory', 'lebesgue-measure', 'real-analysis', 'analysis']"
664707,number field:How can i prove that ${\Bbb Q}[\sqrt{-3}]$ is a cyclotomic field?,Can you help me with this ''simple'' exercise: Prove that ${\Bbb Q}[\sqrt{-3}]$ is a cyclotomic field.,"['field-theory', 'number-theory']"
664724,Closed Monoidal Structures On The Category Of Complete Topological Vector Spaces,"Context: The category of Banach spaces, with the projective tensor product is a closed monoidal category. Question 1 : Is there a tensor product on the category of complete topological vector spaces, such that the monoidal stucture is closed? Question 2 : what are the ""natural/nice"" topologies to put on the set of continuous linear maps between two ctvs? Question 3 : Is it different if instead we use Fréchet (or nuclear Fréchet) spaces?","['topological-vector-spaces', 'category-theory', 'functional-analysis']"
664726,How many strings contain every letter of the alphabet?,"Given an alphabet of size $n$, how many strings of length $c$ contain every single letter of the alphabet at least once? I first attempted to use a recurrence relation to work it out: $$
T(c) = \left\{ \begin{array}{cr}
0 &\mbox{ if $c<n$} \\
n! &\mbox{ if $c = n$} \\
T(c-1) \cdot n \cdot c &\mbox{ if $c > n$}
\end{array} \right.
$$ As there's no strings that contain every letter if c < n, and if c = n then it's just all permutations. When c > n you can take any string of size (c-1) that contains all letters (of which there are $T(c-1)$ to choose from), you choose which letter to add (of which there are $n$ choices) and there are $c$ different positions to put it. However, this gives out results that are larger than $n^c$ (the total number of strings), so it can't be right, and I realised it was because you could count some strings multiple times, as you can make them taking different inserting steps. Then I thought about being simpler: you choose n positions in the string, put each letter of the alphabet in one of those positions, then let the rest of the string be anything: $$
{c\choose{n}} \cdot n! \cdot n^{c-n}
$$ But again this counts strings multiple times. I've also considered using multinomial coefficients, but as we don't know how many times each letter appears in the string it seems unlikely they would be much help. I've also tried several other methods, some complicated and some simple, but none of them seem to work. How would you go about working out a formula for this? I'm sure there's something simple that I'm missing.","['stirling-numbers', 'discrete-mathematics', 'inclusion-exclusion', 'combinatorics-on-words', 'combinatorics']"
664739,understand quotient group,"i am trying to understand what does mean  quotient terminology in group theory  by as simple way as possible,also quotient group  i want to know something about it,using internet i read that ""
In mathematics, specifically group theory, a quotient group (or factor group) is a group obtained by aggregating similar elements of a larger group using an equivalence relation. For example, the cyclic group of addition modulo n can be obtained from the integers by identifying elements that differ by a multiple of n and defining a group structure that operates on each such class (known as a congruence class) as a single entity."" so does it means that quotient  group helps us to divide element into equivalence classes?
example is there : For example, consider the group with addition modulo 6: G = {0, 1, 2, 3, 4, 5}.
Let
N = {0, 3}.
The quotient group is:
G/N = { aN : a ∈ G } = { a{0, 3} : a ∈ {0, 1, 2, 3, 4, 5} } =
{ 0{0, 3}, 1{0, 3}, 2{0, 3}, 3{0, 3}, 4{0, 3}, 5{0, 3} } =
{ {(0+0) mod 6, (0+3) mod 6}, {(1+0) mod 6, (1+3) mod 6},
{(2+0) mod 6, (2+3) mod 6}, {(3+0) mod 6, (3+3) mod 6},
{(4+0) mod 6, (4+3) mod 6}, {(5+0) mod 6, (5+3) mod 6} } =
{ {0, 3}, {1, 4}, {2, 5}, {3, 0}, {4, 1}, {5, 2} } =
{ {0, 3}, {1, 4}, {2, 5}, {0, 3}, {1, 4}, {2, 5} } =

{ {0, 3}, {1, 4}, {2, 5} }. as i know notation $G/N$  to be the set of all left cosets of N in G, i.e., G/N = { aN : a in G }. so what does given  result represent  to original  groups?thanks in  advance,i was also interested about this topic because of  Homology,which as i understand is related to cycles and boundary in group","['homology-cohomology', 'group-theory']"
