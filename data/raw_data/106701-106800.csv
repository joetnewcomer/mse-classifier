question_id,title,body,tags
1519432,Cyclic vector implies commuting linear operator is a polynomial [duplicate],"This question already has answers here : Prove that $T$ has a cyclic vector iff its minimal and characteristic polynomials are the same (2 answers) Closed 5 years ago . The community reviewed whether to reopen this question last year and left it closed: Original close reason(s) were not resolved Let $T$ be a linear operator on the finite dimensional vector space $V$. Suppose $T$ has a cyclic vector. Prove that if $U$ is any linear operator which commutes with $T$, then $U$ is a polynomial in $T$.","['linear-algebra', 'linear-transformations']"
1519449,Change of variables problem.,"We're given a normal xy - plane , with the help of the transformations $ u = x^{2} - y^{2}$ and $v = 2xy$ , we need to plot the corresponding image in the $uv$-plane. First we need to find $x$ and $y$ in terms of $u$ and $v$ , By completing the square , I got : $ (x^{2} + y^{2})^{2} = u^{2} + v^{2}$ => $ x^{2} + y^{2} = \sqrt{u^{2} + v^{2}}$. If I try to find equations for $x$ and $y$ from this , the situation becomes messy .. Can anyone suggest a better way ? Update : Using the equations $y = 2x$ and $y=4$ ,  I got the equations in $u$ and $v$ as : $v= (\dfrac{-4}{3}) u$ and $v^{2} = 64(u + 16)$ , and I was able to draw a graph as follows : (I know that doesn't look like a parabola , but still.. ) Now I am not able to find the image of the line $ y = 2x - 10$ , I tried solving $ u = x^{2} - y^{2}$ and $v = 2xy$ for the given $y$ but the equation ends up in terms of $x$ only.. Could anyone help ?","['calculus', 'multivariable-calculus']"
1519470,How do I write the square of covariance?,"Should it be $\mathrm{cov}^{2}(X,Y)$ or should it be $\mathrm{cov}(X,Y)^2$ or $(\mathrm{cov}(X,Y))^2$ or something completely different? Thank you.","['covariance', 'notation', 'statistics']"
1519540,Does the sequence $a_n = \frac{1 \cdot 3 \cdot 5 \cdots (2n-1)}{2 \cdot 4 \cdot 6 \cdots (2n)}$ converge?,"Does the sequence $a_n = \frac{1 \cdot 3 \cdot 5 \cdots (2n-1)}{2 \cdot 4 \cdot 6 \cdots (2n)}$ converge? This is a homework question for an analysis class. Firstly, I know the sequence is comprised of odd numbers up to $2n-1$ over even numbers up to $2n$. Secondly, I know the sequence decreases. I'm guessing it'll converge, but not specifically to $0$. Where I am stuck is simplifying the series to something easier to work with. Any help would be greatly appreciated! Edit: solved, thank you everyone. I ended up doing what was first suggested, not finding the actual limit but just proving the sequence converges. Thanks again!","['analysis', 'sequences-and-series', 'convergence-divergence', 'real-analysis']"
1519548,Calculate Fourier transform of $V(r)=\frac{-g^2}{4\pi|r|}e^{-\mu|r|}$ in Quantum Field Theory,"(This is purely for personal study - the exercise is 20.2(a) from Lancaster and Blundell (2014), Oxford Uni. Press - an excellent textbook btw.) ""Confirm that the Fourier transform of $V(\underline{r})=\frac{-g^2}{4\pi|\underline{r}|}e^{-\mu|\underline{r}|}$ is $\tilde{V}(\underline{q})=\frac{-g^2}{|\underline{q}|^2+\mu^2}$."" The definition of the 3D transform (equation 22) is $\tilde{f}(\underline{k})=\int d^3x\,\,e^{-i\underline{k}.\underline{x}}f(\underline{x})$; therefore using spherical co-ordinates, I can get as far as $\tilde{V}(\underline{q})=\int_0^\infty dr\,|\underline{r}|^2\frac{-g^2}{4\pi|\underline{r}|}e^{-\mu|\underline{r}|}e^{i|\underline{q}||\underline{r}|}\int_0^\pi \sin\theta d\theta\int_0^{2\pi}d\phi
=4\pi\int_0^\infty dr\,|\underline{r}|\frac{-g^2}{4\pi}e^{-\mu|\underline{r}|+i|\underline{q}||\underline{r}|}\\
=-g^2\int_0^\infty dr\,|\underline{r}|e^{-(\mu-i|\underline{q}|)|\underline{r}|}.$ However, this integral appears to yield $\frac{-1}{\mu-i|\underline{q}|}$, for constant $\mu$ and $q$, since (with $Z_q=\mu-i|\underline{q}|$) $-g^2\int_0^\infty dr\,|\underline{r}|e^{-Z_q|\underline{r}|}
=Z_q^{-1}\lim(c\rightarrow\infty)[(1-c)e^{-Z_q c}-1]$, and the first term vanishes in the limit (due to L'Hopital's rule). One last comment is that I have had a sneaking suspicion this is somehow related to Laplace transforms, a) because the formula for $\tilde{V}(\underline{q})$ is so very Laplace-looking, and b) the Laplace formula itself containing a factor of $\exp(-st)$ (where $s$ is the integration variable). If someone could just please tell me what I am missing I'd be grateful!","['quantum-field-theory', 'calculus', 'fourier-transform']"
1519580,How to Find the Linearization of $f(x) = 8\cos^2(x)$ at the Point Where $x = \pi/4$,"I am looking to find the linearization of $f(x) = 8\cos^2(x)$ at the point where $x = \pi/4$ Now, I know that the general formula for finding linearization is $L(x) = f(x) + f'(x) (x-a)$. So, I have made the following steps to get my answer: 1) Use the above formula to get $L(x) = 8\cos^2(\pi/4)+16\cos(\pi/4)(-\sin(\pi/4))(\pi/4-a)$ 2) Simplify to get $4-8(\pi/4-a)$ However, I am not sure if this is completely correct. Does anyone know whether this is the correct way to find this answer, and if it is not, how to arrive at the true answer?","['calculus', 'trigonometry']"
1519620,If f is continuous does this means that the image under f of any open set is open?,"If $(X,d_X)$ and $(Y,d_Y)$ are metric spaces, and $f : X → Y$ is a continuous map, is it true that for any open set $U ⊂ X$, the set $f(U)$ is open in Y ?","['metric-spaces', 'continuity', 'general-topology']"
1519630,A discontinuous almost everywhere map does not admit an invariant measure,"Let's consider a map $T: X \rightarrow X$ so that it's discontinuous almost everywhere (in particular, let $X = \mathbb{R}$, and $T = 1_{\mathbb{Q}}$ -- Dirichlet function). Is it true that $T$ does not admit an invariant measure (e.g. $\lambda(X) = \lambda(T^{-1}(X))$)? The original problem is to find a map from $3$-dimensional ball to itself with the given property. Bogolybov-Krylov theorem states that for every compact space $X$ and for every continuous $T$ such measure does exist. So, it's reasonable to look for a very ""bad"" maps, such as considered before.","['ergodic-theory', 'real-analysis', 'measure-theory']"
1519635,Prove that if $x(t)$ solves $\dot x(t)=f(x)$ and $x(t_1)=x(t_2)$ then $x(t_1)$ is a fixed point.,"Prove that if $x(t)$ solves $\dot x(t)=f(x)$ where $f$ is continuous differentiable, and $x(t_1)=x(t_2)$ then $x(t_1)$ is a fixed solution. $t_1\ne t_2$. 
Explain by intuition and prove by: 1. Uniqueness and Existence Theorem 2. Analysis. Firstly, what I didn't get here is what $x(t_1)$ exactly is. Is it a shifting of $x(t)$? Can I assume $t_0=0$ and then arrive at $x(t_1):=x(t+t_1)$?  If so, $g(t)=x(t+t_1)$ is also a solution of the equation, but I still don't quite understand. Can $x(t+t_1)$ go up and then down again(and vice versa) before reaching $t=t_2-t_1$? If it can't, then it must remain constant, but what happens next? If it remains constant it will intersect the $x(t)$. So basically, I am really confused. I would really appreciate some help here.",['ordinary-differential-equations']
1519636,If $X_n \rightarrow^{P} 0$ then for any $p >0$ $\frac{|X_n|^p}{1+|X_n|^p} \rightarrow_{P} 0$,"Let $\{X_n\}$ be a sequence of random variables
If $X_n \rightarrow^{P} 0$ then for any $p >0$ $$\frac{|X_n|^p}{1+|X_n|^p} \rightarrow_{P} 0$$ and $$E(\frac{|X_n|^p}{1+|X_n|^p}) \rightarrow 0$$ . Proof Let $\epsilon$ be given. Choose $N$ such that $$P(|X_n|>\epsilon^{\frac{1}{p}}) < \epsilon \> \forall n  \geq N $$ $$\implies P(|X_n|^{p}>\epsilon) < \epsilon \> \forall n  \geq N $$ .
Note that $$\frac{|X_n|^{p}}{1+|X_n|^{p}}\leq |X_n|^{p}$$ So for all $n \geq N$ $$P(\frac{|X_n|^{p}}{1+|X_n|^{p}} > \epsilon) \leq P( |X_n|^p > \epsilon) < \epsilon$$ So $\frac{|X_n|^{p}}{1+|X_n|^{p}}\rightarrow_{P} 0$ I need help with the expectation part. I think I want to use Lebesgue Dominated Convergence but how do I show that $|X_n|$ is bounded","['probability-theory', 'convergence-divergence']"
1519645,"prove that if $\lim \limits_{n \to \infty}F( a_n)=\ell$, then $\lim \limits_{x \to \infty}F( x)=\ell$","Let $a_n$ be a strictly increasing sequence of positive real numbers ($a_n>0$) and $\lim \limits_{n \to \infty} a_n=\infty.$ Suppose that the sequence $(a_{n+1}-a_n)_n$ is bounded. Let $F:\mathbb{R}^+\rightarrow \mathbb R$ be a differentiable function. Ssuppose further that $\lim \limits_{x \to \infty}F'(x)=0$ and $\lim \limits_{n \to \infty}F( a_n)=\ell$. (Note that $\ell$ is a real number). Prove that: $$\lim \limits_{x \to \infty}F( x)=\ell$$ I'm stuck, I've tried to use the MVT but it gets me nowhere! can anyone help me solve this problem?","['limits', 'calculus', 'real-analysis', 'algebra-precalculus']"
1519661,Why affine variety not vector space variety?,I am new to algebraic geometry. A basic question baffles me: why is the setting the affine space not the vector space?,"['algebraic-geometry', 'affine-geometry', 'affine-schemes']"
1519669,"Let $a_f=\text{ arg} \min_{a} \int \left|f(x)-a\right| dx$ and $a_g= \text{ arg} \min_{a} \int \left|g(x)-a\right| dx$, is $a_f \le a_g$?","Let $ f(x) \le g(x) $ and assume that $g(x),f(x) \in L^1$ let 
\begin{align}
a_f= \text{ arg} \min_{a } \int_A \left|f(x)-a\right| dx\\
a_g=\text{ arg} \min_{a } \int_A \left|g(x)-a\right| dx
\end{align}
where $A \subseteq \mathbb{R}$. We assume that such $a_f$ and $a_g$ exist and $|a_f|,|a_g| < \infty$.
Is $a_f \le a_g$? How would one approach this problem?
Thank you.","['lp-spaces', 'optimization', 'functional-analysis', 'integration']"
1519672,"Prove $e^x=1+\frac{1}{\sqrt{\pi }}{\int_0^x \frac{e^t \text{erf}\left(\sqrt{t}\right)}{\sqrt{x-t}} \, dt}$","It seems to me that $$e^x=1+\frac{1}{\sqrt{\pi }}{\int_0^x \frac{e^t \text{erf}\left(\sqrt{t}\right)}{\sqrt{x-t}} \, dt}$$ This integral seems to converge for all $x\in\mathbb{C}$ I came upon this conjecture by following the instructions here to do a half integral twice. Can anyone prove this conjecture is true?","['error-function', 'complex-analysis', 'definite-integrals']"
1519680,A Basic Probability Question - I am getting the wrong answer,"Problem: In a deck of $52$ cards there are $4$ kings. A card is drawn at random
from the deck and its face value noted; then the card is returned. This
procedure is followed $4$ times. Compute the probability that there are
exactly $2$ kings in the $4$ selected cards if it is known that there is at
least one king in those selected. Answer: Let $p$ be the probability we seek. Let $p_2$ be the probability that we
draw exactly $2$ kings. Let $p_1$ be the probability that we draw at least
$1$ king.
\begin{eqnarray*}
p &=& \frac{p_2}{p_1} \\
p_2 &=& {13 \choose 2}{(\frac{4}{52})^2}{(\frac{48}{52})}^2 \\
{13 \choose 2} &=& \frac{13(12)}{2(1)} = 13(6) \\
p_2 &=& 13(6){(\frac{1}{13})^2}{(\frac{12}{13})}^2 = \frac{6(12)^2}{13^3} \\
\end{eqnarray*}
Let $p_0$ be the probability that we draw no kings.
\begin{eqnarray*}
p_0 &=& (\frac{48}{52})^4 = (\frac{12}{13})^4 \\
p_1 &=& 1 - p_0 = 1 - (\frac{12}{13})^4 = \frac{13^4 - 12^4}{13^4} \\
p &=& \frac{ \frac{6(12)^2}{13^3} }{ \frac{13^4 - 12^4}{13^4} } =
\frac{6(13)(12)^2}{13^4 - 12^4} \\
\end{eqnarray*}
However, the book gets:
\begin{eqnarray*}
p = \frac{6(12)^2}{13^4 - 12^4} \\
\end{eqnarray*}
I am hoping that somebody can tell me where I went wrong. ~","['probability', 'statistics', 'probability-distributions', 'combinatorics']"
1519704,Prove that Image of a closed set is closed in isometry,"Suppose that $(X, d_X)$ and $(Y, d_Y )$ are complete metric spaces. Let $i \colon X → Y$ be an isometry. Suppose that $F ⊂ X$ is closed. How can I prove that $i(F)$ is a closed subset of $Y$?","['metric-spaces', 'general-topology']"
1519714,What is Cauchy Schwarz in 8th grade terms?,"I'm an 8th grader. After browsing aops.com, a math contest website, I've seen a lot of problems solved by Cauchy Schwarz. I'm only in geometry (have not started learning trigonometry yet). So can anyone explain Cauchy Schwarz in layman's terms, as if you are explaining it to someone who has just started geo in 8th grade?","['geometry', 'inequality']"
1519734,Show that $\int_{-1}^1 \frac{du}{(1-u^4)^{1/4}} = \frac{\pi}{\sqrt 2}$.,"Show that $\int_{-1}^1 \frac{du}{(1-u^4)^{1/4}} = \frac{\pi}{\sqrt 2}$. Not sure if it is helpful to anyone but 
$\int \frac{du}{(1-u^4)^{1/4}} = f^{-1}(x)$ is a solution to the differential equation $f(x)^4 + f ' (x)^4 = 1$. Also $f(x)$ can be expressed as a hypergeometric function.","['definite-integrals', 'calculus', 'hypergeometric-function', 'ordinary-differential-equations']"
1519801,Show that an invertible holomorphic function must be a rotation if it satisfies these conditions,"Let $f(z)$ be an invertible holomorphic mapping of the unit disc to itself, such that $f(0)=0$. Show that $f(z)=\lambda z$ for some $\lambda$, such that $|\lambda|=1$. I considered using Schwarz lemma. And the aim is to show that there exists $0<|z|<1$, such that $|f(z)|=|z|$. But I have a hard time figuring out how to use the condition that $f$ is invertible.","['complex-analysis', 'complex-numbers']"
1519803,Proving identities using combinatorial interpretation of binomial coefficients,"Let $n \in \mathbb{N}$. Prove the identities $$\binom{n}{k} = \binom{n-1}{k-1} + \binom{n-1}{k}$$ and $$\sum^{n}_{k=0}\binom{n}{k}^2 = \binom{2n}{n}$$ by using only the combinatorial interpretation of the binomial coefficient. I don't exactly get what it means with "" combinatorial interpretation of binomial coefficient "". I can solve the first identity simply using binomial coefficient like this: $$\binom{n-1}{k-1} + \binom{n-1}{k} = \frac{(n-1)!}{(n-k)!(k-1)!} + \frac{(n-1)!}{(n-k-1)!k!} = \frac{(n-1)!k}{(n-k)!k!} + \frac{(n-1)!(n-k)}{(n-k)!k!} = \frac{(n-1)![k+(n-k)]}{(n-k)!k!} = \frac{(n-1)!n}{(n-k)!k!} = \frac{n!}{(n-k)!k!} = \binom{n}{k}$$ And for the second identity, I can apply symmetry, then Vandermonde to get: $$\sum^{n}_{k=0}\binom{n}{k}^2 = \sum^{n}_{k=0}\binom{n}{k}\binom{n}{n-k} = \binom{2n}{n}$$ Though, I don't exactly understand whether the problem asks for this kind of solution, if not, I would like to see a proof to the identities using combinatorial interpretation of binomial coefficient .","['discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
1519811,Logarithmic expansion with cosines,"I found the following expansion in this paper : $$\log\frac{|\boldsymbol{r}-\boldsymbol{r'}|}{L}=\log\frac{r_>}{L}-\sum_{n=1}^{\infty}\frac{1}{n}\left(\frac{r_<}{r_>}\right)^n\cos[n(\phi-\phi')]$$ where $r_>=\max(|\boldsymbol{r}|,|\boldsymbol{r'}|)$, and  $r_<=\min(|\boldsymbol{r}|,|\boldsymbol{r'}|)$ Can anyone point me to a paper/reference/explanation of this, please?","['taylor-expansion', 'real-analysis', 'functional-analysis']"
1519816,"Definition: is a graph allowed to have a ""dangling"" edge without a vertex at its end(s)?","My textbook gives the following definition ""a graph $G=(V,E)$ consisting of $V$, a nonempty set of vertices and $E$, a set of edges. Each edge has either one or two vertices associated with it."" Now consider this ""graph"", o— , where o is a vertex and — is an edge. Is this  a valid graph? If so, is it a subgraph of o—o ? (I know — is not valid because $V$ has to be nonempty) (My textbook: ""A subgraph of a graph $G=(V,E)$ is a graph $H=(W,V)$ where $W \subseteq V$ and $F \subseteq E$"". My book also says ""when edges and vertices are removed from a graph, without removing endpoints of any remaining edges , a smaller graph is obtained; such a graph is called a subgraph of the original graph"") What're the most ""standard"" definitions of graphs and subgraphs?","['graph-theory', 'definition', 'discrete-mathematics']"
1519853,Which heuristic leads to the Hardy-Littlewood conjecture about twin primes?,"According to Wikpedia , Hardy-Littlewood conjecture says that
$$\pi_2(n) \sim 2 C_2 \frac{n}{(\ln n)^2} \sim 2 C_2 \int_2^n {dt \over (\ln t)^2}$$
where 
$$C_2 = \prod_{p\ge 3} \frac{p(p-2)}{(p-1)^2} \approx 0.66016 18158 46869 57392 78121 10014\dots$$
Wikipedia also says that ""This conjecture can be justified (but not proven) by assuming that $1 / \ln t$ describes the density function of the prime distribution, an assumption suggested by the prime number theorem."" Could somebody elaborate a bit on how we can get the above form of the conjecture using probabilistic viewpoint. Very naively, I could say that prime number theorem says me that a number $p\le x$ is a prime is approximately $\frac1{\ln x}$. If I consider ""$p$ is a prime"" and ""$p+2$ is a prime"" as independent events, I would arrive at probability approximately $\frac1{\ln^2 x}$. So this would lead to the conjecture of the form
$$\pi_2(x)\sim \frac{x}{\ln^2 x}.$$
Setting aside the assumption that the two events are independent, the above heuristic is rather problematic. We should somehow incorporate the fact that, in order to get a pair of twin primes, $p+2$ cannot be divisible by any smaller primes. How can we heuristically find out that $C_2$ described above is the ""correct"" constant for this conjecture? Is there a simple probabilistic approach which would lead to the above formula?","['conjectures', 'prime-numbers', 'number-theory', 'twin-primes']"
1519929,Series of Functions - Pointwise and Uniform Convergence,"I'm learning about series of functions and need some help with this problem : Given the series of functions $$ \sum_{n=1}^\infty \frac{x}{x^2+n^2}, \; x \in (0, \infty) $$ show that it converges pointwise and uniformly to a function $ s(x) $ and show that $ s'(x) $ converges uniformly. Here's my attempt : Let $$ f_n(x) = \frac{x}{x^2+n^2} \Rightarrow f_n'(x) = \frac{(x^2 + n^2) - 2x^2}{(x^2+n^2)^2} = \frac{n^2 - x^2}{(x^2+n^2)^2} $$ Then $$ f_n'(x) = 0 \iff n^2 - x^2 = 0 \iff x = \pm \, n $$ On the interval $ (0, \infty), \;  f_n $ takes it's maximum value for $ x = n $ and therefore : $$ f(n) = \frac{n}{n^2+n^2} = \frac{1}{2n} $$ Hence $ |f_n(x)| \le \frac{1}{2n} $ but the series $ \sum_{n=1}^\infty \frac{1}{2n} $ does not converge by the p-series Test. What am I doing wrong here?","['sequences-and-series', 'real-analysis', 'uniform-convergence']"
1519952,"Show that $S(n ,k)$...","Show that
$$S(n,k) = \sum_{m = k-1}^{n-1} {n-1 \choose m} S(m,k-1)  $$ -I was having trouble with this proof in class and my professor suggested to look at it as another proof of the following theorem which states: -For all $n\ge1$
$$B(n) = \sum_{k=0}^{n-1} {n-1 \choose k} B(k)  $$
-Unfortunately I still do not understand how to solve this proof, I do see the similarities in structure although I am brand new to Stirling numbers and am unsure of how this would affect the proof. Any help is appreciated.","['integer-partitions', 'stirling-numbers', 'discrete-mathematics']"
1520026,What is ∃ in set theory?,I stumbled upon this symbol and I'm not sure at all what this symbol denotes. Can someone decode this for me?,"['elementary-set-theory', 'notation']"
1520030,Prerequisites for studying Perelman's proof of the Geometrization Conjecture,"I want to set a course toward understanding Perelman's proof of the Geometrization Conjecture. I realize this will be a lengthy undertaking, but hopefully only on the order of one to two years. I am currently studying John Lee's Introduction to Smooth Manifolds and Steven Weintraub's Fundamentals of Algebraic Topology . I will be taking a graduate course on 4-manifolds next semester. Could you please suggest (1) which subject areas I should study toward this eventual goal and (2) any texts you particularly like?","['low-dimensional-topology', 'differential-geometry', 'algebraic-topology', 'geometric-topology']"
1520040,Why is the height of a pentagonal antiprism equal to the circumradius of the base?,"It is a fact (that one can verify, for example, by plugging in n=5 into the formulae on the Wolfram Mathworld page on antiprisms) that the height of a (regular) pentagonal antiprism (i.e., the pentagonal antiprism with all edges the same length and top and bottom faces regular pentagons) is equal to the circumradius of its base.  Does anyone know a (relatively) short proof of this fact that lends some nice insight into why this equality occurs?  That reveals it as something more essential than a coincidence about the trigonometric functions of angles like $\pi/5$? I have the intuition that the fact that if you augment the pentagonal antiprism with two pentagonal bipyramids you get a regular icosahedron ought to provide a quick proof of the antiprism height = base circumradius equality, but I have been unable to crystallize this intuition into a short, elegant proof.  Thanks for any insight you can provide. To elaborate somewhat, the nicest/most direct proof I know of this equality is as follows.  We first derive the exact value of the circumradius $r$ of the regular pentagon with edge-length 1 (details below); it turns out to be $r=\sqrt{\frac{5+\sqrt{5}}{10}}$. From this, the height $p$ of the equilateral pentagonal pyramid with edge-length 1 is $p = \sqrt{1-r^2} = \sqrt{\frac{5-\sqrt{5}}{10}}$. Now consider the regular icosahedron with side length 1, with one vertex at the ""north pole"" of its circumscribed sphere of radius $R$. The plane $P$ through the five vertices nearest to (but not at) the north pole cuts the icosahedron in a regular pentagon which is the top base of a pentagonal antiprism of height $h$, as well as the base of a pentagonal pyramid with apex at the north pole.  Considering the radius of the sphere from its center to the north pole, it is cut into two pieces by $P$, of lengths $h/2$ and $p$, respectively. That is, $R = h/2 + p$. On the other hand, considering the radius from the center of the sphere to one of the vertices in plane $P$, we get a right triangle with hypotenuse $R$ and legs $h/2$ and $r$.  Hence, $R^2 = (h/2)^2 + r^2$. Squaring the first equation, equating the right hand sides, and solving for $h$ yields
$$h = \frac{r^2-p^2}{p} = \frac{\frac{2\sqrt{5}}{10}}{\sqrt{\frac{5-\sqrt{5}}{10}}} = \frac{\sqrt{2}}{\sqrt{5-\sqrt{5}}} = \sqrt{\frac{5+\sqrt{5}}{10}} = r.$$ Does anyone know or can anyone find a more insightful/less computational proof of this equality? And here's the most elementary way I know of deriving $r$.  I presume the usual well-known occurrences of the golden ratio as in this diagram: Evidently from the diagram, $r^2 = a^2+\frac{1}{4}$  and $\frac{1}{\phi^2} = (a-\frac{r}{\phi^2})^2 + \frac{1}{4}$. Expanding the latter equation, substituting the first, and clearing denominators yields
$r^2(\phi^4 + 1) - 2\phi^2ar = \phi^2$. Moving the remaining term with $a$ to the right, squaring, and and substituting from the first equation again yields $r^4(\phi^4+1)^2 - 2r^2\phi^2(\phi^4+1) + \phi^4 = 4\phi^4(r^2-\frac{1}{4})r^2$. Collecting powers of $r$ gives us $r^4(\phi^8 - 2\phi^4+1) + r^2(-2\phi^6 + \phi^4 - 2\phi^2) + \phi^4 = 0$. Substituting the value of $\phi$ yields, with some calculation, $r^4\left(\frac{35+15\sqrt{5}}{2}\right) + r^2\left(\frac{-35-15\sqrt{5}}{2}\right) + \frac{7+3\sqrt{5}}{2} = 0,$ and dividing by the constant term produces the seemingly miraculous simplification $5r^4 - 5r^2 +1 = 0$, whence $r^2 = \frac{5\pm\sqrt{5}}{10}$. Examination of the magnitudes of the two roots then makes it clear that $r = \sqrt{\frac{5+\sqrt{5}}{10}}$.  A less computational demonstration of the value of $r$ would be welcome also.","['polyhedra', 'geometry']"
1520073,Is there a bijection from $\mathbb{Q} \to \mathbb{Q} \times \mathbb{Q}$?,"I am trying to prove that $\mathbb{Q}$ and $\mathbb{Q} \times \mathbb{Q}$ have the same cardinality so I must construct a bijection between the sets. I have supposed there exists a function $f: \mathbb{Q} \to \mathbb{Q} \times \mathbb{Q}$ where $f$ is 1-1 and onto but I'm not sure where to begin proving this. I doubt explicitly defining this function would be of much use, (much like how Cantor's Diagonalisation argument requires no formula as such, as it is tedius) I'm simply interested in seeing if it is possible to map every $q \in \mathbb{Q}$ to a $(r, s) \in \mathbb{Q} \times \mathbb{Q}$ and testing whether it is 1-1 and onto. I think I could use something similar to Cantor's Diagonalisation argument for a bijection from $\mathbb{N} \to \mathbb{Q}$ but I can't wrap my head around it for my case.","['elementary-set-theory', 'functions']"
1520079,If $f\in L^{+}$ and $\int f < \infty$ then there exists a null set and a $\sigma$-finite set,"This comes from Chapter 2, Real Analysis, by Folland Proposition 2.20 - If $f\in L^{+}$ and $\int f < \infty$ then $\{x:f(x) = \infty\}$ is a null set and $\{x:f(x) > 0\}$ is $\sigma$-finite proof (1st part): Let $E = \{x:f(x) = \infty\}$, then $E$ is measurable. Define a simple function $\phi_n = n1_{E} \ \ \forall n\geq 1$ with $0 \leq \phi_n \leq f$, so $$\int f \geq \int \phi_n = n\mu(E)$$ Thus, $$\frac{1}{n}\int f \geq \mu(E) \ \ \forall n\geq 1$$ Since, $0\leq \int f < \infty$ it follows that $\mu(E) = 0$ Proof (2nd part): Now, set $$\{x:f(x) > 0\} = \bigcup_{n\in\mathbb{N}}\{f(x) > 1/n\}$$ For each $n$, set $\phi_n = \frac{1}{n}1_{\{f(x) > 1/n\}}$ with $0\leq \phi_n \leq f$, so $$\int f \geq \int \phi_n = \frac{1}{n}\mu(\{f(x) > 1/n\})$$ Thus, $$n\int f \geq \mu(\{f(x) > 1/n\})$$ Since, $0\leq \mu(\{f(x) > 1/n\}) \leq n\int f < \infty \ \ \forall n$ so, $\{x:f(x) > 0 \}$ is $\sigma$-finite.","['proof-verification', 'real-analysis', 'measure-theory']"
1520116,converge of ODE solution,"for x(t) solution of $\dot{x}=f(x)$, f(x)  differentiable and the derivative continuous. show that $lim_{t\to{\infty}}x(t)=+-\infty $ or $lim_{t\to{\infty}}x(t)=$stationary point it can visualized through a graph but Im not sure how to prove it in a formal way
thanks ahead","['ordinary-differential-equations', 'derivatives']"
1520120,Modified Leibnitz integral: $\lim\limits_{a \to\infty}\frac1a\int _0^\infty\frac{(x^2+ax+1)\arctan(\frac{1}{x})}{1+x^4}dx=?$,"$\lim\limits_{a \to \infty} \frac{1}{a} \int _0^\infty\frac{(x^2+ax+1)\arctan(\frac{1}{x})}{1+x^4}dx $ ,where $a$ is a parameter. ATTEMPT:- Let $I(a)=\frac{1}{a} \int _0^\infty \frac{(x^2+ax+1)\arctan(\frac{1}{x})}{1+x^4}dx$ Now by Leibnitz theorem, $I'(a)= -\int _0^\infty\frac{(1+x^2)(arccot(x))}{(1+x^4)a^2}dx$ Substituting $x=cot\theta.$ $\implies$ $I'(a)= -\int _0^\frac{\pi}{2}\frac{(\theta)(cosec^4\theta)}{(1+cot^4\theta)a^2}d\theta$ Also  $I'(a)= -\int _0^\frac{\pi}{2}\frac{(\frac{\pi}{2})(sec^4\theta)}{(1+tan^4\theta)a^2}d\theta +\int _0^\frac{\pi}{2}\frac{(\theta)(sec^4\theta)}{(1+tan^4\theta)a^2}d\theta$ $\implies $$2I'(a)= -\int _0^\frac{\pi}{2}\frac{(\frac{\pi}{2})(sec^4\theta)}{(1+tan^4\theta)a^2}d\theta+\int _0^\frac{\pi}{2}\frac{(\theta)(sec^4\theta)}{(1+tan^4\theta)a^2}d\theta -\int _0^\frac{\pi}{2}\frac{(\theta)(cosec^4\theta)}{(1+cot^4\theta)a^2}d\theta$ Note:The last two integrals add to ZERO. $\implies$ $2I'(a)=-\int _0^\frac{\pi}{2}\frac{(\frac{\pi}{2})(sec^4\theta)}{(1+tan^4\theta)a^2}d\theta$ This integral can be easily evaluated by putting $tan\theta =t$ However I am getting $I(a)=\frac{\pi^2}{4\sqrt{2}a}.$ which is not the correct answer.","['calculus', 'limits', 'improper-integrals', 'definite-integrals', 'integration']"
1520135,Does $\lim \frac{f(x)}{g(x)}=1$ tell us anything about $\lim f(x)-g(x)$ or vice versa?,"This is not homework or anything, but I just had a random idea and I'm not really sure where to go with it. The equations:
$$ \lim_{x \to \infty} \frac{f(x)}{g(x)}=1$$
$$ \lim_{x \to \infty} f(x)-g(x) = 0$$ Are both ways of roughly saying that as $x$ gets really large, $f(x)$ and $g(x)$ get really close to each other. My question is, do either of these statements imply the other? By taking logs of the first equation, we can see that it implies 
$$\lim_{x \to \infty} \log(f(x))-\log(g(x))=0$$,
 and by exponentiating the second equation, we get that $$\lim_{x \to \infty} \frac{e^{f(x)}}{e^{g(x)}}=1$$ Other than that, I haven't really noticed anything. Anybody have any insight?","['limits', 'real-analysis']"
1520140,Two questions regarding applications of the CLT,"Suppose $X_1,\ldots,X_n$
  are iid random variables with mean $0$
  and variance $1$
 . By the CLT we know that $\frac{1}{\sqrt{n}}\sum_{i=1}^n X_i$
  converges in distribution to a standard normal distribution. Can you infer from the CLT that $\left(\frac{1}{\sqrt{n}}\sum_{i=1}^n X_i \right)^2$
converges in distribution to Chi-Squared with 1 degree of freedom? Can you infer that $\max\left\{ 0,\frac{1}{\sqrt{n}}\sum_{i=1}^n X_i\right\}$
converges in distribution to the distribution of $\max\left\{ 0,Z\right\}$ 
where $Z\sim\text{Normal}\left(0,1\right)$ ? I'm led to believe both of these things are true but I can't manage to justify to myself why. Help would be appreciated.","['probability-theory', 'central-limit-theorem']"
1520158,Why do these Integration-by-Parts Evaluation Terms Vanish?,"The Associated Legendre operator is
$$
               L_mf = -\frac{d}{dx}\left((1-x^{2})\frac{df}{dx}\right)+\frac{m^{2}}{1-x^{2}}f,
$$
where $m$ is a positive integer. For the purposes here, define the domain $\mathcal{D}(L_m)$ to be the set of twice continuously differentiable real functions on $(-1,1)$ for which $f, L_m f \in L^{2}(-1,1)$. Question: Does anyone know a way to directly verify that
$$
    \int_{-1}^{1}\{ L_m f \}g-f\{ L_m g \} dx = (1-x^{2})\{fg'-f'g\}|_{-1}^{1} = 0,
$$
for all $f,g\in\mathcal{D}(L_m)$? The integral on the left exists because the product of two square integrable functions is absolutely integrable. So the evaluation terms on the right exist as limits at $\pm 1$. The trick is to show that these limits are $0$. Background: The Associated Legendre operators show up when studying the Laplacian on the sphere. It is true that the integration by parts evaluation terms must vanish, and this can be proved indirectly by applying techniques of Functional Analysis to the operator $L_m$. It seems to me that there should be a direct way to verify such a fact using only techniques of Calculus. This is a curiosity, not some kind of homework problem, or an exercise from a text. I've tried many things and have gotten nowhere. :)","['ordinary-differential-equations', 'operator-theory', 'real-analysis', 'functional-analysis']"
1520182,"""Proportional to"" - but nonlinear.","If $A$ is proportional to $B$, then it means that $A$ varies with $B$ linearly (we're just not specifying the linear constant). Is there a similar notion for the case that $A$ increases as $B$ increases, but in the case that this relationship isn't necessarily linear? I'm looking for something like ""$A$ is ______ to $B$"".","['terminology', 'functions']"
1520183,two generalizations of Lax-Milgram theorem,"Apart from the classic Lax-Milgram theorem which is powerful under the Hilbert setting, there are two generalizations: (from Wikipedia) Babuska-Lax-Milgram theorem suppose $U,V$ Hilbert spaces (real-valued), $B: U\times V\rightarrow \mathbb{R}$ a continuous bilinear form, if $B$ is weakly coercive: for some constant $c>0$, $\forall u\in U$,
$$
\sup_{||v||=1}B(u,v)\geq c||u||
$$
and for all $0\neq v\in V$
$$
\sup_{||u||=1}|B(u,v)|>0
$$
then for $f\in V^\ast$, there exists an unique solution $u_f\in U$ to the weak formulation:
$$
B(u_f,v)=(f,v),\quad \forall v\in V
$$
moreover, the solution depends continuously on the datum:
$$
||u_f||\leq\frac{1}{c}||f||
$$ Lions-Lax-Milgram theorem Let $H$ a Hilbert space and $V$ a normed space, $B:H\times V\rightarrow \mathbb{R}$ a continuous bilinear form, the following are equivalent: for constant $c>0$,
$$
\inf_{||v||_V=1}\sup_{||h||_H\leq 1}|B(h,v)|\geq c;
$$
for each continuous linear functional $f\in V^\ast$, there exists $h\in H$ s.t.
$$
B(h,v)=(f,v)\quad \forall v\in V.
$$ I am thinking are there any specific reason or problem to apply these two theorem? In Wikipedia, it says the second theorem may be useful for problem with time-dependent boundary where the classic Lax-Milgram cannot apply, but it does not provide more justification like how the second one can prove the existence. 
Does someone see these two theorem applied in any specific problem? It would be great if you can offer some links or reading list for me.","['functional-analysis', 'partial-differential-equations']"
1520224,How to integrate a 4th power of sine and cosine?,"I'm having some trouble figuring out the right substitutions to make to integrate $$\int \sin^4(\theta)d\theta$$ and $$\int \cos^4(\theta)d\theta$$ Any hints or suggestions are welcome. Thanks,","['trigonometry', 'calculus', 'real-analysis', 'integration']"
1520244,Maximization via Lagrange multipliers vs. substitution and partial derivatives,"Consider the example of maximizing $x^2 y z$ under the constraint that $x^2 + y^2 + z^2 = 5$. One way to do this is to use lagrange multipliers, solving the system of equations $$2xyz = 2x \lambda$$
$$x^2 z = 2 y \lambda$$
$$x^2 y = 2 z \lambda$$
$$x^2 + y^2 + z^2 = 5$$ However, couldn't you just substitute $x^2 = 5 - y^2 - z^2$ into the expression you want to maximize to get: $y z \left(-y^2-z^2+5\right)$ and then just maximize that by setting the $y$ and $z$ partial derivatives equal to zero? Then you just have to solve the arguably simpler system of equations: $$3 y^2 z+z^3=5 z$$
$$y^3+3 y z^2=5 y$$ where the $z$s and $y$s cancel out nicely on both sides. Why is maximize by lagrange multipliers necessary when you can always substitute and maximize the resulting function? When should you choose one over the other?","['calculus', 'partial-derivative', 'multivariable-calculus', 'optimization', 'lagrange-multiplier']"
1520268,Proof that a set is non-star-shaped.,"Note: A subset $S\subseteq \mathbb{R}^2$ is called star-shaped if there exists an element $x\in S$ such that for every $y\in S$, the line segment connecting $x$ to $y$ is contained in $S$. We want to give an example of a non-star shaped subeset of $\mathbb{R}^2$ and carefully prove it is not star-shaped. I have begun by giving my example of a set that is not star shaped. It is the set of all points between the two circles, $x^2+y^2=1$ and $x^2+y^2=4$. This set looks like an Annulus, as shown below. To me, it is obvious that this set is not star shaped, because there is no point in the set that will not have to cross the circle in the middle of the set in order to make a line segment to every other point in the set. I don't know how to prove this, however. Perhaps it is easier to prove giving a different example of a nonstar shaped set. Any help would be greatly appreciated.","['geometry', 'convex-analysis']"
1520348,Term by Term Differentiability in the context of Uniform Convergence,"I'm not sure how differentiability works with uniform convergence. My book says that we can show this (calculation wise) $$\varepsilon (x,a) = \sum_{k=1}^{\infty} E_{k}(x,a)$$ for some $x$ and $a$. In this context, I'm not sure how to go about doing this: Prove that $$f(x)=\sum_{n=1}^{\infty}\frac{1}{n^{2}+x^{2}}$$ is differentiable for all values of $x$. If someone could give me a hand, that would be great. My book has no examples in this topic, so I just chose one of the first questions from it. (If more context is needed, please let me know. This is my first stackexchange question.)","['real-analysis', 'sequences-and-series', 'uniform-convergence', 'analysis', 'derivatives']"
1520353,Taking the connected sum of four closed disks... What do we get?,"If we take the connected sum of four closed disks $S = 4 \mathbb{\overline{D}} = \mathbb{\overline{D}} \# \mathbb{\overline{D}} \# \mathbb{\overline{D}} \#  \mathbb{\overline{D}}$, what does $S$ look like and how do we describe the boundary? (This has been resolved) Is it just a $2$-sphere, since $ \mathbb{\overline{D}} \# \mathbb{\overline{D}}  = \mathbb{S}^2$ and $ \mathbb{S}^2 \# \mathbb{S}^2 = \mathbb{S}^2?$ How do we write down a plane model for this surface? If $S = 4 \mathbb{\overline{D}}$ is an annulus, would it just have the same plane model as the cylinder? (Since they are homeomorphic)",['general-topology']
1520377,Understanding Radon Nikodym derivative,"I am trying to understand the Radon Nikodym derivative. My professor often writes the measure change from $\mathbb{P}$ to $\mathbb{Q}$ as:
$$\eta_t=\dfrac{d\mathbb{Q}}{d\mathbb{P}}|_{\mathscr{F}_t}$$ 
But then he might write the measure change from $\mathbb{Q}$ to $\mathbb{Q^*}$ as 
$$\dfrac{d\mathbb{Q^*}}{d\mathbb{Q}}|_{\mathscr{F}_T}$$ 
What does the notation ""given"" ${\mathscr{F}_T}$ mean here? In one part of my lecture notes, he writes:
$$\dfrac{d\mathbb{Q^*}}{d\mathbb{Q}}|_{\mathscr{F}_T} = \dfrac{e^{-r_T}}{E_0[e^{-r_T}]}$$ 
Does $E_0[e^{-r_T}] = E[e^{-r_T}|\mathscr{F}_0]$? What meaning does this have?
Using the definition of $r_t$ (which I have left out purposefully since it adds no value to the question, one can easily calculate:
$$\tilde{\eta_T}:=\dfrac{d\mathbb{Q^*}}{d\mathbb{Q}}|_{\mathscr{F}_T}$$ where $k \in \mathbb{R}$.
Does this equation hold for every $t \leq T$? In particular, does 
$$\tilde{\eta_t}:=\dfrac{d\mathbb{Q^*}}{d\mathbb{Q}}|_{\mathscr{F}_t}?$$ 
I suppose my question may be like a notation one, but I am hoping this notation is well known enough for someone to explain it to me here. To paraphrase my questions:
What meaning does $E_0[]$ have?
What does it mean to calculate the Radon Nikodym derivative with respect to a filtration at time $t$? How can I better understand this notation?","['probability-theory', 'measure-theory']"
1520389,Finding nonsimilar solutions to the matrix equation $ Y^2 = Y $.,"Let $Y \in M_n $. We have $ Y^2 = Y \Longleftrightarrow Y(Y-I) = 0 $. This means that the vectors in $ Y-I $ are in the nullspace of $ Y$. This means that $ Y $ is a projection (also because the characteristic polynomial is $x^2-x=0$, which has the only roots 0 and 1). Non-similar solutions are then given by non-similar projection matrices, which should be those with unequal ranks. There are thus $n$ non-similar solutions (from rank 1 to rank $n$ projections, where a rank $n$ projection would be defined to just be a positive-definite unitary matrix; if one counts the zero matrix, then that would be $n+1$ solutions, I guess). Since projections are diagonalizable, it is pretty trivial that projections of equal rank are similar to each other. Is there more to this problem than meets the eye?
Edit: the rank-$n$ projection should just be the identity matrix, I believe.","['linear-algebra', 'matrices']"
1520398,"If $g$ is differentiable and $g(1/n)=0$ for all $n$, then $g(0)=0$ and $g'(0)=0$","Suppose that $g:\mathbb{R}\rightarrow\mathbb{R}$ differentiable at $x=0$ and for each natural number $n$, $g(1/n)=0$. Prove that $g(0)=0$ and $g'(0)=0$ Since $g$ is differentiable at $x=0$, so $g$ is continuous at $x=0$ and gives $\lim\limits_{x\rightarrow0}g(x)-g(0)=0$. As for all $n\in\mathbb{N}$, $g(1/n)=0=\lim\limits_{x\rightarrow0}g(x)-g(0)$. I stuck at this step, I don't see any information that I can use to get further. Can someone give me a hit or suggestion to keep going? Thanks","['real-analysis', 'derivatives']"
1520408,Solving $10x^4-13x^2+4=0$,"I just came across a question in my paper that asks me to solve for $x$ in $10x^4-13x^2+4=0$ I've only learned how to factorize quadratics and the quadratic formula, but I'm not sure how to factorize quartics. Is there a way that I can apply my current knowledge to solve for this problem or if not, how would I be able to solve it? For reference, the answer is $(5x^2-4)(2x^2-1)$ and therefore $x^2=0.8$ or $0.5$","['factoring', 'quadratics', 'algebra-precalculus']"
1520422,"The polynomial $p(x)=a_0+a_1x+a_2x^2+\cdots +a_nx^n$ has a zero in $[0,1]$ under a given condition","Show that the polynomial $p(x)=a_0+a_1x+a_2x^2+\cdots +a_nx^n$ has a zero in $[0,1]$ when it is given that, $$ \frac{a_0}{1\cdot 2}+\frac{a_1}{2\cdot 3}+\cdots+\frac{a_n}{(n+1)(n+2)}=0.$$ First we consider the function, $\displaystyle f(x)=\frac{a_0}{1\cdot 2}x^2+\frac{a_1}{2\cdot 3}x^3+\cdots+\frac{a_n}{(n+1)(n+2)}x^{n+2}$ . Then, $f(0)=0$ and $f(1)=0$ . Then by Rolle's theorem, $\exists$ $y\in (0,1)$ such that $f'(y)=0$ which gives, $\displaystyle a_0y+\frac{a_1}{2}y^2+\cdots +\frac{a_n}{n+1}y^{n+1}=0$ . Next consider, $\displaystyle g(z)=a_0z+\frac{a_1}{2}z^2+\cdots +\frac{a_n}{n+1}z^{n+1}$ . Then, $g(0)=0$ and $g(y)=0$ . So by Rolle's theorem, $\exists$ $w\in (0,y)\subset (0,1)$ such that $g'(w)=p(w)=0.$ Hence the proof is complete. Is this proof is correct? I think it is correct. But I am looking for an another proof so that I can avoid two times consideration of functions such as $f$ and $g$ .","['analysis', 'continuity', 'real-analysis']"
1520424,probability calculation for bayesian network,"I am studying Bayesian belief networks and in that I am struggling to understand how probabilities are calculated. 
I found this article here and the network is this: The associated probabilities are: I don't understand how the probability P(Tampering=true|Report=T) is calculated. How I did it was P(Alarm=T|Tampering=T,Fire=T)*P(Leaving=T|Alarm=T)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=F)*P(Leaving=T|Alarm=T)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=T)*P(Leaving=T|Alarm=F)*P(Report=T|Leaving=T)*P(Tampering=T)+
  P(Alarm=F|Tampering=T,Fire=F)*P(Leaving=T|Alarm=F)*P(Report=T|Leaving=T)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=T)*P(Leaving=F|Alarm=T)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=T|Tampering=T,Fire=F)*P(Leaving=F|Alarm=T)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=T)*P(Leaving=F|Alarm=F)*P(Report=T|Leaving=F)*P(Tampering=T)+ P(Alarm=F|Tampering=T,Fire=F)*P(Leaving=F|Alarm=F)*P(Report=T|Leaving=F)*P(Tampering=T) which gives me a value= 0.017989 But the given answer for P(tampering=T|report=T) = 0.399 How do I calculate this probability","['bayesian-network', 'probability', 'statistics']"
1520428,"Automorphisms of $\mathbb{C}[x_1, \dots, x_n]$","Are the linear transformations, and the automorphisms
of the form $\sigma(x_1, \dots, x_n) = (x_1 -f(x_2, \dots, x_n), x_2, \dots, x_n)$, where $f$ is a polynomial, generators of the group of automorphisms of $\mathbb{C}[x_1, \dots, x_n]$? If this is true, where can I find a good reference? Thanks in advance.","['algebraic-geometry', 'several-complex-variables']"
1520458,Motivation of Vieta's transformation,"The depressed cubic equation $y^3 +py + q = 0$ can be solved with Vieta's transformation (or Vieta's substitution ) $y = z - \frac{p}{3 \cdot z}.$ This reduces the cubic equation to a quadratic equation (in $z^3$). Is there any geometric or algebraic motivation for this transformation? I am not asking why this transformations works - this is just an easy calculation. I would rather like to know how to come up with it. Perhaps even how and when Vieta came up with it. I haven't found anything about the history of this transformation, except that it probably wasn't invented by Vieta . Notice that the Ansatz $y = z + \frac{c}{z}$ for a constant $c$ will eventually lead to $c = -\frac{p}{3}$, but what motivates this Ansatz - except for that it works in the end? Here is what I guess (but this is not convincing yet): Polynomial transformations do not work, so let's try rational transformations. Try to keep the degree low. I am aware of Galois theory and how it helps to understand the cubic from a highly conceptual point of view, but I would like to avoid Galois theory here. Any information about the history of this transformation will also be appreciated.","['motivation', 'soft-question', 'math-history', 'algebra-precalculus', 'cubics']"
1520465,Reference books for learning matrices from the beginning?,I am going to learn about matrices by myself. Can anyone recommend me some good books on matrices with exercises.,"['reference-request', 'matrices']"
1520472,Are pseudoheaps and heaps the same thing?,"An exercise in a category textbook asked me to show that the category of pointed heaps and the category of groups are isomorphic. But my proof somehow didn't use the most unintuitive of the defining equations of a heap at all, i.e. $[[a,b,c],d,e] = [a,[d,c,b],e]$. According to wikipedia : Formally, a heap is an algebraic structure consisting of a non-empty set $H$ with a ternary operation denoted $[x,y,z]\in H$ that satisfies the para-associative law
  $$[[a,b,c],d,e] = [a,[d,c,b],e] = [a,b,[c,d,e]] \ \forall \ a,b,c,d,e \in H$$ the identity law
  $$[a,a,x] = [x,a,a] = x \ \forall \ a,x \in H.$$ A group can be regarded as a heap under the operation $[x,y,z] = xy^{-1}z$. Conversely, let $H$ be a heap, and choose an element $e \in H$. The binary operation $x*y = [x,e,y]$ makes $H$ into a group with identity $e$ and inverse  $x^{-1} = [e,x,e]$. A heap can thus be regarded as a group in which the identity has yet to be decided. But the case were $[[a,b,c],d,e] = [a,[d,c,b],e]$ is omitted seems to be called pseudoheap: A pseudoheap or pseudogroud satisfies the partial para-associative condition
  $$[[a,b,c],d,e] = [a,b,[c,d,e]].$$ The Mathematical Structures repository didn't contain heaps at all. Another document document mentioning heaps defined pseudo-associative and semiheaps, but not pseudoheaps. (I think I heard of heaps before, but don't remember where anymore.) I asked automatic theorem provers whether the unintuitive equation follows from the other equations, and apparently it does: prover9: pseudoheap.in -> pseudoheap.out E-theorem prover: pseudoheap.lop -> pseudoheap.proof Was it simply a bad idea of wikipedia to mention pseudoheaps at all, because they are utterly unimportant? Did I just misinterpret the definition of pseudoheap from wikipedia? Is there some better source of information about heaps (and pseudoheaps)?","['abstract-algebra', 'group-theory', 'universal-algebra', 'reference-request']"
1520493,Show that a subsequence of a Cauchy subsequence is also Cauchy,"My approach for solving this problem was to first prove that the sequence is convergent and then use that to prove that the subsequence is convergent and therefore Cauchy. I'm pretty sure this process seems right but I'm not sure how to exactly prove this. If anyone can help, I'd appreciate it. Thanks","['analysis', 'sequences-and-series', 'cauchy-sequences']"
1520512,Every dominated sequence of measurable functions is uniformly integrable?,"This is an exercise from tao's blog . A sequence $f_n:X\to\mathbf{C}$ of absolutely integrable functions is said to be uniformly integrate if the following three statements hold: (Uniform bound on $L^1$ norm) One has $\sup_n\|f_n\|_{L^1(\mu)}=\sup_n\int_X |f_n|\,d\mu<\infty$. (No escape to vertical infinity) One has $\sup_n\int_{|f_n|\geq M}|f_n|\,d\mu\to 0$ as $M\to \infty$. (No escape with width infinity) One has $\sup_n\int_{|f_n|\leq\delta}|f_n|\,d\mu\to 0$ as $\delta\to 0$. Show that every dominated sequence of measurable functions is uniformly integrable. Let $(f_n)_{n=1}^\infty$ is a sequence of measurable function dominated by some absolutely integrable function $g$, that is $|f_n|\leq g$ for all $n=1,2,\dots$. The first statement is trivial. Note that
$$\int_{|f_n|\geq M}|f_n|\,d\mu\leq \int_{|f_n|\geq M}g\,d\mu\leq\int_{|g|\geq M}g\,d\mu,$$ 
then using dominated convergence theorem, the second statement follows. Now  I have trouble in verifying the third statement, since $g\leq\delta$ is contained in $|f_n|\leq\delta$, the above argument doesn't work.","['real-analysis', 'measure-theory']"
1520513,Proof that finite group contains an element of prime order,I tried to prove the following claim but it seemed a bit too easy: Let $G$ be a finite group. Then $G$ contains an element of prime order. Please could someone tell me if my proof is correct or if I'm missing something? Let $g$ be any non-identity element of $G$. Let $p$ be any prime factor of $|g|$. Then $g^{|g|\over p}$ has prime order $p$. $\Box$,"['abstract-algebra', 'group-theory', 'proof-verification']"
1520516,"Find the volume of the solid bounded above by the cone $z^2 = x^2 + y^2$, below by the $xy$ plane, and on the sides by the cylinder$ x^2 + y^2 = 6x$.","Q: Find the volume of the solid bounded above by the cone $z^2 = x^2 + y^2$, below by the xy plane, and on the sides by the cylinder $x^2 + y^2 = 6x$. I can't figure out what I'm doing wrong in my setup. I keep getting $0$ for the volume value based on my setup. However, if you sketch the volume out, it seems like there should be a volume in 3d for this shape. My Work $\int{_{0}^{2\pi}\int{_{0}^{6cos\theta}\int{_{0}^{r}r dzdrd\theta}}}$ Since the xy plane was a bound, I assumed you needed the top part of the cone so $z = \sqrt{x^2+y^2}$ or $z = r$ for the top z bound. Since $x^2 + y^2 = 6x$, polar conversion equations give $r^2 = 6rcos\theta$ or $r^2 - 6rcos\theta=0$ so $r=0$ and $r = 6cos\theta$ from that. $x^2 + y^2 = 6x$ is a full circle so I let $\theta = 0$ to $\theta = 2\pi$ bounds. There is a shift in the circle but I don't believe it affects the $\theta$ bounds.","['polar-coordinates', 'volume', 'multivariable-calculus', 'integration']"
1520541,Divergence in Definition of Laplace-Beltrami Operator,"I am trying to derive an explicit formula for Laplace-Beltrami operator in global Cartesian coordinates for a special case of plane curve.
I have found this article , and I would like to match their expression (6) for LB on a curve with the standard definition in terms of metric tensor . According to formula $(6)$ in the paper , Laplace-Beltrami operator on plane curve can be written as \begin{align}
\Delta_{LB}\, u & = \Delta u + \kappa\,u_{n} - u_{nn}
\\ & = \tag{$\star$}
\Delta u + \kappa\,\vec{n}\cdot\nabla u - \vec{n}\cdot\nabla\left(\vec{n}\cdot\nabla u\right) 
\end{align} $\,\vec{n}\,$ is unit normal vector, $\,\kappa=-\nabla\cdot\vec{n}\,$ is curvature , $\,u_{n} = \vec{n}\cdot\nabla u\,$ and $\,u_{nn} = \vec{n}\cdot\nabla \left(\vec{n}\cdot\nabla u\right)\,$ are first and second normal derivatives , $\,\nabla u\,$ and $\,\Delta u\,$  are respectively gradient and Laplacian of $\,u\,$. I am having troubles deriving $(\star)$ or matching it with metric tensor expression for LB operator \begin{align}\tag{$\ast$}
\Delta_{LB}\, u = \dfrac{1}{\sqrt{\left\lvert g\right\rvert}}\,\partial_i\,\Big(\sqrt{\left\lvert g\right\rvert} \,g^{ij}\,\partial_j \,u \Big)
\end{align} I can derive $(\star)$ from the Laplace-Beltrami expression $\,\Delta_{LB}\,u = \nabla_{s}\cdot\big(\nabla_{s}\,u\big)\,$ assuming surface divergence of a vector equals to the regular divergence of its projection to the curve . This is a BIG assumption, and I do not know how to justify it.
I will appreciate if someone could help me to justify my assumption, or to derive $(\star)$ without assumptions on (surface) divergence. My attempt to derive $(\star)$:
let $\,\nabla_{s}\,$, and $P$ denote surface gradient and projecting operator , then \begin{align}
\Delta_{LB}\, u & = \nabla_{s}\cdot\big(\nabla_{s}\,u\big) \stackrel{\color{red}{\huge ?}}{=} \nabla\cdot\big(\nabla_{s}\,u\big) 
\\ & = \nabla\cdot\big(P\;\nabla \,u\big) 
     = \nabla\cdot\Big(\nabla\,u-\big(\vec{n}\cdot\nabla\,u\big)\,\vec{n}\Big)
\\ & = \Delta\,u-\left(\nabla\cdot\vec{n}\right)\left(\vec{n}\cdot\nabla u\right)-     
       \vec{n}\cdot\nabla\left(\vec{n}\cdot\nabla u\right) 
\\ & = \Delta u + \kappa\,u_{n} - u_{nn}
\end{align}","['laplacian', 'differential-operators', 'plane-curves', 'differential-geometry', 'derivatives']"
1520547,Number of Orientations of Disconnected Manifold,"This seems like a stupid question, but the number of orientations of a smooth manifold with $n$ maximal connected components would be $2^n$, right? Since each connected component $U\subset M$ is open $\Rightarrow$ $U$ is a (connected) manifold and hence has two orientations.","['smooth-manifolds', 'differential-geometry', 'manifolds']"
1520577,Lemmata about equivalence relations,"We've defined relations and equivalence relations a few days ago at university. I tried to look at them a bit more abstract and came up with two lemmata. I am going to write them down with my proofs and it would be nice to let me know what you think of them. Are they useful/useless, are the proofs right/wrong etc... Lemma 1: Be $Z$ a set and be $\sim$ an equivalence relation on a set $M$.
Be $f$ a function with $f: M \rightarrow Z$ and be $g$ a function with $g: M \rightarrow M$ $f$ and $g$ also fulfill the following:
\begin{align}
&\forall x,y \in M: f(x) = f(y) \implies g(x) = g(y)\\
&\forall x \in M: x \sim g(x)
\end{align} It follows: $$\forall x,y \in M: f(x) = f(y) \implies x \sim y$$ Proof. Be $x,y \in M$ and be $f(x) = f(y)$. It follows $g(x) = g(y)$ and because $\sim$ is an equivalence relation it holds: $$x \sim g(x) \sim g(y) \sim y \quad \square$$ Lemma 2: Be $Z$ a set and be $\sim$ an equivalence relation on a set $M$.
Be $f$ a (surjective) function with $f: M \rightarrow Z$. Be also $X \subseteq M$ and be $f \mid_X$ bijective. $f$ also fulfills the following: $$\forall x,y \in M: x \sim y \Longleftrightarrow f(x) = f(y)$$ It follows: $$M/_\sim = \{[a]_\sim \mid a \in X\}$$ and $$\forall x,y \in X: x \sim y \implies x=y$$ Proof. $M/_\sim \supseteq \{[a]_\sim \mid a \in X\}$ is trivial. Be $x \in M/_\sim$ and be $x' \in x$. It holds $f(x') \in Z$. $f \mid_X$ is surjective, hence there is a $y \in X$ with: $$f(y) = f(x')$$
Hence $y \sim x'$, which yields $[y]_\sim = [x']_\sim$. Finally: $$M/_\sim \subseteq \{[a]_\sim \mid a \in X\}$$ Be now $x,y \in X$ and be $x \sim y$.
It follows $f(x) = f(y)$ and since $f \mid_X$ is injective, we get: $$x=y \quad \square$$","['elementary-set-theory', 'equivalence-relations']"
1520582,Number of ways to cover n×n chess board with stones of three different colors,"I'm struggling with this problem for a few days and I'm unable to find the solution. Could someone please help me? Question is: How many ways there is to cover a n×n chessboard with red, yellow and blue stones, so that on every square there is only one stone and no row or column is filled with stones of only one color? What if you had only red and yellow stones?
Number of stones of each color is unlimited. Thank you in advance for your help.","['discrete-mathematics', 'combinatorics']"
1520615,Convergence of the fdds vs convergence in distribution in a function space,"I'm trying to understand the essential difference between two common types of the convergence of random processes: the weak convergence of the finite-dimensional distributions (fdds) and the convergence in distribution in some function space (for example, $\mathcal D[0,1]$ or $\mathcal C[0,1]$). Suppose that $\xi_1,\xi_2,\ldots$ are i.i.d. random variables and with zero means and unit variances. Define
$$
W_n(t)=\frac1{\sqrt n}\sum_{k=1}^{\lfloor nt\rfloor}\xi_k
$$
for $n\ge1$ and $t\in[0,1]$ and let $W$ be the standard Wiener process. We know that the fdds of $\{W_n:n\ge1\}$ converge weakly to the fdds of $W$. Furthermore, by Donsker's theorem , as random variables taking values in the Skorokhod space $\mathcal D[0,1]$, the random functions $\{W_n:n\ge1\}$ converge in distribution to $W$. Since the Skorokhod space $\mathcal D[0,1]$ is complete and separable, the convergence in distribution is equivalent to the weak convergence of the fdds and the tightness of the corresponding probability measures. So the convergence in distribution in $\mathcal D[0,1]$ implies the weak convergence of the fdds. Hence, the convergence in distribution in $\mathcal D[0,1]$ is a stronger result. It seems that I understand the mathematical meaning of these two types of convergence and the fact that convergence in distribution in $\mathcal D[0,1]$ implies the weak convergence of the fdds. But are there any reasons to prove the convergence in distribution in some function space apart from the fact that this is a stronger result? What is the difference between convergence in distribution in $\mathcal C[0,1]$ and $\mathcal D[0,1]$? Why don't we investigate convergence in $L_2[0,1]$, for example? What are the reasons to choose a particular function space? Some examples would be really great and any help is much appreciated!","['probability-theory', 'stochastic-processes', 'random-functions', 'convergence-divergence', 'weak-convergence']"
1520622,Non-circular proof of $\lim_{\theta \to 0}\frac{\sin\theta}{\theta} = 1$,"$$\lim_{\theta \to 0}\frac{\sin\theta}{\theta} = 1$$
The above limit is fundamental to studies of introductory calculus. I know that this limit could be proven by the squeeze theorem and the length of sector , i.e. $$s = r\theta$$ where r is radius and $\theta$ the angle.
However, it is claimed that the proof of this limit is circular. I can't bring myself to agree to that, but apparently the length of sector is a corollary of the limit , which is proven by the inequality $$\cos \theta < \frac{\sin\theta}{\theta} < 1$$ Can anyone point me to other proofs of the limit?","['calculus', 'trigonometry']"
1520644,Easy question that I can't do: Find all continuous functions satisfying $\left\|\int_0^1 f\right\|= \int_0^1 \|f\|$,"I am trying to find all continuous functions $f: [0,1] \to \mathbb R^n$ satisfying: $$\left\|\int_0^1 f\right\|= \int_0^1 \|f\|$$ Any hints? I have tried lots of things, none of which have worked. I have found plenty of functions that work, but have no idea how to describe the entire set. I have tried writing the integral as Riemann sums and using the analogy of the vector triangle inequality, which wasn't helpful. I have tried looking at specific norms to get some necessary conditions, but didn't get far with that either. For $\mathbb R^1$ a necessary condition would be that $f$ is always positive or always negative.","['real-analysis', 'definite-integrals']"
1520670,Use De Moivre's Theorem to express $\sin(3\theta)$ in terms of the powers of $\sin (\theta)$ and $\cos(\theta)$,"There are quite a few resources on this question but I seem to be at a point where I cannot find a resource to match my scenario I tackle questions like this in 3 steps: 1) Apply De Moivre's Theorem 2) Use Pascals Triangle (Proves quicker for me than the method of Binomial Expansion) 3) Know your Trig Identities because this is where you're headed My working so far: $(\cos\theta + i \sin\theta)^3$ = $(\cos3\theta + i \sin3\theta)$ By De Moivre's Theorem For this specific problem I am using the 1 3 3 1 tier of Pascal's Triangle Now I apply this with my powers incremented by 1 for cos and decremented by 1 for sin. (Hope this makes sense?) $1\cos^3\theta i^0 \sin^0\theta + 3\cos^2\theta  i^1 \sin^1\theta + 3\cos^1\theta  i^2 \sin^2\theta + \cos^0\theta  i^3 \sin^3\theta$ Now I know $i^2 = (-1)$ so I proceed as follows: $\cos^3\theta + 3\cos^2\theta i \sin\theta - 3\cos\theta \sin^2\theta - i\sin^3\theta$ Now I would equate the real and imaginary parts as follows: $\cos3\theta = \cos^3\theta +  3\cos\theta \sin^2\theta $ $\sin3\theta = 3\cos^2\theta i \sin\theta +  \sin^3\theta$ I know that I am supposed to derive the cube trig identities here namely: $\cos3\theta = 4\cos^3\theta - 3\cos\theta$ $\sin3\theta = 3\sin\theta - 4\sin^3\theta$ Perhaps I've missed something here. My workings of $\cos4\theta$ and $\cos2\theta$
are spot on though. Thanks for taking the time.","['complex-numbers', 'trigonometry']"
1520685,Prove an equality ($L^P$ spaces),"Prove the equality
$$\int |f(x)|^p dx=\int_0^\infty pt^{p-1}m(\left\lbrace x:|f(x)|\geq t\right\rbrace)dt$$
for $p\geq 1$. My first idea was to try to prove this via induction.  For the case $p=1$, the left side becomes $\|f\|_1,$ and that's going to be finite since we are in $L^1$.  Now I think the right hand side becomes
$$t\cdot m(\left\lbrace x:|f(x)|\geq t\right\rbrace)\Big\vert_0^\infty=\lim_{t\rightarrow\infty}t\cdot m(\left\lbrace x:|f(x)|\geq t\right\rbrace).$$  By a previous exercise I have done a few weeks ago, this limit should go to zero. As it stands, I can't get the two sides equal to each other, and that is only in the $p=1$ case.  Is there a better way to attack this?","['lp-spaces', 'lebesgue-integral', 'measure-theory']"
1520722,"Question about Quotient space, regarding The left coset space of group $G$ with respect to a subgroup $H$","Let $G$ is a left topological group and $H$ is a subgroup of $G$. Denote by $G/H$ the set of all left cosets 
$aH$ of $H$ in $G$ (for each $a\in G$), and endow it with the quotient topology with respect to the canonical mapping $\pi$. Then the space $G/H$ is called the left coset space of $G$ with respect to $H$. A left topological group consists of a group $G$ and a topology $\mathfrak{T}$ on the set $G$ 
  such that for all $a\in G$, the left action $\mathfrak{l}_a$ of $a$ on $G$ is a continuous mapping of the space $G$ 
  to itself. It is not true that a quotient map is necessarily open( Example of quotient mapping that is not open ) but in this case, why $\pi$ is open? EDIT: The following theorem Notes that, $\pi$ is open; But i do not understand why? Thank you for taking the time.","['topological-groups', 'general-topology']"
1520732,Evaluating $\int_0^\infty \frac{\ln x}{x^2+2x+2}dx$ [duplicate],"This question already has answers here : Real integral by keyhole contour (2 answers) Closed 8 years ago . $$\int_0^\infty \frac{\ln x}{x^2+2x+2}dx$$
A question similar to this one has been asked before here , but there the quadratic doesn't have a constant term. I tried to use completing the square and use the answers in the linked question but since the log term in the numerator has $x$ not $x+1 $(after completing the square the quadratic is $(x+1)^2 + 1$) so that doesn't seem to work.","['logarithms', 'calculus', 'integration']"
1520751,How to understand that a distribution has no mean?,"I've learned that Cauchy distribution doesn't have mean, i.e. the integral $\int_{-\infty}^\infty xf(x,x_0,\gamma)dx$ diverges. But it still has Cauchy principal value equal to location parameter $x_0$. So from the divergence of the integral I might conclude that sequence of averages of larger and larger samples won't converge to anything in any sense. But is it really true, or does the existence of Cauchy principal value still allow the sequence of averages to converge to $x_0$?","['means', 'statistics', 'probability-distributions']"
1520790,Curvature on product Riemannian manifolds,"I am working on the following problem from Lee's Riemannian Manifolds : Suppose $g = g_1 \oplus g_2$ is a product metric on $M_1 \times M_2$   (i.e. $$g(X_1+X_2,Y_1+Y_2) = g_1(X_1,Y_1)+g_2(X_2,Y_2),$$ where $$X = X_1 + X_2, Y = Y_1+Y_2 \in T_{(p_1,p_2)}(M_1 \times M_2) = T_{p_1}M_1 \oplus T_{p_2}M_2.$$ (a) Show that for each point $p_i \in M_i$, the submanifolds $M_1 \times \{ p_2 \}$ and $\{ p_1 \} \times M_2$ are totally geodesic. (b) If II $\subseteq T(M_1 \times M_2)$ is a 2-plane spanned by $X_1 \in TM_1$ and $X_2 \in TM_2$, show that $K$(II) $= 0$ (the sectional curvature is $0$). (c) Show that the product metric on $S^2 \times S^2$ has nonnegative sectional curvature. (d) Show that there is an embedding of $T^2$ in $S^2 \times S^2$ such that the induced metric is flat. For part (a), I think I should be showing that the second fundamental form vanishes identically, but I'm not having any luck actually proving that.  I tried using the Weingarten equation, but got nowhere.  For part (b), I think that, using the formula for sectional curvature, this reduces to showing that $Rm(X_1,X_2,X_2,X_1) = 0$, but again I'm not having any luck proving that.  For (c), I think that if we take an arbitrary plane and use an orthonormal basis, we might be able to get something, but to be honest I'm just totally lost.  I have no idea for part (d).  Any help is MUCH appreciated!!!","['differential-geometry', 'manifolds', 'riemannian-geometry', 'curvature']"
1520806,Is $(\oplus\ell_2^n)_{\ell_1}$ complemented in $\ell_1\oplus_\infty\ell_p$?,"Fix any $1<p\leq 2$.  Let us recall that $E:=(\oplus\ell_2^n)_{\ell_1}$ is just the space of sequences $(x_n)_{n=1}^\infty$, $x_n\in\ell_2^n$, such that $(\|x_n\|_{\ell_2^n})_{n=1}^\infty\in \ell_1$, endowed with the norm $\|(x_n)_{n=1}^\infty\|_E=\sum_{n=1}^\infty\|x_n\|_{\ell_2^n}$.  Also, $\ell_1\oplus_\infty\ell_p$ is just the space of ordered pairs $(x,y)$, $x\in\ell_1$, $y\in\ell_p$, endowed with the norm $\|x\oplus y\|_\infty=\max\{\|x\|_{\ell_1},\|y\|_{\ell_p}\}$. Question. Is the space $E=(\oplus\ell_2^n)_{\ell_1}$ complemented in $\ell_1\oplus_\infty\ell_p$?  In other words, does there exists a continuous linear projection $P\in\mathcal{L}(\ell_1\oplus_\infty\ell_p)$ onto a subspace isomorphic to $E$? Recall that $\ell_2^n$'s are uniformly complemented in $\ell_p^{k_n}$ for some increasing sequence of positive integers $k_1<k_2<k_3<\cdots$, and uniformly embedded (but not complementably) into $\ell_1^{k_n}$.  (See Theorem 4.10 here for the first fact.  The second fact is just an application of Dvoretsky's Theorem.)  Perhaps these two facts might help to construct a projection. Thanks!","['lp-spaces', 'banach-spaces', 'functional-analysis']"
1520807,Not isomorphic graphs with same spectrum - exists?,"I am wondering if there exists two graphs, which are not isomorphic with the condition that both of them have the same spectrum. Two graphs are isomorphic when they may be drawn in the same way. Spectrum I mean set of all eigenvalues of the matrix of the graph. https://en.wikipedia.org/wiki/Spectrum_of_a_matrix Anybody may give me hint or some suggestions ? Or maybe this problem is already solved in math ? I have seen the closiest topic to mine: Given two non-isomorphic graphs with the same number of edges, vertices and degree, what is the most efficient way of proving they are not isomorphic? , however it is not direct answer to mine wonders, since the eigenvalues may be different in those graphs if I am correct.","['graph-theory', 'graph-isomorphism', 'eigenvalues-eigenvectors', 'matrices']"
1520866,Limit of a sum of infinite series,"How do I find the following? $$\lim_{n\to\infty} \frac{\left(\sum_{r=1}^n\sqrt{r}\right)\left(\sum_{r=1}^n\frac1{\sqrt{r}}\right)}{\sum_{r=1}^n r}$$ The lower sum is easy to find. However, I don't think there is an expression for the sums of the individual numerator terms... Nor can I think of a way to get the combined sum. I just need a hint.","['limits-without-lhopital', 'summation', 'limits', 'infinite-product']"
1520899,Hint for Lebesgue theory/functional analysis type of problem,"I am trying to solve the following problem, but I am not too familiar with functional analysis. Could you guys tell me where I should start? Thanks! Let $f \in L^1(\mathbb{R})$ and define 
$$f_n(x) = \frac{1}{n} \int_x^{x+n} f(t)\,dt.$$ Show that $\|f_n\|_1 \leq \|f\|_1$ and $\|f_n-f\|_1 \to 0$ as $n \to 0$. This seem quite intuitive given $f_n$, but I have no idea where to start to formally prove it. Thank you so much!","['lebesgue-integral', 'lp-spaces', 'functional-analysis', 'measure-theory']"
1520923,"The set of isomorphisms, $Iso(X,Y)$ is open.","Let $X,Y $ be Banach. I want to show that, $GL(X,Y) = \{ A\in L(X,Y), B \in L(Y,X) : BA= id_{x} \ \ \text{and}  \ BA = id_{y} \} \subset^{open} L(X,Y)$ My attempt,
Let $T \in Iso(X,Y), \ Q \in L(X,Y)$ 
\begin{equation}
Q= T-(T-Q)\\
=T(id_{x} - T^{-1}(T-Q))\\
=T(id_{x} - \lambda )
\end{equation} Letting $\lambda = T^{-1}(T-Q) = id_{x} - T^{-1}Q$ Taking the norm of this, $||\lambda|| =||T^{-1}(T-Q)|| \\
 \le ||T^{-1}||||T-Q|| \\
 < ||T^{-1}||||T^{-1}||^{-1} = 1$ So $id - \lambda$ is invertible (and hence so is Q as it is the product of invertibles).
As Q is continuous,
is this justifiying that $Iso(X,Y) \subset^{open} $ of $L(X,Y)$? Any help would be appreciated!","['real-analysis', 'functional-analysis']"
1520926,The homeomorphism $D^n/S^{n-1}\cong S^n$,"I want to show that
$$D^n/S^{n-1}\cong S^n$$ Let $p$ be the north pole of $S^n$ and denote $(D^n)^o$ the interior of the disc and let $s:\mathbb{R}^n\rightarrow S^n$ be the stereographic projection. Let the map $f:D^n\rightarrow \mathbb{R}^n\rightarrow S^n$
defined as follows if $x\not \in S^{n-1}$ then $f(x)=s \circ h$ where 
$$h:(D^n)^o\longrightarrow \mathbb{R}^n; x\longmapsto {{x}\over {1-||x||}} $$
and if 
$x\in S^{n-1}$, then $f(x)=p$.
Then the quotient by $S^{n-1}$ gives a map 
$\bar f:D^n/S^{n-1}\rightarrow S^n$ which maps the class of $x$ to $f(x)$ and the map $\bar f$ is a homeomorphism. Is this the right way to do it and is there any other better way to do it. Thanks!",['general-topology']
1520961,Average Order of $\frac{1}{\mathrm{rad}(n)}$,"Again a question about $\mathrm{rad}(n).$ Let $\mathrm{rad}(n)$ denote the radical of an integer $n$, which is the product of the distinct prime numbers dividing $n$. Or equivalently, $$\mathrm{rad}(n)=\prod_{\scriptstyle p\mid n\atop p\text{ prime}}p.$$ Assume $\mathrm{rad}(1)=1$, so that $\mathrm{rad}(n)$ is multiplicative. I was trying to obtain asymptotics for the sum $$\sum_{n\le x}\frac{1}{\mathrm{rad}(n)}.$$ If we define the Dirichlet series of $\frac{1}{\mathrm{rad}(n)}$ to be $$R(s)=\sum_{n\ge 1}\frac{1}{n^s\mathrm{rad}(n)},$$
using the multiplicity of $\mathrm{rad}(n)$, we can derive that
\begin{align}
	\begin{split}
	R(s)&=\prod_{p}\left(1+\frac{p^{-1}}{p^s}+\frac{p^{-1}}{p^{2s}}+\frac{p^{-1}}{p^{3s}}+\cdots\right)\\
	&=\prod_{p}\left(1+\frac{p^{-1}}{p^s}\frac{1}{1-\frac{1}{p^s}}\right).
	\end{split}
\end{align} At first, I want to use Perron's formula here, so I have to find analytic continuation for $R(s)$ and then use residue theorem to evaluate the integral in Perron's formula. However, the Dirichlet series $R(s)$ is quite quirky. Both
$$
\sum_{n\ge 1}|\frac{p^{-1}}{p^s}\frac{1}{1-\frac{1}{p^s}}|^2
\le\sum_{n\ge 1}\frac{1}{p^2}\frac{1}{|p^\sigma -1|^2}
$$
and 
$$
\sum_{n\ge 1}|\frac{p^{-1}}{p^s}\frac{1}{1-\frac{1}{p^s}}|
\le\sum_{n\ge 1}\frac{1}{p}\frac{1}{|p^\sigma -1|}.
$$
converge for all $\Re(s)=\sigma>0$ while the second sum diverges at $s=0,$ so the Euler product for $R(s)$ converges for all $\Re(s)>0$ and the abssica of absolute convergence for $R(s)$ is $\sigma_{a}=0.$ It seems $R(s)$ has a pole at $s=0.$ I tried to ""extract"" Rieman zeta function out of $R(s).$
$$R(s)=\prod_{p}\frac{1-p^{-s}+p^{-(s+1)}}{1-p^{-s}}=\zeta(s)\prod_{p}\left(1-p^{-s}+p^{-(s+1)}\right)
$$
It seems no good, so I tried it out with
$$
R(s)=\frac{R(s)}{\zeta(s+1)}\zeta(s+1)=\zeta(s+1)\prod_{p}\left(
1-\frac{1}{p^{2s+2}}+\frac{1}{p^{2s+1}}\frac{1-p^{-(s+1)}}{1-p^{-s}}
\right).
$$
The product still explodes at $s=0.$
I also experimented with extracting out $[\zeta(s+1)]^2$, $[\zeta(s+1)]^3$ and $\zeta(2s+1),$ still geting exploded products at $s=0.$ I can't handle $R(s),$ so I tried with elementary methods.
Since $$
\frac{1}{\mathrm{rad}}*\mu(n)=\frac{\mu(n)\varphi(n)}{n},
$$
$$
\sum_{n\le x}\frac{1}{\mathrm{rad}(n)}=\sum_{n\le x}\sum_{d|n}\frac{\mu(d)\varphi(d)}{d}=\sum_{n\le x}\frac{\mu(n)\varphi(n)}{n}\left[\frac{x}{n}\right]
=x\sum_{n\le x}\frac{\mu(n)\varphi(n)}{n^2}+\mathcal{O}\left(\sum_{n\le x}\frac{|\mu(n)|\varphi(n)}{n}\right).
$$
However, $\sum_{n\ge 1}\frac{\mu(n)\varphi(n)}{n^2}$ still diverges. Thanks for any advice regarding asymptotics for $\sum_{n\le x}\frac{1}{\mathrm{rad}(n)}.$","['multiplicative-function', 'dirichlet-series', 'number-theory', 'analytic-number-theory', 'asymptotics']"
1520972,Finding the shortest distance between an arbitrary point and a parabola,"I'm attempting to find the shortest distance between a point and a parabola. The point in question is (0,b), for any b, and the parabola that we are given is$\ y = x^2 $. How would you approach the problem and find the shortest distance for any given b? What about if the point was (0,0,b), and the equation was $\ z = x^2 + y^2$?",['multivariable-calculus']
1520974,Positive elements in * Algebras,"If one has a * Algebra $W$ one can define the notion of a positive element via the spectrum $\sigma$: $A \in W$ is positive if $A^* = A$ and $\sigma(A) \subset \mathbb{R}_{≥0}$. If $W$ can be given a norm so that it becomes a  C* Algebra then this is equivalent to the notion that there exists a $B \in W$ so that $A=B^* B$. The proof of existence of such a $B$ that I have seen require completeness of $W$, and it doesn't seem unlikely that you can construct * Algebras where you have positive elements that are not decomposable in this way. But is it true in a general * Algebra that if $A=B^*B$ that then $A$ is a positive element?","['c-star-algebras', 'functional-analysis']"
1521008,I dont understand the following notation- could it be explained?,"$f_n$:D$\rightarrow$$\mathbb{R}$ Can someone just explain what the above notation means in literal words. The way i see it is that a function $f_n$ has a domain D which the function sends to a range of the real numbers? Could someone also define the following: $\mathbb{P}$:$\mathscr{B}$$\rightarrow$[0,1] $A\rightarrow$$\mathbb{P}$(A) To me this means that the probability that a function in the Borel set fit between 0 to 1 is equal to the probability of A going to P(A)?","['notation', 'statistics', 'real-analysis']"
1521020,Why are random variables measurable?,Why do we require random variables to be measurable? The only reason I can think of is being able to identify which event happened knowing that the value of random variable (and therefore we can also calculate the probability of random variable assuming that particular value)? This is what the definition of random variable basically says where it requires the random variable function to be measurable. Do the reasons I gave above make sense?,"['probability', 'random-variables', 'measure-theory']"
1521038,Join variety of two non-parallel lines,"This is an exercise in the book by Hassett. Let $l(1)$, $l(2)\in \mathbb{A}^3(\mathbb{R})$ be disjoint non-parallel lines. Show that Join($l(1)$, $l(2)$) = $ \mathbb{A}^3(\mathbb{R}) $. I can see that it must be true. The problem is to show that for an arbitrary point $p\in \mathbb{A}^3(\mathbb{R}) $, we can always find points $p_1\in l(1)$ and $p_2\in l(2)$, such that $p\in \overline{p_1 p_2}$. Take the affine plane through $p$ and $l(1)$, it generally will intersect with $l(2)$, right? Denote the intersection point as $p_2$, then $\overline{p p_2}$ intersects with $l(1)$ at some point $p_1$, and this means $p\in \overline{p_1 p_2}$. But how to make a rigorous proof?",['algebraic-geometry']
1521049,Uniquness of convex combination,"Let $a$ and $b$ be real numbers such that $0<a<b$ and let $x$ be such that $a<x<b$. How can I determine $a_x$ and $b_x$ such that $$
x=a_x\cdot a+b_x\cdot b~~,~~a_x\geq 0,~~b_x\geq 0,~~a_x+b_x=1?
$$ Do $a_x$ and $b_x$ exist unique? I know that a possible solution is $$
a_x = \frac{b-x}{b-a},~b_x = \frac{x-a}{b-a},
$$ but I do not know how to derive it and if this is the unique solution.","['convex-analysis', 'algebra-precalculus']"
1521053,Taylor expansion of exponential function and singularities,"Stackexchange community, i have a little trouble in understanding this condradtiction about singularities. Lets consider the function $f(z)=\exp(-z)$. This function can be expanded as a taylor series: $$f(z)=1-z+\frac{z^2}{2!}-\frac{z^3}{3!}\pm$$ As this is ""some sort of polynomial"" it will never have a singularity on every finite domain of $z$. But if I express $f(z)=\exp(-z)=\frac{1}{\exp(z)}$ and then apply the taylor series on $\exp(z)$ I get: $$f(z)=\frac{1}{1+z+\frac{z^2}{2!}+\frac{z^3}{3!}\pm}$$ Now here comes my confusion, the new representation allows singularities of $f(z)$, as it is ""some kind of polynomial"" in the denominator. What is the problem here? Is it because of the radius of convergence? EDIT: Ok it is because the fundamental theorem of calculus isn't true for infinite sums. Is there some intuitive way of understanding this phenomenon? I would be glad if someone could solve this contradicion.",['complex-analysis']
1521058,Using chain rule to find the derivative of $(4x^2-2)^3$,"I just took a quiz and one of the problems was to get the derivative of $f(x) = (4x^2-2)^3$. I used the chain rule and got $f'(x) = 24x(4x^2-2)^2$. However, plugging it into the derivative function in a TI-89 returns 
$f(x) = 96x(2x^2-1)^2$. Which is right? Me or the calculator?","['chain-rule', 'calculus', 'derivatives']"
1521061,Division in Multiplicatively Closed Sets of the Natural,"Let $X\subset \mathbb{N}$ be multiplicatively closed (i.e. $1\in X$, if $x,y\in X$ then $xy\in X$). Write
$$X = \{x_1,x_2,x_3,\dots\}$$
where $1=x_1<x_2<x_3<\dots$ Then does there exist an $N$ such that for all $n\geq N$
$$\prod_{k=1}^n x_k \quad \mbox{ divides } \quad  \prod_{k=n+1}^{2n} x_k.$$ This is clearly true if $X=\mathbb{N}$ as it will just be $n!|\frac{(2n)!}{n!}$. Further, the statement is not true for all $n$ as if we let
$$X = \{1,3,4,5,\dots\}$$
then when $n=2$ we don't have $a_1a_2=3$ dividing $a_3a_4=20$. My idea is that if $X$ is not ""small"" in some sense then for big enough $n$, the set $\{x_1,\dots,x_n\}$ should look enough like $\mathbb{N}$ for the statement to be true whereas if $X$ is ""small"" in some sense then we would have for all $1\leq k \leq n$ there exists an $n<\ell\leq 2n$ such that $a_k|a_\ell$ but I have no idea how to make this rigorous, nor what ""small"" should mean. Any proof or idea for how to go about doing this would be greatly appreciated.","['number-theory', 'elementary-number-theory']"
1521065,Analytic function on an open disc.,Let $\mathbb{D}=\{ z\in\mathbb{C}:|z|<1\}$. Which of the following are correct? There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(0)=0$ and $f'(0)=2$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(3/4)=3/4$ and $f'(2/3)=3/4$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(3/4)=-3/4$ and $f'(3/4)=-3/4$ There exist a holomorphic function $f:\mathbb{D}\rightarrow\mathbb{D}$ with $f(1/2)=-1/2$ and $f'(1/4)=1.$ Option one is not true by Schwartz-lemma. But i don't know how to think about other options. I  don't know which theorem or result gives condition of existence of this type of holomorphic function. Please help me to solve this problem. If possible please solve this problem. Thanks in advance.,['complex-analysis']
1521128,"Given a line and a point in 3D, how to find the closest point on the line?","I have a point given by $P = (P_x, P_y, P_z)$ , and a line give by the two points $Q = (Q_x, Q_y, Q_z)$ and $R = (R_x, R_y, R_z)$ . I'd like to know a general formula to figure out the closest point to $P$ that resides on the line $\overleftrightarrow{QR}$ . I know that this involves finding a perpendicular line to $\overleftrightarrow{QR}$ , but I don't know where to go from there. Edit: Based on Emilio's answer, I came up with this formula to derive the point; $$\hat{t}=\frac{(R-Q)\cdot(Q-P)}{(R-Q)\cdot(R-Q)}$$ Where $\hat{t}$ is a scalar magnitude that can be used in the following formula. $$G=Q-\hat{t}(R-Q)$$ Where $G$ is the point residing on the line $\overleftrightarrow{QR}$ closest to point $P$ .","['geometry', '3d']"
1521147,Prove the identity $\sum^{n}_{k=0}\binom{m+k}{k} = \binom{n+m+1}{n}$,"Let $n,m \in \mathbb{N}$. Prove the identity $$\sum^{n}_{k=0}\binom{m+k}{k} = \binom{n+m+1}{n}$$ This seems very similar to Vandermonde identity, which states that for nonnegative integers we have $\sum^{m}_{k=0}\binom{m}{k}\binom{n}{r-k} = \binom{m+n}{r}$. But, clearly this identity is somehow different from it. Any ideas?","['discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
1521182,Solve $\sin(x)-\sin(\frac{\pi}{3}-x)=\sqrt{\frac{3}{2}}$,"As in the title, solve $\sin(x)-\sin(\frac{\pi}{3}-x)=\sqrt{\frac{3}{2}}$. I was trying to rewrite it into a simpler form, but without any luck.","['algebra-precalculus', 'trigonometry']"
1521195,How does this partial differentiation work?,"Good day, There was a partial derivative in the lecture today that I can't comprehend. Can someone please explain how this works? Maybe there is a rule that I'm not thinking of right now. It's about the Cauchy problem in a quasilinear PDE second order for independent variables $x,y \in \mathbb{R}$. Further let $\eta \in I \subset \mathbb{R}$.
Let $$n=\frac{1}{\sqrt{x'(\eta)+y'(\eta)}} \binom{-y'(\eta)}{x'(\eta)}$$ 
Then $$ \frac{\partial u(x(\eta),y(\eta))}{\partial n}=\frac{1}{\sqrt{x'(\eta)+y'(\eta)}} \left(-y'(\eta)\frac{\partial u(x(\eta),y(\eta))}{\partial x}+x'(\eta) \frac{\partial u(x(\eta),y(\eta))}{\partial y}\right) $$ But why? It seems the derivate is just $$\frac{\partial u}{\partial n}=<n,\nabla u>$$
Is this a kind of rule? Doesn't look like chain rule to me. Thanks a lot, Marvin","['analysis', 'multivariable-calculus', 'real-analysis', 'derivatives']"
1521235,Prove the identity $\binom{-x}{k}=(-1)^k\binom{x+k-1}{k}$ for complex number $x$,"Prove that for all complex numbers $x$ and all $k \in \mathbb{N}$ we have $$\binom{-x}{k}=(-1)^k\binom{x+k-1}{k}$$ The fact that we have a complex number in the identity confuses me, because I haven't worked with binomial coefficients using complex numbers. EDIT: $$\binom{-x}{k} = \frac{-x^{\underline{k}}}{k!} = \frac{-x(-x-1)(-x-2)\cdots(-x-k+1)}{k(k-1)(k-2)\cdots1}$$ $$\binom{x+k-1}{k} = \frac{(x+k-1)^{\underline{k}}}{k!} = \frac{(x+k-1)(x+k-2)(x+k-3)\cdots(x+1)(x)}{k(k-1)(k-2)\cdots1}$$ So, I can see that both of them are the same thing, except for the sign, which is flipped. I guess this is where $(-1)^k$ comes into play. Can someone help with the finalization of the actual proof? One more thing, if someone can give me an actual example with numbers where this identity holds, I would be glad. Cause, I don't know how can I compute it that $x$ is a complex number.","['discrete-mathematics', 'binomial-coefficients', 'combinatorics']"
1521249,Maximum number of pythagorean triples on a circle not centered on the origin,"Suppose we two equations $$x^2+y^2=r^2$$ and 
$$(x-a)^2+(y-b)^2=2g^2$$ Where x,y and r are integer variables greater than 0. a,b and g are integer constants greater than 0. I conjecture that for any given selection of a,b and g, the number of integer solutions of the form $(x,y,r)$ is less than or equal to 3. How would I go about proving or disproving this? Any tips on tackling this problem. Thanks.","['pythagorean-triples', 'number-theory', 'circles', 'diophantine-equations']"
1521251,"A System of Matrix Equations (2 Riccati, 1 Lyapunov)","Setup: Let $\gamma \in(0,1)$, ${\bf F},{\bf Q} \in \mathbb R^{n\times n}$, ${\bf H}\in \mathbb R^{n\times r}$, and ${\bf R}\in \mathbb R^{r\times r}$ be given and suppose that  ${\bf P}$,${\bf W}$,${\bf X}\in \mathbb R^{n\times n}$, and ${\bf K}$,${\bf L}\in \mathbb R^{n\times r}$ satisfy \begin{align}
{\bf P} &={\bf F}({\bf I}_{n}-{\bf K} {\bf H}^\top){\bf P}{\bf F}^\top+{\bf Q}, \;\;\;\;\;\;\;\;\text{where}\;\;\;\;{\bf K}\equiv {\bf P} {\bf H}\left({\bf H}^\top{\bf P} {\bf H}+ \frac{1}{\gamma}{\bf R} \right)^{-1} \tag1\\[4ex]
{\bf W} &={\bf F}({\bf I}_{n}-{\bf L} {\bf H}^\top){\bf W}{\bf F}^\top+{\bf Q}, \;\;\;\;\;\;\;\;\text{where}\;\;\;\;{\bf L}\equiv {\bf W} {\bf H}({\bf H}^\top {\bf W} {\bf H}+ {\bf R})^{-1} \tag2\\[4ex]
{\bf X} &={\bf K}{\bf H}^\top {\bf W}+({\bf I}_n-{\bf K}{\bf H}^\top){\bf F}{\bf X}({\bf I}_n-{\bf H} {\bf L}^\top){\bf F}^\top \tag3\\
{\color{white}X}
\end{align} Moreover, assume that ${\bf P}$, ${\bf W}$, ${\bf R}$, and ${\bf Q}$ are symmetric, and ${\bf P}$, ${\bf W}$ and ${\bf X}$ are invertible. Want to prove: $${\bf K}=(\gamma{\bf I}_{n}+(1-\gamma) {\bf X} {\bf W}^{-1}){\bf L} \tag4$$ Some ideas and comments: In the scalar case (with $n=r=1$) what works is to subtract $(2)$ from $(1)$ which eliminates ${\bf Q}$, then use that to solve for ${\bf F}^2$, i.e. (suppressing the $^\top$ notation)
$$ {\bf F}^2 = \frac{(\gamma{\bf H}^2{\bf P}+{\bf R})({\bf H}^2{\bf W}+{\bf R})({\bf P}-{\bf W})}{{\bf R}^2({\bf P}-{\bf W})+(1-\gamma){\bf H}^2{\bf R}{\bf P}{\bf W})},$$
substitute this into $(3)$ and solve for ${\bf X}$ which yields
$${\bf X} = \frac{(\gamma {\bf R}({\bf P}-{\bf W})+\gamma(1-\gamma){\bf H}^2{\bf P}{\bf W}}{(1-\gamma)(\gamma {\bf H}^2{\bf P}+{\bf R}))}. $$
Finally, solving for ${\bf X}$ using $(4)$ yields the same thing. Notice that the equations $(1)$ and $(2)$ are Riccati equations on ${\bf P}$ and ${\bf W}$ respectively, which means that there are known methods (described here ) to solve for ${\bf P}$ and ${\bf W}$. Though I was not able to make use of those solutions. Equation $(3)$ is similar to a Lyapunov equation on ${\bf X}$, which means that a vectorization method (described here ) allows one to obtain an equation for ${\bf X}$. I think the proof will come from a procedure similar to the one that works for the scalar case. That is, subtracting $(2)$ from $(1)$, using this equation to eliminate ${\bf F}$ from $(3)$, then showing that the resulting equation implies $(4)$. If you can prove it under additional assumptions that could also be helpful. Here is a simple Matlab code that allows you to test the result: gamma = 0.5;

    F = [2, 2, 3; 4, 5, 6; 7, 8, 9];  % n x n
    H = [1, 2; 3, 1; 2, 1];           % n x r
    R = [3 , 1; 1, 3];                % r x r, symmetric
    Q = [2, 0, 0; 0, 5, 0; 0, 0, 9];  % n x n, symmetric

    n = length(F); 
    r = length(R); 

    I = eye(n);

    P = I;
    W = I;
    X = I;
    for i=1:1000
        K = (P*H)/(H'*P*H+(R/gamma));
        P = F*(P-K*H'*P)*F'+Q;
        L = (W*H)/(H'*W*H+R);    
        W = F*(W-L*H'*W)*F'+Q;
        X = K*H'*W+(I-K*H')*F*X*(I-H*L')*F';
    end

    disp(['K - (gamma*I+(1-gamma)*X*W^(-1))*L = ',...
          num2str(sum(sum(abs(K-(gamma*I+(1-gamma)*X*(W^(-1)))*L))))]) This question is a boiled down version of another question: Forecast equivalence between two steady-state Kalman filters (with ${\bf L} \equiv {\bf L}_1$, ${\bf W} \equiv {\bf W}_{11}$, and ${\bf X} \equiv {\bf W}_{12}$).","['optimal-control', 'optimization', 'matrix-equations', 'matrices']"
1521261,Sequence of functions uniformly integrable but not bounded,"Find a sequence $\{ f_n : E \to \mathbb{R}, m(E) < \infty\}$ of pointwise convergent functions that is uniformly integrable and not bounded by a single integrable function (i.e. there is no integrable function $g$ such that $|f_n| \leq g$ for all $n$). Show your Claim. Show that, for each example that one can find in the above problem, the limit function is integrable. I was thinking $f_n =\frac{1}{n} \chi_{[0,n]}$ but I am not sure, anyone can help? Thank.","['real-analysis', 'measure-theory']"
1521264,Kernels and reduced row echelon form - explanation,"The following text is written in my textbook and I don't really understand it: If $A = (a_{ij}) \in$ Mat $(m x N, F)$ is a matrix in reduced row echelon form with $r$ nonzero rows and pivots in the columns numbered $j_1 < ... < j_r$ , then the kernel ker $(A)$ is generated by the $n-r$ elements $ w_k = e_k - \sum\limits_{1 \le i \le r, j_i \le k} a_{i_k}e_{j_i}$ for $k \in \{ 1, \cdots , n\} \setminus \{j_1, \cdots, j_r\}$ , where $e_1, \cdots, e_n$ are the standard generators of $F^n$ . There are no computational examples and the notation is a bit overwhelming so I don't know how I can use it. Can somebody give an example of this in practice?","['linear-algebra', 'matrices']"
1521333,Applying L'Hopital on $\lim_{x\to1^+}\left( \frac{1}{\ln(x)} - \frac{1}{x - 1} \right)$,"I am trying to apply L'Hopital's rule here: $$\lim_{x\to1^+}\left( \frac{1}{\ln(x)}  - \frac{1}{x - 1} \right)$$ The indeterminate form here is $\infty - \infty$, so I need to somehow shape this limit to have a quotient instead. My attempt: $$\frac{1}{\ln(x)}  - \frac{1}{x - 1} = \frac{\frac{(x-1)-\ln(x)}{\ln(x)}}{(x-1)}$$ This becomes $$\frac{(x-1)-\ln(x)}{\ln(x)\cdot(x-1)}$$ That's $$\frac{0^+-0^+}{0^+\cdot0^+}$$ Hmmmm... Does this become $\frac{0}{0}$? I am not sure. To me, $0^+$ means ""some very small number greater than $0$"", but two $0^+$ don't necessarily refer to the same number... or do they? Because if they don't, then $0^+ - 0^+ \not= 0$. The same goes for $0^+ \cdot 0^+$, they are numbers greater than $0$ so their product cannot be $0$. What do you think? Or am I overthinking it?","['calculus', 'limits']"
1521361,Decomposition of mutual information for conditionally independent variables,"I have a question regarding the mutual information of conditionally independent random variables (observations). Given $p(x,y|z) = p(x|z)p(y|z)$ where $z$ corresponds to a latent variable, I 
was wondering if an established approach exists for the decomposition of the mutual information $I(x;y)$ such that only quantities (MI / entropy / etc.) between one variable and the latent variable need to be calculated $I(x;y) = F(I(x;z), I(y;z))$?","['probability-theory', 'information-theory']"
1521374,Intuitive Explanation why the Fundamental Theorem of Algebra fails for infinite sums,"We know that for every polynomial of $n$.order Fundamental Theorem of Algebra guarantees $n$ complex roots. Lets consider the complex exponential function $f(z)=\exp(z)$. As $f(z)$ is holomorphic, we are allowed to evaluate the power sum of $f(z)$. $$f(z)=1+z+\frac{z^2}{2!}+\frac{z^3}{3!}+\cdots$$ We also know that $$f(z)=\exp(z)=\exp(x+iy)=\exp(x)\exp(iy)=\exp(x)\cdot(\cos(y)+i\sin(y))$$ A zero of this expression would only be possible if $\exp(x)$ or $\cos(y)+i\sin(y)$ or both would vanish. But $\exp(x)>0$ and $|\cos(y)+i\sin(y)|=1$, hence $\exp(z)$ doesn't vanish. As the exponential is fully defined by the powersum with infinite radius of convergence, we can conclude that the powersum, despite of beeing of ""polynomial like type"" does not have any zeros. I would be glad if someone could give me an intuitive explanation why the fundamental theorem of algebra is only true for finite polynomials.",['complex-analysis']
1521391,Does an extension operator in Sobolev spaces commute with derivative operators?,"Assume that $\Omega\subseteq \mathbb R^d$ is open and has a Lipschitz boundary. Let $\tau\geq0$. Then we know that there exists a linear operator $E:H^\tau(\Omega)\to H^\tau(\mathbb R^d)$ such that for all $u\in H^\tau(\Omega)$ we have $Eu = u$, on $\Omega$, $\|Eu\|_{H^\tau(\mathbb R^d)}\leq C_\tau \|u\|_{H^\tau(\Omega)}$, where $C_\tau$ is a constant independent of $u$. The same extension $E$
works for all $\tau$. This was proved by E.M. Stein in 1971 for integer $\tau$ and by R.A. DeVore and R.C. Sharpley in 1993 for real $\tau$. Now my question:
Do $E$ and $D^\alpha$ (weak derivative operator of order $\alpha\in \mathbb N_0^d$ for $|\alpha|\leq \tau$) commute? This means that
$$E(D^\alpha u) = D^\alpha(Eu),~~ for~ all~~ u\in H^{\tau}(\Omega)~~ and~~ |\alpha|\leq\tau.$$
If not, can such alternative extension be proved? Thank you for your consideration in advance.","['sobolev-spaces', 'approximation-theory', 'functional-analysis']"
1521427,Solving $\lim_{x\to-\infty}x^2\cdot e^x$ with L'Hopital,"Use the L'Hopital rule to solve: $$\lim_{x\to-\infty}x^2\cdot e^x$$ I need a quotient of infinities or of zeroes. One way could be this: $$\frac{e^x}{x^{-2}} = \frac{0}{0}$$ So we apply the L'Hopital rule: $$\frac{e^x}{-2x^{-3}}$$ Oh, this is not going to work. We'll be applying L'Hopital countless times without luck. Perhaps this arrangement will do: $$\frac{x^{2}}{e^{-x}} = \frac{\infty}{0}$$ Nope. Maybe I could use one of the properties of natural logarithms. Since $e^x = \ln(x)$ I could have $$\frac{x^2}{\ln(-x)} = \frac{\infty}{\infty}$$ Great! Now we can apply the L'Hopital rule: $$\frac{2x}{\frac{-1}{\ln(-x)}} = \frac{-\infty}{0}$$ Dammit. Well, maybe we can re-arrange this: $$\frac{2x}{\frac{-1}{\ln(-x)}} = 2x\cdot -\ln(-x)$$ Then, $$2x\cdot -\ln(-x) = -\infty \cdot -\infty = \infty$$ Apparently this is wrong. The answer should be $0$. What was my mistake?","['calculus', 'limits', 'derivatives']"
