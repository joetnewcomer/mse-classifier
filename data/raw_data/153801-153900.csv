question_id,title,body,tags
2590408,"Two non-empty, compact, perfect sets in real line, with empty interior, can be mapped into each other by an order preserving isomorphism of real line","Let $A,B$ be non-empty, dense in itself (i.e. every point is a limit point), compact subsets of $\mathbb R$ with empty interior. Then how to show that there exists order preserving isomorphism  $f: \mathbb R \to \mathbb R$ such that $f(A)=B$ ? I can see that both $A,B$ are perfect sets ( https://en.wikipedia.org/wiki/Perfect_set ) , so has cardinality of continuum. Also, it is enough to take one of $A$ or $B$ to be the Cantor set. I can show that $A, B$ are order homeomorphic with the cantor set, but I don't know if such a homeomorphism can be extended to whole real line. I am unable to derive anything else. Please help . Thanks in advance","['general-topology', 'descriptive-set-theory', 'real-analysis', 'metric-spaces']"
2590429,Matrix associated to a linear transformation with respect to a given basis,"We're given $L: \mathbb{R}^3 \rightarrow \mathbb{R}^3$, which is a linear transformation defined by: $$ L \left( \begin{bmatrix}x_{1}\\x_{2}\\x_{3} \end{bmatrix} \right) = \begin{bmatrix}4x_{3}\\3x_{1}+5x_{2}-2x_{3}\\x_{1}+x_{2}+4x_{3} \end{bmatrix}$$ We're also given a basis $$B = \left(\begin{bmatrix}1\\1\\1 \end{bmatrix} , \begin{bmatrix}1\\1\\0 \end{bmatrix}, \begin{bmatrix}1\\0\\0 \end{bmatrix} \right) $$ The point of the exercise is to find a matrix $M$ associated to $L$ with respect to $B$, such that $[L(x)]_{B} = M[x]_{B}$ for all $x\in \mathbb{R}^3$. Here's my approach. I transformed the vectors in $B$ to get the columns of the matrix $M$ giving me: $$M =  \begin{bmatrix}4 & 0 & 0\\ 6&8&3\\6&2&1 \end{bmatrix} $$ The solution sheed says that $M =\begin{bmatrix}6&2&1\\ 0&6&2\\-2&-8&-3 \end{bmatrix}$. I have no idea how to find the the correct solution nor why my approach is wrong.","['change-of-basis', 'linear-algebra', 'linear-transformations']"
2590462,Cauchy definite integral vs Riemann once again,"The problem of showing the equivalence between the Cauchy (definite) integral defined below and the Riemann integral is an exercise with hint in C.R.Rosentrater, Varieties of Integration , 2015. I am interested in one direction, precisely the one contained in exercise 32 of chapter 3. Its converse, easy to prove, is contained in exercise 38 chapter 2. In what follows $\mathcal P_L$ indicates the partition $\mathcal P$ tagged by the left endpoints of its subintervals. The symbol $S_R$ indicates a Riemann sum. A Cauchy sum is a Riemann sum referred to a partition tagged by the left endpoints. It is clear that $f$ is Cauchy integrable over $[a,b]\,$ only if, $\,$ for any $\varepsilon>0$ , we can find a $\delta>0$ so that, whenever $\mathcal P$ and $\mathcal Q$ are partitions of $[a,b]$ with $\|\mathcal P\|<\delta$ and $\|\mathcal Q\|<\delta$ , one has $$|S_R(f,\mathcal P_L)-S_R(f,\mathcal Q_L)|<\varepsilon$$ Author suggests a proof by contraposition using a characterization of Riemann integrability, called there ""height-width bounds theorem"". The statement to be proved is If $f$ is bounded and Cauchy integrable over $[a,b]$ , then $f$ is Riemann integrable over $[a,b]$ I restated what is written in exercise 32 because Cauchy integrability doesn't imply boundedness. This problem appears here and there in the literature but, as far as I know, proofs are not at all elementary. Maybe Rosentrater's hint refers to an elementary one. I don't know how to use the hint. I am waiting for a further hint at least.
Many thanks in advance.","['real-analysis', 'integration', 'analysis']"
2590478,Curl of a cross product with constant vector,"If $\mathbf a$ is a constant vector in the 3-dimensional space and $\mathbf s=x\mathbf e_x+y\mathbf e_y +z\mathbf e_z$, I want to show that 
$$\nabla \land \left(\mathbf a \land \mathbf s\right) = 2\mathbf a. $$ I have done as follows:
$$\nabla \land \left(\mathbf a \land \mathbf s\right)=(\nabla \cdot \mathbf s)\mathbf a\ -\ (\nabla \cdot \mathbf a)\mathbf s=3\mathbf a\ -\ (\nabla \cdot \mathbf a)\mathbf s $$ But I am confused as to how the last part is computed. Could you explicitly show how $(\nabla \cdot \mathbf a)\mathbf s$ equals $\mathbf a$ or point out any other mistake?","['multivariable-calculus', 'vector-analysis']"
2590487,$\pi$ is not algebraic of degree one or two,"Can someone help me understand the explanations made in the last two paragrapghs, starting from the sentence ""Since the factors $P(x)$ and $P(x)-P(0)...$"" I think I need to be more spesific to get an answer.. First of all, can you show that the expressions $P(x)$ and $P(x)-P(0)$ in $f^{(2k)}(x)$ are nonzero for $x=0$ and $x=\pi$? And they must have a factor of $(2n)!$ in the numerator?","['number-theory', 'transcendental-numbers', 'pi']"
2590555,The Jacobi-Madden equation $a^4+b^4+c^4+d^4 = (a+b+c+d)^4$ and disguised Pythagorean triples,"I. The Jacobi-Madden equation ,
$$a^4+b^4+c^4+d^4 = (a+b+c+d)^4$$ is equivalent to a disguised Pythagorean triple,
$$(a^2+ab+b^2)^2+(c^2+cd+d^2)^2 = \big((a+b)^2+(a+b)(c+d)+(c+d)^2\big)^2$$ II. A special case of the Descartes' circle theorem , $$2(a^4+b^4+c^4+d^4)=(a^2+b^2+c^2+d^2)^2$$ and Euler showed this is just, $$(2ab)^2+(2cd)^2 = (a^2+b^2-c^2-d^2)^2$$ III. The Fermat quartic, $$a^4+b^4 = c^4$$ becomes, $$(a b - a c + b c + c^2)^2 + (a b + a c - b c + c^2)^2 = (a^ 2 + b^2 + c^2)^2$$ IV. The Pell equation, $$x^2-2y^2 = -1$$ is also, $$x^2 + (y^2 - 1)^2 = y^4$$ as well as, $$\Big(\frac{x-1}{2}\Big)^2+\Big(\frac{x+1}{2}\Big)^2 = y^2$$ with the latter showing there are infinitely many triples where the legs differ by just $1$. Q: Are there any other examples of simple quadratic or quartic equations that can be expressed as a Pythagorean triple?","['number-theory', 'big-list', 'pythagorean-triples']"
2590563,Algebraic numbers expressible in terms of real-valued radicals,"Here's a question that I bumped into a couple of times over the years when I was still working in maths, but which somehow never yielded to my efforts. Already when I was a student, I heard a professor remark that, although all cubic equations can be solved in terms of radicals, not all of them can be solved in terms of radicals where only roots of real numbers are extracted. Sadly, this piece of information diminished the appeal of the ""cubic formula"" for me. Is there a general characterization of algebraic numbers which can be expressed in terms of real-valued radicals? That is to say, all operations expressed by the formula should take place within the field of real algebraic numbers. As a more modest question, can it be shown that $\sin(2 \pi/7)$ can not be expressed in terms of real-valued radicals?","['number-theory', 'galois-theory', 'algebraic-number-theory']"
2590573,Schauder basis $L^p(\mathbb{R})$,"Let $\{e_{n}(x)\}_{n=0}^{\infty}$ be orthonormal basis of Hilbert space $L^2(\mathbb{R})$. If $\{e_{n}(x)\}_{n=0}^{\infty} \subset L^p(\mathbb{R})$ for some $p\geq 1$, is the $\{e_{n}(x)\}_{n=0}^{\infty}$ Schauder basis for $L^p(\mathbb{R})$? Any reference?","['reference-request', 'functional-analysis', 'lp-spaces', 'orthogonality', 'schauder-basis']"
2590588,A Monotonicity property for Convergence in Measures,"Let $\{ f_n\}_{n\in\mathbb{N}}$ and $\{ g_n\}_{n\in\mathbb{N}}$ are two sequences of real valued measurable functions on the measure space $(\mathscr{X},\mathcal{A},\mu)$ such that $f_n\overset{\mu}\longrightarrow f$ and $g_n\overset{\mu}\longrightarrow g$ and $f_n \ge g_n$ $\mu$-a.e. for each $n\in\mathbb{N}$, then I believe that we should also have $f\ge g$ $\mu$-a.e. It seems intuitive to me that this result should hold true...but I've been trying to prove this statement to myself for quite a while and haven't gotten anywhere! Also I was thinking....if the above statement is true, if I change the condition to $f_n > g_n$ $\mu$-a.e. for each $n\in\mathbb{N}$ would it be correct to say that this DOES NOT guarantee $f> g$ $\mu$-a.e. as I have the feeling that the strict inequality is not preserved under a limiting argument? Thanks =)","['measurable-functions', 'measure-theory', 'convergence-divergence']"
2590603,Find for which real parameter a matrix is diagonalisable,"We're given the folowing matrix.
$$A = \begin{bmatrix}0 & 0&2h\\1 & 0&-2-3h\\0&1&3+h \end{bmatrix}$$ and we're asked to find for which $h \in \mathbb{R}$ this matrix is diagonalisable. Here's my approach. I've been able to find the characteristic polynomial of the matrix, which is: $$-\lambda^3+(3+h)\lambda^2 - (2+3h)\lambda + 2h $$ Since I didn't know what to do from here, I tried to see if the matrix is diagonalisable with $h=1$. This gives me the following polynomial: $$-\lambda^3+4\lambda^2-5\lambda+2 \\ = \ - (\lambda-2)(\lambda-1)^2$$
Therefore, to see if the matrix is diagonalisable for $h=1$, I need to see if $\mathrm{dim}(\mathrm{Ker}(A- 1 \cdot I))$ (where $I$ is the indentity matrix) is equal to $2$.$$ A-1\cdot I= \begin{bmatrix}-1&0&2\\1 & -1&-5\\0&1&3 \end{bmatrix}$$ which in echelon form gives me: $$\begin{bmatrix}1 & 0&-2\\0&1&3\\0&0&0 \end{bmatrix}$$ We can see that $\mathrm{dim}(\mathrm{Ker}(A- 1 \cdot I)) \neq 2$. Thus I would conclude that for $h=1$, the matrix A is not diagonalisable. But the correction sheet says that A is diagonalisable for all $h\in \mathbb{R}$. So first of all, I don't understand why it doesn't work $h=1$ (I guess I made a mistake somewhere, but I can't find it). Then, I don't know how I'm supposed to find out that the matrix is diagonalisable for all  $h \in \mathbb{R}$.","['eigenvalues-eigenvectors', 'diagonalization', 'linear-algebra']"
2590605,Noetherian assumption for coherent sheaves -- equivalence of categories,"Using Hartshorne's definition of coherence, we should still have that an $\mathcal{O}_X$-module $\mathscr{F}$ is coherent if and only if for every affine open $U=\operatorname{Spec}(A)$ of $X$, there exists a finitely generated $A$-module $M$ such that $\mathscr{F}|_U=\widetilde{M}$, $\textbf{even for $X$ not noetherian}$, because if $(f_1,\ldots,f_r)=A$ and each $M_{f_i}$ is a finite $A_{f_i}$-module, then $M$ is a finite $A$-module even if $A$ is not noetherian (see for example Stacks Project ). But then why does the equivalence of categories between finitely generated $A$-modules and coherent $\mathcal{O}_{\operatorname{Spec}(A)}$-modules fail without the noetherian assumption? The functor $M\mapsto \widetilde{M}$ is fully faithful and essentially surjective.","['algebraic-geometry', 'commutative-algebra']"
2590614,Fitting a piece of furniture through a corridor,"In a few days I'm facing the task of trying to move a piece of furniture into my apartment and the situation inspired me mathematically. Above is a sketch of the situation. We are trying to slide a small box of dimensions $h'$ and $w'$ through a corridor of dimensions $h$ and $w$ with entrance and an exit of widths of $a$ and $b$. No assumptions about any variables can be made except that $a$ > $h'$ and $b$ > $h'$, even if the picture suggests some relative dimensions. The box or any other dimension cannot obviously be stretched. The box can be turned freely. I'm looking for the simplest way to calculate if it is possible to fit the box through the corridor, and how. I have come up with some tedious ways of trigonometry but somehow a simple and elegant solution eludes me. Help will be greatly appreciated! EDIT: As pointed out in a comment, the box can be turned freely unlike my original question implied. EDIT2: If it simplifies things, the length $h$ can be for my specific problem be assumed be bigger than $w'$ and $h'$, although it would be interesting to know a fully general case.","['recreational-mathematics', 'geometry']"
2590631,Find $f(f(f(f(f(f(\cdots f(x)))))))$ $2018$ times [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I was given a problem to calculate $f(f(f(\dots f(x))))$ $2018$ times if $f(x)=\frac{x}{3} + 3$ and $x=4$. Is it even possible to be done without a computer?","['recurrence-relations', 'functions']"
2590734,Finding the 3rd axis in 3d space,"I want to draw 3 perpendicular axis in 3d space, for example like this I figured out this much: start by drawing the first axis (x). Any line will do draw the second axis (y). Any line that intersects the x axis should do (because in 3d space we can find an infinite ammount of lines perpendicular to x, and it is impossible to know if a line is perpendicular or not without the 3rd axis) make a ritual sacrifice to the gods of math ??? The first two axis can be basically any lines that intersect, as there is an infinite ammount of 2d planes in 3d space. But the third axis has to be perpendicular to the first two, and there is exactly ONE such line in 3d space. I just don't know how to find it.",['geometry']
2590752,Show matrix is nilpotent,"I have matrices $A,B$ of dimension $n$ with real coefficients which satisfy the following: $A^2-B^2=c(AB-BA)$ where $c$ is a real number. If $c\neq0$ , prove that $(AB-BA)^n = 0$. So far, I've been able to show that $AB-BA$ is singular. Can someone help?","['matrices', 'linear-algebra']"
2590858,"Given that $x^3+x^2=1$, express the infinite product $(1+x)(1+x^2)(1+x^4)(1+x^8)\ldots$ in the form $A+Bx+Cx^2$.","Given that $x^3+x^2=1$ and $x\in\mathbb{R}$, express the infinite product $$(1+x)(1+x^2)(1+x^4)(1+x^8)\ldots$$
  in the form $A+Bx+Cx^2$. In the earlier parts of the question, I have already shown that
$$x^4=-1+x+x^2$$
$$x^{-1}=x+x^2$$
$$1-x+x^2-x^3+x^4-x^5+\ldots=x^2$$
$$\frac{1}{1-x}=2+2x+x^2$$ I also know that
$$1+x=\frac{1}{1-x+x^2-x^3+x^4-x^5+\ldots}.$$ Can anyone give me a hint? Perhaps there is a way to do it using the previous parts, but I cannot see how.",['algebra-precalculus']
2590870,Incorrect computation of Euler Sum using Complex Residues,"First of all, I know this is a long and intimidating question, but I'm sure anyone with a little bit of complex analysis experience can answer it, so please don't turn away. In this paper by Flajolet and Salvy, they use the series representation of the Digamma function and the fact that, if $p$ is a nonnegative integer, as $s\to p$,
$$\psi(-s)+\gamma\sim \frac{1}{s-p}+H_p+...$$
to state that as $s\to p$,
$$(\psi(-s)+\gamma)^2\sim \frac{1}{(s-p)^2}+\frac{2H_p}{s-p}+...$$
and so if $r(s)$ is a function with no poles or zeroes at the positive integers,
$$\begin{align}
\text{Res}\space\space (\psi(-s)+\gamma)^2 r(s)_{s=p}
&= \text{Res}\space\space \frac{r(s)}{(s-p)^2}+\frac{2H_p\space r(s)}{s-p}_{s=p}\\
&= \text{Res}\space\space \frac{r(s)}{(s-p)^2}+\frac{2H_p\space r(s)}{s-p}\\
&= \lim_{s\to p} \frac{d}{ds}r(s)_{s=p}+\lim_{s\to p}2H_pr(s)\\
&= r'(p)+2H_pr(p)\\
\end{align}$$
As long as $r(s)$ is $\mathcal O(s^{-2})$ at infinity, the integral $\oint (\psi(-s)+\gamma)^2 r(s) ds$ around a circle with radius approaching infinity should go to zero, meaning that the sum of all residues of $(\psi(-s)+\gamma)^2 r(s)$ should equal zero. Thus, if $q_i$ are the poles of $r(s)$, we have
$$\color{green}{\sum_{p=0}^\infty (r'(p)+2H_p r(p))+\sum_{q_i}\text{Res} (\psi(-s)+\gamma)^2 r(s)_{s=q_i}=0}$$
Which is the result given in the paper. However, I tried to extend this further by saying that near its poles,
$$(\psi(-s)+\gamma)^3\sim \frac{1}{(s-p)^3}+\frac{3H_p}{(s-p)^2}+\frac{3H_p^2}{s-p}...$$
Which should yield
$$\text{Res}\space\space (\psi(-s)+\gamma)^3 r(s)_{s=p}=\frac{1}{2}r''(p)+3H_p r'(p)+3H_p^2 r(p)$$
and the summatory formula
$$\color{red}{\sum_{p=0}^\infty \bigg(\frac{1}{2}r''(p)+3H_p r'(p)+3H_p^2 r(p)\bigg)+\sum_{q_i}\text{Res} (\psi(-s)+\gamma)^3 r(s)_{s=q_i}=0}$$
But this isn't what the paper says. The paper says that
$$\color{green}{\sum_{p=0}^\infty \bigg(\frac{1}{2}r''(p)-3r(p)\zeta(2)+3H_p r'(p)+3H_p^2 r(p)-3H_p^{(2)}r(p)\bigg)+\sum_{q_i}\text{Res} (\psi(-s)+\gamma)^3 r(s)_{s=q_i}=0}$$ Why is this so? Where was my mistake?","['complex-analysis', 'euler-sums', 'summation', 'residue-calculus']"
2590896,Binomial computation: Probability of winning at least 175 games out of 900 trials,"We roll a die, if it stops on 1 , we win, if not we lose. So we have $\frac{1}{6}$ chance of winning. What is the probability of winnign at least 175 times out of 900 rolls ? We can see this as a repetition of independent games so we can use Binomial distribution. I want to find $$P(\text{Win} \geq 175)$$ but the binomial formula will only give me $P(\text{Win} = 175)$ so I will need to do that for $176,..900$.
Or I can also compute $1-P(\text{Win} < 175)$ but I still need to do 175 calculations.. How can I do it ?","['statistics', 'probability', 'dice']"
2590898,Logarithmic Differentiation for Multivariable functions?,"I was wondering if, and how exactly logarithmic differentiation may be applied to a multivariate function. For example, I have been working with the function $$f(x,y)=\frac{x-y}{x+y}$$ Does the following process hold?  Specifically, does the chain rule step with del f hold? $$\ln(f(x,y))=\ln(x-y)-\ln(x+y)$$ $$\Rightarrow \frac{1}{f(x,y)} \nabla f = \langle \frac{2y}{x^2-y^2} , \frac{-2x}{x^2-y^2} \rangle$$ Solving for $\nabla f$, does give me the correct answer.  I'm wondering is my notation would be correct, and if this will ever not work. Thanks for any help.","['multivariable-calculus', 'logarithms', 'calculus', 'vector-analysis']"
2590943,Matrix nilpotent problem different version,"I have matrices $X,Y$ of dimension $n$ with real coefficients which satisfy the following: $XY+YX=c(YX-XY)$ where $c$ is a real number. If $c\neq0$ , prove that $(YX-XY)^n = 0$. So far, I've been able to show that $YX-XY$ is singular. Can someone help?","['matrices', 'linear-algebra']"
2590962,Show uniform convergence of the series of functions $\sum_{n=1}^\infty \frac{x^n \sin(nx)}{n}$,"Show uniform convergence of the series of functions $\sum_{n=1}^\infty
\frac{x^n \sin(nx)}{n}$ on the interval $[-1,1]$ My attempt : I showed the series converges uniformly on the interval $[-1/2,1/2]$ using Weierstrass M-test. I also showed the series converges uniformly on the interval $[1/2,1]$ by using Dirichlet's criterium, where I used that $\left|\sum_{k=1}^n \sin(kx)\right| \leq \frac{1}{\sin(x/2)}$ However, I'm stuck at showing it converges uniformly on the interval $[-1,-1/2]$. I tried to apply Dirichlet's criterium but can't conclude anything because of the behaviour of the term $x^n/n$ (which does not decrease monotonically). Any ideas?","['uniform-convergence', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
2590967,Holomorphic function on unit disc has no continuous extension to boundary,"The following is a qual study question: Let $$f(z) = \sum_{n=1}^\infty \sqrt{n}z^n$$
Having proven that the radius of convergence is 1, I'm asked to show that this function cannot be extended to a continuous complex-valued function on the closed unit disc. I'm not sure what sort of techniques to use here. I know a statement from Stein and Shakarchi, $f$ cannot be continued analytically past the unit circle if no point of $\partial \mathbb D$ is regular for $f$. A point $w$ is regular for $f$ if there is an open neighborhood $U$ of $w$ and an analytic function $g$ on $U$ such that $f = g$ on $\mathbb D \cap U$. but I haven't figured out how to make use of it. Any hints or helpful tools/theorems would be appreciated!","['continuity', 'complex-analysis', 'holomorphic-functions', 'power-series']"
2590990,Monty Hall Problem With Uneven Door Probabilities,"In the conventional Monty Hall problem it is assumed that the probability of the car being placed behind any of the three doors is the same (namely, $\frac{1}{3}$). (In other words, the host has no inherent bias of placing the car behind a door versus the other two). But what if the probabilities of the car being behind doors 1, 2, or 3, with probabilities $p_1, p_2$ and $p_3$ respectively, are such that the assumption $p_1 = p_2 = p_3$ is not necessarily true. To test whether switching would be beneficial, I decided to experiment using python. I tested switching every time, not switching any time, and randomly deciding whether to switch one million times each. For each option, I used python to generate three random (technically pseudo-random) probabilities, then carried out the experiment. (I will spare you the details of the programming). The results for each option I got were very close to $0.5$. This means that it does not matter whether we switch, do not switch or randomly decide to switch. But more surprising is that given three doors with uneven probabilities of having the car behind, the probability of winning the car is $0.5$ (assuming the contestant picks randomly). Is there any mathematical justification to this? Is my interpretation of the results correct? Edit-- Here is the code snippet for generating random probabilities that I used: def prob_gen(): #Generates random probabilities
    prob_a = round(random.uniform(0, 1), 4)
    prob_b = round(random.uniform(0, 1 - prob_a), 4)
    prob_c = round(1 - (prob_a + prob_b), 4)
    return [prob_a, prob_b, prob_c] Full code is here: https://www.pastiebin.com/5a4d75a3e880e","['statistics', 'monty-hall', 'probability', 'mathematical-modeling']"
2591006,Using the weak law of large numbers to find the limit of $\sum\limits_{r = an}^{bn} {n \choose r } p^r (1-p)^{n-r}$,"I need to find the limit of $\sum\limits_{r}^{} {n \choose r } p^r (1-p)^{n-r}$ such that $ an < r < bn $ in the cases $p < a$, $ a < p < b$, and $b < p$. I know I need to consider the sum of $n$ identically distributed independent Bernoulli random variables, but I'm not sure how to apply the weak law to show what is required. Any help you could offer would be very much appreciated.","['probability-limit-theorems', 'law-of-large-numbers', 'probability-distributions', 'statistics', 'probability']"
2591028,On twisted Euler sums,"An interesting investigation started here and it showed that
$$ \sum_{k\geq 1}\left(\zeta(m)-H_{k}^{(m)}\right)^2 $$
has a closed form in terms of values of the Riemann $\zeta$ function for any integer $m\geq 2$. I was starting to study the cubic analogue $ \sum_{k\geq 1}\left(\zeta(m)-H_{k}^{(m)}\right)^3 $ and I managed to prove through summation by parts that
$$ \sum_{k\geq 1}\frac{\left(H_k^{(2)}\right)^2}{k^2} =\frac{1}{3}\zeta(2)^3-\frac{2}{3}\zeta(6)+\zeta(3)^2 $$
where the LHS, according to Flajolet and Salvy 's notation, is $S_{22,2}$. An explicit evaluation of $\sum_{k\geq 1}\left(\zeta(2)-H_{k}^{(2)}\right)^3 $ is completed by the computation of 
$$\boxed{ S_{12,2} = \sum_{k\geq 1}\frac{H_k H_k^{(2)}}{k^2} }$$
which has an odd weight, hence it is not covered by Thm 4.2 of Flajolet and Salvy. On the other hand they suggest that by the kernel $(\psi(-s)+\gamma)^4$ the previous series and the cubic Euler sum $\sum_{n\geq 1}\frac{H_n^3}{(n+1)^2}=\frac{15}{2}\zeta(5)+\zeta(2)\,\zeta(3)$ are strictly related. Question : can you help me completing this sketch, in order to get an explicit value for $S_{12,2}$ and for $\sum_{k\geq 1}\left(\zeta(2)-H_{k}^{(2)}\right)^3 $? Alternative techniques to summation by parts and residues are equally welcome. Update : I have just realized this is solved by Mike Spivey's answer to Zaid's question here . On the other hand, Mike Spivey's approach is extremely lengthy, and I would be happy to see a more efficient derivation of $S_{12,2}=\zeta(2)\,\zeta(3)+\zeta(5)$.","['residue-calculus', 'riemann-zeta', 'harmonic-numbers', 'sequences-and-series', 'summation-by-parts']"
2591068,How does this version of the multivariable chain rule work?,"In my calculus book, it gives these formulas and states them as versions of the multivariable chain rule.
I do not see how they make sense as if I cancel out the partial x’s, I get 1 = 2.
Can someone explain this and tell me how these formulas work? $\partial f/\partial v = \partial f/\partial x \cdot  dx/dv + \partial f/\partial y \cdot dy/dv$ $\partial f/\partial u = \partial f/\partial x \cdot dx/du + \partial f/\partial y \cdot dy/du$ Note: These formulas are for partial derivatives of functions of form $f(x(u,v),y(u,v))$. Also please try to explain intuitively and not too rigourously.","['multivariable-calculus', 'partial-derivative', 'chain-rule']"
2591080,Shift in origin for polar coordinates,"Consider a set of polar coordinates, $(r, \theta)$ for a plane. Let's say there is a point, at $\left(1,\frac{\pi}{4}\right)$ for which I want to define a translated and rotated coordinate system, $(R, \Theta)$ for which that point has the coordinates $(0,0)$. I just want to verify here, the transformation is given by $R = r - 1$ and $\Theta = \theta - \frac{\pi}{4}$, correct?","['coordinate-systems', 'differential-geometry', 'geometry']"
2591123,How to prove $\cos(n!) \neq 1$ without using $\pi$ is irrational,"Prove
$[\forall n \in \mathbb{N}, \cos(n!) \neq 1]$,
without using $\pi$ is irrational. Using $\pi \in (\mathbb R-\mathbb Q)$, I can prove it... Thanks everyone!",['trigonometry']
2591126,How to show distance between boundary of an open set and a compact subset is positive?,"Let $n \in \mathbb N$ and $U\subset \mathbb R^n$ be an open set.Let $K\subset U$ be a compact subset of $U$. Then How can we show that distance between $K$ and $\partial U$ is positive? Please, someone, give some hints. to solve this. Thank you.","['real-analysis', 'calculus']"
2591158,"How can I generate ""random"" curves?","In game programming (my profession) it is often necessary to generate all kinds of random things, including random curves (for example, to make a procedural island or for an agent to follow some path). For one dimensional things, we usually use some random generator that generates say floats (which are really rational numbers) in some range and that is good enough as an approximation for most purposes. (Even though we cannot generate actual real numbers within a range uniformly, we can get a good sense of it with the rationals that we DO generate.) When it comes to 2D things, though, things are very murky. For example, suppose I want to generate curves uniformly between two points (say, all curves bounded in a box, and say, additional requirements such as that the curves are differentiable). The way we usually do it is to generate random parameters for some specific type of curve - say a Bezier curve, but this is not (AFAI can see) uniform in the original requirements - i.e. some curves that fit the bill will be more likely than others. Is this even a sensible question to ask? And if so, is there a way to generate curves (to a decent approximation) so that they are uniform within the parameters? (bounded and smooth)? It ""feels"" like there are too many curves; it is strictly true with real numbers too... but there we have that rationals can be close enough for practical purposes; but with 2D things it seems less clear that any possible real curve is ""close enough"" to a ""rational curve"". So I guess the main question is... if we have a set of ""all curves"", whether we can find a way to generate another set of approximations so that each ""real"" curve is close enough to our approximation. Or: is there a mapping from ""approximations to reals"" to ""approximations of continuous, differentiable, bounded curves between two points"".... (that preserves uniformity, at least intuitively)? Or: is there a notion of distribution of (bounded differential) curves? (And way to pick items from it). Edit: I am more interested in the theoretical possibilities. I know LOTS of ways to generate curves... I am particular interested in generating curves without some kind of bias, and whether this even makes sense to want. Edit: @pjs36 pointed out the curve may be arbitrary long. I don't mind additional restrictions to prevent pathological curves. Restrictions like ""not longer than $x$"", or not self-crossing.","['probability', 'approximation']"
2591168,Bounded Mean of Partial Sums and Convergence,"This is from Amemiya's Advanced Econometrics Chapter 3 Q5: Suppose $\{a_t\}$ is a non-negative sequence such that $\frac{1}{T}\sum_{t=1}^{T} a_t < M$ for all $T$. Prove that $\lim_{T \rightarrow \infty} \sum_{t=1}^{T} \frac{a_t}{t^2} < \infty$. I'm having problems using the supposition. I have tried to break up either series as such: $\frac{1}{T^2} \sum_{t=1}^{T^2} a_t \geq \frac{1}{T^2} \sum_{t=1}^{T} a_t + \frac{1}{T^2} \sum_{t=T+1}^{T^2} a_t \geq \frac{1}{T^2} \sum_{t=1}^{T} a_t + \sum_{t=T+1}^{T^2} \frac{a_t}{t^2}$ However, the bounds are not tight enough. I have also tried to redefine the supposition so as to apply Kronecker's lemma, but the results are usually a mess. Would appreciate any help on the matter. My ultimate goal is to apply Kolmogorov's SLLN and chanced upon this result that I would like to use.","['real-analysis', 'convergence-divergence', 'probability-theory']"
2591201,"prove that $(xy-2,x^2-2)$ is a maximal ideal of $\mathbb Q[x,y]$","I want to prove that $(xy-2,x^2-2)$ is a maximal ideal of $\mathbb Q[x,y]$. To begin with, I constructed a map $\phi:\mathbb Q[x,y] \to \mathbb Q[\sqrt 2]$ by $f\mapsto f(\sqrt 2, \sqrt 2)$, hoping to show that its kernel is $(xy-2,x^2-2)$. Clearly, $\phi$ kills $(xy-2,x^2-2)$. To show the other containment. We take $f$ vanishing at $(\sqrt 2, \sqrt 2)$. Here is where I get stuck. How to express $f$ as $f=u(xy-2)+v(x^2-2)$, where $u,v\in \mathbb Q[x,y]$? Any other method will be appreciated if this one doesn't work. It would be great if there is a general method to deal with many other similar problems.","['abstract-algebra', 'polynomials']"
2591213,Computing the sum $\sum_\limits{n=2}^\infty \left(\frac{1}{(n-1)!}-\frac{1}{n!}\right)\frac{1}{n+1}$,"I have come across an infinite series, but I have no clue on how to compute its sum. $$\sum_{n=2}^\infty \left(\frac{1}{(n-1)!}-\frac{1}{n!}\right)\frac{1}{n+1}$$ It should have something to do with the Taylor expansion of $e^x$, but I could not figure out how to do this.","['taylor-expansion', 'sequences-and-series', 'calculus']"
2591221,null-homotopic function on circles?,"I am not sure whether the two results are equivalent: continuous function $f$ from $S^n$ (unit circle) to $X$ is null-homotopic. continuous function $f$ could be continuously extended to $B^{n+1}$ (closed unit ball).
(1) implies (2) is quite clear. But does (2) implies (1)?","['algebraic-topology', 'general-topology']"
2591229,Stochastic exponential is a martingale if $\int_0^\infty\|X_t\|^2dt<\infty$ for every $\omega$,"Let $P$ be the Wiener measure on $\Omega=C[0,\infty)^d$ and $W=(W^{(1)},\ldots,W^{(d)})$ be the standard Brownian motion. We may then define the Brownian filtration $\{\mathscr F_t^W,t\ge0\}$. Let $X$ be a $d$-dimensional progressively measurable process with respect to $\{\mathscr F_t^W\}$. The following is an exercise in Karatzas and Shreve($\|\cdot\|$ is the $2$-norm on $\mathbb R^d$): Suppose that $\int_0^\infty\|X_t(\omega)\|^2dt<\infty$ for every $\omega\in\Omega$. Show that $Z_t(X)$, defined as following, is a $\{\mathscr F_t^W\}$-martingale(under $P$).
  $$Z_t(X):=\exp\left(\sum_{i=1}^d\int_0^t X_s^{(i)}dW_s^{(i)}-\frac12\int_0^t\|X_s\|^2ds\right)$$ The result seems much sharper than Novikov and Kazamaki. Beneš condition, which specializes in dealing with Brownian functionals, seems not to work well here, either. I have really no idea where to begin with. The book gives a reference to H.J. Engelbert and R. Hohnle but I can't find relevant results of either author. The word ""every"" in Italics mystifies me a lot. There are some elementary examples showing that ""every"" can not be replaced by ""almost every"", so this must be the key to a proof. But for what reason is ""every"" stronger than ""almost every""? The only difference I can think of is that ""every"" is not dependent on the particular measure while ""almost every"" is. But how can I turn this into a proof?","['martingales', 'probability-theory', 'brownian-motion']"
2591237,Doubts in function mappings,"In an abstract algebra book, in section on mappings on sets, have following doubts,as specified in below two parts: Part 1: It is stated in a given para.: Let $ X, Y$  be sets, and let $ f:X->Y, g:Y->X $ be mappings, s.t. both $ f,g$  are inverse maps of each other. This means: $ fg = 1_Y, gf = 1_X$. Such a $g$ if it exists, is denoted by $f^{-1}$. It can be stated otherwise, that a map $ f: X-> Y$  has an inverse iff $f$ is 
one-to-one and onto, with proof as follows: First prove the 'if' part: Assume that $f$ has an inverse $g$. Thus $g: Y -> X$ & $fg = 1_Y, gf = 1_X.$ (a) Need prove first that: $f$ is 1-1. Proof: Assume $f(x_1)= f(x_2)$. Apply $g$ to both sides and use the fact that : $gf = 1_X$ to get: $x_1 = gf(x_1)= gf(x_2) = x_2$. <-----Issue (i) (b) Now, need prove : $f$ is onto. Proof: Let $y$ be an arbitrary element of $Y$. Need find an element of $X$ that is mapped onto $y$. Let $x = g(y)$. Now using the fact that $fg = 1_Y$, get: $f(x) = f(g(y))= fg(y) = 1_Y(y)=y$. Now, prove the 'only-if' part: Assume that $f$ is 1-1 and onto. Define $g: Y -> X$ as follows: Let $y \in Y$, so there should exist a unique element $x \in X$, s.t. $f(x) = y$. Let $g(y) = x$. This rule makes $g$ a map since $x$ is unique. The fact that $g$ is inverse of $f$ follows directly from the defn. of $g$ and of inverse. Need write proof for the same.   <-----Issue(ii) Description of issues: Issue (i): Want to get my simple elaboration vetted : In $1_Y, Y$ refers to the start element, i.e. $fg = Y->X->Y$. So, $x_1 = gf(x_1)= gf(x_2) = x_2$ means that map by $g$ of the same elements is the same still. Issue (ii): The author wants a proof (it is an exercise question). I do not feel there can be proof to the ""axiomatic definition"" sort of thing given. Part 2: 
The book states that : Given the function g: Y -> X is the inverse of the function f: X -> Y if the two diagrams, as shown in parts (a), (b) in the below diagram commute. The book states the definition of 'commutative diagram'(CD) as: Generally, a diagram of sets and maps is a CD, if following two paths through the diagram, from any of the sets to any of the other sets, give the same result (by function composition). And in a simple case as diagram (0), it means that there are three sets $X,Y,Z$ and maps $f: X-> Y, g: Y->Z, h: X->Z$, with the triangle being a ""commutative diagram"" or it ""commutes"" if $h = gf$. It further asks : (i) Is the diagrammatic definition of one function (mapping) being the inverse of the other different from the above (Part 1) statement for the same. (ii) Can one draw with one diagram with four nodes and 5 arrows - which is commutative iff $g$ is the inverse of $f$. Have drawn diagram (c) for that. Note: In diagrams, 1_X means $1_X$, and so on for 1_Y.","['abstract-algebra', 'functions']"
2591249,On the Euler sum $\sum \limits_{n=1}^{\infty} \frac{H_n^{(4)} H_n^2}{n^6}$,"Here is an Euler sum I ran into. $$\mathcal{S} = \sum_{n=1}^{\infty} \frac{\mathcal{H}_n^{(4)} \mathcal{H}_n^2}{n^6}$$ where $\mathcal{H}_n^{(s)}$ is the generalised harmonic number of order $s$ . I have no idea to what this evaluates neither do I have the appropriate techniques to begin cracking it. We have seen quite plenty Euler sums but I don't think we have seen something like this before. Correct me if I am wrong! Any help? Edit: Maybe this link ( inverse sin ) is helpful for an integral approach. Update (by Editor): By stuffle relations of Multiple Zeta Values the result is: > $$S=\small -\frac{3}{20} \pi ^4 \zeta(6,2)-\frac{5}{3} \pi ^2 \zeta(8,2)+\frac{143}{4} \zeta(10,2)-6\zeta(8,2,1,1)+\frac{\zeta (3)^4}{3}-\frac{23 \pi ^6 \zeta (3)^2}{1620}-\frac{8}{45} \pi ^4 \zeta (5) \zeta (3)-\frac{31}{3} \pi ^2 \zeta (7) \zeta (3)+\frac{2531 \zeta (9) \zeta (3)}{18}-\frac{9 \pi ^2 \zeta (5)^2}{2}+\frac{1115 \zeta (5) \zeta (7)}{8}-\frac{964213 \pi ^{12}}{8756748000}$$","['complex-analysis', 'real-analysis', 'sequences-and-series']"
2591253,Determine canonical coordinates,"I am trying to learn how to solve an ODE using symmetry.
I have got to the point where I have the generators, now I need to use them to get canonical coordinates, $r$ and $s$ where $r(x,y)$ and $s(x,y)$. If $\eta(x,y)=xy$ and $\xi(x,y)=x^2$
Then the equations to solve in order to determine $r$ and $s$ are : $x^2r_x + xyr_y =0$ and $x^2s_x + xys_y=1$ however, I don't know how to move forward from here. It has been eons since I have solved differential equations.
Please can someone walk me through this? UPDATE: I have tried to refresh my memory wrt to solving PDEs.  Here is my attempt: For the first equation I have the following: divide by $x^2$ to get $\frac{\partial r}{\partial x} + \frac{y}{x}\frac{\partial r}{\partial y}=0$ so I need to solve $\frac{dy}{dx}=\frac{y}{x}$ if I separate variables and integrate I get $\ln y =\ln x+C$ $\ln(y/x)=C$ $\frac{y}{x}=C$ Does this mean which means $r(x,y) = \frac{y}{x}$ ? I need to know if this is correct and I need help solving the second equation to find $s(x,y)$. Thanks","['symmetry', 'ordinary-differential-equations', 'lie-algebras']"
2591262,Why don't negative root answer count when using derivatives?,"I was completing the question, Find $f'(2)$ if $f(x)= \sqrt{3x-2}$. When I was calculating it as $1.5/\sqrt4$, I got the answers, $3/4$ and $-3/4$ but $-3/4$ wasn't counted in the answers. Why is that?","['derivatives', 'calculus']"
2591269,"On the dilogarithm integral $\int_{0}^{1} \frac{\log^2(1-x) {\rm Li}_2(-x)}{x} \, {\rm d}x $","Let ${\rm Li}_2$ denote the dilogarithm function . Evaluate the integral $$\mathcal{J} = \int_{0}^{1} \frac{\log^2(1-x) {\rm Li}_2(-x)}{x} \, {\rm d}x $$ A related question is this one here . However, there is a problem because $$\frac{\mathrm{d} }{\mathrm{d} x} {\rm Li}_2(-x) \neq - \frac{\log(1-x)}{x}$$ On the other hand we could expand the $\log^2(1-x)$ in a Taylor series and express that ${\rm Li}_2$ in an integral form and then deal with a harmonic sum , however I am not comfortable with handling double integration. Any help?","['special-functions', 'real-analysis', 'integration']"
2591315,Sum of all Fibonacci numbers $1+1+2+3+5+8+\cdots = -1$? [duplicate],"This question already has answers here : What is the sum of all the Fibonacci numbers from 1 to infinity. [closed] (7 answers) Closed 6 years ago . I just found the sum of all Fibonacci numbers and I don't know if its right or not. The Fibonacci sequence goes like this : $1,1,2,3,5,8,13,\dots$ and so on So the Fibonacci series is this $1+1+2+3+5+8+13+\dots$ Let $1+1+2+3+5+8+\dots=x$ $$\begin{align}
1 + 1 + 2 + 3 + 5 + \dots &= x\\
1 + 1 + 2 + 3 + \dots &= x\\
1 + 2 + 3 + 5 + 8 + \dots &= 2x \text{ (shifting and adding)}
\end{align}$$ We in fact get the same sequence. But the new sequence is one less than the original sequence. So the new sequence is $x-1$. 
But $x-1=2x$ which implies that $x=-1$. So $1+1+2+3+5+8+\dots=x$ which means...
$1+1+2+3+5+8+13+21+\dots=-1$ Is this right or wrong? Can someone please tell? Thanks...","['fibonacci-numbers', 'real-numbers', 'summation', 'divergent-series', 'sequences-and-series']"
2591331,"Prob. 3, Sec. 4, in G.F. Simmons' INTRO TO TOPOLOGY & MODERN ANALYSIS: A ring of subsets of $X \times Y$","Here is Prob. 3, Sec. 4, in the book Introduction to Topology & Modern Analysis by George F. Simmons: Let $X$ and $Y$ be non-empty sets, and let $\mathscr{A}$ and $\mathscr{B}$ be rings of subsets of $X$ and $Y$ , respectively. Show that the class of all finite unions of sets of the form $A \times B$ with $A \in \mathscr{A}$ and $B \in \mathscr{B}$ is a ring of subsets of $X \times Y$ . And, here is Prob. 4, Sec. 2, in that very book: A ring of sets is a non-empty class $\mathscr{A}$ of sets such that if $A$ and $B$ are in $\mathscr{A}$ , then $A \Delta B$ and $A \cap B$ are also in $\mathscr{A}$ . Show that [a ring of sets} $\mathscr{A}$ must also contain the empty set, $A \cup B$ , and $A - B$ . Show that if a non-empty class of sets contains the union and difference of any pair of its sets, then it is a ring of sets. . . . I also know that, for any subsets $A_1$ and $A_2$ of $X$ and for any subsets $B_1$ and $B_2$ of $Y$ , the following hold: $$ \left( A_1 \times B_1 \right) \cap \left( A_2 \times B_2 \right) = \left( A_1 \cap A_2 \right) \times \left( B_1 \cap B_2 \right). \tag{1} $$ $$ \left( A_1 \times B_1 \right) - \left( A_2 \times B_2 \right) = \big[ \left( A_1 - A_2 \right) \times \left( B_1 - B_2 \right) \big] \cup \big[ \left( A_1 \cap A_2 \right) \times \left( B_1 - B_2 \right) \big] \cup \big[ \left( A_1 - A_2 \right) \times \left( B_1 \cap B_2 \right) \big]. \tag{2} $$ $$ \left( A_1 \cup A_2 \right) \times \left( B_1 \cup B_2 \right) = \big[ A_1 \times B_1 \big] \cup  \big[ A_1 \times B_2 \big] \cup  \big[ A_2 \times B_1 \big] \cup  \big[ A_2 \times B_2 \big].     \tag{3} $$ My Attempt: Suppose that $U$ and $V$ be any two sets of our collection. Then there exist sets $A_1, \ldots, A_m, C_1, \ldots, C_n$ in $\mathscr{A}$ and sets $B_1, \ldots, B_m, D_1, \ldots, D_n$ in $\mathscr{B}$ such that $$ U = \bigcup_{i=1}^m \left( A_i \times B_i \right), \qquad \mbox{ and } \qquad V = \bigcup_{j=1}^n \left(  C_j \times D_j \right). $$ We need to show that both $U \cup V$ and $U - V$ are also in our collection. Or, we need to show that both $U \Delta V$ and $U \cap V$ are also in our collection. What next? How to proceed from here?","['ring-theory', 'elementary-set-theory']"
2591363,Counting number of students who have failed in all four subjects,"In an examination of a certain class, at least $69\%$ of the students failed in P, at least $72\%$ failed in C, at least $80\%$ failed in M, and at least $85\%$ failed in B. How many at least must have failed in all the four subjects? My attempt: I'm familiar with the type of questions where the exact number of students is given for each set ( like this ). But in this question, the minimum number for each set is given instead! Every attempt I make is leading me nowhere. I counted the number of students who have passed in each subject, but it still does not help. I feel like I'm missing a specific train of thought that'll lead me to the correct answer. Thus, I need hints for realizing the idea of this problem. Thanks!",['algebra-precalculus']
2591378,How to empirically verify convergence results with stochastic differential equations (with fractional Brownian motions),"Let $ \frac{1}{2} < H < 1$ and let $B^H_t$ be a fractional Brownian motion with Hurst parameter $H$. Then the following stochastic differential equation
$$\mathrm{d}Y_t = 5Y_t\mathrm{d}B^H_t, \quad Y_0 = 1$$
has as unique solution $Y_t = \exp(5B^H_t)$ in the sense of the Young (1936) integral. Recently there has been some literature on solving such equations numerically. When considering the Euler-Maruyama scheme:
\begin{align*}
&Y_0^{(n)} = \xi \\
&Y_{(k+1)/n}^{(n)} = Y_{k/n}^n + 5Y_{k/n}^n\left( B^H_{(k+1)/n} - B^H_{k/n}\right), \quad k \in \{ 0,\dots, n-1\}
\end{align*}
on the interval $[0,1]$ and $n$ is the number of gridpoints. It has been proven (p. 5) that the following convergence result holds:
\begin{equation*}
n^{2H - 1} \| Y^{(n)} - Y \|_{\infty} \overset{\text{a.s.}}{\to} \dfrac{1}{2}\left(\sup_{t \in [0, 1]}\left\lvert\int_0^1 D_s Y_t \mathrm{d}s\right\rvert\right)\label{error1}
\end{equation*}
Where $D_sY_t$ is the Malliavin derivative of $Y_t$. I want to empirically validate this result (and for a different, better approximation scheme). I have implemented the numerical scheme in R and got satisfactory results, but I am now stuck on how to exactly test convergence and how to compare my approximation with the exact result. Is there any literature that details how to do this? More specifically: (1) How can you compare the approximation with the exact result, given that it depends on the sample of the fractional Brownian motion and (2) How do you test the convergence result given above. When dealing with normal ODEs, these questions are easy. But at the moment I am stuck... Edit1: In the end I want to produce graphs similar to the ones given in this presentation on slides 14 through 17.","['stochastic-processes', 'malliavin-calculus', 'brownian-motion', 'numerical-methods', 'ordinary-differential-equations']"
2591385,Finding extreme values where second derivative is zero,"Consider this function: $$f(x)= 5x^6 - 18x^5 + 15x^4 - 10$$ I am told to find the extreme values of this function. So at first, I take the first derivative and set it zero. $$f'(x)=30x^5-90x^4+60x^3=0(say)$$ $$=x^5-3x^4+2x^3=0$$ If I evaluate for $x$, I find $x= 0, 1, 2$. Now let's take the second derivative of $f(x)$: $$f''(x)= 150x^4-360x^3+180x^2$$ I am Ok with $f''(1)$ and $f''(2)$ because they give a negative and positive value respectively. Now, $f''(0) = 0$. So I don't know if I have a maxima or minima at $x=0$. I have found one way to solve this on internet that is named as first derivative test. Here I take two values of $x$, one $<0$, other $>0$.  Let me take $0.5$ and $-1$. $$f'(-1)= -180$$ $$f'(0.5)=45/16$$ So if $x<0$ then the function is decreasing. But when $0 < x <1$ (less than one because we have another maxima at $x=1$, but I am worrying only about that at $x=0$), it's increasing. Thus I can say we have a minima at $x=0$. The main reason behind my asking is, after finding $f''(x)=0$, my solution book has shown that $f^{(iii)}(0)=0$ but $f^{(iv)}(0)= 360>0$. Thus we have a minima at $x=0$. But this is the INFLECTION POINT test, isn't it? But a point being an inflection point doesn't necessarily mean that it is a local maxima or local minima. So I would like to know if my work is right as I am not deeply familiar with the solution that I gave above and if my book's solution is also allowable or not? And one more thing I am not sure about: Can a point be an inflection point and at the same time a local maxima or minima? If yes, an example would be very helpful.","['derivatives', 'calculus', 'extreme-value-theorem']"
2591400,"Book on finite group theory, containing a sufficient number of examples","I read M.Isaacs book on finite group theory now and I find it quite interesting and well written. But also I feel that there are not enough examples (for me) in this book. Maybe there is another book wich can be used to complement Isaacs book which contain enough examples? Or maybe there are resources, where one can find interesting and demonstrative examples concerning finite groups?","['finite-groups', 'book-recommendation', 'group-theory', 'soft-question']"
2591468,Do Carmo Riemanniam Geometry Page 46 quesion 7,"In Do Carmo Riemannian Geometry, page 46 question 7, we show that if $G$ is a compact connected Lie group, it has a bi-invariant Riemannian metric. in the first part we are required to show that if $w$ is a left invariant differential n-form, it is also right invariant. I've shown that for any $a\in G$ we have $\textbf{R}^*_aw$ is left invariant. Do Carmo then says $\cdots$ it follows that $\textbf{R}^*_aw=f(a)w$. Is that an obvious relation which I'm missing, or is it something that requires proof?","['differential-forms', 'riemannian-geometry', 'differential-geometry', 'lie-groups']"
2591485,Proof: Two graphs are identical if their distance matrices are identical,"I am not form Math field and would like to know if distance matrices of two graphs are equal then those graphs are isomorphic or not or it's an open problem.
Any tip for starting point or direction of the proof is also appreciated. (The distance matrix of a graph is the matrix with the $ij$ entry being the distance between $v_{i}$ and $v_{j}$.) PS: I prefer to stay away from row/column permutation problem at the moment. Let's assume if two graphs are isomorphic then their nodes are labeled in the same manner.","['combinatorics', 'graph-theory', 'algebraic-graph-theory', 'discrete-mathematics']"
2591504,Find$ \lim\limits_{n\rightarrow\infty}$ $\frac{n+\sin\left(n^{2}\right)}{n+\cos\left(n\right)}$,"Question Find $$\lim_{n\rightarrow\infty}\frac{n+\sin\left(n^{2}\right)}{n+\cos\left(n\right)}$$ My Approach $$\lim_{n\rightarrow\infty}\frac{n+\sin\left(n^{2}\right)}{n+cos\left(n\right)}=\lim_{n\rightarrow\infty}\left[\frac{n}{n+\cos\left(n\right)}+\frac{\sin\left(n^{2}\right)}{n+\cos n}\right]
=\lim_{n\rightarrow\infty}\left[\frac{1}{1+\frac{\cos\left(n\right)}{n}}+\frac{\sin\left(n^{2}\right)}{n+\cos n}\right]$$ Applying L ' Hospital is not working here","['real-analysis', 'limits', 'trigonometry', 'convergence-divergence', 'sequences-and-series']"
2591516,Proving $\nabla_X (\text{tr}\ F) = \text{tr} (\nabla_XF)$.,"Let $F\in\mathcal T^{k}_{l}(M)$ be a smooth section of a $(k,l)$-tensor bundle over the manifold $M$. The trace operator
$$
\text{tr}:\mathcal T^{k}_{l}(M) \to\mathcal T^{k-1}_{l-1}(M)
$$
is defined by
$$
(\text{tr}\ F)(\omega^1,\dots,\omega^{l-1},Y_1,\dots,Y_{k-1}):=\text{tr}\left( F(\omega^1,\dots,\omega^{l-1},\omega,Y_1,\dots,Y_{k-1},Y) \right)
$$
where trace on the RHS is the regular trace of the $(1,1)$-tensor in variables $\omega$ and $Y$. How do I show that $$\nabla_X (\text{tr} F) =  \text{tr} (\nabla_XF)$$
  holds? Writing it out in coordinate seems like a real pain, is there a nicer way to prove this? I tried to do it in local coordinate and it looks quite messy. EDIT: The definition I am using is the computational one, i.e
$$\begin{align}
\nabla_X F(\omega^1,\dots,\omega^l,Y_1,\dots,Y_k):&=XF(\omega^1,\dots,Y_k)\\&-F(\nabla_X\omega^1,\omega^2,\dots,Y_k)-\dots -F(\omega^1,\dots,Y_{k-1},\nabla_X Y_k)
\end{align}$$","['tensor-products', 'riemannian-geometry', 'manifolds', 'differential-geometry', 'linear-algebra']"
2591521,Group-homomorphism $ \mathbb{R\rightarrow\mathbb{Q}} $ without Axiom of choice,"Without axiom of choice, is there a surjective homomorfism  $ (\mathbb{R},+)\rightarrow(\mathbb{Q},+) $   ? Or some nontrivial homomorphism?","['group-homomorphism', 'group-theory', 'axiom-of-choice']"
2591533,Poincaré's inequality for vector fields on a surface,"$\newcommand{\Ric}{\text{Ric}}$ Let $M$ be a smooth closed oriented Riemannian surface . I am searching for a reference (or a sketch of proof) for the following inequality: $$ \int_M |  \nabla V|^2 \ge  \int_{M} \Ric(V,V)=\int_{M} K|V|^2, \tag{1}$$ for every vector field $V \in \Gamma(TM)$ , where $ \nabla$ is the Levi-Civita connection, and the integration is against the Riemannian volume form. ( $K$ is the Gauss curvature). I guess some kind of Bochner identity is needed. I am also interested to know if this inequality holds for manifolds of higher dimensions. BTW, specializing for the case of the round $2$ -sphere, we get $$ \int_{\mathbb{S}^2} |  \nabla V|^2 \ge  \int_{\mathbb{S}^2} |V|^2. \tag{2}$$ A proof of this specific case can be found here .","['riemannian-geometry', 'integral-inequality', 'geometric-inequalities', 'curvature', 'analysis']"
2591538,Regarding vector-valued (differential) forms,"I denote the space of all $V$-valued differential $k$-forms on $M$ with $\mathcal A^k(M,V)$. Let $\omega\in \mathcal A^k(M,V)$ and $\eta\in \mathcal A^l(M,W)$, where $V,W$ are finite real vector spaces. Then, we know that the usual wedge is a map $\mathcal A^k(M,V)\times \mathcal A^l(M,W)\to \mathcal A^{k+l}(M,V\otimes W)$. Let $i$ run from 1 to $\dim V$. Let $\{v_i\}$ be a basis for $V$ and $\{w_i\}$ a basis for $W$. Then, $\omega=\omega^iv_i$ and $\eta=\eta^iw_i$ (summation convention), where $\omega^i,\eta^i$ are usual forms, meaning they are elements of $\mathcal A^k(M,\mathbb R)=\mathcal A^kM,\mathcal A^lM$ respectively. Therefore, $\omega\wedge\eta=(\omega^i\wedge \eta^j)v_i\otimes w_j$. Let's assume I want to construct a new product, namely $\curlywedge$, that is a map $\mathcal A^k(M,V)\times \mathcal A^l(M,W)\to \mathcal A^{k+l}(M, W)$. Following the method of the product $[\omega\wedge\eta]$ for two Lie algebra-valued forms, I can think of two ways, that $V\otimes W\to W$. Both rely on the universal property of the tensor product. The first way is to define a composite map:
$$v\otimes w\mapsto (v,w)\stackrel{\langle \sigma,\;\rangle\times id}{\to}(\langle\sigma,v\rangle,w)\to \langle \sigma,v\rangle w\in W$$ where $\langle\;,\;\rangle$ is the pairing product, $v\in V$, $w\in W$ and $\sigma\in V^*$ Alternatively, we can use a homomorphism $\phi:V\to End W$. I'll restrict the case now. Let $\mathfrak g$ be the Lie algebra of the Lie Group $G$ and $(\psi,V)$ be a finite representation for $\mathfrak g$, where $\psi:\mathfrak g\to End V$ is a Lie algebra homomorphism (V is the rep space). Let $\omega\in \mathcal A^1(P,\mathfrak g)$ and $\theta\in \mathcal A^1(P,V)$, namely the connection and solder form for a principal $G$-bundle $P\to M$. We have that $\omega\wedge\theta=\omega^i\wedge\theta^jX_i\otimes v_j\in \mathcal A^2(P,\mathfrak g\otimes V)$, where $\{X_i\},\{v_i\}$ bases for $\mathfrak g,V$ respectively. We want a map $\mathfrak g\otimes V\to V$, so that we can define a product $\mathcal A^k(P,\mathfrak g)\times \mathcal A^l(P,V)\to \mathcal A^{k+l}(M,V)$. It seems reasonable to choose the composite map $X\otimes v\to (X,v)\to\psi(X)v\in V$. From this, one can construct the above desired product, let it be $\curlywedge$ and then it can be proven that $\Theta=d\theta+\omega\curlywedge \theta$ is the usual expression for the torsion 2-form. Bianchi identity for $\Theta$ can also be proven. One sees, that when $V=\mathfrak g$, then $\psi=ad$ and the former $X\curlywedge v$ is nothing more than $[X\wedge v]$. My problem is that I cannot explicitly write down an exchange rule for $\omega\curlywedge \theta$. I believe it should follow the exchange rule of $[\omega\wedge\eta]$, namely $[\omega\wedge\eta]=(-1)^{kl+1}[\eta\wedge\omega]$, i.e $\omega\curlywedge \theta=\theta\curlywedge \omega$, but I am not able to show this. Instead I find that the exchange rule is of the usual forms.","['tensor-products', 'exterior-algebra', 'differential-forms', 'differential-geometry', 'connections']"
2591546,Proving: $\sqrt{1!\sqrt{2!\sqrt{3!\sqrt{\cdots\sqrt{n!}}}}} <2$,"I need help to prove the following inequality with a nested radical. $$\sqrt{1!\sqrt{2!\sqrt{3!\sqrt{\cdots\sqrt{n!}}}}} <2$$ I have tired to use the Stirling approximation, but I got stuck with the nested radical.
Does anyone have any idea?","['real-analysis', 'inequality', 'real-numbers', 'calculus', 'sequences-and-series']"
2591553,Finding side length and circumradius in a triangle,"in a triangle $ABC$ if $2\sin B= \sin A $ and $a,b,c$ be the length of side $BC,CA$ and $AB$ and length of internal angle bisector  through $A$ is $\displaystyle \frac{\sqrt{2}}{3}$ unit and the equation $25\cos^2(A-B)+x^2-40\cos(A-B)-2x+17=0$ has at least one solution , then value of $a$ and $R$ (circumradius) Try: $$(x-1)^2+\bigg(5\cos(A-B)-4\bigg)^2=0$$ so $x=1$ and $\displaystyle \cos(A-B) = \frac{4}{5}$ $5\cos A\cos B+5\sin A\sin B=5$ $5\cos A\cos B+10\sin^2 B=5$ could some help me to solve it, thanks",['trigonometry']
2591556,difference between expectation of a random variable in measure theory and in regular calculus probability books,"let X be a random variable with a density function $f_{X}(x)$. The expectation of X is defined as $E[X] = \int x f_{X}(x) dx$ While in the probability books that uses the measure theory it is defined as $E[X] = \int X dP$ how are these two definitions related? and if I have another random variable Y is its expectation defined in a similar manner, i.e., : $E[Y] = \int Y dP$ if yes, how can I know that I am integrating with respect to r.v X or Y ? any help is appreciated","['probability-theory', 'probability', 'expectation']"
2591560,Is there a simple proof for the (co)area formula in the case of equal dimensions?,"Let $\Omega \subseteq \mathbb{R}^n$ be a nice domain (say a ball), and let
$f:\Omega \to \mathbb{R}^n$ be smooth. Then
$$ \int_{\Omega} |\det df|=\int_{\mathbb{R}^n} |f^{-1}(y)|dy, \tag{1}$$
where $|f^{-1}(y)|$ is the cardinality of the set $\{f^{-1}(y)\}$. Formula $(1)$ is a special case of the area and co-area formulas , when the dimensions of the source and target are equal. In general, the area\co-area formulas: Deal with domains of different dimensions. Allow the domain to be any measurable set. Allow $f$ to be less regular (require only Lipschitzity). The proofs for the general claims are not very short or easy. Question: Is there a simpler proof for the specific case mentioned above? (Equal dimensions, $f$ smooth, nice smooth domain). A reference would suffice (I couldn't find one).","['real-analysis', 'multivariable-calculus', 'jacobian', 'change-of-variable', 'area']"
2591634,What is the apex angle of the cone of positive semidefinite matrices?,"Let $\def\S{\mathbf S}\S^n$ be the linear space of symmetric $n \times n$ matrices and $\S_+^n$ be the subset of positive semidefinite matrices. It is well-known that $\S_+^n$ is a convex cone in $\S^n$. In order to get a better geometric understanding of this object, I asked myself what the apex angle of this cone might be. We use the inner product $\DeclareMathOperator{\tr}{tr}\def\<{\langle}\def\>{\rangle}\<A,B\>=\tr(AB)$, where $\tr(A)$ is the trace of $A$. The apex angle $\theta$ of $\S_+^n$ is the biggest value of $\arccos\<A_1,A_2\>$ for $A_i\in\S_+^n$ with $\<A_i,A_i\>=1$. My best result so far Let $\def\E{\mathbf E}\E$ be some Euclidean space and $S\subset \E$ a proper subspace. Let $A_1\in\S_+^n$ be the orthogonal projection onto $S$ and $A_2\in\S_+^n$ the orthogonal projection onto the orthogonal complement $S^\bot$. Then $\<A_i,A_i\>=1$ but $A_1A_2=0$, hence $\<A_1,A_2\>=\tr(A_1A_2)=0$. So we have that $\theta\ge 90^\circ$. Can we do better? Especially, can we have $\tr(A_1A_2)<0$?","['matrices', 'angle', 'positive-semidefinite', 'convex-cone', 'linear-algebra']"
2591657,"Verification: For what $s$ is $\frac{x^4+y^4-6x^2y^2}{(x^2+y^2)^s}$ continuous and differentiable at $(0,0)$","Question For what values of $s$ (where s is real and positive) is: $f(x,y)=\dfrac{x^4+y^4-6x^2y^2}{(x^2+y^2)^s}$ when $(x,y) \neq (0,0)$ and $f(x,y) = 0$ when $(x,y)=(0,0)$ , (a) Continuous at $(0,0)$ (b) Differentiable at $(0,0)$ . Attempt at answer Looking at the line $y=x$, I get: $$f(t,t)=\frac{-4t^4}{(2t^4)^s} = \frac{-4}{(2)^s(t^{4(s-1)})}$$ However for any positive $s$, $f(t,t)$ does not tend to zero as $t$ tends to zero. Therefore $f(x,y)$ is not continuous or differentiable at $(0,0)$ for any positive real $s$. My question is, does this prove the function is not differentiable at $(0,0)$ for any $s$?","['multivariable-calculus', 'real-analysis']"
2591658,$\lim_{n\rightarrow \infty}\left[\frac{\left(1+\frac{1}{n^2}\right)\cdot \cdots\cdots \left(1+\frac{n}{n^2}\right)}{\sqrt{e}}\right]^n$,"$$\lim_{n\rightarrow \infty}\Bigg[\frac{\bigg(1+\frac{1}{n^2}\bigg)\bigg(1+\frac{2}{n^2}\bigg)\cdots\cdots \bigg(1+\frac{n}{n^2}\bigg)}{\sqrt{e}}\Bigg]^n$$ Try: $$y=\lim_{n\rightarrow \infty}\Bigg[\frac{\bigg(1+\frac{1}{n^2}\bigg)\bigg(1+\frac{2}{n^2}\bigg)\cdots\cdots \bigg(1+\frac{n}{n^2}\bigg)}{\sqrt{e}}\Bigg]^n$$ $$\log_{e}(y) =n\sum^{n}_{r=1}\log_{e}\bigg(1+\frac{r}{n^2}\bigg)-\frac{n}{2}$$ could some help me to solve it , thanks",['limits']
2591683,Trigonometric limit mistake,"Question: $$\lim_{x\to 0}\frac{\tan x-\sin x}{x^3}$$ The answer, by L'Hopital's rule as well as wolfram and desmos is $\frac{1}{2}$ Here's what I did:
$$\lim_{x\to0}({\tan x \over x}\times{1\over x^2}-{\sin x \over x}\times{1\over x^2})$$ $$\lim_{x\to0}({1 \over x^2}-{1 \over x^2})=0$$ Im not sure where the mistake is.","['limits-without-lhopital', 'limits']"
2591701,Lipschitz continuous ODE solution intersecting a hyperplane infinitely often in finite time,"I'm trying to prove that a solution of globally Lipschitz continuous system of ODEs cannot intersect any hyperplane infinitely many times in a finite amount of time. So for example, something like a spiral which converges to it's centre in finite time is not possible, because the centre is an equilibrium and therefore the solution for that point is not unique (either a constant trajectory which stays in the equilibrium, or the spiral itself). Also, the solution can't blow up to infinity because the system is globally Lipschitz. My intuition so far is that even in more complex cases, this follows from the fact that Lipschitz continuous equations have unique solutions, which would break if the trajectory converges ""too fast"" to a specific point - like in the case of the spiral above. But I can't quite grasp how to show this for trajectories which do not converge to an equilibrium. For example, take the 2-dimensional above mentioned spiral, but set it into a 3-dimensional system such that $z' = 1$. The spiral still converges to it's centre in finite time, but the centre is not an equilibrium any more. How do I show that the solution is still not unique? Or is it also just ""obvious"" consequence of Picard–Lindelöf? :)","['lipschitz-functions', 'ordinary-differential-equations', 'dynamical-systems', 'limits']"
2591702,Parametric equation with a trigonometric function in exponent,"I'm having trouble thinking of any solution or idea to solve this math problem. Any help will be appreciated. $(a^2 - 1)*2^{-\sin^2 x} = a^2 - 4a + 3 $, $a = ?$ The equation should have real solutions.","['parametric', 'exponential-function', 'trigonometry', 'linear-algebra']"
2591706,Proof: Why Poisson Distribution expresses the probability of a given number of events occurring in a fixed interval of time,"Since i did not find a good proof of this anywhere on the internet, I want somebody to check my proof: An experiment runs over a specific time span $[0,t]$. 
The expected number of arrivals in this time interval is $\lambda$, and the time intervals in between 2 arrivals has exponential distribution (it does not matter when the last arrival took place, the probability distribution until the next one is always the same).
E.g.: number of radioactive decays of a sample in a given time interval, number of calls arriving, ... Let $X$ be the number of arrivals in this time interval $[0,t]$. Then $X$ has the following probability distribution:
$$
P_{[0,t]}(X= k) = \frac{\lambda^k}{k!} e^{-\lambda}.
$$ Proof: If we slice the interval in $n\gg0$ equal parts: $[0,t] = [0,t/n)\cup [t/n, 2\cdot t/n) \cup  \dots \cup  [(n-1)\cdot t/n, t]$
Let $Y_1, Y_2, \dots, Y_n$ be the random variables describing the number of arrivals in the time intervals $[0,t/n), [t/n, 2t/n), \dots, [(n-1)t/n, t]$. Since the time from a specific point until the first arrival has exponential distribution, $P(Y_1 = 1) = P(Y_2 = 1) = \dots = P(Y_n = 1)$. 
Also, the expected number of arrivals in a subinterval is proportional to the length of the interval, therefore:  $P(Y_1 = 1)= \dots =P(Y_n = 1) = \frac \lambda n$.
Because there can only be one arrival at the same time, $n$ can be chosen so big, that there will always be only zero or one arrivals in every subinterval. Now one can see, that the probability of $k$ events in the interval $[0,t]$ can be written as a binomial distribution: \begin{align}
P_{[0,t]}(X = k) 
&= \binom{n}{k} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n} \right)^{n-k} = \\
&= \frac{n(n-1)\cdots (n-k+1)}{k!} \frac{\lambda^k}{n^k} \left(1-\frac{\lambda}{n}\right)^n\left(1-\frac{\lambda}{n}\right)^{-k},
\end{align} since, $\lim_{n\rightarrow \infty} \frac{n(n-1)\cdots(n-k+1)}{n^k} = 1$, $\lim_{n\rightarrow \infty} \left( 1-\frac{\lambda}{n}\right)^n = e^{-\lambda}$ and $\lim_{n \rightarrow \infty} \left(1-\frac{\lambda}{n}\right)^{-k} = 1$: \begin{align}
P_{[0,t]}(X=k) = \frac{\lambda^k}{k!} e^{-\lambda}.
\end{align} (I think it should be mostly correct, put please can anyone check this)","['probability-theory', 'probability-distributions', 'poisson-process', 'statistics', 'poisson-distribution']"
2591748,Show $\sum_{i=0}^\infty {k+i \choose k}a^i=\frac1{(1-a)^{k+1}}.$,"I need to show that for every $k\in\mathbb{N}, |a|<1,$ $$\sum_{i=0}^\infty {k+i \choose k}a^i=\frac1{(1-a)^{k+1}}.$$ 
It's technically a power series in $a$ but no approach in that direction proved fruitful. My only ideas are that $\sum_{i=0}^\infty i^{k+1}a^i=\frac{p(a)}{(1-a)^{k+1}}$ for some polynomial $p$, and that $${k+i \choose k}=\frac{(i+1)\cdots(i+k)}{1\cdots k}.$$","['power-series', 'binomial-coefficients', 'sequences-and-series', 'convergence-divergence']"
2591749,"Finite algebraic structures where all hyperoperations (addition, multiplication, exponentiation, tetration, etc.) are well-defined","Let $\langle R, +, \times, \uparrow, \uparrow\uparrow, \uparrow\uparrow\uparrow, \ldots; 0, 1\rangle$ be an algebraic structure with two constants $0, 1$ and where an infinite sequence of binary hyperoperations is defined, such that that the following holds ( $x\uparrow y$ will equivalently be denoted as $x^y$ ): The substructure $\langle R, +, \times, \uparrow, 0, 1\rangle$ satisfies all of Tarski's identities plus $x+0=x$ , $x\times 0=0$ , $x^0=1$ . In particular, $\langle R, +, \times, 0, 1\rangle$ is a commutative semiring. All higher-order hyperoperations satisfy the identities $x\uparrow^n 0 = 1$ , $x\uparrow^n (y+1) = x\uparrow^{n-1} (x\uparrow^n y)$ for all $n\ge  2$ . The paradigmatic example of such a structure is of course the infinite set of natural numbers $\mathbb{N}$ . However, I'm interested in exploring examples of finite structures of this sort. To simplify the problem, I am for the moment focusing on structures which are ""like $\mathbb{N}$ "" in the sense that all their elements can be obtained from $0$ by repeated incrementation. That is, we assume the following: $R$ is additively generated by $1$ (all its elements can be put as a finite sum of the form $1+1+\ldots+1$ , where the empty sum is taken to be $0$ ). $R$ has finite cardinality as a set. Alternatively, $R$ can be thought of as a finite model of Peano arithmetic, excluding the two axioms $\forall m,n, (S(m)=S(n)) \implies (m=n)$ and $\forall n, S(n)\neq 0$ , and including the corresponding inductive definitions for all the hyperoperations. Conditions 3 and 4 together imply that there must be an identity of the form $$\underbrace{1+1+\ldots+1}_{b\: \text{times}} = \underbrace{1+1+\ldots+1}_{b+a\: \text{times}}$$ where $a$ is a positive integer and $b$ a nonnegative integer. Since this identity must be invariant under the sucessor function $x \mapsto x+1$ and equality is transitive, this means that any such structure must be a finite quotient of $\mathbb{N}$ of the form $\mathbb{N}/(a\mathbb{N}+b)$ , where $a\mathbb{N}+b$ is the congruence relation where two distinct numbers are identified iff they are both greater than $b$ and they differ by a multiple of $a$ (which we will denote by $x \equiv y \mod_{\ge b} a$ ). Thanks to the distributive property, it's straightforward to check that multiplication can be uniquely defined in any quotient of this form, turning it into a semiring. I'm fairly sure this part of my reasoning is correct, as for example this answer from MathOverflow reaches the same conclusion. However, exponentiation cannot always be consistently defined for arbitrary $a$ and $b$ . For example, we have $2\equiv 5 \mod_{\ge 0} 3$ but $2^2 \not\equiv 2^5 \mod_{\ge 0} 3$ , so the ring $\mathbb{N}/(3\mathbb{N}+0) \cong \mathbb{Z}/\mathbb{3Z}$ is not compatible with exponentiation (in fact no nontrivial ring can be compatible with exponentiation, since if $1$ has an additive inverse we must have $1 = 0^0 = 0^{-1 + 1} = 0^{-1} \times 0 = 0$ ). Ordinary modular exponentiation has the property $$k^{\nu(n)} \equiv  k^{\nu(n)+\lambda(n)} \mod_{\ge 0} n,$$ for any integer $k$ , where $\lambda(n)$ is the Carmichael function of $n$ and $\nu(n) = \max_{p\mid n} \nu_p (n)$ is the maximum exponent appearing in the prime factorization of $n$ (with $\nu(1) = 0$ ). Since $k^b \ge b$ for any $k \ge 2$ and nonnegative $b$ , we have that the congruence $$k^b \equiv  k^{a+b} \mod_{\ge b} a$$ will hold for any $k$ if $\lambda(a) \mid a$ and $\nu(a) \le b$ . Call $\Lambda$ the set of pairs $(a,b)$ satisfying these two conditions (the set of possible $a$ form the sequence A124240 in OEIS). The property $m \mid n \implies (\lambda(m) \mid \lambda(n)) \land (\nu(m) \le \nu(n))$ implies that $(\lambda(a), \nu(a)) \in \Lambda$ whenever $(a, b) \in \Lambda$ , so that power towers of arbitrary height can be consistently defined in $\mathbb{N}/(a\mathbb{N}+b)$ . The corresponding congruence relation satisfies $$\forall k\in R, \quad (s\equiv t) \implies (s+k\equiv t+k) \land (s\times k\equiv t\times k) \land (s^k\equiv t^k) \land (k^s\equiv k^t)$$ (the first three congruences on the right side come from basic modular arithmetic), so all of Tarski's identities, which hold in $\mathbb{N}$ , will be preserved when taking the quotient. As for higher order hyperoperations, this is where I have the most doubts. I could only think of two further restrictions: First, base-zero tetration $0 \uparrow \uparrow k$ for $k\in \mathbb{N}$ defines a periodic sequence of period 2 alternating between $1$ and $0$ . If we are to have $0 \uparrow \uparrow b = 0 \uparrow \uparrow (b+a)$ , either $a$ is even or we get the trivial case $0=1$ . In this answer it is shown that modular tetration $x \uparrow \uparrow k \mod_{\ge 0} a$ for any nonzero $x$ is eventually constant as $k \to \infty$ ; call the limiting value $\hat{x}$ and $L(a)$ the least number such that $x \uparrow \uparrow L(a) \equiv \hat{x}$ for all $x$ . A sufficient condition for $$x\uparrow \uparrow b \equiv  x\uparrow \uparrow (b+a) \mod_{\ge b} a$$ to hold, then, is to simply choose $b \ge L(a)$ such that both numbers are congruent to $\hat{x}$ . I believe this condition is also necessary, since if we choose $b \le L(a) - 1$ then there is some $y$ for which $y\uparrow\uparrow (L(a)-1)$ is not congruent to $y\uparrow\uparrow (L(a)-1+a) \equiv \hat{y}$ . These two restrictions also apply for higher-order hyperoperations, as they eventually reduce to repeated tetration. Call $\Lambda^*$ the set of pairs $(a,b) \in \Lambda$ satisfying the two extra conditions $2 \mid a$ and $L(a) \le b$ . If I haven't made any mistake so far, the quotients $\mathbb{N}/(a\mathbb{N}+b)$ with $(a,b) \in \Lambda^*$ are then examples of finite structures compatible with the whole sequence of hyperoperations. The only other finite structure of this sort which is a quotient of $\mathbb{N}$ would be the trivial ring with $0=1$ . My question is: Is my whole reasoning so far essentially correct? Are there any other
restrictions that I missed? EDIT (23-06-2021): I found some literature regarding finite semirings with exponentiation. They seem to be known as HSI-algebras in this context, since Tarski's identities are sometimes referred to as the High School Identities. In particular, Theorem 1.1 of this article confirms that the only finite quotients $\mathbb{N}/(a\mathbb{N}+b)$ admitting exponentiation are the ones such that for any prime $p$ and $e \in \mathbb{N}$ we have $$p^e|a \implies e \le b \qquad \text{and} \qquad p|a \implies (p-1)|a,$$ which is equivalent to $(a,b) \in \Lambda$ (the theorem actually considers quotients of $\mathbb{N}-\{0\}$ , but it can be easily extended to the case with $0$ ). I consider this part of the question settled.","['abstract-algebra', 'elementary-number-theory', 'hyperoperation', 'modular-arithmetic', 'solution-verification']"
2591769,Highly composite numbers and Abundant numbers,"I'm working on Project Euler #23 and for the first time so far, I'm really confused, and the more I Google, the more confused I get. The problem states: A perfect number is a number for which the sum of its proper divisors
  is exactly equal to the number. For example, the sum of the proper
  divisors of 28 would be 1 + 2 + 4 + 7 + 14 = 28, which means that 28
  is a perfect number. A number n is called deficient if the sum of its proper divisors is
  less than n and it is called abundant if this sum exceeds n. As 12 is the smallest abundant number, 1 + 2 + 3 + 4 + 6 = 16, the
  smallest number that can be written as the sum of two abundant numbers
  is 24. By mathematical analysis, it can be shown that all integers
  greater than 28123 can be written as the sum of two abundant numbers.
  However, this upper limit cannot be reduced any further by analysis
  even though it is known that the greatest number that cannot be
  expressed as the sum of two abundant numbers is less than this limit. Find the sum of all the positive integers which cannot be written as
  the sum of two abundant numbers. My initial algorithm is... Calculate all abundant numbers (<= 28123). Calculate all numbers that can be written as the sum of two abundant numbers. (Brute force style - with a nested loop, literally adding every possible combination of the calculated abundant numbers and inserting the sums into an array). Determine all numbers (<= 28123) that do not appear in the generated array of sums. This seemed like a sound approach - it's basically the same one Kristian at Mathblog outlined, but it's not only super inefficient with significantly longer run time than all my previous solutions, but it also gave me the wrong output. I didn't fully understand Kristian's code because a , I don's speak C, and b the dude is summing the factors of prime numbers in his first code block...? What the actual heck is going on here? What do primes have to do with it? Seeking further clarification I ran into this article which casually states: All highly composite numbers or anti-primes greater than six are abundant numbers. However, the linked Wikipedia article lists 7 thru 11 as ""highly composite numbers"" and I know that 12 is the smallest abundant number, so there's no possible way the above statement could be accurate... right? I'm not looking for code, just an efficient, understandable algorithm in plain English. I'm also not a Math person so please try to use small words if you can. I just need to understand that secret prime number sauce Kristian used so I can implement it. I need that voodoo magic from the number gods explained in a way I can understand it. Your time is very much appreciated.","['number-theory', 'project-euler', 'prime-numbers']"
2591779,Exponential families: convergence in distribution implies convergence in mean?,"Various results in statistics are about asymptotic distribution of certain estimators. For example, central limit theorem states that $$\sqrt{n}\left(\widehat{\theta}_{\text{MLE},n} -\theta_0\right) \overset{d}\to \mathcal{N}(0,V)$$ We also have $$ 2 \left[\ell\left(\widehat{\theta}_{\text{MLE},n}\right) - \ell(\theta_0)\right] \overset{d}\to \chi^2_1 $$ where $\ell$ is the log-likelihood. Of course, for them to hold, we will need some assumptions. Common assumptions include $\hat{\theta}_{\text{MLE},n} \overset{p}\to \theta_0$ , $\hat{\theta}_{\text{MLE},n}$ is a zero for the derivative of log-likelihood, minimizer of log-likelihood is unique and an interior point of the support, third order derivative of log-likelihood $\ell \left( x_1, \ldots, x_n, \theta \right)$ is dominated by some function, etc. My question is , assuming all those assumptions hold (sometimes it's called the Classical Conditions, like in Van der Vaart), when can we go from ""convergence in distribution"" to ""convergence in expectation""? As an example where statisticians make such conclusion, here is an excerpt from the book Akaike Information Criterion Statistics: ... Thus we have $\ell^*(\theta_n) = \ell^*(\theta^*) - \frac{1}{2} \sqrt{n} (\theta_n - \theta^*)^T J_* \sqrt{n} (\theta_n - \theta^*) + o_p(1)$ . (there is no $o_p(1)$ in the original text). From asymptotic normality of MLE and relation between normal r.v. and chi-square r.v., $n (\theta_n - \theta^*)^T J_* (\theta_n - \theta^*)$ is asymptotically distributed as chi-square with $K$ degrees of freedom. Consequently, since mean of the chi-square r.v. is $K$ , it is approximately true, for large $n$ , that $$\mathbb{E}[ \ell^*(\theta_n)] = \mathbb{E}[ \ell^*(\theta^*)] - \frac{K}{2}$$ In the last step, author is saying something like ""since $X_n\overset{p}\to W$ , $\mathbb{E}[X_n] \to \mathbb{E}[W]$ "", which is not true in the most general cases. But what about in this case?","['real-analysis', 'measure-theory', 'statistics']"
2591811,"Where does the limit go in the ""little o"" definition of $f'(x)$?","\begin{equation}
f'(x)=\lim_{a\to x} \frac{f(a)-f(x)}{a-x}
\end{equation}
is the definition of a limit that I've known forever, but my professor was saying that we can rearrange this ""ignoring the limit"" to get
\begin{equation}
f'(x)(a-x)=f(a)-f(x)\tag{1}
\end{equation}
\begin{equation}
f'(x)(a-x)+f(x)=f(a)\tag{2}
\end{equation}
But then we have to add a ""little o"" term so 
\begin{equation}
f(a)=f(x)+f'(x)(a-x)+o(a-x)
\end{equation}
where $\lim_{a\to x} o(a-x)/(a-x)=0$ I just don't understand how the ""little o"" term makes up for the original limit that we ignored until the last step. If we rearranged this formula again, it wouldn't equal the original limit because only one term has a limit on it...","['derivatives', 'limits']"
2591816,Adding a diagonal matrix to a product of transpose of a matrix and itself is always invertible,"I am asking this question in context to Regularization/Ridge Regression Let's say that there is a Matrix A of dimension n x d , where n is the number of rows and d is the number of columns ( n may or may not be larger than d ) Consequently, we cannot say if A T A is Invertible or not, irrespective of what is n or d Let's say we have a diagonal matrix D (with diagonal elements > 0) and if we add it to A T A as follows - D + A T A Can we say that the resulting matrix will always be invertible, irrespective whether n is larger or smaller than d ? OR can we say that adding a diagonal matrix to any matrix converts it into a full rank matrix? I have read in the literature that the addition of a diagonal matrix D to A T A 'regularizes' A T A and it becomes invertible, irrespective whether n is larger or smaller than d , but I am looking for a formal proof to it.","['matrices', 'transpose', 'regularization']"
2591847,implicit differentiation when the implicit equation is a differential equation,"I want to find derivative/variation (I think variation is more correct) of solution of a differential equation with respect to one parameter of differential equation but without solving the differential equation explicitly. e.g. consider this differential equation $X'(t)=A X(t) + B(t)$, I need to find the derivative of solution with respect to A (assume a general parametric initial condition). Actually the problem arise from a constrained optimization problem where the differential equation is the constraint and the objective function is an explicit function of solution of differential equation and so implicit function of the differential equation parameters and I need to find the optimum parameters. The actual differential equation is wave PDE which is discretized by some method like finite difference (the second order wave PDE is considered as 2 simultaneous first order equation and after discretization 2 sets of equation stacked together), so the coefficient matrix or parameters are properties of medium where the wave propagates (local propagation speed of wave). Considering solving the optimization problem is the main goal, and the problem must be solved numerically, any approximation of this derivative in order to be used in a gradient descent algorithm or any other iterative solution is welcomed.","['optimization', 'constraints', 'calculus-of-variations', 'ordinary-differential-equations', 'implicit-differentiation']"
2591882,Monotone sequence,"Define $$
a_{n+1} = {1\over2\bar a_n}
$$ where $\bar a_n$ is the average of $a_1, \dots, a_n$ and $a_1 = 1$. It is easy to see that $\lim a_n = {1\over\sqrt2}$, provided the limit exists. It does, indeed, as the sequence is increasing for $n>1$, except that I couldn't prove this (apparently simple) fact. Note also that the averages decrease approaching the limit from the right. I've proven that the sequence converges based on: The sequence is bounded (use induction to see that ${1\over2}\le a_n\le1$). If a subsequence $a_{n_k}$ has a limit $\ell$, then the subsequence of averages $\bar a_{n_k} = (a_1 + \cdots + a_{n_k})/n_k$ also converges, and it does to $1\over2\ell$. Idem 2, but removing all the $a_{n_i}$ from the sum and taking their average (assume $k/n_k \to 0$ here). Any other convergent subsequence $a_{n'_k}$ must converge to the same $\ell$ (remove both the $a_{n_i}$ and the $a_{n'_i}$ from the sum). It follows that the sequence can only have one accumulation point. The part I've been unable to prove is that $a_n$ increases for $n>1$. Addendum: Origin of the problem Here I will describe the origin of the $a_n$ sequence. In the Oil Industry sometimes the rate at which a well produces depends on the rate at which water is injected back into the reservoir, a technique known as voidage replacement . It may happen, however, that the ideal injection rate cannot be satisfied. In consequence, the expected production rate is reduced by a factor $\varphi$, which is the quotient between the actual voidage replacement fraction (total injection/total production) to the required voidage replacement fraction. In a discrete simulation of this technique, assume that the actual injection rate is $1\over2$ of the injection requirement $r$. This means that at every discrete simulation step (e.g., 1 day) we have to penalize the ideal production rate $q$ according to the quotient defined above. This is what happens: We start with $\varphi=1$ and produce $q$ the first day. However, we inject $r\over2$ instead of $r$. The production penalty for the second step is
$$
    \varphi = {{r/2\over q}\over{r\over q}} = {1\over2}
$$
and therefore we produce ${1\over2}q$. In the third step the factor is
$$
    \varphi = {{r/2 + r/2\over q+q/2}\over{r\over q}} = {1\over2(1 + {1\over2})}
$$ and so on. The resulting sequence of values of $\varphi$ behaves exactly as our definition of $(a_n)_n$. In the long run, the production is penalized by a factor that quickly and increasingly approaches $1\over\sqrt2$.","['recurrence-relations', 'sequences-and-series', 'limits']"
2591897,How do I find the vertices of a polygon?,"Exercise: Denote $[n] = \{1,2,\ldots,n\}$. Let $P\subseteq \mathbb{R}^{m\times n}$ be the feasible region of the system $$\begin{split}x\geq &\, 0\\x_{ij}\leq&\, 1 \text{ for all $i\in[m]$ and $j\in[n]$}\\x_{ij} + x_{i'j} + x_{ij'} + x_{i'j'} \leq&\,3 \text{ for all $i,i'\in[m]$ and $j,j'\in[n]$ with $i\neq i'$ and $j\neq j'$}\end{split}$$ Now consider the case $m=n=3$. Show that $$x = \begin{bmatrix}\frac{3}{4}&\frac{3}{4}&\frac{3}{4}\\\frac{3}{4}&\frac{3}{4}&\frac{3}{4}\\\frac{3}{4}&\frac{3}{4}&\frac{3}{4}\end{bmatrix}$$ is a vertex of $P$. What I've tried: It makes a lot of sense to me for $x$ to be a vertex of $P$, since increasing any element of $x$ would mean that $x$ was no longer a member of $P$. I have no clue whatsoever how to show that my intuition is correct though. Question: How do I show that $x$ is a vertex of $P$? Thanks in advance! EDIT: Apparently since $x\in\mathbb{R}^{3\times 3}$, I have to show that $x$ satisfies $9$ equalities that are allowed in $P$, because this would mean that $x$ is a vertex of $P$. I don't know which inequalities/equalities I have to look for.","['optimization', 'linear-algebra', 'linear-programming', 'geometry']"
2591946,How to find median from a histogram?,"I am doing a course on machine learning and as part of it i am also learning statistics. I came across one question in which i have to find the median basing on a histogram. Median is the th  element. But in the histogram the hint is confusing me. What does that mean
43 is the median of the frequencies, but it's not the median of the values. For the median of the values, if you sum up all the frequencies below the median, and all the frequencies above the median, you should get the same number. Please help.","['statistics', 'median']"
2591977,If $2AB = (BA)^2+I_n$ then $1$ is an eigenvalue for $AB$,"Let $n$ be an odd integer, $A,B$ be $n\times n$ real matrices such that $2AB = (BA)^2+I_n$. Prove that $1$ is an eigenvalue of $AB$. This was asked at an oral exam. I've been pondering this question for a while without success. $1$ is an eigenvalue of $AB$ iff $AB-I_n$ is singular, that is $\det(AB-I_n)=0$ which is equivalent to  $\det ((BA)^2-I_n)=0$. That's all I have noted... I'd appreciate any hint. I know that $AB$ and $BA$ have the same characteristic polynomials, hence the same eigenvalues. So it may suffice to prove that $1$ is eigenvalue of $BA$, or $\det(BA-I_n)=0$.","['eigenvalues-eigenvectors', 'linear-algebra']"
2592028,Making a sequence of random variables converge almost surely to $0$,"Prove: for every sequence of random variables $X_1,X_2,X_3,\dots$ there exists a sequence $a_1,a_2,a_3,\dots$ of real numbers ($a_i \neq 0$) such that the sequence $\frac{X_1}{a_1},\frac{X_2}{a_2},\frac{X_3}{a_3},\dots$ converges almost surely to the constant $0$. Note: $X_n$ doesn't neccisarily have finite expectation. What I tried: I wanted to use Borel Cantelli lemma, proving that: $$\sum_{i=0}^n P(|\frac{X_n}{a_n}|\geq \epsilon) <\infty \; \;, \; \forall \epsilon >0 $$ Then I got: $$P(|\frac{X_n}{a_n}| \geq \epsilon)=1-F_{X_n}(a_n \epsilon)+F_{X_n}(-a_n \epsilon) $$ When $F_{X_n}$ is the cumulatie distribution function of $X_n$. My ideas was to show that $1-F_{X_n}(a_n \epsilon)+F_{X_n}(-a_n \epsilon) < \frac{C}{n^2} $ for some constant, so the series will converge. To show that I tried using the fact that $\lim \limits_{t \to \infty} F_{X_n}(t) = 1, \lim \limits_{t \to -\infty}F_{X_n}(t)=0$, that is choosing big enough $a_n$ such that $F_{X_n}(-a_n \epsilon)< \frac{1}{n^2} \;$ $, \; F_{X_n}(a_n \epsilon) > 1-
 \frac{1}{n^2}$. My problem is that the sequence I get is dependant with $\epsilon$, which is not good (I want one sequence for all $\epsilon$). Is there a way to fix my proof ? or another way to solve? 
Thanks.","['probability', 'sequences-and-series', 'convergence-divergence', 'random-variables']"
2592056,Integration Order Change,"I have this integration $$\int_{y=0}^{1} \int_{z=0}^{x^2+y^2}$$ and I want to use the order change method to get $dy dz$ instead. However, when I try that I obtain the following, $$\int_{z=0}^{1+x^2} \int_{y=z-x^2}^{1}$$ but alas they don't give the same result. When I plot the boundaries, I can see the function doesn't really go from $(z-x^2) \to 1$ but I can't really figure out how and why.","['multivariable-calculus', 'calculus']"
2592077,"If two people play tic tac toe choosing their moves randomly, what are the odds that they will tie? [closed]","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question What is the probability that it is a tie game?
What is the probability that X wins?
What is the probability that O wins? Assume X goes first and all moves are random.","['probability-theory', 'probability']"
2592134,Why do we need $x_0$ to be a cluster point if we take take the limit $\lim_{x \to x_0} f(x)$?,"We did limits of functions recently and I am wondering why we always required that $x_0$ is a cluster point of the domain. Why would taking the limit not work if $x_0$ is not a cluster point? Our definition of a limit of a function is Let $D \subseteq \mathbb R$ be a subset, $x_0$ a cluster point of $D$ and $f: D \to \mathbb R$ a function. We say $f$ converges to $L \in \mathbb R$ and write $\lim_{x \to x_0} f(x) = L$ $\iff \forall \varepsilon \gt 0 \, \exists \delta \gt 0 \, \forall x \in D \setminus \{x_0\}: |x-x_0| \lt \delta \implies |f(x)-L| \lt \varepsilon$ Our definition of a cluster point is Let $D \subseteq \mathbb R$ be a subset and $x_0\in \mathbb {R}$. We say $x_0$ is a cluster point of $D$ $\iff$ for every $\delta \gt 0$ we have $D \cap (x_0-\delta, x_0-\delta) \setminus \{x_0\} \neq \emptyset$","['real-analysis', 'limits']"
2592135,pointwise convergence of a piecewise function with intervals dependent on n,"so I have a function $f_n:[0,1] \to \mathbb R$ defined as                      $$ f_n(x) = $$\begin{cases}
   \tfrac{2n}{n-1}x
 &  0\le x\le\tfrac{n-1}{2n}\\
   2-\tfrac{2n}{n-1}x       & \tfrac{n-1}{2n}\le x \le\tfrac{n-1}{n}
\\
   0       & \tfrac{n-1}{n}\le x \le\ 1
  \end{cases}
and I'm trying to figure out the pointwise limit.
my reasoning so far is 
 if $ x=0 $,$\lim_{n\to \infty} f_n(0)=0$ for all n. the next part is the part im having a little trouble understanding, and any clarification would be much appreciated. can i pretty much ignore the middle term by saying if $x>0$, then let $x>\tfrac{N-1}{N}$ , then $f_n(x)=0$ for all $n>N$. so the pointwise limit of $f(x)$ is $0$. If this is correct (which i feel it is based on examples i've seen) is the reason this is so because the intervals involving n become arbitrarily small as n gets very large and so we can essentially ignore them ?","['real-analysis', 'pointwise-convergence', 'sequences-and-series', 'functions', 'convergence-divergence']"
2592170,Lemma 2.8 - Elements of integration by Bartle,"I'm self studying Measure Theory by Bartle's book and I have a doubt in the proof of a lemma. Before I say what is the lemma and what is my doubt, I would like to say that the book is available here if anyone wants to see and I would like to introduce some notation according to the Bartle's book that I believe it's necessary to understand the proof of the lemma. $\textbf{Notation:}$ (i) $\overline{\mathbb{R}} := \mathbb{R} \cup \{ -\infty, +\infty \} $ is the extended real number system and the function with codomain $\overline{\mathbb{R}}$ are said to be extended real valued functions. (ii) $\textbf{X}$ in bold is the $\sigma-$ algebra of a set $X$ . (iii) The collection of all extended real valued $\textbf{X}-$ measurable function on $X$ is denoted by $M(X, \textbf{X})$ . $\textbf{Lemma 2.8}$ An extended real valued function $f$ is measurable if and only if the sets $$A := \{ x \in X \ ; \ f(x) = +\infty \} \hspace{0.5cm} \text{and} \hspace{0.5cm} B := \{ x \in X \ ; \ f(x) = - \infty \}$$ belong to $\textbf{X}$ and the real-valued function $f_1$ defined by $$f_1(x) := f(x), x \notin A \cup B$$ $$f_1(x) := 0, x \in A \cup B$$ is measurable. $\textbf{Proof:}$ If $f \in M(X, \textbf{X})$ , it has already been noted that $A$ and $B$ belong to $\textbf{X}$ . Let $\alpha \in \mathbb{R}$ and $\alpha \geq 0$ , then $$\{ x \in X \ ; \ f_1(x) > \alpha \} = \{ x \in X \ ; \ f(x) > \alpha \} \ \backslash \ A$$ If $\alpha < 0$ , then $$\{ x \in X \ ; \ f_1(x) > \alpha \} = \{ x \in X \ ; \ f(x) > \alpha \} \cup B$$ The proof continues, but my doubt emerges here. I would like to know why $\{ x \in X \ ; \ f_1(x) > \alpha \} = \{ x \in X \ ; \ f(x) > \alpha \} \cup B$ ? I don't know why $\{ x \in X \ ; \ f_1(x) > \alpha \}$ have points of $B$ since $\alpha$ is fixed. Thanks in advance!","['measurable-functions', 'measure-theory', 'proof-explanation']"
2592184,An unexpected application of the Cauchy-Schwarz inequality for integrals,"I discovered this yesterday and I just want to know whether my solution is correct and whether there's a shortcut to it. Let $g(x)$ be a twice-differentiable continuous function that crosses the points $(0, t)$ and $(1, 1)$ and has stationary points there with $t\in(0,1)$. Then if  $$\text{sgn}\left(\int_0^1g(x)g''(x)\,dx\right)-\text{sgn}\left(\int_0^1\frac1{g(x)}\,dx\right)=\pm2$$ for some constant $K\in\mathbb{R}$, $$g(x)=Kg'(x)^2.$$ Furthermore, $g''(x)=\dfrac1{2K}$ when $x\in\mathbb{R}-\{0, 1\}$. Solution We use the Cauchy-Schwarz inequality for integrals with $a=0$ and $b=1$:
$$\left[\int_0^1\frac{g'(x)}{\sqrt{g(x)}}\,dx\right]^2\le\left(\int_0^1g'(x)^2\,dx\right)\left(\int_0^1\frac1{g(x)}\,dx\right)\tag{1}$$ Firstly, consider the LHS. Let $u=g(x)\implies du=g'(x)\,dx$; thus LHS is $$\left[\int_0^1\frac{g'(x)}{\sqrt{g(x)}}\,dx\right]^2=\left[\int_{g(0)}^{g(1)}\frac1{\sqrt{u}}\,du\right]^2=\left(\left[2\sqrt{u}\right]_t^1\right)^2=4(1-\sqrt t)^2=T>0 \tag{2}$$ as $g(0)=t$ and $g(1)=1$. Now use integration by parts for the first integral on the RHS: $$\int_0^1g'(x)^2\,dx=\left[g(x)g'(x)\right]_0^1-\int_0^1g(x)g''(x)\,dx=-\int_0^1g(x)g''(x)\,dx\tag{3}$$ as $g'(0)=g'(1)=0$. Plugging $(2)$ and $(3)$ into $(1)$, we get $$-T\ge\left(\int_0^1g(x)g''(x)\,dx\right)\left(\int_0^1\frac1{g(x)}\,dx\right)\tag{4}$$ with equality holding if, and only if, $$\dfrac{g'(x)}{\sqrt{g(x)}}=k\implies g(x)=\frac1{k^2}g'(x)^2=Kg'(x)^2$$ where $k,K\in\mathbb{R}$ are constants. Differentiating this, we have $g'(x)=2Kg'(x)g''(x)$. We can divide by $g'(x)\neq0$ when $x\neq0, 1$ so for $x\in\mathbb{R}-\{0,1\}$, $$g''(x)=\frac1{2K}.$$ Now back to $(4)$. $$\int_0^1g(x)g''(x)\,dx>0\implies\int_0^1\frac1{g(x)}\,dx<0$$ and $$\int_0^1g(x)g''(x)\,dx<0\implies\int_0^1\frac1{g(x)}\,dx>0$$ This means that the sign of $\int_0^1g(x)g''(x)\,dx$ is always opposite that of $\int_0^1\frac1{g(x)}\,dx$. The result follows.","['derivatives', 'stationary-point', 'definite-integrals', 'cauchy-schwarz-inequality']"
2592199,Sum of 3 uniform random variables is a constant,"Give a construction of three random variables $X,Y,Z$ that are each
  uniform on $(0,1)$ but $X+Y+Z$ is a constant. Is the following argument correct? We first consider every number in $(0,1)$ in ternary and for the $n$-th digit, randomly assign $0,1,2$ to $X, Y, Z$, such that all $n$-th digits are different.  This means each random variable is uniformly distributed since each of it's digits has a 1/3 chance for each $ \{0,1,2 \}$ To rigorize, you can show that $P(X\leq a) = a$ where $a = k/3^n$ and $n,k$ are positive integers. So this extends to $P(X\leq r) = r, r\in \mathbb{Q}\cap (0,1)$ because we can find a decreasing sequence $a_j = \frac{k_j}{3^{n_j}}$ s.t $a_j\downarrow r$.  Do I need to justify this step more?  And then from here we extend it to reals in the same way.  We use decreasing sequences because the CDF is right continuous.  This shows that $X$ is uniform and similarly $Y$ and $Z$ are uniform on $(0,1)$ They add up to a constant since the digit-wise sum is just $0+1+2$ for each place.","['uniform-distribution', 'probability-theory', 'probability', 'probability-distributions']"
2592200,Explanation of 'Infinite collection of intervals'?,"While doing a course, a questions tells me the following: Given an infinite collection $A_n$, $n=1,2,\dots$ of intervals of the real line, their intersection is defined to be $\bigcap^∞_{n=1}A_n=\{x\mid(\forall n)(x\in A_n)\}$. What does this mean? Is $A_n$ the collection of $(1,2),(2,3),(3,4),\dots$? Or is it $[1,2],[2,3],[3,4],\dots$? Or is it something else entirely? This may be a very silly question, but I was taught real analysis in a lecture half an hour long, so my knowledge is extremely lacking. Please help.","['real-analysis', 'real-numbers', 'elementary-set-theory']"
2592208,Ambiguity in rule for determining an outlier,"I have the following set of numbers, in which I need to determine if there are any outliers: 11, 14, 21, 26, 29, 33, 61. I graphed them in Desmos (see above), and visually, it appears to me that 61 is an outlier. I searched online for a mathematical rule to determine whether a number is an outlier, and I found multiple references to the rule that a number is an outlier if it is greater than Q3, or less than Q1, by more than 1.5*(interquartile range). However, I found two different methods for determining the interquartile range of a data set with an odd number of members: method 1: Remove the median of data set as a whole.  Determine the medians of the larger and smaller groups.  Subtract the smaller median from the larger to get the interquartile range. method 2: Consider the median of the dataset as a whole as belonging to both the larger and smaller groups.  Determine the medians of the larger and smaller groups.  Subtract the smaller median from the larger to get the interquartile range. Method 1 gives the groups (11, 14, 21) and (29, 33, 61), which has medians 14 and 33, for an interquartile range of 19. Method 2 gives the groups (11, 14, 21, 26) and (26, 29, 33, 61), which has medians 17.5 and 31, for an interquartile range of 13.5. (Incidentally, the TI-83 calculator uses method 1, and Microsoft Excel uses method 2.) Getting back to the 'determining outliers' question: Using method 1 gives 33 + 1.5*19 = 61.5.  Since this is greater than 61, by this method, there are no outliers in the data set. Using method 2 gives 31 + 1.5*13.5 = 51.25.  Since this is less than 61, by this method, 61 is an outlier. So my question is: Is one of these methods considered more correct than the other?  Or is the whole 'point' of outliers more intuitive, and less bound by actual formulas, so the right method would be just looking at my graph instead?  (If possible, please include links to any authoritative source or reference that you may know of.  Thank you.) EDIT: After reading some of the responses, I think I need to add a bit more context info here.  I am reviewing an Algebra textbook meant for middle to high school students, and this is part of a question which appears in that book, specifically in the area of the book where outliers are being taught about.  It looks to me like the numbers in this question were specifically chosen to have one be as far away as possible from the rest, while having it not be considered an outlier by the 1.5IQR formula. I think that this will give students the perspective that outliers are always determined by a rigid formula, without any sort of intuitive 'that point looks far away from the rest' outlook.  I am looking for input on whether this a correct / proper outlook to be teaching.",['statistics']
2592229,What does it mean for a composite function to be defined?,"I am trying to answer the following question from a past exam paper: Let $A = $ {$1,2,3$}, $B = $ {$2,3,4$}, and $C = $ {$1,2,3,4$}, consider the following functions: $f: A \to B$ $f(x) = x + 1$ $g: A \to C$ $g(x) = x$ $h: C \to A$ $h(1) = 2$, $h(2) = 3$, $h(3) = 2$, $h(4) = 1$ The question is: which of the following are / are not defined. If they are defined, find their domain, codomain and range. If they are not defined, state why. $f \circ g$ $f \circ h$ $h \circ f$ $g \circ h$ I am struggling to understand functions, and wondered if someone might be willing to go through the process of answering one of the above so I can understand how it is done. I have tried searching, but can not find an example that I can understand. Thank you!",['functions']
2592273,Determining whether $\Phi_7(x)$ is irreducible over $\mathbb{F}_{11}$,"The question again for convenience. I want to figure out whether
$$
x^6+x^5+x^4+x^3+x^2+x+1
$$
factors over $\mathbb{F}_{11}$. My work: I have determined that it has no linear term $q$, by noting that 
$$
\frac{x^7-1}{x-1}=x^6+x^5+x^4+x^3+x^2+x+1
$$
and so quotienting $\mathbb{F}_{11}$ by $q$ would lead to a non trivial element of 
$$
a\in \mathbb{F}_{11},a^7=1
$$
but this is impossible, as the order of $\mathbb{F}_{11}$ as a group is $10$. By similar logic, $\Phi_{7}(x)$ cannot factor into a quadratic and a quartic. The problem is when I do this with a potential cubic factor, since 
$$
11^3-1\cong 0\mod 7
$$
so I cannot conclude similarly. Indeed, checking in Wolfram, the polynomial does factor into two cubics modulo 11. How do I check in the affirmative that it should? My idea is that since $\mathbb{F}_{11^3}^*$ is cyclic, and $7$ divides it's order, there is an element in the group with order $7$. Since this element is not in $\mathbb{F}_{11}\subset \mathbb{F}_{11^3}$, it came from quotienting by an irreducible cubic. However, how do I know this cubic divides $\Phi_{7}(x)$? Do I need to find the irreducible cubics in $\mathbb{F}_{11}$?","['finite-fields', 'abstract-algebra', 'cyclotomic-polynomials', 'group-theory', 'field-theory']"
2592310,Riemann-Stieltjes Integral with respect to total variation,"In this Inequality for Riemann-Stieltjes integral the following question came up. Suppose functions $f,g:[a,b] \to \mathbb{R}$ are such that $f$ is Riemann-Stieltjes integrable with respect to $g$. Suppose $g$ has bounded variation and $v_a^x(g)$ is the total variation on interval $[a,x]$. Is it true that $f$ is integrable with respect to $v_a^x(g)$ (even if $f$ is not continuous)? If true how could this be proved?","['real-analysis', 'integration', 'stieltjes-integral', 'bounded-variation']"
2592324,How to do a modular arithmetic with negative exponents?,"I was reading a solution which writes:so we need to compute $2^{-11} \pmod{25}$. But this is simply, by Fermat's Little Theorem, $2^9 = 512 \equiv 12 \pmod{25}$. However I don't really understand the process here: how should I apply the theorem to get this? Thanks in advance","['number-theory', 'modular-arithmetic']"
2592378,Multi-metrics in metric space,"If I have $\mathbb R^n$ an $p\in[ 1,\infty )$ and the distance between vectors v and w is defined as $\sqrt[p]{(|v_1-w_1|^p)}$ . What does $d_\infty(v, w)$ = max { $|v_1-w_1|,|v_2-w_2|,\ldots,|v_n-w_n|$ }
mean? How would you vizualize it? If I have $S^2\subset \mathbb R^3$ and $S^2$ ={ $v\in$ $\mathbb R^3$ ,|v|=1} then we conclude that is metric space. An observation: Shouldn't be enough to write $v\in$ $\mathbb R^2$ ? I'm confused why it is written in my textbook $v\in$ $\mathbb R^3$ . Is it just random reason for example: It's ok, that third dimension of a vector doesn't matter or is a reason behind it? I somehow understand that it is possible to have more metrics in metric space- you just have two defined ways how to measure distance between elements. If I understand  correctly, then for example by line or by arc. But then our professor told us that you only take the shortest way of measuring distance and that would be of course a line.  Is this true? I would really appreciate an explanation.","['multivariable-calculus', 'metric-spaces']"
2592381,cardinality of a set of non-overlapping rectangles on the plane,"I was given a question in set theory and wanted to hear you opinions about the answer I had in mind. The question is this - let T be a set of non-overlapping rectangles on the plane. Find the maximal cardinality of T. I'm not completely sure about my answer, but I think it's $א$. My idea was looking at Riemann sums within an integral - it's an infinite set of non-overlapping rectangles, and the width of each rectangle approaches zero, so it seems that there might be א such rectangles inside some closed interval. The problem is that I'm not sure if the cardinality of these rectangles is actually א (and I'm definitely not sure on how to prove this). Do you think this is a good way to go? Am I even in the right direction? (the cardinality might be smaller and I'm just wasting my time...) How would you tackle this problem? Thanks in advance.","['cardinals', 'elementary-set-theory', 'proof-verification']"
2592425,Some infinite series (just for fun!),"I have a few infinite series problems that I think MSE might enjoy, whose answers I already know: $$\sum_{n=0}^\infty \frac{2^{n-2^n}}{1+2^{-2^n}}=\text{?}$$
  $$\sum_{n=0}^\infty \frac{4^{n+2^n}}{(1+4^{2^n})^2}=\text{?}$$
  $$\sum_{n=0}^\infty \frac{3^n(1+2\cdot3^{-3^n})}{2\cosh(3^n\ln 3)+1}=\text{?}$$ After these all get answered, I will post explanations of how I came up with answers for them. Have fun!","['telescopic-series', 'recreational-mathematics', 'summation', 'sequences-and-series']"
2592439,Calculating the surface of revolution of a cardioid.,"I have the cardioid $r=1+cos(t)$ for $0\leq{t}\leq{2\pi}$ and I want to calculate the surface of revolution of said curve. How can I calculate it? The parematrization of the cardioid is: $$x(t)=(1+cos(t))cos(t)$$
$$y(t)=(1+cos(t))sin(t)$$
and 
$$\frac{dx}{dt}=\left(-2\cos\left(t\right)-1\right)\sin\left(t\right)$$
$$\frac{dy}{dt}=\cos\left(t\right)\left(\cos\left(t\right)+1\right)-\sin^2\left(t\right)
$$ To calculate the surface of revolution I know I can use the formula (since I want to revolve it around the x-axis) $$2\pi \int_{a}^{b} y(t)\sqrt{\bigg(\frac{dx}{dt}\bigg)^2+\bigg(\frac{dy}{dt}\bigg)^2}  dt$$
However, when I do that integral, the result is $0$ (using online calculators ). Why is this wrong? Obviously the surface can't be 0, right? What's the correct answer?","['multivariable-calculus', 'solid-of-revolution', 'parametrization', 'surfaces']"
2592464,Are there any unsolved Problems in Theory of Integration?,"Ever since the development of Theory of integration. each specific problem has led to development of new integrals. The notion of integrability of continuous functions (Cauchy integral) led to Riemann Integral, where the function is still integrable if it has finite number of discontinuities. Failure of convergence theorem and a weaker FTC led to Lebesgue integral. Improper integral and certain non-Lebegsue Integrable functions led to the development of HK(guage) Integrals. Question 1. Have these  developments exhausted integration theory? Question 2. Or there are still some shortcomings or unsolved problems in this area?","['real-analysis', 'integration', 'lebesgue-integral', 'measure-theory', 'research']"
2592466,How to find a vector normal to a circle?,"Assume $S_1$  be the disk in the $ y = 1$  plane bounded by the circle $ x^2$  +$ z^2$  = $9$ . Prove that the rightward pointing unit normal to $ S_1$ is  the vector $ (0, 1, 0)$. I know that the gradient is orthogonal to level curves.","['circles', 'analytic-geometry', 'multivariable-calculus', 'proof-explanation', 'vectors']"
2592478,Do these higher-dimensional analogues of Möbius transformations have a name?,"Do maps of the form
$$
x \in \mathbb{R}^n \mapsto \frac{Ax+b}{c^Tx+d} \in \mathbb{R}^n,
$$
where $A \in \mathbb{R}^{n\times n}, b, c \in \mathbb{R}^n, d\in \mathbb{R}$ have a name? Have they been studied anywhere? It looks somehow familiar to Möbius-transformation but it is different as $A, b, c, d$ are not complex numbers. It is easy to see that the above maps form a group. I am interested in this because of an application in optics where I found that for a thin lense the map which maps image to object points is of the above form. I am especially interested in the $n=2$ and $n=3$ cases.","['reference-request', 'linear-algebra', 'lie-groups']"
2592507,Evaluating $\sin^{-1}(\cos(40))$,"So as the title states I have to evaluate $\sin^{-1}(\cos(40))$ In my textbook they answer it as following: $\sin^{-1}(\cos(40))=90-\cos^{-1}(\cos(40))=50$ I'm however a little confounded over their answer. As I recall this is the complementary angle identity but I don't really understand why it is used, considering is within the bound of [-1,1] Would be extremely grateful if somebody could expand. If my question is unclear, I would be more than happy to further clearify. Thank you in advance!","['trigonometry', 'calculus', 'inverse']"
2592520,Number of real roots of the following polynomial,"I have a cubic polynomial: $f(x)=x^3+3x^2+3x+7$ I wanted to obtain number of real roots of the provided polynomial. What i did: I took the derivative of the function which turned out to be $3x^2+6x+3$ which is  a perfect square after taking $3$ common. Hence, the function is strictly increasing. Also, it has two negative roots. Now, it's function can have at the most three roots using this monotonicity concept. Since, the polynomial is of order three, it can have at the most three roots. Using the rule of sign, we can also say that this polynomial will have either three negative roots or one negative roots. The three negative root situation can be ignored using the monotonicity. Only plausible situation is one negative roots. Hence, this polynomial will have one real root. I think the number of steps that I took can be reduced. I am also using some redundant things please guide me. Are my steps correct to obtain the number of roots. If not, please add some point that I can think of while obtaining number of roots of a polynomial or of any other function whatsoever. Thanks in advance.","['derivatives', 'monotone-functions', 'calculus']"
2592534,Polyhedral graphs from consecutive power distances,"Raise a real value to powers 0 to $n-1$ for $n$ different lengths. Build a polyhedral graph from those lengths, none missing or repeated. I have found 4 solutions, all wheel graphs. Are there any others? In the images below, the number indicates the power.  The 0 edge has length $a^0=1$. These use the 2nd real values of the following polynomials: $$x^6-x^2-1,\\ x^8-x^2-1, \\x^{12}+x^8-x^4-x^2-1, \\6 x^{16}+x^{15}-3 x^{14}-2 x^{13}-3 x^{11}+8 x^{10}-2 x^9-x^8-6 x^7-x^6+x^4-4 x^3-4 x^2+2 x+6$$ Are there any other solutions?","['combinatorics', 'graph-theory', 'polynomials', 'algebraic-geometry']"
2592590,a 3d geometry problem with tetrahedrons and cube,Two distinct regular tetrahedra have all their vertices among the vertices of the same unit cube. What is the volume of the region formed by the intersection of the tetrahedra? So at first thought I tried to drew the figure by hand as this problem is supposed to be done in a non- graphing utility environment -- but it didn't really work out  so I want to ask is there anyway to do this without a diagram? I know the volume of tetrahedrons but I just don't get where they intersect. Thanks in advance.,"['3d', 'geometry']"
