question_id,title,body,tags
1202700,Simplifying and evaluating $\cot 70^\circ+4\cos 70^\circ$,"I have to simplify and evaluate this : $$\cot 70^\circ+4\cos 70^\circ$$ On evaluating it, the answer comes out to be $1.732$ , or $\sqrt 3$ . I tried to get everything in $\sin$ and $\cos$ , but it doesn't go any further. Any hints?",['trigonometry']
1202774,"Spectral sequence $\bigoplus_{k-j=q}\mathrm{Ext}^p(\mathcal{H}^j,\mathcal{H}^k)\Rightarrow \mathrm{Hom}^{p+q}(P,P)$","Reading the proof in Bondal-Orlov reconstruction theorem ( http://arxiv.org/pdf/alg-geom/9712029v1.pdf ), I found the spectral sequence in the title $E_2^{p,q}=\bigoplus_{k-j=q}\mathrm{Ext}^p(\mathcal{H}^j,\mathcal{H}^k)\Rightarrow \mathrm{Hom}^{p+q}(P,P)$ where $P$ is a point-like object and the $\mathcal{H}^j$'s are the cohomology sheaves of the complex $P$. Is it a special case of some other spectral sequence? If not, where could I find a reference for it? One thing I know is that all the cohomology sheaves $\mathcal{H}^j$ are supported at the same single point $x$. Thank you EDIT: I was thinking whether it is possible to get it (or something similar, since the indexing conventions might be different between my other resource, i.e. Huybrecht's Fourier Mukai transforms in algebraic geometry) from the two spectral sequences
\begin{equation}
E^{p,q}_2=\mathrm{Hom}(A,\mathcal{H}^q(B)[p])\Rightarrow\mathrm{Hom}(A,B[p+q])
\end{equation}
and
\begin{equation}
E^{p,q}_2=\mathrm{Hom}(\mathcal{H}^{-q}(A),B[p])\Rightarrow\mathrm{Hom}(A,B[p+q])
\end{equation}
The rough idea was to consider
\begin{equation}
\mathrm{Hom}(\mathcal{H}^{-k},\mathcal{H}^j[p])\Rightarrow\mathrm{Hom}(P,\mathcal{H}^j[p+k]) \Rightarrow \mathrm{Hom}(P,P[p+j+k])
\end{equation}
and then take the direct sum for $j+k=q$ and argue that
\begin{equation}
\bigoplus_{j+k=q}\mathrm{Hom}(\mathcal{H}^{-k},\mathcal{H}^j[p])\Rightarrow \mathrm{Hom}(P,P[p+q])
\end{equation} I fear (and feel) it is not a correct approach (or at least it is not phrased correctly). Am I going in the right direction? If not, what could I do?","['abelian-categories', 'derived-functors', 'algebraic-geometry', 'spectral-sequences', 'category-theory']"
1202801,Is there a way to rewrite this recursive function so that it can be calculated in linear time?,"I have this recursive function:
$$
  f(0)=f(1)=1 \\
  f(x)=\sum_{i=0}^{x} f(i)×f(x-1-i)
$$ The sequence turns out to be $1,1,2,5,14,42, \dotsc$ I want to be able to calculate the nth element quickly. I think doing it in sequence takes $\operatorname{O}(n^2)$ time. Thanks for any help and please consider I have not formally learnt higher maths. For those interested I came up with this from a computer science problem I found, where there are $2n$ dots spread like a polygon and you must calculate in how many ways can the dots be joined to pairs without intersections. I reduced the problem to the recursive formula above. EDIT thanks, i meant linear time. And I see there are some proofs on wikipedia on how to reduce it, unfortunately I am not at the adequate mathematical level to understand them.","['computer-science', 'recursive-algorithms', 'combinatorics', 'recursion']"
1202849,Ring homomorphism takes discriminant to discriminant,"Let $R[x] \xrightarrow{\sigma} S[x]$ be a ring homomorphism where $R,S$ are integral domains of characteristic $0$. Is it true that for any monic polynomial $f(x) \in R[x],\sigma(disc(f(x)))=disc(\sigma(f(x)))$. My approach was as following: If $\alpha_1,\ldots,\alpha_n$ are roots of $f(x)$ in some extension of $Frac(R)$,then $disc(f(x))=\prod_{1\leq i<j\leq n}(\alpha_i-\alpha_j)^2$.Somehow,if $\sigma$ could somehow be extended such that $\sigma(\alpha_i)$ makes sense,then they would be roots of $\sigma(f(x))$ and since there are $n$ such,they are all the roots and we would be done.","['ring-theory', 'polynomials', 'number-theory', 'algebraic-number-theory']"
1202854,How to find the limit of the following series based on a new operation?,"Lets define an operation as $$a*b=a+b+ab$$  Now I need to find the following limit $$\lim_{n\to\infty}\frac{1}{1}*\frac{1}{4}*\frac{1}{9}*\frac{1}{16}\cdots*\frac{1}{n^2}$$
Now I observed the series and found that it is nothing but the sum of the magnitude of  coefficients of the equation except for the first term $$\prod_{i=1}^{n}(x-\frac{1}{i^2})$$ Now to get the sum of coefficients I substituted the value of $x$ as $-1$ thus the answer will be  $$\prod_{i=1}^{n}(-1-\frac{1}{i^2})-1$$ After this I could not proceed. My first doubt was that for $n$ odd value will be negative , and secondly I am not able to evaluate this limit.$$\prod_{i=1}^{\infty}(1+\frac{1}{i^2})$$","['sequences-and-series', 'algebra-precalculus']"
1202892,Is there a memorable solution to Kirkman's School Girl Problem?,"Given a solution to Kirkman's School Girl Problem , it is of course easy enough to check that it actually is a solution. But how could you reconstruct it if you lost it? Is there a method or algorithm for constructing a solution which is easier to remember than the actual solution? There are many combinatorial problems that have such memorable solutions: In the related Tournament Scheduling Problem you fix one player and rotate the remaining $n-1$ players. In the Transylvanian Lottery Problem you divide the 14 points into 2 Fano planes and consider the 7 lines in each Fano plane. And doubtless many others (which it might also be interesting to list).","['alternative-proof', 'combinatorics', 'combinatorial-designs']"
1202936,"Express the distribution function Y = max{X, 0} in terms of the distribution function of X.","This is just asking for a general case, with general distribution of X. I treated it similar to a minimum problem and said that F(y) is P(x >= 0) for x > 0, P(x = 0) for x = 0 and 0 if 0 > x. Is this the right track?",['probability-theory']
1202973,"What is a linear combination, exactly?","I'm used to the definition of linear combination used in linear algebra textbooks.
I'm reading the book Algebra by Artin and on page 357 he says: If $R$ is the ring $\mathbb{Z}[x]$ of integer polynomials, the notation $(2,x)$ stands for the ideal of linear combinations of $2$ and $x$ with integer polynomial coefficients. According to the definition above, the term $x\cdot x+2 = x^2+2$ is a linear combination of $x$ and $2$, which doesn't feel like linear to me. Here is my question: What is the definition of a linear combination? My confusion may arise because in a vector space there is no such thing as product of vectors.","['abstract-algebra', 'ideals', 'linear-algebra', 'ring-theory']"
1202985,Clarification between a module and a vector space?,"I'm reading Kenneth Hoffman's Linear Algebra, Ed2. In $\S5.5$ it talks about Module and Vector Spaces: (1) ￼If $K$ is a commutative ring with identity, a module over $K$ ( or a $K$-module ) is an algebraic system which behaves like a
  vector space, with $K$ playing the role of the scalar field. (2) A basis for the module $V$ is a linearly independent subset
  which spans (or generates) the module. This is the same definition
  which we gave for vector spaces; and, the important property of a
  basis $\mathscr B$ is that each element of $V$ can be expressed uniquely as a linear combination of (some finite number of) elements of $\mathscr B$. (3) The reader is well aware that a basis exists in any vector space
  which is spanned by a finite number of vectors. But this is not the
  case for modules. (4) Definition. The $K$-module $V$ is called a free module if it
  has a basis. If $V$ has a finite basis containing $n$ elements, then
  $V$ is called a free $K$-module with $n$ generators . (5) Definition. The module $V$ is finitely generated if it
  contains a finite subset which spans $V$. The rank of a finitely
  generated module is the smallest integer $k$ such that some $k$
  elements span $V$. (6) We repeat that a module may be finitely generated without having a
  finite basis. (7) Theorem 5. Let $K$ be a commutative ring with identity. If $V$ is
  a free $K$-module with $n$ generators, then the rank of $V$ is $n$. (8) From Theorem 5 we know that ‘free module of rank $n$’ is the same
  as ‘free module with $n$ generators.’ I'm quite lost here -- Q1: (3) and (6) seem are talking about the same thing, that a module $V$ could be spanned by a finite number of elements $\{\beta_1, \dots, \beta_n\}$, but $V$ might not have a finite basis. Does this mean that in module $V$ there might be some element $\alpha$, that it can be expressed as a linear combination of $\{\beta_1, \dots, \beta_n\}$, but in two different ways? (So this violates the "" uniquely "" requirement in the basis definition?) If so, could you pls give me some examples of such a $V$? Q2: however, (8) says: ‘free module of rank $n$’ is the same as ‘free module with $n$ generators.’ Seems this conflicts with (3) and (6)?","['vector-spaces', 'linear-algebra', 'modules']"
1203008,Roots of a cubic,"How would I find the real root, I know I can say another root is (5+i) but would I use the product of the roots at all?",['linear-algebra']
1203025,Find solutions of the differential equation $3x^2y''+5xy'+3xy=0$.,"Find all the solutions of the form $y(x)= x^m \sum_{n=0}^{\infty} a_nx^n, \ x>0 (m \in \mathbb{R})$ of the differential equation $3x^2y''+5xy'+3xy=0$. That's what I have tried: Since $x>0$ the differential equation can be written as follows. $$y''+ \frac{5}{3x}y'+ \frac{1}{x}y=0$$ $$p(x)=\frac{5}{3x}, q(x)= \frac{1}{x}$$ The point $0$ is regular singular, i.e. the fuctions $xp(x), x^2q(x)$ can be written as power series at a region of $0$. We are looking for solutions of the form $y(x)=x^m \sum_{n=0}^{\infty} a_n x^n$ for a suitable $m \in \mathbb{R}$ and for suitable $a_n \in \mathbb{R}$ and for $x \in (0,R)$ where $R$ is a suitable positive number. Then we have: $$y'(x)= \sum_{n=0}^{\infty} a_n (n+m) x^{n+m-1} \\ \Rightarrow xy'=\sum_{n=0}^{\infty} a_n (n+m) x^{n+m} \\ \Rightarrow 5xy'=\sum_{n=0}^{\infty} 5a_n (n+m) x^{n+m}$$ and $$y''(x)= \sum_{n=0}^{\infty} a_n (n+m)(n+m-1) x^{n+m-2} \\ \Rightarrow x^2y''=\sum_{n=0}^{\infty} a_n (n+m)(n+m-1) x^{n+m} \\ \Rightarrow 3x^2y''=\sum_{n=0}^{\infty} 3a_n (n+m)(n+m-1) x^{n+m}$$ $$3xy= \sum_{n=0}^{\infty} 3a_n x^{n+m+1}$$ So it has to hold the following: $$\sum_{n=0}^{\infty} \left[ 3a_n (n+m)(n+m-1) x^{n+m}+5a_n (n+m) x^{n+m}+ 3a_n x^{n+m+1}\right]=0 \Rightarrow \sum_{n=0}^{\infty} \left[ 3a_n (n+m)(n+m-1) +5a_n (n+m) + 3a_n x\right]x^{n+m}=0 $$ So it has to hold that: $$a_n=\frac{-3a_{n-1}}{3m+3n+2}, \forall n=1,2,3, \dots$$ EDIT :  I am looking again at the exercise. For $m=0$ I got the following: $$a_1=-\frac{3a_0}{5} \\ a_2=\frac{3^2 a_0}{5 \cdot 8} \\ a_3=-\frac{3^3 a_0}{5 \cdot 8 \cdot 11} \\ a-4= \frac{3^4 a_0}{5 \cdot 8 \cdot 11 \cdot 14}$$ So isn't for $m=0$ the general formula for $a_n$ the following?
$$$$ $$a_n=(-1)^n \frac{a_0}{\prod_{i=0}^{n-1} (3i+5)}$$ And for $m=-\frac{3}{2}$ isn't the formula for $a_n$ the following? $$a_n=(-1)^n \frac{3^n a_0}{ \prod_{i=0}^{n-1} \frac{(6i+1)}{2}}$$ If so, then could we say the following? $$y_1(x)= x^0 \sum_{n=0}^{\infty} \frac{(-1)^n x^n}{\prod_{i=0}^{n-1}(3i+5)}$$ and $$y_2(x)=x^{-\frac{3}{2}} \sum_{n=0}^{\infty} \frac{(-1)^n 3^n}{ \prod_{i=0}^{n-1} \frac{(6i+1)}{2}}x^n$$ are solutions of the differential equation for $a_0=1$. $$\left| \frac{\frac{(-1)^{n+1} x^{n+1}}{\prod_{i=0}^n (3i+5)}}{\frac{(-1)^{n} x^n}{\prod_{i=0}^{n-1} (3i+5)}}\right|=\left| \frac{x}{3n+5}\right| \to 0<1$$ Do we deduce from the latter that the radius of convergence is $+\infty$. If so, do we continue as follows? Similarly we show that the radius of convergence of $y_2(x)$ is $+\infty$. $$$$ $y_1, y_2$ are linearly independent in $(0,+\infty)$. Because if $c_1, c_2 \in \mathbb{R}$ with $c_1y_1(x)+c_2y_2(x)=0 \forall x \in (0,+\infty)$ then since $c_1 y_1(x)+ c_2y_2(x)$ is a power series with radius of convergence $+\infty$ we have $0= c_1 y_1(x)+c_2y_2(x)= \sum_{n=0}^{\infty} d_n x^n$ for some $d_n \in \mathbb{R}$ and thus $d_n=0 \forall n=0,1,2, \dots$ However $d_0=c_1=0$ and $d_1=-\frac{3}{5} c_2=0 \Rightarrow c_2=0$. Thus, the general solution of the differntial equation is: $$y(x)=c_1 \sum_{n=0}^{\infty} \frac{(-1)^n x^n}{\prod_{i=0}^{n-1}(3i+5)}+ c_2 x^{-\frac{3}{2}} \sum_{n=0}^{\infty} \frac{(-1)^n 3^n}{ \prod_{i=0}^{n-1} \frac{(6i+1)}{2}}x^n, c_1, c_2 \in \mathbb{R}$$ EDIT :
I remade the calculations for $m=0$ and now I got the following:
$$$$
For $n=1$: $a_1=-\frac{3a_0}{1 \cdot 5}$ $$$$
For $n=2$: $a_2=\frac{3^2 a_0}{2 \cdot 5 \cdot 8}$
$$$$
For $n=3$: $a_3=-\frac{3^3 a_0}{2 \cdot 3 \cdot 5 \cdot 8 \cdot 11}$
$$$$
For $n=4$: $a_4=\frac{3^4 a_0}{2 \cdot 3 \cdot 4 \cdot 5 \cdot 8 \cdot 11 \cdot 14}$
$$$$ Are my current calculations right or were the previous one correct? $$$$
If they are right how could we write the formula of $a_n$ without the use of the Gamma function? EDIT :I retried it again. Couldn't we write the general formula for $a_n$ when $m=0$ as follows? $$$$
$$a_n=\frac{(-1)^n a_0}{n! \prod_{i=1}^n (3i+2)}$$
Or am I wrong? Also it should be $m_2=-\frac{2}{3}$. Or am I wrong? If it is like that isn't the general formula for $a_n$ in this case the following? $$a_n=(-1)^n \frac{a_0}{n! \prod_{i=0}^{n-2} (2 \cdot 2+3 \cdot i)}$$ Or am I wrong?",['ordinary-differential-equations']
1203036,Why aren't mathematical series zero-indexed? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. This question is not about mathematics, within the scope defined in the help center . Closed 4 months ago . Improve this question We're learning about sequences in calculus class, and I keep assuming they are zero-indexed because of my experience in programming. Why aren't they zero-indexed? Can they be zero-indexed?",['sequences-and-series']
1203068,When is the convolution of a product the product of convolutions?,"Although the convolution of the product is not the product of the convolution, i.e. $$fg*h\neq (f*h)(g*h).$$ I am wondering if  this true (for a suitable class of functions) in the limit when one uses a delta net. A delta net is defined as: A net $\{(\varphi_{n})\}\in(0,1]$ of smooth functions on $\mathbb{R}^{n}$ is called a  delta net, if $supp( \varphi_{n})\rightarrow {0}$ as $n\rightarrow 0$ $\int\varphi_{n} d\mu\rightarrow $ 1 as $n\rightarrow 0$ $\varphi_{n}$ is uniformly bounded in $L^{1}(\Omega,\mu)$ For example if we consider  the convolution of $f*\varphi_{n}=f_{n}$ where $f$ is in $L_{loc}^{p}$ and if $g*\varphi_{n}=g_{n}$ is uniformly bounded then:
$$\lim_{n\rightarrow 0}||f_{n}g_{n}-fg||_{p_{loc}}\rightarrow 0$$
Of course using the properties of convolutions one also has that:
$$\lim_{n\rightarrow 0}||(fg)*\varphi_{n}-fg||_{p_{loc}}\rightarrow 0$$ I am wondering if anyone ones similar results for $L^{p}$ convergence, measure convergence, pointwise convergece, etc with different assumptions for $f$ and $g$.","['sobolev-spaces', 'convergence-divergence', 'functional-analysis']"
1203069,Convergence epsilon - check my proof please,"Fairly straightforward question (I hope so anyway), would be very grateful if someone could check my proof. I need to show that $\frac{n+1}{n+3} \to 1 \space \text{as} \space n \to \infty$. I start by choosing an arbitrary $\epsilon > 0$. Then I will set $N \in \mathbb{N}$ such that $N \geq \frac{2}{\epsilon} - 1$ Then for some $n \in \mathbb{N}$ such that $n \geq N$, it holds that $n \geq \frac{2}{\epsilon} - 1$ $| \frac{n+1}{2} | \geq \frac{1}{\epsilon}$ $| \frac{2}{n+1}| \leq \epsilon$ $| \frac{n+3}{n+1} - 1 | \leq \epsilon$ as required. Edit: I realise that in some cases, convergence is on the open interval, but my lecturer uses closed epsilon neighborhoods in his definition.","['proof-verification', 'real-analysis', 'sequences-and-series', 'epsilon-delta', 'convergence-divergence']"
1203077,"Sum of Euler's totient, Möbius and divisor functions","Find all the numbers $n$, so that 
$$n=\varphi(n)+\mu(n)+\tau(n),$$
Where $\varphi$ is the Euler's totient function, $\mu$ is the Möbius function and $\tau$ is the sum of positive divisors function. I could use some help on how to approach this problem.",['number-theory']
1203081,Solving $(f(x))^2 = f(\sqrt{2}x)$,"I would like to know how to solve this equation : $$f(x)^2 = f(\sqrt{2}x)$$ We assume that $f : \mathbb R \to \mathbb R$ is $\mathcal C^{2}$. The answer should be $f(x)=e^{-x^{2}/2}$, but I don't know how to show this.","['calculus', 'real-analysis', 'functional-equations']"
1203094,Is there real analogue for Laurent series?,"For example,
$$\frac{3}{z^2-5z+4}$$
has a Laurent series expansion on the angular region $1<|z|<4$. Does the real function
$$\dfrac{3}{x^2-5x+4}$$
have some sort of Laurent series on $(-4,-1)\cup (1,4)$? I'm taking complex analysis, but I have almost no experience with series from calculus. It wasn't in the curriculum. I really need to fill in this gap in my math knowledge :(","['laurent-series', 'complex-analysis']"
1203096,Order of operations when balancing equation,"This is a trivial question, yet I have only really thought about it today and would like some insight. To find the $x$-intercept of the following function: $$f(x) = 2 \sin x + 1$$ We set $f(x) = 0$, subtract $1$ from both sides, divide by $2$ and get the answer: $\sin x= -\frac 12 $. But if we divide by $2$ first, then subtract $1$, we get the answer: $\sin x = -1$. How do we know which operation to ""undo"" first in order to obtain the correct result?","['trigonometry', 'algebra-precalculus', 'functions']"
1203112,"Solving $3\sin x - \cos x = 2$ for $x \in [0, 2\pi)$","Problem: Solve $$3\sin x - \cos x = 2, \ \ \  x \in [0, 2\pi)$$ My attempt: I am able to solve it using Weierstrass substitutions and a good bit of patience, but the problem was given at an exam at a level where such substitutions are not part of the curriculum. I've tried to find ways to rewrite the equation by using $\sin x / \cos x = \tan x$ which I expect is the ""desired"" method, but for some reason, my algebra is failing me, and I can't seem to eliminate the $\sin$ and $\cos$ terms. I've tried squaring both sides, but given the coefficient on $\sin x$, I can't find a way to use that identity either. So far I end up with $$9\sin^2x - 6\sin x\cos x + \cos^2x = 4$$ Any help appreciated!",['trigonometry']
1203143,constant stalks but not constant sheaf?,"In the coherent world we have the following: if X is reduced and F is a coherent sheaf on it, then if the rank of all fibres in constant then F is locally free. I thought something similar held in the topological world but cannot seem to prove it.
In other words: is the following true? Let X be a topological space (say a manifold) and consider a sheaf of Q-vector spaces F. Assume also that F(U) is finite-dimensional for all opens U. Assume also that the stalk $F_x$ has dimension n for all $x \in X$. Then F is a locally constant sheaf. I can easily show that for each $x$ there is a neighborhood $U$, with $F(U)$ of dimension n and such that, for any $x \in V \subset U$ the restriction $F(U) \to F(V)$ is an isomorphism. However, if $V$ is a subset of U not containing x, then I don't know to show that the restriction is an isomorphism (which is what's missing to show that the sheaf is actually locally constant).","['algebraic-geometry', 'homology-cohomology', 'general-topology', 'sheaf-theory']"
1203193,Find the slope at $t=16$ for $s(t) = $arctan$(\sqrt{t})$,"A particle moves along the x axis so that its position at any time when t is greater than or equals zero is $s(t) = $arctan$(\sqrt{t})$. Find the velocity of the particle at $t=16$. The point of this question isn't to find the velocity, but to solve for the derivative and then find the slope of the line at a certain point. The velocity is the slope of the line of a position time graph, so I took the derivative: $$s'(t) = {\frac{1}{\sqrt{t}(2t+2)}}$$ I then made $t=16$, to get: $$s'(16) = 7.4 \cdot 10^{-3} \text{m/s}$$ Did I do this correctly? Any hints or advice would be appreciated.","['solution-verification', 'calculus', 'derivatives']"
1203201,An inverse of Jordan matrix - basis,"Let $A\in M_{n\times n}$ be and invertible matrix over complex field and we assume it's already at Jordan form where $B=\{v_1,…,v_n \}$ is Jordan basis for A. Find Jordan form and Jordan basis for $A^{-1}$ I think I can show that Jordan form will be almost the same with difference that eigenvalue $\lambda$ will be replaced by $\frac{1}{\lambda}$ at diagonal but I don't have idea how basis for this will looks like.","['eigenvalues-eigenvectors', 'jordan-normal-form', 'linear-algebra']"
1203202,Recovering a group from it's group algebra over $\mathbb{Z}$,Question : Is it possible to recover a finite group from it's group algebra over $\mathbb{Z}$? More precisly. By $G_1$ and $G_2$ we denote two finite groups. Let $\mathbb{Z} ( G_1 )$ and $\mathbb{Z} ( G_2 )$ be group algebras. Suppose that $\mathbb{Z} ( G_1 )$ is isomorphic $\mathbb{Z} ( G_2 )$ as algebras. Is $G_1$ isomorphic to $G_2$? Comment. It is quite obvious that there are not isomorphic finite groups $G_1$ and $G_2$ such that $\mathbb{C} ( G_1 )$ is isomorphic $\mathbb{C} ( G_2 )$. For instance two abelian groups of the same order.,"['abstract-algebra', 'group-theory']"
1203220,When can L'Hospital rule be used on Multivariable limits.,"I am wondering about a multivariable limit, and in particular, is it ever valid to use L'hospital rule. For example, I am working on $$ \lim_{(x,y) \to (1,1)} \frac{x^3-y}{x-y}$$ This is what I have done, let $$f(x,y)=\frac{x^3-y}{x-y}$$ $f(x,0) \rightarrow 1$ as $(x,y) \rightarrow (1,1)$ and similiary $f(0,y) \rightarrow 1$ as $(x,y) \rightarrow (1,1)$ Okay now here is where I have a few questions ( I haven't looked at the answer or used wolfram or anything because I want to make sure I understand it first), should I continue to try out different parts, or should I try to see if I can prove the limit is 1. in trying different paths, say $$f(x,x^2)=\frac{x^2(1-x^3)}{(1-x)}$$ would it now be valid to use L'hospital? because the y is gone and we would have 0/0 as x $\rightarrow 1$? or is it never valid to use this rule for multi valued? Is this the right approach I should be taking or is there something else I should be thinking of? Thank you","['multivariable-calculus', 'limits']"
1203251,"How many different permutations are there of the sequence of letters in ""MISSISSIPPI""?","There are 11 letters in the word. M - 1
I - 4
S - 4
P - 2 so the number of different permutations is $\dfrac{11!}{1! 4 !4!2!}$ Is this correct solution?",['combinatorics']
1203269,Two-sided hitting time of Brownian motion,"I am trying to compute the hitting time of a linear Brownian motion on a two-sided boundary. More specifically, let $W_t$ be a (one-dimensional) Wiener process. Let $T = \inf \{t: |W_t| = a \}$ for some $ a > 0$. I want to find $\mathbb{P}\{ T > t\}$. I know that probability distribution hitting time of a positive level, $\inf \, \{t: W_t = b\,, \  b > 0 \}$ can be computed quite easily, but I am not sure how to deal with it when dealing with the two-sided hitting time, i.e. with the absolute value. I am thinking of the minimum of hitting times of level $a$ and $-a$, but I can't get a promising conclusion.","['probability', 'stochastic-processes']"
1203273,How to imagine the difference between the following schemes?,"Consider $A=\operatorname{Spec} k[x]_{(x)}[t]$ and $B=\operatorname{Spec} k[x,t]_{(x)}$ for a field $k$ (Vakil, note 11.3.8). For me, both are infinitesimal neighborhoods of an affine line - the former is the product of an infl nbhd of a point on a line with a line, the latter is simply an infl nbhd of a line on an affine plane. How should I imagine the difference between them, or are they too sophisticated?","['algebraic-geometry', 'schemes', 'commutative-algebra']"
1203288,For which $n$ does $n\mid 1^n+2^n+\cdots+n^n$?,"Find all the natural numbers $n$ such that
$$n\mid 1^n+2^n+\cdots+n^n.$$ We know through Faulhaber's formula, that 
$$\sum_{k=1}^{n}k^n=\frac1{n+1}\sum_{k=0}^n\binom{n+1}{k}B_k n^{n+1-k},$$
where $B_k$ is a Bernoulli number. I checked few dozen values of $n$ and it seems that only odd numbers are solutions. Any ideas on how to proceed from here?",['number-theory']
1203318,Why is the boundary of a topological space $M$ denoted $\partial M$?,Why is the boundary of a topological space $M$ often denoted $\partial M$? Is there any connection between boundary and partial derivative?,"['notation', 'general-topology']"
1203326,Rearranging a Staircase Grid into a Square,"Is there any way to rearrange the above ""staircase"" grid into three pieces that can be rearranged into the 6x6 square grid below it? I have tried this problem for over six hours and have not arrived at any solution. There has to be some general strategy in approaching this problem other than brute force, right?? I would appreciate any and all help--hints, suggestions, anything... I've gone mad trying to solve it :(","['geometry', 'puzzle']"
1203363,Convergence of the probability of RV with negative binomial distribution,"I am seeking an answer to this question. Given the number of tools successfully produced $R$ before the $yth$ failure follows a negative binomial distribution $(y,p)$. $$
P(R=r)=\begin{pmatrix}r+y-1\\
r
\end{pmatrix}(1-p)^{y}p^{r}
$$ Prove that $P(R=r)$ converges to $0$ as $y$ increases. I can see that I need to prove that the factorial ratio 
$
\begin{pmatrix}r+y-1\\
r\end{pmatrix}
$ is going to infinity slower than $(1-p)^y$ is going to $0$, as $y$ increases.","['probability', 'statistics']"
1203368,Show that $\pi =4-\sum_{n=1}^{\infty }\frac{(n)!(n-1)!}{(2n+1)!}2^{n+1}$,"Show that $$\pi =4-\sum_{n=1}^{\infty }\frac{(n)!(n-1)!}{(2n+1)!}2^{n+1}$$
I found the formula of $\pi$ by using the numerical calculation but I dont have the proving. Any help would be appreciated.","['calculus', 'pi', 'number-theory', 'sequences-and-series', 'integration']"
1203371,The closed unit ball is not compact in infinite dimension spaces. Why?,"We know that in finite dimension spaces the closed unit ball is compact, that is if H is a finite dimension space, then there exists an $u$ in the closed unit ball in H and $T \in \mathcal{L}(H, \mathbb{R})$ such that $||T|| = |T u|$. Why doesn't it happen in infinite dimension spaces? For example, let $H = C([a, b])$ with the sup norm. Why doesn't exist an element $u$ in the closed unit ball in $C([a, b])$ such that $T u = ||T||$? Thank you!","['operator-theory', 'functional-analysis']"
1203438,Orthogonality for Binomial Coefficients,"Could somebody explain to me where these two formulas come from as applications of the binomial theorem?
 $$\sum_{k=0}^n {n \choose k}(-1)^kk^r=0$$
for non-negative integers $r\lt n$. And
$$\sum_{k=0}^n {n \choose k}(-1)^kk^n=(-1)^nn!$$","['binomial-theorem', 'summation', 'binomial-coefficients', 'combinatorics']"
1203497,Eigenvectors of a complex matrix,"Given the following matrix $\begin{pmatrix}
0 & 1-i & 0\\
1+i & 0 &1-i\\
0& 1+i &0\\
\end{pmatrix}$ I have found the Eigenvalues $0, 2,-2$. But I have no idea how to calculate the corresponding Eigenvectors and I failed with Gaussian method. What could you recommend? Thanks in advance!",['linear-algebra']
1203506,Convergence in $L^1_{loc}$ implies convergence almost everywhere,"Let $f_n\in L^1_{loc}(\mathbb{R})$ be a sequence of a locally integrable functions such that for all $a<b$ 
$$\int_a^b|f_n(x)|dx\to 0,$$
when $n\to\infty$. We know that for each interval $[a,b]$ there exists a subsequence $(f_{p_n})$ which converges pointwise a.e. on $[a,b]$ to $0$. But can we construct a subsequence which converges a.e. on $\mathbb{R}$. My problem is that the subsequence $(f_{p_n})$ depends on the interval $[a,b]$. I don't even know if it is possible to do this or not.","['real-analysis', 'functional-analysis', 'lp-spaces', 'convergence-divergence', 'lebesgue-integral']"
1203518,Lotka-Volterra model with two predators,"In this, Lotka-Volterra model, we have two predators: $$\frac{dp}{dt} = ap\left(1-\frac{p}{K}\right) - (b_1q_1+b_2q_2)p$$
  $$\frac{dq_1}{dt}=e_1b_1pq_1-m_1q_1$$
  $$\frac{dq_2}{dt}=e_2b_2pq_2-m_2q_2.$$ Where $p$ is the prey, $q_1$ is the first predator and $q_2$ is the second predator. Also, $bpq$ is the interaction rate between the species, $m$ is the mortality rate of the predators, $K$ is the carrying capacitance. We also have that $a=0.2, \ K = 1.7, \ b_1 = 0.1, \ b_2 = 0.2, \ m_1=m_2=0.1, \ e_1 = 1.0,$ and $e_2 =2.0.$ We also, have $p(0) = q_2(0) = 1.7$ and $q_1(0) =1.0$. I solved this system using Euler's method. I noticed that $\text{predator}_1$ vanishes with time thus two predators cannot co-exist in this model. My question is, how do I vary the characteristics of the second predator in order to see if there is an equilibrium? Also, what do I vary, in this system, in order to see if there is chaos between the two species?","['dynamical-systems', 'numerical-methods', 'ordinary-differential-equations']"
1203541,Non-vanishing holomorphic functions on the closed unit disk have the same absolute value.,"This is a past prelim and homework problem for which my proof is missing a detail or two: Suppose $f$ and $g$ are non-vanishing holomorphic functions which extend continuously to $\bar{\mathbb D}$. If $|f(z)| = |g(z)|$ on $\partial\mathbb D$, then $|f(z)| = |g(z)|$ for all $z \in \bar{\mathbb D}$. My proof is as follows: Since $f$ and $g$ are non-vanishing and holomorphic on $\mathbb D$, then $f/g$ and $g/f$ are well defined and holomorphic on $\mathbb D$. Also, $f/g$ and $g/f$ are continuous at all points such that $f(z) \neq 0$ and $g(z) \neq 0$, respectively. I go on to use the Maximum Modulus Theorem to show that $|f/g| = 1$ on $\mathbb D$, under the assumption that $f/g$ and $g/f$ are actually continuous on the boundary of $\mathbb D$. My question: Is it possible to extend $f/g$ to a continuous function on the boundary? I can also prove the statement if I can show that $|f/g|$ or $|g/f|$ is constant on the boundary (in which case, $f/g$ is constant or has a zero on the interior; the latter can't happen). I tried to show that $|f/g|$ is constant by showing that all of the singularities of $f/g$ are removable, and thus extending the function via continuity. We know that if $g(z) = 0$ for some $z$ on the boundary, then $f(z) = 0$ by assumption as well, but do these zeros have the same multiplicity?",['complex-analysis']
1203549,discrete math: Big-oh notation,"I'm confused about how to solve big-oh notation problems using the definition and basic algebra. for example, a problem like this: Prove that
(x sin x + x log(2x + 4) + ((x^3 + 1)/(x^2 + 1)) is an element of big-oh(x log x). hint:This will require both the algebraic properties of $O$ and its formal definition. I'm thinking I can separate it into 3 parts and show each part is big-oh using limits(though I'm not sure that counts as an algebraic property) and the definition $(C,K)$? I'd appreciate any help starting this out.",['discrete-mathematics']
1203565,Are these equivalent? $\cos^2(5x) = (\cos(5x))^2$,Are these equivalent? $$\cos^2(5x) = (\cos(5x))^2$$,"['convention', 'trigonometry', 'algebra-precalculus', 'functions']"
1203572,"Why does Titchmarsh say that we can move the derivative under $\frac{2}{\pi}\int_0^\infty \frac{\Xi(t)}{t^2 + \frac{1}{4}} \cosh(\alpha t) \, dt$","If we define the Riemann-Xi function as $$ \Xi(t) = \xi(\frac{1}{2} + it)$$ where $$\xi(s) = \frac{1}{2}s(s-1)\pi^{-\frac{s}{2}}\Gamma(\frac{s}{2})\zeta(s),$$ then according to Titchmarsh in his adaptation of Hardy's proof that the zeta function has infinitely many zeros on the critical line, if we consider the integral $$ \frac{2}{\pi}\int_0^\infty \frac{\Xi(t)}{t^2 + \frac{1}{4}} \cosh(\alpha t) dt, $$ then ""since $\zeta(\frac{1}{2} + it) = O(t^A)$, $\Xi(t) = O(t^Ae^{-\frac{1}{4}\pi t})$, and the above integral may be differentiated with respect to $\alpha$ any number of times provided that $\alpha < \frac{1}{4}\pi$."" I don't really understand either of the claims; that is, why is $\Xi(T) = O(t^Ae^{-\frac{1}{4}\pi t})$ and why does this imply that we can move the derivative under the integral sign any number of times as long as $\alpha < \frac{1}{4}$.  Can someone explain these things? Here is my work so far: After plugging the definition of $\xi(s)$ into the definition of $\Xi(t)$ we get that $$ \Xi(t) = \frac{1}{2}(-\frac{1}{4} - t^2)\pi^{-\frac{1}{4} - \frac{it}{2}}\Gamma(\frac{1}{4} + \frac{it}{2})\zeta(\frac{1}{2} + it).$$ I can prove that for $|t| \geq 1$ and $Re(s) \geq \frac{1}{2}$, $|\zeta(s)| \leq |t|^{\frac{1}{2} + \epsilon}$ and I can also show that $|\Gamma(\frac{1}{4} + \frac{it}{2})| \leq \frac{\Gamma(\frac{1}{4})}{|t|}. $ Additionally, $|\pi^{-\frac{1}{4} - \frac{it}{2}}| = \pi^{-\frac{1}{4}} = e^{-\frac{1}{4} \log(\pi)}$.  I'm stuck after this.  Can anyone help?","['riemann-zeta', 'analytic-number-theory', 'asymptotics', 'analysis', 'complex-analysis']"
1203583,Find rational points on $x^2 + y^2 = 3$ and on $x^2 + y^2 = 17$,"$(a)$ Find all rational points on the circle $x^2 + y^2 = 3$, if there are any. If there is none, prove so.
 $(b)$ Find all rational points on the circle $x^2 + y^2 = 17$, if there are any. If there is none, prove so. I'm not sure how proceed with finding a general formula (if there is one) I know that for $(a)$ there is no rational points but I don't know how to explain that there are none. whereas for $(b)$ there are such points, $(1,4)$ for example. I think that we can find the intersection between the line $y=m(x-1)+4$ and $x^2 + y^2 = 17$ Any help is appreciated!","['rational-numbers', 'sums-of-squares', 'number-theory', 'diophantine-equations']"
1203601,"If $\{a_n\}$ and $\{b_n\}$ are Cauchy, then $\{a_n + b_n\}$ is Cauchy.","If $\{a_n\}$ and $\{b_n\}$ are Cauchy, then $\{a_n + b_n\}$ is Cauchy. Proof: $|a_{m_1}-a_{n_1}|\lt \epsilon_1$ and $|b_{m_2} - b_{n_2}|\lt \epsilon_2$ Then take $m_3=\max(m_1,m_2),n_3=\max(n_1,n_2)$ Then $|a_{m_3}+b_{m_3} - a_{n_3}-b_{n_3}|\leq |a_{m_3}-a_{n_3}|+|b_{m_3}-b_{n_3}|\lt2\epsilon$ Now I am unsure how to progress. It would work if my original cauchy sequences were less than $\frac{\epsilon}{2}$, but I don't understand how I would obtain this. Thanks","['cauchy-sequences', 'convergence-divergence', 'real-analysis']"
1203603,Is the given relation transitive?,"Consider the relation: $$R = \{(a,b), (a,c), (c,c), (b,b), (c,b), (b,c)\}$$ on the set $A = \{a,b,c\}$. Is $R$ transitive? I said no because $$[(c, c) \wedge (a, c)] \Longrightarrow (c,a)$$ is a false statement. Is my reasoning correct?",['discrete-mathematics']
1203623,Proving an ideal is maximal,"Let p be a prime.  show that A = {(px,y) : x,y $\in$ $\mathbb Z$ }  is a maximal ideal of $\mathbb Z$ x $\mathbb Z$. I am having trouble showing that A is maximal.  To show A is an ideal, first note that $\mathbb Z$ x $\mathbb Z$ is a commutative ring.  Let (px,y) $\in$ A and let (a,b) $\in$ $\mathbb Z$ x $\mathbb Z$.  Then (px,y)(a,b) = (pxa,yb) $\in$ A.  Thus A is an ideal (Is this sufficient?).  To show A is maximal, I think I could either show that ($\mathbb Z$ x $\mathbb Z$)/A is a field or show that any ideal containing A must equal $\mathbb Z$ x $\mathbb Z$, perhaps by showing a unit must be in in an ideal containing A?.  The main trouble I am having is seeing what the cosets from ($\mathbb Z$ x $\mathbb Z$)/A look like.  Do I consider possible remainders for each coordinate? Any hints as to either approach or an idea for a different approach are appreciated.","['abstract-algebra', 'ideals']"
1203639,Is R reflexive? symmetric? transtitive?,"Define a relation on $\mathbb{Z}$ as $xRy$ if $|x-y| < 1$ Is $R$ reflexive? symmetric? transitive? Okay so my reasoning is as such: $|x-y| < 1$ only when $x=y$ $R$ exists if $x=y$ If $x=y$ the relationship is reflexive. If $x=y$ the relationship is symmetric. If $x=y$ the relationship is not transitive. Counterexample of non-transitivity: $(a,a) \wedge (b,b) \Rightarrow (a,b)$ is false. Is my reasoning correct?",['discrete-mathematics']
1203666,Two complicated limits: $\lim_{x\to 0}\frac{e^{ax}-e^{bx}}{\sin(cx)}$ and $\lim_{x\to 0} x(a^{\frac1x}-1)$,"I need to solve these 2 limits ( without using L'Hospital's Rule) , but I can't figure out how to go about them: Let $a \neq b$, $c \neq 0$. $$\lim_{x\to 0}\frac{e^{ax}-e^{bx}}{\sin(cx)}$$ Also, let $a>0$, $a \neq 1$. $$\lim_{x\to 0} x(a^{\frac1x}-1)$$ I don't necessarily need the result, more like understanding the process.","['limits-without-lhopital', 'limits']"
1203676,Is an empty set reflexive? Symmetric? Transitive? [duplicate],"This question already has an answer here : Prove that the empty relation is Transitive, Symmetric but not Reflexive (1 answer) Closed 9 years ago . Suppose $$A\neq\emptyset$$ Since, $$\emptyset\subseteq A\times A$$ the set $$R=\emptyset$$ is a relation on A. Is $R$ reflexive? symmetric? transitive? I remember hearing something can be ""vacuously"" true. So the empty set would be reflexive, symmetric and transitive because it doesn't meet the definition? So there is no $(x,x)$ that can exist in $R$ therefore vacuously reflexive. There is no $(x,y)$ that can exist in $R$ therefore vacuously symmetric. There is no $(x,y)$ that can exist in $R$ therefore vacuously transitive. Is my reasoning correct here?",['discrete-mathematics']
1203677,Why is the Riemann curvature tensor the technical expression of curvature?,"According to my textbook on general relativity (Sean Carrol's book) and differential geometry, the Reimann curvature tensor is the technical expression of curvature. What makes the tensor so special? Why is the Riemann curvature tensor the technical expression of curvature?","['differential-geometry', 'curvature', 'tensors']"
1203683,Proving a ring is Noetherian when all maximal ideals are principal generated by idempotents,"Let $R$ be a commutative ring with unity such that all maximal ideals are of the form $(r)$ where $r\in R$ and $r^2=r$. I wish to show that $R$ is Noetherian. I know that if all prime (or primary) ideals in $R$ are finitely generated, then $R$ is Noetherian, so my plan was to show that all prime or primary ideals in $R$ are maximal and therefore of the above form (finitely generated), but I seem to be missing what exactly I should do to show that. Any help is appreciated!","['abstract-algebra', 'noetherian', 'commutative-algebra']"
1203697,Deformations of associative algebras and Hochschild cohomology.,"I am studying the deformation theory of associative algebras (and Poisson algebras) and came across a question for which I cannot find an answer: Let $(A, \mu)$ be a commutative associative algebra over a field $\mathbb{F}$ . The first order deformations of $\mu$ are classified up to equivalence by the second Hochschild cohomology group $\mathrm{HH}_{\mu}^{2}(A)$ . I’m wondering if this can be generalized in the following sense: Given a $k$ th order deformation $\mu_{(k)} = \mu + \mu_{1} h + \dotsb + \mu_{k} h^k$ of $\mu$ , in some cases it is possible to extend it to a $(k+1)$ th order deformation $\mu_{(k+1)} = \mu_{(k)} + \mu_{k+1}h^{k+1}$ , where $\mu_{k+1}$ is a bilinear map $A \times A \to A$ . In this case it is natural to ask what are all the possible extensions up to equivalence. It turns out that the set of all possible deformations consists of the affine space $
\mu_{k+1} + \ker(\delta_{\mu}^2),
$ where $\delta_{\mu}^2 \colon \mathrm{HC}^{2}(A) \to \mathrm{HC}^{3}(A)$ is the Hochschild coboundary operator. Furthermore, if two extensions correspond to cohomologous elements of $\mathrm{HC}^2(A)$ , it turns out that the extensions are equivalent (in the sense that the resulting deformed algebras are isomorphic). My question is whether the converse holds, which is to say do equivalent extensions correspond to cohomologous elements? (And hence $\mathrm{HH}_{\mu}^2(A)$ would classify the $(k+1)$ th order deformations extending a particular $k$ th order deformation of $\mu$ .) Here is what I have tried so far (in the case of $k = 2$ ): consider two equivalent $2$ nd order deformations of $\mu$ : $$
  \mu_{(2)} = \mu + \mu_{1} h + \eta h^2 \,,
  \quad
  \mu_{(2)}' = \mu + \mu_{1} h + \eta' h^2 \,,
$$ with isomorphism $\Phi = 1 + \phi h + \psi h^2$ . Then from the requirement that $$
  \Phi(\mu_{(2)}(F, G)) = \mu_{(2)}'(\Phi(F), \Phi(G))
$$ for $F, G \in A$ we get that $$
  \delta_{\mu}^{1}(\phi) = 0 \,,
$$ and $$
  \eta - \eta'
  = \delta_{\mu}^{1}(\psi) + \delta_{\mu_{1}}^{1}(\phi) + \mu \circ \phi \otimes \phi \,.
$$ Note that I use the notation $\delta_{\mu_{1}}^{1}(\phi)(F, G) = \mu_{1}(F, \phi(G)) + \mu_{1}(\phi(F), G) - \phi(\mu_{1}(F, G))$ . I need to end up with a formula like $\eta - \eta' = \delta_{\mu}^1(\gamma)$ for some $\gamma \in \mathrm{Hom}_{\mathbb{F}}(A, A)$ . It doesn’t seem like its going to work, but I haven’t been able to think of a counterexample, and I have been assured that the result should be true. P.S. I’d like to know if the analogous statement holds for deformations of a Poisson algebra.","['abstract-algebra', 'homology-cohomology', 'deformation-theory', 'hochschild-cohomology']"
1203722,approximate vanishing in Pontryagin dual,"Let $\{n_k\}\subseteq \mathbb{Z}$ to be any given sequence of integers, and suppose it satisfies the following property: (*) For any $\lambda\in A\subseteq \mathbb{T}$(the unit circle), $|\lambda^{n_k}-1|\to 0$ as $k\to\infty$. Question 1 : Is it true that there exists a subsequence of $\{n_k\}$, say $\{n'_{l}\}$, such that $n'_{l}=0,\forall l\geq 1$ under the following cases: Case1: $A=\mathbb{T}$ in (*). Case2: $A$ is a dense subset (or dense subgroup) of $\mathbb{T}$. Case 3: $A$ is a measurable subset of $\mathbb{T}$ with postive Lebesgue measure. RK: Clearly if $\{n_k\}$ contains a bounded subsequence, then the answer is yes. For case2, when $A$ is ""good"" enough, then the answer is no. A general version of the above question is the following: Suppose $X$ is a compact metrizable abelian group, and $\{\phi_n\}\subseteq \widehat{X}$(the Pontryagin dual of $X$). And suppose it satisfies the following property: (*) For any $x\in A\subseteq X$, $|\phi_n(x)-1|\to 0$ as $n\to \infty$. Question 2 : Can we prove that there exists a subsequence of $\phi_n$, say $\phi'_l$, such that $\phi'_l(x)=1 \forall x\in X, l\geq 1$ under the assumption that $A\subseteq X$ is a dense subset(or subgroup)?","['dynamical-systems', 'sequences-and-series', 'analysis', 'reference-request', 'topological-groups']"
1203799,Integral of derivatives of $e^{-x^2}$,"Let $m,n,k$ be nonnegative integers. How might I go about evaluating the following integral? $$ \int_{-\infty}^\infty \left( \frac{\mathrm{d}^m}{\mathrm{d}x^m} e^{-x^2} \right) \left( \frac{\mathrm{d}^n}{\mathrm{d}x^n} e^{-x^2} \right) x^k e^{x^2} \mathrm{d}x $$","['definite-integrals', 'integration']"
1203812,Is the determinant of a RREF matrix equal to the determinant of the original matrix?,"Prove or disprove: If $R$ is the reduced row echelon form (RREF) of $A$ , then $\det A = \det R$ , where $A$ is an $n \times n$ matrix.","['determinant', 'gaussian-elimination', 'matrices']"
1203868,"Given a pair of continuous functions from a topological space to an ordered set, how to prove that this set is closed? [duplicate]","This question already has answers here : How to prove that this set is closed? (2 answers) Closed 7 years ago . Given that $X$ is an arbitrary topological space, $Y$ is a totally ordered set in the order topology, and $f$, $g \colon X \to Y$ are continuous functions, how to show that the subset $A$ of $X$ given by 
$$ A \colon= \left\{ \ x \in X \  \colon \  f(x) \leq g(x) \ \right\} $$ 
is closed in $X$? Edit based on the answer by Hagen von Eitzen: Let $U \colon= \{ u \times v \in Y \times Y \ \colon \ u < v \ \}$. We show that $U$ is open in $Y \times Y$. Let $u \times v \in U$. Then $u < v$. Case I. If there is some $y \in Y$ such that $u < y < v$, then $u \times v \in (-\infty, y) \times (y, +\infty) \subset U$. Case 2. If $(u,v)$ is empty, then $u \in (-\infty, v)$ and $v \in (u, +\infty)$, and so $u \times v \in (-\infty, v) \times (u, +\infty)$. Moreover, if $a \times b \in (-\infty, v) \times (u, +\infty)$, then we must have $a < v$ and $b> u$. So $a \leq u < v \leq b$, which implies that $a < b$ and so $a \times b \in U$. Thus, $u \times v \in (-\infty, v) \times (u, +\infty) \subset U$. So $U$ is open in $Y \times Y$. Similarly, we can show that the set 
$$V \colon= \left\{ \ u \times v \in Y \times Y \ \colon \ u > v \ \right\}$$ is open in $Y \times Y$. Thus, it follows that the set $A \colon= \{ \ u \times v \in Y \times Y \ \colon \ u \leq v \ \}$ is closed in $Y \times Y$. Now since the maps $f \colon X \to Y$ and $g \colon X \to Y$ are continuous, so is the map $f \times g \colon X \to Y \times Y$ defined as
$$(f \times g)(x) \colon= f(x) \times g(x) \ \mbox{ for all } \ x \in X.$$ Thus, the inverse image under $f \times g$ of the set $A$ is closed in $X$. But 
$$ 
\begin{align} 
(f \times g)^{-1} (A) &= \left\{ \ x \in X \ \colon \ (f \times g)(x) \in A \ \right\} \\
&= \left\{ \ x \in X \ \colon \ f(x) \times g(x) \in A \ \right\} \\
&=  \left\{ \ x \in X \ \colon \ f(x) \leq g(x) \ \right\}.
\end{align} 
$$","['continuity', 'general-topology']"
1203874,Is standard eigenvalue optimization problem convex,"For any arbitrary  symmetric matrix A , is the standard eigenvalue problem convex $ \lambda_{max}(A)= \max_{\|x\| \leq1} x^{T}Ax$","['convex-optimization', 'optimization', 'nonlinear-optimization', 'calculus']"
1203889,How should we think about equations like $dy = 2x \cdot dx$ from the viewpoint of modern geometry?,"We've just started learning about (smooth) manifolds at uni, and I'm kind of hoping this will finally help me get a handle on the dreaded Leibniz notation. Now I've read that expressions $dy$ like can be viewed as differential $1$-forms. I suppose this somehow allows us to make sense of equations like $$dy = 2x \cdot dx$$ So I tried thinking through the details. Pretty soon, I decided it would be nice be able to write something like the following: Let $M$ denote the smooth manifold given as follows. Distinguished Projections: $y,x$ Equations: $y=x^2$ (The idea is that $M$ can be understood concretely as $\{(x,y) \in \mathbb{R}^2 \mid y=x^2\}.$) Then $M \models y=x^2$. Therefore $M \models dy = 2x dx$ I got thinking that maybe there is an algebraic component to all this. Perhaps we should be writing: Let $M$ denote the smooth manifold presented as follows. Generators: $y,x$ Relations: $y=x^2$ Then $M \models y=x^2$. Therefore $M \models dy = 2x dx$ So I guess it would be nice if we could view smooth manifolds as the models of some kind of carefully chosen Lawvere theory. This couldn't possibly work, though, because relations like $y^2 = x^2$ don't yield well-defined smooth manifolds, because $0$ isn't a regular value of $x,y \mapsto y^2-x^2$. Question. How should we think about equations like $dy = 2x \cdot dx$ from the viewpoint of modern geometry? Has it got to do with the
  models of some kind of a special Lawvere theory? And is there a useful
  generalization of the concept ""smooth manifold"" such that every
  equation involving smooth functions defines a smooth manifold, even equations like $x^2=y^2$? I tried thinking about the Lawvere theory whose objects are $\{\mathbb{R}^n \mid n \in \mathbb{N}\}$ and whose arrows are smooth functions, but really wasn't able to get any insight into what the free algebras of this theory look like. (Does anyone know?)","['geometry', 'differential-forms', 'soft-question', 'differential-geometry']"
1203929,"integer ordered pair of $(x,y,z)$ in $x!+y! = z!.\;,$ Where $x,y,z\in \mathbb{W}$","Total no. of integer ordered pair of $(x,y,z)$ in $x!+y! = z!.\;,$ Where $x,y,z\in \mathbb{W}$ $\bf{My\; Try::}$ Let $w=\max\left\{x,y\right\}$. Then $w<z$. So we can write $w\leq (z-1)$ So $w!\leq (z-1)!\Rightarrow w!\cdot z\leq z\cdot (z-1)!=z!=x!+y!\leq 2 w!$ So We get $z\cdot w!\leq 2w!\Rightarrow z\leq 2$ So If $z=2\;,$ Then we get $x=y=w$. So we get $2w!=2\Rightarrow w!=1\Rightarrow w= \left\{0,1\right\}$ So we get $(x,y,z) = \left\{0,0,2\right\}$ and $(x,y,z) = \left\{1,1,2\right\}$. Similarly If $z=1$. Then $x!+y! = 1$. But $x!+y!\geq 2\forall x\in \mathbb{W}.$ Similarly If $z=0$. Then $x!+y! = 1$. But $x!+y!\geq 2\forall x\in \mathbb{W}.$ So We Get $(x,y,z)$ are $\left\{0,0,2\right\}$  and $\left\{1,1,2\right\}$ Is my solution is Right. If Right can we solve it any other way. Thanks","['factorial', 'algebra-precalculus']"
1203933,Behavior of a periodic function,"Can a periodic function satisfy $f''(x)f(x)>0, x\in \mathbb{R}$ My intuition says no. Any thoughts on how to approach this?","['periodic-functions', 'derivatives']"
1203939,Calculating power of a Hypothesis Testing Problem based on Uniform distribution,"Consider the problem of testing $H_0:a=0$ against $H_1:a=1/2$ based on a single observation X from U(a,a+1). The power of the test ""Reject $H_0$ if $X>2/3$"" is (A)1/6     (B)5/6   (C)1/3   (D)2/3 My Steps: Power of Test=P(reject $H_0$|$H_1$ is true) c.d.f. of continuous Uniform distribution is given be $\frac{x-a}{b-a}$, where a and b are parameters of the given Uniform distribution, $U(a,b)$. $$\begin{align}
\text{Power of Test} & = P(\text{reject } H_0|H_1 \text{is true)} \\
 & = P(X>2/3|a=1/2) \\ 
 & = \frac{(2/3-1/2)}{1} \\
 & = 1/6 
\end{align}$$ Did I solve this correctly ? Please help me confirm my solution.","['uniform-distribution', 'statistics', 'statistical-inference', 'hypothesis-testing']"
1203949,Matrix with integer entries,"The determinant of a given square matrix $A$, with rational entries, equals 1. It is known that all entries of $A^{2015}$ are integers. Is it true that all entries of $A$ are integers? My attemt : I've tried to construct a counter example but failed. I believe it's true but don't know how to prove it.","['determinant', 'linear-algebra', 'matrices']"
1203953,Geometrical interpretation of derivative of a complex function,Can we give any geometrical interpretation of derivative of a complex function?,['complex-analysis']
1203966,A question about multiple integral,"How to compute the multiple integral $$\int \int...\int_{(D)}  dx_1dx_2...dx_n, \ \ D:-1\le x_1,x_2,\ldots ,x_n\le1, -1\le x_1+x_2+\cdots +x_n\le1.$$ Thanks in advanced for your help!","['volume', 'multivariable-calculus', 'integration']"
1203989,Long exact cech cohomology sequence for quasicoherent sheafs on separated quasicompact schemes,"Let $X$ be a scheme with an finite affine open covering $\mathcal{U} = (U_i)_{i=1}^k$ such that all intersections of $U_i$'s are affine too. Why does a short exact sequence of quasicoherent $\mathcal{O}_X$-modules
$$ 0 \to \mathcal{F} \to \mathcal{G} \to \mathcal{H} \to 0$$
induces a short exact sequence
$$ 0 \to C^q(\mathcal{U},\mathcal{F}) \to C^q(\mathcal{U},\mathcal{G}) \to C^q(\mathcal{U},\mathcal{H}) \to 0$$
where $C^q(\mathcal{U},\mathcal{F}) = \prod_{i_0 < \ldots < i_q} \mathcal{F}(U_{i_0} \cap \ldots \cap U_{i_q})$ is the Cech-Complex? This is an intermediate step to show that a short exact sequence of quasicoherent sheafs on a separated quasicompact sheaf induces a long exact cech-cohomology sequence. What I've tried: I know that $H^q(U_{i_0} \cap \ldots \cap U_{i_q},\mathcal{F}) = 0$ since the intersection is affine and $\mathcal{F}$ is quasicoherent, so Leray's theorem tells me that $H^q(X,\mathcal{F}) = H^q(\mathcal{U},\mathcal{F})$. However this does not help with the $C^q$, does it? Or is this something much simpler?","['algebraic-geometry', 'sheaf-cohomology']"
1204021,Any elementary proof for Euler's product formula for sine [duplicate],"This question already has answers here : Infinite Product $\prod\limits_{k=1}^\infty\left({1-\frac{x^2}{k^2\pi^2}}\right)$ (5 answers) Closed 8 years ago . Is there a proof for the following fomula of Euler which does not use complex analysis or fourier analysis?
$${\sin (\pi x)} = \pi x\prod_{n=1}^\infty\left(1 - \frac{x^2}{n^2}\right).$$ Suppose that the student studied ""Introduction to Real Analysis"" by Bartle & Sherbert and they just learned what the convergence of an infinite product means. 
Then is there a proof that is suitable for them?","['education', 'real-analysis']"
1204047,Hamel basis and Banach spaces,Suppose $X$ is a linear space and $X$ has a Hamel basis with uncountable number of  elements. Does there exist a norm on $X$ such that $X$ is a Banach space with respect to this norm?,"['banach-spaces', 'functional-analysis']"
1204059,Two inequalities involving distribuants and expected value,"I have to show that if $X \ge 0$ then $$\sum_{n=1}^\infty P(X \ge n) \le E[X] \le 1 + \sum_{n=1}^\infty P(X \ge n).$$ I know that if the random variable $X$ takes only values in $\mathbb N$, we have: $$E[X] = \sum_{n=1}^\infty n P(X=n) = \sum_{n=1}^\infty \sum_{k=1}^j P(X=k) = \sum_{k=1}^\infty \sum_{n=k}^\infty P(X = n) = \sum_{n=1}^\infty P(X \ge n)$$ How can I use this idea to prove my inequality","['probability-theory', 'probability', 'expectation']"
1204067,Comparing the probabilities of rolling a $12$ or two consecutive $7$'s first with a pair of dice,A pair of dice is rolled repeatedly which event is more likely to occur first? Event $A$ both dice shows 6's. Event $B$ two consecutive rolls give a sum of 7 each. By not solving I think it's A since it's more likely to happen since your just going to roll it once rather then event B. Event A So I know that probability of getting a 6 in a dice is $\frac{1}{6}$ since it's two so it will be $\frac{1}{36}$ Event B sum of 7 each roll of two dice so $\frac{6}{36}$  or $\frac{1}{6}$ but it's twice thrown so $\frac{1}{36}$ WAIT it's EQUAL?! I think I'm wrong here somewhere.,['probability']
1204091,Higher dimensional analogue for Riemann Hurwitz formula,"There are few questions like here and here already asked about this. But I don't have the background to understand the answers there. I am just beginning to learn classical algebraic geometry, and don't yet have the understanding of even the basic notions like schemes. So I am asking the question again. In the context of a ramified covering map for Riemann surfaces, the formula relates the Euler characteristics of two surfaces. More precisely if $\pi : X \to Y$ is a complex analytic covering map between two Riemann surfaces, and if the degree of $\pi$ is $N$, then we have $$
2-2g_X = N(2-2g_Y) - R
$$ where $g_X, g_Y$ are the genus of $X,Y$ respectively, $R=\sum_{p\in Y}(e_p-1)$ is a finite sum over the points of $X$ at which $\pi$ is ramified and $e_p$ denotes the ramification index. Now to my actual questions: $1)$ What if $X,Y$ are connected complex manifolds of dimension greater than $1$? How does the formula read? (An explanation as elementary as possible will be greatly appreciated.) $2)$ Why can't the same formula as above be used for manifolds of higher dimension?","['complex-geometry', 'algebraic-geometry', 'complex-manifolds']"
1204100,Estimating special values of the Riemann zeta function on the critical line,"If $p,q$ are primes, is it necessarily true that
$$\left|\zeta\left(\frac{1}{2} + i\frac{p}{q}\right)\right| > (p+q)^{–(p+q)} ?$$ (Here $\zeta$ is the Riemann zeta function.)","['approximation', 'number-theory']"
1204131,Converting a rotated ellipse in parametric form to cartesian form,"I have a rotated ellipse in parametric form: $$\begin{pmatrix}y \\ z\end{pmatrix} = \begin{pmatrix}a\cos t + b\sin t \\ c\cos t + d\sin t\end{pmatrix} \tag{1} $$ or, $$(y,z) = (a\cos t + b\sin t , c\cos t + d\sin t) \tag{2} $$ By using $$\cos^2 t + \sin^2 t = 1 $$ I can rewrite into: $$ \frac{(d^2 + c^2)y^2 + (-2bd-2ac)yz + (a^2+b^2)z^2}{(ad-bc)^2} = 1 \tag{3} $$ I need to compare it with the standard form of a rotated ellipse (the input format in a program I am writing): $$\left(\frac{\cos\theta(y-h) + \sin\theta (z-k)}{r_1}\right)^2 + \left(\frac{\sin\theta(y-h) - \cos\theta (z-k)}{r_2}\right)^2 = 1 \tag{4} $$ To solve for $r_1, r_2, \theta $ (namely the semi-major, minor axis and angle of rotation). However I realized that this will involve 3 non-linear equations. Although it is solvable, I was wondering if there is a simpler way to find the values?","['geometry', 'conic-sections']"
1204140,Prove that $X\triangle\emptyset=X$,"I'm working on my proofs involving sets, though this one is not a homework problem, so if you wish to provide your own example, so be it. I am working on exercise 3.3.14 (1) in Bloch's Proofs and Fundamentals . It asks me to prove that $X\triangle \emptyset=X$. The following is what I have so far with comments in brackets ""[ ]"": Proof: Let $X$ be some nonempty set. Then $X\triangle \emptyset=\left(X\setminus\emptyset\right)\cup\left(\emptyset\setminus
 X\right)$. Now suppose
   $x\in\left(X\setminus\emptyset\right)\cup\left(\emptyset\setminus
 X\right)$, then $x\in\left(X\setminus\emptyset\right)$ or
   $x\in\left(\emptyset\setminus X\right)$. [here I decided I would look
   at either case] Case I: Suppose $x\in\left(X\setminus\emptyset\right)$. Then $x\in X$ and $x\not\in\emptyset$, hence
   $x\in\left(X\setminus\emptyset\right)\cup\left(\emptyset\setminus
 X\right)=x\in X$. Case II: Suppose $x\in\left(\emptyset \setminus X\right)$. Then $x\in\emptyset$ and $x\not\in X$. But $x\not\in\emptyset$ by
   definition, hence $x\in X$. Thus,
   $x\in\left(X\setminus\emptyset\right)\cup\left(\emptyset\setminus
 X\right)=x\in X$ Therefore, $X\triangle \emptyset=X$. Thank you for your time,","['elementary-set-theory', 'proof-writing']"
1204153,correlation between $\sum_{i=1}^{98}X_i$ and $\sum_{i=3}^{100}X_i$,"Let $X_1,...,X_{100}$ be iid $N(0,1)$ random variables. The correlation between $\sum\limits_{i=1}^{98}X_i$ and $\sum\limits_{i=3}^{100}X_i$ is equal to (A) $0$ (B) $\dfrac{96}{98}$ (C) $\dfrac{98}{100}$ (D) 1 My Steps: $96$ of these $98$ variables of each series have the same value . So, B should be the correct option. Did I solve this correctly ? Please help me confirm my solution.","['correlation', 'normal-distribution', 'statistics', 'random-variables']"
1204154,Proving $\lim_{x\to 1} x^3=1$ with $\epsilon$-$\delta$ definition,"Problem: I need to formally prove that $$\lim_{x\to 1} x^3 = 1.$$ My work: This is what I have so far and I'm generally a bit stuck with these proofs from here onwards. Because $$-\epsilon < x^3-1 < \epsilon  =  | x^3-1 | < \epsilon,$$ then $$ -\epsilon < x^3-1 < \epsilon$$ $$-\epsilon+1 < x^3 < \epsilon +1$$ $$ \sqrt[3]{-\epsilon+1}< x < \sqrt[3]{\epsilon+1}.$$ Hoping that what I have done so far is correct. Am I right in thinking that $$ \sqrt[3]{-\epsilon+1}< x < \sqrt[3]{\epsilon+1}$$ is giving me an interval where $x$ is going to give me a $f(x)$ value that falls within the distance $\epsilon$ from the limit on the $y$ -axis ? Or is this interval smaller than the $\epsilon$ -distance on the $y$ -axis?","['calculus', 'limits', 'proof-verification', 'real-analysis', 'epsilon-delta']"
1204219,Number of ways to set 3 queens to attack each other [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question We play chess and want to set 3 queens to attack each other. How many ways we can do it? I know to solve this problem when I have 2 queens. I see the chess board as 4 squares, from an outer square (the 28 squares on the edges and corners) to the inner square, the 4 squares in the center of the board.","['probability-theory', 'combinations', 'probability', 'combinatorics']"
1204236,Variance of first 30 odd numbers,How to calculate variance of first 30 odd numbers ? The method I used requires finding the mean and subtracting each number with it and then squaring the result . Its getting difficult . I used this : Any other way to calculate ?,['statistics']
1204246,"for a given $f$, $f$ is measurable iff $f^{-1} (${$-\infty$}$) \in \mathcal{M}$ , $f^{-1} (${$\infty$}$) \in \mathcal{M}$ and f is measurable on $Y$.","Let $f : X \rightarrow \bar{\mathbb{R}}$ and $Y = f^{-1}(\mathbb{R})$ then f is measurable iff $f^{-1} (${$-\infty$}$) \in \mathcal{M}$ , $f^{-1} (${$\infty$}$) \in \mathcal{M}$ and f is measurable on $Y$. My approach : $\Rightarrow$  $f$ is measurable thus we have $f^{-1}(E) \in \mathcal{M} $  $\forall E \in \mathcal{B}_{\bar{\mathbb{R}}} $ 
now we know that $\mathcal{B}_{\bar{\mathbb{R}}} =\mathcal{B}_{\mathbb{R}} \cup ${$-\infty$} $ \cup ${$\infty$} Thus now $f^{-1} (${$-\infty$}$) \in \mathcal{M}$ , $f^{-1} (${$\infty$}$) \in \mathcal{M}$ and also $f^{-1}(E) \in \mathcal{M} $  $\forall E \in \mathcal{B}_{\mathbb{R}} $ this is nothing but f is measurable on $Y$ ( As $f : Y \rightarrow \mathbb{R}$. Hence proved $\Leftarrow$ NO clue ! Is my approach and first part of proof correct ? Someone please help.","['analysis', 'proof-verification', 'measure-theory']"
1204254,Convergence of a product of sequences convergent in mean when one of them is bounded,"Suppose $X_n\to X$ in $L^1$ and $V_n\to V$ in $L^1$ and $(V_n)$ is a bounded sequence. I'm trying to show that then $\mathbb{E}X_nV_n\to \mathbb{E}XV$. One has for all $N\in\mathbb{N}$
$$|\mathbb{E}X_nV_n-\mathbb{E}XV_n+\mathbb{E}XV_n-\mathbb{E}XV|\leq 
\mathbb{E}|V_n||X_n-X|+N\mathbb{E}(V_n-V)1_{\{|X|\leq N, V_n\geq V\}}+
N\mathbb{E}(V-V_n)1_{\{|X|\leq N, V\geq V_n\}}+|\mathbb{E}X(V_n-V)1_{\{|X|>N\}}|.$$
Now the first three members on the right converge to $0$ as $n\to\infty$. How does one go about the last one? Or maybe it should be done some other way?","['probability-theory', 'convergence-divergence', 'lp-spaces']"
1204273,Differentiate a Differential equation,"Given the Differential equation $y'=-2xy^{2}$. Find the derivative $\frac{d(y')}{dx}$! My approach , which is not correct according to Wolfram Alpha : Plugging in: $\frac{d(y')}{dx}=\frac{d(-2xy^{2})}{dx}$ Pulling out constants #1:$-2\cdot\frac{d(x^{1}\cdot y^{2})}{dx}$ Pulling out constants #2:$-2\cdot y^{2}\cdot\frac{d(x^{1})}{dx}$ Do the differential: $-2\cdot y^{2}\cdot1=\frac{d(y')}{dx}$ Wolfram Alpha computes this:
$\frac{d(y')}{dx}=-4x\cdot y\cdot y'(x)-2y^{2}$ Since i do not have the Pro-Version of Wolfram Alpha and i am curious of knowing the maths behind it: What steps happen here and why can't i do it in my way ? Background info: I want to find those Derivatives in order to compute a numerical approximation for the Differential equation using a Taylor series expansion of 4th order. Edits (after comments and answers were given): So by the product rule, stated as follows: $\left(f(x)\cdot g(x)\right)^{'}=f'(x)\cdot g(x)+f(x)\cdot g'(x)$ I identified the following terms as the elements of that product rule: $f(x)=x$ $g(x)=\left(y(x)\right)^{2}=y(x)\cdot y(x)$ (the product rule has to be applied here a second time) $f'(x)=1$ $g'(x)=y'(x)\cdot y(x)+y(x)\cdot y'(x)$ $\left(f(x)\cdot g(x)\right)^{'}=f'(x)\cdot g(x)+f(x)\cdot g'(x)$ $\left(f(x)\cdot g(x)\right)^{'}=1\cdot\left(y(x)\right)^{2}+x\cdot\left(y'(x)\cdot y(x)+y(x)\cdot y'(x)\right)$ $\left(f(x)\cdot g(x)\right)^{'}=\left(y(x)\right)^{2}+2\cdot x\cdot y'(x)\cdot y(x)$","['taylor-expansion', 'numerical-methods', 'ordinary-differential-equations']"
1204276,"Can't we consider the curve $t\to(\gamma(t),X(\gamma(t))$ instead of the covariant derivative $\nabla_{\gamma(t)}X$?","Many text books on differential geometry motivate covariant derivative more or less by saying that if you have a vector field along a curve on a manifold (that is a curve $\gamma(t)$ and an assignment of a vector $X(\gamma(t))$ at each point) then you can not directly define its derivative because you can not subtract two vectors living at different spaces.
Lie Derivative here does not also help since you would need to extend $\dot{\gamma(t)}$ to a vector field to define the Lie derivative along that vector field and then the Lie derivative will depend on the extension. So ok covariant derivative $\nabla_{\gamma(t)}X$ gives you a way to differentiate vector fields along curves by letting you compare two different tangent spaces through parallel transport along $\gamma(t)$ . But what I dont understand is what is the problem with constructing the curve $t \rightarrow (\gamma(t),X(\gamma(t)))$ which will be a curve inside the manifold TM and then derivative it whose coordinate expression would be $(\gamma(t),X(\gamma(t)),X(\gamma(t)),\beta(t))$ and call $\beta(t)$ the derivative of $X$ along $\gamma(t)$ . This derivative does not live on $TM$ but lives on $TTM$ that is true, but what is the problem with this? This also makes me think whether if one can define a connection on $M$ by defining some kind of projection $\pi: TTM \rightarrow TM$ so that first you find $\beta$ as above and then somehow send it back to $TM$ . In fact this is the way how you turn a second order ODE on $M$ to a first order ODE on $TM$ . Is there are more deeper way of understanding the necessity for covariant derivative?","['differential-geometry', 'connections']"
1204279,Show that $x^4-10x^2+1$ is irreducible over $\mathbb{Q}$,"How do I show that $x^4-10x^2+1$ is irreducible over $\mathbb{Q}$? Someone says I should use the rational root test, but I don't exactly know how that applies. Thanks for any input.","['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
1204328,Proof of lemma that function is bijective,"I found this lemma in a book and decided to prove it: Let $f: A \rightarrow B$. If there are functions $g : B \rightarrow A$ and $h: B \rightarrow A$ such tat $g(f(a)) = a$ for every $a \in A$ and $f(h(b)) = b$ for every $b \in B$, then f is bijective and $g = h = f^{-1}$ I have been able to prove that f is bijective as follows: Injection : Let us assume that f is not injective. Then $b = f(a)$ and $b = f(a')$ and $a \neq a'$. But then $g(b) = a$ and $g(b) = a'$ - which is contradictory since g is a function and this goes against the rule of assignment. This means that f is injective. Surjection : This was a bit simpler. For every $b \in B$ we have $b = f(h(b))$. Which means that f is surjective. Which means that f is bijective and has an inverse function $f^{-1}$. But I can't prove why $g$ and $h$ both have to be the inverse function.",['elementary-set-theory']
1204344,Applications of the following theorem in the real world,We know that every permutation can be expressed as a product of transpositions ( cycles with length 2). As a class project I'm looking for the applications of this fact in the real world; especially in computer science. Thanks in advance!,"['computer-science', 'soft-question', 'permutations', 'abstract-algebra', 'group-theory']"
1204378,Existence of a random variable given a cdf,"For every real function F which can be a CDF (so has the properties that $F(+\infty)=1$, $F(-\infty)=0$, and F is non-decreasing and right continuous), does there exist a random variable on a probability space with this function as it's CDF? Seems rather trivial (I may be misunderstanding something here) but I would like to prove it.","['probability-theory', 'random-variables', 'measure-theory']"
1204391,Replacing entries of dice by average of it neighbours,"I am interested in Representation Theory. I came across the following answer while reading this question on Mathoverflow. An example from Kirillov's book on representation theory: write numbers $1,2,3,4,5,6$ on the faces of a cube, and keep replacing (simultaneously) each number by the average of its neighbours. Describe (approximately) the numbers on the faces after many iterations. However I do not understand how to approach this problem via representation theory.","['representation-theory', 'combinatorics']"
1204396,Why is the sum of the rolls of two dices a Binomial Distribution? What is defined as a success in this experiment?,"I know that a Binomial Distribution, with parameters n and p, is the discrete probability distribution of the number of successes in a sequence of n independent yes/no experiments, each of which yields success with probability p. I read that the sum of the roll of two dice is a binomial distribution. Is this right? I know that the sum looks like a binomial: But if it is a binomial : What event do I regard as a success? What is its probability? How many times do I repeat the experiment? I mean a Binomial Distribution measures the probability of observing an event (which has probability of success p), k times in specific amount of repetitions n. Here I see 12 different events with different probabilities and I am confused.","['dice', 'probability', 'binomial-distribution']"
1204403,$\frac{1}{z^2}$ is holomorphic,"I have to show that $z\mapsto\frac1{z^2}$ is holomorpic on $\mathbb C\setminus\{0\}$ and compute its $n$-th derivative I know that $\frac{1}{z^2}=\sum\limits_{n\ge0}(-1)^n(n+1)(z-1)^n$, so it has a power series representation. Is that sufficient to conclude that the function is analytic, which is stronger than holomorphic. I thought analytic means inifinitely differentiable and holomorphic only continuously differentiable, how can one then compute $n$-th derivative of a holomorphic function, if $n$ is greater than $1$? However I computed it; $\left(\frac{1}{z^2}\right)^{(n)}=\sum\limits_{k\ge n}(-1)^k(n+1)n!(z-1)^{k-n}$ is that correct ?","['analyticity', 'complex-analysis']"
1204495,infinite Union of compact sets,How to Show that an infinite union of compact sets is not necessarily compact ? It can be done for finite union of set but how to do these for infinite union of compact sets.. PLease Help,"['real-analysis', 'general-topology']"
1204501,Cardinality of transcendental numbers,"Hello everyone I'm struggling to prove that $|T|=|R|$, where $T$ is the set of all transcendental numbers. I've seen a few proofs that are based on the statement $$(1)\ \ \mathbb{R}=T\cup \{algebraic\ numbers\}$$
which is simple enough to finish. HOWEVER, on the wikipedia page of algebraic/transcendental numbers it is strictly stated that both transcendentals/algebraics can be complex or real. I was hoping somone with more knowledge can shed some light on me. Edit for clairty: I see that (1) would imply that there are $|T|\geq|R|$ many trascendental numbers, but why would that inequality be strictly an equality?",['elementary-set-theory']
1204511,"Hermitian form, fundamental $2$-form of Kahler structure on $\mathbb{C}^n$","I've come across the following (it is an excerpt of Stolzenberg's lecture notes 19): Wirtinger's Inequality. Let $L$ be a complex linear space and let $M$ be a real
  even-dimensional subspace. Let $H$ be a positive definite Hermitian
  form on $L$ . Then $H = S + iA$ where $S$ is symmetric and $A$ is
  alternating . Let $\{ m_1,...,m_{2k} \} $ be a basis of $M$ which is
  orthonormal with respect to $S$ . Then $$ | A ^k ( m_1 , . . . , m_{2
> k} ) | \le  k !$$ with equality holding precisely when $M$ is a
  complex $k$-dimensional subspace of $L$ . (Here $A^k$ is the $k$-th
  exterior power of $A$ .) By a suitable shuffling of the basis it can be arranged that $A ^k (
> m_1 , . . . , m_{2 k} ) \ge 0$ Let $z_1, . . . , z_n$ be coordinates on complex $n$ - space
  $\mathbb{C}^n$ and set $$\omega = \frac{i}{2} \sum_{j=1}^n dz_j \wedge d \overline{z}_j$$ This is the fundamental $2$-form of the standard Kahler structure on
  $\mathbb{C}^n$ and  at each point $p \in \mathbb{C}^n$ $\omega_p$ is
  the alternating part of the positive definite Hermetian form: $$\sum_{j=1}^n dz_{j(p)} \cdot d \overline{z}_{j(p)}$$ on the tangent space to $\mathbb{C}^n$  at $p$. Therefore , if $\mathcal{M}$ is any smoothn $2k$-dimensional manifold
  immersed in $\mathbb{C}^ n$ , Wirtinger's Inequality implies
  immediately that: $$\int_{\mathcal{M}} \frac{1}{k!} \omega ^k \le \int_{\mathcal{M}} 1 \ d
> \mathcal{M} = \text{Volume} _{2k}(\mathcal{M})$$ with equality is and only if $ \mathcal{M}$ is a complex
  $k$-dimensional manifold. Also each $\frac{1}{k!} \omega ^k $ is an exact $2k$ form. My questions are: Could you explain to me how we use the fact that $\omega$ is the fundamental $2$-form of the standard Kahler structure on $\mathbb{C}^n$ to apply the Wirtinger inequality here? Is this somehow connected to this Second fundamental form ? Could you explain to me what the fundamental $2$-form of the standard Kahler structure is? Or recommend a good source in which I could read about it? In Werner Ballmann's Lectures on Kahler Manifolds the author defines the associated Kahler form (which I presume could be the same as the fundamental $2$-form) in this way: Let $M$ be a complex manifold with complex structure $J$ and
  compatible Riemannian metric $g = < \cdot, \cdot > $  (so $<JX, JY>= < X, Y > $). 
   The alternating $2$-form $\omega(X, Y ) := g(JX, Y )$ is
  called the associated Kahler form. We say that $g$ is a Kahler metric
  and if $\omega$ is closed, we say that $(M, g)$ is a Kahler manifold. On page 48, the author states that we can view $TM$ together with $J$ as a complex vector bundle over $M$, and
  let $h$ be a Hermitian metric on $TM$. Then $g = Re h$ is a compatible
  metric on $M$ and $Imh$ is the associated Kahler form: 
  $$g(JX, Y ) = \Re h(JX, Y ) = \Re h(iX, Y ) = \Re(−ih(X, Y )) = \Im h(X, Y )$$ If $g$ is a
  compatible Riemannian metric on $M$ and $\omega$ is the associated
  Kahler form, then $h = g + i\omega$ is a Hermitian metric on $TM$. Also, a Riemannian metric is a general notion. Looking at what I've pasted into the frame above, do we need to consider Riemannian metrics compatible with the complex structure in general or not necessarily? I would be very grateful for all your insight.","['smooth-manifolds', 'manifolds', 'differential-geometry', 'complex-analysis', 'kahler-manifolds']"
1204581,Basis for proper rational functions,"Suppose $F$ is a field, and let $F(x)$ denote the $F$ -vector space of all rational functions $\frac{f(x)}{g(x)}$ , where $f,g\in F[x]$ are polynomials, with $g$ different from zero. Let $F(x)_p$ denote the subspace of F(x) of all proper fractions, i.e. all $\frac{f(x)}{g(x)}$ where degree( $f$ ) $<$ degree( $g$ ). Show that: (a) $F(x)$ is isomorphic to $F[x]\oplus F(x)_p $ as an $F$ -vector space. (b) If $\mathcal{I}=\{p(x)\in F[x] \mid p \text { is a monic irreducible polynomial}\}$ , then $$\beta= \{\frac{x^{j}}{p(x)^{k}} \mid p(x)\in \mathcal{I}, 0\leq j< \text{degree}(p); k\geq 1 \}  $$ is a basis for $F(x)_p$ as an $F$ -vector space. I am done with part (a), but I don't know how to proceed in part (b).
Can anyone help me please?","['abstract-algebra', 'vector-spaces', 'modules']"
1204599,Square of the distance function,"I am confused about a certain type of problem. I was taught that when solving for a point on a plane (must use partial derivatives) say, $x+y+z=1$ that is closest to the origin, we are to minimize the square of the distance function, i.e. minimize $f(x,y)=x^2+y^2+z^2$. But I don't understand the intuition of why we do this. How could we know that we should minimize the square of the distance formula, and not just the distance formula itself? Thanks",['multivariable-calculus']
1204605,Integration of $\int \frac{\arcsin{e^x}}{e^x}dx$,"I've got a problem with this integral: $$\int \frac{\arcsin{e^x}}{e^x}dx$$ I got such a result: $$\int\frac{\arcsin{e^x}}{e^x}dx=-\frac{\arcsin{e^x}}{e^x}-\ln|\sqrt{e^{-2x}-1}+e^{-x}|+C$$ but the wolphram alpha and the book where this integral is as an exersise give this answer: $$\int\frac{\arcsin{e^x}}{e^x}dx=x-e^x\arcsin{e^x}-\ln(1+\sqrt{1-e^{2x}})+C$$ Where do I make a misteake? This is my solution: $$\int \frac{\arcsin{e^x}}{e^x}dx=\int \frac{e^x\arcsin{e^x}}{e^{2x}}dx  $$ Now, $t=e^x$ $dt=e^xdx$ $$\int \frac{\arcsin{e^x}}{e^x}dx=\int\frac{\arcsin{t}}{t^2}dt$$ Now, I integrate by parts: $u=\arcsin{t},\ v^{'}=\frac{1}{t^2}$ $u^{'}=\frac{1}{\sqrt{1-t^2}},\ v=-\frac 1t$ Hence,
$$\int \frac{\arcsin{t}}{t^2}dt=-\frac{\arcsin{t}}{t}+\int\frac{dt}{t\sqrt{1-t^2}}$$ $s=\frac 1t$ $t=\frac 1s$ $dt=-\frac{1}{s^2}ds$ and I get $$\int\frac{dt}{t\sqrt{1-t^2}}=-\int\frac{ds}{s^2\sqrt{1-\frac{1}{s^2}}\cdot \frac 1s}= -\int\frac{ds}{\sqrt{s^2-1}}=-\ln|\sqrt{s^2-1}+s|+C^{'}$$ From this we get: $$\int\frac{\arcsin{e^x}}{e^x}dx=-\frac{\arcsin{e^x}}{e^x}-\ln|\sqrt{e^{-2x}-1}+e^{-x}|+C$$","['indefinite-integrals', 'integration']"
1204621,How can I interpret the ratio $\frac{f(x_0)}{f'(x_0)}$?,"let $f'(x)$ the first derivative of function $f(x)$. For some $x_0$, how can I interpret the ratio $\frac{f(x_0)}{f'(x_0)}$ ? More specifically, what does it mean a $\frac{f(x_0)}{f'(x_0)} \gg 1$  ?","['derivatives', 'functional-analysis', 'functions']"
1204622,"How to show that $\{(x,y,z)\in\mathbb{R}^3:x^4+y^4+z^4=1\}$ is diffeomorphic to the $2$-sphere.","How to show that the ""squared sphere""
  $$\tilde{S}^2=\{(x,y,z)\in\mathbb{R}^3:x^4+y^4+z^4=1\}$$
  is diffeomorphism to the standard $2$-sphere
  $$S^2=\{(x,y,z)\in\mathbb{R}^3:x^2+y^2+z^2=1\}?$$ One obvious map between the two is
$$F:S^2\to\tilde{S}^2,\quad F(x,y,z)=(x^2,y^2,z^2),$$
but this is clearly not surjective since it maps only to non-negative numbers. What to do? Here is how it looks:","['differential-geometry', 'calculus']"
1204652,Add terms on a limit whose value depends of $\alpha$.,"This may be a silly question, but I had to ask it. Yesterday, I was helping an engineer on doing a limit (we're both studying at the university and he's doing calculus now). I helped him on doing this limit: Solve the following limit for every $\alpha>0$: $$\displaystyle\lim_{x\to0}\frac{\ln(1+x^2)}{\rvert x\lvert^\alpha}.$$ I said him that my solution would be: We know that in a neighborhood of $0,$ $ \ln(1+x^2)\sim x^2$. So we can write:
  $$\displaystyle\lim_{x\to0}\frac{\ln(1+x^2)}{\rvert x\lvert^\alpha}=\lim_{x\to0}\frac{x^2}{\rvert x\lvert^\alpha}=\lim_{x\to0}\frac{\lvert x\rvert^2}{\rvert x\lvert^\alpha}\implies \begin{cases} \alpha>2 \to \displaystyle\lim_{x\to0}\frac{\ln(1+x^2)}{\rvert x\lvert^\alpha}=\infty  \\ \\  \alpha<2 \to \displaystyle\lim_{x\to0}\frac{\ln(1+x^2)}{\rvert x\lvert^\alpha}=0\\ \\ \alpha=2 \to \displaystyle\lim_{x\to0}\frac{\ln(1+x^2)}{\rvert x\lvert^\alpha}=1 \end{cases}$$ But then, his professor gave them another answer, and it looked like that (I'll only post the beginning): $$\displaystyle\lim_{x\to0}\frac{\ln(1+x^2)}{\rvert x\lvert^\alpha}=\lim_{x\to0}\frac{\ln(1+x^2)}{\rvert x\lvert^\alpha}\cdot\frac{x^2}{x^2}=\lim_{x\to0}\frac{x^2}{\lvert x\rvert^\alpha}\cdot{\ln(1+x^2)^{1/x^2}}=\\ =\lim_{x\to0}\frac{x^2}{\lvert x\rvert^\alpha}\cdot \lim_{x \to 0}{\ln(1+x^2)^{1/x^2}}=\lim_{x\to0}\frac{x^2}{\lvert x\rvert^\alpha}\text{, because $(1+x^2)^{(1/x^2)}\to e.$}$$ Doing maths on university, on calculus I, we've been warned several times about put on my limit this kind of fractions, even they where $x^2/x^2$ and you knew that you were multyplying by $1$ the limit. Adding terms this way inside the limits that depended on some values $\alpha$ it could lead to a problem. So now I wanted to ask: when can I add terms on a limits on the way that his professor did? When it's not ""illegal"" to do it? Thank you.","['calculus', 'limits', 'algebra-precalculus']"
1204680,How to interpret the covariance matrix of Brownian motion,"I'm reading Bernt Oksendal's ""Stochastic Differential Equations"". It says, Brownian motion $B_t$ is Gaussian Process,  i.e. for all $0 \leq t1 \leq \cdots \leq t_k$ the random variable 
$Z = (B_{t_1}, \ldots, B_{t_k} ) \in \mathbb{R}^{nk}$   has a (multi)normal distribution with $M = E^x[Z]$ be the mean value of $Z$, 
and $c_{jm} = E^x[(Z_j - M_j)(Z_m -M_m)]$ be the covariance matrix of $Z$. The book shows $$M=E^x[Z]=(x, x, \cdots, x)\in \mathbb{R}^{nk}$$ and
$$C＝[c_{jm}]=\begin{pmatrix} t_1 I_n & t_1 I_n & \cdots & t_1 I_n \\ t_1 I_n & t_2 I_n & \cdots & t_2 I_n\\ \vdots & \vdots & & \vdots \\ t_1 I_n & t_2 I_n & \cdots & t_k I_n \end{pmatrix}\in \mathbb{R}^{nk\times nk}$$ Then the book claims that
$$E^x[(B_t-x)(B_s-x)]=n \min(s,t) \tag{1}$$
and
$$\begin{align}
E^x[(B_{t_{i}}-B_{t_{i-1}})(B_{t_{j}}-B_{t_{j-1}})]&=E^x[B_{t_{i}}B_{t_{j}}-B_{t_{i-1}}B_{t_{j}}-B_{t_{i}}B_{t_{j-1}}+B_{t_{i-1}}B_{t_{j-1}}]\\&=n(t_i-t_{i-1}-t_i+t_{i-1})=0\tag{2}
\end{align}$$ I think $(1)(2)$ should follow from the form of covariance matrix. But I don't know how to interpret $C$ and how to get the result exactly. For example, why do we have $n$ in the results?","['probability-theory', 'brownian-motion', 'normal-distribution', 'stochastic-processes']"
1204689,There is a unique quadric through three disjoint lines,"There is a classical exercise that three disjoint lines in $\mathbb{P}^3$ are contained in a quadric surface $Q$. The existence is trivial. Every quadric in $\mathbb{P}^3$ is determined by nine coefficients and if three distinct points of a line lie on $Q$ then the whole line lie on $Q$. Thus we obtain the system of 9 linear conditions on $Q$. But why such a quadric is unique? To be more precise, why these linear equations are linearly independent?","['algebraic-geometry', 'analytic-geometry']"
1204694,Solution of a special case of Abel's differential equation of the second kind,"My teacher mentioned to the class the following case of Abel's equation: $$y\cdot\frac{dy}{dx}-y=Ax+B$$ where $A, B\in \Bbb R $. I have thoroughly searched the Web, but I haven't found a certain sufficient way to solve it. Any ideas?",['ordinary-differential-equations']
1204701,Proof verification.,"Let $x,y$ be real numbers, with $x < y$. Show that if $x$ and $y$ are rational, then there exists an irrational number $u$ such that $x < u < y$. Now, since $y - x > 0 \implies \frac{y-x}{\sqrt{2}} > 0$ if we take $u =  x + \frac{y-x}{\sqrt{2}}$, we are done. My question is, is this ok? I feel like i need to prove that $x < x + \frac{y-x}{\sqrt{2}} < y$, if that is the case, subtracting $x$ will give the desired result? i.e $0 <\frac{y-x}{\sqrt{2}} < y - x$. A follow up question would be, how would i begin to show that there exists a rational between the reals? This is my attempt, but it's a proof by contradiction; suppose that there is no rational number $q$ between $x$ and $y$, with $x < y$. take the set of real, irrational numbers $\frac{a}{b} + \sqrt{2}$, where $b$ is fixed and $a \in R$ suppose that $x = \frac{a}{b} + \sqrt{2}$ and $y =\frac{a + c}{b} + \sqrt{2}$ for some real $c>0$ then $y - x = c/b$, but if i divide this by 2 and add this to $x$, i get an irrational number. EDIT. 
I am aware that there are proofs, such as; We must choose an $N > 1/(y-x) \implies 1/N < (y-x)$, then theres exists an integer multiple of $1/N$ such that $x < r < y$, where $r = M/N$. However,  I would like to know whether my approach holds any water.","['analysis', 'proof-verification']"
