question_id,title,body,tags
3969368,Likelihood of Uniform Distribution Indicator Function,"It is well known that the likelihood function for the uniform distribution on $[0,\theta]$ is given by $$\frac{1}{\theta^n} \mathbf{1}_{\max(x_1,\ldots,x_n)\leq \theta}$$ Where the reason for this indicator is that the likelihood will be equal to $0$ if one of our observations $x_i$ exceeds $\theta$ . But why do we not impose a similar condition on an observation being less than $0$ ? That is, also including $\mathbf{1}_{\min{(x_1,\ldots,x_n)\geq0}}$ ? Sorry if I've misunderstood anything, please feel free to correct me!","['statistics', 'uniform-distribution', 'probability', 'maximum-likelihood']"
3969381,Existence of a $\mathbb{Z} _{15}$ in a group $G$ where $|G|=3 \cdot 5 \cdot 17$,"Existence of a $\mathbb{Z} _{15}$ in a group $G$ where $|G|=3 \cdot 5 \cdot 17$ . This is my proof: we know (from a previous point of the exercise) that $\mathbb{Z}_{17}$ is a characteristic subgroup of $G$ . For Cauchy, we have that $\exists \mathbb{Z}_3,\ \mathbb{Z}_5 <G$ . If we demonstrate that $\mathbb{Z}_3$ or $\mathbb{Z}_5$ is normal in $G$ , then we have that $\mathbb{Z}_3\mathbb{Z}_5$ (or $\mathbb{Z}_5\mathbb{Z}_3$ ) is a subgroup of $G$ of order 15, therefore is isomorphic to $\mathbb{Z}_{15}$ . For Sylow, we have that $n_5 \equiv 1 \pmod{5}$ and $n_5 \mid 51$ where $n_5$ is the number of $5$ -Sylow in $G$ , so $n_5=1,51$ . If $n_5=1$ then the only $5$ -Sylow in $G$ is normal. If $n_5=51$ then there are $51 \cdot 4$ elements of order $5$ in $G$ , and of the remaining $51$ elements there are $16$ of order $17$ (from the only $\mathbb{Z}_{17}$ ) and one of order $1$ , that is the identity. So we have $34$ elements left. At this point, I thought about two different conclusions, but I am not really sure which one is the correct one: All the $34$ elements have to be of order $3$ , therefore there are $17$ $3$ -Sylow, but this is impossible because $17 \not\equiv 1 \pmod{3}$ . So we can conclude that $n_5=1$ . We have $34$ elements, so we can have at most $17$ $3$ -Sylow (in other words, $n_3\le 17$ ), and this means that $n_3$ can only be $1$ . So if $n_5 \neq 1$ then $n_3=1$ .","['cyclic-groups', 'finite-groups', 'abstract-algebra', 'sylow-theory', 'group-theory']"
3969388,"Calculating $\lim_{(x,y)\rightarrow (0,0)}\frac{1 - \cos(\pi x y ) + \sin (\pi(x^2 + y^2))}{x^2 + y^2}$ if it exists","I'm trying to calculate the above limit. I ran a few paths and found out that the limit is $\pi$ (which I also confirmed through WolframAlpha), but to prove it I use polar coordinates to get an expression of the form $F(r) \cdot G(\theta)$ where $F(r)\rightarrow$ when $r\rightarrow 0$ and $G$ is blocked. So far I have: $$\lim_{r\rightarrow 0} \left|f(r\cos \theta,r \sin \theta)\right| = \lim \left|\frac{1-\cos(\pi r^2 \cos\theta \sin \theta ) + \sin (\pi r^2 (\sin^2\theta  + \cos ^2 \theta ))}{r^2\cos ^2 \theta + r^2 \sin^2 \theta}\right|
\\ \underset{\sin ^2 \theta + \cos ^2 \theta = 1}{=} \lim \left|\frac{1 - \cos(\pi r^2 \cos\theta \sin\theta ) + \sin (\pi r^2 )}{r^2}\right|$$ However, I don't know how to separate $r$ from the rest of the expression at this stage. But it occurred to me that this only works if the limit of the function is zero. So, how do I confirm this is the correct limit in a case such as this?","['limits', 'multivariable-calculus', 'polar-coordinates', 'real-analysis']"
3969440,"How do I calculate an integral like $\oint \vec{E}^{\,} \cdot \vec{dA}^{\,}$?","$$\oint \vec{E}^{\,} \cdot \vec{dA}^{\,}$$ This is Gauss' law from physics but my question is more maths related. Say I have $\vec{E}^{\,}=3.5\times 10^3N/C\times e_x$ and $A = 0,35\times0,70m^2$ . The plane that has that area, where the electric field $E$ is applied, is parallel to $YZ$ . So it has a coordinate in $e_x$ . Right? What does the circle in the integral mean in practice? What is the value of $dA$ ? Why is it a vector? How do I solve this integral?","['integration', 'multivariable-calculus', 'multiple-integral', 'vector-analysis', 'physics']"
3969458,Elevator stops in building,"Bill is working in the 38th floor of an 100-floors building. This building has a strange elevator which only has 2 buttons: the green one which takes you to the next floor every time you press it (and if you are at the last floor, it takes you to the 1st) and a red button which takes you to a random floor every time you press it. Once you enter the elevator, the first stop is selected at random, without pressing any button. Bill wants to eventually arrive at his office at the 38th floor. How is he going to do it, with the least number of steps? I am thinking of a very simplistic approach: Since the first stop is decided at random, depending on the number of the floor where the elevator stops, Bill will decide which button to use: If he is near the 38th and before it, he will keep pressing the green button until he reaches the 38th. If it stops in a floor $>38$ , he will press the red button until the elevator stops at some floor $<38$ , but I assume the problem involves the expected number of stops etc probabilities, which I am not very familiar with!
Any help is really appreciated!","['discrete-optimization', 'puzzle', 'probability']"
3969481,Induction of topological space by an $L^2$-space,"Let $(L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R}),\langle\cdot,\cdot\rangle)$ be a Hilbert space, where $L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})$ denotes the set of all (equivalence classes of) $\boldsymbol{\Xi}$ -measurable $\mathbb{R}$ -valued functions that are square $\mu$ -integrable on $\Xi$ , and $\langle\cdot,\cdot\rangle:L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\times L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\to\mathbb{R}$ denotes its standard inner product given by $$\langle f,g\rangle=\int fg\,\mathrm{d}\mu.$$ I know that this Hilbert space induces a topological space whose induced standard topology $\mathcal{O}$ is the one generated by all open balls whose radii are measured using the induced standard metric $d:L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\times L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\to\mathbb{R}_0^+$ given by $$d(f,g)=\langle f-g,f-g\rangle^{\tfrac{1}{2}}.$$ My question is how to write this standard topology symbolically. At the moment I have defined the topological basis: $$\mathscr{B}=\{B_r(f)\subset L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\,\mid\, r\in\mathbb{R}^+,f\in L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\},$$ where $B_r(f):=\{g\in L^2(\Xi,\boldsymbol{\Xi},\mu;\mathbb{R})\mid d(f,g)<r\}$ is the open ball of radius $r$ centered at $f$ . Then, we define $\mathcal{O}=\varphi(\mathscr{B})$ . Here $\varphi$ represents a map which takes a topological basis as an input and returns a topology as an output. In measure theory, we have the map $\sigma$ which generates a $\sigma$ -algebra from a given collection of subsets. I thought that the same could be done here. However, I haven't found the actual symbol for performing such an operation on a topological basis yet. So, is this the correct way to write the induced standard topology symbolically? Also, is there a better way to write the same thing? Thank you, Frederick.","['measure-theory', 'real-analysis', 'lp-spaces', 'measurable-functions', 'general-topology']"
3969485,Finding matrices that satisfy equation,I am trying to find the set of square matrices that satisfy: $$M=M^{2n-1}-\sum_{k=1}^{2n-2}{M^k}$$ $$n\in \mathbb{N}$$ I have tried simplifying and trying to treat the sum as a geometric series but this hasn't lead me anywhere. How could I go about solving this?.,"['matrices', 'number-theory', 'summation', 'discrete-mathematics']"
3969489,Calculate angle of view based on object sizes in image,"I'm trying to find a way to automatically calculate the angle of view of an image by comparing the size and position of two identical objects in the image. For example, the two bottles below have identical dimensions in reality, but depending on the lens of the camera, the blue bottle may appear to shrink at different rates in the image the further its distance from the camera. I'm wondering if it is possible to calculate the angle of view of the below image, given the following: The two objects have the same dimensions in reality (both humans are equally tall and wide). We can assume that these are 180cm tall. The real-world distance to the objects are not known . The image dimensions are known . Both bounding box dimensions are known . Both bounding box positions relative to the image top-left origin are known . Both objects are standing on flat ground (their bottom points intersect a common plane). Question: Is it possible to calculate the angle of view of the image based entirely on how two (equally-sized) objects are represented in the image as they are moved closer or futher away from the camera? EDIT: See image with bbox coordinates, here: https://i.sstatic.net/tMJKD.png","['trigonometry', 'vector-spaces', 'geometry']"
3969510,Prove $\prod_{i=1}^n \frac{3K_i+2}{2K_i+1}$ can never be a power of $2$,"Suppose we have a finite set of numbers $K_i \in \mathbb N$ . Can we prove that the product $$\prod_{i=1}^n \frac{3K_i+2}{2K_i+1}$$ can never be equal a power of $2$ ? As you can see, each term is between $\frac{3}{2}$ and $\frac{5}{3}$ . The greater $K_i$ , the closer it is to $\frac{3}{2}$ . Ratio between exact power or $\frac{3}{2}$ and the next greater power of $2$ places the constraint on $K_i$ values: the lowest $K_i$ cannot exceed certain value. For example, for products up to $2000$ terms, the biggest lowest value of $K_i$ was found to be for $1636$ terms, and it is $291643$ . The value would be a power of $2$ if all factors of the numerator and the denominator, except of $2$ s in the numerator, completely canceled each other. Note that the denominator is always odd. It appears that there's no set of $K_i$ to make such a product equal to a power of $2$ . But can it be proven?","['number-theory', 'elementary-number-theory']"
3969538,simplify fraction (stone drops off a cliff),How do I get from $$ \frac {dt} {T} = \frac {dx} {gt} \sqrt { \frac {g} {2h} } $$ to $$ \frac {dt} {T} = \frac {1} {2 \sqrt {hx} } dx $$ where $x(t) = \frac {1} {2} gt^2 $ and $ T = \sqrt { \frac {2h} {g}}$ . I'm currently struggling with Griffiths' Introduction to Quantum Mechanics . This is from a worked example on p.11-12 of the 2nd edition.,['derivatives']
3969567,"In ZF, does the ring of continuous functions $C([0,1], \mathbb{R})$ have prime ideals which is not maximal?","In ZFC, it is known that the ring of continuous functions $C([0,1], \mathbb{R})$ have prime ideals which is not maximal. But all proofs of this which I saw uses the axiom of choice. Then, in ZF, does the same statement hold? If ZF cannot prove this, how strong is $\mathrm{ZF}+(\text{$C([0,1], \mathbb{R})$ has prime ideals which is not maximal})$ as an intermediate between ZF and ZFC?","['maximal-and-prime-ideals', 'functional-analysis', 'axiom-of-choice', 'general-topology', 'set-theory']"
3969581,What is the derivative of a complex function that includes a complex conjugate variable?,"How can I take the derivative of $f(z) = z + z^*$ , where $z$ is complex, i.e. $z=a+ib$ ? My question is actually for $f(z, z^*)$ in general. My complex variables book doesn't include such an example - why not?","['complex-analysis', 'derivatives', 'complex-numbers']"
3969614,"If $a^3=e$, then $a$ has a square root. [duplicate]","This question already has answers here : Every element in a finite (abelian) group $G$ is an $n$'th power if $\,\gcd(n,|G|)=1$ (4 answers) Solve $x^{5} \equiv 2$ mod $221\ $ [Taking modular $k$'th roots if unique] (2 answers) Closed 3 years ago . If $a^3=e$ , then $a$ has a square root. I have that $a^3=aaa=e$ and applying $a^{-1}$ twice on both sides of the equation gives us $a=a^{-1}a^{-1}$ and so $a=(a^{-1})^2$ . Thus $a$ has a square root. Is this correct? Is there another way to do this?","['group-theory', 'abstract-algebra']"
3969621,"On a sphere, does a rhumb line always exist between two points? If so, how to calculate it?","We can calculate the bearing between two points (described by lat, lon with an elevation of 0 for simplicity) on Earth by using the Haversine formula, which yields an initial heading and a final heading. When this line is followed the distance is minimal. But is there such a thing as a ""straight line"" which is not distance minimal that can be cast between any two points such that the initial heading is the same as the final heading always? How can this bearing be calculated if so? (As noted in comments, such a path is called a rhumb line or loxodrome .) Example: If point A is some point that lies on the equator of Earth, and B is a point 200 miles to the west of point A, you could simply get from A to B by going 200 miles on a 270 heading. You could also follow a great circle path which would result in less distance but would involve an initial and final bearing which change as a function of your position on the line. Does this straight line exist for any two points on a sphere? I am fairly sure the answer is yes, but I'd like to know how to calculate this if I am correct. What would this line be called? I've heard it described at LOS (line of sight) I think, but unsure of if that is the same idea.","['trigonometry', 'spheres', 'geometry']"
3969632,Integral of functions of several variables,"The function is defined from $[-1,1]\times[-1,1]$ to $\Bbb R$ , given by $f(x,y)=\frac{x^2-y^2}{(x^2+y^2)^2}$ when $(x,y)≠0$ and $f(0,0)=0$ .
I could find that the function is not continuous at origin, so not differentiable  and also partial derivatives does not exist at origin.
But how do we evaluate the integral of the function over the given domain. Being function of several variable how do we deal with the point of discontinuity? Can we convert it to polar coordinates and apply residue theorem? Do we have any other methods?
Any help would be appreciated. Thanks in advance.","['functions', 'real-analysis']"
3969645,"What is the meaning of ""$\pm$""? Can we write $1=\pm1$? or $x^2=4\iff \pm x=\pm 2$?","Does "" $\pm$ "" mean ""positive or negative""? Is it allowed to write: $1 = \pm1\;$ ? Is it allowed to write: $X^2 = 4 \iff \pm X = \pm2\;$ ?","['notation', 'algebra-precalculus', 'definition']"
3969650,Construct the smallest graph homeomorphic to a given graph by smoothing,"The homeomorphism class $ \mathcal{H}(G) $ of a graph $G$ is the set of isomorphism classes of graphs that are topologically homeomorphic to $G$ . It is natural to ask: Is there a ""smallest"" representative in the homeomorphism class? If yes, how to find it? Unfortunately, I found no useful result on this problem after a quick google search. Nevertheless, guided by intuition, I have the following hypothesis: The smallest graph homeomorphic to a graph is obtained by smoothing
every maximal ear. In this post I attempt to sketch a proof, but there is a gap in the proof, so I don't know whether my hypothesis is actually correct. I would appreciate anyone for pointing out my mistakes and filling out the gap. Warning: this would be a long post First, let's clear up some terminology. The term ""ear"" means different things in different graph theory textbooks. In this post, we adopt the following definition: Definition 1 An ear in a graph is either: a cycle whose all except possibly one vertices are of degree $2$ , or a path whose all internal vertices are of degree $2$ . A maximal ear is an ear that is not a proper subgraph of a larger ear.
Equivalently, a maximal ear is one of the following: a cycle that is a whole connected component on its own a cycle in which exactly one vertex is of degree $ \geq 3 $ , while all other vertices are of degree $2$ a path in which all internal vertices are of degree $2$ , while both end vertices are of degree $ \neq 2 $ Two common operations that preserve topology on graphs are subdividing and smoothing: Definition 2 Subdividing an edge means replacing it by an ear. More precisely, let $e = uv$ be an edge. If $u = v$ , then subdividing the self-loop $e$ means replacing it by a
cycle $C$ , and $u = v$ becomes a vertex on $C$ , which may or may not
have degree $2$ , depending on whether $e$ is isolated. On the other hand, if $u \neq v$ , then subdividing $e$ means replacing
it by a path $P$ , and $u, v$ become the end vertices of $P$ . Subdividing a graph means preforming a sequence of subdividing on
edges. Definition 3 Smoothing an ear means replacing it by a single edge. More precisely,
let $C$ be an ear. If $C$ is a cycle, then smoothing $C$ means replacing it by a
self-loop $e$ , and the vertex of degree $ \neq 2 $ on $C$ becomes the
only vertex incident on $e$ (if all vertices on $C$ are of degree $2$ ,
just choose any vertex). On the other hand, If $C$ is actually a path $P$ , then smoothing $P$ means replacing it by a loopless edge $e$ , and the end vertices of $P$ become the end vertices of $e$ . Smoothing a graph means preforming a sequence of smoothing on ears. Next, we have the following classic result on topology of graphs: Theorem 1 Two graphs are homeomorphic if and only if one of them can be obtained
from a sequence of subdividing and smoothing operations on the another. Proof: See this post . Theorem 2 Let $G$ and $H$ be two homeomorphic graphs. Then $ |V(G)| = |V(H)| $ if and only if $ |E(G)| = |E(H)| $ . Sketch of proof: Subdividing (resp. smoothing) always increases (resp. decreases) the number of vertices and edges by the same number. $\square$ In light of Theorem 2, we can define an ordering on the homeomorphism class of a graph: Definition 4 Let $ \mathcal{H}(G) $ be the homeomorphism class of a graph $G$ .
Define the ordering $\preceq$ on $ \mathcal{H}(G) $ by: $$ G_1 \preceq G_2 \iff |V(G_1)| \leq |V(G_2)| $$ for any $ G_1, G_2 \in \mathcal{H}(G) $ . If $ G_1 \preceq G_2 $ and $ G_2 \preceq G_1 $ , then we denote $ G_1 \sim G_2 $ . The ordering $\preceq$ is a total preorder, meaning it is transitive and any two homeomorphic graphs are comparable. Unfortunately it is not a total order, since $ G_1 \sim G_2 $ does not imply $ G_1, G_2 $ are isomorphic, even through Theorem 2 implies $ |E(G_1)| = |E(G_2)| $ . Theorem 3 Any graph without isolated vertex can be uniquely decomposed into an
edge-disjoint union of maximal ears. Sketch of proof: Let $G$ be a graph without isolated vertex. Define the relation $R$ on $E(G)$ by: $$ eRf \iff \exists \text{ ear } C \subseteq{G} \text{ s.t. } e, f \in E(C) $$ for any $ e, f \in E(G) $ . Then $R$ is an equivalence relation on $E(G)$ , in which each equivalence class contains the edges of exactly one maximal ear. Thus, $R$ induces a decomposition of $G$ into an edge-disjoint union of maximal ears. Conversely, any such decomposition must be induced by $R$ , so the decomposition is unique. $\square$ Based on the above decomposition, we can define the following: Definition 5 A graph without isolated vertex is called smooth if every maximal ear
is of length $1$ . For a graph $G$ without isolated vertex, the smooth
graph obtained from smoothing every maximal ear in $G$ is denoted as $ \text{Smooth} (G) $ . The term ""smooth graph"" is not standard, but I could not find any existing term for such a graph, so I just make it up on my own. Theorem 4 Let $G$ be a smooth graph without isolated vertex and $ H \in \mathcal{H}(G) $ , then $ G \preceq H $ . Moreover, $ G \sim H $ if and only if $H$ is a smooth graph. Sketch of proof: By Theorem 1, $H$ can obtained from a sequence of subdividing and smoothing operations on $G$ . Each step of the operations can only change one of the maximal ear to another maximal ear of possibly different length. On the other hand, in a smooth graph all the maximal ears already have the shortest possible length (namely, $1$ ), so any sequence of subdividing and smoothing can never further decrease the number of vertices. Thus, $ |V(G)| \leq |V(H)| $ and the equality holds if and only if $H$ is smooth. $\square$ The following claim is based on intuition, but I don't know how to prove it. It is where the gap of my whole proof lies. Claim 0 Let $G$ and $H$ be two smooth graphs without isolated vertex. If
they are homeomorphic, then they are isomorphic. Finally, assuming the above claim, we can prove the main hypothesis: Main Hypothesis Assume Claim 0 is correct and let $G$ be a graph without isolated
vertex. Then $ \text{Smooth} (G) $ is the unique smallest graph in $ \mathcal{H} (G) $ with respect to the ordering $ \preceq $ . Proof: The fact that $ \text{Smooth} (G) \preceq H $ for all $ H \in \mathcal{H} (G) $ follows from Theorem 4. To prove uniqueness, let $ H \in \mathcal{H} (G) $ be such that $ \text{Smooth} (G) \sim H $ . Since $ \text{Smooth} (G) $ is smooth and $ H \in \mathcal{H} (\text{Smooth} (G)) $ , by Theorem 4, $H$ is smooth as well. Claim 0 then implies $H$ is isomorphic to $ \text{Smooth} (G) $ . $\square$ Questions: Is Claim 0 correct? How to prove it? Even if Claim 0 is wrong, is my main hypothesis still correct? Are there any other mistakes in my proof? Is there a better term for graphs whose every maximal ear is of length $1$ , other than ""smooth graphs""?","['graph-theory', 'general-topology', 'solution-verification', 'topological-graph-theory']"
3969677,"Topology on $[0,1]$ that makes it pseudocompact but not compact?","The space $[0,1]$ is compact with respect to its usual (metric) topology. I was wondering whether there is a known topology on it which makes it pseudocompact but not compact? Now sequentially compact and countably compact both imply pseudocompact so any such topology would work as well. Also, a metric space which is pseudocompact is automatically compact, so the topology cannot be induced by a metric. Any idea or reference would be appreciated. I know we can always find such a topology. For instance, if we consider a pseudocompact space which is not compact which has the same cardinality as $[0,1]$ and transfer the topology to $[0,1]$ via bijection. I wanted to know if there is one which is frequently discussed and/or easy to understand.","['general-topology', 'compactness', 'reference-request']"
3969718,counting cycles and paths in simple graphs,"I'm newly studying graphs in my school courses and I've been facing this common type of questions about how many cycles/paths are there between some vertices I asked my teacher for a simpler or more algorithmic way to count them but he said except for Kn graphs. so I started to search for such an algorithms and I found out there are such algorithms but I have no idea how to use them(as I said I'm a high-school student).
these are the papers I took a look at: https://www.sciencedirect.com/science/article/abs/pii/0020019094001510 http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.156.345 so I'm seeking a way to solve such problems more efficiently and with less probability of making ridiculous mistakes.
any help is appreciated","['graph-theory', 'analysis', 'combinatorics', 'planar-graphs', 'algorithms']"
3969763,"Given $a > b > c > d > 0,$ and U $= \sqrt{ab} + \sqrt{cd}$ , V $= \sqrt{ac} + \sqrt{bd}$ , W $= \sqrt{ad} + \sqrt{bc}$.","Given $a > b > c > d > 0,$ and U $= \sqrt{ab} + \sqrt{cd}$ , $V = \sqrt{ac} + \sqrt{bd}$ , $ W = \sqrt{ad} + \sqrt{bc}$ , arrange $U$ , $V$ , $W$ in ascending order. What I Tried : I squared $U$ , $V$ , $W$ to get :- $\rightarrow U^2 = ab + cd + 2\sqrt{abcd}$ . $\rightarrow V^2 = ac + bd + 2\sqrt{abcd}$ . $\rightarrow  W^2 = ad + bc + 2\sqrt{abcd}$ . We can cancel out the $2\sqrt{abcd}$ from each and we are only left to compare $(ab + cd) , (ac + bd) , (ad + bc)$ in order to compare $U$$,V$ , $W$ . This is where I get stuck. I could say that $ab > ac$ , but I couldn't necessarily show that $cd > bd$ , as $b > c$ . That way does not work for me, and I am not finding any other way to compare these. Can anyone help?","['algebra-precalculus', 'inequality']"
3969830,Find the probability of the outcome which has highest chance of occurring.,"A biased die has numbers $1, 2, 3, 4, 5, 6$ . The probability of obtaining one of the numbers is greater
than ${1\over 6}$ , whereas the probability of obtaining a number opposite to it is less than ${1\over 6}$ . The remaining four numbers each have a probability of ${1\over 6}$ of being obtained. Given that any two opposite faces add up to $7$ . When two such dice are rolled, probability of obtaining a sum $7$ is ${47\over 288}$ . If the number which has the highest probability of being obtained has probability ${p\over q}$ , for ( $p, q$ ) = $1$ , find $p + q$ . Well I know that $P(E)$ = ${No.\;of\;Favourable\;Outcomes\over Total\;Outcomes}$ but I am confused as to how to find the Probability in this case. Because the formula which I wrote, I guess, is applicable only when all the possible outcomes have equal chances of occurring which is not happening in this case.","['probability-theory', 'probability']"
3969856,Solving a Recursive Relation using Generating Functions,"Consider the following recursive relation. $$a_0=0$$ $$a_i = (1-p)a_{i-1} + pa_{i+1} \text{ }\forall \text{ natural numbers }i \text{ }\epsilon\text{ } [1, m - 1] $$ $$a_m=1$$ $$0<p<1$$ I'm trying to find an explicit formula for $a_i$ . I have tried using generating functions to do so. Define $A(x) = \sum_{k=0}^{m} a_k x^k$ . Now, $$\sum_{k=1}^{m-1}[a_i-(1-p)a_{i-1}-pa_{i+1}]x^k=0$$ $$\implies\sum_{k=1}^{m-1}a_kx^k - (1-p)x\sum_{k=1}^{m-1}a_{k-1}x^{k-1}-px^{-1}\sum_{k=1}^{m-1}a_{i+1}x^{i+1}=0$$ $$\implies[A(x) - a_0-a_mx^m]-(1-p)x[A(x)-a_mx^m-a_{m-1}x^{m-1}]-px^{-1}[A(x)-a_1x-a_0]=0$$ $$\implies [1-(1-p)x-px^{-1}]A(x) - x^m+(1-p)x^{m+1}+(1-p)a_{m-1}x^m+a_1p=0$$ $$\implies A(x) = \frac{(1-p)x^{m+2}-pa_{m-1}x^{m+1}+a_1px}{(1-p)x^2-x+p}$$ I am unsure of how to proceed from here. Kindly help.","['recursion', 'discrete-mathematics', 'generating-functions']"
3969860,What's the most elementary way to solve this trigonometric problem?,"A bead is threaded onto a light, inextensible string of length $4m$ . One end of the string is fixed to a point, $A$ , on a (vertical) wall. The other end of the string is attached to a point $B$ on the wall exactly $2m$ directly below $A.$ The bead is held in place so that it is at a distance of $1m$ from the wall, such that the string is taut and the plane the string is in is perpendicular to the plane the wall is in. Find the two possible vertical components of the displacement from $B$ to the bead. This is a question I came up with, and I thought there should be some relatively simple trigonometric methods to get to the answer. I tried lots of stuff but nothing seemed to work. Of course, we could find the equation of the ellipse that corresponds to the locus of points the bead could be when the string is taut, and then find the two values of $y$ when $x = 1$ . But I'm looking for more elementary methods involving only trigonometry and Pythagoras. This is because I want the answer to be aimed at secondary school students who know elementary trigonometry only (Pythagoras, addition angle formulae, R addition formulae etc). Thanks in advance.","['trigonometry', 'triangles']"
3969911,"Show that $\gamma:[a,b]\rightarrow \mathbb{C}$ has bounded variation iff exists $h:[0,1]\rightarrow [a,b]$ with $\gamma \circ h$ Lipschitz.","Let $~\gamma:[a,b]\rightarrow \mathbb{C}~$ be a continuous curve: show that $~\gamma~$ has bounded variation if and only if there exists $~h:[0,1]\rightarrow [a,b]~$ continuous and surjective such that $~\gamma \circ h~$ is a Lipschitz curve. My only idea is for the proof of the reciprocal proposition: if $$
|\gamma(h(x))-\gamma(h(y))|\leq k|x-y|~\forall x,y\in [0,1],$$ then, given a partition $P=\{a=x_0,x_1,\dots, x_n=b\}$ , I have that exists $~y_i~$ with $~h(y_i)=x_i~$ for each $i$ from $1$ to $n$ . Then, $$\sum_{i=1}^n|\gamma(x_i)-\gamma(x_{i-1})|\leq \sum_{i=1}^n|\gamma(h(y_i))-\gamma(h(y_{i-1}))|\leq k\sum_{i=1}^n|y_i-y_{i-1}|$$ But I don't know how to continue, because I think that $h$ is not necessarily monotonic. Edit: For the direct implication I found a reference that helped me a lot, here goes https://mathoverflow.net/questions/253024/from-bounded-variation-to-1-lipschitz-function","['complex-analysis', 'lipschitz-functions', 'analysis', 'bounded-variation']"
3969951,Characterizing isolated singularities of $\frac{z}{e^{z} - z + 1}$,"I intend to characterize the isolated singularities of $f(z) := \frac{z}{e^z - z + 1}$ which is defined on some open subset $\mathbb{C} \backslash f^{-1}({0}) \subset \mathbb{C}$ . The possible singularities are only the zeros of $g(z) := e^z - z + 1$ , so the approach should be to find those zeros, which is actually the difficult task. At this point, what I know is the following: Since no zeros of $g$ lie on $2\pi i \mathbb{Z}$ , if we suppse that $z_{0} \in \mathbb{C}$ is a zero of $g$ , then we will of course have $\lim\limits_{z \to z_{0}} |f(z)| = \infty$ and so $z_{0}$ will be a pole of $f$ . Using then L'Hôpital's rule applied to $\lim\limits_{z \to z_{0}} (z-z_{0})^n f(z)$ , we check that the pole will have to be of order $1$ . $g$ has zeros, which I found out by separating the function $g(z) = 0$ in two equations, concerning the real and imaginary parts of $g$ and then by ploting the resulting functions to see that they intersect. My question is then: Can we see analytically that $g$ has zeros? This is an exercise from a Reinhold Remmert's book, ""Theory of Complex Functions"" (line c) in exercise 1 on page 309) and I think I'm supposed to solve it analytically. Also, keep in mind that, at this point in the book, there are a lot of tools in complex analysis still not available to use, namely residue calculus and Laurent series. Thank you in advance for all the help!","['complex-analysis', 'singularity']"
3969967,CDF's of Two Binomial Distributions with the Same Mean and Different Probabilities,"Suppose we have two binomial random variables $X_i \sim B(\frac{a}{p_i},p_i)$ and $X_j \sim B(\frac{a}{p_j},p_j)$ , where $a$ is a positive integer, and both $\frac{a}{p_i}$ and $\frac{a}{p_j}$ are integers. Assume $p_i > p_j$ . In particular, we have $E[X_i] = E[X_j] = a$ . Let $F_{X_i} (x)$ and $F_{X_j} (x)$ denote the CDF's of $X_i$ and $X_j$ , respectively. It seems true (with an example in the image below) that $F_{X_i} (x) < F_{X_j} (x)$ for $x < a$ and $F_{X_i} (x) > F_{X_j} (x)$ for $x > a$ . Is there a simple way to prove it (or, is this result somewhat established in literature)?","['binomial-distribution', 'probability']"
3969974,"Is $\lim\limits_{a^{-}}f = +\infty \Rightarrow \lim\limits_{a^{-}}f' = +\infty$ true? If so, proof?","Let $f:(-\infty,a) \to \mathbb{R}$ be a differentiable function verifying that $\lim\limits_{a^{-}}f = +\infty$ . Since the function grows rapidly to infinity when getting close to $a$ in a ""finite"" space, I wondered if $\lim\limits_{a^{-}} f' = +\infty$ . I didn't find any counterexample, so I think the implication is true. Now, for the proof, I thought of fixing an $\bar{a}$ arbitrarily close to $a$ , and considering for all $x\in(\bar{a},a)$ , the slope : \begin{equation}
S:=S_{\bar{a}}(x)=\frac{f(x)-f(\bar{a})}{x-\bar{a}}
\end{equation} When $x$ tends to $a$ , $S$ goes to infinity and that's for all $\bar{a}$ (so if $\bar{a}$ tends to $a$ , it'll be the same), which means that : \begin{equation}\lim\limits_{\bar{a}\to a} \lim\limits_{x \to a} S = +\infty \end{equation} When $x$ approaches $\bar{a}$ , S approaches $f'(a)$ , and this being true for all $\bar{a}$ , we can have : \begin{equation}
\lim\limits_{\bar{a}\to a} \lim\limits_{x \to \bar{a}} S = \lim\limits_{\bar{a}\to a} f'(\bar{a})=\lim_{x\to a}f'(x)
\end{equation} I feel that the two procedures are equivalent since we always get $x$ and $\bar{a}$ infinitesimally close, so both limits should be equal in some sense. So we get at the end that $f'(x) \to +\infty$ .","['limits', 'derivatives']"
3970068,How do I prove that a statistic is a pivot?,"In this example I have a sample out of a distribution with density $P_{\theta}(x) = 2x^{\theta} e^{−\theta x^2} I_{x \ge 0}$ .
I know that for all $i \ge 1$ we have $X_i^2 \sim Exp(\theta)$ .
If $\theta = 1$ , then $T_1 = 2\sum_{1 \le i \le n}X_i^2 \sim X_{2n}^2$ .
And now I have to show that $T_{\theta} = 2\sum_{1 \le i \le n} \theta X_i^2$ is a pivot.
A pivot is a function of which the probability function does not depend on $\theta$ .
But how do I show that $T_{\theta}$ does not depend on $\theta$ ? Btw: I tried to plug it first in LaTeX, so that it's easier to read. But that doesn't work.",['statistics']
3970084,line integral of a gradient vector field,"I'm having trouble finding the line integral of this problem.
So they give me the gradient vector field $$\nabla f(x,y,z) = 2xyze^{x^2}i + ze^{x^2}j+ye^{x^2}k$$ they say that $f(0,0,0) = 5$ and i want to know what is the value of line integral $f(1,1,2)$ i know that the line integral of a gradient vector field is given by $$\int_{a}^{b} \nabla f(x,y,z)ds = f(c(b)) -f(c(a))$$ But i'm stuck by how to find $f$ , can someone explain to me","['multivariable-calculus', 'calculus', 'vector-analysis']"
3970161,Prove that a wff built up only with $\lnot$ and $\leftrightarrow$ is a tautology iff $\lnot$ and each statement letter occur an even number of times.,"First of all, I know how to prove this theorem below: A statement form that contains $\leftrightarrow$ as its only connectives is a tautology iff  each statement letter occurs an even number of times. To prove the theorem, I first derived this corollary: A statement built up using only $\leftrightarrow$ is true iff there are an even number of false terms. But now, I have to prove the theorem below: Proving that a statement form that contains $\lnot$ and $\leftrightarrow$ as its only connectives is a tautology iff $\lnot$ and each statement letter occur an even number of times. The bold texts are the only differences comparing it to the previous question that I could solve. I tried modifying the corollary to help me prove the theorem but it didn't help me, or modifying the corollary made it impossible to prove. Is there anything else I could do?","['satisfiability', 'propositional-calculus', 'logic', 'discrete-mathematics']"
3970175,"How to prove there are $\frac{3^n-1}{2}$ couples $A,B \in \mathcal{P}([n])$ such that $A \cup B = [n]$, $A \neq B$.","Consider the unordered couple of sets $A,B \in \mathcal{P}([n])$ such that $A \cup B = [n]$ , $A \neq B$ . I would like to prove that the number of such couples is: $$\frac{3^n-1}{2}$$ I derived that expression by enumerating the solutions for the first values of $n$ , and also considering the sum of the number of those couples for all different values of $n$ over $\mathcal{P}([m])$ : $${2^m \choose 2} = \sum_{n=0}^m {m \choose n}\frac{3^n-1}{2}$$ (this is easy to show using the binomial expansion). I have checked OEIS A003462 where they count the number of couples $A,B \in \mathcal{P}([n])$ with $A \cap B = \emptyset$ and $A \neq \emptyset$ or $B \neq \emptyset$ , with the same $\frac{3^n-1}{2}$ result, but it's not the same thing and I was not able to adapt that reasoning.",['combinatorics']
3970178,Writes in polar coordinates $x''-(1-x^2-(x')^2)x'+4x=0$.,"I need to determine a periodic solution for : $x''-(1-x^2-(x')^2)x'+4x=0$ .
We have the equivalent system: $$\begin{cases} 
       x'=y \\
       y'=(1-x^2-y^2)y-4x.
   \end{cases}
$$ We determined the stationary points for the equivalent system: $(0,0)$ . I saw that this solution is unstable. But now I have to turn this system into polar coordinates. Unfortunately, I tried in all possibilities and I failed to bring the system to a beautiful shape depending on the polar coordinates. I present what I tried: Polar coordinates: $\begin{cases} 
       x(r,\theta)=r\cos(\theta) \\
       y(r,\theta)=r\sin(\theta)
   \end{cases}
$ We have that $x^2+y^2=r^2$ and $\tan(\theta)=\frac{y}{x}$ . So $r'=\frac{xx'+yy'}{r}$ and $\theta'=\frac{xy'-x'y}{r^2}.$ So $$r'=\frac{xy+y[(1-x^2-y^2)y-4x]}{r}=\frac{xy+y^2-x^2y^2-y^4-4xy}{r}.$$ I tried to calculate, but I have no idea how to bring the system into polar coordinates to continue my work.
Thanks!","['polar-coordinates', 'systems-of-equations', 'ordinary-differential-equations', 'dynamical-systems']"
3970221,Directional Derivatives on a Manifold.,Let $M$ be a manifold (if its easier then say a Riemannian Manifold). My aim is to understand directional derivatives of some function $\Phi: M\to \mathbb{R}$ . $\underline{\textit{My Understanding So Far :}}$ For a manifold $M$ the tangent space at a point $p$ (denoted $T_p M$ ) can be seen as the set of equivalence classes of curves on $M$ passing through $p$ . More specifically : https://en.wikipedia.org/wiki/Tangent_space#Definition_via_tangent_curves . A Riemannian Manifold is a manifold $M$ equipped with an inner product on $T_p M \times T_p M$ (which will let us talk about angles and lengths of curves on $M$ ). The classical directional derivative (in direction $v$ and at point $p$ ) of a function acting on $\mathbb{R}^d$ tells you how much the function changes at point $p$ and in direction $v$ . $\underline{\textit{Help : }}$ Im finding it hard to go from the above to the definition of directional derivatives given here https://en.wikipedia.org/wiki/Tangent_space#Tangent_vectors_as_directional_derivatives . Any help ? :),"['tangent-spaces', 'derivatives', 'smooth-manifolds', 'differential-geometry']"
3970261,Skorokhod embedding theorem in higher dimensions,"I recently learned Skorokhod's embedding theorem, which says that for any random variable $X$ with $E[X]=0$ and $E[X^2]<\infty$ , there is a stopping time $T$ (wrt the canonical filtration for Brownian motion $B_t$ ) such that $X$ is equal in distribution to $B_T$ and $E[T] = E[X^2]$ . Are there higher dimensional analogs of this? It's easy to show that $X =_d B_T$ when $X$ takes only two values $a<0<b$ (take $T = \inf\{t\geq 0:B_t\not\in (a,b)\}$ ). One version of the proof shows the general result in 1 dimension by approximating any random variable $X$ satisfying the conditions with a ""binary splitting martingale"" $(X_n)_{n\geq 0}$ , e.g. a martingale such that $X_n$ takes only $2$ values for each $n$ . Could you generalize the result to higher dimensions by approximating $X$ by [a martingale?] $(X_n)_{n\geq 0}$ such that the $X_n$ are valued on nested sets centered at the origin or something like that? Are there more conditions that you would need on $X$ to make this possible? Thanks for any suggestions!","['brownian-motion', 'probability-theory', 'random-variables']"
3970271,Show that $E[ E[Z\lvert \mathcal{F}_{T}\lvert \mathcal{F}_{S}]=E[Z\lvert \mathcal{F}_{T\land S}]$,"Let $T$ and $S$ be stopping times and $Z$ some integrable random variable. I already know that: $\mathcal{F}_{T\land S}=\mathcal{F}_{T}\cap\mathcal{F}_{S}$ and $\{T>S\},\;\{T\leq S\},\; \{T<S\},\;\{T\geq S\} \in \mathcal{F}_{T\land S}$ . And furthermore I have shown that: $E[Z\lvert \mathcal{F}_{T}]=E[Z\lvert \mathcal{F}_{S\land T}]\; \; \mathbb P$ -a.s. on $\{T\leq S\} \; (*)$ I want to show that: $E[ E[Z\lvert \mathcal{F}_{T}]\lvert \mathcal{F}_{S}]=E[Z\lvert \mathcal{F}_{T\land S}]\; \; \mathbb P$ -a.s. I guess we have to use $(*)$ but I get stuck: $E[ E[Z\lvert \mathcal{F}_{T}]\lvert \mathcal{F}_{S}]=E[ E[Z\lvert \mathcal{F}_{T}]1_{\{T\leq S\}}\lvert \mathcal{F}_{S}]+E[ E[Z\lvert \mathcal{F}_{T}]1_{\{T> S\}}\lvert \mathcal{F}_{S}]= E[Z\lvert \mathcal{F}_{T\land S}]1_{\{T\leq S\}}+E[ E[Z\lvert \mathcal{F}_{T}]1_{\{T> S\}}\lvert \mathcal{F}_{S}]$ How can I go about showing that the second term $$ E[ E[Z\lvert \mathcal{F}_{T}]1_{\{T> S\}}\lvert \mathcal{F}_{S}]=E[Z\lvert \mathcal{F}_{T\land S}]1_{\{T>S\}}$$ or am I going about this the wrong way? Reference to Problem 2.17 from Karatzas and Shreve p. 9 Brownian Motion and Stochastic Calculus","['expected-value', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3970347,Solving $x^2 y''-2xy'=0$ using power series,"Given the following ODE $$x^2 y''-2xy'=0$$ I'm trying to solve it using power series. Since $$y=\sum_{n=0}^{\infty} a_{n}x^{n}$$ then $$x^{2}y''=\sum_{n=2}a_{n}n(n-1)x^{n}$$ and $$2xy'=\sum_{n=1}^{\infty}2a_{n}nx^{n}=2a_{1}x+\sum_{n=2}^{\infty}2a_{n}nx^{n}$$ Therefore, in the equation, I get $$-2a_{1}x+\sum_{n=2}^{\infty}(n^{2}-3n)a_{n}x^{n}=0$$ So $$-2a_{1}=0\Rightarrow a_{1}=0$$ and $$(n^{2}-3n)a_{n}=0,\quad\forall n\geq2$$ Since I'm looking for non-trivial solutions, $a_{n} \ne 0\Rightarrow n^{2}-3n=0$ which gives me $n=0$ or $n=3$ . I want to know if it's right and if so, what I'm supposed to do with these values of $n$ .","['power-series', 'ordinary-differential-equations']"
3970350,Consider the function $f(x) = \frac{1}{3^x + \sqrt{3}}.$ Find :- $\sqrt{3}[f(-5) + f(-4) + ... + f(3) + f(4) + f(5) + f(6)]$.,"Consider the function $f(x) = \frac{1}{3^x + \sqrt{3}}.$ Find :- $\sqrt{3}[f(-5) + f(-4) + ... + f(3) + f(4) + f(5) + f(6)]$ . What I Tried : I checked similar questions and answers in the Art of Problem Solving here and here and tried to get some ideas. First thing which I did is thinking of pairing the values, I took for example, $f(-1)$ and $f(1)$ .
We have :- $$\rightarrow f(-1) = \frac{1}{\frac{1}{3} + \sqrt{3}} = \frac{3\sqrt{3} + 1}{3}$$ $$\rightarrow f(1) = \frac{1}{3 + \sqrt{3}}$$ Adding both gives $\frac{7 + 6\sqrt{3}}{12 + 10\sqrt{3}}$ , which more or less looks like a random sum. So my idea of pairing did not work, or at least I couldn't pair them nicely or missed a pattern. So how would I start solving it? Can anyone help?","['algebra-precalculus', 'linear-algebra', 'problem-solving']"
3970372,Sheafification of representable presheaves,"Recall that if $\mathscr{C}$ is a site (which, for me, means a category equipped with a Grothendieck pretopology—not sieves) that it’s not in general true that the representable presheaf $h_X$ associated to an object $X$ of $\mathscr{C}$ is a sheaf. In particular, one can consider the composition of functors $$\mathscr{C}\to \mathsf{PSh}(\mathscr{C})\xrightarrow{(-)^\#}\mathsf{Sh}(\mathscr{C})$$ (where $(-)^\#$ denotes sheafification) and think of the full image—the full subcategory of $\mathsf{Sh}(\mathscr{C})$ whose objects are sheaves isomorphic to $h_X^\#$ for an object $X$ of $\mathscr{C}$ . Let me denote this category with the (probably poorly chosen) notation $\mathscr{C}^\#$ . My question is then the following Question: What is an explicit description of $\mathscr{C}^\sharp$ ? To give an idea of what type of description I’m looking for, I think that one can write that there is a bijection $$\mathrm{Hom}(h_X^\#,h_Y^\#)=\varinjlim_{\substack{\{U_i\to X\}\\ \mathscr{C}\text{-coverings}}}\check{H}^0_\mathrm{loc}(\{U_i\to X\}, h_Y)$$ where $$\check{H}^0_\mathrm{loc}(\{U_i\to X\}, h_Y):=\left\{(f_i)\in\prod_i \mathrm{Hom}_{\mathscr{C}}(U_i,Y): f_i\text{ and }f_j\text{ agree locally on overlaps for all }i,j\right\}$$ where $f_i$ and $f_j$ agreeing locally on overlaps means that there exists a cover $\{V_k\to U_i\times_X U_j\}$ such that $(f_i)\mid_{V_k}=(f_j)\mid_{V_k}$ . This is literally, I believe, just because one has natural bijections $$\mathrm{Hom}(h_X^\#,h_Y^\#)=\mathrm{Hom}(h_X,h_Y^\sharp)=h_Y^\#(X)$$ the first from the definition of sheafification, and the second from Yoneda’s lemma. The claimed equality then follows from the explicit description of sheafification. Refined question: With the above description of $\mathrm{Hom}(h_X^\#,h_Y^\#)$ (or a slightly modified, but still
explicit version) What is the actual map $h_X^\sharp(Z)\to h_Y^\#(Z)$ for $Z$ an object of $\mathscr{C}$ ? What is the composition $$\mathrm{Hom}(h_X^\#,h_Y^\#)\times \mathrm{Hom}(h_Y^\#,h_Z^\#)\to \mathrm{Hom}(h_X^\#,h_Z^\#)$$ look
like? NB: I’m mostly looking for a reference. Obviously you can answer this question by tracing through all the definitions, but I’d like to save myself the time/writing and just cite something. I’d be a little surprised if a reference didn’t exist. Thanks!","['sheaf-theory', 'algebraic-geometry', 'category-theory', 'reference-request']"
3970382,Exponential map on matrices,"I was thinking about different definition of exponential: Case 1: Let $z=a+ib$ be a complex number so we have the exponential map $\exp(z)=\sum \frac{z^n}{n!}$ . But one can also view $z$ as a matrix (indeed $z$ is a special automorphism of $\mathbb{R}^2$ ) of the form $z_r:=Z:=\begin{pmatrix}a & -b \\ b & a \end{pmatrix}$ so one has the exponential matrix map defined by $\exp(Z)=\sum \frac{Z^n}{n!}$ it is not difficult to show that $\exp(z_r)=\exp(z)_r$ (I can give more details for this if it worth, the idea is to use the polar expression of $z$ and that write $Z=a\operatorname{Id}+bI$ and use the Taylor expansion of $\sin$ and $\cos$ ). Case 2: (The question) What about the more general case of the exp function on a linear operator $\phi:\mathbb{C}^n\longrightarrow\mathbb{C}^n$ ? Indeed, let $X$ be a complex matrix of size $n$ , and let $X_r$ the block-matrix obtained by replacing to each $x_{ij}$ the $2\times2$ matrix ${x{_{ij}}}_r$ is it true that $\exp(X_r)=\exp(X)_r$ ? Is it a general thing? My approach: I've tried with a calculation like the Case 1 but it seems to be more difficult to calculate. Another approach I have in mind is to use the fact that $\mathbb{C}^n$ is a real smooth variety with standard complex structure and than use the flow theorem. This approach gives me a characterization for $\exp(X_r)$ but my problem is to prove that $\exp(X)_r$ is also a solution for the flow. (Maybe if this is not very clear I would clarify) Questions: Is it possible to prove that $\exp(X_r)=\exp(X)_r$ by straightforward calculation? Is it possible to prove that $\exp(X_r)=\exp(X)_r$ by using the flow theorem? Any hint or suggestion would be great!","['complex-analysis', 'ordinary-differential-equations', 'differential-geometry']"
3970402,Question on compact subsets of finite dimensional normed spaces,"I'm trying to prove this fact: If $X$ is a finite dimensional normed space and $K$ a compact subset of $X$ that satisfies that if $x, y \in K$ then $\frac{x-y}{2} \in K$ then, given $a \in X \setminus K$ there exists an $\varepsilon >1$ such that $a \not \in\varepsilon K$ I know that the distance from $a$ to $K$ is greater than zero and is attained by some point $x \in K$ , so I'm trying to prove that is enough to take $1 < \varepsilon < d(a,K)+1$ but I'm not able to reach a contradiction if I suppose that $a \in \varepsilon K$ . Any ideas?","['normed-spaces', 'functional-analysis']"
3970413,Derivation with respect to a measure,"I thought about this recently: We first learn the ""usual"" integration, than we are taught that this is a special case, you are just integrating with respect to a particular measure: the Lebesgue measure, and that you can actually integrate with respect to other measures. So why don't we think about derivates the same way? You might differentiate with respect to a measure the following way: if $\mu$ is a measure that is non zero on any non empty invterval, $\partial_\mu f(x) := \lim_{y\to x} \frac{f(y)-f(x)}{\mu([x, x+y])}$ , when this exists. I think that given that definition I have proven an analog of the fundamental theorem of calculus:
if f is a "" $\mu$ -differentiable"" function on $[a,b]$ , and $\partial_\mu f$ is bounded on $[a,b]$ , then $\int_{a}^{b} (\partial_\mu f) d\mu = f(b)-f(a)$ , where the integral is understood as the usual Lebesgue integral with respect to $\mu$ . I have a few questions: -Does this make any sense to you, or is it grossly wrong? -Does any of this exist, does it have any utility, or is it a special case of something I am not aware of? -Is the analog of the fundamental theorem wrong (which means I made a mistake) or could it be right? My proof is quite long but I could try to write it using Latex. Thanks","['integration', 'calculus', 'derivatives']"
3970446,Properties of a hyperbola slice of a cone,"I'm attempting to locate some points (in a 3D coordinate system) on the surface of a cone by slicing the cone with a plane, and using the resultant ellipse, parabola or hyperbola to calculate the points.  I've had success with the ellipse & parabola solutions, but am seeking help with the hyperbola case. Known data:  The slope of the cone, the slope of the plane, and distance from the vertex of the cone to the intersection of the plane and cone's longitudinal axis.  Given these knowns, I'm looking for ""a"" & ""b"". From reading, I have the formulas x²/a² - y²/b² = 1 & c² = a² + b².  I understand distance ""a"" to be half the distance between the two vertices.  Question 1 is, is ""a"" always half the distance between the two vertices, even when the plane is sloped?  If not always half, how is ""a"" calculated when the plane is sloped?  Question 2 is how to determine ""b""?  Question 3 is how to determine the angle of the asymptotes? ...is that the angle of the cone, or if the plane is sloped, some other angle? I'm concerned only with the upper nappe of the cone. As I massage the above formula, attempting to solve for an ""x"" & ""y"" & ""b"", as the plane angle gets shallower, ""a"" gets longer.  And when ""a"" gets longer than an ""x"" value that I am using, my solutions fail due to an attempt to take the square root of a negative number.  So, I know I'm messing up somewhere.  Any help is appreciated. This is my first post here so I don't know my way around.  I'm going to attempt to post a sketch. Thanks in advance.",['geometry']
3970454,Proof Verification of Exercise 2.9 Baby Rudin: Prove that the complement of $E^{o}$ is the closure of the complement of $E$.,"I am stuck on part d of this exercise: Let $E^{o}$ denote the set of all interior points of a set. Prove that the complement of $E^{o}$ is the closure of the complement of $E$ . I solved it using double inclusion: Let $p$ $\in (E^{o})^{c}$ . Since $p$ is not an interior point of $E$ , every neighborhood of $p$ contains a point not in $E$ (or else we have a neighborhood of $p$ that is contained in $E$ and p is an interior point) so $p$ is a limit point of $E^{c}$ so $p$ $\in$ $\overline{E^{c}}$ . Conversely, let $q$ $\in$ $\overline{E^{c}}$ . Then $q$ belongs to $E^{c}$ and is not an interior point of E, or $q$ is a limit point of $E^{c}$ and no neighborhood of $q$ is contained in $E$ , so $q$ is not an interior point of $E$ and so $q \in (E^{o})^{c})$ Is this proof correct? If not, where exactly does it break down? Thank you for your time.","['general-topology', 'solution-verification', 'real-analysis']"
3970512,Expression for the sum of the roots of a polynomial of degree n to the power of k,I am trying to find a function f(m) that given a power m returns the sum of the roots to the power of m. $$(x-a_1)(x-a_2)(x-a_3)...(x-a_n)=0$$ $$f(m)=\sum_{k=1}^n{(a_ k)^m}$$ I attempted doing it manually for small values of n however I wasn't able to spot a pattern after m=3. For m=2 using a quadratic in the form of $x^2+bx+c=0$ I got $b^2-2c$ but that was as far as I got.,"['summation', 'functions', 'roots', 'polynomials']"
3970520,Are the reals genuinely a subset of the complex numbers? [duplicate],"This question already has answers here : Why are integers subset of reals? (11 answers) Is it formally right to say that $\Bbb N \subset \Bbb Z$ etc? [duplicate] (1 answer) Why $\mathbb{R}$ is a subset of $\mathbb{C}$? [duplicate] (4 answers) Is ""$a + 0i$"" in every way equal to just ""$a$""? (10 answers) Closed 3 years ago . In Michael Spivak's Calculus , he defines a complex number as an ordered pair of real numbers: $z=(a,b)$ with $a,b \in \mathbb{R}$ . The imaginary unit $i$ is then just a shorthand for the ordered pair $(0,1)$ . Spivak goes on to say When complex numbers were first introduced, it was understood that real numbers were, in particular, complex numbers; if our definition is to be taken seriously then this is not true—a real number is not a pair of real numbers, after all. Although the complex number $(a,0)$ behaves in pretty much the same way as the real number $a$ , they are still not identical. There seem to be some non-trivial differences, as well: we can't write $(5,0)>(3,0)$ in the way we can write $5>3$ . With this in mind, I ask the following questions: Can the real numbers be said to be a subset of the complex numbers if complex numbers are defined as ordered pairs? If the complex numbers are constructed in some other way, then is it meaningful to write $\mathbb R \subset \mathbb C$ ?","['abstract-algebra', 'complex-numbers']"
3970582,How to find Isomorphism between groups of order 8,"Let $A=\{1,2,3\}$ and $2^A$ is all the subsets of A. Then $(2^A,\triangle)$ is a group. How can I show that the group $\big\{\{1\},\{2\},\{3\},\{1,2\},\{1,3\},\{2,3\},\{1,2,3\},\emptyset\big\}$ with operation $\triangle$ , where $\triangle$ is the symmetric diffrence $C△B=(C \cup B) \backslash (C \cap B)$ is isomorphic to the group $S= \{(0,0,0),(1,0,0),(0,1,0),(0,0,1),(1,1,0),(0,1,1),(1,0,1),(1,1,1)\}= \mathbb{Z}_2 \times \mathbb{Z}_2 \times \mathbb{Z}_2$ with operation $+$ . I did not manage to find a bijection, but both groups have order $8$ and the order of the elements correspond. I did do the cayley tables for both groups but I still did not manage.","['group-theory', 'group-isomorphism', 'discrete-mathematics']"
3970629,Sums of integer powers similar to Prouhet–Tarry–Escott problem,"Recall Prouhet–Tarry–Escott problem . Its solution shows that certain sums of powers of integers can be made to vanish simultaneously if their signs are chosen to follow the Thue–Morse sequence , e.g. $$\sum_{k=0}^{2^4-1}(-1)^{\sigma_2(k)}\,k^n=0\quad\text{for}\;n<4,\quad\text{i.e.}\\
\small
\begin{array}{l}
 0^1+3^1+5^1+6^1+9^1+10^1+12^1+15^1=1^1+2^1+4^1+7^1+8^1+11^1+13^1+14^1 \\
 0^2+3^2+5^2+6^2+9^2+10^2+12^2+15^2=1^2+2^2+4^2+7^2+8^2+11^2+13^2+14^2 \\
 0^3+3^3+5^3+6^3+9^3+10^3+12^3+15^3=1^3+2^3+4^3+7^3+8^3+11^3+13^3+14^3, \\
\end{array}$$ where $\sigma_2(k)$ is the sum of digits of $k$ in base-2 . I am interested in sums of powers of a similar form, but with larger exponents (such that the sum does not vanish anymore). I was able to make a few conjectures: $$\begin{align}
&\sum _{k=0}^{2^n-1} (-1)^{\sigma _2(k)}\, k^{n+2}\stackrel{\color{gray}?}=\frac{2^{\binom{n}{2}}}{36}\, (-1)^n\, \left(2^n-1\right)\, \left(5\times2^n-4\right)\, (n+2)!\\
\\
&\sum _{k=0}^{2^n-1} (-1)^{\sigma _2(k)}\,k^{n+3}\stackrel{\color{gray}?}=\frac{2^{\binom{n}{2}}}{72}\,(-1)^n \,\left(2^n-1\right)^2\,\left(2\times2^n-1\right)\,(n+3)!\\
\\
&\small\sum _{k=0}^{2^n-1} (-1)^{\sigma_2(k)}\,k^{n+4}\stackrel{\color{gray}?}=\frac{2^{\binom{n}{2}}}{32400}\,(-1)^n\,\left(2^n-1\right)\,\left(143\!\times\! 8^n-307\!\times\!4^n+193\!\times\! 2^n-32\right)\,(n+4)!\end{align}$$ This pattern seems to continue within increasingly complicated polynomials of $2^n$ on the right-hand side. Can you suggest an approach to prove these, and to find a more general formula for an arbitrary exponent $k^{n+p}$ ?","['summation', 'conjectures', 'number-theory', 'combinatorics', 'sequences-and-series']"
3970641,Measuring the Shannon entropy of an ordered sequence,"I have 927 unique sequences of the numbers 1, 2 and 3, all of which sum to 12 and represent every possible one-octave scale on the piano, with the numbers representing the intervals between notes in half-steps (i.e., adjacent keys). For example, the Major Scale is { 2,2,1,2,2,2,1 }, while the hexatonic (6-note) Blues Scale is { 3, 2, 1, 1, 3, 2 }. It can help mentally to add a zero at the beginning to represent the root note. I'm trying to decide how to categorize them, and believe Shannon entropy is a natural place to begin, with one problem: The default Shannon Equation returns the same figure agnostic of the order of the sequence (as we would expect), whereas this is a case where the order is supremely relevant. (Music theory and information theory have a lot in common, though this appears to be largely unexplored.) Let's take a simple example: Both of these are valid scales, though neither has a name, to my knowledge: { 1,2,1,2,1,2,1,2 }
{ 2,2,1,2,1,1,1,2 } Since there are equal numbers of 1s and 2s in each set, we don't need a calculator to see that the Shannon Entropy for each is 4: $$-\sum_{i=1}^8 \frac{1}{2} \log_{2}\frac{1}{2}$$ However, I believe--I may be very wrong here--that there is significantly more information contained in the second sequence, given that the first can be communicated as ""{1,2}, four times"" while the second is considerably more arbitrary. (I believe this is debate in bioinformatics, where one can locate long spans of simple repeating sequences of nucleotides that some consider ""junk DNA,"" though others dispute that adjective.) How does one account for order when measuring surprisal? If I were to take, say, The Great Gatsby and sort the ~261,000 characters (as in letters, etc., not fictional people!) in ASCII order, I don't think it would contain the same amount of information as the original text. One strategy I tried was a rolling measure of probability, where the algorithm is initially unaware of the total frequency of each number but accumulates the odds as it goes. (I suppose this is like measuring the accumulating surprisal of a die you cannot see and don't know how many sides it has.) This did not produce very intuitive or useful results. Another thought I had was to divide each sequence into ""words"" that are repeating sub-sequences of at least two digits, then measure the entropy of each word and ... I'm not sure what to do with them. A sum of $H[{1,2}]$ four times still adds to 4. I'm a bit out of my depth here both in reducing sequences to the most efficient subsequences and knowing what to do with them. I've read Shannon's 1948 paper twice, including the discussion of the relative odds of letters in a given language, which seems relevant but is, in fact, not useful in this case, where every possible ordered combination is present and the intervals are added independently of those preceding them, with the edge case that they cannot exceed a sum of 12. Which is all to say, how does one quantify the entropy of an ordered sequence, when the order is of extreme relevance but each item is independent of the others? Below I'll include how I generated the 927 sequences for anyone interested, but it's ancillary to the question, I think. *** First, I wrote a simple recursive algorithm that begins with an empty set and calls itself three times after adding 1, 2 or 3, terminating when the sum is 12 and tossing any that go over. Happy to provide code or pseudo-code, but I think it's intuitive. To check myself, I generated the all the combinations of [1,2,3] that add to 12--there are 19--using a Coin-Change algorithm , and then calculated the unique, distinct permutations of each of them (treating identical digits as indistinguishable). The sum of the permutations is also 927, which range from 1 for the sequence of twelve 1s (the Chromatic Scale) or four 3s (a sparse diminished scale) to 140 possible scales for the intervals { 1, 1, 1, 2, 2, 2, 3 }, which almost subsumes the Harmonic Minor Scale. One more thought Regarding the above example of four 1s and four 2s: If I was flipping an unbiased coin 12 times and coding Heads as ""1"" and Tails as ""2"", I would be more surprised, in a general sense of the word, to get alternating results than to get the second sequence with small clusters. So it's possible that ""surprisal"" is the wrong frame of mind here versus information.","['entropy', 'biology', 'information-theory', 'combinatorics', 'music-theory']"
3970707,Find the number of integer non-negative solutions to $3 x_1+5 x_2+x_3+x_4=10.$,"Find the number of integer non-negative solutions to $$3 x_1+5 x_2+x_3+x_4=10.$$ My proposed solution: First find the possible values for the pairs $(x_1,x_2)$ which are allowed: $(0,0),(0,1),(0,2),(1,0),(1,1),(2,0),(3,0)$ , and count solutions for $x_3, x_4$ in each case. Counting for each case is, respectively: 11,6,1,8,3,5,2. They add to a total of 36 solutions. My problems: Given solution in a book is 30 and I would like to know whether my solution is indeed wrong. Is there a more elegant way to solve this problem and similar problems? I believe my approach is kind of brute force.","['contest-math', 'solution-verification', 'combinatorics', 'integer-partitions']"
3970710,Confusion on the definition of accumulation points,"I've been trying to learn a bit about limits of sequences and accumulation points to get a better intuition behind the workings for calculus and I got confused on the definitions of limits,limit points and accumulation points of sequences and sets. My first question is a limit of a sequence the same as the accumulation point and is that the same as the limit point i looked online and its all very vague.
My second confusion is that is the limit of a sequence the same as the limit of a set if not is there some proof or intuitive explanation as to why not?. I know this is probably a very simple and probably trivial concept for all of you on here but its confused me a lot.
Thanks in advance","['limits', 'calculus', 'sequences-and-series', 'real-analysis']"
3970712,Solve the system of equations for $\sqrt{xy}$,"$$x + y\sqrt{x} = \frac{95}{8}$$ $$y + x\sqrt{y} = \frac{93}{8}$$ $$x, y \in \mathbb{R}$$ I can't solve this system of equations I got asked in a group. I added and substracted them to find the following equations but I don't really know what to do with them. $$\left(\sqrt{x}-\sqrt{y}\right)\left(\sqrt{x}+\sqrt{y}-\sqrt{xy}\right) = \frac{1}{4}$$ $$\left(\sqrt{x}+\sqrt{y}\right)\left(\sqrt{x}+\sqrt{y}+\sqrt{xy}\right) - 2\sqrt{xy} = \frac{47}{2}$$ This is all I have. I checked the answer using Wolframalpha and it was $\frac{15}{4}$ for $\sqrt{xy}$ . I have been looking for this question's solution but didn't find any related question/solution on Stack Exchange or Web. Sorry if it is duplicate, thank you in advance.","['systems-of-equations', 'linear-algebra']"
3970724,Vector normal to the gradient,"I know that the gradient points in the direction of the maximum rate of increase, with the maximum rate given by its magnitude.  Similarly, the maximum rate of decrease is given by the negative of its magnitude.  Does a vector normal to the gradient point in the direction of zero increase?  I.e., if I were standing on a level curve and traveled in a direction normal to the gradient at that point, will I land on a level curve with the same value as when I began?","['multivariable-calculus', 'derivatives']"
3970743,All possible tournament pairing such that you get no pair from the same group.,"I thought about this problem for a while, but I have no idea how to approach it. You have 8 groups, with 4 of the groups having 6 people and rest of the 4 groups having 3 people. So you have 36 people in total. Now we want to pick 18 pairs from 36 people to form a tournament. I believe there are $\frac{36!}{18! 2^{18}}$ (I don't really understand how to get this number though) as can be seen here: Number of ways you can form pairs with a group of people when certain people cannot be paired with each other. Now, I want pairings to be such that no people from the same group play against each other. How many possible pairings exist under this constraint? This is a very similar question: UEFA Champions League quarterfinals 2018 draw - pairing of same country teams However, I don't think the approach there would work. Thanks! EDIT: The most general form of this question would be to let the number of groups and number of people in each group vary, and to find the formula for this. I am now wondering if such a formula exists. So for example, what if you have 11 groups, and 4 of them have 5 people, 5 of them have 4 people, and 2 of them have 12 people. EDIT: I ran some simulation, I keep getting about 0.11 instead of Henry's 0.245. Here is my code. team_list = c(rep(1:6, 4), rep(1:3,4))

for (i in 1:6){
  team_list[i] = paste(""A"", team_list[i], sep = """")
}

for (i in 7:12){
  team_list[i] = paste(""B"", team_list[i], sep = """")
}

for (i in 13:18){
  team_list[i] = paste(""C"", team_list[i], sep = """")
}

for (i in 19:24){
  team_list[i] = paste(""D"", team_list[i], sep = """")
}

for (i in 25:27){
  team_list[i] = paste(""E"", team_list[i], sep = """")
}

for (i in 28:30){
  team_list[i] = paste(""F"", team_list[i], sep = """")
}

for (i in 31:33){
  team_list[i] = paste(""G"", team_list[i], sep = """")
}

for (i in 34:36){
  team_list[i] = paste(""H"", team_list[i], sep = """")
}



check_pair = function(x){
  for (i in seq(from = 1, to = length(x), by = 2)){
    if (substr(x[i],1,1) == substr(x[i+1],1,1)){
      return (TRUE)
    }
  }
  return (FALSE)
}


count = 0

for (i in 1:10000){
  x = sample(team_list, size = 36)
  if (!check_pair(x)){
    count = count+1
  }
}

count/10000





team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""C2"")

pair_combn <- function(x) {
  Filter(function(e) all(unique(x) %in% unlist(e)),
         combn(as.data.frame(combn(x, 2)),
               length(x)/2, simplify = FALSE))
}

pair_combn(team_list)


check_pair = function(x){
  for (i in seq(from = 1, to = length(x), by = 2)){
    if (substr(x[i],1,1) == substr(x[i+1],1,1)){
      return (TRUE)
    }
  }
  return (FALSE)
}


count = 0

for (i in 1:10000){
  x = sample(team_list, size = 6)
  if (!check_pair(x)){
    count = count+1
  }
}

count/10000

team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""D1"")

pair_combn <- function(x) {
  Filter(function(e) all(unique(x) %in% unlist(e)),
         combn(as.data.frame(combn(x, 2)),
               length(x)/2, simplify = FALSE))
}

pair_combn(team_list)


check_pair = function(x){
  for (i in seq(from = 1, to = length(x), by = 2)){
    if (substr(x[i],1,1) == substr(x[i+1],1,1)){
      return (TRUE)
    }
  }
  return (FALSE)
}


count = 0

for (i in 1:10000){
  x = sample(team_list, size = 6)
  if (!check_pair(x)){
    count = count+1
  }
}

count/10000


z = pair_combn(team_list)




team_list = c(""A1"", ""A2"", ""B1"", ""B2"", ""C1"", ""D1"", ""E1"", ""E2"")

pair_combn <- function(x) {
  Filter(function(e) all(unique(x) %in% unlist(e)),
         combn(as.data.frame(combn(x, 2)),
               length(x)/2, simplify = FALSE))
}

combination = pair_combn(team_list)


check_pair = function(x){
  for (i in seq(from = 1, to = length(x), by = 2)){
    if (substr(x[i],1,1) == substr(x[i+1],1,1)){
      return (TRUE)
    }
  }
  return (FALSE)
}

count = 0
for (i in 1:105){
  to_check = as.vector(unlist(combination[[i]]))
  if (!check_pair(to_check)){
    count = count+1
  }
}

print (count)


count = 0

for (i in 1:10000){
  x = sample(team_list, size = 8)
  if (!check_pair(x)){
    count = count+1
  }
}

count/10000



team_list = c(""A1"", ""A2"", ""A3"", ""A4"", ""B1"", ""B2"", ""C1"", ""C2"")

pair_combn <- function(x) {
  Filter(function(e) all(unique(x) %in% unlist(e)),
         combn(as.data.frame(combn(x, 2)),
               length(x)/2, simplify = FALSE))
}

combination = pair_combn(team_list)


check_pair = function(x){
  for (i in seq(from = 1, to = length(x), by = 2)){
    if (substr(x[i],1,1) == substr(x[i+1],1,1)){
      return (TRUE)
    }
  }
  return (FALSE)
}

count = 0
for (i in 1:105){
  to_check = as.vector(unlist(combination[[i]]))
  if (!check_pair(to_check)){
    count = count+1
  }
}

print (count)


count = 0

for (i in 1:10000){
  x = sample(team_list, size = 8)
  if (!check_pair(x)){
    count = count+1
  }
}

count/10000



team_list = c(""A1"", ""A2"", ""A3"", ""B1"", ""B2"", ""B3"", ""C1"", ""C2"")

pair_combn <- function(x) {
  Filter(function(e) all(unique(x) %in% unlist(e)),
         combn(as.data.frame(combn(x, 2)),
               length(x)/2, simplify = FALSE))
}

combination = pair_combn(team_list)


check_pair = function(x){
  for (i in seq(from = 1, to = length(x), by = 2)){
    if (substr(x[i],1,1) == substr(x[i+1],1,1)){
      return (TRUE)
    }
  }
  return (FALSE)
}

count = 0
for (i in 1:105){
  to_check = as.vector(unlist(combination[[i]]))
  if (!check_pair(to_check)){
    count = count+1
  }
}

print (count)


count = 0

for (i in 1:10000){
  x = sample(team_list, size = 8)
  if (!check_pair(x)){
    count = count+1
  }
}

count/10000 And some results I get: For 3 group of 4 people, 2 people, and 2 people, I get 24 out of 105 For 3 group of 3 people, 3 people and 2 people, I get 36 out of 105 For 5 group of 2 people, 2 people, 2 people, 1 person and 1 person, I get 68 out of 105.","['combinations', 'combinatorics', 'probability']"
3970780,Find this limit $\lim_{n\rightarrow \infty} \frac{n}{n+1}-\frac{n+1}{n}$. Am I correct?,"I've found this limit by this way. Am I correct? Find this limit: $\lim_{n\rightarrow \infty}\left(\frac{n}{n+1}-\frac{n+1}{n}\right)$ Let's see that: \begin{align}
\frac{n}{n+1}-\frac{n+1}{n}&=\frac{n^2-(n+1)^2}{(n+1)(n)}\\&=\frac{n^2-n^2-2n-1}{n^2+n}\\&=\frac{-2n-1}{n^2+n}\\&=\frac{-\frac{2}{n}-1}{1+\frac{1}{n}} 
\end{align} Así, \begin{align}
\lim_{n \rightarrow \infty}\left ( \frac{n}{n+1}-\frac{n+1}{n} \right ) &=\lim_{n \rightarrow \infty} \frac{-\frac{2}{n}-1}{1+\frac{1}{n}}=\frac{-1}{1}=-1 
\end{align} Am I correct? Is there another way to find it? I would really be very grateful if you can help me with this. Thank you very much!","['limits', 'calculus', 'sequences-and-series']"
3970799,ELMO Shortlist 2012/G3: Geometry involved angle bisector and right angle,"Given $\triangle ABC$ with $I$ as its incenter, draw $ID$ perpendicular to $BC$ and $IP$ perpendicular to $AD$ . Prove that $\angle BPD=\angle DPC$ It seems like just a normal classic geometry with incenter and some perpendicular, but still I wasn't able to solve it. The solution of this problem involving Pole/Polar or sth like that, that I dun study or know anything about it. Here is the link to the problem and solution I'm a highschool student who like to solve geometry and I want to solve it using just normal method without involving higher theorems and here is my approach: Let $E,F$ be another touching point on $AB$ and $AC$ respectively. Since $IP\perp AD$ it suggests that $A,E,I,P,F$ lie on the same circle with diameter $AI$ Let $J$ be the midpoint of $AI$ so $IJ\perp EF$ Denote $M,N$ be the point where $PC, PB$ meet $(J)$ So $\angle BPD=\angle DPC$ if and only if $AM=AN$ or $EF\parallel MN$ or $EM=FN$ . Another way around is to prove that \begin{equation}
\frac{BD}{DC}=\frac{BP}{PC}
\end{equation} Unfortunately, that's all about that I can do. Please help To simplify the pic I only take the important part because if I take point $C$ too, the pic looks ugly","['contest-math', 'geometry']"
3970809,"If we know the congruence of the apex and the base of two isosceles, are both congruent triangles? (help with the proof)","Well, there are general criteria for congruence of triangles: SAS (Side-Angle-Side) ASA (Angle-Side-Angle) SSS (Side-Side-Side) SAA (Side-Angle-Angle) And there are some criteria for specific triangles: SSA (Side-Side-Angle) The side in front of the angle doesn't have to be minor of the adjacent one HC (Hypotenuse-Cathetus) In a right triangle HA (Hypotenuse-Angle) In a right triangle And my question is about one case that I know is true in Euclidean geometry (which I would call AB—Apex-Base—): If two isosceles triangles have in common the apex and the base, both are congruent It's ""obvious"" but the proof is not that obvious. Here's my attempt. Proof Let △ABC and △A'B'C' be isosceles triangles like the next figure Now, if AB = A'B' both triangles are congruent by SAS, but suppose that's not the case. Without loss of generality assume that AB<A'B', thus it's possible to mark a point D' in A'B' such that A'D' = AB, likewise it's possible to mark a point E' in A'C' such that A'E' = AC. Join the points D'E' to form the △A'D'E' ≅ △ABC by SAS. Then we must conclude that D'E' = B'C', but this is a contradiction since D'E'<B'C', so assuming  AB ≠ A'B' is absurd, hence AB = A'B' which derives △ABC ≅ △A'B'C' Q.E.D. That's what I did, but I feel that the contradiction is not fully handled, especially because I cannot find another argument but visual that D'E' < B'C'.
As I mentioned before, I know this is true in Euclid's (plane) geometry. I'm more interested in a proof (if exist) avoiding parallels (or equivalently the constant sum of the measures of the angles of any triangle), so that the result would be a neutral geometry like the SAA criterion ( https://www.jstor.org/stable/27960835?seq=1 ). Or I'm trying to prove a result that's not neutral geometry that in some cases D'E' =B'C'? Edit Thanks for your answers, they are very useful. But up this moment all of them depends on the parallel postulate which I try to avoid in order to find out if this is a neutral geometry result.","['triangles', 'geometry']"
3970814,Convergence of infinite products flaw in this derivation of Euler product formula?,"I am trying to write a derivation of the Euler product formula in a way that is accessible to younger students and those not mathematically trained at university. Because of this I am starting from the simplest starting point that I can, and use the simplest possible steps in the derivation. I arrive at the following which I know is wrong as it is missing the exponent $s>1$ to ensure convergence. $$ \prod_{p}\frac{1}{(1-\frac{1}{p})}=\sum_{n}\frac{1}{n} $$ My question is to ask where I am introducing the error in the following simple derivation. Step 1 Start with a familiar series, valid for $|x| < 1$ . $$ \frac{1}{(1-x)}=1+x+x^{2}+x^{3}+\ldots $$ We're interested in primes, and might be tempted to set $x$ to a prime $p$ , but we can't because $|x|$ needs to be $<1$ . Let's try $\frac{1}{p}$ which is always $<1$ . $$ \frac{1}{(1-\frac{1}{p})}=1+\frac{1}{p}+\frac{1}{p^{2}}+\frac{1}{p^{3}}+\ldots $$ This series converges to a finite value. Step 2 Let's now pick two different primes $p_1$ and $p_2$ , and multiply the analogous series for each. $$ \frac{1}{(1-\frac{1}{p_{1}})}\cdot\frac{1}{(1-\frac{1}{p_{2}})}=\left(1+\frac{1}{p_{1}}+\frac{1}{p_{1}^{2}}+\ldots\right)\cdot\left(1+\frac{1}{p_{2}}+\frac{1}{p_{2}^{2}}+\ldots\right) $$ I don't think there is a problem here. We are multiplying two infinite series, each one known to converge to a finite value. Am I wrong? Step 3 Now we extend from two primes, $p_1$ and $p_2$ , to all primes $p_i$ . $$ \prod_{p_{i}}\frac{1}{(1-\frac{1}{p_{i}})}=\prod_{p_{i}}\left(1+\frac{1}{p_{i}}+\frac{1}{p_{i}^{2}}+\ldots\right) $$ I think this is the flaw in my derivation. We have an infinite product of finite values. Each factor $\frac{1}{(1-\frac{1}{p_{i}})}$ is $>1$ so the infinite product looks like it might not converge. However each factor tends to $\rightarrow 1$ as $i \rightarrow \infty$ . This suggests the infinite product is ok. Am I wrong? Step 4 If we multiply out those brackets, each of the form $\left(1+\frac{1}{p_{i}}+\frac{1}{p_{i}^{2}}+\ldots\right)$ , we will obtain terms which are all combinations of primes, in all the combinations of powers for each prime. $$ \prod_{p_{i}}\left(1+\frac{1}{p_{i}}+\frac{1}{p_{i}^{2}}+\ldots\right) = 1 + \frac{1}{p_1} + \frac{1}{p_2} + \ldots + \frac{1}{p_1 p_2} + \frac{1}{p_1 p_3} + \ldots + \frac{1}{p_1^2} + \frac{1}{p_2^2} + \ldots  $$ Importantly, each combination occurs only once. Step 5 The fundamental theorem of arithmetic tells us that each integer can be written as a unique product of primes. This means that each integer is represented in the terms we arrived at in the previous step. Because each combination of primes occurs only once, each integer is represented only once. That leads us to the Euler product formula. $$ \boxed{\prod_{p}\frac{1}{(1-\frac{1}{p})}=\sum_{n}\frac{1}{n}} $$ Discussion If my suspicion is correct that the error is in the infinite product because it doesn't converge, how does changing $p$ for $p^s$ for $s>1$ help?","['number-theory', 'euler-product', 'elementary-number-theory', 'prime-numbers']"
3970817,Formally assigning probabilities to sample spaces that change over time,"As mentioned in the title, how are probabilities assigned to changing sample spaces? To make my question more clear, take the classic Polya's Urn Scheme, where we have an urn containing $b$ black balls and $r$ red balls. After each draw of a ball from the urn, the ball is replaced with $c$ more balls of the same color back into the urn. Regarding the first draw, I'm clear..since each ball is equally likely to be picked, a uniform probability space $(\Omega, \mathcal{F}, \mathbb{P})$ does the job once $\Omega$ is taken to be the set of all balls in the urn. After the first draw, or any draw for that matter, the set of balls in the urn is no longer the same as $\Omega$ . But any solution to this problem that I've seen does not mention this..and the answer is computed directly. Of course, its intuitively clear what's going on..but is there a more formal way of depicting this? Do we move to a new sample space $(\Omega', \mathcal{F'}, \mathbb{P}')$ after each draw? What is the general way of working with sample spaces that change over time / after the occurrence of some events?","['probability-distributions', 'probability-theory', 'probability']"
3970821,How to do this counting problem?,"I know that the pigeonhole principle is to be applied here but I can’t see yet how. On a certain planet in the solar system Tau Cetus, more than half the surface of the planet is dry land. Show that the Tau Cetans can dig a tunnel straight through the centre of the planet, beginning and ending on dry land.","['pigeonhole-principle', 'discrete-mathematics']"
3970860,Understanding a proof regarding the relationship between rational generating functions and linear recurrence relations,"I'm trying to understand this lemma from my course notes: It's my understanding that a linear recurrence relation is one of the form $x_n = p(n, x_{n - 1}, \dots, x_{n - k}) = q(n) + b_1 x_{n - 1} + b_2 x_{n - 2} + \dots + b_k x_{n - k}$ for $n \geq k$ . This recurrence relation is homogeneous if $q = 0$ . I find the above proof very terse, so below I give my understanding along with comments/questions where I don't understand things. First part: Rational generating function defines a homogeneous linear recurrence relation Start with $f(x) = a_0 + a_1 x + \dots = \frac{g(x)}{h(x)}$ where $g(x) = b_l x^l + \dots + b_0$ and $h(x) = c_k x^k + \dots + c_0$ . Bring the denominator over to the left so you get $(c_k x^k + \dots + c_i x_i) (a_0 + a_1 x + \dots ) = b_l x^l + \dots + b_0$ . We want to set up something like $a_j = \alpha_1 a_{j - 1} + \dots + \alpha_n a_{j - n}$ . Because we are trying to set up a linear homogeneous recurrence relation, we clearly need to set up something that will work for all $j > \text{[something]}$ , but it's not clear at this stage what that something should be. Clearly based on the product $(c_k x^k + \dots + c_i x_i) (a_0 + a_1 x + \dots )$ we are going to get products of $a$ coefficients with $c$ coefficients. This suggests that we might have to divide an expression involving $a_j c_{\text{something}}$ by $c_{\text{something}}$ in order to isolate $a_j$ . The only two $c_{\text{something}}$ s that we know are not equal to zero are $c_i$ and $c_k$ (which may or may not be distinct). If we try to work with $c_k$ then we would be looking at the coefficient for the $x^{k + j}$ term, which would be something like $c_k a_j + c_{k - 1} a_{j + 1} + \dots + c_i a_{j + (k - i + 1)}$ . This doesn't look like the type of expression we're looking for ( $a_j = \alpha_1 a_{j - 1} + \dots + \alpha_n a_{j - n}$ ) so we'll try using $c_i$ . If we use $c_i$ then we are looking at the coefficient for the $x^{i + j}$ term, which would be something like $c_i a_j + c_{i + 1} a_{j - 1} + \dots + c_k a_{j - (k - i)}$ . Comparing both sides of $(c_k x^k + \dots + c_i x_i) (a_0 + a_1 x + \dots ) = b_l x^l + \dots + b_0$ , we see that $c_i a_j + c_{i + 1} a_{j - 1} + \dots + c_k a_{j - (k - i)} = b_{i + j}$ . We want $b_{i + j} = 0$ so that we can just divide by $c_i$ and move terms over and get our desired recurrence relation. This implies a restriction $i + j > l$ . We also see that we need $j - (k - i) \geq 0$ , so our restrictions on $j$ are that $j > l - i$ and $j \geq k - i$ . Given this, we can divide both sides of $c_i a_j + c_{i + 1} a_{j - 1} + \dots + c_k a_{j - (k - i)} = 0$ by $c_i$ and we get that $a_j = - \frac{1}{c_i} ( c_{i + 1} a_{j - 1} + \dots + c_k a_{j - (k - i)})$ , which is our desired recurrence relation. Why is my bound for $j$ different from that given in the proof ( $j > \max \{ k, l \}$ )? Second part: linear recurrence relation (having function $q(n)$ that has its own rational generating function) has a rational generating function This part doesn't make much sense to me at all. I see that $q$ essentially defines a sequence starting at index $k$ , as opposed to zero, so I can see that $q$ could have an associated generating function. However the generating function $g(x)$ given for $q$ is not even a polynomial, much less rational. Is the assumption that $g(x)$ can be expressed in a rational form? I guess $f(x)$ is supposed to be the generating function for the linear recurrence relation? I suppose a linear recurrence relation defines a sequence so there is guaranteed to be an associated generating function. We define the function $h$ in such a way that all its coefficients beyond $k - 1$ are zero. Since $g(x)$ is presumed to be rational, we can write $g(x) = \frac{r(x)}{s(x)}$ where $r$ and $s$ are polynomials, therefore to be more thorough we can write $f(x) = \frac{h(x)s(x) + r(x)}{s(x)(1 - b_1 x - b_2 x^2 - \dots - b_k x^k)}$ . Does what I'm saying about this second part make sense? I am trying to talk myself through it. What is the intuition behind the definition of $h(x)$ ? I guess we're trying to make some kind of finite polynomial and that is the definition that works? I appreciate any help.","['proof-explanation', 'recurrence-relations', 'discrete-mathematics', 'generating-functions']"
3970938,Does homotopy equivalence to a subspace imply (weak) deformation retract?,"Here is a nearly same question, but with a slight difference in interpretation. We use the definition of wikipedia , which is different from that of Hatcher or Munkres (where deformation retract refers to strong deformation retract on wikipedia). My question is : Suppose $X$ is a path-connected topological space, and $A$ is its subspace. If $X$ and $A$ are homotopic equivalent, is it true that $A$ is a (weak) deformation retract of $X$ ? Both Hatcher and Munkres have provided counterexamples for the case of strong deformation retract, but not the one above. Please help.","['general-topology', 'algebraic-topology']"
3970959,Bounds on $S = \frac{1}{1001} + \frac{1}{1002}+ \frac{1}{1003}+\dots+\frac{1}{3001}$,"$S =  \frac{1}{1001} +   \frac{1}{1002}+ \frac{1}{1003}+ \dots+\frac{1}{3001}$ . Prove that $\dfrac{29}{27}<S<\dfrac{7}{6}$ . My Attempt: $S<\dfrac{500}{1000} +   \dfrac{500}{1500}+ \dfrac{500}{2000}+ \dfrac{500}{2500}+\dfrac{1}{3000} =\dfrac{3851}{3000}$ (Taking 250 terms together involves many fractions and is difficult to calculate by hand.) Using AM-HM inequality gave me $S > 1$ , but the bounds are weak. Prove that $1<\frac{1}{1001}+\frac{1}{1002}+\frac{1}{1003}+\dots+\frac{1}{3001}<\frac43$ Inequality with sum of inverses of consecutive numbers The answers to these questions are nice, but the bounds are weak. Any help without calculus and without calculations involving calculators would be appreciated. (I encountered this question when I was preparing for a contest which neither allows calculators nor calculus(Only high-school mathematics.))","['contest-math', 'algebra-precalculus', 'summation', 'inequality']"
3971075,Noah and his ark - inequalities,"By spending an emerald, Noah turns a swan into a frog or a duck into a lizard, and by spending a ruby, he turns a swan into a duck or a frog into a lizard. Today he spent 20 emeralds and 23 rubies, and the number of frogs increased by 5. How and how much can the number of ducks change? (Give all possible results and explain why). I found this in a Facebook group. Let's name $S_0, F_0, D_0, L_0$ the initial number of each kind and $S_e, F_e, D_e, L_e$ their numbers after the exchange with the use of emeralds.
Clearly we have, for 1 emerald, $S_0-S_n = F_n-F_0$ , therefore for $x$ emeralds, $x(S_0-S_n) = x(F_n-F_0)$ . Also for $y$ emeralds, $y(D_0-D_n) = y(L_n-L_0)$ . We have $x+y=20$ . We get similar equations for the rubies: $z(S_0-S_m) = z(D_m-D_0)$ . $w(F_0-F_m) = w(L_m-L_0)$ . $z+w=23$ . The difference in number of frogs after all transformations is 5 but I don't know how to take into account the consecutive transformations; it is getting very complicated.","['word-problem', 'algebra-precalculus']"
3971096,Double integration using a change of variables for $\iint_D\sqrt{x}\ dx\ dy $,"I need to calculate this double integral using change of variables $$\iint_D\sqrt{x}\ dx\ dy $$ with $D=\{(x,y) \mid x^2+y^2 < x\}$ . I thought of putting $x=r\cos\theta$ and $y=r\sin\theta$ . So $x^2+y^2<x$ will become $r<\cos\theta$ (should I suppose here that $r \ne 0$ ?). I'll just rewrite the integral as $$\int_0^{2\pi}\int_0^{\cos\theta}r\sqrt{r\cos\theta}$$ which is double with a bit of calculation. I would be very thankful if someone can tell me if my method is right. If not, how can I solve it? Thank you very much.","['integration', 'multivariable-calculus', 'change-of-variable']"
3971197,Let $T =\{X\in P(\mathbb{Q}) | X\cup \mathbb{N} = \mathbb{Q} \}$ the cardinality of $T$ is $\aleph$?,"Let $T =\{X\in P(\mathbb{Q}) | X\cup \mathbb{N} = \mathbb{Q} \}$ the cardinality  of $T$ is $\aleph$ ? prove attempt we know that $X\in P(\mathbb{Q})$ so, $X\cup \mathbb{N} = \mathbb{Q}$ create an infinity numbers","['elementary-set-theory', 'cardinals', 'logic']"
3971285,Are two graphs isomorphic?,"Are the two graphs isomorphic? $$G_1=\begin{bmatrix}
a & b & c & d & e & f \\ 
b & a & a & c & d & a \\
c & c & b & e & f & d \\
f &   & d & f &   & e 
\end{bmatrix}\  
\quad\quad
G_2=\begin{bmatrix}
u & v & w & x & y & z \\ 
v & u & v & u & x & u \\
x & w & x & w & z & w \\
z &   & z & y &   & y 
\end{bmatrix}$$ $a,b,c$ creates a triangle in $G_1$ , but no triangle is created in $G_2$ . Is that enough to claim that they are not isomorphic?","['graph-theory', 'graph-isomorphism', 'discrete-mathematics']"
3971294,What does commutativity of partial derivatives imply about geometry about the surface of a function?,"Suppose we have a function $f(x,y)$ and it has the property that: $$  \partial_x \partial_y f(x,y) = \partial_y \partial_x f(x,y)$$ What does this imply about the geometry of the surface described the function?",['multivariable-calculus']
3971313,Combinatorial proof of $\sum_{k=0}^n \binom{n}k \binom{n-k}{m-k} = 2^m \binom{n}m$,"Combinatorial proof of: $$\sum_{k=0}^n \binom{n}k \binom{n-k}{m-k} = 2^m \binom{n}m$$ My answer is: number of ways to form 2 committees of different members from a group of n people. For the first method, choose k members of the first committee from n people, and form the other committee with (m-k) members from the remaining (n-k) people, since k members are already in the first committee. The product is the number of ways. For the second method, choose m members who will be part of the two committees from n people. The number of ways to form committees from m people is the subset of m members, which is $2^m$ . The product is the number of ways. Did I get some things right?","['combinatorics', 'combinatorial-proofs']"
3971317,What is the difference between local coordinates and standard coodinates?,"I am reading ""An introduction to Manifolds"" by Loring Tu. There it is written that we denote the standard coordinates in $R^n$ by $r_1,r_2,....r_n$ . If $(U,\phi:U\to R^n)$ is a chart of a manifold, we let $x^i=r^i\circ\phi$ to be the ith component of $\phi$ and write $\phi=(x^1,...x^n)$ and $(U,\phi)=(U,x^1,...x^n)$ . My question is why they've used $r_1,r_2,....r_n$ and $(x^1,...x^n)$ separately? And what does the ith component of $\phi$ mean? And what is the difference between local coordinates and standard coordinates ? I am also attaching the screenshot where this is written.","['smooth-manifolds', 'multilinear-algebra', 'functions', 'differential-topology', 'differential-geometry']"
3971339,Lie subgroup VS Closed Lie subgroup,"Let $H$ and $G$ be Lie groups, one has, by definition, $H$ is a Lie subgroup of $G$ if exists a smooth injective homomorphism $f:H\longrightarrow G$ . This is automatically an immersion, but it is not an embedding; it is, instead, an embedding if $H$ is closed. If i consider the case in which $f$ is an inclusion map, i have that the Lie algebra of $H$ is a Lie sub-algebra of the Lie algebra of $G$ and it is characterized by the exponential map of $G$ (this due to naturality of the exponential map). What i gain if $H$ is closed? The only thing i found is that there is only one differentiable structure that makes $H$ a Lie group and that this is the one that comes from $G$ (a sort of universal property). Can someone please help me with examples to understand why this is so important? Is there some other property i have missed that can help me to go inside the conceptual difference?","['submanifold', 'soft-question', 'lie-groups', 'differential-geometry']"
3971378,"Can a set $S$ of subsets of $\mathbb{N}$ such that either $P \subset Q$ or $Q \subset P$ for all $P,Q \in S$ be uncountable? [duplicate]","This question already has an answer here : Uncountable chain of subsets of $\mathbb N$ [duplicate] (1 answer) Closed 3 years ago . I've tried a bunch of different approaches to this question (and would particularly appreciate some hints that don't give the whole thing away immediatel y). I've noticed that if $S$ contains some finite subsets, then for each $n \in \mathbb{N}$ there is at most one subset of size $n$ in the collection $S$ as $S$ can't contain duplicates (in order to satisfy the given condition). Certainly if $A_i$ is a finite subset contained in $S$ of size $i$ , then $A_i \subset A_j$ if $i > j$ . I've tried considering the possibilities where there are some finite subsets in the collection $S$ , and then we can also add in infinite-size subsets that are each a superset of all of the finite subsets. However it seems rather difficult to visualise what happens when you consider infinite subsets of $\mathbb{N}$ that can't be obtained by removing finitely many elements from $\mathbb{N}$ . What are good approaches to take to figure out whether such a set can be uncountable - is there an element of construction here?",['elementary-set-theory']
3971414,Counting the number of good functions,"Hy, happy new year everyone. I have been stuck on the following problem for a while now, so I am posting it here in other to discuss it. A function $g: [[1,n]] \to [[0,n]]$ is called good if : $$\forall j \in[[1,n]] , \exists i~ \text{integer} \geq 0 , g^{i} (j)=0 $$ where $g^{i}=g\circ \dots \circ g ~~(i ~~\text{times})$ How many  such good functions  there is?","['functions', 'combinatorics']"
3971449,"Proof that $\sum_{p=0}^\infty \frac{(Ct)^p (\sqrt{p})^p}{p!} \leq Ae^{Bt^2}$ for some constants $A, B > 0$","Fix $C > 0.$ I need to prove that there are constants $A, B> 0$ (depending on $C$ ) such that $$\sum_{p=0}^\infty \frac{(Ct)^p (\sqrt{p})^p}{p!} \leq Ae^{Bt^2}$$ for every $t>0.$ Sorry for not showing any work, but I don't really know how to tackle this. Thanks.","['sequences-and-series', 'real-analysis']"
3971490,Weak convergence in Sobolev Space: does this integral converge to $0$?,"Let $\Omega$ be an open bounded domain in $\mathbb{R^N}$ and $A(x)\in L^{\infty}(\Omega)$ . Let $s\geq 1$ and $(u_n)_n$ be a sequence such that $$|u_n|^s u_n\rightharpoonup|u|^s u\quad\mbox{ in } W_0^{1,p}(\Omega).$$ If we suppose $u=0$ , it is true that $$\int_{\Omega} A(x) \nabla(|u_n|^s u_n) dx\to 0?$$ About me the answer is yes, I reasoned in this way. Since $|u_n|^s u_n\rightharpoonup|u|^s u$ in $W_0^{1, p}(\Omega)$ and $u=0$ , thus $|u_n|^s u_n\rightharpoonup 0$ in $L^p(\Omega)$ and $\nabla(|u_n|^s u_n)\rightharpoonup 0$ in $L^p(\Omega)$ . Moreover, since $1\in L^p(\Omega)$ and since $A(x)\in L^{\infty}(\Omega)$ , a constant $c\geq 0$ exists such that $$\int_{\Omega} |A(x)| \nabla(|u_n|^s u_n) dx\leq c \int_{\Omega} \nabla(|u_n|^s u_n) dx\to 0.$$ It is true or am I missing something? Could anyone please help? Thank you in advance!","['integration', 'sobolev-spaces', 'functional-analysis', 'real-analysis']"
3971555,Optimal control input for nonlinear dynamics,"This is from Chapter 1 of the book, ""Robust Nonlinear Control Design"" by Freeman and Kokotovic. Consider the system $$\dot{x} = -x^3 + u + wx,$$ where $u$ is an unconstrained input and $w$ is known to take values in the interval $[-1,1]$ . If we consider the cost functional, $$
J = \int_0^{\infty} (x^2 + u^2) dt,
$$ then the optimal feedback law that minimizes the cost functional (in the worst case) is claimed to be given by $$
u = x^3 - x - x\sqrt{x^4 -2x^2 + 2}.
$$ Question: How is the optimal feedback law obtained? Attempt #1: I tried using Pontryagin Maximum Principle, and I got the following. The Hamiltonian is given as $$
H = x^2 + u^2 + \lambda(-x^3 + u + wx).
$$ By taking derivatives with respect to $x$ and $u$ and solving them, $$
\dot{\lambda} = -\frac{\partial H}{\partial x} = -2x+ 3\lambda x^2 -\lambda wx \Rightarrow \lambda = ke^{(3x^2-w)t}+\frac{2x}{w-3x^2},
$$ $$
\frac{\partial H}{\partial u} = 0 \Rightarrow u = -\frac{\lambda}{2}.
$$ Substituting $\lambda$ in the first expression into the second expression, $$
u = -\frac{k}{2}e^{(3x^2-w)t}+\frac{2x}{w-3x^2}
$$ The initial or final conditions for the ODE in $\lambda$ are not stated so I cannot solve for $k$ , but the form of the solution that I obtained is quite different from what is given. Does anyone has any ideas or alternative approaches? Attempt #2 (added on Jan 5 2021): I also tried to work directly with the given optimal control input, $u$ and the nonlinear dynamics. Substituting $u$ into the nonlinear dynamics $\dot{x}$ and using the worst-case $w$ of $1$ gives $$
\dot{x}^2 = x^2 (x^4 - 2x^2 +2) = x^6 - 2x^4 + 2x^2
$$ Also note that we have the following expression for $u$ from the nonlinear dynamics, $$
\dot{x} = -x^3 + u + x \Rightarrow u = \dot{x} + x^3 - x 
$$ This is independent of the given optimal control input. With this expression of $u$ , if $\dot{x}$ can be assumed to be $0$ (may not be a valid assumption), then the following can be said of the cost functional, $$
\begin{aligned}
J = \int_0^{\infty} (x^2 + u^2) dt &= \int_0^{\infty} (x^2 + (\dot{x} + x^3 - x)^2) dt\\
&= \int_0^{\infty} (x^2 + x^6 - 2x^4 + x^2) dt\\
&= \int_0^{\infty} (x^6 - 2x^4 + 2x^2) dt\\
&= \int_0^{\infty} \dot{x}^2 dt = 0, 
\end{aligned}
$$ which is the minimum, since the cost functional is nonnegative.","['optimal-control', 'control-theory', 'maximum-principle', 'ordinary-differential-equations']"
3971556,"Analytic solution to $\alpha , \beta \in \mathbb{R}$ such that $\cos \alpha \cdot \sin \beta = \cos \bigl(\sin (\alpha \cdot \beta)\bigr)$?","Are there any $\alpha , \beta \in \mathbb{R}$ such that $$\cos \alpha \cdot \sin \beta = \cos \bigl(\sin (\alpha \cdot \beta)\bigr)?$$ The trivial solutions are $(\alpha, \beta)=(0, \dfrac{\pi}{2})$ . But are there more? I dont see an obvious way of tackling this problem but I keep coming back to it because it seems interesting to me (look at the graph of the solutions in desmos: https://www.desmos.com/calculator/ms8ad8cxqt ). I tried simplifying matters by trying out the case where $\alpha = \beta$ where we get that $$\cos \alpha \cdot \sin \alpha = \cos \bigl(\sin (\alpha ^{2})\bigr)$$ and using the fact that $2\sin \alpha \cos \alpha = \sin 2\alpha$ we really want to find $\alpha \in \mathbb{R}$ such that $$\dfrac{1}{2}\sin 2\alpha = \cos \bigl(\sin (\alpha ^{2}) \bigr),$$ though I have to admit that this does not make the problem easier (it seems to me at least). Has anyone looked at this problem before and have a solution or maybe some hints or suggestions on how to go further in solving the problem?","['calculus', 'trigonometry', 'recreational-mathematics']"
3971602,Web based app for differential geometry visualization,"Is there by any chance a web based app for viewing parametric curves and surfaces that arise in differential geometry to help visualization?
Thanks.","['online-resources', 'parametric', 'visualization', 'differential-geometry']"
3971606,What 'complete' means in Hilbert Space,"From my Professor's Lectures, a Hilbert Space is defined as an inner product space $\bigoplus$ complete. In the same lecture, 'complete' here means, a system $\{\varphi_j\}_{j=1}^\infty \subset V$ is complete if $\nexists g \in V\setminus\{0\} $ such that $g$ is perpendicular to $\varphi_j, \forall j $ . It is also explicitly stated that 'complete' here doesn't mean 'complete space' where all Cauchy sequences are convergent. However, in the proof for a lemma that states: An orthonormal system $\{\varphi_j\}_{j=1}^\infty \subset V$ that is complete is a basis in $V$ , We came to a point where we proved that $S_n(f) = \sum_{k=1}^{\infty} C_k\varphi_k$ is a Cauchy sequence, and then my Professor said that because we're in a Hilbert Space (complete), thus $S_n(f)$ is convergent. Is there something I'm missing here? Are both definition of 'complete' true in Hilbert Spaces?","['analysis', 'hilbert-spaces', 'linear-algebra', 'functional-analysis', 'terminology']"
3971657,What inequalities for convex sets are known since the work of Scott and Awyong?,"In 2000, Paul R. Scott and Poh Way Awyong published the paper Inequalities for Convex Sets , which nicely collates the known results relating various natural geometric functionals (diameter, area, etc.) on convex planar sets. Given that some of the inequalities in the paper cite results published just a few years prior (or in one case , 18 years later!), it seems that the state of knowledge about these inequalities is still evolving, so I would expect some new results to have arisen in the two decades since its original publication. Which new results are known relating geometric functionals on planar convex sets? In particular, I would love to find an equivalent version of this paper with up-to-date information on the current state of knowledge, existing conjectures, etc., or a reliably-updated webpage tracking the same. Two related extensions of the original paper I would be interested to see: An extension of the table on relationships between pairs of functionals giving results for additional measurements, of which there are many possible choices (though perhaps none so natural as the ones in the original paper). An analogous collection of results for convex bodies in $\mathbb{R}^3$ , though of course the number of natural functionals grows substantially and obtaining exact results is likely much harder.","['convex-geometry', 'geometric-inequalities', 'geometry', 'reference-request']"
3971666,Pure states and minimal projections,"Probably it is trivial or already discussed, but I just wanted to pose a simple question about pure states. ${\bf Lemma \; 1 \colon}$ Let $\mathcal{A}$ be a $C^*$ -algebra acting irreducibly on some Hilbert space $\mathcal{H}$ and let $\varphi(x)=(\xi | x \xi)$ be some vector state. If $\xi$ is cyclic, then $\varphi$ is pure. ${\bf Proof \colon}$ It suffices to notice that by $\overline{\mathcal{A} \xi} = \mathcal{H}$ we have that the identity representation is equivalent to the GNS representation $(\pi_\varphi, \mathcal{H}_\varphi, \xi_\varphi)$ . But such a representation is irreducible if and only if $\varphi$ is pure and the assertion follows. A related lemma is the following. ${\bf Lemma \; 2 \colon}$ Let $\mathcal{M}$ be a von Neumann algebra and let $\varphi$ be some faithful normal state in $\mathcal{M}_*^+$ . If $\varphi$ is pure then its support $s(\varphi)$ is minimal. ${\bf Proof \colon}$ We can identify $\mathcal{M}$ with its GNS representation associated to $\varphi$ , so that $\varphi(x) = (\xi | x \xi)$ . By the identity $s(\varphi) = [\mathcal{M}' \xi]$ we have that $s(\varphi)$ is a rank one projection, hence it is minimal. ${\bf Question \colon}$ Is it true that a normal state is pure if and only if its support is minimal? Clearly it could be useful that a state $\omega$ on a $C^*$ -algebra $\mathcal{A}$ is pure if and only if it is the only state vanishing on its left kernel $$ \mathcal{L}_\omega = \{ x \in \mathcal{A} \colon \omega(x^*x)=0 \} \,.$$ I think that the decomposition of a linear functional $\varphi \in \mathcal{M}^*$ in normal and singular part could be useful too. Any hint? Thank you in advance.","['von-neumann-algebras', 'functional-analysis', 'operator-algebras']"
3971690,Expected length of orbit for random permutation,"Pick a permutation $\sigma$ of $\{1,2,\dots,n\}$ uniformly at random. Let $m$ be the smallest positive integer such that $\sigma^m(1)=1$ . What is $\mathbb E[m]$ ? I know that the expected number of cycles of length $k$ for a random permutation is $\frac{1}{k}$ . This seems relevant (we want the expected length of the cycle containing $1$ ), but I'm not sure how. I manually computed the answer for some small values: $n=2$ the answer is $\frac{3}{2}$ . $n=3$ the answer is $2$ . $n=4$ the answer is $\frac{5}{2}$ . So from a (way too small) sample size, it looks like $\frac{n+1}{2}$ ?","['permutations', 'expected-value', 'probability']"
3971723,Measurability of reminder term in Taylor expansion about a point in a Brownian motion,"Suppose that $f: \mathbb R \to \mathbb R$ is twice continuously differentiable and that $\mathrm B$ is a one-dimensional Brownian motion. Using Lagrange's form of the reminder in the Taylor expansion of $f(\mathrm{B}_t(\omega))$ about $f(\mathrm{B}_s(\omega))$ we have that for each $\omega \in \Omega$ , $$
f\left(\mathrm{B}_t(\omega)\right) = f\left(\mathrm{B}_s(\omega)\right) + f'\left(\mathrm{B}_s(\omega)\right)\left(\mathrm{B}_t(\omega)- \mathrm{B}_s(\omega)\right) + \frac{1}{2}f''\left(\xi(\omega)\right)\left(\mathrm{B}_t(\omega)- \mathrm{B}_s(\omega) \right)^2
$$ for some point $$
\xi(\omega) \in \left [\mathrm{B}_s(\omega) , \mathrm{B}_t(\omega)\right].
$$ I would like to show that the map $$
\omega \mapsto \xi(\omega)
$$ is measurable. In the case of a first order Taylor expansion it is possible to prove measurability as follows [following an argument by saz https://math.stackexchange.com/questions/896394/mean-value-theorem-inside-the-expectation)]. For each $\omega$ we have from Taylor's theorem $$
f\left(\mathrm{B}_t(\omega)\right) - f\left(\mathrm{B}_s(\omega)\right) = f'\left(\xi(\omega)\right)\left(\mathrm{B}_t(\omega)- \mathrm{B}_s(\omega)\right)
$$ for some point $$
\xi(\omega) \in \left [\mathrm{B}_s(\omega) , \mathrm{B}_t(\omega)\right].
$$ Now since $$
f\left(\mathrm{B}_t(\omega)\right) - f\left(\mathrm{B}_s(\omega)\right) = \int_{\mathrm{B}_s(\omega)}^{\mathrm{B}_t(\omega)} f'(r) d r,
$$ we get that $$
\xi(\omega) = \frac{1}{\left(\mathrm{B}_t(\omega)- \mathrm{B}_s(\omega)\right)}\int_{\mathrm{B}_s(\omega)}^{\mathrm{B}_t(\omega)} f'(r) d r.
$$ Since $$
s, t \mapsto \int_s^t f'(r) d r,
$$ subtraction and division are continuous maps, and composition of continuous and measurable maps are measurable, it follows that $$
\omega \mapsto \frac{1}{\left(\mathrm{B}_t(\omega)- \mathrm{B}_s(\omega)\right)}\int_{\mathrm{B}_s(\omega)}^{\mathrm{B}_t(\omega)} f'(r) d r
$$ is measurable. Is it possible to do something similar with $\xi(\omega)$ above? Most grateful for any help provided!","['measure-theory', 'brownian-motion', 'probability-theory']"
3971734,When can nets be replaced by sequences?,"For now, my understanding is very unclear. So please help me. My first question is : Can a sequential space(e.g. a pseudometrizable space) be understood to be a space where any topological property(e.g. open, compact, and so on) can be described in terms of sequences instead of nets? If my question is unclear, then, in other words, when can sequences replace nets? I see an example in Wikipedia: In sequential spaces, a function is continuous if and only if it is sequentially continuous. So, in this case, we only need to consider sequences, not nets, to determine whether a function is continuous. I am reading so many things containing sequential spaces, uniform spaces, uniform properties to obtain a clear understanding, which is not that successful until now. All wiki or stack exchange posts seem to be perversely dodging my tantalizing question. My second question is: An bounded linear operator $T$ acting between two Banach spaces is called compact if for any bounded sequence $\{x_n\}$ , the sequence $\{Tx_n\}$ contains a convergent subsequence. In deriving this definition among many other alternative definitions, one use the fact that a metric space is totally bounded if any infinite sequence contains a Cauchy subsequence. In this case, ""a sequence"" is used instead of ""a net"", which means that it suffices to consider ""sequences"" instead of ""nets"" to determine whether a space is totally bounded. But, total boundedness is not a topological property.(Here, I came to know the concept of ""uniform property"" and ""uniform space"". But, these concepts seem to rather interrupt resolving my question.) Another example I found in Wikipedia is : A metric space is complete if and only if it is sequentially complete. Thus, in this case, one only needs to consider Cauchy sequences, instead of Cauchy nets. Here, completeness is not a topological property. But, we can replace nets with sequences. Is it also due to the fact that any metric space is a sequential space? I am guessing that the reason for a sequence to be used instead of a net is that the space concerned is a (pseudo-)metric space. I'd like to know the super-clear and simple reason or logic behind this, without being further covered by advanced concepts, which tends to make the issue more complicated. Thanks a lot.","['cauchy-sequences', 'analysis', 'real-analysis', 'functional-analysis', 'nets']"
3971786,Compact embedding of $l^p$ to $c_0$,if $c_0$ is a space of real sequences that converges to zero with sup norm. I can show that $l^{p} \hookrightarrow c_{0}$ embedding is not compact with the sup norm. But I want something more intresting than that. I want to find norm on $c_0$ such that this emdedding be compact! But until now I can't find such norm. So if one have any idea about this ....,['functional-analysis']
3971804,"If $m,n\in N$ Prove that there is such a positive integer k, such that $(\sqrt{m}+\sqrt{m+1})^n=\sqrt{k}+\sqrt{k+1}$","If $m,n\in N$ Prove that there is such a positive integer k, such that $(\sqrt{m}+\sqrt{m+1})^n=\sqrt{k}+\sqrt{k+1}$ I attempted to solve this question using binomial coefficients, saying: $(\sqrt{m}+\sqrt{m+1})^n=\sqrt{k}+\sqrt{k+1}=\sum\limits_{a=0}^n {n\choose a}*\sqrt{m}^{n-a}*\sqrt{m+1}^a$ and from here I was thinking that I had to do something with $\sqrt{m}^{n-a}$ with $\sqrt{k}$ and do something else with $\sqrt{k+1}$ and $\sqrt{m+1}^a$ . Unfortunately I couldn't think of what to do with this circumstance. I then thought of maybe taking $(\sqrt{k}+\sqrt{k+1})^2=(\sum\limits_{a=0}^n {n\choose a}*\sqrt{m}^{n-a}*\sqrt{m+1}^a)^2$ , but this immediately over-complicated the question. Could you please explain to me how to solve this question and how to solve similar questions in the future?","['number-theory', 'elementary-number-theory', 'binomial-coefficients', 'intuition', 'problem-solving']"
3971807,"What space is $\mathbb{C}^2 \setminus Z$ equivalent to, where $Z = \{(x, y) \in \mathbb{C}^2 | x = 0 \ \text{or} \ y = 0\}$?","Let $Z = \{(x, y) \in \mathbb{C}^2 | x = 0 \ \text{or} \ y = 0\}$ and let $X = \mathbb{C}^2 \setminus Z$ . What space is $X$ homotopy equivalent to? I thought that this would be homotopy equivalent to the torus $T$ by the following reasoning. First, $$
X = \{(x, y) | x \in \mathbb{C}, x \neq 0, y \in \mathbb{C}, y \neq 0\} = (\mathbb{C} \setminus \{0\}) \times (\mathbb{C}\setminus \{0\}).
$$ Now, since $\mathbb{C} \cong \mathbb{R}^2$ , each of these factors is homeomorphic to $\mathbb{R}^2\setminus \{0\}$ , which is homotopy equivalent to the circle $S^1$ . Hence $X \simeq S^1 \times S^1 = T$ . This arose in a question asking what the homology of $X$ was, and the homologies in the answer key were not that of the torus, so I am wondering if I've gone wrong somewhere here.","['general-topology', 'algebraic-topology']"
3971819,A curious infinite product of factorials,"I found the following infinite product of factorials without proof: $$\small\prod_{n=1}^\infty\frac{{(2 n)!}^{20}\,{(8 n)!}^{32}\,{(32 n)!}^2}{{n!}^4\,{(4 n)!}^{37}\,{(16 n)!}^{13}}=\\\frac{\sin ^{14}\!\frac{\pi }{8}\cdot\sin \frac{\pi }{32} \cdot\sin \frac{3 \pi
   }{32} \cdot\sin \frac{5 \pi }{32} \cdot\sin \frac{7 \pi }{32}}{\sin ^6\!\frac{\pi }{16} \cdot\sin ^6\!\frac{3\pi }{16}}\cdot \frac{2^{1283/64}\,\pi^{14}\,\Gamma^{10} \!\left(\frac{1}{8}\right) \Gamma^2\! \left(\frac{5}{32}\right) \Gamma^2 \!\left(\frac{7}{32}\right)}{\Gamma^{18}
   \!\left(\frac{5}{8}\right) \Gamma^{10} \!\left(\frac{1}{16}\right) \Gamma^{10} \!\left(\frac{3}{16}\right) \Gamma^2 \!\left(\frac{17}{32}\right)
   \Gamma^2 \!\left(\frac{19}{32}\right)}.$$ We can verify that $$\small\frac{{(2 n)!}^{20}\,{(8 n)!}^{32}\,{(32 n)!}^2}{{n!}^4\,{(4 n)!}^{37}\,{(16 n)!}^{13}}=1+\mathcal O\left(n^{-3}\right),$$ so the product indeed converges. Can you suggest how to prove its closed form on the right? Is it possible to further simplify it? Is it possible to find a simpler convergent infinite product of this form (involving only integer powers of factorials of integer multiples of $n$ )?","['conjectures', 'factorial', 'analysis', 'gamma-function', 'infinite-product']"
3971828,Can a function have a best quadratic approximation around a point but not a second derivative there?,"Taylor's Theorem says that for a function $f : \mathbb{R} \to \mathbb{R}$ which is $n$ times differentiable around a point $a$ , there exists a function $h_n(x)$ such that $$f(x) = \left(f(a) + \sum_{k=1}^n \frac{f^{(k)}(a)}{k!}(x-a)^k\right) + h_n(x)(x-a)^n$$ and $\lim_{x\to a} h_n(x) = 0$ . I understand the theorem, its motivation and meaning and its proof. A quadratic approximation around a point $a$ exists then if we can write $f(x) = f(a) + b(x-a) + c(x-a)^2 + h_2(x)(x-a)^2$ where $h_2(x) \to 0$ as $x\to a$ . Now, looking deeper into this subject, I've noticed that the existence of a linear approximation implies the differentiability at the point so that they are equivalent (the other direction being proved via Taylor Theorem or otherwise). Indeed $$ \frac{d}{dx}\big(h_1(x)(x-a)\big)|_{x=a} = \lim_{x\to a} \frac{h_1(x)(x-a)}{x-a} = \lim_{x\to a} h_1(x) = 0$$ So I've wondered whether the existence of such a quadratic approximation implies the existence of the second derivative at the point $a$ . At first it seemed true to me but then I found this example: Let $g : \mathbb{R} \to \mathbb{R}$ , $g(x) = \begin{cases} 0, & x\notin\mathbb{Q} \\ (x-1)^3, & x\in\mathbb{Q} \end{cases}$ .
It's not hard to see that this function is only continuous at $x=1$ and the derivative exists there, $g'(1) = 0$ . Then, if we define $u : \mathbb{R} \to \mathbb{R}, u(x) = \frac{g(x)}{(x-1)^2}$ and $u(1) := 0$ , we have $u(x) \to 0$ as $x\to 1$ . So, for the function $f : \mathbb{R} \to \mathbb{R}, f(x) = 5 + 2(x-1) + 3(x-1)^2 + u(x)(x-1)^2$ , the quadratic approximation around $x=1$ exists, but, since $f$ is only differentiable at that point, not around it, the second derivative there doesn't even make sense. Is there anything wrong with this or the two concepts (the existence of the second derivative at a point and the existence of a best quadratic approximation around that point) are really not equivalent?","['calculus', 'functions', 'taylor-expansion']"
3971834,Show that $|\phi(a)| \mid|G|$,"Let $G,H$ be groups and $\phi\colon G\to H$ be a one-to-one group homomorphism. Let $a\in G$ . Show that $|\phi(a)| \mid |G|$ . Not sure how to attack this proof. Do we use the First Isomorphism Theorem and Lagrange's Theorem? I am unsure if the canonical homomorphism is helpful for this proof.","['group-homomorphism', 'group-theory', 'abstract-algebra']"
3971877,"How to prove $ \prod_{n=1}^{\infty} \left(1+\frac{2}{n}\right)^{(-1)^{n+1}n} \,= \frac{\pi}{2e}$","How can I prove that $$ \prod_{n=1}^{\infty} \left(1+\frac{2}{n}\right)^{\large{(-1)^{n+1}n}} \,= \frac{\pi}{2e}$$ The result is given here (result 48). The source: Prudnikov et al. 1986, p. 757 is given, however I have been unable to find the book online. Some of my attempts include : Multiplying known infinite products for $\frac{\pi}{2}$ and $\frac{1}{e}$ $$ \frac{\pi}{2} = \frac{2\cdot2\cdot4\cdot4\cdot6\cdot6\cdots}{1\cdot3\cdot3\cdot5\cdot5\cdot7\cdots} $$ $$ \frac{1}{e} =  \frac{1}{2} \left(\frac{3}{4}\right)^{\large{\frac{1}{4}}}\left(\frac{5\cdot7}{6\cdot8}\right)^{\large{\frac{1}{4}}} \cdots$$ as well as others given in https://arxiv.org/pdf/1005.2712.pdf Trying to find the partial products from ${n=1} $ to $k $ , Mathematica Gives: $$\scriptsize{ \frac{\exp\left(2\left(-\zeta(-1,k+\frac{1}{2})^{(1,0)}+\zeta(-1,k+\frac{3}{2})^{(1,0)}+\zeta(-1,k+1)^{(1,0)}-\zeta(-1,k+2)^{(1,0)}\right)\right)\pi\, \Gamma(k+2)^2}{2\,\Gamma(k+\frac{3}{2})^2}} $$ However, I have been unsuccessful producing partial products on my own. Taking the $\ln$ of the product to try to find the partial sums; Trying to transform the following integral into infinite product. $$\int_{0}^{\infty} \frac{\cos(x)}{1+x^2} = \frac{\pi}{2e} $$ From what I have seen in some papers, the partial products are found, then the Stirling's Approximation is used to find the limit. Question: How can I prove the value of the given Infinite Product? Proofs or hints are both welcome. Thank you kindly for your help and time.","['integration', 'infinite-product', 'sequences-and-series']"
3971969,"Centroid and ""Centre of mass""","I thought that the centroid was also the point at which the area in all directions was net 0. Aka area above the cenrroid was the same area as below. But for a triangle everything I can see seems to suggest that the area above the centroid of a triangle is about 55% of the area, I just dont see how this fits the fact of it being the ""centre of mass"" Even integrating it or just simple equations (rearranging the area of a traingle formula) and even when I checked in Geogebra seemed to show that the point at which half the area is reached vertically is ${\sqrt2}/2$ from the apex for a unit triangle. I am so sure I'm wrong but I cant see how I could be","['integration', 'centroid', 'geometry', 'triangles', 'physics']"
3971980,Solve $\frac{dy}{dx}=\frac{y^2}{\left(x^2+y^2\right)^{\frac{5}{2}}}.$,"Solve $\frac{dy}{dx}=\frac{y^2}{\left(x^2+y^2\right)^{\frac{5}{2}}}.$ My attempt $\frac{dy}{dx}=\frac{y^2}{\left(x^2+y^2\right)^{\frac{5}{2}}}.$ $\implies \left(x^2+y^2\right)^{\frac{5}{2}}dy-y^2dx =0$ Given equation is not homogeneous, so, we can't solve using homogeneous method.
Given equation is not total derivative form. So, that method won't be applicable. Comparing with $Mdx+Ndy=0$ I checked whether the equation is exact or not, I found $\frac{\partial M}{\partial y} \neq \frac{\partial M}{\partial y}. $ Can you please help me?
Thank you.",['ordinary-differential-equations']
3972098,"How few $(42^\circ,60^\circ,78^\circ)$ triangles can an equilateral triangle be divided into?","This is the parallel question to this other post with many answers already , in the sense that the $(42^\circ,60^\circ,78^\circ)$ -similar triangles form the only non-trivial rational-angle tiling of the equilateral triangle (and the regular hexagon), modulo a real conjugation of the coordinate field (a subfield of $\mathbf{Q}(\zeta_{60})$ ) which transforms between $(42^\circ,60^\circ,78^\circ)$ -similar triangles and $(6^\circ,60^\circ,114^\circ)$ -similar triangles. (Reference: M. Laczkovich's Tilings of triangles .) My attempt has been the following: Since $\sin(42^\circ)$ and $\sin(78^\circ)$ have nested radicals, I tried to get rid of them by restricting my basic tiling units to only the $60^\circ$ -angled isosceles trapezoids and parallelograms that are a single row of the triangular tiles. They have shorter-base-to-leg ratios of the form $$m\cdot\frac{9-3\sqrt{5}}{2}+n\cdot\frac{11-3\sqrt{5}}{2}\quad\left(m,n\ge 0\right)$$ which are automatically algebraic integers. Any potential tiling of the equilateral triangle from these quadrilateral units corresponds to some integer polynomial relation of the above algebraics, whose polynomial degree correlates with the number of quadrilateral pieces in the tiling. Unfortunately all the above algebraics have large norms, so a blind search for the desired polynomial is out of the question, and I had to reduce the pieces' proportions again to the rationals. I was able to find a $60^\circ$ -angled isosceles trapezoid with shorter-base-to-leg ratio of $10$ using $79$ tiles, and a $60^\circ$ -angled parallelogram with neighboring sides' ratio of $11$ using $80$ tiles. Thus a few more tiles produce a $60^\circ$ -angled rhombus, and another few more tiles produce a $60^\circ$ -angled isosceles trapezoid with shorter-base-to-leg ratio $1$ , three of which tile an equilateral triangle, using a total of $121\,170$ triangular tiles. While I was at it, I found this less related post that might reduce my number of tiles to a bit below a hundred thousand. Meanwhile, I also did a quick computer search through some conceptually simple configurations that attempt to tile the equilateral triangle using less than about $50$ tiles, and I found nothing at all. I get this feeling that about a hundred thousand tiles is not the optimal amount for such a tiling, so I'm asking to see if people have better ideas. I'm unable to provide cash incentive as the parallel post did, but anyone who tries this puzzle will sure have my gratitude. Edit suggested by RavenclawPrefect: To get to the quadrilateral tiling units that I used, the first thing is to de-nest the radicals as I mentioned above. As $\mathbf{Q}(\zeta_{60})$ is Galois over $\mathbf{Q}(\sqrt{3})$ (the base field here should not be $\mathbf{Q}$ but instead the coordinate field of the equilateral triangle), if we can geometrically construct any length $\ell$ (or techinically, ratio $\ell$ ), such that when we perform the same geometric construction but with all the $42^\circ$ angles and $78^\circ$ angles swapped with each other, we still provably construct the same $\ell$ , then it must hold that $\ell\in\mathbf{Q}(\sqrt{5})$ , so that $\ell$ doesn't contain any nested radicals. There were a couple of ideas on what $\ell$ should specifically be, most of them parallel ideas that can all be found in the parallel question for the square. I settled on the above $\mathbf{Q}(\sqrt{5})$ -quadrilaterals (the ones that are a single row of triangular tiles) because they had the smallest numerator norms among others. As a non-example, there was a double-decker idea using $9$ tiles that resulted in a trapezoid with ratio a rational multiple of $889-321\sqrt{5}$ , yuck. There were also some non-triviality in which way the triangles should be oriented when being put into a single row, but some more calculation showed that the above $(m,n)$ form are all we really get. More precisely, a trapezoid also can't have $m=0$ , and a parallelogram also can't have $n=0$ . After all that work, the rest has really been a matter of trial-and-error. Among all the $(m,n)$ form, I picked a parallelogram with the smallest norm, which is an $(m,n)=(0,1)$ parallelogram with $4$ tiles, and rotated it so that it becomes a $\frac{11+3\sqrt{5}}{38}$ -parallelogram. Then $19$ of those make a $\frac{11+3\sqrt{5}}{2}$ -parallelogram with $76$ tiles, and obviously I combined it to a $(1,0)$ -trapezoid and a $(0,1)$ -parallelogram to get to the rational quadrilaterals. So the process was more like ""I frankly don't know what else to do"" rather than ""I see potential simplifications but I don't know the optimum"". It's also why I'm seeking for completely new ideas (see above) that aren't found in the parallel question about the square. RavenclawPrefect also asked a well-motivated question for if the same tiling could be performed but with congruent tiles. M. Laczkovich proved this is impossible in a subsequent paper Tilings of Convex Polygons with Congruent Triangles .","['puzzle', 'geometry', 'abstract-algebra', 'recreational-mathematics', 'tiling']"
3972099,Exercise 1.5.7 (b) in Abbott’s Understanding Analysis,"In the second edition, this exercise is as follows: Find a 1-1 mapping from $S$ , the open unit square $\{(x,y) : 0<x,y<1\}$ , to the open interval $(0,1)$ . Use the fact that each real number has a decimal expansion. The answer I’ve been seeing the most, and is also the one I thought of, was to consider the decimal expansions of $x$ and $y$ , $0.x_1x_2x_3...$ and $0.y_1y_2y_3...$ , respectively. Map $(x,y)$ to the number in $(0,1)$ of the form $0.x_1y_1x_2y_2...$ Since numbers of the form $0.a_1a_2...a_n$ are equal to $0.a_1a_2...a_{n-1}(a_n-1)99999...$ , I noticed that this creates the following issue: Suppose I have $(.2,.7)$ which is equal to the pair $(.1999...,.6999...)$ . Upon applying the previous mapping to both, they map to $.27$ and $.16999...$ , respectively. Since $.16999...$ is the same as $.17$ , this means the ordered pairs $(.1,.7)$ and $(.2,.7)$ map to the same element of $(0,1)$ . So it isn’t 1-1? Is this problem avoided by just referring to $x$ and $y$ ‘s finite decimal expansion if it exists?","['functions', 'real-analysis']"
3972102,"Solving Coin-Weighing Problem (81 Coins, 1 Fake) Using Information Theory","So I have a coin-weighing puzzle under these situations: There are 80 real coins and 1 fake coin (total of 81 coins). The real coins are all the same weight, and the weight of the fake coin is different from the real coin. The real and fake coins cannot be distinguished, other than weight. A balance is used to identify the fake coin. When using the balance, the same number of coins is placed on either plate. The result is either ""the left plate is heavier,"" ""the right plate is heavier,"" or ""the two plates are the same weight."" According to prior research, this problem cannot be solved by using the balance 4 times or less. I tried to show this by using information theory as follows, but I feel like I am missing something here. Label the coins 1,...,81, and let $C$ be the number of the fake coin. Also, let $W$ be a random variable defined so that $W=1$ when the fake coin is heavier than the real coin, and $W=0$ when lighter. At the initial state, $C$ and $W$ can be regarded as independent random variables following a uniform distribution. Then, define random variable $R_k$ so that $R_k = 0$ , $R_k = 1$ , $R_k = 2$ , when, the result after using the balance for the $k$ th time is, respectively, ""the left plate is heavier,"" ""the right plate is heavier,"" or ""the two plates are the same weight."" Then, $R_k$ can be regarded as uniquely determined by $R_1, ..., R_k,$ and the real values of $C$ and $W$ . (Do I have to add additional proof that this is true?) Assume that the fake coin can be surely identified by four measurements using the balance, then this means that the value of $C$ is determined when $R_1,...,R_4$ have been determined. Thus, using the entropy function and its chain rule, \begin{eqnarray*}
H(C, W, R_1, ..., R_4) &=& H(C) + H(R_1 | C) + H(R_2 | R_1, C) + H(R_3 | R_2, R_1, C) + H(R_4|R_3, R_2, R_1, C) + H (W| R_4, R_3, R_2, R_1, C)
\end{eqnarray*} And, we also have \begin{eqnarray*}
H(C, W, R_1, ..., R_4) &=& H(W) + H(C|W) + H(R_1 | C, W) + H(R_2 | R_1, C, W) + H(R_3 | R_2, R_1, C, W) + H(R_4|R_3, R_2, R_1, C, W)
\end{eqnarray*} Then we notice that $H(C|W) = H(C)$ , as $C$ and $W$ are independent variables. Also, $H(R_1 | W, C) < H(R_1 | C), H(R_2 | R_1, C, W)  < H(R_2 | R_1, C) $ , and so on. Thus, from the two equations, we get $H(W) < H(W | R_1, ..., R_4, C)$ But we know that $H(W | R_1, ..., R_4, C) < H(W)$ , so there is a contradiction. OK. So I somehow arrived at a contradiction, showing that the problem cannot be solved by using the balance for times. But then I realized that the same logic applies when using the balance for any number of times, so apparently there is something wrong... What sort of logic am I missing? I would appreciate any help.","['entropy', 'stochastic-analysis', 'information-theory', 'stochastic-processes', 'discrete-mathematics']"
3972110,Equation of Partial derivatives,"I am currently learning multivariable calculus and the following was done in my lecture to prove one of the properties of Jacobian The property: ( $JJ'=1$ ), where $J$ is $\frac{\partial (x,y)}{\partial(u,v)}$ and $J'$ is $\frac{\partial(u,v)}{\partial (x,y)}$ The equation in the proof: $\partial u = \frac{\partial u}{\partial x} \partial x +\frac{\partial u}{\partial y} {\partial y}$ Then the professoor proceeded to divide by $\partial u$ on both sides so you end up with $\frac{\partial u}{\partial u}$ on the left hand side which is essential 1. He then did this for $v$ also. My question: $\partial u\ , \partial x\ , \partial y$ on their own makes no sense. And since partial derivative is defined for suppose u with respect to some other variable, dividing or multiplying by $\partial (some \ variable)$ should be wrong. What is the correct theory ?","['multivariable-calculus', 'calculus']"
3972121,Why does the constant of integration always come with the independent variable whilst integrating differential equations?,"Say, we had the following differential equation: $$\frac{\mathrm{d}y}{\mathrm{d}x}x = 1+y$$ When we re-arrange the equation and integrate both sides, why will the constant of integration ONLY come with the independent variable, $x$ ? My assumption is that it's because we can think of a function as having an input and an output. The output is the dependent variable, and input is the independent variable. So, all the work is done on the input, to get a desired output. So, the constant should only come with the independent variable. Am I wrong?","['integration', 'indefinite-integrals', 'ordinary-differential-equations']"
3972167,Let $a = \frac{1 + \sqrt{2009}}{2}$ . Find the value of $(a^3 - 503a - 500)^5$ .,"Let $a = \frac{1 + \sqrt{2009}}{2}$ . Find the value of $(a^3 - 503a - 500)^5$ . What I Tried : We have :- $$ (a^3 - 503a - 500)^5 = [a(a^2 - 3) - 500(a - 1)]^5$$ $$= \Bigg(\Bigg[\frac{1 + \sqrt{2009}}{2}\Bigg]\Bigg[\frac{1009 + \sqrt{2009}}{2}\Bigg] - 500\Bigg[\frac{\sqrt{2009} - 1}{2}\Bigg]\Bigg)^5$$ $$= \Bigg[\Bigg(\frac{1010\sqrt{2009} + 3018}{2}\Bigg)\Bigg] - 250(\sqrt{2009} - 1)\Bigg]^5$$ $$=(505\sqrt{2009} + 1509 - 250\sqrt{2009} - 250)^5$$ $$= (250\sqrt{2009} - 1259)^5$$ However, the answer given is $32$ , so there could have been more simplifications. As a question, where did I go wrong? Also can anyone give me some simpler way of solving this?","['algebra-precalculus', 'problem-solving']"
3972195,Show that $\sqrt{\frac{1+2\sin\alpha\cos\alpha}{1-2\sin\alpha\cos\alpha}}=\frac{1+\tan\alpha}{\tan\alpha-1}$,Show that $\sqrt{\dfrac{1+2\sin\alpha\cos\alpha}{1-2\sin\alpha\cos\alpha}}=\dfrac{1+\tan\alpha}{\tan\alpha-1}$ if $\alpha\in\left(45^\circ;90^\circ\right)$ . We have $\sqrt{\dfrac{1+2\sin\alpha\cos\alpha}{1-2\sin\alpha\cos\alpha}}=\sqrt{\dfrac{\sin^2\alpha+2\sin\alpha\cos\alpha+\cos^2\alpha}{\sin^2\alpha-2\sin\alpha\cos\alpha+\cos^2\alpha}}=\sqrt{\dfrac{(\sin\alpha+\cos\alpha)^2}{(\sin\alpha-\cos\alpha)^2}}=\sqrt{\left(\dfrac{\sin\alpha+\cos\alpha}{\sin\alpha-\cos\alpha}\right)^2}.$ Using the fact that $\sqrt{a^2}=|a|$ the given expression is equal to $\left|\dfrac{\sin\alpha+\cos\alpha}{\sin\alpha-\cos\alpha}\right|.$ I think that in the inverval $\left(45^\circ;90^\circ\right) \sin\alpha>\cos\alpha$ but how can I prove that? What to do next?,['trigonometry']
3972218,Adjoint group of a reductive group,"Let $G$ be a (not necessarily quasi-split) reductive group over $\mathbb{Q}$ . In order to use results from semi-simple Lie groups for the reductive group $G(\mathbb{R})$ , it seems common to implicitly use the adjoint group of $G$ . If I understand correclty, it is defined by the exact sequence of algebraic groups $$
1 \rightarrow Z_G \rightarrow G \rightarrow G^{\operatorname{ad}} \rightarrow 1
$$ where $Z_G$ denotes the center of $G$ . My questions are the following: What is the relation between $G^{\operatorname{ad}}(\mathbb{R})$ and $\operatorname{Ad}(G(\mathbb{R}))$ , the image of $G(\mathbb{R})$ under the Adjoint representation? From what I understand, the latter is isomorphic to $G(\mathbb{R}) / C_{G(\mathbb{R})}\,(G(\mathbb{R})^\circ)$ , the quotient modulo the centralizer of the connected component of $G(\mathbb{R})$ . (see Wikipedia on the Adjoint representation) Is $G^{\operatorname{ad}}$ an adjoint semisimple group? (Def: $G$ is called adjoint, if for any connected group $H$ , any isogeny $G \rightarrow H$ is an isomorphism. This implies for example that $G^{\operatorname{ad}}$ is a direct product of its simple factors). To compare group decompositions of both groups (like Iwasawa decomposition), one needs to fix maximal compact subgroups. So let $K \subset G(\mathbb{R})$ and $\tilde{K} \subset G^{\operatorname{ad}}(\mathbb{R})$ be maximal compact subgroups. Is there any way to get a relation between $K$ and $\tilde{K}$ ? Since $\operatorname{Ad}$ is continuous, the image $\operatorname{Ad}(K)$ should be compact in $\operatorname{Ad}(G(\mathbb{R}))$ , but I see no reason for it to be maximal. A toy example would maybe be $GL_2$ with maximal compact subgroup $O(2) \subset GL_2(\mathbb{R})$ . The Adjoint group should be $PGL_2$ with maximal compact subgroup $PO(2) = O(2) / Z(O(2))$ and $Z(O(2)) = Z_{GL_2} \, ((\mathbb{R})) \cap O(2) = \{ \pm 1 \}$ . I would be grateful for any answer. Thank you!","['harmonic-analysis', 'algebraic-groups', 'algebraic-geometry', 'lie-groups']"
