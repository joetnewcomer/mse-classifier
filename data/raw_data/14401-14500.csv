question_id,title,body,tags
114311,Proving that $\binom{n}{k}\binom{\smash{k}}{m}\binom{m}{r} = \binom{n}{r}\binom{n-r}{n-m}\binom{n-m}{n-k}$,"How would you show that 
$$\binom{n}{k}\binom{k}{m}\binom{m}{r} = \binom{n}{r}\binom{n-r}{n-m}\binom{n-m}{k-m}$$
for $n\geq k\geq m\geq r$ ?",['combinatorics']
114330,Show that $\binom{2n}{  n}$ is divisible by 2? [duplicate],This question already has answers here : Closed 12 years ago . Possible Duplicate: prove that $(2n)!/(n!)^2$ is even if $n$ is a positive integer Show that $\binom{2n}{ n}$ is divisible by 2? Any help would be appreciated..,"['binomial-coefficients', 'combinatorics']"
114340,what does following matrix says geometrically,"Let $M\subset \mathbb C^2$ be a hypersurface defined by $F(z,w)=0$. Then for some point $p\in M$, I've
$$\text{ rank of }\left(
    \begin{array}{ccc}
     0 &\frac{\partial F}{\partial z} &\frac{\partial F}{\partial w} \\
 \frac{\partial F}{\partial z} &\frac{\partial^2 F}{\partial ^ 2z} &\frac{\partial^2 F}{\partial z\partial w} \\
 \frac{\partial F}{\partial w} &\frac{\partial^2 F}{\partial w\partial z} &  \frac{\partial^2 F}{\partial w^2} \\
                    \end{array}
                  \right)_{\text{ at p}}=2.$$ What does it mean geometrically? Can anyone give a geometric picture near $p$? Any comment, suggestion, please. Edit: Actually I was reading about Levi flat points and Pseudo-convex domains.  I want to understand the relation between these two concepts. A point p for which the rank of the above matrix is 2 is called Levi flat. If the surface is everywhere Levi flat then it is locally equivalent to $(0,1)\times \mathbb{C}^n$, so I have many examples....but what will happen for others for example take the three sphere in $\mathbb{C}^2$ given by $F(z,w)=|z|^2+|w|^2−1=0$.  This doesn't satisfy the rank 2 condition.  Can I have precisely these two situations?","['geometry', 'complex-geometry', 'differential-geometry', 'linear-algebra', 'intuition']"
114348,Normal Subgroups in Finite p-groups,"In finite $p$-groups, the number of subgroups of order $p^k$ is congruent to $1 \mod p$. Is it true that the number of normal subgroups of order $p^k$ is congruent to $1 \mod p$?",['group-theory']
114349,How is Cauchy's estimate derived?,"Cauchy's integral formula says
$$
f^{(n)}(z)=\frac{n!}{2\pi i}\int_C\frac{f(\zeta)d\zeta}{(\zeta-z)^{n+1}}.
$$ If we let $C$ be the circle of radius $r$, such that $|f(\zeta)|\leq M$ on $C$, then taking $z=a$, one obtains Cauchy's estimate that 
$$
|f^{(n)}(a)|\leq Mn!r^{-n}.
$$
How is this derived? I see instead
$$
|f^{(n)}(a)|\leq\frac{n!}{2\pi}\int_C \frac{|f(\zeta)||d\zeta|}{|\zeta-a|^{n+1}}\leq Mn!\int_C\frac{|d\zeta|}{|\zeta-a|^{n+1}}
$$
but I don't see how this eventually gets to Cauchy's estimate.",['complex-analysis']
114356,Help with a Bollobás proof - Switching between random graph models,"I'm trying to make my way through Bollobás' book 'Models of Random Graphs', and unfortunately I've come entirely unstuck on one of his typical 2-line ""and of course, this is entirely trivial""-style proofs. Despite spending many hours staring at it in vain, I have progressed precisely nowhere and was hoping someone could explain what's going on to me in as much detail as they can possibly summon the energy to give, so that I might finally understand it. The book's theorem (Theorem 2.2) is about switching between the $\mathcal{G}(n,p)$ and $\mathcal{G}(n,m)$ models of random graphs, and goes as follows: Theorem: (i) Let Q be any graph property and suppose $pqN \to \infty$ (where we have $n$ vertices and $N={n \choose 2}$ possible edges). Then the following 2 assertions are equivalent (my comments in italics): a) Almost every graph in $\mathcal{G}(n,p)$ has Q. (Here $\mathcal{G}(n,p)$ represents the probability space of random graphs on $n$ vertices with edges distributed randomly with probability $p$ , i.e. edge-number binomially distributed $\operatorname{Bin} (N,p)$ ) b) Given $x>0$ and $\epsilon > 0$ , if $n$ is sufficiently large, there are $l \geq (1- \epsilon) 2x(pqN)^{1/2}$ integers $M_1,\ldots,\,M_l$ with $pN-x(pqN)^{1/2}<M_1<M_2<\ldots < M_l<pN + x(pqN)^{1/2}$ such that $P_{M_i}(Q)>1-\epsilon$ for every $1 \leq i \leq l$ . Proof: (i) By the De Moivre-Laplace theorem, for every fixed $x > 0$ , $\mathbb{P}_p(|e(G)-pN|<x(pqN)^{-1/2})\sim \Phi(x) - \Phi(-x).$ Since also $\mathbb{P}_p(e(G)=M) = b(M;N,p) < (pqN)^{-1/2}$ for every M, the equivalence follows. So, where to start. With regards to what he did say, I believe the statement of $\Phi$ which we get from the De Moivre-Laplace theorem; I'm happy with that. I can't however see why that probabilty stated is $< (pqN)^{1/2}$ - I can believe it's true, but I can't see the most obvious way to prove it. With regards to the proof of (i) as a whole: I guess the intuitive notion of this part of the theorem is to be able to say 'This property holds iff it holds for lots of graphs close to the mean number of edges', i.e. we can focus on just the behaviour near the mean. So, we do the obvious thing and approximate by a normal distribution, since then we can say lots of nice things in terms of 'number of variances away from the mean'. Sadly though, I can't even figure out which direction he's trying to deal with in his proof, let alone fill in the gaps. We know roughly how likely we are to land within $x(Npq)^{1/2}$ of the mean, and we know an upper bound for the probability of getting $M$ edges: is that really sufficient to just say ""result follows""? So I think that's everything - sorry for the substantial length of this question, if there's anything you think I can remove for brevity then I'll be happy to. As above, I've spent hours and hours getting nowhere with what's meant to be a pretty straightforward theorem here, the material is new to me so maybe that's why, but what I'd be extremely grateful for is a very thorough (and fairly basic if possible) explanation of what's going on here, what I'm missing in the proof and why it is indeed true. Sincere thanks for your help in advance. (Edit: removed second half of theorem due to misunderstanding)","['graph-theory', 'probability-distributions', 'probability']"
114367,Probability: People sitting in a row (linear arrangement),"Question: Ten persons are seated at random in a row. What is the probability that a particular couple will be seated together?
My attempt: 9! 2!/ 10! = $\dfrac{1}{5}$ , since there are 9! ways of sitting in pairs and 2! ways to arrange a couple. The solution I'm given is $\dfrac{1}{63}$. Can someone point out what I'm doing wrong?",['probability']
114371,Deriving the Area of a Sector of an Ellipse,A sector $P_1OP_2$ of an ellipse is given by angles $\theta_1$ and $\theta_2$. Could you please explain me how to find the area of a sector of an ellipse?,['geometry']
114378,When does every group with order divisible by $n$ have a subgroup of order $n$?,"According to Sylow's theorem, every finite group with order divisible by $p^k$ for some prime $p$ has a subgroup of order $p^k$. Is this the best possible result in this direction? That is, if $n$ is not a power of a prime, does there always exist a group with order divisible by $n$ that does not have a subgroup of order $n$? EDIT: Just to clarify, I am aware that groups like this exist. The standard example seems to be $A_4$, which has order divisible by $6$ but no subgroup of order $6$. What I am looking for is a proof that a counterexample exists for any $n$ that is not a power of a prime.","['finite-groups', 'group-theory', 'abstract-algebra']"
114401,A problem about parametric integral,How to solve the following integral. $I(\theta) = \int_0^{\pi}\ln(1+\theta \cos x)dx$ where $|\theta|<1$,['integration']
114403,3rd iterate of a continuous function equals identity function,"If $ f: \mathbb{R} \to \mathbb{R} $ is continuous, and $\forall x \in \mathbb{R} :\;(f \circ f \circ f)(x) = x  $, show that $ f(x) = x $. The condition that $f$ is continuous on $\mathbb{R}$ is crucial for the proof. I can find functions such as $\displaystyle\frac{x-3}{x+1}$ that satisfies  $ (f \circ f \circ f)(x) = x $. I have tried to negate the conclusion to see if there's a contradiction, but got stuck.","['function-and-relation-composition', 'calculus', 'real-analysis', 'functional-equations']"
114420,Calculate the product of two Gaussian PDF's,"I'm trying to understand the origin of the formulas for the $\mu$ and the $\sigma^2$ from this side (stanford): https://ccrma.stanford.edu/~jos/sasp/Product_Two_Gaussian_PDFs.html As I have understood actually the product of two Gaussian PDF's is not again a Gaussian PDF.
But with the formula from the stanford website I again get a Gaussian PDF. Where I need help is: Understand the origin of the two formulas $(\mu, \sigma^2)$ Is the center of the product of two PDF's and the center of a PDF calculated via the two formulas in the same place?",['statistics']
114422,Existence and uniqueness theorems for ODE. Log-Lipschitz regularity.,"Let $\mathbb{X}$ be a linear space with a complete metric $d:\mathbb{X}\times\mathbb{X}\to [0,+\infty)$. Let's $B[x_o,b]$ is a compact ball of radius $b$ centered at $x_o$. THEOREM:If $F:[t_o-a,t_o+a]\times B[x_o,b]\subset\mathbb{R}\times\mathbb{X}\to \mathbb{X}$ a limited application, continuous and continuous Lipschiz in $B[x_o,b]$ (note that if $\mathbb {X}$ have finite demension the condition is limited to be redundant).Then there exists a unique solution
  $$
\varphi : [t_o-\alpha,t_o+\alpha]\to B[x_o,b]
$$
  to the problem of Cauchy
  $$
x'(t)=F(x,t)\quad x(t_o)=x_o
$$
  where $\alpha=\min\{a,b\backslash M\}$ and $M=\sup\{|F(t,x)| : (t,x)\in [t_o-a,t_o+a]\times B[x_o,b] \}$. DEFINITION:We say that $F$  is $\gamma$-log-Lipschitz in $B[x_o,b]$ if there exist $\gamma \ge 0$, $L>0$ and $C>0$ such that
$$
\|F(x,t)- F(y,t) \| \le C{\bigg(\log\frac{L}{\|x-y\|}\bigg)^{\gamma}}\|x-y\|,
$$
 for all $ x,y \in B[x_o,b]$ and all $t\in [t_o-a,t_o+a]$. QUESTION 1. There is a version of this theorem for  Log-Lipschitz fields?We may waive the conditions of compactness of the ball and the range in this case? QUESTION 2. There are other more unusual versions of this theorem where the field $ F $ satisfas
 $$
\|F(x,t)- F(y,t) \| \le |\Psi(x,y)|\cdot\|x-y\|,
$$
 for some function $ \Psi :\mathbb{X}\times\mathbb{X}\to\mathbb{R}$?We may waive the conditions of compactness of the ball and the range in this case? Thank you.","['ordinary-differential-equations', 'functional-analysis', 'analysis']"
114423,How to find the directional derivative of the following function?,"I would like to find all directional derivatives of the function $$f(x,y) = (3x^4 + y^4)^{1/4} , $$ (where $ (x,y) \in \mathbb{R}^2 $), in the point $(0,0)$. I tried to do this by calculating $$\nabla f(x,y) = f_1 (x,y) e_1 + f_2 (x,y) e_2 $$, where $e_n$ is the $n$'th unit vector and $f_n$ is the partial derivative with respect to the $n$'th variable. I found that $f_1 (x,y) = (1/4)\cdot 12x^3 (3x^4 + y^4)^{-3/4} = \frac{3x^3}{(3x^4+y^4)^{3/4}} $, and that $f_2 (x,y) = \frac{y^3}{(3x^4 + y^4)^{3/4}} $. When filling in $(0,0)$ to find $\nabla f(0,0)$, however, I get two expressions involving a $\frac{0}{0}$ - fraction. I do think I need to do this though, since $$D_{v/|v|} f(a,b) = \langle (\frac{v}{|v|}, \nabla f(a,b)  \rangle . $$  Can you please help me with this?",['multivariable-calculus']
114424,Hochschild homology of Weyl algebra,"Could someone explain to me how one can compute the Hochschild homology of the Weyl algebra $A_n$ (i.e., algebra of differential operators with polynomial coefficients in $n$ variables)?","['homological-algebra', 'hochschild-cohomology', 'abstract-algebra']"
114426,How to find the moment generating function of this distribution,"If $f(x) = 0.5 e^{-|x|}$ for $-\infty < x < \infty$, how would you find the moment generating function for this? Also how would you find the distribution of $Y = |X|$? Attempt: $$E(e^{tX}) = \int_{-\infty}^\infty f(x) e^{tx} \; dx.$$",['probability']
114434,Is kernel a complemented subspace,"Let $\mathcal{A}:X\to Y$ be continuous linear operator, $X$ and $Y$ are Banach spaces.
Let $\text{Im} \mathcal{A}=Y$. Is $\ker\mathcal{A}$ a complemented subspace of $X$?","['functional-analysis', 'banach-spaces']"
114438,Symbol of a (non linear) differential operator,"I am interested in knowing whether there is a definition for the symbol of a PDO which is NOT linear.
In Wikipedia and in the book I am reading (An Introduction to Partial Differential Equations by Renardy-Rogers) I only found the definition for linear PDOs. Here is the Wikipedia link: http://en.wikipedia.org/wiki/Symbol_of_a_differential_operator","['ordinary-differential-equations', 'partial-differential-equations', 'differential-operators']"
114442,Möbius inversion formula for two functions f(x) and g(x),"Given the 2 functions $$ g(x)= \sum_{n=1}^{\infty}f\left(\frac{x}n\right)\log(n)\;, $$ how can I use Möbius inversion to recover $f$ from $g$?? I believe that $$ f(x)=  \sum_{n=1}^{\infty}\mu (n)g\left(\frac{x}n\right)\log(n)\;. $$ Here 'mu' is the Möbius function.","['sequences-and-series', 'number-theory']"
114443,Given K balls and N buckets what is the expected number of occupied buckets,Given K balls and N buckets how do you calculate the expected number of buckets with at least 1 ball. Each ball is put in a bucket chosen at random with a uniform probability distribution. Assume also K $\leq$ N.,"['probability', 'combinatorics']"
114445,Analytic function $f$ agrees with $\tan x$ on $0 \leq x \leq 1$—is $f$ entire?,"Suppose an analytic function $f$ agrees with $\tan x$, $0 \leq x \leq 1$. Could $f$ be entire? Since $f$ and $\sin z/\cos z$ agree at a set of points and both are analytic in an open neighborhood of $(0,1)$, $f(z)=\sin z/\cos z$ in that open neighborhood. Now the problem for $f$ being entire is that $\sin z/\cos z$ is not differentiable at $z=(2n-1)\pi/2$, which aren't in $(0,1)$. I'm not sure if this is problem or if we can let $f$ be a different analytic function at the points where $\sin z/\cos z$ isn't defined.","['trigonometry', 'complex-analysis']"
114453,"Solve $x^y \, = \, y^x$ [duplicate]","This question already has answers here : Closed 12 years ago . Possible Duplicate: $x^y = y^x$ for integers $x$ and $y$ I obtained a question asking for how to solve $\large x^y = y^x$. The given restraints was that $x$ and $y$ were both positive integers.
By a bit of error an trial we quickly see that $x=2$ and $y=4$ is one solution. My question is: How do one show that $(2\,,\,4)$ is the only non trivial, positive solution to the equation? Now my initial approach was as follows:
We have $$\large x^y = y^x$$ The trivial solution is obviously when $y=x$, so let us focus on when $y \neq x$. 
Let us make a more general statement. Firstly I take the log of both sides $$\large y \log x = x \log y $$ Let us divide by x and \log x (We now assume $x\neq 0$ and $x\neq 1$ since 0 is not a positive number, and 1 gives us a trivial solution) $$\large \frac{y}{x} = \frac{\log y }{\log x}$$ For these sides to be equal, we must remove the logarithms on the right hand side, this is achived if $y$ is on the form $x^a$. Now This gives $$\large \frac{x^a}{x} = \frac{\log \left(x^a\right) }{\log(x)}$$ $$\large x^{a-1} = a$$ So finaly we obtain that $ \displaystyle \large x=\sqrt[ a-1]{a}$ and $\displaystyle \large y = \sqrt[a-1]{a^a}$ Now setting $a=2$ gives us $x = 2$ and $y=4$ as desired. My question is, how do we prove that $x=2$ and $y=4$ is the only integer solutions? My thought was to show that $ \displaystyle \large \sqrt[ a-1]{a}$ and $\displaystyle \large \sqrt[a-1]{a^a}$ are both irrational when a>2, but I have not been able to show this. Any help is greatly appreciated, cheers =)",['algebra-precalculus']
114462,"A map is continuous if and only if for every set, the image of closure is contained in the closure of image","As a part of self study, I am trying to prove the following statement: Suppose $X$ and $Y$ are topological spaces and $f: X \rightarrow Y$ is a map. Then $f$ is continuous if and only if $f(\overline{A})\subseteq \overline{f(A)}$, where $\overline{A}$ denotes the closure of an arbitrary set $A$. Assuming $f$ is continuous, the result is almost immediate. Perhaps I am missing something obvious, but I have not been able to make progress on the other direction. Could anyone give me a hint which might illuminate the problem for me?","['general-topology', 'continuity']"
114471,Smoothness of radially defined functions.,"Suppose that for each $v \in \mathbb{R}^2$ with $|v| = 1$, there is a smooth ($C^{\infty}$) function $f_v : [0, 1] \rightarrow \mathbb{R}$ such that $f_v(0) = 0$. Now, let $\bar{D}$ be the closed unit disk in $\mathbb{R}^2$ and define $\phi : \bar{D} \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ by setting $\phi(0) = 0$ and, for all other $u \in \bar{D}$, $$\phi(u) := f_{u/|u|}(|u|).$$ QUESTION : Are there reasonable conditions to impose on the family $\{f_v\}_{v~\in~\mathbb{S}^1}$ that guarantee smoothness of $\phi$? Under these conditions, how would you prove it? I apologize for the imprecise use of the word reasonable here; but I'd be interested in pretty much any conditions, other than absolutely trivial ones, like ""take all $f_v$ identically zero"". Thanks!","['multivariable-calculus', 'analysis']"
114497,Vector path length of a hypotenuse,"Consider the red path from A that zigzags to B, which takes $n$ even steps of length $w$. The path length of the route $P_n$ will be equal to: $ P_n = P_x + P_y = \frac{n}{2}\times w + \frac{n}{2}\times w = n \times w $ But $\frac{n}{2}\times w = 1$ beacuse it is the length of one of the sides of the triangle so: $P_n = 2$ Which will be true no matter how many steps you take. However in the limit $n \to \infty, w \to 0$ the parth length $P_\infty$ suddenly becomes: $P_\infty = \sqrt{1^2 + 1^2} =  \sqrt{2}$ Due to Pythagoras. Why is this the case? It seems the path length suddenly decreases by 0.59!","['geometry', 'triangles']"
114504,Arithmetic progressions,"What are the largest known lower bounds for $B_k$, the maximal sum of the reciprocals of the members of subsets of the positive integers which contain no arithmetic progressions of length $k$?
for $k=3,4,5,6...$ $B_k\leq$ sup({ $\sum_{n\in S}1/n$ |$S\subset N$|S contains no arithmetic progressions of length k}) And is the bound proved to be finite for any k? Can there exist a subset for which the maximal bound (finite or infinite), is actually attainable? Ok, I am interested in any known bounds on $B_k$","['reference-request', 'additive-combinatorics', 'number-theory', 'combinatorics']"
114505,What's so special about sine? (Concerning $y'' = -y$),"In an attempt to actually grok sine, I came across the $y''= -y$ definition. This is incredibly cool, but it leads me to a whole new series of questions. Sine seems pretty prevalent everywhere in life (springs, sound, circles...) and I have to wonder, what's so special about the second derivative in this scenario? In other words, why does nature / math seem to care more about the scenario where $y'' = -y$ instead of, say, $y' = -y$ or $y''' = y$? Why is acceleration equal to negative the magnitude such a recurring theme in math and nature, while velocity equal to negative the magnitude ($y'=-y$) or jerk equal to negative the magnitude ($y'''=-y$) are seemingly unimportant? In other words, what makes sine so special? Note that this question also sort of applies to $e$, which satisfies $y'' = y$. (Edit: Yes, I understand that $e$ and $\sin$ are closely related. I'm not looking for a relationship between $e$ and $\sin$. Rather, I'm wondering why these functions in particular, which both arise from a relationship between a function and its own second derivative, are so prevalent. For example, do functions satisfying $y'''=-y$ also recur frequently, and I just haven't noticed them? Or is the second derivative in some way 'important'?)",['ordinary-differential-equations']
114512,How to find the orthonormal transformation that will rotate a vector to the x axis?,I am having trouble remembering linear algebra. I need to find the orthonormal transformation that will rotate a 3-dimensional vector to the x axis. I could not find any similar question on the net. Any tips?,"['matrices', 'transformation', 'orthonormal']"
114516,Functions and Algebraic Operations,"I just need some help on these equations: $f: A \to B$ and $y=f(x)=2x^{3}+1\implies f^{-1}(x)=$ ? THANK YOU very much for reading this and please, pardon me that I'm STILL not skilled enough to use proper or universal mathematical symbols on the Web those might have been recognized almost all around the World... I just checked the equation and please let me know if it's not ' y=2x^(3)+1 '.",['functions']
114544,"Coupon Problem generalized, or Birthday problem backward.","I want to solve a variation on the Coupon Collector Problem , or (alternately) a slight variant on the standard Birthday Problem.
I have a slight variant on the standard birthday problem . In the standard Coupon Collector problem, someone is choosing coupons at random (with replacement) from n different possible coupons. Duplicate coupons do us no good; we need a complete set. The standard question is ""What is the expected number of coupons (or probability distribution in number of coupons) to collect them all? In the standard birthday problem, we choose k items from n options with replacement (such as k people in a room, each with one of 365 possible birthdays) and try to determine the probability distribution for how many unique values there will be (will they have the same birthday?). In my problem, someone has chosen k items from n options and I know that there were p distinct values, but I don't know what k was. If $p=n$ then this is the coupon problem, but I want to allow for values of p that are less than n. I want to determine the probability distribution for k (actually, all I need is the expected value of k, but the distribution would be interesting as well) as a function of p and n.","['coupon-collector', 'discrete-mathematics', 'birthday', 'probability', 'combinatorics']"
114558,Explicitly writing out all elements of $\mathbb{P}^{1}(\mathbb{F}_{n})$,"Explicitly the elements of $\mathbb{P}^{1}(\mathbb{F}_{3})$ are $[1:0], [0:1], [1:1]$, and $[1:-1]$. Why is this so? How would I do this for $\mathbb{P}^{1}(\mathbb{F}_{4})$? What about general $\mathbb{P}^{1}(\mathbb{F}_{n})$?","['geometry', 'algebraic-geometry', 'projective-geometry']"
114561,Is there an algebraic reason why a torus can't contain a projective space?,"Let $X$ be an abelian variety. As abelian varieties are projective then $X$ contains lots and lots of subvarieties. Why can't one of them be a projective space? If $X$ is defined over the complex numbers, then there is a relatively painless way to see this (modulo lots of painful differential geometry, depending on your tastes). Indeed, if $Z$ is a (say smooth) subvariety of any space $X$, then we have an exact sequence $$
0 \longrightarrow T_Z \longrightarrow T_X \longrightarrow N_{Z/X} \longrightarrow 0.$$ We can put a metric $\omega$ on $X$. By restriction, this gives a metric on $Z$. One can now calculate that the curvature of the metric on $Z$ is no more than that of the metric $\omega$ on $X$. A torus admits flat metrics, that is Kähler metrics of zero curvature. If a torus could admit a projective space $\mathbb P^k$, we would then get a Kähler metric of non-positive curvature on $\mathbb P^k$. This cannot happen, for example, because then its Ricci curvature would be negative, in contradiction to the Ricci form representing the positive anticanonical bundle of $\mathbb P^k$. Question: Is there an algebraic way of seeing this? I'm interested because I absolutely don't know. I have little intuition for algebraic methods and would like to try to change that, a simple example like this might be a good place to start.","['algebraic-geometry', 'complex-geometry', 'kahler-manifolds']"
114577,How does the function CycleIndex work in GAP? ( undocumented in GAP ),"Background: When I divide a hexagon in six triangles the group $D_6$ works on the triangles. The cycle index of the group action would be in this case $$p(x_1,x_2,x_3,x_6)=\frac{1}{12}(x_1^6 + 3x_1^2x_2^2 + 4x_2^3+2x_3^2+2x_6)$$ Question: How does CycleIndex work in GAP? The doc in GAP notes that CycleIndex is undocumented, but the function exists.","['gap', 'computer-algebra-systems', 'group-theory']"
114594,Dini's Theorem - Proof.,"I'd like to prove the following: If $f_j$ are continuous functions on a compact set $K$, and $f_{1}(x) \leq f_{2}(x) \leq \dots$ for all $x \in K$, and the $f_j$ converge pointwise to a continuous function $f$ on $K$ then in fact the $f_j$ converge uniformly to $f$ on $K$. Attempt: Let $g_{j}(x) = f(x) - f_{j}(x)$ for all $j$. Then, since $f_j \rightarrow f$ pointwise, we see $g_j \rightarrow 0$ pointwise. Now, let $\varepsilon > 0$ . And examine { $x \in K : g_{j}(x) < \varepsilon$ }. I've been told that the next step should be to  show that { $x \in K : g_{j}(x) < \varepsilon$ } is equal to the intersection of $K$ with some open set $U_j$. But I'm not certain why this is true? Advice? Insight?","['sequences-and-series', 'real-analysis']"
114600,On the modulus of $\Gamma(z)$,"In about two weeks, I'm going to be giving a presentation on the complex-valued Gamma function $\Gamma(z)$. By definition, I know that $$\Gamma(z)= \int_0^\infty e^{-t}t^{z-1}dt.$$ Now if I let $z=x+iy$, how does the following hold? $$|\Gamma(x+iy)| \leq \Gamma(x).$$ It might actually be something quite simple, but here's what I attempted: $$|\Gamma(x+iy)|= |\int_0^\infty e^{-t}t^{z-1}dt|$$ $$=|\int_0^\infty e^{-t}t^{x+iy-1}dt|$$ $$=|\int_0^\infty e^{-t}t^{x-1}t^{iy}dt|$$ $$\leq|\int_0^\infty e^{-t}t^{x-1}dt|$$ $$=\int_0^\infty e^{-t}t^{x-1 }dt$$ $$=\Gamma(x),$$ where $t \gg 1$. I hope this was the correct procedure.","['special-functions', 'complex-analysis']"
114606,Why learn Category Theory in order to study Group Theory?,"I am self-studying Hungerford's book Algebra . He uses a whole section to talk about categories. In the next section (Direct Products and Direct Sums) he proves that the category of groups has a product, but I think I don't need categories in order to prove that a direct product of groups exists. I've looked in Rotman's book (about Group Theory) and he doesn't  mention anything about categories. Here is my question: Why should someone study Category Theory in order to study Group Theory? PS. I am a layman, but I would like to learn about this subject.","['category-theory', 'group-theory']"
114633,"If $f$ is differentiable on $[a,b]$, then it is also Lipschitz on it.","He guys, I am trying to show that a differentiable function defined on a closed interval is also Lipschitz on it. I managed to weave the below proof, but I have a feeling that it may be just a tad too general for this purpose: Theorem. If $f$ is differentiable on $[a,b]$, then it is also Lipschitz on it. Recall that $f:A\to\mathbb{R}$ is Lipschitz on $A$ if there exists an $M>0$ such that$$\left|\frac{f(x)-f(y)}{x-y}\right|\leq M$$for all $x,y\in A$. Proof. Let $f$ be differentiable on $[a,b]$. Because $f$ is continuous and $[a,b]$ is compact, by the Extreme Value Theorem , it follows that $f$ attains a maximum value $M$. Moreover, since $f$ is differentiable on $[a,b]$,$$f'(y)=\lim_{x\to y}\left|\frac{f(x)-f(y)}{x-y}\right|\leq M,$$for all $x,y\in[a,b]$, as required. $\square$ What do you guys think? Edit: What if we were to add that $f'$ is also continuous on $[a,b]$?",['real-analysis']
114646,Looking for a Calculus Textbook,"I want to start signal processing and I need a book that satisfies my mathematical requirements: I am in the third grade of high school and I don't know any useful thing about limit, differential, ... Please help me.","['signal-processing', 'reference-request', 'integration']"
114650,$\ell^p\subseteq\ell^q$ for $0<p<q<\infty$ and $\|\cdot\|_q<\|\cdot\|_p$ [duplicate],"This question already has answers here : How do you show monotonicity of the $\ell^p$ norms? (6 answers) Closed 4 years ago . I'm trying to show the inclusion : $\ell^p\subseteq\ell^q$ for real-value sequences, and show that the norms satisfy: $\|\cdot\|_q<\|\cdot\|_p$. I think I can show the first part without much trouble: Take $a_n$ in $\ell^p$, then the partial sums are a Cauchy sequence, i.e., for any $\epsilon>0$ , there is a natural $N$ with $|S_{n,p}-S_{k,p}|<\epsilon$ for $n,k>N$, and $S_{n,p}$ the partial sums of $|a_n|^p$ and the individual terms go to $0$. So, we choose an index $J$ with $a_j<1$ for $j>J$. We then use that $f(x)=a^x$ decreases in $[0,1]$. This means that $|a_j|^p<|a_j|^q$. So the tail of $S_{n,q}$, the partial sums of $|a_n|^q$ decrease fast-enough to converge, by comparison with the tail of $S_{n,p}$. But I'm having trouble showing $\|\cdot\|_q<\|\cdot\|_p$ . Also, is there a specific canonical embedding between the two spaces?","['functional-analysis', 'real-analysis']"
114654,What's the explicit formula for Permutations of Subsets of a Multiset? [duplicate],"This question already has answers here : How to find the number of $k$-permutations of $n$ objects with $x$ types, and $r_1, r_2, r_3, \cdots , r_x$ = the number of each type of object? (4 answers) Closed last year . What is the number of permutations of subsets of the multiset $S$ with cardinality $n$ ? A sample problem would be to find the number of ways you can construct ""words"" with three of the letters in the set $\{G,R,E,E,N\}$ . I've looked everywhere and found two identical posts by the same person on MSE and on MO , but no formula was posted. Such formula exists for sets with distinct elements, $P(n,r)$ . The number of permutations of a multiset also exists as the multinomial coefficient. But there seems to be no way to compute the number of permutations of subsets of a multiset given the cardinality, other than going case by case and using logic. I've heard that generating functions can be used to solve such problems (as was written in Maple's help files) but I'm looking for a general solution using combinatorics, although a generating functions solution would be cool too (I have yet to learn generating functions). I played around with this last week, and found a formula when the multiset only contains one element that is duplicated. Let's suppose the number of duplicates is $E$ , the cardinality of the multiset $S$ is $n$ , and that the cardinality of the subsets desired is $P$ . Then, the number of permutations is $$\sum_{k=0}^{E}\binom{P}{k}P(n-E,P-k)$$ This formula only works when $n\geq E+P$ and even then it might not work, and I didn't know how to proceed. Suresh Venkat suggested to sum multinomial coefficients , but I don't understand his reasoning. I originally posted this on MathOverflow , now deleted.","['multisets', 'combinatorics']"
114658,How should I deal with this two-dimensional $\frac{0}{0}$ limit?,"Here is my question : Does the following limit exist?
  $$
\lim_{y\to\xi}\frac{(\xi_i-y_i)(\xi_j-y_j)({{\xi}-y})\cdot n(y)}{|\xi-y|^5},\quad 1\leq i,j\leq 3,\tag{*}
$$
  where $S\subset{\mathbb R}^3$ is a surface which has a continuously varying normal vector, $\xi=(\xi_1,\xi_2,\xi_3)\in S$, $y=(y_1,y_2,y_3)\in S$, $n(y)$ is the [EDITED: unit] normal vector at point $y$. Here $(\xi-y)\cdot n(y)$ is the dot product. In the spirit of Polya, I find a simpler case where $S$ is a unit sphere. Then we have $n(y)=y$. But I don't have a strategy to go on.","['multivariable-calculus', 'differential-geometry', 'limits']"
114662,Isomorphism of representations of the symmetric group,"This might be a silly question, but I don't understand why the solution to the following problem implies the result: Let $A = \mathbb{C}S_d$ and let $c_{\lambda}$ denote the Young symmetrizer (with $c_{\lambda} = a_{\lambda}b_{\lambda}$). The problem asks to show that $Aa_{\lambda}b_{\lambda} \cong Ab_{\lambda}a_{\lambda}$. The solution says to consider the maps from $Aa_{\lambda}b_{\lambda} \to Ab_{\lambda}a_{\lambda} \to Aa_{\lambda}b_{\lambda}$ given by multiplication by $a_\lambda$ and $b_\lambda$ respectively. The composite is a scalar multiplication on a vector space (since $c_\lambda$ is idempotent) and hence an isomorphism. I understand all this argument, but how does it follow from this that implies the needed isomorphism? A composite map on an vector space that is an isomorphism certainly does not imply that the component maps are isomorphisms... edit: Also, it seems that every element $Aa_\lambda b_\lambda$ can be written as $e_g e_p e_q$ where $e_g \in A$, $e_p$ and $e_q$ are components of the sums $a_\lambda$ and $b_\lambda$. So can I just write an explicit map $e_g e_p e_q \mapsto e_g e_q e_p$? Is it right to sa that this doesn't work because this is a bijection but not an isomorphism?","['linear-algebra', 'representation-theory']"
114664,"Evaluate  $\int_0^1 {\ln(1+x)\over x}\,dx$.","How would one evaluate   $\int_0^1 {\ln(1+x)\over x}\,dx$? I'd like to do this without approximations. Not quite sure where to start. What really bothers me is that I came across this while reviewing my old intro to calculus book... but I'm fairly certain I've exhausted all the basic methods they teach in that text.","['logarithms', 'calculus', 'integration']"
114676,Proving that Continuous Open Functions are Strictly Monotonic,"It is a fact from analysis that a continuous and open real-valued function of a real variable is strictly
monotonic. The proof I know runs something like this: Suppose $f$ is an open and continuous map but is not 
strictly monotonic. Consequently, there exist three numbers $a < c < b$ such that either
$$
f(a) \geq f(c) \leq f(b) \;\;\;\; (1)
$$
or
$$
f(a) \leq f(c) \geq f(b) \;\;\;\; (2)
$$
If $(1)$ holds then the exteme value theorem guarantees that $f$ attains its infimum on $[a,b]$; but by assumption,
the infimum is at least as small as $f(c)$ so in fact $f$ attains its infimum on $(a,b)$. Also by assumption,
$f$ carries open intervals to open intervals. With this though we have a contradiction since an open
interval cannot contain it's own infimum. A similar argument yields considering suprema yields an
analagous contradiction. Therefore, $f$ is strictly monotonic. My question is, Is there a more constructive way to prove this that doesn't involve contradiction? Although I think 
the proof given is nice, I don't think I could have come up with it own my own because the consequences of $f$ not being strictly monotonic as exhibited in (1) and (2)
would not have occurred to me. So, it would be good to see a direct way of proving this.",['real-analysis']
114678,Unit group of power series ring,"Is there any way to calculate the multiplicative group of the units of power series ring $k[[x]]$, where $k$ is a field ?","['power-series', 'abstract-algebra']"
114694,Proving Cauchy's Generalized Mean Value Theorem,"This is an exercise from Stephen Abbott's Understanding Analysis . The hint it gives on how to solve it is not very clear, in my opinion, so I would like for a fresh set of eyes to go over it with me: pp 143 Exercise 5.3.4. (a) Supply the details for the proof of Cauchy's Generalized Mean Value Theorem (Theorem 5.3.5.). Theorem 5.3.5. (Generalized Mean Value Theorem). If $f$ and $g$ are continuous on the closed interval $[a,b]$ and differentiable on the open interval $(a,b)$, then there exists a point $c\in(a,b)$ where$$[f(b)-f(a)]g'(c)=[g(b)-g(a)]f'(c).$$If $g'$ is never zero on $(a,b)$, then the conclusion can be stated as$$\frac{f'(c)}{g'(c)}=\frac{f(b)-f(a)}{g(b)-g(a)}.$$ * Hint: This result follows by applying the Mean Value Theorem to the function *$$h(x)=[f(b)-f(a)]g(x)-[g(b)-g(a)]f(x)$$ First of all, I know that the Mean Value Theorem (MVT) states that if $f:[a,b]\to\mathbb{R}$ is continuous on $[a,b]$ and differentiable on $(a,b)$, then there exists a point $c\in(a,b)$ where$$f'(c)=\frac{f(b)-f(a)}{b-a}.$$ If we assume that $h$ has the above properties, then applying the MVT to it, for some $c\in(a,b)$, would yield$$h'(c)=\frac{h(b)-h(a)}{b-a}=$$ $$\frac{[f(b)-f(a)]g(b)-[g(b)-g(a)]f(b) \quad - \quad [f(b)-f(a)]g(a)+[g(b)-g(a)]f(a)}{b-a}=$$ $$[f(b)-f(a)]\left(\frac{g(b)-g(a)}{b-a}\right) \quad - \quad[g(b)-g(a)]\left(\frac{f(b)-f(a)}{b-a}\right)=$$ $$[f(b)-f(a)]g'(c) \quad - \quad [g(b)-g(a)]f'(c).$$This is the best I could achieve; I have no clue on how to reach the second equation in the above theorem. Do you guys have any ideas? Thanks in advance!","['proof-verification', 'real-analysis']"
114703,Limit of positive sequence $(f_n)$ defined by $f_n(x)^2=\int^x_0 f_{n-1}(t)\mathrm{d}t$,"Assume $f_{0}(x)$ is integrable in $[0,1]$, $f_{0}(x)>0$.
$$f_n(x)=\sqrt{\int^x_0 f_{n-1}(t)\mathrm{d}t}, \quad n=1,2,...$$ How can one calculate $\lim\limits_{n \to {\infty}}f_n(x)$?","['calculus', 'real-analysis']"
114711,A question on Jacobi sums,"I am trying to work through Ireland and Rosen's Number theory book. Following is ex. 26, ch.8(Gauss and Jacobi sums). Let $p$ be a prime. $p\equiv 1\mod{4}$, $\chi$ a multiplicative character of order 4 on $F_{p}$, and $\rho$ the Legendre symbol. Put $J(\chi,\rho)=a+bi$. Show 1.) $N(y^2=1-x^4)=p+\sum \rho(1-x^{4})$ 2.) $2a\equiv -(-1)^{(p-1)/4}(^{2m}_{m})(p)$ where $m=(p-1)/4$ I am not a mathematician so I find it difficult many times to use abstract theory to solve concrete problems(assuming I understand the theory in the first place!). I would like to see how to solve one of these(or both) problems and at least a hint for the other one, since I am not sure how to proceed with these problems. Thank you for your time.","['finite-fields', 'number-theory']"
114723,How to prove that $\frac{\cos\alpha}{\cos\beta}=a/b$,"If $\alpha \not= \beta$, and $$ a\tan \alpha+b\tan\beta=(a+b)\tan\frac{\alpha+\beta}{2}$$ then can we prove that $\frac{\cos\alpha}{\cos\beta}=\frac{a}{b}$? Seems like I am stuck on this one.","['trigonometry', 'algebra-precalculus']"
114727,understanding a proof of the hitting time theorem for a right-continuous random walk using generating functions,"This is particularly directed at those who have Grimmett & Stirzaker, Probability and random processes (2005), at hand.
It pertains to the proof step prior to equation (10), p. 166.
For others: $X_i$ are i.i.d. integer-valued random variables with
$\mathbb{P}(X_i \leq 1) = 1$ and $\mathbb{P}(X_i = 1) > 0$. $T_b=\min\{n:\sum_{i=1}^n X_i = b\}>0$ is the first hitting time of the point $b$. $G(z) = \mathbb{E}\left(z^{-X_1}\right)
 = \sum_{n=-\infty}^1 z^{-n} \mathbb{P}(X_1=n)$ $F_b(z) = \mathbb{E}\left(z^{T_b}\right)
 = \sum_{n=0}^\infty z^n \mathbb{P}(T_b=n)$ equation (9): $F_b(z) = F_1(z)^b$ for $b \geq 1$ I'm not understanding how to prove
$$
\mathbb{E}(\mathbb{E}(z^{T_1}|X_1))
 = \mathbb{E}(z^{1+T_{1-X_1}})
 = z \mathbb{E}\left(F_{1-X_1}(z)\right)
 = z \mathbb{E}\left(F_1(z)^{1-X_1}\right)
 = z F_1(z)G(F_1(z))
$$ In J. G. Wendel, ""Left-continuous random walk and the Lagrange expansion"" (1975),
he argues in essence that
$$
\begin{align*}
\mathbb{E}(\mathbb{E}(z^{T_1}|X_1))
 & = \sum_{n=-1}^\infty \mathbb{E}(z^{T_1}|X_1=-n)\ \mathbb{P}(X_1=-n) \\
 & = z \mathbb{P}(X_1=1) + \sum_{n=0}^\infty \mathbb{E}(z^{T_1}|X_1=-n)\ \mathbb{P}(X_1=-n)
 & T_1=1 \Leftrightarrow X_1=1 \\
 & = z \mathbb{P}(X_1=1) + \sum_{n=0}^\infty \mathbb{E}(z^{1+T_{1+n}})\ \mathbb{P}(X_1=-n)
 & \textrm{homogeneity} \\
 & = z \mathbb{P}(X_1=1) + z \sum_{n=0}^\infty F_{1+n}(z)\ \mathbb{P}(X_1=-n)
 & \textrm{definition of }F \\
 & = z \mathbb{P}(X_1=1) + z \sum_{n=0}^\infty F_1(z)^{1+n}\ \mathbb{P}(X_1=-n)
 & \textrm{equation (9)} \\
 & = z F_1(z) \sum_{n=-1}^\infty F_1(z)^n\ \mathbb{P}(X_1=-n) \\
 & = z F_1(z) G(F_1(z))
 & \textrm{definition of }G
\end{align*}
$$ In the second line, $n=-1$ is treated specially,
because the temporal and spatial homogeneity assumptions don't apply to it.
Specifically, the further time required to hit 1 is 0;
applying the homogeneity assumptions would imply $T_0=0$,
which isn't allowed, hitting times are positive. In the fifth line, applying equation (9),
you can see that $n=-1$ needs to be treated specially there as well. So although
$\mathbb{E}(\mathbb{E}(z^{T_1}|X_1)) = z F_1(z)G(F_1(z))$,
it seems that Grimmett's intermediate steps are nonsensical.
Or can you see his logic? Incidentally,
$$
\mathbb{E}\left(F_1(z)^{1-X_1}\right)
 = \sum_{n=0}^\infty F_1(z)^n\ \mathbb{P}(1-X_1=n)
 = \sum_{n=-1}^\infty F_1(z)^{1+n}\ \mathbb{P}(X_1=-n)
 = F_1(z)G(F_1(z))
$$
so the subsequent application of Lagrange's inversion formula on p. 166 is still done correctly.","['random-walk', 'probability']"
114733,Mapping half-plane to unit disk?,Say you have the half-plane $\{z\in\mathbb{C}:\Re(z)>0\}$. Is there a rigorous explanation why the transformation $w=\dfrac{z-1}{z+1}$ maps the half plane onto $|w|<1$?,['complex-analysis']
114750,How many combinations of 6 items are possible?,"I have 6 items and want to know how many combinations are possible in sets of any amount. (no duplicates) e.g. It's possible to have any of the following: 1,2,3,4,5,6 1,3,5,6,2 1 1,3,4 there cannot be duplicate combinations: 1,2,3,4 4,3,2,1 Edit: for some reason I cannot add more comments. @miracle173 is correct. Also {1,1} is not acceptable",['combinatorics']
114772,Proof of the Gauss-Green Theorem,"I can't seem to find any references that gives a proof of the Gauss-Green theorem : Let $U\subset\mathbb{R}^{n}$ be an open, bounded set with $\partial U$ being $C^1$ . Suppose $u\in C^{1}(\bar{U})$ , then $$\int_{U}{\frac{\partial u}{\partial x_i}}dx=\int_{\partial U}u\nu^{i}dS\;\;\;\;(i=1,\ldots,n),$$ where $\nu=(\nu^1,\ldots\nu^n)$ denotes the outward-pointing unit normal vector field to the region $U$ . Evans' PDE textbook presents the theorem (with no proof) in the appendix, and proceeds to use it to derive Green's formulas and the formula for $n$ -dimensional integration by parts. So I'd really like to have a proof of the theorem for future reference.","['greens-theorem', 'multivariable-calculus', 'integration', 'partial-differential-equations']"
114777,Change of Variables Clarification,"How can we show that $v(L(C)) = |\det DL|v(C)$ for any open cube $C$ an element of $\mathbb{R}^n$ and any linear transformation $L: \mathbb{R}^n \rightarrow \mathbb{R}^n$, without direct applying the change of variables theorem? Thanks",['analysis']
114782,Nowhere differentiability of Space-filling curves?,"In a homework assigment, we were given a certain recursive definition of a space-filling curve $f : [0,1] \mapsto [0,1]^2$ and asked to determine where it is differentiable. My intuition tells me that (as a fractal construction is involved) the curve should be nowhere differentiable . I think I finally came up with an elementary proof for this particular curve, however it's quite messy with quite some case distinctions necessary. So looking for a more elegant proof, my question is : Does the mere fact that $f$ is a space-filling curve, i.e. surjective and continuous, already allow us to deduce where $f$ is differentiable? And if so, how elementary can such a proof be? Yet, we don't know Brouwer fixed-point theorem etc.","['general-topology', 'real-analysis']"
114783,Prove the opposite angles of a quadrilateral are supplementary implies it is cyclic.,"There is a well-known theorem that a cyclic quadrilateral (its vertices all lie on the same circle) has supplementary opposite angles. I have a feeling the converse is true, but I don't know how to prove it. The converse states: If a quadrilateral's opposite angles are supplementary then it is cyclic. Should I approach this proof by contradiction? Or is it possible to prove by construction?",['geometry']
114784,Bennett's Inequality to Bernstein's Inequality,"Bennett's Inequality is stated with a rather unintuitive function, $$
h(u) = (1+u) \log(1+u) - u
$$ See here .  I have seen in multiple places that Bernstein's Inequality, while slightly weaker, can be obtained by bounding $h(u)$ from below, $$
h(u) \ge \frac{ u^2 }{ 2 + \frac{2}{3} u}
$$ and plugging it back into Bennett's Inequality.  However, I can't see where this expression comes from .  Could someone point me in the right direction?","['probability-theory', 'pade-approximation', 'inequality', 'real-analysis']"
114799,Is Completeness intrinsic to a space?,"Is completeness an intrinsic property of a space that is independent of metric? For example, since $\mathbb{R}^n$ is complete with the Euclidean metric, is it complete with any other metric? If completeness is an intrinsic property, why is it intrinsic? Thanks :)","['metric-spaces', 'convergence-divergence', 'analysis']"
114800,Infinite Series: Fibonacci/ $2^n$ [duplicate],"This question already has answers here : How to prove the Fibonacci sum $\sum \limits_{n=0}^{\infty}\frac{F_n}{p^n} = \frac{p}{p^2-p-1}$ (3 answers) Closed 7 years ago . I presented the following problem to some of my students recently (from Senior Mathematical Challenge - edited by Gardiner) In the Fibonacci sequence $1, 1, 2, 3, 5, 8, 13, 21, 34, 55,\ldots$ each term after the first two is the sum of the two previous terms. What is the sum to infinity of the series: $$\frac{1}{2} + \frac{1}{4}+ \frac{2}{8} + \frac{3}{16} + \frac{5}{32} +\frac{8}{64} + \frac{13}{128} +\frac{21}{256} +\frac{34}{512}+ \frac{55}{1024} + \cdots$$ Now, I solved this using an infinite geometric matrix series (incorporating the matrix version of the relation $a_n= \frac{a_{n-1}}{2}+ \frac{a_{n-2}}{4}$ ), and my students, after much hinting on my part, googled the necessary string to stumble across Binet's formula (which allows one to split the series into two simple, if rather messy, geometrics). Both of these are good methods, but neither really seems plausible for a challenge set for 15-18 year olds under exam conditions. So how is one supposed to do it?","['fibonacci-numbers', 'education', 'sequences-and-series']"
114826,Are two subgroups that contain a common element conjugate iff they are conjugate under the normalizer?,"I have two isomorphic subgroups $U,V\leq G$ and an element $a \in U \cap V$. Is it true that $U$ and $V$ are conjugate under $G$ if and only if they are conjugate under $N_G(\langle a \rangle)$? I vaguely remember hearing such a statement but at the moment I can neither think of a proof nor find a counterexample. Thanks in advance for any help.",['group-theory']
114840,"$y''=y-y^3$, $y,y'\in L^2(\mathbb R)$","I'm currently studying this non linear differential equation $$y''=y-y^3.$$ The assumption are that $y,y'$ are in $L^2(\mathbb R)$ , however no boundary conditions are assigned. I am asked to prove that $\mid y(x)\mid\le \sqrt 2.$ My attempt goes as follows: multiply both sides by $y'$ and integrate to obtain: $$(\clubsuit)\quad\mid y'(x)\mid=\sqrt{2\left(\frac{y^2}{2}-\frac{y^4}{4}+C_1\right)}.$$ Then what is inside the square root must be nonnegative, however I have no hypothesis on $C_1$ since no boundary conditions are provided. Another thing which should be useful is that $y^2\in L^1(\mathbb R)$ and, since $$\int {y^2}=2\int \mid yy'\mid\leq \left(\int y^2\right)^{1/2}\left(\int y'^2\right)^{1/2}< +\infty, $$ Then, by noticing that $$\mid y^2(t)-y^2(0)\mid=\mid\int_0^t (y^2)'\mid< C.$$ Hence $y$ is bounded. But nowhere from here. Hints? Finishing the exercise: As Julian pointed out, from the fact that $y\in L^2(\mathbb R)$ and it is bounded we conclude that $$\int y^4\leq \|y\|_\infty^2\int y^2< \infty,$$ so that $y\in L^4(\mathbb R).$ Squaring and integrating $(\clubsuit)$ one must conclude $C_1=0$ . The constant solutions are $$y=0.$$",['ordinary-differential-equations']
114848,"What does ""relatively closed"" mean?","Let $S\subset U$. What does it mean to say that $S$ is relatively closed in $U$? Also $U\subset\mathbb{R}^{n}$ is open and bounded, but I don't know if that's essential. Here follows an example from where I found the term, a sort of ""use it in a sentence"", if you like. Theorem 4 from chapter 2 of Partial Differential Equations by Lawrence C. Evans ($U\subset\mathbb{R}^{n}$ is open and bounded): Strong maximum principle . Suppose $u\in C^{2}\left(U\right)\cap C\left(\bar{U}\right)$ is harmonic within $U$. (1) Then $$\max_{\bar{U}}u=\max_{\partial U}u$$ (2) Furthermore, if $U$ is connected and there exists a point $x_{0}\in U$ such that $$u\left(x_{0}\right)=\max_{\bar{U}}u$$ then $$u\text{ is constant within }U.$$ Proof . Suppose there eixsts a point $x_{0}\in U$  with $u\left(x_{0}\right)=M:=\max_{\bar{U}}u$. Then for $0<r<\text{dist}\left(x_{0},\partial U\right)$, the mean-value property asserts $$M=u\left(x_{0}\right)=\frac{1}{V}\int_{B\left(x_{0},r\right)}udy\leq M.$$ As equality holds only if $u\equiv M$  within $B\left(x_{0},r\right)$, we see that $u\left(y\right)=M$  for all $y\in B\left(x,r\right)$. Hence the set $\left\{ x\in U|u\left(x\right)=M\right\}$ is both open and relatively closed in $U$, and thus equals $U$ if $U$ is connected. This proves assertion (2), from which (1) follows. $\blacksquare$ Thus, I need to know: What does it mean to say that $S\subset U$ is relatively closed in $U$? And, why if $U$ is connected it follows that $S=U$? Thanks.","['general-topology', 'terminology']"
114864,Why are properties lost in the Cayley–Dickson construction?,"Motivating question : What lies beyond the Sedenions? I'm aware that one can construct a hierarchy of number systems via the Cayley–Dickson process: $$\mathbb{R} \subset \mathbb{C} \subset \mathbb{H} \subset \mathbb{O} \subset \mathbb{S} \subset \ldots $$ ""Reals"" $\subset$ ""Complex"" $\subset$ ""Quaternions"" $\subset$ ""Octonions"" $\subset$ ""Sedenions"" $\subset$ $\ldots$ and that at each step you're given a multiplication table that tell how the elements interact. As you move up the ladder, certain ""nice"" properties are lost: ordering,  commutativity, associativity, multiplicative normedness, etc... Given the multiplication table, you can show that these properties don't hold. Eric Naslund noted that ""the first 4 are very special as they are the unique 4 normed division algebras over ℝ"", no surprise then that these $2^n$-ions have found quite a bit of use. I'm interested in the sequence itself however, irrespective of how useful a $2^{256}$-ion might be ( ducenti-quinquaginta-sex-ion ?). I feel like something deeper is going on here though that I don't understand. Why are these particular properties lost at each step? Is it possible to quantify the process such that, at the $2^n$-ion you can say something about the symmetry of the multiplication table*? * I'm making an ansatz that there is a connection between the symmetry of the multiplication table and these ""nice"" properties.","['octonions', 'abstract-algebra', 'hypercomplex-numbers', 'quaternions', 'sedenions']"
114878,Boundary of invertibles in a normed algebra,"A student and I are reading the book Introduction to Banach Spaces and Algebras, by Allan, and we're stuck.  Exercise 4.5 says: Let $A$ be a normed algebra with unit sphere $S$.  Let $a\in A$.  Then $a$ is a topological divisor of 0 if
  $$ \inf\{\|ab\|+\|ba\|:b\in S \}=0. $$
  Prove that every element in the frontier of $G(A)$ is a topological divisor of $0$. Here $G(A)$ is the collection of invertible elements of $A$.  I assume that the question really means to say that $A$ is a unital normed algebra.  Then the book already essentially proves this result for Banach algebras (Corollary 4.13). So if $B$ is the completion of $A$, and if $a$ is still in the frontier of $G(B)$, then we're done (the infimum obviously doesn't change if we replace $S$ by the unit sphere of $B$). Conversely, if there is an example of $a\in\partial G(A)$ with $a\in G(B)$, then we have a counter-example to the exercise.  So my question is: If $a\in\partial G(A)$ and $B$ is the completion of $A$, then is $a\in\partial G(B)$? Edit: Embarrassingly, I think I can now answer this! Let $A$ be the complex polynomials, interpreted as an algebra of continuous functions on the interval $[0,1]$.  A little bit of algebra shows that $G(A)$ consists of just the constant polynomials.  So $G(A)$ is actually closed (not open, which would be the case if $A$ were Banach).  So being careful about what ""frontier"" means, I guess $G(A)$ is its own frontier.  But then the exercise is trivially false, as the frontier of $G(A)$ contains invertibles. So the exercise seems wrong.  But somehow my counter-example seems cheap.  So a new question: Can the frontier of $G(A)$ contain a non-invertible element which is invertible in $B$?  Are there examples where $G(A)$ is open?","['banach-algebras', 'functional-analysis']"
114883,"Is there a ""closed"" form of sequence $u_{n+1}=\frac{u_n^2}{u_n+1}$","Let $u_0=1$ and $u_{n+1}=\frac{u_n^2}{u_n+1}, \forall n\in \mathbb{N}$. a) Find the formula of $u_n$? b) Calculate the limit $\displaystyle\varlimsup_{n\rightarrow \infty} (u_n)^{\frac{1}{n}}$.",['calculus']
114884,Is there an elementary method for evaluating $\displaystyle \int_0^\infty \frac{dx}{x^s (x+1)}$?,I found a way to evaluate $\displaystyle \int_0^\infty \frac{dx}{x^s (x+1)}$ using the assumption that $s\in\mathbb{R}$ and $0<s<1$. Apparently it should be easily extended to all $s\in\mathbb{C}$ with $0<Re(s)<1$. I posted my solution here: http://thetactician.net/Math/Analysis/Integral1.pdf I'm pretty sure there's a more concise method for evaluating it...and I'd also like to make the extension to $\mathbb{C}$ more rigorous. Any ideas?,['complex-analysis']
114888,Note on Ring Homomorphisms of Matrices Rings,"Assume that $\mathbb{F}$ is a field, and let $\mathbb{M}_{t}\left(
\mathbb{F}\right)  $ be the ring of matrices of order $t$ over $\mathbb{F}$. Does there exist a non-trivial ring homomorphism from $\mathbb{M}_{n+1}\left(
\mathbb{F}\right)  $ to $\mathbb{M}_{n}\left(  \mathbb{F}\right)  $?","['matrices', 'ring-theory', 'field-theory']"
114890,Yet another natural Connection on Riemannian manifolds?,"The exterior derivative $d:\mathcal{A}^1(M)\to\mathcal{A}^2(M)$ can be regarded as an connection on $T^*M\to M$. If $g$ is a Riemannian connection on $M$, we can can pull $d$ back to get an connection $\nabla$ on $TM\to M$, explicitly $$\nabla_XY:=\left(i_X(d(Y^\flat))\right)^\sharp,$$
where $TM\xrightarrow{\flat}T^*M\xrightarrow{\sharp}TM$ denote the canonical isomorphisms induced by $g$ and $i_X:\mathcal{A}^k(M)\to\mathcal{A}^{k-1}(M)$ is the contraction with $X$. One would expect $\nabla$ to be exactly the Levi-Civita-Connection, however I have calculated its Christoffel symbols as $$\Gamma_{ij}^k=\frac{1}{2}g^{lk}\left(\partial_ig_{jl}-\partial_lg_{ji}\right),$$ so we are missung missing the $\partial_j g_{il}$ summand inside the brackets. Did i make some stupid mistake or do we really have ""yet another canonical connection"" on $M$?! Robert","['riemannian-geometry', 'differential-geometry']"
114904,Huffman Code Proof,"Suppose we have an optimal preﬁx-free code on a set $C = \{0, 1, \dots , n − 1\}$ of characters and we wish to transmit this code using as few bits as possible. How to represent any optimal preﬁx-free code on $C$ using only $2n − 1 + n\lceil\log n\rceil$ bits. My approach: Begin with $n$ trees, each consists of a single node corresponding to one message word, with the weight of $p(i)$ Repeat until there is only one tree. pick two subtrees with smallest weights combine them by adding a new node as root, and make the two trees its children. The weight of the new tree is the sum of the weight of two subtrees With a heap, each step of combining tree takes $O(\log n)$ time, and the total time is $O(n \log n)$. Is there any solid proof?",['discrete-mathematics']
114914,Rationality test for a rational power of a rational,"It has been known since Pythagoras that 2^(1/2) is irrational. It is also obvious that 4^(1/2) is rational. There is also a fun proof that even the power of two irrational numbers can be rational. Can you, in general, compute whether the power of two rational numbers is rational? The reason I am asking, besides curiosity, is that the Fraction-type in Python always returns a float on exponentiation. If there is a quick way to tell if it could be accurately expressed as a fraction, the power function could conceivably only return floats when it has to. EDIT:
By popular demand, I changed 0.5 to 1/2 to make it clearer that it is a fraction and not a float.","['irrational-numbers', 'number-theory']"
114938,Tensor product of 2 coordinate rings,"For the term variety, I mean the irreducible algebraic set. My question is, if $V$ and $W$ are 2 varieties over a field $\Bbbk$, then does $\Bbb{k}[V]\otimes \Bbb{k}[W]$ has special structure? I try to prove that, it is another coordinate ring of another variety, which depends on $V$ and $W$. Then from the irreducible of $V$ and $W$ I reduced the problem to understand the tensor product of $\mathfrak{R}/\mathfrak{p} \otimes \mathfrak{R}/\mathfrak{q}$, which is known that isomorphic to $\mathfrak{R}/\mathfrak{(p+q)}$, where $\mathfrak{R}$ is a Noetherian ring(or a finitly generated algebra), and $\mathfrak{p},\mathfrak{q}$ are prime ideals of $\mathfrak{R}$. So, what can we imagine the element of $\mathfrak{R}/\mathfrak{p} \otimes \mathfrak{R}/\mathfrak{q}$? I just can understand the tensor product for 2 things(roughly speaking): making bilinear map into linear map, and playing the role of a funtor acting on exact sequence. I could not imagine concretely the element of tensor product(for example, $u\otimes v$ where $u,v$ are two vectors). Therefore, I could not define the tensor product of 2 coordinate rings( there may be some different ways, please answer here if you got them). The above sentences describe my situation. Please help me point it out the intuitive picture of tensor product and help me to solve(prove/disprove) my initial question on tensor product of 2 coordinate rings. Thanks.","['commutative-algebra', 'algebraic-geometry']"
114939,"Compute $ \sum\limits_{k=0}^{m}(-1)^k {n \choose k} {n \choose m-k}$ and $\sum\limits_{A,B\subseteq X} |A\cup B|$ for some given finite set $X$","I've got a problem with deducing closed-form expressions for sums: $1) \ \sum_{k=0}^{m}(-1)^k {n \choose k} {n \choose m-k}$ $2) \ \sum_{A,B\subseteq X} |A\cup B|$ where $|X|=n$ Can anyone help me? In 1) I have no idea. I can use identity $\sum_{i=0}^{k} {n \choose i} {m \choose k-i}= {n+m \choose k}$ but I don't know if it will be useful. In 2) I was thinking about this way: $\sum_{A,B\subseteq X} |A\cup B|=\sum_{i=0}^{n} {n \choose i}\cdot i \cdot 2^i$. Explanation: firstly I choose subset with $i$ elements. I can do this in ${ n\choose i} $ ways. It's cardinality equals $i$ and secondly I choose $2^i$ subsets of choosen subset. But it gives a wrong answer even for $n=1$.. Moreover it's still not closed-form expression..",['discrete-mathematics']
114947,Under which circumstances is the Laplacian compact?,"I want to know when the Laplacian is a compact Operator. Do you know some good literature about this topic? For instance, is the Laplacian compact on the Sobolev space $H^2(\Omega)$?
Or maybe on the Hilbert space $C^{\infty}_c(\Omega)$ with the inner product $\langle f,g\rangle:=\int\limits_{\Omega}f\cdot g\text{ }dx$ ? Thanks you for your answers.","['operator-theory', 'sobolev-spaces', 'functional-analysis']"
114972,Inequality involving norm of matrix integral,"This question seems basic but I could not find an answer. I have seen the inequality
$$\left\|\int_a^b x(t) dt \right\| \leq \int_a^b \left\| x(t) \right\| dt $$
where $x(t) \in \mathbb{R}^n$ is a vector function and $\|\cdot\|$ is a vector norm, and $a < b$. I wonder if this also holds for matrices with induced norm, that is
$$\left\|\int_a^b X(t) dt \right\| \leq \int_a^b \left\| X(t) \right\| dt $$
where $X(t)$ is a matrix function and $\|\cdot\|$ is an induced matrix norm, and $a < b$.  If it is true, is there any reliable citation source?","['matrices', 'normed-spaces', 'inequality', 'integration']"
114974,"At most, how many new lines are obtained?","If there are $n$ straight lines in a plane, no two of which are parallel, and no three pass through the same point. Their points of intersection are joined. How could we prove that the maximum number of fresh lines thus obtained is given by $$ \frac{n(n-1)(n-2)(n-3)}8$$",['combinatorics']
114978,Algebraic closure for $\mathbb{Q}$ or $\mathbb{F}_p$ without Choice?,"I know the usual proof of the existence of an algebraic closure for any field using Zorn's Lemma. The answer to this previous question makes it clear that in general, some nonconstructive axiom (not necessarily the full AC) is needed to guarantee an algebraic closure. My question is if we can avoid any of this in the cases of $\mathbb{Q}$ and $\mathbb{F}_p$. Can algebraic closures for $\mathbb{Q}$ and $\mathbb{F}_p$ be constructed in ZF? Intuitively, it seems plausible to me that they can. There are two places I see a need for an AC-typed axiom in the construction of an algebraic closure: one is to create some order (i.e. bijection with $\mathbb{N}$) for the set of polynomials whose roots I need to adjoin; two is to handle what happens when I start adjoining roots and the polynomials start factoring into smaller factors. (Which factor do I approach first?) It seems to me that $\mathbb{Q}$ and $\mathbb{F}_p$ both have structure that could be used cleverly to resolve both of these points without recourse to AC. However, I don't see the path clearly.","['set-theory', 'axiom-of-choice', 'abstract-algebra', 'field-theory']"
114996,Prove that $N$ has a Poisson distribution with parameter $\lambda$.,"Let $\lambda > 0$, define the random variable $N$ as follows: where $U_1$, $U_2$, $\ldots$ is a sequence of iid $U(0,1)$ random variables. $U_1 \geq e^{-\lambda}, U_1U_2 \geq e^{-\lambda}, U_1U_2 \ldots U_N \geq e^{-\lambda}$ but $U_1U_2 \ldots U_N U_{N+1} < e^{-\lambda}$. Can we show that $N$ has a poission distribution with paramter $\lambda$? This is a homework problem. My thought is that we might possibly use $\log U_i/\lambda$, but I'm stuck so far... Any idea is helpful!",['probability']
114999,How do I calculate the derivative of matrix?,"I'd like to expand a real, symmetric and positive definite Matrix $M$ into a Taylor series. I'm trying to do $$ M (T) = M(T_0) + \frac{\partial M}{\partial T} (T-T_0) + \cdots$$ $T$ is a algebraic vector of parameters (e.g. temperatures at finite element nodes). I'm only interested in the first order term, i.e. the derivative of $M$ at $T_0$. My Professor tried to do this, but used unclear notation.","['matrices', 'calculus', 'numerical-methods']"
115015,Showing $\int_0^{2\pi} \log|1-ae^{i\theta}|d\theta=0$,"This is a homework problem for a second course in complex analysis. I've done a good bit of head-bashing and I'm still not sure how to solve it-- so I might just be missing something here. The task is to show that given $|a|<1$,
$$\int_0^{2\pi} \log|1-ae^{i\theta}|d\theta=0.$$ So right off the bat we can let $z=e^{i\theta}$ so that 
$$\int_0^{2\pi} \log|1-ae^{i\theta}|d\theta=\int_{|z|=1} \log|1-az|\frac{dz}{iz}=-i\int_{|z|=1} \log|1-az|{dz}.$$ After that I'm not sure if using the residue theorem is the way to go?","['integration', 'complex-analysis', 'analysis']"
115020,Hilbert Schmidt Norm-Rank-inequality,"Problem: Let $A_{n.n}$ be square complex matrix. Prove the following:
$$\left \| A \right \|=\left \| A \right \|_{HS}\Leftrightarrow  rank(A)\leqslant 1$$. Where $\left \| . \right \|_{HS} $ is the Hilbert Schmidt Norm. Please read my solution and tell me whether it is correct. If not, let me know where the mistake is. Proof of the implication $\Leftarrow $: If $rank(A)=0$, then in this case $A=0$. It follows that $\left \| A \right \|=\left \| A \right \|_{HS}=0$ If $rank(A)=1$, than: $ A=\begin{pmatrix}
A_{1}\\ 
\alpha _{2}A_{1}\\ 
...\\ 
\alpha _{n}A_{1}
\end{pmatrix}$ where $A_{1}$ is the first row of $A$ and in this case: $\left \| A \right \|=\left \| A \right \|_{HS}=\left \| A_{1} \right \|\sqrt{1+\alpha _{1}^{2}+...+\alpha _{n}^{2}}$ Proof of the implication $\Rightarrow $ We know that $\left \| A \right \|=max_{\left \| x \right \|=1}\left \| Ax \right \|$ On the other hand: $
A=\begin{pmatrix}
A_{1}\\ 
A_{2}\\ 
...
\\ A_{n}

\end{pmatrix}$. So, $$\left \| Ax \right \|=\left \| \begin{pmatrix}
\left \langle A_{1},x \right \rangle\\ 
\left \langle A_{2},x \right \rangle\\ 
...\\ 

\left \langle A_{n},x \right \rangle\end{pmatrix} \right \|=\sqrt{\left \langle A_{1},x \right \rangle^{2}+\left \langle A_{2},x \right \rangle^{2}+...+\left \langle A_{n},x \right \rangle^{2}}
$$ Where $
\left \langle A_{i},x \right \rangle$ is the inner product of $A_{i}$ and $x$ Using the Cauchy-Schwarz inequality: $\left \langle A_{i},x \right \rangle^{2}\leq \left \| A_{i} \right \|^{2}\left \| x \right \|^{2}$, we get: $\left \| A \right \|=max_{\left \| x \right \|=1}\left \| Ax \right \|\leq max_{\left \| x \right \|=1}\left \| x \right \|\left \| A \right \|_{HS}=\left \| A \right \|_{HS}$. In order to have the equality: $\left \| A \right \|=\left \| A \right \|_{HS}$, we should have: $\left \langle A_{i},x \right \rangle^{2}=\left \| A_{i} \right \|^{2}\left \| x \right \|^{2}
$ which occurs only if $A_{i}=\lambda _{i} x$. So, the rows of A are dependent, which implies that $rank(A)=1$. Note that the case $rank(A)=0$ happens when $A=0$ Please let me know if my solution makes sense.","['matrices', 'normed-spaces', 'linear-algebra']"
115022,Pdf of the difference of two exponentially distributed random variables,"Suppose we have two independent random variables $Y$ and $X$ , both being exponentially distributed with respective parameters $\mu$ and $\lambda$ . How can we calculate the pdf of $Y-X$ ?","['probability-distributions', 'probability', 'exponential-distribution']"
115023,How were trigonometrical functions of $\dfrac{2\pi}{17}$ calculated?,"I know they were calculated by Gauss, but how? Is there a method for calculating them?",['trigonometry']
115026,An uncountable family of measurable sets with positive measure,"Is there a family of measurable sets $\{E_\alpha\}_{\alpha \in A}$ , disjoint, uncountable and each one with positive measure?","['measure-theory', 'real-analysis']"
115029,Cauchy sequence,"Show that if $(x_{n})_{n}$ is a Cauchy sequence in X and $\lambda \in \mathbb{R}$, then the sequence $(\lambda x_{n})_{n}$, is also Cauchy in X. We know that for $(x_{n})_{n}$, we have $$\forall \epsilon >0:\exists N\in \mathbb{N} : n,m\ge N\implies ||x_{n}-x_{m}||\le \epsilon$$ We can also assume that $$||\lambda (x_{n}-x_{m})||\le \epsilon$$ So to prove this, we can say that: $$||\lambda (x_{n}-x_{m})||\le |\lambda |\cdot||x_{n}-x_{m}|| \le |\lambda|\epsilon$$ But I can't help but feel dubious about having the $\lambda$ at the end. Any tips?",['analysis']
115034,"A Hilbert basis for $L^2 ([0,1]\times[0,1])$","Let $\{f_n(x)\}$ and $\{g_n(x)\}$ be two Hilbert basis of $L^2 ([0,1])$ then $\{g_n(x)f_k(y)\}$ is a Hilbert basis for $L^2 ([0,1]\times[0,1])$. Obs: That is Orthogonal, and unitary is I proved with a slight use of Fubini-Tonelli. It is only missing the density part of the span.","['functional-analysis', 'real-analysis', 'analysis']"
115041,Show the sequence $a_{n} = \frac{1}{n+1} + \frac{1}{n+2} ... +\frac{1}{2n}$ converges to ln 2 [duplicate],"This question already has answers here : Closed 12 years ago . Possible Duplicate: Is $\lim\limits_{k\to\infty}\sum\limits_{n=k+1}^{2k}{\frac{1}{n}} = 0$? Please help me with this homework question. Let $\lbrace a_{n} \rbrace$ be the sequence defined by $$a_{n} = \frac{1}{n+1} + \frac{1}{n+2} ... +\frac{1}{2n}$$
for each positive integer $n$. Prove that this sequence converges to ln 2 by showing that $a_{n}$ is related to the partial sums of the series $\displaystyle\sum\limits_{k=0}^\infty (-1)^{k+1}/k.$ I know that $\displaystyle\sum\limits_{k=0}^\infty (-1)^{k+1}/k$ converges to ln 2. I also know that $s_{1} = 1,$ $s_{2} = 1/2,$ $s_{3} = 5/6,$ $s_{4} = 7/12,$ etc. However, I am having a hard time understanding how $\lbrace a_{n} \rbrace$ is related to the partial sum of the given series. Any help or hints are greatly appreciated.","['sequences-and-series', 'real-analysis', 'harmonic-numbers']"
115078,Is the support of a Borel measure measured the same as the whole space?,"Wikipedia says Let (X, T) be a topological space. Let μ be a measure on the Borel σ-algebra on X. Then the support
  (or spectrum) of μ is defined to be the set of all points x in X for
  which every open neighbourhood Nx of x has positive measure. The support of μ is a Borel-measurable subset, because The support of a measure is closed in X. I wonder if the support of μ is measured the same as the whole space? It is equivalent to that the complement of the support of μ has 0 measure. But the following property seems to say it is not true Under certain conditions on X and µ, for instance X being a
  topological Hausdorff space and µ being a Radon measure, a measurable
  set A outside the support has measure zero So when does the support of a measure on a Borel sigma algebra have different measure from the whole space?
Thanks!",['measure-theory']
115084,Cross products and integrals,"I have been told that the following equation is true, but I don't think it is all that obvious... could someone please explain why it is necessarily true? Suppose $C_1$ and $C_2$ are closed paths in $\mathbb R^3$, and $\vec{r}$ is a position vector, then
$$\oint_{C_1} d\vec{s}\times \left(\oint_{C_2}{d\vec{s'}\times \hat{r}\over |\vec{r}|^2}\right)=-\oint_{C_2} d\vec{s'}\times \left(\oint_{C_1}{d\vec{s}\times \hat{r}\over |\vec{r}|^2}\right)$$ My guess would be that we can somehow write the expressions on both sides as a simpler cross-product and $\oint_{C_1} d\vec{s}\times \left(\oint_{C_2}{d\vec{s'}\times \hat{r}\over |\vec{r}|^2}\right)$ say equals to $\vec{a}\times \vec{b}$ and $\oint_{C_2} d\vec{s'}\times \left(\oint_{C_1}{d\vec{s}\times \hat{r}\over |\vec{r}|^2}\right)$ equals $\vec{b}\times \vec{a}$? Just to be clear, $C_1,C_2$ are fixed in  shape and location in $\mathbb R^3$. As @joriki has pointed out, $\vec{r}$ should be $s-s'$ (resp. $s'-s$)","['multivariable-calculus', 'integration']"
115085,Elementary Set Theory Question,"I am working on the following question. Let $X$ be a nonempty set and consider a map $f:X\to Y$. Prove that the following are equivalent: (a) $f$ is injective; (b) there exists $g:Y\to X$ such that $g∘f=1_{X}$ where $1_{X}:X\to X$ is the identity map; (c) for any set $Z$ and any maps $h_{1},h_{2}:Z\to X$, the equation $f∘h_{1}=f∘h_{2}$ implies that $h_{1}=h_{2}$. (*I would like to add here that the ""$1$"" from each ""$1_{X}$"" is supposed to be written with the Math Blackboard font - I'm not sure how to do that*) My issue at the moment arises from being unable to understand (some of) the notation and ideas. I will attempt to describe in my own terms what I believe to understand. I apologize for the terribly imprecise language. You will see why I am not ready to prove anything yet. (a) That the function $f$ is injective means that it never maps distinct elements of its domain to the same element of its codomain. So every element from the set $X$ maps to a unique element in the set $Y$. And vice versa. A function of the form $f(x)=ax+c$ would be injective (and also a bijection) while a function of the form $f(x)=ax^{2}+bx+c$ would not be (assuming no restrictions on the domain). (b) This part states that there exists a function $g$ that maps the set $Y$ to the set $X$. The rest I am not sure of. The composite function $g∘f$ equals the identity map $1_{X}$. Does the identity map simply map X back onto X? For instance if $X=\left \{ 1,2 \right \}$, does $1_{X}$ map $1 \to 1$ and $2 \to 2$? So this part would mean, informally, that if you take an element from $Y$, replace it with its corresponding element from $X$, and then map it back to the same element from $X$, you get the identity map. Essentially each element from $Y$ maps to one element from $X$ and you can go back and forth between the sets. (c) Now the final part. There is a set $Z$ and two maps $h_{1}$, and $h_{2}$, both of which map the set $Z$ to the set $X$. Furthermore (and I dont know if this notation is acceptable), $$f:(h_{1}:Z \to X) \to Y=f:(h_{2}:Z \to X) \to Y.$$ I'm not seeing why this shows that $f$ is injective. I apologize again for this clutter. This is my first real exposure to set theory for my first year Calculus course and our textbook (Stewart) does not cover this. Writing this out has actually helped me to get a better grasp of what I am trying to prove, though I doubt it looks that way. Any help would be appreciated.","['calculus', 'elementary-set-theory']"
115105,"Question on the presentation of $(\mathbb{R}, +)$","In this question , it is shown that $(\mathbb{R}, +)$ is not a free group.  But my question is: if it is not a free group, exactly what relations is it subject to? My other question is: are there sets other than $\mathbb{R}$ that generate $(\mathbb{R}, +)$?","['free-groups', 'group-theory']"
115113,Bound for the Legendre function of the second kind of degree $1/2$,"Let $Q_{1/2}(u)$ be the Legendre function of the second kind of degree $1/2$. One can show that $Q_{1/2}(u) = O(u^{-3/2})$ as $u\to \infty$; see Equation 21 in Section 3.9.2 of Higher transcendental functions , the Bateman Manuscripta Project Volume 1 . I'm looking for a more precise statement. Namely, I would like to know if one can prove an upper bound for $Q_{1/2}(u)$ of the form $c u^{-3/2}$, where $c$ is an explicit real number. Where can I find this, or how can I derive this?","['special-functions', 'inequality', 'functions', 'estimation']"
115121,Elementary proof that there are infinitely many primes of form $7+10n$,"Is there a known ""elementary"" proof that there are infinitely many
  primes congruent to 7 modulo 10? Dirichlet's well known theorem gives that there are infinitely many such primes, as 10 and 7 are coprime. But Dirichlet's result is not ""elementary"" (even though one can in essence give a real variable proof. I am using elementary here in a somewhat intuitive sense). There is a well-known result of Murty showing that there is no ""Euclidean"" proof of this fact (see here and here ). One way of formalizing Murty's result is by saying that, for $a,m$ relatively prime, a polynomial for $a,m$ is a $p\in{\mathbb Z}[x]$ such that for all but finitely many $n$, the prime factors of $p(n)$ are congruent to 1 or $a$ modulo $m$ and, infinitely often, the second possibility occurs. Murty argues that ""Euclidean"" proofs all produce such polynomials, and his proof gives that if there is such a $p$, then $a^2\equiv 1\pmod m$. In particular, there is no polynomial for $2,5$, so there is no Euclidean proof that there are infinitely many primes of the form $5t+2$ or, equivalently, $10t+7$. But an elementary proof does not need to be a ""Euclidean"" proof. I would settle for a proof that uses a modest amount of algebraic number theory. I would even be happy if it turns out that no elementary proof is known, but a proof that does not require the full machinery of Dirichlet's theorem is possible. Finally, I would also like to know of a source giving a more or less complete list of pairs $(a,b)$ for which there are known elementary proofs that there are infinitely many primes of the form $at+b$. I know Narkiewicz discusses some pairs in section 2.5 of his ""The development of prime number theory"" and refers to Dickson's ""History of the theory of numbers"". It may be these are the sources. But just in case there are some others, I would appreciate a reference.",['number-theory']
115123,Are these two notions of Galois morphism the same,Let $f:X\to Y$ be a finite morphism of integral schemes. Let $G$ be the automorphism group of $X$ over $Y$. Are the following two conditions equivalent? The function field extension $K(Y)\subset K(X)$ is Galois (in the field-theoretic sense) The quotient $X/G$ exists and the natural morphism $X/G\to Y$ is an isomorphism.,"['galois-theory', 'arithmetic-geometry', 'algebraic-geometry', 'covering-spaces']"
115143,Prove that $\varlimsup _{n\rightarrow \infty}(u_n)^{\frac{1}{n}}=1$ where $u_{n+1}=\frac{2u_n^3+2u_n^2+u_n}{2u_n^2+3u_n+1}$ and $u_0=1$.,"Prove that 
$$\varlimsup_{n\rightarrow \infty} (u_n)^{\frac{1}{n}}=1,$$ 
where $u_0=1$ and $$u_{n+1}=\frac{2u_n^3+2u_n^2+u_n}{2u_n^2+3u_n+1}\;.$$",['calculus']
115146,"Kummer's test - Calculus, Apostol, 10.16 #15.","I want to prove the following: Let $\{ a_n \}$ and $\{ b_n \}$ be two sequences with $a_n>0$ and $b_n>0$ for all $n \geq N$, and let $$c_n = b_n - \frac{a_{n+1}b_{n+1}}{a_n}$$ Then If there exists $r>0$ such that $0<r\leq c_n \text{ ; } \forall n\geq N$ then $\displaystyle\sum a_n$ converges. If $c_n\leq0$ for $n\geq N$ and if $\displaystyle\sum \dfrac{1}{b_n}$ diverges, then so does $\displaystyle\sum a_n$. So far I know how to use and prove Cauchy's, D'Alambert's and the integral criterion, so I'd like a hint on either using those or a new idea. The book suggests that for $1$, I show that $$\sum\limits_{k = N}^n {{a_k} \leq  \frac{{{a_N}{b_N}}}{r}} $$ and for $2$, to prove that $\displaystyle\sum a_n$ dominates $\displaystyle\sum \dfrac{1}{b_n}$ I'd like to prove this with previous theory on series convergence (Cauchy's and/or D'Alambert's preferrably, comparison test) since it is what precedes the problem, and would appreaciate great HINTS rather than answers. I can't seem to understand the inequalities. I mean, Cauchy's and D'Alambert's criteria reveal that the proof relies on the fact that a geometric series of with ratio $|r| < 1$ converges, but I can't understand the motivation in this proof. Summing up the work. For 1: $$\eqalign{
  & {b_N} = {c_N} + \frac{{{a_{N + 1}}}}{{{a_N}}}{b_{N + 1}}  \cr 
  & {b_N} = {c_N} + \frac{{{a_{N + 1}}}}{{{a_N}}}{c_{N + 1}} + \frac{{{a_{N + 2}}}}{{{a_N}}}{b_{N + 2}}  \cr 
  & {b_N} = {c_N} + \frac{{{a_{N + 1}}}}{{{a_N}}}{c_{N + 1}} + \frac{{{a_{N + 2}}}}{{{a_N}}}{c_{N + 2}} + \frac{{{a_{N + 3}}}}{{{a_N}}}{b_{N + 3}} \cr} $$ Induction over $n$ we get $${b_N} = {c_N} + \frac{{{a_{N + 1}}}}{{{a_N}}}{c_{N + 1}} + \frac{{{a_{N + 2}}}}{{{a_N}}}{c_{N + 2}} +  \cdots  + \frac{{{a_{N + n}}}}{{{a_N}}}{c_{N + n}} + \frac{{{a_{N + n + 1}}}}{{{a_N}}}{b_{N + n + 1}}$$ So $$\eqalign{
  & {b_N} \geqslant r\left( {1 + \frac{{{a_{N + 1}}}}{{{a_N}}} + \frac{{{a_{N + 2}}}}{{{a_N}}} +  \cdots  + \frac{{{a_{N + n}}}}{{{a_N}}}} \right) + \frac{{{a_{N + n + 1}}}}{{{a_N}}}{b_{N + n + 1}}  \cr 
  & {b_N} > r\left( {1 + \frac{{{a_{N + 1}}}}{{{a_N}}} + \frac{{{a_{N + 2}}}}{{{a_N}}} +  \cdots  + \frac{{{a_{N + n}}}}{{{a_N}}}} \right)  \cr 
  & \frac{{{a_N}{b_N}}}{r} > {a_N} + {a_{N + 1}} + {a_{N + 2}} +  \cdots  + {a_{N + n}} = \sum\limits_{k = N}^n {{a_k}}  \cr} $$ As desired.","['divergent-series', 'convergence-divergence', 'sequences-and-series']"
115150,Proving or refuting an inequality regarding the variance,"I'm trying to prove, or find a counterexample, for the following problem: Let $Y = \{y_i\}_{i=1}^n$ be a set of data, where $y_i \ge 1$ for $i \in \{1,\ldots,n\}$, and let $\alpha$ be a natural number. Then the following holds between the variances of $Y$ and $Y^\alpha = \{y_i^\alpha\}_{i=1}^n$: $Var[Y] \le Var[Y^\alpha]$ Note that: $Var[Y] = \frac{1}{n}\sum_{i=1}^n(y_i - E[Y])^2$ $Var[Y^\alpha] = \frac{1}{n}\sum_{i=1}^n(y_i^\alpha - E[Y^\alpha])^2$ I tried a lot of examples, and a term-wise comparison always resulted in the following (for all $i \in {1,\ldots,n}$): $(y_i - E[Y])^2 \le (y_i^\alpha - E[Y^\alpha])^2$ I'm still not sure if that's the case, but since I couldn't find any counterexamples, I used the identity $A^\alpha - B^\alpha = (A-B)(A^{\alpha-1} + A^{\alpha-2}B + \cdots + B^{\alpha-1})$ to expand left-hand side of the above inequality: $(y_i^\alpha - E[Y^\alpha])^2 = (ny_i^\alpha - (y_1^\alpha+\cdots+y_n^\alpha))^2/n^2
= [\sum_{1\le j \le n}(y_i^\alpha - y_j ^\alpha)]^2/n^2
= [\sum_{1\le j \le n}(y_i-y_j)(y_i^{\alpha-1} + y_i^{\alpha-2}y_j + \cdots + y_j^{\alpha-1})]^2/n^2$ and the value $(y_i^{\alpha-1} + y_i^{\alpha-2}y_j + \cdots + y_j^{\alpha-1})$ is at least $\alpha$, since we assumed that $y_i$'s are at least 1. But that's pretty much it, and I couldn't go any further, since the value $(y_i-y_j)$ might be negative. Any help is appreciated. Please note that my approach might be totally wrong, so please feel free to use any suitable approach. Edit: I finally found an example which shows the term-wise approach does not work. Let $Y=\{2,7,9.7\}$, and consider $\alpha = 2$. Then, $E[Y] = 6.23$ and $E[Y^2] = 49.03$, and for $y_2$ (which is 7) we have: $(y_2 - E[Y])^2 = 0.59$, which is greater than $(y_2^2 - E[Y^2])^2 = 0.0009$. Still, note that the inequality in question holds; i.e. $Var[Y] \le Var[Y^\alpha]$.","['statistics', 'inequality']"
115160,Is a von Neumann algebra just a C*-algebra which is generated by its projections?,"von Neumann algebras have the nice property that they are generated by their projections (the elements satisfying $e = e^{\ast} = e^2$) in the sense that they are the norm closure of the subspace generated by projections. This is a sensible property to require from the perspective of ""noncommutative measure theory"" where one thinks of von Neumann algebras as generalizations of algebras of the form $L^{\infty}(X)$ ($X$ a $\sigma$-finite measure space); here the projections are the indicator functions of measurable subsets of $X$ (modulo sets of measure zero) and the subspace generated by the projections are the simple functions. Does this property characterize von Neumann algebras among $C^{\ast}$-algebras?","['operator-algebras', 'functional-analysis']"
115188,Reference request for Geometric Group Theory,"I am doing a reading course this semester on Geometric Group Theory. I have been following A Course on Geometric Group Theory by Bowditch. The professor who is guiding me is not aware of good textbooks on Geometric Group Theory. I am looking for a supplement to Bowditch's book. Initially I began reading the book Groups, Graphs and Trees: An Introduction to the Geometry of Infinite Groups by John Meier. Although this is a nicely written book, I found its approach (and the professor I am reading under agreed) too combinatorial. Could someone suggest sources, especially ones that develop  the theory of hyperbolic groups and the related machinery in a self contained manner? I should mention that I do not have command over French or Russian, so sources should be in English.","['reference-request', 'geometric-group-theory', 'group-theory']"
115198,The derivative of a complex function.,"Question: Find all points at which the complex valued function $f$ define by $$f(z)=(2+i)z^3-iz^2+4z-(1+7i)$$ has a derivative. I know that $z^3$,$z^2$, and $z$ are differentiable everywhere in the domain of $f$, but how can I write my answer formally? Please can somebody help? Note:I want to solve the problem without using Cauchy-Riemann equations.",['complex-analysis']
115215,Evaluate if $\sin10°$ be expressed in real surd form? [duplicate],This question already has an answer here : Closed 12 years ago . Possible Duplicate: Calculating $\sin(10^\circ)$ with a geometric method Evaluate if $\sin10°$  be expressed in real surd form? Thank you!,['trigonometry']
