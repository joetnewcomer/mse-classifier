question_id,title,body,tags
661643,Prove trig identity: $(\sin \theta + 1)(\sin \theta − 1) = −\cos^2 θ$,"This is my attempt: $(\sin \theta+1)(\sin \theta-1) = \sin\theta^2 - \sin\theta + \sin\theta - 1$ $= \sin^2\theta - 1$ $= -\cos^2\theta$ Is it correct, and can it be improved? Thanks!",['trigonometry']
661644,How can I show it?,"Let $f$ be an absolute continuous function in $(0, 1)$ and satisfies 
$$
|f(x+h)+f(x-h)-2f(x)|\leq \text{const}\frac{|h|}{(\log\frac{1}{|h|})^{\gamma}} ,
$$ 
where $\gamma \in (0, 1)$ and $|h|$- is sufficiently small. 
Q: Is following 
$$
\int_{|h|}^{1-|h|}|f'(x+|h|)-f'(x)|dx\leq \text{const}\frac{1}{(\log\frac{1}{|h|})^{\gamma}}  
$$
  inequality true? If it is how can I show?","['real-analysis', 'analysis']"
661649,Derivative of a Linear Map,"I'm devastatingly incompetent at linear algebra and multivariable calculus. I just cannot understand it at all. Here's the easiest problem from my homework, and my attempt at solving it, and where I am stuck. Hopefully if I find at least one point of illumination in this problem, I may be able to find more light in this cold dark dungeon. The Problem: Suppose that $f:R^n\to R^m$ is linear. Show that $Df(x)$ exists for each $x\in R^n$ and $Df(x)=f(x)$ My attempt: Take any $x\in R^n$. Consider $$\lim_{h\to 0}\|f(x+h)-f(x)-Th\|/\|h\| = \lim_{h\to 0}\|f(x)+f(h)-f(x)-Th\|/\|h\| = \lim_{h\to 0}\|f(h)-Th\|/\|h\|$$ If there exists a linear map T such that this limit equals 0, then f is differentiable at x and $Df(x)=T$. My issues: I don't know where to go from there. If I assumed that $Th=Df(h)=f(h)$, I know that $$\lim_{h\to 0}\|f(h)-f(h)\|/\|h\|=0$$, but I don't know how to prove it the other way around.","['multivariable-calculus', 'linear-algebra', 'ordinary-differential-equations', 'derivatives']"
661666,Upper bound for area of polygons,"is there a formula for an upper bound for the area of a polygon, knowing the length of its edges? In the ideal situation, the answer would be a function $f_n(l_1,l_2,\dots,l_n)$ of the edges lengths (the number $n$ of edges is fixed). In a less ideal situation, the answer would be a function $g_n(p)$ of the perimeter (one function for every parameter $n$) which give a better estimation than the isoperimetric inequality (cf. example below). Isoperimetric inequality is not ideal as the following example shows: consider all parallelograms with sides $1$ and $a$. Then the maximum of area is $a$, obtained for the rectangle. But the isoperimetric inequality only gives $A\leqslant \frac{p^2}{4\pi}=\frac{(a+1)^2}{\pi}$. Edit: by polygons, I mean convex polygons. But if there exists a formula for the convex and nonconvex case, it will be fine for me (I guess that nonconvex polygons tend to have a smaller area than convex ones).","['geometry', 'estimation', 'area']"
661692,Find the probability of at least 1 three appearing when you roll 4 dice. Why is the probability low?,"If you roll 4 dice, what is the probability of at least 1 three appearing? I'm not sure if I did the calculation correctly but here it is: $\text{P(At least 1 three)} = P(1\mbox{ three}) + P(2\mbox{ threes}) +P(3\mbox{ threes}) +P(4\mbox{ threes})$ $(^4C_1)+(^4C_2)+(^4C_3)+(^4C_4)/6^{4} = 5/432$ I am not sure if I have calculated the probability correctly (probably not) but the probability of $5/432$ seems very low. Logically speaking, if you have more dice, you have more chances of a three appearing on at least one of them right? So why is the probability lower than the probability of getting a 3 on one dice (1/6)?",['probability']
661693,"Elementary Set Theory - Questions from final exam, check my answers","Yesterday I had my final exam in set theory, while I think it went pretty well, I'd like to doublecheck my answers, just so I could sleep at night. Would greatly appreciate any input. Question Find the cardinality of the following sets: a) the set of all sequences of natural numbers. b) the set of all monotonic ascending sequences of natural numbers For every set $A$ of real numbers, we define the subtraction set as: $\bar A=\{x-y\mid \forall x \in A \forall y \in A\}$
Find the cardinal of the following sets: a) $\{A \in P(\mathbb Z)\mid \bar A \subseteq (-1,1)\}$ b) $\{A \in P(\mathbb R)\mid \bar A =\{-1,0,1\}\}$ c) $\{A \in P(\mathbb R)\mid \bar A \subseteq (-1,1)\}$ My answers: 1.a - $c$ 1.b - $c$ 2.a - $\aleph_0$ 2.b - $c$ 2.c - $2^c$ Can also share my reasoning for said answers, but I just want to check if my answers are correct, rather than bore everyone with the details :)","['elementary-set-theory', 'proof-verification']"
661701,Prove that $\frac{1}{1*3}+\frac{1}{3*5}+\frac{1}{5*7}+...+\frac{1}{(2n-1)(2n+1)}=\frac{n}{2n+1}$,"Trying to prove that above stated question for $n \geq 1$. A hint given is that you should use $\frac{1}{(2k-1)(2k+1)}=\frac{1}{2}(\frac{1}{2k-1}-\frac{1}{2k+1})$. Using this, I think I reduced it to $\frac{1}{2}(\frac{1}{n^2}-(\frac{1}{3}+\frac{1}{5}+\frac{1}{7}+\cdots+\frac{1}{2n+1}))$. Just not sure if it's correct, and what to do with the second half.",['discrete-mathematics']
661726,"Prove that every compact metric space $K$ has a countable base, and that $K$ is therefore separable.","Prove that every compact metric space $K$ has a countable base, and that $K$ is therefore separable. How does the following look? Proof: For each $n \in \mathbb{N}$, make an open cover of $K$ by neighborhoods of radius $\frac{1}{n}$, and we have a finite subcover by compactness, i.e. $$K \subset \bigcup_{x \in K} N_{\frac{1}{n}}(x) \ \Rightarrow \ \exists x_1, ..., x_N \in K \text{ such that } K \subset \bigcup_{i=1}^{N} N_{\frac{1}{n}} (x_i)$$ Doing this for every $n \in \mathbb{N}$, we  get a countable union of finite collections of sets, so the collection of these sets, call it $S$, is countable. We claim that $S$ is a countable base for $K$, which is defined as a countable collection of open sets such that for any $x \in K$ and any open set $G$ with $x \in G$, there is some $V \in S$ such that $x \in V \subset G$. Let $x \in K$ and let $G$ be any open set with $x \in G$. Then since $G$ is open, there is some $r > 0$ such that $N_r(x) \subset G$. Choose $n \in \mathbb{N}$ such that $\frac{1}{n} < \frac{r}{2}$, so that the maximal distance between points in a neighborhood of radius $\frac{1}{n}$ is $r$. Then there must be some $i$ such that $x \in N_{\frac{1}{n}}(x_i) \subset N_r(x)$ because any neighborhood of radius $\frac{1}{n}$ containing $x$ cannot contain points a distance more than $r$ away. This shows that $S$ is a countable base. The second part of the question asks us to show that $K$ is separable. Let $\{V_n\}$ be our countable base for $K$. For each $n \in \mathbb{N}$, choose $x_n \in V_n$, and let $E = \{ x_n \ | \ n \in \mathbb{n} \}$. We claim that $E$ is a countable dense set, which would show that $K$ is separable. First, note that $E$ is clearly countable. To show that it's dense, we need to show that $\overline{E} = K$. This is equivalent to showing that $(\overline{E})^c = \emptyset$. Now $(\overline{E})^c$ is an open set because it's the complement of a closed set, $\overline{E}$. If $(\overline{E})^c$ is nonempty, then there is some $x \in (\overline{E})^c$, which is open, so since $\{V_n\}$ is a base, there is some $n$ such that $x \in V_n \subset (\overline{E})^c$, which implies that $x_n \in (\overline{E})^c$, a contradiction, because $x_n \in E \implies x_n \in \overline{E} \implies x_n \notin (\overline{E})^c$. Therefore, $(\overline{E})^c = \emptyset$, so that $\overline{E} = K$. Q.E.D.","['general-topology', 'second-countable', 'proof-verification', 'metric-spaces', 'compactness']"
661736,"Show that ${\rm Hom}(G,\mathbb{C}^{\star}) \cong G \cong {\rm Hom}(G,\mathbb{Q}/\mathbb{Z})$","How can I show that ${\rm Hom}(G,\mathbb{C}^{\star}) \cong G \cong {\rm Hom}(G,\mathbb{Q}/\mathbb{Z})$, where $G$ is finite abelian group, $\mathbb{C}$ is the set of complex number, $\mathbb{Q}$ is the set of rational, $\mathbb{Z}$ is the set of integers and ${\rm Hom}(A,B)$ is the set of all homomorphisms from a group $A$ to a group $B$.",['group-theory']
661746,"Prove that $\int\limits_0^1 x^a(1-x)^{-1}\ln x \,dx = -\sum\limits_{n=1}^\infty \frac{1}{(n+a)^2}$","Prove that $$\int_0^1 x^a(1-x)^{-1}\ln x \,dx = -\sum_{n=1}^\infty \frac{1}{(n+a)^2}$$ I know that we have a product of $x^a$, $\displaystyle\sum_{n=0}^\infty x^n$, and $\displaystyle\sum_{n=0}^\infty \frac{(1-x)^n}{n}$, but it hasn't helped me so far. Any tips? We are given that $a>-1$.","['sequences-and-series', 'calculus', 'integration', 'definite-integrals', 'real-analysis']"
661747,How to determine quantity of concavity?,"Given a function $f(x)$ I can determine whether its concave up or concave down by using the second derivative as it says e. g. here .
$$f''(x) > 0 \qquad \text{concave up}$$
$$f''(x) < 0 \qquad \text{concave down}$$ For instance
$$f(x) = x^2 \qquad f'(x) = 2x \qquad f''(x) = 2$$ Does that mean that since $f''> 0$ is true for all x, the function $f(x)$ is always concave up? And how can I determine the quantity of concavity? I thought somehow that $f''$ gives me the quantity but $f''$ is constant and to me it seems that the concavity of $f$ changes, so I guess this is wrong. I mean $f(x)$ has a stronger concavity around $x = 0$, hasn't it?","['derivatives', 'analysis']"
661752,Proving that $X$ is a Banach space iff convergence of $\sum\|x_n\|$ implies convergence of $\sum x_n$,"The following is an Exercise of Conway's Functional Analysis . Prove that $X$ is a $\,Banach$ space iff whenever $\{x_n\}$ is a sequence in $X$, such that $\sum \| x_n \| < \infty$, then $\sum x_n$ converges. I easily can show that if $X$ is a Banach space then $\sum x_n$ converges. My problem is showing that $X$ is a Banach space. For this I suppose that $\{s_n\}$ is a Cauchy sequence in $X$, then I want to make a series. For this I do not have any idea. Please help me.","['sequences-and-series', 'banach-spaces', 'normed-spaces', 'real-analysis', 'functional-analysis']"
661759,A closed ball in a metric space is a closed set,"Prove that a closed ball in a metric space is a closed set My attempt: Suppose $D(x_0, r)$ is a closed ball. We show that $X \setminus D $ is open. In other words, we need to find an open ball contained in $X \setminus D$. Pick $$t \in X-D \implies d(t,x_0) > r \implies d(t,x_0) - r > 0 $$ Let $B(y, r_1)$ be an open ball, and pick $z \in B(y,r_1)$. Then, we must have $d(y,z) < r_1 $. We need to choose $r_1$ so that $d(z,x_0) > r$. Notice by the triangle inequality $$ d(x_0,t) \leq d(x_0,z) + d(z,t) \implies d(z,x_0) \geq d(x_0,t) - d(z,t) > d(x_0,t) - r_1.$$ Notice, if we pick $r_1 = d(t,x_0)-r$ then we are done. Is this correct?","['general-topology', 'metric-spaces', 'real-analysis']"
661774,Visualize Fundamental Homomorphism Theorem for $\phi: A_4 \rightarrow C_3$,"Question 1. How do you see $\ker\phi = V_4 $ = Klein 4 group ? Book doesn't give formula for $\phi$? Question 2. What's $H$ in $i(aH) = \phi(a)$? I think $H = \ker\phi$ ? Question 3. Why is $i: \frac{A_4}{\ker\phi} \to C_3$ defined as $i(aH) = \phi(a)$ ? Why not just $i(aH) = a$ ? This is from Nathan Carter page 169  Visual Group Theory. Question 4. page 167 says 
When $\phi$ is not an embedding, somewhere it must collapse two domain elements to
one codomain element. In fact, because quotient maps follow a repeating pattern, every
coset of $\ker\phi$ will have at least two elements in it. Can someone please explain this last sentence?","['intuition', 'group-theory', 'visualization']"
661775,$A$ is open iff it is union of open balls,"Suppose $(X,d)$ is metric space. I want to show that $A \subseteq X$ is open iff $A$ is union of open balls. My attempt. suppose $A$ is open, then for every $x \in A$, there exists $r>0$ such that $B(x,r) \subset A$ by definition. We claim that $A = \bigcup_{x\in A} B(x,r) $. To see this, pick $x \in A$, then can find $r>0$ such that $x \in B(x,r) \subseteq \bigcup B(x,r)$. Conversely, suppose $y \in \bigcup B(x,r) \implies y \in B(x,r) $ for some $x$. But $B(x,r) \subseteq A$ for some $x$, hence $y \in A$. So, our claim is proved. For the other direction, suppose $A = \bigcup_{\alpha} O_{\alpha} $ where $O_{\alpha}$ is open ball. Take $x \in A$, then $x \in O_{\alpha} $ for some $\alpha$. But $O_{\alpha} \subseteq \bigcup O_{\alpha} = A $. So, we have found an open ball inside $A$, and since $x$ was chosen arbitrary, then $A$ must be an open set by definition. Is this correct? Any feedback would be greatly appreciated. thanks","['general-topology', 'real-analysis']"
661783,$X_n$ iid Poisson($\lambda$) with $\lambda>0$. Show that $\limsup_{n\rightarrow\infty}\frac{X_n\ln(\ln n)}{\ln n}=1$ a.s,"Let $X_n$ be iid Poisson random variables with parameter $\lambda>0$. Show that $\limsup_{n\rightarrow\infty}\frac{X_n\ln(\ln n)}{\ln n}=1$ with probability 1. I tried to use the Borell Cantelli's first and second lemmas in a usual way. Distribution is Poisson,hence  calculations got really messy, and I just gave up. Any other way or approach are welcome. I aimed to show $P(\frac{X_n\ln(\ln n)}{\ln n}\geq1+\epsilon \mbox{ infinitely often})=0$ and $P(\frac{X_n\ln(\ln n)}{\ln n}\geq1-\epsilon \mbox{ infinitely often})=1$ to conclude the result but again I could not continue after some point. Maybe there is an another way Thanks,","['probability-theory', 'probability-distributions', 'probability']"
661786,"If a finite group has all $p$-complements, is it always solvable?","On reading the question Subgroups of Prime Power Index I immediately thought ""if the group had a $p$-complement for each prime $p$ then it would be solvable"". But then I realized that the argument I had half-structured in my head was not actually correct, and I was not able to salvage it. My basic idea was that it seems like one could apply Hall's criterion for solvability by taking suitable intersections of $p$-complements to get the desired Hall-subgroups. But on further consideration, it is not so clear why this should work. Another idea was to do the same while looking at a minimal counterexample, but it was not clear to me why those $p$-complements should themselves satisfy the conditions (and hence, the minimality was not much use).","['finite-groups', 'group-theory']"
661801,infinite matrix leading eigenvalue problem,"I'm trying to find the leading eigenvalue and corresponding left and right eigenvectors of the following infinite matrix, for $\lambda>0$: $$
\mathrm{A}=\left(
\begin{array}{cccccc}
1 &e^{-\lambda} & 0 &0 &0 & \dots\\
1 &e^{-\lambda} & e^{-2\lambda} &0 &0 & \dots\\
1 &e^{-\lambda} & e^{-2\lambda} &e^{-3\lambda} &0 & \dots\\
\vdots & \vdots & \vdots & & \ddots
\end{array}
\right)
$$ Note that there are terms above the main diagonal. I know that in general infinite matrices aren't really a self-consistent idea, but from doing it numerically with $n\times n$ matrices using power iteration it looks like the problem converges in the limit of infinite $n$. The convergence is slower for smaller values of $\lambda$, but it looks like it probably converges for all $\lambda>0$. Note that I only care about the leading eigenvalue, i.e. the one with the largest magnitude, which should be real and positive. Its corresponding eigenvectors should have only positive entries, due to the Perron-Frobenius theorem. Alternatively, if it's easier, a solution for the following matrix will be just as useful to me:
$$
\mathrm{B}=\left(
\begin{array}{cccccc}
1 & 1& 0 &0 &0 & \dots\\
e^{-\lambda} &e^{-\lambda} & e^{-\lambda} &0 &0 & \dots\\
e^{-2\lambda} & e^{-2\lambda} &e^{-2\lambda} &e^{-2\lambda} &0 & \dots\\
\vdots & \vdots & \vdots & & \ddots
\end{array}
\right)
$$ Again note the terms above the diagonal. (The two problems are not equivalent, it's just that either one of them will help me solve a larger problem.) The problem is, I just don't have much of an idea how to do this. I've tried a variety of naive methods, along the lines of writing the eigenvalue equation $\mathrm{A}\mathbf{x} = \eta \mathbf{x}$ as a system of equations involving infinite sums and then trying to find $\{x_i >0\}$ and $\eta>0$ to satisfy them, but this doesn't seem to lead anywhere nice. It could be that there is no analytical solution. Or even worse it could be that these matrices have unbounded spectra after all (in which case I'd really like to know!), but if anyone has any insight into how to solve one of these two problems I'd really appreciate it.","['linear-algebra', 'sequences-and-series', 'systems-of-equations']"
661803,Irreducibility of $p(x)=x^4-4x^2+8x+2$ over $\mathbb{Q}(\sqrt{-2})$- Dummit Foote Abstract algebra $9.4.10$,"Question is : Prove that the polynomial $p(x)=x^4-4x^2+8x+2$ is irreducible over the quadratic field $F=\mathbb{Q}(\sqrt{-2})$. [Hint : first use the method of proposition $11$ for the U.F.D $\mathbb{Z}[\sqrt{-2}]$(cf.Exercise $8$, Section $8.1$) to show that if $\alpha \in \mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)$ then $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$ . Conclude that $\alpha$ must be $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ and hence show that $p(x)$ has no linear factor over $F$. Show similarly that $p(x)$ is not the product of quadratics with coefficients in $F$.] What I have done so far is : Suppose $\alpha \in\mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)=x^4-4x^2+8x+2$ we would then have : $p(\alpha)=\alpha^4-4\alpha^2+8\alpha+2=0\Rightarrow 2=\alpha(-\alpha^3+4\alpha-8)$ i.e., $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$. so, I have used the method of proposition $11$ for the U.F.D $\mathbb{Z}[\sqrt{-2}]$(cf.Exercise $8$, Section $8.1$) to show that if $\alpha \in \mathbb{Z}[\sqrt{-2}]$ is a root of $p(x)$ then $\alpha$ is a divisor of $2$ in $\mathbb{Z}[\sqrt{-2}]$ I do not understand why does he mentioned that $\mathbb{Z}[\sqrt{-2}]$ is U.F.D and all... I do not use that at all... It is unnecessarily confusing me or i am unnecessarily getting confused..
hint is actually misleading me :( Now, I have to prove that $\alpha$ must be $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ i.e., suppose I have $2=ab$ in $\mathbb{Z}[\sqrt{-2}]$ then, $N(2)=N(ab)\Rightarrow 4=N(a)N(b)$ i.e.,$N(a)=1\text{ or }2\text{ or } 4$ i.e., $p^2+2q^2=1\text{ or }2\text{ or } 4$ for $a=p+\sqrt{-2}q$ $p^2+2q^2=1\Rightarrow p=\pm 1 \Rightarrow a=\pm 1$ $p^2+2q^2=2\Rightarrow q=\pm 1\Rightarrow a=\pm\sqrt{-2}$ $p^2+2q^2=4\Rightarrow p=\pm 2\Rightarrow a=\pm 2$ Once I prove that those are the only divisors then I would consider : $p(1)=(1)^4-4(1)^2+8(1)+2\neq 0$ $p(-1)=(-1)^4-4(-1)^2+8(-1)+2\neq 0$ $p(\sqrt{-2})=(\sqrt{-2})^4-4(\sqrt{-2})^2+8(\sqrt{-2})+2\neq 0$ $p(-\sqrt{-2})=(-\sqrt{-2})^4-4(-\sqrt{-2})^2+8(-\sqrt{-2})+2\neq 0$ $p(2)=(2)^4-4(2)^2+8(2)+2\neq 0$ $p(-2)=(-2)^4-4(-2)^2+8(-2)+2\neq 0$ So, no divisor of $2$ is a root.. Thus $p(x)$ do not have a root in $\mathbb{Z}[\sqrt{-2}]$ suppose I have something like : $$x^4-4x^2+8x+2=(x^2+ax+b)(x^2+cx+d)=x^4+(a+c)x^3+(b+d+ac)x^2+(ad+bc)x+bd$$ But then, $bd=2\Rightarrow \text { b,d  are  a divisors of 2 in $\mathbb{Z}\sqrt{-2}$}$ But then we have seen that only divisors of $2$ in $\mathbb{Z}\sqrt{-2}$ are $\pm 1,\pm \sqrt{-2}$ or $\pm 2$ So, only possibilities are $x^4-4x^2+8x+2=(x^2+ax\pm 1)(x^2+cx\mp 2)$ $x^4-4x^2+8x+2=(x^2+ax\pm \sqrt{-2})(x^2+cx\mp \sqrt{-2})$ But these are not possible... This only tells that $p(x)$ is irreducible in $\mathbb{Z}[\sqrt{-2}]$ but then how do i show this is irreducible in $\mathbb{Q}(\sqrt{-2})$ I was expecting gauss lemma to help but it only works for integers and rationals... So, please help me to clear this.. Thank you... P.S : Proposition $11$ is Rational root theorem and Exercise $8$ is that ring of integers of $\mathbb{Q}(\sqrt{-2})$ is an Euclidean domain.","['irreducible-polynomials', 'abstract-algebra', 'field-theory']"
661812,Integration limits of the double integral after conversion to the polar coordinates,"I want to solve the following double integral: $$\int_0^{\infty}dx\int_{-\infty}^{\infty}dy\,f(x,y).$$ And for example I made a conversion to the polar coordinates, $x=r\cos{\theta}$ and $y=r\sin{\theta}$ and get a new integral where I plugged in new variables and multiplied the Integral with the Jacobian factor, in this case $r$. How could I find new integration limits in terms of $r$ and $\theta$ based on the integration limits in terms of $x$ and $y$?","['multivariable-calculus', 'improper-integrals', 'calculus', 'integration', 'definite-integrals']"
661813,"Find the limit of a multivariable function $f(x,y)=\frac{\ln(1+x^2y^2)}{x^2}$","The function is as follows: $f(x,y)=\frac{\ln(1+x^2y^2)}{x^2}$ and I want to calculate the following limit: $\lim_{(x,y)\to(0,y_0)}f(x,y)$ The reason I'm having trouble with this one is because the limit doesn't seem to be $0$ but $y_0^2$. Because of that, I need 2 functions to compare $f$ to, instead of one.
The greater one I found like this: $\ln(1+x^2y^2)\leq x^2y^2$ $\frac{\ln(1+x^2y^2)}{x^2}\leq y^2$ so (if I'm correct) the limit is definitely lower or equal to $y_0^2$. But I can't find the function to be my upper bound that also converges to that value.","['multivariable-calculus', 'limits']"
661846,Uniform convergence of Taylor series,"I am trying to show: If $f: B(0,R) \to \mathbb C$ is analytic then the Taylor series of $f$ at $0$ converges uniformly to $f$ in $B(0,r)$ for all $r\in (0,R)$ But I got stuck with my proof. Please can somebody help me? Here is what I have so far: From here I have 
$$ f(z) = \sum_{n=0}^\infty z^n {1\over 2 \pi i}\int_C {f(w) \over w^{n+1}}dw$$ Therefore the Taylor series of $f$ at $0$ is $T_0(z) = \sum_{n=0}^\infty z^n c_n$ where $c_n = {1\over 2 \pi i}\int_C {f(w) \over w^{n+1}}dw$. My idea is to apply the Weierstrass $M$-test here for $f_n(x) = z^n c_n$. It holds that $|z^n| < r^n$ and $|c_n|\le {M \over r^n}$ and therefore $|f_n(z)|\le M$. The problem is how to show $\sum_{n=0}^\infty M < \infty$? It is obviously not true (consider $R=1$). Where is my mistake?","['uniform-convergence', 'complex-analysis']"
661855,Is it faster to count to the infinite going one by one or two by two? [closed],Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 10 years ago . Improve this question A child asked me this question yesterday: Would it be faster to count to the infinite going one by one or two by two ? And I was split with two answers: In both case it will take an infinite time. Skipping half of the number should be really faster. Which brings me this question: Could an infinite be greater than another one?,['elementary-set-theory']
661891,Problems with fake proofs of limit of sequences,"I can hardly imagine an easier example of the fact that my understanding of the topic is more than rusty. I will divide the question in two parts to make the reading easier: 1) Background; 2) Problem. In the first part, I will show how I usually approach the proof that a sequence converge to a certain limit with an example, hopefully to get if what I am doing is right or wrong. In the second part I will show my ""proof"" of a wrong statement, hoping to see what's wrong there for sure. 1) BACKGROUND Let's assume the definition of the limit of a sequence (just to agree on the notation - with $M$ written as $M(\epsilon)$ to emphasize that it can be depend on $\epsilon$) $$ \lim_{n \rightarrow \infty} a_n = \mathcal{l} \Longleftrightarrow \forall \epsilon >0, \exists M(\epsilon) \in \mathbb{N}: \forall m \in \mathbb{N}( m > M(\epsilon) \longrightarrow | a_m - \mathcal{l}|< \epsilon).$$ What I learned is that I should proceed in two steps, assuming the LHS of the previous definition in order to establish the RHS: i) the ""scratch work"" (a.k.a. guessing-the-value-of-$M$), that does not appear in the proof, ii) and the actual proof. Example Prove that $\lim_{n \rightarrow \infty} \frac{1}{n} = 0$. Scratch work: In order to find $M$, the first thing we have to notice is that $$ \left| \frac{1}{n}-0 \right| < \epsilon \Longrightarrow \left| \frac{1}{n} \right| < \epsilon \Longrightarrow \frac{1}{n} < \epsilon \Longrightarrow \frac{1}{\epsilon} < n.$$ From this, we will set in the proof that $M=  \frac{1}{\epsilon} $. Proof : Let $\epsilon >0$ be an arbitrary real number. Let $M= \frac{1}{\epsilon} $, from which we have that $\epsilon = \frac{1}{M}$. Let $m$ be an arbitrary natural number, and assume that $m > M$. Thus, $\frac{1}{m} < \frac{1}{M}$. Hence, $$ \left| \frac{1}{m} - 0 \right| = \left| \frac{1}{m} \right| = \frac{1}{m} < \frac{1}{M} = \epsilon.$$
$\square$ 2) PROBLEM To state it precisely, I do have the feeling that between scratch work and proof, I can prove whatever I want, in particular false statements. Example Prove that $\lim_{n \rightarrow \infty} \frac{1}{n} = 1$. Scratch work: In order to find $M$, the first thing we have to notice is that $$ \left| \frac{1}{n}-1 \right| = \left| \frac{1-n}{n} \right| = \frac{1-n}{n} < \epsilon \Longrightarrow n > \frac{1}{1 + \epsilon}.$$ From this, we will set in the proof that $M=  \frac{1}{\epsilon + 1} $. Proof : Let $\epsilon >0$ be an arbitrary real number. Let $M= \frac{1}{\epsilon + 1} $, from which we have that $\epsilon = \frac{1-M}{M}$. Let $m$ be an arbitrary natural number, and assume that $m > M$, that is $m > \frac{1}{\epsilon + 1}$ and $\frac{1}{m} < \frac{1}{M}$. Hence, from $m > \frac{1}{\epsilon + 1}$ we get that $\frac{1 - m}{m} < \epsilon$, that after some algebraic manipulations gives us $$ \left| \frac{1}{m} - 1 \right| < \epsilon.$$
$\square$ Some thoughts There is (or maybe there are) an obvious mistake that I simply cannot see. Rephrasing my problem, I feel that after that I get the value of $M$ out of the scratch work, no matter if it comes from a reasonable limit or not, it's basically done. I assume that $m > M$ and, due to the fact that this implies that $m$ has to be higher than a certain expression with $\epsilon$, I always go back to the original formula, vacously (and wrongly) ""proving"" the result. Obviously it is a problem of a vicious circle, but I don't see where I start to make mistakes. Thanks a lot for any feedback, that will be more than welcome.","['calculus', 'algebra-precalculus', 'proof-verification', 'fake-proofs']"
661910,"Second order linear ODE, self adjoint (Sturm-Liouville) form. Orthogonality of solutions - confused about the weight factor.","If I have an ODE of the form $$a(x)y''+b(x)y'+c(x)y= \lambda y$$ Such that $b=a'$, then it is equivalent to: $$(a(x)y')'+c(x)y= \lambda y$$ So the solutions corresponding to two different eigenvalues (suppose they are indexed by integers) are orthogonal (suppose $x\in[0,1]$): $$\int_0^1 y_n(x)y_m(x)dx=\delta_{nm}||y_n||.$$ But now if $b \neq a'$, I want to multiply the equation through a weight $w(x)$ so that $wb =(wa)'$, therefore $$w(x)=\frac{1}{a} \exp{\int \frac{b}{a}}.$$ After this, the solutions are orthogonal, this time with the weight factor added in: $$\int_0^1 y_n(x)y_m(x) w(x)dx=\delta_{nm}||y_n||.$$ Is the above correct? If so, consider the Bessel equation: $$x^2y''+xy'+(x^2-n^2)y$$ The weight is $w(x)=\frac{1}{x}$, so why on earth does it say here that: $$\int_0^1 xJ_\alpha (xu_{\alpha,n})J_\alpha (xu_{\alpha,m})dx = \delta_{nm}(\text{stuff})$$ Are those 'scaled' Bessel functions solution to some different differential equation with weight $x$?","['ordinary-differential-equations', 'special-functions', 'bessel-functions']"
661922,Presentation of a non-trivial group,"I'm having a bit of trouble understanding group presentations.  For example, I'm reliably informed that the group $$
\langle x, y \mid x^2=y^3 \rangle
$$ is not the trivial group, but I don't see why not?  Why couldn't it be? Any help appreciated, thanks!","['geometric-group-theory', 'group-theory', 'group-presentation']"
661930,Proof that finite-dimensional Wiener process distributions are Gaussian,I have to prove that finite-dimensional Wiener process distributions are Gaussian and calculate them. How should I start? I know the definition and properties of Wiener process.,"['probability-theory', 'stochastic-processes', 'brownian-motion']"
661974,Intersecting circles and their angles,"There are 3 tangent circles: Now we move circles A and B such that they intersect C but do not intersect each other: In the figure, the angle near C increases. Will this always be the case? I tried to prove this using the law of cosines : $$\cos{\angle{C}} = \frac{a^2+b^2-c^2}{2ab}$$ When the circles are tangent, the following equations hold (where $r_X$ is the radius of circle $X$): $$a = R_B+R_C\ \ \ \ \ b=R_C+R_A\ \ \ \ c=R_A+R_B$$ But after we move them: $$a' < R_B+R_C\ \ \ \ \ b'<R_C+R_A\ \ \ \ c'>R_A+R_B$$ $a$ and $b$ decrease, while $c$ increases. The nominator of $\cos{\angle{C}}$ indeed decreases, but, so does the denominator, so this approach doesn't lead to a proof... Is it true that $\cos{\angle{C}}$ always increases, or maybe in some cases it can decrease?","['geometry', 'circles']"
661999,Are infinitesimals dangerous?,"Amir Alexander is a historian of mathematics.  His new book is entitled ""Infinitesimal: How a Dangerous Mathematical Theory Shaped the Modern World"".  See here . Two questions: (1) In what sense are these dangerous? (2) The ban on infinitesimals and the trial against Galileo's alleged endorsement of heliocentrism date from the same year: 1632 (and in fact occurred within a month of each other). Is there any reason for such a coincidence? What I find particularly interesting is Alexander's comment that infinitesimals were officially declared forbidden by catholic clerics on 10 august 1632.  The reason this is interesting is because the date 1632 falls precisely in a critical period in Fermat's mathematical activity.  Fermat originally introduced his techique of adequality in 1629, but it was first made known to a wider audience in the late 1630s. In the meantime infinitesimals have been declared persona non-grata . This may explain Fermat's legendary reluctance to talk about infinitesimals. In this he may have been more affected than for instance Wallis who spoke freely about infinitesimals. Wallis was not catholic but a presbyterian. Note 1. Wiki reports that the original heliocentric ban dates from 1615. Furthermore, In September 1632, Galileo was ordered to come to Rome to stand trial. He finally arrived in February 1633 and was brought before inquisitor Vincenzo Maculani to be charged. Thus the infinitesimal ban from august 1632 seems to be a separate development. Note 2. Here is Amir Alexander's own description of his historical work: I am currently working on a new book, provisionally entitled Infinitely Small, which examines the interconnections between mathematics and political and social order. Mathematics, at its most abstract, is the science of order, and it follows that different conceptions of mathematics have been associated with different views of proper social arrangements. In particular, the book will examine a sequence of historical instances in which mathematical infinitesimals acquired political significance, showing that even the purest mathematics can at times serve to buttress or undermine a political order. See here . Note 3. Paulos provides a hint of an answer in the following terms: To the Jesuits, tradition, resoluteness and authority seemed bound up with Euclid and Catholicism; chaos, confusion and paradoxes were associated with infinitesimals and the motley array of proliferating Protestant sects. See here . Note 4. See also this NPR review . Note 5. The latest review is in the Notices of the American Mathematical Society by Slava Gerovitch .","['calculus', 'math-history', 'infinitesimals', 'soft-question', 'nonstandard-analysis']"
662009,What is the difference between vector-valued functions and parametric equations?,"So as it is, I'm now starting to cover vector-valued functions in my Calculus III class. While studying the topic, I noticed that it seemed to be the exact same thing as parametric equations. I know that I am probably missing an important difference between the two topics, but I can't seem to figure it out. So the question is: What is the difference between a set of parametric equations and a vector-valued function?","['multivariable-calculus', 'calculus', 'vectors']"
662029,TVS: Topology vs. Scalar Product,"I just had an idea: It is clear that every scalar product induces a norm and that a metric and that finally a topology. Turning this argument around we know: Not every topology induces a metric only the metrizable ones, not every metric induces a norm only the homogeneous translational invariant ones and finally not every norm induces a scalar product only the ones that obeys the parallelogram law. In between we know that: A metrizable topology admits many metrics, a metric space admits at most one norm as well as a normed space admits at most one scalar product. So from many to less! So, my thoughts were: 1.) Does every metrizable topology admit at least one norm? 2.a) Is that norm necessarily unique? 2.b) Are there several norms? 3.) Is there necessarily one that admits a scalar product? 4.a) Is that scalar product necessarily unique? 4.b) Are there several scalar products? ...I would always like to start from some given topology:","['inner-products', 'general-topology', 'normed-spaces', 'metric-spaces', 'functional-analysis']"
662036,Is there a general way to solve a multivariate polynomial?,"Is there a general way to solve a multivariate polynomial (for example the one given here ). Say for instance I knew some function $F(x,y) = xy + x^2 + y^3 + 2x^2y^2 = 5$ , and $G(x,y) = 7xy^2 + 4y^2x + x^2 = 7$ , could I find a solution set? Is there a general method (either analytic or numeric) for solving systems such as these?","['multivariable-calculus', 'polynomials']"
662053,Area of a triangle,"The following problem in elementary geometry was proposed to me. As a mathematical analyst, I confess that I can't solve it. And I have no idea of what I could do. Here it is: pick a triangle, and draw the three mediana (i.e. the segments that join a vertex with the midpoint of the opposite side). Use the three segments to construct a second triangle, and prove that the area of this triangle is $3/4$ times the area of the original triangle. Any help is welcome.","['geometry', 'triangles', 'area']"
662056,Integral in $n-$dimensional euclidean space,"I want to calculate this integral in $n$-dimensional euclidean space. $$I(x)=\int_{\mathbb{R}^n}\frac{d^n k}{(2\pi)^n}\frac{e^{i(k\cdot x)}}{k^2+a^2},$$
where $k^2=(k\cdot k)$, $k=(k_1,\ldots,k_n)\in\mathbb{R}^n$, $x=(x_1,\ldots,x_n)\in\mathbb{R}^n$,$a\in \mathbb{R}$. I've done this integral for $n=3$ by spherical coordinates and residue theorem. I have $$I(r)=\frac{1}{4\pi r}e^{-ar},$$
where $r=|x|$ But in $n$- dimensions I failed in using spherical coordinates , because I have never done it before. Also I see that this integral is Fourier transform of $\frac{1}{k^2+a^2}$, but I failed here too, because I can't find Fourier pair in my reference books. If someone could guide me in this integration it would be great.","['special-functions', 'integration', 'definite-integrals', 'real-analysis', 'analysis']"
662099,"Show that if $E\subset\mathbb{R}$ is a measurable set, so $f:E\rightarrow \mathbb{R}$ is a measurable function.","If $E\subset \mathbb{R}$ is a set Lebesgue Measurable and $f:E \rightarrow \mathbb{R}$ a monotone function, show that $f$ is measurable. I'm trying for hours with no progress.","['monotone-functions', 'measure-theory', 'lebesgue-measure', 'measurable-functions']"
662104,Kelly criterion with more than two outcomes,"I want to calculate the Kelly bet for an event with more than two possible outcomes. Suppose the following game: A jar contains $10$ jelly beans. There are $7$ black jelly beans, $2$ blue jelly beans, and $1$ red jelly bean. The player wagers $x$ and grabs a single jelly bean randomly from the bag. The payouts are such: Black Jelly Bean: no payout (i.e. simply lose wager amount $x$) Blue Jelly Bean: net odds received on the wager = $10$ Red Jelly Bean: net odds received on the wager = $30$ In essence the only way to lose the bet is to grab a black jelly bean (i.e. $q = 0.7$). But the net odds received on the wager is still dependent on whether the player grabs a blue ($b = 10$) or red ($b = 30$) jelly bean. How would I calculate the Kelly bet for this game? Is it correct to simply calculate the Kelly bet for each positive outcome and then find the weighted average for the final wager? For example: $$x_b = \frac{10\times0.2 - 0.8}{10} = 0.12$$ $$x_r = \frac{30\times0.1 - 0.9}{30} = 0.07$$ $$x = \frac{0.12\times0.2 + 0.07\times0.1}{0.2 + 0.1} \approx 0.103$$ So the amount to wager would be 10.3% of the bankroll. Or should I have instead found the weighted average of the net odds received on the wager and then calculated the Kelly bet based on the winning outcomes as a whole (i.e. $p = 0.1 + 0.2 = 0.3$)? For example: $$b = \frac{10\times0.2 + 30\times0.1}{0.2 + 0.1} \approx 16.7$$ $$x = \frac{16.7\times0.3 - 0.7}{16.7} \approx 0.258 $$ So the amount to wager would be 25.8% of the bankroll.","['probability', 'gambling']"
662121,The equation $3^n+4^m=5^k$ in positive integer numbers,"Please help me to prove that the equation $3^n + 4^m = 5^k$
where $n$, $m$, $k$ are positive integer numbers has only the solution $n=m=k=2$. I know how to prove it for $n=m=k$. If $3^x + 4^x = 5^x$ then $(3/4)^x + 1 = (5/4)^x$,
and this equation has at most one solution
since the function $(3/4)^x + 1$ decreases and the function $(5/4)^x$ increases
for all real $x$. So the solution $x = 2$ is unique. Thank you very much in advance!","['elementary-number-theory', 'number-theory']"
662149,Measurability of points regular,"I'm reviewing the proof of the theorem of oseledet the book  Mañe: Let $M$ a compact metric space and $f:M \rightarrow M$ a homeomorphism, $\pi: F \rightarrow M$ a finite-dimensional continuos vector bundle over $M$, endowed with a continuous Riemannian metric. Let $L: F \rightarrow F$ vector bundles covering $f$ (i.e. $\pi\circ L= f\circ \pi$) such that both $L$ and $L^{-1}$ have bounded normas. Denote by $L_n$ the n-th iterate of $L$ 
$$L_n(x)=L(f^{n-1}(x))\circ \ldots \circ L(f(x))\circ L(x) \ \ \ \mbox{if} \ \ n>0,$$
$$L_n(x)=L^{-1}(f^{-n+1}(x))\circ \ldots \circ L^{-1}(f^{-1}(x))\circ L^{-1}(x)\ \ \ \mbox{if} \ \ n<0.$$
For $n_1,\ldots, n_l\geq 1$ fixed. Let $A_k$ the set of 2l-uples of rational numbers $\alpha_1>\beta_1\ldots \alpha_l>\beta_l$ with $(\alpha_i-\beta_i)<\frac{1}{k}$ for $1\leq i\leq l.$ For $m\geq 1$ and ($\alpha_1,\ldots,\beta_l)\in A_k$, let $\Lambda(m,\alpha_1,\ldots,\beta_l)$ be the set of point $x\in M$ for which there is a splitting $F_x=F_1(x)\oplus \ldots \oplus F_l(x)$ with $dimF_j=n_j$ and $$exp(n\alpha_j)\Vert u\Vert \geq \Vert L_n(x)u\Vert \geq exp(n\beta_j)\Vert u\Vert $$ 
$$exp(-n\alpha_j)\Vert u\Vert \leq \Vert L_{-n}(x)u\Vert \leq exp(-n\beta_j)\Vert u\Vert $$ for all $n\geq m$, $1\leq j\leq l$ and $u\in F_j$. Then the set $\Lambda(m,\alpha_1,\ldots,\beta_l)$ is closed and $\Lambda(m,\alpha_1,\ldots,\beta_l) \ni x \rightarrow F_j(x)$ is contionuos for every $1\leq j\leq l$. This is where I have difficulty Let $(x_n)\subset \Lambda(m,\alpha_1,\ldots,\beta_l)$ such that $x_n \rightarrow y\in M$, then there $F_{x_n}=F_1(x_n)\oplus \ldots \oplus F_l(x_n)$ with $dimF_j(x_n)=n_j$ but as I can guarantee that $F_{x_n} \rightarrow F_{y}$? how to make the convergence of subspaces? thanks for any suggestions","['geometric-measure-theory', 'ordinary-differential-equations', 'ergodic-theory', 'compact-manifolds']"
662166,Coefficients in Pochhammer Expansion,"Can anyone tell me if there is a formula for finding the coefficient of $x^3$ in the expansion of $(3x+5)_{6}$, where $(a)_n$ denotes the Pochhammer symbol, i.e. $(a)_{n}=a\cdot(a+1)\cdots(a+n-1)$? It would be even better if someone could explain how I might derive a general formula for the coefficient of $x^k$ in the expansion $(ax+b)_n$.","['pochhammer-symbol', 'binomial-coefficients', 'combinatorics']"
662195,Particular integral of $\frac{d^2y}{dx^2} - 5\frac{dy}{dx} + 4y = \mathrm{e}^x\ $,"I need to find the particular integral for the following equation:
$\dfrac{d^2y}{dx^2} - 5\dfrac{dy}{dx} + 4y = \mathrm{e}^x\ $ So far I have found that $y = A\mathrm{e}^{4x}+B\mathrm{e}^x $. Then for PI, $y = C\mathrm{e}^x $, $\dfrac{dy}{dx} =C\mathrm{e}^x $, $\dfrac{d^2y}{dx^2}=C\mathrm{e}^x $. But when I tried to substitute this to the equation at the top, the result came out to be $0$. Does this mean $C$ is zero? I was told by my teacher that the answer is not zero and can't seem to find the answer. Many thanks!","['ordinary-differential-equations', 'calculus', 'integration']"
662241,Limit of $(n-k)! \cdot n^k$ as $n$ approaches infinity,Is it true that $(n-k)! \cdot n^k$ tends to $n!$ as $n \to \infty$? I think it is correct but can't think of a satisfying proof.,"['factorial', 'infinity', 'limits']"
662249,Gateaux and Frechet derivatives and related notions,"Let $X$ and $Y$ be normed real vector spaces, and $f : X \to Y$ a map. Let's say that: G) $f$ is Gateaux differentiable at $x_0 \in X$ if for all directions $v \in X$ the limit $f'(x_0)(v) := \lim_{t \searrow 0} t^{-1} [f(x_0 + t v) - f(x_0)]$ exists in $Y$. F) $f$ is Frechet differentiable at $x_0 \in X$ if there exists a bounded linear operator $A : X \to Y$ such that for all $h \in X$: $f(x+h) - f(x) = A h + o(\|h\|_{X})$ as $h \to 0$ in $X$. That's a little Landau-oh; the residual term $o(\|h\|_{X})$ is supposed to be bounded in terms of $\|h\|_X$ only, uniformly in $h / \|h\|_X$. Fix $x_0 \in X$. Once we know that $f$ is Gateaux differentiable at $x_0$, there are several obstructions to it being Frechet differentiable at $x_0$. Suppose $f$ is Gateaux differentiable at $x_0$
and the Gateaux differential $v \mapsto f'(x_0)(v)$ is
one of the following: 0) exactly the Frechet derivative. 1) linear but not continuous in $v$. 2) continuous but not linear in $v$. 3) linear and continuous in $v$. Suppose the Gateaux derivative $f'(x) : X \to Y$ is a bounded linear functional for each $x \in X$ and $f'$ is
one of the following: 4) continuous at $x_0$: $f'(x) \to f'(x_0)$ in operator norm whenever $x \to x_0$ in $X$. 5) continuous at $x_0$ weakly: $f'(x) \to f'(x_0)$ in operator norm whenever $x$ converges weakly to $x_0$. 6) weakly continuous at $x_0$: for each $v \in X$ fixed, one has $f'(x)(v) \to f'(x_0)(v)$ whenever $x \to x_0$ in $X$. You are welcome to answer any subset of the following questions . a) Is any of those notions redundant? b) Is any of those notions redundant if $X$ and $Y$ are Banach spaces? Provide examples, if such exist, for: c): 3) but not 0). d): 6) but not 5). e): 4) but not 5). f): $x \mapsto f'(x)$ is $C^1$ but not 0). g): where 5) occurs. h): where 6) occurs. Suppose in 4)--6), $f$ is Frechet differentiable at each $x$. i) In which case is $f$ necessarily Frechet differentiable at $x_0$? j) Same as i), but assuming $X$ and $Y$ are Banach spaces.","['normed-spaces', 'operator-theory', 'derivatives', 'banach-spaces']"
662251,"The function $f(x)$ passes through the point $(-1,6)$ and $f'(x)=3x^2+2x+1$",a) find $f(x)$ I found that to be $f(x) = x^3+x^2+x+7$ b) Prove $f$ has a root between $x=-3$ and $x=-2$ I don't know how to do part b.,"['ordinary-differential-equations', 'math-software']"
662253,pullback and pushforward of line bundles,"I have two questions. For the first, we consider a projective morphism between two smooth, projective varieties over $k$, $f:X\rightarrow Y$. Let $\mathcal{L}$ be a line bundle and $f^*\mathcal{L}$ the pullback. Under what assumptions is $f*\mathcal{L}$ again a line bundle? (more generally what happens for a vector bundle $\mathcal{E}$ ?)
For the second, we consider a closed embedding of a smooth variety $X$ into a smooth and projective variety $Y$ , $j:X\rightarrow Y$ and $\mathcal{L}$ a line bundle on $X$. When is $j_*\mathcal{L}$ again a line bundle? (more generally what for a vector bundle $\mathcal{E}$ ?)",['algebraic-geometry']
662272,Complex manifolds and Hermitian metrics,"I've been trying to learn some complex geometry, and was getting
confused in thinking about Hermitian metrics.  In this post, I've
written up my current understanding, in hopes that someone can look it
over and verify/clarify where I have gone
right/wrong. $\newcommand{\pp}[1]{\frac{\partial}{\partial #1}}$
I'll start with definitions, to fix notation and for practice. Let $M$ be a complex manifold of dimension $n$, and let us fix a point
$p \in M$.  Around $p$ we can find a holomorphic coordinate chart: an
open set $U \subset M$ and holomorphic coordinates $z_1, \dots, z_n :
M \to \mathbb{C}$.  If $x_j, y_j$ are the real and imaginary parts of
$z_j$, then $x_1, y_1, \dots, x_n, y_n : U \to \mathbb{R}$ give us a
smooth coordinate chart.  So $M$ is also a differentiable manifold of
real dimension $2n$, and thus we can define a tangent space $T_p M$ in
the usual way as a real vector space of dimension $2n$; a basis for
$T_p M$ is given by $\pp{x_1}, \pp{y_1}, \dots, \pp{x_n}, \pp{y_n}$. Now $T_p M$ carries a natural almost complex structure; namely, the
linear map $J$ defined by $J \pp{x_j} = \pp{y_j}$ and $J \pp{y_j} =
-\pp{x_j}$.  If the differentiable manifold $M$ carries a Riemannian
metric $g$, so that $g_p : T_p M \times T_p M \to \mathbb{R}$ is a
bilinear symmetric positive definite form, then we say this metric is Hermitian if it respects the almost complex structure: $g_p(J v, J
w) = g_p(v,w)$ (and the same holds for every other point $p$).  So
far, so good? We may also consider the complexified tangent space $T_p M \otimes
\mathbb{C}$, which is a complex vector space of complex dimension
$2n$.  As I understand it, we typically extend $g_p$ to $T_p M \otimes
\mathbb{C}$ by bilinearity ; in particular, for $\alpha, \beta \in
\mathbb{C}$, we have $g_p(\alpha v, \beta w) = \alpha \beta
g_p(v,w)$.  So $g_p$ is now a bilinear symmetric form on $T_p M
\otimes \mathbb{C}$. In particular, $g_p : (T_p M \otimes \mathbb{C})^2 \to \mathbb{C}$ is no longer positive definite: indeed, $$g_p\left(\pp{x_i} - i \pp{y_j}, \pp{x_i} - i \pp{y_j}\right) = 0.$$ This confused me for a while, because the more usual notion of an inner
product on a complex vector space is a positive definite sesquilinear symmetric form:
i.e., $\langle \alpha v, \beta w \rangle = \alpha \bar{\beta} \langle
v,w \rangle$.  Indeed, the word ""Hermitian"" is often used to describe
such a form.  So I would naively ask: Why is it better to take $g_p$
to be bilinear on $T_p M \otimes \mathbb{C}$, rather than
sesquilinear? If we took the sesquilinear extension instead, would
we still get a reasonable theory, or would something bad happen? I think part of the reason I was confused is that $T_p M \otimes
\mathbb{C}$, considered as a real vector space of dimension $4n$ (with
basis $\left\{ \pp{x_j}, i \pp{x_j}, \pp{y_j}, i \pp{y_j} \right\}$)
actually carries two distinct almost complex structures.  First is the
obvious one: multiplication by $i$, sending $\pp{x_j}$ to $i
\pp{x_j}$ and so on.  The other one is the complex linear extension of
$J$, which sends $\pp{x_j}$ to $\pp{y_j}$, sends $i \pp{x_j}$ to $i
\pp{y_j}$ and so on.  And the point is that we take our extension of
$g_p$ to be Hermitian with respect to the latter, not the former. Have I understood all this correctly?","['complex-geometry', 'differential-geometry']"
662283,If $f_{n}$ are non-negative and $\int_{X}f_{n}d\mu=1$ does $\frac{1}{n}f_{n}$ converge almost-everywhere to $0$? does $\frac{1}{n^{2}}f_{n}$?,"Question from an exam sample I'm studying for: Suppose $\left(X,\mathcal{F},\mu\right)$
  is a measure space and $f_{n}:\left(X,\mathcal{F}\right)\to\mathbb{R}$
  a sequence of non-negative integrable functions such that $\int_{X}f_{n}d\mu=1$
 . Is is it necessarily true that $\frac{1}{n}f_{n}$
  converges almost everywhere to $0$
 ? what about $\frac{1}{n^{2}}f_{n}$
 ? My line of thought: From Fatou's llema we got that: $$\int\limits _{X}\liminf_{n\to\infty}\frac{1}{n}f_{n}d\mu\geq\liminf_{n\to\infty}\int\limits _{X}\frac{1}{n}f_{n}d\mu=\liminf_{n\to\infty}\frac{1}{n}\int\limits _{X}f_{n}d\mu=\liminf_{n\to\infty}\frac{1}{n}=0$$
 Thus $g:=\liminf\frac{1}{n}f_{n}$
  is a non-negative function whose integral equals zero and thus $g=0$
  almost-everywhere. So if I knew that $\frac{1}{n}f_{n}$
  converged almost-everywhere then in particular it would be equal to $g$
  almost-everywhere and thus to $0$
 . I've been racking my head trying to think whether it's possible to construct a sequence with the given properties such that $\frac{1}{n}f_{n}$
  would fail to converge on a set of positive measure. I want to say that this is impossible and that both claims are true (which would make the phrasing of the question quite mean since these questions usually imply one case is true and one is false) but I'm not certain. I'd really appreciate help clearing this up! Edit: Since you can only accept one answer I wanted to thank Did, Vincent and M. Luethi for their replies. Combined we got two counter-examples for $\frac{1}{n}$ and a proof for $\frac{1}{n^{2}}$.","['measure-theory', 'real-analysis']"
662293,Polynomial map is surjective if it is injective,"A friend of mine told me the following fact: If $k$ is any algebraically closed field, then a polynomial map $f\colon k^n\to k^n$ of affine space $k^n$ is surjective if it is injective. The proof he told me was actually a logic argument, which I didn't really understand, so I can't fully reproduce it here. The idea was that since it is the first order statement, it is enough to prove it for fields of characteristic $p>0$ for infinitely many $p$. Then by some reason it was enough to prove it for locally finite fields, and it somehow reduces to the same statement about finite fields $k$, where it is already obvious. I am very far from logic, so I would like to see a nice algebraic (or geometric) proof of this fact. Do you know how to do that? Thank you very much!","['logic', 'algebraic-geometry', 'polynomials']"
662295,Additive endomorphisms of $\mathbb Z$,"I need to find all additive endomorphisms of ${\Bbb{Z}}$. I checked that given an integer $m$, the function $f:{\Bbb{Z}}\to{\Bbb{Z}}$ defined by $f(x) = mx$ is an additive endomorphism. I suspect that every such endomorphism has the form above but I don't know how to prove it. So, how can I do it?","['group-theory', 'abstract-algebra']"
662299,"If a subsequence of a Cauchy sequence converges, then the whole sequence converges.","Let $(X,d)$ be a metric space, and say $(x_n)$ is a Cauchy sequence such that it has a convergent subsequence $(x_{n_k})$ that converges to $x$. We show $x_n \to x$. Let $\epsilon > 0$. Take $N >0$ such that for all $n,m > N$, we have $$d(x_n,x_m) < \frac{\epsilon}{2}.$$ By hypothesis, we can take also $K >0$ such that for all $n_k > K$, we have $$ d(x_{n_k},x) < \frac{\epsilon}{2}.$$ Put $M = \max \{N,K\}$. Therefore, for all $n,m,n_k > M$, we have $$ d(x_n,x) \leq d(x_n, x_{n_k}) + d( x_{n_k},x) < \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon.$$ Hence, $x_n \to x$ as desired. Is this a correct approach? Thank you very much in advance.","['general-topology', 'metric-spaces', 'proof-verification', 'cauchy-sequences']"
662306,Prove: if $A$ is infinite set and $B$ is finite set then $\left| {A - B} \right| = \left| A \right|$,"Prove: if $A$ is infinite set and $B$ is finite set then $\left| {A - B} \right| = \left| A \right|$ Well, one way to show it, is to find an injective function, for both directions. First, Lets define: $C = A-B$. $f:A\rightarrow C$ such that $f(x) = x$ $g:C\rightarrow A$ such that $g(x) = max(B) + x$ Hence, $$\left| C \right| = \left| {A - B} \right| = \left| A \right|$$ I have three questions: Is my solution right? Assuming I am right, Is there a good alternative for $g(x)$? I don't like the idea of using the $max$ function in this kind proof. Is there another solution other then finding two injective functions? Thanks in advance.","['cardinals', 'elementary-set-theory', 'functions']"
662313,The equation $x^3 + y^3 = z^3$ has no integer solutions - A short proof,"Can someone provide the proof of the special case of Fermat's Last Theorem for $n=3$, i.e., that 
$$
x^3 + y^3 = z^3,
$$ 
has no positive integer solutions, as briefly as possible? I have seen some good proofs, but they are quite long (longer than a page) or use many variables. However, I would rather have an elementary long proof with many variables than a complex short proof. Edit. Even if the bounty expires I will award one to someone if they have a satisfying answer.","['alternative-proof', 'elementary-number-theory', 'diophantine-equations', 'number-theory']"
662324,Wanted: simple invertible function with specified derivative properties,"I'm looking for a positive function $F(x)$, defined for positive real numbers, with the following properties. $F(x)$ is expressible with the standard computer math library routines; $F(x)$ is invertible and its inversion expressible with the standard computer math library routines; $F'(x)>0$ and $F''\le0$. at $x\to\infty$: $F'\propto x^{-\gamma}$ with $1<\gamma<2$ a parameter; at $x\to0$: $F'\to\mathrm{const}$ and $F''\to0$ (ideally $F''\propto x$ in this limit). I couldn't find anything (despite some extensive search). The first condition really makes it hard. Of course, I could use numerical inversion, but this will be the second choice. Why do I need this? I want to sample $N$ points at positive $x$ with number density $n\propto x^{-\gamma}$ at large $x$ and continuously differentiable $n(r)=F'(|r|)$ (in particular at $r=0$). I don't want to sample these positions randomly, but equidistantly in the cumulated number $\propto F(x)$, hence the requirement to invert $F(x)$. Also, I don't want to suffer from round-off error more than absolutely necessary (hence preferentially no numerical inversion). edit So what did I try? $F(x)=x(1+x^{\gamma-1})^{1/(1-\gamma)}$ meets  criteria 1-4, but $F''(x)\to\infty$ at $x\to0$","['derivatives', 'functions']"
662384,Simplify the following indices,$3^{x+4} * 5^{x+7} * 15^{2x-1}$ I tried it in this way: $3^{x+4}*5^{x+1}*(3*5)^{2x-1}$ Then: $3^{x+4}*5^{x+1}*3^{2x-1}*5^{2x-1}$ And what about next?,['algebra-precalculus']
662404,$\int e^{-x} \log \log x dx$ - another special integral?,"I came across this integral in some old notes. After several unsuccessful attempts I ran it in WA and got an interesting result: the antiderivative (closed form) doesn't exist, but the bounded integral (i.e. from $1$ to $\infty$) is a small constant, which is unsurprising given that the integrand is dominated by $e^{-x}$, which decreases much slower that $\log \log x$ grows for $x \to \infty$. So I wonder if this integral is known as another 'special' one like the error function $\text{Erf} (x)$. Also, does it have special representations like Legendre Polynomials and estimates of order? It seems to be $O(1)$, but that's just a guess...","['calculus', 'integration']"
662417,Recommendation on a rigorous and deep introductory logic textbook,"In this post, I don't mean any word by its somewhat ""mathematical or logical"" meaning but just ""literally"". It's been three years since I started ""formal"" mathematics, and now I'm familiar with set theory and formal proof. In the meantime, I have never studied ""logic"" before (it's nonsense to me), so now i think it's the time to start with it. I have asked a similar question before, and people recommended me some texts. Almost all of them started with introducing ""proposition logic"". I guess authors intended to introduce a rather easier example at first. I don't think it's a good way to study logic rigorously . I felt like I'm not studying mathematics when I was reading those books, but I felt like I'm reading an philosophy article, which I felt extremely uncomfortable. Frankly, to me, it's really hard to know what people mean by logic. I have searched wikipedia, but there are so many types of logics such as propositional logic, intuition logic(?), classical logic and etc. I even found some ""logics"" are subcategory of other!
What is logic exactly? I don't want to start logic with 'handy and easy' examples. I want to study logic from its core so I could answer questions like: What is ""proof""? What is ""truth""? Please... please recommend me a good precise logic textbook. I'm eager to learn logic precisely... Thank you in advance ! :)","['model-theory', 'logic', 'elementary-set-theory', 'reference-request', 'soft-question']"
662433,Solving a partial differential equation using method of characteristics,"I keep getting stuck and have a hard time understanding my professor, so I'm hoping to get some help here.  The question is: Solve the partial diff/eq: ${\partial u}\over{\partial t}$ + $c {{\partial u}\over{\partial x}}$ = $e^{2x}$ of an unknown function of two variables $u=u(t, x)$ where $c \in \mathbb{R}$ is a fixed parameter, and with the additional initial condition $u(0, x) = f(x)$, where $f$ is a given function. What I have so far: 1st Step: Characteristic Curves
$s \to (t(s), x(s))$ ${d \over ds} u(t(s), x(s)) = t'(s){\partial u \over \partial t} + x'(s){\partial u \over \partial x}$ Char. curves: 
\begin{cases}
t'(s) = 1 \\
x'(s) = c \\
\end{cases} so:
\begin{cases}
t(s) = s+d_1 \\
x(s) = cs + d_2  \\
\end{cases} the characteristics eq's thus become:
\begin{cases}
t(s) = s' \\
x(s) = cs + d  \\
\end{cases} 2nd Step: As long as everything above is correct, this is now where I'm getting stuck: Solve for $u$ along the curve: $z(s) = u(t(s), x(s))$ $z'(s) + z(s) = e^{2x}$ and then I'm lost...any help would be great...","['ordinary-differential-equations', 'partial-differential-equations']"
662436,Total space of a geometric vector bundle,"Suppose that $X$ is a scheme with a $B$-action, and that $\lambda: B \to \mathbb{C}^*$ is a character of $B$. We then have a geometric vector bundle $\pi: X \times^B k \to X/B$, where $B$ acts on $X \times^B k$ via $(x,v).b = (xb,\lambda(b)^{-1}v)$. Suppose that $X'$ is a scheme with a $B'$-action and that $f: X'/B' \to X/B$ is a morphism of schemes. Then the pullback bundle is $(X'/B') \times_{X/B} (X \times^Bk)$ with projection onto the first factor. If this was merely a topological vector bundle, then we could easily identify the total space of the pullback bundle - it is just $\{(x',(x,v)) \mid f(x') = \pi(x,v) \}$. But since this is a geometric bundle, we are in the category of schemes, and the fibre product in Schemes is not the same as in the category of topological spaces or sets. Is it nonetheless true that as a set the total space $(X'/B') \times_{X/B} (X \times^Bk)$ admits the 'easy' description available in the case of topological bundles?","['vector-bundles', 'algebraic-geometry', 'algebraic-topology']"
662441,Show that $S=\frac{1}{a_1}+\cdots+\frac{1}{a_n}$ is not an integer.,"So I have a bunch of integers $a_1,...,a_n$ and a prime number $p$ that divides only one of the numbers in this sequence, say $a_k$ I want to show, that $S=\dfrac{1}{a_1}+\cdots+\dfrac{1}{a_n}$ is not an integer. Well we can express the sum in another way, by putting them under a commond denominator, then the sum is $$\sum_{i=1}^n\dfrac{\prod_{j=1,j \neq i}^n a_j}{\prod_{j=1}^n a_j}$$ All of the members of this sum are divisible by $p$ expect the $k$'th one. But is this helpful in any way?","['discrete-mathematics', 'number-theory']"
662459,Integral curves of $X = z \dfrac{\partial}{\partial \theta} - \sin \theta \dfrac{\partial}{\partial z}$ on a cylinder,"Consider coordinates $(\theta, z)$ on $S^1 \times \mathbb R$, and a vector field $$X = z \dfrac{\partial}{\partial \theta} - \sin \theta \dfrac{\partial}{\partial z}.$$ Show that the integral curve of $X$ through $(\pi/2,0)$ defines a compact submanifold, and find another point s.t. the passing integral curve is not compact. Hint: calculate $H = \dfrac{z^2}{2}-\cos \theta$ on the integral curves. 1st attempt. By brute force one obtains for an integral curve $\alpha_t = (\alpha^1_t, \alpha^2_t)$ the system
$$ \begin{cases}
\dot \alpha^1 = \alpha^2\\
\dot \alpha^2 = - \sin \alpha^1
\end{cases}$$
the second equation being not integrable with elementary functions. However maybe one could deduce some properties of the solution? 2nd attempt. A quick calculation shows that $H$ is costant along integral curves. Therefore $z$ is limited on the integral curve, so the curve lies on a limited cilinder. But how do I know that it is compact (and moreover the curve is injective with non null derivative)?","['multivariable-calculus', 'manifolds', 'vector-fields', 'differential-geometry']"
662477,What does $\Delta$ mean in context of vector calculus?,"I'm reading an article that has a formula for $\Delta \phi(x)$, where $\phi : \mathbf{R}^2 \rightarrow \mathbf{R}$ and $x \in \mathbf{R}^2$ and $\Delta \phi(x) : \mathbf{R}^2 \rightarrow \mathbf{R}$ From context I think it has to do with the gradient of $\phi$.  Specifically I strongly suspect it means $|\nabla \phi(x)|$, but I've never seen $\Delta$ used to mean that.  Is that a common practice? The paper specifically is Transfinite mean value interpolation , bottom of page 17.","['multivariable-calculus', 'calculus', 'vector-analysis']"
662487,"""There is, up to Isomorphism, Only One Cyclic Group Structure of a Given Order""","In Fraleigh's A First Course in Abstract Algebra , I encountered this statement (p. 106). However, I hadn't seen a proof of the statement before. So, can anyone tell me why this is true? Proposition. There is, up to Isomorphism, Only One Cyclic Group Structure of a Given Order. The implication here being that any two cyclic groups of the same order are isomorphic, which seems like a rather powerful tool. What is it about being cyclic that preserves the structural properties of groups of the same order?","['group-theory', 'abstract-algebra']"
662491,How many automorphisms of $\Bbb Z \oplus \Bbb Z_2$,"The question is how many isomorphisms (of groups) exist from $\Bbb Z \oplus \Bbb Z_2$ to itself. I tried to define isomorphism by taking generators to generators, but I want to see convincing proof for that. Thanks","['group-theory', 'abstract-algebra']"
662500,When does a measurable function exist with a given distribution?,"Let's suppose (A,X,P) and (B,Y,Q) are two probability spaces (A,B underlying spaces, X,Y sigma-algebras, P,Q probability measures, respectively). Under what (topological and/or measure theoretic) conditions on these two spaces does there exist a measurable map M: A -> B
such that P(M in b) = Q(b)   for an arbitrary element b of Y. Thanks a lot for your help.","['probability-theory', 'measure-theory', 'probability']"
662540,Finding transformed region by change of variables,"I have the equation of a curve $x^{2/3} + y^{2/3} = a^{2/3}$ and I'm using the change of variables $x = u\cos^3v $, $y = u\sin^3v$ . I have calculated the Jacobian $\frac{\partial(x,y)}{\partial(u,v)}$, but how do I use all this stuff to find the area of the region bounded by the curve and the positive x- and y-axes? I'm having particular difficulty figuring out the new limits for the double integral wrt u and v. Thanks","['multivariable-calculus', 'integration', 'partial-derivative']"
662557,"Every Cauchy sequence in a metric space $(X,d)$ is bounded.","MY attempt: Suppose $(x_n)$ is a Cauchy sequence in $(X,d)$. Take $\varepsilon = 1 $. Hence, can find $N$ such that $d(x_m,x_n) < 1 $ for all $n,m >  N$. Also, we have $d(x_N, x_n) < 1 $ for all $n > N$. Hence, $$ d(a,x_n) \leq d(a, x_N) + d(x_N,x_n) < d(a,x_N) + 1.$$ Put $K = \max \{ d(a,x_i) : 1 \leq i < N \} $ $$\therefore d(a,x_n) \leq K \; \; \forall n > N$$ So $(x_n)$ is bounded. Is this a correct approach? Also, is boundedness of a sequence sufficient for the sequence to be cauchy? convergent? My answer is not. For instance, $x_n = (-1)^n$ is bounded, but it is not Cauchy, neither convergent. IS this correct? Thanks in advance.","['general-topology', 'proof-verification', 'real-analysis']"
662584,Does the fibres being equal dimensional imply flatness?,"Let $f: Y \to X$ be a morphism of varieties (proper if necessary). I read from a paper that if all the fibres of $f$ are of the same dimension then $f$ is flat. This seems skeptical for me, and I was wondering more conditions are need to have the flatness","['flatness', 'algebraic-geometry']"
662590,Why is $L^{1} \cap L^{\infty}$ dense is in $L^{p}$?,It is mentioned that using the interpolation inequality $$\Vert f \Vert_{p} \leq \Vert f \Vert^{1/p}_{1} \Vert f \Vert_{\infty}^{1-1/p}$$ one can deduce that the space $L^{1} \cap L^{\infty}$ is dense in $L^{p}$ . Does anybody knows the trick behind this? Thanks !,"['interpolation', 'functional-analysis', 'lp-spaces', 'analysis']"
662592,Show that $\mathfrak{S}=\bigcup_{N=1}^{\infty}\mathfrak{Z}_N\cup\left\{\emptyset\right\}$ is a semi-ring,"Let $\Gamma$ be a finite set, $\Omega=\Gamma^{\mathbb{N}}=\left\{(x_1,x_2,\ldots):~\forall i\in\mathbb{N} x_i\in\Gamma\right\}$. For $a_1,\ldots,a_N\in\Gamma$ let
    $$
[a_1,\ldots,a_N]:=\left\{(x_1,x_2,\ldots)\in\Gamma^{\mathbb{N}}: i=1,\ldots,N x_i=a_i\right\}
$$
    be the $N$-cylinder which is determined by $a_1,\ldots,a_N$. Define
    $$
\mathfrak{Z}_N:=\left\{[a_1,\ldots,a_N]: a_1,\ldots,a_N\in\Gamma\right\}.
$$
    Show, that then
    $$
\mathfrak{S}:=\bigcup_{N=1}^{\infty}\mathfrak{Z}_N\cup\left\{\emptyset\right\}
$$
    is a semi-ring for $\Omega$. Hello! Three things are to show: (1) $\emptyset\in\mathfrak{S}$ (2) $A,B\in\mathfrak{S}\implies A\cap B\in\mathfrak{S}$ (3) $A,B\in\mathfrak{S}$ and $A\subset B\implies~\exists A_1,\ldots,A_n\in\mathfrak{S}$ pairwise disjoint, so that $B\setminus A=A_1\cup\cdots\cup A_n$. Proof. (1) is clear by definition of $\mathfrak{S}$. (2) $A\in\mathfrak{S}$, i.e. $A=[a_1,\ldots,a_N]$ for a $N\in\mathbb{N}$ and $a_1,\ldots,a_N\in\Gamma$. $B\in\mathfrak{S}$, i.e. $B=[b_1,\ldots,b_M]$ for a $M\in\mathbb{N}$ and $b_1,\ldots,b_M\in\Gamma$. To my opinion then
$$
A\cap B=\begin{cases}A, & N\leq M\wedge a_i=b_i, i=1,\ldots,N\\B, & M\leq N\wedge b_i=a_i, i=1,\ldots,M\\\emptyset, & \text{otherwise}\end{cases}
$$
and $A,B,\emptyset\in\mathfrak{S}$. (3) $A,B\in\mathfrak{S}, A\subset B$. If $A\subset B$, this means for $A=[a_1,\ldots a_N]$ and $B=[b_1,\ldots,b_M]$ that $N\leq M$ and $a_i=b_i, i=1,\ldots,N$. I am not sure, but to my opinion then $B\setminus A=\emptyset$. And so $B\setminus A$ can be writte as disjoint union of ONE set, namely the emptyset. Would be great to know if my proof is ok. Miro","['measure-theory', 'proof-verification']"
662601,"If $X$ and $Y$ are uniformly distributed on $(0,1)$, what is the distribution of $\max(X,Y)/\min(X,Y)$?","Suppose that $X$ and $Y$ are chosen randomly and independently according to the uniform distribution from $(0,1)$ . Define $$ Z=\frac{\max(X,Y)}{\min(X,Y)}.$$ Compute the probability distribution function of $Z$ . Can anyone give me some hints on how to proceed? I can only note that $\mathbb{P}[Z\geq 1]=1$ and $$F_Z(t)= \mathbb{P}[Z \leq t]=\mathbb{P}[X\leq Y, Y\leq tX]+\mathbb{P}[Y \leq X, x\leq tY]$$","['uniform-distribution', 'probability-distributions', 'probability']"
662615,"What does $W^{1,p}(I)\subset C\big(\overline{I}\big)$ mean?","Let $I\subset\mathbb{R}$ be a bounded open interval. Brézis book states that the injection $W^{1,p}(I)\subset C(\overline{I})$ is compact for all $1<p\leq\infty$ . Elements of $W^{1,p}(I)$ are functions whose domain is $I$ and elements of $C(\overline{I})$ are functions whose domain is $\overline{I}$. So, I would like an explanation on the meaning of the inclusion $W^{1,p}(I)\subset C(\overline{I})$. In the begining of the chapter is proved that for each $u\in W^{1,p}(I)$ there exists a $\tilde{u}\in C(\overline{I})$ such that $u=\tilde{u}$ a.e. on $I$. When the author says ""the injection $W^{1,p}(I)\subset C(\overline{I})$"" is he talking about the application
$u\mapsto\tilde{u}$? Thanks.","['sobolev-spaces', 'complete-spaces', 'functional-analysis', 'limits']"
662624,Ideal sheaf on a surface,"Let $S\subset\mathbb{P}^n$ a smooth complex projective surface.
I consider the exact sequence
$$0\rightarrow I_S\rightarrow\mathcal{O}_{\mathbb{P}^n}\rightarrow\mathcal{O}_S\rightarrow 0,$$
where $I_S$ is the ideal sheaf of $S$ and with $\mathcal{O}_S$ I denote $i_*\mathcal{O}_S$ ($i :S\hookrightarrow\mathbb{P}^n$ the inclusion), so it is the extension by zero outside $S$ of the sheaf $\mathcal{O}_S$. From this exact sequence I obtain this other exact sequence
$$0\rightarrow I_S(k)\rightarrow\mathcal{O}_{\mathbb{P}^n}(k)\rightarrow\mathcal{O}_S(k)\rightarrow 0.$$
$I_S(k)$ is the sheaf of polynomials of degree $k$ that vanish on $S$. My question is, how can i look at $\mathcal{O}_S(k)$? Is it correct to say that it is equal to $\mathcal{O}_S(kH)$ where $H$ is an hyperplane section of $S$? It should be actually a sheaf on $\mathbb{P}^n$. My aim is to calculate $h^0(I_S(k))=dimH^0(I_S(k))$, so i need to know $h^0(\mathcal{O}_S(k))$ and to know it i'd like to use Riemann-Roch, that's why i thought to introduce a section $H$ on $S$.","['sheaf-theory', 'algebraic-geometry', 'sheaf-cohomology', 'surfaces']"
662634,Find the approximate center of a circle passing through more than three points,"Consider n point $(x_1,y_1), (x_2,y_2),\ldots, (x_n,y_n)$. For $n = 3$ it is easy to find the center of the circle passing through the three points. I wanted find the approximate center of the circle passing through more than three points. The application is as follows. I have circles on a sheet of metal. I can poll different points on the circle to get the their co-ordinates. By polling three points on every circle I can predict the co-ordinates of the center. But I wanted to improve the accuracy of the prediction. A Google search reveals only the center of the passing through three points. Edit 1:
In response to Hoda 's comment, I am adding that the measurements related to the points on the circle have errors. The objective is to minimize the error in the position of the center by polling more points on the circle.","['geometry', 'circles']"
662687,Spectrum of unbounded Operators + Spectral Theorem [duplicate],"This question already has answers here : Resolvent: Definition (2 answers) Closed 10 years ago . I've seen a variaty of slightly different definitions for the spectrum and its division into pure point spectrum residual spectrum and so on. Thus I'm wondering what could be an appropriate definition. Moreover, when does the spectral theorem apply in principle? I have heard for normal operators and read once (I don't remember where) positive operators I guess...",['functional-analysis']
662688,Conditional probability combining discrete and continuous variables,"Let $A$ and $B$ be some continuous random variables. We proceed as follows: we take a coin with bias $b$ and flip it. If heads, we inspect $A$, if tails we inspect $B$. Call this resulting random variable $C$. Now say I can observe $C$ and want to figure out if the coin was heads or tails, i.e. I want to compute $\Pr[$head$|C = c]$ Everywhere I have looked, the definition is either for purely discrete or purely continuous random variables, I have not found a rigorous way of combining the two types of variables. One thought I had was to approximate the coin toss with a continuous random variable $K$ with pdf: $k(x) = b, \mbox{ for } x \in [-1, 0]   $ $k(x) = 1-b, \mbox{ for } x \in [0,1]$ Then one could compute the joint density function for $K$ and $C$ and compute $\Pr[K < 0 | C = c]$ from there. But this looks clunky and ugly. Is there a better way?","['probability', 'conditional-probability']"
662705,Using quantifiers to express this sentence.,"These are from a study guide, just checking my work. Let $F(x,y)$ be the statement ""$x$ and $y$ are friends."" where the domains consists of all people in the class. Use quantifiers to express the following: A.) ""There exists some student in this class who is friends with all of the others."" $\exists x \forall y F(x,y) $ B.) ""All students in this class must have at least one friend."" $\forall x \exists y F(x,y)$ C.) ""There exists some students in this class whose friends are not friends with each other."" $\exists x \exists y \neg F(x,y)$","['logic', 'quantifiers', 'discrete-mathematics']"
662718,Show by comparison that $\sum\limits_{n=1}^\infty \sin(\frac{1}{n})$ diverges?,"By using the integral test, I know that $$\sum\limits_{n=1}^\infty \sin\left(\frac{1}{n}\right)$$ diverges. However, how would I show that the series diverges using the limit comparison test? Would I simply let $\sum\limits_{n=1}^\infty a_n = \sum\limits_{n=1}^\infty b_n =  \sum\limits_{n=1}^\infty \sin\left(\frac{1}{n}\right)$ and then take $\displaystyle \lim_{n \rightarrow \infty}\frac{a_n}{b_n}$ to show the series diverges (assuming the limit converges to some nonnegative, finite value)?","['sequences-and-series', 'divergent-series', 'calculus', 'limits']"
662720,What are some properties that imply that a group must be the trivial group?,"In the problem posed in this question of mine we want to show that a particular group is both perfect and solvable, and therefore trivial, and this turns out to be useful in proving the result. What other combinations of properties required of a group imply that it must be isomorphic to the trivial group?","['big-list', 'soft-question', 'group-theory', 'abstract-algebra']"
662739,What do combinations of non-integers actually represent?,"I understand that a combination is a way of selecting a finite number of things out of a larger group, in which the order of elements do not matter. That is all fine. But, in my Mathematical Reasoning course, we have come across using non-integers in the Binomial Theorem. For example, in determining a finite number of terms of the expansion $(1+x)^{-\frac{1}{3}}$ one has to use the equation: $$(1+x)^n=\sum_{i=0}^{\infty}{n\choose i}x^i$$ This clearly gives what is usually considered as a combination which one can not evaluate. But, avoiding the factorial definition of a combination allows us to assign a number to these coefficients. My question is whether these combinations have any actually meaning in the traditionally combinatorial sense. Or, are they merely a means of expansion?",['combinatorics']
662752,Is this determinant identity correct?,"For complex valued matrices $A,B$ where $B$ is invertible, does $$\det(I+B^{-1}AA^*)=\det(I+AA^*B^{-1})=\det(I+AB^{-1}A^*)=\det(I+A^*B^{-1}A)?$$
Here $A^*$ is the conjugate transform. I guess $\det(I+B^{-1}AA^*)=\det(I+AA^*B^{-1})$ holds by Sylvester's identity . Correction $$\det(I+B^{-1}AA^*)=\det(I+AA^*B^{-1})=\det(I+A^*B^{-1}A)?$$","['matrices', 'determinant']"
662767,Do we know a number $n\gt 5$ with no twin prime $n\lt q\lt 2n$?,"This is essentially a Bertrand's postulate version for twin primes. I am interested in both an explicit example and large lower bounds for it because of this answer of mine . In the comments below the answer, it is shown that there is no such $n$ below $8\times 10^{15}$. An efficient algorithm would be as follows: take an initial point $m$ for which Bertrand's postulate for twin primes is true (say, $13$). Find the greatest prime twin $p\lt 2n$. The new initial point is $p$. Iterate. An explicit example of such $n$ would cause a very large gap $\approx n$. Although it seems quite unlikely for such $n$ to exist, a proof remains far from reality, so I am interested in a computational effort. Do we know $n\gt 5$ with no twin prime $n\lt q \lt 2n$?  If not, what's the best known lower bound?","['prime-numbers', 'number-theory']"
662793,Multivariable Calculus Vector Fields,"I have to prove that if 
$f(x,y,z)=f_{a}(x,y,z)+f_b(x,y,z)+f_c(x,y,z)$ is a conservative vector field and and $g(x,y,z)=g_{a}(x,y,z)+g_b(x,y,z)+g_c(x,y,z)$ is also a conservative vector field, then $(cf+dg)(x,y,z)$ is conservative.","['vector-spaces', 'multivariable-calculus']"
662795,Closed-Form Solution to Infinite Sum,"Does the convergent infinite sum
$$
\sum_{n=0}^{\infty} \frac{1}{2^n + 1}
$$
have a closed form solution? Quickly coding this up, the decimal approximation appears to be $1.26449978\ldots$","['sequences-and-series', 'calculus', 'algebra-precalculus']"
662819,Finding the super-mean (NOT the mean) of a set of numbers.,"the super-mean is found by grouping pairs of numbers and finding the average successively
until there is just one number. For example, $$(1-2-3-4-5) \to ((1+2)/2,(2+3)/2,(3+4)/2,(4+5)/2) \\ 
(1.5,2.5,3.5,4.5) \to(1.5+2.5)/2,(2.5+3.5)/2,(3.5+4.5)/2) \\
(2.0,3.0,4.0) \to2.5,2.5)$$ Then the super-mean is 3.0.i suspect a relationship between these problems and pascal triangles, then binomial coefficients, how to find the super-mean out of the set of numbers. I have read that the super-mean is given by: $$S_{n} = \left(\frac{1}{2^{n-1}}\right)\sum_{i = 0}^{n-1}\binom{n - 1}{i}a_{i}$$ $n$ is the size of the input $[0, \ldots, n]$.
$(1,2,3,4,5) \to n = 4$ How can I relate the problem with this formula, how do i derive the formula for the super-mean.?. Is there any reading material for these kind of problems?","['binomial-coefficients', 'discrete-mathematics', 'reference-request', 'combinatorics']"
662846,Non-technical question about maximum likelihood estimation / intuition,"Just a quick question on MLE, sorry if its too basic but I would love help on this issue! If we want to calculate the probability $P$ of the number of males in the United States and we knew the distribution $pmf$/$pdf$, why can't we just take the arithmetic mean and use $\bar{y}$. Why go through the trouble of using the MLE? For example, if we suppose that we are looking at a Bernoulli R.V. where $X_1=1$ is male and $X_2=0$ is a female and we want to estimate the parameter, which is $p$ in the case of Bernoulli, why would we go to great lengths to find the MLE when we could just see the $mean$ from our sample? I'm very confused on why MLE is useful in that way especially when we have the data. Thanks so much!",['statistics']
662868,Multivariable Calculus Divergence Theorem,"I have a cylinder where the top is given by $ z=-2$ the bottom is $z=2$ and the ""lateral surface"" is $x^2+y^2=1$. I have to find$\iint_{s}(4x+3y+z^2) \ dS$. I know this involves using the divergence theorem and then plugging in the answer into the volume of a cylinder but I have no idea how to set up the limits on the triple integral once I have found the partials and split up the integral for the divergence theorem. Thanks.","['multivariable-calculus', 'volume']"
662893,Which series converges question,"Which of the following statements are true. Given $S_1, S_2$, where $S_1:$ A series $$\sum_{n=0}^{\infty}a_n$$ converges if for a given $\epsilon\gt0$ there exists $N_o \in N$ such that $|a_{n+1}-a_{n}|\lt \epsilon$ for all $n\ge N_o$. $S_2:$ A series $$\sum_{n=0}^{\infty}a_n$$ converges if $|a_{n+1}-a_{n}|\lt \alpha^n$ where $\alpha$ is a fixed real no in $(0,1)$.",['sequences-and-series']
662906,Standard deviation and intervals,"I'm working on some homework and I'm stuck on a question that is not making sense to me in terms of my answer. The question states: The following data is the last digit of the social security number of a group of students
1, 6, 9, 1, 5, 9, 0, 2, 8, 4, 0, 7, 3, 4, 2, 5, 8, 4, 2, 3, 2, 0, 0, 2, 1, 2, 7, 7, 4, 0, 
0, 9, 9, 5, 3, 8, 4, 7, 4, 6, 6, 9, 0, 2, 6, 2, 9, 5, 8, 5, 1, 7, 7, 7, 8, 7, 5, 1, 8, 3,       
4, 1, 9, 3, 8, 6, 6, 6, 6

a. Determine the intervals x +- s; x +- 2s; and x +- 3s.
b. Find the proportion of the measurements that lie in each of these intervals. The standard deviation that I got was aprox 2.90647, which means my three intervals are 1.70223 to 7.51517, -1.20424 to 10.42164, and -4.11071 to 13.32811. Which leads to my first question, is it possible to have ranges that go from negative? Because for question b, for the 2 last intervals I get 100% for both intervals, again is that possible? Something doesn't seem right to me. Thank you.","['statistics', 'standard-deviation']"
662928,No constant curvature metric on $S^2 \times S^1$,"I was reading the introduction to Hamilton's paper ""Three-manifolds with Positive Ricci Curvature."" He states that $S^2 \times S^1$ admits no metric of constant sectional curvature, and therefore represents an obstruction to improving the hypothesis of the main theorem from positive Ricci curvature to nonnegative Ricci curvature. My question is: Can someone provide a reference to the result that $S^2 \times S^1$ doesn't have a constant curvature metric or to a general result which implies it?","['riemannian-geometry', 'differential-geometry']"
662959,On finite group with inner automorphisms group,Let $G$ be a finite $2$-group such that $\mid Inn(G)\mid=4$ and $\Phi(G)\subsetneq Z(G)$ where $\Phi(G)$ is frattini subgroup. Then prove that there exists an $\alpha\in Aut(G)$ such that $\alpha(g)\neq g$ for some $g\in Z(G)$. Thank you,['group-theory']
662967,Is it true that $(2^n+n^2)(n^3+3^n)$ is $O(6^n)$?,"$(2^n+n^2)$ is $O(2^n)$ and $(n^3+3^n)$ is $O(3^n)$, therefore I conclude that $(2^n+n^2)(n^3+3^n)$ is $O(2^n*3^n)=O(6^n)$","['asymptotics', 'discrete-mathematics']"
662968,Number of peaks in a random iid sequence [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Let $X_1,X_2,\ldots, X_\ell$ be a sequence of continuous iid random variables. Define a peak to occur at time $n$ if $X_{n-1}<X_n>X_{n+1}$. Then, how to show that as $\ell\rightarrow\infty$, the asymptotic proportion of times that a peak occurs is equal to $1/3$ with probability one (almost surely)?","['probability-theory', 'probability-distributions', 'probability']"
662979,Earnshaw's theorem,"Proposition Suppose $U\colon\Omega\to\mathbb R$ is a non-constant harmonic function, i.e. $U\in\mathcal C^\omega$, i.e. analytic, and $\Delta U=0$, where $\Omega\subseteq\mathbb R^n$ is a region. Then every equilibrium of the system $\ddot x=-\nabla U$ is unstable in the sense of Lyapunov. (In other words, suppose $(x_0,y_0)$ is an equilibrium of $\dot x=y,\dot y=-\nabla U$, then $(x_0,y_0)$ is unstable.) Discussion In electrostatic, the preceding statement is known as Earnshaw's theorem. However, the proofs I saw aren't completely rigorous. They rely on the maximum principle of harmonic functions, and the following statement : If $\nabla U(x_0)=0$ and $x_0$ isn't a strict local minimum, then the equilibrium $x=x_0,\dot x=0$ is unstable. However, in V.I.Arnold's Mathematical Methods of Classical Mechanics , it's said that It seems likely that in an analytic system with $n$ degrees of freedom, an equilibrium position which is not a minimum point (of the potential energy) is unstable; but this has never been proved for $n>2$. In addition, $\Delta U=0$ implies that the Hessian $H$ of $U$ at $x_0$ satisfies $\operatorname{tr}H=0$. If $H$ has a negative eigenvalue (otherwise $H=0$), then by spectrum theorem of symmetric matrix $H$ and the theory of linearization, system is unstable at $x_0$. However, there's no evident that $H\neq0$. Any idea? Thanks!","['dynamical-systems', 'ordinary-differential-equations', 'physics']"
662989,Exponential decay and time constants,"The time constant τ is the amount of time that
an exponentially decaying quantity takes to decay by a factor of 1/e. Because 1/e
is approximately 0.368, τ is the amount of time that the quantity takes to decay to
approximately 36.8% of its original amount.
(a) How are the time constant τ and the decay rate λ related? I used the decay model: $r = r_0e^{\lambda t} $ Where t = time r = amount of the particular exponentially decaying matter at time t $-\lambda$ = decay rate $e^{-\lambda t} = \frac{r}{r_0}$ Then I let $\frac{r}{r_0} = \frac{1}{e}$ and $t = τ$ $e^{-\lambda τ} = \frac{1}{e}$ Simplifying I got, $τ = \frac{1}{\lambda}$ Is this the correct way to show that the time constant is inversely proportional to the decay rate? (b) Express the time constant in terms of the half-life. I'm not sure how to do this, do I just set $\frac{r}{r_0}  = 0.5$?",['ordinary-differential-equations']
663000,Gradient-descent and Hidden Markov Models,"I would like to use gradient-descent to fit the parameters of a simple 2-state HMM. This paper Levinson, S. E., Rabiner, L. R. and Sondhi, M. M. (1983), An Introduction to the Application of the Theory of Probabilistic Functions of a Markov Process to Automatic Speech Recognition . Bell System Technical Journal, 62: 1035–1074. doi: 10.1002/j.1538-7305.1983.tb03114.x shows derivations of the partial derivatives required for gradient descent, but I am having trouble following the steps. Namely, the paper starts by stating that: $$P(\mathbf{O}|\mathbf{M})=\sum_{i=1}^{N}\sum_{j=1}^{N}\alpha_{t}(i)a_{ij}b_{j}(O_{t+1})\beta_{t+1}(j)$$ for any $t$ such that $1 \leq t \leq T-1$, where $\mathbf{O} = O_1...O_T$ are the observations and $\mathbf{M}$ represents the transition and emission matrices. $\alpha$ is the forward probability and $\beta$ is the backwards probability. $a_{ij}$ is the probability of transition from state $i$ to state $j$ and $b_j(O_{t+1})$ is the probability of observing $O_{t+1}$ given state $j$. Finally, $N$ is the number of states. To run gradient descent, one needs to calculate the partial derivatives with respect to model parameters. The paper derives: $$\frac{\partial{P}}{\partial{a_{ij}}}=\sum_{t=1}^{T-1}\alpha_t(i)b_j(O_{t+1})\beta_{t+1}(j)$$ But the exact steps for reaching this formula are not shown. Can anyone elaborate on how this result was obtained? Thank you,","['optimization', 'markov-chains', 'bayesian-network', 'probability']"
663052,Applications of the theory of distributions outside of PDEs?,"Are there any interesting, important or powerful mathematical applications to the Theory of Distributions besides those dealing with partial differential equations?","['applications', 'distribution-theory', 'partial-differential-equations', 'analysis']"
663064,Coordinates rotation by $120$ degree,"If I have a point on a standard grid with coordinates say: $A_1=(1000,0)$ $A_2=(707,707)$ Is there a easy way to transfer this points to $\pm 120$ degrees from the origin $(0,0)$, and keeping the same distance?
So for $A_1$, the result should be something like: 
$B_1=(800,-200);\  C_1=(800,-200)$ I can make this with triangles and calculate it but there should be some formula. I need a formula to use with software.","['trigonometry', 'transformation', 'coordinate-systems']"
663077,Questions on Proofs - Equivalent Conditions of Normal Subgroup - Fraleigh p. 141 Theorem 14.13,"(1.) Why did Fraleigh shirk the proof for $(2) \implies (1)$? By dint of Arthur's comment, $(2) \iff \color{crimson}{gHg^{-1} \subseteq H} \quad \wedge \quad gHg^{-1} \supseteq H \implies \color{crimson}{gHg^{-1} \subseteq H} \iff (1)$ (2.) In $(1) \implies (2)$, how does $\{ghg^{-1} : h \in H \} \subseteq H$? (3.) I know left cosets $\neq$ right cosets. The same $H$ appears on both sides $gH = Hg$ in: $gH = Hg \iff gh_1 = h_2g$, hence why isn't $h_1 = h_2$ always? I read $gH = Hg$ is a set equality and not an equality elementwise. But I'm confounded. To boot, I know $gh_1 = h_2g \iff G$ Abelian $\iff \color{magenta}{g^{-1}}gh_1 = \color{magenta}{g^{-1}}gh_2 \iff h_1 = h_2$. $G$ can be nonAbelian hence if it is nonabelian, the previous line muffs.","['intuition', 'group-theory', 'proof-verification', 'normal-subgroups']"
663080,Order of $\frac{f}{g}$,"An entire function is of finite order $\rho$ if $$\rho = \inf \{\lambda \geq 0  \ | \ \exists A, B > 0 \ s.t. \  |f(z)|\leq Ae^{B|z|^{\lambda}} \forall z \in \mathbb{C} \}$$ Prove that if $f$ and $g$ are entire functions of finite order  $\rho$, and $\frac{f}{g}$ is entire,then $\frac{f}{g}$ is of order $\leq \rho$. Any hint ?","['complex-analysis', 'analysis']"
663096,Convergence of a series concerning the multiplicative order of 2,"I was trying to bound the value of $v_p(2^n-1)$ and some of the series I obtain made me wonder about the following problem. Problem : 
  When does the series $$\sum_{prime \: p} \frac{1}{(ord_p 2)^z} = \sum_{n=1}^{\infty} \frac{\#\{p|ord_p2 = n\}}{n^z}$$ converge if $ord _p 2$ denotes the multiplicative order of $2$ in $\mathbb{Z}/p\mathbb{Z}$ for an odd prime $p$? I noticed that it diverges when $z=1$ since $\#\{p|ord_p 2 = n\} \ge 1$ for all $n \ge 2$ except for $n=6$. Also, it converges when $z > 2$ because $$\sum_{n=1}^{\infty} \frac{\#\{p|ord_p2 = n\}}{n^z} \le \sum_{n=1}^{\infty} \frac{\sum_{ord_p2=n} \log p}{n^z} \le \sum_{n=1}^{\infty} \frac{\log (2^n -1)}{n^z}$$ I'm especially interested about what happens when $z=2$. Thanks in advance!","['analytic-number-theory', 'number-theory']"
663126,A doubt regarding Picard's theorem.,"Picard's theorem states: If $f(x,y)$ and $\frac{\partial f}{\partial x}$ are continuous functions on a closed rectangle $R$, then through each point $(x_0,y_0)\in R$ there passes a unique integral curve of the equation $\frac{dy}{dx}=f(x,y)$. Here, should we assume that $x$ and $y$ are independent? If they were independent, $\frac{dy}{dx}$ would simply equal $0$, which would imply $f(x,y)=0$ passes through every point inside $R$. Why could the theorem not have simply stated $f(x,y)=0$ passes through every point in $R$, instead of saying $\frac{dy}{dx}=f(x,y)$ passes through every such point? Is there some subtle difference between these two statements that I'm missing? Thanks in advance!",['ordinary-differential-equations']
