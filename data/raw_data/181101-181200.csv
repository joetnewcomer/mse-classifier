question_id,title,body,tags
3300043,"If the sum of the differences of consecutive terms of a sequence between any two terms is less than or equal to one, then the sequence converges","I recently decided to learn real analysis, and started using Krantz's analysis text. I was working through the second chapter on sequences and series and came across this question: Let $\{a_j\}$ be a sequence. Suppose for all $N>M>0$ , $|a_M-a_{M+1}|+|a_{M+1}-a_{M+2}|+\ldots+|a_{N-1}-a_N|\leq 1$ . Prove that $\{a_j\}$ converges. First of all, I know that this question is a duplicate of Proof that if the sum of the differences of consecutive terms of a sequence between any two terms is bounded above by one, then the sequence converges . However, I don't quite understand the accepted answer in that question. I want to prove this using only the definition of convergence and Cauchy sequence, either by directly choosing an $N>0$ for an arbitrary $\epsilon>0$ , or through a contradiction, as these are the only thing I've learned so far. When I try to prove by contradiction it just feels like I'm running around in circles, and when I try to prove it directly I haven't the faintest idea how to choose $N$ . Any help would be greatly appreciated. Also, I know I'm not suppose to open a new question when there's already a duplicate. If there's something else I could have done, please do inform me in the comment section. Thank you.","['sequences-and-series', 'real-analysis']"
3300058,Is the definition of a Sigma Algebra not implied by the Power Set?,"Given a *subset of the* power set of $X$ , called $A$ , $A$ is a Sigma algebra of $X$ if: $X$ is an element of $A$ The complement of a set $B$ , element of $A$ , with reference to $X$ , is also in $A$ . A countable collection of sets in $A$ has a union which is also in $A$ . This is the setup as I understand it. What I am curious about is the seeming redundancy between these conditions, and the characteristics a power set will have implicitly. I cannot think of a power-set which would violate any of the conditions of a sigma-algebra. Am I mistaken? If so, what are/is the counter-example(s)? *correction","['elementary-set-theory', 'measure-theory']"
3300121,chi-squared test statistic implementation in python,"I am tasked with creating a script version of a spreadsheet which does overall model testing of satellite measurements for land subsidence. In one particular cell of this spreadsheet, I see a formula as follows. Although it is not explicitly stated, I suspect that the cell is calculating a chi-squared test statistic: $$\chi^2 = \sum_{i=1}^n \frac{(z_i-z_{regr,i})^2}{\sigma_{assumed}^2}$$ I have done a bit of research into python libraries from which to generate this result because the idea of the script is to code as little as possible from scratch. Unfortunately, all online resources show that the test statistic is calculated as follows: $$\chi^2 = \sum_{i=1}^n \frac{(z_i-z_{regr,i})^2}{z_{regr, i}}$$ Part of the idea of this spreadsheet is that the standard deviation must be a user-defined input, and I cannot reconciliate that with the above formula. Furthermore, common python methods such as scipy.stats.chisquare only have the following mathematical inputs: f_obs : array_like
    Observed frequencies in each category.
f_exp : array_like, optional
    Expected frequencies in each category.  By default the categories are
    assumed to be equally likely.
ddof : int, optional
    ""Delta degrees of freedom"": adjustment to the degrees of freedom
    for the p-value.  The p-value is computed using a chi-squared
    distribution with ``k - 1 - ddof`` degrees of freedom, where `k`
    is the number of observed frequencies.  The default value of `ddof`
    is 0. And the following outputs: chisq : float or ndarray
    The chi-squared test statistic.  The value is a float if `axis` is
    None or `f_obs` and `f_exp` are 1-D.
p : float or ndarray
    The p-value of the test.  The value is a float if `ddof` and the
    return value `chisq` are scalars. And never require standard deviation as input. My question is twofold: Is the first equation that I am showing correct? Why then is it different than the chi-squared test statistic provided in literature? If the first equation is correct, how can I use functions such as scipy.stats.chisquare to evaluate it, namely with an assumed $\sigma$ ? Thanks","['statistics', 'python', 'probability']"
3300131,"Can ""Taking algebraic closure"" be made into a functor?","I am now confused with such problem as title goes. To be exact, the problem is Does there exist a functor from $A:\mathsf{Field}\to \mathsf{Field}$ with a natural transformation from identity functor $\iota: \operatorname{id}\to A$ such that for each $F$ , $A(F)$ is the algebraically closure of $F$ through $\iota_F:F\to A(F)$ ? It is not easy rather than first glimpse. Let me explain. Note that, the existence of algebraic closure only ensures that there exist a map from $\operatorname{Obj}(\mathsf{Field})$ to itself. Since the ""extension"" property is not unique, it is not generally true that we can extend the map to $\operatorname{Mor}(\mathsf{Field})$ for arbitrary choice of algebraic closure. For example, consider the fields $$\begin{array}{ccc}
\mathbb{Q}[\sqrt[3]{2}, \sqrt{2}] &\to & \mathbb{Q}[\omega\sqrt[3]{2}, \sqrt{2}]\\
\uparrow &&\uparrow \\
\mathbb{Q}[\sqrt[3]{2}] & \to & \mathbb{Q}[\omega\sqrt[3]{2}]
\end{array}$$ If we choose the algebraically closure of $\left[\begin{matrix}\mathbb{Q}[\sqrt[3]{2}, \sqrt{2}] & \mathbb{Q}[\omega\sqrt[3]{2}, \sqrt{2}]\\ & \mathbb{Q}[\omega\sqrt[3]{2}]\end{matrix}\right]$ by inclusion to $\overline{\mathbb{Q}}$ , and the closure of $\mathbb{Q}[\sqrt[3]{2}]\to \overline{\mathbb{Q}}$ by $\sqrt[3]{2}\mapsto \omega\sqrt[3]{2}$ . 
We cannot extend a well-defined functor. Similar problem exists for transcendental extension, for example, square like this $$\begin{array}{ccc}
\mathbb{C}[X,Y] &\to & \mathbb{C}[X^2,Y]\\
\uparrow &&\uparrow \\
\mathbb{C}[X] & \to & \mathbb{C}[X^2]
\end{array}$$ A reasonable method is to avoid phenomenon above is as follow. 
Fix an algebraically closed field $F$ , and take all of its subfields as ""skeleton"", then fix an isomorphism to a subfields of $F$ from all fields whose algebraic closure is $F$ up to an isomorphism. The isomorphic class of algebraically closure are completely dependen by its characteristic and the transcendental dimension over prime field $\mathbb{Q}$ or $\mathbb{F}_p$ . Now the problem is how to naturally chose extensions for endmorphisms. But unfortunately, the choice is fragile. For instance, consider the following diagram $$\begin{array}{ccccl}
\mathbb{Q}[\sqrt{3}, \sqrt{2}] &\to & \mathbb{Q}[\sqrt{3}, \sqrt{2}] &: &\sqrt{3}\mapsto -\sqrt{3},\sqrt{2}\mapsto \pm \sqrt{2}\\
\uparrow &&\uparrow \\
\mathbb{Q}[\sqrt{3}] & \to & \mathbb{Q}[\sqrt{3}] &:&\sqrt{3}\mapsto -\sqrt{3}
\end{array}$$ There is no suitable choice such that $$\begin{array}{ccccl}
\overline{\mathbb{Q}} &\to & \overline{\mathbb{Q}} &: &\sqrt{3}\mapsto -\sqrt{3},\sqrt{2}\mapsto \pm \sqrt{2}\\
\parallel &&\parallel \\
\overline{\mathbb{Q}}& \to & \overline{\mathbb{Q}} &:&\sqrt{3}\mapsto -\sqrt{3}
\end{array}$$ commutes for both $\pm=+$ and $\pm=-$ .","['field-theory', 'abstract-algebra', 'category-theory']"
3300150,Evaluating $\sum_{r=1}^n \frac{\tan(x/2^r)}{2^{r-1}\cos(x/2^{r-1})}$,I was asked to find the sum of $$\sum_{r=1}^n  \dfrac{\tan \dfrac{x}{2^r}}{2^{r-1}\cos\dfrac{x}{2^{r-1}}}$$ I proceeded by breaking $\tan x$ into $\sin x$ and $\cos x$ and writing numerator as follows $$\sin\left(\frac{x}{2^{r-1}}-\frac{x}{2^r} \right)$$ then by opening brackets and simplifying I got $$\frac{1}{2^{r-1}}\left(\tan\frac{x}{2^{r-1}}-\tan\frac{x}{2^r}\right)$$ But I couldn't proceed from here. Any help will be appreciated,"['trigonometric-series', 'trigonometry']"
3300153,What is a bispectrum analysis?,I am in the atmospheric sciences and when I read papers on non linear interactions I came up with this term - bispectrum . It is not very clear what a 2nd order cumulant is . So assuming I have wind speed magnitude across a latitude circle as a function of longitude and time I know that I can take a Fourier expansion of the wind speed across the entire globe. So then I can check for wavenumber from that Fourier expansion. I can also check for the temporal frequency of a wave. Then I am lost. Why would I want to take the bispectrum analysis ? So the paper I am reading talks of a cross spectrum analysis . I am not sure what that means but I am presuming if a particular time series has different temporal frequencies and assuming if the energies associated with these temporal frequencies interact with each other will that show up in a bispectrum analysis as explained in the introduction of this article - Introduction to bispectrum ? Here is a paper(not from my field) but from plasma physics that talks of the cross bispectrum . By taking simple use cases can somebody explain what is a bispectrum and from that a cross bispectrum ?,"['statistics', 'fourier-analysis', 'fourier-transform', 'correlation', 'cumulants']"
3300185,"Prove $\bigcup\limits_{n \in \mathbb{ N} }{\left[0,1-\frac{1}{n}\right]} = [0,1)$","First, I apologize for my English, it is not my native language. To solve this exercise I started by proving that $\displaystyle\bigcup_{n \in \mathbb{ N} }{\left[0,1-\frac{1}
 {n}\right]} \subseteq [0,1)$ : Let $x \displaystyle\bigcup_{n \in \mathbb{ N} }{\left[0,1-\frac{1}
 {n}\right]}$ . Therefore, there exist some $N \in \mathbb{N}$ such that $x \in \left[0,1-\frac{1}{N}\right]$ Since $N \in \mathbb{N}$ , $\frac{1}{N} > 0$ . (Note that in my case the natural numbers start at 1) Thus $0 \leq x \leq 1- \frac{1}{N} < 1$ , Then $x \in [0,1)$ This is, $\left[0,1-\frac{1}{N}\right] \subseteq [0,1)$ Then, $\displaystyle\bigcup_{n \in \mathbb{ N} }{\left[0,1-\frac{1}{n}\right]} \subseteq [0,1)$ . Edit (I used the suggestions received to finish the second part of the proof. Is this well? ) To obtain the opposite inclusion, suppose $x\subseteq [0,1)$ and choose $ \varepsilon =1-x >0$ . By the Archimedean property follows that there exist $N \in \mathbb{N}$ such that $\frac{1}{N}<1-x$ Thus, $0 \leqslant x<1-\frac{1}{N}$ . Therefore, $x \in \left[0,1-\frac{1}{N}\right]$ . This means, $x \in \displaystyle\bigcup_{n \in \mathbb{ N} }{\left[0,1-\frac{1}{n}\right]}$ . We conclude that $[0,1) \subseteq \displaystyle\bigcup_{n \in \mathbb{ N} }{\left[0,1-\frac{1}
 {n}\right]}$ .","['elementary-set-theory', 'calculus', 'metric-spaces', 'real-analysis']"
3300220,Is the localization of intersection of modules equal to the intersection of appropriate localizations?,"Given a commutative unital ring $R$ , and a multiplicative subset $S\subseteq R$ , I know that for two $R$ -submodules $M_1,M_2$ of $M$ , we have: (I) $S^{-1}M_1 \cap S^{-1}M_2= S^{-1}(M_1\cap M_2)$ (II) $S^{-1}M_1+S^{-1}M_2=S^{-1}(M_1+M_2)$ My question is does this also hold for infinite intersections and sums. I am pretty sure that a sum of localizations is equal to the localization of the sum, simply because every element in a sum of modules can be discussed within a finite sum. I suspect that this is untrue for the intersection, but I could not think of a counter-example.","['localization', 'abstract-algebra', 'commutative-algebra', 'modules']"
3300257,"$\lim_{n \to \infty}\frac{d(x_{n+1}, x_\star)}{d(x_n, x_\star)} = 0$, show that $d(x_n, x_\star)\leq K\varepsilon^n \quad \text{for all }n\geq 0$","Let $(\mathcal{X}, d)$ be a metric space and $(x_n)_{n = 0}^\infty$ a sequence in $\mathcal{X}$ converging to $x_\star \in \mathcal{X}$ , meaning that $\lim_{n \to \infty}d(x_n, x_\star) = 0$ We suppose that $$
\lim_{n \to \infty}\frac{d(x_{n+1}, x_\star)}{d(x_n, x_\star)} = 0
$$ Show that, for all $\varepsilon \in (0,1)$ , there exists $K = K(\varepsilon)\in (0,\infty)$ s.t. $$
d(x_n, x_\star)\leq K\varepsilon^n \quad \text{for all }n\geq 0 
$$ answer :
We suppose that $$
\lim_{n \to \infty}\frac{d(x_{n+1}, x_\star)}{d(x_n, x_\star)} = 0
$$ $\forall \varepsilon \in (0,1), \exists n_0 \in \mathbb{N}, \forall n\geq n_0,\frac{d(x_{n+1}, x_\star)}{d(x_n, x_\star)} \leq \varepsilon$ \newline
Then $d(x_{n +1}, x_\star)\leq \varepsilon d(x_n, x_\star)$ \newline
However $\forall n > n_0, \exists k\in \mathbb{N}^\star$ , $n = n_0 + k$ . And then: \begin{align*}
d(x_n, x_\star) &= d(x_{n_0 + k}, x_\star)\\
&\leq \varepsilon d(x_{n_0 + k-1}, x_\star) \qquad (1)\\
&\leq \varepsilon^2 d(x_{n_0 + k-2}, x_\star) \qquad (2)\\
&\leq \varepsilon^{(k_0)} d(x_{n_0}, x_\star)\cdot \frac{\varepsilon^{(k_0)}}{\varepsilon^{(k_0)}} \qquad (3)\\
&\leq \varepsilon^n\underbrace{\frac{d(x_{n_0}, x_\star)}{\varepsilon^{(n_0)}}}_{K_1}
\end{align*} And for $n \leq n_0$ : The set $\Big\{\frac{d(x_{n_0}, x^\star)}{\varepsilon^{(n_0)}}; n <n_0\Big\}$ is finite and therefore it has a maximum noted $K_2$ Then for $n \leq n_0$ : $d(x_n, x_\star) = \frac{d(x_{n}, x^\star)}{\varepsilon^{n}}\varepsilon^n \leq K_2\varepsilon^n$ We take $K(\varepsilon) = \max (K_1, K_2)$ and we have the result:
\newline $\forall n \in \mathbb{N}$ if $n \leq n_0$ ; $d(x_n, x_\star) \leq \varepsilon^n K_2 \leq \varepsilon^n K(\varepsilon)$ else ; $d(x_n, x_\star) \leq \varepsilon^n K_1 \leq \varepsilon^n K(\varepsilon)$ $\rightarrow \forall n \in \mathbb{N} d(x_n, x^\star) \leq \varepsilon^n K(\varepsilon)$ My question How can we justify that the inequality still remains valid when going from (1 : "" $\leq \varepsilon d(x_{n_0 + k-1}, x_\star)$ "" to (2: "" $\leq \varepsilon^2 d(x_{n_0 + k-2}, x_\star)$ "")","['limits', 'sequences-and-series']"
3300276,About the complement of a compact set.,"I tried to prove that If $\omega$ is the complement of a compact set, then $\omega$ has only one unbounded component. I know that the complement of a large disc containing the compact set is unbounded and connected. I see the prove saying that if $\omega$ is not connect, then it must have another component in the disc. But thus it is bounded. I just have a question of the definition of being ""bounded."" Why $\omega$ having at least one component bounded by the disc, another unbounded, being a bounded set?",['general-topology']
3300340,Definition of automorphism functor for $\mathbf{Lie}(\mathbf{Aut})(R) = \mathrm{Der}(R).$,"$\newcommand\Lie{\mathbf{Lie}} \newcommand\Aut{\mathbf{Aut}} \newcommand\Alg{\mathrm{Alg}} \newcommand\Grp{\mathrm{Grp}} \newcommand\Der{\mathrm{Der}}$ Let $F: \Alg \to \Grp$ be a functor and $R$ an algebra. Then $\Lie(F)(R)$ is a Lie algebra. My goal is to show that $\Lie(\Aut)(R)$ equals the Lie algebra of derivations $\Der(R).$ However, I am not sure how to define the functor $\Aut : \Alg \to \Grp.$ I can see two options: $\Aut$ maps an algebra $A$ to its automorphism group. We fix some algebra $R$ and define a functor $\Aut_R,$ where $\Aut_R(A)$ maps an algebra to the automorphism group of the tensor product $R \otimes A.$ From this, we construct a functor $\Aut$ which maps an algebra to the functor $\Aut_R.$ Then the goal is to prove $\Lie(\Aut(R)) = \Der(R).$ Does the first case suffice? I cannot see why the latter would be chosen, however it is used in Zhihau Chang's notes on Lie algebras of affine group schemes (see Section 4.3) and J.S. Milne's Basic Theory of Affine Group Schemes (see Ch VIII Section 2 and Ch XI). In the second case I am struggling to understand how the morphism $\Aut_R(f)$ is defined, where $f : A \to B$ is an algebra morphism. Take $\alpha$ to be an automorphism on $R \otimes A,$ that is $\alpha \in \Aut_R(A).$ Then its image under $\Aut_R(f)$ is defined as the automorphism $\beta$ on $R \otimes B$ where $$ \beta(r \otimes 1_B) = (1_R \otimes f)\alpha(r \otimes 1_A).$$ Why does it suffice to define $\beta$ on elements $r \otimes 1_B$ ? Moreover, how is it surjective on $R \otimes B$ if $f$ is not necessarily surjective?","['lie-algebras', 'category-theory', 'algebraic-geometry', 'abstract-algebra', 'noncommutative-algebra']"
3300343,"Characterization of real-valued $C^1$ functions on $[0,1]$","I have encountered the following example, where I found things I don't understand: Let $\Bbb{Q}^+$ be the set of positive rational numbers, $C([0,1])$ be the space of all continuous real-valued functions on $[0,1]$ and denote by $C^1$ the class of continuously differentiable functions in $C([0,1])$ .
  (At the endpoints we take one-sided derivatives.)
  Then for $f\in C([0,1])$ , $f\in C^1$ iff for all $\epsilon\in\Bbb{Q}^+$ there exists rational open intervals $I_0,\dots,I_{n-1}$ covering $[0,1]$ s.t. for all $j<n$ : $$\forall a,b,c,d\in I_j\cap [0,1], a\ne b,c\ne d,\lvert \frac{f(a)-f(b)}{a-b}-\frac{f(c)-f(d)}{c-d}\rvert\le \epsilon.$$ So for an open interval $J$ and $\epsilon>0$ , we put $$A_{J,\epsilon}=\{f\in C([0,1])\mid \forall a,b,c,d\in J\cap [0,1], a\ne b,c\ne d,\lvert \frac{f(a)-f(b)}{a-b}-\frac{f(c)-f(d)}{c-d}\rvert\le \epsilon\},$$ we have that $A_{J,\epsilon}$ is closed in $C([0,1])$ . As I understand it, functions in $C^1$ are characterized in terms of the uniform continuity of the quotient difference (right?). Question: How can I prove that? Attempt: By definition, $$f\in C^1 \iff \forall x\in (0,1),\exists \lim_{y\to x}\frac{f(y)-f(x)}{y-x}=f'(x), f'(x)=\lim_{y\to x}f'(y)$$ (at endpoints a similar condition holds with right/left limits).
It seems clear to me that the above implies continuity of the quotient difference at every $x\in [0,1]$ , but does the converse hold?
If not, how can I rigorously prove the above characterization? Thank you in advance for your help.","['continuity', 'derivatives', 'uniform-continuity', 'real-analysis']"
3300362,Fixed point theorem involving nonexpansive mapping on uniformly convex Banach space,"This is an exercise from the Dirk Werner's book about fixed point theorem: Let $X$ be a uniformly convex Banach space. Let $F:B_X\to X$ be a nonexpansive mapping, i.e. $$ \forall x,y\in B_X: \|F(x)-F(y)\|\leq \|x-y\|.$$ Here denotes $B_X$ the closed unit ball in $X$ . Then Either $F$ has a fixed point, or there exists some $x\in S_X$ and some $\lambda>1$ such that $F(x)=\lambda x$ . Here $S_X$ denotes the unit sphere of $X$ . If $F(S_X)\subset B_X$ , then $F$ has a fixed point. I am still working with 1. What I tried is to assume that $F$ has no fixed point. In this case, the range of $F$ is contained in the ball $B_{1+\|F(0)\|}$ , and using rescaling one easily concludes that $F(x)=\lambda x$ for some $x\in B_X$ and $\lambda>1$ . However, I am not able to conclude that the point $x$ is exactly a point on the sphere. Any advice and suggestion is very welcome! Some thoughts: To show the statement (assuming no fixed points) it is equivalent to show that the function $(F(z)-z)/\|F(z)-z\|$ has a fixed point. Notice that this function has image in $S_X$ , so one might want to apply the Browder's FPT to this function stated in the Werner's textbook. However, it is no more nonexpansive now, so my goal is to construct a new function, derived from this one, which has image in $B_X$ and nonexpansive.","['functional-analysis', 'fixed-point-theorems', 'real-analysis']"
3300405,Can a ring have no zero divisors while being non-commutative and having no unity?,"I was wondering if, in a ring, the property of having no zero-divisors (except for zero itself) is independent from the ring being commutative or from having a unity (i.e.multiplicative identity) so I started looking for a ring with the following properties: non-commutative no unity (i.e. no multiplicative identity: a so-called ""rng"") no zero-divisors I came up with the set of 2 x 2 matrices with even entries: $M_2(2\Bbb Z)$ endowed with the usual matrix addition and matrix multiplication.
It is: non-commutative: $$\begin{pmatrix}2&2\\2&0\end{pmatrix}\begin{pmatrix}0&2\\2&2\end{pmatrix}\neq\begin{pmatrix}2&2\\2&0\end{pmatrix}\begin{pmatrix}0&2\\2&2\end{pmatrix}$$ no unity: $$\begin{pmatrix}1&0\\0&1\end{pmatrix}\notin M_2(2\Bbb Z)$$ But unfortunately it does have zero divisors: $$\begin{pmatrix}2&0\\0&0\end{pmatrix}\begin{pmatrix}0&0\\0&2\end{pmatrix}=\begin{pmatrix}0&0\\0&0\end{pmatrix}$$ So, can you come up with a ring having those three properties? Or a proof that such a group cannot exist?","['ring-theory', 'rngs', 'abstract-algebra']"
3300453,Conjugacy classes in virtually nilpotent groups,Let $G$ be a f.g. virtually nilpotent group. Can an element $g\in G$ of infinite order be conjugate to its power $g^n$ for $n>1$ ? Let $G$ be a f.g. virtually abelian group. Is it true that elements of infinite order have finite conjugacy classes? Note that for the infinite dihedral group non-trivial elements of finite order have infinite conjugacy classes.,"['nilpotent-groups', 'group-theory', 'abelian-groups']"
3300465,"Finding the number of solutions to $\cos^4(2x)+2\sin^2(2x)=17(1+\sin 2x)^4$ for $x\in(0,2\pi)$","Number of solution of the equation $\cos^4(2x)+2\sin^2(2x)=17(1+\sin 2x)^4\; \forall $ $x\in(0,2\pi)$ what i try $\cos^4(2x)+2\sin^2 2x=17(1+\sin^2(2x)+2\sin 2x)^2$ $1+\sin^4 (2x)=17(1+\sin^4 2x+2\sin^2 2x+4\sin^24x+4\sin 2x(1+\sin^2 2x))$ $16\sin^4 (2x)+68\sin^3 2x+34\sin^2 2x+68\sin 2x+68\sin^2 4x+16=0$ How do i solve it Help me please",['trigonometry']
3300575,Does the sum $\sum_{n = 1} ^\infty \frac{\sqrt {n!}} {(3+\sqrt 1)(3+\sqrt 2)...(3+\sqrt n)} $ converge or diverge?,The task is to study the convergence of the series $\sum_{n = 1} ^\infty \frac{\sqrt {n!} } {(3+\sqrt 1)(3+\sqrt 2)...(3+\sqrt n)} $ . I've tried applying Gauss's and ratio test but it didn't get me anywhere. In my textbook it says that this series is convergent.,"['calculus', 'sequences-and-series']"
3300598,Can one prove that $f(ab) = f(a) + f(b)$ can only be a linear sum of the $4$ functions?,"I was recently wondering how many functions are there take the positive integers as inputs and follows the following property: $$ f(ab) = f(a) + f(b)$$ Here are some functions I could think of: $$ f_1(x) = \ln(x)$$ $$ f_2(x) = 0 $$ $$ f_3(x) = \text{Number of primes of }(x)$$ $$ f_4(x) = \text{Sum of primes of }(x)$$ For example: $$ f_3(75) = 1 + 2 =3 $$ $$ f_4(75) = 5+ 5+ 3 =13$$ with $f_3(0)= f_4(0) = 0$ Question Is it possible to prove any function with the property: $f(ab) = f(a) + f(b)$ can only be a linear combination of the functions $f_1$ , $f_2$ , $f_3$ and $f_4$ ?","['functions', 'discrete-mathematics', 'logarithms']"
3300617,"Suppose $f\in L^1(\mathbb R)$ satisfies $\int_G f(x)\,dx=\int_{\bar{G}}f(x)\,dx\ \ \text{for all open set } G\subset\mathbb R$, then $f=0$ a.e.","Problem: Suppose $f\in L^1(\mathbb R)$ satisfies $$\int_G f(x) dx=\int_{\bar{G}}f(x) dx\ \ \text{for all open sets } G\subset\mathbb R.$$ Show that $f(x)=0$ for almost all $x\in\mathbb R$ . My attempt: For any open set $G\subset\mathbb R$ , we can write $G=\bigcup_{k=1}^\infty (a_k,b_k)$ , where $a_1<b_1\leq a_2<b_2\cdots$ . The condition in the problem implies that $\int_{\cup_k\{a_k,b_k\}}f=0$ , right? But it seems right for all $f\in L^1(\mathbb R)$ since $m(\cup_k\{a_k,b_k\})=0$ . So I'm confused. What did I miss? Any help will be appreciated.","['measure-theory', 'analysis', 'real-analysis']"
3300631,Is my proof here correct (basic real analysis/order theory question)?,"I'm self-studying real analysis and came across a simple problem I was trying to solve (although I think this is more of an order theory problem): Let $A\subseteq \mathbb{R}$ so that $ε\:>0$ and $\forall \alpha \in A:\alpha >\:ε$ Show that the greatest lower bound (infimum) of $A$ is not $0$ . Pardon me if the language is somewhat imprecise, I translated this question to English and I'm not yet fully proficient in English mathematical terminology. Anyway, I solved this question in the following way: since all elements of set $A$ are bigger than $ε$ , I figured out that $Inf A=ε$ , and since $ε>0$ , we can use transitivity to conclude that $Inf A > 0$ , and therefore $Inf A 	\neq 0$ .∎ Is my proof correct and acceptable? Because in the solutions file, the author of the question did something different and proved it by contradiction. Thank you very much :)","['real-analysis', 'order-theory', 'calculus', 'elementary-set-theory', 'supremum-and-infimum']"
3300681,Intermediate steps in showing that $ \lim_{n\to\infty}\frac{n}{\sqrt[n]{n!}}= \lim_{n\to\infty}(1+\frac{1}{n})^{n}$,"I would like to understand why $ \lim_{n\to\infty}\frac{n}{\sqrt[n]{n!}}= \lim_{n\to\infty}(1+\frac{1}{n})^{n}$ . I was given a solution, but it gives no further details than $$\lim_{n\to\infty}\frac{n}{\sqrt[n]{n!}}=\lim_{n\to\infty}\sqrt[n]{\frac{n^n}{n!}}=\lim_{n\to\infty}\frac{(n+1)^{(n+1)}/(n+1)!}{n^n/n!}=\lim_{n\to\infty}(1+\frac{1}{n})^n.$$ What happened between $\lim_{n\to\infty}\sqrt[n]{\frac{n^n}{n!}}$ and $\lim_{n\to\infty}\frac{(n+1)^{(n+1)}/(n+1)!}{n^n/n!}$ ?","['limits', 'sequences-and-series']"
3300703,Counterexample finite intersection property,"Let $(X,\mathcal T)$ be a (not necessarily Hausdorff) topological space. It is well-known that $X$ is compact (in the sense of every open cover has a finite subcover) if and only if for every family of closed subsets $(C_i)_{i\in I}$ of $X$ satisfying the finite intersection property, $\bigcap _{i\in I}C_i$ is nonempty. Now does the following assertion hold: If $(X,\mathcal T)$ is compact and $(C_i)_{i\in I}$ is a family of $\textbf{compact}$ subsets satisfying the finite intersection property, then $\bigcap_{i\in I}C_i$ is compact. Since compact subsets in non-Hausdorff spaces need not be closed, I am not sure if this holds. Is there a counterexample?","['general-topology', 'examples-counterexamples', 'compactness']"
3300737,Evaluate $\lim_{n\to\infty} [{1\over kn}+{1\over k(n+1)}+{1\over k(n+2)}+\cdots+{1\over k(n+p-k)}]$ where $k<p$,"There are four options. Which of them is correct?- (a) ${p\over k}$ (b) ${k\over p}$ (c) $\log({p\over k})$ (d) ${\log p\over k}$ I somehow want to use the rule for evaluating this kind of sum using integration, i.e. $\int_{0}^{1} f(x) \ dx=\lim_{n\to\infty} {1\over n}\sum_{r=1}^{n}f({r\over n})$ But the given expression $\lim_{n\to\infty} [{1\over kn}+{1\over k(n+1)}+{1\over k(n+2)}+\cdots+{1\over k(n+p-k)}]={1\over k}\lim_{n\to\infty}{1\over n}\sum_{r=0}^{p-k}\frac{1}{1+{r\over n}}$ , sum running from $0$ to $p-k$ instead of $n$ . So, how to evaluate this limit? Thanks for assistance in advance.","['limits', 'definite-integrals', 'sequences-and-series', 'real-analysis']"
3300753,When is $y=3x^2+3x+1$ a prime number in $\mathbb{Z}$ with $x \in \mathbb{Z}$?,"The first few values of $y=3x^2+3x+1$ for integer values of $x$ are $7, 19, 37, 61, 91$ , and $127$ .  I am wondering under what conditions of $x$ is $y$ a prime number? I had initially hoped that Vieta's formula would produce something notable but was unsuccessful.  I believe that knowing $3x^2+3x+1$ factors as $\frac1{12}(-6ix + \sqrt3-3i)(6ix+\sqrt3+3i)$ could be useful, although I have not been able to make any further progress and would appreciate some help. I also wonder how the results on this might generalize over to other irreducible polynomials $ax^2+ax+1$ , although I am still trying to pick apart the case for $a=3$ .","['prime-factorization', 'irreducible-polynomials', 'number-theory', 'polynomials', 'prime-numbers']"
3300764,A polynomial with nowhere surjective derivative,"Let $P:\mathbb {R}^2\rightarrow \mathbb {R}^2$ be a polynomial map. It is given that the Jacobian of $P$ is everywhere not surjective. Must  the following  be true: There exist polynomial maps $f:\mathbb {R}^2 \rightarrow \mathbb {R}$ , $g:\mathbb {R} \rightarrow \mathbb {R}^2$ such that $P= g \circ f $ . Thank you. The reason why I put the tag abstract algebra instead of differential geometry tag only is because I am asking for the existence of morphisms which are polynomial maps and not just any morphisms in the category of smooth manifolds.","['algebraic-geometry', 'abstract-algebra', 'polynomials', 'implicit-function-theorem']"
3300771,If a sequence $\{x_{n}\}$ is a Cauchy sequence and the sequence has a limit point $x_{0}$ then $x_{n} \rightarrow x_{0}$,"I am trying to prove that if a sequence $\{x_{n}\}$ in a set $M\in X$ ( $X$ is a metric space) is a Cauchy sequence and the sequence has a limit point $x_{0}$ then $x_{n} \rightarrow x_{0}$ . I wish to understand the details in such a proof whence I will try to explain my thoughts. I know that the sequence $\{x_{n}\}_{N\in \mathbb{N}}$ is a Cauchy sequence which means that for all $\epsilon >0$ I can find an $N \in \mathbb{N}$ beyond which the distance between any to elements $x_{n}$ and $x_{m}$ of the sequence will be smaller than $\epsilon$ . This means that I can make the distance between any two element of the sequence arbitrarily small. Furthermore we know that $x_{0}$ is a limit point which means that for every $\epsilon>0$ there is a point $m \in M$ such that $m \in B(x_{0},\epsilon)$ . I wish to argue as follows: 1) I would like to argue that $x_{m}=m \in B(x_{0},\frac{\epsilon}{2})$ (I can freely choose $r=\frac{\epsilon}{2}$ since $x_{0}$ is a limit point. 2) Since $\{x_{n}\}$ is a Cauchy sequence $d(x_{n},x_{m})$ will be smaller than any $\epsilon$ I choose, so I choose $\frac{\epsilon}{2}$ . Therefore $d(x_{n},x_{m})<\frac{\epsilon}{2}$ . 3) Since $x_{m}=m \in B(x_{0},\frac{\epsilon}{2})$ then $d(x_{m},x_{0})<\frac{\epsilon}{2}$ . 4) Using the triangle inequality we have $d(x_{n},x_{0}) \leq d(x_{n},x_{m}) + d(x_{m},x_{0}) \leq \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon$ 5) We can conclude that $x_{n} \rightarrow x_{0}$ Can someone please comment on the proof and the arguments presented?
How can I convince myself of 1) ?
How do I convince myself of the choice of epsilon (I start my choice of epsilon from the fact that $x_{0}$ is a limit point and from this I choose my epsilon for the distance between $x_{n}$ and $x_{m}$ ). Many thanks","['cauchy-sequences', 'proof-verification', 'metric-spaces', 'real-analysis', 'convergence-divergence']"
3300775,Proving a space is complete by assuming Cauchy sequences converge,"I had an interesting debate with some classmates on how to prove that a space is complete. I went through the process of taking a Cauchy sequence, finding a candidate limit, and showing that the limit is both in the space and is the actual limit of the Cauchy sequence. However, some of my classmates instead supposed that the Cauchy sequence converged to something , and proceeded to show that the limit is in the space. Is their method correct? It seems odd to me to assume that the Cauchy sequence converges. I know we could use this to show that the space is closed, but we are not assuming that the ambient space is complete. They argue that every Cauchy sequence converges in the completion of the metric space so it is no problem assuming that the Cauchy sequence converges: all that is left is to show that the limit belongs to the space. Is this a legitimate strategy for showing that a space is complete? EDIT: More explicitly, to show a space $X$ is complete, can we say ``let $(x_n)$ be a Cauchy sequence that converges to $x$ . It suffices to show $x\in X$ ?''","['metric-spaces', 'real-analysis']"
3300788,What are the isomorphism classes of $\pi_1(\mathbb{R}^2\setminus C)$ where $C$ ranges over all countable subsets of $\mathbb{R}^2$?,"I recently thought of this problem and have made very little progress. I conjecture that $\pi_1(\mathbb{R}^2\setminus \mathbb{Q}^2)$ is the biggest possible such group, in the sense that every other group of this form is isomorphic to a subgroup of it, but I have no idea how to justify this. Is classifying these groups even possible? Do these groups always have to be free?","['general-topology', 'algebraic-topology', 'group-theory']"
3300839,Proof of De Gua's Theorem using Cauchy Binet,"I was trying to prove the generalized version of De Gua's theorem using the Cauchy-Binet formula , and I ran into a bit of trouble. We are considering a right-angled simplex in $\Bbb R^n$ whose corners are the origin and the coordinates $a_i e_i$ (where $a_i > 0$ and $e_1,\dots,e_n$ denotes the canonical basis of $\Bbb R^n$ ). The ( $n$ -dimensional) volume of a simplex whose corners are the origin and (column-vectors) $v_1,\dots,v_n$ can be computed with the formula $$
V = \frac 1{n!}\det \pmatrix{v_1 & \cdots & v_n}
$$ Similarly, the ( $(n-1)$ -dimensional) volume of a simplex whose corners are $v_1,\dots,v_n$ can be computed via $V^2 = \frac 1{((n-1)!)^2}\det M^TM$ where $$
M = \pmatrix{v_1 & v_2 & \cdots & v_n\\ 1 & 1 & \cdots & 1}
$$ (or so I believe). Note that the above $M$ is not square: it has size $(n+1) \times n$ . With the above in mind: let $A$ denote the diagonal matrix $$
A = \pmatrix{a_1 \\ & \ddots \\ && a_n}
$$ and let $x = (1,1,\dots,1)^T \in \Bbb R^n$ .
De Gua's theorem should tell us that $$
((n-1)!)^2 V^2 = \det \left[\pmatrix{A\\x^T}^T\pmatrix{A\\x^T}\right] = \sum_{i=1}^n (P/a_i)^2
$$ where $P = \det A = a_1 a_2 \cdots a_n$ .  However, applying the Cauchy-Binet formula yields $$
\det \left[\pmatrix{A\\x^T}^T\pmatrix{A\\x^T}\right] = P^2 + \sum_{i=1}^n (P/a_i)^2.
$$ The question: So, where did I go wrong?  I suspect that there's an issue with the $M^TM$ formula I give above, but I'm not confident that this is the issue.  If that is the issue, I'm not sure if the above proof is salvageable. Any feedback here is appreciated.","['matrices', 'proof-verification', 'linear-algebra', 'geometry']"
3300843,Derivative of sum of matrix-vector product,"I would like to take the derivative of the following expression w.r.t. the matrix $A \in \mathbb{R}^{m \times n}$ , i.e., $$ \frac{\partial \big( \sum_{i=1}^m (Ax)_i \big)}{\partial A}, $$ where $x \in \mathbb{R}^n$ . The second answer here gives the derivative of the matrix-vector product w.r.t. the matrix, but, I wasn't sure how it changes with the summation? Though I think that it should work out cleanly since derivative and summation are linear operators and can be interchanged? I am not sure about how the indices would change so any advice regarding that would be much appreciated.","['derivatives', 'matrix-calculus', 'linear-algebra']"
3300912,Obtaining positive eigenvalues of the matrix $A$?,"Let us consider the matrix $A$ which has three parameters $R,C1,C3$ . This is from the Ikeda map in real form. It is defined as $$x \rightarrow R+(x \cos(\tau)-y \sin(\tau))$$ $$y \rightarrow x\sin(\tau)+y\cos(\tau)$$ The Jacobain matrix is given by: \begin{equation*}
A =
\begin{bmatrix}
 \cos(\tau) + x \frac{\partial}{\partial x} \cos \tau - y\frac{\partial}{\partial x}\sin\tau & x\frac{\partial}{\partial y} \cos \tau - \sin \tau - y \frac{\partial}{\partial y} \sin \tau\\
\sin\tau + x \frac{\partial}{\partial x} \sin \tau + y \frac{\partial}{\partial x} \cos \tau & x \frac{\partial}{\partial y}\sin\tau + \cos \tau + y\frac{\partial}{\partial y}\cos \tau
\end{bmatrix}
\end{equation*} where $$\tau = C_{1} - \frac{C_{3}} {1+x^2+y^2}$$ $x,y$ are solutions of the non-linear equation \begin{equation}
R+x \cos \tau - y \sin \tau = x\\
x\sin \tau + y \cos \tau = y
\end{equation} After calculating the determinant of the matrix $A$ , we get $det(A)=1$ (so product of eigenvalues is 1) using $$\frac{\partial \tau}{\partial x} = \frac{2C_{3}x}{(1+x^2+y^2)^2}$$ $$\frac{\partial \tau}{\partial y} = \frac{2C_{3}y}{(1+x^2 + y^2)^2}$$ I am wondering for which values of $R,C_{1},C_{3}$ I can obtain positive eigenvalues? as I see after trying many values I get complex eigenvalues or negative eigenvalues. I am thinking whether the above matrix can have any positive eigenvalues at all? Any sharp hawk eye observations to this? EDIT - If suppose $R=0$ , then we see that $x=0,y=0$ satisfies the non linear equation and if we obtain the trace of the matrix at $(0,0)$ we get the trace as $2\cos \tau$ and now for the eigen values to be real and positive we need $\cos \tau > 1$ which is not possible so we can eliminate the $R=0$ case. Now I am thinking whether if for $R \neq 0$ , can we have positive eigenvalues for the Jacobian matrix?","['eigenvalues-eigenvectors', 'matrices', 'computational-mathematics', 'linear-algebra', 'dynamical-systems']"
3300921,"Show that for any $a \ne 0$, $f(x)=1/x$ approaches $1/a$ as $x$ approaches $a$.","To show in general that $f$ approaches $1/a$ near $a$ for any $a$ we proceed in basically the same way, except that,again, we have to be a little more careful in formulating our initial stipulation. It's not good enough simply to require that $|x-a|$ should be less than $1$ , or any other particular number, because if $a$ is close to $0$ this would allow values of $x$ that are negative (not to mention the embarrassing possibility that $x=0$ , so that $f(x)$ isn't even defined!). The trick in this case is to first require that $$|x-a|<\frac{|a|}{2};$$ in other words, we require that $x$ be less than half as far from $a$ as $a$ is from $0$ . You should be able to check first that $x \ne 0$ and that $1/|x|$ < $2/|a|$ , and then work out the rest of the argument. In order to check that $x \ne 0$ I checked both cases $a \ge 0$ and $a<0$ : $a > 0$ : $|x-a|<\dfrac{|a|}{2}$ $\implies$ $-\dfrac{|a|}{2}<x-a<\dfrac{|a|}{2}$ $\implies$ $-\dfrac{a}{2}<x-a<\dfrac{a}{2}$ $\implies$ $-\dfrac{a}{2}+a<x<\dfrac{a}{2}+a$ and so $\dfrac{2a-a}{2}<x<\dfrac{a+2a}{2}$ . Thus $x>0$ since $0<\dfrac{a}{2}<x$ . $a<0$ : $|x-a|<\dfrac{|a|}{2}$ $\implies$ $-\dfrac{(-a)}{2}<x-a<\dfrac{(-a)}{2}$ $\implies$ $-\dfrac{(-a)}{2} + a <x<\dfrac{(-a)}{2}+a$ $\implies$ $\dfrac{a}{2}+a=\dfrac{2a +a}{2}=\dfrac{3a}{2}<x<\dfrac{(-a)}{2}+a=\dfrac{2a-a}{2}=\dfrac{a}{2}$ . Therefore $x<0$ since $x<\dfrac{a}{2}<0$ . In order to get that $1/|x|<2/|a|$ , I did the following: $|x-a|<\dfrac{|a|}{2}$ $\implies$ $-\dfrac{|a|}{2}<x-a<\dfrac{|a|}{2}$ and so $-\dfrac{|a|}{2}+a<x$ $\implies$ $-\dfrac{3|a|}{2}=-\dfrac{|a|}{2}-|a|\le-\dfrac{|a|}{2} + a< x$ which implies that $\dfrac{1}{x}<-\dfrac{2}{3|a|}<\dfrac{2}{3|a|}<\dfrac{2}{|a|}.$ Thus verifying that $\dfrac{1}{|x|}<\dfrac{2}{|a|}$ . Now using this information, I am to show that in general, $f(x)=1/x$ approaches $1/a$ for $x$ near $a$ . My approach so far: $\biggl|\dfrac{1}{x} - \dfrac{1}{a}\biggr|=\biggl|\dfrac{a-x}{ax}\biggr|=\dfrac{1}{a}\cdot\dfrac{1}{|x|}\cdot |x-a|<\dfrac{1}{a}\cdot \dfrac{2}{|a|}\cdot |x-a|$ and so requiring that $|x-a|<\dfrac{|a|\cdot a}{2}\epsilon$ gives us our desired result. What is the problem with allowing negative values of $x$ ?","['epsilon-delta', 'proof-verification', 'analysis', 'real-analysis', 'limits']"
3300943,Four vertices of a regular dodecagon are randomly selected. Find the probability that they form a rectangle (including squares).,"Four points are randomly selected from the set of the vertices of a regular  dodecagon (or 12 sided regular polygon). Find the probability that those four points  form a rectangle (including squares). I tried by trying to see the cases where there are rectangles or squares by connecting some vertices, but ended up resorting to bashing. It would be helpful if someone gives a less bashy way to solve this.","['geometry', 'probability']"
3300968,Embedding a Hilbert space into the bounded operators on a Hilbert space,Consider a norm-decreasing linear map from a Hilbert space $H$ to the bounded linear operators $B(H')$ on another Hilbert space $H'$ . Can it happen that the image of $H$ in $B(H')$ is not closed - can somebody please give an example.,"['hilbert-spaces', 'c-star-algebras', 'functional-analysis', 'operator-algebras']"
3301051,How many elements in a 3rd order tensor with certain symmetries?,"I have a tensor $A_{ijk}$ were indices $i$ , $j$ , and $k$ run from $1$ to $N$ . Obviously there are $N^3$ elements, but how many unique elements are there if the following symmetries exist? $A_{iij} = A_{iji} = A_{jii} $ $A_{ijk} = A_{ikj} = A_{jik} = A_{jki} = A_{kij} = A_{kji}$ These are all the symmetries that would exist with differentiation, since this tensor actually represents the third derivative of a function.","['statistics', 'tensors', 'combinatorics']"
3301059,Showing $\int_0^{\pi} \log(2 - 2 \cos x) = 0$.,"I want to show that $$\int_0^{\pi} \log(2 - 2 \cos x) = 0$$ However, I cannot do this.  I tried splitting the integral into $\int_0^{\pi/3} \log(2 - 2 \cos x)\,dx + \int_{\pi/3}^{\pi} \log(2 - 2 \cos x) \,dx$ and showing that the two parts were negatives of one another.  Wolframalpha does not give very a simple antiderivative.  I was wondering if there was a nice way to do this. Other attempts: using $\int_0^a f(x) \,dx = \int_0^{a} f(a-x) \,dx$ , trying to change the $\cos$ to $\sin$ by some substitution like $u = \pi/2 - x$ and trying to get things to cancel.","['integration', 'definite-integrals', 'logarithms', 'calculus', 'trigonometric-integrals']"
3301141,Rational Decomposition,"Find the partial fractions for $\frac{3x^5+7x^4-7x^3-3x^2+x}{3x^2+10x+3}$ First, I recognize it's not a proper fraction. I also know the denominator is $(x+3)(3x+1)$ . Now every time I try long division to convert to a proper fraction by hand I get $x^3-x^2+1+(\frac{-10x-3}{(x+3)(3x+1)})$ , but this is wrong because I'm supposed to get $x^3-x^2+\frac{x}{(x+3)(3x+1)}$ . I can't find the partial fraction just yet if I can't convert this into a proper fraction. When I tried I got very close, but not exactly correct at all. I wish I could show my work, but it seems displaying long division or synthetic division isn't doable on this website. Can anyone help? Or provide an alternative method that may not require so much long division?","['algebra-precalculus', 'polynomials']"
3301156,The closed-form solution of the family $\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(pn+m)}$?,"( The results below extend this post .) Given the Clausen function $\operatorname{Cl}_n\left(z\right)$ . And, $$\begin{aligned}
\operatorname{Cl}_2\left(\frac\pi2\right) &= \text{Catalan's constant}\\
\operatorname{Cl}_2\left(\frac\pi3\right) &= \text{Gieseking's constant}\\
\operatorname{Cl}_2\left(\frac\pi4\right) &= \text{unnamed}\\
\operatorname{Cl}_2\left(\frac\pi6\right) &= \tfrac23\,\operatorname{Cl}_2\left(\frac\pi2\right)+\tfrac14\,\operatorname{Cl}_2\left(\frac\pi3\right)
\end{aligned}$$ Then we have the closed-forms, \begin{eqnarray*}
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(n+m)} &=& 2 \zeta(3) \\
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(2n+m)} &=& \frac{11}{8} \zeta(3) \\
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(3n+m)} &=& \frac{5}{3} \zeta(3) -\frac{2}{9}\pi\,\operatorname{Cl}_2\left(\frac\pi{\color{blue}3}\right)\\
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(4n+m)} &=& \frac{67}{32} \zeta(3) -\frac{1}{2}\pi\, \operatorname{Cl}_2\left(\frac\pi2\right) \\
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(6n+m)} &=& \frac{73}{24} \zeta(3) -\frac{8}{9}\pi\,\operatorname{Cl}_2\left(\frac\pi{\color{blue}3}\right)\\
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(8n+m)} &=& \frac{515}{128} \zeta(3) -\frac{3}{8}\pi\,\operatorname{Cl}_2\left(\frac\pi2\right)-\pi\,\operatorname{Cl}_2\left(\frac\pi{\color{red}4}\right)\\
\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(12n+m)} &=& \frac{577}{96} \zeta(3) -\frac{7}{6}\pi\,\operatorname{Cl}_2\left(\frac\pi2\right)-\frac{19}{18}\pi\,\operatorname{Cl}_2\left(\frac\pi{\color{blue}3}\right)\\
\end{eqnarray*} where for $p=12$ we could have used $\operatorname{Cl}_2\left(\frac\pi2\right)$ and $\operatorname{Cl}_2\left(\frac\pi6\right)$ . As the OP from the other post points out, note that, $$I(p)=\sum_{n=1}^{\infty} \sum_{m=1}^{\infty} \frac{1}{nm(pn+m)} =\int_0^1  \frac{\ln(1-z) \ln(1-z^p)}{z} dz$$ Q: The results above suggest a family. Can we find the closed-form of the integral $I(p)$ for $p=5$ and others? $\color{red}{\text{Update July 24}}$ : Thanks to Zacky's answer which provided the clue that more than one Clausen function with argument $\frac{m\,\pi}p$ may be needed, after some tinkering, I managed to find a closed-form for $I(p)$ , namely, $$I(p)= \frac{p^3+3}{2p^2}\zeta(3)-\frac{\pi}p\sum_{k=1}^{\lfloor(p-1)/2\rfloor}(p-2k)\operatorname{Cl}_2\left(\frac{2k\pi}p\right)$$ with floor function $\lfloor x\rfloor$ . I found this using odd $p$ , but it seems to work for even $p$ as well. However, a rigorous proof is needed to show it holds true for all $p$ .","['integration', 'definite-integrals', 'experimental-mathematics', 'closed-form', 'constants']"
3301159,Immersion is equivalent to local embedding: Different proof when image is submanifold,"Update : Based on this , I think: Surjective immersions are local diffeomorphisms because surjective immersions have $\dim {\text{domain}} = \dim{\text{range/image}}$ . Similarly, immersions whose images are (regular/embedded) submanifolds of range are local diffeomorphisms onto their images because $\dim {\text{domain}} = \dim{\text{image}}$ , i.e. $n=k$ , as below. Please verify that this in fact answers these three questions: Immersions whose images are actually submanifolds? Or surjective immersions? (I think surjective immersions are local diffeomorphisms) https://math.stackexchange.com/questions/3301259/are-immersions-equivalent-to-local-diffeomorphisms-onto-their-images-if-their-im Immersion is equivalent to local embedding: Different proof when image is submanifold Question A . For these proofs (one on stackexchange, one on wordpress ) that immersions are local embeddings: I understand that images of immersions are immersed submanifolds , not necessarily (regular/embedded) submanifolds and not necessarily manifolds. Do I understand correctly that, nevertheless, immersions are local embeddings and that these proofs indeed prove such with the images of the immersions being assumed only immersed submanifolds? Question B . Is this proof for immersion, whose image is a submanifold, is a local embedding correct? (I won't prove that local embeddings are immersions.) In particular, I'm not sure about (5). I think (5) is true if $F(N)$ has the same dimension as $N$ . I think I at least proved local diffeomorphisms onto images with images submanifolds are local embeddings Let $N$ and $M$ be smooth manifolds with respective dimensions $n$ and $m$ . Let $p \in N$ . Let $F: N \to M$ be an immersion at $p$ . Let its image $F(N)$ be a (regular/embedded) $k$ -submanifold of $M$ . Let us show $F$ is a local embedding at $p$ , defined as that there exists a neighborhood $V_p$ of $p$ in $N$ such that $F|_{V_p}: V_p \to M$ is an embedding. Because $F(N)$ is a submanifold of $M$ , $F(N)$ is a manifold, so it would make sense to say, if we were to say that 3.1. The inclusion $\iota: F(N) \to M$ is a map of manifolds 3.2. $\tilde F: N \to F(N)$ , $F$ with restricted range that satisfies $F = \iota \circ \tilde F$ , is a map of manifolds. Assert (3.1) and (3.2). Additionally, the maps in (3) are smooth because $F(N)$ is a submanifold: 4.1. $\iota$ is smooth by this 4.2. $\tilde F$ is smooth by this . $\tilde F$ is a local diffeomorphism, i.e. $F$ is a ""local diffeomorphism onto its image"" by this , where there is no ambiguity in the definition of ""local diffeomorphism onto its image"" because its image is a submanifold. Edit: Not quite sure about this step actually. I think true if $n=k$ . Let $G=\tilde F$ By (5), there exists a neighborhood $U_p$ of $p$ in $N$ such that $G(U_p)$ is open in $F(N)$ , and $\tilde{G|_{U_p}}: U_p \to G(U_p)$ is a diffeomorphism, where $\tilde{G|_{U_p}}$ is $G|_{U_p}: U_p \to F(N)$ with restricted range. Choose $V_p = U_p$ . This works because, under this definition for embedding , equivalent to the more natural one : 7.1 $G|_{U_p}$ is an immersion if and only if $\tilde{G|_{U_p}}$ is an immersion, by this . 7.2 $G|_{U_p}$ is a topological embedding because $\tilde{G|_{U_p}}$ is a homeomorphism because $\tilde{G|_{U_p}}$ is a diffeomorphism. 7.3 $F|_{U_p} = \iota \circ G|_{U_p}$ 7.4 $F|_{U_p}$ is an immersion if both $G|_{U_p}$ and $\iota$ are immersions. 7.5 $\iota$ is an immersion by this . 7.6 $\tilde{G|_{U_p}}$ is an immersion since $\tilde{G|_{U_p}}$ is a diffeomorphism. 7.7 $G|_{U_p}$ is an immersion by (7.1) and (7.6). 7.8 Therefore, $F|_{U_p}$ is an immersion by (7.4) and (7.7). 7.9 $F|_{U_p}$ is a topological embedding if and only if $G|_{U_p}$ is a topoloigcal embedding. 7.10 Therefore, $F|_{U_p}$ is a topological embedding by (7.9) and (7.2). 7.11 Therefore, $F|_{U_p}$ is a smooth embedding by (7.10) and (7.8).","['solution-verification', 'manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
3301179,Why do Carmichael numbers (appear to) frequently end in $1$?,"An integer $n$ is a Carmichael number if it is composite and satisfies $a^{n-1} \equiv 1(\mod{n})$ for all integers $a$ with $1<a<n$ and $\gcd(a,b)=1$ .  From the relevant OEIS : $$561, 1105, 1729, 2465, 2821, 6601, 8911, 10585, 15841, 29341, 41041, 46657, 52633, 62745, 63973, 75361, 101101, 115921, 126217, 162401, 172081, 188461, 252601, 278545, 294409, 314821, 334153, 340561, 399001, 410041, 449065, 488881, 512461$$ Are the first $33$ Carmichael numbers.  If we consider that Carmichael numbers must end in $1, 3, 5, 7$ , and $9$ , then with no further consideration one might begin with the very rough heuristic that out of the first $k$ Carmichael numbers approximately $\frac15$ must end in $1$ , for reasonably large $k$ , if you expect equitable distribution for whatever reason. Yet we have $20$ Carmichael primes which end in $1$ out of the first $33$ , which very much so does not suggest any equitable distribution. I would like some clarification as to why this is, hopefully in an at least partly analytic approach. edit: a quick scroll through a much longer list of Carmichael numbers similarly suggests a much greater amount one Carmichael numbers which end in $1$ than would seem normal.  Additionally, they almost always seem to be consecutive; this might just be due to the fact that there are more of them.","['number-theory', 'carmichael-numbers']"
3301219,Cosine interpolation reverts to linear interpolation in higher dimensions?,"Paul Bourke's article on interpolation explains different types of interpolation including linear, cubic, Hermite spline and cosine.  He goes on to state (emphasis mine): In most cases the interpolation can be extended into higher dimensions simply by applying it to each of the x,y,z coordinates independently. This is shown on the right for 3 dimensions for all but the cosine interpolation. By a cute trick the cosine interpolation reverts to linear if applied independently to each coordinate. I've implemented all of them in 2D and realized the truth in this.  When I interpolate between 2D points by linearly interpolating X and cosine interpolating Y the output is curvy; however, if I interpolate both X and Y independently by cosine, it does revert to being a linear interpolation. Looking at the equations, I guess it should be something to do with the same parameter t being used for both the equations, that makes this $$
    x(t) = x_1 + ((1 - \cos({t \pi})) / 2) (x_2 - x_1)  \\
    y(t) = y_1 + ((1 - \cos({t \pi})) / 2) (y_2 - y_1)
$$ into $$
    x(t) = x_1 + t (x_2 - x_1)  \\
    y(t) = y_1 + t (y_2 - y_1)
$$ I'm really interested in knowing what ""cute trick"" makes cosine interpolation linear.","['trigonometry', 'interpolation', 'parametric']"
3301247,On $\mathcal{A}$ with $\forall C\in\mathcal{P}_{\infty}(\mathbb{N})\exists A\in\mathcal{A}:A\cap C\in\mathcal{P}_{\infty}(\mathbb{N})$,"Edit: I came up with an answer myself, see below. Denote $\mathcal{P}_{\infty}(\mathbb{N})=\{A\subseteq\mathbb{N}\ |\ A\text{ infinite}\}$ and let $\mathcal{A}\subseteq \mathcal{P}_{\infty}(\mathbb{N})$ be such that for all $C\in\mathcal{P}_{\infty}(\mathbb{N})$ there exists $A\in\mathcal{A}$ with $A\cap C\in\mathcal{P}_{\infty}(\mathbb{N})$ . Furthermore, suppose that $\mathcal{A}$ is stable under finite union, i.e. $A\cup B\in\mathcal{A}$ for all $A,B\in\mathcal{A}$ . Is it true that there exists $N\in\mathbb{N}$ and $A\in\mathcal{A}$ such that $\{N,N+1,...\}\subseteq A$ ? This question came up when I tried to characterize the sets $\mathcal{B}\subseteq \mathcal{P}_{\infty}(\mathbb{N})$ such that a sequence $a\in\mathbb{R}^\mathbb{N}$ converges to some $a_\infty\in\mathbb{R}$ if and only if $a|_{B}$ converges to $a_\infty$ for every $B\in\mathcal{B}$ . If the statement in question would be true, then it would imply that there must be $B_1,...,B_n\in\mathcal{B}$ and $N\in\mathbb{N}$ with $\{N,N+1,...\}\subseteq B_1\cup...\cup B_n$ . I tried to generalize the concepts that arise here and when doing so, I realized that it seems to be linked to a notion that I never learned about in class yet but already heard of, namely that of a filter . This is because if we define the quasi-order $\lesssim$ on $\mathcal{P}(\mathbb{N})$ by $$
\forall A,B\in\mathcal{P}(\mathbb{N}):\quad A\lesssim B\iff \exists N\in\mathbb{N}:A\cap[N,\infty[\supseteq B\cap[N,\infty[,
$$ then $\mathcal{A}$ can be extended to a filter to of $(\mathcal{P}(\mathbb{N}),\lesssim)$ by also including all subsets of elements of $\mathcal{A}$ into $\mathcal{A}$ . The problem is that apart from being able to understand the definition, I know nothing about filters. Is there a theorem or concept which simplifies matters here?","['filters', 'convergence-divergence', 'set-theory', 'sequences-and-series']"
3301261,Immersions whose images are actually submanifolds? Or surjective immersions? (I think surjective immersions are local diffeomorphisms),"Update : Based on this , I think: Surjective immersions are (surjective) local diffeomorphisms because surjective immersions have $\dim {\text{domain}} = \dim{\text{range/image}}$ . In particular, surjective immersions are equivalent to surjective local diffeomorphisms. Similarly, immersions whose images are (regular/embedded) submanifolds of range are local diffeomorphisms onto their images because $\dim {\text{domain}} = \dim{\text{image}}$ , i.e. $n=k$ , as below. Please verify that this in fact answers these three questions: Immersions whose images are actually submanifolds? Or surjective immersions? (I think surjective immersions are local diffeomorphisms) Are immersions equivalent to local diffeomorphisms onto their images if their images are submanifolds? Different proof for immersion is equivalent to local embedding when image is submanifold Let $N$ and $M$ be smooth manifolds with respective dimensions $n$ and $m$ . Let $p \in N$ . Let $F: N \to M$ be an immersion at $p$ . It can be shown $F$ is a local embedding at $p$ (and conversely ). Main questions : If $F$ is an immersion for each $p \in N$ and $F(N)$ is, not only an immersed submanifold of $M$ , but actually a (regular/an embedded) $k$ -submanifold of $M$ , then what can we say (about $F$ , $N$ , $F(N)$ , the restriction $\tilde F: N \to F(N)$ etc)? Or what about if $F$ is additionally surjective (then its image is of course a submanifold of itself...I guess )? So far I have: (I think these don't use that $F$ is an immersion.) A. The inclusion $\iota: F(N) \to M$ is a smooth topological embedding and  immersion. B. The map $\tilde F: N \to F(N)$ , $F$ with restricted range that satisfies $F = \iota \circ \tilde F$ is smooth. Some guide questions for the main questions: C. Does $N$ have the same dimension as $F(N)$ , i.e. is $n=k$ ? D. I haven't thought of any other guide questions. I'm asking because I find that the assumption that $F(N)$ is a submanifold makes the proof that $F$ is a local embedding a lot simpler , assuming the proof is correct. Whether or not the proof is correct, I'm thinking that there's something more to this. Perhaps assuming $F(N)$ submanifold makes $F$ into something where it would be obvious that $F$ is indeed a local embedding, such as because $F$ is actually an embedding (I think $F$ isn't necessarily injective) or a local diffeomorphism (I think immersions are not necessarily local diffeomorphisms). We might be able to characterize such immersions as equivalent to local diffeomorphisms onto their images . But in this case I think this would mean that surjective immersions are (surjective) local diffeomorphisms. While this would be consistent with both that bijective immersions are diffeomorphisms and that bijective local diffeomorphisms are diffeomorphisms, I wasn't able to find anything about surjective immersions being local diffeomorphisms, but I think this is true if $n=m$ and even if not surjective (and immersions would be local diffeomorphisms onto their images if $n=k$ , I guess). In relation to (1), I think (both local diffeomorphisms and) local diffeomorphisms onto images are local embeddings. Since immersions are equivalent to local embeddings , I guess a local embedding with a submanifold image is a local diffeomorphism onto image. For such an $F$ , we can say $F$ is an immersion if and only if $\tilde F$ is an immersion . I suppose we might say this even if $F(N)$ weren't a submanifold or maybe even if not a manifold as long as we have some kind of smoothness definition .","['manifolds', 'general-topology', 'differential-topology', 'differential-geometry']"
3301267,Can the derivative of a function that involves $\sqrt{x}$ have 2 answers?,"Textbook question- Calculate the gradient of the tangent where $x=1$ for: $f(x)=3x^3+x\sqrt{x}$ . My working- Okay here i used the power rule to determine the derivative, and i got: $f'(x)=9x^2+\frac{3}{2}\sqrt{x}$ . From my equation, $f'(1)=\frac{21}{2}$ .But my textbook answer gave: $f'(1)=\frac{15}{2}$ . Which means that the textbook's equation is $f'(x)=9x^2-\frac{3}{2}\sqrt{x}$ . It somehow turned into minus which i could not understand. So my question is can the $\frac{3}{2}\sqrt{x}$ be ± (plus or minus)? Thanks.","['calculus', 'derivatives']"
3301270,A family of probability measures is dominated by a $\sigma$-finite measure then it is dominated by a probability measure.,"I am reading Jun Shao's Mathematical Statistics and I got stuck on the proof of this lemma: I understood the proof but to extend it from finite measure $\nu$ to a $\sigma$ -finite measure $\nu$ is not trivial for me. I have try to decompose $\nu$ as a countable sum of finite measures $\nu_i$ . But then, the family $\mathcal{P}$ is not dominated by $\nu_i$ . If someone could give me a correct idea, I would be very appreciated. Note: A measure $\mu$ is dominated by $\nu$ if $\mu$ is absolutely continuous with respect to $\nu$ . In other words, $\nu(E)=0$ implies $\mu(E)=0$ .","['proof-explanation', 'statistics', 'measure-theory']"
3301303,Algebra for Algebraic Geometry/Topology,"I am an Applied Math student. I have concluded my BSc and will be moving to Pure Math this September. I am writing to have some advice about what Algebra I should study to start tackling Algebraic Geometry and (advanced) Algebraic Topology. My background consists in Linear Algebra and a 'fundational' course covering the basics of Groups, Rings and Fields. So I think I can learn about this topics, having all the necessary prerequisites, but do not know which are the most relevant and fundamental topics to the stated area. 
Any advice and reference to some compact text apt to self study would be great!","['self-learning', 'reference-request', 'algebraic-geometry', 'abstract-algebra', 'algebraic-topology']"
3301334,How to show that $f:V\to V$ is linear?,"Let $(V,|.|)$ be a normed finite dimensional vector space and $f:V\to V$ a map with the following property: $|f(y)|=|f(x+y)-f(x)|,\quad \forall x, y\in V.$ Then how to prove that $f$ is linear? Update: what can be say if $V$ is a real vector space?","['normed-spaces', 'linear-algebra', 'vector-spaces', 'linear-transformations']"
3301360,"Find all $(x,a,b,c)\in \mathbb{Q}_+\times\mathbb{N}^{*3}$ such that $\cos(\pi x)=\frac{\sqrt {a}+b}{c}$","We will assume that $0<\pi x<\frac{\pi}{2}$ or $0<x<\frac{1}{2}$ case 1 : If $a$ is a perfect square, say $a=\alpha^2$ , $\alpha\in \mathbb{N}^*$ , then the question is equivalent to find $x$ rational such that $\cos(\pi x)$ is rational: $\cos(\pi x)=\frac{\alpha + b}{c}$ Using Niven's theorem, as discussed here or here , the only solution for $0<x<\frac{1}{2}$ is $x=\frac{1}{3} $ ; $\cos(\frac{\pi}{3})=\frac{1}{2}$ Therefore, $c$ must be even, $a=(\frac{c}{2}-b)^2$ and $c>2b$ case 2 : If $a$ is not a perfect square, here is a conjecture : there is a  unique solution $x=\frac{1}{5}$ and $\cos(\frac{\pi}{5})=\frac{\sqrt{5}+1}{4}$ more precisely: $x=\frac{1}{5}$ ; $ a=5k^2$ ; $b=k$ ; $c=4k$ ; $k\in\mathbb{N}^*$ Any proof or counterexample? UPDATE The link given by @Fabio Lucchini proves that the topic is not new and has been already studied in details. The conjecture is true but more importantly the results are for $cos(\pi x)=\frac{\sqrt a +b}{c}$ ; $0\leq x\leq \frac{1}{2}$ ; $x\in\mathbb{Q}$ , $a\in \mathbb{N}$ , $b\in \mathbb{N}$ , $c\in \mathbb{N^*}$ i.e including $a=0$ or $b=0$ $x=0 $ ; $\; $ $\cos(0)=1$ $x=\frac{1}{6}$ ; $\; \cos(\frac{\pi}{6})=\frac{\sqrt 3}{2}$ $x=\frac{1}{5}$ ; $\; \cos(\frac{\pi}{5})=\frac{\sqrt 5 +1}{4}$ $x=\frac{1}{4}$ ; $\; \cos(\frac{\pi}{4})=\frac{\sqrt 2}{2}$ $x=\frac{1}{3}$ ; $\; \cos(\frac{\pi}{3})=\frac{1}{2}$ $x=\frac{1}{2}$ ; $\; \cos(\frac{\pi}{2})=0$",['trigonometry']
3301389,Linear map of borel set is a measurable set?,"Let $T\colon\mathbb{R}^n \to \mathbb{R}^m$ ( $n>m$ ) be a linear map. Is it true that $T(A)$ is a Lebesgue measurable set for the Borel set $A$ ? $T(A)$ for the compact set $A$ is compact set, so is measurable. If $A$ is an open set, then $A$ is countable sum of compact sets and $T(A)$ is measurable. For closed set is the same situation. I don't know what else for other type of Borel sets? Of course, it may by used the open mapping theorem if we assume that $T$ is surjective.","['measure-theory', 'geometric-measure-theory']"
3301407,Find all $x$ such that $\sin x = \frac{4}{5}$ and $\cos x = \frac{3}{5}$.,"Let $$
\left\{ 
\begin{array}{c}
\sin x = \frac{4}{5} \\ 
\cos x = \frac{3}{5}
\end{array}
\right. 
$$ Find all of the possible values for $x$ . My try: By dividing the equations we obtain $\tan x = \frac{4}{3}$ and then $$x = \arctan\frac{4}{3} + k\pi$$ But WolframAlpha gives $$x = 2k\pi + 2\arctan\frac{1}{2}$$ Using $\arctan(x)+\arctan(y) = \arctan\left(\frac{x+y}{1-xy}\right)$ , we get $$2\arctan\frac{1}{2} = \arctan\frac{4}{3}$$ but the answers are different still. Why does this happen? And what is the correct answer?","['trigonometry', 'systems-of-equations', 'real-analysis']"
3301418,"How to find radius of a circle inscribed in a quadrilateral, given its sides?","I came across this problem as I was preparing for an olympiad and it totally stumped me out. Can anyone please help me to solve it... Here it is: In a quadrilateral $ABCD$ , it is given that $AB = AD = 13$ , $BC = CD = 20$ , $BD = 24$ . If $r$ is the radius of a circle inscribed in the quadrilateral, then what is the integer closest to $r$ ? Thanks in advance.",['geometry']
3301458,Primes of $\Bbb R[x]$ and Galois theory in terms of affine schemes,"I want to find all prime ideals of $\Bbb R[x]$ . These are generated by the monic irreducible polynomials. Since $\Bbb C/\Bbb R$ is a degree two extension, and is algebraically closed, any other algebraic extension of $\Bbb R$ must be of degree $2$ or $1$ , so is either $\Bbb R/\Bbb R$ or is isomorphic to $\Bbb C$ . Then any monic irreducible polynomial in $\Bbb R[x]$ has degree at most two (otherwise we would obtain $\Bbb R[x]/(f)$ an algebraic extension of degree greater than two which is impossible). Then since $\text{Gal}(\Bbb C/\Bbb R)$ is generated by conjugation, and this degree two monic polynomial cannot have any $\Bbb R$ -roots, the roots must be complex conjugate. Then $\text{Spec}(\Bbb R[x])=\{(0),(x-a),(x^2-2ax+a^2+b^2)\mid a\in \Bbb R, b\in \Bbb R\backslash\{0\}\}$ . Is this correct? Then $\Bbb A^1_{\Bbb R}$ looks like $\Bbb C$ , with all the real points $(x-a)$ on the real line, but we identify points that are complex conjugate - so in some sense we are left with the upper half plane $\mathcal{H}=\{a+bi\mid a\in\Bbb R, b\in\Bbb R_{\geq 0}\}\subset \Bbb C$ . Additionally, in general, for $K$ a field which is not algebraically closed, is there a way to treat the theory of Galois extensions $L/K$ in terms of automorphisms of $\text{Spec}(K[x])$ ? It seems that the closed points which aren't codimension one encode a Galois action at that point? Like these $(x^2-2a+a^2+b^2)$ points can already see the $\Bbb C$ -conjugate points in $\Bbb C[x]$ .","['galois-theory', 'algebraic-geometry', 'abstract-algebra']"
3301472,Prove that $A$ is nonsingular,"Problem: Let $M$ be a $n \times n$ nonsingular matrix, and $$M = \begin{bmatrix}
    A \quad B \\
    C \quad D
\end{bmatrix}  \in \mathbb{K}^{n \times n}$$ with $\mathbb{K} = \mathbb{R}$ or $\mathbb{C}$ , $A \in \mathbb{K}^{k \times k}$ , $D \in \mathbb{K}^{q \times q}$ , $k<n$ . Prove that $A$ is nonsingular. My attempt: Since $M$ be a nonsingular matrix so every leading principal submatrices of $M$ nonsingular and $A$ be the leading pricipal submatrix of order $k$ of $M$ . Q.E.D Is that true? Thank all!","['matrices', 'linear-algebra', 'matrix-decomposition']"
3301485,Solving recurrence relations with characteristics root method,"I am able to solve more simple recurrences using this method, however I was given a problem that I can’t seem to work out. I think my mistake is in forming the characteristic polynomial but I’m not sure. The recurrence is: $g(0) = 2, g(1) = 16, g(n)=\frac{g(n-1)^3}{2g(n-2)^2}$ I get the characteristics polynomial as $r^n = \frac{r^3(n-1)}{2r^2(n-2)}$ which simply gives the results $r=2$ . But the usually steps from here don’t give a correct closed form. I think my characteristics polynomial is wrong as I’ve never had to deal with the recurrence being a fraction or the fact they are to different powers. I would be grateful if someone could explain how to obtain the correct one and if there are any tricks to solving recurrences like this.","['recurrence-relations', 'discrete-mathematics']"
3301489,Discriminant of homogeneous polynomials,"Let $f$ be a homogeneous polynomial in variables $x,y,z$ . Suppose that the sum of coefficients of $\frac{\partial^i f}{\partial x^i}$ is $0$ for each $0 \leq i \leq r$ . I believe that, in this situation, $(y-z)^r$ must divide $\textrm{Disc}_x(f)$ . Let us give you a simple example. Let $f=x^2-2xy+z^2$ . Then $\frac{\partial f}{\partial x}=2x-2y$ and $$
\textrm{Disc}_x(f)=4y^2-4z^2=4(y-z)(y+z).
$$ There are many examples which I computed using program. Why this happens? Is there any reference which mention on this situation?","['algebraic-curves', 'discriminant', 'computational-algebra', 'algebraic-geometry', 'abstract-algebra']"
3301492,How do I solve the equation $2\sin(3x)\cos(4x)=1$?,"How do I solve the equation $2\sin(3x)\cos(4x)=1$ ? Normally, I'd use the $\sin(2x)=2\sin(x)\cos(x)$ rule, but here you have two different values for $x$ , so I'm not sure how to add them together.","['trigonometric-series', 'trigonometry']"
3301504,Find All Entire Functions that Satisfy Some Condition,"I am working on a problem stating that Find all entire functions $f$ that satisfy: $|zf(z)-\sin z|\leq 1+|z|^{4/3}$ for all $z\in\mathbb{C}$ . I am stuck in this problem but I had some attempts: (1): Since we are dealing with an  entire function, we want to apply Liouville’s theorem. However, the RHS is not a constant number. So we consider a disc $D(0, R)$ for $R$ large enough. Then for $z\in D(0,R)$ , we have $$|zf(z)-1|\leq |zf(z)-\sin z|\leq 1+|z|^{4/3}\leq 1+R^{4/3}.$$ Thus, by Liouville’s theorem, we know that the entire function $$g(z):=zf(z)-1$$ is constant. Thus, we have $$zf(z)-1=C,\ \text{for some constant}\ C.$$ However, here comes the problem. If we continue, we would have $$f(z)=\dfrac{c+1}{z},$$ but then $$\lim_{z\rightarrow 0}f(z)\neq 0$$ and thus $f(z)$ has a singularity at $z=0$ which is not removable, and thus $f(z)$ cannot be entire. So, such functions do not exist? I don't think my argument here is correct since $g(z)$ is only constant on a large disc, but not the whole complex plane. However, this is the only way I can think of to have some entire function being bounded. Other attempts could not yield me a constant on a side and an entire function on the other side. For instance (2): We can move $|z|^{4/3}$ to the LHS so that we have $$|zf(z)-\sin z|-|z|^{4/3}\leq 1,$$ but then I could not get a way to further shrink the LHS so that we have an entire function inside the complex norm. We can also move everything to the RHS, so that we can indeed have something like $$-1\leq |z|^{4/3}-|zf(z)-\sin z|\leq \Big||z|^{4/3}-|zf(z)-\sin z|\Big|\leq |z^{4/3}-zf(z)+\sin z|,$$ but this inequality does not tell us anything since the RHS must be positive, so it is absolutely larger than $-1$ . Any hints, ideas would be greatly appreciated! Thank you. Edit: The Whole Proof This proof follows exactly from what Martin R suggested. I am just adding more details. Define $$g(z):=zf(z)-\sin z.$$ As $f(z)$ is entire, $g(z)$ must also be entire. Thus, for any $R>0$ and $z_{0}\in\mathbb{C}$ , $g$ is holomorphic in an open set containing the closure of the disc $D(z_{0}, R)$ . Thus, by Cauchy's Inequalities, we have $$|g^{(n)}(z_{0})|\leq\dfrac{n!\sup_{z\in \partial D}|g(z)|}{R^{n}}.$$ On the other hand, as $|g(z)|\leq 1+|z|^{4/3}$ for all $z\in\mathbb{C}$ , we have $$\sup_{z\in \partial D}|g(z)|=1+R^{4/3},$$ so that $$|g^{(n)}(z_{0})|\leq\dfrac{n!(1+R^{4/3})}{R^{n}},\ \text{for all}\ z_{0}\in\mathbb{C}.$$ Taking $R\rightarrow 0$ , we can conclude that as long as $n>4/3>1$ , we have $|g^{n}(z_{0})|=0$ for $z_{0}\in\mathbb{C}$ . Thus, $g(z)$ is a polynomial of degree $1$ , i.e. we can write $g(z)$ as $$g(z)=az+b\ \text{for all}\ z\in\mathbb{C}.$$ Then, we have $$g(0)=0=b,$$ so that $$g(z)=az\ \text{for all}\ z\in\mathbb{C}.$$ Thus, $$|az|\leq 1+|z|^{4/3}\ \text{for all}\ z\in\mathbb{C}.$$ If $z=0$ , then $0\leq 1$ holds for all $a$ . For $z\in\mathbb{C}\setminus\{0\}$ , we can divide $|z|$ in both side so that $$|a|\leq |z|^{-1}+|z|^{1/3}.$$ For each $z\in\mathbb{C}\setminus\{0\}$ , we can find a disc with center at $0$ and radius $|z|:=r$ so that $z$ lives on the boundary. Thus, the above inequality can be rewritten into $$|a|\leq \dfrac{1}{r}+r^{1/3}\ \text{for all}\ r>0.$$ Since this inequality holds for all $r>0$ , we have $$|a|\leq\min\Big\{r>0:\dfrac{1}{r}+r^{1/3}\Big\}.$$ To find the minimum, define $$h(r):=\dfrac{1}{r}+r^{1/3},$$ so that $$h'(r)=-r^{-2}+\dfrac{1}{3}r^{-2/3}=r^{-2}\Big(-1+\dfrac{1}{3}r^{4/3}\Big),$$ and we have the critical point $r_{\min}=3^{3/4}$ . Also, for $r>r_{\min}$ , $h'(r)>0$ , and $r<r_{\min}$ , $h'(r)<0$ . Thus, $h(r)$ achieves local minimum for $r>0$ at $r_{\min}$ with the local minimum value $$h(r_{\min})=\dfrac{4}{3^{3/4}}.$$ Therefore, the entire function $f(z)$ also the form: $$f(z)=az,\ \text{where}\ |a|\leq \dfrac{4}{3^{3/4}}.$$ I'd like to express my appreciation to Martin R who always patiently answers my dumb questions. Please upvote his post, I own him too much. ^ ^",['complex-analysis']
3301517,Mistake in reasoning regarding initial value problem,"Let $y(x)$ be the solution to the initial value problem: $y''y=(y')^2$ $y(0)=1, y'(0)=2$ I am very close to the right answer, but there is a mistake in my reasoning, and I would like to know where: Let's define $z=y'$ . $y''=z \frac{dz}{dy}$ . Therefore z $\frac {dz}{dy}y=z^2$ $z dz=\frac{z^2}{y}dy$ $\frac{dz}{z}=\frac{1}{y}dy$ Therefore $lnz=lny$ , meaning the derivative is identical to the original function. And therefore $y = e^x$ . I know that the right answer is $y=e^{2x}$ , so I am close, but there is a mistake somewhere. I suspect it is in the very last step, but I am not sure what the right alternative should be… Thank you!",['ordinary-differential-equations']
3301522,Extending a regular conditional distribution,"Let $(X\times Y,\mathcal{X}\otimes\mathcal{Y}, P)$ be a product probability space and $f_1, f_2$ the two projection maps. Let $Q:\mathcal{X}\times\Omega\rightarrow [0,1]$ be a conditional distribution of $f_1$ given $f_2$ , i.e.~ $\omega\mapsto Q(A,.)$ is $Y$ -measurable for any $A\in\mathcal{X}$ ; $Q(.,\omega)$ is a probability distribution for any $\omega\in\Omega$ ; $P(A\cap B)=\int_BQ(A,\omega)dP$ for any $A\in\mathcal{X}$ and $B\in\mathcal{Y}$ . My question is whether there is a canonical extension of this $Q$ to a regular conditional distribution of $P$ given $f_2$ (which is a function $Q': \mathcal{X}\otimes\mathcal{Y}\times \Omega\rightarrow [0,1]$ ). Right now I know how to define $Q'(A\times B,\omega)=Q(A,\omega)1_B(\omega)$ . So the question could also be framed as one about extending a regular conditional distribution defined on $\mathcal{C}\times\Omega$ to $\sigma C\times\Omega$ . Thanks in advance for any help! (I have tried to extend $Q(.,\omega)$ pointwise by the Caratheodory extension theorem, but I don't know how to prove that this extension preserves measurability...)","['conditional-probability', 'measure-theory', 'probability']"
3301540,"Double Integral $\int\limits_0^a\int\limits_0^a\frac{dx\,dy}{(x^2+y^2+a^2)^\frac32}$","How to solve this integral? $$\int_0^a\!\!\!\int_0^a\frac{dx\,dy}{(x^2+y^2+a^2)^\frac32}$$ my attempt $$
\int_0^a\!\!\!\int_0^a\frac{dx \, dy}{(x^2+y^2+a^2)^\frac{3}{2}}=
\int_0^a\!\!\!\int_0^a\frac{dx}{(x^2+\rho^2)^\frac{3}{2}}dy\\
\rho^2=y^2+a^2\\
x=\rho\tan\theta\\
dx=\rho\sec^2\theta \, d\theta\\
x^2+\rho^2=\rho^2\sec^2\theta\\
\int_0^a\!\!\!\int_0^{\arctan\frac{a}{\rho}}\frac{\rho\sec\theta}{\rho^3\sec^3\theta}d\theta \, dy=
\int_0^a\!\!\!\frac{1}{\rho^2}\!\!\!\int_0^{\arctan\frac{a}{\rho}}\cos\theta \, d\theta \, dy=\\
\int_0^a\frac{1}{\rho^2}\sin\theta\bigg|_0^{\arctan\frac{a}{\rho}} d\theta \, dy=
\int_0^a\frac{1}{\rho^2}\frac{x}{\sqrt{x^2+\rho^2}}\bigg|_0^ady=\\
\int_0^a\frac{a}{(y^2+a^2)\sqrt{y^2+2a^2}}dy$$ Update: $$\int_0^a\frac{a}{(y^2+a^2)\sqrt{y^2+2a^2}}dy=\frac{\pi}{6a}$$","['integration', 'definite-integrals', 'multivariable-calculus', 'calculus', 'multiple-integral']"
3301558,Why $r!$ divides the integer $\frac{(rn)!}{(n!)^r}$ and why $\frac{(rn)!}{(n!)^r}$ is integer.,"During my reading for some lecture notes, I found the following statement : It is clear that $r!$ divides the integer $\dfrac{(rn)!}{(n!)^r}$ , where $r$ and $n$ are positive integers. I am not sure why $\dfrac{(rn)!}{(n!)^r}$ is integer and why it is divisible by $r!$ . I tried to figure it out by numbers but I could not see how to prove it. Thanks",['number-theory']
3301560,Finding a particular solution curve and simplifying,"Find the equation of the curve that passes through the point $(1, 3)$ and has a slope of $y/x^2$ at any point $(x, y)$ . $$\frac{dy}{dx} = \frac{y}{x^2}
$$ with the initial condition $y(1) = 3$ $$\int \frac{dy}{dx} = \int \frac{y}{x^2} ,~~~y \ne 0,x > 0
$$ After integrating and solving for $y$ , I was able to get $$y = e^{ - (1/x) + C_1}
$$ but I don't know how the book then gets an answer of $$y = Ce^{\frac{ - 1}{x}}
$$ I appreciate any assistance in helping me make sense of this simplification.","['multivariable-calculus', 'ordinary-differential-equations']"
3301579,Euler exact sequence for $\mathbb{P}^n$ and toric varieties,I would like to understand explicitly the maps in the Euler exact sequence of $\mathbb{P}^n$ : $$0\rightarrow \Omega_{\mathbb{P}^n}^1\rightarrow \mathcal{O}_{\mathbb{P}^n}(-1)^{n+1}\rightarrow \mathcal{O}_{\mathbb{P}^n}\rightarrow 0$$ and more generally of a smooth toric variety: $$0\rightarrow \Omega_{X_{\Sigma}}^1\rightarrow \bigoplus_{\rho\in\Sigma(1)}\mathcal{O}_{X_{\Sigma}}(-D_{\rho})^{n+1}\rightarrow Pic(X_{\Sigma})\otimes\mathcal{O}_{X_{\Sigma}}\rightarrow 0$$ What is an explicit presentation of the maps in these exact sequences? Thank you very much.,"['projective-geometry', 'differential-geometry', 'co-tangent-space', 'algebraic-geometry', 'projective-space']"
3301598,"""Calculus 4th Edition"" by Michael Spivak -- Chapter 11 Problem 59","In Michael Spivak's ""Calculus"" 4th edition, Chapter 11 Problem 59 reads Suppose that the function $f > 0$ has the property that $$(f')^2=f-{1 \over f^2}.$$ Find a formula for $f''$ in terms of $f$ . (Why is this problem in this chapter?) This seems to be straight-forward: \begin{align}
(f')^2 &= f-{1 \over f^2} \\
2f'f'' &= f'+{2 \over f^3}f' \\
2f''   &= 1+{2 \over f^3} \\
f''    &= {1 \over 2} + {1 \over f^3}
\end{align} My problem is I can't figure out how to answer why this problem is in this chapter. Chapter 11 covers Rolle's Theorem, the Mean Value Theorem, the Cauchy Mean Value Theorem and L'Hopital's Rule. It also covers local extrema and the Second-Derivative Test. We answered a substantially similar question in Chapter 10 after covering the Chain Rule etc. Since I'm not using any new concepts, I'm suspicious I'm doing something wrong. I'd very much appreciate any insight. EDIT: Thank you everyone, you have all been very helpful. I would accept both answers if I could.",['calculus']
3301610,Proving differentiability at a point if limit of derivative exists at that point,"Suppose that $f:\mathbb{R} \rightarrow \mathbb{R}$ is continuous, is known to be differentiable everywhere but $a \in \mathbb{R}$ , but that $\lim_{x \rightarrow a}f'(x)=L$ .  Is it permissible to apply the mean value theorem as follows to show that $f$ is differentiable at $a$ ? $\frac{f(a+h)-f(a)}{h}=f'(\theta)$ for some $\theta \in (a, h+a) $ implies that $ \lim_{h \rightarrow 0} \frac{f(a+h)-f(a)}{h} = \lim_{\theta \rightarrow a}f'(\theta) = L$ since $\theta$ is sandwiched in between $a$ and $a+h$ .","['limits', 'calculus', 'derivatives', 'analysis']"
3301722,why is $\cos x + i \sin x = i^\frac{x}{90^\circ}$ [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 4 years ago . Improve this question I was calculating $\sqrt{i}$ and $\sqrt[3]{i}$ , and I found out that in both of those cases, $\cos x + i \sin x = i^\frac{x}{90}$ this formula is right. and this formula is right on x=0,30,45,90,360 But  I can't prove it.
Can anybody prove this?",['trigonometry']
3301729,A problem about lcm and irrational number,"Denote by $A_n$ the least common multiple of the integers from 1 to n, prove that $\displaystyle\sum_{n=1}^{\infty} \dfrac{f(n)}{A_n}$ is irrational, where $f(x)$ is a polynomial with integer coefficients. This problem was introduced by Erdős and published on Pi Mu Epsilon Journal Problems without a solution! I have difficulty finishing it.","['number-theory', 'irrational-numbers']"
3301749,estimating the tail of $p$-series,"Let $  p >0 $ be a positive real. We consider the $p$ -series $$ \sum_{ n > N} \frac{1}{n^p} $$ where $ N \to \infty.$ An application of the integral test show that in the case where the series converges (namely for $ p > 1,$ then one has the estimate $$ \sum_{ n > N} \frac{1}{n^p} \ll N^{1-p},$$ as $ N \to \infty.$ My question is the following. Question 1: Under what assumptions one can obtain the tighter upper bound $$ \sum_{ n > N} \frac{1}{n^p} \ll N^{-p},$$ as $ N \to \infty?$ edit: After the comments of Sandeep Silwal , I have decided to change a bit the range of summation, hoping to get something better than $ \ll N^{1-p}.$ Here is the new question: Question 2: Let $ \delta \in (0,1).$ Under what assumptions on p, is it true that $$ \sum_{ n > N^\delta} \frac{1}{n^p} \ll N^{-p\delta} \quad ? $$ Finally, I think (if such an estimate is valid) that one could sum at the level $ n \geq h(N)$ where $h (N)$ is a positive slowly, increasing to infinity function, with $h(N) = o(N), \quad N \to \infty.$","['divergent-series', 'asymptotics', 'analysis', 'sequences-and-series']"
3301779,Normalized probabilist's Hermite polynomial sum,"The normalized probabilist's Hermite polynomials are $\frac{1}{\sqrt{n!}}He_n(x)$ , and they satisfy orthonormality. Are there any simple formulas for the following two sums, $$\displaystyle\sum_{n=0}^\infty \frac{1}{\sqrt{n!}}He_n(x)$$ $$\displaystyle\sum_{n=0}^\infty \frac{1}{n!}He_n(x)He_n(y)$$ It is also not clear to me that the sums are even convergent. Edit: the following formula appears in this Math Overflow post (after converting from physicists' to probabilists'): $$\displaystyle\sum_{n=0}^\infty \frac{1}{n!}He_n(x)He_n(y)u^n = \frac{1}{\sqrt{1-u^2}}\exp\left(\frac{xy}{1+u} - \frac{u^2}{2(1-u^2)}(x-y)^2\right)$$ Can anyone provide a reference?","['orthogonal-polynomials', 'hermite-polynomials', 'probability-theory']"
3301867,"Showing that $(a,a')\in R\implies f(a)=f(a')$","From https://arxiv.org/pdf/1612.09375.pdf (p.130): I'm confused by the proof given at the end. Namely, I don't understand why the statement ""so these statements are equivalent"" follows. And also I don't understand what for the author defines the third relation (I don't know how to type that symbol here). Can one prove the original claim as follows? Let $\sim$ be the equivalence relation generated by $R$ . We need to show that $(a,a')\in R\implies f(a)=f(a')$ , knowing that $(a,a')\in \sim \implies f(a)=f(a')$ [which is (5.19)]. So assume $(a,a')\in R$ . Since $\sim$ is the equivalence relation generated by $R$ , the relation $\sim$ contains $R$ . Thus $(a,a')\in \sim$ . Now by (5.19), $f(a)=f(a')$ . I don't see what's wrong with my proof, but it doesn't use that $\sim$ is the smallest equivalence relation generated by $R$ .","['elementary-set-theory', 'equivalence-relations', 'proof-verification', 'relations']"
3301873,"If $a_{n}$ is a prime number, is $n$ is also a prime number?","Let $a_{n}$ be the $n^\text{th}$ term of a sequence. Let $a_{n}$ be defined as follows: $$a_n=\begin{cases}
1 & n = 1 \\
2 & n = 2 \\
2a_{n-1}+a_{n-2} & n \ge 3
\end{cases}$$ Can we say that ""if $a_{n}$ is a prime number, then $n$ is also a
  prime number"" ?","['number-theory', 'elementary-number-theory', 'generating-functions', 'sequences-and-series', 'prime-numbers']"
3301878,finding a solution to a matrix inequality,"I would like to find a 19x19 matrix V such that the following inequality holds: $$V^TAV<K$$ and where all entries of V are positive and the sum of entires in a row of V are equal to 1. Also < is taken point wise and K and A are particular matrices specified by the problem. In particular, the ij th element of A is sign(j-i) where sign(x)=|x|/x for x≠0 and 0 for x=0. K has the following property: The diagonal of K is all 0's and each other entry of K is either a 1 or e where 0 < e << 1. Also Kij = 1 iff Kji = e. Although for my specific problem there are some additional properties satisfied by A and K, I am interested in more general approaches to solving problems of this form. So far, the best idea for solving this is to use gradient descent. In particular I was considering picking a random matrix V, then computing Q as follows: $$Q=V^TAV-K$$ Then let $$err = ∑_{i,j} max(Qij,0) $$ and then I would try to minimize err via gradient descent","['matrices', 'gradient-descent', 'numerical-optimization']"
3301883,Euclidean distance (cosine) between two random positive unit vectors in high dimensional space,"I found out that the largest possible euclidean distance (which is the cosine) between two random positive unit vectors decreases as the dimension of vector increases and approximates 0.71. This was done by a simulation where I randomly sample unit vectors and compute the maximal pair-wise Euclidean distance. I found the value 0.71 intriguing. It's as if the maximal angle between all vectors is 45 degrees (cosine(45) ≈ 0.71), which is half of 90 degrees related to the constraint of having only positive elements. Why is that? I sense there is an intuitive explanation to this which can be generalized to other cases, e.g. without the positive vector constraints. You can use the following code to reproduce the simulation. import numpy as np
from sklearn.preprocessing import Normalizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
matrices = [Normalizer(norm = 'l2').fit_transform(np.random.rand(1000, N)) for N in range(2,10000, 100)]
res = [euclidean_distances(matrix, matrix).max() for matrix in matrices]
plt.plot(range(len(res)),res) plot of the max euclidean distance with different dimension","['machine-learning', 'linear-algebra', 'geometry', 'probability']"
3301932,Three dice are thrown simultaneously,"Three dice are thrown simultaneously . The probability that 4 appears on two dice , given that 5 has appeared on one dice is . The way I’ve gone about it is : _ _ 5 , _ 5 _ , 5 _ _ A: event of 4 appearing twice B: event of 5 appearing once (In three throws ) Then , P(A/B) = P(A∩B)/P(B) = $\frac{^3C_1(1/6)^3}{^3C_1 (1/6)}$ Where $^3C_1$ in the numerator is for selecting any 1 dice for 5 and the other two automatically get selected for 4 .
While $(1/6)^3$ Is probability of digits 5 ,4,4 appearing on the 3 dices . This method is not giving me the desired answer ,as given in the question . The ans given is $\frac{3}{91}$","['permutations', 'combinations', 'conditional-probability', 'combinatorics', 'probability']"
3301934,Extension Theorems,"If we were to abstractly represent ""analytic continuation"" from complex analysis, it would look something like this: ""If $f$ is a function with property $P$ on a set $U$ satisfying some conditions $C$ , then $f$ can be uniquely extended to a bigger set $Q$ such that $P\subset Q$ and $f$ still has property $P$ ."" In measure theory, the Caratheodory Extension Theorem says that any measure $\mu$ defined on a ring $R$ of subsets can be extended to the sigma algebra generated by $R$ and this extension is unique as long as the $\mu$ is sigma finite. So in a way, subaddativity and sigma-finiteness for measures are analogous to complex-analytic for functions. Question 1: What are some other examples of such unique extension theorems, say in combinatorics, or group theory? Question 2: Is there a nice unification (""categorification?"") of these extension theorems? Specially, in what ways must property $P$ be special? Edit: I would like to re-emphasize that the extension should be unique .","['complex-analysis', 'measure-theory', 'abstract-algebra']"
3302039,"A Function $g(x)$, Written in Terms of $f(x)$, That Flips Sign when a Root of $f(x)$ is Encountered","Let $f(x)$ be any continuous, differentiable function that has extrema and that $f(x) \geq 0$ for all $x$ and has a finite amount of roots (it is not always a polynomial). Let $g(x)$ be a function (written in terms of $f(x)$ ) that flips sign only when a root of $f(x)$ is encountered. For example, let's say that $f(x)$ has roots at $2,3,7,11$ . That means if from $0$ to $2$ , $g(x)$ is positive, from $2$ to $3$ , $g(x)$ should be negative. From $3$ to $7$ it should be positive and from $7$ to $11$ it should be negative. $g(x)$ should be written in terms of $f(x)$ ; therefore $g(x)$ should be a general equation. You should not need to know the roots of $f(x)$ in order to construct $f(x)$ . $g(x)$ does not have to be continuous nor differentiable. Hopefully, $g(x)$ is closed form (ie. no $\sum$ or $\prod$ ). What is one definition of $g(x)$ ? Or is such a function possible to construct? In any answer, please use $f(x)=\sin^2(\frac{33}{x}\pi)+sin^2(x \pi)$ as the example function. Background: I was thinking about this problem because I wanted to know if it was possible to find roots numerically for functions that are all positive and have other extrema other than the roots (so something like f(x)/f'(x) wouldn't work). Newton's, fixed point, and so on are only valuable if you start near the root, and even then, with a function like the example, it's not guaranteed to work. Bisection is the only one guaranteed to work, but I need to get the equations in a form so that can work. EDIT : After giving it some thought, I'm thinking that such $g(x)$ , if possible, will probably include sine, cosine, and/or tangent in some way, but I'm not sure how. I was hoping someone could help me.","['number-theory', 'calculus', 'functions']"
3302062,Find the Maximum and Minimum Values of $f(x) = \cos\sqrt{x+1} - \cos\sqrt{x}$,I saw today in a fb forum the following excersice: Find the range of values of $f(x)=\cos\sqrt{x+1}-\cos\sqrt{x}$ I have tried to find the mix and max of the function but failed. Any ideas?,"['maxima-minima', 'functions']"
3302092,Why is this the coequalizer in $\mathbf {Set}$?,"Take sets and functions $s,t:X\to Y$ . Let $\sim$ be the equivalence relation generated by the set $R=\{(s(x),t(x)):x\in X\}$ . The claim is that the pair $(Y/{\sim},\pi:Y\to Y/{\sim})$ where $\pi$ is the quotient map, is the coequalizer of $s,t$ . To prove this, we need to verify two things: 1) $\pi s=\pi t$ 2) if $(C,f:Y\to C)$ is another pair with $fs=ft$ , then there is a unique $g:Y/{\sim}\to C$ s.t. $g\pi=f$ For 1): For any $x\in X$ , we have $\pi(s(x))=\pi(t(x))$ iff $s(x)\sim t(x)$ , by the definition of $\pi$ . But we do know that for all $x\in X$ , $s(x)\sim t(x)$ (since $R$ contains all pairs $(s(x),t(x))$ ). Therefore, $\pi s=\pi t$ . For 2): Suppose there is $(C,f)$ as described above. We need to construct $g:Y/{\sim}\to C$ . One natural choice would be to define $g([y])=f(y)$ — this will force $g\pi=f$ . But I don't see how to prove that the map is well-defined. Leinster says that the whole thing follows from Remark 5.2.8 (also quoted here ), but I don't see how exactly everything follows. The remark says that maps $Y/{\sim}\to C$ correspond bijectively to maps $F:Y\to C$ such that $y\sim y'\implies F(y)=F(y')$ .","['elementary-set-theory', 'equivalence-relations', 'relations', 'category-theory']"
3302101,Alternative methods for solving a system of one linear one non linear simultaneous equations,Take the equations $$x+y=5$$ $$x^2 + y^2 =13$$ The most basic method to solve this system is to first express the linear equation in terms of one of the variables and then sub that into the non-linear equation. But I am curious if there are other methods to solve such a system ?,"['quadratics', 'algebra-precalculus', 'systems-of-equations', 'roots']"
3302111,Examples of self adjoint compact operators on Hilbert spaces,"As the titles says, I'm looking for examples of self adjoint compact operators on Hilbert spaces. So far I know of the diagonal operator on $\ell^2$ , $$
(Tx)_i = \alpha_ix_i 
$$ for some sequence $\alpha_i \to 0$ ;  and the Hilbert Schmidt integral operator in $L^2(\Omega)$ , $$
Kg = \int_{\Omega}K(x,y)g(y)dy
$$ with $K \in L^2(\Omega^2)$ a symmetric Hilbert-Schmidt kernel. I would also like to know of some applications that use Hilbert Schmidt integral operators. Edit: I'd be really grateful to know about the behaviour of the norm of the operators as well. Thanks in advance.","['hilbert-spaces', 'big-list', 'functional-analysis']"
3302122,Does the fiber cardinality increase under specialization over a finite field?,"Let $p \in \mathbb{Z}$ be a prime. Suppose we have a quasi-finite map $f \colon X \to \mathbb{A}^n$ of schemes over $\mathbb{Z}$ , and let $f_p \colon X_{\mathbb{F}_p} \to \mathbb{A}_{\mathbb{F}_p}^n$ be the basechange of $f$ along $\operatorname{Spec} \mathbb{F}_p \to \operatorname{Spec} \mathbb{Z}$ . Let $H \subset \mathbb{A}_{\mathbb{F}_p}^n$ be a hypersurface defined over $\mathbb{F}_p$ , and let $U = \mathbb{A}_{\mathbb{F}_p}^n \setminus H$ be the complement. Suppose that neither $U(\mathbb{F}_p)$ nor $H(\mathbb{F}_p)$ is empty. Question: Suppose that there is some number $N$ such that the fiber cardinality $\# f_p^{-1}(x) = N$ for every $x \in U$ . Can anything be said about the fiber cardinality for $x \in H$ ? Is it true, for example, that $f_p^{-1}(x) \geq N$ for every $x \in H$ ? What I know: I'm aware of the standard results on upper-semicontinuity of fiber cardinality / dimension over algebraically closed fields, so I was wondering what can be said over finite fields.","['finite-fields', 'algebraic-geometry', 'schemes']"
3302126,Are primes (ignoring $2$) equally likely to be $1~\text{or}~3\pmod 4$?,"For all primes $p\neq 2$ , it's easy to see that $$p\equiv 1~\text{or}~3\pmod 4$$ I was wondering if it's equally likely ( $50\%-50\%$ ) that prime modulo $4$ is $1$ or $3$ . And if so, is there a simple proof?","['number-theory', 'modular-arithmetic', 'probability', 'prime-numbers']"
3302193,"A deck of cards contains $26$ black and $13$ red cards, taking out the cards in a particular way, what is the probability the last card left is black","You have a deck of cards containing 26 black and 13 red cards. You pull out 2 cards at the same time and check their color. If both cards are the same color, then a black card is added to the deck. However, if the cards are of diﬀerent colors, then a red card is used to replace them. Once the cards are taken out of the deck, they are not returned to the deck, and thus the number of cards in the deck keeps reducing. What is the probability the last card left in the deck is black? my attempt:
for both cards are the same colors: (both black)+(both red) ((26/39) (25/38)) + ((13/39) (12/38))=0.5438 the cards are of diﬀerent colors: (black +red)+(red +black) ((26/39) (13/38))+((13/39) (26/38))=0.4561 please let me know how to continue for the answer for:
What is the likelihood the last card left in the deck is black?","['probability-theory', 'probability']"
3302207,Looking for a Simple Proof of the Divergence of the Prime Harmonic Series,"It is well known that $$\sum_{i=1}^{\infty} \frac{1}{p_{i}}$$ diverges, where the $p_{i}$ 's are the prime numbers. Does anybody know a very elementary proof of this result that would be suitable for calculus-level students? Many thanks.","['elementary-number-theory', 'prime-numbers', 'sequences-and-series']"
3302217,Probability of Multiple Weighted Coin Flips,"I would like to calculate the probabilities of the outcomes of three weighted coins being flipped. I believe what I am looking for is a Poisson Binomial Distribution . I am having trouble verifying/interpreting the results that I am finding on an online calculator . Edit: Order does not matter in this question - the below is a table of the sums of outcomes. +---------+---------+-------------+
| Outcome | Heads P | Probability |
+---------+---------+-------------+
| 3 heads |     .75 | .421875??   |
| 2 heads |     .75 | ??          |
| 1 heads |     .75 | ??          |
| 0 heads |     .75 | ??          |
|         |         |  (Sum = 1)  |
+---------+---------+-------------+ The .42 is calcualted for X>=3, but since there are only 3 flips it cannot be any greater. An alternate calculator provides a much lower answer, .03, which seems too low. Is a Poisson binomial distribution the correct calculation for this answer? (X=3 trials, .75 success) How would I find the probability of 2 out of 3 heads, 1 out of 3 heads, and no heads? Thank you for taking the time to explain what I might be missing here.","['poisson-distribution', 'statistics', 'probability']"
3302233,Every metric space can be isometrically embedded in a Banach space.,"(I have already read the explanations given for the suggested similar questions.) I approximate that I only understand about 40% of this solution.  I have been told that this follows from Kuratowski's Embedding Theorem but I can't find much more than a statement of the theorem.  I would like references on where I can get the information needed to comprehend this proof or other elementary proofs of the statement. Let $X$ be a set and $B(X, \mathbb R)$ the set of bounded functions $f:X\to \mathbb R$ with norm $||f||=\sup\{|f(x)|:x\in X\}$ . Claim: Every metric space $(X,d)$ can be embedded isometrically into the Banach Space $E=B(X,\mathbb R)$ . Proof of claim: Assume $X\neq \varnothing$ . Fix a point $a_0\in X$ and for every $a\in X$ define a function $f_a:X\to\mathbb R$ by $f_a(x)=d(x,a)-d(x,a_0)$ . The $|f_a(x)|\leq d(a,a_0)$ for every $x\in X$ so $f_a$ is bounded. By setting $\rho : X\to E$ , $\rho(a)=f_a$ we have the mapping $\rho : X \to E$ . Claim: $\rho$ is an isometry. Proof: Let $a,b\in X$ . As $x \in X$ we have that $|f_a(x)-f_b(x)|=|d(x,a)-d(x,b)|\leq d(a,b) \therefore ||f_a-f_b||\leq d(a,b)$ . On the otherhand (this specifically is a big part I dont understand, why are we looking at $f$ at $a$ now instead of $f$ at $x$ ?) $|f_a(a)-f_b(a)|=|d(a,a)-d(a,a_0)-d(a,b)+d(a,a_o)|=d(a,b) \therefore ||\rho(a)-\rho(b)||=||f_a-f_b||=d(a,b).$","['banach-spaces', 'functional-analysis']"
3302251,Any source to find distance between vertices in generalized Petersen graphs?,"I am trying to find the distance between vertices of generalized Petersen graphs $P(n,k)$ . For $n = 50$ and $k<\frac{n}{2}$ I did everything manually. I manually wrote down a shortest path between any two vertices. However, it is really cumbersome to find the same for higher values of $n$ . Is there any site/software/link to find a shortest distance between vertices of generalized Petersen graphs?
I will be really grateful for the help. Thanks for the help. P.S. I tried Mathematica with the help of a friend and got to know that I can get radius and diameter using this. But I am interested in the shortest paths. The generalized Petersen graphs $P(n,1)$ and generalized Petersen graphs $P(n,2)$ are shown below.","['graph-theory', 'combinatorics', 'discrete-mathematics']"
3302256,How to understand multi-resolution analysis and wavelet transform?,"I just started learning multi-resolution analysis. I know that given a scaling function, through dilation and translation, a sequence of spaces can be generated: $\cdots V_{-1} \subset V_0 \subset V_1 \cdots$ and their union is dense in $L^2(\mathbb{R^n})$ . Also $V_i$ can be decomposed as $V_{i-1} \oplus W_{i-1}$ , where $W_{i-1}$ is generated by wavelet functions. My question is, since we can approximate functions in $L^2(\mathbb{R^n})$ by scaling functions, why do we still need wavelet functions? And why do we need the decomposition $V_i = V_{i-1} \oplus W_{i-1}$ ?","['fourier-analysis', 'real-analysis', 'functional-analysis', 'signal-processing', 'wavelets']"
3302303,locally constant $\mathbb{Q}_l$-sheaf from an $A$-torsor.,"This is a construction everybody talks about, but I have not seen it explicitly anywhere. Let $A$ be a finite group and $X$ be a scheme. An $A$ -torsor $T$ on $X$ is a sheaf for the etale topology of $X$ , such that it is locally constant with stalks $A$ on which $A$ acts by right translation. Suppose also that there is a linear representation $A \xrightarrow{\rho} GL(V)$ into a finite dimensional $\overline{\mathbb{Q}_l}$ -vector space $V$ . With these two data, how does one obtain a smooth $\overline{\mathbb{Q}_l}$ -sheaf on $X$ ? I could not find an explicit construction anywhere, so either that or a reference where this is carried out in detail(in English, I hope) would be great. Thanks!","['algebraic-number-theory', 'algebraic-geometry', 'arithmetic-geometry']"
3302314,Where's my mistake in this closed formula for homogeneous linear recurrence equations?,"The following is a try for a proof which is supposed to give a concrete formula for the generating function of a homogeneous linear recurrence equation (with constant coefficients). However, when I tried applying the formula onto a concrete problem, I've ended up with results that made me pretty sure that there's something wrong with my proof. Here it is: Let $(g_n)_{n\in\mathbb{N}}\in \mathbb{C}^\mathbb{N}$ be a sequence and $(\alpha_1,...,\alpha_d)\in\mathbb{C}^d $ complex numbers. Let the following inhomogeneous recurrence equation be given: $$
a_{n+d}+\alpha_1\cdot a_{n+d-1} + \alpha_2\cdot a_{n+d-2}+...+\alpha_d\cdot a_{n} + g_{n+d}=0 , \qquad n\ge 0
$$ We're starting off with the generating functioin of $a_n$ : $$\sum_{n\geq0}{a_nx^n}=\left(\sum_{n=0}^{d-1}{a_nx^n}\right)+\left(\sum_{n\geq d}{a_nx^n}\right)=
\\
\left(\sum_{n=0}^{d-1}{a_nx^n}\right)+\left(\sum_{n\geq d}{\left(\left(\sum_{i=1}^{d}{-\alpha_ia_{n-i}}\right)-g_n\right)x^n}\right)
$$ Rearranging the summands: $$
=\left(\sum_{n=0}^{d-1}{a_nx^n}\right)-\left(\sum_{n\geq d}{\sum_{i=1}^{d}{\alpha_ia_{n-i}}x^n}\right)-\left(\sum_{n\geq d}{g_nx^n}\right)
$$ Swapping inner and outer sum: $$=\left(\sum_{n=0}^{d-1}{a_nx^n}\right)-\left(\sum_{i=1}^{d}{\alpha_i\sum_{n\geq d}{a_{n-i}x^n}}\right)-\left(\sum_{n\geq d}{g_nx^n}\right)
$$ Index shift $n\gets n+i $ in the inner sum: $$
=\left(\sum_{n=0}^{d-1}{a_nx^n}\right)-\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n\geq d-i}{a_nx^n}}\right)-\left(\sum_{n\geq d}{g_nx^n}\right)
$$ We're adding a zero (by putting sum summands into the inner sum): $$=\left(\sum_{n=0}^{d-1}{a_nx^n}\right)-\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n\geq0}{a_nx^n}}\right)-\left(\sum_{n\geq d}{g_nx^n}\right)+\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n\geq0}^{d-i-1}{a_nx^n}}\right)
$$ The equation now looks like this: $$
\sum_{n\geq0}{a_nx^n}+\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n\geq0}{a_nx^n}}\right)=\left(\sum_{n=0}^{d-1}{a_nx^n}\right)-\left(\sum_{n\geq d}{g_nx^n}\right)+\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n\geq0}^{d-i-1}{a_nx^n}}\right)
$$ Replacing $\sum_{n\ge 0} a_n x^n $ by its generating function $f_a(x)$ : $$
f_a\left(x\right)+\left(\sum_{i=1}^{d}{\alpha_ix^if_a\left(x\right)}\right)=\left(\sum_{n=0}^{d-1}{a_nx^n}\right)-\left(\sum_{n\geq d}{g_nx^n}\right)+\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n\geq0}^{d-i-1}{a_nx^n}}\right)
$$ Factoring $f_a(x) $ out: $$
f_a\left(x\right)\left(1+\left(\sum_{i=1}^{d}{\alpha_ix^i}\right)\right)=\left(\sum_{n=0}^{d-1}{a_nx^n}\right)-\left(\sum_{n\geq d}{g_nx^n}\right)+\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n=0}^{d-i-1}{a_nx^n}}\right)
$$ We arrive at the desired form: $$
f_a\left(x\right)=\frac{\left(\sum_{n=0}^{d-1}{a_nx^n}\right)-\left(\sum_{n\geq d}{g_nx^n}\right)+\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n=0}^{d-i-1}{a_nx^n}}\right)}
{\left(1+\left(\sum_{i=1}^{d}{\alpha_ix^i}\right)\right)}
$$ The question now is: Where is the mistake in this calculation? The scenario where it fails is the following: Consider the recurrence equation $$
f(n):= \frac{f(n-1)^3}{2f(n-2)^2}\qquad f(0)=2, f(1)=16
$$ Then we have: $$
\log_2(f(n))= \log_2\left(\frac{f(n-1)^3}{2f(n-2)^2}\right) 
\\\Leftrightarrow\\
\log_2(f(n))= 3\log_2\left(f(n-1)\right)-2\log_2\left(f(n-2)\right)  -\log_2(2)
$$ By defining $a_n :=\log_2(f(n))$ we therefore arrive at an inhomogeneous lineare recurrence equation, i.e.: $$
a_{n+2}- 3a_{n+1}+2a_{n}  +1 =0
$$ We prepare for substituting into the formula: $$
\left(\sum_{n=0}^{d-1}{a_nx^n}\right) = \log_2(2) + \log_2(16)x = 1+4x
$$ $$
\left(\sum_{n\geq d}{g_nx^n}\right) =x^2+x^3+...= \frac{x^2}{1-x}
$$ $$
\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n=0}^{d-i-1}{a_nx^n}}\right)=-3x\cdot 2=-6x
$$ $$
{\left(1+\left(\sum_{i=1}^{d}{\alpha_ix^i}\right)\right)}= 1-3x+2x^2
$$ We therefore get: $$
f_a\left(x\right)=\frac{\left(\sum_{n=0}^{d-1}{a_nx^n}\right)
-\left(\sum_{n\geq d}{g_nx^n}\right)
+\left(\sum_{i=1}^{d}{\alpha_ix^i\sum_{n=0}^{d-i-1}{a_nx^n}}\right)}
{\left(1+\left(\sum_{i=1}^{d}{\alpha_ix^i}\right)\right)}
$$ $$f_a(x) = \frac{1+4x-\frac{x^2}{1-x} - 6x}{1-3x+2x^2}
$$ However if I develop this using Taylor at $x=0$ , I get the coefficients: $$- 119·x^7 - 56·x^6 - 25·x^5 - 10·x^4 - 3·x^3 + x + 1$$ Which is for $a_2$ already wrong.","['proof-verification', 'recurrence-relations', 'discrete-mathematics', 'generating-functions']"
3302351,Isomorphism of sheaves of rings,"Suppose we have locally ringed spaces $(X, F_1), (X, F_2)$ . If $F_1(X)$ and $F_2(X)$ are isomorphic as rings, can we conclude that sheaves $F_1$ and $F_2$ are isomorphic? I think this is true because isomorphism of sheaves $\phi : F_1 \rightarrow 
 F_2$ are the set of isomorphisms of rings $\phi(U) : F_1(U) \rightarrow 
 F_2(U)$ for any open set $U$ in $X$ . Furthermore, if we have locally ringed spaces $(X, F_1), (Y, F_2)$ where X and Y are homeomorphic and $F_1(X)$ and $F_2(Y)$ are isomorphic as rings, can we still conclude that sheaves $F_1$ and $F_2$ are isomorphic as sheaves? Thank you.","['affine-schemes', 'algebraic-geometry', 'schemes', 'sheaf-theory']"
3302352,1D-Biased Random Walk Hitting Time Distribution,"Let $X_{s}$ be a Bernoulli r.v such that it returns (1-p) with probability p and returns (-p) with probability (1-p). All $X_s$ are mutually independent. Let $S_n = X_1 + X_2 + \cdots X_n$ and T is the stopping time when $S_n<a$ or $S_n>b$ for some $a<0$ or $b>0$ . What is the distribution of the stopping time T? I guess expected stopping time might be infinity as a random walk does, but I am not sure. Now consider the unbalanced case, so that $X_s$ returns (1-p) with probability q and returns (-p) with probability (1-q). WLOG $q>p$ . Now can we calculate the distribution of the stopping time T? I have read some documents about discrete random walks, and it uses characteristic function to calcualte expected stopping time, but I don't think I can apply that method to this problem. I am now researching about CUSUM(CUmulative SUM), SPRT(Sequential Probability Ratio Test) things and it is necessary for my further research - I need more information than upper bound of stopping time...... Please help......","['stopping-times', 'probability-distributions', 'random-walk', 'probability']"
3302368,What is the growth rate of the products of binomial coefficients?,"Claim: Experimental data seems to suggest that $$
{n \choose 1^a b}{n \choose 2^a b}{n \choose 3^a b}\cdots {n \choose m^a b} 
\sim \exp\bigg(\frac{2n^{1 + \frac{1}{a}}}{ab+3b}\bigg)
$$ where $a$ and $b$ are a fixed positive integers and $m$ is the largest positive integer such that $m^a b \le n$ . Note that the above asymptotic are supported by the data even if we relax the condition that $a,b$ are integers and allow them to be reals $a > 0, b > 0$ and replace $k^a b$ with $\lfloor k^a b\rfloor$ . As an illustration, for $a = 3, b = 1$ , the $\%$ error between the asymptotic and the actual product is shown below. Note : Posted in MO since in it unanswered in MSE Update 19-Dec-19 : Combined the two individual claims into a single claim based on experimental data.","['summation', 'number-theory', 'binomial-coefficients', 'combinatorics', 'sequences-and-series']"
3302372,A question about groups of order $504=2^3\cdot 3^2 \cdot 7$,"I was looking at past qualifying exams in algebra and came across the following problem which I can't solve. The problem asks to show that if a group $G$ of order $504=2^3\cdot 3^2 \cdot 7$ has a normal subgroup of order $2^3$ , then it has at most $8$ Sylow $7$ -subgroups. Applying the Sylow theorems gives that the number of Sylow $7$ -subgroups is either $1$ , $8$ , or $36$ . So we only need to exclude the last possibility.
If $P$ is a  Sylow $7$ -subgroup of $G$ and if $G$ has $36$ Sylow $7$ -subgroups, then $N_G(P)$ has order $14$ . I don't see what to do with that information though. Any help would be appreciated.","['group-theory', 'abstract-algebra', 'finite-groups', 'sylow-theory']"
3302387,Does $\int_{\mathbb R}x^2f_X(x)dx=\int_{\mathbb R}x^2f_X(x)^2dx$ or are they comparable?,"Let $f_X$ a density function, i.e. $\mu(dx)=f_X(x)dx$ is an absolute continuous measure w.r.t. Lebesgue measure. We have that $$\int_{\mathbb R}x\mu(dx)=\int_\mathbb R xf_X(x)dx.$$ Using Jensen inequality, $$\left(\int_{\mathbb R}xf_X(x)dx\right)^2\leq \int_{\mathbb R}x^2f_X(x)^2dx$$ and $$\left(\int_{\mathbb R}x\mu(dx)\right)^2\leq \int_{\mathbb R}x^2\mu(dx)=\int_{\mathbb R}x^2f_X(x)dx.$$ In somehow, we have the same integral, but not the same upperbound. Does $$\int_{\mathbb R}x^2f_X(x)dx=\int_{\mathbb R}x^2f_X(x)^2dx\ \ ?$$ Or at least, are they comparable ? ( like, does $$\int_{\mathbb R}x^2f_X(x)dx\leq\int_{\mathbb R}x^2f_X(x)^2dx\quad \text{or}\quad \int_{\mathbb R}x^2f_X(x)dx\geq\int_{\mathbb R}x^2f_X(x)^2dx$$ hold ? May be my question has no sense, but I'm quite surprise that we have 2 differents ""optimal"" upperbound for the same integral. (by optimal, I mean that in some case, we can have equality).",['measure-theory']
3302482,The sum: $\sum_{k=1}^{n}(-1)^{k-1}~ [(H_k)^2+ H_k^{(2)}]~ {n \choose k}=\frac{2}{n^2}$,"This attractive identity that $$\sum_{k=1}^{n}(-1)^{k-1}~ [(H_k)^2+ H_k^{(2)}]~ {n \choose k}=\frac{2}{n^2}~~~(*)$$ emerged while doing numerics at Mathematica with harmonic numbers, binomial coefficients
 and sums involving them.
Here $$H_k=1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{k},~~ H_k^{(2)}=1+\frac{1}{2^2}+\frac{1}{3^2}+...+\frac{1}{k^2}. $$ The question is: How to prove it $(*)$ by hand?","['summation', 'real-analysis', 'harmonic-numbers', 'binomial-coefficients', 'sequences-and-series']"
3302511,Derivative of ODE with respect to parameter,"For each value of a parameter $a \in \mathbb{R}$ , let $x(a,t)$ be defined by the ODE $$\frac{dx}{dt}=F(a,x,t)$$ where $F$ is (say) smooth and, for each fixed $a$ , Lipschitz in $x$ . It is well known in this case that $x$ is well-defined and is smooth with respect to $a$ . Question (general): What is known about the derivatives of $x$ with respect to $a$ ? If this question is too general to be helpful, here's a more specific one: Question (specific) : If $F(a,x,t)$ is zero unless $x \in [-B,B]$ for some constant $B$ , does this imply that all the derivatives of $x$ with respect to $a$ are bounded functions of $t$ ? (An answer to either question could be a reference to a book) The obvious thing to do is to write down an ODE satisfied by $y:=\frac{\partial x}{\partial a}$ , which is, I think, $$\frac{dy}{dt}=\frac{\partial F}{\partial a}+\frac{\partial F}{\partial x}y$$ and this could be used to study the first derivative (and similar for the higher ones). But these equations get a little messy for higher derivatives.","['dynamical-systems', 'ordinary-differential-equations', 'reference-request']"
3302513,Finding the limit: $\lim_{n\to\infty}\frac{1+1/2+1/3+\ldots+1/n}{(\pi^{n}+e^{n})^{1/n}\ln n}$,Find the given limit $$\lim_{n\to\infty}\frac{1+1/2+1/3+\ldots+1/n}{(\pi^{n}+e^{n})^{1/n}\ln n}$$ I'm able to find one part in denominator of this limit i.e. $\lim_{n\to \infty} (\pi ^{n} + e^{n})^{1/n} = \pi$ So there will be a $\pi$ in the denominator of the answer. How to find the rest part $?$,['limits']
3302616,On the definition of algebraic/transcendental functions.,"On Wikipedia it says ``Formally, an analytic function $f(z)$ of one real or complex variable $z$ is transcendental if it is algebraically independent of that variable. This can be extended to functions of several variables.'' I have a real analytic function $f$ which is defined only on some closed and bounded interval $I$ . Suppose there exists a polynomial $g(x, y)$ such that $$
g(x, f(x)) = 0
$$ on $I$ . Does it then mean that $f$ is algebraic? I was not sure because this holds only on $I$ ... Any comments would be appreciated. Thank you.","['complex-analysis', 'definition', 'transcendental-equations', 'real-analysis']"
3302713,Is this matrix function bounded from above by a norm,"Given two symmetric, positive definite matrices $A$ and $B$ ,
let $$
d(A, B) = \textrm{tr}(A) + \textrm{tr}(B) - 2 \, \textrm{tr} \, \left((A^{1/2} B A^{1/2})^{1/2}\right).
$$ This function coincides with the square of the 2-Wasserstein distance between Gaussians  with equal means and with covariance matrices given by $A$ and $B$ , respectively.
Is $d(\cdot, \cdot)$ bounded from above by a matrix norm? That is to say, is there a constant $C$ such that $$
d(A, B) \leq C \|A - B\| \qquad \forall A, B \in \mathbb R^{n\times n} \, s.p.d.,
$$ where $\|\cdot\|$ is any matrix norm? In dimension one, this is true: $$
d(A, B) = (\sqrt A - \sqrt B)^2 \leq |A-B|,
$$ because $|\sqrt{A} - \sqrt{B}| \leq \sqrt{|A - B|}$ by concavity. More generally, if $A$ and $B$ commute, i.e. if there exists $P$ such that $A = P D_A P^T$ and $B = P D_B P^T$ , $$
d(A, B) = \mathrm{tr}(D_A) + \mathrm{tr}(D_B) - 2 \, \mathrm{tr}((D_A D_B)^{1/2}) = \mathrm{tr}(|D_A^{1/2} - D_B^{1/2}|^2) \leq \mathrm{tr} (|D_A - D_B|) \leq n\|A - B\|_2.
$$ What about the general case? A friend pointed out to me that the Araki–Lieb–Thirring inequality , with $r=1/2$ and $q=1$ , could be employed to obtain $$
\mathrm{tr}((A^{1/2}BA^{1/2})^{1/2}) \geq \mathrm{tr}(A^{1/4}B^{1/2}A^{1/4}) = \mathrm{tr}(A^{1/2}B^{1/2}),
$$ which implies that $$
d(A, B) \leq \mathrm{tr}((A^{1/2} - B^{1/2})^2) = \|A^{1/2} - B^{1/2}\|_F^2.
$$","['matrices', 'linear-algebra']"
