question_id,title,body,tags
2031435,Uniqueness of Hahn-Banach extension for dense subspace,"Let $A$ be a normed space and $B\subset A$ a linear subspace with $\phi\in B^*$.
I am looking to prove the following: B is dense in $A$ iff there is a unique extension of $\phi$ to a continuous linear functional on $A$. What I thought: Hahn-Banach tells us that there does exist an extension of $\psi$ of $\phi$ such that $\|\phi\|=\|\psi\|$. Further $B$ being dense in $A$ means that each sequence in $B$ converges to an $a\in A$. How do I use these to prove the statement? Edit: $\implies$: Suppose $f,g$ are extensions of $\phi$ on $A$. Let $a\in A\backslash B$. Then $a=\lim_{n\rightarrow\infty}b_n$ for $b_n\in B$. This gives
$$f(a)=f(\lim_{n\rightarrow\infty}b_n)=\lim_{n\rightarrow\infty}f(b_n)=\lim_{n\rightarrow\infty}g(b_n)=g(\lim_{n\rightarrow\infty}b_n)=g(a).$$ Is this a good proof? How does the other way go?","['functional-analysis', 'normed-spaces', 'general-topology', 'linear-transformations']"
2031498,How many distinct trees with N nodes?,"I need help on this question regarding how many distinct trees exist given N nodes in the tree. ""Distinct"" here means that two isomorphic trees are counted as one. For 3 nodes, would the number of trees be 1 (since every other tree with 3 nodes is just an isomorphism of the other)? Thanks.","['graph-theory', 'trees', 'discrete-mathematics']"
2031501,Measure theory: Counterexample for a limit of Lebesgue measurable sets,"Let $(A_k)_{k \in \Bbb {N}}$ be a sequence of Lebesgue measurable subsets of $\Bbb {R}^n$. 
$A_k \in \mathscr {A}_n {} ,(A_k) \subset \Bbb{R}^n \ \forall k \in \Bbb {N}$ Let $ A^* = \{ x \in \Bbb {R}^n \mid x \in A_k \text{ for infinitely many } k \in \Bbb {N} \} $ I'm trying to find a sequence $A_k$ to disprove the following statement if $ \lim_{k \to \infty } (\mathscr{L}^n(A_k)) = 0 $ then $ \mathscr{L}^n(A^*) = 0 $ with $ \mathscr{A}_n = \{ A \in \Bbb {R}^n \mid \text{A is Lebesgue-measurable}\}$ and $ \mathscr{L}^n $ is the n-dimensional Lebesgue-measure. Thanks for any help","['lebesgue-measure', 'measure-theory', 'limits']"
2031507,A question regarding picking balls from an urn,"Five balls are randomly chosen, without replacement,
from an urn that contains 5 red, 6 white, and
7 blue balls. Find the probability that at least one
ball of each color is chosen. I suppose I should use the Inclusion–exclusion principle but I would like to know why my initial attempt was wrong. $$\frac{\binom{5}{1}\binom{6}{1}\binom{7}{1}\binom{15}{2}}{\binom{18}{5}}$$ Why is this wrong? Since there has to be at least 1 ball of each color we have $\binom{5}{1}\binom{6}{1}\binom{7}{1}$ ways of picking them. For  each combination there remains 2 balls to be picked from the remaining $15$, so $\binom{15}{2}$ ways. The sample space consists of $\binom{18}{5}$ outcomes. Or so I though, clearly I am wrong. What did I mess up?","['combinatorics', 'binomial-coefficients', 'probability', 'discrete-mathematics']"
2031547,$L_p$ norm of the Dirichlet Kernel,"I am trying to show that $$ \left(\int_{-1/2}^{1/2} \left|\dfrac{\sin(\pi(2N+1)x)}{\sin(\pi x)}\right|^p dx \right)^{1/p}  \approx N^{\frac{p-1}{p}}$$ for all $1<p\leq \infty$ by using the fact that $|\sin(x)| \approx |x|$ if $x \in [-1/2, 1/2)$. I have tried using the change $y=Nx$ and I end having the result $2N+1$. I do not know what I am doing wrong. I would appreciate any help.","['complex-analysis', 'fourier-series', 'fourier-analysis']"
2031553,Is there a way to graphically visually integration by substitution?,"In integration by substitution, we change the variable. For example:
$$\int_{x^{2}=0}^{x^{2}=9} x^{2} d(x^{2})=\int_{x=0}^{x=3} x^{2} \dfrac{d(x^{2})}{dx}dx$$ 
Here since we have two different variables I find it impossible to graphically visualize how integration by substitution works. Is there any other way to visualize this. Any help will be appreciated.","['substitution', 'visualization', 'integration', 'calculus']"
2031572,How to prove $\sum\limits_{n=1}^\infty\frac{\sin(n)}n=\frac{\pi-1}2$ using only real numbers.,"I noticed that a lot of the time, people ask whether the following sum converges: $$\sum_{n=1}^\infty\frac{\sin(n)}n$$ Though I've never stopped to ask what it equaled.  According to this other post , the sum is given as $$\sum_{n=1}^\infty\frac{\sin(n)}n=\frac{\pi-1}2$$ The solution involves realizing $\sin(n)=\Im e^{in}$ and the Taylor expansion for the natural logarithm. While thats great and all, how can I prove this using only real numbers?","['alternative-proof', 'real-analysis', 'sequences-and-series', 'pi']"
2031586,"Why does this pattern of ""nasty"" integrals stop?","I. Integrals We have ( typo corrected ), \begin{align}
I_1 &=\pi =\int_{-\infty}^{\infty}\frac{(x-1)^2}{\color{blue}{(2x - 1)}^2 + (x^2 - x)^2}\,dx,\quad\text{(by Mark S.)}\\[1.8mm]
I_3 &=\pi =\int_{-\infty}^{\infty}\frac{(x+1)^2}{\color{blue}{(x + 1)}^2 + (x^2 + x)^2}\,dx\\[1.8mm]
I_5 &=\pi =\int_{-\infty}^{\infty}\frac{(x+1)^2}{\color{blue}{(x^2 - x - 1) }^2 + (x^2 + x)^2}\,dx\\[1.8mm]
\color{red}{I_7} &=\pi =\int_{-\infty}^{\infty}\frac{(x+1)^2}{\color{blue}{(x^3 + 2x^2 - x - 1)}^2 + (x^2 + x)^2}\,dx\\[1.8mm]
I_9 &=\pi =\int_{-\infty}^{\infty}\frac{(x-1)^2}{\color{blue}{(x^3 - 3x^2 + 1)}^2 + (x^2 - x)^2}\,dx\\[1.8mm]
I_{11} &=\, ?? =\int_{-\infty}^{\infty}\frac{(x\pm1)^2}{\color{blue}{(x^5 + 3x^4 - 3x^3 - 4x^2 + x + 1)}^2 + (x^2 \pm x)^2}\,dx
\end{align} where those in blue are the minimal polynomials of $x=\frac{1}{2\cos(2\pi/p)}$ for $p=1,3,5,7,9,11$ . These integrals have the form, $$I_p  =\int_{-\infty}^{\infty}\frac{(x\pm 1)^2}{F_p(x)}$$ where $F(x)=0$ is an equation with a solvable Galois group excepting $p=11$ . The red integral $I_7$ is the one in the post, A nasty integral of a rational function , $$\int_0^{\infty} \frac{x^8 - 4x^6 + 9x^4 - 5x^2 + 1}{x^{12} - 10 x^{10} + 37x^8 - 42x^6 + 26x^4 - 8x^2 + 1} \, dx = \frac{\pi}{2}$$ as well as in this post after some manipulation. II. Question 1 Q: Why did the ""pattern"" of using minimal polynomials work then stop at $p=11$ , and how can we make it continue by adjusting other parameters? III. Alternative forms Based on an insight from an old post , for $p=7$ we use the ""negative"" case on both its numerator and denominator. The denominator is a sextic again with a solvable Galois group, discriminant factor $12833,$ and we find, $$\int_{-\infty}^{\infty}\frac{(x\color{red}-1)^2}{\color{blue}{(x^3 + 2x^2 - x - 1)}^2 + (x^2 \color{red}- x)^2}\,dx=\pi\sqrt{\frac{u}{\color{green}{12833}}}$$ where $u$ is a root of a nonic also with a solvable Galois group, $$\small -\color{green}{12833}^3*1782434241^2 - 41120374319577904376201744753 u - 354521093943488815427187669 u^2 - 550802363395052799639795 u^3 - 
  176617825075778391189 u^4 + 116970252692553921 u^5 - 20201478347596 u^6 + 
  1625465206 u^7 - 63997 u^8 + u^9=0$$ For $p=9$ , if we use the positive case, the denominator still is solvable. However, for $p=11$ , then $F(x) = 0$ is not solvable for either case. IV. Question 2 Q: So was the pattern interrupted because the denominator of $p=11$ no longer has a solvable Galois group?","['galois-theory', 'trigonometry', 'calculus', 'definite-integrals', 'pi']"
2031591,Is the derivative of Inverse hyperbolic tan and cotan function the same??,"I was just having some trouble with the derivatives of Inverse Hyperbolic function,, especially the Tan hyperbolic inverse and the Cotan hyperbolic inverse, they both have the same derivative but their graphs are different.
And i was thinking, how can functions having different graphs have the same derivatives? Sorry for, me being a bit dumb, in-case.... REGARDS!!","['derivatives', 'calculus', 'functions']"
2031677,Is $(x^3)/x$ really the same as $x^2$? [duplicate],"This question already has answers here : How can $\frac{x^3-4x^2+4x}{x^2-4}$ be both $0$ and ""undefined"" when $x = 2$? (4 answers) Closed 7 years ago . Is $f(x)=\dfrac{x^3}{x}$ really the same as $x^2$? At $x=0$, $f(x)=\dfrac{x^3}x$ is undefined.  So then why can't I just say $f(x) = \dfrac{x^3}{x} = x^2$ therefore $f(x)=\dfrac{x^3}{x} $  at $x=0$ is $0$ and not undefined!","['algebra-precalculus', 'functions']"
2031699,Boundary of the intersection of two open sets in $\mathbb{R}^n$,"Let $A,B$ be open subsets of $\mathbb{R}^n$. Does the following equality hold? $$\partial(A\cap B)= (\bar A \cap \partial B) \cup (\partial A \cap \bar B)$$ Edit: Thanks for showing me in the answers that above formula fails if $A$ and $B$ are disjoint but their boundaries still intersect. I was able to come up with a similar formula which avoids this case
$$[\partial(A\cap B)]\setminus(\partial A \cap \partial B)= (A \cap \partial B) \cup (\partial A \cap B),$$
which I was able to prove and suffices for what I need to do. However, when showing that $ (A \cap \partial B) \cup (\partial A \cap B)\subseteq \partial(A\cap B)$, I needed to assume that the topology is induced by a metric. I wonder if the formula still holds in an arbitrary topological space.","['general-topology', 'metric-spaces', 'elementary-set-theory']"
2031744,"On the integral $\int_0^\infty \eta^2(i x) \,dx = \ln(1+\sqrt{3}+\sqrt{3+2 \sqrt{3}})$ and its cousins","While experimenting with integrals involving the Dedekind Eta function, I came across a family of integrals which seem to follow 
a very simple pattern. With $y \in \mathbb{N}$, define:
$$A(y) = \int_0^{\infty} \eta( i x)\,\eta(i x y)\,dx.$$
The integral can be rewritten in the following infinite series forms: \begin{align}
A(y) & = \frac{12}{\pi} \sum_{(n,m) \in \mathbb{Z}^2} \frac{(-1)^{n+m}}{(6n+1)^2+y \, (6m+1)^2} \\[8pt]
& =\frac{2 \sqrt{3}}{\sqrt{y}} \sum_{n \in \mathbb{Z}} \frac{(-1)^n}{6n+1} \, \dfrac{ \sinh \frac{\pi \sqrt{y}}{3} (6n+1)}{\cosh \frac{\pi \sqrt{y}}{2} (6n+1)} \\[8pt]
& = \frac{2}{\sqrt{y}} \sum_{n \in \mathbb{Z}} (-1)^n \tanh^{-1} \left( \frac{\sqrt{3}}{2} \operatorname{sech}(\pi \sqrt{y} (n+1/6))\right).
\end{align} Numerical computations seem to confirm that \begin{align}
A(1) & = \ln\left(1+ \sqrt{3} +\sqrt{3+2 \sqrt{3}} \right) \tag{1} \\[8pt]
A(2) & = \frac1{\sqrt{2}} \ln \left(1+ \sqrt{2} + \sqrt{2+ 2 \sqrt{2}} \right) \tag{2} \\[8pt]
A(3) & = \frac1{\sqrt{3}} \ln \left( 1+ 2^{1/3} + 2^{2/3} \right) \tag{3}
\end{align} And generally, it looks like $$A(y) = \frac1{\sqrt{y}} \,\ln u \tag{4}$$
where $u$ is the root closest to $1$ from above, of a polynomial $P_y$. 
I've checked dozens of different $y$'s and made a list of those polynomials - check this pastebin link. Some are missing, e.g. I could not find $P_6$. Others seem to follow patterns of their own, for example the Heegner numbers. Here's the polynomial for $y=163$: $$\small P_{163}(u) = u^{12} + 640314 u^{10} + 1280624 u^9 + 640287 u^8 - 1280736 u^7 - 2561412 u^6 - 1280736 u^5 + 640287 u^4 + 1280624 u^3 + 640314 u^2 + 1 = 0$$ Other interesting things to look at are the behaviour of $P_y(1)$ and $P_y(-1)$, with regard to $y \pmod{24}$, and approximations to $\pi$ which follow from terminating the infinite series at its first term. However, I have got no clue how to prove it. What would be a way to prove $(4)$? What can be said about the polynomials $P_y$?
  Also, can you help me find $P_6$, or other missing polynomials from my list? Edit. Finally, I was able to produce a closed form for this integral thanks to @DaveHuff's hints. The idea is to rewrite the infinite series as
 $$A(y) = \frac2{\sqrt{y}} \sum_{n=0}^{\infty} \tanh^{-1}\left( \dfrac{\cos \frac{\pi}{6} (2n+1)}{\cosh \frac{\pi \sqrt{y}}{6} (2n+1)}\right),$$
and then, using $\displaystyle \,\,\,\tanh^{-1}x = \frac12 \ln \left( \frac{1+x}{1-x} \right),$ proceed to factorize the summand and obtain 
$$\sqrt{y} \,A(y) = \sum_{n=1}^{\infty} \ln \left( \dfrac{(1-e^{5 \pi i n/6-\pi n\sqrt{y}/6})(1-e^{-5 \pi i n/6-\pi n\sqrt{y}/6})}{(1-e^{ \pi i n/6-\pi n\sqrt{y}/6})(1-e^{-\pi i n/6-\pi n\sqrt{y}/6})} \right),$$ which means: 
$$A(y) = \frac1{\sqrt{y}} \,\ln \left( \dfrac{\eta\left(\frac{i \sqrt{y}+5}{12}\right)\eta\left(\frac{i \sqrt{y}-5}{12}\right)}{\eta\left(\frac{i \sqrt{y}+1}{12}\right)\eta\left(\frac{i \sqrt{y}-1}{12}\right)}\right).$$ I still don't know enough eta quotient theory, so I don't know how to show that this eta quotient is in fact algebraic for every natural $y$ (let alone bring it to the implicit form in @TitoPiezasIII 's answer), but this is still good progress.","['closed-form', 'integration', 'definite-integrals', 'modular-forms', 'sequences-and-series']"
2031800,"Continuous mapping from $[0,1]$ to $[0,1]^2$","As explained in this answer , it is possible to create a bijection from $[0,1]\rightarrow[0,1]^2$. However, the example provided is clearly not continuous. It seems either very complicated or impossible to create a continuous bijection between the unit interval and the unit square. Does this mapping exist? If so, what does it look like? If not, how does one prove that there does not exist a continuous bijective mapping between $[0,1]\rightarrow[0,1]^2$?","['continuity', 'general-topology', 'elementary-set-theory']"
2031832,How to prove the following statement about non-terminating decimals?,I was asked to prove the following statement: Suppose $A=.a_1a_2a_3...$ and $B=.b_1b_2b_3..$ are non-terminating decimals in standard form with $A>B$. There is a rational number between $A$ and $B$. Can somebody explain this to me? Thank you very much.,"['number-theory', 'real-analysis', 'rational-numbers', 'discrete-mathematics']"
2031850,"Prove a matrix in $SL(2,\Bbb R)$ representing a Möbius transformation is an isometry of upper half plane","Let $H ⊂ C$ be the upper half plane with the hyperbolic metric.
  Prove than any matrix $M ∈ SL(2, \mathbb{R})$ representing a Möbius
  transformation is an isometry of $H$. How do I prove this statement? I know $SL(2,\mathbb{R})$ is the group of 2 x 2 matrices with entries in $\mathbb{R}$, and that the Möbius transformation is defined as:
$$A(z) = \frac{az+b}{cz+d}$$","['hyperbolic-geometry', 'mobius-transformation', 'geometry']"
2031858,"Can $(\mathcal P(\mathbb N),\subseteq)$ be partitioned into maximal antichains?","If you look at the set of finite subsets of $\mathbb N$ (side question: Is there a standard notation for that?) partially ordered by the subset relation, you see that it can be partitioned into maximal antichains (that is, you have a set of maximal antichains so that any two of them are disjunct, and their union is the set of finite subsets of $\mathbb N). One possibility (but by far not the only one) is to have each antichain consist of all sets of the same cardinality. Also for the set of all subsets of $\mathbb N$ that are either finite or cofinite, it's not hard to define such a partition; partition the finite sets according to their cardinality, and the cofinite sets according to the cardinality of the complement. Of course such simple strategies won't work any more with the full $\mathcal P(\mathbb N)$. Indeed, I have no idea how one would either define such a partition, or prove that there doesn't exist one. Of course there's also the possibility that there exists such a partition, but you cannot explicitly specify it. Therefore my question is: Does there exist a partition of $(\mathcal P(\mathbb N),\subseteq)$ into maximal antichains, and if so, is is possible to explicitly specify one?","['order-theory', 'elementary-set-theory']"
2031900,Proving the irrationality of the number $\cos\frac\pi9$,"The question is if there exists a standard way of proving that 
$$ \cos{ π \over 9}$$ is an irrational number.","['algebra-precalculus', 'number-theory', 'rationality-testing', 'trigonometry']"
2031923,Upper bound for $|e^z|$,I want to find an upper bound for $|e^z|$ on the circle $\gamma(t)=2e^{it}.$ My thoughts are as follows: $$|e^z|=|e^{2(\cos t+i\sin t)}|=|e^{2\cos t}|\cdot|e^{2i\sin t}|\leq |e^2|\cdot|e^{2i}|=e^2$$ I'm not convinced that this is correct though. Is this right?,['complex-analysis']
2031926,Self study Control Theory,"Please forgive the long setup but I think it is relevant to my question. I am a third year Electrical Engineering student (before dismissing me a an engineer please read the rest of the question) and I am planning on doing graduate studies in Control Theory. I find it really brings together pure math and some sort of distant application which is enough for me. As such I've taken the usual engineering math courses  (Calculus, Linear Algebra, Complex Analysis, Dynamical Systems, a whole ton of Fourier analysis, PDEs, Probabilities and such) where they proceeded to completely disregard any rigor. The only thing close to rigorous math that I actually did was in our Algorithms course which was fascinating  (P=NP, Graphs, etc) and actually satisfyingly rigorous. Anyways, I am now at a point where I want to strengthen my actual math knowledge and especially work towards a really good knowledge of Differential Geometry, Complex Analysis and Topology. As such I began studying the basics: real analysis with Chapman Pugh which I am really enjoying. However I would have appreciated some input on what you think is the best way to proceed from here. My plan was next to do Topology with Munkres, Abstract Algebra with Dummit (perhaps not everything but at the very least a good coverage of group theory) and sometime after Smooth Manifolds by Lee and Papa Rudin. What do you think?","['real-analysis', 'dynamical-systems', 'control-theory', 'general-topology', 'differential-geometry']"
2031949,What points on surface is the tangent plane parallel to $xy$- plane?,"At what pts. on the surface $z = x^{2}y + y^{2}x + 3x$ is the tangent plane parallel to the $xy$-plane? So first I define a function $F(x, y, z) =  x^{2}y + y^{2}x + 3x - z$ which has gradient $grad F = (2xy + y^2 + 3, x^{2} + 2yx, -1)$. So the equation of our tangent plane is: $(2xy + y^{2} + 3)(x - x_{0}) + (x^{2} + 2yx)(y - y_{0}) - (z - z_{0}) = 0$. So we get as a normal line: $r(t) = (x_{0} + (2x_{0}y_{0} + y_{0}^{2} + 3)t, y_{0} + (x_{0}^{2} +2y_{0}x_{0})t, z_{0} - t)$. Now I know two planes are parallel if their normal lines are parallel, but I'm not quite sure how to complete the problem.",['multivariable-calculus']
2031980,Where is the wild use of the Dirac delta function in physics justfied?,"Wikipedia has a wild article about the Dirac delta function. Are the things listed correct? Or is there no proof that they are correct? For my master thesis I want to refer to rigorous proofs of these properties if they exist. The problem is that Wikipedia's list of references is meager and in almost every appropriate place, the references are missing. To give you a taste, some properties Wikipedia lists are: Fourier transform of delta function, delta function composition with another function translations of delta function, delta function is an even function the property $\delta(ax) = \delta(x)/|a|$ algebraic properties integration by parts of integrals containing delta function, distributional derivatives I looked at a few texts, but they were not relevant for two reasons, i.e. Griffel - modern functional analysis, because the space of functions were too small (test functions with compact support). In physics, the convolving function (not the generalized function) is usually any function on $\mathbb{R}^d$, and therefore I am interested in a large a space as possible. And second, they didn't refer to anywhere near all these properties. Is there a math book written by a mathematician (not a physicist) which treats much of the above rigorously? Alternatively, if you can justify that the above properties are just physics (not math) sufficiently well, then I can let it go and get on with my life. Either is appreciated.","['functional-analysis', 'dirac-delta', 'mathematical-physics', 'fourier-analysis']"
2032002,Group (co)homology and classyfing spaces,I would like to ask where I can find in the literature the proof of the following fact: the group cohomology of the group $G$ is naturally isomorphic with the ordinary (say singular) cohomology of the classyfing space $BG$ of $G$.,"['homology-cohomology', 'reference-request', 'classifying-spaces', 'group-cohomology', 'group-theory']"
2032029,Prove that all nxn nilpotent matrices of order n are similar.,I have to show that all $n \times n$ nilpotent matrices of order n are similar. My initial approach was to show that for all nilpotent matrices their minimun characteristic polynomial is of the form: $$\lambda^n$$ Is this sufficient? Can someone show me a formal approach to this problem? Thanks!,"['matrices', 'linear-algebra', 'nilpotence']"
2032038,Is it possible to use polynomial interpolation to show that $\cos(x) = \sum_{n=0}^{\infty} \frac{(-1)^nx^{2n}}{(2n)!}$?,"Several months ago, I discovered that one can make use a system of linear equations to obtain a polynomial that approaches certain functions . And I know these is the series representation for: $$\displaystyle \cos(x) = 1 - {x^{2} \over 2!} + {x^{4} \over 4!} - \cdots = \sum_{n=0}^{\infty} \frac{(-1)^nx^{2n}}{(2n)!}$$ So I decided to test this and try to obtain this series with the bakground I learned above. So I did the following: I'd need a systems of equations in the following form: $$\begin{cases}
 a_1 x_1+a_0=\cos(x_1) \\
 a_1 x_2+a_0=\cos(x_2) \\
\end{cases}$$ $$\begin{cases}
 a_2 x^2_1+a_1 x_1+a_0=\cos(x_1) \\
 a_2 x^2_2+a_1 x_2+a_0=\cos(x_2) \\
 a_2 x^2_3+a_1 x_3+a_0=\cos(x_3) \\
\end{cases}$$ $$\begin{cases}
 a_3 x^3_1+a_2 x_1^2+a_1 x_1+a_0=\cos(x_1) \\
 a_3 x^3_2+a_2 x^2_2+a_1 x_2+a_0=\cos(x_2) \\
 a_3 x^3_3+a_2 x^2_3+a_1 x_3+a_0=\cos(x_3) \\
 a_3 x^3_4+a_2 x^2_4+a_1 x_4+a_0=\cos(x_4)\\
\end{cases}$$ So, find a solution for $a_n$ should give me the coefficients of a polynomial that approaches the $\cos(x)$ at $x_n$. And hence, I did this: $$\begin{cases}
 a_0+\frac{\pi  a_1}{4}=\frac{1}{\sqrt{2}} \\
 a_0+\frac{\pi  a_1}{2}=0 \\
\end{cases}$$ $$\begin{cases}
 a_0+\frac{\pi  a_1}{4}+\frac{\pi ^2 a_2}{16}=\frac{1}{\sqrt{2}} \\
 a_0+\frac{\pi  a_1}{2}+\frac{\pi ^2 a_2}{4}=0 \\
 a_0+\frac{3 \pi  a_1}{4}+\frac{9 \pi ^2 a_2}{16}=-\frac{1}{\sqrt{2}} \\
\end{cases}$$ $$\begin{cases}
 a_0+\frac{\pi  a_1}{4}+\frac{\pi ^2 a_2}{16}+\frac{\pi ^3 a_3}{64}=\frac{1}{\sqrt{2}} \\
 a_0+\frac{\pi  a_1}{2}+\frac{\pi ^2 a_2}{4}+\frac{\pi ^3 a_3}{8}=0 \\
 a_0+\frac{3 \pi  a_1}{4}+\frac{9 \pi ^2 a_2}{16}+\frac{27 \pi ^3 a_3}{64}=-\frac{1}{\sqrt{2}} \\
 a_0+\pi  a_1+\pi ^2 a_2+\pi ^3 a_3=-1 \\
\end{cases}$$ And (using Mathematica), I've found the solutions: $$\begin{array}{cc}
 a_0= \sqrt{2} & a_1= -\frac{2 \sqrt{2}}{\pi } \\
\end{array}$$ $$\begin{array}{ccc}
 a_0= \sqrt{2} & a_1= -\frac{2 \sqrt{2}}{\pi } & a_2= 0 \\
\end{array}$$ $$\begin{array}{cccc}
 a_0= 1 & a_1= \frac{2 \left(8 \sqrt{2}-11\right)}{3 \pi } & a_2= -\frac{16 \left(\sqrt{2}-1\right)}{\pi ^2} & a_3= \frac{32 \left(\sqrt{2}-1\right)}{3 \pi ^3} \\
\end{array}$$ My thinking is that as we put more equations in the system for more values of $\cos$, it will give a polynomial that better approaches $\cos$. And as I put more equations with more values for cosine at the system, the solutions were: $$\begin{array}{cc}
 a_0= \sqrt{2} & a_1= -\frac{2 \sqrt{2}}{\pi } \\
\end{array}$$ $$\begin{array}{ccc}
 a_0= \sqrt{2} & a_1= -\frac{2 \sqrt{2}}{\pi } & a_2= 0 \\
\end{array}$$ $$\begin{array}{cccc}
 a_0= 1 & a_1= \frac{2 \left(8 \sqrt{2}-11\right)}{3 \pi } &  a_2= -\frac{16 \left(\sqrt{2}-1\right)}{\pi ^2} &  a_3= \frac{32 \left(\sqrt{2}-1\right)}{3 \pi ^3} \\
\end{array}$$ $$\begin{array}{ccccc}
 a_0= 5-3 \sqrt{2} & a_1= -\frac{122-91 \sqrt{2}}{3 \pi } & a_2= -\frac{2 \left(129 \sqrt{2}-164\right)}{3 \pi ^2} & \\  a_3= \frac{16 \left(17 \sqrt{2}-22\right)}{3 \pi ^3} & a_4= -\frac{32 \left(3
   \sqrt{2}-4\right)}{3 \pi ^4} \\
\end{array}$$ $$\begin{array}{cccccc}
 a_0= -5 \left(2 \sqrt{2}-3\right) & a_1= \frac{2 \left(707 \sqrt{2}-990\right)}{15 \pi } & a_2= -\frac{4 \left(222 \sqrt{2}-307\right)}{3 \pi ^2} &\\  a_3= \frac{8 \left(153 \sqrt{2}-214\right)}{3 \pi
   ^3} & a_4= -\frac{64 \left(12 \sqrt{2}-17\right)}{3 \pi ^4} & a_5= \frac{128 \left(7 \sqrt{2}-10\right)}{15 \pi ^5} \\
\end{array}$$ $$\begin{array}{ccccccc}
 a_0= 35-24 \sqrt{2} & a_1= \frac{8 \left(434 \sqrt{2}-615\right)}{15 \pi } & a_2= -\frac{4 \left(9014 \sqrt{2}-12725\right)}{45 \pi ^2} & \\ a_3= \frac{128 \left(31 \sqrt{2}-44\right)}{3 \pi ^3} &
   a_4= -\frac{32 \left(317 \sqrt{2}-452\right)}{9 \pi ^4} & a_5= \frac{1024 \left(7 \sqrt{2}-10\right)}{15 \pi ^5} & \\ a_6= -\frac{512 \left(7 \sqrt{2}-10\right)}{45 \pi ^6} \\
\end{array}$$ $$\begin{array}{cccccccc}
 a_0= -3 (16 \sqrt{2}-23) & a_1= \frac{2 \left(25220 \sqrt{2}-35733\right)}{105 \pi } & a_2= -\frac{4 \left(20270 \sqrt{2}-28671\right)}{45 \pi ^2} & \\ a_3= \frac{8 \left(19044
   \sqrt{2}-26999\right)}{45 \pi ^3} &  a_4= -\frac{32 \left(989 \sqrt{2}-1404\right)}{9 \pi ^4} & a_5= \frac{256 \left(360 \sqrt{2}-511\right)}{45 \pi ^5} & \\ a_6= -\frac{512 \left(55
   \sqrt{2}-78\right)}{45 \pi ^6} & a_7= \frac{2048 \left(12 \sqrt{2}-17\right)}{315 \pi ^7} \\
\end{array}$$ Now, here I expected a miracle: $\quad \quad \quad\quad \quad\quad$ I expected that somehow, the coefficients of $a_n$ converged to the coefficients of the series I gave in the beginning (because of the better polynomial that approaches $\cos$) but just by looking at it, this doesn't seems to be the case. But I don't know how to prove this is actually not the case: Is it possible that the method I employed could yield the results I expect or is it impossible? I understand that my thinking is poorly justified and perhaps too vague but I want to know if something can be made with it or if it is possible to use polynomial interpolation to show that $\cos(x) = \sum_{n=0}^{\infty} \frac{(-1)^nx^{2n}}{(2n)!}$?","['real-analysis', 'sequences-and-series']"
2032059,Function injective iff,"Let $f:X\to Y$ . Prove that $$\text{f is injective}\iff \forall A \subseteq X, \quad f(X-A)\subseteq Y-f(A)$$ My try: For $\leftarrow$ . Let $f(x_1)= f(x_2)$ and take for $A=\{x_1\}$ then if $x_1\neq x_2$ then $x_2\in X-A$ so $f(x_2)\subseteq Y-f(x_1)=Y-f(x_2)$ so $x_1=x_2$ For $\rightarrow$ If $y\in f(X-A)$ then $f^{-1}(y) \in X-A $ $y\in f(X)  $ and $f^{-1}(y)\notin A$ Since $f(X)\subseteq Y$ then $$y\in Y-f(A)$$ I'm not sure for $\leftarrow$ , but for $\rightarrow$ I think I'm wrong because didn't use injective","['elementary-set-theory', 'functions']"
2032110,Probability - mixing cards,"The package contains 8 different cards, two of each color (that means 4 colors). We will mix the package. How likely we get combination in which no two cards of the same color are next to each other? There are $8!$ combinations how to mix the package. Now, I have to compute the number of combinations in which no two cards of the same color are next to each other. No idea how to do that. Maybe we place 4 cards of different color randomly (in $8*7*6*5$ ways) and then - I don't know. Maybe some Inclusion-Exclusion Principle?","['combinatorics', 'probability']"
2032119,Show that $X$ is regular iff for every point $x$ and its nbd $V$ there is nbd of $x$ such as $x \in U \subset cl(U) \subset V$,"Show that $X$ is regular iff for every point $x$ and its nbd $V$ there is nbd of $x$ such as $x \in U \subset cl(U) \subset V$. I'll start with implication $(\Leftarrow)$. Let $F$ be an arbitrary closed set $F\subset X$ and $x \in F^c$. From assumption, since $F^c$ is open, there exists nbd of $x$ such as $x \in U \subset cl(U) \subset F^c$. Moreover, $(cl(U))^c$ is an open set containing closed set $F$. Of course $(cl(U))^c \cap U = \emptyset$. We have shown, that $X$ is regular. $(\Rightarrow)$Suppose $X$ is regular. Take an arbitrary point $x\in X$ and its nbd $V$.
Set $V^c$ is closed and $x\notin V^c$. From the fact, that $X$ is regular we find open sets $U_1, U_2$ such as $x\in U_1$,$V^c \subset U_2$ and $U_1 \cap U_2 = \emptyset$. Of course $U_1 \subset V$. But how do we know, that $cl(U_1) \subset V$? Any hints would be great.","['general-topology', 'elementary-set-theory']"
2032178,"Help with $\int \cos^6{(x)} \,dx$","Problem: \begin{eqnarray*}
\int \cos^6{(x)} dx \\
\end{eqnarray*} Answer: \begin{eqnarray*}
\int \cos^4{(x)} \,\, dx &=& \int { \cos^2{(x)}(\cos^2{(x)})  } \,\, dx \\
\int \cos^4{(x)} \,\, dx &=& \int { \frac{(1+\cos(2x))^2}{4}  } \,\, dx \\
\int \cos^4{(x)} \,\, dx &=&
    \int { \frac{\cos^2(2x)^2 + 2\cos(2x)+1}{4}  } \,\, dx \\
\int \cos^4{(x)} \,\, dx &=&
    \int { \frac{(\frac{1+\cos(4x)}{2} + 2\cos(2x)+1}{4}  } \,\, dx \\
\int \cos^4{(x)} \,\, dx &=&
    \int { \frac{1+\cos(4x) + 4\cos(2x)+2}{8}  } \,\, dx \\
\int \cos^4{(x)} \,\, dx &=&
    \int { \frac{\cos(4x) + 4\cos(2x)+3}{8}  } \,\, dx \\
\int \cos^4{(x)} \,\, dx &=& \frac{\sin(4x)+ 8 \sin(2x)+12x}{32} \\
\text{Let }I_6 &=& \int \cos^6{(x)} \,\, dx \\
\end{eqnarray*}
To perform this integration, I use integration by parts with
$u = \cos^5(x)$ and $dv = \cos(x) dx$.
\begin{eqnarray*}
I_6 &=& \sin(x)\cos^5(x) - \int \sin(x) 5\cos^4(x)(-\sin(x)) \,\, dx \\
I_6 &=& \sin(x)\cos^5(x) + \int 5\cos^4(x)(\sin(x))^2 \,\, dx \\
I_6 &=& \sin(x)\cos^5(x) + \int 5\cos^4(x)(1 - \cos(x))^2 \,\, dx \\
I_6 &=& \sin(x)\cos^5(x) + \int 5\cos^4(x) \,\, dx  - 5I_6 \\
6I_6 &=& \sin(x)\cos^5(x) + \int 5\cos^4(x) \,\, dx \\
6I_6 &=& \sin(x)\cos^5(x) + \frac{5\sin(4x)+ 40 \sin(2x)+60x}{32}  + C_1 \\
6I_6 &=& \frac{32\sin(x)\cos^5(x) + 5\sin(4x)+ 40 \sin(2x)+60x}{32} + C_1 \\
I_6 &=& \frac{32\sin(x)\cos^5(x) + 5\sin(4x)+ 40 \sin(2x)+60x}{192} + C  \\
\end{eqnarray*}
I believe that the above result is wrong. Using an online integral
calculator, I get:
\begin{eqnarray*}
I_6 &=& \frac{\sin(6x) + 9\sin(4x) + 45 \sin(2x) + 60x}{192} + C \\
\end{eqnarray*}
I am hoping that somebody can tell me where I went wrong. Bob","['integration', 'trigonometry', 'calculus']"
2032209,Understanding why conditional probability is defined the way it is.,Just moments ago I stumbled upon the definition of conditional probability and I'm experiencing some difficulties in acquiring an intuitive understanding of why it's defined the way it is. $$P(E|F)= \dfrac{P(E \cap F)}{P(F)}$$ I'm more familiar with taking into consideration the amount of outcomes of interest and dividing that amount by the amount of outcomes in the sample space. I don't know how to interpret the logic behind conditional probability. I understand that $P(F)$ is the probability that the event which is known to have occured occurs. So I suppose that it can be calulated the way I am familiar with. Presumably the same goes for $P(E \cap F)$ by using the Inclusion–exclusion principle. But why one is divided by the other I cannot fathom. Why is it defined this way? How does one make sense of it.,"['probability', 'discrete-mathematics']"
2032212,Calculating $\lim_{x\to\infty}\left(x e^{\frac{1}{x}} - \sqrt{x^2+x+1} \right)$,"I've managed to solve it by rewriting the expression as
$$\frac{1 - \frac{\sqrt{x^2 +x + 1}}{x e^{\frac{1}{x}}} }{ \frac{1}{x e^{\frac{1}{x}}} }$$ then applying L'Hospital's rule. This took up one whole page and was very hairy, even after substituting $t = \sqrt{x^2+x+1}$. I'm wondering if there's a simpler way. A friend suggested substituting $e = (1+\frac{1}{x})^x$, but that's a bit suspicious. In both cases, the answer is $\frac{1}{2}$, as confirmed by my computer.",['limits']
2032217,Using the Uniform Continuity of the Characteristic Function to Show it's Differentiable,"I am working on part (iii) of exercise 3.3.17. in Durrett's Probability book. See this question: Relationship between the weak law of large numbers and characteristic functions Basically, my issue is this. $\varphi$ is the ch.f. of a random variable. We know that $n(\varphi(t/n)-1)\to iat$ for all $t$ as $n\to\infty$ through the integers.  I am trying to show that 
$$
\frac{\varphi(h)-1}{h}\to ia
$$
as $h\downarrow 0$ in an arbitrary way, thereby proving that $\varphi'(0)$ exists. I know that $\varphi$ is uniformly continuous. Following the solution suggested in the above link, I considered the following approach. Let $h_{n}$ be an arbitrary sequence of real numbers descending to $0$. For an arbitrary $\delta >0$, we may write $h_{n}=t_{n}/m_{n}$ for sufficiently large $n$, where $m_{n}\in\mathbb{N}$ and $|t_{n}-1|<\delta$. Hence, for sufficiently large $n$, $$
\begin{aligned}
\left|\frac{\varphi\left(\frac{t_{n}}{m_{n}}\right)-1}{\frac{t_{n}}{m_{n}}}-ia\right|&=\frac{1}{t_{n}}\left|m_{n}\left(\varphi\left(\frac{t_{n}}{m_{n}}\right)-1\right)-iat_{n}\right|\\
&\leq\frac{1}{1-\delta}\left|m_{n}\left(\varphi\left(\frac{t_{n}}{m_{n}}\right)-\varphi\left(\frac{1}{m_{n}}\right)\right)\right|\\
&\qquad+\frac{1}{1-\delta}\left|m_{n}\left(\varphi\left(\frac{1}{m_{n}}\right)-1\right)-ia\right|\\
&\qquad+\frac{1}{1-\delta}\left|ia(1-t_{n})\right|
\end{aligned}
$$ Question: The last two terms I can control, my question is can I use the uniform continuity of $\varphi$ to prove that 
$$
\left|m_{n}\left(\varphi\left(\frac{t_{n}}{m_{n}}\right)-\varphi\left(\frac{1}{m_{n}}\right)\right)\right|\to 0\qquad\text{ as }n\to\infty?
$$","['uniform-continuity', 'probability-theory']"
2032225,Inverting Conditional Expectation,"I'm having difficulty finding papers which deal with the following inversion problem. Suppose I stochastic process $Y_t$ (which is described by a certain Hilbert-Space-valued SDE).  I want to know how to characterize all stochastic processes $X_t$ satisfying the following: If $\mathfrak{G}_t$ is the filtration generated by $Y_t$ and $\mathfrak{F}_t$ is the filtration generated by $X_t$, then $$
\mathfrak{G}_t\subseteq \mathfrak{F}_t$$ $\mathbb{E}[X_t \mid \mathfrak{G}_t]=Y_t$. I expect this has something to do with inverting the conditional expectation given $\mathfrak{F}_t$, but how can I do that?","['stochastic-processes', 'probability-theory', 'probability', 'stochastic-integrals', 'conditional-expectation']"
2032300,"For $A$ a tail event, show that $P(A)=0$ or $1$ by calculating expectations","I am a beginner student in probability theory.
I am having difficulty understanding the following problem: Suppose $I_A$ is a random variable on the infinite product probability space,
   $\Omega = \prod_{j=1}^\infty \Omega_j$, where $(\Omega_j, P_j)$ is a probability space.
   Suppose changing first $n$ coordinates of $I_A$ does not change the value of $I_A$.
   Show that $P(A)=0$ or $1$ by calculating $\int_{\Omega_n} \cdots \int_{\Omega_1} I_A dP_1 \cdots dP_n$.
   and $\int_{\Omega_n} \cdots \int_{\Omega_1} I_{A^c} dP_1 \cdots dP_n$. I understand that 
 $A$ is a tail event and that the Kolmogorov Zero-One Law gives the desired result; but having trouble how 
 I can see the result through expectations.
 I understand
 $P(A) = \int_{\prod_i \Omega_i} I_A dP$ where $P$ is the unique probability measure on $\Omega$.
 Any hint or advice would be appreciated.","['probability-theory', 'probability']"
2032361,Counting outcomes for coin tosses,"Don't laugh, this is a dumb question, but my brain just doesn't work mathematically.  A question in my math class says A coin is tossed 4 times.  Compute the probability of at least 2 tails
  occurring. OK, so I know I figure out how many total events are in the sample, then figure out how many possible ways at least 2 tails are occurring, and divide.  My problem is, I can NEVER seem to figure out how many total events there are!  I start with HHHH, HHHT, HHTH, HTHH, and so on, but I always get lost somewhere along the way, miss an event, and never get them all.  My book says there are 16 different possibilities.  Is there a better way of figuring out how many different events could happen??",['probability']
2032366,On a Clarkson-like inequality in $L^p$,"I'm currently reading the book ""Topics in Almost Everywhere Convergence"" by A. Garsia. At a certain point, he claims the validity of the following inequality, for $f, g \in L^p(X, \mathcal{A}, \mu)$, $\mu$ being a probability measure: \begin{equation*}
\|  f - g \|^{p}_{p} \leq C_{p} \left[ \| f \|_{p}^{p} + \| g \|_{p}^{p} -2 \left\| \frac{f + g}{2} \right\|_{p}^{p} \right]^{\min \{1, p/2\}}
\end{equation*} for any $p>1$, where $C_p$ is a constant and $f, g$ are on the unit ball. If $p\geq 2$, I see that this is Clarkson's inequality. However, for $1 < p <2$, it doesn't seem to be that simple. What bugs me the most is that this result is accompanied by the following footnote: This can be established by expressing $$|f|^p + |g|^p - 2 \left| \frac{f + g}{2} \right|^p$$ as an integral involving the second derivative of $|x|^p$. The constant $C_p$ tends to infinity as $p \to 1$. The above suggests that there is some unified approach for all values of $p$ and possibly elementary. Any hint on that direction would be appreciated.","['inequality', 'integral-inequality', 'functional-analysis', 'lp-spaces', 'measure-theory']"
2032387,Why can't my graphing calculator find the RREF of the transpose of a matrix?,"I know this is somewhat of an odd question, but I am having trouble with my TI-84 calculator and I don't know why. I'm trying to find the RREF of the transpose of a $4\times6$ matrix; for some reason my graphing calculator gives me an error. Something to do with the dimensions? Here is a photo of matrix $A$ . I want to find RREF $(A$ transposed $)$ .","['matrices', 'calculator', 'linear-algebra']"
2032408,Use elementary set operations to show sequence of sets is disjoint,"Let $\{A_n\}_{n=1}^\infty$ be an arbitrary sequence of sets. Construct from it a new sequence $\{B_n\}_{n=1}^\infty$ defined by $B_1=A_1$ and for $n>1$, we let $B_n=A_n\smallsetminus \left(\bigcup_{k=1}^{n-1}A_k\right)$. I want to show the $B_n$ are pairwise disjoint. That is, for any $i \ne j$, without loss of generality $i>j$,
\begin{align*}
B_i\cap B_j
&=\left(A_i \smallsetminus \bigcup_{n=1}^{i-1} A_n\right)\cap \left(A_j\smallsetminus \bigcup_{n=1}^{j-1} A_n\right) \\
&=\left(\bigcap_{n=1}^{i-1}(A_i \smallsetminus A_n)\right) \cap \left(\bigcap_{n=1}^{j-1}(A_j\smallsetminus A_n)\right) \\
&=\bigcap_{n=1}^{j-1} \left((A_i \smallsetminus A_n) \cup (A_j \smallsetminus A_n)\right) \cap \bigcap_{n=j}^{i-1} (A_i \smallsetminus A_n) \\
&=\bigcap_{n=1}^{j-1} \left((A_i \cup A_j) \smallsetminus A_n\right) \cap \bigcap_{n=j}^{i-1} (A_i \smallsetminus A_n) \\
&=\cdots \\
&=\emptyset
\end{align*}
It's easy enough to argue in words that this intersection must equal the empty set: For any $x$ in $\left(A_i \smallsetminus \bigcup_{n=1}^{i-1} A_n\right)\cap \left(A_j\smallsetminus \bigcup_{n=1}^{j-1} A_n\right)$, we would have $x \in A_i$ and $x
 \in A_j$, but $x \notin \bigcup_{n=1}^{i=1} A_n$ and $x \notin
 \bigcup_{n=1}^{j-1} A_n$, i.e.  $x \notin A_n$, $n=1,\ldots,i-1$ and
   $x \notin A_n$, $n=1,\ldots,j-1$. Since $i>j$, the last statement is
   redundant. Thus $x \in A_i$ and $x \in A_j$, but $x \notin A_n$,
   $i=1,\ldots,i-1$. But since $j<i$, the statement $i=1,\ldots,i-1$
   implies $x \notin A_j$, which is a contradiction. However I don't want to prove this in a paragraph of words -- I want to show algebraically that the intersection must equal the empty set using basic set operations (properties of the set difference, unions and intersections, etc.) to manipulate the above equations. But I get stuck along the way and it's not obvious what rules I should use next to manipulate the above equations. Anyone see any neat tricks to use? Thanks!","['sequences-and-series', 'elementary-set-theory']"
2032422,Some boys in the class are taller than all the girls?,"""Some boys in the class are taller than all the girls"" I tried in the following way : As it says that some boys are there, means that atleast 1 boy is there who is taller than all the girls . I think that its propositional logic can be :- $(∃x)(boy(x) ∧ (∀y)(girl(y) \rightarrow taller(x,y)))$ Here 1st AND shows that a boy is must, which implies that at least one boy should be there and 2nd IMPLIES shows that even if class does not have any girl, the property holds good. Am I right here ?","['predicate-logic', 'first-order-logic', 'discrete-mathematics']"
2032424,The difference of closure of a set,"Let $A$, $B\subset \mathbb R^N$ be given such that $A\subset B$. Assume that $\mathcal H^{N-1}(B\setminus A)<\epsilon$ where $\epsilon>0$ is a fixed constant and $\mathcal H^{N-1}$ is the $N-1$ dimensional Hausdorff measure (so we may think $A$ and $B$ are two curves embedded in $\mathbb R^N$). Moreover, we know that $\mathcal H^{N-1}(\overline {B}\setminus B)<\epsilon$ where $\overline{B}$ denotes the closure of set $B$, and $\mathcal H^{N-1}(\bar A\setminus A)=0$. My question: do we have 
$$
\mathcal H^{N-1}(\overline {B\setminus A})<2\epsilon
$$
hold? Update: I added an assumption on $A$ such that $A$ is compact, i.e., 
$$
\mathcal H^{N-1}(\overline {A}\setminus A^{\circ})=0
$$
where by $A^\circ$ we mean the interior of $A$. That is, I assume that $\mathcal H^{N-1}(\partial A)=0$. Hence, I may write
\begin{align}
\mathcal H^{N-1}(\overline {B\setminus A})\leq\mathcal H^{N-1}(\overline {\overline {B}\setminus A^\circ}) = \mathcal H^{N-1}( {\overline {B}\setminus A^\circ})\\
\leq\mathcal H^{N-1}( {\overline {B}\setminus B})+\mathcal H^{N-1}( {{B}\setminus A})+\mathcal H^{N-1}( {{A}\setminus A^\circ})\leq 2\epsilon.
\end{align} PS: I understand that $A^\circ$ might be ill-defined... I am trying to work out a fix.","['general-topology', 'lebesgue-measure', 'measure-theory']"
2032459,How to solve $\sqrt{6}\cdot x^4 - (\sqrt{3}+\frac{3}{2}\sqrt{2})x^2 +\frac{3}{2} = 0 $,"Of course I could put this is mathematica/wolframalpha or use a formula, but I think in here is a trick how to solve it very simply, but I can't figure it out. Help/Hints very appreciated $\sqrt{6}\cdot x^4 - (\sqrt{3}+\frac{3}{2}\sqrt{2})x^2 +\frac{3}{2} = 0 \Leftrightarrow $ $x^2(\sqrt{6}x^2-\sqrt{3}+ \frac{3}{2}\sqrt{2})= -\frac{3}{2}\Leftrightarrow $","['algebra-precalculus', 'roots', 'polynomials', 'quartics']"
2032507,Algebraic proof that if $a>0$ then $1+a^9 \leq \frac{1}{a}+a^{10} $,"Prove that if $a>0$ then $1+a^9 \leq \frac{1}{a}+a^{10} $. Using the fact that $a \gt 0$, multiply by $a$ on both sides and get everything to one side we have; $a^{11}-a^{10}-a+1 \geq 0$. By factoring $(a^{10}-1)(a-1) \geq 0 $. I am not sure how to proceed any further.","['algebra-precalculus', 'inequality', 'rearrangement-inequality']"
2032509,Show $e_1\wedge\cdots \wedge e_d$ is a non-zero vector in $\Lambda_d (V)$,"Given $\{e_1,\cdots,e_d\}$ a basis of $V$, we have $e_1\wedge\cdots
 \wedge e_d$ is a non-zero vector in the exterior algebra $\Lambda_d (V)$. Given a decomposable element which can be written as $v_1\wedge\cdots\wedge v_d$, it is the $0$ vector in $\Lambda_d (V)$ if $v_i = v_j$ for some $i,j$ between $1$ and $d$. So in general, the finite sum of decomposable elements like above are also zero. How would I argue that $e_1\wedge\cdots \wedge e_d$ can not be written as the sum of such elements.","['differential-geometry', 'differential-topology', 'exterior-algebra']"
2032590,"$\int_0^\infty \frac{\ln(x^2+1)}{x^{\alpha+1}}dx, 0<\alpha <2 $ using Residue and IBP","I am practicing the examples in alfors and I've been stuck in this problem for a quite few days $$\int_0^\infty \frac{\ln(x^2+1)}{x^{\alpha+1}}dx, 0<\alpha <2$$
What I've done so far was \begin{eqnarray*}
\int_0^\infty \frac{\ln(x^2+1)}{x^{\alpha+1}}dx\
&=&\frac{1}{-\alpha} \frac{\ln(x^2+1)}{x^{\alpha}}|_0^\infty 
+\frac{1}{\alpha} \int_0^\infty \frac{2x}{(x^2+1)x^{\alpha}}dx\\
&=^L& \frac{1}{(-\alpha)^2}[0-\lim_{x\to 0}\frac{2x}{(x^2+1)x^{\alpha +1}}] +\frac{2}{\alpha(1+e^{-i\pi (\alpha-1)})} \int_0^\infty \frac{(1+e^{i\pi (\alpha-1)})}{(x^2+1)x^{\alpha-1}}dx\\
&=&-\frac{1}{\alpha^2}\lim_{x\to 0}\frac{2}{(x^2+1)x^{\alpha}} +\frac{2}{\alpha(1+e^{-i\pi (\alpha-1)})}[\int_0^\infty \frac{1}{(x^2+1)x^{\alpha-1}}dx +\int_0^\infty \frac{e^{-i\pi (\alpha-1)}}{(x^2+1)x^{\alpha-1}}dx]\\
&=&-\frac{1}{\alpha^2}\lim_{x\to 0}\frac{2}{(x^2+1)x^{\alpha}} +\frac{2}{\alpha(1+e^{-i\pi (\alpha-1)})}[\int_0^\infty \frac{1}{(x^2+1)x^{\alpha-1}}dx +\int_0^\infty \frac{1}{(x^2+1)(xe^{i\pi})^{(\alpha-1)}}dx]\\
&=&-\frac{1}{\alpha^2}\lim_{x\to 0}\frac{2}{(x^2+1)x^{\alpha}} +\frac{2}{\alpha(1+e^{-i\pi (\alpha-1)})}[\int_0^\infty \frac{1}{(x^2+1)x^{\alpha-1}}dx +\int_0^\infty \frac{1}{((-x)^2+1)(-x)^{(\alpha-1)}}dx]\\
&=&-\frac{1}{\alpha^2}\lim_{x\to 0}\frac{2}{(x^2+1)x^{\alpha}} +\frac{2}{\alpha(1+e^{-i\pi (\alpha-1)})}[\int_0^\infty \frac{1}{(x^2+1)x^{\alpha-1}}dx +\int_0^{-\infty} \frac{1}{((x)^2+1)x^{\alpha-1}}(-dx)]\\
&=&-\frac{1}{\alpha^2}\lim_{x\to 0}\frac{2}{(x^2+1)x^{\alpha}} +\frac{2}{\alpha(1+e^{-i\pi (\alpha-1)})}\int_{-\infty}^\infty \frac{1}{(x^2+1)x^{\alpha-1}}dx\\
&=&-\frac{1}{\alpha^2}\lim_{x\to 0}\frac{2}{(x^2+1)x^{\alpha}} +\frac{2}{\alpha(1+e^{-i\pi (\alpha-1)})}[\oint-\int_{|z|=R,R\to \infty\\{Im(z>0)}\\Counterclockwise} -\int_{|z|=r,r\to 0\\{Im(z>0)}\\Clockwise}]\frac{1}{(z^2+1)z^{(\alpha-1)}}dz\\
\end{eqnarray*} Then, I'am stucked........
Any help would be appreciated.","['complex-analysis', 'improper-integrals']"
2032608,"Prove $\lim_{n\to\infty}\int_{E_n}f(x)d\mu=\int_E f(x)d\mu\,\,\,\,\,\,\text{ where }E=\cup_{n=1}^\infty E_n$","(a) Let $$E_1\subset E_2\subset ... \subset E_n\subset ... \subset I_0=:[a,b]$$ be a sequence of measurable sets and let $f:[a,b]\to\mathbb{R}$ be a non-negative integrable function. Show that $$\lim_{n\to\infty}\int_{E_n}f(x)d\mu=\int_E f(x)d\mu\,\,\,\,\,\,\text{ where }E=\cup_{n=1}^\infty E_n$$ (b) Is the above statement true without the hypothesis ""$f$ is non-negative""? Justify your answer. By Levi's theorem I know we can deal with non-decreasing measurable functions, but I don't know how to deal with this. Any help would be greatly appreciated. Thanks in advance.","['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
2032632,The set of self-adjoint operators over a Hilbert space doesn't form a lattice,"How can someone prove, that over a Hilbert space $\mathcal{H}$ with $dim \mathcal{H} \geq 2$, the set of all self-adjoint operators doesn't form a lattice? I found a result from Kadison, that if two self adjoint operators $A, B$ are not comparable, then they don't have a least upper bound. In 2 dimensions, I got two upper bounds of the (standard) projections $P_1, P_2$, which are not comparable. I think its not enough, but I can't go any further. Please help!","['functional-analysis', 'lattice-orders', 'operator-theory', 'hilbert-spaces']"
2032660,What is the dihedral angle formed by the faces of a tetrahedron,Background Dihedral angles are angles that are formed by two intersecting planes and no this is not a duplicate i check everyone possible duplicate because there is a slight variation that changes the problem in each question A regular tetrahedron is a triangular pyramid in which all four faces are equilateral triangle. find the acute dihedral angle between two faces of regular tetrahedron to the nearest tenth of a degree,"['algebra-precalculus', '3d', 'trigonometry', 'geometry']"
2032704,Triangle formed by any three tangents of the parabola $y^2=4ax$,"If a triangle is formed by any three tangents of the parabola $y^2=4ax$, two of whose vertices lie on the parabola $x^2=4by$, then find the locus of the third vertex.","['locus', 'analytic-geometry', 'triangles', 'geometry', 'conic-sections']"
2032707,Prove $\sum_{k=1}^{n}{n \choose k}{n \choose k-1} = {2n+2 \choose n+1}/2-{2n \choose n}$,I'm not sure where to start on this one. Would solving it via a combinatorial proof or induction be easier? $\sum_{k=1}^{n}{n \choose k}{n \choose k-1} = {2n+2 \choose n+1}/2-{2n \choose n}$,"['combinatorics', 'summation', 'binomial-coefficients']"
2032708,What is the m-th derivative of $f(x)=a_{n}x^{n}+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+\ldots+a_{2}x^{2}+a_{1}x+a_{0}$?,"Let there be an arbitrary polynomial of degree $n$: $$f(x)=a_{n}x^{n}+a_{n-1}x^{n-1}+a_{n-2}x^{n-2}+\ldots+a_{2}x^{2}+a_{1}x+a_{0}$$ where the $a_{i}$'s are constants. What would be the m-th derivative of f(x), i.e. $f^{(m)}(x)$? I figured out there would be 3 cases for $m$ and $n$. If $m=n$, then $$f^{(m)}(x)=n\cdot (n-1)\cdot (n-2)\cdot \ldots \cdot 1\cdot a_{n}\cdot x^{n-m}=n!\cdot a_{n}$$ If $m>n$, then $$f^{(m)}(x)=\frac{d^{m-n} \space f^{(n)}(x)}{dx^{m-n}}=\frac{d^{m-n} \space (n!\cdot a_{n})}{dx^{m-n}}=0$$ But what happens if $m<n$? I couldn't make any sense out of the expression I obtained. Any help would be appreciated. Thanks.","['derivatives', 'polynomials', 'calculus']"
2032724,Find $d/dx f(x)$ given that $d/dx [f(e^x )] = x$,"I was given this question as part of some coursework, and I came to an answer by:
Integrating to get $f(e^x) = 0.5*x^2 (+c)$; Replacing $x$ with $\ln(x)$ to get $f(x) = 0.5*(\ln(x))^2 (+c)$; Differentiating to get $d/dx f(x) = \ln(x)/x$. However, a friend interpreted the question as saying that if $d/dx f(x) = g(x)$, then $g(e^x)= x$. This leads to $d/dx f(x) = g(x) = \ln(x)$. Which is correct, or is the question too vaguely stated for a correct answer to be determined? Thanks in advance.","['calculus', 'functions']"
2032760,Solving this trigonometric summation: $\sum_{i=1}^{88}{\frac{1}{\cos i°\cdot cos(i+1)°}}$ [duplicate],This question already has an answer here : Find the sum : $\frac{1}{\cos0^\circ\cos1^\circ}+\frac{1}{\cos1^\circ \cos2^\circ} +\frac{1}{\cos2^\circ \cos3^\circ}+......+$ (1 answer) Closed 7 years ago . How would we solve this summation? $$\sum_{i=1}^{88}{\frac{1}{\cos i°\cdot \cos(i+1)°}}$$ I can't seem to make a start anywhere...,"['summation', 'trigonometry']"
2032836,Calculate $\int_{0}^\infty\frac{dx}{\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots}$,"I'm interested in the integral
$$
I=\int_{0}^\infty\frac{dx}{\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots}.\tag{1}
$$
So far I have been able to reduce this integral to an integral of an elementary function in the hope that it will be more tractable
$$
I=\frac{8\pi}{\sqrt{3}}\int_{-\infty}^\infty\frac{e^{ix\sqrt{3}}\ dx}{\left(e^x+e^{-x}+e^{ix\sqrt{3}}\right)^3},\tag{2}
$$
using the approach from this question . In that question it was also proved that
$$
\int_{-\infty}^\infty\frac{dx}{\left(e^x+e^{-x}+e^{ix\sqrt{3}}\right)^2}=\frac{1}{3},\tag{3}
$$
which gives some indication that the integral in the right hand side of $(2)$ might be calculable. Also note that the integrand in $(1)$ can be expressed as 
$$
\Gamma(x+1)\left|\Gamma\left(1+e^{\frac{2\pi i}{3}}x\right)\right|^2.
$$ Bending the contour of integration in the integral on the RHS of $(2)$ one obtains an alternative representation
$$
I=8\pi\int_0^\infty\frac{e^{x\sqrt{3}}~dx}{\left(2\cos x+e^{x\sqrt{3}}\right)^3}.\tag{4}
$$ There are some calculable integrals containing the infinite product $\prod\limits_{k=1}^\infty\left(1+\frac{x^3}{k^3}\right)$, e.g.
$$
\int_{0}^\infty\frac{\left(1-e^{\pi\sqrt{3}x}\cos\pi x\right)e^{-\frac{2\pi}{\sqrt{3}}x}\ dx}{x\left(1+\frac{x^3}{1^3}\right)\left(1+\frac{x^3}{2^3}\right)\left(1+\frac{x^3}{3^3}\right)\ldots}=0.
$$ Q: Is it possible to calculate $(1)$ in closed form?","['infinite-product', 'integration', 'definite-integrals', 'special-functions', 'gamma-function']"
2032959,Evaluate limit.,"Let $f : \mathbb R \to \mathbb R$ be differentiable at $x = a$. Evaluate: $$ \lim_{n\to \infty}\large[{f(a +\frac{1}{n^2})}+{f(a +\frac{2}{n^2})}+...+{f(a +\frac{n}{n^2})}-nf(a)] $$
  Answer: $\   $ $\ \frac{1}{2}f'(a)$ My attempt :
$$ \lim_{n\to \infty}\large[{f(a +\frac{1}{n^2})}-f(a)+{f(a +\frac{2}{n^2})}-f(a)+...+{f(a +\frac{n}{n^2})}- f(a)] $$
I don't know how to proceed from here? Please just give me hint. I want to solve this question by my self. Thank you.","['derivatives', 'real-analysis', 'continuity', 'limits']"
2032962,Statistic is not complete: uniform distribution,"How can one proove, that $X$, which is uniformly distributed on the interval $(\theta, \theta+1), \theta \in \mathbb{R}$ is not complete for $\theta$? I have to find a function, such that $E_{\theta}[h(T)] = 0$ where $h(t) \neq 0$ right? Does someone have an idea?","['uniform-distribution', 'probability-theory', 'probability', 'statistics']"
2032990,Is there a more efficient way of evaluating this limit?,"$$\lim_{x\to 0} \frac{\sin(x)-\arctan(x)}{x^2\ln(1+2x+x^2)}$$ This was a multiple choice question so it should not take me such a long time but the only way I see how to attack it is just L'Hôpital rule multiple times which is so inefficient as it keeps getting bigger and I'm more likely to make errors. The limit is $ \frac{1}{12} $ but I'm not sure how to show it. If there are any helpful tips on how to reduce the amount of calculation and make it simpler, it'd be appreciated.","['limits-without-lhopital', 'calculus', 'limits']"
2033032,What is the value of lim$_{n\to \infty} a_n$ if $\lim_{n \to \infty}\left|a_n+ 3\left(\frac{n-2}{n}\right)^n \right|^{\frac{1}{n}}=\frac{3}{5}$?,Let $\{a_n\}$ be a sequence of real numbers such that $$\lim_{n \to \infty}\left|a_n+ 3\left(\frac{n-2}{n}\right)^n \right|^{\frac{1}{n}}=\frac{3}{5}.$$ What is the value of $\lim_{n\to \infty} a_n$?,"['real-analysis', 'sequences-and-series', 'limits']"
2033048,Criterion on nefness of a divisor on algebraic surfaces,"Question 1: Let $X$ be a smooth rational surface with anti-canonical cycle, i.e, $-K_X$ is effective and its irreducible components form a polygon. Say, assume that $-K_X=\sum_\limits{i=1}^N D_i$ and $D_i^2=a_i$ (self intersection numbers).I wonder whether there exists a criterion for a divisor,say $N$ being nef on this surface. It seems that if I want to show that $-K_X$ is nef, It is enough to show that $-K_X.D_i=D_i^2+2\geq 0$, i.e:$a_i\geq -2$ for each $i$, I wonder whether there exists similar criterion for general divisor $D$ without computing intersection numbers for each irreducible curves on $X$ but with certain class(with finitely many members) of irreducible class of curves on $X$. The example I have in my mind is a toric surface $X$. Since all the divisors are linear equivalent to the boundary divisors, so one just need to verify the Criterion on boundary divisors. Note that $(X,-K_X=D)$ is called an anti canonical pair or Looijenga pair. It seems that there is a statement saying that any Looijenga pair has a toric model. I wonder whether we can obtain some ""convenient"" criterion from this connections. Question 2: Let $X$ be a rational surface with $K_X^2>0$, i.e $X$ is a rational surface with big anti canonical class. I wonder whether in this setting, we have ""convenient"" criterion for a divisor being nef. Note that one is able to show that $X$ is actually a Mori-dream space(they called rational Mori dream surface).And Mori-dream space is natural generalization of toric varieties. I wonder whether this helps to establish some convenient criterion. Question 3: Since those two type of surfaces are ""close"" to toric surface in some sense,I wonder whether algebraic geometry on them also have some ""combinatoric"" flavor using convex cones,dual cones,etc. Thanks","['toric-varieties', 'algebraic-geometry', 'birational-geometry']"
2033052,Proving a formula for the Krawtchuck polynomials and the Hamming distance on finite sets,"Let $Q$ be a finite set with $|Q| = q$. Let $n \in \mathbb N$ be fixed, and let $a, b \in Q^n$ two elements with $d(a, b) = k$, where $d$ is the Hamming distance, i.e. the number of $1 ≤ i ≤ n$ with $a_i ≠ b_i$. We then define the set: $$c_k(r, s) := \left| \left\{ c \in Q^n: d(a, c) = r \text{ and } d(b, c) = s\right\}\right|$$ I now want to show that: $$P_r(i) P_s(i) = \sum_{k=0}^n c_k(r, s) P_k(i)$$ where $P_r(i), P_s(i)$ are the Krawtchuck polynomials , i.e. $P_r(i) = \sum_{j=0}^r (-1)^j (q - 1)^{r-j} \pmatrix{i \\ j} \pmatrix{n - i \\ r - j}$. I must admit that I couldn't really get started so far. I've noticed that the set $c_k(r, s)$ is independent of the choice of $a, b$ as long as they satisfy the condition $d(a, b) = k$ (otherwise, it wouldn't make sense to not include $a, b$ as parameters for $c$). I don't really know though how I can get from the Krawtchuck polynomials to that formula. I know some basic properties of the Krawtchuck polynomials like their orthogonality relation(s): $\displaystyle \sum_{i=0}^n P_r(i) P_i(s) = q^n \delta_{r, s} \\ \sum_{i=0}^n \pmatrix{n \\ i} (q - 1)^i P_r(i) P_s(i) = q^n \pmatrix{n \\ r} (q - 1)^r \delta_{r, s} $ (where $\delta_{r, s}$ is the Kronecker-Delta, and where $q ≥ 2$). And I suspect that I somehow have to use them and utilize some smart properties or observations about these $c_k(r, s)$.","['abstract-algebra', 'coding-theory', 'combinatorics']"
2033066,n such that $|\sin (\sqrt{n+1})-\sin \sqrt n|< \lambda$,I broke $|\sin (\sqrt{n+1})-\sin \sqrt n|$ as $|2cos(\frac{\sqrt{n+1}+\sqrt n}{2})sin(\frac{\sqrt{n+1}-\sqrt n}{2})|$ .I am facing trouble in proving that it is less than some number for some n.Please help me in his regard.Thanks.,"['inequality', 'trigonometry']"
2033107,Problem with limit proof $lim(|x_n+y_n|-|x_n-y_n|)$,"I have:
$$\lim_{n\to \infty}(|x_n+y_n|-|x_n-y_n|)=+\infty$$
Need to prove:
$$\lim_{n\to \infty}|x_n|=\lim_{n\to \infty}|y_n|=\lim_{n\to \infty}x_ny_n=+\infty$$
I can prove $\lim_{n\to \infty}|x_n|=\lim_{n\to \infty}|y_n|=+\infty$ but I don't know what to do with other part. I can notice that $\lim_{n\to \infty}|x_n||y_n|=\lim_{n\to \infty}|y_nx_n|=+\infty$ but it's not what I exactly need because $\lim_{n\to \infty}|y_nx_n|=+\infty \Rightarrow \lim_{n\to \infty}y_nx_n=\infty $. Maybe there is some possibility to prove that $ x_n$ and $y_n$ have the same sign.",['limits']
2033127,Question about proof of existence of Laurent Series,"I'm reading a book that defines and proves that there exists a series with negative and positive terms inside a disk. I'll have to write a bunch of things because of the context, but the main question is easy, just look at the image... Now, the book says: Consider $f$ in the annulus $f:A(a,p_1,p_2)\to\mathbb{C}$, fix a point $z$ in $A(a,p_1,p_2)$ and let $r_1,r_2$ be two real numbers satisfying $p_1<r_1<|z|<r_2<p_2$. Look to the closed annulus $\overline{A}(a,r_1,r_2)$. Its boundary is formed by the circles $\gamma_1=\{|w-a|r_1\}$ and $\gamma_2=\{|w-a|=r_2\}$. Lets use the Cauchy Integral Formula to describe $f$ around $z$. Initially, observe that $g(w) = \frac{f(w)}{w-z}$ is holomorph in the ring $A(a,p_1,p_2)$ except in the point $z$. Therefore, we'll isolate $z$ considering the disk with it in the center, $D(z,\tau)$ such that $\overline{D}(z,\tau)\subset A(a,r_1,r_2)$ and the boundary is the circle $\gamma$, which we oriented counterwise. By the Cauchy Integral Formula we have: $$f(z) = \frac{1}{2i\pi}\int_{\lambda}\frac{f(w)}{w-z}\ dw$$ Consider now the region $V$ formed by the points interior to $\gamma_2$, exterior to $\gamma_1$ and $\lambda$. Its boundary $\partial V$ is formed by the three Jordan curves $\lambda, \gamma_1$ and $\gamma_2$. By considering the compatible orientation, we have: $\partial V = \gamma_1^{-}\cup \lambda^{-}\cup \gamma_2$. Since $g(w) = \frac{f(w)}{w-z}$ is holomorph in an open wich contains $V$ and $\partial V$, the Cauchy Theorem guarantees us that: $$0 = \int_{\partial V}g(w)\ dw = \int_{\partial V}\frac{f(w)}{w-z}\ dw$$ Is the integral above $0$ because I can integrate like in the image I drawn? If not, how should I break up the annulus in order for the integral to be $0$ and be represented as the sum of the integrals of each circle?","['laurent-series', 'complex-analysis', 'power-series']"
2033168,How to show that $\left|\sum_{k=0}^\infty\frac{(ix)^k}{(k+1)!}\right|\le \left|\sum_{k=0}^\infty\frac{(ix)^k}{k!}\right|=|e^{ix}|=1$ with restrictions,"How to show that $\left|\sum_{k=0}^\infty\frac{(ix)^k}{(k+1)!}\right|\le \left|\sum_{k=0}^\infty\frac{(ix)^k}{k!}\right|=|e^{ix}|=1$ with restrictions, for $x\in\Bbb R$. To prove this inequality we cant use any related to derivatives, integrals, geometric statements about sine or cosine, or uniform convergence. We can use limits and basic facts about the convergent properties of these power series. We already knows that $|e^{ix}|=1$ for $x\in\Bbb R$. The inequality is a slight rewrite of $$\frac{|e^{ix}-1|}{|x|}=\left|\sum_{k=0}^\infty\frac{(ix)^k}{(k+1)!}\right|\le 1,\quad\forall x\in\Bbb R$$ what need to be proved. I dont know exactly what to do here, Im completely lost. The best I can think is to prove something like $$\forall\epsilon>0,\exists N\in\Bbb N:\left|\sum_{k=0}^n\frac{(ix)^k}{(k+1)!}-L\right|<\epsilon,\quad\forall n\ge N$$ for some $0\le L<1$. The exercise leave the hint $\lim_{z\to 0}\frac{\exp(z)-1}{z}=1$ for $z\in\Bbb C\setminus\{0\}$, but I dont see how to relate this to our problem, because we need the result for any $x$, not just for $x=0$. Some hint or solution will be appreciated, thank you.","['power-series', 'convergence-divergence', 'analysis']"
2033178,The relationship between minimum of summation and the summation of minimum,"I would like to investigate the relationship between: $\min\{f(x) + g(x)\}$ and $\min\{f(x)\} + \min\{g(x)\}$ I think that it is fundamental and of course there exists a theorem or a lemma handling this relationship but I cannot find out. My try: I made a toy example:
$f(x) = x^2 - 2x - 3$ and $g(x) = x^2 + 2x -3$. Then  $\min\{f(x) + g(x)\} = -6$ and $\min\{f(x)\} + \min\{g(x)\} = -8$. It means that  $\min\{f(x) + g(x)\}\geq \min\{f(x)\} + \min\{g(x)\}$","['functional-analysis', 'complex-analysis', 'real-analysis']"
2033218,"This estimator, why is it good?","I've been given the following as an estimate for the parameter of a Poisson distribution, and must explain why it is a sensible estimate. $$\log\left(\frac1n \sum_{i=1}^n 2^{x_i} \right)               $$ I'm pretty confused because I've covered method of moments estimators and the MLE, but this looks like neither of those. Any advice as to what I'm missing would be much appreciated. Note: The log is the natural logarithm - they like to use that instead of ln for clarity and say that ln can easily confuse some expressions.","['statistics', 'parameter-estimation']"
2033223,"If $X_{1}, X_{2}, \ldots$ is an i.i.d. sequence, is the sequence of sup's independent?","Let $X_{1}, X_{2}, \ldots$ be a sequence of i.i.d. random variables. Let
\begin{align*}
Y_{n} = \sup_{k\leq n} X_{k}
\end{align*}
Is the sequence $\{Y_{n}\}_{n=1}^{\infty}$ a sequence of independent random variables? My intuition is no, but can anyone provide either a proof or counterexample?","['probability-theory', 'measure-theory']"
2033272,How to find a inverse of a multivariable function?,"I have a function $f:\mathbb{R}^{2} \rightarrow \mathbb{R}^{2}$ defined as: $$f(x,y) = (3x-y, x-5y)$$ I proved that it's a bijection, now I have to find the inverse function $f^{-1}$. Because $f$ is a bijection, it has a inverse and this is true: $$(f^{-1}\circ f)(x,y) = (x,y)$$ $$f^{-1}(3x-y,x-5) = (x,y)$$ I don't know where to go from here. In a one variable function I would do a substitution of the argument of $f^{-1}$ with a variable and express x with that variable, and then just switch places. I tried to do a substitution like this: $$3x-y = a$$
$$x-5y = b$$ And then express $x$ and $y$ by $a$ and $b$ , and get this: $$f^{-1}(x,y) = (\frac{15x-3y}{42}, \frac{x-3y}{14})$$ But I'm not sure if I'm allowed to swap $x$ for $a$, and $y$ for $b$. Any hint is highly appreciated.","['inverse-function', 'linear-algebra', 'functions']"
2033280,"Proving if function is decreasing or increasing, then function is one to one","My question reads: Prove that if the real-valued function $f$ is increasing (or decreasing), then f is one-to-one. Here is my proof: Let $f:\Bbb{R}\to\Bbb{R}$ be increasing (or decreasing) on $\Bbb{R}$ Let $x_1,x_2 \in \Bbb{R}$ s.t. $x_1<x_2$ Case 1 $f$ is increasing then $f(x_1)< f(x_2)$ $x_1< x_2$, so $x_1$ doesn't equal $x_2$, also $f(x_1)< f(x_2)$,  then $f(x_1)$ doesn't equal $f(x_2)$ since $x_1$ doesn't equal $x_2$. Thus $f$ is one to one. Case 2 $f$ is decreasing then $f(x_1) >f(x_2)$ $x_1< x_2$, so $x_1$ doesn't equal $x_2$, also $f(x_1) >f(x_2)$, then $f(x_1)$ doesn't equal $f(x_2)$ since $x_1$ doesn't equal $x_2$. Thus f is one to one.","['functions', 'proof-verification', 'proof-writing', 'elementary-set-theory', 'order-theory']"
2033306,k piles with $k(k+1)/2$ balls,"Given $\frac{k(k+1)}{2}$ balls arranged in $m$ piles. A player picks a ball from each pile and creates a new pile. As a result, piles with one ball disappear, and a new pile with $m$ balls is created. For example ($k=2$), if we sort the piles by their size:
$$(1,1,1)\rightarrow (3) \rightarrow (1,2) \rightarrow (1,2)$$ It is easy to see, that for any $k$:
$$(1,2,\dots,k)\rightarrow (1,2,\dots,k)$$ Let $(1,2,\dots,k)$ be denoted as the stationary state Show that no matter what is the initial configuration of piles, the piles configuration would converge to the stationary state .","['algebra-precalculus', 'puzzle']"
2033338,Complex exponential and the Cauchy problem $\begin{cases} f'=f\\ f(0)=1 \end{cases}$,"How do you prove that the exponential function is the unique solution to this Cauchy problem in $\mathbb{C}$? $$\begin{cases}
f'=f\\
f(0)=1
\end{cases}$$","['complex-analysis', 'ordinary-differential-equations']"
2033370,How to determine the number of coin tosses to identify one biased coin from another?,"If coin $X$ and coin $Y$ are biased, and have the probability of turning up heads at $p$ and $q$ respectively, then given one of these coins at random, how many times must coin A be flipped in order to identify whether we're dealing with coin $X$ or $Y$? We assume a 0.5 chance that we can get either coin.","['statistics', 'probability', 'statistical-inference']"
2033387,Closure of a function,"Consider a function $f: \mathbb{R}^n \rightarrow \left\{-\infty, + \infty \right\}$. The epigraph of the function is the subset of $\mathbb{R}^{n+1}$
given by $\operatorname{epi}(f) = \left\{(x,\mu): \, f(x) \le \mu \right\}$. Given a set $F$ of $\mathbb{R}^{n+1}$, one may define a function 
$\psi: \mathbb{R}^n \rightarrow \left\{-\infty, + \infty \right\}$, by 
$\psi(x) = \inf \left\{ \mu: \, (x,\mu) \in F \right\}$. Now, the way i understand it, in his book Convex Analysis, at page 52 Rockafellar defines the 
closure of $f$, to be the function $\psi$ corresponding to the 
closure of $\operatorname{epi}(f)$. Let us denote this function by 
$f_{cl}$. According to my understanding 
\begin{align}
f_{cl}(x) = \inf \left\{ \mu: \,x \in \bigcap_{\alpha> \mu} 
cl\left\{y: \, f(y) \le \alpha \right\} \right\}, \, \, \, (*)
\end{align} where 
$cl\left\{y: \, f(y) \le \alpha \right\}$ denotes the closure of the set
$\left\{y: \, f(y) \le \alpha \right\}$. However, Rockafellar says towards the bottom of page 52 that 
\begin{align}
f_{cl}(x) = \inf \left\{ \mu: \,x \in 
cl\left\{y: \, f(y) \le \mu \right\} \right\}, \, \, \, (**). 
\end{align} How do we see that the two values given in $(*)$ and $(**)$ coincide? One idea is to try and show that $\bigcap_{\alpha> \mu} 
cl\left\{y: \, f(y) \le \alpha \right\} =cl\left\{y: \, f(y) \le \mu \right\}$. It is clear that the RHS is inside the LHS, but i have trouble proving the other inclusion.","['general-topology', 'real-analysis', 'convex-analysis', 'analysis']"
2033435,Real matrices such that $A^2=-I_n$,"Find all $n\times n$ matrices with real entries such that $A^2=-I_n$. If $A$ is such a matrix, since $(\det A)^2 = (-1)^n$, $n$ must be even. Furthermore, $A$ annihilates $X^2+1 = (X-i)(X+i)$, so $A$ is diagonalizable over $\mathbb C$, with eigenvalues in $\{-i,i\}$. Let us write $A=PDP^{-1}$ where $D$ is a diagonal matrix with entries in $\{-i,i\}$ and $P$ is complex and non-singular. Since the trace of $A$ is real, there must be the same number of $i$ and $-i$ on $D$'s diagonal. Although interesting, this doesn't give a very explicit description of $A$. I'm not even sure any product $$P\begin{pmatrix}
i\\
&\!\!i\\
&&\ddots\\
&&&-i\\
&&&&-i
\end{pmatrix}P^{-1}$$ yields a matrix with real entries, that's why I think something much more specific can be said about $A$.","['matrices', 'matrix-equations', 'linear-algebra']"
2033443,Is this a valid transformation of a expression?,I need to check if this function is continuous: $$f(x)= \lim_{n\to\infty}\sqrt[n]{4+x^{6n}}$$ So I did this: $$f(x)= \lim_{n\to\infty}\sqrt[n]{4+x^{6n}} = \lim_{n\to\infty}(4+x^{6n})^{1/n} =\lim_{n\to\infty} \left(x^{6n}\cdot \left(\frac{4}{x^{6n}}+ 1 \right) \right)^{1/n}$$ $$f(x) = \lim_{n\to\infty}x^6 \cdot \left(\frac 4 {x^{6n}}+ 1\right)^{1/n} = x^6$$ Is this valid? Can I now just check the continuity of: $$f(x) = x^6$$,"['continuity', 'functions', 'limits']"
2033463,The number of solutions to $x^2-xy+y^2=n$ is finite and a multiple of 6.,"Let be $n$ a positive integer. Show that the number of integers solutions $(x,y)$ of the following equation $$x^2-xy+y^2=n$$ Is finite and multiple of 6. My approach: If $(x,y)$ is a integer solution of  $x^2-xy+y^2=n$ ,then also is $\{(-x,-y),(y-x,-x),(-y,x-y),(x-y,x),(y,y-x)\}$; But this solutions was find only by the simetry of equation. So, I can't ensure these solutions are all integers solutions for the problem. Can give me some hint. Thanks!",['number-theory']
2033467,Understanding Preimage,"$f: \mathbb{R} \to \mathbb{R}$ defined by $f(x) = x^2$.
The image of $\{−2, 3\}$ under $f$ is $f(\{−2, 3\}) = \{4, 9\}$, and the image of $f$ is $\mathbb{R}^+$. I understand up till here. I cannot understand this statement - ""The preimage of $\{4, 9\}$ under $f$ is $f^{−1}(\{4, 9\}) = \{−3, −2, 2, 3\}$."" Can someone please explain it to me?","['elementary-set-theory', 'functions']"
2033470,Uniqueness of multiplicative (and additive) inverses in $\Bbb Z_n$ (or any abelian monoid),"Assume that an integer $a$ has a multiplicative inverse modulo an integer $n$ . Prove that this inverse is unique modulo $n$ . I was given a hint that proving this Lemma: \begin{align}
n \mid ab \  \wedge \  \operatorname{gcd}\left(n,a\right) = 1
\qquad \Longrightarrow \qquad
n \mid b
\end{align} should help me in finding the answer. Here are my steps in trying to solve the problem: \begin{align}
\operatorname{gcd}\left(n,a\right) = 1
& \qquad \Longrightarrow \qquad
sn + ta = 1
\qquad \Longrightarrow \qquad
sn = 1 - ta \\
& \qquad \Longrightarrow \qquad
1 \equiv ta \mod n
\qquad \Longrightarrow \qquad
ta \equiv 1 \mod n .
\end{align} I know that having the GCD of m and a equal to 1 proves there is a multiplicative inverse mod n, but I'm not sure on how to prove $n \mid b$ with and how it helps prove the multiplicative inverse is unique.","['modular-arithmetic', 'gcd-and-lcm', 'proof-explanation', 'inverse', 'discrete-mathematics']"
2033506,A method for evaluating sums/discrete functions by assuming they can be made continuous and differentiable?,"Suppose I had a function that satisfied the property $f(x)=f(x-1)+g(x)$.  For any $x\in\mathbb N$, it is easy enough to see that this boils down to the statement $$f(x)=f(0)+\sum_{k=1}^xg(k)$$ If we return to our functional equation and differentiate it $n$ times, we get $$f^{(n)}(x)=f^{(n)}(x-1)+g^{(n)}(x)$$ Once again, for any $x\in\mathbb N$, we have $$f^{(n)}(x)=f^{(n)}(0)+\sum_{k=1}^xg^{(n)}(k)$$ One could then integrate both sides.  For example, this asserts that $$\sum_{k=1}^xg(k)=xf'(0)+\int_0^x\sum_{k=1}^tg'(k)dt$$ If the sum inside the intagral is generalized to any upper bound. How would I justify this for discrete functions? An example of this is letting $f_p(x)=\sum_{k=1}^xk^p$, as it seems to follow the above result.  We can see from the above that $$f_p(x)=a_px+p\int_0^xf_{p-1}(t)dt$$ $$a_p=1-p\int_0^1f_{p-1}(t)dt$$ which appears to be a true recursive formula. Under what conditions can I extend discrete functions $f(x)$ and $g(x)$ into continuous differentiable functions and apply this method?","['summation-method', 'real-analysis', 'summation', 'functions']"
2033521,Trivial question on radicals,"I saw the following equation : $$x^{2/3}$$ Instead of the correct expansion 
$$x^{2/3} = ( \sqrt[3]{x} ) ^ 2$$ I made the following mistake 
$$x^{2/3} = ( \sqrt[3]{x^2} ) $$ In order not to make the same mistake again I tried to formulate my mistake in terms of some rule but I do not really see what rule I trespassed. I would appreciate if could let me know. Edit : 
I see that in this particular case 
$$( \sqrt[3]{x} ) ^ 2 = ( \sqrt[3]{x^2} ) $$ but what if the equation was $$x^{2/4}$$ then $$( \sqrt[4]{x} ) ^ 2 \neq ( \sqrt[4]{x^2} ) $$ as two functions would have different domains. I know, I could simplify the 2/4 to 1/2 but for the sake of argument I choose not to and I am not aware of any rule that forces me to do the simplification.","['algebra-precalculus', 'radicals']"
2033566,Purpose of Inverse Functions,"Finding inverse functions and understanding their properties is fairly basic within mathematics. During my studies it was found fairly simple and easy to comprehend that it was a swapping of the outputs and inputs of a function. But now it has reappeared in calculus as finding the derivative of inverse functions and has me thinking  what is the actual real world application of inverses.Like how studying quadratics is extremely useful in modeling objects in free fall. I know my question may seem trivial to many here, i'm a high school student and we never get to have these discussions in class.",['algebra-precalculus']
2033582,"Proving that $G-\{x_1,x_2\}$ is connected if $G-v$ is $1$-connected and $x_1$ and $x_2$ belong to different blocks","I was reading the proof of Brook's Theorem in Bollobas'$\,$ $\textit{Modern Graph Theory}$ $\,$ book (pages 148-149) and there is one claim that Bollobas makes, but does not prove. Suppose that $G$ is $k$-regular with $k\geq 3$. Also suppose that $G$ is $2$-connected, but not $3$-connected. Then there exists a vertex $v$ such that $G-v$ is $1$-connected, and thus has at least two blocks, call them $B_1$ and $B_2$. Let $x_1$ and $x_2$ be vertices belonging to $B_1$ and $B_2$, respectively. Here is the claim: $G-\{x_1,x_2\}$ is connected. I have been trying to prove this claim in order to believe it! I believe that if you try assuming that $G-\{x_1,x_2\}$ is disconnected then you will end up contradicting that $G-v$ is $1$-connected. Somehow we could demonstrate that $v$ would be a cut vertex because there must not exist a path connecting $B_1$ and $B_2$, but there are details missing. If anyone sees a nice proof for this, I would love to see it and I would be very appreciative! Thank you :-)","['graph-connectivity', 'combinatorics', 'graph-theory', 'discrete-mathematics']"
2033602,How do you prove this very different method for evaluating $\sum_{k=1}^nk^p$,"I found the following formula in my previous question .  This differs from my previous question in that I want an alternative proof of the below recursive formula for calculating $\displaystyle\sum_{k=1}^nk^p$. Suppose I had a function recursively defined as $$f(x,p)=a_px+p\int_0^xf(t,p-1)dt$$ $$a_p=1-p\int_0^1f(t,p-1)dt$$ For $p\in\mathbb N$.  For $p=0$, we trivially get $f(x,0)=x$, which shall be our initial condition. It can then be noticed that $$a_1=1-\int_0^1tdt=\frac12$$ $$f(x,1)=\frac12x+\int_0^xtdt=\frac12x+\frac12x^2$$ $$a_2=1-2\int_0^1\frac12t+\frac12t^2dt=\frac16$$ $$f(x,2)=\frac16x+\int_0^x\frac12t+\frac12t^2dt=\frac16x+\frac14x^2+\frac16x^3$$ And the general pattern is $f(x,p)=\sum_{k=1}^xk^p$ whenever $x\in\mathbb N\quad(?)$ How do I prove that whenever $x\in\mathbb N$ $$f(x,p)=\sum_{k=1}^xk^p$$ without applying the methods mentioned in the link above?","['recurrence-relations', 'real-analysis', 'alternative-proof', 'definite-integrals', 'summation']"
2033639,Mod of numbers with large exponents [modular order reduction],"I've read about Fermat's little theorem and generally how congruence works. But I can't figure out how to work out these two: $13^{100} \bmod 7$ $7^{100} \bmod 13$ I've also heard of the Congruence Power Rule $$a \equiv b \,\Rightarrow\, a^k \equiv b^k \pmod n $$ But I don't see how exactly to use that here, because from $13^1 \bmod 7\,$ I get $6$ , and $13^2 \bmod 7$ is $1$ . I'm unclear as to which one to raise to the $k$ 'th power here (I'm assuming $k = 100$ ?) Any hints or pointers in the right direction would be great.","['discrete-mathematics', 'modular-arithmetic', 'elementary-number-theory']"
2033676,Smooth function $f\colon S^n\longrightarrow \mathbb{R}$ with $df_x=df_y=0$,"How can I prove that for any smooth function $f\colon S^n\longrightarrow \mathbb{R}$ always exist $x,y\in S^n$ such that $df_x=df_y=0$? I have tried it by induction, but I don't know to prove it even with $n=1$.",['differential-geometry']
2033712,Darboux coordinate for contact geometry,"I'm reading Geiges' notes. ( https://arxiv.org/pdf/math/0307242.pdf ) In the proof of Theorem 2.44 on page 17, the existence of the contact version Darboux coordinate is reduced to solving $H_t$ for each $t$, the PDE near the origin of $\mathbb{R}^{2n+1}$ 
$$\dot{\alpha}_t (R_{\alpha_t})+dH_t(R_{\alpha_t} )= 0$$
where $\alpha_t$ is a $1$-parameter family of contact forms and $R_{\alpha_t}$ is the corresponding reeb vector field. And he said that this equation always has a solution by integration if the neighborhood is small enough so that $R_{\alpha_t}$ has no closed orbit. My question is why this is obvious? What I know is that this equation is a quasilinear first order PDE and can possibly be solved by the method of characteristics. But I can't find a reference that contains a clear statement when this kind of equation can be solved. Thank you.","['contact-topology', 'differential-topology', 'partial-differential-equations', 'symplectic-geometry', 'ordinary-differential-equations']"
2033725,Is there a geometric reason for why every map has a divergence-free Jacobian cofactor matrix?,"$\newcommand{\Cof}{\text{Cof}}$ Consider the following claim: Let $f:\mathbb{R}^n  \to \mathbb{R}^n$ be a $C^2$ map. Then $$ \text{div} (\Cof df)=0, $$
  where $\Cof df$ is the cofactor matrix of $df$, and the divergence is taken row-by-row. In other words
  $$ \sum_{j=1}^n \frac{\partial(Cof(Du))_{kj}}{\partial x_j} = 0,$$ for every $1 \le k \le n$. This is proved in Evan's PDE book, in section 8.1 of the Calculus of Variation. This identity is ""universal"", that is, it is satisfied by any smooth (or $C^2$) map $\mathbb{R}^n \to \mathbb{R}^n$. I follow his proof, but is there an intuitive/geometric way to see why this should be true? I seems like an arbitrary identity - how would someone know this?","['euler-lagrange-equation', 'riemannian-geometry', 'partial-differential-equations', 'calculus-of-variations', 'differential-geometry']"
2033801,"Dropping the ""positive"" and ""decreasing"" conditions in the integral test","I know the Integral test is the following theorem: Assume $f$ is continuous, positive , and decreasing on [ $1, \infty$ ). If $\int_1 ^{\infty}f(x)\,dx$ exists and is finite, then $\sum f(n)$ converges and vice versa. I am searching for counterexamples to this test if: (i)
the condition positive is dropped; (ii) the condition decreasing is dropped.","['examples-counterexamples', 'improper-integrals', 'sequences-and-series', 'convergence-divergence']"
2033834,Line integrals with triangle vertices,"Evaluate the work integral where $F(x,y)=\langle-y,x\rangle$ over a triangle with vertices $A(-2,-2)$, $B(2,-2)$, $C(0,1)$. I am not sure how to approach this problem. 
I tried setting $AB(4,0)$, $BC(-2,3)$ and $CA(-2,-3)$ but I am not sure how to proceed. Without using Green's theorem","['multivariable-calculus', 'line-integrals']"
2033858,how to show that $e^{\pi z}-1 = \pi z e^{\frac{\pi z}{2}}\prod_1^{\infty}(1+\frac{z^2}{4n^2})$?,"how to show that $e^{\pi z}-1 = \pi z e^{\frac{\pi z}{2}}\prod_1^{\infty}(1+\frac{z^2}{4n^2})$? I would want to show that $F := \frac{e^{\pi z}-1}{\pi z e^{\frac{\pi z}{2}}}= \prod_1^{\infty}(1+\frac{z^2}{4n^2}) : = G$. Then I want to show that $\frac{F'}{F}= \frac{G'}{G}$, but I do not have any information on $\frac{G'}{G}$",['complex-analysis']
2033905,"You have N people and groups of K, what is the minimal number iterations of groups until everyone meets everybody?","For example, you have 30 people and groups of 5, what is the minimal number iterations of groups until everyone meets everybody? If you have 4 people (numbered 1-4) and groups of 2, then you need 3 iterations: iteration 1 groups: (1,2), (3,4)
iteration 2 groups: (1,3), (2,4)
iteration 3 groups: (1,4), (2,3) If you have 6 people and groups of 3, then you need 4 iterations, e.g.: iteration 1 groups: (1,2,3), (4,5,6)
iteration 2 groups: (1,4,5), (2,3,6)
iteration 3 groups: (1,6,3), (2,4,5)
iteration 4 groups: (3,4,1), (2,5,6) How to solve this for n=30 and k=5?  Is 10 iterations provably not sufficient for n=30 and k=5?  Would a greedy (non-exact) algorithm be a good approach?",['combinatorics']
2033968,Limits of a distribution property,"I've been cracking my brains since several days so far trying to solve this exercise. I'll firstly claim the problem and then will clarify what I know and what I've tried to do. So, we are given a real-valued r.v. on some probability space s.t. $\mathbb E(|X|)<\infty$ and by $F$ we denote the distribution function.
What we need to show is
$$\lim_{z \ \rightarrow \ - \ \infty}z F(z) = \lim_{z \ \rightarrow \ + \ \infty}z (1-F(z)) = 0$$ We know, that $\lim_{z \ \rightarrow \ - \ \infty}F(z) = 0$ and $\lim_{z \ \rightarrow \ + \ \infty}F(z) = 1$ and what I though of was to somehow show that the distribution function increases to $1$ faster than $z$ goes to infinity. Also, on this step we still don't know whether a density exists (it will be mentioned later in the exercise). I realize that the solution might be quite simple but I'm really stuck with it.
Any help would be highly appreciated.","['probability-theory', 'probability-distributions']"
2033987,The limit of $(1+\frac1x)^x$ as $x\to\infty$,"I was experimenting with a graphing calculator to check
$$\lim_{x\to\infty} (1+\frac1x)^x=e$$
I plotted the graph of $y=(1+\frac1x)^x$, and I was surprised when I zoomed out enough. It is oscillating until it reaches $x=9\times 10^{15}$, where $y$ becomes $1$ and stays there afterwards. How could we explain this?","['constants', 'limits']"
2033992,What conditions on a map of schemes guarantee that pullback of global sections is injective?,"Consider a morphism of schemes $f: X \rightarrow Y$. What conditions on $f, X, Y$ are sufficient to guarantee that $H^0(Y, \mathscr{F}) \rightarrow H^0(X, f^* \mathscr{F})$ is injective for All $\mathscr{O}_Y$ modules $\mathscr{F}$? All (quasi-)coherent $\mathscr{O}_Y$ modules $\mathscr{F}$? A necessary condition for the first and second questions is that $f$ is surjective on closed points, since if $y \in Y \setminus f(X)$ is closed, we can take $\mathscr{F} = i_* \mathscr{O}_{k(y)}$. Then for any $x \in X$, $(f^* \mathscr{F})_x \simeq \mathscr{F}_{f(x)} = 0$, so $f^* \mathscr{F} = 0$. But $H^0(Y, \mathscr{F}) = k(y) \neq 0$. In the case that $\mathscr{F}$ is a locally free sheaf, $f$ is quasi-compact and $Y$ is reduced, this condition is also sufficient (and in fact, we only need $f$ to be dominant). To see this, the map $H^0(Y, \mathscr{F}) \rightarrow H^0(X, f^* \mathscr{F})$ is the global part of the canonical map of sheaves $\mathscr{F} \rightarrow f_* f^* \mathscr{F}$. Let $U$ be an affine open set such that $\mathscr{F}|_U \simeq \mathscr{O}_U$. Then on $U$, the canonical map is identified with the structure map $\mathscr{O}_U \rightarrow f_* \mathscr{O}_{f^{-1}(U)}$, which is injective since $\mathscr{O}_Y \rightarrow f_* \mathscr{O}_X$ is injective under these hypotheses. Is this condition also sufficient for the first two questions? The affine version of the question is: Which extensions of rings $A \subseteq B$ have the property that for any (resp. any finitely presented) $A$-module $M$, the map $M \rightarrow M \otimes_A B$ is injective? Since this always holds when $M$ is flat (which implies locally free in the finitely presented case), it seems natural to guess that we should require $B$ to be faithfully flat over $A$. However, I cannot find a way to use this property or a counterexample when $\mathrm{Spec} \ B \rightarrow \mathrm{Spec} \ A$ is surjective but $B$ is not flat over $A$. EDIT I found a partial answer to this question in EGA IV-2 2.2.8: if $X, Y$ are arbitrary and $f$ is faithfully flat, then the canonical morphism is injective for all sheaves of quasi-coherent modules. This goes by identifying the global sections of $\mathscr{F}$ with morphisms $u: \mathscr{O}_Y \rightarrow \mathscr{F}$ and noting that the canonical map agrees with the map $u \rightarrow f^*(u)$. Faithful flatness says that if $f^*(u) = 0$ then $u = 0$. Actually, Remark 2.2.9 says that the $\mathscr{O}_Y$-module $\mathscr{F}$ does not need to be quasi-coherent for this proof to go through, although the proof is unclear to me. Also, Alex provided a counterexample in the case that $f$ is surjective but not flat. So now, the remaining question is: If $X$ and $Y$ are ""nice enough"", does $f$ really have to be flat? EDIT 2 Here is an easy counterexample when $X, Y$ are both smooth but not integral. Let $Y = \mathbf{A}^1$, $X = (\mathbf{A}^1 \setminus \{0\}) \sqcup \{0\}$, and $f$ the map given on rings by $k[x] \rightarrow k \times k[x,x^{-1}]$, $x \mapsto (0, x)$. Then let $\mathscr{F}$ be the coherent sheaf corresponding to the module $k[x]/x^2$. $f^* \mathscr{F} \simeq k$, since $(0,1) = x^2 * x^{-2}$ is killed. Then, $x$ maps to $0$ in the global section map.","['algebraic-geometry', 'commutative-algebra']"
2033993,Linearization of nonlinear system and the behavior of the linearized system,"Consider the nonlinear system: \begin{cases} x' = x^2 + y \\\\
y' = x - y + a \\\\
\end{cases}
where $ a $ is a parameter. $ a) $ Find all equilibrium points and compute the linearized equation at each. For this question I solve \begin{cases} x^2 + y = 0 \\\\
x - y + a = 0 \\\\
\end{cases} to give me $ \displaystyle  x = \frac{-1 \pm \sqrt{1 - 4a}}{2} $ and $ \displaystyle  y = \frac{-1 \pm \sqrt{1 - 4a}}{2} + a $ as equilibrium points. The linearized system I got is
\begin{cases} x' = y \\\\
y' = x - y \\\\
\end{cases} $ b) $ Describe the behavior of the linearized system at each equilibrium point? Can someone help me with this one? The linearized system doesn't depend on $ a $ and so why does it ask for the behavior at each equilibrium point?","['ordinary-differential-equations', 'nonlinear-system']"
2034050,Maximum number of aeroplanes landing at a single airport,I am new to Stackexchange so hope this problem is already known and a simple proof to the answer exists. Flatland is a plane extending infinitely in all directions. It has an infinite number of airfields no two of which are exactly the same distance apart. A training execise involves a single auroplane taking off from each airfield and flying to and landing at its nearest adjacent airport. What is the maximum number of aeroplanes that may land at any single airfield? I think the answer is 5 but have no definitive proof. Am I correct and is there a simple geometrical or trigonometrical proof please?,"['trigonometry', 'geometry']"
2034082,Step in proof of Ito isometry,"Question I am following the course advanced stochastic processes online but I'm struggling with an equality in the proof of Ito iseometry of theorem 1. On the third line of page 3 it is used that:
$$
\mathbb{E}[X_{t_j}^2 \mathbb{E}[(B_{t_{j+1}} - B_{t_j})^2 \mid \mathcal{F}_{t_j}]] = \mathbb{E}[X_{t_j}^2 (t_{j+1} -t_j)].
$$
where $X_t$ is a simple process and $(B_t)_t$ a Brownian motion, both adopted to the filtration $(\mathcal{F}_t)_t$. I'm pretty sure this step isn't very hard to show but I can't figure it out. Side Question I have a mathematical background and I'm looking at this theory to tackle inventory theory problems in a mathematical way, if you have some more interesting further references this could also be interesting. I'm thinking about Applied Probability and Queues","['stochastic-processes', 'probability-theory', 'stochastic-integrals']"
2034102,If $x + y + z = 0$ then $x\left(\frac1y+\frac1z\right)+y\left(\frac1z+\frac1x\right)+z\left(\frac1x+\frac1y\right) = -3$,"Im asked to prove given $x + y + z = 0$, that: 
$$x\left(\frac{1}{y}+\frac{1}{z}\right)+y\left(\frac{1}{z}+\frac{1}{x}\right)+z\left(\frac{1}{x}+\frac{1}{y}\right) = -3$$ Im stuck, I've tried to use that: $$x=-y-z$$ $$y=-x-z$$ $$z = -y-x$$
and trying to expand after that.
But I don't know if that is a good way of proving something like this?","['algebra-precalculus', 'symmetric-polynomials']"
2034108,A non-Vandermonde matrix with Vandermonde-like determinant?,"This question is related to the previous one . Consider $n$ variables $x_1,x_2,\ldots,x_n$ and the following $n\times n$ matrix: $$
A=\begin{bmatrix}
1 & \cdots &  1 \\ 
x_2 + x_3 + \dots + x_n & \dots &  x_1 + x_2 + \dots + x_{n-1} \\
x_2{x_3}  + x_2{x_4}+ \dots + x_{n-1}x_n & \dots &   x_1{x_2}  + x_1{x_3}+ \dots + x_{n-2}x_{n-1 } \\
\vdots & \dots & \vdots\\
x_2 x_3 \dots x_n & \dots &  x_1 x_2 \dots x_{n-1} \\
\end{bmatrix}.
$$ 
When $i>1$, the element $a_{ij}$ is the sum of all possible products of $i-1$ variables $x_k$'s with distinct indices, except that $x_j$ is not participating in any term on column $j$. Formally,
$$
a_{ij}=\sum_{k_1<\cdots<k_{i-1} \text{ and they are } \ne j} x_{k_1}x_{k_2}\cdots x_{k_{i-1}}.
$$ Of course, when some $x_i=x_j$, $A$ has two equal columns and it becomes singular, but is this the only possibility for $\det A=0$?","['matrices', 'symmetric-polynomials', 'linear-algebra', 'determinant']"
2034128,Group algebra is indecomposable for p-groups,"Let $k$ be a field of prime characteristic $p$, and let $G$ be a finite $p$-group. Show that the group algebra $k[G]$ is indecomposable as a $k[G]$ module, that is, if $V,W\subset $ are sub-left $k[G]$-modules, with 
  $k[G]=V\oplus W$, then either $k[G]=V$ or $k[G]=W$. Here are the only interesting things that I noted so far. If $\displaystyle t=\sum_{g\in G}g$, then $U=\{
\lambda t \ | \ \lambda\in k \}$, is a simple module of dimension 1 over $k$, thus it must be entirely contained in one of the two summands, say $V$. Then I notice that $W
\subset \{\sum_{g \in G} \lambda_{g}g \ | \ \sum\lambda_{g}=0 \}$. Also I see that $t^2=0$.","['representation-theory', 'group-theory']"
2034145,Prove almost sure convergence related to i.i.d random variables,"I have following question and stuck at the 1st one. $\left\{X_n\right\}$ are i.i.d. random variables with non-zero finite mean. Let $S_n=X_1+X_2+\dots+X_n$. Prove 1. $|X_n|/n \xrightarrow{a.s.}0$; 2. $(\max_{1\le k \le n}|X_k|)/n \xrightarrow{a.s.} 0$ 3. $(\max_{1\le k \le n}|X_k|)/(1+S_n) \xrightarrow{a.s.} 0$ I tried to use Borel-Cantelli lemma and Markov inequality, but failed. 1st Try: It's equivalent to show for any $\epsilon > 0$, we have $P(|X_n|/n > \epsilon \text{ i.o.})=0$ $$\sum_{n=1}^{\infty} P(|X_n|/n > \epsilon) \le \sum_{n=1}^{\infty}E[|X_n|]/n\epsilon=\infty$$
I figured it didn't work probably because i.i.d. condition was not used. 2nd Try : $$\begin{align}P(|X_n|/n > \epsilon \text{ i.o.}) &= \lim_{m \rightarrow \infty}P(\bigcup_{n=m}^\infty |X_n|/n > \epsilon) \\ &= \lim_{m \rightarrow \infty}1-P((\bigcup_{n=m}^\infty |X_n|/n > \epsilon)^c) \\ &=\lim_{m \rightarrow \infty}1-\prod_{n=m}^\infty P(|X_1|/n \le \epsilon)\end{align}$$ Stuck again.","['probability-theory', 'convergence-divergence']"
2034198,"$(1+2+3+....+n)+k= 2013$, find $n-k$","If for some natural number '$n$' ; $(1+2+3+..+n) + k = 2013$ where $k$ is
  one of the numbers $1,2,3,.....,n$, then find the value of $n-k$. This question seems to be based on hit and trial method since we only have one equation and two variables; I got the answer using hit and trial pretty quickly, but I am sure there has to be a better approach to this question. $$\frac{n(n+1)}{2}  + k = 2013$$ is the only equation I am able to develop and also using the fact that $k$ is less than or equal to n , I got that $n> 62$. Beyond this, I have no idea how to further proceed with this question. Help me out.","['sequences-and-series', 'elementary-number-theory']"
