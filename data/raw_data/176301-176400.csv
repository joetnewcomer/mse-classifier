question_id,title,body,tags
3164388,Why isn't the quotient space $X=\mathbb{R}^2/(\mathbb{R} \times \{0\})$ first-countable?,"Consider the quotient space $X=\mathbb{R}^2/(\mathbb{R} \times \{0\})$ I'm supposed to prove it isn't first countable. It seems to me that this space is homeomorphic to two open triangles joined at their apexes with that point added. That point is the problematic one, but why isn't the collection of open balls with descending rational radii centered at this point intersected with $X$ a countable basis? Thank you for your answers. Edit: I found this problem on my university's website. We did this same problem at school but first-countability was replaced with local compactness. It could be possible that the space is in fact first-countable, and the problem statement on the website was incorrect.",['general-topology']
3164391,Enigmatic patterns in Archimedean spirals,"Distributing the natural numbers as circles evenly along the Archimedean spiral yields surprising patterns when changing the radius of the circles: they cover more and more of the plane, finally covering it completely. But shortly before this happens, more or less obvious and intricate patterns shortly show up, and I'd like to understand them. The numbers are arranged by these formulas with $\hat k = \frac{\sqrt{k}}{2}$ $$x_\alpha(k) = -\hat k\cos(\alpha\cdot 2 \pi\cdot \hat k)$$ $$y_\alpha(k) = -\hat k\sin(\alpha\cdot 2 \pi\cdot \hat k)$$ – the distance between consecutive numbers along the spiral being controlled by the parameter $\alpha$ . This is how the number spirals look like for $\alpha = \frac{\sqrt{2}}{2}, 1, \sqrt{2}, 2,2 \sqrt{2},4, \ldots = \sqrt{2}^k$ : [Click image to enlarge.] When the radius of the circles is enlarged until they almost cover the plane, one observes different spot patterns: a spiral, a cross with $8$ -fold rotation symmetry, another cross with $4$ -fold rotation symmetry and a series of horizontal stripes. [Click image to enlarge.] When we compare $\alpha = 0.99, 1, 1.01$ we see that the straight cross for $\alpha = 1$ is the limit of two bundles of eight spirals running in opposite directions. [Click image to enlarge.] Here is my question: How can the cross with the 8-fold rotational symmetry (for $\alpha=1$ )
  be explained? (""For $\alpha=1$ there is a cross with a 8-fold
  rotational symmetry, because ...."") Note that for $\alpha=1$ the square numbers are aligned along the horizontal axis: One final remark: The observed patterns come as a surprise (somehow) because ""from the distance"" the spiral looks almost like a set of concentric circles thus having seemingly total rotational symmetry. But in fact the spiral has no rotational symmetry at all (only for 360°). And the ever changing patterns are due to this fact: the concentric circles do show only patterns reflecting the density of numbers along them. In this example the density is $10$ per $2\pi$ . Note how the triangle numbers (compared to the square numbers in the case of the spiral) are arranged along the horizontal line. Let $\triangle(k) = \frac{k(k+1)}{2}$ take the values $0,1,3,6,10,15,\dots$ We observe along the horizontal line $n(k) = 10\triangle(k) + 1$ (to the right) and $m(k) = n(k) + 5k$ (to the left): To see how the spiral patterns continue here for $\alpha = 4\sqrt{2}, 8, 8\sqrt{2}$ : There's a little Youtube video where you can see the number spiral continuously change for $\alpha$ going from 1 to 4.","['arithmetic', 'visualization', 'geometry']"
3164401,Universal property of blow up of complex analytic space,"I know that there is a universal property of blow-ups in the algebraic setting (see Wikipedia ). How does this translate to the case of complex geometry and holomorphic/bimeromorphic maps? 
I am particularly interested in the case of a blow up of a complex orbifold. A statement of the universal property together with a reference to the proof would be enough. But of course, I would prefer if you also write a (sketch of a) proof. Please note that I am not very familiar with algebraic geometry, so keep things simple and smooth.","['blowup', 'complex-geometry', 'reference-request', 'algebraic-geometry', 'differential-geometry']"
3164440,A heuristic argument for the Goldbach conjecture?,"This question here is purely speculative so be warned if you read on:
This question is related to a sequence $b_n$ which is defined here: A series related to prime numbers For the numbers $a_{2n,2}$ of ordered sums of writing $2n$ as a sum of two primes, we have: $$a_{2n,2} = \frac{1}{n-2} \sum_{v=0}^{2n-1} a_{v,2} \cdot b_{2n-1-v}$$ which using the conjecture $b_n / b_{n+1} \approx \gamma = -0.62923367 \cdots$ becomes: $$ \approx \frac{1}{n-2} \sum_{v=0}^{2n-1} a_{v,2} \gamma^v b_{2n-1}$$ We can divide this last sum into two parts: $$=\frac{b_{2n-1}}{n-2}(  \sum_{v=0,v \equiv 0 (2)}^{2n-1} a_{v,2} \gamma^v + \sum_{v=0,v\equiv 1 (2)}^{2n-1} a_{v,2} \gamma^v )$$ For the second sum observe, that $a_{v,2} = 2$ if and only if $v=p+2$ for some prime $p$ . Hence we get for the second sum, shoul be : $$\sum_{v=0,v\equiv 1 (2)}^{2n-1} a_{v,2} \gamma^v  = 2 \sum_{v=p+2, p \text{prime}}^{2n-1} \gamma^{p+2} $$ Since for large $n$ we have $2 f(t)\cdot t^2 \approx 2 \sum_{p<n, p \text{ prime }} t^{p+2}$ we get for the second sum ,since ( as remains to be shown) $f(\gamma)=0$ : $$ \approx 2 f(\gamma)\cdot \gamma^2 = 0$$ . The first sum is by induction on $n$ ( $a_{v,2} \ge 1$ for $v \equiv 0 (2), v < 2n-1$ ) not zero. Hence the whole sum should not be zero. One thing to observe for this argumentation is $b_{2n-1}$ seems to always be negative, so since this is only a heuristic, this should not be a problem. My questions is, if you can think of some way to make the steps above more rigorous, if this is not asked to much? Thanks for your help!","['number-theory', 'goldbachs-conjecture', 'prime-numbers']"
3164457,Evaluate limit of the series: $\lim_{n\to\infty} \left[\frac{1}{n^{2}} + \frac{2}{n^{2}} + \frac{3}{n^{2}} + \cdots + \frac{n}{n^{2}}\right]$,"I am pretty confident that the following limit is $0.5$ : $$\lim_{n\to\infty} \left[\frac{1}{n^{2}} + \frac{2}{n^{2}} + \frac{3}{n^{2}} + \cdots + \frac{n}{n^{2}}\right]=\lim_{n\to\infty} \left[\frac{1+2+3+ \cdots +n}{n^{2}}\right]=\lim_{n\to\infty} \left[\frac{n^2+n}{2n^{2}}\right]=\frac{1}{2}$$ However one of the students argued that if we write limit of sum as sum of individual limits, it will be zero. Why we cannot write limit of sum as sum of limits in this case? I've been taught that if individual limits exist, the limit of sum is equal to the sum of limits. It would be helpful to get an explanation or a reference to similar rules for limits of series.","['limits', 'sequences-and-series']"
3164463,"Euclidean sphere $\mathbb{S}^n$ immersed in Lorentzian sphere $\mathbb{S}^{(1,n+1)}$","Let $\mathbb{S}^n=\{x\in\mathbb{R}^{n+1}\mid \langle x,x\rangle_\text{euc}=1\}$ and $\mathbb{S}^{(1,n+1)}:=\{x\in \mathbb{R}^{(1,n+2)}\mid \langle x,x\rangle=1\}$ , where $(\mathbb{R}^{(1,n+2)},\langle\cdot,\cdot\rangle)$ is the Lorentzian space with $\langle\cdot,\cdot\rangle=-dx_1^2+dx_2^2+...+dx_{n+3}^2$ . Define: \begin{align*}
f: \mathbb{S}^n &\to \mathbb{S}^{(1,n+1)}\\
x &\mapsto (\psi(x),\psi(x),i(x))
\end{align*} where $\psi:\mathbb{S}^n\to\mathbb{R}$ is a smooth function and $i:\mathbb{S}^n\to \mathbb{R}^{n+1}$ is the natural embedding. Show that $f$ is an isometric immersion and compute its second fundamental form. I could easily show that $f$ is an isometric immersion by using the fact that $i$ is an immersion and by verifying that $f^*(-dx_1^2+dx_2^2+...+dx_{n+3}^2)=i^*(dx_1^2+...+dx_{n+1}^2)=g_{\mathbb{S}^n}$ . I had the following idea for computing the fundamental form, which I'm not sure is correct: If $\nabla, \nabla^\text{euc}$ are the Levi-Civita connections for $\mathbb{S}^n$ and $\mathbb{R}^{n+1}$ respectively, we can easily verify that $\nabla_XY(p)=\nabla^\text{euc}_xY(p)-\langle X,Y\rangle_\text{euc}p$ . Similarly, if $\widetilde{\nabla}$ , $\nabla^\text{lor}$ are the LC connections for $\mathbb{S}^{(1,n+1)}$ and $\mathbb{R}^{(1,n+2)}$ respectively, we find $\widetilde{\nabla}_XY(p)=\nabla^\text{lor}_XY(p)+\langle X,Y\rangle p$ . The second fundamental form $\alpha$ of $f$ would therefore be given by: \begin{align*}
\alpha(X,Y)(p)&=\widetilde{\nabla}_XY(p)-\nabla_XY(p)\\
&=\nabla^\text{euc}_XY(p)-\nabla^\text{lor}_XY(p)+(\langle X,Y\rangle+\langle X,Y\rangle_\text{euc})p\\
&=(\langle X,Y\rangle+\langle X,Y\rangle_\text{euc})p
\end{align*} Where in the last equality I tried to argue that, since Christoffel symbols vanish in Euclidean and Lorentzian spaces, then $\nabla^\text{euc}$ and $\nabla^\text{lor}$ look essentially the same. I know I've used some cheating and language abuse, but I hope this is essentialy correct, or at least restorable.","['proof-verification', 'riemannian-geometry', 'differential-geometry']"
3164543,Is the space of real sequences normable,"Intuition says the vector space of real sequences $R^N$ ( $N$ the natural numbers, pointwise addition of real coordinates) is not normable. I have found this surprisingly hard to prove. I am aware that $R^N$ in the product (Tychonoff) topology is not normable (but metrizable i.e. is a Frechet space). This is proven for instance in Aliprantis–Border: Infinite Dimensional Analysis (2006, p. 207), a reference which I found on Is a metrizable topological vector space normable? in the answer by @triple_sec which I understand and appreciate. However, this leaves open whether a TVS topology on $R^N$ stronger than the product topology could be normable. Here are my attempts to prove there is no norm defined everywhere on $R^N$ making it a TVS with topology at least as strong as the product topology i.e. with continuous coordinate functions. I aim for an indirect proof: assume there is a norm on $R^N$ and try to get a contradiction. a) Banach space arguments: complete the normed space and apply Banach space technology like Uniform Boundedness, Open Mapping etc.. I could not find any proof along this line. (In particular, I found it hard to control whether the completion of $R^N$ in the assumed norm would not make the original normed space ""bigger"" i.e. adding ideal points outside of $R^N$ ). But since experts in the field might well know a good argument, I mention the attempt. b) Geometric argument - construct a vector with an infinite norm: begin with the ""unit"" vectors $e_n = (0,..., 1, 0, ...) \in R^N, n\in N$ with a $1$ in the n-th coordinate and $0$ elsewhere. Rescale every $e_n$ to have the norm $||e_n||=1$ which is just a coordinate change. Now try $v=(1, 2, 3, ...) \in R^N$ to obtain a vector $v$ with norm $||v||\geq n$ $\forall n$ - are we done? I think no, because the norm $||v||$ of a vector $v=(p_1, p_2, p_3, ...)$ with non-negative real coordinates $p_i, i\in N$ is in general (unlike in the standard sequence spaces $l^p$ ) not a non-decreasing function of its real coordinates.
So I wonder how to argue strictly that $||v||\geq n$ $\forall n$ .
I tried flipping the signs of each coordinate i.e. consider $v=(\pm 1, \pm 2, \pm 3, ...)$ and use the fact that for arbitrary $v, x$ in a normed space one of $||v+x||$ and $||v-x||$ must be not smaller than $||v||$ and $||x||$ (triangle inequality). But to generate an optimal $v$ with maximal (infinite) norm $||v||$ I face (countably) infinitely many flips depending all on each other. I have no idea how to control (countably) infinitely many sign flips to make such an argument rigorous, but perhaps somebody else has. The idea seems to be included in the answer of @David C. Ullrich to Can the real vector space of all real sequences be normed so that it is complete ? . There is also an answer and a comment by @paul garrett which indicates what I am trying to prove here is an obvious matter of fact to the experts. However LF-spaces are currently too advanced for me, so I tried the same geometric argument one more time, but now ""weakly"": c) Geometric argument - construct a ""weakly unbounded"" vector: we start again with unit vectors $e_n, n\in N$ like in b), and take the dual sequence of linear functionals $p_n\in (R^N)^*, \forall n \in N$ projecting an arbitrary vector $v$ to its $n$ th coordinate. These coordinate functionals are continuous by assumption, and since $p_n(e_n)=1$ , the functional norm $||p_n||$ is $\geq 1$ . Now we consider the vector $v=(1||p_1||, 2||p_2||, 3||p_3||, ..., n||p_n||, ...)$ and estimate $||v||$ from below: $||v|| \geq |p_n(v)|/||p_n|| =n$ $\forall n \in N$ . My question: is the geometric argument in (c) good enough for a reasonable proof? Remark upon my original motivation: reading that a product of barreled spaces is barrelled - ""Un produit d'espaces tonnelés est tonnelé."" on the french https://fr.wikipedia.org/wiki/Espace_tonnel%C3%A9 (the fact is not yet on the english page https://en.wikipedia.org/wiki/Barrelled_space ) I tried to prove this. I looked at $R^N$ as one of the simplest non-trivial examples of a product of barrelled spaces: are in there any other barrels except closures of finite products of convex open balls=intervals (all remaining factors equal $R$ )? Answer: there are not. For the ingeneous Bourbaki this was so obvious to write in http://www.numdam.org/article/AIF_1950__2__5_0.pdf on page 6 mere one sentence: ""On montre sans peine que ... tout produit d'espaces tonnelés est tonnelé.""","['normed-spaces', 'topological-vector-spaces', 'functional-analysis']"
3164625,Validating a proof for necessary and sufficient conditions on sets A & B such that $P(A) \cup P(B) = P(A\cup B)$,"Is the solution correct for this? Problem: Find necessary and sufficient conditions on sets $A$ and $B$ such that the following relation holds among the power sets: $P(A)\cup P(B) = P(A\cup B)$ . Answer: Suppose first that $A\nsubseteq B$ and $B\nsubseteq A$ . Then there exists $a \in A \setminus B$ and $b \in B \setminus A$ . The subset, {a,b} of $A \cup B$ is not a subset of $A$ , nor is it a subset of $B$ . Thus, we do not have equality. Suppose that $A\subseteq B$ , then $A \cup B = B$ . So, $P(B) \subseteq P(A) \cup P(B)$ by the definition of power sets. Moreover, all subsets of $A$ are subset of $B$ , thus you arrive to $P(A) \cup P(B) = P(A \cup B)$ . It is the same if $B \subseteq A$ . Thus, the condition is that $A \subseteq B$ or $B\subseteq A.$","['elementary-set-theory', 'proof-verification', 'discrete-mathematics']"
3164631,Enumerate graphs with hexagonal faces,"How many are there non isotopic (in a sphere) embeddings of planar, simple, connected graph embeddings, which vertices are of degree at least two with $n$ vertices, such that all faces are hexagons (including external face)? A given graph and its mirror is counted as one. The number for $n=12$ is $12$ as shown in the figure:","['graph-theory', 'combinatorics']"
3164633,Find all real numbers satisfying the given equation.,"I came across a question which required solving two equations in real numbers $(x,y) $ .
The two equations were: \begin{align}
\log_3{x} +\log_2{y} &=2 \\
3^{x}-2^{y} &= 23
\end{align} Now, an obvious solution is $(3,2) $ . But I want to know that how do we actually solve such equations with both exponentials and logarithms simultaneously? I tried substituting the logarithmic terms but that gave me more complicated terms in the second equation which was hard to deal with. Please help.",['algebra-precalculus']
3164637,"Is the set of normal, positive, faithful, linear functionals on a W*-algebra open?","Let $\mathcal{A}$ be an infinite-dimensional W*-algebra, that is, an infinite-dimensional $C^{*}$ -algebra which is the Banach dual of a Banach space $\mathcal{A}_{*}$ (equivalently, $\mathcal{A}$ is an abstract von Neumann algebra). Consider the so-called normal positive, linear functionals on $\mathcal{A}$ .
According to the general theory of W*-algebras, these are all those positive linear functionals in the dual space $\mathcal{A}^{*}$ that are in the image $i(\mathcal{A}_{*})\subset\mathcal{A}^{*}$ of $\mathcal{A}_{*}$ in its bidual $(\mathcal{A}_{*})^{**}=\mathcal{A}^{*}$ . Now, consider the set $\mathcal{P}$ composed of all those normal,positive, linear functionals on $\mathcal{A}$ that are faithful (assuming, of course, that $\mathcal{A}$ admits normal, positive, linear functionals that are normal), that is, $\omega\in\mathcal{P}$ is such that $\omega(\mathbf{a}\mathbf{a}^{\dagger})=0$ for some $\mathbf{a}\in\mathcal{A}$ implies $\mathbf{a}=\mathbf{0}$ . Is the set $\mathcal{P}$ open in $\mathcal{A}^{*}$ and/or $\mathcal{A}_{*}$ ?","['c-star-algebras', 'functional-analysis']"
3164648,Existence of a particular inverse transformation,"Let $h : \mathbb{R}^D \rightarrow \mathbb{R}^d$ , where $d < D$ , be a differentiable function. I would like to find minimal conditions under which there exists a differentiable function $g : \mathbb{R}^{D} \rightarrow \mathbb{R}^{D-d}$ such that the function $f : \mathbb{R}^D \rightarrow \mathbb{R}^D$ defined by $f(x)=(h(x)^\top, g(x)^\top)^\top$ is invertible. If possible, I would also like to obtain a construction of this $g$ function. I hypothesize that the following conditions might be enough, but I am not sure: - $h$ is surjective. - $h$ cannot have the same value on a set with non-zero measure, that is, for every $y \in \mathbb{R}^{d}$ , the set $h^{-1}(\{y\})=\{x\in\mathbb{R}^D : h(x)=y\}$ has Lebesgue measure 0. The first condition is clearly necessary, and the reason why I believe that the second condition might be enough is the following: In order for $f$ to be invertible, $f^{-1}(\{z\})$ has to be a singleton for every $z \in \mathbb{R}^D$ . If $g$ was such that $g(x_1)\neq g(x_2)$ for every $x_1$ and $x_2$ such that $h(x_1)=h(x_2)$ , that would ensure that $f^{-1}(\{z\})$ is indeed a singleton for every $z \in \mathbb{R}^D$ . My intuition is that the second condition might ensure that such a $g$ function actually exists. Furthermore, if such a $g$ exists that also makes $f$ surjective, the result would follow. Any help would be very appreciated, either in proving my above conjecture, disproving it, or providing non trivial assumptions about $h$ that would result in the existence of $g$ . Thank you very much!","['differential-topology', 'lebesgue-measure', 'analysis', 'inverse-function']"
3164671,"Show that $A^{-1} + B^{-1}$ is invertible when $A,B$ and $A+B$ are invertible","I have the following issue: $A,B\in\mathbb C^{n\times n}$ invertible, such that also $A + B$ is invertible. How is it shown that $A^{-1} + B^{-1}$ is invertible?","['matrices', 'matrix-equations']"
3164739,When is a class function the character of a representation?,"The representations of a finite group can be understood by their irreducible characters. A class function is a function from the group to the complex numbers that is constant on the conjugacy classes. I know that any linear combination of the irreducible characters is the character of some representation. I also know that not all class functions are characters of a representation. Let's say that I don't know all the irreducible characters of a group, but I come across a class function whose inner product with itself is 1. My question is: How do I know whether this function is actually the character of an irreducible representation? More generally: How do I know whether a given class function is the character of some representation of a group without knowing all the irreducible representations? EDIT: I see this question with answers: Class function as a character . This almost answers my question. To clarify what I am specifically interested in knowing, if I have found some irreducible representations of a group $G$ . Say I have $\chi_1, \dots, \chi_m$ . I know I haven't found all of them because I know the number of conjugacy classes. Then, say, I some other non-irreducible character $\chi$ and I know, say, that this is the character of some representation. Then I subtract a linear combination of $\chi_1, \dots, \chi_m$ , and define the class function $\psi = \chi - (a_1\chi_1 + \dots + a_m\chi_m)$ . How do I know whether this $\psi$ is the character of some representation?","['representation-theory', 'group-theory', 'abstract-algebra', 'finite-groups']"
3164779,Prove that $AC \perp CE$.,"$MA$ , $MBC$ and $BD$ is respectively a tangent, a secant and a diamter of $(O)$ ( $MB < MC$ ). $MO$ intersects $AD$ at $E$ . Prove that $AC \perp CE$ . I am trying to prove that $\widehat{MAB} = \widehat{ECD}$ because $$\widehat{MAB} = \widehat{ACB} = 90^\circ - \widehat{DCA} = \widehat{ECD}$$","['euclidean-geometry', 'geometry']"
3164780,Sum of $2n$ numbers arbitrarily grouped into $2$ groups of $n$,"The first $2n$ natural numbers are arbitrarily divided into $2$ groups of $n$ each. The first group (named $a$ ) is arranged $a_1<\ldots<a_n$ . The second group ( $b$ ) is arranged $b_1>\ldots>b_n$ . Find, with proof, the sum $|a_1-b_1| + \ldots + |a_n-b_n|$ . Or more compactly $$\sum_{i=1}^n |a_i-b_i|$$ ( Guess: Arbitrarily means any possible group of $n$ numbers. The modulus can't be removed because any sum can be a negative number.) Some pattern (not sure how to create a table here) n=1, sum=1, n=2, sum=4, diff=3 n=3, sum=9, diff=5 n=4, sum=16, diff=7 n=5, sum=25, diff=9 I'm not a mathematician, and am just looking for some help about to start thinking on the problem. Don't solve it (but if it is solved anywhere I appreciate the link).","['summation', 'combinatorics', 'induction', 'discrete-mathematics']"
3164781,"Integer addition + constant, is it a group?","Assume we define an operator $$a\circ b = a+b+k, \\\forall a,b\in \mathbb Z$$ Can we prove that it together with range for $a,b$ is a group, for any given $k\in \mathbb Z$ ? I have tried, and found that it fulfills all group axioms, but I might have made a mistake? If it is a group, does it have a name? My observations: Closure is obvious as addition of integers is closed. Identity If we take $e=-k$ , then $a\circ e = a+k-k=a$ Verification $e\circ a = -k\circ a = -k+a+k=a$ , as required. Inverse would be $a^{-1} = -a-2k$ , which is unique. Verification of inverse $a\circ a^{-1} = a + (-a-2k)+k = -k = e$ , as required. Associativity $(a\circ b) \circ c = (a + (b+k)) + (c + k)$ . We see everything involved is addition, which is associative, so we can remove parentheses and change order as we wish.","['group-theory', 'abstract-algebra', 'arithmetic']"
3164819,simplicity of the Janko group $J_1$,"In the paper , Janko shows the simplicity of Janko group $J_1$ at the Lemma 2.1. In this proof it says ""By a transfer theorem all involutions are conjugate in $G$ "", but I cannot understand. Some propositions are named ""transfer theorem"", such as Burnside's transfer theorem, Thompson's transfer theorem, etc... . I want to know which proposition is used. I found an Additional description for the proof , but this part of proof is not correct (because the author uses the result of the Janko's paper, and the original proof doesn't use any specific calculations). I want to know theoretic approach of the problem.","['group-theory', 'simple-groups', 'finite-groups']"
3164890,How can we prove that any integral in the set of non-elementary integrals cannot be expressed in the form of elementary functions?,We know that the derivative of some non-elementary functions can be expressed in elementary functions. For example $ \frac{d}{dx} Si(x)= \frac{\sin(x)}{x} $ So similarly are there any non-elementary functions whose integrals can be expressed in elementary functions? If not then how can we prove that any integral in the set of non-elementary integrals cannot be expressed in the form of elementary functions?,"['integration', 'calculus']"
3165083,Given $\mathbb E(5X+2)=12$ and $\mathbb E(X|Y)=Y^3$ compute $\mathbb E(Y^3)$,"Given $\mathbb E(5X+2)=12$ and $\mathbb E(X|Y)=Y^3$ compute $\mathbb E(Y^3)$ . I've been trying this a million different ways and can't seem to reach a final answer, I would love any suggestions!","['conditional-probability', 'conditional-expectation', 'expected-value', 'probability-theory', 'probability']"
3165099,"If a,b,c are positive rational numbers such that a>b>c then tell which of the following statement are correct following quadratic equation","I am solving following question based on quadratic equation If $a,b,c$ are positive rational numbers such that $a>b>c$ and the quadratic equation $(a+b-2c)x^2+(b+c-2a)x+(c+a-2b)=0$ has a root in the interval $(-1,0)$ then which of the following statements are true ? $b+c>a$ $c+a<2b$ both roots of the given equation are rational the equation $ax^2+2bx+c=0$ has both negative real roots. My Approach First I calculated discriminant of the given quadratic equation which turns out to be $3(b-c)$ (This proves statement 3). So root 1 $r_1$ is $$r_1 = \frac{-b-c+2a+3b-3c}{2(a+b-2c)}=1$$ So root 2 will be $$\frac{c+a-2b}{a+b-2c}$$ As it is mentioned that one root will in $(-1,0) $ so $\frac{c+a-2b}{a+b-2c}$ will be that root.
So $$ -1<\frac{c+a-2b}{a+b-2c}<0 \\
-a-b+2c<c+a-2b<0 $$ Solving first half of the above inequality i.e. $c+a-2b<0$ will prove statement 2 to be true. Solving another half of the inequality i.e. $-a-b+2c < c+a-2b$ will prove statement 1 to false as our results are $b+c<2a$ . But I am not able to find the reasoning for fourth statement. My work for proving 4th statement to true: As $a,b,c$ are all positive and sum of the root for $ax^2+2bx+c$ is $\alpha+\beta=-2b/a$ . This proves that at least one of the root is negative. The product of the root is $\alpha\beta=c/a$ as $c/a$ is positive this states that both the roots are negative. if the discriminant of the $ax^2+2bx+c$ is > 0 only then this equation will have real roots.
How do I prove that the discriminant $D=b^2-4ac>0$ ?","['algebra-precalculus', 'quadratics', 'roots']"
3165146,Method to test if a number is a perfect power?,"Is there a general method for testing numbers to see if they are perfect $n$ th powers? For example, suppose that I did not know that $121$ was a perfect square.  A naive test in a code might be to see if $$\lfloor\sqrt{121}\rfloor=\sqrt{121}$$ But I imagine there are much more efficient ways of doing this (if I'm working with numbers with many digits).","['number-theory', 'perfect-powers']"
3165239,Integral Using Argument Principle,"I think I have the following problem solved, but I'm not completely sure my reasoning is sound: Let $n\in\mathbb{N}$ and let $C$ denote the unit circle with the counterclockwise orientation. Evaluate $$\frac{1}{2\pi i}\int_{C}\frac{z^{n-1}}{3z^{n}-1}~dz.$$ My attempt: We first recall the Argument Principle: Theorem. Let $G$ be a domain in $\mathbb{C}$ and let $\gamma$ be a simple contour whose interior is contained in $G$ . Let $f$ be a holomorphic function in $G$ without zeros on $\gamma$ , then the number of zeros of $f$ in the interior of $\gamma$ (taking into account multiplicities) is $$\frac{1}{2\pi i}\int_{\gamma}\frac{f'(z)}{f(z)}~dz.$$ In our case, we note that $$\frac{1}{2\pi i}\int_{C}\frac{z^{n-1}}{3z^{n}-1}~dz=\frac{1}{3n}\cdot\frac{1}{2\pi i}\int_{C}\frac{nz^{n-1}}{z^{n}-\frac{1}{3}}~dz.$$ Now, $g(z)=z^{n}-\frac{1}{3}$ is an entire function (since $n>0$ by assumption) and $g\not\equiv 0$ on the unit circle $C$ . Moreover, $g'(z)=nz^{n-1}$ , so it follows by the Argument Principle that \begin{equation}\frac{1}{2\pi i}\int_{C}\frac{nz^{n-1}}{z^{n}-\frac{1}{3}}~dz=\frac{1}{2\pi i}\int_{C}\frac{g'(z)}{g(z)}~dz\tag{*}\end{equation} is none other than the number of zeros of $g(z)=z^{n}-\frac{1}{3}$ in the interior of the unit circle. Counting multiplicities, there are $n$ zeros of $g$ in the interior of $C$ (namely the $n$ th roots of $\frac{1}{3}$ ), so we conclude that the quantity in (*) is exactly $n$ . Hence, $$\frac{1}{2\pi i}\int_{C}\frac{z^{n-1}}{3z^{n}-1}~dz=\frac{n}{3n}=\frac{1}{3}.$$ My questions: Does the above work look okay? I think it's right, but it felt like too simple of an argument (I know that the Argument Principle is a pretty useful tool, but still). Thank you in advance for any comments!","['complex-analysis', 'contour-integration', 'proof-verification', 'analysis']"
3165338,Evaluate $\sum_{k=0}^n {{2n + 1}\choose {2k + 1}}$,"Evaluate $$ \sum_{k=0}^n {{2n + 1}\choose {2k + 1}} $$ I'm really stuck on this one, no idea how to progress. My best guess is to somehow get it into the form of $ n\choose k $ and then take that summation and work with that. Or maybe binomial theorem, but I'm very experienced with that. If you could give a breakdown on how to tackle these problems that'd be great!","['summation', 'combinatorics', 'discrete-mathematics']"
3165353,Finding the expected value of $\sqrt{x^2 + y^2}$,"Below is a problem from the Schaum book on Probability and Statistics. I did part a right but my answer for part b is wrong. I am hoping somebody can
tell me where I went wrong.
Thanks, Bob Problem: Let $X$ and $Y$ have join density function: $$f(x,y) = \begin{cases}
cxy & \text{for } 0 < x < 1, 0 < y < 1\\
0 & otherwise \\
\end{cases} \\
$$ Find (a) $E(X^2 + Y^2)$ , (b) $E(\sqrt{X^2+Y^2})$ . Answer: (a) The first thing we need to do is find $c$ . \begin{align*}
\int_0^1 \int_0^1 cxy \, dy \, dx &= 1 \\
\int_0^1 \frac{cx}{2} \, dx &= 1 \\
\frac{c}{4} &= 1 \\
c &= 4 \\
E(X^2 + Y^2) &= \int_0^1 \int_0^1 4xy(x^2+y^2) \, dy \, dx \\
E(X^2 + Y^2) &= \int_0^1 \int_0^1 4x^3y + 4xy^3 \, dy \, dx \\
E(X^2 + Y^2) &= \int_0^1  2x^3y^2 + xy^4 \,\Big{|}_{y = 0}^{y=1} dx \\
E(X^2 + Y^2) &= \int_0^1 2x^3 + x \, dx = \frac{2x^4}{4} + \frac{x^2}{2} \Big{|}_0^1 = \frac{2}{4} + \frac{1}{2} \\
E(X^2 + Y^2) &= 1 \\
\end{align*} Part (b) \begin{align*}
E(\sqrt{X^2+Y^2}) &= \int_0^1 \int_0^1 4xy \sqrt{x^2+y^2} \, dy \, dx \\
\end{align*} Now we use the substitution $u_1 = x^2 + y^2$ with $du_1 = 2y_1 dy$ . \begin{align*}
E(\sqrt{X^2+Y^2}) &= \int_0^1 \int_{x^2}^{x^2+1} 2xu_1 \sqrt{u_1} \, du_1 \, dx =
	\int_0^1 \int_{x^2}^{x^2+1} 2xu_1^{\frac{3}{2}} \, du_1 \, dx \\
E(\sqrt{X^2+Y^2}) &=  \int_0^1 \frac{2xu_1^{ \frac{5}{2} }}{\frac{5}{2}} \Big{|}_{u_1 = x^2}^{u_1 = x^2 + 1} \, dx =
	 \int_0^1 \frac{4xu_1^{ \frac{5}{2} }}{5} \Big{|}_{u_1 = x^2}^{u_1 = x^2 + 1} \, dx \\
E(\sqrt{X^2+Y^2}) &= \int_0^1 \frac{4x(x^2+1)^\frac{5}{2}}{5} - \frac{4x(x^2)^\frac{5}{2}}{5} \, dx \\
\int_0^1 \frac{4x(x^2)^\frac{5}{2}}{5} \, dx  &= \int_0^1 \frac{4x^6}{5} \, dx = \frac{4x^7}{35} \Big|_0^1 \\
\int_0^1 \frac{4x(x^2)^\frac{5}{2}}{5} \, dx  &= \frac{4}{35} \\
\end{align*} Now we need to perform the following integration: $$ \int_0^1 \frac{4x(x^2+1)^\frac{5}{2}}{5} \, dx  $$ \newline
To perform this integration, we use the substitution $u_2 = x^2 + 1$ . \begin{align*}
\int_0^1 \frac{4x(x^2+1)^\frac{5}{2}}{5} \, dx  &= \int_1^2 \frac{ 2u^{\frac{5}{2} } }{5} \, du_2 \\
\int_0^1 \frac{4x(x^2+1)^\frac{5}{2}}{5} \, dx  &= \frac{2u^{ \frac{7}{2} }}{ \frac{5(7)} {2 }} \Big{|}_1^2 \\
\int_0^1 \frac{4x(x^2+1)^\frac{5}{2}}{5} \, dx  &= \frac{4u^{ \frac{7}{2} }}{ 35 } \Big{|}_1^2 \\
\int_0^1 \frac{4x(x^2+1)^\frac{5}{2}}{5} \, dx  &= \frac{4 (2^\frac{7}{2})}{35} - \frac{4}{35} \\
E(\sqrt{X^2+Y^2}) &= \frac{4 (2^\frac{7}{2})}{35} - \frac{4}{35} - \frac{4}{35} \\
E(\sqrt{X^2+Y^2}) &= \frac{ 32 \sqrt{2} - 8 }{35}  \\
E(\sqrt{X^2+Y^2}) &= \frac{8(4 \sqrt{2} - 1)}{35}  \\
\end{align*} However, the book's answer is: $$ \frac{8(2 \sqrt{2} - 1)} {15} $$","['integration', 'multivariable-calculus', 'probability']"
3165393,"Shortcut for value of $f(1)$ where $f(x) = \int e^x \left(\arctan x + \frac {2x}{(1+x^2)^2}\right)\,dx$","If $$f(x) = \int e^x \biggr(\arctan x + \frac {2x}{(1+x^2)^2}\biggr)\,dx$$ and $f(0)=0$ then value of $f(1)$ is? This is actually a Joint Entrance Examination question so I have to do it in two minutes. Is there a shortcut to finding this result quickly? It seems very complicated. The answer is $e(\pi/4-(1/2)). $","['integration', 'indefinite-integrals', 'calculus']"
3165395,The optimal way to concretize the opposite category of sets,"Let $\mathrm{Set}^{\mathrm{op}}$ be the category opposite to the category of sets. Does there exist a faithful functor $F:\mathrm{Set}^{\mathrm{op}}\rightarrow \mathrm{Set}$ such that $|F(X)|\leq |X|$ for all $X\in Obj(\mathrm{Set}^{\mathrm{op}})$ of infinite cardinality? I think the power set functor (with arrows going in the appropriate direction) gives an example of a faithful functor with $|F(X)|=2^{|X|}$ . If it matters, assume the axiom of choice is on.","['elementary-set-theory', 'category-theory']"
3165418,"$X$ is a random variable, if $\Bbb E(X^2)=1$ and $\Bbb E(X)\geq a>0$, prove that $\Bbb P(X\geq\lambda a)\geq(a-\lambda a)^2$ for $0\leq\lambda\leq 1$.","This is a problem in KaiLai Chung's A Course in Probability Theory . Given a nonnegative random variable $X$ defined on $\Omega$ , if $\mathbb{E}(X^2)=1$ and $\mathbb{E}(X)\geq a >0$ , prove that $$\mathbb{P}(X\geq \lambda a)\geq (a-\lambda a)^2$$ for $0\leq\lambda \leq 1$ . Let $A=\{x\in \Omega:X(x)\geq \lambda a\}$ , we get $$\int_A (X-\lambda a)\geq a-\int_A\lambda a -\int_{A^c}X$$ and $$\int_A (X^2-\lambda^2 a^2)=1-\int_A\lambda^2a^2-\int_{A^c}X^2$$ I want to contrast $\int_A (X-\lambda a)$ and $\int_A (X^2-\lambda^2 a^2)$ , but I don't know how to do it, could anyone gives me some hints?","['integration', 'lp-spaces', 'probability']"
3165528,Compute the probability that the outcome of a die's fifth throw is one of the previous 4,"A die is randomly rolled five times, the probability that outcome of
the fifth throw is one of the outcomes of the first 4 throws is? Attempt: For first 4, there are following possibilities:  (after that we will multilply the possibilities for the fifth one) All different 2 same 2 different 3 same 1 different All same $1.$ All different: Number of ways: $(6*5*4*3)\times\dbinom 41 = 1440$ $2$ . $2$ same, $2$ different: Number of ways: $\dfrac{4!}{2!}\dbinom 63 \times \dbinom 31 = 720$ $3$ . $3$ same, $1$ different: Number of ways: $\dfrac{4!}{3!}\dbinom 62 \times \dbinom 21 = 120$ $4$ . All same: Number of ways: $\dbinom 61 \times \dbinom 11 = 6$ Thus, $p(E) = \dfrac{@1+@2+@3+@4}{6^5} = \dfrac{381}{6^4}$ But answer given is: $\dfrac{671}{6^4}$ What's my mistake? Edit: Forgot to use: (as pointed out by @anryvian in comments) $5.$ 2 same, 2 same: Number of ways: $\dfrac{4!}{2!2!} \times \dbinom 6 2 \times 2 = 180$ Which gives the answer as: $\dfrac{411}{6^4}$ (still incorrect :( )",['probability']
3165531,Proving that level sets of a surface near local max/min are closed curves,"Let $S$ be a surface in $\mathbb{R}^3$ defined by the graph $z=f(x,y)$ of a smooth function $f: \mathbb{R}^2 \to \mathbb{R}$ . Suppose furthermore that $S$ satisfies the second-derivative test for a local max or min at a critical point $p^* = (x^*,y^*)$ ; i.e. the Hessian matrix $H(x,y)$ of $f$ satisfies det $(H)>0$ , and either $H_{xx}>0$ or $H_{xx}<0$ when evaluated at $p^*$ . I'm looking for a proof (or counterexample) of the following statement: Suppose $f(x^*,y^*)=c^*$ . Then horizontal slices $f(x,y) = c$ include
  closed curves for values of $c$ sufficiently close to $c^*$ on either the right or the left. This is obvious for elliptic paraboloids $f(x,y) = x^2/a^2+y^2/b^2$ . Otherwise we can Taylor expand around the critical point so that the nontrivial leading-order terms are quadratic in $x$ and $y$ , but it's not clear how to show that the intersections contain 'just slightly perturbed ellipses near $p^*$ ' in that case.","['multivariable-calculus', 'surfaces', 'differential-geometry']"
3165540,Comparing two Differential equations which have a same solution set.,"$$P(x)y''+Q(x)y'+R(x)y=0$$ $$P_1(x)y''+Q_1(x)y'+R_1(x)y=0$$ Suppose above two differential equations have a same solution set, then does it true that it must imply conditions $$P(x)=kP_1(x) , Q(x)=kQ_1(x) , R(x)=kR_1(x) \ \ \ \ \ \ \  \text{for some $k(x,y)$}$$ ?? ( $y''= \frac{d^2y}{dx^2} ,y'= \frac{dy}{dx}$ ) If this is true, then how can i prove this?",['ordinary-differential-equations']
3165546,Are all n-ary operators simply compositions of binary operators?,"Take for example $A \times B \cdot C$ = $(A \times B) \cdot C$ where $A, B, C$ are 3-component real vectors. We can define a 3-nary operator $\times - \cdot$ that is a composition of the two common binary operators $\times$ and $\cdot$. The same thing happens with most functions (operators) - the way we calculate them is by doing smaller binary problems and adding together. Every time I try to come up with an $(n > 2)$-ary operator my mind automatically looks for binary operators. So, the question is, do there exist operators (of some weird kind in some branch of math) that cannot be decomposed into 2-ary and 1-ary operators? Thanks.","['elementary-set-theory', 'logic']"
3165547,Every continuous function is uniformly continuous $\Rightarrow$ Lebesgue number exists for every open cover,"How to prove the following proposition? Let $(X, d)$ be a metric space, if for any metric space $(Y,\tilde{d})$ , any continuous map $f:(X,d)\rightarrow (Y,\tilde{d})$ is uniformly continuous then $(X,d)$ satisfies the following property: 
For any open cover of $X$ , there exist a real number $\delta >0$ , such that every subset of X having diameter less than $\delta$ is contained in some member of the cover. The property stated above comes from the well known Lebesgue number lemma(See James R. Munkres Topology second edition Lemma 7.5): If the metric space $(X,d)$ is compact and $\mathcal{A}$ is an open cover of $X$ , then there exists a number $\delta >0$ such that every subset of $X$ having diameter less than $\delta$ is contained in some member of $\mathcal{A}$ .","['general-topology', 'uniform-continuity', 'metric-spaces']"
3165559,"Let A = {1, 2, 3, 4, 5} How many onto functions f : A → A are there so that f ◦ f (1) = 2? Explain","This is a practice i was doing preparing for my quiz and i thought the answer would be 18 but the answer key states 1x4x3x2x1 or 24. I tried to understand why it would be 24 but i don't get it? I began by choosing a value for f(1) and i know because it is onto then 1 cannot be 1 or 2 because if f(1) =1 then f(f(1) cannot be 2 and similarily if f(1)=2 then f(f(1))=f(2)=2 and since it is a finite set in order for it to be onto it must also be one to one thus if f(1)=2 then two elements of the domain point to 2 which would be fine if for instance there were 6 elements in the domain. Is my logic flawed or am i missing something please let me know. Continuing to the other numbers i just would remove an options so f(2) cannot be 2 for the same reason above or the number picked for f(1), so 3 options there , and then down to 2 then 1 and 1. If anyone could explain this please, the answer key did not explain and it seems simple enough don't know why i'm stuck.","['functions', 'combinatorics', 'discrete-mathematics']"
3165573,"Number of words that can be made using all the letters of the word W, if Os as well as Is are separated is?",I am facing difficulty in solving the 18th Question from the above passage. Attempt: I have attempted it using principal of inclusion and exclusion. Let n be the required number of ways. $n = \text{Total number of ways - Number of ways in which Os and Is are together}$ $\implies n = \dfrac{12!}{3!2!2!} - \dfrac{11!}{2!3!} - \dfrac{10!}{2!2!}+ \dfrac{9!2!}{2!} = 399 \times 8!$ This gives $N = 399$ which is wrong. Can you please tell me why am I getting the  wrong answer?,"['permutations', 'combinations', 'combinatorics']"
3165650,Find the angle in an isosceles triangle,"Let triangle $\Delta ABC$ have $AB=AC$ . Then we draw the angle bisector from $B$ to $AC$ intersecting at $D$ . Find the angle $\angle BAC$ if $BC=AD+BD$ . My attempts: I know that the answer is 100° but I couldn't prove that if you extended $AD$ to a point $E$ so it is equal to $BC$ , then the angle $\angle DCE$ is the same as $\angle ACB$ .","['contest-math', 'euclidean-geometry', 'angle', 'geometry', 'triangles']"
3165878,Sum of Infinite series $\frac{1.3}{2}+\frac{3.5}{2^2}+\frac{5.7}{2^3}+\frac{7.9}{2^4}+......$,"Prove that the sum of the infinite series $\frac{1.3}{2}+\frac{3.5}{2^2}+\frac{5.7}{2^3}+\frac{7.9}{2^4}+......$ is 23. My approach 
I got the following term $S_n=\sum_1^\infty\frac{4n^2}{2^n}-\sum_1^\infty\frac{1}{2^n}$ . For $\sum_1^\infty\frac{1}{2^n}$ the answer is 1 as it forms a geometric series but I am bot able to find the solution to $\sum_1^\infty\frac{4n^2}{2^n}$ .",['sequences-and-series']
3165902,What does the shoelace formula mean for polygons with crossings?,"Given a simple polygon with vertices (in order) $v_1,v_2,\ldots,v_n$ , the area of this polygon can be computed based on only the coordinates of these vertices via the shoelace formula: $$A=\frac{1}{2}\left|\ \sum_{i=1}^{n-1} (x_iy_{i+1}-y_ix_{i+1}) + (x_{n}y_{1} - y_{n}x_{1})\ \right|,$$ where $v_i=(x_i,y_i)$ . We can still compute this value if we have a polygon that is formed by a single boundary (so no holes), but has multiple crossings. Does the value $A$ have a geometric meaning in this case? To motivate the problem, let me give an example. Take the following polygonal chain with vertices A-F: In this case, $A=15$ . If we sum up the areas of ABH, EFHG, and GCD, we get the same value. So, in this case the area in GHI is counted two times, and in the other parts of the polygon the area is counted once. So, it seems that $A$ is equal to the total area in the polygon, but certain regions are counted more than once, depending on the specific order of crossing. This leads to the following questions: Is it indeed true that $A$ is a weighted sum of the 'subareas' of the polygon, and how can we prove this? How can we determine the weights for each area?","['geometry', 'polygons']"
3165909,"Divisibility relations on $\Bbb N, \Bbb Z^*$, and properties thereof","I have two problems for which I need to find whether it is reflexive, irreflexive, symmetric, antisymmetric, or transitive. The relation $T$ on $\mathbb{N}$ as defined by $$aTb \iff a \mid b$$ The relation $U$ on the set $\mathbb{Z}^*$ is defined as $$aUb \iff a \mid b$$ For #1, the way I worked it out was: Reflexive: Yes, because $a  \mid  a$ for any positive integer $a$ Irreflexive: No, see above Symmetry: No, because $a \mid b$ does not necessarily mean $b \mid a$ example, $4 \mid 12$ but $12$ does not divide $4$ Antisymmetric: Yes, because if $a  \mid  b$ and $b \mid a$ then $a$ must equal $b$ Transitive: Yes, because if $a \mid b$ and $b \mid c$ then $a \mid c$ For question #2, however I am lost because the answer is reflexive and transitive. I get that it is reflexive and transitive and not symmetric for the same reasons as #1 but I don't understand why #2 is not antisymmetric but #1 is. I am guessing that it has something to do with #2 being a relation of $\mathbb{Z}^*$ , but that just means a non-zero integer. Can someone help me understand why #1 is antisymmetric and #2 isn't antisymmetric?","['relations', 'divisibility', 'discrete-mathematics']"
3165916,Show that $\lim_{n\to \infty} \int_E \cos^2(nx + a_n) dx = \frac{1}{2}m(E)$,"My task is basically to show that if $E$ is any measurable set in $\mathbb{R}$ , $m(E) < \infty$ and $\{a_n\}$ is any sequence of real numbers then $\lim_{n\to \infty} \int_E \cos^2(nx + a_n) dx = \frac{1}{2}m(E)$ Usually for such limits, my class has relied on the use of theorems such as monotone or dominated convergence, but the issue here is that $\lim_{n \to \infty} \cos^2(nx + a_n)$ does not converge. Does anyone have any hints for getting started?","['lebesgue-integral', 'real-analysis', 'calculus', 'trigonometry', 'convergence-divergence']"
3165944,Proving Girsanov Theorem,"There's a step I'm not following in the proof of Girsanov theorem. I've looked in ""Brownian Motion, Martingales, and Stochastic Calculus"" by Le Gall (Theorem 5.22) and in ""Foundations of Modern Probability"" by Kallenberg (Theorem 18.19) - and they both do pretty much the same thing. Reminder: Suppose $\Sigma=(\Sigma_t)_{t\ge 0}$ is a complete and right-continuous filtration,
  and $\mu\cong\nu$ are probability measures on $\Sigma_{\infty}$ . Denote $D_t:=\frac{d\nu}{d\mu}\big\vert_{\Sigma_t}$ .
  If $(M_t)_{t\ge 0}$ is a continuous local martingale under $\mu$ ,
  then $\hat{M}_t=M_t-[M,\mathcal{E}\left(D\right)]_t$ is a continuous local martingale under $\nu$ . Where I've denoted by $\mathcal{E}$ the stochastic exponentiation: $\mathcal{E}(X):=\exp\left(X_t-\frac{1}{2}[X_t]\right)$ ), and by $[X,Y]$ ""the bracket"" (=covariation, $\approx$ polarization of the quadratic variation). The step that eludes me is (I think) the claim - $$[M,D]_t=[\hat{M},D]_t$$ that I guess is equivalent to - $$\big[[M,\mathcal{E}(D)],D\big]_t=0$$ Why does it hold? Is it really just an immediate consequence of the construction - $$\left[(V\cdot M),N\right]_t=\left(V\cdot\left[M,N\right]\right)_t$$ and Ito's lemma (where $(V\cdot M)_t:=\int_0^tV_sdM_s$ )? How so?","['stochastic-analysis', 'stochastic-processes', 'probability-theory', 'stochastic-calculus']"
3166002,Communication on the boundary of a $C^1$ domain,"Assume $\Omega$ is a $C^1$ bounded domain of $\mathbb{R}^d$ , $d \geq 2$ . For $(x,y) \in (\partial \Omega)^2$ , we say $x \sim y$ if $n_x \cdot (y-x) > 0$ , $n_y \cdot (x-y) > 0$ , and $(tx+(1-t)y) \in \Omega$ for all $t \in (0,1)$ . Is it true that for any $(x,y) \in (\partial \Omega)^2$ such that $x \sim y$ , one can find $\epsilon_1 > 0, \epsilon_2 > 0$ such that $(B(x,\epsilon_1) \cap \partial \Omega) \sim (B(y,\epsilon_2) \cap \partial \Omega)$ (in the sense that for any $a \in (B(x,\epsilon_1) \cap \partial \Omega)$ , $b \in B(y,\epsilon_2) \cap \partial \Omega)$ , $a \sim b$ )? From the $C^1$ property of the domain it seems clear that for all $(x,y) \in \partial \Omega^2$ with $x \sim y$ , one can find $\epsilon > 0$ such that $x \sim B(y,\epsilon) \cap \partial \Omega$ (and I have a proof for it). However the stronger result that I ask, although I don't see any reason why this should not hold, puzzles me a lot more. Any idea whether the statement is true ? And how to show it ?","['analytic-geometry', 'analysis', 'differential-geometry']"
3166094,Right-sided derivative of $f(x)=\frac{\sin(\sqrt{x})}{\sqrt{x}}$,"Let define $f:\mathbb{R}\rightarrow\mathbb{R}$ such as $f(x)=\frac{\sin(\sqrt{x})}{\sqrt{x}}$ for $x>0$ and $f(x)=1$ for $x=0$ Prove that $f$ has right-sided all-order derivatives in $0$ . My approach: I find out that $f$ can be written as the power series $$
f(x)=\sum_{n=0}^{\infty}\frac{(-1)^k}{(2k+1)!}x^k
$$ which has an infinite radius of convergence so the $n$ -th derivative of $f$ in zero would be $$
f^{(n)}(0)=\frac{(-1)^n n!}{(2n+1)!}
$$ but I do not know how to connect these facts with the right-sided derivative of this function","['power-series', 'trigonometry', 'derivatives', 'real-analysis']"
3166134,Prove a sequence with bounded variation converges.,"A sequence is said to have bounded variation if: $$
\exists M \in\Bbb R: \sigma_n = |x_2 - x_1| + |x_3 - x_2| + \cdots + |x_{n+1} - x_n| \le M,\ \forall n\in\Bbb N
$$ Prove that boundedness of variation implies convergence of $\{x_n\}$ This question is based on my previous question here , where I needed to prove 'convergence implies boundedness of variation'. Now I want to do the opposite. First, note that $\sigma_n \ge 0,\ \forall n\in \Bbb N$ . The sequence is also convergent by monotone convergence theorem, because $\sigma_n$ is monotonically increasing: $$
\sigma_n \le M,\ \sigma_{n+1} \ge \sigma_n \implies \exists \lim_{n\to\infty}\sigma_n = L
$$ Then $\sigma_n$ satisfy Cauchy's criteria, thus we may fix any $p \in\Bbb N$ , such that: $$
\lim_{n\to\infty}(\sigma_{n+p} - \sigma_n) = 0
$$ Consider the difference: $$
\sigma_{n+p} - \sigma_n = \sum_{k=n+1}^{n+p}|x_k - x_{k-1}|
$$ Writing the limit for both sides: $$
\lim_{n\to\infty}(\sigma_{n+p} - \sigma_n) = \lim_{n\to\infty}\sum_{k=n+1}^{n+p}|x_k - x_{k-1}| = 0
$$ And that is only possible in case every term is the sum tends to 0 no matter what $p$ we choose, which means: $$
\exists \lim_{n\to\infty} |x_{n+p} - x_{n}| = 0
$$ Therefore $x_n$ is Cauchy, hence convergent. I would like to ask for verification of my proof. If the above is invalid, what would be a proper proof?","['limits', 'proof-verification', 'real-analysis']"
3166147,Proving that the composition of a harmonic function and a Cauchy-Riemann mapping is harmonic,"Let $\mathcal{O}$ be an open subset of the plane $\mathbb{R}^{2}$ and
  let the mapping $F : \mathcal{O} \rightarrow \mathbb{R}^{2}$ be
   represented by $F(x, y) = (u(x, y), v(x, y))$ for $(x, y)$ in $\mathcal{O}$ . Then, we say the mapping $F : \mathcal{O} \rightarrow
 \mathbb{R}^{2}$ is called a Cauchy-Riemann mapping provided that
   each of the functions $u : \mathcal{O} \rightarrow \mathbb{R}$ and $v
 : \mathcal{O} \rightarrow \mathbb{R}$ has continuous second-order
   partial derivatives and $$\frac{\partial u}{\partial x}(x, y) =
 \frac{\partial v}{\partial y}(x, y) \hspace{1em} \text{ and }
 \hspace{1em} \frac{\partial u}{\partial y} = -\frac{\partial
 v}{\partial x}(x, y)$$ for all $(x, y)$ in $\mathcal{O}$ . Prove that if $w : \mathbb{R}^{2} \rightarrow \mathbb{R}$ is harmonic and the mapping $F : \mathcal{O} \rightarrow \mathbb{R}^{2}$ is a Cauchy-Riemann mapping, then the function $w \circ F : \mathcal{O} \rightarrow \mathbb{R}$ is also harmonic. So I know that a function is harmonic provided that the sum of its second derivatives equals $0$ . This means we have $\nabla^2 w = 0$ . Also, we can write $F(x, y) = (u(x, y), v(x,y))$ . I don't really know how to prove this fact. We have the relations above in the definition of a Cauchy-Riemann mapping, but I'm not so sure about where to use them. I would appreciate some help.","['complex-analysis', 'multivariable-calculus', 'multivalued-functions', 'real-analysis']"
3166159,Find $f(x)$ if $f(x)+f\left(\frac{1-x}{x}\right)=1-x$,"If $f: \mathbb{R} \to\mathbb{R} $ , $x \ne 0,1$ Find all functions $f(x)$ such that $f(x)+f\left(\frac{1-x}{x}\right)=1-x$ My try: Letting $$g(x)=x+f(x)$$ we get $$g(x)+g\left(\frac{1-x}{x}\right)=\frac{1}{x}$$ Replacing $x \to 1-x$ , we get: $$g(1-x)+g\left(\frac{x}{1-x}\right)=\frac{1}{1-x}$$ any clue here?","['functional-equations', 'algebra-precalculus', 'functions']"
3166217,Multiplication Operator on $L^2$ is densely defined,"This is an exercise in Terence Tao's notes on spectral theory Let $(X, \mu)$ be a measure space with a countable generated $\sigma$ -algebra and $m: X \to \mathbb{R}$ a measurable function. Let $D$ be the space of all $f \in L^2(X)$ such that $mf \in L^2(X)$ . Show that the operator $L: D \to L^2$ defined by $Lf:= mf$ is a densely defined self-adjoint operator. The self-adjoint part is fine, and it is clear to me that if $m$ were bounded then I can just see that simple functions belong to $D$ making it densely defined. However, I feel like since $m$ is just measurable it's possible to make it very non-integrable on lots of sets so that $D$ might not be dense. Can anyone give me an idea for why $D$ must be a dense subset of $L^2$ ?","['integration', 'measure-theory', 'functional-analysis', 'real-analysis']"
3166301,Number of rational numbers in $A$,"Consider the set $A=\{\sqrt{2017+n^2}:n\in N\}$ . How many numbers in the set A are rational? My attempt: The square-root of a non-negative integer can either be a rational number or an irrational number. When it is a rational number it has to be an integer. It cannot be anything else (I do not exactly know why but my mind says so). So by this logic, if $\sqrt{2017+n^2},n\in N$ is a rational number , it has to be a positive integer. Therefore, $2017+n^2=k^2$ , for some $k\in N$ . Therefore, $2017=(k+n)(k-n)$ . Since $k,n\in N$ , and $2017$ is a prime number, $(k+n)=2017,(k-n)=1$ . This implies, $k=1009, n=1008$ . Since we got one value of $n$ , there is only one number is $A$ which is rational. Is my reasoning and my answer right? If not then what is the correct reasoning and answer and if yes then what is the justification of the line in bold?","['number-theory', 'prime-numbers']"
3166359,Circle inscribed in a semicircle,"There is black semicircle, which radius is $ R $ . The red circle is tangentially inward to the semicircle and to the diameter in its center. The yellow one is tangent externally to the red circle, internally to the semicircle and tangent to the diameter of the semicircle. My question is : What is the relationship between $R$ and the radius $r$ of yellow one? My attempts : I tried to use similarity of triangles, but always I had the third unknown number and two equations. I am sure that the radius of the red one is $ 0.5R$","['circles', 'geometry']"
3166405,Expected number of tries to choose x unique values,"it's been a long time since I've dealt with probability so I thought I would ask here. I'm sampling elements independently and uniformly and with repetition from a population. Given that the population is of size n, how many tries (in expectation) would it take me to gather x unique elements? Thank you :)","['expected-value', 'bootstrap-sampling', 'probability', 'sampling']"
3166422,$E_6$ and the lines on a cubic surface,"According to Wikipedia , in reference to the Lie algebra/group $E_6$ , Its fundamental representation is 27-dimensional (complex), and a basis is given by the 27 lines on a cubic surface. What is the meaning of this claim? Just a reference is fine.","['algebraic-geometry', 'lie-algebras', 'lie-groups', 'reference-request']"
3166442,Free throws in basketball game about probability [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 months ago . Improve this question Someone shoots free throws. He/She made the first one and missed the second one. From the third shot, the probability of hitting the ball equals to the free throw percentage he/she made before it. For example, if the made 87 out of 100 tries. Then the probability of making the next one is 87/100. What is the probability of the person making the n th? Does it matter whether he makes the n-1 th free throws?",['probability']
3166508,"Continuity of $f$ at $(0,0)$ determined by different limits","The function $f$ is defined as $$f(x, y) =\frac{x^2 y^2} {x^2 y^2 +|x-y|}$$ for $(x,y)\neq(0,0)$ and $0$ otherwise. We can clearly take two different paths $y=x$ and $y=-x$ which would give two different limits and thus $f$ is not continuous at $(0,0)$ .  How would introducing polar coordinates lead to such a result exactly?","['continuity', 'multivariable-calculus']"
3166557,Application of Lévy Zero-One Law,"Question Let $(X_n)$ be a sequence of random variables taking values in $[0, \infty)$ . Let $D=\{X_n=0\; \text{for some $n\geq 1$}\}$ and assume that $$
P(D\mid X_{1}, \dotsc, X_n)\geq \delta(x)>0
 \quad \text{a.s. on $\{X_n\leq x\}$}.\tag{0}$$ Use Lévy's Zero-One Law to conclude that $P(D\cup \{\lim_{n} X_n=\infty\})=1$ . My attempt Let $\mathcal{F}_n=\sigma(X_1, \dotsc, X_n)$ and $\mathcal{F}_{\infty}=\bigcup \mathcal{F}_n$ . Since $D\in \mathcal{F}_{\infty}$ , Lévy Zero-One Law implies that $$
P(D\mid \mathcal{F}_n)\to I(D)\tag{1}
$$ where $I$ is the indicator function. For $m\geq 1$ let $A_m$ be the set on which $X_n\leq m$ eventually. By $(0)$ and $(1)$ it follows that $I(D)=1$ on the set $\bigcup_{m=1}^\infty A_m=\{\limsup X_n<\infty\}$ i.e. $$
\bigcup_{m=1}^\infty A_m=\{\limsup X_n<\infty\}\subset D.
$$ Since $D\cup D^c\subset D\cup \{\limsup X_n=\infty\}$ , it follows that $P(D\cup \{\limsup X_n=\infty\})=1$ . My problem Assuming that everything above is correct, I have only been able to show that $P(D\cup \{\limsup X_n=\infty\})=1$ . But ostensibly this is not enough since $P(D\cup \{\lim_{n} X_n=\infty\})\leq P(D\cup \{\limsup X_n=\infty\})$ . Unless there is a typo in the question. But I got the question from Durrett.","['conditional-expectation', 'martingales', 'convergence-divergence', 'probability-theory', 'probability']"
3166607,"The map of graded rings $k[w, x, y, z] \rightarrow k[s, t]$ induces a closed embedding $\mathbb{P}_k^1 \rightarrow \mathbb{P}_k^3$","Show that the map of graded rings $k[w, x, y, z] \rightarrow k[s, t]$ given by $(w, x, y, z) \mapsto (s^3, s^2t, st^2, t^3)$ induces a closed embedding $\mathbb{P}_k^1 \rightarrow \mathbb{P}_k^3$ , which yields an isomorphism of $\mathbb{P}_k^1$ with the twisted cubic. I think I need to use the following exercise: If $S \rightarrow R$ is a surjection of graded rings, then the domain of the induced morphism is $Proj (R)$ , and the induced morphism $Proj (R) \rightarrow Proj (S)$ is a closed embedding. However, I don't see how the map $(w, x, y, z) \mapsto (s^3, s^2t, st^2, t^3)$ is surjective.","['projective-geometry', 'projective-schemes', 'algebraic-geometry', 'commutative-algebra', 'projective-space']"
3166621,"$X, Y$ are two complete vector fields with$[X, Y] = 0$, what is the resulting flow of $X+Y$?","If $X, Y$ are two complete vector fields with $[X, Y] = 0$ , what is the resulting flow of $X+Y$ ? I'm kind of confused on what the flow is. I know that the respective flows for $\Phi_t^X$ and $\Phi_t^Y$ commute, but what is the flow for the addition of two vector fields? Thank you.","['vector-fields', 'differential-geometry']"
3166644,When Does an Atlas Uniquely Define a Manifold?,"I am totally new to differential geometry and am having trouble understanding a very basic idea. In what follows, I apologize for being gratuitously pedantic, but I want to be sure I clearly understand what's going on. If $M$ is a set and $T$ is a topology on $M$ such that $(M,T)$ is Hausdorff and second countable, then $M$ is a topological manifold if for all $p\in M$ there exists an ordered pair $(U,x)$ such that $U \subset M$ is $T$ -open and $x:U\rightarrow \mathbb{R}^d$ is a homeomorphism whose image is an open subset of $\mathbb{R}^d$ in the standard topology. Ordered pairs $(U,x)$ that satisfy the conditions in the above paragraph are called charts on the manifold. An atlas for $M$ is a collection of charts on $M$ , $A = \{(U_a,x_a)\colon a \in I\}$ , such that $\cup_{\alpha\in I}U_a = M$ . Question 1: Does every manifold have at least one atlas? My answer: I believe so, since by the definition of a manifold there exists at least one chart for each point, and the collection of either all or at least one of the charts at each point can be taken as an atlas. Perhaps however there is some technical problem in set theory with this construction. Question 2: Does an atlas uniquely define a manifold? That is, if $A$ and $A'$ are atlases and $A \neq A'$ , is it necessary true that the manifolds with $(X,T)$ as their underlying space but with atlases $A$ and $A'$ respectively are different? (In the naive sense--not considering the possibility that they are diffeomorphic) I believe the core concept I'm struggling with here is what the naive notion of equivalence is for manifolds. (For example, for topological spaces ""naive equivalence"" means that the two underlying sets are equal and the two topologies have exactly the same open sets, rather than the existence of a homeomorphism, which is a more sophisticated notion of equivalence.) If instead we define a topological manifold as an ordered triple $(M,T,A)$ , where $A$ is an atlas, my confusion vanishes. But then naive equivalence requires exactly the same charts in the atlas, which might be too much to reasonably say that two manifolds are the same. I've also not seen this definition in any of the references I'm using. This brings up the following question. Question 3: Is it possible to define a manifold as an ordered triple, as in the paragraph above?","['manifolds', 'differential-topology', 'smooth-manifolds', 'differential-geometry']"
3166653,Equations of 1st order but not of 1st degree.,"Topic : equations solvable for p Q: $(1-y^2+\frac{y^4}{x^2})p^2-\frac{2y}{x}p+\frac{y^2}{x^2}=0$ There is no $\frac{dy}{dx}$ into the equation (if it was, then it has to be replaced by 'p') Now solving the quadratic equation in p Using quadratic formula $\frac{\frac{2y}{x}\pm\frac{4y^2}{x^2}-4(1-y^2+\frac{y^4}{x^2})\frac{y^2}{x^2})}{2(1-y^2+\frac{y^4}{x^2}}$ How to solve this further",['ordinary-differential-equations']
3166658,How would I convert this discrete math statement from logic/equation to English?,"Given that $B(x)$ means "" $x$ is a bear"", $F(x)$ means "" $x$ is a fish"", and $E(x,y)$ means "" $x$ eats $y$ "", what is the best English translation of $\forall x[F(x)\rightarrow \forall y(E(y,x)\rightarrow B(y))]$ ? How can I do solve this? I got ""Every fish is eaten by some bear"", but that is not the answer. I'm not entirely sure how to go about this since I am fairly new to Discrete Math. Any help is greatly appreciated.","['quantifiers', 'logic', 'discrete-mathematics', 'logic-translation']"
3166691,Path-continuity and the Axiom of Choice,"We tell the following to our Calc III students (usually for $\mathbf{R}^2$ , and never so formally): Let $A$ be an open subset of $\mathbf{R}^n$ , $a\in A$ , $f$ a real-valued function on $A$ and $\Gamma = \{\gamma \in A^{[0,1]} : \gamma(0) = a$ and $\gamma$ is continuous at $0\}$ .  If 𝑓∘𝛾 is continuous at $0$ for all $\gamma \in \Gamma$ , then $f$ is continuous at $a$ . We may generalize this: $A$ can be a first countable locally path-connected space, and the codomain may be any topological space.  See Continuity on paths implies continuity on space? . Here is my question: Does one need the Axiom of Choice (or at least countable choice) to prove this result? For example, the essentials of my proof of the (restricted) result is:  If $f$ is not continuous at $a$ , then there is a neighborhood $V$ of $f(a)$ such that $f^{-1}(V)$ is not a neighborhood of $a$ .  For each positive integer $n$ , choose a point in $ B(a,1/n)\backslash f^{-1}(V)$ and connect the points with a piecewise linear path. Thus, we are choosing countably many points. The proof at the link above also uses countable choice.","['path-connected', 'continuity', 'multivariable-calculus', 'axiom-of-choice', 'general-topology']"
3166705,Mean Value Inequality in Banach Space without Hahn-Banach or Integrals,"If $f : E \to F$ is a continuous map of Banach spaces, with bounded Fréchet derivative. Then $x_0,x_1 \in E\Rightarrow \|f(x_1) − f(x_0)\| ≤ M\|x_1 − x_0\|$ where $M = \sup \|f'(x)\|.$ The most efficient way to prove this, as far as I know, is to apply Hahn-Banach. Alternatively, one starts with $g(t)= f(x_0 + t(x_1 − x_0));\ 0\le t\le 1$ and reduces the problem to the real case. But, of course, the Hahn-Banach theorem is a (relatively) big gun, and to do the integral if one uses $g$ , then integration in Banach spaces must be dealt with (via regulated functions, for example.) The only elementary proof I have seen uses the dot product (Apostol, Rudin), but then of course, one must assume an inner product. Below I sketch a very basic proof, but it required more effort than I expected, so my question is: can one get it cheaper, using only elementary means (very basic facts about normed spaces and the definition of derivative)? Assume for convenience that $x_0=f(x_0)=0$ and consider the segment $\{tx_1:\ 0\le t\le 1\}.$ We have $\|f(x)\|\le M\|x\|+\|r(x)\|\cdot\|x\|$ where $\frac{\|r(x)\|}{\|x\|}\to 0$ as $x\to 0.$ So, if $\epsilon>0,$ we can choose $\delta>0$ such that $t\le \min \left(1,\frac{\delta}{\|x_1\|}\right)\Rightarrow \|f(tx_1)\| ≤ (M + \epsilon)t\|x_1\|$ . To prove the claim, it will suffice to prove that $t=1$ satisfies this last inequality, so to that end, let $\tau=\sup\{r>0:\|f(tx_1)\| ≤ (M + \epsilon)t\|x_1\|\text{for all}\ t\in [0,r]\}$ , so that $\tau\le 1$ and $\tau\in \{r>0:\|f(tx_1)\| ≤ (M + \epsilon)t\|x_1\|\text{for all}\ t\in [0,r]\}$ (because $f$ is continuous.) Now, toward a contradiction, suppose that $\tau<1$ and choose $c>0$ and small enough so that $(\tau+c)x_1$ is on the segment. Now, there is a $\delta' > 0$ such that $\|f(x) − f(\tau x_1)\| \le (M + \epsilon)||x − \tau x_1\|<\epsilon$ whenever $\|x − \tau x_1\| <\delta'.$ So, since $\|(\tau + c)x_1 − \tau x_1\| = c\|x_1\|<\delta' $ if $c$ is small enough, we have, with $x=(\tau + c)x_1$ , $\|f((\tau+c) x_1)-f(\tau x_1)\| \le (M+\epsilon)\|(\tau+c)x_1-\tau x_1\|=(M+\epsilon)\|cx_1\|$ and so finally, $f((\tau+c)x_1)\le (M+\epsilon)\|cx_1\|+\|f(\tau x_1)\|\le $ $(M+\epsilon)\|cx_1\|+ (M+\epsilon)\|\tau x_1\|=(M+\epsilon)(c+\tau)\|x_1\|$ , which contradicts the fact that $\tau$ is a supremum.","['banach-spaces', 'normed-spaces', 'real-analysis', 'frechet-derivative', 'functional-analysis']"
3166717,Find $\lim_{n \rightarrow\infty } P_n$whreas $P_n=\frac{2^3-1}{2^3+1}\cdot\frac{3^3-1}{3^3+1}\cdot\cdot\cdot\frac{n^3-1}{n^3+1}$.,"$\lim_{n \rightarrow\infty }  P_n$ whreas $P_n=\frac{2^3-1}{2^3+1}\cdot\frac{3^3-1}{3^3+1}\cdot\cdot\cdot\frac{n^3-1}{n^3+1}$ . This is a past problem of a high-school level math compettion. My tries: 1.Initially I thought of finding the product of the sequence.But then I realize there is no need of product coz' it'll make the function more complicated. 2.Then I tried to simplify first few terms so that may be in some way some of the middle terms may be cancelled out . So the product of first few terms look sth like this, $\frac{7}{9}\cdot\frac{26}{28}\cdot\frac{63}{65}\cdot\cdot\frac{n^3-1}{n^3+1}$ But I could'nt find any pattern in this.So how  the limit can be evaluated?","['limits', 'real-analysis']"
3166722,Proof of Cramér-Lundberg inequality,"I'm trying to prove the Cramér-Lundberg inequality, which deals with the probability of ruin for an insurance company given a certain initial capital. Specifically, if $Y_1, Y_2, \ldots$ are the differences between the premiums and payments of an insurance company at time $n$ , and $X_n = Y_1 + \cdots + Y_n$ is the total gain of the insurance company at time $n$ , and $k_0$ is the initial capital, then the probability of eventual ruin $p(k_0)$ satisfies the Cramér-Lundberg inequality: $$
p(k_0) := \mathbb P\left[ \inf\left\{ X_n + k_0 : n \in \mathbb N_0 \right\} < 0 \right] \leq \exp\left(\theta^* k_0\right)
$$ where $\theta^* < 0$ satisfies $\log\left( \mathbb E\left[ \exp(\theta^* Y_1 )\right]\right) = 0$ . My reference text proposes proving this in the following steps. Suppose $Y_1, Y_2, \ldots$ are i.i.d. integrable random variables that are not almost surely constant. Let $X_n = Y_1 + \cdots + Y_n$ , and suppose there is $\delta > 0$ so that $\mathbb E\left[\exp\left(\theta Y_1 \right)\right] < \infty$ for all $\theta \in (-\delta, \delta)$ . Define $\psi : (-\delta, \delta) \to \mathbb R$ by $$\psi(\theta) := \log \left(\mathbb E\left[\exp\left(\theta Y_1 \right)\right]\right)$$ and define the process $Z^\theta = \left(Z^\theta_n\right)_{n \geq 1}$ by $Z_n^\theta := \exp\left(\theta X_n - n\psi(\theta)\right)$ . We are suggested to show the following: $Z^\theta$ is a martingale for all $\theta \in (-\delta, \delta)$ . $\psi$ is strictly convex. $\mathbb E\left[\sqrt{Z_n^\theta}\right] \xrightarrow{n \to \infty} 0$ for $\theta \neq 0$ . $Z_n^\theta \xrightarrow{n \to \infty} 0$ almost surely. If $\mathbb E[Y_1] > 0$ and if $\psi(\theta) = 0$ has a nonzero solution $\theta^*$ , then $\theta^* < 0$ . Prove that if such a $\theta^* < 0$ exists, and if $\mathbb E[Y_1] > 0$ , then $p(k_0) \leq \exp\left(\theta^* k_0\right)$ . I've been able to show 1, 4 (from 3), and 5 (from 2). I'm close for 2 but having some trouble: we need to show $\psi(\lambda\theta + (1-\lambda)\phi) < \lambda \psi(\theta) + (1-\lambda)\psi(\phi)$ whenever $\theta \neq \phi$ and $\lambda \in (0,1)$ . Clearly we have $$\psi(\lambda\theta + (1-\lambda)\phi) = \log\mathbb E\left[ \exp\left(\lambda\theta Y_1 + (1-\lambda)\phi Y_1 \right)\right]$$ Meanwhile by Jensen's inequality and concavity of $x \mapsto x^\lambda$ for $0 < \lambda < 1$ , \begin{align*}
\lambda \psi(\theta) + (1-\lambda)\psi(\phi) &= \log \left( \mathbb E\left[\exp (\theta Y_1) \right]^\lambda\right) + \log\left(\mathbb E\left[ \exp(\phi Y_1)\right]^{1-\lambda}\right) \\
&\geq \log\left(\mathbb E\left[\exp\left(\lambda \theta Y_1\right)\right]\right) + \log\left(\mathbb E\left[\exp\left((1-\lambda)\phi Y_1\right)\right]\right) \\
&= \log\left(\mathbb E\left[\exp\left(\lambda \theta Y_1\right)\right]\mathbb E\left[\exp\left((1-\lambda)\phi Y_1\right)\right]\right).
\end{align*} If I could show $\mathbb E\left[\exp\left(\lambda \theta Y_1\right)\right]\mathbb E\left[\exp\left((1-\lambda)\phi Y_1\right)\right] \geq \mathbb E\left[\exp\left(\lambda \theta Y_1\right)\exp\left((1-\lambda)\phi Y_1\right)\right]$ ,that would solve this problem, but this is very far from obvious to me (especially since the integrands aren't independent). Then 3 and 6 I'm really stuck on. Any help on any of these three would be greatly appreciated. Note I would prefer not to use martingale convergence theorems because these results have yet to appear in my textbook; I can only work with square integrable martingales and stopping times.","['real-analysis', 'stochastic-processes', 'martingales', 'stopping-times', 'probability-theory']"
3166727,If $(a_n)\to A\neq 0$ and $(a_n b_n)\to AB$ then $(b_n)\to B$,"Let $(a_n)$ and $(b_n)$ be sequences. If $(a_n) \to A\neq 0$ and $(a_n b_n)\to AB$ then $(b_n)\to B$ I know that we need to show this for both $A > 0$ and $A < 0$ . But I am having problems using the assumptions to deduce that $$|b_n - B| < \epsilon$$ I know that since $<a_n>\to A$ then there exists an $N_1\in \mathbb{N}$ such that for all $n > N_1$ $$|a_n - A| < \epsilon$$ Similarly, since $<a_n b_n>\to AB$ then there exists an $N_2\in\mathbb{N}$ such that for all $n > N_2$ $$|a_n b_n - AB| < \epsilon$$ Any help would be appreciated. Background information: Theorem 8.7 - If the sequence $(a_n)$ converges to $A$ and the sequence $(b_n)$ converges to $B$ then the sequence $(a_n b _n)$ converges to $AB$ Lemma 8.1 - If $a_n\neq 0$ for all $n\in\mathbb{N}$ and if $(a_n)$ converges to $A\neq 0$ then the sequence $(1/a_n)$ converges to $1/A$ Attempted proof - Using these two theorems above we can write $(a_n b_n/a_n) = (b_n)$ which converges to $B$ . I don't think this is complete can someone help me add details?","['proof-writing', 'sequences-and-series', 'real-analysis']"
3166745,"A question about a lemma in Kenneth Kunen's article ""Some points in $\beta \mathbb{N}$.""","The article reference is: Kunen, K. (1976). Some points in βN. Mathematical Proceedings of the Cambridge Philosophical Society, 80(3), 385-398. doi:10.1017/S0305004100053032. I am stuck in lemma 5.2 which says: Let $\mathcal{U}$ be a selective ultrafilter and $(\mathcal{M}, v)$ a non-atomic measure algebra. Then, in $V^{\mathcal{M}}$ , there is  no $\mathcal{P}$ -point extending $\mathcal{U}$ . The proof goes like this: ""Define a finitely additive measure $\rho$ on $\mathcal{P}(\omega)$ in $V^{\mathcal{M}}$ as follows. If $[[x\subseteq \omega]]=1$ , define a measure $\sigma_x$ on $\mathcal{M}$ (in $\mathcal{V}$ ) by $\sigma_x(b)=\mathcal{U}- \lim (v([[n\in x]] \wedge b):n\in \omega)$ . $\sigma_x$ may be identified with an $\mathcal{M}$ -valued element of $[0,1]$ , which we call $\rho(x)$ .  "" (The following is the assertion which i'm troubling with:) ""Since $\mathcal{M}$ is non-atomic, $\rho$ is with value 1 non-atomic. "" Why is $\rho$ with value 1, non-atomic? Sorry if the question is too little elaborate, but is something very specific I need to understand. Thanks for the help!!","['boolean-algebra', 'proof-explanation', 'measure-theory', 'set-theory']"
3166772,"$M_n(R)/[M_n(R), M_n(R)] \cong R/[R,R]$","If $R$ is an associative ring then $[R,R]$ is the subgroup generated by the elements $[r,s]= rs-sr,$ for $r,s\in R$ .
Show that $Trace : M_n(R)\longrightarrow R/[R,R]$ induces an isomorphism $$ M_n(R)/[M_n(R),M_n(R)] \longrightarrow R/[R,R]$$ What I have tried so far is this:
I have a map $trace : M_n(R) \longrightarrow R$ the usual trace which is surjective
Then $j : R\longrightarrow R/[R,R]$ which is also surjective. So I have a surjection $Trace$ ( $(j\circ trace))$ form $ M_n(R)\longrightarrow R/[R,R]$ Now I need to show that Kernel(Trace) is my $[M_n(R),M_n(R)] $ Since $trace [AB-BA] \in [R,R]$ I have one way containment which is: $$ [M_n(R),M_n(R)] \subset Kernel(Trace)$$ I am having trouble in proving $$Kernel(Trace)\subset [M_n(R),M_n(R)]$$ What I mistakenly proved is that for any $r\in [R,R]$ there exists $A,B \in M_n(R)$ such that $trace(AB-BA) = r$ . Which doesn't help me. So if you guys could help me out I will be delighted. Thank you.","['abstract-algebra', 'linear-algebra', 'lie-algebras']"
3166866,Confidence interval probability,I am struggling to even understand how to approach this problem Finding the probability of $$P(Z<z_a+z_{1-a})$$ Where Z is a standard normal variable and $$P(Z\leq z_a)=1-a$$ Is there manipulation rules for adding arguments in a normal distribution? How do I even start with this?,"['statistical-inference', 'statistics', 'normal-distribution', 'probability-theory', 'probability']"
3166878,Find the least value of $ \sec^6 x +\csc^6 x + \sec^6 x\csc^6 x$,"Find the least value of $$ \sec^6 x +\csc^6 x + \sec^6 x\csc^6 x$$ I tried AM greater than equal to GM
But that's for finding maximum value.  This can probably be solved with calculus but I don't know for some reason I can't find the answer . Which is $80$ .","['maxima-minima', 'trigonometry']"
3166928,$xf(f(f(x)))=1$ continuous,Assume $f:\mathbb{R}_{>0}\to\mathbb{R}_{>0}$ is a continuous function such that $xf(f(f(x)))=1$ for all $x>0$ . I found that $f(x)=1/x$ is a solution. Could we find another such function? And why?,"['analysis', 'real-analysis']"
3166947,Transform $\prod_{k=0}^{n} (1+x^{2^{k}})$ to $\sum_{k=0}^{n} c_{k}x^{k}$,"I want to transform the following $$\prod_{k=0}^{n} (1+x^{2^{k}})$$ to the canonical form $\sum_{k=0}^{n} c_{k}x^{k}$ This is what I got so far \begin{align*}
\prod_{k=0}^{n} (1+x^{2^{k}})= \dfrac{x^{2^{n}}-1}{x-1} (x^{2^{n}}+1) \\
\end{align*} but I don't know how to continue, can someone help me with this?",['calculus']
3166969,Has $\ 2^{n-1}\equiv 2^{41}+1\mod n\ $ a solution?,"Has $$2^{n-1}\equiv 2^{41}+1\mod n$$ a solution with a positive integer $\ n>1\ $ ? Motivation : The equation $$2^{n-1}\equiv k\mod n$$ has always a solution, if $\ k-1\ $ has an odd prime factor (this odd prime factor is then a solution) and for $\ k=2^m+1\ $ , I know a solution for $$m=1,2,3,\cdots,40$$ Hence, this is the smallest number for which I know no solution. Upto $\ n=10^9\ $ , there is no solution.","['number-theory', 'modular-arithmetic', 'elementary-number-theory']"
3166977,Neighboring solids in tetrahedral-octahedral honeycomb,"In the tetrahedral-octahedral honeycomb , each vertex seems to be incident to 6 octahedra and 8 tetrahedra: Such simple combinatorial fact is probably well-known, or perhaps even obvious. However, coming from a different field, I struggle to justify it mathematically. I thought perhaps one can read this from the Schläfli symbols notation or the Coxeter diagram , but did not succeed at that. How would one go at arriving at this result if one does not want to use the rigorous method of counting colorful solids in a Wikipedia picture?","['polyhedra', 'tessellations', 'geometry', 'solid-geometry', 'tiling']"
3166991,Is there a way to put 5 points on the surface of the sphere so that they are indistinguishable?,"Is it possible to put 5 points on the surface of the sphere such that, for every pair of them, say A and B, there is an isometric transformation of the space such that A is mapped onto B, B is mapped onto A, and the convex cover of all 5 points is mapped onto itself, so is entire sphere, and the 5 points do not all lie in one plane ?",['geometry']
3167006,Monodromy when fiber is connected,"When I learned about monodromy, it was in the context of covering spaces. There, if $p$ is the covering map and $l$ is a loop with $\gamma(0)=\gamma(1)=x$ , then a $\bar \gamma$ lift of $\gamma$ is uniquely determined by $\bar \gamma (0)$ and the monodromy $m$ map is given by $m(\bar \gamma(0))=\bar \gamma(1)$ . The point is; the fact that the fibers of $p$ are discrete ensures that the lift is unique. So what happens in the case of a fiber bundle with connected fiber? Isn't it then impossible to talk about monodromy, because if the fiber of $p$ is (path-)connected, then for every $y$ in the fiber, there is a path $\sigma_y$ connecting $\bar \gamma(1)$ with $y$ . Hence for every $y$ in the fiber, the concatination $\sigma_y \cdot \bar\gamma$ is a lift of $\gamma$ with starting point $\bar \gamma (0)$ and endpoint $y$ . I wonder because I read about monodromy  of mapping tori  (see here for example) and I want to make sense of it.","['fiber-bundles', 'covering-spaces', 'differential-topology', 'algebraic-topology', 'differential-geometry']"
3167039,Is this Poincaré-type inequality valid?,"It is proved that the Poincaré inequality is still true for functions with zero mean boundary traces. Motivated by this, I have the following question: Let $\Omega$ be an open,bounded and connected subset of $\mathbb R^3$ with a $C^2-$ boundary $\partial \Omega \equiv \Gamma$ . If $f \in
 W^{1,2}(\Omega)$ then could we claim that: ${\vert \vert f - \frac{1}{\vert \Gamma \vert } \int_{\Gamma} {\vert f \vert}^{1/2}
 \vert \vert}_{L^2(\Omega)} \leq C {\vert \vert \nabla f \vert
 \vert}_{L^2(\Omega)}$ If for any $u\in \{ u\in H^1(\Omega): \frac{1}{\vert \Gamma \vert } \int_{\Gamma} u=0 \}$ we have the estimate: ${\vert \vert u \vert \vert}_{L^2(\Omega)} \leq C {\vert \vert \nabla u \vert\vert}_{L^2(\Omega)}$ then it seems logical to me that the above claim could be true. However I wasn't able to prove it (if indeed can be proved) so any help is much appreciated. Thanks in advance!","['inequality', 'sobolev-spaces', 'functional-analysis', 'partial-differential-equations']"
3167051,"If a polynomial function has an axis of symmetry at $x = c$, is it true that c is equal to the average of the roots?","I was trying to learn more about cool substitutions to make my life easier when solving polynomial equations. For example, in the problem $$x(x+1)(x+2)(x+3) = 24,$$ the LHS is symmetric at $x = -\frac{3}{2}$ , which is the average of the zeroes, so we can do the substitution $$u = x - (-\frac{3}{2})$$ and it would be easier to solve it that way. I tried more examples like $$y = (x-5)(x-3)(x+5)(x+3)$$ and lo and behold, it is symmetric at $x = 0$ . Not every polynomial function has an axis of symmetry but if they do, is it always at $$x = \text{(avg. of roots)}?$$","['algebra-precalculus', 'functions', 'polynomials', 'symmetry']"
3167065,"Bijection between $ \bigcup_{i \in [0, 1]} X_i \ \ \ \text{and} \ \ \ [0, 1] \times [0, 1] $","So I have got the following sets $$ \bigcup_{i \in [0, 1]} X_i \ \ \ \text{and} \ \ \ [0, 1] \times [0, 1] $$ where each $X_i$ has cardinality $c$ of the continuum and each pair of $X_i$ where $i \in [0, 1]$ is disjoint. I am basically trying to show that such a union of sets with cardinality $c$ has cardinality $c$ . I have separately been able to prove that the cardinality of $[0, 1] \times [0, 1]$ is $c$ and just need this bijection to arrive at the result. Is there such a bijection and if so, what is it?","['elementary-set-theory', 'proof-writing', 'proof-verification', 'cardinals']"
3167078,multivariable calculus - Proving that this limit exists with polar coordinates,"I have the following limit: $\lim \limits_{(x, y) \to (0,0)} \cfrac{x^2y^2}{x^2+y^4}$ According to my book the limit is supposed to exist and be equal to 0, but I'm not sure what I'm doing wrong. First, I try to approach it from two different directions, I'll skip this and say that I tried 3 different directions and got 0 everytime. Now onto polar coordinates: $\lim \limits_{\rho \to 0} \cfrac{\rho cos^2 \theta \rho^2sin^2\theta}{\rho^2cos^2\theta+\rho^4sin^4\theta} = \lim \limits_{\rho \to 0} \cfrac{\rho^4cos^2\theta sin^2\theta}{\rho^2(cos^2\theta+\rho^2sin^4\theta)}$ Simplifying the above expression: $\lim \limits_{\rho \to 0} \cfrac{\rho^2cos^2\theta sin^2\theta}{cos^2\theta+r^2sin^4\theta}$ Now, when $\rho \to 0$ the above function is dependant on theta, and even though the numerator tends to $0$ there's the chance of $\theta = k\pi-\cfrac{\pi}{2}$ meaning that we'd end up with $cos^2\theta = 0$ therefor we'd be in a $0/0$ situation. Because of that, the above limit is dependant on $\theta$ and not $\rho$ , and that means that the function will assume different values on different directions, meaning that the limit does not exist, but according to my textbook the limit is 0. I really can't understand what I'm doing wrong.","['limits', 'calculus']"
3167104,How can I express $3 \cdot 7 \cdot 11 \cdots (4n+3)$ in terms of factorial?,This is the work I have done so far: $\prod_{k=0}^n(4k+3) = \frac{(4n)!}{2^n(2n)!}\cdot\prod_{k=0}^n\frac{1}{4k+1}$ . I would really appreciate a clever trick how to reduce the latter product that involves $\frac{1}{4k+1}$ ;),"['infinite-product', 'discrete-mathematics', 'products']"
3167180,Evaluating $\int^{\infty}_{0}\frac{\cos x}{(x^2+1)^2}dx$,Finding value of $\displaystyle \int^{\infty}_{0}\frac{x\sin x}{(x^2+1)^3}dx$ Let $$ I = \frac{1}{2}\int^{\infty}_{0}\sin x\frac{2x}{(x^2+1)^3}dx$$ Integrating by parts $$ \Rightarrow I = -\frac{\sin x}{(x^2+1)^2}\bigg|^{\infty}_{0}+\int^{\infty}_{0}\frac{\cos x}{(x^2+1)^2}dx=\int^{\infty}_{0}\frac{\cos x}{(x^2+1)^2}dx$$ How do i solve it?,"['integration', 'trigonometry', 'definite-integrals']"
3167208,$a_n > 0$ and $\sum_\limits{n=1}^{+\infty} \frac{1}{a_n}$ converges. Prove $\sum_\limits{n=1}^{+\infty} \frac{n}{a_1 + \cdots + a_n}$ is convergent. [duplicate],"This question already has answers here : If $\sum_{n=1}^\infty \frac{1}{a_n}$ converges, must $\sum_{n=1}^\infty \frac{n}{a_1 + \dots + a_n}$ converge? (3 answers) Closed 5 years ago . $a_n > 0$ and $\sum_\limits{n=1}^{+\infty} \frac{1}{a_n}$ converges. Prove $\sum_\limits{n=1}^{+\infty} \frac{n}{a_1 + \cdots + a_n}$ is convergent. I find that this may have something to do with Stolz Theorem which says that if $\{\frac{1}{a_n}\}$ is convergent then $$\lim_{n \rightarrow +\infty} \frac{n}{a_1+\cdots +a_n} = \lim_{n \rightarrow +\infty} \frac{1}{a_n}$$ This may implies that $\frac{n}{a_1+\cdots +a_n}$ and $\frac{1}{a_n}$ have the same declining speed so leads to the answer of the question. However, I don't know how to turn this into correct proof.",['sequences-and-series']
3167222,Finding quadratic residues without Legendre symbols,"I ran into two very similar problems concerning quadratic residues, and I'm having a bit of trouble working through them. These problems are supposed to rely exclusively on the theory of cyclic groups, without use of Legendre symbols. I'm posting both in one question since I roughly managed to solve the first one and it's meant to show my thought process towards solving the second. Let $p$ be a prime congruent to $1$ modulo $3$ . Show that there exists
  an $a \in \mathbb{Z}$ such that $a^2 + a + 1 \equiv 0 \textrm{ mod } p$ and
  conclude that $-3$ is a square modulo $p$ . To solve this one, I let $p = 3k + 1$ , and take $g \in (\mathbb{Z}_p, \times)$ to be a generator from which follows that $g^{3k} - 1 = (g^k - 1)(g^{2k} + g^k + 1) \equiv 0 \textrm{ mod } p$ . Since $g$ is a generator, $g^k \ne 1$ . To conclude $-3$ is a square, I (somewhat randomly) noticed that \begin{align*}
     (g^k - g^{-k})^2 &= g^{2k} - 2 + g^{-2k} \\
                      &= g^{2k} + g^k + 1 - 3 \\
                      &\equiv -3 \textrm{ mod } p 
\end{align*} I was wondering, is there any significance to the element $g^k - g^{-k}$ as a root for $-3$ ? Is there any way to intuitively know immediately that's the square you're looking for? I remember seeing similarly defined elements before, and I pretty much just plugged it in hoping for the best, without really knowing what I was doing. The next problem has me completely stumped. Let $p$ be a prime congruent to $1$ modulo $5$ . Show that there exists
  an $a \in \mathbb{Z}$ such that $(a + a⁴)² + (a + a⁴) - 1 \equiv 0 \textrm{ mod } p$ and conclude that $5$ is a square modulo $p$ . I sort of have this sense that I'm gonna need an element of order $10$ , i.e. $g^{\frac{5k}{2}}$ where $g$ is yet again a generator, however I can't seem to get anywhere with this. If I let $x = a + a^4$ , then I can tell I'm basically looking for an element $x$ which has the next element $x + 1$ as its inverse, but that doesn't really help me forward.","['modular-arithmetic', 'number-theory', 'cyclic-groups', 'quadratic-residues', 'prime-numbers']"
3167246,"The ""correct"" standard deviation","This may end up being a question more about scientific best practice than anything else, but I think this is the right community to ask it in to get the insight I'm looking for. Say I have two little square widgets made out of a material that shrinks when it gets wet.  I want to know by how much.  I measure the length of the widgets along two lines each (because they're not shaped perfectly and my measurement technique isn't perfect), before and after soaking them with water.  I come back with data that looks like this: Widget  Measurement  Before  After  Shrinkage
1       1            1.898   1.722  0.176
1       2            1.904   1.737  0.167
2       1            2.003   1.763  0.240
2       2            2.029   1.843  0.186 Now, I can calculate the overall mean without worrying too much in this case, since the mean of two means is the same as the mean of all the points that went in as long as each mean has the same number of samples, which in this case they do.  So: avg(0.176,0.167,0.240,0.186) = 0.192 = avg(avg(0.176,0.167),avg(0.240,0.186)) However, this type of relation is not true for the standard deviation.  There are several approaches that immediately present themselves to me as options for finding an overall standard deviation for this dataset: Use all of the data at once: sd(0.176,0.167,0.240,0.186) = 0.033 Get a standard deviation for each widget, and average them: avg(sd(0.176,0.167),sd(0.240,0.186)) = 0.022 Get the average for each widget, and take the standard deviation of the two: sd(avg(0.176,0.167),avg(0.240,0.186)) = 0.029 Now, maybe it's just confusion on my part as to the meaning of a standard deviation, but I don't know which approach would be correct to use here (for the purpose of, for example, putting error bars on a graph).  Intuitively I'm drawn to the first method, because it seems to incorporate the most information about the data in the actual standard deviation calculation.  I'm wary, though, that doing this could be be implicitly making some assumption about the structure of the data, such as homogeneity , which may not actually hold. What approach is generally regarded as correct , and what assumptions about the structure of the data does it imply?  Is there another, more correct method (or another method that makes fewer assumptions) which I failed to list?","['philosophy', 'statistics', 'descriptive-statistics']"
3167295,Littlewood's inequality for $L^p$ spaces,"I have tried to prove the following inequality, but I couldn't do yet. Prove the following interpolation estimate: $$\| u\|_q \leq \| u\|_p^{\theta} \| u\|_r^{1- \theta}$$ where $p≤q≤r$ , $θ∈[0,1]$ and $\frac{1}{q} = \frac{\theta}{p} + \frac{1-\theta}{r}$ . Note that $\| u\|_q $ denotes $L^q$ norm. Analysis kills me. Any help will be appreciated.","['inequality', 'integral-inequality', 'real-analysis']"
3167384,determinant of a tricky matrix,"I'm doing a research on matrix integrators and I ran into a problem in one particular case. To finish my proof the last thing remaining is to prove the nonsingularity of a specific matrix $$M_n: (m_{ij} = \frac{1}{a_i - a_j}, 1\leq i \leq n, 1\leq j \leq n,i\neq j;m_{ii} = \frac{c}{a_i - b} + \sum\limits_{k\neq i, 1\leq k \leq n}\frac{1}{a_i - a_k}),$$ where all $a_i, b$ are distinct. To be more clear I provide $$M_2 = \begin{pmatrix}
\frac{c}{a_1 -b} + \frac{1}{a_1 - a_2} && \frac{1}{a_1 - a_2}\\
\frac{1}{a_2 - a_1} && \frac{c}{a_2 -b} + \frac{1}{a_2 - a_1}
\end{pmatrix}$$ $$M_3 = \begin{pmatrix}
\frac{c}{a_1 -b} + \frac{1}{a_1 - a_2} + \frac{1}{a_1 - a_3} && \frac{1}{a_1 - a_2} && \frac{1}{a_1 - a_3}\\
\frac{1}{a_2 - a_1} && \frac{c}{a_2 -b} + \frac{1}{a_2 - a_1} + \frac{1}{a_2 - a_3} && \frac{1}{a_2 - a_3}\\
\frac{1}{a_3 - a_1} && \frac{1}{a_3 - a_2} && \frac{c}{a_3 - b} + \frac{1}{a_3 - a_1} + \frac{1}{a_3 - a_2}
\end{pmatrix}$$ For $n \leq 7$ I calculated the $det(M_n) = \frac{c(c+1)...(c + n -1)}{\prod\limits_{1\leq i\leq n}(a_i - b)}$ , but I have no idea how to prove this in general case. I my particular case $c\in \mathbb N$ , so this formula will prove the nonsingularity of $M_n$ . Any ideas and tips to prove the formula, or even to prove nonsingularity of $M_n$ in some other way - are very appreciated","['matrices', 'determinant', 'linear-algebra']"
3167430,How to solve a differential equation with a term to a power?,How would I solve an equation where one of the differential terms is to a power? For example: $$\frac{d^2y}{dx^2}+k(\frac{dy}{dx})^2=0$$ I've been given advice to use the $D$ operator which apparently means $\frac{d}{dx}()$ but I'm not sure how that's applicable to this scenario. Any alternative suggestions or explanations would be appreciated!,"['calculus', 'ordinary-differential-equations']"
3167436,Why use Classic fourth-order Runge-Kutta over the 3/8-rule?,"I have been reading about Runge-Kutta methods, particularly the ""classical"" fourth-order method. When it is talked about, the 3/8th rule is often mentioned. For example, in this document , the classical method is said to be more popular, but somehow the 3/8th rule is more precise. The wikipedia page of the list of Runge-Kutta methods also states that the classical rule is more notorious, even though both were presented in the same paper. Why exactly is one method more popular than the other?","['runge-kutta-methods', 'numerical-methods', 'ordinary-differential-equations']"
3167442,Solving Integral Equation by Converting to Differential Equations,"Consider the problem $$\phi(x) = x - \int_0^x(x-s)\phi(s)\,ds$$ How can we solve this by converting to a differential equation?","['integral-equations', 'ordinary-differential-equations', 'integro-differential-equations']"
3167456,How do the eigenvalues change if we change the diagonal entries of the matrix?,"Suppose $A \in M_n(\mathbb R)$ is stable. By stable, we mean the eigenvalues are all on the left open half plane of $\mathbb C$ . Now if we decrease the value of $A_{11}$ , does the matrix remain stable? I first thought in terms of Gershgorin Disks. If we decrease the entry $A_{11}$ , the center of corresponding disk would move to the left of the real axis. But then I realized this is not enough since we only know the eigenvalues are contained in the union of all disks. However, I could not see a counterexample. Alternatively, the question is a perturbation with rank-one matrix, i.e., we want to know whether $A-t e_1e_1^T$ remains stable for $t > 0$ where $e_1 = (1, 0, \dots, 0)^T$ .","['gershgorin-sets', 'eigenvalues-eigenvectors', 'linear-algebra', 'perturbation-theory', 'matrix-analysis']"
3167462,Series $\sum_{n=1}^{\infty} \frac{n^2 - 5n}{n^3 + n + 1}$,"Alright, this is another problem that I have been stuck on. The goal is to determine whether it is convergent or divergent. $$\sum_{n=1}^{\infty} \frac{n^2 - 5n}{n^3 + n + 1}$$ So to start off, Integral Test seems rough as the denominator is not factorable for partial fraction decomposition. So then, I tried Direct Comparison Theorem, but... $$\frac{1}{n^3} < \frac{n^2 - 5n}{n^3 + n + 1}[n > 5]$$ Although not for the intervals [0, 5]. $$\frac{1}{n^3} > \frac{n^2 - 5n}{n^3 + n + 1}[0<n<5]$$ So yeah, that's kind of confusing. Especially since the problem starts at n = 1 instead of n = 5. However, I know that, by p-series $$\sum_{n=1}^{\infty} \frac{1}{n^3} --> converges $$ And if the smaller value converges, then Direct Comparison Theorem tells us nothing. So I decided to try the Limit Comparison Theorem: $$b_n = \frac{1}{n^3} $$ $$\lim_{n\to0} \frac{n^2 - 5n}{n^3+n+1}*\frac{n^3}{1} = \lim_{n\to0} \frac{n^6 - 5n^4}{n^3 + n + 1} = {\infty}$$ So if bn is convergent by p series, but the limit is divergent, then LCT is useless. So, now my question is where did I go wrong in attempting to prove convergence/divergence?","['convergence-divergence', 'analysis', 'sequences-and-series']"
3167479,How many n strings are there of letters of english alphabet in which there are no consecutive z's?,I have this combinatorics problem: How many n strings are there of letters of english alphabet in which there are no consecutive z's? I want to solve this problem using generating functions Generating functions of single letters other than z is obvious but i can't find the generating function for z. I know that its function will be a polynomial with degree of $\frac{n}{2}$ or $\frac{n+1}{2}$ depending on whether n is even or odd but i can't find the coefficients of the function. Can anyone lead me to a solution? Thanks in advance.,"['combinatorics-on-words', 'combinatorics', 'generating-functions']"
3167494,Geometric proof of $\sin x \geq x - x^3 /6 $?,"We know (from Taylor expansion for example) that if $x \geq 0$ , then $\sin x \geq x - \frac{x^3}{6}$ . In Prove that: $\sin(x) \cos(x) \geq x-x^3$ a geometric proof of the inequality $\sin x \geq x - \frac{x^3}{4}$ is given. Is there any geometric proof of the first one (which is slightly stronger ?","['trigonometry', 'inequality']"
3167534,Increasing limit of sets is in union of families,"Let $A_1 \subseteq A_2 \subseteq \cdots$ be a sequence of sets such that $A_i \in \cal{F}_i$ , where $\cal{F}_i \supseteq \cal{F}_{i-1} \forall i$ Let $A = \bigcup_{i \in \mathbb{N}} {A_i}, \cal{F} = \bigcup_{i \in \mathbb{N}} {\cal{F}_i}$ How can I say that $A \in \cal{F}$ ?  This seems true, but I'm not able to get the argument. Edit: Not true.  See comment below.",['elementary-set-theory']
3167542,Can every function be represented as $ e^{kx} $,"Are all real continous elementary functions included in $$ e^{kx} $$ $k$ is a complex number , $x$ is real variable . This question came to my mind when solving linear higher order ODE. We use a substitution like this to solve those equations and i often hear people say we assume the solution is a exponetial function, although we often get $  \sin, \cos $ functions ( which we get by the magic of euler formula). If $k$ is a real number we have only the exponential function. If $k$ is equal to $i$ we get $  \sin, \cos $ can we get other all other functions such as $x^n$ or $\log x$ if $k$ is a complex number $a+ib$ , then we would have $$  e ^{(a+ib)x}=e^{ax}(\cos bx+i \sin bx)    $$ So can we find $a,b$ such this expression is equal to e.g. $ \sqrt x  $ for all $x$ . I think it is not possible but solving that equation for $a,b$ seems only possible numerically","['algebra-precalculus', 'functions', 'exponential-function', 'complex-numbers']"
3167554,Compute connection 1-forms of warped product manifold using method of moving frames,"Let $(\bar{M},\bar{g})$ and $(\dot{M},\dot{g})$ be two Riemannian manifolds and let $f\in C^{\infty}(\bar{M})$ be nowhere zero. Let $(M^n,g)$ be the warped product of the two manifolds with warping function $f$ ; that is, $M=\bar{M}\times\dot{M}$ and \begin{equation}
g=\bar{g}\times_f\dot{g}:=\bar{\pi}^*\bar{g}+(f\circ\bar{\pi})^2\dot{\pi}^*\dot{g}
\end{equation} where $\bar{\pi}:\bar{M}\times\dot{M}\to\bar{M}$ and $\dot{\pi}:\bar{M}\times\dot{M}\to\dot{M}$ are the natural projections. (If you like, we can simply write $g=\bar{g}+f^2\dot{g}$ ). Convention on indices: $1\leq a,b,c,\cdots\leq q$ for $(\bar{M},\bar{g})$ , $q+1\leq\alpha,\beta,\gamma,\cdots\leq n$ for $(\dot{M},\dot{g})$ and $1\leq i,j,k,\cdots\leq n$ for $(M,g)$ . Einstein summation convention is assumed. Let $\left\{\bar{\omega}^a\right\}_{a=1}^q$ and $\left\{\dot{\omega}^{\alpha}\right\}_{\alpha=q+1}^n$ be local orthonormal coframes on $(\bar{M},\bar{g})$ and $(\dot{M},\dot{g})$ respectively. Then a local orthonormal coframe on $(M,g)$ can be given by \begin{align}
\omega^i:=\left\{
\begin{array}{ccl}
\bar{\pi}^*\bar{\omega}^i & \mbox{if} & 1\leq i\leq q \\
(f\circ\bar{\pi})\dot{\pi}^*\dot{\omega}^i & \mbox{if} & q+1\leq i\leq n
\end{array}
\right.
\end{align} (Again, if you like, we can simply write $\bar{\omega}^i$ and $f\dot{\omega}^i$ respectively). Moreover, under these two coframes, denote the connection 1-forms by $\bar{\omega}^b_a$ and $\dot{\omega}^{\beta}_{\alpha}$ respectively. My goal is to compute the connection 1-forms of $(M,g)$ . By taking exterior derivative of the definition of $\omega^i$ , applying the Cartan's 1st structural equation and gather the terms to the LHS, I arrive at \begin{gather}
\omega^b\wedge\big(\omega^a_b-\bar{\pi}^*\bar{\omega}^a_b\big)+\omega^{\beta}\wedge\omega^a_{\beta}=0 
\\
\omega^b\wedge\left(\omega^{\alpha}_b-\frac{(f\circ\bar{\pi})_b}{f\circ\bar{\pi}}\omega^{\alpha}\right)+\omega^{\beta}\wedge\big(\omega^{\alpha}_{\beta}-\dot{\pi}^*\dot{\omega}^{\alpha}_{\beta}\big)=0
\end{gather} where $(f\circ\bar{\pi})_i$ is defined via $d(f\circ\bar{\pi})=(f\circ\bar{\pi})_i\omega^i$ . Now it is tempting to conclude directly from above that \begin{align}
\omega^a_b&=\bar{\pi}^*\bar{\omega}^a_b
\\
\omega^{\alpha}_{\beta}&=\dot{\pi}^*\dot{\omega}^{\alpha}_{\beta} 
\\
\omega^{\alpha}_b&=\frac{(f\circ\bar{\pi})_b}{f\circ\bar{\pi}}\omega^{\alpha}
\end{align} but I don't think this is valid in general for sum of wedge products. The Cartan's lemma tells us that at most we only can conclude that the expressions in the parentheses can be written as a linear combination of the $\omega^i$ 's (this is trivial here) with coefficients satisfying some symmetry on the indices. Hence, I would like to ask for the way to proceed. How do we continue to compute the connection 1-forms? Any comment, hint and answer is welcomed and appreciated. P.S. This is not a homework problem. I was just trying to explore and play around the things on my own. Thus, there is a chance that what I have written contains some errors. Feel free to correct me if I have written something wrong.","['riemannian-geometry', 'differential-geometry']"
3167560,Show that if $f(z)$ is entire and if $f(z)/z^n$ is bounded when $z$ is large then $f$ must be a polynomial. [duplicate],"This question already has answers here : Entire function bounded by a polynomial is a polynomial (5 answers) Closed 2 years ago . Suppose that if $f(z)$ is an entire function such that $\dfrac{f(z)}{z^n}$ is bounded for $|z|\ge R$ then $f(z)$ must be a polynomial of degree at most $n$ This same question has already been asked and solved on this website but the solution relies on power series and this question is asked in my text before power series has been introduced. My book gives the hint that I should use Cauchy's estimates for $f^{(m+1)}(z)$ on a disk $|z-z_0|<R$ and then let $R \to \infty$ to obtain that $f^{(m+1)}(z_0)=0$ I proved the hint as follows. $f$ is analytic on $|z|<R$ and also $|f(z)|<k|z|^n$ when $|z|\ge R$ so by Cauchy's estimate on $|z|<R$ , $f^{(m)}(0)\le \dfrac{m!}{R^m}k|z|^n=m!kR^{n-m}\to0$ when $m>n$ and so $f^{(m)}(0)=0 \; \forall \;m>n$ . Now let $z_0\in \mathbb C$ and choose $R'$ big enough such that $B_R(0) \subset B_{R'}(z_0)$ , hence $|z|>R$ when $z \in \partial B_{R'}(z_0).$ $f$ being entire is then analytic on $B_{R'}(z_0)$ and so again by Cauchy's estimates we see that $f^{(m)}(z_0)\le \dfrac{m!}{(R')^m}k|\hat z|^n$ for $\hat z\in \partial B_{R'}(z_0)$ such that $|\hat z| \ge |z|$ for any $z \in \partial B_{R'}(z_0)$ . Note that $|\hat z|=|z_0|+R'$ since for any $z \in \partial B_{R'}(z_0)$ we have $|z|\le |z-z_0|+|z_0|= R' +|z_0|$ . So $|\hat z| \le R' + |z_0|$ but we see that $z_0 + R'\dfrac{z_0}{|z_0|}$ is on $\partial B_{R'}(z_0)$ and $|z_0 + R'\dfrac{z_0}{|z_0|}|=|z_0|+R'$ and this means that $|\hat z| = R' +|z_0|$ . Using this we now see that $f^{(m)}(z_0)\le \dfrac{m!}{(R')^m}k(|z_0|+R')^n$ and if we let $m>n$ then we see that $f^{(m)}(z_0) \to 0$ and $R' \to \infty$ . Now we can say that $f^{(m)}(z)=0$ whenever $m>n$ . Now I do not know how to continue? Why does this mean that $f$ must be a polynomial? I see how it is true if we can use power series but thats not available to me now. Can I use induction as follows? I want to show that if $f$ is entire and $f^{(m)}(z)=0$ for $m>n$ means that $f$ is a polynomial with degree at most $n$ . For the base case suppose $f^{m}(z)=0$ whenever $m>0$ . Hence $f'(z)=0$ which means $f$ is a constant function, or in other words a polynomial with degree $0$ . So the base case is true. Now suppose that $f^{m}(z)=0$ whenever $m>k$ means that $f$ is a polynomial if at most degree $k$ . Suppose that $f^{m}(z)=0$ whenever $m>k+1$ . Let $g(z)=f'(z)$ which is also entire since $f$ is entire. Then we see that $g^{m}(z)=0$ whenever $m>k$ which implys that $g$ is a polynomial of degree at most $k$ and therfore $f'(z)$ is a polynomial of degree at most $k$ which means that $f(z)$ is a polynomial of  degree at most $k+1$ which proves the result. Is this all correct?",['complex-analysis']
3167571,Let consider a square $10$x$10$ and write in the every unit square the numbers from $1$ to $100$,Let   consider   a  square $10\times 10$ and  write  in  the   every   unit  square    the   numbers   from $1$ to $100$ such  that   every  two   consecutive  numbers  are  in   squares   which  has  a  common edge.  Then  there  are  two  perfect  squares   on  the  same line  or  column. Can  you   give  me  an  hint? How  to  start?,"['chessboard', 'puzzle', 'combinatorics']"
3167630,"If $\text P\left[|X_n|>n^{-\alpha}\right]\to0$ as $n\to\infty$ for some $\alpha>0$, does $(X_n)_{n\in\mathbb N}$ converge in probability?","Let $(X_n)_{n\in\mathbb N}$ be a sequence of real-valued random variables on a probability space $(\Omega,\mathcal A,\operatorname P)$ and $\alpha>0$ . Is there some relation between convergence in probability, i.e. $$\operatorname P\left[|X_n|>\varepsilon\right]\xrightarrow{n\to\infty}0\;\;\;\text{for all }\varepsilon>0\tag1$$ and $$\operatorname P\left[|X_n|>\frac1{n^\alpha}\right]\xrightarrow{n\to\infty}0?\tag2$$ It seems like neither implies the other. If so, can we deduce any other mode of convergence from $(2)$ ?","['measure-theory', 'probability-theory', 'weak-convergence']"
3167676,For complex function : $f'(z)$ exists $\implies$ $f$ continous in $z$?,Consider a complex function $f(z): A\subset\mathbb C \to\mathbb C$ . If the derivative of $f$ exists then $f$ must necessarily be a continuous function? Is the following true? $f'(z)$ exists $\implies$ $f$ continuous in $z$,"['complex-analysis', 'continuity', 'functions', 'derivatives', 'complex-numbers']"
3167697,How many distinct 20-bead necklaces can be made with beads of 3 different colors?,"First of all, I am aware that these types of questions are very common and are around the internet in all shapes and sizes. However, in this case I was just really wondering if I'm doing the right thing, as the 'standard' approach wouldn't work here as the size of the problem is too big. Therefore, I thought of some ways to finalize my answer and I'm not sure if I'm missing any steps in my process. How many non-equivalent 20-bead necklaces can be made if we use 3 different colors? How many can be made with every color appearing at least 3 times? Let's assume we use the colors Blue, Green and Red, denoted by $b,g,r$ respectively. We will first calculate how many necklaces can be made at all, with no restrictions on the amount of colors appearing each time. The group of necklace operations (turning it bead per bead) is isomorphic to $C_{20}$ or $\mathbb{Z}/20\mathbb{Z}$ . Therefore, we can find the terms of the Cycle Index: $\phi(1)=1$ so there's $1$ permutation of order $20; z_1^{20}$ $\phi(2) = 1$ so there's $1$ permutation of order $10; z_2^{10}$ $\phi(4) = 2; \ 2z_4^5$ $\phi(5)=4;\ 4z_5^4$ $\phi(10)=4; \ 4z_{10}^2$ $\phi(20) = 8; \ 8z_{20}$ where $\phi$ denotes the Euler Phi function. Combining this gives the Cycle Index: $$Z(z_1,z_2,z_4,z_5,z_{10},z_{20})=\frac{1}{20}\big(z_1^{20}+z_2^{10}+2z_4^5+4z_5^4+4z_{10}^2+8z_{20}\big)$$ Filling in $3$ for each of the $z_i$ gives the CFB-formula, which will lead to all possible 20-bead necklaces using any of the 3 colors. This gives $$|O|=174\ 342\ 216$$ Now we will look at all the necklaces having each color used at least 3 times. This is the same as looking at all the necklaces that have at least once color used less than 3 times. The latter can then be subtracted from the total number of necklaces possible to get the desired answer. Edit : this was my initial approach but I forgot about terms where only 2 colors were used at all (and thus not all colors were used more than 3 times). This made me have a direct approach again: For the term $z_1^{20}$ we are interested in coefficients of the terms $b^3g^ir^{17-i}$ where $i=3,\dots,14$ and $b^4g^ir^{16-i}$ where $i=3,\dots,13$ up until $b^{14}g^3r^3$ . The coefficients of these terms are $\binom{20}{3}\binom{17}{i}, \binom{20}{4}\binom{16}{i}\dots \binom{20}{14}\binom{6}{3}$ respectively. From the summation we get: $$\sum_{n=3}^{14}\bigg[\binom{20}{n}\sum_{i=3}^{17-n}\binom{20-n}{i}\bigg]=3\ 3 02\ 869\ 446$$ For the term $z_2^{10}$ we look at the coefficients of the terms $b^4g^{2i}r^{16-2i}$ where $i=2,\dots,6$ and $b^6g^{2i}r^{14-2i}$ where $i=2,\dots,5$ , up until $b^{12}g^4r^4$ . Using the same method as before, we get: $$\sum_{n=2}^{6}\bigg[\binom{10}{n}\sum_{i=2}^{8-n}\binom{10-n}{i}\bigg]=40\ 950$$ For the term $z_4^5$ we can apply the same as before, but not only with even numbers, but with any exponent that's a multiple of 4. Our summation will be: $$2*\sum_{n=1}^{3}\bigg[\binom{5}{n}\sum_{i=1}^{4-n}\binom{5-n}{i}\bigg]=300$$ The only possibilities for $z_5^4$ are $b^5g^5r^{10},b^5g^{10}r^5$ and $b^{10}g^5r^5$ . Our summation will be shorter: $$4*\bigg[\binom{4}{1}\binom{3}{1}+\binom{4}{1}\binom{3}{2}+\binom{4}{2}\binom{2}{1}\bigg]=144$$ The remaining terms $z_{10}^2$ and $z_{20}$ will not contribute to our counting problem as all the terms $b^ig^jr^k$ will have $i,j,k\geq10$ or either of the exponents being $0$ , which means there are no cases in which all three colors are used at all, so in particular they won't be used 3 or more times. Combining all the coefficients for all the terms using all the colors at least 3 times, we find: $$|N|=\frac{1}{20}\big(3\ 3 02\ 869\ 446 + 40\ 950 + 300 + 144 \big) = 165\ 145\ 542 $$","['polya-counting-theory', 'combinatorics', 'discrete-mathematics']"
