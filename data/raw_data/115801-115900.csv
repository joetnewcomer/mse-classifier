question_id,title,body,tags
1700408,Expected value of the smallest eigenvalue,"Consider a random $m\times n$ matrix $M$ with elements from $\{-1,1\}$ and $m<n$. What is known about the expected value of the smallest eigenvalue of $MM^T$? The following picture shows numerical results for the expected value of the smallest eigenvalue of $MM^T$ for $n=120$ and $m=1 \dots 60$. How can you prove that the expected value is monotonically decreasing? Is it possible to get an estimate for the expected value?","['eigenvalues-eigenvectors', 'random-matrices', 'probability', 'linear-algebra']"
1700459,prove that for $n \geq 2$ there does not exist an n-vertex simple graph whose vertices have distinct degrees,"prove that for $n \geq 2$ there does not exist an n-vertex simple graph whose vertices have distinct degrees. So looking at this question the degrees would have to be from $n\leq 1$ since the degree of a simple graph of with n vertices would be n - 1. I do not know how to continue from there. The question was previously asked and I attempted the hints which were what is the degree, what does it mean if they are all different, What does the largest degree mean, and what about the smallest.","['combinatorics', 'graph-theory', 'discrete-mathematics']"
1700463,"Given a field $\mathbb{F}$, what is $\text{Aut}(\mathbb{F}^{\ast})$?","There are many well-known problems and results concerning automorphism groups of fields. For example, it is well-known that the automorphism group of each field in $\{ \mathbb{Q}, \mathbb{F}_{p}, \mathbb{R} \}$ is trivial, and it is well-known that the (known) constructions of the 'wild' automorphisms of the field $\mathbb{C}$ require the axiom of choice (or Zorn's lemma). It thus seems natural to consider the 'easier' problem of evaluating the group $\text{Aut}(\mathbb{F}^{\ast})$ of group automorphisms of the underlying multiplicative group $\mathbb{F}^{\ast}$ of $\mathbb{F}$. It is clear that the problem of evaluating $\text{Aut}(\mathbb{F}_{p}^{\ast})$ reduces to the closed problem of evaluating the automorphism group of a finite abelian group (see Automorphisms of Finite Abelian Groups ), and it is clear that evaluating $\text{Aut}(\mathbb{Q}^{\ast})$ reduces to the  problem of evaluating the group of group automorphisms of $C_{2} \oplus \mathbb{Z} \oplus \mathbb{Z} \oplus \cdots$ (see this related discussion). It thus seems natural to ask: (1) What is $\text{Aut}\left(\mathbb{R}^{\ast}\right)$? (2) What is $\text{Aut}\left(\mathbb{C}^{\ast}\right)$? (3) What is $\text{Aut}\left(\mathbb{C}(t)^{\ast}\right)$? (4) What is $\text{Aut}\left(\mathbb{Q}_{p}^{\ast}\right)$, where $\mathbb{Q}_{p}$ denotes the field of $p$-adic numbers? (5) More generally, given a field $\mathbb{F}$, is there a known way of evaluating $\mathbb{F}^{\ast}$?","['field-theory', 'group-theory']"
1700470,Let $z_k = \cos\frac{2k\pi}n + i\sin\frac{2k\pi}n$. Show that $\sum_{k=1}^n|z_k-z_{k-1}|<2\pi$.,"Let $z_k = \cos\frac{2k\pi}n + i\sin\frac{2k\pi}n$. Show that $\sum_{k=1}^n|z_k-z_{k-1}|<2\pi$. So, this is a problem from Herb Silverman's ""Complex Variables"". I gave it a try with several ways, e.g., reducing all terms to one term, but none of them work. It seems that I never got close. Can someone help me?",['complex-analysis']
1700491,Cohomology of structure sheaf of abelian variety,"Let $X$ be an abelian variety over $\mathbb{C}$ of dimension $n$. Consider the structure sheaf $O_X$. It's Euler characteristic is zero, because $\chi(O_X)= (O_X^n)/n!$. And the self intersection of $O_X$ is 0. But is there some way to compute the $h^i(X,O_X)$? If the dimension $n=2$, then since $h^0=h^2=1$, we get $h^1=2$. What about for n>2? Is there some way to check this dimension?","['schemes', 'sheaf-cohomology', 'algebraic-geometry', 'abelian-varieties']"
1700495,Russells Paradox and definition of a set in Terry Tao's Analysis I,"In his book ""Analysis 1"", Terry Tao writes (check out page 39): To summarize so far, among all the objects studied in mathematics, some of the objects happen to be sets; and if $x$ is an object
  and $A$ is a set, then either $x\in A$ is true or $x\in A$ is false. (If $A$ is not a set, we leave the statement $x\in A$ undefined; for instance,
  we consider the statement $3\in 4$ to neither be true or false, but
  simply meaningless, since $4$ is not a set.) But when discussing Russell's Paradox, he defines on page 53 a set $\Omega := \{x : x \text{ is a set and }x\notin x\}$ . So he defines that an arbitrary object $x$ is an element of $\Omega$ if and only if $x$ is a set and $x\not\in x$ . But this definition does not make any sense, since, according to his definition, we would have $4\in\Omega$ if and only if $4$ is a set and $4\not\in 4$ . But $4\not\in 4$ is meaningless, as he says, and therefore "" $4$ is a set and $4\not\in 4$ "" is meaningless as well. QUESTION: How to fix this fault? Note: I understand Russell's Paradox. But the definition $\Omega := \{x : x \text{ is a set and }x\not\in x\}$ does not satisfy me formally . My question is exactly how to make it formally work.","['paradoxes', 'elementary-set-theory']"
1700508,Solving differential equation $xdy + ydx = 0$,"Solve following equation $$xdy + ydx = 0$$ My process: group variables $$xdy = -ydx \ \ \ ; \ \ \ \frac{x}{dx} = -\frac{y}{dy}$$ Integrate $$\int{\frac{dx}{x}} = \int{\frac{-dy}{y}}$$
$$\ln |x| + K = - \ln |y| + K$$ Solution 
$$\ln|xy| = K$$ However my textbook gives answer: $$xy = K$$ Where am I going wrong?","['integration', 'ordinary-differential-equations', 'calculus']"
1700528,When is a polynomial contained in the ideal generated by its partial derivatives?,"Let $R = k[x_1,\dots,x_n]$ be a multivariate polynomial ring over a field $k$ of characteristic zero, and let $f\in R$ . Is there an easy-to-test necessary and sufficient condition on $f$ such that $f$ is in the ideal of $R$ generated by its partial derivatives $\partial_if$ ? Geometrically, $f\in \left(\partial_1 f,\dots, \partial_n f\right)$ is the statement that the map $f:\mathbb{A}^n\rightarrow\mathbb{A}^1$ is a submersion anywhere it is nonzero. ( Edit per a comment of @Evangelion045: this isn't quite true. $f\in(\partial_1f,\dots,\partial_n f)$ implies that $f$ is a submersion everywhere it's nonzero, but in the opposite direction, $f$ being  a sumbersion everywhere it's nonzero only implies $f$ is in the radical of the ideal generated by its partials.) A sufficient condition is if $f$ is homogeneous of degree $d$ , due to Euler's formula $$ d\cdot f = \sum_i x_i\partial_i f$$ I was led to the question by the surprise discovery that the statement is also true if $f$ happens to be the resolvent cubic of a monic quartic polynomial $x^4 - \sigma_1x^3 +\sigma_2x^2 - \sigma_3x +\sigma_4$ , which is an inhomogeneous polynomial of degree three in the four coefficients $\sigma_1,\dots,\sigma_4$ plus an auxiliary variable $\Lambda$ . But the resolvent cubic is, to be sure, weighted homogeneous (with weight $i$ for $\sigma_i$ and weight $2$ for $\Lambda$ ). And sure enough, the proof for Euler's formula generalizes to this case. We have $$ d\cdot f = \sum_i d_ix_i\partial_if$$ where $d_i$ is the weight of $x_i$ and $d$ is the weighted degree of $f$ . Thus the existence of a set of weights making $f$ weighted homogeneous is also a sufficient criterion. (A google search revealed an analytic generalization in a book of Arnol'd , citing Saito.) However, it's not quite necessary: any (nonconstant) linear function also trivially has $f\in \left(\partial_1 f,\dots,\partial_n f\right)$ since the latter is the unit ideal, while if its constant term is nonzero then it is not homogeneous with respect to any set of (positive integer) weights. Do you know a condition that is both sufficient and necessary?","['polynomials', 'algebraic-geometry', 'commutative-algebra']"
1700560,Number of common roots of $x^3 + 2 x^2 +2x +1 = 0$ and $x^{200} + x^{130} + 1 = 0 $,"The equations $x^3 + 2 x^2 +2x +1 = 0$ and $x^{200} + x^{130} + 1 = 0 $ have exactly one common root; no common root; exactly three common roots; exactly two common roots. I factored the first equation. I think the roots are $-1$, $\omega$ and $\omega^2$.","['algebra-precalculus', 'contest-math', 'complex-numbers']"
1700601,"Surjectivity of linear map between ""naive"" and ""abstract"" Zariski tangent spaces","I know this is probably a simple problem but I have got myself stuck trying to prove this fact myself. I'd be very grateful if anyone could clear this up for me. Let $V$ be an affine variety in $\mathbb{A}^n$ (say, over an algebraically closed field $K$) and suppose $P = (0,\dots, 0)\in V$ is the origin of affine space. I am trying to prove there's an isomorphism between the ""abstract"" Zariski tangent space $T_P (V) = (\mathfrak{m}_P/\mathfrak{m}_P^2)^*$ and the ""naive"" vector space $$W = \left\{(\alpha_1, \dots, \alpha_n): \sum_{i=1}^n \alpha_i \frac{\partial f}{\partial x_i} (P)=0, \quad \forall f\in I(V)\right\}$$ I've shown there's an injection $\phi: W\to T_P (V)$ as follows: for $Q = (\alpha_1, \dots, \alpha_n)\in W$ we get a linear functional $\phi_Q : \mathfrak{m}_P/\mathfrak{m}_P^2 \to K$ via $$\phi(Q) = \phi_Q = \sum_{i=1}^n \alpha_i \frac{\partial}{\partial x_i}\lvert_P$$ which corresponds to taking a ""weighted total derivative"" of an equivalence class of a function $r\in \mathfrak{m}_P$ modulo $\mathfrak{m}_P^2$ i.e. $$\phi_Q (\bar{r}) = \sum_{i=1}^n \alpha_i \frac{\partial r}{\partial x_i} (P)$$ where $\bar{r}$ denotes the image of $r$ in the quotient. This is indeed a linear functional on $\mathfrak{m}_P/\mathfrak{m}_P^2$. Moreover the mapping $\phi$ is an injective $K$-linear map $W\to T_P (V)$. What I'm struggling to do is show surjectivity of this map. Every element $g\in T_P (V)$ can be written as $$ g = \sum_{i=1}^n \alpha_i g_i$$ where $g_i (\bar{x_j}) = \delta_{i j}$ is one of the dual basis vectors. What isn't clear to me is that the coefficients $\alpha_i$ come from some $Q = (\alpha_1, \dots, \alpha_n)\in W$ i.e. that $$\sum_{i=1}^n g(\bar{x_i}) \frac{\partial f}{\partial x_i} (P) = 0, \quad \forall f\in I(V)$$ Can anyone explain why this map is surjective? Edit : I mistakenly forgot to include the condition that the linear combination sums to zero in the definition of the ""naive"" tangent space in the original post, which caused some confusion. This has been amended above.",['algebraic-geometry']
1700608,Use of inequality $1 - \cos (x) \leq x^2 /2$,"In this answer the value of $1 - \cos(x)$ has to be evaluated in order to find its upper limit, if it exists. In particular, $x = 2 \pi / n$. The answer is related to the length of a side of a regular $n$-gon inscribed into a unit-radius circumference; because the perimeter of the $n$-gon is always less than $2 \pi$, the single side must always be less than $2 \pi / n$. The inequality $$1 - \cos (x) \leq \displaystyle \frac{x^2}{2}$$
(1) is used and the proof is completed with $$2(1 - \cos(x)) \leq (2 \pi / n)^2$$ $$\sqrt{2(1 - \cos(x))} \leq 2 \pi / n$$ But it is well known that the cosine is a function $f(x) \in [-1;1]$, so $1 - \cos (x) \in [0,2]$. By using this information, we would obtain $$1 - \cos (x) \leq 2$$
(2) The proof would provide $$2(1 - \cos(x)) \leq 4$$ $$\sqrt{2(1 - \cos(x))} \leq 2$$ which is a completely different result. Why in that case it is preferable to use (1) instead of (2)? How to choose when it is convenient to use (1) and when to use (2) in a proof?","['real-analysis', 'inequality', 'trigonometry', 'calculus', 'proof-verification']"
1700613,When is $\binom{2n}{n}\cdot \frac{1}{2n}$ an integer?,"In a recent question here , asking about the number of necklaces of $n$ white and $n$ black beads ( reworded in terms of apples and oranges ), one of the naive and incorrect answers was that as there are $\binom{2n}{n}$ ways to arrange the beads in a straight line, dividing by $2n$ to account for the symmetry of the circle would correct the count. In the case that $p$ is a prime not equal to two, it is clear to see that $\dfrac{(2p)!}{p!p!2p}$ has a factor of $p$ exactly twice in the numerator yet three times in the denominator and is thus not even an integer. My question: For what values of $n$ will $\binom{2n}{n}\frac{1}{2n}$ be an integer? A similar question was asked here for the more general case of when $\frac{1}{n}\binom{n}{k}$ is an integer, generating some very nice graphics, and some special cases were mentioned such as when $\gcd(n,k)=1$, however that will never be the case in the special case I ask about (since $\gcd(2n,n)=n\neq 1$ for all $n>1$).  Indeed, when looking at the lovely image made by @BrunoJoyal, one notices a black line down the center of the image, which would correspond to those positions I am interested in. Wolfram gives us the beginnings of a sequence $1,6,15,28,42,45,66,77,91,\dots$  With the exception of $42$ and $77$ these numbers are the first hexagonal numbers, but that pattern breaks with $120$ not being in the sequence. A longer list from the comments by @BanachTarski: There are 89 such numbers in the first 1000 natural numbers 1, 6, 15, 28, 42, 45, 66, 77, 91, 110, 126, 140, 153, 156, 170, 187, 190, 204, 209, 210, 220, 228, 231, 238, 266, 276, 299, 308, 312, 315, 322, 325, 330, 345, 378, 414, 420, 429, 435, 440, 442, 450, 459, 460, 468, 476, 483, 493, 496, 510, 527, 551, 558, 561, 570, 580, 589, 600, 609, 620, 651, 665, 682, 684, 696, 703, 740, 744, 748, 770, 777, 806, 812, 814, 851, 861, 868, 888, 902, 920, 924, 936, 943, 946, 950, 962, 966, 988, 989 Is there anything special we can say about those $n$ for which this is the case?  (By imposing the extra condition on $k$ and $n$ in the generalized question, more patterns will hopefully emerge)","['number-theory', 'combinatorics', 'elementary-number-theory']"
1700639,Evaluate the line integral of a parabola,"How can I evaluate : $$\int_{C} y \;dx + x^2 \; dy$$ where $C$ is the parabola define by $$y=4x-x^2 \quad \text{from } \; (4,0) \; \text{ to } \; (1,3).$$ Do I need to parameterize the parabola?","['multivariable-calculus', 'integration', 'calculus', 'line-integrals']"
1700651,Symbol of differential operator transforms like a cotangent vector,"Suppose that $D=\sum_{|\alpha| \leq k} A_{\alpha}(x)\frac{\partial^{\alpha}}{\partial x_1^{\alpha_1}...\partial x_n^{\alpha_n}}$ is a differential operator defined on vector valued functions on $\mathbb{R}^n$ (here $A_{\alpha}$ are matrices). Then one can form the expression $\sum_{|\alpha| = k} A_{\alpha}(x)\xi_1^{\alpha_1} \cdot ... \cdot \xi_n^{\alpha_n}$ which is called the principial symbol of $D$. This is fine while we deal with flat case, i.e. everything takes place on $\mathbb{R}^n$. But differential operators may be defined in the broader context of (say) compact manifolds and arbitrary vector bundle. Then the symbol is defined by the similiar procedure, but only locally . On the global level suddenly cotangent bundle somehow pops up: I've heard that this follows from the fact that the principial symbol transforms like a $(0,1)$ tensor more precisely that the variables $\xi$ transform like this. I'm a bit confuses what does it mean: I know transformation law for general tensors of type $(p,q)$ but here are formulas which involve higher order differential operators (not just first order as in standard vector fields). So How one can show that the variables $\xi$ transform like a $(0,1)$ tensor? How it can be used to define symbol as a function from the cotangent bundle? There is also more invariant way of defining symbol, I asked about this some time ago and I received the answer only to the half of my questions (the relevant discussion may be found here Symbol of the differential operator on vector bundles ). So I would also like to ask Why this invariant definition which can be found in this discussion produces locally the expression $\sum_{|\alpha| = k} A_{\alpha}(x)\xi_1^{\alpha_1} \cdot ... \cdot \xi_n^{\alpha_n}$","['ordinary-differential-equations', 'differential-geometry']"
1700705,Find mean and variance using Moment generating function of the negative binomial.,I was asked to derive the mean and variance for the negative binomial using the moment generating function of the negative binomial. However i am not sure how to go about using the formula to go out and actually solve for the mean and variance.,"['calculus', 'probability-distributions', 'statistics', 'probability', 'negative-binomial']"
1700724,"What's the maximum number of faces a convex polyhedron can have, given that it's polyhedron with all the same faces?","I know there's a polyhedron named a disdyakis triacontahedron, it has 120 faces and they're all the same. Could there be a polyhedron with a larger number of faces? Can it be arbitrarily large?","['solid-geometry', 'geometry']"
1700730,"$\{\{1\},\emptyset\}\setminus \{\emptyset\}=$?","If we find the set difference between the set $\{\{1\},\emptyset\}$ and the set $\{\emptyset\}$, what do we get? My best guess is $\{\{1\}\}$.",['elementary-set-theory']
1700739,Possible divisors of $s(2s+1)$,"I write $\psi(s) = s(2s+1)$ and let $d$ be the divisor function. If $s$ is prime then 4 divides $d(\psi(s))$. For example if $s=37$ then $d(\psi(s)) = d(2775) = 12$ and $4|12$. Is this trivial? I am not sure how to attack and prove this. Here is my approach: Now I am thinking $d$ is multiplicative so we need to determine $d(2s+1)$. case 1 : If $2s+1$ is prime then $d(\psi(s))=d(s(2s+1))=d(s)*d(2s+1) = 2*2 =4$ and $4|4$. case 2 : $2s+1$ is not prime. This is where I am stuck. Now, $d(2s+1)$ is either even or odd. If it is even then $d(\psi(s))=d(s(2s+1))=d(s)*d(2s+1) = 2*2k =4k$ and $4|4k$ for some positive integer $k$. But if it's odd I am not sure of the next move. If it is odd and squarefree then $2s+1$ has an even number of divisors? Is this the right approach or is there a better way to go about this? Also is the statement even true, is there a quick counter example? I want to go a step further and claim that $d(\psi(s))$ is equal to $4, 8, 12, 16, 20$ or $24$","['divisor-counting-function', 'number-theory', 'elementary-set-theory', 'combinatorics', 'prime-numbers']"
1700771,Metric spaces whose open sets form a $\sigma$-algebra.,"I have the following question Characterise the metric spaces whose open sets form a $\sigma$-algebra. I apologise if this seems like too basic of a question to ask here, but seeing as English is not my native language, I am having some trouble understanding exactly what is expected of me in this question. Can anyone please assist in giving me some clarity?","['metric-spaces', 'measure-theory']"
1700798,Is linear algebra more “fully understood” than other maths disciplines?,"In a recent question , it was discussed how LA is a foundation to other branches of mathematics, be they pure or applied. One answer argued that linear problems are fully understood , and hence a natural target to reduce pretty much anything to. Now, it's evident enough that such a linearisation, if possible, tends to make hard things easier. Find a Hilbert space hidden in your domain, obtain an orthonormal basis, and bam , any point/state can be described as a mere sequence of numbers, any mapping boils down to a matrix; we have some good theorems for existence of inverses / eigenvectors/exponential objects / etc.. So, LA sure is convenient . OTOH, it seems unlikely that any nontrivial mathematical system could ever be said to be thoroughly understood . Can't we always find new questions within any such framework that haven't been answered yet? I'm not firm enough with Gödel's incompleteness theorems to judge whether they are relevant here. The first incompleteness theorem says that discrete disciplines like number theory can't be both complete and consistent. Surely this is all the more true for e.g. topology. Is LA for some reason exempt from such arguments, or does it for some other reason deserve to be called the best understood branch of mathematics?","['incompleteness', 'linear-algebra', 'soft-question']"
1700801,100th derivative of $\frac{1+x^2}{1+\tan^2(x)}$ at point 0,"$$\frac{\mathrm d^{100}}{\mathrm dx^{100}}\frac{1+x^2}{1+\tan^2(x)}$$
Without Taylor
Is there a way to solve this problem by using General Leibniz rule. I tried but numerator make problem.","['derivatives', 'real-analysis', 'calculus']"
1700808,Corollary of Monotone Convergence Theorem,"Let $(g_n)$ be a sequence in $M^+$, then $\int \left(\sum_{n=1}^\infty g_n\right)d\mu=\sum_{n=1}^\infty\left(\int g_nd\mu \right)$ proof: Let $f_n=g_1+\cdots+g_n$, then $f_n$ is a monotone increasing sequence of functions in $M^+$. I wan t use Monotone Convergence Theorem but I don't know how to guarantee that $f_n$ converges to $f=\lim_{n\to \infty}\sum_{i=1}^n g_n=\sum_{i=1}^{\infty}g_n$.",['measure-theory']
1700995,What is the significance of these two functions' relationship?,"I noticed that the graph of $x^2$ looked somewhat like $\sin(x)$, so I tried to ""recreate"" $\sin(x)$ using it. $-(-1)^{\lfloor x/2\rfloor}\cdot(x-2\cdot\lfloor x/2\rfloor-1)^2 + (-1)^{\lfloor x/2\rfloor}$ Anyway, that equation came from me trying to take the lower parts of $x^2$ (between -1 and 1) and squish them together, alternating positive and negative. Graph it and you'll see what I mean. Anyway, it didn't quite match up with $\sin(x)$, which wasn't surprising. The wavelength was all wrong. But if I do $\sin(\frac{x\pi}{2})$, the wavelength matches perfectly. To my dismay, the functions are not identical. $\sin(x)$ is always a bit closer to zero (except on the turning/inflection points). Still, it's interesting. But is there any inherent relationship here or am I just throwing things together all haphazardly? I feel like something's important because of the $\pi/2$, but then again it might just be something obvious and silly I'm overlooking. Any insights would be terrific. Thank you!","['trigonometry', 'functions']"
1701008,Can anyone explain why commuting matrices share common eigenvector? [duplicate],"This question already has answers here : Matrices commute if and only if they share a common basis of eigenvectors? (5 answers) Do commuting matrices share the same eigenvectors? (8 answers) Closed 8 years ago . If two matrices $A$ and $B$ commute with each other, why would they share some eigenvector? Does that mean that an eigenvector for $A$ is also an eigenvector for $B$ and vice-versa?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1701021,"Integrating, the $\int_0^\infty \frac{\text{ d}x}{x^2\ln x+1}$",I am trying to find a closed form for $$\int_0^\infty \frac{\text{ d}x}{x^2\ln x+1}$$ My usual tactic of partial differentiation under the integral (Mellin) does not work here due to that pesky +1,['integration']
1701055,Hermite Polynomials: Rodrigues to Integral Representation,"I would like to go from this representation of the Hermite polynomials: $$H_n(z)=(-1)^ne^{z^2}\frac{d^n}{dz^n}e^{-z^2} \tag{1}$$ to this representation $$H_n(z)=\frac{2^n}{\sqrt{\pi}}\int_{-\infty}^{\infty}(z+is)^n\,e^{-s^2}\,ds \tag{2}$$ I have tried to use Cauchy's theorem to give the $n^{\textrm{th}}$ derivative term in terms of a contour integral, and then contort the integrand and contour so that we're left with an integral over the real line, but I just can't find a way to do it. I've also read this question , but all of answers go through a different representation/route than the one I desire. Could you help me out? EDIT: To shed some light on what exactly I desire, I will present the first few steps of my attempted path. For an analytic function $f(z)$ , we can express its $n^{\textrm{th}}$ derivative by a contour integral. $$\frac{d^n}{dz^n}f(z)=\frac{n!}{2\pi i}\oint_{\Gamma} \frac{f(w)}{(w-z)^{n+1}} dw $$ Where $\Gamma$ is a simple closed curve that encircles the point $z$ in the complex plane. Using this we can rewrite $(1)$ as $$H_n(z)=(-1)^ne^{z^2}\frac{n!}{2\pi i}\oint_{\Gamma} \frac{e^{-w^2}}{(w-z)^{n+1}} dw$$ I don't know where to go from here. If I make the substitution $s=w-z$ , I end up going in a circle showing that $H_n(z)=H_n(z)$ . Moreover, I can't find a simple way to reduce that integral to an integral over $\mathbb{R}$ (due to the gaussian term in the integral).","['special-functions', 'ordinary-differential-equations', 'complex-integration']"
1701072,Substitution for Trig Integral - GRE Math Subject Test,"Problem Statement : What is the value of $\int_{-\pi/4}^{\pi/4}(\cos t +\sqrt{1+t^{2}}\sin^{3}t\cos^{3}t)dt?$ I am working on an old GRE Math Subject test, and I am having trouble determining which substitution to do for the given integral. With algebraic substitution, I have
$$u = \cos t,\ \ du = -\sin t dt$$
with the resulting integral
$$\sin t - \int \sqrt{1+\arccos^{2}u}\ u^{3}(1-u^{2})du.$$
This seems not to simplify things because of the $\sqrt{1+\arccos^{2}u}$ factor. With trigonometric substitution, we let
$$t = \tan\theta,\ \ dt=\sec^{2}\theta d\theta$$
with the resulting integeral
$$\sin t + \int \sec^{3}\theta\ \sin^{3}(\tan\theta)\cos^{3}(\tan\theta)d\theta.$$
Then if I try to do an algebraic-substitution from here I believe I will result in the original integral... Should I be using integration-by-parts for this integral? I did not try this method because I figured it would be far too complicated, if even possible... Any suggestions for how I should tackle this integral? The correct resulting value is $\sqrt{2}$. Thank you","['gre-exam', 'substitution', 'trigonometry', 'calculus', 'definite-integrals']"
1701142,Associating a $m-1$-tensor on $\mathbb R^m$ to an element of $\mathbb R^m$.,"Show that for every alternating $m-1$-tensor on $\mathbb R^m$ there
  exists a unique $v \in \mathbb R^m$ such that for every linear
  function from $\mathbb R^m$ into $\mathbb R$ and for every $v_1,
 \dots, v_m \in \mathbb R^m$, $(\omega \wedge f)(v_1, \dots,
 v_m)=f(v)\det(v_1, \dots, v_m)$. I have reduced the problem to the following: Show that for every alternating $m-1$-tensor on $\mathbb R^m$ there
  exists a unique $v \in \mathbb R^m$ such that for every linear
  function from $\mathbb R^m$ into $\mathbb R$ , $(\omega \wedge f)(e_1, \dots, e_m)=f(v)$. I have accomplished this, but my proof was very ugly (I calculated the left side using the definition of the wedge product, using the Alt function). I'd like to know if there is a better way to accomplish it. Edit: It's very simple to prove this result if there is an easy way to prove that $(\phi_1\wedge\dots\wedge \phi_{k-1}\wedge \phi_{k+1}\wedge \dots \wedge\phi_m\wedge f)(e_1, \dots, e_m)=f(e_k)$, where the $\phi_i(e_j)=\delta_{ij}$. Is there an elegant way to show this?","['tensor-products', 'linear-algebra', 'multilinear-algebra']"
1701189,Is a ring a set?,"We know that a ring consists of a set equipped with two binary operations. My question is whether a ring is a set or not. For example, we can have $(\mathbb{R},+,-)$ where $\mathbb{R}$ is a set and $+$ and $-$ are binary operations associated with the set. Note that binary operations are functions, and functions are set, so we have a 3-tuple consisting of three sets. My first question is whether this tuple itself is a set? i.e. what exactly is a tuple? In addition, the problem is I am not comfortable with defining ring as something with soemthing else. What exactly does it mean by ""with""? (for example, is it a union?) it just seems overly informal. Any help is apprecaited.","['abstract-algebra', 'ring-theory', 'elementary-set-theory']"
1701261,How to determine if a probability problem has a binomial distribution or not?,"I'm studying for my Stats midterm and I am confused about the binomial distribution concept. Among these 2 problems, why does the second question have a binomial distribution and not the first question? 1) In a large 2 lb bag of candies, 15% of the candies are green. The chances of pulling out at least one green candy in three tries is... 2) An owner suspects that only 5% of the customers buy a magazine and thinks that he might be able to use the display space to sell something more profitable. What is the probability that exactly 2 of the first 10 customers buy magazines? We already know about SPIN: S(Success/Failure) P(Probability) I(Independent) N(Fixed number of trials) and I'm curious as to why SPIN doesn't apply to the first problem as well? Any help would be appreciated. Thank you.","['statistics', 'probability-distributions']"
1701276,"Probability: mathematically what does it mean to say ""let $X$ be a random variable WITH a cdf/pdf""","I don't quite understand what people mean by let ""$X$ be a random variable WITH a cdf/pdf"". For example, there is a question that says: ""Let X be a random variable with the 3-parameter Weibull pdf and cdf"" Suppose I say: Let $X$ be a random variable with Gaussian CDF. What does that mean exactly? $X$ is a function that maps from the event space to a real number. What does it mean to ""connect"" it, ""link"" it, ""equip"" it, WITH a CDF? It is already a function, what does it mean to let it hook up with another function, why don't we just deal with $X$ directly. Then I look at the CDF: $f_X(x) = \int_A \exp(-x^2/2)dx$ I ask myself: Is ""$\exp(-x^2/2)$"" part the random variable? No. Is ""$\int_A \exp(-x^2/2)dx$"" the random variable? No. Is little $x$ is the random variable? No. What is the difference if I wrote $f(x)$ instead of $f_X(x)$? Nothing happens. What does the CDF/PDF have to do with the random variable exactly? How do you know which CDF/PDF a random variable ""has""?","['random-variables', 'terminology', 'probability', 'soft-question', 'definition']"
1701284,Show that there does not exist any analytic function for which $f\left(\dfrac{1}{n}\right)=\dfrac{1}{2^n}$,"Show that there does not exist any analytic function $f$ on the open  disc for which $f\left(\dfrac{1}{n}\right)=\dfrac{1}{2^n}$.$\forall n\in \Bbb N$ Suppose such a function say $f$ exists then $f\left(\dfrac{1}{n}\right)=\dfrac{1}{2^n}$.
By continuity of $f$ we have $\lim _{n\to \infty}f\left(\dfrac{1}{n}\right)=\lim_{n\to \infty}\dfrac{1}{2^n}\implies f(0)=0$ Also $f$ has a power series representation about $0$ i.e $f(z)=\sum_{n=0}^\infty \dfrac{f^n(0)}{n!}z^n;\forall z\in D$ where $D$ is open disc. But I am failing to arrive at a contradiction from here.Please give some hints.","['complex-analysis', 'analytic-functions']"
1701320,Bounded Operators: Topological Dual,"Given Hilbert spaces $\mathcal{H}$ and $\mathcal{K}$. Consider the bounded operators:
$$\mathcal{B}(\mathcal{H},\mathcal{K}):=\{T:\mathcal{H}\to\mathcal{K}:\|T\|<\infty\}$$ Regard the linear functionals:
$$l_{(\varphi,\psi)}T:=\langle T\varphi,\psi\rangle_\mathcal{K}:\quad|l_{(\varphi,\psi)}T|\leq\|\varphi\|_\mathcal{H}\|\psi\|_\mathcal{K}\cdot\|T\|$$ Do these exhaust its topological dual:
$$\mathcal{B}(\mathcal{H},\mathcal{K})'=\overline{\langle\{l_{(\varphi,\psi)}:(\varphi,\psi)\in\mathcal{H}\times\mathcal{K}\}\rangle}$$ (I'm wondering about this already for some time.)","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
1701331,How do people calculate values for trig functions?,"This may sound like a stupid question, but I'm wondering how people originally calculated specific values for trig functions before calculators existed. Did they just draw circles and manually measure the ratios, or was there some more clever method they could use?","['numerical-methods', 'math-history', 'trigonometry']"
1701333,Evaluate $\int_a^{2a}\sqrt{2ax-x^2}\:dx$ where $a$ is a constant.,"Evaluate $$\int_a^{2a}\sqrt{2ax-x^2}\:dx$$ where $a$ is a constant. I used substitution, $x=a(1-\sin k)$ . This is my working But I think I made some mistake since answer isn't correct. Please help.","['integration', 'definite-integrals', 'calculus']"
1701344,Show $\binom{a}{b}\binom{b}{c}=\binom{a}{a-c}\binom{a-c}{a-b}$,"I am trying to give a non-algebraic proof for this equality: $$\dbinom{a}{b}\dbinom{b}{c}=\dbinom{a}{a-c}\dbinom{a-c}{a-b}$$ So far, I could only use the identity $\dbinom{x}{y}=\dbinom{x}{x-y}$. What I got is $\dbinom{a}{a-c}\dbinom{a-c}{a-b}=\dbinom{a}{c}\dbinom{a-c}{b-c}$. But I don't think I have made any progress from there. It seems reasonable if we think about the identity, but I just find it difficult to give a proper proof for it. Thanks for the help.","['combinatorics', 'proof-writing', 'binomial-coefficients', 'alternative-proof']"
1701359,Laplace transformations on a homogeneous ODE,"$$y^{\prime\prime} - 3y^{\prime} + 2y = 0$$ $y(0) = 14$, $y^{\prime}(0)=0$, and using the Laplace transformation I'm trying to solve this IVP","['laplace-transform', 'ordinary-differential-equations', 'calculus']"
1701363,Solve $ 6\sin^2(x)+\sin(x)\cos(x)-\cos^2(x)=5 $,"Question: Solve $$ 6\sin^2(x)+\sin(x)\cos(x)-\cos^2(x)=5 $$
  $$ 0 \le x \le  360^{\circ} $$ My attempt: $$ 6\sin^2(x)+\sin(x)\cos(x)-\cos^2(x)=5 $$ $$ 6(\frac{1}{2} - \frac{\cos(2x)}{2}) + \sin(x)\cos(x) -(\frac{1}{2} + \frac{\cos(2x)}{2}) = 5 $$ $$ 3 - 3\cos(2x)+ \sin(x)\cos(x) - \frac{1}{2} - \frac{\cos(2x)}{2} = 5$$ $$ \frac{7\cos(2x)}{2}  - \sin(x)\cos(x) + \frac{5}{2} = 0 $$ $$ 7\cos(2x) - 2\sin(x)\cos(x) + 5  = 0 $$ $$ 7\cos(2x) - \sin(2x) + 5 = 0 $$ So at this point I am stuck what to do, I have attempted a Weierstrass sub of $\tan(\frac{x}{2}) = y$ and $\cos(x) = \frac{1-y^2}{1+y^2}$ and $\sin(x)=\frac{2y}{1+y^2} $ but I got a quartic and I was not able to solve it.",['trigonometry']
1701401,"$f(x)\geq 0$, $f^{\prime}(x)>0$ and $\frac{f(x)}{f(\frac{x}{2})}=a$, where $a$ is a fixed constant value. Only $f(x)=x^{b}$ be possible?","I meet one problem. The function $f(x)$ satisfies $f(x)\geq 0$, $f^{\prime}(x)>0$ and $\frac{f(x)}{f(\frac{x}{2})}=a$, where $a$ is a fixed constant value. It is easy to see $f(x)=x^{b}$ and $a=2^{b}$ meet these conditions. The question is there any other function satisfies these conditions ?",['functions']
1701406,Isaacs FGT Problem 5B.1,"I am trying to solve Isaacs' Theory of Finite Groups problem 5B.1.
Let $G$ be finite and suppose that $P\in Syl_p(G)$ and that $g\in P$ has order $p$ . If $g\in G'$ , but $g\notin P'$ , show that $g^t\in P'$ for some element $t\in G$ with $t\notin P$ . Following the indication, I have applied the transfer evaluation theorem: Let $v:G\rightarrow P/P'$ be the transfer map and $T$ a right transversal for $P$ in $G$ . Then $$v(g)=P'\prod_{t\in T_0}tg^{n_t}t^{-1}$$ where $T_0\subset T$ , $n_t|o(g)$ , $\sum_{t\in T_0}n_t=[G:P]$ and $tg^{n_t}t^{-1}\in P$ .
Since $o(g)=p, n_t=1$ or $p$ . As $g^p=1$ , it follows that $v(g)=P'\prod_{t\in T_0}tgt^{-1}$ . Since $g\in G'$ , $g\in\ker v$ and so $\prod_{t\in T_0}tgt^{-1}\in P'$ .
Now I need to show that one of the $tgt^{-1}$ belongs to $P'$ .","['finite-groups', 'abstract-algebra', 'group-theory']"
1701418,Evaluate $\int_0^1\int_0^1 \left\{ \frac{e^x}{e^y} \right\}dxdy$,"I want compute this integral $$\int_0^1\int_0^1 \left\{  \frac{e^x}{e^y}  \right\}dxdy, $$ where $ \left\{ x \right\} $ is the fractional part function . Following PROBLEMA 171, Prueba de a) , as detailed in the last paragraph of page 109 and the first two paragraphs of page 110, here in Spanish , I solve for the case $k=1$ . When I substitute $x=\log u$ and $y=\log v$ , then I can show that $$\int_0^1\int_0^1 \left\{  \frac{e^x}{e^y}  \right\}dxdy=\int_1^e\int_1^e \left\{  \frac{x}{y}  \right\}\frac{1}{xy}dxdy=I_1+I_2$$ by following the strategy in the cited problem. Now take $t=\frac{1}{u}$ , $$I_1:=\int_1^e\int_1^x \left\{  \frac{x}{y}  \right\}\frac{1}{xy}dydx=\int_1^e\frac{1}{x}\int_{\frac{1}{x}}^1 \left\{  \frac{1}{t}  \right\}\frac{dt}{t}dx=\int_1^e\int_1^x\frac{ \left\{ u \right\} }{u}dudx,$$ and if there are no mistakes, we have $$ \int_1^x\frac{ \left\{ u \right\} }{u}du =
\begin{cases}
x-1-\log x,  & \text{if $1\leq x<2$} \\
1+\log 2+(x-2)-2\log x, & \text{if $2\leq x\leq e$}
\end{cases}$$ thus, $$I_1=\int_1^2\frac{1}{x}(x-1-\log x)dx+\int_1^2\frac{1}{x}(1+\log 2+(x-2)-2\log x)dx,$$ As such, $I_1=-3+\log 2-\frac{\log^22}{2}+e$ . On the other hand, if we follow the cited problem, then since $y>x$ , we have $ \left\{ \frac{x}{y} \right\}=  \frac{x}{y}$ and the second integral is computed as follows: $$I_2:=\int_1^e\int_x^e \left\{  \frac{x}{y}  \right\}\frac{1}{xy}dydx=\int_1^e\int_x^e  \frac{x}{y} \frac{1}{y^2}dydx.$$ Thus, $I_2=\frac{1}{e}$ . Question. I would to know if my computations with the fractional part function $ \left\{ x \right\} $ were right (the evaluation of $ \int_1^x\frac{ \left\{ u \right\} }{u}du$ and $I_1$ ). Can you compute $$\int_0^1\int_0^1 \left\{  \frac{e^x}{e^y}  \right\}^kdxdy$$ for the case $k=1$ ? (At least this case to see it as a proof verification of my computations; your are welcome if you provide us similar identities for integers $k\geq 1$ , as in the cited problem). Thanks in advance.","['fractional-part', 'closed-form', 'multivariable-calculus', 'integration', 'solution-verification']"
1701452,Is it true that $P(A|B)+P(A|\overline B) = 1$?,"tl;dr $P(A|B) + P(A|\overline B)=1$. My question is, is this true? More detail The book I'm reading (Statistics for Business and Economics, Paul Newbold et al) has this example (paraphrased a little). 10% athletes have used performance enhancing drugs. A test is available that correctly identifies an athlete's drug usage 90% of the time. If an athlete is a drug user, the probability is 0.9 that the athlete is correctly identified by the test as a drug user. Similarly is not a drug user, the prob is 0.9 that the athlete is correctly identified as not using drugs. So this is fine so far. From this I'd get the following: Let D = athlete is a drug user, + = test calls positive, - = test calls negative $ \begin{align}
   P(D) &= 0.10  \implies P(\overline D)\\
   P(+|D) &= 0.90 \\
   P(-|\overline D) &= 0.90
  \end{align}
$ Where the example looses me is that it says that the following can also be defined from the above information... $ \begin{align}
   P(+|\overline D) &= 0.10 \\
   P(-|D) &= 0.10
  \end{align}
$ And this is where I'm struggling... it seems that they can only be getting this by assuming $P(+|D)+P(+|\overline D)=1$, or more generally $P(A|B) + P(A|\overline B)=1$. My question is, is this true? Here's what I've tried so far to see if it is true... $
\begin{align}
P(A|B)+P(A|\overline B) &= \frac{P(A \cap B)}{P(B)} + \frac{P(A \cap \overline B)}{P(\overline B)}\\
&= \frac{P(A \cap B)P(\overline B) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)} \\
&= \frac{P(A \cap B)(1-P(B)) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)}\\
&= \frac{P(A \cap B) - P(A \cap B)P(B) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)}\\
&= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{P(A \cap \overline B) - P(A \cap B)}{P(\overline B)} \\
&= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{P(A \cap \overline B) - (1 - P(A \cap \overline B))}{P(\overline B)} \\
&= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{2\cdot P(A \cap \overline B) - 1}{P(\overline B)} \\
&= \frac{P(A \cap B)}{P^2(B)} + \frac{2\cdot P(A \cap \overline B) - 1}{P(\overline B)} \\
&= ?????
\end{align} 
$ And then stuck... can't see how this is true. And looking at a Venn diagram representation it didn't enlighten me... any thoughts on how this question's answer in the book is making the assertions it is? Many thanks.","['bayes-theorem', 'statistics', 'probability']"
1701470,Limit of ratio of exponential function as variable tends to infinity:$\lim_{x\to \infty}\frac{e^x}{e^{x^2}}$,"Could someone please point out resources or provide the solution with detailed steps to calculate the following limits? If possible, please provide solutions with or without using L'Hopital's rule. $$
\underset{x\rightarrow\infty}{\lim}\left[\frac{e^{x}}{e^{x^{2}}}\right]
$$ Thanks,","['real-analysis', 'limits-without-lhopital', 'limits']"
1701540,$n^{th}$ derivative of $\cot x$,What is the $n^{th}$ derivative of $\cot(x)$? I tried to differentiate it may times: I can't see a pattern forming. Please help.,"['derivatives', 'calculus']"
1701548,Does ZFC decide every question about finitely generated groups?,"In ZFC, we can easily say when a triple $\mathscr{G}=\left\langle G,\cdot,1 \right\rangle $ is a group. Furthermore, we can say when a group is finitely generated: First define a ""canonical"" finitely generated group on $n$ generators by taking the set  of all finite ordered tuples of elements from a fixed set of size $n$ (""words in these elements""), and defining the usual equivalence relation that will make the set of equivalence classes into a group. Second, a f.g. group will be a group isomorphic to some quotient of that canonical f.g. group (I believe we can say all this in ZFC, please correct me if I'm mistaken). So now the question is - will every statement about f.g. groups be decidable in ZFC? Put differently - can any statement about these groups be independent of ZFC?
What about finitely presented groups (where the the group in the quotient is itself f.g.)? For reference, I think of Whitehead's problem that was shown by Shelah to be independent of ZFC. The main difference is that here we are dealing with things that have some finiteness in them, so it is less clear to me whether they can be so manipulated.","['finitely-generated', 'set-theory', 'group-theory']"
1701563,Range of a function using graph,"If we are given a function $$y = \frac{x-1}{x+2}$$ and we have to find the range . So I tried, I wrote
$$y = 1 - \frac3{x+2}$$
$$y-1 = \frac{-3}{x-2}$$
We know this is an equation of rectangular hyperbola , but 
how can I find range using its graph?","['functions', 'graphing-functions']"
1701581,Can you factor our terms while calculating a limit which *might* equal 0 along some paths?,"Suppose I am solving the following limit: $$\lim_{(x,y)\rightarrow(1, -1)} \frac{x^2 - y^2}{x^3 + y^3}$$ I begin by factorizing as follows: $$\lim_{(x,y)\rightarrow(1,-1)} \frac{(x+y)(x-y)}{(x+y)(x^2-xy+y^2)}$$ And then I am tempted to factor out $(x+y)$ from the numerator and denominator: $$\lim_{(x,y)\rightarrow(1,-1)} \frac{(x-y)}{(x^2-xy+y^2)}$$ Normally when factoring out the terms we must check that they do not equal zero. Sometimes in the context of limits though, we can disregard this concern if the term being factored out is only approaching zero without ever reaching it. However in the example above it seems that we must still consider this, since if we approach $(1,-1)$ along the line $x = -y$, then the term $(x + y)$ does indeed equal 0, even before it reaches the origin. What is going on here? 1) When evaluating the limit in $\mathbb{R}^2$, do we only care about approach paths which are actually defined as the approach the point in question? (the path $(x = -y)$ in this case is undefined at all points!) 2) Does the existence of this approach path for which a limit doesn't exist (because nothing on that path is defined anyway!) mean that the limit itself at that point doesn't exist?","['multivariable-calculus', 'limits']"
1701626,Mean of $ \sum (X_i - \bar{X})^2$,"If $X_1,...,X_n$ are iid, what is the mean of the following variable:? $ \sum (X_i - \bar{X})^2$ I know the answer is $\sigma^2(n-1)$, but how is this calculated in general? If I expand, I get the variables squared, and that turns quite ugly. What's the trick here?","['probability', 'expected-value']"
1701627,What is the probability of dealing all $52$ cards in a standard well shuffled deck getting a single quad?,"I would like to know if you take a well shuffled deck of $52$ cards and then deal out all of them one at a time without replacement, what is the probability that they will be dealt such that there is exactly one quad dealt in order such as $4$ consecutive kings?  That run of $4$ has to be the only run of that length, there cannot be any others.  For example, 5, ... ,K,K,K,K,7,J,J,J,J is a ""loser"".  Other than computer simulation I am not sure how to solve this.","['inclusion-exclusion', 'probability']"
1701633,"arrangement of the word $""\bf{MATHEMATICS}""$ in which no two same letter occur together.","Total number of arrangement of the word $""\bf{MATHEMATICS}""$ in which no two same letter occur together. $\bf{My\; Try::}$ Here word contain $\bf{2M,2A,2T,H,E,I,C,S}$ So first we will arrange $\bf{H,E,I,C,S}$ as $\bf{5!}$ ways $$\bf{-H-E-I-C-S-}$$ No we have $6$ gap and we can arrange $\bf{2M,2T,2A}$ as $\displaystyle \frac{6!}{2!\cdot 2!\cdot 2!}$ So total number of ways is $\displaystyle \bf{5!\times \frac{6!}{2!\cdot 2!\cdot 2!}}$ Is my solution is right, If not then how can we calculate it. Help me Thanks",['combinatorics']
1701674,100th derivative of $(1-2x)^{2/3}$ at point $x=0$,"$$\frac{\mathrm d^{100}}{\mathrm dx^{100}} (1-2x)^{2/3}$$
Without Taylor. I relay don't have any idea how to use General Leibniz rule in this case.","['derivatives', 'real-analysis', 'calculus']"
1701702,Prove that the determinant is a multiple of $17$ without developing it,"Let, matrix is given as :
$$D=\begin{bmatrix}
1 & 1 & 9 \\
1 & 8 & 7 \\
1 & 5 & 3\end{bmatrix}$$ Prove that the determinant is a multiple of $17$ without developing it? I saw a resolution by the Jacobi method , but could not apply the methodology in this example.","['matrices', 'determinant', 'linear-algebra', 'divisibility']"
1701791,Homogeneity lemma in point set topology,"The statement is simple: For all $x\in \operatorname{int} D_n:=\{x\in\Bbb R^n: \| x \|<1\}$, there exists a homeomorphism $h$ on $D_n$ such that $h(0)=x$ and $h$ does not move the points of $S_{n-1}$. This somehow reminds me of the sound wave pattern present in the Doppler effect: Perhaps I can accordingly construct an explicit homeomorphism mapping? But it's a very vague and naive idea, and doesn't seem to help me in any practical way. If an explicit homeomorphism is not to be easily found, then is there any intuitive (and rigorous and convincing, of course) way to tackle this seemingly simple problem? (When I search for a proof, I find that most results are actually not what I want, rather, they seem relevant to another lemma (under the same name) in differential topology/geometry, of which I know nothing.) Ps: the following theorem might be related (but I don't know how): Any closed, convex ""volume"" (I don't know the terminology; put simply, something solid and has a volume) in $\Bbb R^n$ is homeomorphic to $D_n$.","['general-topology', 'geometry']"
1701795,An infimum of a double integral on the unit disk,"The following question comes from Arnold's Trivium of $1991$ and it is problem $68$. I do not have a solution neither can I come up with something. Find $$\inf  \iint \limits_{x^2+y^2 \leq 1} \left[ \left ( \frac{\partial u}{\partial x} \right)^2 + \left ( \frac{\partial u}{\partial y} \right )^2 \right ]\, {\rm d}x \, {\rm d}y$$ for $C^{\infty}$ functions $u$ that vanish at $0$ and equal $1$ on $x^2+y^2=1$.","['multivariable-calculus', 'contest-math', 'real-analysis']"
1701863,"$E(2\xi_1\mid\xi_1, \xi_1+\xi_2)$.","If $\xi_1$ and $\xi_2$ are independent identically distributed random variables with $P(\xi=1)=P(\xi=-1)=1/2$ Find $E(2\xi_1\mid\xi_1, \xi_1+\xi_2)$. I don't understand what the notation $\xi_1, \xi_1+\xi_2$ means in this context. I read something about it being a decomposition induced by random variables, but it wasn't really helpful.",['probability-theory']
1701914,Functional equation with sqrt solutions [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Let $f:(0,\infty)\to(0,\infty)$ so that for all $x,y\in(0,\infty)$ we have $$f\left(\frac {x} {f(y)}\right)=\frac {x} {f(x\sqrt y)}.$$ Find function $f$.","['functions', 'functional-equations']"
1701923,Finding function for capital interest,"Haven't fully grasped derivatives and I believe this question really holds the gist of it Your bank account has a continuous capital interest rate of 7%. The formula for this is $$\frac{dB}{dt} = 0.07B$$ where B stands for balance. I'm probably reading this wrong, but here's what I read: The change in your balance over time is 0.07B Shouldn't there be a $t$ factor on the RHS? i.e. $$0.07Bt$$","['derivatives', 'integration', 'calculus']"
1701935,"Let $a_n=\cos(a_{n-1}), L=[a_1,a_2,...,a_n,...].$ Is there an $a_0$ such that $L$ is dense in$[-1,1]?$","I've been experimenting with recursive sequences lately and I've come up with this problem: Let  $a_n= \cos(a_{n-1})$ with $a_0 \in \Bbb{R}$ and $L=[a_1,a_2,...,a_n,...].$ Does there exist an $a_0$ such that $L$ is dense in $[-1,1]?$ I know of $3$ ways of examining whether a set is dense: $i)$The definition, that is, whether its closure is the set on which it is dense, in our case this means if: $\bar L=[-1,1]$. ii)$(\forall x \in [-1,1])(\forall \epsilon>0)(\exists b \in L):|x-b|<\epsilon$ $iii)$ $(\forall x \in [-1,1])(\exists b_n \subseteq L):b_n\rightarrow 
x$ So far I haven't been able to use these to answer the question. I tried plugging in different values of $a_0$ and see where that leads but I have not found any corresponding promising ""pattern"" for $a_n$. Any ideas on how to approach this?","['real-analysis', 'sequences-and-series']"
1701936,Distribution of final digits of consecutive primes,"There's been a lot in the press recently about the unexpected distribution of final digits in pairs of consecutive primes , and many people have written programs to confirm the observation that pairs with the same last digit are relatively uncommon. But this heatmap shows a curious (near-)symmetry about one of the diagonals, when comparing the probabilities: is this unexpected too or is there a simple explanation (or mistake) I'm missing? i.e. the probability of a 7 followed by a 1, P(7,1) is close to the probability P(9,3); P(1,3) is close to P(7,9), etc. How is it that the probabilities are similar when considering pairs of last-digit pairs differing by the same number (mod 10) (e.g. 1-7 = 3-9, 3-1 = 9-7).","['number-theory', 'prime-numbers']"
1701954,Density of sets whose image is dense.,"This is probably easy, but I can't think of an answer. Assume $X$ is a Banach space and $A$ is a (not assumed closed) subspace of $X$. Let $T:X \to X$ be a bounded operator, which is also injective. If $T(A)$ is dense in $X$, does it follow that $A$ is dense in $X$?","['functional-analysis', 'operator-theory']"
1701960,Largest prime gap under $2^{64}$,"Thanks to Tomás Oliveira e Silva's extensive calculations, it is known that the largest prime gap less than $4\cdot10^{18}\approx2^{61.8}$ is 1476. I'd like an upper bound for the largest prime gap less than $2^{64}$ . I know it will be horrifically large, but I'm hoping that more can be done than the best I know: $$
\left\lfloor\frac{2^{64}}{25\log^2(2^{64})}\right\rfloor=374946102691094
$$ due to [1]. As DanaJ suggested in the comments, this can be improved by a result of Axler [2]. In fact Büthe [3] improves on both for this range, reducing the bound to 672606194883. Note: When I write ""the largest prime gap less than $x$ "" I mean ""the largest $q-p$ where $p$ and $q$ are consecutive primes and $p<x$ "". [1] Pierre Dusart, Estimates of Some Functions Over Primes without R.H. (2010) [2] Christian Axler, New bounds for the prime counting function π(x) (2014) [3] Jan Büthe, Estimating π(x) and related functions under partial RH assumptions (2014)","['number-theory', 'prime-gaps', 'computational-mathematics', 'prime-numbers']"
1701970,Writing a Hilbert C*-submodule of $L^2(X)$ as an integral sum over Hilbert subundles,"In Ergodic Theory, some (though not all) presentations of compact extensions use Hilbert bundles.
Given $(X,\mathcal{B},\mu,T)$ and a sub $\sigma$-algebra $\mathcal{G}\subseteq\mathcal{A}$ one has an associated factor map $\pi:(X,\mu,T)\to (Y,\nu,T)$ (where $\pi(x)=\pi(x')$ iff ($x\in A\leftrightarrow x'\in A$) for every $A\in\mathcal{G}$) and a decomposition $\mu=\int\mu_yd\nu$ (where $\nu=\pi_*(\mu)$). Then one can informally think of the space of functions in $L^2(X,\mu)$ as an ""integral"" over the spaces of functions $H_y:=L^2(X,\mu_y)$ for $\nu$-a.e. $y$. Moreover, the union $\coprod_yH_y$ defines a Hilbert bundle over $Y$ (of course, $Y$ a priori has no topological structure, so this is not strictly precise).
This is the approach taken in these notes by Yuri Lima and in Ch. 9 of Glasner's book, for instance. One then considers $L^\infty(Y)$-submodules (i.e. closed $L^\infty(Y,\nu)$-invariant subspaces) of $L^2(X,\mu)$. Now, here comes my problem. In proving many of the properties that one wants to prove for any such submodule $M$ (I won't go into these details or into compact extensions themselves) the authors usually consider the collection of $\{M_y\}_{y\in Y}$, which are thought of as closed subspaces of the $H_y$ defined above (i.e. $\{M_y\}_{y\in Y}$ is a subbundle of the Hilbert bundle). If $f\in M$, then $f_y$ is in $M_y$, where $f_y$ is just $f$ ""seen"" as an element of $L^2(X,\mu_y)$ instead of $L^2(X,\mu)$ (warning: this is not the conditional expectation $\mu_y(f))$. For instance, if we fix topological models such that $X=Y\times U$ then $f_y=f(y,\cdot)$ The problem is that $f$ is not a function, it is an equivalence class of functions. Certainly, for a fixed $f\in L^2(Y\times U)$ the function $f_y=f(y,\cdot)$ is defined for $\nu$-a.e. $y$. But that doesn't mean we can actually define a map $M\mapsto \{M_y\}_{\nu\text{-a.e.} y}$ for any closed subspace $M$, since such subspaces have uncountably many $f$'s. Question: Is there a way around this technical problem?","['functional-analysis', 'ergodic-theory', 'measure-theory']"
1701974,Differentiability class of Matern function (based on Modified Bessel Function of second kind),"I am working on some techniques using the Matérn covariance function: $h(r) = \frac{2^{1-\nu}}{\Gamma(\nu)}\Bigg(\sqrt{2\nu}\frac{r}{\rho}\Bigg)^\nu K_\nu\Bigg(\sqrt{2\nu}\frac{r}{\rho}\Bigg)$ with $r\in\mathbb{R}^+$ and $\nu\in\mathbb{R}^+$. For some reasons, I am looking at the continuity properties of this function wrt to $\nu$. By studying the first and second derivatives of it wrt $r$. I can show that  these derivatives are continuous on $\mathbb{R}^+$ if $\nu>1$. The idea now is to find the full continuity properties wrt to $\nu$. For doing this I am looking on some recurrence relations on the derivatives of $K_\nu(x)$ or $x^\nu K_\nu(x)$ wrt $r$.","['derivatives', 'continuity', 'bessel-functions']"
1701989,How does the formula for length of a graph relate to that of parametric description?,"So I know how to solve for the length of a regular graph and for a parametric description. Regular graph length formula: $$L = \int_{x=a}^{x=b}\sqrt[]{1 + (f'(x))^2} \,\,\,dx$$ Parametric description length formula: $$\int_{t = a}^{t=b} \sqrt[]{(x'(t))^2+(y'(t))^2} \,\,\,\,dt$$ The form of these two are so radically different that I can't see how one relates to the other. The parametric description uses the form for path velocity but I don't understand why.. If more elaboration is needed, please ask. I'll supply. Highly appreciated, -Bowser",['trigonometry']
1702009,When do you use differential equations?,"I have a problem whose answer I find rather questionable in my textbook. A psychologist has determined that the initial probability of success for a given exam is 0.02, and that the maximum amount learned is 0.86. After studying 1 month, probability of success increases to 0.23 Within how many months studying will the probability reach 0.70? The answer to this exercise is formulated as a differential function. I do not see the need to differentiate as there is no indication of non-linearity. Can't I simply go $$\frac{0.23 - 0.2}{1\text{ (month)}}$$ Rate of learning is $0.21/\text{month}$, so it will take $$\frac{0.70-0.2}{0.21} = 3.24$$ months to reach 0.70. How is this process incorrect?","['ordinary-differential-equations', 'calculus']"
1702035,Applications of Derivatives problem,"$$f(x) = x^3 + ax^2 + bx + 5\sin^2x $$
is an increasing function on the set $R$. Then $a$ and $b$ satisfy: $a^2 - 3b - 15 > 0$ $a^2 - 3b + 15 > 0$ $a^2 - 3b + 15 < 0$ $ a> 0$ and $b > 0$ I know I have to differentiate the function but I am unable to solve the equation due to the $\sin^2x$ term I get after differentiating.","['derivatives', 'functions']"
1702041,How to prove convergence of process and stopping time,"We consider the random function $X^n=(X^n_t)_{t\geq 0}$ with values in the Skorokhod space $\mathcal{D}$ of càdlàg paths, and suppose that it weakly converges (i.e in distribution) to $X=(X_t)_{t\geq0}$ as $n\rightarrow \infty$. If we define the first passage time to level $x\in\mathbb{R}$, by:
$$\tau_x(Y)=\inf\{t\geq 0 : Y_t\geq x\},$$
for any random function $Y$ with values in $\mathcal{D}$, I would like to prove that $(X^n,\tau_x(X^n))$ weakly converges to $(X,\tau_x(X))$ as $n\rightarrow \infty$. I am wondering if there is already an existing result in the literature of weak convergence of stochastic processes, or if there is any result (possibly under more restrictive assumptions) which enables one to prove joint weak convergence? Any ideas or references to the literature would be greatly appreciated. update: My general idea about how to proceed is to use something along the lines of: if $X^n$ weakly converges to $X$ as $n\rightarrow\infty$, then we should expect  $(X^n,f(X^n))$ to weakly converge to $(X,f(X))$ as $n\rightarrow \infty$ for any measurable $f$, and apply this to the case of the first passage time, but I am not sure whether this is entirely rigorous?","['stochastic-processes', 'probability-theory', 'weak-convergence', 'stochastic-analysis', 'convergence-divergence']"
1702076,How to integrate $\int_{\theta_0}^{\pi} \sqrt{\frac{(1-\cos \theta)}{(\cos \theta_0 - \cos \theta)}}d\theta$?,"I was wondering if you could solve this integral for me. It is part of a much larger problem, and I can't seem to solve it at all. I know that the answer should be some constant. Thanks in advance! $\int_{\theta_0}^{\pi} \sqrt{\frac{(1-\cos \theta)}{(\cos \theta_0 - \cos \theta)}}d\theta$ I have tried substituting $u = \cos \theta$. However, this did now work since one of the limits of integration then depends on $\theta_0$.","['definite-integrals', 'integration', 'trigonometry']"
1702099,Why this equation does not develop a boundary layer?,"The equation I am talking about is
$$
\epsilon  y''(x)+y(x)+1=0,y(0)=0,y(1)=1
$$ The $+1$ is not essential as $y(x)$ can be decomposed into $1 + y_1$, but is kept here for a more direct comparison with the other example below. This equation takes a more innocent look if multiplied by $1/\epsilon $ that yields $y''(x) + 1/ \epsilon  y(x) + 1/\epsilon = 0$, sine/cosine function follows (the figure below shows solution with $\epsilon $ = 0.01, which corresponds to a period $2 \pi \sqrt{\epsilon} = 0.62$). Some may say as $\epsilon $ decreases, the frequency gets higher and the curve get steeper, but there is no boundary layer for at least two reasons: first, this is a global behavior; second, typical boundary layers has an exponential rate of change that limit it to a narraw region (then merges smoothly with the outer solution). The example to be compared against is one with the second term $y(x)$ replaced by $y'(x)$, clearly boundary layer develops (figure also uses $\epsilon = 0.01$). Buy why? The only distinction is there is no first order term in the first equation, but this argument appears to be very superficial.","['ordinary-differential-equations', 'perturbation-theory']"
1702103,Why is it useful to find the domain and range of a function graph,"I know about domain and range but my professor has asked us why it may be useful to find the domain and range and I cant really think of a reason that would be considered ""useful"". Can anyone think of anything that it can be useful to find domain and range. Maybe just some ideas please of what they may be looking for. Thanks","['algebra-precalculus', 'functions', 'graphing-functions']"
1702123,$(x+1)^2 + (y+1)^2 + xy(x+y+3)=2$,"I've came across this problem some hours ago and, although it looks (and possibly is) just some algebra calculus, I can't get on the right track. Find $x$, $y$ integers such that
  $$ (x+1)^2 + (y+1)^2 + xy(x+y+3)=2 $$ Some basic algebra will lead to: $$
(x+y)^2 + x(xy+2) + y(xy+2) + xy = 0$$
 $$(x+y)(xy+x+y+2)=-xy$$
Now, some divisibility properties should end the problem.
Well, maybe my approach isn't the right one, but I'm just stuck at this point. A piece of advice or a hint would be apreciated.","['algebra-precalculus', 'number-theory', 'square-numbers', 'linear-algebra']"
1702145,Convergence of the alternating series $\sum_{n=1}^\infty \frac{(-1)^n(2n)!!}{(2n+1)!!}$,"I want to find out whether the series $\sum_{n=1}^\infty \frac{(-1)^n(2n)!!}{(2n+1)!!}$ convergent and I know the alternating series test. However, I don't know whether the absolute term converges to 0 or not. I already show that it is not absolutely convergent. Thanks.","['real-analysis', 'convergence-divergence', 'sequences-and-series', 'calculus']"
1702220,Is there an analogue of the open mapping theorem in algebraic geometry?,"Let $f: X \rightarrow Y$ be a dominant map of varieties. What conditions on $X, Y$ and $f$ are necessary to ensure that $f$ is open? EDIT This argument does not work - see the comments: (Clearly, proper is sufficient since a dominant proper map is surjective and thus the image of an open set $U$ in $X$ is the complement in $Y$ of the image of the closed set $X \setminus U$.) So I'm looking for conditions that apply when $f$ is non-proper, so in particular when $X$ and $Y$ are not necessarily projective.",['algebraic-geometry']
1702253,"Shouldn't l'Hopital's rule work for every limit, not just indeterminate forms?","Why does taking the ratio of $f'(x)$ to $g'(x)$ as $x \to a$ give you the correct limit when $f(a)$ and $g(a)$ $= 0, \infty, -\infty$  , but not for other values of $a$? If the rationale for using LHR is that the tangent is the linear approximation of the curve at a point, shouldn't the rule work for all values of $a$?","['derivatives', 'calculus', 'limits']"
1702267,"For every positive integer $n$, $n^2 + n +19$ is prime","I'm trying to prove that for every positive integer $n, n^2 + n +19$ is prime. I tried to disapprove it saying that is is not prime. If it's not prime, then $n^2 + n +19$ has to have at least two factors which are greater than $1$. I'm stuck here. I'm not sure if I'm going in the right direction.","['discrete-mathematics', 'prime-numbers', 'elementary-number-theory']"
1702271,Existence and uniqueness of the eigen decomposition of a square matrix,"I'm confused on the sufficient conditions for the existence and uniqueness of the eigen decomposition of a square matrix. Consider a matrix $A$ of dimension $m\times m$, a matrix $B$ of dimension $m\times m$ and a matrix $D$ diagonal of dimension $m\times m$. Assumption 1 : $B$ invertible Assumption 2 : The diagonal elements of $D$ are all distinct Assumption 3 : $A=BDB^{-1}$ where $B^{-1}$ exists by Assumption 1 Questions : (1) Does Assumption 3 mean that $BDB^{-1}$ is the eigen decomposition of $A$? In other words, does Assumption 3 is equivalent to say that the columns of $B$ are the eigenvectors of $A$ and the diagonal elements of $D$ are the eigenvalues of $A$? Or do we need other assumptions to state that? My doubt is that: if Assumption 3 means that the columns of $B$ are the eigenvectors of $A$ and the diagonal elements of $D$ are the eigenvalues of $A$, then, since $B$ is invertible, it should be that the eigenvectors of $A$ are linearly independent and, hence, that $A$ is invertible (which is not among my assumptions). (2) From what I have read in some sources, Assumptions 2 and 3 imply that the the eigen decomposition of $A$ is unique [up to a left multiplication of $B$ by a invertible diagonal matrix and up to an order for the eigenvalues]. What does ""unique"" exactly mean? My thought was that it means that there are no other matrices $E,F$ with $F$ diagonal such that $A=EFE^{-1}$? But if that is right, the  uniqueness would be necessary to guarantee that the columns of $B$ are the eigenvectors of $A$ and the diagonal elements of $D$ are the eigenvalues of $A$; in other words would be ""embedded"" in saying that $BDB^{-1}$ is the eigen decomposition of $A$. Could you clarify this point?","['matrices', 'eigenvalues-eigenvectors', 'linear-algebra']"
1702282,using L'Hospital solve $\lim_{x \to \infty} x - x^{2}\ln(1 + \frac{1}{x})$,"I can't get this to $ = \frac{0}{0}$ form so I can use l'Hospital rule
$$\lim_{x \to \infty} x - x^{2}\ln\left(1 + \frac{1}{x}\right)$$ tips? [EDIT]
$$\lim_{x \to 0} \frac{1}{x} - \frac{\ln(1 + x)}{x^{2}}$$
second term $$\lim_{x \to 0} \frac{\ln(1 + x)}{x^{2}} = 
\lim_{x \to 0}  \frac{\frac{1}{1 + x}}{2x} =
2\lim_{x \to 0}  \frac{x}{x+1} = 0$$
first term
$$ \lim_{x \to 0}  \frac{1}{x} = \infty$$ is this okey?",['derivatives']
1702295,Categorical formulations of basic results and ideas from functional analysis?,"I'm taking a first (undergrad) course on functional analysis. Though the material is nice, the approach seems very ad hoc and in a sense, near-sighted (?). I was wondering whether the/a big picture of (parts of) the elementary landscape of functional analysis admits some nice categorical descriptions. What are some basic facts, theorems, and constructions in elementary functional analysis admit enlightening categorical formulations?","['functional-analysis', 'category-theory', 'big-list', 'big-picture']"
1702384,Isomorphic graphs,"I was wondering if this solution for finding wheter or not two graphs are isomorphic would work: I claim that two graphs are isomorphic if  their degree list coincide. For example let's say that I have graphs A and B given by their adjacence matrix like so:
$$ A = \begin{pmatrix}
0 &  1& 1 & 1 &0 \\ 
1 &  0& 0 & 0 &1 \\ 
 1& 0 & 0 & 0 &0 \\ 
 1& 0 & 0 & 0 &1 \\ 
 0& 1 & 0 & 1 &0 
\end{pmatrix} $$ $$B= \begin{pmatrix}
0 & 1 & 1 & 0 & 0\\ 
1 & 0 & 0 & 1 & 1\\ 
1 & 0 & 0 & 1 & 0\\ 
0 & 1 & 1 & 0 & 0\\ 
0 & 1 & 0 & 0 & 0
\end{pmatrix}$$ The degree list for A is 3,2,1,2,2 and for B is 2,3,2,2,1. This sets are equal. Therefore I say that A and B are isomorphic. If I am wrong, can you please explain me why is that with a counterexample","['matrices', 'graph-theory', 'graph-isomorphism']"
1702402,"Prove that the group $\mathrm{GL}(n, \mathbb{Z})$ is finitely generated [duplicate]","This question already has answers here : What is the easiest way to generate $\mathrm{GL}(n,\mathbb Z)$? (2 answers) Closed 4 years ago . Knowing that for $n \geq 2$, $\mathrm{GL}(n, \mathbb{Z}) = \big\{ A \in \mathrm{M}_{n,n}(\mathbb{Z}) \mid \det(A) \in \{ 1, −1 \} \big\}$ is a group with respect to matrix multiplication, prove that for every integer $n \geq 2$ the group $\mathrm{GL}(n, \mathbb{Z})$ is finitely generated. If I prove that  $\mathrm{GL}(n, \mathbb{Z})$ has finite subgroups does that mean it has a finite set of generators so that it is finitely generated?","['abstract-algebra', 'group-theory', 'linear-algebra', 'finitely-generated']"
1702405,Write an element of a group as product of generators,"Say we have a finite group $G$ generated by $g_1,\cdots,g_n$. Are there any algorithms or techniques to write any element $g$ as a product of these generators? Ofcourse we could just try all combinations, but I hope there are more elegant ways, like in a vector space, you can just project your element on the generators. I'm asking because this is the group theoretic generalisation of solving a Rubik's cube. By labeling the stickers with natural numbers, we see that moves are permutations, and every legal position is one too. The Rubik's cube group is then the group that is generated by the legal moves: $$G=<R,L,U,D,F,B>$$ In standard notation To solve the cube is the same as to write an element of this group as a product of these generators, so in this case there are many algorithms to do this. What algorithms exist for the general case?","['rubiks-cube', 'computational-algebra', 'group-theory']"
1702423,Proof of fundamental theorem of integral calculus,"This is the result I am after. Theorem Let $F:[a,b]\to\mathbb{R}$. Then the following are equivalent: $F$ is absolutely continuous, that is, for all $\epsilon$ there exists $\delta$ such that whenever $[a_i,b_i]\subseteq[a,b]$ and $\sum(b_i-a_i)<\delta$, then $\sum|F(b_i)-F(a_i)|<\epsilon$; $F$ is a.e. differentiable and $F(x)=\int_a^xf'(t)\mathrm{d}t$. I have come across this a number of times, but I have never seen a complete proof of this. Is it possible to find one online?","['real-analysis', 'lebesgue-integral', 'measure-theory', 'absolute-continuity']"
1702429,How to deduce the poles and residues just by looking?,"Let $$f(z)=\frac{5z-2}{z(z-1)}$$ Then $f$ has simple poles at $0,1$ with $\text{Res}(f,0)=2$ and $\text{Res}(f,1)=3$. How can one tell this? The way I did it was to say $z(z-1)=z^2-z$ which vanishes at $0,1$ yet its derivative $2z-1$ does not vanish at either $0,1$ and also $5z-2$ doesn't vanish at $0,1$ so $f(z)$ has simple poles at $0,1$ and then $\text{Res}(f,0)=\lim_{z \rightarrow 0} \frac{5z-2}{z-1}=2$ and similarly for the other residue. Is there a better/quicker way?",['complex-analysis']
1702442,Union and Intersection of Indexed Family,"I am currently trying to understand something that was stated in ""Introduction to Analysis"", it is the fifth edition. It is used for the Advance Calculus 1 course at ASU. I'm not taking the class right now but I want to get a jump on the material. I've taken an intro course on Logic and I've also taken a Discrete Mathematics course. I think I understand these two definitions well. The first is ""Let $\Lambda$ be a set, and suppose for each $\lambda\in\Lambda$, a subset $A_\lambda$ of a given set S is specified. The collection of sets $A_\lambda$ is called an $\textit{indexed family}$ of subsets of S with $\Lambda$ as the index set. We denote this by $\{A_\lambda\}_{\lambda\in\Lambda}$"". The second is: If $A_\lambda$ is an indexed family of sets, define $$\bigcap_{\lambda\in\Lambda} A_\lambda=\{x:x \in A_\lambda, \text{for all }\lambda \in \Lambda\}$$ and $$\bigcup_{\lambda\in\Lambda} A_\lambda=\{x:x \in A_\lambda, \text{for some } \lambda \in \Lambda\}$$ The book states that if $\Lambda$ is empty then the union will be the empty set but that it is unclear what to expect from the intersection. I don't understand why that is. If $\Lambda$ is empty then doesn't that mean that there is no index for $A_\lambda$ and that there is no way of creating the intersection and union of $A_\lambda$?",['elementary-set-theory']
1702479,$L^{2}$ convergence of sequence $|u_{j}|^{p}\nabla u_{j}$,"Suppose a sequence $\{u_{j}\}$ is bounded in the Sobolev space $H^{2+\epsilon}(\Omega)$, for $\epsilon>0$, where $\Omega$ is say a bounded, $C^{\infty}$ domain. Here, the fractional space $H^{s}(\Omega)$ is defined as the restriction of elements of $H^{s}(\mathbb{R}^{n})$ to $\Omega$, but this definition is equivalent to the usual definition of $W^{s,q}(\Omega)$ by the extension property. By weak* compactness, we have that there is a $u\in H^{2+\epsilon}(\Omega)$ such that (up to a subsequence) $u_{j}\rightharpoonup u$. By Rellich-Kondrachov, $u_{j}\rightarrow u$ in $H^{2}(\Omega)$. In a problem I'm considering, it is stated that $|u_{j}|^{p}\nabla u_{j}\rightarrow |u|^{p}\nabla u$ in $L^{2}(\Omega)$, for certain $p\geq 1$, leaving it to the reader a size condition on $p$ for dimension $n\geq 1$ fixed. I don't know see why this should be true for general $n$. If $n\leq 2$, then there is no issue by Sobolev embedding and Holder's inequality. Suppose $n\geq 3$. Observe that
$$\nabla(|u_{j}|^{p+1})=(p+1)|u_{j}|^{p-1}u_{j}\nabla u_{j}$$ If $|u_{j}|^{p}\nabla u_{j}\in L^{2}(\Omega)$, then $\nabla(|u_{j}|^{p+1})\in L^{2}(\Omega)$, so by Poincare inequality $|u_{j}|^{p+1}\in L^{2}(\Omega)$. Suppose $p=1$, then the preceding implies that $u_{j}\in L^{4}(\Omega)$. I don't see why this should hold a priori, since if $n$ is very large then Sobolev embedding will not give that $u_{j}\in L^{4}(\Omega)$. Any thoughts? Does anyone take issue with my argument above?","['functional-analysis', 'real-analysis', 'sobolev-spaces']"
1702483,Evaluation $\lim_{n\to \infty}\frac{{\log^k n}}{n^{\epsilon}}$,"Evaluate where $\epsilon>0,k\geqslant 1$ are constants $$\lim_{n\to \infty}\frac{{\log^k n}}{n^{\epsilon}}$$ L'Hopital can't help here, also I tried to use $\log$ rules but it didn't helped, I know that $\log$ grows slower then polynom, but $n^\epsilon$ is not polynom, how can I evaluate this limit? thank you",['limits']
1702535,Integral of $\frac{1}{x\sqrt{x-1}}$ using partial fractions.,Find $$\int\frac{1}{x\sqrt{x-1}}\ dx.$$ I have attempted to use the $A/x + B/\sqrt{x-1}$ method. That does not work. I have tried a substitution with $t= \sqrt{x-1}$ and $t^2 +1 = x$. Finding the $dt$ and exchanging it with $dx$ creates another square root in the denominator.,"['radicals', 'partial-fractions', 'calculus', 'indefinite-integrals', 'integration']"
1702538,Calculation of extrinsic curvature,"I asked this question first on physics.SE but I got no complete answer so I thought maybe someone here could help. I'm trying to understand how to derive the extrinsic curvature (in order to understand some calculation on fluid/gravity dynamics). But I hit a wall in my progress. I stuck at trying to verify the extrinsic curvature of a slowing-rotating Kerr solution ( page 94, E.Poisson: A relativistic Toolkit: The mathematics of black holes ):
$$ds_+^2=g_{ab}\;dx^a dx^b=-f dt^2+f^{-1}dr^2+r^2 d\Omega^2-\frac{4Ma}{r}\;\sin^2(\theta)\;dr\;d\phi$$
where $f=1-2M/r$ and cut of $r=R$ which defines the hypersurface $\Sigma$ on which we'll work on. I derive the induced metric (with $\psi=\phi-\Omega t$ and $\Omega=\frac{2Ma}{R^3}$) :
\begin{equation}
h_{ab}\;dy^ady^b=-f dt^2+R^2(d\theta^2+\sin^2\theta d\psi^2)
\end{equation} But from here on, I stuck. So my stucking points are: How can I derive the form of the unit normal vector $n_a$ here and in not so obvious metrics ?(The answer for this problem is $n_a=f^{-1/2}\partial_a\;r$, this means that $n_a=f^{-1/2}\delta^r_a$) ? The extrinsic curvature is defined as $$K_{AB}=n_{a;b}\frac{\partial x^a}{\partial y^A}\frac{\partial x^b}{\partial y^B} \;\;\;\;\;\;\; (1)$$ where $x^a=x^a(y^A)$. Edit : Until now I have compute the $n_a=f^{-1/2}\delta^{r}_{a}$ but if I try to compute the components of the extrinsic curvature, my answers are in complete disagreement with the answers from the book. I found for example $$K_{\theta\theta}=1/2$$ which is obviously wrong. The right answer is $$K_{\theta\theta}=f^{1/2}/R$$ Any suggestions? Thank you.","['riemannian-geometry', 'general-relativity', 'curvature', 'manifolds', 'differential-geometry']"
1702564,The existence of minimizer in Sobolev space,"Let $B\subset \mathbb R^2$ be a unit ball. let $v\in W^{1,2}(B)$ be given. We know that $0\leq v\leq 1$ and it is possible that $v=0$ on some positive $\mathcal L^2$ measurable set in $B$. Let $w\in W^{1,2}(B)$ be given as well. Define
$$
\bar u:=\operatorname{argmin}\left\{\int_B|\nabla u|^2v^2,\,u\in W^{1,2}(B),\,\, T[u]=T[w]\right\}
$$
where $T$ denote the standard trace operator. My question: do we have $\bar u\in W^{1,2}(B)$ exist? (I do not care about uniqueness)","['functional-analysis', 'sobolev-spaces', 'partial-differential-equations']"
1702572,how to find the basis of a plane or a line?,"Find a basis for the plane $x-2y+3z=0$ in $R^3$. Then find a basis for the intersection of that plane with the $xy$ plane. Is there a proper/algebraic way of finding the basis of a plane? Just by looking at it a basis could be $(2, 1, 0)$ because any multiple of that will give you $0$ when you substitute, but how do I find this without guessing? would I use the same process when finding the basis of a line? Any hints on how to figure out the second part of the question?",['linear-algebra']
1702595,Proof for Centroid Formula for a Polygon,I was reading a paper and I found this formula for the centroid of a polygon in terms of its coordinates but no proof was given. $C_x =\frac{1}{6A} \sum_{i=0}^{N-1}(x_i+x_{i+1})(x_iy_{i+1}-x_{i+1}y_i) $ $C_y =\frac{1}{6A} \sum_{i=0}^{N-1}(y_i+y_{i+1})(x_iy_{i+1}-x_{i+1}y_i)$ where $x_N=x_0$ and A = the area of the polygon. Does anyone know the proof for this formula? And how is it connected (if it is) to the formula for the centroid of a uniformly dense lamina:,"['centroid', 'polygons', 'geometry']"
1702600,"Are there any pairs of functions where $g(n,x)=f^{(n)}(x)$?","Are there any non-piecewise pairs of functions that satisfy this quality? $g(n,x)=f^{(n)}(x)$ Where $n\in \Bbb{Z}$ and is the $n^{th}$ derivitive of $f(x)$ This is a long shot but I'm just curious","['derivatives', 'calculus']"
1702617,$X$ and $Y$ are homeomorphic. Show that also their one-point compactifications are homeomorphic.,"Assume $X$ and $Y$ are two homeomorphic locally compact Hausdorff-spaces. Show that also their one-point compactifications are homeomorphic. Give an example of two non homeomorphic locally compact Hausdorff-spaces but which one-point compactifications are homeomorphic. Let $X$ and $Y$ be two locally compact Hausdorff-spaces and $f: X \rightarrow Y$ a homeomorphism. Define the two spaces
one-point compactifications as $X'$ and $Y'$ and call the
additional points $p$ and $q$ . Extend $f$ by letting $f(p) = q$ . To show that $f$ is a homeomorphism it is enough to show that $f(U)$ and $f^{-1}(V)$ are open in $Y'$ and $X'$ where $U$ and $V$ are open neighborhoods of $p$ and $q$ , respectively. This is the first problem i am solving which deals with one-point compactifications. I am not sure how to show this and also have difficulties
to come up with an example. Any ideas? edit: First part is solved. Only the example they are looking for remains.",['general-topology']
1702618,Equivalence of two definitions of rational equivalence,"Let $X$ be a variety. In order to define the Chow ring of $X$, there seem to be two different ways of defining rational equivalence of $i$-cycles $Z \sim Z'$. Definition 1:
$Z \sim Z'$ iff there is a subvariety $V \subseteq X$ of dimension $i+1$ and a rational function $\varphi \in K(V)$ such that $Z - Z' = \text{div}(\varphi)$. This is the definition at the Wikipedia article for adequate equivalence relation , for example. Definition 2:
$Z \sim Z'$ iff there is a subvariety $V \subseteq \mathbb{P}^1 \times X$ and points $a,b \in \mathbb{P}^1$ such that $(V \cap \{a\} \times X) - (V \cap \{b\} \times X) = Z - Z'$. I've seen this stated both with and without the additional hypothesis that $V$ is flat over $\mathbb{P}^1$. This is the definition at the Wikipedia page for Chow Ring , for example. Of course, I'd love to see a proof in as much generality as possible, but I will be satisfied with a proof in the case when $X$ is a smooth projective variety over $\mathbb{C}$ and $Z,Z'$ Cartier divisors on $X$. EDIT I should add my attempts: it's not hard to see that the first definition implies the second, by taking $V$ equal to the graph of the rational function on the dimension $i + 1$ subvariety and taking the pushforward. For the second direction, we need to show  (in the case of divisors) that $V$ somehow is related to the graph of a non-constant rational function on $X$. But I don't see why this must be true: surely there are examples where $\mathbb{P}^1 \times \{x\}$ for some $x \in X$ is not just a point! (A dumb example is $\mathbb{P}^1 \times W$ for some subvariety $W$ - this only shows that $W$ is rationally equivalent to $W$)","['intersection-theory', 'algebraic-geometry']"
1702651,"Understanding ""trace of map"" in the definition of harmonic maps","I have difficulty understanding ""trace of map"" in the definition of harmonic map. Let $\phi: (M,g)\to (N,h)$ is map between two Riemannian manifolds, the energy density is defined as $$e(\phi)=\frac12trace_g\phi^*h$$ From my understanding, the trace of $\phi^*h$ is the trace of its matrix representation with basis $\{ \frac{\partial}{\partial x^i}\}$ , that is $$trace_g\phi^*h=\sum_{i=1}^m\phi^*h(\frac{\partial}{\partial x^i},\frac{\partial}{\partial x^i})=\sum_{i=1}^mh(\phi_*\frac{\partial}{\partial x^i},\phi_*\frac{\partial}{\partial x^i})=\sum_{i=1}^mh(\frac{\partial\phi^{\alpha}}{\partial x^i}\frac{\partial}{\partial y^{\alpha}},\frac{\partial\phi^{\beta}}{\partial x^i}\frac{\partial}{\partial y^{\beta}})=\sum_{i=1}^m\frac{\partial\phi^{\alpha}}{\partial x^i}\frac{\partial\phi^{\beta}}{\partial x^i}h_{\alpha \beta}$$ One can see the reference here , that it explains that in local coordinates, the energy density can be written as: $$e(\phi)=\frac12g^{ij}h_{\alpha \beta}\frac{\partial\phi^{\alpha}}{\partial x^i} \frac{\partial\phi^{\beta}}{\partial x^j}$$ which is different with my understanding! So the trace certainly involves metric $g$ , it seems as the interpretation of $trace_g$ is to raise it up by $g^{ij}$ and regard it as a (1,1)-tensor, instead of a (0,2)-tensor. But why? Any help would be appreciated!","['trace', 'riemannian-geometry', 'differential-geometry']"
1702666,"If more than one prime number satisfies a given congruence, must an infinite number of primes satisfy that congruence?","I understand that this is kind of a broad question, but if no affirmative proof is known, can anyone give a counterexample?","['algebraic-number-theory', 'number-theory', 'congruences', 'prime-numbers', 'modular-arithmetic']"
1702685,"Zariski topology, non-empty intersection of open sets","Let $k$ be a field and $X=\mathbb k^n$. A subset $Y \subset X$ is closed if there are $f_1,\ldots,f_m \in k[x_1,.\ldots,x_n]$ such that $Y=\{a \in k^n :f_i(a)=0 \space \forall \space i\}$, we write $Y=V(f_1,\ldots,f_m)$. The Zariski topology is $T=\{U \subset X : X \setminus U=V(f_1,\ldots,f_m) \}$. I am trying to show that given the Zariski topology on $k^n$, if $U$ and $V$ are non-empty open subsets, then $U \cap V$ is non-empty. I don't know how to prove this so any hints would be greatly appreciated.","['abstract-algebra', 'zariski-topology', 'polynomials', 'algebraic-geometry']"
1702687,Tangent Space to Moduli Space of Vector Bundles on Curve,"Let $X$ be a curve of genus $g \geq 2$.  Using Geometric Invariant Theory, we can construct a moduli space $\mathcal{M}(r,d)$ of vector bundles on $X$ of rank $r$ and degree $d$.  The details of this construction are a bit over my head for now, however I would like to at least be able to prove that the dimension of this moduli space is $r^{2}(g-1)+1$. I'm lacking understanding of one key fact.  In Michael Thaddeus' paper ( http://www.math.columbia.edu/~thaddeus/papers/odense.pdf ) he mentions that the tangent space to $\mathcal{M}(r,d)$ at any stable bundle $E$ satisfies the following $T_{E} \mathcal{M}(r,d) \simeq H^{1}(\rm{End}E)$ Can anyone help me understand this?  I don't understand Thaddeus' argument.  Given the above fact, it's trivial to apply Hirzebruch-Riemann-Roch and complete the derivation of the dimension of the moduli space.","['complex-geometry', 'algebraic-geometry']"
1702730,'Sign' of normalized eigenvector for singular value decomposition,"I'm working on an SV decomposition script in Python. I am getting incorrect results because of the 'indeterminacy' associated with normalizing the singular vectors. I understand that the sign of the vectors does not matter in terms of their behaviour as eigenvectors, but it does give incorrect results for SV decomposition. My example is this matrix: $$
A = \begin{bmatrix}
3 & 2\\
1 & -1\\
\end{bmatrix}
$$ When I use numpy.linalg.eig to calculate the normalized eigenvectors for the singular vectors, some of them are the opposite sign to the singular vectors returned by numpy.linalg.svd (i.e. negative of each other) - if I understand correctly both should be valid normalized eigenvectors. In all other respects my algorithm's results are the same as Numpy's. When I expand the factorisation, a lot of the time mine is incorrect while Numpy's always is. I believe the problem is that numpy.linalg.eig just happens to return the 'wrongly signed' eigenvectors. For singular value decomposition, is there any easy/deterministic way to check which 'sign' your singular vectors need to have?","['eigenvalues-eigenvectors', 'matrix-decomposition', 'svd', 'linear-algebra']"
1702758,"If a, b, c are three natural numbers with $\gcd(a,b,c) = 1$ such that $\frac{1}{a}+\frac{1}{b}=\frac{1}{c}$ then show that $a+b$ is a square.","If a, b, c are three natural numbers with $\gcd(a,b,c) = 1$ such that $$\frac{1}{a} + \frac{1}{b}= \frac{1}{c}$$ then show that $a+b$ is a perfect square. This can be simplified to: $$a+b = \frac{ab}{c}$$ Also, first few such examples of $(a,b,c)$ are $(12, 4, 3)$ and $(20, 5, 4)$ . So, I have a feeling that $b$ and $c$ are consecutive. I don't think I have made much progress. Any help would be appreciated.","['square-numbers', 'divisibility', 'gcd-and-lcm', 'number-theory', 'elementary-number-theory']"
