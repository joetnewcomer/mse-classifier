question_id,title,body,tags
492179,How find this$\lim_{n\to\infty}n^2\left(n\sin{(2e\pi\cdot n!)}-2\pi\right)=\frac{2\pi(2\pi^2-3)}{3}$,"show  that $$\lim_{n\to\infty}n^2\left(n\sin{(2e\pi\cdot n!)}-2\pi\right)=\dfrac{2\pi(2\pi^2-3)}{3}$$ we are kown that
$$\lim_{n\to\infty}n\sin{(2\pi e\cdot n!)}=2\pi$$ because we note
$$e=1+\dfrac{1}{1!}+\dfrac{1}{2!}+\cdots+\dfrac{1}{n!}+\dfrac{1}{(n+1)!}+O(\dfrac{1}{(n+1)!})$$ then
$$2e\pi\cdot n! =2k\pi+\dfrac{2\pi}{n+1}+o(\dfrac{1}{n+1}))$$ for this problem we 
$$e=1+\dfrac{1}{1!}+\dfrac{1}{2!}+\cdots+\dfrac{1}{n!}+\dfrac{1}{(n+1)!}+\dfrac{1}{(n+2)!}+o(\dfrac{1}{(n+2)!})$$
so
$$2\pi en!=2k\pi+\dfrac{2\pi}{n+1}+\dfrac{2\pi}{(n+1)(n+2)}+o(\dfrac{1}{(n+1)(n+2)})$$ and use
$$\sin{x}=x-\dfrac{x^3}{6}+o(x^3)$$
But I can't work",['limits']
492204,Connections on a manifold and principal connections on the frame bundle,"Suppose $M$ is a manifold, and $E$ a vector bundle over $M$ equipped with a connection $\nabla $. If $F$ is the frame bundle of $E$, is there an explicit construnction of a connection on $F$ associated with $\nabla$ such that in this way connections on $E$ and $F$ are $1$-$1$ correspondent? Edit for the bounty: I really need an answer to this question, and as it was already posted I think that putting a bounty on it is the most sensible way to go. To rephrase the question in my own terms: Let $M$ be a smooth $n$-manifold. We can associate the following principal $GL(n)$-bundle to it:
$$F = \{(m,\theta)|m\in M, \theta:\mathbb{R}^n\to T_mM\mathrm{\ lin.\ isom.}\}$$
with right action given by $(m,\theta)g = (m,\theta g)$. Its tangent space is defined (as for any other manifold) as a quotient of the space of paths on $F$. In order to get a more concrete representation, we need a way to differentiate ""paths of frames,"" but as such paths can be seen as tuples of paths of vectors on $M$, it is enough to specify a connection $\nabla$ on $M$ to obtain the identification
$$T_{(m,\theta)}F \cong \{(\hat{m},\hat{\theta})|\hat{m}\in T_mM,\hat{\theta}:\mathbb{R}^n\to T_mM\}$$
where we identify the equivalence class of paths $[\gamma(t),\theta(t)]$ with $(\dot{\gamma}(0),(\nabla_{\dot{\gamma}}\theta)(0))$. This gives us a map
$$\{\mathrm{connections\ on\ }M\}\longrightarrow\{\mathrm{principal\ connections\ on\ F}\}$$
mapping $\nabla$ to $A([\gamma,\theta]) = \theta^{-1}\nabla_{\dot{\gamma}}\theta\in\mathfrak{gl}(n)$. I believe there should be a way to invert this map (maybe only on a subset of the principal connections, though) but I cannot see how. Does anyone have an idea or a solution? Remark 1: My question is in fact a special case of the original question on vector bundles, namely if we take $E=TM$. Remark 2: I took a look at Taubes' book, as suggested in the answers, but I didn't find what I need (or maybe I found it, but wasn't smart enough to realize it).","['principal-bundles', 'connections', 'differential-geometry']"
492218,"induction (sum of squares of products of elements of certain subsets of $\{1,\dots,n\}$)","Let $n$ be any natural number. Consider all nonempty subsets of the set {$1,2,...,n$}, which do not contain any neighboring elements. Prove that the sum of the squares of the products of all numbers in these subsets is $$(n + 1)! - 1.$$ For example, if $n = 3$, then such subsets of {$1,2,3$} are {$1$}, {$2$}, {$3$}, and {$1,3$}, and $$1^2 + 2^2 + 3^2 + (1\cdot3)^2 = 23 = 4! -1.$$ Is there a way I can write the sum of the squares of the products of all numbers in these subsets is $(n + 1)! - 1$? I'm actually stuck in this problem.
This is all I have for this problem but I'm not sure if I'm doing the problem right. For the Basis step I let $ n= 2$ and the subsets of {$1,2$} are just {$1$} and {$2$}. Thus, $$1^2+2^2 = 5 = 6-1 = 3! -1$$ So, it's true for n=2. Inductive step: I assume that the statement holds for $n = k$ where $k$ is a natural number. Then the sum of the squares of the products of all numbers in these subsets is $(k+1)!-1$ We have to show that the statement holds for for $n = k+1$. That is to say that the sum of the squares of the products of all numbers in these subsets is $(k+2)! -1$ Please let me know if I'm actually doing the proof right if not correct me. Thanks","['induction', 'algebra-precalculus']"
492250,Suppose that $U$ is a subspace of $V$. What is $U+U$?,"Suppose that $U$ is a subspace of $V$. What is $U+U$? Why does $U+U = U?$ I want to think of this geometrically, say in $\mathbb{R^{3}}$  we have some random plane in space that intersects the origin. How is this subspace, when added to itself, equal to itself?",['linear-algebra']
492251,"$f$ such that $\|Df - \text{Id}\|$ is close to zero, yet $f$ is not bijective","A problem from my differential geometry class: Suppose $f:\mathbb{R}^2 \to \mathbb{R}^2$ is a $C^1$ mapping, and for every $x\in \mathbb{R}^2$ $$\| Df(x) - \text{Id} \| < 10^{-10}.$$ Prove or disprove: $f$ must be a bijection. My intuition tells me that there should be a counterexample. $f$ linear will not work, because either it is an isomorphism, or it has range of dimension $\leq 1$, in which case $\|Df - \text{Id} \| = \|f - \text{Id}\|$ will be too big. One idea I had is a function which on the complex plane would be expressed as $z\mapsto z^{\alpha}$, where $\alpha - 1$ is positive and very close to zero. This would certainly not be a bijection, but should not move anything on the unit circle too much. The derivative of such a function would be the matrix representing the complex number $\alpha (a+bi)^{\alpha -1}$. It seems like this matrix would be sort of tricky to come up with. $\alpha(a+bi)^{\alpha -1} :=\alpha e^{(\alpha-1) \log{(a+bi)}}$, and how can I simplify this? I know this function is not complex-differentiable at zero, but perhaps it is differentiable when viewed from $\mathbb{R}^2 \to \mathbb{R}^2$? Any hints or ideas? No need to feed me the answer. Thanks",['multivariable-calculus']
492281,Why not introduce quotient groups this way?,"$\DeclareMathOperator{\Ker}{Ker}$ Hopefully this question won't be too vague, naive, or have incorrect information. I am taking an algebra class (using Robert Ash's algebra text) and we have finished the first groups theory sections and I have been looking it over, especially the isomorphism theorems and kernels/normal subgroups. It just so happens that I started reading a paper a little before I started looking over the group which defines kernels of a function in a different way than it is defined in group theory. First we will define the kernel in the paper. Let $f:S \to U$ be a function and $\Ker f$ will be the partition induced on $S$ by the equivalence relation $\sim$ defined by $a \sim b \iff f(a)=f(b)$ . Unless I am mistaken, $\Ker f$ where $f$ is a group homomorphism $G \to H$ is the set $G/\ker f$ (I am pretty sure you can actually use any element of $\Ker f$ as the quotient). In my mind, $\Ker$ seems like a more natural concept to come up with and ""more directly"" explains the first isomorphism theorem, at least at first blush. By ""more directly"" I guess I mean you don't have to pass through defining normal subgroups, the typical group kernel, or even cosets. Is there a reason why the concept of $\ker$ seems to be favored more than $\Ker$ ? In an attempt to think of why I came up with a few potential things, but not sure how valid they are. One is that you don't need to develop cosets for this and cosets are more useful than just objects for quotient group, but I suspect from the concept of $\Ker$ one could better motivate looking at cosets (although I am not sure how). Another thought I have is that maybe notationally and conceptually it becomes more useful to think of $G/N$ , especially when you are given a normal subgroup or need to remove/preserve some properties. Then again I feel like $\Ker$ could motivate those concepts, so I am not sure if these are great arguments against $\Ker$ .","['quotient-group', 'group-theory', 'abstract-algebra']"
492288,"Is there limit $ \lim_{(x,y) \to (0,0)} \frac{x^3}{x^2 + y^2}$?","How to show if the limit $$ \lim_{(x,y) \to (0,0)} \frac{x^3}{x^2 + y^2}$$ exists? I suspect that there is, as I can't find any path that would show that limit doesn't exist, and WolframAlpha also suggests that the limit is (0,0). In general, can you recommend any tips how to learn to approach similar limit problems (fractions and polynomials like this)? edit That is, excluding the polar coordinate conversion method?","['multivariable-calculus', 'calculus', 'limits']"
492297,"$f,g:\mathbb R^3\to\mathbb R$ are nonzero linear maps. Then which are true?","(A) is wrong: Consider $f:(x,y,z)\mapsto(x,0,0),~g:(x,y,z)\mapsto(x,y,0)$ (B) is wrong: Consider $f:(x,y,z)\mapsto(x,0,0),~g:(x,y,z)\mapsto(x,y,0)$ (C) is wrong: $\ker g$ is a subspace of $\mathbb R^3$ and let $f:\ker g\to\mathbb R$ be the restriction of $f.$ Then since $\ker f\subset\ker g$ by isomorphism theorem $\ker g /\ker f\simeq\Im(f)\ne\mathbb R.$ (D) is correct. Please tell me if I'm right. I'm skeptical especially about (C).","['linear-algebra', 'proof-verification']"
492317,What do the curvature and torsion measure? [duplicate],"This question already has answers here : Geometric interpretation of connection forms, torsion forms, curvature forms, etc (3 answers) Closed 10 years ago . Consider a smooth surface for simplicity. What does its curvature measure? What does its Gaussian/Riemannian curvature measure? What does its torsion measure? What does the Ricci curvature measure?","['curvature', 'differential-geometry']"
492322,"Let $A= {x_0, x_1, · · · , x_m}$ be a subset of ${1, 2, · · · , n}$,where $m > n/2$,show that A contains two numbers b and c such that $x_0 + b = c$.","Given $A = \{a_0, a_1,...,a_m\}$  such that it's a subset of $\{1,2,...,n\}$ where $m>n/2$, and $a_0$ is the smallest number in $A$. Show that $A$ contains two numbers $b$ and $c$ such that $a_0+b=c$ with the use of the pigeonhole principle. 
Consider the following if stuck: $a_1-a_0, a_2-a_0,...,a_m-a_0$ Hi, I am new to this site. Please help, I have been stuck on this problem for hours now. How would you go about it?","['pigeonhole-principle', 'discrete-mathematics', 'combinatorics']"
492332,"Let $a,b$ be in a group $G$. Show $(ab)^n=a^nb^n$ $\forall n\in\mathbb{Z}$ if and only if $ab=ba$.","Let $G$ be a group and $a,b\in G$.  Show $(ab)^n=a^nb^n$ for all $n\in\mathbb{Z}$ if and only if $ab=ba$. I don't known where to start. It seems trivially.","['group-theory', 'abstract-algebra']"
492350,A bipartite graph question,"Is there a bipartite graph with degrees $3,3,3,3,3,3,3,3,3,5,6,6$? I've been stuck attempting to draw this graph but keep getting lost. I think it is no, but I am not concrete about it. Is it no?","['graph-theory', 'discrete-mathematics']"
492356,The Ricci flow and $\frac{\partial}{\partial t}g_{ij}=-2(R_{ij}+\nabla_i \nabla_j f)$ are equivalent up to diffeomorphism,"Suppose $M$ is a Riemannian manifold. Consider flow $\frac{\partial}{\partial t}g_{ij}=-2(R_{ij}+\nabla_i \nabla_j f)$, where $f$ is a time-dependent function. I would like to prove that flows of this form are equivalent, up to diffeomorphism, to the Ricci flow $\frac{\partial}{\partial t}g_{ij}=-2R_{ij}$, that is: By defining a 1-parameter family of diffeomorphism $\Psi(t):M\to M$ by $$\frac{d}{dt}\Psi(t)=\nabla_{g(t)}f(t),$$
$$\Psi(0)=id_M$$ I want to show that $\bar{g}(t):=\Psi(t)^*g(t)$ satisfy
$$\frac{\partial}{\partial t}\bar{g}_{ij}=-2 \bar{R}_{ij}.$$ My problem is that I don't know how to calculate $\frac{\partial}{\partial t}\Psi(t)^*g(t)$. I know that $\frac{\partial}{\partial t}\Psi(t)^* \alpha=\mathcal{L}_{\nabla f} \alpha$, where $\mathcal{L}$ is Lie derivative and $\alpha$ is a time-independent object, but I faced problem when $\alpha$ is a time-dependent object. Can someone point me in the right direction? Thanks in advance for your time.","['ricci-flow', 'riemannian-geometry', 'differential-geometry']"
492369,Is the strong convergence of Borel probability measure metrizable?,"In a metric space $(X,e)$, a sequence of Borel probability measure converges strongly, $\mu_i \xrightarrow{s} \mu$, iff for each Borel subset $S \in X$, we have $\lim_{i \to \infty}\mu_i(S) = \mu(S)$. Is there a metric $d$ on $\Delta(X)$, the space of all Borel probability measures on $X$, such that if $\lim_{i \to \infty}d(\mu_i,\mu)=0$, then $\mu_i \xrightarrow{s} \mu$?","['probability-theory', 'convergence-divergence', 'metric-spaces']"
492413,Determine if a function is a total derivative,"Lagrangian is defined up to addition of a total derivative of function of positions and time. Now suppose we have a function $f(x,\dot x,t)$. How can one show (check) that
$$\not\exists g(x,t):\; f(x,\dot x,t)=\frac{\text{d}}{\text{d}t}g(x,t)$$
?",['derivatives']
492433,"If $|A|=30$ and $|B|=20$, find the number of surjective functions $f:A \to B$.","Let there be: $|A|=n$ and $|B|=m$  if $m>n$ then there are $$m(m-1)\cdots(m-n+1)$$ injective functions, so in this case  we have $|A|=30$ and  $|B|=20$ that means $m<n$ so there exists a surjective function, but I'm not sure if I can  find the number of surjective functions in the same way that I did find the number of injective functions.","['elementary-number-theory', 'functions', 'combinatorics']"
492513,Use Laplace transform to solve the following initial–value problems.,"Use Laplace transform to solve the following initial–value problem. $y′′′′ + 2y′′ + y = 0, y(0) = 1, y′(0) = −1, y′′(0) = 0, y′′′(0) = 2$ Answer $s^4 L(s) - s^3y(0) -s^2 y'(0) - s y''(0) - y'''(0) +2[s^2L(s)-sy(0)-y'(0)] +L(s) \\\\$
I get the partial fraction part and got stuck, need help! $L(s) =\frac{s^3 - s^2 +2s}{s^4 +2s^2 +1}= \frac{s-1}{s^2 +1}+\frac{s+1}{(s^2+1)^2}  \:\:$Factorising the denominator I get: $(s^2+1)^2$ Please some let me know if Im heading in the wrong direction here.","['ordinary-differential-equations', 'laplace-transform']"
492522,Measurability of integral,"Consider a function $f: \mathbb{R}^n \times \mathbb{R}^m \rightarrow \mathbb{R}$ which is continuous in the first argument, measurable in the second. Let $m: \mathcal{B}(\mathbb{R}^m) \rightarrow [0,1]$ be a finite measure. I am wondering if the function $F: \mathbb{R}^n \rightarrow [0,1]$ defined as 
$$ F(x) := m\left( \{ y \in \mathbb{R}^m \mid f(x,y) \leq 0 \} \right) $$
is measurable. What I tried to do is to claim that $F$ is upper semicontinuous. This should imply measurability.","['measure-theory', 'probability-distributions', 'functional-analysis']"
492530,Finding the extrema of $E(\vec{r})=\frac1a x^2+\frac1b y^2+ \frac1c z^2$ with respect to constraints geometrically,"I have a function, 
$$E(\vec{r})=\frac1a x^2+\frac1b y^2+ \frac1c z^2.$$
Where $\vec{r}=(x,y,z)$ and $a>b>c>0$. I wish to find the maximum and minimum of this function with respect to the constraints,
$$\vec{r}\cdot\vec{r}=1,\qquad\vec{k}\cdot\vec{r}=0,$$
where $\vec{r}=(k_1,k_2,k_3)$, is an arbitrary constant vector. I do not wish to solve this using Lagrange multipliers, but instead via a geometrical argument. The constraints are clearly the unit sphere intersecting with a plane normal to $\vec{k}$ through the origin. So this is a unit circle rotated in 3 dimensions through the origin, dependent on the direction of the vector $\vec{k}$. So to analyse to the maxima and minima of $E$ w.r.t. to the constraints above we can consider the intersections of the rotated circle through the origin with the family of ellipsoids $$E(\vec{r})=\text{constant}$$ My question is, is this the right way to look at this problem from a geometrical perspective? If we let $E=constant=\lambda$, imagine this $\lambda>>1$, so that the ellipsoid is very large and outside of the unit sphere. Then as we lower the value of $E$ and hence $\lambda$ eventually as some point on the intersection of the plane $\vec{k}\cdot\vec{r}=0$ with the unit sphere and the ellipsoid will touch. This point will be the point that maximises $E$ and similarly the last point to touch the ellipsoid as it is shrunk further will be the minimum, is this correct? If so how could these points be found? Here is a diagram to help explain what i'm talking about. EDIT#1: Here is the tilted circle (formed from the intersection on a sphere and a plane), in parametric form $$\vec{r}(\theta)=\left(\begin{array}{c} \mathrm{k_1}\, \mathrm{k_2}\, \left(\sqrt{1 - {\mathrm{k_3}}^2} - 1\right)\\ {\mathrm{k_2}}^2\, \sqrt{1 - {\mathrm{k_3}}^2} + {\mathrm{k_3}}^2\, \sqrt{1 - {\mathrm{k_3}}^2} - {\mathrm{k_2}}^2 - {\mathrm{k_3}}^2 + 1\\ - \mathrm{k_2}\, \mathrm{k_3} \end{array}\right)\sin(\theta)+\left(\begin{array}{c} {\mathrm{k_2}}^2 - {\mathrm{k_2}}^2\, \sqrt{1 - {\mathrm{k_3}}^2} + \sqrt{1 - {\mathrm{k_3}}^2}\\ \mathrm{k_1}\, \mathrm{k_2}\, \left(\sqrt{1 - {\mathrm{k_3}}^2} - 1\right)\\ - \mathrm{k_1}\, \mathrm{k_3} \end{array}\right)\cos(\theta)$$ EDIT#2: Or it can be described more neatly by defining $\vec{k_\perp}=(-k_2,k_1,0)$, then $$\vec{r}(\theta)=\vec{k_\perp}\sin(\theta)+(\vec{k_\perp}\times\vec{k})\cos(\theta)$$","['optimization', 'geometry']"
492544,"Intuition behind denoting the power set of $\Omega$ as $\{0,1\}^\Omega$","I'm trying to understand a textbook example, specifically I want to understand why the notation is the way it is.  I'm new to this. A die is thrown once.  We can take the sample space
$\Omega = \{1,2,3,4,5,6\}$ We can take a $\sigma$-field $\mathcal F= \{0,1\}^\Omega$ (all possible subsets). I understand why we want to reason about $\mathcal F$, and I understand why its cardinality is 2^6.  Since we're raising a 2-element set to a 6-element set, that kind of makes sense with this notation. But from reading, I get that $X^Y=\{f\colon Y\to X\mid f\ \text{is a function}\}$ But this gives me a set of functions, right?   While the power set notation gives me something I think of as a set of sets. Which piece am I oversimplifying or missing?",['elementary-set-theory']
492547,What does directional derivative zeros imply when directional vector is not zero?,"This question might sound stupid but I want to confirm an answer from it. I saw somewhere online that it means that when the directional derivative of function $f$ along the none zero vector $v$ at certain point is equal to $0$, it means that the function $f$ is constant in that direction. But what does ""constant in direction"" mean? can anyone give me an example of it such as $f(x,y)$ to explain this? Thanks!","['derivatives', 'analysis']"
492548,A vector space is an abelian group with some extra structure?,"Question: A vector space is an abelian group with some extra structure. Given
two vector spaces V1 × V2, show that the group V1 × V2 is a vector space. Can someone explain to me the first sentence? Especially why it is commutative? As to the second sentence, is it just saying the product of vector spaces is vector space? Why it mentions ""group"" V1 × V2 particularly? Thx in advance~","['group-theory', 'abstract-algebra']"
492573,Group theory with analysis,"I've studied group theory upto isomorphism. Topics include : Lagrange's theorem, Normal subgroups, Quotient groups, Isomorphism theorems. I too have done metric spaces and real analysis properly. Can you recommend any good topic to be presented in a short discussion. A good proof on an interesting problem will be highly appreciated.(E.g.- Any subgroup of (R,+) is either cyclic or dense).Is there any such problem which relates number theory and metric spaces or real analysis? Thanks in advance.","['metric-spaces', 'group-theory', 'real-analysis']"
492576,Characteristic Function of Inverse Gaussian Distribution,"The pdf of Inverse  Gaussian distribution, IG$(\mu,\lambda)$, is : $$p_X(x)=\sqrt\frac{\lambda}{2\pi x^3}\exp\left[\frac{-\lambda}{2\mu^2x}(x-\mu)^2\right];\quad x>0,\lambda,\mu>0$$ I have to compute the Characteristic Function, $\phi_X(t)$. $$\phi_X(t)=\mathbb E(e^{itX})=\int_0^\infty e^{itx}\sqrt\frac{\lambda}{2\pi x^3}\exp\left[\frac{-\lambda}{2\mu^2x}(x-\mu)^2\right] \, dx$$ I tried to fall it under Gamma function. $$\phi_X(t)=\sqrt\frac{\lambda}{2\pi}e^{\lambda/\mu}\int_0^\infty x^{\frac{-3}{2}}\exp\left[-\left(\frac{\lambda}{2\mu^2}+\frac{\lambda}{2x^2}-it\right)x\right]dx$$ $$ = \sqrt\frac{\lambda}{2\pi}e^{\lambda/\mu}\int_0^\infty x^{\frac{-3}{2}}\exp\left[\left(it-\frac{\lambda}{2\mu^2}\right)x-\frac{\lambda}{2x}\right]dx  $$","['statistics', 'definite-integrals', 'normal-distribution', 'probability-distributions', 'probability']"
492598,What's the intuition behind the tangent bundle?,"Well, when we work with a smooth manifold $M$ we can associate with each point $p\in M$ a vector space $T_p M$ of all vectors at $p$ tangent to $M$: this is the space of linear functionals obeying liebniz rule in the algebra of germs of functions at $p$. This definition of vector is very intuitive, since it generalizes the main property of vectors in $\mathbb{R}^n$ of producing the directional derivative. Now, then we usually say: ""well, we must find a way to assemble all of the tangent spaces together to have a domain and range for the derivative"", then we define $TM$ as the disjoint union of all $T_p M$ and if $\pi : TM \to M$ is the projection on the first coordinate, we want to construct a vector bundle $\pi : TM \to M$. Now, what doesn't seem clear to me is why do we want the structure of a vector bundle. The definition of a fiber bundle is meant as I understand, to make a space that locally looks like a product space, but why do we want this? Is this because $T\mathbb{R}^n = \mathbb{R}^n \times \mathbb{R}^n$ and we want to ``copy'' this behavior locally? Also, how do we know that there's an obstruction in general to write $TM = M \times \mathbb{R}^n$? I've seem a question like this before here and there were answers based on hairy ball theorem and so on. The point is, this result needs that we first define $TM$ as it is define. If we don't know any of these theorems, how do we know that writing $TM$ that way is not possible? Thanks very much in advance for the aid!","['manifolds', 'vector-bundles', 'differential-geometry']"
492599,$f : S^1 \to\mathbb R$ is continuous then $f(x)=f(-x)$ for some $x\in S^1$,"Question is to prove : $f : S^1 \to \mathbb R$ is continuous then $f(x)=f(-x)$ for some $x\in S^1$ I guess it would be helpful to use intermediate value theorem Assuming $f(x)\neq f(-x)$ then given any $p\in (f(-x),f(x))$ (assuming $f(-x)<f(x)$) there exists $y\in (-x, x)$ such that $f(y)=p$ I am not very sure of how to use this.. It would be helpful if someone can give some hint which would help me to solve this.. Thank you.","['general-topology', 'real-analysis']"
492605,"If $\,x-\frac 1 x=k, \, k$ being any integer,then $\,\,x^5-\frac {1}{x^5}=?$","I am stuck with the following problem which one of friends gave me : If $\,x-\frac 1 x=k, \, k$ being any integer,then $\,\,x^5-\frac {1}{x^5}=?$ The options are $\,\,k^5+4k^3+4k, \,k^5+5k^3+6k,\,k^5+5k^3+5k,\,k^5+5k^3+4k $ . We see that $x-\frac 1 x=k \implies x=\frac{k \pm \sqrt{k^2+4}}{2}$ . Now putting this value to $\,\,x^5-\frac {1}{x^2}$ makes the calculation complicated. Can anyone help? Thanks and regards to all. EDIT: The problem contained a typo and thanks to @noam for pointing that out. Now using binomial expansion of $x^5-\frac{1}{x^5}$ , we see that option 3 is the correct choice.",['algebra-precalculus']
492607,"For a general plane, what is the parametric equation for a circle laying in the plane","Given a general equation for a plane through the origin
$$\vec{n}\cdot\vec{r}=0$$
With no assumptions made on $\vec{n}$ except having unit modulus, real $3\times1$ vector. How can you describe a unit circle, centred at the origin, laying in this plane? I can only seem to find parametric equations that rely on knowing two vectors in the plane, but with no knowledge of the vector $\vec{n}$ you can't generally create two such vectors, as some component(s) of $\vec{n}$ may be zero. All the information you need to define such a circle is contained within the normal to the plane, so I am confused as to why there is not a form defined only with reference to this vector. EDIT#1: With reference to this matrix . Can we start with in the $xy$ plane $$(x,y,z)=(\cos(\theta),\sin(\theta),0)$$
Then rotate this about the axis ($\vec{u}$ in the link) 
$$\vec{u}=(-n_2,n_1,0)$$
about an angle $\phi$ that satisfies
$$\tan(\phi)=\frac{n_3}{\sqrt{n_1^2+n_2^2}}.$$
I claim that $\vec{u}$ is the axis of rotation as this vector is perpendicular to the normal of the plane $\vec{n}$ and lies in the $xy$ plane. Also that $\phi$ is the angle which the $xy$ plane is rotate about $\vec{u}$ by. Therefore by substituting into the matrix linked to at the beginning of this edit, transforming $(x,y,z)=(\cos(\theta),\sin(\theta),0)$ by said matrix will give parametric coordinates for the tilted circle in terms of $\vec{n}$? EDIT #2: I find this for the rotation matrix from the $xy$ plane to the plane with normal $\vec{n}$, from the method described above. $$Q=\small{\left(\begin{array}{ccc} {\mathrm{n_2}}^2 - {\mathrm{n_2}}^2\, \sqrt{1 - {\mathrm{n_3}}^2} + \sqrt{1 - {\mathrm{n_3}}^2} & \mathrm{n_1}\, \mathrm{n_2}\, \left(\sqrt{1 - {\mathrm{n_3}}^2} - 1\right) & \mathrm{n_1}\, \mathrm{n_3}\\ \mathrm{n_1}\, \mathrm{n_2}\, \left(\sqrt{1 - {\mathrm{n_3}}^2} - 1\right) & {\mathrm{n_2}}^2\, \sqrt{1 - {\mathrm{n_3}}^2} + {\mathrm{n_3}}^2\, \sqrt{1 - {\mathrm{n_3}}^2} - {\mathrm{n_2}}^2 - {\mathrm{n_3}}^2 + 1 & \mathrm{n_2}\, \mathrm{n_3}\\ - \mathrm{n_1}\, \mathrm{n_3} & - \mathrm{n_2}\, \mathrm{n_3} & \sqrt{1 - {\mathrm{n_3}}^2} \end{array}\right)}$$ This is found from this MATLAB code . EDIT #3: Using $\vec{n}=(\frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}})$ I find this parametrically plots",['geometry']
492610,Relations that are: reflexive but not transitive; transitive but not symmetric; symmetric but not reflexive,"I have an incomplete answer to my question. Can anyone help me answer the last two parts. My question is: Find example of a set $S$ and three relations $R_1$, $R_2$, $R_3$ on it such that $R_1$ is reflexive but not transitive $R_2$ is transitive but not symmetric $R_3$ is symmetric but not reflexive My solution is: Let's start with the first part of the question. For simplicity, we will use a small set to work with, say $\{a, b, c\}$. First, the definitions. A binary relation (we'll call it $R$) is reflexive if $(x, x) \in R$. And a relation is transitive if $(x , y)\in R$ and $(y, z) \in R$ implies that $(x, z) \in R$. So an example of a reflexive relation that is not transitive on $\{a,b,c\}$ would be the following relation: $$\{(a,a),(b,b),(c,c), (a,b), (b,c)\}$$ Note that every element is in relation to itself, so it is reflexive. However, it is not transitive, because although $a$ is in relation with $ b$ and $b$ is in relation to $c$, $a$ is not in relation $c$. Can anyone help me answer the other two parts of the question ?","['relations', 'elementary-set-theory']"
492622,what to do next recurrence relation when solving exponential function?,"find gernal solution of :$a_n = 5a_{n– 1} – 6a_{n –2} + 7^n$ Homogeneous solution: $$a_n -5a_{n– 1} + 6a_{n –2} = 7^n$$
put $a_n=b^n$: $$b^n -5b^{n– 1} + 6b^{n –2} =0
\\b^{n-2} (b^2-5b^{} + 6b) =0
\\b^2-5b^{} + 6b =0
\\(b-2)(b-3)=0\\
b=2,3$$
$$a^h_{(n)} = C_1 3^n+ C_2 2^n$$ Particular solution:
Since RHS is exponent so $a^p_{(n)} = da^n$ put $a^p_{(n)}$ in $a_n -5a_{n– 1} + 6a_{n –2} = 7^n$ $$da^n -5da^{n– 1} + 6da^{n –2} =7^n$$","['recurrence-relations', 'discrete-mathematics']"
492637,Differential — Mathematically conform?,"In calculus, I know that one defined the differential quotient
$$\frac{dy}{dx} := \lim\limits_{h \rightarrow 0}{\frac{y(x+h)-y(x)}{h}}$$
I learned that it is not a quotient , but can be treated as one in many cases which you can prove like
$$ \frac{dy}{dx} = {\frac{dx}{dy}}^{-1} \quad or \quad \frac{dy}{dx} \frac{dx}{dt} = \frac{dy}{dt} $$
For examples like that, it seems more intuitive and is easier to understand — but in a mathematically conform way . As far as this, no problem — until I reach some content in my book saying things just like
$$ dU = d\vec{r} \cdot \operatorname{grad} U \quad \text{or even} \quad d\vec{r} \times \stackrel{\rightarrow}{A} = 0  $$ This confuses me in two ways: Math is the only science where it is essential to define everything which appears in an equation/expression etc. When I see the term $dy$, I ask myself “How is this defined?”.
Each of the terms $\frac{dy}{dx}$, $∫fdx$ etc. have a concret definition, wheras $dy$ doesn't seem to have one — intuitively, one supposes to say $dx := \lim\limits_{h\rightarrow 0}{\left(x – (x+h)\right)}$, which would exactly be zero.
According to what Wikipedia says, it is defined as $df(x,Δx):=f'(x)Δx$, which would not accord to the differential with one parameter as always used.
Therefore, WP says $df(x):=f'(x)dx$ which is not appropriate because one cannot define a new operator under usage of this new operator itself. When some new content is introduced in a book with these expressions, even if I understand the intuitive sense or meaning of this equation, I feel like not to have understood a single word (or variable), because 90% of my thoughts ask how I should evaluate the equation/expression mathematically and that it is not legitimate to approve such knowledge based on wrong or unclear axioms, which results in a 2h-long bafflement. Could you please make this topic a little more clear for me?","['differential', 'calculus', 'definition']"
492676,Recognizing that a function has no elementary antiderivative [duplicate],"This question already has answers here : How can you prove that a function has no closed form integral? (7 answers) Closed 9 years ago . Is there a method to check whether a function is integrable? Of-course trying to solve it is one but some questions in integration may be so tricky that I don't get the correct method to start off with those problems. So, is there a method to find correctly whether a function is integrable? Clarification: I am asking about indefinite integrals which have no elementary anti derivative.","['calculus', 'integration']"
492686,Can we generalize the regular value theorem even beyond the Ehresmann's theorem?,"The formulation is complicated, but the answer may be some clever usage of the partition of unity, because locally the answer is given by the regular value theorem and the whole problem is to glue it to a global thing. Anyway, I don't know how to do it. Introduction Ehresmann's theorem generalizes the regular value theorem. It states that there is a natural diffeomorphism $$f^{-1}(B_n) \simeq B_n \times f^{-1}(n),$$
where $n$ is a regular value of $f$, $B_n$ is its sufficiently small neighbourhood and $f$ is a smooth proper map between manifolds $f\colon M\to N$ (proper = pre-image of a compact set is compact). We can restrict to the case where $M$ is compact - then $f$ is always proper. We can easily further generalize it to the case where we take the pre-image of (a neighbourhood of) a smooth submanifold $V$ of $N$ instead of a single point $n\in N$, assuming that the normal bundle to it is trivial: by tubular neighbourhood theorem we can find a neighbourhood of $V$ diffeomorphic to $V\times B$ (where $B$ is a ball in the normal bundle), and deduce the claim by applying the theorem to the composition $\pi_{_B} \circ f$, where $\pi_{_B}$ is the projection $V\times B\to B$. I want to ask if this diffeomorphism may be natural in some way and if the theorem can be generalized to nontrivial bundles. Question To formulate the question properly, let's look at normal bundles $\def\N{\mathcal N} \N$. We can see that $$\pi_{\N(V)}\circ f_*:\N(f^{-1}(V))\to \N(V)$$ establishes a fiberwise isomorphism of the bundles (where $\pi_{\N(V)}$ is the orthogonal projection $TN\to \N(V)$) and thus we can think of $\N(f^{-1}(V))$ as a pullback of $\N(V)$. Since by the tubular nbhd thm normal bundles are diffeomorphic with the respective neighbourhoods, $f^{-1}(U)$ is some kind of pullback, but we have to go through the normal bundles and tangent maps to see this. The question is if we can represent it as a pullback naturally with respect to $f$ (not $f_*$). Formally: Can we find such diffeomorphisms $\N(f^{-1}(V))\overset{d_M}\to f^{-1}(U)$  and $\N(V)\overset{d_N}\to U$ that the composition:
  $c = d_N^{-1} \circ f \circ d_M$ is ""fiberwise""; i.e., it is a  diffeomorphism on the fibres: $\N_{w}(f^{-1}(V)) \to \N_{f(w)}(V)$ for each $w\in f^{-1}(V)$ (not necessarily equal to $\pi_{\N(V)}\circ f_*$). Update: I think that the orthogonal projection $\pi_{\N(V)}$ in the formula above establishing the pullback may be omitted if we choose appropriate scalar product on $TM$ (divide $T_{f^{-1}(V)}M$ into orthogonal [with respect to any scalar product] subspaces: $\mathrm{ker} f_* \oplus W$ and observe that $W$ is isomorphic to $T_{V}N$ by $f_*$ so it is enough to pull the scalar product back from $TN$ to $V$). Does it help anyhow?","['fiber-bundles', 'manifolds', 'algebraic-topology', 'differential-geometry']"
492698,a finitely additive measure that is continuous at $\emptyset$ is $\sigma$-additive,"Let $ (\Omega,M)$ a $\sigma$-algebra of events, and let $P$ be a finitely additive measure. We say that $P$ is continuous at an event $ A\in M$ if $A_n,B_n\in M$ are sequences of events such that $A_{n+1}\subset A_n$ , $B_n \subset B_{n+1}$ and $ \cup B_n=A=\cap A_n$ then $ \lim_{n\to \infty}P(A_n)=\lim_{n\to \infty} P(B_n)$. It's well known that if $P$ is $\sigma$-additive then it's continuous at each point. Here we have a reciprocal, but I can't prove it. Prove that if $P$ is a finitely additive measure that is continuous at $\emptyset$, then $\sigma$-additive, and thus is continuous at each event. Clearly continuous at $\emptyset$ only consider decreasing sequences $A_n$. This is my attempt: Let $C_n$ a disjoint sequence of events. Let $ C=\cup_{k=1}^{\infty}C_k$, $A_n= \cup_{k=n+1}^{\infty} C_k$, $B_n= \cup_{k=1}^{n} C_k$. Obviously $C=A_n \cup B_n$ , we want to prove that $P(C)=\sum_{k=1}^{\infty}{P(C_k)}$. Note that using finitely additivity $P(C)=P(A_n)+P(B_n)=P(A_n)+\sum_{k=1}^{n}{P(C_k)}$.
Since $A_n \to \emptyset$ decreasing, $P(A_n)\to 0$, thus given $\epsilon>0$ there exist $N_{\epsilon}$ such that, $n \ge N_{\epsilon} \Rightarrow 0\le P(A_n)< \epsilon$ . Fixing some $M$ such that $M> N_\epsilon$  $P(C)=P(A_M)+\sum_{k=1}^{M}{P(C_k)}<\epsilon+\sum_{k=1}^{M}{P(C_k)}<\epsilon+\sum_{k=1}^{\infty}{P(C_k)}$ And since this inequality it's for every $\epsilon>0$ we conclude that $ P(C) \le \sum_{k=1}^{\infty}{P(C_k)}$ i.e is $\sigma$-subadditive , but I don't know how to continue, and if I have some mistakes in my proof, because I used only properties of measure, not even probability.","['probability-theory', 'measure-theory']"
492707,Why $f(x) = \sqrt{x}$ is a function?,"Why $f(x) = \sqrt{x}$ is a function ( as I found in my textbook ) since for example the square root of $25$ has two different outputs ($-5,5$) and a function is defined as ""A function from A to B is a rule of corre-
spondence that assigns to each element in set A exactly one element in B."", so $f(x) = \sqrt{x}$ is not a function?",['functions']
492713,Surface infinitesimals and its intuitive manipulation?,"The excess pressure in the concave side of any liquid bubble or drop with surface tension of the liquid being $T$ is $\frac {4T}r$ and $\frac {2T}r$ respectively . I wanted to derive it using a parametrized sphere and then considering the equilibrium of an infinitesimal area element , but this heavily depended on the intuition behind surface integrals and was unconventional. I was hoping for some support here:- Alternative Method Consider a spherical drop (the bubble case is almost similar) centred at $(0,0,0)$ and characterised by $$\vec r=r \cos \theta \hat z+r \sin \theta \cos \phi \hat x+ r \sin \theta \sin \phi \hat y$$ 
$$0<\theta<\pi\text{ };\text{ }0<\phi<2\pi$$
 Where $\theta$ is the angle of the position vector with $z$ axis and $\phi$ the angle of the projection of the position vector in x-y plane with x axis. The infinitesimal area element will be $$|\frac {d\vec r}{d\theta}\times \frac{d\vec r}{d\phi}|d\theta d\phi\hat r=r^2\sin\theta d\theta d\phi \hat r=\vec {da}$$ 
This is, intuitively( or so i believe), actually an area bound by the parallelogram having its two sides as $\frac {d\vec r}{d\theta}d\theta(=r_\theta d\theta)$ and $\frac{d\vec r}{d\phi}d\phi(=r_\phi d\phi)$[Fig(a)]. Thus, to calculate the downward force by the surface tension, we consider the net force in the downward ($-\hat r$) direction and equate it to $\Delta P\vec {da}$ to get the value of $\Delta P$. To evaluate the force of surface tension, consider the side $r_\theta$ of the infinitesimal area parallelogram. Considering $T$ to be per unit length , the force on this (sidewards) is $2T \sin\frac{d\theta}{2}$ which is $Td\theta$ per unit length[Fig(b)]. This is valid for the length of $|r_\phi|d\phi$ [Fig(c)]which evaluates to net downward force as $T|r_\phi|d\theta d\phi$. Considering the side of $r_\phi$, the same arguments apply and the net downward force on either side of this will be $T|r_\theta|d\theta d\phi$. hence:-$$\Delta P\vec {da}=Td\theta d\phi (|r_\theta|+|r_\phi|)(\hat {-r})$$ But this does not yield the answer. It comes close but not quite the answer. In fact it predicts non-uniform pressure for different spherical co-ordinates, which is obviously not correct. Is there something wrong with my intuition or my calculations? Sorry, if this has a trivial mistake .","['multivariable-calculus', 'surfaces', 'physics', 'infinitesimals']"
492719,Sets with no asymptotical density over $\mathbb N$,"Let's consider the Natural density on $\mathbb N$ defined by: Take $ A\subset \mathbb N$; define the sequence $x_n= \dfrac{|A\cap[1,n]|}{n}$, and then if $\lim\limits_{n\to\infty} x_n$ exists, call it $d(A)$, the density of $A$ over $\mathbb N$. My teacher said that the collection of sets that have a natural density is not an algebra, but I don't know why. I can't even find a set that does not have a natural density. Please help me )=","['measure-theory', 'number-theory']"
492732,"Proposed proof for: if $\{s_{n}\}$ is bounded, then $\{\frac{s_{n}}{n}\}$ is convergent.","I have written a proposed proof for the proposition below, but I am not entirely certain if it is valid. Could someone take a look at it, and let me know if you see any errors or steps that could use more justification? Proposition 1: Let $\{s_{n}\}$ be a sequence of real numbers. If $\{s_{n}\}$ is bounded, prove that $\{s_n/n\}$
is convergent. Proof. Assume that $\{s_{n}\}$ is bounded. Then, by definition, there exists
$M\in\mathbb{R},M>0$ such that
$$|s_{n}|\leq M\qquad\forall n.$$ That is, 
$$
-M\leq s_{n}\leq M\qquad\forall n.
$$ It follows that
$$
\frac{-M}{n}\leq\frac{s_{n}}{n}\leq\frac{M}{n}\qquad\forall n,$$ and so 
$$
|\frac{s_{n}}{n}|\leq\frac{M}{n}\qquad\forall n.$$ Therefore, we have 
$$
|\frac{s_{n}}{n}-0|\leq\frac{M}{n}\qquad\forall n.$$ Now, for every $\epsilon>0$ and every $M>0$, there exists an $n\in\mathbb{N}$
such that $\frac{M}{n}<\epsilon$. For, suppose not: then there exists
$\epsilon>0$ and $M>0$ such that for every $n\in\mathbb{N}$, we
have $\frac{M}{n}\geq\epsilon$. It follows that 
$n\leq\frac{M}{\epsilon}\;\forall n$. This, however, contradicts the fact that $\mathbb{N}$ is unbounded
above. Thus, our original claim must hold. Furthermore, if for some
$\epsilon>0$, $M>0,$ and some $n\in\mathbb{N}$, we have 
$\frac{M}{n}<\epsilon$, then $\frac{M}{p}<\epsilon$ for every $p\in\mathbb{N}$,
where $p>n$ (should I include a proof by induction of this statement as a lemma? Or is it sufficiently obvious?). But if it is true that for every $\epsilon>0$ and every $M>0$, there
exists an $n\in\mathbb{N}$ such that $\frac{M}{n}<\epsilon$, it
implies that we can make the expression
$|\frac{s_{n}}{n}-0|$ less than any given $\epsilon$. Therefore, for every $\epsilon>0$, there exists an $N\in\mathbb{N}$
such that $n>N$ implies 
$|\frac{_{s_{n}}}{n}-0|\leq\frac{M}{n}<\epsilon$. It follows that $\{\frac{s_{n}}{n}\}$ converges, and, in particular,
that $\{\frac{s_{n}}{n}\}\rightarrow0$ as $n\rightarrow\infty$. QED Thanks in advance!",['real-analysis']
492746,Eigenvalues of $AB$ from eigenvalues of $A$ and $B$,"Is it possible to find the eigenvalues of $AB$ if we know the eigenvalues of $A$, say $\lambda_1, \lambda_2,...,\lambda_n$ and those of $B$ say $\lambda_1, \mu_2,...,\mu_n$ and given that $A$ and $B$ are positive semi/definite symmetric complex valued matrices. Even if not possible can we build a relation of magnitude of the eigenvalues? Thank you.
Related to https://math.stackexchange.com/questions/492697/possible-determinant-inequality-det-leftiaaib-right-1-leq-det-l","['matrices', 'linear-algebra', 'eigenvalues-eigenvectors']"
492750,Reformulation of the Weak Axiom of Revealed Preference,"This question about foundations of mathematical economics. Let $X$ be some set, $\mathcal{B}\subset 2^{X}$ and $C:\mathcal{B}\rightarrow 2^{X}$ such that for all $B\in\mathcal{B}$ we have 1) $C(B)\neq\emptyset$; 2) $C(B)\subset B$. The Weak Axiom of Revealed Preference (see http://en.wikipedia.org/wiki/Revealed_preference ) states that for all $B_{1},B_{2}\in\mathcal{B}$ with $x,y\in B_{1}$, $x,y\in B_{2}$ and $x\in C(B_{1})$, $y\in C(B_{2})$ it holds that $x\in C(B_{2})$. My question is following Does there exists purely set-theoretic reformulation of the Weak Axiom of
  Revealed Preference? I'm looking for something like this $$B_{1},B_{2}\in\mathcal{B},\ x\in C(B_{1})\cap B_{2},\ y\in C(B_{2})\cap B_{1}\Rightarrow \{x,y\}\in C(B_{1})\cap C(B_{2}).$$ but in more ""closed-formula"" way (i.e. without $x$ and $y$).","['economics', 'elementary-set-theory']"
492751,Is Zorn's lemma necessary to show discontinuous $f\colon {\mathbb R} \to {\mathbb R}$ satisfying $f(x+y) = f(x) + f(y)$?,"A UC Berkeley prelim exam problem asked whether an additive function $f\colon {\mathbb R} \to {\mathbb R}$, i.e. satisfying $f(x + y) = f(x) + f(y)$ must be continuous. The counterexample involved taking a positive-valued Hamel basis $X$ of $\mathbb{R}$ as a vector space over ${\mathbb Q}$, and then letting $f(x_1) =1$ and $f(x_2)=-1$ for two different $x_1,x_2 \in X$, and letting $f(x)$ be arbitrary for other $x \in X$, and then extending the function to all of ${\mathbb R}$ using the property of additivity. Then a sequence $a_n = {p_nx_1 + q_nx_2}$ could be found with rational $p_n,q_n$ such that $a_n \to 0$ but $\lim \limits_{n\to \infty} f(a_n) \neq 0$, showing discontinuity. But is Zorn's Lemma necessary to produce such an example? In other words, is Zorn's Lemma saying we can find a Hamel basis of ${\mathbb R}$ over ${\mathbb Q}$ equivalent to being able to construct a discontinuous additive function $f\colon {\mathbb R} \to {\mathbb R}$?","['set-theory', 'axiom-of-choice', 'real-analysis', 'functional-equations']"
492767,Is this an analog of the mean value theorem for vector-valued functions?,"I was reading through various proofs of the multi-dimensional analogues of the mean value theorem. Suppose we have a $C^1$ function $f: \mathbb{R}^n \supseteq U \to \mathbb{R}^m$. I had thought there was a theorem that Given a ball $B\subset U$,  $x,y\in B$, there exists a point $\xi \in B$ such that $f(x)-f(y)= Df(\xi)(x-y)$ , although in general $\xi$ will not lie on the line between $x$ and $y$. But the way I had remembered to prove it is incorrect. Is this a theorem at all? Another related theorem is that \2. Suppose $C\subset U$ is convex. Given $x,y \in C$, suppose $\|Df(\xi)\| \leq \eta$ for all $\xi $ on the line between $x$ and $y$. Then $\|f(x) - f(y)\| \leq \eta \|x-y\|$. The proofs I'm reading for #2 are somewhat complicated (e.g. Rudin PMA pp. 113 and 219), and I wondered if there was a simpler one just leveraging #1. Thanks for clarifying this for me.","['multivariable-calculus', 'derivatives']"
492780,How to find a homeomorphism $\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}$ having certain properties,"Let $n\ge 2$ and let $C$ be a Cantor space in $\mathbb{R}^{n}$ . That is, $C$ is homeomorphic to the Cantor ternary set . Let $x$ and $y$ be two points in $\mathbb{R}^{n}-C$ , and let $L_{xy}$ be the straight line segment joining them. For a fixed $\varepsilon>0$ we would like to to find a homeomorphism $\phi:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}$ such that $\phi(x)=x$ and $\phi(y)=y$ . Outside an $\varepsilon$ -neighborhood of $L_{xy}$ , $\phi$ is the identity, and $|\phi(z)-z|<\varepsilon$ . $\phi(L_{xy})\cap C=\emptyset$ . How do we construct/show existence of such a homeomorphism $\phi?$","['general-topology', 'real-analysis', 'cantor-set']"
492781,Why is the directional derivative $D_v(F)$ equal to $\nabla F \cdot v$?,"Why is the directional derivative $D_{\bf v}(F)$ equal to $\nabla F \cdot {\bf v}$?  It doesn't seem obvious from the definition of the directional derivative, $$\lim_{h \to 0} \frac{f({\bf x} + h{\bf v}) - f({\bf x})}{h}$$","['multivariable-calculus', 'calculus']"
492785,Bijective function,"Recently I was wondering if we need the Axiom of Choice in order to find an inverse function given an bijective funcion:
If $f:A \rightarrow B$ is bijective we mean that $f$ is injective and surjective. Assume that $f:A \rightarrow B$ is bijective. I want to define $f^{-1}: B \rightarrow A$ s.t. $f \circ f^{-1} = 1_B$ and $f^{-1} \circ f = 1_A$. For each $b \in B$ let $X_b := \{x \in X: f(x) = b \}$. By surjectivity each $X_b$ is non-empty. But not knowing wether $A$ or $B$ are finite I need AC in order to select from each $X_b$ an (in fact unique) element $x_b$ and defining $f^{-1}(b) := x_b$ for each $b \in B$. Is AC necassary ?","['elementary-set-theory', 'functions']"
492816,"Prove that all the solutions of (2): $\frac{dy}{dt}=A(t)y+f(t)$ are bounded in $ \left[t_0,+\infty \right )$","I have a problem: Assume that system (1): $$\dfrac{dx}{dt}=A(t)x$$ is stable, where
  $A(t) \in C\left [t_0,+\infty  \right )$, when $t \to \infty$ and $$\begin{cases}
 & \mathrm{  } \lim \inf_{t \to \infty}\int_{t_0}^{t}Tr(A(t_1)dt_1> - \infty;(1') \\ \\
 & \mathrm{  } \int_{t_0}^{\infty}\left \|f(t_1)  \right \|dt_1<+\infty; (2').
\end{cases}$$ Prove that all the solutions of (2): $$\frac{dy}{dt}=A(t)y+f(t)$$ are
  bounded in $ \left[t_0,+\infty  \right )$. ........................................................................... Ok, Here's my solution: (I'm not sure, but I still post it). Assume that $X(t)$ be a fundamental matrix of (1), $X(t_0)=E$. Then $$y(t)=X(t)X^{-1}(t)x(t_0)+X(t)\int_{t_0}^{t}X^{-1}(s)f(s)\mathrm{ds}$$ Because system (1) is stable, so $X(t)$ is bounded Applying Ostrogradski - Liouville, we have:$$\det X(t)=\det E \cdot \exp \left[\int_{t_0}^{t} TrA(s)\mathrm{ds}\right]=\exp \left[\int_{t_0}^{t} TrA(s)\mathrm{ds}\right]$$
whence 
$$\lim \inf_{t \to \infty}\int_{t_0}^{t}Tr(A(s)\mathrm{d}s=\lim \inf_{t \to \infty}\ln\det X(t)> - \infty$$ We see that, provided (1') is satisfied, $X^{-1}(t)$ is bounded as $t \to \infty$. Let $c_1=\max\{\sup_{t \ge t_0}\|X(t)\|;\sup_{t \ge t_0}\|X^{-1}(t)\|;\sup\|y(t_0)\|\}$. Therefore, $\|y(t)\| \le c_{1}^{3}+c_{1}^{2}\int_{t_0}^{t}\|f(s)\|\mathrm{d}s$. Since (2'): $\int_{t_0}^{\infty}\left \|f(t_1)  \right \|dt_1<+\infty$, we're done! I've made several errors with my solution, may be! :(.
Anyone can check it help me? Thanks!","['control-theory', 'trace', 'ordinary-differential-equations']"
492821,On a Putnam's 2009 problem [duplicate],"This question already has answers here : On the problem $1$ of Putnam $2009$ (2 answers) Closed 10 years ago . Find all even natural numbers $n$ such that the following is true: There is a non-constant function $f : \Bbb{R}^2 \longrightarrow \Bbb{Z}_2$ such that for any regular $n$-gon $A_1...A_n$, $f(A_1) + \cdots + f(A_n) =0$. NOTE: This is the unsolved part of THIS problem. I chose to state it in a separate question first to get more attention and second since some people may want to put a bounty on this part.","['geometry', 'problem-solving', 'combinatorics']"
492834,Geometric Mean limit of $\ell_p$ norm of sums,"My analysis professor introduced the $\ell_p$ norm to our class as:
\begin{align}
\| x \|_p = \left(\frac{1}{n}\sum_{j=1}^{n} |x_j|^p\right)^{1/p}.
\end{align} We are asked to prove the following:
\begin{align}
\lim_{p \to 0} \|x\|_p &= \left( \prod_{j=1}^{n} |x_j| \right)^{1/n},
\end{align} Can anyone give me a sort of ""intuition"" as to why this is true, and a hint as to how to approach the problem? All the reading material I come across uses measure theory and integrals instead of sums so I can't quite follow it. On another note, is there any way to improve mathematical intuition? It seems that every proof in the class relies on little mathematical ""tricks"", which I find frustrating because I don't even know where to begin for the problems we're assigned. (I find that it's not at all the same in my Algebra or Probability classes) Thank you!","['normed-spaces', 'intuition', 'lp-spaces', 'limits']"
492839,Block Decomposition of a linear map on $\Lambda^2TM$,"I'm trying a exercise from Peter Petersen's book, and I did the following: Let $*$ be the Hodge star operator, I know that $\Lambda^2TM$ decompose into $+1$ and $-1$ eigenspaces $\Lambda^+TM$ and $\Lambda^-TM$ for $*$. I know that, if $e_1,e_2,e_3,e_4$ is an oriented orthonormal basis, then
  $$e_1\wedge e_2\pm e_3\wedge e_4\in\Lambda^{\pm}TM$$
  $$e_1\wedge e_3\pm e_4\wedge e_2\in\Lambda^{\pm}TM$$
  $$e_1\wedge e_4\pm e_2\wedge e_3\in\Lambda^{\pm}TM$$ What i can't prove is: Thus, any linear map $L:\Lambda^2TM\to\Lambda^2TM$ has a block decomposition
  $$\begin{bmatrix}
 A&B \\ 
 C&D 
\end{bmatrix}$$ $$A:\Lambda^+TM\to\Lambda^+TM$$
$$B:\Lambda^-TM\to\Lambda^+TM$$
$$C:\Lambda^+TM\to\Lambda^-TM$$
$$D:\Lambda^-TM\to\Lambda^-TM$$","['linear-algebra', 'riemannian-geometry']"
492841,Tate's proof that the character group of a local field is isomorphic to its additive group,"I'm reading Tate's thesis, and I'm stuck on one of his proofs. Let $k$ denote the completion of an algebraic number field at a prime divisor $p$. Tate claims that the additive group $k^+$ of $k$ is isomorphic, both topologically and algebraically, to its character group. Let $\xi \mapsto \chi(\xi)$ be a non-trivial character of $k^+$ and define a map from $k^+$ to $\widehat{k^+}$ by $\eta \mapsto \chi(\eta \xi)$. He proves that the map is injective and bicontinuous, but I don't understand why the map is surjective. In the proof he first shows that the image of the map is dense in $\widehat{k^+}$. By bicontinuity, the image is locally compact. Then he concludes, ""Local compactness implies completeness and therefore closure..."" (p. 309 of Cassels & Frohlich). Could someone explain that sentence? How does local compactness imply completeness, and what does completeness even mean in the case of a character group? Is there a metric on the character group? I've looked in several books (e.g. Lang's Algebraic Number Theory, Ramakrishnan & Valenza) and could not find an explanation. I'd appreciate any help.",['number-theory']
492846,Show the Grassmannian is a smooth manifold (using dummy definition of smooth manifold),"We received the following problem in my Differential Geometry class: Suppose $0\leq k \leq n$ are integers. Let $G(k,n)$ be the collection of orthogonal projections $T: \mathbb{R}^n \to \mathbb{R}^n$ with rank $k$. Identifying the collection $L(\mathbb{R}^n , \mathbb{R}^n)$ of linear transformations $\mathbb{R}^n \to \mathbb{R}^n$ with the collection $M_{n \times n}$ of $n \times n$ matrices, show that $G(k,n) \subset M_{n\times n} \simeq \mathbb{R}^2$ is a smooth manifold. Here our (provisional) definition of a $k$-manifold is $M \subset \mathbb{R}^n$ is a $k$-manifold if for each point $p\in M$ there exists a neighborhood $U$ of $p$ and $I = \{i_1, \dotsc, i_k\} \subset \{1,\dotsc,n\}$ such that $U \cap M$ is the graph of a $C^\infty$ function $f: V \to \mathbb{R}^{I^c}$, where $V \subset \mathbb{R}^I$ . Now I know the Grassmannian should have dimension $k(n-k)$ (see this question). That means that out of the conditions $F: \mathbb{R}^{n^2} \to \mathbb{R}^{n^2}$ requiring $\rho$ to be an orthogonal projection of rank $k$, I need to find a submatrix of $DF$ of dimension $n^2 - k(n-k) = n^2 - kn +k^2$ which is non-singular. The requirements are 1. $\rho^2 = \rho \; $ 2. $\rho^T = \rho \;$ 3.  $\operatorname{rk}{(\rho)}=k$. So $$a_{ij} = a_{ji} \tag{1}$$ $$\sum_{k=1}^n a_{ik}a_{kj} = a_{ij} \tag{2}.$$ I need to find a clever way to express the last one as an equation, and to show that at each point there is the necessary submatrix. Any ideas?","['multivariable-calculus', 'differential-geometry']"
492856,Solving homogeneous differential equation in symmetric form,"Let $g: \mathbb R \rightarrow \mathbb R$ be a differentiable and integrable function. The integral curve of the differential equation is: $(y + g(x))dx + (x - g(y))dy = 0$ that passes through the point $(1, 1)$ must also pass through which of the following points? $(0, 0),$
$(2, 1/2),$
$(1/2, 2),$
$(-1, -1),$ or 
$(0, 1)$",['ordinary-differential-equations']
492858,Jacobian matrix and Hessian matrix identity,"I am trying understand the following identity in two dimensions: $$ H_{XY} = J^TH_{xy}J$$ Here $x,y$ and $X,Y$ are different coordinates for $\mathbb R^2$, the $J$ is the Jacobian matrix and the $H$ are the Hessian matrices in the coordinates. My thoughts are the following: the $J$ is locally a coordinate transformation from $XY$ to $xy$ coordinates. At least is how I thought of Jacobians until today. The problem is that then $J^T$ should be $J^{-1}$. I checked and Jacobians are not necessarily unitary. Now I wonder: how do I understand the equation above and in general the Jacobian matrix? In particular why is it $J^T$ and not $J^{-1}$?","['multivariable-calculus', 'linear-algebra']"
492859,Elegant solution of a problem about binary relations,"Let $f$, $g$, $a$, $b$ are binary relations on some set. I want an elegant proof that $(a\circ f^{-1})\cap(g^{-1}\circ b) \ne \varnothing \Leftrightarrow (\operatorname{dom}a\times\operatorname{dom}b)\cap f\ne\varnothing \wedge (\operatorname{im}a\times\operatorname{im}b)\cap g\ne\varnothing$. I have a solution myself (I have reduced it to the special case when $\operatorname{card}a=\operatorname{card}b=1$.) But I want a more direct and more elegant proof.","['relations', 'elementary-set-theory']"
492880,Is an ultrafilter free if and only if it contains the cofinite filter?,"A filter $\mathcal F$ is called free if $\bigcap \mathcal F=\emptyset$. Filter, which is not free is called principal. any principal ultrafilter has the form $$\mathcal F_a=\{A\subseteq X; a\in A\}$$ for some $a\in X$.
Fréchet filter (or. cofinite filter) on a set $X$ is the filter consisting of all cofinite set, i.e., it is equal to $$\mathcal F_{F}=\{A\subseteq X; X\setminus A\text{ is finite}\}.$$ Is an ultrafilter  free if and only if it contains the cofinite  filter ? Why ?","['general-topology', 'filters', 'elementary-set-theory']"
492892,Isometry Group of a Manifold,"Let $(M,g)$ be a Riemannian manifold and let $I = Iso(M)$ be the group of isometries of $M$. Suppose that $I$ has no subgroups. What does this tell us about $M$?",['differential-geometry']
492904,approximation of sum of gaussian-like function?,"Let: $g(u; x,s) = \dfrac{1}{s\sqrt{2\pi}} \exp\left(-\dfrac{1}{2} \left(\dfrac{x-u}{s}\right)^2\right)$ Where $x,s$ are parameters I'm looking for a closed-form solution or approximation of: $f_1(k) = \dfrac{\sum\limits^{r=+\infty}_{r=-\infty} rg(k+rD)}{\sum\limits^{r=+\infty}_{r=-\infty} g(k+rD)}$ and $f_2(k) = \dfrac{\sum\limits^{r=+\infty}_{r=-\infty} r^2g(k+rD)}{\sum\limits^{r=+\infty}_{r=-\infty} g(k+rD)}$ Typically: $D > 0$ $0 < s < D$ $\dfrac{-D}{2} < k < \dfrac{D}{2}$ $\dfrac{-D}{2} < x < \dfrac{D}{2}$ In practice, the summation converges very quickly, so $r$ is summed from at most -10 to 10. Background: this resulted from working with wrapped gaussians, where I need to solve this equation for $k$: $\sum\limits^{N}_{n=0}p(n)\left(x_n - k - D \frac{\sum\limits^{\infty}_{r=-\infty} rg(k+rD;x_n,s_n)}{\sum\limits^{\infty}_{r=-\infty}g(k+rD;x_n, s_n)} \right) = 0$ If the nastiness with last fraction of sums wasn't there, it'd be super easy.","['numerical-methods', 'sequences-and-series', 'summation', 'discrete-mathematics']"
492938,"The book ""Opera De Cribro"" by John Friedlander and Henryk Iwaniec","John Friedlander and  Henryk Iwaniec wrote a book Opera De Cribro . 
How about this book? What's the meaning of its title?  A number theory book with such a title seems odd. p.s.  I have no way to buy this book or borrow a copy at the moment, so I want to learn some information about  it.","['reference-request', 'number-theory']"
492941,Sufficient statistics and isometries,"Let $(M,g)$ be an infinite dimensional statistical manifold with the Fisher information metric $g$. Is it true that any isometry on this manifold must correspond to a sufficient statistic?","['statistics', 'information-geometry', 'differential-geometry']"
492971,Equality of inner and outer measure,"I have the following elementary Lebesgue measure theory question: Let $E\subset \mathbb{R}^n$ with $|E|_e$ finite. Then $E$ is measurable if and only if $|E|_i = |E|_e.$ I wrote the following proof: Let $\epsilon >0$. A set $E$ is measurable if and only if there exist an open set $G\supset E$ and a closed set $F\subset E$ such that
$$
|G\setminus E|_e <\frac{\epsilon}{2}
$$
and
$$
|E\setminus F|_e <\frac{\epsilon}{2}
$$
Now since $G\setminus F = (G\setminus E) \cup (E \setminus F)$, we have
$$
|G\setminus F|_e \leq |G\setminus E|_e + |E\setminus F|_e< \epsilon
$$
by the above inequalities. Thus, $E$ is measurable if and only if $|E|_i = |E|_e$. What's wrong with this proof? I never use the fact that $|E|_e$ is finite. Thanks so much.","['measure-theory', 'proof-verification', 'real-analysis']"
492985,why is the square of this matrix with sin and cos equal to the identity matrix?,"I have a question about why the square of the 
matrix  Q, below, is equal to the identity matrix. Q = cos X  -sin X
   sin X   cos X My knowledge of trigonometry seems to have rotted away, and I can't 
figure out what rules are used to justify the statement  made
by professor Strang at 11:55
of this video > Lec 20 | MIT 18.06 Linear Algebra, Spring 2005 (he says the square of  Q is equal to I) The thing that has me stuck is the following:   In order to calculate the 
first cell of  Q * Q   we take the dot product of the first row and the 
first column.  That would be cos^2 Q  -  sin^2 Q But how is that equal to the ""1"" that we want in the upper left most cell 
of the identity matrix ? If this were 
      cos^2 Q  +  sin^2 Q then it would be equal to 1.. but we have a difference here, not a sum. Thanks in advance !
   chris epilogue:  thanks for the answers ! I don't know how I missed the fact that he was not making this claim for Q^2,  but  Q-transpose * Q, instead. Appreciate your pointing it out.","['matrices', 'linear-algebra', 'trigonometry']"
492989,Linear Dependence Lemma,"This is out of my textbook, Axler's ""Linear Algebra Done Right"" which I am self-studying from. ( I organized my thoughts in which I would like some sort of response with Roman Numerals ). Linear Dependence Lemma : If $(v_{1},\ldots,v_{m})$ is linearly dependent in $V$ and $v_{1} \neq 0$, then there exists $j \in \{2,\ldots,m\}$ such that the following hold: (a) $v_{j} \in span(v_{1},\ldots,v_{j-1})$; ( I. Why does this need to be justified? Is it because $v_{j}$ is an ""extra"" vector, which would make this arbitrary set of linear combinations dependent?). (b) If the $j^{th}$ term is removed from $(v_{1},\ldots,v_{m})$, the span of the remaining list equal $span(v_{1},\ldots,v_{m})$. ( II. My assumption is that this basically means that if we remove this extra vector, then we still have the same list of linear combinations). (I also found the following proof a bit confusing and need some clarification). PROOF: Suppose $(v_{1},\ldots,v_{m})$ is linearly dependent in $V$ and $v_{1} \neq 0$. Then there exists $a_{1},\ldots,a_{m} \in \mathbb{F}$, not all $0$ such that $$a_{1}v_{1}+\cdots+a_{m}v_{m} = 0$$. (So far so good, from what I know, this is just stating the opposite of Linear Independence, where the only choice of $a_{1},\ldots,a_{m} \in \mathbb{F}$ that satisfies $a_{1}v_{1}+\cdots+a_{m}v_{m} = 0$  is $a_1 =\cdots= a_{m} = 0$) CONT: Not all of $a_{2},a_{3},\ldots,a_{m}$ can be $0$ (because $v_1 \neq 0)$. Let $j$ be the largest element of $\{2,\ldots.,m\}$ such that $a_{j} \neq 0$. Then  $$ v_{j} = -\frac{a_1}{a_j}v_1 - \cdots - \frac{a_{j-1}}{a_j}v_{j-1} ,$$ proving (a). ( III. I will fill in the extra steps here because I feel that I may have the right idea). $Span(v_{1},\ldots,v_{m}) = 0$ for $j \in \{2,\ldots,m\} = a_{1}v_{1} + \cdots + a_{j}v_{j} = 0$. Here I just solved for $v_j$, and got the result  $v_{j} = -\frac{a_1}{a_j}v_1 - \cdots - \frac{a_{j-1}}{a_j}v_{j-1} ,$ which corresponds to the above. $a_{j} \neq 0$ because we have $a_j^{-1}$ for each term, and $v_1 \neq 0$ because if we have $a_{1}v_{1}+\cdots+a_{j}v_{j} = 0$ then all the scalars $a_{2},\ldots,a_{m} \in \mathbb{F}$ could be equal to $0$, if that was the case. I think I have an idea, but how exactly does this prove that $v_j$ is contained in the span of $(v_{1},\ldots,v_{j-1})$? Is it because $ -\frac{a_1}{a_j}v_1 - \cdots - \frac{a_{j-1}}{a_j}v_{j-1}$, is just a linear combination of vectors that is equal to $v_j$? CONT: to prove (b), suppose that $u \in span(v_{1},\ldots,v_{m})$. Then there exists $c_{1},\ldots,c_m \in \mathbb{F}$ such that $$u = c_1v_1 + \cdots + c_mv_m$$. In the equation above, we replace $v_j$ with the right side of 2.5, which shows that $u$ is in the span of the list obtained by removing the $j^{th}$ term from $(v_1,\ldots,v_m)$. Thus (b) holds. $\Box$ ( IV. So how exactly does this work? I find this part the most confusing). Sorry that this is such a long list, but I really want to fully understand everything I am learning, and I am pretty new to proving stuff, so I want to make sure that I improve that skill as well.",['linear-algebra']
492994,Uniqueness of Brownian motion,"May be it is a dumb question, but it vexed me a little bit. I understand the construction of the Brownian motion (first use Kolmogorov extension theorem to construct value at dyadic times and then use (Kolmogorov again?) continuity theorem to fill in the gaps). In short we get a measurable map $f: (\Omega, \mathcal F, P) \to \mathbb R^{[0, +\infty)}$ such that the trajectories are a.s. continuous, of independent increments as Gaussian r.v., etc. However, I'm considering the following (maybe too pedantic) question: Suppose there is another measurable map $\tilde f: (\tilde \Omega, \mathcal{\tilde F}, \tilde P) \to \mathbb R^{[0, +\infty)}$ whose trajectories are a.s. continuous and has finite dimensional distribution identical to the Brownian motion (constructed above). Then is there a measure preserving isomorphism (maybe modulo the null sets) $\phi: (\Omega, \mathcal F, P) \to (\tilde \Omega, \mathcal{\tilde F}, \tilde P)$ such that f = φf $\tilde f =  f\phi$? In other words is there a ""universal"" (in the sense of category theory) Brownian motion. Maybe some requirements on the space $(\tilde \Omega, \mathcal{\tilde F}, \tilde P)$ is necessary, in which case I'll assume it to be the Standard Borel probability space. Also a side remark: is such consideration really important in probability theory? Or are we satisfied with equivalences of stochastic processes (having the same finite dimensional distribution), which I suppose is weaker than measure-preserving ""isomorphisms""? Edit : I made a silly mistake in the expression of the (supposed) universal property. It should be $\tilde f = f \phi$ instead of $\tilde f = \phi f$.","['probability-theory', 'brownian-motion', 'measure-theory', 'stochastic-calculus']"
493005,Picard group of product of spaces,"Suppose $X,Y$ are varieties over an algebraically closed field $k$. Can we compute $\operatorname{Pic}(X \times_k Y) $ in terms of $\operatorname{Pic}(X),\operatorname{Pic}(Y)$? It seems that $\operatorname{Pic}(X \times_k Y) \cong \operatorname{Pic}(X) \times \operatorname{Pic}(Y)$ is not quite right, but I cannot figure out a counterexample. (I thought one might construct UFDs $A,B$, but their tensor product is not UFD).",['algebraic-geometry']
493022,showing / proving curl identity $\nabla \times \left( \frac{1}{r^2} \hat r \right) = 0$,"OK, I have to show the following: $$ \nabla \times \left( \frac{1}{r^2}  \hat r \right) = 0$$ This should be pretty easy, but I wanted to be sure I was doing this correctly. I set up the matrix: $$
        \begin{bmatrix}
        \hat r & \hat \theta & \hat \phi \\
        \frac{\partial}{\partial r}  & \frac{\partial}{\partial \theta} & \frac{\partial}{\partial \phi} \\
        \frac{1}{r^2} & 0 & 0 \\
        \end{bmatrix}
=\left(\frac{\partial}{\partial \theta}(0)-\frac{\partial}{\partial \phi}(0)\right)\hat r-\left(\frac{\partial}{\partial r}(0)-\frac{\partial}{\partial \phi}(\frac{1}{r^2})\right)\hat \theta-\left(\frac{\partial}{\partial r}(0)-\frac{\partial}{\partial \theta}(\frac{1}{r^2})\right)\hat \phi$$
which leaves me with 0 because $\frac{\partial}{\partial \theta}(\frac{1}{r^2})$ and $\frac{\partial}{\partial \phi}(\frac{1}{r^2})$ are both zero. This is correct, yes? I know this is ridiculously simple a problem but I want to make sure I did not forget everything I learned last semester. (Also, I was curious if there is a more rigorous proof, tho this is for a phys and not a math class). Edit: BTW this is in spherical (I think -- the assignment uses $\hat r$ so I am going with that).","['multivariable-calculus', 'cross-product', 'vector-analysis']"
493028,Placing Ts on the $x$-axis,"A ""T"" consists of two perpendicular intervals $\{c\}\times[0,a]$ and $[b,d]\times \{a\}$ (with $b<c<d$) on the plane. We say that the T is placed on point $c$. Is it possible to place non-intersecting T's on all real numbers on the $[0,1]$ interval of the $x$-axis? I believe the answer should be ""no"". Suppose it were possible. We can assume that each T has equal left-halfwidth and right-halfwidth (i.e. half of the horizontal line of the T.) For each real number $x\in[0,1]$, let $h_x$ denote the height of its T and $w_x$ denote its halfwidth. Then two real numbers $x,y\in[0,1]$ have intersecting T's if $h_y< h_x$ and $|x-y|\le w_y$, and vice versa. So every time we have $h_x>h_y$, we must have $|x-y|>w_y$. How can we get a contradiction?","['elementary-set-theory', 'real-analysis']"
493037,Almost everywhere limit of Borel measurable scalar functions is Borel measurable in a complete measure space,"I am trying to solve the following exercise from Royden: Let $(\Omega, \Sigma, \mu)$ be a complete measure space and $f_{n}:\Omega\to\mathbb{R}$ be measurable for each $n\geq 1$.  If $f_{n}\to f$ almost everywhere on $\Omega$, then $f$ is measurable. What I was thinking might work is if I could somehow construct an increasing sequence of measurable functions $g_{n}:\Omega\to\mathbb{R}$ which also converge to $f$ almost everywhere.  That is, $g_{n}(\lambda)\geq g_{n-1}(\lambda)$ for all $\lambda\in\Omega,n\geq 1$. Then I could use the fact that $\{\lambda\in\Omega : f(\lambda) \geq \alpha\}$ is ""almost equal"" to $\bigcup_{n=1}^{\infty}\{\lambda\in\Omega : f_{n}(\lambda) \geq \alpha\}$, and pull some magic with completeness to get that $\{\lambda\in\Omega : f(\lambda) \geq \alpha\}\in\Sigma$. Is there a way to construct such $g_{n}$?",['measure-theory']
493041,Cohomology and Global Sections,"For a topological space X, $ \  H^0 (X, \Bbb Z)$ tells you about the connected components of $X$. For a sheaf $\mathcal O_X$ on $X$, $H^0 (X, \mathcal O_X)$ is usually written to refer to global sections of your sheaf. Sorry if I'm being dense, but what is the connection? Are global sections like connected components in some sense? Also let me know if this question is imprecise, my experience with sheaves is limited.","['homology-cohomology', 'algebraic-geometry', 'algebraic-topology']"
493046,Precise mathematical translation of the 68–95–99.7 rule?(Not a proof!),"The rule: In statistics, the 68–95–99.7 rule, also known as the three-sigma rule or empirical rule, states that nearly all values lie within 3 standard deviations of the mean in a normal distribution. About 68.27% of the values lie within 1 standard deviation of the mean. Similarly, about 95.45% of the values lie within 2 standard deviations of the mean. Nearly all (99.73%) of the values lie within 3 standard deviations of the mean. So suppose that I have a set of values (measurements) which has the normal distribution property.
Let's call it S. When they say ""about 68.27% of the values"" what values do they mean? Do they mean that the standard deviation of any 68.27 % of the elements of S is smaller than 1? Do they mean something more? Could someone give me a precise mathematical statement that is equivalent to this ""68–95–99.7 rule"". I've posted this on math.stackexchange because I would like a mathematical answer.",['statistics']
493055,Equivalent characterizations of ultrafilters,"If $\mathcal{F}$ is a filter on $X$, will the below conditions be equivalent? (1) $\mathcal{F}$ is an ultrafilter. (2) For every $ \emptyset \neq M \subset X$, either $M \in \mathcal{F}$ or $X - M \in \mathcal{F}$. (3) If $F_1 \cup \ldots \cup F_n \in \mathcal{F}$, then there is $j$ s.t $F_j \in \mathcal{F}.$ I know the proofs of (2‎)$\implies$(3) and (3)$\implies$(1). Could you help me to prove (1)$\implies$(2)?","['general-topology', 'filters', 'elementary-set-theory']"
493058,"Given the first N integers, how many large prime factors can I disallow and still have half the set remaining?","Conjecture: For $N$ sufficiently large, take the set of positive integers up to $N$. Then remove all numbers which have a prime factor larger than $\sqrt{N}$. More than half the set will remain. Example: Suppose I had the set of integers from 1 to 37.
Now I keep only the multiples of 2, 3, and 5, disallowing any larger prime factors. I end up with the following set.  $$\{2,3,4,5,6,8,9,10,12,15,16,18,20,24, 25,27,30,32,36\} $$ Just over half the set $19/37 = .\overline{513}$ remains. Is my conjecture true?",['number-theory']
493063,Recommendation request: Reasoning behind statistics,"It seems, to me at least, that most Statistics textbooks focus on the Statistical methods and techniques, or on the mathematics behind them. Would you recommend me some textbooks (or any online source) that discuss the ""logical"" reasoning behind the techniques? Thanks in advance!","['statistics', 'philosophy']"
493075,Is it correct to think about homeomorphisms as deformations?,"The definition of homeomorphism is that of a continuous bijection with continuous inverse. Because we can think of continuous functions as functions that maps nearby points to nearby points, we could think that a homeomorphism is a function that in some sense deforms one topological space into another. But I'm a little unsure of that intuition because I know there's something called homotopy. I haven't get to homotopy yet, but by what I've heard, it seems that the true mathematical concept of ""deforming one space into another"" has something to do with homotopy rather than homeomophisms. Is this intuition of homeomorphisms correct? If not, what should be the intuition? Just a way to identify topologies? Thanks very much in advance!","['general-topology', 'intuition']"
493078,A non-exponentially bounded analytic function?,"A function $f:\mathbb R\to\mathbb R$ is said to be exponentially bounded if there is an $n$ such that for sufficiently large $x\in\mathbb R$, $\exp(\exp(\cdots \exp(x)))>f(x)$ (where the $\exp$ is repeated $n$ times). You know what analytic means.  Is there a ""classical"" (or easy to describe) non-exponentially bounded function? I ask because this is related to an open question in model theory, namely whether the real field, expanded with a non-exponentially-bounded function, can be o-minimal.  Most of what we know about o-minimal expansions are related to analytic functions, so I'm interested in what we could be looking for.","['analyticity', 'exponentiation', 'examples-counterexamples', 'analysis']"
493083,Derivative of a summation in order to minimize,"I am asked to minimize $\sum^n_{i=0}(x_i - C)^2$ with respect only to C so I know I have to take the derivative  respect to C,  set it equal to 0, and then solve. I have never done summation in my life and this is very new. I have been trying to search the web for information about how to proceed in these cases but all I have found is long theorems of summation or explanations of very simple operations with the summation notation. I have found, nevertheless, the answer to my question which is as follows:
$$S = \sum^n_{i=0}(x_i - C)^2$$ $$\frac{\partial S}{\partial C} = \sum^n_{i=0} 2 (x_i - C)(-1) = -2 \sum^n_{i=0} (x_i - C)$$ $$\frac{\partial S}{\partial C} = 0 \implies \sum^n_{i=0} (x_i - C) = 0$$ $$ \sum^n_{i=0} x_i - \sum^n_{i=0} C = 0$$ $$ \sum^n_{i=0} x_i = \sum^n_{i=0} C = nC$$ $$C = \frac{\sum^n_{i=0} X_i}{n}$$ First step, I don't get what this guy is doing,  so when he takes the derivative why he puts that (-1) at the end? is it because this is originally the square of a difference? That's the only thing I can think of.. Second step, where has the (-2) gone? It just vanished. Third step, I get this one. Fourth, where is this $nC$ coming from? What does it mean? 
I understand that at the end what he is doing is  $ \sum^n_{i=0} x_i= nC$ so it isolates $C$ and he finally gets the result  $C = \frac{\sum^n_{i=0} X_i}{n}$. Any reasons though why he chooses to swap $\sum^n_{i=0} C$ instead of $\sum^n_{i=0} x_i$ for $nC$? Thanks a lot, I'd really appreciate if you could please refer me to any page you might know about summation which doesn't go about 1000 theorems and properties . Unfortunately I can spend much time on summation as I have many other topics in my exam that I need to cover and this is just a small part of it. Cheers!","['linear-algebra', 'summation', 'derivatives']"
493093,Can rearranging a SEQUENCE (not a series) change the limit?,"I have this question on a homework assignment.  I sat down with two other people for a long time and we derived the alternating harmonic series example, but I don't think that's valid because the question explicitly asks about sequences and not series. Note that it's for an analysis class and so far we've covered open and closed sets and balls, preimages, and cluster points.","['convergence-divergence', 'sequences-and-series', 'analysis']"
493104,Evaluating $\int_a^b \frac12 r^2\ \mathrm d\theta$ to find the area of an ellipse,"I'm finding the area of an ellipse given by $\frac{x^2}{a^2}+\frac{y^2}{b^2} = 1$. I know the answer should be $\pi ab$ (e.g. by Green's theorem). Since we can parameterize the ellipse as $\vec{r}(\theta) = (a\cos{\theta}, b\sin{\theta})$, we can write the polar equation of the ellipse as $r = \sqrt{a^2 \cos^2{\theta}+ b^2\sin^2{\theta}}$. And we can find the area enclosed by a curve $r(\theta)$ by integrating $$\int_{\theta_1}^{\theta_2} \frac12 r^2 \ \mathrm d\theta.$$ So we should be able to find the area of the ellipse by $$\frac12 \int_0^{2\pi} a^2 \cos^2{\theta} + b^2 \sin^2{\theta} \ \mathrm d\theta$$ $$= \frac{a^2}{2} \int_0^{2\pi} \cos^2{\theta}\ \mathrm d\theta + \frac{b^2}{2} \int_0^{2\pi} \sin^2{\theta} \ \mathrm d\theta$$ $$= \frac{a^2}{4} \int_0^{2\pi} 1 + \cos{2\theta}\ \mathrm d\theta + \frac{b^2}{4} \int_0^{2\pi} 1- \cos{2\theta}\ \mathrm d\theta$$ $$= \frac{a^2 + b^2}{4} (2\pi) + \frac{a^2-b^2}{4} \underbrace{\int_0^{2\pi} \cos{2\theta} \ \mathrm d\theta}_{\text{This is $0$}}$$ $$=\pi\frac{a^2+b^2}{2}.$$ First of all, this is not the area of an ellipse. Second of all, when I plug in $a=1$, $b=2$, this is not even the right value of the integral, as Wolfram Alpha tells me . What am I doing wrong?","['geometry', 'calculus', 'integration']"
493109,How to calculate $2^{\sqrt{2}}$ by hand efficiently?,"I've been trying to calculate $2^{\sqrt{2}}$ by hand efficiently, but whatever I've tried to do so far fails at some point because I need to use many decimals of $\sqrt{2}$ or $\log(2)$ to get a roughly good approximation. Is it even possible to do so without facing irrational expressions like $\sqrt{2}$ or $\log(2)$ in our calculations? EDIT It seems like no one is paying attention to the requirements in my question at all : (  You are not allowed to use use $\log(2)$ or $\sqrt{2}$ in your answers. Use of continued fractions is allowed. Let me phrase my question in this way: Find an infinite series $\displaystyle \sum_{n=0}^{\infty}a_n$ such that $a_n \in \mathbb{Q}$. There exists at least one such series, namely, the series that is obtained by writing the decimal expansion of $2^{\sqrt{2}}$, but that series is good for nothing because if we already knew the decimal expansion of $2^{\sqrt{2}}$ then we didn't need to be after approximating $2^{\sqrt{2}}$ by using infinite series. Look at the following series: $\displaystyle e = \sum_{n=0}^{\infty}\frac{1}{n!} = 2 + \frac{1}{2} + \frac{1}{6} + \frac{1}{24}+\frac{1}{120}+\frac{1}{720} + \cdots$ $\displaystyle \pi = \frac{4}{1} - \frac{4}{3} + \frac{4}{5} - \frac{4}{7} + \frac{4}{9} - \frac{4}{11} + \cdots$ $\displaystyle \pi = 3 + \frac{4}{2\times 3 \times 4} - \frac{4}{ 4 \times 5 \times 6} + \frac{4}{6 \times 7 \times 8} - \frac{4}{8 \times 9 \times 10} + \cdots $ Both $e$ and $\pi$ are irrational transcendental numbers. But we have found non-trivial infinite series with rational terms for them. Can someone possibly find a similar series for $2^{\sqrt{2}}$? This is something I proposed as a challenge to myself and I failed, now I wonder if someone on here could tackle it.","['calculus', 'algebra-precalculus', 'real-analysis', 'numerical-methods']"
493116,"Show that root $x\equiv 0$ of $\dfrac{dx}{dt}=F(t,x)$ is uniformly stable (uniformly asymptotically stable)","I have a problem: For the system of equations: $$\bf \dfrac{dx}{dt}=F(t,x) \tag 1$$ where $F$ is continuous in $I \times D \subset\mathbb{R}\times \mathbb{R}^n$ and
  $F(t,0)\equiv0$, $F(t+\omega,x)=F(t,x), \omega >0$, it means that $F$ is periodic function.
  Prove that, if root $x\equiv 0$ of (1) is stable ( asymptotically
  stable ) then it is uniformly stable ( uniformly asymptotically
  stable ). Uniformly Stable : If any given $\epsilon >0$, $\exists \delta=\delta(\epsilon)>0$:
$$\|x(t_0)\|< \delta \implies \|x(t)\|<\epsilon, \forall t\ge t_0 >0$$ I have thought about my problem, I used the definition uniformly stable/ uniformly asymptotically stable. But I'm having trouble when I try to find a solution to the problem, and I still have no solution. Any help will be appreciated. Thanks!","['control-theory', 'ordinary-differential-equations']"
493131,Is the restriction of a flat morphism flat?,"Let $X$ be a projective scheme, $X_1, X_2$ be closed subschemes of $X$. Let $f:X \to S$ be a flat morphism for some scheme $S$. Denote by $i_1$ and $i_2$ the natural inclusion maps from $X_1$ and $X_2$, respectively to $X$. Assume that the composition maps $f \circ i_1$ and $f \circ i_2$ are flat. Is it then true that the fiber product $X_1 \times_X X_2$ is flat over $S$ under the natural maps $f \circ i_1 \circ pr_1$ or $f \circ i_2 \circ pr_2$, where $pr_i$ is the natural projection morphism from $X_1 \times_X X_2$ onto its $i$-th coordinate?",['algebraic-geometry']
493145,The proof of the Lagrange's Rational Function Theorem,"Lagrange's rational function theorem states that if one has two rational functions in multiple variables $f(x_1,x_2,...x_n)$ and $g(x_1,x_2,...,x_n)$ then one can can express $f$ as a rational function in $g$ if and only if the set of permutations that keep $g$ unchanged is a subset of the set of permutations that preserve $f$. A slightly more precise statement of the theorem can be found here in the first paragraph of this paper here . Is anyone familiar with the proof of this theorem? While it is fairly clear that if $f$ can be expressed in terms of $g$ the set of permutations that keep $g$ unchanged has to be the subset of those that keep $f$ unchanged, the converse is far from obvious.","['reference-request', 'abstract-algebra']"
493169,Why the expected value of the error when doing regression by OLS is 0?,"What I know to begin with is that the sum will be 0 if there is a y-intercept b0 , why is that? my book doesnt say and can't figure it out. I also know that an importantant assumption for the OLS estimators to be BlUE is that x and the erros can't be corralated otherwise the estimators would be biased.  This correlation assumption may entail problems so we take one step further and we assert that by combining E(u)=0 ( an assumption that the book doesnt explain where it comes from) + E(u|x)  - the average value of u doesnt depend on the value of x) , we get E(u)=0=E(u|x). so this assumption is somehow related to that the sum of residuals should be 0. But how do I mathematically prove that? Sorry if I have been a bit unclear but I am a quite confused, it seems all this topic quite redundant to me , like of the assumptions that jusify the method are infered from the method itself..","['statistics', 'order-statistics']"
493173,Find sufficient and necessary conditions to guarantees this property,"Let $f$ be a real non polynomial analytic function. Suppose that the function $f$ assumes arbitrarily large and arbitrarily small values, i.e., for all $K>0$, there are $a,b$ with $f(a)<−K$ and $f(b)>K$. My question is: Can we find sufficient and necessary conditions to guarantees this property persists for the derivatives $f^{(k)}, k=1,2,..$.","['derivatives', 'real-analysis']"
493176,Smallest topology containing all topologies [duplicate],"This question already has answers here : What is meant with unique smallest/largest topology? (2 answers) Closed 9 years ago . Let $\{T_\alpha\}$ be a family of topologies on $X$. Show that there is a unique smallest topology on $X$ containing all the collections $T_\alpha$, and a unique largest topology contained in all $T_\alpha$. We can check that $\bigcap T_\alpha$ is a topology on $X$, so it is the unique largest topology contained in all $T_\alpha$. Now, a topology containing all $T_\alpha$ must contain $\bigcup T_\alpha$. It must also contain arbitrary unions and finite intersections of sets in $\bigcup T_\alpha$. Since the union of the sets in $T_\alpha$ is $X$, this is the topology generated by the subbasis $\bigcup T_\alpha$. How can we prove that it is the unique smallest one containing all the collections $T_\alpha$?",['general-topology']
493179,Properties of special rectangle (measure),"Let $I$ be a special rectangle in $\mathbb{R}^n$, and denote $\lambda(A)$ the measure of $A$. Prove that the following conditions are equivalent: a) $\lambda(I)=0$ b) $I^{\circ}=\emptyset$ (i.e., the interior of $I$ is empty) c) $I$ is contained in an affine subspace of $\mathbb{R}^n$ having dimension smaller than $n$. (An affine subspace is any set of the form $\{x_0+x|x\in E\}$, where $x_0\in\mathbb{R}^n$ is fixed and $E$ is a subspace of the vector space $\mathbb{R}^n$. Its dimension is equal to the dimension of $E$.) The implication $a\implies b$ isn't too bad (using the definition if $I=[a_1,b_1]\times...\times[a_n,b_n]$ then $\lambda(I)=(b_1-a_2)...(b_n-a_n)$. So we conclude $a_i=b_i$ for some $i$. And since $I^{\circ}$ is open, there can't be anything contained in it). I also see how c) makes sense (at least intuitively), but not sure how to show it formally. 
Thank you.","['measure-theory', 'linear-algebra', 'real-analysis', 'analysis', 'lebesgue-integral']"
493203,A Pasting lemma for measurable functions,"I have the following setting: Let $(\Omega,\Sigma)$, $(\Gamma, \mathcal{C})$, $(X_{1},\mathcal{B}_{1})$, and $(X_{2},\mathcal{B}_{2})$ be measurable spaces such that $\Omega = X_{1}\cup X_{2}$, $X_{1}\cap X_{2} = \emptyset$, $\mathcal{B}_{1} = \{X_{1}\cap A:A\in\Sigma)$, $\mathcal{B}_{2} = \{X_{2}\cap A:A\in\Sigma)$. Let $f_{1}:X_{1}\to\Gamma$ and $f_{2}:X_{2}\to\Gamma$ be measurable. Then I think $f:=\begin{cases}f_{1} & \text{ on }X_{1}\\f_{2} & \text{ on }X_{2}\end{cases}$ is measurable as a function $f:\Omega\to\Gamma$. The following seems to work, could someone confirm this is correct and that I haven't overlooked anything? Let $A\in \mathcal{C}$, then $f^{-1}(A) = (X_{1}\cap f^{-1}(A))\cup (X_{2}\cap f^{-1}(A)) = \underbrace{f_{1}^{-1}(A)}_{\in \mathcal{B_{1}}}\cup \underbrace{f_{2}^{-1}(A)}_{\in\mathcal{B_{2}}}\in\Sigma.$","['measure-theory', 'solution-verification']"
493216,How to Compute $\zeta (0)$?,"Ultimately, I am interested in analytically continuing the function
$$
\eta _a(s):=\sum _{n=1}^\infty \frac{1}{(n^2+a^2)^s},
$$
where $a$ is a non-negative real number, and calculating $\eta _a$ and its derivatives (at least the first derivative) at the origin:  $\eta _a(0),\eta _a'(0),\ldots $. It is well-known that $\zeta (0)=-\tfrac{1}{2}$ and that $\zeta '(0)=-\tfrac{1}{2}\ln (2\pi)$, but I do not actually know how to obtain these ($\zeta$ is of course the Riemann Zeta function ).  I figured that, perhaps if I knew how to calculate these values, I would be able to generalize the technique to be able to calculate the corresponding values of $\eta _a$. So then, how does one calculate $\zeta (0)$, $\zeta '(0)$, etc.?  If this technique does not obviously generalize to $\eta _a$, any ideas how I might go about calculating these values?","['riemann-zeta', 'complex-analysis']"
493219,Onto and one-one,"Let $f \colon A \to B$ be a surjection and $g \colon B \to C$ be such that
  $g\circ f$ is an injection. Prove that both $f$ and $g$ are
  injections. Since $f$ is onto then there exists a $f(a)$ such that $f(a)=b$, for all $b\in B$. Now since $g\circ f$ is one-one then for $a,a'\in A$ we get that $ g(f(a)) \ne g(f(a'))$ implies that $f(a)\ne f(a')$. Then since $f(a)\ne f(a') \implies b=f(a)\ne f(a')=b'$ implies that $b\ne b'$ hence $g$ is also one-one. I can't find a way to show that $f$ is one-one. Can I just say that since  $b\ne b'$ and $f$ is onto then all of $b$ has an $a$ such that $f(a)=b$ but $f(a)\ne f(a')$ (which I proved above) thus $a\ne a'$ therefore $f$ is one-one?","['elementary-set-theory', 'functions']"
493226,Can the diagonal of a manifold be expressed as the zero set of a section of a vector bundle?,"Let $\mathbb{C} \mathbb{P}^2$ be the two dimensional complex 
projective space and $$M:= \mathbb{C} \mathbb{P}^2 \times \mathbb{C} \mathbb{P}^2.$$
Let $ \gamma \rightarrow \mathbb{C} \mathbb{P}^2 $ be 
the tautological line bundle over $\mathbb{C} \mathbb{P}^2$. Denote 
$\Delta_{M}$ to be the diagonal of $M$, i.e., 
$$ \Delta_{M} := \{ (p_1,p_2) \in \mathbb{C} \mathbb{P}^2 \times \mathbb{C} \mathbb{P}^2: p_1 = p_2  \}. $$ My question is the following: is there some obvious rank two vector bundle 
$V \rightarrow M$ over $M$ and a section 
$s: M \rightarrow V$ of this vector bundle such that 
$$ s^{-1}(0) = \Delta_{M} $$
?
Moreover $V$ restricted to $\Delta_M$ should be the normal bundle of 
$\Delta_M$ inside $M$. It seems to me $V$ should be something obvious that is made up using 
$\pi_1^{*} \gamma$ and $\pi_2^*\gamma $ (and their duals). The section 
$s$ should essentially be 
$$ s(p_1, p_2) = p_1 - p_2 $$ 
Of course $p_1-p_2$ for the time being makes no sense. Note: $\pi_1, \pi_2: M \rightarrow \mathbb{C} \mathbb{P}^2$ are the 
two projection maps.","['differential-topology', 'algebraic-geometry', 'vector-bundles', 'differential-geometry']"
493228,How to prove that $B$ is nilpotent.,"Let $A$ and $B$ be complex matrices with $AB^2-B^2A=B$ . Prove that $B$ is nilpotent. By the way: This problem is from American Mathematical Monthly, Problem 10339,and this solution post 1996 American Mathematical Monthly, page 907. My question: This problem has other nice solutions? Thank you.","['matrices', 'linear-algebra']"
493240,Is there always a bijection mapping one element of an infinite set onto another?,"Let $S$ be an infinite set, and let $s_1$, $s_2$ be any two distinct elements of $S$. Then how to determine whether or not there is always a bijection of $S$ onto itself that maps $s_1$ onto $s_2$? I know that this does hold true for a non-empty finite set $S$. How to establish the truth or falsity of this assertion in the case of infinite sets?","['permutations', 'elementary-set-theory']"
493250,Values of the Christoffel symbols,Are the values of the christoffel symbols the same for all coordinate systems on a surface/manifold? I would love to see an example for the cone in two different parametrizations.,['differential-geometry']
493258,"Show that all the roots of $\frac{dx}{dt}=A(t)x$ are bounded in $[t_0, \infty)$.","For real system of equations$$\frac{dx}{dt}=A(t)x,(1)$$ where $A(t) \in C[t_0, +\infty)$. Prove that if $\int_{t_0}^{\infty} \|A(t_1)+A^T(t_1)\|< +\infty$ then all the roots of (1) are bounded in $[t_0, \infty)$. Can anyone help me? Thanks.","['control-theory', 'ordinary-differential-equations']"
493259,What's the smallest exponent to give the identity in $S_n$?,"Let $S_n$ denote the symmetric group on $n$ letters. We know that $\tau^{n!} = e$ for any element $\tau \in S_n,$ where $e$ denotes the identity element. Can we find a smaller positive integer $m$ with this property? That is, can we find a positive integer $m < n!$ such that $$\tau^m = e$$ for all $\tau \in S_n$?","['permutations', 'finite-groups', 'group-theory', 'abstract-algebra']"
493264,Finding the inverse of a matrix by elementary transformations.,"While using the elementary transformation method to find the inverse of a matrix, our goal is to convert the given matrix into an identity matrix. We can use  three transformations:- 1) Multiplying a row by a constant 2) Adding a multiple of another row 3) Swapping two rows The thing is, I can't seem to figure out what to do to achieve that identity matrix. There are so many steps which I can start off with, but how do I know which one to do? I think of one step to get a certain position to a $1$ or a $0$, and then get a new matrix. Now again there are so many options, it's boggling. Is there some specific procedure to be followed? Like, first convert the top row into:
\begin{bmatrix}
1&0&0\\
a_{21}&a_{22}&a_{23}\\
a_{31}&a_{32}&a_{33}
\end{bmatrix}
Then do the second row and then the third? What do I start off with? I hope I've made my question clear enough. Thanks to @Brian M. Scott. $P.S:$ Does anyone have any other methods? Brian's works perfectly, but it's always great to know more than one method. :)","['matrices', 'inverse']"
493275,Is there an automorphism of symmetric group of degree 6 sending a transposition to product of two transpositions?,$\operatorname{Aut}(S_6)\cong S_6\rtimes C_2$. there are several (720) automorphisms sending a transposition to product of three transpositions. Is there an automorphism sending a transposition to product of two transpositions? Why?,"['finite-groups', 'group-theory', 'symmetric-groups']"
493309,How find this limit $\lim \limits_{x\to+\infty}e^{-x}\left(1+\frac{1}{x}\right)^{x^2}$ [duplicate],"This question already has answers here : finding the limit $\lim\limits_{x \to \infty }(\frac{1}{e}(1+\frac{1}{x})^x)^x$ (2 answers) Closed 6 years ago . find this limit $$\lim \limits_{x\to+\infty}e^{-x}\left(1+\dfrac{1}{x}\right)^{x^2}$$ my idea:
$$\lim \limits_{x\to+\infty}e^{-x}\left(1+\dfrac{1}{x}\right)^{x^2}=\lim \limits_{x\to+\infty}e^{-x}\cdot e^x=1$$ But book is answer is not 1? and How about find it? Thank you",['limits']
493368,"For any $x\in\mathbb R$ and any positive integer $n$,$\ $is $\left|\sum_{k=1}^n\frac{\sin{kx}}{k}\right|\le2\sqrt{\pi}$ true?","I'm interested in finding the min of constants $C$ such that 
$$\left|\sum_{k=1}^n\frac{\sin{kx}}{k}\right|\le C.$$ By using computer, I reached the following expectation: $$\left|\sum_{k=1}^n\frac{\sin{kx}}{k}\right|\le2\sqrt{\pi}$$ 
for any $x\in\mathbb R$ and any positive integer $n$. I can neither prove this nor find any counterexample even by using computer. If my expectation is true, then could you show me how to prove that? Also, please show me whether $2\sqrt{\pi}$ is the min of such $C$. If it's not true, please show me the counterexample. I need your help.",['trigonometry']
493399,Calculate limits $ \lim_{x\to+\infty} \frac{3x-1}{x^2+1}$ and $\lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1}$,"I want to calculate the following limits $$\begin{matrix}
\lim_{x\to+\infty} \frac{3x-1}{x^2+1} & \text{(1)} \\
\lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1} & \text{(2)}
\end{matrix}$$ In both cases we have indeterminate forms. Using L'Hôpital's rule on $\text{(1)}$  gives $$\lim_{x\to+\infty} \frac{3x-1}{x^2+1} = \lim_{x\to+\infty}\frac{3}{2x} = 0$$ Using L'Hôpital's rule on $\text{(2)}$ gives $$\lim_{x\to-\infty} \frac{3x^3-4}{2x^2+1} = \lim_{x\to-\infty}\frac{9x^2}{4x} = \lim_{x\to-\infty}\frac{18x}{4} = -\infty$$ Is this correct?",['limits']
493419,proof by induction : $n^n \ge 2^{n-1} n!$,"I am trying to show that
 $$\begin{matrix} n^n \ge 2^{n-1} n! & \text{(1)} \end{matrix}$$ I tried to solve it for n=n+1 $$(n+1)^{n+1}=(n+1)^n(n+1) \ge n^n(n+1) \ge 2^{n-1}n!(n+1)= 2^{n-1}(n+1)!$$ So I ended up having $2^{n-1}$, but I wanted $2^n$. How can I prove $\text{(1)}$?","['induction', 'analysis']"
