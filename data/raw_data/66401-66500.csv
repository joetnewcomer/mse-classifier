question_id,title,body,tags
786453,Proof that Newton Raphson method has quadratic convergence,"I've googled this and I've seen different types of proofs but they all use notations that I don't understand. But first of all, I need to understand what quadratic convergence means, I read that it has to   do with the speed of an algorithm. Is this correct? Ok, so I know that this is the Newton-Raphson method: $$x_{n+1}=x_n-\dfrac{f(x_n)}{f'(x_n)}$$ How do I prove that it converges? Thanks.","['numerical-linear-algebra', 'calculus', 'numerical-methods']"
786487,What does a customer see when it begins to be served in $M/M/1$ queue?,"In queueing theory, the PASTA (Poisson Arrivals See Time Averages) principle [wiki] justifies $a_n = P_n$ where 
$$a_n = \text{proportion of customers that find } n \text{ customers in the system when they arrive}$$ and,
$$P_n = \lim_{t \to \infty} P \{ X(t) = n \}$$ ($X(t) \text{ here denotes the number of customers in system at time } t$). However, I am now more interested in the moment when a customer begins to be served , rather than when it arrives. Specifically, I focus on the case of $M/M/1$ queue (i.e., a single-server exponential queueing system with FCFS service discipline ) and consider $$s_n = \text{proportion of customers that find } n \text{ in the } M/M/1 \text{ queue when it begins to be served.}$$ My question is: Question: What does a customer see when it begins to be served in $M/M/1$ queue with the FCFS service discipline? In other words, what is the relationship between $s_n$ and $P_n$ (or, the relationship between $s_n$ and $a_n$)?","['stochastic-processes', 'markov-chains', 'queueing-theory', 'probability-theory', 'probability']"
786501,Calculus Question: $\lim_{x \rightarrow 0}\sin(x)\ln{\sin{x}}$,"I'm having trouble to compute $$\lim_{x \rightarrow 0}\sin(x)\ln{\sin{x}}$$ I tried to find this limit using Wolfram Alpha and the result is 0, but I don't know how to get this 0.","['calculus', 'limits']"
786503,"If $R$ is zero-dimensional, then $\mathrm{Spec}(R)$ is Hausdorff and totally disconnected","I've found the following claim. If $R$ is a commutative ring, and every prime ideal is maximal, then $\mathrm{Spec}(R)$ with the Zariski topology is Hausdorff and totally disconnected. Is it true ? Why ?","['commutative-algebra', 'algebraic-geometry']"
786522,Find the value of $\left | b-c \right |$,"Given that $a, b, c \in \mathbb{Z}$, $a>10$ and $$(x-a)(x-12)+2=(x+b)(x+c)$$ Find the value of $\left | b-c \right |$ NOTE : The answer to this problem (as given on the last page of my book) is $1$ and not an expression in terms of $a$, $b$ or $c$. I compared the coefficients on both sides of the equation and I was getting two equations (but three unknowns).So I used the fact that $a>10$ and tried to set up inequalities hoping to get something 
  like L.H.S>$k$ , R.H.S. so that I could assert that both L.H.S. and R.H.S. equal to k+1 (number between them since we are dealing in Integers).But my tries were in vain. Any help would be appreciated. Thank you for your time and patience.","['inequality', 'algebra-precalculus', 'roots', 'polynomials', 'quadratics']"
786525,Is there a number $n$ such that there are exactly 1 million abelian groups of order $n$?,"Is there a number $n$ such that there are exactly 1 million abelian groups of order $n$ ? Can anyone please explain. I would yes because numbers are infinitive, and so any number $n$ can be expressed as a direct product of cyclic groups of order $n$ .","['group-theory', 'abstract-algebra']"
786526,$a^{\phi (n) +1} \equiv a \pmod{\! n}; $ Carmichael generalization of Fermat & Euler theorems.,"I want to know a proof of an alternative form of Fermat-Euler's theorem $$a^{\phi (n) +1} \equiv a \pmod n$$ I searched some number theory books and a cryptography book and internet, but there were only proofs of the original theorem $a^{\phi (n)} \equiv 1 \pmod n$ or in case n=pq which is used for RSA. So I would be very thankful if someone show me a proof or book I should read.","['number-theory', 'modular-arithmetic', 'totient-function', 'abstract-algebra', 'cryptography']"
786527,"If $f,g$ are uniformly continuous prove $f+g$ is uniformly continuous but $fg$ and $\dfrac{f}{g}$ are not","Suppose $f:\mathbb{R} \supset E \rightarrow \mathbb{R}$ and $g: \mathbb{R} \supset E \rightarrow \mathbb{R}$ are uniformly continuous. Show that $f+g$ is uniformly continuous. What about $fg$ and $\dfrac{f}{g}$ ? My Attempt Firstly let's state the definition; a function is uniformly continuous if $$\forall \varepsilon >0\ \ \exists \ \ \delta >0 \ \ \text{such that} \ \ |f(x)-f(y)|< \varepsilon \ \ \forall \ \ x,y \in \mathbb{R} \ \ \text{such  that} \ \ |x-y|<\delta$$ Sum $f+g$ Now to to prove $f+g$ is uniformly continuous; $\bullet$ Choose $\delta_1 >0$ such that $\forall$ $x,y \in \mathbb{R}$ $|x-y|<\delta_1$ $\implies$ $|f(x)-f(y)|< \dfrac{\epsilon}{2}$ $\bullet$ Choose $\delta_2 >0$ such that $\forall$ $x,y \in \mathbb{R}$ $|x-y|<\delta_2$ $\implies$ $|g(x)-g(y)|< \dfrac{\varepsilon}{2}$ $\bullet$ Now take $\delta := min\{ \delta_1, \delta_2\}$ Then we obtain for all $x,y \in \mathbb{R}$ $$
|x-y|<\delta \implies
|f(x)+g(x)-f(y)+g(y)| <
|f(x)-f(y)| + |g(x)-g(y)| <
\dfrac{\varepsilon}{2}+\dfrac{\varepsilon}{2}=
\varepsilon$$ Product $fg$ Now for $fg$ for this to hold both $f:E \rightarrow \mathbb{R}$ and $g:E \rightarrow \mathbb{R}$ must be bounded , if not it doesn't hold. $\bullet$ $\exists \ \ M>0 \ \  such \ that \ \ |f(x)|<M \ \ and \ \ |g(x)|<M \ \ \forall \ x \in E$ $\bullet$ Choose $\delta_1 >0$ such that $\forall$ $x,y \in \mathbb{R}$ $|x-y|<\delta_1$ $\implies$ $|f(x)-f(y)|< \dfrac{\epsilon}{2M}$ $\bullet$ Choose $\delta_2 >0$ such that $\forall$ $x,y \in \mathbb{R}$ $|x-y|<\delta_2$ $\implies$ $|g(x)-g(y)|< \dfrac{\epsilon}{2M}$ $\bullet$ Now take $\delta := min\{ \delta_1, \delta_2\}$ . Then, $|x-y|<\delta$ implies for all $x,y \in \mathbb{R}$ , that $$|f(x)g(x)-f(y)g(y)| \leq
|g(x)||f(x)+f(y)|+|f(y)||g(x)+g(y)| \leq
$$ $$
M|f(x)+f(y)| + M|g(x)+g(y)| <
M \dfrac{\epsilon}{2M} + M \dfrac{\epsilon}{2M} =
\epsilon$$ Are these proofs correct?
I am not sure how to approach the $\dfrac{f}{g}$ case.","['epsilon-delta', 'continuity', 'proof-verification', 'real-analysis', 'uniform-continuity']"
786563,How find the minimum of the value $k$ such this intergral $\int_{0}^{1}f^2(x)dx\le k\left(\int_{0}^{1}f(x)dx\right)^2$,"Find the minimum of the value $k$, such have 
  $$\int_{0}^{1}f^2(x)dx\le k\left(\int_{0}^{1}f(x)dx\right)^2$$
  for any integrable function $f(x)$,and 
    $1\le f(x)\le 2,x\in(0,1)$ My idea: use Cauchy-Schwarz inequality we have
$$\int_{0}^{1}f^2(x)dx\ge\left(\int_{0}^{1}f(x)dx\right)^2$$ I know this can't usefull to solve my problem. Thank you","['integral-inequality', 'analysis']"
786572,Actions of Weyl group,"I get a feeling what I am going to ask is very standard and classic, but I am not able to find any reference. Any answer or reference would be appreciated. Let us assume that $G$ is a simply connected compact Lie subgroup of $GL(n,\mathbb{C})$. Let $T$ be a maximal torus of $G$. Let $\mathfrak{g}$ and $\mathfrak{t}$ denote the Lie algebras of $G$ and $T$ respectively. We know that the Weyl group $W$ of $G$ acts freely transitively on the following three sets, $N_G(T)/T$ where $N_G$ is the normalizer in $G$ Borel subgroups containing $T$ The unit eigenvectors for $\mathfrak{t}$ in $\mathfrak{g}$ (Trace norm) We can use any of the three to define the Weyl group. The correspondence between the first two is pretty explicit and can be found in standard texts, say Humphreys. I wanted to ask if one can give an explicit correspondence between 1 and 3 or 2 and 3? I tried exponentiating the roots but to no avail. Even for the simple case of $G=SL(n,\mathbb{C})$ and $T$ being the diagonal matrices, the exponentials of the roots are $1 + E_{ij}$ but these do not lie in distinct Borel subgroups nor are they elements of the normalizer.","['lie-algebras', 'lie-groups', 'differential-geometry']"
786600,Why is this polynomial a monomial?,"Let $p$ be a polynomial of degree $n$ such that $|p(z)| = 1$ for all $|z| = 1$. Why is it that $p(z) = az^n$ for some $|a| = 1$? I've noticed that we could easily prove this by induction if we could show that 0 was a root of $p$. My guess is that Rouche's theorem and/or the Maximum Modulus principle should be used. My background to the problem: This question is the last question on the take-home portion of my final exam that I haven't been able to figure out yet. We are allowed to collaborate with other people in the class (and I have) as well as use any book and the internet (including this site). So basically, it's a homework assignment that is worth more points than usual. Nevertheless, in case it helps you decide how much information to give, the final is due tomorrow (but since I'm going to a math conference, I may turn it in late).","['roots', 'complex-analysis']"
786626,$\beta_a(n)=(a_1*\cdots(a_n*b))\setminus_* b$ and Iterations in right divisible magmas e representability by left translations.),"Let's consider the magma $(G,*)$ with infinite elements. Now I define $\operatorname{left}(G)$ the set of all the left translations $$\operatorname{left}(G):\{L_a:a \in G ,L_a(b)=a*b\}$$ And $iter(a)$ as the set formed by the left traslation by $a\in G$ and closed under function composition or in other words the iterations of the left translations. $$\operatorname{iter}(a):\{L_a^{n}:n \in \Bbb N\setminus\{0\}\}$$ What are the weakest conditions that $(G,*)$ must satisfies if we want
  that exist an collection injective functions $\mathcal F_a:\operatorname{iter}(a)\rightarrow
> \operatorname{left}(G)$? $\mathcal F_a$ are defined in this way $$\mathcal F_a(L_a^1)=L_a$$ $$\mathcal F_a(L_a^n)=L_{a'}$$ $$\mathcal (\mathcal F_a(L_a^n))(x)=L_a^n(x)$$ I think that this is equivalent to the this statement $$\operatorname{iter}(a)\subseteq \operatorname{left}(G)$$. If $(G,*)$ is associative  then this always holds because $L_a(L_a(x))=L_{a*a}(x)$ and in general $\mathcal F_a(L_a^n)=L_{a^n}$ But this assumption is too stroong for my needs A weaker condition is that if $*$ is right invertible (exists a $R_a^{-1}$ such that $R_b^{-1}(a*b)=(a*b)\setminus_* b=a$)  then we can define the functions $\beta_a$ $$\beta_a(n)*b=a_1*\cdots(a_n*b)$$ 
$$\beta_a(n)=(a_1*\cdots(a_n*b))\setminus_* b$$ $$\beta_a(n)=R_b(L_a^n(b))$$ and these functions MUST be always constants (for every $b$) so we can define the injections $\mathcal F_a$ : $$L^n_a=L_{\beta_a(n)}$$ and thus $ \mathcal F_a$ exists $$\mathcal F_a(L_a^n)=L_{\beta_a(n)}$$ $1$-$\beta_a$ not depend from $b$ and is always costant, $\mathcal F_a$
  exists and $\operatorname{iter}(a)\subseteq \operatorname{left}(G)$ are three equivalent statements? $3$-When $\beta_a$ satisfies that weak condition? $3$-If $(G,*)$ is not commutative, not associative and not left
  invertible but is right invertible is possible that this bijection
  from $\operatorname{iter}(a)\rightarrow \operatorname{left}(g)$ exists? Or maybe there can be a surjection? Note: the image of $\operatorname{iter}(a)$ by$\mathcal F_a$, $\mathcal F_a[\operatorname{iter}(a)]$ should be always a commutative subsemigroup of $(\operatorname{left}(G),\circ)$, commutative submonoid if $*$ has a left unit and a commutative  subgroup if $*$ is right invertible. Update: here a related question. Existence of an operation $\cdot$ such that $(a*(b*c))=(a\cdot b)*c$ Seems to me that the conditiont that the User Goos found is really similar to inclusion condition. Anyways I think that the questions here are still meaningfull.","['functions', 'abstract-algebra', 'magma']"
786648,fast multiplication for a matrix and its transpose.,I know Strassen and other methods can achieve better than $O(n^3)$ for general square matrix multiplication. I am curious of the spacial case where the multiplication is between  a $n*m$ matrix $A$ with its transpose $A^T$ . Is there known algorithm that computes this case fast? thanks,"['numerical-linear-algebra', 'matrices', 'linear-algebra']"
786657,Calculus Riemann Sums - why do the partitions have to be of the same size?,"To set up Riemann sums for integration, my calculus text will say that the intervals of partition are all of the same size.  Isn't it rather the case that they could be any size, as long as they are bounded by a largest partition which goes to zero as we take the limit?  Why bother being so explicit about the equalities of each delta x? Similarly, does it matter that the point within each partition be determined in the same manner each time?  As the limit goes to zero, as long as the x-value we choose is somewhere within that segment of the domain...",['calculus']
786672,$\sqrt{\frac{15}4+\sum\cos(A-B)}\ge\sum\sin A$ in a triangle?,"How can I prove that ( $\small{\sum}$ denotes cyclic sum here), for any triangle $ABC$:
$$\sqrt{\frac{15}4+\sum\cos(A-B)}\ge\sum\sin A$$ I don't see where to begin even. Any hints would be appreciated :)","['geometry', 'triangles', 'inequality']"
786678,Prove that the family of open sets in $\mathbb{R}$ has cardinality equal to $2^{\aleph_0}$,"Let $\mathcal{T}$ be the family of all open sets in $\mathbb{R}$. Show that $| \mathcal{T}|=2^{\aleph_0}$ $\textbf{My Attempt:}$ I know that $\forall A \in \mathcal{T}$. $A$ is the countable union of open intervals with rational end points. I want to use the Cantor-Bernstein Theorem. That is I need to find injective functions $f$ and $g$ such that $f: 2^{\aleph_0} \to \mathcal{T}$ and $g: \mathcal{T} \to 2^{\aleph_0}$. I know each $A \in \mathcal{T}$ is of the form $A = \bigcup_{x \in A} (r_x,s_x)$ where $r_x,s_x \in \mathbb{Q}$. How can I use this fact to find the injective function $f$ and $g$?",['elementary-set-theory']
786689,Differentiation of norm in Banach space (explanation of text needed),"Let $Y$ be uniformly smooth Banach space. Consider the convex $C^1$ functional $\Phi:Y \to \mathbb{R}$ defined
$$\Phi(y) = \frac{1}{q}\Vert y \Vert^q_{Y}.$$ Its derivative $\varphi:Y \to Y'$ is a monotone operator satisfying
  $$\langle \varphi(y), y \rangle = \Vert y \Vert^q_Y.$$ How to prove this? I presume this refers to the Gateaux derivative but I cannot get anywhere after forming the directional derivative expression. Is the proof hard? Let $u \in L^p_{loc}(0,T;X) \cap L^q_{loc}(0,T;Y)$ be such that $\varphi(u) \in L^{q'}_{loc}(0,T;Y')$ is weakly differentiable with $(\varphi(u))' \in L^{p'}_{loc}(0,T;X')$. Then
  $$\frac{d}{dt}\frac{1}{q'}\Vert u(t) \Vert^q_Y = \langle (\varphi(u))', u \rangle$$
  holds in the sense of distributions on $(0,T)$. I don't obtain this: I don't get the factor of $\frac{1}{q'}$. I get:
$$-\int_0^T \psi(t)\langle (\varphi(u))', u \rangle = \int_0^T \psi'(t)\langle (\varphi(u)), u \rangle = \int_0^T \psi'(t)\Vert u(t) \Vert^q$$
by the equation above. So I get
$$\frac{d}{dt}\Vert u(t) \Vert^q_Y = \langle (\varphi(u))', u \rangle.$$
Where did I go wrong? Thanks for any help. EDIT Source is http://link.springer.com/article/10.1007%2Fs10492-012-0004-0 , section A.3 in the appendix.","['banach-spaces', 'operator-theory', 'reference-request', 'weak-derivatives', 'functional-analysis']"
786693,Are semisimplicity and regularity closed or open conditions in an algebraic group $G$?,"Let $G$ be a connected algebraic group over an algebraically closed field.  I'm trying to understand the phrase ""the subvariety of semisimple elements in $G$ which are not regular.""  This tacitly implies that the conditions of semisimplicity and regularity must be open or closed. For reference, an element in $g\in G$ is semisimple if $g=su$ is its Jordan decomposition and $u$ is the identity element of $G$.  Also, an element is regular if the dimension of its centralizer is equal to the dimension of a maximal torus in $G$. I believe I can prove that regularity is an open condition for $G=\mathrm{GL}_n$, as a matrix $A$ is regular if and only if $\{I,A,A^2,\ldots,A^{n-1}\}$ is a linearly independent set.  How can I see that regularity is an open condition for arbitrary $G$? Concerning semisimplicity, I read on pg. $99$ of Humphrey's ""Linear Algebraic Groups"" that the set of semisimple elements ""$G_s$ is rarely a closed subset of $G$.""  In light of the phrase I'm trying to understand, are there conditions on $G$ which make semisimplicity a closed or open condition?","['algebraic-geometry', 'algebraic-groups', 'abstract-algebra']"
786708,Elevator Probability Question,"There are four people in an elevator, four floors in the building, and each person exits at random. Find the probability that: a) all exit at different floors b) all exit at the same floor c) two get off at one floor and two get off at another For a) I found $4!$ ways for the passengers to get off at different floors, so $$\frac{4!}{4^4} \text{would be the probability} = \frac{3}{32}$$ For b) there are only four ways for them to all exit on the same floor, so $$\frac{4}{256} = \frac{1}{64}$$ For c) am I allowed to group the $4$ people so that I am solving for $2$ people technically? For two people there would be $12$ possibilities, and there are three ways to group the $4$ individuals, so $$\frac{12 \cdot 3}{256} = \frac{9}{64}$$ I'm not sure if I'm doing these right, can you please check? Thank you.",['probability']
786710,Nonlinear first order system of ODEs,"While solving some physical problem, I have obtained the following system of differential equations with boundary conditions: $$\left\{\begin{matrix}
\frac{d\phi_1}{dz}=\frac{m^2}{\lambda}- \lambda\phi_1^2-\alpha\phi_2^2
\\ \frac{d\phi_2}{dz}=-2\alpha\phi_1\phi_2
\\ \phi_2(\pm\infty)=0
\\ \phi_1(\pm\infty)=\pm\frac{m}{\lambda}
\end{matrix}\right.$$ where $\phi_1(z),\phi_2(z)$ are just functions of real variables, $m,\lambda,\alpha\in \mathbb{R}$ As far as I know, to solve this problem I should solve the system of differential equations and after that use boundary conditions. I see that it's easy to solve this system when $\lambda=\alpha$ : Just sum this two equations to obtain 
$$\frac{d(\phi_1+\phi_2)}{dz}=\frac{m^2}{\lambda}-\lambda(\phi_1+\phi_2)$$
This DE easily solved 
$$(\phi_1+\phi_2)=\frac{m}{\lambda}\tanh(mz-m\lambda C_1)$$
where $C_1$ is an integration constant. 
After that I can find exact solutions for $\phi_1$ and $\phi_2$. And boundary conditions are satisfied automaticaly. But I would like to obtain the solution for any $\alpha$ and $\lambda$ at least by quadrature. My attempt was to reproduce the aproach as in case $\lambda=\alpha$: I've obtained $$\frac{1}{\sqrt{\alpha}}\frac{(\sqrt{\alpha}\phi_1+\lambda\phi_2)}{dz}=\frac{m^2}{\lambda}-(\sqrt{\lambda}\phi_1+\sqrt{\alpha}\phi_2)^2$$ So, this attempt was a fail. Also I have noticed that these two equations look like as Riccati equation And I have no any ideas how to solve it. Any help will be appreciated.","['dynamical-systems', 'nonlinear-system', 'ordinary-differential-equations', 'boundary-value-problem']"
786719,Formula for position in an upper triangular matrix,"I'm currently working on the Travelling Salesman's Problem in a computer science module. I have implemented some linear programming techniques using the software lp_solve. I've ended up with an upper triangular matrix, that is missing the diagonal, consisting of $1$s and $0$s which indicate whether the route between two specific towns took place. Here's an example of what I'm talking about with 5 towns:
$$\begin{bmatrix}\cdot & 0&0&0&1\\\cdot&\cdot & 0&0&1\\\cdot&\cdot&\cdot&0&1\\\cdot&\cdot&\cdot&\cdot&1\\\cdot&\cdot&\cdot&\cdot&\cdot\end{bmatrix}$$
I wanted to derive a formula that maps the position ""single dimensional coordinate"" to its corresponding matrix position vector. An example for clarity, again in a system of 5 towns:
$$0\mapsto(0,1) \\
1\mapsto(0,2) \\
2\mapsto(0,3) \\
3\mapsto(0,4) \\
4\mapsto(1,2) \\
5\mapsto(1,3) \\
6\mapsto(1,4)\\
7\mapsto(2,3)\\
8\mapsto(2,4)\\
9\mapsto(3,4)$$
where the ""single-dimensional coordinate"" I mentioned above is the index that gets mapped to the position vector. So my question: how can I derive a formula that defines the map I've expressed above?","['matrices', 'graph-theory', 'linear-programming']"
786763,Motivation for solving integrals of specific forms.,I was reading a book (Problems in One Variable Calculus by IA Maron) and there was a chapter called Integration of a Binomial Differential . I'm quoting a part of text The integral $\int x^m(a+bx^n)^p dx$ can be evaluated in the following ways- Case I. $p$ is an integer . Then if $p>0$ break the binomial up and if $p<0$ then put $x=t^k$ where k is the common denominator of the fractions $m$ and $n$ . Case II. $\frac{m+1}{n}$ is an integer. We put $a+bx^n=t^k$ where k is the denominator of the fraction p. Case III. $\frac{m+1}{n}+p$ is  an integer. We put $a+bx^n=t^kx^n$ where k is the denominator of the fraction p. I am curious about how people came up with these? What were the motivations behind it? What were they thinking when they came up with these substitutions.,"['calculus', 'integration', 'indefinite-integrals']"
786774,Complex structure on $\mathbb{C}\mathbb{P}^2\# \dots \# \mathbb{C}\mathbb{P}^2$,"I know the chern classes-related theorem that states that $\mathbb{C}\mathbb{P}^2\# \dots \# \mathbb{C}\mathbb{P}^2$ ($k$ times) has no almost complex structure (hence no complex structure) if and only if $k$ is even. I also know that $\mathbb{C}\mathbb{P}^2\# \mathbb{C}\mathbb{P}^2 \# \mathbb{C}\mathbb{P}^2$ has no complex structure, hence the almost complex ones you define on it are not integrable. Where can I find a proof of this proposition? How do I see that the connected sum of three (or five, or seven, or every odd number) copies of $\mathbb{C}\mathbb{P}^2$ doesn't admit a complex structure?","['complex-geometry', 'differential-geometry']"
786778,Why isn't this set a Borel set and why is it measurable?,"Could someone explain to me why the set constructed as follows: For any positive integer $n$, let $n^*$ denote the decimal rational obtained
by writing the decimal form of $n$ in reverse order and then putting
a decimal point before it. For example, $2^* = 0.2, \ \ 500^* = 0.005, \ \ 1234^* = 0.4231$,etc. Let $A$ be the set of those elements $x$ of $[0,1]$ for which there is
an infinite sequence of positive integers $k_1, k_2, ..., k_n, ... $ with
$k_1^* \le k_2^* \le ... \le k_n^* \le ...$ such that $x_{k_n} = 3$ for all $n$,
where $x_k$ is the $k$-th digit in some decimal expansion of $x$ (that is,
$x = \sum_{k \ge 1} \frac{  x_k}{10^k}$). is not Borel but it is Leb. measurable. There are a few sequences in $\mathbb{N}$ which quite immediately come to mind and fulfill the condition, for example: $\{1,11,111,1111, ... \}$ 
or $\{1, 11, 12, 13, 14,15,16,17,18,19, 119,1119,11119,...\}$ 
or a mix $\{1, 11, 12, 13, 14,15,16,17,18,19,29,39,49,59,69,79,89,99,999,9999,99999,...\}$, etc., etc. So these numbers would be $0,... \ 3 \ ... \ 3 \ ... \ 3 \ ...$ with $3$s in the special places $k_n$ as described above. I don't see how this prevents $A$ from being Borel, but still $A$ remains measurable. I would very much appreciate an explanation that doesn't use the fact that this set is analytic, if that's all right.","['measure-theory', 'lebesgue-measure']"
786790,Fermat's Last Theorem where $n$ is a power of $2$,"I have seen the proof that Fermat gives for $$x^4 +y^4 \neq z^2$$ which we know also works for $z^4$. BUT I am wondering if the same basic argument can be used for the power of $2^n$. Thinks 8,16,32 Can we write a proof saying 
 $$x^8+y^8 \neq z^8$$
More generally written as:
$$x^{2^n} +y^{2^n} \neq z^{2^n}$$ Anyone have a proper way to go about this?? Maybe some helpful links?","['diophantine-equations', 'number-theory']"
786827,"The PMF of the larger of two numbers selected at random from $1,\dots,12$","Two balls are chosen at random from a box containing 12 balls, numbered 1;2; : : : ;12. Let X be the
  larger of the two numbers obtained. Compute the PMF of X, if the sampling is done (a) without replacement; (b) with replacement I understand the numerator for both cases. In case 1, we have 1 ball x such that X=x and x-1 balls smaller than x, so we have 1(x-1) = x-1. In case two, we have x choices for a ball, then x-1 choices, so x+x-1 = 2x-1. The denominator is troubling me and it's a core probability concept I never understood In case 1, we have 12 options for the first choice and 11 for the second. Therefore, the total number of possibilities should be 12*11 = 132. But it's not, it's half of that, which is 66 In case 2, we have 12 options for the first choice and 12 for the second. Total possibilities is 12*12 = 144. This is correct Why am I right in the 2nd case but wrong in the first? We had a similar question on our midterm: We have 7 unique children and 20 identical cookies. How many ways can we distribute the cookies such that each child gets one? I thought if each child gets one, there are 13 left. Each of those 13 cookies can go to one of 7 children, so the answer should be 7^13. After learning the stars and stripes method, I realize the correct calculation leads to 19C7. I'm wondering WHY it is that my calculation is wrong, why there are two possible calculations, and what my calculation represents. It is this concept that I never understood that is still giving me trouble. I can do PMF and density functions, but I have trouble with this simplest concept","['probability-distributions', 'probability']"
786832,convergence of $\sum_1^ \infty n^2 e^{- \sqrt{n} }$,"I'm trying to determine if $\sum_1^ \infty  n^2 e^{- \sqrt{n} }$ converges.
For divergence test, I got 0 (well my calculator did... I'm not entirely sure how to limit this...) . For ratio test, I got 1. For root test, I got 0. Now I'm trying to use comparison test but i'm not sure what to compare it with....","['sequences-and-series', 'calculus']"
786837,Show that the form $w$ is closed but not exact,"Let $$w~=~\dfrac{-y}{x^2+y^2}dx+\dfrac{x}{x^2+y^2}dy, \qquad (x,y)~\in\mathbb{R}^2\backslash \{(0,0)\}.$$ Showing that $w$ is closed is easy. Just calculate $dw$ and you'll get 0. But how do I show that $w$ is not exact? In other words, I need to prove that there is no form $\lambda$ such that $w=d \lambda$ Should I assume that $w=d \lambda$ and try to get to a contradiction?","['multivariable-calculus', 'differential-forms']"
786888,Let $f(x)=\frac{f(x+e)+f(x-e)}2$. Show that $f$ is affine,"Let $f:[a,b] \rightarrow \mathbb{R}$ , continuous and  and satisfying for all $x\in (a,b)$ there exists $e>0$ such that $$f(x)=\frac{f(x+e)+f(x-e)}2$$ Show that $f$ is affine $f$ is continuous on $[a,b]$ then I know that $f$ is bounded, I tried to use $(\varepsilon,\eta$ ) method to see something, but I did not succeed. Thank you in advance for your help.","['functions', 'calculus', 'real-analysis']"
786969,closed form for combinatorial sum [duplicate],"This question already has answers here : Sum with binomial coefficients: $\sum_{k=0}^{n}{2n\choose 2k}$ [closed] (5 answers) Closed 5 years ago . Is there a closed form expression for $\displaystyle\sum_{k=0}^n \binom{2n}{2k}$? A student I tutor was asking me about this and I didn't know. I know if this had a $k$ instead of $2k$, this sum would just be $(2n)^n$ but summing over evens complicates things. Is there even an asymptotic form for this?",['combinatorics']
786984,"Confusion about ""horizontal composition"" of natural transformations","I'm having trouble with an exercise from Rotman's Homological Algebra. It has to do with what Wikipedia calls "" horizontal composition "" of natural transformations. Namely, given $F, G:\mathcal{A}\to\mathcal{B}$ and $F^\prime, G^\prime:\mathcal{B}\to\mathcal{C}$ covariant functors and $\sigma:F\to G$ and $\tau:F^\prime\to G^\prime$ natural transformations, the goal is to show that there is a composite natural transformation $\tau\sigma: F^\prime F\to G^\prime G$. There should be a ""natural choice"" for the morphism $(\tau\sigma)_A$ associated to any $A\in\operatorname{obj}\mathcal{A}$, and this is where I'm confused. The problem says to define $$(\tau\sigma)_A=\tau_{FA}\sigma_A : F^\prime F(A)\to G^\prime G(A)$$ but this doesn't make sense to me since $\tau_{FA}\in\operatorname{Hom}(F^\prime F(A),G^\prime F(A))$ and $\sigma_A\in\operatorname{Hom}(FA,GA)$ (right?). It's not clear to me why this is the right composition, or that it even is a composition. If I had to guess, I would say $(\tau\sigma)_A:=\tau_{GA}F^\prime(\sigma_A)$ because this is the only thing I can come up with that actually is a morphism $F^\prime F(A)\to G^\prime G(A)$. Can anyone clear up my confusion?","['category-theory', 'abstract-algebra']"
787009,Evaluate Gauss-like Integral,Evaluate Integral $$\int_0^\infty e^{-ay^{2}-\frac{b}{y^2}}dy $$ Where a and b are real and positive. This integral is eerily similar to the Gaussian integral $$\int_0^\infty e^{-\alpha x^2}dx = \frac{1}{2} \sqrt{\frac{\pi}{\alpha}}$$ This is an integral I have come across as a step in a problem doing some homework for Advanced Statistics... Not sure where to begin.,"['definite-integrals', 'improper-integrals', 'calculus', 'integration']"
787045,How can probabilities be modeled in a universe where time travel is possible?,"Please don't take this as a joke, its actually a serious question. If it sounds silly its only because of my (lack of) understanding of probabilities, but my motivation is genuine. Lets take the following 2 events: $A$: Shooting once at a bullseye and hitting at an specific point $P_A$. $B$: Shooting twice at a bullseye and hitting both times in the same point $P_B$. Under classic asumptions (for some sensible definition of classic) both events have $0$ probability. Right? Now suppose we have backwards time travel (despite physics contradictions). I can watch where the projectile hits the first time, then go back in time, and make a prediction with probability $1$ for $P_A$. However, even with time travel, event $B$ still has $0$ probability. My questions are: Is there some real difference in how these two events are modeled, or interpreted, or is there (more probably) some logical flaw in my reasoning? Does this means that time travel is impossible from a logical point of view, without even looking at physics?","['probability', 'soft-question']"
787129,Is there an identity for cos(ab)?,"I know that there is a trig identity for $\cos(a+b)$ and an identity for $\cos(2a)$, but is there an identity for $\cos(ab)$? $\cos(a+b)=\cos a \cos b -\sin a \sin b$ $\cos(2a)=\cos^2a-\sin^2a$ $\cos(ab)=?$",['trigonometry']
787199,On the existence of non-abelian finite groups,Is it true that for any $n\in \mathbb{Z}$ with $n\geq 6$ and $n$ not a prime there exists a non abelian group of order $n$? How can we prove it? If the answer to the above is negative is it maybe true that there are for any $p$ prime and $n$ positive integer grower than $3$ a non abelian group of order $p^n$?,"['finite-groups', 'group-theory', 'abstract-algebra']"
787233,Calculate $\int_0^1 e^x dx$ as a limit of a sum?,"As for now, I've been doing the opposite thing. For a given sum in terms of $n\in\mathbb{N}$ I had to calculate the limit (as $n$ approaches infinity) of that sum by applying: http://en.wikibooks.org/wiki/Calculus/Integration_techniques/Infinite_Sums , more precisely, a special case: $$[a, b] = [0, 1] , \space x_k = \frac{k}{n} \implies \lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n f\bigg(\frac{k}{n}\bigg) = \int_0^1f(x)\,dx$$ Example: $$ \lim_{n\to\infty} \bigg( \frac{1}{n+1} + \frac{1}{n+2} + \cdots + \frac{1}{2n}\bigg) = \lim_{n\to\infty} \sum_{k=1}^n\frac{1}{n+k} = \lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n\frac{1}{1 + \frac{k}{n}}$$ = integral sums ( I literally translated the term we use for this in my Analysis class, I don't know how it's called in English ) for $f(x) = \frac{1}{1+x}$ on $[0, 1]$ $$ = \int_0^1 \frac{1}{1+x} \,dx = \ln(1+x)\bigg\vert_0^1 = \ln2 - \ln1 = \ln2 $$ so the limit of the sum as $n$ approaches infinity is $\ln2$. The following exercise asks to reverse the process (i.e. to use integral sums to calculate the limit), so I have: $$\int_0^1 e^x \,dx$$ The regular approach gives me: $\int_0^1 e^x \,dx = $ Leibniz-Newton $ = e^x \vert_0^1 = e^1 - e^0 = e -1$ If this integral can be expressed as a limit of a sum, then it should (if I am correct) have the following form: $$\int_0^1 e^x \,dx = \lim_{n \to \infty}\frac{1}{n}\sum_{k=1}^ne^\frac{k}{n}= \lim_{n \to \infty}\sum_{k=1}^n\frac{e^\frac{k}{n}}{n}$$ And since one definition of $e$ is:
$$e = \lim_{n\to\infty}\bigg(1+\frac{1}{n}\bigg)^n$$ I have:
$$\int_0^1 e^x \, dx = \lim_{n \to \infty}\sum_{k=1}^n\frac{((1+\frac{1}{n})^n)^\frac{k}{n}}{n} = \lim_{n \to \infty}\sum_{k=1}^n\frac{(1+\frac{1}{n})^k}{n} =$$
$$\lim_{n \to \infty} \bigg[ \frac{(1+\frac{1}{n})^1}{n} + \frac{(1+\frac{1}{n})^2}{n} + \cdots + \frac{(1+\frac{1}{n})^{n-1}}{n} + \frac{(1+\frac{1}{n})^n}{n}\bigg]$$ ... which doesn't seem to be what I am looking for (or I am not seeing it). I would appreciate a hint (or two :))! EDIT: By using Ron Gordons big hint we have: $$\int_0^1 e^x\,dx = \lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n e^\frac{k}{n} = \lim_{n\to\infty}\frac{1}{n} \bigg( e^\frac{1}{n} + e^\frac{2}{n} + e^\frac{3}{n} + \cdots + e^\frac{n}{n} \bigg)$$ $$\lim_{n\to\infty}\frac{1}{n} \bigg( e^\frac{1}{n} + e^\frac{1}{n}\cdot e^\frac{1}{n} + e^\frac{1}{n} \cdot e^\frac{1}{n} \cdot e^\frac{1}{n} + \cdots + \underbrace{e^\frac{1}{n} \cdot e^\frac{1}{n} \cdots e^\frac{1}{n}}_{n \space factors} \bigg) =$$
$$ \lim_{n\to\infty}\frac{1}{n} \bigg( e^\frac{1}{n} + e^\frac{1}{n} \cdot e^\frac{1}{n} + e^\frac{2}{n} \cdot e^\frac{1}{n} + e^\frac{3}{n} \cdot e^\frac{1}{n} + \cdots + e^\frac{n-1}{n} \cdot e^\frac{1}{n} \bigg) = $$
$$ \lim_{n\to\infty}\frac{1}{n} \bigg( e^\frac{1}{n} + \underbrace{(e^\frac{1}{n})^1}_q \cdot e^\frac{1}{n} + \underbrace{(e^\frac{1}{n})^2}_{q^2} \cdot e^\frac{1}{n} + \underbrace{(e^\frac{1}{n})^3}_{q^3} \cdot e^\frac{1}{n} + \cdots + \underbrace{(e^\frac{1}{n})^{n-1}}_{q^{n-1}} \cdot e^\frac{1}{n} \bigg)$$ The expression inside the parentheses can be interpreted as a sum of a geometric series: $a_1 + a_2 + a_3 + a_4 + \cdots + a_n = a_1 + q\cdot a_1 + q^2\cdot a_1 + q^3\cdot a_1 +  \cdots + q^{n-1}\cdot a_1$ where $a_1 = e^\frac{1}{n}$ and $q = e^\frac{1}{n}$ so $a_1 = q$ and by using the formula $S_n = a_1 \cdot \frac{q^n - 1}{q - 1}$ we get: $$ S_n = e^\frac{1}{n} \cdot \frac{(e^\frac{1}{n})^n - 1}{e^\frac{1}{n} - 1} = e^\frac{1}{n} \cdot \frac{e^\frac{n}{n} - 1}{e^\frac{1}{n} - 1} = e^\frac{1}{n} \cdot \frac{e - 1}{e^\frac{1}{n} - 1}$$ so our integral is actually the following limit: $$ \int_0^1 e^x\,dx = \lim_{n\to\infty} \frac{1}{n} \cdot S_n = \lim_{n\to\infty} \frac{1}{n} \cdot e^\frac{1}{n} \frac{e - 1}{e^\frac{1}{n} - 1} = $$ ... by using some properties of limits we get:
$$ = \lim_{n\to\infty} e^\frac{1}{n} \cdot  \lim_{n\to\infty}\frac{1}{n}\frac{e - 1}{e^\frac{1}{n} - 1} = \lim_{n\to\infty} e^\frac{1}{n} \cdot \frac{\lim_{n\to\infty} (e - 1)}{\lim_{n\to\infty} n\cdot (e^\frac{1}{n} - 1)}$$ $$\lim_{n\to\infty} e^\frac{1}{n} = e^\frac{1}{+\infty} = e^0 = 1$$
$$\lim_{n\to\infty} (e - 1) = e - 1$$ so we have: $$\int_0^1 e^x\,dx = 1\cdot \frac{e - 1}{\lim_{n\to\infty}n\cdot (e^\frac{1}{n} - 1)} = \frac{e - 1}{\lim_{n\to\infty}n\cdot (e^\frac{1}{n} - 1)}$$ The only thing left is to show: $\lim_{n\to\infty}n\cdot (e^\frac{1}{n} - 1) = 1$ Approach 1:
$$\lim_{n\to\infty}n\cdot (e^\frac{1}{n} - 1) = \begin{bmatrix} t = \frac{1}{n}
\\ n \to \infty \implies t\to 0 \end{bmatrix} = \lim_{t\to 0} \frac{1}{t}(e^t - 1) = \lim_{t\to 0}\frac{e^t - 1}{t} = 1$$ Aproach 2:
$$\lim_{n\to\infty}n\cdot (e^\frac{1}{n} - 1) = [\infty \cdot 0] = \lim_{n\to\infty}\frac{(e^\frac{1}{n} - 1)}{\frac{1}{n}} = \bigg[\frac{0}{0}\bigg] = L'Hospital = \lim_{n\to\infty}\frac{(e^\frac{1}{n}\cdot (-\frac{1}{n^2}) - 0)}{-\frac{1}{n^2}} = \lim_{n\to\infty}\frac{e^\frac{1}{n}\cdot (-\frac{1}{n^2})}{-\frac{1}{n^2}} = \lim_{n\to\infty} e^\frac{1}{n} = e^\frac{1}{+\infty} = e^0 = 1$$ finally: $$\int_0^1 e^x\,dx = \frac{e-1}{\lim_{n\to\infty}n\cdot (e^\frac{1}{n} - 1)} = \frac{e-1}{1} = e - 1$$","['definite-integrals', 'integration', 'real-analysis']"
787299,"What is the isomorphism between the fields $(Z_2[x]^{<3},+_{x^3+x^2+1},\times_{x^3+x^2+1})$ and $(Z_2[x]^{<3},+_{x^3+x+1},\times_{x^3+x+1})$? [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question They are both Galois fields of order 8.
I'm not exactly sure what the question means - how does one determine/describe an isomorphism?","['group-isomorphism', 'number-theory', 'finite-fields', 'abstract-algebra', 'field-theory']"
787304,differential equation $y''(x)-ay^3(x)+by(x)=0$,"Hi I am trying to find a solution $y(x)$ to this non linear differential equation
$$
y''(x)-ay^3(x)+by(x)=0.
$$
I know a nice solution exists, however how can I go about solving this?  I know non linear ODE's a are tougher than linaer ODE's, however this one has such a closed form solution I thought maybe it would be straight forward. I can verify that a solution exists , we can write it in the general form $$
y(x)=A \tanh cx,\quad y''(x)=2c^2A\tanh cx(\tanh^2 cx-1).
$$
We can simply verify this works by plugging into the ODE to obtain$$
2c^2A\tanh^3 cx-2c^2A\tanh cx-aA^3\tanh^3 cx+bA\tanh cx=0,\quad a,b\in \mathbb{R}.
$$
We can see this is true if 
$$
2c^2 A=aA^3,\quad 2c^2A=bA,\to A=\sqrt\frac{2c^2}{a}=\sqrt \frac{b}{a},\quad c=\sqrt \frac{b}{2}.
$$
We can now see
$
y(x)=A\tanh cx 
$ is a solution for these values of A and c. Now how can we solve this differential equation and obtain y(x)?  Thanks for reading this and thinking about it","['ordinary-differential-equations', 'calculus', 'real-analysis', 'analysis']"
787322,Number of Binary Operations On a Set,"For a group $[S,*]$ where $S=\{a,b\}$, how come there are $2^4$ binary operations that can be defined on $S$ instead of $2^2$? I can only see $a*a$, $a*b$, $b*a$, and $b*b$, which is $4=2^2$. What other operations can possibly exist? What am I not seeing here?","['discrete-mathematics', 'group-theory', 'abstract-algebra']"
787334,How does Schwartz's paradox of surface area affect modelling of 3D objects?,"Question I just became aware of Schwartz's paradox of surface area (explanation below for the unfamiliar). How does this effect mathematical modelling of real-life surfaces? For example, suppose I wanted to measure the surface area of a mountain and had the elevation data. I've found approaches that produce a polyhedral approximation ( here ), but how do we know this polyhedral approximation is actually approaching the surface area of the mountain? Thanks! PS Maybe this is a better physics question? Also, Mandlebrot's first fractal paper comes to mind as a similar problem. Schwartz's Paradox Explanation If I understand correctly, Schwartz's Paradox shows that simply because a polyhedral approximation, $P_n$, of a curved surface $S$ approaches the curved surface as $n \to \infty$, the surface area of the polyhedral approximation, $A(P_n)$, does not approach the geometrically intuitive surface area of the surface, $A(S)$. In summary, $$\lim_{n\to\infty} P_n = S \not\Rightarrow \lim_{n\to\infty} A(P_n) = A(S) $$ I surmised this from the following paper .",['geometry']
787343,Deciding eigenvalue degeneracy without calculating all eigenvalues and eigenvectors,"Given a diagonalizable matrix $M$ (that is, a normal matrix ), can we determine whether the matrix has degenerate eigenvalues without explicitly calculating all the eigenvalues and eigenvectors? An example that came to my mind is that $M$ is square of a skew-Hermitian matrix since a skew-symmetric matrix always has pairs of pure imaginary eigenvalues $\pm i \lambda_i$ . Similarly, a matrix that is square of a matrix that has pairs of eigenvalues with different signs such as $\lambda_1,-\lambda_1,\dots$ is such a case. However, these things require sorts of decomposition of the matrix $M$ , which is another problem! Another way is calculating the characteristic polynomial $\det(M-\lambda I)=0$ and factorize it, then check the degrees of each terms. But this amounts to calculating all the eigenvalues already. Do we have other (simple) criteria or ways to determine the degeneracy of eigenvalues of a matrix $M$ ?","['eigenvalues-eigenvectors', 'matrices', 'linear-algebra', 'spectral-theory', 'functional-analysis']"
787371,Determining if these surjections have sections,"Let $\pi:\ \operatorname{GL}(2,k)\ \longrightarrow\ \operatorname{PGL}(2,k)$ be the canonical homomorphism, and pick some finite subgroup $G\subset \operatorname{PGL}(2,k)$ . Then we have an exact sequence $$1\ \longrightarrow\ \{\alpha I\mid \alpha \in k\}\ \longrightarrow\ \pi^{-1}(G)\ \longrightarrow\ G\ \longrightarrow\ 1.$$ Specific question: Let $k$ be algebraically closed of characteristic zero and let $G$ be some subgroup of $\operatorname{PGL}(2,k)$ isomorphic to $A_5$ . Does this sequence split in this case? (It seems to me it shouldn't, but I don't have a proof.) General question: How would you go about determining, for any particular case of $k$ and $G$ , if this sequence splits?","['classical-groups', 'algebraic-groups', 'exact-sequence', 'group-theory', 'linear-groups']"
787379,A question regarding Frobenius method in ODE,"Suppose $b(x),c(x)$ are real functions analytic at $0$. Let $b(x)=\sum_{i=0}^\infty b_ix^i, c(x)=\sum_{i=0}^\infty c_ix^i$ on $(-R,R)$. Suppose $r$ is a double root of  $r(r-1)+b_0r+c_0=0$. It is well known that the differential equation $$x^2y''+xb(x)y'+c(x)y=0$$ has a solution of the form $$y_1=x^r(1+\sum_{i=1}^\infty a_ix^i),$$ where the series $\sum_{i=1}^\infty a_ix^i$ has radius of convergence $\ge R$ (e.g., see Tyn Myint-U, Ordinary Differential Equations). Another solution is of the form $$y_1\ln x + x^r(\sum_{i=1}^\infty A_ix^i).$$ Most books (including Tyn's) mention without proof that $\sum_{i=1}^\infty A_ix^i$ also has radius of convergence at least $R$. Let $I(s)=s(s-1)+b_0s+c_0$. Then $A_i, i\ge 1$ satisfy the following recursive relation
$$I(r+i)A_i=-\sum_{k=0}^{i-1}A_k[(r+k)b_{i-k}+c_{i-k}]-2ia_i-\sum_{k=1}^{i}b_ka_{i-k}$$
where $A_0=0$. (Note that $2r=1-b_0$). Proving that the power series $\sum_{k=1}A_kx^k$ has radius of convergence at least $R$
directly seems to be hopeless. I tried comparison test as in Coddington's book Introduction
to Ordinary Differential Equations , but with no success. Does anyone have a proof, or a reference where a proof is given?","['complex-analysis', 'ordinary-differential-equations', 'reference-request', 'real-analysis']"
787382,Irrationality of $\pi$ another proof,"Proposition. Let $\alpha\in\mathbb{R}$. If there is a sequence of integers $a_n,b_n$ such that  $0<|b_n\alpha-a_n|\longrightarrow 0^+$ as $n\longrightarrow \infty$, then $\alpha$ is irrational. How to prove that $\pi$ is irrational using this proposition? I know several proof of the irrationality of π with complex analysis, but I think in this way is very difficult. For example to prove the irrationality of $e$ consider $$0<n!e-n!\left(1+\frac{1}{2!}+\frac{1}{3!}+\cdots +\frac{1}{n!}\right)\le\frac{1}{n}\longrightarrow0^+$$ Any hint would be appreciated.","['transcendental-numbers', 'irrational-numbers', 'real-analysis']"
787397,"Recommend textbooks that expain branch cut, Riemann surface and contour integration with branch cut in detail","I read several textbook on complex analysis, but few of them explain the branch cut and Riemann surface in detail and treat the contour integration with branch cut. But this is very important for many application and I'm curious why textbooks on complex analysis all skip this part. So is there some books or materials that can take branch cut seriously? Thanks!","['book-recommendation', 'online-resources', 'reference-request', 'branch-cuts', 'complex-analysis']"
787410,Proof: Force always perpendicular and motion in a plane implies that the trajectory is a circle,"I am looking for a proof for a physics problem. Consider a particle which is subject to a force $\vec{F}(t)$ with $|\vec{F}(t)| = \text{const}$ which is always perpendicular to the velocity $\vec{v}(t)$. Further assume that the motion takes places in a plane. To put it in a mathematical problem: Let $x\colon \mathbb{R} \to \mathbb{R}^2$ (2 because of the ""plane"" condition) be smooth. Suppose $<x''(t),x'(t)>= 0$ for all $t$ and $|x''(t)| = \text{const}$. Then $x(\mathbb{R})$ is a circle. $<\cdot,\cdot>$ denotes the standard scalar product on $\mathbb{R}^2$ and $'$ the derivative. How to prove this? Does the theorem remains correct if one drops the assumption $|x''(t)| = \text{const}$? Note this is not a homework problem, I just want to know how to prove this physical result mathematically. In physics books the statement above is claimed sometimes, but in every instance I have seen they proved just the logically converse statement.","['physics', 'vector-analysis', 'differential-geometry']"
787417,What is the difference between $\Delta r$ and $dr$ in Taylor series,"All I know about Taylor series is at here . It tells how to expand a funcion to a polynomial. However I see the Taylor series at the form like this (here $r$ is a parametrized surface of $u,v$): $$\Delta r=dr+\frac12d^2r+o(du^2+dv^2)$$ It confuses me since I don't know the difference between $\Delta r$ and  $dr$ (all I know is they are the same at 2 dimensional function, $f=f(x)$ when $\Delta x$ becomes infinitesimal). Can anybody give me a geometrical intuition of $\Delta r$ and $dr$ together with $\Delta^nr $ and $d^nr$ ? Also, I have heard that in a higher dimension, derivatives exist not implies differentiability. Can anyone give me some examples about that? Thirdly, I don't know when the 'infinitesimal of higher order' can be neglect. In many case we will neglect the $o(x^n)$ function. But when can we neglect and how can we know which order can we neglect? Using the above Taylor series as example, let $n$ be an unit normal vector of the points on the surface,  my book said $$\Delta r\cdot n=\left[dr+\frac12d^2r+o(du^2+dv^2)\right]\cdot n=\frac12d^2r\cdot n$$ Why the term $o(du^2+dv^2)$ can be neglect but not the higher or lower order of $o$ funcion?","['multivariable-calculus', 'partial-derivative', 'calculus', 'derivatives']"
787466,What is the completion of this space?,"This question asks us to show that $\Bbb R$ with the following metric is not complete: Fix a strictly positive function $f \in L^1(\Bbb R)$, and let $d(x,y)=\left|\int_x^y f(t)dt\right|$. It's easy to see (in line with the answers to the linked question) that any unbounded increasing sequence of real numbers is Cauchy without limit in this metric. What is the completion of this metric space? Is it homeomorphic to any well-known space? If not, what are some interesting properties it has? If the problem is intractable for arbitrary $f$, feel free to choose a suitably interesting $f$ or subclass of such $f$. (In particular, continuous $f$ or smooth $f$.)","['general-topology', 'metric-spaces', 'real-analysis']"
787484,Proof that Limit of the Log is the Log of the Limit,Proof that Limit of the Log is the Log of the Limit. What is the intuition behind this statement?,"['calculus', 'limits']"
787500,Find $e^{AT}$ where $A$ is a Matrix that is given,How to find the value of  $e^{At}$ where $A$ is the matrix $A =\begin{bmatrix} 4 & 3 \\ 2 & -1 \end{bmatrix}$,"['matrices', 'linear-algebra', 'sequences-and-series', 'ordinary-differential-equations']"
787505,"If J is uncountable, then $R^J$ is not normal.","If J is uncountable, then $R^J$ is not normal. Let X = $(Z+)^J$; it 
will suffice to show that X is not normal, since X is a closed subspace of $R^J$ . We 
use functional notation for the elements of X, so that the typical element of X is 
a function x : J $\rightarrow$ Z+. (a) If x $\in$ X and if В is a finite subset of J, let U(x, B) denote the set consisting 
of all those elements у of X such that у ($\alpha$) = x($\alpha$) for $\alpha\in$ B. Show the sets 
U(x, B) are a basis for X. (b) Define $P_n$ to be the subset of X consisting of those x such that on the set 
J — $x^{-1}$(n), the map x is injective. Show that $P_1$ and $P_2$ are closed and 
disjoint. (c) Suppose U and V are open sets containing $P_1$ and $P_2$, respectively. Given a 
sequence $\alpha_1$,$\alpha_2$ ,... of distinct elements of J, and a sequence 
0 = 
< $n_0$ < $n_1$ <...
of integers, for each i > 1 let us set 
$B_i$ ={ $\alpha_1$,$\alpha_2$,...,$\alpha_{n_i}$}
and define $x_i$ $\in$ X by the equations 
$x_i$($\alpha_j$) = J for 1 =< j =< $n_{i-1}$ . 
$x_i(\alpha)$ = 1 for all other values of $\alpha$. 
Show that one can choose the sequences $\alpha_j$ and $n_j$ so that for each i, one 
has the inclusion 
U($x_i$,$B_i$)$\subset$U. 
[Hint: To begin, note that $x_1(\alpha)$ = 1 for all $\alpha$; now choose $B_1$ so that
 U($x_1$,$ B_1$) $\subset$ U] this is an exercise from munkres topology ive done part a & b but i have no idea for part c . can anyone help me with c ? of course there is  some similar questions about this problem but they werent any help.
thank u.","['general-topology', 'separation-axioms', 'product-space']"
787515,annihilator method confusion,"I have a final in the morning and I am extremely confused on the annihilator method.
I have been googling different explanations all night and I just dont get it at all. I am looking at an example: $$\ddot{y}+6\dot{y}+y=e^{(3x)}-\sin(x)$$ now I get that the annihilator of the $e$ term is $(D-3)$ but the answer is $(D-3)(D+1)(D^2 +6D +8)$ can someone explain the second part and if you are feeling generous how to do other annihilators maybe with examples in really simple language. I get so lost with these explanations that use ""math language"" also is there a list or something I can study for what annihilates what? i have found one that I understand but it's really limited. A lot of them are written in extremely complicated language. thanks for your help","['higher-order-logic', 'ordinary-differential-equations']"
787516,"Why is analysis called ""analysis""?","Just as the topic says, how did the name ""analysis"" come to denote the specific mathematical branch dealing with limits and stuff? The term ""analysis"" seems very generic compared to the words for the other two main branches, ""algebra"" and ""geometry"", which do not seem to have other unrelated meanings.","['soft-question', 'math-history', 'terminology', 'real-analysis']"
787534,What does it means that sequences characterize closed sets and functions?,"A text book I'm reading says at one point the following: ""In metric spaces are sequences the ones which chacterize closed sets and continuous functions"". What is exactly the meaning of that phrase?, is that every closed set and every continuous function can be described by sequences. I know a couple of things about metric spaces and sequences that I believe are related: $1-$ In a closed sets sequences inside a set converge to a point inside the set $2-$ A function $f(x)$ is continuous iff $\{f(x_n)\}\to f(x)$ for every sequence convergent to $x$. But I don't understand what it means by 'characterize', are sequences in metric spaces enough to define what closed sets and continuous functions are or there is something more behind that statement?","['general-topology', 'metric-spaces', 'continuity']"
787536,Sufficient condition for time-changed quadratic covariation to vanish in probability,"Let $(M_t^n)_{t \geq 0}$ be a sequence of continuous martingales of the form $M^n_t = \int_0^t X^n_s \, dB_s$ where $B_s$ is a Brownian motion. Let $\tau^n(t)$ be the time change associated to $M_t^n$ via the Dambis-Dubins-Schwarz theorem, i.e. $\tau^n(t) = \inf \, \{s \mid \langle  M^n,M^n \rangle_s > t \}$ and we have that $M_t^n = \widetilde{B}_{\tau^n(t)}$, where $\widetilde{B}$ is another Brownian motion and $\langle M^n,M^n \rangle_t$ denotes the quadratic variation of $M^n_t$. I'm reading a paper and can't figure out the following statement: "" In order for $\langle M^n,B \rangle_{\tau^n(t)}$ to converge to zero in probability (for $n \to \infty$), it is sufficient to show that $\langle M^n,B \rangle_{t}$ converges to zero in probability, uniformly in $t$ on compact sets. "" How does one prove this? Is this true for any stopping time? What the authors in fact show is uniform convergence in $L^p$, i.e. that $\sup_{0 \leq t \leq T} \operatorname{E} \left[ \left| \langle M^n,B \rangle_{t} \right|^p \right]$ converges to zero for $n \to \infty$, any $p \geq 2$ and any $T>0$, but this also doesn't give me an idea for a proof.","['stochastic-processes', 'martingales', 'stochastic-integrals', 'probability-theory', 'stochastic-calculus']"
787537,Perfect Square relationship with no solutions,"I would like to show that for positive integers $a>b,c$ all greater than 1 such that $c\nmid a$, there are no solutions to the following equation: $$a^2+1=b^2(c^2+1)$$ As was pointed out in the comments, it might help to rearrange and factor: $$(a-b)(a+b)=(bc+1)(bc-1)$$ Another interesting approach to the question, if we rewrite: $$a^2-b^2c^2=b^2-1$$ Then we are trying to argue that $b^2-1$ cannot be squarefree (in particular, $c^2|b^2-1$)","['square-numbers', 'number-theory']"
787576,Binomial Summation,"The sum
$$ 1 + {n \choose 1}\cos \theta + {n \choose 2}\cos 2\theta + \cdots+ {n \choose n}\cos n\theta $$
is? I try to write this as the real part of $(1 +  \cos \theta + i\sin \theta)^n$ but then I'm stuck.","['contest-math', 'binomial-coefficients', 'complex-analysis']"
787594,Finding the missing coordinate of a point within a 3D triangle,"We have an equilateral triangle $ABC$ in 3-dimensional space. The points are known, such as: $A = (x_1,y_1,z_1)$ $B = (x_2,y_2,z_2)$ $C = (x_3,y_3,z_3)$ Point $P$ is on triangle $ABC$. If I know that $P = (x_4, y_4, ?)$ where $x_4$ and $y_4$ are given, how can I calculate the missing coordinate of that point?","['geometry', 'triangles', 'trigonometry', '3d']"
787625,To solve $ \dfrac {dy}{dx}=\dfrac 1{x^2+y^2}$,How do we solve $ \dfrac {dy}{dx}=\dfrac 1{x^2+y^2}$ ? In general for which positive real $b$ do the equation $\dfrac {dy}{dx}=\dfrac 1{(x^2+y^2)^b}$ admit an analytic solution ?,['ordinary-differential-equations']
787650,Are there more rational or irrational numbers? [duplicate],"This question already has answers here : Proof that the irrational numbers are uncountable (4 answers) Intuitive explanation for how could there be ""more"" irrational numbers than rational? [duplicate] (8 answers) Closed 10 years ago . On the number line, are there more rational numbers or irrational numbers? I was told that there are equally many rational and irrational numbers. Is this correct? How could we prove that?",['elementary-set-theory']
787656,A problem on 0-1 matrices.,"Given a 0-1 matrix $A$, is there an efficient way to find all 0-1 vectors $x$ such that $Ax = v$ where the entries of $v$ belong to a set $\{a,b\} \subseteq \mathbb{Z}$ of size $2$? 
Note that $v$ is not a fixed vector, it can vary over all $2^n$ vectors where $n$ is the dimension. Of course, I require something which would be more efficient than going through all the $2^n$ possible values for $v$ where $n$ is the length of vector $v$ and doing Gaussian elimination each time. Is there something more efficient than that? Edit: The motivation comes from the following problem. Given a $k$-uniform family $F$ of subsets of $[n] := \{1,\ldots,n\}$ determine all subsets of $[n]$ that intersect each member of $F$ in $1$ or $k$ points. For $k = 3$ this can be done easily by computing the nullspace of the incidence matrix over $GF(2)$ since a subset intersects a member of $F$ in $1$ or $3$ points if and only if its complement intersects that member in $0$ or $2$ points. I was wondering if there are similar approaches for other values of $k$. It doesn't look like the trick generalises to larger $k$.","['constraint-programming', 'matrices', 'linear-algebra', 'computer-science', 'combinatorics']"
787666,Does the fundamental theorem of calculus hold for BV functions?,"I am a bit confused and I hope you can help me in understanding a bit better these things. Let us start by considering one dimensional case. Let $f\colon \mathbb (a,b) \to \mathbb R$ be a function. As far as I know, the equality 
$$\tag{FTC}
f(x) = f(a) + \int_a^x f^{\prime}(t)dt
$$ holds for every $x \in (a,b)$ if and only if the function $f$ ia $AC(a,b)$. This makes sense, because an absolutely continuous function on the real line is differentiable Lebesgue a.e. (for instance, because it can be written as sum of monotone functions: then a deep theorem by Lebesgue assures a.e. differentiability). Moreover, we know that AC is a (proper) subset of BV; the formula (FTC) does not hold in BV (counterexample: the devil staircase ). Am I right so far? Hope so. Now let turn to the n-dimensional case, $f \colon \mathbb R^n \to \mathbb R$. We define a BV function as a function whose first (distributional) derivatives are signed measures with finite total variation. Now the point is: here I read (Theorem 9 ) that for every BV function there is a signed measure such that $f=\mu((-\infty,x])=\int_{-\infty}^x d\mu$. But this is exactly FTC, up to writing in the RHS $\int_{\infty}^x f^{\prime}$ instead of $\int f^{\prime}dt$! I mean, the only difference is that $\mu$ need not be absolutely continuous (as a measure) with respect to Lebesgue measure. So my final conjecture is: FTC holds formulation for every BV function but the RHS must be considered as the distributional derivative. And AC functions are precisely the BV functions whose distributional derivative is absolutely continuous wrt Lebesgue. Is this correct? Is there anything to add?
Thanks.","['bounded-variation', 'distribution-theory', 'integration', 'real-analysis']"
787672,"Is $[0,1]^{[0,1]}$ Hausdorff and first-countable?","I'm trying to determine if $[0,1]^{[0,1]}$ is Hausdorff or first-countable. What I know until now, is that $[0,1]^{[0,1]}$ has the product topology, then if $x\in [0,1]$ and $U$ open in $[0,1]$ the open sets of the product space are given by $$S(x,U)=\{f:[0,1]\to[0,1]:f(x)\in U\}$$ So the $B_Y$ is a basis for $[0,1]$ the subbasis will be given by $$\{S(x,B):x\in[0,1], B\in B_y\}$$ After that I was unable to conclude any of the questions I wanted to know. A few things are un my mind about it: Since there is $[0,1]$ is first countable seems reasonable that $[0,1]^{[0,1]}$ be first countable, I tried taking a countable basis for both but it didn't seem to work. And to prove that is  a Hausdorff space, the idea was the same that to prove $[0,1]^{[0,1]}$ is first countable, this is, using that both sets are Hausdorff. Considering $f_1,f_2\in [0,1]^{[0,1]}$ then there are $U_1,V_1\in [0,1]$ (domain) such that satisfies the Hausdorff condition and $U_2,V_2\in [0,1]$ codomain as well, then $U_1\times V_1$ and $U_2\times V_2$ should satisfy the Hausdorff condition as well?, would that prove it?.","['general-topology', 'continuity']"
787688,Prove that $e^{\ln{z}}=z$ from the power series,For my course in complex analysis we have to prove that the trivial relation $e^{\ln{z}}=z$. We are given the series for $\ln z$: $$f(w)=\sum_{n=0}^\infty (-1)^{n+1}\frac{w^n}{n}$$ $$\ln z = f(z-1)$$ I know that the series for $e^x$ is $$e^{x}=\sum_{n=0}^\infty \frac{x^n}{n!}$$ I tried to solve $$e^{\ln{z}}=\sum_{n=0}^\infty \frac{\left(\sum_{m=0}^\infty (-1)^{m+1}\frac{(z-1)^m}{m}\right)^n}{n!}$$ But just inserting the previous series into this does not yield a very convenient result. I think that if we expand the first power series around $z=0$ we would have already a problem (this makes sense since also $\ln 0$ does not exist. How and with what technique is this problem solved? Edit (clarification): We need to prove the relation given using the power series for $\ln{z}$ as definition.,"['power-series', 'complex-analysis']"
787690,A power of the characteristic polynomial,"Let $A$ be a square matrix with real or complex coefficients of size $n$. Define its characteristic polynomial by $\chi_A(X) = \det(A-XI_n)$ (or $\det(XI_n-A)$ if you prefer). The question is  : Prove that there exists a positive integer $q$ such that $\chi_A^q(A)=0$ where $\chi_A^q(X)= \chi_A(X)\times\cdots\times \chi_A(X)$ without using the Cayley-Hamilton theorem or the definition of an ideal of a ring. My problem with this problem is to find a ""good"" proof that doesn't mimic a proof of Cayley-Hamilton theorem. I know that it is easy to see (with a dimensional argument) that there exists a annihilating polynomial. But here I can't think of anything. An attempt of solution in the real or complex case : We know that there exists an annihilating polynomial (since $(I_n,A,A^2,\cdots,A^{n^2})$ can't be linearly independent, where $I_n$ is the identity matrix), we denote by $P$ such a polynomial. Then $P=\prod_{i=1}^p \left( X-\lambda_i\right)^{\alpha_i}$ ($\lambda_i\in \mathbb{C}$). We can assume that the $\lambda_i$ are roots of the characteristic polynomial. If not, then by definition of the characteristic polynomial $A-\lambda_iI_n$ is invertible. We can multiply $P$ by $(A-\lambda_iI_n)^{-\alpha_i}$, we still get an annihilating polynomial, and since we can permute all the terms, the term $\left( X-\lambda_i\right)^{\alpha_i}$ disappears. So if we take a sufficiently large power of the characteristic polynomial of $A$, we recover all the factors of $P$ times an another polynomial. This gives the desired result. What do you think of my attempt? Any ideas for the case where the coefficients of $A$ belong to an arbitrary abelian ring?","['alternative-proof', 'linear-algebra', 'proof-verification']"
787719,Why a function with compact support vanishes on the boundary of its domain,"A function has compact support if its support is a compact set, while the support of a function $u:G\rightarrow\mathbb{R}$ is defined to be $$\mathrm{supp}(u)=\overline{\{x\in G\mid u(x)\neq0\}}.$$ Lately, a statement said that If a function has compact support, it vanishes on the boundary of its domain. So, how does this implication come up? Is there anyone who can prove it? Thanks.","['general-topology', 'compactness', 'real-analysis']"
787754,Solve for $x$ in $6x^2-25x+12+\frac{25}{x}+\frac{6}{x^2}=0$,"I simplified to get $6x^4-25x^3+12x^2+25x+6=0$ Or $6 (x^2+1)^2+25x(1-x^2)=0$ Then I substituted $z=x^2+1$, to get $6z^2+25\sqrt{(z-1)}(2-z)=0$ I can't find a way to proceed further.",['algebra-precalculus']
787770,Hartshorne Propositon I.3.3,"In Hartshorne book Proposition (I.3.3) is that Proposition  : Let $U_i\subset \mathbb{P}^n$ be the open set defined by the equation $x_i\neq 0.$ Then the mapping $\varphi_i : U_i\longrightarrow \mathbb A^n$ is an isomorphism of varieties. Let $$\varphi_i : U_i\longrightarrow \mathbb A^n\\(a_0 : \cdots : a_n)\longrightarrow (\frac{a_0}{a_i} , \dots ,\frac{a_{i-1}}{a_i},\frac{a_{i+1}}{ a_i},\dots,\frac{a_n}{a_i})$$ $$\varphi_i^{-1} :\mathbb A^n \longrightarrow  U_i\\(a_1\dots,a_n)\longmapsto (a_1:\cdots:a_{i-1}:1:a_{i+1}:\cdots:a_n)$$ and
$$\alpha_i : A^h \longrightarrow R  \hspace{3.2cm}  f \longmapsto f(y_1,\dots,y_{i-1},1,y_i,\dots,y_n) $$
$$\beta_i : R \longrightarrow A^h \hspace{5mm} g \longmapsto x_{i}^{d} g(x_0/x_i,\dots,x_{i-1}/x_{i},x_{i+1}/x_i,\dots,x_{n}/x_{i}).$$
where $R=k[y_1,\dots,y_n],$  $A=k|x_0,\dots,x_n]$ and $A^h$ is the set of  homogeneous elements of $A.$ My question is : How to prove that for every open sets $V\subseteq U_i,$ $U\subseteq \mathbb{A}^n$ and for every 
regulars functions $f: V\longrightarrow k,$ $g: U\longrightarrow k$ the functions $fo\varphi_i:\varphi_i^{-1}(V)\longrightarrow k$ and $go\varphi_i^{-1}:\varphi_i(U)\longrightarrow k$ are regulars using the maps $\alpha_i$ and $\beta_i.$ Any help would be appreciated.",['algebraic-geometry']
787797,Evaluate $\int_{0}^{\infty} \frac{\ln (1+u) -\ln 2}{(u+1)\sqrt{u} \ln u} du$,Please help me with evaluate the following improper integral $$\int_{0}^{\infty} \frac{\ln (1+u) -\ln 2}{(u+1)\sqrt{u} \ln u} du.$$,"['definite-integrals', 'improper-integrals', 'integration']"
787815,find the point $P$ such that the expression has minimum value,"Let $ABC$ be a triangle with sides 
$$a,b,c.$$
Find a point $P$ inside the triangle such that 
$$a(PA)^2+b(PB)^2+c(PC)^2$$ 
is minimum","['geometry', 'trigonometry']"
787855,Differentiating $\left[\frac{\mathrm{d}^{n}}{\mathrm{d}x^{n}}(x^{2}-1)^{n}\right]^{2}$ [closed],Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question Given that $$\frac{\mathrm{d}^{2n}}{\mathrm{d}x^{2n}}(x^{2}-1)^{n} = (2n)!$$ How can we find $$\left[\frac{\mathrm{d}^{n}}{\mathrm{d}x^{n}}(x^{2}-1)^{n}\right]^{2}\quad ?$$,['derivatives']
787872,Proving that a function is a contraction map,"I have a function defined by:
$F(X) = a \left( \frac{X-A}{\|X-A\|_2} - \frac{B-X}{\|B-X\|_2} \right)  $ with $X,A,B \in \mathbb{R}^3 $ $a\in \mathbb{R}_+ $. Is this a contraction map? If yes I want to prove it. I tried $\|F(Y) - F(X)\|\le\alpha\|Y-X\| $ with  $ 0 \le \alpha < 1$ numerically thousands of times with random $X,Y$ and the disequality is always satisfied. 
Any suggestion ??","['convergence-divergence', 'functions']"
787909,block matrix multiplication,"If $A,B$ are $2 \times 2$ matrices of real or complex numbers, then $$AB = \left[
\begin{array}{cc} a_{11} & a_{12} \\ a_{21} & a_{22} \end{array} \right]\cdot
\left[
\begin{array}{cc} b_{11} & b_{12} \\ b_{21} & b_{22} \end{array} \right]
= 
\left[
\begin{array}{cc} a_{11}b_{11}+a_{12}b_{21} & a_{11}b_{12}+a_{12}b_{22} \\ a_{21}b_{11}+a_{22}b_{21} & a_{22}b_{12}+a_{22}b_{22} \end{array} \right]
$$ What if the entries $a_{ij}, b_{ij}$ are themselves $2 \times 2$ matrices?  Does matrix multiplication hold in some sort of ""block"" form ? $$AB = \left[
\begin{array}{c|c} A_{11} & A_{12} \\\hline A_{21} & A_{22} \end{array} \right]\cdot
\left[
\begin{array}{c|c} B_{11} & B_{12} \\\hline B_{21} & B_{22} \end{array} \right]
= 
\left[
\begin{array}{c|c} A_{11}B_{11}+A_{12}B_{21} & A_{11}B_{12}+A_{12}B_{22} \\\hline A_{21}B_{11}+A_{22}B_{21} & A_{22}B_{12}+A_{22}B_{22} \end{array} \right]
$$
This identity would be very useful in my research.","['numerical-linear-algebra', 'matrices', 'linear-algebra']"
787911,Finding 1000th 5-smooth number,"Smooth numbers are natural numbers that are products of only small prime numbers. They have some applications in cryptography. A number is 5-smooth if its only prime factors are $2,3$ or $5$. Example: $$1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, \dots$$ Interesting thing is that as they become larger and larger, they are sparser and sparser, with respect to all natural numbers... I have 2 problems I am struggling with: 1. Find an algorithm for finding $n$-th 5-smooth number. (if possible, in less than $\mathcal{O}(n)$) 2. What is 1000th 5-smooth number? Appreciate any idea and/or insight.","['sequences-and-series', 'algorithms', 'number-theory']"
787936,A group theoretical game: Is it possible to reach a state when only blue marbles are left?,"I've found this problem in a math contest. Apparently it's solved by group theory but I have no idea how. We're playing a game with a set of red and blue marbles arranged in a line. Here are the rules of the game: A blue marble can jump over two red marbles and kills one of the two. A marble (blue or red) can jump over three adjacent red marbles and kills the three. A marble (blue or red) can jump over two adjacent blue marbles and kills both. Suppose that at the initial state we have $2007$ blue marbles, $2008$ red marbles and again $2007$ blue marbles arranged in a line. Is it possible to reach a state when only blue marbles are left?","['group-theory', 'contest-math']"
787939,Show that the least squares estimator of the slope is an unbiased estimator of the `true' slope in the model. [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Under the assumptions of the classical simple linear regression model, show that the
least squares estimator of the slope is an unbiased estimator of the `true' slope in the model. Anyone have any ideas for the following questions?","['statistics', 'probability-distributions', 'economics', 'probability-theory']"
787971,Homeomorphic or Homotopic,"Q1: Are the Fig (a) and (b), the equivalence ""=""   is Homeomorphic or Homotopic? ps. for details of the figures see Ref here . I learned that ""The characterization of a homeomorphism often leads to confusion with the concept of homotopy, which is actually defined as a continuous deformation, but from one function to another, rather than one space to another. In the case of a homeomorphism, envisioning a continuous deformation is a mental tool for keeping track of which points on space X correspond to which points on Y—one just follows them as X deforms. In the case of homotopy, the continuous deformation from one map to the other is of the essence, and it is also less restrictive, since none of the maps involved need to be one-to-one or onto. Homotopy does lead to a relation on spaces: homotopy equivalence."" Q2: Does Homeomorphic necessary imply the Homotopic equivalence of space? So Homeomorphic is stronger restricted condition than Homotopic?","['geometric-topology', 'general-topology', 'algebraic-topology', 'differential-topology', 'homotopy-theory']"
787979,Evaluate $a+b+c+d$,"If $a$, $b$, $c$, and $d$ are distinct integers such that $$(x-a)(x-b)(x-c)(x-d)=4$$ has an integral root $r$, what is the value of $a+b+c+d$ in terms of $r$? I tried to analyze graphically by shifting the graph of $f(x)=(x-a)(x-b)(x-c)(x-d)$ four units downward but couldn't infer anything due to the random nature of $a$, $b$, $c$ and $d$.","['quadratics', 'algebra-precalculus', 'roots', 'polynomials']"
788016,"How prove this frog can finite steps jump the point $(\frac{1}{5},\frac{1}{17})$","A frog starts at $A(0,0)$ and jumps repeatedly, such that jump covers a distance of exactly $1$ , and  such each point jumped to has rational coordinates. Show that: (1): This frog can jump with finitely many jumps to the point $(\frac{1}{5},\frac{1}{17})$ (2): This frog can't jump with finitely many jumps to the point $(0,\dfrac{1}{4})$ I think this problem is interesting. And note $$1=\left(\frac{3}{5}\right)^2+\left(\frac{4}{5}\right)^2$$ so I want to first jump to $(\frac{3}{5},\frac{4}{5})$ , but then I don't know how to continue.","['analysis', 'combinatorics']"
788017,Superassociative operation,"Background : Addition and multiplication are associative, but exponentiation is not. Question : Does an operation $\circ_1:\mathbb{N}\times\mathbb{N}\to\mathbb{N}$ exist such that $$\circ_i(x,y)=\underset{y\text{ times}}{\underbrace{x\circ_{i-1}x\circ_{i-1}\cdots\circ_{i-1}x}}$$ is associative, that is $x\circ_i(y\circ_i z)=(x\circ_i y)\circ_i z$, for all $i\in\mathbb{N}$? My own thoughts : Perhaps this question is closely related to groups, but I'm not sure about that. Maybe $\forall i\in\mathbb{N}$ is not possible, but $\forall i\in\{1,2,\cdots, N\}$ is, I actually don't know any operation for which the above requirement holds for $i$ larger than $2$ (which is exactely the dull operation called addition).","['associativity', 'hyperoperation', 'group-theory']"
788034,"Integrating $\int_0^1 \frac{\ln x}{x^x}\, dx.$","I am trying to integrate this.
$$
\int_0^1 \frac{\ln x}{x^x}\, dx.
$$ Thanks. I thought
$$
\int_0^1 \ln x \, x^{-x} \, dx=\int_0^1 \ln x\, e^{-x\ln x}\, dx=\sum_{n=0}^\infty\frac{(-1)^n}{n!}\int_0^1 x^n \ln x (\ln x)^n\, dx=\\\sum_{n=0}^\infty\frac{(-1)^n}{n!}\int_0^1 x^n (\ln x)^{n+1}\,dx
$$
but now I am confused because I cannot solve this integral.  I do know that
$$
\int_0^1 x^{-x}\, dx= \sum_{n=1}^\infty n^{-n}.
$$","['definite-integrals', 'calculus', 'integration']"
788041,Which is the relationship between weak convergence and pointwise convergence?,In one of my indipendent works at functional analysis course have to come up with an explicit way of telling which is the relationshpip between weak and pointwise convergence for $C(K)$ where $K$ is a compact Hausdorff space. I searched some articles but didn't find anything which is enough helpfull. The theory behind is kind of complicated and I don't think I have the necessary background to understand it. Can somebody guide me to get to the right point? Till now I have been working with Eberlein-Smulian theorem and weak compactness.,"['functional-analysis', 'banach-spaces']"
788048,Find $\lim_{x\rightarrow 1}\frac{\sin{(x^2-1)}}{x-1}$,My problem is to calculate $$\lim_{x\rightarrow 1}\frac{\sin{(x^2-1)}}{x-1}$$ I evaluated to $\frac{\sin(x+1)(x-1)}{x-1}$ and then to $\sin(x+1)$ but I wonder about the result of limit as x approach 1 of $\sin{(x+1)}$. I cannot think of any result I cannot connect to anything.,"['functions', 'limits']"
788063,Functions that cannot be differentiated in terms of elementary functions,"A while ago, I learned how to take the derivative of $y=x^x$ using implicit differentiation, and I wondered if the same trick would work on every function of this type. I tried to differentiate $y=x^{x^x}$ the same way: $\ln y=x^x\ln x$ $\ln (\ln y)=x \ln x+\ln (\ln x)$ $\frac{\frac{dy}{dx}}{y\ln y}=1+\ln x+\frac{1}{x\ln x}$ $\frac{dy}{dx}=x^{x^x+x}\ln x(1+\ln x+\frac{1}{x\ln x})$ This result seems to imply that all functions of this type, no matter how complicated, could be differentiated in this manner. My question is: Are there any functions of this sort that are so complicated that they are impossible to differentiate? If not, can this be proven?","['implicit-differentiation', 'calculus', 'derivatives']"
788064,Difference of concave functions,"Suppose that there are two concave functions $f_1(x)$ and $f_2(x)$ defined on $x\geq0$. In addition, the functions are  positive, smooth, bounded ($|f_2|\leq b_2,|f_1|\leq b_1$ such that $b_2 = b_1<\infty$), monotone increasing and $f_1\geq f_2$ where $f_1(0)=f_2(0)=0$. I'm trying to be as much specific as I can because my question is a bit vague: Is there something general that can be said about the  difference $f_1-f_2$ without the further knowledge of the behavior of their derivatives? Namely, is there something to say about the number of local extrema or stationary points the difference can have? To elaborate: clearly, $f'_1(0)>f'_2(0)$ but for $x>0$ the derivative of $f_2$ can become greater than that of $f_1$ at least once. In that case there is  one stationary point. Can there be more? What changes if $b_2< b_1<\infty$ or if both functions are unbounded? Feel free to point me to books, web sites or lecture notes where the answers are. This is not a homework. EDIT: Loosely speaking, can a difference of two functions satisfying the assumptions above have many ($>1$) humps and dips? If yes provide an example or argument. What would the two functions have to satisfy for their difference to have just one stationary point (that is one function approaches the other, crosses it and departs)?","['convex-analysis', 'functions']"
788095,Is Calculus a requirement to become better at Probability and Satistics?,"Is Calculus really required to be better at Statistics and Probability and to be a good Data Scientist? Arthur Benjamin says in his TED video : ""Very few people actually use calculus in a conscious, meaningful way in their day-to-day lives.  On the other hand, statistics–that’s a subject that you could, and should, use on a daily basis.” “If it’s taught properly, it can be a lot of FUN. I mean, probability and statistics–it’s the mathematics of games and gambling, it’s…it’s analyzing trends, it’s predicting the future.”","['statistics', 'calculus']"
788096,How to prove that $\lim_{n \to\infty} \frac{(2n-1)!!}{(2n)!!}=0$,"So guys, how can I evaluate and prove that $$\lim_{n \to\infty} \frac{(2n-1)!!}{(2n)!!}=0.$$ Any ideas are welcomed. $n!!$ is the double factorial, as explained in this wolfram post.","['factorial', 'calculus', 'limits']"
788125,Prove: matrix A is diagonalizable iff exp(A) is diagonalizble,"I need to prove: matrix A is diagonalizable iff $\exp(A)$ is diagonalizble. exp means exponent function. I know to prove that if $A$ is diagonalizable so $\exp(A)$ is diagonalizable, but have a problem with the other side. can I write $P^{-1}.\exp(A).P=D$ (since $\exp(A)$ is diagonalizable  ) and operate log on both sides of the equation? if yes I'm done, or any other hints?","['matrices', 'exponentiation', 'linear-algebra']"
788168,Number of Fixed Points in a Map from the Torus to itself using Lefschetz Trace,"Let $f: X \to X$ be a continuous map.  For any fixed point $f(x) = x$ with $x \in X$, we can find the index of that fixed point $i(f,x)$.  The Lefschetz-Hopf formula says: $$ \sum_{x \in \mathrm{Fix}(f)} i(f,x) = \sum_{k \geq 0} (-1)^k \mathrm{Tr}(f_*|H_k(X,\mathbb{Q}))
 $$ I would like to understand the Lefschetz fixed point formula with an example. Let's try $X = S^1 \times S^1$ be a 2-dimensional torus and consider the linear map \begin{eqnarray*}
x &\mapsto& 3x - y\\
y &\mapsto& x + 3y
\end{eqnarray*} In the complex plane this would be $z \mapsto (3+i)z$.  Here both equations are taken mod 1.  One can compute the number of fixed points of this map to be $\mathbf{5} = (2+i)(2-i) $, since we solve $z = (3+i)z  \mod \mathbb{Z}[i]$ and get the number of lattice points inside the parallogram. How do we compute the traces on each of the elements of the homology? $H_0(S^1 \times S^1) = \mathbb{Q}$ $H_1(S^1 \times S^1) = \mathbb{Q}\oplus \mathbb{Q}$ $H_2(S^1 \times S^1) = \mathbb{Q}$ How do I get the induced action of $f$ on each of the homology groups and verify the traces?","['algebraic-topology', 'number-theory']"
788177,"""Duality"" for weak $L^p$ spaces","Let $1<p<\infty$. Denote by $L^{p,\infty}$ the weak $L^p$ space in $\mathbb{R}^n$ and let $f\in L^{p,\infty}$ where we define the weak $L^p$ quasinorm as $$\|f\|_{p,\infty} = \sup_{\lambda >0} \lambda\cdot m(\{ |f|>\lambda \})^{1/p}$$ where $m$ denotes the Lebesgue measure on $\mathbb{R}^n$. Question: Is it true that
  $$\|f\|_{p,\infty}= \sup_{E} |E|^{-1/p^\prime} |\langle f,1_E\rangle|$$
  where the supremum goes over all measurable sets $E$ of finite measure, $1_E$ denotes the characteristic function of $E$ and $\langle f,g\rangle=\int fg$ and $\frac{1}{p}+\frac{1}{p^\prime}=1$. I would already be very happy with ""$\le$"" and I also don't care if ""$\le$,$\ge$"" are maybe only true with additional multiplicative constants. To show ""$\le$"" I tried plugging in $E=\{|f|>\lambda\}$ for $\lambda>0$, but then I get $$|\langle f,1_E\rangle|=\left| \int_{\{|f|>\lambda\}} f \right|$$ The idea was to estimate this against $\lambda\cdot m(\{ |f|>\lambda\})$, but that doesn't work because the absolute value signs are outside instead of inside the integral. So I tried assuming that $f$ is positive, then its fine, but the application I have in mind needs $f$ complex-valued. Remark: The question is motivated by the fact that for (normal) $L^p$ spaces we have the duality statement $$\|f\|_p = \sup_{g\in L^{p^\prime}, g\not\equiv 0} \frac{|\langle f,g\rangle|}{\|g\|_{p^\prime}}$$","['measure-theory', 'functional-analysis', 'real-analysis']"
788208,The Levi-Civita connection in infinite dimensions,Is there an analogue of the Fundamental Theorem of Riemannian Geometry for (some subclass of) infinite-dimensional manifolds?,"['riemannian-geometry', 'functional-analysis', 'differential-geometry']"
788236,What does the inverted V represent in math,"I know that A V B represents Logical disjunction which means A OR B and the result of it is false only when both A and B are false . But I still didn't understand what an inverted V means as shown in the image below. I know that cij , ail and blj are cells in a matrix but I dont understand the meaning on the whole. Can someone please help.","['matrices', 'discrete-mathematics']"
788247,Riddle with Pi = 3,"This is a riddle someone posted on Google+, so please forgive it's triviality - I'm asking here because I just can't figure out what exactly is wrong, and it really bugs me ;) I think something is not right with the square root at the end, but I'm not sure. Here is the post and here the riddle - ""Find the mistake"": \begin{align*}
x&=(\pi+3)/2\newline
2x&=\pi+3\newline
2x(\pi-3)&=(\pi+3)(\pi-3)\newline
2\pi x-6x&=\pi^2-9\newline
9-6x&=\pi^2-2\pi x\newline
9-6x+x^2&=\pi^2-2\pi x+x^2\newline
(3-x)^2&=(\pi-x)^2\newline
3-x&=\pi-x\newline
\pi&=3\newline
\end{align*}","['algebra-precalculus', 'fake-proofs']"
788254,Error propagation of the median absolute deviation.,"I wonder if there is a way to estimate error propagation of the mad (=median absolute deviation) for the difference between two median distributions, similar to how you estimate error propagation for the standard deviation for the difference between two average distributions? I want to compare the difference between two average size distributions and the difference between two median size distributions for the same data set, and I would like to compare the uncertainties by putting the corresponding form of propagated errors as error bars on each plot. Is there some way to do this or some other way to represent the errors for the median difference distribution?","['statistics', 'median']"
788256,To what math branches are these assignments related to,"I have two different assignments: 1 Hailey was asked to hang seven paintings in a row on the wall. In how many different ways can she arrange them? The answer would be 7! 2 Calculate the amount of possibility's with 4 digits in base 3. The answer would be 4^3. to what math branches are these questions related? When do I know which question belongs to which of these math branch? I seem to be confused with why you need to use different methods to each of these assignments, when you're counting the amount of possible outcomes with both assignments. P.S. Can someone edit the tag appropiately? I don't know what tag this topic is supposed to be.","['discrete-mathematics', 'combinatorics']"
788301,Reinventing The Wheel - Part 1: The Riemann Integral [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question Preface The core of any notion of integral is some sort of weighted sum:
$$\sum b\mu(A)$$ Depending on wether the domain or range is decomposed these split into Riemann and Lebesgue type ones:
$$\{A_i\}_{I \in I}: b_i\in fA_i$$
$$\{b_i\}_{I \in I}:A_i=f^{-1}\{b_i\}$$ In order to handle kinds of infinite sums one can introduce a notion of convergence:
$$\lim_{\leq}$$
The crucial ingredient for uniqueness is a directed order together with a Hausdorff space:
$$\leq\text{ directed}\\
\mathcal{T}\text{ Hausdorff}$$
(For more details see Hausdorffness vs Uniqueness .) (Besides, these two first facts, namely summation and convergence, are the ones that weak notions of integral exploit.) For Lebesgue type ones the natural notion of convergence fails; that is plain summation gives:
$$f:[0,1]\to\mathbb{R}:f(x):=x:\quad\{\sum_{b\in B}b\mu(f^{-1}\{b\})\}_{\# B_0<\infty}=0\qquad B_0\leq B_0':\iff B_0\subseteq B_0'$$
For Riemann type ones this subtlety does not arise since it foots on collections of sets rather than elements. That will be the starting point of this article! Strategy & Goal The basic strategy of this article is to study a notion of integral of Riemann type under a suitable notion of convergence with: Hausdorff topological vector space: $V$ Measure space of possible infinite size: $\mu(\Omega)\leq\infty$ Integral of Riemann type: $I(f)=\lim_{\leq}\sum_{A\in\mathcal{A}}f(b)\mu(A)$ The primary goal will be to entail functions with poles and oscillations while retaining uniformly continuous functionsof the following form: Uniformly continuous: $I(f)\text{ exists}$ Poles: $f:(0,1]\to\mathbb{R}: f(x):=x^{\alpha>-1}$ Oscillation: $g:[1,\infty)\to\mathbb{R}: g(x):=\frac{1}{x}\sin(x)$ Definition Consider a sigma-finite complete measure space and a Banach space as well as Banach space valued functions:
$$(\Omega,\Sigma,\mu)\text{ and }(E,\|\cdot\|) \text{ and }(\mathcal{F},\ldots)$$ Define the integral if it exists by:
$$\int f\mathrm{d}\mu:=\lim_{(\Sigma_0,\leq)}\left\{\sum_{(A,a)\in\Sigma_0}\mu(A)f(a)\right\}_{\Sigma_0}$$
with the finite collections of disjoint measurable subsets of finite size:
$$\Sigma_0\subseteq\Sigma: \qquad \#\Sigma_0<\infty\text{ as well as }\mu(A)<\infty\text{ and }A\cap B=\varnothing\text{ for }A\neq B,A,B\in\Sigma_0$$
being ordered by refinement and expansion:
$$\Sigma_0\leq\Sigma_0':\iff\Sigma_0\dashv\Sigma_0',\Sigma_0\prec\Sigma_0'$$
where refinement and expansion are defined as: $$\Sigma_0\dashv\Sigma_0':\iff\forall A\in\Sigma_0\exists A'\in\Sigma_0':A\supseteq A'$$
$$\Sigma_0\prec\Sigma_0':\iff\cup_{A\in\Sigma_0}A\subseteq\cup_{A'\in\Sigma_0'}A'$$ In fact, these are considered as tagged collections but for better reading this is masked: $(A,a)\in\Sigma_0$ Note also that the collections are not required to actually cover the measure space: $\cup_{A\in\Sigma_0}A\subseteq\Omega$ The ordering of collections is chosen so to give the right result: $\int s\mathrm{d}\mu=\sum_{e\in \mathrm{im}s}\mu(s^{-1}\{e\})e$ Interpretation: This can be interpreted as the net of simple functions:
$$s_{\Sigma_0}:=\sum_{(A,a)\in\Sigma_0}f(a)\chi_A$$ Then the above read:
$$\int s_{\Sigma_0}\mathrm{d}\mu\to\int f\mathrm{d}\mu$$ Moreover for integrable functions the net of simple functions converges pointwise (proof?):
$$\left(\int s_{\Sigma_0}\mathrm{d}\mu \to \int f\mathrm{d}\mu\right) \Rightarrow \left(s_{\Sigma_0}(\omega)\to f(\omega)\right)$$
(Note that it is claimed pointwise convergence everywhere rather than almost everywhere.) So the question arises how this Riemann type integral relates to the Lebesgue type integral by Bochner. (The crucial difference is that this approach considers the net of simple functions related to the function under consideration while the approach by Bochner considers some sequence of simple functions not necessarily related to the function under consideration.) Discussion: It turns out that this notion of integrability is very restrictive. A necessary condition on integrability is:
$$\exists\mu(N)=0: \|f(\Omega\setminus N)\|<\infty$$ So though the first critical example won't be dissolved by this notion:
$$f:(0,1]\to\mathbb{R}:x\mapsto \frac{1}{\sqrt{x}}$$
the second will be dissolved however:
$$g:[1,\infty)\to\mathbb{R}:x\mapsto\frac{1}{x}\sin(x)$$ Especially no Lebesgue type integrability does imply this Riemann type integrability. However, a positive result is achieved on finite measure spaces. A sufficient condition on integrability is:
$$\ldots$$ Absolute integrability does not imply integrability (example?). Regarding convergence theorems the uniform convergence theorem holds (proof?) but the dominated, monotone and Fatou convergence theorem fail (example?). Summary: $$\ldots$$","['integration', 'banach-spaces', 'general-topology', 'lebesgue-integral', 'functional-analysis']"
788307,Examples of non-finitely presented groups,"I know several constructions leading to finitely generated non-finitely presented groups, using amalgamated products: Property : Let $A,B$ be two finitely presented groups. Then $A \underset{C}{\ast} B$ is finitely presented iff $C$ is finitely generated. using HNN extensions: Property : Let $A$ be a finitely presented group. Then $\underset{C}{\ast} A$ is finitely presented iff $C$ is finitely generated. or using wreath products (more difficult result): Property : Let $A,B$ be two finitely presented groups. Then $A \wr B$ is finitely presented iff $A$ is trivial or $B$ is finite. However, the only application that I know giving a ""nice"" group, that is a group with a simple description (not using a presentation of course), is the lamplighter group $L_2= \mathbb{Z}_2 \wr \mathbb{Z}$. Do you know other examples?","['examples-counterexamples', 'combinatorial-group-theory', 'group-theory', 'group-presentation']"
788312,Symmetric Matrices with trace zero,"Let $M_n$ denote the set of complex matrices of order $n$. It is well known that if $A\in M_n$ has trace zero then $A$ can be written as $A=BC-CB$, where $B,C\in M_n$. Is it true that every symmetric matrix $S\in M_n$ with trace zero can be written as $S=RR^t-R^tR$, for some $R\in M_n$? This theorem is true for real matrices. If $S$ is a real symmetric matrix with trace zero and order $n$ then exists a real matrix $R$ of order $n$ such that $S=RR^t-R^tR$. Is it true for complex matrices?","['trace', 'matrices', 'linear-algebra', 'symmetric-matrices']"
788327,Solving a 2nd order ODE with trigonometric coefficients,"How would one solve the following eigenvalue problem? $y'' + (\cot(x) - \tan(x)) y' = \lambda y$ for $\lambda$ an arbitrary constant, $x \in [0, \pi/2]$, and boundary conditions $y(0) = y(\pi/2) = 0$",['ordinary-differential-equations']
788332,How to prove the inequality $\det (AA^T) \ge 0$? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 6 months ago . Improve this question How to prove for any matrix $A \in \Bbb R^{n \times n}$ , that
the inequality $\det(AA^T) \ge 0$ is true?","['matrices', 'linear-algebra', 'determinant']"
