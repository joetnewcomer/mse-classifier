question_id,title,body,tags
1744556,The Marginal Distribution of a Multinomial,"The binomial distribution is generalized by the multinomial distribution, which follows: \begin{align}
f(x_1,\ldots,x_k;n,p_1,\ldots,p_k) & {} = \Pr(X_1 = x_1\mbox{ and }\dots\mbox{ and }X_k = x_k) \\  \\
& {} = \begin{cases} { \displaystyle {n! \over x_1!\cdots x_k!}p_1^{x_1}\cdots p_k^{x_k}}, \quad &
\mbox{when } \sum_{i=1}^k x_i=n \\  \\
0 & \mbox{otherwise,} \end{cases}
\end{align} In particular, the ""three""nomial distribution follows: $${n! \over x_1! x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}p_3^{n-x_1-x_2}$$ I am not able to show why the marginal probability of this distribution, with respect to either $x_1$ or $x_2$ follows $b(n, p_1)$ or $b(n, p_2)$, respectively. Please help!","['probability', 'probability-distributions']"
1744567,Basis of a Cyclotomic Field,"I've started learning algebraic number theory when I found something that confused me; for a prime $p$, where $\zeta=e^{(2\pi i/p)}$, a primitive $p$-th root of unity. Then the extension $\mathbb{Q}[\zeta]$ has basis $\{1,\zeta,\zeta^2...\zeta^{p-2}\}$. Could someone explain why the basis doesn't contain all $p$ roots? And was the choice of not including $\zeta^{p-1}$ arbitrary, or did it have to be that root in particular? I suppose it's naive of me, but it seemed intuitive that the basis would need all roots.","['number-theory', 'abstract-algebra', 'algebraic-number-theory']"
1744609,Finding the coefficient of expansion,"Question: Find the coefficient of $x^{11}$ in the expansion of:$$(1+x^2)^4(1+x^3)^7(1+x^4)^{12}$$ The traditional way of doing this, as far as I know, is to first find the coefficient of each term that has $x^{11}$, and then sum it. However, with three individual terms in multiplication, this would be a very tedious job. Is there a shorter way to approach such problems?","['algebra-precalculus', 'binomial-theorem', 'binomial-coefficients']"
1744623,Prove the identity $\sum_{r=0}^n r^2 \binom {n}{r} p^r q^{n-r}=npq+n^2p^2$ when $p+q = 1$,"If $p+q=1$, then show that $$\sum_{r=0}^n r^2 \binom {n}{r} p^r q^{n-r}=npq+n^2p^2.$$ I was able to solve this by differentiating the expression twice and then relating the given variables.
But the method turned out to be pretty tedious, moreover it took me a while to figure it out. Is there any method I can employ to solve this?","['derivatives', 'combinatorics', 'summation']"
1744633,Examples of complex-variable functions that fail to have a limit at some point,"My notes from class have the example $\frac{\overline{z}}{z}$ as z tends to zero.  That the limit does not exist is shown by exhibiting that along the $x$-axis the limit is $1$ and along the $y$-axis it is $-1$.  Also our homework set for the section has only two limit problems.  Can someone please post some examples?  I'm looking for more examples to get comfortable with this idea but when I search online I keep running into this same example. Also, is there a way to tell ahead of time that a complex function will not have a limit?","['complex-numbers', 'limits', 'functions', 'complex-analysis', 'analysis']"
1744717,Quotient map that is not closed,"Can anyone help me find some example of a closed relation $\sim$ on a Hausdorff space $X$ such that the quotient map $p:Xâ†’X/\sim$ is not a closed map? Here an equivalence relation $\sim$ is closed if the set $\{(x,y):x \sim y \}$ is closed.","['examples-counterexamples', 'closed-map', 'algebraic-topology', 'general-topology', 'quotient-spaces']"
1744731,Finding the inverse of linear transformation using matrix,"Assuming I have a linear transformation represented by a matrix with respect to some random bases, how could I find the inverse of the transformation using the matrix representation? I know I should find the inverse matrix but from there on, I have no clue what to do. Thanks in advance!","['matrices', 'linear-algebra', 'linear-transformations', 'inverse']"
1744733,Hypersurfaces have no embedded points (Vakil 5.5.I),"Here's a question from Vakil's FOAG. If $f\in k[x_1,\ldots,x_n]$ is non-zero, show that $A:=k[x_1,\ldots,x_n]/(f)$ has no embedded points. Hint: suppose $\bar{g}\in A$ is a zero-divisor, and choose a lift $g\in k[x_1,\ldots,x_n]$ of $\bar{g}$. Show that $g$ has a common factor with $f$. The hint is easily proven: if $\bar{g}\bar{h} = 0$ with $\bar{h}\neq 0$ in $A$, then $gh\in (f)$ in $k[x_1,\ldots,x_n]$ for some lift $h$ of $\bar{h}$. $h\notin (f)$ since $\bar{h}\neq 0$, so $g$ has a common factor with $f$ since $k[x_1,\ldots,x_n]$ is a UFD. Unfortunately, I do not see how the hint is related to embedded points. Presumably it has something to do with the following property of associated primes which is assumed to be true: (C) An element $f$ of a Noetherian ring $A$ is a zero-divisor of the finitely generated $A$-module $M$ (i.e., there exists $m \neq 0$ with $fm = 0$) if and only if it vanishes at some associated point of $M$ (i.e., is contained in some associated prime of $M$). I feel like I'm missing something obvious here. Could someone help me out please? Note that Vakil is adopting a geometric approach here: associated points are defined to be the generic points of irreducible components of the support of some element, and primary decomposition has not been developed, so it would be great if an answer could be given from this geometric perspective.",['algebraic-geometry']
1744753,Pure states on $C(X)$ are exactly evaluations,"Let $X$ be a compact Hausdorff space. I want to show that pure states are of the form $ \phi (f) =f(x)$. By Reisz Represenation Theorem states on $C(X)$ are of the form $\phi (f)= \int fd\mu$ where $\mu$ is a probability regular borel measure. I'm also familiar with the equivalent defenition: $\phi$ is pure iff for every positive functional $\psi$ satisfying $\psi \le \phi$ there exists $t \in [0,1]$ s.t. $\psi = t \phi$. $\Rightarrow$Suppose $\phi$ is an evaluation and show it's pure: write $\phi = t \psi_1 + (1-t) \psi_2$ for $t \in [0,1]$, and $\psi_1, \psi_2 \in S(A)$  so $\forall f\in C(X)$ we have $f(x)=\phi(f) = t \psi_1(f) + (1-t) \psi_2(f)=t\int fd\mu_1+ (1-t)\int fd\mu_2$ for some $\mu_1, \mu_2$ borel, regular probability measures. If I could take $f=\chi_{\{x\}}$ I think I can finish the argument. Maybe I should approximate this indicator by continuous functions in $L^1$, but I'm not sure it's the right direction. For the second direction I have nothing to present... I would like to get some hints. Thank you.","['representation-theory', 'c-star-algebras', 'measure-theory']"
1744760,Scalar multiplication as a special form of matrix multiplication,"Question What do we gain or lose, conceptually, if we consider scalar multiplication as a special form of matrix multiplication ? Background The question bothers me since I have been reading about dilations and scaling of geometrical objects in Paul Lockhart's book ""Measurement"". Geometrically, dilation is a transformation that stretches an object in one dimension by a certain factor. Analogously, the linear transformation
$$
\begin{pmatrix}
  1 & 0 & 0 \\
  0 & 1 & 0 \\
  0 & 0 & \lambda
\end{pmatrix}
\cdot
\begin{pmatrix}
  x_1 \\
  x_2 \\
  x_3
\end{pmatrix}
$$
""stretches"" the third component by the factor $\lambda$. Scaling is a geometric transformation that stretches an object in all dimensions by a certain factor. Analogously, the linear transformation
$$
\begin{pmatrix}
  \lambda & 0 & 0 \\
  0 & \lambda & 0 \\
  0 & 0 & \lambda
\end{pmatrix}
\cdot
\begin{pmatrix}
  x_1 \\
  x_2 \\
  x_3
\end{pmatrix}
$$
""stretches"" all three components by the factor $\lambda$. This, however, can be written more succinctly using scalar multiplication:
$$
\lambda
\cdot
\begin{pmatrix}
  x_1 \\
  x_2 \\
  x_3
\end{pmatrix}.
$$
In fact, every scalar multiplication can be expressed as a multiplication with a special matrix, and it turns out to be a mere shortcut. On the face of it, this observation is not very spectacular; however, it raises interesting philosophical and conceptual questions as to the foundations of linear algebra. For example, if scalar multiplication is only a nice-to-have shortcut, then isn't it in fact superfluous conceptually? Currently, scalar multiplication is taught as if it was a distinct concept, independent of matrix multiplication. What would change if we got rid of this shortcut? What could alternative axioms of vector spaces and moduls look like? What about linear transformations? What is easier, what is harder$-$not to write down, but conceptually? I know that this topic is very broad, but I would like to collect opinions, ideas, examples.","['linear-algebra', 'soft-question', 'philosophy']"
1744832,Find the Matrix $A^{482}$ in terms of $A$,"Given $$A=\begin{bmatrix}
-4 & 3\\ 
-7 & 5
\end{bmatrix}$$ Find $A^{482}$ in terms of $A$ I tried using Characteristic equation of $A$ which is $$|\lambda I-A|=0$$ which gives $$A^2=A-I$$ so $$A^4=A^2A^2=(A-I)^2=A^2-2A+I=-A$$ so $$A^4=-A$$ but $482$ is neither multiple of $4$ nor Power of $2$, How can I proceed ?","['matrices', 'eigenvalues-eigenvectors']"
1744851,Why doesn't this definition of natural numbers hold up in axiomatic set theory?,"I was reading about older definitions of the natural numbers on Wikipedia here (in retrospect, not the best place to learn mathematics) and came across the following definition for the natural numbers: (paraphrased) Let $\sigma$ be a function such that for every set $A$, $\sigma(A) := \{ x \cup \{ y \} \mid x \in A \wedge y \notin x \} $. Then $\sigma(A)$ is the set obtained by adding any new element to all elements of $A$. Then define $0 := \{ \emptyset \}$, $1 := \sigma(0)$, $2 := \sigma(1)$ et cetera. The way I understood this definition is that the natural number $n$ is ""defined"" as the set of all sets with exactly $n$ elements. This sounded straightforward to me, until I read the next paragraph: This definition works in naive set theory, type theory, and in set theories that grew out of type theory, such as New Foundations and related systems. But it does not work in the axiomatic set theory ZFC and related systems, because in such systems the equivalence classes under equinumerosity are ""too large"" to be sets. For that matter, there is no universal set V in ZFC, under pain of the Russell paradox. Why exactly doesn't this definition work in ZFC? I don't fully understand how the sets in this definition are ""too large"". Is part of the problem just that there is no ""universal set"" to pick the element $y$ from? I tried to do some more reading to find my answer, but the material was way out of my depth. (I am only familiar with the basics of set theory, Russell Paradox, Cantor diagonal argument, and not much more. ) So I apologize in advance if this is a really simple question...","['foundations', 'elementary-set-theory']"
1744858,Is $53\cdot 83\cdot109+40\cdot66\cdot96$ prime or composite?,"Let $$A=53\cdot 83\cdot109+40\cdot66\cdot96$$
  Is this number prime or composite? I'm sure it's a composite number. But I do not know how to prove it.","['number-theory', 'calculus']"
1744950,Is there a binary operation satisfying these conditions?,"Last night I started to read some book that has to do with applications of groups in physics and the question came in my mind about the existence of some structure, which I define in this way: Suppose that we have set $S$ which has at least countably infinite number of elements which is equipped with the binary operation $*$ and that we have: 1) $\forall x,y \in S$ we have $x*y \in S$ 2) There exist one and only one $e \in S$ such that we have $x*e=e*x=x$, for every $x \in S$. 3) For every $x \in S$ there exist $l \in S$ and $r \in S$ such that we have $l*x=e$ and $x*r=e$ and $l \neq r$. So this structure is similar to the group in that that it satisfies closure axiom and it has unique identity element but it is different from group in that that every element has left and right inverse which do not coincide and we do not assume associativity. Since I know that there are a lot of structures in mathematics if this structure exists it is probably not something new, but I do not know. And now the question: Does structure defined in this way exist?",['abstract-algebra']
1744958,Do similar matrices have equal singular values?,"Is it true that if $A$ and $B$ are similar matrices, $B=S^{-1}AS$, then $A$ and $B$ have the same singular values?","['matrices', 'svd', 'linear-algebra']"
1745005,Set Representation of $\bigcap\limits_{A\subseteq C}C$,"Let $G$ be a group and $\emptyset\neq A\subseteq G$. Let 
$M(A)=\bigcap_{A\subseteq C}C$ where $C$ is any subset of $G$ such that $c^k\in C$ for all $c\in C$ and $k\in\mathbb N\cup\{0\}$ and if there is $g\in G$ such that 
$g^k=\prod_{i=1}^mc_i^{k_i}$ and $k=\sum_{i=1}^mk_i$ 
for $c_i\in C$ and $k_i\in\mathbb N$, then $g\in C$. How to prove that
$$M(A)=\left\{g\in G:g^n=\prod_{i=1}^ma_i^{n_i},a_i\in A,n_i\in\mathbb N\cup\{0\},n\in\mathbb N\right\}?\tag{*}$$ Also I proved that the equality in $(*)$ holds, if we redefine $M(A)$ by adding a third condition to $C$, namely, if there is $k\in\mathbb N$ and $g\in G$ such that $g^k\in C$ then $g\in C$.","['modules', 'abstract-algebra', 'group-theory', 'ring-theory', 'field-theory']"
1745045,Is this a Schwartz function?,"I would like to know whether this function $f : \mathbb{R} \rightarrow \mathbb{R}$ 
$$f(x):=\frac{1}{\sum_{k=0}^{\infty} \frac{x^{2k}}{(k!)^2}}$$ is a Schwartz function? By applying the chain-rule it is clear that $f \in C^{\infty}(\mathbb{R})$ and more or less obviously we have that $|x^a f(x)| \rightarrow 0$  for $x \rightarrow \pm \infty$. But what about derivatives? How can I show that $|x^{a} f^{(\beta)} (x)| \rightarrow 0$ for $x \rightarrow \pm \infty$ or is this false? If anything is unclear, please let me know.","['real-analysis', 'partial-differential-equations', 'calculus', 'functional-analysis', 'analysis']"
1745070,Understanding Operator Norm of Matrices,"Let $X$ denote the vector space of $n\times n$ complex matrices. To every matrix $A\in X$ one can associate two operator norms: Thinking of $A$ as a map $A\colon \mathbb{C}^n\to \mathbb{C}^n$ or $A\in L(\mathbb{C}^n)$ in short, we define $\|A\|_{L(\mathbb{C}^n)}=\sup_{v\in \mathbb{C}^n, \|v\|=1}{\|Av\|}$. Thinking of $A$ as a map $A\colon X\to X$ or $A\in L(X)$ in short, we define $\|A\|_{L(X)}=\sup_{B\in X, \|B\|_{L(\mathbb{C}^n)}=1}{\|AB\|}$. It is well-known that $\|A\|_{L(\mathbb{C}^n)}=s_1(A)$ where $s_1$ is the largest singular value of $A$. My questions are: Is there is a (spectral?) characterization of $\|A\|_{L(X)}$? or perhaps a relation between the two above norms? Is there any application of the second norm (in, say functional analysis)? I will explain below why I started thinking about this norm in the first place. I was trying to understand the following paragraph that lead to my questions above. ""If $X$ is equipped with the operator norm $\|\cdot\|_{L(\mathbb{C}^n)}$, then its dual space $X^*$ is the space $X$ equipped with the trace norm $\|\cdot\|_1=\text{ sum of singular values}$, and vice versa."" I still don't see why (3) has to be true, but if necessary, and if it turns out to be irrelevant to the other two questions, I can ask it in a separate question. Any help is appreciated.","['functional-analysis', 'c-star-algebras', 'linear-algebra', 'operator-theory']"
1745083,What is the optimal path between $2$ fixed points around an invisible obstructing wall?,"Every day you walk from point A to point B, which are $3$ miles apart. There is a $50$% chance each walk that there is an invisible wall somewhere strictly between the two points (never at A or B). The wall extends $1$ mile in each direction perpendicular to the line segment (direct path) between A and B, and its position can be at any random location between the two points. That is, it can be any distance between A and B such as $0.1$ miles away from A, $1.5$ miles away, $2.9$ miles away.... You don't know if the wall is present or where it is until you walk into it.  You must walk around the wall if present as there is no other way to circumvent it.  Assume the wall is negligible thickness (like a force field), all ground is perfectly flat, and the y coordinates at both A and B are $0$ (although I don't think the optimal path will change much if they weren't). What strategy minimizes the average expected walk distance between A and B?  How do we know for certain this strategy yields the shortest average walking distance? To get the $100$ bounty points, I would like a convincing argument from you as to why you feel your solution is optimal and cannot be beaten.  For those of you using computer simulation, anything reasonably close to optimal is a candidate for the bounty. Can anyone beat the optimal solutions submitted so far?  There are still a few days to try.  Even a slight beat (if not due to roundoff error or some other error) would help prove previous solutions are non-optimal.  You can just use the table of $31$ points (x-y coordinates) and compute that path length and then if you can find better then I will accept that answer.  I think by Sunday night I may have to award the bounty otherwise it may get auto-awarded.","['graph-theory', 'simulation', 'ordinary-differential-equations', 'optimization']"
1745101,Least Squares with Singular $AA^T$,"Given the following system, find all least squares solutions:
$\begin{bmatrix}1 & 2 & 3\\2 & 3 & 4\\3 & 4 & 5\end{bmatrix}  \vec{x} = \begin{bmatrix}1\\1\\2\end{bmatrix}$
However, after trying to minimize residuals with:
$\vec{x} = (A^TA)^{-1}A^T\begin{bmatrix}1\\1\\2\end{bmatrix}$
I found that $det(AA^T)$ is singular... I think this means that their exist infinitely many least squares solutions to the system, but I don't know how to go about describing them all. I am relatively new to linear algebra (Uni level into class at the moment) so any help/explanation would be great!","['statistics', 'linear-algebra', 'least-squares']"
1745114,Show the operator $T$ is bounded if and only if $\sup|\lambda_j| < \infty$,"Let $(\lambda_n)$ be a sequence of non-zero scalers and let $D(T)= \{x=(\epsilon_j) \in l^2 : \sum^\infty_{j=1} |\lambda _j |^2 |\epsilon _j |^2 <\infty \}$ We define a linear operator $D(T) \to Ran(T)$,  $D(T) \in l^2$ and $Ran(T) \in l^2$ , as $$Tx= T(\epsilon_j)^\infty_1=(\lambda _j \epsilon _j)^\infty _1$$ where $x=(\epsilon_j) \in D(T)$ I am trying to show that $T$ is bounded if and only if $\sup|\lambda_j| \leq \infty$ This is the proof I have:
For any $x \in l^2$ we have 
$||Tx||^2 = \sum_{j} |\lambda _j | |\epsilon_j|^2 \leq (\sup_{j} |\lambda_j|)^2 ||x||^2 $ So $$||T|| \leq \sup_j |\lambda_j|$$ I understand the above but I dont understand the remaining proof below. 
In the other direction $||T || \geq \sup_j ||Te_j|| = \sup _j |\lambda _j |$ Where does this last bit come from? What is $e_j$? and why do we require it?",['functional-analysis']
1745174,Convolution of two gaussian functions,"I want to calculate the convolution $F * G$ of two Gaussian functions without resorting to Fouritertransforms: $F(t) := \exp(-at^2), G(t) := \exp(-bt^2) \qquad a,b>0$ But intuitively I expected the convolution to result again in a non constant function. Can anyone find my mistake / confirm that this calculation is correct? Let $\Omega = \mathbb R$, then $\begin{align*} (F*G)(x) &= \int_\Omega F(t)G(x-t)dt &\\
& = \int_\Omega e^{-at^2-b(x-t)^2} dt \qquad\qquad \quad  \text{substitute }u = t+\frac{1}{2} x \implies ""du=dt"" \\
&=\int_\Omega e^{-a(u-\frac{1}{2}x)^2-b(\frac{1}{2}x-u)^2}dt \qquad \text{substitute }v = u-\frac{1}{2} x \implies ""du=dv""\\
&=\int_\Omega e^{-(a+b)v^2} dv \qquad\qquad \qquad\,\, \text{substitute } w = \sqrt{a+b}v \implies""dw = \sqrt{a+b}dv"" \\
&=\frac{1}{\sqrt{a+b}}\int_\Omega e^{-w^2}dw \\
&=\frac{\sqrt{\pi}}{\sqrt{a+b}}
\end{align*}$","['real-analysis', 'convolution', 'analysis', 'probability-distributions']"
1745249,Permutations of $S_7$,"Find all permutations $\alpha \in S_7$ such that $\alpha^3 = (1 2 3 4)$. My attempt:
We know that such an $\alpha$ must ""look like"" $(1432)$, since $(1432)^3=(1234)$. I think I need to find the elements that are conjugate to $(1432)$, so we seek $\alpha$ such that $$\sigma ^{-1} \alpha \sigma = (1432) \implies \alpha = (1\sigma 4\sigma 3\sigma 2\sigma).$$ This seems to me like it means that all permutations of $(1234)$ are fair game because there exists some $\sigma$ that permutes them into $(1432)$. Is this wishful thinking?","['permutations', 'group-theory', 'symmetric-groups']"
1745262,"Can a figure 8 be an orbit of $dx /dt =f(x,y)$, $dy/ dt =g(x,y)$ where $f$ and $g$ have continuous partial derivatives with respect to $x$ and $y$?","Can a figure 8 ever be an orbit of \begin{align}
\frac{dx}{dt} & =f(x,y), \\[10pt]
\frac{dy}{dt} & =g(x,y)
\end{align}
where $f$ and $g$ have continuous partial derivatives with respect to $x$ and $y$?",['ordinary-differential-equations']
1745263,Cremona Transformation and isomorphism,"Let $P_1=(1:0:0),P_2=(0:1:0),P_3=(0:0:1) \in \mathbb{P}_2$ (over an algebraic closed field). Denote $U=\mathbb{P}^2 \setminus \{P_1,P_2,P_3 \}$ and consider the map $$
f:U \rightarrow \mathbb{P}^2, (a_0:a_1:a_2) \mapsto (a_1a_2:a_0a_2:a_0a_1)
$$ Let $\tilde{\mathbb{P}}^2$ be the bow up at $\{P_1,P_2,P_3 \}$. According to the Andreas Gathmann notes, there is an isomorphism $\tilde{f}:\tilde{\mathbb{P}}^2 \rightarrow \tilde{\mathbb{P}}^2$ that extends $f$. Can someone explain me, or give me a hint on how can we proove that?","['algebraic-geometry', 'blowup']"
1745315,Blow-up and resolving a singularity,"Given a variety $X=\{F:=x_0^3+t(x_1^3+x_2^3+x_3^3+x_4^3+1)=0\}\subset \mathbb{C}^6$, where $(x_0,...,x_4,t)$ are coordinates of $\mathbb{C}^6$. How to resolve the singularity by only blow-up smooth subvariety of $X$ that is contained in $\{x_0^3=0\}$? How many steps do we need for blow-ups, and what are the exceptional divisors for each step? Can we even use computers? :-)","['algebraic-geometry', 'commutative-algebra']"
1745330,For a given relation in $\mathbb{N}\times \mathbb{N}$ find the number of elements in it's equivalence class,"The whole problem goes like this: We define the relation $R$ in $\mathbb{N}\times \mathbb{N}$ in the following way: $(a,b)R(c,d)$ iff $a-d=c-b$ First find proof the it's a relation of equivalence (done). Then, and here i have a problem, for each $(a,b)$ belonging to $\mathbb{N}\times \mathbb{N}$ find the amount of elements in it's equivalence class. Any help will do. Thanks.","['relations', 'combinatorics', 'elementary-set-theory']"
1745350,Equation of a Riemann surface?,"Intuitively in complex analysis I know what a Riemann surface is. It is a surface such that at every point on it the value of a function $f(z)$ is single-valued. However, how would I go about finding the equation for such a surface, i.e. if I was to plot one what one I plot?","['riemann-surfaces', 'complex-analysis']"
1745355,Approximate spectral decomposition,"I am interested in effective and computations for finding approximate spectral decompositions in some suitable format. Namely, let $A: H \rightarrow H$ be a Hermitian operator on an $n-$dimensional Hilbert space $H$ with the spectrum $\{\lambda_1, \ldots \lambda_m\}, m \leq n$. Then, $A$ can be decomposed as: $$ A = \sum_{i=1}^{m}\lambda_i P_i,$$ where $P_i, i=1,\ldots m$ are orthogonal projections with $P_i, P_j = 0, i \neq j$ onto the eigenspaces $H_i = \ker \{ \lambda_i I - A \}$ such that: $$  H= \displaystyle \underset{i=1}{\overset{m}{\oplus}} H_i.$$ In an approximate format, the theorem can be stated as follows (p. 380): for any $\varepsilon > 0$, there exist projections $P_i, i=1, \ldots n$ with $P_i, P_j = 0, i \neq j$, and real numbers $\alpha_1, \ldots \alpha_n$ such that $\big|\big| A - \displaystyle \sum_{i=1}^{n} \alpha_i P_i \big|\big| \leq \varepsilon$. What about the approximate eigenspaces? A particular example is this article , but it addresses exact spectral decomposition at the cost of additional input (cardinality of spectrum).","['constructive-mathematics', 'functional-analysis', 'complex-analysis', 'computability', 'linear-algebra']"
1745437,If $f$ is entire and $\lim_\limits{z\to\infty} \frac{f(z)}{z} = 0$ show that $f$ is constant,"I'm learning Complex Analysis and need to verify my work to this problem since my textbook does not provide any solution: If $f$ is entire and $\lim_\limits{z\to\infty} \dfrac{f(z)}{z} = 0$ show that $f$ is constant. My work and thoughts: From the $\varepsilon$ â€” $\delta$ definition of the limit we have that  $$\forall{\varepsilon} > 0, \exists{n_0} \in \mathbb{N} : \forall{\left|z\right|} \geq n: \left| \frac{f(z)}{z} \right| < \varepsilon \iff \frac{\left| f(z) \right|}{\left| z \right|} < \varepsilon\iff \left| f(z) \right| < \varepsilon \left| z \right|.$$ Now let $C_R = \{z \in \mathbb{C} : \left| z \right| = R \}$. For every $\left| z \right| < R$, by Cauchy's integral formula for derivatives we have that $$ \left| f'(z) \right| = \frac{1}{2 \pi } \left| \int_{|\zeta|=R} \frac{f(\zeta)}{(\zeta - z)^2} \, d\zeta \right|= \frac{1}{2 \pi } \left| \int_{0}^{2\pi} \frac{f(\zeta)}{(\zeta - z)^2} \, \zeta'(t) dt \right| \le$$ $$\le \frac{1}{2\pi} \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} 2\pi R = \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} R.$$ Thus, letting $R \rightarrow \infty$ yields the desired result, that is  $$\left| f'(z) \right| \leq \lim_{R \to \infty} \frac{\varepsilon \left| z \right|}{(R - \left| z \right|)^2} R = 0 \implies f(z) = c \;\; \text{with} \; c \in \mathbb{C}.$$ Is my work correct? Are there parts of the proof that need improvements? I'm also looking for other (possibly quicker) solutions using the  ""big guns"" theorems. The only one I'm familiar with is Picard's little theorem but it doesn't apply here.","['cauchy-integral-formula', 'complex-analysis', 'proof-verification', 'complex-integration']"
1745469,What happens when we pick a Random sample?,"Let $(\Omega, \mathcal{F} , \mathbb{P})$ be a probability space and $X:\Omega \to \mathbb{R}$ be a random variable. When we simulate or pick a random sample of size $n$ from $X$, are we picking values $X (\omega_1), X (\omega_2), X (\omega_3), \dots, X (\omega_n)$ where each $\omega_i\in \Omega$, or are we picking values $X_1(\omega_1), X_2 (\omega_2), X_3(\omega_3), \dots, X_n (\omega_n)$ where the $X_i$s are iid random variables with the same distribution as $X$?","['probability-theory', 'statistics']"
1745483,Differentiation under integral sign?,"I am trying to understand the following argument given in a text book: Suppose $f \in L^1(\mathbb R^n)$ , consider the function $\hat{f}(\zeta)= \int_{\mathbb R^n} \exp(-2\pi i X.\zeta)f(X)dX$ . Suppose $x_j f(X) \in L^1(\mathbb R^n)$ for $1 \leq j \leq n$ then $$\delta_j (\hat{f}(\zeta))=-2\pi i \int_{\mathbb R^n} \exp(-2\pi i X.\zeta)x_j f(X)dX $$ where $\delta_j$ denote partial derivative w.r.t. $\zeta_j$ Why can we interchange differentiation and integration as is done in the above argument?","['multivariable-calculus', 'integral-transforms', 'measure-theory', 'fourier-transform']"
1745520,How do you create an alternating series with the sign being the same twice in a row?,"I am working on a Taylor series question and I have created a series which alternates however, it does so in doubles. in other words it follows the following pattern: $x$, $x$, $-x$, $-x$, $x$, $x$,... My goal is to write this series using summation notation. 
I know that to produce a normal alternative series I simply use $(-1)^n$. However, I've found this significantly harder to create in summation notation because any manipulation to the $(-1)^n$ part of the sum only moves the position where the alternating series starts. Any suggestions are appreciated! edit: please note that in my example, ""$x$"" is just an arbitrary function and each other $x$ does not equal the other $x$'s.","['power-series', 'taylor-expansion', 'sequences-and-series', 'calculus']"
1745544,"Proving continuity and monotonicity of $t\mapsto t^x, t>0$ with minimal assumptions.","I'm trying to prove that The function $t\mapsto t^x,\, x\in \Bbb R,\, t>0$ is continuous and monotonic. Suppose $+, \cdot\,:\Bbb R^2\to \Bbb R$ (addition and multiplication) have already been defined (via the standard dedekind cuts construction). If $a\in \Bbb Z$, we define $t^a=t^{a-1}\cdot t$, $t^{1}=t$. If $r=\frac a b\in \Bbb Q$, we define $t^r=\sup \{x: x^b<t^a\}$. If $x\in\Bbb R$, we define, for $t>1$, $t^x=\sup\{t^r: r<x, r\in\Bbb Q\}$.  And if $t<1$ we swap $\sup$ by $\inf$ in the previous definition. I want to avoid usage of the exponential function $e^x=\sum \frac {x^n}{n!}$, series and further concepts, as I want to build the foundation for those first.",['real-analysis']
1745569,Proof intersection is finite and non-empty,"Course: Analysis (1st year course). Question: If $A_3$ is a subset of $A_2$ and $A_2$ is a subset of $A_1$ and so on... are all finite, nonempty sets of real numbers, then the intersection $\bigcap_{n = 1}^{\infty} A_{n}$ is finite and non-empty. My shot: Proof by contradiction. Assume $\bigcap_{n = 1}^{\infty}A_n$ is empty. Let $x$ be part of $A_{1}$. Then $x \not \in A_{k}$ for some $k>1$, because otherwise $\bigcap_{n = 1}^{\infty} A_{n}$ is non-empty. From here I get stuck. EDIT: Somebody erroneously edited my message. The way of inclusion is opposite.","['real-analysis', 'examples-counterexamples', 'elementary-set-theory']"
1745570,Why is the Laplacian of $1/r$ a Dirac delta? [duplicate],"This question already has answers here : Dirac's delta in 3 dimensions: proof of $\nabla^2(\|\boldsymbol{x}-\boldsymbol{x}_0\|^{-1})=-4\pi\delta(\boldsymbol{x}-\boldsymbol{x}_0)$ (2 answers) Closed 8 years ago . How does one show that $\nabla^2 1/r$ (in spherical coords) is the Dirac delta function ? Intuitively, it would seem that the function undefined at the origin and I'm not able to construct a limiting argument that avoids this problem.","['functional-analysis', 'partial-differential-equations']"
1745574,Limits of integrals,"How would you show that if
$f : [0,1] \rightarrow \Bbb R$ is continuous, then $$\lim_{n\rightarrow \infty}\int_0^1\int_0^1 \cdots \int_0^1 f\left( \frac{x_1+x_2+\cdots+x_n}{n} \right)~dx_1~dx_2\cdots dx_n = f\left( \frac{1}{2} \right) $$ and $$\lim_{n\rightarrow \infty}\int_0^1\int_0^1 \cdots \int_0^1 f((x_1 x_2 \cdots x_n)^{\frac{1}{n}})~dx_1~dx_2\cdots dx_n = f\left(\frac{1}{e}\right) $$",['limits']
1745592,When does the equality $\mathrm{ht}\:\mathfrak{p}+\mathrm{coht}\:\mathfrak{p}=\dim R$ happen?,"In the context of Krull dimension, given any commutative ring $R$ and $\mathfrak{p}\subset R$ a prime ideal, we have (almost by definition)
$$
\mathrm{ht}\:\mathfrak{p}+\mathrm{coht}\:\mathfrak{p} \leq \dim R
$$
In the special circumstance of the coordinate ring of an (irreducible) affine variety, i.e. $R$ being a finitely generated $K$-algebra which is an integral domain we have the equality
$$
\mathrm{ht}\:\mathfrak{p}+\mathrm{coht}\:\mathfrak{p} = \dim R\quad (*)
$$ I was curious on when (which type of rings) this equality $(*)$ happens? By the way, does this equality/inequality have a name? First of all seems like we better assume $\dim R<\infty$ for preventing things to go haywire. 
Then if $\mathfrak{p}_0\subsetneq\cdots\subsetneq \mathfrak{p}_m=\mathfrak{p}$ is a chain the length of which is $\mathrm{ht} \: \mathfrak{p}$ and $\mathfrak{p}\subsetneq\cdots\subsetneq \mathfrak{p}_n=\mathfrak{m}$ a chain the length of which is $\mathrm{coht}\: \mathfrak{p}$, then defining $n$ as the length of the two chains combined:
$$n\leq  \mathrm{ht}\:\mathfrak{m}\leq \dim R.$$
So we have two inequalities we need to satisfy. The second inequality can be satisfied by assuming $R$ is equicodimensional , i.e. $\operatorname{ht}\mathfrak{m}=\dim R$ for any maximal ideal $\mathfrak m$. The first one is trickier. It is happening because it is possible to have another maximal chain of primes inside $\mathfrak{m}$ which doesn't pass through $\mathfrak{p}$ and its length is bigger than $n$. I know of one way to make this imposible (which may not be the most general condition): Fact : If $R$ is a equicodimensional Cohen-Macaulay ring then every maximal chain of prime ideals is of the same length $\dim R$. So what I have come up with is if $R$ is a equicodimensional CM-ring then the equality (*) holds (right?). How much further can one go in stating the most general condition for the onset of equality $(*)$? Is it even useful to go further?","['algebraic-geometry', 'krull-dimension', 'commutative-algebra', 'ring-theory', 'dimension-theory-algebra']"
1745608,general conditions for reverse poincare inequality,"I'd like to know when the reverse Poincare inequality is true: Given a bounded domain $\Omega$, and $f \in L^2(\Omega)$, under what conditions on $f$ (neglecting the trivial constant case) and/or $\Omega$ is it true that there is a constant $C(\Omega)$ such that $\|\nabla f\|_{L^2} \leq C \|f\|_{L^2}$? Thanks in advance.","['functional-analysis', 'real-analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
1745611,Giving a specific example of a positive sequence increasing to 1 and with its partial products having a positive limit,"In my real analysis class I was asked this which got me stick: Is there an example of a sequence of real positive numbers increasing to the limit 1 $ \{ a_n \}_{n=1}^{\infty} $ such that the partial products $ a_1 , a_1a_2,a_1a_2a_3,... $ converges to a positive limit? I thought about it and thought it might be true because I coud not disprove it generally but I cannot come up with an example. Woud someone please be able to provide an example if any? Thanks to all helpers.","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'limits']"
1745620,"Closed form for the area of a convex cyclic n-gon, given the set of edge lengths","Let's say we are given a set of positive reals, and we're told that these are the edges of a convex cyclic $n$-gon, and we must compute it's area. For $n = 3$ there is the famous Heron's formula: $$A = {1\over 4}\sqrt{4a^2b^2 - (a^2 + b^2 - c^2)^2}$$ For $n = 4$ there is Brahmagupta's formula: $$A = {1\over 4}\sqrt{(a^2 + b^2 + c^2 + d^2)^2 + 8abcd - 2(a^4 + b^4 + c^4 + d^4)}$$ Is there a generalization for arbitrary $n$? Does it even exist?","['area', 'polygons', 'geometry']"
1745628,"Show that $\mathbb{Q}(\sqrt{2}+\sqrt[3]{5})=\mathbb{Q}(\sqrt{2},\sqrt[3]{5})$","Show that $\mathbb{Q}(\sqrt{2}+\sqrt[3]{5})=\mathbb{Q}(\sqrt{2},\sqrt[3]{5})$ and find all $w\in \mathbb{Q}(\sqrt{2},\sqrt[3]{5})$ such that $\mathbb{Q}(w)=\mathbb{Q}(\sqrt{2},\sqrt[3]{5})$. It is clear that  $\mathbb{Q}(\sqrt{2}+\sqrt[3]{5}) \subseteq \mathbb{Q}(\sqrt{2},\sqrt[3]{5})$. But given any $x\in \mathbb{Q}(\sqrt{2},\sqrt[3]{5})$, how do I show that $x\in \mathbb{Q}(\sqrt{2}+\sqrt[3]{5})$? For the second question, is $w$ the associates of $\sqrt{2}+\sqrt[3]{5}$? How do I show that? Thanks!","['abstract-algebra', 'field-theory']"
1745645,"$p$-adics, elements of $\mathbb{Q}_5^\times/(\mathbb{Q}_5^\times)^2$?","Here is a question surrounding the $p$-adics. I am curious as to what the description of the quotient group $\mathbb{Q}_5^\times/(\mathbb{Q}_5^\times)^2$ is, i.e. what are its elements? Here is an idea. I know that there is an isomorphism of groups $\mathbb{Q}_p^\times/\mathbb{Z}_p^\times = \mathbb{Z}$ which sends the class of $p^n$ ($n \in \mathbb{Z}$) to $n$, if that helps.","['number-theory', 'abstract-algebra', 'elementary-number-theory']"
1745649,"If a polynomial ring is a free module over some subring, is that subring itself a polynomial ring?","Suppose I have a graded polynomial ring $k[x_1,\ldots,x_n]$ on homogeneous generators, where $k$ is a field and the $x_i$ indeterminates, and further that I have a homogeneous graded subring $A$ such that $k[x_1,\ldots,x_n]$ is made a free $A$-module by the inclusion, $k[x_1,\ldots,x_n]$ is finite over $A$. It follows, as pointed out in comments, that then $A$ contains another polynomial ring on $n$ variables. I'd like this to imply $A$ is a polynomial ring too, but is it?","['polynomials', 'abstract-algebra', 'ring-theory', 'free-modules', 'commutative-algebra']"
1745650,Sum of a step function,"Please help me to find the following summation
$$\sum_{m=0}^{N} \sum_{n=0}^N \sum_{i=0}^N \sum_{j=0}^N \mathbb{1}(m,n,i,j)$$
where
$1(m,n,i,j)= \left\{ \begin{matrix} 1 \qquad m+n=i+j \\0 \qquad \; \; \; \;\; \textrm{otherwise} \end{matrix}\right.$ Thank you very much!","['multivariable-calculus', 'real-analysis', 'linear-algebra', 'calculus']"
1745659,What is the catch when introducing measure theory using $\sigma$-ring instead of $\sigma$-algebra?,"I am currently using Matthew A Pons book Real Anaysis for Undergrad for introduction of measure theory In my opinion this book is unbelievably clear for almost all the sections EXCEPT the section where measure is introduced. And the reason is because the author insists on using something called $\sigma$-ring for all the definitions, but litters the sections with ring and $\sigma$-algebra so in the problem section you will see that one question is with respect to $\sigma$-ring another is with respect to $\sigma$-algebra And you will see some quite convoluted parts like: Also let's ignore for the time being that almost all the books written post 2000s deals with $\sigma$-algebra. This book was published in 2014. So the main question is what is the catch when developing measure theory from the perspective of $\sigma$-ring instead of $\sigma$-algebra? I know that for a ring, the condition $A^c \in \mathcal{R}$ does not hold (not closed under complement). Can someone contrast the difference in the ways that key properties of the measure are derived (or proven) with respect to a $\sigma$-ring instead of a $\sigma$-algebra?","['lebesgue-measure', 'measure-theory', 'soft-question', 'definition']"
1745670,proof of upper bound on differential entropy of f(X),"I asked a similar question yesterday, 
but I organized my question here a little and further asked my second question. Suppose $X$ is a continuous random variable with the pdf $f_x$, and $Y=g(X)$.
If $g$ is a bijection, then via the change of variable method, 
the pdf of $Y$ is $f_y = f_x/|J|$, where $|J|$ is the Jacobian of $g$.
Therefore, $$h(Y)=h(X)+\int f_x \log |J| dx$$. From Wikipedia , if $dim(X)=dim(Y)$, there exists an upper bound on $h(Y)$ for a general map $g$: $$h(Y)\leq h(X)+\int f_x \log |J| dx \tag{1}$$ 
My first question is how to derive the inequality in Eq.(1).
Second, is there a general approach to derive $h(Y)$ or an upper bound on it if $dim(X)\neq dim(Y)$. I'd appreciate any help and suggestions!","['information-theory', 'entropy', 'probability']"
1745720,What is $\lim\limits_{n\to {\infty}} (\frac{n}{1+n})^n$? [duplicate],"This question already has answers here : Finding the limit of $\left(\frac{n}{n+1}\right)^n$ (9 answers) Closed 8 years ago . What is $\lim\limits_{n\to {\infty}} (\frac{n}{1+n})^n$. Is it possible to write the function $f(x)=x^n$ and since we know $\frac{n}{1+n}\to 1$, so $f(\frac{n}{1+n})\to 1^n=1$. So the limit it $1$. Is it correct. If so, is there an easier way to do it?","['limits', 'exponential-function', 'functions', 'calculus', 'sequences-and-series']"
1745722,Quotient of compact metric space is metrizable (when Hausdorff)?,"Apparently it's a standard result that, although not every (Hausdorff) quotient of a metric space is metrizable, it always is metrizable when the space being quotiented is compact.
Alas, I can't find a proof - neither in textbooks nor one of my own.
Can anyone give a hint,  or a reference (or a proof, of course)? Question 2: Is every quotient of a compact metric space (i.e. whether this quotient is Hausdorff or not) second-countable?","['general-topology', 'metric-spaces', 'compactness', 'quotient-spaces']"
1745800,Let $f(x)$ be an increasing function. Assume its image $f(C) $ is also a connected set. Prove that $f$ must be continuous,"Let $f: R â†’ R$  be an increasing function. Assume that for every connected subset $A$ of $R$, its image $f(A)$ is also a connected set. Prove that $f$ must be continuous. To prove this, I am thinking it will be best to prove the contrapositive. Assume $f$ is discontinuous. Then since $f$ is increasing, every discontinuity is a jump discontinuity, which would then disconnect the set $f(A)$. Since this is true, it must be true that the original statement is true. I am having trouble writing up a formal proof, but I think my idea is correct","['continuity', 'real-analysis', 'functions']"
1745810,"""There is no set containing everything""? [duplicate]","This question already has answers here : Why is ""the set of all sets"" a paradox, in layman's terms? (13 answers) Closed 8 years ago . I was reading this question regarding codomains, and I found something interesting in User134824's answer: ""On the other hand, owing to the set-theoretic fact that ""there is no set containing everything,"" it's not possible to pick a single universal codomain for functions."" Why is it impossible to have a set containing everything? Why can't we define $U=\mathbb{R} \cup \mathbb{C} \cup ....$(all possible sets)? P.S. This is a soft-question, so I am looking for intuitive, non-technical answers; I do not know any set theory","['soft-question', 'elementary-set-theory']"
1745832,Every normal topological space is Hausdorff,"It is stated in Kolmogorov & Fomin's Introductory Real Analysis that every normal space is Hausdorff.  I cannot seem to find an explanation for this anywhere, and don't see why this is obviously true... since it is not necessarily the case in an arbitrary topological space that a singleton is closed. Any help in understanding this would be appreciated!",['general-topology']
1745838,"Understanding an example of ""for all"" and ""for some"" usage in statements.","I'm reading ""Analysis I"" by Tao and reviewing an appendix chapter on logic. In there he gives an example on how ""for all x"" is usually much stronger than just saying ""for some x"": ""$6<2x<4$ for all $3<x<2$"" is vacuously true, but ""$6<2x<4$ for some $3<x<2$"" is false. I can see how the first statement is vacuously true: the hypothesis ""for all $3<x<2$"" is false as there is no $x$ that satisfies both $3<x$ and $x<2$, meaning the statement is true by default. But I don't see how the second statement works. I presume to say that statement 2 is false, one has to show that the implication (""$6<2x<4$"") is false when the hypothesis (""for some $3<x<2$"") is true. But is there a $x$ such that ""$3<x<2$"" is true? I'm obviously missing something here so clarification on this would be appreciated.","['inequality', 'logic', 'analysis']"
1745840,Testing whether the circumcenter of a cyclic quadrilateral lies inside it,"For a triangle with sides $a, b, c$ (where $c$ is the biggest side) there is a simple check to see whether it's circumcenter lies inside of it: $$a^2 + b^2 < c^2$$ Is there such an inequality for a cyclic quadrilateral, given its side lengths $a, b, c, d$ (with longest side $d$)? Can this be generalized to a cyclic convex $n$-gon?","['quadrilateral', 'geometry']"
1745841,Prove the intersection of events to be 1,"$B_n$, $n$ from $1$ to infinity is countably infinite sequence of events and each event has probability $1$. How do I formally prove that the probability of intersection of $B_n$ from $n = 1$ to infinity is also $1$. Intuitively I know because $P[B_i] = 1$, so all events are equivalent to the total sample space, and so does its intersection. But how to prove it in formal way?","['probability', 'elementary-set-theory']"
1745878,Using the principle of inclusion-exclusion determine the number of prime numbers not exceeding 100.,"Using the principle of inclusion-exclusion determine the number of prime numbers
not exceeding 100. How would you approach this problem?","['inclusion-exclusion', 'discrete-mathematics', 'elementary-number-theory']"
1745912,$\aleph_1$ almost sure events that almost never all hold,"This recent question sparked my curiosity. Is there a family of events $(E_k)_{k \in I}$ such that$\def\pp{\mathbb{P}}$ $\pp(E_k) = 1$ for any $k \in I$ but $\pp( \bigcap_{k \in I} E_k ) = 0$? Clearly any such family must be uncountable, and my intuition tells me that it exists, so I proceeded to try constructing one. Let $X \sim U([0,1])$, and let $E_r = ( X \ne r )$ for each $r \in [0,1]$. Then $\pp(E_r) = 1$ for any $r \in [0,1]$, but $\pp( \bigcap_{r \in [0,1]} E_r ) = 0$. So now my question is, is there a family of size $\aleph_1$ (that ZFC proves has the above property)? At first I meant my question to be general, where one is allowed to choose any maximal probability measure (non-negative, total measure 1, countable additivity, cannot be extended) based on which all the events are defined. But Eric's comment suggests that the question may be non-trivial even for the Lebesgue measure on a Euclidean space. So I'm now interested in both variants. =)","['probability-theory', 'set-theory']"
1745931,"Dubious ""proof"" of $e^x$ derivative?","The proof to which I am referring is amply discussed here: Derivative of exponential function proof , but I remain unconvinced by the answers that pertain to the specific proof discovered by user1346994. It all boils down to showing that $\lim_{h\to 0}\left({\dfrac{e^{h}-1}{h}}\right) = 1$ I find it highly deceiving to replace $e$ with $(1+h)^{1/h}$ in the expression in the limit. https://math.stackexchange.com/a/671305/309566 is the answer in which I am most interested. But I'm still puzzled by the remark 'again by continuity' and the change of variables bit. I suppose if my wish were modest, it would be a proof that follows the one stated but with clear justifications. Thanks and sorry if I sound confused!","['derivatives', 'exponential-function', 'limits']"
1745932,Decomposition of $\mathbb N$ into mutually disjoint infinite subsets [duplicate],"This question already has answers here : Partition of N into infinite number of infinite disjoint sets? [duplicate] (7 answers) Closed 6 years ago . $$\mathbb N =\bigcup_{j\in \mathbb N}\Delta_j $$ where each $\Delta_j$ is an infinite subset of $\mathbb N$  and $\Delta_j\cap \Delta_i=\Phi \ for\ i\neq j.$ Now what I need is a few examples of such decompositions. The only one I can think of now is the collection of the odd numbers and the even numbers. That satisfies it. Another possibility I was considering was like this :: $$\Delta_1=2\mathbb N\\ \Delta_2=3\mathbb N \backslash \Delta_1\\ \Delta_3=5\mathbb N\backslash (\Delta_1\cup\Delta_2)\\.\\.\\.\\.\\.\\.\\so\ \ on.$$ The technique here is for any arbitrary $k$ , $\Delta_k=p\mathbb N\backslash \left(\bigcup_{i=1}^{k-1}\Delta_i\right)$.  Clearly I can see all these sets are mutually disjoint and also infinite since there are infinitely many prime numbers. So , are there any other construction of this kind possible $?$ If so please let me know . Also , if there is any fault in my above construction point it out . Thank you.","['set-partition', 'elementary-set-theory']"
1745942,How to calculate $\lim\limits_{x\to 0} \frac{[\sin{x}-x][\cos({3x})-1]}{x[e^x -1]^4}$ without using L'HÃ´pital's Rule?,How to calculate $\lim\limits_{x\to 0} \frac{[\sin{x}-x][\cos({3x})-1]}{x[e^x -1]^4}$ without using L'HÃ´pital's Rule? I tried Taylor expansion but I couldn't solve the resulting summations. I also tried expanding them out but there were way too many terms. What is a valid way to solve the question?,"['limits-without-lhopital', 'calculus', 'limits']"
1745962,Show $\sum_{n=2}^{\infty}\frac{1}{n\ln n}$ diverges.,"I wish to show $\sum_{n=2}^{\infty}\frac{1}{n\ln n}$ diverges. I initially wanted to use the comparison test, but couldn't come up with a series that is obviously less than $\frac{1}{n\ln n}$ that diverges. So I moved on to the integral test. The problem here is that I need to show that $f(x)=\frac{1}{x\ln x}$ is continuous on $[2,\infty)$, using $\epsilon$-$\delta$ definition of continuity. I've been given theorems that allow me to just assert that $\ln x$ is continuous on the interval, as I know $1$ is continuous, $x$ is continuous, and so if $\ln x$ is continuous then as we have a composition of continuous functions, $\frac{1}{x\ln x}$ will be continuous on $[2,\infty)$. The trouble I'm having is showing $\ln x$ is continuous. I again got stuck doing this. And now it feels like I've completely over-complicated things. I need to be rigorous when showing that this series diverges, but we've only been given a certain amount of tools to use. We can't use Cauchy's condensation test, and if I wish to use the integral test I have to show that $f(x)$ is monotone (easy) and also that $f(x)$ is continuous (and the only tool we have for that is $\epsilon$-$\delta$). I've seen that there are very similar questions to this on the site, but they don't particularly help in my case. Have I missed something? Thanks for your time. EDIT: Thank you everyone for your help. Much appreciated!","['real-analysis', 'sequences-and-series']"
1745996,How much classical geometry must a geometer know?,"From my reading Wikipedia, I understand there are several branches of classical geometry (if the ordering is off, or I'm missing a few things, let me know): Absolute Euclidean Non-Euclidean Spherical Hyperbolic Projective Affine Transformational Inversive These can be studied from: Coordinate geometry (aka algebraic) view Axiomatic (aka synthetic) view Analytic view The combination of these branches and points of view generate many possible avenues of study. How many of these are useful for a modern geometer to know? By useful, I    mean fairly likely to lend intuitive insights into their
  work (This may     seem vague without specifying what kind of work
  they do. But since most     geometers aren't working in classical
  geometry, I guess the work of any     such geometer could be
  considered relevant to the question). How deeply must they learn? I've got a good high school level knowledge of math, and some college level math, and I have an interest in pure mathematics for a career. EDIT: Added tags relating to modern branches of geometry, so that these kinds of geometers see this question.","['riemannian-geometry', 'algebraic-geometry', 'soft-question', 'geometry', 'differential-geometry']"
1746015,Prove a function is constant. (complex analysis),Suppose function $f$ is holomorphic on $\mathbb C-\{0\}$ and satisfies $$|f(z)| \le \sqrt {|z|} + \frac{1}{\sqrt {|z|}}.$$ Prove that $f$ is a constant function. I think it's related to Laurent series representation and ML inequality but I have no idea how to prove it. Can anyone give me some hints? Thanks in advance!,['complex-analysis']
1746035,How to find number of vertices in a given graph?,"I am studying on the graphs where eccentricity of every vertex is same. If $G$ is such graph where eccentricity is $r$
for every vertex and for a vertex $x$
if there exists at least two vertices such that $d(x,y) = d(x,z) =r$, then how to find number of vertices in the graph. My attempt: I considered two shortest paths $P$ and $P'$ between $x$ and $y$, and $x$ and $z$, respectively, such that lengths of these 
paths is $r$. So, total number of vertices traversed is $2r+2$ but the vertex $x$ is common, so finally I came to the conclusion
that the graph has at least 2r+1 vertices, i.e., $n\geq 2r+1$. Is my procedure true? Am I missing any important fact? Kindly help. Any hint or suggestion is welcome.. Thanks for the help. What if some vertices are repeated. I am not getting any idea. Kindly help.","['graph-theory', 'proof-verification', 'proof-explanation', 'combinatorics', 'discrete-mathematics']"
1746062,Riesz basis of Paley-Wiener space.,"Let us consider the Paley-Wiener space:
$$PW_\pi:=\{f\in L^2(\mathbb R)\cap C(\mathbb R),\ \operatorname{supp}\hat f\subset [-\pi,\pi] \}.$$
Let $\{\lambda_n\}_{n\in\mathbb Z}$ be a sequence of real numbers.
The sequence $\{\operatorname{sinc}(t-\lambda_n)\}_{n\in\mathbb Z}$ is a Riesz basis for $PW_\pi$ if $|\lambda_n-n|\leqq L< 1/4$ (Kadec's $1/4$ Theorem for exponential bases). I wonder if $\{\operatorname{sinc}(t-\lambda_n)\}_{n\in\mathbb N}$ is still a Riesz basis for $PW_\pi$. I think that this is not true, because one-sided sequences could not generate a Riesz basis in the whole space $PW_\pi$. How can prove (or disprove) it?","['functional-analysis', 'harmonic-analysis']"
1746065,Most efficient method for computing Singular Value Decomposition of a triangular matrix?,There are several methods available for computing SVD of a general matrix. I am interested in knowing about the best approach which could be used for computing SVD of an upper triangular matrix. Please suggest me an algorithm which could be optimized for this special case of matrices.,"['matrices', 'matrix-decomposition', 'svd', 'algorithms', 'linear-algebra']"
1746077,Difference between Increasing and Monotone increasing function,"I have some confusion in difference between monotone increasing function and Increasing function. For example $$f(x)=x^3$$ is Monotone increasing i.e, if $$x_2 \gt x_1$$ then $$f(x_2) \gt f(x_1)$$ and some books give such functions as Strictly Increasing functions. But if $$f(x)= \begin{cases} 
      x & x\leq 1 \\
      1 & 1\leq x\leq 2\\
      x-1 & 2\leq x 
   \end{cases}
$$ Is this function Monotone increasing?","['derivatives', 'calculus']"
1746084,Is there a set of all topological spaces?,"This question is from Willard's General Topology: Is there a set of all topological spaces? My try is: 
Suppose $\mathfrak T $ is set of all topological spaces, then $\mathfrak T $ 'contains' all the sets (i.e., if $S$ is some set, then $\{\varnothing, S\}\in\mathfrak T $). Since Willard assumes that a set cannot be element of itself (exact words in Willard: Russell's paradox can be avoided (in our naive discussion) by agreeing that no aggregate shall be a set which would be an element of itself.) But, if $\mathfrak T$ is a set, then 'set of all sets' is 'subset' of $\mathfrak T$, counter to our agreement. I find my argument appealing as well as sloppy at the same time :), :(. Have I done something wrong?","['general-topology', 'elementary-set-theory']"
1746131,Discontinuous derivative *not* by oscillation,"All the differentiable functions that I have ever seen whose derivative is discontinuous, achieve this discontinuity by oscillating: See, e.g., this question . Is it possible to construct differentiable functions where the discontinuity of the derivative is achieved by some other way? (The basic idea achieving discontinuous behavior by osciallation is: Let it oscillate around the point $x_0$ where we want our derivative to be discontinuous, but decrease the amplitude as we approach $x_0$ so that we can achieve differentiability. Then the derivative will oscillate as well, but will not descrease in amplitude, so will be discontinuous at $x_0$.)",['derivatives']
1746172,Prove that $\oint_{|z|=r} {dz \over P(z)} = 0$,"I got stuck on this problem, hope anyone can give me some hints to go on solving this: P is a polynomial with degree greater than 1 and all the roots of $P$ in complex plane are in the disk B: $|z| = r$. Prove that: $$\oint_{|z| = r} {{dz}\over{P(z)}} = 0$$
  Here, the direction of the integral is the positive direction(actually, it can take whatever direction, because the value of the integral is 0). What I tried so far: Applying D'Alembert-Gauss theorem, we can write $P(z) = (z-z_1)^{p_1}(z-z_2)^{p_2}...(z-z_n)^{p_n}$, here $z_i$ are complex numbers which different from each other. We can choose for each $i = 1,...,n$ a $r_i > 0$ small enough such that $B(p_i,r_i)$ are disjoint with each others and all belong to $B$. So use Cauchy theorem for compact Jordan region generated by $B$ and $B(p_i, r_i)$, it's easy to see that:
$$\oint_{|z| = r} {{dz}\over{P(z)}} = \sum_1^{n}{\oint_{|z-z_i|=r_i} {{dz}\over{P(z)}}} =  \sum_1^{n}{\oint_{|z-z_i|=r_i} {{\prod_{j \neq i}{1 \over {(z-z_j)^{p_j}}}}\over{(z-z_i)^{p_i}}}}$$. Then I tried to apply Cauchy theorem for each ${\oint_{|z-z_i|=r_i} {{\prod_{j \neq i}{1 \over {(z-z_j)^{p_j}}}}\over{(z-z_i)^{p_i}}}}$:
$$f^{(k)}(z) = {k! \over {2 \pi i}} \oint_{\partial{B}}{{f(t) \over (t-z)^{k+1}}dt}$$, here $\partial{B}$ is notion for the boundary of the disk $B$ But I got stuck when trying to calculate the $(p_i - 1)$-th derivative for ${\prod_{j \neq i}{1 \over {(z-z_j)^{p_j}}}}$. I expect that each expression should be equal to 0, but I can't prove it. Anyone has any ideas to move on? If there's any point unclear, please don't hesitate to ask me. Thanks!","['complex-numbers', 'line-integrals', 'complex-integration', 'complex-analysis', 'integration']"
1746246,Geometric Series question,Could someone give me a hint on how I could do this question( it is a non- calculator question): The 5th term of a geometric series is 12 and the 7th term is 3. Find the two possible values of the sum to infinity of the series,['sequences-and-series']
1746268,"Matrix norm inequality : $\| Ax\| \leq |\lambda| \|x\|$, proof verification","Suppose that $A$ is a normal $n\times n$ matrix.  Show that $\|Ax \| \geq |\lambda_n|\|x\|$ for all 
  $x \in \mathbf{C}^n$, if $\lambda_n$ is the eigenvalue to $A$ of smallest absolute value. Is this also always true when $A$
  is not normal?  Give a proof
  or a counterexample! First question, does this depend on which norm I choose? Since $x\in\mathbf{C}^n$, then I am inclined to choose the induced norm (whatever its real name is), but I do not know where $A$ exists. If I can choose the 'natural one', then $$ \|Ax\|^2 = (Ax,Ax) = x^*A^*Ax.$$ Since $A$ is normal, it is unitarily similar to diagonal matrix $\Lambda$, so if $y = Ux$ (isometry) one gets $$ x^*A^*Ax = x^*U^*\Lambda^*\Lambda U x = y^*\Lambda^*\Lambda y = 
\sum_i^n |\lambda_i|^2 |y_i|^2 \geq |\lambda_n|^2 \|y\|^2$$
and because $\|y\| = \|x\|$ one gets $\|Ax\| \geq |\lambda_n|\|x\|$. Is this correct? Suppose $A$ not normal, then one can obtain the SVD $A = W\Sigma V^*$ and apply a similar proof
$$ \|Ax\|^2 = \dots = x^*V\Sigma^* \Sigma V^* x.
$$
Take $v = V^*x$, isometric, and singular values $\sigma_1 \geq \dots \geq \sigma_n \geq 0$, one gets
$$ x^*V\Sigma^*\Sigma V^*x = v^*\Sigma^*\Sigma v = \sum_i^n \sigma_i^2 |v_i|^2
\geq \sigma_n^2 \|v\|^2
$$
so, $\|v\| = \|x\|$ one gets $\|Ax\| \geq \sigma_n\|x\|$. And since 
$\sigma_n = \sqrt{\lambda_n} \geq \lambda_n$ for $\lambda_n \leq 1$, the statement is probably not always true, thus I can find a counterexample. I still feel like the not-normal case should be true, since it is on verge of being true, and because of my insecurity with norms and singular values. Any improvements, criticism and hints are appreciated.","['matrices', 'normed-spaces', 'svd', 'linear-algebra']"
1746277,Determining the values a random variable takes,"Let $(X_n)$ be IID bernoulli random variables and set $$Y_n = \sum_{i=1}^n \frac{X_i}{2^i}$$ I am trying to show this converges weakly to the uniform distribution on $[0,1]$. I am given a hint that I should first show what values it takes, and find it's distrubtion function. I found solutions online which state $Y_n$ takes values $k/2^n$ for $0 \leq k \leq 2^n - 1$ each with probability $1/2^n$ - I can't see this. Could someone please explain why this is so","['real-analysis', 'probability-distributions', 'probability', 'probability-theory']"
1746281,How does ZFC solve the problem of alphabet in formal languages?,"(In case someone thinks this is another question about the seeming circularity in formal languages and is going to downvote because of this, it's really not; don't downvote yet, keep reading) Perhaps the most widely known example of a formal language is the language of first-order logic, whose alphabet consists, among others, of symbols (defined as ""objects meaning other objects"" like ${\forall}$ or ${\implies}$. As alphabet is a set of symbols used in the language, then in the ZFC set theory$^1$, where every element of a set is another set, these symbols, since they belong to a set, should be sets too. I haven't seen any way to define them as sets (like I did in the case of natural numbers, where for example $0$ is often defined as ${\emptyset}$). Did anyone propose a way how to do such a thing? $^1$I feel like there is a way of using ZFC even before defining a formal language: list the axioms in a natural language$^2$, define set as every object which can be built from these axioms$^3$, build a first-order logic language using this notion of a set, write down the ZFC using this first-order logic language and use this new list of axioms. Is this correct? $^2$The meaning which ZFC tries to convey is possible to be said in a natural language. $^3$In case somebody says that at this level the concept of a set doesn't need to be formalised and is best left to be intuitively understood, one of the reasons ZFC is so popular is that it reproduces intuitive properties of sets - so there seems to be no harm in using ZFC this way.","['formal-languages', 'elementary-set-theory']"
1746290,What is duality argument for the operator on $L^p-$ spaces?,"Suppose that the operator  $T: L^{p}(\mathbb R) \to  L^{p}(\mathbb R)$ (say for instance, some nice convolution operator)  is bounded for $1\leq p \leq  2.$ At various, places we see that (for instance: in the proof of Hilbert transform is bounded on $1<p<\infty$ ), if the operator is bounded on for the range $1<p<2,$ then the operator  is bounded on $L^{p}$  for $p>2$ by duality argument. My Vague Question is: What is the standard duality argument in these kind of situations?   Can  you illustrate some specific example?","['harmonic-analysis', 'lp-spaces', 'fourier-analysis', 'analysis']"
1746310,Is the restriction of a finite map of affine varieties also finite?,"If $f:X\to Y$ is a dominant(i.e.$f(X)$ is dense in $Y$) regular map of affine varieties, then $f$ is called a finite map if $k[X]$ is integral over $f^*k[Y]$. My question is: if $Z\subset X$ is a closed subset of $X$, then how to
  show the restiction $f|_Z: Z\to \overline{f(Z)}$ is still a finite
  map? (Note: This result is supposed to prove the fact that ""a finite map takes closed sets to closed sets""(cf.Page60, Basic Algebraic Geometry 1, by Shafarevich), so please do not use the latter fact in the answer.)",['algebraic-geometry']
1746326,Relation between Karamata's and Hardy-Littlewood's inequalities,"In the field of (elementary) classical inequalities one of the most famous tools is the majorization inequality due to Karamata [1] (also known as Hardy-Littlewood-Polya ). In its integral version, it states that: If $\psi_1, \psi_2 : [a,b] \rightarrow \mathbb{R_{>0}}$ are non-negative measurable functions and, for example, $\psi_1$ ""majorates"" over $\psi_2$ (usually donated via $\psi_2 \succeq \psi_2$): $$\int_{a}^{s} \psi_1 \, dx \geq \int_{a}^{s} \psi_2 \, dx, \, \forall s \in [a,b) \> \text{ and } \> \int_{a}^{b} \psi_1 \, dx = \int_{a}^{b} \psi_2 \, dx$$
  then for any increasing $\phi : [a,b] \rightarrow \mathbb{R}$ holds:
  $$\int_{a}^{b} \psi_1 \phi \, dx \geq \int_{a}^{b} \psi_2 \phi \, dx .$$ From here one may derive [2] the majority of the classical inequalities: $AM \geq GM$, Muirhead, Schur, Cauchy-Schwartz, HÃ¶lder, Minkowski, Jensen, Chebyshev, etc. Besides this one, in the literature there is another famous inequality [3] , named after Hardy and Littlewood - the generalized rearrangement inequality: Let $\phi^*$ donates the symmetric (decreasing) rearrangement of a measurable, non-negative, asymptotically vanishing function $\phi$ defined over $\mathbb{R}^n$ - roughly speaking, $\phi^* (x)$ is the ""height"" at which the ""size"" of the level set $\{ t : \phi(t) > \phi^* (x) \}$ is equal to $x$ (please, excuse me for not going into great depth with the definitions). Then for any two functions $f, g : \mathbb{R}^n \rightarrow \mathbb{R}_{>0}$ of the above type:
  $$ \int f g \, dx \leq \int f^* g^* \, dx .$$ My question is whether there is any relation between the above inequalities and, more generally, between the concepts of majorization and symmetric rearrangement? I'm sorry if the answer is obvious - I haven't given it much thought...","['integral-inequality', 'measure-theory', 'analysis']"
1746329,Proof and precise formulation of Welch-Satterthwaite equation,"In my statistics course notes the Welch-Satterthwaite equation, as used in the derivation of the Welch test, is formulated as follows: Suppose $S_1^2, \ldots, S_n^2$ are sample variances of $n$ samples, where the $k$-th sample is a sample of size $m_k$ from a population with distribution $N(\mu_k, \sigma_k^2)$. For any real numbers $a_1, \ldots, a_n$, the statistic
  $$
L = \frac{\nu}{\sum_{k=1}^{n} a_k\sigma_k^2}\sum_{k=1}^n a_kS_k^2
$$
  with
  $$
\nu = \frac{\left(\sum_{k=1}^m a_kS_k^2\right)^2}{\sum_{k=1}^m \frac{(a_kS_k^2)^2}{N_k - 1}}
$$
  approximately (sic) follows a chi-squared distribution with $\nu$ degrees of freedom. Doing a quick Google search, most sources seem to follow a similar formulation.  There are a few questions I have though: How can the number of degrees of freedom of a chi-squared distribution depend on the statistics $S_i$? Shouldn't the number of degrees of freedom be a constant? What does 'approximately follow a distribution' mean? This is closely related to my third question: How can one justify this approximation? All 'proofs' I have seen on the internet seem to assume that $L$ follows a chi-squared distribution and then show that $\nu$ must have the stated value, using basic properties of expected value and variance. Even those arguments are confusing to mee, since they seem to ignore the fact that the $S_i$ are itself stochastic variables and not known constants. I found a link to the original papers by Welch and Satterthwaite , which I can't access freely. I wonder if there is a reasonably short answer to at least the first two of my questions. Us students are not expected to be able to prove the equation, so it's not that bad if there is no readily available proof, but I'd like to at least understand the statement itself.","['hypothesis-testing', 'probability-distributions', 'statistics', 'chi-squared', 'approximation']"
1746344,Reordering a conditionally convergent series,"I have the series
$$\sum_{n=1}^\infty(-1)^{n+1}\frac{1}{n}=\ln(2),$$
and I want to reorder it to
$$\sum_{n=1}^\infty\frac{8n-3}{2n(4n-3)(4n-1)}.$$
If we write the terms of the first series we get $1+\frac{1}{3}-\frac{1}{2}+\frac{1}{5}+\frac{1}{7}-\frac{1}{4}+\frac{1}{9}+\frac{1}{11}-\frac{1}{6}+...$, if we group each set of three successive terms we get $\frac{1}{6}+\frac{13}{140}+\frac{7}{198}+...$ 1 How do I show that this is equal to the second series? 2 How do I show that the second series cannot have the values $\ln(2)$? I was thinking about using partial fractions for the first one, but I'm not sure how.","['complex-analysis', 'sequences-and-series', 'convergence-divergence']"
1746358,find the rate of change $f(x) = 4\sin^3 x$ when $x = \frac{5\pi}{6}$,"find the rate of change $f(x) = 4\sin^3 x$ when $x = \frac{5\pi}{6}$ To find the rate of change I need to find $\frac{dy}{dx}$ using the chain rule $h'(x) = g'(f(x)).f'(x)$ $g'(f(x)) = 12\sin^2 x$ $f'(x) = \cos x$ $h'(x) = 12\sin^2 x \cos x$ After this, I am completely stuck, this comes from a paper that does not allow calculators and am I supposed to know what $\frac{5\pi}6$ means and be able to apply it to the derivative function? If so could somebody offer a link or something for me to learn becasue I do not know this.","['derivatives', 'calculus']"
1746369,Exercise about Lagrangian submanifolds,"I am trying to solve the following exercise: Let $(M,\omega)$ be a symplectic manifold and $L$ a compact Lagrangian submanifold such that $H^{1}(L)=0$. Let $\{L_{t}\}_{t\in(-1,1)}$ be a smooth family of Lagrangian submanifolds of $(M,\omega)$ with $L_{0}=L$. Does there exist $\epsilon>0$ such that for all $t\in(-\epsilon,\epsilon)$: $L\cap L_{t}\neq\emptyset$? So far, all counterexamples I could find have nontrivial $H^{1}$, like for instance a family of circles in $T^{*}S^{1}\cong S^{1}\times\mathbb{R}$. This makes me believe that the statement is true. Any suggestions how to prove it?","['symplectic-geometry', 'differential-geometry']"
1746395,Finding the power series of a complex function,"So I have the function
$$\frac{z^2}{(z+i)(z-i)^2}.$$ I want to determine the power series around $z=0$ of this function. I know that the power series is $\sum_{n=0}^\infty a_n(z-a)^n$, where $a_n=\frac{f^{(n)}(a)}{n!}$. But this gives me coefficients, how can I find a series for this? Edit: maybe we can use partial fractions?","['complex-analysis', 'power-series']"
1746413,p-Norm with p $\to$ infinity [duplicate],"This question already has answers here : Show that $\lim_{n\rightarrow \infty} \sqrt[n]{c_1^n+c_2^n+\ldots+c_m^n} = \max\{c_1,c_2,\ldots,c_m\}$ [duplicate] (3 answers) Closed 2 years ago . I have to show that: for all vectors $v\in \Bbb R^n$ : $\lim_{p\to \infty}||v||_p = \max_{1\le i \le n}|v_i|$ with the $||\cdot ||_p$ norm defined as $$ ||\cdot ||_p: (v_1, \dots ,v_n) \to (\sum^n_{i=i} |v_i|^p)^{1/p} $$ I think I once read something about mixing the root and the same power with the power going to infinity but i can't really remember anything concrete.
Any Ideas? Thanks in advance","['normed-spaces', 'real-analysis', 'summation']"
1746421,What is an intuition behind conjugate permutations?,"I know the definition of conjugate permutations.
 $$\exists p \quad p^{-1} \alpha p=\beta$$
So the $\alpha$ and $\beta$ is a pair of conjugate permutations. But can anybody can give some concise, vivid example to describe conjugate permutations? To help me understand the relation of $\alpha$ and $\beta$ intuitively? I'm a newbie in group-theory. First time here. If there is anything unsuitable in my specification, do tell me please.","['permutations', 'group-theory']"
1746444,Sheaf associated to a Cartier divisor,"This question is motivated by a construction, unclear for me, related to Cartier divisors. But, in the end it can be reduced to a question involving only sheaves on topological spaces. Let $X$ be a locally Noetherian scheme. Consider a Cartier divisor $D=\{(f_i,U_i)_i\}$ where as usual: $X=\bigcup_i U_i$ is an open cover $f_i\in\mathcal K_X^\times(U_i)$ and $\frac{f_i|_{U_i\cap U_j}}{f_j|_{U_i\cap U_j}}\in\mathcal O_X^\times$. Remember that $\mathcal K_X$ is the sheaf of stalks of meromorphic functions. We want to define a subsheaf $\mathcal O_X(D)\subset K_X$ associated to $D$. Liu's and Hartshorne's book give the following definition:
$$\mathcal O_X(D)(U_i):=f_i^{-1}\mathcal O_X(U_i)$$ Therefore they define the sheaf only on the open stes $U_i$ . Where is the definition of $\mathcal O_X(D)$ on the remaining open sets of $X$? I'm sure that my question will be solved some argument of the type: ""there exists a unique minimal subsheaf $\mathcal G$ of $\mathcal K_X$ such that $\mathcal G(U_i)=\mathcal O_X(D)(U_i)$"". Unfortunately I can't find any reference for this result.","['schemes', 'sheaf-theory', 'divisors-algebraic-geometry', 'algebraic-geometry']"
1746455,If double derivative test fails can we go for Higher derivatives,"if $f(x)=x^4$ we have critical points given by $$4x^3=0$$ which is $x=0$ Now $$f''(x)=12x^2$$ so $$f''(0)=0$$ and also $x=0$ is not Point of Inflexion since $f''(0^{+})$ and $f''(0^{-})$ have same sign. Now if we take triple derivative $$f'''(x)=24x$$ and $$f''''(0) \gt 0$$ Can we say $x=0$ is Local Minima because from graph of $x^4$,Minima occurs at $x=0$","['algebra-precalculus', 'derivatives']"
1746482,Showing the sum of a C* subalgebra and ideal is itself a C* subalgebra,In my functional analysis class I was recently met with this in the context of C* algebras: Let A be a C*-Algebra and B is a C*-subalgebra of A and I an ideal of A. We are asked to show that $ B+I $ is itself a C*-subalgebra of A (in particular it is closed). I am stuck and cannot solve this. Can someone please kindly assist?,"['functional-analysis', 'c-star-algebras', 'banach-algebras', 'ideals']"
1746485,Decreasing sequence of non-negative Lebesgue measurable functions and MCT,"I'm learning about measure theory, specifically the Lebesgue integral of nonnegative functions, and need help with the following problem: Suppose that $f$ and $f_n$ are nonnegative measurable functions, that $f_n$ decreases pointwise to $f$, and that $\int_{\mathbb{R}}f_1 < \infty$. Prove that $\int_{\mathbb{R}}f = \lim\int_{\mathbb{R}}f_n$. [Hint: Consider $g_n = f_1 - f_n$]. Show with a counterexample that the assumption that $\int_{\mathbb{R}}f_1 < \infty$ is necessary. The assumptions are (I always rewrite the problem to see if I understand it correctly): $\forall x \in \mathbb{R}, f_n(x) \geq f_{n+1}(x)$. $\int_{\mathbb{R}}f_1 < \infty$,that is $f_1 \in L^1(\mathbb{R})$. $f_n \to f$ pointwise in $\mathbb{R}$. My work and thoughts: As $f_n$ is monotone non-increasing, $g_n = f_1 - f_n$ is a monotone non-decreasing sequence of non-negative Lebesgue measurable functions, i.e $0 \leq g_1 \leq g_2 \leq \cdots \leq f_1 - f$ and $\lim g_n = f_1 - f$. Therefore, by the monotone convergence theorem $$ \int_{\mathbb{R}}\lim_{n \to \infty} g_n = \int_{\mathbb{R}}(f_1 - f) = \lim_{n \to \infty}\int_{\mathbb{R}}(f_1 - f_n).$$ Because $\int_{\mathbb{R}}f_1 < \infty$ and $f_n \leq f_1$ for all $n \in \mathbb{N}$, this implies that $\int_{\mathbb{R}}f_n < \infty$ for all $n \in \mathbb{N}$. This is where I'm stuck. I think I'm really close to the desired result. How do I continue from here? Also how do I show that the assumption that $\int_{\mathbb{R}}f_1 < \infty$ is necessary using a counterexample?","['real-analysis', 'lebesgue-integral', 'measure-theory', 'lebesgue-measure']"
1746491,"In a $\triangle ABC,a^2+b^2+c^2=ac+ab\sqrt3$,then the triangle is","In a $\triangle ABC,a^2+b^2+c^2=ac+ab\sqrt3$,then the triangle is $(A)$equilateral $(B)$isosceles $(C)$right angled $(D)$none of these The given condition is $a^2+b^2+c^2=ac+ab\sqrt3$. Using sine rule, $a=2R\sin A,b=2R\sin B,c=2R\sin C$,we get $\sin^2A+\sin^2B+\sin^2C=\sin A\sin C+\sin A\sin B\sqrt3$ I am stuck here.",['trigonometry']
1746517,For which complex parameters the following matrix is diagonalizable,"For all possible complex values of the parameter $\lambda$ , determine if the matrix $A$ is diagonalizable and if so find an invertible matrix $C$ and a diagonal matrix $D$ so that $C^{-1}$$DC=A$ $A$ = 
$\left( \begin{array}{ccc}
1 & i & 0 \\
0 & \lambda & 1 \\
0 & 0 & i \end{array} \right)$ To begin with, I am not even sure what are the parameters I should be working with for $\lambda$ and then how should I proceed with them?","['matrices', 'diagonalization', 'eigenvalues-eigenvectors', 'linear-algebra']"
1746525,Is there any function continuous in $R$ and differentiable in rational numbers with zero derivative?,"I'm looking for a function continuous in $R$ and differentiable in all rational numbers and it's derivative should be $0$.But not the constant function. And there is a same question about irrational numbers.
Can any one help??",['derivatives']
1746527,$S^1$ acting on $SO(n+1)/SO(n-1)$ by translations,"I'm ready right now in a paper, that $S^1$ acts on $SO(n+1)/SO(n-1)$ by right translations. I thought that a Liegroup $G$ acting by right translations, means that we have a right action $\varphi \colon G \times G \to G, \ (g,h) \mapsto \varphi_g(h)$ with $\varphi_g \circ \varphi_h = \varphi_{hg}$. But we have clearly, that $SO(n+1)/SO(n-1) \neq S^1$. So what do the author mean by ""$S^1$ acts on $SO(n+1)/SO(n-1)$ by right translations""? Edit: Maybe I should mention, that in this paper we get an action of $SO(n+1) \times S^1$, so that $S^1$ has to commute with the action of $SO(n+1)$.","['differential-geometry', 'lie-groups']"
1746580,What is the advantage (if any) of neighborhoods which are not open?,"From wikipedia If $X$ is a topological space and $p$ is a point in $X$, a neighbourhood of $p$ is a subset $V$ of $X$ that includes an open set $U$ containing $p$,
$$p \in U \subseteq V.$$ What is the added advantage of defining the neighborhood to be $V$, which need not be open, as opposed to defining the neighborhood to be the open set $U$ from the start?","['general-topology', 'analysis']"
1746581,Trigonometric limit $\lim_{x\to\pi/4}\frac{1-\tan x}{1-\sqrt{2}\sin x}$,"The limit is
$$\lim_{x\to\pi/4}\frac{1-\tan x}{1-\sqrt{2}\sin x}$$ I was able to solve it using L'hopital and the answer that I got was $2$. Can you please confirm if the answer is right and suggest some other way to evaluate the limit without using L'hopital?","['limits-without-lhopital', 'calculus', 'limits']"
1746626,4 cards are drawn from a pack without replacement. What is the probability of getting all 4 from different suits?,"4 cards are drawn from a pack without replacement. What is the probability of getting all 4 from different suits? Here's how I tried to solve: For the first draw, we have 52 cards, and we have to pick one suit. So, probability for this is $\frac{13}{52}$. For the second draw, only 51 cards are left. The second suit has to be selected, so there are 13 cards from that suit. The probability is $\frac{13}{51}$. Similarly, the third and fourth draw have probabilities $\frac{13}{50}$ and $\frac{13}{49}$ respectively. Since the draws are independent, the total probability becomes $$\frac{13}{52} \times \frac{13}{51} \times \frac{13}{50} \times \frac{13}{49}$$ But my book says the answer is $\frac{{13\choose 1} \times {13 \choose 1} \times {13\choose1} \times {13\choose1}}{52 \choose 4}$. My answer differs by a factor of $4!$. What did I do wrong?","['combinatorics', 'probability']"
1746630,Complex power series expansion of $\frac{e^z}{1+z}$,"I'm trying to find complex power series expansion of $\frac{e^z}{1+z}$ centered at $z=0$ and its radius of convergence. Here is my attempt: Since $e^z = \sum_{n=0}^\infty \frac{z^n}{n!}$, we can divide both terms by $1+z$ to get $e^z = \sum_{n=0}^\infty \frac{z^n}{(1+z)n!}$. Then I can get radius of convergence using the usual Cauchy-Hadamard formula. Is this correct?
Thanks for any help!","['complex-analysis', 'power-series']"
1746631,Product topology is discrete,"Willard's General Topology says: For each $\alpha\in A$, let $X_{\alpha}$ be discrete topological space. Then $\prod_{\alpha\in A}X_{\alpha}$(under product topology) will be a discrete space if and only if A is finite. But, if $X_{\alpha}=\{1\}$ for each $\alpha\in A$, then  $\prod_{\alpha\in A}X_{\alpha}$ is discrte space, right?",['general-topology']
1746632,topology related to Binary space,"I ran upon this topology based on binary space, perhaps using obscure terminology, but I am curious what it is and its properties. Let binary space be the set of strings of $0,1$'s, and let $S$ be the set of all functions that map the binary space to a set of two elements, $\{0,1\}$. It's like it decides a true or false for every binary string. For the topology $\mathcal{T}$, let a basic set be $U_{V,f}$, where any $g$ in this set must satisfy $g(x)=f(x)$ for all $x$ in $V$, and $V$ is a finite subset of $B$. Is this space $(S,\mathcal{T})$ Hausdorff? Compact? Any related material is welcome. Thanks",['general-topology']
1746648,Any subgroup that contains the subgroup generated by all commutators is normal.,"First, I was asked to show that if $G$ is a group and $G'$ is generated by $\{xyx^{-1}y^{-1}|x,y\in G\}$, then $G'\trianglelefteq G$ and $G/G'$ is Abelian. This was not too difficult to show. The second part of the question said if $G$ is a group and $H\supseteq G'$, where $G'$ is as in the last part, then $H\trianglelefteq G$ and $G/H$ is Abelian. I'm not sure of the best way to approach this problem. Any help would be appreciated.","['abstract-algebra', 'group-theory']"
1746711,Alternating series test for complex series,"I want to show that we can continue Riemann's zeta function to Re$(s)>0$, $s\neq 1$ by the following formula
\begin{align}
(1-2^{1-s})\zeta(s)&=\left(1-2\frac{1}{2^s}\right)\left(\frac1{1^s}+\frac1{2^s}+\ldots \right) \\
&=\frac1{1^s}+\frac1{2^s}+\ldots -2\left(\frac1{2^s}+\frac1{4^s}+\ldots \right)\\
&=\frac1{1^s}-\frac1{2^s}+\frac1{3^s}-\frac1{4^s}+\ldots  \\
&=\sum_{n=1}^\infty (-1)^{n-1}\frac1{n^s}.
\end{align}
In order to do that, I need to show that the series converges for Re$(s)>0$, except $s=\frac{2k\pi i}{\ln 2}+1$, $k\in \mathbb{Z}$, which are removable singularities. Any ideas on how to do that?","['complex-analysis', 'analytic-continuation', 'sequences-and-series']"
