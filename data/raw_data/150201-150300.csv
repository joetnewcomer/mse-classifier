question_id,title,body,tags
2497587,Open and closed balls in discrete metric,"Let $(X,d)$ be the discrete metric space, $x,y\in X$.
I'm reading in one source that the open ball in the discrete metric $$d(x,y)=\cases{0 & $x=y$\\ 1 & $x\ne y$}$$ are defined as $$\mbox{Open ball: }B(x_0, \varepsilon)=\cases{\{x_0\} & $0<\varepsilon \le 1$\\
X & $\varepsilon > 1$}$$
-and- $$\mbox{Closed ball: } B[x_0, \varepsilon]=\cases{\{x_0\} & $0<\varepsilon < 1$\\
X & $\varepsilon \ge 1$}$$ However, I do not understand how, for example, in the open ball it is possible that we have just the singleton when $\varepsilon=1$, and thus what is the difference between open and closed balls in the discrete metric? I think that if $\varepsilon=1$ then the ball should be the entire space $X$. Would appreciate some clarification.","['general-topology', 'metric-spaces']"
2497588,"Wedge products, dual basis and exterior algebra in my real analysis book","I'm reading a book on Real Analysis and there's a chapter about surface integrals. It starts by defining the wedge product, and then it starts defining differential forms of some degree. It starts like this: Let's use the notation $\{dx_1, \ldots, dx_m\}$ for the canonical
  basis of $(\mathbb{R}^m)^*$, dual of the basis $\{e_1, \ldots,
e_m\}\subset\mathbb{R}^m$, where $e_1 = (1,0,\ldots, 0)$ etc. For each
  set $I = \{i_1< \cdots < i_r\}\subset \{1,2,\ldots, m\}$, let's write $$dx_I = dx_{i_1}\wedge \cdots \wedge dx_{i_r}$$ the $r$-linear alternating forms $d_{x_I}$ make the canonical basis of
  the vector space $A_r(\mathbb{R}^m)$ (space of the $r$ linear maps
  from $\mathbb{R}^m$ to $\mathbb{R}$). Given a list of $r$ vectors $v_1,\ldots, v_r\in\mathbb{R}^m$, we
  obtain a matrix $a = (a_{ij})$, with $m$ lines and $r$ columns, at
  which the $j$-th column is the vector $v_j = (a_{1j}, \ldots,
 a_{mk})$. In this case: $$d_{x_I}(v_1, \ldots, v_r) = \det(a_I)$$ where $a_I$ is the matrix $r\times r$ obtained selecting the lines
  such that its indexes belong to the set $I$ I know that here, $dx_1, \ldots$ are just names for the dual basis elements, but it has something to do with $dx$ of integrals. What is this relation? Why are we even using dual basis vectors, for what they're useful? I've been googling things and found that this is related to something called exterior algebra, which uses a lot of wedge products, but I'm completely lost here, I don't get anything about the usefulness of wedge products and its relation to dual vectors. Could somebody help me?","['real-analysis', 'integration', 'linear-algebra', 'exterior-algebra']"
2497592,Manipulating the left-hand side into a right-hand side of a Hypergeometric sequence expansion,"How do you show that$$F\left(\frac 13,\frac 23;\frac 32;\frac {27}4x^2(1-x^2)^2\right)=\frac {2\sin\left[\tfrac 13\arcsin\left(\tfrac {3\sqrt3}2x(x^2-1)\right)\right]}{x\sqrt3(x^2-1)}$$ I'm not sure where to begin. I thought about using the expansion of $\sin^{-1}$ since its expansion is equivalent to$$\arcsin z=z\, F\left(\frac 12,\frac 12;\frac 32;z^2\right)$$But am not sure how to incorporate that. I also thought about using some identity to make a transformation, but I'm not sure which specific one to use.","['algebra-precalculus', 'hypergeometric-function', 'summation']"
2497611,Why I cannot show $f(A\cap B) \supseteq f(A)\cap f(B)$?,"$f:X\rightarrow Y$ $A,B\subseteq X$ The question got me to show a counterexample where $$f(A\cap B) \neq f(A)\cap f(B)$$ and also to show $$f(A\cap B) \subseteq f(A)\cap f(B).$$ This was done in the following way: let $y\in f(A\cap B)$. Then there exists $x\in A\cap B$ such that $y=f(x)$. So, $x\in A, y\in f(A)$ and $x\in B, y\in f(B)$ So this means $y \in f(A) \cap f(B)$.  $\qquad (\star)$ So $f(A\cap B) \subseteq f(A) \cap f(B)$. However, why can I not go in the reverse direction by starting at $(\star)$ to show that if $y\in f(A)\cap f(B)$, then $y \in f(A\cap B)$? I suspect it might have something to do with taking the pre-image, but it seems that we used the pre-image definition anyway in the first line of the proof.","['elementary-set-theory', 'functions']"
2497642,What's the derivation of this integral formula?,I was searching around the web for some information about integrals and I came across the formula: $$\int_{-\infty}^\infty \frac{\ln(x^2)e^{\frac{-x^2}{2\sigma}}}{(2\pi)^\frac{1}{2}\sigma}dx= \ln(\sigma^2)-\gamma-\ln(2)$$ $\gamma =$ the Euler-Mascheroni Constant I'm very unsure where the Euler-Mascheroni constant came from. I tried rearranging the integral to simpler terms but I end up getting: $$\int_{-\infty}^\infty \ln|x|e^{-x^2}dx$$ which isn't overtly integrable. Where does this formula come from?,"['integration', 'definite-integrals', 'calculus']"
2497661,Integration problem with powers of trig-expressions,"Is there any (elementary) way to evaluate the integral $$\int_0^{\pi/2}(\cos x)^{a}(1-\cos x)^{1-a}dx $$ for any $a\in\ (0,1)\,\,\,\,?$ I tried many ways, but could not succeed. Any idea? EDIT:
This is what I got from Mathematica. It looks bit complicated.","['trigonometry', 'hypergeometric-function', 'improper-integrals', 'definite-integrals', 'integration']"
2497664,When can't you change the order of integration?,"Apparently there are integrals which you can express as $\int_A \int_B f(x, y) \mathop{}\!\mathrm{d}x \mathop{}\!\mathrm{d}y$ but not $\int_C \int_D f(x, y) \mathop{}\!\mathrm{d}y \mathop{}\!\mathrm{d}x$. When would this be the case? Is it to do with their limits not being invertible functions?","['multivariable-calculus', 'real-analysis', 'calculus']"
2497682,Approximate or exact solution of a trigonometric equation [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question How does one determine how close $\theta = \frac{\pi}{\sqrt{2}}$ is to being an explicit solution of the equation 
$\cos \theta = -\left(\frac{1 + \sqrt{7}}{6 }\right)$?","['real-analysis', 'trigonometry']"
2497733,Diffeomorphisms preserve tangency between curves,"I've been trying to solve the following problem: Prove that if two regular curves $C_1$ and $C_2$ of a regular surface $S$ are tangent at a point $p \in S$, and if $\alpha\colon S \to S$ is a diffeomorphism, then $\alpha(C_1)$ and $\alpha(C_2)$ are regular curves which are tangent at $\alpha(p)$. Any help would be great. Thanks in advance!","['parametrization', 'differential-geometry', 'surfaces']"
2497742,"Is $\operatorname{tr}\left(\int A(t)\,dt\right) = \int \operatorname{tr}(A(t))\,dt$ true?","Is it true that the trace of a matrix integration equals the integration of the trace of such matrix? $$\operatorname{tr}\left(\int A(t)\,dt\right) = \int \operatorname{tr}(A(t))\,dt$$","['ordinary-differential-equations', 'linear-algebra']"
2497775,Prove that $\sum_{k=0}^n a_k x^k = 0$ has at least $1$ real root if $\sum_{k=0}^n \frac{a_k}{k+1} = 0$,"Knowing that
$$ \frac{a_0}{1} + \frac{a_1}{2} + \frac{a_2}{3} +\cdots + \frac{a_n}{n+1} =0$$
Prove that 
$$ a_0 + a_1x + a_2x^2 + \cdots + a_nx^n = 0$$
has at least one real solution. I suspect that it's proven with the intermediate value theorem. But can't find two numbers that satisfy it.","['derivatives', 'real-analysis', 'polynomials', 'calculus']"
2497816,Summation over roots of unity,"Find the value of $\displaystyle\sum_{r=1}^{4} \frac{1}{2-\alpha^r} $
where $ \alpha^k (k=0,1,2,3,4,5) $ are fifth roots of unity. My approach:- 
As we know that $ \alpha^k (k=0,1,2,3,4,5) $ are fifth roots of unity, then $ \alpha^k - 1$ should be equal to zero. Therefore the final answer to the summation $\displaystyle\sum_{r=1}^{4} \frac{1}{2-\alpha^r} $ should be $\displaystyle\sum_{r=1}^{4}  1 = 4  $ But the answer given is $ \dfrac{ 49}{31} $ Any help or hint will be much appreciated!","['sequences-and-series', 'complex-numbers']"
2497895,How to prove that this diophantine equation has only two solutions?,"Consider an equation of the form. $$z^3=y^2+4$$ where z ,y $\in \Bbb N$ Hence, the solution of form (z,y) are (2,2) and (5,11).
So How to prove that this diophantine equation only has these two solutions.","['number-theory', 'diophantine-equations']"
2497906,probability measure on $\sigma$-algebra,"Let $\mu$ be a $\sigma$-finite measure on a $\sigma$-algebra $\mathcal{A}$ of subsets of $\Omega$. Show that there exists probability measures $\mu_n$ on $\mathcal{A}~(n \in \mathbb{N})$ and $a_n>0$ such that for every set $A \in \mathcal{A}:$
$$\mu (A)= \sum_{n=1}^{\infty} a_n \mu_n (A).$$ Is there anyone can give me hints or show how to start proving this question?","['probability', 'measure-theory']"
2497922,Prove that $\sum\limits_{n=1}^\infty\frac{\text{Si}^2(\pi n)}{n^2}=\frac{\pi^2}2$,"I was doing numerical calculations and found $$\sum _{n=1}^{\infty } \left(\frac{\text{Si}(\pi  n)}{\pi n}\right)^2\overset{?}{=}\frac{1}{2},$$ where $\text{Si}(x)$ means the sine integral . Interestingly, it seems that only when the terms are squared can the result be a rational number. I attempted to evaluate the following series expansion about $x=0$: $$\frac{\text{Si}(\pi  x)}{\pi  x}=\sum_{n=1}^\infty\frac{(-1)^n(\pi x)^{2 n}}{(2 n+1)^2 (2 n)!}=1-\frac{\pi ^2 n^2}{9}+\frac{13 \pi ^4 n^4}{2025}-\frac{8 \pi ^6 n^6}{33075}+O\left(n^8\right).$$ But it didn't give me any clue. I still have no idea about how to evaluate $$\sum_{n=1}^\infty\ \displaystyle\left(\frac{\text{Si}(\pi  n)}{\pi n}\right)^2.$$",['sequences-and-series']
2498020,"If $|\,f'(p)|<1$, prove that $p$ is an attracting fixed point for $f$","Suppose that $f:(a,b) \to (a,b)$ has a fixed point $p$ in $(a, b)$ and that $f$ is differentiable at $p$. Furthermore, assume that $|\,f'(p)|<1$. Question: How do I prove that $p$ is an attracting fixed point for $f$. I know that $p$ is an attracting fixed point for $f$ if there exists a $0<\delta<1$ such that $|\,f(x) - p|<|x - p|$ whenever $|x - p|<\delta, x \neq p$. I've tried to think of what the relationship of the derivative of $f$ with the fixed point $p$ would be, but I'm kind of stuck.. Thanks in advance!","['derivatives', 'fixed-point-theorems', 'real-analysis', 'convergence-divergence']"
2498052,How to prove that gcd of two numbers is one.,"For $l \in \mathbb{N}$ I'm to prove that the greatest common divisor, 
$\gcd(8l^2+20l+13,4l+2) = 1$. I've tried induction, but I couldn't pull off, now I'm at a loss of how to even begin to solve this. PS: It's also possible that it's not possible to prove it, because it's not correct.",['analysis']
2498056,What is the difference between the Laplacian and second order derivative?,Is the Laplacian of a function the same as second order derivative of the function in 1-D? What about in 2-D?,"['multivariable-calculus', 'laplacian', 'laplace-transform', 'calculus']"
2498071,What is special of being countably infinite?,"I saw the proof of ""there exists no function that is only continuous on $\mathbb{Q}$"". The idea of the proof is to enumerate a sequence in $\mathbb{Q}$. And choose a set of nested non-degenerated compact intervals. https://holdenlee.wordpress.com/2010/04/26/can-a-function-be-continuous-only-on-rationals/ My question is: What is special of being countably infinite? E.g. for that proof, on an uncoutable set, we can just ""enumerate"" all points by an arbitrary index set $J$... And construct the same intervals, due to the existence of well-ordering, we can actually argue such construction works.","['real-analysis', 'elementary-set-theory']"
2498085,"Beilinson-Bernstein localization, equivariant modules","I have a question regarding the equivariance in the Beilinson-Bernstein localization. Let $G$ be an simply connected algebraic group over a field of charateristic $0$ and $K$ a closed subgroup of $G$ with corresponding lie algebras $\mathfrak{g}, \mathfrak{k}$ and $X$ be the flag variety. One can define then the notions of $K$-equivariant $U(\mathfrak{g})$ modules and $K$-equivariant  $D$-modules. The Beilinson-Bernstein localization states that there is an equivalence between $K$-equivariant finite generated $U(\mathfrak{g})$ modules with trivial central character and $K$-equivariant $D_X$ modules. (One proof can be found in HTT theorem 11.5.3). The proof uses the crucial fact that $X$ is $D-$ affine. Suppose for a moment that we ignore the fact that $X$ is $D$-affine. Can we still prove that the localization functor sends  $K$-equivariant finite generated $U(\mathfrak{g})$ modules with trivial central character to $K$-equivariant $D_X$ modules and similar for the global section functor? I do not require this to be an equivalence.","['algebraic-groups', 'lie-algebras', 'd-modules', 'algebraic-geometry']"
2498123,"Given a $2 \times 2$ matrix $B$ that satisfies $B^2=3B-2I$, find the eigenvalues of $B$","Given a $2 \times 2$ matrix $B$ that satisfies $B^2=3B-2I$, find the eigenvalues of $B$. My attempt: Let $v$ be an eigenvector for B, and $\lambda$ it's corresponding eigenvalue. Also, let $T$ be the linear transformation (not that this is exactly necessary for the question, but just added it in for my understanding.) Therefore, $$T(v) = Bv = \lambda v$$ Now I'm unsure how to incorporate this information into the quadratic equation given above since by matrix / vector arithmetic isn't extremely solid. Thanks!","['eigenvalues-eigenvectors', 'matrix-equations', 'matrices', 'linear-transformations', 'linear-algebra']"
2498142,Additive functionals of simple Markov chain,"Suppose we have an irreducible and aperiodic discrete-time Markov chain on a finite set $S$ with stationary probability $\pi$; denote it by $(X_0, X_1, X_2,...)$. It is known that for every $x\in S$ and every positive function $f:S\to \mathbb{R}_+$
$$ \frac{1}{n}\sum_{k=0}^{n-1} f(X_k) \to \int f d\pi$$
$\mathbb{P}_x$ almost surely. Are there any good resources where the speed of this convergence, namely, the quantity (for an $f\in L^1(\pi)$)
$$ \mathbb{P}_x\bigg( \bigg|\frac{1}{n}\sum_{k=0}^{n-1} f(X_k) -\int f d\pi \bigg| > \varepsilon\bigg)$$
is explored ? I guess this probability decays exponentially for every $x\in S$ in the ""ideal"" (finite, irreducible, aperiodic) case. Are there any books that answer this question in this simple setting ? I am not looking for generalisations to arbitrary spaces, that most recent papers deal with, but rather a simple, clean and concise statement and proof ! More precisely, I am interested in the case where $f(x)=f_y(x)=1\{x=y\}$ for $y \in S$, since I would like to have exact quantitative bounds on the probability that the empirical measure of the Markov chain deviates from the true invariant probability by more than some small amount.","['concentration-of-measure', 'probability-theory', 'markov-chains', 'probability', 'monte-carlo']"
2498226,Why is dimension of solution space of homogeneous equations n-r?,"This throws me off track completely - its like pushing me out of moving train.I am referring to page 65 of Shilov (Linear algebra). The author clearly states that in Homogeneous system of linear equations: If the coefficient matrix has order k x n (k -> number of equations, n -> number of unknowns) r is rank of the matrix. Then linear solution space has dimension n-r. I would think if rank is r, then the number of linearly independent rows is r. So if x i denotes any solution for r+1st equation to kth equation, it should be totally describable by linearly independent solutions r i from i=1 to i=r (Again going by rank). Yet, the dimension of solution space L is given by n-r. Why? Update: What's being said is starting to makes sense. I am probably mixing up the concept of linear independence of columns of basis minor matrix (rank r) with dimension of solution space. I guess the fact that first r columns of coefficient matrix of rank r are linearly independent implies that other columns r+1 .... n is expressible in terms of r columns. That gives us freedom to arbitrarily choose solutions c r+1...n for dependent column variables with solutions c 1...r for linearly  independent column elements uniquely determinable (By Cramers rule). This ""freedom"" manifests as dimension n-r of solution space.
Does the above sound coherent?","['matrices', 'matrix-rank', 'linear-algebra', 'homogeneous-equation']"
2498229,The central ideas in Hales's proof of the Honeycomb conjecture.,"I have been trying to understand Thomas Hales's proof of the honeycomb conjecture: https://arxiv.org/pdf/math/9906042.pdf However, despite the fact that the paper is clearly written, I find myself lost. I am wondering if anybody who knows this proof would be so kind to give a brief ordered list of the central ideas of the proof, so that I am able to understand what is a central idea and what is a technical detail and enable me to follow the proof better. Thank you very much, Maithreya","['discrete-geometry', 'combinatorial-geometry', 'proof-explanation', 'geometry', 'discrete-mathematics']"
2498230,Invertible Sheaf isn't isomorphic to $\mathcal{O}_X $,"Let $X$ a scheme and $ \mathcal{L}$ a invertible $\mathcal{O}_X $-module, therefore locally isomorphical to structure sheaf $\mathcal{O}_X $. We know, that a morphism of sheaves $\phi:\mathcal{F} \to \mathcal{G}$ on $X$  is an isomorphism if and only if for every $x \in X$ the induced morphism $\phi_x:\mathcal{F}_x \to \mathcal{G}_x$ in stalks is an isomorphism. Because $ \mathcal{L}$ locally isomorphic to $\mathcal{O}_X $ so we have $\mathcal{L}_x \cong \mathcal{O}_{X,x}$ in each $x \in X$. Why in general $\mathcal{L} \cong \mathcal{O}_X$ doesn't hold for every invertible sheaf $ \mathcal{L}$?","['sheaf-theory', 'algebraic-geometry']"
2498255,Difference between Higgs bundle and vector bundle with connection,"Let the pair $(E,A)$ be a $G$ equivariant vector bundle with connection
over an algebraic variety $X$ and let $G$ be a classical Lie group.
$A$ is the connection 1-form, i.e. $A \in \Omega^1(X)$. Of course, by
considering a specific associated bundle, i.e. the adjoint bundle the
induced connection is a Lie algebra valued 1-form. In a local
coordinate system we write $A = A(x)dx$ with $A(x)$ a matrix. Let the pair $(E', \phi)$ be a $G$ equivariant vector bundle with a
Higgs field $\phi \in End(E')\otimes K_X$ and if $X$ is a complex
curve (which is what I am interested for) then  $\phi \in
   End(E')\otimes \Omega^1 (X)$. Locally we write $\phi = \phi(x) dx$
where $\phi(x)$ is a matrix again. The Higgs field satisfies $\phi \wedge \phi = 0$. My understanding is that for a $G$ equivariant vector bundle $F$ with Lie algebra $\mathfrak{g}$ we can consider $End(F) \cong \mathfrak{g}$. How true is this? If this is the case (at least more or less) then what is the
  difference between a vector bundle with connection and a Higgs bundle? If I have stated something not quite precisely can you please help me make it precise and if not answer at least provide some references that target this question?","['vector-bundles', 'differential-geometry', 'algebraic-geometry']"
2498259,Properties of the Collatz map necessary to prove Collatz Conjecture,"In complexity theory, there is the famous result that whether or not $\mathrm P = \mathrm{NP}$ is not a question that relativises; since there are oracles $O$ such that $\mathrm{P}^O = \mathrm{NP}^O$ and ones such that $\mathrm{P}^O \neq \mathrm{NP}^O$, any resolution of the problem must use some property of Turing machines which is not true of all Turing machines with oracles. Somewhat similarly, I think, (although I do not claim to understand this) sieve theory cannot be used to resolve the twin prime conjecture , and thus a resolution of the conjecture must necessarily use something else than sieve theory. Is there something similar for the Collatz conjecture? Are there generalizations of the Collatz conjecture with a lot of similar properties for which the CC both holds and fails, depending on parameters?  Or can we rule out proof techniques which work for similar problems like for sieves?","['number-theory', 'reverse-math', 'collatz-conjecture']"
2498298,Products and Sums of Sheaves,Let $X$ a sheaf and $ \{\mathcal{F}_{\lambda} \}_{\lambda}$ a arbitrary family of $ \mathcal{O}_X$-Modules. Because thats an abelian category it contains products and coproducts (=sums). We considering the product presheaf $\prod \mathcal{F}_{\lambda}$ by defining $U \to \prod \mathcal{F}_{\lambda}(U)$ for euch open $U$ (resp. the sum presheaf $\bigoplus \mathcal{F}_{\lambda}$ by defining $U \to \bigoplus \mathcal{F}_{\lambda}(U)$). My question is why the product presheaf as defined above is automatically a sheaf (therefore the sheaf axiom holds) where the sum is only a presheaf (therefore have to be sheafificated)?,"['sheaf-theory', 'algebraic-geometry']"
2498317,Consistency of maximum likelihood estimator with non-normal data,"Let $X_1,...,X_n\stackrel{iid}{\sim}\text{Normal}(\theta,1)$ and define\begin{align}
Y_i=\begin{cases}1&X_i>0\\
0&X_i\leq 0.
\end{cases}
\end{align}
Let $\psi=\mathbb{P}(Y_1=1)$ and $\widehat{\psi}$ be the maximum likelihood estimator (MLE) of $\psi$. I want to show that if the data are not normal, then the MLE $\widehat{\psi}$ is not consistent and show to which it converges, if it converges at all. I determined the MLE, which is given by $\widehat{\psi}=\Phi(\overline{X})$, where $\Phi$ is the CDF of the standard normal distribution. I have looked at the proof of consistency of the MLE but so far I haven't found a direct relation with the fact that the data are normal. Any ideas?","['probability-theory', 'probability', 'statistics', 'statistical-inference']"
2498359,Probability of meeting,This is a basic probability question. Persons A and B decide to arrive and meet sometime between 7 and 8 pm. Whoever arrives first will wait for ten minutes for the other person. If the other person doesn't turn up inside ten minutes then the person waiting will leave. What is the probability that they will meet? I am assuming uniform distribution for arrival time between 7 pm and 8 pm for both of them.,['probability']
2498376,Conditional Expectation and the Tower Law,"Let $X,Y$ be two independent random variables with a uniform distribution on the unit interval. The questions first asks for $E(X^k)$ where $k$ is some fixed constant that is at least 0. This calculation is easy, as it is just 
$$\int_{0}^{1}x^{k}f_X(x)dx = \frac{1}{k+1}$$
Now, the question gets slightly trickier, and this is where my understanding of conditional expectation and conditional probability gets fuzzy. The question asks: what is $E(X^Y)$.? A hint is given, saying to use the tower law, i.e the fact that $E(X) = E(E(X|Y)) $. First, I am not sure what the inner expectation means. Most textbooks say it is a function of $Y$, which makes sense, but is not completely sound to me. Setting up this particular example with the tower law, we have: $$E(X^Y) = E(E(X^Y|Y))$$
After this I am somewhat stuck. I attempted to use the following:
$$E(X^Y|Y) = \int_{0}^{\infty}yf_{X^Y|Y}(x,y)dy$$
but I am fairly unsure as to what this statement actually means . If someone could help me develop a better understanding of conditional expectation of R.Vs and conditional probability in general, I would appreciate it, moreso than just an answer to this question.","['calculus', 'statistics', 'probability', 'conditional-expectation', 'random-variables']"
2498411,Find $\lim_{x\rightarrow0}\frac{3^x-5^x}{4^x-10^x}$,Find $$\lim_{x\rightarrow0}\frac{3^x-5^x}{4^x-10^x}$$ My work so far: $$\lim_{x\rightarrow0}\frac{3^x-5^x}{4^x-10^x}=\frac{\ln3-\ln5}{\ln4-\ln10}$$ Is correct? Add: I used $a^x\sim 1+x\ln a$ for $x\rightarrow 0$,"['real-analysis', 'limits']"
2498423,How to differentiate $\sqrt[5]{1/x}$,Hey guys I could use some help with this derivative: $$\sqrt[5]{1/x}$$ This is what I have so far: $$=-\dfrac{1}{5}\left(\dfrac{1}{x}\right)^{-6/5}$$ Having trouble simplifying this to my given solution so I don't know if it is correct. Given solution: $$-\frac{1}{5x\sqrt[5]{x}}$$,"['derivatives', 'calculus']"
2498424,Sequences with bounded iterated sums,"Consider double sequences $a_{n,m}\in\mathbb R$ where $n,m\in\mathbb Z,$ satisfying $a_{n,m}=a_{n-1,m}+a_{n,m-1}$ for all $n,m\in\mathbb Z,$ and $\sup_\limits{m\in\mathbb Z}|a_{n,m}|<\infty$ for all $n\in\mathbb Z.$ An example solution is $a_{n,m}=(-1)^m2^{-n}.$ A more general solution is
$$a_{n,m}=\int z^{-m}(1-z)^{-n} d\mu(z),\tag{x}$$
for a 
finite signed measure $\mu$ supported on an arc of the unit circle $\{\exp(2\pi i\theta)\mid \theta\in[\epsilon,2\pi-\epsilon]\}$ with $\epsilon>0.$ I am curious if there is a characterization, but to make a specific question: Is there a solution of (1.) and (2.) not of the form (x)? My thoughts: Decreasing $n$ is taking the discrete backwards difference. Increasing $n$ is like choosing a discrete integral. Given a row $(a_{n,m})_{m\in\mathbb Z}$ such that $\sup_{m}|a_{n,m}|$ is finite, the previous row is always ok: $\sup_{m}|a_{n-1,m}|$ is automatically finite because $a_{n-1,m}=a_{n,m}-a_{n,m-1}$ Any row $(a_{n,m})_{m\in\mathbb Z}$ determines $(a_{n,m})_{n,m\in\mathbb Z}$ uniquely if a solution exists. To prove this, by linearity it suffices to show there is a unique solution of conditions 1 and 2 satisfying $a_{0,m}=0$ for all $m.$ Condition 1 gives $a_{1,m}=a_{1,m-1}$ so $a_{1,m}=a_{1,0}$ for all $m.$ This then gives $a_{2,m}=a_{1,0}+a_{2,m-1},$ so $a_{2,m}=a_{1,0}m+a_{2,0}$ for all $m.$ Condition 2 with $n=2$ forces $a_{1,0}=0,$ so $a_{1,m}=0$ for all $m.$ By induction, we get $a_{n,m}=0$ for all $n\geq 0.$ And $a_{n-1,m}=a_{n,m}-a_{n,m-1}$ implies $a_{n,m}=0$ for all $n=-1$ and hence all negative $n$ by induction.","['functional-analysis', 'measure-theory', 'sequences-and-series']"
2498454,Question about balls and empty bags,"I did this exercise after studying this theory in a book. Is my reasoning correct? There are $210$ indistinguishable balls to distribute to $20$ distinct bags, staying exactly $7$ empty bags. How many different ways can the balls be distributed? The set $B$ of balls is the domain and the set $C$ of bags is the range. Every function in $C^B$ describes a different one of the ways to put balls into bags. Since $7$ are to remain empty  we are interested in functions $f$ with $|Image(f)| = 13$. So the answer should be $S(210,13) \frac{20!}{(20-13)!}$ , where $S$ represents the Stirling number of second kind.","['combinations', 'combinatorics', 'discrete-mathematics']"
2498456,Proving that $k[C]$ is a Dedekind domain for a smooth affine curve $C$,"Let $C$ be an affine smooth curve over a field $k$. I want to prove that the coordinate ring $k[C]$ is a Dedekind domain, using the following proposition: Let $A$ be a Dedekind domain with fraction field $K$. Let $L$ be a finite separable field extension of $K$ and denote by $B$ the integral closure of $A$ in $L$. Then $B$ is a Dedekind domain. The following is my attempt of solution. Suppose that we have a finite morphism $f: C\to \mathbb{A}^1_k$, i.e. the pullback $f^*:k[\mathbb{A}^1_k]=k[t]\hookrightarrow k[C]$ is injective and $k[t]\subseteq k[C]$ is an integral extension of rings. Then, since $C$ is a smooth curve, $k[C]$ is integrally closed, so the integral closure of $k[t]$ in $k(C)$ is $k[C]$. Now, if $k(C)/k(t)$ is separable, I can apply the previous proposition with $A=k[t]$. So, my questions are: Is it true that a finite morphism $f: C\to \mathbb{A}^1_k$ always exists? Is it true that $k(C)/k(t)$ is a separable extension of fields? Do we need to assume that $k$ is algebraically closed? Thank you. Edit: Maybe, 1. is a particular case of Noether normalization lemma, right?","['algebraic-geometry', 'abstract-algebra', 'affine-varieties', 'algebraic-curves', 'dedekind-domain']"
2498480,Big O estimate of $\frac{(5x^5+3x^2)(x\log x+x)}{10x^3}$.,"I have this function $$\frac{(5x^5+3x^2)(x\log x+x)}{10x^3}$$ and I have to give a big O estimate for it and so far here's what I have got. I know to give a big O estimate, first I have to find the dominant term. In this case, after getting rid of slow increasing terms and simplifying, I am here: $$\frac{x^3\log_2(x)}{2}+\frac{x^3}{2}$$ Then I can factor a $x^3$ out of the two fractions which I think is dominant term, so then the Big O estimate would be $O(x^3)$. Is this correct? I am mainly confused because of the $\log x$ in the function towards the end. Thanks!","['asymptotics', 'discrete-mathematics']"
2498512,Simplify: $\frac{\sqrt{\sqrt[4]{27}+\sqrt{\sqrt{3}-1}}-\sqrt{\sqrt[4]{27}-\sqrt{\sqrt{3}-1}}}{\sqrt{\sqrt[4]{27}-\sqrt{2\sqrt{3}+1}}}$,"I am doing a pretty hard problem:
$$\frac{\sqrt{\sqrt[4]{27}+\sqrt{\sqrt{3}-1}}-\sqrt{\sqrt[4]{27}-\sqrt{\sqrt{3}-1}}}{\sqrt{\sqrt[4]{27}-\sqrt{2\sqrt{3}+1}}}$$
So it is a pretty long and complicated problem. I got stuck though. My idea was to turn $\sqrt[4]{27} =\sqrt[4]{3}\sqrt{3}$ and since I cant make the second part easier with Langranges formula (it doesn't apply to this) I made it $\sqrt[4]{3}-1$.
I seemed happy that I was getting somewhere and I thought that I had it but later on I just got stuck primarily by the 1's that I don't know what to do with.",['algebra-precalculus']
2498518,How to determine a sample size to get accurate estimates of a given data set?,"I have a question with a statistical nature; I think there should be some standard theory about this issue. Suppose I have a large data set of size $N$ items, which has an amount of $K<N$ unwanted items. I am interested in finding the value of $K$. Testing all items takes too much time, so I want to determine a suitable sample size $n<N$ of randomly selected items in the data set. Suppose I just pick a value for $n$ Then, of a randomly sample data of size $n$, I search for the unwanted items of which there are some amount of $k\leq n$. Let this amount be a test statistic $T$, i.e. I will test on the probability $P(T \geq k)$. I can now find a smallest integer value $K_\min$ such that for the estimation $K = K_\min$ we have $P(T \geq k) \geq \alpha$. That is, for any smaller integer estimation $K<K_\min$ we have $P(T \geq k) < \alpha$. If I am correct, I can now state that with a significance level $\alpha$ we have that $K \geq K_\min$. Is that true? If this is true, the question now is: How accurate is this lower bound? This is also my main question. Based on the amount $n$ and accuracy level $\alpha$, what can we say about the accuracy of $K_\min$. In other words, can we determine some confidence interval on $K$ in relationship to $K_\min$ and $\alpha$? Any tips or other approaches are very much appreciated! Best,
Koen Edit 26 November: Another formulation of the problem as mentioned by David K is as follows: Given some ""error"" tolerance $\varepsilon$, how do we choose $n$ for a given $\alpha$ such that we can guarantee that $|K_\min−K|/N\leq \varepsilon$ (or some assurance like that)?","['statistics', 'sampling', 'data-analysis', 'sampling-theory']"
2498522,Inverse image of a sub manifold - Transversal intersection,"Suppose $N,M$ are smooth manifolds and  $f:N\rightarrow M$ is a smooth map intersecting transversally with a submanifold $S$ of $M$. The question is to prove that $f^{-1}(S)$ is a smooth submanifold of $N$. There is a proof in Lee’s smooth manifolds book but that seems to be incomplete or I am misunderstanding something. The idea given there is to somehow show that $f^{-1}(S)$ is a regular level set of  some smooth map $N\rightarrow M’$ for some smooth manifold $M’$. As $S$ is an embedded submanifold, it is locally a regular level set i.e., given $p\in S$ there exists open $U$ in $M$ containing $p$ and a smooth map $\varphi :U\rightarrow \mathbb{R}^k$ such that $U\cap S=\varphi^{-1}(0)$. We then have $f^{-1}(U\cap S)=f^{-1}\varphi^{-1}(0)=(\varphi\circ f)^{-1}(0)$. By $f$ in $\varphi\circ f$ I mean restriction of $f$ to $\varphi^{-1}(U)$. This would only tell me (after proving that $0$ is a regular value for composition) that $f^{-1}(U\cap S)=f^{-1}(U)\cap f^{-1}(S)$ is a submanifold of $f^{-1}(U)$. I do not see why this would imply $f^{-1}(S)$ is a submanifold of $N$. Is it that straightforward? Any suggestion is welcome.","['transversality', 'smooth-manifolds', 'differential-geometry']"
2498536,How much does continuity correction improve the normal approximation of binomial?,"From the central limit theorem, we know that $(\text{Bin}(n,p)-np)/\sqrt{npq}$ is approximately normal, with $q=1-p$. The Berry-Esseen theorem gives an upper bound for the error of this approximation: 
$$
\sup_{x\in \mathbb R}\left|\mathbb P\left(\frac{\text{Bin}(n,p)-np}{\sqrt{npq}}\le x\right)-\Phi(x)\right|\le \frac{C(p^2+q^2)}{\sqrt{npq}}\le \frac{1}{\sqrt{npq}}\tag{$*$}
$$
Furthermore, this estimate is optimal up to a constant, because the largest point probability for $\text{Bin}(n,p)$ is on the order of $1/\sqrt{2\pi npq}$. However, it is common practice to use a ""continutity correction"" when approximating a binomial distribtuion by a normal. I was wondering whether this correction leads to significant improvements in the error. That is, are there any convenient upper bounds for 
$$
\sup_{k\in \mathbb Z} \left|\mathbb P\left(\text{Bin}(n,p)\le k\right)-\Phi\left(\frac{k+\frac12-np}{\sqrt{npq}}\right)\right|
$$
which are better than ($*$)?","['probability-theory', 'normal-distribution', 'probability-distributions']"
2498571,How do I solve $xy'= x^2+y^2$?,"I have: $$xy'= x^2+y^2$$ I tried to separate variables but it did not work, checked if it could be homogeneous equation but it is not (obiviously), all my transformations did not give me linear equation, so I have no clue how to approach it now :(",['ordinary-differential-equations']
2498581,Function composition and the identity function.,"Define f to be a function whose domain is $X$ and whose target is $Y$ such that $X ∩ Y = ∅$. For each of the following functions, indicate whether the function is well-defined. If your answer is ""well-defined"", indicate how the function relates to f. (a) $f \circ I_X$: well-defined because $f(X ->X)$ maps all elements in X to X (b) $f \circ I_Y$: well-defined because $f(X ->X)$ maps all elements in Y to Y (c) $I_X \circ f$: how would this work? (d) $I_Y \circ f$: how would this work I'm not really sure if my reasoning is correct for the first two. My understanding of the identity function $I_X$ is that it means $X->X$ for all elements in $X$? Is that correct, and are the answers above correct? I also don't know how to interpret and approach c and d, any help or explanation is appreciated. Thanks","['functions', 'discrete-mathematics']"
2498587,Invariant products of holomorphic differentials,"Let $C$ be a smooth projective curve over $\mathbb{C}$ with automorphism group $G$. Is there a nice way to describe which products of holomorphic differentials on $C$ are invariant under the action of $G$? If we're just looking for $G$-invariant holomorphic differentials in general, then these correspond to holomorphic differentials on the quotient $C/G$ (which you can describe in terms of the degree of the projection map and the ramification divisor using the Riemann-Hurwitz formula). However, invariant products aren't necessarily products of invariant differentials. Finally, is there a nice way to estimate the terms involved in the Riemann-Hurwitz formula (e.g. in terms of the signature of the group action)?",['algebraic-geometry']
2498616,Diffeomorphism group and covering spaces,"Let $M$ be a smooth manifold and Diff($M$) be its diffeomorphism group. Let $N\to M$ be a finite cover (for example an orientable double cover if $M$ is not orientable). Then what is the relation between Diff($N$) and Diff($M$? Is it true for example that Diff($N$) injects in Diff($M$)? If the cover is canonical in some sense (e.g. universal), is it true that the action of any group on $M$ lifts to $N$?","['algebraic-topology', 'differential-geometry', 'differential-topology']"
2498618,Calculate the derivative of $f$. Let $f(x)=\sqrt{1+|x|^2}$ for $x\in H$ a real Hilbert space.,"Let $f:H\to H,\, x\mapsto x/\sqrt{1+|x|^2}$ for $H$ a real Hilbert space. Calculate the derivative of $f$. I want to confirm if my calculation is correct. Setting $g(x):=(1+(x|x))^{-1/2}$ we have that $f(x)=g(x)\cdot x$ where the dot means the scalar multiplication in $H$ (not the inner product, just the product of a real number by a vector). Then applying the product rule we find $$\partial f(x)h=\partial g(x)h\cdot x+g(x)\cdot h,\quad x,h\in H$$ where $\partial g(x)h=-(1+|x|^2)^{-3/2}(x|h)$. Is that correct or there is something wrong? Thank you in advance.","['derivatives', 'real-analysis', 'hilbert-spaces', 'proof-verification', 'analysis']"
2498628,Proof only by transformation that : $ \int_0^\infty \cos(x^2) dx = \int_0^\infty \sin(x^2) dx $,"This was a  question in our exam and I did not know which change of variables or trick to apply How to show  by inspection ( change of variables or whatever trick  ) that $$ \int_0^\infty \cos(x^2) dx = \int_0^\infty \sin(x^2) dx \tag{I} $$ Computing the values of these integrals are known as routine. Further from their values, the equality holds. But can we show equality beforehand? Note : I am not asking for computation since it can be found here and we have as well that, $$ \int_0^\infty \cos(x^2) dx = \int_0^\infty \sin(x^2) dx =\sqrt{\frac{\pi}{8}}$$ and the result can be recover here, Evaluating $\int_0^\infty \sin x^2\, dx$ with real methods? . Is there any trick to prove the equality in (I) without computing the exact values of these integrals beforehand?","['fresnel-integrals', 'calculus', 'complex-analysis', 'integration', 'analysis']"
2498629,How can I find the inverse of $f(x) = 7 + 5x^3 + x^7$?,"Let $f(x) = 7 + 5x^3 + x^7$. What will the inverse of $f(x)$ be? How do I isolate $x$? I'm not being able to group $x$ together And then how do I find 
$(f^{-1})''(1)$?","['derivatives', 'inverse-function', 'calculus']"
2498701,Subspaces of matrices whose determinant is $0$,"Consider matrices of size $n\times n$ over finite field $\mathbb{F}_2$. It is linear space of dimension $n^2$. \begin{bmatrix}
    x_{11}       & x_{12}  & \dots & x_{1n} \\
    x_{21}       & x_{22}  & \dots & x_{2n} \\
     \\
    x_{n1}       & x_{n2}  & \dots & x_{nn}
\end{bmatrix} Now consider set of matrices for which some fixed rows are linearly dependent. For example: let $L$ is set of matrices for which first two rows are the same. It is clear that $L$ is a linear subspace of dimension $n^2-n$ and for all matrices of $L$ determinant is equal to $0$. I am interested if the opposite is true. Let $L$ is subspace of dimension $n^2-n$ and determinant is $0$ for all matrices of $L$. Can we say that we can fix some set of rows which are linearly dependant for all matrices of $L$. One can see that there are $2^n-1$ linear combination of rows. So the question is if there are any other subspaces of dimension $n^2-n$ whose determinant is $0$ or each of such subspaces is identified by some linear combination of rows.","['matrices', 'linear-algebra', 'determinant']"
2498708,Cancellation law in a ring without unity,"When discussing rings, integral domains, fields etc, I'm told that the cancellation law holds in any ring that has no zero divisors. By cancellation law, I mean that if we have no zero divisors, we can look at the equation $ab = ac$ and ""cancel"" the a on the left-hand side, and thus know that $b=c$. (I believe that the proof of this comes out of saying that $(ab-ac) = a(b-c) = 0$ thus implying that $(b-c) = 0$ if $a \neq 0$, and so $b=c$). What I'm confused about, is that the requirement for the cancliation law is simply that our ring has no zero divsors, there's no mention of our ring containg unity. However, if our ring doesn't contain unity, but the cancellation law holds, then what can we make of the equation $a^2 = a$? Every time I try to simplify this, I find the need to use unity, which I don't believe I am guaranteed to have in my ring. Does saying that our ring has no zero divisors, in fact, imply that our ring contains unity? Can somone help explain/correct this apparent paradox for me please?","['abstract-algebra', 'ring-theory', 'integral-domain', 'inverse']"
2498739,"""Class"" of functions whose inverse, where defined, is the same ""class""","Please excuse the amateurish use of the term ""class"", I don't know what the exact term is for what I'm looking for. Anyway, details. I'm asking specifically about real-valued functions on the real domain ($\mathbb{R}\to\mathbb{R}$).  To keep things simple, let's assume that the function is defined on some interval of interest, and is continuous and strictly monotonic in that interval, so that there is an inverse function that's also continuous and monotonic. I am looking for a ""class"" of functions where the inverse is of the same ""class"".  By ""class"", I mean a set of functions with a finite number parameters that, if you changed them, the function would still be in the same ""class"".  (An obvious example of what I mean by a ""class"" is the polynomials: you can change the coefficients but the function is still a polynomial.)  Again I apologize if this is omitting a detail or if there's a nice little word for this that I don't know. I know of a few examples of ""classes"" that meet these criteria, including: Linear functions Piecewise linear functions Polynomials, of course, do not fit this criteria in general: the inverse of a polynomial is generally not a polynomial.  I don't think rational functions do either, but I'm not sure. For the record, I am asking partly out of curiosity, and partly because I have a nice application in mind.  I have a application where I need a function that can approximate a curve with perfect round-tripping ($f(f'(x))=x$, exactly).  We're using piecewise linear approximation for now, but it's desirable to be smooth as well. Thanks.","['applications', 'inverse-function', 'functions']"
2498818,On existence of boards that be covered by every free tetromino,"There is a board which can be covered by each of five free tetrominoes: However, it's not simply-connected (has a hole). I wonder if there is a simply-connected board with the same property.","['combinatorics', 'combinatorial-geometry', 'tiling']"
2498832,Concerning this integral $\int_{0}^{1}\left({1\over \ln(x)}+{1\over 1-x} -{x^s\over 2}\right){\mathrm dx\over 1-x}$,"Motivation from this question $(1)$ $$\int_{0}^{1}\left({1\over \ln(x)}+{1\over 1-x} -{1\over 2}\right){x^s\over 1-x}\mathrm dx=F(s)\tag1$$ setting $s=0$ then $F(0)=-{1\over 2}+{1\over 2}\ln(2\pi)-{1\over 2}\gamma$ by a slight variation of $(1)$, we have $$\int_{0}^{1}\left({1\over \ln(x)}+{1\over 1-x} -{x^s\over 2}\right){\mathrm dx\over 1-x}={1\over 2}H_s-{1\over 2}+{1\over 2}\ln(2\pi)-{1\over 2}\gamma\tag2$$ $H_s$ is the harmonic number , $H_0=0$ How do we go about to prove $(2)?$",['integration']
2498864,Can the infinite sum $\sum_{n=0}^\infty {2^n \sum_{k=0}^n (-1)^k \frac{ {{n}\choose{k}}}{ (n+k)! }}$ be simplified?,"EDIT2: I have made this related question for general $n$ (in this question $n=2$). Can the sum $$S = \sum_{n=0}^\infty  {2^n \sum_{k=0}^n (-1)^k \frac{ {{n}\choose{k}}}{ (n+k)! }}$$ be simplified? I think the inner sum $ b_n = \sum_{k=0}^n (-1)^k \frac{ {{n}\choose{k}}}{ (n+k)! }$ equals the integral $$\int_{0}^1 (1-x_1) \int_{0}^{1-x_1} (1-x_2) \dots \int_{0}^{1-\sum_{j=1}^{n-1} x_j} (1-x_n) dx_n\dots dx_2dx_1$$ since I calculated it for some values of $n$ and found OEIS A006902 . Is this equality true? EDIT: Hypothesis: $S$ equals the limit (as $M\to \infty$) of the sum of the first column of the matrix $$
A_M = -M^2
\begin{pmatrix}
-M^2 &  &  \\
2M-1 & -M^2  &  \\
2M-3 & 2M-1 & -M^2  \\
\vdots & \vdots & \vdots & \ddots  &  \\
5 & 7 & 9 & \dots & -M^2  & \\
3 & 5 & 7 & \dots & 2M-1 & -M^2
\end{pmatrix}^{-1}
$$ The matrix $A_M$ has $-M^2$ on the diagonal (or equivalently $1$ if the multiplier $-\frac{1}{M^2}$ is put inside the inverse and multiplied into the matrix) and then on the lower diagonals the odd numbers starting from $2M-1$ down to $3$. I guess (from calculating these for some values of $M$) that the first column of $A_M$ is $\left(1, \frac{\alpha_2}{M^2}, \frac{\alpha_3}{M^4},\dots \frac{\alpha_M}{M^{2(M-1)}} \right)$, where the $\alpha$'s are some natural numbers (for example for $M=5$ they are $(1,9, 256, 7004, 182836)$ ($\alpha_1 = 1$ always)). A WA calculation . It also seems that  $\alpha_2 = 2M-1$ and $\frac{\alpha_j}{\alpha_{j-1}} \to M^2$.","['definite-integrals', 'sequences-and-series']"
2498895,Prove that $A \times B = B \times A $ if and only if $A = B \lor A = \emptyset \lor B = \emptyset$ [duplicate],"This question already has answers here : If $A$ and $B$ are nonempty sets, prove that $A \times B = B \times A$ if and only if $A = B$ (4 answers) Closed 6 years ago . Prove that $A \times B = B \times A $ if and only if $A = B \lor A =  \emptyset \lor B = \emptyset $ So, I need to prove that 
$$A\times B = B \times A \iff A = B \lor A = \emptyset \lor B = \emptyset$$
It is easy to show the right-to-left implication. The problem begins when I want to show the left-to-right one. I tried using the axiom of extentionality, but that did not work. What kind of trick should I use to prove that the relation from left to right holds as well?",['elementary-set-theory']
2498898,If $N\lhd G$ then $n_p(G/N) \leq n_p(G)$.,"I want to prove the above statement where $N$ is a normal subgroup of $G$, and $n_p(G) = \vert Syl_p(G)\vert$, i.e. the number of Sylow $p$-subgroups of $G$. I am quite stuck on this problem. My initial thought was to define a map from the Sylow $p$-subgroups of $G$ to those of $G/N$ and then show that the map is surjective, but this turns into a gargantuan mess with a ton of Lagrange cardinality and divisibility arguments and such, and does not quite get me what I want to show anyway even with a substantial amount of hand-waving. Any suggestions? I also naturally thought about trying to prove it indirectly by way of contradiction, though I really am not certain how to even begin to go about it that way.","['abstract-algebra', 'sylow-theory']"
2498922,Is a quotient group a subgroup? [closed],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Is a quotient group a subgroup? I am trying to solve the question below, and if the answer to above is ""yes,"" then my proof will follow below. I am trying to prove that a cyclic group G, has a cyclic quotient group G/N. 
Where N is a normal subgroup. A SUBGROUP OF A CYCLIC GROUP IS CYCLIC. 
By https://proofwiki.org/wiki/Subgroup_of_Cyclic_Group_is_Cyclic So if (1) G is cyclic (2) G/N is a subgroup (3) G/N is a cyclic subgroup (4) The Quotient group G/N is cyclic I am unsure about my reasoning in step (2), Is this a valid assumption?","['group-theory', 'quotient-group']"
2498947,"Weierstrass M-test, Banach spaces, and absolute convergence","As per the Weiestrass M-test, if absolute convergence of the series associated with a sequence in some normed vector space $X$ implies convergence of the series, then $X$ is Banach. However, I think it can be proved that if a series converges absolutely then it necessarily converges. So what is the point I'm missing here?","['real-analysis', 'banach-spaces', 'functional-analysis', 'convergence-divergence', 'sequences-and-series']"
2498981,Distribution of the sample mean with multiple population definitions,"The time taken by a randomly selected applicant for a mortgage to fill out a certain form has a normal distribution with mean value 10 min and standard deviation 2 min. If five individuals fill out a form on one day and six on another, what is the probability that the sample average amount of time taken on each day is at most 11 min? In an attempt to work out the problem, I started by identifying the known variables: $X$: the time taken by a randomly selected applicant for a mortgage to fill out a certain form (that is, one form) $\mu_{X}=10$ $\sigma_{X}=2$ Now, there are obviously more variables but this is where it starts to get a bit confusing for me. In the first part of the problem, $X$ clearly refers to the time it takes to fill out a single form. But in the second part of the problem, the population ($n=5$) fills out a different number of papers on each day, changing the population the question at the end of the problem is addressing. Presumably, there is some other population $Y$ and I'm looking for $P(\overline{Y}\leq11)$. Figuring out what population $Y$ encompasses and how to set up the solution is where I'm stumped. Any nudge in the right direction is greatly appreciated.","['means', 'statistics', 'normal-distribution', 'probability-distributions']"
2499026,"If $\mu$ is absolutely continuous wrt $\nu$, then $\frac{{\rm d}\mu}{{\rm d}v}(t)=\liminf\frac{\mu((r,t])}{\nu((r,t])}$","I've read that if $\mu$ and $\nu$ are finite measures on $[0,\infty)$ (equipped with arbitarary, different, $\sigma$-algebras or both with the Borel $\sigma$-algebra?) and $\mu$ is absolutely continuous with respect to $\nu$, then $$\frac{{\rm d}\mu}{{\rm d}v}(t)=\liminf_{r\uparrow t}\frac{\mu((r,t])}{\nu((r,t])}$$ for $\nu$-almost all $t>0$, where the limit inferior is taken with respect to $r<t$, $r$ rational. How can we prove that?","['reference-request', 'real-analysis', 'measure-theory']"
2499036,l'Hôpital vs Other Methods,"Consider the first example using repeated l'Hôpital: $$\lim_{x \rightarrow 0} \frac{x^4}{x^4+x^2} = \lim_{x \rightarrow 0} \frac{\frac{d}{dx}(x^4)}{\frac{d}{dx}(x^4+x^2)} = \lim_{x \rightarrow 0} \frac{4x^3}{4x^3+2x} = ... =  \lim_{x \rightarrow 0}\frac{\frac{d}{dx}(24x)}{\frac{d}{dx}(24x)} = \frac{24}{24}=1 $$ Consider the following example using a different method: $$ \lim_{x \rightarrow 0} \frac{x^4}{x^4+x^2} = \lim_{x \rightarrow 0}\frac{\frac{x^4}{x^4}}{\frac{x^4}{x^4}+\frac{x^2}{x^4}} = \lim_{x \rightarrow 0} \frac {1}{1 +\frac{1}{x^2}} = \frac {1}{1+\infty} = \frac{1}{\infty}=0 $$ The graph here clearly tells me the limit should be $0$, but why does l'Hôpital fail?","['calculus', 'limits']"
2499149,Question about math notiations and functions,"If you have a function for example $f(x) = x^2$
Say you insert $-5$ in to the function you get $f(-5) = (-5)^2$, how do you know when to use certain math notations? In this case, parentheses. So say I would like to make a function and make sure there should be no parentheses when you input $-5$, to make it $f(-5) = -5^2$ how do I do that?","['algebra-precalculus', 'notation', 'functions']"
2499171,Rigid motion vs Isometry,"Does anyone know the difference between rigid motion and isometry? In the real plane these two definitions coincide, but do always coincide?","['isometry', 'real-analysis', 'rigid-transformation', 'geometry']"
2499202,Understanding time reversal symmetry in differential equations,"(In Strogatz' Nonlinear dynamics and chaos, page 163) I've read that any mechanical system of the form: $mx'' = F(x)$ is symmetric under time reversal. The author notes that if we make the change t -> -t that the second derivative is unchanged while the first derivative is reversed. My first question is that I see that $x(-t)'$ = $-x(-t)'$ 
and $x(-t)''$ = $x(-t)''$, however, I'm not quite clear why exactly the mapping t -> -t is of interest to us. If the idea is to reverse time, then we would want to start at the end of our motion and work backwards along the trajectory we originally came in on. Suppose our original trajectory goes from time t = $t_1$ to t = $t_9$. So x(-t) will map the largest t value in our original trajectory to the ""farthest left"" t value on the negative x-axis. Does that mean after we flip our trajectory over the y-axis that we are now interested in the dynamics of a path in the time range t = -9 to t = -1? It seems a bit odd that we would now be looking at a time range over negative time values. Is this a correct interpretation? Is there a better way to look at it? Thanks.","['ordinary-differential-equations', 'calculus']"
2499215,Sum of $\frac{1}{1\times3\times5}+\frac{1}{3\times5\times7}+\cdots + \frac{1}{13\times15\times17}$,"I solved like this, but it took me lots of time and I have to use the calculator. But in exam I can't use the calculator and I need to be fast. (1) Is there any alternative to solve this easily? (2) How to solve this if given for $n$ terms? My work: 
\begin{align}
\frac{1}{1\times3\times5}&+\frac{1}{3\times5\times7}+\cdots +\frac{1}{13\times15\times17}\\
&=\frac{1}{1\times3\times5}+\frac{1}{3\times5\times7}+\frac{1}{5\times7\times9}+\frac{1}{7\times9\times11}+\frac{1}{9\times11\times13}\\
&\ \ \ \ \ +\frac{1}{11\times13\times15}+\frac{1}{13\times15\times17}\\
&=\frac{1}{15}[1+1/7+1/21]+\frac{1}{11\times9}[1/7+1/13]+\frac{1}{15\times17}[1/11+1/17]\\
&=7/85
\end{align}","['algebra-precalculus', 'sequences-and-series']"
2499216,Legendre Polynomial Orthogonality Integral,"I want to show that $$\int_{-1}^{1}L_n(x)L_m(x)dx$$ is zero for $m<n$ and $\frac{2}{2n+1}$ for $m=n$. For $m<n$, I want to apply $(x^2-1)^n=(x-1)^n(x+1)^n$ and integration by parts. For $m=n$ it should be possible to use the substitution $y=\sqrt{x}$. Some relevant formulae: $$\text{Rodrigues' formula:}\hspace{.4cm} L_n(x)=\frac{1}{2^nn!}\frac{d^n}{dx^n}[(x^2-1)^n]$$ $$\text{Beta Integral:}\hspace{.4cm}\int_{0}^{1}x^{\alpha-1}(1-x)^{\beta-1}dx=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$$ $$\text{Gamma identities:}\hspace{.4cm}\Gamma(x+1)=x\Gamma(x),\hspace{.2cm}\Gamma(n+1)=n!$$
For $m=n$, $$I_n=\int_{-1}^{1}L_n^2dx=(\frac{1}{2^{n}n!})^2\int_{-1}^{1}\Big(\frac{d^n}{dx^n}\big[(x^2-1)^n\big]\Big)^2dx= \big(\frac{1}{2^{n}n!}\big)^2\Big[\frac{d^{n-1}}{dx^{n-1}}[(x-1)^n(x+1)^n]\frac{d^n}{dx^n}[(x-1)^n(x+1)^n]\Big\rvert_{-1}^{\hspace{.2cm}1}-\int_{-1}^{1}\frac{d^{n-1}}{dx^{n-1}}[(x-1)^n(x+1)^n]\frac{d^{n+1}}{dx^{n+1}}[(x-1)^n(x+1)^n]\Big]$$
I'm not sure where to where to go from here. Is there something that should cancel? Is there a way to do iterative integration by parts here? How do I get to $\frac{2}{2n+1}$? --------------------------EDIT------------------------- I finally got it. Here is the proof. We want to prove the orthogonality relation $I$ defined by \begin{equation}
I = \int_{-1}^{1}L_n(x)L_m(x)dx
\end{equation} is zero for $m\neq n$ and $\dfrac{2}{2n+1}$ for $m=n$. In $I$, we can use Rodrigues' formula to express $L_n$ as \begin{equation}
L_n(x)= \frac{1}{2^nn!}\frac{d^n}{dx^n}\big[(x^2-1)^n\big]
\end{equation}
and apply integration by parts, $\int u'v=uv-\int uv'$. \begin{equation}
\begin{split}
I= \frac{1}{2^nn!}\int_{-1}^{1}\Big(\frac{d^n}{dx^n}\big[(x^2-1)^n\big]L_m(x)\Big)dx \\ =\frac{1}{2^nn!} \Bigg(\frac{d^{n-1}}{dx^{n-1}}\big[(x^2-1)^n\big]L_m(x) \biggr\rvert_{-1}^{1} - \int_{-1}^{1}\frac{d^{n-1}}{dx^{n-1}}\big[(x^2-1)^n\big]L_m^{(1)}(x)dx  \Bigg) \\
= -\frac{1}{2^nn!} \int_{-1}^{1}\frac{d^{n-1}}{dx^{n-1}}\big[(x^2-1)^n\big]L_m^{(1)}(x)dx
        \end{split}
\end{equation} Repeated integration by parts $n$ times leaves only \begin{equation}
\begin{split}
I= (-1)^n\frac{1}{2^nn!}\int_{-1}^{1}(x^2-1)^nL_m^{(n)}(x)dx
        \end{split}
\end{equation} As $L_m$ has polynomial degree $m$, it will become a constant upon differentiation $m$ times. Since $m<n$, $L_m^{(n)}=0$, so $I=0$ for $m<n$. Since the same argument can be made for $L_n$ when $n<m$, $I$ is always zero for $m\neq n$. For the case $m=n$, \begin{equation}
\begin{split}
I= (-1)^n\frac{1}{2^nn!}\int_{-1}^{1}(x^2-1)^nL_n^{(n)}(x)dx \\
= (-1)^n\frac{1}{2^n n!}\int_{-1}^{1}(x^2-1)^n  \frac{d^{2n}}{dx^{2n}}\big[(x^2-1)^n\big] dx \\ =(-1)^n\frac{1}{2^{2n} (n!)^2}\int_{-1}^{1}(x^2-1)^n (2n)!dx \\
=\frac{(2n)!}{2^{2n} (n!)^2}\int_{-1}^{1}(1-x^2)^ndx
    \end{split} 
\end{equation} Considering only the integral $J=\int_{-1}^{1}(x^2-1)^ndx$, use the substitution $x=\sqrt{y}$. \begin{equation}
\begin{split}
J=2\int_{0}^{1}(1-y)^n \cdot \frac{1}{2\sqrt{y}}dx
    \end{split}
\end{equation} Letting $\beta=n+1, \alpha=\frac{1}{2}$ and applying the Beta integral, \begin{equation}
\begin{split}
J=\frac{\Gamma(\frac{1}{2})\Gamma(n+1)}{\Gamma(n+\frac{3}{2})}
    \end{split}
\end{equation} Using the given Gamma identity for integers, \begin{equation}
\begin{split}
\Gamma(n+\frac{3}{2})=(n+\frac{1}{2})\Gamma(n+\frac{1}{2}) \\
= (n+\frac{1}{2})(n-\frac{1}{2})(n-\frac{3}{2})\cdot\cdot\cdot\frac{1}{2}\Gamma(\frac{1}{2})
    \end{split}
\end{equation} and since $\Gamma(n+1)=n!$ we get \begin{equation}
\begin{split}
J=\frac{n!}{(n+\frac{1}{2})(n-\frac{1}{2})(n-\frac{3}{2})\cdot\cdot\cdot\frac{1}{2}}
    \end{split}
\end{equation} Then \begin{equation}
\begin{split}
I=\frac{(2n)!}{2^{2n} (n!)^2}\cdot\frac{n!}{(n+\frac{1}{2})(n-\frac{1}{2})(n-\frac{3}{2})\cdot\cdot\cdot\frac{1}{2}} \\
=\frac{1}{(n+\frac{1}{2})}\frac{(2n)!}{2^{2n}n!(n-\frac{1}{2})(n-\frac{3}{2})\cdot\cdot\cdot\frac{1}{2}} = \frac{1}{\frac{2n+1}{2}}= \frac{2}{2n+1}
    \end{split}
\end{equation} So \begin{equation}
I = \int_{-1}^{1}L_n(x)L_n(x)dx = \frac{2}{2n+1}
\end{equation}","['legendre-polynomials', 'integration', 'orthogonality', 'orthogonal-polynomials']"
2499234,Ideal Generated by a Finite Number of Polynomials?,"Background I have been confused about a particular definition in the textbook for my abstract algebra class, Ideals, Varieties, and Algorithms by Cox, Little, and O'Shea.  It is frustrating because I feel that I have a partial grasp on what the definition is trying to say, but when it comes down to it I simply find my confused.  So, instead of suffering by myself for any longer with this definition, I have decided to turn to you lovely folks to help me understand this seemingly simple concept. What I Understand First off, I understand (at least in the context of this book) what an ideal is.  The definition my book gives for an ideal is Definition. A subset $I\subseteq k[x_1,..., x_n]$ is an ideal if it satisfies: (i) $0\in I$ . (ii) If $f,g\in I$ , then $f+g\in I$ . (iii)  If $f\in I$ and $h\in k[x_1,...,x_n]$ , then $hf\in I$ . I find this to be a simple, easy to understand definition.  My problem, however, arises a few lines later when they define an ideal generated by a finite number of polynomials. What I Don't Understand And now, I give you the definition that has been causing me an incredible amount of confusion and frustration. Definition. Let $f_1,...,f_s$ be polynomials in $k[x_1,...,x_n]$ .  Then we set $$\langle f_1,...,f_s \rangle=\Big\lbrace \sum_{i=1}^s h_if_i \ | \ h_1,...,h_s\in k[x_1,...,x_n] \Big\rbrace.$$ I know what you are thinking. How does he not understand this ?  I wish I knew the answer to that question, but in the meantime, can someone please help me visualize what this set looks like?  I understand that $\langle f_1,...,f_s \rangle$ is an ideal, but I don't understand its structure, if that makes sense.  In other words, I can't visualize this definition in a way that makes sense to me.  The authors do make a slightly helpful note, saying that ""we can think of $\langle f_1,...,f_s \rangle$ as consisting of all 'polynomial consequences' of the equations $f_1=f_2=...=f_s=0$ ."" To elaborate a little more on my confusion, what I'm asking for is a less ""compact"" definition.  When I read this definition, for whatever reason the only thing I can come up with is $$f_1h_1+f_2h_2+...+f_sh_s.$$ But that doesn't make sense, because $\langle f_1,...,f_s \rangle$ is supposed to generate a set , not just a single polynomial. As always, thank you all for your time.  If you find this to be a stupid or silly question, then I'm sorry to have disappointed you -- I'm a slow learner, and I get hung up on stupid things sometimes. Oh, and Happy Halloween!","['abstract-algebra', 'ideals', 'definition']"
2499258,"Given the ratios of distances from three corners of a rectangle, find the coordinates of a point with said ratios.","I think the picture can explain it better than words, but I'm wondering how to figure this out. Given three ratios of distances from corners, not lengths (in the picture I set the base, $base=1$, to be the distance from the top left corner, while the other two corners are of lengths $\alpha\cdot$$base$ and $\beta\cdot$$base$) and given the height $H$ and width $W$ of a rectangle, what are the coordinates of a point with said ratios? I'm sure the Apollonian Theorem comes into play, but I can't quite figure it out. Thanks!","['ratio', 'trigonometry', 'algebraic-geometry', 'geometry']"
2499263,How to find remainder when determinant is divided by 5,"$$A= \begin{vmatrix}
2014^{2014} &  2015^{2015} & 2016^{2016}\\ 
         2017^{2017} &  2018^{2018} & 2019^{2019} \\
         2020^{2020} &  2021^{2021} & 2022^{2022}
\end{vmatrix}$$ I thought I would have to find the value if the determinant, but it is obviously too large to be found. Is there a shortcut to solving this?","['algebra-precalculus', 'number-theory', 'determinant']"
2499305,Show that the total space $E$ of a fibre bundle $\pi : E \rightarrow M$ is connected.,"Let $(E,\pi,M,F)$ is a fibre bundle. The map $\pi : E \rightarrow M$ is the projection map. The smooth manifolds ; $E$ is the total space, $M$ is the base space, and $F$ is a smooth manifold appear in the following local trivialization : For any $p \in M$, there are open subset $U\subset M$ contain $p$ and diffeomorphism $$\phi : \pi^{-1}(U) \rightarrow U \times F$$ such that $\pi = Proj_U \circ \phi$ on $\pi^{-1}(U)$, where $Proj_U : U \times F \rightarrow U$ is the projection to the first factor. $\textbf{Problem}$ : If $M$ and $F$ connected, show that $E$ is connected. I already make such construction, but i'm not really sure and curious about other solution too. Feel free to post new proof or disprove my proof : I'm having hard time with this, but i end up trying to prove this by using the following theorem from topology (e.g from Willard's book theorem 26.15 ) : If a topological space $X$ is connected and $\mathscr{U}$ is an open cover for $X$, then any two points can be connected by a simple chain consisting of elements of $\mathscr{U}$. By local trivialization for each $p \in M$ we have an open subset $U \subset M$ containing $p$ and a diffeomorphism $\phi : \pi^{-1}(U) \rightarrow U \times F$. Let $\{\pi^{-1}(U)\}$ be the open cover for $E$. Because $F$ and $M$ connected, then  $U\subset M$ connected, $U \times F$ connected, $\phi^{-1}(U\times F) = \pi^{-1}(U)$ connected. With this open cover, we have a simple chain where each of its elements is connected (implies path-connectedness). By this we can easily make a path connecting $v,w \in E$ by joining the paths from each chain.","['general-topology', 'fiber-bundles', 'smooth-manifolds', 'connectedness']"
2499347,"show that:for every $x\in S$, there exsit $y,z,w\in S$, such $x=y^2+z^2+w^2$ [closed]","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Define $S=\{a+b\cdot\dfrac{-1+\sqrt{3}i}{2}|a,b\in Z\}$. Show that for every $x\in S$, there exit $y,z,w\in S$,such
$$x=y^2+z^2+w^2$$where $i$ such  $i^2=-1$ My attempt: Since
$$\left(a+b\dfrac{-1+\sqrt{3}i}{2}\right)^2=\left(a^2-ab-\dfrac{1}{2}b^2\right)+\dfrac{\sqrt{3}}{2}b(a-b)i$$",['number-theory']
2499365,How many walks of length 3 are there between two distinct vertices in a complete graph?,"Let $v,w$ be two distinct vertices in the complete graph $K_n$, where $n \geq 3$. How many walks of length 3 are there from $v$ to $w$? It is explained as follows. Let $v, x, y, w$ be walk of length 3 from $v$ to $w$. If $x=w$ then there are $n-1$ choices for $y \neq w$. if $x \neq w $ then there are $n-2$ choices for $x \neq v, w$. So, total the number of choices is $n-1 + (n-2)^2 = n^2 -3n +3$. I get the $n-1$ part because a vertex cannot go to itself since there are no loops in a complete graph. But how do we get the other part?","['graph-theory', 'discrete-mathematics']"
2499380,What is an interpretation of the matrix exponential?,"I just read about the existence of the ""matrix exponential"" $$e^X := \sum_{k = 0}^\infty\frac1{k!}X^k$$ Is there a simple way to interpret this? I understand the analog between  real number exponentials as infinite Taylor expansions. However, I have no easy way of interpreting in the case of a matrix. I've read that it relates to linear ODE's","['matrices', 'matrix-exponential', 'exponentiation']"
2499403,"Limit of $\frac{f(2x)-f(x)}{f(3x)-f(x)}$ when $x\to0$, for $f$ twice continuously differentiable in a neighborhood of $0$","Let $f$ be a two times continuously differentiable function in a neighborhood of $x=0$. Find
  $$\lim_{x \to 0} \frac{f(2x)-f(x)}{f(3x)-f(x)}$$
  when, a. $f'(0)\neq 0 $ b. $f'(0)= 0 $ but $f''(0)\neq 0 $ Thoughts, I feel like this should be a straightforward question but I'm not sure how for example, how to use the conditions to find the limit.  Like for example for a, how does the derivative at $0$ not equalling $0$ help me get the limit. I was thinking of using L'Hopital's Rule as I get $0/0$ when I plug in.
If I use it, I take derivative of top and bottom and get 
$$\frac{2f'(2x)-f'(x)}{3f'(3x)-f'(x)}.$$ Plugging in 0 I get, $(2f'(0)-f'(0))/(3f'(0)-f'(0))$.  For part a, I know $f'(0)$ does not equal 0. So I get $f'(0)/2f'(0)$  I know $f'(0)$ is just some number not equal to 0 so I get limit equal to $1/2$. For part b, I will have to do L'Hopital's Rule twice so I get taking first derivative:
$$\frac{2f'(2x)-f'(x)}{3f'(3x)-f'(x)}$$. Plug in, I still get $0/0$.  I take a second derivative and get :
$$\frac{4f''(2x)-f''(x)}{9f''(3x) -f''(x)}.$$  Plug in 0, I get $(4f''(0)- f''(0))/(9f''(0)-f''(0))$ So limit is $3/8$. I have no idea if this is correct, however.","['derivatives', 'real-analysis', 'functions', 'limits']"
2499411,Analysis: Spotting why Proof/Derivation is Wrong (part in which proof is wrong),"I'm having trouble figuring out what the error is in the above derivative.  I have no idea what is happening in the first line, how an application of the Mean Value Theorem gives such an expression to the right.
I just verified, some of the other parts and they seem to be okay as $\lim_{x \to 0} x\sin(1/x)$ is indeed $0$ so limit of $2\xi\sin(1/\xi)$ would also be $0$. So, honestly I'm not sure what the error is in the above derivation. I could really use some help.  Thank you.","['derivatives', 'real-analysis', 'calculus', 'limits']"
2499412,Proof of Riemann's Second Bilinear Relation,"Let $\eta$ be a meromorphic differential and let $\omega$ be a differential with no residue on a Riemann surface $\Sigma$. Let $\mathcal{L}$ be the simply connected domain obtained by cutting $\Sigma$ along a canonical basis $\{a_i, b_i \}$ for its homology and consider the map $\mathfrak{u} : \mathcal{L} \to \mathbb{C}$ given by $\mathfrak{u}(P) = \int_{P_0}^P \omega$. Here, $P_0 \in \mathcal{L}$ is fixed. In ""Riemann Surfaces and Theta Functions"" (page 33), Bertola gives the second Riemann bilinear relation as
$$\sum_{Q = \text{pole of } \eta, \omega} \underset{Q}{Res}\ \mathfrak{u} \eta = \frac{1}{2\pi i}\sum_{i=1}^g \oint_{b_i} \omega \oint_{a_i} \eta - \oint_{b_i} \eta \oint_{a_i} \omega$$
Bertola then claims that this can be proven using the residue theorem. However, I don't see how the residue theorem can be applied and I'm not sure how to approach this proof. Does anyone have any suggestions for how to approach this proof?","['riemann-surfaces', 'complex-analysis']"
2499446,An upper bound on automorphism orbit lengths in nonabelian finite simple groups,"In what follows, for a group $G$, $\operatorname{Aut}(G)$ and $\operatorname{Out}(G)$ denote the automorphism and outer automorphism group of $G$ respectively, and for $x\in G$, $x^G$ and $x^{\operatorname{Aut}(G)}$ denote the conjugacy class and automorphism orbit of $x$ in $G$ respectively, whereas $\operatorname{C}_G(x)$ denotes the centralizer of $x$ in $G$. Question: Is it true that for all nonabelian finite simple groups $S$ and all $x\in S$, one has $|x^{\operatorname{Aut}(S)}|\leq\frac{1}{2}\cdot(|S|-1)$? Some thoughts/remarks: Since $|x^{\operatorname{Aut}(S)}|\leq|\operatorname{Out}(S)|\cdot|x^S|$, for the answer to the Question to be ""yes"" for a given $S$, it is sufficient to have $|x^S|\leq\frac{1}{2|\operatorname{Out}(S)|}\cdot(|S|-1)$, or equivalently, $|\operatorname{C}_S(x)|\geq2\cdot\frac{|S|}{|S|-1}\cdot|\operatorname{Out}(S)|$ for all $x\in S$, so in particular, $|\operatorname{C}_S(x)|\geq\frac{120}{59}\cdot|\operatorname{Out}(S)|=2.033\ldots\cdot|\operatorname{Out}(S)|$ would be sufficient. Using the above considerations and information from the ATLAS, it can be checked that the answer to the Question is ""yes"" for all alternating and sporadic $S$. A Google search for relevant literature has only turned up rather recent lower bounds on the maximum conjugacy class length, such as [2] and [3], and older results on the existence of elements with a large centralizer, such as the ones mentioned in Geoff Robinson's answer to this mathoverflow question . The Question is motivated by a connection between the existence of large automorphism orbits on a finite group $G$ and the largest Hamming distance a function on $G$ can have from the set of affine functions on $G$ (functions of the form $x\mapsto g\varphi(x)$ for $g\in G$ and $\varphi\in\operatorname{End}(G)$ fixed), see [1, Definition 2.8 and Proposition 2.9] if you are interested. References: A. Bors, Worst-case approximability of functions on finite groups by endomorphisms and affine maps, preprint (2017), arXiv:1709.00734 . L. He and W. Shi, The largest lengths of conjugacy classes and the Sylow subgroups of finite groups, Arch. Math. 86 :1-6 (2006). G. Qian and Y. Yang, The largest character degree, conjugacy class size and subgroups of finite groups, to appear in Comm. Algebra , accepted author version .","['finite-groups', 'group-theory', 'simple-groups']"
2499476,How to calculate $\lim_{n \to \infty} \sum_{k=1}^n\binom nk k!k\frac{1}{n^k}$?,"How to calculate this limit :
$$\lim_{n\rightarrow +\infty}u_n$$
with :
$$u_n=\sum_{k=1}^n\binom nk k!k\frac{1}{n^k}$$
We can write this :
$$u_n=\sum_{k=1}^n\frac{n}{n}\times\frac{n-1}{n}\times\cdots\times\frac{n-k+1}{n}\times k$$
But I can't find the solution.","['binomial-coefficients', 'sequences-and-series', 'limits']"
2499485,Solving systems of equation with the unknowns nested in trigonometric functions,"Would be nice, if someone could help me with following systems of equation with the unknowns nested in trigonometric functions. Find the angles $\alpha_1$ and $\alpha_2$ solving the equations $$
\begin{align}
x_1&= \sin(\beta_{11}+\alpha_1)+ \sin(\beta_{21}+\alpha_2) \\
x_2&= \sin(\beta_{12}+\alpha_1)+ \sin(\beta_{22}+\alpha_2).
\end{align}
$$ All $\beta_{ij}$ , $x_1$ , and $x_2$ are known. I tried to apply the idea from http://www.mathcentre.ac.uk/resources/workbooks/mathcentre/web-rcostheta-alphaetc.pdf , but struggled, since the unknowns are nested in the arguments of $\sin$ .
A substitution didn’t worked for me, since then we end up with 4 unknowns.
Any help would be very appreciated.","['trigonometry', 'algebraic-geometry', 'systems-of-equations']"
2499516,Solve the equation $x^2+x+2=2^y$ in positive integers.,"Let $x,y$ are positive integers. Solve the equation $$x^2+x+2=2^y$$ My work so far: $$(2x+1)^2 + 7 = 2^{y+2}$$ If $y$ is even, then $x=1,y=2$ .","['number-theory', 'integers']"
2499522,Describe the movement of a string-pendulum with initial speed $v_0=2\sqrt{gL}$,"I posted this question here (physics.stackexchange) a few days ago, but our fellow physicians did not seem to like the question. I am giving it another try among the community of mathematicians! The question was asked in a written test years ago, in a post graduate course. Therefore I assume it is possible to answer without the help of a computer. Nevertheless, all approaches are welcome. The question is quite straightforward, it's all in the title. Suppose you have a classical pendulum of mass $m$, linked to the frictionless pivot by a weightless string (not the classical rod) of length $L$. The pendulum is initially in vertical position, in its equilibrium position. If you put it in motion with a horizontal speed $v_0=2 \sqrt{gL}$, what happens ? How can the movement be described? I know for a fact (from a simulation) that I need to find the equations of the trajectory in the picture below. That is, the trajectory is circular (in red) up to a certain height, after which it becomes parabolic (in blue). Approach #1: I know the equation describing the movement of a pendulum is 
$$
\frac{d^2 \theta}{d t^2} + \frac{g}{L}\sin \theta = 0,
$$
where $\theta$ is the amplitude of the pendulum. So I suppose one could solve the differential equation numerically with the initial conditions
$$\theta(0)=0,\quad \frac{d \theta}{d t}(0) = \frac{2 \sqrt{gL}}{L}=2 \sqrt{\frac{g}{L}}$$
and find an approximate solution. However, there is no closed form possible, and this was probably not the expected approach in the written exam. This being said, I am interested in knowing if the approach is correct from a theoretical point of view. Approach #2: It is not very difficult to show that the tension of the string is given by
$$
T(\theta) = mg \cos \theta + m L \left(\frac{d \theta}{dt}\right)^2
$$
where again, $\theta$ is the amplitude from the vertical position. Or in terms of $h$, the height of the pendulum (assuming $h=0$ in the initial position):
$$
T(h) = mg \frac{h-L}{L}+ 4mg(1-\frac{h}{2L})
$$ The string becomes slack when $T(h)=0$, i.e., when $ h = \frac{5L}{3}$. At this point, the pendulum is only submitted to its weight, and the trajectory becomes parabolic. Would this be correct? How can we find the height at which the pendulum's trajectory becomes circular again (the bottom left part of the red trajectory in the picture). Any input is welcome. Thanks!","['classical-mechanics', 'physics', 'ordinary-differential-equations']"
2499583,finding a distribution given marginals and correlation matrix,"Given a $2 \times 2$ correlation matrix $A$ and distributions $g(x)$ (say a fixed Gaussian distribution) and $h(y)$(say a fixed exponential distribution), can we find 'a' distribution $f(x,y)$, such that $g(x)$ and $h(y)$ are the marginal distributions of $f(x,y)$ with correlation matrix $A$?","['probability', 'probability-distributions']"
2499649,Proof of obtaining multiple of 10 by using arithmetic operations on any three numbers,"While doing a few math puzzles I noted that you could take any three numbers (integers) and use basic arithmetic operations (Addition, Subtraction, Multiplication and Parentheses only)
to obtain a multiple of 10, using each number only once. Eg. Using 29, 73, 36: $73+36-29=80$ Using 2, 4, 7: $2*7-4=10$ Is there a proof for this theory in particular, or is there a more general theorem that applies to this? If not, is there a set of three numbers which disproves this theory? I found a few clues while solving this: If one of the numbers is a multiple of 5 (call it $x$) then there definitely exists a solution divisible by 10. This one is easily provable as you merely need an even number to multiply with. If any one of the remaining two numbers is even, you can use that to multiply with $x$ to get number divisible by 10. If both numbers are odd then you can add them to get an even number to multiply with $x$. It would seem as only the units place digits have any bearing on whether it's a multiple of 10 or not. As you could take any of the examples, add or subtract any multiple of 10 from it and do the same operations to still get a multiple of ten. I feel this is also easily provable but I can't think of a way to do it which isn't long-winded. EDIT: It can be proven as such, let $a,b$ be two integers s.t $a+b|10$ Adding two multiples of 10 ($10m,10n$) to $a$ and $b$ we get $10m+a+10n+b$ Since $a+b|10$ it can be written as $10m+10n+10k$ where $a+b=10k$ Which is divisible by ten Now let $a,b$ be two integers s.t. $a.b|10$ Adding $10m,10n$ to $a$ and $b$ we get $(10m+a)(10n+b)$ $=100mn+10an+10bm+ab$ or $100mn+10an+10bm+10k$ Which is divisible by ten Therefore any combination of Addition and Multiplication with the three no.s shouldn't matter. I realise that could replace 10 with any no. in this proof and it would still work. So we really need to just prove for every single digit no. I ran a program in python that checked for every combination of single digit no.s, but it didn't find any combination that disproves this. I'm not sure how this question would be categorised, hence the lack lustre tags. I'm fairly new to StackExchange. Please forgive me if I've worded this question poorly.","['number-theory', 'arithmetic', 'elementary-number-theory']"
2499664,Probability density for velocity in mechanical energy,"To be sure my basic physics isn't rusty... Consider a 2-D bowled shaped classical potential well within which a classical particle of mass m is rolling.
In this system the conservation of energy holds so the particle of mass m would roll from one end to another. Because conservation of energy holds, we expect the mechanical energy to be $E=T + U = \frac{1}{2}mv^{2}-mgh$ where v is the velocity of the particle g is the gravitational acceleration and h is the heigh relative to the ground. In classical physics, the maximum velocity of the particle occurs when the particle is at $r=\left ( x,h=0 \right )$  and the minimum velocity occurs when the particle is at some position $r=\left ( x,h \right )$ \exists h on both end of the well such that its kinetic energy T is 0 and potential energy U is at maximum. Again, this follows from the conservation of energy: $\Delta T= - \Delta U$ Now, I would like to construct a mathematical equation describing the probability of finding this particle of mass m as a function of its velocity.
Intuitively, the greater the velocity of the particle at some point the lower the probability to find the particle and the smaller its velocity is the higher the probability to find the particle. Solving $ E=T + U = \frac{1}{2}mv^{2}-mgh$ for v: $v=\sqrt{\frac{2 \left ( E+mgh \right )
}{m}}$ If we want to explictly determine the probability of finding the particle as a function of its velocity, we should expect the probability density as a function of velocity to be of the form $P=P\left ( v \right ) \propto \frac{1}{v}$ which comports to our common sense intuition. How can I go about constructing a more explicit and informative equation that would enable to me determine the probability of finding the particle as a function of its velocity? Any help is appreciated.","['physics', 'mathematical-physics', 'statistics', 'mathematical-modeling', 'applications']"
2499703,"Under what circumstances is the (Cartesian) product of the power set, the power set of the product?","I'm trying to find all sets $A$ and $B$ that satisfy
$$ 2^{A \times B} = 2^A \times 2^B  \ .$$ My line of reasoning (I'll use $P()$ notation to avoid confusion):
$P(A \times B)$ has $2^{|A| |B|}$ elements.
$P(A) \times P(B)$ has $2^{|A|}2^{|B|}$ elements, so it remains to find positive integers $x$ and $y$ (representing the cardinalities of each set) such that $$2^{xy} = 2^x2^y$$ whose solution is $x=y=0$ (empty set), or $x=y=2$ (set containing 2 elements). I've tried plugging in $A= B = \emptyset$, but I get that $$\{\emptyset, \{(\emptyset, \emptyset )\}\} \neq \emptyset \times \emptyset = \{(\emptyset, \emptyset)\} \ .$$ What's going wrong? Why is this not working? I'm thinking that these might be necessary but not sufficient conditions for the first equality to hold, but it doesn't seem to work with any combination of 2-element sets. Any thoughts?",['elementary-set-theory']
2499705,"Change the Recursive Relation into Formula : $f(n,k) = f(n-1,k) + f(n-2, k-1)$","I am trying to find the formula for the number $f(n,k)$ which is defined as the number of $k$-subsets of $[n]$ in which no two elements are consecutive numbers in $[n]$. From the simple thinking I had made up following recursion: $$f(n,k) = f(n-1,k) + f(n-2, k-1) $$ This is true since I can construct without last element of $[n]$ then make up $k$-subsets, then otherwise must contain the last element of $[n]$ then construct remaining $k-1$ elements among $[n-2]$ since with the last one, I can't use $n-1$. However, I had never learned any techniques regarding changing those recursion into a well-summarized formula in terms of $n$ and $k$. Any guidance would be appreciate.","['generating-functions', 'combinatorics', 'recursion']"
2499709,How to calculate $\lim_{x\to0} \frac{\ln(1+x)+\ln(1-x)}{x^2}$?,I am new at computing limits with infinitesimals and I am having trouble solving this one: $$\lim_{x\to0} \frac{\ln(1+x)+\ln(1-x)}{x^2}$$ I tried to substitute by means of equivalent infinitesimals and I came up with this: $$\lim_{x\to0}\frac{x-x}{x^2}$$ But I do not know how to continue. The result must be $-1$. Any help would be appreciated!,"['infinitesimals', 'calculus', 'limits']"
2499712,What is $\int_0^{\infty}e^{-x^{1.5}+\theta x}dx=?$,"Is there a way to obtain an expression for $$\int_0^{\infty}e^{-x^{1.5}+\theta x}dx=?$$ If $\theta=0$, we know the above is the same as $\frac{\Gamma(2/1.5)}{\Gamma(1/1.5)}$ from a generalized Gamma function. Also, I am interested in $$\int_0^{\infty}xe^{-x^{1.5}+\theta x}dx=?$$ or, $$\int_0^{\infty}\sqrt xe^{-x^{1.5}+\theta x}dx=?$$ It seems the 2nd integral above has to do with the generalized normal density, but coudn't figure out the exact connection. I am particularly interested in the limiting behavior of the above integrals when $\theta$ gets very large? Any help or intuitions would be very appreciated!","['real-analysis', 'limits', 'gamma-distribution', 'definite-integrals', 'probability']"
2499725,Is the orthogonal complement a complementable submodule?,"Let $H$ be a Hilbert $C^*$-module over some $C^*$-algebra $A$, and consider a closed submodule $M\subseteq H$. Then it is well-known that $M$ is not necessarily orthogonally complementable in $H$. That is, we do not necessarily have (as one does when $A=\mathbb{C}$) the relation $$H\cong M\oplus M^{\perp}.$$ As an example of this phenomenon, one can let $A = C(\mathbb{R})$, the continuous functions $\mathbb{R}\rightarrow\mathbb{C}$, let $H = A$ be the Hilbert module with the $A$-valued inner product given by $(a,b) = a^*b$, and let $M$ be the closed submodule of functions in $A$ that vanish at $0$. However, I noticed in this case that we still have that $M^{\perp\perp}\oplus M^{\perp} = H\oplus\{0\}\cong H$. Question: Is it always true that for a closed submodule $M$ of $H$, we have $H = M^\perp\oplus M^{\perp\perp}$?","['functional-analysis', 'c-star-algebras', 'operator-algebras', 'noncommutative-geometry']"
2499746,Solve $\lfloor \sqrt x +\sqrt{x+1}+\sqrt{x+2}\rfloor=x$,"$$\lfloor \sqrt x +\sqrt{x+1}+\sqrt{x+2}\rfloor=x$$ 
I tried to solve this equation.
   First thing is $\lfloor \sqrt x +\sqrt{x+1}+\sqrt{x+2}\rfloor \in \mathbb{Z} $ so $x \in \mathbb{Z}$ second $$\sqrt x +\sqrt{x+1}+\sqrt{x+2} \geq \sqrt 0 +\sqrt{0+1}+\sqrt{0+2} \\\to x \in \mathbb{N}$$ so we can check $x=1,2,3,4,5,6,7,8,9,\ldots$ by a MATLAB program.  I checked the natural numbers to find solution. I found $x=8,9$ worked here. Now my question is about somehow an analytical solving of the equation, or another idea. Can any one help me? Thanks in advance.","['algebra-precalculus', 'ceiling-and-floor-functions', 'diophantine-equations', 'alternative-proof']"
2499753,"Let $A\in M_n(\Bbb R)$ prove that, $\|A^n\|\le \frac{n}{\ln 2}\|A\|^{n-1}$ when $\lambda_i<1.$","Let $n\in \Bbb N$ be fixed and $A$  be a $n\times n$  complex matrix whose eigenvalues $(\lambda_i)$ satisfy $|\lambda_i|\lt 1$. Prove that:
  $$
\|A^n\|\le \frac{n}{\ln 2}\|A\|^{n-1}
$$ where for any matrix $B$
 $$
\|B\|:= \sup_{\|x\|= 1}\|Bx\| ~~~\text{with}~~\|x\|^2 = \sum^{n}_{i=1} |x_i|^2
$$ Edit: Here $n$ is fixed and represent the dimension of our space and matrix as well. I also thought it could be done by induction but this was  a wrong way. l don't know how to proceed.","['matrices', 'contest-math', 'eigenvalues-eigenvectors', 'linear-algebra']"
2499766,"If $i : N \rightarrow M$ is an injective immersion, find a $i$-linked vector field $Y$ to $X$","I have an injective immersion $i:N\rightarrow M$ and a vector field $X$ on $N$. How to find a field $Y$ on $M$ which is $i$-linked to $X$? Reminder: $X,Y$ vector fields on $N,M$ respectively and $\psi:N\rightarrow M$ a differential map. Then $X$ and $Y$ are $\psi$ linked if $\psi_{*_p}(X_p) = Y_{\psi(p)}$ To do this, I define on $i(N), Y_{i(p)} := i_{*_p}(X_p)$ and this works. But I have to extend it to the whole of $M$ and I don't see how I can do that. I don't quite understand the argument extending a vector field defined on a closed submanifold , so if someone could help I would be gratefull.","['vector-fields', 'smooth-manifolds', 'differential-geometry', 'differential-topology']"
2499781,Probability on circumference,"Let $\xi$ be uniformly distributed on $\left[-\pi,\,\pi\right]$, $X = \cos \xi$, $Y = \sin \xi$. Is it true that $\Pr \left( X=1\mid Y=0 \right) = 0.5$? It is obvious this problem cannot be solved in term of events as $\Pr \left( Y=0 \right) = 0$. Therefore I am to compute conditional pdf $p \left( x \mid y \right)$. But joint pdf $p \left( x, y \right)$ is distributed on the zero-measured set. So, I'm a bit confused with this. EDIT: The key problem here is that the distribution on the unit circumference is singular in $\mathbb{R}^2$. However I still don't know if this equality is correct in any sense.",['probability']
2499795,The relation $y^2=f(x)$ [closed],"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 years ago . Improve this question Given a sketch of a function $f(x)$ , how to sketch the graph of $y^2=f(x)$? Is there any relationship between the features of two graphs? Like vertical asymptotes or the zeros.","['function-and-relation-composition', 'functions', 'graphing-functions']"
2499797,Meromorphic functions and embedding complex manifolds in projective space,"Motivating example : Using complex analysis, one can show that for some lattice $\Omega$ in $\mathbb{C}$, the field of meromorphic functions on the torus $\mathbb{C}/\Omega$ is generated by the associated Weierstrass elliptic function and its derivative, $\wp$ and $\wp'$. Moreover these functions satisfy the differential equation 
$$
\wp'^2=4\wp^3-g_2\wp-g_3
$$
where $g_2,g_3$ are the associated modular invariants : this relation actually gives an isomorphism between the torus $\mathbb{C}/\Omega$ and a smooth cubic in $\mathbb{P}^2(\mathbb{C})$. Thus any complex 1-torus can be embedded into the complex projective plane. Question : Does the study of the field of meromorphic functions on some arbitrary (compact) complex manifold give us any information as to whether or not the given manifold can be embedded into some projective space ? For starters a generalization to $n$-dimensional tori seems reasonable (edit : apparently it isn't !). More generally, having ""many"" such functions could be a necessary condition. In our case we have the happy accident of the Weirestrass function but I suspect the general case to be much messier. Any enlightenment would be appreciated.","['projective-geometry', 'elliptic-curves', 'complex-geometry', 'algebraic-geometry']"
2499859,Ideals and quotient rings.,"Let $R=\{a+bi \space | \space a,b\in \mathbb{Z} \} $ Let I be the ideal $\langle 3+5i \rangle $ In the quotient ring $ R/I $ (a) Without finding zero divisors explain why $R/I$ cannot be an integral domain. (b) Explain why $I$ is not prime. In the first part of the question I found that the order of $(1+I)$ is $34$.
I was hoping that this would help me answer these two questions but I can't figure it out. I can know that they are equivalent statements as $I$ is prime iff $R/I$ is an integral domain. my problem is I can't seem to figure out how write out what an element in the quotient ring looks like. If I could show there was an element of a different order than $34$ I would be done. Edit: i think we can use the fact that $(17+I)+(17+I) = (34+I)$ doesn't this imply that the order of $(17+I) =2$ ? But by theorem the only possible order was already proved to be 34 so R/I is not a FID?","['finite-groups', 'group-theory']"
2499875,Why isn't it true that $M \cap \mathcal{P}(M) = \emptyset$ for all sets $M$?,"Apparently it is false, that $M \cap \mathcal{P}(M) = \emptyset$ for all sets $M$, if I am to believe my source material. However, if I am not missing some convention, this cannot be true: $A \cap B := \{ x | x \in A \land x \in B\}$ And $\mathcal{P} := \{ m | m \subseteq a \}$ And hence $\forall x \in A. \forall m \in \mathcal{P}(A). x \neq m$, as an element of $A$ is of a different type than a set of elements of $A$. I don't think I am missing something here, but I am not inclined to assume my source is wrong. Is it though?",['elementary-set-theory']
2499883,Radius of Convergence of $\sum n^{-1}z^{3n}$,"I want to find the Convergence Radius of the series $\sum_{n=1}^\infty n^{-1}z^{3n}$ ($z\in\mathbb{C}$). Firstly, i set 
$b_k := \begin{cases}
    a_n=1/k, & \text{for } k=3n, \ n\in \mathbb{N}^* \\
    0, & \text{else}
  \end{cases}$ Now I have $\sum_{k=1}^\infty b_kz^k$ and use Cauchy-Hadamard Criterion and get $R=\frac{1}{\limsup |b_k|^{1/k}}=\frac{1}{\limsup \sqrt[3n]{|a_n|}}$ I know that $1/\limsup |a_k|^{1/n}=1$ and want to determine $R$ by the squeezing lemma. This is where I am not quite sure anymore. Can I make the estimate $\limsup |a_k|^{1/(3n)}\ge\limsup |a_k|^{1/n}=1$? Because $|a_k|\le 1$ for all $k\in\mathbb{N}^*$ we should have $1\ge \limsup |a_k|^{1/(3n)}$ too, right? I concluded $R=1$ but I have my doubts, as I am a total newbe in series.","['complex-analysis', 'sequences-and-series', 'power-series']"
2499943,What is $\arctan(-\tan(\theta))$ equal to?,"I am studying parametrizations, and while trying to prove an inverse function is continuous. I am stuck with the following: $\arctan(-\tan(\theta))=\arctan(\frac{\sin(\theta)}{-\cos(\theta)})=?$ Question: What is $\arctan(-\tan(\theta))$ equals to? How do I handle the minus sign?",['trigonometry']
2499959,Weak operator topology - the operator multiplication is not a continuous function,"A Hilbert space $ \mathscr l^2 $ is defined as a space with the scalar product $ (x,y)=\sum_{i=1}^\infty x_iy_i$ over $ \mathbb R $, where $x_i$ and $y_i$ are sequences. Then there is a space $L(\mathscr l^2)$, which is a space of all bounded linear operators $\mathscr l² \rightarrow \mathscr l²$. A weak operator topology is defined on this space, as an initial topology with a function that induces it: $$ w_{x,y} : L(\mathscr l²)\rightarrow \mathbb R : w_{x,y}(A)=(Ax, y), x,y \in \mathscr l²$$ 
It is to be shown that the multiplication of the operators in form $$ L(\mathscr l²)\times L(\mathscr l²) \rightarrow L(\mathscr l²):(A,B) \mapsto AB $$ is not continuous. Well, I've encountered many proofs of this property, but given that we have certain translations, in this case left $ A_n(x)(k) = x(k+n) $ and right $ B_n(x)(k)=x(k-n)$ if $ k\gt n$ and 0 otherwise, I am not very sure of how I can use that in my proof. Also, what does this given function $w_{x,y}$ do in general, as in how can I actually use this given property to show the problem with multiplication of the operators?","['general-topology', 'weak-topology', 'hilbert-spaces']"
