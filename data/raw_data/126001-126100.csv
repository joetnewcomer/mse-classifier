question_id,title,body,tags
1912720,A proof of the identity $ \sum_{k = 0}^{n} \frac{(-1)^{k} \binom{n}{k}}{x + k} = \frac{n!}{(x + 0) (x + 1) \cdots (x + n)} $.,"I have to prove that
$$
\forall n \in \mathbb{N}_{0}, ~ \forall x \in \mathbb{R} \setminus \mathbb{N}_{0}:
\qquad
  \sum_{k = 0}^{n} \frac{(-1)^{k} \binom{n}{k}}{x + k}
= \frac{n!}{(x + 0) (x + 1) \cdots (x + n)}.
$$
However, I was unable to find a proof. I have tried to use the binomial expansion of $ (1 + x)^{n} $ to get the l.h.s., by performing a suitable multiplication followed by integration, but I was unable to obtain the required form. Please help me out with the proof. Thanks in advance.","['combinatorics', 'summation', 'binomial-coefficients']"
1912745,Example of a first-countable non-$T_1$ compact topological space which is not sequentially compact?,"It is known that a first-countable, compact $T_1$ topological space is sequentially compact. Now, the way I know the proof, you pass through limit point compacity to, given a sequence, construct an appropriate subsequence using the fact that the space is $T_1$ and first-countable. In this post, it is shown an example of a first-countable, limit point compact , non-$T_1$ topological space which is not sequentially compact. But the space used as example is not compact. Therefore, I ask: what is an example of a first-countable, compact non-$T_1$ topological space which is not sequentially compact? (or do we really not necessarily need $T_1$?)","['general-topology', 'examples-counterexamples', 'compactness']"
1912803,Are there other good ways to look at this differential equation or is this it?,"\begin{align}
\tan \frac \alpha 2 & = u \\[4pt]
\alpha & = 2\arctan u \\[4pt]
d\alpha & = \frac{2\,du}{1+u^2} \\[4pt]
\sin\alpha & = \sin(2\arctan u) = 2(\sin\arctan u) (\cos \arctan u) \\[4pt]
& = 2\,\frac u {\sqrt{1+u^2}} \cdot \frac 1 {\sqrt{1+u^2}} = \frac{2u}{1+u^2}
\end{align}
$$ \frac{\hspace{6cm}}{} \qquad \S \qquad \frac{\hspace{6cm}}{} $$ The well known substitution above is for the moment my preferred approach to solving the differential equation
$$
\frac{d\alpha}{\sin\alpha} = \frac{d\beta}{\sin\beta}. \tag{differential equation}
$$
One gets
$$
\frac{d\alpha}{\sin\alpha} = \frac{\left( \dfrac{2\,du}{1+u^2} \right)}{\left( \dfrac{2u}{1+u^2} \right)} = \frac{du} u
$$
and writing $v = \tan \dfrac\beta 2$, we then have
$$
\frac{du} u = \frac {dv} v
$$
so that $\log u = \log v + \text{constant}$ and so $u = v\times \text{constant}$, and finally
$$
\tan \frac\alpha 2 = \text{constant} \times \tan \frac\beta 2. \tag{solution}
$$
So my question is whether there are other ways to approach this that are either better or otherwise worth some attention.","['substitution', 'ordinary-differential-equations']"
1912804,"What is the rigorous formal definition of the ""limit position"" of a line with variable parameters","My question is taken from here (it was asked long time ago without satisfactory answer, so I feel like it is necessary to raise it again), do Carmo defines the notion of strong and weak tangent by using the notion of ""limit position"" without defining it. (Weak tangent) $\alpha: I \to \Bbb R^3$ has a weak tangent at $t_0 \in I$ , if the line determined by $\alpha(t_0 + h)$ and $\alpha(t_0)$ has a limit position when $h \to 0$ . (Strong tangent) $\alpha: I \to \Bbb R^3$ has a strong tangent at $t_0 \in I$ , if the line determined by $\alpha(t_0 + h)$ and $\alpha(t_0 + k)$ has a limit position when $h \to 0$ and $k \to 0$ . I think we can define it by the included angle between the variable line and the limit line but this can't rule out the case when they are parallel to each other with a positive distance. Does anyone have an elegant definition for the ""limit position""?","['differential-geometry', 'limits']"
1912806,The value of $|z|^2+|z−3|^2+|z−i|^2$ is minimum when $z$ equals?,"The value of $|z|^2+|z−3|^2+|z−i|^2$ is minimum when $z$ equals? I thought probably the circumcentre of the triangle formed by $0,i,3$ should be the answer as in that case the distances would be equal.But the answer is different.Is there anyway to logically deduce the answer instead of the generic method that books follow (i.e. put $z=x+iy$ and then find minima).","['optimization', 'complex-numbers', 'analytic-geometry', 'complex-analysis', 'triangles']"
1912816,B-spline curve function,"It's well known fact that B-spline curve can be obtained using the equation
$$C\left( \xi  \right) = \sum\limits_{i = 1}^n {{N_{i,p}}\left( \xi  \right)} {B_i}$$
However, I can't find an example of how to do that having basis functions and control points coordinates. Let's assume the knot vector $\mathcal{S} = \left\{ {0,0,0,0.3,0.5,0.5,0.6,1,1,1} \right\}$ with $m=10$ , so that $p=2$ order basis functions for this knot vector are
$$
\begin{aligned}
{N_{0,2}}\left( \xi  \right) &= \begin{cases}
{\left( {1 - \frac{{10}}{3}\xi } \right)^2},& 0 \leqslant \xi  < 0.3
\end{cases} \\
{N_{1,2}}\left( \xi  \right) &= \begin{cases}
{\frac{{20}}{3}\left( {\xi  - \frac{8}{3}{\xi ^2}} \right)},& 0 \leqslant \xi  < 0.3\\
{2.5{\left( {1 - 2\xi } \right)^2}},& 0.3 \leqslant \xi  < 0.5
\end{cases} \\
{N_{2,2}}\left( \xi  \right) &= \begin{cases}
{\frac{{20}}{3}{\xi ^2}},& 0 \leqslant \xi  < 0.3\\
{- 3.75 + 25\xi  - 35{\xi ^2}},& 0.3 \leqslant \xi  < 0.5
\end{cases} \\
{N_{3,2}}\left( \xi  \right) &= \begin{cases}
{{\left( {5\xi  - 1.5} \right)^2}},& 0.3 \leqslant \xi  < 0.5\\
{{\left( {6 - 10\xi } \right)^2}},& 0.5 \leqslant \xi  < 0.6
\end{cases} \\
{N_{4,2}}\left( \xi  \right) &= \begin{cases}
{- 40 + 140\xi  - 120{\xi ^2}},& 0.5 \leqslant \xi  < 0.6\\
{5{\left( {1 - \xi } \right)^2}},& 0.6 \leqslant \xi  < 1
\end{cases} \\
{N_{5,2}}\left( \xi  \right) &= \begin{cases}
{20{\xi ^2} - 20\xi  + 5},& 0.5 \leqslant \xi  < 0.6\\
{- 11.25{\xi ^2} + 17.5u - 6.25},& 0.6 \leqslant \xi  < 1
\end{cases} \\
{N_{6,2}}\left( \xi  \right) &= \begin{cases}
{6.25{\xi ^2} - 7.5\xi  + 2.25},& 0.6 \leqslant \xi  < 1
\end{cases}
\end{aligned}
$$
Let's assume $m-p-1=7$ control points with certain coordinates in physical space $\mathcal{B} = \left\{ {\left( {1,1} \right),\left( {2,2} \right),\left( {3,1} \right),\left( {4,2} \right),\left( {5,1} \right),\left( {6,2} \right),\left( {7,2} \right)} \right\}$. Now I need to draw the B-spline curve with the given data in physical space. How should I do that? What is the general procedure?","['spline', 'piecewise-continuity', 'functions']"
1912822,Payoff of a dice game,"I came across this question today: ""A fair die is tossed. If 2,3 or 5 occurs, the player wins that number of rupees, but if 1, 4 or 6 occurs, the player loses that number if rupees. Then find the possible payoffs for the player"". My textbook has then proceeded to solve it like this: What is the logic behind directly adding all the values? Secondly, how is it that the game is unfavorable to the player? There is an equal chance that the player will get 2, 3 or 5 and 1,4 or 6! Please help. (Also note that this doubt is not specific to this problem alone, since this concept is crucial to understanding this part of the chapter ""Probability"".) Much thanks in advance :) Regards. Edit : Thanks ever so much for these answers :) I read up on ""Expected values"" but encountered another important doubt. I have posted it here and hope that you will clear my doubt :)","['probability-theory', 'probability', 'word-problem', 'probability-distributions']"
1912830,Tensor Calculus,"I am currently a 3rd year undergraduate electronic engineering student. I have completed a course in dynamics, calculus I, calculus II and calculus III. I've started self studying tensor calculus, my sources are the video lecture series on the YouTube channel; ""MathTheBeautiful"" and the freeware textbook/notes; ""Introduction to Tensor Calculus"" by Kees Dullemond & Kasper Peeters. Other textbooks go much more in depth in advanced math topics. I have been through the first 3 chapters and watched the first 5 videos, but I don't seem to understand the content. I don't know what I should take from these lectures and notes and what part of the work to focus on in order to start practicing as soon as possible. I want to learn tensor calculus in order to study more advanced mathematics and physics such as; General Relativity, Differential Geometry, Continuum Mechanics etc. I've also seen many other textbooks on continuum mechanics and tensor analysis for mathematicians/physicists. All of these sources seem quite different and seem like I require much more advanced topics in mathematics in order to understand. How should I approach tensor calculus? through a physics or through a mathematics perspective? From what I've seen, tensor calculus seems very abstract and more towards the proving side of the spectrum (like a pure mathematics subject), it doesn't look ""practicable"" as appose to other calculus courses where I could go to any chapter in the textbook and find many problems to practice and become familiar with the concept. Is my current knowledge in calculus and physics + dynamics enough, or do I need to first learn a few more concepts in mathematics in order to begin attacking tensor calculus problems?","['general-relativity', 'tensors', 'physics', 'calculus', 'differential-geometry']"
1912836,Alternative computation of eigenvalues of this tridiagonal matrix,"Consider the tridiagonal symmetric pd matrix $$ M=\begin{bmatrix} 2 & -1 &\dots \\ -1 & 2 &-1&\dots \\ \vdots & \ddots & \ddots & \ddots \\ 0 & \dots & -1 & 2 & -1 \\ 0  &\dots &\dots & -1 & 1\end{bmatrix}$$ The question is how to find eigenvalues and eigenvectors of $M$. I already know a way, which consists in short as introducing the sequence on the components $\phi_i$ of an eigenvector $\phi$ (the sequence is $-\phi_{k-1}+2\phi_k-\phi_{k+1}=\lambda \phi_k$). Then it is possible to find the general term and $\lambda$ using the polynomial associated with the sequence. After some manipulation, the final result is: 
$$\lambda_k=2\Big(1-\cos\Big(\dfrac{(2k-1)\pi}{2n+1}\Big)\Big)$$
and the eigenvectors are given by
$$\phi_k^{(i)}=\sin\Big(\dfrac{i(2k-1)\pi}{2n+1}\Big)$$
where $i$ is the component index and $k$ the index of the eigenvector.
I was just wondering if someone knew another way of finding the eigendecomposition.","['eigenvalues-eigenvectors', 'tridiagonal-matrices', 'linear-algebra', 'alternative-proof']"
1912850,Adjoint operator of generalized Volterra operator $\int_{0}^{t} f(t-s)g(s) ds$,"Let $f \in C(\mathbb{R})$, $g\in L^2([0,a])$ (where $a$ is finite) and we define 
$(Vg)(t):=\int_{0}^{t} f(t-s)g(s) ds.$ Then I want to find the operator $V^*,$ i.e. $$\langle Vg,h \rangle_{L^2[0,a]} = \langle g,V^*h \rangle_{L^2[0,a]}.$$ This operator somehow reminded me of the Volterra operator, but now there is  a mean integral kernel there additionally. Does anybody know how to determine this one?","['real-analysis', 'partial-differential-equations', 'calculus', 'functional-analysis', 'analysis']"
1912860,Borel measures on $\mathbb{R}$ that satisfy $\mu(A)=\mu(\bar{A})$ for every $A$,"Describe all Borel measures $\mu : B(\mathbb{R})\rightarrow [0, \infty])$ that satisfy $\mu(A)=\mu(\bar{A})$ for every $A$. ($\bar{A}$ is the closure of $A$). Well, there are several results I already have but none of them really solved the question. First of all, $\mu(\mathbb{Q})=\mu(\mathbb{R}-\mathbb{Q})=\mu(\mathbb{R})$ so $\mu(\mathbb{R})$ is either $0$ or $\infty$. The $0$ case is trivial. The other case, tho, is much more intersting. 
The main trick I used now is dealing with sets that are sequences, where the closure contains the limit:$\overline{\left \{ a_n : n\in\mathbb{N} \right \}}={\left \{ a_n : n\in\mathbb{N} \right \} }\cup \left \{ \lim a_n \right \}$ This allowed me to prove the following results (you can use them of course, but it will take a lot of time to explain all of them): Let's call a real number $x$ ""heavy"" if $\mu(\left \{ x \right \})>0$. then: The set of heavy rationals is infinite. If $x$ is heavy, then any open set that contains $x$ has measure $\infty$. Any suggestions?","['general-topology', 'measure-theory']"
1912937,Sigma algebra generated by a topology that in it's turn is generated by a class of sets,"Let $(X,\mathcal{A})$ be a measurable space and f a function $f:X \mapsto \mathbb{R}$. Then f is measurable if $f^{-1}(a,+\infty) \in \mathcal{A}$ for every $a \in \mathbb{R}$. I think that the sets of the form $(a,+\infty)$ generate a topology (is it called the borel topology?) on $\mathbb{R}$. I also know that there's a theorem that says that if a sigma algebra is generated by a class $\mathcal{G}$ then it is enough for a function $f: (X,\mathcal{A}) \mapsto (Y, \sigma(\mathcal{G}))$ to be measurable that 
 $f^{-1}(\mathcal{G}) \subset \mathcal{A}$. My question is: If a sigma algebra $\mathcal{B}$ is generated by a topology that in turn is generated by a class of sets $\mathcal{G}$ (so that $\mathcal{B}=\sigma(\tau(\mathcal{G}))$. Is it enough for a function $f: (X,\mathcal{A}) \mapsto (Y, \mathcal{B})$ to be measurable that $f^{-1}(\mathcal{G}) \subset \mathcal{A}$?",['measure-theory']
1912940,Graphing 2 variable functions,"I have a few questions where they ask to sketch 2 variable functions. I am just wondering if there any specific tricks or calculations to do when solving problems like this instead of just pure logical thinking. It just doesn't feel like I am doing this correctly when there are no calculations involved. $$
f(x,y) = 4-x^2-y^2
$$
This is how I figured it out the answer. It's an upside down paraboloid that starts at $z = 4$. Steps of execution I did. Think of $x^2$ and it's function. Think of $x^2+y^2$ and how it is the same but in 3D. Think of $-x^2$ and it turns the function upside down. Think of $-x^2-y^2$. It again must turn the function upside down. Think of $4 + x^2$ and how it is the same function but starts at four. Putting it altogether. It is an upside down paraboloid starting at $z=4$.","['multivariable-calculus', 'graphing-functions']"
1912995,Enumerative combinatorics applications in Computer Science,"I am interested in specific examples and applications of enumerative combinatorics in Computer Science -- concrete problems in this field that make explicit use of the concepts and ideas from combinatorics. Are there any good references that you can point me to (books, lectures, ...)?","['combinatorics', 'reference-request', 'computer-science']"
1912998,Computing geodesics (or shortest paths),"I'm interested in computing geodesic curves (or locally shortest paths) on surfaces in 3D. We can assume that the surface is given in parametric form $(u,v) \mapsto \mathbf{S}(u,v)$. If it helps, we can even assume that the parameterization is given by polynomials of fairly low degree (say 3, 4, or 5). Further, we are given two points $\mathbf{P}_0 = \mathbf{S}(u_0,v_0)$ and $\mathbf{P}_1 = \mathbf{S}(u_1,v_1)$ lying on the surface. Two questions: (1) I want to compute a curve of minimal length between $\mathbf{P}_0$ and $\mathbf{P}_1$, and lying in the surface. (2) I want to compute a curve between $\mathbf{P}_0$ and $\mathbf{P}_1$, lying in the surface, on which the geodesic curvature is zero at every point. I believe questions (1) and (2) have a close relationship, though I'm not exactly sure what it is. The relationship is not particularly important to me; I mentioned it only because it might allow us to solve both problems with one method. The surfaces I'm dealing with are ""real world"" ones -- think about the roof of a car, for example, or the upper surface of the wing of an aircraft. The surfaces are very smooth, and are usually convex, if that helps. There are important applications in manufacturing, which I can explain if anyone is interested. Edit: After some more searching, I found this paper , which seems to have what I need. The ideas are quite similar to those in the accepted answer below.","['geometry', 'numerical-methods', 'ordinary-differential-equations', 'differential-geometry', 'geodesic']"
1913032,"If $ f $ is a Borel function, and $ X $ and $ f(X) $ are independent, then $ \mathsf{P}(f(X) = c) = 1 $ for some constant $ c \in \mathbb{R} $.","Problem. Let $ X $ be a random variable, and $ f: \mathbb{R} \to \mathbb{R} $ a Borel function such that $ X $ and $ f(X) $ are independent. Show that there exists a constant $ c \in \mathbb{R} $ such that $ \mathsf{P}(f(X) = c) = 1 $. This is what I have tried so far: $ X $ and $ f(X) $ are independent, so $ X $ and $ X $ must be independent. I was then able to show that there exists a constant $ c \in \mathbb{R} $ such that $ \mathsf{P}(X = c) = 1 $. I’m not sure how to proceed further.","['independence', 'probability-theory', 'measure-theory', 'random-variables']"
1913045,Need to simplify ratio test: $\frac{(2(k+1))!}{(2k)!} $,"So I am going to check if this series converges.
$$\sum_{k=1}^\infty \frac{(2k)!}{k^{k}} $$ I used the ratio test for this, and I end up with this limit:
$$\lim_{k \to \infty} \frac{(2(k+1))!\cdot{k^{k}}}{(2k)!\cdot{(k+1)}^{k+1}}$$ I have no clue on how I simplify: $$\frac{(2(k+1))!}{(2k)!} $$
I know for instance:
$$\frac{(k+1)!}{k!} = k+1 $$ But the constant 2 infront of the brackets and inside the !-sign makes me a bit confused. Could someone help me out?","['algebra-precalculus', 'factorial', 'real-analysis', 'sequences-and-series']"
1913047,Finding the 19th derivative of $\frac{x-1}{e^x}$ using taylor series,"Full context: The problem is multiple choice and originally asks to find the 19th derivative which I prefer to do by Taylor Series. My method get's the answer (after plugging in $x=0$) but it is a bit unsatisfying since it relies on there being multiple choice options and I am wondering if there is a less multiple choice-y way to do the question under time pressure. I took 
$$f(x)=e^{-x}(x-1)=\sum_{n=0}^{\infty}\frac{1}{n!}(-x)^{n+1}-\sum_{n=0}^{\infty}\frac{1}{n!}(-x)^{n}$$
A taylor series centered at zero. Then we can equate 
$$
\frac{f^{(n)}(0)}{n!}=a_n\Rightarrow \frac{f^{(19)}(0)}{19!}=\frac{1}{18!}+\frac{1}{19!}\Rightarrow f^{(19)}(0)=20
$$
Then plugging in, only one solution satisfies $f^{(19)}(0)=20$: $(20-x)e^{-x}$. I am wondering: Is there a more sound way to find a closed form solution? I tend to not be great at looking for a pattern, especially under pressure, so if that is your method please explain how you go about seeing a pattern quickly after a couple of computations.","['derivatives', 'taylor-expansion', 'calculus']"
1913067,Convergence of $\sum2^{-\sqrt{k}} $,"So I am going to determine whether this series converges or not:
$$\sum_{k=0}^\infty 2^{-\sqrt{k}} $$ Since this chapter is about the ratio test, I applied that test to this series.
I end up with this limit $$\lim_{k \to \infty} 2^{\sqrt{k}-\sqrt{k+1}}$$ I'm stuck here, don't know how to calculate this limit. I could simplify to: $$\sqrt{k}-\sqrt{k+1} = \frac{1}{\sqrt{k}+\sqrt{k+1}} $$
But I doubt this will help me. Could anyone help me?",['analysis']
1913112,Prove $n=m$ if $(q^n-1)(q^n-q)\cdots (q^n-q^{n-1}) = (q^m-1)(q^m-q)\cdots (q^m-q^{m-1})$.,"Let $m, n, q \in \mathbb{Z}_{\geq 0}$. If $(q^n-1)(q^n-q)\cdots (q^n-q^{n-1}) = (q^m-1)(q^m-q)\cdots (q^m-q^{m-1})$, how to prove $n=m$?","['number-theory', 'elementary-number-theory']"
1913141,Is the $0\times 0$ matrix (zero-times-zero matrix) a well-defined concept?,"Is the $0\times 0$ matrix a well-defined concept, and if yes, what can be said about it? Intuitively it should be a well-defined concept, since we have the zero vector space, and every linear mapping between vector spaces (such as the zero mapping from the zero vector space to itself) can be represented by a matrix. The determinant of a $0\times 0$ matrix should be $1$ , intuitively, just as the zero-dimensional volume of a point is $1$ . If the $0\times 0$ matrix is a bad concept or ill-defined concept, can you explain where to find the catch?","['matrices', 'linear-algebra']"
1913210,Number that equals occurences of 1,"I have a small problem that goes like this: Find number $N$ in a series of consecutive numbers starting from $1$, $(1,2,\cdots,N)$ where $N$ is a multiple of $10$, and the number of appearances of the digit $1$ in the entire series equals $N$. EX: $f(1) = 1 \ $ ( 1 ) $f(2) = 1 \ $ ( 1 ,2) $f(12) = 5 \ $ ( 1 ,2,3,4,5,6,7,8,9, 1 0, 11 , 1 2) I have written a Java program that does this for me, and I came up with $N=199990$, but how would I go about explaining this result in a mathematical way ? Thanks","['decimal-expansion', 'sequences-and-series', 'discrete-mathematics']"
1913221,Spivak's Calculus - Chapter 1 Question 23,"In Spivak's Calculus Chapter 1 Question 23: Replace the question marks in the following statement ing $\varepsilon, x_0$ and $y_0$ so that the conclusion will be true:
  If $y_0\neq 0$ and $$|y-y_0|<?  \qquad\text{and}\qquad  |x-x_0|<?$$ then $y\neq 0$ and $$ \bigg| \frac{x}{y}-\frac{x_0}{y_0}\bigg|<\varepsilon.$$ The answer in its Solution Manual is $$|x-x_0|<\min\bigg(\frac{\varepsilon}{2(1/|y_0|+1)},1 \bigg)$$ and $$|y-y_0|<\min\bigg( \frac{|y_0|}{2},\frac{\varepsilon|y_0|^2}{4(|x_0|+1)} \bigg).$$ The latter is same as my solution, but the first is a bit different. So I wonder if $$|x-x_0|<\min\bigg(\frac{\varepsilon |y_0|}{4},1 \bigg)$$, is the solution still be true?
Thanks in advance.","['epsilon-delta', 'calculus', 'analysis']"
1913222,Find all polynomials $p$ such that $p(x+1)=p(x)+2x+1.$,Find all polynomials $p$ such that $p(x+1)=p(x)+2x+1.$ I obtained $p(1)=p(-1).$ I claimed that $p(x)=x^2$ but was unable to prove it. Any help will be appreciated.,"['polynomials', 'functions', 'functional-equations']"
1913260,Find integral $\int_0^1 \frac{\ln x}{1 - x^2} \mathrm{d}x$,"I have to find definite integration $$\int_0^1 \frac{\ln x}{1 - x^2} \mathrm{d}x$$ 
I tried to subtitute $x = \sin u$  and $x = e^u$ 
but got no result . Please help me in proceeding.","['improper-integrals', 'integration', 'definite-integrals']"
1913266,"prove $f\in L^2([0,1])$","Assume $f:[0,1]\to R$ is a measurable function such that $fg\in L^1([0,1])$ for all $g\in L^2([0,1])$.prove that $f\in L^2([0,1])$. My opinion: if I can find a function g such that f+g is in $L^2([0,1])$, then use $$\int(f+g)^2-\int2fg+g^2$$to get $\int f^2$, then we can prove f is in $L^2([0,1])$. Is it right?","['functional-analysis', 'complex-analysis', 'real-analysis', 'analysis']"
1913276,Serre's Trick for flatness of a morphism of schemes,"I'm reading some exercises on abelian varieties and I came across the following claim: Claim (Serre's Trick): Let $X,Y,S$ be schemes and suppose that $X \times_S Y$ is flat over $S$. If $X(S) \neq \emptyset$ then $Y$ is flat over $S$. Evidently to prove the claim we may reduce to the case where $X = \operatorname{Spec} C$, $S = \operatorname{Spec} A$ and $Y= \operatorname{Spec} B$ where $A,B,C$ are local rings and the maps $A \to B$, $A \to C$ are local homomorphisms. Let $\mathfrak{m}_A, \mathfrak{m}_B$ and $\mathfrak{m}_C$ be the maximal ideals of $A,B,C$ respectively. (**) Suppose for the moment that the tensor product $B \otimes_A C$ contains a maximal ideal $\mathfrak{m}$ that contracts simultaneously to $\mathfrak{m}_A$ and $\mathfrak{m}_B$. By localizing at $\mathfrak{m}$, we may assume that $B \otimes_A C$ is local, and the composition
$$A \to B \to B \otimes_A C$$
is faithfully flat (flat + local homomorphism implies faithfully flat). With this I think we can prove that $B$ is flat over $A$ as follows. Let
$M \to N$ be an injection of $A$-modules. Let $K$ be the kernel of the map
$M \otimes_A B \to N \otimes_A B$. Tensoring with $C$, we get that 
$$K \otimes_A C  = 0$$ using flatness of $B \otimes_A C$ over $A$. Now tensor with $B$ to get
$$ K \otimes_A (C \otimes_A B) = 0$$
and conclude that $K= 0$ by faithful flatness. My question is: A necessary condition for (**) to be true is that the product $B \otimes_A C$ is not zero. How can I get this just from the fact that there is a map $C \to A$? Indeed the example
    $$ \Bbb{Z}/2 \otimes_{\Bbb{Z}} \Bbb{Q} = 0$$
    shows that the condition on the existence of a section is really needed.\ Edit: I was tired from travelling and stupidly concluded that $-\otimes_A C$ was injective.","['algebraic-geometry', 'commutative-algebra']"
1913281,"Prove that union, intersection and difference of measurable sets is measurable using specific definition of measurability","I found a lot of questions with the similar title on the forum, but not all of them are properly answered and those, which are, differ significantly from mine. I work in the closed interval $[0,1]$. I use the following definition of Lebesgue measurability: $\mathbf{Def. 1}$ The set E is called measurable iff $$\lambda^{*}(E)+\lambda^{*}([0,1]\backslash E)=1,$$ where $\lambda^{*}$ is the outer lebesgue measure, i.e. $\lambda^{*}(E)=\inf_{U\supset E}\lambda(U)$, where $U$ is an open set. I can prove that this definition is equivalent to the following: $\mathbf{Def. 2}$ The set E is called measurable iff $\forall \epsilon >0 \ \exists U_{\epsilon} ,F_{\epsilon}$ - open and closed sets respectively, such that $F_{\epsilon} \subset E \subset U_{\epsilon}\ \lambda^{*}(U_{\epsilon})-\lambda^{*}(F_{\epsilon})<\epsilon$. $\sigma$-additivity for $\lambda$ is also proven (for a measurable set $E$: $\lambda(E)=\lambda^{*}(E))$ : If $\{E_n\}$ - a collection of measurable sets and $E_k\cap E_l = \varnothing$ then $\lambda \left (\bigcup_{n=1}^{\infty}E_n \right)=\sum_{n=1}^\infty{\lambda(E_n)}$. And here is my question: a) If $A$ and $B$ are measurable sets (they may intersect) prove that $A\cup B, A\cap B, A\backslash B$ are measurable using $\mathbf{ Def. 1}$ or $\mathbf{ Def. 2}$. b) Prove that countable intersection and countable union of the measurable sets is measurable. I'd appreciate your help, guys.","['real-analysis', 'lebesgue-measure', 'measure-theory']"
1913294,"Prove that $|\sin\,(\text{Re}\,z)|\le|\sin z|$.","How do you prove that $|\sin\,(\text{Re}\,z)|\le|\sin z|$ for $z\in\mathbb{C}$? I know that $|\text{Re}\,z|\le|z|$ but then what? Even a hint will help, thanks.","['complex-analysis', 'trigonometry']"
1913307,For given $f(x)$ find the value of $\frac{f(101)}{f'(101)}$?,"If $$f(x)=\prod_{n=1}^{100} (x-n)^{n(101-n)}$$, then what will be the value of $$\frac{f(101)}{f'(101)}?$$ $(A)$ $5050$ $(A)$ $1/5050$ $(A)$ $10010$ $(A)$ $1/10010$ Could someone give me slight hint for this question as I am not able to initiate?","['derivatives', 'calculus', 'functions']"
1913325,"Real-Analysis Methods to Evaluate $\int_0^\infty \frac{x^a}{1+x^2}\,dx$, $|a|<1$.","In THIS ANSWER , I used straightforward contour integration to evaluate the integral $$\bbox[5px,border:2px solid #C0A000]{\int_0^\infty \frac{x^a}{1+x^2}\,dx=\frac{\pi}{2}\sec\left(\frac{\pi a}{2}\right)}$$for $|a|<1$. An alternative approach is to enforce the substitution $x\to e^x$ to obtain $$\begin{align}
\int_0^\infty \frac{x^a}{1+x^2}\,dx&=\int_{-\infty}^\infty \frac{e^{(a+1)x}}{1+e^{2x}}\,dx\\\\
&=\int_{-\infty}^0\frac{e^{(a+1)x}}{1+e^{2x}}\,dx+\int_{0}^\infty\frac{e^{(a-1)x}}{1+e^{-2x}}\,dx\\\\
&=\sum_{n=0}^\infty (-1)^n\left(\int_{-\infty}^0 e^{(2n+1+a)x}\,dx+\int_{0}^\infty e^{-(2n+1-a)x}\,dx\right)\\\\
&=\sum_{n=0}^\infty (-1)^n \left(\frac{1}{2n+1+a}+\frac{1}{2n+1-a}\right)\\\\
&=2\sum_{n=0}^\infty (-1)^n\left(\frac{2n+1}{(2n+1)^2-a^2}\right) \tag 1\\\\
&=\frac{\pi}{2}\sec\left(\frac{\pi a}{2}\right)\tag 2
\end{align}$$ Other possible ways forward include writing the integral of interest as $$\begin{align}
\int_0^\infty \frac{x^a}{1+x^2}\,dx&=\int_{0}^1 \frac{x^{a}+x^{-a}}{1+x^2}\,dx
\end{align}$$ and proceeding similarly, using $\frac{1}{1+x^2}=\sum_{n=0}^\infty (-1)^nx^{2n}$. Without appealing to complex analysis, what are other approaches one can use to evaluate this very standard integral? EDIT: Note that we can show that $(1)$ is the partial fraction representation of $(2)$ using Fourier series analysis.  I've included this development for completeness in the appendix of the solution I posted on THIS PAGE .","['real-analysis', 'definite-integrals']"
1913354,Does $c\cdot f(x) = f(cx) \implies f$ is linear? [duplicate],"This question already has answers here : Are all multiplicative functions additive? (2 answers) Closed 7 years ago . A linear functions $f$ is a function that has the following two properties: $c\cdot f(x) = f(cx)$ $f(x+y) = f(x) + f(y)$ But does $c\cdot f(x) = f(cx) \implies f$ is linear? Can we assume property $2$ above, if we have a function $f$ satisfying property $1$?","['linear-algebra', 'functions']"
1913356,Improper Integral $\int_0^\infty\left(\frac{\tanh(x)}{x^3}-\frac1{x^2\cosh^2(x)}\right)dx = \frac{7\zeta(3)}{\pi^2} $,"$\newcommand{\sech}{\operatorname{sech}}$
$\displaystyle \int_0^{\infty}{\left(\frac{\tanh(x)}{x^3} - \frac{\sech^2(x)}{x^2} \right)\ dx }= \frac{7\zeta(3)}{\pi^2} $ What I tried I simplified it to - $\displaystyle \int_0^{\infty}{\frac{\sinh(2x) - 2x}{x^3 \cosh^2(x)} \ dx}$ Then I don't know how to solve. I tried Feynman's method $\displaystyle I(a) = \int_0^{\infty}{\frac{\sinh(ax) - ax}{x^3 \cosh^2(x)} \ dx}$ But then too it didn't help much. I thought of replacing them with trigonometric forms and then complex number real and imaginary part but wasn't helpful much. Please try to avoid complex analysis.","['calculus', 'closed-form', 'improper-integrals', 'integration', 'definite-integrals']"
1913369,"How to write ""$k$ is equal to any integer"" in symbols?","How do you state that $k$ is equal to any integer in the following? The solutions to this equation
  $$2\sin(3x)-1=0$$
  are
  $$
\left\{
\begin{array}{ll}
x=\dfrac{\pi}{18}+\dfrac{2\pi}{3}k\\[4pt] 
x=\dfrac{5\pi}{18}+\dfrac{2\pi}{3}k \\  
\end{array} 
\right.
$$","['trigonometry', 'notation']"
1913394,How to prove that the rank of a matrix is a lower semi-continuous function?,"I need to prove that rank($\mathrm{A}$) is not continuous everywhere but is lower semi-continuous everywhere, where $\mathrm{A}\in \mathbb{C}^{n\times m} $","['matrices', 'real-analysis', 'linear-algebra', 'analysis']"
1913416,Find closest point between 2D Point and 2D Area,"This is a mathematics problem with the application in computer science. Basically I have a rotated 2D box (black) and I need to find the closest point (red) on its' bounds towards a point (green) in 2D Space. The box is defined by center (x/y) size (x,y) and rotation (y euler angles). Approximations which are performance efficient are welcome as well.","['area', 'linear-algebra', 'computer-science']"
1913426,Show that $\frac{X_{n}}{c_{n}}\rightarrow 0$ almost surely,"Suppose $X_{n}$ is any sequence of (real-valued) random variables defined on a common probability space $(\Omega,\mathcal{F},\mathbb{P})$. Show that there exists a sequence $c_{n}\rightarrow \infty$ such that  $\frac{X_{n}}{c_{n}}\rightarrow 0$ almost surely. The key is to use the Borel Cantelli lemma, but I am not able to formulate pairwise independent events $A_{n}$ such that $\sum\limits_
{n=1}^{\infty}\mathbb{P}(A_{n})=\infty$ implies $\mathbb{P}(A_{n}~\text{i.o.})=1$, where i.o. stands for infinitely often. Just a few small hints would be greatly appreciated.","['probability-theory', 'borel-cantelli-lemmas']"
1913507,Expected number of rolls to get 1 followed by 2,"We have a fair, six-sided dice. The questions are What's the expected number of rolls to get 1 followed by 1? What's the expected number of rolls to get 1 followed by 2? Let $E$ be the expected time to get '11'. From the geometric distribution, we know that it takes on average 6 rolls to get a 1. Let us roll until we have a 1. Then there is a $1/6$ chance of being done in the next roll
$$E = 6 + \frac{1}{6} \cdot 1 + \frac{5}{6}(1 + E) \qquad \Rightarrow \qquad E = 42.$$
I am fairly certain that my solution is correct for the first one, but I am a bit confused about the logic for the second one. I know its very similar to the first one but with a twist. Let $E$ be the expected time to get '12'. Then we first have to roll on average 6 times, after which we have a $1/6$ probability of being done (2), a $4/6$ chance of starting all over (3,4,5,6), and a $1/6$ probability of making no progress (1). Then
$$E = 6 + \frac16\cdot 1 + \frac46 \cdot (1 + E) + \frac16 \cdot (1+6) \qquad\Rightarrow\qquad E=48.$$
Is the $(1+6)$ part right? For some reason I don't think it is.",['probability']
1913532,Quickest general strategy for village meeting,"Here is a problem, which neither I nor my friends (very experienced in solving things like this) can't solve. But it was used for a competition several years ago and one guy solved it there, as far as I know. Unfortunately the solution (and the guy) is lost. You have a village. It is shaped as a square 1 by 1. The headman lives at the exact center of the square. Other houses are spread throughout the area of the village, and there is only one person per house. There are finite number of houses, they all have size 0 and everyone is aware of their placement. The headman needs to organise a meeting, which collects all villagers. To do this, he goes to some other house and tells about the meeting, then go to the another, etc. Each villager is of course is guaranteed to be found in his house; once informed, he can either participate in the gathering or go to the meeting place at the headman house. They all travel at the speed of 1 and it takes 0 time to inform someone, once you've reached his(-er) house. You need to find the minimum time $T_{\text{MinMax}}$ in which all villagers (including headman) can be collected at the centre of village, regardless of their number and initial placement. The answer should come together with proof, i.e. you need to: a) provide a strategy (who goes where) and prove that it will work for any village in time $t \le T_{\text{MinMax}}$ b) prove that for all other strategies there must a village, which will be ""collected"" in time $t \ge T_{\text{MinMax}}$. Can anyone here solve it? You can be sure, that $T_{\text{MinMax}} < \infty$. For example, the following strategy works in $T_{\text{Max}} < 3\sqrt{5}+3\sqrt{2}/2$: 1) The village area is divided into 4 square subareas 0.5 by 0.5. 2) The headman goes to a closest house in one subarea and assings its host to be a subheadman and asks him to do the same strategy in his subarea. 3) Then the headman goes to another, neighboring subarea and does the same. And repeats this with the rest of 2 subareas. 4) The headman comes back to the centre of village. 5) If some subarea has no houses inside the headman just skips it. Let's say that in the worst case scenario it will take time $X$. Then for subheadmen it will take time $X/2$. The first subheadman is assigned in at most $\sqrt{2}/2$ time, the next in $\sqrt{2}/2+\sqrt{5}/2$ and the last in $\sqrt{2}/2+3\sqrt{5}/2$. Then at time $\sqrt{2}/2+3\sqrt{5}/2+X/2$ the last subarea is collected it its center and in $\sqrt{2}/4$ time it can be at village center. Which means $X < \sqrt{2}/2+3\sqrt{5}/2+X/2+\sqrt{2}/4$. So $T_{Max} = X < 3\sqrt{5}+3\sqrt{2}/2$. It is easy to prove that $T_{\text{MinMax}} \ge 2+\sqrt{2}$ (consider a village with 4 houses in the corners), and I am almost sure that $T_{\text{MinMax}} = 2+\sqrt{2}$, it was the result of that guy from the competition.","['recreational-mathematics', 'optimization', 'geometry']"
1913557,"What are ""shapes"" and/or the polynomials associated to them really called?","While trying to formalize basic Year 8 geometry, I came up with the following: Definition 0. A shape is a CW-complex $S$ together with a topological embedding $f_S:S \rightarrow \mathbb{R}^n$ such that for all natural numbers $n$, writing $S_n$ for the union of the $n$-dimensional cells of $S$, we have that $f_S(S_n)$ has finite $n$-dimensional measure. Two shapes are equal iff there exists a proper rigid transformation that turns one shape into the other. Examples. The line segment of length $a$, the $(a\times b)$-rectangle, the circle of radius $r$, the two-dimensional disk of radius $r$, etc. We can also take cartesian products of shapes; for example, the $a\times b$-rectangle can be expressed as the cartesian product of a line segment of length $a$ and another of length $b$. Similarly, we can get the cylinder by taking the cartesian product of a circle and a line segment. The definition of a shape is rigged so that to each shape $S$, we can assign a polynomial $S(x)$ as follows. Definition 1. If $S$ is a shape, write $S(x)$ for the formal polynomial in the symbol $x$ with coefficients in $\mathbb{R}_{\geq 0}$ such that the coefficient of $x^n$ is the $n$-dimensional measure of $f_S(S_n)$. For example: If we write $[a]$ for the line segment of length $a$, then $[a](x) = 2+a x$. Notice the polynomial tells us both the number of vertexes, and the length of the interval. If $S=[a] \times [b],$ then $S$ is the rectangle of size $a \times b$. Therefore: $$S(x) = 4+(2a+2b)x+abx^2,$$ because $4$ is the number of vertexes, $2a+2b$ is the perimeter, and $ab$ is the area. If $S_r^2$ is the circle of radius $r$ (that's not filled in), then $S_r^2(x) = 2\pi rx$, because the coefficient of $x$ is the perimeter of the circle. Similarly, if $B_r^2$ is the two-dimensional ball of radius $r$, then $B_r^2(x) = 2\pi rx+\pi r^2x^2.$ The $2\pi r$ is the perimeter, and the $\pi r^2$ is the area. If $S$ is the point, then $S(x) = 1$. Now. the whole reason we want to be viewing these as polynomials (rather than just sequences) is that it seems to be a general principle that $$(S \times T)(x) = S(x) \cdot T(x).$$ We can use this to derive dot point $1$ from dot point $2$. In particular: $$([a] \times [b])(x) = [a](x) \cdot [b](x) = (2+ax)(2+bx) = 4+(2a+2b)x+abx^2.$$ Its also possible to take sums of shapes, defined by disjoint union. We have: $$(S + T)(x) = S(x)+T(x)$$ Anyway, geometry has been around for a long time. Surely I'm not the first person to have this idea, so: Question. What are ""shapes"" and/or the polynomials associated to them really called?","['reference-request', 'terminology', 'measure-theory', 'geometry', 'differential-geometry']"
1913565,Find the number of simple labeled graphs which have no isolated vertices,"Find the number of simple labeled graphs on n vertices which have no isolated vertices? Compute the result for n=13 Total number of simple labeled graphs = $2^{n \choose 2}$.
How to remove vertices of degree greater than 0 ? 
Should I directly write a Computer Program enumerating on all vertices?","['combinatorics', 'graph-theory', 'algorithms', 'discrete-mathematics']"
1913595,limit of product of $(a_1a_2.\dots a_n)^{\frac{1}{n}}$ [duplicate],"This question already has answers here : How to prove that $\lim \frac{1}{n} \sqrt[n]{(n+1)(n+2)... 2n} = \frac{4}{e}$ (5 answers) Closed 7 years ago . How to calculate the following limit 
$$ \lim_{n\rightarrow \infty} \left[ \left(1+\frac{1}{n}\right)\left(1+\frac{2}{n}\right)\cdots \left(1+\frac{n}{n}\right) \right]^\frac{1}{n} .$$
 I was trying this by taking the $\log $ of the product and then limit but I am not getting the answer could anybody please help me. And, also is there any general rule for calculating the limit for  $$ (a_1a_2.\dots a_n)^{\frac{1}{n}}.$$ Thanks.","['radicals', 'sequences-and-series', 'limits']"
1913600,Closed form of the following Recurrence Relation,"Let $L\colon\mathbb{N}^3 \to \mathbb{N}$ satisfy the following recurrence relationship, $$
L(a,b,c) = 1 + \sum_{i=0}^{a-1} \sum_{j=0}^{b-1} \sum_{k=0}^{c-1} L(i,j,k),
$$ With ""initial conditions"" $L(0,a,b) = L(c,0,d) = L(0,e,f) = 0$.  I am interested in knowing a closed form of $L$. Work I have done: I have investigated a simpler case
$
G\colon \mathbb{N}^2\to \mathbb{N}
$, satisfying 
$$G(a,b) = 1 + \sum_{i=0}^{a-1} \sum_{j=0}^{b-1} G(i,j)$$
with similar ""initial conditions"" and can obtain $$G(a,b) = \binom{a+b-2}{a-1}= \binom{a+b-2}{b-1}= \frac{(a-b-2)!}{(a-1)!(b-1)!},$$ so I would have guessed that $$L(a,b,c) = \frac{(a+b+c-3)!}{(a-1)!(b-1)!(c-1)!}, $$ but this isn't correct.  I would appreciate any hints on how to find a closed form solution for this.","['recurrence-relations', 'discrete-mathematics']"
1913602,"If $f \in L_p$ and $g \in L_\infty$, show that $fg \in L_p$.","If $f \in L_p, 1\le p\le \infty$, and $g \in L_\infty$, then the product $fg \in L_p$ and $\|fg\|_p \le \|f\|_p\|g\|_\infty$. I am still trying to show the first part, that $fg \in L_p$. What I have tried so far is the following: We must try and show that $$\int |fg|^p \, d\mu < \infty.$$
Notice that $$|fg|=|f||g|\le |f|\|g\|_\infty,$$ since $|g(x)|\le \|g\|_\infty$ for every $x$. Now \begin{align}\int |fg|^p d\mu &= \int \left(|f|~|g|\right)^p \, d\mu \\ &= \int |f|^p|g|^p d\mu \\ &\le \int |f|^p \|g\|_\infty^p \, d\mu \\ &= \|g\|_\infty^p \int |f|^p\, d\mu <\infty,\end{align} i.e. $fg \in L_p$. Is this correct? EDIT: The inequality in question then follows directly from seeing that $||fg||_p=(\int |fg|^p d\mu)^{\frac{1}{p}}$ and applying the inequality we obtained above.","['lebesgue-measure', 'lebesgue-integral', 'measure-theory']"
1913674,Convergence of power series around another point,Suppose $f(z)=\sum_{n=0}^\infty a_nz^n$ is a power series that converges on $B_R(0)$ for some $R>0$. Let $w \in B_R(0)$ and $r=|w|<R$. I'm trying to show that there exists a power series $f(z)=\sum_{n=0}^\infty b_n (z-w)^n$ that converges on $B_{R-r}(w)$. I tried to expand $f(z+w)$ to determine coefficients $b_n$ but I'm having a lot of trouble.,"['complex-analysis', 'analytic-functions']"
1913678,"Let $F,G$ to be distribution. Is the product $FG$ also a distribution?","Let $F,G$ to be distribution functions of a random variable, say $X$. Is the product $FG$ also a distribution? We define $\psi(x) = F(x)G(x)$. We first have:
$$\lim_{x \to \infty } \psi(x) = \lim_{x \to \infty} F(x)G(x) = 1,$$
$$\lim_{x \to -\infty } \psi(x) = \lim_{x \to -\infty} F(x)G(x) = 0.$$
because both $F,G$ are distribution. Also, if $x < y$, then 
$$\psi(x) \leq \psi(y) \Leftrightarrow F(x)G(x) \leq F(y)G(y),$$
but $F(x) \leq F(y)$ and $G(x) \leq G(y)$, so the previous inequality holds. Finally, we have
$$\lim_{h \to 0+ } \psi(x + h) = \lim_{h \to 0+ }F(x+h)G(x+h) = F(x)G(x) = \psi(x).$$
Is this reasoning correct? I am not sure, if the products of two functions is defined I used them. I am also not sure if the operations make sense. Thanks in advance","['probability-theory', 'probability', 'proof-verification', 'probability-distributions']"
1913689,Proof that $A \subset f^{-1}(f(A))$,"Let $f: X \rightarrow Y$ be a function. $A \subset X$ and $B \subset Y$.
  Prove $A \subset f^{-1}(f(A))$. Here is my approach. Let $x \in A$. Then there exists some $y \in f(A)$ such that $y = f(x)$. By the definition of inverse function, $f^{-1}(f(x)) = \{ x \in X$ such that $y = f(x) \}$. Thus $x \in f^{-1}(f(A)).$ Does this look OK, and how can I improve it?","['elementary-set-theory', 'proof-verification']"
1913696,What is the derivative of $|f(x)|^n$,"Well, it's time for a trivial question but I really need a clarification about! Let's say I have to evaluate $$\frac{\text{d}}{\text{d}x}\ |f(x)|^n$$ Shall I have to reason by treating the function as $$|f(x)|^n = \left(\sqrt{f(x)^2}\right)^n$$ and then it would be quite easy, or shall I try to apply, somehow, the same rule for the derivative of $|x|$ like? $$D\ |f(x)|^n = n\ f(x)^{n-1}\frac{|f(x)|}{f(x)}f'(x) = n\ f(x)^{n-2}|f(x)|f'(x)$$ Thank you for the clarification!","['derivatives', 'absolute-value', 'calculus']"
1913699,Expectation of a sample variance,"Let $Y_1$ and $Y_2$ be two independent realizations of the random variable $Y$ such that $E(Y_1)=E(Y_2)=E(Y)$ and $Var(Y_1)=Var(Y_2)=Var(Y)$. With $Y_1$ and $Y_2$ as our sample, the sample variance is written as $\sum (Y_i-\overline Y)^2$. I want to write the sample variance in terms of $Y_1$ and $Y_2$ only, is it correct to state that $\overline Y=E(Y_1)=E(Y_2)=E(Y)$ and then get as sample variance:
$$[Y_1-E(Y_1)]^2+[Y_2-E(Y_2)]^2$$ If so, I am asked to show that $E(\text{sample variance})=Var(Y)$ but I am only able to show that it is equal to $2Var(Y)$.","['expectation', 'sampling', 'variance', 'statistics', 'random-variables']"
1913704,Prove that there is a vector $v\in \mathbb{R}^k$ such that $u \cdot v =0$,"Let $u \in \mathbb{R}^k$ be a vector with one component positive, one component negative, and the remaining $k-2$ can have at most one component that is equal to zero. Then is there a vector $v \in \mathbb{R}^k$ such that all its components are strictly positive and $u \cdot v= 0$? Intuitively this seems to be true. But how can I go about showing this formally?",['linear-algebra']
1913712,Understanding rational maps in Algebraic Geometry-Examples of birational equivalence between varieties,"I am struggling to understand the concept of rational maps. In Hartshorne, the definition of rational maps is as follows Let $X$ and $Y$ be varieties. A rational map $\phi:X\rightarrow Y$ is an equivalence class of pairs $\langle U,\phi_{U} \rangle$ where $U$ is a nonempty open subset of $X$, $\phi_{U}$ is a morphism of $U$ to $Y$, and where $\langle U,\phi_{U} \rangle$ and $\langle V,\phi_{V} \rangle$ are equivalent if $\phi_{U}$ and $\phi_{V}$ agree on $U\cap V$. The rational map $\phi$ is dominant if for some (and hence every) pair $\langle U,\phi_{U} \rangle$, the image of $\phi_{U}$ is dense in $Y$. I get what this definition is saying, but It seems so obscure and doesn't allow me to look at a map and say whether it is rational or not. Also, why is it called rational... It doesn't feel rational (fractions). Apparently, I have seen somewhere (very briefly, so this may be wrong) that $\mathbb{P}^1$ is birational to $\mathbb{A}^1$. If I were to try to prove this is map I would go for is $\psi:\mathbb{A}^1\rightarrow \mathbb{P}^1$, $\phi(x)=[x:1]$. The inverse map I would then go for is $\theta:\mathbb{P}^1\rightarrow \mathbb{A}^1,\theta([a:b])=\frac{a}{b}$. This seems to be wrong since it fails if $b=0$... This is my issue, are the maps even the right ones and even if they are, how can they be seen to be rational using the definition above. What I would really like are some examples of varieties which are birationally equivalent to each other and really explain why the maps between these spaces are rational. Another exercise in Hartshorne is to show that any conic in $\mathbb{P}^2$ is birational to $\mathbb{P}^n$ for some $n$. I would like to eventually justify this myself but could someone explain how the specific conic (or another conic, if you so please) $x_1x_0+x_0x_2+x_2^2=0$ is birational to $\mathbb{P}^n$ for some $n$ emphasizing on the explanation of how the maps between these two varieties are rational. As you can probably tell, I am not very good at this subject so please refrain from saying things like ""it's trivial"" or ""it's obvious"" as it will probably won't be obvious to me (of course though, if its the issue of showing something like a bijection, that's all good just please don't dance around the details of rational maps...). Also, I do not know schemes, so please no answers appealing to much higher results than the ones presented in Hartshorne up until this point of the book. Thanks in advance.","['birational-geometry', 'projective-geometry', 'algebraic-geometry', 'commutative-algebra']"
1913728,Probability that no couple sits together in a circle,"Suppose $n$ couples are seated in a circle, and let $P_n$ be the probability that no couple is sitting together. Using Inclusion-Exclusion, I believe it can be shown that $\hspace{.2 in}\displaystyle P_n=1-\sum_{i=1}^n (-1)^{i+1}\binom{n}{i}2^i\frac{(2n-1-i)!}{(2n-1)!},$ and I would like to find out how to prove that  $\displaystyle\lim_{n\to\infty}P_n=\frac{1}{e}\;\;$ (or show that this is not the case). Here are some numerical values: $P_3\approx.267,\;P_4\approx.295,\;P_5\approx.310\;, P_6\approx.320,\;P_7\approx.327,\;P_8\approx.332,\;P_9\approx.336,\;\;P_{10}\approx.340$ For a related question, see Showing probability no husband next to wife converges to $e^{-1}$","['combinatorics', 'probability', 'discrete-mathematics']"
1913755,Global inf-sup condition in Brezzi (Babuška-Brezzi or Ladyzhenskaya-Babuška-Brezzi) Theorem,"I'm studing the Brezzi Theorem (also called Babuška-Brezzi or Ladyzhenskaya-Babuška-Brezzi Theorem). The Theorem 1 (on that link) ensures the continuous dependence of the solution, that is $$\|(u,\lambda)\|_{X\times M}\leq C\{\|f\|_{X^*}+\|g\|_{M^*}\}.$$ With this expresion and recalling that $$\|f\|_{X^*}=\sup_{v\in X}\dfrac{\langle f,v\rangle}{\|v\|_X}\quad\text{ and }\quad\|g\|_{M^*}=\sup_{\mu\in M}\dfrac{\langle g,\mu\rangle}{\|\mu\|_M}$$ we obtain that $$\|(u,\lambda)\|_{X\times M}\leq C\left\{\sup_{v\in X}\dfrac{\langle f,v\rangle}{\|v\|_X}+\sup_{\mu\in M}\dfrac{\langle g,\mu\rangle}{\|\mu\|_M}\right\}$$ $$=C\left\{\sup_{v\in X}\dfrac{a(u,v)+b(v,\lambda)}{\|v\|_X}+\sup_{\mu\in M}\dfrac{b({\color{red}u},\mu)}{\|\mu\|_M}\right\}$$ My question is, it is possible to prove the following? $$\boxed{\|(u,\lambda)\|_{X\times M}\leq C\left\{\sup_{(v,\mu)\in X\times M}\dfrac{a(u,v)+b(v,\lambda)+b({\color{red}u},\mu)}{\|(v,\mu)\|_{X\times M}}\right\}}$$ This is something like a global inf-sup condition.","['functional-analysis', 'supremum-and-infimum', 'partial-differential-equations']"
1913763,Why unit circle has radius 1 [closed],"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 7 years ago . Improve this question I'm looking for how demonstrate why unit circle has radius 1, but I don't know how start. Please I need a hint.","['circles', 'trigonometry']"
1913765,Show that a particular mapping of an open ball in $\mathbb{R}^k$ onto $\mathbb{R}^k$ is a diffeomorphism.,"This is a problem from Guilleman and Pollack: Page 5, question 4. Let $B_a$ be the open ball $\{ x: |x|^2 < a \}$ in $\mathbb{R}^k$, where $|x|^2 = \sum_i x_i^2$. Show that the map \begin{equation}
x \mapsto \frac{ax}{\sqrt{a^2 - |x|^2}}
\end{equation} is a diffeomorphism of $B_a$ onto $\mathbb{R}^k$. My question is mostly about the language of this problem. The author says show that this is a map ${\bf onto}$ $\mathbb{R}^k$. Does this mean it is supposed to be a ${\bf surjective}$ map? If so, shouldn't the definition of the ball be such that $\{ x: |x|^2 < a^2 \}$, so that it is a ball of radius $a$, and points near the boundary get sent to infinity in $\mathbb{R}^k$?","['general-topology', 'differential-geometry', 'differential-topology']"
1913778,"Using the standard basis of $\mathbb{R}^2$, determine the matrix of each of the following linear transformations","I've asked questions about these problems before but thus far, no one has been able to help me understand. I've been attempting these problems for tens of hours over a couple of weeks now. I'm desperate for some help. The problem are as follows: Exercise 6. Using the standard basis of $\mathbb R^2$ , determine the matrix of each of the following linear transformations and compute their determinants: (1) and anitclockwise rotation of angle $\theta$ around the origin. (2) (Harder) a reflection in a line forming an angle $\theta/2$ with the $x$ -axis. The issue is not the linear transformation aspects - I can do those problems well. However, despite having done trigonometry in the past, I think my professors skipped over anything comparable to this. I really just cannot grasp the trigonometry aspect of these. At this point, I've literally spent tens of hours trying to understand these and have not been able to. Please, help me understand how the trigonometry of these problems works and please use simple mathematical language. Note that I have studied trigonometry in the past but there must be deficiencies since I just cannot understand how the trigonometric angles are derived using the usual ( $x = \cos(\theta)$ , $y = \sin(\theta)$ ). According to the solutions given in the book the result should be $\begin{pmatrix}
  \cos\theta & \sin\theta \\
  \sin\theta & -\cos\theta \\
\end{pmatrix}$ . Please help! I'm desperate at this point. Thank you.","['matrices', 'trigonometry', 'reflection', 'linear-transformations', 'linear-algebra']"
1913797,Greatest number of parts that n circles can divide the plane,"What is the greatest number of domains(or parts) that n circles could divide the plane? From many small cases I get the feeling that intersecting circles would provide the greatest number of parts. 
Is this recursion right C(n+1) = 2C(n) using the previous statement. Since the new circle intersects all the circles and doubles the parts. Here C(n) is the number of parts for n circles. How could I prove formally? If I could get an inequality that I will know for sure that I have got the greatest number of parts.","['combinatorics', 'discrete-optimization', 'discrete-mathematics', 'geometry']"
1913829,Why is the line at infinity one-dimensional?,"Why is the line at infinity a one-dimensional manifold, i.e. why is it truly a ""line"" at infinity and not a plane? Is my reasoning below at all correct? (When I say ""dimension"" I mean ""real dimension"" if talking about $\mathbb{RP}^2$ and ""complex dimension"" when talking about $\mathbb{CP}^2$ -- I do see why the complex line at infinity would be a two-real-dimensional manifold if the real line at infinity is a one-dimensional manifold.) Naively, it seems like the line at infinity has two degrees of freedom, not just one. For either $\mathbb{RP}^2$ or $\mathbb{CP}^2$, it seems like one should have the following ""basis"" for the line at infinity: $$(1:0:0), (0:1:0) $$ Note: while writing up this question, I think I may have already thought up of an answer, so my attempt (which is long and not very rigorous) is included as a community wiki answer below, and I will add the (proof-verification) tag. However, I more or less only want to know any elegant answers/proofs which you may have, rather than whether or not my tentative  answer is correct.","['projective-space', 'projective-geometry', 'algebraic-geometry', 'proof-verification']"
1913851,Video Lectures that closely follow Rudin's Real Analysis/Royden's Real Analysis,"I plan to apply for the financial engineering course at NTU, Singapore. I intend to study real analysis and measure theory, as I have the mornings and evenings to myself after work. I am working through Rudin's PMA currently, with the help of online videos and am enjoying those. Can someone point me to any video lectures online, that closely follow Rudin's Real Analysis? It would be tremendous help. Thanks, Quasar",['real-analysis']
1913857,Popcorn Probability,"Question:
The time to microwave a bag of popcorn using the automatic setting can be treated as a random variable having a normal distribution with mean 2 min and standard deviation 15 seconds. three independent bags of popcorn A,B and C are selected. The two bags A and B are put into a microwave immediately. As soon as bag A pops, the bag C is put into microwave. Find the probability that B pops before C. I really don't know where do start. I think it would be something along the lines of P(B pops before A)*P(B pops before c - 2). Any help would be greatly appreciated,
 thanks.","['means', 'normal-distribution', 'independence', 'standard-deviation', 'probability']"
1913865,Brezis' Functional Analysis Exercise 2.5,"The exercise is from Brezis's functional analysis page 50: Let $E$ be a Banach space and let $\varepsilon_n$ be a sequence of positive
  numbers such that $\lim \varepsilon_n = 0$. Further, let $(f_n)$ be a sequence
  in $E^{\star}$ statisfying the property,
  $$ \left\{ \begin{array}{l}
     \exists r > 0, \forall x \in E \, \text{with}\, \| x \| < r, \exists C
     (x) \in \mathbb{R} \quad \text{such that}\\
     \\
     \langle f_n, x \rangle \leqslant \varepsilon_n \| f_n \| + C (x) \quad
     \forall n.
   \end{array} \right. $$
  Prove that $(f_n)$ is bounded. ( Hint : Introduce $g_n = f_n / (1 +
\varepsilon_n \| f_n \|)$.) Here is my solution: Fix $x \neq 0$, we have
  $$ g_n (x) = \frac{f_n (x)}{1 + \varepsilon_n \| f_n \|} = \frac{2 \| x \|
   }{r}  \frac{f_n \left( \frac{r}{2 \| x \|} x \right)}{1 + \varepsilon_n \|
   f_n \|} \leqslant \frac{2 \| x \| }{r}  \frac{C \left( \frac{r}{2 \| x \|}
   x \right) + \varepsilon_n \| f_n \|}{1 + \varepsilon_n \| f_n \|} $$ $$ = \frac{2
   \| x \| }{r} \left( \frac{C (x) - 1}{1 + \varepsilon_n \| f_n \|} + 1
   \right) \leqslant \frac{2 \| x \|}{r}  (| C (x) - 1 | + 1) . $$
  for all $n \in \mathbb{N}$. Thus $\sup_n g_n (x)$ is finite for all $x \in
E$. By uniform bounded principle, we derive that
  $$ g_n (x) \leqslant M \| x \| $$
  for all $x \in E$, $n \in \mathbb{N}$. So we get
  $$ f_n (x) \leqslant M (1 + \varepsilon_n \| f_n \|)  \| x \| . $$
  If we restrict $\| x \| \leqslant 1$, and taking the supremum with respect to
  $x$, we have
  $$ \| f_n \| \leqslant M + \varepsilon_n M \| f_n \| . $$
  Since $0 < \varepsilon_n \rightarrow 0$, there exists $n_0 \in \mathbb{N}$
  such that $\varepsilon_n M < 1 / 2$ when $n \geqslant n_0 + 1$. In other
  words,
  $$ \| f_n \| \leqslant 2 M $$
  when $n \geqslant n_0 + 1$. Taking $N = \max \{ \| f_1 \|, \cdots, \| f_{n_0}
\|, 2 M \}$, we have $\| f_n \| \leqslant N$ for all $n \in \mathbb{N}$.
  Therefore, $(f_n)$ is a bounded sequence in $E^{\star}$. Question : I am not quite confident with my proof, because it seems a little bit unclean for me. I would be glad for anyone to check my proof or to give a neat proof. Thanks!","['functional-analysis', 'linear-algebra', 'analysis']"
1913867,Does $A$ have any special status as an $\mathrm{End}(A)$ module?,"Let $A$ be an abelian group and $\mathrm{End}(A)$ its endomorphism ring. Then to give an abelian group $B$ the structure of a (left) $\mathrm{End}(A)$ module, we provide a morphism $\mathrm{End}(A)\to\mathrm{End}(B)$. Obviously $\mathrm{id}:\mathrm{End}(A)\to\mathrm{End}(A)$ gives $A$ the structure of an $\mathrm{End}(A)$ module. Q: Does $A$ have in general any special properties as an $\mathrm{End}(A)$ module? Obviously it's not e.g. the free $\mathrm{End}(A)$ module on a single generator or something (since that's $\mathrm{End}(A)$). A related question is whether non-isomorphic abelian groups can have isomorphic endomorphism rings. I suspect they can (but I should definitely think about this question more), which rules out the possibility that $A$ can have any truly universal properties in the category of $\mathrm{End}(A)$ modules, since universal properties are unique up to isomorphism.","['abelian-groups', 'abstract-algebra', 'modules']"
1913908,"Value of $a,b $ given two conditions","If the function $f (x)=a\log|x|+bx^2+x $ has extreme points at $x=-1,2$ then the value of $a,b $ is? Now at extreme points $1^{st}$ derivative is $0$ so I differentiated it by making cases : i.e.  $x <0,x>0$(which is probably wrong) so we get two equations as $0.5a-4b=-1,2a-4b=-2$:but they yield a wrong answer. Wheres the fault?Thanks","['derivatives', 'calculus']"
1913909,How to prove that $\int_{-\infty}^{\infty} \frac{1-\cos x}{x^2} dx$ equal to $\pi $?,How to prove that $\int_{-\infty}^{\infty} \frac{1-\cos x}{x^2} dx$ equal to $\pi $? Is there any simple approach that does not require knowledge in Fourier Analysis or Complex analysis?,"['real-analysis', 'integration', 'calculus']"
1913921,Conditional Probability for a coin to be fair,"A gambler has in his pocket a fair coin and a biased coin which will land heads with probability $\frac34$. He selects one of the coins at random; when he tosses it, it lands heads.
What is the probability it is the fair coin? (II)If he tosses the same coin a second time, and again it lands heads. What now
is the probability it is the fair coin? (III) If he tosses the same coin for a third time, and this time it lands tails. What now is the probability it is the fair coin? My solution using Bayes: (I)$$P(\text{fair}|\text{heads})=\frac{P(\text{fair}\cap\text{heads})}{P(\text{heads})}=\frac{\frac12\cdot\frac12}{\frac12\cdot\frac12+\frac12\cdot\frac34}=\frac{\frac14}{\frac58}=\frac25$$ (II)
$$P(\text{fair}|\text{heads,heads})=\frac{P(\text{fair}\cap\text{heads}\cap\text{heads})}{P(\text{heads}\cap\text{heads})}=\frac{\frac12\cdot\frac12\cdot\frac12}{\frac12\cdot\frac12\cdot\frac12+\frac12\cdot\frac34\cdot\frac34}=\frac{4}{13}$$ (III)
$$P(\text{fair}|\text{heads,heads,Tails})=\frac{P(\text{fair}\cap\text{heads}\cap\text{heads}\cap\text{tails})}{P(\text{heads}\cap\text{heads}\cap\text{tails})}=\frac{\frac12\cdot\frac12\cdot\frac12\cdot\frac12}{\frac12\cdot\frac12\cdot\frac12\cdot\frac12+\frac12\cdot\frac34\cdot\frac34\cdot\frac14}=\frac{8}{17}$$
Please can someone help me if my understanding is correct.","['bayes-theorem', 'probability']"
1913933,"Constraining a dense sequence on a product space, one factor at a time","Slogan: Given a sequence on $X\times Y$, can we choose subsequences to fix the limit in $X$ while leaving the behavior on $Y$ free? Details: Suppose $X$ and $Y$ are topological spaces and $(x_n,y_n)_n$ is a sequence that is ""limit-dense"" in $X\times Y$, meaning that for every point $(x,y)\in X\times Y$, there is a subsequence $(x_m,y_m)_m$ that converges to $(x,y)$. Does that imply the following: For every point $x\in X$, there is a subsequence $(x_m,y_m)_m$ such that $(x_m)_m$ converges to $x$ and $(y_m)_m$ is limit-dense in $Y$? The answer is ""yes"" if $X$ is first-countable and $Y$ is second-countable. Those axioms give us the open rectangles that we need the subsequence to hit. But are those additional assumptions necessary? Edits: Here's a proof of the earlier claim. Suppose $X$ is first-countable and $Y$ is second-countable. Let $U_1\supset U_2\supset\cdots\ni x$ be a descending countable local basis at $x$ and let $V_i$ be a countable basis on $Y$. Define a sequence of target rectangles $(T_n)_n$ to be $(U_1\times V_1, U_2\times V_1, U_2\times V_2, U_3\times V_1, U_3\times V_2, U_3\times V_3, \ldots)$. Now recursively define the subsequence $n_k$ by $n_0=0$ and for $k\geq 1$, $n_k$ is the first value greater than $n_{k-1}$ such that $(x_{n_k}, y_{n_k})\in T_k$. Then $x_{n_k}\to x$. And for any $y\in Y$, we can find a sequence of $V$s that are a descending countable local basis around $y$, and then a further subsequence of $y_{n_k}$ that stays within that basis. For context, I'm working on an application where $X$ and $Y$ are really nice spaces, compact manifolds, so the claim is fairly obvious: For our target rectangles, we can cover $\{x\}\times Y$ with $1/n$-balls. I'm just curious how far we can take the principle for more general spaces.","['second-countable', 'separable-spaces', 'product-space', 'first-countable', 'general-topology']"
1913942,What is an unit area vector?,"As the title suggests, What is a unit area vector? I've tried googling but unable to arrive at any satisfactory answers. Any help is appreciated.","['physics', 'multivariable-calculus', 'electromagnetism', 'area', 'differential-geometry']"
1913951,Improper Integral $\int_0^\infty\tan\left(\frac x{\sqrt{x^3+x^2}}\right)\frac{\ln(1+\sqrt x)}xdx$,"This integral is from integral Find 
$$\int_0^\infty\tan\left(\frac x{\sqrt{x^3+x^2}}\right)\frac{\ln(1+\sqrt x)}xdx$$ I have get
$$\int_0^\infty\tan\left(\frac x{\sqrt{x^3+x^2}}\right)\frac{\ln(1+\sqrt x)}xdx=\int_0^{\infty}\tan\left(\frac1{\sqrt{x+1}}\right)\frac{\ln(1+\sqrt x)}{x}dx$$
Let$$\dfrac{1}{\sqrt{x+1}}=t$$
that
$$I=\int_{0}^{1}\dfrac{\tan{t}\ln{\left(1+\sqrt{\frac{1}{t^2}-1}\right)}}{t-t^3}dt$$
This integral is have  closed form ?","['calculus', 'closed-form', 'improper-integrals', 'integration', 'analysis']"
1913959,Relationship between Stokes's theorem and the Gauss-Bonnet theorem,"Stokes's theorem and the Gauss-Bonnet theorem are clearly very spiritually similar: they both relate the integral of a quantity $A$ over a region to the integral of some quantity $B$ over the boundary of the region, where $A$ can in some sense be thought of as a ""curvature at one higher derivative"" of $B$ or a closely related quantity.  Is either of these theorems a special case of the other?  If not, is there a more general theorem of which they are both special cases (which isn't too many levels higher up in abstraction)? Edit : the answers to this follow-up question provide derivations of the Gauss-Bonnet theorem from Stokes's theorem in this paper , on pg. 105 of this textbook , and in Chapter 6 Section 1 of this textbook . Unfortunately, the derivations are too advanced for me to understand, as I haven't formally studied graduate-level differential geometry. I would appreciate any answer that summarizes the basic idea of the derivation.","['algebraic-topology', 'stokes-theorem', 'differential-geometry']"
1913980,Is the intersection of $\sin(\mathbb{N})$ and $\cos(\mathbb{N})$ empty?,"My guess is that the intersection is empty and this is as far as I got in an attempt to prove this by contradiction: $\exists n,m \in \mathbb{N}, \cos(n)=\sin(m) \land n \neq m \quad (1)$ $\cos^2(n)=1-\cos^2(m) \iff \cos^2(n)+\cos^2(m)=1 \quad (2)$ I'm almost certain that the last equation can't be satisfied but I'm not sure how to proceed.","['real-analysis', 'trigonometry', 'analytic-number-theory']"
1913999,"The level curves of a function with $|\nabla u(x,y)|=f(u(x,y))$ and $\Delta u=1$ are lines or circles (locally)","Consider $u:\Omega\subset \mathbb R^2\to \mathbb R$ be a $C^2$
  function. Knowing that $\nabla u\neq 0$ everywhere on $\Omega$,
  $\Delta u\equiv 1$ and $|\nabla u(x,y)|=f(u(x,y))$ for some $f$ $C^1$, prove
  that, locally, the level curves of $u$ are lines or circles. My attempt was to prove that these curves have locally constant curvature. I calculated the curvature, following the Frenet formulas, as the module of the derivative of the normal vector. So, given a local arc length parametrization of a level curve (it exists by the implicit function theorem) we can say that $$k(t)=\Big|\frac{d}{dt}\frac{\nabla u(x(t),y(t))}{f(u(x(t),y(t)))}\Big|$$ since the gradient is normal to the level curve. Developing the formulas, one actually makes use of the hypotesis $\Delta u=1$ in order to simplify the expression, but I didn't obtain that $k$ is constant. Is my attempt successful? Are there any better ways? Thank you in advance.","['derivatives', 'real-analysis', 'curvature']"
1914006,Determine for which values the series $\sum_{k=1}^\infty \frac{b^{k^{2}}}{k!}$ is convergent.,"So I am trying to figure out for which positive real numbers b this series $$\sum_{k=1}^\infty \frac{b^{k^{2}}}{k!}
$$ is convergent. Since it looks pretty hard to compare it with other series, I decided to use the ratio test.
$$\lim_{k \to \infty} \left|\frac{b^{(k+1)^{2}}}{(k+1)!}\cdot{\frac{k!}{b^{k^{2}}}}\right| $$ 
$$=\lim_{k \to \infty} \left|\frac{b^{2k+1}}{k+1}\right| < 1 $$ But I am stuck here, this doesnt look too useful. Looking for some help.","['convergence-divergence', 'sequences-and-series', 'calculus', 'analysis']"
1914029,Atiyah Bundles over Elliptic Curves,"I am reading the paper ""Vector Bundles over Elliptic Curves"" by Atiyah. I get a problem in understanding the ""uniqueness"" of the Atiyah bundles. Let me fix the notation first: $X$ is an elliptic over an algebraic closed field. $\mathcal{E}(r,0)$ is the set of all indecomposable holomorphic vector bundles over $X$, which have rank $r$ and degree $0$ As is stated in Lemma 16 (I am focusing on $d=0$ case): ""For any $E'\in\mathcal{E}(r',0)$ with $\Gamma(E')\neq 0$, there exists $E\in\mathcal{E}(r,0)$, unique up to isomorphism, given by the extension
$$0\rightarrow I_1\rightarrow E\rightarrow E'\rightarrow 0,$$
where $I_1$ is the trivial line bundle of $X$."" However, in the simplest case $r'=1$, any self extension of $I_1$ gives such a $E$ and since the space of isomorphism class of self extensions of $I_1$ is given by
$$H^1(X,Hom(I_1,I_1))=H^1(X,I_1)=H^{0,1}(X)=\mathbb{C}.$$
Hence every non-trivial element in $H^1(X,Hom(I_1,I_1))$ would correspond an indecomposable self extension of $I_1$ with degree $0$ and therefore such $E$ can't be unique. I think I must get something wrong but I don't see that. It would be my pleasure if somebody can point out what I get wrong. Thank you very much!","['elliptic-curves', 'complex-geometry', 'algebraic-geometry', 'holomorphic-bundles']"
1914098,Is the interior of the closure of a set equal to the interior of that set?,"I tried to prove that with the set being  subset of a space X with metric d,
"" the interior of the closure of a set equal to the interior of that set"".
I proved that the interior of,namely, $A$ is included in the interior of the closure of $A$. But I could not prove the reverse, in special because I think that there can be points that are limit points of A and is contained in the interior of the closure, am I wrong? I am doing this to prove that the closure is equal to the union of the interior points of the closure with the set of all limit points of the set. Is the aforementioned statement true? Thank you.","['proof-verification', 'proof-writing', 'proof-explanation', 'algebraic-topology', 'general-topology']"
1914121,Integral $\int\frac{\sqrt{\cot x}} {\sin x \cos x}dx$,"How can we evaluate the integral?:
$$\int\frac{\sqrt{\cot x}} {\sin x \cos x}dx$$
To get an answer in terms of $\sqrt{\cot x}$? I tried using sin2x formula and then by-parts but didn't get the answer. P.S- I am a beginner in integrals. Would love some tips on how to learn the same and what all to keep in mind while solving it's problems.","['trigonometry', 'calculus', 'indefinite-integrals', 'integration', 'trigonometric-integrals']"
1914226,Generating the compact-open topology on the Pontryagin dual group.,"Let $X$ be a topological space, and let $K \subset X$ be compact and $U \subset \mathbb{C}$ be open. Define 
$$ L (K,U) := \{ f : X \to \mathbb{C} \; | \; f(K) \subset U \}. $$ Then the topology generated by the sets $L(K,U)$, as $K$ and $U$ vary, is the compact-open topology on the space of continuous functions $C(X, \mathbb{C})$. There is the following result: Let $\mathcal{U}$ be a basis for the locally compact Abelian group $G$ and let $\mathcal{U}_c$ denote the set of all relatively compact sets $U \in \mathcal{U}$, i.e., the set $\overline{U}$ is compact. Then the sets $L(\overline{U}, V)$, where $U \in \mathcal{U}_c$ and $V \subset \mathbb{T}$ open, generate the compact-open topology on the Pontryagin dual group $\widehat{G}$. I understand all the necessary concepts. My idea to prove this is to show that the collection $\mathcal{F}$ of all finite intersections of sets $L(\overline{U}, V)$ forms a basis for the compact-open topology on $\widehat{G}$. However, I am unable to do so. Any help and/or comment is highly appreciated.","['locally-compact-groups', 'general-topology', 'topological-groups']"
1914263,$f$ ACL $\implies \exists \nabla f$ almost everywhere,"We have the following definition for an absolutely continuous function: Definition (absolutely continuous): A function $f:I\to \mathbb{R}^n$ , $I \subset \mathbb{R}$ interval, is said to be absolutely continuous if, $\forall \epsilon>0$ , $\exists \delta>0$ such that, $$[x_k,y_k]\subset I, k\in \{1,\dots,n\}\text{ pairwise disjoint intervals with }\sum_{k=1}^n|y_k-x_k|<\delta$$ $$\implies\sum_{k=1}^n|f(y_k)-f(x_k)|<\epsilon.$$ And then, we have the following proposition Proposition 1: If $f:I\longrightarrow\Bbb{R}^n$ is absolutely continuous, then $f$ is differentiable at almost everywhere in $I$ . Ok, now we give the definition of a absolutely continuous on lines (ACL) function. Definition (ACL): Let $\Omega\subset \Bbb{R}^n$ be a domain (open connected set) and $F:\Omega\longrightarrow \Bbb{R}^m$ a function. Given a $n$ -dimensional parallelepiped $P=[a_1,b_1]\times \dots \times [a_n,b_n]\subset \Omega$ and given a choice of $n-1$ fixed values $x_1\in [a_1,b_1],\dots,x_{i-1}\in[a_{i-1},b_{i-1}],x_{i+1}\in[a_{i+1},b_{i+1}],\dots,x_n\in[a_n,b_n]$ , we define the function $$\begin{array}{cccc}F^P_{x_1\dots x_{i-1}x_{i+1}\dots x_n}:&[a_i,b_i]&\longrightarrow &\Bbb{R}^m\\ &x_i&\mapsto& F(x_1,\dots,x_i,\dots,x_n)\end{array}$$ which ""fix"" the coordinates of $F$ at $P$ , except for $x_i$ . Then, we say $F$ is absolutely continuous on lines (or, simply, ACL), if, for every parallelepiped $P\in \Omega$ , $$F^P_{x_1\dots x_{i-1}x_{i+1}\dots x_n} \text{ is absolutely continuous for almost every ""$n-1$-choice"" as above.}$$ What I want to prove, maybe throughout Proposition 1, is Proposition 2: If $F:\Omega\subset \Bbb{R}^n\longrightarrow \Bbb{R}^m$ is ACL, then $\nabla F$ (or, partial derivatives) exists almost everywhere on $\Omega$ . ""Almost everywhere"" (:D) I've searched, books say ""it's easy to see"", ""easy to prove"", but I could not do it by myself. Can some one at least give me some insight of how to do it? I really need the case where $n=m=2$ . Fixing $x$ and looking to $F^R_x(y)=F(x,y)$ , I've tried to use that, at those points in which $F^R_y$ is NOT absolutely continuous is a set of measure zero, Proposition 1 holds. And, then, to look to the points where $F_x^R$ is NOT differentiable (which again has measure zero) and finally to make the union (in $x$ ) of all these sets, hoping that this had still measure zero. Done this, I would have taken out from $R$ a set of measure zero. Doing the same for fixed $y$ 's I would have reached the result. But my conjecture has prooved to be FALSE (in the sense that this set I'm looking at might NOT TO BE MEASURABLE), as we see here . THANK YOU, GUYS!","['derivatives', 'almost-everywhere', 'lebesgue-measure', 'continuity', 'measure-theory']"
1914271,Proving a sequence is in $\ell^{p'}$ - Brezis' Exercise 2.7,"I am self-studying Brezis' functional analysis, and here is an exercise in it: Exercise 2.7 Let $a=(a_n)$ be a given sequence sequence of real numbers and let $1\leq p\leq\infty$. Assume that 
  $$\sum |a_n x_n|<\infty$$
  for every $x=(x_n)\in \ell^p$. Prove that $a\in\ell^{p'}$, where $\frac{1}{p}+\frac{1}{p'}=1$. My attempt (basically following the book's hint): Write $E=\ell^{p}$. Define $$T_nx:=\sum_{i=1}^n a_ix_i$$ 
  for all $n\in \mathbb{N}$. Note that $T_n\in E^\star$. Since $\sum |a_n x_n|<\infty$, $T_nx$ tends to a limit $Tx\in\mathbb{R}$ as $n\rightarrow\infty$. By uniform boundedness principle, we have
  $$|T_nx|\leq C\lVert x\rVert_{\mathscr{l}^p}$$
  for some $C>0$. I stopped here. It seems that I need to take specific $x$ to derive desired conclusion, but I only have a little experience with sequence spaces. Could anyone offer a further hint for me?","['functional-analysis', 'sequences-and-series', 'analysis']"
1914282,Determining probability of a normal random variable at a single point?,"I tried to do this exercise from A first course in probability by Sheldon Ross: An image is partitioned into two regions, one
  white and the other black. A reading taken from
  a randomly chosen point in the white section will
  give a reading that is normally distributed with $μ =
4$ and $σ^2 = 4$, whereas one taken from a randomly chosen point in the black region will have a normally
  distributed reading with parameters $(6, 9)$.
  A point is randomly chosen on the image and has
  a reading of $5$. If the fraction of the image that is
  black is $α$, for what value of α would the probability
  of making an error be the same, regardless of
  whether one concluded that the point was in the
  black region or in the white region? My attempt at the problem: Let $A$ be the event that the chosen point has a reading of $5$, and $B$ that it's in the black region.
We need to show that $P(B\mid A)=P(B'\mid A)$, which is equivalent to $P(B\mid A)=\frac12$. We know that $$P(B\mid A)=\frac{P(B)P(A\mid B)}{P(B)P(A\mid B)+P(B')P(A\mid B')}$$ Here is my problem. Isn't $P(A)=0$, because of the normal random variable being continuous? If so, how can I compute $P(A\mid B)$ and $P(A\mid B')$? Or maybe my whole approach is wrong?","['probability', 'random-variables']"
1914284,"Why is , $ \mathcal{O} (1) $ restricted to a curve $ C $, of degree $ d $?",Let $ C \subset \mathbb{P}^2 $ be a smooth curve defined by a homogeneous polynomial $ f $ of degree $ d $. How to establish that the line bundle $ \mathcal{O} (1) $ restricted to $ C $ is of degree $ d $ ? Thanks in advance for your help.,"['complex-geometry', 'algebraic-geometry']"
1914318,"Prove that one of two given complex numbers is $1$ or $-1$, when $uv = 5 + 2i\sqrt{3}$","Given the set $A = \{a + ib\sqrt{3} \mid a, b \in \mathbb{Z}\}$ and $u, v \in A$ with $uv = 5 + 2i\sqrt{3}$, prove that one of $u$ and $v$ is $1$ or $-1$. First, lets represent $u$ and $v$ as follows: $u = a + ib\sqrt{3}$ and $v = c + id\sqrt{3}$, where $a, b, c, d \in \mathbb{Z}$. By doing some basic operations on what we are given, I got the following $abcd = 0$ and $(a^2 - 3b^2)(c^2 - 3d^2) = 13$. Because $a, b, c, d$ are integers, we only have four possibilities for the last multiplication: $1 \cdot 13, 13 \cdot 1, -1 \cdot (-13), -13 \cdot (-1)$. Now, we need to consider each of these cases and in every case we also need to deal with $abcd = 0$ by setting each of the numbers $a, b, c, d$ to $0$ separately. After doing what I explained above, I first got $b = 0$ and $a = \pm 1$ and then $d = 0$ and $c = \pm 1$. However, this solution seems to be a little bit too long, and I would like to have a more direct solution. So, if you have any ideas, please share them! Thank you!","['algebra-precalculus', 'complex-numbers']"
1914338,"How to prove that $[2^n \sqrt{2}],[2^{n+1} \sqrt{2}],\ldots, [2^{2n} \sqrt{2}]$ contains at least one even numbers for every integer $n\ge 1$?","I tried as follows: If not, denote $x=\{2^{n-1}\sqrt{2}\}$, then 
  $$1-\frac{1}{2^{n+1}}<x<1.$$
Denote $y=[2^{n-1}\sqrt{2}+1]$ and assume $|\sqrt{2}-p/q|<1/q^2$, then
  $$\frac{2^{n-1}p}{q}-\frac{2^{n-1}}{q^2}<y<\frac{2^{n-1}p}{q}+\frac{2^{n-1}}{q^2}+\frac{1}{2^{n+1}}.$$ But it doesn't work.","['number-theory', 'diophantine-approximation']"
1914354,Showing the radius of convergence for a power series is equal to the radius of convergence for its derivative,"Consider the power series: $$
\sum_{n=0}^{\infty} a_n (x - c)^n
$$ Now consider its derivative: $$
\sum_{n=1}^{\infty} n a_n (x - c)^{n-1}
$$ We can say at first that the Radius of Convergence for the original power series is $$
R = \lim_{n \to \infty} |a_{n+1} / a_{n}|
$$ (via the Ratio Test). On the other hand, can we not also say that the radius of convergence for the derivative of the power series is $$
\lim_{n \to \infty} \left|\frac{(n+1) a_{n+1}}{n a_{n}} \right| = |a_{n+1} / a_{n}| = R?
$$ via the same argument?  Is my reasoning correct?  That is, is the argument that the Radius of Convergence the same for both a power series and its derivative really this simple? :)","['real-analysis', 'power-series']"
1914363,Open sets with compact closure containing a given compact set,"Let $X$ be a locally compact Hausdorff space. Let $K \subset X$ be a compact subspace, and $U \subset X$ an open set, such that $K \subset U$. Can we find an open set $V \subset X$ such that $K \subset V \subset U$ and $\overline V$ is compact? I know that for all $x \in U$ there is an open set $V_x \ni x$ with compact closure contained in $U$. But the closure of $\bigcup_{x \in K} V_x$ doesn't have to be compact.","['general-topology', 'compactness']"
1914378,Setting up Equations for Mixture Problem,"An automobile radiator contains 16 liters of antifreeze and water. This mixture is 30% antifreeze. How much of this mixture should be drained and replaced with pure antifreeze so that there will be 50% antifreeze? I can obtain the answer using my own method of solving this problem, but the problem is that I need to set up equations for this, looking for help, thanks","['algebra-precalculus', 'systems-of-equations']"
1914409,A demonstration of Lagrange's Form for the Remainder of a Taylor Series,"The following argument for Lagrange's Form for the Remainder of a Taylor polynomial is a typical one in analysis books.  Even in the case of finding the remainder when the Taylor polynomial is a linear polynomial, deciding on the functions $g(x)$ and $h(x)$ is not apparent.  (See the following argument.)  Can someone provide the motivation for these functions?  Also, does anyone know who concocted this argument? Lagrange's Form for the Remainder $f$ is a twice differentiable function defined on an interval $I$, and $a$ is an element in $I$ distinct from any endpoints of $I$. For every real number $x \in I$ distinct from $a$, there is a real number $c$ between $a$ and $x$ such that
\begin{equation*}
R_{1}(x) = \frac{f^{(2)}(c)}{2!} \, (x - a)^{2} .
\end{equation*}
So, if $T_{1}$ denotes the linear Taylor polynomial of $f$ at $a$,
\begin{equation*}
f(x) = T_{1}(x) + \frac{f^{(2)}(c)}{2!} \, (x - a)^{2} .
\end{equation*} Demonstration \begin{equation*}
g(u) = f(x) - \Bigl[f(u) + f^{\prime}(u)(x - u)\Bigr]
\end{equation*}
is a differentiable, and
\begin{equation*}
g^{\prime}(u) = - f^{\prime\prime}(u)(x - u) .
\end{equation*}
The function
\begin{equation*}
h(u) = g(u) - g(a) \left(\frac{1}{x - a}\right)^{2} (x - u)^{2}
\end{equation*}
is a also differentiable, and
\begin{equation*}
h^{\prime}(u) = - f^{\prime\prime}(u)(x - u) + 2g(a) \left(\frac{1}{x - a}\right)^{2} (x - u) .
\end{equation*}
Moreover, $h(x) = g(x) = 0$, and $h(a) = 0$. According to Rolle's Theorem, there is a real number $a < c < x$ such that $h^{\prime}(c) = 0$.
\begin{equation*}
0 = h^{\prime}(c)
= - f^{\prime\prime}(c)(x - c) + 2g(a) \left(\frac{1}{x - a}\right)^{2} (x - c) ,
\end{equation*}
or equivalently, since $x \neq c$ and since
\begin{equation*}
g(a) = f(x) - \Bigl[f(a) + f^{\prime}(a)(x - a)\Bigr] ,
\end{equation*}
\begin{equation*}
f(x) - \Bigl[f(a) + f^{\prime}(a)(x - a)\Bigr] = \frac{f^{\prime\prime}(c)}{2!} \, (x - a)^{2} .
\end{equation*}","['real-analysis', 'math-history', 'taylor-expansion', 'calculus', 'analysis']"
1914440,On the sum of the reciprocals of the roots of a Polynomial,"A polynomial of degree n with real coefficients may be represented as $$P(x) = \sum_{i = 0}^n a_ix^i$$ which when factorised yields $$P(x) = (x-r_1)(x-r_2)\cdots(x-r_n)$$ where $r_1, r_2,\cdots,r_n$ are the roots of the polynomial. Now consider the first derivative of this polynomial. This will be $$P^{'}(x) = \frac{(x-r_1)^{'}P(x)}{(x-r_1)} + \frac{(x-r_2)^{'}P(x)}{(x-r_2)} + \frac{(x-r_3)^{'}P(x)}{(x-r_3)}+ \cdots + \frac{(x-r_n)^{'}P(x)}{(x-r_n)}$$ On simplifying and rearranging we get $$P^{'}(x) = \frac{P(x)}{(x-r_1)} + \frac{P(x)}{(x-r_2)} + \frac{P(x)}{(x-r_3)}+\cdots+ \frac{P(x)}{(x-r_n)}$$ $$P^{'}(x) = P(x)\left(\frac{1}{x-r_1} + \frac{1}{x-r_2} + \frac{1}{x-r_3} + \cdots+ \frac{1}{x-r_n}\right)$$ $$\frac{P^{'}(x)}{P(x)} = \frac{1}{x-r_1} + \frac{1}{x-r_2} + \frac{1}{x-r_3} + \cdots + \frac{1}{x-r_n}$$ for $x = 0$, we have $$\frac{P^{'}(0)}{P(0)} = \frac{1}{-r_1} + \frac{1}{-r_2} + \frac{1}{-r_3} +\cdots +  \frac{1}{-r_n}$$ $$-\frac{P^{'}(0)}{P(0)} = \sum_{i = 0}^n\frac{1}{r_i}$$ I'm an amateur at best so please share your views.","['algebra-precalculus', 'polynomials']"
1914443,Verify a distribution that is exponential family,"Given the parametric class formed by the density functions defined as follows:
  $$p(y;\theta)=\theta(\theta+1)y(1-y)^{\theta-1},\ y\in(0,1),\ \theta >0$$
  Does this parametric class forms an exponential family like $$f(y, \theta)=q(y) exp\{\phi(\theta)t(y)-\tau(\theta)\}$$
  ? I could write the density function in this way:$$p(y;\theta)=y\exp\{(\theta-1)ln(1-y)+ln(\theta(\theta+1))\}$$ so, if $$q(y)=y,\ \phi(\theta)=(\theta-1),\ t(y)=,\ \tau(\theta)=-ln(\theta(\theta+1))$$ then the answer should be yes. Is that correct? Is also correct the relationship $p(y;\theta)=Beta(2,\theta)$?","['self-learning', 'statistics']"
1914444,Complex analysis vs Real Analysis of $\lim_{x\to0}{x}^{x}$,"In attempting to solve $\lim_{x\to0}x^x$, I tried two different approaches. One is to convert $x^x$ into a complex function and solve the limit in $\mathbb{C}$. The other is to take the limit of the points of the dense sets in $\mathbb{R}^{-}$ and $\mathbb{R}^{+}$. According to this article , $\lim_{x\to0}{x}^{x}$ can be converted into
$\lim_{x\to{0}}|x|^{x}(\cos((2n+1)\pi x)+i\sin((2n+1)\pi x)$ where $n\in\mathbb{N}$ are the branches of complex logarithm. This leads to $$\lim_{x\to0}{|x|}^{x}\lim_{x\to0}\cos((2n+1)\pi x)+i\lim_{x\to0}|x|^{x}\lim_{x\to0}\sin((2n+1)\pi x)=1$$ So using complex analysis $\lim_{x\to0}{x^x}=1$ However, if we take the points on real axis, where x-values of the complex function of $|x|^{x}(\cos((2n+1)\pi x)+i\sin((2n+1)\pi x)=a+0i$ (see this graph) , we have the following domain.  $$\left\{x=\left.-\frac{m}{2k+1}\right|m,k\in\mathbb{N}\right\}\bigcup{\mathbb{R}^{+}}$$ Which is divided into $$x^x=\begin{cases} x^x & x>0\\ |x|^x & x=\left\{ -{2m\over 2k+1}\ |\ m, k \in \Bbb N\right\}\\ -|x|^{x} & x=\left\{ -{2m+1\over 2k+1}\ |\ m, k \in \Bbb N\right\}\ \\ \text{undefined} & x=\left\{ -{2m+1\over 2k}\ |\ m, k \in \Bbb N\right\}\bigcup \left\{\mathbb{R}^{-}\backslash \mathbb{Q}^{-}\right\} \end{cases}$$ Since $\left.-\frac{2m+1}{2k+1}\right|m,k \in \mathbb{N}$ and $\left.-\frac{2m}{2k+1}\right|m,k \in \mathbb{N}$ are dense sets; they can approximate arbitrarily close to any  $x\in{\mathbb{R}}^{-}$. Thus a limit can exist if the subsets converge to the same value. Hence $\lim_{x\to0}x^x$ exists if $$\lim_{\left\{x\in-\frac{2m+1}{2k+1}\right\}\to0^{-}}x^x=\lim_{\left\{x\in-\frac{2m}{2k+1}\right\}\to0^{-}}x^x=\lim_{x\to0^{+}}{x^x}$$ Which is the same as $$\lim_{x\to0^{-}}-|x|^x=\lim_{x\to0^{-}}|x|^x=\lim_{x\to0^{+}}x^x$$ However this equality fails since $\lim_{x\to0^{-}}-|x|^x=-1$ and the other limit are equal to $1$. So using real analysis, $\lim_{x\to0}x^x$ does not exist. I believe that the limit should be the same by real or complex analysis but I am no expert in either feild. Did I do both approaches correctly? Does my answer depend on which analysis I use?","['complex-analysis', 'real-analysis', 'differential-topology', 'limits']"
1914513,Is $\mathbb{Z}[[t]][x]/(x^2-(1+t))$ integrally closed?,"Since $\mathbb{Z}$ is a PID, $\mathbb{Z}[[t]]$ is a UFD. Note that the square root of $1+t$ is:
$$1 + \frac{t}{2} -\frac{t^2}{8}+\cdots$$
Thus, the polynomial $x^2-(1+t)$ has no roots in $\mathbb{Z}[[t]]$, so it is irreducible, hence prime, and thus $\mathbb{Z}[[t]][x]/(x^2-(1+t))$ is an integral domain. Is it integrally closed? What is its ramification locus over $\mathbb{Z}[[t]]$? EDIT: The ramification locus certainly contains $(2)$ and $(1+t)$. Could it be ramified elsewhere?","['algebraic-geometry', 'commutative-algebra']"
1914515,The integral $\int\frac{2(2y^2+1)}{(y^2+1)^{0.5}} dy$,"What is $$\int\frac{2(2y^2+1)}{(y^2+1)^{0.5}} dy?$$ I split it as $\frac{y^{2}}{(y^2+1)^{0.5}} + \sqrt{y^2+1}.$ Now I substituted $y^{2}=u $ thus $2y\,dy=du$ so we get $0.5 \sqrt{\frac{u}{u + 1}} + 0.5 \sqrt{\frac{1 + u}{u}}$ but now what to do? Another idea was doing $+1-1$ in original question but that too doesn't lead anywhere. Now $y=\tan{x} $ as suggested below is an easy way but I am seeking for a purely algebraic way. Thanks.",['integration']
1914565,How to prove that : $\sum \limits_{k=0}^{n-1} \lfloor x+\frac{k}{n}\rfloor = \lfloor nx\rfloor$? [duplicate],"This question already has answers here : Prove $\Sigma_{k=0}^{n-1}\lfloor x+\frac{k}{n}\rfloor=\lfloor nx\rfloor$ , n is a Natural Number (2 answers) Closed 7 years ago . for all $x\in \mathbb{R}$ and $n\in\mathbb{N}^*$ without using euclidian division. First I re-write the sum in this way : $\sum \limits_{k=0}^{n-1} \lfloor x+\frac{k}{n}\rfloor = \lfloor x\rfloor+\lfloor x+\frac{1}{n}\rfloor+... +\lfloor x+\frac{i-1}{n}\rfloor+ \lfloor x+1-\frac{i}{n}\rfloor+...+\lfloor x+1-\frac{1}{n}\rfloor$ Now we can see that there is two possibilities for $x$ between two natural numbers $[q,q+1]$. Indeed we have the part $\sum \limits_{k=0}^{i-1}\lfloor x+\frac{k}{n}\rfloor=ji$ with $0\le j\le n$.And the other part $\sum \limits_{k=i}^{n-1}\lfloor x+1-\frac{k}{n}\rfloor=(j+1)(n-i)$. Finally the floor will be $nj+(n-i)$. Now for $\lfloor nx \rfloor$ it will be between $[nq,nq+q]$ which lets $n$ possibilities for its values but it would be perfect if it was $nj+(n-i)$ . Thanks in advance !","['algebra-precalculus', 'proof-writing', 'proof-verification', 'ceiling-and-floor-functions']"
1914591,"Dual number $(a+b\varepsilon)$ raised to a dual power, e.g. $(a+b\varepsilon)^{(c+d\varepsilon)}$","I'm working on some code which utilizes Newton's method, and I would like to take advantage of dual numbers to simplify taking the derivative. I've worked out a class definition Dual which works great for polynomials, pow (where either base or exponent is real) exp , and log . However, I am a bit stymied at raising a dual number to the power of another dual number, e.g. $(a+b\varepsilon)^{(c+d\varepsilon)}$ I used the general form derived from the Taylor series $f(a+b\varepsilon) = f(a) + bf'(a)\varepsilon$ to derive the rules for $x^n$ and $n^x$ where $n$ is real and $x$ is dual. For those, I got: $x^n = a^n + bna^{n-1}$ , where $ x = a+b\varepsilon$ $n^y = n^c + d\ln(n)n^{c}$ , where $  y = c+d\varepsilon$ Substituting and simplifying, I end up with: $x^y = a^c + (d\ln(a)a^c + bca^{c-1})\varepsilon$ This seems to work right in my code, but I do not know if this is actually correct. The implementations of exp and pow work properly with this more general code, and $\varepsilon^\varepsilon = 1 + NaN\varepsilon$, which is a good-ish sign (if I got something well-formed, that would be more troubling). Is this formula valid?","['derivatives', 'hypercomplex-numbers', 'nilpotence']"
1914612,Does topology apply to the integers? [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question What is the natural topology (or topologies) on the integers. Can we define a metric on the integers?","['general-topology', 'metric-spaces', 'integers']"
1914614,Evaluate this sum: $ \sum_{q=0}^{2n} \binom{p+l-q}{p} \binom{2n}{q}$,"In the midst of a calculation, I ran into the following sum.  I'd like to find a form for it which is more explicit, although I haven't figured anything out yet.  Here it is: Let $p,l$ and $n$ be positive integers with $p+l\geq 2n$.  Then I would like to evaluate:
$$
\sum\limits_{q=0}^{2n}\begin{pmatrix}p+l-q\\p\end{pmatrix}\begin{pmatrix}2n\\q\end{pmatrix}
$$
Any ideas/hints/thoughts?  Thanks!","['combinatorics', 'summation', 'binomial-coefficients']"
1914692,Shortest distance between helix and line?,"What is the shortest distance between the helix with parametric equations:
$$x = \cos u, \quad y = \sin u, \quad z = \tfrac{2}{\sqrt{\pi}}u\qquad \text{ for }u \in\mathbb{R}$$ and the line
$$x + y = \sqrt{2},\quad z = −\sqrt{\pi}$$ What are the steps that should be followed in solving this problem or other similar ones?","['parametric', 'optimization', 'geometry']"
1914697,Solving exponential equation of form $(a+b)^x + (a-b)^x = c$,"I'm given equation:
$$\left(2-\sqrt3\right)^\frac{x}{2} + \left(2+\sqrt3\right)^\frac{x}{2} = 4,$$
and I'm stuck with it. Which way shall I dig into to solve it?","['algebra-precalculus', 'logarithms', 'exponential-function']"
1914718,Open set containing cantor set,Is it possible to construct an open set of measure less than a given positive real and containing cantor set?,"['measure-theory', 'cantor-set']"
1914816,$X: \mathbb{R} \to \mathbb{R}$ is not Lipschitz continuous,"Show that there doesn't exist any Lipschitz continuous function $X: \mathbb{R} \to \mathbb{R}$ with following property: The curve $\gamma : \mathbb{R} \to \mathbb{R}$, $\gamma(t)=\frac{t^2}{1+t^2}$ is a solution curve to differential equation $\dot{\gamma}(t)=X(\gamma(t)).$ This was as an exercise in previous exam in Analysis 2. But, in my all efforts I was capable to show that such a function $X$ is in fact Lipschitz-continuous. I have used the fact $\dot{\gamma}(t)=\frac{2t}{(1+t^2)^2}=X(\gamma(t))$ and by definition of Lipschitz continuity this was in fact bounded for all $t \in \mathbb{R}$. I am not sure if I understood real problem or not but I need your help for this question.","['real-analysis', 'ordinary-differential-equations', 'analysis']"
1914821,A generalization of the product of harmonic numbers to non-integer arguments,"This question is somewhat related to one of my previous questions: Fibonorial of a fractional or complex argument . Recall the definition of harmonic numbers:
$$H_n=\sum_{k=1}^n\frac1k=1+\frac12+\,...\,+\frac1n\tag1$$
Obviously, harmonic numbers satisfy the following functional equation:
$$H_n-H_{n-1}=\frac1n\tag2$$
The definition $(1)$ is valid only for $n\in\mathbb N$, but it can be generalized to all positive indices. There are several equivalent ways to do this:
$$H_a=\sum_{k=1}^\infty\left(\frac1k-\frac1{k+a}\right)=\int_0^1\frac{1-x^a}{1-x}\,dx=\frac{\Gamma'(a+1)}{\Gamma(a+1)}+\gamma\tag3$$
This generalized definition gives a real-analytic function (that can be extended to a complex-analytic if needed) and still satisfies the functional equation $(2)$ even for non-integer values of $a$. Now, consider the product of harmonic numbers:
$$P_n=\prod_{k=1}^nH_k=H_1\,H_2\,...H_n=1\times\left(1+\frac12\right)\times\,...\times\left(1+\frac12+\,...+\frac1n\right)\tag4$$
The numerators and denominators of the terms of this sequence appear as A097423 and A097424 in the OEIS. Obviously, the following function equations hold:
$$\frac{P_n}{P_{n-1}}=H_n,\quad\quad\frac{P_n}{P_{n-1}}-\frac{P_{n-1}}{P_{n-2}}=\frac1n\tag5$$
I'm looking for a continuous generalization $P_a$ of the discrete sequence $P_n$, which is real-analytic for all $a>0$ and satisfies the functional equations $(5)$. Could you suggest a way to construct such a function? Is there a series or integral representation for it? Can we generalize it to complex arguments? Update: It seems we can use the same trick that is used to define $\Gamma$-function using a limit involving factorials of integers:
$$P_a=\lim_{n\to\infty}\left[\left(H_n\right)^a\cdot\prod_{k=1}^n\frac{H_k}{H_{a+k}}\right]=\frac1{H_{a+1}}\cdot\prod_{n=1}^\infty\frac{\left(H_{n+1}\right)^{a+1}}{\left(H_n\right)^a\,H_{a+n+1}}\tag6$$","['real-analysis', 'number-theory', 'oeis', 'harmonic-numbers', 'gamma-function']"
