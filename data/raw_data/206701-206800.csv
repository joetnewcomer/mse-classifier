question_id,title,body,tags
4127450,To calculate correleation between two large vectors [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I have some graph with $500$ k nodes. after applying different hierarchical clustering algorithms I want to calculate the cophenetic correlation coefficient.
However, since the pairwise distance vectors length is roughly $n^2$ , straight forward correlation calculation is not feasible. How can I split the calcualtion? Or is there any different approach in order to calculate the cophenetic correlation coefficient?","['graph-theory', 'statistics']"
4127552,Holomorphic function on a connected compact Riemann surface is constant,"I was trying to solve the following exercise. I wanted to check if my solution was correct/rigorous enough, and ask a question at the end. (The general direction is given in here: holomorphic map between compact Riemann surfaces , and I seem to have expanded out the steps in a detailed way) Let $h\colon X \rightarrow Y$ be a morphism of Riemann surfaces. Assume that $X$ is connected and $h$ is not constant. Show that the image of $h$ is open in $Y .$ Deduce that $h$ is surjective if we moreover assume that $X$ is non-empty and compact, and $Y$ is connected. This implies that a morphism from a connected compact Riemann surface to a connected non-compact Riemann surface is always constant. In particular, every holomorphic function on a connected compact Riemann surface is constant. Open mapping theorem: If $U$ is a connected open subset of $\mathbb{C}$ , then the image of every non-constant holomorphic function $f: U \rightarrow \mathbb{C}$ is open. Proof: Let $h\colon X \rightarrow Y$ be such a morphism. Let $O \subset X$ be an open subset of $X$ , and we will show $h(O)$ is open. For any $x \in O$ , let $(U,\phi)$ be a chart of $O$ containing $x$ , and $(V,\psi)$ a chart of $Y$ containing $h(x)$ . Then consider the holomorphic map $\psi \circ h \circ \phi^{-1}$ defined on the open set $\phi(U \cap h^{-1}(V))\ni\phi(x)$ . Draw an open neighbourhood around $\phi(x)$ , and apply $\psi \circ h \circ \phi^{-1}$ to it. The result is an open in $\mathbb{C}$ around $\psi \circ h(x)$ , using the open mapping theorem. Composing from the left with $\psi^{-1}$ , we obtain an open neighbourhood around $h(x)$ . Since this holds for any point $x \in O$ , $h(O)$ is open in $Y$ . Now assume that $X$ is connected, non-empty, compact, and $Y$ connected. Let the notation be as above. Then $h(X)$ is compact, non-empty, and connected. As $h$ is an open map, $h(X)$ is open in $Y$ . As $h(X)$ is compact, it is closed in Hausdorff space $Y$ . As $Y$ is connected, we conclude $h(X) = Y$ . Now, if $Y$ is non-compact, a continuous map cannot map a compact space to a non-compact space, so $h$ must be a constant (otherwise we proved it is surjective). Is my solution correct? Also, I do not understand why this implies that every holomorphic function on a connected compact Riemann surface is constant.","['manifolds', 'complex-manifolds', 'solution-verification', 'differential-geometry']"
4127570,Invariant $\sigma$-algebras and Skew-Products,"$\newcommand{\mc}{\mathcal}$ $\newcommand{\Z}{\mathbb Z}$ Let $(X, \mc X, \mu)$ be a probability space and $G$ be a countable group.
Let $T:G\times X\to X$ be a measure preserving action of $G$ on $X$ .
Let $\nu$ be a probability measure on $G$ such that the support of $\nu$ contains a generating set of $G$ .
Equip $G^\Z$ with the probability measure $\nu^\Z$ and let $\sigma:G^\Z\to G^\Z$ be the shift map.
We will write an element of $G^\Z$ as $g = (g_n)_{n\in \Z}$ . We define a map $\Phi:X\times G^\Z\to X\times G^\Z$ as $$
\Phi(x, g) = (T^{g_0}x, \sigma(g))
$$ By Fubini's theorem it follows that $\Phi$ preserves the measure $\mu\times \nu^{\Z}$ . Let $\mc I$ be the $\sigma$ -algebra on $X$ consisting of all the $G$ -invariant subsets of $X$ . Question. Can we describe the $\sigma$ -algebra of $\Phi$ -invariant subsets of $X\times G^{\mathbb Z}$ in terms of $\mc I$ . It is clear that for any $A\in \mc I$ we have $A\times G^\Z$ is $\Phi$ -invariant.
Perhaps these are all the $\Phi$ -invariant subsets.
The question is important since in order to get interesting information by applying ergodic theorems to the map $\Phi$ it would be useful to know the $\Phi$ -invariant $\sigma$ -algebra.","['measure-theory', 'ergodic-theory']"
4127588,Escaping infinitely many pursuers,"The fugitive is at the origin. They move at a speed of 1. There's a guard at every integer coordinate except the origin. A guard's speed is 1/100. The fugitive and the guards move simultaneously and continuously. At any moment, the guards only move towards the current position of the fugitive , i.e. a guard's trajectory is a pursuit curve . If they're within 1/100 distance from a guard, the fugitive is caught. The game is played on $\mathbb{R}^2$ . Can the fugitive avoid capture forever? What I know: The distance between two guards is always non-increasing, but the farther away from the fugitive, the slower that distance decreases. If the fugitive runs along a straight line, they will always be caught by some far away guard. For example, if the fugitive starts at $(0.5, 0)$ and runs due north, they will be caught by a guard at about $(0, \frac{50^{100}}{4})$ . Consult radiodrome for calculation. If there're just 2 guards at distance 1 from each other, then the fugitive can always find a path to safely pass between them. This is true regardless of the pair's distance and relative positions to the fugitive. The fugitive can escape if they're just ""enclosed"" by guards who're at distance 1 from each other: The shape of the fence doesn't have to be rectangular. Circles or other shapes don't prevent escape either, regardless of the size. 3 and 4 are nontrivial, but can be proved by geometry argument alone without calculus. To avoid unnecessarily clustering the question, further details are given as an answer below for those who're interested, hopefully instrumental in solving the original problem.","['optimization', 'calculus', 'geometry', 'dynamical-systems']"
4127624,Proving constructed homeomorphism map is continuous,"I was constructing a homeomorphism from $S^2 / \langle x \sim -x \rangle$ to $\mathbb{R}P^2$ , the real projective plane, defined to be the space of all lines through the origin in $\mathbb{R}^3$ .A basis for $\mathbb{R}P^2$ is given by the collection of subsets of lines specified by open double cones with the cone point at the origin . The homeomorphism I came up with is $f:S^2 / \langle x \sim -x \rangle \rightarrow \mathbb{R}P^2,$ given by $f(\{x,-x\})=tx$ .Where $t$ is a parameter. I was having some difficulty showing that this map is continuous and came across the following theorem: Let $p:X \rightarrow Y$ be a quotient map. Let $Z$ be a space and let $g:X \rightarrow Z$ be a map that is constant on each set $p^{-1}(\{y\})$ , for $y \in Y$ . Then $g$ induces a map $f:Y \rightarrow Z$ such that $f \circ p=g$ . The induced map $f$ is continuous if and only if $g$ is continuous; $f$ is a quotient map if and only if $g$ is a quotient map. Can I use this theorem to show the function $f$ I have constructed is continuous? For this I will denote $p:S^2 \rightarrow S^2/ \langle x \sim -x \rangle$ to be the quotient map, sending points $x,-x$ on the sphere to the equivalence class $\{x,-x\}$ . So then in terms of the theorem I can take $p=p,X=S^2, Y=S^2/ \langle x \sim -x \rangle,Z=\mathbb{R}P^2,f=f,g=g$ and $g:S^2 \rightarrow \mathbb{R}P^2$ given by $g(x)=tx$ for all points in the sphere. Then $g$ is constant on $p^{-1}(\{\{x,-x\}\})$ , since $g(x)=tx,g(-x)=tx$ . Can I just say $g$ is continuous since each of the components of $tx$ is a continuous polynomial, or is that not allowed since $\mathbb{R}P^2$ cannot be embedded in $\mathbb{R}^3$ ? Now I am unsure whether this makes any progress, because I still have to show $g$ is continuous, which seems nonobvious. Any help?",['general-topology']
4127695,Evaluate $\sum_{r=0}^n 2^{n-r} \binom{n+r}{r}$,"Evaluate: $$\sum_{r=0}^n 2^{n-r} \binom{n+r}{r}$$ This looks like an unusual hockey stick sum. Here are my attempts: Method 1: The sum is equivalent to $$S=\sum_{r=0}^n 2^{n-r} \binom{n+r}{n}=\sum_{r=0}^n 2^{r} \binom{2n-r}{n-r}$$ and I could evaluate neither of these. Method 2: $$S=\text{coefficient of $x^n$ in }:$$ $$2^n(1+x)^n\Bigg( 1+\frac{1+x}{2}+\left(\frac{1+x}{2}\right)^2+\cdots+\left(\frac{1+x}{2}\right)^n \Bigg)$$ $$=(1+x)^n\left(\frac{(1+x)^{n+1}-2^{n+1}}{(x-1)}\right)$$ It looks like a heavy task to collect all the $x^n$ coefficients from this expression. Im out of ideas. Any hint is appreciated. From Putnam 2020, Q A2","['contest-math', 'binomial-coefficients', 'sequences-and-series']"
4127713,"Is there a compact set with positive measure on $[0,1]\setminus \Bbb Q$ [duplicate]","This question already has an answer here : Is there a compact subset of the irrationals with positive Lebesgue measure? (1 answer) Closed 3 years ago . I'm wondering if there exists a Lebesgue compact set (with respect to the usual topology on $[0,1]$ ) in $[0,1]\setminus \mathbb{Q}$ whose Lebesgue measure is positive. In fact we've just seen the Egoroff theorem in class, and I thought of the functions $$
f_n(x)= \left\{
    \begin{array}{ll}
        \frac{1}{n} & \mbox{if } x\in[0,1]\setminus \mathbb Q\\
        1 & \mbox{otherwise.}
    \end{array} \right.
$$ Obviously $f_n\to f\; \mu$ -a.e., but since $\mathbb Q$ is dense, I'm wondering how we can find a compact set $F\subset [0,1]$ for a given $\delta>0$ such that $\mu([0,1]\setminus F)<\delta$ and $\sup_{x\in F} |f_n(x)-f(x)|\to 0 $ as $n\to 0$ . Could you please explain why Egoroff holds in this case?","['general-topology', 'lebesgue-measure', 'measure-theory']"
4127720,"If $\{a,b,c\}\subset\mathbb C$ such that $a^2+b^2+c^2=ab +bc +ca$ prove that they lie on the vertices of an equilateral triangle in the complex plane","Exercise 1.11 (from Friendly Approach to Complex Analysis). If $a$ , $b$ , $c$ are real numbers such that $a^2+b^2+c^2=ab+bc+ca$ , then they must be equal. Indeed, doubling both sides and rearranging gives $(a-b)^2+(b-c)^2+(c-a)^2=0$ , and since each summand is nonnegative, it must be that case that each is $0$ . On the other hand, now show that if $a$ , $b$ , $c$ are complex numbers such that $a^2+b^2+c^2=ab+bc+ca$ , then they must lie on the vertices of an equilateral triangle in the complex plane. Explain the real case result in the light of this fact. Hint: Calculate $\big((b-a)\omega+(b-c)\big)\big((b-a)\omega^2+(b-c)\big)$ , where $\omega$ is a nonreal cube root of unity. It is a solved exercise but I don't understand the solution (or the hint). More than that I don't get why the author shared this exercise. I understand the cube roots of unity are $\{ (1,0), (-\frac{1}{2}, \frac{\sqrt{3}}{2}), (-\frac{1}{2}, -\frac{\sqrt{3}}{2}) \}$ So I have $a := (1,0)$ and $b := (-\frac{1}{2}, \frac{\sqrt{3}}{2}) $ and solved for $c$ , and got two values. One of them was the last cube root of unity. However I have observed that the points (solutions for $c$ considered one at a time) lie on the vertices of an equilateral triangle. Isn't this enough? What is the thought process behind the hint?",['complex-analysis']
4127725,Reference for analytification of schemes/varieties,"It seems that algebraic geometers form some of their intuition by thinking about the analytification of a scheme. E.g. Alex Youcis mentions that this is often the ""correct"" topology to think about or for elliptic curves it seems indispensable to switch between the algebraic scheme and the corresponding analytified Riemann surface. Yet, many of the introductory books like Hartshorne, Liu, Görtz do not discuss this topic (and Vakil only in very few starred exercises). Hence my request: What's a good reference to start learning about analytifications of schemes/varieties ?","['algebraic-geometry', 'reference-request']"
4127736,Factoring a polynomial modulo prime,"How would I go about factoring a polynomial $x^{5}-4$ over a finite field $\mathbb{F}_{29}=\mathbb{Z}/29\mathbb{Z}$ ? I know that $29$ is prime, so that will be relevant at the very least. Moreover, if we solve the equation $x^{5}\equiv 4 \mod 29$ , we would get the solution $x=6$ unique up to modulo $29$ . Is there a way to factor this over $\mathbb{Z}/29\mathbb{Z}$ by using the solution obtained from the equation?","['number-theory', 'abstract-algebra', 'discrete-mathematics']"
4127753,"Connected components of $\mathbb{R}^2 \setminus \gamma$, where $\gamma \subset \mathbb{R}^2$ is a closed path","Let $\gamma$ be a closed path in $\mathbb{R}^2$ ( $\gamma : [0,1] \to \mathbb{R}^2$ is continuous and satisfys $\gamma(0)=\gamma(1)$ ). Are the following statements true? $\gamma$ divides the plane into (at most countably infinite, since every component would contain a rational point) connected components $Q_1, Q_2, Q_3,...$ : $$\mathbb{R}^2 \setminus \gamma = \bigcup_{i=1}^{\infty} Q_i$$ There is exactly one unbounded component (which we call) $Q_1$ . $Q_i$ is bounded for every $i\geq 2$ . The boundary of the union of all bounded components is equal to $\gamma$ : $$\partial \bigcup_{i=2}^{\infty} Q_i = \gamma$$ If 3 doesn't hold, do we at least know that the boundary is a subset of $\gamma$ ? Essentially I am asking if a generalization of the Jordan curve theorem for not necessarily simply connected paths is true.","['plane-curves', 'curves', 'general-topology', 'connectedness']"
4127755,Linear regression with two possible slopes,"Let's say, I have a dataset with $X$ and $Y$ values. $X$ represents the monthly average temperature and $Y$ represents the money spent on utilities. My underlying hypothesis is that the heating energy (and utility bill) will be proportional to the average monthly temperature, but depending upon whether the house has gas or electric heating, the slope, $ ^\circ C$ , will be different. How can I use linear regression to extract out these two slopes? If I just do a simple linear regression with $X$ and $Y$ , I will only get a single slope that will represent the average $^\circ C$ between gas and electric heating. If I do a scatter plot, it's quite easy to see distinct linear relations (as shown in figure below), but I am lost in terms of how to extract the two slopes.","['regression', 'statistics', 'linear-regression']"
4127766,Getting a negative variance for the sum of dice rolling,"I'm trying to find what I did wrong. If $X$ signifies the sum of what you get from rolling a regular die (1-6), 100 times and $X_i$ for a single roll. Then: $$E\left[X\right]=\sum_{i=1}^{100}\frac{7}{2}=100\frac{7}{2}=350$$ and: $$E\left[X^{2}\right]=E\left[\sum_{i=1}^{100}X_{i}^{2}\right]=\sum_{i=1}^{100}E\left[X_{i}^{2}\right]=100\cdot\frac{91}{6}=\frac{4550}{3}$$ Then the variance is negative: $$Var\left(X\right)=E\left[X^{2}\right]-E\left[X\right]^{2}=\frac{-362950}{3}$$ In this way, however, I recieve a positive number: $$100Var\left(X_{i}\right)=100\left(E\left[X_{i}^{2}\right]-E\left[X_{i}\right]^{2}\right)=100\left(\frac{91}{6}-\left(\frac{7}{2}\right)^{2}\right)$$ I suppose the latter is correct, but why is the first way false?","['dice', 'variance', 'probability']"
4127790,Normal bundles of $S^1$ in a Klein bottle,"Consider the Klein bottle $K$ obtained from a square by gluing the corresponding edges in the blow figure. Then we get two obvious embedding of $S^1$ to Klein bottle $i_a: S^1\to K$ and $i_b:S^1\to K$ , that is, embedded into the circle $a$ and the circle $b$ respectively. I want to identify the normal bundles with respect to those two embedding. My guess: the first normal bundle is trivial bundle over $S^1$ and the second one is the unbounded Möbius band on $S^1$ . But I have trouble in showing this explicitly. My attempt starts with writing a smooth atlas of the Klein bottle and I hope this can help me do calculation. However, by definition, the normal bundle $N_{K/S^1}$ is the quotient bundle $((i_a)^*TK)/TS^1$ , that is, $$0\to TS^1 \to ((i_a)^*TK)/TS^1 \to N_{K/S^1} \to 0$$ However, I don’t know how to write the first map in local chart so that I can calculate the bundle explicitly. Any reference, hints, and answers are welcome!","['geometric-topology', 'general-topology', 'differential-topology', 'differential-geometry']"
4127807,Can you prove Fatou's lemma for conditional expectations by that of the normal version?,"I'd like to discuss proofs of Fatou's lemma for conditional expectations . It can be proved by almost the same idea for normal version, i.e., by applying the monotone convergence theorem for conditional expectations for $\inf_{k \geq n} X_k$ . You can review its detail by the link above toward Wikipedia. Then, I wonder how we can prove Fatou's lemma for conditional expectations, not using the monotone convergence theorem for conditional expectations, but using Fatou's lemma of the normal version . Do you know this proof? Letting
\[
N = \left\{ E[\liminf_{n \to  \infty} X_n | \mathcal{G}] > \liminf_{n \to \infty} E[X_n | \mathcal{G}] \right\},
\]
I tried to prove $P(N) = 0$ by applying Fatou's lemma for $\{ E[X_n | \mathcal{G}] \}$ and $\{ X_n \}$ , but failed. It seemed that simple ideas didn't work well. I consulted my textbooks for probability theory and related fields and I found only the same proof above. Kindly please note that our definition of conditional expectations is a standard one characterized by integrals and measurableness . If we define conditional probabilities first and then introduce conditional expectations by integrals with them, Fatou's lemma for conditional expectations is proved by that of the normal version, obviously. I hope you will tell me a connection between the standard definition of conditional expectations and Fatou's lemma of the normal version.","['conditional-expectation', 'measure-theory', 'probability-theory']"
4127818,Getting different answers for a definite Integral using different approaches.,"I am trying to solve this definite integral problem. $$\int_0^\pi \frac{dx}{1+\cos^{2} x}$$ dividing numerator and denomenator by $\cos^{2} x$ , the integrand becomes, $$\int_0^\pi \frac{\sec^{2} x \ dx}{\sec^{2} x+1} = \int_0^\pi \frac{\sec^{2} x \ dx}{\tan^{2} x+2}$$ Now with a substitution like - $$u = \tan x$$ The definite integral reduces to, $$\int_0^0 \frac{du}{u^{2}+2} = 0 \ ?$$ But using the property of definite integral we know, $$\int_0^{2a} f(x) \ dx = \ \int_0^{a} (f(x) + f(2a-x))\ dx $$ Applying this property to our function, the integral becomes, $$2\int_0^{\pi/2} \frac{\sec^{2} x \ dx}{\tan^{2} x+2} \ dx = 2\int_0^{\infty} \frac{du}{u^{2}+2} = \frac{\pi}{\sqrt{2}} \ !!$$ Getting different answers in both cases. What am I doing wrong? Please advice. *I am new to MathJax. Any syntax error is regretted.","['algebra-precalculus', 'definite-integrals', 'substitution']"
4127830,How do I evaluate $\int \frac{x+1}{(x^2+1) \sqrt{x^2-6x+1}} dx$?,"I am trying to evaluate this indefinite integral: $$\int \frac{x+1}{(x^2+1) \sqrt{x^2-6x+1}} dx$$ What I tried Substitution $u = \arctan(x)$ . However, no luck after this Find substitutions to convert $x^2 - 6x + 1$ into $(a + bu)^2$ or $a - (b + cu)^2$ , however I could not find any Converted $x^2 - 6x + 1$ into $(x-3)^2 - 8$ and used the derivative of $\sec^{-1}{(x)}$ but not any luck after that as well. I suspect that it has a real solution, so the solution from wolfram alfa is not what I am looking for. Any help/solutions would be very much appreciated!","['integration', 'indefinite-integrals', 'calculus']"
4127847,Is Donald Cohn's second edition of Measure Theory good? [closed],"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 3 years ago . Improve this question I read (most of) Baby Rudin, and now i am interested in learning more stuff about real analysis, in particular measure theory and functional analysis. Is ""Measure Theory: Second Edition"" by Donald L. Cohn a good introduction book in these subjects? (good = comprehensive, has a lot of medium/hard practice problems and more importantly, counterexamples). If not, are there any companion books/notes i can use while reading it?","['measure-theory', 'functional-analysis', 'book-recommendation', 'real-analysis']"
4127856,"$X:= \sum_{j=1}^Z Z_j$, where $Z \sim$ Po$(\gamma)$ and $Z_j$'s are independent","Let $m\in \mathbb N$ and suppose that $Z_n, n\in \mathbb N$ , is a sequence of independent random vectors in $\mathbb R^m$ with common distribution $\mathbb P(Z_1 = e_i) = p_i, i\in \{ 1,...,m\}$ , where $e_i$ is the $i-$ th unit vector in $\mathbb R^m$ and $p_1+ \cdots+ p_m = 1$ . Let $Z \sim$ Po $(\gamma)$ , independent of $(Z_1, Z_2,...).$ Show that the components of the random vector $X := \sum_{j=1}^Z Z_j$ are independent and Poisson distributed with parameters $p_1\gamma, ..., p_m \gamma$ . This can be proved if we show that $$\mathbb P(X_1 = k_1, ... , X_n = k_n) = \prod_{j=1}^n \mathbb P(X_j = k_j) = \prod_{j=1}^n \text{Po}(k_j; p_i \gamma).$$ How to prove the above equation? Is there any other easy way to prove the statement? Can we argue that the components of $X$ are indepedent by that $Z_n, n\in \mathbb N$ , is a sequence of independent random vectors?","['poisson-distribution', 'probability-theory', 'probability']"
4127877,Series convergence by Gauss Test,"I want to try to prove that the $$\sum_{n=1}^\infty \frac{n!e^n}{n^{n+p}}$$ series convergent for $p>1.5$ with Gauss Test but failed? Gauss Test said if $\frac{a_n}{a_{n+1}}$ can be represnted as $\frac{a_n}{a_{n+1}}=\lambda+\frac{\mu}{n}+b_n$ where $\sum_{n=1}^\infty b_n$ absolutely convergent then $\lambda>1$ convergent $\lambda<1$ divergent $\lambda=1, \mu>1 $ convergent $\lambda=1, \mu\leq1 $ divergent My work : I found that $$\frac{a_n}{a_{n+1}}=\frac{1}{e}{(1+\frac{1}{n})}^{n+p}=\frac{1}{e}(1+1/n)^{n+p}=\frac{1}{e}(1+\frac{n+p}{n}+\frac{(n+p)(n+p-1)}{2}\frac{1}{n^2}+\dots)),$$ and then stopped and didnt see a continuation.","['calculus', 'real-analysis']"
4127922,An explicit representation of a free nilpotent group by unitriangular matrices,"P. Hall proved that every finitely generated torsion-free nilpotent group can be faithfully represented by upper unitriangular matrices over $\mathbb Z$ . The most famous example is the integral Heisenberg group, which is free nilpotent, of rank $2$ and class $2$ , and is isomorphic to $UT(3,\mathbb{Z})$ . I would like to know what is the easiest such representation for the free nilpotent group $F(3,2)$ , of rank $3$ and class $2$ . Its group presentation is $$F(3,2)=\langle x,y,z \,\|\, [x,[x,y]],[y,[x,y]],[z,[x,y]],[x,[y,z]],[y,[y,z]],[z,[y,z]],[x,[x,z]],[y,[x,z]],[z,[x,z]] \rangle.$$ An algorithm to compute this representation was implemented in GAP, based on the work of de Graaf and Nickel [ de Graaf, Willem A.; Nickel, Werner , Constructing faithful representations of finitely-generated torsion-free nilpotent groups , J. Symb. Comput. 33, No. 1, 31-41 (2002). ZBL1021.20006 .] Unfortunately I am not proficient with GAP to run it myself. In the above paper the authors state that the algorithm produces a representation for $F(3,2)$ in $UT(6,\mathbb{Z})$ . Is there a faithful representation of $F(3,2)$ , over integer matrices, of degree less than $6$ ?","['gap', 'group-theory', 'nilpotent-groups']"
4127992,Proof or disprove: There exists a real $n \times n$ matrix $A$ that satisfies the equation when $n$ is even. [closed],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Prove or disprove: There exists a real $n \times n$ matrix $A$ with $$
A^2+2\cdot A+5\cdot I_n = 0
$$ if and only if n is even. I could not find a counterexample for an odd $n$ . Therefore, I suspect that the statement is true, but I have not yet found a solution.","['matrices', 'matrix-equations', 'linear-algebra']"
4128002,The probability of recovering from a disease,"It is known that the probability of recovering from a disease is $0.23$ . In a community of 6 people with this disease, what is the probability that at least $3$ people will survive? Hello guys, today our teacher had asked this question and I found and answer. I used binomial distribution to solve this problem and my answer is $0.1391$ , in the system the answer $0,89$ . How can this would be possible? I am thinking that answer of teacher is wrong and mine is correct.","['statistics', 'word-problem', 'binomial-distribution', 'probability', 'rational-numbers']"
4128128,Is there an $n$ such as $\sum_{k=1}^n (-1)^k * k! \equiv 1\mod n$ other than the divisors of 246?,"$-1! \equiv 1\mod  1$ . $-1! + 2! \equiv 1\mod  2$ . $-1! + 2! - 3!\equiv -5 \equiv  1\mod 3$ . $-1! + 2! - 3! + 4! - 5! + 6! \equiv 619\equiv 1 \mod 6$ . Let $S(n) = \sum_{k=1}^n (-1)^k * k!.$ When $n = 1, 2, 3, 6, 41, 82, 123$ and $246$ , $S(n)\equiv 1\mod n$ . Is there an n such as $S(n) \equiv 1\mod n$ other than the divisors of 246?",['number-theory']
4128132,How can I prove these two questions without using the following theorem?,"Question 1: Let $X_1, X_2, \cdots$ be independent random variables such that $$P(X_n=-n^{\theta})=P(X_n=n^{\theta})=\frac{1}{2}.$$ If $\theta > -\frac{1}{2}$ prove that the Lyapunov condition works and the sequence satisfies the central limit theorem. Question 2: Let $X_1, X_2, \cdots$ be independent random variables such that $$P(X_n=-n^{\theta})=P(X_n=n^{\theta})=\frac{1}{6n^{2(\theta -1)}}\quad \text{and} \quad P(X_n=0)=1-\frac{1}{3n^{2(\theta -1)}}.$$ If $1< \theta < \frac{3}{2}$ prove that the Lindeberg condition works works and the sequence satisfies the central limit theorem. THEOREM: Let be $\lambda >0$ , then $$\frac{1}{n^{\lambda +1}}\displaystyle\sum_{k=1}^{n} k^{\lambda}\underset{n\to +\infty}{\longrightarrow} \frac{1}{\lambda+1},$$ in such a way that $\displaystyle\sum_{k=1}^{n} k^{\lambda}$ has the order $\mathcal{O}= n^{\lambda + 1}$ . Solution of the question 1: $EX_n=0\; \forall n\in \mathbb{N}$ , $Var(X_n)=EX_n^2=n^{2\theta}$ and $\displaystyle\sum_{k=1}^{n} Var X_k = \displaystyle\sum_{k=1}^{n}k^{2\theta}$ is (by the theorem above) $\mathcal{O}(n^{2\theta +1})$ . Also $S_n=\left(\sum_{k=1}^{n}Var(X_k)\right)^{\frac{1}{2}}$ is (using the theorem above) $\mathcal{O}=\left(n^{(2\theta+1)/2}\right)$ . By the Lyapunov condition there exists $\delta >0$ , such that \begin{align*}
\lim_{n\to +\infty} \frac{1}{s_n^{2+\delta}} \displaystyle\sum_{k=1}^{n} E|X_k|^{2+\delta} &=lim_{n\to +\infty} \frac{1}{2^{2+\delta}}\displaystyle\sum_{k=1}^{n} K^{(2+\delta)\theta}\\
	&=\lim_{n\to +\infty} \frac{\mathcal{O}\left(n^{(2+\delta)\theta+1}\right)}{\mathcal{O}\left(n^{(2+\delta)(2\theta +1)/2}\right)}\\
	&=\lim_{n\to +\infty} \frac{\mathcal{O}(n)}{\mathcal{O}(n^{(2+\delta)/2})}\\
	&=0\quad \text{for}\; \delta=2
\end{align*} Thus, the Lyapunov condition is satisfied $\forall \alpha \in \mathbb{R}$ and $\delta =2$ . Therefore, $$\frac{\displaystyle\sum_{k=1}^{n} X_k - E\sum_{k=1}^{n} X_k}{\sqrt{\displaystyle\sum_{k=1}^{n}Var(X_k)}}\overset{D}{\longrightarrow} \mathcal{N}(0,1).$$ The convergence above means that converge in distribution to standard normal distribution $\mathcal{N}(0,1)$ . REMARK: Notice that the question 1 is already answered, however I'm strying to prove again without use the theorem above. Can you help me with this?","['central-limit-theorem', 'weak-convergence', 'probability-distributions', 'probability-theory', 'probability']"
4128159,Unusual proof for the spherical cosine rule,"We have $0\lt a\leq b\leq c\lt \frac{\pi}{2}$ , and $A$ =( $0$ , $0$ , $1$ ), $B$ =( $\sin c$ , $0$ , $\cos c$ ) on the unit sphere. Also $$C_\phi=(\sin b\cos \phi, \sin b\sin \phi,\cos b)$$ is given such that $\lvert AC_\phi\rvert = b$ for all $\phi$ Firstly I need to show $$\exists\, \phi\; with\; \lvert BC_\phi\rvert=a \iff a+b\geq c.$$ Then I must deduce the spherical cosine rule from this for a spherical triangle with sides $a,b,c$ and opposite angles $\alpha,\beta,\gamma$ : $$\cos a =\cos b\cos c +\sin b\sin c\cos \alpha.$$ $\space$ For the first part I have gotten as far as showing that $\lvert BC_\phi \rvert=a $ $$\iff \exists\phi \:with\;\cos \phi = \frac{2-2\cos b\cos c - a^2}{2\sin b\sin c}$$ $$\iff\cos (c+b)\leq1- \frac{a^2}{2}\leq\cos (c-b)\,,$$ But I am unsure where to go from here. I'm thinking that $1- \frac{a^2}{2} \leq \cos a$ may be useful since $\cos a \leq \cos(c-b)$ gives the result, but I cannot see how to show this second inequality. Any guidance would be great. Thank you!","['spherical-trigonometry', 'trigonometry', 'geometry', 'spherical-geometry']"
4128203,if $AB+BC+AC\le 2+\sqrt{3}$ find the maxmum of the value $P=AB\cdot BC\cdot AC$,"For $\Delta ABC$ if the circumradius $R=1$ ,and such $$AB+BC+AC\le 2+\sqrt{3}$$ find the maxmum of the value $$P=AB\cdot BC\cdot AC$$ if let $a=BC,b=AC,c=AB$ ,then we have $$a+b+c\le 2+\sqrt{3}$$ and if use sine theorem we have $$a=2R\sin{A}=2\sin{A},b=2\sin{B},c=2\sin{C}$$ so $$\sin{A}+\sin{B}+\sin{C}\le\dfrac{2+\sqrt{3}}{2}$$ so we want to find the maximum of the value $$P=AB\cdot BC\cdot AC=abc=8\sin{A}\sin{B}\sin{C}$$ if we use AM-GM $$\sin{A}\sin{B}\sin{C}\le\left(\dfrac{\sin{A}+\sin{B}+\sin{C}}{3}\right)^3\le\left(\dfrac{2+\sqrt{3}}{2}\right)^3$$ the $=$ iff $A=B=C$ but this is clear wrong.so How to solve this problem? Thanks","['trigonometry', 'geometry']"
4128223,Solve the following via generating functions,"Question: Solve the following using generation functions: How many non-negative solutions over $\mathbb{Z}$ there are for the following equation: $$3x_1+2x_2+3x_3+2x_4+3x_5+2x_6+3x_7=20$$ when at least one of these variables is odd, and $x_1,...,x_7\geq0$ ? The previous sub-question gave us the number of non-negative solutions over $\mathbb{Z}$ , when there isn't a restriction of the variables, and I got 1203 solutions. My attempt: $Solution$ .  We shall apply the complement method, using the previous sub-question, and subtract the number of solutions in which all the variables are even. Therefore, we suppose that: $x_1,...,x_7\in\{0,2,4,6,...\}$ , so we get the next generation function: $$f(x)=(x^0+x^6+x^{12}+x^{18}+...)^4(x^0+x^4+x^8+x^{12})^3=D(4,k)x^{6k}\cdot D(3,i)x^{4i}$$ Now, we consider $6k+4i=20$ , for the coefficient of $x^{20}$ , and get the next table for the compatible $k,i$ to satisfy the equation: $$\begin{array}{|c|c|c|c|}
\hline
k& i   \\ \hline
 0& 5 \\ \hline
 2&  2 \\ 
  \hline
\end{array}$$ So in total: $$D(4,0)x^0\cdot D(3,5)x^{20}+D(4,2)x^{12}\cdot D(3,2)x^8=[\binom{4}{4}\binom{7}{5}+\binom{5}{2}\binom{4}{2}]x^{20}=81x^{20}$$ Thus, according to the complement method, we get our final result: $$1203x^{20}-81x^{20}=1122x^{20}$$ Therefore, we have $1122$ non-negative solutions over $\mathbb{Z}$ . I have a feeling that this is not true, and I need to apply the inclusion-exclusion method instead. Therefore, I will be glad to see what you think. Thanks!","['solution-verification', 'combinatorics', 'discrete-mathematics', 'generating-functions']"
4128274,Finding maximal length of a log (calculus),"Let the width of a river be $a$ and the width of a canal be $b$ . Canal is perpendicular to the river. What is the maximum length of a log that can be send from river to canal? The result given in a book is $(a^{2/3} + b^{2/3})^{3/2}$ . I have found this exercise in the book of exercises by Boris Demidovič. It is known in eastern Europe to be the one of the best collections of problems. edit: changed word to perpendicular, thanks Henry Lee.","['optimization', 'calculus', 'maxima-minima', 'derivatives']"
4128351,"Why is the ring homomorphism $\Gamma: D^{o}\rightarrow \text{End}_{M_n(D)}(D^n)$, where $D$ is a division ring, a bijection?","It is said in this answer that for any division ring $D$ , the following ring homomorphism is a bijection: $\Gamma: D^{o}\rightarrow \text{End}_{M_n(D)}(D^n)=\{M_n(D)\text{-module endomorphisms of }D^n\}\\d\mapsto \theta_d\quad \text{s.t.}\quad \theta_d(x_1,\ldots,x_n)=(x_1d,\ldots,x_nd)$ I can see why it is an injective homomorphism (if $d\neq d’$ , $(x_1 d,\ldots,x_n d) \neq (x_1 d’,\ldots,x_n d’)$ ) but I’m not sure about how to prove it is surjective too. How can I write every element of $\text{End}_{M_n(D)}(D^n)$ in that form? Oh, I also wanted to know what does the notation $D^o$ exactly mean here.","['matrices', 'ring-theory', 'abstract-algebra', 'modules']"
4128409,How do I find Maclaurin-like series for parametrically defined curves?,"Suppose I have a parametrically defined curve: $$x=x(t),\quad y=y(t).$$ For some parametrically defined curves, such as $x=t^2,y=\sin(t^2)$ (a very basic example, I know) we can eliminate $t$ and write the equation of the curve in terms of $x$ and $y$ only. However, for many other parametrically defined curves, we cannot eliminate $t$ . I have been wondering if there's a way we could write the equation of the curve as an infinite Maclaurin-like series instead, ie as $$y=\sum_{n=0}^{\infty}a_n x^n$$ where $a_n$ is the coefficient of $x^n$ . Do you know of any way we could do this? I know you would like me to show any work I have done myself but I simply have no idea where to start. Thank you for your time and help.","['calculus', 'functions', 'parametric', 'taylor-expansion', 'power-series']"
4128454,Show that $(x+1)^p \equiv x^p +1 \pmod{p^2}$ given conditions on $x$ and $p$.,"The problem is as follows. Let $p$ be a prime of the form $p = 3k + 1$ for some $k \in \mathbb{Z}$ . Let $x$ be an integer such that $p \nmid x$ and $[x]_p$ has multiplicative order 3 in the ring $(\mathbb{Z}/p\mathbb{Z})^{\times}$ . Show that $$
(x+1)^p \equiv x^p+1 \pmod{p^2}
$$ My attempt: Rewrite $(x+1)^p$ in its binomial expansion. We get $(x+1)^p = x^p+ {p\choose 1}x^{p-1} + {p\choose 2}x^{p-2} + \dots + {p\choose p-1}x + 1$ . Now it is sufficient to prove that ${p\choose 1}x^{p-1} + {p\choose 2}x^{p-2} + \dots + {p\choose p-1}x \equiv 0 \pmod {p^2}$ . However I do not know how to prove this last equivalence. Any hints on how to procede would be greatly appreciated!
My knowledge consists of basic number theory and $p$ -adic numbers and related theorems.","['number-theory', 'p-adic-number-theory']"
4128455,Is every subalgebra of a group algebra isomorphic to the group algebra of some subgroup?,"Consider a discrete group $G$ (not necessarily amenable), and let $\mathbb{C} G$ be its group algebra (with the usual $\star$ -algebra structure). Is every $\star$ -subalgebra of $\mathbb{C} G$ isomorphic (as $\star$ -algebras) to $\mathbb{C}H$ for some subgroup $H$ of $G$ ? This happens to be the case for all examples I considered (some simple cases of subalgebras where $G$ is a free group), but I can't find a proof in general. In case the above is true, what can one say about ideals? It appears somewhat intuitive that an ideal cannot just be the group algebra of some subgroup (but my intuition is by no means well formed here). This is the principal reason I believe for now that the initial statement might actually be untrue. My main motivation here is to (eventually) study group $C^\star$ algebras in this light, if possible... I also noted that perhaps the field being $\mathbb{C}$ is of crucial importance here: a couple of related questions on Math Stack Exchange and Math Overflow seem to imply that the characteristic of the field is a deciding factor.","['operator-algebras', 'analysis', 'ring-theory', 'abstract-algebra', 'group-theory']"
4128468,When does $A\times B$ measurable imply both $A$ and $B$ measurable? Is Fubini's applicable?,"When $A\subset\mathbb R^n$ and $B\subset\mathbb R^m$ are Lebesgue measurable, then so is $A\times B\subset \mathbb R^{n+m}$ and $\mu(A\times B)=\mu(A)\cdot\mu(B)$ . I'm being loose with the notation here assuming that we can understand that each $\mu$ is Lebesgue measure on the appropriate Euclidean space in each instance and ignoring any technical issues with specifying $\mathbb R^{n+m}$ vs $\mathbb R^{n}\times\mathbb R^{m}$ . I'm using the definition of Lebesgue outer measure: $$\mu^*(E)=\inf\left\{\sum v(I_k)\mid E\subset \bigcup I_k, \text{ with closed boxes } I_k \right\}$$ and $\mu(E)=\mu^*(E)$ exists when for any $\epsilon>0$ there is an open set $G\supset E$ such that $\mu^*(G\setminus E)<\epsilon$ . I'd like to avoid the Carathéodory's criterion It is also true that nonmeasurable $A$ and measure zero $B$ gives $A\times B$ measurable with measure zero. Thus $A\times B$ measurable doesn't imply that $A$ and $B$ are both measurable. (Always meaning Lebesgue measurable etc.) So I am wondering under what additional conditions, if any, do we have $A\times B$ measurable implying that $A$ and $B$ are both measurable? Is $\mu(A\times B)>0$ sufficient? Will Fubini's theorem will give us something here? Certainly $\mu(A\times B)=\mu^*(A\times B)=\mu^*(A)\cdot \mu^*(B)$ . We also have that $\mathbf 1_{A\times B}$ the characteristic function on a measurable set and is thus measurable, and in fact $\mathbf 1_{A\times B}(x,y)=\mathbf 1_{A}(x)\cdot\mathbf 1_{B}(y)$ . Thus we get $$\int_{\mathbb R^{n+m}}\mathbf 1_A(x)\mathbf 1_B(y)=\int_{\mathbb R^{n+m}}\mathbf 1_{A\times B}(x,y)=\mu(A\times B)>0$$ But I don't quite see how I can say anything about $A$ and $B$ or $\mathbf 1_A$ and $\mathbf 1_B$ individually. If I try to use Fubini's to iterate the integral, I end up with $\mu(A)\mu(B)$ . Thus if Fubini's is true then it makes mean think that $A$ and $B$ have to both be measurable when $\mu(A\times B)>0$ . I don't see how Fubini's can be applied to $\mathbf 1_{A\times B}$ if we don't have specific knowledge about the measurability of $A$ and $B$ . Can I just say that $$0<\mu(A\times B)=\int_{\mathbb R^{n}}\mathbf 1_A(x) \cdot \int_{\mathbb R^{m}}\mathbf 1_B(y)$$ and then I get to conclude that the right side must be the product of two positive numbers and hence $A$ and $B$ must both be measurable? That just feels a bit uncomfortable... Now I'm not even sure if Fubini's is even relavant here. When one set is nonmeasurable: If $A\subset\mathbb R^n$ is nonmeasurable and $B\subset\mathbb R^m$ is measure zero, then I can almost work it out with Fubini's but not quite. I do believe we trivially get that $\mu(A\times B)=0$ though without much work. $$\begin{aligned}
\int_{y\in\mathbb R^m}\mathbf 1_{A\times B}(x,y)&=
\begin{cases}
\mu(B) &\text{ if } x\in A\\
0 &\text{ if } x\not\in A\\
\end{cases}\\
&=0\cdot 1_{A}(x)=0\end{aligned}$$ Thus giving $\int_{\mathbb R^{n+m}}\mathbf 1_{A\times B} =\int_{\mathbb R^{n}}\int_{\mathbb R^{m}} \mathbf 1_{A\times B}=\int_{\mathbb R^{n}}0=0$ which is what I would hope for. If we iterate the integral in the other order, then I run into issues though since $$
\int_{x\in\mathbb R^n}\mathbf 1_{A\times B}(x,y) = \mathbf 1_{B}(y) \cdot \int_{x\in\mathbb R^n}\mathbf 1_{A}(x)$$ But $\mu(A)$ is undefined! For the purpose of this problem though, I can define $\int_{x\in\mathbb R^n}\mathbf 1_{A}(x)$ to be whatever I want though giving zero for the final result, but that kinda bothers me. I think maybe Fubini's theorem doesn't apply here since it starts off with the product measure? I am sure there is probably some technical matter I am overlooking or making some mistake that is easy to fix.","['measure-theory', 'lebesgue-measure', 'fubini-tonelli-theorems']"
4128520,"Integrating $\int \sqrt{2me-mkr^2-\frac{1}{2}m br^4 - \frac{a^2}{r^2}} \,dr$","I was trying to find Hamiltons principle function, $S$ ,  for the Hamiltonian: $$ H = \frac{1}{2} m \left( P_{r}^2 + \frac{P_{\theta}^2}{r^2} \right) + \frac{1}{2}kr^2 + \frac{1}{4} b r^4$$ After considering the form $S = f(r, \theta) - Et = R(r) + \Theta(\theta) - Et$ and identifying the canonical momenta with the partial derivatives of $S$ I got to: $$ \left(\frac{dR}{dr} \right)^2 r^2 + mkr^4 + \frac{1}{2}mbr^6 - 2mEr^2 = -\left(\frac{d \Theta}{d \theta} \right)^2 $$ Each side must be a constant, $-a^2$ , and so: $$ \frac{dR}{dr} =  \sqrt{2mE-mkr^2-\frac{1}{2}m br^4 - \frac{a^2}{r^2}} $$ which leads to: $$ R(r)=  \int \sqrt{2mE-mkr^2-\frac{1}{2}m br^4 - \frac{a^2}{r^2}} \,dr$$ I've tried to find a substitution of variables to make it simpler but to no luck. How can I solve this?","['integration', 'ordinary-differential-equations', 'hamilton-equations', 'substitution', 'derivatives']"
4128525,For finite $A$: $f$ injective implies $f$ surjective,"I am trying to prove: If $A$ is a finite set, then any injective map $f : A \to A$ is also surjective. Here is my attempt. If $A = \emptyset$ , then the empty function $f: A \to A$ is vacuously bijective, so suppose $A \neq \emptyset$ . Let $f: A \to A$ be an injection. As $A$ is finite, there are exactly $|A|^{|A|}$ functions $A \to A$ , so there exists $m > 1$ such that $f^m = f$ . Fix $a \in A$ , so $f^m (a) = f(a)$ . By left cancellation, we have $f^{m-1} (a) = a$ . That is, $f\left(f^{m-2} (a)\right) = a$ ; by the definition of composition, $f^{m-2} (a) \in A$ (if $m = 2$ , then we define $f^0$ to be the identity function) so $f$ is surjective, as desired. How does this look? Do I need to separate the $m=2$ case, or does the way I've handled it work?","['functions', 'solution-verification']"
4128528,Octahedron to tetrahedron ratio in generalized polyominoes in the tetrahedral-octahedral honeycomb,"Drake Thomas and I have proposed a sequence A343909 to the On-Line Encyclopedia of Integer Sequences (OEIS), which counts ""generalized polyforms"": generalizations of free polyominoes (Tetris pieces), but with cells in the tetrahedral-octahedral honeycomb . That is, take a subset of tetrahedral or octahedral cells in the honeycomb such that each cell is connected to every other cell by a chain of face-to-face connections. Consider two subsets to be the same if there is a rigid transformation that takes one to the other. The ( $0$ -indexed) sequence begins: 1, 2, 1, 4, 9, 44, 195, 1186, 7385, 49444, 337504, ... Which is to say that there is 1 polyform with 0 cells (the empty polyform), 2 polyforms with 1 cell (the tetrahedron and the octahedron), 1 polyform with 2 cells (the tetrahedron attached to the octahedron by a face), 4 polyforms with 3 cells, and 9 with 4 cells, as shown below: Tetrahedra/octahedra breakdown It's hard to compute large values of this sequence, but here is the breakdown of the number of octahedra and tetrahedra in $8$ - and $9$ -cell polyforms.: $n = 8 \\ A343909(8) = 7385$ 1 octahedron, 7 tetrahedra: $1$ 2 octahedra,  6 tetrahedra: $285$ 3 octahedra,  5 tetrahedra: $3223$ 4 octahedra,  4 tetrahedra: $3440$ 5 octahedra,  3 tetrahedra: $432$ 6 octahedra,  2 tetrahedra: $4$ $n = 9 \\ A343909(9) = 49444$ 1 octahedron, 8 tetrahedra: $1$ 2 octahedra,  7 tetrahedra: $356$ 3 octahedra,  6 tetrahedra: $10853$ 4 octahedra,  5 tetrahedra: $27632$ 5 octahedra,  4 tetrahedra: $10141$ 6 octahedra,  3 tetrahedra: $459$ 7 octahedra,  2 tetrahedra: $2$ Questions In these (and smaller) cases, the greatest number of polyforms occurs when the number of octahedra is $\lfloor (n-1)/2 \rfloor$ . Based on the fact that the honeycomb is composed of alternating regular octahedra and tetrahedra in a ratio of 1:2, I would have expected the mode to be closer to one-third. In the limit, is the mode asymptotic to $n/2$ , $n/3$ , or something else? For a fixed number of cells, does the number of polyforms with $m$ octahedra have a known distribution in $m$ ? What is the minimum number of octahedra than an $n$ -cell polyform can have? The maximum number?","['polyhedra', 'tessellations', 'oeis', 'combinatorics', 'polyomino']"
4128547,Weak convergence in $l^2$ spaces,"We say that $x_n$ converges weakly to $x$ in normed space $X$ when for any linear and continuous functional $f$ we have $f(x_n) \rightarrow f(x)$ . Let's define sequence $(e_n)$ as $e_n=1$ and $e_j = 0$ for $j \neq n$ . e.g. $$e_2 = (0, 1, 0, 0, 0...)$$ I want to judge on convergence/divergence of $\sqrt{n}e_n$ in $l^2$ space. My work so far We know that every linear and continuous functional in $l^2$ has to be in form $f(x_n) = \sum_{n=1}^\infty x_na_n$ where $a_n \in l^2$ and $x_n \in l^2$ . We are asking is there is a sequence $b_n \in l^2$ that $\sum_{j=1}^\infty a_j\sqrt{j}e_j$ converges to. But when I take $a_j = e_j$ I have that $a_j \in l^2$ and $$\sum_{j =1}^\infty a_j\sqrt{j}e_j = \sum_{j=1}^\infty \sqrt{j}e_j^2 = 0 + 0 +... +\sqrt{n} + 0 +.. = \sqrt{n} \rightarrow \infty$$ So I found linear, continuous functional that doesn't converge. Is this sufficient argument to say that $\sqrt{n}e_n$ diverges in $l^2$ ?","['convergence-divergence', 'functional-analysis', 'real-analysis']"
4128556,"Question 1.25 of Fulton's algebraic geometry: decomposing $V (Y^4 - X^2,Y^4- X^2Y^2 +XY^2-X^3)$ into irreducibles","I have been struggling with this question 1.25 of Fulton because I cannot find an example of someone doing this explicitly. I am asked to decompose: $V (Y^4 - X^2,Y^4- X^2Y^2 +XY^2-X^3)$ into irreducible factors. We see that: $$ (Y^2-X)(Y^2+X)=Y^2-XY^2+XY^2-X^2=Y^4-X^2.$$ $$(Y+X)(Y-X)(Y^2+X)=Y^4- X^2Y^2 +XY^2-X^3.$$ We then use the properties from Fulton to simplify the algebraic sets. $$V (Y^4 - X^2,Y^4- X^2Y^2 +XY^2-X^3)$$ $$=V((Y+X)(Y-X)(Y^2+X), (Y^2-X)(Y^2+X)).$$ We split off the common factor. $$V( (Y^2+X) ((Y+X)(Y-X), (Y^2-X))= $$ $$V(Y^2+X) \cup V((Y+X)(Y-X), (Y^2-X)) $$ We simplify the last bit. $$V((Y+X)(Y-X), (Y^2-X))= V((Y+X)(Y-X)) \cap V(Y^2-X) $$ $$= (V(Y+X) \cup V(Y-X)) \cap V(Y^2-X). $$ We use the distributive law of unions and intersections and arrive at: $$V((Y+X)(Y-X), (Y^2-X))=  $$ $$ (V(Y+X) \cap V(Y^2-X)) \cup (V(Y-X) \cap V(Y^2-X)$$ Which in the end gets us: $$V(Y^2+X) \cup  (V(Y+X) \cap V(Y^2-X)) \cup (V(Y-X) \cap V(Y^2-X)$$ As a decomposition into irreducible factor.... but this does not look very satisfactory, is this okay?
I have written it as a union of objects, but how do I know these are indeed irreducible?","['algebraic-geometry', 'multivariate-polynomial']"
4128624,Find the integral $\int_0^\infty \mu^x / \Gamma(x + 1) dx$ [duplicate],"This question already has an answer here : Exponential integral $ \int_0^\infty \frac{x^t}{\Gamma(t+1)}\text dt$ (1 answer) Closed 3 years ago . Basically, I'm looking for advice on how I could find the value of $$\int_0^\infty \frac{\mu^x}{\Gamma(x + 1)}dx $$ where $\mu > 0$ is an arbitrary positive constant. Based on the infinite series, I was initially expecting this to be something close to $e^\mu$ (if not exactly that). However, numerical experiments have convinced me that this is a flawed assumption unless $\mu$ is relatively large. I'm happy to push on the problem myself --- I'm just a bit unsure where to start. P.S. For context, I'm an applied statistician trying to force through an unorthodox probability distribution for data-efficiency reasons. Thanks in advance!","['integration', 'definite-integrals', 'exponential-function', 'gamma-function']"
4128631,"Find the $\max$ and the $\min$ of $f(x,y)=xy$ subject to $g(x,y)=\frac{x^2}{a^2}+\frac{y^2}{b^2}-1=0$, using Lagrange multipliers","Find the $\max$ and the $\min$ of $$f(x,y)=xy$$ subject to the constraint $$g(x,y)=\frac{x^2}{a^2}+\frac{y^2}{b^2}-1=0$$ using Lagrange multipliers. My Attempt:","['optimization', 'multivariable-calculus', 'lagrange-multiplier']"
4128666,Transform differential equation $u'' +f(u) = 0$ into system of first order,"For $f \in C^1(\mathbb{R})$ let the following differential equation be given: $u'' +f(u) = 0$ . How can one transform this equation into a system of first order and give a non-constant first integral of this system? I know that $f(u)= \omega^2 \sin(u)$ describes the mathematical pendulum and that we probably need this to transform the equation, but I'm not sure how! I found a page which described the nonlinear pendulum, but it describes it by using a second order differential equation:","['integration', 'systems-of-equations', 'ordinary-differential-equations']"
4128699,$T_{n}$ a set of all binary trees with $n$ leaves,"Let $T_{n}$ be a set of all binary trees with $n$ leaves. Show that: $$|T_1|=1,|T_2|=1,|T_3|=2,|T_4|=5$$ My attempt: I was trying to find how many options of leaves we should add to the previous tree when the tree belongs to $T_{n-1}$ , and then subtract the common options after the addition of the leaf. For example, for $T_4$ we have the following trees of $T_3$ : C             C  
                   /   \          / \
                  C     L        L   C 
                 / \                / \
                L   L     ,        L   L we have 3 options to add another leaf for each tree, however, we have to remove the common tree when: C       
                      /   \    
                     C     C  
                    / \   / \       
                   L   L L   L and we got $6-1=5$ options of trees for $T_4$ . Now, I don't know how to formal this and create a regression formula based on the process which I have used.","['trees', 'combinatorics', 'discrete-mathematics']"
4128731,What do you get when you cut a disk out of a Klein Bottle?,"I heard that you can obtain a real projective plane by gluing a disk to a Mobius band. But then I thought: if you cut a disk out of a Klein bottle (1 face, 0 edges) you'd get a shape with 1 face and 1 edges. This sounds a lot like a mobius band, but clearly isn't because that would mean reinserting the disk would yield a Klein bottle, not the aforementioned projective plane. What do you get instead?","['general-topology', 'klein-bottle', 'surfaces']"
4128742,Finding the probability density function of the $n$th largest random variable.,"Let $X_1,...,X_{25}$ be independent Unif $[0,1]$ random variables. Let $Y$ be the $13$ th largest of the $25$ random variables. Find the probability density function of $Y$ . I already know the answer for this one, but the answer that was provided just told me to use a formula to get the answer without much explanation as to why I should use that formula. This was the answer I was given: Formula: $g(x_\gamma)=\frac{n!}{(\gamma-1)!(n-\gamma)!}[F(x)]^{\gamma-1}\cdot f(x)\cdot[1-F(x)]^{n-\gamma}$ Then since $X_1,X_2,\ldots,X_{25}\sim Unif[0,1]$ , we have $$
f(x)=
\begin{cases} 
1 & \text{if } 0\leq x\leq 1 \\
0 & \text{otherwise}
\end{cases}
$$ and $$
F(x)=\int^x_01~dx=
\begin{cases}
0 & \text{if } x<0\\
x & \text{if } 0\leq x\leq 1\\
1 &\text{if } x>1
\end{cases}
$$ Then $Y=X_{(13)}$ so $$f(y)=\frac{25!}{(13-1)!(25-13)!}(x)^{13-1}\cdot1\cdot(1-x)^{25-13}$$ $$={^{25}C_{13}}13(x)^{12}(1-x)^{12}$$ Thus, the p.d.f. is $$
g(Y)=
\begin{cases}
{^{25}C_{13}}13(x)^{12}(1-x)^{12} & \text{if } 0\leq x\leq 1\\
0 & \text{otherwise}
\end{cases}
$$ Could I get an explanation of why I should use this formula or if there is another way to get the answer that is more clear? Thank you.","['uniform-distribution', 'probability-distributions', 'order-statistics', 'probability', 'density-function']"
4128758,Set theory Let R a equivalence relation on A and suppose that B is a subset A...,"Translation: I'm attempting the following proof, but I don't know which definition to use moving forward; I appreciate the help: Let $R$ be an equivalence relation on $A$ , and suppose that $B\subset A$ . Prove that, for each $x\in B$ , we have $[x]_{R|_B}=[x]_R\cap B$ . Let $x\in[x]_{R|_B}$ . Then $(x,x)\in R|_B\implies x\in B\implies x\in A$ by hypothesis, which implies $(x,x)\in R\wedge x\in B$ . estoy intentando trabajar en la siguiente demostración pero estoy en este punto y no sé que definición utilizar para avanzar, agradezco las ayudas, The following picture shows my attempt.","['elementary-set-theory', 'equivalence-relations']"
4128780,"Is $ f : \mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{Z} $, $f(x,y) = x^2-2y $ Surjective?","Is $ f : \mathbb{Z} \times \mathbb{Z} \rightarrow \mathbb{Z} $ , $f(x,y) = x^2-2y $ Surjective? My work: $f(x,y) = m = x^2-2y$ When $x=0$ , $m = -2y$ $y = -\dfrac{m}{2}$ $f(0,m) = 0-2(-\dfrac{m}{2})  = m $ Thus it is surjective. Is this sufficient. Am I missing anything?","['elementary-set-theory', 'functions']"
4128800,Any proofs of $[f(X)]^c = f(X^c)$?,"In a proof on continuity, the author heavily relies on the fact that $[f(X)]^c = f(X^c)$ to make a statement about continuity.  In words, this states that the complement of the image is equal to the image of the complement. Are there any proofs out there on this? I haven't seen any. I have an idea for how we could prove this. (Although, I will point out that my proof isn't a general result; it heavily relies on having both the domain and domain be the universal set. I understand and acknowledge this in advance.) Proof Idea Suppose $X$ is a subset of a space $\mathbb{X}$ and let $f:\mathbb{X} \to \mathbb{X}$ be a continuous function. Then $f(X) \subset \mathbb{X}.$ Now consider $X^c$ . Obviously, $X \cup X^c = \mathbb{X}$ . Then $f(X)\cup f(X^c)=f(X\cup X^c)=f(\mathbb{X})=\mathbb{X}$ . Since $f(X)\cup f(X^c)= \mathbb{X}, \hspace{0.5cm}f(X^c)= \mathbb{X} \setminus f(X)$ But notice that $\mathbb{X} \setminus f(X) = [f(X)]^c$ . This is only the case because we already established that $\mathbb{X}$ can be expressed as the union of $f(X)$ and $f(X^c)$ . Thus, we have shown that $[f(X)]^c = f(X^c) \hspace{1cm} \square$ What do you think of my idea for the proof? Does it work? Let me know what you think. I just haven't seen any formal proofs of this lemma.","['continuity', 'general-topology', 'functions']"
4128805,Property about odd function,"Let $y: \mathbb{R} \longrightarrow \mathbb{R}$ be an odd and continuous function and $T>0$ . Suppose that there exists $\varphi: \mathbb{R} \longrightarrow \mathbb{R}$ a continuous function such that $$
\int_0^T \varphi(x)\; dx=0 \tag{1}
$$ and, for some constant $\gamma>0$ , $$
y(x+T)=y(x)+\gamma\varphi(x), \; \forall \; x \in \mathbb{R}. \tag{2}
$$ Question. Is it true that $$
\int_0^T y(x) \; dx =0? \tag{*}
$$ I thought of the following: integrating $(2)$ over $[0,T]$ and using $(1)$ we obtain $$
\int_0^T y(x+L) \; dx = \int_T^{2T} y(u) \; dx. \tag{3}
$$ Now, I know that, since $y$ is odd then holds $$\int_{-T}^T y(x)\; dx=0. \tag{4}$$ Can I use $(4)$ in order to prove $(*)$ ? If so, how can I use it?","['even-and-odd-functions', 'functions', 'definite-integrals', 'real-analysis']"
4128806,Geometric quantity related to $a^3 + b^3 + c^3$,"The following geometric proof of the Pythagoras theorem relies on the fact that one can cut out 4 right angled triangles (of area $\frac12ab$ each) out of a square of side length $a+b$ to obtain another square. That is, $(a+b)^2-4\times\frac12ab$ is a square of a quantity, and it is easy to see that this quantity is the hypotenuse of the right-angled triangle of perpendicular sides $a$ and $b$ . In a similar vein, since $(a+b+c)^3 = a^3 + b^3 + c^3 + 3(a^2b+ab^2+a^2c+ac^2+b^2c+bc^2) + 6abc$ , is it possible to cut out finitely many tetrahedrons, whose total volume adds up to $3(a^2b+ab^2+a^2c+ac^2+b^2c+bc^2) + 6abc$ , out of a cube of edge-length $a+b+c$ and be left with a perfect cube with the volume of $a^3+b^3+c^3$ ? In case it is possible, does this edge of length $(a^3+b^3+c^3)^{1/3}$ have a nice geometric interpretation? Edit 1: The edge-lengths of each such tetrahedron should lie in $\mathbb{Q}[a,b,c]$ , otherwise it is trivially possible.","['euclidean-geometry', 'analytic-geometry', 'geometry', 'combinatorial-geometry', 'combinatorics']"
4128849,Why Not To Define the Lebesgue Integral Using the Upper Lebesgue Sum.,"I am trying to understand why the Lebesgue integral is defined using the lower Lebesgue sum rather than the upper Lebesgue sum. I am trying to prove the following inter-related propositions: (a) Suppose $(X, \mathcal S, \mu)$ is a measure space with $\mu(X)<\infty$ . Suppose that $f\colon X\to[0, \infty)$ is a bounded $\mathcal S$ -measurable function. Prove that \begin{align*}
\int f \; d\mu = \inf\left\{\sum_{j=1}^m \mu(A_j) \sup_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\}
\end{align*} The author of my text calls the expression on the right hand side of the equation above the upper Lebesgue sum. My textbook describes the Lebesgue integral as: $\int f \; d\mu = \sup\left\{\sum_{j=1}^m \mu(A_j) \inf_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\}$ , so I know that I have to show that $$\sup\left\{\sum_{j=1}^m \mu(A_j) \inf_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\} = \inf\left\{\sum_{j=1}^m \mu(A_j) \sup_{A_j} f: A_1, \ldots, A_m \text{ is an } \mathcal S\text{-partition of } X \right\}$$ I'd really appreciate it if someone can show me how this can be done. (b) Show that the conclusion of part (a) can fail if the condition that $\mu(X)< \infty$ is deleted. I have no clue how to approach this one. Can someone give me some examples of sets whose Lebesgue measure is infinite? I'll try to complete the solution from there. Any help on one or both of these questions would be greatly appreciated!","['measure-theory', 'lebesgue-measure', 'lebesgue-integral', 'real-analysis']"
4128850,Intuition behind Irreducible Elements and Prime Elements,"The following is from C.Musili's Introduction to Rings and Modules . Let $R$ be a commutative integral domain with unity. Definition (Irreducible elements) : A non-zero non-unit $a\in R$ is said to be irreducible if $a = bc$ , then either $b$ or $c$ is a unit, i.e. $a$ cannot be written as a product of two non-units. Equivalently, the only divisors of $a$ are its associates or units. Definition (Prime Elements) : A non-zero non-unit $a\in R$ is said to be prime if $a|bc$ ( $b,c\in R$ ), then either $a|b$ or $a|c$ . What is the intuition behind the two definitions above? I understand what they mean, and how they are different - but how were these definitions motivated? What should I think about when I think about irreducibility or primality (besides the definitions)? In some sense, I thought irreducibility (by the English definition) meant that irreducible elements cannot be further broken down into ""smaller"" elements? The definition seems to say that irreducible elements are those non-zero non-units, which cannot be broken down as the product of two non-units. However, they can still be broken down into their associates or units - so what is the point? Are they really ""irreducible"" ? When learning about $\mathbb N$ as a child, I had similar notions of prime elements in mind - i.e. they are the building blocks of all numbers in that they cannot be broken down as the product of numbers except $1$ and the number itself. Perhaps my childhood intuition has misguided me at this stage since this appears to be what we mean by irreducibility? How do I think of primality, then? I also know that primes are irreducible, but the converse is not true (follows from the definitions). I suspect this could be a reason why I am confusing the two notions (in terms of intuition; of course I understand the definitions and difference otherwise). An example of an irreducible element that is not prime is $1 + i\sqrt 3$ in $\mathbb Z[i\sqrt 3]$ . Could you please give me intuition for irreducibility and primality (in the context of rings, or more generally if you wish) like I'm five? Thank you!","['ring-theory', 'abstract-algebra']"
4128901,"Spectrum of $\Delta+a$ on a compact manifold, where $a$ is a function","Let $(M,g)$ be a closed Riemannian manifold and $\Delta$ be its Laplace-Beltrami operator. It is well known that the spectrum of $\Delta$ is a discrete subset of $[0,+\infty)$ and the eigenfunctions form an orthogonal basis of the Hilbert space $W^{1,2}(M)$ . My question is: Question: Given $a\in C^\infty(M)$ , does the operator $Lf:=\Delta f+af$ have the same spectral property as $\Delta$ (except that the interval $[0,+\infty)$ should be replaced by $[\lambda_0,+\infty)$ , where $\lambda_0$ is the lowest eigenvalue)? My background on analysis is quite limited, so any hint about the ideas behind this kind of results and their generalizations would be appreciated!","['laplacian', 'elliptic-equations', 'riemannian-geometry', 'differential-geometry']"
4128909,How can I prove that $\lim_{n \to \infty}\left(1+c\cdot \left(\exp\left(\frac{it}{n}\right) - 1\right)\right)^n=\exp(i\cdot tc)$?,"I'm trying to prove some random variable converges to a constant $c$ and this limit showed up $$\lim_{n \to \infty}\left(1+c\cdot \left(\exp\left(\frac{it}{n}\right) - 1\right)\right)^n$$ For the random variable in question to converge to $c$ it's necessary that this limit above be equal to $\exp(itc)$ , which is the reason for the title. I tried using the classic: $$\lim_{n \to \infty}\left(1+\frac{z}{n}\right)^n=e^z$$ but this did not help me. I'm thinking I'm gonna have to use some other known limit involving the exponential but I don't know how to do so. I appreciate any help!","['limits', 'calculus', 'probability-theory', 'complex-numbers']"
4128930,Prime numbers dividing infinitely many numbers in a sequence,"Here I found a question: Show that every prime not equal to $2$ or $5$ divides infinitely many
of the numbers $1,11,111,1111,\dots$ etc. which is partly solved here Prime numbers divide an element from a set . From this the following conjecture seems reasonable: Given any finite set $S=\{q_1,\dots,q_k\}$ of $k$ primes, then any
prime $p\notin S$ divides infinitely many of the numbers $a_1,a_2,a_3\dots$ , where $a_1=1$ and $a_{n+1}=1+a_n\prod q_i$ . Can this be proved?","['elementary-number-theory', 'divisibility', 'sequences-and-series']"
4129004,Show that $\frac\partial{\partial r}\int_{B_r(x)}f=\int_{\partial B_r(x)}f$,"Let $\lambda$ denote the Lebesgue measure on $\mathbb R$ , $d\in\mathbb N$ , $f\in C(\mathbb R^d)$ , $x\in\mathbb R^d$ and $$g(r):=\int_{B_r(x)}f\:{\rm d}\lambda^{\otimes d}\;\;\;\text{for }r>0.$$ I would like to show that $^1$ $$g'(r)=\int f\:{\rm d}\sigma_{\partial B_r(x)}\tag0.$$ For clarity of exposition, let $$\tau_x:\mathbb R^d\to\mathbb R^d\;,\;\;\;y\mapsto y+x$$ and $$\theta_r:\mathbb R^d\to\mathbb R^d\;,\;\;\;x\mapsto rx.$$ We know that $\tau_x\left(\lambda^{\otimes d}\right)=\lambda^{\otimes d}$ ; $\theta_r\left(\lambda^{\otimes d}\right)=r^{-d}\lambda^{\otimes d}$ for all $r>0$ ; $B_r(x)=rB_1(0)+x=\tau_x\left(\theta_r\left(B_1(0)\right)\right)$ for all $r>0$ and $$\int_M\frac{\partial\varphi}{\partial x_i}\psi\:{\rm d}\lambda^{\otimes d}=\int\varphi\psi\left(\nu_{\partial M}\right)_i\:{\rm d}\sigma_{\partial M}-\int_M\varphi\frac{\partial\psi}{\partial x_i}\:{\rm d}\lambda^{\otimes d}\tag4$$ for every bounded $d$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ with boundary and $C^1$ -differentiable $\varphi,\psi:M\to\mathbb R$ , where $\nu_{\partial M}$ denotes the unit outward pointing normal field on $\partial M$ . So, $$g(r)=r^d\int_{B_1(0)}f\circ\tau_x\circ\theta_r\:{\rm d}\lambda^{\otimes d}\tag5$$ and $$\int f\:{\rm d}\sigma_{\partial B_r(x)}=r^{d-1}\int f\circ\tau_x\circ\theta_r\:{\rm d}\sigma_{\partial B_1(0)}\tag6.$$ However, I still don't see how we obtain $(0)$ . In order to proceed with $(5)$ , I would usually ""differentiate under the integral sign"", but in order to do that, we would need to assume that $f$ is differentiable. On the other hand, even if I do assume differentiability, this should yield $$g'(r)=dr^d\int_{B_r(x)}\langle y-x,\nabla f(y)\rangle\:\lambda^{\otimes d}({\rm d}y)\tag7$$ and applying $(4)$ , we should obtain $$\int_{B_r(x)}\langle y-x,\nabla f(y)\rangle\:\lambda^{\otimes d}({\rm d}y)=\int f(y)\langle y-x,\nu_{\partial M}(y)\rangle\:{\rm d}\sigma_{\partial B_r(x)}-d\int_{B_r(x)}f\:{\rm d}\lambda^{\otimes d},\tag8$$ which doesn't seem to be helpful. So, what am I missing and how can we prove claim without assuming differentiability of $f$ ? $^1$ Let $\sigma_M$ denote the surface measure on $\mathcal B(M)$ for every embedded $C^1$ -submanifold $M$ of $\mathbb R^d$ .","['divergence-theorem', 'measure-theory', 'lebesgue-integral', 'real-analysis', 'differential-geometry']"
4129036,If $A$ is normal show that $A+A^*$ bijective implies $A$ is bijective,"Suppose $A$ is a normal ( $||Ax||=||A^*x||$ for all $x \in H$ ) bounded linear operator on a Hilbert space $H$ . We want to show that if $A+A^*$ is a bijection then so is $A$ . A is injective is very easy since $kerA=kerA^*$ we have that  if $Ax=0$ then $x \in ker(A)\cap ker(A^*)$ so $x \in ker(A+A^*)$ so $x=0_H$ . I'm stuck on surjective. My hint is to use the open mapping theorem (so $A+A^*$ is open); but I can't see how this helps me at all. I thought maybe I could prove $Im(A)$ was dense and closed but I can't relate either to $A+A^*$ . EDIT
In",['functional-analysis']
4129069,Find partial differential using chain rule,Show that $\frac{\partial }{\partial x}=\frac{\partial }{\partial z}+\frac{\partial }{\partial \bar{z}}$ and $\frac{\partial }{\partial y}=i\left (\frac{\partial }{\partial z}-\frac{\partial }{\partial \bar{z}}  \right )$ Let $z=x+iy$ then $\bar{z}=x-iy$ from here $\qquad\begin{align}\frac{\partial }{\partial x}&=\frac{\partial z }{\partial x}\cdot\frac{\partial }{\partial z}+\frac{\partial \bar{z}}{\partial x}\cdot\frac{\partial }{\partial \bar{z}}\\&=1\cdot\frac{\partial }{\partial z}+1\cdot\frac{\partial }{\partial \bar{z}}\\&=\frac{\partial }{\partial z}+\frac{\partial }{\partial \bar{z}}\end{align}$ and $\qquad\begin{align}\frac{\partial }{\partial y}&=\frac{\partial z }{\partial y}\cdot\frac{\partial }{\partial z}+\frac{\partial \bar{z}}{\partial y}\cdot\frac{\partial }{\partial \bar{z}}\\&=i\cdot\frac{\partial }{\partial z}-i\cdot\frac{\partial }{\partial \bar{z}}\\&=i\cdot\left ( \frac{\partial }{\partial z} -\frac{\partial }{\partial \bar{z}}\right)\end{align}$ Is that okay or should I use the equalities $\frac{\partial }{\partial z}=\frac{1}{2}\left ( \frac{\partial }{\partial x}-i\frac{\partial }{\partial y} \right )$ and $\frac{\partial }{\partial \bar{z}}=\frac{1}{2}\left ( \frac{\partial }{\partial x} +i\frac{\partial }{\partial y}\right )$,"['analysis', 'complex-analysis', 'partial-fractions', 'partial-derivative', 'complex-numbers']"
4129115,"The hairy ball theorem, from Brouwer's fixed point.","EDIT : The question is now the following. I know this statement of the hairy ball theorem : Theorem : Let $n \geq 3$ be an odd number, and $f:\mathbb{S}^{n-1} \rightarrow \mathbb{R}^n$ be a continuous map such that $\langle f(x),x \rangle = 0$ for every $x \in \mathbb{S}^{n-1}$ . Then there exists $x_0 \in \mathbb{S}^{n-1}$ such that $f(x_0)=0$ . In the linked paper provided by C.F.G., there is this version of hairy ball theorem : Theorem : For any continuous map $v : B \rightarrow R^n$ such that $\langle v(x), x \rangle \leq 0$ for all $x \in \mathbb{S}^{n-1}$ , there
exists some $z \in B$ such that $v(z)=0$ . To be honest, I don't really see how to go from one of these versions to the other : how the even dimension is replaced, in the second version, by the hypothesis $\langle v(x), x \rangle \leq 0$ ? Is someone could explain how these two statements are linked, that would be great ! $$-------------------------------------$$ Original question : My question is rather simple today : is there an easy proof of hairy ball theorem that uses Brouwer fixed point theorem ? I know that these two results are similar in some ways, and I know that they have proofs that rely on the same kind of arguments (I saw Milnor proofs for these two results), but my concern is : let's suppose that you know that Brouwer's fixed point theorem is true ; is there a way to deduce the hairy ball theorem with only elementary steps from there ? I guess there may be an obstruction, due to the fact that Brouwer theorem is true in every dimension, whereas the hairy ball theorem is not. If someone knows a short proof, or has a reference, it would be really nice. Thanks !","['general-topology', 'differential-topology', 'reference-request', 'differential-geometry']"
4129139,Sign in definition of Cap product,"We define the cap product in the following way : $$a \frown z := \epsilon \otimes 1(a \otimes Ez \circ \Delta_\star(z))$$ Where : $1. \hspace{0.3cm} \Delta_\star$ is the induced map on chain complex by the diagonal map $\Delta : X \longrightarrow X \times X$ $2. \hspace{0.3cm}Ez$ is a choince of an Eilenberg-Zielber map $Ez : C_\bullet(X \times X) \longrightarrow C_\bullet(X) \otimes C_\bullet(X)$ $3.\hspace{0.3cm} \epsilon$ is the map defined only in degree $0$ , more accurately $\epsilon_n = 0$ if $n \ne 0$ and $\epsilon_0 : (C^\bullet(X)\otimes C_\bullet(X))_0 \longrightarrow \mathbb{Z}$ where $\langle f,x \rangle = f(x), f \in C^i(X),x \in C_i(X)$ . With those convention it should be clear that we call cap product the following map : $$C^q(X) \otimes C_{p+q}(X) \overset{\frown}{\longrightarrow} C_p(X)$$ Now, since the Eilenberg-Zielber theorem due to acyclic models theorem we have that any choice (dependant on chain level) that extends the diagonal will be as good as the defined since they will induce the same map in homology. Given the premise I'd like to substitute the $Ez \circ \Delta_\star(z)$ with $AW(z) = \sum\limits_{p+q = n} \sigma_p^1 \otimes \sigma_q^2$ the Alexander Whitney map, see the definition in a previous question here . What I don't understand is the following : If I compute $\varphi \frown \sigma$ with $\varphi \in C^p$ and $\sigma : \Delta^{p+q} \longrightarrow X$ I end up having the formula $\varphi(\sigma_{|[e_q,\cdots,e_{p+q}]})\cdot \sigma_{|[e_0,\cdots e_q]}$ which is indeed the formula of the cap product here . What I should get according to my professor is $(-1)^{pq}\varphi(\sigma_{|[e_q,\cdots,e_{p+q}]})\cdot \sigma_{|[e_0,\cdots e_q]}$ . Where the sign on $(-1)$ comes from ? Reading ""Tammo Tom Dieck, Algebraic Topology"" at page $290$ , I found the following Is this somehow related to my problem? I thought $f = \epsilon$ and $g = \text{id}$ could work. I'm not sure since if the degree of a map is defined as the integer $p$ such that $f : C_q(X) \longrightarrow C_{q+p}(X)$ the identity should have degree $0$ , which doesn't solve the problem. Addendum : Is the sign of the $(1)^{|g||a|}$ there for particular reasons ? I thought this could be since if we define the differential of two chain complex with a factor $(-1)^{\bullet}$ then that is the right sign to achieve $d(f \otimes g) = (f\otimes g)d$ , but computing the two of them, that doesn't seem relevant. Any help in understanding this would de be appreciated since the construction of cap product and cup product is strictly related to understanding duality.","['abstract-algebra', 'group-cohomology', 'tensor-products', 'homology-cohomology', 'algebraic-topology']"
4129197,How to relate non-harmonic oscillation to harmonic oscillation,"Consider the follwoing equation $$\partial_t^2\phi(t)+\lambda\phi^3(t)=0. \tag{1}$$ This equation describes an oscillator in a potential $V(\phi)=\phi^4/4$ . And we know that the solution is the elliptic consine function: $$\phi(t)=\phi_0{\rm cn}[\sqrt{\lambda}\phi_0t,1/\sqrt{2}],$$ where $\phi_0$ is an integration constant. Since the elliptic cosine function is also a periodic function, I would assume that it is possible to  relate it to the cosine function by a rescalling of the time. So is it possible to transform Eq. (1) to the equation of motion for a harmonic oscillator with a rescalling of time $t\rightarrow \tau=f(t)$ , $$(\partial_\tau^2+\omega^2)\phi=0$$ with some frequency $\omega$ ?",['ordinary-differential-equations']
4129294,"If $(AB)^n = 0$, must $(BA)^n=0$?","Let $A, B$ be two $n\times n$ matrices. If $(AB)^n = 0$ , must $(BA)^n=0$ ? I believe it's true but don't know how to pove it. To clarify, $n$ here is not just any arbitrary integer but the dimension of the matrices.","['matrices', 'linear-algebra']"
4129330,Show that $\mathcal{F}$ and $\mathcal{G}$ are independent $\sigma$-algebras,"We have a probability space $(\Omega, \mathcal{A}, \mathbb{P})$ , let $(A_n)_{n \geq 1}$ be a sequence of independent sub- $\sigma$ -algebras of $\mathcal{A}$ . We consider: $\mathcal{F}:= \sigma \left ( \bigcup_{n even} \mathcal{A}_n\right )$ and $\mathcal{G}:= \sigma \left ( \bigcup_{n odd} \mathcal{A}_n\right )$ I want to show that $\mathcal{F}$ and $\mathcal{G}$ are independent. For that I want to use a proposition and check that: $\mathcal{F}$ and $\mathcal{G}$ are independent $\iff \forall F \in \sigma(\mathcal{F}) = \{\emptyset, \mathcal{F}, \mathcal{F}^c, \Omega\}, \forall G \in \sigma(\mathcal{G}) = \{\emptyset, \mathcal{G}, \mathcal{G}^c, \Omega\} \implies \mathbb{P}[F \cap G] = \mathbb{P}[F] \mathbb{P} [G]$ . Now I would check for each combination the conditions hold: Case 1: If both $F = G = \emptyset$ then the statement obviously holds since by defintion $\mathbb{P}[\emptyset] = 0$ . Case 2: If either $F$ or $G$ equals the empty set, the condition hold by the same argument. Case 3: If both $F = G = \Omega$ the condition holds again by a similar argument. Now the harder cases are those if I have to consider for example: $F =  \mathcal{F}$ and $G = \mathcal{G}$ . How can I proceed here?","['measure-theory', 'independence']"
4129340,Lie group structure induced by a surjective group homomorphism.,"Let $H$ be a group and $G$ a connected Lie group. Suppose we have a surjective group $f:H \to G$ , whose kernel is finite lying in $H$ 's centre $Z(H)$ . The question is, how to show that $H$ has a unique Lie group structure such that $f$ is also a Lie group homomorphism, as well as a covering map . My attempt was identifying $V_i = f^{-1}(U_i)$ and $\psi_i = \varphi_i \circ f$ for the atlas of $H$ while $(U_i,\psi_i)_i$ is an atlas for $G$ . But I think my attempt solved nothing at all. Perhaps I had only used surjectivity of $f$ , meanwhile I guess the finiteness of its kernel, and the connectedness of $G$ , should have been used already. Would you like to give any hint or a proof for this question? I found no document teaching this on the internet :(","['topological-groups', 'smooth-manifolds', 'group-theory', 'lie-groups', 'differential-geometry']"
4129387,Variance of the minimum of two r.v.'s,"For two nonnegative independent r.v.'s, $X,Y$ , with the same distribution and finite second moment, I'm trying to show that $Var[\min(X,Y)]\leqslant Var[X]$ . Attempt 1. For the continuous case, I've written the first and second moments of $\min(X,Y)$ in terms of $X$ but have no idea how to proceed with them. Specifically, with $Z=\min(X,Y)$ , I have $\mathbb{E}\left[Z\right]=2\mathbb{E}[X]+\int_{0}^{\infty}F^2_{X}(z)dz$ , $\mathbb{E}\left[Z^2\right]=2\mathbb{E}\left[X^{2}\right]+2\int_{0}^{\infty}zF_{X}^{2}(z)dz$ , (where $F_{X}$ is the cdf of $X$ ) but don't know what to do with the integrals in the RHS's of the above expressions. Attempt 2. Noting that $\min(X,Y)=\frac{1}{2}\left(X+Y-|X-Y|\right)$ , I can write \begin{equation} \label{eq1}
\begin{split}
Var\left[\min(X,Y)\right] & = Var[X]-\frac{1}{4}\left(\mathbb{E}\left[\left|X-Y\right|^2\right]+4\text{Cov}\left(X,|X-Y|\right)\right),  \\
\end{split} 
\end{equation} but am struggling to show that the RHS's second term (1/4(...)) is less than or equal to zero. Any suggestions about how I might proceed or confirmation these are dead-ends would be appreciated.","['cumulative-distribution-functions', 'order-statistics', 'variance', 'probability']"
4129426,How to show $\begin{pmatrix}1&1 \\ 1&1\end{pmatrix}^n = 2^{n-1}\begin{pmatrix}1&1 \\ 1&1\end{pmatrix}$?,"Initial note: I'm interested in the combinatorics aspect of the following problem, not how to proof the relation in general. The idea is to show the following relationship: $$
\begin{pmatrix}1&1 \\ 1&1\end{pmatrix}^n = 2^{n-1}{\underbrace{\begin{pmatrix}1&1 \\ 1&1\end{pmatrix}}_{\equiv M}}
$$ by decomposing the matrix $M = A + B + C + D$ into the four individual matrices $$
A = \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix} \qquad
B = \begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix} \qquad
C = \begin{pmatrix} 0 & 0 \\ 1 & 0 \end{pmatrix} \qquad
D = \begin{pmatrix} 0 & 0 \\ 0 & 1 \end{pmatrix}
$$ and noting the following relationships for matrix multiplication: $\ast$ $A$ $B$ $C$ $D$ $\bf{A}$ $A$ $B$ $0$ $0$ $\bf{B}$ $0$ $0$ $A$ $B$ $\bf{C}$ $C$ $D$ $0$ $0$ $\bf{D}$ $0$ $0$ $C$ $D$ If these matrix products were commutative, one could use the multinomial theorem in order to compute the coefficients for the resulting polynomial $(A+B+C+D)^n$ . Since they are not, one needs to consider all possible combinations for the matrices $A,B,C,D$ (like for this question ): $$
\sum_{combinations} X_1X_2\dots X_n \qquad, \quad \mathrm{where} \; X_i \in \{A,B,C,D\}
$$ However due to the above relations, each pair of matrices $X_iX_{i+1}$ can be reduced to either zero or another matrix of the set $\{A,B,C,D\}$ (which means the contribution of the whole expression $X_1X_2\dots X_n$ will reduce to either $0$ or $1$ ). So I'm wondering whether by applying this knowledge it is possible to combine the various permutations for a given term $A^{k_1}B^{k_2}C^{k_3}D^{k_4}$ in order to determine how many nonzero permutations there are. Together with the multinomial coefficients this could then be used to calculate the result. At this point I'm struggling to find the number of nonzero permutations for a given set of powers $\{k_1,k_2,k_3,k_4 | k_i \geq 0\}$ in the expression $A^{k_1}B^{k_2}C^{k_3}D^{k_4}$ . Is there are way to determine this?","['matrices', 'combinatorics', 'multinomial-coefficients', 'multinomial-theorem']"
4129455,"Does the ""average derivative of a function"" exist?","Given a function $f$ that is differentiable everywhere,
what would $$\frac{\sum_{x\in\mathbb{R}}\frac{df(x)}{dx}}{|\mathbb{R}|}$$ denote? Does this expression even make sense? The size of $\mathbb{R}$ is infinite, so there is more confusion there as well. For example, intuitively, I know $$f(x)=x$$ has an average derivative of $1$ , since $\frac{dx}{dx}=1$ for all $x\in\mathbb{R}$ . How can this be extended to all differentiable functions?","['calculus', 'derivatives']"
4129476,"How to define the grad, div and the curl of a distribution?","I have learned how to define the derivative or partial derivative of a distribution, but I still can't find a clear definition of the grad, div and curl of a distribution, I would appreciate it if you could write down the detailed definition of the definitions of these operators of distribution or recommend me some books about the curl, div and grad of distributions","['distribution-theory', 'functional-analysis', 'real-analysis']"
4129545,There is only one analytic real function of a complex variable. Why am I wrong?,"Consider a function $f: \mathbb{C} \mapsto \mathbb{R}$ . As far as I know, for this function $f(x, y) = u(x, y) + iv(x, y)$ to be analytic, it must satisfy the Cauchy-Riemann conditions, which state: $$
\frac{\partial u}{\partial x} =\frac{\partial v}{\partial y} \\
\frac{\partial u}{\partial y} = -\frac{\partial v}{\partial x} 
$$ Of course, $v(x, y) = 0$ . This implies that $u(x, y) = C$ where $C$ is constant, and thus the only real function of a complex variable is $f(z) = C$ . This cannot be right, surely? Why am I wrong?","['complex-analysis', 'functions', 'complex-numbers']"
4129636,"Dodecahedron faces are buttons, vertices have counters that track the use of the buttons","As a follow up to this question , I'm trying to teach invariants by creating a game. The idea is to start with a dodecahedron where each of the 20 vertices has a counter on it and each of the 12 faces is a button. You can click a button to increase the value of each counter on that face by 1, or right-click a button to decrease the value of each counter on that face by 1. Counters are all initially set to 0. The challenge is to describe all possible sets of values that the counters can take on. Clearly the sum of the counters must be a multiple of 5, but i don't think that this necessary condition is sufficient as there are less faces than vertices. It's easy enough to create a 20x12 matrix that shows each vertex counter's value in terms of the 12 faces. For a given set of counter values, I think we could create a 20x13 augmented matrix and row reduce to see if there's a combination of buttons that could be pressed to achieve that set - of course we'd need integer value solutions - but I'd like a more general result. Would a 13th column made of constants help any? A linear algebra solution would be great, but is there a more clever (elementary) way to do this that doesn't involve linear algebra? Thanks for your help!","['invariance', 'geometry', 'platonic-solids']"
4129646,Is my direct proof correct for $ \prod_{i=2}^{n} \left(1- \frac{1}{i^2}\right) =\frac {n+1}{2n} $ good/correct? [duplicate],"This question already has an answer here : show that for any n $\in$ $\Bbb N$ , if n $\ge$ 2, then $\prod_\limits{i=2}^n $ $\left( 1-\frac{1}{i^2}\right)$ = $\frac{n+1}{2n}$ (1 answer) Closed 3 years ago . I need to show via direct proof that: $$  \prod_{i=2}^{n} \left (1-
\frac{1}{i^2}\right) =\frac {n+1}{2n} $$ We first note that $$1-\frac{1}{i^2} = \frac{(i-1)(i+1)}{i\cdot i}.$$ Then \begin{align}
\prod_{i=2}^{n}  \left(1-
\frac{1}{i^2}\right)&=\prod_{i=2}^{n} \frac{(i-1)(i+1)}{i\cdot i}\\
&=\frac {(n-1)!\cdot \frac{(n+1)!}{2} } {n!\cdot n!}\\
&=\frac {(n-1)!\cdot(n+1)!}{2\cdot n!\cdot n!}\\
&=\frac {(n+1)}{2n}.
\end{align} Direct proof end. Is that sufficient enough for a direct proof? Any critique would be helpful! Thanks!","['solution-verification', 'discrete-mathematics', 'products']"
4129750,Find explicit formula for summation for p>0,Find explicit formula for summation for any $p>0$ : $$\sum_{k=1}^n(-1)^kk\binom{n}{k}p^k.$$ Any ideas how to do that? I can't figure out how to bite it. I appreciate any help.,"['power-series', 'summation', 'discrete-mathematics', 'sequences-and-series']"
4129800,"Why $\gcd(b,qb+r)=\gcd(b,r),\,$ so $\,\gcd(b,a) = \gcd(b,a\bmod b)$","Given: $a = qb + r$ . Then it holds that $\gcd(a,b)=\gcd(b,r)$ . That doesn't sound logical to me. Why is this so? Addendum by LePressentiment on 11/29/2013: (in the interest of http://meta.math.stackexchange.com/a/4110/53259 and averting a duplicate) What's the intuition behind this result? I only recognise the proof and examples solely due to algebraic properties and formal definitions; I'd like to apprehend the result naturally.","['divisibility', 'elementary-number-theory', 'gcd-and-lcm', 'abstract-algebra', 'ideals']"
4129805,Find a rectangular parallelepiped of total area 'A' having the maximum volume.,"Find a rectangular parallelepiped of total area 'A' having the maximum volume.
Using Lagrange multipliers, Determine: Function to optimize. Condition or constraint. The dimensions of 'x', 'y', 'z'. $g(x,y,z) = xyz=V$ $f(x,y,z)=2(xy+yz+zx)$ By lagrange multipliers, we get the following relations $$2(z+y) = \lambda yz \tag{1}$$ $$ 2(z+x) = \lambda xz \tag{2}$$ $$ 2(y+x)= \lambda xy \tag{3}$$ From (1) and (2),: $$ \frac{z+y}{z+x} = \frac{y}{x}$$ $$ xz + xy = zy + yx$$ Hence, $$ x=z$$ Similarly , by solving the system, we get $x=y=z$ , plugging $xyz$ into the expression for $g$ : $$ x^3 = S$$ $$ x = S^{\frac13}$$ Finally, I have reached the point where $x$ = $\sqrt[3]{s}$ , I am not very sure if the procedures I have performed are correct because of this result; I am not sure how to proceed to find the variables $x, y, z$ . Can anyone help me with this, please?","['calculus', 'derivatives', 'lagrange-multiplier']"
4129806,Limit of infinite composition of sin(x),"I was playing around on desmos the other day, and noticed that $\sin\left(\sin\left(x\right)\right)$ is basically a version of sin with a lower amplitude (which makes intuitive sense). To me, it seems intuitve that this curve, when composed infinite times, becomes a straight line, as the values at $x=\frac{\pi}{2}\mathbb{Z}$ would move (slowly) towards the values at $x=\pi\mathbb{Z}$ by virtue of them moving away from the peaks, but is there a way to go about properly proving this?","['limits', 'functions']"
4129831,$\lim_{n \to \infty} \int_{0}^{1} e^{x^2} \sin(nx) dx$ [duplicate],This question already has answers here : How to prove that $\lim\limits_{n\to\infty}\int\limits _{a}^{b}\sin\left(nt\right)f\left(t\right)dt=0\text { ? }$ (3 answers) Closed 3 years ago . $$\lim_{n \to \infty} \int_{0}^{1} e^{x^2} \sin(nx) dx$$ I am trying to find above limit without using the concept of Lebesgue integration. I know that $e^{x^2} sin(nx)$ is not a uniformly convergent sequence of functions so i can not take limit inside integration. So give me any idea that is it really possible to evaluate the limit without using the concept of lebesgue integration. Thank you,"['integration', 'limits', 'real-analysis']"
4130036,"If $A$ and $B$ are positive-definite matrices with $A>B$, must $A^k > B^k$ for $k>0$? [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Assume $A$ and $B$ are positive-definite matrices. If $A>B$ , can we conclude that $A^k > B^k$ for any positive scalar $k$ ? Note that $A>B$ means $A-B$ is a positive-definite matrix, not an element-wise comparison. I've tried using Cayley-Hamilton theorem but could not get anywhere with it so far.","['matrices', 'linear-algebra']"
4130082,Definition of weak* convergence in $L^{\infty}$,"I'm new to functional analysis and have (what I think is) a basic question on the definition of weak* convergence. Let $X$ be a normed linear space with dual $X^{\ast}$ . According to the definition I know, a sequence $(f_n)_{n \in \mathbb{N}}$ in $X^{\ast}$ is said to converge weakly* to $f \in X^{\ast}$ if $f_n$ converges pointwise to $f$ , that is, if $$\forall x \in X, \quad\lim_{n \rightarrow \infty} f_n(x) = f(x).$$ In the special case that $X^{\ast} = L^{\infty}(\Omega,\mu)$ for some measure space $(\Omega,\mathcal{A},\mu)$ , I've stumpled upon a different definition (for example, here and here ): a sequence $(f_n)_{n \in \mathbb{N}}$ in $L^{\infty}(\Omega,\mu)$ converges weakly* to $f \in L^{\infty}(\Omega,\mu)$ if $$\forall g \in L^1(\Omega,\mu), \quad \lim_{n \rightarrow \infty} \int_{\Omega} f_n g \,\text{d}\mu = \int_{\Omega} f g \,\text{d}\mu.$$ My feeling is that both definitions are equivalent because of Riesz' Representation Theorem. Is this correct? If so, how can the equivalence be formally proved?","['lp-spaces', 'functional-analysis', 'weak-convergence']"
4130102,Can you explain this relation between finite fields and circles?,"Let $p$ be a prime such that $p \bmod 4 = 1$ , so there exists some $i=\sqrt{-1}$ in $\mathbb{F}_p$ . Furthermore, let $r \in \mathbb{N}$ be the radius of a circle such that there are $p-1$ lattice points on it. (The sums of squares function allows to compute such $r$ .) I think that for every lattice point $(x,y)$ there is a unique $z = x + iy$ in $\mathbb{F}_p$ . Also, there is a generator $g$ in $\mathbb{F}_p$ such that $g^\alpha$ traverses the lattice points in the order given by their angle on the circle. Here's an example with $g=2$ : (The line segments in the picture above point to $(x \bmod p)$ and $(y \bmod p)$ . They describe a circle of radius $(r \bmod p)$ in the finite plane $\mathbb{F}_p \times \mathbb{F}_p$ .) Is there any literature about that phenomenon? Can you prove the order of points fits the order given by $g^\alpha$ ? Here are questions related to that topic: How does trigonometry in a Galois field work? The structure of the unit circle in the plane $F^2$, where $F$ is a finite field with odd characteristic. Another interesting observation is that this relation between pythagorean triples and field elements allows to map elements of finite fields to rational points on the unit circle .","['gaussian-integers', 'finite-fields', 'galois-theory', 'discrete-logarithms', 'group-theory']"
4130116,Finding angles of a triangle given a relation between it's sides and angles.,"F̶i̶n̶d̶ ̶a̶l̶l̶ ̶a̶n̶g̶l̶e̶s̶ (edit: that might have been asking for too much, sorry for the wrong problem statement, I thought that by solving for all angles, finding x would be trivial but as it seems to be thanks to timon92 that might not be possible) Find the angle $x$ knowing only the length of the side |AB|, the constants $E_A$ and $E_B$ and the relation $$E_B  r_B^2 sin(\gamma) = E_A r_A^2sin(\delta)$$ I've tried to solve a system of equations containing the known relation the sine law, the three cosine laws for each of the sides along with the pythagorean identities. I wasn't even sure if this had a solution but I've managed to reduce it to a system of 4th degree polynomials and I'm still not sure if this is doable. Any sort of help would be greatly appreciated. (Edit: the second to last bracket is wrong but that doesn't change much, it's still a not an easy system of equations) The give a bit of context the problem comes from my own project, where there is a light point source at C, two luminosity readings at A and B, $E_i = \frac{I}{r_i^2}cos(\theta) $ , where I is the unknown intensity and $\theta$ is the angle between the illuminated surface and the plane perpendicular to the incident light. Originally I wanted to find the azimuth and altitude angles (x in the 2d case) of the light source given three sensors and their known relative position without the distance (so 2 out of 3 spherical coordinates) but even the 2d case stumped me.","['trigonometry', 'geometry']"
4130123,Left inverse iff injective; Right inverse iff surjective,"I'm trying to make the below proof as rigorous as possible, but I am not completely certain on how to phrase several steps and their justifications. The statement is: Let $f: X \to Y$ be a map of sets. A function $g: Y \to X$ is called a left (resp. right) inverse of $f$ if $g \circ f = \mathrm{id}_X$ (resp. $f \circ g = \mathrm{id}_Y$ ). Show that $f$ admits a right inverse if and only if $f$ is surjective (onto). Show that, in general, a right inverse is not unique. Show that $f$ admits a left inverse if and only if $f$ is injective (one-to-one). Show that, in general, a left inverse is not unique. The prompt doesn't require that $X,Y $ be nonempty, so I felt the need to first rule out these ""edge cases."" We first rule out the edge cases. Notice that if one of $X$ or $Y$ is empty, then the other must be empty for this result to hold. Indeed, if $X = \emptyset$ , then $f: X \to Y$ is only defined if $Y = \emptyset$ . Similarly, if $Y = \emptyset$ , then a function $g: Y \to X$ is defined only if $X = \emptyset$ . So if $X = Y = \emptyset$ , then $f: X \to Y$ , the empty function, is vacuously bijective and is, in fact, its own inverse. We proceed under the assumption that $X,Y \neq \emptyset$ . I'm not sure if this above explanation is fully rigorous. Here's now my attempt at the forward direction for part (a). Suppose that $f$ admits a right inverse $g: Y \to X$ . Given $y \in Y$ , there exists a unique $x \in X$ such that $g(y) = x$ . But then $$f(g(y)) = (f \circ g)(y) = \mathrm{id}_Y (y) = y = f(x),$$ so $f$ is surjective. I'm fairly confident in this forward direction, but less so in the backward direction. Conversely, suppose that $f$ is surjective. Define the function $g: Y \to X$ sending $y \longmapsto x$ for some preimage $x \in f^{-1} (y)$ . In the case where the preimage of $y$ in $x$ is non-unique, we apply the axiom of the choice to pick a single $x$ . Given $y \in Y$ with corresponding $x = g(y)$ , we have \begin{align*}
(f \circ g)(y) = f(g(y)) = f(x) = y, 
\end{align*} so $f \circ g = \mathrm{id}_Y$ , and $f$ admits a right inverse. My key point of confusion is whether it makes sense to ""define"" $x$ as $g(y)$ . The more rigorous approach seems to be to argue that $f \circ g = \mathrm{id}_Y$ by definition, or perhaps there's a better argument. For lack of uniqueness, here's what I came up with. I'll be defining $\mathbb{Z}/2 = \{0,1\}$ with addition given by $(a,b) \mapsto$ $a + b$ if $a + b < 2$ and $a + b - 2$ otherwise. I claim that a right inverse is not
in general unique. Consider the reduction map $$
\begin{array}{rccl}
f \colon & \mathbb{Z} & \longrightarrow & \mathbb{Z}/2  \\
& a & \longmapsto & a \text{ mod $2$}.
\end{array}
$$ Notice that $f$ is surjective, but $1,3 \in f^{-1} (1)$ , so we can define right inverses $g_1: Y \to X$ sending $$
y \longmapsto \begin{cases}
1, \; \text{ if $y = 1$} \\
0, \; \text{ if $y = 0$}
\end{cases}
$$ and $g_2: Y \to X$ sending $$
y \longmapsto \begin{cases}
3, \; \text{ if $y = 3$} \\
0, \; \text{ if $y = 0$}.
\end{cases}
$$ Given $y \in \mathbb{Z}/2$ , we then have \begin{align*}
(f \circ g_1)(y) = f(g_1 (y)) = \begin{cases}
f(1), \; \text{ if $y = 1$} \\ f(0), \; \text{ if $y = 0$} 
\end{cases} \hspace{-2.5mm} = \begin{cases}
1, \; \text{ if $y = 1$} \\
0, \; \text{ if $y = 0$} 
\end{cases}
\end{align*} so $f \circ g = \mathrm{id}_Y$ . Similarly, for any $y \in \mathbb{Z}/2$ , we have \begin{align*}
(f \circ g_2)(y) = f(g_2 (y)) = \begin{cases}
f(3), \; \text{ if $y = 1$} \\ f(0), \; \text{ if $y = 0$} 
\end{cases} \hspace{-2.5mm} = \begin{cases}
1, \; \text{ if $y = 1$} \\
0, \; \text{ if $y = 0$} \end{cases},
\end{align*} so $f \circ g_2 = \mathrm{id}_Y$ , so $g_1 \neq g_2$ are both right inverses of $f$ . I believe the above is correct unless there is a more 'general' approach than a simple counterexample. Now, for part (b), beginning with the forward direction. Suppose that $f$ admits a left inverse $g: Y \to X$ . Given $a,b \in X$ for which $f(a) = f(b)$ , we have \begin{align*}
a = \mathrm{id}_X (a) = (g \circ f)(a) = g(f(a)) = g(f(b)) = (g \circ f)(b) = \mathrm{id}_X (b) = b,
\end{align*} so $f$ is injective. Again, I feel fairly confident about the forward direction, but less so about the backward direction. Suppose that $f: X \to Y$ is injective. Fix $x_0 \in X$ , and define the map $g: Y \to X$ by $$ 
y \longmapsto \begin{cases}
x, \; & \text{ if $y = f(x)$ for some $x \in X$} \\
x_0, \; & \text{ if $y \not \in f(X)$}
\end{cases}
$$ This map is well-defined because if $y \in f(X)$ , its preimage in $X$ is unique because $f$ is injective. Then, for any $x \in X$ for which $f(x) = y$ for a unique $y \in Y$ , we have \begin{align*}
(g \circ f)(x) = g(f(x)) = g(y) = y,
\end{align*} so $g \circ f = \mathrm{id}_X$ , as desired. Again, I'm not sure if it's fully rigorous to define $f(x) = y$ , or if I should argue that $x$ is the unique element of $X$ mapping to $y$ or, simply, that $g \circ f = \mathrm{Id}_X$ by definition. Here is the final step that a left inverse isn't unique. I claim that a left inverse is not, in general, unique. Let $X = \{1,2\}$ and $Y = \{3,4,5\}$ , and define the map $f: X \to Y$ by $1 \longmapsto 3$ , $2 \longmapsto 4$ . Then we can define the following two inverses: \begin{align*}
& g_1: Y \to X, \; 3 \longmapsto 1, 4 \longmapsto 2, 5 \longmapsto 1 \\
& g_1: Y \to X, \; 3 \longmapsto 1, 4 \longmapsto 2, 5 \longmapsto 2.
\end{align*} How do these look? My main concerns, as I noted, are (1) the edge cases; (2) the proof that I constructed a proper left inverse; (3) the proof that I constructed a proper right inverse; and (4) the way to notate the left inverse $g: Y \to A$ , because the definition, though it is well-defined, sounds as though it isn't well-defined (i.e., the ""for some $x \in X$ "").","['elementary-set-theory', 'solution-verification']"
4130127,Bartle exercise 9.N from elements of integration,"The exercise states:
Let $X$ be a set, $\mathbf{A}$ an algebra of subsets of $X$ , and $\mu$ a measure on $\mathbf{A}$ . If $B\subset X$ is arbitrary, let $$\mu'(B)=\inf\{\mu(A):B\subset A\in\mathbf{A}\}$$ and $$\mu^*(B)=\inf\{\sum_{n=1}^\infty \mu(I_n):B\subset \bigcup_{n=1}^\infty I_n,\{I_n\}_{n\in \mathbb{N}}\subset \mathbf{A}\}$$ Show that $\mu'(E)=\mu(E)$ for all $E\in \mathbf{A} $ and that $\mu^*(B)\leq \mu'(B)$ . Moreover, $\mu^*=\mu'$ in case $X$ is the countable union of sets with finite $\mu$ -measure. My question: I already proved all but the ""Moreover, $\mu^*=\mu'$ in case $X$ is the countable union of sets with finite $\mu$ -measure"". To prove it one must show that in that case $$\mu^*(B)\geq\mu'(B)$$ for all $B\subset X$ . Any hints or suggestions?","['measure-theory', 'outer-measure', 'analysis']"
4130129,"Can we define $z^{\frac{m}{n}}$, where $z\in\mathbb{C}$ and $m,n\in\mathbb{Z}$?","I was thinking that it might has to be $m$ and $n$ coprimes, but I don't have a consolidated idea of how I can prove it. Incidentally, how could I prove that it doesn't work for any integers? (is there any counterexample? I was thinking about $z^{\frac{1}{2}}=\pm z$ ). So, my first question is, Can we define $z^{\frac{m}{n}}$ , where $z\in\mathbb{C}$ and $m,n\in\mathbb{Z}$ ? After that, if the answer is ""no"", can we say something using that fact that i said previously? PS: I need to prove that statement without using exponential definition of complex numbers. So, what I need to use is: Find a $z$ that satisfies $z^n=z_0$ with: $$z=\sqrt[n]{|z_0|}\left(\cos\left(\frac{\theta_0+2k\pi}{n}\right)+i\sin\left(\frac{\theta_0+2k\pi}{n}\right)\right),\text{ for all }k\in\mathbb{Z}.$$","['complex-analysis', 'complex-numbers']"
4130146,"For positive integer $n$, why is $\lfloor \log_{10}(2^n)\rfloor + \lfloor \log_{10}(5^n)\rfloor + 2 = n+1$?","For positive integer $n$ , why is $\lfloor \log_{10}(2^n)\rfloor + \lfloor \log_{10}(5^n)\rfloor + 2 = n+1$ ? This question comes from counting the number of digits of $10^n$ in terms of the number of digits of $2^n$ and $5^n$ . Number of digits of $10^n$ is $n+1$ which equals to the  sum of the number of digits of $2^n$ and $5^n$ . I know that the number of digits of a positive integer $x$ is $\lfloor \log_{10}(x)\rfloor + 1$ . Using programming, I've checked that this is true for $n$ less than $100$ .","['algebra-precalculus', 'integers', 'ceiling-and-floor-functions', 'logarithms']"
4130174,Set of possible limits of two-variable functions along curves -- connected?,"I am currently teaching a multivariable calculus class and trying to come up with problems for the final exam, in particular a problem about multivariable limits. The following question popped into my head: Let $f(x,y) = \frac{P(x,y)}{Q(x,y)}$ be a rational function ( $P$ and $Q$ are polynomials) with $P(0,0) = Q(0,0) = 0$ . For different curves $C: [0,1] \to \mathbb{R}^2$ with $C(0) = (0,0)$ , the limits $\lim\limits_{t \to 0} f(C(t))$ may depend on $C$ , or might not even exist. What can we say about the set of (extended) real numbers $L$ which are limits of $f$ along some curve $C$ ? My gut instinct is that this set should be a connected subset of the extended real line, but I haven't been able to prove it. Comments: If it makes the problem easier, feel free to assume that $Q \neq 0$ in a neighborhood of the origin. I don't necessarily care about the most general result, I'm just interested in any kind of result. I don't think it should matter, but let's let our curves be any continuous curves. Would the answer change if we forced our curves to be $C^1$ or $C^\infty$ ? Or algebraic? I only asked that $f$ is a rational function because those are the kinds of functions we tend to give students in multivariable calculus classes -- also, my first attempt at this was to rewrite $\frac{P}{Q} = k$ as $P - kQ = 0$ and try to think about the geometry of that as a polynomial equation in three variables. But I suspect that whatever we could say about rational functions we could also say about functions which are just continuous away from the origin. My two attempts: Rewrite $\frac{P}{Q} = k$ as $P - kQ = 0$ which is now just a polynomial equation. I thought at first that maybe something along the lines of ""for most values of $L$ which are the limit along some curve, there is in fact a curve to $(0,0)$ along which the function is a constant $L$ "" but I'm not sure if that's actually true. Suppose that $A$ and $B$ are curves along which $f$ has limits $a$ and $b$ respectively, and let $c$ be between $a$ and $b$ . Reparametrize them so that $|A(t)| = |B(t)|$ for all $t$ . For each $t$ , look at the circular arc between $A(t)$ and $B(t)$ . I want to use the intermediate value theorem to pick points, for each $t$ , along this arc which are close to $c$ . (The function is continuous and there are points near the origin along $A$ which are close to $a$ and along $B$ which are close to $b$ so there should be points in between them which are close to $c$ .) But it's not clear to me that we can choose such points $C(t)$ for each $t$ in a way that makes the resulting function $t \mapsto C(t)$ continuous.","['limits', 'multivariable-calculus', 'real-analysis']"
4130225,$\cos ^{-1} x-\cos ^{-1} y$,"$$
\cos ^{-1} x-\cos ^{-1} y=\left\{\begin{array}{l}
\cos ^{-1}\left(x y+\sqrt{1-x^{2}} \sqrt{1-y^{2}}\right) ; \text { if }-1 \leq x, y \leq 1 \quad \text{and} \quad x \leq y \\
-\cos ^{-1}\left(x y+\sqrt{1-x^{2}} \sqrt{1-y^{2}}\right) ; \text { if }-1 \leq y \leq 0,0<x \leq 1 \quad \text{and} \quad x \geqslant 1
\end{array}\right.
$$ I'm having some issues proving for different cases, this is what I tried so far: Let $\cos ^{-1} x=\alpha, \quad \cos ^{-1} y=\beta \quad \Longrightarrow \quad x=\cos \alpha, y=\cos \beta$ $$
\begin{aligned}
\cos (\alpha-\beta) &=\cos \alpha \cos \beta+\sin \alpha \sin \beta \\
&=\cos \alpha \cos \beta+\sqrt{1-\cos ^{2} \alpha} \sqrt{1-\cos ^{2} \beta} \\
&=\left(x y+\sqrt{1-\cos ^{2} \alpha} \sqrt{1-\cos ^{2} \beta}\right)
\end{aligned}
$$ $$
\begin{aligned}
\therefore \alpha-\beta &=\cos ^{-1} x-\cos ^{-1} y \\
&=\cos ^{-1}\left(x y+\sqrt{1-x^{2}} \sqrt{1-y^{2}}\right)
\end{aligned}
$$",['trigonometry']
4130247,Differentiate $x^{a^x}$ without logarithmic differentiation?,"Problem. Compute $\frac{d}{dx} x^{a^x}$ . Method 1: Logarithmic Differentiation (Correct): \begin{align*}
y&= x^{a^x} \\
\ln(y)&=a^x \cdot \ln(x) \\
\frac{1}{y} \frac{dy}{dx} &=a^x \frac{1}{x} + \ln(x) \ln(a) a^x \\
\frac{dy}{dx} &= y\left(\frac{1}{x} a^x + \ln(a) \ln(x) a^x\right) \\
\frac{dy}{dx} &= x^{a^x}\left(\frac{1}{x} a^x + \ln(a) \ln(x) a^x\right) \\
\frac{dy}{dx} &= a^x x^{a^x}\left(\frac{1}{x} + \ln(a) \ln(x)\right) \\
\frac{dy}{dx} &= a^x x^{a^x-1}\left(1 + x\ln(a) \ln(x) \right) \\
\end{align*} Method 2: Chain Rule (Incorrect): \begin{align*}
y&= x^{a^x} \\
\frac{dy}{dx} &= a^x x^{a^x-1} \cdot \left[\ln(a) \cdot a^x\right]
\end{align*} Method 2 is incorrect because it $x^{a^x}$ is not a power function, so we cannot apply power rule (thanks @Alann_Rosas and @Parcly_Taxel). My Question: Can Ninad Munshi's answer here be adopted to correct method 2 without the use of logarithmic differentiation? What is the name (and/or proof) of this generalized version of chain rule? Thank you!","['logarithms', 'calculus', 'derivatives', 'exponential-function', 'chain-rule']"
4130270,A conservative vector field on the unit sphere,"Consider the unit sphere $x^2+y^2+z^2=1$ and a vector field $$(x(y^2-z^2), -y(x^2+2z^2), z(x^2+2y^2)).$$ on the sphere. Show that this vector field is conservative on the sphere and find a potential function of it. I know how to show the vector field is conservative. One can simply show that the line integral of this vector field over any simple closed curve on the sphere is 0. However, I am not sure how to find a potential function of this vector field.","['manifolds', 'multivariable-calculus', 'vector-fields']"
4130280,"A nonnegative function $f(a,b)\geq 0$","Let $c$ be a fixed positive real  umber such that $c\geq 1.$ If $a\geq c^m, b\geq c, $ where $m$ is any positive integer, then is $$f(a,b)=c(ab+1)(a-c^m)(b-c)+c(ab+1)(a-c^m)(b+1)+c^m(b-c)(ab+1)(a+1)-(ab-c^{m+1})(a+1)(b+1)\geq 0?$$ We can check the validity for the two  cases $a=c^m,$ or $b=c$ easily. In fact the equality in the above claim  occurs at $(a, b)=(c^m,c).$ Kindly suggest me the way  to establish $f(a,b)\geq 0$ if it is true.","['real-numbers', 'multivariable-calculus', 'inequality']"
4130303,Ways to prove a relation featuring $\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx$,"From a previous post the following integral arised: $$\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx$$ And there user178256 linked us to this question where the user M.N.C.E. stated the following: $$\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx=\frac{1}{24}\int _0^{\infty }\frac{\ln ^4\left(1+x^2\right)}{x^2}\:dx+\frac{2}{3}\int _0^{\infty }\frac{\arctan ^4\left(x\right)}{x^2}\:dx$$ My question is, how can we prove this relation without evaluating each integral while also avoiding complex numbers? What I thought of doing is to use the following algebraic identity: $$a^2b^2=\frac{1}{12}\left(a+b\right)^4+\frac{1}{12}\left(a-b\right)^4-\frac{1}{6}a^4-\frac{1}{6}b^4$$ This means that if we set $a=\arctan\left(x\right)$ and $b=\ln\left(1+x^2\right)$ we have: $$\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx=\frac{1}{12}\int _0^{\infty }\frac{\left(\arctan \left(x\right)+\ln \left(1+x^2\right)\right)^4}{x^2}\:dx$$ $$+\frac{1}{12}\int _0^{\infty }\frac{\left(\arctan \left(x\right)-\ln \left(1+x^2\right)\right)^4}{x^2}\:dx-\frac{1}{6}\int _0^{\infty }\frac{\arctan ^4\left(x\right)}{x^2}\:dx-\frac{1}{6}\int _0^{\infty }\frac{\ln ^4\left(1+x^2\right)}{x^2}\:dx$$ Though I'm having a little bit of trouble getting somewhere with the first $2$ integrals, any help will be well received.","['integration', 'calculus', 'definite-integrals']"
4130364,Two conjectures about the prime counting function : $\frac{\pi{(x)}}{\pi{(\pi{(x)}})}<\ln(x)$,Let $x\geq 100$ then we have as conjecture : $$\frac{\pi{(x)}}{\pi{(\pi{(x)}})}<\ln(x)$$ I have tested at $x=100$ to $x=5000000000$ without any counter-example. The first fact : It seems that the function : $$f(x)=\frac{\pi{(x)}}{\pi{(\pi{(x)}})}-\ln(x)$$ Can be associated to a  decreasing function $h(x)$ for $x\geq 100$ .I have no informations on $h(x)$ . To show it I have tried to use the PNT wich states : $$\lim_{x\to \infty}\frac{\pi(x)}{\frac{x}{\ln(x)}}=1$$ But this is an asymptotic information and I don't see any good outcome . I have also a stronger statement : Let $x\geq 10^{10}$ then we have : $$\frac{\pi{(x)}}{\pi{(\pi{(x)}})}<\ln(x)-\ln(\ln(x))-1$$ But I have serious doubt on this second conjecture. Edit : Now I have an equality wich is also a conjecture : Let $x\geq 10^{10}$ then we have : $$\lfloor\frac{\pi{(x)}}{\pi{(\pi{(x)}})}\rfloor\pm 0.5=\lfloor \ln(x)-\ln(\ln(x))-1\rfloor\pm 0.5$$ Warning with the sign $\pm$ we can have  4 possibilities not simultaneously of course! Question: Can you prove or disprove it ? Is it well-know ? Thanks in advance for your effort !,"['analytic-number-theory', 'number-theory', 'inequality', 'prime-numbers']"
4130497,Find $\int_0^1 \frac{f(x)}{\sqrt{1+x^2}}dx$,"Let $f(x)$ be continuous on $[0;1]$ , with $f(0) = 0; f(1) = 1$ and $$\int_0^1 [f'(x)]^2 \sqrt{1+x^2} \,dx = \dfrac{1}{\ln\left(1+\sqrt{2}\right)}$$ Find ${\displaystyle \int_0^1} \dfrac{f(x)}{\sqrt{1+x^2}} \,dx$ Attempt: I tried to use Cauchy-Scharwz as below: $$\int_0^1 [f'(x)]^2 \sqrt{1+x^2} \,dx \cdot \int_0^1 \dfrac{f(x)}{\sqrt{1+x^2}} \,dx \geq \left(\int_0^1 \sqrt{[f'(x)]^2 \sqrt{1+x^2}} \cdot \sqrt{\dfrac{f(x)}{\sqrt{1+x^2}}} \,dx\right)^2$$ $$\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,=\left(\int_0^1 f'(x) \sqrt{f(x)} \,dx\right)^2$$ I was able to find ${\displaystyle \int_0^1} f'(x) \sqrt{f(x)} \,dx = \dfrac{2}{3}$ , but the problem is I can't show if the equality is happen or not, so my attempt isn't helpful at all. Is there a better way to approach this?","['integration', 'calculus', 'definite-integrals', 'real-analysis']"
4130565,Very Basic Ito's Formula Problem,"Let $(X_t)_{t≥0}$ be an Ito process of the form $dX_t = µ(t)dt + σ(t)dW_t$ for some $µ ∈ \mathbb{L}^1(0, T)$ and $σ ∈ \mathbb{L}^2(0, T)$ . I have been asked to apply Ito’s formula to $Y_t = g(t, X_t)$ for $g(t, x) = e^x + t \,sin(x)$ to write $Y_t$ as an Ito process. So far, I have calculated the partial derivatives: $$g_t = sin(x)$$ $$g_x = e^x + t\,cos(x)$$ $$g_{xx}=e^x - t\, sin(x)$$ And I have plugged these into Ito's formula to give: $$dY_t = sin(X_t)\, dt\, + \, (e^{X_t} + t \, cos(X_t)) \, dX_t \, + \, \frac{1}{2}\sigma^2(e^{X_t} \, - \, t\, sin(X_t))\, dt$$ However I am told this is incorrect, and it also needs further steps. Can anyone help guide me in the right direction and inform me where I have went wrong? EDIT: I am told that the final solution is as follows: $$dg(t, X_t) = (sin(X_t) + (e^{X_t} + t\,cos(X_t))\mu(t) + \frac{1}{2}(e^{X_t} - t\,sin(X_t)\sigma^2(t)))\, dt \, + (e^{X_t} + t\,cos(X_t))\sigma(t)\,dW_t$$","['stochastic-processes', 'calculus', 'derivatives', 'brownian-motion']"
4130590,Deformation of a Rigid Scheme is étale Locally Trivial.,"This question is from ex.III.9.10, Hartshorne. All scheme are finite type over an algebraically closed field $k$ . Let $f: X \rightarrow T$ be a flat projective morphism from $X$ to a nonsingular curve $T$ . Assume that there is a closed point $t \in T$ s.t. $X_t \sim \mathbb{P}^1_k$ . Then we need to show that there is a nonsingular curve $T'$ and a flat morphism $g: T' \rightarrow T$ whose image contains $T$ and $X' = X \times_T T'$ is isomorphic to $\mathbb{P}^1_{T'}$ . By flatness and smoothness of the fibre of $t$ , we know that $f$ is smooth in a neighbourhood of every point of $X_t$ . But the singular locus is closed and its image by $f$ is closed not containing $t$ . Hence we have a neighbourhood $U$ of $t$ s.t. $f^{-1}(U)$ is in the smooth locus, i.e. $f: f^{-1}(U) \rightarrow U$ is smooth. Now by flatness $f_* \mathcal{O}_X$ is torsion free hence flat and locally free. By formal function theorem we know that it is of rank one. So every fibre is smooth connected curve of arithmetic genus $0$ , which must be $\mathbb{P}^1$ . Now we have reduced to the situation of a smooth family of $\mathbb{P}^1$ over a smooth curve. It remains to find the suitable local base $T'$ . Moreover, I wonder whether we can choose $g$ to be étale. It seems reasonable since étaleness is a reasonable replacement of analytically localness. And when a scheme is rigid, I don't wish that it can be trivialized only after ramified base change.","['algebraic-geometry', 'deformation-theory']"
4130609,"Find surjective, continuous function such that diagram commutes [closed]","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question If we have a continuous function $g\colon X\to X$ with $g(Y)\subset Y$ and $h\colon Y\to Y$ , where $h$ is the restriction of $g$ to $Y\subset X$ , is there a continuous, surjective function $\pi\colon X\to Y$ such that $$
\pi\circ g = h\circ\pi?
$$",['analysis']
4130618,"If $X,Y$ and $Z$ are independent, then $\sigma(X,Y)$ and $\sigma(Z)$ are independent","If we have 3 independent random variables $X,Y$ and $Z$ on a probability space $(\Omega,\mathscr{F},\mathbb{P})$ , then how do we show that $\sigma(X,Y)$ and $\sigma(Z)$ are independent? It feels intuitively obvious, but I'm having real difficulty making it precise. I feel like using the fact that if two measures $\mu _1$ and $\mu _2$ are equal on a $\pi$ system $\mathscr{A}$ then they are equal on $\sigma (\mathscr{A})$ could be useful, but am unsure exactly what measures/ $\pi$ systems to use. Any help would be really appreciated - thanks! :)","['measure-theory', 'independence', 'probability-theory']"
4130691,How to calculate the lower and upper bound of the error in estimating a ratio with low sample size?,"I have the following problem, I am trying to estimate the conversion rate of product sales online, my data is simple,
I have the number of clicks and the number of sales for each product. Sales are sparse so there are few sales per product. how can I estimate the upper and lower bound of the error on each product? For example, if I have 21 clicks and 1 sale, the conversion rate is 1/21=0.07, I want to be able to add a lower and upper bound on the error of this estimation. Thank you","['descriptive-statistics', 'statistics', 'estimation']"
4130696,Find area of the largest possible triangle inscribed in the cardioid $r=1-\cos\theta$.,"The best I can do is the triangle with vertices (in rectangular coordinates) $(0,1)$ , $(0,-1)$ and $(-2,0)$ . Can you do better or prove this yields maximal area? I can show this is maximal for all triangles with either one vertex at $(0,0)$ or with one side that contains the point $(0,0)$ .","['optimization', 'triangles', 'area', 'geometry']"
4130708,Describe a subset of $R^{3}$ and modify the order of an iterated triple integral,"I have come to a problem in a multivariate calculus book that I am having trouble solving. The problem goes : If $D \subseteq \mathbb{R}^{3}$ and : \begin{equation}
\int\int\int_{D} d(x,y,z) = \int_{-1}^{1} \left[ \int_{x^{2}}^{1} \left( \int_{0}^{1-y} dz\right)dy\right]dx
\end{equation} then describe $D$ . Rewrite the triple integral as an iterated integral in which $dx$ , $dy$ , and $dz$ appear in each of the following orders (i.) $dz,dx,dy$ , (ii.) $dx,dy,dz$ , (iii.) $dx,dz,dy$ , (iv.) $dy,dz,dx$ , (v.) $dy,dx,dz$ . I'm not sure how to approach this problem. I was able to do previous problems in the book that required changing the order of 2D iterated integrals, but in the 3D case I am having more trouble. Can someone help with this ? Edit : After reading the comments, I have come up with a possible solution. The solution is below : We have for the cross section perpendicular to the z-axis at $z = 0$ : Now suppose we have $E \subset \mathbb{R}^{3}$ s.t. : \begin{equation}
\int\int\int_{E} d(x,y,z) = \int_{-1}^{1} \left[ \int_{x^{2}}^{1} \left( \int_{0}^{1} dz \right) dy \right] dx
\end{equation} Then $E$ is a parabolic cylinder with height $1$ and base at the plane corresponding to $z = 0$ : \begin{equation}
E = \{ (x,y,z) \in \mathbb{R}^{3} \; : \; x \in [-1,1] \text{ and } y \in [x^{2},1] \text{ and } z \in [0,1] \}
\end{equation} $D$ is a subset of $E$ . Define plane $P$ : \begin{equation}
P = \{ (x,y,z) \in \mathbb{R}^{3} \; : \; y + z = 1 \}
\end{equation} Now define region of $\mathbb{R}^{3}$ below $P$ : \begin{equation}
M = \{ (x,y,z) \in \mathbb{R}^{3} \; : \; y + z \leq 1 \}
\end{equation} We see : \begin{equation}
D = \{ (x,y,z) \in \mathbb{R}^{3} \; : \; (x,y,z) \in E \bigcap M \}
\end{equation} We see : \begin{equation}
y + z \leq 1 \Leftrightarrow y \leq 1 - z
\end{equation} We see : \begin{equation}
y = x^{2} \Rightarrow x = \pm \sqrt{y}
\end{equation} So for plane $z = z_{0}$ we have the cross section of $D$ : So you can peform the integration by adding up slices like those shown above. In this case the order is $[dy,dx,dz]$ or $[dx,dy,dz]$ I believe. Let : \begin{equation}
I = \int\int\int_{D} d(x,y,z)
\end{equation} Then I think we have for $dy,dx,dz$ : \begin{equation}
I = \int_{0}^{1} \left[ \int_{-\sqrt{1-z}}^{\sqrt{1-z}} \left( \int_{0}^{x^{2}} dy \right) dx \right] dz \; \checkmark
\end{equation} and : \begin{equation}
I = \int_{0}^{1} \left[ \int_{0}^{1-z} \left( \int_{-\sqrt{y}}^{\sqrt{y}} dx \right) dy \right] dz \; \checkmark
\end{equation} Now still need $[dz,dx,dy]$ , $[dx,dz,dy]$ , and $[dy,dz,dx]$ . For $[dz,dx,dy]$ and $[dx,dz,dy]$ we will need to sum cross sections that are perpendicular to the y-axis. We can draw the cross-section of $D$ at $y = y_{0}$ as : So we have : \begin{equation}
I = \int_{0}^{1} \left[ \int_{-\sqrt{y}}^{\sqrt{y}} \left( \int_{0}^{1-x^{2}} dz \right) dx \right] dy \; \checkmark
\end{equation} and : \begin{equation}
I = \int_{0}^{1} \left[ \int_{0}^{1-y} \left( \int_{-\sqrt{1-z}}^{\sqrt{1-z}} dx \right) dz \right] dy \; \checkmark
\end{equation} Now only need $[dy,dz,dx]$ . We see : \begin{align}
y \in [x^{2},1] \text{ and } z \in [0,1-y] 	& \Rightarrow z \in [1-1,1-x^{2}]\\
						& \Rightarrow z \in [0,1-x^{2}]
\end{align} We see : \begin{align}
z = 1-x^{2} 	& \Leftrightarrow z - 1 = -x^{2} \\
		& \Leftrightarrow 1 - z = x^{2}
\end{align} So : \begin{equation}
y \in [x^{2},1] \Rightarrow y \in [1-z,1]
\end{equation} and : \begin{equation}
I = \int_{-1}^{1} \left[ \int_{0}^{1-x^{2}} \left( \int_{1-z}^{1} dy \right) dz \right] dx \; \checkmark
\end{equation}",['multivariable-calculus']
4130740,Limit of the sequence $x_{n+1}=x_n(2-ax_n)$ For some real $a$ positive.,Find the limit of the following recurrence relation $$x_{n+1}=x_n(2-ax_n)$$ For some real $a$ positive. I don't know how to find a closed form of the given recurrence relation and since I don't have any initial value so I cannot check OEIS sequence for a possible solution.,"['limits', 'calculus', 'recurrence-relations', 'sequences-and-series']"
